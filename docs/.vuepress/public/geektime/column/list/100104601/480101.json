{"id":480101,"title":"01 | 爬虫需求的诞生：我们是正经的软件工程师","content":"<p>你好，我是DS Hunter，反爬虫专家。</p><p>也许你是一个爬虫工程师，也许是反爬虫工程师，甚至，也许你只是一个业务方的普通研发，被授予了反爬的重任。但是，不论你的身份是什么，“什么是爬虫”这个问题都是你必须要了解的。</p><p>为什么这么说呢？</p><p>可能你常把爬虫挂在嘴边，觉得自己已经很熟悉爬虫了，但当你尝试自己做一个爬虫或者完成一个反爬虫动作时，却发现无从下手。其实，很大的一个原因就是你对于“什么是爬虫”这个问题了解得并不透彻。</p><p>从历史的视角来了解爬虫从哪里来、能做什么，以及从诞生到现在的这段时间里都发生了什么样的变化，可以让你对“什么是爬虫”这个问题产生更深度的思考，这也是我要在课程里特地为你设置一个“历史背景篇”的主要原因。咱们接下来正式开始吧。</p><h2><strong>什么是爬虫？</strong></h2><p>爬虫是一个历史悠久的需求，严格来说，它甚至比网络出现得还早。或者你也可以理解为，网络出现之后，网络和爬虫才结合成了我们所熟知的网络爬虫。因为互联网大部分的功能其实并没有什么新意，只不过是把线下的场景搬到线上来了。</p><p>而爬虫，其实就起源于线下。再聚焦一些，爬虫，起源于再平常不过的——菜市场。</p><h3>买菜和爬虫？买菜也爬虫？</h3><p>前几天我听了一首很喜欢的歌，叫《说走就走》。里面有一段话，说的是：“走世界，看精彩，从18岁讲到现在，最后到巷口去买菜。”</p><!-- [[[read_end]]] --><p>本意是说，年少充满理想，长大后被生活压垮，每天沉迷于菜场买菜这种小事，再也没有了理想。但是实际上，<strong>买菜并不是小事，它充满了技术含量。</strong></p><p>菜场买菜的大妈们砍价非常厉害——我感觉我这辈子都学不来。对她们来说，即使只差一毛钱，也可能会让她们选择去别的摊位买菜。也许你不太理解这种行为，觉得，我都在这问了价了，就因为隔壁少一毛钱，就去隔壁，这多不好意思啊。但是对于菜场的顾客来说，这很正常啊，“同样的东西， 哪里便宜我就去哪呗”，这是再正常不过的“<strong>博弈</strong>”了。</p><p>说回喜欢在网上买东西的你。一个小东西，A网站比B网站便宜一毛钱，你是不是就果断抛弃了B网站？或者A说，价格一样，我包邮。你是不是就直接去A网站买了？这个时候，因为没有面对面的交流，你就没什么不好意思的了。所以说，趋利避害这是人性使然，自古如此，与年代性格都无关。<strong>只要有人的地方，就会有“博弈”。</strong></p><p>最后，在买菜或者买东西的故事里，除了“你”这个主角，商贩们其实也没闲着。他们也会做一些操作，比如让自己的家人去四处转转，看看别的摊位卖多少钱、有没有偷偷降价。如果有顾客来自己的摊位买菜，也会顺便问问，“哎你这个菜多少钱买的啊”，只要不低于成本，他就敢降到一样的价格，甚至更低。</p><p>实际上，大妈们获取价格的方法、你对比价格的过程以及商贩们相互获取价格的方法，都可以理解为“爬虫”行为，和网络爬虫其实也没有什么区别。只是人工问价效率低，爬虫效率高。价格，就是在这样不断博弈的过程中，慢慢均衡下来的。而博弈的第一步，就是“问价”——<strong>获取数据</strong>。</p><h3>不止买菜：我只是要数据</h3><p>为什么获取数据这么重要？其实《孙子兵法》就提到过：知彼知己者，百战不殆。商场如战场，获取数据自古就是胜负的关键。</p><p>至于获取数据的需求是怎么产生的，我给你举个例子吧。获取数据的手段——爬虫，很难学的一个主要原因就是描述它的词汇太多了。你可以看下网络上对爬虫的定义，有几个常用的词：爬虫、抓取、spider、crawler……可能我也说不全。日常使用的话，这些词你随便挑哪一个都行。但是搜索对应知识的时候，为了更全面一些，就要全搜一遍。那如果你不想连搜四次，怎样操作才能<strong>一次性拿到所有的结果</strong>呢？</p><p>这个时候，聪明的你可能已经想到了，我要不要写个爬虫全拿下来呢？恭喜你，你为了获取爬虫的知识，已经自发地产生了一个爬虫的需求。</p><p>因此你会发现，<strong>爬虫需求的产生是自然而然的，</strong>而你的需求不一定是一个坏的需求——你看，我们多正经。是的，技术只是工具，与善恶无关。</p><p>最早的Google工程师就是这么想的，或者再早的Yahoo。我们无从得知当时具体发生了什么、第一个爬虫是如何被写出来的。但可以想象的是，<strong>因为当时的互联网数据越来越多，获取信息变得越来越难，于是他们就写了一个网络爬虫来获取数据。</strong>从此，潘多拉的魔盒就被打开，后面的事情就不再可控了。</p><h2>搜索引擎和爬虫</h2><p>既然提到了Google和Yahoo，我们就紧接着从历史视角，审视一下搜索引擎和爬虫的关系，看看爬虫的早期历史和相关的技术变迁。</p><h3>美好的上古田园时代</h3><p>搜索引擎可以认为是爬虫的集大成者了。它本质上就是用爬虫<strong>爬取天下数据</strong>，汇聚在自己的网站上，让大家可以在自己的网站上直接<strong>搜索到全天下的知识。</strong>这个操作对于搜索引擎和站点两方都是有利的，搜索引擎自己能够获得稳定客户，甚至商业利益；站点本身可以获得流量，未来也可以获得商业价值。</p><p>为了这个双赢的局面，还引发了一个叫robots.txt（也叫robots协议）的君子协定，里面会约定，哪些可以爬，哪些不可以爬。但是因为大家很依赖搜索引擎，所以除非是用户信息，否则一般都是开放的。甚至有些站点不写robots.txt，默认对搜索引擎全部开放。除此之外，还可以写sitemap来指定自己网站都有什么，欢迎搜索引擎来赶紧爬走，给自己打个好评，引导用户过来。大家主动交流，相互沟通，真的是一个美好的上古田园时代。</p><h3>春秋时期</h3><p>但是美好的上古田园时代由于网络的不断发展，注定不会持久，很快，爬虫就发展到了春秋时期。</p><ul>\n<li><strong>春秋前期</strong></li>\n</ul><p>在春秋前期，爬虫已经不是新技术了。你的那个不懂技术的老板，可能都已经知道了：想要寻找大量数据，可以用爬虫去爬别人。所以，你就接受了这样的需求，开始学习相关的知识。</p><p>但是你也知道，网络历史从 TCP 到 HTTP，现在又回到了 TCP。随着历史的变化，爬虫本身的技术也会随之变化。毕竟，<strong>服务器使用了什么类型的网络，爬虫就要被迫使用什么类型的网络。</strong></p><ul>\n<li><strong>春秋中期</strong></li>\n</ul><p>当爬虫开始受网络发展的影响，就注定也会被其它因素影响。在春秋前期，大家逐渐产生“爬取数据”的需求，到了春秋中期，这些需求逐渐演变成了一个业务的雏形。也就是说，在这个时候，<strong>不同的业务开始对爬虫技术产生影响</strong>了。</p><p>咱们先说<strong>扒站</strong>这件事。最初爬虫都是一些大公司的特权，小公司自己的业务都做不完，哪有时间去搞爬虫。但是出于业务的需要，一个新的行为就诞生了——站点复制，俗称扒站。</p><p>也就是说，别人网站做得好，我刚创业，追赶别人根本来不及。怎么办呢？答案很简单，我写个爬虫把整个网站抓下来不就好了。然后把数据放在我的服务器上，就可以瞬间追上别人的进度，站在同一起跑线。</p><p>还有就是<strong>浏览量</strong>的需求了。站长很想让搜索引擎来爬自己的数据，因为有了搜索引擎的爬取，就会有排名，就会有业绩。而为了提高搜索引擎的分数，他们十分渴望搜索引擎来抓取自己所有的数据。</p><p>关于搜索引擎爬取自己数据的这件事，我们可以回顾一下历史。</p><p>早年的网站结构其实很简单，就是一个服务器，上面挂了一些静态的文件。有的站点甚至会打开目录遍历权限，也就是说你去找一个目录看一下，能直接看到目录下面有什么文件，这种站点扒起来简直太舒服了。 但是如果没有开目录遍历权限，就要麻烦很多了，似乎抓起来就没有前面说得那么容易。</p><p>好了，从历史回顾里跳出来，春秋中期的站长，为了给搜索引擎抓取数据提供便利，通常会有两种操作：一种是<strong>sitemap</strong>，也就是给整个站点建一个地图，给对方使用；还一种就是<strong>内链</strong>，通过自己不断引用自己，来实现引导爬虫爬取完整站。</p><p>这样一来，爬虫工程师的爬虫思路就显而易见了：既然站长提供了sitemap和内链两种便利，我只要声称自己是搜索引擎就好了。这样对方不但不会拒绝，还会引导我去爬取整个站点。这样，想扒整个站就变得非常容易。</p><p>你可能会觉得，这里有点引狼入室的感觉了——难道站长已经有准备了？没有。等狼真的来了也没有什么办法——撑死就是封一封明显太过分的IP。</p><p>最后我来给你总结一下这个时期爬虫的爬取思路吧。春秋中期，爬虫基本上就两个爬取思路，一个是<strong>深度优先遍历</strong>， 一个是<strong>广度优先遍历，</strong>它们的最终目的都是抓完整站。所以爬虫会有一个“spider”的名字，蜘蛛能结网，指的就是这个遍历方式。如果你以后面试的时候，面试官着重考查这两个知识点，你要理解，他已经很久不做爬虫了。这是远古时代的基本技能，现在大家已经不太关注这个了。</p><ul>\n<li><strong>春秋后期</strong></li>\n</ul><p>后来两件事情改变了这个行业的格局。一个是<strong>电子商务的出现和普及</strong>，一个是<strong>站点的动态化和伪静态化</strong>，我们也就随着这两件事从春秋中期进入到了春秋后期。</p><p>先看第一件事：电子商务的出现和普及。你还记不记得我在开头提到的一句话：互联网大部分功能其实并没有什么新意，只不过是把线下场景搬到线上来了。</p><p><strong>电子商务其实就是把菜场搬到了线上。</strong> 菜场有爬虫，电子商务就会有爬虫。与搜索引擎不同的是，商场如战场，战场上的较量，有时候就没有那么强调道德了。爬虫也就渐渐<strong>为所欲为</strong>了起来。</p><p>另一件事就是站点的动态化和伪静态化，动态化页面导致站点内容变得十分丰富，甚至可以认为近乎无穷无尽，通过改变参数就可以不断改变站点内容，这一点对搜索引擎非常不友好。但是好消息是，这一点对其它爬虫，一样很不友好。</p><p>因此，站点开始进行伪静态化。假装自己依然是个静态站点后，爬虫的需求开始变得复杂，单纯的深度优先和广度优先满足不了大家的要求了。尤其是随着Web 2.0的诞生，站点更加复杂，本身也开始了分层，界面是界面，数据是数据。那么我们的爬虫最关注的是什么？是数据。那就是说，爬虫甚至可以只抓数据，跳过界面。这个时候，爬虫就变得<strong>十分高效。</strong></p><p>不过，当爬虫变高效之后，服务器的噩梦就诞生了。由于前后端分离， 静态资源放置于CDN，通常并不是很怕爬虫。但是数据位于服务层，服务层比CDN脆弱得多，爬虫一来，可能<strong>打爆链接数</strong>，甚至可能<strong>击穿数据库</strong>、<strong>拖慢站点性能，</strong>各种诡异的情况都可能发生。</p><p>总的来说，<strong>电子商务的出现和普及</strong>以及<strong>站点的动态化和伪静态化</strong>这两件事出现之后，爬虫就很容易不小心惹事。很多文章都会教你，尽量控制频率，不要把站点爬挂。而我们被爬的站长那一方，他欢迎搜索引擎，但是不喜欢爬虫，不过依旧没有太好的办法区分彼此。</p><p>如果说爬虫是一场战争，那么现在的春秋时代，大家打仗还是讲究一个“礼”字的。截止到目前，还没有彻底崩坏。但是，根据历史我们可以知道，这样的事情不会持续多久，战国，很快就要来了。</p><h2>小结</h2><p>好了，最后我来给你小结一下。今天和你聊了爬虫的产生、早期历史以及一些相关的技术变迁。</p><p>可以说，“爬虫”是竞争的必然产物，而网络的出现，赋予了爬虫在互联网领域的生命。再次强调，这项技术只是工具，与善恶无关。</p><p><img src=\"https://static001.geekbang.org/resource/image/fb/c4/fb75017928052748b4d88267e86565c4.jpg?wh=1920x869\" alt=\"\"></p><p>在美好的上古田园时代，爬虫彬彬有礼，用技术不断辅助大家，让整个互联网变得更好。搜索引擎自己能够获得稳定客户，甚至商业利益。而站点本身可以获得流量，未来也可以获得商业价值。你看，<strong>需求正经，做的也是正经事</strong>。</p><p>截止到这个时候，爬虫还没有任何过错，还没有到现在这种人人喊打的地步。如果人类的爬虫技术止步于此，那么这个世界将非常美好。遗憾的是，人性自古不变，行业建设到一定程度就会产生内卷。</p><p>在春秋时期，随着不同业务需求的诞生，爬虫技术也随之发展。春秋前期，我们发现爬虫开始不停地迭代，适应网络环境。后来，春秋中期的扒站行为，本身已经是一种轻度内卷了。同时，站长出于对浏览量的需求，提供了sitemap这张地图以及内链的方式，助长了爬虫疯狂爬取的气焰。而到了春秋后期，电子商务更为爬虫增添了不少的商业气息，商人逐利，爬虫也逐渐为所欲为。站点的动态化和伪静态化，让爬虫直接爬取数据层，站点无法承受攻击……</p><p>下一讲，我们会进入到战国时期，看下礼乐制度彻底崩溃、内卷到血流成河的时候，整个行业会成为什么样子。而这，也是你我共同面临的环境。</p><h2>思考题</h2><p>好了，这次是我第一次给你留思考题。下面有三个方向，你可以选择一个来和我分享：</p><ol>\n<li>站长在喜欢搜索引擎的同时痛恨爬虫，不过搜索引擎本身也是一种爬虫。那么，假如一个爬虫冒充搜索引擎，怎么办？</li>\n<li>爬虫为这个世界做出了什么贡献？</li>\n<li>你的爬虫或者反爬虫经历是什么？有什么奇葩的经历吗？</li>\n</ol><p>期待你在评论区的分享，我会及时回复，不过要记得注意保密脱敏。</p><p><img src=\"https://static001.geekbang.org/resource/image/4c/5e/4c46d50182f789041ef81ef206fdcb5e.jpg?wh=1500x1615\" alt=\"\"></p>","neighbors":{"left":{"article_title":"开篇词 | 如何突破“爬虫反爬虫”内卷之怪现状？","id":480086},"right":{"article_title":"02 | 爬虫的内卷和黑化：我们变得不正经啦","id":480844}},"comments":[{"had_liked":false,"id":331535,"user_name":"程序员二师兄","can_delete":false,"product_type":"c1","uid":1205697,"ip_address":"","ucode":"C9E3B5B3358BDF","user_header":"https://static001.geekbang.org/account/avatar/00/12/65/c1/afcd981b.jpg","comment_is_top":false,"comment_ctime":1642644384,"is_pvip":false,"replies":[{"id":121139,"content":"哈哈哈，还抓过搜索引擎，可以。其实搜索引擎并不好抓，只是抓的少的时候不触发任务反爬处理，它们不当回事。","user_name":"作者回复","user_name_real":"编辑","uid":2662783,"ctime":1642657306,"ip_address":"","comment_id":331535,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100104601,"comment_content":"本人刚接触爬虫这一块不久，看到思考题留的作业，按照自己对爬虫浅薄的理解回答一下：\n\n1. 假如爬虫冒充搜索引擎，怎么办？\n\n以百度搜索引擎的爬虫为例、爬虫会带有标识，如 baiduspider，可以初步判断为搜索引擎。\n\n假如其他爬虫此时也加上了baiduspider的标识，那么可以根据robots.txt 协议来进行处理。\n\n爬虫所抓取的链接在robots.txt协议中，进一步可以认为搜索引擎。\n\n而往往其他爬虫不像搜索引擎，它是不遵守robots.txt协议的，它抓取的链接以及数据可能也不在约定的协议中，那么可以认为爬虫冒充了搜索引擎。\n\n此时对这类爬虫进行拦截，识别到这类爬虫后，接口可以返回非正常数据，还见过虚假数据，让竞争对手拿到的是虚假数据。\n\n2. 爬虫为这个世界做了什么贡献？\n\n个人认为，爬虫对这个世界最大的贡献是数据的聚合。\n\n没有爬虫之前，每个站点的数据都犹如一座孤岛，很难在众多孤岛找到所需要的数据，解决待满足的需求。\n\n搜索引擎的爬虫很好的解决这个问题，只需要一个输入框，输入想问的问题，搜索引擎将爬虫抓取到的数据进行优化，将更相关的资料优先展示在网页上。\n\n3. 你的爬虫或者反爬虫的经历是什么？有什么奇葩的经历吗？\n\n爬虫经历：\n一、\n为了找到某些关键词在搜索引擎的需求以及权重。\n将某一个关键词，通过爬虫的方式从各大搜索引擎获取前10条返回结果。\n搜索引擎能够返回的数据，说明需求量是比较大的。\n\n二、\n通过爬虫抓取第三方数据平台，获取文章以及短视频的各方面的数据。\n比如通过爬虫对短视频平台的视频去水印、视频文案提取。\n\n反爬虫经历：\n\n接口防刷。\n\n简单介绍一下背景，所在的公司有电商业务，当品牌做一些活动时，参与人数会比较多，而其中有小部分人会利用爬虫来刷接口。\n\n处理方法：\n针对用户的请求及频率，如果是爬虫，频率会比较高，增加图形验证码，通过图形验证码才能后续的操作。\n\n自己的奇葩经历：\n自从了解一些爬虫知识后，看到有意思的网站或者app，总是忍不住想抓包看一下它们的接口。\n\n经常魔怔，比如看到一些加密的请求，虽然不知道有什么意义，总是想研究一番，常常研究半天还是没能琢磨透。\n","like_count":8},{"had_liked":false,"id":333930,"user_name":"ll","can_delete":false,"product_type":"c1","uid":2444836,"ip_address":"","ucode":"FC12C35B9205D7","user_header":"https://static001.geekbang.org/account/avatar/00/25/4e/24/c491ac2b.jpg","comment_is_top":false,"comment_ctime":1644592772,"is_pvip":false,"replies":[{"id":121987,"content":"免费的就是最贵的，这里完美体现了这一点。","user_name":"作者回复","user_name_real":"编辑","uid":2662783,"ctime":1644649372,"ip_address":"","comment_id":333930,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100104601,"comment_content":"我的经历：\n1、 16年开始做爬虫，那个时候什么58、美团、淘宝什么的，数据都是免费爬，当时我们的一个目标就是怎么重复利用cpu，带宽，让我们的爬虫采集效率最快。那个时候淘宝的数据都是没有反爬的，我们的工作就是疯狂写爬虫，很少有反爬的，那个时候我记得我3个月写了快100跟网站的爬虫，所有爬虫一键爬起来的时候，那个壮观，现在想想都觉得我疯了；\n2、后来发现有些小的障碍了，比如下一页的连接是js生成的，网站要开始限制cookie了，某些登录验证需要梳理他的js逻辑了，比如微博和百度贴吧，不过那个时候捋下逻辑，还是可以搞定的，从那个时候开始，爬虫的速度，就再也不是面试的考点了，都是问怎么安全、稳定；\n3、 后来就发现了一些特别恶心的，比如请求的参数就一个很大的字符串，所有请求体的都是加密成一个字符串，验证header里也是加密的，每此请求header里的auth都是一次性的；完了js还没法逆向回去，或者说我没法逆向回去，你调试的时候还会定位到你，把你封ip，之前就被这么搞过，不过后来还是搞定了，我记得是瑞数科技的专门做的，都过去好多些年了，希望不要针对我；\n4、再后来就越来越觉得，几乎每个网站都有反爬虫，但是也不是突破不了，然而突破了好像对我们来说也意义不大，因为有些硬性的指标，比如你的账户、跟ip绑定后，限制了你的行为，只能有那么多次的访问上限，基本上限制死了单个账号的数据访问量，爬虫已经不是一个人可以做的事情了，背后需要很多账号、ip这样的资源，有时候感觉就是财力的比拼；甚至后来发现天眼查充了会员后，同样的接口，没充钱的数据你拿到是假数据，还需要研究他的js再处理一下，而会员就可以爬到真数据，我发现后震惊了，立马冲了个会员，工作量一下就降低了不少，才感觉到别人产品经理已经把挣钱放到我们爬虫开发人员身上了，再后来越来越发现，爬虫已经告别了西部牛仔--一个人闯荡的、单靠技术就能过得不错的时代了，以后的数据也会越来越难获取，爬虫也不再是一个人的武林了；\n5、 逐渐疏远爬虫，一想到破解后维护也是个大问题，就没有动力；\n\n现在想想，奇葩的经历，肯定要算天眼查要挣我们爬虫开发人员的钱，我是被震惊了","like_count":5,"discussions":[{"author":{"id":2662783,"avatar":"https://static001.geekbang.org/account/avatar/00/28/a1/7f/7303735d.jpg","nickname":"DS Hunter","note":"","ucode":"C7F2B79FC8A93A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":547398,"discussion_content":"哈哈哈，还抓过搜索引擎，可以。其实搜索引擎并不好抓，只是抓的少的时候不触发任务反爬处理，它们不当回事。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1642657306,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":332365,"user_name":"lidashuang","can_delete":false,"product_type":"c1","uid":1104850,"ip_address":"","ucode":"560ABE8032760E","user_header":"https://static001.geekbang.org/account/avatar/00/10/db/d2/e29f8834.jpg","comment_is_top":false,"comment_ctime":1643187427,"is_pvip":false,"replies":[{"id":121423,"content":"哈哈哈，美团反爬是很强，他们老板人也不错。主要你得看他是在什么样的对手下成长起来的。强大的对手能让你更强。呃这算招人广告不，无利益相关，理性分析而已😂😂😂","user_name":"作者回复","user_name_real":"编辑","uid":2662783,"ctime":1643204595,"ip_address":"","comment_id":332365,"utype":1}],"discussion_count":2,"race_medal":2,"score":2,"product_id":100104601,"comment_content":"爬过最难爬的是美团，各种给你下毒","like_count":3,"discussions":[{"author":{"id":2662783,"avatar":"https://static001.geekbang.org/account/avatar/00/28/a1/7f/7303735d.jpg","nickname":"DS Hunter","note":"","ucode":"C7F2B79FC8A93A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":550636,"discussion_content":"免费的就是最贵的，这里完美体现了这一点。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1644649373,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":332277,"user_name":"demo123567","can_delete":false,"product_type":"c1","uid":1116610,"ip_address":"","ucode":"4FE8E6AA361673","user_header":"https://static001.geekbang.org/account/avatar/00/11/09/c2/4e086a4b.jpg","comment_is_top":false,"comment_ctime":1643153985,"is_pvip":false,"replies":[{"id":121391,"content":"没错，两者可以结合用，ua做粗筛，然后ip细筛。","user_name":"作者回复","user_name_real":"编辑","uid":2662783,"ctime":1643159376,"ip_address":"","comment_id":332277,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100104601,"comment_content":"第一个问题应该是user-agent，虽然可以模拟；然后大型搜索引擎爬虫一般都是有固定的IP段，所以应该也可以识别","like_count":2,"discussions":[{"author":{"id":2662783,"avatar":"https://static001.geekbang.org/account/avatar/00/28/a1/7f/7303735d.jpg","nickname":"DS Hunter","note":"","ucode":"C7F2B79FC8A93A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":548347,"discussion_content":"没错，两者可以结合用，ua做粗筛，然后ip细筛。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1643159376,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":331561,"user_name":"fsc2016","can_delete":false,"product_type":"c1","uid":1255585,"ip_address":"","ucode":"5480F05703A974","user_header":"https://static001.geekbang.org/account/avatar/00/13/28/a1/fd2bfc25.jpg","comment_is_top":false,"comment_ctime":1642654225,"is_pvip":false,"replies":[{"id":121138,"content":"是的，移动端如果感兴趣，后续可以再出课程","user_name":"作者回复","user_name_real":"编辑","uid":2662783,"ctime":1642657113,"ip_address":"","comment_id":331561,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100104601,"comment_content":"感觉现在爬虫对抗，慢慢从web转战到移动端了","like_count":2,"discussions":[{"author":{"id":2662783,"avatar":"https://static001.geekbang.org/account/avatar/00/28/a1/7f/7303735d.jpg","nickname":"DS Hunter","note":"","ucode":"C7F2B79FC8A93A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":548347,"discussion_content":"没错，两者可以结合用，ua做粗筛，然后ip细筛。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1643159376,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":331514,"user_name":"peter","can_delete":false,"product_type":"c1","uid":1058183,"ip_address":"","ucode":"261C3FC001DE2D","user_header":"https://static001.geekbang.org/account/avatar/00/10/25/87/f3a69d1b.jpg","comment_is_top":false,"comment_ctime":1642638201,"is_pvip":false,"replies":[{"id":121141,"content":"太感动了，泣不成声。","user_name":"作者回复","user_name_real":"编辑","uid":2662783,"ctime":1642657408,"ip_address":"","comment_id":331514,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100104601,"comment_content":"写得太好啦，牛啊，文采真好，通顺，有趣，也没有错别字！！！！  我还有很多课程没有看，这个课程和自己目前的关系并不是很大，犹豫再三才买的。真庆幸自己没有错过这么好的文章。理工男能写这么好，不容易，不多见啊。","like_count":2,"discussions":[{"author":{"id":2662783,"avatar":"https://static001.geekbang.org/account/avatar/00/28/a1/7f/7303735d.jpg","nickname":"DS Hunter","note":"","ucode":"C7F2B79FC8A93A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":547396,"discussion_content":"是的，移动端如果感兴趣，后续可以再出课程","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1642657114,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":331451,"user_name":"GAC·DU","can_delete":false,"product_type":"c1","uid":1385403,"ip_address":"","ucode":"7847FBE1C13740","user_header":"https://static001.geekbang.org/account/avatar/00/15/23/bb/a1a61f7c.jpg","comment_is_top":false,"comment_ctime":1642589462,"is_pvip":false,"replies":[{"id":121110,"content":"然而还是有可能无效对吧，最关键，有效无效还很难验证。。。除非把对方收购了直接问他😂😂😂","user_name":"作者回复","user_name_real":"编辑","uid":2662783,"ctime":1642607517,"ip_address":"","comment_id":331451,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100104601,"comment_content":"一次经历见证了一家公司技术的成长，甚至把后端由15人加到了30。从携cookie能登录到手机验证码再到扫脸登录，api加了token，后来把限流和熔断也加上了。","like_count":2,"discussions":[{"author":{"id":2662783,"avatar":"https://static001.geekbang.org/account/avatar/00/28/a1/7f/7303735d.jpg","nickname":"DS Hunter","note":"","ucode":"C7F2B79FC8A93A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":547400,"discussion_content":"太感动了，泣不成声。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1642657409,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":336073,"user_name":"圆桌π","can_delete":false,"product_type":"c1","uid":1901578,"ip_address":"","ucode":"4D3B954ACC9504","user_header":"https://static001.geekbang.org/account/avatar/00/1d/04/0a/07a48224.jpg","comment_is_top":false,"comment_ctime":1645882535,"is_pvip":false,"replies":[{"id":122883,"content":"感谢。爬虫的确有风险，没有法务帮忙的确很难玩下去。","user_name":"作者回复","user_name_real":"编辑","uid":2662783,"ctime":1646027193,"ip_address":"","comment_id":336073,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100104601,"comment_content":"没接触过爬虫，觉得新奇，买课来看看。\n第一次听说爬虫，是数据库老师说找数据，然后又半开玩笑的说最好不要。极客时间App的一门法律课里也有提及。\n\n期待课程老师，继续加油！💪","like_count":1,"discussions":[{"author":{"id":2662783,"avatar":"https://static001.geekbang.org/account/avatar/00/28/a1/7f/7303735d.jpg","nickname":"DS Hunter","note":"","ucode":"C7F2B79FC8A93A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":553682,"discussion_content":"感谢。爬虫的确有风险，没有法务帮忙的确很难玩下去。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1646027194,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":333035,"user_name":"ZeroIce","can_delete":false,"product_type":"c1","uid":1305369,"ip_address":"","ucode":"30133BA83CE349","user_header":"https://static001.geekbang.org/account/avatar/00/13/eb/19/0d990b03.jpg","comment_is_top":false,"comment_ctime":1643994754,"is_pvip":false,"replies":[{"id":121712,"content":"哈哈哈，我不是那个大佬，匿名是为了低调。不能光教别人低调自己却高调呀。","user_name":"作者回复","user_name_real":"编辑","uid":2662783,"ctime":1644039689,"ip_address":"","comment_id":333035,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100104601,"comment_content":"虽然说作者没有说出真实名字，但说话风格特别像一个大佬（上一篇文章有那个大佬评论：你是个有故事的人？）","like_count":1,"discussions":[{"author":{"id":2662783,"avatar":"https://static001.geekbang.org/account/avatar/00/28/a1/7f/7303735d.jpg","nickname":"DS Hunter","note":"","ucode":"C7F2B79FC8A93A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":553682,"discussion_content":"感谢。爬虫的确有风险，没有法务帮忙的确很难玩下去。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1646027194,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":332362,"user_name":"Blue","can_delete":false,"product_type":"c1","uid":1111640,"ip_address":"","ucode":"3ED45694A80952","user_header":"https://static001.geekbang.org/account/avatar/00/10/f6/58/7458ac2e.jpg","comment_is_top":false,"comment_ctime":1643186581,"is_pvip":false,"replies":[{"id":121421,"content":"赞","user_name":"作者回复","user_name_real":"编辑","uid":2662783,"ctime":1643204453,"ip_address":"","comment_id":332362,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100104601,"comment_content":"2. 爬虫从技术的角度上来讲，我觉得一方面提升了一些专业人员获取信息的效率，我们可以脱离浏览器，通过爬虫程序来获取我们期望得到的数据（不影响服务性能且不违规违法的前提下），这样就有更多的时间与精力去专注于解决更难更有意义的问题，这也是我当初做爬虫的一个初衷；另一方面我认为爬虫与反爬是存在良性竞争的，互相博弈可以提升各自的技术能力与认知边界，同时也让服务提供方有的放矢地设计出更具容错性，安全性的系统。","like_count":1,"discussions":[{"author":{"id":2662783,"avatar":"https://static001.geekbang.org/account/avatar/00/28/a1/7f/7303735d.jpg","nickname":"DS Hunter","note":"","ucode":"C7F2B79FC8A93A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":548465,"discussion_content":"赞","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1643204454,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":331535,"user_name":"程序员二师兄","can_delete":false,"product_type":"c1","uid":1205697,"ip_address":"","ucode":"C9E3B5B3358BDF","user_header":"https://static001.geekbang.org/account/avatar/00/12/65/c1/afcd981b.jpg","comment_is_top":false,"comment_ctime":1642644384,"is_pvip":false,"replies":[{"id":121139,"content":"哈哈哈，还抓过搜索引擎，可以。其实搜索引擎并不好抓，只是抓的少的时候不触发任务反爬处理，它们不当回事。","user_name":"作者回复","user_name_real":"编辑","uid":2662783,"ctime":1642657306,"ip_address":"","comment_id":331535,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100104601,"comment_content":"本人刚接触爬虫这一块不久，看到思考题留的作业，按照自己对爬虫浅薄的理解回答一下：\n\n1. 假如爬虫冒充搜索引擎，怎么办？\n\n以百度搜索引擎的爬虫为例、爬虫会带有标识，如 baiduspider，可以初步判断为搜索引擎。\n\n假如其他爬虫此时也加上了baiduspider的标识，那么可以根据robots.txt 协议来进行处理。\n\n爬虫所抓取的链接在robots.txt协议中，进一步可以认为搜索引擎。\n\n而往往其他爬虫不像搜索引擎，它是不遵守robots.txt协议的，它抓取的链接以及数据可能也不在约定的协议中，那么可以认为爬虫冒充了搜索引擎。\n\n此时对这类爬虫进行拦截，识别到这类爬虫后，接口可以返回非正常数据，还见过虚假数据，让竞争对手拿到的是虚假数据。\n\n2. 爬虫为这个世界做了什么贡献？\n\n个人认为，爬虫对这个世界最大的贡献是数据的聚合。\n\n没有爬虫之前，每个站点的数据都犹如一座孤岛，很难在众多孤岛找到所需要的数据，解决待满足的需求。\n\n搜索引擎的爬虫很好的解决这个问题，只需要一个输入框，输入想问的问题，搜索引擎将爬虫抓取到的数据进行优化，将更相关的资料优先展示在网页上。\n\n3. 你的爬虫或者反爬虫的经历是什么？有什么奇葩的经历吗？\n\n爬虫经历：\n一、\n为了找到某些关键词在搜索引擎的需求以及权重。\n将某一个关键词，通过爬虫的方式从各大搜索引擎获取前10条返回结果。\n搜索引擎能够返回的数据，说明需求量是比较大的。\n\n二、\n通过爬虫抓取第三方数据平台，获取文章以及短视频的各方面的数据。\n比如通过爬虫对短视频平台的视频去水印、视频文案提取。\n\n反爬虫经历：\n\n接口防刷。\n\n简单介绍一下背景，所在的公司有电商业务，当品牌做一些活动时，参与人数会比较多，而其中有小部分人会利用爬虫来刷接口。\n\n处理方法：\n针对用户的请求及频率，如果是爬虫，频率会比较高，增加图形验证码，通过图形验证码才能后续的操作。\n\n自己的奇葩经历：\n自从了解一些爬虫知识后，看到有意思的网站或者app，总是忍不住想抓包看一下它们的接口。\n\n经常魔怔，比如看到一些加密的请求，虽然不知道有什么意义，总是想研究一番，常常研究半天还是没能琢磨透。\n","like_count":8,"discussions":[{"author":{"id":2662783,"avatar":"https://static001.geekbang.org/account/avatar/00/28/a1/7f/7303735d.jpg","nickname":"DS Hunter","note":"","ucode":"C7F2B79FC8A93A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":547398,"discussion_content":"哈哈哈，还抓过搜索引擎，可以。其实搜索引擎并不好抓，只是抓的少的时候不触发任务反爬处理，它们不当回事。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1642657306,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":333930,"user_name":"ll","can_delete":false,"product_type":"c1","uid":2444836,"ip_address":"","ucode":"FC12C35B9205D7","user_header":"https://static001.geekbang.org/account/avatar/00/25/4e/24/c491ac2b.jpg","comment_is_top":false,"comment_ctime":1644592772,"is_pvip":false,"replies":[{"id":121987,"content":"免费的就是最贵的，这里完美体现了这一点。","user_name":"作者回复","user_name_real":"编辑","uid":2662783,"ctime":1644649372,"ip_address":"","comment_id":333930,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100104601,"comment_content":"我的经历：\n1、 16年开始做爬虫，那个时候什么58、美团、淘宝什么的，数据都是免费爬，当时我们的一个目标就是怎么重复利用cpu，带宽，让我们的爬虫采集效率最快。那个时候淘宝的数据都是没有反爬的，我们的工作就是疯狂写爬虫，很少有反爬的，那个时候我记得我3个月写了快100跟网站的爬虫，所有爬虫一键爬起来的时候，那个壮观，现在想想都觉得我疯了；\n2、后来发现有些小的障碍了，比如下一页的连接是js生成的，网站要开始限制cookie了，某些登录验证需要梳理他的js逻辑了，比如微博和百度贴吧，不过那个时候捋下逻辑，还是可以搞定的，从那个时候开始，爬虫的速度，就再也不是面试的考点了，都是问怎么安全、稳定；\n3、 后来就发现了一些特别恶心的，比如请求的参数就一个很大的字符串，所有请求体的都是加密成一个字符串，验证header里也是加密的，每此请求header里的auth都是一次性的；完了js还没法逆向回去，或者说我没法逆向回去，你调试的时候还会定位到你，把你封ip，之前就被这么搞过，不过后来还是搞定了，我记得是瑞数科技的专门做的，都过去好多些年了，希望不要针对我；\n4、再后来就越来越觉得，几乎每个网站都有反爬虫，但是也不是突破不了，然而突破了好像对我们来说也意义不大，因为有些硬性的指标，比如你的账户、跟ip绑定后，限制了你的行为，只能有那么多次的访问上限，基本上限制死了单个账号的数据访问量，爬虫已经不是一个人可以做的事情了，背后需要很多账号、ip这样的资源，有时候感觉就是财力的比拼；甚至后来发现天眼查充了会员后，同样的接口，没充钱的数据你拿到是假数据，还需要研究他的js再处理一下，而会员就可以爬到真数据，我发现后震惊了，立马冲了个会员，工作量一下就降低了不少，才感觉到别人产品经理已经把挣钱放到我们爬虫开发人员身上了，再后来越来越发现，爬虫已经告别了西部牛仔--一个人闯荡的、单靠技术就能过得不错的时代了，以后的数据也会越来越难获取，爬虫也不再是一个人的武林了；\n5、 逐渐疏远爬虫，一想到破解后维护也是个大问题，就没有动力；\n\n现在想想，奇葩的经历，肯定要算天眼查要挣我们爬虫开发人员的钱，我是被震惊了","like_count":5,"discussions":[{"author":{"id":2662783,"avatar":"https://static001.geekbang.org/account/avatar/00/28/a1/7f/7303735d.jpg","nickname":"DS Hunter","note":"","ucode":"C7F2B79FC8A93A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":550636,"discussion_content":"免费的就是最贵的，这里完美体现了这一点。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1644649373,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":332365,"user_name":"lidashuang","can_delete":false,"product_type":"c1","uid":1104850,"ip_address":"","ucode":"560ABE8032760E","user_header":"https://static001.geekbang.org/account/avatar/00/10/db/d2/e29f8834.jpg","comment_is_top":false,"comment_ctime":1643187427,"is_pvip":false,"replies":[{"id":121423,"content":"哈哈哈，美团反爬是很强，他们老板人也不错。主要你得看他是在什么样的对手下成长起来的。强大的对手能让你更强。呃这算招人广告不，无利益相关，理性分析而已😂😂😂","user_name":"作者回复","user_name_real":"编辑","uid":2662783,"ctime":1643204595,"ip_address":"","comment_id":332365,"utype":1}],"discussion_count":2,"race_medal":2,"score":2,"product_id":100104601,"comment_content":"爬过最难爬的是美团，各种给你下毒","like_count":3,"discussions":[{"author":{"id":2662783,"avatar":"https://static001.geekbang.org/account/avatar/00/28/a1/7f/7303735d.jpg","nickname":"DS Hunter","note":"","ucode":"C7F2B79FC8A93A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":548467,"discussion_content":"哈哈哈，美团反爬是很强，他们老板人也不错。主要你得看他是在什么样的对手下成长起来的。强大的对手能让你更强。呃这算招人广告不，无利益相关，理性分析而已😂😂😂","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1643204595,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":1104850,"avatar":"https://static001.geekbang.org/account/avatar/00/10/db/d2/e29f8834.jpg","nickname":"lidashuang","note":"","ucode":"560ABE8032760E","race_medal":2,"user_type":1,"is_pvip":false},"reply_author":{"id":2662783,"avatar":"https://static001.geekbang.org/account/avatar/00/28/a1/7f/7303735d.jpg","nickname":"DS Hunter","note":"","ucode":"C7F2B79FC8A93A","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":550871,"discussion_content":"强大的对手让我放弃😇","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1644763328,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":548467,"ip_address":"","group_id":0},"score":550871,"extra":""}]}]},{"had_liked":false,"id":332277,"user_name":"demo123567","can_delete":false,"product_type":"c1","uid":1116610,"ip_address":"","ucode":"4FE8E6AA361673","user_header":"https://static001.geekbang.org/account/avatar/00/11/09/c2/4e086a4b.jpg","comment_is_top":false,"comment_ctime":1643153985,"is_pvip":false,"replies":[{"id":121391,"content":"没错，两者可以结合用，ua做粗筛，然后ip细筛。","user_name":"作者回复","user_name_real":"编辑","uid":2662783,"ctime":1643159376,"ip_address":"","comment_id":332277,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100104601,"comment_content":"第一个问题应该是user-agent，虽然可以模拟；然后大型搜索引擎爬虫一般都是有固定的IP段，所以应该也可以识别","like_count":2,"discussions":[{"author":{"id":2662783,"avatar":"https://static001.geekbang.org/account/avatar/00/28/a1/7f/7303735d.jpg","nickname":"DS Hunter","note":"","ucode":"C7F2B79FC8A93A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":548467,"discussion_content":"哈哈哈，美团反爬是很强，他们老板人也不错。主要你得看他是在什么样的对手下成长起来的。强大的对手能让你更强。呃这算招人广告不，无利益相关，理性分析而已😂😂😂","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1643204595,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":1104850,"avatar":"https://static001.geekbang.org/account/avatar/00/10/db/d2/e29f8834.jpg","nickname":"lidashuang","note":"","ucode":"560ABE8032760E","race_medal":2,"user_type":1,"is_pvip":false},"reply_author":{"id":2662783,"avatar":"https://static001.geekbang.org/account/avatar/00/28/a1/7f/7303735d.jpg","nickname":"DS Hunter","note":"","ucode":"C7F2B79FC8A93A","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":550871,"discussion_content":"强大的对手让我放弃😇","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1644763328,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":548467,"ip_address":"","group_id":0},"score":550871,"extra":""}]}]},{"had_liked":false,"id":331561,"user_name":"fsc2016","can_delete":false,"product_type":"c1","uid":1255585,"ip_address":"","ucode":"5480F05703A974","user_header":"https://static001.geekbang.org/account/avatar/00/13/28/a1/fd2bfc25.jpg","comment_is_top":false,"comment_ctime":1642654225,"is_pvip":false,"replies":[{"id":121138,"content":"是的，移动端如果感兴趣，后续可以再出课程","user_name":"作者回复","user_name_real":"编辑","uid":2662783,"ctime":1642657113,"ip_address":"","comment_id":331561,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100104601,"comment_content":"感觉现在爬虫对抗，慢慢从web转战到移动端了","like_count":2,"discussions":[{"author":{"id":2662783,"avatar":"https://static001.geekbang.org/account/avatar/00/28/a1/7f/7303735d.jpg","nickname":"DS Hunter","note":"","ucode":"C7F2B79FC8A93A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":547396,"discussion_content":"是的，移动端如果感兴趣，后续可以再出课程","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1642657114,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":331514,"user_name":"peter","can_delete":false,"product_type":"c1","uid":1058183,"ip_address":"","ucode":"261C3FC001DE2D","user_header":"https://static001.geekbang.org/account/avatar/00/10/25/87/f3a69d1b.jpg","comment_is_top":false,"comment_ctime":1642638201,"is_pvip":false,"replies":[{"id":121141,"content":"太感动了，泣不成声。","user_name":"作者回复","user_name_real":"编辑","uid":2662783,"ctime":1642657408,"ip_address":"","comment_id":331514,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100104601,"comment_content":"写得太好啦，牛啊，文采真好，通顺，有趣，也没有错别字！！！！  我还有很多课程没有看，这个课程和自己目前的关系并不是很大，犹豫再三才买的。真庆幸自己没有错过这么好的文章。理工男能写这么好，不容易，不多见啊。","like_count":2,"discussions":[{"author":{"id":2662783,"avatar":"https://static001.geekbang.org/account/avatar/00/28/a1/7f/7303735d.jpg","nickname":"DS Hunter","note":"","ucode":"C7F2B79FC8A93A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":547400,"discussion_content":"太感动了，泣不成声。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1642657409,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":331451,"user_name":"GAC·DU","can_delete":false,"product_type":"c1","uid":1385403,"ip_address":"","ucode":"7847FBE1C13740","user_header":"https://static001.geekbang.org/account/avatar/00/15/23/bb/a1a61f7c.jpg","comment_is_top":false,"comment_ctime":1642589462,"is_pvip":false,"replies":[{"id":121110,"content":"然而还是有可能无效对吧，最关键，有效无效还很难验证。。。除非把对方收购了直接问他😂😂😂","user_name":"作者回复","user_name_real":"编辑","uid":2662783,"ctime":1642607517,"ip_address":"","comment_id":331451,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100104601,"comment_content":"一次经历见证了一家公司技术的成长，甚至把后端由15人加到了30。从携cookie能登录到手机验证码再到扫脸登录，api加了token，后来把限流和熔断也加上了。","like_count":2,"discussions":[{"author":{"id":2662783,"avatar":"https://static001.geekbang.org/account/avatar/00/28/a1/7f/7303735d.jpg","nickname":"DS Hunter","note":"","ucode":"C7F2B79FC8A93A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":547310,"discussion_content":"然而还是有可能无效对吧，最关键，有效无效还很难验证。。。除非把对方收购了直接问他😂😂😂","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1642607517,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":336073,"user_name":"圆桌π","can_delete":false,"product_type":"c1","uid":1901578,"ip_address":"","ucode":"4D3B954ACC9504","user_header":"https://static001.geekbang.org/account/avatar/00/1d/04/0a/07a48224.jpg","comment_is_top":false,"comment_ctime":1645882535,"is_pvip":false,"replies":[{"id":122883,"content":"感谢。爬虫的确有风险，没有法务帮忙的确很难玩下去。","user_name":"作者回复","user_name_real":"编辑","uid":2662783,"ctime":1646027193,"ip_address":"","comment_id":336073,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100104601,"comment_content":"没接触过爬虫，觉得新奇，买课来看看。\n第一次听说爬虫，是数据库老师说找数据，然后又半开玩笑的说最好不要。极客时间App的一门法律课里也有提及。\n\n期待课程老师，继续加油！💪","like_count":1,"discussions":[{"author":{"id":2662783,"avatar":"https://static001.geekbang.org/account/avatar/00/28/a1/7f/7303735d.jpg","nickname":"DS Hunter","note":"","ucode":"C7F2B79FC8A93A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":547310,"discussion_content":"然而还是有可能无效对吧，最关键，有效无效还很难验证。。。除非把对方收购了直接问他😂😂😂","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1642607517,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":333035,"user_name":"ZeroIce","can_delete":false,"product_type":"c1","uid":1305369,"ip_address":"","ucode":"30133BA83CE349","user_header":"https://static001.geekbang.org/account/avatar/00/13/eb/19/0d990b03.jpg","comment_is_top":false,"comment_ctime":1643994754,"is_pvip":false,"replies":[{"id":121712,"content":"哈哈哈，我不是那个大佬，匿名是为了低调。不能光教别人低调自己却高调呀。","user_name":"作者回复","user_name_real":"编辑","uid":2662783,"ctime":1644039689,"ip_address":"","comment_id":333035,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100104601,"comment_content":"虽然说作者没有说出真实名字，但说话风格特别像一个大佬（上一篇文章有那个大佬评论：你是个有故事的人？）","like_count":1,"discussions":[{"author":{"id":2662783,"avatar":"https://static001.geekbang.org/account/avatar/00/28/a1/7f/7303735d.jpg","nickname":"DS Hunter","note":"","ucode":"C7F2B79FC8A93A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":549508,"discussion_content":"哈哈哈，我不是那个大佬，匿名是为了低调。不能光教别人低调自己却高调呀。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1644039689,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":332362,"user_name":"Blue","can_delete":false,"product_type":"c1","uid":1111640,"ip_address":"","ucode":"3ED45694A80952","user_header":"https://static001.geekbang.org/account/avatar/00/10/f6/58/7458ac2e.jpg","comment_is_top":false,"comment_ctime":1643186581,"is_pvip":false,"replies":[{"id":121421,"content":"赞","user_name":"作者回复","user_name_real":"编辑","uid":2662783,"ctime":1643204453,"ip_address":"","comment_id":332362,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100104601,"comment_content":"2. 爬虫从技术的角度上来讲，我觉得一方面提升了一些专业人员获取信息的效率，我们可以脱离浏览器，通过爬虫程序来获取我们期望得到的数据（不影响服务性能且不违规违法的前提下），这样就有更多的时间与精力去专注于解决更难更有意义的问题，这也是我当初做爬虫的一个初衷；另一方面我认为爬虫与反爬是存在良性竞争的，互相博弈可以提升各自的技术能力与认知边界，同时也让服务提供方有的放矢地设计出更具容错性，安全性的系统。","like_count":1,"discussions":[{"author":{"id":2662783,"avatar":"https://static001.geekbang.org/account/avatar/00/28/a1/7f/7303735d.jpg","nickname":"DS Hunter","note":"","ucode":"C7F2B79FC8A93A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":549508,"discussion_content":"哈哈哈，我不是那个大佬，匿名是为了低调。不能光教别人低调自己却高调呀。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1644039689,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":331797,"user_name":"leslie","can_delete":false,"product_type":"c1","uid":1324255,"ip_address":"","ucode":"798E7C1CC98CC2","user_header":"https://static001.geekbang.org/account/avatar/00/14/34/df/64e3d533.jpg","comment_is_top":false,"comment_ctime":1642763120,"is_pvip":false,"replies":[{"id":121224,"content":"是的，但是我们改变不了世界，只能改变自己，去勇敢面对这些挑战。","user_name":"作者回复","user_name_real":"编辑","uid":2662783,"ctime":1642837668,"ip_address":"","comment_id":331797,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100104601,"comment_content":"爬虫其实是变形为其中的内容再推广，这就像搜索引擎；同样像作者所说；爬取对被爬者的服务器带宽造成了很大压力，持续消耗对方资源这个就有点恶意攻击了。","like_count":1},{"had_liked":false,"id":331950,"user_name":"默默","can_delete":false,"product_type":"c1","uid":2646999,"ip_address":"","ucode":"E5554B0D286C74","user_header":"https://static001.geekbang.org/account/avatar/00/28/63/d7/efa4bfd1.jpg","comment_is_top":false,"comment_ctime":1642918771,"is_pvip":false,"replies":[{"id":121320,"content":"后面会有专门介绍","user_name":"作者回复","user_name_real":"编辑","uid":2662783,"ctime":1643018812,"ip_address":"","comment_id":331950,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100104601,"comment_content":"加密的爬虫改怎么破解？该怎么分析js代码等？","like_count":0,"discussions":[{"author":{"id":2662783,"avatar":"https://static001.geekbang.org/account/avatar/00/28/a1/7f/7303735d.jpg","nickname":"DS Hunter","note":"","ucode":"C7F2B79FC8A93A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":547720,"discussion_content":"是的，但是我们改变不了世界，只能改变自己，去勇敢面对这些挑战。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1642837668,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":333931,"user_name":"ll","can_delete":false,"product_type":"c1","uid":2444836,"ip_address":"","ucode":"FC12C35B9205D7","user_header":"https://static001.geekbang.org/account/avatar/00/25/4e/24/c491ac2b.jpg","comment_is_top":false,"comment_ctime":1644592804,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100104601,"comment_content":"我的经历：\n1、 16年开始做爬虫，那个时候什么58、美团、淘宝什么的，数据都是免费爬，当时我们的一个目标就是怎么重复利用cpu，带宽，让我们的爬虫采集效率最快。那个时候淘宝的数据都是没有反爬的，我们的工作就是疯狂写爬虫，很少有反爬的，那个时候我记得我3个月写了快100跟网站的爬虫，所有爬虫一键爬起来的时候，那个壮观，现在想想都觉得我疯了；\n2、后来发现有些小的障碍了，比如下一页的连接是js生成的，网站要开始限制cookie了，某些登录验证需要梳理他的js逻辑了，比如微博和百度贴吧，不过那个时候捋下逻辑，还是可以搞定的，从那个时候开始，爬虫的速度，就再也不是面试的考点了，都是问怎么安全、稳定；\n3、 后来就发现了一些特别恶心的，比如请求的参数就一个很大的字符串，所有请求体的都是加密成一个字符串，验证header里也是加密的，每此请求header里的auth都是一次性的；完了js还没法逆向回去，或者说我没法逆向回去，你调试的时候还会定位到你，把你封ip，之前就被这么搞过，不过后来还是搞定了，我记得是瑞数科技的专门做的，都过去好多些年了，希望不要针对我；\n4、再后来就越来越觉得，几乎每个网站都有反爬虫，但是也不是突破不了，然而突破了好像对我们来说也意义不大，因为有些硬性的指标，比如你的账户、跟ip绑定后，限制了你的行为，只能有那么多次的访问上限，基本上限制死了单个账号的数据访问量，爬虫已经不是一个人可以做的事情了，背后需要很多账号、ip这样的资源，有时候感觉就是财力的比拼；甚至后来发现天眼查充了会员后，同样的接口，没充钱的数据你拿到是假数据，还需要研究他的js再处理一下，而会员就可以爬到真数据，我发现后震惊了，立马冲了个会员，工作量一下就降低了不少，才感觉到别人产品经理已经把挣钱放到我们爬虫开发人员身上了，再后来越来越发现，爬虫已经告别了西部牛仔--一个人闯荡的、单靠技术就能过得不错的时代了，以后的数据也会越来越难获取，爬虫也不再是一个人的武林了；\n5、 逐渐疏远爬虫，一想到破解后维护也是个大问题，就没有动力；\n\n现在想想，奇葩的经历，肯定要算天眼查要挣我们爬虫开发人员的钱，我是被震惊了","like_count":11},{"had_liked":false,"id":331953,"user_name":"默默","can_delete":false,"product_type":"c1","uid":2646999,"ip_address":"","ucode":"E5554B0D286C74","user_header":"https://static001.geekbang.org/account/avatar/00/28/63/d7/efa4bfd1.jpg","comment_is_top":false,"comment_ctime":1642919608,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100104601,"comment_content":"加密的爬虫随机header相关的，该怎么去破解爬虫呢？","like_count":0,"discussions":[{"author":{"id":2662783,"avatar":"https://static001.geekbang.org/account/avatar/00/28/a1/7f/7303735d.jpg","nickname":"DS Hunter","note":"","ucode":"C7F2B79FC8A93A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":548065,"discussion_content":"后面会有专门介绍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1643018812,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":331797,"user_name":"leslie","can_delete":false,"product_type":"c1","uid":1324255,"ip_address":"","ucode":"798E7C1CC98CC2","user_header":"https://static001.geekbang.org/account/avatar/00/14/34/df/64e3d533.jpg","comment_is_top":false,"comment_ctime":1642763120,"is_pvip":false,"replies":[{"id":121224,"content":"是的，但是我们改变不了世界，只能改变自己，去勇敢面对这些挑战。","user_name":"作者回复","user_name_real":"编辑","uid":2662783,"ctime":1642837668,"ip_address":"","comment_id":331797,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100104601,"comment_content":"爬虫其实是变形为其中的内容再推广，这就像搜索引擎；同样像作者所说；爬取对被爬者的服务器带宽造成了很大压力，持续消耗对方资源这个就有点恶意攻击了。","like_count":1,"discussions":[{"author":{"id":2662783,"avatar":"https://static001.geekbang.org/account/avatar/00/28/a1/7f/7303735d.jpg","nickname":"DS Hunter","note":"","ucode":"C7F2B79FC8A93A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":547720,"discussion_content":"是的，但是我们改变不了世界，只能改变自己，去勇敢面对这些挑战。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1642837668,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":331950,"user_name":"默默","can_delete":false,"product_type":"c1","uid":2646999,"ip_address":"","ucode":"E5554B0D286C74","user_header":"https://static001.geekbang.org/account/avatar/00/28/63/d7/efa4bfd1.jpg","comment_is_top":false,"comment_ctime":1642918771,"is_pvip":false,"replies":[{"id":121320,"content":"后面会有专门介绍","user_name":"作者回复","user_name_real":"编辑","uid":2662783,"ctime":1643018812,"ip_address":"","comment_id":331950,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100104601,"comment_content":"加密的爬虫改怎么破解？该怎么分析js代码等？","like_count":0,"discussions":[{"author":{"id":2662783,"avatar":"https://static001.geekbang.org/account/avatar/00/28/a1/7f/7303735d.jpg","nickname":"DS Hunter","note":"","ucode":"C7F2B79FC8A93A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":548065,"discussion_content":"后面会有专门介绍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1643018812,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":333931,"user_name":"ll","can_delete":false,"product_type":"c1","uid":2444836,"ip_address":"","ucode":"FC12C35B9205D7","user_header":"https://static001.geekbang.org/account/avatar/00/25/4e/24/c491ac2b.jpg","comment_is_top":false,"comment_ctime":1644592804,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100104601,"comment_content":"我的经历：\n1、 16年开始做爬虫，那个时候什么58、美团、淘宝什么的，数据都是免费爬，当时我们的一个目标就是怎么重复利用cpu，带宽，让我们的爬虫采集效率最快。那个时候淘宝的数据都是没有反爬的，我们的工作就是疯狂写爬虫，很少有反爬的，那个时候我记得我3个月写了快100跟网站的爬虫，所有爬虫一键爬起来的时候，那个壮观，现在想想都觉得我疯了；\n2、后来发现有些小的障碍了，比如下一页的连接是js生成的，网站要开始限制cookie了，某些登录验证需要梳理他的js逻辑了，比如微博和百度贴吧，不过那个时候捋下逻辑，还是可以搞定的，从那个时候开始，爬虫的速度，就再也不是面试的考点了，都是问怎么安全、稳定；\n3、 后来就发现了一些特别恶心的，比如请求的参数就一个很大的字符串，所有请求体的都是加密成一个字符串，验证header里也是加密的，每此请求header里的auth都是一次性的；完了js还没法逆向回去，或者说我没法逆向回去，你调试的时候还会定位到你，把你封ip，之前就被这么搞过，不过后来还是搞定了，我记得是瑞数科技的专门做的，都过去好多些年了，希望不要针对我；\n4、再后来就越来越觉得，几乎每个网站都有反爬虫，但是也不是突破不了，然而突破了好像对我们来说也意义不大，因为有些硬性的指标，比如你的账户、跟ip绑定后，限制了你的行为，只能有那么多次的访问上限，基本上限制死了单个账号的数据访问量，爬虫已经不是一个人可以做的事情了，背后需要很多账号、ip这样的资源，有时候感觉就是财力的比拼；甚至后来发现天眼查充了会员后，同样的接口，没充钱的数据你拿到是假数据，还需要研究他的js再处理一下，而会员就可以爬到真数据，我发现后震惊了，立马冲了个会员，工作量一下就降低了不少，才感觉到别人产品经理已经把挣钱放到我们爬虫开发人员身上了，再后来越来越发现，爬虫已经告别了西部牛仔--一个人闯荡的、单靠技术就能过得不错的时代了，以后的数据也会越来越难获取，爬虫也不再是一个人的武林了；\n5、 逐渐疏远爬虫，一想到破解后维护也是个大问题，就没有动力；\n\n现在想想，奇葩的经历，肯定要算天眼查要挣我们爬虫开发人员的钱，我是被震惊了","like_count":11},{"had_liked":false,"id":331953,"user_name":"默默","can_delete":false,"product_type":"c1","uid":2646999,"ip_address":"","ucode":"E5554B0D286C74","user_header":"https://static001.geekbang.org/account/avatar/00/28/63/d7/efa4bfd1.jpg","comment_is_top":false,"comment_ctime":1642919608,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100104601,"comment_content":"加密的爬虫随机header相关的，该怎么去破解爬虫呢？","like_count":0}]}