{"id":309846,"title":"17 | Embedding+MLP：如何用TensorFlow实现经典的深度学习模型？","content":"<p>你好，我是王喆。</p><p>今天我们正式进入深度学习模型的实践环节，来一起学习并实现一种最经典的模型结构，Embedding+MLP。它不仅经典，还是我们后续实现其他深度学习模型的基础，所以你一定要掌握好。</p><p>这里面的Embedding我们已经很熟悉了，那什么叫做MLP呢？它其实是Multilayer perceptron，多层感知机的缩写。感知机是神经元的另外一种叫法，所以多层感知机就是多层神经网络。</p><p>讲到这里啊，我想你脑海中已经有这个模型结构的大致图像了。今天，我就以微软著名的深度学习模型Deep Crossing为例，来给你详细讲一讲Embedding+MLP模型的结构和实现方法。</p><h2>Embedding+MLP模型的结构</h2><p>图1 展示的就是微软在2016年提出的深度学习模型Deep Crossing，微软把它用于广告推荐这个业务场景上。它是一个经典的Embedding+MLP模型结构，我们可以看到，Deep Crossing从下到上可以分为5层，分别是Feature层、Embedding层、Stacking层、MLP层和Scoring层。</p><p>接下来，我就从下到上来给你讲讲每一层的功能是什么，以及它们的技术细节分别是什么样的。</p><!-- [[[read_end]]] --><p><img src=\"https://static001.geekbang.org/resource/image/50/71/5076071d3c69d3a9fff848a9e631f371.jpeg?wh=1920*1080\" alt=\"\" title=\"图1 经典的Embedding+MLP模型结构（图片来自 Deep Crossing - Web-Scale Modeling without Manually Crafted Combinatorial Features）\"></p><p>我们先来看Feature层。Feature层也叫做输入特征层，它处于Deep Crossing的最底部，作为整个模型的输入。仔细看图1的话，你一定会发现不同特征在细节上的一些区别。比如Feature#1向上连接到了Embedding层，而Feature#2就直接连接到了更上方的Stacking层。这是怎么回事呢？</p><p>原因就在于Feature#1代表的是类别型特征经过One-hot编码后生成的特征向量，而Feature#2代表的是数值型特征。我们知道，One-hot特征太稀疏了，不适合直接输入到后续的神经网络中进行训练，所以我们需要通过连接到Embedding层的方式，把这个稀疏的One-hot向量转换成比较稠密的Embedding向量。</p><p>接着，我们来看Embedding层。Embedding层就是为了把稀疏的One-hot向量转换成稠密的Embedding向量而设置的，我们需要注意的是，Embedding层并不是全部连接起来的，而是每一个特征对应一个Embedding层，不同Embedding层之间互不干涉。</p><p>那Embedding层的内部结构到底是什么样子的呢？我想先问问你，你还记得Word2vec的原理吗？Embeding层的结构就是Word2vec模型中从输入神经元到隐层神经元的部分（如图2红框内的部分）。参照下面的示意图，我们可以看到，这部分就是一个从输入层到隐层之间的全连接网络。</p><p><img src=\"https://static001.geekbang.org/resource/image/8a/29/8a26d9a531ae8bef89f3730388f59a29.jpeg?wh=1920*1080\" alt=\"\" title=\"图2 Word2vec模型中Embedding层的部分\"></p><p>一般来说，Embedding向量的维度应远小于原始的稀疏特征向量，按照经验，几十到上百维就能够满足需求，这样它才能够实现从稀疏特征向量到稠密特征向量的转换。</p><p>接着我们来看Stacking层。Stacking层中文名是堆叠层，我们也经常叫它连接（Concatenate）层。它的作用比较简单，就是把不同的Embedding特征和数值型特征拼接在一起，形成新的包含全部特征的特征向量。</p><p>再往上看，MLP层就是我们开头提到的多层神经网络层，在图1中指的是Multiple Residual Units层，中文叫多层残差网络。微软在实现Deep Crossing时针对特定的问题选择了残差神经元，但事实上，神经元的选择有非常多种，比如我们之前在深度学习基础知识中介绍的，以Sigmoid函数为激活函数的神经元，以及使用tanh、ReLU等其他激活函数的神经元。我们具体选择哪种是一个调参的问题，一般来说，ReLU最经常使用在隐层神经元上，Sigmoid则多使用在输出神经元，实践中也可以选择性地尝试其他神经元，根据效果作出最后的决定。</p><p>不过，不管选择哪种神经元，MLP层的特点是全连接，就是不同层的神经元两两之间都有连接。就像图3中的两层神经网络一样，它们两两连接，只是连接的权重会在梯度反向传播的学习过程中发生改变。</p><p><img src=\"https://static001.geekbang.org/resource/image/7a/99/7a2b22c106c454af3db2edaed555e299.jpeg?wh=1920*1080\" alt=\"\" title=\"图3 全连接神经网络\"></p><p>MLP层的作用是让特征向量不同维度之间做充分的交叉，让模型能够抓取到更多的非线性特征和组合特征的信息，这就使深度学习模型在表达能力上较传统机器学习模型大为增强。</p><p>最后是Scoring层，它也被称为输出层。虽然深度学习模型的结构可以非常复杂，但最终我们要预测的目标就是一个分类的概率。如果是点击率预估，就是一个二分类问题，那我们就可以采用逻辑回归作为输出层神经元，而如果是类似图像分类这样的多分类问题，我们往往在输出层采用softmax这样的多分类模型。</p><p>到这里，我们就讲完了Embedding+MLP的五层结构。它的结构重点用一句话总结就是，<strong>对于类别特征，先利用Embedding层进行特征稠密化，再利用Stacking层连接其他特征，输入MLP的多层结构，最后用Scoring层预估结果。</strong></p><h2>Embedding+MLP模型的实战</h2><p>现在，我们从整体上了解了Embedding+MLP模型的结构，也许你对其中的细节实现还有些疑问。别着急，下面我就带你用SparrowRecsys来实现一个Embedding+MLP的推荐模型，帮你扫清这些疑问。</p><p>实战中，我们按照构建推荐模型经典的步骤，特征选择、模型设计、模型实现、模型训练和模型评估这5步来进行实现。</p><p>首先，我们来看看特征选择和模型设计。</p><h3>特征选择和模型设计</h3><p>在上一节的实践准备课程中，我们已经为模型训练准备好了可用的训练样本和特征。秉着“类别型特征Embedding化，数值型特征直接输入MLP”的原则，我们选择movieId、userId、movieGenre、userGenre作为Embedding化的特征，选择物品和用户的统计型特征作为直接输入MLP的数值型特征，具体的特征选择你可以看看下面的表格：</p><p><img src=\"https://static001.geekbang.org/resource/image/af/94/af3fabdcb119c9e06ddc0f7225bbc094.jpg?wh=1809*1156\" alt=\"\"></p><p>选择好特征后，就是MLP部分的模型设计了。我们选择了一个三层的MLP结构，其中前两层是128维的全连接层。我们这里采用好评/差评标签作为样本标签，因此要解决的是一个类CTR预估的二分类问题，对于二分类问题，我们最后一层采用单个sigmoid神经元作为输出层就可以了。</p><p>当然了，我知道你肯定对这一步的细节实现有很多问题，比如为什么要选三层的MLP结构，为什么要选sigmoid作为激活函数等等。其实，我们对模型层数和每个层内维度的选择是一个超参数调优的问题，这里的选择不能保证最优，我们需要在实战中根据模型的效果进行超参数的搜索，找到最适合的模型参数。</p><h3>Embedding+MLP模型的TensorFlow实现</h3><p>确定好了特征和模型结构，就万事俱备，只欠实现了。下面，我们就看一看利用TensorFlow的Keras接口如何实现Embedding+MLP的结构。总的来说，TensorFlow的实现有七个步骤。因为这是我们课程中第一个TensorFlow的实现，所以我会讲得详细一些。而且，我也把全部的参考代码放在了Sparrow Recsys项目TFRecModel模块的EmbeddingMLP.py，你可以结合它来听我下面的讲解。</p><p><strong>我们先来看第一步，导入TensorFlow包。</strong> 如果你按照实战准备一的步骤配置好了TensorFlow Python环境，就可以成功地导入TensorFlow包。接下来，你要做的就是定义好训练数据的路径TRAIN_DATA_URL了，然后根据你自己训练数据的本地路径，替换参考代码中的路径就可以了。</p><pre><code>import tensorflow as tf\n\n\nTRAIN_DATA_URL = &quot;file:///Users/zhewang/Workspace/SparrowRecSys/src/main/resources/webroot/sampledata/modelSamples.csv&quot;\nsamples_file_path = tf.keras.utils.get_file(&quot;modelSamples.csv&quot;, TRAIN_DATA_URL)\n</code></pre><p><strong>第二步是载入训练数据</strong>，我们利用TensorFlow自带的CSV数据集的接口载入训练数据。注意这里有两个比较重要的参数，一个是label_name，它指定了CSV数据集中的标签列。另一个是batch_size，它指定了训练过程中，一次输入几条训练数据进行梯度下降训练。载入训练数据之后，我们把它们分割成了测试集和训练集。</p><pre><code>def get_dataset(file_path):\n    dataset = tf.data.experimental.make_csv_dataset(\n        file_path,\n        batch_size=12,\n        label_name='label',\n        na_value=&quot;?&quot;,\n        num_epochs=1,\n        ignore_errors=True)\n    return dataset\n\n\n\n# sample dataset size 110830/12(batch_size) = 9235\nraw_samples_data = get_dataset(samples_file_path)\n\n\ntest_dataset = raw_samples_data.take(1000)\ntrain_dataset = raw_samples_data.skip(1000)\n\n</code></pre><p><strong>第三步是载入类别型特征。</strong> 我们用到的类别型特征主要有这三类，分别是genre、userId和movieId。在载入genre类特征时，我们采用了 <code>tf.feature_column.categorical_column_with_vocabulary_list</code> 方法把字符串型的特征转换成了One-hot特征。在这个转换过程中我们需要用到一个词表，你可以看到我在开头就定义好了包含所有genre类别的词表genre_vocab。</p><p>在转换userId和movieId特征时，我们又使用了 <code>tf.feature_column.categorical_column_with_identity</code> 方法把ID转换成One-hot特征，这个方法不用词表，它会直接把ID值对应的那个维度置为1。比如，我们输入这个方法的movieId是340，总的movie数量是1001，使用这个方法，就会把这个1001维的One-hot movieId向量的第340维置为1，剩余的维度都为0。</p><p>为了把稀疏的One-hot特征转换成稠密的Embedding向量，我们还需要在One-hot特征外包裹一层Embedding层，你可以看到 <code>tf.feature_column.embedding_column(movie_col, 10)</code> 方法完成了这样的操作，它在把movie one-hot向量映射到了一个10维的Embedding层上。</p><pre><code>genre_vocab = ['Film-Noir', 'Action', 'Adventure', 'Horror', 'Romance', 'War', 'Comedy', 'Western', 'Documentary',\n               'Sci-Fi', 'Drama', 'Thriller',\n               'Crime', 'Fantasy', 'Animation', 'IMAX', 'Mystery', 'Children', 'Musical']\n\n\nGENRE_FEATURES = {\n    'userGenre1': genre_vocab,\n    'userGenre2': genre_vocab,\n    'userGenre3': genre_vocab,\n    'userGenre4': genre_vocab,\n    'userGenre5': genre_vocab,\n    'movieGenre1': genre_vocab,\n    'movieGenre2': genre_vocab,\n    'movieGenre3': genre_vocab\n}\n\n\ncategorical_columns = []\nfor feature, vocab in GENRE_FEATURES.items():\n    cat_col = tf.feature_column.categorical_column_with_vocabulary_list(\n        key=feature, vocabulary_list=vocab)\n    emb_col = tf.feature_column.embedding_column(cat_col, 10)\n    categorical_columns.append(emb_col)\n\n\nmovie_col = tf.feature_column.categorical_column_with_identity(key='movieId', num_buckets=1001)\nmovie_emb_col = tf.feature_column.embedding_column(movie_col, 10)\ncategorical_columns.append(movie_emb_col)\n\n\nuser_col = tf.feature_column.categorical_column_with_identity(key='userId', num_buckets=30001)\nuser_emb_col = tf.feature_column.embedding_column(user_col, 10)\ncategorical_columns.append(user_emb_c\n</code></pre><p><strong>第四步是数值型特征的处理。</strong> 这一步非常简单，我们直接把特征值输入到MLP内，然后把特征逐个声明为 <code>tf.feature_column.numeric_column</code> 就可以了，不需要经过其他的特殊处理。</p><pre><code>numerical_columns = [tf.feature_column.numeric_column('releaseYear'),\n                   tf.feature_column.numeric_column('movieRatingCount'),\n                     tf.feature_column.numeric_column('movieAvgRating'),\n                     tf.feature_column.numeric_column('movieRatingStddev'),\n                     tf.feature_column.numeric_column('userRatingCount'),\n                     tf.feature_column.numeric_column('userAvgRating'),\n                     tf.feature_column.numeric_column('userRatingStddev')]\n\n</code></pre><p><strong>第五步是定义模型结构。</strong> 这一步的实现代码也非常简洁，我们直接利用DenseFeatures把类别型Embedding特征和数值型特征连接在一起形成稠密特征向量，然后依次经过两层128维的全连接层，最后通过sigmoid输出神经元产生最终预估值。</p><pre><code>preprocessing_layer = tf.keras.layers.DenseFeatures(numerical_columns + categorical_columns)\n\n\nmodel = tf.keras.Sequential([\n    preprocessing_layer,\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid'),\n])\n\n</code></pre><p><strong>第六步是定义模型训练相关的参数。</strong> 在这一步中，我们需要设置模型的损失函数，梯度反向传播的优化方法，以及模型评估所用的指标。关于损失函数，我们使用的是二分类问题最常用的二分类交叉熵，优化方法使用的是深度学习中很流行的adam，最后是评估指标，使用了准确度accuracy作为模型评估的指标。</p><pre><code>model.compile(\n    loss='binary_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy'])\n\n</code></pre><p><strong>第七步是模型的训练和评估。</strong> TensorFlow模型的训练过程和Spark MLlib一样，都是调用fit函数，然后使用evaluate函数在测试集上进行评估。不过，这里我们要注意一个参数epochs，它代表了模型训练的轮数，一轮代表着使用所有训练数据训练一遍，epochs=10代表着训练10遍。</p><pre><code>model.fit(train_dataset, epochs=10)\n\n\ntest_loss, test_accuracy = model.evaluate(test_dataset)\n\n\nprint('\\n\\nTest Loss {}, Test Accuracy {}'.format(test_loss, test_accuracy)\n\n</code></pre><p>如果一切顺利的话，你就可以看到模型的训练过程和最终的评估结果了。从下面的训练输出中你可以看到，每轮训练模型损失（Loss）的变化过程和模型评估指标Accuracy的变化过程。你肯定会发现，随着每轮训练的Loss减小，Accuracy会变高。换句话说，每轮训练都会让模型结果更好，这是我们期望看到的。需要注意的是，理论上来说，我们应该在模型accuracy不再变高时停止训练，据此来确定最佳的epochs取值。但如果模型收敛的时间确实过长，我们也可以设置一个epochs最大值，让模型提前终止训练。</p><pre><code>Epoch 1/10\n8236/8236 [==============================] - 20s 2ms/step - loss: 2.7379 - accuracy: 0.5815\nEpoch 2/10\n8236/8236 [==============================] - 21s 3ms/step - loss: 0.6397 - accuracy: 0.6659\nEpoch 3/10\n8236/8236 [==============================] - 21s 3ms/step - loss: 0.5550 - accuracy: 0.7179\nEpoch 4/10\n8236/8236 [==============================] - 21s 2ms/step - loss: 0.5209 - accuracy: 0.7431\nEpoch 5/10\n8236/8236 [==============================] - 21s 2ms/step - loss: 0.5010 - accuracy: 0.7564\nEpoch 6/10\n8236/8236 [==============================] - 20s 2ms/step - loss: 0.4866 - accuracy: 0.7641\nEpoch 7/10\n8236/8236 [==============================] - 20s 2ms/step - loss: 0.4770 - accuracy: 0.7702\nEpoch 8/10\n8236/8236 [==============================] - 21s 2ms/step - loss: 0.4688 - accuracy: 0.7745\nEpoch 9/10\n8236/8236 [==============================] - 20s 2ms/step - loss: 0.4633 - accuracy: 0.7779\nEpoch 10/10\n8236/8236 [==============================] - 20s 2ms/step - loss: 0.4580 - accuracy: 0.7800\n1000/1000 [==============================] - 1s 1ms/step - loss: 0.5037 - accuracy: 0.7473\n\n\n\n\nTest Loss 0.5036991238594055, Test Accuracy 0.747250020503997\n</code></pre><p>最终的模型评估需要在测试集上进行，从上面的输出中我们可以看到，最终的模型在测试集上的准确度是0.7472，它意味着我们的模型对74.72%的测试样本作出了正确的预测。当然了，模型的评估指标还是很多，我们会在之后的模型评估篇中进行详细的讲解。</p><h2>小结</h2><p>这节课是我们深度学习模型实践的第一课，我们要掌握两个重点内容，一是Embedding+MLP的模型结构，二是Embedding+MLP模型的TensorFlow实现。</p><p>Embedding+MLP主要是由Embedding部分和MLP部分这两部分组成，使用Embedding层是为了将类别型特征转换成Embedding向量，MLP部分是通过多层神经网络拟合优化目标。具体来说，以微软的Deep Crossing为例，模型一共分为5层，从下到上分别是Feature层、Embedding层、Stacking层、MLP层和Scoring层。</p><p>在TensorFlow实践部分，我们利用上节课处理好的特征和训练数据，实现了Sparrow Recsys项目中的第一个深度学习模型。在实践过程中，我们要重点掌握类别型特征的处理方法，模型的定义方式和训练方式，以及最后的模型评估方法。</p><p>我也把这些重点知识总结在了一张表格里，你可以利用它来认真回顾。</p><p><img src=\"https://static001.geekbang.org/resource/image/4e/67/4e34e77589d386c8924542794dyy1867.jpg?wh=1870*1273\" alt=\"\"></p><p>今天，我们一起完成了Embedding MLP模型的实现。在之后的课程中，我们会进一步实现其他深度学习模型，通过模型的评估进行效果上的对比。另外，我们也会利用训练出的深度学习模型完成Sparrow Recsys的猜你喜欢功能，期待与你一起不断完善我们的项目。</p><h2>课后思考</h2><p>在我们实现的Embedding+MLP模型中，也有用户Embedding层和物品Embedding层。你觉得从这两个Embedding层中，抽取出来的用户和物品Embedding，能直接用来计算用户和物品之间的相似度吗？为什么？</p><p>欢迎把你的思考和疑惑写在留言区，也欢迎你把这节课转发给希望用TensorFlow实现深度推荐模型的朋友，我们下节课见！</p>","comments":[{"had_liked":false,"id":265390,"user_name":"范闲","can_delete":false,"product_type":"c1","uid":1073125,"ip_address":"","ucode":"F21FD7DF6BA53C","user_header":"https://static001.geekbang.org/account/avatar/00/10/5f/e5/54325854.jpg","comment_is_top":false,"comment_ctime":1606887691,"is_pvip":false,"replies":[{"id":"96522","content":"是的","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1606940359,"ip_address":"","comment_id":265390,"utype":1}],"discussion_count":4,"race_medal":0,"score":"100391135499","product_id":100060801,"comment_content":"无法直接计算相似度. user embedding 和 item embedding 虽然输入数据来源自同一个数据集，但是本身并不在一个向量空间内.","like_count":23,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":510913,"discussion_content":"是的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606940359,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2475449,"avatar":"https://static001.geekbang.org/account/avatar/00/25/c5/b9/4bf9a45d.jpg","nickname":"时间选真人","note":"","ucode":"DE38EAC48BE80D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":364710,"discussion_content":"在不在一个空间到底如何判断，请老师多解释一下","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617570615,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":2407533,"avatar":"https://static001.geekbang.org/account/avatar/00/24/bc/6d/e582fc2f.jpg","nickname":"kun","note":"","ucode":"306BAD4BFB6E66","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2475449,"avatar":"https://static001.geekbang.org/account/avatar/00/25/c5/b9/4bf9a45d.jpg","nickname":"时间选真人","note":"","ucode":"DE38EAC48BE80D","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":378592,"discussion_content":"后面懂了吗？我也不懂是如何判断出来的，不在同一向量空间？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1623296835,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":364710,"ip_address":""},"score":378592,"extra":""}]},{"author":{"id":2452019,"avatar":"https://static001.geekbang.org/account/avatar/00/25/6a/33/7e314945.jpg","nickname":"优秀是一种信仰","note":"","ucode":"2FEF98FF9BC379","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":351584,"discussion_content":"不在一个空间指的是长度不一致无法计算的意思吗？如果控制长度一致是否就可以了？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1614335158,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":262887,"user_name":"Geek_f9ea8a","can_delete":false,"product_type":"c1","uid":2303670,"ip_address":"","ucode":"5FA37C8F8A23F8","user_header":"","comment_is_top":false,"comment_ctime":1605870189,"is_pvip":false,"replies":[{"id":"95379","content":"1. 确实没有加normalization，当然可以在tensorflow预处理时候加上normalization，或者在spark中生成训练样本的时候加上特征预处理的一些操作，没问题。而且也确实推荐在实际工作中尝试用normalization，bucketize，maxminscaling去做不同的预处理查看效果，这一点我们之前在特征工程部分介绍过。<br><br>2.是个好问题，如果embedidng层是在模型中，通过e2e训练的，那么你如果细致的理解梯度下降的过程就知道，某个用户的embedding确实是只用TA自己的历史数据生成的。<br><br>这样的弊端当然有，就是收敛慢，而且在用户历史行为过少的时候，这个用户的embedding不稳定。所以也可以采用embedding预训练的方式，就像我们之前embedding部分讲解的。<br><br><br>推荐其他同学也思考这两个问题，非常好的实践问题。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1605903257,"ip_address":"","comment_id":262887,"utype":1}],"discussion_count":4,"race_medal":0,"score":"78915281517","product_id":100060801,"comment_content":"请问老师：<br><br>1.看了您实现的MLPRecModel, 由于对tf2.x 版本不是很熟悉，没有看出来 是否 针对 发布时间、电影阅读数等等统计字段 进行了 标准化，<br>我当时用keras 实现了一下，没有对统计特征进行标准化，效果很差，只有56%左右，损失一直不降，然后最那些统计指标进行标准化话，训练完第一轮，测试集就能达到73%。<br>2. 您这次实现的MLPRecModel，针对用户、电影，先直接给出的初始化Embedding，然后训练对应的Embedding 权重，<br>在训练集中，假如 一个用户 有10条样本数据集，那么模型训练该用户Embedding 是根据这10条数据最终训练成能表示该用户Embedding吗？<br>数据集特征中， 针对一条样本，没有特征表示： 用户历史观看电影 【电影1，电影2 电影3。。。】（按照时间排序） 这样一条特征，对训练Embedding有影响吗，我总感觉好像丢了这部分信息。","like_count":19,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":510017,"discussion_content":"1. 确实没有加normalization，当然可以在tensorflow预处理时候加上normalization，或者在spark中生成训练样本的时候加上特征预处理的一些操作，没问题。而且也确实推荐在实际工作中尝试用normalization，bucketize，maxminscaling去做不同的预处理查看效果，这一点我们之前在特征工程部分介绍过。\n\n2.是个好问题，如果embedidng层是在模型中，通过e2e训练的，那么你如果细致的理解梯度下降的过程就知道，某个用户的embedding确实是只用TA自己的历史数据生成的。\n\n这样的弊端当然有，就是收敛慢，而且在用户历史行为过少的时候，这个用户的embedding不稳定。所以也可以采用embedding预训练的方式，就像我们之前embedding部分讲解的。\n\n\n推荐其他同学也思考这两个问题，非常好的实践问题。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605903257,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":1295330,"avatar":"https://static001.geekbang.org/account/avatar/00/13/c3/e2/261c6579.jpg","nickname":"SuperBoBo","note":"","ucode":"D65217640F88D1","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":550809,"discussion_content":"请问老师，线上的时间戳、统计特征如何做归一化呢？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1644742572,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":510017,"ip_address":""},"score":550809,"extra":""}]},{"author":{"id":1222185,"avatar":"https://static001.geekbang.org/account/avatar/00/12/a6/29/607da279.jpg","nickname":"programmer","note":"","ucode":"9C2A7C62929790","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":339918,"discussion_content":"请问老师，之前说过，这里如果采用预训练的方式，embedding就作为特征向量不再变化了是吗？是否也可以把预训练的结果作为参数的初始化，继续参与梯度下降的训练呢？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1609840790,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1944884,"avatar":"","nickname":"AstrHan","note":"","ucode":"14C5F3323A472D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1222185,"avatar":"https://static001.geekbang.org/account/avatar/00/12/a6/29/607da279.jpg","nickname":"programmer","note":"","ucode":"9C2A7C62929790","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":342497,"discussion_content":"继续参加会好一点 相当于在现有的数据机上做了微调","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1610699262,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":339918,"ip_address":""},"score":342497,"extra":""}]}]},{"had_liked":false,"id":282373,"user_name":"科西嘉的怪物","can_delete":false,"product_type":"c1","uid":2456788,"ip_address":"","ucode":"9B18239202E770","user_header":"https://static001.geekbang.org/account/avatar/00/25/7c/d4/e9cae41d.jpg","comment_is_top":false,"comment_ctime":1615208986,"is_pvip":false,"replies":[{"id":"102595","content":"是这样","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1615336956,"ip_address":"","comment_id":282373,"utype":1}],"discussion_count":2,"race_medal":0,"score":"70334685722","product_id":100060801,"comment_content":"如果这个模型的结构变一下，把拼接操作变成user emb点乘item emb直接得到预测评分，那训练出来user emb和item emb就在一个向量空间了吧","like_count":16,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":516721,"discussion_content":"是这样","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1615336956,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2067128,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/yb5R8iaxicD8ttsqXiaNFQHQvc3pcdabma6QPTcO1qeNicfPMn9GiaicWr2ubjxmmr09Vbspf4fWc7icu48hyl0Fz6n3A/132","nickname":"RocketQian","note":"","ucode":"57A30F6896B628","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":533327,"discussion_content":"这就是MF吧？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1637838277,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"user_type\":1}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":300047,"user_name":"月臻","can_delete":false,"product_type":"c1","uid":2665713,"ip_address":"","ucode":"EFC17B18F88D08","user_header":"https://static001.geekbang.org/account/avatar/00/28/ac/f1/42508146.jpg","comment_is_top":false,"comment_ctime":1624962551,"is_pvip":false,"replies":[{"id":"109381","content":"赞，推荐其他同学参考。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1626215210,"ip_address":"","comment_id":300047,"utype":1}],"discussion_count":3,"race_medal":0,"score":"57459537399","product_id":100060801,"comment_content":"老师，您好，我使用Pytorch实现了项目中用到的模型：https:&#47;&#47;github.com&#47;hillup&#47;recommend","like_count":14,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":522626,"discussion_content":"赞，推荐其他同学参考。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1626215210,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1602315,"avatar":"https://static001.geekbang.org/account/avatar/00/18/73/0b/0f918fa2.jpg","nickname":"快乐小夜曲","note":"","ucode":"0E257D2EAAA499","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":548564,"discussion_content":"很棒的操作！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1643264910,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2687465,"avatar":"","nickname":"Infp","note":"","ucode":"17467CFFB40E6B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":386038,"discussion_content":"感谢大佬分享","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627385897,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":263114,"user_name":"浣熊当家","can_delete":false,"product_type":"c1","uid":1952248,"ip_address":"","ucode":"939F06050423E4","user_header":"https://static001.geekbang.org/account/avatar/00/1d/c9/f8/72955ef9.jpg","comment_is_top":false,"comment_ctime":1606011072,"is_pvip":false,"replies":[{"id":"95606","content":"这里的embedding层是跟上层神经网络一起end2end训练出来的。当然是标签的，就是样本中的标签。<br><br>embedding层是通过上层逐层传导回来的梯度来进行更新的。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1606168541,"ip_address":"","comment_id":263114,"utype":1}],"discussion_count":1,"race_medal":0,"score":"48850651328","product_id":100060801,"comment_content":"想请教下老师，关于embedding训练的原理， 比如图二中Word2Vec的训练我们有输入值X（one-hot向量）， 和输出Y（作为label， multi-hot向量），所以我们可以训练我们的的Word2Vec的词向量，使其得到最贴近训练样本标签的结果。但是我们这节课讲的embedding层只有前一部分，并没有Y（label）这部分，embedding是通过什么原理训练出来的呢？embedding本质是个unsupervised learning吗？","like_count":11,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":510100,"discussion_content":"这里的embedding层是跟上层神经网络一起end2end训练出来的。当然是标签的，就是样本中的标签。\n\nembedding层是通过上层逐层传导回来的梯度来进行更新的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606168541,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":265559,"user_name":"张程","can_delete":false,"product_type":"c1","uid":2017495,"ip_address":"","ucode":"0CF937A9112FBF","user_header":"https://static001.geekbang.org/account/avatar/00/1e/c8/d7/909d815d.jpg","comment_is_top":false,"comment_ctime":1606933860,"is_pvip":false,"replies":[{"id":"96556","content":"怎么可能只有buy和click，有impression没被click和buy的商品不就是最合适的负样本吗。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1606969277,"ip_address":"","comment_id":265559,"utype":1}],"discussion_count":1,"race_medal":0,"score":"40261639524","product_id":100060801,"comment_content":"如果是电商推荐商品。没有 0和1 的label, 只有buy还是click的区别，这样的话请问应该如何处理？lable列全部为1吗？谢谢！","like_count":9,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":510976,"discussion_content":"怎么可能只有buy和click，有impression没被click和buy的商品不就是最合适的负样本吗。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606969277,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":266584,"user_name":"Geek_b4af04","can_delete":false,"product_type":"c1","uid":2345393,"ip_address":"","ucode":"BB2A926CAC5390","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/uzvibJnyK9kXJC0p6hv1tyDk5naXzNwOrjibfMAKAb4dadJ608Gd3FW5PCqh0YCXQxMIRkmP6mpEzvraTCJzGvhA/132","comment_is_top":false,"comment_ctime":1607403774,"is_pvip":false,"replies":[{"id":"96826","content":"按照embedding层的构造，是一定要把id转换成onehot的，否则id这个数字本身怎么能输入到网络中呢？<br><br>参数爆炸这个事情也是肯定的，这也是为什么说embedding layer是最费时，费空间的部分，一个神经网络有可能超过90%的参数和时间都花在训练embedding层上。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1607467360,"ip_address":"","comment_id":266584,"utype":1}],"discussion_count":3,"race_medal":0,"score":"31672174846","product_id":100060801,"comment_content":"王喆老师，你好，我最近准备吧这几个模型改写为pytorch版本的代码，在进行category features的embedding的时候，是需要先将这些features变为one hot向量，再将这些one hot的向量变成embedding向量吗？但这样的话有些问题，这样数据大小就爆炸了，比如movie id 的features（19000个数据），从(19000,) -&gt; (19000, 30001) -&gt; (19000, 30001, 10)","like_count":7,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":511320,"discussion_content":"按照embedding层的构造，是一定要把id转换成onehot的，否则id这个数字本身怎么能输入到网络中呢？\n\n参数爆炸这个事情也是肯定的，这也是为什么说embedding layer是最费时，费空间的部分，一个神经网络有可能超过90%的参数和时间都花在训练embedding层上。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1607467360,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2394429,"avatar":"https://static001.geekbang.org/account/avatar/00/24/89/3d/a470e6f8.jpg","nickname":"君恒","note":"","ucode":"01F2A2520B8696","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":384661,"discussion_content":"楼上说的对 你说的对 具体可以看github DeepCTR-pytorch的实现","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1626693684,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2310887,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/ibbg35VbtSTXrcBE1AWgwXAHmKBjru5HzSzEUaxiaTeahQqDVxr4ZATHibn67aanoMmT4uG34PNRv3norpmOqjwMw/132","nickname":"嘿人","note":"","ucode":"F56D9A416ED46D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":333891,"discussion_content":"Pytorch的实现是做labelencoder再传到nn.embedding，和tf有区别","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1607663581,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":262433,"user_name":"那时刻","can_delete":false,"product_type":"c1","uid":1150927,"ip_address":"","ucode":"B0D150856C3A4A","user_header":"https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg","comment_is_top":false,"comment_ctime":1605719414,"is_pvip":false,"replies":[{"id":"95224","content":"其实不可以，因为二者不在一个向量空间。直接用dot product或者cosin similarity计算相似度都不可以。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1605746812,"ip_address":"","comment_id":262433,"utype":1}],"discussion_count":3,"race_medal":0,"score":"31670490486","product_id":100060801,"comment_content":"课后思考题，我的想法是在Stacking 层把不同的 Embedding 特征和数值型特征拼接在一起，即把电影和用户的 Embedding 向量拼接起来，形成新的包含全部特征的特征向量，该特征向量保存了用户和电影之间的相似性关系，应该可以直接用来计算用户和物品之间的相似度。","like_count":7,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509829,"discussion_content":"其实不可以，因为二者不在一个向量空间。直接用dot product或者cosin similarity计算相似度都不可以。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605746812,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1150927,"avatar":"https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg","nickname":"那时刻","note":"","ucode":"B0D150856C3A4A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":327134,"discussion_content":"老师，您题目中说的是在embedding层抽取用户和电影embedding向量，它们不在同一向量空间。我之前理解题意有偏差。\n\n另外，在embedding向量那一节课，提到从 Netflix 利用矩阵分解方法生成的电影和用户的 Embedding 向量示意图中，我们可以看出不同的电影和用户分布在一个二维的空间内，由于 Embedding 向量保存了它们之间的相似性关系。这里提到的方法和本节课提到的模型里的stacking层是否一致呢？可能我的理解有偏差，麻烦老师解惑下","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605752887,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":1150927,"avatar":"https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg","nickname":"那时刻","note":"","ucode":"B0D150856C3A4A","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":329194,"discussion_content":"因为矩阵分解使用点积操作作为最后的输出层，所以他们在一个空间内。而这里的stacking操作，不同embedding之间没有直接关系，也没有互操作，所以他们不在一个向量空间。","likes_number":15,"is_delete":false,"is_hidden":false,"ctime":1606334819,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":327134,"ip_address":""},"score":329194,"extra":""}]}]},{"had_liked":false,"id":262430,"user_name":"那时刻","can_delete":false,"product_type":"c1","uid":1150927,"ip_address":"","ucode":"B0D150856C3A4A","user_header":"https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg","comment_is_top":false,"comment_ctime":1605718441,"is_pvip":false,"replies":[{"id":"95225","content":"不一定，关于特征选择，不要纠结于这样的问题，自己去尝试。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1605746861,"ip_address":"","comment_id":262430,"utype":1}],"discussion_count":1,"race_medal":0,"score":"23080554921","product_id":100060801,"comment_content":"请问老师，对于数值型特征都有均值和标准差，比如电影评分均值和电影评分标准差两个特征。您在实际工作中，对于数值型特征都会额外加上均值和标准差两个特征吗？","like_count":5,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509828,"discussion_content":"不一定，关于特征选择，不要纠结于这样的问题，自己去尝试。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605746861,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":274500,"user_name":"灯灯灯","can_delete":false,"product_type":"c1","uid":2402565,"ip_address":"","ucode":"A801439F74127C","user_header":"https://static001.geekbang.org/account/avatar/00/24/a9/05/6822b8a5.jpg","comment_is_top":false,"comment_ctime":1611040352,"is_pvip":false,"replies":[{"id":"99654","content":"大量TF的warning是平台自己的问题，暂时不用过于纠结","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1611096432,"ip_address":"","comment_id":274500,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18790909536","product_id":100060801,"comment_content":"老师你好， 我在运行时会出现以下的waring。请问是我设置的原因还是什么其他原因呢？<br><br>WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a &lt;class &#39;collections.OrderedDict&#39;&gt; input: OrderedDict([(&#39;movieId&#39;, &lt;tf.Tensor &#39;ExpandDims_4:0&#39; shape=(None, 1) dtype=int32&gt;), (&#39;userId&#39;, &lt;tf.Tensor &#39;ExpandDims_17:0&#39; shape=(None, 1) dtype=int32&gt;), (&#39;rating&#39;, &lt;tf.Tensor &#39;ExpandDims_7:0&#39; shape=(None, 1) dtype=float32&gt;), (&#39;timestamp&#39;, &lt;tf.Tensor &#39;ExpandDims_9:0&#39; shape=(None, 1) dtype=int32&gt;), (&#39;releaseYear&#39;, &lt;tf.Tensor &#39;ExpandDims_8:0&#39; shape=(None, 1) dtype=int32&gt;), (&#39;movieGenre1&#39;, &lt;tf.Tensor &#39;ExpandDims_1:0&#39; shape=(None, 1) dtype=string&gt;), (&#39;movieGenre2&#39;, &lt;tf.Tensor &#39;ExpandDims_2:0&#39; shape=(None, 1) dtype=string&gt;), (&#39;movieGenre3&#39;, &lt;tf.Tensor &#39;ExpandDims_3:0&#39; shape=(None, 1) dtype=string&gt;), (&#39;movieRatingCount&#39;, &lt;tf.Tensor &#39;ExpandDims_5:0&#39; shape=(None, 1) dtype=int32&gt;), (&#39;movieAvgRating&#39;, &lt;tf.Tensor &#39;ExpandDims:0&#39; shape=(None, 1) dtype=float32&gt;), (&#39;movieRatingStddev&#39;, &lt;tf.Tensor &#39;ExpandDims_6:0&#39; shape=(None, 1) dtype=float32&gt;), (&#39;userRatedMovie1&#39;, &lt;tf.Tensor &#39;ExpandDims_18:0&#39; shape=(None, 1) dtype=int32&gt;), <br>...<br>(&#39;userGenre5&#39;, &lt;tf.Tensor &#39;ExpandDims_16:0&#39; shape=(None, 1) dtype=string&gt;)])<br>Consider rewriting this model with the Functional API.","like_count":4,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":514037,"discussion_content":"大量TF的warning是平台自己的问题，暂时不用过于纠结","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1611096432,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":263678,"user_name":"。LEAF","can_delete":false,"product_type":"c1","uid":2304080,"ip_address":"","ucode":"99C30EBBBBADC1","user_header":"https://static001.geekbang.org/account/avatar/00/23/28/50/c8cb0c3b.jpg","comment_is_top":false,"comment_ctime":1606215916,"is_pvip":false,"replies":[{"id":"95681","content":"这是parameter sever的问题了，绝大部分都是求sum，因为loss本身就是累加的。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1606246248,"ip_address":"","comment_id":263678,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18786085100","product_id":100060801,"comment_content":"老师好，想问一个问题，分布式训练模型的时候，loss是直接做sum好，还是求mean呢？","like_count":4,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":510268,"discussion_content":"这是parameter sever的问题了，绝大部分都是求sum，因为loss本身就是累加的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606246248,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":289826,"user_name":"小强","can_delete":false,"product_type":"c1","uid":2398148,"ip_address":"","ucode":"C3D1215867302D","user_header":"https://static001.geekbang.org/account/avatar/00/24/97/c4/6c92c78a.jpg","comment_is_top":false,"comment_ctime":1619192438,"is_pvip":false,"replies":[{"id":"105128","content":"模型篇中应该没有直接生成embedding，而是直接生成的预测分数对吧，所以模型篇主要用于ranking，之前讲过的item2vec等方法生成的embedding，可以用于召回，当然也可以作为ranking的一部分特征。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1619283870,"ip_address":"","comment_id":289826,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14504094326","product_id":100060801,"comment_content":"通过学习code，推荐模型篇的Embedding都是通过tensorflow直接生成。请问在实际应用中，深度学习的模型的Embedding和线上服务篇生成的Embedding (Item2Vec, Graph Embedding)一般都是独立的吗？线上服务篇生成的用于Recall？模型篇生成的用于Sorting?","like_count":3,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":519027,"discussion_content":"模型篇中应该没有直接生成embedding，而是直接生成的预测分数对吧，所以模型篇主要用于ranking，之前讲过的item2vec等方法生成的embedding，可以用于召回，当然也可以作为ranking的一部分特征。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1619283870,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":262477,"user_name":"Sebastian","can_delete":false,"product_type":"c1","uid":1797634,"ip_address":"","ucode":"62E6FC13DB00E3","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/55lYKUdcPFgUHibRYmaRiaBdrsmnLGOHdPp4OicjBh197X0vyGa9qAwruEqicAPuUgibXO4Lz5jLudlcbtsqq2p3CpA/132","comment_is_top":false,"comment_ctime":1605749052,"is_pvip":false,"replies":[{"id":"95329","content":"tensorflow的分布式训练也是一个非常大的话题。涉及到parameter server模式的训练方式和分布式环境的部署。<br>推荐参考官方资料 https:&#47;&#47;www.tensorflow.org&#47;guide&#47;distributed_training<br><br>因为这个问题上，没有环境我们几乎没法实践，所以咱们课程暂时不会涉及到。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1605833648,"ip_address":"","comment_id":262477,"utype":1}],"discussion_count":3,"race_medal":0,"score":"14490650940","product_id":100060801,"comment_content":"老师，在实战中由于数据量庞大，用tf搭建的模型是否需要进行分布式训练？一般是如何分布式训练？之后会有类似的章节讲到吗？","like_count":4,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509849,"discussion_content":"tensorflow的分布式训练也是一个非常大的话题。涉及到parameter server模式的训练方式和分布式环境的部署。\n推荐参考官方资料 https://www.tensorflow.org/guide/distributed_training\n\n因为这个问题上，没有环境我们几乎没法实践，所以咱们课程暂时不会涉及到。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605833648,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1658932,"avatar":"https://static001.geekbang.org/account/avatar/00/19/50/34/172342fd.jpg","nickname":"吴十一","note":"","ucode":"47232ED3225081","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":327502,"discussion_content":"这个网页打不开呢 ","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605852003,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":1658932,"avatar":"https://static001.geekbang.org/account/avatar/00/19/50/34/172342fd.jpg","nickname":"吴十一","note":"","ucode":"47232ED3225081","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":327686,"discussion_content":"可能国内被墙了？看一下这个能不能打开 \nhttps://tensorflow.google.cn/guide/distributed_training","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605913963,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":327502,"ip_address":""},"score":327686,"extra":""}]}]},{"had_liked":false,"id":306331,"user_name":"潘","can_delete":false,"product_type":"c1","uid":2727709,"ip_address":"","ucode":"B66C4AE20BAB3E","user_header":"https://static001.geekbang.org/account/avatar/00/29/9f/1d/049d2002.jpg","comment_is_top":false,"comment_ctime":1628500872,"is_pvip":false,"replies":[{"id":"110913","content":"是的，最好的方法是共享emb矩阵，可以在这个版本技术上进行修改","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1628530860,"ip_address":"","comment_id":306331,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10218435464","product_id":100060801,"comment_content":"老师您好，userGenre1-userGenre5，movieGenre1-movieGenre3 里面的数据是一致的，one-hot大小是1 *19 ，对应的embedding参数矩阵大小就是19*10 ，那么这八列数据对应要训练8个 19*10的矩阵参数，但是他们的one hot是一样的，请问可否可以共享一个19*10的参数矩阵","like_count":2,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":524720,"discussion_content":"是的，最好的方法是共享emb矩阵，可以在这个版本技术上进行修改","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1628530860,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":296020,"user_name":"挖掘机","can_delete":false,"product_type":"c1","uid":2371003,"ip_address":"","ucode":"B604CF78054E25","user_header":"https://static001.geekbang.org/account/avatar/00/24/2d/bb/8bd1b6e1.jpg","comment_is_top":false,"comment_ctime":1622707014,"is_pvip":false,"replies":[{"id":"108159","content":"1. 会有冲突，在硬件允许情况下，最好把hashbucket数量加大。<br>2. 自己调参，一般不建议非常大<br>3. 经典面试题，自己去搜一下相关资料。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1623876449,"ip_address":"","comment_id":296020,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10212641606","product_id":100060801,"comment_content":"老师好，最近正好在做dssm，其中的好几个有疑惑的点一起讨论<br>1. 当id类特征，比如movieId和userId数量很大时，目前userId大概每天有1000w级别。我选择了先使用hash_bucket来做散列，然后再压缩到300维的embedding。但是我对这种方法有怀疑，就是这么大的数量，会不会出现大量的冲突。这样对准确性是不是有影响。<br>2. mlp的每层的维度如何确定，是越大越好，还是越小越好。<br>3. 模型特征可选的目前大概有几千个，如何从中选出重要性最大的特征呢？","like_count":3,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":521295,"discussion_content":"1. 会有冲突，在硬件允许情况下，最好把hashbucket数量加大。\n2. 自己调参，一般不建议非常大\n3. 经典面试题，自己去搜一下相关资料。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1623876449,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":266404,"user_name":"Sebastian","can_delete":false,"product_type":"c1","uid":1797634,"ip_address":"","ucode":"62E6FC13DB00E3","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/55lYKUdcPFgUHibRYmaRiaBdrsmnLGOHdPp4OicjBh197X0vyGa9qAwruEqicAPuUgibXO4Lz5jLudlcbtsqq2p3CpA/132","comment_is_top":false,"comment_ctime":1607325882,"is_pvip":false,"replies":[{"id":"96796","content":"这是个好问题，你觉得划分和不划分各有哪些优劣？按时间划分就一点好吗？有没有基于按时间划分的更好的评估方法？","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1607390564,"ip_address":"","comment_id":266404,"utype":1}],"discussion_count":8,"race_medal":0,"score":"10197260474","product_id":100060801,"comment_content":"老师，想问下在划分训练集测试集，怎么就直接使用<br>test_dataset = raw_samples_data.take(1000)train_dataset = raw_samples_data.skip(1000)<br>这里的take和skip的意思是选1000条样本作为训练，然后选1000条样本作为测试集吗？<br>难道不需要按照时间划分吗？","like_count":2,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":511250,"discussion_content":"这是个好问题，你觉得划分和不划分各有哪些优劣？按时间划分就一点好吗？有没有基于按时间划分的更好的评估方法？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1607390564,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2310887,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/ibbg35VbtSTXrcBE1AWgwXAHmKBjru5HzSzEUaxiaTeahQqDVxr4ZATHibn67aanoMmT4uG34PNRv3norpmOqjwMw/132","nickname":"嘿人","note":"","ucode":"F56D9A416ED46D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":333997,"discussion_content":"我感觉特征是没有穿越的，之前所做的统计特征已经按照滑动窗口的方式避免了穿越问题，也就是说当前t时刻的预测，考虑且仅考虑了t时刻以前的特征，这里随机划分应该也不为过","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1607687881,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1797634,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/55lYKUdcPFgUHibRYmaRiaBdrsmnLGOHdPp4OicjBh197X0vyGa9qAwruEqicAPuUgibXO4Lz5jLudlcbtsqq2p3CpA/132","nickname":"Sebastian","note":"","ucode":"62E6FC13DB00E3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":332944,"discussion_content":"老师我理解应该是在生成数据的时候，就按照时间进行数据划分？这样可以避免特征穿越。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1607399599,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":5,"child_discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":1797634,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/55lYKUdcPFgUHibRYmaRiaBdrsmnLGOHdPp4OicjBh197X0vyGa9qAwruEqicAPuUgibXO4Lz5jLudlcbtsqq2p3CpA/132","nickname":"Sebastian","note":"","ucode":"62E6FC13DB00E3","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":334060,"discussion_content":"前面 嘿人同学说的挺好，我们在设计特征的时候避免了特征穿越，所以随机划分的问题也不太大，但确实还是存在这一些样本乱序的问题，不能说完全避免了数据穿越。\n\n按时间划分也有问题，比如一个用户的行为历史可能完全出现在样本集，或者完全出现在测试集，这样就很难预测了，因为模型没有包含任何这个用户的id型特征。\n\n最好的方式其实是离线replay或者按用户行为序列的分用户时间切割。","likes_number":9,"is_delete":false,"is_hidden":false,"ctime":1607716786,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":332944,"ip_address":""},"score":334060,"extra":""},{"author":{"id":2403705,"avatar":"","nickname":"Wa","note":"","ucode":"96E28E50FCA96C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":343671,"discussion_content":"“一个用户的行为历史可能完全出现在测试集，这样就很难预测了，因为模型没有包含任何这个用户的id型特征。” 意思是这个用户有关的数据在训练集中没出现过，所以测试集中出现时很难预测。这里有点没想明白。模型训练时只是没学到这个用户的用户id特征，但用户的历史行为特征包括很多的统计特征（用户评分标准差、用户平均评分、用户喜欢电影风格...）模型都有学到，那它出现在测试集中应该也能预测啊。或者换个问题，如果根本不把用户ID这个特征加进来，模型效果会差很多吗？","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1611131423,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":334060,"ip_address":""},"score":343671,"extra":""},{"author":{"id":2201497,"avatar":"https://static001.geekbang.org/account/avatar/00/21/97/99/f5e9740a.jpg","nickname":"庄小侠","note":"","ucode":"36943D87578024","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2403705,"avatar":"","nickname":"Wa","note":"","ucode":"96E28E50FCA96C","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":349769,"discussion_content":"这里我理解的意思是不能按照时间一刀切训练测试集（比如1月20号前为训练集后为测试集），比如一个最近才注册的用户，很可能被一刀切成了测试集，压根没有训练集。所以也就没有用户评分、电影风格这些特征了。也就是老师说的按照用户行为序列时间切割会更好","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1613530595,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":343671,"ip_address":""},"score":349769,"extra":""}]}]},{"had_liked":false,"id":313801,"user_name":"Geek_59735b","can_delete":false,"product_type":"c1","uid":2769141,"ip_address":"","ucode":"420BED92906245","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epzA7E8kS3g2qezPWGxB4Gb6g6ApXaoyxeibbOV5XlTkDWgg3yHRYtYxlh9GoJcGH8yeSmOz8BKzbA/132","comment_is_top":false,"comment_ctime":1632669487,"is_pvip":false,"replies":[{"id":"113709","content":"只有在计算距离时才有现实意义，embedding本身你是根本没法解读出现实意义的。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1632767010,"ip_address":"","comment_id":313801,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5927636783","product_id":100060801,"comment_content":"请问下对于 Word2Vec 这样的任务，我们可以清楚的知道 embedding 后的 vector 之间的距离有其现实意义，因为 loss 函数的设计会使得在数据集中常常相邻的词距离相近，但是请问对于 这种 End2End 的应用，embedding 出来的 vector 有具体的现实意义吗 ？ 看 loss 好像看不出其有何具体的意义；","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527478,"discussion_content":"只有在计算距离时才有现实意义，embedding本身你是根本没法解读出现实意义的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1632767010,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":298474,"user_name":"Yvonne","can_delete":false,"product_type":"c1","uid":2577469,"ip_address":"","ucode":"85287A0AC7456C","user_header":"https://static001.geekbang.org/account/avatar/00/27/54/3d/366462d0.jpg","comment_is_top":false,"comment_ctime":1624137843,"is_pvip":false,"replies":[{"id":"108424","content":"可以，建议使用shared embedding。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1624388181,"ip_address":"","comment_id":298474,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5919105139","product_id":100060801,"comment_content":"老师，请问为什么不同的genres要分开embedding呢，他们可以用shared_embedding_columns吗？如果ta们是一个embedding universe的话","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":522151,"discussion_content":"可以，建议使用shared embedding。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1624388181,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":283958,"user_name":"Geek_cabb26","can_delete":false,"product_type":"c1","uid":2404973,"ip_address":"","ucode":"55BC98355F5147","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erPuYd30G4OpyHBJ0pkYPyGhUVyvd5lwzkCow1lvBAINazF8yE957liaGkbVnOJ5oZEHOlRHp9bvGQ/132","comment_is_top":false,"comment_ctime":1615996867,"is_pvip":false,"replies":[{"id":"103416","content":"是这样。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1616636395,"ip_address":"","comment_id":283958,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5910964163","product_id":100060801,"comment_content":"这里训练的不在一个向量空间，如果想直接拿user，item的，可以构图做一个metapath2vec，同时产出两个向量～","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":517190,"discussion_content":"是这样。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616636395,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1915541,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/3a/95/e8fc39d5.jpg","nickname":"Eayon","note":"","ucode":"9239EA2CA3D19B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":369569,"discussion_content":"同学，能解释一下，metapath2vec是啥意思么，这个思路是啥","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1619083329,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":282778,"user_name":"FayeChen","can_delete":false,"product_type":"c1","uid":2421713,"ip_address":"","ucode":"72AA0C00128017","user_header":"https://static001.geekbang.org/account/avatar/00/24/f3/d1/0663e55c.jpg","comment_is_top":false,"comment_ctime":1615399927,"is_pvip":false,"replies":[{"id":"102839","content":"大致的思路是利用tf中的embedding_lookup_sparse操作来生成multi hot的embedding。<br><br>生成embedding之后，可以用一些pooling的操作或者其他embedding间的操作把多个embedding合并成一个。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1615794388,"ip_address":"","comment_id":282778,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5910367223","product_id":100060801,"comment_content":"对于multi_hot(比如说历史的观影序列)的特征应该怎么生成embedding呢，感觉还是需要建立字典通过embedding_lookup查找pooling，或者矩阵相乘的方法么","like_count":2,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":516834,"discussion_content":"大致的思路是利用tf中的embedding_lookup_sparse操作来生成multi hot的embedding。\n\n生成embedding之后，可以用一些pooling的操作或者其他embedding间的操作把多个embedding合并成一个。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1615794388,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":281445,"user_name":"cymx66688","can_delete":false,"product_type":"c1","uid":1510592,"ip_address":"","ucode":"8198B851961BC7","user_header":"https://wx.qlogo.cn/mmopen/vi_32/TYeIuNZlibjr0eCvnCCTkYnFEgc8t7BialET3Bnsrbv9micpGIvbhwQrw7Zvt9BicThAEPPXojibVteAvQLb0eTO3DA/132","comment_is_top":false,"comment_ctime":1614753071,"is_pvip":false,"replies":[{"id":"102384","content":"当然最好是标准化，如果值域范围比较接近的话，也可以不标准化。<br><br>再次提醒大家，代码并不是什么标准答案，是帮助大家理解原理的，事实上这个领域也没有什么所谓的标准答案。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1615024144,"ip_address":"","comment_id":281445,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5909720367","product_id":100060801,"comment_content":"构造出的这些特征，在模型训练前不用标准化吗","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":516401,"discussion_content":"当然最好是标准化，如果值域范围比较接近的话，也可以不标准化。\n\n再次提醒大家，代码并不是什么标准答案，是帮助大家理解原理的，事实上这个领域也没有什么所谓的标准答案。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1615024144,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":277687,"user_name":"Sanders","can_delete":false,"product_type":"c1","uid":1697075,"ip_address":"","ucode":"3D460FEEDCDF34","user_header":"","comment_is_top":false,"comment_ctime":1612516299,"is_pvip":false,"replies":[{"id":"100821","content":"课程主要目的是让大家理解模型框架和经典结构，所有的细节问题还需要大家去多尝试，不可能都包含在课程中。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1612599925,"ip_address":"","comment_id":277687,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5907483595","product_id":100060801,"comment_content":"课程中对Deep Crossing的实现没有用到Residual Units，Stacking后直接用MLP，是为了简便吗？","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":515139,"discussion_content":"课程主要目的是让大家理解模型框架和经典结构，所有的细节问题还需要大家去多尝试，不可能都包含在课程中。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1612599925,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":276465,"user_name":"Geek_1e3d35","can_delete":false,"product_type":"c1","uid":2401742,"ip_address":"","ucode":"3FF20CF1CD86A5","user_header":"","comment_is_top":false,"comment_ctime":1611939225,"is_pvip":false,"replies":[{"id":"100800","content":"输入当然可以是任意维，side information可以拼接进来。<br>输出一般就是根据你的分类数量确定维度。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1612594636,"ip_address":"","comment_id":276465,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5906906521","product_id":100060801,"comment_content":"老师好，关于维度问题，模型拼接的输入维度是任意的吗，那么这种情况，在矩阵分解是拼接进辅助信息的向量是否可行？模型的输出维度也是可以作为优化参数进行调整的吗？","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":514712,"discussion_content":"输入当然可以是任意维，side information可以拼接进来。\n输出一般就是根据你的分类数量确定维度。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1612594636,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":274516,"user_name":"灯灯灯","can_delete":false,"product_type":"c1","uid":2402565,"ip_address":"","ucode":"A801439F74127C","user_header":"https://static001.geekbang.org/account/avatar/00/24/a9/05/6822b8a5.jpg","comment_is_top":false,"comment_ctime":1611044649,"is_pvip":false,"replies":[{"id":"99656","content":"咱们这里并没有。但embedding预训练+MLP线上预估是很流行的业界做法。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1611096540,"ip_address":"","comment_id":274516,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5906011945","product_id":100060801,"comment_content":"老师请问这里从embedding层开始都是线上运行的吗？","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":514041,"discussion_content":"咱们这里并没有。但embedding预训练+MLP线上预估是很流行的业界做法。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1611096540,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2156292,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/4icayE3ic5IA7RWwZcrxpMZE4T1WViakEgPsDC3UnhZwU83ad65IjmxPficy0vNZz6Q6vCiclnmyBDc5IYf7soHAXrQ/132","nickname":"Geek_790c43","note":"","ucode":"FFFAE0636A91EF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":347939,"discussion_content":"预训练的emb是通过item2vec或者graph2vec得到的把\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1612390108,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":263103,"user_name":"shenhuaze","can_delete":false,"product_type":"c1","uid":1960811,"ip_address":"","ucode":"32927236CBEA0B","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/qw7rRHUPRzhibxXWLG7kc3zkhZwBn4JZaryzko2eWOjSxDlRvUathHugrIVKhcCqxhtsANUTq0140AlbDkLZmcw/132","comment_is_top":false,"comment_ctime":1606008170,"is_pvip":false,"replies":[{"id":"95563","content":"据我了解应tensorflow应该没有默认支持残差网络中的残差神经元，需要自己实现残差神经元的结构。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1606115568,"ip_address":"","comment_id":263103,"utype":1}],"discussion_count":4,"race_medal":0,"score":"5900975466","product_id":100060801,"comment_content":"老师，如果要实现原版Deep Crossing的多层残差网络，是将MLP里的激活函数替换一下就可以了，还是需要做一下结构上的改动？","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":510097,"discussion_content":"据我了解应tensorflow应该没有默认支持残差网络中的残差神经元，需要自己实现残差神经元的结构。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606115568,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1797573,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/6d/c5/c0665034.jpg","nickname":"Wiiki","note":"","ucode":"037F2D44C087C5","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":328319,"discussion_content":"据我所知，在tf中使用Sequential按层顺序构建模型无法支持残差网络的建模，需要使用函数式API构建残差网络这种有跳接的结构模型~","likes_number":5,"is_delete":false,"is_hidden":false,"ctime":1606123222,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":2,"child_discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":1797573,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/6d/c5/c0665034.jpg","nickname":"Wiiki","note":"","ucode":"037F2D44C087C5","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":329193,"discussion_content":"是这样","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606334714,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":328319,"ip_address":""},"score":329193,"extra":""},{"author":{"id":1960811,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/qw7rRHUPRzhibxXWLG7kc3zkhZwBn4JZaryzko2eWOjSxDlRvUathHugrIVKhcCqxhtsANUTq0140AlbDkLZmcw/132","nickname":"shenhuaze","note":"","ucode":"32927236CBEA0B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1797573,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/6d/c5/c0665034.jpg","nickname":"Wiiki","note":"","ucode":"037F2D44C087C5","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":329546,"discussion_content":"多谢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606401056,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":328319,"ip_address":""},"score":329546,"extra":""}]}]},{"had_liked":false,"id":262207,"user_name":"myrfy","can_delete":false,"product_type":"c1","uid":1169401,"ip_address":"","ucode":"2814BAE5D70098","user_header":"","comment_is_top":false,"comment_ctime":1605665114,"is_pvip":false,"replies":[{"id":"95230","content":"是的，这里的embedding训练是在模型内部end2end训练的。<br><br>哪种更好这个问题我们之前已经讨论过几次了。希望你有自己的思考，可以写在下面，我们再讨论。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1605747263,"ip_address":"","comment_id":262207,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5900632410","product_id":100060801,"comment_content":"请问老师，这里的embedding训练是框架自动完成的吗？如果使用离线的预训练embedding和这种框架顺带训练的方式相比，哪种会更好呢？","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509735,"discussion_content":"是的，这里的embedding训练是在模型内部end2end训练的。\n\n哪种更好这个问题我们之前已经讨论过几次了。希望你有自己的思考，可以写在下面，我们再讨论。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605747263,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":354256,"user_name":"Geek_285507","can_delete":false,"product_type":"c1","uid":2865345,"ip_address":"广东","ucode":"DC1D2FA57DDE79","user_header":"","comment_is_top":false,"comment_ctime":1660219804,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1660219804","product_id":100060801,"comment_content":"给的trainingSamples中同一个用户ID，在不同的两行的userRatingCount值是不相等的，说明这个用户评分总数不是真正的用户评分总数，而是最近的？","like_count":0},{"had_liked":false,"id":342252,"user_name":"Geek_8197bf","can_delete":false,"product_type":"c1","uid":1907163,"ip_address":"","ucode":"401E78A595B5C0","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIf6b0zNIdVqOAMqT78lo39PdJB9qRIXqbwoOGlAEapFFezPiaFqCbUXS7VwI04MymFicgmsuOkILaQ/132","comment_is_top":false,"comment_ctime":1650157518,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1650157518","product_id":100060801,"comment_content":"你好老师，GENRE_FEATURES中的8个风格特征怎么来的？在特征中没有看到它们啊？","like_count":0},{"had_liked":false,"id":341064,"user_name":"啊?","can_delete":false,"product_type":"c1","uid":2873755,"ip_address":"","ucode":"9AB6AB1C24D149","user_header":"https://static001.geekbang.org/account/avatar/00/2b/d9/9b/40fa8f43.jpg","comment_is_top":false,"comment_ctime":1649321911,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1649321911","product_id":100060801,"comment_content":"为什么不用spark？<br><br>","like_count":0},{"had_liked":false,"id":333718,"user_name":"FruitDealer","can_delete":false,"product_type":"c1","uid":2386643,"ip_address":"","ucode":"34C8692B5C2413","user_header":"https://static001.geekbang.org/account/avatar/00/24/6a/d3/294cb209.jpg","comment_is_top":false,"comment_ctime":1644482675,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1644482675","product_id":100060801,"comment_content":"老师好，在运行代码之后，每一次预测都是用相同的模型和数据预测的，但是预测结果却不同，很奇怪为什么会发生这样的情况，还希望老师帮忙看一下，十分感谢<br><br>predictions = model.predict(test_dataset)<br>predictions2 = model.predict(test_dataset)<br>predictions==predictions2<br>array([[False],<br>       [False],<br>       [False],<br>       ...,<br>       [False],<br>       [False],<br>       [False]])","like_count":0},{"had_liked":false,"id":332792,"user_name":"test","can_delete":false,"product_type":"c1","uid":1065849,"ip_address":"","ucode":"9A4973E591DD12","user_header":"https://static001.geekbang.org/account/avatar/00/10/43/79/18073134.jpg","comment_is_top":false,"comment_ctime":1643611865,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1643611865","product_id":100060801,"comment_content":"老师，请问下，我训练出来后的模型，对于预测数据输出都是同一个分数，请问有可能是什么原因呢？","like_count":0},{"had_liked":false,"id":325061,"user_name":"神奇","can_delete":false,"product_type":"c1","uid":2850615,"ip_address":"","ucode":"D8345FF657FAB3","user_header":"https://static001.geekbang.org/account/avatar/00/2b/7f/37/744486bb.jpg","comment_is_top":false,"comment_ctime":1638792335,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1638792335","product_id":100060801,"comment_content":"老师，我把embedding改成了shared embeddings，就是把这一部分<br>categorical_columns = []<br>for feature, vocab in GENRE_FEATURES.items(): <br>cat_col = tf.feature_column.categorical_column_with_vocabulary_list( key=feature, vocabulary_list=vocab) <br>emb_col = tf.feature_column.embedding_column(cat_col, 10)<br>categorical_columns.append(emb_col)<br>改成了<br>categorical_columns = []<br>for feature, vocab in GENRE_FEATURES.items():<br>    cat_col = tf.feature_column.categorical_column_with_vocabulary_list(<br>        key=feature, vocabulary_list=vocab)<br>    categorical_columns.append(cat_col)<br>    <br>categorical_columns = tf.feature_column.shared_embeddings(categorical_columns, 10)<br>但是执行会有错误，这是什么原因啊","like_count":0},{"had_liked":false,"id":322363,"user_name":"m-rui","can_delete":false,"product_type":"c1","uid":2829048,"ip_address":"","ucode":"75C9CBB9580C88","user_header":"https://static001.geekbang.org/account/avatar/00/2b/2a/f8/1af3bba6.jpg","comment_is_top":false,"comment_ctime":1637319395,"is_pvip":false,"replies":[{"id":"117938","content":"新用户需要冷启动方法。主流公司肯定会至少天级别更新模型，否则效果根本上不去，在大用户量情况下，成本肯定小于收益。","user_name":"作者回复","user_name_real":"编辑","uid":"1662192","ctime":1638816309,"ip_address":"","comment_id":322363,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1637319395","product_id":100060801,"comment_content":"老师请教下，可能有点小白的问题，在这里userID这种id类的embedding，我的理解训练时候其实和线性层一样，那这样的话，对于线上来说新用户要怎样处理呢？<br><br>nlp中通常直接用一个固定的OOV代替所有新的词汇，但是推荐以及其他与用户相关的应用似乎都不能这么做，请问解决方案是什么呢？<br><br>即使是您前面提到的聚类用相似用户的embedding做用户冷启动，是不是也仍然存在需要定期重新训练全量ID类embedding的问题？那这样的话成本会不会很高，因为每天都有新用户？","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":536561,"discussion_content":"新用户需要冷启动方法。主流公司肯定会至少天级别更新模型，否则效果根本上不去，在大用户量情况下，成本肯定小于收益。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1638816309,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":310825,"user_name":"Cjw","can_delete":false,"product_type":"c1","uid":1235530,"ip_address":"","ucode":"27DB44737B9D48","user_header":"https://static001.geekbang.org/account/avatar/00/12/da/4a/b71d3f27.jpg","comment_is_top":false,"comment_ctime":1630923469,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1630923469","product_id":100060801,"comment_content":"one-hot embedding 是否可以用 labelencode + embedding实现。<br>one-hot后进入embedding，表示不同类别在embedding层的索引，<br>这样可以直接用labelencode后，一样可以在embedding层进行索引。<br>labelencode的实现比one-hot更节省时间和空间","like_count":0},{"had_liked":false,"id":310824,"user_name":"Cjw","can_delete":false,"product_type":"c1","uid":1235530,"ip_address":"","ucode":"27DB44737B9D48","user_header":"https://static001.geekbang.org/account/avatar/00/12/da/4a/b71d3f27.jpg","comment_is_top":false,"comment_ctime":1630923370,"is_pvip":false,"replies":[{"id":"113111","content":"好像不行，可以实践验证一下","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1631663066,"ip_address":"","comment_id":310824,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1630923370","product_id":100060801,"comment_content":"请问老师，one-hot + embedding 是否可以用labelencode + embedding来实现？ ","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526368,"discussion_content":"好像不行，可以实践验证一下","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631663066,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2860286,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eouDIfq73Kq7UWda6bAQ9IAFiaqQz3saRjAK9PhMeqxf7W5ZE0qTbia1B8ZG1K8RAReIjP9VIhrnONQ/132","nickname":"Geek_c26f3a","note":"","ucode":"67D252B5F60631","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":537646,"discussion_content":"感觉是可以的，labelencode将类型映射到从0开始的整数，编码后这个特征的最大值就是这个特征下不同类型的个数，然后就可以构建embedding矩阵进行查询了。 feat.vocabulary_size=labelencode[fea].max()  Embedding(vocabulary_size, embedding_dim)","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1639128587,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":308324,"user_name":"Geek_8a732a","can_delete":false,"product_type":"c1","uid":2723806,"ip_address":"","ucode":"97A312D97F7B91","user_header":"","comment_is_top":false,"comment_ctime":1629534985,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1629534985","product_id":100060801,"comment_content":"不能直接计算，因为不再同一个向量空间内","like_count":0},{"had_liked":false,"id":304328,"user_name":"Roy Liang","can_delete":false,"product_type":"c1","uid":1098898,"ip_address":"","ucode":"1DF5FC831A35DA","user_header":"https://static001.geekbang.org/account/avatar/00/10/c4/92/338b5609.jpg","comment_is_top":false,"comment_ctime":1627355072,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1627355072","product_id":100060801,"comment_content":"embedding维度10和mlp前两层128维是怎样得出的？","like_count":0},{"had_liked":false,"id":304051,"user_name":"Yang Hong","can_delete":false,"product_type":"c1","uid":2664414,"ip_address":"","ucode":"B92C87587CE9E1","user_header":"","comment_is_top":false,"comment_ctime":1627208926,"is_pvip":false,"replies":[{"id":"110048","content":"不可以这么理解。embedding_column就是一个one-hot到embedding layer的全连接层。和序列化样本没有直接关系","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1627264190,"ip_address":"","comment_id":304051,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1627208926","product_id":100060801,"comment_content":"老师，想跟您确认一下tensorflow的api：embedding_column的训练样本是类似word2vec的skip-gram模型根据item的时序生成的吗？我们在代码中对movieid，userid和genre都做了embedding，是否可以理解成tensorflow在内部根据timestamp column分别对它们排序好然后切割生成训练样本的呢？","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":523916,"discussion_content":"不可以这么理解。embedding_column就是一个one-hot到embedding layer的全连接层。和序列化样本没有直接关系","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627264190,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2664414,"avatar":"","nickname":"Yang Hong","note":"","ucode":"B92C87587CE9E1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":385858,"discussion_content":"明白了，谢谢老师。这里的embedding层是end2end训练出来的，它的标签是样本的标签，不是word2vec中通过skip- gram独立训练出来的embedding。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627302057,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":286794,"user_name":"时间选真人","can_delete":false,"product_type":"c1","uid":2475449,"ip_address":"","ucode":"DE38EAC48BE80D","user_header":"https://static001.geekbang.org/account/avatar/00/25/c5/b9/4bf9a45d.jpg","comment_is_top":false,"comment_ctime":1617599281,"is_pvip":false,"replies":[{"id":"104150","content":"后续会有涉及，这门课主要的目的就是讲清楚如何应用深度学习模型，建立工程框架。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1617643945,"ip_address":"","comment_id":286794,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1617599281","product_id":100060801,"comment_content":"通过模型的训练与评估，确定了当前模型最优参数，那么此模型该如何应用到真实的业务场景中呢，模型训练的结果在哪里，要怎么应用到推荐列表里","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":518091,"discussion_content":"后续会有涉及，这门课主要的目的就是讲清楚如何应用深度学习模型，建立工程框架。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617643945,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":283399,"user_name":"haolison","can_delete":false,"product_type":"c1","uid":1740391,"ip_address":"","ucode":"7BF883557C461A","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/60UgZMiaYPUp1xRqRuRLCclg25KuKyL81pwwj9meQwF7ribZU3t7AhxVC2AxUia4iawcsb3fuiaJJx2BsrWeYGoDERA/132","comment_is_top":false,"comment_ctime":1615766694,"is_pvip":false,"replies":[{"id":"102835","content":"数据不可能出问题，大家都正常运行，应该是pycharm或者tf，python版本的问题。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1615793937,"ip_address":"","comment_id":283399,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1615766694","product_id":100060801,"comment_content":"王老师好，用pycharm运行EmbeddingMLP.py报错<br>model.fit(train_dataset, epochs=5)<br>以上行总出问题<br>ValueError: in converted code:<br>    relative to F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column:<br><br>    feature_column_v2.py:473 call *<br>        tensor = column.get_dense_tensor(transformation_cache,<br>    feature_column_v2.py:3121 get_dense_tensor<br>        transformation_cache, state_manager)<br>    feature_column_v2.py:3710 get_sparse_tensors<br>        transformation_cache.get(self, state_manager), None)<br>    feature_column_v2.py:2562 get<br>        transformed = column.transform_feature(self, state_manager)<br>    feature_column_v2.py:3688 transform_feature<br>        return self._transform_input_tensor(input_tensor)<br>    feature_column_v2.py:3668 _transform_input_tensor<br>        prefix=&#39;column_name: {} input_tensor&#39;.format(self.key))<br>    utils.py:58 assert_string_or_int<br>        &#39;{} dtype must be string or integer. dtype: {}.&#39;.format(prefix, dtype))<br><br>    ValueError: column_name: movieGenre1 input_tensor dtype must be string or integer. dtype: &lt;dtype: &#39;float32&#39;&gt;.<br>请问是数据出了问题吗？","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":517019,"discussion_content":"数据不可能出问题，大家都正常运行，应该是pycharm或者tf，python版本的问题。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1615793937,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":277477,"user_name":"彭小鑫","can_delete":false,"product_type":"c1","uid":2407410,"ip_address":"","ucode":"9BEFBE52BC124E","user_header":"http://thirdwx.qlogo.cn/mmopen/VdM9K3h96B7usk6dk8Q2KsAJmLDuFBXKEUtcKxS2yhSt4aKgtO9FgC7ZdVztkPAT71c7vJQgafU70hvUgPXJXerJ7LIZ3Bxn/132","comment_is_top":false,"comment_ctime":1612426778,"is_pvip":false,"replies":[{"id":"100820","content":"电影品类是要做one hot encoding","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1612599841,"ip_address":"","comment_id":277477,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1612426778","product_id":100060801,"comment_content":"我们把词表做string2index的时候，这里是不是采取了比较简单的方法？因为电影品类之间是没有大小关系的，是不是最好用one-hot编码？","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":515065,"discussion_content":"电影品类是要做one hot encoding","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1612599841,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":272312,"user_name":"梁栋💝","can_delete":false,"product_type":"c1","uid":1067594,"ip_address":"","ucode":"16EEF0DD596A80","user_header":"https://static001.geekbang.org/account/avatar/00/10/4a/4a/fdae1e16.jpg","comment_is_top":false,"comment_ctime":1610028120,"is_pvip":false,"replies":[{"id":"98734","content":"就是把两个向量连接起来，这个没必要用数学公式表达，并不影响BP的过程。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1610046312,"ip_address":"","comment_id":272312,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1610028120","product_id":100060801,"comment_content":"feature_column产出的多个vector之后，进行Concatenate操作连接是否是数学公式可以表达的动作？<br>因为我理解深度模型从头到尾都是一个嵌套的数学公式，包括Concatenate自身。<br>","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":513232,"discussion_content":"就是把两个向量连接起来，这个没必要用数学公式表达，并不影响BP的过程。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1610046312,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":270426,"user_name":"A我隔壁的","can_delete":false,"product_type":"c1","uid":1159125,"ip_address":"","ucode":"0DDDE623D99AB4","user_header":"https://static001.geekbang.org/account/avatar/00/11/af/d5/1659da70.jpg","comment_is_top":false,"comment_ctime":1609124093,"is_pvip":false,"replies":[{"id":"98139","content":"不用一定是10维，理论上可以是任何你认为合适的维度。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1609200118,"ip_address":"","comment_id":270426,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1609124093","product_id":100060801,"comment_content":"为什么外面一层embeding是10维？","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":512620,"discussion_content":"不用一定是10维，理论上可以是任何你认为合适的维度。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1609200118,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":267121,"user_name":"alexliu","can_delete":false,"product_type":"c1","uid":1112019,"ip_address":"","ucode":"DD65983BBC9CD4","user_header":"https://static001.geekbang.org/account/avatar/00/10/f7/d3/2bbc62b2.jpg","comment_is_top":false,"comment_ctime":1607601866,"is_pvip":false,"replies":[{"id":"96981","content":"1. 没有太多理由，可根据你的需要任意决定长度<br>2. genre的词表一定是一样的，因为他们的来源是一样的。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1607649764,"ip_address":"","comment_id":267121,"utype":1}],"discussion_count":5,"race_medal":0,"score":"1607601866","product_id":100060801,"comment_content":"老师您好，问个小白的问题，userGenre1-userGenre5，movieGenre1-movieGenre3中的数据都是一样的：<br>1、为什么设置用户类型为5个，电影类型为3个？<br>2、为什么这些类型中的词表内容都是一样的？<br>谢谢老师~","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":511515,"discussion_content":"1. 没有太多理由，可根据你的需要任意决定长度\n2. genre的词表一定是一样的，因为他们的来源是一样的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1607649764,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":1335314,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIcIiaFaIstAv2LE4ibmWBnbe4BDIbia0Gk0S50rHWsvNpaFibkCZBKxSibOLwQERaxxwQbe7NOVicDEIfQ/132","nickname":"Geek_04f3c1","note":"","ucode":"0DB5CE69766BB7","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":534244,"discussion_content":"老师您好，整体的genre词表是一样的，但每个user、item具体关联的只有5到10个genre。这部分userGenre和itemGenre设置为一样有些不太理解，作用只是设置genre样本空间大小吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1638149047,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":511515,"ip_address":""},"score":534244,"extra":""}]},{"author":{"id":2310887,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/ibbg35VbtSTXrcBE1AWgwXAHmKBjru5HzSzEUaxiaTeahQqDVxr4ZATHibn67aanoMmT4uG34PNRv3norpmOqjwMw/132","nickname":"嘿人","note":"","ucode":"F56D9A416ED46D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":333995,"discussion_content":"我觉得应该是统计过单个用户最多喜欢的电影类型有5种，而单个电影的电影类型最多能被分为3类；类型都是这些类型，所以词表就一样囖","likes_number":4,"is_delete":false,"is_hidden":false,"ctime":1607687190,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1944884,"avatar":"","nickname":"AstrHan","note":"","ucode":"14C5F3323A472D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":342521,"discussion_content":"这5个用户类型用一个multihot表示在一起可不可以？感觉扩展性更好一些，比如有的人可能只有三个类型标签","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1610704387,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2310887,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/ibbg35VbtSTXrcBE1AWgwXAHmKBjru5HzSzEUaxiaTeahQqDVxr4ZATHibn67aanoMmT4uG34PNRv3norpmOqjwMw/132","nickname":"嘿人","note":"","ucode":"F56D9A416ED46D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":333996,"discussion_content":"如果是提前用labelencoder将这些类型进行编码，应该可以和id特征一样，利用tf.feature_column.categorical_column_with_identity来做处理吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1607687284,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":262422,"user_name":"Ho","can_delete":false,"product_type":"c1","uid":2198638,"ip_address":"","ucode":"72986244AB74C7","user_header":"https://static001.geekbang.org/account/avatar/00/21/8c/6e/057ab2ff.jpg","comment_is_top":false,"comment_ctime":1605713921,"is_pvip":false,"replies":[{"id":"95226","content":"正确","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1605746867,"ip_address":"","comment_id":262422,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1605713921","product_id":100060801,"comment_content":"不能 不在一个向量空间里","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509823,"discussion_content":"正确","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605746867,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1915541,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/3a/95/e8fc39d5.jpg","nickname":"Eayon","note":"","ucode":"9239EA2CA3D19B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":370453,"discussion_content":"同学，不在一个向量空间是什么意思，能详细说一下吗","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1619419855,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}