{"id":132598,"title":"07 | 分布式锁和原子性：你看到的未读消息提醒是真的吗？","content":"<p>你好，我是袁武林。</p><p>在前面几节课程中，我着重把即时消息场景中几个核心的特性，进行了较为详细的讲解。在实际用户场景下，除了实时性、可靠性、一致性、安全性这些刚需外，还有很多功能对用户体验的影响也是很大的，比如今天我要讲的“消息未读数”。</p><p>消息未读数对用户使用体验影响很大，这是因为“未读数”是一种强提醒方式，它通过App角标，或者App内部Tab的数字标签，来告诉用户收到了新的消息。</p><p>对于在多个社交App来回切换的重度用户来说，基本上都是靠“未读数”来获取新消息事件，如果“未读数”不准确，会对用户造成不必要的困扰。</p><p>比如，我们看到某个App有一条“未读消息提醒”，点进去事件却没有，这种情况对于“强迫症患者”实在属于不可接受；或者本来有了新的消息，但未读数错误，导致没有提醒到用户，这种情况可能会导致用户错过一些重要的消息，严重降低用户的使用体验。所以，从这里我们可以看出“消息未读数”在整个消息触达用户路径中的重要地位。</p><h2>消息和未读不一致的原因</h2><p>那么在即时消息场景中，究竟会有哪些情况导致消息和未读数出现“不一致”的情况呢？要搞清楚这个问题，我们要先了解两个涉及未读数的概念：“总未读”与“会话未读”。我们分别来看看以下两个概念。</p><!-- [[[read_end]]] --><ul>\n<li>\n<p><strong>会话未读：</strong>当前用户和某一个聊天方的未读消息数。比如用户A收到了用户B的2条消息，这时，对于用户A来说，他和用户B的会话未读就是“2”，当用户A打开和用户B的聊天对话页查看这两条消息时，对于用户A来说，他和用户B的会话未读就变成0了。对于群聊或者直播间来说也是一样的逻辑，会话未读的对端只不过是一个群或者一个房间。</p>\n</li>\n<li>\n<p><strong>总未读：</strong>当前用户的所有未读消息数，这个不难理解，总未读其实就是所有会话未读的和。比如用户A除了收到用户B的2条消息，还收到了用户C的3条消息。那么，对于用户A来说，总未读就是“5”。如果用户查看了用户B发给他的2条消息，这时用户A的总未读就变成了“3”。</p>\n</li>\n</ul><p>从上面的概念我们知道，实际上总未读数就是所有会话未读数的总和，那么，在实现上是不是只需要给每个用户维护一套会话未读就可以了呢？</p><h3>会话未读和总未读单独维护</h3><p>理论上是可以的。但在很多即时消息的“未读数”实现中，会话未读数和总未读数一般都是单独维护的。</p><p>原因在于“总未读”在很多业务场景里会被高频使用，比如每次消息推送需要把总未读带上用于角标未读展示。</p><p>另外，有些App内会通过定时轮询的方式来同步客户端和服务端的总未读数，比如微博的消息栏总未读不仅包括即时消息相关的消息数，还包括其他一些业务通知的未读数，所以通过消息推送到达后的累加来计算总未读，并不是很准确，而是换了另外一种方式，通过轮询来同步总未读。</p><p>对于高频使用的“总未读”，如果每次都通过聚合所有会话未读来获取，用户的互动会话不多的话，性能还可以保证；一旦会话数比较多，由于需要多次从存储获取，容易出现某些会话未读由于超时等原因没取到，导致总未读数计算少了。</p><p>而且，多次获取累加的操作在性能上比较容易出现瓶颈。所以，出于以上考虑，总未读数和会话未读数一般是单独维护的。</p><h3>未读数的一致性问题</h3><p>单独维护总未读和会话未读能解决总未读被“高频”访问的性能问题，但同时也会带来新的问题：未读数的一致性。</p><p>未读数一致性是指：<strong>维护的总未读数和会话未读数的总和要保持一致</strong>。如果两个未读数不能保持一致，就会出现“收到新消息，但角标和App里的消息栏没有未读提醒”，或者“有未读提醒，点进去找不到是哪个会话有新消息”的情况。</p><p>这两种异常情况都是我们不愿意看到的。那么这些异常情况究竟是怎么出现的呢？</p><p><strong>我们来看看案例，我们先来看看第一个：</strong></p><p><img src=\"https://static001.geekbang.org/resource/image/1c/c5/1c65a1af8589c1b4f6e84173c6bca1c5.png?wh=1024*768\" alt=\"\"></p><p>用户A给用户B发送消息，用户B的初始未读状态是：和用户A的会话未读是0，总未读也是0。</p><p>消息到达IM服务后，执行加未读操作：先把用户B和用户A的会话未读加1，再把用户B的总未读加1。</p><p>假设加未读操作第一步成功了，第二步失败。最后IM服务把消息推送给用户B。这个时候用户B的未读状态是：和用户A的会话未读是1，总未读是0。</p><p>这样，由于加未读第二步执行失败导致的后果是：用户B不知道收到了一条新消息的情况，从而可能漏掉查看这条消息。</p><p>那么案例是由于在加未读的第二步“加总未读”的时候出现异常，导致未读和消息不一致的情况。</p><p>那么，是不是只要加未读操作都正常执行就没有问题了呢？<strong>接下来，我们再看下第二个案例。</strong></p><p><img src=\"https://static001.geekbang.org/resource/image/fa/42/fa303ab3ddf0aba4baf2e0630a8a5542.png?wh=1024*768\" alt=\"\"></p><p>用户A给用户B发送消息，用户B的初始未读状态是：和用户A的会话未读是0，总未读也是0。</p><p>消息到达IM服务后，执行加未读操作：先执行加未读的第一步，把用户B和用户A的会话未读加1。</p><p>这时执行加未读操作的服务器由于某些原因变慢了，恰好这时用户B在App上点击查看和用户A的聊天会话，从而触发了清未读操作。</p><p>执行清未读第一步，把用户B和用户A的会话未读清0，然后继续执行清未读第二步，把用户B的总未读也清0。</p><p>清未读的操作都执行完之后，执行加未读操作的服务器才继续恢复执行加未读的第二步，把用户B的总未读加1，那么这个时候就出现了两个未读不一致的情况。</p><p>导致的后果是：用户B退出会话后，看到有一条未读消息，但是点进去却找不到是哪个聊天会话有未读消息。</p><p><strong>这里，我来分析一下这两种不一致的案例原因：其实都是因为两个未读的变更不是原子性的，会出现某一个成功另一个失败的情况，也会出现由于并发更新导致操作被覆盖的情况。所以要解决这些问题，需要保证两个未读更新操作的原子性。</strong></p><h2>保证未读更新的原子性</h2><p>那么，在分布式场景下，如何保证两个未读的“原子更新”呢？一个比较常见的方案是使用一个分布式锁来解决，每次修改前先加锁，都变更完后再解开。</p><h3>分布式锁</h3><p>分布式锁的实现有很多，比如，依赖DB的唯一性、约束来通过某一条固定记录的插入成功与否，来判断锁的获取。也可以通过一些分布式缓存来实现，比如MC的add、比如Redis的setNX等。具体实现机制，我这里就不细讲了，在我们的实战课程中，我们会有相应的代码体现。</p><p>不过，要注意的是，分布式锁也存在它自己的问题。由于需要增加一套新的资源访问逻辑，锁的引入会降低吞吐；同时对锁的管理和异常的处理容易出现Bug，比如需要资源的单点问题、需要考虑宕机情况下如何保证锁最终能释放。</p><h3>支持事务功能的资源</h3><p>除了分布式锁外，还可以通过一些支持事务功能的资源，来保证两个未读的更新原子性。</p><p>事务提供了一种“将多个命令打包，然后一次性按顺序地执行”的机制，并且事务在执行的期间不会主动中断，服务器在执行完事务中的所有命令之后，才会继续处理其他客户端的其他命令。</p><p>比如：Redis通过 MULTI、DISCARD 、EXEC和WATCH四个命令来支持事务操作。</p><p>比如每次变更未读前先watch要修改的key，然后事务执行变更会话未读和变更总未读的操作，如果在最终执行事务时被watch的两个未读的key的值已经被修改过，那么本次事务会失败，业务层还可以继续重试直到事务变更成功。</p><p>依托Redis这种支持事务功能的资源，如果未读数本身就存在这个资源里，是能比较简单地做到两个未读数“原子变更”的。</p><p>但这个方案在性能上还是存在一定的问题，由于watch操作实际是一个乐观锁策略，对于未读变更较频繁的场景下（比如一个很火的群里大家发言很频繁），可能需要多次重试才可以最终执行成功，这种情况下执行效率低，性能上也会比较差。</p><h3>原子化嵌入脚本</h3><p>那么有没有性能不错还能支持“原子变更”的方案呢？</p><p>其实在很多资源的特性中，都支持“原子化的嵌入脚本”来满足业务上对多条记录变更高一致性的需求。Redis就支持通过嵌入Lua脚本来原子化执行多条语句，利用这个特性，我们就可以在Lua脚本中实现总未读和会话未读的原子化变更，而且还能实现一些比较复杂的未读变更逻辑。</p><p>比如，有的未读数我们不希望一直存在而干扰到用户，如果用户7天没有查看清除未读，这个未读可以过期失效，这种业务逻辑就比较方便地使用Lua脚本来实现“读时判断过期并清除”。</p><p>原子化嵌入脚本不仅可以在实现复杂业务逻辑的基础上，来提供原子化的保障，相对于前面分布式锁和watch事务的方案，在执行性能上也更胜一筹。</p><p>不过这里要注意的是，由于Redis本身是服务端单线程模型，Lua脚本中尽量不要有远程访问和其他耗时的操作，以免长时间悬挂（Hang）住，导致整个资源不可用。</p><h2>小结</h2><p>本节课我们先了解了未读数在即时消息场景中的重要性，然后分析了造成未读数和消息不一致的原因，原因主要在于：“总未读数”和“会话未读数”在大部分业务场景中需要能够独立维护，但两个未读数的变更存在成功率不一致和并发场景下互相覆盖的情况。</p><p>接下来我们探讨了几种保证未读数原子化变更的方案，以及深入分析了每种方案各自的优劣，三种方案分别为：</p><ul>\n<li><strong>分布式锁</strong>，具备较好普适性，但执行效率较差，锁的管理也比较复杂，适用于较小规模的即时消息场景；</li>\n<li><strong>支持事务功能的资源</strong>，不需要额外的维护锁的资源，实现较为简单，但基于乐观锁的watch机制在较高并发场景下失败率较高，执行效率比较容易出现瓶颈；</li>\n<li><strong>原子化嵌入脚本</strong>，不需要额外的维护锁的资源，高并发场景下性能也较好，嵌入脚本的开发需要一些额外的学习成本。</li>\n</ul><p>这一篇我们讲到的内容，简单来看只是消息未读数不一致的场景，但是，如果我们站在宏观视角下，不难看出在分布式场景下，这其实是一个并发更新的问题。</p><p>不管是分布式锁、还是支持事务功能的资源，以及我们最后讲到的原子化的嵌入脚本，其实不仅仅可以用来解决未读数的问题，对于通用的分布式场景下涉及的需要保证多个操作的原子性或者事务性的时候，这些都是可以作为可选方案来考虑的。</p><p>最后给你留一个思考题：<strong>类似Redis+Lua的原子化嵌入脚本的方式，是否真的能够做到“万无一失”的变更一致性？比如，执行过程中机器掉电会出现问题吗？</strong></p><p>你可以给我留言，我们一起讨论，感谢你的收听，我们下次再见。</p>","neighbors":{"left":{"article_title":"06 | HttpDNS和TLS：你的消息聊天真的安全吗？","id":132434},"right":{"article_title":"08 | 智能心跳机制：解决网络的不确定性","id":134231}},"comments":[{"had_liked":false,"id":137256,"user_name":"Darcy","can_delete":false,"product_type":"c1","uid":1677627,"ip_address":"","ucode":"3A78522A550376","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/0wpUDw5m0LRvdDueia3uMWqKbTXqNJwYQjwXWN9dC2LLdKpbib98knPlWOQROslLPN11bvqLI1BicdFwoGiaSRLaMA/132","comment_is_top":false,"comment_ctime":1569669477,"is_pvip":false,"replies":[{"id":"52865","content":"是的，对于需要使用lua的数据需要确保两个key能hash到一个节点。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1569806180,"ip_address":"","comment_id":137256,"utype":1}],"discussion_count":2,"race_medal":0,"score":"78879080805","product_id":100034901,"comment_content":"redis cluster集群模式lua脚本如果操作的两个key不在同一个节点，好像会报异常","like_count":18,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":469001,"discussion_content":"是的，对于需要使用lua的数据需要确保两个key能hash到一个节点。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1569806180,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1220552,"avatar":"https://static001.geekbang.org/account/avatar/00/12/9f/c8/0318c83e.jpg","nickname":"Geek_b617bf","note":"","ucode":"9BAFC3B184B1D2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":274326,"discussion_content":"可以采用{}的方式包裹key，{}里的内容一样的key会落在同一个节点上","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1590568510,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":132901,"user_name":"王棕生","can_delete":false,"product_type":"c1","uid":1337944,"ip_address":"","ucode":"901BD0447A871E","user_header":"https://static001.geekbang.org/account/avatar/00/14/6a/58/f2c6d65b.jpg","comment_is_top":false,"comment_ctime":1568266717,"is_pvip":false,"replies":[{"id":"50940","content":"思路是好的哈，不过很多时候不仅仅是用户登录的时候才需要总未读，比如每来一条消息需要进行系统推送时，由于苹果的APNs不支持角标未读的累加，只能每次获取总未读带下去。另外，客户端维护总未读这个也需要考虑比如离线消息太多，需要推拉结合获取时，到达客户端的消息数不一定是真正的未读消息数。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1568288274,"ip_address":"","comment_id":132901,"utype":1}],"discussion_count":1,"race_medal":0,"score":"61697808861","product_id":100034901,"comment_content":"对于老师本节讲述的未读数不一致的问题，我想是否可以通过下面的方法来解决：<br>1  用户的未读数是在用户离线的时候，其他用户给他发消息的时候产生的，所以，只需要维护用户会话未读数即可；<br>2  当用户登录的时候，发送一个消息到MQ，由MQ触发维护用户总的未读数的操作，即将用户所有的会话未读数相加后的数值放入总未读数字段中。<br>      这样的设计的好处时，降低维护用户总未读数的压力，只在用户登录的时候进行维护即可，不用每次收到一条消息就维护一次。<br>      然后用户在线期间，收到的消息的未读数由前端来进行维护，不用服务端进行操作了。","like_count":14,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":467167,"discussion_content":"思路是好的哈，不过很多时候不仅仅是用户登录的时候才需要总未读，比如每来一条消息需要进行系统推送时，由于苹果的APNs不支持角标未读的累加，只能每次获取总未读带下去。另外，客户端维护总未读这个也需要考虑比如离线消息太多，需要推拉结合获取时，到达客户端的消息数不一定是真正的未读消息数。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1568288274,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":132488,"user_name":"leslie","can_delete":false,"product_type":"c1","uid":1324255,"ip_address":"","ucode":"798E7C1CC98CC2","user_header":"https://static001.geekbang.org/account/avatar/00/14/34/df/64e3d533.jpg","comment_is_top":false,"comment_ctime":1568137217,"is_pvip":false,"replies":[{"id":"50849","content":"没关系哈，互相探讨的过程希望大家不要拘谨。正如你所说，redis在执行lua脚本过程中如果发生掉电，是可能会导致两个未读不一致的，因为lua脚本在redis中的执行只能保证多条命令会原子执行，整体执行完成才会同步给从库并写入aof，所以如果执行过程中掉电，会直接导致被中断的后面部分的脚本得不到执行。当然， 实际情况中这种概率非常小。作为兜底的方案，可以在未读变更时如果会话比较少，可以获取一次全量的会话未读来覆盖总未读，从而有机会能得到最终一致。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1568200012,"ip_address":"","comment_id":132488,"utype":1}],"discussion_count":1,"race_medal":0,"score":"40222842881","product_id":100034901,"comment_content":"      Redis不是特别熟悉：其实老师今天的问题和另外一个问题有点类似；既然问题是&quot;执行过程中掉电是否会出现问题&quot;这个极端场景：那么我就用极端场景解释，老师看看是否有理或者可能啊。<br>      我的答案是会：尤其是极端场景下会，虽然概念很小；其实老师今天的问题是李玥老师的消息队列课程中前几天的期中考题，&quot;数据写入PageCache后未做刷盘，那种情况下数据会丢失“当时的答案就是断电。<br>     其实老师在提掉电时：未提及一个前提条件；掉电后硬件是否正常？如果掉电后硬件损坏了呢，那么数据肯定就丢失了，线上最新的数据都没了，数据肯定就丢了。因为问题是极端场景，回答就只能是极端场景，希望老师不介意；这就像云服务器厂商几乎都会某个区域出现一次事故，Amaze云已经连续多年有次事情，异地灾备做的好当然不受影响；一旦异地灾备没做直接的后果就是数据丢失，这种事情相信老师自己同样听到同行提及或者转载过。<br>   故而这道题目的现实场景非常重要：Redis的异地多副本做了-可能不会；多副本没做且硬件刚好因为掉电导致出现了无法恢复的损坏-肯定丢失。谢谢老师的分享。","like_count":9,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":466967,"discussion_content":"没关系哈，互相探讨的过程希望大家不要拘谨。正如你所说，redis在执行lua脚本过程中如果发生掉电，是可能会导致两个未读不一致的，因为lua脚本在redis中的执行只能保证多条命令会原子执行，整体执行完成才会同步给从库并写入aof，所以如果执行过程中掉电，会直接导致被中断的后面部分的脚本得不到执行。当然， 实际情况中这种概率非常小。作为兜底的方案，可以在未读变更时如果会话比较少，可以获取一次全量的会话未读来覆盖总未读，从而有机会能得到最终一致。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1568200012,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":132512,"user_name":"钢","can_delete":false,"product_type":"c1","uid":1106184,"ip_address":"","ucode":"A49848BF63A579","user_header":"https://static001.geekbang.org/account/avatar/00/10/e1/08/3dc76043.jpg","comment_is_top":false,"comment_ctime":1568159319,"is_pvip":false,"replies":[{"id":"50850","content":"示例挺多的哈，给一个redis官网的例子：<br><br>local current<br>current = redis.call(&quot;incr&quot;,KEYS[1])<br>if tonumber(current) == 1 then<br>    redis.call(&quot;expire&quot;,KEYS[1],1)<br>end<br>","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1568200456,"ip_address":"","comment_id":132512,"utype":1}],"discussion_count":1,"race_medal":0,"score":"31632930391","product_id":100034901,"comment_content":"原子化嵌入式脚本有例子介绍吗","like_count":8,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":466982,"discussion_content":"示例挺多的哈，给一个redis官网的例子：\n\nlocal current\ncurrent = redis.call(&amp;quot;incr&amp;quot;,KEYS[1])\nif tonumber(current) == 1 then\n    redis.call(&amp;quot;expire&amp;quot;,KEYS[1],1)\nend\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1568200456,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":132682,"user_name":"romantic_PK","can_delete":false,"product_type":"c1","uid":1645099,"ip_address":"","ucode":"F2F0113F98F5E0","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/9X0Joj8QFUYwYKfCFGsgGdkDtXibBF5kOyTRsb1HWRyAm11vYVUvEl17ibgMOomSicNg5lLeLRFzINFZTvo3Wh9rA/132","comment_is_top":false,"comment_ctime":1568191096,"is_pvip":false,"replies":[{"id":"50856","content":"这个应该是客户端逻辑哈，点击未读数实际上是把最新的一条消息id带进去了，端上在已有的消息里查询这条消息就可以了。这也是为什么最近联系人需要带上最新的一条消息了。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1568201371,"ip_address":"","comment_id":132682,"utype":1}],"discussion_count":3,"race_medal":0,"score":"10158125688","product_id":100034901,"comment_content":"老师你好，我想请教一个问题，如何实现微信打开聊天窗口后，点击未读数定位到第一条未读消息的位置，请指点迷津，谢谢。","like_count":2,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":467067,"discussion_content":"这个应该是客户端逻辑哈，点击未读数实际上是把最新的一条消息id带进去了，端上在已有的消息里查询这条消息就可以了。这也是为什么最近联系人需要带上最新的一条消息了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1568201371,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1005030,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/55/e6/87197b10.jpg","nickname":"GeekAmI","note":"","ucode":"232C0B6DFB9F56","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":24240,"discussion_content":"同问，这个回答我也没看懂","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570068699,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1111899,"avatar":"https://static001.geekbang.org/account/avatar/00/10/f7/5b/d2e7c2c4.jpg","nickname":"时隐时现","note":"","ucode":"DA4D622FF84920","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":23028,"discussion_content":"&#34;把最新的一条消息id带进去了&#34;有点没理解，是找到最老的一条未读信息的位置，为何要用最新的1条消息ID，应该是最老的未读消息ID吧？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1569743683,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":138232,"user_name":"null","can_delete":false,"product_type":"c1","uid":1024294,"ip_address":"","ucode":"F9039EFED6B55D","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaELZPnUAiajaR5C25EDLWeJURggyiaOP5GGPe2qlwpQcm5e3ybib8OsP4tvddFDLVRSNNGL5I3SFPJHsA/132","comment_is_top":false,"comment_ctime":1570109832,"is_pvip":false,"replies":[{"id":"53276","content":"1. 其实就是有一些纳入到总未读里的消息不一定会进行消息下推。<br>客户端统计总未读的情况如果是需要多终端同步或者离线消息下推采用推拉结合的，不一定会话会话就是全量的，这种情况计算总未读就会有误差。<br>2. 不需要这个前提，理论上只需要会话未读就可以保证准确，增加总未读是为了提升读取性能。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1570275292,"ip_address":"","comment_id":138232,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5865077128","product_id":100034901,"comment_content":"老师您好，有几个问题，请教一下。<br><br>re：比如微博的消息栏总未读不仅包括即时消息相关的消息数，还包括其他一些业务通知的未读数，所以通过消息推送到达后的累加来计算总未读，并不是很准确，而是换了另外一种方式，通过轮询来同步总未读。<br><br>没太理解上面这一小段：<br>1. 为什么通过消息推送到达，（谁？）累加计算未读数，不是很准确？能举个例子么？<br><br>文章提到，服务端聚合所有会话未读数，得到总未读数，存在不准确的问题，如获取某个会话未读数失败时。<br><br>但是在客户端统计总未读数，这时客户端的会话未读数，不应该是准确的么，从而所统计的总未读数，也是准确的？<br><br>2. 为啥通过轮询来同步总未读是准确的？这个准确，是否需要一个前提：会话未读和总未读，在服务端单独维护？","like_count":1,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":469445,"discussion_content":"1. 其实就是有一些纳入到总未读里的消息不一定会进行消息下推。\n客户端统计总未读的情况如果是需要多终端同步或者离线消息下推采用推拉结合的，不一定会话会话就是全量的，这种情况计算总未读就会有误差。\n2. 不需要这个前提，理论上只需要会话未读就可以保证准确，增加总未读是为了提升读取性能。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570275292,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":132681,"user_name":"小祺","can_delete":false,"product_type":"c1","uid":1193548,"ip_address":"","ucode":"2819BCA9E71C9F","user_header":"https://static001.geekbang.org/account/avatar/00/12/36/4c/46c43cce.jpg","comment_is_top":false,"comment_ctime":1568190801,"is_pvip":false,"replies":[{"id":"50855","content":"分布式锁需要能拿到锁就能保证同一时间只有拿到锁的进程才行执行操作，因为会话未读和总未读变更是在一个进程里，所以理论上是可以保证原子性的。但如果像你所说，第二条加未读的命令一直执行失败还是会出现不一致的情况，这种情况一个是重试，另外就是回滚第一个操作。<br><br>lua脚本这个可以考虑在脚本中增加一些修复机制，比如会话数比较少的情况下聚合一次未读来覆盖总未读。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1568201275,"ip_address":"","comment_id":132681,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5863158097","product_id":100034901,"comment_content":"首先，如果修改“会话未读数“和“总未读数”是放在一个数据库事务中肯定是可以保证原子性的，但是数据库没法满足高并发的需求，所以通常可以使用Redis来解决高并发问题，为了保证Redis多条命令的原子性老师给出了3个方案。<br>分布式锁：我认为分布式锁只能解决并发问题，因为第一条命令成功第二条命令失败的情况依然可能发生，怎么办呢？只能不断的重试第二条命令吗？<br>watch机制：与分布式锁有想同的问题<br>lua脚本机制：确实是原子操作没有问题，但是由于redis主从异步同步，掉电时slave在没同步到最新数据的情况下提升为master，客户端就可能读到错误的未读数。有什么解决方案吗？<br>请老师分别解答一下","like_count":1,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":467066,"discussion_content":"分布式锁需要能拿到锁就能保证同一时间只有拿到锁的进程才行执行操作，因为会话未读和总未读变更是在一个进程里，所以理论上是可以保证原子性的。但如果像你所说，第二条加未读的命令一直执行失败还是会出现不一致的情况，这种情况一个是重试，另外就是回滚第一个操作。\n\nlua脚本这个可以考虑在脚本中增加一些修复机制，比如会话数比较少的情况下聚合一次未读来覆盖总未读。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1568201275,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":132554,"user_name":"大魔王汪汪","can_delete":false,"product_type":"c1","uid":1010680,"ip_address":"","ucode":"4B205CB52FC95F","user_header":"https://static001.geekbang.org/account/avatar/00/0f/6b/f8/b4da7936.jpg","comment_is_top":false,"comment_ctime":1568165302,"is_pvip":false,"replies":[{"id":"50852","content":"buffer缓冲和强一致性本身就是两个比较对立的概念，所以要做到既能缓冲请求频率又保证强一致性是比较困难的。如果可以的话，尽量让不容易宕机的一方来进行buffer缓冲，比如：如果是客户端和服务端都能缓冲，那还是让服务端来缓冲可能比较可靠一些。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1568200731,"ip_address":"","comment_id":132554,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5863132598","product_id":100034901,"comment_content":"老师请教个问题，针对于高频修改场景，频繁的一个字段状态变更，为了解决一个操作一次请求的问题可以采用客户端缓存一段时间聊天记录，批量发送，或者服务端分区批量发送以减少网络io或者db压力，但是两者都存在因为crash造成消息丢失的问题，请问这种情况有什么比较好的解决吗🙏","like_count":1,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":467005,"discussion_content":"buffer缓冲和强一致性本身就是两个比较对立的概念，所以要做到既能缓冲请求频率又保证强一致性是比较困难的。如果可以的话，尽量让不容易宕机的一方来进行buffer缓冲，比如：如果是客户端和服务端都能缓冲，那还是让服务端来缓冲可能比较可靠一些。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1568200731,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":351843,"user_name":"薛建辉","can_delete":false,"product_type":"c1","uid":1165917,"ip_address":"","ucode":"17928DD8497E9C","user_header":"https://static001.geekbang.org/account/avatar/00/11/ca/5d/c35b117c.jpg","comment_is_top":false,"comment_ctime":1658224884,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1658224884","product_id":100034901,"comment_content":"关于三种原子化方案，请教下老师，主流大厂是使用哪种？谢谢。","like_count":0},{"had_liked":false,"id":320046,"user_name":"Geek_LeonSZ","can_delete":false,"product_type":"c1","uid":1904472,"ip_address":"","ucode":"1C748B3A09CD9B","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/edMMg8wmu2RRIFVw2UgAytIx7Yjmx3z2sX1Apc3DfX423dIpyKO6Kg2y65bjPF2jRZVt16AbfYS74A6BAWDJGQ/132","comment_is_top":false,"comment_ctime":1636056731,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1636056731","product_id":100034901,"comment_content":"麻烦问一下未读数是怎么存储的? 第一节课讲了三个表, 好像之后数据是怎么存储的, 存在database, 还是in-memory cache, 等等的, 就没有再涉及到了.","like_count":0},{"had_liked":false,"id":274009,"user_name":"滩涂曳尾","can_delete":false,"product_type":"c1","uid":1187478,"ip_address":"","ucode":"40F650F2A419D4","user_header":"https://static001.geekbang.org/account/avatar/00/12/1e/96/c735ad6b.jpg","comment_is_top":false,"comment_ctime":1610787604,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1610787604","product_id":100034901,"comment_content":"请问老师，未读数为啥不在app本地保存呢，而是要服务端维护？我能想到的一个场景是，服务端维护可以支持多终端登录后知道用户读取的状态，以及离线推送啥的，可以详细说说有哪些场景吗","like_count":0},{"had_liked":false,"id":233680,"user_name":"慎独明强","can_delete":false,"product_type":"c1","uid":1965699,"ip_address":"","ucode":"DC2F7F2C0C8F60","user_header":"https://static001.geekbang.org/account/avatar/00/1d/fe/83/df562574.jpg","comment_is_top":false,"comment_ctime":1594384617,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1594384617","product_id":100034901,"comment_content":"既然不能保证事务的强一致性，那么就保证事务的最终一致性","like_count":0},{"had_liked":false,"id":221109,"user_name":"Alice","can_delete":false,"product_type":"c1","uid":1069156,"ip_address":"","ucode":"4ACF5F78AC75AE","user_header":"https://static001.geekbang.org/account/avatar/00/10/50/64/112b28bc.jpg","comment_is_top":false,"comment_ctime":1590407470,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1590407470","product_id":100034901,"comment_content":"使用lua的数据需要确保两个key能hash到一个分片。那么如何将会话未读数和总未读数一起更新？会话未读数和总未读数没办法使用同一个category来保存吧","like_count":0,"discussions":[{"author":{"id":1024994,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/a3/e2/5cb4f43f.jpg","nickname":"laolinshi","note":"","ucode":"269B879389D7D5","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":558637,"discussion_content":"可以考虑用redis的哈希表来保存会话未读数和总未读数，实现方式可以是: 哈希表通过用户ID来获取，哈希表中的item使用不同的key值来区分是总未读还是各个用户发送来的未读消息，比如使用 key为-1表示总未读数，key为用户ID表示这个用户发送过来的未读消息数。通过这样的实现方式让可以让key都在同一个分片。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1648429442,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":215399,"user_name":"mickey","can_delete":false,"product_type":"c1","uid":1051663,"ip_address":"","ucode":"8B490C2DDE4010","user_header":"https://static001.geekbang.org/account/avatar/00/10/0c/0f/93d1c8eb.jpg","comment_is_top":false,"comment_ctime":1588986713,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1588986713","product_id":100034901,"comment_content":"在案例2中，为什么用户B查看了用户A的会话后，会将自己的总读数清零呢？","like_count":0},{"had_liked":false,"id":214843,"user_name":"piboye","can_delete":false,"product_type":"c1","uid":1066752,"ip_address":"","ucode":"7CFD8712857A85","user_header":"https://static001.geekbang.org/account/avatar/00/10/47/00/3202bdf0.jpg","comment_is_top":false,"comment_ctime":1588830227,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1588830227","product_id":100034901,"comment_content":"未读数最难的地方是在离线推送的时候，客户端的显示可以客户端维持。那么离线推送的时候，其实更怕计数器的误差累计，我的解决方案是，保存两个计数器，一个是客户端确认的未读数和确认到的消息id，一个是服务端从客户端的msgid到最近的msgid之间的新增未读数和消息id。","like_count":0},{"had_liked":false,"id":158465,"user_name":"分清云淡","can_delete":false,"product_type":"c1","uid":1269873,"ip_address":"","ucode":"7045AE6BF72D31","user_header":"https://static001.geekbang.org/account/avatar/00/13/60/71/895ee6cf.jpg","comment_is_top":false,"comment_ctime":1575377955,"is_pvip":false,"replies":[{"id":"60944","content":"对于点对点聊天，直接通过p2p的方式不经过服务端来收发消息是可行的，市面上较早就已经有类似的软件了。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1575627139,"ip_address":"","comment_id":158465,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1575377955","product_id":100034901,"comment_content":"p2p的方式可以用来同步消息么？","like_count":0,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":476737,"discussion_content":"对于点对点聊天，直接通过p2p的方式不经过服务端来收发消息是可行的，市面上较早就已经有类似的软件了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1575627139,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":146681,"user_name":"郑印","can_delete":false,"product_type":"c1","uid":1005282,"ip_address":"","ucode":"181B0FDE5E1532","user_header":"https://static001.geekbang.org/account/avatar/00/0f/56/e2/2dcab30d.jpg","comment_is_top":false,"comment_ctime":1572602806,"is_pvip":false,"replies":[{"id":"57189","content":"未读数这个实际上访问量不大的话实现会灵活很多，上面这种实现实际上得看消息ID是否需要用到，不需要的话不用存储消息ID，否则对存储是一种浪费；另外会话未读的获取并发大的时候hgetall性能也是一个问题。具体看业务上是否够用哈","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1573034385,"ip_address":"","comment_id":146681,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1572602806","product_id":100034901,"comment_content":"这部分在我们的消息系统中设计的时候是使用Redis hash 来实现的<br>结构如下：<br>UNREAD_${userId}  messageId contactId<br><br>写入未读：<br>hset  UNREAD_${userId}  messageId contactId <br>获取总的未读数<br>hlen UNREAD_${userId} <br>获取会话的未读数,取出所有的未读消息，然后在程序里进行过滤，类似下面的代码<br><br>            getUnreadMessages(userId)<br>                    .values()<br>                    .stream()<br>                    .filter(v -&gt; v == contactId)<br>                    .count();<br><br>这样实现不用能够平衡两者的读取，也不用使用原子操作，目前已知的问题是当某个用户的未读数多一会，在获取会话的未读数时，会比较慢，但是获取会话未读不是高频操作，且这样的用户基本属于长时间不使用才会导致未读数堆积。 目前这样的方式，不知道有没什么考虑不足的？","like_count":0,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":472972,"discussion_content":"未读数这个实际上访问量不大的话实现会灵活很多，上面这种实现实际上得看消息ID是否需要用到，不需要的话不用存储消息ID，否则对存储是一种浪费；另外会话未读的获取并发大的时候hgetall性能也是一个问题。具体看业务上是否够用哈","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1573034385,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":138519,"user_name":"GeekAmI","can_delete":false,"product_type":"c1","uid":1005030,"ip_address":"","ucode":"232C0B6DFB9F56","user_header":"https://static001.geekbang.org/account/avatar/00/0f/55/e6/87197b10.jpg","comment_is_top":false,"comment_ctime":1570288899,"is_pvip":false,"replies":[{"id":"53730","content":"这个看场景吧，一般支持多终端消息同步的话建议采用推拉结合的方式，因为消息会在服务端存储，按会话维度拉取也比较方便。另外，第二个问题，一般点未读是直接展示最新的消息呀，不会跳到最旧的。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1570625375,"ip_address":"","comment_id":138519,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1570288899","product_id":100034901,"comment_content":"老师您好，再请教下，假如一个用户的离线消息非常多比如说一万条，那么等用户上线的时候是全量同步到本地呢（类似微信）还是说只同步一部分消息剩下的等用户下拉的时候再懒加载比较老的消息呢（类似QQ）？ 如果使用后者的话，当用户点击聊天对话框的未读数字时需要立即锚点到最老的那个未读消息，这个是怎么做到的呢","like_count":0,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":469553,"discussion_content":"这个看场景吧，一般支持多终端消息同步的话建议采用推拉结合的方式，因为消息会在服务端存储，按会话维度拉取也比较方便。另外，第二个问题，一般点未读是直接展示最新的消息呀，不会跳到最旧的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570625375,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":138346,"user_name":"怡红公子","can_delete":false,"product_type":"c1","uid":1679704,"ip_address":"","ucode":"2F97155A0C3C2C","user_header":"","comment_is_top":false,"comment_ctime":1570174939,"is_pvip":false,"replies":[{"id":"53286","content":"服务端接收到查看会话的请求时，除了返回会话内容，还会在服务端进行未读清理。另外课程中说的离线消息下推是指用户由断连再重新上线后的过程，不是指用户网络离线。所以收到离线消息并不会清未读。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1570278177,"ip_address":"","comment_id":138346,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1570174939","product_id":100034901,"comment_content":"老师我有疑问，会话未读和消息总未读由服务端存储的，那么在客户端收到离线推送过程之后，并没有在线查看相关消息内容，而在离线条件下查看相关会话，此时会话未读更新是不是仅仅是客户端的逻辑，不需要客户端发送信令到服务端？还是说，服务端只负责将离线消息成功推给客户端后，就将相关会话和总未读清零了？这样的话客户端和服务端是不是需要有各自的会话未读管理啊？而且两者不是在一个纬度上的。服务端的会话未读管理是离线过程中新消息条数，客户端的会话管理，是新消息是否查看？还请老师解答一下，自己想有点乱套了","like_count":0,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":469495,"discussion_content":"服务端接收到查看会话的请求时，除了返回会话内容，还会在服务端进行未读清理。另外课程中说的离线消息下推是指用户由断连再重新上线后的过程，不是指用户网络离线。所以收到离线消息并不会清未读。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570278177,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":138171,"user_name":"GeekAmI","can_delete":false,"product_type":"c1","uid":1005030,"ip_address":"","ucode":"232C0B6DFB9F56","user_header":"https://static001.geekbang.org/account/avatar/00/0f/55/e6/87197b10.jpg","comment_is_top":false,"comment_ctime":1570074869,"is_pvip":false,"replies":[{"id":"53273","content":"跟着消息带下去，或者建连后从服务端同步一次然后端上通过接收的消息进行本地累加。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1570274227,"ip_address":"","comment_id":138171,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1570074869","product_id":100034901,"comment_content":"老师您好，请问下会话里的未读数怎么同步给客户端的？","like_count":0,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":469422,"discussion_content":"跟着消息带下去，或者建连后从服务端同步一次然后端上通过接收的消息进行本地累加。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570274227,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":137895,"user_name":"盘尼西林","can_delete":false,"product_type":"c1","uid":1197347,"ip_address":"","ucode":"B59569FC25144F","user_header":"https://static001.geekbang.org/account/avatar/00/12/45/23/28311447.jpg","comment_is_top":false,"comment_ctime":1569908387,"is_pvip":false,"replies":[{"id":"53265","content":"是的，redis的事务实际上需要使用方自行处理失败的后续操作。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1570270669,"ip_address":"","comment_id":137895,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1569908387","product_id":100034901,"comment_content":"redis 的multi 多条操作，前面几条操作成功，最后一条失败，无法做已经执行成功语句的 回滚。比如<br>127.0.0.1:6379&gt; get locked<br>&quot;1&quot;<br>127.0.0.1:6379&gt; watch locked<br>OK<br>127.0.0.1:6379&gt; multi<br>OK<br>127.0.0.1:6379&gt; incr locked<br>QUEUED<br>127.0.0.1:6379&gt; lpop list_key<br>QUEUED<br>127.0.0.1:6379&gt; incr locked<br>QUEUED<br>127.0.0.1:6379&gt; exec<br>1) (integer) 2<br>2) (nil)<br>3) (integer) 3<br>127.0.0.1:6379&gt; get locked<br>&quot;3&quot;<br>上面的语句 incr 会执行成功，但是lpop 是失败的<br>","like_count":0,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":469297,"discussion_content":"是的，redis的事务实际上需要使用方自行处理失败的后续操作。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570270669,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":137844,"user_name":"天天向上","can_delete":false,"product_type":"c1","uid":1168220,"ip_address":"","ucode":"DF08B67EAD61E7","user_header":"https://static001.geekbang.org/account/avatar/00/11/d3/5c/796962de.jpg","comment_is_top":false,"comment_ctime":1569893841,"is_pvip":false,"replies":[{"id":"53266","content":"是的，redis嵌入的lua脚本是会原子化执行的。具体使用可以参考redis官网示例。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1570270767,"ip_address":"","comment_id":137844,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1569893841","product_id":100034901,"comment_content":"请问，redis嵌入的lua脚本都是原子化执行的吗？<br>还是有特殊的声明，或则什么语法结构？","like_count":0,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":469285,"discussion_content":"是的，redis嵌入的lua脚本是会原子化执行的。具体使用可以参考redis官网示例。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570270767,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":136257,"user_name":"天天平安","can_delete":false,"product_type":"c1","uid":1119208,"ip_address":"","ucode":"C4850F9655F4DD","user_header":"https://static001.geekbang.org/account/avatar/00/11/13/e8/08b829a9.jpg","comment_is_top":false,"comment_ctime":1569398585,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1569398585","product_id":100034901,"comment_content":"我想在自己的app中直接引用收费的聊天产品，老师推荐用哪个比较好？","like_count":0},{"had_liked":false,"id":134553,"user_name":"qijj","can_delete":false,"product_type":"c1","uid":1231369,"ip_address":"","ucode":"AAE7BAD5DABEE2","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLLn1y9RSL9JcACGRVkkhkEmjH7z1eiag763CVKwn3Mzb3djbibwbx0fgZqyBpPozGLOicnllSfydEng/132","comment_is_top":false,"comment_ctime":1568864407,"is_pvip":false,"replies":[{"id":"51592","content":"对于群聊业务来说，由于消息扇出问题，一般处理上和点对点聊天不太一样。群聊消息一般采用”读扩散“的方式，一个群的消息只会记录一份，这个群里的每个用户在需要查看数据的时候都从会获取这个群的消息记录。未读数是每一个用户单独一份的，和消息不一样。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1568877629,"ip_address":"","comment_id":134553,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1568864407","product_id":100034901,"comment_content":"老师，群聊的未读消息业务应该如何设计，在数据库表设计时建立一个关系表，一条消息和群聊中的每个人的对应关系都存入这表，是不是效率低呢，如果群里有500人，这个关系表里就会插入500条记录，很快这个表中的数据量就会很大很大了，是不是会严重影响系统的性能？应该如何设计能够提高系统的效率。请帮忙解答下，这个问题困扰我很久了，谢谢","like_count":0,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":467802,"discussion_content":"对于群聊业务来说，由于消息扇出问题，一般处理上和点对点聊天不太一样。群聊消息一般采用”读扩散“的方式，一个群的消息只会记录一份，这个群里的每个用户在需要查看数据的时候都从会获取这个群的消息记录。未读数是每一个用户单独一份的，和消息不一样。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1568877629,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1965699,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/fe/83/df562574.jpg","nickname":"慎独明强","note":"","ucode":"DC2F7F2C0C8F60","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":290228,"discussion_content":"看了老师的评论，有点类似于mq的消息存储在服务端，但是在服务都存储了每个客户端的消费进度，那么每个客户端都可以读取到全量的消息了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1594384438,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":132755,"user_name":"墙角儿的花","can_delete":false,"product_type":"c1","uid":1258474,"ip_address":"","ucode":"EE5CAD76175CCF","user_header":"","comment_is_top":false,"comment_ctime":1568214105,"is_pvip":false,"replies":[{"id":"50938","content":"可以的，长连接入层和后面的业务层之间可以通过redis的pub sub来降低消息延迟，消息发送的api层和具体的持久化层出于成本考虑可以通过其他非内存型来实现，kafka由于是顺序的读写，写入和读取的性能有系统的PageCache来加速，所以性能上不会差。不知道你这里说的延迟批量发布消息具体是什么原因呢？","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1568288068,"ip_address":"","comment_id":132755,"utype":1}],"discussion_count":3,"race_medal":0,"score":"1568214105","product_id":100034901,"comment_content":"老师 对于im服务器集群，客户端的socket均布在各个服务器，目标socket不在同一个服务器上时，服务器间需要转发消息，这个场景需要低延迟无需持久化，服务器间用redis的发布订阅，因其走内存较快，即使断电还可以走库。im服务器和入库服务间用其他mq解耦，因为这个环节需要持久化，所以选rocketmq或kafka，但kafka会延迟批量发布消息 所以选rocketmq，这两个环节的mq选型可行吗。","like_count":0,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":467107,"discussion_content":"可以的，长连接入层和后面的业务层之间可以通过redis的pub sub来降低消息延迟，消息发送的api层和具体的持久化层出于成本考虑可以通过其他非内存型来实现，kafka由于是顺序的读写，写入和读取的性能有系统的PageCache来加速，所以性能上不会差。不知道你这里说的延迟批量发布消息具体是什么原因呢？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1568288068,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1258474,"avatar":"","nickname":"墙角儿的花","note":"","ucode":"EE5CAD76175CCF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":10584,"discussion_content":"哦 我是了解到kafka消息生产者发送消息不是立即发送 而是积攒一批 批量发送","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1568296724,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1111899,"avatar":"https://static001.geekbang.org/account/avatar/00/10/f7/5b/d2e7c2c4.jpg","nickname":"时隐时现","note":"","ucode":"DA4D622FF84920","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1258474,"avatar":"","nickname":"墙角儿的花","note":"","ucode":"EE5CAD76175CCF","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":23031,"discussion_content":"这个可以通过producer端参数调整的，linger.ms和batch.size","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1569744234,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":10584,"ip_address":""},"score":23031,"extra":""}]}]},{"had_liked":false,"id":132569,"user_name":"卫江","can_delete":false,"product_type":"c1","uid":1101226,"ip_address":"","ucode":"DE2F7A6916F1A9","user_header":"https://static001.geekbang.org/account/avatar/00/10/cd/aa/33d48789.jpg","comment_is_top":false,"comment_ctime":1568167387,"is_pvip":false,"replies":[{"id":"50854","content":"是的，redis对于脚本执行并没有做到真正的事务性，lua脚本在redis中的执行只能保证多条命令会原子执行，整体执行完成才会同步给从库并写入aof，所以如果执行过程中掉电，会直接导致被中断的后面部分的脚本得不到执行。lua脚本中可以增加一些修复机制，比如会话比较少的话就聚合一次会话来覆盖总未读。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1568201027,"ip_address":"","comment_id":132569,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1568167387","product_id":100034901,"comment_content":"首先，我认为redis的脚本化提供了类似于事务的功能，只是功能上面更强大，也更便捷。但是同redis的事务一样，对于事务的ACID支持并不完善。老师提的问题，执行过程中掉电，首先这个的执行事务肯定是失败的，即使开启持久化也没有办法修复，同时客户端也会收到断线回复，所以，就可以当做失败处理，而针对于失败，业务可以通过重试来进行容错，但是感觉这里需要特别的设计，比如针对于某个玩家的消息未读等信息的更新和读取需要一直依赖某一条连接，这样才能保证针对于该玩家的消息的顺序性，不知道想的对不对？","like_count":0,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":467013,"discussion_content":"是的，redis对于脚本执行并没有做到真正的事务性，lua脚本在redis中的执行只能保证多条命令会原子执行，整体执行完成才会同步给从库并写入aof，所以如果执行过程中掉电，会直接导致被中断的后面部分的脚本得不到执行。lua脚本中可以增加一些修复机制，比如会话比较少的话就聚合一次会话来覆盖总未读。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1568201027,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":132563,"user_name":"bbpatience","can_delete":false,"product_type":"c1","uid":1642676,"ip_address":"","ucode":"0573DA545B2811","user_header":"","comment_is_top":false,"comment_ctime":1568166104,"is_pvip":false,"replies":[{"id":"50853","content":"好像和提的问题不大对的上哈，redis对于脚本的执行问题在于并不能保证执行过程掉电后从库或者aof能够感知到来用于恢复。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1568200897,"ip_address":"","comment_id":132563,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1568166104","product_id":100034901,"comment_content":"掉电会出现问题，在redis做主从拷贝时，锁信息有可能正好没有同步到从，这些从在切为主时，没有锁信息。可以用zk来解决分布式锁问题，它能保证掉电后再选举成功的节点，一定包含锁信息","like_count":0,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":467010,"discussion_content":"好像和提的问题不大对的上哈，redis对于脚本的执行问题在于并不能保证执行过程掉电后从库或者aof能够感知到来用于恢复。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1568200897,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":132535,"user_name":"云师兄","can_delete":false,"product_type":"c1","uid":1010459,"ip_address":"","ucode":"4475AF1598FBFD","user_header":"https://static001.geekbang.org/account/avatar/00/0f/6b/1b/4b397b80.jpg","comment_is_top":false,"comment_ctime":1568163041,"is_pvip":false,"replies":[{"id":"50851","content":"是的，未读数读取是一个相对高频的场景，特别是总未读。推送时更新角标和app上的消息tab未读轮询都会用到，所以如果是基于服务端来实现的话，推荐使用redis。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1568200555,"ip_address":"","comment_id":132535,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1568163041","product_id":100034901,"comment_content":"老师解决原子性方案两个是从redis角度提出的，是否实践中就是使用redis存储消息未读数？是考虑未读数的高频读写吗","like_count":0,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":466993,"discussion_content":"是的，未读数读取是一个相对高频的场景，特别是总未读。推送时更新角标和app上的消息tab未读轮询都会用到，所以如果是基于服务端来实现的话，推荐使用redis。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1568200555,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]}]}