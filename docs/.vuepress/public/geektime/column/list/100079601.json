[{"article_id":378127,"article_title":"开篇词 | 从 0 开始搭建一个企业级 Go 应用","article_content":"<p>你好，我是孔令飞，很高兴能在这里和你聊聊如何用 Go 构建企业级应用。</p><p>在过去的 5 年里，我一直在腾讯使用 Go 做大型企业级项目。比如说，腾讯云云函数 SCF、腾讯游戏容器平台 TenC、腾讯游戏微服务中台等。目前，我在腾讯云负责容器服务 TKE 的相关研发工作，专注于云原生混合云领域的基础架构开发。</p><h2>“云”是大势所趋，而Go是云时代的语言</h2><p>最近几年，我发现腾讯很多团队的开发语言都在转 Go。其实，不光腾讯，像阿里、华为和百度这类国内一线大厂也都在积极转 Go。甚至不少团队，所有项目都是用 Go 构建的。伴随而来的，就是各个公司对Go研发工程师的需求越来越旺盛。那么， Go 为什么会变得这么火热呢？我认为，原因主要有两个方面。</p><p>一方面，Go 是一门非常优秀的语言，它具有很多核心优势，例如：语言简单、语言层面支持并发编程、跨平台编译和自带垃圾回收机制等，这些优势是这些团队选择 Go 最根本的原因。</p><p>另一方面，也因为 Go 是云时代的语言。为什么这么说呢？下面，我来详细说说。</p><p>随着云计算平台的逐渐成熟，应用上云已经成为一个不可逆转的趋势了，很多公司都选择将基础架构/业务架构云化，例如阿里、腾讯都在将公司内部业务全面云化。可以说，全面云化已经是公司层面的核心 KPI了，我们甚至可以理解为以后所有的技术都会围绕着云来构建。</p><!-- [[[read_end]]] --><p><strong>而云目前是朝着云原生架构的方向演进的，云原生架构中具有统治力（影响力）的项目绝大部分又是用 Go 构建的。</strong>我们从下面这张云原生技术栈语言组成图中可以看到，有  63% 的具有统治力的云原生项目都是用 Go 来构建的。</p><p><img src=\"https://static001.geekbang.org/resource/image/c6/51/c608623543c26b8f088bea958856f551.png\" alt=\"\" title=\"云原生技术栈\"></p><blockquote>\n<p><span class=\"reference\">完整的云原生技术栈可参考<a href=\"https://landscape.cncf.io/images/landscape.png\">云原生技术图谱</a></span></p>\n</blockquote><p>因此，想要把基础架构/业务架构云化，离不开对这些云原生开源项目的学习、改造。而一个团队为了节省成本，技术栈最好统一。既然我们一定要会 Go，而且 Go 这么优秀，那最好的方式就是将整个团队的语言技术栈 all in Go，这也是 Go 为什么重要的另一个原因了。</p><p>那么，我们用 Go 做什么呢，当然是项目开发。但很多开发者在用 Go 进行项目开发时会面临一系列问题。</p><h2>学习 Go 项目开发面临哪些问题？</h2><p>我带过不少刚接触 Go 语言的开发者，他们为了学习 Go 项目开发，会上网搜很多 Go 相关的技术文章，也确实花了很多时间去学习。但是，当我做 Code Review 时，发现他们开发的代码仍然存在很多问题。</p><p>比如说，有个开发者写的代码依赖数据库连接，没法写单元测试。细问之后，我发现他参考的文章没有将数据库层跟业务层通过接口解耦。</p><p>再比如说，还有一些开发者开发的项目很难维护，项目中出现了大量的 common、util、const 这类 Go 包。只看包名，我完全不知道包所实现的功能，问了之后才发现他是参考了一个带有 dao、model、controller、service 目录的、不符合 Go 设计哲学的项目。</p><p>而这些问题其实只是冰山一角，总的来说，我们在学习 Go 项目开发时会面临以下4大类问题。</p><ol>\n<li><strong>知识盲区</strong>：Go 项目开发会涉及很多知识点，但自己对这些知识点却一无所知。想要学习，却发现网上很多文章结构混乱、讲解不透彻。想要搜索一遍优秀的文章，又要花费很多时间，劳神劳力。</li>\n<li><strong>学不到最佳实践，能力提升有限</strong>：网上有很多文章会介绍 Go 项目的构建方法，但很多都不是最佳实践，学完之后不能在能力和认知上带来最佳提升，还要自己花时间整理学习，事倍功半。</li>\n<li><strong>不知道如何完整地开发一个 Go 项目</strong>：学了很多 Go 开发相关的知识点、构建方法，但都不体系、不全面、不深入。学完之后，自己并不能把它们有机结合成一个 Go 项目研发体系，真正开发的时候还是一团乱，效率也很低。</li>\n<li><strong>缺乏一线项目练手，很难检验学习效果</strong>：为了避免闭门造车，我们肯定想学习一线大厂的大型项目构建和研发经验，来检验自己的学习成果，但自己平时又很难接触到，没有这样的学习途径。</li>\n</ol><p>为了解决这些问题，我设计了《Go 语言项目开发实战》这个专栏，希望帮助你成为一名优秀的Go开发者，在职场中建立自己的核心竞争力。</p><h2>这个专栏是如何设计的？</h2><p>《Go 语言项目开发实战》这个专栏又是如何解决上述问题的呢？在这个专栏里，我会围绕一个可部署、可运行的企业应用源码，为你详细讲解实际开发流程中会涉及的技能点，让你彻底学会如何构建企业级 Go 应用，并解决 Go 项目开发所面临的各类问题。</p><p>一方面，你能够从比较高的视野俯瞰整个 Go 企业应用开发流程，不仅知道一个优秀的企业应用涉及的技能点和开发工作，还能知道如何高效地完成每个阶段的开发工作。另一方面，你能够深入到每个技能点，掌握它们的具体构建方法、业界的最佳实践和一线开发经验。</p><p>最后我还想强调一点，除了以上内容，专栏最终还会交付给你一套优秀、可运行的企业应用代码。这套代码能够满足绝大部分的企业应用开发场景，你可以基于它做二次开发，快速构建起你的企业应用。</p><p>说了这么多，我们到底能学到哪些技能点呢？我按照开发顺序把它们总结在下面这张图中，图中包含了Go项目开发中大部分技能点。</p><p><img src=\"https://static001.geekbang.org/resource/image/c4/8c/c4a4bdfc103f193d292b54e44510f28c.jpg\" alt=\"\"></p><p>除此之外，<strong>专栏中的每个技能点我都会尽可能朝着“最佳实践”的方向去设计</strong>。例如，我使用的 Go 包都是业界采纳度最高的包，而且设计时，我也会尽可能遵循 Go 设计模式、Go 开发规范、Go 最佳实践、go clean architecture 等。同时，我也会尽量把我自己<strong>做一线Go项目研发的经验，融合到讲解的过程中</strong>，给你最靠谱的建议，这些经验和建议可以让你在构建应用的过程中，少走很多弯路。</p><p>为了让你更好地学习这门课程，我把整个专栏划分为了6个模块。其中，第1个模块是实战环境准备，第2到第6个模块我会带着你按照研发的流程来实际构建一个应用。</p><p><strong>实战准备</strong>：我会先手把手带你准备一个实验环境，再带你部署我们的实战项目。加深你对实战项目的理解的同时，给你讲解一些部署的技能点，包括如何准备开发环境、制作CA证书，安装和配置用到的数据库、应用，以及Shell脚本编写技巧等。</p><p><strong>实战第 1 站：规范设计</strong>：我会详细介绍开发中常见的10大规范，例如目录规范、日志规范、错误码规范、Commit规范等。通过本模块，你能够学会如何设计常见的规范，为高效开发一个高质量、易阅读、易维护的 Go 应用打好基础。</p><p><strong>实战第 2 站：基础功能设计或开发</strong>：我会教你设计或开发一些Go应用开发中的基础功能，这些功能会影响整个应用的构建方式，例如日志包、错误包、错误码等。</p><p><strong>实战第 3 站：服务开发</strong>：我会带你一起解析一个企业级的Go项目代码，让你学会如何开发Go应用。在解析的过程中，我也会详细讲解Go开发阶段的各个技能点，例如怎么设计和开发API服务、Go SDK、客户端工具等。</p><p><strong>实战第 4 站：服务测试</strong>：我会围绕实战项目来讲解进行单元测试、功能测试、性能分析和性能调优的方法，最终让你交付一个性能和稳定性都经过充分测试的、生产级可用的服务。</p><p><strong>实战第 5 站：服务部署</strong>：本模块通过实战项目的部署，来告诉你如何部署一个高可用、安全、具备容灾能力，又可以轻松水平扩展的企业应用。这里，我会重点介绍 2 种部署方式：传统部署方式和容器化部署方式，每种方式在部署方法、复杂度和能力上都有所不同。</p><p>最后，关于怎么学习这个专栏，我还想给你一些建议。</p><p>第一，我建议你先学习这个专栏的图文内容，再详细去读源码。学习过程中如果产生一些想法可以通过修改代码，并查看运行结果的方式来加以验证。这个专栏的代码，我都放在GitHub上，你可以点击<a href=\"https://github.com/marmotedu/iam\">这个链接</a>查看。</p><p>第二，在专栏中，我不会详细去介绍每行代码，只会挑选一些核心代码来讲。一些没有讲到的地方，如果有疑问，你一定要在评论区留言，因为这个专栏我就是要带你攻克开发过程中的所有难题，千万不要让小问题积攒成大难题，那真的得不偿失。我可以承诺的是，留言回复可能会迟到，但绝不会缺席。</p><p>好啦，从现在开始，让我们一起开启这场充满挑战的Go项目实战旅途，为真正开发出一个优秀的企业级Go应用，成为一个Go资深开发者，一起努力吧！</p>","neighbors":{"left":[],"right":{"article_title":"01 | IAM系统概述：我们要实现什么样的 Go 项目？","id":377998}}},{"article_id":377998,"article_title":"01 | IAM系统概述：我们要实现什么样的 Go 项目？","article_content":"<p>你好，我是孔令飞。从今天开始我们进入课前准备阶段，我会用3讲的时间给你讲清楚，我们要实现的实战项目 IAM 应用长啥样、它能干什么，以及怎么把它部署到 Linux 服务器上。先和我一起扫除基础的障碍，你就能够更轻松地学习后面的课程了。</p><p>今天这一讲，我先来说说为什么选择 IAM 应用，它能实现什么功能，以及它的架构和使用流程。</p><h2>项目背景：为什么选择 IAM 系统作为实战项目？</h2><p>我们在做 Go 项目开发时，绕不开的一个话题是安全，如何保证 Go 应用的安全，是每个开发者都要解决的问题。虽然 Go 应用的安全包含很多方面，但大体可分为如下 2 类：</p><ul>\n<li><strong>服务自身的安全</strong>：为了保证服务的安全，需要禁止非法用户访问服务。这可以通过服务器层面和软件层面来解决。服务器层面可以通过物理隔离、网络隔离、防火墙等技术从底层保证服务的安全性，软件层面可以通过 HTTPS、用户认证等手段来加强服务的安全性。服务器层面一般由运维团队来保障，软件层面则需要开发者来保障。</li>\n<li><strong>服务资源的安全</strong>：服务内有很多资源，为了避免非法访问，开发者要避免 UserA 访问到 UserB 的资源，也即需要对资源进行授权。通常，我们可以通过资源授权系统来对资源进行授权。</li>\n</ul><p><strong>总的来说，为了保障Go应用的安全，我们需要对访问进行认证，对资源进行授权</strong>。那么，我们要如何实现访问认证和资源授权呢？</p><!-- [[[read_end]]] --><p>认证功能不复杂，我们可以通过 JWT （JSON Web Token）认证来实现。授权功能比较复杂，授权功能的复杂性使得它可以囊括很多 Go 开发技能点。因此，在这个专栏中，我将认证和授权的功能实现升级为 IAM 系统，通过讲解它的构建过程，给你讲清楚 Go 项目开发的全部流程。</p><h2>IAM 系统是什么？</h2><p>IAM（Identity and Access Management，身份识别与访问管理）系统是用 Go 语言编写的一个 Web 服务，用于给第三方用户提供访问控制服务。</p><p>IAM 系统可以帮用户解决的问题是：<strong>在特定的条件下，谁能够/不能够对哪些资源做哪些操作</strong>（<strong>Who</strong> is <strong>able</strong> to do <strong>what</strong> on <strong>something</strong> given some <strong>context</strong>），也即完成资源授权功能。</p><blockquote>\n<p><span class=\"reference\">提示：以后我们在提到 IAM 系统或者 IAM 时都是指代 IAM 应用。</span></p>\n</blockquote><p>那么，IAM 系统是如何进行资源授权的呢？下面，我们通过 IAM 系统的资源授权的流程，来看下它是如何工作的，整个过程可以分为 4 步。</p><p><img src=\"https://static001.geekbang.org/resource/image/ee/50/eed75fcd91d6e726ca74315d65193150.jpg?wh=2513*1134\" alt=\"\" title=\"IAM 系统的功能示意图\"></p><ol>\n<li>用户需要提供昵称、密码、邮箱、电话等信息注册并登录到 IAM 系统，这里是以用户名和密码作为唯一的身份标识来访问 IAM 系统，并且完成认证。</li>\n<li>因为访问 IAM 的资源授权接口是通过密钥（secretID/secretKey）的方式进行认证的，所以用户需要在 IAM 中创建属于自己的密钥资源。</li>\n<li>因为 IAM 通过授权策略完成授权，所以用户需要在 IAM 中创建授权策略。</li>\n<li>请求 IAM 提供的授权接口，IAM 会根据用户的请求内容和授权策略来决定一个授权请求是否被允许。</li>\n</ol><p>我们可以看到，在上面的流程中，IAM 使用到了 3 种系统资源：用户（User）、密钥（Secret）和策略（Policy），它们映射到程序设计中就是 3 种 RESTful 资源：</p><ul>\n<li>用户（User）：实现对用户的增、删、改、查、修改密码、批量修改等操作。</li>\n<li>密钥（Secret）：实现对密钥的增、删、改、查操作。</li>\n<li>策略（Policy）：实现对策略的增、删、改、查、批量删除操作。</li>\n</ul><h2>IAM 系统的架构长啥样？</h2><p>知道了 IAM 的功能之后，我们再来详细说说 IAM 系统的架构，架构图如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/0a/42/0a5f6fd67af1eda1c690c8216dc5e042.jpg?wh=3197*2063\" alt=\"\" title=\"IAM 系统的完整架构\"></p><p>总的来说，IAM 架构中包括 9 大组件和 3 大数据库。我将这些组件和功能都总结在下面的表格中。这里面，我们主要记住5个核心组件，包括iam-apiserver、iam-authz-server、iam-pump、marmotedu-sdk-go和iamctl的功能，还有3个数据库Redis、MySQL和MongoDB的功能。</p><p><img src=\"https://static001.geekbang.org/resource/image/6c/71/6cdbde36255c7fb2d4f2e718c9077a71.jpeg?wh=1920*1043\" alt=\"\" title=\"前 5 个组件是我们需要实现的核心组件。[br]后 4 个组件是一些旁路组件，不影响项目的使用。[br]如果感兴趣，你可以自行实现\"></p><p>此外，IAM 系统为存储数据使用到的 3 种数据库的说明如下所示。<br>\n<img src=\"https://static001.geekbang.org/resource/image/e6/f2/e68c21e1991c74becc4b8a6a8bf5a8f2.jpeg?wh=1818*496\" alt=\"\"></p><h3>通过使用流程理解架构</h3><p>只看到这样的系统架构图和核心功能讲解，你可能还不清楚整个系统是如何协作，来最终完成资源授权的。所以接下来，我们通过详细讲解 IAM 系统的使用流程及其实现细节，来进一步加深你对 IAM 架构的理解。总的来说，我们可以通过 4 步去使用 IAM 系统的核心功能。</p><p><strong>第1步，创建平台资源。</strong></p><p>用户通过 iam-webconsole（RESTful API）或 iamctl（sdk marmotedu-sdk-go）客户端请求 iam-apiserver 提供的 RESTful API 接口完成用户、密钥、授权策略的增删改查，iam-apiserver 会将这些资源数据持久化存储在 MySQL 数据库中。而且，为了确保通信安全，客户端访问服务端都是通过 HTTPS 协议来访问的。</p><p><strong>第2步，请求 API 完成资源授权。</strong></p><p>用户可以通过请求 iam-authz-server 提供的 /v1/authz 接口进行资源授权，请求 /v1/authz 接口需要通过密钥认证，认证通过后 /v1/authz 接口会查询授权策略，从而决定资源请求是否被允许。</p><p>为了提高 /v1/authz 接口的性能，iam-authz-server 将密钥和策略信息缓存在内存中，以便实现快速查询。那密钥和策略信息是如何实现缓存的呢？</p><p>首先，iam-authz-server 通过调用 iam-apiserver 提供的 gRPC 接口，将密钥和授权策略信息缓存到内存中。同时，为了使内存中的缓存信息和 iam-apiserver 中的信息保持一致，当 iam-apiserver 中有密钥或策略被更新时，iam-apiserver 会往特定的 Redis Channel（iam-authz-server 也会订阅该 Channel）中发送 PolicyChanged 和 SecretChanged 消息。这样一来，当 iam-authz-server 监听到有新消息时就会获取并解析消息，根据消息内容判断是否需要重新调用 gRPC 接来获取密钥和授权策略信息，再更新到内存中。</p><p><strong>第3步，授权日志数据分析。</strong></p><p>iam-authz-server 会将授权日志上报到 Redis 高速缓存中，然后 iam-pump 组件会异步消费这些授权日志，再把清理后的数据保存在 MongoDB 中，供运营系统 iam-operating-system 查询。</p><p>这里还有一点你要注意：iam-authz-server 将授权日志保存在 Redis 高性能 key-value 数据库中，可以最大化减少写入延时。不保存在内存中是因为授权日志量我们没法预测，当授权日志量很大时，很可能会将内存耗尽，造成服务中断。</p><p><strong>第4步，运营平台授权数据展示。</strong></p><p>iam-operating-system 是 IAM 的运营系统，它可以通过查询 MongoDB 获取并展示运营数据，比如某个用户的授权/失败次数、授权失败时的授权信息等。此外，我们也可以通过 iam-operating-system 调用 iam-apiserver 服务来做些运营管理工作。比如，以上帝视角查看某个用户的授权策略供排障使用，或者调整用户可创建密钥的最大个数，再或者通过白名单的方式，让某个用户不受密钥个数限制的影响等等。</p><h3>IAM 软件架构模式</h3><p>在设计软件时，我们首先要做的就是选择一种软件架构模式，它对软件后续的开发方式、软件维护成本都有比较大的影响。因此，这里我也会和你简单聊聊 2 种最常用的软件架构模式，分别是前后端分离架构和 MVC 架构。</p><h4>前后端分离架构</h4><p>因为IAM 系统采用的就是前后端分离的架构，所以我们就以 IAM 的运营系统 iam-operating-system 为例来详细说说这个架构。一般来说，运营系统的功能可多可少，对于一些具有复杂功能的运营系统，我们可以采用前后端分离的架构。其中，<strong>前端负责页面的展示以及数据的加载和渲染，后端只负责返回前端需要的数据</strong>。</p><p>iam-operating-system 前后端分离架构如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/a2/76/a2e1f1cc135debd86611yya1f221c476.jpg?wh=2519*1447\" alt=\"\"></p><p>采用了前后端分离架构之后，当你通过浏览器请求前端 ops-webconsole 时，ops-webconsole 会先请求静态文件服务器加载静态文件，比如 HTML、CSS 和 JavaScript，然后它会执行 JavaScript，通过负载均衡请求后端数据，最后把后端返回的数据渲染到前端页面中。</p><p>采用前后端分离的架构，让前后端通过 RESTful API 通信，会带来以下5点好处：</p><ul>\n<li>可以让前、后端人员各自专注在自己业务的功能开发上，让专业的人做专业的事，来提高代码质量和开发效率</li>\n<li>前后端可并行开发和发布，这也能提高开发和发布效率，加快产品迭代速度</li>\n<li>前后端组件、代码分开，职责分明，可以增加代码的维护性和可读性，减少代码改动引起的 Bug 概率，同时也能快速定位 Bug</li>\n<li>前端 JavaScript 可以处理后台的数据，减少对后台服务器的压力</li>\n<li>可根据需要选择性水平扩容前端或者后端来节约成本</li>\n</ul><h4>MVC 架构</h4><p>但是，如果运营系统功能比较少，采用前后端分离框架的弊反而大于利，比如前后端分离要同时维护 2 个组件会导致部署更复杂，并且前后端分离将人员也分开了，这会增加一定程度的沟通成本。同时，因为代码中也需要实现前后端交互的逻辑，所以会引入一定的开发量。</p><p>这个时候，我们可以尝试直接采用 MVC 软件架构，MVC 架构如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/a2/eb/a23b8ba92705710c694fd7cb99812feb.jpg?wh=1753*869\" alt=\"\"></p><p>MVC 的全名是 Model View Controller，它是一种架构模式，分为 Model、View、Controller 三层，每一层的功能如下：</p><ul>\n<li>View（视图）：提供给用户的操作界面，用来处理数据的显示。</li>\n<li>Controller（控制器）：根据用户从 View 层输入的指令，选取 Model 层中的数据，然后对其进行相应的操作，产生最终结果。</li>\n<li>Model（模型）：应用程序中用于处理数据逻辑的部分。</li>\n</ul><p><strong>MVC 架构的好处是通过控制器层将视图层和模型层分离之后，当更改视图层代码后时，我们就不需要重新编译控制器层和模型层的代码了。</strong>同样，如果业务流程发生改变也只需要变更模型层的代码就可以。在实际开发中为了更好的 UI 效果，视图层需要经常变更，但是通过 MVC 架构，在变更视图层时，我们根本不需要对业务逻辑层的代码做任何变化，这不仅减少了风险还能提高代码变更和发布的效率。</p><p>除此之外，还有一种跟 MVC 比较相似的软件开发架构叫三层架构，它包括UI 层、BLL 层和DAL 层。其中，UI 层表示用户界面，BLL 层表示业务逻辑，DAL 层表示数据访问。在实际开发中很多人将 MVC 当成三层架构在用，比如说，很多人喜欢把软件的业务逻辑放在 Controller 层里，将数据库访问操作的代码放在 Model 层里，软件最终的代码放在 View 层里，就这样硬生生将 MVC 架构变成了伪三层架构。</p><p>这种代码不仅不伦不类，同时也失去了三层架构和 MVC 架构的核心优势，也就是：<strong>通过 Controller层将 Model层和 View层解耦，从而使代码更容易维护和扩展</strong>。因此在实际开发中，我们也要注意遵循 MVC 架构的开发规范，发挥 MVC 的核心价值。</p><h2>总结</h2><p>一个好的 Go 应用必须要保证应用的安全性，这可以通过认证和授权来保障。也因此认证和授权是开发一个 Go 项目必须要实现的功能。为了帮助你实现这 2 个功能，并借此机会学习 Go 项目开发，我将这 2 个功能升级为一个 IAM系统。通过讲解如何开发 IAM 系统，来教你如何开发 Go 项目。</p><p>因为后面的学习都是围绕 IAM 系统展开的，所以这一讲我们要重点掌握 IAM 的功能、架构和使用流程，我们可以通过 4 步使用流程来了解。</p><p>首先，用户通过调用 iam-apiserver 提供的 RESTful API 接口完成注册和登录系统，再调用接口创建密钥和授权策略。</p><p>创建完密钥对和授权策略之后，IAM 可以通过调用 iam-authz-server 的授权接口完成资源的授权。具体来说，iam-authz-server 通过 gRPC 接口获取 iam-apiserver 中存储的密钥和授权策略信息，通过 JWT 完成认证之后，再通过 <a href=\"https://github.com/ory/ladon\">ory/ladon</a> 包完成资源的授权。</p><p>接着，iam-pump 组件异步消费 Redis 中的数据，并持久化存储在 MongoDB 中，供 iam-operating-system 运营平台展示。</p><p>最后，IAM 相关的产品、研发人员可以通过 IAM 的运营系统 iam-operating-system 来查看 IAM 系统的使用情况，进行运营分析。例如某个用户的授权/失败次数、授权失败时的授权信息等。</p><p>另外，为了提高开发和访问效率，IAM 分别提供了 marmotedu-sdk-go SDK 和 iamctl 命令行工具，二者通过 HTTPS 协议访问 IAM 提供的 RESTful 接口。</p><h2>课后练习</h2><ol>\n<li>你在做 Go 项目开发时经常用到哪些技能点？有些技能点是 IAM 没有包含的？</li>\n<li>在你所接触的项目中，哪些是前后端分离架构，哪些是 MVC 架构呢？你觉得项目采用的架构是否合理呢？</li>\n</ol><p>期待在留言区看到你的思考和分享，我们下一讲见！</p>","neighbors":{"left":{"article_title":"开篇词 | 从 0 开始搭建一个企业级 Go 应用","id":378127},"right":{"article_title":"02 | 环境准备：如何安装和配置一个基本的 Go 开发环境？","id":378076}}},{"article_id":378076,"article_title":"02 | 环境准备：如何安装和配置一个基本的 Go 开发环境？","article_content":"<p>你好，我是孔令飞。</p><p>上一讲我们讲了 IAM 系统的功能和架构，接下来的两讲，我们就将它部署到你的服务器上。不过，在正式部署之前，我们还需要准备一个Go 开发环境，这是因为我们是通过编译源码来获取部署需要的二进制文件的。</p><p>因此，今天这一讲，我先手把手带你配置好一个 Go 的开发环境，供你以后开发、编译用，下一讲再带你部署IAM系统。</p><p>想要配置一个 Go 开发环境，我们可以通过以下 4 步实现：</p><ol>\n<li>Linux 服务器申请和配置</li>\n<li>依赖安装和配置</li>\n<li>Go 编译环境安装和配置</li>\n<li>Go 开发 IDE 安装和配置</li>\n</ol><h2>Linux 服务器申请和配置</h2><p>毫无疑问，要安装一个 Go 开发环境，你首先需要有一个 Linux 服务器。Linux 服务器有很多操作系统可供选择，例如：CentOS、Ubuntu、RHEL、Debian 等，但目前生产环境用得最多的还是 CentOS 系统，为了跟生产环境保持一致，我们选择当前最新的 CentOS 版本：CentOS 8.2。</p><p>因为本专栏的所有操作都是在 CentOS 8.2 系统上进行的，为了避免环境不一致导致的操作失败，我建议你也使用 CentOS 8.2。安装一个 Linux 服务器需要两步：服务器申请和配置。</p><h3>Linux 服务器申请</h3><p>我们可以通过以下 3 种方式来安装一个 CentOS 8.2 系统。</p><!-- [[[read_end]]] --><ol>\n<li>在物理机上安装一个 CentOS 8.2 系统。</li>\n<li>在 Windows/MacBook 上安装虚拟机管理软件，用虚拟机管理软件创建 CentOS 8.2 虚拟机。其中，Windows 建议用 VMWare Workstation 来创建虚拟机，MacBook 建议用 VirtualBox 来创建虚拟机。</li>\n<li>在诸如腾讯云、阿里云、华为云等平台上购买一个虚拟机，并预装 CentOS 8.2 系统。</li>\n</ol><h3>Linux 服务器配置</h3><p>申请完 Linux 服务之后，我们需要通过 SecureCRT 或 Xshell 等工具登录 Linux 服务器，并对服务器做一些简单必要的配置，包括创建普通用户、添加 sudoers、配置 <code>$HOME/.bashrc</code> 文件。接下来，我们一一来说。</p><p><strong>第一步，用Root 用户登录Linux 系统，并创建普通用户。</strong></p><p>一般来说，一个项目会由多个开发人员协作完成，为了节省企业成本，公司不会给每个开发人员都配备一台服务器，而是让所有开发人员共用一个开发机，通过普通用户登录开发机进行开发。因此，为了模拟真实的企业开发环境，我们也通过一个普通用户的身份来进行项目的开发，创建方法如下：</p><pre><code># useradd going # 创建 going 用户，通过 going 用户登录开发机进行开发\n# passwd going # 设置密码\nChanging password for user going.\nNew password:\nRetype new password:\npasswd: all authentication tokens updated successfully.\n</code></pre><p>不仅如此，使用普通用户登录和操作开发机也可以保证系统的安全性，这是一个比较好的习惯，所以我们在日常开发中也要尽量避免使用 Root 用户。</p><p><strong>第二步，添加 sudoers。</strong></p><p>我们知道很多时候，普通用户也要用到 Root 的一些权限，但 Root 用户的密码一般是由系统管理员维护并定期更改的，每次都向管理员询问密码又很麻烦。因此，我建议你将普通用户加入到 sudoers 中，这样普通用户就可以通过 sudo 命令来暂时获取 Root 的权限。具体来说，你可以执行如下命令添加：</p><pre><code># sed -i '/^root.*ALL=(ALL).*ALL/a\\going\\tALL=(ALL) \\tALL' /etc/sudoers\n</code></pre><p><strong>第三步，用新的用户名（going）和密码登录Linux 服务器。</strong>这一步也可以验证普通用户是否创建成功。</p><p><strong>第四步，配置 $HOME/.bashrc 文件。</strong></p><p>我们登录新服务器后的第一步就是配置 $HOME/.bashrc 文件，以使 Linux 登录 shell 更加易用，例如配置 <code>LANG</code> 解决中文乱码，配置 <code>PS1</code> 可以避免整行都是文件路径，并将 <code>$HOME/bin</code> 加入到 <code>PATH</code> 路径中。配置后的内容如下：</p><pre><code># .bashrc\n \n# User specific aliases and functions\n \nalias rm='rm -i'\nalias cp='cp -i'\nalias mv='mv -i'\n \n# Source global definitions\nif [ -f /etc/bashrc ]; then\n        . /etc/bashrc\nfi\n \n# User specific environment\n# Basic envs\nexport LANG=&quot;en_US.UTF-8&quot; # 设置系统语言为 en_US.UTF-8，避免终端出现中文乱码\nexport PS1='[\\u@dev \\W]\\$ ' # 默认的 PS1 设置会展示全部的路径，为了防止过长，这里只展示：&quot;用户名@dev 最后的目录名&quot;\nexport WORKSPACE=&quot;$HOME/workspace&quot; # 设置工作目录\nexport PATH=$HOME/bin:$PATH # 将 $HOME/bin 目录加入到 PATH 变量中\n \n# Default entry folder\ncd $WORKSPACE # 登录系统，默认进入 workspace 目录\n</code></pre><p>有一点需要我们注意，在 export <code>PATH</code> 时，最好把 <code>$PATH</code> 放到最后，因为我们添加到目录中的命令是期望被优先搜索并使用的。配置完 <code>$HOME/.bashrc</code> 后，我们还需要创建工作目录 workspace。将工作文件统一放在 <code>$HOME/workspace</code> 目录中，有几点好处。</p><ul>\n<li>可以使我们的<code>$HOME</code>目录保持整洁，便于以后的文件查找和分类。</li>\n<li>如果哪一天 <code>/分区空间不足，可以将整个</code> <code>workspace</code> 目录 mv 到另一个分区中，并在 <code>/分区中保留软连接，例如：/home/going/workspace -&gt; /data/workspace/</code>。</li>\n<li>如果哪天想备份所有的工作文件，可以直接备份 <code>workspace</code>。</li>\n</ul><p>具体的操作指令是<code>$ mkdir -p $HOME/workspace</code>。配置好 <code>$HOME/.bashrc</code> 文件后，我们就可以执行 bash 命令将配置加载到当前 shell 中了。</p><p>至此，我们就完成了 Linux 开发机环境的申请及初步配置。</p><h2>依赖安装和配置</h2><p>在 Linux 系统上安装 IAM 系统会依赖一些 RPM 包和工具，有些是直接依赖，有些是间接依赖。为了避免后续的操作出现依赖错误，例如，因为包不存在而导致的编译、命令执行错误等，我们先统一依赖安装和配置。安装和配置步骤如下。</p><p><strong>第一步，安装依赖。</strong></p><p>首先，我们在 CentOS 系统上通过 <code>yum</code> 命令来安装所需工具的依赖，安装命令如下：</p><pre><code>$ sudo yum -y install make autoconf automake cmake perl-CPAN libcurl-devel libtool gcc gcc-c++ glibc-headers zlib-devel git-lfs telnet ctags lrzsz jq expat-devel openssl-devel\n</code></pre><p>虽然有些 CentOS 8.2 系统已经默认安装这些依赖了，但是为了确保它们都能被安装，我仍然会尝试安装一遍。如果系统提示 <code>Package xxx is already installed.</code>，说明已经安装好了，你直接忽略即可。</p><p><strong>第二步，安装 Git。</strong></p><p>因为安装 IAM 系统、执行 <code>go get</code> 命令、安装 protobuf 工具等都是通过 Git 来操作的，所以接下来我们还需要安装 Git。由于低版本的 Git 不支持<code>--unshallow</code> 参数，而 go get 在安装 Go 包时会用到 <code>git fetch --unshallow</code> 命令，因此我们要确保安装一个高版本的 Git，具体的安装方法如下：</p><pre><code>$ cd /tmp\n$ wget https://mirrors.edge.kernel.org/pub/software/scm/git/git-2.30.2.tar.gz\n$ tar -xvzf git-2.30.2.tar.gz\n$ cd git-2.30.2/\n$ ./configure\n$ make\n$ sudo make install\n$ git --version          # 输出 git 版本号，说明安装成功\ngit version 2.30.2\n</code></pre><p>注意啦，按照上面的步骤安装好之后，我们要把 Git 的二进制目录添加到 PATH 路径中，不然 Git 可能会因为找不到一些命令而报错。你可以通过执行以下命令添加目录：</p><pre><code>tee -a $HOME/.bashrc &lt;&lt;'EOF'\n# Configure for git\nexport PATH=/usr/local/libexec/git-core:$PATH\nEOF\n</code></pre><p><strong>第三步，配置 Git。</strong>我们直接执行如下命令配置 Git：</p><pre><code>$ git config --global user.name &quot;Lingfei Kong&quot;    # 用户名改成自己的\n$ git config --global user.email &quot;colin404@foxmail.com&quot;    # 邮箱改成自己的\n$ git config --global credential.helper store    # 设置 Git，保存用户名和密码\n$ git config --global core.longpaths true # 解决 Git 中 'Filename too long' 的错误\n</code></pre><p>除了按照上述步骤配置 Git 之外，我们还有几点需要注意。</p><p>首先，在 Git 中，我们会把非 ASCII 字符叫做 Unusual 字符。这类字符在 Git 输出到终端的时候默认是用 8 进制转义字符输出的（以防乱码），但现在的终端多数都支持直接显示非 ASCII 字符，所以我们可以关闭掉这个特性，具体的命令如下：</p><pre><code>$ git config --global core.quotepath off\n</code></pre><p>其次，如果你觉得访问 github.com 太慢，可以通过国内 GitHub 镜像网站来访问，配置方法如下：</p><pre><code>$ git config --global url.&quot;https://github.com.cnpmjs.org/&quot;.insteadOf &quot;https://github.com/&quot;\n</code></pre><p>这里你要注意，通过镜像网站访问仅对 HTTPS 协议生效，对 SSH 协议不生效，并且 github.com.cnpmjs.org 的同步时间间隔为 1 天。</p><p>最后，GitHub 限制最大只能克隆 100M 的单个文件，为了能够克隆大于 100M 的文件，我们还需要安装 Git Large File Storage，安装方式如下：</p><pre><code>$ git lfs install --skip-repo\n</code></pre><p>好啦，现在我们就完成了依赖的安装和配置。</p><h2>Go 编译环境安装和配置</h2><p>我们知道，Go 是一门编译型语言，所以在部署 IAM 系统之前，我们需要将代码编译成可执行的二进制文件。因此我们需要安装 Go 编译环境。</p><p>除了 Go，我们也会用 gRPC 框架展示 RPC 通信协议的用法，所以我们也需要将 ProtoBuf 的.proto 文件编译成 Go 语言的接口。因此，我们也需要安装 ProtoBuf 的编译环境。</p><h3>Go 编译环境安装和配置</h3><p>安装 Go 语言相对来说比较简单，我们只需要下载源码包、设置相应的环境变量即可。</p><p>首先，我们从 Go 语言官方网站下载对应的 Go 安装包以及源码包，这里我下载的是 go1.17.2 版本：</p><pre><code>$ wget https://golang.google.cn/dl/go1.17.2.linux-amd64.tar.gz -O /tmp/go1.17.2.linux-amd64.tar.gz\n</code></pre><p>接着，我们完成解压和安装，命令如下：</p><pre><code>$ mkdir -p $HOME/go\n$ tar -xvzf /tmp/go1.17.2.linux-amd64.tar.gz -C $HOME/go\n$ mv $HOME/go/go $HOME/go/go1.17.2\n</code></pre><p>最后，我们执行以下命令，将下列环境变量追加到<code>$HOME/.bashrc</code> 文件中。</p><pre><code>tee -a $HOME/.bashrc &lt;&lt;'EOF'\n# Go envs\nexport GOVERSION=go1.17.2 # Go 版本设置\nexport GO_INSTALL_DIR=$HOME/go # Go 安装目录\nexport GOROOT=$GO_INSTALL_DIR/$GOVERSION # GOROOT 设置\nexport GOPATH=$WORKSPACE/golang # GOPATH 设置\nexport PATH=$GOROOT/bin:$GOPATH/bin:$PATH # 将 Go 语言自带的和通过 go install 安装的二进制文件加入到 PATH 路径中\nexport GO111MODULE=&quot;on&quot; # 开启 Go moudles 特性\nexport GOPROXY=https://goproxy.cn,direct # 安装 Go 模块时，代理服务器设置\nexport GOPRIVATE=\nexport GOSUMDB=off # 关闭校验 Go 依赖包的哈希值\nEOF\n</code></pre><p>为什么要增加这么多环境变量呢？这是因为，Go 语言是通过一系列的环境变量来控制 Go 编译器行为的。因此，我们一定要理解每一个环境变量的含义。</p><p><img src=\"https://static001.geekbang.org/resource/image/4b/c1/4bde380dc05cd9900ec56dc7027c15c1.jpeg?wh=1920*1080\" alt=\"\"></p><p>因为 Go 以后会用 Go modules 来管理依赖，所以我建议你将 GO111MODULE 设置为 on。</p><p>在使用模块的时候，<code>$GOPATH</code> 是无意义的，不过它还是会把下载的依赖储存在 <code>$GOPATH/pkg/mod</code> 目录中，也会把 go install 的二进制文件存放在 <code>$GOPATH/bin</code> 目录中。</p><p>另外，我们还要将<code>$GOPATH/bin</code>、<code>$GOROOT/bin</code> 加入到 Linux 可执行文件搜索路径中。这样一来，我们就可以直接在 bash shell 中执行 go 自带的命令，以及通过 go install 安装的命令。</p><p>最后就是进行测试了，如果我们执行 go version 命令可以成功输出 Go 的版本，就说明 Go 编译环境安装成功。具体的命令如下：</p><pre><code>$ bash\n$ go version\ngo version go1.17.2 linu x/amd64\n</code></pre><h3>ProtoBuf 编译环境安装</h3><p>接着，我们再来安装 protobuf 的编译器 protoc。protoc 需要 protoc-gen-go 来完成 Go 语言的代码转换，因此我们需要安装 protoc 和 protoc-gen-go 这 2 个工具。它们的安装方法比较简单，你直接看我下面给出的代码和操作注释就可以了。</p><pre><code># 第一步：安装 protobuf\n$ cd /tmp/\n$ git clone --depth=1 https://github.com/protocolbuffers/protobuf\n$ cd protobuf\n$ ./autogen.sh\n$ ./configure\n$ make\n$ sudo make install\n$ protoc --version # 查看 protoc 版本，成功输出版本号，说明安装成功\nlibprotoc 3.15.6\n\n# 第二步：安装 protoc-gen-go\n$ go get -u github.com/golang/protobuf/protoc-gen-go\n\n</code></pre><p>当你第一次执行 go get 命令的时候，因为本地无缓存，所以需要下载所有的依赖模块。因此安装速度会比较慢，请你耐心等待。</p><h2>Go 开发 IDE 安装和配置</h2><p>编译环境准备完之后，我们还需要一个代码编辑器才能开始 Go 项目开发，并且为了提高开发效率，我们需要将这个编辑器配置成 Go IDE。</p><p>目前，GoLand、VSCode 这些 IDE 都很优秀，我们使用的也很多，但它们都是 Windows 系统下的 IDE。因此，在 Linux 环境下我们可以选择将 Vim 配置成 Go IDE，熟悉 Vim IDE 的操作之后，它的开发效率不输 GoLand 和 VSCode。</p><p>比如说，我们可以通过 SpaceVim 将 Vim 配置成一个 Go IDE。SpaceVim 是一个社区驱动的模块化的 Vim IDE，以模块的方式组织管理插件以及相关配置， 为不同的语言开发量身定制了相关的开发模块，该模块提供代码自动补全、 语法检查、格式化、调试、REPL 等特性。我们只需要载入相关语言的模块就能得到一个开箱即用的 Vim IDE 了。</p><p>Vim 可以选择 NeoVim，NeoVim 是基于 Vim 的一个 fork 分支，它主要解决了 Vim8 之前版本中的异步执行、开发模式等问题，对 Vim 的兼容性很好。同时对 vim 的代码进行了大量地清理和重构，去掉了对老旧系统的支持，添加了新的特性。</p><p>虽然 Vim8 后来也新增了异步执行等特性，在使用层面两者差异不大，但是 NeoVim 开发更激进，新特性更多，架构也相对更合理，所以我选择了 NeoVim，你也可以根据个人爱好来选择（都是很优秀的编辑器，这里不做优缺点比较）。Vim IDE 的安装和配置主要分五步。</p><p><strong>第一步，安装 NeoVim。</strong>我们直接执行 pip3 和 yum 命令安装即可，安装方法如下：</p><pre><code>$ sudo pip3 install pynvim\n$ sudo yum -y install neovim\n</code></pre><p><strong>第二步，配置</strong> <code>$HOME/.bashrc</code>。先配置 nvim 的别名为 vi，这样当我们执行 vi 时，Linux系统就会默认调用 nvim。同时，配置 EDITOR 环境变量可以使一些工具，例如 Git 默认使用 nvim。配置方法如下：</p><pre><code>tee -a $HOME/.bashrc &lt;&lt;'EOF'\n# Configure for nvim\nexport EDITOR=nvim # 默认的编辑器（git 会用到）\nalias vi=&quot;nvim&quot;\nEOF\n</code></pre><p><strong>第三步，检查 nvim 是否安装成功。</strong>我们可以通过查看 NeoVim 版本来确认是否成功安装，如果成功输出版本号，说明 NeoVim 安装成功。</p><pre><code>$ bash\n$ vi --version # 输出 NVIM v0.3.8 说明安装成功\nNVIM v0.3.8\nBuild type: RelWithDebInfo\n...\n</code></pre><p><strong>第四步，离线安装 SpaceVim。</strong>安装 SpaceVim 步骤稍微有点复杂，为了简化你的安装，同时消除网络的影响，我将安装和配置 SpaceVim 的步骤做成了一个离线安装包 <a href=\"https://github.com/marmotedu/marmotVim\">marmotVim</a> 。marmotVim 可以进行 SpaceVim 的安装、卸载、打包等操作，安装步骤如下：</p><pre><code>$ cd /tmp\n$ wget https://marmotedu-1254073058.cos.ap-beijing.myqcloud.com/tools/marmotVim.tar.gz\n$ tar -xvzf marmotVim.tar.gz\n$ cd marmotVim\n$ ./marmotVimCtl install\n</code></pre><p>SpaceVim 配置文件为：<code>$HOME/.SpaceVim.d/init.toml</code> 和<code>$HOME/.SpaceVim.d/autoload/custom_init.vim</code>，你可自行配置（配置文件中有配置说明）：</p><ul>\n<li>init.toml：SpaceVim 的配置文件</li>\n<li>custom_init.vim：兼容 vimrc，用户自定义的配置文件</li>\n</ul><p>SpaceVim Go IDE 常用操作的按键映射如下表所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/f1/d9/f1ec06569a411be4369byy7b8c7469d9.jpeg?wh=1920*1080\" alt=\"\"></p><p><strong>第五步，Go 工具安装。</strong></p><p>SpaceVim 会用到一些 Go 工具，比如在函数跳转时会用到 guru、godef 工具，在格式化时会用到 goimports，所以我们也需要安装这些工具。安装方法有 2 种：</p><ol>\n<li>Vim 底线命令安装：vi test.go，然后执行：<code>:GoInstallBinaries</code> 安装。</li>\n<li>拷贝工具：直接将整理好的工具文件拷贝到<code>$GOPATH/bin</code> 目录下。</li>\n</ol><p>为了方便，你可以直接拷贝我已经打包好的 Go 工具到指定目录下：</p><pre><code>$ cd /tmp\n$ wget https://marmotedu-1254073058.cos.ap-beijing.myqcloud.com/tools/gotools-for-spacevim.tgz\n$ mkdir -p $GOPATH/bin\n$ tar -xvzf gotools-for-spacevim.tgz -C $GOPATH/bin\n</code></pre><h2>总结</h2><p>这一讲，我们一起安装和配置了一个 Go 开发环境，为了方便你回顾，我将安装和配置过程绘制成了一个流程图，如下所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/28/8e/28e52b697e735ecd58770c5fede7e58e.jpg?wh=2588*1894\" alt=\"\"></p><p>有了这个开发环境，接下来我们就可以在学习的过程中随时进行编码，来熟悉和验证知识点了，所以你一定要在学习后面的课程之前先完成这一讲的部署。</p><h2>课后练习</h2><ol>\n<li>试着编写一个 main.go，在 main 函数中打印 <code>Hello World</code>，并执行 <code>go run main.go</code> 运行代码，测试 Go 开发环境。</li>\n<li>试着编写一个 main.go，代码如下：</li>\n</ol><pre><code>package main\n\nimport &quot;fmt&quot;\n\nfunc main() {\n    fmt.Println(&quot;Hello World&quot;)\n}\n</code></pre><p>将鼠标放在 <strong>Println</strong> 上，键入 <strong>Enter</strong> 键跳转到函数定义处，键入 <strong>Ctrl + I</strong> 返回到跳转点。</p><p>期待在留言区看到你的思考和答案，也欢迎和我一起探讨环境安装过程中的问题，我们下一讲见！</p>","neighbors":{"left":{"article_title":"01 | IAM系统概述：我们要实现什么样的 Go 项目？","id":377998},"right":{"article_title":"03 | 项目部署：如何快速部署 IAM 系统？","id":378082}}},{"article_id":378082,"article_title":"03 | 项目部署：如何快速部署 IAM 系统？","article_content":"<p>你好，我是孔令飞。</p><p>上一讲，我们一起安装和配置了一个基本的 Go 开发环境。这一讲，我就来教你怎么在它的基础上，快速部署好 IAM 系统。</p><p>因为我们要通过一个 IAM 项目来讲解怎么开发企业级 Go 项目，所以你要对 IAM 项目有比较好的了解，了解 IAM 项目一个最直接有效的方式就是去部署和使用它。</p><p>这不仅能让你了解到 IAM 系统中各个组件功能之间的联系，加深你对 IAM 系统的理解，还可以协助你排障，尤其是跟部署相关的故障。此外，部署好 IAM 系统也能给你后面的学习准备好实验环境，边学、边练，从而提高你的学习效率。</p><p>所以，今天我们专门花一讲的时间来说说怎么部署和使用 IAM 系统。同时，因为 IAM 系统是一个企业级的项目，有一定的复杂度，我建议你严格按照我说的步骤去操作，否则可能会安装失败。</p><p>总的来说，我把部署过程分成 2 大步。</p><ol>\n<li>安装和配置数据库：我们需要安装和配置 MariaDB、Redis和MongoDB。</li>\n<li>安装和配置 IAM 服务：我们需要安装和配置 iam-apiserver、iam-authz-server、iam-pump、iamctl和man 文件。</li>\n</ol><p>当然啦，如果你实在不想这么麻烦地去安装，我也在这一讲的最后给出了一键部署 IAM 系统的方法，但我还是希望你能按照我今天讲的详细步骤来操作。</p><!-- [[[read_end]]] --><p>那话不多说，我们直接开始操作吧！</p><h2>下载 iam 项目代码</h2><p>因为 IAM 的安装脚本存放在 iam 代码仓库中，安装需要的二进制文件也需要通过 iam 代码构建，所以在安装之前，我们需要先下载 iam 代码：</p><pre><code>$ mkdir -p $WORKSPACE/golang/src/github.com/marmotedu\n$ cd $WORKSPACE/golang/src/github.com/marmotedu\n$ git clone --depth=1 https://github.com/marmotedu/iam\n\n</code></pre><p>其中，marmotedu 和 marmotedu/iam 目录存放了本实战项目的代码，在学习过程中，你需要频繁访问这 2 个目录，为了访问方便，我们可以追加如下 2 个环境变量和 2 个 alias 到<code>$HOME/.bashrc</code> 文件中：</p><pre><code>$ tee -a $HOME/.bashrc &lt;&lt; 'EOF'\n# Alias for quick access\nexport GOWORK=&quot;$WORKSPACE/golang/src&quot;\nexport IAM_ROOT=&quot;$GOWORK/github.com/marmotedu/iam&quot;\nalias mm=&quot;cd $GOWORK/github.com/marmotedu&quot;\nalias i=&quot;cd $GOWORK/github.com/marmotedu/iam&quot;\nEOF\n$ bash\n</code></pre><p>之后，我们可以先通过执行 alias 命令 <code>mm</code> 访问 <code>$GOWORK/github.com/marmotedu</code> 目录，再通过执行 alias 命令 <code>i</code> 访问 <code>$GOWORK/github.com/marmotedu/iam</code> 目录。</p><p>这里我也建议你善用 alias，将常用操作配置成 alias，方便以后操作。</p><p>在安装配置之前需要执行以下命令export going用户的密码，这里假设密码是 <code>iam59!z$</code>：</p><pre><code>export LINUX_PASSWORD='iam59!z$'\n\n</code></pre><h2>安装和配置数据库</h2><p>因为 IAM 系统用到了 MariaDB、Redis、MongoDB 数据库来存储数据，而 IAM 服务在启动时会先尝试连接这些数据库，所以为了避免启动时连接数据库失败，这里我们先来安装需要的数据库。</p><h3>安装和配置 MariaDB</h3><p>IAM 会把 REST 资源的定义信息存储在关系型数据库中，关系型数据库我选择了 MariaDB。为啥选择 MariaDB，而不是 MySQL呢？。选择 MariaDB 一方面是因为它是发展最快的 MySQL 分支，相比 MySQL，它加入了很多新的特性，并且它能够完全兼容 MySQL，包括 API 和命令行。另一方面是因为 MariaDB 是开源的，而且迭代速度很快。</p><p>首先，我们可以通过以下命令安装和配置 MariaDB，并将 Root 密码设置为 <code>iam59!z$</code>：</p><pre><code>$ cd $IAM_ROOT\n$ ./scripts/install/mariadb.sh iam::mariadb::install\n</code></pre><p>然后，我们可以通过以下命令，来测试 MariaDB 是否安装成功：</p><pre><code>$ mysql -h127.0.0.1 -uroot -p'iam59!z$'\nMariaDB [(none)]&gt;\n</code></pre><h3>安装和配置 Redis</h3><p>在 IAM 系统中，由于 iam-authz-server 是从 iam-apiserver 拉取并缓存用户的密钥/策略信息的，因此同一份密钥/策略数据会分别存在 2 个服务中，这可能会出现数据不一致的情况。数据不一致会带来一些问题，例如当我们通过 iam-apiserver 创建了一对密钥，但是这对密钥还没有被 iam-authz-server 缓存，这时候通过这对密钥访问 iam-authz-server 就会访问失败。</p><p>为了保证数据的一致性，我们可以使用 Redis 的发布订阅(pub/sub)功能进行消息通知。同时，iam-authz-server 也会将授权审计日志缓存到 Redis 中，所以也需要安装 Redis key-value 数据库。我们可以通过以下命令来安装和配置 Redis，并将 Redis 的初始密码设置为 <code>iam59!z$</code> ：</p><pre><code>$ cd $IAM_ROOT\n$ ./scripts/install/redis.sh iam::redis::install\n</code></pre><p>这里我们要注意，scripts/install/redis.sh 脚本中 iam::redis::install 函数对 Redis 做了一些配置，例如修改 Redis 使其以守护进程的方式运行、修改 Redis 的密码为 <code>iam59!z$</code>等，详细配置可参考函数 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.0/scripts/install/redis.sh#L20\">iam::redis::install</a> 函数。</p><p>安装完成后，我们可以通过以下命令，来测试 Redis 是否安装成功：</p><pre><code> $ redis-cli -h 127.0.0.1 -p 6379 -a 'iam59!z$' # 连接 Redis，-h 指定主机，-p 指定监听端口，-a 指定登录密码\n\n</code></pre><h3>安装和配置 MongoDB</h3><p>因为 iam-pump 会将 iam-authz-server 产生的数据处理后存储在 MongoDB 中，所以我们也需要安装 MongoDB 数据库。主要分两步安装：首先安装 MongoDB，然后再创建 MongoDB 账号。</p><h4>第 1 步，安装 MongoDB</h4><p>首先，我们可以通过以下 4 步来安装 MongoDB。</p><ol>\n<li>配置 MongoDB yum 源，并安装 MongoDB。</li>\n</ol><p>CentOS8.x 系统默认没有配置安装 MongoDB 需要的 yum 源，所以我们需要先配置好 yum 源再安装：</p><pre><code>$ sudo tee /etc/yum.repos.d/mongodb-org-4.4.repo&lt;&lt;'EOF'\n[mongodb-org-4.4]\nname=MongoDB Repository\nbaseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/4.4/x86_64/\ngpgcheck=1\nenabled=1\ngpgkey=https://www.mongodb.org/static/pgp/server-4.4.asc\nEOF\n\n$ sudo yum install -y mongodb-org\n</code></pre><ol start=\"2\">\n<li>关闭 SELinux。</li>\n</ol><p>在安装的过程中，SELinux 有可能会阻止 MongoDB 访问/sys/fs/cgroup，所以我们还需要关闭 SELinux：</p><pre><code>$ sudo setenforce 0\n$ sudo sed -i 's/^SELINUX=.*$/SELINUX=disabled/' /etc/selinux/config # 永久关闭 SELINUX\n</code></pre><ol start=\"3\">\n<li>开启外网访问权限和登录验证。</li>\n</ol><p>MongoDB 安装完之后，默认情况下是不会开启外网访问权限和登录验证，为了方便使用，我建议你先开启这些功能，执行如下命令开启：</p><pre><code>$ sudo sed -i '/bindIp/{s/127.0.0.1/0.0.0.0/}' /etc/mongod.conf\n$ sudo sed -i '/^#security/a\\security:\\n  authorization: enabled' /etc/mongod.conf\n</code></pre><ol start=\"4\">\n<li>启动 MongoDB。</li>\n</ol><p>配置完 MongoDB 之后，我们就可以启动它了，具体的命令如下：</p><pre><code>$ sudo systemctl start mongod\n$ sudo systemctl enable mongod # 设置开机启动\n$ sudo systemctl status mongod # 查看 mongod 运行状态，如果输出中包含 active (running)字样说明 mongod 成功启动\n\n</code></pre><p>安装完 MongoDB 后，我们就可以通过 <code>mongo</code> 命令登录 MongoDB Shell。如果没有报错，就说明 MongoDB 被成功安装了。</p><pre><code>$ mongo --quiet &quot;mongodb://127.0.0.1:27017&quot;\n&gt;\n\n</code></pre><h4>第 2 步，创建 MongoDB 账号</h4><p>安装完 MongoDB 之后，默认是没有用户账号的，为了方便 IAM 服务使用，我们需要先创建好管理员账号，通过管理员账户登录 MongoDB，我们可以执行创建普通用户、数据库等操作。</p><ol>\n<li>创建管理员账户。</li>\n</ol><p>首先，我们通过 <code>use admin</code> 指令切换到 admin 数据库，再通过 <code>db.auth(\"用户名\"，\"用户密码\")</code> 验证用户登录权限。如果返回 1 表示验证成功；如果返回 0 表示验证失败。具体的命令如下：</p><pre><code>$ mongo --quiet &quot;mongodb://127.0.0.1:27017&quot;\n&gt; use admin\nswitched to db admin\n&gt; db.createUser({user:&quot;root&quot;,pwd:&quot;iam59!z$&quot;,roles:[&quot;root&quot;]})\nSuccessfully added user: { &quot;user&quot; : &quot;root&quot;, &quot;roles&quot; : [ &quot;root&quot; ] }\n&gt; db.auth(&quot;root&quot;, &quot;iam59!z$&quot;)\n1\n</code></pre><p>此外，如果想删除用户，可以使用 <code>db.dropUser(\"用户名\")</code> 命令。</p><p><code>db.createUser</code> 用到了以下 3 个参数。</p><ul>\n<li>user: 用户名。</li>\n<li>pwd: 用户密码。</li>\n<li>roles: 用来设置用户的权限，比如读、读写、写等。</li>\n</ul><p>因为 admin 用户具有 MongoDB 的 Root 权限，权限过大安全性会降低。为了提高安全性，我们还需要创建一个 iam 普通用户来连接和操作 MongoDB。</p><ol start=\"2\">\n<li>创建 iam 用户，命令如下：</li>\n</ol><pre><code>$ mongo --quiet mongodb://root:'iam59!z$'@127.0.0.1:27017/iam_analytics?authSource=admin # 用管理员账户连接 MongoDB\n&gt; use iam_analytics\nswitched to db iam_analytics\n&gt; db.createUser({user:&quot;iam&quot;,pwd:&quot;iam59!z$&quot;,roles:[&quot;dbOwner&quot;]})\nSuccessfully added user: { &quot;user&quot; : &quot;iam&quot;, &quot;roles&quot; : [ &quot;dbOwner&quot; ] }\n&gt; db.auth(&quot;iam&quot;, &quot;iam59!z$&quot;)\n1\n</code></pre><p>创建完 iam 普通用户后，我们就可以通过 iam 用户登录 MongoDB 了：</p><pre><code>$ mongo --quiet mongodb://iam:'iam59!z$'@127.0.0.1:27017/iam_analytics?authSource=iam_analytics\n\n</code></pre><p>至此，我们成功安装了 IAM 系统需要的数据库 MariaDB、Redis 和 MongoDB。</p><h2>安装和配置 IAM 系统</h2><p>要想完成 IAM 系统的安装，我们还需要安装和配置 iam-apiserver、iam-authz-server、iam-pump 和 iamctl。这些组件的功能我们在<a href=\"https://time.geekbang.org/column/article/377998\">第1讲</a>详细讲过，如果不记得你可以翻回去看看。</p><blockquote>\n<p>提示：IAM 项目我会长期维护、定期更新，欢迎你 Star &amp; Contributing。</p>\n</blockquote><h3>准备工作</h3><p>在开始安装之前，我们需要先做一些准备工作，主要有 5 步。</p><ol>\n<li>初始化 MariaDB 数据库，创建 iam 数据库。</li>\n<li>配置 scripts/install/environment.sh。</li>\n<li>创建需要的目录。</li>\n<li>创建 CA 根证书和密钥。</li>\n<li>配置 hosts。</li>\n</ol><p><strong>第 1 步，初始化 MariaDB 数据库，创建 iam 数据库。</strong></p><p>安装完 MariaDB 数据库之后，我们需要在 MariaDB 数据库中创建 IAM 系统需要的数据库、表和存储过程，以及创建 SQL 语句保存在 IAM 代码仓库中的 configs/iam.sql 文件中。具体的创建步骤如下。</p><ol>\n<li>登录数据库并创建 iam 用户。</li>\n</ol><pre><code>$ cd $IAM_ROOT\n$ mysql -h127.0.0.1 -P3306 -uroot -p'iam59!z$' # 连接 MariaDB，-h 指定主机，-P 指定监听端口，-u 指定登录用户，-p 指定登录密码\nMariaDB [(none)]&gt; grant all on iam.* TO iam@127.0.0.1 identified by 'iam59!z$';\nQuery OK, 0 rows affected (0.000 sec)\nMariaDB [(none)]&gt; flush privileges;\nQuery OK, 0 rows affected (0.000 sec)\n</code></pre><ol start=\"2\">\n<li>用 iam 用户登录 MariaDB，执行 iam.sql 文件，创建 iam 数据库。</li>\n</ol><pre><code>$ mysql -h127.0.0.1 -P3306 -uiam -p'iam59!z$'\nMariaDB [(none)]&gt; source configs/iam.sql;\nMariaDB [iam]&gt; show databases;\n+--------------------+\n| Database           |\n+--------------------+\n| iam                |\n| information_schema |\n+--------------------+\n2 rows in set (0.000 sec)\n</code></pre><p>上面的命令会创建 iam 数据库，并创建以下数据库资源。</p><ul>\n<li>表：user 是用户表，用来存放用户信息；secret 是密钥表，用来存放密钥信息；policy 是策略表，用来存放授权策略信息；policy_audit 是策略历史表，被删除的策略会被转存到该表。</li>\n<li>admin 用户：在 user 表中，我们需要创建一个管理员用户，用户名是 admin，密码是 Admin@2021。</li>\n<li>存储过程：删除用户时会自动删除该用户所属的密钥和策略信息。</li>\n</ul><p><strong>第 2 步，配置 scripts/install/environment.sh。</strong></p><p>IAM 组件的安装配置都是通过环境变量文件 <a href=\"https://github.com/marmotedu/iam/blob/master/scripts/install/environment.sh\">scripts/install/environment.sh</a> 进行配置的，所以我们要先配置好 scripts/install/environment.sh 文件。这里，你可以直接使用默认值，提高你的安装效率。</p><p><strong>第 3 步，创建需要的目录。</strong></p><p>在安装和运行 IAM 系统的时候，我们需要将配置、二进制文件和数据文件存放到指定的目录。所以我们需要先创建好这些目录，创建步骤如下。</p><pre><code>$ cd $IAM_ROOT\n$ source scripts/install/environment.sh\n$ sudo mkdir -p ${IAM_DATA_DIR}/{iam-apiserver,iam-authz-server,iam-pump} # 创建 Systemd WorkingDirectory 目录\n$ sudo mkdir -p ${IAM_INSTALL_DIR}/bin #创建 IAM 系统安装目录\n$ sudo mkdir -p ${IAM_CONFIG_DIR}/cert # 创建 IAM 系统配置文件存放目录\n$ sudo mkdir -p ${IAM_LOG_DIR} # 创建 IAM 日志文件存放目录\n</code></pre><p><strong>第 4 步， 创建 CA 根证书和密钥。</strong></p><p>为了确保安全，IAM 系统各组件需要使用 x509 证书对通信进行加密和认证。所以，这里我们需要先创建 CA 证书。CA 根证书是所有组件共享的，只需要创建一个 CA 证书，后续创建的所有证书都由它签名。</p><p>我们可以使用 CloudFlare 的 PKI 工具集 cfssl 来创建所有的证书。</p><ol>\n<li>安装 cfssl 工具集。</li>\n</ol><p>我们可以直接安装 cfssl 已经编译好的二进制文件，cfssl 工具集中包含很多工具，这里我们需要安装 cfssl、cfssljson、cfssl-certinfo，功能如下。</p><ul>\n<li>cfssl：证书签发工具。</li>\n<li>cfssljson：将 cfssl 生成的证书（json 格式）变为文件承载式证书。</li>\n</ul><p>这两个工具的安装方法如下：</p><pre><code>$ cd $IAM_ROOT\n$ ./scripts/install/install.sh iam::install::install_cfssl\n</code></pre><ol start=\"2\">\n<li>创建配置文件。</li>\n</ol><p>CA 配置文件是用来配置根证书的使用场景 (profile) 和具体参数 (usage、过期时间、服务端认证、客户端认证、加密等)，可以在签名其它证书时用来指定特定场景：</p><pre><code>$ cd $IAM_ROOT\n$ tee ca-config.json &lt;&lt; EOF\n{\n  &quot;signing&quot;: {\n    &quot;default&quot;: {\n      &quot;expiry&quot;: &quot;87600h&quot;\n    },\n    &quot;profiles&quot;: {\n      &quot;iam&quot;: {\n        &quot;usages&quot;: [\n          &quot;signing&quot;,\n          &quot;key encipherment&quot;,\n          &quot;server auth&quot;,\n          &quot;client auth&quot;\n        ],\n        &quot;expiry&quot;: &quot;876000h&quot;\n      }\n    }\n  }\n}\nEOF\n</code></pre><p>上面的 JSON 配置中，有一些字段解释如下。</p><ul>\n<li>signing：表示该证书可用于签名其它证书（生成的 ca.pem 证书中 CA=TRUE）。</li>\n<li>server auth：表示 client 可以用该证书对 server 提供的证书进行验证。</li>\n<li>client auth：表示 server 可以用该证书对 client 提供的证书进行验证。</li>\n<li>expiry：876000h，证书有效期设置为 100 年。</li>\n</ul><ol start=\"3\">\n<li>创建证书签名请求文件。</li>\n</ol><p>我们创建用来生成 CA 证书签名请求（CSR）的 JSON 配置文件：</p><pre><code>$ cd $IAM_ROOT\n$ tee ca-csr.json &lt;&lt; EOF\n{\n  &quot;CN&quot;: &quot;iam-ca&quot;,\n  &quot;key&quot;: {\n    &quot;algo&quot;: &quot;rsa&quot;,\n    &quot;size&quot;: 2048\n  },\n  &quot;names&quot;: [\n    {\n      &quot;C&quot;: &quot;CN&quot;,\n      &quot;ST&quot;: &quot;BeiJing&quot;,\n      &quot;L&quot;: &quot;BeiJing&quot;,\n      &quot;O&quot;: &quot;marmotedu&quot;,\n      &quot;OU&quot;: &quot;iam&quot;\n    }\n  ],\n  &quot;ca&quot;: {\n    &quot;expiry&quot;: &quot;876000h&quot;\n  }\n}\nEOF\n</code></pre><p>上面的 JSON 配置中，有一些字段解释如下。</p><ul>\n<li>C：Country，国家。</li>\n<li>ST：State，省份。</li>\n<li>L：Locality (L) or City，城市。</li>\n<li>CN：Common Name，iam-apiserver 从证书中提取该字段作为请求的用户名 (User Name) ，浏览器使用该字段验证网站是否合法。</li>\n<li>O：Organization，iam-apiserver 从证书中提取该字段作为请求用户所属的组 (Group)。</li>\n<li>OU：Company division (or Organization Unit – OU)，部门/单位。</li>\n</ul><p>除此之外，还有两点需要我们注意。</p><ul>\n<li>不同证书 csr 文件的 CN、C、ST、L、O、OU 组合必须不同，否则可能出现 <code>PEER'S CERTIFICATE HAS AN INVALID SIGNATURE</code> 错误。</li>\n<li>后续创建证书的 csr 文件时，CN、OU都不相同（C、ST、L、O相同），以达到区分的目的。</li>\n</ul><ol start=\"4\">\n<li>创建 CA 证书和私钥</li>\n</ol><p>首先，我们通过 <code>cfssl gencert</code> 命令来创建：</p><pre><code>$ cd $IAM_ROOT\n$ source scripts/install/environment.sh\n$ cfssl gencert -initca ca-csr.json | cfssljson -bare ca\n$ ls ca*\nca-config.json  ca.csr  ca-csr.json  ca-key.pem  ca.pem\n$ sudo mv ca* ${IAM_CONFIG_DIR}/cert # 需要将证书文件拷贝到指定文件夹下（分发证书），方便各组件引用\n</code></pre><p>上述命令会创建运行 CA 所必需的文件 ca-key.pem（私钥）和 ca.pem（证书），还会生成 ca.csr（证书签名请求），用于交叉签名或重新签名。</p><p>创建完之后，我们可以通过 <code>cfssl certinfo</code> 命名查看 cert 和 csr 信息：</p><pre><code>$ cfssl certinfo -cert ${IAM_CONFIG_DIR}/cert/ca.pem # 查看 cert(证书信息)\n$ cfssl certinfo -csr ${IAM_CONFIG_DIR}/cert/ca.csr # 查看 CSR(证书签名请求)信息\n</code></pre><p><strong>第 5 步，配置 hosts。</strong></p><p>iam 通过域名访问 API 接口，因为这些域名没有注册过，还不能在互联网上解析，所以需要配置 hosts，具体的操作如下：</p><pre><code>$ sudo tee -a /etc/hosts &lt;&lt;EOF\n127.0.0.1 iam.api.marmotedu.com\n127.0.0.1 iam.authz.marmotedu.com\nEOF\n</code></pre><h3>安装和配置 iam-apiserver</h3><p>完成了准备工作之后，我们就可以安装 IAM 系统的各个组件了。首先我们通过以下 3 步来安装 iam-apiserver 服务。</p><p><strong>第 1 步，创建 iam-apiserver 证书和私钥。</strong></p><p>其它服务为了安全都是通过 HTTPS 协议访问 iam-apiserver，所以我们要先创建 iam-apiserver 证书和私钥。</p><ol>\n<li>创建证书签名请求：</li>\n</ol><pre><code>$ cd $IAM_ROOT\n$ source scripts/install/environment.sh\n$ tee iam-apiserver-csr.json &lt;&lt;EOF\n{\n  &quot;CN&quot;: &quot;iam-apiserver&quot;,\n  &quot;key&quot;: {\n    &quot;algo&quot;: &quot;rsa&quot;,\n    &quot;size&quot;: 2048\n  },\n  &quot;names&quot;: [\n    {\n      &quot;C&quot;: &quot;CN&quot;,\n      &quot;ST&quot;: &quot;BeiJing&quot;,\n      &quot;L&quot;: &quot;BeiJing&quot;,\n      &quot;O&quot;: &quot;marmotedu&quot;,\n      &quot;OU&quot;: &quot;iam-apiserver&quot;\n    }\n  ],\n  &quot;hosts&quot;: [\n    &quot;127.0.0.1&quot;,\n    &quot;localhost&quot;,\n    &quot;iam.api.marmotedu.com&quot;\n  ]\n}\nEOF\n</code></pre><p>代码中的 hosts 字段是用来指定授权使用该证书的 IP 和域名列表，上面的 hosts 列出了 iam-apiserver 服务的 IP 和域名。</p><ol start=\"2\">\n<li>生成证书和私钥：</li>\n</ol><pre><code>$ cfssl gencert -ca=${IAM_CONFIG_DIR}/cert/ca.pem \\\n  -ca-key=${IAM_CONFIG_DIR}/cert/ca-key.pem \\\n  -config=${IAM_CONFIG_DIR}/cert/ca-config.json \\\n  -profile=iam iam-apiserver-csr.json | cfssljson -bare iam-apiserver\n$ sudo mv iam-apiserver*pem ${IAM_CONFIG_DIR}/cert # 将生成的证书和私钥文件拷贝到配置文件目录\n</code></pre><p><strong>第 2 步，安装并运行 iam-apiserver。</strong></p><p>iam-apiserver 作为 iam 系统的核心组件，需要第一个安装。</p><ol>\n<li>安装 iam-apiserver 可执行程序：</li>\n</ol><pre><code>$ cd $IAM_ROOT\n$ source scripts/install/environment.sh\n$ make build BINS=iam-apiserver\n$ sudo cp _output/platforms/linux/amd64/iam-apiserver ${IAM_INSTALL_DIR}/bin\n</code></pre><ol start=\"2\">\n<li>生成并安装 iam-apiserver 的配置文件（iam-apiserver.yaml）：</li>\n</ol><pre><code>$ ./scripts/genconfig.sh scripts/install/environment.sh configs/iam-apiserver.yaml &gt; iam-apiserver.yaml\n$ sudo mv iam-apiserver.yaml ${IAM_CONFIG_DIR}\n</code></pre><ol start=\"3\">\n<li>创建并安装 iam-apiserver systemd unit 文件：</li>\n</ol><pre><code>$ ./scripts/genconfig.sh scripts/install/environment.sh init/iam-apiserver.service &gt; iam-apiserver.service\n$ sudo mv iam-apiserver.service /etc/systemd/system/\n</code></pre><ol start=\"4\">\n<li>启动 iam-apiserver 服务：</li>\n</ol><pre><code>$ sudo systemctl daemon-reload\n$ sudo systemctl enable iam-apiserver\n$ sudo systemctl restart iam-apiserver\n$ systemctl status iam-apiserver # 查看 iam-apiserver 运行状态，如果输出中包含 active (running)字样说明 iam-apiserver 成功启动\n</code></pre><p><strong>第 3 步，测试 iam-apiserver 是否成功安装。</strong></p><p>测试 iam-apiserver 主要是测试 RESTful 资源的 CURD：用户 CURD、密钥 CURD、授权策略 CURD。</p><p>首先，我们需要获取访问 iam-apiserver 的 Token，请求如下 API 访问：</p><pre><code>$ curl -s -XPOST -H'Content-Type: application/json' -d'{&quot;username&quot;:&quot;admin&quot;,&quot;password&quot;:&quot;Admin@2021&quot;}' http://127.0.0.1:8080/login | jq -r .token\neyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA\n</code></pre><p>代码中下面的 HTTP 请求通过<code>-H'Authorization: Bearer &lt;Token&gt;'</code> 指定认证头信息，将上面请求的 Token 替换 <code>&lt;Token&gt;</code> 。</p><p><strong>用户 CURD</strong></p><p>创建用户、列出用户、获取用户详细信息、修改用户、删除单个用户、批量删除用户，请求方法如下：</p><pre><code># 创建用户\n$ curl -s -XPOST -H'Content-Type: application/json' -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' -d'{&quot;password&quot;:&quot;User@2021&quot;,&quot;metadata&quot;:{&quot;name&quot;:&quot;colin&quot;},&quot;nickname&quot;:&quot;colin&quot;,&quot;email&quot;:&quot;colin@foxmail.com&quot;,&quot;phone&quot;:&quot;1812884xxxx&quot;}' http://127.0.0.1:8080/v1/users\n\n# 列出用户\n$ curl -s -XGET -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' 'http://127.0.0.1:8080/v1/users?offset=0&amp;limit=10'\n\n# 获取 colin 用户的详细信息\n$ curl -s -XGET -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' http://127.0.0.1:8080/v1/users/colin\n\n# 修改 colin 用户\n$ curl -s -XPUT -H'Content-Type: application/json' -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' -d'{&quot;nickname&quot;:&quot;colin&quot;,&quot;email&quot;:&quot;colin_modified@foxmail.com&quot;,&quot;phone&quot;:&quot;1812884xxxx&quot;}' http://127.0.0.1:8080/v1/users/colin\n\n# 删除 colin 用户\n$ curl -s -XDELETE -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' http://127.0.0.1:8080/v1/users/colin\n\n# 批量删除用户\n$ curl -s -XDELETE -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' 'http://127.0.0.1:8080/v1/users?name=colin&amp;name=mark&amp;name=john'\n</code></pre><p><strong>密钥 CURD</strong></p><p>创建密钥、列出密钥、获取密钥详细信息、修改密钥、删除密钥请求方法如下：</p><pre><code># 创建 secret0 密钥\n$ curl -s -XPOST -H'Content-Type: application/json' -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' -d'{&quot;metadata&quot;:{&quot;name&quot;:&quot;secret0&quot;},&quot;expires&quot;:0,&quot;description&quot;:&quot;admin secret&quot;}' http://127.0.0.1:8080/v1/secrets\n\n# 列出所有密钥\n$ curl -s -XGET -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' http://127.0.0.1:8080/v1/secrets\n\n# 获取 secret0 密钥的详细信息\n$ curl -s -XGET -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' http://127.0.0.1:8080/v1/secrets/secret0\n\n# 修改 secret0 密钥\n$ curl -s -XPUT -H'Content-Type: application/json' -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' -d'{&quot;metadata&quot;:{&quot;name&quot;:&quot;secret0&quot;},&quot;expires&quot;:0,&quot;description&quot;:&quot;admin secret(modified)&quot;}' http://127.0.0.1:8080/v1/secrets/secret0\n\n# 删除 secret0 密钥\n$ curl -s -XDELETE -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' http://127.0.0.1:8080/v1/secrets/secret0\n</code></pre><p>这里我们要注意，因为密钥属于重要资源，被删除会导致所有的访问请求失败，所以密钥不支持批量删除。</p><p><strong>授权策略 CURD</strong></p><p>创建策略、列出策略、获取策略详细信息、修改策略、删除策略请求方法如下：</p><pre><code># 创建策略\n$ curl -s -XPOST -H'Content-Type: application/json' -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' -d'{&quot;metadata&quot;:{&quot;name&quot;:&quot;policy0&quot;},&quot;policy&quot;:{&quot;description&quot;:&quot;One policy to rule them all.&quot;,&quot;subjects&quot;:[&quot;users:&lt;peter|ken&gt;&quot;,&quot;users:maria&quot;,&quot;groups:admins&quot;],&quot;actions&quot;:[&quot;delete&quot;,&quot;&lt;create|update&gt;&quot;],&quot;effect&quot;:&quot;allow&quot;,&quot;resources&quot;:[&quot;resources:articles:&lt;.*&gt;&quot;,&quot;resources:printer&quot;],&quot;conditions&quot;:{&quot;remoteIPAddress&quot;:{&quot;type&quot;:&quot;CIDRCondition&quot;,&quot;options&quot;:{&quot;cidr&quot;:&quot;192.168.0.1/16&quot;}}}}}' http://127.0.0.1:8080/v1/policies\n\n# 列出所有策略\n$ curl -s -XGET -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' http://127.0.0.1:8080/v1/policies\n\n# 获取 policy0 策略的详细信息\n$ curl -s -XGET -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' http://127.0.0.1:8080/v1/policies/policy0\n\n# 修改 policy0 策略\n$ curl -s -XPUT -H'Content-Type: application/json' -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' -d'{&quot;metadata&quot;:{&quot;name&quot;:&quot;policy0&quot;},&quot;policy&quot;:{&quot;description&quot;:&quot;One policy to rule them all(modified).&quot;,&quot;subjects&quot;:[&quot;users:&lt;peter|ken&gt;&quot;,&quot;users:maria&quot;,&quot;groups:admins&quot;],&quot;actions&quot;:[&quot;delete&quot;,&quot;&lt;create|update&gt;&quot;],&quot;effect&quot;:&quot;allow&quot;,&quot;resources&quot;:[&quot;resources:articles:&lt;.*&gt;&quot;,&quot;resources:printer&quot;],&quot;conditions&quot;:{&quot;remoteIPAddress&quot;:{&quot;type&quot;:&quot;CIDRCondition&quot;,&quot;options&quot;:{&quot;cidr&quot;:&quot;192.168.0.1/16&quot;}}}}}' http://127.0.0.1:8080/v1/policies/policy0\n\n# 删除 policy0 策略\n$ curl -s -XDELETE -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MTc5MjI4OTQsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MTc4MzY0OTQsInN1YiI6ImFkbWluIn0.9qztVJseQ9XwqOFVUHNOtG96-KUovndz0SSr_QBsxAA' http://127.0.0.1:8080/v1/policies/policy0\n\n</code></pre><h3>安装 iamctl</h3><p>上面，我们安装了 iam 系统的 API 服务。但是想要访问 iam 服务，我们还需要安装客户端工具 iamctl。具体来说，我们可以通过 3 步完成 iamctl 的安装和配置。</p><p><strong>第 1 步，创建 iamctl 证书和私钥。</strong></p><p>iamctl 使用 https 协议与 iam-apiserver 进行安全通信，iam-apiserver 对 iamctl 请求包含的证书进行认证和授权。iamctl 后续用于 iam 系统访问和管理，所以这里创建具有最高权限的 admin 证书。</p><ol>\n<li>创建证书签名请求。</li>\n</ol><p>下面创建的证书只会被 iamctl 当作 client 证书使用，所以 hosts 字段为空。代码如下：</p><pre><code>$ cd $IAM_ROOT\n$ source scripts/install/environment.sh\n$ cat &gt; admin-csr.json &lt;&lt;EOF\n{\n  &quot;CN&quot;: &quot;admin&quot;,\n  &quot;key&quot;: {\n    &quot;algo&quot;: &quot;rsa&quot;,\n    &quot;size&quot;: 2048\n  },\n  &quot;names&quot;: [\n    {\n      &quot;C&quot;: &quot;CN&quot;,\n      &quot;ST&quot;: &quot;BeiJing&quot;,\n      &quot;L&quot;: &quot;BeiJing&quot;,\n      &quot;O&quot;: &quot;marmotedu&quot;,\n      &quot;OU&quot;: &quot;iamctl&quot;\n    }\n  ],\n  &quot;hosts&quot;: []\n}\nEOF\n</code></pre><ol start=\"2\">\n<li>生成证书和私钥：</li>\n</ol><pre><code>$ cfssl gencert -ca=${IAM_CONFIG_DIR}/cert/ca.pem \\\n  -ca-key=${IAM_CONFIG_DIR}/cert/ca-key.pem \\\n  -config=${IAM_CONFIG_DIR}/cert/ca-config.json \\\n  -profile=iam admin-csr.json | cfssljson -bare admin\n$ mkdir -p $(dirname ${CONFIG_USER_CLIENT_CERTIFICATE}) $(dirname ${CONFIG_USER_CLIENT_KEY}) # 创建客户端证书存放的目录\n$ mv admin.pem ${CONFIG_USER_CLIENT_CERTIFICATE} # 安装 TLS 的客户端证书\n$ mv admin-key.pem ${CONFIG_USER_CLIENT_KEY} # 安装 TLS 的客户端私钥文件\n</code></pre><p><strong>第 2 步，安装 iamctl。</strong></p><p>iamctl 是 IAM 系统的客户端工具，其安装位置和 iam-apiserver、iam-authz-server、iam-pump 位置不同，为了能够在 shell 下直接运行 iamctl 命令，我们需要将 iamctl 安装到<code>$HOME/bin</code> 下，同时将 iamctl 的配置存放在默认加载的目录下：<code>$HOME/.iam</code>。主要分 2 步进行。</p><ol>\n<li>安装 iamctl 可执行程序：</li>\n</ol><pre><code>$ cd $IAM_ROOT\n$ source scripts/install/environment.sh\n$ make build BINS=iamctl\n$ cp _output/platforms/linux/amd64/iamctl $HOME/bin\n\n</code></pre><ol start=\"2\">\n<li>生成并安装 iamctl 的配置文件（iamctl.yaml）：</li>\n</ol><pre><code>$ ./scripts/genconfig.sh scripts/install/environment.sh configs/iamctl.yaml&gt; iamctl.yaml\n$ mkdir -p $HOME/.iam\n$ mv iamctl.yaml $HOME/.iam\n</code></pre><p>因为 iamctl 是一个客户端工具，可能会在多台机器上运行。为了简化部署 iamctl 工具的复杂度，我们可以把 config 配置文件中跟 CA 认证相关的 CA 文件内容用 base64 加密后，放置在 config 配置文件中。具体的思路就是把 config 文件中的配置项 client-certificate、client-key、certificate-authority 分别用如下配置项替换 client-certificate-data、client-key-data、certificate-authority-data。这些配置项的值可以通过对 CA 文件使用 base64 加密获得。</p><p>假如，<code>certificate-authority</code> 值为<code>/etc/iam/cert/ca.pem</code>，则 <code>certificate-authority-data</code> 的值为 <code>cat \"/etc/iam/cert/ca.pem\" | base64 | tr -d '\\r\\n'</code>，其它<code>-data</code> 变量的值类似。这样当我们再部署 iamctl 工具时，只需要拷贝 iamctl 和配置文件，而不用再拷贝 CA 文件了。</p><p><strong>第 3 步，测试 iamctl 是否成功安装。</strong></p><p>执行 <code>iamctl user list</code> 可以列出预创建的 admin 用户，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/3f/17/3f24e2f6ddd12aae99cd62de5b037d17.png?wh=1920*152\" alt=\"\"></p><h3>安装和配置 iam-authz-server</h3><p>接下来，我们需要安装另外一个核心组件：iam-authz-server，可以通过以下 3 步来安装。</p><p><strong>第 1 步，创建 iam-authz-server 证书和私钥。</strong></p><ol>\n<li>创建证书签名请求：</li>\n</ol><pre><code>$ cd $IAM_ROOT\n$ source scripts/install/environment.sh\n$ tee iam-authz-server-csr.json &lt;&lt;EOF\n{\n  &quot;CN&quot;: &quot;iam-authz-server&quot;,\n  &quot;key&quot;: {\n    &quot;algo&quot;: &quot;rsa&quot;,\n    &quot;size&quot;: 2048\n  },\n  &quot;names&quot;: [\n    {\n      &quot;C&quot;: &quot;CN&quot;,\n      &quot;ST&quot;: &quot;BeiJing&quot;,\n      &quot;L&quot;: &quot;BeiJing&quot;,\n      &quot;O&quot;: &quot;marmotedu&quot;,\n      &quot;OU&quot;: &quot;iam-authz-server&quot;\n    }\n  ],\n  &quot;hosts&quot;: [\n    &quot;127.0.0.1&quot;,\n    &quot;localhost&quot;,\n    &quot;iam.authz.marmotedu.com&quot;\n  ]\n}\nEOF\n</code></pre><p>代码中的 hosts 字段指定授权使用该证书的 IP 和域名列表，上面的hosts列出了 iam-authz-server 服务的 IP 和域名。</p><ol start=\"2\">\n<li>生成证书和私钥：</li>\n</ol><pre><code>$ cfssl gencert -ca=${IAM_CONFIG_DIR}/cert/ca.pem \\\n  -ca-key=${IAM_CONFIG_DIR}/cert/ca-key.pem \\\n  -config=${IAM_CONFIG_DIR}/cert/ca-config.json \\\n  -profile=iam iam-authz-server-csr.json | cfssljson -bare iam-authz-server\n$ sudo mv iam-authz-server*pem ${IAM_CONFIG_DIR}/cert # 将生成的证书和私钥文件拷贝到配置文件目录\n</code></pre><p><strong>第 2 步，安装并运行 iam-authz-server。</strong></p><p>安装 iam-authz-server 步骤和安装 iam-apiserver 步骤基本一样，也需要 4 步。</p><ol>\n<li>安装 iam-authz-server 可执行程序：</li>\n</ol><pre><code>$ cd $IAM_ROOT\n$ source scripts/install/environment.sh\n$ make build BINS=iam-authz-server\n$ sudo cp _output/platforms/linux/amd64/iam-authz-server ${IAM_INSTALL_DIR}/bin\n\n</code></pre><ol start=\"2\">\n<li>生成并安装 iam-authz-server 的配置文件（iam-authz-server.yaml）：</li>\n</ol><pre><code>$ ./scripts/genconfig.sh scripts/install/environment.sh configs/iam-authz-server.yaml &gt; iam-authz-server.yaml\n$ sudo mv iam-authz-server.yaml ${IAM_CONFIG_DIR}\n</code></pre><ol start=\"3\">\n<li>创建并安装 iam-authz-server systemd unit 文件：</li>\n</ol><pre><code>$ ./scripts/genconfig.sh scripts/install/environment.sh init/iam-authz-server.service &gt; iam-authz-server.service\n$ sudo mv iam-authz-server.service /etc/systemd/system/\n</code></pre><ol start=\"4\">\n<li>启动 iam-authz-server 服务：</li>\n</ol><pre><code>$ sudo systemctl daemon-reload\n$ sudo systemctl enable iam-authz-server\n$ sudo systemctl restart iam-authz-server\n$ systemctl status iam-authz-server # 查看 iam-authz-server 运行状态，如果输出中包含 active (running)字样说明 iam-authz-server 成功启动。\n</code></pre><p><strong>第 3 步，测试 iam-authz-server 是否成功安装。</strong></p><ol>\n<li>重新登陆系统，并获取访问令牌</li>\n</ol><pre><code>$ token=`curl -s -XPOST -H'Content-Type: application/json' -d'{&quot;username&quot;:&quot;admin&quot;,&quot;password&quot;:&quot;Admin@2021&quot;}' http://127.0.0.1:8080/login | jq -r .token`\n</code></pre><ol start=\"2\">\n<li>创建授权策略</li>\n</ol><pre><code>$ curl -s -XPOST -H&quot;Content-Type: application/json&quot; -H&quot;Authorization: Bearer $token&quot; -d'{&quot;metadata&quot;:{&quot;name&quot;:&quot;authztest&quot;},&quot;policy&quot;:{&quot;description&quot;:&quot;One policy to rule them all.&quot;,&quot;subjects&quot;:[&quot;users:&lt;peter|ken&gt;&quot;,&quot;users:maria&quot;,&quot;groups:admins&quot;],&quot;actions&quot;:[&quot;delete&quot;,&quot;&lt;create|update&gt;&quot;],&quot;effect&quot;:&quot;allow&quot;,&quot;resources&quot;:[&quot;resources:articles:&lt;.*&gt;&quot;,&quot;resources:printer&quot;],&quot;conditions&quot;:{&quot;remoteIPAddress&quot;:{&quot;type&quot;:&quot;CIDRCondition&quot;,&quot;options&quot;:{&quot;cidr&quot;:&quot;192.168.0.1/16&quot;}}}}}' http://127.0.0.1:8080/v1/policies\n</code></pre><ol start=\"3\">\n<li>创建密钥，并从命令的输出中提取secretID 和 secretKey</li>\n</ol><pre><code>$ curl -s -XPOST -H&quot;Content-Type: application/json&quot; -H&quot;Authorization: Bearer $token&quot; -d'{&quot;metadata&quot;:{&quot;name&quot;:&quot;authztest&quot;},&quot;expires&quot;:0,&quot;description&quot;:&quot;admin secret&quot;}' http://127.0.0.1:8080/v1/secrets\n{&quot;metadata&quot;:{&quot;id&quot;:23,&quot;name&quot;:&quot;authztest&quot;,&quot;createdAt&quot;:&quot;2021-04-08T07:24:50.071671422+08:00&quot;,&quot;updatedAt&quot;:&quot;2021-04-08T07:24:50.071671422+08:00&quot;},&quot;username&quot;:&quot;admin&quot;,&quot;secretID&quot;:&quot;ZuxvXNfG08BdEMqkTaP41L2DLArlE6Jpqoox&quot;,&quot;secretKey&quot;:&quot;7Sfa5EfAPIwcTLGCfSvqLf0zZGCjF3l8&quot;,&quot;expires&quot;:0,&quot;description&quot;:&quot;admin secret&quot;}\n</code></pre><ol start=\"4\">\n<li>生成访问 iam-authz-server 的 token</li>\n</ol><p>iamctl 提供了 <code>jwt sigin</code> 命令，可以根据 secretID 和 secretKey 签发 Token，方便你使用。</p><pre><code>$ iamctl jwt sign ZuxvXNfG08BdEMqkTaP41L2DLArlE6Jpqoox 7Sfa5EfAPIwcTLGCfSvqLf0zZGCjF3l8 # iamctl jwt sign $secretID $secretKey\neyJhbGciOiJIUzI1NiIsImtpZCI6Ilp1eHZYTmZHMDhCZEVNcWtUYVA0MUwyRExBcmxFNkpwcW9veCIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXV0aHoubWFybW90ZWR1LmNvbSIsImV4cCI6MTYxNzg0NTE5NSwiaWF0IjoxNjE3ODM3OTk1LCJpc3MiOiJpYW1jdGwiLCJuYmYiOjE2MTc4Mzc5OTV9.za9yLM7lHVabPAlVQLCqXEaf8sTU6sodAsMXnmpXjMQ\n</code></pre><p>如果你的开发过程中有些重复性的操作，为了方便使用，也可以将这些操作以iamctl子命令的方式集成到iamctl命令行中。</p><ol start=\"5\">\n<li>测试资源授权是否通过</li>\n</ol><p>我们可以通过请求 <code>/v1/authz</code> 来完成资源授权：</p><pre><code>$ curl -s -XPOST -H'Content-Type: application/json' -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsImtpZCI6Ilp1eHZYTmZHMDhCZEVNcWtUYVA0MUwyRExBcmxFNkpwcW9veCIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXV0aHoubWFybW90ZWR1LmNvbSIsImV4cCI6MTYxNzg0NTE5NSwiaWF0IjoxNjE3ODM3OTk1LCJpc3MiOiJpYW1jdGwiLCJuYmYiOjE2MTc4Mzc5OTV9.za9yLM7lHVabPAlVQLCqXEaf8sTU6sodAsMXnmpXjMQ' -d'{&quot;subject&quot;:&quot;users:maria&quot;,&quot;action&quot;:&quot;delete&quot;,&quot;resource&quot;:&quot;resources:articles:ladon-introduction&quot;,&quot;context&quot;:{&quot;remoteIPAddress&quot;:&quot;192.168.0.5&quot;}}' http://127.0.0.1:9090/v1/authz\n{&quot;allowed&quot;:true}\n</code></pre><p>如果授权通过会返回：<code>{\"allowed\":true}</code> 。</p><h3>安装和配置 iam-pump</h3><p>安装 iam-pump 步骤和安装 iam-apiserver、iam-authz-server 步骤基本一样，具体步骤如下。</p><p><strong>第 1 步，安装 iam-pump 可执行程序。</strong></p><pre><code>$ cd $IAM_ROOT\n$ source scripts/install/environment.sh\n$ make build BINS=iam-pump\n$ sudo cp _output/platforms/linux/amd64/iam-pump ${IAM_INSTALL_DIR}/bin\n</code></pre><p><strong>第 2 步，生成并安装 iam-pump 的配置文件（iam-pump.yaml）。</strong></p><pre><code>$ ./scripts/genconfig.sh scripts/install/environment.sh configs/iam-pump.yaml &gt; iam-pump.yaml\n$ sudo mv iam-pump.yaml ${IAM_CONFIG_DIR}\n</code></pre><p><strong>第 3 步，创建并安装 iam-pump systemd unit 文件。</strong></p><pre><code>$ ./scripts/genconfig.sh scripts/install/environment.sh init/iam-pump.service &gt; iam-pump.service\n$ sudo mv iam-pump.service /etc/systemd/system/\n</code></pre><p><strong>第 4 步，启动 iam-pump 服务。</strong></p><pre><code>$ sudo systemctl daemon-reload\n$ sudo systemctl enable iam-pump\n$ sudo systemctl restart iam-pump\n$ systemctl status iam-pump # 查看 iam-pump 运行状态，如果输出中包含 active (running)字样说明 iam-pump 成功启动。\n</code></pre><p><strong>第 5 步，测试 iam-pump 是否成功安装。</strong></p><pre><code>$ curl http://127.0.0.1:7070/healthz\n{&quot;status&quot;: &quot;ok&quot;}\n</code></pre><p>经过上面这  5  个步骤，如果返回 <strong>{“status”: “ok”}</strong>  就说明 iam-pump 服务健康。</p><h2>安装 man 文件</h2><p>IAM 系统通过组合调用包：<code>github.com/cpuguy83/go-md2man/v2/md2man</code> 和 <code>github.com/spf13/cobra</code> 的相关函数生成了各个组件的 man1 文件，主要分 3 步实现。</p><p><strong>第 1 步，生成各个组件的 man1 文件。</strong></p><pre><code>$ cd $IAM_ROOT\n$ ./scripts/update-generated-docs.sh\n</code></pre><p><strong>第 2 步，安装生成的 man1 文件。</strong></p><pre><code>$ sudo cp docs/man/man1/* /usr/share/man/man1/\n</code></pre><p><strong>第 3 步，检查是否成功安装 man1 文件。</strong></p><pre><code>$ man iam-apiserver\n</code></pre><p>执行 <code>man iam-apiserver</code> 命令后，会弹出 man 文档界面，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/a7/37/a7415f8a7ea08302067ccc93c2cab437.png?wh=1796*423\" alt=\"\"></p><p>至此，IAM 系统所有组件都已经安装成功了，你可以通过 <code>iamctl version</code> 查看客户端和服务端版本，代码如下：</p><pre><code>$ iamctl version -o yaml\nclientVersion:\n  buildDate: &quot;2021-04-08T01:56:20Z&quot;\n  compiler: gc\n  gitCommit: 1d682b0317396347b568a3ef366c1c54b3b0186b\n  gitTreeState: dirty\n  gitVersion: v0.6.1-5-g1d682b0\n  goVersion: go1.16.2\n  platform: linux/amd64\nserverVersion:\n  buildDate: &quot;2021-04-07T22:30:53Z&quot;\n  compiler: gc\n  gitCommit: bde163964b8c004ebb20ca4abd8a2ac0cd1f71ad\n  gitTreeState: dirty\n  gitVersion: bde1639\n  goVersion: go1.16.2\n  platform: linux/amd64\n\n</code></pre><h2>总结</h2><p>这一讲，我带你一步一步安装了 IAM 应用，完成安装的同时，也希望能加深你对 IAM 应用的理解，并为后面的实战准备好环境。为了更清晰地展示安装流程，这里我把整个安装步骤梳理成了一张脑图，你可以看看。</p><p><img src=\"https://static001.geekbang.org/resource/image/05/ae/05de7498aaba1fddd1ae6ec3cb5b2fae.jpg?wh=2778*1741\" alt=\"\"></p><p>此外，我还有一点想提醒你，我们今天讲到的所有组件设置的密码都是 <strong>iam59!z$</strong>，你一定要记住啦。</p><h2>课后练习</h2><p>请你试着调用 iam-apiserver 提供的 API 接口创建一个用户：<code>xuezhang</code>，并在该用户下创建 policy 和 secret 资源。最后调用 iam-authz-server 提供的<code>/v1/authz</code> 接口进行资源鉴权。如果有什么有趣的发现，记得分享出来。</p><p>期待在留言区看到你的尝试，我们下一讲见！</p><hr><h2>彩蛋：一键安装</h2><p>如果学完了<a href=\"https://time.geekbang.org/column/article/378076\">第02讲</a>，你可以直接执行如下脚本，来完成 IAM 系统的安装：</p><pre><code>$ export LINUX_PASSWORD='iam59!z$' # 重要：这里要 export going 用户的密码\n$ version=latest &amp;&amp; curl https://marmotedu-1254073058.cos.ap-beijing.myqcloud.com/iam-release/${version}/iam.tar.gz | tar -xz -C / tmp/       \n$ cd /tmp/iam/ &amp;&amp; ./scripts/install/install.sh iam::install::install\n\n</code></pre><p>此外，你也可以参考 <a href=\"https://github.com/marmotedu/iam/tree/master/docs/guide/zh-CN/installation/README.md\">IAM 部署指南</a> 教程进行安装，这个安装手册可以让你在创建完普通用户后，一键部署整个 IAM 系统，包括实战环境和 IAM 服务。</p>","neighbors":{"left":{"article_title":"02 | 环境准备：如何安装和配置一个基本的 Go 开发环境？","id":378076},"right":{"article_title":"04 | 规范设计（上）：项目开发杂乱无章，如何规范？","id":380033}}},{"article_id":380033,"article_title":"04 | 规范设计（上）：项目开发杂乱无章，如何规范？","article_content":"<p>你好，我是孔令飞。今天，我们来聊聊开发应用中需要用到的那些规范。</p><p>无规矩不成方圆，生活如此，软件开发也是如此。一个应用基本都是多人协作开发的，但不同人的开发习惯、方式都不同。如果没有一个统一的规范，就会造成非常多的问题，比如：</p><ul>\n<li><strong>代码风格不一：</strong>代码仓库中有多种代码风格，读/改他人的代码都是一件痛苦的事情，整个代码库也会看起来很乱。</li>\n<li><strong>目录杂乱无章：</strong>相同的功能被放在不同的目录，或者一个目录你根本不知道它要完成什么功能，新开发的代码你也不知道放在哪个目录或文件。这些都会严重降低代码的可维护性。</li>\n<li><strong>接口不统一：</strong>对外提供的 API 接口不统一，例如修改用户接口为<code>/v1/users/colin</code>，但是修改密钥接口为<code>/v1/secret?name=secret0</code>，难以理解和记忆。</li>\n<li><strong>错误码不规范：</strong>错误码会直接暴露给用户，主要用于展示错误类型，以定位错误问题。错误码不规范会导致难以辨别错误类型，或者同类错误拥有不同错误码，增加理解难度。</li>\n</ul><p>因此，在设计阶段、编码之前，我们需要一个好的规范来约束开发者，以确保大家开发的是“<strong>一个应用”</strong>。一个好的规范不仅可以提高软件质量，还可以提高软件的开发效率，降低维护成本，甚至能减少 Bug 数，也可以使你的开发体验如行云流水一般顺畅。所以，在编码之前，有必要花一些时间和团队成员一起讨论并制定规范。</p><!-- [[[read_end]]] --><p>那么，有哪些地方需要制定规范，这些规范又该如何制定呢？</p><h2>有哪些地方需要制定规范？</h2><p>一个 Go 项目会涉及很多方面，所以也会有多种规范，同类规范也会因为团队差异而有所不同。所以，在这门课中我只给你讲一些开发中常用的规范。为了便于你记忆，根据是否跟代码相关，我将它们分为非编码类规范和编码类规范：</p><ul>\n<li>非编码类规范，主要包括开源规范、文档规范、版本规范、Commit 规范和发布规范。</li>\n<li>编码类规范，则主要包括目录规范、代码规范、接口规范、日志规范和错误码规范。</li>\n</ul><p>为了便于你记忆，我将这些规范整理成了下面一张图：</p><p><img src=\"https://static001.geekbang.org/resource/image/db/4e/dbcb06d2c406446418778d07d917604e.png?wh=1981*1091\" alt=\"\"></p><p>这一讲，我们先来说说开源规范、文档规范和版本规范，因为 Commit 规范比较多，我们放到下一讲。至于其他规范，会在后面内容中介绍。例如日志规范，因为和日志设计结合比较紧密，我会放在日志包设计中一起讲。</p><h2>开源规范</h2><p>首先，我们来介绍下开源规范。</p><p>其实业界并没有一个官方的开源规范，实际开发中，也很少有人提这个。那么，我们为什么一定要知道开源规范呢？</p><p>原因主要有两方面：一是，开源项目在代码质量、代码规范、文档等方面，要比非开源项目要求更高，在项目开发中按照开源项目的要求来规范自己的项目，可以更好地驱动项目质量的提高；二是，一些大公司为了不重复造轮子，会要求公司团队能够将自己的项目开源，所以提前按开源标准来驱动 Go 项目开发，也会为我们日后代码开源省去不少麻烦。</p><p>一个开源项目一定需要一个开源协议，开源协议规定了你在使用开源软件时的权利和责任，也就是规定了你可以做什么，不可以做什么。所以，开源规范的第一条规范就是选择一个合适的开源协议。那么有哪些开源协议，如何选择呢？接下来，我来详细介绍下。</p><h3>开源协议概述</h3><p>首先要说明的是，只有开源项目才会用到开源协议，如果你的项目不准备开源，就用不到开源协议。但先了解一下总是没错的，以后总能用得上。</p><p>业界有上百种开源协议，每种开源协议的要求不一样，有的协议对使用条件要求比较苛刻，有的则相对比较宽松。我们没必要全都记住，只需要知道经常使用的 6 种开源协议，也就是 GPL、MPL、LGPL、Apache、BSD 和 MIT 就可以了。至于它们的介绍，你可以参考 <a href=\"https://github.com/marmotedu/geekbang-go/blob/master/%E5%BC%80%E6%BA%90%E5%8D%8F%E8%AE%AE%E4%BB%8B%E7%BB%8D.md\">开源协议介绍</a> 。</p><p>那具体如何选择适合自己的开源协议呢？你可以参考乌克兰程序员 Paul Bagwell 画的这张图：</p><p><img src=\"https://static001.geekbang.org/resource/image/61/00/61b4d5da6c8327b738e9657c6c144000.png?wh=6503*2466\" alt=\"\"></p><p>在上图中，右边的协议比左边的协议宽松，在选择时，你可以根据菱形框中的选择项从上到下进行选择。为了使你能够毫无负担地使用 IAM 项目提供的源码，我选择了最宽松的 MIT 协议。</p><p>另外，因为 Apache 是对商业应用友好的协议，使用者也可以在需要的时候修改代码来满足需要，并作为开源或商业产品发布/销售，所以大型公司的开源项目通常会采用 Apache 2.0 开源协议。</p><h3>开源规范具有哪些特点？</h3><p>那我们在参与开源项目，或者按照开源项目的要求来规范代码时，需要关注哪些方面的规范呢？</p><p>其实，在我看来，一切能让项目变得更优秀的规范，都应该属于开源规范。</p><p>开源项目的代码，除了要遵守上面所说的编码类规范和非编码类规范之外，还要遵守下面几个规范。</p><p>第一，开源项目，应该有一个高的单元覆盖率。这样，一方面可以确保第三方开发者在开发完代码之后，能够很方便地对整个项目做详细的单元测试，另一方面也能保证提交代码的质量。</p><p>第二，要确保整个代码库和提交记录中，不能出现内部 IP、内部域名、密码、密钥这类信息。否则，就会造成敏感信息外漏，可能会对我们的内部业务造成安全隐患。</p><p>第三，当我们的开源项目被别的开发者提交 pull request、issue、评论时，要及时处理，一方面可以确保项目不断被更新，另一方面也可以激发其他开发者贡献代码的积极性。</p><p>第四，好的开源项目，应该能够持续地更新功能，修复 Bug。对于一些已经结项、不维护的开源项目，需要及时地对项目进行归档，并在项目描述中加以说明。</p><p>在我看来，上面这些，是开源规范中比较重要的几点。如果你想了解详细的开源规范包括哪些内容，可以看我放在 GitHub 上的 <a href=\"https://github.com/marmotedu/geekbang-go/blob/master/%E5%BC%80%E6%BA%90%E8%A7%84%E8%8C%83%E8%AF%A6%E7%BB%86%E5%88%97%E8%A1%A8.md\">这份资料</a> 。</p><p>最后提醒你两件事：第一件，如果有条件，你可以宣传、运营开源项目，让更多的人知道、使用、贡献代码。比如，你可以在掘金、简书等平台发表文章，也可以创建 QQ、微信交流群等，都是不错的方式。第二件，如果你英文好、有时间，文档最好有中英文 2 份，优先使用英文，让来自全球的开发者都能了解、使用和参与你的项目。</p><h2>文档规范</h2><p>工作中我发现，很多开发者非常注重代码产出，但不注重文档产出。他们觉得，即使没有软件文档也没太大关系，不影响软件交付。我要说的是，这种看法是错误的！因为文档属于软件交付的一个重要组成部分，没有文档的项目很难理解、部署和使用。</p><p>因此，编写文档是一个必不可少的开发工作。那么一个项目需要编写哪些文档，又该如何编写呢？我认为项目中最需要的 3 类文档是 README文档、项目文档和 API 接口文档。</p><p>下面，我们一一来说它们的编写规范。</p><h3>README 规范</h3><p>README文档是项目的门面，它是开发者学习项目时第一个阅读的文档，会放在项目的根目录下。因为它主要是用来介绍项目的功能、安装、部署和使用的，所以它是可以规范化的。</p><p>下面，我们直接通过一个 README模板，来看一下 README 规范中的内容：</p><pre><code># 项目名称\n\n&lt;!-- 写一段简短的话描述项目 --&gt;\n\n## 功能特性\n\n&lt;!-- 描述该项目的核心功能点 --&gt;\n\n## 软件架构(可选)\n\n&lt;!-- 可以描述下项目的架构 --&gt;\n\n## 快速开始\n\n### 依赖检查\n\n&lt;!-- 描述该项目的依赖，比如依赖的包、工具或者其他任何依赖项 --&gt;\n\n### 构建\n\n&lt;!-- 描述如何构建该项目 --&gt;\n\n### 运行\n\n&lt;!-- 描述如何运行该项目 --&gt;\n\n## 使用指南\n\n&lt;!-- 描述如何使用该项目 --&gt;\n\n## 如何贡献\n\n&lt;!-- 告诉其他开发者如果给该项目贡献源码 --&gt;\n\n## 社区(可选)\n\n&lt;!-- 如果有需要可以介绍一些社区相关的内容 --&gt;\n\n## 关于作者\n\n&lt;!-- 这里写上项目作者 --&gt;\n\n## 谁在用(可选)\n\n&lt;!-- 可以列出使用本项目的其他有影响力的项目，算是给项目打个广告吧 --&gt;\n\n## 许可证\n\n&lt;!-- 这里链接上该项目的开源许可证 --&gt;\n</code></pre><p>更具体的示例，你可以参考 IAM 系统的 <a href=\"https://raw.githubusercontent.com/marmotedu/iam/master/README.md\">README.md 文件</a> 。</p><p>这里，有个在线的README生成工具，你也可以参考下：readme.so。</p><h3>项目文档规范</h3><p>项目文档包括一切需要文档化的内容，它们通常集中放在/docs 目录下。当我们在创建团队的项目文档时，通常会预先规划并创建好一些目录，用来存放不同的文档。因此，在开始 Go 项目开发之前，我们也要制定一个软件文档规范。好的文档规范有 2 个优点：易读和可以快速定位文档。</p><p>不同项目有不同的文档需求，在制定文档规范时，你可以考虑包含两类文档。</p><ul>\n<li>开发文档：用来说明项目的开发流程，比如如何搭建开发环境、构建二进制文件、测试、部署等。</li>\n<li>用户文档：软件的使用文档，对象一般是软件的使用者，内容可根据需要添加。比如，可以包括 API 文档、SDK 文档、安装文档、功能介绍文档、最佳实践、操作指南、常见问题等。</li>\n</ul><p>为了方便全球开发者和用户使用，开发文档和用户文档，可以预先规划好英文和中文 2 个版本。</p><p>为了加深你的理解，这里我们来看下实战项目的文档目录结构：</p><pre><code>docs\n├── devel                            # 开发文档，可以提前规划好，英文版文档和中文版文档\n│   ├── en-US/                       # 英文版文档，可以根据需要组织文件结构\n│   └── zh-CN                        # 中文版文档，可以根据需要组织文件结构\n│       └── development.md           # 开发手册，可以说明如何编译、构建、运行项目\n├── guide                            # 用户文档\n│   ├── en-US/                       # 英文版文档，可以根据需要组织文件结构\n│   └── zh-CN                        # 中文版文档，可以根据需要组织文件结构\n│       ├── api/                     # API文档\n│       ├── best-practice            # 最佳实践，存放一些比较重要的实践文章\n│       │   └── authorization.md\n│       ├── faq                      # 常见问题\n│       │   ├── iam-apiserver\n│       │   └── installation\n│       ├── installation             # 安装文档\n│       │   └── installation.md\n│       ├── introduction/            # 产品介绍文档\n│       ├── operation-guide          # 操作指南，里面可以根据RESTful资源再划分为更细的子目录，用来存放系统核心/全部功能的操作手册\n│       │   ├── policy.md\n│       │   ├── secret.md\n│       │   └── user.md\n│       ├── quickstart               # 快速入门\n│       │   └── quickstart.md\n│       ├── README.md                # 用户文档入口文件\n│       └── sdk                      # SDK文档\n│           └── golang.md\n└── images                           # 图片存放目录\n    └── 部署架构v1.png\n</code></pre><h3>API 接口文档规范</h3><p>接口文档又称为 API 文档，一般由后台开发人员编写，用来描述组件提供的 API 接口，以及如何调用这些 API 接口。</p><p>在项目初期，接口文档可以解耦前后端，让前后端并行开发：前端只需要按照接口文档实现调用逻辑，后端只需要按照接口文档提供功能。</p><p>当前后端都开发完成之后，我们就可以直接进行联调，提高开发效率。在项目后期，接口文档可以提供给使用者，不仅可以降低组件的使用门槛，还能够减少沟通成本。</p><p>显然，一个有固定格式、结构清晰、内容完善的接口文档，就非常重要了。那么我们该如何编写接口文档，它又有什么规范呢？</p><p>接口文档有四种编写方式，包括编写 Word 格式文档、借助工具编写、通过注释生成和编写 Markdown 格式文档。具体的实现方式见下表：</p><p><img src=\"https://static001.geekbang.org/resource/image/91/63/912fe30a70df0866d168ef1c0a50cb63.jpeg?wh=1920*1080\" alt=\"\"></p><p>其中，通过注释生成和编写 Markdown 格式文档这 2 种方式用得最多。在这个专栏，我采用编写 Markdown 格式文档的方式，原因如下：</p><ul>\n<li>相比通过注释生成的方式，编写 Markdown 格式的接口文档，能表达更丰富的内容和格式，不需要在代码中添加大量注释。</li>\n<li>相比 Word 格式的文档，Markdown 格式文档占用的空间更小，能够跟随代码仓库一起发布，方便 API 文档的分发和查找。</li>\n<li>相比在线 API 文档编写工具，Markdown 格式的文档免去了第三方平台依赖和网络的限制。</li>\n</ul><p>API 接口文档又要遵循哪些规范呢？其实，一个规范的 API 接口文档，通常需要包含一个完整的 API 接口介绍文档、API 接口变更历史文档、通用说明、数据结构说明、错误码描述和 API 接口使用文档。API 接口使用文档中需要包含接口描述、请求方法、请求参数、输出参数和请求示例。</p><p>当然，根据不同的项目需求，API 接口文档会有不同的格式和内容。我以这门课的实战项目采用的 API 接口文档规范为例，和你解释下。</p><p>接口文档拆分为以下几个 Markdown 文件，并存放在目录 <a href=\"https://github.com/marmotedu/iam/tree/v1.0.0/docs/guide/zh-CN/api\">docs/guide/zh-CN/api</a> 中：</p><ul>\n<li><a href=\"https://github.com/marmotedu/iam/blob/master/docs/guide/zh-CN/api/README.md\">README.md</a> ：API 接口介绍文档，会分类介绍 IAM 支持的 API 接口，并会存放相关 API 接口文档的链接，方便开发者查看。</li>\n<li><a href=\"https://github.com/marmotedu/iam/blob/master/docs/guide/zh-CN/api/CHANGELOG.md\">CHANGELOG.md</a> ：API 接口文档变更历史，方便进行历史回溯，也可以使调用者决定是否进行功能更新和版本更新。</li>\n<li><a href=\"https://github.com/marmotedu/iam/blob/master/docs/guide/zh-CN/api/generic.md\">generic.md</a> ：用来说明通用的请求参数、返回参数、认证方法和请求方法等。</li>\n<li><a href=\"https://github.com/marmotedu/iam/blob/master/docs/guide/zh-CN/api/struct.md\">struct.md</a> ：用来列出接口文档中使用的数据结构。这些数据结构可能被多个 API 接口使用，会在 user.md、secret.md、policy.md 文件中被引用。</li>\n<li><a href=\"https://github.com/marmotedu/iam/blob/master/docs/guide/zh-CN/api/user.md\">user.md</a> 、 <a href=\"https://github.com/marmotedu/iam/blob/master/docs/guide/zh-CN/api/secret.md\">secret.md</a> 、 <a href=\"https://github.com/marmotedu/iam/blob/master/docs/guide/zh-CN/api/policy.md\">policy.md</a> ：API 接口文档，相同 REST 资源的接口会存放在一个文件中，以 REST 资源名命名文档名。</li>\n<li><a href=\"https://github.com/marmotedu/iam/blob/master/docs/guide/zh-CN/api/error_code_generated.md\">error_code.md</a> ：错误码描述，通过程序自动生成。</li>\n</ul><p>这里我拿 user.md 接口文档为例，和你解释下接口文档是如何写的。<code>user.md</code> 文件记录了用户相关的接口，每个接口按顺序排列，包含如下 5 部分。</p><ul>\n<li>接口描述：描述接口实现了什么功能。</li>\n<li>请求方法：接口的请求方法，格式为 <code>HTTP 方法 请求路径</code>，例如 <code>POST /v1/users</code>。在 <strong>通用说明</strong>中的<strong>请求方法</strong>部分，会说明接口的请求协议和请求地址。</li>\n<li>输入参数：接口的输入字段，它又分为 Header 参数、Query 参数、Body 参数、Path 参数。每个字段通过：<strong>参数名称</strong>、<strong>必选</strong>、<strong>类型</strong> 和 <strong>描述</strong> 4 个属性来描述。如果参数有限制或者默认值，可以在描述部分注明。</li>\n<li>输出参数：接口的返回字段，每个字段通过 <strong>参数名称</strong>、<strong>类型</strong> 和 <strong>描述</strong> 3 个属性来描述。</li>\n<li>请求示例：一个真实的 API 接口请求和返回示例。</li>\n</ul><p>如果掌握了这些内容之后，你还想了解更详细的 API 接口文档规范，可以参考这个 <a href=\"https://github.com/marmotedu/iam/tree/master/docs/guide/zh-CN/api\">链接</a> 。</p><h2>版本规范</h2><p>在做 Go 项目开发时，我建议你把所有组件都加入版本机制。原因主要有两个：一是通过版本号，我们可以很明确地知道组件是哪个版本，从而定位到该组件的功能和代码，方便我们定位问题。二是发布组件时携带版本号，可以让使用者知道目前的项目进度，以及使用版本和上一个版本的功能差别等。</p><p>目前业界主流的版本规范是语义化版本规范，也是 IAM 系统采用的版本规范。那什么是语义化版本规范呢？</p><h3>什么是语义化版本规范（SemVer）？</h3><p>语义化版本规范（SemVer，Semantic Versioning）是 GitHub 起草的一个具有指导意义的、统一的版本号表示规范。它规定了版本号的表示、增加和比较方式，以及不同版本号代表的含义。</p><p>在这套规范下，版本号及其更新方式包含了相邻版本间的底层代码和修改内容的信息。语义化版本格式为：<code>主版本号.次版本号.修订号（X.Y.Z）</code>，其中 X、Y 和 Z 为非负的整数，且禁止在数字前方补零。</p><p>版本号可按以下规则递增：</p><ul>\n<li>主版本号（MAJOR）：当做了不兼容的 API 修改。</li>\n<li>次版本号（MINOR）：当做了向下兼容的功能性新增及修改。这里有个不成文的约定需要你注意，偶数为稳定版本，奇数为开发版本。</li>\n<li>修订号（PATCH）：当做了向下兼容的问题修正。</li>\n</ul><p>例如，<code>v1.2.3</code> 是一个语义化版本号，版本号中每个数字的具体含义见下图：</p><p><img src=\"https://static001.geekbang.org/resource/image/29/2b/29803c34698fee8a1e7e2c54cc77a92b.png?wh=1131*675\" alt=\"\"></p><p>你可能还看过这么一种版本号：<code>v1.2.3-alpha</code>。这其实是把先行版本号（Pre-release）和版本编译元数据，作为延伸加到了<code>主版本号.次版本号.修订号</code>的后面，格式为 <code>X.Y.Z[-先行版本号][+版本编译元数据]</code>，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/22/33/221ec1a06f4b0byy0716cb1ce5e82f33.png?wh=1841*744\" alt=\"\"></p><p>我们来分别看下先行版本号和版本编译元数据是什么意思。</p><p>先行版本号意味着，该版本不稳定，可能存在兼容性问题，格式为：<code>X.Y.Z-[一连串以句点分隔的标识符]</code> ，比如下面这几个例子：</p><pre><code>1.0.0-alpha\n1.0.0-alpha.1\n1.0.0-0.3.7\n1.0.0-x.7.z.92\n</code></pre><p>编译版本号，一般是编译器在编译过程中自动生成的，我们只定义其格式，并不进行人为控制。下面是一些编译版本号的示例：</p><pre><code>1.0.0-alpha+001\n1.0.0+20130313144700\n1.0.0-beta+exp.sha.5114f85\n</code></pre><p>注意，<strong>先行版本号和编译版本号只能是字母、数字，且不可以有空格</strong>。</p><h3>语义化版本控制规范</h3><p>语义化版本控制规范比较多，这里我给你介绍几个比较重要的。如果你需要了解更详细的规范，可以参考 <a href=\"https://semver.org/lang/zh-CN/\">这个链接</a> 的内容。</p><ul>\n<li>标记版本号的软件发行后，禁止改变该版本软件的内容，任何修改都必须以新版本发行。</li>\n<li>主版本号为零（0.y.z）的软件处于开发初始阶段，一切都可能随时被改变，这样的公共 API 不应该被视为稳定版。1.0.0 的版本号被界定为第一个稳定版本，之后的所有版本号更新都基于该版本进行修改。</li>\n<li>修订号 Z（x.y.Z | x &gt; 0）必须在只做了向下兼容的修正时才递增，这里的修正其实就是 Bug 修复。</li>\n<li>次版本号 Y（x.Y.z | x &gt; 0）必须在有向下兼容的新功能出现时递增，在任何公共 API 的功能被标记为弃用时也必须递增，当有改进时也可以递增。其中可以包括修订级别的改变。每当次版本号递增时，修订号必须归零。</li>\n<li>主版本号 X（X.y.z | X &gt; 0）必须在有任何不兼容的修改被加入公共 API 时递增。其中可以包括次版本号及修订级别的改变。每当主版本号递增时，次版本号和修订号必须归零。</li>\n</ul><h3>如何确定版本号？</h3><p>说了这么多，我们到底该如何确定版本号呢？</p><p>这里我给你总结了这么几个经验：</p><p>第一，在实际开发的时候，我建议你使用 0.1.0 作为第一个开发版本号，并在后续的每次发行时递增次版本号。</p><p>第二，当我们的版本是一个稳定的版本，并且第一次对外发布时，版本号可以定为 1.0.0。</p><p>第三，当我们严格按照 Angular commit message 规范提交代码时，版本号可以这么来确定：</p><ul>\n<li>fix 类型的 commit 可以将修订号+1。</li>\n<li>feat 类型的 commit 可以将次版本号+1。</li>\n<li>带有 BREAKING CHANGE 的 commit 可以将主版本号+1。</li>\n</ul><h2>总结</h2><p>一套好的规范，就是一个项目开发的“规矩”，它可以确保整个项目的可维护性、可阅读性，减少 Bug 数等。</p><p>一个项目的规范设计主要包括编码类和非编码类这两类规范。今天我们一起学习了开源规范、文档规范和版本规范，现在我们回顾一下重点内容吧。</p><ol>\n<li>新开发的项目最好按照开源标准来规范，以驱动其成为一个高质量的项目。</li>\n<li>开发之前，最好提前规范好文档目录，并选择一种合适的方式来编写 API 文档。在这门课的实战项目中，我采用的是 Markdown 格式，也推荐你使用这种方式。</li>\n<li>项目要遵循版本规范，目前业界主流的版本规范是语义化版本规范，也是我推荐的版本规范。</li>\n</ol><p>今天示范用到的项目规范示例，我把详细版放在这里，方便你随时查看：<a href=\"https://github.com/marmotedu/geekbang-go/blob/master/%E5%BC%80%E6%BA%90%E8%A7%84%E8%8C%83%E8%AF%A6%E7%BB%86%E5%88%97%E8%A1%A8.md\">开源规范</a> 、 <a href=\"https://raw.githubusercontent.com/marmotedu/iam/master/README.md\">README规范</a> 、 <a href=\"https://github.com/marmotedu/iam/tree/master/docs/guide/zh-CN/api\">API接口文档规范</a> 。</p><h2>课后练习</h2><ol>\n<li>除了今天我们介绍的这些非编码类规范之外，你在开发中还用到过哪些规范?</li>\n<li>试着用这一讲介绍的API文档规范，书写一份你当前项目的API接口。</li>\n</ol><p>期待在留言区看到你的思考和答案，也欢迎和我一起探讨关于规范设计的问题，我们下一讲见！</p>","neighbors":{"left":{"article_title":"03 | 项目部署：如何快速部署 IAM 系统？","id":378082},"right":{"article_title":"05 | 规范设计（下）：commit 信息风格迥异、难以阅读，如何规范？","id":380989}}},{"article_id":380989,"article_title":"05 | 规范设计（下）：commit 信息风格迥异、难以阅读，如何规范？","article_content":"<p>你好，我是孔令飞。今天，我们继续学习非编码类规范中的 Commit 规范。</p><p>我们在做代码开发时，经常需要提交代码，提交代码时需要填写 Commit Message（提交说明），否则就不允许提交。</p><p>而在实际开发中，我发现每个研发人员提交 Commit Message 的格式可以说是五花八门，有用中文的、有用英文的，甚至有的直接填写“11111”。这样的 Commit Message，时间久了可能连提交者自己都看不懂所表述的修改内容，更别说给别人看了。</p><p>所以在 Go 项目开发时，一个好的 Commit Message 至关重要：</p><ul>\n<li>可以使自己或者其他开发人员能够<strong>清晰地知道每个 commit 的变更内容</strong>，方便快速浏览变更历史，比如可以直接略过文档类型或者格式化类型的代码变更。</li>\n<li>可以基于这些 Commit Message <strong>进行过滤查找</strong>，比如只查找某个版本新增的功能：<code>git log --oneline --grep \"^feat|^fix|^perf\"</code>。</li>\n<li>可以基于规范化的 Commit Message <strong>生成 Change Log</strong>。</li>\n<li>可以依据某些类型的 Commit Message <strong>触发构建或者发布流程</strong>，比如当 type 类型为 feat、fix 时我们才触发 CI 流程。</li>\n<li><strong>确定语义化版本的版本号</strong>。比如 <code>fix</code> 类型可以映射为 PATCH 版本，<code>feat</code> 类型可以映射为 MINOR 版本。带有 <code>BREAKING CHANGE</code> 的 commit，可以映射为 MAJOR 版本。在这门课里，我就是通过这种方式来自动生成版本号。</li>\n</ul><!-- [[[read_end]]] --><p>总结来说，一个好的 Commit Message 规范可以使 Commit Message 的可读性更好，并且可以实现自动化。那究竟如何写一个易读的 Commit Message 呢？</p><p>接下来，我们来看下如何规范 Commit Message。另外，除了 Commit Message 之外，我还会介绍跟 Commit 相关的 3 个重点，以及如何通过自动化流程来保证 Commit Message 的规范化。</p><h2>Commit Message 的规范有哪些？</h2><p>毫无疑问，我们可以根据需要自己来制定 Commit Message 规范，但是我更建议你采用开源社区中比较成熟的规范。一方面，可以避免重复造轮子，提高工作效率。另一方面，这些规范是经过大量开发者验证的，是科学、合理的。</p><p>目前，社区有多种 Commit Message 的规范，例如 jQuery、Angular 等。我将这些规范及其格式绘制成下面一张图片，供你参考：</p><p><img src=\"https://static001.geekbang.org/resource/image/16/48/1699f5c1933cfe72803dfb038152fc48.png?wh=973*172\" alt=\"\"></p><p>在这些规范中，Angular 规范在功能上能够满足开发者 commit 需求，在格式上清晰易读，目前也是用得最多的。</p><p>Angular 规范其实是一种语义化的提交规范（Semantic Commit Messages），所谓语义化的提交规范包含以下内容：</p><ul>\n<li>Commit Message 是语义化的：Commit Message 都会被归为一个有意义的类型，用来说明本次 commit 的类型。</li>\n<li>Commit Message 是规范化的：Commit Message 遵循预先定义好的规范，比如 Commit Message 格式固定、都属于某个类型，这些规范不仅可被开发者识别也可以被工具识别。</li>\n</ul><p>为了方便你理解 Angular 规范，我们直接看一个遵循 Angular 规范的 commit 历史记录，见下图：</p><p><img src=\"https://static001.geekbang.org/resource/image/e2/fe/e227e4976406daaa039438feb5affefe.png?wh=825*420\" alt=\"\"></p><p>再来看一个完整的符合 Angular 规范的 Commit Message，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/da/cb/da69572c5605556b8144eb4ee281c4cb.png?wh=1877*406\" alt=\"\"></p><p>通过上面 2 张图，我们可以看到符合 Angular Commit Message 规范的 commit 都是有一定格式，有一定语义的。</p><p>那我们该<strong>怎么写出符合 Angular 规范的 Commit Message 呢</strong>？</p><p>在 Angular 规范中，Commit Message 包含三个部分，分别是 <strong>Header</strong>、<strong>Body</strong> 和 <strong>Footer</strong>，格式如下：</p><pre><code>&lt;type&gt;[optional scope]: &lt;description&gt;\n// 空行\n[optional body]\n// 空行\n[optional footer(s)]\n</code></pre><p>其中，Header是必需的，Body和Footer可以省略。在以上规范中，<code>&lt;scope&gt;</code>必须用括号 <code>()</code> 括起来， <code>&lt;type&gt;[&lt;scope&gt;]</code> 后必须紧跟冒号 ，冒号后必须紧跟空格，2 个空行也是必需的。</p><p>在实际开发中，为了使 Commit Message 在 GitHub 或者其他 Git 工具上更加易读，我们往往会限制每行 message 的长度。根据需要，可以限制为 50/72/100 个字符，这里我将长度限制在 72 个字符以内（也有一些开发者会将长度限制为 100，你可根据需要自行选择）。</p><p>以下是一个符合 Angular 规范的 Commit Message：</p><pre><code>fix($compile): couple of unit tests for IE9\n# Please enter the Commit Message for your changes. Lines starting\n# with '#' will be ignored, and an empty message aborts the commit.\n# On branch master\n# Changes to be committed:\n# ...\n\nOlder IEs serialize html uppercased, but IE9 does not...\nWould be better to expect case insensitive, unfortunately jasmine does\nnot allow to user regexps for throw expectations.\n\nCloses #392\nBreaks foo.bar api, foo.baz should be used instead\n</code></pre><p>接下来，我们详细看看 Angular 规范中 Commit Message 的三个部分。</p><h3>Header</h3><p>Header 部分只有一行，包括三个字段：type（必选）、scope（可选）和 subject（必选）。</p><p>我们先来说 <strong>type</strong>，它用来说明 commit 的类型。为了方便记忆，我把这些类型做了归纳，它们主要可以归为 Development 和 Production 共两类。它们的含义是：</p><ul>\n<li>Development：这类修改一般是项目管理类的变更，不会影响最终用户和生产环境的代码，比如 CI 流程、构建方式等的修改。遇到这类修改，通常也意味着可以免测发布。</li>\n<li>Production：这类修改会影响最终的用户和生产环境的代码。所以对于这种改动，我们一定要慎重，并在提交前做好充分的测试。</li>\n</ul><p>我在这里列出了 Angular 规范中的常见 type 和它们所属的类别，你在提交 Commit Message 的时候，一定要注意区分它的类别。举个例子，我们在做 Code Review 时，如果遇到 Production 类型的代码，一定要认真 Review，因为这种类型，会影响到现网用户的使用和现网应用的功能。</p><p><img src=\"https://static001.geekbang.org/resource/image/89/27/89c618a7415c0c38b09d86d7f882a427.png?wh=726*511\" alt=\"\"></p><p>有这么多 type，我们该如何确定一个 commit 所属的 type 呢？这里我们可以通过下面这张图来确定。</p><p><img src=\"https://static001.geekbang.org/resource/image/35/a7/3509bd169ce285f59fbcfa6ebea75aa7.png?wh=2513*1078\" alt=\"\"></p><p>如果我们变更了应用代码，比如某个 Go 函数代码，那这次修改属于代码类。在代码类中，有 4 种具有明确变更意图的类型：feat、fix、perf 和 style；如果我们的代码变更不属于这 4 类，那就全都归为 refactor 类，也就是优化代码。</p><p>如果我们变更了非应用代码，例如更改了文档，那它属于非代码类。在非代码类中，有 3 种具有明确变更意图的类型：test、ci、docs；如果我们的非代码变更不属于这 3 类，那就全部归入到 chore 类。</p><p>Angular 的 Commit Message 规范提供了大部分的 type，在实际开发中，我们可以使用部分 type，或者扩展添加我们自己的 type。但无论选择哪种方式，<strong>我们一定要保证一个项目中的 type 类型一致。</strong></p><p>接下来，我们说说 Header 的第二个字段 <strong>scope</strong>。</p><p>scope 是用来说明 commit 的影响范围的，它必须是名词。显然，不同项目会有不同的 scope。在项目初期，我们可以设置一些粒度比较大的 scope，比如可以按组件名或者功能来设置 scope；后续，如果项目有变动或者有新功能，我们可以再用追加的方式添加新的 scope。</p><p>我们这门课采用的 scope，主要是根据组件名和功能来设置的。例如，支持 apiserver、authzserver、user 这些 scope。</p><p><strong>这里想强调的是，scope 不适合设置太具体的值</strong>。太具体的话，一方面会导致项目有太多的 scope，难以维护。另一方面，开发者也难以确定 commit 属于哪个具体的 scope，导致错放 scope，反而会使 scope 失去了分类的意义。</p><p>当然了，在指定 scope 时，也需要遵循我们预先规划的 scope，所以我们要将 scope 文档化，放在类似 devel 这类文档中。这一点你可以参考下 IAM 项目的 scope 文档： <a href=\"https://github.com/marmotedu/iam/blob/master/docs/devel/zh-CN/scope.md\">IAM commit message scope</a> 。</p><p>最后，我们再说说 <strong>subject。</strong></p><p>subject 是 commit 的简短描述，必须以动词开头、使用现在时。比如，我们可以用 change，却不能用 changed 或 changes，而且这个动词的第一个字母必须是小写。通过这个动词，我们可以明确地知道 commit 所执行的操作。此外我们还要注意，subject 的结尾不能加英文句号。</p><h3>Body</h3><p>Header 对 commit 做了高度概括，可以方便我们查看 Commit Message。那我们如何知道具体做了哪些变更呢？答案就是，可以通过 Body 部分，它是对本次 commit 的更详细描述，是可选的。</p><p>Body 部分可以分成多行，而且格式也比较自由。不过，和 Header 里的<subject>一样，它也要以动词开头，使用现在时。此外，它还必须<strong>要包括修改的动机</strong>，以及<strong>和跟上一版本相比的改动点</strong>。</subject></p><p>我在下面给出了一个范例，你可以看看：</p><pre><code>The body is mandatory for all commits except for those of scope &quot;docs&quot;. When the body is required it must be at least 20 characters long.\n</code></pre><h3>Footer</h3><p>Footer 部分不是必选的，可以根据需要来选择，主要用来说明本次 commit 导致的后果。在实际应用中，Footer 通常用来说明不兼容的改动和关闭的 Issue 列表，格式如下：</p><pre><code>BREAKING CHANGE: &lt;breaking change summary&gt;\n// 空行\n&lt;breaking change description + migration instructions&gt;\n// 空行\n// 空行\nFixes #&lt;issue number&gt;\n</code></pre><p>接下来，我给你详细说明下这两种情况：</p><ul>\n<li>不兼容的改动：如果当前代码跟上一个版本不兼容，需要在 Footer 部分，以 <code>BREAKING CHANG:</code> 开头，后面跟上不兼容改动的摘要。Footer 的其他部分需要说明变动的描述、变动的理由和迁移方法，例如：</li>\n</ul><pre><code>BREAKING CHANGE: isolate scope bindings definition has changed and\n    the inject option for the directive controller injection was removed.\n\n    To migrate the code follow the example below:\n\n    Before:\n\n    scope: {\n      myAttr: 'attribute',\n    }\n\n    After:\n\n    scope: {\n      myAttr: '@',\n    }\n    The removed `inject` wasn't generaly useful for directives so there should be no code using it.\n</code></pre><ul>\n<li>关闭的 Issue 列表：关闭的 Bug 需要在 Footer 部分新建一行，并以 Closes 开头列出，例如：<code>Closes #123</code>。如果关闭了多个 Issue，可以这样列出：<code>Closes #123, #432, #886</code>。例如:</li>\n</ul><pre><code> Change pause version value to a constant for image\n    \n    Closes #1137\n</code></pre><h3>Revert Commit</h3><p>除了 <strong>Header</strong>、<strong>Body</strong> 和 <strong>Footer 这 3 个部分，</strong>Commit Message 还有一种特殊情况：如果当前 commit 还原了先前的 commit，则应以 <code>revert:</code> 开头，后跟还原的 commit 的 Header。而且，在 Body 中必须写成 <code>This reverts commit &lt;hash&gt;</code> ，其中 hash 是要还原的 commit 的 SHA 标识。例如：</p><pre><code>revert: feat(iam-apiserver): add 'Host' option\n\nThis reverts commit 079360c7cfc830ea8a6e13f4c8b8114febc9b48a.\n</code></pre><p>为了更好地遵循 Angular 规范，建议你在提交代码时养成不用 <code>git commit -m</code>，即不用-m 选项的习惯，而是直接用 <code>git commit</code> 或者 <code>git commit -a</code> 进入交互界面编辑 Commit Message。这样可以更好地格式化 Commit Message。</p><p>但是除了 Commit Message 规范之外，在代码提交时，我们还需要关注 3 个重点内容：提交频率、合并提交和 Commit Message 修改。</p><h2>Commit 相关的 3 个重要内容</h2><p>我们先来看下提交频率。</p><h3>提交频率</h3><p>在实际项目开发中，如果是个人项目，随意 commit 可能影响不大，但如果是多人开发的项目，随意 commit 不仅会让 Commit Message 变得难以理解，还会让其他研发同事觉得你不专业。因此，我们要规定 commit 的提交频率。</p><p>那到底什么时候进行 commit 最好呢？</p><p>我认为主要可以分成两种情况。一种情况是，只要我对项目进行了修改，一通过测试就立即 commit。比如修复完一个 bug、开发完一个小功能，或者开发完一个完整的功能，测试通过后就提交。另一种情况是，我们规定一个时间，定期提交。这里我建议代码下班前固定提交一次，并且要确保本地未提交的代码，延期不超过 1 天。这样，如果本地代码丢失，可以尽可能减少丢失的代码量。</p><p>按照上面 2 种方式提交代码，你可能会觉得代码 commit 比较多，看起来比较随意。或者说，我们想等开发完一个完整的功能之后，放在一个 commit 中一起提交。这时候，我们可以在最后合并代码或者提交 Pull Request 前，执行 <code>git rebase -i</code> 合并之前的所有 commit。</p><p>那么如何合并 commit 呢？接下来，我来详细说说。</p><h3>合并提交</h3><p>合并提交，就是将多个 commit 合并为一个 commit 提交。这里，我建议你把新的 commit 合并到主干时，只保留 2~3 个 commit 记录。那具体怎么做呢？</p><p>在 Git 中，我们主要使用 git rebase 命令来合并。git rebase 也是我们日后开发需要经常使用的一个命令，所以我们一定要掌握好它的使用方法。</p><p><strong>git rebase 命令介绍</strong></p><p>git rebase 的最大作用是它可以重写历史。</p><p>我们通常会通过 <code>git rebase -i &lt;commit ID&gt;</code>使用 git rebase 命令，<code>-i</code> 参数表示交互（interactive），该命令会进入到一个交互界面中，其实就是 Vim 编辑器。在该界面中，我们可以对里面的 commit 做一些操作，交互界面如图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/c6/ac/c63a8682c03862802e5eacf1641b86ac.png?wh=1345*866\" alt=\"\"></p><p>这个交互界面会首先列出给定<code>&lt;commit ID&gt;</code>之前（不包括<commit id=\"\">，越下面越新）的所有 commit，每个 commit 前面有一个操作命令，默认是 pick。我们可以选择不同的 commit，并修改 commit 前面的命令，来对该 commit 执行不同的变更操作。</commit></p><p>git rebase 支持的变更操作如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/5f/f2/5f5a79a5d2bde029d4de9d98026ef3f2.png?wh=629*393\" alt=\"\"></p><p>在上面的 7 个命令中，squash 和 fixup 可以用来合并 commit。例如用 squash 来合并，我们只需要把要合并的 commit 前面的动词，改成 squash（或者 s）即可。你可以看看下面的示例：</p><pre><code>pick 07c5abd Introduce OpenPGP and teach basic usage\ns de9b1eb Fix PostChecker::Post#urls\ns 3e7ee36 Hey kids, stop all the highlighting\npick fa20af3 git interactive rebase, squash, amend\n</code></pre><p>rebase 后，第 2 行和第 3 行的 commit 都会合并到第 1 行的 commit。这个时候，我们提交的信息会同时包含这三个 commit 的提交信息：</p><pre><code># This is a combination of 3 commits.\n# The first commit's message is:\nIntroduce OpenPGP and teach basic usage\n\n# This is the 2ndCommit Message:\nFix PostChecker::Post#urls\n\n# This is the 3rdCommit Message:\nHey kids, stop all the highlighting\n</code></pre><p>如果我们将第 3 行的 squash 命令改成 fixup 命令：</p><pre><code>pick 07c5abd Introduce OpenPGP and teach basic usage\ns de9b1eb Fix PostChecker::Post#urls\nf 3e7ee36 Hey kids, stop all the highlighting\npick fa20af3 git interactive rebase, squash, amend\n</code></pre><p>rebase 后，还是会生成两个 commit，第 2 行和第 3 行的 commit，都合并到第 1 行的 commit。但是，新的提交信息里面，第 3 行 commit 的提交信息会被注释掉：</p><pre><code># This is a combination of 3 commits.\n# The first commit's message is:\nIntroduce OpenPGP and teach basic usage\n\n# This is the 2ndCommit Message:\nFix PostChecker::Post#urls\n\n# This is the 3rdCommit Message:\n# Hey kids, stop all the highlighting\n</code></pre><p>除此之外，我们在使用 git rebase 进行操作的时候，还需要注意以下几点：</p><ul>\n<li>删除某个 commit 行，则该 commit 会丢失掉。</li>\n<li>删除所有的 commit 行，则 rebase 会被终止掉。</li>\n<li>可以对 commits 进行排序，git 会从上到下进行合并。</li>\n</ul><p>为了加深你的理解，我给你完整演示一遍合并提交。</p><p><strong>合并提交操作示例</strong></p><p>假设我们需要研发一个新的模块：user，用来在平台里进行用户的注册、登录、注销等操作，当模块完成开发和测试后，需要合并到主干分支，具体步骤如下。</p><p><strong>首先，我们新建一个分支</strong>。我们需要先基于 master 分支新建并切换到 feature 分支：</p><pre><code>$ git checkout -b feature/user\nSwitched to a new branch 'feature/user'\n</code></pre><p>这是我们的所有 commit 历史：</p><pre><code>$ git log --oneline\n7157e9e docs(docs): append test line 'update3' to README.md\n5a26aa2 docs(docs): append test line 'update2' to README.md\n55892fa docs(docs): append test line 'update1' to README.md\n89651d4 docs(doc): add README.md\n</code></pre><p><strong>接着，我们在</strong> <code>feature/user</code>分支进行功能的开发和测试，并遵循规范提交 commit，功能开发并测试完成后，Git 仓库的 commit 记录如下：</p><pre><code>$ git log --oneline\n4ee51d6 docs(user): update user/README.md\n176ba5d docs(user): update user/README.md\n5e829f8 docs(user): add README.md for user\nf40929f feat(user): add delete user function\nfc70a21 feat(user): add create user function\n7157e9e docs(docs): append test line 'update3' to README.md\n5a26aa2 docs(docs): append test line 'update2' to README.md\n55892fa docs(docs): append test line 'update1' to README.md\n89651d4 docs(doc): add README.md\n</code></pre><p>可以看到我们提交了 5 个 commit。接下来，我们需要将 <code>feature/user</code>分支的改动合并到 master 分支，但是 5 个 commit 太多了，我们想将这些 commit 合并后再提交到 master 分支。</p><p><strong>接着，我们合并所有 commit</strong>。在上一步中，我们知道 <code>fc70a21</code>是 <code>feature/user</code>分支的第一个 commit ID，其父 commit ID 是 <code>7157e9e</code>，我们需要将<code>7157e9e</code>之前的所有分支 进行合并，这时我们可以执行：</p><pre><code>$ git rebase -i 7157e9e\n</code></pre><p>执行命令后，我们会进入到一个交互界面，在该界面中，我们可以将需要合并的 4 个 commit，都执行 squash 操作，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/6e/4e/6e41e61c27ca2a46e55e8801c47cd04e.png?wh=1097*320\" alt=\"\"></p><p>修改完成后执行<code>:wq</code> 保存，会跳转到一个新的交互页面，在该页面，我们可以编辑 Commit Message，编辑后的内容如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/73/87/73a884bac481236969ba2a219a2e9187.png?wh=1184*399\" alt=\"\"></p><p><code>#</code>开头的行是 git 的注释，我们可以忽略掉，在 rebase 后，这些行将会消失掉。修改完成后执行<code>:wq</code> 保存，就完成了合并提交操作。</p><p>除此之外，这里有 2 个点需要我们注意：</p><ul>\n<li><code>git rebase -i &lt;commid ID&gt;</code>这里的<commid id=\"\">一定要是需要合并 commit 中最旧 commit 的父 commit ID。</commid></li>\n<li>我们希望将 feature/user 分支的 5 个 commit 合并到一个 commit，在 git rebase 时，需要保证其中最新的一个 commit 是 pick 状态，这样我们才可以将其他 4 个 commit 合并进去。</li>\n</ul><p><strong>然后，我们用如下命令来检查 commits 是否成功合并</strong>。可以看到，我们成功将 5 个 commit 合并成为了一个 commit：<code>d6b17e0</code>。</p><pre><code>$ git log --oneline\nd6b17e0 feat(user): add user module with all function implements\n7157e9e docs(docs): append test line 'update3' to README.md\n5a26aa2 docs(docs): append test line 'update2' to README.md\n55892fa docs(docs): append test line 'update1' to README.md\n89651d4 docs(doc): add README.md\n</code></pre><p><strong>最后，我们就可以将 feature 分支</strong> <code>feature/user</code> 的改动合并到主干分支，从而完成新功能的开发<strong>。</strong></p><pre><code>$ git checkout master\n$ git merge feature/user\n$ git log --oneline\nd6b17e0 feat(user): add user module with all function implements\n7157e9e docs(docs): append test line 'update3' to README.md\n5a26aa2 docs(docs): append test line 'update2' to README.md\n55892fa docs(docs): append test line 'update1' to README.md\n89651d4 docs(doc): add README.md\n</code></pre><p>这里给你一个小提示，如果你有太多的 commit 需要合并，那么可以试试这种方式：先撤销过去的 commit，然后再建一个新的。</p><pre><code>$ git reset HEAD~3\n$ git add .\n$ git commit -am &quot;feat(user): add user resource&quot;\n</code></pre><p>需要说明一点：除了 commit 实在太多的时候，一般情况下我不建议用这种方法，有点粗暴，而且之前提交的 Commit Message 都要重新整理一遍。</p><h3>修改 Commit Message</h3><p>即使我们有了 Commit Message 规范，但仍然可能会遇到提交的 Commit Message 不符合规范的情况，这个时候就需要我们能够修改之前某次 commit 的 Commit Message。</p><p>具体来说，我们有两种修改方法，分别对应两种不同情况：</p><ol>\n<li>git commit --amend：修改最近一次 commit 的 message；</li>\n<li>git rebase -i：修改某次 commit 的 message。</li>\n</ol><p>接下来，我们分别来说这两种方法。</p><p><strong>git commit --amend：修改最近一次 commit 的 message</strong></p><p>有时候，我们刚提交完一个 commit，但是发现 commit 的描述不符合规范或者需要纠正，这时候，我们可以通过 <code>git commit --amend</code> 命令来修改刚刚提交 commit 的 Commit Message。具体修改步骤如下：</p><ol>\n<li>查看当前分支的日志记录。</li>\n</ol><pre><code>$ git log –oneline\n418bd4 docs(docs): append test line 'update$i' to README.md\n89651d4 docs(doc): add README.md\n</code></pre><p>可以看到，最近一次的 Commit Message 是 <code>docs(docs): append test line 'update$i' to README.md</code>，其中 <code>update$i</code> 正常应该是 <code>update1</code>。</p><ol start=\"2\">\n<li>更新最近一次提交的 Commit Message</li>\n</ol><p>在当前 Git 仓库下执行命令：<code>git commit --amend</code>，后会进入一个交互界面，在交互界面中，修改最近一次的 Commit Message，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/9e/a3/9ea39c153fccdbfd951a990e131ddea3.png?wh=1362*466\" alt=\"\"></p><p>修改完成后执行:wq 保存，退出编辑器之后，会在命令行显示，该 commit 的 message 的更新结果如下：</p><pre><code>[master 55892fa] docs(docs): append test line 'update1' to README.md\n Date: Fri Sep 18 13:40:42 2020 +0800\n 1 file changed, 1 insertion(+)\n</code></pre><ol start=\"3\">\n<li>查看最近一次的 Commit Message 是否被更新</li>\n</ol><pre><code>$ git log --oneline\n55892fa docs(docs): append test line 'update1' to README.md\n89651d4 docs(doc): add README.md\n</code></pre><p>可以看到最近一次 commit 的 message 成功被修改为期望的内容。</p><p><strong>git rebase -i：修改某次 commit 的 message</strong></p><p>如果我们想修改的 Commit Message 不是最近一次的 Commit Message，可以通过 <code>git rebase -i &lt;父 commit ID&gt;</code>命令来修改。这个命令在实际开发中使用频率比较高，我们一定要掌握。具体来说，使用它主要分为 4 步。</p><ol>\n<li>查看当前分支的日志记录。</li>\n</ol><pre><code>$ git log --oneline\n1d6289f docs(docs): append test line 'update3' to README.md\na38f808 docs(docs): append test line 'update$i' to README.md\n55892fa docs(docs): append test line 'update1' to README.md\n89651d4 docs(doc): add README.md\n</code></pre><p>可以看到倒数第 3 次提交的 Commit Message 是：<code>docs(docs): append test line 'update$i' to README.md</code>，其中 update$i 正常应该是 update2。</p><ol start=\"2\">\n<li>修改倒数第 3 次提交 commit 的 message。</li>\n</ol><p>在 Git 仓库下直接执行命令 <code>git rebase -i 55892fa</code>，然后会进入一个交互界面。在交互界面中，修改最近一次的 Commit Message。这里我们使用 reword 或者 r，保留倒数第3次的变更信息，但是修改其 message，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/9e/b9/9e8344df0dd8f66f63a307b5a6487fb9.png?wh=1319*273\" alt=\"\"></p><p>修改完成后执行<code>:wq</code> 保存，还会跳转到一个新的交互页面，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/0e/24/0ef693d6fc195ebd179b7992e0776f24.png?wh=1392*359\" alt=\"\"></p><p>修改完成后执行<code>:wq</code> 保存，退出编辑器之后，会在命令行显示该 commit 的 message 的更新结果：</p><pre><code>[detached HEAD 5a26aa2] docs(docs): append test line 'update2' to README.md\n Date: Fri Sep 18 13:45:54 2020 +0800\n 1 file changed, 1 insertion(+)\nSuccessfully rebased and updated refs/heads/master.\n</code></pre><p><code>Successfully rebased and updated refs/heads/master.</code>说明 rebase 成功，其实这里完成了两个步骤：更新 message，更新该 commit 的 HEAD 指针。</p><p>注意：这里一定要传入想要变更 Commit Message 的父 commit ID：<code>git rebase -i &lt;父 commit ID&gt;</code>。</p><ol start=\"3\">\n<li>查看倒数第 3 次 commit 的 message 是否被更新。</li>\n</ol><pre><code>$ git log --oneline\n7157e9e docs(docs): append test line 'update3' to README.md\n5a26aa2 docs(docs): append test line 'update2' to README.md\n55892fa docs(docs): append test line 'update1' to README.md\n89651d4 docs(doc): add README.md\n</code></pre><p>可以看到，倒数第 3 次 commit 的 message 成功被修改为期望的内容。</p><p>这里有两点需要你注意：</p><ul>\n<li>Commit Message 是 commit 数据结构中的一个属性，如果 Commit Message 有变更，则 commit ID 一定会变，<code>git commit --amend</code> 只会变更最近一次的 commit ID，但是 <code>git rebase -i</code> 会变更父 commit ID 之后所有提交的 commit ID。</li>\n<li>如果当前分支有未 commit 的代码，需要先执行 <code>git stash</code> 将工作状态进行暂存，当修改完成后再执行 <code>git stash pop</code> 恢复之前的工作状态。</li>\n</ul><h2>Commit Message 规范自动化</h2><p>其实，到这里我们也就意识到了一点：Commit Message 规范如果靠文档去约束，就会严重依赖开发者的代码素养，并不能真正保证提交的 commit 是符合规范的。</p><p>那么，有没有一种方式可以确保我们提交的 Commit Message 一定是符合规范的呢？有的，我们可以通过一些工具，来自动化地生成和检查 Commit Message 是否符合规范。</p><p>另外，既然 Commit Message 是规范的，那么我们能不能利用这些规范来实现一些更酷的功能呢？答案是有的，我将可以围绕着 Commit Message 实现的一些自动化功能绘制成了下面一张图。</p><p><img src=\"https://static001.geekbang.org/resource/image/87/be/87cd05c48ac90ec93c379b568a6006be.png?wh=2141*1219\" alt=\"\"></p><p>这些自动化功能可以分为以下 2 类：</p><ul>\n<li>Commit Message 生成和检查功能：生成符合 Angular 规范的 Commit Message、Commit Message 提交前检查、历史 Commit Message 检查。</li>\n<li>基于 Commit Message 自动生成 CHANGELOG 和 SemVer 的工具。</li>\n</ul><p>我们可以通过下面这 5 个工具自动的完成上面的功能：</p><ul>\n<li><a href=\"https://github.com/lintingzhen/commitizen-go\">commitizen-go</a>：使你进入交互模式，并根据提示生成 Commit Message，然后提交。</li>\n<li>commit-msg：githooks，在 commit-msg 中，指定检查的规则，commit-msg 是个脚本，可以根据需要自己写脚本实现。这门课的 commit-msg 调用了 go-gitlint 来进行检查。</li>\n<li><a href=\"https://github.com/llorllale/go-gitlint\">go-gitlint</a>：检查历史提交的 Commit Message 是否符合 Angular 规范，可以将该工具添加在 CI 流程中，确保 Commit Message 都是符合规范的。</li>\n<li><a href=\"https://github.com/arnaud-deprez/gsemver\">gsemver</a>：语义化版本自动生成工具。</li>\n<li><a href=\"https://github.com/git-chglog/git-chglog\">git-chglog</a>：根据 Commit Message 生成 CHANGELOG。</li>\n</ul><p>这些工具你先有个印象就好了，在后面的课程内容中，我会带你通过实际使用来熟悉它们的用法。</p><h2>总结</h2><p>今天我向你介绍了 Commit Message 规范，主要讲了业界使用最多的 Angular 规范。</p><p>Angular 规范中，Commit Message 包含三个部分：Header、Body 和 Footer。Header 对 commit 做了高度概括，Body 部分是对本次 commit 的更详细描述，Footer 部分主要用来说明本次 commit 导致的后果。格式如下：</p><pre><code>&lt;type&gt;[optional scope]: &lt;description&gt;\n// 空行\n[optional body]\n// 空行\n[optional footer(s)]\n</code></pre><p>另外，我们也需要控制 commit 的提交频率，比如可以在开发完一个功能、修复完一个 bug、下班前提交 commit。</p><p>最后，我们也需要掌握一些常见的提交操作，例如通过 <code>git rebase -i</code> 来合并提交 commit，通过 <code>git commit --amend</code> 或 <code>git rebase -i</code> 来修改 commit message。</p><h2>课后练习</h2><ol>\n<li>新建一个 git repository，提交 4 个符合 Angular 规范的 Commit Message，并合并前 2 次提交。</li>\n<li>使用 git-chglog 工具来生成 CHANGEOG，使用 gsemver 工具来生成语义化版本号。</li>\n</ol><p>期待在留言区看到你的思考和答案，也欢迎和我一起探讨关于规范设计的问题，我们下一讲见！</p>","neighbors":{"left":{"article_title":"04 | 规范设计（上）：项目开发杂乱无章，如何规范？","id":380033},"right":{"article_title":"06 | 目录结构设计：如何组织一个可维护、可扩展的代码目录？","id":381392}}},{"article_id":381392,"article_title":"06 | 目录结构设计：如何组织一个可维护、可扩展的代码目录？","article_content":"<p>你好，我是孔令飞。今天我们来聊聊如何设计代码的目录结构。</p><p>目录结构是一个项目的门面。很多时候，根据目录结构就能看出开发者对这门语言的掌握程度。所以，在我看来，遵循一个好的目录规范，把代码目录设计得可维护、可扩展，甚至比文档规范、Commit 规范来得更加重要。</p><p>那具体怎么组织一个好的代码目录呢？在今天这一讲，我会从 2 个维度来解答这个问题。</p><p>首先，我会介绍组织目录的一些基本原则，这些原则可以指导你去组织一个好的代码目录。然后，我会向你介绍一些具体的、优秀的目录结构。你可以通过学习它们，提炼总结出你自己的目录结构设计方法，或者你也可以直接用它们作为你的目录结构规范，也就是说结构即规范。</p><h2>如何规范目录？</h2><p>想设计好一个目录结构，我们首先要知道一个好的目录长什么样，也就是目录规范中包含哪些内容。</p><p>目录规范，通常是指我们的项目由哪些目录组成，每个目录下存放什么文件、实现什么功能，以及各个目录间的依赖关系是什么等。在我看来，一个好的目录结构至少要满足以下几个要求。</p><ul>\n<li><strong>命名清晰</strong>：目录命名要清晰、简洁，不要太长，也不要太短，目录名要能清晰地表达出该目录实现的功能，并且目录名最好用单数。一方面是因为单数足以说明这个目录的功能，另一方面可以统一规范，避免单复混用的情况。</li>\n<li><strong>功能明确</strong>：一个目录所要实现的功能应该是明确的、并且在整个项目目录中具有很高的辨识度。也就是说，当需要新增一个功能时，我们能够非常清楚地知道把这个功能放在哪个目录下。</li>\n<li><strong>全面性</strong>：目录结构应该尽可能全面地包含研发过程中需要的功能，例如文档、脚本、源码管理、API 实现、工具、第三方包、测试、编译产物等。</li>\n<li><strong>可预测性</strong>：项目规模一定是从小到大的，所以一个好的目录结构应该能够在项目变大时，仍然保持之前的目录结构。</li>\n<li><strong>可扩展性</strong>：每个目录下存放了同类的功能，在项目变大时，这些目录应该可以存放更多同类功能。举个例子，有如下目录结构：</li>\n</ul><!-- [[[read_end]]] --><pre><code>$ ls internal/\napp  pkg  README.md\n</code></pre><p>internal 目录用来实现内部代码，app 和 pkg 目录下的所有文件都属于内部代码。如果 internal 目录不管项目大小，永远只有 2 个文件 app 和 pkg，那么就说明 internal 目录是不可扩展的。</p><p>相反，如果 internal 目录下直接存放每个组件的源码目录（一个项目可以由一个或多个组件组成），当项目变大、组件增多时，可以将新增加的组件代码存放到 internal 目录，这时 internal 目录就是可扩展的。例如：</p><pre><code>$ ls internal/\napiserver  authzserver  iamctl  pkg  pump  watcher\n</code></pre><p>刚才我讲了目录结构的总体规范，现在来看 2 个具体的、可以作为目录规范的目录结构。</p><p>通常，<strong>根据功能，我们可以将目录结构分为结构化目录结构和平铺式目录结构两种</strong>。结构化目录结构主要用在 Go 应用中，相对来说比较复杂；而平铺式目录结构主要用在 Go 包中，相对来说比较简单。</p><p>因为平铺式目录结构比较简单，所以接下来先介绍它。</p><h2>平铺式目录结构</h2><p>一个 Go 项目可以是一个应用，也可以是一个代码框架/库，当项目是代码框架/库时，比较适合采用平铺式目录结构。</p><p>平铺方式就是在项目的根目录下存放项目的代码，整个目录结构看起来更像是一层的，这种方式在很多框架/库中存在，使用这种方式的好处是引用路径长度明显减少，比如 <code>github.com/marmotedu/log/pkg/options</code>，可缩短为 <code>github.com/marmotedu/log/options</code>。例如 log 包 <code>github.com/golang/glog</code> 就是平铺式的，目录如下：</p><pre><code>$ ls glog/\nglog_file.go  glog.go  glog_test.go  LICENSE  README\n</code></pre><p>接下来，我们来学习结构化目录结构，它比较适合 Go 应用，也比较复杂。</p><h2>结构化目录结构</h2><p>当前 Go 社区比较推荐的结构化目录结构是 <a href=\"https://github.com/golang-standards/project-layout\">project-layout</a> 。虽然它并不是官方和社区的规范，但因为组织方式比较合理，被很多 Go 开发人员接受。所以，我们可以把它当作是一个事实上的规范。</p><p>首先，我们来看下在开发一个 Go 项目时，通常应该包含的功能。这些功能内容比较多，我放在了 GitHub 的 <a href=\"https://github.com/marmotedu/geekbang-go/blob/master/Go%E9%A1%B9%E7%9B%AE%E9%80%9A%E5%B8%B8%E5%8C%85%E5%90%AB%E7%9A%84%E5%8A%9F%E8%83%BD.md\">Go项目通常包含的功能</a> 里，我们设计的目录结构应该能够包含这些功能。</p><p>我结合 project-layout，以及上面列出的 Go 项目常见功能，总结出了一套 Go 的代码结构组织方式，也就是 IAM 项目使用的目录结构。这种方式保留了 project-layout 优势的同时，还加入了一些我个人的理解，希望为你提供一个拿来即用的目录结构规范。</p><p>接下来，我们一起看看这门课的实战项目所采用的 Go 目录结构。因为实战项目目录比较多，这里只列出了一些重要的目录和文件，你可以快速浏览以加深理解。</p><pre><code>├── api\n│   ├── openapi\n│   └── swagger\n├── build\n│   ├── ci\n│   ├── docker\n│   │   ├── iam-apiserver\n│   │   ├── iam-authz-server\n│   │   └── iam-pump\n│   ├── package\n├── CHANGELOG\n├── cmd\n│   ├── iam-apiserver\n│   │   └── apiserver.go\n│   ├── iam-authz-server\n│   │   └── authzserver.go\n│   ├── iamctl\n│   │   └── iamctl.go\n│   └── iam-pump\n│       └── pump.go\n├── configs\n├── CONTRIBUTING.md\n├── deployments\n├── docs\n│   ├── devel\n│   │   ├── en-US\n│   │   └── zh-CN\n│   ├── guide\n│   │   ├── en-US\n│   │   └── zh-CN\n│   ├── images\n│   └── README.md\n├── examples\n├── githooks\n├── go.mod\n├── go.sum\n├── init\n├── internal\n│   ├── apiserver\n│   │   ├── api\n│   │   │   └── v1\n│   │   │       └── user\n│   │   ├── apiserver.go\n│   │   ├── options\n│   │   ├── service\n│   │   ├── store\n│   │   │   ├── mysql\n│   │   │   ├── fake\n│   │   └── testing\n│   ├── authzserver\n│   │   ├── api\n│   │   │   └── v1\n│   │   │       └── authorize\n│   │   ├── options\n│   │   ├── store\n│   │   └── testing\n│   ├── iamctl\n│   │   ├── cmd\n│   │   │   ├── completion\n│   │   │   ├── user\n│   │   └── util\n│   ├── pkg\n│   │   ├── code\n│   │   ├── options\n│   │   ├── server\n│   │   ├── util\n│   │   └── validation\n├── LICENSE\n├── Makefile\n├── _output\n│   ├── platforms\n│   │   └── linux\n│   │       └── amd64\n├── pkg\n│   ├── util\n│   │   └── genutil\n├── README.md\n├── scripts\n│   ├── lib\n│   ├── make-rules\n├── test\n│   ├── testdata\n├── third_party\n│   └── forked\n└── tools\n</code></pre><p>看到这一长串目录是不是有些晕？没关系，这里我们一起给这个大目录分下类，然后再具体看看每一类目录的作用，你就清楚了。</p><p>在我看来，一个 Go 项目包含 3 大部分：Go 应用 、项目管理和文档。所以，我们的项目目录也可以分为这 3 大类。同时，Go 应用又贯穿开发阶段、测试阶段和部署阶段，相应的应用类的目录，又可以按开发流程分为更小的子类。当然了，这些是我建议的目录，Go 项目目录中还有一些不建议的目录。所以整体来看，我们的目录结构可以按下图所示的方式来分类：</p><p><img src=\"https://static001.geekbang.org/resource/image/94/a3/94e521c6eb884096ea107fc4c36f30a3.png?wh=2248x1832\" alt=\"\"></p><p>接下来你就先专心跟着我走一遍每个目录、每个文件的作用，等你下次组织代码目录的时候，可以再回过头来看看，那时你一定会理解得更深刻。</p><h3>Go 应用 ：主要存放前后端代码</h3><p>首先，我们来说说开发阶段所涉及到的目录。我们开发的代码包含前端代码和后端代码，可以分别存放在前端目录和后端目录中。</p><ol>\n<li>/web</li>\n</ol><p>前端代码存放目录，主要用来存放Web静态资源，服务端模板和单页应用（SPAs）。</p><ol start=\"2\">\n<li>/cmd</li>\n</ol><p>一个项目有很多组件，可以把组件 main 函数所在的文件夹统一放在<code>/cmd</code> 目录下，例如：</p><pre><code>$ ls cmd/\ngendocs  geniamdocs  genman  genswaggertypedocs  genyaml  iam-apiserver  iam-authz-server  iamctl  iam-pump\n\n$ ls cmd/iam-apiserver/\napiserver.go\n</code></pre><p>每个组件的目录名应该跟你期望的可执行文件名是一致的。这里要保证 <code>/cmd/&lt;组件名&gt;</code> 目录下不要存放太多的代码，如果你认为代码可以导入并在其他项目中使用，那么它应该位于 /pkg 目录中。如果代码不是可重用的，或者你不希望其他人重用它，请将该代码放到 /internal 目录中。</p><ol start=\"3\">\n<li>/internal</li>\n</ol><p>存放<strong>私有应用</strong>和库代码。如果一些代码，你不希望在其他应用和库中被导入，可以将这部分代码放在<code>/internal</code> 目录下。</p><p>在引入其它项目 internal 下的包时，Go 语言会在编译时报错：</p><pre><code>An import of a path containing the element “internal” is disallowed\nif the importing code is outside the tree rooted at the parent of the\n&quot;internal&quot; directory.\n</code></pre><p>可以通过 Go 语言本身的机制来约束其他项目 import 项目内部的包。<code>/internal</code> 目录建议包含如下目录：</p><ul>\n<li>/internal/apiserver：该目录中存放真实的应用代码。这些应用的共享代码存放在<code>/internal/pkg</code> 目录下。</li>\n<li>/internal/pkg：存放项目内可共享，项目外不共享的包。这些包提供了比较基础、通用的功能，例如工具、错误码、用户验证等功能。</li>\n</ul><p>我的建议是，一开始将所有的共享代码存放在/<code>internal/pkg</code> 目录下，当该共享代码做好了对外开发的准备后，再转存到<code>/pkg</code>目录下。</p><p>下面，我详细介绍下 IAM 项目的 <code>internal</code>目录 ，来加深你对 <code>internal</code> 的理解，目录结构如下：</p><pre><code>├── apiserver\n│   ├── api\n│   │   └── v1\n│   │       └── user\n│   ├── options\n│   ├── config\n│   ├── service\n│   │   └── user.go\n│   ├── store\n│   │   ├── mysql\n│   │   │   └── user.go\n│   │   ├── fake\n│   └── testing\n├── authzserver\n│   ├── api\n│   │   └── v1\n│   ├── options\n│   ├── store\n│   └── testing\n├── iamctl\n│   ├── cmd\n│   │   ├── cmd.go\n│   │   ├── info\n└── pkg\n    ├── code\n    ├── middleware\n    ├── options\n    └── validation\n</code></pre><p>/internal 目录大概分为 3 类子目录：</p><ul>\n<li>/internal/pkg：内部共享包存放的目录。</li>\n<li>/internal/authzserver、/internal/apiserver、/internal/pump、/internal/iamctl：应用目录，里面包含应用程序的实现代码。</li>\n<li>/internal/iamctl：对于一些大型项目，可能还会需要一个客户端工具。</li>\n</ul><p>在每个应用程序内部，也会有一些目录结构，这些目录结构主要根据功能来划分：</p><ul>\n<li>/internal/apiserver/api/v1：HTTP API 接口的具体实现，主要用来做 HTTP 请求的解包、参数校验、业务逻辑处理、返回。注意这里的业务逻辑处理应该是轻量级的，如果业务逻辑比较复杂，代码量比较多，建议放到 /internal/apiserver/service 目录下。该源码文件主要用来串流程。</li>\n<li>/internal/apiserver/options：应用的 command flag。</li>\n<li>/internal/apiserver/config：根据命令行参数创建应用配置。</li>\n<li>/internal/apiserver/service：存放应用复杂业务处理代码。</li>\n<li>/internal/apiserver/store/mysql：一个应用可能要持久化的存储一些数据，这里主要存放跟数据库交互的代码，比如 Create、Update、Delete、Get、List 等。</li>\n</ul><p>/internal/pkg 目录存放项目内可共享的包，通常可以包含如下目录：</p><ul>\n<li>/internal/pkg/code：项目业务 Code 码。</li>\n<li>/internal/pkg/validation：一些通用的验证函数。</li>\n<li>/internal/pkg/middleware：HTTP 处理链。</li>\n</ul><ol start=\"4\">\n<li>/pkg</li>\n</ol><p>/pkg 目录是 Go 语言项目中非常常见的目录，我们几乎能够在所有知名的开源项目（非框架）中找到它的身影，例如 Kubernetes、Prometheus、Moby、Knative 等。</p><p>该目录中存放可以被外部应用使用的代码库，其他项目可以直接通过 import 导入这里的代码。所以，我们在将代码库放入该目录时一定要慎重。</p><ol start=\"5\">\n<li>/vendor</li>\n</ol><p>项目依赖，可通过 go mod vendor 创建。需要注意的是，如果是一个 Go 库，不要提交 vendor 依赖包。</p><ol start=\"6\">\n<li>/third_party</li>\n</ol><p>外部帮助工具，分支代码或其他第三方应用（例如Swagger UI）。比如我们 fork 了一个第三方 go 包，并做了一些小的改动，我们可以放在目录/third_party/forked 下。一方面可以很清楚的知道该包是 fork 第三方的，另一方面又能够方便地和 upstream 同步。</p><h3>Go 应用：主要存放测试相关的文件和代码</h3><p>接着，我们再来看下测试阶段相关的目录，它可以存放测试相关的文件。</p><ol start=\"7\">\n<li>/test</li>\n</ol><p>用于存放其他外部测试应用和测试数据。/test 目录的构建方式比较灵活：对于大的项目，有一个数据子目录是有意义的。例如，如果需要 Go 忽略该目录中的内容，可以使用/test/data 或/test/testdata 目录。</p><p>需要注意的是，<strong>Go 也会忽略以“.”或 “_” 开头的目录或文件。</strong>这样在命名测试数据目录方面，可以具有更大的灵活性。</p><h3>Go 应用：存放跟应用部署相关的文件</h3><p>接着，我们再来看下与部署阶段相关的目录，这些目录可以存放部署相关的文件。</p><ol start=\"8\">\n<li>/configs</li>\n</ol><p>这个目录用来配置文件模板或默认配置。例如，可以在这里存放 confd 或 consul-template 模板文件。这里有一点要注意，配置中不能携带敏感信息，这些敏感信息，我们可以用占位符来替代，例如：</p><pre><code>apiVersion: v1    \nuser:    \n  username: ${CONFIG_USER_USERNAME} # iam 用户名    \n  password: ${CONFIG_USER_PASSWORD} # iam 密码\n</code></pre><ol start=\"9\">\n<li>/deployments</li>\n</ol><p>用来存放 Iaas、PaaS 系统和容器编排部署配置和模板（Docker-Compose，Kubernetes/Helm，Mesos，Terraform，Bosh）。在一些项目，特别是用 Kubernetes 部署的项目中，这个目录可能命名为 deploy。</p><p>为什么要将这类跟 Kubernetes 相关的目录放到目录结构中呢？主要是因为当前软件部署基本都在朝着容器化的部署方式去演进。</p><ol start=\"10\">\n<li>/init</li>\n</ol><p>存放初始化系统（systemd，upstart，sysv）和进程管理配置文件（runit，supervisord）。比如 sysemd 的 unit 文件。这类文件，在非容器化部署的项目中会用到。</p><h3>项目管理：存放用来管理 Go 项目的各类文件</h3><p>在做项目开发时，还有些目录用来存放项目管理相关的文件，这里我们一起来看下。</p><ol start=\"11\">\n<li>/Makefile</li>\n</ol><p>虽然 Makefile 是一个很老的项目管理工具，但它仍然是最优秀的项目管理工具。所以，一个 Go 项目在其根目录下应该有一个 Makefile 工具，用来对项目进行管理，Makefile 通常用来执行静态代码检查、单元测试、编译等功能。其他常见功能，你可以参考这里： <a href=\"https://github.com/marmotedu/geekbang-go/blob/master/Makefile%E5%B8%B8%E8%A7%81%E7%AE%A1%E7%90%86%E5%86%85%E5%AE%B9.md\">Makefile常见管理内容</a> 。</p><p>我还有一条建议：直接执行 make 时，执行如下各项 <code>format -&gt; lint -&gt; test -&gt; build</code>，如果是有代码生成的操作，还可能需要首先生成代码 <code>gen -&gt; format -&gt; lint -&gt; test -&gt; build</code>。</p><p>在实际开发中，我们可以将一些重复性的工作自动化，并添加到 Makefile 文件中统一管理。</p><ol start=\"12\">\n<li>/scripts</li>\n</ol><p>该目录主要用来存放脚本文件，实现构建、安装、分析等不同功能。不同项目，里面可能存放不同的文件，但通常可以考虑包含以下 3 个目录：</p><ul>\n<li>/scripts/make-rules：用来存放 makefile 文件，实现/Makefile 文件中的各个功能。Makefile 有很多功能，为了保持它的简洁，我建议你将各个功能的具体实现放在<code>/scripts/make-rules</code> 文件夹下。</li>\n<li>/scripts/lib：shell 库，用来存放 shell 脚本。一个大型项目中有很多自动化任务，比如发布、更新文档、生成代码等，所以要写很多 shell 脚本，这些 shell 脚本会有一些通用功能，可以抽象成库，存放在<code>/scripts/lib</code> 目录下，比如 logging.sh，util.sh 等。</li>\n<li>/scripts/install：如果项目支持自动化部署，可以将自动化部署脚本放在此目录下。如果部署脚本简单，也可以直接放在/scripts 目录下。</li>\n</ul><p>另外，shell 脚本中的函数名，建议采用语义化的命名方式，例如 <code>iam::log::info</code> 这种语义化的命名方式，可以使调用者轻松的辨别出函数的功能类别，便于函数的管理和引用。在Kubernetes 的脚本中，就大量采用了这种命名方式。</p><ol start=\"13\">\n<li>/build</li>\n</ol><p>这里存放安装包和持续集成相关的文件。这个目录下有 3 个大概率会使用到的目录，在设计目录结构时可以考虑进去。</p><ul>\n<li>/build/package：存放容器（Docker）、系统（deb, rpm, pkg）的包配置和脚本。</li>\n<li>/build/ci：存放 CI（travis，circle，drone）的配置文件和脚本。</li>\n<li>/build/docker：存放子项目各个组件的 Dockerfile 文件。</li>\n</ul><ol start=\"14\">\n<li>/tools</li>\n</ol><p>存放这个项目的支持工具。这些工具可导入来自/pkg 和/internal 目录的代码。</p><ol start=\"15\">\n<li>/githooks</li>\n</ol><p>Git 钩子。比如，我们可以将 commit-msg 存放在该目录。</p><ol start=\"16\">\n<li>/assets</li>\n</ol><p>项目使用的其他资源(图片、CSS、JavaScript 等)。</p><ol start=\"17\">\n<li>/website</li>\n</ol><p>如果你不使用 GitHub 页面，那么可以在这里放置项目网站相关的数据。</p><h3>文档：主要存放项目的各类文档</h3><p>一个项目，也包含一些文档，这些文档有很多类别，也需要一些目录来存放这些文档，这里我们也一起来看下。</p><ol start=\"18\">\n<li>/README.md</li>\n</ol><p>项目的 README 文件一般包含了项目的介绍、功能、快速安装和使用指引、详细的文档链接以及开发指引等。有时候 README 文档会比较长，为了能够快速定位到所需内容，需要添加 markdown toc 索引，可以借助工具 <a href=\"https://github.com/nochso/tocenize\">tocenize</a> 来完成索引的添加。</p><p>这里还有个建议，前面我们也介绍过 README 是可以规范化的，所以这个 README 文档，可以通过脚本或工具来自动生成。</p><ol start=\"19\">\n<li>/docs</li>\n</ol><p>存放设计文档、开发文档和用户文档等（除了 godoc 生成的文档）。推荐存放以下几个子目录：</p><ul>\n<li>/docs/devel/{en-US,zh-CN}：存放开发文档、hack 文档等。</li>\n<li>/docs/guide/{en-US,zh-CN}: 存放用户手册，安装、quickstart、产品文档等，分为中文文档和英文文档。</li>\n<li>/docs/images：存放图片文件。</li>\n</ul><ol start=\"20\">\n<li>/CONTRIBUTING.md</li>\n</ol><p>如果是一个开源就绪的项目，最好还要有一个 CONTRIBUTING.md 文件，用来说明如何贡献代码，如何开源协同等等。CONTRIBUTING.md 不仅能够规范协同流程，还能降低第三方开发者贡献代码的难度。</p><ol start=\"21\">\n<li>/api</li>\n</ol><p>/api 目录中存放的是当前项目对外提供的各种不同类型的 API 接口定义文件，其中可能包含类似 <code>/api/protobuf-spec</code>、<code>/api/thrift-spec</code>、<code>/api/http-spec</code>、<code>openapi</code>、<code>swagger</code> 的目录，这些目录包含了当前项目对外提供和依赖的所有 API 文件。例如，如下是 IAM 项目的/api 目录：</p><pre><code>├── openapi/\n│   └── README.md\n└── swagger/\n    ├── docs/\n    ├── README.md\n    └── swagger.yaml\n</code></pre><p>二级目录的主要作用，就是在一个项目同时提供了多种不同的访问方式时，可以分类存放。用这种方式可以避免潜在的冲突，也能让项目结构更加清晰。</p><ol start=\"22\">\n<li>/LICENSE</li>\n</ol><p>版权文件可以是私有的，也可以是开源的。常用的开源协议有：Apache 2.0、MIT、BSD、GPL、Mozilla、LGPL。有时候，公有云产品为了打造品牌影响力，会对外发布一个本产品的开源版本，所以在项目规划初期最好就能规划下未来产品的走向，选择合适的 LICENSE。</p><p>为了声明版权，你可能会需要将 LICENSE 头添加到源码文件或者其他文件中，这部分工作可以通过工具实现自动化，推荐工具： <a href=\"https://github.com/marmotedu/addlicense\">addlicense</a> 。</p><p>当代码中引用了其它开源代码时，需要在 LICENSE 中说明对其它源码的引用，这就需要知道代码引用了哪些源码，以及这些源码的开源协议，可以借助工具来进行检查，推荐工具： <a href=\"https://github.com/ribice/glice\">glice</a> 。至于如何说明对其它源码的引用，大家可以参考下 IAM 项目的 <a href=\"https://github.com/marmotedu/iam/blob/master/LICENSE\">LICENSE</a> 文件。</p><ol start=\"23\">\n<li>/CHANGELOG</li>\n</ol><p>当项目有更新时，为了方便了解当前版本的更新内容或者历史更新内容，需要将更新记录存放到 CHANGELOG 目录。编写 CHANGELOG 是一个复杂、繁琐的工作，我们可以结合 <a href=\"https://github.com/angular/angular/blob/22b96b9/CONTRIBUTING.md#-commit-message-guidelines\">Angular规范</a> 和 <a href=\"https://github.com/git-chglog/git-chglog\">git-chglog</a> 来自动生成 CHANGELOG。</p><ol start=\"24\">\n<li>/examples</li>\n</ol><p>存放应用程序或者公共包的示例代码。这些示例代码可以降低使用者的上手门槛。</p><h3>不建议的目录</h3><p>除了上面这些我们建议的目录，在 Go 项目中，还有一些目录是不建议包含的，这些目录不符合 Go 的设计哲学。</p><ol>\n<li>/src/</li>\n</ol><p>一些开发语言，例如 Java 项目中会有 src 目录。在 Java 项目中， src 目录是一种常见的模式，但在 Go 项目中，不建议使用 src 目录。</p><p>其中一个重要的原因是：在默认情况下，Go 语言的项目都会被放置到<code>$GOPATH/src</code> 目录下。这个目录中存放着所有代码，如果我们在自己的项目中使用<code>/src</code> 目录，这个包的导入路径中就会出现两个 src，例如：</p><pre><code>$GOPATH/src/github.com/marmotedu/project/src/main.go\n</code></pre><p>这样的目录结构看起来非常怪。</p><ol start=\"2\">\n<li>xxs/</li>\n</ol><p>在 Go 项目中，要避免使用带复数的目录或者包。建议统一使用单数。</p><h2>一些建议</h2><p>上面介绍的目录结构包含很多目录，但一个小型项目用不到这么多目录。对于小型项目，可以考虑先包含 cmd、pkg、internal 3 个目录，其他目录后面按需创建，例如：</p><pre><code>$ tree --noreport -L 2 tms\ntms\n├── cmd\n├── internal\n├── pkg\n└── README.md\n</code></pre><p>另外，在设计目录结构时，一些空目录无法提交到 Git 仓库中，但我们又想将这个空目录上传到 Git 仓库中，以保留目录结构。这时候，可以在空目录下加一个 <code>.keep</code> 文件，例如：</p><pre><code>$ ls -A build/ci/ \n.keep\n</code></pre><h2>总结</h2><p>今天我们主要学习了怎么设计代码的目录结构。先讲了目录结构的设计思路：在设计目录结构时，要确保目录名是清晰的，功能是明确的，并且设计的目录结构是可扩展的。</p><p>然后，我们一起学习了 2 种具体的目录结构：结构化目录结构和平铺式目录结构。结构化目录结构比较适合 Go 应用，平铺式目录结构比较适合框架/库。因为这2种目录结构组织比较合理，可以把它们作为目录规范来使用。</p><p>你还可以结合实战项目的例子，来加深对这两种目录结构的理解。对于结构化目录结构，你可以参考这门课 <a href=\"https://github.com/marmotedu/iam\">IAM</a> 实战项目的目录结构；对于平铺式的目录结构，你可以参考这门课实战部分设计的 <a href=\"https://github.com/marmotedu/log\">log</a> 包。</p><h2>课后练习</h2><ol>\n<li>试着用本节课描述的目录规范，重构下你当前的项目，并看下有啥优缺点。</li>\n<li>思考下你工作中遇到过哪些比较好的目录结构，它们有什么优点和可以改进的地方。</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"05 | 规范设计（下）：commit 信息风格迥异、难以阅读，如何规范？","id":380989},"right":{"article_title":"07 | 工作流设计：如何设计合理的多人开发模式？","id":382342}}},{"article_id":382342,"article_title":"07 | 工作流设计：如何设计合理的多人开发模式？","article_content":"<p>你好，我是孔令飞。今天我们来聊聊如何设计合理的开发模式。</p><p>一个企业级项目是由多人合作完成的，不同开发者在本地开发完代码之后，可能提交到同一个代码仓库，同一个开发者也可能同时开发几个功能特性。这种多人合作开发、多功能并行开发的特性如果处理不好，就会带来诸如丢失代码、合错代码、代码冲突等问题。</p><p>所以，在编码之前，我们需要设计一个合理的开发模式。又因为目前开发者基本都是基于 Git 进行开发的，所以本节课，我会教你怎么基于 Git 设计出一个合理的开发模式。</p><p>那么如何设计工作流呢？你可以根据需要，自己设计工作流，也可以采用业界沉淀下来的、设计好的、受欢迎的工作流。一方面，这些工作流经过长时间的实践，被证明是合理的；另一方面，采用一种被大家熟知且业界通用的工作流，会减少团队内部磨合的时间。在这一讲中，我会为你介绍4种受欢迎的工作流，你可以选择其中一种作为你的工作流设计。</p><p>在使用 Git 开发时，有4种常用的工作流，也叫开发模式，按演进顺序分为集中式工作流、功能分支工作流、Git Flow 工作流和Forking 工作流。接下来，我会按演进顺序分别介绍这 4 种工作流。</p><h2>集中式工作流</h2><p>我们先来看看集中式工作流，它是最简单的一种开发方式。集中式工作流的工作模式如下图所示：</p><!-- [[[read_end]]] --><p><img src=\"https://static001.geekbang.org/resource/image/31/eb/3174a9e1373ed2d6d14471164dcb13eb.png\" alt=\"\"></p><p>A、B、C 为 3 位开发者，每位开发者都在本地有一份远程仓库的拷贝：本地仓库。A、B、C 在本地的 master 分支开发完代码之后，将修改后的代码commit到远程仓库，如果有冲突就先解决本地的冲突再提交。在进行了一段时间的开发之后，远程仓库 master 分支的日志可能如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/fb/c7/fbcc75ba5b91223f6bf243f0bc08bac7.png\" alt=\"\"></p><p>集中式工作流是最简单的开发模式，但它的缺点也很明显：不同开发人员的提交日志混杂在一起，难以定位问题。如果同时开发多个功能，不同功能同时往 master 分支合并，代码之间也会相互影响，从而产生代码冲突。</p><p>和其他工作流相比，集中式工作流程的代码管理较混乱，容易出问题，因此适合用在<strong>团队人数少、开发不频繁、不需要同时维护多个版本的小项目</strong>中。当我们想要并行开发多个功能时，这种工作流就不适用了，这时候怎么办呢？我们接下来看功能分支工作流。</p><h2>功能分支工作流</h2><p>功能分支工作流基于集中式工作流演进而来。在开发新功能时，基于 master 分支新建一个功能分支，在功能分支上进行开发，而不是直接在本地的 master 分支开发，开发完成之后合并到 master 分支，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/1c/0b/1c0b08a1c9032c87c35b85de6ca6820b.png\" alt=\"\"></p><p>相较于集中式工作流，这种工作流让不同功能在不同的分支进行开发，只在最后一步合并到master分支，不仅可以避免不同功能之间的相互影响，还可以使提交历史看起来更加简洁。</p><p>还有，在合并到 master 分支时，需要提交 PR（pull request），而不是直接将代码 merge 到 master 分支。PR 流程不仅可以把分支代码提供给团队其他开发人员进行 CR（Code Review），还可以在 PR 页面讨论代码。通过 CR ，我们可以确保合并到 master 的代码是健壮的；通过 PR 页面的讨论，可以使开发者充分参与到代码的讨论中，有助于提高代码的质量，并且提供了一个代码变更的历史回顾途径。</p><p>那么，功能分支工作流具体的开发流程是什么呢？我们一起来看下。</p><ol>\n<li>基于 master 分支新建一个功能分支，功能分支可以取一些有意义的名字，便于理解，例如feature/rate-limiting。</li>\n</ol><pre><code>$ git checkout -b feature/rate-limiting\n</code></pre><ol start=\"2\">\n<li>在功能分支上进行代码开发，开发完成后 commit 到功能分支。</li>\n</ol><pre><code>$ git add limit.go\n$ git commit -m &quot;add rate limiting&quot;\n</code></pre><ol start=\"3\">\n<li>将本地功能分支代码 push 到远程仓库。</li>\n</ol><pre><code>$ git push origin feature/rate-limiting\n</code></pre><ol start=\"4\">\n<li>在远程仓库上创建 PR（例如：GitHub）。</li>\n</ol><p>进入 GitHub 平台上的项目主页，点击 <strong>Compare &amp; pull request</strong> 提交 PR，如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/db/ac/dbcd25542515788c7f4f2f592d0029ac.png\" alt=\"\"></p><p>点击 <strong>Compare &amp; pull request</strong> 后会进入 PR 页面，在该页面中可以根据需要填写评论，最后点击 <strong>Create pull request</strong> 提交 PR。</p><ol start=\"5\">\n<li>代码管理员收到 PR 后，可以 CR 代码，CR 通过后，再点击 <strong>Merge pull request</strong> 将 PR 合并到 master，如下图所示。</li>\n</ol><p><img src=\"https://static001.geekbang.org/resource/image/48/c6/48aaa3a94108de765cb07bd34d899fc6.png\" alt=\"\"></p><p>图中的“Merge pull request” 提供了 3 种 merge 方法：</p><ul>\n<li><strong>Create a merge commit：</strong>GitHub 的底层操作是 <code>git merge --no-ff</code>。feature 分支上所有的 commit 都会加到 master 分支上，并且会生成一个 merge commit。这种方式可以让我们清晰地知道是谁做了提交，做了哪些提交，回溯历史的时候也会更加方便。</li>\n<li><strong>Squash and merge</strong>：GitHub 的底层操作是 <code>git merge --squash</code>。<strong>Squash and merge</strong>会使该 pull request 上的所有 commit 都合并成一个commit ，然后加到master分支上，但原来的 commit 历史会丢失。如果开发人员在 feature 分支上提交的 commit 非常随意，没有规范，那么我们可以选择这种方法来丢弃无意义的 commit。但是在大型项目中，每个开发人员都应该是遵循 commit 规范的，因此我不建议你在团队开发中使用 Squash and merge。</li>\n<li><strong>Rebase and merge：</strong>GitHub 的底层操作是 <code>git rebase</code>。这种方式会将 pull request 上的所有提交历史按照原有顺序依次添加到 master 分支的头部（HEAD）。因为git rebase 有风险，在你不完全熟悉 Git 工作流时，我不建议merge时选择这个。</li>\n</ul><p>通过分析每个方法的优缺点，在实际的项目开发中，我比较推荐你使用 <strong>Create a merge commit</strong> 方式。</p><p>从刚才讲完的具体开发流程中，我们可以感受到，功能分支工作流上手比较简单，不仅能使你并行开发多个功能，还可以添加code review，从而保障代码质量。当然它也有缺点，就是无法给分支分配明确的目的，不利于团队配合。它适合用在<strong>开发团队相对固定、规模较小的项目</strong>中。接下来我们要讲的Git Flow 工作流以功能分支工作流为基础，较好地解决了上述问题。</p><h2>Git Flow 工作流</h2><p>Git Flow 工作流是一个非常成熟的方案，也是非开源项目中最常用到的工作流。它定义了一个围绕项目发布的严格分支模型，通过为代码开发、发布和维护分配独立的分支来让项目的迭代流程更加顺畅，<strong>比较适合大型的项目或者迭代速度快的项目。</strong>接下来，我会通过介绍Git Flow的5种分支和工作流程，来给你讲解GIt Flow是如何工作的。</p><h3>Git Flow 的5种分支</h3><p>Git Flow 中定义了 5 种分支，分别是 master、develop、feature、release和 hotfix。其中，master 和 develop 为常驻分支，其他为非常驻分支，不同的研发阶段会用到不同的分支。这5种分支的详细介绍见下表：</p><p><img src=\"https://static001.geekbang.org/resource/image/fa/d9/fa611f83053afd77cf3ddf83561ba1d9.png\" alt=\"\"></p><h3>Git Flow 开发流程</h3><p>这里我们用一个实际的例子来演示下Git Flow 的开发流程。场景如下：</p><p>a. 当前版本为：0.9.0。</p><p>b. 需要新开发一个功能，使程序执行时向标准输出输出“hello world”字符串。</p><p>c. 在开发阶段，线上代码有 Bug 需要紧急修复。</p><p>假设我们的 Git 项目名为 gitflow-demo，项目目录下有 2 个文件，分别是 README.md 和 main.go，内容如下。</p><pre><code>package main\n\nimport &quot;fmt&quot;\n\nfunc main() {\n\tfmt.Println(&quot;callmainfunction&quot;)\n}\n</code></pre><p>具体的开发流程有 12 步，你可以跟着以下步骤操作练习。</p><ol>\n<li>创建一个常驻的分支：develop。</li>\n</ol><pre><code>$ git checkout -b develop master\n</code></pre><ol start=\"2\">\n<li>基于 develop 分支，新建一个功能分支：feature/print-hello-world。</li>\n</ol><pre><code>$ git checkout -b feature/print-hello-world develop\n</code></pre><ol start=\"3\">\n<li>feature/print-hello-world 分支中，在 main.go 文件中添加一行代码<code>fmt.Println(\"Hello\")</code>，添加后的代码如下。</li>\n</ol><pre><code>package main\n\nimport &quot;fmt&quot;\n\nfunc main() {\n\tfmt.Println(&quot;callmainfunction&quot;)\n\tfmt.Println(&quot;Hello&quot;)\n}\n</code></pre><ol start=\"4\">\n<li>紧急修复 Bug。</li>\n</ol><p>我们正处在新功能的开发中（只完成了 <code>fmt.Println(\"Hello\")</code>而非 <code>fmt.Println(\"Hello World\")</code>）突然线上代码发现了一个 Bug，我们要立即停止手上的工作，修复线上的 Bug，步骤如下。</p><pre><code>$ git stash # 1. 开发工作只完成了一半，还不想提交，可以临时保存修改至堆栈区\n$ git checkout -b hotfix/print-error master # 2. 从 master 建立 hotfix 分支\n$ vi main.go # 3. 修复 bug，callmainfunction -&gt; call main function\n$ git commit -a -m 'fix print message error bug' # 4. 提交修复\n$ git checkout develop # 5. 切换到 develop 分支\n$ git merge --no-ff hotfix/print-error # 6. 把 hotfix 分支合并到 develop 分支\n$ git checkout master # 7. 切换到 master 分支\n$ git merge --no-ff hotfix/print-error # 8. 把 hotfix 分支合并到 master\n$ git tag -a v0.9.1 -m &quot;fix log bug&quot; # 9. master 分支打 tag\n$ go build -v . # 10. 编译代码，并将编译好的二进制更新到生产环境\n$ git branch -d hotfix/print-error # 11. 修复好后，删除 hotfix/xxx 分支\n$ git checkout feature/print-hello-world # 12. 切换到开发分支下\n$ git merge --no-ff develop # 13. 因为 develop 有更新，这里最好同步更新下\n$ git stash pop # 14. 恢复到修复前的工作状态\n</code></pre><ol start=\"5\">\n<li>继续开发。</li>\n</ol><p>在 main.go 中加入 <code>fmt.Println(\"Hello World\")</code>。</p><ol start=\"6\">\n<li>提交代码到 feature/print-hello-world 分支。</li>\n</ol><pre><code>$ git commit -a -m &quot;print 'hello world'&quot;\n</code></pre><ol start=\"7\">\n<li>在 feature/print-hello-world 分支上做 code review。</li>\n</ol><p>首先，我们需要将 feature/print-hello-world push 到代码托管平台，例如 GitHub 上。</p><pre><code>$ git push origin feature/print-hello-world\n</code></pre><p>然后，我们在 GitHub 上，基于 feature/print-hello-world 创建 pull request，如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/ac/ea/ac70d5ab86887e47f78c48d1df42f2ea.png\" alt=\"\"></p><p>创建完 pull request 之后，我们就可以指定 Reviewers 进行 code review，如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/bc/50/bc5168fe73abc257ba35342764647250.png\" alt=\"\"></p><ol start=\"8\">\n<li>code review 通过后，由代码仓库 matainer 将功能分支合并到 develop 分支。</li>\n</ol><pre><code>$ git checkout develop\n$ git merge --no-ff feature/print-hello-world\n</code></pre><ol start=\"9\">\n<li>基于 develop 分支，创建 release 分支，测试代码。</li>\n</ol><pre><code>$ git checkout -b release/1.0.0 develop\n$ go build -v . # 构建后，部署二进制文件，并测试\n</code></pre><ol start=\"10\">\n<li>测试失败，因为我们要求打印“hello world”，但打印的是“Hello World”，修复的时候，</li>\n</ol><p>我们直接在 release/1.0.0 分支修改代码，修改完成后，提交并编译部署。</p><pre><code>$ git commit -a -m &quot;fix bug&quot;\n$ go build -v .\n</code></pre><ol start=\"11\">\n<li>测试通过后，将功能分支合并到 master 分支和 develop 分支。</li>\n</ol><pre><code>$ git checkout develop\n$ git merge --no-ff release/1.0.0\n$ git checkout master\n$ git merge --no-ff release/1.0.0\n$ git tag -a v1.0.0 -m &quot;add print hello world&quot; # master 分支打 tag\n</code></pre><ol start=\"12\">\n<li>删除 feature/print-hello-world 分支，也可以选择性删除 release/1.0.0 分支。</li>\n</ol><pre><code>$ git branch -d feature/print-hello-world\n</code></pre><p>亲自操作一遍之后，你应该会更了解这种模式的优缺点。它的缺点，就是你刚才已经体会到的，它有一定的上手难度。不过Git Flow工作流还是有很多优点的：Git Flow工作流的每个分支分工明确，这可以最大程度减少它们之间的相互影响。因为可以创建多个分支，所以也可以并行开发多个功能。另外，和功能分支工作流一样，它也可以添加code review，保障代码质量。</p><p>因此，Git Flow工作流比较<strong>适合开发团队相对固定，规模较大的项目</strong>。</p><h2>Forking 工作流</h2><p>上面讲的Git Flow 是非开源项目中最常用的，而在开源项目中，最常用到的是Forking 工作流，例如 Kubernetes、Docker 等项目用的就是这种工作流。这里，我们先来了解下 fork 操作。</p><p>fork 操作是在个人远程仓库新建一份目标远程仓库的副本，比如在 GitHub 上操作时，在项目的主页点击 fork 按钮（页面右上角），即可拷贝该目标远程仓库。Forking 工作流的流程如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/63/ea/63419f767c61c9580861b59445b90fea.png\" alt=\"\"></p><p>假设开发者 A 拥有一个远程仓库，如果开发者 B 也想参与 A 项目的开发，B 可以 fork 一份 A 的远程仓库到自己的 GitHub 账号下。后续 B 可以在自己的项目进行开发，开发完成后，B 可以给 A 提交一个 PR。这时候 A 会收到通知，得知有新的 PR 被提交，A 会去查看 PR 并 code review。如果有问题，A 会直接在 PR 页面提交评论，B 看到评论后会做进一步的修改。最后 A 通过 B 的 PR 请求，将代码合并进了 A 的仓库。这样就完成了 A 代码仓库新特性的开发。如果有其他开发者想给 A 贡献代码，也会执行相同的操作。</p><p>GitHub中的 Forking 工作流详细步骤共有6步（假设目标仓库为 gitflow-demo），你可以跟着以下步骤操作练习。</p><ol>\n<li>Fork 远程仓库到自己的账号下。</li>\n</ol><p>访问<a href=\"https://github.com/marmotedu/gitflow-demo\">https://github.com/marmotedu/gitflow-demo</a> ，点击<strong>fork</strong>按钮。fork 后的仓库地址为：<a href=\"https://github.com/colin404fork/gitflow-demo\">https://github.com/colin404fork/gitflow-demo</a> 。<br>\n2) 克隆 fork 的仓库到本地。</p><pre><code>$ git clone https://github.com/colin404fork/gitflow-demo\n$ cd gitflow-demo\n$ git remote add upstream https://github.com/marmotedu/gitflow-demo\n$ git remote set-url --push upstream no_push # Never push to upstream master\n$ git remote -v # Confirm that your remotes make sense\norigin\thttps://github.com/colin404fork/gitflow-demo (fetch)\norigin\thttps://github.com/colin404fork/gitflow-demo (push)\nupstream\thttps://github.com/marmotedu/gitflow-demo (fetch)\nupstream\thttps://github.com/marmotedu/gitflow-demo (push)\n</code></pre><ol start=\"3\">\n<li>创建功能分支。</li>\n</ol><p>首先，要同步本地仓库的 master 分支为最新的状态（跟 upstream master 分支一致）。</p><pre><code>$ git fetch upstream\n$ git checkout master\n$ git rebase upstream/master\n</code></pre><p>然后，创建功能分支。</p><pre><code>$ git checkout -b feature/add-function\n</code></pre><ol start=\"4\">\n<li>提交 commit。</li>\n</ol><p>在 feature/add-function 分支上开发代码，开发完代码后，提交 commit。</p><pre><code>$ git fetch upstream # commit 前需要再次同步 feature 跟 upstream/master\n$ git rebase upstream/master\n$ git add &lt;file&gt;\n$ git status\n$ git commit\n</code></pre><p>分支开发完成后，可能会有一堆 commit，但是合并到主干时，我们往往希望只有一个（或最多两三个）commit，这可以使功能修改都放在一个或几个commit中，便于后面的阅读和维护。这个时候，我们可以用 git rebase 来合并和修改我们的 commit，操作如下：</p><pre><code>$ git rebase -i origin/master\n</code></pre><p>第5讲已经介绍过了<code>git rebase -i</code> 的使用方法 ，如果你有疑问可以再去看看，这里不再说明。</p><p>还有另外一种合并 commit 的简便方法，就是先撤销过去 5 个 commit，然后再建一个新的：</p><pre><code>$ git reset HEAD~5\n$ git add .\n$ git commit -am &quot;Here's the bug fix that closes #28&quot;\n$ git push --force\n</code></pre><p>squash 和 fixup 命令，还可以当作命令行参数使用，自动合并 commit。</p><pre><code>$ git commit --fixup\n$ git rebase -i --autosquash\n</code></pre><ol start=\"5\">\n<li>push 功能分支到个人远程仓库。</li>\n</ol><p>在完成了开发，并 commit 后，需要将功能分支 push 到个人远程代码仓库，代码如下：</p><pre><code>$ git push -f origin feature/add-function\n</code></pre><ol start=\"6\">\n<li>在个人远程仓库页面创建 pull request。</li>\n</ol><p>提交到远程仓库以后，我们就可以创建 pull request，然后请求reviewers进行代码 review，确认后合并到 master。这里要注意，创建pull request时，base通常选择目标远程仓库的master分支。</p><p>我们已经讲完了 Forking 工作流的具体步骤，你觉得它有什么优缺点呢？</p><p>结合操作特点，我们来看看它的优点：Forking工作流中，项目远程仓库和开发者远程仓库完全独立，开发者通过提交 Pull Request 的方式给远程仓库贡献代码，项目维护者选择性地接受任何开发者的提交，通过这种方式，可以避免授予开发者项目远程仓库的权限，从而提高项目远程仓库的安全性，这也使得任意开发者都可以参与项目的开发。</p><p>但Forking工作流也有局限性，就是对于职能分工明确且不对外开源的项目优势不大。</p><p>Forking工作流比较适用于以下三种场景：（1）开源项目中；（2）开发者有衍生出自己的衍生版的需求；（3）开发者不固定，可能是任意一个能访问到项目的开发者。</p><h2>总结</h2><p>这一讲中，我基于 Git 向你介绍了 4 种开发模式，现在跟我回顾一下吧。</p><ul>\n<li>集中式工作流：开发者直接在本地 master 分支开发代码，开发完成后 push 到远端仓库 master 分支。</li>\n<li>功能分支工作流：开发者基于 master 分支创建一个新分支，在新分支进行开发，开发完成后合并到远端仓库 master 分支。</li>\n<li>Git Flow 工作流：Git Flow 工作流为不同的分支分配一个明确的角色，并定义分支之间什么时候、如何进行交互，比较适合大型项目的开发。</li>\n<li>Forking 工作流：开发者先 fork 项目到个人仓库，在个人仓库完成开发后，提交 pull request 到目标远程仓库，远程仓库 review 后，合并 pull request 到 master 分支。</li>\n</ul><p>集中式工作流是最早的Git工作流，功能分支工作流以集中式工作流为基础，Git Flow 工作流又是以功能分支工作流为基础，Forking工作流在Git Flow 工作流基础上，解耦了个人远端仓库和项目远端仓库。</p><p>每种开发模式各有优缺点，适用于不同的场景，我总结在下表中：</p><p><img src=\"https://static001.geekbang.org/resource/image/55/07/5503ce60f7c2ae5d7628222a4d87cc07.png\" alt=\"\"></p><p>总的来说，在选择工作流时，我的推荐如下：</p><ul>\n<li>非开源项目采用 Git Flow 工作流。</li>\n<li>开源项目采用 Forking 工作流。</li>\n</ul><p>因为这门课的实战项目对于项目开发者来说是一个偏大型的非开源项目，所以采用了Git Flow工作流。</p><h2>课后练习</h2><ol>\n<li>请你新建立一个项目，并参考<strong>Git Flow开发流程</strong>，自己操作一遍，观察每一步的操作结果。</li>\n<li>请你思考下，在 Git Flow 工作流中，如果要临时解决一个 Bug，该如何操作代码仓库。</li>\n</ol><p>期待在留言区看到你的思考和分享，我们下一讲见！</p>","neighbors":{"left":{"article_title":"06 | 目录结构设计：如何组织一个可维护、可扩展的代码目录？","id":381392},"right":{"article_title":"08 | 研发流程设计（上）：如何设计 Go 项目的开发流程？","id":383390}}},{"article_id":383390,"article_title":"08 | 研发流程设计（上）：如何设计 Go 项目的开发流程？","article_content":"<p>你好，我是孔令飞。今天我们来聊聊如何设计研发流程。</p><p>在Go 项目开发中，我们不仅要完成产品功能的开发，还要确保整个过程是高效的，代码是高质量的。这就离不开一套设计合理的研发流程了。</p><p>而一个不合理的研发流程会带来很多问题，例如：</p><ul>\n<li><strong>代码管理混乱。</strong>合并代码时出现合错、合丢、代码冲突等问题。</li>\n<li><strong>研发效率低。</strong>编译、测试、静态代码检查等全靠手动操作，效率低下。甚至，因为没有标准的流程，一些开发者会漏掉测试、静态代码检查等环节。</li>\n<li><strong>发布效率低。</strong>发布周期长，以及发布不规范造成的现网问题频发。</li>\n</ul><p>所以，Go 项目开发一定要设计一个合理的研发流程，来提高开发效率、减少软件维护成本。研发流程会因为项目、团队和开发模式等的不同而有所不同，但不同的研发流程依然会有一些相似点。</p><p>那么如何设计研发流程呢？这也是你看到题目中“设计”两个字后，会直接想要问的。看到这俩字，你第一时间可能会觉得我是通过一系列的方法论，来告诉你怎么进行流程设计。但实际情况是，项目研发流程会因为团队、项目、需求等的不同而不同，很难概括出一个方法论让你去设计研发流程。</p><p>所以在这一讲中，我会介绍一种业界已经设计好的、相对标准的研发流程，来告诉你怎么设计研发流程。通过学习它，你不仅能够了解到项目研发的通用流程，而且还可以基于这个流程来优化、定制，满足你自己的流程需求。</p><!-- [[[read_end]]] --><h2>在设计研发流程时，需要关注哪些点？</h2><p>在看具体的研发流程之前，我们需要先思考一个问题：你觉得，一个好的流程应该是什么样子的？</p><p>虽然我们刚才说了，不同团队、项目、需求的研发流程不会一成不变，但为了最大限度地提高研发效能，这些不同的流程都会遵循下面这几个原则。</p><ul>\n<li>发布效率高：研发流程应该能提高发布效率，减少发布时间和人工介入的工作量。</li>\n<li>发布质量高：研发流程应该能够提高发布质量，确保发布出去的代码是经过充分测试的，并且完全避免人为因素造成的故障。</li>\n<li>迭代速度快：整个研发流程要能支持快速迭代，产品迭代速度越快，意味着产品的竞争力越强，在互联网时代越能把握先机。</li>\n<li>明确性：整个研发流程中角色的职责、使用的工具、方法和流程都应该是明确的，这可以增强流程的可执行性。</li>\n<li>流程合理：研发流程最终是供产品、开发、测试、运维等人员使用的，所以整个流程设计不能是反人类的，要能够被各类参与人员接受并执行。</li>\n<li>柔性扩展：研发流程应该是柔性且可扩展的，能够灵活变通，并适应各类场景。</li>\n<li>输入输出：研发流程中的每个阶段都应该有明确的输入和输出，这些输入和输出标志着上一个阶段的完成，下一个阶段的开始。</li>\n</ul><p>明确了这些关注点，我们就有了设计、优化研发流程的抓手了。接下来，我们就可以一起去学习一套业界相对标准的研发流程了。在学习的过程中，你也能更好地理解我对各个流程的一些经验和建议了。</p><h2>业界相对标准的研发流程，长啥样？</h2><p>一个项目从立项到结项，中间会经历很多阶段。业界相对标准的划分，是把研发流程分为六个阶段，分别是需求阶段、设计阶段、开发阶段、测试阶段、发布阶段、运营阶段。其中，开发人员需要参与的阶段有4个：设计阶段、开发阶段、测试阶段和发布阶段。下图就是业界相对比较标准的流程：</p><p><img src=\"https://static001.geekbang.org/resource/image/ab/3b/ab6ac57696c0e90cf82624f78a82333b.png?wh=7309*2306\" alt=\"\"></p><p>每个阶段结束时，都需要有一个最终的产出物，可以是文档、代码或者部署组件等。这个产出物既是当前阶段的结束里程碑，又是下一阶段的输入。所以说，各个阶段不是割裂的，而是密切联系的整体。每个阶段又细分为很多步骤，这些步骤是需要不同的参与者去完成的工作任务。在完成任务的过程中，可能需要经过多轮的讨论、修改，最终形成定稿。</p><p>这里有个点我们一定要注意：研发流程也是一种规范，很难靠开发者的自觉性去遵守。为了让项目参与人员尽可能地遵守规范，需要借助一些工具、系统来对他们进行强约束。所以，在我们设计完整个研发流程之后，需要认真思考下，有哪些地方可以实现自动化，有哪些地方可以靠工具、系统来保障规范的执行。这些自动化工具会在第 <strong>16 讲</strong> 中详细介绍。</p><p>接下来，咱们就具体看看研发的各个阶段，以及每个阶段的具体内容。</p><h3>需求阶段</h3><p>需求阶段是将一个抽象的产品思路具化成一个可实施产品的阶段。在这个阶段，产品人员会讨论产品思路、调研市场需求，并对需求进行分析，整理出一个比较完善的需求文档。最后，产品人员会组织相关人员对需求进行评审，如果评审通过，就会进入设计阶段。</p><p><strong>需求阶段，一般不需要研发人员参与。但这里，我还是建议你积极参与产品需求的讨论。</strong>虽然我们是研发，但我们的视野和对团队的贡献，可以不仅仅局限在研发领域。</p><p>这里有个点需要提醒你，如果你们团队有测试人员，这个阶段也需要拉测试人员旁听下。因为了解产品设计，对测试阶段测试用例的编写和功能测试等都很有帮助。</p><p>需求阶段的产出物是一个通过评审的详细的需求文档。</p><h3>设计阶段</h3><p>设计阶段，是整个产品研发过程中非常重要的阶段，包括的内容也比较多，你可以看一下这张表：</p><p><img src=\"https://static001.geekbang.org/resource/image/81/1b/81296e3f9f0f90e77dd771ee4f61b71b.png?wh=642*458\" alt=\"\"></p><p>这里的每一个设计项都应该经过反复的讨论、打磨，最终在团队内达成共识。这样可以确保设计是合理的，并减少返工的概率。<strong>这里想提醒你的是，技术方案和实现都要经过认真讨论，并获得一致通过，否则后面因为技术方案设计不当，需要返工，你要承担大部分责任。</strong></p><p>对于后端开发人员，在设计技术方案之前，要做好充足的调研。一个技术方案，不仅要调研业界优秀的实现，还要了解友商相同技术的实现。只有这样，才可以确保我们的技术用最佳的方式实现。</p><p>除此之外，在这个阶段一些设计项可以并行，以缩短设计阶段的耗时。例如，产品设计和技术设计可以并行展开。另外，如果你们团队有测试人员，研发阶段最好也拉上测试人员旁听下，有利于后面的测试。</p><p>该阶段的产出物是一系列的设计文档，这些文档会指导后面的整个研发流程。</p><h3>开发阶段</h3><p>开发阶段，从它的名字你就知道了，这是开发人员的主战场，同时它可能也是持续时间最长的阶段。在这一阶段，开发人员根据技术设计文档，编码实现产品需求。</p><p>开发阶段是整个项目的核心阶段，包含很多工作内容，而且每一个 Go 项目具体的步骤是不同的。我把开发阶段的常见步骤总结在了下图中，帮助你对它进行整体把握。</p><p><img src=\"https://static001.geekbang.org/resource/image/13/57/137a2a20067d1472c9f00c6387a30857.png?wh=2225*2031\" alt=\"\"></p><p>让我们来详细看下这张图里呈现的步骤。<strong>开发阶段又可以分为“开发”和“构建”两部分</strong>，我们先来看开发。</p><p>首先，我们需要制定一个所有研发人员共同遵循的 Git 工作流规范。最常使用的是 Git Flow 工作流或者 Forking 工作流。</p><p>为了提高开发效率，越来越多的开发者采用生成代码的方式来生成一部分代码，所以在真正编译之前可能还需要先生成代码，比如生成.pb.go 文件、API 文档、测试用例、错误码等。<strong>我的建议是，在项目开发中，你要思考怎么尽可能自动生成代码。</strong>这样不仅能提高研发效率，还能减少错误。</p><p>对于一个开源项目，我们可能还需要检查新增的文件是否有版权信息。此外，根据项目不同，开发阶段还可能有其它不同的步骤。在流程的最后，通常会进行静态代码检查、单元测试和编译。编译之后，我们就可以启动服务，并进行自测了。</p><p>自测之后，我们可以遵循 Git Flow 工作流，将开发分支 push 到代码托管平台进行 code review。code review 通过之后，我们就可以将代码 merge 到 develop 分支上。</p><p>接下来进入构建阶段。这一阶段最好借助 CI/CD 平台实现自动化，提高构建效率。</p><p>合并到 develop 分支的代码同样需要进行代码扫描、单元测试，并编译打包。最后，我们需要进行归档，也就是将编译后的二进制文件或 Docker 镜像上传到制品库或镜像仓库。</p><p>我刚刚带着你完整走了一遍开发阶段的常见步骤。可以看到，整个开发阶段步骤很多，而且都是高频的操作。那<strong>怎么提高效率呢</strong>？这里我推荐你两种方法：</p><ul>\n<li>将开发阶段的步骤通过 Makefile 实现集中管理；</li>\n<li>将构建阶段的步骤通过 CI/CD 平台实现自动化。</li>\n</ul><p>你还需要特别注意这一点：<strong>在最终合并代码到 master 之前，要确保代码是经过充分测试的</strong>。这就要求我们一定要借助代码管理平台提供的 Webhook 能力，在代码提交时触发 CI/CD 作业，对代码进行扫描、测试，最终编译打包，并以整个作业的成功执行作为合并代码的先决条件。</p><p>开发阶段的产出物是满足需求的源代码、开发文档，以及编译后的归档文件。</p><h3>测试阶段</h3><p>测试阶段由测试工程师（也叫质量工程师）负责，这个阶段的主要流程是：测试工程师根据需求文档创建测试计划、编写测试用例，并拉研发同学一起评审测试计划和用例。评审通过后，测试工程师就会根据测试计划和测试用例对服务进行测试。</p><p><strong>为了提高整个研发效率，测试计划的创建和测试用例的编写可以跟开发阶段并行。</strong></p><p>研发人员在交付给测试时，要提供自测报告、自测用例和安装部署文档。<strong>这里我要强调的是：在测试阶段，为了不阻塞测试，确保项目按时发布，研发人员应该优先解决测试同学的Bug，至少是阻塞类的Bug。为了减少不必要的沟通和排障，安装部署文档要尽可能详尽和准确。</strong></p><p>另外，<strong>你也可以及时跟进测试，了解测试同学当前遇到的卡点</strong>。因为实际工作中，一些测试同学在遇到卡点时，不善于或者不会及时地跟你同步卡点，往往研发1分钟就可以解决的问题，可能要花测试同学几个小时或者更久的时间去解决。</p><p>当然，测试用例几乎不可能涵盖整个变更分支，所以对于一些难测，隐藏的测试，需要研发人员自己加强测试。</p><p>最后，一个大特性测试完，请测试同学吃个饭吧，大家唠唠家常，联络联络感情，下次合作会更顺畅。</p><p>测试阶段的产出物是满足产品需求、达到发布条件的源代码，以及编译后的归档文件。</p><h3>发布阶段</h3><p>发布阶段主要是将软件部署上线，为了保证发布的效率和质量，我们需要遵循一定的发布流程，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/37/88/37yy6e0896daa8f97883631624996388.png?wh=2288*1938\" alt=\"\"></p><p>发布阶段按照时间线排序又分为代码发布、发布审批和服务发布3个子阶段。接下来，我详细给你介绍下这3个子阶段。我们先来看一下代码发布。</p><p><strong>首先，</strong>开发人员首先需要将经过测试后的代码合并到主干，通常是 master 分支，并生成版本号，然后给最新的 commit 打上版本标签。之后，可以将代码 push 到代码托管平台，并触发 CI 流程，CI流程一般会执行代码扫描、单元测试、编译，最后将构建产物发布到制品库。CI流程中，我们可以根据需要添加任意功能。</p><p><strong>接着，</strong>进入到发布审批阶段。首先需要申请资源，<strong>资源申请周期可能会比较久，所以申请得越早越好，甚至资源申请可以在测试阶段发起。</strong>在资源申请阶段，可以申请诸如服务器、MySQL、Redis、Kafka 之类资源。</p><p>资源申请通常是开发人员向运维人员提需求，由运维人员根据需求，在指定的时间前准备好各类资源。如果是物理机通常申请周期会比较久，但当前越来越多的项目选择容器化部署，这可以极大地缩短资源的申请周期。如果在像腾讯云弹性容器这类Serverless容器平台上部署业务，甚至可以秒申请资源。所以这里，我也建议优先采用容器化部署。</p><p>发布之前需要创建发布计划，里面需要详细描述本次的变更详情，例如变更范围、发布方案、测试结果、验证和回滚方案等。这里需要你注意，<strong>在创建发布计划时，一定要全面梳理这次变更的影响点。</strong>例如，是否有不兼容的变更，是否需要变更配置，是否需要变更数据库等。任何一个遗漏，都可能造成现网故障，影响产品声誉和用户使用。</p><p>接下来，需要创建发布单，在发布单中可以附上发布计划，并根据团队需求填写其它发布内容，发布计划需要跟相关参与者对齐流程、明确职责。发布单最终提交给审批人（通常是技术 leader）对本次发布进行审批，审批通过后，才可以进行部署。</p><p><strong>最后，</strong>就可以进入到服务发布阶段，将服务发布到现网。在正式部署的时候，应用需要先部署到预发环境。在预发环境，产品人员、测试人员和研发人员会分别对产品进行验证。其中，产品人员主要验证产品功能的体验是否流畅，开发和测试人员主要验证产品是否有 Bug。预发环境验证通过，产品才能正式发布到现网。</p><p>这里，我强烈建议，<strong>编写一些自动化的测试用例，在服务发布到现网之后，对现网服务做一次比较充分的回归测试。</strong>通过这个自动化测试，可以以最小的代价，最快速地验证现网功能，从而保障发布质量。</p><p>另外，我们还要注意，<strong>现网可能有多个地域，每个地域发布完成之后都要进行现网验证。</strong></p><p>发布阶段的产出物是正式上线的软件。</p><h3>运营阶段</h3><p>研发流程的最后一个阶段是运营阶段，该阶段主要分为产品运营和运维两个部分。</p><ul>\n<li><strong>产品运营</strong>：通过一系列的运营活动，比如线下的技术沙龙、线上的免费公开课、提高关键词排名或者输出一些技术推广文章等方式，来推高整个产品的知名度，提高产品的用户数量，并提高月活和日活。</li>\n<li><strong>运维</strong>：由运维工程师负责，核心目标是确保系统稳定的运行，如果系统异常，能够及时发现并修复问题。长期目标是通过技术手段或者流程来完善整个系统架构，减少人力投入、提高运维效率，并提高系统的健壮性和恢复能力。</li>\n</ul><p>从上面可以看到，运维属于技术类，运营属于产品类，这二者不要搞混。为了加深你的理解和记忆，我将这些内容，总结在了下面一张图中。</p><p><img src=\"https://static001.geekbang.org/resource/image/e0/b5/e0a4d8ed5f3a6a8a4bc4035e261881b5.png?wh=2519*1431\" alt=\"\"></p><p>在运营阶段，研发人员的主要职责就是协助运维解决现网Bug，优化部署架构。当然，研发人员可能也需要配合运营人员开发一些运营接口，供运营人员使用。</p><p>到这里，业界相对标准的这套研发流程，我们就学完了。在学习过程中，你肯定也发现了，整个研发流程会涉及很多角色，不同角色参与不同的阶段，负责不同的任务。这里我再给你额外扩展一个点，就是这些核心角色和分工是啥样的。</p><p>这些扩展内容，我放在了一张图和一张表里。这些角色和分工比较好理解，也不需要你背下来，只要先有一个大概的印象就可以了。</p><p><img src=\"https://static001.geekbang.org/resource/image/d1/da/d1797845f4105476c99ecc22cc7562da.png?wh=3088*1325\" alt=\"\"></p><p>具体分工如下表所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/40/d5/40a1e20b153bb3ba1005cea4aefe62d5.png?wh=754*815\" alt=\"\"></p><h2>总结</h2><p>在开发Go项目时，掌握项目的研发流程很重要。掌握研发流程，会让项目研发对我们更加白盒，并且有利于我们制定详细的工作任务。</p><p>那么如何设计项目研发流程呢？你可以根据需要自行设计。自行设计时有些点是一定要关注的，例如我们的流程需要支持高的发布效率和发布质量，支持快速迭代，流程是合理、可扩展的，等等。</p><p>如果你不想自己设计，也可以。在这一讲中，我介绍了一套相对通用、标准的研发流程，如果合适可以直接拿来作为自己设计的研发流程。</p><p>这套研发流程包含6个阶段：需求阶段、设计阶段、开发阶段、测试阶段、发布阶段和运营阶段。这里我将这些流程和每个流程的核心点总结在下面一张图中。</p><p><img src=\"https://static001.geekbang.org/resource/image/dd/0f/ddb314275ba1bab28413221bc56ac80f.png?wh=3225*1256\" alt=\"\"></p><h2>课后练习</h2><ol>\n<li>回忆下研发阶段具体包括哪些工作内容，如果你觉得这些工作内容满足不了研发阶段的需求，还需要补充什么呢？</li>\n<li>思考、调研下有哪些工具，可以帮助实现整个流程，以及流程中任务的自动化，看下它们是如何提高我们的研发效率的。</li>\n</ol><p>研发流程会因团队、项目、需求的不同而不同，如果你有更好的流程方案，欢迎你在留言区与我交流讨论。我们下一讲见！</p>","neighbors":{"left":{"article_title":"07 | 工作流设计：如何设计合理的多人开发模式？","id":382342},"right":{"article_title":"09 | 研发流程设计（下）：如何管理应用的生命周期？","id":384021}}},{"article_id":384021,"article_title":"09 | 研发流程设计（下）：如何管理应用的生命周期？","article_content":"<p>你好，我是孔令飞。今天我们来聊聊如何管理应用生命周期。</p><p>上一讲，我们介绍了一个相对标准的研发流程，这个研发流程可以确保我们高效地开发出一个优秀的Go项目。这一讲，我们再来看下，如何管理我们的Go项目，也就是说如何对应用的生命周期进行管理。</p><p>那应用的生命周期管理，怎么理解呢？其实，就是指<strong>采用一些好的工具或方法在应用的整个生命周期中对应用进行管理，以提高应用的研发效率和质量</strong>。</p><p>那么，如何设计一套优秀的应用生命周期管理手段呢？这就跟研发流程“设计”的思路一样，你可以自己设计，也可以采用业界沉淀下来的优秀管理手段。同样地，我更建议你采用已有的最佳实践，因为重复造轮子、造一个好轮子太难了。</p><p>所以，这一讲我们就一起学习下，业界在不同时期沉淀下来的优秀管理手段，以及我对这些管理手段的经验和建议，帮助你选到一个最合适的。</p><h2>应用生命周期管理技术有哪些？</h2><p>那么，有哪些应用生命周期管理技术呢？</p><p>在这里我先整体介绍一下，你先有个大致的印象，一会我们再一个个细讲。我们可以<strong>从两个维度来理解应用生命周期管理技术</strong>。</p><p>第一个维度是演进维度。应用生命周期，最开始主要是通过研发模式来管理的，按时间线先后出现了瀑布模式、迭代模式、敏捷模式。接着，为了解决研发模式中的一些痛点出现了另一种管理技术，也就是CI/CD技术。随着CI/CD技术的成熟，又催生了另一种更高级的管理技术DevOps。</p><!-- [[[read_end]]] --><p>第二个维度是管理技术的类别。应用生命周期管理技术可以分为两类：</p><ul>\n<li>研发模式，用来确保整个研发流程是高效的。</li>\n<li>DevOps，主要通过协调各个部门之间的合作，来提高软件的发布效率和质量。DevOps中又包含了很多种技术，主要包括CI/CD和多种Ops，例如AIOps、ChatOps、GitOps、NoOps等。其中，CI/CD技术提高了软件的发布效率和质量，而Ops技术则提高了软件的运维和运营效率。</li>\n</ul><p>尽管这些应用生命周期管理技术有很多不同，但是它们彼此支持、相互联系。研发模式专注于<strong>开发过程</strong>，DevOps技术里的CI/CD 专注于<strong>流程</strong>，Ops则专注于<strong>实战。</strong></p><p>为了帮助你理解，我总结出了下面这张图供你参考。</p><p><img src=\"https://static001.geekbang.org/resource/image/9a/a3/9a290c28b0c238dd69e24dcc9f5c7ea3.png\" alt=\"\"></p><p>这两个维度涉及的管理技术虽然不少，但一共就是那几类。所以，<strong>为了能够逻辑清晰地给你讲解明白这些技术，我会从演进维度来展开，也就是按照这样的顺序：研发模式（瀑布模式 -&gt; 迭代模式 -&gt; 敏捷模式） -&gt; CI/CD -&gt; DevOps</strong>。</p><p>你可能会问了，既然是演进，那这些技术肯定有优劣之分，我应该怎么选择呢，一定是选择后面出现的技术吗？</p><p>为了解决你的这个问题，这里，对于研发模式和DevOps这两类技术的选择，我提前给出我的建议：<strong>研发模式建议选择敏捷模式，因为它更能胜任互联网时代快速迭代的诉求。DevOps则要优先确保落地CI/CD技术，接着尝试落地ChatOps技术，如果有条件可以积极探索AIOps和GitOps。</strong></p><p>接下来，我们就详细说说这些应用生命周期的管理方法，先来看专注于开发过程的研发模式部分。</p><h2>研发模式</h2><p>研发模式主要有三种，演进顺序为瀑布模式-&gt;迭代模式-&gt;敏捷模式，现在我们逐一看下。</p><h3>瀑布模式</h3><p>在早期阶段，软件研发普遍采用的是瀑布模式，像我们熟知的RHEL、Fedora等系统就是采用瀑布模式。</p><p>瀑布模式按照预先规划好的研发阶段来推进研发进度。比如，按照需求阶段、设计阶段、开发阶段、测试阶段、发布阶段、运营阶段的顺序串行执行开发任务。每个阶段完美完成之后，才会进入到下一阶段，阶段之间通过文档进行交付。整个过程如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/7c/89/7ccc702a02cf24e2295cc50a506e6289.png\" alt=\"\"></p><p>瀑布模式最大的优点是简单。它严格按照研发阶段来推进研发进度，流程清晰，适合按项目交付的应用。</p><p>但它的缺点也很明显，最突出的就是这两个：</p><ul>\n<li>只有在项目研发的最后阶段才会交付给客户。交付后，如果客户发现问题，变更就会非常困难，代价很大。</li>\n<li>研发周期比较长，很难适应互联网时代对产品快速迭代的诉求。</li>\n</ul><p>为了解决这两个问题，迭代式研发模式诞生了。</p><h3>迭代模式</h3><p>迭代模式，是一种与瀑布式模式完全相反的开发过程：研发任务被切分为一系列轮次，每一个轮次都是一个迭代，每一次迭代都是一个从设计到实现的完整过程。它<strong>不要求每一个阶段的任务都做到最完美，而是先把主要功能搭建起来，然后再通过客户的反馈信息不断完善</strong>。</p><p>迭代开发可以帮助产品改进和把控进度，它的灵活性极大地提升了适应需求变化的能力，克服了高风险、难变更、复用性低的特点。</p><p>但是，迭代模式的问题在于比较专注于开发过程，很少从项目管理的视角去加速和优化项目开发过程。接下来要讲的敏捷模式，就弥补了这个缺点。</p><h3>敏捷模式</h3><p>敏捷模式把一个大的需求分成多个、可分阶段完成的小迭代，每个迭代交付的都是一个可使用的软件。在开发过程中，软件要一直处于可使用状态。</p><p>敏捷模式中具有代表性的开发模式，是Scrum开发模型。Scrum开发模型网上有很多介绍，你可以去看看。</p><p>在敏捷模式中，我们会把一个大的需求拆分成很多小的迭代，这意味着开发过程中会有很多个开发、构建、测试、发布和部署的流程。这种高频度的操作会给研发、运维和测试人员带来很大的工作量，降低了工作效率。为了解决这个问题，CI/CD技术诞生了。</p><h2>CI/CD：自动化构建和部署应用</h2><p>CI/CD技术通过自动化的手段，来快速执行代码检查、测试、构建、部署等任务，从而提高研发效率，解决敏捷模式带来的弊端。</p><p>CI/CD包含了3个核心概念。</p><ul>\n<li><strong>CI</strong>：Continuous Integration，持续集成。</li>\n<li><strong>CD</strong>：Continuous Delivery，持续交付。</li>\n<li><strong>CD</strong>：Continuous Deployment，持续部署。</li>\n</ul><p>CI容易理解，但两个CD很多开发者区分不开。这里，我来详细说说这3个核心概念。</p><p><strong>首先是持续集成。</strong>它的含义为：频繁地（一天多次）将开发者的代码合并到主干上。它的流程为：在开发人员完成代码开发，并push到Git仓库后，CI工具可以立即对代码进行扫描、（单元）测试和构建，并将结果反馈给开发者。持续集成通过后，会将代码合并到主干。</p><p>CI流程可以使应用软件的问题在开发阶段就暴露出来，这会让开发人员交付代码时更有信心。因为CI流程内容比较多，而且执行比较频繁，所以CI流程需要有自动化工具来支撑。</p><p><strong>其次是持续交付，</strong>它指的是一种能够使软件在较短的循环中可靠发布的软件方法。</p><p>持续交付在持续集成的基础上，将构建后的产物自动部署在目标环境中。这里的目标环境，可以是测试环境、预发环境或者现网环境。</p><p>通常来说，持续部署可以自动地将服务部署到测试环境或者预发环境。因为部署到现网环境存在一定的风险，所以如果部署到现网环境，需要手工操作。手工操作的好处是，可以使相关人员评估发布风险，确保发布的正确性。</p><p><strong>最后是持续部署，</strong>持续部署在持续交付的基础上，将经过充分测试的代码自动部署到生产环境，整个流程不再需要相关人员的审核。持续部署强调的是自动化部署，是交付的最高阶段。</p><p>我们可以借助下面这张图，来了解持续集成、持续交付、持续部署的关系。</p><p><img src=\"https://static001.geekbang.org/resource/image/96/d0/963b9983543de3d66379567ba491d7d0.png\" alt=\"\"></p><p>持续集成、持续交付和持续部署强调的是持续性，也就是能够支持频繁的集成、交付和部署，这离不开自动化工具的支持，离开了这些工具，CI/CD就不再具有可实施性。持续集成的核心点在<strong>代码</strong>，持续交付的核心点在<strong>可交付的产物</strong>，持续部署的核心点在<strong>自动部署。</strong></p><h2>DevOps：研发运维一体化</h2><p>CI/CD技术的成熟，加速了DevOps这种应用生命周期管理技术的成熟和落地。</p><p>DevOps（Development和Operations的组合）是<strong>一组过程、方法与系统的统称</strong>，用于促进开发（应用程序/软件工程）、技术运营和质量保障（QA）部门之间的沟通、协作与整合。这3个部门的相互协作，可以提高软件质量、快速发布软件。如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/c8/79/c81a361fb98500cec8c866f465f14679.png\" alt=\"\"></p><p>要实现DevOps，需要一些工具或者流程的支持，CI/CD可以很好地支持DevOps这种软件开发模式，如果没有CI/CD自动化的工具和流程，DevOps就是没有意义的，CI/CD使得DevOps变得可行。</p><p>听到这里是不是有些晕？你可能想问，DevOps跟CI/CD到底是啥区别呢？其实，这也是困扰很多开发者的问题。这里，我们可以这么理解：DevOps ！= CI/CD。DevOps是一组过程、方法和系统的统称，而CI/CD只是一种软件构建和发布的技术。</p><p>DevOps技术之前一直有，但是落地不好，因为没有一个好的工具来实现DevOps的理念。但是随着容器、CI/CD技术的诞生和成熟，DevOps变得更加容易落地。也就是说，这几年越来越多的人采用DevOps手段来提高研发效能。</p><p>随着技术的发展，目前已经诞生了很多Ops手段，来实现运维和运营的高度自动化。下面，我们就来看看DevOps中的四个Ops手段：AIOps、ChatOps、GitOps、NoOps。</p><h3>AIOps：智能运维</h3><p>在2016年，Gartner提出利用AI技术的新一代IT运维，即AIOps（智能运维）。通过AI手段，来智能化地运维IT系统。AIOps通过搜集海量的运维数据，并利用机器学习算法，智能地定位并修复故障。</p><p>也就是说，AIOps在自动化的基础上，增加了智能化，从而进一步推动了IT运维自动化，减少了人力成本。</p><p>随着IT基础设施规模和复杂度的倍数增长，企业应用规模、数量的指数级增长，传统的人工/自动化运维，已经无法胜任愈加沉重的运维工作，而AIOps提供了一个解决方案。在腾讯、阿里等大厂很多团队已经在尝试和使用AIOps，并享受到了AIOps带来的红利。例如，故障告警更加灵敏、准确，一些常见的故障，可以自动修复，无须运维人员介入等。</p><h3>ChatOps：聊着天就把事情给办了</h3><p>随着企业微信、钉钉等企业内通讯工具的兴起，最近几年出现了一个新的概念ChatOps。</p><p>简单来说，ChatOps就是在一个聊天工具中，发送一条命令给 ChatBot 机器人，然后 ChatBot会执行预定义的操作。这些操作可以是执行某个工具、调用某个接口等，并返回执行结果。</p><p>这种新型智能工作方式的优势是什么呢？它可以利用 ChatBot 机器人让团队成员和各项辅助工具连接在一起，以沟通驱动的方式完成工作。ChatOps可以解决人与人、人与工具、工具与工具之间的信息孤岛，从而提高协作体验和工作效率。</p><p>ChatOps的工作流程如下图所示（网图）：</p><p><img src=\"https://static001.geekbang.org/resource/image/29/6e/292372572f1fa8cae9a44891bd233a6e.png\" alt=\"\"></p><p>开发/运维/测试人员通过@聊天窗口中的机器人Bot来触发任务，机器人后端会通过API接口调用等方式对接不同的系统，完成不同的任务，例如持续集成、测试、发布等工作。机器人可以是我们自己研发的，也可以是开源的。目前，业界有很多流行的机器人可供选择，常用的有Hubot、Lita、Errbot、StackStorm等。</p><p>使用ChatOps可以带来以下几点好处。</p><ul>\n<li><strong>友好、便捷</strong>：所有的操作均在同一个聊天界面中，通过@机器人以聊天的方式发送命令，免去了打开不同系统，执行不同操作的繁琐操作，方式更加友好和便捷。</li>\n<li><strong>信息透明</strong>：在同一个聊天界面中的所有同事都能够看到其他同事发送的命令，以及命令执行的结果，可以消除沟通壁垒，工作历史有迹可循，团队合作更加顺畅。</li>\n<li><strong>移动友好</strong>：可以在移动端向机器人发送命令、执行任务，让移动办公变为可能。</li>\n<li><strong>DevOps 文化打造</strong>：通过与机器人对话，可以降低项目开发中，各参与人员的理解和使用成本，从而使DevOps更容易落地和推广。</li>\n</ul><h3>GitOps： 一种实现云原生的持续交付模型</h3><p>GitOps是一种持续交付的方式。它的核心思想是将应用系统的声明性基础架构（YAML）和应用程序存放在Git版本库中。将Git作为交付流水线的核心，每个开发人员都可以提交拉取请求（Pull Request），并使用Gi​​t来加速和简化Kubernetes的应用程序部署和运维任务。</p><p>通过Git这样的工具，开发人员可以将精力聚焦在功能开发，而不是软件运维上，以此提高软件的开发效率和迭代速度。</p><p>使用GitOps可以带来很多优点，其中最核心的是：当使用Git变更代码时，GitOps可以自动将这些变更应用到程序的基础架构上。因为整个流程都是自动化的，所以部署时间更短；又因为Git代码是可追溯的，所以我们部署的应用也能够稳定且可重现地回滚。</p><p>我们可以从概念和流程上来理解GitOps，它有3个关键概念。</p><ul>\n<li><strong>声明性容器编排</strong>：通过Kubernetes YAML格式的资源定义文件，来定义如何部署应用。</li>\n<li><strong>不可变基础设施</strong>：基础设施中的每个组件都可以自动的部署，组件在部署完成后，不能发生变更。如果需要变更，则需要重新部署一个新的组件。例如，Kubernetes中的Pod就是一个不可变基础设施。</li>\n<li><strong>连续同步</strong>：不断地查看Git存储库，将任何状态更改反映到Kubernetes集群中。</li>\n</ul><p><img src=\"https://static001.geekbang.org/resource/image/2f/8d/2f1b427674e7da60668b2af42cf7338d.png\" alt=\"\" title=\"GitOps的工作流程图\"></p><p>GitOps的工作流程如下：</p><p><strong>首先，</strong>开发人员开发完代码后推送到Git仓库，触发CI流程，CI流程通过编译构建出Docker镜像，并将镜像push到Docker镜像仓库中。Push动作会触发一个push事件，通过webhook的形式通知到Config Updater服务，Config Updater服务会从 webhook 请求中获取最新 push 的镜像名，并更新Git仓库中的Kubernetes YAML文件。</p><p><strong>然后，</strong>GitOps的Deploy Operator服务，检测到YAML文件的变动，会重新从Git仓库中提取变更的文件，并将镜像部署到Kubernetes集群中。Config Updater 和 Deploy Operator 两个组件需要开发人员设计开发。</p><h3>NoOps：无运维</h3><p>NoOps即无运维，完全自动化的运维。在NoOps中不再需要开发人员、运营运维人员的协同，把微服务、低代码、无服务全都结合了起来，开发者在软件生命周期中只需要聚焦业务开发即可，所有的维护都交由云厂商来完成。</p><p>毫无疑问，NoOps是运维的终极形态，在我看来它像DevOps一样，更多的是一种理念，需要很多的技术和手段来支撑。当前整个运维技术的发展，也是朝着NoOps的方向去演进的，例如GitOps、AIOps可以使我们尽可能减少运维，Serverless技术甚至可以使我们免运维。相信未来NoOps会像现在的Serverless一样，成为一种流行的、可落地的理念。</p><h2>如何选择合适的应用生命周期管理技术？</h2><p>好了，到这里我们就把主要的应用生命周期管理技术，学得差不多了。那在实际开发中，如何选择适合自己的呢？在我看来，你可以从这么几个方面考虑。</p><p><strong>首先，</strong>根据团队、项目选择一个合适的研发模式。如果项目比较大，需求变更频繁、要求快速迭代，建议选择敏捷开发模式。敏捷开发模式，也是很多大公司选择的研发模式，在互联网时代很受欢迎。</p><p><strong>接着，</strong>要建立自己的CI/CD流程。任何变更代码在合并到master分支时，一定要通过CI/CD的流程的验证。我建议，你在CI/CD流程中设置质量红线，确保合并代码的质量。</p><p><strong>接着，</strong>除了建立CI/CD系统，我还建议将ChatOps带入工作中，尽可能地将可以自动化的工作实现自动化，并通过ChatOps来触发自动化流程。随着企业微信、钉钉等企业聊天软件成熟和发展，ChatOps变得流行和完善。</p><p><strong>最后，</strong>GitOps、AIOps可以将部署和运维自动化做到极致，在团队有人力的情况下，值得探索。</p><p>到这里你可能会问了，大厂是如何管理应用生命周期的？</p><p><strong>大厂普遍采用敏捷开发的模式，来适应互联网对应用快速迭代的诉求。</strong>例如，腾讯的<a href=\"https://www.tapd.cn/\">TAPD</a>、<a href=\"https://coding.net/\">Coding</a>的Scrum敏捷管理就是一个敏捷开发平台。<strong>CI/CD强制落地，ChatOps已经广泛使用，AIOps也有很多落地案例，GitOps目前还在探索阶段，NoOps还处在理论阶段。</strong></p><h2>总结</h2><p>这一讲，我从技术演进的维度介绍了应用生命周期管理技术，这些技术可以提高应用的研发效率和质量。</p><p>应用生命周期管理最开始是通过研发模式来管理的。在研发模式中，我按时间线分别介绍了瀑布模式、迭代模式和敏捷模式，其中的敏捷模式适应了互联网时代对应用快速迭代的诉求，所以用得越来越多。</p><p>在敏捷模式中，我们需要频繁构建和发布我们的应用，这就给开发人员带来了额外的工作量，为了解决这个问题，出现了CI/CD技术。CI/CD可以将代码的检查、测试、构建和部署等工作自动化，不仅提高了研发效率，还从一定程度上保障了代码的质量。另外，CI/CD技术使得DevOps变得可行，当前越来越多的团队采用DevOps来管理应用的生命周期。</p><p>另外，这一讲中我也介绍了几个大家容易搞混的概念。</p><ul>\n<li>持续交付和持续部署。二者都是持续地部署应用，但是持续部署整个过程是自动化的，而持续交付中，应用在发布到现网前需要人工审批是否允许发布。</li>\n<li>CI/CD和DevOps。DevOps是一组过程、方法与系统的统称，其中也包含了CI/CD技术。而CI/CD是一种自动化的技术，DevOps理念的落地需要CI/CD技术的支持。</li>\n</ul><p>最后，关于如何管理应用的生命周期，我给出了一些建议：<strong>研发模式建议选择敏捷模式</strong>，因为它更能胜任互联网时代快速迭代的诉求。DevOps则要<strong>优先确保落地CI/CD技术</strong>，接着尝试落地ChatOps技术，如果有条件可以积极探索AIOps和GitOps。</p><h2>课后练习</h2><ol>\n<li>学习并使用GitHub Actions，通过Github Actions完成提交代码后自动进行静态代码检查的任务。</li>\n<li>尝试添加一个能够每天自动打印“hello world”的企业微信机器人，并思考下，哪些自动化工作可以通过该机器人来实现。</li>\n</ol><p>期待在留言区看到你的思考和答案，我们下一讲见！</p>","neighbors":{"left":{"article_title":"08 | 研发流程设计（上）：如何设计 Go 项目的开发流程？","id":383390},"right":{"article_title":"10 | 设计方法：怎么写出优雅的 Go 项目？","id":384648}}},{"article_id":384648,"article_title":"10 | 设计方法：怎么写出优雅的 Go 项目？","article_content":"<p>你好，我是孔令飞，今天我们来聊聊如何写出优雅的 Go 项目。</p><p>Go语言简单易学，对于大部分开发者来说，编写可运行的代码并不是一件难事，但如果想真正成为Go编程高手，你需要花很多精力去研究Go的编程哲学。</p><p>在我的Go开发生涯中，我见过各种各样的代码问题，例如：代码不规范，难以阅读；函数共享性差，代码重复率高；不是面向接口编程，代码扩展性差，代码不可测；代码质量低下。究其原因，是因为这些代码的开发者<strong>很少花时间去认真研究如何开发一个优雅的Go项目，更多时间是埋头在需求开发中</strong>。</p><p>如果你也遇到过以上问题，那么是时候花点时间来研究下如何开发一个优雅的Go项目了。只有这样，你才能区别于绝大部分的Go开发者，从而在职场上建立自己的核心竞争力，并最终脱颖而出。</p><p>其实，我们之前所学的各种规范设计，也都是为了写出一个优雅的Go项目。在这一讲，我又补充了一些内容，从而形成了一套“写出优雅Go项目”的方法论。这一讲内容比较多，但很重要，希望你能花点精力认真掌握，掌握之后，能够确保你开发出一个优秀的Go项目。</p><h2>如何写出优雅的Go项目？</h2><p>那么，如何写出一个<strong>优雅</strong>的<strong>Go项目</strong>呢？在回答这个问题之前，我们先来看另外两个问题：</p><ol>\n<li>为什么是Go项目，而不是Go应用？</li>\n<li>一个优雅的Go项目具有哪些特点？</li>\n</ol><!-- [[[read_end]]] --><p>先来看第一个问题。Go项目是一个偏工程化的概念，不仅包含了Go应用，还包含了项目管理和项目文档：</p><p><img src=\"https://static001.geekbang.org/resource/image/24/aa/24ba3548f8574a747b51e291224097aa.png?wh=2175x834\" alt=\"\"></p><p>这就来到了第二个问题，一个优雅的Go项目，不仅要求我们的Go应用是优雅的，还要确保我们的项目管理和文档也是优雅的。这样，我们根据前面几讲学到的Go设计规范，很容易就能总结出一个优雅的Go应用需要具备的特点：</p><ul>\n<li>符合Go编码规范和最佳实践；</li>\n<li>易阅读、易理解，易维护；</li>\n<li>易测试、易扩展；</li>\n<li>代码质量高。</li>\n</ul><p>解决了这两个问题，让我们回到这一讲的核心问题：如何写出优雅的Go项目？</p><p>写出一个优雅的Go项目，在我看来，就是<strong>用“最佳实践”的方式去实现Go项目中的Go应用、项目管理和项目文档</strong>。具体来说，就是编写高质量的Go应用、高效管理项目、编写高质量的项目文档。</p><p>为了协助你理解，我将这些逻辑绘制成了下面一张图。</p><p><img src=\"https://static001.geekbang.org/resource/image/77/03/77d541223576135df4c3d511abbfe603.png?wh=3131x1488\" alt=\"\"></p><p>接下来，我们就看看如何根据前面几讲学习的Go项目设计规范，实现一个优雅的Go项目。我们先从编写高质量的Go应用看起。</p><h2>编写高质量的Go应用</h2><p>基于我的研发经验，要编写一个高质量的Go应用，其实可以归纳为5个方面：代码结构、代码规范、代码质量、编程哲学和软件设计方法，见下图。</p><p><img src=\"https://static001.geekbang.org/resource/image/23/69/2392d94feb95d3d64d765abe7d6e5e69.png?wh=3544x766\" alt=\"\"></p><p>接下来，我们详细说说这些内容。</p><h3>代码结构</h3><p>为什么先说代码结构呢？因为组织合理的代码结构是一个项目的门面。我们可以通过两个手段来组织代码结构。</p><p>第一个手段是，组织一个好的目录结构。关于如何组合一个好的目录结构，你可以回顾 <a href=\"https://time.geekbang.org/column/article/381392\">06讲</a> 的内容。</p><p>第二个手段是，选择一个好的模块拆分方法。做好模块拆分，可以使项目内模块职责分明，做到低耦合高内聚。</p><p>那么Go项目开发中，如何拆分模块呢？目前业界有两种拆分方法，分别是按层拆分和按功能拆分。</p><p><strong>首先，我们看下按层拆分</strong>，最典型的是MVC架构中的模块拆分方式。在MVC架构中，我们将服务中的不同组件按访问顺序，拆分成了Model、View和Controller三层。</p><p><img src=\"https://static001.geekbang.org/resource/image/ed/46/ed0c3dfyy52ac82539cb602eec9f0146.png?wh=497x625\" alt=\"\"></p><p>每层完成不同的功能：</p><ul>\n<li>View（视图）是提供给用户的操作界面，用来处理数据的显示。</li>\n<li>Controller（控制器），负责根据用户从 View 层输入的指令，选取 Model 层中的数据，然后对其进行相应的操作，产生最终结果。</li>\n<li>Model（模型），是应用程序中用于处理数据逻辑的部分。</li>\n</ul><p>我们看一个典型的按层拆分的目录结构：</p><pre><code>$ tree --noreport -L 2 layers\nlayers\n├── controllers\n│   ├── billing\n│   ├── order\n│   └── user\n├── models\n│   ├── billing.go\n│   ├── order.go\n│   └── user.go\n└── views\n    └── layouts\n</code></pre><p>在Go项目中，按层拆分会带来很多问题。最大的问题是循环引用：相同功能可能在不同层被使用到，而这些功能又分散在不同的层中，很容易造成循环引用。</p><p>所以，<strong>你只要大概知道按层拆分是什么意思就够了，在Go项目中我建议你使用的是按功能拆分的方法，这也是Go项目中最常见的拆分方法。</strong></p><p>那什么是按功能拆分呢？我给你看一个例子你就明白了。比如，一个订单系统，我们可以根据不同功能将其拆分成用户（user）、订单（order）和计费（billing）3个模块，每一个模块提供独立的功能，功能更单一：</p><p><img src=\"https://static001.geekbang.org/resource/image/0d/a5/0d65eb1363bf8055e209bc24d1d99ca5.png?wh=625x572\" alt=\"\"></p><p>下面是该订单系统的代码目录结构：</p><pre><code>$ tree pkg\n$ tree --noreport -L 2 pkg\npkg\n├── billing\n├── order\n│   └── order.go\n└── user\n</code></pre><p>相较于按层拆分，按功能拆分模块带来的好处也很好理解：</p><ul>\n<li>不同模块，功能单一，可以实现高内聚低耦合的设计哲学。</li>\n<li>因为所有的功能只需要实现一次，引用逻辑清晰，会大大减少出现循环引用的概率。</li>\n</ul><p>所以，有很多优秀的Go项目采用的都是按功能拆分的模块拆分方式，例如 Kubernetes、Docker、Helm、Prometheus等。</p><p>除了组织合理的代码结构这种方式外，编写高质量Go应用的另外一个行之有效的方法，是遵循Go语言代码规范来编写代码。在我看来，这也是最容易出效果的方式。</p><h3>代码规范</h3><p>那我们要遵循哪些代码规范来编写Go应用呢？在我看来，其实就两类：编码规范和最佳实践。</p><p><strong>首先，我们的代码要符合Go编码规范，这是最容易实现的途径</strong>。Go社区有很多这类规范可供参考，其中，比较受欢迎的是<a href=\"https://github.com/xxjwxc/uber_go_guide_cn\">Uber Go 语言编码规范</a>。</p><p>阅读这些规范确实有用，也确实花时间、花精力。所以，我在参考了已有的很多规范后，结合自己写Go代码的经验，特地为你整理了一篇Go编码规范作为加餐，也就是“特别放送 | 给你一份清晰、可直接套用的Go编码规范”。</p><p>有了可以参考的编码规范之后，我们需要扩展到团队、部门甚至公司层面。只有大家一起参与、遵守，规范才会变得有意义。其实，我们都清楚，要开发者靠自觉来遵守所有的编码规范，不是一件容易的事儿。这时候，我们可以使用静态代码检查工具，来约束开发者的行为。</p><p>有了静态代码检查工具后，不仅可以确保开发者写出的每一行代码都是符合Go编码规范的，还可以将静态代码检查集成到CI/CD流程中。这样，在代码提交后自动地检查代码，就保证了只有符合编码规范的代码，才会被合入主干。</p><p>Go语言的静态代码检查工具有很多，目前用的最多的是<a href=\"https://github.com/golangci/golangci-lint\">golangci-lint</a>，这也是我极力推荐你使用的一个工具。关于这个工具的使用，我会在<strong>第15讲</strong>和你详细介绍。</p><p>除了遵循编码规范，<strong>要想成为Go编程高手，你还得学习并遵循一些最佳实践</strong>。“最佳实践”是社区经过多年探索沉淀下来的、符合Go语言特色的经验和共识，它可以帮助你开发出一个高质量的代码。</p><p>这里我给你推荐几篇介绍Go语言最佳实践的文章，供你参考：</p><ul>\n<li><a href=\"https://golang.org/doc/effective_go\">Effective Go</a>：高效Go编程，由Golang官方编写，里面包含了编写Go代码的一些建议，也可以理解为最佳实践。</li>\n<li><a href=\"https://github.com/golang/go/wiki/CodeReviewComments\">Go Code Review Comments</a>：Golang官方编写的Go最佳实践，作为Effective Go的补充。</li>\n<li><a href=\"https://rakyll.org/style-packages/\">Style guideline for Go packages</a>：包含了如何组织Go包、如何命名Go包、如何写Go包文档的一些建议。</li>\n</ul><h3>代码质量</h3><p>有了组织合理的代码结构、符合Go语言代码规范的Go应用代码之后，我们还需要通过一些手段来确保我们开发出的是一个高质量的代码，这可以通过单元测试和Code Review来实现。</p><p><strong>单元测试非常重要。</strong>我们开发完一段代码后，第一个执行的测试就是单元测试。它可以保证我们的代码是符合预期的，一些异常变动能够被及时感知到。进行单元测试，不仅需要编写单元测试用例，还需要我们确保代码是可测试的，以及具有一个高的单元测试覆盖率。</p><p>接下来，我就来介绍下如何编写一个可测试的代码。</p><p>如果我们要对函数A进行测试，并且A中的所有代码均能够在单元测试环境下按预期被执行，那么函数A的代码块就是可测试的。我们来看下一般的单元测试环境有什么特点：</p><ul>\n<li>可能无法连接数据库。</li>\n<li>可能无法访问第三方服务。</li>\n</ul><p>如果函数A依赖数据库连接、第三方服务，那么在单元测试环境下执行单元测试就会失败，函数就没法测试，函数是不可测的。</p><p>解决方法也很简单：将依赖的数据库、第三方服务等抽象成接口，在被测代码中调用接口的方法，在测试时传入mock类型，从而将数据库、第三方服务等依赖从具体的被测函数中解耦出去。如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/0c/97/0cef423ec1a4f06f6f4715bd0b9f4497.png?wh=1500x438\" alt=\"\"></p><p>为了提高代码的可测性，降低单元测试的复杂度，对function和mock的要求是：</p><ul>\n<li>要尽可能减少function中的依赖，让function只依赖必要的模块。编写一个功能单一、职责分明的函数，会有利于减少依赖。</li>\n<li>依赖模块应该是易Mock的。</li>\n</ul><p>为了协助你理解，我们先来看一段不可测试的代码：</p><pre><code>package post\n\nimport &quot;google.golang.org/grpc&quot;\n\ntype Post struct {\n\tName    string\n\tAddress string\n}\n\nfunc ListPosts(client *grpc.ClientConn) ([]*Post, error) {\n\treturn client.ListPosts()\n}\n</code></pre><p>这段代码中的ListPosts函数是不可测试的。因为ListPosts函数中调用了<code>client.ListPosts()</code>方法，该方法依赖于一个gRPC连接。而我们在做单元测试时，可能因为没有配置gRPC服务的地址、网络隔离等原因，导致没法建立gRPC连接，从而导致ListPosts函数执行失败。</p><p>下面，我们把这段代码改成可测试的，如下：</p><pre><code>package main\n\ntype Post struct {\n\tName    string\n\tAddress string\n}\n\ntype Service interface {\n\tListPosts() ([]*Post, error)\n}\n\nfunc ListPosts(svc Service) ([]*Post, error) {\n\treturn svc.ListPosts()\n}\n</code></pre><p>上面代码中，ListPosts函数入参为Service接口类型，只要我们传入一个实现了Service接口类型的实例，ListPosts函数即可成功运行。因此，我们可以在单元测试中可以实现一个不依赖任何第三方服务的fake实例，并传给ListPosts。上述可测代码的单元测试代码如下：</p><pre><code>package main\n\nimport &quot;testing&quot;\n\ntype fakeService struct {\n}\n\nfunc NewFakeService() Service {\n\treturn &amp;fakeService{}\n}\n\nfunc (s *fakeService) ListPosts() ([]*Post, error) {\n\tposts := make([]*Post, 0)\n\tposts = append(posts, &amp;Post{\n\t\tName:    &quot;colin&quot;,\n\t\tAddress: &quot;Shenzhen&quot;,\n\t})\n\tposts = append(posts, &amp;Post{\n\t\tName:    &quot;alex&quot;,\n\t\tAddress: &quot;Beijing&quot;,\n\t})\n\treturn posts, nil\n}\n\nfunc TestListPosts(t *testing.T) {\n\tfake := NewFakeService()\n\tif _, err := ListPosts(fake); err != nil {\n\t\tt.Fatal(&quot;list posts failed&quot;)\n\t}\n}\n</code></pre><p>当我们的代码可测之后，就可以借助一些工具来Mock需要的接口了。常用的Mock工具，有这么几个：</p><ul>\n<li><a href=\"https://github.com/golang/mock\">golang/mock</a>，是官方提供的Mock框架。它实现了基于interface的Mock功能，能够与Golang内置的testing包做很好的集成，是最常用的Mock工具。golang/mock提供了mockgen工具用来生成interface对应的Mock源文件。</li>\n<li><a href=\"https://github.com/DATA-DOG/go-sqlmock\">sqlmock</a>，可以用来模拟数据库连接。数据库是项目中比较常见的依赖，在遇到数据库依赖时都可以用它。</li>\n<li><a href=\"https://github.com/jarcoal/httpmock\">httpmock</a>，可以用来Mock HTTP请求。</li>\n<li><a href=\"https://github.com/bouk/monkey\">bouk/monkey</a>，猴子补丁，能够通过替换函数指针的方式来修改任意函数的实现。如果golang/mock、sqlmock和httpmock这几种方法都不能满足我们的需求，我们可以尝试通过猴子补丁的方式来Mock依赖。可以这么说，猴子补丁提供了单元测试 Mock 依赖的最终解决方案。</li>\n</ul><p>接下来，我们再一起看看<strong>如何提高我们的单元测试覆盖率</strong>。</p><p>当我们编写了可测试的代码之后，接下来就需要编写足够的测试用例，用来提高项目的单元测试覆盖率。这里我有以下两个建议供你参考：</p><ul>\n<li>使用gotests工具自动生成单元测试代码，减少编写单元测试用例的工作量，将你从重复的劳动中解放出来。</li>\n<li>定期检查单元测试覆盖率。你可以通过以下方法来检查：</li>\n</ul><pre><code>$ go test -race -cover  -coverprofile=./coverage.out -timeout=10m -short -v ./...\n$ go tool cover -func ./coverage.out\n</code></pre><p>执行结果如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/d2/89/d2fae0aca602c7c33466411e39c49489.png?wh=2162x412\" alt=\"\"></p><p>在提高项目的单元测试覆盖率时，我们可以先提高单元测试覆盖率低的函数，之后再检查项目的单元测试覆盖率；如果项目的单元测试覆盖率仍然低于期望的值，可以再次提高单元测试覆盖率低的函数的覆盖率，然后再检查。以此循环，最终将项目的单元测试覆盖率优化到预期的值为止。</p><p>这里要注意，对于一些可能经常会变动的函数单元测试，覆盖率要达到100%。</p><p>说完了单元测试，我们再看看<strong>如何通过Code Review来保证代码质量。</strong></p><p>Code Review可以提高代码质量、交叉排查缺陷，并且促进团队内知识共享，是保障代码质量非常有效的手段。在我们的项目开发中，一定要建立一套持久可行的Code Review机制。</p><p>但在我的研发生涯中，发现很多团队没有建立有效的Code Review机制。这些团队都认可Code Review机制带来的好处，但是因为流程难以遵守，慢慢地Code Review就变成了形式主义，最终不了了之。其实，建立Code Review机制很简单，主要有3点：</p><ul>\n<li>首先，确保我们使用的代码托管平台有Code Review的功能。比如，GitHub、GitLab这类代码托管平台都具备这种能力。</li>\n<li>接着，建立一套Code Review规范，规定如何进行Code Review。</li>\n<li>最后，也是最重要的，每次代码变更，相关开发人员都要去落实Code Review机制，并形成习惯，直到最后形成团队文化。</li>\n</ul><p><strong>到这里我们可以小结一下：组织一个合理的代码结构、编写符合Go代码规范的代码、保证代码质量，在我看来都是编写高质量Go代码的外功。那内功是什么呢？就是编程哲学和软件设计方法。</strong></p><h3>编程哲学</h3><p>那编程哲学是什么意思呢？在我看来，编程哲学，其实就是要编写符合Go语言设计哲学的代码。Go语言有很多设计哲学，对代码质量影响比较大的，我认为有两个：面向接口编程和面向“对象”编程。</p><p>我们先来看下面向接口编程。</p><p>Go 接口是一组方法的集合。任何类型，只要实现了该接口中的方法集，那么就属于这个类型，也称为实现了该接口。</p><p>接口的作用，其实就是为不同层级的模块提供一个定义好的中间层。这样，上游不再需要依赖下游的具体实现，充分地对上下游进行了解耦。很多流行的Go设计模式，就是通过面向接口编程的思想来实现的。</p><p>我们看一个面向接口编程的例子。下面这段代码定义了一个<code>Bird</code>接口，Canary和Crow类型均实现了<code>Bird</code>接口。</p><pre><code>package main\n\nimport &quot;fmt&quot;\n\n// 定义了一个鸟类\ntype Bird interface {\n\tFly()\n\tType() string\n}\n\n// 鸟类：金丝雀\ntype Canary struct {\n\tName string\n}\n\nfunc (c *Canary) Fly() {\n\tfmt.Printf(&quot;我是%s，用黄色的翅膀飞\\n&quot;, c.Name)\n}\nfunc (c *Canary) Type() string {\n\treturn c.Name\n}\n\n// 鸟类：乌鸦\ntype Crow struct {\n\tName string\n}\n\nfunc (c *Crow) Fly() {\n\tfmt.Printf(&quot;我是%s，我用黑色的翅膀飞\\n&quot;, c.Name)\n}\n\nfunc (c *Crow) Type() string {\n\treturn c.Name\n}\n\n// 让鸟类飞一下\nfunc LetItFly(bird Bird) {\n\tfmt.Printf(&quot;Let %s Fly!\\n&quot;, bird.Type())\n\tbird.Fly()\n}\n\nfunc main() {\n\tLetItFly(&amp;Canary{&quot;金丝雀&quot;})\n\tLetItFly(&amp;Crow{&quot;乌鸦&quot;})\n}\n</code></pre><p>这段代码中，因为Crow和Canary都实现了Bird接口声明的Fly、Type方法，所以可以说Crow、Canary实现了Bird接口，属于Bird类型。在函数调用时，可以传入Bird类型，并在函数内部调用Bird接口提供的方法，以此来解耦Bird的具体实现。</p><p>好了，我们总结下使用接口的好处吧：</p><ul>\n<li>代码扩展性更强了。例如，同样的Bird，可以有不同的实现。在开发中用的更多的是，将数据库的CURD操作抽象成接口，从而可以实现同一份代码对接不同数据库的目的。</li>\n<li>可以解耦上下游的实现。例如，LetItFly不用关注Bird是如何Fly的，只需要调用Bird提供的方法即可。</li>\n<li>提高了代码的可测性。因为接口可以解耦上下游实现，我们在单元测试需要依赖第三方系统/数据库的代码时，可以利用接口将具体实现解耦，实现fake类型。</li>\n<li>代码更健壮、更稳定了。例如，如果要更改Fly的方式，只需要更改相关类型的Fly方法即可，完全影响不到LetItFly函数。</li>\n</ul><p>所以，我建议你，在Go项目开发中，一定要多思考，那些可能有多种实现的地方，要考虑使用接口。</p><p>接下来，我们再来看下面向“对象”编程。</p><p>面向对象编程（OOP）有很多优点，例如可以使我们的代码变得易维护、易扩展，并能提高开发效率等，所以一个高质量的Go应用在需要时，也应该采用面向对象的方法去编程。那什么叫“在需要时”呢？就是我们在开发代码时，如果一个功能可以通过接近于日常生活和自然的思考方式来实现，这时候就应该考虑使用面向对象的编程方法。</p><p>Go语言不支持面向对象编程，但是却可以通过一些语言级的特性来实现类似的效果。</p><p>面向对象编程中，有几个核心特性：类、实例、抽象，封装、继承、多态、构造函数、析构函数、方法重载、this指针。在Go中可以通过以下几个方式来实现类似的效果：</p><ul>\n<li>类、抽象、封装通过结构体来实现。</li>\n<li>实例通过结构体变量来实现。</li>\n<li>继承通过组合来实现。这里解释下什么叫组合：一个结构体嵌到另一个结构体，称作组合。例如一个结构体包含了一个匿名结构体，就说这个结构体组合了该匿名结构体。</li>\n<li>多态通过接口来实现。</li>\n</ul><p>至于构造函数、析构函数、方法重载和this指针等，Go为了保持语言的简洁性去掉了这些特性。</p><p>Go中面向对象编程方法，见下图：</p><p><img src=\"https://static001.geekbang.org/resource/image/27/b8/27c84757b1f4626e84535d994ca70eb8.png?wh=1872x606\" alt=\"\"></p><p>我们通过一个示例，来具体看下Go是如何实现面向对象编程中的类、抽象、封装、继承和多态的。代码如下：</p><pre><code>package main\n\nimport &quot;fmt&quot;\n\n// 基类：Bird\ntype Bird struct {\n\tType string\n}\n\n// 鸟的类别\nfunc (bird *Bird) Class() string {\n\treturn bird.Type\n}\n\n// 定义了一个鸟类\ntype Birds interface {\n\tName() string\n\tClass() string\n}\n\n// 鸟类：金丝雀\ntype Canary struct {\n\tBird\n\tname string\n}\n\nfunc (c *Canary) Name() string {\n\treturn c.name\n}\n\n// 鸟类：乌鸦\ntype Crow struct {\n\tBird\n\tname string\n}\n\nfunc (c *Crow) Name() string {\n\treturn c.name\n}\n\nfunc NewCrow(name string) *Crow {\n\treturn &amp;Crow{\n\t\tBird: Bird{\n\t\t\tType: &quot;Crow&quot;,\n\t\t},\n\t\tname: name,\n\t}\n}\n\nfunc NewCanary(name string) *Canary {\n\treturn &amp;Canary{\n\t\tBird: Bird{\n\t\t\tType: &quot;Canary&quot;,\n\t\t},\n\t\tname: name,\n\t}\n}\n\nfunc BirdInfo(birds Birds) {\n\tfmt.Printf(&quot;I'm %s, I belong to %s bird class!\\n&quot;, birds.Name(), birds.Class())\n}\n\nfunc main() {\n    canary := NewCanary(&quot;CanaryA&quot;)\n    crow := NewCrow(&quot;CrowA&quot;)\n\tBirdInfo(canary)\n\tBirdInfo(crow)\n}\n</code></pre><p>将上述代码保存在oop.go文件中，执行以下代码输出如下：</p><pre><code>$ go run oop.go\nI'm CanaryA, I belong to Canary bird class!\nI'm CrowA, I belong to Crow bird class!\n</code></pre><p>在上面的例子中，分别通过Canary和Crow结构体定义了金丝雀和乌鸦两种类别的鸟，其中分别封装了name属性和Name方法。也就是说通过结构体实现了类，该类抽象了鸟类，并封装了该鸟类的属性和方法。</p><p>在Canary和Crow结构体中，都有一个Bird匿名字段，Bird字段为Canary和Crow类的父类，Canary和Crow继承了Bird类的Class属性和方法。也就是说通过匿名字段实现了继承。</p><p>在main函数中，通过NewCanary创建了Canary鸟类实例，并将其传给BirdInfo函数。也就是说通过结构体变量实现实例。</p><p>在BirdInfo函数中，将Birds接口类型作为参数传入，并在函数中调用了birds.Name，birds.Class方法，这两个方法会根据birds类别的不同而返回不同的名字和类别，也就是说通过接口实现了多态。</p><h3>软件设计方法</h3><p>接下来，我们继续学习编写高质量Go代码的第二项内功，也就是让编写的代码遵循一些业界沉淀下来的，优秀的软件设计方法。</p><p>优秀的软件设计方法有很多，其中有两类方法对我们代码质量的提升特别有帮助，分别是设计模式（Design pattern）和SOLID原则。</p><p>在我看来，设计模式可以理解为业界针对一些特定的场景总结出来的最佳实现方式。它的特点是解决的场景比较具体，实施起来会比较简单；而SOLID原则更侧重设计原则，需要我们彻底理解，并在编写代码时多思考和落地。</p><p>关于设计模式和SOLID原则，我是这么安排的：在<strong>第11讲</strong>，我会带你学习Go项目常用的设计模式；至于SOLID原则，网上已经有很多高质量的文章了，所以我会简单告诉你这个原则是啥，然后给你推荐一篇介绍文章。</p><p>我们先了解下有哪些设计模式。</p><p>在软件领域，沉淀了一些比较优秀的设计模式，其中最受欢迎的是GOF设计模式。GOF设计模式中包含了3大类（创建型模式、结构型模式、行为型模式），共25种经典的、可以解决常见软件设计问题的设计方案。这25种设计方案同样也适用于Go语言开发的项目。</p><p>这里，我将这25种设计模式总结成了一张图，你可以先看看，有个大概的印象，对于一些在Go项目开发中常用的设计模式，我会在<strong>第11讲</strong>详细介绍。</p><p><img src=\"https://static001.geekbang.org/resource/image/14/9c/1440f4bbcda682c8f5e7a599c8c51f9c.png?wh=2963x1613\" alt=\"\"></p><p><strong>如果说设计模式解决的是具体的场景，那么SOLID原则就是我们设计应用代码时的指导方针。</strong></p><p>SOLID原则，是由罗伯特·C·马丁在21世纪早期引入的，包括了面向对象编程和面向对象设计的五个基本原则：</p><p><img src=\"https://static001.geekbang.org/resource/image/19/3b/19b697bbbe31450d6cc8f222491d3e3b.png?wh=1462x879\" alt=\"\"></p><p>遵循SOLID原则可以确保我们设计的代码是易维护、易扩展、易阅读的。SOLID原则同样也适用于Go程序设计。</p><p>如果你需要更详细地了解SOLID原则，可以参考下<a href=\"https://github.com/marmotedu/geekbang-go/blob/master/SOLID%E5%8E%9F%E5%88%99%E4%BB%8B%E7%BB%8D.md\">SOLID原则介绍</a>这篇文章。</p><p>到这里，我们就学完了“编写高质量的Go应用”这部分内容。接下来，我们再来学习下如何高效管理Go项目，以及如何编写高质量的项目文档。这里面的大部分内容，之前我们都有学习过，因为它们是“如何写出优雅的Go项目”的重要组成部分，所以，这里我仍然会简单介绍下它们。</p><h2>高效管理项目</h2><p>一个优雅的Go项目，还需要具备高效的项目管理特性。那么如何高效管理我们的项目呢？</p><p>不同团队、不同项目会采用不同的方法来管理项目，在我看来比较重要的有3点，分别是制定一个高效的开发流程、使用Makefile管理项目和将项目管理自动化。我们可以通过自动生成代码、借助工具、对接CI/CD系统等方法来将项目管理自动化。具体见下图：</p><p><img src=\"https://static001.geekbang.org/resource/image/61/6d/61e022c1b25dab2b0fefb407fc1c776d.png?wh=2356x766\" alt=\"\"></p><h3>高效的开发流程</h3><p>高效管理项目的第一步，就是要有一个高效的开发流程，这可以提高开发效率、减少软件维护成本。你可以回想一下设计开发流程的知识，如果印象比较模糊了，一定要回去复习下<strong>08讲</strong>的内容<strong>，</strong>因为这部分很重要 。</p><h3>使用Makefile管理项目</h3><p>为了更好地管理项目，除了一个高效的开发流程之外，使用Makefile也很重要。Makefile可以将项目管理的工作通过Makefile依赖的方式实现自动化，除了可以提高管理效率之外，还能够减少人为操作带来的失误，并统一操作方式，使项目更加规范。</p><p>IAM项目的所有操作均是通过Makefile来完成的，具体Makefile完成了如下操作：</p><pre><code> build              Build source code for host platform.\n  build.multiarch    Build source code for multiple platforms. See option PLATFORMS.\n  image              Build docker images for host arch.\n  image.multiarch    Build docker images for multiple platforms. See option PLATFORMS.\n  push               Build docker images for host arch and push images to registry.\n  push.multiarch     Build docker images for multiple platforms and push images to registry.\n  deploy             Deploy updated components to development env.\n  clean              Remove all files that are created by building.\n  lint               Check syntax and styling of go sources.\n  test               Run unit test.\n  cover              Run unit test and get test coverage.\n  release            Release iam\n  format             Gofmt (reformat) package sources (exclude vendor dir if existed).\n  verify-copyright   Verify the boilerplate headers for all files.\n  add-copyright      Ensures source code files have copyright license headers.\n  gen                Generate all necessary files, such as error code files.\n  ca                 Generate CA files for all iam components.\n  install            Install iam system with all its components.\n  swagger            Generate swagger document.\n  serve-swagger      Serve swagger spec and docs.\n  dependencies       Install necessary dependencies.\n  tools              install dependent tools.\n  check-updates      Check outdated dependencies of the go projects.\n  help               Show this help info.\n</code></pre><h3>自动生成代码</h3><p>低代码的理念现在越来越流行。虽然低代码有很多缺点，但确实有很多优点，例如：</p><ul>\n<li>自动化生成代码，减少工作量，提高工作效率。</li>\n<li>代码有既定的生成规则，相比人工编写代码，准确性更高、更规范。</li>\n</ul><p>目前来看，自动生成代码现在已经成为趋势，比如 Kubernetes项目有很多代码都是自动生成的。我认为，想写出一个优雅的Go项目，你也应该认真思考哪些地方的代码可以自动生成。在这门课的IAM项目中，就有大量的代码是自动生成的，我放在这里供你参考：</p><ul>\n<li>错误码、错误码说明文档。</li>\n<li>自动生成缺失的doc.go文件。</li>\n<li>利用gotests工具，自动生成单元测试用例。</li>\n<li>使用Swagger工具，自动生成Swagger文档。</li>\n<li>使用Mock工具，自动生成接口的Mock实例。</li>\n</ul><h3>善于借助工具</h3><p>在开发Go项目的过程中，我们也要善于借助工具，来帮助我们完成一部分工作。利用工具可以带来很多好处：</p><ul>\n<li>解放双手，提高工作效率。</li>\n<li>利用工具的确定性，可以确保执行结果的一致性。例如，使用golangci-lint对代码进行检查，可以确保不同开发者开发的代码至少都遵循golangci-lint的代码检查规范。</li>\n<li>有利于实现自动化，可以将工具集成到CI/CD流程中，触发流水线自动执行。</li>\n</ul><p>那么，Go项目中，有哪些工具可以为我们所用呢？这里，我给你整理了一些有用的工具：</p><p><img src=\"https://static001.geekbang.org/resource/image/90/80/90ca527c2863fe642f9ab3d5b90fe980.png?wh=1645x1477\" alt=\"\"></p><p>所有这些工具都可以通过下面的方式安装。</p><pre><code>$ cd $IAM_ROOT\n$ make tools.install\n</code></pre><p>IAM项目使用了上面这些工具的绝大部分，用来尽可能提高整个项目的自动化程度，提高项目维护效率。</p><h3>对接CI/CD</h3><p>代码在合并入主干时，应该有一套CI/CD流程来自动化地对代码进行检查、编译、单元测试等，只有通过后的代码才可以并入主干。通过CI/CD流程来保证代码的质量。当前比较流行的CI/CD工具有Jenkins、GitLab、Argo、Github Actions、JenkinsX等。在<strong>第51讲</strong> 和 <strong>第52讲</strong>中，我会详细介绍CI/CD的原理和实战。</p><h2>编写高质量的项目文档</h2><p>最后，一个优雅的项目，还应该有完善的文档。例如 README.md、安装文档、开发文档、使用文档、API接口文档、设计文档等等。这些内容在<a href=\"https://time.geekbang.org/column/article/380033\">第04讲</a>的文档规范部分有详细介绍，你可以去复习下。</p><h2>总结</h2><p>使用Go语言做项目开发，核心目的其实就是<strong>开发一个优雅的Go项目</strong>。那么如何开发一个优雅的Go项目呢？Go项目包含三大内容，即 Go应用、项目管理、项目文档，因此开发一个优雅的Go项目，其实就是<strong>编写高质量的Go应用</strong>、<strong>高效管理项目</strong>和<strong>编写高质量的项目文档</strong>。针对每一项，我都给出了一些实现方式，这些方式详见下图：</p><p><img src=\"https://static001.geekbang.org/resource/image/b0/cc/b051da025c897996473df44693ea4ecc.png?wh=3619x2006\" alt=\"\"></p><h2>课后练习</h2><ol>\n<li>在工作中，你还有哪些方法，来帮助你开发一个优雅的Go项目呢？</li>\n<li>在你的当前项目中有哪些可以接口化的代码呢？找到它们，并尝试用面向接口的编程哲学去重写这部分代码吧。</li>\n</ol><p>期待在留言区看到你的思考和答案，我们下一讲见！</p>","neighbors":{"left":{"article_title":"09 | 研发流程设计（下）：如何管理应用的生命周期？","id":384021},"right":{"article_title":"11 | 设计模式：Go常用设计模式概述","id":386238}}},{"article_id":386238,"article_title":"11 | 设计模式：Go常用设计模式概述","article_content":"<p>你好，我是孔令飞，今天我们来聊聊Go项目开发中常用的设计模式。</p><p>在软件开发中，经常会遇到各种各样的编码场景，这些场景往往重复发生，因此具有典型性。针对这些典型场景，我们可以自己编码解决，也可以采取更为省时省力的方式：直接采用设计模式。</p><p>设计模式是啥呢？简单来说，就是将软件开发中需要重复性解决的编码场景，按最佳实践的方式抽象成一个模型，模型描述的解决方法就是设计模式。使用设计模式，可以使代码更易于理解，保证代码的重用性和可靠性。</p><p>在软件领域，GoF（四人帮，全拼 Gang of Four）首次系统化提出了3大类、共25种可复用的经典设计方案，来解决常见的软件设计问题，为可复用软件设计奠定了一定的理论基础。</p><p>从总体上说，这些设计模式可以分为创建型模式、结构型模式、行为型模式3大类，用来完成不同的场景。这一讲，我会介绍几个在Go项目开发中比较常用的设计模式，帮助你用更加简单快捷的方法应对不同的编码场景。其中，简单工厂模式、抽象工厂模式和工厂方法模式都属于工厂模式，我会把它们放在一起讲解。</p><p><img src=\"https://static001.geekbang.org/resource/image/98/20/98fb0ecb8ba65bc83f25bb2504e51d20.png?wh=3142x1613\" alt=\"\"></p><h2>创建型模式</h2><p>首先来看创建型模式（Creational Patterns），它提供了一种<strong>在创建对象的同时隐藏创建逻辑</strong>的方式，而不是使用 new 运算符直接实例化对象。</p><!-- [[[read_end]]] --><p>这种类型的设计模式里，单例模式和工厂模式（具体包括简单工厂模式、抽象工厂模式和工厂方法模式三种）在Go项目开发中比较常用。我们先来看单例模式。</p><h3>单例模式</h3><p>单例模式（Singleton Pattern），是<strong>最简单的一个模式</strong>。在Go中，单例模式指的是全局只有一个实例，并且它负责创建自己的对象。单例模式不仅有利于减少内存开支，还有减少系统性能开销、防止多个实例产生冲突等优点。</p><p>因为单例模式保证了实例的全局唯一性，而且只被初始化一次，所以比较适合<strong>全局共享一个实例，且只需要被初始化一次的场景</strong>，例如数据库实例、全局配置、全局任务池等。</p><p>单例模式又分为<strong>饿汉方式</strong>和<strong>懒汉方式</strong>。饿汉方式指全局的单例实例在包被加载时创建，而懒汉方式指全局的单例实例在第一次被使用时创建。你可以看到，这种命名方式非常形象地体现了它们不同的特点。</p><p>接下来，我就来分别介绍下这两种方式。先来看<strong>饿汉方式</strong>。</p><p>下面是一个饿汉方式的单例模式代码：</p><pre><code>package singleton\n\ntype singleton struct {\n}\n\nvar ins *singleton = &amp;singleton{}\n\nfunc GetInsOr() *singleton {\n    return ins\n}\n</code></pre><p>你需要注意，因为实例是在包被导入时初始化的，所以如果初始化耗时，会导致程序加载时间比较长。</p><p><strong>懒汉方式是开源项目中使用最多的</strong>，但它的缺点是非并发安全，在实际使用时需要加锁。以下是懒汉方式不加锁的一个实现：</p><pre><code>package singleton\n\ntype singleton struct {\n}\n\nvar ins *singleton\n\nfunc GetInsOr() *singleton {\n    if ins == nil {\n        ins = &amp;singleton{}\n    }\n    \n    return ins\n}\n</code></pre><p>可以看到，在创建ins时，如果 <code>ins==nil</code>，就会再创建一个ins实例，这时候单例就会有多个实例。</p><p>为了解决懒汉方式非并发安全的问题，需要对实例进行加锁，下面是带检查锁的一个实现：</p><pre><code>import &quot;sync&quot;\n\ntype singleton struct {\n}\n\nvar ins *singleton\nvar mu sync.Mutex\n\nfunc GetIns() *singleton {\n\tif ins == nil {\n\t\tmu.Lock()\n\t\tif ins == nil {\n\t\t\tins = &amp;singleton{}\n\t\t}\n        mu.Unlock()\n\t}\n\treturn ins\n}\n</code></pre><p>上述代码只有在创建时才会加锁，既提高了代码效率，又保证了并发安全。</p><p>除了饿汉方式和懒汉方式，在Go开发中，还有一种更优雅的实现方式，我建议你采用这种方式，代码如下：</p><pre><code>package singleton\n\nimport (\n    &quot;sync&quot;\n)\n\ntype singleton struct {\n}\n\nvar ins *singleton\nvar once sync.Once\n\nfunc GetInsOr() *singleton {\n    once.Do(func() {\n        ins = &amp;singleton{}\n    })\n    return ins\n}\n</code></pre><p>使用<code>once.Do</code>可以确保ins实例全局只被创建一次，once.Do函数还可以确保当同时有多个创建动作时，只有一个创建动作在被执行。</p><p>另外，IAM应用中大量使用了单例模式，如果你想了解更多单例模式的使用方式，可以直接查看IAM项目代码。IAM中单例模式有 <a href=\"https://github.com/colin404test/iam/blob/IAMTAG/internal/authzserver/store/store.go#L45\">GetStoreInsOr</a>、<a href=\"https://github.com/colin404test/iam/blob/IAMTAG/internal/apiserver/store/etcd/etcd.go#L83\">GetEtcdFactoryOr</a>、<a href=\"https://github.com/colin404test/iam/blob/IAMTAG/internal/apiserver/store/mysql/mysql.go#L55\">GetMySQLFactoryOr</a>、<a href=\"https://github.com/colin404test/iam/blob/IAMTAG/internal/apiserver/api/v1/cache/cache.go#L33\">GetCacheInsOr</a>等。</p><h3>工厂模式</h3><p>工厂模式（Factory Pattern）是面向对象编程中的常用模式。在Go项目开发中，你可以通过使用多种不同的工厂模式，来使代码更简洁明了。Go中的结构体，可以理解为面向对象编程中的类，例如 Person结构体（类）实现了Greet方法。</p><pre><code>type Person struct {\n  Name string\n  Age int\n}\n\nfunc (p Person) Greet() {\n  fmt.Printf(&quot;Hi! My name is %s&quot;, p.Name)\n}\n</code></pre><p>有了Person“类”，就可以创建Person实例。我们可以通过简单工厂模式、抽象工厂模式、工厂方法模式这三种方式，来创建一个Person实例。</p><p>这三种工厂模式中，<strong>简单工厂模式</strong>是最常用、最简单的。它就是一个接受一些参数，然后返回Person实例的函数：</p><pre><code>type Person struct {\n  Name string\n  Age int\n}\n\nfunc (p Person) Greet() {\n  fmt.Printf(&quot;Hi! My name is %s&quot;, p.Name)\n}\n\nfunc NewPerson(name string, age int) *Person {\n  return &amp;Person{\n    Name: name,\n    Age: age,\n  }\n}\n</code></pre><p>和<code>p：=＆Person {}</code>这种创建实例的方式相比，简单工厂模式可以确保我们创建的实例具有需要的参数，进而保证实例的方法可以按预期执行。例如，通过<code>NewPerson</code>创建Person实例时，可以确保实例的name和age属性被设置。</p><p>再来看<strong>抽象工厂模式，</strong>它和简单工厂模式的唯一区别，就是它返回的是接口而不是结构体。</p><p>通过返回接口，可以<strong>在你不公开内部实现的情况下，让调用者使用你提供的各种功能</strong>，例如：</p><pre><code>type Person interface {\n  Greet()\n}\n\ntype person struct {\n  name string\n  age int\n}\n\nfunc (p person) Greet() {\n  fmt.Printf(&quot;Hi! My name is %s&quot;, p.name)\n}\n\n// Here, NewPerson returns an interface, and not the person struct itself\nfunc NewPerson(name string, age int) Person {\n  return person{\n    name: name,\n    age: age,\n  }\n}\n</code></pre><p>上面这个代码，定义了一个不可导出的结构体<code>person</code>，在通过NewPerson创建实例的时候返回的是接口，而不是结构体。</p><p>通过返回接口，我们还可以<strong>实现多个工厂函数，来返回不同的接口实现</strong>，例如：</p><pre><code>// We define a Doer interface, that has the method signature\n// of the `http.Client` structs `Do` method\ntype Doer interface {\n\tDo(req *http.Request) (*http.Response, error)\n}\n\n// This gives us a regular HTTP client from the `net/http` package\nfunc NewHTTPClient() Doer {\n\treturn &amp;http.Client{}\n}\n\ntype mockHTTPClient struct{}\n\nfunc (*mockHTTPClient) Do(req *http.Request) (*http.Response, error) {\n\t// The `NewRecorder` method of the httptest package gives us\n\t// a new mock request generator\n\tres := httptest.NewRecorder()\n\n\t// calling the `Result` method gives us\n\t// the default empty *http.Response object\n\treturn res.Result(), nil\n}\n\n// This gives us a mock HTTP client, which returns\n// an empty response for any request sent to it\nfunc NewMockHTTPClient() Doer {\n\treturn &amp;mockHTTPClient{}\n}\n</code></pre><p><code>NewHTTPClient</code>和<code>NewMockHTTPClient</code>都返回了同一个接口类型Doer，这使得二者可以互换使用。当你想测试一段调用了Doer接口Do方法的代码时，这一点特别有用。因为你可以使用一个Mock的HTTP客户端，从而避免了调用真实外部接口可能带来的失败。</p><p>来看个例子，假设我们想测试下面这段代码：</p><pre><code>func QueryUser(doer Doer) error {\n\treq, err := http.NewRequest(&quot;Get&quot;, &quot;http://iam.api.marmotedu.com:8080/v1/secrets&quot;, nil)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t_, err := doer.Do(req)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n</code></pre><p>其测试用例为：</p><pre><code>func TestQueryUser(t *testing.T) {\n\tdoer := NewMockHTTPClient()\n\tif err := QueryUser(doer); err != nil {\n\t\tt.Errorf(&quot;QueryUser failed, err: %v&quot;, err)\n\t}\n}\n</code></pre><p>另外，在使用简单工厂模式和抽象工厂模式返回实例对象时，都可以返回指针。例如，简单工厂模式可以这样返回实例对象：</p><pre><code>return &amp;Person{\n  Name: name,\n  Age: age\n}\n</code></pre><p>抽象工厂模式可以这样返回实例对象：</p><pre><code>return &amp;person{\n  name: name,\n  age: age\n}\n</code></pre><p>在实际开发中，我建议返回非指针的实例，因为我们主要是想通过创建实例，调用其提供的方法，而不是对实例做更改。如果需要对实例做更改，可以实现<code>SetXXX</code>的方法。通过返回非指针的实例，可以确保实例的属性，避免属性被意外/任意修改。</p><p>在<strong>简单工厂模式</strong>中，依赖于唯一的工厂对象，如果我们需要实例化一个产品，就要向工厂中传入一个参数，获取对应的对象；如果要增加一种产品，就要在工厂中修改创建产品的函数。这会导致耦合性过高，这时我们就可以使用<strong>工厂方法模式</strong>。</p><p>在<strong>工厂方法模式</strong>中，依赖工厂函数，我们可以通过实现工厂函数来创建多种工厂，将对象创建从由一个对象负责所有具体类的实例化，变成由一群子类来负责对具体类的实例化，从而将过程解耦。</p><p>下面是<strong>工厂方法模式</strong>的一个代码实现：</p><pre><code>type Person struct {\n\tname string\n\tage int\n}\n\nfunc NewPersonFactory(age int) func(name string) Person {\n\treturn func(name string) Person {\n\t\treturn Person{\n\t\t\tname: name,\n\t\t\tage: age,\n\t\t}\n\t}\n}\n</code></pre><p>然后，我们可以使用此功能来创建具有默认年龄的工厂：</p><pre><code>newBaby := NewPersonFactory(1)\nbaby := newBaby(&quot;john&quot;)\n\nnewTeenager := NewPersonFactory(16)\nteen := newTeenager(&quot;jill&quot;)\n</code></pre><h2>结构型模式</h2><p>我已经向你介绍了单例模式、工厂模式这两种创建型模式，接下来我们来看结构型模式（Structural Patterns），它的特点是<strong>关注类和对象的组合</strong>。这一类型里，我想详细讲讲策略模式和模板模式。</p><h3>策略模式</h3><p>策略模式（Strategy Pattern）定义一组算法，将每个算法都封装起来，并且使它们之间可以互换。</p><p>在什么时候，我们需要用到策略模式呢？</p><p>在项目开发中，我们经常要根据不同的场景，采取不同的措施，也就是不同的<strong>策略</strong>。比如，假设我们需要对a、b 这两个整数进行计算，根据条件的不同，需要执行不同的计算方式。我们可以把所有的操作都封装在同一个函数中，然后通过 <code>if ... else ...</code> 的形式来调用不同的计算方式，这种方式称之为<strong>硬编码</strong>。</p><p>在实际应用中，随着功能和体验的不断增长，我们需要经常添加/修改策略，这样就需要不断修改已有代码，不仅会让这个函数越来越难维护，还可能因为修改带来一些bug。所以为了解耦，需要使用策略模式，定义一些独立的类来封装不同的算法，每一个类封装一个具体的算法（即策略）。</p><p>下面是一个实现策略模式的代码：</p><pre><code>package strategy\n\n// 策略模式\n\n// 定义一个策略类\ntype IStrategy interface {\n\tdo(int, int) int\n}\n\n// 策略实现：加\ntype add struct{}\n\nfunc (*add) do(a, b int) int {\n\treturn a + b\n}\n\n// 策略实现：减\ntype reduce struct{}\n\nfunc (*reduce) do(a, b int) int {\n\treturn a - b\n}\n\n// 具体策略的执行者\ntype Operator struct {\n\tstrategy IStrategy\n}\n\n// 设置策略\nfunc (operator *Operator) setStrategy(strategy IStrategy) {\n\toperator.strategy = strategy\n}\n\n// 调用策略中的方法\nfunc (operator *Operator) calculate(a, b int) int {\n\treturn operator.strategy.do(a, b)\n}\n</code></pre><p>在上述代码中，我们定义了策略接口 IStrategy，还定义了 add 和 reduce 两种策略。最后定义了一个策略执行者，可以设置不同的策略，并执行，例如：</p><pre><code>func TestStrategy(t *testing.T) {\n\toperator := Operator{}\n\n\toperator.setStrategy(&amp;add{})\n\tresult := operator.calculate(1, 2)\n\tfmt.Println(&quot;add:&quot;, result)\n\n\toperator.setStrategy(&amp;reduce{})\n\tresult = operator.calculate(2, 1)\n\tfmt.Println(&quot;reduce:&quot;, result)\n}\n</code></pre><p>可以看到，我们可以随意更换策略，而不影响Operator的所有实现。</p><h3>模版模式</h3><p>模版模式 (Template Pattern)定义一个操作中算法的骨架，而将一些步骤延迟到子类中。这种方法让子类在不改变一个算法结构的情况下，就能重新定义该算法的某些特定步骤。</p><p>简单来说，模板模式就是将一个类中能够公共使用的方法放置在抽象类中实现，将不能公共使用的方法作为抽象方法，强制子类去实现，这样就做到了将一个类作为一个模板，让开发者去填充需要填充的地方。</p><p>以下是模板模式的一个实现：</p><pre><code>package template\n\nimport &quot;fmt&quot;\n\ntype Cooker interface {\n\tfire()\n\tcooke()\n\toutfire()\n}\n\n// 类似于一个抽象类\ntype CookMenu struct {\n}\n\nfunc (CookMenu) fire() {\n\tfmt.Println(&quot;开火&quot;)\n}\n\n// 做菜，交给具体的子类实现\nfunc (CookMenu) cooke() {\n}\n\nfunc (CookMenu) outfire() {\n\tfmt.Println(&quot;关火&quot;)\n}\n\n// 封装具体步骤\nfunc doCook(cook Cooker) {\n\tcook.fire()\n\tcook.cooke()\n\tcook.outfire()\n}\n\ntype XiHongShi struct {\n\tCookMenu\n}\n\nfunc (*XiHongShi) cooke() {\n\tfmt.Println(&quot;做西红柿&quot;)\n}\n\ntype ChaoJiDan struct {\n\tCookMenu\n}\n\nfunc (ChaoJiDan) cooke() {\n\tfmt.Println(&quot;做炒鸡蛋&quot;)\n}\n</code></pre><p>这里来看下测试用例：</p><pre><code>func TestTemplate(t *testing.T) {\n\t// 做西红柿\n\txihongshi := &amp;XiHongShi{}\n\tdoCook(xihongshi)\n\n\tfmt.Println(&quot;\\n=====&gt; 做另外一道菜&quot;)\n\t// 做炒鸡蛋\n\tchaojidan := &amp;ChaoJiDan{}\n\tdoCook(chaojidan)\n\n}\n</code></pre><h2>行为型模式</h2><p>然后，让我们来看最后一个类别，行为型模式（Behavioral Patterns），它的特点是关注<strong>对象之间的通信</strong>。这一类别的设计模式中，我们会讲到代理模式和选项模式。</p><h3>代理模式</h3><p>代理模式 (Proxy Pattern)，可以为另一个对象提供一个替身或者占位符，以控制对这个对象的访问。</p><p>以下代码是一个代理模式的实现：</p><pre><code>package proxy\n\nimport &quot;fmt&quot;\n\ntype Seller interface {\n\tsell(name string)\n}\n\n// 火车站\ntype Station struct {\n\tstock int //库存\n}\n\nfunc (station *Station) sell(name string) {\n\tif station.stock &gt; 0 {\n\t\tstation.stock--\n\t\tfmt.Printf(&quot;代理点中：%s买了一张票,剩余：%d \\n&quot;, name, station.stock)\n\t} else {\n\t\tfmt.Println(&quot;票已售空&quot;)\n\t}\n\n}\n\n// 火车代理点\ntype StationProxy struct {\n\tstation *Station // 持有一个火车站对象\n}\n\nfunc (proxy *StationProxy) sell(name string) {\n\tif proxy.station.stock &gt; 0 {\n\t\tproxy.station.stock--\n\t\tfmt.Printf(&quot;代理点中：%s买了一张票,剩余：%d \\n&quot;, name, proxy.station.stock)\n\t} else {\n\t\tfmt.Println(&quot;票已售空&quot;)\n\t}\n}\n</code></pre><p>上述代码中，StationProxy代理了Station，代理类中持有被代理类对象，并且和被代理类对象实现了同一接口。</p><h3>选项模式</h3><p>选项模式（Options Pattern）也是Go项目开发中经常使用到的模式，例如，grpc/grpc-go的<a href=\"https://github.com/grpc/grpc-go/blob/v1.37.0/server.go#L514\">NewServer</a>函数，uber-go/zap包的<a href=\"https://github.com/uber-go/zap/blob/v1.16.0/logger.go#L65\">New</a>函数都用到了选项模式。使用选项模式，我们可以创建一个带有默认值的struct变量，并选择性地修改其中一些参数的值。</p><p>在Python语言中，创建一个对象时，可以给参数设置默认值，这样在不传入任何参数时，可以返回携带默认值的对象，并在需要时修改对象的属性。这种特性可以大大简化开发者创建一个对象的成本，尤其是在对象拥有众多属性时。</p><p>而在Go语言中，因为不支持给参数设置默认值，为了既能够创建带默认值的实例，又能够创建自定义参数的实例，不少开发者会通过以下两种方法来实现：</p><p>第一种方法，我们要分别开发两个用来创建实例的函数，一个可以创建带默认值的实例，一个可以定制化创建实例。</p><pre><code>package options\n\nimport (\n\t&quot;time&quot;\n)\n\nconst (\n\tdefaultTimeout = 10\n\tdefaultCaching = false\n)\n\ntype Connection struct {\n\taddr    string\n\tcache   bool\n\ttimeout time.Duration\n}\n\n// NewConnect creates a connection.\nfunc NewConnect(addr string) (*Connection, error) {\n\treturn &amp;Connection{\n\t\taddr:    addr,\n\t\tcache:   defaultCaching,\n\t\ttimeout: defaultTimeout,\n\t}, nil\n}\n\n// NewConnectWithOptions creates a connection with options.\nfunc NewConnectWithOptions(addr string, cache bool, timeout time.Duration) (*Connection, error) {\n\treturn &amp;Connection{\n\t\taddr:    addr,\n\t\tcache:   cache,\n\t\ttimeout: timeout,\n\t}, nil\n}\n</code></pre><p>使用这种方式，创建同一个Connection实例，却要实现两个不同的函数，实现方式很不优雅。</p><p>另外一种方法相对优雅些。我们需要创建一个带默认值的选项，并用该选项创建实例：</p><pre><code>package options\n\nimport (\n\t&quot;time&quot;\n)\n\nconst (\n\tdefaultTimeout = 10\n\tdefaultCaching = false\n)\n\ntype Connection struct {\n\taddr    string\n\tcache   bool\n\ttimeout time.Duration\n}\n\ntype ConnectionOptions struct {\n\tCaching bool\n\tTimeout time.Duration\n}\n\nfunc NewDefaultOptions() *ConnectionOptions {\n\treturn &amp;ConnectionOptions{\n\t\tCaching: defaultCaching,\n\t\tTimeout: defaultTimeout,\n\t}\n}\n\n// NewConnect creates a connection with options.\nfunc NewConnect(addr string, opts *ConnectionOptions) (*Connection, error) {\n\treturn &amp;Connection{\n\t\taddr:    addr,\n\t\tcache:   opts.Caching,\n\t\ttimeout: opts.Timeout,\n\t}, nil\n}\n</code></pre><p>使用这种方式，虽然只需要实现一个函数来创建实例，但是也有缺点：为了创建Connection实例，每次我们都要创建ConnectionOptions，操作起来比较麻烦。</p><p>那么有没有更优雅的解决方法呢？答案当然是有的，就是使用选项模式来创建实例。以下代码通过选项模式实现上述功能：</p><pre><code>package options\n\nimport (\n\t&quot;time&quot;\n)\n\ntype Connection struct {\n\taddr    string\n\tcache   bool\n\ttimeout time.Duration\n}\n\nconst (\n\tdefaultTimeout = 10\n\tdefaultCaching = false\n)\n\ntype options struct {\n\ttimeout time.Duration\n\tcaching bool\n}\n\n// Option overrides behavior of Connect.\ntype Option interface {\n\tapply(*options)\n}\n\ntype optionFunc func(*options)\n\nfunc (f optionFunc) apply(o *options) {\n\tf(o)\n}\n\nfunc WithTimeout(t time.Duration) Option {\n\treturn optionFunc(func(o *options) {\n\t\to.timeout = t\n\t})\n}\n\nfunc WithCaching(cache bool) Option {\n\treturn optionFunc(func(o *options) {\n\t\to.caching = cache\n\t})\n}\n\n// Connect creates a connection.\nfunc NewConnect(addr string, opts ...Option) (*Connection, error) {\n\toptions := options{\n\t\ttimeout: defaultTimeout,\n\t\tcaching: defaultCaching,\n\t}\n\n\tfor _, o := range opts {\n\t\to.apply(&amp;options)\n\t}\n\n\treturn &amp;Connection{\n\t\taddr:    addr,\n\t\tcache:   options.caching,\n\t\ttimeout: options.timeout,\n\t}, nil\n}\n</code></pre><p>在上面的代码中，首先我们定义了<code>options</code>结构体，它携带了timeout、caching两个属性。接下来，我们通过<code>NewConnect</code>创建了一个连接，<code>NewConnect</code>函数中先创建了一个带有默认值的<code>options</code>结构体变量，并通过调用</p><pre><code>for _, o := range opts {\n    o.apply(&amp;options)\n}\n</code></pre><p>来修改所创建的<code>options</code>结构体变量。</p><p>需要修改的属性，是在<code>NewConnect</code>时，通过Option类型的选项参数传递进来的。可以通过<code>WithXXX</code>函数来创建Option类型的选项参数：WithTimeout、WithCaching。</p><p>Option类型的选项参数需要实现<code>apply(*options)</code>函数，结合WithTimeout、WithCaching函数的返回值和optionFunc的apply方法实现，可以知道<code>o.apply(&amp;options)</code>其实就是把WithTimeout、WithCaching传入的参数赋值给options结构体变量，以此动态地设置options结构体变量的属性。</p><p>这里还有一个好处：我们可以在apply函数中自定义赋值逻辑，例如<code>o.timeout = 100 * t</code>。通过这种方式，我们会有更大的灵活性来设置结构体的属性。</p><p>选项模式有很多优点，例如：支持传递多个参数，并且在参数发生变化时保持兼容性；支持任意顺序传递参数；支持默认值；方便扩展；通过WithXXX的函数命名，可以使参数意义更加明确，等等。</p><p>不过，为了实现选项模式，我们增加了很多代码，所以在开发中，要根据实际场景选择是否使用选项模式。选项模式通常适用于以下场景：</p><ul>\n<li>结构体参数很多，创建结构体时，我们期望创建一个携带默认值的结构体变量，并选择性修改其中一些参数的值。</li>\n<li>结构体参数经常变动，变动时我们又不想修改创建实例的函数。例如：结构体新增一个retry参数，但是又不想在NewConnect入参列表中添加<code>retry int</code>这样的参数声明。</li>\n</ul><p>如果结构体参数比较少，可以慎重考虑要不要采用选项模式。</p><h2>总结</h2><p>设计模式，是业界沉淀下来的针对特定场景的最佳解决方案。在软件领域，GoF首次系统化提出了3大类设计模式：创建型模式、结构型模式、行为型模式。</p><p>这一讲，我介绍了Go项目开发中6种常用的设计模式。每种设计模式解决某一类场景，我给你总结成了一张表格，你可以根据自己的需要进行选择。</p><p><img src=\"https://static001.geekbang.org/resource/image/1e/01/1e32f9d8318c8968b50e9ea7e89bbe01.png?wh=1455x1015\" alt=\"\"></p><h2>课后练习</h2><ol>\n<li>你当前开发的项目中，哪些可以用单例模式、工厂模式、选项模式来重新实现呢？如果有的话，我建议你试着重写下这部分代码。</li>\n<li>除了这一讲我们学习的 6 种设计模式之外，你还用过其他的设计模式吗？欢迎你在留言区和我分享下你的经验，或者你踩过的坑。</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"10 | 设计方法：怎么写出优雅的 Go 项目？","id":384648},"right":{"article_title":"12 | API 风格（上）：如何设计RESTful API？","id":386970}}},{"article_id":386970,"article_title":"12 | API 风格（上）：如何设计RESTful API？","article_content":"<p>你好，我是孔令飞。从今天开始，我们就要进入实战第二站，开始学习如何设计和开发Go项目开发中的基础功能了。接下来两讲，我们一起来看下如何设计应用的API风格。</p><p>绝大部分的Go后端服务需要编写API接口，对外提供服务。所以在开发之前，我们需要确定一种API风格。API风格也可以理解为API类型，目前业界常用的API风格有三种：REST、RPC和GraphQL。我们需要根据项目需求，并结合API风格的特点，确定使用哪种API风格，这对以后的编码实现、通信方式和通信效率都有很大的影响。</p><p>在Go项目开发中，用得最多的是REST和RPC，我们在IAM实战项目中也使用了REST和RPC来构建示例项目。接下来的两讲，我会详细介绍下REST和RPC这两种风格，如果你对GraphQL感兴趣，<a href=\"https://graphql.cn/\">GraphQL中文官网</a>有很多文档和代码示例，你可以自行学习。</p><p>这一讲，我们先来看下RESTful API风格设计，下一讲再介绍下RPC API风格。</p><h2>RESTful API介绍</h2><p>在回答“RESTful API是什么”之前，我们先来看下REST是什么意思：REST代表的是表现层状态转移（REpresentational State Transfer），由Roy Fielding在他的论文<a href=\"https://www.ics.uci.edu/~fielding/pubs/dissertation/top.htm\">《Architectural Styles and the Design of Network-based Software Architectures》</a>里提出。REST本身并没有创造新的技术、组件或服务，它只是一种软件架构风格，是一组架构约束条件和原则，而不是技术框架。</p><!-- [[[read_end]]] --><p><strong>REST有一系列规范，满足这些规范的API均可称为RESTful API</strong>。REST规范把所有内容都视为资源，也就是说网络上一切皆资源。REST架构对资源的操作包括获取、创建、修改和删除，这些操作正好对应HTTP协议提供的GET、POST、PUT和DELETE方法。HTTP动词与 REST风格CRUD的对应关系见下表：</p><p><img src=\"https://static001.geekbang.org/resource/image/40/92/409164157ce4cde3131f0236d660e092.png?wh=1754x582\" alt=\"\"></p><p>REST风格虽然适用于很多传输协议，但在实际开发中，由于REST天生和HTTP协议相辅相成，因此HTTP协议已经成了实现RESTful API事实上的标准。所以，REST具有以下核心特点：</p><ul>\n<li>\n<p>以资源(resource)为中心，所有的东西都抽象成资源，所有的行为都应该是在资源上的CRUD操作。</p>\n<ul>\n<li>资源对应着面向对象范式里的对象，面向对象范式以对象为中心。</li>\n<li>资源使用URI标识，每个资源实例都有一个唯一的URI标识。例如，如果我们有一个用户，用户名是admin，那么它的URI标识就可以是/users/admin。</li>\n</ul>\n</li>\n<li>\n<p>资源是有状态的，使用JSON/XML等在HTTP Body里表征资源的状态。</p>\n</li>\n<li>\n<p>客户端通过四个HTTP动词，对服务器端资源进行操作，实现“表现层状态转化”。</p>\n</li>\n<li>\n<p>无状态，这里的无状态是指每个RESTful API请求都包含了所有足够完成本次操作的信息，服务器端无须保持session。无状态对于服务端的弹性扩容是很重要的。</p>\n</li>\n</ul><p>因为怕你弄混概念，这里强调下REST和RESTful API的区别：<strong>REST是一种规范，而RESTful API则是满足这种规范的API接口。</strong></p><h2>RESTful API设计原则</h2><p>上面我们说了，RESTful API就是满足REST规范的API，由此看来，RESTful API的核心是规范，那么具体有哪些规范呢？</p><p>接下来，我就从URI设计、API版本管理等七个方面，给你详细介绍下RESTful API的设计原则，然后再通过一个示例来帮助你快速启动一个RESTful API服务。希望你学完这一讲之后，对如何设计RESTful API有一个清楚的认知。</p><h3>URI设计</h3><p>资源都是使用URI标识的，我们应该按照一定的规范来设计URI，通过规范化可以使我们的API接口更加易读、易用。以下是URI设计时，应该遵循的一些规范：</p><ul>\n<li>\n<p>资源名使用名词而不是动词，并且用名词复数表示。资源分为Collection和Member两种。</p>\n<ul>\n<li>Collection：一堆资源的集合。例如我们系统里有很多用户（User）,这些用户的集合就是Collection。Collection的URI标识应该是 <code>域名/资源名复数</code>, 例如<code>https:// iam.api.marmotedu.com/users</code>。</li>\n<li>Member：单个特定资源。例如系统中特定名字的用户，就是Collection里的一个Member。Member的URI标识应该是 <code>域名/资源名复数/资源名称</code>, 例如<code>https:// iam.api.marmotedu/users/admin</code>。</li>\n</ul>\n</li>\n<li>\n<p>URI结尾不应包含<code>/</code>。</p>\n</li>\n<li>\n<p>URI中不能出现下划线 <code>_</code>，必须用中杠线 <code>-</code>代替（有些人推荐用 <code>_</code>，有些人推荐用 <code>-</code>，统一使用一种格式即可，我比较推荐用 <code>-</code>）。</p>\n</li>\n<li>\n<p>URI路径用小写，不要用大写。</p>\n</li>\n<li>\n<p>避免层级过深的URI。超过2层的资源嵌套会很乱，建议将其他资源转化为<code>?</code>参数，比如：</p>\n</li>\n</ul><pre><code>/schools/tsinghua/classes/rooma/students/zhang # 不推荐\n/students?school=qinghua&amp;class=rooma # 推荐\n</code></pre><p>这里有个地方需要注意：在实际的API开发中，可能你会发现有些操作不能很好地映射为一个REST资源，这时候，你可以参考下面的做法。</p><ul>\n<li>将一个操作变成资源的一个属性，比如想在系统中暂时禁用某个用户，可以这么设计URI：<code>/users/zhangsan?active=false</code>。</li>\n<li>将操作当作是一个资源的嵌套资源，比如一个GitHub的加星操作：</li>\n</ul><pre><code>PUT /gists/:id/star # github star action\nDELETE /gists/:id/star # github unstar action\n</code></pre><ul>\n<li>如果以上都不能解决问题，有时可以打破这类规范。比如登录操作，登录不属于任何一个资源，URI可以设计为：/login。</li>\n</ul><p>在设计URI时，如果你遇到一些不确定的地方，推荐你参考  <a href=\"https://developer.github.com/v3/\">GitHub标准RESTful API</a>。</p><h3>REST资源操作映射为HTTP方法</h3><p>基本上RESTful API都是使用HTTP协议原生的GET、PUT、POST、DELETE来标识对资源的CRUD操作的，形成的规范如下表所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/d9/2d/d970bcd53d2827b7f2096e639d5fa82d.png?wh=1524x698\" alt=\"\"></p><p>对资源的操作应该满足安全性和幂等性：</p><ul>\n<li>安全性：不会改变资源状态，可以理解为只读的。</li>\n<li>幂等性：执行1次和执行N次，对资源状态改变的效果是等价的。</li>\n</ul><p>使用不同HTTP方法时，资源操作的安全性和幂等性对照见下表：</p><p><img src=\"https://static001.geekbang.org/resource/image/b7/e1/b746421291654e4d2e51509b885c4ee1.png?wh=1434x448\" alt=\"\"></p><p>在使用HTTP方法的时候，有以下两点需要你注意：</p><ul>\n<li>GET返回的结果，要尽量可用于PUT、POST操作中。例如，用GET方法获得了一个user的信息，调用者修改user的邮件，然后将此结果再用PUT方法更新。这要求GET、PUT、POST操作的资源属性是一致的。</li>\n<li>如果对资源进行状态/属性变更，要用PUT方法，POST方法仅用来创建或者批量删除这两种场景。</li>\n</ul><p>在设计API时，经常会有批量删除的需求，需要在请求中携带多个需要删除的资源名，但是HTTP的DELETE方法不能携带多个资源名，这时候可以通过下面三种方式来解决：</p><ul>\n<li>发起多个DELETE请求。</li>\n<li>操作路径中带多个id，id之间用分隔符分隔, 例如：<code>DELETE /users?ids=1,2,3</code>  。</li>\n<li>直接使用POST方式来批量删除，body中传入需要删除的资源列表。</li>\n</ul><p>其中，第二种是我最推荐的方式，因为使用了匹配的DELETE动词，并且不需要发送多次DELETE请求。</p><p>你需要注意的是，这三种方式都有各自的使用场景，你可以根据需要自行选择。如果选择了某一种方式，那么整个项目都需要统一用这种方式。</p><h3>统一的返回格式</h3><p>一般来说，一个系统的RESTful API会向外界开放多个资源的接口，每个接口的返回格式要保持一致。另外，每个接口都会返回成功和失败两种消息，这两种消息的格式也要保持一致。不然，客户端代码要适配不同接口的返回格式，每个返回格式又要适配成功和失败两种消息格式，会大大增加用户的学习和使用成本。</p><p>返回的格式没有强制的标准，你可以根据实际的业务需要返回不同的格式。本专栏 <strong>第19讲</strong> 中会推荐一种返回格式，它也是业界最常用和推荐的返回格式。</p><h3>API 版本管理</h3><p>随着时间的推移、需求的变更，一个API往往满足不了现有的需求，这时候就需要对API进行修改。对API进行修改时，不能影响其他调用系统的正常使用，这就要求API变更做到向下兼容，也就是新老版本共存。</p><p>但在实际场景中，很可能会出现同一个API无法向下兼容的情况。这时候最好的解决办法是从一开始就引入API版本机制，当不能向下兼容时，就引入一个新的版本，老的版本则保留原样。这样既能保证服务的可用性和安全性，同时也能满足新需求。</p><p>API版本有不同的标识方法，在RESTful API开发中，通常将版本标识放在如下3个位置：</p><ul>\n<li>URL中，比如<code>/v1/users</code>。</li>\n<li>HTTP Header中，比如<code>Accept: vnd.example-com.foo+json; version=1.0</code>。</li>\n<li>Form参数中，比如<code>/users?version=v1</code>。</li>\n</ul><p>我们这门课中的版本标识是放在URL中的，比如<code>/v1/users</code>，这样做的好处是很直观，GitHub、Kubernetes、Etcd等很多优秀的API均采用这种方式。</p><p>这里要注意，有些开发人员不建议将版本放在URL中，因为他们觉得不同的版本可以理解成同一种资源的不同表现形式，所以应该采用同一个URI。对于这一点，没有严格的标准，根据项目实际需要选择一种方式即可。</p><h3>API命名</h3><p>API通常的命名方式有三种，分别是驼峰命名法(serverAddress)、蛇形命名法(server_address)和脊柱命名法(server-address)。</p><p>驼峰命名法和蛇形命名法都需要切换输入法，会增加操作的复杂性，也容易出错，所以这里建议用脊柱命名法。GitHub API用的就是脊柱命名法，例如  <a href=\"https://docs.github.com/en/rest/reference/actions#get-allowed-actions-for-an-organization\">selected-actions</a>。</p><h3>统一分页/过滤/排序/搜索功能</h3><p>REST资源的查询接口，通常情况下都需要实现分页、过滤、排序、搜索功能，因为这些功能是每个REST资源都能用到的，所以可以实现为一个公共的API组件。下面来介绍下这些功能。</p><ul>\n<li>分页：在列出一个Collection下所有的Member时，应该提供分页功能，例如<code>/users?offset=0&amp;limit=20</code>（limit，指定返回记录的数量；offset，指定返回记录的开始位置）。引入分页功能可以减少API响应的延时，同时可以避免返回太多条目，导致服务器/客户端响应特别慢，甚至导致服务器/客户端crash的情况。</li>\n<li>过滤：如果用户不需要一个资源的全部状态属性，可以在URI参数里指定返回哪些属性，例如<code>/users?fields=email,username,address</code>。</li>\n<li>排序：用户很多时候会根据创建时间或者其他因素，列出一个Collection中前100个Member，这时可以在URI参数中指明排序参数，例如<code>/users?sort=age,desc</code>。</li>\n<li>搜索：当一个资源的Member太多时，用户可能想通过搜索，快速找到所需要的Member，或着想搜下有没有名字为xxx的某类资源，这时候就需要提供搜索功能。搜索建议按模糊匹配来搜索。</li>\n</ul><h3>域名</h3><p>API的域名设置主要有两种方式：</p><ul>\n<li><code>https://marmotedu.com/api</code>，这种方式适合API将来不会有进一步扩展的情况，比如刚开始marmotedu.com域名下只有一套API系统，未来也只有这一套API系统。</li>\n<li><code>https://iam.api.marmotedu.com</code>，如果marmotedu.com域名下未来会新增另一个系统API，这时候最好的方式是每个系统的API拥有专有的API域名，比如：<code>storage.api.marmotedu.com</code>，<code>network.api.marmotedu.com</code>。腾讯云的域名就是采用这种方式。</li>\n</ul><p>到这里，我们就将REST设计原则中的核心原则讲完了，这里有个需要注意的点：不同公司、不同团队、不同项目可能采取不同的REST设计原则，以上所列的基本上都是大家公认的原则。</p><p>REST设计原则中，还有一些原则因为内容比较多，并且可以独立成模块，所以放在后面来讲。比如  RESTful API安全性、状态返回码和认证等。</p><h2>REST示例</h2><p>上面介绍了一些概念和原则，这里我们通过一个“Hello World”程序，来教你用Go快速启动一个RESTful API服务，示例代码存放在<a href=\"https://github.com/marmotedu/gopractise-demo/blob/main/apistyle/ping/main.go\">gopractise-demo/apistyle/ping/main.go</a>。</p><pre><code>package main\n\nimport (\n\t&quot;log&quot;\n\t&quot;net/http&quot;\n)\n\nfunc main() {\n\thttp.HandleFunc(&quot;/ping&quot;, pong)\n\tlog.Println(&quot;Starting http server ...&quot;)\n\tlog.Fatal(http.ListenAndServe(&quot;:50052&quot;, nil))\n}\n\nfunc pong(w http.ResponseWriter, r *http.Request) {\n\tw.Write([]byte(&quot;pong&quot;))\n}\n</code></pre><p>在上面的代码中，我们通过http.HandleFunc，向HTTP服务注册了一个pong handler，在pong handler中，我们编写了真实的业务代码：返回pong字符串。</p><p>创建完main.go文件后，在当前目录下执行go run main.go启动HTTP服务，在一个新的Linux终端下发送HTTP请求，进行使用curl命令测试：</p><pre><code>$ curl http://127.0.0.1:50052/ping\npong\n</code></pre><h2>总结</h2><p>这一讲，我介绍了两种常用API风格中的一种，RESTful API。REST是一种API规范，而RESTful API则是满足这种规范的API接口，RESTful API的核心是规范。</p><p>在REST规范中，资源通过URI来标识，资源名使用名词而不是动词，并且用名词复数表示，资源都是分为Collection和Member两种。RESTful API中，分别使用POST、DELETE、PUT、GET来表示REST资源的增删改查，HTTP方法、Collection、Member不同组合会产生不同的操作，具体的映射你可以看下 <strong>REST资源操作映射为HTTP方法</strong> 部分的表格。</p><p>为了方便用户使用和理解，每个RESTful API的返回格式、错误和正确消息的返回格式，都应该保持一致。RESTful API需要支持API版本，并且版本应该能够向前兼容，我们可以将版本号放在URL中、HTTP Header中、Form参数中，但这里我建议将版本号放在URL中，例如 <code>/v1/users</code>，这种形式比较直观。</p><p>另外，我们可以通过脊柱命名法来命名API接口名。对于一个REST资源，其查询接口还应该支持分页/过滤/排序/搜索功能，这些功能可以用同一套机制来实现。 API的域名可以采用 <code>https://marmotedu.com/api</code> 和 <code>https://iam.api.marmotedu.com</code> 两种格式。</p><p>最后，在Go中我们可以使用net/http包来快速启动一个RESTful API服务。</p><h2>课后练习</h2><ol>\n<li>使用net/http包，快速实现一个RESTful API服务，并实现/hello接口，该接口会返回“Hello World”字符串。</li>\n<li>思考一下，RESTful API这种API风格是否能够满足你当前的项目需要，如果不满足，原因是什么？</li>\n</ol><p>期待在留言区看到你的思考和答案，也欢迎和我一起探讨关于RESTful API相关的问题，我们下一讲见！</p>","neighbors":{"left":{"article_title":"11 | 设计模式：Go常用设计模式概述","id":386238},"right":{"article_title":"13 | API 风格（下）：RPC API介绍","id":387602}}},{"article_id":387602,"article_title":"13 | API 风格（下）：RPC API介绍","article_content":"<p>你好，我是孔令飞。这一讲，我们继续来看下如何设计应用的API风格。</p><p>上一讲，我介绍了REST API风格，这一讲我来介绍下另外一种常用的API风格，RPC。在Go项目开发中，如果业务对性能要求比较高，并且需要提供给多种编程语言调用，这时候就可以考虑使用RPC API接口。RPC在Go项目开发中用得也非常多，需要我们认真掌握。</p><h2>RPC介绍</h2><p>根据维基百科的定义，RPC（Remote Procedure Call），即远程过程调用，是一个计算机通信协议。该协议允许运行于一台计算机的程序调用另一台计算机的子程序，而程序员不用额外地为这个交互作用编程。</p><p>通俗来讲，就是服务端实现了一个函数，客户端使用RPC框架提供的接口，像调用本地函数一样调用这个函数，并获取返回值。RPC屏蔽了底层的网络通信细节，使得开发人员无需关注网络编程的细节，可以将更多的时间和精力放在业务逻辑本身的实现上，从而提高开发效率。</p><p>RPC的调用过程如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/98/1d/984yy094616b9b24193b22a1f2f2271d.png?wh=2521x1671\" alt=\"\"></p><p>RPC调用具体流程如下：</p><ol>\n<li>Client通过本地调用，调用Client Stub。</li>\n<li>Client Stub将参数打包（也叫Marshalling）成一个消息，然后发送这个消息。</li>\n<li>Client所在的OS将消息发送给Server。</li>\n<li>Server端接收到消息后，将消息传递给Server Stub。</li>\n<li>Server Stub将消息解包（也叫 Unmarshalling）得到参数。</li>\n<li>Server Stub调用服务端的子程序（函数），处理完后，将最终结果按照相反的步骤返回给 Client。</li>\n</ol><!-- [[[read_end]]] --><p>这里需要注意，Stub负责调用参数和返回值的流化（serialization）、参数的打包和解包，以及网络层的通信。Client端一般叫Stub，Server端一般叫Skeleton。</p><p>目前，业界有很多优秀的RPC协议，例如腾讯的Tars、阿里的Dubbo、微博的Motan、Facebook的Thrift、RPCX，等等。但使用最多的还是<a href=\"https://github.com/grpc/grpc-go\">gRPC</a>，这也是本专栏所采用的RPC框架，所以接下来我会重点介绍gRPC框架。</p><h2>gRPC介绍</h2><p>gRPC是由Google开发的高性能、开源、跨多种编程语言的通用RPC框架，基于HTTP 2.0协议开发，默认采用Protocol Buffers数据序列化协议。gRPC具有如下特性：</p><ul>\n<li>支持多种语言，例如 Go、Java、C、C++、C#、Node.js、PHP、Python、Ruby等。</li>\n<li>基于IDL（Interface Definition Language）文件定义服务，通过proto3工具生成指定语言的数据结构、服务端接口以及客户端Stub。通过这种方式，也可以将服务端和客户端解耦，使客户端和服务端可以并行开发。</li>\n<li>通信协议基于标准的HTTP/2设计，支持双向流、消息头压缩、单TCP的多路复用、服务端推送等特性。</li>\n<li>支持Protobuf和JSON序列化数据格式。Protobuf是一种语言无关的高性能序列化框架，可以减少网络传输流量，提高通信效率。</li>\n</ul><p>这里要注意的是，gRPC的全称不是golang Remote Procedure Call，而是google Remote Procedure Call。</p><p>gRPC的调用如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/01/09/01ac424c7c1d64f678e1218827bc0109.png?wh=2079x1025\" alt=\"\"></p><p>在gRPC中，客户端可以直接调用部署在不同机器上的gRPC服务所提供的方法，调用远端的gRPC方法就像调用本地的方法一样，非常简单方便，通过gRPC调用<strong>，我们可以非常容易地构建出一个分布式应用。</strong></p><p>像很多其他的RPC服务一样，gRPC也是通过IDL语言，预先定义好接口（接口的名字、传入参数和返回参数等）。在服务端，gRPC服务实现我们所定义的接口。在客户端，gRPC存根提供了跟服务端相同的方法。</p><p>gRPC支持多种语言，比如我们可以用Go语言实现gRPC服务，并通过Java语言客户端调用gRPC服务所提供的方法。通过多语言支持，我们编写的gRPC服务能满足客户端多语言的需求。</p><p>gRPC API接口通常使用的数据传输格式是Protocol Buffers。接下来，我们就一起了解下Protocol Buffers。</p><h2>Protocol Buffers介绍</h2><p>Protocol Buffers（ProtocolBuffer/ protobuf）是Google开发的一套对数据结构进行序列化的方法，可用作（数据）通信协议、数据存储格式等，也是一种更加灵活、高效的数据格式，与XML、JSON类似。它的传输性能非常好，所以常被用在一些对数据传输性能要求比较高的系统中，作为数据传输格式。Protocol Buffers的主要特性有下面这几个。</p><ul>\n<li>更快的数据传输速度：protobuf在传输时，会将数据序列化为二进制数据，和XML、JSON的文本传输格式相比，这可以节省大量的IO操作，从而提高数据传输速度。</li>\n<li>跨平台多语言：protobuf自带的编译工具 protoc 可以基于protobuf定义文件，编译出不同语言的客户端或者服务端，供程序直接调用，因此可以满足多语言需求的场景。</li>\n<li>具有非常好的扩展性和兼容性，可以更新已有的数据结构，而不破坏和影响原有的程序。</li>\n<li>基于IDL文件定义服务，通过proto3工具生成指定语言的数据结构、服务端和客户端接口。</li>\n</ul><p>在gRPC的框架中，Protocol Buffers主要有三个作用。</p><p><strong>第一，可以用来定义数据结构。</strong>举个例子，下面的代码定义了一个SecretInfo数据结构：</p><pre><code>// SecretInfo contains secret details.\nmessage SecretInfo {\n    string name = 1;\n    string secret_id  = 2;\n    string username   = 3;\n    string secret_key = 4;\n    int64 expires = 5;\n    string description = 6;\n    string created_at = 7;\n    string updated_at = 8;\n}\n</code></pre><p><strong>第二，可以用来定义服务接口。</strong>下面的代码定义了一个Cache服务，服务包含了ListSecrets和ListPolicies 两个API接口。</p><pre><code>// Cache implements a cache rpc service.\nservice Cache{\n  rpc ListSecrets(ListSecretsRequest) returns (ListSecretsResponse) {}\n  rpc ListPolicies(ListPoliciesRequest) returns (ListPoliciesResponse) {}\n}\n</code></pre><p><strong>第三，可以通过protobuf序列化和反序列化，提升传输效率。</strong></p><h2>gRPC示例</h2><p>我们已经对gRPC这一通用RPC框架有了一定的了解，但是你可能还不清楚怎么使用gRPC编写API接口。接下来，我就通过gRPC官方的一个示例来快速给大家展示下。运行本示例需要在Linux服务器上安装Go编译器、Protocol buffer编译器（protoc，v3）和 protoc 的Go语言插件，在 <a href=\"https://time.geekbang.org/column/article/378076\"><strong>02讲</strong></a> 中我们已经安装过，这里不再讲具体的安装方法。</p><p>这个示例分为下面几个步骤：</p><ol>\n<li>定义gRPC服务。</li>\n<li>生成客户端和服务器代码。</li>\n<li>实现gRPC服务。</li>\n<li>实现gRPC客户端。</li>\n</ol><p>示例代码存放在<a href=\"https://github.com/marmotedu/gopractise-demo/tree/main/apistyle/greeter\">gopractise-demo/apistyle/greeter</a>目录下。代码结构如下：</p><pre><code>$ tree\n├── client\n│   └── main.go\n├── helloworld\n│   ├── helloworld.pb.go\n│   └── helloworld.proto\n└── server\n    └── main.go\n</code></pre><p>client目录存放Client端的代码，helloworld目录用来存放服务的IDL定义，server目录用来存放Server端的代码。</p><p>下面我具体介绍下这个示例的四个步骤。</p><ol>\n<li>定义gRPC服务。</li>\n</ol><p>首先，需要定义我们的服务。进入helloworld目录，新建文件helloworld.proto：</p><pre><code>$ cd helloworld\n$ vi helloworld.proto\n</code></pre><p>内容如下：</p><pre><code>syntax = &quot;proto3&quot;;\n\noption go_package = &quot;github.com/marmotedu/gopractise-demo/apistyle/greeter/helloworld&quot;;\n\npackage helloworld;\n\n// The greeting service definition.\nservice Greeter {\n  // Sends a greeting\n  rpc SayHello (HelloRequest) returns (HelloReply) {}\n}\n\n// The request message containing the user's name.\nmessage HelloRequest {\n  string name = 1;\n}\n\n// The response message containing the greetings\nmessage HelloReply {\n  string message = 1;\n}\n</code></pre><p>在helloworld.proto定义文件中，option关键字用来对.proto文件进行一些设置，其中go_package是必需的设置，而且go_package的值必须是包导入的路径。package关键字指定生成的.pb.go文件所在的包名。我们通过service关键字定义服务，然后再指定该服务拥有的RPC方法，并定义方法的请求和返回的结构体类型：</p><pre><code>service Greeter {\n  // Sends a greeting\n  rpc SayHello (HelloRequest) returns (HelloReply) {}\n}\n</code></pre><p>gRPC支持定义4种类型的服务方法，分别是简单模式、服务端数据流模式、客户端数据流模式和双向数据流模式。</p><ul>\n<li>\n<p>简单模式（Simple RPC）：是最简单的gRPC模式。客户端发起一次请求，服务端响应一个数据。定义格式为rpc SayHello (HelloRequest) returns (HelloReply) {}。</p>\n</li>\n<li>\n<p>服务端数据流模式（Server-side streaming RPC）：客户端发送一个请求，服务器返回数据流响应，客户端从流中读取数据直到为空。定义格式为rpc SayHello (HelloRequest) returns (stream HelloReply) {}。</p>\n</li>\n<li>\n<p>客户端数据流模式（Client-side streaming RPC）：客户端将消息以流的方式发送给服务器，服务器全部处理完成之后返回一次响应。定义格式为rpc SayHello (stream HelloRequest) returns (HelloReply) {}。</p>\n</li>\n<li>\n<p>双向数据流模式（Bidirectional streaming RPC）：客户端和服务端都可以向对方发送数据流，这个时候双方的数据可以同时互相发送，也就是可以实现实时交互RPC框架原理。定义格式为rpc SayHello (stream HelloRequest) returns (stream HelloReply) {}。</p>\n</li>\n</ul><p>本示例使用了简单模式。.proto文件也包含了Protocol Buffers 消息的定义，包括请求消息和返回消息。例如请求消息：</p><pre><code>// The request message containing the user's name.\nmessage HelloRequest {\n  string name = 1;\n}\n</code></pre><ol start=\"2\">\n<li>生成客户端和服务器代码。</li>\n</ol><p>接下来，我们需要根据.proto服务定义生成gRPC客户端和服务器接口。我们可以使用protoc编译工具，并指定使用其Go语言插件来生成：</p><pre><code>$ protoc -I. --go_out=plugins=grpc:$GOPATH/src helloworld.proto\n$ ls\nhelloworld.pb.go  helloworld.proto\n</code></pre><p>你可以看到，新增了一个helloworld.pb.go文件。</p><ol start=\"3\">\n<li>实现gRPC服务。</li>\n</ol><p>接着，我们就可以实现gRPC服务了。进入server目录，新建main.go文件：</p><pre><code>$ cd ../server\n$ vi main.go\n</code></pre><p>main.go内容如下：</p><pre><code>// Package main implements a server for Greeter service.\npackage main\n\nimport (\n\t&quot;context&quot;\n\t&quot;log&quot;\n\t&quot;net&quot;\n\n\tpb &quot;github.com/marmotedu/gopractise-demo/apistyle/greeter/helloworld&quot;\n\t&quot;google.golang.org/grpc&quot;\n)\n\nconst (\n\tport = &quot;:50051&quot;\n)\n\n// server is used to implement helloworld.GreeterServer.\ntype server struct {\n\tpb.UnimplementedGreeterServer\n}\n\n// SayHello implements helloworld.GreeterServer\nfunc (s *server) SayHello(ctx context.Context, in *pb.HelloRequest) (*pb.HelloReply, error) {\n\tlog.Printf(&quot;Received: %v&quot;, in.GetName())\n\treturn &amp;pb.HelloReply{Message: &quot;Hello &quot; + in.GetName()}, nil\n}\n\nfunc main() {\n\tlis, err := net.Listen(&quot;tcp&quot;, port)\n\tif err != nil {\n\t\tlog.Fatalf(&quot;failed to listen: %v&quot;, err)\n\t}\n\ts := grpc.NewServer()\n\tpb.RegisterGreeterServer(s, &amp;server{})\n\tif err := s.Serve(lis); err != nil {\n\t\tlog.Fatalf(&quot;failed to serve: %v&quot;, err)\n\t}\n}\n</code></pre><p>上面的代码实现了我们上一步根据服务定义生成的Go接口。</p><p>我们先定义了一个Go结构体server，并为server结构体添加<code>SayHello(context.Context, pb.HelloRequest) (pb.HelloReply, error)</code>方法，也就是说server是GreeterServer接口（位于helloworld.pb.go文件中）的一个实现。</p><p>在我们实现了gRPC服务所定义的方法之后，就可以通过 <code>net.Listen(...)</code> 指定监听客户端请求的端口；接着，通过 <code>grpc.NewServer()</code> 创建一个gRPC Server实例，并通过 <code>pb.RegisterGreeterServer(s, &amp;server{})</code> 将该服务注册到gRPC框架中；最后，通过 <code>s.Serve(lis)</code> 启动gRPC服务。</p><p>创建完main.go文件后，在当前目录下执行 <code>go run main.go</code> ，启动gRPC服务。</p><ol start=\"4\">\n<li>实现gRPC客户端。</li>\n</ol><p>打开一个新的Linux终端，进入client目录，新建main.go文件：</p><pre><code>$ cd ../client\n$ vi main.go\n</code></pre><p>main.go内容如下：</p><pre><code>// Package main implements a client for Greeter service.\npackage main\n\nimport (\n\t&quot;context&quot;\n\t&quot;log&quot;\n\t&quot;os&quot;\n\t&quot;time&quot;\n\n\tpb &quot;github.com/marmotedu/gopractise-demo/apistyle/greeter/helloworld&quot;\n\t&quot;google.golang.org/grpc&quot;\n)\n\nconst (\n\taddress     = &quot;localhost:50051&quot;\n\tdefaultName = &quot;world&quot;\n)\n\nfunc main() {\n\t// Set up a connection to the server.\n\tconn, err := grpc.Dial(address, grpc.WithInsecure(), grpc.WithBlock())\n\tif err != nil {\n\t\tlog.Fatalf(&quot;did not connect: %v&quot;, err)\n\t}\n\tdefer conn.Close()\n\tc := pb.NewGreeterClient(conn)\n\n\t// Contact the server and print out its response.\n\tname := defaultName\n\tif len(os.Args) &gt; 1 {\n\t\tname = os.Args[1]\n\t}\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tr, err := c.SayHello(ctx, &amp;pb.HelloRequest{Name: name})\n\tif err != nil {\n\t\tlog.Fatalf(&quot;could not greet: %v&quot;, err)\n\t}\n\tlog.Printf(&quot;Greeting: %s&quot;, r.Message)\n}\n</code></pre><p>在上面的代码中，我们通过如下代码创建了一个gRPC连接，用来跟服务端进行通信：</p><pre><code>// Set up a connection to the server.\nconn, err := grpc.Dial(address, grpc.WithInsecure(), grpc.WithBlock())\nif err != nil {\n    log.Fatalf(&quot;did not connect: %v&quot;, err)\n}\ndefer conn.Close()\n</code></pre><p>在创建连接时，我们可以指定不同的选项，用来控制创建连接的方式，例如grpc.WithInsecure()、grpc.WithBlock()等。gRPC支持很多选项，更多的选项可以参考grpc仓库下<a href=\"https://github.com/grpc/grpc-go/blob/v1.37.0/dialoptions.go\">dialoptions.go</a>文件中以With开头的函数。</p><p>连接建立起来之后，我们需要创建一个客户端stub，用来执行RPC请求<code>c := pb.NewGreeterClient(conn)</code>。创建完成之后，我们就可以像调用本地函数一样，调用远程的方法了。例如，下面一段代码通过 <code>c.SayHello</code> 这种本地式调用方式调用了远端的SayHello接口：</p><pre><code>r, err := c.SayHello(ctx, &amp;pb.HelloRequest{Name: name})\nif err != nil {\n    log.Fatalf(&quot;could not greet: %v&quot;, err)\n}\nlog.Printf(&quot;Greeting: %s&quot;, r.Message)\n</code></pre><p>从上面的调用格式中，我们可以看到RPC调用具有下面两个特点。</p><ul>\n<li>调用方便：RPC屏蔽了底层的网络通信细节，使得调用RPC就像调用本地方法一样方便，调用方式跟大家所熟知的调用类的方法一致：<code>ClassName.ClassFuc(params)</code>。</li>\n<li>不需要打包和解包：RPC调用的入参和返回的结果都是Go的结构体，不需要对传入参数进行打包操作，也不需要对返回参数进行解包操作，简化了调用步骤。</li>\n</ul><p>最后，创建完main.go文件后，在当前目录下，执行go run main.go发起RPC调用：</p><pre><code>$ go run main.go\n2020/10/17 07:55:00 Greeting: Hello world\n</code></pre><p>至此，我们用四个步骤，创建并调用了一个gRPC服务。接下来我再给大家讲解一个在具体场景中的注意事项。</p><p>在做服务开发时，我们经常会遇到一种场景：定义一个接口，接口会通过判断是否传入某个参数，决定接口行为。例如，我们想提供一个GetUser接口，期望GetUser接口在传入username参数时，根据username查询用户的信息，如果没有传入username，则默认根据userId查询用户信息。</p><p>这时候，我们需要判断客户端有没有传入username参数。我们不能根据username是否为空值来判断，因为我们不能区分客户端传的是空值，还是没有传username参数。这是由Go语言的语法特性决定的：如果客户端没有传入username参数，Go会默认赋值为所在类型的零值，而字符串类型的零值就是空字符串。</p><p>那我们怎么判断客户端有没有传入username参数呢？最好的方法是通过指针来判断，如果是nil指针就说明没有传入，非nil指针就说明传入，具体实现步骤如下：</p><ol>\n<li>编写protobuf定义文件。</li>\n</ol><p>新建user.proto文件，内容如下:</p><pre><code>syntax = &quot;proto3&quot;;\n\npackage proto;\noption go_package = &quot;github.com/marmotedu/gopractise-demo/protobuf/user&quot;;\n\n//go:generate protoc -I. --experimental_allow_proto3_optional --go_out=plugins=grpc:.\n\nservice User {\n  rpc GetUser(GetUserRequest) returns (GetUserResponse) {}\n}\n\nmessage GetUserRequest {\n  string class = 1;\n  optional string username = 2;\n  optional string user_id = 3;\n}\n\nmessage GetUserResponse {\n  string class = 1;\n  string user_id = 2;\n  string username = 3;\n  string address = 4;\n  string sex = 5;\n  string phone = 6;\n}\n</code></pre><p>你需要注意，这里我们在需要设置为可选字段的前面添加了<strong>optional</strong>标识。</p><ol start=\"2\">\n<li>使用protoc工具编译protobuf文件。</li>\n</ol><p>在执行protoc命令时，需要传入<code>--experimental_allow_proto3_optional</code>参数以打开<strong>optional</strong>选项，编译命令如下：</p><pre><code>$ protoc --experimental_allow_proto3_optional --go_out=plugins=grpc:. user.proto\n</code></pre><p>上述编译命令会生成user.pb.go文件，其中的GetUserRequest结构体定义如下：</p><pre><code>type GetUserRequest struct {\n    state         protoimpl.MessageState\n    sizeCache     protoimpl.SizeCache\n    unknownFields protoimpl.UnknownFields\n\n    Class    string  `protobuf:&quot;bytes,1,opt,name=class,proto3&quot; json:&quot;class,omitempty&quot;`\n    Username *string `protobuf:&quot;bytes,2,opt,name=username,proto3,oneof&quot; json:&quot;username,omitempty&quot;`\n    UserId   *string `protobuf:&quot;bytes,3,opt,name=user_id,json=userId,proto3,oneof&quot; json:&quot;user_id,omitempty&quot;`\n}\n</code></pre><p>通过 <code>optional</code> + <code>--experimental_allow_proto3_optional</code> 组合，我们可以将一个字段编译为指针类型。</p><ol start=\"3\">\n<li>编写gRPC接口实现。</li>\n</ol><p>新建一个user.go文件，内容如下：</p><pre><code>package user\n\nimport (\n    &quot;context&quot;\n\n    pb &quot;github.com/marmotedu/api/proto/apiserver/v1&quot;\n\n    &quot;github.com/marmotedu/iam/internal/apiserver/store&quot;\n)\n\ntype User struct {\n}\n\nfunc (c *User) GetUser(ctx context.Context, r *pb.GetUserRequest) (*pb.GetUserResponse, error) {\n    if r.Username != nil {\n        return store.Client().Users().GetUserByName(r.Class, r.Username)\n    }\n\n    return store.Client().Users().GetUserByID(r.Class, r.UserId)\n}\n</code></pre><p>总之，在GetUser方法中，我们可以通过判断r.Username是否为nil，来判断客户端是否传入了Username参数。</p><h2>RESTful VS gRPC</h2><p>到这里，今天我们已经介绍完了gRPC API。回想一下我们昨天学习的RESTful API，你可能想问：这两种API风格分别有什么优缺点，适用于什么场景呢？我把这个问题的答案放在了下面这张表中，你可以对照着它，根据自己的需求在实际应用时进行选择。</p><p><img src=\"https://static001.geekbang.org/resource/image/e6/ab/e6ae61fc4b0fc821f94d257239f332ab.png?wh=1483x1026\" alt=\"\"></p><p>当然，更多的时候，RESTful API 和gRPC API是一种合作的关系，对内业务使用gRPC API，对外业务使用RESTful API，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/47/18/471ac923d2eaeca8fe13cb74731c1318.png?wh=1606x1144\" alt=\"\"></p><h2>总结</h2><p>在Go项目开发中，我们可以选择使用 RESTful API 风格和 RPC API 风格，这两种服务都用得很多。其中，RESTful API风格因为规范、易理解、易用，所以<strong>适合用在需要对外提供API接口的场景中</strong>。而RPC API因为性能比较高、调用方便，<strong>更适合用在内部业务中</strong>。</p><p>RESTful API使用的是HTTP协议，而RPC API使用的是RPC协议。目前，有很多RPC协议可供你选择，而我推荐你使用gRPC，因为它很轻量，同时性能很高、很稳定，是一个优秀的RPC框架。所以目前业界用的最多的还是gRPC协议，腾讯、阿里等大厂内部很多核心的线上服务用的就是gRPC。</p><p>除了使用gRPC协议，在进行Go项目开发前，你也可以了解业界一些其他的优秀Go RPC框架，比如腾讯的tars-go、阿里的dubbo-go、Facebook的thrift、rpcx等，你可以在项目开发之前一并调研，根据实际情况进行选择。</p><h2>课后练习</h2><ol>\n<li>使用gRPC包，快速实现一个RPC API服务，并实现PrintHello接口，该接口会返回“Hello World”字符串。</li>\n<li>请你思考这个场景：你有一个gRPC服务，但是却希望该服务同时也能提供RESTful API接口，这该如何实现？</li>\n</ol><p>期待在留言区看到你的思考和答案，也欢迎和我一起探讨关于RPC API相关的问题，我们下一讲见！</p>","neighbors":{"left":{"article_title":"12 | API 风格（上）：如何设计RESTful API？","id":386970},"right":{"article_title":"14 | 项目管理：如何编写高质量的Makefile？","id":388920}}},{"article_id":388920,"article_title":"14 | 项目管理：如何编写高质量的Makefile？","article_content":"<p>你好，我是孔令飞。今天我们来聊聊如何编写高质量的Makefile。</p><p>我们在 <a href=\"https://time.geekbang.org/column/article/384648\">第10讲</a> 学习过，要写出一个优雅的Go项目，不仅仅是要开发一个优秀的Go应用，而且还要能够高效地管理项目。有效手段之一，就是通过Makefile来管理我们的项目，这就要求我们要为项目编写Makefile文件。</p><p>在和其他开发同学交流时，我发现大家都认可Makefile强大的项目管理能力，也会自己编写Makefile。但是其中的一些人项目管理做得并不好，我和他们进一步交流后发现，这些同学在用Makefile简单的语法重复编写一些低质量Makefile文件，根本没有把Makefile的功能充分发挥出来。</p><p>下面给你举个例子，你就会理解低质量的Makefile文件是什么样的了。</p><pre><code>build: clean vet\n\t@mkdir -p ./Role\n\t@export GOOS=linux &amp;&amp; go build -v .\n\nvet:\n\tgo vet ./...\n\nfmt:\n\tgo fmt ./...\n\nclean:\n\trm -rf dashboard\n</code></pre><p>上面这个Makefile存在不少问题。例如：功能简单，只能完成最基本的编译、格式化等操作，像构建镜像、自动生成代码等一些高阶的功能都没有；扩展性差，没法编译出可在Mac下运行的二进制文件；没有Help功能，使用难度高；单Makefile文件，结构单一，不适合添加一些复杂的管理功能。</p><p>所以，我们不光要编写Makefile，还要编写高质量的Makefile。那么如何编写一个高质量的Makefile呢？我觉得，可以通过以下4个方法来实现：</p><!-- [[[read_end]]] --><ol>\n<li>打好基础，也就是熟练掌握Makefile的语法。</li>\n<li>做好准备工作，也就是提前规划Makefile要实现的功能。</li>\n<li>进行规划，设计一个合理的Makefile结构。</li>\n<li>掌握方法，用好Makefile的编写技巧。</li>\n</ol><p>那么接下来，我们就详细看看这些方法。</p><h2>熟练掌握Makefile语法</h2><p>工欲善其事，必先利其器。编写高质量Makefile的第一步，便是熟练掌握Makefile的核心语法。</p><p>因为Makefile的语法比较多，我把一些建议你重点掌握的语法放在了近期会更新的特别放送中，包括Makefile规则语法、伪目标、变量赋值、条件语句和Makefile常用函数等等。</p><p>如果你想更深入、全面地学习Makefile的语法，我推荐你学习陈皓老师编写的<a href=\"https://github.com/seisman/how-to-write-makefile\">《跟我一起写 Makefile》 (PDF 重制版)</a>。</p><h2>规划Makefile要实现的功能</h2><p>接着，我们需要规划Makefile要实现的功能。提前规划好功能，有利于你设计Makefile的整体结构和实现方法。</p><p>不同项目拥有不同的Makefile功能，这些功能中一小部分是通过目标文件来实现的，但更多的功能是通过伪目标来实现的。对于Go项目来说，虽然不同项目集成的功能不一样，但绝大部分项目都需要实现一些通用的功能。接下来，我们就来看看，在一个大型Go项目中Makefile通常可以实现的功能。</p><p>下面是IAM项目的Makefile所集成的功能，希望会对你日后设计Makefile有一些帮助。</p><pre><code>$ make help\n\nUsage: make &lt;TARGETS&gt; &lt;OPTIONS&gt; ...\n\nTargets:\n  # 代码生成类命令\n  gen                Generate all necessary files, such as error code files.\n\n  # 格式化类命令\n  format             Gofmt (reformat) package sources (exclude vendor dir if existed).\n\n  # 静态代码检查\n  lint               Check syntax and styling of go sources.\n\n  # 测试类命令\n  test               Run unit test.\n  cover              Run unit test and get test coverage.\n\n  # 构建类命令\n  build              Build source code for host platform.\n  build.multiarch    Build source code for multiple platforms. See option PLATFORMS.\n\n  # Docker镜像打包类命令\n  image              Build docker images for host arch.\n  image.multiarch    Build docker images for multiple platforms. See option PLATFORMS.\n  push               Build docker images for host arch and push images to registry.\n  push.multiarch     Build docker images for multiple platforms and push images to registry.\n\n  # 部署类命令\n  deploy             Deploy updated components to development env.\n\n  # 清理类命令\n  clean              Remove all files that are created by building.\n\n  # 其他命令，不同项目会有区别\n  release            Release iam\n  verify-copyright   Verify the boilerplate headers for all files.\n  ca                 Generate CA files for all iam components.\n  install            Install iam system with all its components.\n  swagger            Generate swagger document.\n  tools              install dependent tools.\n\n  # 帮助命令\n  help               Show this help info.\n\n# 选项\nOptions:\n  DEBUG        Whether to generate debug symbols. Default is 0.\n  BINS         The binaries to build. Default is all of cmd.\n               This option is available when using: make build/build.multiarch\n               Example: make build BINS=&quot;iam-apiserver iam-authz-server&quot;\n  ...\n</code></pre><p>更详细的命令，你可以在IAM项目仓库根目录下执行<code>make help</code>查看。</p><p>通常而言，Go项目的Makefile应该实现以下功能：格式化代码、静态代码检查、单元测试、代码构建、文件清理、帮助等等。如果通过docker部署，还需要有docker镜像打包功能。因为Go是跨平台的语言，所以构建和docker打包命令，还要能够支持不同的CPU架构和平台。为了能够更好地控制Makefile命令的行为，还需要支持Options。</p><p>为了方便查看Makefile集成了哪些功能，我们需要支持help命令。help命令最好通过解析Makefile文件来输出集成的功能，例如：</p><pre><code>## help: Show this help info.\n.PHONY: help\nhelp: Makefile\n  @echo -e &quot;\\nUsage: make &lt;TARGETS&gt; &lt;OPTIONS&gt; ...\\n\\nTargets:&quot;\n  @sed -n 's/^##//p' $&lt; | column -t -s ':' | sed -e 's/^/ /'\n  @echo &quot;$$USAGE_OPTIONS&quot;\n</code></pre><p>上面的help命令，通过解析Makefile文件中的<code>##</code>注释，获取支持的命令。通过这种方式，我们以后新加命令时，就不用再对help命令进行修改了。</p><p>你可以参考上面的Makefile管理功能，结合自己项目的需求，整理出一个Makefile要实现的功能列表，并初步确定实现思路和方法。做完这些，你的编写前准备工作就基本完成了。</p><h2>设计合理的Makefile结构</h2><p>设计完Makefile需要实现的功能，接下来我们就进入Makefile编写阶段。编写阶段的第一步，就是设计一个合理的Makefile结构。</p><p>对于大型项目来说，需要管理的内容很多，所有管理功能都集成在一个Makefile中，可能会导致Makefile很大，难以阅读和维护，所以<strong>建议采用分层的设计方法，根目录下的Makefile聚合所有的Makefile命令，具体实现则按功能分类，放在另外的Makefile中</strong>。</p><p>我们经常会在Makefile命令中集成shell脚本，但如果shell脚本过于复杂，也会导致Makefile内容过多，难以阅读和维护。并且在Makefile中集成复杂的shell脚本，编写体验也很差。对于这种情况，<strong>可以将复杂的shell命令封装在shell脚本中，供Makefile直接调用，而一些简单的命令则可以直接集成在Makefile中</strong>。</p><p>所以，最终我推荐的Makefile结构如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/5c/f7/5c524e0297b6d6e4e151643d2e1bbbf7.png?wh=2575x1017\" alt=\"\"></p><p>在上面的Makefile组织方式中，根目录下的Makefile聚合了项目所有的管理功能，这些管理功能通过Makefile伪目标的方式实现。同时，还将这些伪目标进行分类，把相同类别的伪目标放在同一个Makefile中，这样可以使得Makefile更容易维护。对于复杂的命令，则编写成独立的shell脚本，并在Makefile命令中调用这些shell脚本。</p><p>举个例子，下面是IAM项目的Makefile组织结构：</p><pre><code>├── Makefile\n├── scripts\n│   ├── gendoc.sh\n│   ├── make-rules\n│   │   ├── gen.mk\n│   │   ├── golang.mk\n│   │   ├── image.mk\n│   │   └── ...\n    └── ...\n</code></pre><p>我们将相同类别的操作统一放在scripts/make-rules目录下的Makefile文件中。Makefile的文件名参考分类命名，例如 golang.mk。最后，在/Makefile 中 include 这些 Makefile。</p><p>为了跟Makefile的层级相匹配，golang.mk中的所有目标都按<code>go.xxx</code>这种方式命名。通过这种命名方式，我们可以很容易分辨出某个目标完成什么功能，放在什么文件里，这在复杂的Makefile中尤其有用。以下是IAM项目根目录下，Makefile的内容摘录，你可以看一看，作为参考：</p><pre><code>include scripts/make-rules/golang.mk\ninclude scripts/make-rules/image.mk\ninclude scripts/make-rules/gen.mk\ninclude scripts/make-rules/...\n\n## build: Build source code for host platform.\n.PHONY: build\nbuild:\n\t@$(MAKE) go.build\n\n## build.multiarch: Build source code for multiple platforms. See option PLATFORMS.\n.PHONY: build.multiarch\nbuild.multiarch:\n\t@$(MAKE) go.build.multiarch\n\n## image: Build docker images for host arch.\n.PHONY: image\nimage:\n\t@$(MAKE) image.build\n\n## push: Build docker images for host arch and push images to registry.\n.PHONY: push\npush:\n\t@$(MAKE) image.push\n\n## ca: Generate CA files for all iam components.\n.PHONY: ca\nca:\n\t@$(MAKE) gen.ca\n</code></pre><p>另外，一个合理的Makefile结构应该具有前瞻性。也就是说，要在不改变现有结构的情况下，接纳后面的新功能。这就需要你整理好Makefile当前要实现的功能、即将要实现的功能和未来可能会实现的功能，然后基于这些功能，利用Makefile编程技巧，编写可扩展的Makefile。</p><p>这里需要你注意：上面的Makefile通过 <code>.PHONY</code> 标识定义了大量的伪目标，定义伪目标一定要加 <code>.PHONY</code> 标识，否则当有同名的文件时，伪目标可能不会被执行。</p><h2>掌握Makefile编写技巧</h2><p>最后，在编写过程中，你还需要掌握一些Makefile的编写技巧，这些技巧可以使你编写的Makefile扩展性更强，功能更强大。</p><p>接下来，我会把自己长期开发过程中积累的一些Makefile编写经验分享给你。这些技巧，你需要在实际编写中多加练习，并形成编写习惯。</p><h3>技巧1：善用通配符和自动变量</h3><p>Makefile允许对目标进行类似正则运算的匹配，主要用到的通配符是<code>%</code>。通过使用通配符，可以使不同的目标使用相同的规则，从而使Makefile扩展性更强，也更简洁。</p><p>我们的IAM实战项目中，就大量使用了通配符<code>%</code>，例如：<code>go.build.%</code>、<code>ca.gen.%</code>、<code>deploy.run.%</code>、<code>tools.verify.%</code>、<code>tools.install.%</code>等。</p><p>这里，我们来看一个具体的例子，<code>tools.verify.%</code>（位于<a href=\"https://github.com/marmotedu/iam/blob/master/scripts/make-rules/tools.mk#L17\">scripts/make-rules/tools.mk</a>文件中）定义如下：</p><pre><code>tools.verify.%:\n  @if ! which $* &amp;&gt;/dev/null; then $(MAKE) tools.install.$*; fi\n</code></pre><p><code>make tools.verify.swagger</code>, <code>make tools.verify.mockgen</code>等均可以使用上面定义的规则，<code>%</code>分别代表了<code>swagger</code>和<code>mockgen</code>。</p><p>如果不使用<code>%</code>，则我们需要分别为<code>tools.verify.swagger</code>和<code>tools.verify.mockgen</code>定义规则，很麻烦，后面修改也困难。</p><p>另外，这里也能看出<code>tools.verify.%</code>这种命名方式的好处：tools说明依赖的定义位于<code>scripts/make-rules/tools.mk</code> Makefile中；<code>verify</code>说明<code>tools.verify.%</code>伪目标属于verify分类，主要用来验证工具是否安装。通过这种命名方式，你可以很容易地知道目标位于哪个Makefile文件中，以及想要完成的功能。</p><p>另外，上面的定义中还用到了自动变量<code>$*</code>，用来指代被匹配的值<code>swagger</code>、<code>mockgen</code>。</p><h3>技巧2：善用函数</h3><p>Makefile自带的函数能够帮助我们实现很多强大的功能。所以，在我们编写Makefile的过程中，如果有功能需求，可以优先使用这些函数。我把常用的函数以及它们实现的功能整理在了 <a href=\"https://github.com/marmotedu/geekbang-go/blob/master/makefile/Makefile%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0%E5%88%97%E8%A1%A8.md\">Makefile常用函数列表</a> 中，你可以参考下。</p><p>IAM的Makefile文件中大量使用了上述函数，如果你想查看这些函数的具体使用方法和场景，可以参考IAM项目的Makefile文件 <a href=\"https://github.com/marmotedu/iam/tree/master/scripts/make-rules\">make-rules</a>。</p><h3>技巧3：依赖需要用到的工具</h3><p>如果Makefile某个目标的命令中用到了某个工具，可以将该工具放在目标的依赖中。这样，当执行该目标时，就可以指定检查系统是否安装该工具，如果没有安装则自动安装，从而实现更高程度的自动化。例如，/Makefile文件中，format伪目标，定义如下：</p><pre><code>.PHONY: format\nformat: tools.verify.golines tools.verify.goimports\n  @echo &quot;===========&gt; Formating codes&quot;\n  @$(FIND) -type f -name '*.go' | $(XARGS) gofmt -s -w\n  @$(FIND) -type f -name '*.go' | $(XARGS) goimports -w -local $(ROOT_PACKAGE)\n  @$(FIND) -type f -name '*.go' | $(XARGS) golines -w --max-len=120 --reformat-tags --shorten-comments --ignore-generated .\n</code></pre><p>你可以看到，format依赖<code>tools.verify.golines tools.verify.goimports</code>。我们再来看下<code>tools.verify.golines</code>的定义：</p><pre><code>tools.verify.%:\n  @if ! which $* &amp;&gt;/dev/null; then $(MAKE) tools.install.$*; fi\n</code></pre><p>再来看下<code>tools.install.$*</code>规则：</p><pre><code>.PHONY: install.golines\ninstall.golines:\n  @$(GO) get -u github.com/segmentio/golines\n</code></pre><p>通过<code>tools.verify.%</code>规则定义，我们可以知道，<code>tools.verify.%</code>会先检查工具是否安装，如果没有安装，就会执行<code>tools.install.$*</code>来安装。如此一来，当我们执行<code>tools.verify.%</code>目标时，如果系统没有安装golines命令，就会自动调用<code>go get</code>安装，提高了Makefile的自动化程度。</p><h3>技巧4：把常用功能放在/Makefile中，不常用的放在分类Makefile中</h3><p>一个项目，尤其是大型项目，有很多需要管理的地方，其中大部分都可以通过Makefile实现自动化操作。不过，为了保持/Makefile文件的整洁性，我们不能把所有的命令都添加在/Makefile文件中。</p><p>一个比较好的建议是，将常用功能放在/Makefile中，不常用的放在分类Makefile中，并在/Makefile中include这些分类Makefile。</p><p>例如，IAM项目的/Makefile集成了<code>format</code>、<code>lint</code>、<code>test</code>、<code>build</code>等常用命令，而将<code>gen.errcode.code</code>、<code>gen.errcode.doc</code>这类不常用的功能放在scripts/make-rules/gen.mk文件中。当然，我们也可以直接执行 <code>make gen.errcode.code</code>来执行<code>gen.errcode.code</code>伪目标。通过这种方式，既可以保证/Makefile的简洁、易维护，又可以通过<code>make</code>命令来运行伪目标，更加灵活。</p><h3>技巧5：编写可扩展的Makefile</h3><p>什么叫可扩展的Makefile呢？在我看来，可扩展的Makefile包含两层含义：</p><ol>\n<li>可以在不改变Makefile结构的情况下添加新功能。</li>\n<li>扩展项目时，新功能可以自动纳入到Makefile现有逻辑中。</li>\n</ol><p>其中的第一点，我们可以通过设计合理的Makefile结构来实现。要实现第二点，就需要我们在编写Makefile时采用一定的技巧，例如多用通配符、自动变量、函数等。这里我们来看一个例子，可以让你更好地理解。</p><p>在我们IAM实战项目的<a href=\"https://github.com/marmotedu/iam/blob/v1.0.0/scripts/make-rules/golang.mk#L34\">golang.mk</a>中，执行 <code>make go.build</code> 时能够构建cmd/目录下的所有组件，也就是说，当有新组件添加时， <code>make go.build</code> 仍然能够构建新增的组件，这就实现了上面说的第二点。</p><p>具体实现方法如下：</p><pre><code>COMMANDS ?= $(filter-out %.md, $(wildcard ${ROOT_DIR}/cmd/*))\nBINS ?= $(foreach cmd,${COMMANDS},$(notdir ${cmd}))\n\n.PHONY: go.build\ngo.build: go.build.verify $(addprefix go.build., $(addprefix $(PLATFORM)., $(BINS)))\n.PHONY: go.build.%               \n\ngo.build.%:             \n  $(eval COMMAND := $(word 2,$(subst ., ,$*)))\n  $(eval PLATFORM := $(word 1,$(subst ., ,$*)))\n  $(eval OS := $(word 1,$(subst _, ,$(PLATFORM))))           \n  $(eval ARCH := $(word 2,$(subst _, ,$(PLATFORM))))                         \n  @echo &quot;===========&gt; Building binary $(COMMAND) $(VERSION) for $(OS) $(ARCH)&quot;\n  @mkdir -p $(OUTPUT_DIR)/platforms/$(OS)/$(ARCH)\n  @CGO_ENABLED=0 GOOS=$(OS) GOARCH=$(ARCH) $(GO) build $(GO_BUILD_FLAGS) -o $(OUTPUT_DIR)/platforms/$(OS)/$(ARCH)/$(COMMAND)$(GO_OUT_EXT) $(ROOT_PACKAGE)/cmd/$(COMMAND)\n</code></pre><p>当执行<code>make go.build</code> 时，会执行go.build的依赖 <code>$(addprefix go.build., $(addprefix $(PLATFORM)., $(BINS)))</code> ,<code>addprefix</code>函数最终返回字符串 <code>go.build.linux_amd64.iamctl go.build.linux_amd64.iam-authz-server go.build.linux_amd64.iam-apiserver ...</code> ，这时候就会执行 <code>go.build.%</code> 伪目标。</p><p>在 <code>go.build.%</code> 伪目标中，通过eval、word、subst函数组合，算出了COMMAND的值 <code>iamctl/iam-apiserver/iam-authz-server/...</code>，最终通过 <code>$(ROOT_PACKAGE)/cmd/$(COMMAND)</code> 定位到需要构建的组件的main函数所在目录。</p><p>上述实现中有两个技巧，你可以注意下。首先，通过</p><pre><code>COMMANDS ?= $(filter-out %.md, $(wildcard ${ROOT_DIR}/cmd/*))\nBINS ?= $(foreach cmd,${COMMANDS},$(notdir ${cmd}))\n</code></pre><p>获取到了cmd/目录下的所有组件名。</p><p>接着，通过使用通配符和自动变量，自动匹配到<code>go.build.linux_amd64.iam-authz-server</code> 这类伪目标并构建。</p><p>可以看到，想要编写一个可扩展的Makefile，熟练掌握Makefile的用法是基础，更多的是需要我们动脑思考如何去编写Makefile。</p><h3>技巧6：将所有输出存放在一个目录下，方便清理和查找</h3><p>在执行Makefile的过程中，会输出各种各样的文件，例如 Go 编译后的二进制文件、测试覆盖率数据等，我建议你把这些文件统一放在一个目录下，方便后期的清理和查找。通常我们可以把它们放在<code>_output</code>这类目录下，这样清理时就很方便，只需要清理<code>_output</code>文件夹就可以，例如：</p><pre><code>.PHONY: go.clean\ngo.clean:\n  @echo &quot;===========&gt; Cleaning all build output&quot;\n  @-rm -vrf $(OUTPUT_DIR)\n</code></pre><p>这里要注意，要用<code>-rm</code>，而不是<code>rm</code>，防止在没有<code>_output</code>目录时，执行<code>make go.clean</code>报错。</p><h3>技巧7：使用带层级的命名方式</h3><p>通过使用带层级的命名方式，例如<code>tools.verify.swagger</code> ，我们可以实现<strong>目标分组管理</strong>。这样做的好处有很多。首先，当Makefile有大量目标时，通过分组，我们可以更好地管理这些目标。其次，分组也能方便理解，可以通过组名一眼识别出该目标的功能类别。最后，这样做还可以大大减小目标重名的概率。</p><p>例如，IAM项目的Makefile就大量采用了下面这种命名方式。</p><pre><code>.PHONY: gen.run\ngen.run: gen.clean gen.errcode gen.docgo\n\n.PHONY: gen.errcode\ngen.errcode: gen.errcode.code gen.errcode.doc\n\n.PHONY: gen.errcode.code\ngen.errcode.code: tools.verify.codegen\n    ...\n.PHONY: gen.errcode.doc\ngen.errcode.doc: tools.verify.codegen\n    ...\n</code></pre><h3>技巧8：做好目标拆分</h3><p>还有一个比较实用的技巧：我们要合理地拆分目标。比如，我们可以将安装工具拆分成两个目标：验证工具是否已安装和安装工具。通过这种方式，可以给我们的Makefile带来更大的灵活性。例如：我们可以根据需要选择性地执行其中一个操作，也可以两个操作一起执行。</p><p>这里来看一个例子：</p><pre><code>gen.errcode.code: tools.verify.codegen\n\ntools.verify.%:    \n  @if ! which $* &amp;&gt;/dev/null; then $(MAKE) tools.install.$*; fi  \n\n.PHONY: install.codegen\ninstall.codegen:              \n  @$(GO) install ${ROOT_DIR}/tools/codegen/codegen.go\n</code></pre><p>上面的Makefile中，gen.errcode.code依赖了tools.verify.codegen，tools.verify.codegen会先检查codegen命令是否存在，如果不存在，再调用install.codegen来安装codegen工具。</p><p>如果我们的Makefile设计是：</p><pre><code>gen.errcode.code: install.codegen\n</code></pre><p>那每次执行gen.errcode.code都要重新安装codegen命令，这种操作是不必要的，还会导致 <code>make gen.errcode.code</code> 执行很慢。</p><h3>技巧9：设置OPTIONS</h3><p>编写Makefile时，我们还需要把一些可变的功能通过OPTIONS来控制。为了帮助你理解，这里还是拿IAM项目的Makefile来举例。</p><p>假设我们需要通过一个选项 <code>V</code> ，来控制是否需要在执行Makefile时打印详细的信息。这可以通过下面的步骤来实现。</p><p><strong>首先，</strong>在/Makefile中定义 <code>USAGE_OPTIONS</code> 。定义 <code>USAGE_OPTIONS</code> 可以使开发者在执行 <code>make help</code> 后感知到此OPTION，并根据需要进行设置。</p><pre><code>define USAGE_OPTIONS    \n                         \nOptions:\n  ...\n  BINS         The binaries to build. Default is all of cmd.\n               ...\n  ...\n  V            Set to 1 enable verbose build. Default is 0.    \nendef    \nexport USAGE_OPTIONS    \n</code></pre><p><strong>接着，</strong>在<a href=\"https://github.com/marmotedu/iam/blob/master/scripts/make-rules/common.mk#L70\">scripts/make-rules/common.mk</a>文件中，我们通过判断有没有设置V选项，来选择不同的行为：</p><pre><code>ifndef V    \nMAKEFLAGS += --no-print-directory    \nendif\n</code></pre><p>当然，我们还可以通过下面的方法来使用 <code>V</code> ：</p><pre><code>ifeq ($(origin V), undefined)                                \nMAKEFLAGS += --no-print-directory              \nendif\n</code></pre><p>上面，我介绍了 <code>V</code> OPTION，我们在Makefile中通过判断有没有定义 <code>V</code> ，来执行不同的操作。其实还有一种OPTION，这种OPTION的值我们在Makefile中是直接使用的，例如<code>BINS</code>。针对这种OPTION，我们可以通过以下方式来使用：</p><pre><code>BINS ?= $(foreach cmd,${COMMANDS},$(notdir ${cmd}))\n...\ngo.build: go.build.verify $(addprefix go.build., $(addprefix $(PLATFORM)., $(BINS)))\n</code></pre><p>也就是说，通过 <strong>?=</strong> 来判断 <code>BINS</code> 变量有没有被赋值，如果没有，则赋予等号后的值。接下来，就可以在Makefile规则中使用它。</p><h3>技巧10：定义环境变量</h3><p>我们可以在Makefile中定义一些环境变量，例如：</p><pre><code>GO := go                                          \nGO_SUPPORTED_VERSIONS ?= 1.13|1.14|1.15|1.16|1.17    \nGO_LDFLAGS += -X $(VERSION_PACKAGE).GitVersion=$(VERSION) \\    \n  -X $(VERSION_PACKAGE).GitCommit=$(GIT_COMMIT) \\       \n  -X $(VERSION_PACKAGE).GitTreeState=$(GIT_TREE_STATE) \\                          \n  -X $(VERSION_PACKAGE).BuildDate=$(shell date -u +'%Y-%m-%dT%H:%M:%SZ')    \nifneq ($(DLV),)                                                                                                                              \n  GO_BUILD_FLAGS += -gcflags &quot;all=-N -l&quot;    \n  LDFLAGS = &quot;&quot;      \nendif                                                                                   \nGO_BUILD_FLAGS += -tags=jsoniter -ldflags &quot;$(GO_LDFLAGS)&quot; \n...\nFIND := find . ! -path './third_party/*' ! -path './vendor/*'    \nXARGS := xargs --no-run-if-empty \n</code></pre><p>这些环境变量和编程中使用宏定义的作用是一样的：只要修改一处，就可以使很多地方同时生效，避免了重复的工作。</p><p>通常，我们可以将GO、GO_BUILD_FLAGS、FIND这类变量定义为环境变量。</p><h3>技巧11：自己调用自己</h3><p>在编写Makefile的过程中，你可能会遇到这样一种情况：A-Target目标命令中，需要完成操作B-Action，而操作B-Action我们已经通过伪目标B-Target实现过。为了达到最大的代码复用度，这时候最好的方式是在A-Target的命令中执行B-Target。方法如下：</p><pre><code>tools.verify.%:\n  @if ! which $* &amp;&gt;/dev/null; then $(MAKE) tools.install.$*; fi\n</code></pre><p>这里，我们通过 <code>$(MAKE)</code> 调用了伪目标 <code>tools.install.$*</code> 。要注意的是，默认情况下，Makefile在切换目录时会输出以下信息：</p><pre><code>$ make tools.install.codegen\n===========&gt; Installing codegen\nmake[1]: Entering directory `/home/colin/workspace/golang/src/github.com/marmotedu/iam'\nmake[1]: Leaving directory `/home/colin/workspace/golang/src/github.com/marmotedu/iam'\n</code></pre><p>如果觉得<strong>Entering directory</strong>这类信息很烦人，可以通过设置 <code>MAKEFLAGS += --no-print-directory</code> 来禁止Makefile打印这些信息。</p><h2>总结</h2><p>如果你想要高效管理项目，使用Makefile来管理是目前的最佳实践。我们可以通过下面的几个方法，来编写一个高质量的Makefile。</p><p>首先，你需要熟练掌握Makefile的语法。我建议你重点掌握以下语法：Makefile规则语法、伪目标、变量赋值、特殊变量、自动化变量。</p><p>接着，我们需要提前规划Makefile要实现的功能。一个大型Go项目通常需要实现以下功能：代码生成类命令、格式化类命令、静态代码检查、 测试类命令、构建类命令、Docker镜像打包类命令、部署类命令、清理类命令，等等。</p><p>然后，我们还需要通过Makefile功能分类、文件分层、复杂命令脚本化等方式，来设计一个合理的Makefile结构。</p><p>最后，我们还需要掌握一些Makefile编写技巧，例如：善用通配符、自动变量和函数；编写可扩展的Makefile；使用带层级的命名方式，等等。通过这些技巧，可以进一步保证我们编写出一个高质量的Makefile。</p><h2>课后练习</h2><ol>\n<li>走读IAM项目的Makefile实现，看下IAM项目是如何通过 <code>make tools.install</code> 一键安装所有功能，通过 <code>make tools.install.xxx</code> 来指定安装 <code>xxx</code> 工具的。</li>\n<li>你编写Makefile的时候，还用到过哪些编写技巧呢？欢迎和我分享你的经验，或者你踩过的坑。</li>\n</ol><p>期待在留言区看到你的思考和答案，也欢迎和我一起探讨关于Makefile的问题，我们下一讲见！</p>","neighbors":{"left":{"article_title":"13 | API 风格（下）：RPC API介绍","id":387602},"right":{"article_title":"15 | 研发流程实战：IAM项目是如何进行研发流程管理的？","id":389649}}},{"article_id":389649,"article_title":"15 | 研发流程实战：IAM项目是如何进行研发流程管理的？","article_content":"<p>你好，我是孔令飞。</p><p>在 <a href=\"https://time.geekbang.org/column/article/383390\"><strong>08讲</strong></a>  和 <a href=\"https://time.geekbang.org/column/article/388920\"><strong>14讲</strong></a>  ，我分别介绍了如何设计研发流程，和如何基于 Makefile 高效地管理项目。那么今天，我们就以研发流程为主线，来看下IAM项目是如何通过Makefile来高效管理项目的。学完这一讲，你不仅能更加深刻地理解 <strong>08讲</strong> 和 <strong>14讲</strong> 所介绍的内容，还能得到很多可以直接用在实际操作中的经验、技巧。</p><p>研发流程有很多阶段，其中的开发阶段和测试阶段是需要开发者深度参与的。所以在这一讲中，我会重点介绍这两个阶段中的Makefile项目管理功能，并且穿插一些我的Makefile的设计思路。</p><p>为了向你演示流程，这里先假设一个场景。我们有一个需求：给IAM客户端工具iamctl增加一个helloworld命令，该命令向终端打印hello world。</p><p>接下来，我们就来看下如何具体去执行研发流程中的每一步。首先，我们进入开发阶段。</p><h2>开发阶段</h2><p>开发阶段是开发者的主战场，完全由开发者来主导，它又可分为代码开发和代码提交两个子阶段。我们先来看下代码开发阶段。</p><h3>代码开发</h3><p>拿到需求之后，首先需要开发代码。这时，我们就需要选择一个适合团队和项目的Git工作流。因为Git  Flow工作流比较适合大型的非开源项目，所以这里我们选择<strong>Git</strong>  <strong>Flow工作流</strong>。代码开发的具体步骤如下：</p><!-- [[[read_end]]] --><p>第一步，基于develop分支，新建一个功能分支  feature/helloworld。</p><pre><code>$ git checkout -b feature/helloworld develop\n</code></pre><p><strong>这里需要注意</strong>：新建的branch名要符合Git  Flow工作流中的分支命名规则。否则，在git commit阶段，会因为branch不规范导致commit失败。IAM项目的分支命令规则具体如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/15/79/15bb43219269273baf70a27ea94e1279.png?wh=2775x1250\" alt=\"\"></p><p>IAM项目通过pre-commit githooks来确保分支名是符合规范的。在IAM项目根目录下执行git commit 命令，git会自动执行<a href=\"https://github.com/marmotedu/iam/blob/master/githooks/pre-commit\">pre-commit</a>脚本，该脚本会检查当前branch的名字是否符合规范。</p><p>这里还有一个地方需要你注意：git不会提交 <code>.git/hooks</code> 目录下的githooks脚本，所以我们需要通过以下手段，确保开发者clone仓库之后，仍然能安装我们指定的githooks脚本到 <code>.git/hooks</code> 目录：</p><pre><code># Copy githook scripts when execute makefile    \nCOPY_GITHOOK:=$(shell cp -f githooks/* .git/hooks/) \n</code></pre><p>上述代码放在<a href=\"https://github.com/marmotedu/iam/blob/master/scripts/make-rules/common.mk#L74\">scripts/make-rules/common.mk</a>文件中，每次执行make命令时都会执行，可以确保githooks都安装到 <code>.git/hooks</code> 目录下。</p><p>第二步，在feature/helloworld分支中，完成helloworld命令的添加。</p><p>首先，通过 <code>iamctl new helloworld</code> 命令创建helloworld命令模板：</p><pre><code>$ iamctl new helloworld -d internal/iamctl/cmd/helloworld\nCommand file generated: internal/iamctl/cmd/helloworld/helloworld.go\n</code></pre><p>接着，编辑<code>internal/iamctl/cmd/cmd.go</code>文件，在源码文件中添加<code>helloworld.NewCmdHelloworld(f, ioStreams),</code>，加载helloworld命令。这里将helloworld命令设置为<code>Troubleshooting and Debugging Commands</code>命令分组：</p><pre><code>import (\n    &quot;github.com/marmotedu/iam/internal/iamctl/cmd/helloworld&quot;\n)\n        ...\n        {\n            Message: &quot;Troubleshooting and Debugging Commands:&quot;,\n            Commands: []*cobra.Command{\n                validate.NewCmdValidate(f, ioStreams),\n                helloworld.NewCmdHelloworld(f, ioStreams),\n            },\n        },\n</code></pre><p>这些操作中包含了low code的思想。在第 <a href=\"https://time.geekbang.org/column/article/384648\"><strong>10讲</strong></a> 中我就强调过，要尽可能使用代码自动生成这一技术。这样做有两个好处：一方面能够提高我们的代码开发效率；另一方面也能够保证规范，减少手动操作可能带来的错误。所以这里，我将iamctl的命令也模板化，并通过 <code>iamctl new</code> 自动生成。</p><p>第三步，生成代码。</p><pre><code>$ make gen\n</code></pre><p>如果改动不涉及代码生成，可以不执行<code>make gen</code>操作。 <code>make gen</code> 执行的其实是gen.run伪目标：</p><pre><code>gen.run: gen.clean gen.errcode gen.docgo.doc\n</code></pre><p>可以看到，当执行 <code>make gen.run</code> 时，其实会先清理之前生成的文件，再分别自动生成error code和doc.go文件。</p><p>这里需要注意，通过<code>make gen</code> 生成的存量代码要具有幂等性。只有这样，才能确保每次生成的代码是一样的，避免不一致带来的问题。</p><p>我们可以将更多的与自动生成代码相关的功能放在 gen.mk Makefile 中。例如：</p><ul>\n<li>gen.docgo.doc，代表自动生成doc.go文件。</li>\n<li>gen.ca.%，代表自动生成iamctl、iam-apiserver、iam-authz-server证书文件。</li>\n</ul><p>第四步，版权检查。</p><p>如果有新文件添加，我们还需要执行 <code>make verify-copyright</code>  ，来检查新文件有没有添加版权头信息。</p><pre><code>$ make verify-copyright\n</code></pre><p>如果版权检查失败，可以执行<code>make add-copyright</code>自动添加版权头。添加版权信息只针对开源软件，如果你的软件不需要添加，就可以略过这一步。</p><p>这里还有个Makefile编写技巧：如果Makefile的command需要某个命令，就可以使该目标依赖类似tools.verify.addlicense这种目标，tools.verify.addlicense会检查该工具是否已安装，如果没有就先安装。</p><pre><code>.PHONY: copyright.verify    \ncopyright.verify: tools.verify.addlicense \n  ...\ntools.verify.%:          \n  @if ! which $* &amp;&gt;/dev/null; then $(MAKE) tools.install.$*; fi\n.PHONY: install.addlicense                              \ninstall.addlicense:        \n  @$(GO) get -u github.com/marmotedu/addlicense\n</code></pre><p>通过这种方式，可以使 <code>make copyright.verify</code> 尽可能自动化，减少手动介入的概率。</p><p>第五步，代码格式化。</p><pre><code>$ make format\n</code></pre><p>执行<code>make format</code>会依次执行以下格式化操作：</p><ol>\n<li>调用gofmt格式化你的代码。</li>\n<li>调用goimports工具，自动增删依赖的包，并将依赖包按字母序排序并分类。</li>\n<li>调用golines工具，把超过120行的代码按golines规则，格式化成&lt;120行的代码。</li>\n<li>调用 <code>go mod edit -fmt</code> 格式化go.mod文件。</li>\n</ol><p>第六步，静态代码检查。</p><pre><code>$ make lint\n</code></pre><p>关于静态代码检查，在这里你可以先了解代码开发阶段有这个步骤，至于如何操作，我会在下一讲给你详细介绍。</p><p>第七步，单元测试。</p><pre><code>$ make test\n</code></pre><p>这里要注意，并不是所有的包都需要执行单元测试。你可以通过如下命令，排除掉不需要单元测试的包：</p><pre><code>go test `go list ./...|egrep -v $(subst $(SPACE),'|',$(sort $(EXCLUDE_TESTS)))`\n</code></pre><p>在go.test的command中，我们还运行了以下命令：</p><pre><code>sed -i '/mock_.*.go/d' $(OUTPUT_DIR)/coverage.out\n</code></pre><p>运行该命令的目的，是把mock_.* .go文件中的函数单元测试信息从coverage.out中删除。mock_.*.go文件中的函数是不需要单元测试的，如果不删除，就会影响后面的单元测试覆盖率的计算。</p><p>如果想检查单元测试覆盖率，请执行：</p><pre><code>$ make cover\n</code></pre><p>默认测试覆盖率至少为60%，也可以在命令行指定覆盖率阈值为其他值，例如：</p><pre><code>$ make cover COVERAGE=90\n</code></pre><p>如果测试覆盖率不满足要求，就会返回以下错误信息：</p><pre><code>test coverage is 62.1%\ntest coverage does not meet expectations: 90%, please add test cases!\nmake[1]: *** [go.test.cover] Error 1\nmake: *** [cover] Error 2\n</code></pre><p>这里make命令的退出码为<code>1</code>。</p><p>如果单元测试覆盖率达不到设置的阈值，就需要补充测试用例，否则禁止合并到develop和master分支。IAM项目配置了GitHub Actions CI自动化流水线，CI流水线会自动运行，检查单元测试覆盖率是否达到要求。</p><p>第八步，构建。</p><p>最后，我们执行<code>make build</code>命令，构建出<code>cmd/</code>目录下所有的二进制安装文件。</p><pre><code>$ make build\n</code></pre><p><code>make build</code> 会自动构建 <code>cmd/</code> 目录下的所有组件，如果只想构建其中的一个或多个组件，可以传入 <code>BINS</code>选项，组件之间用空格隔开，并用双引号引起来：</p><pre><code>$ make build BINS=&quot;iam-apiserver iamctl&quot;\n</code></pre><p>到这里，我们就完成了代码开发阶段的全部操作。</p><p>如果你觉得手动执行的make命令比较多，可以直接执行make命令：</p><pre><code>$ make\n===========&gt; Generating iam error code go source files\n===========&gt; Generating error code markdown documentation\n===========&gt; Generating missing doc.go for go packages\n===========&gt; Verifying the boilerplate headers for all files\n===========&gt; Formating codes\n===========&gt; Run golangci to lint source codes\n===========&gt; Run unit test\n...\n===========&gt; Building binary iam-pump v0.7.2-24-g5814e7b for linux amd64\n===========&gt; Building binary iamctl v0.7.2-24-g5814e7b for linux amd64\n...\n</code></pre><p>直接执行<code>make</code>会执行伪目标<code>all</code>所依赖的伪目标 <code>all: tidy gen add-copyright format lint cover build</code>，也即执行以下操作：依赖包添加/删除、生成代码、自动添加版权头、代码格式化、静态代码检查、覆盖率测试、构建。</p><p>这里你需要注意一点：all中依赖cover，cover实际执行的是 <code>go.test.cover</code> ，而 <code>go.test.cover</code> 又依赖 <code>go.test</code> ，所以cover实际上是先执行单元测试，再检查单元测试覆盖率是否满足预设的阈值。</p><p>最后补充一点，在开发阶段我们可以根据需要随时执行 <code>make gen</code> 、 <code>make format</code> 、 <code>make lint</code> 、 <code>make cover</code> 等操作，为的是能够提前发现问题并改正。</p><h3>代码提交</h3><p>代码开发完成之后，我们就需要将代码提交到远程仓库，整个流程分为以下几个步骤。</p><p>第一步，开发完后，将代码提交到feature/helloworld分支，并push到远端仓库。</p><pre><code>$ git add internal/iamctl/cmd/helloworld internal/iamctl/cmd/cmd.go\n$ git commit -m &quot;feat: add new iamctl command 'helloworld'&quot;\n$ git push origin feature/helloworld\n</code></pre><p>这里我建议你只添加跟<code>feature/helloworld</code>相关的改动，这样就知道一个commit做了哪些变更，方便以后追溯。所以，我不建议直接执行<code>git add .</code>这类方式提交改动。</p><p>在提交commit时，commit-msg githooks会检查commit message是否符合Angular Commit Message规范，如果不符合会报错。commit-msage调用了<a href=\"https://github.com/llorllale/go-gitlint\">go-gitlint</a>来检查commit message。go-gitlint会读取 <code>.gitlint</code> 中配置的commit message格式：</p><pre><code>--subject-regex=^((Merge branch.*of.*)|((revert: )?(feat|fix|perf|style|refactor|test|ci|docs|chore)(\\(.+\\))?: [^A-Z].*[^.]$))\n--subject-maxlen=72\n--body-regex=^([^\\r\\n]{0,72}(\\r?\\n|$))*$\n</code></pre><p>IAM项目配置了GitHub Actions，当有代码被push后，会触发CI流水线，流水线会执行<code>make all</code>目标。GitHub Actions CI流程执行记录如下图：</p><p><img src=\"https://static001.geekbang.org/resource/image/68/22/6819f96bda8dcb214c3b7eeba2f37022.png?wh=2061x435\" alt=\"\"></p><p>如果CI不通过，就需要修改代码，直到CI流水线通过为止。</p><p>这里，我们来看下GitHub Actions的配置：</p><pre><code>name: IamCI\n\non: \n  push:\n    branchs:\n    - '*'\n  pull_request:\n    types: [opened, reopened]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n\n    - name: Set up Go\n      uses: actions/setup-go@v2\n      with:\n        go-version: 1.16\n\n    - name: all\n      run: make\n</code></pre><p>可以看到，GitHub Actions实际上执行了3步：拉取代码、设置Go编译环境、执行make命令（也就是执行 <code>make all</code> 目标）。</p><p>GitHub Actions也执行了 <code>make all</code> 目标，和手动操作执行的 <code>make all</code> 目标保持一致，这样做是为了让线上的CI流程和本地的CI流程完全保持一致。这样，当我们在本地执行make命令通过后，在线上也会通过。保持一个一致的执行流程和执行结果很重要。否则，本地执行make通过，但是线上却不通过，岂不很让人头疼？</p><p>第二步，提交pull request。</p><p>登陆GitHub，基于feature/helloworld创建pull request，并指定Reviewers进行code review。具体操作如下图：</p><p><img src=\"https://static001.geekbang.org/resource/image/53/ab/53f4103f5c8cabb76ef2fddaec3a54ab.png?wh=1694x733\" alt=\"\"></p><p>当有新的pull request被创建后，也会触发CI流水线。</p><p>第三步，创建完pull request后，就可以通知reviewers 来 review代码，GitHub也会发站内信。</p><p>第四步，Reviewers 对代码进行review。</p><p>Reviewer通过review github diff后的内容，并结合CI流程是否通过添加评论，并选择Comment（仅评论）、Approve（通过）、Request Changes（不通过，需要修改），如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/39/ce/39d992c7bdb35848706bce792877e8ce.png?wh=2473x1001\" alt=\"\"></p><p>如果review不通过，feature开发者可以直接在feature/helloworld分支修正代码，并push到远端的feature/helloworld分支，然后通知reviewers再次review。因为有push事件发生，所以会触发GitHub Actions CI流水线。</p><p>第五步，code review通过后，maintainer就可以将新的代码合并到develop分支。</p><p>使用<strong>Create a merge commit</strong>的方式，将pull request合并到develop分支，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/30/7d/30de6bb6c8ff431ec56debbc0f5b667d.png?wh=1247x366\" alt=\"\"></p><p><strong>Create a merge commit</strong>的实际操作是 <code>git merge --no-ff</code>，feature/helloworld分支上所有的 commit 都会加到 develop 分支上，并且会生成一个 merge commit。使用这种方式，可以清晰地知道是谁做了哪些提交，回溯历史的时候也会更加方便。</p><p>第六步，合并到develop分支后，触发CI流程。</p><p>到这里，开发阶段的操作就全部完成了，整体流程如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/44/73/444b0701f8866b50a49bd0138488c873.png?wh=1697x1028\" alt=\"\"></p><p>合并到develop分支之后，我们就可以进入开发阶段的下一阶段，也就是测试阶段了。</p><h2>测试阶段</h2><p>在测试阶段，开发人员主要负责提供测试包和修复测试期间发现的bug，这个过程中也可能会发现一些新的需求或变动点，所以需要合理评估这些新的需求或变动点是否要放在当前迭代修改。</p><p>测试阶段的操作流程如下。</p><p>第一步，基于develop分支，创建release分支，测试代码。</p><pre><code>$ git checkout -b release/1.0.0 develop\n$ make\n</code></pre><p>第二步，提交测试。</p><p>将release/1.0.0分支的代码提交给测试同学进行测试。这里假设一个测试失败的场景：我们要求打印“hello world”，但打印的是“Hello World”，需要修复。那具体应该怎么操作呢？</p><p>你可以直接在release/1.0.0分支修改代码，修改完成后，本地构建并提交代码：</p><pre><code>$ make\n$ git add internal/iamctl/cmd/helloworld/\n$ git commit -m &quot;fix: fix helloworld print bug&quot;\n$ git push origin release/1.0.0\n</code></pre><p>push到release/1.0.0后，GitHub Actions会执行CI流水线。如果流水线执行成功，就将代码提供给测试；如果测试不成功，再重新修改，直到流水线执行成功。</p><p>测试同学会对release/1.0.0分支的代码进行充分的测试，例如功能测试、性能测试、集成测试、系统测试等。</p><p>第三步，测试通过后，将功能分支合并到master分支和develop分支。</p><pre><code>$ git checkout develop\n$ git merge --no-ff release/1.0.0\n$ git checkout master\n$ git merge --no-ff release/1.0.0\n$ git tag -a v1.0.0 -m &quot;add print hello world&quot; # master分支打tag\n</code></pre><p>到这里，测试阶段的操作就基本完成了。测试阶段的产物是master/develop分支的代码。</p><p>第四步，删除feature/helloworld分支，也可以选择性删除release/1.0.0分支。</p><p>我们的代码都合并入master/develop分支后，feature开发者可以选择是否要保留feature。不过，如果没有特别的原因，我建议删掉，因为feature分支太多的话，不仅看起来很乱，还会影响性能，删除操作如下：</p><pre><code>$ git branch -d feature/helloworld\n</code></pre><h2>IAM项目的Makefile项目管理技巧</h2><p>在上面的内容中，我们以研发流程为主线，亲身体验了IAM项目的Makefile项目管理功能。这些是你最应该掌握的核心功能，但IAM项目的Makefile还有很多功能和设计技巧。接下来，我会给你分享一些很有价值的Makefile项目管理技巧。</p><h3>help自动解析</h3><p>因为随着项目的扩展，Makefile大概率会不断加入新的管理功能，这些管理功能也需要加入到 <code>make help</code> 输出中。但如果每添加一个目标，都要修改 <code>make help</code> 命令，就比较麻烦，还容易出错。所以这里，我通过自动解析的方式，来生成<code>make help</code>输出：</p><pre><code>## help: Show this help info.    \n.PHONY: help           \nhelp: Makefile               \n  @echo -e &quot;\\nUsage: make &lt;TARGETS&gt; &lt;OPTIONS&gt; ...\\n\\nTargets:&quot;                         \n  @sed -n 's/^##//p' $&lt; | column -t -s ':' | sed -e 's/^/ /'    \n  @echo &quot;$$USAGE_OPTIONS&quot;    \n</code></pre><p>目标help的命令中，通过 <code>sed -n 's/^##//p' $&lt; | column -t -s ':' | sed -e 's/^/ /'</code> 命令，自动解析Makefile中 <code>##</code> 开头的注释行，从而自动生成 <code>make help</code> 输出。</p><h3>Options中指定变量值</h3><p>通过以下赋值方式，变量可以在Makefile options中被指定：</p><pre><code>ifeq ($(origin COVERAGE),undefined)    \nCOVERAGE := 60    \nendif   \n</code></pre><p>例如，如果我们执行<code>make</code>  ，则COVERAGE设置为默认值60；如果我们执行<code>make COVERAGE=90</code>  ，则COVERAGE值为90。通过这种方式，我们可以更灵活地控制Makefile的行为。</p><h3>自动生成CHANGELOG</h3><p>一个项目最好有CHANGELOG用来展示每个版本之间的变更内容，作为Release Note的一部分。但是，如果每次都要手动编写CHANGELOG，会很麻烦，也不容易坚持，所以这里我们可以借助<a href=\"https://github.com/git-chglog/git-chglog\">git-chglog</a>工具来自动生成。</p><p>IAM项目的git-chglog工具的配置文件放在<a href=\"https://github.com/marmotedu/iam/tree/master/.chglog\">.chglog</a>目录下，在学习git-chglog工具时，你可以参考下。</p><h3>自动生成版本号</h3><p>一个项目也需要有一个版本号，当前用得比较多的是语义化版本号规范。但如果靠开发者手动打版本号，工作效率低不说，经常还会出现漏打、打的版本号不规范等问题。所以最好的办法是，版本号也通过工具自动生成。在IAM项目中，采用了<a href=\"https://github.com/arnaud-deprez/gsemver\">gsemver</a>工具来自动生成版本号。</p><p>整个IAM项目的版本号，都是通过<a href=\"https://github.com/marmotedu/iam/blob/master/scripts/ensure_tag.sh\">scripts/ensure_tag.sh</a>脚本来生成的：</p><pre><code>version=v`gsemver bump`\nif [ -z &quot;`git tag -l $version`&quot; ];then\n  git tag -a -m &quot;release version $version&quot; $version\nfi\n</code></pre><p>在scripts/ensure_tag.sh脚本中，通过 <code>gsemver bump</code> 命令来自动化生成语义化的版本号，并执行 <code>git tag -a</code> 给仓库打上版本号标签，<code>gsemver</code> 命令会根据Commit Message自动生成版本号。</p><p>之后，Makefile和Shell脚本用到的所有版本号均统一使用<a href=\"https://github.com/marmotedu/iam/blob/v1.0.0/scripts/make-rules/common.mk#L28\">scripts/make-rules/common.mk</a>文件中的VERSION变量：</p><pre><code>VERSION := $(shell git describe --tags --always --match='v*')\n</code></pre><p>上述的Shell命令通过 <code>git describe</code> 来获取离当前提交最近的tag（版本号）。</p><p>在执行 <code>git describe</code> 时，如果符合条件的tag指向最新提交，则只显示tag的名字，否则会有相关的后缀，来描述该tag之后有多少次提交，以及最新的提交commit id。例如：</p><pre><code>$ git describe --tags --always --match='v*'\nv1.0.0-3-g1909e47\n</code></pre><p>这里解释下版本号中各字符的含义：</p><ul>\n<li>3：表示自打tag v1.0.0以来有3次提交。</li>\n<li>g1909e47：g 为git的缩写，在多种管理工具并存的环境中很有用处。</li>\n<li>1909e47：7位字符表示为最新提交的commit id 前7位。</li>\n</ul><p>最后解释下参数：</p><ul>\n<li>–tags，使用所有的标签，而不是只使用带注释的标签（annotated tag）。<code>git tag &lt;tagname&gt; </code>生成一个 unannotated tag，<code>git tag -a &lt;tagname&gt; -m '&lt;message&gt;' </code>生成一个 annotated tag。</li>\n<li>–always，如果仓库没有可用的标签，那么使用commit缩写来替代标签。</li>\n<li>–match <pattern>，只考虑与给定模式相匹配的标签。</pattern></li>\n</ul><h3>保持行为一致</h3><p>上面我们介绍了一些管理功能，例如检查Commit Message是否符合规范、自动生成CHANGELOG、自动生成版本号。这些可以通过Makefile来操作，我们也可以手动执行。例如，通过以下命令，检查IAM的所有Commit是否符合Angular Commit Message规范：</p><pre><code>$ go-gitlint\nb62db1f: subject does not match regex [^(revert: )?(feat|fix|perf|style|refactor|test|ci|docs|chore)(\\(.+\\))?: [^A-Z].*[^.]$]\n</code></pre><p>也可以通过以下命令，手动来生成CHANGELOG：</p><pre><code>$ git-chglog v1.0.0 CHANGELOG/CHANGELOG-1.0.0.md\n</code></pre><p>还可以执行gsemver来生成版本号：</p><pre><code>$ gsemver bump\n1.0.1\n</code></pre><p>这里要强调的是，我们要保证<strong>不管使用手动操作，还是通过Makefile操作</strong>，都要确保git commit message规范检查结果、生成的CHANGELOG、生成的版本号是一致的。这需要我们<strong>采用同一种操作方式</strong>。</p><h2>总结</h2><p>在整个研发流程中，需要开发人员深度参与的阶段有两个，分别是开发阶段和测试阶段。在开发阶段，开发者完成代码开发之后，通常需要执行生成代码、版权检查、代码格式化、静态代码检查、单元测试、构建等操作。我们可以将这些操作集成在Makefile中，来提高效率，并借此统一操作。</p><p>另外，IAM项目在编写Makefile时也采用了一些技巧，例如<code>make help</code> 命令中，help信息是通过解析Makefile文件的注释来完成的；可以通过git-chglog自动生成CHANGELOG；通过gsemver自动生成语义化的版本号等。</p><h2>课后练习</h2><ol>\n<li>看下IAM项目的 <code>make dependencies</code> 是如何实现的，这样实现有什么好处？</li>\n<li>IAM项目中使用 了<code>gofmt</code> 、<code>goimports</code> 、<code>golines</code> 3种格式化工具，思考下，还有没有其他格式化工具值得集成在 <code>make format</code> 目标的命令中？</li>\n</ol><p>欢迎你在留言区分享你的见解，和我一起交流讨论，我们下一讲见！</p>","neighbors":{"left":{"article_title":"14 | 项目管理：如何编写高质量的Makefile？","id":388920},"right":{"article_title":"16 | 代码检查：如何进行静态代码检查？","id":390401}}},{"article_id":390401,"article_title":"16 | 代码检查：如何进行静态代码检查？","article_content":"<p>你好，我是孔令飞。上一讲中，我在讲代码开发的具体步骤时，提到了静态代码检查，今天我就来详细讲讲如何执行静态代码检查。</p><p>在做Go项目开发的过程中，我们肯定需要对Go代码做静态代码检查。虽然Go命令提供了go vet和go tool vet，但是它们检查的内容还不够全面，我们需要一种更加强大的静态代码检查工具。</p><p>其实，Go生态中有很多这样的工具，也不乏一些比较优秀的。今天我想给你介绍的golangci-lint，是目前使用最多，也最受欢迎的静态代码检查工具，我们的IAM实战项目也用到了它。</p><p>接下来，我就从golangci-lint的优点、golangci-lint提供的命令和选项、golangci-lint的配置这三个方面来向你介绍下它。在你了解这些基础知识后，我会带着你使用golangci-lint进行静态代码检查，让你熟悉操作，在这个基础上，再把我使用golangci-lint时总结的一些经验技巧分享给你。</p><h2>为什么选择golangci-lint做静态代码检查？</h2><p>选择golangci-lint，是因为它具有其他静态代码检查工具不具备的一些优点。在我看来，它的核心优点至少有这些：</p><ul>\n<li>速度非常快：golangci-lint是基于gometalinter开发的，但是平均速度要比gometalinter快5倍。golangci-lint速度快的原因有三个：可以并行检查代码；可以复用go build缓存；会缓存分析结果。</li>\n<li>可配置：支持YAML格式的配置文件，让检查更灵活，更可控。</li>\n<li>IDE集成：可以集成进多个主流的IDE，例如 VS Code、GNU Emacs、Sublime Text、Goland等。</li>\n<li>linter聚合器：1.41.1版本的golangci-lint集成了76个linter，不需要再单独安装这76个linter。并且golangci-lint还支持自定义linter。</li>\n<li>最小的误报数：golangci-lint调整了所集成linter的默认设置，大幅度减少了误报。</li>\n<li>良好的输出：输出的结果带有颜色、代码行号和linter标识，易于查看和定位。</li>\n</ul><!-- [[[read_end]]] --><p>下图是一个golangci-lint的检查结果：</p><p><img src=\"https://static001.geekbang.org/resource/image/ed/d4/ed9c1d775e31a8a5b60a5a6882d0bed4.png?wh=2527x563\" alt=\"\"></p><p>你可以看到，输出的检查结果中包括如下信息：</p><ul>\n<li>检查出问题的源码文件、行号和错误行内容。</li>\n<li>出问题的原因，也就是打印出不符合检查规则的原因。</li>\n<li>报错的linter。</li>\n</ul><p>通过查看golangci-lint的输出结果，可以准确地定位到报错的位置，快速弄明白报错的原因，方便开发者修复。</p><p>除了上述优点之外，在我看来golangci-lint还有一个非常大的优点：<strong>当前更新迭代速度很快，不断有新的linter被集成到golangci-lint中。</strong>有这么全的linter为你的代码保驾护航，你在交付代码时肯定会更有自信。</p><p>目前，有很多公司/项目使用了golangci-lint工具作为静态代码检查工具，例如 Google、Facebook、Istio、Red Hat OpenShift等。</p><h2>golangci-lint提供了哪些命令和选项？</h2><p>在使用之前，首先需要<strong>安装golangci-lint</strong>。golangci-lint的安装方法也很简单，你只需要执行以下命令，就可以安装了。</p><pre><code>$ go get github.com/golangci/golangci-lint/cmd/golangci-lint@v1.41.1\n$ golangci-lint version # 输出 golangci-lint 版本号，说明安装成功\ngolangci-lint has version v1.39.0 built from (unknown, mod sum: &quot;h1:aAUjdBxARwkGLd5PU0vKuym281f2rFOyqh3GB4nXcq8=&quot;) on (unknown)\n</code></pre><p>这里注意，为了避免安装失败，强烈建议你安装golangci-lint releases page中的指定版本，例如 v1.41.1。</p><p>另外，还建议你定期更新 golangci-lint 的版本，因为该项目正在被积极开发并不断改进。</p><p>安装之后，就可以使用了。我们可以通过执行 <code>golangci-lint -h</code> 查看其用法，golangci-lint支持的<strong>子命令</strong>见下表：</p><p><img src=\"https://static001.geekbang.org/resource/image/34/42/34617a68604b7b5613948f89230c7a42.png?wh=1376x1015\" alt=\"\"></p><p>此外，golangci-lint还支持一些<strong>全局选项</strong>。全局选项是指适用于所有子命令的选项，golangci-lint支持的全局选项如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/79/88/79e517e6a7fd3882ce30320f28aa7088.png?wh=1339x1063\" alt=\"\"></p><p>接下来，我就详细介绍下golangci-lint支持的核心子命令：run、cache、completion、config、linters。</p><h3>run命令</h3><p>run命令执行golangci-lint，对代码进行检查，是golangci-lint最为核心的一个命令。run没有子命令，但有很多选项。run命令的具体使用方法，我会在讲解如何执行静态代码检查的时候详细介绍。</p><h3>cache命令</h3><p>cache命令用来进行缓存控制，并打印缓存的信息。它包含两个子命令：</p><ul>\n<li>clean用来清除cache，当我们觉得cache的内容异常，或者cache占用空间过大时，可以通过<code>golangci-lint cache clean</code>清除cache。</li>\n<li>status用来打印cache的状态，比如cache的存放目录和cache的大小，例如：</li>\n</ul><pre><code>$ golangci-lint cache status\nDir: /home/colin/.cache/golangci-lint\nSize: 773.4KiB\n</code></pre><h3>completion命令</h3><p>completion命令包含4个子命令bash、fish、powershell和zsh，分别用来输出bash、fish、powershell和zsh的自动补全脚本。</p><p>下面是一个配置bash自动补全的示例：</p><pre><code>$ golangci-lint completion bash &gt; ~/.golangci-lint.bash\n$ echo &quot;source '$HOME/.golangci-lint.bash'&quot; &gt;&gt; ~/.bashrc\n$ source ~/.bashrc\n</code></pre><p>执行完上面的命令，键入如下命令，即可自动补全子命令：</p><pre><code>$ golangci-lint comp&lt;TAB&gt;\n</code></pre><p>上面的命令行会自动补全为<code>golangci-lint completion</code> 。</p><h3>config命令</h3><p>config命令可以打印golangci-lint当前使用的配置文件路径，例如：</p><pre><code>$ golangci-lint config path\n.golangci.yaml\n</code></pre><h3>linters命令</h3><p>linters命令可以打印出golangci-lint所支持的linter，并将这些linter分成两类，分别是配置为启用的linter和配置为禁用的linter，例如：</p><pre><code>$ golangci-lint linters\nEnabled by your configuration linters:\n...\ndeadcode: Finds unused code [fast: true, auto-fix: false]\n...\nDisabled by your configuration linters:\nexportloopref: checks for pointers to enclosing loop variables [fast: true, auto-fix: false]\n...\n</code></pre><p>上面我介绍了golangci-lint提供的命令，接下来，我们再来看下golangci-lint的配置。</p><h2>golangci-lint配置</h2><p>和其他linter相比，golangci-lint一个非常大的优点是使用起来非常灵活，这要得益于它对自定义配置的支持。</p><p>golangci-lint支持两种配置方式，分别是命令行选项和配置文件。如果bool/string/int的选项同时在命令行选项和配置文件中被指定，命令行的选项就会覆盖配置文件中的选项。如果是slice类型的选项，则命令行和配置中的配置会进行合并。</p><p><code>golangci-lint run</code> 支持很多<strong>命令行选项</strong>，可通过<code>golangci-lint run -h</code>查看，这里选择一些比较重要的选项进行介绍，见下表：</p><p><img src=\"https://static001.geekbang.org/resource/image/ac/fa/ac6098cf64cde7b8326cfd3508b04dfa.jpg?wh=2284x3988\" alt=\"\"></p><p>此外，我们还可以通过golangci-lint<strong>配置文件</strong>进行配置，默认的配置文件名为.golangci.yaml、.golangci.toml、.golangci.json，可以通过<code>-c</code>选项指定配置文件名。通过配置文件，可以实现下面几类功能：</p><ul>\n<li>golangci-lint本身的一些选项，比如超时、并发，是否检查<code>*_test.go</code>文件等。</li>\n<li>配置需要忽略的文件和文件夹。</li>\n<li>配置启用哪些linter，禁用哪些linter。</li>\n<li>配置输出格式。</li>\n<li>golangci-lint支持很多linter，其中有些linter支持一些配置项，这些配置项可以在配置文件中配置。</li>\n<li>配置符合指定正则规则的文件可以忽略的linter。</li>\n<li>设置错误严重级别，像日志一样，检查错误也是有严重级别的。</li>\n</ul><p>更详细的配置内容，你可以参考<a href=\"https://golangci-lint.run/usage/configuration/\">Configuration</a>。另外，你也可以参考IAM项目的golangci-lint配置<a href=\"https://github.com/marmotedu/iam/blob/master/.golangci.yaml\">.golangci.yaml</a>。.golangci.yaml里面的一些配置，我建议你一定要设置，具体如下：</p><pre><code>run:\n  skip-dirs: # 设置要忽略的目录\n    - util\n    - .*~\n    - api/swagger/docs\n  skip-files: # 设置不需要检查的go源码文件，支持正则匹配，这里建议包括：_test.go\n    - &quot;.*\\\\.my\\\\.go$&quot;\n    - _test.go\nlinters-settings:\n  errcheck:\n    check-type-assertions: true # 这里建议设置为true，如果确实不需要检查，可以写成`num, _ := strconv.Atoi(numStr)`\n    check-blank: false\n  gci:\n    # 将以`github.com/marmotedu/iam`开头的包放在第三方包后面\n    local-prefixes: github.com/marmotedu/iam\n  godox:\n    keywords: # 建议设置为BUG、FIXME、OPTIMIZE、HACK\n      - BUG\n      - FIXME\n      - OPTIMIZE\n      - HACK\n  goimports:\n    # 设置哪些包放在第三方包后面，可以设置多个包，逗号隔开\n    local-prefixes: github.com/marmotedu/iam\n  gomoddirectives: # 设置允许在go.mod中replace的包\n    replace-local: true\n    replace-allow-list:\n      - github.com/coreos/etcd\n      - google.golang.org/grpc\n      - github.com/marmotedu/api\n      - github.com/marmotedu/component-base\n      - github.com/marmotedu/marmotedu-sdk-go\n  gomodguard: # 下面是根据需要选择可以使用的包和版本，建议设置\n    allowed:\n      modules:\n        - gorm.io/gorm\n        - gorm.io/driver/mysql\n        - k8s.io/klog\n      domains: # List of allowed module domains\n        - google.golang.org\n        - gopkg.in\n        - golang.org\n        - github.com\n        - go.uber.org\n    blocked:\n      modules:\n        - github.com/pkg/errors:\n            recommendations:\n              - github.com/marmotedu/errors\n            reason: &quot;`github.com/marmotedu/errors` is the log package used by marmotedu projects.&quot;\n      versions:\n        - github.com/MakeNowJust/heredoc:\n            version: &quot;&gt; 2.0.9&quot;\n            reason: &quot;use the latest version&quot;\n      local_replace_directives: false\n  lll:\n    line-length: 240 # 这里可以设置为240，240一般是够用的\n  importas: # 设置包的alias，根据需要设置\n    jwt: github.com/appleboy/gin-jwt/v2         \n    metav1: github.com/marmotedu/component-base/pkg/meta/v1\n</code></pre><p>需要注意的是，golangci-lint不建议使用 <code>enable-all: true</code> 选项，为了尽可能使用最全的linters，我们可以使用以下配置：</p><pre><code>linters: \n  disable-all: true  \n  enable: # enable下列出 &lt;期望的所有linters&gt;\n    - typecheck\n    - ... \n</code></pre><p><code>&lt;期望的所有linters&gt; = &lt;golangci-lint支持的所有linters&gt; - &lt;不期望执行的linters&gt;</code>，我们可以通过执行以下命令来获取：</p><pre><code>$ ./scripts/print_enable_linters.sh\n    - asciicheck\n    - bodyclose\n    - cyclop\n    - deadcode\n    - ...\n</code></pre><p>将以上输出结果替换掉.golangci.yaml配置文件中的 <code>linters.enable</code> 部分即可。</p><p>上面我们介绍了与golangci-lint相关的一些基础知识，接下来我就给你详细展示下，如何使用golangci-lint进行静态代码检查。</p><h2>如何使用golangci-lint进行静态代码检查？</h2><p>要对代码进行静态检查，只需要执行 <code>golangci-lint run</code> 命令即可。接下来，我会先给你介绍5种常见的golangci-lint使用方法。</p><ol>\n<li>对当前目录及子目录下的所有Go文件进行静态代码检查：</li>\n</ol><pre><code>$ golangci-lint run\n</code></pre><p>命令等效于<code>golangci-lint run ./...</code>。</p><ol start=\"2\">\n<li>对指定的Go文件或者指定目录下的Go文件进行静态代码检查：</li>\n</ol><pre><code>$ golangci-lint run dir1 dir2/... dir3/file1.go\n</code></pre><p>这里需要你注意：上述命令不会检查dir1下子目录的Go文件，如果想递归地检查一个目录，需要在目录后面追加<code>/...</code>，例如：<code>dir2/...</code>。</p><ol start=\"3\">\n<li>根据指定配置文件，进行静态代码检查：</li>\n</ol><pre><code>$ golangci-lint run -c .golangci.yaml ./...\n</code></pre><ol start=\"4\">\n<li>运行指定的linter：</li>\n</ol><p>golangci-lint可以在不指定任何配置文件的情况下运行，这会运行默认启用的linter，你可以通过<code>golangci-lint help linters</code>查看它。</p><p>你可以传入参数<code>-E/--enable</code>来使某个linter可用，也可以使用<code>-D/--disable</code>参数来使某个linter不可用。下面的示例仅仅启用了errcheck linter：</p><pre><code>$ golangci-lint run --no-config --disable-all -E errcheck ./...\n</code></pre><p>这里你需要注意，默认情况下，golangci-lint会从当前目录一层层往上寻找配置文件名<code>.golangci.yaml</code>、<code>.golangci.toml</code>、<code>.golangci.json</code>直到根（/）目录。如果找到，就以找到的配置文件作为本次运行的配置文件，所以为了防止读取到未知的配置文件，可以用 <code>--no-config</code> 参数使golangci-lint不读取任何配置文件。</p><ol start=\"5\">\n<li>禁止运行指定的liner：</li>\n</ol><p>如果我们想禁用某些linter，可以使用<code>-D</code>选项。</p><pre><code>$ golangci-lint run --no-config -D godot,errcheck\n</code></pre><p>在使用golangci-lint进行代码检查时，可能会有很多误报。所谓的误报，其实是我们希望golangci-lint的一些linter能够容忍某些issue。那么如何尽可能减少误报呢？golangci-lint也提供了一些途径，我建议你使用下面这三种：</p><ul>\n<li>在命令行中添加<code>-e</code>参数，或者在配置文件的<code>issues.exclude</code>部分设置要排除的检查错误。你也可以使用<code>issues.exclude-rules</code>来配置哪些文件忽略哪些linter。</li>\n<li>通过<code>run.skip-dirs</code>、<code>run.skip-files</code>或者<code>issues.exclude-rules</code>配置项，来忽略指定目录下的所有Go文件，或者指定的Go文件。</li>\n<li>通过在Go源码文件中添加<code>//nolint</code>注释，来忽略指定的代码行。</li>\n</ul><p>因为golangci-lint设置了很多linters，对于一个大型项目，启用所有的linter会检查出很多问题，并且每个项目对linter检查的粒度要求也不一样，所以glangci-lint<strong>使用nolint标记来开关某些检查项</strong>，不同位置的nolint标记效果也会不一样。接下来我想向你介绍nolint的几种用法。</p><ol>\n<li>忽略某一行所有linter的检查</li>\n</ol><pre><code>var bad_name int //nolint\n</code></pre><ol start=\"2\">\n<li>忽略某一行指定linter的检查，可以指定多个linter，用逗号 <code>,</code> 隔开。</li>\n</ol><pre><code>var bad_name int //nolint:golint,unused\n</code></pre><ol start=\"3\">\n<li>忽略某个代码块的检查。</li>\n</ol><pre><code>//nolint\nfunc allIssuesInThisFunctionAreExcluded() *string {\n  // ...\n}\n\n//nolint:govet\nvar (\n  a int\n  b int\n)\n</code></pre><ol start=\"4\">\n<li>忽略某个文件的指定linter检查。</li>\n</ol><p>在package xx 上面一行添加<code>//nolint</code>注释。</p><pre><code>//nolint:unparam\npackage pkg\n...\n</code></pre><p>在使用nolint的过程中，有3个地方需要你注意。</p><p>首先，如果启用了nolintlint，你就需要在<code>//nolint</code>后面添加nolint的原因<code>// xxxx</code>。</p><p>其次，你使用的应该是<code>//nolint</code>而不是<code>// nolint</code>。因为根据Go的规范，需要程序读取的注释//后面不应该有空格。</p><p>最后，如果要忽略所有linter，可以用<code>//nolint</code>；如果要忽略某个指定的linter，可以用<code>//nolint:&lt;linter1&gt;,&lt;linter2&gt;</code>。</p><h2>golangci-lint使用技巧</h2><p>我在使用golangci-lint时，总结了一些经验技巧，放在这里供你参考，希望能够帮助你更好地使用golangci-lint。</p><p><strong>技巧1：第一次修改，可以按目录修改。</strong></p><p>如果你第一次使用golangci-lint检查你的代码，一定会有很多错误。为了减轻修改的压力，可以按目录检查代码并修改。这样可以有效减少失败条数，减轻修改压力。</p><p>当然，如果错误太多，一时半会儿改不完，想以后慢慢修改或者干脆不修复存量的issues，那么你可以使用golangci-lint的 <code>--new-from-rev</code> 选项，只检查新增的code，例如：</p><pre><code>$ golangci-lint run --new-from-rev=HEAD~1\n</code></pre><p><strong>技巧2：按文件修改，减少文件切换次数，提高修改效率。</strong></p><p>如果有很多检查错误，涉及很多文件，建议先修改一个文件，这样就不用来回切换文件。可以通过grep过滤出某个文件的检查失败项，例如：</p><pre><code>$ golangci-lint run ./...|grep pkg/storage/redis_cluster.go\npkg/storage/redis_cluster.go:16:2: &quot;github.com/go-redis/redis/v7&quot; imported but not used (typecheck)\npkg/storage/redis_cluster.go:82:28: undeclared name: `redis` (typecheck)\npkg/storage/redis_cluster.go:86:14: undeclared name: `redis` (typecheck)\n...\n</code></pre><p><strong>技巧3：把linters-setting.lll.line-length设置得大一些。</strong></p><p>在Go项目开发中，为了易于阅读代码，通常会将变量名/函数/常量等命名得有意义，这样很可能导致每行的代码长度过长，很容易超过<code>lll</code> linter设置的默认最大长度80。这里建议将<code>linters-setting.lll.line-length</code>设置为120/240。</p><p><strong>技巧4：尽可能多地使用golangci-lint提供的linter。</strong></p><p>golangci-lint集成了很多linters，可以通过如下命令查看：</p><pre><code>$ golangci-lint linters\nEnabled by your configuration linters:\ndeadcode: Finds unused code [fast: true, auto-fix: false]\n...\nvarcheck: Finds unused global variables and constants [fast: true, auto-fix: false]\n\nDisabled by your configuration linters:\nasciicheck: Simple linter to check that your code does not contain non-ASCII identifiers [fast: true, auto-fix: false]\n...\nwsl: Whitespace Linter - Forces you to use empty lines! [fast: true, auto-fix: false]\n</code></pre><p>这些linter分为两类，一类是默认启用的，另一类是默认禁用的。每个linter都有两个属性：</p><ul>\n<li>fast：true/false，如果为true，说明该linter可以缓存类型信息，支持快速检查。因为第一次缓存了这些信息，所以后续的运行会非常快。</li>\n<li>auto-fix：true/false，如果为true说明该linter支持自动修复发现的错误；如果为false说明不支持自动修复。</li>\n</ul><p>如果配置了golangci-lint配置文件，则可以通过命令<code>golangci-lint help linters</code>查看在当前配置下启用和禁用了哪些linter。golangci-lint也支持自定义linter插件，具体你可以参考：<a href=\"https://golangci-lint.run/contributing/new-linters\">New linters</a>。</p><p>在使用golangci-lint的时候，我们要尽可能多的使用linter。使用的linter越多，说明检查越严格，意味着代码越规范，质量越高。如果时间和精力允许，建议打开golangci-lint提供的所有linter。</p><p><strong>技巧5：每次修改代码后，都要执行golangci-lint。</strong></p><p>每次修改完代码后都要执行golangci-lint，一方面可以及时修改不规范的地方，另一方面可以减少错误堆积，减轻后面的修改压力。</p><p><strong>技巧6：建议在根目录下放一个通用的golangci-lint配置文件。</strong></p><p>在<code>/</code>目录下存放通用的golangci-lint配置文件，可以让你不用为每一个项目都配置golangci-lint。当你需要为某个项目单独配置golangci-lint时，只需在该项目根目录下增加一个项目级别的golangci-lint配置文件即可。</p><h2>总结</h2><p>Go项目开发中，对代码进行静态代码检查是必要的操作。当前有很多优秀的静态代码检查工具，但golangci-lint因为具有检查速度快、可配置、少误报、内置了大量linter等优点，成为了目前最受欢迎的静态代码检查工具。</p><p>golangci-lint功能非常强大，支持诸如run、cache、completion、linters等命令。其中最常用的是run命令，run命令可以通过以下方式来进行静态代码检查：</p><pre><code>$ golangci-lint run #  对当前目录及子目录下的所有Go文件进行静态代码检查\n$ golangci-lint run dir1 dir2/... dir3/file1.go # 对指定的Go文件或者指定目录下的Go文件进行静态代码检查\n$ golangci-lint run -c .golangci.yaml ./... # 根据指定配置文件，进行静态代码检查\n$ golangci-lint run --no-config --disable-all -E errcheck ./... # 运行指定的 errcheck linter\n$ golangci-lint run --no-config -D godot,errcheck # 禁止运行指定的godot,errcheck liner\n</code></pre><p>此外，golangci-lint还支持 <code>//nolint</code> 、<code>//nolint:golint,unused</code> 等方式来减少误报。</p><p>最后，我分享了一些自己使用golangci-lint时总结的经验。例如：第一次修改，可以按目录修改；按文件修改，减少文件切换次数，提高修改效率；尽可能多地使用golangci-lint提供的linter。希望这些建议对你使用golangci-lint有一定帮助。</p><h2>课后练习</h2><ol>\n<li>执行<code>golangci-lint linters</code>命令，查看golangci-lint支持哪些linter，以及这些linter的作用。</li>\n<li>思考下，如何在golangci-lint中集成自定义的linter。</li>\n</ol><p>如果遇到任何疑问，欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"15 | 研发流程实战：IAM项目是如何进行研发流程管理的？","id":389649},"right":{"article_title":"17 | API 文档：如何生成 Swagger API 文档 ？","id":391142}}},{"article_id":391142,"article_title":"17 | API 文档：如何生成 Swagger API 文档 ？","article_content":"<p>你好，我是孔令飞。</p><p>作为一名开发者，我们通常讨厌编写文档，因为这是一件重复和缺乏乐趣的事情。但是在开发过程中，又有一些文档是我们必须要编写的，比如API文档。</p><p>一个企业级的Go后端项目，通常也会有个配套的前端。为了加快研发进度，通常是后端和前端并行开发，这就需要后端开发者在开发后端代码之前，先设计好API接口，提供给前端。所以在设计阶段，我们就需要生成API接口文档。</p><p>一个好的API文档，可以减少用户上手的复杂度，也意味着更容易留住用户。好的API文档也可以减少沟通成本，帮助开发者更好地理解API的调用方式，从而节省时间，提高开发效率。这时候，我们一定希望有一个工具能够帮我们自动生成API文档，解放我们的双手。Swagger就是这么一个工具，可以帮助我们<strong>生成易于共享且具有足够描述性的API文档</strong>。</p><p>接下来，我们就来看下，如何使用Swagger生成API文档。</p><h2>Swagger介绍</h2><p>Swagger是一套围绕OpenAPI规范构建的开源工具，可以设计、构建、编写和使用REST API。Swagger包含很多工具，其中主要的Swagger工具包括：</p><ul>\n<li><strong>Swagger编辑器：</strong>基于浏览器的编辑器，可以在其中编写OpenAPI规范，并实时预览API文档。<a href=\"https://editor.swagger.io/\">https://editor.swagger.io</a> 就是一个Swagger编辑器，你可以尝试在其中编辑和预览API文档。</li>\n<li><strong>Swagger UI：</strong>将OpenAPI 规范呈现为交互式API文档，并可以在浏览器中尝试API调用。</li>\n<li><strong>Swagger Codegen：</strong>根据OpenAPI规范，生成服务器存根和客户端代码库，目前已涵盖了40多种语言。</li>\n</ul><!-- [[[read_end]]] --><h3>Swagger和OpenAPI的区别</h3><p>我们在谈到Swagger时，也经常会谈到OpenAPI。那么二者有什么区别呢？</p><p>OpenAPI是一个API规范，它的前身叫Swagger规范，通过定义一种用来描述API格式或API定义的语言，来规范RESTful服务开发过程，目前最新的OpenAPI规范是<a href=\"https://swagger.io/docs/specification\">OpenAPI 3.0</a>（也就是Swagger 2.0规范）。</p><p>OpenAPI规范规定了一个API必须包含的基本信息，这些信息包括：</p><ul>\n<li>对API的描述，介绍API可以实现的功能。</li>\n<li>每个API上可用的路径（/users）和操作（GET /users，POST /users）。</li>\n<li>每个API的输入/返回的参数。</li>\n<li>验证方法。</li>\n<li>联系信息、许可证、使用条款和其他信息。</li>\n</ul><p>所以，你可以简单地这么理解：OpenAPI是一个API规范，Swagger则是实现规范的工具。</p><p>另外，要编写Swagger文档，首先要会使用Swagger文档编写语法，因为语法比较多，这里就不多介绍了，你可以参考Swagger官方提供的<a href=\"https://swagger.io/specification/\">OpenAPI Specification</a>来学习。</p><h2>用go-swagger来生成Swagger API文档</h2><p>在Go项目开发中，我们可以通过下面两种方法来生成Swagger API文档：</p><p>第一，如果你熟悉Swagger语法的话，可以直接编写JSON/YAML格式的Swagger文档。建议选择YAML格式，因为它比JSON格式更简洁直观。</p><p>第二，通过工具生成Swagger文档，目前可以通过<a href=\"https://github.com/swaggo/swag\">swag</a>和<a href=\"https://github.com/go-swagger/go-swagger\">go-swagger</a>两个工具来生成。</p><p>对比这两种方法，直接编写Swagger文档，不比编写Markdown格式的API文档工作量小，我觉得不符合程序员“偷懒”的习惯。所以，本专栏我们就使用go-swagger工具，基于代码注释来自动生成Swagger文档。为什么选go-swagger呢？有这么几个原因：</p><ul>\n<li>go-swagger比swag功能更强大：go-swagger提供了更灵活、更多的功能来描述我们的API。</li>\n<li>使我们的代码更易读：如果使用swag，我们每一个API都需要有一个冗长的注释，有时候代码注释比代码还要长，但是通过go-swagger我们可以将代码和注释分开编写，一方面可以使我们的代码保持简洁，清晰易读，另一方面我们可以在另外一个包中，统一管理这些Swagger API文档定义。</li>\n<li>更好的社区支持：go-swagger目前有非常多的Github star数，出现Bug的概率很小，并且处在一个频繁更新的活跃状态。</li>\n</ul><p>你已经知道了，go-swagger是一个功能强大的、高性能的、可以根据代码注释生成Swagger API文档的工具。除此之外，go-swagger还有很多其他特性：</p><ul>\n<li>根据Swagger定义文件生成服务端代码。</li>\n<li>根据Swagger定义文件生成客户端代码。</li>\n<li>校验Swagger定义文件是否正确。</li>\n<li>启动一个HTTP服务器，使我们可以通过浏览器访问API文档。</li>\n<li>根据Swagger文档定义的参数生成Go model结构体定义。</li>\n</ul><p>可以看到，使用go-swagger生成Swagger文档，可以帮助我们减少编写文档的时间，提高开发效率，并能保证文档的及时性和准确性。</p><p>这里需要注意，如果我们要对外提供API的Go SDK，可以考虑使用go-swagger来生成客户端代码。但是我觉得go-swagger生成的服务端代码不够优雅，所以建议你自行编写服务端代码。</p><p>目前，有很多知名公司和组织的项目都使用了go-swagger，例如 Moby、CoreOS、Kubernetes、Cilium等。</p><h3>安装Swagger工具</h3><p>go-swagger通过swagger命令行工具来完成其功能，swagger安装方法如下：</p><pre><code>$ go get -u github.com/go-swagger/go-swagger/cmd/swagger\n$ swagger version\ndev\n</code></pre><h3>swagger命令行工具介绍</h3><p>swagger命令格式为<code>swagger [OPTIONS] &lt;command&gt;</code>。可以通过<code>swagger -h</code>查看swagger使用帮助。swagger提供的子命令及功能见下表：</p><p><img src=\"https://static001.geekbang.org/resource/image/yy/78/yy3428aa968c7029cb4f6b11f2596678.png?wh=1176x1180\" alt=\"\"></p><h2>如何使用swagger命令生成Swagger文档？</h2><p>go-swagger通过解析源码中的注释来生成Swagger文档，go-swagger的详细注释语法可参考<a href=\"https://goswagger.io\">官方文档</a>。常用的有如下几类注释语法：</p><p><img src=\"https://static001.geekbang.org/resource/image/94/b3/947262c5175f6f518ff677063af293b3.png?wh=1087x1134\" alt=\"\"></p><h3>解析注释生成Swagger文档</h3><p>swagger generate命令会找到main函数，然后遍历所有源码文件，解析源码中与Swagger相关的注释，然后自动生成swagger.json/swagger.yaml文件。</p><p>这一过程的示例代码为<a href=\"https://github.com/marmotedu/gopractise-demo/tree/main/swagger\">gopractise-demo/swagger</a>。目录下有一个main.go文件，定义了如下API接口：</p><pre><code>package main\n\nimport (\n    &quot;fmt&quot;\n    &quot;log&quot;\n    &quot;net/http&quot;\n\n    &quot;github.com/gin-gonic/gin&quot;\n\n    &quot;github.com/marmotedu/gopractise-demo/swagger/api&quot;\n    // This line is necessary for go-swagger to find your docs!\n    _ &quot;github.com/marmotedu/gopractise-demo/swagger/docs&quot;\n)\n\nvar users []*api.User\n\nfunc main() {\n    r := gin.Default()\n    r.POST(&quot;/users&quot;, Create)\n    r.GET(&quot;/users/:name&quot;, Get)\n\n    log.Fatal(r.Run(&quot;:5555&quot;))\n}\n\n// Create create a user in memory.\nfunc Create(c *gin.Context) {\n    var user api.User\n    if err := c.ShouldBindJSON(&amp;user); err != nil {\n        c.JSON(http.StatusBadRequest, gin.H{&quot;message&quot;: err.Error(), &quot;code&quot;: 10001})\n        return\n    }\n\n    for _, u := range users {\n        if u.Name == user.Name {\n            c.JSON(http.StatusBadRequest, gin.H{&quot;message&quot;: fmt.Sprintf(&quot;user %s already exist&quot;, user.Name), &quot;code&quot;: 10001})\n            return\n        }\n    }\n\n    users = append(users, &amp;user)\n    c.JSON(http.StatusOK, user)\n}\n\n// Get return the detail information for a user.\nfunc Get(c *gin.Context) {\n    username := c.Param(&quot;name&quot;)\n    for _, u := range users {\n        if u.Name == username {\n            c.JSON(http.StatusOK, u)\n            return\n        }\n    }\n\n    c.JSON(http.StatusBadRequest, gin.H{&quot;message&quot;: fmt.Sprintf(&quot;user %s not exist&quot;, username), &quot;code&quot;: 10002})\n}\n</code></pre><p>main包中引入的<strong>User struct</strong>位于gopractise-demo/swagger/api目录下的<a href=\"https://github.com/marmotedu/gopractise-demo/blob/main/swagger/api/user.go\">user.go</a>文件：</p><pre><code>// Package api defines the user model.\npackage api\n\n// User represents body of User request and response.\ntype User struct {\n    // User's name.\n    // Required: true\n    Name string `json:&quot;name&quot;`\n\n    // User's nickname.\n    // Required: true\n    Nickname string `json:&quot;nickname&quot;`\n\n    // User's address.\n    Address string `json:&quot;address&quot;`\n\n    // User's email.\n    Email string `json:&quot;email&quot;`\n}\n</code></pre><p><code>// Required: true</code>说明字段是必须的，生成Swagger文档时，也会在文档中声明该字段是必须字段。</p><p>为了使代码保持简洁，我们在另外一个Go包中编写带go-swagger注释的API文档。假设该Go包名字为docs，在开始编写Go API注释之前，需要在main.go文件中导入docs包：</p><pre><code>_ &quot;github.com/marmotedu/gopractise-demo/swagger/docs&quot;\n</code></pre><p>通过导入docs包，可以使go-swagger在递归解析main包的依赖包时，找到docs包，并解析包中的注释。</p><p>在gopractise-demo/swagger目录下，创建docs文件夹：</p><pre><code>$ mkdir docs\n$ cd docs\n</code></pre><p>在docs目录下，创建一个doc.go文件，在该文件中提供API接口的基本信息：</p><pre><code>// Package docs awesome.\n//\n// Documentation of our awesome API.\n//\n//     Schemes: http, https\n//     BasePath: /\n//     Version: 0.1.0\n//     Host: some-url.com\n//\n//     Consumes:\n//     - application/json\n//\n//     Produces:\n//     - application/json\n//\n//     Security:\n//     - basic\n//\n//    SecurityDefinitions:\n//    basic:\n//      type: basic\n//\n// swagger:meta\npackage docs\n</code></pre><p><strong>Package docs</strong>后面的字符串 <code>awesome</code> 代表我们的HTTP服务名。<code>Documentation of our awesome API</code>是我们API的描述。其他都是go-swagger可识别的注释，代表一定的意义。最后以<code>swagger:meta</code>注释结束。</p><p>编写完doc.go文件后，进入gopractise-demo/swagger目录，执行如下命令，生成Swagger API文档，并启动HTTP服务，在浏览器查看Swagger：</p><pre><code>$ swagger generate spec -o swagger.yaml\n$ swagger serve --no-open -F=swagger --port 36666 swagger.yaml\n\n2020/10/20 23:16:47 serving docs at http://localhost:36666/docs\n</code></pre><ul>\n<li>-o：指定要输出的文件名。swagger会根据文件名后缀.yaml或者.json，决定生成的文件格式为YAML或JSON。</li>\n<li>–no-open：因为是在Linux服务器下执行命令，没有安装浏览器，所以使–no-open禁止调用浏览器打开URL。</li>\n<li>-F：指定文档的风格，可选swagger和redoc。我选用了redoc，因为觉得redoc格式更加易读和清晰。</li>\n<li>–port：指定启动的HTTP服务监听端口。</li>\n</ul><p>打开浏览器，访问<a href=\"http://url\">http://localhost:36666/docs</a> ，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/9a/2c/9a9fb7a31d418d8e4dc13b19cefa832c.png?wh=2524x699\" alt=\"\"></p><p>如果我们想要JSON格式的Swagger文档，可执行如下命令，将生成的swagger.yaml转换为swagger.json：</p><pre><code>$ swagger generate spec -i ./swagger.yaml -o ./swagger.json\n</code></pre><p>接下来，我们就可以编写API接口的定义文件（位于<a href=\"https://github.com/marmotedu/gopractise-demo/blob/main/swagger/docs/user.go\">gopractise-demo/swagger/docs/user.go</a>文件中）：</p><pre><code>package docs\n\nimport (\n    &quot;github.com/marmotedu/gopractise-demo/swagger/api&quot;\n)\n\n// swagger:route POST /users user createUserRequest\n// Create a user in memory.\n// responses:\n//   200: createUserResponse\n//   default: errResponse\n\n// swagger:route GET /users/{name} user getUserRequest\n// Get a user from memory.\n// responses:\n//   200: getUserResponse\n//   default: errResponse\n\n// swagger:parameters createUserRequest\ntype userParamsWrapper struct {\n    // This text will appear as description of your request body.\n    // in:body\n    Body api.User\n}\n\n// This text will appear as description of your request url path.\n// swagger:parameters getUserRequest\ntype getUserParamsWrapper struct {\n    // in:path\n    Name string `json:&quot;name&quot;`\n}\n\n// This text will appear as description of your response body.\n// swagger:response createUserResponse\ntype createUserResponseWrapper struct {\n    // in:body\n    Body api.User\n}\n\n// This text will appear as description of your response body.\n// swagger:response getUserResponse\ntype getUserResponseWrapper struct {\n    // in:body\n    Body api.User\n}\n\n// This text will appear as description of your error response body.\n// swagger:response errResponse\ntype errResponseWrapper struct {\n    // Error code.\n    Code int `json:&quot;code&quot;`\n\n    // Error message.\n    Message string `json:&quot;message&quot;`\n}\n</code></pre><p>user.go文件说明：</p><ul>\n<li>swagger:route：<code>swagger:route</code>代表API接口描述的开始，后面的字符串格式为<code>HTTP方法 URL Tag ID</code>。可以填写多个tag，相同tag的API接口在Swagger文档中会被分为一组。ID是一个标识符，<code>swagger:parameters</code>是具有相同ID的<code>swagger:route</code>的请求参数。<code>swagger:route</code>下面的一行是该API接口的描述，需要以英文点号为结尾。<code>responses:</code>定义了API接口的返回参数，例如当HTTP状态码是200时，返回createUserResponse，createUserResponse会跟<code>swagger:response</code>进行匹配，匹配成功的<code>swagger:response</code>就是该API接口返回200状态码时的返回。</li>\n<li>swagger:response：<code>swagger:response</code>定义了API接口的返回，例如getUserResponseWrapper，关于名字，我们可以根据需要自由命名，并不会带来任何不同。getUserResponseWrapper中有一个Body字段，其注释为<code>// in:body</code>，说明该参数是在HTTP Body中返回。<code>swagger:response</code>之上的注释会被解析为返回参数的描述。api.User自动被go-swagger解析为<code>Example Value</code>和<code>Model</code>。我们不用再去编写重复的返回字段，只需要引用已有的Go结构体即可，这也是通过工具生成Swagger文档的魅力所在。</li>\n<li>swagger:parameters：<code>swagger:parameters</code>定义了API接口的请求参数，例如userParamsWrapper。userParamsWrapper之上的注释会被解析为请求参数的描述，<code>// in:body</code>代表该参数是位于HTTP Body中。同样，userParamsWrapper结构体名我们也可以随意命名，不会带来任何不同。<code>swagger:parameters</code>之后的createUserRequest会跟<code>swagger:route</code>的ID进行匹配，匹配成功则说明是该ID所在API接口的请求参数。</li>\n</ul><p>进入gopractise-demo/swagger目录，执行如下命令，生成Swagger API文档，并启动HTTP服务，在浏览器查看Swagger：</p><pre><code>$ swagger generate spec -o swagger.yaml\n$ swagger serve --no-open -F=swagger --port 36666 swagger.yaml\n2020/10/20 23:28:30 serving docs at http://localhost:36666/docs\n</code></pre><p>打开浏览器，访问 <a href=\"http://localhost:36666/docs\">http://localhost:36666/docs</a> ，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/e6/e0/e6d6d138fb890ef219d71671d146d5e0.png?wh=2450x1213\" alt=\"\"></p><p>上面我们生成了swagger风格的UI界面，我们也可以使用redoc风格的UI界面，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/dd/48/dd568a44290283861ba5c37f28307d48.png?wh=2527x1426\" alt=\"\"></p><h3>go-swagger其他常用功能介绍</h3><p>上面，我介绍了swagger最常用的generate、serve命令，关于swagger其他有用的命令，这里也简单介绍一下。</p><ol>\n<li>对比Swagger文档</li>\n</ol><pre><code>$ swagger diff -d change.log swagger.new.yaml swagger.old.yaml\n$ cat change.log\n\nBREAKING CHANGES:\n=================\n/users:post Request - Body.Body.nickname.address.email.name.Body : User - Deleted property\ncompatibility test FAILED: 1 breaking changes detected\n</code></pre><ol start=\"2\">\n<li>生成服务端代码</li>\n</ol><p>我们也可以先定义Swagger接口文档，再用swagger命令，基于Swagger接口文档生成服务端代码。假设我们的应用名为go-user，进入gopractise-demo/swagger目录，创建go-user目录，并生成服务端代码：</p><pre><code>$ mkdir go-user\n$ cd go-user\n$ swagger generate server -f ../swagger.yaml -A go-user\n</code></pre><p>上述命令会在当前目录生成cmd、restapi、models文件夹，可执行如下命令查看server组件启动方式：</p><pre><code>$ go run cmd/go-user-server/main.go -h\n</code></pre><ol start=\"3\">\n<li>生成客户端代码</li>\n</ol><p>在go-user目录下执行如下命令：</p><pre><code>$ swagger generate client -f ../swagger.yaml -A go-user\n</code></pre><p>上述命令会在当前目录生成client，包含了API接口的调用函数，也就是API接口的Go SDK。</p><ol start=\"4\">\n<li>验证Swagger文档是否合法</li>\n</ol><pre><code>$ swagger validate swagger.yaml\n2020/10/21 09:53:18\nThe swagger spec at &quot;swagger.yaml&quot; is valid against swagger specification 2.0\n</code></pre><ol start=\"5\">\n<li>合并Swagger文档</li>\n</ol><pre><code>$ swagger mixin swagger_part1.yaml swagger_part2.yaml\n</code></pre><h2>IAM Swagger文档</h2><p>IAM的Swagger文档定义在<a href=\"https://github.com/marmotedu/iam/tree/v1.0.0/api/swagger/docs\">iam/api/swagger/docs</a>目录下，遵循go-swagger规范进行定义。</p><p><a href=\"https://github.com/marmotedu/iam/blob/v1.0.0/api/swagger/docs/doc.go\">iam/api/swagger/docs/doc.go</a>文件定义了更多Swagger文档的基本信息，比如开源协议、联系方式、安全认证等。</p><p>更详细的定义，你可以直接查看iam/api/swagger/docs目录下的Go源码文件。</p><p>为了便于生成文档和启动HTTP服务查看Swagger文档，该操作被放在Makefile中执行（位于<a href=\"https://github.com/marmotedu/iam/blob/v1.0.0/scripts/make-rules/swagger.mk\">iam/scripts/make-rules/swagger.mk</a>文件中）：</p><pre><code>.PHONY: swagger.run    \nswagger.run: tools.verify.swagger    \n  @echo &quot;===========&gt; Generating swagger API docs&quot;    \n  @swagger generate spec --scan-models -w $(ROOT_DIR)/cmd/genswaggertypedocs -o $(ROOT_DIR)/api/swagger/swagger.yaml    \n    \n.PHONY: swagger.serve    \nswagger.serve: tools.verify.swagger    \n  @swagger serve -F=redoc --no-open --port 36666 $(ROOT_DIR)/api/swagger/swagger.yaml  \n</code></pre><p>Makefile文件说明：</p><ul>\n<li>tools.verify.swagger：检查Linux系统是否安装了go-swagger的命令行工具swagger，如果没有安装则运行go get安装。</li>\n<li>swagger.run：运行 <code>swagger generate spec</code> 命令生成Swagger文档swagger.yaml，运行前会检查swagger是否安装。 <code>--scan-models</code> 指定生成的文档中包含带有swagger:model 注释的Go Models。<code>-w</code> 指定swagger命令运行的目录。</li>\n<li>swagger.serve：运行 <code>swagger serve</code> 命令打开Swagger文档swagger.yaml，运行前会检查swagger是否安装。</li>\n</ul><p>在iam源码根目录下执行如下命令，即可生成并启动HTTP服务查看Swagger文档：</p><pre><code>$ make swagger\n$ make serve-swagger\n2020/10/21 06:45:03 serving docs at http://localhost:36666/docs\n</code></pre><p>打开浏览器，打开<code>http://x.x.x.x:36666/docs</code>查看Swagger文档，x.x.x.x是服务器的IP地址，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/6a/3b/6ac3529ed98aa94573862da99434683b.png?wh=2524x1440\" alt=\"\"></p><p>IAM的Swagger文档，还可以通过在iam源码根目录下执行<code>go generate ./...</code>命令生成，为此，我们需要在iam/cmd/genswaggertypedocs/swagger_type_docs.go文件中，添加<code>//go:generate</code>注释。如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/cc/d7/cc03b896e5403cc55d7e11fe2078d9d7.png?wh=1657x397\" alt=\"\"></p><h2>总结</h2><p>在做Go服务开发时，我们要向前端或用户提供API文档，手动编写API文档工作量大，也难以维护。所以，现在很多项目都是自动生成Swagger格式的API文档。提到Swagger，很多开发者不清楚其和OpenAPI的区别，所以我也给你总结了：OpenAPI是一个API规范，Swagger则是实现规范的工具。</p><p>在Go中，用得最多的是利用go-swagger来生成Swagger格式的API文档。go-swagger包含了很多语法，我们可以访问<a href=\"https://goswagger.io\">Swagger 2.0</a>进行学习。学习完Swagger 2.0的语法之后，就可以编写swagger注释了，之后可以通过</p><pre><code>$ swagger generate spec -o swagger.yaml\n</code></pre><p>来生成swagger文档 swagger.yaml。通过</p><pre><code>$ swagger serve --no-open -F=swagger --port 36666 swagger.yaml\n</code></pre><p>来提供一个前端界面，供我们访问swagger文档。</p><p>为了方便管理，我们可以将 <code>swagger generate spec</code> 和 <code>swagger serve</code> 命令加入到Makefile文件中，通过Makefile来生成Swagger文档，并提供给前端界面。</p><h2>课后练习</h2><ol>\n<li>尝试将你当前项目的一个API接口，用go-swagger生成swagger格式的API文档，如果中间遇到问题，欢迎在留言区与我讨论。</li>\n<li>思考下，为什么IAM项目的swagger定义文档会放在iam/api/swagger/docs目录下，这样做有什么好处？</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"16 | 代码检查：如何进行静态代码检查？","id":390401},"right":{"article_title":"18 | 错误处理（上）：如何设计一套科学的错误码？","id":391895}}},{"article_id":391895,"article_title":"18 | 错误处理（上）：如何设计一套科学的错误码？","article_content":"<p>你好，我是孔令飞。今天我们来聊聊如何设计业务的错误码。</p><p>现代的软件架构，很多都是对外暴露RESTful API接口，内部系统通信采用RPC协议。因为RESTful API接口有一些天生的优势，比如规范、调试友好、易懂，所以通常作为直接面向用户的通信规范。</p><p>既然是直接面向用户，那么首先就要求消息返回格式是规范的；其次，如果接口报错，还要能给用户提供一些有用的报错信息，通常需要包含Code码（用来唯一定位一次错误）和Message（用来展示出错的信息）。这就需要我们设计一套规范的、科学的错误码。</p><p>这一讲，我就来详细介绍下，如何设计一套规范的、科学的错误码。下一讲，我还会介绍如何提供一个errors包来支持我们设计的错误码。</p><h2>期望错误码实现的功能</h2><p>要想设计一套错误码，首先就得弄清我们的需求。</p><p>RESTful API是基于HTTP协议的一系列API开发规范，HTTP请求结束后，无论API请求成功或失败，都需要让客户端感知到，以便客户端决定下一步该如何处理。</p><p>为了让用户拥有最好的体验，需要有一个比较好的错误码实现方式。这里我介绍下在设计错误码时，期望能够实现的功能。</p><p>第一个功能是有业务Code码标识。</p><p>因为HTTP Code码有限，并且都是跟HTTP Transport层相关的Code码，所以我们希望能有自己的错误Code码。一方面，可以根据需要自行扩展，另一方面也能够精准地定位到具体是哪个错误。同时，因为Code码通常是对计算机友好的10进制整数，基于Code码，计算机也可以很方便地进行一些分支处理。当然了，业务码也要有一定规则，可以通过业务码迅速定位出是哪类错误。</p><!-- [[[read_end]]] --><p>第二个功能，考虑到安全，希望能够对外对内分别展示不同的错误信息。</p><p>当开发一个对外的系统，业务出错时，需要一些机制告诉用户出了什么错误，如果能够提供一些帮助文档会更好。但是，我们不可能把所有的错误都暴露给外部用户，这不仅没必要，也不安全。所以也需要能让我们获取到更详细的内部错误信息的机制，这些内部错误信息可能包含一些敏感的数据，不宜对外展示，但可以协助我们进行问题定位。</p><p>所以，我们需要设计的错误码应该是规范的，能方便客户端感知到HTTP是否请求成功，并带有业务码和出错信息。</p><h2>常见的错误码设计方式</h2><p>在业务中，大致有三种错误码实现方式。我用一次因为用户账号没有找到而请求失败的例子，分别给你解释一下：</p><p>第一种方式，不论请求成功或失败，始终返回<code>200 http status code</code>，在HTTP Body中包含用户账号没有找到的错误信息。</p><p>例如Facebook API的错误Code设计，始终返回200 http status code：</p><pre><code>{\n  &quot;error&quot;: {\n    &quot;message&quot;: &quot;Syntax error \\&quot;Field picture specified more than once. This is only possible before version 2.1\\&quot; at character 23: id,name,picture,picture&quot;,\n    &quot;type&quot;: &quot;OAuthException&quot;,\n    &quot;code&quot;: 2500,\n    &quot;fbtrace_id&quot;: &quot;xxxxxxxxxxx&quot;\n  }\n}\n</code></pre><p>采用固定返回<code>200 http status code</code>的方式，有其合理性。比如，HTTP Code通常代表HTTP Transport层的状态信息。当我们收到HTTP请求，并返回时，HTTP Transport层是成功的，所以从这个层面上来看，HTTP Status固定为200也是合理的。</p><p>但是这个方式的缺点也很明显：对于每一次请求，我们都要去解析HTTP Body，从中解析出错误码和错误信息。实际上，大部分情况下，我们对于成功的请求，要么直接转发，要么直接解析到某个结构体中；对于失败的请求，我们也希望能够更直接地感知到请求失败。这种方式对性能会有一定的影响，对客户端不友好。所以我不建议你使用这种方式。</p><p>第二种方式，返回<code>http 404 Not Found</code>错误码，并在Body中返回简单的错误信息。</p><p>例如：Twitter API的错误设计，会根据错误类型，返回合适的HTTP Code，并在Body中返回错误信息和自定义业务Code。</p><pre><code>HTTP/1.1 400 Bad Request\nx-connection-hash: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\nset-cookie: guest_id=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\nDate: Thu, 01 Jun 2017 03:04:23 GMT\nContent-Length: 62\nx-response-time: 5\nstrict-transport-security: max-age=631138519\nConnection: keep-alive\nContent-Type: application/json; charset=utf-8\nServer: tsa_b\n\n{&quot;errors&quot;:[{&quot;code&quot;:215,&quot;message&quot;:&quot;Bad Authentication data.&quot;}]}\n</code></pre><p>这种方式比第一种要好一些，通过<code>http status code</code>可以使客户端非常直接地感知到请求失败，并且提供给客户端一些错误信息供参考。但是仅仅靠这些信息，还不能准确地定位和解决问题。</p><p>第三种方式，返回<code>http 404 Not Found</code>错误码，并在Body中返回详细的错误信息。</p><p>例如：微软Bing API的错误设计，会根据错误类型，返回合适的HTTP Code，并在Body中返回详尽的错误信息。</p><pre><code>HTTP/1.1 400\nDate: Thu, 01 Jun 2017 03:40:55 GMT\nContent-Length: 276\nConnection: keep-alive\nContent-Type: application/json; charset=utf-8\nServer: Microsoft-IIS/10.0\nX-Content-Type-Options: nosniff\n\n{&quot;SearchResponse&quot;:{&quot;Version&quot;:&quot;2.2&quot;,&quot;Query&quot;:{&quot;SearchTerms&quot;:&quot;api error codes&quot;},&quot;Errors&quot;:[{&quot;Code&quot;:1001,&quot;Message&quot;:&quot;Required parameter is missing.&quot;,&quot;Parameter&quot;:&quot;SearchRequest.AppId&quot;,&quot;HelpUrl&quot;:&quot;http\\u003a\\u002f\\u002fmsdn.microsoft.com\\u002fen-us\\u002flibrary\\u002fdd251042.aspx&quot;}]}}\n</code></pre><p>这是我比较推荐的一种方式，既能通过<code>http status code</code>使客户端方便地知道请求出错，又可以使用户根据返回的信息知道哪里出错，以及如何解决问题。同时，返回了机器友好的业务Code码，可以在有需要时让程序进一步判断处理。</p><h2>错误码设计建议</h2><p>综合刚才讲到的，我们可以总结出一套优秀的错误码设计思路：</p><ul>\n<li>有区别于<code>http status code</code>的业务码，业务码需要有一定规则，可以通过业务码判断出是哪类错误。</li>\n<li>请求出错时，可以通过<code>http status code</code>直接感知到请求出错。</li>\n<li>需要在请求出错时，返回详细的信息，通常包括3类信息：业务Code码、错误信息和参考文档（可选）。</li>\n<li>返回的错误信息，需要是可以直接展示给用户的安全信息，也就是说不能包含敏感信息；同时也要有内部更详细的错误信息，方便debug。</li>\n<li>返回的数据格式应该是固定的、规范的。</li>\n<li>错误信息要保持简洁，并且提供有用的信息。</li>\n</ul><p>这里其实还有两个功能点需要我们实现：业务Code码设计，以及请求出错时，如何设置<code>http status code</code>。</p><p>接下来，我会详细介绍下如何实现这两个功能点。</p><h2>业务Code码设计</h2><p>要解决业务Code码如何设计这个问题，我们先来看下为什么要引入业务Code码。</p><p>在实际开发中，引入业务Code码有下面几个好处：</p><ul>\n<li>可以非常方便地定位问题和定位代码行（看到错误码知道什么意思、grep错误码可以定位到错误码所在行、某个错误类型的唯一标识）。</li>\n<li>错误码包含一定的信息，通过错误码可以判断出错误级别、错误模块和具体错误信息。</li>\n<li>Go中的HTTP服务器开发都是引用net/http包，该包中只有60个错误码，基本都是跟HTTP请求相关的错误码，在一个大型系统中，这些错误码完全不够用，而且这些错误码跟业务没有任何关联，满足不了业务的需求。引入业务的Code码，则可以解决这些问题。</li>\n<li>业务开发过程中，可能需要判断错误是哪种类型，以便做相应的逻辑处理，通过定制的错误可以很容易做到这点，例如：</li>\n</ul><pre><code>if err == code.ErrBind {\n    ...\n}\n</code></pre><p>这里要注意，业务Code码可以是一个整数，也可以是一个整型字符串，还可以是一个字符型字符串，它是错误的唯一标识。</p><p>通过研究腾讯云、阿里云、新浪的开放API，我发现新浪的API Code码设计更合理些。所以，我参考新浪的Code码设计，总结出了我推荐的<strong>Code码设计规范：纯数字表示，不同部位代表不同的服务，不同的模块。</strong></p><p>错误代码说明：<code>100101</code></p><ul>\n<li><strong>10:</strong> 服务。</li>\n<li><strong>01:</strong> 某个服务下的某个模块。</li>\n<li><strong>01:</strong> 模块下的错误码序号，每个模块可以注册100个错误。</li>\n</ul><p>通过<code>100101</code>可以知道这个错误是<strong>服务 A</strong>，<strong>数据库</strong>模块下的<strong>记录没有找到错误</strong>。</p><p>你可能会问：按这种设计，每个模块下最多能注册100个错误，是不是有点少？其实在我看来，如果每个模块的错误码超过100个，要么说明这个模块太大了，建议拆分；要么说明错误码设计得不合理，共享性差，需要重新设计。</p><h3>如何设置HTTP Status Code</h3><p>Go net/http包提供了60个错误码，大致分为如下5类：</p><ul>\n<li>1XX - （指示信息）表示请求已接收，继续处理。</li>\n<li>2XX - （请求成功）表示成功处理了请求的状态代码。</li>\n<li>3XX - （请求被重定向）表示要完成请求，需要进一步操作。通常，这些状态代码用来重定向。</li>\n<li>4XX - （请求错误）这些状态代码表示请求可能出错，妨碍了服务器的处理，通常是客户端出错，需要客户端做进一步的处理。</li>\n<li>5XX - （服务器错误）这些状态代码表示服务器在尝试处理请求时发生内部错误。这些错误可能是服务器本身的错误，而不是客户端的问题。</li>\n</ul><p>可以看到HTTP Code有很多种，如果每个Code都做错误映射，会面临很多问题。比如，研发同学不太好判断错误属于哪种<code>http status code</code>，到最后很可能会导致错误或者<code>http status code</code>不匹配，变成一种形式。而且，客户端也难以应对这么多的HTTP错误码。</p><p>所以，这里建议<code>http status code</code>不要太多，基本上只需要这3个HTTP Code:</p><ul>\n<li>200 - 表示请求成功执行。</li>\n<li>400 - 表示客户端出问题。</li>\n<li>500 - 表示服务端出问题。</li>\n</ul><p>如果觉得这3个错误码不够用，最多可以加如下3个错误码：</p><ul>\n<li>401 - 表示认证失败。</li>\n<li>403 - 表示授权失败。</li>\n<li>404 - 表示资源找不到，这里的资源可以是URL或者RESTful资源。</li>\n</ul><p>将错误码控制在适当的数目内，客户端比较容易处理和判断，开发也比较容易进行错误码映射。</p><h2>IAM项目错误码设计规范</h2><p>接下来，我们来看下IAM项目的错误码是如何设计的。</p><h3>Code 设计规范</h3><p>先来看下IAM项目业务的Code码设计规范，具体实现可参考<a href=\"https://github.com/marmotedu/iam/tree/master/internal/pkg/code\">internal/pkg/code目录</a>。IAM项目的错误码设计规范符合上面介绍的错误码设计思路和规范，具体规范见下。</p><p>Code 代码从 <strong>100001</strong> 开始，1000 以下为 <code>github.com/marmotedu/errors</code> 保留 code。</p><p><strong>错误代码说明：</strong><code>100001</code></p><p><img src=\"https://static001.geekbang.org/resource/image/9c/6e/9c088dcb4c7b2509c2eaa81ed3be3b6e.jpg?wh=1385x699\" alt=\"\"></p><p><strong>服务和模块说明</strong></p><p><img src=\"https://static001.geekbang.org/resource/image/91/f5/91296aab54da035580e80b6637dd4df5.png?wh=1457x1188\" alt=\"\"><br>\n通用<strong>：</strong>说明所有服务都适用的错误，提高复用性，避免重复造轮子。</p><p><strong>错误信息规范说明</strong></p><ul>\n<li>对外暴露的错误，统一大写开头，结尾不要加<code>.</code>。</li>\n<li>对外暴露的错误要简洁，并能准确说明问题。</li>\n<li>对外暴露的错误说明，应该是 <code>该怎么做</code> 而不是 <code>哪里错了</code>。</li>\n</ul><p>这里你需要注意，错误信息是直接暴露给用户的，不能包含敏感信息。</p><h3>IAM API接口返回值说明</h3><p>如果返回结果中存在 <code>code</code> 字段，则表示调用 API 接口失败。例如：</p><pre><code>{\n  &quot;code&quot;: 100101,\n  &quot;message&quot;: &quot;Database error&quot;,\n  &quot;reference&quot;: &quot;https://github.com/marmotedu/iam/tree/master/docs/guide/zh-CN/faq/iam-apiserver&quot;\n}\n</code></pre><p>上述返回中 <code>code</code> 表示错误码，<code>message</code> 表示该错误的具体信息。每个错误同时也对应一个 HTTP 状态码。比如上述错误码对应了 HTTP 状态码 500(Internal Server Error)。另外，在出错时，也返回了<code>reference</code>字段，该字段包含了可以解决这个错误的文档链接地址。</p><p>关于IAM 系统支持的错误码，我给你列了一个表格，你可以看看：</p><p><img src=\"https://static001.geekbang.org/resource/image/b5/95/b58ff5b9455d13fc397fdf5228ea7195.png?wh=1441x1518\" alt=\"\"><img src=\"https://static001.geekbang.org/resource/image/c6/d2/c6d356a3f5f2bfc3d6001yy3c05a90d2.png?wh=1321x1570\" alt=\"\"></p><h2>总结</h2><p>对外暴露的API接口需要有一套规范的、科学的错误码。目前业界的错误码大概有3种设计方式，我用一次因为用户账号没有找到而请求失败的例子，给你做了解释：</p><ul>\n<li>不论请求成功失败，始终返回<code>200 http status code</code>，在HTTP Body中包含用户账号没有找到的错误信息。</li>\n<li>返回<code>http 404 Not Found</code>错误码，并在Body中返回简单的错误信息。</li>\n<li>返回<code>http 404 Not Found</code>错误码，并在Body中返回详细的错误信息。</li>\n</ul><p>这一讲，我参考这3个错误码设计，给出了自己的错误码设计建议：错误码包含HTTP Code和业务Code，并且业务Code会映射为一个HTTP Code。错误码也会对外暴露两种错误信息，一种是直接暴露给用户的，不包含敏感信息的信息；另一种是供内部开发查看，定位问题的错误信息。该错误码还支持返回参考文档，用于在出错时展示给用户，供用户查看解决问题。</p><p>建议你重点关注我总结的Code码设计规范：<strong>纯数字表示，不同部位代表不同的服务，不同的模块。</strong></p><p>比如错误代码<code>100101</code>，其中10代表服务；中间的01代表某个服务下的某个模块；最后的01代表模块下的错误码序号，每个模块可以注册100个错误。</p><h2>课后练习</h2><ol>\n<li>既然错误码是符合规范的，请思考下：有没有一种Low Code的方式，根据错误码规范，自动生成错误码文档呢？</li>\n<li>思考下你还遇到过哪些更科学的错误码设计。如果有，也欢迎在留言区分享交流。</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"17 | API 文档：如何生成 Swagger API 文档 ？","id":391142},"right":{"article_title":"19 | 错误处理（下）：如何设计错误包？","id":393022}}},{"article_id":393022,"article_title":"19 | 错误处理（下）：如何设计错误包？","article_content":"<p>你好，我是孔令飞。</p><p>在Go项目开发中，错误是我们必须要处理的一个事项。除了我们上一讲学习过的错误码，处理错误也离不开错误包。</p><p>业界有很多优秀的、开源的错误包可供选择，例如Go标准库自带的<code>errors</code>包、<code>github.com/pkg/errors</code>包。但是这些包目前还不支持业务错误码，很难满足生产级应用的需求。所以，在实际开发中，我们有必要开发出适合自己错误码设计的错误包。当然，我们也没必要自己从0开发，可以基于一些优秀的包来进行二次封装。</p><p>这一讲里，我们就来一起看看，如何设计一个错误包来适配上一讲我们设计的错误码，以及一个错误码的具体实现。</p><h2>错误包需要具有哪些功能？</h2><p>要想设计一个优秀的错误包，我们首先得知道一个优秀的错误包需要具备哪些功能。在我看来，至少需要有下面这六个功能：</p><p><strong>首先，应该能支持错误堆栈。</strong>我们来看下面一段代码，假设保存在<a href=\"https://github.com/marmotedu/gopractise-demo/blob/master/errors/bad.go\">bad.go</a>文件中：</p><pre><code>package main\n\nimport (\n\t&quot;fmt&quot;\n\t&quot;log&quot;\n)\n\nfunc main() {\n\tif err := funcA(); err != nil {\n\t\tlog.Fatalf(&quot;call func got failed: %v&quot;, err)\n\t\treturn\n\t}\n\n\tlog.Println(&quot;call func success&quot;)\n}\n\nfunc funcA() error {\n\tif err := funcB(); err != nil {\n\t\treturn err\n\t}\n\n\treturn fmt.Errorf(&quot;func called error&quot;)\n}\n\nfunc funcB() error {\n\treturn fmt.Errorf(&quot;func called error&quot;)\n}\n</code></pre><p>执行上面的代码：</p><pre><code>$ go run bad.go\n2021/07/02 08:06:55 call func got failed: func called error\nexit status 1\n</code></pre><p>这时我们想定位问题，但不知道具体是哪行代码报的错误，只能靠猜，还不一定能猜到。为了解决这个问题，我们可以加一些Debug信息，来协助我们定位问题。这样做在测试环境是没问题的，但是在线上环境，一方面修改、发布都比较麻烦，另一方面问题可能比较难重现。这时候我们会想，要是能打印错误的堆栈就好了。例如：</p><!-- [[[read_end]]] --><pre><code>2021/07/02 14:17:03 call func got failed: func called error\nmain.funcB\n\t/home/colin/workspace/golang/src/github.com/marmotedu/gopractise-demo/errors/good.go:27\nmain.funcA\n\t/home/colin/workspace/golang/src/github.com/marmotedu/gopractise-demo/errors/good.go:19\nmain.main\n\t/home/colin/workspace/golang/src/github.com/marmotedu/gopractise-demo/errors/good.go:10\nruntime.main\n\t/home/colin/go/go1.16.2/src/runtime/proc.go:225\nruntime.goexit\n\t/home/colin/go/go1.16.2/src/runtime/asm_amd64.s:1371\nexit status 1\n</code></pre><p>通过上面的错误输出，我们可以很容易地知道是哪行代码报的错，从而极大提高问题定位的效率，降低定位的难度。所以，在我看来，一个优秀的errors包，首先需要支持错误堆栈。</p><p><strong>其次，能够支持不同的打印格式。</strong>例如<code>%+v</code>、<code>%v</code>、<code>%s</code>等格式，可以根据需要打印不同丰富度的错误信息。</p><p><strong>再次，能支持Wrap/Unwrap功能，也就是在已有的错误上，追加一些新的信息。</strong>例如<code>errors.Wrap(err, \"open file failed\")</code> 。Wrap通常用在调用函数中，调用函数可以基于被调函数报错时的错误Wrap一些自己的信息，丰富报错信息，方便后期的错误定位，例如：</p><pre><code>func funcA() error {\n    if err := funcB(); err != nil {\n        return errors.Wrap(err, &quot;call funcB failed&quot;)\n    }\n\n    return errors.New(&quot;func called error&quot;)\n}\n\nfunc funcB() error {\n    return errors.New(&quot;func called error&quot;)\n}\n</code></pre><p>这里要注意，不同的错误类型，Wrap函数的逻辑也可以不同。另外，在调用Wrap时，也会生成一个错误堆栈节点。我们既然能够嵌套error，那有时候还可能需要获取被嵌套的error，这时就需要错误包提供<code>Unwrap</code>函数。</p><p><strong>还有，错误包应该有<code>Is</code>方法</strong>。在实际开发中，我们经常需要判断某个error是否是指定的error。在Go 1.13之前，也就是没有wrapping error的时候，我们要判断error是不是同一个，可以使用如下方法：</p><pre><code>if err == os.ErrNotExist {\n\t// normal code\n}\n</code></pre><p>但是现在，因为有了wrapping error，这样判断就会有问题。因为你根本不知道返回的err是不是一个嵌套的error，嵌套了几层。这种情况下，我们的错误包就需要提供<code>Is</code>函数：</p><pre><code>func Is(err, target error) bool\n</code></pre><p>当err和target是同一个，或者err是一个wrapping error的时候，如果target也包含在这个嵌套error链中，返回true，否则返回fasle。</p><p><strong>另外，错误包应该支持</strong>  <code>As</code>  <strong>函数。</strong></p><p>在Go 1.13之前，没有wrapping error的时候，我们要把error转为另外一个error，一般都是使用type assertion或者type switch，也就是类型断言。例如：</p><pre><code>if perr, ok := err.(*os.PathError); ok {\n\tfmt.Println(perr.Path)\n}\n</code></pre><p>但是现在，返回的err可能是嵌套的error，甚至好几层嵌套，这种方式就不能用了。所以，我们可以通过实现 <code>As</code> 函数来完成这种功能。现在我们把上面的例子，用 <code>As</code> 函数实现一下：</p><pre><code>var perr *os.PathError\nif errors.As(err, &amp;perr) {\n\tfmt.Println(perr.Path)\n}\n</code></pre><p>这样就可以完全实现类型断言的功能，而且还更强大，因为它可以处理wrapping error。</p><p><strong>最后，能够支持两种错误创建方式：非格式化创建和格式化创建。</strong>例如：</p><pre><code>errors.New(&quot;file not found&quot;)\nerrors.Errorf(&quot;file %s not found&quot;, &quot;iam-apiserver&quot;)\n</code></pre><p>上面，我们介绍了一个优秀的错误包应该具备的功能。一个好消息是，Github上有不少实现了这些功能的错误包，其中<code>github.com/pkg/errors</code>包最受欢迎。所以，我基于<code>github.com/pkg/errors</code>包进行了二次封装，用来支持上一讲所介绍的错误码。</p><h2>错误包实现</h2><p>明确优秀的错误包应该具备的功能后，我们来看下错误包的实现。实现的源码存放在<a href=\"https://github.com/marmotedu/errors\">github.com/marmotedu/errors</a>。</p><p>我通过在文件<a href=\"https://github.com/marmotedu/errors/blob/master/errors.go#L299\">github.com/pkg/errors/errors.go</a>中增加新的<code>withCode</code>结构体，来引入一种新的错误类型，该错误类型可以记录错误码、stack、cause和具体的错误信息。</p><pre><code>type withCode struct {\n    err   error // error 错误\n    code  int // 业务错误码\n    cause error // cause error\n    *stack // 错误堆栈\n}\n</code></pre><p>下面，我们通过一个示例，来了解下<code>github.com/marmotedu/errors</code>所提供的功能。假设下述代码保存在<code>errors.go</code>文件中：</p><pre><code>package main\n\nimport (\n\t&quot;fmt&quot;\n\n\t&quot;github.com/marmotedu/errors&quot;\n\tcode &quot;github.com/marmotedu/sample-code&quot;\n)\n\nfunc main() {\n\tif err := bindUser(); err != nil {\n\t\t// %s: Returns the user-safe error string mapped to the error code or the error message if none is specified.\n\t\tfmt.Println(&quot;====================&gt; %s &lt;====================&quot;)\n\t\tfmt.Printf(&quot;%s\\n\\n&quot;, err)\n\n\t\t// %v: Alias for %s.\n\t\tfmt.Println(&quot;====================&gt; %v &lt;====================&quot;)\n\t\tfmt.Printf(&quot;%v\\n\\n&quot;, err)\n\n\t\t// %-v: Output caller details, useful for troubleshooting.\n\t\tfmt.Println(&quot;====================&gt; %-v &lt;====================&quot;)\n\t\tfmt.Printf(&quot;%-v\\n\\n&quot;, err)\n\n\t\t// %+v: Output full error stack details, useful for debugging.\n\t\tfmt.Println(&quot;====================&gt; %+v &lt;====================&quot;)\n\t\tfmt.Printf(&quot;%+v\\n\\n&quot;, err)\n\n\t\t// %#-v: Output caller details, useful for troubleshooting with JSON formatted output.\n\t\tfmt.Println(&quot;====================&gt; %#-v &lt;====================&quot;)\n\t\tfmt.Printf(&quot;%#-v\\n\\n&quot;, err)\n\n\t\t// %#+v: Output full error stack details, useful for debugging with JSON formatted output.\n\t\tfmt.Println(&quot;====================&gt; %#+v &lt;====================&quot;)\n\t\tfmt.Printf(&quot;%#+v\\n\\n&quot;, err)\n\n\t\t// do some business process based on the error type\n\t\tif errors.IsCode(err, code.ErrEncodingFailed) {\n\t\t\tfmt.Println(&quot;this is a ErrEncodingFailed error&quot;)\n\t\t}\n\n\t\tif errors.IsCode(err, code.ErrDatabase) {\n\t\t\tfmt.Println(&quot;this is a ErrDatabase error&quot;)\n\t\t}\n\n\t\t// we can also find the cause error\n\t\tfmt.Println(errors.Cause(err))\n\t}\n}\n\nfunc bindUser() error {\n\tif err := getUser(); err != nil {\n\t\t// Step3: Wrap the error with a new error message and a new error code if needed.\n\t\treturn errors.WrapC(err, code.ErrEncodingFailed, &quot;encoding user 'Lingfei Kong' failed.&quot;)\n\t}\n\n\treturn nil\n}\n\nfunc getUser() error {\n\tif err := queryDatabase(); err != nil {\n\t\t// Step2: Wrap the error with a new error message.\n\t\treturn errors.Wrap(err, &quot;get user failed.&quot;)\n\t}\n\n\treturn nil\n}\n\nfunc queryDatabase() error {\n\t// Step1. Create error with specified error code.\n\treturn errors.WithCode(code.ErrDatabase, &quot;user 'Lingfei Kong' not found.&quot;)\n}\n</code></pre><p>上述代码中，通过<a href=\"https://github.com/marmotedu/errors/blob/v1.0.2/errors.go#L306\">WithCode</a>函数来创建新的withCode类型的错误；通过<a href=\"https://github.com/marmotedu/errors/blob/v1.0.2/errors.go#L314\">WrapC</a>来将一个error封装成一个withCode类型的错误；通过<a href=\"https://github.com/marmotedu/errors/blob/v1.0.2/code.go#L121\">IsCode</a>来判断一个error链中是否包含指定的code。</p><p>withCode错误实现了一个<code>func (w *withCode) Format(state fmt.State, verb rune)</code>方法，该方法用来打印不同格式的错误信息，见下表：</p><p><img src=\"https://static001.geekbang.org/resource/image/18/5c/18a93313e017d4f3b21370099d011c5c.png?wh=1755x1198\" alt=\"\"></p><p>例如，<code>%+v</code>会打印以下错误信息：</p><pre><code>get user failed. - #1 [/home/colin/workspace/golang/src/github.com/marmotedu/gopractise-demo/errors/errortrack_errors.go:19 (main.getUser)] (100101) Database error; user 'Lingfei Kong' not found. - #0 [/home/colin/workspace/golang/src/github.com/marmotedu/gopractise-demo/errors/errortrack_errors.go:26 (main.queryDatabase)] (100101) Database error\n</code></pre><p>那么你可能会问，这些错误信息中的<code>100101</code>错误码，还有<code>Database error</code>这种对外展示的报错信息等等，是从哪里获取的？这里我简单解释一下。</p><p>首先， <code>withCode</code> 中包含了int类型的错误码，例如<code>100101</code>。</p><p>其次，当使用<code>github.com/marmotedu/errors</code>包的时候，需要调用<code>Register</code>或者<code>MustRegister</code>，将一个Coder注册到<code>github.com/marmotedu/errors</code>开辟的内存中，数据结构为：</p><pre><code>var codes = map[int]Coder{}\n</code></pre><p>Coder是一个接口，定义为：</p><pre><code>type Coder interface {\n    // HTTP status that should be used for the associated error code.\n    HTTPStatus() int\n\n    // External (user) facing error text.\n    String() string\n\n    // Reference returns the detail documents for user.\n    Reference() string\n\n    // Code returns the code of the coder\n    Code() int\n}\n</code></pre><p>这样 <code>withCode</code> 的<code>Format</code>方法，就能够通过 <code>withCode</code> 中的code字段获取到对应的Coder，并通过Coder提供的HTTPStatus、String、Reference、Code函数，来获取 <code>withCode</code> 中code的详细信息，最后格式化打印。</p><p>这里要注意，我们实现了两个注册函数：<code>Register</code>和<code>MustRegister</code>，二者唯一区别是：当重复定义同一个错误Code时，<code>MustRegister</code>会panic，这样可以防止后面注册的错误覆盖掉之前注册的错误。在实际开发中，建议使用<code>MustRegister</code>。</p><p><code>XXX()</code>和<code>MustXXX()</code>的函数命名方式，是一种Go代码设计技巧，在Go代码中经常使用，例如Go标准库中<code>regexp</code>包提供的<code>Compile</code>和<code>MustCompile</code>函数。和<code>XXX</code>相比，<code>MustXXX</code> 会在某种情况不满足时panic。因此使用<code>MustXXX</code>的开发者看到函数名就会有一个心理预期：使用不当，会造成程序panic。</p><p>最后，我还有一个建议：在实际的生产环境中，我们可以使用JSON格式打印日志，JSON格式的日志可以非常方便的供日志系统解析。我们可以根据需要，选择<code>%#-v</code>或<code>%#+v</code>两种格式。</p><p>错误包在代码中，经常被调用，所以我们要保证错误包一定要是高性能的，否则很可能会影响接口的性能。这里，我们再来看下<code>github.com/marmotedu/errors</code>包的性能。</p><p>在这里，我们把这个错误包跟go标准库的 <code>errors</code> 包，以及 <code>github.com/pkg/errors</code> 包进行对比，来看看它们的性能：</p><pre><code>$  go test -test.bench=BenchmarkErrors -benchtime=&quot;3s&quot;\ngoos: linux\ngoarch: amd64\npkg: github.com/marmotedu/errors\nBenchmarkErrors/errors-stack-10-8         \t57658672\t        61.8 ns/op\t      16 B/op\t       1 allocs/op\nBenchmarkErrors/pkg/errors-stack-10-8     \t 2265558\t      1547 ns/op\t     320 B/op\t       3 allocs/op\nBenchmarkErrors/marmot/errors-stack-10-8  \t 1903532\t      1772 ns/op\t     360 B/op\t       5 allocs/op\nBenchmarkErrors/errors-stack-100-8        \t 4883659\t       734 ns/op\t      16 B/op\t       1 allocs/op\nBenchmarkErrors/pkg/errors-stack-100-8    \t 1202797\t      2881 ns/op\t     320 B/op\t       3 allocs/op\nBenchmarkErrors/marmot/errors-stack-100-8 \t 1000000\t      3116 ns/op\t     360 B/op\t       5 allocs/op\nBenchmarkErrors/errors-stack-1000-8       \t  505636\t      7159 ns/op\t      16 B/op\t       1 allocs/op\nBenchmarkErrors/pkg/errors-stack-1000-8   \t  327681\t     10646 ns/op\t     320 B/op\t       3 allocs/op\nBenchmarkErrors/marmot/errors-stack-1000-8         \t  304160\t     11896 ns/op\t     360 B/op\t       5 allocs/op\nPASS\nok  \tgithub.com/marmotedu/errors\t39.200s\n</code></pre><p>可以看到<code>github.com/marmotedu/errors</code>和<code>github.com/pkg/errors</code>包的性能基本持平。在对比性能时，重点关注<strong>ns/op</strong>，也即每次error操作耗费的纳秒数。另外，我们还需要测试不同error嵌套深度下的error操作性能，嵌套越深，性能越差。例如：在嵌套深度为10的时候， <code>github.com/pkg/errors</code> 包ns/op值为1547， <code>github.com/marmotedu/errors</code> 包ns/op值为1772。可以看到，二者性能基本保持一致。</p><p>具体性能数据对比见下表：</p><p><img src=\"https://static001.geekbang.org/resource/image/a6/5e/a6a794d7523bc1edfa459d3a49f9685e.png?wh=1737x1145\" alt=\"\"></p><p>我们是通过<a href=\"https://github.com/marmotedu/errors/blob/v1.0.2/bench_test.go#L39\">BenchmarkErrors</a>测试函数来测试error包性能的，你感兴趣可以打开链接看看。</p><h2>如何记录错误？</h2><p>上面，我们一起看了怎么设计一个优秀的错误包，那如何用我们设计的错误包来记录错误呢？</p><p>根据我的开发经验，我推荐两种记录错误的方式，可以帮你快速定位问题。</p><p>方式一：通过<code>github.com/marmotedu/errors</code>包提供的错误堆栈能力，来跟踪错误。</p><p>具体你可以看看下面的代码示例。以下代码保存在<a href=\"https://github.com/marmotedu/gopractise-demo/blob/master/errors/errortrack_errors.go\">errortrack_errors.go</a>中。</p><pre><code>package main\n\nimport (\n\t&quot;fmt&quot;\n\n\t&quot;github.com/marmotedu/errors&quot;\n\n\tcode &quot;github.com/marmotedu/sample-code&quot;\n)\n\nfunc main() {\n\tif err := getUser(); err != nil {\n\t\tfmt.Printf(&quot;%+v\\n&quot;, err)\n\t}\n}\n\nfunc getUser() error {\n\tif err := queryDatabase(); err != nil {\n\t\treturn errors.Wrap(err, &quot;get user failed.&quot;)\n\t}\n\n\treturn nil\n}\n\nfunc queryDatabase() error {\n\treturn errors.WithCode(code.ErrDatabase, &quot;user 'Lingfei Kong' not found.&quot;)\n}\n</code></pre><p>执行上述的代码：</p><pre><code>$ go run errortrack_errors.go\nget user failed. - #1 [/home/colin/workspace/golang/src/github.com/marmotedu/gopractise-demo/errors/errortrack_errors.go:19 (main.getUser)] (100101) Database error; user 'Lingfei Kong' not found. - #0 [/home/colin/workspace/golang/src/github.com/marmotedu/gopractise-demo/errors/errortrack_errors.go:26 (main.queryDatabase)] (100101) Database error\n</code></pre><p>可以看到，打印的日志中打印出了详细的错误堆栈，包括错误发生的函数、文件名、行号和错误信息，通过这些错误堆栈，我们可以很方便地定位问题。</p><p>你使用这种方法时，我推荐的用法是，在错误最开始处使用 <code>errors.WithCode()</code> 创建一个 withCode类型的错误。上层在处理底层返回的错误时，可以根据需要，使用Wrap函数基于该错误封装新的错误信息。如果要包装的error不是用<code>github.com/marmotedu/errors</code>包创建的，建议用 <code>errors.WithCode()</code> 新建一个error。</p><p>方式二：在错误产生的最原始位置调用日志包记录函数，打印错误信息，其他位置直接返回（当然，也可以选择性的追加一些错误信息，方便故障定位）。示例代码（保存在<a href=\"https://github.com/marmotedu/gopractise-demo/blob/master/errors/errortrack_log.go\">errortrack_log.go</a>）如下：</p><pre><code>package main\n\nimport (\n\t&quot;fmt&quot;\n\n\t&quot;github.com/marmotedu/errors&quot;\n\t&quot;github.com/marmotedu/log&quot;\n\n\tcode &quot;github.com/marmotedu/sample-code&quot;\n)\n\nfunc main() {\n\tif err := getUser(); err != nil {\n\t\tfmt.Printf(&quot;%v\\n&quot;, err)\n\t}\n}\n\nfunc getUser() error {\n\tif err := queryDatabase(); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\nfunc queryDatabase() error {\n\topts := &amp;log.Options{\n\t\tLevel:            &quot;info&quot;,\n\t\tFormat:           &quot;console&quot;,\n\t\tEnableColor:      true,\n\t\tEnableCaller:     true,\n\t\tOutputPaths:      []string{&quot;test.log&quot;, &quot;stdout&quot;},\n\t\tErrorOutputPaths: []string{},\n\t}\n\n\tlog.Init(opts)\n\tdefer log.Flush()\n\n\terr := errors.WithCode(code.ErrDatabase, &quot;user 'Lingfei Kong' not found.&quot;)\n\tif err != nil {\n\t\tlog.Errorf(&quot;%v&quot;, err)\n\t}\n\treturn err\n}\n</code></pre><p>执行以上代码：</p><pre><code>$ go run errortrack_log.go\n2021-07-03 14:37:31.597\tERROR\terrors/errortrack_log.go:41\tDatabase error\nDatabase error\n</code></pre><p>当错误发生时，调用log包打印错误。通过log包的caller功能，可以定位到log语句的位置，也就是定位到错误发生的位置。你使用这种方式来打印日志时，我有两个建议。</p><ul>\n<li>只在错误产生的最初位置打印日志，其他地方直接返回错误，一般不需要再对错误进行封装。</li>\n<li>当代码调用第三方包的函数时，第三方包函数出错时打印错误信息。比如：</li>\n</ul><pre><code>if err := os.Chdir(&quot;/root&quot;); err != nil {\n    log.Errorf(&quot;change dir failed: %v&quot;, err)\n}\n</code></pre><h2>一个错误码的具体实现</h2><p>接下来，我们看一个依据上一讲介绍的错误码规范的具体错误码实现<code>github.com/marmotedu/sample-code</code>。</p><p><code>sample-code</code>实现了两类错误码，分别是通用错误码（<a href=\"https://github.com/marmotedu/sample-code/blob/master/base.go\">sample-code/base.go</a>）和业务模块相关的错误码（<a href=\"https://github.com/marmotedu/sample-code/blob/master/apiserver.go\">sample-code/apiserver.go</a>）。</p><p>首先，我们来看通用错误码的定义：</p><pre><code>// 通用: 基本错误\n// Code must start with 1xxxxx\nconst (\n    // ErrSuccess - 200: OK.\n    ErrSuccess int = iota + 100001\n\n    // ErrUnknown - 500: Internal server error.\n    ErrUnknown\n\n    // ErrBind - 400: Error occurred while binding the request body to the struct.\n    ErrBind\n\n    // ErrValidation - 400: Validation failed.\n    ErrValidation\n\n    // ErrTokenInvalid - 401: Token invalid.\n    ErrTokenInvalid\n)\n</code></pre><p>在代码中，我们通常使用整型常量（ErrSuccess）来代替整型错误码（100001），因为使用ErrSuccess时，一看就知道它代表的错误类型，可以方便开发者使用。</p><p>错误码用来指代一个错误类型，该错误类型需要包含一些有用的信息，例如对应的HTTP Status Code、对外展示的Message，以及跟该错误匹配的帮助文档。所以，我们还需要实现一个Coder来承载这些信息。这里，我们定义了一个实现了<code>github.com/marmotedu/errors.Coder</code>接口的<code>ErrCode</code>结构体：</p><pre><code>// ErrCode implements `github.com/marmotedu/errors`.Coder interface.\ntype ErrCode struct {\n    // C refers to the code of the ErrCode.\n    C int\n\n    // HTTP status that should be used for the associated error code.\n    HTTP int\n\n    // External (user) facing error text.\n    Ext string\n\n    // Ref specify the reference document.\n    Ref string\n}\n</code></pre><p>可以看到<code>ErrCode</code>结构体包含了以下信息：</p><ul>\n<li>int类型的业务码。</li>\n<li>对应的HTTP Status Code。</li>\n<li>暴露给外部用户的消息。</li>\n<li>错误的参考文档。</li>\n</ul><p>下面是一个具体的Coder示例：</p><pre><code>coder := &amp;ErrCode{\n    C:    100001,\n    HTTP: 200,\n    Ext:  &quot;OK&quot;,\n    Ref:  &quot;https://github.com/marmotedu/sample-code/blob/master/README.md&quot;,\n}\n</code></pre><p>接下来，我们就可以调用<code>github.com/marmotedu/errors</code>包提供的<code>Register</code>或者<code>MustRegister</code>函数，将Coder注册到<code>github.com/marmotedu/errors</code>包维护的内存中。</p><p>一个项目有很多个错误码，如果每个错误码都手动调用<code>MustRegister</code>函数会很麻烦，这里我们通过代码自动生成的方法，来生成register函数调用：</p><pre><code>//go:generate codegen -type=int\n//go:generate codegen -type=int -doc -output ./error_code_generated.md\n</code></pre><p><code>//go:generate codegen -type=int</code> 会调用<a href=\"https://github.com/marmotedu/iam/tree/master/tools/codegen\">codegen</a>工具，生成<a href=\"https://github.com/marmotedu/sample-code/blob/master/sample_code_generated.go\">sample_code_generated.go</a>源码文件：</p><pre><code>func init() {\n\tregister(ErrSuccess, 200, &quot;OK&quot;)\n\tregister(ErrUnknown, 500, &quot;Internal server error&quot;)\n\tregister(ErrBind, 400, &quot;Error occurred while binding the request body to the struct&quot;)\n\tregister(ErrValidation, 400, &quot;Validation failed&quot;)\n    // other register function call\n}\n</code></pre><p>这些<a href=\"https://github.com/marmotedu/iam/blob/v1.0.0/internal/pkg/code/code.go#L58\">register</a>调用放在init函数中，在加载程序的时候被初始化。</p><p>这里要注意，在注册的时候，我们会检查HTTP Status Code，只允许定义200、400、401、403、404、500这6个HTTP错误码。这里通过程序保证了错误码是符合HTTP Status Code使用要求的。</p><p><code>//go:generate codegen -type=int -doc -output ./error_code_generated.md</code>会生成错误码描述文档 <a href=\"https://github.com/marmotedu/sample-code/blob/master/error_code_generated.md\">error_code_generated.md</a>。当我们提供API文档时，也需要记着提供一份错误码描述文档，这样客户端才可以根据错误码，知道请求是否成功，以及具体发生哪类错误，好针对性地做一些逻辑处理。</p><p><code>codegen</code>工具会根据错误码注释生成<code>sample_code_generated.go</code>和<code>error_code_generated.md</code>文件：</p><pre><code>// ErrSuccess - 200: OK.\n ErrSuccess int = iota + 100001\n</code></pre><p>codegen工具之所以能够生成<code>sample_code_generated.go</code>和<code>error_code_generated.md</code>，是因为我们的错误码注释是有规定格式的：<code>// &lt;错误码整型常量&gt; - &lt;对应的HTTP Status Code&gt;: &lt;External Message&gt;.</code>。</p><p>codegen工具可以在IAM项目根目录下，执行以下命令来安装：</p><pre><code>$ make tools.install.codegen\n</code></pre><p>安装完 <code>codegen</code> 工具后，可以在 <code>github.com/marmotedu/sample-code</code> 包根目录下执行 <code>go generate</code> 命令，来生成<code>sample_code_generated.go</code>和<code>error_code_generated.md</code>。这里有个技巧需要你注意：生成的文件建议统一用  <code>xxxx_generated.xx</code> 来命名，这样通过 <code>generated</code> ，我们就知道这个文件是代码自动生成的，有助于我们理解和使用。</p><p>在实际的开发中，我们可以将错误码独立成一个包，放在 <code>internal/pkg/code/</code>目录下，这样可以方便整个应用调用。例如IAM的错误码就放在IAM项目根目录下的<a href=\"https://github.com/marmotedu/iam/tree/master/internal/pkg/code\">internal/pkg/code/</a>目录下。</p><p>我们的错误码是分服务和模块的，所以这里建议你把相同的服务放在同一个Go源文件中，例如IAM的错误码存放文件：</p><pre><code>$ ls base.go apiserver.go authzserver.go \napiserver.go  authzserver.go  base.go\n</code></pre><p>一个应用中会有多个服务，例如IAM应用中，就包含了iam-apiserver、iam-authz-server、iam-pump三个服务。这些服务有一些通用的错误码，为了便于维护，可以将这些通用的错误码统一放在base.go源码文件中。其他的错误码，我们可以按服务分别放在不同的文件中：iam-apiserver服务的错误码统一放在apiserver.go文件中；iam-authz-server的错误码统一存放在authzserver.go文件中。其他服务以此类推。</p><p>另外，同一个服务中不同模块的错误码，可以按以下格式来组织：相同模块的错误码放在同一个const代码块中，不同模块的错误码放在不同的const代码块中。每个const代码块的开头注释就是该模块的错误码定义。例如：</p><pre><code>// iam-apiserver: user errors.\nconst (\n    // ErrUserNotFound - 404: User not found.\n    ErrUserNotFound int = iota + 110001\n\n    // ErrUserAlreadyExist - 400: User already exist.\n    ErrUserAlreadyExist\n)\n\n// iam-apiserver: secret errors.\nconst (\n    // ErrEncrypt - 400: Secret reach the max count.\n    ErrReachMaxCount int = iota + 110101\n\n    //  ErrSecretNotFound - 404: Secret not found.\n    ErrSecretNotFound\n)\n</code></pre><p>最后，我们还需要将错误码定义记录在项目的文件中，供开发者查阅、遵守和使用，例如IAM项目的错误码定义记录文档为<a href=\"https://github.com/marmotedu/iam/blob/master/docs/guide/zh-CN/api/code_specification.md\">code_specification.md</a>。这个文档中记录了错误码说明、错误描述规范和错误记录规范等。</p><h2>错误码实际使用方法示例</h2><p>上面，我讲解了错误包和错误码的实现方式，那你一定想知道在实际开发中我们是如何使用的。这里，我就举一个在gin web框架中使用该错误码的例子：</p><pre><code>// Response defines project response format which in marmotedu organization.\ntype Response struct {\n    Code      errors.Code `json:&quot;code,omitempty&quot;`\n    Message   string      `json:&quot;message,omitempty&quot;`\n    Reference string      `json:&quot;reference,omitempty&quot;`\n    Data      interface{} `json:&quot;data,omitempty&quot;`\n}\n\n// WriteResponse used to write an error and JSON data into response.\nfunc WriteResponse(c *gin.Context, err error, data interface{}) {\n    if err != nil {\n        coder := errors.ParseCoder(err)\n\n        c.JSON(coder.HTTPStatus(), Response{\n            Code:      coder.Code(),\n            Message:   coder.String(),\n            Reference: coder.Reference(),\n            Data:      data,\n        })\n    }\n\n    c.JSON(http.StatusOK, Response{Data: data})\n}\n\nfunc GetUser(c *gin.Context) {\n    log.Info(&quot;get user function called.&quot;, &quot;X-Request-Id&quot;, requestid.Get(c))\n    // Get the user by the `username` from the database.\n    user, err := store.Client().Users().Get(c.Param(&quot;username&quot;), metav1.GetOptions{})\n    if err != nil {\n        core.WriteResponse(c, errors.WithCode(code.ErrUserNotFound, err.Error()), nil)\n        return\n    }\n\n    core.WriteResponse(c, nil, user)\n}\n</code></pre><p>上述代码中，通过<code>WriteResponse</code>统一处理错误。在 <code>WriteResponse</code> 函数中，如果<code>err != nil</code>，则从error中解析出Coder，并调用Coder提供的方法，获取错误相关的Http Status Code、int类型的业务码、暴露给用户的信息、错误的参考文档链接，并返回JSON格式的信息。如果 <code>err == nil</code> 则返回200和数据。</p><h2>总结</h2><p>记录错误是应用程序必须要做的一件事情，在实际开发中，我们通常会封装自己的错误包。一个优秀的错误包，应该能够支持错误堆栈、不同的打印格式、Wrap/Unwrap/Is/As等函数，并能够支持格式化创建error。</p><p>根据这些错误包设计要点，我基于 <code>github.com/pkg/errors</code> 包设计了IAM项目的错误包 <code>github.com/marmotedu/errors</code> ，该包符合我们上一讲设计的错误码规范。</p><p>另外，本讲也给出了一个具体的错误码实现 sample-code ， sample-code 支持业务Code码、HTTP Status Code、错误参考文档、可以对内对外展示不同的错误信息。</p><p>最后，因为错误码注释是有固定格式的，所以我们可以通过codegen工具解析错误码的注释，生成register函数调用和错误码文档。这种做法也体现了我一直强调的low code思想，可以提高开发效率，减少人为失误。</p><h2>课后练习</h2><ol>\n<li>在这门课里，我们定义了base、iam-apiserver服务的错误码，请试着定义iam-authz-server服务的错误码，并生成错误码文档。</li>\n<li>思考下，这门课的错误包和错误码设计能否满足你当前的项目需求，如果觉得不能满足，可以在留言区分享你的看法。</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"18 | 错误处理（上）：如何设计一套科学的错误码？","id":391895},"right":{"article_title":"20 | 日志处理（上）：如何设计日志包并记录日志？","id":393905}}},{"article_id":393905,"article_title":"20 | 日志处理（上）：如何设计日志包并记录日志？","article_content":"<p>你好，我是孔令飞，接下来的两讲，我们来聊聊如何设计和开发日志包。</p><p>在做Go项目开发时，除了处理错误之外，我们必须要做的另外一件事是记录日志。通过记录日志，可以完成一些基本功能，比如开发、测试期间的Debug，故障排除，数据分析，监控告警，以及记录发生的事件等。</p><p>要实现这些功能，首先我们需要一个优秀的日志包。另外，我还发现不少Go项目开发者记录日志很随意，输出的日志并不能有效定位到问题。所以，我们还需要知道怎么更好地记录日志，这就需要一个日志记录规范。</p><p>有了优秀的日志包和日志记录规范，我们就能很快地定位到问题，获取足够的信息，并完成后期的数据分析和监控告警，也可以很方便地进行调试了。这一讲，我就来详细介绍下，如何设计日志包和日志记录规范。</p><p>首先，我们来看下如何设计日志包。</p><h2>如何设计日志包</h2><p>目前，虽然有很多优秀的开源日志包可供我们选择，但在一个大型系统中，这些开源日志包很可能无法满足我们定制化的需求，这时候我们就需要自己开发日志包。</p><p>这些日志包可能是基于某个，或某几个开源的日志包改造而来，也可能是全新开发的日志包。那么在开发日志包时，我们需要实现哪些功能，又如何实现呢？接下来，我们就来详细聊聊。</p><p>先来看下日志包需要具备哪些功能。根据功能的重要性，我将日志包需要实现的功能分为<strong>基础功能</strong>、<strong>高级功能</strong>和<strong>可选功能</strong>。基础功能是一个日志包必须要具备的功能；高级功能、可选功能都是在特定场景下可增加的功能。我们先来说基础功能。</p><!-- [[[read_end]]] --><h3>基础功能</h3><p>基础功能，是优秀日志包必备的功能，能够满足绝大部分的使用场景，适合一些中小型的项目。一个日志包应该具备以下4个基础功能。</p><ol>\n<li>支持基本的日志信息</li>\n</ol><p>日志包需要支持基本的日志信息，包括时间戳、文件名、行号、日志级别和日志信息。</p><p>时间戳可以记录日志发生的时间。在定位问题时，我们往往需要根据时间戳，来复原请求过程，核对相同时间戳下的上下文，从而定位出问题。</p><p>文件名和行号，可以使我们更快速定位到打印日志的位置，找到问题代码。一个日志库如果不支持文件名和行号，排查故障就会变得非常困难，基本只能靠grep和记忆来定位代码。对于企业级的服务，需要保证服务在故障后能够快速恢复，恢复的时间越久，造成的损失就越大，影响就越大。这就要求研发人员能够快速定位并解决问题。通过文件名和行号，我们可以精准定位到问题代码，尽快地修复问题并恢复服务。</p><p>通过日志级别，可以知道日志的错误类型，最通常的用法是：直接过滤出 <code>Error</code> 级别的日志，这样就可以直接定位出问题出错点，然后再结合其他日志定位出出错的原因。如果不支持日志级别，在定位问题时，可能要查看一大堆无用的日志。在大型系统中，一次请求的日志量很多，这会大大延长我们定位问题的时间。</p><p>而通过日志信息，我们可以知道错误发生的具体原因。</p><ol start=\"2\">\n<li>支持不同的日志级别</li>\n</ol><p>不同的日志级别代表不同的日志类型，例如：Error级别的日志，说明日志是错误类型，在排障时，会首先查看错误级别的日志。Warn级别日志说明出现异常，但还不至于影响程序运行，如果程序执行的结果不符合预期，则可以参考Warn级别的日志，定位出异常所在。Info级别的日志，可以协助我们Debug，并记录一些有用的信息，供后期进行分析。</p><p>通常一个日志包至少要实现6个级别，我给你提供了一张表格，按优先级从低到高排列如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/bb/2b/bb1356bd3cf332ddeb30d3aef8fc8d2b.png?wh=1794x1120\" alt=\"\"></p><p>有些日志包，例如logrus，还支持Trace日志级别。Trace级别比Debug级别还低，能够打印更细粒度的日志信息。在我看来，Trace级别不是必须的，你可以根据需要自行选择。</p><p>打印日志时，一个日志调用其实具有两个属性：</p><ul>\n<li>输出级别：打印日志时，我们期望日志的输出级别。例如，我们调用 <code>glog.Info(\"This is info message\")</code> 打印一条日志，则输出日志级别为Info。</li>\n<li>开关级别：启动应用程序时，期望哪些输出级别的日志被打印。例如，使用glog时 <code>-v=4</code> ，说明了只有日志级别高于4的日志才会被打印。</li>\n</ul><p>如果开关级别设置为 <code>L</code> ，只有输出级别 <code>&gt;=L</code> 时，日志才会被打印。例如，开关级别为Warn，则只会记录Warn、Error 、Panic 和Fatal级别的日志。具体的输出关系如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/dd/ed/dd4e9c3ed26b254cb5b65ff1fddd40ed.png?wh=1654x526\" alt=\"\"></p><ol start=\"3\">\n<li>支持自定义配置</li>\n</ol><p>不同的运行环境，需要不同的日志输出配置，例如：开发测试环境为了能够方便地Debug，需要设置日志级别为Debug级别；现网环境为了提高应用程序的性能，则需要设置日志级别为Info级别。又比如，现网环境为了方便日志采集，通常会输出JSON格式的日志；开发测试环境为了方便查看日志，会输出TEXT格式的日志。</p><p>所以，我们的日志包需要能够被配置，还要不同环境采用不同的配置。通过配置，可以在不重新编译代码的情况下，改变记录日志的行为。</p><ol start=\"4\">\n<li>支持输出到标准输出和文件</li>\n</ol><p>日志总是要被读的，要么输出到标准输出，供开发者实时读取，要么保存到文件，供开发者日后查看。输出到标准输出和保存到文件是一个日志包最基本的功能。</p><h3>高级功能</h3><p>除了上面提到的这些基本功能外，在一些大型系统中，通常还会要求日志包具备一些高级功能。这些高级功能可以帮我们更好地记录日志，并实现更丰富的功能，例如日志告警。那么一个日志包可以具备哪些高级功能呢？</p><ol>\n<li>支持多种日志格式</li>\n</ol><p>日志格式也是我们要考虑的一个点，一个好的日志格式，不仅方便查看日志，还能方便一些日志采集组件采集日志，并对接类似Elasticsearch这样的日志搜索引擎。</p><p>一个日志包至少需要提供以下两种格式：</p><ul>\n<li>TEXT格式：TEXT格式的日志具有良好的可读性，可以方便我们在开发联调阶段查看日志，例如：</li>\n</ul><p>2020-12-02T01:16:18+08:00 INFO example.go:11 std log</p><p>2020-12-02T01:16:18+08:00 DEBUG example.go:13 change std log to debug level</p><ul>\n<li>JSON格式：JSON格式的日志可以记录更详细的信息，日志中包含一些通用的或自定义的字段，可供日后的查询、分析使用，而且可以很方便地供filebeat、logstash这类日志采集工具采集并上报。下面是JSON格式的日志：</li>\n</ul><pre><code>{&quot;level&quot;:&quot;DEBUG&quot;,&quot;time&quot;:&quot;2020-12-02T01:16:18+08:00&quot;,&quot;file&quot;:&quot;example.go:15&quot;,&quot;func&quot;:&quot;main.main&quot;,&quot;message&quot;:&quot;log in json format&quot;}\n{&quot;level&quot;:&quot;INFO&quot;,&quot;time&quot;:&quot;2020-12-02T01:16:18+08:00&quot;,&quot;file&quot;:&quot;example.go:16&quot;,&quot;func&quot;:&quot;main.main&quot;,&quot;message&quot;:&quot;another log in json format&quot;}\n</code></pre><p>我建议在开发联调阶段使用TEXT格式的日志，在现网环境使用JSON格式的日志。一个优秀的日志库，例如logrus，除了提供基本的输出格式外，还应该允许开发者自定义日志输出格式。</p><ol start=\"2\">\n<li>能够按级别分类输出</li>\n</ol><p>为了能够快速定位到需要的日志，一个比较好的做法是将日志按级别分类输出，至少错误级别的日志可以输出到独立的文件中。这样，出现问题时，可以直接查找错误文件定位问题。例如，glog就支持分类输出，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/10/4b/100af3121e8d4e84428979f9d0yydf4b.png?wh=2091x326\" alt=\"\"></p><ol start=\"3\">\n<li>支持结构化日志</li>\n</ol><p>结构化日志（Structured Logging），就是使用JSON或者其他编码方式使日志结构化，这样可以方便后续使用Filebeat、Logstash Shipper等各种工具，对日志进行采集、过滤、分析和查找。就像下面这个案例，使用zap进行日志打印：</p><pre><code>package main\n\nimport (\n    &quot;time&quot;\n\n    &quot;go.uber.org/zap&quot;\n)\n\nfunc main() {\n    logger, _ := zap.NewProduction()\n    defer logger.Sync() // flushes buffer, if any\n    url := &quot;http://marmotedu.com&quot;\n    // 结构化日志打印\n    logger.Sugar().Infow(&quot;failed to fetch URL&quot;, &quot;url&quot;, url, &quot;attempt&quot;, 3, &quot;backoff&quot;, time.Second)\n\n    // 非结构化日志打印\n    logger.Sugar().Infof(&quot;failed to fetch URL: %s&quot;, url)\n}\n</code></pre><p>上述代码输出为：</p><pre><code>{&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:1607303966.9903321,&quot;caller&quot;:&quot;zap/structured_log.go:14&quot;,&quot;msg&quot;:&quot;failed to fetch URL&quot;,&quot;url&quot;:&quot;http://marmotedu.com&quot;,&quot;attempt&quot;:3,&quot;backoff&quot;:1}\n{&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:1607303966.9904354,&quot;caller&quot;:&quot;zap/structured_log.go:17&quot;,&quot;msg&quot;:&quot;failed to fetch URL: http://marmotedu.com&quot;}\n</code></pre><ol start=\"4\">\n<li>支持日志轮转</li>\n</ol><p>在一个大型项目中，一天可能会产生几十个G的日志。为了防止日志把磁盘空间占满，导致服务器或者程序异常，就需要确保日志大小达到一定量级时，对日志进行切割、压缩，并转存。</p><p>如何切割呢？你可以按照日志大小进行切割，也可以按日期切割。日志的切割、压缩和转存功能可以基于GitHub上一些优秀的开源包来封装，例如：<a href=\"https://github.com/natefinch/lumberjack\">lumberjack</a>可以支持按大小和日期归档日志，<a href=\"https://github.com/lestrrat-go/file-rotatelogs\">file-rotatelogs</a>支持按小时数进行日志切割。</p><p>对于日志轮转功能，其实我不建议在日志包中添加，因为这会增加日志包的复杂度，我更建议的做法是借助其他的工具来实现日志轮转。例如，在Linux系统中可以使用Logrotate来轮转日志。Logrotate功能强大，是一个专业的日志轮转工具。</p><ol start=\"5\">\n<li>具备Hook能力</li>\n</ol><p>Hook能力可以使我们对日志内容进行自定义处理。例如，当某个级别的日志产生时，发送邮件或者调用告警接口进行告警。很多优秀的开源日志包提供了Hook能力，例如logrus和zap。</p><p>在一个大型系统中，日志告警是非常重要的功能，但更好的实现方式是将告警能力做成旁路功能。通过旁路功能，可以保证日志包功能聚焦、简洁。例如：可以将日志收集到Elasticsearch，并通过ElastAlert进行日志告警。</p><h3>可选功能</h3><p>除了基础功能和高级功能外，还有一些功能。这些功能不会影响到日志包的核心功能，但是如果具有这些功能，会使日志包更加易用。比如下面的这三个功能。</p><ol>\n<li>支持颜色输出</li>\n</ol><p>在开发、测试时开启颜色输出，不同级别的日志会被不同颜色标识，这样我们可以很轻松地发现一些Error、Warn级别的日志，方便开发调试。发布到生产环境时，可以关闭颜色输出，以提高性能。</p><ol start=\"2\">\n<li>兼容标准库log包</li>\n</ol><p>一些早期的Go项目大量使用了标准库log包，如果我们的日志库能够兼容标准库log包，我们就可以很容易地替换掉标准库log包。例如，logrus就兼容标准库log包。这里，我们来看一个使用了标准库log包的代码：</p><pre><code>package main\n\nimport (\n    &quot;log&quot;\n)\n\nfunc main() {\n    log.Print(&quot;call Print: line1&quot;)\n    log.Println(&quot;call Println: line2&quot;)\n}\n</code></pre><p>只需要使用<code>log \"github.com/sirupsen/logrus\"</code>替换<code>\"log\"</code>就可以完成标准库log包的切换：</p><pre><code>package main\n\nimport (\n    log &quot;github.com/sirupsen/logrus&quot;\n)\n\nfunc main() {\n    log.Print(&quot;call Print: line1&quot;)\n    log.Println(&quot;call Println: line2&quot;)\n}\n</code></pre><ol start=\"3\">\n<li>支持输出到不同的位置</li>\n</ol><p>在分布式系统中，一个服务会被部署在多台机器上，这时候如果我们要查看日志，就需要分别登录不同的机器查看，非常麻烦。我们更希望将日志统一投递到Elasticsearch上，在Elasticsearch上查看日志。</p><p>我们还可能需要从日志中分析某个接口的调用次数、某个用户的请求次数等信息，这就需要我们能够对日志进行处理。一般的做法是将日志投递到Kafka，数据处理服务消费Kafka中保存的日志，从而分析出调用次数等信息。</p><p>以上两种场景，分别需要把日志投递到Elasticsearch、Kafka等组件，如果我们的日志包支持将日志投递到不同的目的端，那会是一项非常让人期待的功能：</p><p><img src=\"https://static001.geekbang.org/resource/image/bd/4b/bda7177a7a627b0117bfffdbd129914b.png?wh=1904x842\" alt=\"\"></p><p>如果日志不支持投递到不同的下游组件，例如Elasticsearch、Kafka、Fluentd、Logstash等位置，也可以通过Filebeat采集磁盘上的日志文件，进而投递到下游组件。</p><h3>设计日志包时需要关注的点</h3><p>上面，我们介绍了日志包具备的功能，这些功能可以指导我们完成日志包设计。这里，我们再来看下设计日志包时，我们还需要关注的几个层面：</p><ul>\n<li><strong>高性能：</strong>因为我们要在代码中频繁调用日志包，记录日志，所以日志包的性能是首先要考虑的点，一个性能很差的日志包必然会导致整个应用性能很差。</li>\n<li><strong>并发安全：</strong>Go应用程序会大量使用Go语言的并发特性，也就意味着需要并发地记录日志，这就需要日志包是并发安全的。</li>\n<li><strong>插件化能力：</strong>日志包应该能提供一些插件化的能力，比如允许开发者自定义输出格式，自定义存储位置，自定义错误发生时的行为（例如 告警、发邮件等）。插件化的能力不是必需的，因为日志自身的特性就能满足绝大部分的使用需求，例如：输出格式支持JSON和TEXT，存储位置支持标准输出和文件，日志监控可以通过一些旁路系统来实现。</li>\n<li><strong>日志参数控制：</strong>日志包应该能够灵活地进行配置，初始化时配置或者程序运行时配置。例如：初始化配置可以通过 <code>Init</code> 函数完成，运行时配置可以通过 <code>SetOptions</code> / <code>SetLevel</code> 等函数来完成。</li>\n</ul><h2>如何记录日志？</h2><p>前面我们介绍了在设计日志包时，要包含的一些功能、实现方法和注意事项。但在这个过程中，还有一项重要工作需要注意，那就是日志记录问题。</p><p>日志并不是越多越好，在实际开发中，经常会遇到一大堆无用的日志，却没有我们需要的日志；或者有效的日志被大量无用的日志淹没，查找起来非常困难。</p><p>一个优秀的日志包可以协助我们更好地记录、查看和分析日志，但是如何记录日志决定了我们能否获取到有用的信息。日志包是工具，日志记录才是灵魂。这里，我就来详细讲讲如何记录日志。</p><p>想要更好地记录日志，我们需要解决以下几个问题：</p><ul>\n<li>在何处打印日志？</li>\n<li>在哪个日志级别打印日志？</li>\n<li>如何记录日志内容？</li>\n</ul><h3>在何处打印日志？</h3><p>日志主要是用来定位问题的，所以整体来说，我们要在有需要的地方打印日志。那么具体是哪些地方呢？我给你几个建议。</p><ul>\n<li><strong>在分支语句处打印日志。</strong>在分支语句处打印日志，可以判断出代码走了哪个分支，有助于判断请求的下一跳，继而继续排查问题。</li>\n<li><strong>写操作必须打印日志。</strong>写操作最可能会引起比较严重的业务故障，写操作打印日志，可以在出问题时找到关键信息。</li>\n<li><strong>在循环中打印日志要慎重。</strong>如果循环次数过多，会导致打印大量的日志，严重拖累代码的性能，建议的办法是在循环中记录要点，在循环外面总结打印出来。</li>\n<li><strong>在错误产生的最原始位置打印日志。</strong>对于嵌套的Error，可在Error产生的最初位置打印Error日志，上层如果不需要添加必要的信息，可以直接返回下层的Error。我给你举个例子：</li>\n</ul><pre><code>package main\n\nimport (\n    &quot;flag&quot;\n    &quot;fmt&quot;\n\n    &quot;github.com/golang/glog&quot;\n)\n\nfunc main() {\n    flag.Parse()\n    defer glog.Flush()\n\n    if err := loadConfig(); err != nil {\n        glog.Error(err)\n    }\n}\n\nfunc loadConfig() error {\n    return decodeConfig() // 直接返回\n}\n\nfunc decodeConfig() error {\n    if err := readConfig(); err != nil {\n        return fmt.Errorf(&quot;could not decode configuration data for user %s: %v&quot;, &quot;colin&quot;, err) // 添加必要的信息，用户名称\n    }\n\n    return nil\n}\n\nfunc readConfig() error {\n    glog.Errorf(&quot;read: end of input.&quot;)\n    return fmt.Errorf(&quot;read: end of input&quot;)\n}\n</code></pre><p>通过在最初产生错误的位置打印日志，我们可以很方便地追踪到日志的根源，进而在上层追加一些必要的信息。这可以让我们了解到该错误产生的影响，有助于排障。另外，直接返回下层日志，还可以减少重复的日志打印。</p><p>当代码调用第三方包的函数，且第三方包函数出错时，会打印错误信息。比如：</p><pre><code>if err := os.Chdir(&quot;/root&quot;); err != nil {\n    log.Errorf(&quot;change dir failed: %v&quot;, err)\n}\n</code></pre><h3>在哪个日志级别打印日志？</h3><p>不同级别的日志，具有不同的意义，能实现不同的功能，在开发中，我们应该根据目的，在合适的级别记录日志，这里我同样给你一些建议。</p><ol>\n<li>Debug级别</li>\n</ol><p>为了获取足够的信息进行Debug，通常会在Debug级别打印很多日志。例如，可以打印整个HTTP请求的请求Body或者响应Body。</p><p>Debug级别需要打印大量的日志，这会严重拖累程序的性能。并且，Debug级别的日志，主要是为了能在开发测试阶段更好地Debug，多是一些不影响现网业务的日志信息。所以，对于Debug级别的日志，在服务上线时我们一定要禁止掉。否则，就可能会因为大量的日志导致硬盘空间快速用完，从而造成服务宕机，也可能会影响服务的性能和产品体验。</p><p>Debug这个级别的日志可以随意输出，任何你觉得有助于开发、测试阶段调试的日志，都可以在这个级别打印。</p><ol start=\"2\">\n<li>Info级别</li>\n</ol><p>Info级别的日志可以记录一些有用的信息，供以后的运营分析，所以Info级别的日志不是越多越好，也不是越少越好，应以满足需求为主要目标。一些关键日志，可以在Info级别记录，但如果日志量大、输出频度过高，则要考虑在Debug级别记录。</p><p>现网的日志级别一般是Info级别，为了不使日志文件占满整个磁盘空间，在记录日志时，要注意避免产生过多的Info级别的日志。例如，在for循环中，就要慎用Info级别的日志。</p><ol start=\"3\">\n<li>Warn级别</li>\n</ol><p>一些警告类的日志可以记录在Warn级别，Warn级别的日志往往说明程序运行异常，不符合预期，但又不影响程序的继续运行，或者是暂时影响，但后续会恢复。像这些日志，就需要你关注起来。Warn更多的是业务级别的警告日志。</p><ol start=\"4\">\n<li>Error级别</li>\n</ol><p>Error级别的日志告诉我们程序执行出错，这些错误肯定会影响到程序的执行结果，例如请求失败、创建资源失败等。要记录每一个发生错误的日志，避免日后排障过程中这些错误被忽略掉。大部分的错误可以归在Error级别。</p><ol start=\"5\">\n<li>Panic级别</li>\n</ol><p>Panic级别的日志在实际开发中很少用，通常只在需要错误堆栈，或者不想因为发生严重错误导致程序退出，而采用defer处理错误时使用。</p><ol start=\"6\">\n<li>Fatal级别</li>\n</ol><p>Fatal是最高级别的日志，这个级别的日志说明问题已经相当严重，严重到程序无法继续运行，通常是系统级的错误。在开发中也很少使用，除非我们觉得某个错误发生时，整个程序无法继续运行。</p><p>这里用一张图来总结下，如何选择Debug、Info、Warn、Error、Panic、Fatal这几种日志级别。</p><p><img src=\"https://static001.geekbang.org/resource/image/75/35/75e8c71a791f279a68c35734f2451035.png?wh=3646x1542\" alt=\"\"></p><h3>如何记录日志内容？</h3><p>关于如何记录日志内容，我有几条建议：</p><ul>\n<li>在记录日志时，不要输出一些敏感信息，例如密码、密钥等。</li>\n<li>为了方便调试，通常会在Debug级别记录一些临时日志，这些日志内容可以用一些特殊的字符开头，例如 <code>log.Debugf(\"XXXXXXXXXXXX-1:Input key was: %s\", setKeyName)</code> 。这样，在完成调试后，可以通过查找 <code>XXXXXXXXXXXX</code> 字符串，找到这些临时日志，在commit前删除。</li>\n<li>日志内容应该小写字母开头，以英文点号 <code>.</code> 结尾，例如 <code>log.Info(\"update user function called.\")</code> 。</li>\n<li>为了提高性能，尽可能使用明确的类型，例如使用 <code>log.Warnf(\"init datastore: %s\", err.Error())</code> 而非 <code>log.Warnf(\"init datastore: %v\", err)</code> 。</li>\n<li>根据需要，日志最好包含两个信息。一个是请求ID（RequestID），是每次请求的唯一ID，便于从海量日志中过滤出某次请求的日志，可以将请求ID放在请求的通用日志字段中。另一个是用户和行为，用于标识谁做了什么。</li>\n<li>不要将日志记录在错误的日志级别上。例如，我在项目开发中，经常会发现有同事将正常的日志信息打印在Error级别，将错误的日志信息打印在Info级别。</li>\n</ul><h3>记录日志的“最佳”实践总结</h3><p>关于日志记录问题，我从以上三个层面给你讲解了。综合来说，对于日志记录的最佳实践，你在平时都可以注意或进行尝试，我把这些重点放在这里，方便你后续查阅。</p><ul>\n<li>开发调试、现网故障排障时，不要遗忘一件事情：根据排障的过程优化日志打印。好的日志，可能不是一次就可以写好的，可以在实际开发测试，还有现网定位问题时，不断优化。但这需要你重视日志，而不是把日志仅仅当成记录信息的一种方式，甚至不知道为什么打印一条Info日志。</li>\n<li>打印日志要“不多不少”，避免打印没有作用的日志，也不要遗漏关键的日志信息。最好的信息是，仅凭借这些关键的日志就能定位到问题。</li>\n<li>支持动态日志输出，方便线上问题定位。</li>\n<li>总是将日志记录在本地文件：通过将日志记录在本地文件，可以和日志中心化平台进行解耦，这样当网络不可用，或者日志中心化平台故障时，仍然能够正常的记录日志。</li>\n<li>集中化日志存储处理：因为应用可能包含多个服务，一个服务包含多个实例，为了查看日志方便，最好将这些日志统一存储在同一个日志平台上，例如Elasticsearch，方便集中管理和查看日志。</li>\n<li>结构化日志记录：添加一些默认通用的字段到每行日志，方便日志查询和分析。</li>\n<li>支持RequestID：使用RequestID串联一次请求的所有日志，这些日志可能分布在不同的组件，不同的机器上。支持RequestID可以大大提高排障的效率，降低排障难度。在一些大型分布式系统中，没有RequestID排障简直就是灾难。</li>\n<li>支持动态开关Debug日志：对于定位一些隐藏得比较深的问题，可能需要更多的信息，这时候可能需要打印Debug日志。但现网的日志级别会设置为Info级别，为了获取Debug日志，我们可能会修改日志级别为Debug级别并重启服务，定位完问题后，再修改日志级别为Info级别，然后再重启服务，这种方式不仅麻烦而且还可能会对现网业务造成影响，最好的办法是能够在请求中通过 <code>debug=true</code> 这类参数动态控制某次请求是否开启Debug日志。</li>\n</ul><h2>拓展内容：分布式日志解决方案（EFK/ELK）</h2><p>前面我们介绍了设计日志包和记录日志的规范，除此之外，还有一个问题你应该了解，那就是：我们记录的日志如何收集、处理和展示。</p><p>在实际Go项目开发中，为了实现高可用，同一个服务至少需要部署两个实例，通过轮询的负载均衡策略转发请求。另外，一个应用又可能包含多个服务。假设我们的应用包含两个服务，每个服务部署两个实例，如果应用出故障，我们可能需要登陆4（2 x 2）台服务器查看本地的日志文件，定位问题，非常麻烦，会增加故障恢复时间。所以在真实的企业场景中，我们会将这些日志统一收集并展示。</p><p>在业界，日志的收集、处理和展示，早已经有了一套十分流行的日志解决方案：EFK（Elasticsearch + Filebeat + Kibana）或者ELK（Elasticsearch + Logstash + Kibana），EFK可以理解为ELK的演进版，把日志收集组件从Logstash替换成了Filebeat。用Filebeat替换Logstash，主要原因是Filebeat更轻量级，占用的资源更少。关于日志处理架构，你可以参考这张图。</p><p><img src=\"https://static001.geekbang.org/resource/image/5d/c8/5daabdfea213c05fc0387aa735e54ec8.png?wh=4194x778\" alt=\"\"></p><p>通过log包将日志记录在本地文件中（*.log文件），再通过Shipper收集到Kafka中。Shipper可以根据需要灵活选择，常见的Shipper有Logstash Shipper、Flume、Fluentd、Filebeat。其中Filebeat和Logstash Shipper用得最多。Shipper没有直接将日志投递到Logstash indexer，或者Elasticsearch，是因为Kafka能够支持更大的吞吐量，起到削峰填谷的作用。</p><p>Kafka中的日志消息会被Logstash indexer消费，处理后投递到Elasticsearch中存储起来。Elasticsearch是实时全文搜索和分析引擎，提供搜集、分析、存储数据三大功能。Elasticsearch中存储的日志，可以通过Kibana提供的图形界面来展示。Kibana是一个基于Web的图形界面，用于搜索、分析和可视化存储在 Elasticsearch中的日志数据。</p><p>Logstash负责采集、转换和过滤日志。它支持几乎任何类型的日志，包括系统日志、错误日志和自定义应用程序日志。Logstash又分为Logstash Shipper和Logstash indexer。其中，Logstash Shipper监控并收集日志，并将日志内容发送到Logstash indexer，然后Logstash indexer过滤日志，并将日志提交给Elasticsearch。</p><h2>总结</h2><p>记录日志，是应用程序必备的功能。记录日志最大的作用是排障，如果想更好地排障，我们需要一个优秀的工具，日志包。那么如何设计日志包呢？首先我们需要知道日志包的功能，在我看来日志包需要具备以下功能：</p><ul>\n<li>基础功能：支持基本的日志信息、支持不同的日志级别、支持自定义配置、支持输出到标准输出和文件。</li>\n<li>高级功能：支持多种日志格式、能够按级别分类输出、支持结构化日志、支持日志轮转、具备Hook能力。</li>\n<li>可选功能：支持颜色输出、兼容标准库log包、支持输出到不同的位置。</li>\n</ul><p>另外，一个日志包还需要支持不同级别的日志，按日志级别优先级从低到高分别是：Trace &lt; Debug &lt; Info &lt; Warn/Warning &lt; Error &lt; Panic &lt; Fatal。其中Debug、Info、Warn、Error、Fatal是比较基础的级别，建议在开发一个日志包时包含这些级别。Trace、Panic是可选的级别。</p><p>在我们掌握了日志包的功能之后，就可以设计、开发日志包了。但我们在开发过程中，还需要确保我们的日志包具有比较高的性能、并发安全、支持插件化的能力，并支持日志参数控制。</p><p>有了日志包，我们还需要知道如何更好地使用日志包，也就是如何记录日志。在文中，我给出了一些记录建议，内容比较多，你可以返回文中查看。</p><p>最后，我还给出了分布式日志解决方案：EFK/ELK。EFK是ELK的升级版，在实际项目开发中，我们可以直接选择EFK。在EFK方案中，通过Filebeat将日志上传到Kafka，Logstash indexer消费Kafka中的日志，并投递到Elasticsearch中存储起来，最后通过Kibana图形界面来查看日志。</p><h2>课后练习</h2><p>思考一下，你的项目中，日志包还需要哪些功能，如何设计？你的日常开发中，如果有比较好的日志记录规范，也欢迎在留言区分享讨论。</p><p>期待你的思考和看法，我们下一讲见。</p>","neighbors":{"left":{"article_title":"19 | 错误处理（下）：如何设计错误包？","id":393022},"right":{"article_title":"21 | 日志处理（下）：手把手教你从 0 编写一个日志包","id":394633}}},{"article_id":394633,"article_title":"21 | 日志处理（下）：手把手教你从 0 编写一个日志包","article_content":"<p>你好，我是孔令飞。</p><p>上一讲我介绍了如何设计日志包，今天是实战环节，我会手把手教你从0编写一个日志包。</p><p>在实际开发中，我们可以选择一些优秀的开源日志包，不加修改直接拿来使用。但更多时候，是基于一个或某几个优秀的开源日志包进行二次开发。想要开发或者二次开发一个日志包，就要掌握日志包的实现方式。那么这一讲中，我来带你从0到1，实现一个具备基本功能的日志包，让你从中一窥日志包的实现原理和实现方法。</p><p>在开始实战之前，我们先来看下目前业界有哪些优秀的开源日志包。</p><h2>有哪些优秀的开源日志包？</h2><p>在Go项目开发中，我们可以通过修改一些优秀的开源日志包，来实现项目的日志包。Go生态中有很多优秀的开源日志包，例如标准库log包、glog、logrus、zap、seelog、zerolog、log15、apex/log、go-logging等。其中，用得比较多的是标准库log包、glog、logrus和zap。</p><p>为了使你了解开源日志包的现状，接下来我会简单介绍下这几个常用的日志包。至于它们的具体使用方法，你可以参考我整理的一篇文章：<a href=\"https://github.com/marmotedu/geekbang-go/blob/master/%E4%BC%98%E7%A7%80%E5%BC%80%E6%BA%90%E6%97%A5%E5%BF%97%E5%8C%85%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B.md\">优秀开源日志包使用教程</a>。</p><h3>标准库log包</h3><p>标准库log包的功能非常简单，只提供了Print、Panic和Fatal三类函数用于日志输出。因为是标准库自带的，所以不需要我们下载安装，使用起来非常方便。</p><!-- [[[read_end]]] --><p>标准库log包只有不到400行的代码量，如果你想研究如何实现一个日志包，阅读标准库log包是一个不错的开始。Go的标准库大量使用了log包，例如<code>net/http</code> 、 <code>net/rpc</code> 等。</p><h3>glog</h3><p><a href=\"https://github.com/golang/glog\">glog</a>是Google推出的日志包，跟标准库log包一样，它是一个轻量级的日志包，使用起来简单方便。但glog比标准库log包提供了更多的功能，它具有如下特性：</p><ul>\n<li>支持4种日志级别：Info、Warning、Error、Fatal。</li>\n<li>支持命令行选项，例如<code>-alsologtostderr</code>、<code>-log_backtrace_at</code>、<code>-log_dir</code>、<code>-logtostderr</code>、<code>-v</code>等，每个参数实现某种功能。</li>\n<li>支持根据文件大小切割日志文件。</li>\n<li>支持日志按级别分类输出。</li>\n<li>支持V level。V level特性可以使开发者自定义日志级别。</li>\n<li>支持vmodule。vmodule可以使开发者对不同的文件使用不同的日志级别。</li>\n<li>支持traceLocation。traceLocation可以打印出指定位置的栈信息。</li>\n</ul><p>Kubernetes项目就使用了基于glog封装的klog，作为其日志库。</p><h3>logrus</h3><p><a href=\"https://github.com/sirupsen/logrus\">logrus</a>是目前GitHub上star数量最多的日志包，它的优点是功能强大、性能高效、高度灵活，还提供了自定义插件的功能。很多优秀的开源项目，例如Docker、Prometheus等，都使用了logrus。除了具有日志的基本功能外，logrus还具有如下特性：</p><ul>\n<li>支持常用的日志级别。logrus支持Debug、Info、Warn、Error、Fatal和Panic这些日志级别。</li>\n<li>可扩展。logrus的Hook机制允许使用者通过Hook的方式，将日志分发到任意地方，例如本地文件、标准输出、Elasticsearch、Logstash、Kafka等。</li>\n<li>支持自定义日志格式。logrus内置了JSONFormatter和TextFormatter两种格式。除此之外，logrus还允许使用者通过实现Formatter接口，来自定义日志格式。</li>\n<li>结构化日志记录。logrus的Field机制允许使用者自定义日志字段，而不是通过冗长的消息来记录日志。</li>\n<li>预设日志字段。logrus的Default Fields机制，可以给一部分或者全部日志统一添加共同的日志字段，例如给某次HTTP请求的所有日志添加X-Request-ID字段。</li>\n<li>Fatal handlers。logrus允许注册一个或多个handler，当产生Fatal级别的日志时调用。当我们的程序需要优雅关闭时，这个特性会非常有用。</li>\n</ul><h3>zap</h3><p><a href=\"https://github.com/uber-go/zap\">zap</a>是uber开源的日志包，以高性能著称，很多公司的日志包都是基于zap改造而来。除了具有日志基本的功能之外，zap还具有很多强大的特性：</p><ul>\n<li>支持常用的日志级别，例如：Debug、Info、Warn、Error、DPanic、Panic、Fatal。</li>\n<li>性能非常高。zap具有非常高的性能，适合对性能要求比较高的场景。</li>\n<li>支持针对特定的日志级别，输出调用堆栈。</li>\n<li>像logrus一样，zap也支持结构化的目录日志、预设日志字段，也因为支持Hook而具有可扩展性。</li>\n</ul><h3>开源日志包选择</h3><p>上面我介绍了很多日志包，每种日志包使用的场景不同，你可以根据自己的需求，结合日志包的特性进行选择：</p><ul>\n<li><strong>标准库log包：</strong> 标准库log包不支持日志级别、日志分割、日志格式等功能，所以在大型项目中很少直接使用，通常用于一些短小的程序，比如用于生成JWT Token的main.go文件中。标准库日志包也很适合一些简短的代码，用于快速调试和验证。</li>\n<li><strong>glog：</strong> glog实现了日志包的基本功能，非常适合一些对日志功能要求不多的小型项目。</li>\n<li><strong>logrus：</strong> logrus功能强大，不仅实现了日志包的基本功能，还有很多高级特性，适合一些大型项目，尤其是需要结构化日志记录的项目。</li>\n<li><strong>zap：</strong> zap提供了很强大的日志功能，性能高，内存分配次数少，适合对日志性能要求很高的项目。另外，zap包中的子包zapcore，提供了很多底层的日志接口，适合用来做二次封装。</li>\n</ul><p>举个我自己选择日志包来进行二次开发的例子：我在做容器云平台开发时，发现Kubernetes源码中大量使用了glog，这时就需要日志包能够兼容glog。于是，我基于zap和zapcore封装了<a href=\"https://github.com/marmotedu/iam/tree/master/pkg/log\">github.com/marmotedu/iam/pkg/log</a>日志包，这个日志包可以很好地兼容glog。</p><p>在实际项目开发中，你可以根据项目需要，从上面几个日志包中进行选择，直接使用，但更多时候，你还需要基于这些包来进行定制开发。为了使你更深入地掌握日志包的设计和开发，接下来，我会从0到1带你开发一个日志包。</p><h2>从0编写一个日志包</h2><p>接下来，我会向你展示如何快速编写一个具备基本功能的日志包，让你通过这个简短的日志包实现掌握日志包的核心设计思路。该日志包主要实现以下几个功能：</p><ul>\n<li>支持自定义配置。</li>\n<li>支持文件名和行号。</li>\n<li>支持日志级别  Debug、Info、Warn、Error、Panic、Fatal。</li>\n<li>支持输出到本地文件和标准输出。</li>\n<li>支持JSON和TEXT格式的日志输出，支持自定义日志格式。</li>\n<li>支持选项模式。</li>\n</ul><p>日志包名称为<code>cuslog</code>，示例项目完整代码存放在  <a href=\"https://github.com/marmotedu/gopractise-demo/tree/main/log/cuslog\">cuslog</a>。</p><p>具体实现分为以下四个步骤：</p><ol>\n<li>定义：定义日志级别和日志选项。</li>\n<li>创建：创建Logger及各级别日志打印方法。</li>\n<li>写入：将日志输出到支持的输出中。</li>\n<li>自定义：自定义日志输出格式。</li>\n</ol><h3>定义日志级别和日志选项</h3><p>一个基本的日志包，首先需要定义好日志级别和日志选项。本示例将定义代码保存在<a href=\"https://github.com/marmotedu/gopractise-demo/blob/main/log/cuslog/options.go\">options.go</a>文件中。</p><p>可以通过如下方式定义日志级别：</p><pre><code>type Level uint8\n\nconst (\n    DebugLevel Level = iota\n    InfoLevel\n    WarnLevel\n    ErrorLevel\n    PanicLevel\n    FatalLevel\n)\n\nvar LevelNameMapping = map[Level]string{\n    DebugLevel: &quot;DEBUG&quot;,\n    InfoLevel:  &quot;INFO&quot;,\n    WarnLevel:  &quot;WARN&quot;,\n    ErrorLevel: &quot;ERROR&quot;,\n    PanicLevel: &quot;PANIC&quot;,\n    FatalLevel: &quot;FATAL&quot;,\n}\n</code></pre><p>在日志输出时，要通过对比开关级别和输出级别的大小，来决定是否输出，所以日志级别Level要定义成方便比较的数值类型。几乎所有的日志包都是用常量计数器iota来定义日志级别。</p><p>另外，因为要在日志输出中，输出可读的日志级别（例如输出INFO而不是1），所以需要有Level到Level Name的映射LevelNameMapping，LevelNameMapping会在格式化时用到。</p><p>接下来看定义日志选项。日志需要是可配置的，方便开发者根据不同的环境设置不同的日志行为，比较常见的配置选项为：</p><ul>\n<li>日志级别。</li>\n<li>输出位置，例如标准输出或者文件。</li>\n<li>输出格式，例如JSON或者Text。</li>\n<li>是否开启文件名和行号。</li>\n</ul><p>本示例的日志选项定义如下：</p><pre><code>type options struct {\n    output        io.Writer\n    level         Level\n    stdLevel      Level\n    formatter     Formatter\n    disableCaller bool\n}\n</code></pre><p>为了灵活地设置日志的选项，你可以通过选项模式，来对日志选项进行设置：</p><pre><code>type Option func(*options)\n\nfunc initOptions(opts ...Option) (o *options) {\n    o = &amp;options{}\n    for _, opt := range opts {\n        opt(o)\n    }\n\n    if o.output == nil {\n        o.output = os.Stderr\n    }\n\n    if o.formatter == nil {\n        o.formatter = &amp;TextFormatter{}\n    }\n\n    return\n}\n\nfunc WithLevel(level Level) Option {\n    return func(o *options) {\n        o.level = level\n    }\n}\n...\nfunc SetOptions(opts ...Option) {\n    std.SetOptions(opts...)\n}\n\nfunc (l *logger) SetOptions(opts ...Option) {\n    l.mu.Lock()\n    defer l.mu.Unlock()\n\n    for _, opt := range opts {\n        opt(l.opt)\n    }\n}\n</code></pre><p>具有选项模式的日志包，可通过以下方式，来动态地修改日志的选项：</p><pre><code>cuslog.SetOptions(cuslog.WithLevel(cuslog.DebugLevel))\n</code></pre><p>你可以根据需要，对每一个日志选项创建设置函数 <code>WithXXXX</code>  。这个示例日志包支持如下选项设置函数：</p><ul>\n<li>WithOutput（output io.Writer）：设置输出位置。</li>\n<li>WithLevel（level Level）：设置输出级别。</li>\n<li>WithFormatter（formatter Formatter）：设置输出格式。</li>\n<li>WithDisableCaller（caller bool）：设置是否打印文件名和行号。</li>\n</ul><h3>创建Logger及各级别日志打印方法</h3><p>为了打印日志，我们需要根据日志配置，创建一个Logger，然后通过调用Logger的日志打印方法，完成各级别日志的输出。本示例将创建代码保存在<a href=\"https://github.com/marmotedu/gopractise-demo/blob/main/log/cuslog/logger.go\">logger.go</a>文件中。</p><p>可以通过如下方式创建Logger：</p><pre><code>var std = New()\n\ntype logger struct {\n    opt       *options\n    mu        sync.Mutex\n    entryPool *sync.Pool\n}\n\nfunc New(opts ...Option) *logger {\n    logger := &amp;logger{opt: initOptions(opts...)}\n    logger.entryPool = &amp;sync.Pool{New: func() interface{} { return entry(logger) }}\n    return logger\n}\n</code></pre><p>上述代码中，定义了一个Logger，并实现了创建Logger的New函数。日志包都会有一个默认的全局Logger，本示例通过 <code>var std = New()</code> 创建了一个全局的默认Logger。cuslog.Debug、cuslog.Info和cuslog.Warnf等函数，则是通过调用std Logger所提供的方法来打印日志的。</p><p>定义了一个Logger之后，还需要给该Logger添加最核心的日志打印方法，要提供所有支持级别的日志打印方法。</p><p>如果日志级别是Xyz，则通常需要提供两类方法，分别是非格式化方法<code>Xyz(args ...interface{})</code>和格式化方法<code>Xyzf(format string, args ...interface{})</code>，例如：</p><pre><code>func (l *logger) Debug(args ...interface{}) {\n    l.entry().write(DebugLevel, FmtEmptySeparate, args...)\n}\nfunc (l *logger) Debugf(format string, args ...interface{}) {\n    l.entry().write(DebugLevel, format, args...)\n}\n</code></pre><p>本示例实现了如下方法：Debug、Debugf、Info、Infof、Warn、Warnf、Error、Errorf、Panic、Panicf、Fatal、Fatalf。更详细的实现，你可以参考 <a href=\"https://github.com/marmotedu/gopractise-demo/blob/main/log/cuslog/logger.go\">cuslog/logger.go</a>。</p><p>这里要注意，Panic、Panicf要调用panic()函数，Fatal、Fatalf函数要调用 <code>os.Exit(1)</code> 函数。</p><h3>将日志输出到支持的输出中</h3><p>调用日志打印函数之后，还需要将这些日志输出到支持的输出中，所以需要实现write函数，它的写入逻辑保存在<a href=\"https://github.com/marmotedu/gopractise-demo/blob/main/log/cuslog/entry.go\">entry.go</a>文件中。实现方式如下：</p><pre><code>type Entry struct {\n    logger *logger\n    Buffer *bytes.Buffer\n    Map    map[string]interface{}\n    Level  Level\n    Time   time.Time\n    File   string\n    Line   int\n    Func   string\n    Format string\n    Args   []interface{}\n}\n\nfunc (e *Entry) write(level Level, format string, args ...interface{}) {\n    if e.logger.opt.level &gt; level {\n        return\n    }\n    e.Time = time.Now()\n    e.Level = level\n    e.Format = format\n    e.Args = args\n    if !e.logger.opt.disableCaller {\n        if pc, file, line, ok := runtime.Caller(2); !ok {\n            e.File = &quot;???&quot;\n            e.Func = &quot;???&quot;\n        } else {\n            e.File, e.Line, e.Func = file, line, runtime.FuncForPC(pc).Name()\n            e.Func = e.Func[strings.LastIndex(e.Func, &quot;/&quot;)+1:]\n        }\n    }\n    e.format()\n    e.writer()\n    e.release()\n}\n\nfunc (e *Entry) format() {\n    _ = e.logger.opt.formatter.Format(e)\n}\n\nfunc (e *Entry) writer() {\n    e.logger.mu.Lock()\n    _, _ = e.logger.opt.output.Write(e.Buffer.Bytes())\n    e.logger.mu.Unlock()\n}\n\nfunc (e *Entry) release() {\n    e.Args, e.Line, e.File, e.Format, e.Func = nil, 0, &quot;&quot;, &quot;&quot;, &quot;&quot;\n    e.Buffer.Reset()\n    e.logger.entryPool.Put(e)\n}\n</code></pre><p>上述代码，首先定义了一个Entry结构体类型，该类型用来保存所有的日志信息，即日志配置和日志内容。写入逻辑都是围绕Entry类型的实例来完成的。</p><p>用Entry的write方法来完成日志的写入，在write方法中，会首先判断日志的输出级别和开关级别，如果输出级别小于开关级别，则直接返回，不做任何记录。</p><p>在write中，还会判断是否需要记录文件名和行号，如果需要则调用 <code>runtime.Caller()</code> 来获取文件名和行号，调用 <code>runtime.Caller()</code> 时，要注意传入正确的栈深度。</p><p>write函数中调用 <code>e.format</code> 来格式化日志，调用 <code>e.writer</code> 来写入日志，在创建Logger传入的日志配置中，指定了输出位置 <code>output io.Writer</code> ，output类型为 <code>io.Writer</code>  ，示例如下：</p><pre><code>type Writer interface {\n    Write(p []byte) (n int, err error)\n}\n</code></pre><p>io.Writer实现了Write方法可供写入，所以只需要调用<code>e.logger.opt.output.Write(e.Buffer.Bytes())</code>即可将日志写入到指定的位置中。最后，会调用release()方法来清空缓存和对象池。至此，我们就完成了日志的记录和写入。</p><h3>自定义日志输出格式</h3><p>cuslog包支持自定义输出格式，并且内置了JSON和Text格式的Formatter。Formatter接口定义为：</p><pre><code>type Formatter interface {\n    Format(entry *Entry) error\n}\n</code></pre><p>cuslog内置的Formatter有两个：<a href=\"https://github.com/marmotedu/gopractise-demo/blob/main/log/cuslog/formatter_json.go\">JSON</a>和<a href=\"https://github.com/marmotedu/gopractise-demo/blob/main/log/cuslog/formatter_text.go\">TEXT</a>。</p><h3>测试日志包</h3><p>cuslog日志包开发完成之后，可以编写测试代码，调用cuslog包来测试cuslog包，代码如下：</p><pre><code>package main\n\nimport (\n    &quot;log&quot;\n    &quot;os&quot;\n\n    &quot;github.com/marmotedu/gopractise-demo/log/cuslog&quot;\n)\n\nfunc main() {\n    cuslog.Info(&quot;std log&quot;)\n    cuslog.SetOptions(cuslog.WithLevel(cuslog.DebugLevel))\n    cuslog.Debug(&quot;change std log to debug level&quot;)\n    cuslog.SetOptions(cuslog.WithFormatter(&amp;cuslog.JsonFormatter{IgnoreBasicFields: false}))\n    cuslog.Debug(&quot;log in json format&quot;)\n    cuslog.Info(&quot;another log in json format&quot;)\n\n    // 输出到文件\n    fd, err := os.OpenFile(&quot;test.log&quot;, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)\n    if err != nil {\n        log.Fatalln(&quot;create file test.log failed&quot;)\n    }\n    defer fd.Close()\n\n    l := cuslog.New(cuslog.WithLevel(cuslog.InfoLevel),\n        cuslog.WithOutput(fd),\n        cuslog.WithFormatter(&amp;cuslog.JsonFormatter{IgnoreBasicFields: false}),\n    )\n    l.Info(&quot;custom log with json formatter&quot;)\n}\n</code></pre><p>将上述代码保存在main.go文件中，运行：</p><pre><code>$ go run example.go\n2020-12-04T10:32:12+08:00 INFO example.go:11 std log\n2020-12-04T10:32:12+08:00 DEBUG example.go:13 change std log to debug level\n{&quot;file&quot;:&quot;/home/colin/workspace/golang/src/github.com/marmotedu/gopractise-demo/log/cuslog/example/example.go:15&quot;,&quot;func&quot;:&quot;main.main&quot;,&quot;message&quot;:&quot;log in json format&quot;,&quot;level&quot;:&quot;DEBUG&quot;,&quot;time&quot;:&quot;2020-12-04T10:32:12+08:00&quot;}\n{&quot;level&quot;:&quot;INFO&quot;,&quot;time&quot;:&quot;2020-12-04T10:32:12+08:00&quot;,&quot;file&quot;:&quot;/home/colin/workspace/golang/src/github.com/marmotedu/gopractise-demo/log/cuslog/example/example.go:16&quot;,&quot;func&quot;:&quot;main.main&quot;,&quot;message&quot;:&quot;another log in json format&quot;}\n</code></pre><p>到这里日志包就开发完成了，完整包见  <a href=\"https://github.com/marmotedu/gopractise-demo/tree/main/log/cuslog\">log/cuslog</a>。</p><h2>IAM项目日志包设计</h2><p>这一讲的最后，我们再来看下我们的IAM项目中，日志包是怎么设计的。</p><p>先来看一下IAM项目log包的存放位置：<a href=\"https://github.com/marmotedu/iam/tree/v1.0.0/pkg/log\">pkg/log</a>。放在这个位置，主要有两个原因：第一个，log包属于IAM项目，有定制开发的内容；第二个，log包功能完备、成熟，外部项目也可以使用。</p><p>该log包是基于 <code>go.uber.org/zap</code> 包封装而来的，根据需要添加了更丰富的功能。接下来，我们通过log包的<a href=\"https://github.com/marmotedu/iam/blob/master/pkg/log/options.go#L47\">Options</a>，来看下log包所实现的功能：</p><pre><code>type Options struct {\n    OutputPaths       []string `json:&quot;output-paths&quot;       mapstructure:&quot;output-paths&quot;`\n    ErrorOutputPaths  []string `json:&quot;error-output-paths&quot; mapstructure:&quot;error-output-paths&quot;`\n    Level             string   `json:&quot;level&quot;              mapstructure:&quot;level&quot;`\n    Format            string   `json:&quot;format&quot;             mapstructure:&quot;format&quot;`\n    DisableCaller     bool     `json:&quot;disable-caller&quot;     mapstructure:&quot;disable-caller&quot;`\n    DisableStacktrace bool     `json:&quot;disable-stacktrace&quot; mapstructure:&quot;disable-stacktrace&quot;`\n    EnableColor       bool     `json:&quot;enable-color&quot;       mapstructure:&quot;enable-color&quot;`\n    Development       bool     `json:&quot;development&quot;        mapstructure:&quot;development&quot;`\n    Name              string   `json:&quot;name&quot;               mapstructure:&quot;name&quot;`\n}\n</code></pre><p>Options各配置项含义如下：</p><ul>\n<li>development：是否是开发模式。如果是开发模式，会对DPanicLevel进行堆栈跟踪。</li>\n<li>name：Logger的名字。</li>\n<li>disable-caller：是否开启 caller，如果开启会在日志中显示调用日志所在的文件、函数和行号。</li>\n<li>disable-stacktrace：是否在Panic及以上级别禁止打印堆栈信息。</li>\n<li>enable-color：是否开启颜色输出，true，是；false，否。</li>\n<li>level：日志级别，优先级从低到高依次为：Debug, Info, Warn, Error, Dpanic, Panic, Fatal。</li>\n<li>format：支持的日志输出格式，目前支持Console和JSON两种。Console其实就是Text格式。</li>\n<li>output-paths：支持输出到多个输出，用逗号分开。支持输出到标准输出（stdout）和文件。</li>\n<li>error-output-paths：zap内部(非业务)错误日志输出路径，多个输出，用逗号分开。</li>\n</ul><p>log包的Options结构体支持以下3个方法：</p><ul>\n<li>Build方法。Build方法可以根据Options构建一个全局的Logger。</li>\n<li>AddFlags方法。AddFlags方法可以将Options的各个字段追加到传入的pflag.FlagSet变量中。</li>\n<li>String方法。String方法可以将Options的值以JSON格式字符串返回。</li>\n</ul><p>log包实现了以下3种日志记录方法：</p><pre><code>log.Info(&quot;This is a info message&quot;, log.Int32(&quot;int_key&quot;, 10))\nlog.Infof(&quot;This is a formatted %s message&quot;, &quot;info&quot;)\nlog.Infow(&quot;Message printed with Infow&quot;, &quot;X-Request-ID&quot;, &quot;fbf54504-64da-4088-9b86-67824a7fb508&quot;)\n</code></pre><p><code>Info</code> 使用指定的key/value记录日志。<code>Infof</code> 格式化记录日志。 <code>Infow</code> 也是使用指定的key/value记录日志，跟 <code>Info</code> 的区别是：使用 <code>Info</code> 需要指定值的类型，通过指定值的日志类型，日志库底层不需要进行反射操作，所以使用 <code>Info</code> 记录日志性能最高。</p><p>log包支持非常丰富的类型，具体你可以参考  <a href=\"https://github.com/marmotedu/iam/blob/master/pkg/log/types.go#L56\">types.go</a>。</p><p>上述日志输出为：</p><pre><code>2021-07-06 14:02:07.070 INFO This is a info message {&quot;int_key&quot;: 10}\n2021-07-06 14:02:07.071 INFO This is a formatted info message\n2021-07-06 14:02:07.071 INFO Message printed with Infow {&quot;X-Request-ID&quot;: &quot;fbf54504-64da-4088-9b86-67824a7fb508&quot;}\n</code></pre><p>log包为每种级别的日志都提供了3种日志记录方式，举个例子：假设日志格式为 <code>Xyz</code> ，则分别提供了 <code>Xyz(msg string, fields ...Field)</code> ，<code>Xyzf(format string, v ...interface{})</code> ，<code>Xyzw(msg string, keysAndValues ...interface{})</code> 3种日志记录方法。</p><p>另外，log包相较于一般的日志包，还提供了众多记录日志的方法。</p><p><strong>第一个方法，</strong> log包支持V Level，可以通过整型数值来灵活指定日志级别，数值越大，优先级越低。例如：</p><pre><code>// V level使用\nlog.V(1).Info(&quot;This is a V level message&quot;)\nlog.V(1).Infof(&quot;This is a %s V level message&quot;, &quot;formatted&quot;)\nlog.V(1).Infow(&quot;This is a V level message with fields&quot;, &quot;X-Request-ID&quot;, &quot;7a7b9f24-4cae-4b2a-9464-69088b45b904&quot;)\n</code></pre><p>这里要注意，Log.V只支持 <code>Info</code> 、<code>Infof</code> 、<code>Infow</code>三种日志记录方法。</p><p><strong>第二个方法，</strong> log包支持WithValues函数，例如：</p><pre><code>// WithValues使用\nlv := log.WithValues(&quot;X-Request-ID&quot;, &quot;7a7b9f24-4cae-4b2a-9464-69088b45b904&quot;)\nlv.Infow(&quot;Info message printed with [WithValues] logger&quot;)\nlv.Infow(&quot;Debug message printed with [WithValues] logger&quot;)\n</code></pre><p>上述日志输出如下：</p><pre><code>2021-07-06 14:15:28.555 INFO Info message printed with [WithValues] logger {&quot;X-Request-ID&quot;: &quot;7a7b9f24-4cae-4b2a-9464-69088b45b904&quot;}\n2021-07-06 14:15:28.556 INFO Debug message printed with [WithValues] logger {&quot;X-Request-ID&quot;: &quot;7a7b9f24-4cae-4b2a-9464-69088b45b904&quot;}\n</code></pre><p><code>WithValues</code> 可以返回一个携带指定key-value的Logger，供后面使用。</p><p><strong>第三个方法，</strong> log包提供 <code>WithContext</code> 和 <code>FromContext</code> 用来将指定的Logger添加到某个Context中，以及从某个Context中获取Logger，例如：</p><pre><code>// Context使用\nctx := lv.WithContext(context.Background())\nlc := log.FromContext(ctx)\nlc.Info(&quot;Message printed with [WithContext] logger&quot;)\n</code></pre><p><code>WithContext</code>和<code>FromContext</code>非常适合用在以<code>context.Context</code>传递的函数中，例如：</p><pre><code>func main() {\n \n    ...\n \n    // WithValues使用\n    lv := log.WithValues(&quot;X-Request-ID&quot;, &quot;7a7b9f24-4cae-4b2a-9464-69088b45b904&quot;)\n     \n    // Context使用\n    lv.Infof(&quot;Start to call pirntString&quot;)\n    ctx := lv.WithContext(context.Background())\n    pirntString(ctx, &quot;World&quot;)  \n}\n \nfunc pirntString(ctx context.Context, str string) {\n    lc := log.FromContext(ctx)\n    lc.Infof(&quot;Hello %s&quot;, str)\n}\n</code></pre><p>上述代码输出如下：</p><pre><code>2021-07-06 14:38:02.050 INFO Start to call pirntString {&quot;X-Request-ID&quot;: &quot;7a7b9f24-4cae-4b2a-9464-69088b45b904&quot;}\n2021-07-06 14:38:02.050 INFO Hello World {&quot;X-Request-ID&quot;: &quot;7a7b9f24-4cae-4b2a-9464-69088b45b904&quot;}\n</code></pre><p>将Logger添加到Context中，并通过Context在不同函数间传递，可以使key-value在不同函数间传递。例如上述代码中， <code>X-Request-ID</code> 在main函数、printString函数中的日志输出中均有记录，从而实现了一种调用链的效果。</p><p><strong>第四个方法，</strong> 可以很方便地从Context中提取出指定的key-value，作为上下文添加到日志输出中，例如  <a href=\"https://github.com/marmotedu/iam/blob/v1.0.0/internal/apiserver/api/v1/user/create.go#L20\">internal/apiserver/api/v1/user/create.go</a>文件中的日志调用：</p><pre><code>log.L(c).Info(&quot;user create function called.&quot;)\n</code></pre><p>通过调用 <code>Log.L()</code> 函数，实现如下：</p><pre><code>// L method output with specified context value.\nfunc L(ctx context.Context) *zapLogger {\n    return std.L(ctx)\n}\n \nfunc (l *zapLogger) L(ctx context.Context) *zapLogger {\n    lg := l.clone()\n \n    requestID, _ := ctx.Value(KeyRequestID).(string)\n    username, _ := ctx.Value(KeyUsername).(string)\n    lg.zapLogger = lg.zapLogger.With(zap.String(KeyRequestID, requestID), zap.String(KeyUsername, username))\n \n    return lg\n}\n</code></pre><p><code>L()</code> 方法会从传入的Context中提取出 <code>requestID</code> 和 <code>username</code> ，追加到Logger中，并返回Logger。这时候调用该Logger的Info、Infof、Infow等方法记录日志，输出的日志中均包含 <code>requestID</code> 和 <code>username</code> 字段，例如：</p><pre><code>2021-07-06 14:46:00.743 INFO    apiserver       secret/create.go:23     create secret function called.  {&quot;requestID&quot;: &quot;73144bed-534d-4f68-8e8d-dc8a8ed48507&quot;, &quot;username&quot;: &quot;admin&quot;}\n</code></pre><p>通过将Context在函数间传递，很容易就能实现调用链效果，例如：</p><pre><code>// Create add new secret key pairs to the storage.\nfunc (s *SecretHandler) Create(c *gin.Context) {\n    log.L(c).Info(&quot;create secret function called.&quot;)\n     \n    ...\n     \n    secrets, err := s.srv.Secrets().List(c, username, metav1.ListOptions{    \n        Offset: pointer.ToInt64(0),\n        Limit:  pointer.ToInt64(-1),\n    })\n     \n    ...\n     \n     if err := s.srv.Secrets().Create(c, &amp;r, metav1.CreateOptions{}); err != nil {\n        core.WriteResponse(c, err, nil)\n\n        return\n    }\n \n    core.WriteResponse(c, nil, r)\n}\n</code></pre><p>上述代码输出为：</p><pre><code>2021-07-06 14:46:00.743 INFO    apiserver       secret/create.go:23     create secret function called.  {&quot;requestID&quot;: &quot;73144bed-534d-4f68-8e8d-dc8a8ed48507&quot;, &quot;username&quot;: &quot;admin&quot;}\n2021-07-06 14:46:00.744 INFO    apiserver       secret/create.go:23     list secret from storage.  {&quot;requestID&quot;: &quot;73144bed-534d-4f68-8e8d-dc8a8ed48507&quot;, &quot;username&quot;: &quot;admin&quot;}\n2021-07-06 14:46:00.745 INFO    apiserver       secret/create.go:23     insert secret to storage.  {&quot;requestID&quot;: &quot;73144bed-534d-4f68-8e8d-dc8a8ed48507&quot;, &quot;username&quot;: &quot;admin&quot;}\n</code></pre><p>这里要注意， <code>log.L</code> 函数默认会从Context中取 <code>requestID</code> 和 <code>username</code> 键，这跟IAM项目有耦合度，但这不影响log包供第三方项目使用。这也是我建议你自己封装日志包的原因。</p><h2>总结</h2><p>开发一个日志包，我们很多时候需要基于一些业界优秀的开源日志包进行二次开发。当前很多项目的日志包都是基于zap日志包来封装的，如果你有封装的需要，我建议你优先选择zap日志包。</p><p>这一讲中，我先给你介绍了标准库log包、glog、logrus和zap这四种常用的日志包，然后向你展现了开发一个日志包的四个步骤，步骤如下：</p><ol>\n<li>定义日志级别和日志选项。</li>\n<li>创建Logger及各级别日志打印方法。</li>\n<li>将日志输出到支持的输出中。</li>\n<li>自定义日志输出格式。</li>\n</ol><p>最后，我介绍了IAM项目封装的log包的设计和使用方式。log包基于 <code>go.uber.org/zap</code>封装，并提供了以下强大特性：</p><ul>\n<li>log包支持V Level，可以灵活的通过整型数值来指定日志级别。</li>\n<li>log包支持 <code>WithValues</code> 函数， <code>WithValues</code> 可以返回一个携带指定key-value对的Logger，供后面使用。</li>\n<li>log包提供 <code>WithContext</code> 和 <code>FromContext</code> 用来将指定的Logger添加到某个Context中和从某个Context中获取Logger。</li>\n<li>log包提供了 <code>Log.L()</code> 函数，可以很方便的从Context中提取出指定的key-value对，作为上下文添加到日志输出中。</li>\n</ul><h2>课后练习</h2><ol>\n<li>\n<p>尝试实现一个新的Formatter，可以使不同日志级别以不同颜色输出（例如：Error级别的日志输出中 <code>Error</code> 字符串用红色字体输出， <code>Info</code> 字符串用白色字体输出）。</p>\n</li>\n<li>\n<p>尝试将<a href=\"https://github.com/marmotedu/gopractise-demo/blob/master/log/cuslog/entry.go#L36\">runtime.Caller(2)</a>函数调用中的 <code>2</code> 改成 <code>1</code> ，看看日志输出是否跟修改前有差异，如果有差异，思考差异产生的原因。</p>\n</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"20 | 日志处理（上）：如何设计日志包并记录日志？","id":393905},"right":{"article_title":"22 | 应用构建三剑客：Pflag、Viper、Cobra 核心功能介绍","id":395705}}},{"article_id":395705,"article_title":"22 | 应用构建三剑客：Pflag、Viper、Cobra 核心功能介绍","article_content":"<p>你好，我是孔令飞。这一讲我们来聊聊构建应用时常用的Go包。</p><p>因为IAM项目使用了Pflag、Viper和Cobra包来构建IAM的应用框架，为了让你后面学习更加容易，这里简单介绍下这3个包的核心功能和使用方式。其实如果单独讲每个包的话，还是有很多功能可讲的，但我们这一讲的目的是减小你后面学习IAM源码的难度，所以我会主要介绍跟IAM相关的功能。</p><p>在正式介绍这三个包之前，我们先来看下如何构建应用的框架。</p><h2>如何构建应用框架</h2><p>想知道如何构建应用框架，首先你要明白，一个应用框架包含哪些部分。在我看来，一个应用框架需要包含以下3个部分：</p><ul>\n<li>命令行参数解析：主要用来解析命令行参数，这些命令行参数可以影响命令的运行效果。</li>\n<li>配置文件解析：一个大型应用，通常具有很多参数，为了便于管理和配置这些参数，通常会将这些参数放在一个配置文件中，供程序读取并解析。</li>\n<li>应用的命令行框架：应用最终是通过命令来启动的。这里有3个需求点，一是命令需要具备Help功能，这样才能告诉使用者如何去使用；二是命令需要能够解析命令行参数和配置文件；三是命令需要能够初始化业务代码，并最终启动业务进程。也就是说，我们的命令需要具备框架的能力，来纳管这3个部分。</li>\n</ul><!-- [[[read_end]]] --><p>这3个部分的功能，你可以自己开发，也可以借助业界已有的成熟实现。跟之前的想法一样，我不建议你自己开发，更建议你采用业界已有的成熟实现。命令行参数可以通过<a href=\"https://github.com/spf13/pflag\">Pflag</a>来解析，配置文件可以通过<a href=\"https://github.com/spf13/viper\">Viper</a>来解析，应用的命令行框架则可以通过<a href=\"https://github.com/spf13/cobra\">Cobra</a>来实现。这3个包目前也是最受欢迎的包，并且这3个包不是割裂的，而是有联系的，我们可以有机地组合这3个包，从而实现一个非常强大、优秀的应用命令行框架。</p><p>接下来，我们就来详细看下，这3个包在Go项目开发中是如何使用的。</p><h2>命令行参数解析工具：Pflag使用介绍</h2><p>Go服务开发中，经常需要给开发的组件加上各种启动参数来配置服务进程，影响服务的行为。像kube-apiserver就有多达200多个启动参数，而且这些参数的类型各不相同（例如：string、int、ip类型等），使用方式也不相同（例如：需要支持<code>--</code>长选项，<code>-</code>短选项等），所以我们需要一个强大的命令行参数解析工具。</p><p>虽然Go源码中提供了一个标准库Flag包，用来对命令行参数进行解析，但在大型项目中应用更广泛的是另外一个包：Pflag。Pflag提供了很多强大的特性，非常适合用来构建大型项目，一些耳熟能详的开源项目都是用Pflag来进行命令行参数解析的，例如：Kubernetes、Istio、Helm、Docker、Etcd等。</p><p>接下来，我们就来介绍下如何使用Pflag。Pflag主要是通过创建Flag和FlagSet来使用的。我们先来看下Flag。</p><h3>Pflag包Flag定义</h3><p>Pflag可以对命令行参数进行处理，一个命令行参数在Pflag包中会解析为一个Flag类型的变量。Flag是一个结构体，定义如下：</p><pre><code>type Flag struct {\n    Name                string // flag长选项的名称\n    Shorthand           string // flag短选项的名称，一个缩写的字符\n    Usage               string // flag的使用文本\n    Value               Value  // flag的值\n    DefValue            string // flag的默认值\n    Changed             bool // 记录flag的值是否有被设置过\n    NoOptDefVal         string // 当flag出现在命令行，但是没有指定选项值时的默认值\n    Deprecated          string // 记录该flag是否被放弃\n    Hidden              bool // 如果值为true，则从help/usage输出信息中隐藏该flag\n    ShorthandDeprecated string // 如果flag的短选项被废弃，当使用flag的短选项时打印该信息\n    Annotations         map[string][]string // 给flag设置注解\n}\n</code></pre><p>Flag的值是一个Value类型的接口，Value定义如下：</p><pre><code>type Value interface {\n    String() string // 将flag类型的值转换为string类型的值，并返回string的内容\n    Set(string) error // 将string类型的值转换为flag类型的值，转换失败报错\n    Type() string // 返回flag的类型，例如：string、int、ip等\n}\n</code></pre><p>通过将Flag的值抽象成一个interface接口，我们就可以自定义Flag的类型了。只要实现了Value接口的结构体，就是一个新类型。</p><h3>Pflag包FlagSet定义</h3><p>Pflag除了支持单个的Flag之外，还支持FlagSet。FlagSet是一些预先定义好的Flag的集合，几乎所有的Pflag操作，都需要借助FlagSet提供的方法来完成。在实际开发中，我们可以使用两种方法来获取并使用FlagSet：</p><ul>\n<li>方法一，调用NewFlagSet创建一个FlagSet。</li>\n<li>方法二，使用Pflag包定义的全局FlagSet：CommandLine。实际上CommandLine也是由NewFlagSet函数创建的。</li>\n</ul><p>先来看下第一种方法，自定义FlagSet。下面是一个自定义FlagSet的示例：</p><pre><code>var version bool\nflagSet := pflag.NewFlagSet(&quot;test&quot;, pflag.ContinueOnError)\nflagSet.BoolVar(&amp;version, &quot;version&quot;, true, &quot;Print version information and quit.&quot;)\n</code></pre><p>我们可以通过定义一个新的FlagSet来定义命令及其子命令的Flag。</p><p>再来看下第二种方法，使用全局FlagSet。下面是一个使用全局FlagSet的示例：</p><pre><code>import (\n    &quot;github.com/spf13/pflag&quot;\n)\n\npflag.BoolVarP(&amp;version, &quot;version&quot;, &quot;v&quot;, true, &quot;Print version information and quit.&quot;)\n</code></pre><p>这其中，pflag.BoolVarP函数定义如下：</p><pre><code>func BoolVarP(p *bool, name, shorthand string, value bool, usage string) {\n    flag := CommandLine.VarPF(newBoolValue(value, p), name, shorthand, usage)\n    flag.NoOptDefVal = &quot;true&quot;\n}\n</code></pre><p>可以看到pflag.BoolVarP最终调用了CommandLine，CommandLine是一个包级别的变量，定义为：</p><pre><code>// CommandLine is the default set of command-line flags, parsed from os.Args.\nvar CommandLine = NewFlagSet(os.Args[0], ExitOnError)\n</code></pre><p>在一些不需要定义子命令的命令行工具中，我们可以直接使用全局的FlagSet，更加简单方便。</p><h3>Pflag使用方法</h3><p>上面，我们介绍了使用Pflag包的两个核心结构体。接下来，我来详细介绍下Pflag的常见使用方法。Pflag有很多强大的功能，我这里介绍7个常见的使用方法。</p><ol>\n<li>支持多种命令行参数定义方式。</li>\n</ol><p>Pflag支持以下4种命令行参数定义方式：</p><ul>\n<li>支持长选项、默认值和使用文本，并将标志的值存储在指针中。</li>\n</ul><pre><code>var name = pflag.String(&quot;name&quot;, &quot;colin&quot;, &quot;Input Your Name&quot;)\n</code></pre><ul>\n<li>支持长选项、短选项、默认值和使用文本，并将标志的值存储在指针中。</li>\n</ul><pre><code>var name = pflag.StringP(&quot;name&quot;, &quot;n&quot;, &quot;colin&quot;, &quot;Input Your Name&quot;)\n</code></pre><ul>\n<li>支持长选项、默认值和使用文本，并将标志的值绑定到变量。</li>\n</ul><pre><code>var name string\npflag.StringVar(&amp;name, &quot;name&quot;, &quot;colin&quot;, &quot;Input Your Name&quot;)\n</code></pre><ul>\n<li>支持长选项、短选项、默认值和使用文本，并将标志的值绑定到变量。</li>\n</ul><pre><code>var name string\npflag.StringVarP(&amp;name, &quot;name&quot;, &quot;n&quot;,&quot;colin&quot;, &quot;Input Your Name&quot;)\n</code></pre><p>上面的函数命名是有规则的：</p><ul>\n<li>函数名带<code>Var</code>说明是将标志的值绑定到变量，否则是将标志的值存储在指针中。</li>\n<li>函数名带<code>P</code>说明支持短选项，否则不支持短选项。</li>\n</ul><ol start=\"2\">\n<li>使用<code>Get&lt;Type&gt;</code>获取参数的值。</li>\n</ol><p>可以使用<code>Get&lt;Type&gt;</code>来获取标志的值，<code>&lt;Type&gt;</code>代表Pflag所支持的类型。例如：有一个pflag.FlagSet，带有一个名为flagname的int类型的标志，可以使用<code>GetInt()</code>来获取int值。需要注意flagname必须存在且必须是int，例如：</p><pre><code>i, err := flagset.GetInt(&quot;flagname&quot;)\n</code></pre><ol start=\"3\">\n<li>获取非选项参数。</li>\n</ol><p>代码示例如下：</p><pre><code>package main\n\nimport (\n    &quot;fmt&quot;\n\n    &quot;github.com/spf13/pflag&quot;\n)\n\nvar (\n    flagvar = pflag.Int(&quot;flagname&quot;, 1234, &quot;help message for flagname&quot;)\n)\n\nfunc main() {\n    pflag.Parse()\n\n    fmt.Printf(&quot;argument number is: %v\\n&quot;, pflag.NArg())\n    fmt.Printf(&quot;argument list is: %v\\n&quot;, pflag.Args())\n    fmt.Printf(&quot;the first argument is: %v\\n&quot;, pflag.Arg(0))\n}\n</code></pre><p>执行上述代码，输出如下：</p><pre><code>$ go run example1.go arg1 arg2\nargument number is: 2\nargument list is: [arg1 arg2]\nthe first argument is: arg1\n</code></pre><p>在定义完标志之后，可以调用<code>pflag.Parse()</code>来解析定义的标志。解析后，可通过<code>pflag.Args()</code>返回所有的非选项参数，通过<code>pflag.Arg(i)</code>返回第i个非选项参数。参数下标0到pflag.NArg() - 1。</p><ol start=\"4\">\n<li>指定了选项但是没有指定选项值时的默认值。</li>\n</ol><p>创建一个Flag后，可以为这个Flag设置<code>pflag.NoOptDefVal</code>。如果一个Flag具有NoOptDefVal，并且该Flag在命令行上没有设置这个Flag的值，则该标志将设置为NoOptDefVal指定的值。例如：</p><pre><code>var ip = pflag.IntP(&quot;flagname&quot;, &quot;f&quot;, 1234, &quot;help message&quot;)\npflag.Lookup(&quot;flagname&quot;).NoOptDefVal = &quot;4321&quot;\n</code></pre><p>上面的代码会产生结果，具体你可以参照下表：</p><p><img src=\"https://static001.geekbang.org/resource/image/fe/3f/fe76a52906c35b49b890225d1f5fc93f.png?wh=1428x336\" alt=\"图片\"></p><ol start=\"5\">\n<li>弃用标志或者标志的简写。</li>\n</ol><p>Pflag可以弃用标志或者标志的简写。弃用的标志或标志简写在帮助文本中会被隐藏，并在使用不推荐的标志或简写时打印正确的用法提示。例如，弃用名为logmode的标志，并告知用户应该使用哪个标志代替：</p><pre><code>// deprecate a flag by specifying its name and a usage message\npflag.CommandLine.MarkDeprecated(&quot;logmode&quot;, &quot;please use --log-mode instead&quot;)\n</code></pre><p>这样隐藏了帮助文本中的logmode，并且当使用logmode时，打印了<code>Flag --logmode has been deprecated, please use --log-mode instead</code>。</p><ol start=\"6\">\n<li>保留名为port的标志，但是弃用它的简写形式。</li>\n</ol><pre><code>pflag.IntVarP(&amp;port, &quot;port&quot;, &quot;P&quot;, 3306, &quot;MySQL service host port.&quot;)\n\n// deprecate a flag shorthand by specifying its flag name and a usage message\npflag.CommandLine.MarkShorthandDeprecated(&quot;port&quot;, &quot;please use --port only&quot;)\n</code></pre><p>这样隐藏了帮助文本中的简写P，并且当使用简写P时，打印了<code>Flag shorthand -P has been deprecated, please use --port only</code>。usage message在此处必不可少，并且不应为空。</p><ol start=\"7\">\n<li>隐藏标志。</li>\n</ol><p>可以将Flag标记为隐藏的，这意味着它仍将正常运行，但不会显示在usage/help文本中。例如：隐藏名为secretFlag的标志，只在内部使用，并且不希望它显示在帮助文本或者使用文本中。代码如下：</p><pre><code>// hide a flag by specifying its name\npflag.CommandLine.MarkHidden(&quot;secretFlag&quot;)\n</code></pre><p>至此，我们介绍了Pflag包的重要用法。接下来，我们再来看下如何解析配置文件。</p><h2>配置解析神器：Viper使用介绍</h2><p>几乎所有的后端服务，都需要一些配置项来配置我们的服务，一些小型的项目，配置不是很多，可以选择只通过命令行参数来传递配置。但是大型项目配置很多，通过命令行参数传递就变得很麻烦，不好维护。标准的解决方案是将这些配置信息保存在配置文件中，由程序启动时加载和解析。Go生态中有很多包可以加载并解析配置文件，目前最受欢迎的是Viper包。</p><p>Viper是Go应用程序现代化的、完整的解决方案，能够处理不同格式的配置文件，让我们在构建现代应用程序时，不必担心配置文件格式。Viper也能够满足我们对应用配置的各种需求。</p><p>Viper可以从不同的位置读取配置，不同位置的配置具有不同的优先级，高优先级的配置会覆盖低优先级相同的配置，按优先级从高到低排列如下：</p><ol>\n<li>通过viper.Set函数显示设置的配置</li>\n<li>命令行参数</li>\n<li>环境变量</li>\n<li>配置文件</li>\n<li>Key/Value存储</li>\n<li>默认值</li>\n</ol><p>这里需要注意，Viper配置键不区分大小写。</p><p>Viper有很多功能，最重要的两类功能是读入配置和读取配置，Viper提供不同的方式来实现这两类功能。接下来，我们就来详细介绍下Viper如何读入配置和读取配置。</p><h3>读入配置</h3><p>读入配置，就是将配置读入到Viper中，有如下读入方式：</p><ul>\n<li>设置默认的配置文件名。</li>\n<li>读取配置文件。</li>\n<li>监听和重新读取配置文件。</li>\n<li>从io.Reader读取配置。</li>\n<li>从环境变量读取。</li>\n<li>从命令行标志读取。</li>\n<li>从远程Key/Value存储读取。</li>\n</ul><p>这几个方法的具体读入方式，你可以看下面的展示。</p><ol>\n<li>设置默认值。</li>\n</ol><p>一个好的配置系统应该支持默认值。Viper支持对key设置默认值，当没有通过配置文件、环境变量、远程配置或命令行标志设置key时，设置默认值通常是很有用的，可以让程序在没有明确指定配置时也能够正常运行。例如：</p><pre><code>viper.SetDefault(&quot;ContentDir&quot;, &quot;content&quot;)\nviper.SetDefault(&quot;LayoutDir&quot;, &quot;layouts&quot;)\nviper.SetDefault(&quot;Taxonomies&quot;, map[string]string{&quot;tag&quot;: &quot;tags&quot;, &quot;category&quot;: &quot;categories&quot;})\n</code></pre><ol start=\"2\">\n<li>读取配置文件。</li>\n</ol><p>Viper可以读取配置文件来解析配置，支持JSON、TOML、YAML、YML、Properties、Props、Prop、HCL、Dotenv、Env格式的配置文件。Viper 支持搜索多个路径，并且默认不配置任何搜索路径，将默认决策留给应用程序。</p><p>以下是如何使用 Viper 搜索和读取配置文件的示例：</p><pre><code>package main\n\nimport (\n\t&quot;fmt&quot;\n\n\t&quot;github.com/spf13/pflag&quot;\n\t&quot;github.com/spf13/viper&quot;\n)\n\nvar (\n\tcfg  = pflag.StringP(&quot;config&quot;, &quot;c&quot;, &quot;&quot;, &quot;Configuration file.&quot;)\n\thelp = pflag.BoolP(&quot;help&quot;, &quot;h&quot;, false, &quot;Show this help message.&quot;)\n)\n\nfunc main() {\n\tpflag.Parse()\n\tif *help {\n\t\tpflag.Usage()\n\t\treturn\n\t}\n\n  // 从配置文件中读取配置\n\tif *cfg != &quot;&quot; {\n\t\tviper.SetConfigFile(*cfg)   // 指定配置文件名\n\t\tviper.SetConfigType(&quot;yaml&quot;) // 如果配置文件名中没有文件扩展名，则需要指定配置文件的格式，告诉viper以何种格式解析文件\n\t} else {\n\t\tviper.AddConfigPath(&quot;.&quot;)          // 把当前目录加入到配置文件的搜索路径中\n\t\tviper.AddConfigPath(&quot;$HOME/.iam&quot;) // 配置文件搜索路径，可以设置多个配置文件搜索路径\n\t\tviper.SetConfigName(&quot;config&quot;)     // 配置文件名称（没有文件扩展名）\n\t}\n\n\tif err := viper.ReadInConfig(); err != nil { // 读取配置文件。如果指定了配置文件名，则使用指定的配置文件，否则在注册的搜索路径中搜索\n\t\tpanic(fmt.Errorf(&quot;Fatal error config file: %s \\n&quot;, err))\n\t}\n\n\tfmt.Printf(&quot;Used configuration file is: %s\\n&quot;, viper.ConfigFileUsed())\n}\n</code></pre><p>Viper支持设置多个配置文件搜索路径，需要注意添加搜索路径的顺序，Viper会根据添加的路径顺序搜索配置文件，如果找到则停止搜索。如果调用SetConfigFile直接指定了配置文件名，并且配置文件名没有文件扩展名时，需要显式指定配置文件的格式，以使Viper能够正确解析配置文件。</p><p>如果通过搜索的方式查找配置文件，则需要注意，SetConfigName设置的配置文件名是不带扩展名的，在搜索时Viper会在文件名之后追加文件扩展名，并尝试搜索所有支持的扩展类型。</p><ol start=\"3\">\n<li>监听和重新读取配置文件。</li>\n</ol><p>Viper支持在运行时让应用程序实时读取配置文件，也就是热加载配置。可以通过WatchConfig函数热加载配置。在调用WatchConfig函数之前，需要确保已经添加了配置文件的搜索路径。另外，还可以为Viper提供一个回调函数，以便在每次发生更改时运行。这里我也给你个示例：</p><pre><code>viper.WatchConfig()\nviper.OnConfigChange(func(e fsnotify.Event) {\n   // 配置文件发生变更之后会调用的回调函数\n\tfmt.Println(&quot;Config file changed:&quot;, e.Name)\n})\n</code></pre><p>我不建议在实际开发中使用热加载功能，因为即使配置热加载了，程序中的代码也不一定会热加载。例如：修改了服务监听端口，但是服务没有重启，这时候服务还是监听在老的端口上，会造成不一致。<br>\n4) 设置配置值。</p><p>我们可以通过viper.Set()函数来显式设置配置：</p><pre><code>viper.Set(&quot;user.username&quot;, &quot;colin&quot;)\n</code></pre><ol start=\"5\">\n<li>使用环境变量。</li>\n</ol><p>Viper还支持环境变量，通过如下5个函数来支持环境变量：</p><ul>\n<li>AutomaticEnv()</li>\n<li>BindEnv(input …string) error</li>\n<li>SetEnvPrefix(in string)</li>\n<li>SetEnvKeyReplacer(r *strings.Replacer)</li>\n<li>AllowEmptyEnv(allowEmptyEnv bool)</li>\n</ul><p>这里要注意：Viper读取环境变量是区分大小写的。Viper提供了一种机制来确保Env变量是唯一的。通过使用SetEnvPrefix，可以告诉Viper在读取环境变量时使用前缀。BindEnv和AutomaticEnv都将使用此前缀。比如，我们设置了viper.SetEnvPrefix(“VIPER”)，当使用viper.Get(“apiversion”)时，实际读取的环境变量是<code>VIPER_APIVERSION</code>。</p><p>BindEnv需要一个或两个参数。第一个参数是键名，第二个是环境变量的名称，环境变量的名称区分大小写。如果未提供Env变量名，则Viper将假定Env变量名为：<code>环境变量前缀_键名全大写</code>。例如：前缀为VIPER，key为username，则Env变量名为<code>VIPER_USERNAME</code>。当显示提供Env变量名（第二个参数）时，它不会自动添加前缀。例如，如果第二个参数是ID，Viper将查找环境变量ID。</p><p>在使用Env变量时，需要注意的一件重要事情是：每次访问该值时都将读取它。Viper在调用BindEnv时不固定该值。</p><p>还有一个魔法函数SetEnvKeyReplacer，SetEnvKeyReplacer允许你使用strings.Replacer对象来重写Env键。如果你想在Get()调用中使用<code>-</code>或者<code>.</code>，但希望你的环境变量使用<code>_</code>分隔符，可以通过SetEnvKeyReplacer来实现。比如，我们设置了环境变量<code>USER_SECRET_KEY=bVix2WBv0VPfrDrvlLWrhEdzjLpPCNYb</code>，但我们想用<code>viper.Get(\"user.secret-key\")</code>，那我们就调用函数：</p><pre><code>viper.SetEnvKeyReplacer(strings.NewReplacer(&quot;.&quot;, &quot;_&quot;, &quot;-&quot;, &quot;_&quot;))\n</code></pre><p>上面的代码，在调用viper.Get()函数时，会用_替换<code>.</code>和<code>-</code>。默认情况下，空环境变量被认为是未设置的，并将返回到下一个配置源。若要将空环境变量视为已设置，可以使用AllowEmptyEnv方法。使用环境变量示例如下：</p><pre><code>// 使用环境变量\nos.Setenv(&quot;VIPER_USER_SECRET_ID&quot;, &quot;QLdywI2MrmDVjSSv6e95weNRvmteRjfKAuNV&quot;)\nos.Setenv(&quot;VIPER_USER_SECRET_KEY&quot;, &quot;bVix2WBv0VPfrDrvlLWrhEdzjLpPCNYb&quot;)\n\nviper.AutomaticEnv()                                             // 读取环境变量\nviper.SetEnvPrefix(&quot;VIPER&quot;)                                      // 设置环境变量前缀：VIPER_，如果是viper，将自动转变为大写。\nviper.SetEnvKeyReplacer(strings.NewReplacer(&quot;.&quot;, &quot;_&quot;, &quot;-&quot;, &quot;_&quot;)) // 将viper.Get(key) key字符串中'.'和'-'替换为'_'\nviper.BindEnv(&quot;user.secret-key&quot;)\nviper.BindEnv(&quot;user.secret-id&quot;, &quot;USER_SECRET_ID&quot;) // 绑定环境变量名到key\n</code></pre><ol start=\"6\">\n<li>使用标志。</li>\n</ol><p>Viper支持Pflag包，能够绑定key到Flag。与BindEnv类似，在调用绑定方法时，不会设置该值，但在访问它时会设置。对于单个标志，可以调用BindPFlag()进行绑定：</p><pre><code>viper.BindPFlag(&quot;token&quot;, pflag.Lookup(&quot;token&quot;)) // 绑定单个标志\n</code></pre><p>还可以绑定一组现有的pflags（pflag.FlagSet）：</p><pre><code>viper.BindPFlags(pflag.CommandLine)             //绑定标志集\n</code></pre><h3>读取配置</h3><p>Viper提供了如下方法来读取配置：</p><ul>\n<li>Get(key string) interface{}</li>\n<li>Get<code>&lt;Type&gt;</code>(key string) <code>&lt;Type&gt;</code></li>\n<li>AllSettings() map[string]interface{}</li>\n<li>IsSet(key string) : bool</li>\n</ul><p>每一个Get方法在找不到值的时候都会返回零值。为了检查给定的键是否存在，可以使用IsSet()方法。<code>&lt;Type&gt;</code>可以是Viper支持的类型，首字母大写：Bool、Float64、Int、IntSlice、String、StringMap、StringMapString、StringSlice、Time、Duration。例如：GetInt()。</p><p>常见的读取配置方法有以下几种。</p><ol>\n<li>访问嵌套的键。</li>\n</ol><p>例如，加载下面的JSON文件：</p><pre><code>{\n    &quot;host&quot;: {\n        &quot;address&quot;: &quot;localhost&quot;,\n        &quot;port&quot;: 5799\n    },\n    &quot;datastore&quot;: {\n        &quot;metric&quot;: {\n            &quot;host&quot;: &quot;127.0.0.1&quot;,\n            &quot;port&quot;: 3099\n        },\n        &quot;warehouse&quot;: {\n            &quot;host&quot;: &quot;198.0.0.1&quot;,\n            &quot;port&quot;: 2112\n        }\n    }\n}\n</code></pre><p>Viper可以通过传入<code>.</code>分隔的路径来访问嵌套字段：</p><pre><code>viper.GetString(&quot;datastore.metric.host&quot;) // (返回 &quot;127.0.0.1&quot;)\n</code></pre><p>如果<code>datastore.metric</code>被直接赋值覆盖（被Flag、环境变量、set()方法等等），那么<code>datastore.metric</code>的所有子键都将变为未定义状态，它们被高优先级配置级别覆盖了。</p><p>如果存在与分隔的键路径匹配的键，则直接返回其值。例如：</p><pre><code>{\n    &quot;datastore.metric.host&quot;: &quot;0.0.0.0&quot;,\n    &quot;host&quot;: {\n        &quot;address&quot;: &quot;localhost&quot;,\n        &quot;port&quot;: 5799\n    },\n    &quot;datastore&quot;: {\n        &quot;metric&quot;: {\n            &quot;host&quot;: &quot;127.0.0.1&quot;,\n            &quot;port&quot;: 3099\n        },\n        &quot;warehouse&quot;: {\n            &quot;host&quot;: &quot;198.0.0.1&quot;,\n            &quot;port&quot;: 2112\n        }\n    }\n}\n</code></pre><p>通过viper.GetString获取值：</p><pre><code>viper.GetString(&quot;datastore.metric.host&quot;) // 返回 &quot;0.0.0.0&quot;\n</code></pre><ol start=\"2\">\n<li>反序列化。</li>\n</ol><p>Viper可以支持将所有或特定的值解析到结构体、map等。可以通过两个函数来实现：</p><ul>\n<li>Unmarshal(rawVal interface{}) error</li>\n<li>UnmarshalKey(key string, rawVal interface{}) error</li>\n</ul><p>一个示例：</p><pre><code>type config struct {\n\tPort int\n\tName string\n\tPathMap string `mapstructure:&quot;path_map&quot;`\n}\n\nvar C config\n\nerr := viper.Unmarshal(&amp;C)\nif err != nil {\n\tt.Fatalf(&quot;unable to decode into struct, %v&quot;, err)\n}\n</code></pre><p>如果想要解析那些键本身就包含<code>.</code>(默认的键分隔符）的配置，则需要修改分隔符：</p><pre><code>v := viper.NewWithOptions(viper.KeyDelimiter(&quot;::&quot;))\n\nv.SetDefault(&quot;chart::values&quot;, map[string]interface{}{\n    &quot;ingress&quot;: map[string]interface{}{\n        &quot;annotations&quot;: map[string]interface{}{\n            &quot;traefik.frontend.rule.type&quot;:                 &quot;PathPrefix&quot;,\n            &quot;traefik.ingress.kubernetes.io/ssl-redirect&quot;: &quot;true&quot;,\n        },\n    },\n})\n\ntype config struct {\n\tChart struct{\n        Values map[string]interface{}\n    }\n}\n\nvar C config\n\nv.Unmarshal(&amp;C)\n</code></pre><p>Viper在后台使用<code>github.com/mitchellh/mapstructure</code>来解析值，其默认情况下使用<code>mapstructure tags</code>。当我们需要将Viper读取的配置反序列到我们定义的结构体变量中时，一定要使用mapstructure tags。</p><ol start=\"3\">\n<li>序列化成字符串。</li>\n</ol><p>有时候我们需要将Viper中保存的所有设置序列化到一个字符串中，而不是将它们写入到一个文件中，示例如下：</p><pre><code>import (\n    yaml &quot;gopkg.in/yaml.v2&quot;\n    // ...\n)\n\nfunc yamlStringSettings() string {\n    c := viper.AllSettings()\n    bs, err := yaml.Marshal(c)\n    if err != nil {\n        log.Fatalf(&quot;unable to marshal config to YAML: %v&quot;, err)\n    }\n    return string(bs)\n}\n</code></pre><h2>现代化的命令行框架：Cobra全解</h2><p>Cobra既是一个可以创建强大的现代CLI应用程序的库，也是一个可以生成应用和命令文件的程序。有许多大型项目都是用Cobra来构建应用程序的，例如 Kubernetes、Docker、etcd、Rkt、Hugo等。</p><p>Cobra建立在commands、arguments和flags结构之上。commands代表命令，arguments代表非选项参数，flags代表选项参数（也叫标志）。一个好的应用程序应该是易懂的，用户可以清晰地知道如何去使用这个应用程序。应用程序通常遵循如下模式：<code>APPNAME VERB NOUN --ADJECTIVE或者APPNAME COMMAND ARG --FLAG</code>，例如：</p><pre><code>git clone URL --bare # clone 是一个命令，URL是一个非选项参数，bare是一个选项参数\n</code></pre><p>这里，VERB代表动词，NOUN代表名词，ADJECTIVE代表形容词。</p><p>Cobra提供了两种方式来创建命令：Cobra命令和Cobra库。Cobra命令可以生成一个Cobra命令模板，而命令模板也是通过引用Cobra库来构建命令的。所以，这里我直接介绍如何使用Cobra库来创建命令。</p><h3>使用Cobra库创建命令</h3><p>如果要用Cobra库编码实现一个应用程序，需要首先创建一个空的main.go文件和一个rootCmd文件，之后可以根据需要添加其他命令。具体步骤如下：</p><ol>\n<li>创建rootCmd。</li>\n</ol><pre><code>$ mkdir -p newApp2 &amp;&amp; cd newApp2\n</code></pre><p>通常情况下，我们会将rootCmd放在文件cmd/root.go中。</p><pre><code>var rootCmd = &amp;cobra.Command{\n  Use:   &quot;hugo&quot;,\n  Short: &quot;Hugo is a very fast static site generator&quot;,\n  Long: `A Fast and Flexible Static Site Generator built with\n                love by spf13 and friends in Go.\n                Complete documentation is available at http://hugo.spf13.com`,\n  Run: func(cmd *cobra.Command, args []string) {\n    // Do Stuff Here\n  },\n}\n\nfunc Execute() {\n  if err := rootCmd.Execute(); err != nil {\n    fmt.Println(err)\n    os.Exit(1)\n  }\n}\n</code></pre><p>还可以在init()函数中定义标志和处理配置，例如cmd/root.go。</p><pre><code>import (\n  &quot;fmt&quot;\n  &quot;os&quot;\n\n  homedir &quot;github.com/mitchellh/go-homedir&quot;\n  &quot;github.com/spf13/cobra&quot;\n  &quot;github.com/spf13/viper&quot;\n)\n\nvar (\n    cfgFile     string\n\t  projectBase string\n    userLicense string\n)\n\nfunc init() {\n  cobra.OnInitialize(initConfig)\n  rootCmd.PersistentFlags().StringVar(&amp;cfgFile, &quot;config&quot;, &quot;&quot;, &quot;config file (default is $HOME/.cobra.yaml)&quot;)\n  rootCmd.PersistentFlags().StringVarP(&amp;projectBase, &quot;projectbase&quot;, &quot;b&quot;, &quot;&quot;, &quot;base project directory eg. github.com/spf13/&quot;)\n  rootCmd.PersistentFlags().StringP(&quot;author&quot;, &quot;a&quot;, &quot;YOUR NAME&quot;, &quot;Author name for copyright attribution&quot;)\n  rootCmd.PersistentFlags().StringVarP(&amp;userLicense, &quot;license&quot;, &quot;l&quot;, &quot;&quot;, &quot;Name of license for the project (can provide `licensetext` in config)&quot;)\n  rootCmd.PersistentFlags().Bool(&quot;viper&quot;, true, &quot;Use Viper for configuration&quot;)\n  viper.BindPFlag(&quot;author&quot;, rootCmd.PersistentFlags().Lookup(&quot;author&quot;))\n  viper.BindPFlag(&quot;projectbase&quot;, rootCmd.PersistentFlags().Lookup(&quot;projectbase&quot;))\n  viper.BindPFlag(&quot;useViper&quot;, rootCmd.PersistentFlags().Lookup(&quot;viper&quot;))\n  viper.SetDefault(&quot;author&quot;, &quot;NAME HERE &lt;EMAIL ADDRESS&gt;&quot;)\n  viper.SetDefault(&quot;license&quot;, &quot;apache&quot;)\n}\n\nfunc initConfig() {\n  // Don't forget to read config either from cfgFile or from home directory!\n  if cfgFile != &quot;&quot; {\n    // Use config file from the flag.\n    viper.SetConfigFile(cfgFile)\n  } else {\n    // Find home directory.\n    home, err := homedir.Dir()\n    if err != nil {\n      fmt.Println(err)\n      os.Exit(1)\n    }\n\n    // Search config in home directory with name &quot;.cobra&quot; (without extension).\n    viper.AddConfigPath(home)\n    viper.SetConfigName(&quot;.cobra&quot;)\n  }\n\n  if err := viper.ReadInConfig(); err != nil {\n    fmt.Println(&quot;Can't read config:&quot;, err)\n    os.Exit(1)\n  }\n}\n</code></pre><ol start=\"2\">\n<li>创建main.go。</li>\n</ol><p>我们还需要一个main函数来调用rootCmd，通常我们会创建一个main.go文件，在main.go中调用rootCmd.Execute()来执行命令：</p><pre><code>package main\n\nimport (\n  &quot;{pathToYourApp}/cmd&quot;\n)\n\nfunc main() {\n  cmd.Execute()\n}\n</code></pre><p>需要注意，main.go中不建议放很多代码，通常只需要调用cmd.Execute()即可。</p><ol start=\"3\">\n<li>添加命令。</li>\n</ol><p>除了rootCmd，我们还可以调用AddCommand添加其他命令，通常情况下，我们会把其他命令的源码文件放在cmd/目录下，例如，我们添加一个version命令，可以创建cmd/version.go文件，内容为：</p><pre><code>package cmd\n\nimport (\n  &quot;fmt&quot;\n\n  &quot;github.com/spf13/cobra&quot;\n)\n\nfunc init() {\n  rootCmd.AddCommand(versionCmd)\n}\n\nvar versionCmd = &amp;cobra.Command{\n  Use:   &quot;version&quot;,\n  Short: &quot;Print the version number of Hugo&quot;,\n  Long:  `All software has versions. This is Hugo's`,\n  Run: func(cmd *cobra.Command, args []string) {\n    fmt.Println(&quot;Hugo Static Site Generator v0.9 -- HEAD&quot;)\n  },\n}\n</code></pre><p>本示例中，我们通过调用<code>rootCmd.AddCommand(versionCmd)</code>给rootCmd命令添加了一个versionCmd命令。</p><ol start=\"4\">\n<li>编译并运行。</li>\n</ol><p>将main.go中<code>{pathToYourApp}</code>替换为对应的路径，例如本示例中pathToYourApp为<code>github.com/marmotedu/gopractise-demo/cobra/newApp2</code>。</p><pre><code>$ go mod init github.com/marmotedu/gopractise-demo/cobra/newApp2\n$ go build -v .\n$ ./newApp2 -h\nA Fast and Flexible Static Site Generator built with\nlove by spf13 and friends in Go.\nComplete documentation is available at http://hugo.spf13.com\n \nUsage:\nhugo [flags]\nhugo [command]\n \nAvailable Commands:\nhelp Help about any command\nversion Print the version number of Hugo\n \nFlags:\n-a, --author string Author name for copyright attribution (default &quot;YOUR NAME&quot;)\n--config string config file (default is $HOME/.cobra.yaml)\n-h, --help help for hugo\n-l, --license licensetext Name of license for the project (can provide licensetext in config)\n-b, --projectbase string base project directory eg. github.com/spf13/\n--viper Use Viper for configuration (default true)\n \nUse &quot;hugo [command] --help&quot; for more information about a command.\n</code></pre><p>通过步骤一、步骤二、步骤三，我们就成功创建和添加了Cobra应用程序及其命令。</p><p>接下来，我再来详细介绍下Cobra的核心特性。</p><h3>使用标志</h3><p>Cobra可以跟Pflag结合使用，实现强大的标志功能。使用步骤如下：</p><ol>\n<li>使用持久化的标志。</li>\n</ol><p>标志可以是“持久的”，这意味着该标志可用于它所分配的命令以及该命令下的每个子命令。可以在rootCmd上定义持久标志：</p><pre><code>rootCmd.PersistentFlags().BoolVarP(&amp;Verbose, &quot;verbose&quot;, &quot;v&quot;, false, &quot;verbose output&quot;)\n</code></pre><ol start=\"2\">\n<li>使用本地标志。</li>\n</ol><p>也可以分配一个本地标志，本地标志只能在它所绑定的命令上使用：</p><pre><code>rootCmd.Flags().StringVarP(&amp;Source, &quot;source&quot;, &quot;s&quot;, &quot;&quot;, &quot;Source directory to read from&quot;)\n</code></pre><p><code>--source</code>标志只能在rootCmd上引用，而不能在rootCmd的子命令上引用。</p><ol start=\"3\">\n<li>将标志绑定到Viper。</li>\n</ol><p>我们可以将标志绑定到Viper，这样就可以使用viper.Get()获取标志的值。</p><pre><code>var author string\n\nfunc init() {\n  rootCmd.PersistentFlags().StringVar(&amp;author, &quot;author&quot;, &quot;YOUR NAME&quot;, &quot;Author name for copyright attribution&quot;)\n  viper.BindPFlag(&quot;author&quot;, rootCmd.PersistentFlags().Lookup(&quot;author&quot;))\n}\n</code></pre><ol start=\"4\">\n<li>设置标志为必选。</li>\n</ol><p>默认情况下，标志是可选的，我们也可以设置标志为必选，当设置标志为必选，但是没有提供标志时，Cobra会报错。</p><pre><code>rootCmd.Flags().StringVarP(&amp;Region, &quot;region&quot;, &quot;r&quot;, &quot;&quot;, &quot;AWS region (required)&quot;)\nrootCmd.MarkFlagRequired(&quot;region&quot;)\n</code></pre><h3>非选项参数验证</h3><p>在命令的过程中，经常会传入非选项参数，并且需要对这些非选项参数进行验证，Cobra提供了机制来对非选项参数进行验证。可以使用Command的Args字段来验证非选项参数。Cobra也内置了一些验证函数：</p><ul>\n<li>NoArgs：如果存在任何非选项参数，该命令将报错。</li>\n<li>ArbitraryArgs：该命令将接受任何非选项参数。</li>\n<li>OnlyValidArgs：如果有任何非选项参数不在Command的ValidArgs字段中，该命令将报错。</li>\n<li>MinimumNArgs(int)：如果没有至少N个非选项参数，该命令将报错。</li>\n<li>MaximumNArgs(int)：如果有多于N个非选项参数，该命令将报错。</li>\n<li>ExactArgs(int)：如果非选项参数个数不为N，该命令将报错。</li>\n<li>ExactValidArgs(int)：如果非选项参数的个数不为N，或者非选项参数不在Command的ValidArgs字段中，该命令将报错。</li>\n<li>RangeArgs(min, max)：如果非选项参数的个数不在min和max之间，该命令将报错。</li>\n</ul><p>使用预定义验证函数，示例如下：</p><pre><code>var cmd = &amp;cobra.Command{\n  Short: &quot;hello&quot;,\n  Args: cobra.MinimumNArgs(1), // 使用内置的验证函数\n  Run: func(cmd *cobra.Command, args []string) {\n    fmt.Println(&quot;Hello, World!&quot;)\n  },\n}\n</code></pre><p>当然你也可以自定义验证函数，示例如下：</p><pre><code>var cmd = &amp;cobra.Command{\n  Short: &quot;hello&quot;,\n  // Args: cobra.MinimumNArgs(10), // 使用内置的验证函数\n  Args: func(cmd *cobra.Command, args []string) error { // 自定义验证函数\n    if len(args) &lt; 1 {\n      return errors.New(&quot;requires at least one arg&quot;)\n    }\n    if myapp.IsValidColor(args[0]) {\n      return nil\n    }\n    return fmt.Errorf(&quot;invalid color specified: %s&quot;, args[0])\n  },\n  Run: func(cmd *cobra.Command, args []string) {\n    fmt.Println(&quot;Hello, World!&quot;)\n  },\n}\n</code></pre><h3>PreRun and PostRun Hooks</h3><p>在运行Run函数时，我们可以运行一些钩子函数，比如PersistentPreRun和PreRun函数在Run函数之前执行，PersistentPostRun和PostRun在Run函数之后执行。如果子命令没有指定<code>Persistent*Run</code>函数，则子命令将会继承父命令的<code>Persistent*Run</code>函数。这些函数的运行顺序如下：</p><ol>\n<li>PersistentPreRun</li>\n<li>PreRun</li>\n<li>Run</li>\n<li>PostRun</li>\n<li>PersistentPostRun</li>\n</ol><p>注意，父级的PreRun只会在父级命令运行时调用，子命令是不会调用的。</p><p>Cobra还支持很多其他有用的特性，比如：自定义Help命令；可以自动添加<code>--version</code>标志，输出程序版本信息；当用户提供无效标志或无效命令时，Cobra可以打印出usage信息；当我们输入的命令有误时，Cobra会根据注册的命令，推算出可能的命令，等等。</p><h2>总结</h2><p>在开发Go项目时，我们可以通过Pflag来解析命令行参数，通过Viper来解析配置文件，用Cobra来实现命令行框架。你可以通过pflag.String()、 pflag.StringP()、pflag.StringVar()、pflag.StringVarP()方法来设置命令行参数，并使用Get<code>&lt;Type&gt;</code>来获取参数的值。</p><p>同时，你也可以使用Viper从命令行参数、环境变量、配置文件等位置读取配置项。最常用的是从配置文件中读取，可以通过viper.AddConfigPath来设置配置文件搜索路径，通过viper.SetConfigFile和viper.SetConfigType来设置配置文件名，通过viper.ReadInConfig来读取配置文件。读取完配置文件，然后在程序中使用Get/Get<code>&lt;Type&gt;</code>来读取配置项的值。</p><p>最后，你可以使用Cobra来构建一个命令行框架，Cobra可以很好地集成Pflag和Viper。</p><h2>课后练习</h2><ol>\n<li>\n<p>研究下Cobra的代码，看下Cobra是如何跟Pflag和Viper进行集成的。</p>\n</li>\n<li>\n<p>思考下，除了Pflag、Viper、Cobra，你在开发过程中还遇到哪些优秀的包，来处理命令行参数、配置文件和启动命令行框架的呢？欢迎在留言区分享。</p>\n</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见！</p>","neighbors":{"left":{"article_title":"21 | 日志处理（下）：手把手教你从 0 编写一个日志包","id":394633},"right":{"article_title":"23 | 应用构建实战：如何构建一个优秀的企业应用框架？","id":396523}}},{"article_id":396523,"article_title":"23 | 应用构建实战：如何构建一个优秀的企业应用框架？","article_content":"<p>你好，我是孔令飞。今天我们来聊聊开发应用必须要做的那些事儿。</p><p>应用开发是软件开发工程师最核心的工作。在我这 7 年的 Go 开发生涯中，我构建了大大小小不下 50 个后端应用，深谙其中的痛点，比如：</p><ul>\n<li>重复造轮子。同样的功能却每次都要重新开发，浪费非常多的时间和精力不说，每次实现的代码质量更是参差不齐。</li>\n<li>理解成本高。相同的功能，有 N 个服务对应着 N 种不同的实现方式，如果功能升级，或者有新成员加入，都可能得重新理解 N 次。</li>\n<li>功能升级的开发工作量大。一个应用由 N 个服务组成，如果要升级其中的某个功能，你需要同时更新 N 个服务的代码。</li>\n</ul><p>想要解决上面这些问题，一个比较好的思路是：<strong>找出相同的功能，然后用一种优雅的方式去实现它，并通过 Go 包的形式，供所有的服务使用。</strong></p><p>如果你也面临这些问题，并且正在寻找解决方法，那么你可以认真学习今天这一讲。我会带你找出服务的通用功能，并给出优雅的构建方式，帮助你一劳永逸地解决这些问题。在提高开发效率的同时，也能提高你的代码质量。</p><p>接下来，我们先来分析并找出 Go 服务通用的功能。</p><h2>构建应用的基础：应用的三大基本功能</h2><p>我们目前见到的 Go 后端服务，基本上可以分为 API 服务和非 API 服务两类。</p><ul>\n<li>API 服务：通过对外提供 HTTP/RPC 接口来完成指定的功能。比如订单服务，通过调用创建订单的 API 接口，来创建商品订单。</li>\n<li>非 API 服务：通过监听、定时运行等方式，而不是通过 API 调用来完成某些任务。比如数据处理服务，定时从 Redis 中获取数据，处理后存入后端存储中。再比如消息处理服务，监听消息队列（如 NSQ/Kafka/RabbitMQ），收到消息后进行处理。</li>\n</ul><!-- [[[read_end]]] --><p>对于 API 服务和非 API 服务来说，它们的启动流程基本一致，都可以分为三步：</p><ol>\n<li>应用框架的构建，这是最基础的一步。</li>\n<li>应用初始化。</li>\n<li>服务启动。</li>\n</ol><p>如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/2a/9e/2a4ef770df3df2439ae595ef301e4d9e.png?wh=3075x1819\" alt=\"\"></p><p>图中，命令行程序、命令行参数解析和配置文件解析，是所有服务都需要具备的功能，这些功能有机结合到一起，共同构成了应用框架。</p><p>所以，我们要构建的任何一个应用程序，至少要具备命令行程序、命令行参数解析和配置文件解析这 3 种功能。</p><ul>\n<li><strong>命令行程序</strong>：用来启动一个应用。命令行程序需要实现诸如应用描述、help、参数校验等功能。根据需要，还可以实现命令自动补全、打印命令行参数等高级功能。</li>\n<li><strong>命令行参数解析</strong>：用来在启动时指定应用程序的命令行参数，以控制应用的行为。</li>\n<li><strong>配置文件解析</strong>：用来解析不同格式的配置文件。</li>\n</ul><p>另外，上述 3 类功能跟业务关系不大，可以抽象成一个统一的框架。应用初始化、创建 API/非 API 服务、启动服务，跟业务联系比较紧密，难以抽象成一个统一的框架。</p><h2>iam-apiserver 是如何构建应用框架的？</h2><p>这里，我通过讲解 iam-apiserver 的应用构建方式，来给你讲解下如何构建应用。iam-apiserver 程序的 main 函数位于 <a href=\"https://github.com/marmotedu/iam/blob/master/cmd/iam-apiserver/apiserver.go\">apiserver.go</a> 文件中，其构建代码可以简化为：</p><pre><code>import (\n    ...\n    &quot;github.com/marmotedu/iam/internal/apiserver&quot;\n    &quot;github.com/marmotedu/iam/pkg/app&quot;\n)\n\nfunc main() {\n    ...\n    apiserver.NewApp(&quot;iam-apiserver&quot;).Run()\n}\n\nconst commandDesc = `The IAM API server validates and configures data ...`\n\n// NewApp creates a App object with default parameters.\nfunc NewApp(basename string) *app.App {\n    opts := options.NewOptions()\n    application := app.NewApp(&quot;IAM API Server&quot;,\n        basename,\n        app.WithOptions(opts),\n        app.WithDescription(commandDesc),\n        app.WithDefaultValidArgs(),\n        app.WithRunFunc(run(opts)),\n    )\n\n    return application\n}\n\nfunc run(opts *options.Options) app.RunFunc {\n    return func(basename string) error {\n        log.Init(opts.Log)\n        defer log.Flush()\n\n        cfg, err := config.CreateConfigFromOptions(opts)\n        if err != nil {\n            return err\n        }\n\n        return Run(cfg)\n    }\n}\n</code></pre><p>可以看到，我们是通过调用包 <code>github.com/marmotedu/iam/pkg/app</code> 来构建应用的。也就是说，我们将构建应用的功能抽象成了一个 Go 包，通过 Go 包可以提高代码的封装性和复用性。iam-authz-server 和 iam-pump 组件也都是通过 <code>github.com/marmotedu/iam/pkg/app</code> 来构建应用的。</p><p>构建应用的流程也很简单，只需要创建一个 application 实例即可：</p><pre><code>opts := options.NewOptions()\napplication := app.NewApp(&quot;IAM API Server&quot;,\n    basename,\n    app.WithOptions(opts),\n    app.WithDescription(commandDesc),\n    app.WithDefaultValidArgs(),\n    app.WithRunFunc(run(opts)),\n)\n</code></pre><p>在创建应用实例时，我传入了下面这些参数。</p><ul>\n<li>IAM API Server：应用的简短描述。</li>\n<li>basename：应用的二进制文件名。</li>\n<li>opts：应用的命令行选项。</li>\n<li>commandDesc：应用的详细描述。</li>\n<li>run(opts)：应用的启动函数，初始化应用，并最终启动 HTTP 和 GRPC Web 服务。</li>\n</ul><p>创建应用时，你还可以根据需要来配置应用实例，比如 iam-apiserver 组件在创建应用时，指定了 <code>WithDefaultValidArgs</code> 来校验命令行非选项参数的默认校验逻辑。</p><p>可以看到，iam-apiserver 通过简单的几行代码，就创建出了一个应用。之所以这么方便，是因为应用框架的构建代码都封装在了 <code>github.com/marmotedu/iam/pkg/app</code> 包中。接下来，我们来重点看下 <code>github.com/marmotedu/iam/pkg/app</code> 包是如何实现的。为了方便描述，我在下文中统称为 App 包。</p><h2>App 包设计和实现</h2><p>我们先来看下 App 包目录下的文件：</p><pre><code>[colin@dev iam]$ ls pkg/app/\napp.go  cmd.go  config.go  doc.go  flag.go  help.go  options.go\n</code></pre><p><code>pkg/app</code> 目录下的 5 个主要文件是 app.go、cmd.go、config.go、flag.go、options.go，分别实现了应用程序框架中的应用、命令行程序、命令行参数解析、配置文件解析和命令行选项 5 个部分，具体关系如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/ea/12/ea3a0e20854b23fce7a654ce5f207512.png?wh=2378x828\" alt=\"\"></p><p>我再来解释下这张图。应用由命令行程序、命令行参数解析、配置文件解析三部分组成，命令行参数解析功能通过命令行选项来构建，二者通过接口解耦合：</p><pre><code>type CliOptions interface {    \n    // AddFlags adds flags to the specified FlagSet object.    \n    // AddFlags(fs *pflag.FlagSet)    \n    Flags() (fss cliflag.NamedFlagSets)    \n    Validate() []error    \n}    \n</code></pre><p>通过接口，应用可以定制自己独有的命令行参数。接下来，我们再来看下如何具体构建应用的每一部分。</p><h3>第 1 步：构建应用</h3><p>APP 包提供了 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/pkg/app/app.go#L157\">NewApp</a> 函数来创建一个应用：</p><pre><code>func NewApp(name string, basename string, opts ...Option) *App {\n    a := &amp;App{\n        name:     name,\n        basename: basename,\n    }\n \n    for _, o := range opts {\n        o(a)\n    }\n \n    a.buildCommand()\n \n    return a\n}\n</code></pre><p>NewApp 中使用了设计模式中的选项模式，来动态地配置 APP，支持 WithRunFunc、WithDescription、WithValidArgs 等选项。</p><h3>第 2 步：命令行程序构建</h3><p>这一步，我们会使用 Cobra 包来构建应用的命令行程序。</p><p>NewApp 最终会调用 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/pkg/app/app.go#L172\">buildCommand</a> 方法来创建 Cobra Command 类型的命令，命令的功能通过指定 Cobra Command 类型的各个字段来实现。通常可以指定：Use、Short、Long、SilenceUsage、SilenceErrors、RunE、Args 等字段。</p><p>在 buildCommand 函数中，也会根据应用的设置添加不同的命令行参数，例如：</p><pre><code>if !a.noConfig {\n    addConfigFlag(a.basename, namedFlagSets.FlagSet(&quot;global&quot;))\n} \n</code></pre><p>上述代码的意思是：如果我们设置了 <code>noConfig=false</code>，那么就会在命令行参数 global 分组中添加以下命令行选项：</p><pre><code>-c, --config FILE                                                        Read configuration from specified FILE, support JSON, TOML, YAML, HCL, or Java properties formats.\n</code></pre><p>为了更加易用和人性化，命令还具有如下 3 个功能。</p><ul>\n<li>帮助信息：执行 <code>-h/--help</code> 时，输出的帮助信息。通过 <code>cmd.SetHelpFunc</code> 函数可以指定帮助信息。</li>\n<li>使用信息（可选）：当用户提供无效的标志或命令时，向用户显示“使用信息”。通过 <code>cmd.SetUsageFunc</code> 函数，可以指定使用信息。如果不想每次输错命令打印一大堆 usage 信息，你可以通过设置 <code>SilenceUsage: true</code> 来关闭掉 usage。</li>\n<li>版本信息：打印应用的版本。知道应用的版本号，对故障排查非常有帮助。通过 <code>verflag.AddFlags</code> 可以指定版本信息。例如，App 包通过 <code>github.com/marmotedu/component-base/pkg/version</code> 指定了以下版本信息：</li>\n</ul><pre><code>$ ./iam-apiserver --version\n  gitVersion: v0.3.0\n   gitCommit: ccc31e292f66e6bad94efb1406b5ced84e64675c\ngitTreeState: dirty\n   buildDate: 2020-12-17T12:24:37Z\n   goVersion: go1.15.1\n    compiler: gc\n    platform: linux/amd64\n$ ./iam-apiserver --version=raw\nversion.Info{GitVersion:&quot;v0.3.0&quot;, GitCommit:&quot;ccc31e292f66e6bad94efb1406b5ced84e64675c&quot;, GitTreeState:&quot;dirty&quot;, BuildDate:&quot;2020-12-17T12:24:37Z&quot;, GoVersion:&quot;go1.15.1&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux/amd64&quot;}\n</code></pre><p>接下来，再来看下应用需要实现的另外一个重要功能，也就是命令行参数解析。</p><h3>第 3 步：命令行参数解析</h3><p>App 包在构建应用和执行应用两个阶段来实现命令行参数解析。</p><p><strong>我们先看构建应用这个阶段。</strong>App 包在 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/pkg/app/app.go#L172\">buildCommand</a> 方法中通过以下代码段，给应用添加了命令行参数：</p><pre><code>var namedFlagSets cliflag.NamedFlagSets\nif a.options != nil {\n    namedFlagSets = a.options.Flags()\n    fs := cmd.Flags()\n    for _, f := range namedFlagSets.FlagSets {\n        fs.AddFlagSet(f)\n    }\n \n    ...\n}\n \nif !a.noVersion {\n    verflag.AddFlags(namedFlagSets.FlagSet(&quot;global&quot;))\n}\nif !a.noConfig {\n    addConfigFlag(a.basename, namedFlagSets.FlagSet(&quot;global&quot;))\n}\nglobalflag.AddGlobalFlags(namedFlagSets.FlagSet(&quot;global&quot;), cmd.Name())\n</code></pre><p>namedFlagSets 中引用了 Pflag 包，上述代码先通过 <code>a.options.Flags()</code> 创建并返回了一批 FlagSet，<code>a.options.Flags()</code> 函数会将 FlagSet 进行分组。通过一个 for 循环，将 namedFlagSets 中保存的 FlagSet 添加到 Cobra 应用框架中的 FlagSet 中。</p><p>buildCommand 还会根据应用的配置，选择性添加一些 flag。例如，在 global 分组下添加 <code>--version</code> 和 <code>--config</code> 选项。</p><p>执行 <code>-h</code> 打印命令行参数如下：</p><pre><code>..\n \nUsage:\n  iam-apiserver [flags]\n \nGeneric flags:\n \n      --server.healthz               Add self readiness check and install /healthz router. (default true)\n      --server.max-ping-count int    The max number of ping attempts when server failed to startup. (default 3)\n \n...\n \nGlobal flags:\n \n  -h, --help                     help for iam-apiserver\n      --version version[=true]   Print version information and quit.\n</code></pre><p>这里有两个技巧，你可以借鉴。</p><p>第一个技巧，<strong>将 flag 分组</strong>。</p><p>一个大型系统，可能会有很多个 flag，例如 kube-apiserver 就有 200 多个 flag，这时对 flag 分组就很有必要了。通过分组，我们可以很快地定位到需要的分组及该分组具有的标志。例如，我们想了解 MySQL 有哪些标志，可以找到 MySQL 分组：</p><pre><code>Mysql flags:\n \n      --mysql.database string\n                Database name for the server to use.\n      --mysql.host string\n                MySQL service host address. If left blank, the following related mysql options will be ignored. (default &quot;127.0.0.1:3306&quot;)\n      --mysql.log-mode int\n                Specify gorm log level. (default 1)\n      ...\n</code></pre><p>第二个技巧，<strong>flag 的名字带有层级关系</strong>。这样不仅可以知道该 flag 属于哪个分组，而且能够避免重名。例如：</p><pre><code>$ ./iam-apiserver -h |grep host\n      --mysql.host string                         MySQL service host address. If left blank, the following related mysql options will be ignored. (default &quot;127.0.0.1:3306&quot;)\n      --redis.host string                   Hostname of your Redis server. (default &quot;127.0.0.1&quot;)\n</code></pre><p>对于 MySQL 和 Redis， 都可以指定相同的 host 标志，通过 <code>--mysql.host</code> 也可以知道该 flag 隶属于 mysql 分组，代表的是 MySQL 的 host。</p><p><strong>我们再看应用执行阶段。</strong>这时会通过 viper.Unmarshal，将配置 Unmarshal 到 Options 变量中。这样我们就可以使用 Options 变量中的值，来执行后面的业务逻辑。</p><p>我们传入的 Options 是一个实现了 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/pkg/app/options.go#L13\">CliOptions</a> 接口的结构体变量，CliOptions 接口定义为：</p><pre><code>type CliOptions interface {\n    Flags() (fss cliflag.NamedFlagSets)\n    Validate() []error\n}\n</code></pre><p>因为 Options 实现了 Validate 方法，所以我们就可以在应用框架中调用 Validate 方法来校验参数是否合法。另外，我们还可以通过以下代码，来判断选项是否可补全和打印：如果可以补全，则补全选项；如果可以打印，则打印选项的内容。实现代码如下：</p><pre><code>func (a *App) applyOptionRules() error {\n    if completeableOptions, ok := a.options.(CompleteableOptions); ok {  \n        if err := completeableOptions.Complete(); err != nil {\n            return err                     \n        }                                                    \n    }                    \n                                                                               \n    if errs := a.options.Validate(); len(errs) != 0 {                           \n        return errors.NewAggregate(errs)                                            \n    }                                                            \n                                        \n    if printableOptions, ok := a.options.(PrintableOptions); ok &amp;&amp; !a.silence {\n        log.Infof(&quot;%v Config: `%s`&quot;, progressMessage, printableOptions.String())\n    }                                                     \n                                                                                                                                    \n    return nil                                                                                                                      \n}       \n</code></pre><p>通过配置补全，可以确保一些重要的配置项具有默认值，当这些配置项没有被配置时，程序也仍然能够正常启动。一个大型项目，有很多配置项，我们不可能对每一个配置项都进行配置。所以，给重要配置项设置默认值，就显得很重要了。</p><p>这里，我们来看下 iam-apiserver 提供的 Validate 方法：</p><pre><code>func (s *ServerRunOptions) Validate() []error {\n    var errs []error\n\n    errs = append(errs, s.GenericServerRunOptions.Validate()...)\n    errs = append(errs, s.GrpcOptions.Validate()...)\n    errs = append(errs, s.InsecureServing.Validate()...)\n    errs = append(errs, s.SecureServing.Validate()...)\n    errs = append(errs, s.MySQLOptions.Validate()...)\n    errs = append(errs, s.RedisOptions.Validate()...)\n    errs = append(errs, s.JwtOptions.Validate()...)\n    errs = append(errs, s.Log.Validate()...)\n    errs = append(errs, s.FeatureOptions.Validate()...)\n\n    return errs\n}\n</code></pre><p>可以看到，每个配置分组，都实现了 <code>Validate()</code> 函数，对自己负责的配置进行校验。通过这种方式，程序会更加清晰。因为只有配置提供者才更清楚如何校验自己的配置项，所以最好的做法是将配置的校验放权给配置提供者（分组）。</p><h3>第 4 步：配置文件解析</h3><p>在 buildCommand 函数中，通过addConfigFlag调用，添加了 <code>-c, --config FILE</code> 命令行参数，用来指定配置文件：</p><pre><code>addConfigFlag(a.basename, namedFlagSets.FlagSet(&quot;global&quot;))\n</code></pre><p>addConfigFlag函数代码如下：</p><pre><code>func addConfigFlag(basename string, fs *pflag.FlagSet) {\n    fs.AddFlag(pflag.Lookup(configFlagName))\n\n    viper.AutomaticEnv()\n    viper.SetEnvPrefix(strings.Replace(strings.ToUpper(basename), &quot;-&quot;, &quot;_&quot;, -1))\n    viper.SetEnvKeyReplacer(strings.NewReplacer(&quot;.&quot;, &quot;_&quot;, &quot;-&quot;, &quot;_&quot;))\n\n    cobra.OnInitialize(func() {\n        if cfgFile != &quot;&quot; {\n            viper.SetConfigFile(cfgFile)\n        } else {\n            viper.AddConfigPath(&quot;.&quot;)\n\n            if names := strings.Split(basename, &quot;-&quot;); len(names) &gt; 1 {\n                viper.AddConfigPath(filepath.Join(homedir.HomeDir(), &quot;.&quot;+names[0]))\n            }\n\n            viper.SetConfigName(basename)\n        }\n\n        if err := viper.ReadInConfig(); err != nil {\n            _, _ = fmt.Fprintf(os.Stderr, &quot;Error: failed to read configuration file(%s): %v\\n&quot;, cfgFile, err)\n            os.Exit(1)\n        }\n    })\n}\n</code></pre><p>addConfigFlag 函数中，指定了 Cobra Command 在执行命令之前，需要做的初始化工作：</p><pre><code>func() {\n\tif cfgFile != &quot;&quot; {\n\t\tviper.SetConfigFile(cfgFile)\n\t} else {\n\t\tviper.AddConfigPath(&quot;.&quot;)\n\n\t\tif names := strings.Split(basename, &quot;-&quot;); len(names) &gt; 1 {\n\t\t\tviper.AddConfigPath(filepath.Join(homedir.HomeDir(), &quot;.&quot;+names[0]))\n\t\t}\n\n\t\tviper.SetConfigName(basename)\n\t}\n\n\tif err := viper.ReadInConfig(); err != nil {\n\t\t_, _ = fmt.Fprintf(os.Stderr, &quot;Error: failed to read configuration file(%s): %v\\n&quot;, cfgFile, err)\n\t\tos.Exit(1)\n\t}\n}\n</code></pre><p>上述代码实现了以下功能：</p><ul>\n<li>如果命令行参数中没有指定配置文件的路径，则加载默认路径下的配置文件，通过 viper.AddConfigPath、viper.SetConfigName 来设置配置文件搜索路径和配置文件名。通过设置默认的配置文件，可以使我们不用携带任何命令行参数，即可运行程序。</li>\n<li>支持环境变量，通过 viper.SetEnvPrefix 来设置环境变量前缀，避免跟系统中的环境变量重名。通过 viper.SetEnvKeyReplacer 重写了 Env 键。</li>\n</ul><p>上面，我们给应用添加了配置文件的命令行参数，并设置在命令执行前，读取配置文件。在命令执行时，会将配置文件中的配置项和命令行参数绑定，并将 Viper 的配置 Unmarshal 到传入的 Options 中：</p><pre><code>if !a.noConfig {    \n    if err := viper.BindPFlags(cmd.Flags()); err != nil {    \n        return err    \n    }    \n    \n    if err := viper.Unmarshal(a.options); err != nil {    \n        return err    \n    }  \n}  \n</code></pre><p>Viper 的配置是命令行参数和配置文件配置 merge 后的配置。如果在配置文件中指定了 MySQL 的 host 配置，并且也同时指定了 <code>--mysql.host</code> 参数，则会优先取命令行参数设置的值。这里需要注意的是，不同于 YAML 格式的分级方式，配置项是通过点号 <code>.</code> 来分级的。</p><p>至此，我们已经成功构建了一个优秀的应用框架，接下来我们看下这个应用框架具有哪些优点吧。</p><h2>这样构建的应用程序，有哪些优秀特性？</h2><p>借助 Cobra 自带的能力，构建出的应用天然具备帮助信息、使用信息、子命令、子命令自动补全、非选项参数校验、命令别名、PreRun、PostRun 等功能，这些功能对于一个应用来说是非常有用的。</p><p>Cobra 可以集成 Pflag，通过将创建的 Pflag FlagSet 绑定到 Cobra 命令的 FlagSet 中，使得 Pflag 支持的标志能直接集成到 Cobra 命令中。集成到命令中有很多好处，例如：<code>cobra -h</code> 可以打印出所有设置的 flag，Cobra Command 命令提供的 GenBashCompletion 方法，可以实现命令行选项的自动补全。</p><p>通过 viper.BindPFlags 和 viper.ReadInConfig 函数，可以统一配置文件、命令行参数的配置项，使得应用的配置项更加清晰好记。面对不同场景可以选择不同的配置方式，使配置更加灵活。例如：配置 HTTPS 的绑定端口，可以通过 <code>--secure.bind-port</code> 配置，也可以通过配置文件配置（命令行参数优先于配置文件）：</p><pre><code>secure:    \n    bind-port: 8080\n</code></pre><p>可以通过 <code>viper.GetString(\"secure.bind-port\")</code> 这类方式获取应用的配置，获取方式更加灵活，而且全局可用。</p><p>将应用框架的构建方法实现成了一个 Go 包，通过 Go 包可以提高应用构建代码的封装性和复用性。</p><h2>如果你想自己构建应用，需要注意些什么？</h2><p>当然，你也可以使用其他方式构建你的应用程序。比如，我就见过很多开发者使用如下方式来构建应用：直接在 <code>main.go</code> 文件中通过 <code>gopkg.in/yaml.v3</code> 包解析配置，通过 Go 标准库的 flag 包简单地添加一些命令行参数，例如<code>--help</code>、<code>--config</code>、<code>--version</code>。</p><p>但是，在你自己独立构建应用程序时，很可能会踩这么 3 个坑：</p><ul>\n<li>构建的应用功能简单，扩展性差，导致后期扩展复杂。</li>\n<li>构建的应用没有帮助信息和使用信息，或者信息格式杂乱，增加应用的使用难度。</li>\n<li>命令行选项和配置文件支持的配置项相互独立，导致配合应用程序的时候，不知道该使用哪种方式来配置。</li>\n</ul><p>在我看来，对于小的应用，自己根据需要构建没什么问题，但是对于一个大型项目的话，还是在应用开发之初，就采用一些功能多、扩展性强的优秀包。这样，以后随着应用的迭代，可以零成本地进行功能添加和扩展，同时也能体现我们的专业性和技术深度，提高代码质量。</p><p>如果你有特殊需求，一定要自己构建应用框架，那么我有以下几个建议：</p><ul>\n<li>应用框架应该清晰易读、扩展性强。</li>\n<li>应用程序应该至少支持如下命令行选项：<code>-h</code> 打印帮助信息；<code>-v</code> 打印应用程序的版本；<code>-c</code> 支持指定配置文件的路径。</li>\n<li>如果你的应用有很多命令行选项，那么建议支持 <code>--secure.bind-port</code> 这样的长选项，通过选项名字，就可以知道选项的作用。</li>\n<li>配置文件使用 <code>yaml</code> 格式，<code>yaml</code> 格式的配置文件，能支持复杂的配置，还清晰易读。</li>\n<li>如果你有多个服务，那么要保持所有服务的应用构建方式是一致的。</li>\n</ul><h2>总结</h2><p>一个应用框架由命令、命令行参数解析、配置文件解析 3 部分功能组成，我们可以通过 Cobra 来构建命令，通过 Pflag 来解析命令行参数，通过 Viper 来解析配置文件。一个项目，可能包含多个应用，这些应用都需要通过 Cobra、Viper、Pflag 来构建。为了不重复造轮子，简化应用的构建，我们可以将这些功能实现为一个 Go 包，方便直接调用构建应用。</p><p>IAM 项目的应用都是通过 <code>github.com/marmotedu/iam/pkg/app</code> 包来构建的，在构建时，调用 App 包提供的 NewApp 函数，来构建一个应用：</p><pre><code>func NewApp(basename string) *app.App {\n    opts := options.NewOptions()\n    application := app.NewApp(&quot;IAM API Server&quot;,\n        basename,\n        app.WithOptions(opts),\n        app.WithDescription(commandDesc),\n        app.WithDefaultValidArgs(),\n        app.WithRunFunc(run(opts)),\n    )\n\n    return application\n}\n</code></pre><p>在构建应用时，只需要提供应用简短/详细描述、应用二进制文件名称和命令行选项即可。App 包会根据 Options 提供的 <code>Flags()</code> 方法，来给应用添加命令行选项。命令行选项中提供了 <code>-c, --config</code> 选项来指定配置文件，App 包也会加载并解析这个配置文件，并将配置文件和命令行选项相同配置项进行 Merge，最终将配置项的值保存在传入的 Options 变量中，供业务代码使用。</p><p>最后，如果你想自己构建应用，我给出了一些我的建议：设计一个清晰易读、易扩展的应用框架；支持一些常见的选项，例如 <code>-h</code>， <code>-v</code>， <code>-c</code> 等；如果应用的命令行选项比较多，建议使用 <code>--secure.bind-port</code> 这样的长选项。</p><h2>课后练习</h2><ol>\n<li>除了 Cobra、Viper、Pflag 之外，你还遇到过哪些比较优秀的包或者工具，可以用来构建应用框架？欢迎在留言区分享。</li>\n<li>研究下 iam-apiserver 的命令行选项 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/apiserver/options/options.go\">Options</a> 是如何通过 Options 的 Flags()方法来实现 Flag 分组的，并思考下这样做有什么好处。</li>\n</ol><p>欢迎你在留言区与我交流讨论。当然了，你也可以把这一讲分享给你身边的朋友，他们的一些想法或许会让你有更大的收获。我们下一讲见！</p>","neighbors":{"left":{"article_title":"22 | 应用构建三剑客：Pflag、Viper、Cobra 核心功能介绍","id":395705},"right":{"article_title":"24 | Web 服务：Web 服务核心功能有哪些，如何实现？","id":397475}}},{"article_id":397475,"article_title":"24 | Web 服务：Web 服务核心功能有哪些，如何实现？","article_content":"<p>你好，我是孔令飞。从今天开始，我们进入实战第三站：服务开发。在这个部分，我会讲解 IAM项目各个服务的构建方式，帮助你掌握Go 开发阶段的各个技能点。</p><p>在Go项目开发中，绝大部分情况下，我们是在写能提供某种功能的后端服务，这些功能以RPC API 接口或者RESTful API接口的形式对外提供，能提供这两种API接口的服务也统称为Web服务。今天这一讲，我就通过介绍RESTful API风格的Web服务，来给你介绍下如何实现Web服务的核心功能。</p><p>那今天我们就来看下，Web服务的核心功能有哪些，以及如何开发这些功能。</p><h2>Web服务的核心功能</h2><p>Web服务有很多功能，为了便于你理解，我将这些功能分成了基础功能和高级功能两大类，并总结在了下面这张图中：</p><p><img src=\"https://static001.geekbang.org/resource/image/1a/2e/1a6d38450cdd0e115e505ab30113602e.jpg?wh=2248x1835\" alt=\"\"></p><p>下面，我就按图中的顺序，来串讲下这些功能。</p><p>要实现一个Web服务，首先我们要选择通信协议和通信格式。在Go项目开发中，有HTTP+JSON 和 gRPC+Protobuf两种组合可选。因为iam-apiserver主要提供的是REST风格的API接口，所以选择的是HTTP+JSON组合。</p><p><strong>Web服务最核心的功能是路由匹配。</strong>路由匹配其实就是根据<code>(HTTP方法, 请求路径)</code>匹配到处理这个请求的函数，最终由该函数处理这次请求，并返回结果，过程如下图所示：</p><!-- [[[read_end]]] --><p><img src=\"https://static001.geekbang.org/resource/image/1f/9d/1f5yydeffb32732e7d0e23a0a9cd369d.jpg?wh=2248x975\" alt=\"\"></p><p>一次HTTP请求经过路由匹配，最终将请求交由<code>Delete(c *gin.Context)</code>函数来处理。变量<code>c</code>中存放了这次请求的参数，在Delete函数中，我们可以进行参数解析、参数校验、逻辑处理，最终返回结果。</p><p>对于大型系统，可能会有很多个API接口，API接口随着需求的更新迭代，可能会有多个版本，为了便于管理，我们需要<strong>对路由进行分组</strong>。</p><p>有时候，我们需要在一个服务进程中，同时开启HTTP服务的80端口和HTTPS的443端口，这样我们就可以做到：对内的服务，访问80端口，简化服务访问复杂度；对外的服务，访问更为安全的HTTPS服务。显然，我们没必要为相同功能启动多个服务进程，所以这时候就需要Web服务能够支持<strong>一进程多服务</strong>的功能。</p><p>我们开发Web服务最核心的诉求是：输入一些参数，校验通过后，进行业务逻辑处理，然后返回结果。所以Web服务还应该能够进行<strong>参数解析</strong>、<strong>参数校验</strong>、<strong>逻辑处理</strong>、<strong>返回结果</strong>。这些都是Web服务的业务处理功能。</p><p>上面这些是Web服务的基本功能，此外，我们还需要支持一些高级功能。</p><p>在进行HTTP请求时，经常需要针对每一次请求都设置一些通用的操作，比如添加Header、添加RequestID、统计请求次数等，这就要求我们的Web服务能够支持<strong>中间件</strong>特性。</p><p>为了保证系统安全，对于每一个请求，我们都需要进行<strong>认证</strong>。Web服务中，通常有两种认证方式，一种是基于用户名和密码，一种是基于Token。认证通过之后，就可以继续处理请求了。</p><p>为了方便定位和跟踪某一次请求，需要支持<strong>RequestID</strong>，定位和跟踪RequestID主要是为了排障。</p><p>最后，当前的软件架构中，很多采用了前后端分离的架构。在前后端分离的架构中，前端访问地址和后端访问地址往往是不同的，浏览器为了安全，会针对这种情况设置跨域请求，所以Web服务需要能够处理浏览器的<strong>跨域</strong>请求。</p><p>到这里，我就把Web服务的基础功能和高级功能串讲了一遍。当然，上面只介绍了Web服务的核心功能，还有很多其他的功能，你可以通过学习<a href=\"https://github.com/gin-gonic/gin\">Gin的官方文档</a>来了解。</p><p>你可以看到，Web服务有很多核心功能，这些功能我们可以基于net/http包自己封装。但在实际的项目开发中， 我们更多会选择使用基于net/http包进行封装的优秀开源Web框架。本实战项目选择了Gin框架。</p><p>接下来，我们主要看下Gin框架是如何实现以上核心功能的，这些功能我们在实际的开发中可以直接拿来使用。</p><h2>为什么选择Gin框架？</h2><p>优秀的Web框架有很多，我们为什么要选择Gin呢？在回答这个问题之前，我们先来看下选择Web框架时的关注点。</p><p>在选择Web框架时，我们可以关注如下几点：</p><ul>\n<li>路由功能；</li>\n<li>是否具备middleware/filter能力；</li>\n<li>HTTP 参数（path、query、form、header、body）解析和返回；</li>\n<li>性能和稳定性；</li>\n<li>使用复杂度；</li>\n<li>社区活跃度。</li>\n</ul><p>按 GitHub Star 数来排名，当前比较火的 Go Web 框架有 Gin、Beego、Echo、Revel 、Martini。经过调研，我从中选择了Gin框架，原因是Gin具有如下特性：</p><ul>\n<li>轻量级，代码质量高，性能比较高；</li>\n<li>项目目前很活跃，并有很多可用的 Middleware；</li>\n<li>作为一个 Web 框架，功能齐全，使用起来简单。</li>\n</ul><p>那接下来，我就先详细介绍下Gin框架。</p><p><a href=\"https://github.com/gin-gonic/gin\">Gin</a>是用Go语言编写的Web框架，功能完善，使用简单，性能很高。Gin核心的路由功能是通过一个定制版的<a href=\"https://github.com/julienschmidt/httprouter\">HttpRouter</a>来实现的，具有很高的路由性能。</p><p>Gin有很多功能，这里我给你列出了它的一些核心功能：</p><ul>\n<li>支持HTTP方法：GET、POST、PUT、PATCH、DELETE、OPTIONS。</li>\n<li>支持不同位置的HTTP参数：路径参数（path）、查询字符串参数（query）、表单参数（form）、HTTP头参数（header）、消息体参数（body）。</li>\n<li>支持HTTP路由和路由分组。</li>\n<li>支持middleware和自定义middleware。</li>\n<li>支持自定义Log。</li>\n<li>支持binding和validation，支持自定义validator。可以bind如下参数：query、path、body、header、form。</li>\n<li>支持重定向。</li>\n<li>支持basic auth middleware。</li>\n<li>支持自定义HTTP配置。</li>\n<li>支持优雅关闭。</li>\n<li>支持HTTP2。</li>\n<li>支持设置和获取cookie。</li>\n</ul><h2>Gin是如何支持Web服务基础功能的？</h2><p>接下来，我们先通过一个具体的例子，看下Gin是如何支持Web服务基础功能的，后面再详细介绍这些功能的用法。</p><p>我们创建一个webfeature目录，用来存放示例代码。因为要演示HTTPS的用法，所以需要创建证书文件。具体可以分为两步。</p><p>第一步，执行以下命令创建证书：</p><pre><code>cat &lt;&lt; 'EOF' &gt; ca.pem\n-----BEGIN CERTIFICATE-----\nMIICSjCCAbOgAwIBAgIJAJHGGR4dGioHMA0GCSqGSIb3DQEBCwUAMFYxCzAJBgNV\nBAYTAkFVMRMwEQYDVQQIEwpTb21lLVN0YXRlMSEwHwYDVQQKExhJbnRlcm5ldCBX\naWRnaXRzIFB0eSBMdGQxDzANBgNVBAMTBnRlc3RjYTAeFw0xNDExMTEyMjMxMjla\nFw0yNDExMDgyMjMxMjlaMFYxCzAJBgNVBAYTAkFVMRMwEQYDVQQIEwpTb21lLVN0\nYXRlMSEwHwYDVQQKExhJbnRlcm5ldCBXaWRnaXRzIFB0eSBMdGQxDzANBgNVBAMT\nBnRlc3RjYTCBnzANBgkqhkiG9w0BAQEFAAOBjQAwgYkCgYEAwEDfBV5MYdlHVHJ7\n+L4nxrZy7mBfAVXpOc5vMYztssUI7mL2/iYujiIXM+weZYNTEpLdjyJdu7R5gGUu\ng1jSVK/EPHfc74O7AyZU34PNIP4Sh33N+/A5YexrNgJlPY+E3GdVYi4ldWJjgkAd\nQah2PH5ACLrIIC6tRka9hcaBlIECAwEAAaMgMB4wDAYDVR0TBAUwAwEB/zAOBgNV\nHQ8BAf8EBAMCAgQwDQYJKoZIhvcNAQELBQADgYEAHzC7jdYlzAVmddi/gdAeKPau\nsPBG/C2HCWqHzpCUHcKuvMzDVkY/MP2o6JIW2DBbY64bO/FceExhjcykgaYtCH/m\noIU63+CFOTtR7otyQAWHqXa7q4SbCDlG7DyRFxqG0txPtGvy12lgldA2+RgcigQG\nDfcog5wrJytaQ6UA0wE=\n-----END CERTIFICATE-----\nEOF\n\ncat &lt;&lt; 'EOF' &gt; server.key\n-----BEGIN PRIVATE KEY-----\nMIICdQIBADANBgkqhkiG9w0BAQEFAASCAl8wggJbAgEAAoGBAOHDFScoLCVJpYDD\nM4HYtIdV6Ake/sMNaaKdODjDMsux/4tDydlumN+fm+AjPEK5GHhGn1BgzkWF+slf\n3BxhrA/8dNsnunstVA7ZBgA/5qQxMfGAq4wHNVX77fBZOgp9VlSMVfyd9N8YwbBY\nAckOeUQadTi2X1S6OgJXgQ0m3MWhAgMBAAECgYAn7qGnM2vbjJNBm0VZCkOkTIWm\nV10okw7EPJrdL2mkre9NasghNXbE1y5zDshx5Nt3KsazKOxTT8d0Jwh/3KbaN+YY\ntTCbKGW0pXDRBhwUHRcuRzScjli8Rih5UOCiZkhefUTcRb6xIhZJuQy71tjaSy0p\ndHZRmYyBYO2YEQ8xoQJBAPrJPhMBkzmEYFtyIEqAxQ/o/A6E+E4w8i+KM7nQCK7q\nK4JXzyXVAjLfyBZWHGM2uro/fjqPggGD6QH1qXCkI4MCQQDmdKeb2TrKRh5BY1LR\n81aJGKcJ2XbcDu6wMZK4oqWbTX2KiYn9GB0woM6nSr/Y6iy1u145YzYxEV/iMwff\nDJULAkB8B2MnyzOg0pNFJqBJuH29bKCcHa8gHJzqXhNO5lAlEbMK95p/P2Wi+4Hd\naiEIAF1BF326QJcvYKmwSmrORp85AkAlSNxRJ50OWrfMZnBgzVjDx3xG6KsFQVk2\nol6VhqL6dFgKUORFUWBvnKSyhjJxurlPEahV6oo6+A+mPhFY8eUvAkAZQyTdupP3\nXEFQKctGz+9+gKkemDp7LBBMEMBXrGTLPhpEfcjv/7KPdnFHYmhYeBTBnuVmTVWe\nF98XJ7tIFfJq\n-----END PRIVATE KEY-----\nEOF\n\ncat &lt;&lt; 'EOF' &gt; server.pem\n-----BEGIN CERTIFICATE-----\nMIICnDCCAgWgAwIBAgIBBzANBgkqhkiG9w0BAQsFADBWMQswCQYDVQQGEwJBVTET\nMBEGA1UECBMKU29tZS1TdGF0ZTEhMB8GA1UEChMYSW50ZXJuZXQgV2lkZ2l0cyBQ\ndHkgTHRkMQ8wDQYDVQQDEwZ0ZXN0Y2EwHhcNMTUxMTA0MDIyMDI0WhcNMjUxMTAx\nMDIyMDI0WjBlMQswCQYDVQQGEwJVUzERMA8GA1UECBMISWxsaW5vaXMxEDAOBgNV\nBAcTB0NoaWNhZ28xFTATBgNVBAoTDEV4YW1wbGUsIENvLjEaMBgGA1UEAxQRKi50\nZXN0Lmdvb2dsZS5jb20wgZ8wDQYJKoZIhvcNAQEBBQADgY0AMIGJAoGBAOHDFSco\nLCVJpYDDM4HYtIdV6Ake/sMNaaKdODjDMsux/4tDydlumN+fm+AjPEK5GHhGn1Bg\nzkWF+slf3BxhrA/8dNsnunstVA7ZBgA/5qQxMfGAq4wHNVX77fBZOgp9VlSMVfyd\n9N8YwbBYAckOeUQadTi2X1S6OgJXgQ0m3MWhAgMBAAGjazBpMAkGA1UdEwQCMAAw\nCwYDVR0PBAQDAgXgME8GA1UdEQRIMEaCECoudGVzdC5nb29nbGUuZnKCGHdhdGVy\nem9vaS50ZXN0Lmdvb2dsZS5iZYISKi50ZXN0LnlvdXR1YmUuY29thwTAqAEDMA0G\nCSqGSIb3DQEBCwUAA4GBAJFXVifQNub1LUP4JlnX5lXNlo8FxZ2a12AFQs+bzoJ6\nhM044EDjqyxUqSbVePK0ni3w1fHQB5rY9yYC5f8G7aqqTY1QOhoUk8ZTSTRpnkTh\ny4jjdvTZeLDVBlueZUTDRmy2feY5aZIU18vFDK08dTG0A87pppuv1LNIR3loveU8\n-----END CERTIFICATE-----\nEOF\n</code></pre><p>第二步，创建main.go文件：</p><pre><code>package main\n\nimport (\n\t&quot;fmt&quot;\n\t&quot;log&quot;\n\t&quot;net/http&quot;\n\t&quot;sync&quot;\n\t&quot;time&quot;\n\n\t&quot;github.com/gin-gonic/gin&quot;\n\t&quot;golang.org/x/sync/errgroup&quot;\n)\n\ntype Product struct {\n\tUsername    string    `json:&quot;username&quot; binding:&quot;required&quot;`\n\tName        string    `json:&quot;name&quot; binding:&quot;required&quot;`\n\tCategory    string    `json:&quot;category&quot; binding:&quot;required&quot;`\n\tPrice       int       `json:&quot;price&quot; binding:&quot;gte=0&quot;`\n\tDescription string    `json:&quot;description&quot;`\n\tCreatedAt   time.Time `json:&quot;createdAt&quot;`\n}\n\ntype productHandler struct {\n\tsync.RWMutex\n\tproducts map[string]Product\n}\n\nfunc newProductHandler() *productHandler {\n\treturn &amp;productHandler{\n\t\tproducts: make(map[string]Product),\n\t}\n}\n\nfunc (u *productHandler) Create(c *gin.Context) {\n\tu.Lock()\n\tdefer u.Unlock()\n\n\t// 1. 参数解析\n\tvar product Product\n\tif err := c.ShouldBindJSON(&amp;product); err != nil {\n\t\tc.JSON(http.StatusBadRequest, gin.H{&quot;error&quot;: err.Error()})\n\t\treturn\n\t}\n\n\t// 2. 参数校验\n\tif _, ok := u.products[product.Name]; ok {\n\t\tc.JSON(http.StatusBadRequest, gin.H{&quot;error&quot;: fmt.Sprintf(&quot;product %s already exist&quot;, product.Name)})\n\t\treturn\n\t}\n\tproduct.CreatedAt = time.Now()\n\n\t// 3. 逻辑处理\n\tu.products[product.Name] = product\n\tlog.Printf(&quot;Register product %s success&quot;, product.Name)\n\n\t// 4. 返回结果\n\tc.JSON(http.StatusOK, product)\n}\n\nfunc (u *productHandler) Get(c *gin.Context) {\n\tu.Lock()\n\tdefer u.Unlock()\n\n\tproduct, ok := u.products[c.Param(&quot;name&quot;)]\n\tif !ok {\n\t\tc.JSON(http.StatusNotFound, gin.H{&quot;error&quot;: fmt.Errorf(&quot;can not found product %s&quot;, c.Param(&quot;name&quot;))})\n\t\treturn\n\t}\n\n\tc.JSON(http.StatusOK, product)\n}\n\nfunc router() http.Handler {\n\trouter := gin.Default()\n\tproductHandler := newProductHandler()\n\t// 路由分组、中间件、认证\n\tv1 := router.Group(&quot;/v1&quot;)\n\t{\n\t\tproductv1 := v1.Group(&quot;/products&quot;)\n\t\t{\n\t\t\t// 路由匹配\n\t\t\tproductv1.POST(&quot;&quot;, productHandler.Create)\n\t\t\tproductv1.GET(&quot;:name&quot;, productHandler.Get)\n\t\t}\n\t}\n\n\treturn router\n}\n\nfunc main() {\n\tvar eg errgroup.Group\n\n\t// 一进程多端口\n\tinsecureServer := &amp;http.Server{\n\t\tAddr:         &quot;:8080&quot;,\n\t\tHandler:      router(),\n\t\tReadTimeout:  5 * time.Second,\n\t\tWriteTimeout: 10 * time.Second,\n\t}\n\n\tsecureServer := &amp;http.Server{\n\t\tAddr:         &quot;:8443&quot;,\n\t\tHandler:      router(),\n\t\tReadTimeout:  5 * time.Second,\n\t\tWriteTimeout: 10 * time.Second,\n\t}\n\n\teg.Go(func() error {\n\t\terr := insecureServer.ListenAndServe()\n\t\tif err != nil &amp;&amp; err != http.ErrServerClosed {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t\treturn err\n\t})\n\n\teg.Go(func() error {\n\t\terr := secureServer.ListenAndServeTLS(&quot;server.pem&quot;, &quot;server.key&quot;)\n\t\tif err != nil &amp;&amp; err != http.ErrServerClosed {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t\treturn err\n\t})\n\n\tif err := eg.Wait(); err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n</code></pre><p>运行以上代码：</p><pre><code>$ go run main.go\n</code></pre><p>打开另外一个终端，请求HTTP接口：</p><pre><code># 创建产品\n$ curl -XPOST -H&quot;Content-Type: application/json&quot; -d'{&quot;username&quot;:&quot;colin&quot;,&quot;name&quot;:&quot;iphone12&quot;,&quot;category&quot;:&quot;phone&quot;,&quot;price&quot;:8000,&quot;description&quot;:&quot;cannot afford&quot;}' http://127.0.0.1:8080/v1/products\n{&quot;username&quot;:&quot;colin&quot;,&quot;name&quot;:&quot;iphone12&quot;,&quot;category&quot;:&quot;phone&quot;,&quot;price&quot;:8000,&quot;description&quot;:&quot;cannot afford&quot;,&quot;createdAt&quot;:&quot;2021-06-20T11:17:03.818065988+08:00&quot;}\n\n# 获取产品信息\n$ curl -XGET http://127.0.0.1:8080/v1/products/iphone12\n{&quot;username&quot;:&quot;colin&quot;,&quot;name&quot;:&quot;iphone12&quot;,&quot;category&quot;:&quot;phone&quot;,&quot;price&quot;:8000,&quot;description&quot;:&quot;cannot afford&quot;,&quot;createdAt&quot;:&quot;2021-06-20T11:17:03.818065988+08:00&quot;}\n</code></pre><p>示例代码存放地址为<a href=\"https://github.com/marmotedu/gopractise-demo/tree/master/gin/webfeature\">webfeature</a>。</p><p>另外，Gin项目仓库中也包含了很多使用示例，如果你想详细了解，可以参考 <a href=\"https://github.com/gin-gonic/examples\">gin examples</a>。</p><p>下面，我来详细介绍下Gin是如何支持Web服务基础功能的。</p><h3>HTTP/HTTPS支持</h3><p>因为Gin是基于net/http包封装的一个Web框架，所以它天然就支持HTTP/HTTPS。在上述代码中，通过以下方式开启一个HTTP服务：</p><pre><code>insecureServer := &amp;http.Server{\n\tAddr:         &quot;:8080&quot;,\n\tHandler:      router(),\n\tReadTimeout:  5 * time.Second,\n\tWriteTimeout: 10 * time.Second,\n}\n...\nerr := insecureServer.ListenAndServe()\n</code></pre><p>通过以下方式开启一个HTTPS服务：</p><pre><code>secureServer := &amp;http.Server{\n\tAddr:         &quot;:8443&quot;,\n\tHandler:      router(),\n\tReadTimeout:  5 * time.Second,\n\tWriteTimeout: 10 * time.Second,\n}\n...\nerr := secureServer.ListenAndServeTLS(&quot;server.pem&quot;, &quot;server.key&quot;)\n</code></pre><h3>JSON数据格式支持</h3><p>Gin支持多种数据通信格式，例如application/json、application/xml。可以通过<code>c.ShouldBindJSON</code>函数，将Body中的JSON格式数据解析到指定的Struct中，通过<code>c.JSON</code>函数返回JSON格式的数据。</p><h3>路由匹配</h3><p>Gin支持两种路由匹配规则。</p><p><strong>第一种匹配规则是精确匹配。</strong>例如，路由为/products/:name，匹配情况如下表所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/11/df/11be05d7fe7f935e01725e2635f315df.jpg?wh=2248x1418\" alt=\"\"></p><p><strong>第二种匹配规则是模糊匹配。</strong>例如，路由为/products/*name，匹配情况如下表所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/b5/7b/b5ccd9924e53dd90a64af6002967b67b.jpg?wh=2248x1636\" alt=\"\"></p><h3>路由分组</h3><p>Gin通过Group函数实现了路由分组的功能。路由分组是一个非常常用的功能，可以将相同版本的路由分为一组，也可以将相同RESTful资源的路由分为一组。例如：</p><pre><code>v1 := router.Group(&quot;/v1&quot;, gin.BasicAuth(gin.Accounts{&quot;foo&quot;: &quot;bar&quot;, &quot;colin&quot;: &quot;colin404&quot;}))\n{\n    productv1 := v1.Group(&quot;/products&quot;)\n    {\n        // 路由匹配\n        productv1.POST(&quot;&quot;, productHandler.Create)\n        productv1.GET(&quot;:name&quot;, productHandler.Get)\n    }\n\n    orderv1 := v1.Group(&quot;/orders&quot;)\n    {\n        // 路由匹配\n        orderv1.POST(&quot;&quot;, orderHandler.Create)\n        orderv1.GET(&quot;:name&quot;, orderHandler.Get)\n    }\n}\n\nv2 := router.Group(&quot;/v2&quot;, gin.BasicAuth(gin.Accounts{&quot;foo&quot;: &quot;bar&quot;, &quot;colin&quot;: &quot;colin404&quot;}))\n{\n    productv2 := v2.Group(&quot;/products&quot;)\n    {\n        // 路由匹配\n        productv2.POST(&quot;&quot;, productHandler.Create)\n        productv2.GET(&quot;:name&quot;, productHandler.Get)\n    }\n}\n</code></pre><p>通过将路由分组，可以对相同分组的路由做统一处理。比如上面那个例子，我们可以通过代码</p><pre><code>v1 := router.Group(&quot;/v1&quot;, gin.BasicAuth(gin.Accounts{&quot;foo&quot;: &quot;bar&quot;, &quot;colin&quot;: &quot;colin404&quot;}))\n</code></pre><p>给所有属于v1分组的路由都添加gin.BasicAuth中间件，以实现认证功能。中间件和认证，这里你先不用深究，下面讲高级功能的时候会介绍到。</p><h3>一进程多服务</h3><p>我们可以通过以下方式实现一进程多服务：</p><pre><code>var eg errgroup.Group\ninsecureServer := &amp;http.Server{...}\nsecureServer := &amp;http.Server{...}\n\neg.Go(func() error {\n\terr := insecureServer.ListenAndServe()\n\tif err != nil &amp;&amp; err != http.ErrServerClosed {\n\t\tlog.Fatal(err)\n\t}\n\treturn err\n})\neg.Go(func() error {\n\terr := secureServer.ListenAndServeTLS(&quot;server.pem&quot;, &quot;server.key&quot;)\n\tif err != nil &amp;&amp; err != http.ErrServerClosed {\n\t\tlog.Fatal(err)\n\t}\n\treturn err\n}\n\nif err := eg.Wait(); err != nil {\n\tlog.Fatal(err)\n})\n</code></pre><p>上述代码实现了两个相同的服务，分别监听在不同的端口。这里需要注意的是，为了不阻塞启动第二个服务，我们需要把ListenAndServe函数放在goroutine中执行，并且调用eg.Wait()来阻塞程序进程，从而让两个HTTP服务在goroutine中持续监听端口，并提供服务。</p><h3>参数解析、参数校验、逻辑处理、返回结果</h3><p>此外，Web服务还应该具有参数解析、参数校验、逻辑处理、返回结果4类功能，因为这些功能联系紧密，我们放在一起来说。</p><p>在productHandler的Create方法中，我们通过<code>c.ShouldBindJSON</code>来解析参数，接下来自己编写校验代码，然后将product信息保存在内存中（也就是业务逻辑处理），最后通过<code>c.JSON</code>返回创建的product信息。代码如下：</p><pre><code>func (u *productHandler) Create(c *gin.Context) {\n\tu.Lock()\n\tdefer u.Unlock()\n\n\t// 1. 参数解析\n\tvar product Product\n\tif err := c.ShouldBindJSON(&amp;product); err != nil {\n\t\tc.JSON(http.StatusBadRequest, gin.H{&quot;error&quot;: err.Error()})\n\t\treturn\n\t}\n\n\t// 2. 参数校验\n\tif _, ok := u.products[product.Name]; ok {\n\t\tc.JSON(http.StatusBadRequest, gin.H{&quot;error&quot;: fmt.Sprintf(&quot;product %s already exist&quot;, product.Name)})\n\t\treturn\n\t}\n\tproduct.CreatedAt = time.Now()\n\n\t// 3. 逻辑处理\n\tu.products[product.Name] = product\n\tlog.Printf(&quot;Register product %s success&quot;, product.Name)\n\n\t// 4. 返回结果\n\tc.JSON(http.StatusOK, product)\n}\n</code></pre><p>那这个时候，你可能会问：HTTP的请求参数可以存在不同的位置，Gin是如何解析的呢？这里，我们先来看下HTTP有哪些参数类型。HTTP具有以下5种参数类型：</p><ul>\n<li>路径参数（path）。例如<code>gin.Default().GET(\"/user/:name\", nil)</code>， name就是路径参数。</li>\n<li>查询字符串参数（query）。例如<code>/welcome?firstname=Lingfei&amp;lastname=Kong</code>，firstname和lastname就是查询字符串参数。</li>\n<li>表单参数（form）。例如<code>curl -X POST -F 'username=colin' -F 'password=colin1234' http://mydomain.com/login</code>，username和password就是表单参数。</li>\n<li>HTTP头参数（header）。例如<code>curl -X POST -H 'Content-Type: application/json' -d '{\"username\":\"colin\",\"password\":\"colin1234\"}' http://mydomain.com/login</code>，Content-Type就是HTTP头参数。</li>\n<li>消息体参数（body）。例如<code>curl -X POST -H 'Content-Type: application/json' -d '{\"username\":\"colin\",\"password\":\"colin1234\"}' http://mydomain.com/login</code>，username和password就是消息体参数。</li>\n</ul><p>Gin提供了一些函数，来分别读取这些HTTP参数，每种类别会提供两种函数，一种函数可以直接读取某个参数的值，另外一种函数会把同类HTTP参数绑定到一个Go结构体中。比如，有如下路径参数：</p><pre><code>gin.Default().GET(&quot;/:name/:id&quot;, nil)\n</code></pre><p>我们可以直接读取每个参数：</p><pre><code>name := c.Param(&quot;name&quot;)\naction := c.Param(&quot;action&quot;)\n</code></pre><p>也可以将所有的路径参数，绑定到结构体中：</p><pre><code>type Person struct {\n    ID string `uri:&quot;id&quot; binding:&quot;required,uuid&quot;`\n    Name string `uri:&quot;name&quot; binding:&quot;required&quot;`\n}\n\nif err := c.ShouldBindUri(&amp;person); err != nil {\n    // normal code\n    return\n}\n</code></pre><p>Gin在绑定参数时，是通过结构体的tag来判断要绑定哪类参数到结构体中的。这里要注意，不同的HTTP参数有不同的结构体tag。</p><ul>\n<li>路径参数：uri。</li>\n<li>查询字符串参数：form。</li>\n<li>表单参数：form。</li>\n<li>HTTP头参数：header。</li>\n<li>消息体参数：会根据Content-Type，自动选择使用json或者xml，也可以调用ShouldBindJSON或者ShouldBindXML直接指定使用哪个tag。</li>\n</ul><p>针对每种参数类型，Gin都有对应的函数来获取和绑定这些参数。这些函数都是基于如下两个函数进行封装的：</p><ol>\n<li>ShouldBindWith(obj interface{}, b binding.Binding) error</li>\n</ol><p>非常重要的一个函数，很多ShouldBindXXX函数底层都是调用ShouldBindWith函数来完成参数绑定的。该函数会根据传入的绑定引擎，将参数绑定到传入的结构体指针中，<strong>如果绑定失败，只返回错误内容，但不终止HTTP请求。</strong>ShouldBindWith支持多种绑定引擎，例如 binding.JSON、binding.Query、binding.Uri、binding.Header等，更详细的信息你可以参考 <a href=\"https://github.com/gin-gonic/gin/blob/v1.7.2/binding/binding.go#L72\">binding.go</a>。</p><ol start=\"2\">\n<li>MustBindWith(obj interface{}, b binding.Binding) error</li>\n</ol><p>这是另一个非常重要的函数，很多BindXXX函数底层都是调用MustBindWith函数来完成参数绑定的。该函数会根据传入的绑定引擎，将参数绑定到传入的结构体指针中，<strong>如果绑定失败，返回错误并终止请求，返回HTTP 400错误。</strong>MustBindWith所支持的绑定引擎跟ShouldBindWith函数一样。</p><p>Gin基于ShouldBindWith和MustBindWith这两个函数，又衍生出很多新的Bind函数。这些函数可以满足不同场景下获取HTTP参数的需求。Gin提供的函数可以获取5个类别的HTTP参数。</p><ul>\n<li>路径参数：ShouldBindUri、BindUri；</li>\n<li>查询字符串参数：ShouldBindQuery、BindQuery；</li>\n<li>表单参数：ShouldBind；</li>\n<li>HTTP头参数：ShouldBindHeader、BindHeader；</li>\n<li>消息体参数：ShouldBindJSON、BindJSON等。</li>\n</ul><p>每个类别的Bind函数，详细信息你可以参考<a href=\"https://github.com/marmotedu/geekbang-go/blob/master/Gin%E6%8F%90%E4%BE%9B%E7%9A%84Bind%E5%87%BD%E6%95%B0.md\">Gin提供的Bind函数</a>。</p><p>这里要注意，Gin并没有提供类似ShouldBindForm、BindForm这类函数来绑定表单参数，但我们可以通过ShouldBind来绑定表单参数。当HTTP方法为GET时，ShouldBind只绑定Query类型的参数；当HTTP方法为POST时，会先检查content-type是否是json或者xml，如果不是，则绑定Form类型的参数。</p><p>所以，ShouldBind可以绑定Form类型的参数，但前提是HTTP方法是POST，并且content-type不是application/json、application/xml。</p><p>在Go项目开发中，我建议使用ShouldBindXXX，这样可以确保我们设置的HTTP Chain（Chain可以理解为一个HTTP请求的一系列处理插件）能够继续被执行。</p><h2>Gin是如何支持Web服务高级功能的？</h2><p>上面介绍了Web服务的基础功能，这里我再来介绍下高级功能。Web服务可以具备多个高级功能，但比较核心的高级功能是中间件、认证、RequestID、跨域和优雅关停。</p><h3>中间件</h3><p>Gin支持中间件，HTTP请求在转发到实际的处理函数之前，会被一系列加载的中间件进行处理。在中间件中，可以解析HTTP请求做一些逻辑处理，例如：跨域处理或者生成X-Request-ID并保存在context中，以便追踪某个请求。处理完之后，可以选择中断并返回这次请求，也可以选择将请求继续转交给下一个中间件处理。当所有的中间件都处理完之后，请求才会转给路由函数进行处理。具体流程如下图：</p><p><img src=\"https://static001.geekbang.org/resource/image/f0/80/f0783cb9ee8cffa969f846ebe8eae880.jpg?wh=2248x1655\" alt=\"\"></p><p>通过中间件，可以实现对所有请求都做统一的处理，提高开发效率，并使我们的代码更简洁。但是，因为所有的请求都需要经过中间件的处理，可能会增加请求延时。对于中间件特性，我有如下建议：</p><ul>\n<li>中间件做成可加载的，通过配置文件指定程序启动时加载哪些中间件。</li>\n<li>只将一些通用的、必要的功能做成中间件。</li>\n<li>在编写中间件时，一定要保证中间件的代码质量和性能。</li>\n</ul><p>在Gin中，可以通过gin.Engine的Use方法来加载中间件。中间件可以加载到不同的位置上，而且不同的位置作用范围也不同，例如：</p><pre><code>router := gin.New()\nrouter.Use(gin.Logger(), gin.Recovery()) // 中间件作用于所有的HTTP请求\nv1 := router.Group(&quot;/v1&quot;).Use(gin.BasicAuth(gin.Accounts{&quot;foo&quot;: &quot;bar&quot;, &quot;colin&quot;: &quot;colin404&quot;})) // 中间件作用于v1 group\nv1.POST(&quot;/login&quot;, Login).Use(gin.BasicAuth(gin.Accounts{&quot;foo&quot;: &quot;bar&quot;, &quot;colin&quot;: &quot;colin404&quot;})) //中间件只作用于/v1/login API接口\n</code></pre><p>Gin框架本身支持了一些中间件。</p><ul>\n<li><strong>gin.Logger()：</strong>Logger中间件会将日志写到gin.DefaultWriter，gin.DefaultWriter默认为 os.Stdout。</li>\n<li><strong>gin.Recovery()：</strong>Recovery中间件可以从任何panic恢复，并且写入一个500状态码。</li>\n<li><strong>gin.CustomRecovery(handle gin.RecoveryFunc)：</strong>类似Recovery中间件，但是在恢复时还会调用传入的handle方法进行处理。</li>\n<li><strong>gin.BasicAuth()：</strong>HTTP请求基本认证（使用用户名和密码进行认证）。</li>\n</ul><p>另外，Gin还支持自定义中间件。中间件其实是一个函数，函数类型为gin.HandlerFunc，HandlerFunc底层类型为func(*Context)。如下是一个Logger中间件的实现：</p><pre><code>package main\n\nimport (\n\t&quot;log&quot;\n\t&quot;time&quot;\n\n\t&quot;github.com/gin-gonic/gin&quot;\n)\n\nfunc Logger() gin.HandlerFunc {\n\treturn func(c *gin.Context) {\n\t\tt := time.Now()\n\n\t\t// 设置变量example\n\t\tc.Set(&quot;example&quot;, &quot;12345&quot;)\n\n\t\t// 请求之前\n\n\t\tc.Next()\n\n\t\t// 请求之后\n\t\tlatency := time.Since(t)\n\t\tlog.Print(latency)\n\n\t\t// 访问我们发送的状态\n\t\tstatus := c.Writer.Status()\n\t\tlog.Println(status)\n\t}\n}\n\nfunc main() {\n\tr := gin.New()\n\tr.Use(Logger())\n\n\tr.GET(&quot;/test&quot;, func(c *gin.Context) {\n\t\texample := c.MustGet(&quot;example&quot;).(string)\n\n\t\t// it would print: &quot;12345&quot;\n\t\tlog.Println(example)\n\t})\n\n\t// Listen and serve on 0.0.0.0:8080\n\tr.Run(&quot;:8080&quot;)\n}\n</code></pre><p>另外，还有很多开源的中间件可供我们选择，我把一些常用的总结在了表格里：</p><p><img src=\"https://static001.geekbang.org/resource/image/67/10/67137697a09d9f37bd87a81bf322f510.jpg?wh=1832x1521\" alt=\"\"></p><h3>认证、RequestID、跨域</h3><p>认证、RequestID、跨域这三个高级功能，都可以通过Gin的中间件来实现，例如：</p><pre><code>router := gin.New()\n\n// 认证\nrouter.Use(gin.BasicAuth(gin.Accounts{&quot;foo&quot;: &quot;bar&quot;, &quot;colin&quot;: &quot;colin404&quot;}))\n\n// RequestID\nrouter.Use(requestid.New(requestid.Config{\n    Generator: func() string {\n        return &quot;test&quot;\n    },\n}))\n\n// 跨域\n// CORS for https://foo.com and https://github.com origins, allowing:\n// - PUT and PATCH methods\n// - Origin header\n// - Credentials share\n// - Preflight requests cached for 12 hours\nrouter.Use(cors.New(cors.Config{\n    AllowOrigins:     []string{&quot;https://foo.com&quot;},\n    AllowMethods:     []string{&quot;PUT&quot;, &quot;PATCH&quot;},\n    AllowHeaders:     []string{&quot;Origin&quot;},\n    ExposeHeaders:    []string{&quot;Content-Length&quot;},\n    AllowCredentials: true,\n    AllowOriginFunc: func(origin string) bool {\n        return origin == &quot;https://github.com&quot;\n    },\n    MaxAge: 12 * time.Hour,\n}))\n</code></pre><h3>优雅关停</h3><p>Go项目上线后，我们还需要不断迭代来丰富项目功能、修复Bug等，这也就意味着，我们要不断地重启Go服务。对于HTTP服务来说，如果访问量大，重启服务的时候可能还有很多连接没有断开，请求没有完成。如果这时候直接关闭服务，这些连接会直接断掉，请求异常终止，这就会对用户体验和产品口碑造成很大影响。因此，这种关闭方式不是一种优雅的关闭方式。</p><p>这时候，我们期望HTTP服务可以在处理完所有请求后，正常地关闭这些连接，也就是优雅地关闭服务。我们有两种方法来优雅关闭HTTP服务，分别是借助第三方的Go包和自己编码实现。</p><p>方法一：借助第三方的Go包</p><p>如果使用第三方的Go包来实现优雅关闭，目前用得比较多的包是<a href=\"https://github.com/fvbock/endless\">fvbock/endless</a>。我们可以使用fvbock/endless来替换掉net/http的ListenAndServe方法，例如：</p><pre><code>router := gin.Default()\nrouter.GET(&quot;/&quot;, handler)\n// [...]\nendless.ListenAndServe(&quot;:4242&quot;, router)\n</code></pre><p>方法二：编码实现</p><p>借助第三方包的好处是可以稍微减少一些编码工作量，但缺点是引入了一个新的依赖包，因此我更倾向于自己编码实现。Go 1.8版本或者更新的版本，http.Server内置的Shutdown方法，已经实现了优雅关闭。下面是一个示例：</p><pre><code>// +build go1.8\n\npackage main\n\nimport (\n\t&quot;context&quot;\n\t&quot;log&quot;\n\t&quot;net/http&quot;\n\t&quot;os&quot;\n\t&quot;os/signal&quot;\n\t&quot;syscall&quot;\n\t&quot;time&quot;\n\n\t&quot;github.com/gin-gonic/gin&quot;\n)\n\nfunc main() {\n\trouter := gin.Default()\n\trouter.GET(&quot;/&quot;, func(c *gin.Context) {\n\t\ttime.Sleep(5 * time.Second)\n\t\tc.String(http.StatusOK, &quot;Welcome Gin Server&quot;)\n\t})\n\n\tsrv := &amp;http.Server{\n\t\tAddr:    &quot;:8080&quot;,\n\t\tHandler: router,\n\t}\n\n\t// Initializing the server in a goroutine so that\n\t// it won't block the graceful shutdown handling below\n\tgo func() {\n\t\tif err := srv.ListenAndServe(); err != nil &amp;&amp; err != http.ErrServerClosed {\n\t\t\tlog.Fatalf(&quot;listen: %s\\n&quot;, err)\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal to gracefully shutdown the server with\n\t// a timeout of 5 seconds.\n\tquit := make(chan os.Signal, 1)\n\t// kill (no param) default send syscall.SIGTERM\n\t// kill -2 is syscall.SIGINT\n\t// kill -9 is syscall.SIGKILL but can't be catch, so don't need add it\n\tsignal.Notify(quit, syscall.SIGINT, syscall.SIGTERM)\n\t&lt;-quit\n\tlog.Println(&quot;Shutting down server...&quot;)\n\n\t// The context is used to inform the server it has 5 seconds to finish\n\t// the request it is currently handling\n\tctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n\tdefer cancel()\n\tif err := srv.Shutdown(ctx); err != nil {\n\t\tlog.Fatal(&quot;Server forced to shutdown:&quot;, err)\n\t}\n\n\tlog.Println(&quot;Server exiting&quot;)\n}\n</code></pre><p>上面的示例中，需要把srv.ListenAndServe放在goroutine中执行，这样才不会阻塞到srv.Shutdown函数。因为我们把srv.ListenAndServe放在了goroutine中，所以需要一种可以让整个进程常驻的机制。</p><p>这里，我们借助了有缓冲channel，并且调用signal.Notify函数将该channel绑定到SIGINT、SIGTERM信号上。这样，收到SIGINT、SIGTERM信号后，quilt通道会被写入值，从而结束阻塞状态，程序继续运行，执行srv.Shutdown(ctx)，优雅关停HTTP服务。</p><h2>总结</h2><p>今天我们主要学习了Web服务的核心功能，以及如何开发这些功能。在实际的项目开发中， 我们一般会使用基于net/http包进行封装的优秀开源Web框架。</p><p>当前比较火的Go Web框架有 Gin、Beego、Echo、Revel、Martini。你可以根据需要进行选择。我比较推荐Gin，Gin也是目前比较受欢迎的Web框架。Gin Web框架支持Web服务的很多基础功能，例如 HTTP/HTTPS、JSON格式的数据、路由分组和匹配、一进程多服务等。</p><p>另外，Gin还支持Web服务的一些高级功能，例如 中间件、认证、RequestID、跨域和优雅关停等。</p><h2>课后练习</h2><ol>\n<li>使用 Gin 框架编写一个简单的Web服务，要求该Web服务可以解析参数、校验参数，并进行一些简单的业务逻辑处理，最终返回处理结果。欢迎在留言区分享你的成果，或者遇到的问题。</li>\n<li>思考下，如何给iam-apiserver的/healthz接口添加一个限流中间件，用来限制请求/healthz的频率。</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"23 | 应用构建实战：如何构建一个优秀的企业应用框架？","id":396523},"right":{"article_title":"25 | 认证机制：应用程序如何进行访问认证？","id":398410}}},{"article_id":398410,"article_title":"25 | 认证机制：应用程序如何进行访问认证？","article_content":"<p>你好，我是孔令飞，今天我们来聊聊如何进行访问认证。</p><p>保证应用的安全是软件开发的最基本要求，我们有多种途径来保障应用的安全，例如网络隔离、设置防火墙、设置IP黑白名单等。不过在我看来，这些更多是从运维角度来解决应用的安全问题。作为开发者，我们也可以从软件层面来保证应用的安全，这可以通过认证来实现。</p><p>这一讲，我以HTTP服务为例，来给你介绍下当前常见的四种认证方法：Basic、Digest、OAuth、Bearer。还有很多基于这四种方法的变种，这里就不再介绍了。</p><p>IAM项目使用了Basic、Bearer两种认证方法。这一讲，我先来介绍下这四种认证方法，下一讲，我会给你介绍下IAM项目是如何设计和实现访问认证功能的。</p><h2>认证和授权有什么区别？</h2><p>在介绍四种基本的认证方法之前，我想先带你区分下认证和授权，这是很多开发者都容易搞混的两个概念。</p><ul>\n<li><strong>认证（Authentication，英文缩写authn）</strong>：用来验证某个用户是否具有访问系统的权限。如果认证通过，该用户就可以访问系统，从而创建、修改、删除、查询平台支持的资源。</li>\n<li><strong>授权（Authorization，英文缩写authz）</strong>：用来验证某个用户是否具有访问某个资源的权限，如果授权通过，该用户就能对资源做增删改查等操作。</li>\n</ul><!-- [[[read_end]]] --><p>这里，我通过下面的图片，来让你明白二者的区别：</p><p><img src=\"https://static001.geekbang.org/resource/image/8b/96/8b63cc7a624dbdb32b37898180a37596.jpg?wh=2248x1747\" alt=\"\"></p><p>图中，我们有一个仓库系统，用户 james、colin、aaron分别创建了Product-A、Product-B、Product-C。现在用户colin通过用户名和密码（认证）成功登陆到仓库系统中，但他尝试访问Product-A、Product-C失败，因为这两个产品不属于他（授权失败），但他可以成功访问自己创建的资源Product-B（授权成功）。由此可见：<strong>认证证明了你是谁，授权决定了你能做什么。</strong></p><p>上面，我们介绍了认证和授权的区别。那么接下来，我们就回到这一讲的重心：应用程序如何进行访问认证。</p><h2>四种基本的认证方式</h2><p>常见的认证方式有四种，分别是 Basic、Digest、OAuth 和 Bearer。先来看下Basic认证。</p><h3>Basic</h3><p>Basic认证（基础认证），是最简单的认证方式。它简单地将<code>用户名:密码</code>进行base64编码后，放到HTTP Authorization Header中。HTTP请求到达后端服务后，后端服务会解析出Authorization Header中的base64字符串，解码获取用户名和密码，并将用户名和密码跟数据库中记录的值进行比较，如果匹配则认证通过。例如：</p><pre><code>$ basic=`echo -n 'admin:Admin@2021'|base64`\n$ curl -XPOST -H&quot;Authorization: Basic ${basic}&quot; http://127.0.0.1:8080/login\n</code></pre><p>通过base64编码，可以将密码以非明文的方式传输，增加一定的安全性。但是，base64不是加密技术，入侵者仍然可以截获base64字符串，并反编码获取用户名和密码。另外，即使Basic认证中密码被加密，入侵者仍可通过加密后的用户名和密码进行重放攻击。</p><p>所以，Basic认证虽然简单，但极不安全。使用Basic认证的唯一方式就是将它和SSL配合使用，来确保整个认证过程是安全的。</p><p>IAM项目中，为了支持前端通过用户名和密码登录，仍然使用了Basic认证，但前后端使用HTTPS来通信，保证了认证的安全性。</p><p>这里需要注意，在设计系统时，要遵循一个通用的原则：<strong>不要在请求参数中使用明文密码，也不要在任何存储中保存明文密码。</strong></p><h3>Digest</h3><p>Digest认证（摘要认证），是另一种 HTTP 认证协议，它与基本认证兼容，但修复了基本认证的严重缺陷。Digest具有如下特点：</p><ul>\n<li>绝不会用明文方式在网络上发送密码。</li>\n<li>可以有效防止恶意用户进行重放攻击。</li>\n<li>可以有选择地防止对报文内容的篡改。</li>\n</ul><p>摘要认证的过程见下图：</p><p><img src=\"https://static001.geekbang.org/resource/image/c6/b5/c693394977b4f91ae14b8c06f69056b5.jpg?wh=2248x1872\" alt=\"\"></p><p>在上图中，完成摘要认证需要下面这四步：</p><ol>\n<li>客户端请求服务端的资源。</li>\n<li>在客户端能够证明它知道密码从而确认其身份之前，服务端认证失败，返回<code>401 Unauthorized</code>，并返回<code>WWW-Authenticate</code>头，里面包含认证需要的信息。</li>\n<li>客户端根据<code>WWW-Authenticate</code>头中的信息，选择加密算法，并使用密码随机数nonce，计算出密码摘要response，并再次请求服务端。</li>\n<li>服务器将客户端提供的密码摘要与服务器内部计算出的摘要进行对比。如果匹配，就说明客户端知道密码，认证通过，并返回一些与授权会话相关的附加信息，放在Authorization-Info中。</li>\n</ol><p><code>WWW-Authenticate</code>头中包含的信息见下表：</p><p><img src=\"https://static001.geekbang.org/resource/image/59/9e/593e48602465b84165678bdc98467d9e.jpg?wh=2248x1755\" alt=\"\"></p><p>虽然使用摘要可以避免密码以明文方式发送，一定程度上保护了密码的安全性，但是仅仅隐藏密码并不能保证请求是安全的。因为请求（包括密码摘要）仍然可以被截获，这样就可以重放给服务器，带来安全问题。</p><p>为了防止重放攻击，服务器向客户端发送了密码随机数nonce，nonce每次请求都会变化。客户端会根据nonce生成密码摘要，这种方式，可以使摘要随着随机数的变化而变化。服务端收到的密码摘要只对特定的随机数有效，而没有密码的话，攻击者就无法计算出正确的摘要，这样我们就可以防止重放攻击。</p><p>摘要认证可以保护密码，比基本认证安全很多。但摘要认证并不能保护内容，所以仍然要与HTTPS配合使用，来确保通信的安全。</p><h3>OAuth</h3><p>OAuth（开放授权）是一个开放的授权标准，允许用户让第三方应用访问该用户在某一Web服务上存储的私密资源（例如照片、视频、音频等），而无需将用户名和密码提供给第三方应用。OAuth目前的版本是2.0版。</p><p>OAuth2.0一共分为四种授权方式，分别为密码式、隐藏式、凭借式和授权码模式。接下来，我们就具体介绍下每一种授权方式。</p><p><strong>第一种，密码式。</strong>密码式的授权方式，就是用户把用户名和密码直接告诉给第三方应用，然后第三方应用使用用户名和密码换取令牌。所以，使用此授权方式的前提是无法采用其他授权方式，并且用户高度信任某应用。</p><p>认证流程如下：</p><ol>\n<li>网站A向用户发出获取用户名和密码的请求；</li>\n<li>用户同意后，网站A凭借用户名和密码向网站B换取令牌；</li>\n<li>网站B验证用户身份后，给出网站A令牌，网站A凭借令牌可以访问网站B对应权限的资源。</li>\n</ol><p><strong>第二种，隐藏式。</strong>这种方式适用于前端应用。认证流程如下：</p><ol>\n<li>A网站提供一个跳转到B网站的链接，用户点击后跳转至B网站，并向用户请求授权；</li>\n<li>用户登录B网站，同意授权后，跳转回A网站指定的重定向redirect_url地址，并携带B网站返回的令牌，用户在B网站的数据给A网站使用。</li>\n</ol><p>这个授权方式存在着“中间人攻击”的风险，因此只能用于一些安全性要求不高的场景，并且令牌的有效时间要非常短。</p><p><strong>第三种，凭借式。</strong>这种方式是在命令行中请求授权，适用于没有前端的命令行应用。认证流程如下：</p><ol>\n<li>应用A在命令行向应用B请求授权，此时应用A需要携带应用B提前颁发的secretID和secretKey，其中secretKey出于安全性考虑，需在后端发送；</li>\n<li>应用B接收到secretID和secretKey，并进行身份验证，验证通过后返回给应用A令牌。</li>\n</ol><p><strong>第四种，授权码模式。</strong>这种方式就是第三方应用先提前申请一个授权码，然后再使用授权码来获取令牌。相对来说，这种方式安全性更高，前端传送授权码，后端存储令牌，与资源的通信都是在后端，可以避免令牌的泄露导致的安全问题。认证流程如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/54/a6/547b6362aba9e9ce8b72b511afee94a6.jpg?wh=2248x1127\" alt=\"\"></p><ol>\n<li>A网站提供一个跳转到B网站的链接+redirect_url，用户点击后跳转至B网站；</li>\n<li>用户携带向B网站提前申请的client_id，向B网站发起身份验证请求；</li>\n<li>用户登录B网站，通过验证，授予A网站权限，此时网站跳转回redirect_url，其中会有B网站通过验证后的授权码附在该url后；</li>\n<li>网站A携带授权码向网站B请求令牌，网站B验证授权码后，返回令牌即access_token。</li>\n</ol><h3>Bearer</h3><p>Bearer认证，也称为令牌认证，是一种 HTTP 身份验证方法。Bearer认证的核心是bearer token。bearer token是一个加密字符串，通常由服务端根据密钥生成。客户端在请求服务端时，必须在请求头中包含<code>Authorization: Bearer &lt;token&gt;</code>。服务端收到请求后，解析出 <code>&lt;token&gt;</code> ，并校验 <code>&lt;token&gt;</code> 的合法性，如果校验通过，则认证通过。跟基本认证一样，Bearer认证需要配合HTTPS一起使用，来保证认证安全性。</p><p>当前最流行的token编码方式是JSON Web Token（JWT，音同 jot，详见 <a href=\"https://tools.ietf.org/html/rfc7519\">JWT RFC 7519</a>）。接下来，我通过讲解JWT认证来帮助你了解Bearer认证的原理。</p><h2>基于JWT的Token认证机制实现</h2><p>在典型业务场景中，为了区分用户和保证安全，必须对 API 请求进行鉴权，但是不能要求每一个请求都进行登录操作。合理做法是，在第一次登录之后产生一个有一定有效期的 token，并将它存储在浏览器的 Cookie 或 LocalStorage 之中。之后的请求都携带这个 token ，请求到达服务器端后，服务器端用这个 token 对请求进行认证。在第一次登录之后，服务器会将这个 token 用文件、数据库或缓存服务器等方法存下来，用于之后请求中的比对。</p><p>或者也可以采用更简单的方法：直接用密钥来签发Token。这样，就可以省下额外的存储，也可以减少每一次请求时对数据库的查询压力。这种方法在业界已经有一种标准的实现方式，就是JWT。</p><p>接下来，我就来具体介绍下JWT。</p><h3>JWT简介</h3><p>JWT是Bearer Token的一个具体实现，由JSON数据格式组成，通过HASH散列算法生成一个字符串。该字符串可以用来进行授权和信息交换。</p><p>使用JWT Token进行认证有很多优点，比如说无需在服务端存储用户数据，可以减轻服务端压力；而且采用JSON数据格式，比较易读。除此之外，使用JWT Token还有跨语言、轻量级等优点。</p><h3>JWT认证流程</h3><p>使用JWT Token进行认证的流程如下图：</p><p><img src=\"https://static001.geekbang.org/resource/image/48/01/480397e0a0e1503a350a082f44ec5901.jpg?wh=2248x1471\" alt=\"\"></p><p>具体可以分为四步：</p><ol>\n<li>\n<p>客户端使用用户名和密码请求登录。</p>\n</li>\n<li>\n<p>服务端收到请求后，会去验证用户名和密码。如果用户名和密码跟数据库记录不一致，则验证失败；如果一致则验证通过，服务端会签发一个Token返回给客户端。</p>\n</li>\n<li>\n<p>客户端收到请求后会将Token缓存起来，比如放在浏览器Cookie中或者LocalStorage中，之后每次请求都会携带该Token。</p>\n</li>\n<li>\n<p>服务端收到请求后，会验证请求中的Token，验证通过则进行业务逻辑处理，处理完后返回处理后的结果。</p>\n</li>\n</ol><h3>JWT格式</h3><p>JWT由三部分组成，分别是Header、Payload 和 Signature，它们之间用圆点<code>.</code>连接，例如：</p><pre><code>eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2NDI4NTY2MzcsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MzUwODA2MzcsInN1YiI6ImFkbWluIn0.Shw27RKENE_2MVBq7-c8OmgYdF92UmdwS8xE-Fts2FM\n</code></pre><p>JWT中，每部分包含的信息见下图：</p><p><img src=\"https://static001.geekbang.org/resource/image/0c/08/0c6657bc2d0fd2a98737660c7c373e08.jpg?wh=2248x1732\" alt=\"\"></p><p>下面我来具体介绍下这三部分，以及它们包含的信息。</p><ol>\n<li>Header</li>\n</ol><p>JWT Token的Header中，包含两部分信息：一是Token的类型，二是Token所使用的加密算法。</p><p>例如：</p><pre><code>{\n  &quot;typ&quot;: &quot;JWT&quot;,\n  &quot;alg&quot;: &quot;HS256&quot;\n}\n</code></pre><p>参数说明：</p><ul>\n<li>typ：说明Token类型是JWT。</li>\n<li>alg：说明Token的加密算法，这里是HS256（alg算法可以有多种）。</li>\n</ul><p>这里，我们将Header进行base64编码：</p><pre><code>$ echo -n '{&quot;typ&quot;:&quot;JWT&quot;,&quot;alg&quot;:&quot;HS256&quot;}'|base64\neyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9\n</code></pre><p>在某些场景下，可能还会有kid选项，用来标识一个密钥ID，例如：</p><pre><code>{\n    &quot;alg&quot;: &quot;HS256&quot;,\n    &quot;kid&quot;: &quot;XhbY3aCrfjdYcP1OFJRu9xcno8JzSbUIvGE2&quot;,\n    &quot;typ&quot;: &quot;JWT&quot;\n}\n</code></pre><ol start=\"2\">\n<li>Payload（载荷）</li>\n</ol><p>Payload中携带Token的具体内容由三部分组成：JWT标准中注册的声明（可选）、公共的声明、私有的声明。下面来分别看下。</p><p><strong>JWT标准中注册的声明部分，有以下标准字段</strong>：</p><p><img src=\"https://static001.geekbang.org/resource/image/c2/e3/c271d01d41dc7f4a45a9f2e8892057e3.png?wh=2248x2077\" alt=\"\"></p><p>本例中的payload内容为：</p><pre><code>{\n  &quot;aud&quot;: &quot;iam.authz.marmotedu.com&quot;,\n  &quot;exp&quot;: 1604158987,\n  &quot;iat&quot;: 1604151787,\n  &quot;iss&quot;: &quot;iamctl&quot;,\n  &quot;nbf&quot;: 1604151787\n}\n</code></pre><p>这里，我们将Payload 进行base64编码：</p><pre><code>$ echo -n '{&quot;aud&quot;:&quot;iam.authz.marmotedu.com&quot;,&quot;exp&quot;:1604158987,&quot;iat&quot;:1604151787,&quot;iss&quot;:&quot;iamctl&quot;,&quot;nbf&quot;:1604151787}'|base64\neyJhdWQiOiJpYW0uYXV0aHoubWFybW90ZWR1LmNvbSIsImV4cCI6MTYwNDE1ODk4NywiaWF0Ijox\nNjA0MTUxNzg3LCJpc3MiOiJpYW1jdGwiLCJuYmYiOjE2MDQxNTE3ODd9\n</code></pre><p>除此之外，还有公共的声明和私有的声明。公共的声明可以添加任何的需要的信息，一般添加用户的相关信息或其他业务需要的信息，注意不要添加敏感信息；私有声明是客户端和服务端所共同定义的声明，因为base64是对称解密的，所以一般不建议存放敏感信息。</p><ol start=\"3\">\n<li>Signature（签名）</li>\n</ol><p>Signature是Token的签名部分，通过如下方式生成：将Header和Payload分别base64编码后，用 <code>.</code> 连接。然后再使用Header中声明的加密方式，利用secretKey对连接后的字符串进行加密，加密后的字符串即为最终的Signature。</p><p>secretKey是密钥，保存在服务器中，一般通过配置文件来保存，例如：</p><p><img src=\"https://static001.geekbang.org/resource/image/b1/d3/b183d2695c01cd863f782edf0a6d12d3.png?wh=1024x256\" alt=\"\"></p><p>这里要注意，<strong>密钥一定不能泄露。密钥泄露后，入侵者可以使用该密钥来签发JWT Token，从而入侵系统</strong>。</p><p>最后生成的Token如下：</p><pre><code>eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJhdWQiOiJpYW0uYXV0aHoubWFybW90ZWR1LmNvbSIsImV4cCI6MTYwNDE1ODk4NywiaWF0IjoxNjA0MTUxNzg3LCJpc3MiOiJpYW1jdGwiLCJuYmYiOjE2MDQxNTE3ODd9.LjxrK9DuAwAzUD8-9v43NzWBN7HXsSLfebw92DKd1JQ\n</code></pre><p>签名后服务端会返回生成的 Token，客户端下次请求会携带该 Token。服务端收到 Token 后会解析出 header.payload，然后用相同的加密算法和密钥对 header.payload 再进行一次加密，得到 Signature。并且，对比加密后的 Signature 和收到的 Signature 是否相同，如果相同则验证通过，不相同则返回 <code>HTTP 401 Unauthorized</code> 的错误。</p><p>最后，关于JWT的使用，我还有两点建议：</p><ul>\n<li>不要存放敏感信息在Token里；</li>\n<li>Payload中的exp值不要设置得太大，一般开发版本 7 天，线上版本 2 小时。当然，你也可以根据需要自行设置。</li>\n</ul><h2>总结</h2><p>在开发Go应用时，我们需要通过认证来保障应用的安全。认证，用来验证某个用户是否具有访问系统的权限，如果认证通过，该用户就可以访问系统，从而创建、修改、删除、查询平台支持的资源。业界目前有四种常用的认证方式：Basic、Digest、OAuth、Bearer。其中Basic和Bearer用得最多。</p><p>Basic认证通过用户名和密码来进行认证，主要用在用户登录场景；Bearer认证通过Token来进行认证，通常用在API调用场景。不管是Basic认证还是Bearer认证，都需要结合HTTPS来使用，来最大程度地保证请求的安全性。</p><p>Basic认证简单易懂，但是Bearer认证有一定的复杂度，所以这一讲的后半部分通过JWT Token，讲解了Bearer Token认证的原理。</p><p>JWT Token是Bearer认证的一种比较好的实现，主要包含了3个部分：</p><ul>\n<li>Header：包含了Token的类型、Token使用的加密算法。在某些场景下，你还可以添加kid字段，用来标识一个密钥ID。</li>\n<li>Payload：Payload中携带Token的具体内容，由JWT标准中注册的声明、公共的声明和私有的声明三部分组成。</li>\n<li>Signature：Signature是Token的签名部分，程序通过验证Signature是否合法，来决定认证是否通过。</li>\n</ul><h2>课后练习</h2><ol>\n<li>思考下：使用JWT作为登录凭证，如何解决token注销问题？</li>\n<li>思考下：Token是存放在LocalStorage中好，还是存放在Cookie中好？</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"24 | Web 服务：Web 服务核心功能有哪些，如何实现？","id":397475},"right":{"article_title":"26 | IAM项目是如何设计和实现访问认证功能的？","id":399307}}},{"article_id":399307,"article_title":"26 | IAM项目是如何设计和实现访问认证功能的？","article_content":"<p>你好，我是孔令飞。</p><p>上一讲，我们学习了应用认证常用的四种方式：Basic、Digest、OAuth、Bearer。这一讲，我们再来看下IAM项目是如何设计和实现认证功能的。</p><p>IAM项目用到了Basic认证和Bearer认证。其中，Basic认证用在前端登陆的场景，Bearer认证用在调用后端API服务的场景下。</p><p>接下来，我们先来看下IAM项目认证功能的整体设计思路。</p><h2>如何设计IAM项目的认证功能？</h2><p>在认证功能开发之前，我们要根据需求，认真考虑下如何设计认证功能，并在设计阶段通过技术评审。那么我们先来看下，如何设计IAM项目的认证功能。</p><p>首先，我们要<strong>梳理清楚认证功能的使用场景和需求</strong>。</p><ul>\n<li>IAM项目的iam-apiserver服务，提供了IAM系统的管理流功能接口，它的客户端可以是前端（这里也叫控制台），也可以是App端。</li>\n<li>为了方便用户在Linux系统下调用，IAM项目还提供了iamctl命令行工具。</li>\n<li>为了支持在第三方代码中调用iam-apiserver提供的API接口，还支持了API调用。</li>\n<li>为了提高用户在代码中调用API接口的效率，IAM项目提供了Go SDK。</li>\n</ul><p>可以看到，iam-apiserver有很多客户端，每种客户端适用的认证方式是有区别的。</p><!-- [[[read_end]]] --><p>控制台、App端需要登录系统，所以需要使用<code>用户名：密码</code>这种认证方式，也即Basic认证。iamctl、API调用、Go SDK因为可以不用登录系统，所以可以采用更安全的认证方式：Bearer认证。同时，Basic认证作为iam-apiserver已经集成的认证方式，仍然可以供iamctl、API调用、Go SDK使用。</p><p>这里有个地方需要注意：如果iam-apiserver采用Bearer Token的认证方式，目前最受欢迎的Token格式是JWT Token。而JWT Token需要密钥（后面统一用secretKey来指代），因此需要在iam-apiserver服务中为每个用户维护一个密钥，这样会增加开发和维护成本。</p><p>业界有一个更好的实现方式：将iam-apiserver提供的API接口注册到API网关中，通过API网关中的Token认证功能，来实现对iam-apiserver API接口的认证。有很多API网关可供选择，例如腾讯云API网关、Tyk、Kong等。</p><p>这里需要你注意：通过iam-apiserver创建的密钥对是提供给iam-authz-server使用的。</p><p>另外，我们还需要调用iam-authz-server提供的RESTful API接口：<code>/v1/authz</code>，来进行资源授权。API调用比较适合采用的认证方式是Bearer认证。</p><p>当然，<code>/v1/authz</code>也可以直接注册到API网关中。在实际的Go项目开发中，也是我推荐的一种方式。但在这里，为了展示实现Bearer认证的过程，iam-authz-server自己实现了Bearer认证。讲到iam-authz-server Bearer认证实现的时候，我会详细介绍这一点。</p><p>Basic认证需要用户名和密码，Bearer认证则需要密钥，所以iam-apiserver需要将用户名/密码、密钥等信息保存在后端的MySQL中，持久存储起来。</p><p>在进行认证的时候，需要获取密码或密钥进行反加密，这就需要查询密码或密钥。查询密码或密钥有两种方式。一种是在请求到达时查询数据库。因为数据库的查询操作延时高，会导致API接口延时较高，所以不太适合用在数据流组件中。另外一种是将密码或密钥缓存在内存中，这样请求到来时，就可以直接从内存中查询，从而提升查询速度，提高接口性能。</p><p>但是，将密码或密钥缓存在内存中时，就要考虑内存和数据库的数据一致性，这会增加代码实现的复杂度。因为管控流组件对性能延时要求不那么敏感，而数据流组件则一定要实现非常高的接口性能，所以iam-apiserver在请求到来时查询数据库，而iam-authz-server则将密钥信息缓存在内存中。</p><p>那在这里，可以总结出一张IAM项目的认证设计图：</p><p><img src=\"https://static001.geekbang.org/resource/image/7e/b6/7eed8e2364d358a8483c671d972fd2b6.jpg?wh=2248x1094\" alt=\"\"></p><p>另外，为了将控制流和数据流区分开来，密钥的CURD操作也放在了iam-apiserver中，但是iam-authz-server需要用到这些密钥信息。为了解决这个问题，目前的做法是：</p><ul>\n<li>iam-authz-server通过gRPC API请求iam-apiserver，获取所有的密钥信息；</li>\n<li>当iam-apiserver有密钥更新时，会Pub一条消息到Redis Channel中。因为iam-authz-server订阅了同一个Redis Channel，iam-authz-searver监听到channel有新消息时，会获取、解析消息，并更新它缓存的密钥信息。这样，我们就能确保iam-authz-server内存中缓存的密钥和iam-apiserver中的密钥保持一致。</li>\n</ul><p>学到这里，你可能会问：将所有密钥都缓存在iam-authz-server中，那岂不是要占用很大的内存？别担心，这个问题我也想过，并且替你计算好了：8G的内存大概能保存约8千万个密钥信息，完全够用。后期不够用的话，可以加大内存。</p><p>不过这里还是有个小缺陷：如果Redis down掉，或者出现网络抖动，可能会造成iam-apiserver中和iam-authz-server内存中保存的密钥数据不一致，但这不妨碍我们学习认证功能的设计和实现。至于如何保证缓存系统的数据一致性，我会在新一期的特别放送里专门介绍下。</p><p>最后注意一点：Basic 认证请求和 Bearer 认证请求都可能被截获并重放。所以，为了确保Basic认证和Bearer认证的安全性，<strong>和服务端通信时都需要配合使用HTTPS协议</strong>。</p><h2>IAM项目是如何实现Basic认证的？</h2><p>我们已经知道，IAM项目中主要用了Basic 和 Bearer 这两种认证方式。我们要支持Basic认证和Bearer认证，并根据需要选择不同的认证方式，这很容易让我们想到使用设计模式中的策略模式来实现。所以，在IAM项目中，我将每一种认证方式都视作一个策略，通过选择不同的策略，来使用不同的认证方法。</p><p>IAM项目实现了如下策略：</p><ul>\n<li><a href=\"https://github.com/marmotedu/iam/blob/v1.0.0/internal/pkg/middleware/auth/auto.go\">auto策略</a>：该策略会根据HTTP头<code>Authorization: Basic XX.YY.ZZ</code>和<code>Authorization: Bearer XX.YY.ZZ</code>自动选择使用Basic认证还是Bearer认证。</li>\n<li><a href=\"https://github.com/marmotedu/iam/blob/v1.0.0/internal/pkg/middleware/auth/basic.go\">basic策略</a>：该策略实现了Basic认证。</li>\n<li><a href=\"https://github.com/marmotedu/iam/blob/v1.0.0/internal/pkg/middleware/auth/jwt.go\">jwt策略</a>：该策略实现了Bearer认证，JWT是Bearer认证的具体实现。</li>\n<li><a href=\"https://github.com/marmotedu/iam/blob/v1.0.0/internal/pkg/middleware/auth/cache.go\">cache策略</a>：该策略其实是一个Bearer认证的实现，Token采用了JWT格式，因为Token中的密钥ID是从内存中获取的，所以叫Cache认证。这一点后面会详细介绍。</li>\n</ul><p>iam-apiserver通过创建需要的认证策略，并加载到需要认证的API路由上，来实现API认证。具体代码如下：</p><pre><code>jwtStrategy, _ := newJWTAuth().(auth.JWTStrategy)\ng.POST(&quot;/login&quot;, jwtStrategy.LoginHandler)\ng.POST(&quot;/logout&quot;, jwtStrategy.LogoutHandler)\n// Refresh time can be longer than token timeout\ng.POST(&quot;/refresh&quot;, jwtStrategy.RefreshHandler)\n</code></pre><p>上述代码中，我们通过<a href=\"https://github.com/marmotedu/iam/blob/75b978b722f0af3d6aefece3f9668269be3f5b2e/internal/apiserver/auth.go#L59\">newJWTAuth</a>函数创建了<code>auth.JWTStrategy</code>类型的变量，该变量包含了一些认证相关函数。</p><ul>\n<li>LoginHandler：实现了Basic认证，完成登陆认证。</li>\n<li>RefreshHandler：重新刷新Token的过期时间。</li>\n<li>LogoutHandler：用户注销时调用。登陆成功后，如果在Cookie中设置了认证相关的信息，执行LogoutHandler则会清空这些信息。</li>\n</ul><p>下面，我来分别介绍下LoginHandler、RefreshHandler和LogoutHandler。</p><ol>\n<li>LoginHandler</li>\n</ol><p>这里，我们来看下LoginHandler Gin中间件，该函数定义位于<code>github.com/appleboy/gin-jwt</code>包的<a href=\"https://github.com/appleboy/gin-jwt/blob/v2.6.4/auth_jwt.go#L431\">auth_jwt.go</a>文件中。</p><pre><code>func (mw *GinJWTMiddleware) LoginHandler(c *gin.Context) {\n\tif mw.Authenticator == nil {\n\t\tmw.unauthorized(c, http.StatusInternalServerError, mw.HTTPStatusMessageFunc(ErrMissingAuthenticatorFunc, c))\n\t\treturn\n\t}\n\n\tdata, err := mw.Authenticator(c)\n\n\tif err != nil {\n\t\tmw.unauthorized(c, http.StatusUnauthorized, mw.HTTPStatusMessageFunc(err, c))\n\t\treturn\n\t}\n\n\t// Create the token\n\ttoken := jwt.New(jwt.GetSigningMethod(mw.SigningAlgorithm))\n\tclaims := token.Claims.(jwt.MapClaims)\n\n\tif mw.PayloadFunc != nil {\n\t\tfor key, value := range mw.PayloadFunc(data) {\n\t\t\tclaims[key] = value\n\t\t}\n\t}\n\n\texpire := mw.TimeFunc().Add(mw.Timeout)\n\tclaims[&quot;exp&quot;] = expire.Unix()\n\tclaims[&quot;orig_iat&quot;] = mw.TimeFunc().Unix()\n\ttokenString, err := mw.signedString(token)\n\n\tif err != nil {\n\t\tmw.unauthorized(c, http.StatusUnauthorized, mw.HTTPStatusMessageFunc(ErrFailedTokenCreation, c))\n\t\treturn\n\t}\n\n\t// set cookie\n\tif mw.SendCookie {\n\t\texpireCookie := mw.TimeFunc().Add(mw.CookieMaxAge)\n\t\tmaxage := int(expireCookie.Unix() - mw.TimeFunc().Unix())\n\n\t\tif mw.CookieSameSite != 0 {\n\t\t\tc.SetSameSite(mw.CookieSameSite)\n\t\t}\n\n\t\tc.SetCookie(\n\t\t\tmw.CookieName,\n\t\t\ttokenString,\n\t\t\tmaxage,\n\t\t\t&quot;/&quot;,\n\t\t\tmw.CookieDomain,\n\t\t\tmw.SecureCookie,\n\t\t\tmw.CookieHTTPOnly,\n\t\t)\n\t}\n\n\tmw.LoginResponse(c, http.StatusOK, tokenString, expire)\n}\n</code></pre><p>从LoginHandler函数的代码实现中，我们可以知道，LoginHandler函数会执行<code>Authenticator</code>函数，来完成Basic认证。如果认证通过，则会签发JWT Token，并执行 <code>PayloadFunc</code>函数设置Token Payload。如果我们设置了 <code>SendCookie=true</code> ，还会在Cookie中添加认证相关的信息，例如 Token、Token的生命周期等，最后执行 <code>LoginResponse</code> 方法返回Token和Token的过期时间。</p><p><code>Authenticator</code>、<code>PayloadFunc</code>、<code>LoginResponse</code>这三个函数，是我们在创建JWT认证策略时指定的。下面我来分别介绍下。</p><p>先来看下<a href=\"https://github.com/marmotedu/iam/blob/v1.0.0/internal/apiserver/auth.go#L97\">Authenticator</a>函数。Authenticator函数从HTTP Authorization Header中获取用户名和密码，并校验密码是否合法。</p><pre><code>func authenticator() func(c *gin.Context) (interface{}, error) {\n\treturn func(c *gin.Context) (interface{}, error) {\n\t\tvar login loginInfo\n\t\tvar err error\n\n\t\t// support header and body both\n\t\tif c.Request.Header.Get(&quot;Authorization&quot;) != &quot;&quot; {\n\t\t\tlogin, err = parseWithHeader(c)\n\t\t} else {\n\t\t\tlogin, err = parseWithBody(c)\n\t\t}\n\t\tif err != nil {\n\t\t\treturn &quot;&quot;, jwt.ErrFailedAuthentication\n\t\t}\n\n\t\t// Get the user information by the login username.\n\t\tuser, err := store.Client().Users().Get(c, login.Username, metav1.GetOptions{})\n\t\tif err != nil {\n\t\t\tlog.Errorf(&quot;get user information failed: %s&quot;, err.Error())\n\n\t\t\treturn &quot;&quot;, jwt.ErrFailedAuthentication\n\t\t}\n\n\t\t// Compare the login password with the user password.\n\t\tif err := user.Compare(login.Password); err != nil {\n\t\t\treturn &quot;&quot;, jwt.ErrFailedAuthentication\n\t\t}\n\n\t\treturn user, nil\n\t}\n}\n</code></pre><p><code>Authenticator</code>函数需要获取用户名和密码。它首先会判断是否有<code>Authorization</code>请求头，如果有，则调用<code>parseWithHeader</code>函数获取用户名和密码，否则调用<code>parseWithBody</code>从Body中获取用户名和密码。如果都获取失败，则返回认证失败错误。</p><p>所以，IAM项目的Basic支持以下两种请求方式：</p><pre><code>$ curl -XPOST -H&quot;Authorization: Basic YWRtaW46QWRtaW5AMjAyMQ==&quot; http://127.0.0.1:8080/login # 用户名:密码通过base64加码后，通过HTTP Authorization Header进行传递，因为密码非明文，建议使用这种方式。\n$ curl -s -XPOST -H'Content-Type: application/json' -d'{&quot;username&quot;:&quot;admin&quot;,&quot;password&quot;:&quot;Admin@2021&quot;}' http://127.0.0.1:8080/login # 用户名和密码在HTTP Body中传递，因为密码是明文，所以这里不建议实际开发中，使用这种方式。\n</code></pre><p>这里，我们来看下 <code>parseWithHeader</code> 是如何获取用户名和密码的。假设我们的请求为：</p><pre><code>$ curl -XPOST -H&quot;Authorization: Basic YWRtaW46QWRtaW5AMjAyMQ==&quot; http://127.0.0.1:8080/login\n</code></pre><p>其中，<code>YWRtaW46QWRtaW5AMjAyMQ==</code>值由以下命令生成：</p><pre><code>$ echo -n 'admin:Admin@2021'|base64\nYWRtaW46QWRtaW5AMjAyMQ==\n</code></pre><p><code>parseWithHeader</code>实际上执行的是上述命令的逆向步骤：</p><ol>\n<li>获取<code>Authorization</code>头的值，并调用strings.SplitN函数，获取一个切片变量auth，其值为 <code>[\"Basic\",\"YWRtaW46QWRtaW5AMjAyMQ==\"]</code> 。</li>\n<li>将<code>YWRtaW46QWRtaW5AMjAyMQ==</code>进行base64解码，得到<code>admin:Admin@2021</code>。</li>\n<li>调用<code>strings.SplitN</code>函数获取 <code>admin:Admin@2021</code> ，得到用户名为<code>admin</code>，密码为<code>Admin@2021</code>。</li>\n</ol><p><code>parseWithBody</code>则是调用了Gin的<code>ShouldBindJSON</code>函数，来从Body中解析出用户名和密码。</p><p>获取到用户名和密码之后，程序会从数据库中查询出该用户对应的加密后的密码，这里我们假设是<code>xxxx</code>。最后<code>authenticator</code>函数调用<code>user.Compare</code>来判断 <code>xxxx</code> 是否和通过<code>user.Compare</code>加密后的字符串相匹配，如果匹配则认证成功，否则返回认证失败。</p><p>再来看下<code>PayloadFunc</code>函数：</p><pre><code>func payloadFunc() func(data interface{}) jwt.MapClaims {\n    return func(data interface{}) jwt.MapClaims {\n        claims := jwt.MapClaims{\n            &quot;iss&quot;: APIServerIssuer,\n            &quot;aud&quot;: APIServerAudience,\n        }\n        if u, ok := data.(*v1.User); ok {\n            claims[jwt.IdentityKey] = u.Name\n            claims[&quot;sub&quot;] = u.Name\n        }\n\n        return claims\n    }\n}\n</code></pre><p>PayloadFunc函数会设置JWT Token中Payload部分的 iss、aud、sub、identity字段，供后面使用。</p><p>再来看下我们刚才说的第三个函数，LoginResponse函数：</p><pre><code>func loginResponse() func(c *gin.Context, code int, token string, expire time.Time) {\n    return func(c *gin.Context, code int, token string, expire time.Time) {\n        c.JSON(http.StatusOK, gin.H{\n            &quot;token&quot;:  token,\n            &quot;expire&quot;: expire.Format(time.RFC3339),\n        })\n    }\n}\n</code></pre><p>该函数用来在Basic认证成功之后，返回Token和Token的过期时间给调用者：</p><pre><code>$ curl -XPOST -H&quot;Authorization: Basic YWRtaW46QWRtaW5AMjAyMQ==&quot; http://127.0.0.1:8080/login\n{&quot;expire&quot;:&quot;2021-09-29T01:38:49+08:00&quot;,&quot;token&quot;:&quot;XX.YY.ZZ&quot;}\n</code></pre><p>登陆成功后，iam-apiserver会返回Token和Token的过期时间，前端可以将这些信息缓存在Cookie中或LocalStorage中，之后的请求都可以使用Token来进行认证。使用Token进行认证，不仅能够提高认证的安全性，还能够避免查询数据库，从而提高认证效率。</p><ol start=\"2\">\n<li>RefreshHandler</li>\n</ol><p><code>RefreshHandler</code>函数会先执行Bearer认证，如果认证通过，则会重新签发Token。</p><ol start=\"3\">\n<li>LogoutHandler</li>\n</ol><p>最后，来看下<code>LogoutHandler</code>函数：</p><pre><code>func (mw *GinJWTMiddleware) LogoutHandler(c *gin.Context) {\n    // delete auth cookie\n    if mw.SendCookie {\n        if mw.CookieSameSite != 0 {\n            c.SetSameSite(mw.CookieSameSite)\n        }\n\n        c.SetCookie(\n            mw.CookieName,\n            &quot;&quot;,\n            -1,\n            &quot;/&quot;,\n            mw.CookieDomain,\n            mw.SecureCookie,\n            mw.CookieHTTPOnly,\n        )\n    }\n\n    mw.LogoutResponse(c, http.StatusOK)\n}\n</code></pre><p>可以看到，LogoutHandler其实是用来清空Cookie中Bearer认证相关信息的。</p><p>最后，我们来做个总结：Basic认证通过用户名和密码来进行认证，通常用在登陆接口/login中。用户登陆成功后，会返回JWT Token，前端会保存该JWT Token在浏览器的Cookie或LocalStorage中，供后续请求使用。</p><p>后续请求时，均会携带该Token，以完成Bearer认证。另外，有了登陆接口，一般还会配套/logout接口和/refresh接口，分别用来进行注销和刷新Token。</p><p>这里你可能会问，为什么要刷新Token？因为通过登陆接口签发的Token有过期时间，有了刷新接口，前端就可以根据需要，自行刷新Token的过期时间。过期时间可以通过iam-apiserver配置文件的<a href=\"https://github.com/marmotedu/iam/blob/master/configs/iam-apiserver.yaml#L66\">jwt.timeout</a>配置项来指定。登陆后签发Token时，使用的密钥（secretKey）由<a href=\"https://github.com/marmotedu/iam/blob/master/configs/iam-apiserver.yaml#L65\">jwt.key</a>配置项来指定。</p><h2>IAM项目是如何实现Bearer认证的？</h2><p>上面我们介绍了Basic认证。这里，我再来介绍下IAM项目中Bearer认证的实现方式。</p><p>IAM项目中有两个地方实现了Bearer认证，分别是 iam-apiserver 和 iam-authz-server。下面我来分别介绍下它们是如何实现Bearer认证的。</p><h3>iam-authz-server Bearer认证实现</h3><p>先来看下iam-authz-server是如何实现Bearer认证的。</p><p>iam-authz-server通过在 <code>/v1</code> 路由分组中加载cache认证中间件来使用cache认证策略：</p><pre><code>auth := newCacheAuth()\napiv1 := g.Group(&quot;/v1&quot;, auth.AuthFunc())\n</code></pre><p>来看下<a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/authzserver/jwt.go#L15\">newCacheAuth</a>函数：</p><pre><code>func newCacheAuth() middleware.AuthStrategy {\n    return auth.NewCacheStrategy(getSecretFunc())\n}\n\nfunc getSecretFunc() func(string) (auth.Secret, error) {\n    return func(kid string) (auth.Secret, error) {\n        cli, err := store.GetStoreInsOr(nil)\n        if err != nil {\n            return auth.Secret{}, errors.Wrap(err, &quot;get store instance failed&quot;)\n        }\n\n        secret, err := cli.GetSecret(kid)\n        if err != nil {\n            return auth.Secret{}, err\n        }\n\n        return auth.Secret{\n            Username: secret.Username,\n            ID:       secret.SecretId,\n            Key:      secret.SecretKey,\n            Expires:  secret.Expires,\n        }, nil\n    }\n}\n</code></pre><p>newCacheAuth函数调用<code>auth.NewCacheStrategy</code>创建了一个cache认证策略，创建时传入了<code>getSecretFunc</code>函数，该函数会返回密钥的信息。密钥信息包含了以下字段：</p><pre><code>type Secret struct {\n    Username string\n    ID       string\n    Key      string\n    Expires  int64\n}\n</code></pre><p>再来看下cache认证策略实现的<a href=\"https://github.com/marmotedu/iam/blob/master/internal/pkg/middleware/auth/cache.go#L48\">AuthFunc</a>方法：</p><pre><code>func (cache CacheStrategy) AuthFunc() gin.HandlerFunc {\n\treturn func(c *gin.Context) {\n\t\theader := c.Request.Header.Get(&quot;Authorization&quot;)\n\t\tif len(header) == 0 {\n\t\t\tcore.WriteResponse(c, errors.WithCode(code.ErrMissingHeader, &quot;Authorization header cannot be empty.&quot;), nil)\n\t\t\tc.Abort()\n\n\t\t\treturn\n\t\t}\n\n\t\tvar rawJWT string\n\t\t// Parse the header to get the token part.\n\t\tfmt.Sscanf(header, &quot;Bearer %s&quot;, &amp;rawJWT)\n\n\t\t// Use own validation logic, see below\n\t\tvar secret Secret\n\n\t\tclaims := &amp;jwt.MapClaims{}\n\t\t// Verify the token\n\t\tparsedT, err := jwt.ParseWithClaims(rawJWT, claims, func(token *jwt.Token) (interface{}, error) {\n\t\t\t// Validate the alg is HMAC signature\n\t\t\tif _, ok := token.Method.(*jwt.SigningMethodHMAC); !ok {\n\t\t\t\treturn nil, fmt.Errorf(&quot;unexpected signing method: %v&quot;, token.Header[&quot;alg&quot;])\n\t\t\t}\n\n\t\t\tkid, ok := token.Header[&quot;kid&quot;].(string)\n\t\t\tif !ok {\n\t\t\t\treturn nil, ErrMissingKID\n\t\t\t}\n\n\t\t\tvar err error\n\t\t\tsecret, err = cache.get(kid)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, ErrMissingSecret\n\t\t\t}\n\n\t\t\treturn []byte(secret.Key), nil\n\t\t}, jwt.WithAudience(AuthzAudience))\n\t\tif err != nil || !parsedT.Valid {\n\t\t\tcore.WriteResponse(c, errors.WithCode(code.ErrSignatureInvalid, err.Error()), nil)\n\t\t\tc.Abort()\n\n\t\t\treturn\n\t\t}\n\n\t\tif KeyExpired(secret.Expires) {\n\t\t\ttm := time.Unix(secret.Expires, 0).Format(&quot;2006-01-02 15:04:05&quot;)\n\t\t\tcore.WriteResponse(c, errors.WithCode(code.ErrExpired, &quot;expired at: %s&quot;, tm), nil)\n\t\t\tc.Abort()\n\n\t\t\treturn\n\t\t}\n\n\t\tc.Set(CtxUsername, secret.Username)\n\t\tc.Next()\n\t}\n}\n\n// KeyExpired checks if a key has expired, if the value of user.SessionState.Expires is 0, it will be ignored.\nfunc KeyExpired(expires int64) bool {\n\tif expires &gt;= 1 {\n\t\treturn time.Now().After(time.Unix(expires, 0))\n\t}\n\n\treturn false\n}\n</code></pre><p>AuthFunc函数依次执行了以下四大步来完成JWT认证，每一步中又有一些小步骤，下面我们来一起看看。</p><p>第一步，从Authorization: Bearer XX.YY.ZZ请求头中获取XX.YY.ZZ，XX.YY.ZZ即为JWT Token。</p><p>第二步，调用github.com/dgrijalva/jwt-go包提供的ParseWithClaims函数，该函数会依次执行下面四步操作。</p><p>调用ParseUnverified函数，依次执行以下操作：</p><p>从Token中获取第一段XX，base64解码后得到JWT Token的Header{“alg”:“HS256”,“kid”:“a45yPqUnQ8gljH43jAGQdRo0bXzNLjlU0hxa”,“typ”:“JWT”}。</p><p>从Token中获取第二段YY，base64解码后得到JWT Token的Payload{“aud”:“iam.authz.marmotedu.com”,“exp”:1625104314,“iat”:1625097114,“iss”:“iamctl”,“nbf”:1625097114}。</p><p>根据Token Header中的alg字段，获取Token加密函数。</p><p>最终ParseUnverified函数会返回Token类型的变量，Token类型包含 Method、Header、Claims、Valid这些重要字段，这些字段会用于后续的认证步骤中。</p><p>调用传入的keyFunc获取密钥，这里来看下keyFunc的实现：</p><pre><code>func(token *jwt.Token) (interface{}, error) {\n\t// Validate the alg is HMAC signature\n\tif _, ok := token.Method.(*jwt.SigningMethodHMAC); !ok {\n\t\treturn nil, fmt.Errorf(&quot;unexpected signing method: %v&quot;, token.Header[&quot;alg&quot;])\n\t}\n\n\tkid, ok := token.Header[&quot;kid&quot;].(string)\n\tif !ok {\n\t\treturn nil, ErrMissingKID\n\t}\n\n\tvar err error\n\tsecret, err = cache.get(kid)\n\tif err != nil {\n\t\treturn nil, ErrMissingSecret\n\t}\n\n\treturn []byte(secret.Key), nil\n}\n</code></pre><p>可以看到，keyFunc接受 <code>*Token</code> 类型的变量，并获取Token Header中的kid，kid即为密钥ID：secretID。接着，调用cache.get(kid)获取密钥secretKey。cache.get函数即为getSecretFunc，getSecretFunc函数会根据kid，从内存中查找密钥信息，密钥信息中包含了secretKey。</p><ol start=\"3\">\n<li>从Token中获取Signature签名字符串ZZ，也即Token的第三段。</li>\n<li>获取到secretKey之后，token.Method.Verify验证Signature签名字符串ZZ，也即Token的第三段是否合法。token.Method.Verify实际上是使用了相同的加密算法和相同的secretKey加密XX.YY字符串。假设加密之后的字符串为WW，接下来会用WW和ZZ base64解码后的字符串进行比较，如果相等则认证通过，如果不相等则认证失败。</li>\n</ol><p><strong>第三步，</strong>调用KeyExpired，验证secret是否过期。secret信息中包含过期时间，你只需要拿该过期时间和当前时间对比就行。</p><p><strong>第四步，</strong>设置HTTP Header<code>username: colin</code>。</p><p>到这里，iam-authz-server的Bearer认证分析就完成了。</p><p>我们来做个总结：iam-authz-server通过加载Gin中间件的方式，在请求<code>/v1/authz</code>接口时进行访问认证。因为Bearer认证具有过期时间，而且可以在认证字符串中携带更多有用信息，还具有不可逆加密等优点，所以<strong>/v1/authz采用了Bearer认证，Token格式采用了JWT格式</strong>，这也是业界在API认证中最受欢迎的认证方式。</p><p>Bearer认证需要secretID和secretKey，这些信息会通过gRPC接口调用，从iam-apisaerver中获取，并缓存在iam-authz-server的内存中供认证时查询使用。</p><p>当请求来临时，iam-authz-server Bearer认证中间件从JWT Token中解析出Header，并从Header的kid字段中获取到secretID，根据secretID查找到secretKey，最后使用secretKey加密JWT Token的Header和Payload，并与Signature部分进行对比。如果相等，则认证通过；如果不等，则认证失败。</p><h3>iam-apiserver Bearer认证实现</h3><p>再来看下 iam-apiserver的Bearer认证。</p><p>iam-apiserver的Bearer认证通过以下代码（位于<a href=\"https://github.com/marmotedu/iam/blob/v1.1.0/internal/apiserver/router.go#L65\">router.go</a>文件中）指定使用了auto认证策略：</p><pre><code>v1.Use(auto.AuthFunc())\n</code></pre><p>我们来看下<a href=\"https://github.com/marmotedu/iam/blob/v1.0.0/internal/pkg/middleware/auth/auto.go#L38\">auto.AuthFunc()</a>的实现：</p><pre><code>func (a AutoStrategy) AuthFunc() gin.HandlerFunc {\n\treturn func(c *gin.Context) {\n\t\toperator := middleware.AuthOperator{}\n\t\tauthHeader := strings.SplitN(c.Request.Header.Get(&quot;Authorization&quot;), &quot; &quot;, 2)\n\n\t\tif len(authHeader) != authHeaderCount {\n\t\t\tcore.WriteResponse(\n\t\t\t\tc,\n\t\t\t\terrors.WithCode(code.ErrInvalidAuthHeader, &quot;Authorization header format is wrong.&quot;),\n\t\t\t\tnil,\n\t\t\t)\n\t\t\tc.Abort()\n\n\t\t\treturn\n\t\t}\n\n\t\tswitch authHeader[0] {\n\t\tcase &quot;Basic&quot;:\n\t\t\toperator.SetStrategy(a.basic)\n\t\tcase &quot;Bearer&quot;:\n\t\t\toperator.SetStrategy(a.jwt)\n\t\t\t// a.JWT.MiddlewareFunc()(c)\n\t\tdefault:\n\t\t\tcore.WriteResponse(c, errors.WithCode(code.ErrSignatureInvalid, &quot;unrecognized Authorization header.&quot;), nil)\n\t\t\tc.Abort()\n\n\t\t\treturn\n\t\t}\n\n\t\toperator.AuthFunc()(c)\n\n\t\tc.Next()\n\t}\n}\n</code></pre><p>从上面代码中可以看到，AuthFunc函数会从Authorization Header中解析出认证方式是Basic还是Bearer。如果是Bearer，就会使用JWT认证策略；如果是Basic，就会使用Basic认证策略。</p><p>我们再来看下JWT认证策略的<a href=\"https://github.com/marmotedu/iam/blob/v1.0.0/internal/pkg/middleware/auth/jwt.go#L30\">AuthFunc</a>函数实现：</p><pre><code>func (j JWTStrategy) AuthFunc() gin.HandlerFunc {\n\treturn j.MiddlewareFunc()\n}\n</code></pre><p>我们跟随代码，可以定位到<code>MiddlewareFunc</code>函数最终调用了<code>github.com/appleboy/gin-jwt</code>包<code>GinJWTMiddleware</code>结构体的<a href=\"https://github.com/appleboy/gin-jwt/blob/v2.6.4/auth_jwt.go#L369\">middlewareImpl</a>方法：</p><pre><code>func (mw *GinJWTMiddleware) middlewareImpl(c *gin.Context) {\n\tclaims, err := mw.GetClaimsFromJWT(c)\n\tif err != nil {\n\t\tmw.unauthorized(c, http.StatusUnauthorized, mw.HTTPStatusMessageFunc(err, c))\n\t\treturn\n\t}\n\n\tif claims[&quot;exp&quot;] == nil {\n\t\tmw.unauthorized(c, http.StatusBadRequest, mw.HTTPStatusMessageFunc(ErrMissingExpField, c))\n\t\treturn\n\t}\n\n\tif _, ok := claims[&quot;exp&quot;].(float64); !ok {\n\t\tmw.unauthorized(c, http.StatusBadRequest, mw.HTTPStatusMessageFunc(ErrWrongFormatOfExp, c))\n\t\treturn\n\t}\n\n\tif int64(claims[&quot;exp&quot;].(float64)) &lt; mw.TimeFunc().Unix() {\n\t\tmw.unauthorized(c, http.StatusUnauthorized, mw.HTTPStatusMessageFunc(ErrExpiredToken, c))\n\t\treturn\n\t}\n\n\tc.Set(&quot;JWT_PAYLOAD&quot;, claims)\n\tidentity := mw.IdentityHandler(c)\n\n\tif identity != nil {\n\t\tc.Set(mw.IdentityKey, identity)\n\t}\n\n\tif !mw.Authorizator(identity, c) {\n\t\tmw.unauthorized(c, http.StatusForbidden, mw.HTTPStatusMessageFunc(ErrForbidden, c))\n\t\treturn\n\t}\n\n\tc.Next()\n}\n</code></pre><p>分析上面的代码，我们可以知道，middlewareImpl的Bearer认证流程为：</p><p><strong>第一步</strong>：调用<code>GetClaimsFromJWT</code>函数，从HTTP请求中获取Authorization Header，并解析出Token字符串，进行认证，最后返回Token Payload。</p><p><strong>第二步</strong>：校验Payload中的<code>exp</code>是否超过当前时间，如果超过就说明Token过期，校验不通过。</p><p><strong>第三步</strong>：给gin.Context中添加<code>JWT_PAYLOAD</code>键，供后续程序使用（当然也可能用不到）。</p><p><strong>第四步</strong>：通过以下代码，在gin.Context中添加IdentityKey键，IdentityKey键可以在创建<code>GinJWTMiddleware</code>结构体时指定，这里我们设置为<code>middleware.UsernameKey</code>，也就是username。</p><pre><code>identity := mw.IdentityHandler(c)\n\nif identity != nil {\n    c.Set(mw.IdentityKey, identity)\n}\n</code></pre><p>IdentityKey键的值由IdentityHandler函数返回，IdentityHandler函数为：</p><pre><code>func(c *gin.Context) interface{} {\n    claims := jwt.ExtractClaims(c)\n\n    return claims[jwt.IdentityKey]\n}\n</code></pre><p>上述函数会从Token的Payload中获取identity域的值，identity域的值是在签发Token时指定的，它的值其实是用户名，你可以查看<a href=\"https://github.com/marmotedu/iam/blob/v1.0.0/internal/apiserver/auth.go#L177\">payloadFunc</a>函数了解。</p><p><strong>第五步</strong>：接下来，会调用<code>Authorizator</code>方法，<code>Authorizator</code>是一个callback函数，成功时必须返回真，失败时必须返回假。<code>Authorizator</code>也是在创建GinJWTMiddleware时指定的，例如：</p><pre><code>func authorizator() func(data interface{}, c *gin.Context) bool {    \n    return func(data interface{}, c *gin.Context) bool {    \n        if v, ok := data.(string); ok {    \n            log.L(c).Infof(&quot;user `%s` is authenticated.&quot;, v)         \n                                                                     \n            return true                            \n        }                                                        \n                                                                 \n        return false                     \n    }    \n}    \n</code></pre><p><code>authorizator</code>函数返回了一个匿名函数，匿名函数在认证成功后，会打印一条认证成功日志。</p><h2>IAM项目认证功能设计技巧</h2><p>我在设计IAM项目的认证功能时，也运用了一些技巧，这里分享给你。</p><h3>技巧1：面向接口编程</h3><p>在使用<a href=\"https://github.com/marmotedu/iam/blob/v1.0.0/internal/pkg/middleware/auth/auto.go#L30\">NewAutoStrategy</a>函数创建auto认证策略时，传入了<a href=\"https://github.com/marmotedu/iam/blob/v1.0.0/internal/pkg/middleware/auth.go#L12\">middleware.AuthStrategy</a>接口类型的参数，这意味着Basic认证和Bearer认证都可以有不同的实现，这样后期可以根据需要扩展新的认证方式。</p><h3>技巧2：使用抽象工厂模式</h3><p><a href=\"https://github.com/marmotedu/iam/blob/v1.0.0/internal/apiserver/auth.go\">auth.go</a>文件中，通过newBasicAuth、newJWTAuth、newAutoAuth创建认证策略时，返回的都是接口。通过返回接口，可以在不公开内部实现的情况下，让调用者使用你提供的各种认证功能。</p><h3>技巧3：使用策略模式</h3><p>在auto认证策略中，我们会根据HTTP 请求头<code>Authorization: XXX X.Y.X</code>中的XXX来选择并设置认证策略（Basic 或 Bearer）。具体可以查看<code>AutoStrategy</code>的<a href=\"https://github.com/marmotedu/iam/blob/v1.0.0/internal/pkg/middleware/auth/auto.go#L38\">AuthFunc</a>函数：</p><pre><code>func (a AutoStrategy) AuthFunc() gin.HandlerFunc {\n\treturn func(c *gin.Context) {\n\t\toperator := middleware.AuthOperator{}\n\t\tauthHeader := strings.SplitN(c.Request.Header.Get(&quot;Authorization&quot;), &quot; &quot;, 2)\n        ...\n\t\tswitch authHeader[0] {\n\t\tcase &quot;Basic&quot;:\n\t\t\toperator.SetStrategy(a.basic)\n\t\tcase &quot;Bearer&quot;:\n\t\t\toperator.SetStrategy(a.jwt)\n\t\t\t// a.JWT.MiddlewareFunc()(c)\n\t\tdefault:\n\t\t\tcore.WriteResponse(c, errors.WithCode(code.ErrSignatureInvalid, &quot;unrecognized Authorization header.&quot;), nil)\n\t\t\tc.Abort()\n\n\t\t\treturn\n\t\t}\n\n\t\toperator.AuthFunc()(c)\n\n\t\tc.Next()\n\t}\n}\n</code></pre><p>上述代码中，如果是Basic，则设置为Basic认证方法<code>operator.SetStrategy(a.basic)</code>；如果是Bearer，则设置为Bearer认证方法<code>operator.SetStrategy(a.jwt)</code>。 <code>SetStrategy</code>方法的入参是AuthStrategy类型的接口，都实现了<code>AuthFunc() gin.HandlerFunc</code>函数，用来进行认证，所以最后我们调用<code>operator.AuthFunc()(c)</code>即可完成认证。</p><h2>总结</h2><p>在IAM项目中，iam-apiserver实现了Basic认证和Bearer认证，iam-authz-server实现了Bearer认证。这一讲重点介绍了iam-apiserver的认证实现。</p><p>用户要访问iam-apiserver，首先需要通过Basic认证，认证通过之后，会返回JWT Token和JWT Token的过期时间。前端将Token缓存在LocalStorage或Cookie中，后续的请求都通过Token来认证。</p><p>执行Basic认证时，iam-apiserver会从HTTP Authorization Header中解析出用户名和密码，将密码再加密，并和数据库中保存的值进行对比。如果不匹配，则认证失败，否则认证成功。认证成功之后，会返回Token，并在Token的Payload部分设置用户名，Key为 username 。</p><p>执行Bearer认证时，iam-apiserver会从JWT Token中解析出Header和Payload，并从Header中获取加密算法。接着，用获取到的加密算法和从配置文件中获取到的密钥对Header.Payload进行再加密，得到Signature，并对比两次的Signature是否相等。如果不相等，则返回 HTTP 401 Unauthorized 错误；如果相等，接下来会判断Token是否过期，如果过期则返回认证不通过，否则认证通过。认证通过之后，会将Payload中的username添加到gin.Context类型的变量中，供后面的业务逻辑使用。</p><p>我绘制了整个流程的示意图，你可以对照着再回顾一遍。</p><p><img src=\"https://static001.geekbang.org/resource/image/64/7e/642a010388e759dd76d411055bbd637e.jpg?wh=2248x1104\" alt=\"\"></p><h2>课后练习</h2><ol>\n<li>走读<code>github.com/appleboy/gin-jwt</code>包的<code>GinJWTMiddleware</code>结构体的<a href=\"https://github.com/appleboy/gin-jwt/blob/v2.6.4/auth_jwt.go#L407\">GetClaimsFromJWT</a>方法，分析一下：GetClaimsFromJWT方法是如何从gin.Context中解析出Token，并进行认证的？</li>\n<li>思考下，iam-apiserver和iam-authzserver是否可以使用同一个认证策略？如果可以，又该如何实现？</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"25 | 认证机制：应用程序如何进行访问认证？","id":398410},"right":{"article_title":"27 | 权限模型：5大权限模型是如何进行资源授权的？","id":400213}}},{"article_id":400213,"article_title":"27 | 权限模型：5大权限模型是如何进行资源授权的？","article_content":"<p>你好，我是孔令飞。在开始讲解如何开发服务之前，我先来介绍一个比较重要的背景知识：权限模型。</p><p>在你的研发生涯中，应该会遇到这样一种恐怖的操作：张三因为误操作删除了李四的资源。你在刷新闻时，也可能会刷到这么一个爆款新闻：某某程序员删库跑路。操作之所以恐怖，新闻之所以爆款，是因为这些行为往往会带来很大的损失。</p><p>那么如何避免这些风险呢？答案就是对资源做好权限管控，这也是项目开发中绕不开的话题。腾讯云会强制要求所有的云产品都对接 <a href=\"https://cloud.tencent.com/document/product/598/10583\">访问管理（CAM）</a> 服务（阿里云也有这种要求），之所以这么做，是因为保证资源的安全是一件非常非常重要的事情。</p><p>可以说，保证应用的资源安全，已经成为一个应用的必备能力。作为开发人员，你也一定要知道如何保障应用的资源安全。那么如何才能保障资源的安全呢？我认为你至少需要掌握下面这两点：</p><ul>\n<li><strong>权限模型：</strong>你需要了解业界成熟的权限模型，以及这些模型的适用场景。只有具备足够宽广的知识面和视野，我们才能避免闭门造车，设计出优秀的资源授权方案。</li>\n<li><strong>编码实现：</strong>选择或设计出了优秀的资源授权方案后，你就要编写代码实现该方案。这门课的 IAM 应用，就是一个资源授权方案的落地项目。你可以通过对 IAM 应用的学习，来掌握如何实现一个资源授权系统。</li>\n</ul><!-- [[[read_end]]] --><p>无论是第一点还是第二点，都需要你掌握基本的权限模型知识。那么这一讲，我就来介绍下业界优秀的权限模型，以及这些模型的适用场景，以使你今后设计出更好的资源授权系统。</p><h2>权限相关术语介绍</h2><p>在介绍业界常见的权限模型前，我们先来看下在权限模型中出现的术语。我把常见的术语总结在了下面的表格里：</p><p><img src=\"https://static001.geekbang.org/resource/image/6a/1d/6aa623500bb76b3d40a5c4c6d15be91d.jpg?wh=2248x1623\" alt=\"\"></p><p>为了方便你理解，这一讲我分别用<strong>用户</strong>、<strong>操作</strong>和<strong>资源</strong>来替代 Subject、Action 和 Object。</p><h2>权限模型介绍</h2><p>接下来，我就详细介绍下一些常见的权限模型，让你今后在设计权限系统时，能够根据需求选择合适的权限模型。</p><p>不同的权限模型具有不同的特点，可以满足不同的需求。常见的权限模型有下面这 5 种：</p><ul>\n<li>权限控制列表（ACL，Access Control List）。</li>\n<li>自主访问控制（DAC，Discretionary Access Control）。</li>\n<li>强制访问控制（MAC，Mandatory Access Control）。</li>\n<li>基于角色的访问控制（RBAC，Role-Based Access Control）。</li>\n<li>基于属性的权限验证（ABAC，Attribute-Based Access Control）。</li>\n</ul><p>这里先简单介绍下这 5 种权限模型。<strong>ACL</strong> 是一种简单的权限模型；<strong>DAC</strong> 基于 ACL，将权限下放给具有此权限的主题；但 DAC 因为权限下放，导致它对权限的控制过于分散，为了弥补 DAC 的这个缺陷，诞生了 <strong>MAC</strong> 权限模型。</p><p>DAC 和 MAC 都是基于 ACL 的权限模型。ACL 及其衍生的权限模型可以算是旧时代的权限模型，灵活性和功能性都满足不了现代应用的权限需求，所以诞生了 <strong>RBAC。</strong>RBAC 也是迄今为止最为普及的权限模型。</p><p>但是，随着组织和应用规模的增长，所需的角色数量越来越多，变得难以管理，进而导致角色爆炸和职责分离（SoD）失败。最后，引入了一种新的、更动态的访问控制形式，称为基于属性的访问控制，也就是 ABAC。ABAC 被一些人看作是权限系统设计的未来。腾讯云的 CAM、AWS 的 IAM、阿里云的 RAM 都是 ABAC 类型的权限访问服务。</p><p>接下来，我会详细介绍这些权限模型的基本概念。</p><h3>简单的权限模型：权限控制列表（ACL）</h3><p>ACL（Access Control List，权限控制列表），用来判断用户是否可以对资源做特定的操作。例如，允许 Colin 创建文章的 ACL 策略为：</p><pre><code>Subject: Colin\nAction: Create\nObject: Article\n</code></pre><p>在 ACL 权限模型下，权限管理是围绕资源 Object 来设定的，ACL 权限模型也是比较简单的一种模型。</p><h3>基于 ACL 下放权限的权限模型：自主访问控制（DAC）</h3><p>DAC (Discretionary Access Control，自主访问控制)，是 ACL 的扩展模型，灵活性更强。使用这种模型，不仅可以判断 Subject 是否可以对 Object 做 Action 操作，同时也能让 Subject 将 Object、Action 的相同权限授权给其他的 Subject。例如，Colin 可以创建文章：</p><pre><code>Subject: Colin\nAction: Create\nObject: Article\n</code></pre><p>因为 Colin 具有创建文章的权限，所以 Colin 也可以授予 James 创建文章的权限：</p><pre><code>Subject: James\nAction: Create\nObject: Article\n</code></pre><p>经典的 ACL 模型权限集中在同一个 Subject 上，缺乏灵活性，为了加强灵活性，在 ACL 的基础上，DAC 模型将权限下放，允许拥有权限的 Subject 自主地将权限授予其他 Subject。</p><h3>基于 ACL 且安全性更高的权限模型：强制访问控制（MAC）</h3><p>MAC (Mandatory Access Control，强制访问控制)，是 ACL 的扩展模型，安全性更高。MAC 权限模型下，Subject 和 Object 同时具有安全属性。在做授权时，需要同时满足两点才能授权通过：</p><ul>\n<li>Subject 可以对 Object 做 Action 操作。</li>\n<li>Object 可以被 Subject 做 Action 操作。</li>\n</ul><p>例如，我们设定了“Colin 和 James 可以创建文章”这个 MAC 策略：</p><pre><code>Subject: Colin\nAction: Create\nObject: Article\n\nSubject: James\nAction: Create\nObject: Article\n</code></pre><p>我们还有另外一个 MAC 策略“文章可以被 Colin 创建”：</p><pre><code>Subject: Article\nAction: Create\nObject: Colin\n</code></pre><p>在上述策略中，Colin 可以创建文章，但是 James 不能创建文章，因为第二条要求没有满足。</p><p>这里你需要注意，在 ACL 及其扩展模型中，Subject 可以是用户，也可以是组或群组。</p><p>ACL、DAC 和 MAC 是旧时代的权限控制模型，无法满足现代应用对权限控制的需求，于是诞生了新时代的权限模型：RBAC 和 ABAC。</p><h3>最普及的权限模型：基于角色的访问控制（RBAC）</h3><p>RBAC (Role-Based Access Control，基于角色的访问控制)，引入了 Role（角色）的概念，并且将权限与角色进行关联。用户通过扮演某种角色，具有该角色的所有权限。具体如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/c5/cf/c5ab6b1a77069caac2c5de709dff32cf.jpg?wh=2248x902\" alt=\"\"></p><p>如图所示，每个用户关联一个或多个角色，每个角色关联一个或多个权限，每个权限又包含了一个或者多个操作，操作包含了对资源的操作集合。通过用户和权限解耦，可以实现非常灵活的权限管理。例如，可以满足以下两个权限场景：</p><p>第一，可以通过角色批量给一个用户授权。例如，公司新来了一位同事，需要授权虚拟机的生产、销毁、重启和登录权限。这时候，我们可以将这些权限抽象成一个运维角色。如果再有新同事来，就可以通过授权运维角色，直接批量授权这些权限，不用一个个地给用户授权这些权限。</p><p>第二，可以批量修改用户的权限。例如，我们有很多用户，同属于运维角色，这时候对运维角色的任何权限变更，就相当于对运维角色关联的所有用户的权限变更，不用一个个去修改这些用户的权限。</p><p>RBAC 又分为 RBAC0、RBAC1、RBAC2、RBAC3。RBAC0 是 RBAC 的核心思想，RBAC1 是基于 RBAC 的角色分层模型，RBAC2 增加了 RBAC 的约束模型。而 RBAC3，其实相当于 RBAC1 + RBAC2。</p><p>下面我来详细介绍下这四种 RBAC。</p><p>RBAC0：基础模型，只包含核心的四要素，也就是用户（User）、角色（Role）、权限（Permission：Objects-Operations）、会话（Session）。用户和角色可以是多对多的关系，权限和角色也是多对多的关系。</p><p>RBAC1：包括了 RBAC0，并且添加了角色继承。角色继承，即角色可以继承自其他角色，在拥有其他角色权限的同时，还可以关联额外的权限。</p><p>RBAC2：包括 RBAC0，并且添加了约束。具有以下核心特性：</p><ul>\n<li><strong>互斥约束：</strong>包括互斥用户、互斥角色、互斥权限。同一个用户不能拥有相互排斥的角色，两个互斥角色不能分配一样的权限集，互斥的权限不能分配给同一个角色，在 Session 中，同一个角色不能拥有互斥权限。</li>\n<li><strong>基数约束：</strong>一个角色被分配的用户数量受限，它指的是有多少用户能拥有这个角色。例如，一个角色是专门为公司 CEO 创建的，那这个角色的数量就是有限的。</li>\n<li><strong>先决条件角色：</strong>指要想获得较高的权限，要首先拥有低一级的权限。例如，先有副总经理权限，才能有总经理权限。</li>\n<li><strong>静态职责分离</strong>(Static Separation of Duty)：用户无法同时被赋予有冲突的角色。</li>\n<li><strong>动态职责分离</strong>(Dynamic Separation of Duty)：用户会话中，无法同时激活有冲突的角色。</li>\n</ul><p>RBAC3：全功能的 RBAC，合并了 RBAC0、RBAC1、RBAC2。</p><p>此外，RBAC 也可以很方便地模拟出 DAC 和 MAC 的效果。</p><p>这里举个例子，来协助你理解 RBAC。例如，我们有 write article 和 manage article 的权限：</p><pre><code>Permission:\n    - Name: write_article\n        - Effect: &quot;allow&quot;\n        - Action: [&quot;Create&quot;, &quot;Update&quot;, &quot;Read&quot;]\n        - Object: [&quot;Article&quot;]\n    - Name: manage_article\n        - Effect: &quot;allow&quot;\n        - Action: [&quot;Delete&quot;, &quot;Read&quot;]\n        - Object: [&quot;Article&quot;]\n</code></pre><p>同时，我们也有 Writer、Manager和 CEO 3个角色，Writer 具有 write_article 权限，Manager 具有 manage_article 权限，CEO 具有所有权限：</p><pre><code>Role:\n    - Name: Writer\n      Permissions:\n        - write_article\n    - Name: Manager\n      Permissions:\n        - manage_article\n    - Name: CEO\n      Permissions:\n        - write_article\n        - manage_article\n</code></pre><p>接下来，我们对 Colin 用户授予 Writer 角色：</p><pre><code>Subject: Colin\nRoles:\n    - Writer\n</code></pre><p>那么现在 Colin 就具有 Writer 角色的所有权限 write_article，write_article 权限可以创建文章。</p><p>接下来，再对 James 用户授予 Writer 和 Manager 角色：</p><pre><code>Subject: James\nRoles:\n    - Writer\n    - Manager\n</code></pre><p>那么现在 James 就具有 Writer 角色和 Manager 角色的所有权限：write_article、manage_article，这些权限允许 James 创建和删除文章。</p><h3>最强大的权限模型：基于属性的权限验证（ABAC）</h3><p>ABAC (Attribute-Based Access Control，基于属性的权限验证），规定了哪些属性的用户可以对哪些属性的资源在哪些限制条件下进行哪些操作。跟 RBAC 相比，ABAC 对权限的控制粒度更细，主要规定了下面这四类属性：</p><ul>\n<li>用户属性，例如性别、年龄、工作等。</li>\n<li>资源属性，例如创建时间、所属位置等。</li>\n<li>操作属性，例如创建、修改等。</li>\n<li>环境属性，例如来源 IP、当前时间等。</li>\n</ul><p>下面是一个 ABAC 策略：</p><pre><code>Subject:\n    Name: Colin\n    Department: Product\n    Role: Writer\nAction:\n    - create\n    - update\nResource:\n    Type: Article\n    Tag:\n        - technology\n        - software\n    Mode:\n        - draft\nContextual:\n    IP: 10.0.0.10\n</code></pre><p>上面权限策略描述的意思是，产品部门的 Colin 作为一个 Writer 角色，可以通过来源 IP 是 10.0.0.10 的客户端，创建和更新带有 technology 和 software 标签的草稿文章。</p><p>这里提示一点：ABAC 有时也被称为 PBAC（Policy-Based Access Control）或 CBAC（Claims-Based Access Control）。</p><p>这里，我通过现实中的 ABAC 授权策略，帮你理解 ABAC 权限模型。下面是一个腾讯云的 CAM 策略，也是一种 ABAC 授权模式：</p><pre><code>{\n  &quot;version&quot;: &quot;2.0&quot;,\n  &quot;statement&quot;: [\n    {\n      &quot;effect&quot;: &quot;allow&quot;,\n      &quot;action&quot;: [\n        &quot;cos:List*&quot;,\n        &quot;cos:Get*&quot;,\n        &quot;cos:Head*&quot;,\n        &quot;cos:OptionsObject&quot;\n      ],\n      &quot;resource&quot;: &quot;qcs::cos:ap-shanghai:uid/1250000000:Bucket1-1250000000/dir1/*&quot;,\n      &quot;condition&quot;: {\n        &quot;ip_equal&quot;: {\n          &quot;qcs:ip&quot;: [\n            &quot;10.217.182.3/24&quot;,\n            &quot;111.21.33.72/24&quot;\n          ]\n        }\n      }\n    }\n  ]\n}\n</code></pre><p>上面的授权策略表示：用户必须在 10.217.182.3/24 或者 111.21.33.72/24 网段才能调用云 API（cos:List*、cos:Get*、cos:Head*、cos:OptionsObject），对 1250000000 用户下的 dir1 目录下的文件进行读取操作。</p><p>这里，ABAC 规定的四类属性分别是：</p><ul>\n<li>用户属性：用户为 1250000000。</li>\n<li>资源属性：dir1 目录下的文件。</li>\n<li>操作属性：读取（cos:List*、cos:Get*、cos:Head*、cos:OptionsObject 都是读取 API）。</li>\n<li>环境属性：10.217.182.3/24 或者 111.21.33.72/24 网段。</li>\n</ul><h2>相关开源项目</h2><p>上面我介绍了权限模型的相关知识，但是现在如果让你真正去实现一个权限系统，你可能还是不知从何入手。</p><p>在这里，我列出了一些 GitHub 上比较优秀的开源项目，你可以学习这些项目是如何落地一个权限模型的，也可以基于这些项目进行二次开发，开发一个满足业务需求的权限系统。</p><h3>Casbin</h3><p><a href=\"https://github.com/casbin/casbin\">Casbin</a> 是一个用 Go 语言编写的访问控制框架，功能强大，支持 ACL、RBAC、ABAC 等访问模型，很多优秀的权限管理系统都是基于 Casbin 来构建的。Casbin 的核心功能都是围绕着访问控制来构建的，不负责身份认证。如果以后老板让你实现一个权限管理系统，Casbin 是一定要好好研究的开源项目。</p><h3>keto</h3><p><a href=\"https://github.com/ory/keto\">keto</a> 是一个云原生权限控制服务，通过提供 REST API 进行授权，支持 RBAC、ABAC、ACL、AWS IAM 策略、Kubernetes Roles 等权限模型，可以解决下面这些问题：</p><ul>\n<li>是否允许某些用户修改此博客文章？</li>\n<li>是否允许某个服务打印该文档？</li>\n<li>是否允许 ACME 组织的成员修改其租户中的数据？</li>\n<li>是否允许在星期一的下午 4 点到下午 5 点，从 IP 10.0.0.2 发出的请求执行某个 Job？</li>\n</ul><h3>go-admin</h3><p><a href=\"https://github.com/go-admin-team/go-admin\">go-admin</a> 是一个基于 Gin + Vue + Element UI 的前后端分离权限管理系统脚手架，它的访问控制模型采用了 Casbin 的 RBAC 访问控制模型，功能强大，包含了如下功能：</p><ul>\n<li>基础用户管理功能；</li>\n<li>JWT 鉴权；</li>\n<li>代码生成器；</li>\n<li>RBAC 权限控制；</li>\n<li>表单构建；</li>\n<li>……</li>\n</ul><p>该项目还支持 RESTful API 设计规范、Swagger 文档、GORM 库等。go-admin 不仅是一个优秀的权限管理系统，也是一个优秀的、功能齐全的 Go 开源项目。你在做项目开发时，也可以参考该项目的构建思路。go-admin 管理系统自带前端，如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/21/98/21c8307e034fc6e082833d1c9fd0f498.png?wh=2535x827\" alt=\"\"></p><h3>LyricTian/gin-admin</h3><p><a href=\"https://github.com/LyricTian/gin-admin\">gin-admin</a> 类似于 go-admin，是一个基于 Gin+Gorm+Casbin+Wire 实现的权限管理脚手架，并自带前端，在做权限管理系统调研时，也非常值得参考。</p><p>gin-admin 大量采用了 Go 后端开发常用的技术，比如 Gin、GORM、JWT 认证、RESTful API、Logrus 日志包、Swagger 文档等。因此，你在做 Go 后端服务开发时，也可以学习该项目的构建方法。</p><h3>gin-vue-admin</h3><p><a href=\"https://github.com/flipped-aurora/gin-vue-admin\">gin-vue-admin</a> 是一个基于 Gin 和 Vue 开发的全栈前后端分离的后台管理系统，集成了 JWT 鉴权、动态路由、动态菜单、Casbin 鉴权、表单生成器、代码生成器等功能。gin-vue-admin 集成了 RBAC 权限管理模型，界面如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/a3/f3/a391723e154f862d5c7bf796edcf5bf3.png?wh=2527x627\" alt=\"\"></p><h3>选择建议</h3><p>介绍了那么多优秀的开源项目，最后我想给你一些选择建议。如果你想研究 ACL、RBAC、ABAC 等权限模型如何落地，我强烈建议你学习 <a href=\"https://github.com/casbin/casbin\">Casbin</a> 项目，Casbin 目前有近万的 GitHub star 数，处于活跃的开发状态。有很多项目在使用 Casbin，例如 <a href=\"https://github.com/go-admin-team/go-admin\">go-admin</a>、 <a href=\"https://github.com/LyricTian/gin-admin\">gin-admin</a> 、 <a href=\"https://github.com/flipped-aurora/gin-vue-admin\">gin-vue-admin</a> 等。</p><p><a href=\"https://github.com/ory/keto\">keto</a> 类似于 Casbin，主要通过 Go 包的方式，对外提供授权能力。keto 也是一个非常优秀的权限类项目，当你研究完 Casbin 后，如果还想再研究下其他授权类项目，建议你读下 keto 的源码。</p><p>go-admin、gin-vue-admin、gin-admin 这 3 个都是基于 Casbin 的 Go 项目。其中，gin-vue-admin 是后台管理系统框架，里面包含了 RBAC 权限管理模块；go-admin 和 gin-admin 都是 RBAC 权限管理脚手架。所以，如果你想找一个比较完整的 RBAC 授权系统（自带前后端），建议你优先研究下 go-admin，如果还有精力，可以再研究下 gin-admin、gin-vue-admin。</p><h2>总结</h2><p>这一讲，我介绍了 5 种常见的权限模型。其中，ACL 最简单，ABAC 最复杂，但是功能最强大，也最灵活。RBAC 则介于二者之间。对于一些云计算厂商来说，因为它们面临的授权场景复杂多样，需要一个非常强大的授权模型，所以腾讯云、阿里云和 AWS 等云厂商普遍采用了 ABAC 模型。</p><p>如果你的资源授权需求不复杂，可以考虑 RBAC；如果你需要一个能满足复杂场景的资源授权系统，建议选择 ABAC，ABAC 的设计思路可以参考下腾讯云的 CAM、阿里云的 RAM 和 AWS 的 IAM。</p><p>另外，如果你想深入了解权限模型如何具体落地，建议你阅读 <a href=\"https://github.com/casbin/casbin\">Casbin</a> 源码。</p><h2>课后练习</h2><ol>\n<li>思考一下，如果公司需要你实现一个授权中台系统，应该选用哪种权限模型来构建，来满足不同业务的不同需求？</li>\n<li>思考一下，如何将授权流程集成进统一接入层，例如 API 网关？</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"26 | IAM项目是如何设计和实现访问认证功能的？","id":399307},"right":{"article_title":"28 | 控制流（上）：通过iam-apiserver设计，看Web服务的构建","id":401190}}},{"article_id":401190,"article_title":"28 | 控制流（上）：通过iam-apiserver设计，看Web服务的构建","article_content":"<p>你好，我是孔令飞。</p><p>前面我们讲了很多关于应用构建的内容，你一定迫不及待地想看下IAM项目的应用是如何构建的。那么接下来，我就讲解下IAM应用的源码。</p><p>在讲解过程中，我不会去讲解具体如何Code，但会讲解一些构建过程中的重点、难点，以及Code背后的设计思路、想法。我相信这是对你更有帮助的。</p><p>IAM项目有很多组件，这一讲，我先来介绍下IAM项目的门面服务：iam-apiserver（管理流服务）。我会先给你介绍下iam-apiserver的功能和使用方法，再介绍下iam-apiserver的代码实现。</p><h2>iam-apiserver服务介绍</h2><p>iam-apiserver是一个Web服务，通过一个名为iam-apiserver的进程，对外提供RESTful API接口，完成用户、密钥、策略三种REST资源的增删改查。接下来，我从功能和使用方法两个方面来具体介绍下。</p><h3>iam-apiserver功能介绍</h3><p>这里，我们可以通过iam-apiserver提供的RESTful API接口，来看下iam-apiserver具体提供的功能。iam-apiserver提供的RESTful API接口可以分为四类，具体如下：</p><p><strong>认证相关接口</strong></p><!-- [[[read_end]]] --><p><img src=\"https://static001.geekbang.org/resource/image/43/6d/43ec9261ccdb165c56e9c25b45e6af6d.jpg?wh=1920x1062\" alt=\"图片\"></p><p><strong>用户相关接口</strong></p><p><img src=\"https://static001.geekbang.org/resource/image/60/24/60f8a05f4cb43cbac84c0fb12c40c824.jpg?wh=1920x1314\" alt=\"图片\"></p><p><strong>密钥相关接口</strong></p><p><img src=\"https://static001.geekbang.org/resource/image/e8/95/e8f6aee66a29ff2a5aefeb00c5045c95.jpg?wh=1920x1326\" alt=\"图片\"></p><p><strong>策略相关接口</strong></p><p><img src=\"https://static001.geekbang.org/resource/image/0f/9e/0f3fcaa80020c3f72229fbab2f014a9e.jpg?wh=1920x1275\" alt=\"图片\"></p><h3>iam-apiserver使用方法介绍</h3><p>上面我介绍了iam-apiserver的功能，接下来就介绍下如何使用这些功能。</p><p>我们可以通过不同的客户端来访问iam-apiserver，例如前端、API调用、SDK、iamctl等。这些客户端最终都会执行HTTP请求，调用iam-apiserver提供的RESTful API接口。所以，我们首先需要有一个顺手的REST API客户端工具来执行HTTP请求，完成开发测试。</p><p>因为不同的开发者执行HTTP请求的方式、习惯不同，为了方便讲解，这里我统一通过cURL工具来执行HTTP请求。接下来先介绍下cURL工具。</p><p>标准的Linux发行版都安装了cURL工具。cURL可以很方便地完成RESTful API的调用场景，比如设置Header、指定HTTP请求方法、指定HTTP消息体、指定权限认证信息等。通过<code>-v</code>选项，也能输出REST请求的所有返回信息。cURL功能很强大，有很多参数，这里列出cURL工具常用的参数：</p><pre><code>-X/--request [GET|POST|PUT|DELETE|…]  指定请求的 HTTP 方法\n-H/--header                           指定请求的 HTTP Header\n-d/--data                             指定请求的 HTTP 消息体（Body）\n-v/--verbose                          输出详细的返回信息\n-u/--user                             指定账号、密码\n-b/--cookie                           读取 cookie\n</code></pre><p>此外，如果你想使用带UI界面的工具，这里我推荐你使用 Insomnia 。</p><p>Insomnia是一个跨平台的REST API客户端，与Postman、Apifox是一类工具，用于接口管理、测试。Insomnia功能强大，支持以下功能：</p><ul>\n<li>发送HTTP请求；</li>\n<li>创建工作区或文件夹；</li>\n<li>导入和导出数据；</li>\n<li>导出cURL格式的HTTP请求命令；</li>\n<li>支持编写swagger文档；</li>\n<li>快速切换请求；</li>\n<li>URL编码和解码。</li>\n<li>…</li>\n</ul><p>Insomnia界面如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/63/e0/635aa6f3374af05ec2bff7e193314ae0.png?wh=1920x749\" alt=\"图片\"></p><p>当然了，也有很多其他优秀的带UI界面的REST API客户端，例如 Postman、Apifox等，你可以根据需要自行选择。</p><p>接下来，我用对secret资源的CURD操作，来给你演示下<strong>如何使用iam-apiserver的功能</strong>。你需要执行6步操作。</p><ol>\n<li>登录iam-apiserver，获取token。</li>\n<li>创建一个名为secret0的secret。</li>\n<li>获取secret0的详细信息。</li>\n<li>更新secret0的描述。</li>\n<li>获取secret列表。</li>\n<li>删除secret0。</li>\n</ol><p>具体操作如下：</p><ol>\n<li>登录iam-apiserver，获取token：</li>\n</ol><pre><code>$ curl -s -XPOST -H&quot;Authorization: Basic `echo -n 'admin:Admin@2021'|base64`&quot; http://127.0.0.1:8080/login | jq -r .token\neyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MzUwNTk4NDIsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MjcyODM4NDIsInN1YiI6ImFkbWluIn0.gTS0n-7njLtpCJ7mvSnct2p3TxNTUQaduNXxqqLwGfI\n</code></pre><p>这里，为了便于使用，我们将token设置为环境变量：</p><pre><code>TOKEN=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MzUwNTk4NDIsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MjcyODM4NDIsInN1YiI6ImFkbWluIn0.gTS0n-7njLtpCJ7mvSnct2p3TxNTUQaduNXxqqLwGfI\n</code></pre><ol start=\"2\">\n<li>创建一个名为secret0的secret：</li>\n</ol><pre><code>$ curl -v -XPOST -H &quot;Content-Type: application/json&quot; -H&quot;Authorization: Bearer ${TOKEN}&quot; -d'{&quot;metadata&quot;:{&quot;name&quot;:&quot;secret0&quot;},&quot;expires&quot;:0,&quot;description&quot;:&quot;admin secret&quot;}' http://iam.api.marmotedu.com:8080/v1/secrets\n* About to connect() to iam.api.marmotedu.com port 8080 (#0)\n*   Trying 127.0.0.1...\n* Connected to iam.api.marmotedu.com (127.0.0.1) port 8080 (#0)\n&gt; POST /v1/secrets HTTP/1.1\n&gt; User-Agent: curl/7.29.0\n&gt; Host: iam.api.marmotedu.com:8080\n&gt; Accept: */*\n&gt; Content-Type: application/json\n&gt; Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXBpLm1hcm1vdGVkdS5jb20iLCJleHAiOjE2MzUwNTk4NDIsImlkZW50aXR5IjoiYWRtaW4iLCJpc3MiOiJpYW0tYXBpc2VydmVyIiwib3JpZ19pYXQiOjE2MjcyODM4NDIsInN1YiI6ImFkbWluIn0.gTS0n-7njLtpCJ7mvSnct2p3TxNTUQaduNXxqqLwGfI\n&gt; Content-Length: 72\n&gt; \n* upload completely sent off: 72 out of 72 bytes\n&lt; HTTP/1.1 200 OK\n&lt; Content-Type: application/json; charset=utf-8\n&lt; X-Request-Id: ff825bea-53de-4020-8e68-4e87574bd1ba\n&lt; Date: Mon, 26 Jul 2021 07:20:26 GMT\n&lt; Content-Length: 313\n&lt; \n* Connection #0 to host iam.api.marmotedu.com left intact\n{&quot;metadata&quot;:{&quot;id&quot;:60,&quot;instanceID&quot;:&quot;secret-jedr3e&quot;,&quot;name&quot;:&quot;secret0&quot;,&quot;createdAt&quot;:&quot;2021-07-26T15:20:26.885+08:00&quot;,&quot;updatedAt&quot;:&quot;2021-07-26T15:20:26.907+08:00&quot;},&quot;username&quot;:&quot;admin&quot;,&quot;secretID&quot;:&quot;U6CxKs0YVWyOp5GrluychYIRxDmMDFd1mOOD&quot;,&quot;secretKey&quot;:&quot;fubNIn8jLA55ktuuTpXM8Iw5ogdR2mlf&quot;,&quot;expires&quot;:0,&quot;description&quot;:&quot;admin secret&quot;}\n</code></pre><p>可以看到，请求返回头中返回了<code>X-Request-Id</code> Header，<code>X-Request-Id</code>唯一标识这次请求。如果这次请求失败，就可以将<code>X-Request-Id</code>提供给运维或者开发，通过<code>X-Request-Id</code>定位出失败的请求，进行排障。另外<code>X-Request-Id</code>在微服务场景中，也可以透传给其他服务，从而实现请求调用链。</p><ol start=\"3\">\n<li>获取secret0的详细信息：</li>\n</ol><pre><code>$ curl -XGET -H&quot;Authorization: Bearer ${TOKEN}&quot; http://iam.api.marmotedu.com:8080/v1/secrets/secret0\n{&quot;metadata&quot;:{&quot;id&quot;:60,&quot;instanceID&quot;:&quot;secret-jedr3e&quot;,&quot;name&quot;:&quot;secret0&quot;,&quot;createdAt&quot;:&quot;2021-07-26T15:20:26+08:00&quot;,&quot;updatedAt&quot;:&quot;2021-07-26T15:20:26+08:00&quot;},&quot;username&quot;:&quot;admin&quot;,&quot;secretID&quot;:&quot;U6CxKs0YVWyOp5GrluychYIRxDmMDFd1mOOD&quot;,&quot;secretKey&quot;:&quot;fubNIn8jLA55ktuuTpXM8Iw5ogdR2mlf&quot;,&quot;expires&quot;:0,&quot;description&quot;:&quot;admin secret&quot;}\n</code></pre><ol start=\"4\">\n<li>更新secret0的描述：</li>\n</ol><pre><code>$ curl -XPUT -H&quot;Authorization: Bearer ${TOKEN}&quot; -d'{&quot;metadata&quot;:{&quot;name&quot;:&quot;secret&quot;},&quot;expires&quot;:0,&quot;description&quot;:&quot;admin secret(modify)&quot;}' http://iam.api.marmotedu.com:8080/v1/secrets/secret0\n{&quot;metadata&quot;:{&quot;id&quot;:60,&quot;instanceID&quot;:&quot;secret-jedr3e&quot;,&quot;name&quot;:&quot;secret0&quot;,&quot;createdAt&quot;:&quot;2021-07-26T15:20:26+08:00&quot;,&quot;updatedAt&quot;:&quot;2021-07-26T15:23:35.878+08:00&quot;},&quot;username&quot;:&quot;admin&quot;,&quot;secretID&quot;:&quot;U6CxKs0YVWyOp5GrluychYIRxDmMDFd1mOOD&quot;,&quot;secretKey&quot;:&quot;fubNIn8jLA55ktuuTpXM8Iw5ogdR2mlf&quot;,&quot;expires&quot;:0,&quot;description&quot;:&quot;admin secret(modify)&quot;}\n</code></pre><ol start=\"5\">\n<li>获取secret列表：</li>\n</ol><pre><code>$ curl -XGET -H&quot;Authorization: Bearer ${TOKEN}&quot; http://iam.api.marmotedu.com:8080/v1/secrets\n{&quot;totalCount&quot;:1,&quot;items&quot;:[{&quot;metadata&quot;:{&quot;id&quot;:60,&quot;instanceID&quot;:&quot;secret-jedr3e&quot;,&quot;name&quot;:&quot;secret0&quot;,&quot;createdAt&quot;:&quot;2021-07-26T15:20:26+08:00&quot;,&quot;updatedAt&quot;:&quot;2021-07-26T15:23:35+08:00&quot;},&quot;username&quot;:&quot;admin&quot;,&quot;secretID&quot;:&quot;U6CxKs0YVWyOp5GrluychYIRxDmMDFd1mOOD&quot;,&quot;secretKey&quot;:&quot;fubNIn8jLA55ktuuTpXM8Iw5ogdR2mlf&quot;,&quot;expires&quot;:0,&quot;description&quot;:&quot;admin secret(modify)&quot;}]}\n</code></pre><ol start=\"6\">\n<li>删除secret0：</li>\n</ol><pre><code>$ curl -XDELETE -H&quot;Authorization: Bearer ${TOKEN}&quot; http://iam.api.marmotedu.com:8080/v1/secrets/secret0\nnull\n</code></pre><p>上面，我给你演示了密钥的使用方法。用户和策略资源类型的使用方法跟密钥类似。详细的使用方法你可以参考 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/scripts/install/test.sh\">test.sh</a> 脚本，该脚本是用来测试IAM应用的，里面包含了各个接口的请求方法。</p><p>这里，我还想顺便介绍下<strong>如何测试IAM应用中的各个部分</strong>。确保iam-apiserver、iam-authz-server、iam-pump等服务正常运行后，进入到IAM项目的根目录，执行以下命令：</p><pre><code>$ ./scripts/install/test.sh iam::test::test # 测试整个IAM应用是否正常运行\n$ ./scripts/install/test.sh iam::test::login # 测试登陆接口是否可以正常访问\n$ ./scripts/install/test.sh iam::test::user # 测试用户接口是否可以正常访问\n$ ./scripts/install/test.sh iam::test::secret # 测试密钥接口是否可以正常访问\n$ ./scripts/install/test.sh iam::test::policy # 测试策略接口是否可以正常访问\n$ ./scripts/install/test.sh iam::test::apiserver # 测试iam-apiserver服务是否正常运行\n$ ./scripts/install/test.sh iam::test::authz # 测试authz接口是否可以正常访问\n$ ./scripts/install/test.sh iam::test::authzserver # 测试iam-authz-server服务是否正常运行\n$ ./scripts/install/test.sh iam::test::pump # 测试iam-pump是否正常运行\n$ ./scripts/install/test.sh iam::test::iamctl # 测试iamctl工具是否可以正常使用\n$ ./scripts/install/test.sh iam::test::man # 测试man文件是否正确安装\n</code></pre><p>所以，每次发布完iam-apiserver后，你可以执行以下命令来完成iam-apiserver的冒烟测试：</p><pre><code>$ export IAM_APISERVER_HOST=127.0.0.1 # iam-apiserver部署服务器的IP地址\n$ export IAM_APISERVER_INSECURE_BIND_PORT=8080 # iam-apiserver HTTP服务的监听端口\n$ ./scripts/install/test.sh iam::test::apiserver\n</code></pre><h2>iam-apiserver代码实现</h2><p>上面，我介绍了iam-apiserver的功能和使用方法，这里我们再来看下iam-apiserver具体的代码实现。我会从配置处理、启动流程、请求处理流程、代码架构4个方面来讲解。</p><h3>iam-apiserver配置处理</h3><p>iam-apiserver服务的main函数位于<a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/cmd/iam-apiserver/apiserver.go#L18\">apiserver.go</a>文件中，你可以跟读代码，了解iam-apiserver的代码实现。这里，我来介绍下iam-apiserver服务的一些设计思想。</p><p>首先，来看下iam-apiserver中的3种配置：Options配置、应用配置和 HTTP/GRPC服务配置。</p><ul>\n<li><strong>Options配置：</strong>用来构建命令行参数，它的值来自于命令行选项或者配置文件（也可能是二者Merge后的配置）。Options可以用来构建应用框架，Options配置也是应用配置的输入。</li>\n<li><strong>应用</strong><strong>配置：</strong>iam-apiserver组件中需要的一切配置。有很多地方需要配置，例如，启动HTTP/GRPC需要配置监听地址和端口，初始化数据库需要配置数据库地址、用户名、密码等。</li>\n<li><strong>HTTP/GRPC服务配置：</strong>启动HTTP服务或者GRPC服务需要的配置。</li>\n</ul><p>这三种配置的关系如下图：</p><p><img src=\"https://static001.geekbang.org/resource/image/8c/b5/8ca8d9fa1efaab21e012471874e89cb5.jpg?wh=1346x727\" alt=\"\"></p><p>Options配置接管命令行选项，应用配置接管整个应用的配置，HTTP/GRPC服务配置接管跟HTTP/GRPC服务相关的配置。这3种配置独立开来，可以解耦命令行选项、应用和应用内的服务，使得这3个部分可以独立扩展，又不相互影响。</p><p>iam-apiserver根据Options配置来构建命令行参数和应用配置。</p><p>我们通过<code>github.com/marmotedu/iam/pkg/app</code>包的<a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/pkg/app/app.go#L199\">buildCommand</a>方法来构建命令行参数。这里的核心是，通过<a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/pkg/app/app.go#L157\">NewApp</a>函数构建Application实例时，传入的<a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/apiserver/options/options.go#L19\">Options</a>实现了<code>Flags() (fss cliflag.NamedFlagSets)</code>方法，通过buildCommand方法中的以下代码，将option的Flag添加到cobra实例的FlagSet中：</p><pre><code>\tif a.options != nil {\n\t\t\tnamedFlagSets = a.options.Flags()\n\t\t\tfs := cmd.Flags()\n\t\t\tfor _, f := range namedFlagSets.FlagSets {\n\t\t\t\tfs.AddFlagSet(f)\n\t\t\t}\n\t\n            ...\n\t\t}\n</code></pre><p>通过<a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/apiserver/config/config.go#L16\">CreateConfigFromOptions</a>函数来构建应用配置：</p><pre><code>        cfg, err := config.CreateConfigFromOptions(opts)                      \n        if err != nil {                                               \n            return err                                                \n        }  \n</code></pre><p>根据应用配置来构建HTTP/GRPC服务配置。例如，以下代码根据应用配置，构建了HTTP服务器的Address参数：</p><pre><code>func (s *InsecureServingOptions) ApplyTo(c *server.Config) error {\n    c.InsecureServing = &amp;server.InsecureServingInfo{\n        Address: net.JoinHostPort(s.BindAddress, strconv.Itoa(s.BindPort)),\n    }\n\n    return nil\n}\n</code></pre><p>其中，<code>c *server.Config</code>是HTTP服务器的配置，<code>s *InsecureServingOptions</code>是应用配置。</p><h3>iam-apiserver启动流程设计</h3><p>接下来，我们来详细看下iam-apiserver的启动流程设计。启动流程如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/8a/c7/8a94938bc087ed96d0ec87261db292c7.jpg?wh=4770x1487\" alt=\"\"></p><p><strong>首先，</strong>通过<code>opts := options.NewOptions()</code>创建带有默认值的Options类型变量opts。opts变量作为<code>github.com/marmotedu/iam/pkg/app</code>包的<code>NewApp</code>函数的输入参数，最终在App框架中，被来自于命令行参数或配置文件的配置（也可能是二者Merge后的配置）所填充，opts变量中各个字段的值会用来创建应用配置。</p><p><strong>接着，</strong>会注册<a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/apiserver/apiserver.go#L36\">run</a>函数到App框架中。run函数是iam-apiserver的启动函数，里面封装了我们自定义的启动逻辑。run函数中，首先会初始化日志包，这样我们就可以根据需要，在后面的代码中随时记录日志了。</p><p><strong>然后，</strong>会创建应用配置。应用配置和Options配置其实是完全独立的，二者可能完全不同，但在iam-apiserver中，二者配置项是相同的。</p><p><strong>之后，</strong>根据应用配置，创建HTTP/GRPC服务器所使用的配置。在创建配置后，会先分别进行配置补全，再使用补全后的配置创建Web服务实例，例如：</p><pre><code>genericServer, err := genericConfig.Complete().New()\nif err != nil {\n    return nil, err\n}\nextraServer, err := extraConfig.complete().New()\nif err != nil {\n    return nil, err\n}\n...\nfunc (c *ExtraConfig) complete() *completedExtraConfig {\n    if c.Addr == &quot;&quot; {\n        c.Addr = &quot;127.0.0.1:8081&quot;\n    }\n\n    return &amp;completedExtraConfig{c}\n}\n</code></pre><p>上面的代码中，首先调用<code>Complete</code>/<code>complete</code>函数补全配置，再基于补全后的配置，New一个HTTP/GRPC服务实例。</p><p>这里有个设计技巧：<code>complete</code>函数返回的是一个<code>*completedExtraConfig</code>类型的实例，在创建GRPC实例时，是调用<code>completedExtraConfig</code>结构体提供的<code>New</code>方法，这种设计方法可以确保我们创建的GRPC实例一定是基于complete之后的配置（completed）。</p><p>在实际的Go项目开发中，我们需要提供一种机制来处理或补全配置，这在Go项目开发中是一个非常有用的步骤。</p><p><strong>最后，</strong>调用<code>PrepareRun</code>方法，进行HTTP/GRPC服务器启动前的准备。在准备函数中，我们可以做各种初始化操作，例如初始化数据库，安装业务相关的Gin中间件、RESTful API路由等。</p><p>完成HTTP/GRPC服务器启动前的准备之后，调用<code>Run</code>方法启动HTTP/GRPC服务。在<code>Run</code>方法中，分别启动了GRPC和HTTP服务。</p><p>可以看到，整个iam-apiserver的软件框架是比较清晰的。</p><p>服务启动后，就可以处理请求了。所以接下来，我们再来看下iam-apiserver的RESTAPI请求处理流程。</p><h3>iam-apiserver 的REST API请求处理流程</h3><p>iam-apiserver的请求处理流程也是清晰、规范的，具体流程如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/94/76/9400e9855b10yyac47871a7af87e9776.jpg?wh=5771x1691\" alt=\"\"></p><p>结合上面这张图，我们来看下iam-apiserver 的REST API请求处理流程，来帮你更好地理解iam-apiserver是如何处理HTTP请求的。</p><p><strong>首先，</strong>我们通过API调用（<code>&lt;HTTP Method&gt; + &lt;HTTP Request Path&gt;</code>）请求iam-apiserver提供的RESTful API接口。</p><p><strong>接着，</strong>Gin Web框架接收到HTTP请求之后，会通过认证中间件完成请求的认证，iam-apiserver提供了Basic认证和Bearer认证两种认证方式。</p><p><strong>认证</strong><strong>通过后，</strong>请求会被我们加载的一系列中间件所处理，例如跨域、RequestID、Dump等中间件。</p><p><strong>最后，</strong>根据<code>&lt;HTTP Method&gt; + &lt;HTTP Request Path&gt;</code>进行路由匹配。</p><p>举个例子，假设我们请求的RESTful API是<code>POST + /v1/secrets</code>，Gin Web框架会根据HTTP Method和HTTP Request Path，查找注册的Controllers，最终匹配到<a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/apiserver/controller/v1/secret/create.go\">secretController.Create</a>Controller。在Create Controller中，我们会依次执行请求参数解析、请求参数校验、调用业务层的方法创建Secret、处理业务层的返回结果，最后返回最终的HTTP请求结果。</p><h3>iam-apiserver代码架构</h3><p>iam-apiserver代码设计遵循简洁架构设计，一个简洁架构具有以下5个特性：</p><ul>\n<li><strong>独立于框架：</strong>该架构不会依赖于某些功能强大的软件库存在。这可以让你使用这样的框架作为工具，而不是让你的系统陷入到框架的约束中。</li>\n<li><strong>可测试性：</strong>业务规则可以在没有UI、数据库、Web服务或其他外部元素的情况下进行测试，在实际的开发中，我们通过Mock来解耦这些依赖。</li>\n<li><strong>独立于UI ：</strong>在无需改变系统其他部分的情况下，UI可以轻松地改变。例如，在没有改变业务规则的情况下，Web UI可以替换为控制台UI。</li>\n<li><strong>独立于数据库：</strong>你可以用Mongo、Oracle、Etcd或者其他数据库来替换MariaDB，你的业务规则不要绑定到数据库。</li>\n<li><strong>独立于外部媒介：</strong>实际上，你的业务规则可以简单到根本不去了解外部世界。</li>\n</ul><p>所以，基于这些约束，每一层都必须是独立的和可测试的。iam-apiserver代码架构分为4层：模型层（Models）、控制层（Controller）、业务层 （Service）、仓库层（Repository）。从控制层、业务层到仓库层，从左到右层级依次加深。模型层独立于其他层，可供其他层引用。如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/f2/f0/f2fffd84dfbc1a6643887db3d5d541f0.jpg?wh=2498x747\" alt=\"\"></p><p>层与层之间导入包时，都有严格的导入关系，这可以防止包的循环导入问题。导入关系如下：</p><ul>\n<li>模型层的包可以被仓库层、业务层和控制层导入；</li>\n<li>控制层能够导入业务层和仓库层的包。这里需要注意，如果没有特殊需求，控制层要避免导入仓库层的包，控制层需要完成的业务功能都通过业务层来完成。这样可以使代码逻辑更加清晰、规范。</li>\n<li>业务层能够导入仓库层的包。</li>\n</ul><p>接下来，我们就来详细看下每一层所完成的功能，以及其中的一些注意点。</p><ol>\n<li>模型层（Models）</li>\n</ol><p>模型层在有些软件架构中也叫做实体层（Entities），模型会在每一层中使用，在这一层中存储对象的结构和它的方法。IAM项目模型层中的模型存放在<a href=\"https://github.com/marmotedu/api/tree/master/apiserver/v1\">github.com/marmotedu/api/apiserver/v1</a>目录下，定义了<code>User</code>、<code>UserList</code>、<code>Secret</code>、<code>SecretList</code>、<code>Policy</code>、<code>PolicyList</code>、<code>AuthzPolicy</code>模型及其方法。例如：</p><pre><code>type Secret struct {\n\t// May add TypeMeta in the future.\n\t// metav1.TypeMeta `json:&quot;,inline&quot;`\n\n\t// Standard object's metadata.\n\tmetav1.ObjectMeta `       json:&quot;metadata,omitempty&quot;`\n\tUsername          string `json:&quot;username&quot;           gorm:&quot;column:username&quot;  validate:&quot;omitempty&quot;`\n\tSecretID          string `json:&quot;secretID&quot;           gorm:&quot;column:secretID&quot;  validate:&quot;omitempty&quot;`\n\tSecretKey         string `json:&quot;secretKey&quot;          gorm:&quot;column:secretKey&quot; validate:&quot;omitempty&quot;`\n\n\t// Required: true\n\tExpires     int64  `json:&quot;expires&quot;     gorm:&quot;column:expires&quot;     validate:&quot;omitempty&quot;`\n\tDescription string `json:&quot;description&quot; gorm:&quot;column:description&quot; validate:&quot;description&quot;`\n}\n</code></pre><p>之所以将模型层的模型存放在<code>github.com/marmotedu/api</code>项目中，而不是<code>github.com/marmotedu/iam</code>项目中，是为了让这些模型能够被其他项目使用。例如，iam的模型可以被<code>github.com/marmotedu/shippy</code>应用导入。同样，shippy应用的模型也可以被iam项目导入，导入关系如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/13/c9/1307e374f4193ecc3d5b73a987cdd0c9.jpg?wh=3896x1433\" alt=\"\"></p><p>上面的依赖关系都是单向的，依赖关系清晰，不存在循环依赖的情况。</p><p>要增加shippy的模型定义，只需要在api目录下创建新的目录即可。例如，shippy应用中有一个vessel服务，其模型所在的包可以为<code>github.com/marmotedu/api/vessel</code>。</p><p>另外，这里的模型既可以作为数据库模型，又可以作为API接口的请求模型（入参、出参）。如果我们能够确保<strong>创建资源时的属性</strong>、<strong>资源保存在数据库中的属性</strong>、<strong>返回资源的属性</strong>三者一致，就可以使用同一个模型。通过使用同一个模型，可以使我们的代码更加简洁、易维护，并能提高开发效率。如果这三个属性有差异，你可以另外新建模型来适配。</p><ol start=\"2\">\n<li>仓库层（Repository)</li>\n</ol><p>仓库层用来跟数据库/第三方服务进行CURD交互，作为应用程序的数据引擎进行应用数据的输入和输出。这里需要注意，仓库层仅对数据库/第三方服务执行CRUD操作，不封装任何业务逻辑。</p><p>仓库层也负责选择应用中将要使用什么样的数据库，可以是MySQL、MongoDB、MariaDB、Etcd等。无论使用哪种数据库，都要在这层决定。仓库层依赖于连接数据库或其他第三方服务（如果存在的话）。</p><p>这一层也会起到数据转换的作用：将从数据库/微服务中获取的数据转换为控制层、业务层能识别的数据结构，将控制层、业务层的数据格式转换为数据库或微服务能识别的数据格式。</p><p>iam-apiserver的仓库层位于<a href=\"https://github.com/marmotedu/iam/tree/v1.0.3/internal/apiserver/store/mysql\">internal/apiserver/store/mysql</a>目录下，里面的方法用来跟MariaDB进行交互，完成CURD操作，例如，从数据库中获取密钥：</p><pre><code>func (s *secrets) Get(ctx context.Context, username, name string, opts metav1.GetOptions) (*v1.Secret, error) {\n    secret := &amp;v1.Secret{}\n    err := s.db.Where(&quot;username = ? and name= ?&quot;, username, name).First(&amp;secret).Error\n    if err != nil {\n        if errors.Is(err, gorm.ErrRecordNotFound) {\n            return nil, errors.WithCode(code.ErrSecretNotFound, err.Error())\n        }\n\n        return nil, errors.WithCode(code.ErrDatabase, err.Error())\n    }\n\n    return secret, nil\n}\n</code></pre><ol start=\"3\">\n<li>业务层 (Service)</li>\n</ol><p>业务层主要用来完成业务逻辑处理，我们可以把所有的业务逻辑处理代码放在业务层。业务层会处理来自控制层的请求，并根据需要请求仓库层完成数据的CURD操作。业务层功能如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/61/b6/6103c58d837fd81769977bc3c947ffb6.jpg?wh=1796x1236\" alt=\"\"></p><p>iam-apiserver的业务层位于<a href=\"https://github.com/marmotedu/iam/tree/v1.0.3/internal/apiserver/service\">internal/apiserver/service</a>目录下。下面是iam-apiserver业务层中，用来创建密钥的函数：</p><pre><code>func (s *secretService) Create(ctx context.Context, secret *v1.Secret, opts metav1.CreateOptions) error {\n    if err := s.store.Secrets().Create(ctx, secret, opts); err != nil {\n        return errors.WithCode(code.ErrDatabase, err.Error())\n    }\n\n    return nil\n}\n</code></pre><p>可以看到，业务层最终请求仓库层的<code>s.store</code>的<code>Create</code>方法，将密钥信息保存在MariaDB数据库中。</p><ol start=\"4\">\n<li>控制层（Controller）</li>\n</ol><p>控制层接收HTTP请求，并进行参数解析、参数校验、逻辑分发处理、请求返回这些操作。控制层会将逻辑分发给业务层，业务层处理后返回，返回数据在控制层中被整合再加工，最终返回给请求方。控制层相当于实现了业务路由的功能。具体流程如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/12/08/120137fc2749aa12a013099ec11e1b08.jpg?wh=960x1029\" alt=\"\"></p><p>这里我有个建议，不要在控制层写复杂的代码，如果需要，请将这些代码分发到业务层或其他包中。</p><p>iam-apiserver的控制层位于<a href=\"https://github.com/marmotedu/iam/tree/v1.0.3/internal/apiserver/controller\">internal/apiserver/controller</a>目录下。下面是iam-apiserver控制层中创建密钥的代码：</p><pre><code>func (s *SecretHandler) Create(c *gin.Context) {\n\tlog.L(c).Info(&quot;create secret function called.&quot;)\n\n\tvar r v1.Secret\n\n\tif err := c.ShouldBindJSON(&amp;r); err != nil {\n\t\tcore.WriteResponse(c, errors.WithCode(code.ErrBind, err.Error()), nil)\n\n\t\treturn\n\t}\n\n\tif errs := r.Validate(); len(errs) != 0 {\n\t\tcore.WriteResponse(c, errors.WithCode(code.ErrValidation, errs.ToAggregate().Error()), nil)\n\n\t\treturn\n\t}\n\n\tusername := c.GetString(middleware.UsernameKey)\n\n\tsecrets, err := s.srv.Secrets().List(c, username, metav1.ListOptions{\n\t\tOffset: pointer.ToInt64(0),\n\t\tLimit:  pointer.ToInt64(-1),\n\t})\n\tif err != nil {\n\t\tcore.WriteResponse(c, errors.WithCode(code.ErrDatabase, err.Error()), nil)\n\n\t\treturn\n\t}\n\n\tif secrets.TotalCount &gt;= maxSecretCount {\n\t\tcore.WriteResponse(c, errors.WithCode(code.ErrReachMaxCount, &quot;secret count: %d&quot;, secrets.TotalCount), nil)\n\n\t\treturn\n\t}\n\n\t// must reassign username\n\tr.Username = username\n\n\tif err := s.srv.Secrets().Create(c, &amp;r, metav1.CreateOptions{}); err != nil {\n\t\tcore.WriteResponse(c, err, nil)\n\n\t\treturn\n\t}\n\n\tcore.WriteResponse(c, nil, r)\n}\n</code></pre><p>上面的代码完成了以下操作：</p><ol>\n<li>解析HTTP请求参数。</li>\n<li>进行参数验证，这里可以添加一些业务性质的参数校验，例如：<code>secrets.TotalCount &gt;= maxSecretCount</code>。</li>\n<li>调用业务层<code>s.srv</code>的<code>Create</code>方法，完成密钥的创建。</li>\n<li>返回HTTP请求参数。</li>\n</ol><p>上面，我们介绍了iam-apiserver采用的4层结构，接下来我们再看看<strong>每一层之间是如何通信的</strong>。</p><p>除了模型层，控制层、业务层、仓库层之间都是通过接口进行通信的。通过接口通信，一方面可以使相同的功能支持不同的实现（也就是说具有插件化能力），另一方面也使得每一层的代码变得可测试。</p><p>这里，我用创建密钥API请求的例子，来给你讲解下层与层之间是如何进行通信的。</p><p><strong>首先，来看下控制层如何跟业务层进行通信。</strong></p><p>对密钥的请求处理都是通过SecretController提供的方法来处理的，创建密钥调用的是它的<code>Create</code>方法：</p><pre><code>func (s *SecretController) Create(c *gin.Context) {\n    ...\n\tif err := s.srv.Secrets().Create(c, &amp;r, metav1.CreateOptions{}); err != nil {\n\t\tcore.WriteResponse(c, err, nil)\n\n\t\treturn\n\t}\n\t...\n}\n</code></pre><p>在<code>Create</code>方法中，调用了<code>s.srv.Secrets().Create()</code>来创建密钥，<code>s.srv</code>是一个接口类型，定义如下：</p><pre><code>type Service interface {\n    Users() UserSrv\n    Secrets() SecretSrv\n    Policies() PolicySrv\n}\n\ntype SecretSrv interface {                                                             \n    Create(ctx context.Context, secret *v1.Secret, opts metav1.CreateOptions) error    \n    Update(ctx context.Context, secret *v1.Secret, opts metav1.UpdateOptions) error            \n    Delete(ctx context.Context, username, secretID string, opts metav1.DeleteOptions) error                        \n    DeleteCollection(ctx context.Context, username string, secretIDs []string, opts metav1.DeleteOptions) error    \n    Get(ctx context.Context, username, secretID string, opts metav1.GetOptions) (*v1.Secret, error)    \n    List(ctx context.Context, username string, opts metav1.ListOptions) (*v1.SecretList, error)    \n} \n</code></pre><p>可以看到，控制层通过业务层提供的<code>Service</code>接口类型，剥离了业务层的具体实现。业务层的Service接口类型提供了<code>Secrets()</code>方法，该方法返回了一个实现了<code>SecretSrv</code>接口的实例。在控制层中，通过调用该实例的<code>Create(ctx context.Context, secret *v1.Secret, opts metav1.CreateOptions) error</code>方法来完成密钥的创建。至于业务层是如何创建密钥的，控制层不需要知道，也就是说创建密钥可以有多种实现。</p><p>这里使用到了设计模式中的<strong>工厂方法模式</strong>。<code>Service</code>是工厂接口，里面包含了一系列创建具体业务层对象的工厂函数：<code>Users()</code>、<code>Secrets()</code>、<code>Policies()</code>。通过工厂方法模式，不仅隐藏了业务层对象的创建细节，而且还可以很方便地在<code>Service</code>工厂接口实现方法中添加新的业务层对象。</p><p>例如，我们想新增一个<code>Template</code>业务层对象，用来在iam-apiserver中预置一些策略模板，可以这么来加：</p><pre><code>type Service interface {\n    Users() UserSrv\n    Secrets() SecretSrv\n    Policies() PolicySrv\n    Templates() TemplateSrv\n}\n\nfunc (s *service) Templates() TemplateSrv {\n    return newTemplates(s)\n}\n</code></pre><p>接下来，新建一个<code>template.go</code>文件：</p><pre><code>type TemplateSrv interface {\n    Create(ctx context.Context, template *v1.Template, opts metav1.CreateOptions) error\n    // Other methods\n}\n\ntype templateService struct {\n    store store.Factory\n}\n\nvar _ TemplateSrv = (*templateService)(nil)\n\nfunc newTemplates(srv *service) *TemplateService {\n    // more create logic\n    return &amp;templateService{store: srv.store}\n}\n\nfunc (u *templateService) Create(ctx context.Context, template *v1.Template, opts metav1.CreateOptions) error {\n    // normal code\n\n    return nil\n}\n</code></pre><p>可以看到，我们通过以下三步新增了一个业务层对象：</p><ol>\n<li>在<code>Service</code>接口定义中，新增了一个入口：<code>Templates() TemplateSrv</code>。</li>\n<li>在<code>service.go</code>文件中，新增了一个函数：<code>Templates()</code>。</li>\n<li>新建了<code>template.go</code>文件，在<code>template.go</code>中定义了templateService结构体，并为它实现了<code>TemplateSrv</code>接口。</li>\n</ol><p>可以看到，我们新增的Template业务对象的代码几乎都闭环在<code>template.go</code>文件中。对已有的<code>Service</code>工厂接口的创建方法，除了新增一个工厂方法<code>Templates() TemplateSrv</code>外，没有其他任何入侵。这样做可以避免影响已有业务。</p><p>在实际项目开发中，你也有可能会想到下面这种错误的创建方式：</p><pre><code>// 错误方法一\ntype Service interface {\n    UserSrv\n    SecretSrv\n    PolicySrv\n    TemplateSrv\n}\n</code></pre><p>上面的创建方式中，我们如果想创建User和Secret，那只能定义两个不同的方法：CreateUser和 CreateSecret，远没有在User和Secret各自的域中提供同名的Create方法来得优雅。</p><p>IAM项目中还有其他地方也使用了工厂方法模式，例如<a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/apiserver/store/store.go#L12\">Factory</a>工厂接口。</p><p><strong>再来看下业务层和仓库层是如何通信的。</strong></p><p>业务层和仓库层也是通过接口来通信的。例如，在业务层中创建密钥的代码如下：</p><pre><code>func (s *secretService) Create(ctx context.Context, secret *v1.Secret, opts metav1.CreateOptions) error {\n    if err := s.store.Secrets().Create(ctx, secret, opts); err != nil {\n        return errors.WithCode(code.ErrDatabase, err.Error())\n    }\n\n    return nil\n}\n</code></pre><p><code>Create</code>方法中调用了<code>s.store.Secrets().Create()</code>方法来将密钥保存到数据库中。<code>s.store</code>是一个接口类型，定义如下：</p><pre><code>type Factory interface {\n    Users() UserStore\n    Secrets() SecretStore\n    Policies() PolicyStore\n    Close() error\n}\n</code></pre><p>业务层与仓库层的通信实现，和控制层与业务层的通信实现类似，所以这里不再详细介绍。</p><p>到这里我们知道了，控制层、业务层和仓库层之间是通过接口来通信的。通过接口通信有一个好处，就是可以让各层变得可测。那接下来，我们就来看下<strong>如何测试各层的代码</strong>。因为<strong>第38讲</strong>和<strong>第39讲</strong>会详细介绍如何测试Go代码，所以这里只介绍下测试思路。</p><ol>\n<li>模型层</li>\n</ol><p>因为模型层不依赖其他任何层，我们只需要测试其中定义的结构及其函数和方法即可。</p><ol start=\"2\">\n<li>控制层</li>\n</ol><p>控制层依赖于业务层，意味着该层需要业务层来支持测试。你可以通过<a href=\"https://github.com/golang/mock\">golang/mock</a>来mock业务层，测试用例可参考<a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/apiserver/controller/v1/user/create_test.go#L19\">TestUserController_Create</a>。</p><ol start=\"3\">\n<li>业务层</li>\n</ol><p>因为该层依赖于仓库层，意味着该层需要仓库层来支持测试。我们有两种方法来模拟仓库层：</p><ul>\n<li>通过<code>golang/mock</code>来mock仓库层。</li>\n<li>自己开发一个fake仓库层。</li>\n</ul><p>使用<code>golang/mock</code>的测试用例，你可以参考<a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/apiserver/service/v1/secret_test.go#L19\">Test_secretService_Create</a>。</p><p>fake的仓库层可以参考<a href=\"https://github.com/marmotedu/iam/tree/v1.0.4/internal/apiserver/store/fake\">fake</a>，使用该fake仓库层进行测试的测试用例为<a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/apiserver/service/v1/user_test.go#L76\"> Test_userService_List</a>。</p><ol start=\"4\">\n<li>仓库层</li>\n</ol><p>仓库层依赖于数据库，如果调用了其他微服务，那还会依赖第三方服务。我们可以通过<a href=\"https://github.com/DATA-DOG/go-sqlmock\">sqlmock</a>来模拟数据库连接，通过<a href=\"https://github.com/jarcoal/httpmock\">httpmock</a>来模拟HTTP请求。</p><h2>总结</h2><p>这一讲，我主要介绍了iam-apiserver的功能和使用方法，以及它的代码实现。iam-apiserver是一个Web服务，提供了REST API来完成用户、密钥、策略三种REST资源的增删改查。我们可以通过cURL、Insomnia等工具，来完成REST API请求。</p><p>iam-apiserver包含了3种配置：Options配置、应用配置、HTTP/GRPC服务配置。这三种配置分别用来构建命令行参数、应用和HTTP/GRPC服务。</p><p>iam-apiserver在启动时，会先构建应用框架，接着会设置应用选项，然后对应用进行初始化，最后创建HTTP/GRPC服务的配置和实例，最终启动HTTP/GRPC服务。</p><p>服务启动之后，就可以接收HTTP请求了。一个HTTP请求会先进行认证，接着会被注册的中间件处理，然后，会根据<code>(HTTP Method, HTTP Request Path)</code>匹配到处理函数。在处理函数中，会解析请求参数、校验参数、调用业务逻辑处理函数，最终返回请求结果。</p><p>iam-apiserver采用了简洁架构，整个应用分为4层：模型层、控制层、业务层和仓库层。模型层存储对象的结构和它的方法；仓库层用来跟数据库/第三方服务进行CURD交互；业务层主要用来完成业务逻辑处理；控制层接收HTTP请求，并进行参数解析、参数校验、逻辑分发处理、请求返回操作。控制层、业务层、仓库层之间通过接口通信，通过接口通信可以使相同的功能支持不同的实现，并使每一层的代码变得可测试。</p><h2>课后练习</h2><ol>\n<li>\n<p>iam-apiserver和iam-authz-server都提供了REST API服务，阅读它们的源码，看看iam-apiserver和iam-authz-server是如何共享REST API相关代码的。</p>\n</li>\n<li>\n<p>思考一下，iam-apiserver的服务构建方式，能够再次抽象成一个模板（Go包）吗？如果能，该如何抽象？</p>\n</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"27 | 权限模型：5大权限模型是如何进行资源授权的？","id":400213},"right":{"article_title":"29｜控制流（下）：iam-apiserver服务核心功能实现讲解","id":402206}}},{"article_id":402206,"article_title":"29｜控制流（下）：iam-apiserver服务核心功能实现讲解","article_content":"<p>你好，我是孔令飞。</p><p><a href=\"https://time.geekbang.org/column/article/401190\">上一讲</a>，我介绍了 iam-apiserver 是如何构建 Web 服务的。这一讲，我们再来看下 iam-apiserver 中的核心功能实现。在对这些核心功能的讲解中，我会向你传达我的程序设计思路。</p><p>iam-apiserver 中包含了很多优秀的设计思想和实现，这些点可能比较零碎，但我觉得很值得分享给你。我将这些关键代码设计分为 3 类，分别是应用框架相关的特性、编程规范相关的特性和其他特性。接下来，我们就来详细看看这些设计点，以及它们背后的设计思想。</p><h2>应用框架相关的特性</h2><p>应用框架相关的特性包括三个，分别是优雅关停、健康检查和插件化加载中间件。</p><h3>优雅关停</h3><p>在讲优雅关停之前，先来看看不优雅的停止服务方式是什么样的。</p><p>当我们需要重启服务时，首先需要停止服务，这时可以通过两种方式来停止我们的服务：</p><ul>\n<li>在 Linux 终端键入 Ctrl + C（其实是发送 SIGINT 信号）。</li>\n<li>发送 SIGTERM 信号，例如 <code>kill</code> 或者 <code>systemctl stop</code> 等。</li>\n</ul><p>当我们使用以上两种方式停止服务时，都会产生下面两个问题：</p><ul>\n<li>有些请求正在处理，如果服务端直接退出，会造成客户端连接中断，请求失败。</li>\n<li>我们的程序可能需要做一些清理工作，比如等待进程内任务队列的任务执行完成，或者拒绝接受新的消息等。</li>\n</ul><!-- [[[read_end]]] --><p>这些问题都会对业务造成影响，所以我们需要一种优雅的方式来关停我们的应用。在 Go 开发中，通常通过拦截 <code>SIGINT</code> 和 <code>SIGTERM</code> 信号，来实现优雅关停。当收到这两个信号时，应用进程会做一些清理工作，然后结束阻塞状态，继续执行余下的代码，最后自然退出进程。</p><p>先来看一个简单的优雅关停的示例代码：</p><pre><code class=\"language-go\">package main\n\nimport (\n    \"context\"\n    \"log\"\n    \"net/http\"\n    \"os\"\n    \"os/signal\"\n    \"time\"\n\n    \"github.com/gin-gonic/gin\"\n)\n\nfunc main() {\n    router := gin.Default()\n    router.GET(\"/\", func(c *gin.Context) {\n        time.Sleep(5 * time.Second)\n        c.String(http.StatusOK, \"Welcome Gin Server\")\n    })\n\n    srv := &amp;http.Server{\n        Addr:    \":8080\",\n        Handler: router,\n    }\n\n    go func() {\n        // 将服务在 goroutine 中启动\n        if err := srv.ListenAndServe(); err != nil &amp;&amp; err != http.ErrServerClosed {\n            log.Fatalf(\"listen: %s\\n\", err)\n        }\n    }()\n\n    quit := make(chan os.Signal)\n    signal.Notify(quit, os.Interrupt)\n    &lt;-quit // 阻塞等待接收 channel 数据\n    log.Println(\"Shutdown Server ...\")\n\n    ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second) // 5s 缓冲时间处理已有请求\n    defer cancel()\n    if err := srv.Shutdown(ctx); err != nil { // 调用 net/http 包提供的优雅关闭函数：Shutdown\n        log.Fatal(\"Server Shutdown:\", err)\n    }\n    log.Println(\"Server exiting\")\n}\n</code></pre><p>上面的代码实现优雅关停的思路如下：</p><ol>\n<li>将 HTTP 服务放在 goroutine 中运行，程序不阻塞，继续执行。</li>\n<li>创建一个无缓冲的 channel  <code>quit</code>，调用 <code>signal.Notify(quit, os.Interrupt)</code>。通过 signal.Notify 函数调用，可以将进程收到的 os.Interrupt（SIGINT）信号，发送给 channel <code>quit</code>。</li>\n<li><code>&lt;-quit</code> 阻塞当前 goroutine（也就是 main 函数所在的 goroutine），等待从 channel <code>quit</code> 接收关停信号。通过以上步骤，我们成功启动了 HTTP 服务，并且 main 函数阻塞，防止启动 HTTP 服务的 goroutine 退出。当我们键入 <code>Ctrl + C</code>时，进程会收到 SIGINT 信号，并将该信号发送到 channel <code>quit</code> 中，这时候<code>&lt;-quit</code>收到了 channel 另一端传来的数据，结束阻塞状态，程序继续执行。这里，<code>&lt;-quit</code>唯一目的是阻塞当前的 goroutine，所以对收到的数据直接丢弃。</li>\n<li>打印退出消息，提示准备退出当前服务。</li>\n<li>调用 <code>net/http</code> 包提供的 Shutdown 方法，Shutdown 方法会在指定的时间内处理完现有请求，并返回。</li>\n<li>最后，程序执行完 <code>log.Println(\"Server exiting\")</code> 代码后，退出 main 函数。</li>\n</ol><p><strong>iam-apiserver 也实现了优雅关停，优雅关停思路跟上面的代码类似。</strong>具体可以分为三个步骤，流程如下：</p><p><strong>第一步</strong>，创建 channel 用来接收 os.Interrupt（SIGINT）和 syscall.SIGTERM（SIGKILL）信号。</p><p>代码见 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/pkg/server/signal.go#L19\">internal/pkg/server/signal.go</a> 。</p><pre><code class=\"language-go\">var onlyOneSignalHandler = make(chan struct{})\n\nvar shutdownHandler chan os.Signal\n\nfunc SetupSignalHandler() &lt;-chan struct{} {\n    close(onlyOneSignalHandler) // panics when called twice\n\n    shutdownHandler = make(chan os.Signal, 2)\n\n    stop := make(chan struct{})\n\n    signal.Notify(shutdownHandler, shutdownSignals...)\n\n    go func() {\n        &lt;-shutdownHandler\n        close(stop)\n        &lt;-shutdownHandler\n        os.Exit(1) // second signal. Exit directly.\n    }()\n\n    return stop\n}\n</code></pre><p>SetupSignalHandler 函数中，通过 <code>close(onlyOneSignalHandler)</code>来确保 iam-apiserver 组件的代码只调用一次 SetupSignalHandler 函数。否则，可能会因为信号传给了不同的 shutdownHandler，而造成信号丢失。</p><p>SetupSignalHandler 函数还实现了一个功能：收到一次 SIGINT/ SIGTERM 信号，程序优雅关闭。收到两次 SIGINT/ SIGTERM 信号，程序强制关闭。实现代码如下：</p><pre><code class=\"language-go\">go func() {\n    &lt;-shutdownHandler\n    close(stop)\n    &lt;-shutdownHandler\n    os.Exit(1) // second signal. Exit directly.\n}()\n</code></pre><p>这里要注意：<code>signal.Notify(c chan&lt;- os.Signal, sig ...os.Signal)</code>函数不会为了向 <code>c</code> 发送信息而阻塞。也就是说，如果发送时 <code>c</code> 阻塞了，signal 包会直接丢弃信号。为了不丢失信号，我们创建了有缓冲的 channel  <code>shutdownHandler</code>。</p><p>最后，SetupSignalHandler 函数会返回 <code>stop</code>，后面的代码可以通过关闭 <code>stop</code> 来结束代码的阻塞状态。</p><p><strong>第二步</strong>，将 channel  <code>stop</code> 传递给启动 HTTP（S）、gRPC 服务的函数，在函数中以 goroutine 的方式启动 HTTP（S）、gRPC 服务，然后执行 <code>&lt;-stop</code> 阻塞 goroutine。</p><p><strong>第三步</strong>，当 iam-apiserver 进程收到 SIGINT/SIGTERM 信号后，关闭 <code>stop</code>  channel，继续执行 <code>&lt;-stop</code> 后的代码，在后面的代码中，我们可以执行一些清理逻辑，或者调用 <code>google.golang.org/grpc</code>和 <code>net/http</code>包提供的优雅关停函数 GracefulStop 和 Shutdown。例如下面这个代码（位于 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/apiserver/grpc.go#L36\">internal/apiserver/grpc.go</a> 文件中）：</p><pre><code class=\"language-go\">func (s *grpcAPIServer) Run(stopCh &lt;-chan struct{}) {\n    listen, err := net.Listen(\"tcp\", s.address)\n    if err != nil {\n        log.Fatalf(\"failed to listen: %s\", err.Error())\n    }\n\n    log.Infof(\"Start grpc server at %s\", s.address)\n\n    go func() {\n        if err := s.Serve(listen); err != nil {\n            log.Fatalf(\"failed to start grpc server: %s\", err.Error())\n        }\n    }()\n\n    &lt;-stopCh\n\n    log.Infof(\"Grpc server on %s stopped\", s.address)\n    s.GracefulStop()\n}\n</code></pre><p>除了上面说的方法，iam-apiserver 还通过 <a href=\"https://github.com/marmotedu/iam/tree/v1.0.4/pkg/shutdown\">github.com/marmotedu/iam/pkg/shutdown</a> 包，实现了另外一种优雅关停方法，这个方法更加友好、更加灵活。实现代码见 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/apiserver/server.go#L81\">PrepareRun</a> 函数。</p><p><code>github.com/marmotedu/iam/pkg/shutdown</code> 包的使用方法如下：</p><pre><code class=\"language-go\">package main\nimport (\n\t\"fmt\"\n\t\"time\"\n\t\"github.com/marmotedu/iam/pkg/shutdown\"\n\t\"github.com/marmotedu/iam/pkg/shutdown/shutdownmanagers/posixsignal\"\n)\nfunc main() {\n\t// initialize shutdown\n\tgs := shutdown.New()\n\t// add posix shutdown manager\n\tgs.AddShutdownManager(posixsignal.NewPosixSignalManager())\n\t// add your tasks that implement ShutdownCallback\n\tgs.AddShutdownCallback(shutdown.ShutdownFunc(func(string) error {\n\t\tfmt.Println(\"Shutdown callback start\")\n\t\ttime.Sleep(time.Second)\n\t\tfmt.Println(\"Shutdown callback finished\")\n\t\treturn nil\n\t}))\n\t// start shutdown managers\n\tif err := gs.Start(); err != nil {\n\t\tfmt.Println(\"Start:\", err)\n\t\treturn\n\t}\n\t// do other stuff\n\ttime.Sleep(time.Hour)\n}\n</code></pre><p>上面的代码中，通过 <code>gs := shutdown.New()</code> 创建 shutdown 实例；通过 <code>AddShutdownManager</code> 方法添加监听的信号；通过 <code>AddShutdownCallback</code> 方法设置监听到指定信号时，需要执行的回调函数。这些回调函数可以执行一些清理工作。最后，通过 <code>Start</code> 方法启动 shutdown 实例。</p><h3>健康检查</h3><p>通常，我们会根据进程是否存在来判定 iam-apiserver 是否健康，例如执行 <code>ps -ef|grep iam-apiserver</code>。在实际开发中，我发现有时候服务进程仍然存在，但是 HTTP 服务却不能接收和处理请求，所以更加靠谱的检查方法是，直接请求 iam-apiserver 的健康检查接口。</p><p>我们可以在启动 iam-apiserver 进程后，手动调用 iam-apiserver 健康检查接口进行检查。但还有更方便的方法：启动服务后自动调用健康检查接口。这个方法的具体实现，你可以查看 GenericAPIServer 提供的 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/pkg/server/genericapiserver.go#L219\">ping</a> 方法。在 ping 方法中，你需要注意函数中的如下代码：</p><pre><code class=\"language-go\">url := fmt.Sprintf(\"http://%s/healthz\", s.InsecureServingInfo.Address)\nif strings.Contains(s.InsecureServingInfo.Address, \"0.0.0.0\") {\n    url = fmt.Sprintf(\"http://127.0.0.1:%s/healthz\", strings.Split(s.InsecureServingInfo.Address, \":\")[1])\n}\n</code></pre><p>当 HTTP 服务监听在所有网卡时，请求 IP 为 <code>127.0.0.1</code>；当 HTTP 服务监听在指定网卡时，我们需要请求该网卡的 IP 地址。</p><h3>插件化加载中间件</h3><p>iam-apiserver 支持插件化地加载 Gin 中间件，通过这种插件机制，我们可以根据需要选择中间件。</p><p>那么，为什么要将中间件做成一种插件化的机制呢？一方面，每个中间件都完成某种功能，这些功能不是所有情况下都需要的；另一方面，中间件是追加在 HTTP 请求链路上的一个处理函数，会影响 API 接口的性能。为了保证 API 接口的性能，我们也需要选择性地加载中间件。</p><p>例如，在测试环境中为了方便 Debug，可以选择加载 dump 中间件。dump 中间件可以打印请求包和返回包信息，这些信息可以协助我们 Debug。但是在现网环境中，我们不需要 dump 中间件来协助 Debug，而且如果加载了 dump 中间件，请求时会打印大量的请求信息，严重影响 API 接口的性能。这时候，我们就期望中间件能够按需加载。</p><p>iam-apiserver 通过 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/pkg/server/genericapiserver.go#L94\">InstallMiddlewares</a> 函数来安装 Gin 中间件，函数代码如下：</p><pre><code class=\"language-go\">func (s *GenericAPIServer) InstallMiddlewares() {\n    // necessary middlewares\n    s.Use(middleware.RequestID())\n    s.Use(middleware.Context())\n\n    // install custom middlewares\n    for _, m := range s.middlewares {\n        mw, ok := middleware.Middlewares[m]\n        if !ok {\n            log.Warnf(\"can not find middleware: %s\", m)\n\n            continue\n        }\n\n        log.Infof(\"install middleware: %s\", m)\n        s.Use(mw)\n    }\n}\n</code></pre><p>可以看到，安装中间件时，我们不仅安装了一些必备的中间件，还安装了一些可配置的中间件。</p><p>上述代码安装了两个默认的中间件： <a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/pkg/middleware/requestid.go#L22\">RequestID</a> 和 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/pkg/middleware/context.go#L17\">Context</a> 。</p><p>RequestID 中间件，主要用来在 HTTP 请求头和返回头中设置 <code>X-Request-ID</code> Header。如果 HTTP 请求头中没有 <code>X-Request-ID</code> HTTP 头，则创建 64 位的 UUID，如果有就复用。UUID 是调用 <code>github.com/satori/go.uuid</code>包提供的 <code>NewV4().String()</code>方法来生成的：</p><pre><code class=\"language-go\">rid = uuid.NewV4().String()\n</code></pre><p>另外，这里有个 Go 常量的设计规范需要你注意：常量要跟该常量相关的功能包放在一起，不要将一个项目的常量都集中放在 const 这类包中。例如， <a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/pkg/middleware/requestid.go\">requestid.go</a> 文件中，我们定义了 <code>XRequestIDKey = \"X-Request-ID\"</code>常量，其他地方如果需要使用 <code>XRequestIDKey</code>，只需要引入 <code>XRequestIDKey</code>所在的包，并使用即可。</p><p>Context 中间件，用来在 gin.Context 中设置 <code>requestID</code>和 <code>username</code>键，在打印日志时，将 gin.Context 类型的变量传递给 <code>log.L()</code> 函数，<code>log.L()</code> 函数会在日志输出中输出 <code>requestID</code>和 <code>username</code>域：</p><pre><code class=\"language-bash\">2021-07-09 13:33:21.362 DEBUG   apiserver       v1/user.go:106  get 2 users from backend storage.       {\"requestID\": \"f8477cf5-4592-4e47-bdcf-82f7bde2e2d0\", \"username\": \"admin\"}\n</code></pre><p><code>requestID</code>和 <code>username</code>字段可以方便我们后期过滤并查看日志。</p><p>除了默认的中间件，iam-apiserver 还支持一些可配置的中间件，我们可以通过配置 iam-apiserver 配置文件中的 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/configs/iam-apiserver.yaml#L11\">server.middlewares</a> 配置项，来配置这些这些中间件。</p><p>可配置以下中间件：</p><ul>\n<li>recovery：捕获任何 panic，并恢复。</li>\n<li>secure：添加一些安全和资源访问相关的 HTTP 头。</li>\n<li>nocache：禁止客户端缓存 HTTP 请求的返回结果。</li>\n<li>cors：HTTP 请求跨域中间件。</li>\n<li>dump：打印出 HTTP 请求包和返回包的内容，方便 debug。注意，生产环境禁止加载该中间件。</li>\n</ul><p>当然，你还可以根据需要，添加更多的中间件。方法很简单，只需要编写中间件，并将中间件添加到一个 <code>map[string]gin.HandlerFunc</code> 类型的变量中即可：</p><pre><code class=\"language-go\">func defaultMiddlewares() map[string]gin.HandlerFunc {&nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; return map[string]gin.HandlerFunc{&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; \"recovery\":&nbsp; gin.Recovery(),&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; \"secure\":&nbsp; &nbsp; Secure,&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; \"options\":&nbsp; &nbsp;Options,&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; \"nocache\":&nbsp; &nbsp;NoCache,&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; \"cors\":&nbsp; &nbsp; &nbsp; Cors(),&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; \"requestid\": RequestID(),&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; \"logger\":&nbsp; &nbsp; Logger(),&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; \"dump\":&nbsp; &nbsp; &nbsp; gindump.Dump(),&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; }&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n}&nbsp;&nbsp;\n</code></pre><p>上述代码位于 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/pkg/middleware/middleware.go#L56\">internal/pkg/middleware/middleware.go</a> 文件中。</p><h2>编程规范相关的特性</h2><p>编程规范相关的特性有四个，分别是 API 版本、统一的资源元数据、统一的返回、并发处理模板。</p><h3>API 版本</h3><p>RESTful API 为了方便以后扩展，都需要支持 API 版本。在<a href=\"https://time.geekbang.org/column/article/386970\"> 12 讲</a> 中，我们介绍了 API 版本号的 3 种标识方法，iam-apiserver 选择了将 API 版本号放在 URL 中，例如<code>/v1/secrets</code>。放在 URL 中的好处是很直观，看 API 路径就知道版本号。另外，API 的路径也可以很好地跟控制层、业务层、模型层的代码路径相映射。例如，密钥资源相关的代码存放位置如下：</p><pre><code class=\"language-bash\">internal/apiserver/controller/v1/secret/  # 控制几层代码存放位置\ninternal/apiserver/service/v1/secret.go # 业务层代码存放位置\ngithub.com/marmotedu/api/apiserver/v1/secret.go # 模型层代码存放位置\n</code></pre><p>关于代码存放路径，我还有一些地方想跟你分享。对于 Secret 资源，通常我们需要提供 CRUD 接口。</p><ul>\n<li>C：Create（创建 Secret）。</li>\n<li>R：Get（获取详情）、List（获取 Secret 资源列表）。</li>\n<li>U：Update（更新 Secret）。</li>\n<li>D：Delete（删除指定的 Secret）、DeleteCollection（批量删除 Secret）。</li>\n</ul><p>每个接口相互独立，为了减少更新 A 接口代码时因为误操作影响到 B 接口代码的情况，这里建议 CRUD 接口每个接口一个文件，从物理上将不同接口的代码隔离开。这种接口还可以方便我们查找 A 接口的代码所在位置。例如，Secret 控制层相关代码的存放方式如下：</p><pre><code class=\"language-bash\">$ ls internal/apiserver/controller/v1/secret/\ncreate.go  delete_collection.go  delete.go  doc.go  get.go  list.go  secret.go  update.go\n</code></pre><p>业务层和模型层的代码也可以这么组织。iam-apiserver 中，因为 Secret 的业务层和模型层代码比较少，所以我放在了 <code>internal/apiserver/service/v1/secret.go</code>和 <code>github.com/marmotedu/api/apiserver/v1/secret.go</code>文件中。如果后期 Secret 业务代码增多，我们也可以修改成下面这种方式：</p><pre><code class=\"language-bash\"> $ ls internal/apiserver/service/v1/secret/\n create.go  delete_collection.go  delete.go  doc.go  get.go  list.go  secret.go  update.go\n</code></pre><p>这里再说个题外话：<code>/v1/secret/</code>和<code>/secret/v1/</code>这两种目录组织方式都可以，你选择一个自己喜欢的就行。</p><p>当我们需要升级 API 版本时，相关代码可以直接放在 <code>v2</code> 目录下，例如：</p><pre><code class=\"language-go\">internal/apiserver/controller/v2/secret/ # v2 版本控制几层代码存放位置\ninternal/apiserver/service/v2/secret.go # v2 版本业务层代码存放位置\ngithub.com/marmotedu/api/apiserver/v2/secret.go # v2 版本模型层代码存放位置\n</code></pre><p>这样既能够跟 v1 版本的代码物理隔离开，互不影响，又方便查找 v2 版本的代码。</p><h3>统一的资源元数据</h3><p>iam-apiserver 设计的一大亮点是，<strong>像Kubernetes REST 资源一样，支持统一的资源元数据。</strong></p><p>iam-apiserver 中所有的资源都是 REST 资源，iam-apiserver 将 REST 资源的属性也进一步规范化了，这里的规范化是指所有的 REST 资源均支持两种属性：</p><ul>\n<li>公共属性。</li>\n<li>资源自有的属性。</li>\n</ul><p>例如，Secret 资源的定义方式如下：</p><pre><code class=\"language-go\">type Secret struct {\n    // May add TypeMeta in the future.\n    // metav1.TypeMeta `json:\",inline\"`\n\n    // Standard object's metadata.\n    metav1.ObjectMeta `       json:\"metadata,omitempty\"`\n    Username          string `json:\"username\"           gorm:\"column:username\"  validate:\"omitempty\"`\n    SecretID          string `json:\"secretID\"           gorm:\"column:secretID\"  validate:\"omitempty\"`\n    SecretKey         string `json:\"secretKey\"          gorm:\"column:secretKey\" validate:\"omitempty\"`\n\n    // Required: true\n    Expires     int64  `json:\"expires\"     gorm:\"column:expires\"     validate:\"omitempty\"`\n    Description string `json:\"description\" gorm:\"column:description\" validate:\"description\"`\n}\n</code></pre><p>资源自有的属性，会因资源不同而不同。这里，我们来重点看一下公共属性 <a href=\"https://github.com/marmotedu/component-base/blob/v1.0.1/pkg/meta/v1/types.go#L38\">ObjectMeta</a> ，它的定义如下：</p><pre><code>type ObjectMeta struct {\n\tID uint64 `json:&quot;id,omitempty&quot; gorm:&quot;primary_key;AUTO_INCREMENT;column:id&quot;`\n\tInstanceID string `json:&quot;instanceID,omitempty&quot; gorm:&quot;unique;column:instanceID;type:varchar(32);not null&quot;`\n\tName string `json:&quot;name,omitempty&quot; gorm:&quot;column:name;type:varchar(64);not null&quot; validate:&quot;name&quot;`\n\tExtend Extend `json:&quot;extend,omitempty&quot; gorm:&quot;-&quot; validate:&quot;omitempty&quot;`\n\tExtendShadow string `json:&quot;-&quot; gorm:&quot;column:extendShadow&quot; validate:&quot;omitempty&quot;`\n\tCreatedAt time.Time `json:&quot;createdAt,omitempty&quot; gorm:&quot;column:createdAt&quot;`\n\tUpdatedAt time.Time `json:&quot;updatedAt,omitempty&quot; gorm:&quot;column:updatedAt&quot;`\n}\n</code></pre><p>接下来，我来详细介绍公共属性中每个字段的含义及作用。</p><ol>\n<li>ID</li>\n</ol><p>这里的 ID，映射为 MariaDB 数据库中的 <code>id</code> 字段。<code>id</code> 字段在一些应用中，会作为资源的唯一标识。但 iam-apiserver 中没有使用 ID 作为资源的唯一标识，而是使用了 InstanceID。iam-apiserver 中 ID 唯一的作用是跟数据库 <code>id</code> 字段进行映射，代码中并没有使用到 <code>ID</code>。</p><ol start=\"2\">\n<li>InstanceID</li>\n</ol><p>InstanceID 是资源的唯一标识，格式为<code>&lt;resource identifier&gt;-xxxxxx</code>。其中，<code>&lt;resource identifier&gt;</code>是资源的英文标识符号，<code>xxxxxx</code>是随机字符串。字符集合为 <code>abcdefghijklmnopqrstuvwxyz1234567890</code>，长度&gt;=6，例如 <code>secret-yj8m30</code>、<code>user-j4lz3g</code>、<code>policy-3v18jq</code>。</p><p>腾讯云、阿里云、华为云也都是采用这种格式的字符串作为资源唯一标识的。</p><p>InstanceID 的生成和更新都是自动化的，通过 gorm 提供的 <code>AfterCreate</code> Hooks 在记录插入数据库之后，生成并更新到数据库的 <code>instanceID</code>字段：</p><pre><code class=\"language-go\">func (s *Secret) AfterCreate(tx *gorm.DB) (err error) {\n    s.InstanceID = idutil.GetInstanceID(s.ID, \"secret-\")\n\n    return tx.Save(s).Error\n}\n</code></pre><p>上面的代码，在 Secret 记录插入到 iam 数据库的 secret 表之后，调用 <code>idutil.GetInstanceID</code>生成 InstanceID，并通过 <code>tx.Save(s)</code>更新到数据库 secret 表的 <code>instanceID</code>字段。</p><p>因为通常情况下，应用中的 REST 资源只会保存到数据库中的一张表里，这样就能保证应用中每个资源的数据库 ID 是唯一的。所以 <code>GetInstanceID(uid uint64, prefix string) string</code>函数使用 <code>github.com/speps/go-hashids</code>包提供的方法，对这个数据库 ID 进行哈希，最终得到一个数据库级别的唯一的字符串（例如：<code>3v18jq</code>），并根据传入的 prefix，得到资源的 InstanceID。</p><p>使用这种方式生成资源的唯一标识，有下面这两个优点：</p><ul>\n<li>数据库级别唯一。</li>\n<li>InstanceID 是长度可控的字符串，长度最小是 6 个字符，但会根据表中的记录个数动态变长。根据我的测试，2176782336 条记录以内生成的 InstanceID 长度都在 6 个字符以内。长度可控的另外一个好处是方便记忆和传播。</li>\n</ul><p>这里需要你注意：如果同一个资源分别存放在不同的表中，那在使用这种方式时，生成的 InstanceID 可能相同，不过概率很小，几乎为零。这时候，我们就需要使用分布式 ID 生成技术。这又是另外一个话题了，这里不再扩展讲解。</p><p>在实际的开发中，不少开发者会使用数据库数字段 ID（例如 <code>121</code>）和 36/64 位的 UUID（例如 <code>20cd59d4-08c6-4e86-a9d4-a0e51c420a04</code> ）来作为资源的唯一标识。相较于这两种资源标识方式，使用<code>&lt;resource identifier&gt;-xxxxxx</code>这种标识方式具有以下优点：</p><ul>\n<li>看标识名就知道是什么类型的资源，例如：<code>secret-yj8m30</code>说明该资源是 secret 类型的资源。在实际的排障过程中，能够有效减少误操作。</li>\n<li>长度可控，占用数据库空间小。iam-apiserver 的资源标识长度基本可以认为是 12 个字符（secret/policy 是 6 个字符，再加 6 位随机字符）。</li>\n<li>如果使用 <code>121</code> 这类数值作为资源唯一标识，相当于间接向友商透漏系统的规模，是一定要禁止的。</li>\n</ul><p>另外，还有一些系统如 Kubernetes 中，使用资源名作为资源唯一标识。这种方式有个弊端，就是当系统中同类资源太多时，创建资源很容易重名，你自己想要的名字往往填不了，所以 iam-apiserver 不采用这种设计方式。</p><p>我们使用 instanceID 来作为资源的唯一标识，在代码中，就经常需要根据 instanceID 来查询资源。所以，在数据库中要设置该字段为唯一索引，一方面可以防止 instanceID 不唯一，另一方面也能加快查询速度。</p><ol start=\"3\">\n<li>Name</li>\n</ol><p>Name 即资源的名字，我们可以通过名字很容易地辨别一个资源。</p><ol start=\"4\">\n<li>Extend、ExtendShadow</li>\n</ol><p>Extend 和 ExtendShadow 是 iam-apiserver 设计的又一大亮点。</p><p>在实际开发中，我们经常会遇到这个问题：随着业务发展，某个资源需要增加一些属性，这时，我们可能会选择在数据库中新增一个数据库字段。但是，随着业务系统的演进，数据库中的字段越来越多，我们的 Code 也要做适配，最后就会越来越难维护。</p><p>我们还可能遇到这种情况：我们将上面说的字段保存在数据库中叫 <code>meta</code>的字段中，数据库中 <code>meta</code>字段的数据格式是<code>{\"disable\":true,\"tag\":\"colin\"}</code>。但是，我们如果想在代码中使用这些字段，需要 Unmarshal 到一个结构体中，例如：</p><pre><code class=\"language-go\">metaData := `{\"disable\":true,\"tag\":\"colin\"}`\nmeta := make(map[string]interface{})\nif err := json.Unmarshal([]byte(metaData), &amp;meta); err != nil {\n    return err\n}\n</code></pre><p>再存入数据中时，又要 Marshal 成 JSON 格式的字符串，例如：</p><pre><code class=\"language-go\">meta := map[string]interface{}{\"disable\": true, \"tag\": \"colin\"}\ndata, err := json.Marshal(meta)\nif err != nil {\n    return err\n}\n</code></pre><p>你可以看到，这种 Unmarshal 和 Marshal 操作有点繁琐。</p><p>因为每个资源都可能需要用到扩展字段，那么有没有一种通用的解决方案呢？iam-apiserver 就通过 Extend 和 ExtendShadow 解决了这个问题。</p><p>Extend 是 Extend 类型的字段，Extend 类型其实是 <code>map[string]interface{}</code>的类型别名。在程序中，我们可以很方便地引用 Extend 包含的属性，也就是 map 的 key。Extend 字段在保存到数据库中时，会自动 Marshal 成字符串，保存在 ExtendShadow 字段中。</p><p>ExtendShadow 是 Extend 在数据库中的影子。同样，当从数据库查询数据时，ExtendShadow 的值会自动 Unmarshal 到 Extend 类型的变量中，供程序使用。</p><p>具体实现方式如下：</p><ul>\n<li>借助 gorm 提供的 <code>BeforeCreate</code>、<code>BeforeUpdate</code>  Hooks，在插入记录、更新记录时，将 Extend 的值转换成字符串，保存在 ExtendShadow 字段中，并最终保存在数据库的 ExtendShadow 字段中。</li>\n<li>借助 gorm 提供的 <code>AfterFind</code>  Hooks，在查询数据后，将 ExtendShadow 的值 Unmarshal 到 Extend 字段中，之后程序就可以通过 Extend 字段来使用其中的属性。</li>\n</ul><ol start=\"5\">\n<li>CreatedAt</li>\n</ol><p>资源的创建时间。每个资源在创建时，我们都应该记录资源的创建时间，可以帮助后期进行排障、分析等。</p><ol start=\"6\">\n<li>UpdatedAt</li>\n</ol><p>资源的更新时间。每个资源在更新时，我们都应该记录资源的更新时间。资源更新时，该字段由 gorm 自动更新。</p><p>可以看到，ObjectMeta 结构体包含了很多字段，每个字段都完成了很酷的功能。那么，如果把 ObjectMeta 作为所有资源的公共属性，这些资源就会自带这些能力。</p><p>当然，有些开发者可能会说，User 资源其实是不需要 <code>user-xxxxxx</code>这种资源标识的，所以 InstanceID 这个字段其实是无用的字段。但是在我看来，和功能冗余相比，功能规范化、不重复造轮子，以及 ObjectMeta 的其他功能更加重要。所以，也建议所有的 REST 资源都使用统一的资源元数据。</p><h3>统一的返回</h3><p>在<a href=\"https://time.geekbang.org/column/article/391895\">18 讲</a> 中，我们介绍过 API 的接口返回格式应该是统一的。要想返回一个固定格式的消息，最好的方式就是使用同一个返回函数。因为 API 接口都是通过同一个函数来返回的，其返回格式自然是统一的。</p><p>IAM 项目通过 <a href=\"https://github.com/marmotedu/component-base/tree/master/pkg/core\">github.com/marmotedu/component-base/pkg/core</a> 包提供的 <a href=\"https://github.com/marmotedu/component-base/blob/master/pkg/core/core.go#L33\">WriteResponse</a> 函数来返回结果。WriteResponse 函数定义如下：</p><pre><code class=\"language-go\">func WriteResponse(c *gin.Context, err error, data interface{}) {\n    if err != nil {\n        log.Errorf(\"%#+v\", err)\n        coder := errors.ParseCoder(err)\n        c.JSON(coder.HTTPStatus(), ErrResponse{\n            Code:      coder.Code(),\n            Message:   coder.String(),\n            Reference: coder.Reference(),\n        })\n\n        return\n    }\n\n    c.JSON(http.StatusOK, data)\n}\n</code></pre><p>可以看到，WriteResponse 函数会判断 err 是否为 nil。如果不为 nil，则将 err 解析为 <code>github.com/marmotedu/errors</code>包中定义的 Coder 类型的错误，并调用 Coder 接口提供的  <code>Code()</code> 、<code>String()</code> 、<code>Reference()</code> 方法，获取该错误的业务码、对外展示的错误信息和排障文档。如果 err 为 nil，则调用 <code>c.JSON</code>返回 JSON 格式的数据。</p><h3>并发处理模板</h3><p>在 Go 项目开发中，经常会遇到这样一种场景：查询列表接口时，查询出了多条记录，但是需要针对每一条记录做一些其他逻辑处理。因为是多条记录，比如 100 条，处理每条记录延时如果为 X 毫秒，串行处理完 100 条记录，整体延时就是 <code>100 * X 毫秒</code>。如果 X 比较大，那整体处理完的延时是非常高的，会严重影响 API 接口的性能。</p><p>这时候，我们自然就会想到利用 CPU 的多核能力，并发来处理这 100 条记录。这种场景我们在实际开发中经常遇到，有必要抽象成一个并发处理模板，这样以后在查询时，就可以使用这个模板了。</p><p>例如，iam-apiserver 中，查询用户列表接口 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/apiserver/service/v1/user.go#L43\">List</a> ，还需要返回每个用户所拥有的策略个数。这就用到了并发处理。这里，我试着将其抽象成一个模板，模板如下：</p><pre><code class=\"language-go\">func (u *userService) List(ctx context.Context, opts metav1.ListOptions) (*v1.UserList, error) {\n\tusers, err := u.store.Users().List(ctx, opts)\n\tif err != nil {\n\t\tlog.L(ctx).Errorf(\"list users from storage failed: %s\", err.Error())\n\n\t\treturn nil, errors.WithCode(code.ErrDatabase, err.Error())\n\t}\n\n\twg := sync.WaitGroup{}\n\terrChan := make(chan error, 1)\n\tfinished := make(chan bool, 1)\n\n\tvar m sync.Map\n\n\t// Improve query efficiency in parallel\n\tfor _, user := range users.Items {\n\t\twg.Add(1)\n\n\t\tgo func(user *v1.User) {\n\t\t\tdefer wg.Done()\n\n            // some cost time process\n\t\t\tpolicies, err := u.store.Policies().List(ctx, user.Name, metav1.ListOptions{})\n\t\t\tif err != nil {\n\t\t\t\terrChan &lt;- errors.WithCode(code.ErrDatabase, err.Error())\n\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tm.Store(user.ID, &amp;v1.User{\n                ...\n\t\t\t\tPhone:       user.Phone,\n\t\t\t\tTotalPolicy: policies.TotalCount,\n\t\t\t})\n\t\t}(user)\n\t}\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(finished)\n\t}()\n\n\tselect {\n\tcase &lt;-finished:\n\tcase err := &lt;-errChan:\n\t\treturn nil, err\n\t}\n\n\t// infos := make([]*v1.User, 0)\n\tinfos := make([]*v1.User, 0, len(users.Items))\n\tfor _, user := range users.Items {\n\t\tinfo, _ := m.Load(user.ID)\n\t\tinfos = append(infos, info.(*v1.User))\n\t}\n\n\tlog.L(ctx).Debugf(\"get %d users from backend storage.\", len(infos))\n\n\treturn &amp;v1.UserList{ListMeta: users.ListMeta, Items: infos}, nil\n}\n</code></pre><p>在上面的并发模板中，我实现了并发处理查询结果中的三个功能：</p><p><strong>第一个功能，goroutine 报错即返回。</strong>goroutine 中代码段报错时，会将错误信息写入 <code>errChan</code>中。我们通过 List 函数中的 select 语句，实现只要有一个 goroutine 发生错误，即返回：</p><pre><code class=\"language-go\">select {\ncase &lt;-finished:\ncase err := &lt;-errChan:\n    return nil, err\n}\n</code></pre><p><strong>第二个功能，保持查询顺序。</strong>我们从数据库查询出的列表是有顺序的，比如默认按数据库 ID 字段升序排列，或者我们指定的其他排序方法。在并发处理中，这些顺序会被打断。但为了确保最终返回的结果跟我们预期的排序效果一样，在并发模板中，我们还需要保证最终返回结果跟查询结果保持一致的排序。</p><p>上面的模板中，我们将处理后的记录保存在 map 中，map 的 key 为数据库 ID。并且，在最后按照查询的 ID 顺序，依次从 map 中取出 ID 的记录，例如：</p><pre><code class=\"language-go\">    var m sync.Map\n\tfor _, user := range users.Items {\n        ...\n\t\tgo func(user *v1.User) {\n            ...\n\t\t\tm.Store(user.ID, &amp;v1.User{})\n\t\t}(user)\n\t}\n    ...\n\tinfos := make([]*v1.User, 0, len(users.Items))\n\tfor _, user := range users.Items {\n\t\tinfo, _ := m.Load(user.ID)\n\t\tinfos = append(infos, info.(*v1.User))\n\t}\n</code></pre><p>通过上面这种方式，可以确保最终返回的结果跟从数据库中查询的结果保持一致的排序。</p><p><strong>第三个功能，并发安全。</strong>Go 语言中的 map 不是并发安全的，要想实现并发安全，需要自己实现（如加锁），或者使用 sync.Map。上面的模板使用了 sync.Map。</p><p>当然了，如果期望 List 接口能在期望时间内返回，还可以添加超时机制，例如：</p><pre><code class=\"language-go\">    select {\n    case &lt;-finished:\n    case err := &lt;-errChan:\n        return nil, err\n    case &lt;-time.After(time.Duration(30 * time.Second)):\n        return nil, fmt.Errorf(\"list users timeout after 30 seconds\")\n\n    }\n</code></pre><p>goroutine 虽然很轻量，但还是会消耗资源，如果我们需要处理几百上千的并发，就需要用协程池来复用协程，达到节省资源的目的。有很多优秀的协程包可供我们直接使用，比如 <a href=\"https://github.com/panjf2000/ants\">ants</a> 、 <a href=\"https://github.com/Jeffail/tunny\">tunny</a> 等。</p><h2>其他特性</h2><p>除了上面那两大类，这里我还想给你介绍下关键代码设计中的其他特性，包括插件化选择 JSON 库、调用链实现、数据一致性。</p><h3>插件化选择 JSON 库</h3><p>Golang 提供的标准 JSON 解析库 encoding/json，在开发高性能、高并发的网络服务时会产生性能问题。所以很多开发者在实际的开发中，往往会选用第三方的高性能 JSON 解析库，例如 <a href=\"https://github.com/json-iterator/go\">jsoniter</a> 、 <a href=\"https://github.com/mailru/easyjson\">easyjson</a> 、 <a href=\"https://github.com/buger/jsonparser\">jsonparser</a> 等。</p><p>我见过的很多开发者选择了 jsoniter，也有一些开发者使用了 easyjson。jsoniter 的性能略高于 encoding/json。但随着 go 版本的迭代，encoding/json 库的性能也越来越高，jsoniter 的性能优势也越来越有限。所以，IAM 项目使用了 jsoniter 库，并准备随时切回 encoding/json 库。</p><p>为了方便切换不同的 JSON 包，iam-apiserver 采用了一种插件化的机制来使用不同的 JSON 包。具体是通过使用 go 的标签编译选择运行的解析库来实现的。</p><p>标签编译就是在源代码里添加标注，通常称之为编译标签（build tag）。编译标签通过注释的方式在靠近源代码文件顶部的地方添加。go build 在构建一个包的时候，会读取这个包里的每个源文件并且分析编译便签，这些标签决定了这个源文件是否参与本次编译。例如：</p><pre><code class=\"language-go\">// +build jsoniter\n\npackage json\n\nimport jsoniter \"github.com/json-iterator/go\"\n</code></pre><p><code>+build jsoniter</code>就是编译标签。这里要注意，一个源文件可以有多个编译标签，多个编译标签之间是逻辑“与”的关系；一个编译标签可以包括由空格分割的多个标签，这些标签是逻辑“或”的关系。例如：</p><pre><code class=\"language-go\">// +build linux darwin\n// +build 386\n</code></pre><p>这里要注意，编译标签和包的声明之间应该使用空行隔开，否则编译标签会被当作包声明的注释，而不是编译标签。</p><p>那具体来说，我们是如何实现插件化选择 JSON 库的呢？</p><p>首先，我自定义了一个 <a href=\"https://github.com/marmotedu/component-base/tree/master/pkg/json\">github.com/marmotedu/component-base/pkg/json</a> json 包，来适配 encoding/json 和 json-iterator。<code>github.com/marmotedu/component-base/pkg/json</code> 包中有两个文件：</p><ul>\n<li><strong>json.go：</strong>映射了 encoding/json 包的 Marshal、Unmarshal、MarshalIndent、NewDecoder、NewEncoder 方法。</li>\n<li><strong>jsoniter.go：</strong>映射了 github.com/json-iterator/go 包的 Marshal、Unmarshal、MarshalIndent、NewDecoder、NewEncoder。</li>\n</ul><p>json.go 和 jsoniter.go 通过编译标签，让 Go 编译器在构建代码时选择使用哪一个 json 文件。</p><p>接着，通过在执行 <code>go build</code>时指定 <a href=\"https://github.com/marmotedu/iam/blob/master/scripts/make-rules/golang.mk#L19\">-tags</a> 参数，来选择编译哪个 json 文件。</p><p>json/json.go、json/jsoniter.go 这两个 Go 文件的顶部，都有一行注释：</p><pre><code class=\"language-go\">// +build !jsoniter\n\n// +build jsoniter\n</code></pre><p><code>// +build !jsoniter</code>表示，tags 不是 jsoniter 的时候编译这个 Go 文件。<code>// +build jsoniter</code>表示，tags 是 jsoniter 的时候编译这个 Go 文件。也就是说，这两种条件是互斥的，只有当 tags=jsoniter 的时候，才会使用 json-iterator，其他情况使用 encoding/json。</p><p>例如，如果我们想使用包，可以这么编译项目：</p><pre><code class=\"language-go\">$ go build -tags=jsoniter\n</code></pre><p>在实际开发中，<strong>我们需要根据场景来选择合适的JSON 库。</strong>这里我给你一些建议。</p><p>场景一：结构体序列化和反序列化场景</p><p>在这个场景中，我个人首推的是官方的 JSON 库。可能你会比较意外，那我就来说说我的理由：</p><p>首先，虽然 easyjson 的性能压倒了其他所有开源项目，但它有一个最大的缺陷，那就是需要额外使用工具来生成这段代码，而对额外工具的版本控制就增加了运维成本。当然，如果你的团队已经能够很好地处理 protobuf 了，也是可以用同样的思路来管理 easyjson 的。</p><p>其次，虽然 Go 1.8 之前，官方 JSON 库的性能总是被大家吐槽，但现在（1.16.3）官方 JSON 库的性能已不可同日而语。此外，作为使用最为广泛，而且没有之一的 JSON 库，官方库的 bug 是最少的，兼容性也是最好的</p><p>最后，jsoniter 的性能虽然依然优于官方，但没有达到逆天的程度。如果你追求的是极致的性能，那么你应该选择 easyjson 而不是 jsoniter。jsoniter 近年已经不活跃了，比如说，我前段时间提了一个 issue 没人回复，于是就上去看了下 issue 列表，发现居然还遗留着一些 2018 年的 issue。</p><p>场景二：非结构化数据的序列化和反序列化场景</p><p>这个场景下，我们要分高数据利用率和低数据利用率两种情况来看。你可能对数据利用率的高低没啥概念，那我举个例子：JSON 数据的正文中，如果说超过四分之一的数据都是业务需要关注和处理的，那就算是高数据利用率。</p><p>在高数据利用率的情况下，我推荐使用 jsonvalue。</p><p>至于低数据利用率的情况，还可以根据 <strong>JSON 数据是否需要重新序列化，</strong>分成两种情况。</p><p>如果无需重新序列化，这个时候选择 jsonparser 就行了，因为它的性能实在是耀眼。</p><p>如果需要重新序列化，这种情况下你有两种选择：如果对性能要求相对较低，可以使用 jsonvalue；如果对性能的要求高，并且只需要往二进制序列中插入一条数据，那么可以采用 jsoniter 的 Set 方法。</p><p>实际操作中，超大 JSON 数据量，并且同时需要重新序列化的情况非常少，往往是在代理服务器、网关、overlay 中继服务等，同时又需要往原数据中注入额外信息的时候。换句话说，jsoniter 的适用场景比较有限。</p><p>下面是从 10%到 60%数据覆盖率下，不同库的操作效率对比（纵坐标单位：μs/op）：</p><p><img src=\"https://static001.geekbang.org/resource/image/fc/a6/fcc79727a26a37345af705df1179c1a6.png?wh=1920x1266\" alt=\"图片\"></p><p>可以看到，当 jsoniter 的数据利用率达到 25% 时，和 jsonvalue、jsonparser 相比就已经没有任何优势；至于 jsonvalue，由于对数据做了一次性的全解析，因此解析后的数据存取耗时极少，因此在不同数据覆盖率下的耗时都很稳定。</p><h3>调用链实现</h3><p>调用链对查日志、排障帮助非常大。所以，在 iam-apiserver 中也实现了调用链，通过 <code>requestID</code>来串联整个调用链。</p><p>具体是通过以下两步来实现的：</p><p>第一步，将 <code>ctx context.Context</code> 类型的变量作为函数的第一个参数，在函数调用时传递。</p><p>第二步，不同函数中，通过 <code>log.L(ctx context.Context)</code>来记录日志。</p><p>在请求到来时，请求会通过 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/pkg/middleware/context.go#L17\">Context</a> 中间件处理：</p><pre><code class=\"language-go\">func Context() gin.HandlerFunc {\n\treturn func(c *gin.Context) {\n\t\tc.Set(log.KeyRequestID, c.GetString(XRequestIDKey))\n\t\tc.Set(log.KeyUsername, c.GetString(UsernameKey))\n\t\tc.Next()\n\t}\n}\n</code></pre><p>在 Context 中间件中，会在 gin.Context 类型的变量中设置 <code>log.KeyRequestID</code>键，其值为 36 位的 UUID。UUID 通过 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/pkg/middleware/requestid.go#L22\">RequestID</a> 中间件来生成，并设置在 gin 请求的 Context 中。</p><p>RequestID 中间件在 Context 中间件之前被加载，所以在 Context 中间件被执行时，能够获取到 RequestID 生成的 UUID。</p><p><code>log.L(ctx context.Context)</code>函数在记录日志时，会从头 ctx 中获取到 <code>log.KeyRequestID</code>，并作为一个附加字段随日志打印。</p><p>通过以上方式，我们最终可以形成 iam-apiserver 的请求调用链，日志示例如下：</p><pre><code class=\"language-plain\">2021-07-19 19:41:33.472 INFO&nbsp; &nbsp; apiserver&nbsp; &nbsp; &nbsp; &nbsp;apiserver/auth.go:205&nbsp; &nbsp;user `admin` is authenticated.&nbsp; {\"requestID\": \"b6c56cd3-d095-4fd5-a928-291a2e33077f\", \"username\": \"admin\"}\n2021-07-19 19:41:33.472 INFO&nbsp; &nbsp; apiserver&nbsp; &nbsp; &nbsp; &nbsp;policy/create.go:22&nbsp; &nbsp; &nbsp;create policy function called.&nbsp; {\"requestID\": \"b6c56cd3-d095-4fd5-a928-291a2e33077f\", \"username\": \"admin\"}\n...\n</code></pre><p>另外，<code>ctx context.Context</code>作为函数/方法的第一个参数，还有一个好处是方便后期扩展。例如，如果我们有以下调用关系：</p><pre><code class=\"language-go\">package main\n\nimport \"fmt\"\n\nfunc B(name, address string) string {\n    return fmt.Sprintf(\"name: %s, address: %s\", name, address)\n}\n\nfunc A() string {\n    return B(\"colin\", \"sz\")\n}\n\nfunc main() {\n    fmt.Println(A())\n}\n</code></pre><p>上面的代码最终调用 <code>B</code>函数打印出用户名及其地址。如果随着业务的发展，希望 A 调用 B 时，传入用户的电话，B 中打印出用户的电话号码。这时候，我们可能会考虑给 B 函数增加一个电话号参数，例如：</p><pre><code class=\"language-go\">func B(name, address, phone string) string {\n    return fmt.Sprintf(\"name: %s, address: %s, phone: %s\", name, address)\n}\n</code></pre><p>如果我们后面还要增加年龄、性别等属性呢？按这种方式不断增加 B 函数的参数，不仅麻烦，而且还要改动所有调用 B 的函数，工作量也很大。这时候，可以考虑通过 <code>ctx context.Context</code> 来传递这些扩展参数，实现如下：</p><pre><code class=\"language-go\">package main\n\nimport (\n    \"context\"\n    \"fmt\"\n)\n\nfunc B(ctx context.Context, name, address string) string {\n    return fmt.Sprintf(\"name: %s, address: %s, phone: %v\", name, address, ctx.Value(\"phone\"))\n}\n\nfunc A() string {\n    ctx := context.WithValue(context.TODO(), \"phone\", \"1812884xxxx\")\n    return B(ctx, \"colin\", \"sz\")\n}\n\nfunc main() {\n    fmt.Println(A())\n}\n</code></pre><p>这样，我们下次需要新增参数的话，只需要调用 context 的 WithValue 方法：</p><pre><code class=\"language-go\">ctx = context.WithValue(ctx, \"sex\", \"male\")\n</code></pre><p>在 B 函数中，通过 <code>context.Context</code> 类型的变量提供的 <code>Value</code> 方法，从 context 中获取 <code>sex</code> key 即可：</p><pre><code class=\"language-go\">return fmt.Sprintf(\"name: %s, address: %s, phone: %v, sex: %v\", name, address, ctx.Value(\"phone\"), ctx.Value(\"sex\"))\n</code></pre><h3>数据一致性</h3><p>为了提高 iam-authz-server 的响应性能，我将密钥和授权策略信息缓存在 iam-authz-server 部署机器的内存中。同时，为了实现高可用，我们需要保证 iam-authz-server 启动的实例个数至少为两个。这时候，我们会面临数据一致性的问题：所有 iam-authz-server 缓存的数据要一致，并且跟 iam-apiserver 数据库中保存的一致。iam-apiserver 通过如下方式来实现数据一致性：</p><p><img src=\"https://static001.geekbang.org/resource/image/4c/b7/4ce0ff51e4cecb12f7234241137c20b7.jpg?wh=2248x798\" alt=\"\"></p><p>具体流程如下：</p><p>第一步，iam-authz-server 启动时，会通过 grpc 调用 iam-apiserver 的 GetSecrets 和 GetPolicies 接口，获取所有的密钥和授权策略信息。</p><p>第二步，当我们通过控制台调用 iam-apiserver 密钥/授权策略的写接口（POST、PUT、DELETE）时，会向 Redis 的 <code>iam.cluster.notifications</code>通道发送 SecretChanged/PolicyChanged 消息。</p><p>第三步，iam-authz-server 会订阅 <code>iam.cluster.notifications</code>通道，当监听到有 SecretChanged/PolicyChanged 消息时，会请求 iam-apiserver 拉取所有的密钥/授权策略。</p><p>通过 Redis 的 Sub/Pub 机制，保证每个 iam-authz-server 节点的缓存数据跟 iam-apiserver 数据库中保存的数据一致。所有节点都调用 iam-apiserver 的同一个接口来拉取数据，通过这种方式保证所有 iam-authz-server 节点的数据是一致的。</p><h2>总结</h2><p>今天，我和你分享了 iam-apiserver 的一些关键功能实现，并介绍了我的设计思路。这里我再简要梳理下。</p><ul>\n<li>为了保证进程关停时，HTTP 请求执行完后再断开连接，进程中的任务正常完成，iam-apiserver 实现了优雅关停功能。</li>\n<li>为了避免进程存在，但服务没成功启动的异常场景，iam-apiserver 实现了健康检查机制。</li>\n<li>Gin 中间件可通过配置文件配置，从而实现按需加载的特性。</li>\n<li>为了能够直接辨别出 API 的版本，iam-apiserver 将 API 的版本标识放在 URL 路径中，例如 <code>/v1/secrets</code>。</li>\n<li>为了能够最大化地共享功能代码，iam-apiserver 抽象出了统一的元数据，每个 REST 资源都具有这些元数据。</li>\n<li>因为 API 接口都是通过同一个函数来返回的，其返回格式自然是统一的。</li>\n<li>因为程序中经常需要处理并发逻辑，iam-apiserver 抽象出了一个通用的并发模板。</li>\n<li>为了方便根据需要切换 JSON 库，我们实现了插件化选择 JSON 库的功能。</li>\n<li>为了实现调用链功能，iam-apiserver 不同函数之间通过 <code>ctx context.Context</code> 来传递 RequestID。</li>\n<li>iam-apiserver 通过 Redis 的 Sub/Pub 机制来保证数据一致性。</li>\n</ul><h2>课后练习</h2><ol>\n<li>思考一下，在你的项目开发中，使用过哪些更好的并发处理方式，欢迎你在留言区分享。</li>\n<li>试着给 iam-apiserver 增加一个新的、可配置的 Gin 中间件，用来实现 API 限流的效果。</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"28 | 控制流（上）：通过iam-apiserver设计，看Web服务的构建","id":401190},"right":{"article_title":"30 | ORM：CURD 神器 GORM 包介绍及实战","id":403351}}},{"article_id":403351,"article_title":"30 | ORM：CURD 神器 GORM 包介绍及实战","article_content":"<p>你好，我是孔令飞。</p><p>在用Go开发项目时，我们免不了要和数据库打交道。每种语言都有优秀的ORM可供选择，在Go中也不例外，比如<a href=\"https://github.com/go-gorm/gorm\">gorm</a>、<a href=\"https://github.com/go-xorm/xorm\">xorm</a>、<a href=\"https://github.com/gohouse/gorose\">gorose</a>等。目前，GitHub上 star数最多的是GORM，它也是当前Go项目中使用最多的ORM。</p><p>IAM项目也使用了GORM。这一讲，我就来详细讲解下GORM的基础知识，并介绍iam-apiserver是如何使用GORM，对数据进行CURD操作的。</p><h2>GORM基础知识介绍</h2><p>GORM是Go语言的ORM包，功能强大，调用方便。像腾讯、华为、阿里这样的大厂，都在使用GORM来构建企业级的应用。GORM有很多特性，开发中常用的核心特性如下：</p><ul>\n<li>功能全。使用ORM操作数据库的接口，GORM都有，可以满足我们开发中对数据库调用的各类需求。</li>\n<li>支持钩子方法。这些钩子方法可以应用在Create、Save、Update、Delete、Find方法中。</li>\n<li>开发者友好，调用方便。</li>\n<li>支持Auto Migration。</li>\n<li>支持关联查询。</li>\n<li>支持多种关系数据库，例如MySQL、Postgres、SQLite、SQLServer等。</li>\n</ul><p>GORM有两个版本，<a href=\"https://github.com/jinzhu/gorm\">V1</a>和<a href=\"https://github.com/go-gorm/gorm\">V2</a>。遵循用新不用旧的原则，IAM项目使用了最新的V2版本。</p><!-- [[[read_end]]] --><h2>通过示例学习GORM</h2><p>接下来，我们先快速看一个使用GORM的示例，通过该示例来学习GORM。示例代码存放在<a href=\"https://github.com/marmotedu/gopractise-demo/blob/main/gorm/main.go\">marmotedu/gopractise-demo/gorm/main.go</a>文件中。因为代码比较长，你可以使用以下命令克隆到本地查看：</p><pre><code class=\"language-bash\">$ mkdir -p $GOPATH/src/github.com/marmotedu\n$ cd $GOPATH/src/github.com/marmotedu\n$ git clone https://github.com/marmotedu/gopractise-demo\n$ cd gopractise-demo/gorm/\n</code></pre><p>假设我们有一个MySQL数据库，连接地址和端口为 <code>127.0.0.1:3306</code> ，用户名为 <code>iam</code> ，密码为 <code>iam1234</code> 。创建完main.go文件后，执行以下命令来运行：</p><pre><code class=\"language-bash\">$ go run main.go -H 127.0.0.1:3306 -u iam -p iam1234 -d test\n2020/10/17 15:15:50 totalcount: 1\n2020/10/17 15:15:50 \tcode: D42, price: 100\n2020/10/17 15:15:51 totalcount: 1\n2020/10/17 15:15:51 \tcode: D42, price: 200\n2020/10/17 15:15:51 totalcount: 0\n</code></pre><p>在企业级Go项目开发中，使用GORM库主要用来完成以下数据库操作：</p><ul>\n<li>连接和关闭数据库。连接数据库时，可能需要设置一些参数，比如最大连接数、最大空闲连接数、最大连接时长等。</li>\n<li>插入表记录。可以插入一条记录，也可以批量插入记录。</li>\n<li>更新表记录。可以更新某一个字段，也可以更新多个字段。</li>\n<li>查看表记录。可以查看某一条记录，也可以查看符合条件的记录列表。</li>\n<li>删除表记录。可以删除某一个记录，也可以批量删除。删除还支持永久删除和软删除。</li>\n<li>在一些小型项目中，还会用到GORM的表结构自动迁移功能。</li>\n</ul><p>GORM功能强大，上面的示例代码展示的是比较通用的一种操作方式。</p><p>上述代码中，首先定义了一个GORM模型（Models），Models是标准的Go struct，用来代表数据库中的一个表结构。我们可以给 Models 添加 TableName 方法，来告诉 GORM 该Models映射到数据库中的哪张表。Models定义如下：</p><pre><code class=\"language-go\">type Product struct {\n    gorm.Model\n    Code  string `gorm:\"column:code\"`\n    Price uint   `gorm:\"column:price\"`\n}\n\n// TableName maps to mysql table name.\nfunc (p *Product) TableName() string {\n    return \"product\"\n}\n</code></pre><p>如果没有指定表名，则GORM使用结构体名的蛇形复数作为表名。例如：结构体名为 <code>DockerInstance</code> ，则表名为 <code>dockerInstances</code> 。</p><p>在之后的代码中，使用Pflag来解析命令行的参数，通过命令行参数指定数据库的地址、用户名、密码和数据库名。之后，使用这些参数生成建立 MySQL 连接需要的配置文件，并调用 <code>gorm.Open</code> 建立数据库连接：</p><pre><code class=\"language-go\">var (\n    host     = pflag.StringP(\"host\", \"H\", \"127.0.0.1:3306\", \"MySQL service host address\")\n    username = pflag.StringP(\"username\", \"u\", \"root\", \"Username for access to mysql service\")\n    password = pflag.StringP(\"password\", \"p\", \"root\", \"Password for access to mysql, should be used pair with password\")\n    database = pflag.StringP(\"database\", \"d\", \"test\", \"Database name to use\")\n    help     = pflag.BoolP(\"help\", \"h\", false, \"Print this help message\")\n)\n\nfunc main() {\n    // Parse command line flags\n    pflag.CommandLine.SortFlags = false\n    pflag.Usage = func() {\n        pflag.PrintDefaults()\n    }\n    pflag.Parse()\n    if *help {\n        pflag.Usage()\n        return\n    }\n\n    dsn := fmt.Sprintf(`%s:%s@tcp(%s)/%s?charset=utf8&amp;parseTime=%t&amp;loc=%s`,\n        *username,\n        *password,\n        *host,\n        *database,\n        true,\n        \"Local\")\n    db, err := gorm.Open(mysql.Open(dsn), &amp;gorm.Config{})\n    if err != nil {\n        panic(\"failed to connect database\")\n    }\n}\n</code></pre><p>创建完数据库连接之后，会返回数据库实例 <code>db</code> ，之后就可以调用db实例中的方法，完成数据库的CURD操作。具体操作如下，一共可以分为六个操作：</p><p>第一个操作，自动迁移表结构。</p><pre><code class=\"language-go\">// 1. Auto migration for given models\ndb.AutoMigrate(&amp;Product{})\n</code></pre><p><strong>我不建议你在正式的代码中自动迁移表结构。</strong>因为变更现网数据库是一个高危操作，现网数据库字段的添加、类型变更等，都需要经过严格的评估才能实施。这里将变更隐藏在代码中，在组件发布时很难被研发人员感知到，如果组件启动，就可能会自动修改现网表结构，也可能会因此引起重大的现网事故。</p><p>GORM的AutoMigrate方法，只对新增的字段或索引进行变更，理论上是没有风险的。在实际的Go项目开发中，也有很多人使用AutoMigrate方法自动同步表结构。但我更倾向于规范化、可感知的操作方式，所以我在实际开发中，都是手动变更表结构的。当然，具体使用哪种方法，你可以根据需要自行选择。</p><p>第二个操作，插入表记录。</p><pre><code class=\"language-go\">// 2. Insert the value into database\nif err := db.Create(&amp;Product{Code: \"D42\", Price: 100}).Error; err != nil {\n    log.Fatalf(\"Create error: %v\", err)\n}\nPrintProducts(db)\n</code></pre><p>通过 <code>db.Create</code> 方法创建了一条记录。插入记录后，通过调用 <code>PrintProducts</code> 方法打印当前表中的所有数据记录，来测试是否成功插入。</p><p>第三个操作，获取符合条件的记录。</p><pre><code class=\"language-go\">// 3. Find first record that match given conditions\nproduct := &amp;Product{}\nif err := db.Where(\"code= ?\", \"D42\").First(&amp;product).Error; err != nil {\n    log.Fatalf(\"Get product error: %v\", err)\n}\n</code></pre><p>First方法只会返回符合条件的记录列表中的第一条，你可以使用First方法来获取某个资源的详细信息。</p><p>第四个操作，更新表记录。</p><pre><code class=\"language-go\">// 4. Update value in database, if the value doesn't have primary key, will insert it\nproduct.Price = 200\nif err := db.Save(product).Error; err != nil {\n    log.Fatalf(\"Update product error: %v\", err)\n}\nPrintProducts(db)\n</code></pre><p>通过Save方法，可以把 product 变量中所有跟数据库不一致的字段更新到数据库中。具体操作是：先获取某个资源的详细信息，再通过 <code>product.Price = 200</code> 这类赋值语句，对其中的一些字段重新赋值。最后，调用 <code>Save</code> 方法更新这些字段。你可以将这些操作看作一种更新数据库的更新模式。</p><p>第五个操作，删除表记录。</p><p>通过 <code>Delete</code> 方法删除表记录，代码如下：</p><pre><code class=\"language-go\">// 5. Delete value match given conditions\nif err := db.Where(\"code = ?\", \"D42\").Delete(&amp;Product{}).Error; err != nil {\n    log.Fatalf(\"Delete product error: %v\", err)\n}\nPrintProducts(db)\n</code></pre><p>这里需要注意，因为 <code>Product</code> 中有 <code>gorm.DeletedAt</code> 字段，所以，上述删除操作不会真正把记录从数据库表中删除掉，而是通过设置数据库 <code>product</code> 表 <code>deletedAt</code> 字段为当前时间的方法来删除。</p><p>第六个操作，获取表记录列表。</p><pre><code class=\"language-go\">products := make([]*Product, 0)\nvar count int64\nd := db.Where(\"code like ?\", \"%D%\").Offset(0).Limit(2).Order(\"id desc\").Find(&amp;products).Offset(-1).Limit(-1).Count(&amp;count)\nif d.Error != nil {\n    log.Fatalf(\"List products error: %v\", d.Error)\n}\n</code></pre><p>在PrintProducts函数中，会打印当前的所有记录，你可以根据输出，判断数据库操作是否成功。</p><h2>GORM常用操作讲解</h2><p>看完上面的示例，我想你已经初步掌握了GORM的使用方法。接下来，我再来给你详细介绍下GORM所支持的数据库操作。</p><h3>模型定义</h3><p>GORM使用模型（Models）来映射一个数据库表。默认情况下，使用ID作为主键，使用结构体名的 <code>snake_cases</code> 作为表名，使用字段名的 <code>snake_case</code> 作为列名，并使用 CreatedAt、UpdatedAt、DeletedAt字段追踪创建、更新和删除时间。</p><p>使用GORM的默认规则，可以减少代码量，但我更喜欢的方式是<strong>直接指明字段名和表名</strong>。例如，有以下模型：</p><pre><code class=\"language-go\">type Animal struct {\n  AnimalID int64        // 列名 `animal_id`\n  Birthday time.Time    // 列名 `birthday`\n  Age      int64        // 列名 `age`\n}\n</code></pre><p>上述模型对应的表名为 <code>animals</code> ，列名分别为 <code>animal_id</code> 、 <code>birthday</code> 和 <code>age</code> 。我们可以通过以下方式来重命名表名和列名，并将 <code>AnimalID</code> 设置为表的主键：</p><pre><code class=\"language-go\">type Animal struct {\n    AnimalID int64     `gorm:\"column:animalID;primarykey\"` // 将列名设为 `animalID`\n    Birthday time.Time `gorm:\"column:birthday\"`            // 将列名设为 `birthday`\n    Age      int64     `gorm:\"column:age\"`                 // 将列名设为 `age`\n}\n\nfunc (a *Animal) TableName() string {\n    return \"animal\"\n}\n</code></pre><p>上面的代码中，通过 <code>primaryKey</code> 标签指定主键，使用 <code>column</code> 标签指定列名，通过给Models添加 <code>TableName</code> 方法指定表名。</p><p>数据库表通常会包含4个字段。</p><ul>\n<li>ID：自增字段，也作为主键。</li>\n<li>CreatedAt：记录创建时间。</li>\n<li>UpdatedAt：记录更新时间。</li>\n<li>DeletedAt：记录删除时间（软删除时有用）。</li>\n</ul><p>GORM也预定义了包含这4个字段的Models，在我们定义自己的Models时，可以直接内嵌到结构体内，例如：</p><pre><code class=\"language-go\">type Animal struct {\n    gorm.Model\n    AnimalID int64     `gorm:\"column:animalID\"` // 将列名设为 `animalID`\n    Birthday time.Time `gorm:\"column:birthday\"` // 将列名设为 `birthday`\n    Age      int64     `gorm:\"column:age\"`      // 将列名设为 `age`\n}\n</code></pre><p>Models中的字段能支持很多GORM标签，但如果我们不使用GORM自动创建表和迁移表结构的功能，很多标签我们实际上是用不到的。在开发中，用得最多的是 <code>column</code> 标签。</p><h3>连接数据库</h3><p>在进行数据库的CURD操作之前，我们首先需要连接数据库。你可以通过以下代码连接MySQL数据库：</p><pre><code class=\"language-go\">import (\n  \"gorm.io/driver/mysql\"\n  \"gorm.io/gorm\"\n)\n\nfunc main() {\n  // 参考 https://github.com/go-sql-driver/mysql#dsn-data-source-name 获取详情\n  dsn := \"user:pass@tcp(127.0.0.1:3306)/dbname?charset=utf8mb4&amp;parseTime=True&amp;loc=Local\"\n  db, err := gorm.Open(mysql.Open(dsn), &amp;gorm.Config{})\n}\n</code></pre><p>如果需要GORM正确地处理 <code>time.Time</code> 类型，在连接数据库时需要带上 <code>parseTime</code> 参数。如果要支持完整的UTF-8编码，可将<code>charset=utf8</code>更改为<code>charset=utf8mb4</code>。</p><p>GORM支持连接池，底层是用 <code>database/sql</code> 包来维护连接池的，连接池设置如下：</p><pre><code class=\"language-go\">sqlDB, err := db.DB()\nsqlDB.SetMaxIdleConns(100)              // 设置MySQL的最大空闲连接数（推荐100）\nsqlDB.SetMaxOpenConns(100)             // 设置MySQL的最大连接数（推荐100）\nsqlDB.SetConnMaxLifetime(time.Hour)    // 设置MySQL的空闲连接最大存活时间（推荐10s）\n</code></pre><p>上面这些设置，也可以应用在大型后端项目中。</p><h3>创建记录</h3><p>我们可以通过 <code>db.Create</code> 方法来创建一条记录：</p><pre><code class=\"language-go\">type User struct {\n  gorm.Model\n  Name         string\n  Age          uint8\n  Birthday     *time.Time\n}\nuser := User{Name: \"Jinzhu\", Age: 18, Birthday: time.Now()}\nresult := db.Create(&amp;user) // 通过数据的指针来创建\n</code></pre><p>db.Create函数会返回如下3个值：</p><ul>\n<li>user.ID：返回插入数据的主键，这个是直接赋值给user变量。</li>\n<li>result.Error：返回error。</li>\n<li>result.RowsAffected：返回插入记录的条数。</li>\n</ul><p>当需要插入的数据量比较大时，可以批量插入，以提高插入性能：</p><pre><code class=\"language-go\">var users = []User{{Name: \"jinzhu1\"}, {Name: \"jinzhu2\"}, {Name: \"jinzhu3\"}}\nDB.Create(&amp;users)\n\nfor _, user := range users {\n  user.ID // 1,2,3\n}\n</code></pre><h3>删除记录</h3><p>我们可以通过Delete方法删除记录：</p><pre><code class=\"language-go\">// DELETE from users where id = 10 AND name = \"jinzhu\";\ndb.Where(\"name = ?\", \"jinzhu\").Delete(&amp;user)\n</code></pre><p>GORM也支持根据主键进行删除，例如：</p><pre><code class=\"language-go\">// DELETE FROM users WHERE id = 10;\ndb.Delete(&amp;User{}, 10)\n</code></pre><p>不过，我更喜欢使用db.Where的方式进行删除，这种方式有两个优点。</p><p>第一个优点是删除方式更通用。使用db.Where不仅可以根据主键删除，还能够随意组合条件进行删除。</p><p>第二个优点是删除方式更显式，这意味着更易读。如果使用<code>db.Delete(&amp;User{}, 10)</code>，你还需要确认User的主键，如果记错了主键，还可能会引入Bug。</p><p>此外，GORM也支持批量删除：</p><pre><code class=\"language-go\">db.Where(\"name in (?)\", []string{\"jinzhu\", \"colin\"}).Delete(&amp;User{})\n</code></pre><p>GORM支持两种删除方法：软删除和永久删除。下面我来分别介绍下。</p><ol>\n<li>软删除</li>\n</ol><p>软删除是指执行Delete时，记录不会被从数据库中真正删除。GORM会将 <code>DeletedAt</code> 设置为当前时间，并且不能通过正常的方式查询到该记录。如果模型包含了一个 <code>gorm.DeletedAt</code> 字段，GORM在执行删除操作时，会软删除该记录。</p><p>下面的删除方法就是一个软删除：</p><pre><code class=\"language-go\">// UPDATE users SET deleted_at=\"2013-10-29 10:23\" WHERE age = 20;\ndb.Where(\"age = ?\", 20).Delete(&amp;User{})\n\n// SELECT * FROM users WHERE age = 20 AND deleted_at IS NULL;\ndb.Where(\"age = 20\").Find(&amp;user)\n</code></pre><p>可以看到，GORM并没有真正把记录从数据库删除掉，而是只更新了 <code>deleted_at</code> 字段。在查询时，GORM查询条件中新增了<code>AND deleted_at IS NULL</code>条件，所以这些被设置过 <code>deleted_at</code> 字段的记录不会被查询到。对于一些比较重要的数据，我们可以通过软删除的方式删除记录，软删除可以使这些重要的数据后期能够被恢复，并且便于以后的排障。</p><p>我们可以通过下面的方式查找被软删除的记录：</p><pre><code class=\"language-go\">// SELECT * FROM users WHERE age = 20;\ndb.Unscoped().Where(\"age = 20\").Find(&amp;users)\n</code></pre><ol start=\"2\">\n<li>永久删除</li>\n</ol><p>如果想永久删除一条记录，可以使用Unscoped：</p><pre><code class=\"language-go\">// DELETE FROM orders WHERE id=10;\ndb.Unscoped().Delete(&amp;order)\n</code></pre><p>或者，你也可以在模型中去掉gorm.DeletedAt。</p><h3>更新记录</h3><p>GORM中，最常用的更新方法如下：</p><pre><code class=\"language-go\">db.First(&amp;user)\n\nuser.Name = \"jinzhu 2\"\nuser.Age = 100\n// UPDATE users SET name='jinzhu 2', age=100, birthday='2016-01-01', updated_at = '2013-11-17 21:34:10' WHERE id=111;\ndb.Save(&amp;user)\n</code></pre><p>上述方法会保留所有字段，所以执行Save时，需要先执行First，获取某个记录的所有列的值，然后再对需要更新的字段设置值。</p><p>还可以指定更新单个列：</p><pre><code class=\"language-go\">// UPDATE users SET age=200, updated_at='2013-11-17 21:34:10' WHERE name='colin';\ndb.Model(&amp;User{}).Where(\"name = ?\", \"colin\").Update(\"age\", 200)\n</code></pre><p>也可以指定更新多个列：</p><pre><code class=\"language-go\">// UPDATE users SET name='hello', age=18, updated_at = '2013-11-17 21:34:10' WHERE name = 'colin';\ndb.Model(&amp;user).Where(\"name\", \"colin\").Updates(User{Name: \"hello\", Age: 18, Active: false})\n</code></pre><p>这里要注意，这个方法只会更新非零值的字段。</p><h3>查询数据</h3><p>GORM支持不同的查询方法，下面我来讲解三种在开发中经常用到的查询方式，分别是检索单个记录、查询所有符合条件的记录和智能选择字段。</p><ol>\n<li>检索单个记录</li>\n</ol><p>下面是检索单个记录的示例代码：</p><pre><code class=\"language-go\">// 获取第一条记录（主键升序）\n// SELECT * FROM users ORDER BY id LIMIT 1;\ndb.First(&amp;user)\n\n// 获取最后一条记录（主键降序）\n// SELECT * FROM users ORDER BY id DESC LIMIT 1;\ndb.Last(&amp;user)\nresult := db.First(&amp;user)\nresult.RowsAffected // 返回找到的记录数\nresult.Error        // returns error\n\n// 检查 ErrRecordNotFound 错误\nerrors.Is(result.Error, gorm.ErrRecordNotFound)\n</code></pre><p>如果model类型没有定义主键，则按第一个字段排序。</p><ol start=\"2\">\n<li>查询所有符合条件的记录</li>\n</ol><p>示例代码如下：</p><pre><code class=\"language-go\">users := make([]*User, 0)\n\n// SELECT * FROM users WHERE name &lt;&gt; 'jinzhu';\ndb.Where(\"name &lt;&gt; ?\", \"jinzhu\").Find(&amp;users)\n</code></pre><ol start=\"3\">\n<li>智能选择字段</li>\n</ol><p>你可以通过Select方法，选择特定的字段。我们可以定义一个较小的结构体来接受选定的字段：</p><pre><code class=\"language-go\">type APIUser struct {\n  ID   uint\n  Name string\n}\n\n// SELECT `id`, `name` FROM `users` LIMIT 10;\ndb.Model(&amp;User{}).Limit(10).Find(&amp;APIUser{})\n</code></pre><p>除了上面讲的三种常用的基本查询方法，GORM还支持高级查询，下面我来介绍下。</p><h3>高级查询</h3><p>GORM支持很多高级查询功能，这里我主要介绍4种。</p><ol>\n<li>指定检索记录时的排序方式</li>\n</ol><p>示例代码如下：</p><pre><code class=\"language-go\">// SELECT * FROM users ORDER BY age desc, name;\ndb.Order(\"age desc, name\").Find(&amp;users)\n</code></pre><ol start=\"2\">\n<li>Limit &amp; Offset</li>\n</ol><p>Offset指定从第几条记录开始查询，Limit指定返回的最大记录数。Offset和Limit值为-1时，消除Offset和Limit条件。另外，Limit和Offset位置不同，效果也不同。</p><pre><code class=\"language-go\">// SELECT * FROM users OFFSET 5 LIMIT 10;\ndb.Limit(10).Offset(5).Find(&amp;users)\n</code></pre><ol start=\"3\">\n<li>Distinct</li>\n</ol><p>Distinct可以从数据库记录中选择不同的值。</p><pre><code class=\"language-go\">db.Distinct(\"name\", \"age\").Order(\"name, age desc\").Find(&amp;results)\n</code></pre><ol start=\"4\">\n<li>Count</li>\n</ol><p>Count可以获取匹配的条数。</p><pre><code class=\"language-go\">var count int64\n// SELECT count(1) FROM users WHERE name = 'jinzhu'; (count)\ndb.Model(&amp;User{}).Where(\"name = ?\", \"jinzhu\").Count(&amp;count)\n</code></pre><p>GORM还支持很多高级查询功能，比如内联条件、Not 条件、Or 条件、Group &amp; Having、Joins、Group、FirstOrInit、FirstOrCreate、迭代、FindInBatches等。因为IAM项目中没有用到这些高级特性，我在这里就不展开介绍了。你如果感兴趣，可以看下<a href=\"https://gorm.io/zh_CN/docs/index.html\">GORM的官方文档</a>。</p><h3>原生SQL</h3><p>GORM支持原生查询SQL和执行SQL。原生查询SQL用法如下：</p><pre><code class=\"language-go\">type Result struct {\n  ID   int\n  Name string\n  Age  int\n}\n\nvar result Result\ndb.Raw(\"SELECT id, name, age FROM users WHERE name = ?\", 3).Scan(&amp;result)\n</code></pre><p>原生执行SQL用法如下；</p><pre><code class=\"language-go\">db.Exec(\"DROP TABLE users\")\ndb.Exec(\"UPDATE orders SET shipped_at=? WHERE id IN ?\", time.Now(), []int64{1,2,3})\n</code></pre><h3>GORM钩子</h3><p>GORM支持钩子功能，例如下面这个在插入记录前执行的钩子：</p><pre><code class=\"language-go\">func (u *User) BeforeCreate(tx *gorm.DB) (err error) {\n  u.UUID = uuid.New()\n\n    if u.Name == \"admin\" {\n        return errors.New(\"invalid name\")\n    }\n    return\n}\n</code></pre><p>GORM支持的钩子见下表：</p><p><img src=\"https://static001.geekbang.org/resource/image/20/2c/20fb0b6a11dbcebd9ddf428517240d2c.jpg?wh=1920x1338\" alt=\"图片\"></p><h2>iam-apiserver中的CURD操作实战</h2><p>接下来，我来介绍下iam-apiserver是如何使用GORM，对数据进行CURD操作的。</p><p><strong>首先，</strong>我们需要配置连接MySQL的各类参数。iam-apiserver通过<a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/pkg/options/mysql_options.go#L29\">NewMySQLOptions</a>函数创建了一个带有默认值的<a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/pkg/options/mysql_options.go#L17\">MySQLOptions</a>类型的变量，将该变量传给<a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/pkg/app/app.go#L157\">NewApp</a>函数。在App框架中，最终会调用MySQLOptions提供的AddFlags方法，将MySQLOptions提供的命令行参数添加到Cobra命令行中。</p><p><strong>接着，</strong>在<a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/apiserver/server.go#L81\">PrepareRun</a>函数中，调用<a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/apiserver/store/mysql/mysql.go#L55\">GetMySQLFactoryOr</a>函数，初始化并获取仓库层的实例<a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/apiserver/store/mysql/mysql.go#L50\">mysqlFactory</a>。实现了仓库层<a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/apiserver/store/store.go#L12\">store.Factory</a>接口：</p><pre><code class=\"language-go\">type Factory interface {\n    Users() UserStore\n    Secrets() SecretStore\n    Policies() PolicyStore\n    Close() error\n}\n</code></pre><p>GetMySQLFactoryOr函数采用了我们在 <a href=\"https://time.geekbang.org/column/article/386238\">11讲</a> 中提过的单例模式，确保iam-apiserver进程中只有一个仓库层的实例，这样可以减少内存开支和系统的性能开销。</p><p>GetMySQLFactoryOr函数中，使用<a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/pkg/db/mysql.go#L30\">github.com/marmotedu/iam/pkg/db</a>包提供的New函数，创建了MySQL实例。New函数代码如下：</p><pre><code class=\"language-go\">func New(opts *Options) (*gorm.DB, error) {&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; dsn := fmt.Sprintf(`%s:%s@tcp(%s)/%s?charset=utf8&amp;parseTime=%t&amp;loc=%s`,&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; opts.Username,&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; opts.Password,&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; opts.Host,&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; opts.Database,&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; true,&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; \"Local\")&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; db, err := gorm.Open(mysql.Open(dsn), &amp;gorm.Config{&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; Logger: logger.New(opts.LogLevel),&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; })&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; if err != nil {&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; return nil, err&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; }&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; sqlDB, err := db.DB()&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; if err != nil {&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; return nil, err&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; }&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; // SetMaxOpenConns sets the maximum number of open connections to the database.\n&nbsp; &nbsp; sqlDB.SetMaxOpenConns(opts.MaxOpenConnections)\n\n&nbsp; &nbsp; // SetConnMaxLifetime sets the maximum amount of time a connection may be reused.\n&nbsp; &nbsp; sqlDB.SetConnMaxLifetime(opts.MaxConnectionLifeTime)\n\n&nbsp; &nbsp; // SetMaxIdleConns sets the maximum number of connections in the idle connection pool.\n&nbsp; &nbsp; sqlDB.SetMaxIdleConns(opts.MaxIdleConnections)\n\n&nbsp; &nbsp; return db, nil\n}\n</code></pre><p>上述代码中，我们先创建了一个 <code>*gorm.DB</code> 类型的实例，并对该实例进行了如下设置：</p><ul>\n<li>通过SetMaxOpenConns方法，设置了MySQL的最大连接数（推荐100）。</li>\n<li>通过SetConnMaxLifetime方法，设置了MySQL的空闲连接最大存活时间（推荐10s）。</li>\n<li>通过SetMaxIdleConns方法，设置了MySQL的最大空闲连接数（推荐100）。</li>\n</ul><p>GetMySQLFactoryOr函数最后创建了datastore类型的变量mysqlFactory，该变量是仓库层的变量。mysqlFactory变量中，又包含了 <code>*gorm.DB</code> 类型的字段 <code>db</code> 。</p><p><strong>最终</strong><strong>，</strong>我们通过仓库层的变量mysqlFactory，调用其 <code>db</code> 字段提供的方法来完成数据库的CURD操作。例如，创建密钥、更新密钥、删除密钥、获取密钥详情、查询密钥列表，具体代码如下（代码位于<a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/apiserver/store/mysql/secret.go\">secret.go</a>文件中）：</p><pre><code class=\"language-go\">// Create creates a new secret.\nfunc (s *secrets) Create(ctx context.Context, secret *v1.Secret, opts metav1.CreateOptions) error {\n\treturn s.db.Create(&amp;secret).Error\n}\n\n// Update updates an secret information by the secret identifier.\nfunc (s *secrets) Update(ctx context.Context, secret *v1.Secret, opts metav1.UpdateOptions) error {\n\treturn s.db.Save(secret).Error\n}\n\n// Delete deletes the secret by the secret identifier.\nfunc (s *secrets) Delete(ctx context.Context, username, name string, opts metav1.DeleteOptions) error {\n\tif opts.Unscoped {\n\t\ts.db = s.db.Unscoped()\n\t}\n\n\terr := s.db.Where(\"username = ? and name = ?\", username, name).Delete(&amp;v1.Secret{}).Error\n\tif err != nil &amp;&amp; !errors.Is(err, gorm.ErrRecordNotFound) {\n\t\treturn errors.WithCode(code.ErrDatabase, err.Error())\n\t}\n\n\treturn nil\n}\n\n// Get return an secret by the secret identifier.\nfunc (s *secrets) Get(ctx context.Context, username, name string, opts metav1.GetOptions) (*v1.Secret, error) {\n\tsecret := &amp;v1.Secret{}\n\terr := s.db.Where(\"username = ? and name= ?\", username, name).First(&amp;secret).Error\n\tif err != nil {\n\t\tif errors.Is(err, gorm.ErrRecordNotFound) {\n\t\t\treturn nil, errors.WithCode(code.ErrSecretNotFound, err.Error())\n\t\t}\n\n\t\treturn nil, errors.WithCode(code.ErrDatabase, err.Error())\n\t}\n\n\treturn secret, nil\n}\n\n// List return all secrets.\nfunc (s *secrets) List(ctx context.Context, username string, opts metav1.ListOptions) (*v1.SecretList, error) {\n\tret := &amp;v1.SecretList{}\n\tol := gormutil.Unpointer(opts.Offset, opts.Limit)\n\n\tif username != \"\" {\n\t\ts.db = s.db.Where(\"username = ?\", username)\n\t}\n\n\tselector, _ := fields.ParseSelector(opts.FieldSelector)\n\tname, _ := selector.RequiresExactMatch(\"name\")\n\n\td := s.db.Where(\" name like ?\", \"%\"+name+\"%\").\n\t\tOffset(ol.Offset).\n\t\tLimit(ol.Limit).\n\t\tOrder(\"id desc\").\n\t\tFind(&amp;ret.Items).\n\t\tOffset(-1).\n\t\tLimit(-1).\n\t\tCount(&amp;ret.TotalCount)\n\n\treturn ret, d.Error\n}\n</code></pre><p>上面的代码中， <code>s.db</code> 就是 <code>*gorm.DB</code> 类型的字段。</p><p>上面的代码段执行了以下操作：</p><ul>\n<li>通过 <code>s.db.Save</code> 来更新数据库表的各字段；</li>\n<li>通过 <code>s.db.Unscoped</code> 来永久性从表中删除一行记录。对于支持软删除的资源，我们还可以通过 <code>opts.Unscoped</code> 选项来控制是否永久删除记录。 <code>true</code> 永久删除， <code>false</code> 软删除，默认软删除。</li>\n<li>通过 <code>errors.Is(err, gorm.ErrRecordNotFound)</code> 来判断GORM返回的错误是否是没有找到记录的错误类型。</li>\n<li>通过下面两行代码，来获取查询条件name的值：</li>\n</ul><pre><code class=\"language-go\">selector, _ := fields.ParseSelector(opts.FieldSelector)&nbsp; &nbsp;&nbsp;\nname, _ := selector.RequiresExactMatch(\"name\")\n</code></pre><p>我们的整个调用链是：控制层 -&gt; 业务层 -&gt; 仓库层。这里你可能要问：<strong>我们<strong><strong>是</strong></strong>如何<strong><strong>调用</strong></strong>到<strong><strong>仓库层的</strong></strong>实例mysqlFactory<strong><strong>的</strong></strong>呢？</strong></p><p>这是因为我们的控制层实例包含了业务层的实例。在创建控制层实例时，我们传入了业务层的实例：</p><pre><code class=\"language-go\">type UserController struct {&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; srv srvv1.Service&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n}&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n// NewUserController creates a user handler.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\nfunc NewUserController(store store.Factory) *UserController {\n&nbsp; &nbsp; return &amp;UserController{&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; srv: srvv1.NewService(store),&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; }&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n}&nbsp;\n</code></pre><p>业务层的实例包含了仓库层的实例。在创建业务层实例时，传入了仓库层的实例：</p><pre><code class=\"language-go\">type service struct {&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; store store.Factory&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n}&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n// NewService returns Service interface.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\nfunc NewService(store store.Factory) Service {&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; return &amp;service{&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; store: store,&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; }\n}\n</code></pre><p>通过这种包含关系，我们在控制层可以调用业务层的实例，在业务层又可以调用仓库层的实例。这样，我们最终通过仓库层实例的 <code>db</code> 字段（<code>*gorm.DB</code> 类型）完成数据库的CURD操作。</p><h2>总结</h2><p>在Go项目中，我们需要使用ORM来进行数据库的CURD操作。在Go生态中，当前最受欢迎的ORM是GORM，IAM项目也使用了GORM。GORM有很多功能，常用的功能有模型定义、连接数据库、创建记录、删除记录、更新记录和查询数据。这些常用功能的常见使用方式如下：</p><pre><code class=\"language-go\">package main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\n\t\"github.com/spf13/pflag\"\n\t\"gorm.io/driver/mysql\"\n\t\"gorm.io/gorm\"\n)\n\ntype Product struct {\n\tgorm.Model\n\tCode&nbsp; string `gorm:\"column:code\"`\n\tPrice uint&nbsp; &nbsp;`gorm:\"column:price\"`\n}\n\n// TableName maps to mysql table name.\nfunc (p *Product) TableName() string {\n\treturn \"product\"\n}\n\nvar (\n\thost&nbsp; &nbsp; &nbsp;= pflag.StringP(\"host\", \"H\", \"127.0.0.1:3306\", \"MySQL service host address\")\n\tusername = pflag.StringP(\"username\", \"u\", \"root\", \"Username for access to mysql service\")\n\tpassword = pflag.StringP(\"password\", \"p\", \"root\", \"Password for access to mysql, should be used pair with password\")\n\tdatabase = pflag.StringP(\"database\", \"d\", \"test\", \"Database name to use\")\n\thelp&nbsp; &nbsp; &nbsp;= pflag.BoolP(\"help\", \"h\", false, \"Print this help message\")\n)\n\nfunc main() {\n\t// Parse command line flags\n\tpflag.CommandLine.SortFlags = false\n\tpflag.Usage = func() {\n\t\tpflag.PrintDefaults()\n\t}\n\tpflag.Parse()\n\tif *help {\n\t\tpflag.Usage()\n\t\treturn\n\t}\n\n\tdsn := fmt.Sprintf(`%s:%s@tcp(%s)/%s?charset=utf8&amp;parseTime=%t&amp;loc=%s`,\n\t\t*username,\n\t\t*password,\n\t\t*host,\n\t\t*database,\n\t\ttrue,\n\t\t\"Local\")\n\tdb, err := gorm.Open(mysql.Open(dsn), &amp;gorm.Config{})\n\tif err != nil {\n\t\tpanic(\"failed to connect database\")\n\t}\n\n\t// 1. Auto migration for given models\n\tdb.AutoMigrate(&amp;Product{})\n\n\t// 2. Insert the value into database\n\tif err := db.Create(&amp;Product{Code: \"D42\", Price: 100}).Error; err != nil {\n\t\tlog.Fatalf(\"Create error: %v\", err)\n\t}\n\tPrintProducts(db)\n\n\t// 3. Find first record that match given conditions\n\tproduct := &amp;Product{}\n\tif err := db.Where(\"code= ?\", \"D42\").First(&amp;product).Error; err != nil {\n\t\tlog.Fatalf(\"Get product error: %v\", err)\n\t}\n\n\t// 4. Update value in database, if the value doesn't have primary key, will insert it\n\tproduct.Price = 200\n\tif err := db.Save(product).Error; err != nil {\n\t\tlog.Fatalf(\"Update product error: %v\", err)\n\t}\n\tPrintProducts(db)\n\n\t// 5. Delete value match given conditions\n\tif err := db.Where(\"code = ?\", \"D42\").Delete(&amp;Product{}).Error; err != nil {\n\t\tlog.Fatalf(\"Delete product error: %v\", err)\n\t}\n\tPrintProducts(db)\n}\n\n// List products\nfunc PrintProducts(db *gorm.DB) {\n\tproducts := make([]*Product, 0)\n\tvar count int64\n\td := db.Where(\"code like ?\", \"%D%\").Offset(0).Limit(2).Order(\"id desc\").Find(&amp;products).Offset(-1).Limit(-1).Count(&amp;count)\n\tif d.Error != nil {\n\t\tlog.Fatalf(\"List products error: %v\", d.Error)\n\t}\n\n\tlog.Printf(\"totalcount: %d\", count)\n\tfor _, product := range products {\n\t\tlog.Printf(\"\\tcode: %s, price: %d\\n\", product.Code, product.Price)\n\t}\n}\n</code></pre><p>此外，GORM还支持原生查询SQL和原生执行SQL，可以满足更加复杂的SQL场景。</p><p>GORM中，还有一个非常有用的功能是支持Hooks。Hooks可以在执行某个CURD操作前被调用。在Hook中，可以添加一些非常有用的功能，例如生成唯一ID。目前，GORM支持 <code>BeforeXXX</code> 、 <code>AfterXXX</code> 和 <code>AfterFind</code> Hook，其中 <code>XXX</code> 可以是 Save、Create、Delete、Update。</p><p>最后，我还介绍了IAM项目的GORM实战，具体使用方式跟总结中的示例代码大体保持一致，你可以返回文稿查看。</p><h2>课后练习</h2><ol>\n<li>GORM支持AutoMigrate功能，思考下，你的生产环境是否可以使用AutoMigrate功能，为什么？</li>\n<li>查看<a href=\"https://gorm.io/zh_CN/docs/index.html\">GORM官方文档</a>，看下如何用GORM实现事务回滚功能。</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"29｜控制流（下）：iam-apiserver服务核心功能实现讲解","id":402206},"right":{"article_title":"31 | 数据流：通过iam-authz-server设计，看数据流服务的设计","id":404542}}},{"article_id":404542,"article_title":"31 | 数据流：通过iam-authz-server设计，看数据流服务的设计","article_content":"<p>你好，我是孔令飞。</p><p>在 <a href=\"https://time.geekbang.org/column/article/401190\">28讲</a> 和 <a href=\"https://time.geekbang.org/column/article/402206\">29讲</a> ，我介绍了IAM的控制流服务iam-apiserver的设计和实现。这一讲，我们再来看下IAM数据流服务iam-authz-server的设计和实现。</p><p>因为iam-authz-server是数据流服务，对性能要求较高，所以采用了一些机制来最大化API接口的性能。另外，为了提高开发效率，避免重复造轮子，iam-authz-server和iam-apiserver共享了大部分的功能代码。接下来，我们就来看下，iam-authz-server是如何跟iam-apiserver共享代码的，以及iam-authz-server是如何保证API接口性能的。</p><h2>iam-authz-server的功能介绍</h2><p>iam-authz-server目前的唯一功能，是通过提供 <code>/v1/authz</code> RESTful API接口完成资源授权。 <code>/v1/authz</code> 接口是通过<a href=\"https://github.com/ory/ladon\">github.com/ory/ladon</a>来完成资源授权的。</p><p>因为iam-authz-server承载了数据流的请求，需要确保API接口具有较高的性能。为了保证API接口的性能，iam-authz-server在设计上使用了大量的缓存技术。</p><!-- [[[read_end]]] --><h3>github.com/ory/ladon包介绍</h3><p>因为iam-authz-server资源授权是通过 <code>github.com/ory/ladon</code> 来完成的，为了让你更好地理解iam-authz-server的授权策略，在这里我先介绍下 <code>github.com/ory/ladon</code> 包。</p><p>Ladon是用Go语言编写的用于实现访问控制策略的库，类似于RBAC（基于角色的访问控制系统，Role Based Access Control）和ACL（访问控制列表，Access Control Lists）。但是与RBAC和ACL相比，Ladon可以实现更细粒度的访问控制，并且能够在更为复杂的环境中（例如多租户、分布式应用程序和大型组织）工作。</p><p>Ladon解决了这个问题：在特定的条件下，谁能够/不能够对哪些资源做哪些操作。为了解决这个问题，Ladon引入了授权策略。授权策略是一个有语法规范的文档，这个文档描述了谁在什么条件下能够对哪些资源做哪些操作。Ladon可以用请求的上下文，去匹配设置的授权策略，最终判断出当前授权请求是否通过。下面是一个Ladon的授权策略样例：</p><pre><code class=\"language-json\">{\n&nbsp; \"description\": \"One policy to rule them all.\",\n&nbsp; \"subjects\": [\"users:&lt;peter|ken&gt;\", \"users:maria\", \"groups:admins\"],\n&nbsp; \"actions\" : [\"delete\", \"&lt;create|update&gt;\"],\n&nbsp; \"effect\": \"allow\",\n&nbsp; \"resources\": [\n&nbsp; &nbsp; \"resources:articles:&lt;.*&gt;\",\n&nbsp; &nbsp; \"resources:printer\"\n&nbsp; ],\n&nbsp; \"conditions\": {\n&nbsp; &nbsp; \"remoteIP\": {\n&nbsp; &nbsp; &nbsp; &nbsp; \"type\": \"CIDRCondition\",\n&nbsp; &nbsp; &nbsp; &nbsp; \"options\": {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"cidr\": \"192.168.0.1/16\"\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; }\n&nbsp; }\n}\n</code></pre><p>策略（Policy）由若干元素构成，用来描述授权的具体信息，你可以把它们看成一组规则。核心元素包括主题（Subject）、操作（Action）、效力（Effect）、资源（Resource）以及生效条件（Condition）。元素保留字仅支持小写，它们在描述上没有顺序要求。对于没有特定约束条件的策略，Condition元素是可选项。一条策略包含下面6个元素：</p><ul>\n<li>主题（Subject），主题名是唯一的，代表一个授权主题。例如，“ken” or “printer-service.mydomain.com”。</li>\n<li>操作（Action），描述允许或拒绝的操作。</li>\n<li>效力（Effect），描述策略产生的结果是“允许”还是“拒绝”，包括 allow（允许）和 deny（拒绝）。</li>\n<li>资源（Resource），描述授权的具体数据。</li>\n<li>生效条件（Condition），描述策略生效的约束条件。</li>\n<li>描述（Description），策略的描述。</li>\n</ul><p>有了授权策略，我们就可以传入请求上下文，由Ladon来决定请求是否能通过授权。下面是一个请求示例：</p><pre><code class=\"language-json\">{\n&nbsp; \"subject\": \"users:peter\",\n&nbsp; \"action\" : \"delete\",\n&nbsp; \"resource\": \"resources:articles:ladon-introduction\",\n&nbsp; \"context\": {\n&nbsp; &nbsp; \"remoteIP\": \"192.168.0.5\"\n&nbsp; }\n}\n</code></pre><p>可以看到，在 <code>remoteIP=\"192.168.0.5\"</code> 生效条件（Condition）下，针对主题（Subject） <code>users:peter</code> 对资源（Resource） <code>resources:articles:ladon-introduction</code> 的 <code>delete</code> 操作（Action），授权策略的效力（Effect）是 <code>allow</code> 的。所以Ladon会返回如下结果：</p><pre><code class=\"language-json\">{\n&nbsp; &nbsp; \"allowed\": true\n}\n</code></pre><p>Ladon支持很多Condition，具体见下表：</p><p><img src=\"https://static001.geekbang.org/resource/image/b8/dd/b84d2a1dc0e9ac07605a867594d734dd.jpg?wh=1920x1521\" alt=\"图片\"></p><p>至于如何使用这些Condition，你可以参考 <a href=\"https://github.com/marmotedu/geekbang-go/blob/master/LadonCondition%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B.md\">Ladon Condition使用示例</a>。此外，Ladon还支持自定义Condition。</p><p>另外，Ladon还支持授权审计，用来记录授权历史。我们可以通过在ladon.Ladon中附加一个ladon.AuditLogger来实现：</p><pre><code class=\"language-go\">import \"github.com/ory/ladon\"\nimport manager \"github.com/ory/ladon/manager/memory\"\n\nfunc main() {\n\n&nbsp; &nbsp; warden := ladon.Ladon{\n&nbsp; &nbsp; &nbsp; &nbsp; Manager: manager.NewMemoryManager(),\n&nbsp; &nbsp; &nbsp; &nbsp; AuditLogger: &amp;ladon.AuditLoggerInfo{}\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; // ...\n}\n</code></pre><p>在上面的示例中，我们提供了ladon.AuditLoggerInfo，该AuditLogger会在授权时打印调用的策略到标准错误。AuditLogger是一个interface：</p><pre><code class=\"language-go\">// AuditLogger tracks denied and granted authorizations.\ntype AuditLogger interface {\n&nbsp; &nbsp; LogRejectedAccessRequest(request *Request, pool Policies, deciders Policies)\n&nbsp; &nbsp; LogGrantedAccessRequest(request *Request, pool Policies, deciders Policies)\n}\n</code></pre><p>要实现一个新的AuditLogger，你只需要实现AuditLogger接口就可以了。比如，我们可以实现一个AuditLogger，将授权日志保存到Redis或者MySQL中。</p><p>Ladon支持跟踪一些授权指标，比如 deny、allow、not match、error。你可以通过实现ladon.Metric接口，来对这些指标进行处理。ladon.Metric接口定义如下：</p><pre><code class=\"language-go\">// Metric is used to expose metrics about authz\ntype Metric interface {\n&nbsp; &nbsp; // RequestDeniedBy is called when we get explicit deny by policy\n&nbsp; &nbsp; RequestDeniedBy(Request, Policy)\n&nbsp; &nbsp; // RequestAllowedBy is called when a matching policy has been found.\n&nbsp; &nbsp; RequestAllowedBy(Request, Policies)\n&nbsp; &nbsp; // RequestNoMatch is called when no policy has matched our request\n&nbsp; &nbsp; RequestNoMatch(Request)\n&nbsp; &nbsp; // RequestProcessingError is called when unexpected error occured\n&nbsp; &nbsp; RequestProcessingError(Request, Policy, error)\n}\n</code></pre><p>例如，你可以通过下面的示例，将这些指标暴露给prometheus：</p><pre><code class=\"language-go\">type prometheusMetrics struct{}\n\nfunc (mtr *prometheusMetrics) RequestDeniedBy(r ladon.Request, p ladon.Policy) {}\nfunc (mtr *prometheusMetrics) RequestAllowedBy(r ladon.Request, policies ladon.Policies) {}\nfunc (mtr *prometheusMetrics) RequestNoMatch(r ladon.Request) {}\nfunc (mtr *prometheusMetrics) RequestProcessingError(r ladon.Request, err error) {}\n\nfunc main() {\n\n&nbsp; &nbsp; warden := ladon.Ladon{\n&nbsp; &nbsp; &nbsp; &nbsp; Manager: manager.NewMemoryManager(),\n&nbsp; &nbsp; &nbsp; &nbsp; Metric:&nbsp; &amp;prometheusMetrics{},\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; // ...\n}\n</code></pre><p>在使用Ladon的过程中，有两个地方需要你注意：</p><ul>\n<li>所有检查都区分大小写，因为主题值可能是区分大小写的ID。</li>\n<li>如果ladon.Ladon无法将策略与请求匹配，会默认授权结果为拒绝，并返回错误。</li>\n</ul><h3>iam-authz-server使用方法介绍</h3><p>上面，我介绍了iam-authz-server的资源授权功能，这里介绍下如何使用iam-authz-server，也就是如何调用 <code>/v1/authz</code> 接口完成资源授权。你可以通过下面的3大步骤，来完成资源授权请求。</p><p><strong>第一步，登陆iam-<strong><strong>a</strong></strong>p<strong><strong>i</strong></strong>s<strong><strong>e</strong></strong>r<strong><strong>v</strong></strong>er，创建授权策略和密钥。</strong></p><p>这一步又分为3个小步骤。</p><ol>\n<li>登陆iam-apiserver系统，获取访问令牌：</li>\n</ol><pre><code class=\"language-shell\">$ token=`curl -s -XPOST -H'Content-Type: application/json' -d'{\"username\":\"admin\",\"password\":\"Admin@2021\"}' http://127.0.0.1:8080/login | jq -r .token`\n</code></pre><ol start=\"2\">\n<li>创建授权策略：</li>\n</ol><pre><code class=\"language-shell\">$ curl -s -XPOST -H\"Content-Type: application/json\" -H\"Authorization: Bearer $token\" -d'{\"metadata\":{\"name\":\"authztest\"},\"policy\":{\"description\":\"One policy to rule them all.\",\"subjects\":[\"users:&lt;peter|ken&gt;\",\"users:maria\",\"groups:admins\"],\"actions\":[\"delete\",\"&lt;create|update&gt;\"],\"effect\":\"allow\",\"resources\":[\"resources:articles:&lt;.*&gt;\",\"resources:printer\"],\"conditions\":{\"remoteIP\":{\"type\":\"CIDRCondition\",\"options\":{\"cidr\":\"192.168.0.1/16\"}}}}}' http://127.0.0.1:8080/v1/policies\n</code></pre><ol start=\"3\">\n<li>创建密钥，并从请求结果中提取secretID 和 secretKey：</li>\n</ol><pre><code class=\"language-shell\">$ curl -s -XPOST -H\"Content-Type: application/json\" -H\"Authorization: Bearer $token\" -d'{\"metadata\":{\"name\":\"authztest\"},\"expires\":0,\"description\":\"admin secret\"}' http://127.0.0.1:8080/v1/secrets\n{\"metadata\":{\"id\":23,\"name\":\"authztest\",\"createdAt\":\"2021-04-08T07:24:50.071671422+08:00\",\"updatedAt\":\"2021-04-08T07:24:50.071671422+08:00\"},\"username\":\"admin\",\"secretID\":\"ZuxvXNfG08BdEMqkTaP41L2DLArlE6Jpqoox\",\"secretKey\":\"7Sfa5EfAPIwcTLGCfSvqLf0zZGCjF3l8\",\"expires\":0,\"description\":\"admin secret\"}\n</code></pre><p><strong>第二步，生成访问 iam-authz-server的 token。</strong></p><p>iamctl 提供了 <code>jwt sigin</code> 子命令，可以根据 secretID 和 secretKey 签发 Token，方便使用。</p><pre><code class=\"language-shell\">$ iamctl jwt sign ZuxvXNfG08BdEMqkTaP41L2DLArlE6Jpqoox 7Sfa5EfAPIwcTLGCfSvqLf0zZGCjF3l8 # iamctl jwt sign $secretID $secretKey\neyJhbGciOiJIUzI1NiIsImtpZCI6Ilp1eHZYTmZHMDhCZEVNcWtUYVA0MUwyRExBcmxFNkpwcW9veCIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXV0aHoubWFybW90ZWR1LmNvbSIsImV4cCI6MTYxNzg0NTE5NSwiaWF0IjoxNjE3ODM3OTk1LCJpc3MiOiJpYW1jdGwiLCJuYmYiOjE2MTc4Mzc5OTV9.za9yLM7lHVabPAlVQLCqXEaf8sTU6sodAsMXnmpXjMQ\n</code></pre><p>你可以通过 <code>iamctl jwt show &lt;token&gt;</code> 来查看Token的内容：</p><pre><code class=\"language-shell\">$ iamctl jwt show eyJhbGciOiJIUzI1NiIsImtpZCI6Ilp1eHZYTmZHMDhCZEVNcWtUYVA0MUwyRExBcmxFNkpwcW9veCIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXV0aHoubWFybW90ZWR1LmNvbSIsImV4cCI6MTYxNzg0NTE5NSwiaWF0IjoxNjE3ODM3OTk1LCJpc3MiOiJpYW1jdGwiLCJuYmYiOjE2MTc4Mzc5OTV9.za9yLM7lHVabPAlVQLCqXEaf8sTU6sodAsMXnmpXjMQ\nHeader:\n{\n&nbsp; &nbsp; \"alg\": \"HS256\",\n&nbsp; &nbsp; \"kid\": \"ZuxvXNfG08BdEMqkTaP41L2DLArlE6Jpqoox\",\n&nbsp; &nbsp; \"typ\": \"JWT\"\n}\nClaims:\n{\n&nbsp; &nbsp; \"aud\": \"iam.authz.marmotedu.com\",\n&nbsp; &nbsp; \"exp\": 1617845195,\n&nbsp; &nbsp; \"iat\": 1617837995,\n&nbsp; &nbsp; \"iss\": \"iamctl\",\n&nbsp; &nbsp; \"nbf\": 1617837995\n}\n</code></pre><p>我们生成的Token包含了下面这些信息。</p><p><strong>Header</strong></p><ul>\n<li>alg：生成签名的算法。</li>\n<li>kid：密钥ID。</li>\n<li>typ：Token的类型，这里是JWT。</li>\n</ul><p><strong>Claims</strong></p><ul>\n<li>aud：JWT Token的接受者。</li>\n<li>exp：JWT Token的过期时间（UNIX时间格式）。</li>\n<li>iat：JWT Token的签发时间（UNIX时间格式）。</li>\n<li>iss：签发者，因为我们是用 iamctl 工具签发的，所以这里的签发者是 iamctl。</li>\n<li>nbf：JWT Token的生效时间（UNIX时间格式），默认是签发时间。</li>\n</ul><p><strong>第三步，调用</strong><code>/v1/authz</code><strong>接口</strong><strong>，</strong><strong>完成资源授权请求。</strong></p><p>请求方法如下：</p><pre><code class=\"language-shell\">$ curl -s -XPOST -H'Content-Type: application/json' -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsImtpZCI6Ilp1eHZYTmZHMDhCZEVNcWtUYVA0MUwyRExBcmxFNkpwcW9veCIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXV0aHoubWFybW90ZWR1LmNvbSIsImV4cCI6MTYxNzg0NTE5NSwiaWF0IjoxNjE3ODM3OTk1LCJpc3MiOiJpYW1jdGwiLCJuYmYiOjE2MTc4Mzc5OTV9.za9yLM7lHVabPAlVQLCqXEaf8sTU6sodAsMXnmpXjMQ' -d'{\"subject\":\"users:maria\",\"action\":\"delete\",\"resource\":\"resources:articles:ladon-introduction\",\"context\":{\"remoteIP\":\"192.168.0.5\"}}' http://127.0.0.1:9090/v1/authz\n{\"allowed\":true}\n</code></pre><p>如果授权通过，会返回：<code>{\"allowed\":true}</code> 。 如果授权失败，则返回：</p><pre><code class=\"language-shell\">{\"allowed\":false,\"denied\":true,\"reason\":\"Request was denied by default\"}\n</code></pre><h2>iam-authz-server的代码实现</h2><p>接下来，我们来看下iam-authz-server的具体实现，我会从配置处理、启动流程、请求处理流程和代码架构4个方面来讲解。</p><h3>iam-authz-server的配置处理</h3><p>iam-authz-server服务的main函数位于<a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/cmd/iam-authz-server/authzserver.go\">authzserver.go</a>文件中，你可以跟读代码，了解iam-authz-server的代码实现。iam-authz-server的服务框架设计跟iam-apiserver的服务框架设计保持一致，也是有3种配置：Options配置、组件配置和HTTP服务配置。</p><p>Options配置见<a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/authzserver/options/options.go\">options.go</a>文件：</p><pre><code class=\"language-go\">type Options struct {\n&nbsp; &nbsp; RPCServer&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;string\n&nbsp; &nbsp; ClientCA&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; string\n&nbsp; &nbsp; GenericServerRunOptions *genericoptions.ServerRunOptions\n&nbsp; &nbsp; InsecureServing&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;*genericoptions.InsecureServingOptions\n&nbsp; &nbsp; SecureServing&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;*genericoptions.SecureServingOptions\n&nbsp; &nbsp; RedisOptions&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; *genericoptions.RedisOptions\n&nbsp; &nbsp; FeatureOptions&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; *genericoptions.FeatureOptions\n&nbsp; &nbsp; Log&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;*log.Options\n&nbsp; &nbsp; AnalyticsOptions&nbsp; &nbsp; &nbsp; &nbsp; *analytics.AnalyticsOptions\n}\n</code></pre><p>和iam-apiserver相比，iam-authz-server多了 <code>AnalyticsOptions</code>，用来配置iam-authz-server内的Analytics服务，Analytics服务会将授权日志异步写入到Redis中。</p><p>iam-apiserver和iam-authz-server共用了GenericServerRunOptions、InsecureServing、SecureServing、FeatureOptions、RedisOptions、Log这些配置。所以，我们只需要用简单的几行代码，就可以将很多配置项都引入到iam-authz-server的命令行参数中，这也是命令行参数分组带来的好处：批量共享。</p><h3>iam-authz-server启动流程设计</h3><p>接下来，我们来详细看下iam-authz-server的启动流程。</p><p>iam-authz-server的启动流程也和iam-apiserver基本保持一致。二者比较大的不同在于Options参数配置和应用初始化内容。另外，和iam-apiserver相比，iam-authz-server只提供了REST API服务。启动流程如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/19/35/195178d37854bac7d5243d80e42a4c35.jpg?wh=2248x799\" alt=\"\"></p><h3>iam-authz-server 的 RESTful API请求处理流程</h3><p>iam-authz-server的请求处理流程也是清晰、规范的，具体流程如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/5a/89/5a83384f5762c41831190628bfa60989.jpg?wh=2248x780\" alt=\"\"></p><p><strong>首先，</strong>我们通过API调用（<code>&lt;HTTP Method&gt; + &lt;HTTP Request Path&gt;</code>）请求iam-authz-server提供的RESTful API接口 <code>POST /v1/authz</code> 。</p><p><strong>接着，</strong>Gin Web框架接收到HTTP请求之后，会通过认证中间件完成请求的认证，iam-authz-server采用了Bearer认证方式。</p><p><strong>然后，</strong>请求会被我们加载的一系列中间件所处理，例如跨域、RequestID、Dump等中间件。</p><p><strong>最后，</strong>根据<code>&lt;HTTP Method&gt; + &lt;HTTP Request Path&gt;</code>进行路由匹配。</p><p>比如，我们请求的RESTful API是<code>POST /v1/authz</code>，Gin Web框架会根据 HTTP Method 和 HTTP Request Path，查找注册的Controllers，最终匹配到 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/authzserver/controller/v1/authorize/authorize.go#L33\">authzController.Authorize</a> Controller。在 Authorize Controller中，会先解析请求参数，接着校验请求参数、调用业务层的方法进行资源授权，最后处理业务层的返回结果，返回最终的 HTTP 请求结果。</p><h3>iam-authz-server的代码架构</h3><p>iam-authz-server的代码设计和iam-apiserver一样，遵循简洁架构设计。</p><p>iam-authz-server的代码架构也分为4层，分别是模型层（Models）、控制层（Controller）、业务层 （Service）和仓库层（Repository）。从控制层、业务层到仓库层，从左到右层级依次加深。模型层独立于其他层，可供其他层引用。如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/a5/dd/a57832495c9e031a94282f0a8a3a61dd.jpg?wh=2248x702\" alt=\"\"></p><p>iam-authz-server 和 iam-apiserver 的代码架构有这三点不同：</p><ul>\n<li>iam-authz-server客户端不支持前端和命令行。</li>\n<li>iam-authz-server仓库层对接的是iam-apiserver微服务，而非数据库。</li>\n<li>iam-authz-server业务层的代码存放在目录<a href=\"https://github.com/marmotedu/iam/tree/v1.0.4/internal/authzserver/authorization\">authorization</a>中。</li>\n</ul><h2>iam-authz-server关键代码分析</h2><p>和 iam-apiserver 一样，iam-authz-server也包含了一些优秀的设计思路和关键代码，这里我来一一介绍下。</p><h3>资源授权</h3><p>先来看下，iam-authz-server是如何实现资源授权的。</p><p>我们可以调用iam-authz-server的 <code>/v1/authz</code>  API接口，实现资源的访问授权。 <code>/v1/authz</code> 对应的controller方法是<a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/authzserver/controller/v1/authorize/authorize.go#L33\">Authorize</a>：</p><pre><code class=\"language-go\">func (a *AuthzController) Authorize(c *gin.Context) {\n\tvar r ladon.Request\n\tif err := c.ShouldBind(&amp;r); err != nil {\n\t\tcore.WriteResponse(c, errors.WithCode(code.ErrBind, err.Error()), nil)\n\n\t\treturn\n\t}\n\n\tauth := authorization.NewAuthorizer(authorizer.NewAuthorization(a.store))\n\tif r.Context == nil {\n\t\tr.Context = ladon.Context{}\n\t}\n\n\tr.Context[\"username\"] = c.GetString(\"username\")\n\trsp := auth.Authorize(&amp;r)\n\n\tcore.WriteResponse(c, nil, rsp)\n}\n</code></pre><p>该函数使用 <code>github.com/ory/ladon</code> 包进行资源访问授权，授权流程如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/7c/a6/7c251c61cb535714edd390eac18df8a6.jpg?wh=2248x920\" alt=\"\"></p><p>具体分为以下几个步骤：</p><p>第一步，在Authorize方法中调用 <code>c.ShouldBind(&amp;r)</code> ，将API请求参数解析到 <code>ladon.Request</code> 类型的结构体变量中。</p><p>第二步，调用<a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/authzserver/authorization/authorizer.go#L21\">authorization.NewAuthorizer</a>函数，该函数会创建并返回包含Manager和AuditLogger字段的<a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/authzserver/authorization/authorizer.go#L16\">Authorizer</a>类型的变量。</p><p>Manager包含一些函数，比如 Create、Update和FindRequestCandidates等，用来对授权策略进行增删改查。AuditLogger包含 LogRejectedAccessRequest 和 LogGrantedAccessRequest 函数，分别用来记录被拒绝的授权请求和被允许的授权请求，将其作为审计数据使用。</p><p>第三步，调用<a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/authzserver/authorization/authorizer.go#L31\">auth.Authorize</a>函数，对请求进行访问授权。auth.Authorize函数内容如下：</p><pre><code class=\"language-go\">func (a *Authorizer) Authorize(request *ladon.Request) *authzv1.Response {\n\tlog.Debug(\"authorize request\", log.Any(\"request\", request))\n\n\tif err := a.warden.IsAllowed(request); err != nil {\n\t\treturn &amp;authzv1.Response{\n\t\t\tDenied: true,\n\t\t\tReason: err.Error(),\n\t\t}\n\t}\n\n\treturn &amp;authzv1.Response{\n\t\tAllowed: true,\n\t}\n}\n</code></pre><p>该函数会调用 <code>a.warden.IsAllowed(request)</code> 完成资源访问授权。IsAllowed函数会调用 <code>FindRequestCandidates(r)</code> 查询所有的策略列表，这里要注意，我们只需要查询请求用户的policy列表。在Authorize函数中，我们将username存入ladon Request的context中：</p><pre><code class=\"language-go\">r.Context[\"username\"] = c.GetHeader(\"username\")\n</code></pre><p>在<a href=\"https://github.com/marmotedu/iam/blob/v1.0.4/internal/authzserver/authorization/manager.go#L54\">FindRequestCandidates</a>函数中，我们可以从Request中取出username，并根据username查询缓存中的policy列表，FindRequestCandidates实现如下：</p><pre><code class=\"language-go\">func (m *PolicyManager) FindRequestCandidates(r *ladon.Request) (ladon.Policies, error) {\n\t\tusername := \"\"\n\t\n\t\tif user, ok := r.Context[\"username\"].(string); ok {\n\t\t\tusername = user\n\t\t}\n\t\n\t\tpolicies, err := m.client.List(username)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"list policies failed\")\n\t\t}\n\t\n\t\tret := make([]ladon.Policy, 0, len(policies))\n\t\tfor _, policy := range policies {\n\t\t\tret = append(ret, policy)\n\t\t}\n\t\n\t\treturn ret, nil\n\t}\n</code></pre><p>IsAllowed函数代码如下：</p><pre><code class=\"language-go\">func (l *Ladon) IsAllowed(r *Request) (err error) {\n&nbsp; &nbsp; policies, err := l.Manager.FindRequestCandidates(r)\n&nbsp; &nbsp; if err != nil {\n&nbsp; &nbsp; &nbsp; &nbsp; go l.metric().RequestProcessingError(*r, nil, err)\n&nbsp; &nbsp; &nbsp; &nbsp; return err\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; return l.DoPoliciesAllow(r, policies)\n}\n</code></pre><p>IsAllowed会调用 <code>DoPoliciesAllow(r, policies)</code> 函数进行权限校验。如果权限校验不通过（请求在指定条件下不能够对资源做指定操作），就调用 <code>LogRejectedAccessRequest</code> 函数记录拒绝的请求，并返回值为非nil的error，error中记录了授权失败的错误信息。如果权限校验通过，则调用 <code>LogGrantedAccessRequest</code> 函数记录允许的请求，并返回值为nil的error。</p><p>为了降低请求延时，LogRejectedAccessRequest和LogGrantedAccessRequest会将授权记录存储在Redis中，之后由iam-pump进程读取Redis，并将授权记录持久化存储在MongoDB中。</p><h3>缓存设计</h3><p>iam-authz-server主要用来做资源访问授权，属于数据流的组件，对接口访问性能有比较高的要求，所以该组件采用了缓存的机制。如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/05/51/05d1c9a9acdc451f915684c18c8b9f51.jpg?wh=2248x822\" alt=\"\"></p><p>iam-authz-server组件通过<strong>缓存密钥和授权策略信息</strong>到内存中，加快密钥和授权策略的查询速度。通过<strong>缓存授权记录</strong>到内存中，提高了授权数据的写入速度，从而大大降低了授权请求接口的延时。</p><p>上面的缓存机制用到了Redis key-value存储，所以在iam-authz-server初始化阶段，需要先建立Redis连接（位于<a href=\"https://github.com/marmotedu/iam/blob/v1.0.5/internal/authzserver/server.go#L132\">initialize</a>函数中）：</p><pre><code class=\"language-go\">go storage.ConnectToRedis(ctx, s.buildStorageConfig())\n</code></pre><p>这个代码会维护一个Redis连接，如果Redis连接断掉，会尝试重连。这种方式可以使我们在调用Redis接口进行数据读写时，不用考虑连接断开的问题。</p><p>接下来，我们就来详细看看，iam-authz-server是如何实现缓存机制的。</p><p><strong>先来看下密钥和策略缓存。</strong></p><p>iam-authz-server通过<a href=\"https://github.com/marmotedu/iam/tree/v1.0.5/internal/authzserver/load\">load</a>包来完成密钥和策略的缓存。</p><p>在iam-authz-server进程启动时，会创建并启动一个Load服务（位于<a href=\"https://github.com/marmotedu/iam/blob/v1.0.5/internal/authzserver/server.go#L144\">initialize</a>函数中）：</p><pre><code class=\"language-go\">load.NewLoader(ctx, cacheIns).Start()&nbsp;\n</code></pre><p><strong>先来看创建Load服务。</strong>创建Load服务时，传入了cacheIns参数，cacheIns是一个实现了<a href=\"https://github.com/marmotedu/iam/blob/v1.0.5/internal/authzserver/load/load.go#L16\">Loader</a>接口的实例：</p><pre><code class=\"language-go\">type Loader interface {\n&nbsp; &nbsp; Reload() error\n}\n</code></pre><p><strong>然后看启动Load服务。</strong>通过Load实例的 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.5/internal/authzserver/load/load.go#L37\">Start</a> 方法来启动Load服务：</p><pre><code class=\"language-go\">func (l *Load) Start() {\n&nbsp; &nbsp; go startPubSubLoop()\n&nbsp; &nbsp; go l.reloadQueueLoop()\n&nbsp; &nbsp; go l.reloadLoop()\n\n&nbsp; &nbsp; l.DoReload()\n}\n</code></pre><p>Start函数先启动了3个协程，再调用 <code>l.DoReload()</code> 完成一次密钥和策略的同步：</p><pre><code class=\"language-go\">func (l *Load) DoReload() {\n&nbsp; &nbsp; l.lock.Lock()\n&nbsp; &nbsp; defer l.lock.Unlock()\n\n&nbsp; &nbsp; if err := l.loader.Reload(); err != nil {\n&nbsp; &nbsp; &nbsp; &nbsp; log.Errorf(\"faild to refresh target storage: %s\", err.Error())\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; log.Debug(\"refresh target storage succ\")\n}\n</code></pre><p>上面我们说了，创建Load服务时，传入的cacheIns实例是一个实现了Loader接口的实例，所以在<a href=\"https://github.com/marmotedu/iam/blob/v1.0.5/internal/authzserver/load/load.go#L119\">DoReload</a>方法中，可以直接调用Reload方法。cacheIns的Reload方法会从iam-apiserver中同步密钥和策略信息到iam-authz-server缓存中。</p><p>我们再来看下，startPubSubLoop、reloadQueueLoop、reloadLoop 这3个Go协程分别完成了什么功能。</p><ol>\n<li>startPubSubLoop协程</li>\n</ol><p><a href=\"https://github.com/marmotedu/iam/blob/v1.0.5/internal/authzserver/load/redis_signals.go#L46\">startPubSubLoop</a>函数通过<a href=\"https://github.com/marmotedu/iam/blob/v1.0.5/pkg/storage/redis_cluster.go#L897\">StartPubSubHandler</a>函数，订阅Redis的 <code>iam.cluster.notifications</code> channel，并注册一个回调函数：</p><pre><code class=\"language-go\">func(v interface{}) {\n&nbsp; &nbsp; handleRedisEvent(v, nil, nil)\n}\n</code></pre><p><a href=\"https://github.com/marmotedu/iam/blob/v1.0.5/internal/authzserver/load/redis_signals.go#L65\">handleRedisEvent</a>函数中，会将消息解析为<a href=\"https://github.com/marmotedu/iam/blob/v1.0.5/internal/authzserver/load/redis_signals.go#L32\">Notification</a>类型的消息，并判断Command的值。如果是NoticePolicyChanged或NoticeSecretChanged，就会向 <code>reloadQueue</code> channel中写入一个回调函数。因为我们不需要用回调函数做任何事情，所以这里回调函数是nil。 <code>reloadQueue</code> 主要用来告诉程序，需要完成一次密钥和策略的同步。</p><ol start=\"2\">\n<li>reloadQueueLoop协程</li>\n</ol><p>reloadQueueLoop函数会监听 <code>reloadQueue</code> ，当发现有新的消息（这里是回调函数）写入时，会实时将消息缓存到 <code>requeue</code> 切片中，代码如下：</p><pre><code class=\"language-go\">func (l *Load) reloadQueueLoop(cb ...func()) {\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase &lt;-l.ctx.Done():\n\t\t\t\treturn\n\t\t\tcase fn := &lt;-reloadQueue:\n\t\t\t\trequeueLock.Lock()\n\t\t\t\trequeue = append(requeue, fn)\n\t\t\t\trequeueLock.Unlock()\n\t\t\t\tlog.Info(\"Reload queued\")\n\t\t\t\tif len(cb) != 0 {\n\t\t\t\t\tcb[0]()\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n</code></pre><ol start=\"3\">\n<li>reloadLoop协程</li>\n</ol><p>通过<a href=\"https://github.com/marmotedu/iam/blob/v1.0.5/internal/authzserver/load/load.go#L81\">reloadLoop</a>函数启动一个timer定时器，每隔1秒会检查 <code>requeue</code> 切片是否为空，如果不为空，则调用 <code>l.DoReload</code> 方法，从iam-apiserver中拉取密钥和策略，并缓存在内存中。</p><p>密钥和策略的缓存模型如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/a2/11/a2f5694e5d6291ca610b84ee49469211.jpg?wh=2248x890\" alt=\"\"></p><p><strong>密钥和策略缓存的具体流程如下：</strong></p><p>接收上游消息（这里是从Redis中接收），将消息缓存到切片或者带缓冲的channel中，并启动一个消费协程去消费这些消息。这里的消费协程是reloadLoop，reloadLoop会每隔1s判断 <code>requeue</code> 切片是否长度为0，如果不为0，则执行 <code>l.DoReload()</code> 缓存密钥和策略。</p><p>讲完了密钥和策略缓存，<strong>再<strong><strong>来</strong></strong>看下授权日志缓存。</strong></p><p>在启动iam-authz-server时，还会启动一个Analytics服务，代码如下（位于<a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/authzserver/server.go#L147-L156\">internal/authzserver/server.go</a>文件中）：</p><pre><code class=\"language-go\">&nbsp; &nbsp; if s.analyticsOptions.Enable {&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; analyticsStore := storage.RedisCluster{KeyPrefix: RedisKeyPrefix}&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; analyticsIns := analytics.NewAnalytics(s.analyticsOptions, &amp;analyticsStore)&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; analyticsIns.Start()&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; s.gs.AddShutdownCallback(shutdown.ShutdownFunc(func(string) error {&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; analyticsIns.Stop()&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; return nil&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; }))&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; }\n</code></pre><p><a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/authzserver/analytics/analytics.go#L64-L79\">NewAnalytics</a>函数会根据配置，创建一个Analytics实例：</p><pre><code class=\"language-go\">func NewAnalytics(options *AnalyticsOptions, store storage.AnalyticsHandler) *Analytics {\n\t\tps := options.PoolSize\n\t\trecordsBufferSize := options.RecordsBufferSize\n\t\tworkerBufferSize := recordsBufferSize / uint64(ps)\n\t\tlog.Debug(\"Analytics pool worker buffer size\", log.Uint64(\"workerBufferSize\", workerBufferSize))\n\t\n\t\trecordsChan := make(chan *AnalyticsRecord, recordsBufferSize)\n\t\n\t\treturn &amp;Analytics{\n\t\t\tstore:                      store,\n\t\t\tpoolSize:                   ps,\n\t\t\trecordsChan:                recordsChan,\n\t\t\tworkerBufferSize:           workerBufferSize,\n\t\t\trecordsBufferFlushInterval: options.FlushInterval,\n\t\t}\n\t}&nbsp;\n</code></pre><p>上面的代码创建了一个带缓冲的 <code>recordsChan</code> ：</p><pre><code class=\"language-go\">recordsChan := make(chan *AnalyticsRecord, recordsBufferSize)\n</code></pre><p><code>recordsChan</code> 存放的数据类型为<a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/authzserver/analytics/analytics.go#L26-L35\">AnalyticsRecord</a>，缓冲区的大小为 <code>recordsBufferSize</code> （通过 <code>--analytics.records-buffer-size</code> 选项指定）。可以通过<a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/authzserver/analytics/analytics.go#L115-L126\">RecordHit</a>函数，向<code>recordsChan</code> 中写入 AnalyticsRecord 类型的数据：</p><pre><code class=\"language-go\">func (r *Analytics) RecordHit(record *AnalyticsRecord) error {&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; // check if we should stop sending records 1st&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; if atomic.LoadUint32(&amp;r.shouldStop) &gt; 0 {&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; return nil&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; }&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; // just send record to channel consumed by pool of workers&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; // leave all data crunching and Redis I/O work for pool workers&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; r.recordsChan &lt;- record&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; return nil&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n}&nbsp; &nbsp;\n</code></pre><p>iam-authz-server是通过调用 LogGrantedAccessRequest 和 LogRejectedAccessRequest 函数来记录授权日志的。在记录授权日志时，会将授权日志写入 <code>recordsChan</code>  channel中。<a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/authzserver/authorization/authorizer/authorizer.go#L100-L115\">LogGrantedAccessRequest</a>函数代码如下：</p><p></p><pre><code class=\"language-go\">func (auth *Authorization) LogGrantedAccessRequest(r *ladon.Request, p ladon.Policies, d ladon.Policies) {\n&nbsp; &nbsp; conclusion := fmt.Sprintf(\"policies %s allow access\", joinPoliciesNames(d))&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; rstring, pstring, dstring := convertToString(r, p, d)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; record := analytics.AnalyticsRecord{&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; TimeStamp:&nbsp; time.Now().Unix(),&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; Username:&nbsp; &nbsp;r.Context[\"username\"].(string),&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; Effect:&nbsp; &nbsp; &nbsp;ladon.AllowAccess,&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; Conclusion: conclusion,&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; Request:&nbsp; &nbsp; rstring,&nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; Policies:&nbsp; &nbsp;pstring,&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; Deciders:&nbsp; &nbsp;dstring,&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; }&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; record.SetExpiry(0)\n&nbsp; &nbsp; _ = analytics.GetAnalytics().RecordHit(&amp;record)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n}&nbsp;\n</code></pre><p>上面的代码，会创建AnalyticsRecord类型的结构体变量，并调用RecordHit将变量的值写入 <code>recordsChan</code>  channel中。将授权日志写入 <code>recordsChan</code> &nbsp; channel中，而不是直接写入Redis中，这可以大大减少写入延时，减少接口的响应延时。</p><p>还有一个worker进程从recordsChan中读取数据，并在数据达到一定阈值之后，批量写入Redis中。在<a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/authzserver/analytics/analytics.go#L87-L100\">Start</a>函数中，我们创建了一批worker，worker个数可以通过 <code>--analytics.pool-size</code> 来指定 。Start函数内容如下：</p><pre><code class=\"language-go\">func (r *Analytics) Start() {\n\t\tanalytics = r\n\t\tr.store.Connect()\n\t\n\t\t// start worker pool\n\t\tatomic.SwapUint32(&amp;r.shouldStop, 0)\n\t\tfor i := 0; i &lt; r.poolSize; i++ {\n\t\t\tr.poolWg.Add(1)\n\t\t\tgo r.recordWorker()\n\t\t}\n\t\n\t\t// stop analytics workers\n\t\tgo r.Stop()\n\t}\n</code></pre><p>上面的代码通过 <code>go r.recordWorker()</code> 创建了 由<code>poolSize</code> 指定个数的<a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/authzserver/analytics/analytics.go#L128-L173\">recordWorker</a>（worker），recordWorker函数会从 <code>recordsChan</code> 中读取授权日志并存入recordsBuffer中，recordsBuffer的大小为workerBufferSize，workerBufferSize计算公式为：</p><pre><code class=\"language-go\">ps := options.PoolSize\nrecordsBufferSize := options.RecordsBufferSize\nworkerBufferSize := recordsBufferSize / uint64(ps)\n</code></pre><p>其中，options.PoolSize由命令行参数 <code>--analytics.pool-size</code> 指定，代表worker 的个数，默认 50；options.RecordsBufferSize由命令行参数 <code>--analytics.records-buffer-size</code> 指定，代表缓存的授权日志消息数。也就是说，我们把缓存的记录平均分配给所有的worker。</p><p>当recordsBuffer存满或者达到投递最大时间后，调用 <code>r.Store.AppendToSetPipelined(analyticsKeyName, recordsBuffer)</code> 将记录批量发送给Redis，为了提高传输速率，这里将日志内容编码为msgpack格式后再传输。</p><p>上面的缓存方法可以抽象成一个缓存模型，满足实际开发中的大部分需要异步转存的场景，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/47/95/479fyy2cd16a6c1fa5f6074f7ce6fe95.jpg?wh=2248x668\" alt=\"\"></p><p>Producer将数据投递到带缓冲的channel中，后端有多个worker消费channel中的数据，并进行批量投递。你可以设置批量投递的条件，一般至少包含<strong>最大投递日志数</strong>和<strong>最大投递时间间隔</strong>这两个。</p><p>通过以上缓冲模型，你可以将日志转存的时延降到最低。</p><h3>数据一致性</h3><p>上面介绍了 iam-authz-server的 <code>/v1/authz</code> 接口，为了最大化地提高性能，采用了大量的缓存设计。因为数据会分别在持久化存储和内存中都存储一份，就可能会出现数据不一致的情况。所以，我们也要确保缓存中的数据和数据库中的数据是一致的。数据一致性架构如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/72/a4/72c2afe63d197e7335deec1ac9f550a4.jpg?wh=2248x1006\" alt=\"\"></p><p>密钥和策略同步流程如下：</p><ol>\n<li>通过iam-webconsole请求iam-apiserver创建（或更新、删除）密钥（或策略）。</li>\n<li>iam-apiserver收到“写”请求后，会向Redis  <code>iam.cluster.notifications</code> channel发送PolicyChanged或SecretChanged消息。</li>\n<li>Loader收到消息后，会触发cache loader实例执行 <code>Reload</code> 方法，重新从iam-apiserver中同步密钥和策略信息。</li>\n</ol><p>Loader不会关心 <code>Reload</code> 方法的具体实现，只会在收到指定消息时，执行 <code>Reload</code> 方法。通过这种方式，我们可以实现不同的缓存策略。</p><p>在cache实例的 <code>Reload</code> 方法中，我们其实是调用仓库层Secret和Policy的List方法来获取密钥和策略列表。仓库层又是通过执行gRPC请求，从iam-apiserver中获取密钥和策略列表。</p><p>cache的<a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/authzserver/load/cache/cache.go#L105-L132\">Reload</a>方法，会将获取到的密钥和策略列表缓存在<a href=\"https://github.com/dgraph-io/ristretto\">ristretto</a>类型的Cache中，供业务层调用。业务层代码位于<a href=\"https://github.com/marmotedu/iam/tree/v1.0.6/internal/authzserver/authorization\">internal/authzserver/authorization</a>目录下。</p><h2>总结</h2><p>这一讲中，我介绍了IAM数据流服务iam-authz-server的设计和实现。iam-authz-server提供了 <code>/v1/authz</code> RESTful API接口，供第三方用户完成资源授权功能，具体是使用Ladon包来完成资源授权的。Ladon包解决了“在特定的条件下，谁能够/不能够对哪些资源做哪些操作”的问题。</p><p>iam-authz-server的配置处理、启动流程和请求处理流程跟iam-apiserver保持一致。此外，iam-authz-server也实现了简洁架构。</p><p>iam-authz-server通过缓存密钥和策略信息、缓存授权日志来提高 <code>/v1/authz</code> 接口的性能。</p><p>在缓存密钥和策略信息时，为了和iam-apiserver中的密钥和策略信息保持一致，使用了Redis Pub/Sub机制。当iam-apiserver有密钥/策略变更时，会往指定的Redis channel Pub一条消息。iam-authz-server订阅相同的channel，在收到新消息时，会解析消息，并重新从iam-apiserver中获取密钥和策略信息，缓存在内存中。</p><p>iam-authz-server执行完资源授权之后，会将授权日志存放在一个带缓冲的channel中。后端有多个worker消费channel中的数据，并进行批量投递。可以设置批量投递的条件，例如最大投递日志数和最大投递时间间隔。</p><h2>课后练习</h2><ol>\n<li>iam-authz-server和iam-apiserver共用了应用框架（包括一些配置项）和HTTP服务框架层的代码，请阅读iam-authz-server代码，看下IAM项目是如何实现代码复用的。</li>\n<li>iam-authz-server使用了<a href=\"https://github.com/dgraph-io/ristretto\">ristretto</a>来缓存密钥和策略信息，请调研下业界还有哪些优秀的缓存包可供使用，欢迎在留言区分享。</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"30 | ORM：CURD 神器 GORM 包介绍及实战","id":403351},"right":{"article_title":"32 | 数据处理：如何高效处理应用程序产生的数据？","id":405524}}},{"article_id":405524,"article_title":"32 | 数据处理：如何高效处理应用程序产生的数据？","article_content":"<p>你好，我是孔令飞。今天我们来聊聊，如何更好地进行异步数据处理。</p><p>一个大型应用为了后期的排障、运营等，会将一些请求数据保存在存储系统中，供日后使用。例如：应用将请求日志保存到 Elasticsearch 中，方便排障；网关将 API 请求次数、请求消息体等数据保存在数据库中，供控制台查询展示。</p><p>为了满足这些需求，我们需要进行数据采集，数据采集在大型应用中很常见，但我发现不少开发者设计的数据采集服务，通常会存在下面这些问题：</p><ul>\n<li>采集服务只针对某个采集需求开发，如果采集需求有变，需要修改主代码逻辑，代码改动势必会带来潜在的 Bug，增加开发测试工作量。</li>\n<li>数据采集服务会导致已有的服务请求延时变高。</li>\n<li>采集数据性能差，需要较长时间才能采集完一批数据。</li>\n<li>启停服务时，会导致采集的数据丢失。</li>\n</ul><p>这一讲，我就来详细教你如何设计和落地一个数据采集服务，解决上面这些问题。</p><h2>数据采集方式的分类</h2><p>首先，你需要知道当前数据采集有哪些方式，以便更好地理解异步数据处理方案。</p><p>目前，数据采集主要有两种方式，分别是同步采集和异步采集。二者的概念和优缺点如下表所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/d4/b9/d4d4d6547225de5b565f99957106dbb9.jpg?wh=1920x1058\" alt=\"图片\"></p><p>现代应用对性能的要求越来越高，而异步采集对应用程序的性能影响更小，因此异步采集更受开发者欢迎，得到了大规模的应用。接下来，我要介绍的 IAM Pump Server 服务，采用的就是异步采集的方式。</p><!-- [[[read_end]]] --><h2>数据采集系统设计</h2><p>这一讲，我采用理论+实战的方式来展示如何设计一个数据采集服务，这里先来介绍下关于数据采集的理论知识，后面会有具体的实战案例。</p><p>在过往的项目开发中，我发现很多开发人员添加了数据采集功能后，因为同步上报数据、单线程、上报逻辑不对等原因，让整个应用程序的性能受到了严重影响。那么，如何在采集过程中不影响程序的性能？</p><p>答案就是让数据采集模型化。通过模型化，可以使设计出来的采集系统功能更加通用，能够满足未来的很多同类需求，我们也就不需要重复开发相同的系统了。</p><p>我今天就来给你详细介绍下，如何将数据采集功能模型化，以及该模型是如何解决上面说的的各种问题的。</p><h3>设计数据采集系统时需要解决的核心问题</h3><p>采集系统首先需要一个数据源 Input，Input 可以是一个或者多个，Input 中的数据来自于应用程序上报。采集后的数据通常需要经过处理，比如格式化、增删字段、过滤无用的数据等，然后将处理后的数据存储到下游系统（Output）中，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/a9/75/a91db8c7818af0898a1774073e9bfe75.jpg?wh=1920x1145\" alt=\"图片\"></p><p>这里，我们需要解决这 3 个核心问题：</p><ul>\n<li>进行数据采集，就需要在正常流程中多加一个上报数据环节，这势必会影响程序的性能。那么，如何让程序的性能损失最小化？</li>\n<li>如果 Input 产生数据的速度大于 Output 的消费能力，产生数据堆积怎么办？</li>\n<li>数据采集后需要存储到下游系统。在存储之前，我们需要对数据进行不同的处理，并可能会存储到不同的下游系统，这种可变的需求如何满足？</li>\n</ul><p>对于让程序性能损失最小化这一点，最好的方法是异步上报。如果是异步，我们需要先把数据缓存在内存中，然后再异步上报到目标系统中。当然，为了提高上报的效率，可以采用批量上报的方式。</p><p>对于数据堆积这个问题，比较好的解决方法是，将采集的数据先上报到一些具有高吞吐量、可以存储大量数据的中间组件，比如 Kafka、Redis 中。这种方式也是业界标准的处理方式。</p><p>对于采集需求多样化这个问题，我们可以将采集程序做成插件化、可扩展的，满足可变的需求。</p><p>要解决这 3 个问题，其实就涉及到了数据采集系统中的两个功能点的设计，它们分别是数据上报功能和数据采集功能。接下来我们就来看下，如何设计这两个功能点。</p><h3>数据上报功能设计</h3><p>为了提高异步上报的吞吐量，你可以将数据缓存在内存中（Go 中可以使用有缓冲 channel），并使用多个 worker 去消费内存中的数据。使用多个 worker ，可以充分发挥 CPU 的多核能力。另外，上报给下游系统时，你也可以采用批量上报的方式。</p><h3>数据采集功能设计</h3><p>现代应用程序越来越讲究插件化、扩展性，在设计采集系统时，也应该考虑到未来的需求。比如，未来你可能需要将数据从上报到 MongoDB 切换到 HBase 中，或者同时将数据上报到 MongoDB 和 HBase 中。因此，上报给下游的程序逻辑要具有插件化的能力，并能通过配置选择需要的插件。</p><p>为了提高程序性能，会先把数据缓存在内存中。但是这样有个缺点：在关停程序时，内存中的数据就会丢失。所以，在程序结束之前，我们需要确保内存中的数据能够上报成功，也就是说采集程序需要实现优雅关停功能。优雅关停不仅要确保缓存中的数据被成功上报，还要确保正在处理的数据被成功上报。</p><p>当然了，既然是数据采集，还要能够配置采集的频率。最后，因为采集程序通常是非 API 类型的，所以还需要对外暴露一个特殊的 API，用来返回采集程序的健康状态。</p><h3>数据采集应用模型</h3><p>通过上面的分析和设计，可以绘制出下面这个采集模型：</p><p><img src=\"https://static001.geekbang.org/resource/image/2e/34/2ecccdb3c851577f9cd5a56bb7197c34.jpg?wh=1920x910\" alt=\"图片\"></p><p>异步上报需要额外的异步逻辑，会增加开发工作量和程序复杂度，所以，对于一些 Input 数据生产速度小于 Output 消费速度，并且 Output 具有高吞吐量、低延时特性的场景，也可以采用同步上报，例如同步上报给 Redis。</p><h2>数据采集系统落地项目：iam-authz-server + iam-pump</h2><p>上面，我介绍了数据采集系统的架构，但是只有模型和理论，肯定还不足以解决你对数据采集程序的开发需求。所以，接下来我来介绍下如何落地上面的数据采集架构。整个架构包括两个部分，分别由不同的服务实现：</p><ul>\n<li>iam-authz-server：实现数据上报功能。</li>\n<li>iam-pump：实现数据采集功能。</li>\n</ul><p>整个采集系统的架构，跟上面描述的数据采集架构完全一致，这里就不重复说明了。</p><h2>iam-authz-server：数据上报</h2><p>数据上报的最大难点，就是如何减少上报逻辑对应用性能的影响。对此，我们主要的解决思路就是异步上报数据。</p><p>接下来我会介绍 iam-authz-server 的数据上报设计。这是一个非常成熟的设计，在我所开发和了解的项目中被大量采用，有些项目可以承载十亿级/天的请求量。通过介绍这个设计，我们来看看异步上报的具体方法，以及上报过程中要考虑的因素。</p><p>iam-authz-server 的数据上报架构如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/4d/3f/4d288a15fa6ebaae5ef25df8af5ac13f.jpg?wh=1920x764\" alt=\"图片\"></p><p>iam-authz-server 服务中的数据上报功能可以选择性开启，开启代码见 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/authzserver/server.go#L147-L156\">internal/authzserver/server.go</a> ，代码如下：</p><pre><code class=\"language-go\">&nbsp;if s.analyticsOptions.Enable {&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; analyticsStore := storage.RedisCluster{KeyPrefix: RedisKeyPrefix}&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; analyticsIns := analytics.NewAnalytics(s.analyticsOptions, &amp;analyticsStore)&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; analyticsIns.Start()&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; s.gs.AddShutdownCallback(shutdown.ShutdownFunc(func(string) error {&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; analyticsIns.Stop()&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; return nil&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; }))&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; }&nbsp; &nbsp;&nbsp; \n</code></pre><p>上面的代码中，当 <code>s.analyticsOptions.Enable</code> 为 <code>true</code> 时，开启数据上报功能。因为数据上报会影响程序的性能，而且在未来可能会存在禁掉数据上报功能的场景，所以在设计 iam-authz-server 时，就把数据上报功能做成了可配置的，也就是说可以通过配置文件来启用/禁用数据上报功能。配置方式也很简单：将 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/configs/iam-authz-server.yaml#L63\">iam-authz-server.yaml</a> 的 analytics.enable 设置为 true，代表开启数据上报功能；设置为 false ，则代表关闭数据上报功能。</p><p>这里，我建议你在设计程序时，将未来的可能变量考虑进去，并将这些变量做成可配置的。这样，如果哪天需求变化，我们就能通过修改配置文件，而不是修改代码的方式来满足需求。这种方式可以将应用程序的变动局限在配置文件中，从而大大减小现网服务出现故障的概率，做到只变更配置文件就可以缩短发布变更的周期。</p><p>在上面的代码中，通过 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/authzserver/analytics/analytics.go#L64-L79\">NewAnalytics</a> 创建一个数据上报服务，代码如下：</p><pre><code class=\"language-go\">func NewAnalytics(options *AnalyticsOptions, store storage.AnalyticsHandler) *Analytics {&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; ps := options.PoolSize&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; recordsBufferSize := options.RecordsBufferSize&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; workerBufferSize := recordsBufferSize / uint64(ps)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; log.Debug(\"Analytics pool worker buffer size\", log.Uint64(\"workerBufferSize\", workerBufferSize))&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; recordsChan := make(chan *AnalyticsRecord, recordsBufferSize)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; return &amp;Analytics{&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; store:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; store,&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; poolSize:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;ps,&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; recordsChan:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; recordsChan,&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; workerBufferSize:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;workerBufferSize,&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; recordsBufferFlushInterval: options.FlushInterval,&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; }&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n}&nbsp; &nbsp; &nbsp;&nbsp;\n</code></pre><p>这里的代码根据传入的参数，创建 Analytics 类型的变量并返回，变量中有 5 个字段需要你关注：</p><ul>\n<li>store： <a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/pkg/storage/storage.go#L65-L71\">storage.AnalyticsHandler</a> 接口类型，提供了 <code>Connect() bool</code>和 <code>AppendToSetPipelined(string, byte)</code>函数，分别用来连接 storage 和上报数据给 storage。iam-authz-server 用了 redis storage。</li>\n<li>recordsChan：授权日志会缓存在 recordsChan 带缓冲 channel 中，其长度可以通过 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/configs/iam-authz-server.yaml#L65\">iam-authz-server.yaml</a> 配置文件中的  <code>analytics.records-buffer-size</code>  配置。</li>\n<li>poolSize：指定开启 worker 的个数，也就是开启多少个 Go 协程来消费 recordsChan 中的消息。</li>\n<li>workerBufferSize：批量投递给下游系统的的消息数。通过批量投递，可以进一步提高消费能力、减少 CPU 消耗。</li>\n<li>recordsBufferFlushInterval：设置最迟多久投递一次，也就是投递数据的超时时间。</li>\n</ul><p>analytics.ecords-buffer-size 和 analytics.pool-size 建议根据部署机器的 CPU 和内存来配置。在应用真正上线前，我建议你通过压力和负载测试，来配置一个合适的值。</p><p>Analytics提供了 3 种方法：</p><ul>\n<li>Start()，用来启动数据上报服务。</li>\n<li>Stop()，用来关停数据上报服务。主程序在收到系统的终止命令后，调用 Stop 方法优雅关停数据上报服务，确保缓存中的数据都上报成功。</li>\n<li>RecordHit(record *AnalyticsRecord) error，用来记录 AnalyticsRecord 的数据。</li>\n</ul><p>通过 NewXxx （NewAnalytics）返回一个 Xxx （Analytics）类型的结构体，Xxx（Analytics） 类型带有一些方法，如下：</p><pre><code class=\"language-go\">func NewAnalytics(options) *Analytics {\n    ...\n}\n\nfunc (r *Analytics) Start() {\n    ...\n}\nfunc (r *Analytics) Stop() {\n    ...\n}\nfunc (r *Analytics) RecordHit(record *AnalyticsRecord) error {\n    ...\n}\n</code></pre><p>其实，上述代码段是一种常见的 Go 代码编写方式/设计模式。你在以后的开发生涯中，会经常遇到这种设计方式。使用上述代码设计方式有下面两个好处。</p><ul>\n<li><strong>功能模块化：</strong>将数据上报的功能封装成一个服务模块，数据和方法都围绕着 Xxx 结构体来展开。这和 C++、Java、Python 的类有相似的地方，你可以这么理解：Xxx 相当于类，NewXxx 相当于初始化一个类实例，Start、Stop、RecordHit 是这个类提供的方法。功能模块化可以使程序逻辑更加清晰，功能更独立、更好维护，也可以供其他应用使用。</li>\n<li><strong>方便数据传递：</strong>可以将数据存放在 Xxx 结构体字段中，供不同的方法共享使用，如果有并发，数据共享时，注意要给非并发安全的类型加锁，例如recordsChan。</li>\n</ul><p>接下来，我会介绍 iam-authz-server 服务中跟数据上报相关的 3 部分核心代码，分别是启动数据上报服务、异步上报授权日志和优雅关停数据上报。</p><h3>启动服务：启动数据上报服务</h3><p>在服务启动时，首先要启动数据上报功能模块。我们通过调用 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/authzserver/analytics/analytics.go#L87-L100\">analyticsIns.Start()</a> 启动数据上报服务。Start 代码如下：</p><pre><code class=\"language-go\">func (r *Analytics) Start() {\n    analytics = r\n    r.store.Connect()\n\n    // start worker pool\n    atomic.SwapUint32(&amp;r.shouldStop, 0)\n    for i := 0; i &lt; r.poolSize; i++ {\n        r.poolWg.Add(1)\n        go r.recordWorker()\n    }\n\n    // stop analytics workers\n    go r.Stop()\n}\n</code></pre><p>这里有一点需要你注意，数据上报和数据采集都大量应用了 Go 协程来并发地执行操作，为了防止潜在的并发读写引起的Bug，建议你的测试程序编译时加上 -race，例如go build -race cmd/iam-authz-server/authzserver.go。然后，在测试过程中，观察程序日志，看有无并发问题出现。</p><p>Start 中会开启 poolSize 个数的 worker 协程，这些协程共同消费 recordsChan 中的消息，消费逻辑见 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/authzserver/analytics/analytics.go#L128-L173\">recordWorker()</a> ，代码如下：</p><pre><code class=\"language-go\">func (r *Analytics) recordWorker() {\n\tdefer r.poolWg.Done()\n\n\t// this is buffer to send one pipelined command to redis\n\t// use r.recordsBufferSize as cap to reduce slice re-allocations\n\trecordsBuffer := make([][]byte, 0, r.workerBufferSize)\n\n\t// read records from channel and process\n\tlastSentTS := time.Now()\n\tfor {\n\t\treadyToSend := false\n\t\tselect {\n\t\tcase record, ok := &lt;-r.recordsChan:\n\t\t\t// check if channel was closed and it is time to exit from worker\n\t\t\tif !ok {\n\t\t\t\t// send what is left in buffer\n\t\t\t\tr.store.AppendToSetPipelined(analyticsKeyName, recordsBuffer)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\t// we have new record - prepare it and add to buffer\n\n\t\t\tif encoded, err := msgpack.Marshal(record); err != nil {\n\t\t\t\tlog.Errorf(\"Error encoding analytics data: %s\", err.Error())\n\t\t\t} else {\n\t\t\t\trecordsBuffer = append(recordsBuffer, encoded)\n\t\t\t}\n\n\t\t\t// identify that buffer is ready to be sent\n\t\t\treadyToSend = uint64(len(recordsBuffer)) == r.workerBufferSize\n\n\t\tcase &lt;-time.After(r.recordsBufferFlushInterval):\n\t\t\t// nothing was received for that period of time\n\t\t\t// anyways send whatever we have, don't hold data too long in buffer\n\t\t\treadyToSend = true\n\t\t}\n\n\t\t// send data to Redis and reset buffer\n\t\tif len(recordsBuffer) &gt; 0 &amp;&amp; (readyToSend || time.Since(lastSentTS) &gt;= recordsBufferForcedFlushInterval) {\n\t\t\tr.store.AppendToSetPipelined(analyticsKeyName, recordsBuffer)\n\t\t\trecordsBuffer = recordsBuffer[:0]\n\t\t\tlastSentTS = time.Now()\n\t\t}\n\t}\n}\n</code></pre><p>recordWorker 函数会将接收到的授权日志保存在 recordsBuffer 切片中，当数组内元素个数为 workerBufferSize ，或者距离上一次投递时间间隔为 recordsBufferFlushInterval 时，就会将 recordsBuffer 数组中的数据上报给目标系统（Input）。<br>\nrecordWorker()中有些设计技巧，很值得你参考。</p><ul>\n<li>使用 <a href=\"https://github.com/vmihailenco/msgpack\">msgpack</a> 序列化消息：msgpack 是一个高效的二进制序列化格式。它像 JSON 一样，让你可以在各种语言之间交换数据。但是它比 JSON 更快、更小。</li>\n<li>支持 Batch Windows：当 worker 的消息数达到指定阈值时，会批量投递消息给 Redis，阈值判断代码为<code>readyToSend = uint64(len(recordsBuffer)) == r.workerBufferSize</code>。</li>\n<li>超时投递：为了避免因为产生消息太慢，一直达不到 Batch Windows，无法投递消息这种情况，投递逻辑也支持超时投递，通过 <code>case &lt;-time.After(r.recordsBufferFlushInterval)</code>代码段实现。</li>\n<li>支持优雅关停：当 recordsChan 关闭时，将 recordsBuffer 中的消息批量投递给 Redis，之后退出 worker 协程。</li>\n</ul><p>这里有个注意事项：投递完成后，你需要重置 recordsBuffer 和计时器，否则会重复投递数据：</p><pre><code class=\"language-go\">recordsBuffer = recordsBuffer[:0]\nlastSentTS = time.Now()\n</code></pre><p>这里还设置了一个最大的超时时间 recordsBufferForcedFlushInterval，确保消息最迟被投递的时间间隔。也就是说， iam-authz-server 强制要求最大投递间隔为 recordsBufferForcedFlushInterval 秒，这是为了防止配置文件将 recordsBufferFlushInterval 设得过大。</p><h3>运行服务：异步上报授权日志</h3><p>开启了数据上报服务后，当有授权日志产生时，程序就会自动上报数据。接下来，我会详细介绍下如何高效上报数据。</p><p>iam-authz-server 会在授权成功时调用 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/authzserver/authorization/authorizer/authorizer.go#L100-L115\">LogGrantedAccessRequest</a> 函数，在授权失败时调用 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/authzserver/authorization/authorizer/authorizer.go#L71-L97\">LogRejectedAccessRequest</a> 函数。并且，在这两个函数中，调用 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/authzserver/analytics/analytics.go#L115-L126\">RecordHit </a>函数，记录授权日志。</p><p>iam-authz-server 通过调用 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/authzserver/analytics/analytics.go#L115-L126\">RecordHit(record *AnalyticsRecord) error</a> 函数，异步缓存授权日志。调用 RecordHit 后，会将 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/authzserver/analytics/analytics.go#L26-L35\">AnalyticsRecord</a> 类型的消息存放到 recordsChan 有缓冲 channel 中。</p><p>这里要注意：在缓存前，需要判断上报服务是否在优雅关停中，如果在关停中，则丢弃该消息：</p><pre><code class=\"language-go\">if atomic.LoadUint32(&amp;r.shouldStop) &gt; 0 {\n    return nil\n}\n</code></pre><p>通过将授权日志缓写入 recordsChan 有缓冲 channel 中，LogGrantedAccessRequest 和 LogRejectedAccessRequest 函数可以不用等待授权日志上报成功就返回，这样就使得整个授权请求的性能损耗几乎为零。</p><h3>关停服务：优雅关停数据上报</h3><p>完成数据上报之后的下一步，就是要优雅地将数据上报关停。为了确保在应用关停时，缓存中的数据和正在投递中的数据都能够投递到 Redis，iam-authz-server 实现了数据上报关停功能，代码如下：</p><pre><code class=\"language-go\">gs.AddShutdownCallback(shutdown.ShutdownFunc(func(string) error {\n    analyticsIns.Stop()\n    return nil\n}))\n</code></pre><p>当收到 os.Interrupt 和 syscall.SIGTERM 系统信号后，调用 analyticsIns.Stop()函数，关停数据上报服务， <a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/authzserver/analytics/analytics.go#L103-L112\">Stop</a> 函数会停止接收新的授权日志，并等待正在上报的数据上报完成。</p><p>上面我介绍了数据上报部分的功能设计，接下来，我来介绍下数据采集部分的功能设计。</p><h2>iam-pump：数据采集</h2><p>iam-authz-server 将数据上报到 Redis，iam-pump 消费 Redis 中的数据，并保存在 MongoDB 中做持久化存储。</p><p>iam-pump 的设计要点是：插件化、可配置地将 Redis 中的数据处理后存储到下游系统中，并且实现优雅关停功能，这些也是设计数据采集程序的要点和难点所在。下面，我们就来看下 iam-pump 是如何插件化地实现一个数据采集程序的。这个数据采集程序的设计思路，在我开发的大型企业应用中有实际的落地验证，你可以放心使用。</p><p>iam-pump 数据采集架构如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/91/ed/913b92d58cfd7cba0dff26612be9e9ed.jpg?wh=1920x1129\" alt=\"图片\"></p><p>在iam-pump服务启动时，要启动数据采集功能，启动代码见 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/pump/server.go#L58\">internal/pump/server.go</a>。</p><p>接下来，我会介绍下 iam-pump 服务中的 5 部分核心代码：</p><ul>\n<li>数据采集插件定义。</li>\n<li>初始化数据采集插件。</li>\n<li>健康检查。</li>\n<li>启动 Loop 周期性消费 Redis 数据。</li>\n<li>优雅关停数据采集服务。</li>\n</ul><h3>初始化服务：数据采集插件定义</h3><p>数据采集组件设计的核心是插件化，这里我<strong>将需要上报的系统抽象成一个个的 pump</strong>，那么如何定义 pump 接口呢？接口定义需要参考实际的采集需求，通常来说，至少需要下面这几个函数。</p><ul>\n<li><strong>New：</strong>创建一个 pump。</li>\n<li><strong>Init：</strong>初始化一个 pump，例如，可以在 Init 中创建下游系统的网络连接。</li>\n<li><strong>WriteData：</strong>往下游系统写入数据。为了提高性能，最好支持批量写入。</li>\n<li><strong>SetFilters：</strong>设置是否过滤某条数据，这也是一个非常常见的需求，因为不是所有的数据都是需要的。</li>\n<li><strong>SetTimeout：</strong>设置超时时间。我就在开发过程中遇到过一个坑，连接 Kafka 超时，导致整个采集程序超时。所以这里需要有超时处理，通过超时处理，可以保证整个采集框架正常运行。</li>\n</ul><p>我之前开发过公有云的网关服务，网关服务需要把网关的请求数据转存到 MongoDB 中。我们的网关服务曾经遇到一个比较大的坑：有些用户会通过网关上传非常大的文件（百 M 级别），这些数据转存到 MongoDB 中，快速消耗了 MongoDB 的存储空间（500G 存储空间）。为了避免这个问题，在转存数据时，需要过滤掉一些比较详细的数据，所以 iam-pump 添加了 SetOmitDetailedRecording 来过滤掉详细的数据。</p><p>所以，最后 iam-pump 的插件接口定义为 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/pump/pumps/pump.go#L15-L26\">internal/pump/pumps/pump.go</a> ：</p><pre><code class=\"language-go\">type Pump interface {\n\tGetName() string\n\tNew() Pump\n\tInit(interface{}) error\n\tWriteData(context.Context, []interface{}) error\n\tSetFilters(analytics.AnalyticsFilters)\n\tGetFilters() analytics.AnalyticsFilters\n\tSetTimeout(timeout int)\n\tGetTimeout() int\n\tSetOmitDetailedRecording(bool)\n\tGetOmitDetailedRecording() bool\n}\n</code></pre><p>你在实际开发中，如果有更多的需求，可以在 Pump interface 定义中继续添加需要的处理函数。</p><h3>初始化服务：初始化数据采集插件</h3><p>定义好插件之后，需要初始化插件。在 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/pump/server.go#L97-L124\">initialize</a> 函数中初始化 pumps：</p><pre><code class=\"language-go\">func (s *pumpServer) initialize() {\n\tpmps = make([]pumps.Pump, len(s.pumps))\n\ti := 0\n\tfor key, pmp := range s.pumps {\n\t\tpumpTypeName := pmp.Type\n\t\tif pumpTypeName == \"\" {\n\t\t\tpumpTypeName = key\n\t\t}\n\n\t\tpmpType, err := pumps.GetPumpByName(pumpTypeName)\n\t\tif err != nil {\n\t\t\tlog.Errorf(\"Pump load error (skipping): %s\", err.Error())\n\t\t} else {\n\t\t\tpmpIns := pmpType.New()\n\t\t\tinitErr := pmpIns.Init(pmp.Meta)\n\t\t\tif initErr != nil {\n\t\t\t\tlog.Errorf(\"Pump init error (skipping): %s\", initErr.Error())\n\t\t\t} else {\n\t\t\t\tlog.Infof(\"Init Pump: %s\", pmpIns.GetName())\n\t\t\t\tpmpIns.SetFilters(pmp.Filters)\n\t\t\t\tpmpIns.SetTimeout(pmp.Timeout)\n\t\t\t\tpmpIns.SetOmitDetailedRecording(pmp.OmitDetailedRecording)\n\t\t\t\tpmps[i] = pmpIns\n\t\t\t}\n\t\t}\n\t\ti++\n\t}\n}\n</code></pre><p>initialize 会创建、初始化，并调用 SetFilters、SetTimeout、SetOmitDetailedRecording 来设置这些 pump。Filters、Timeout、OmitDetailedRecording 等信息在 pump 的配置文件中指定。</p><p>这里有个技巧你也可以注意下：pump 配置文件支持通用的配置，也支持自定义的配置，配置结构为 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/pump/options/options.go#L18-L24\">PumpConfig</a> ：</p><pre><code class=\"language-go\">type PumpConfig struct {\n\tType                  string\n\tFilters               analytics.AnalyticsFilters\n\tTimeout               int\n\tOmitDetailedRecording bool\n\tMeta                  map[string]interface{}\n}\n</code></pre><p>pump 自定义的配置可以存放在 map 类型的变量 Meta 中。通用配置可以使配置共享，减少开发和维护工作量，自定义配置可以适配不同pump的差异化配置。</p><h3>初始化服务：健康检查</h3><p>因为 iam-pump 是一个非 API 服务，为了监控其运行状态，这里也设置了一个健康检查接口。iam-pump 组件通过调用 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/pump/server/server.go#L15-L25\">server.ServeHealthCheck</a> 函数启动一个 HTTP 服务，ServeHealthCheck 函数代码如下：</p><pre><code class=\"language-go\">func ServeHealthCheck(healthPath string, healthAddress string) {\n\thttp.HandleFunc(\"/\"+healthPath, func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(\"Content-type\", \"application/json\")\n\t\tw.WriteHeader(http.StatusOK)\n\t\t_, _ = w.Write([]byte(`{\"status\": \"ok\"}`))\n\t})\n\n\tif err := http.ListenAndServe(healthAddress, nil); err != nil {\n\t\tlog.Fatalf(\"Error serving health check endpoint: %s\", err.Error())\n\t}\n}\n</code></pre><p>该函数启动了一个 HTTP 服务，服务监听地址通过 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/configs/iam-pump.yaml#L7\">health-check-address</a> 配置，健康检查路径通过 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/configs/iam-pump.yaml#L6\">health-check-path</a> 配置。如果请求 <code>http://&lt;health-check-address&gt;/&lt;health-check-path&gt;</code>返回<code>{\"status\": \"ok\"}</code>，说明 iam-pump 可以正常工作。</p><p>这里的健康检查只是简单返回了一个字符串，实际开发中，可以封装更复杂的逻辑。比如，检查进程是否可以成功 ping 通数据库，进程内的工作进程是否处于 worker 状态等。</p><p>iam-pump 默认的健康检查请求地址为<code>http://127.0.0.1:7070/healthz</code> 。</p><h3>运行服务：启动 Loop 周期性消费 Redis 数据</h3><p>初始化 pumps 之后，就可以通过 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/pump/server.go#L58-L95\">Run</a> 函数启动消费逻辑了。在 Run 函数中，会定期（通过配置 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/configs/iam-pump.yaml#L5\">purge-delay</a> 设置轮训时间）从 Redis 中获取所有数据，经过 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/pump/server.go#L72\">msgpack.Unmarshal</a> 解压后，传给 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/pump/server.go#L126\">writeToPumps</a> 处理：</p><pre><code class=\"language-go\">func (s preparedPumpServer) Run(stopCh &lt;-chan struct{}) error {\n\tticker := time.NewTicker(time.Duration(s.secInterval) * time.Second)\n\tdefer ticker.Stop()\n\n\tfor {\n\t\tselect {\n\t\tcase &lt;-ticker.C:\n\t\t\tanalyticsValues := s.analyticsStore.GetAndDeleteSet(storage.AnalyticsKeyName)\n\t\t\tif len(analyticsValues) &gt; 0 {\n\t\t\t\t// Convert to something clean\n\t\t\t\tkeys := make([]interface{}, len(analyticsValues))\n\n\t\t\t\tfor i, v := range analyticsValues {\n\t\t\t\t\tdecoded := analytics.AnalyticsRecord{}\n\t\t\t\t\terr := msgpack.Unmarshal([]byte(v.(string)), &amp;decoded)\n\t\t\t\t\tlog.Debugf(\"Decoded Record: %v\", decoded)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tlog.Errorf(\"Couldn't unmarshal analytics data: %s\", err.Error())\n\t\t\t\t\t} else {\n\t\t\t\t\t\tif s.omitDetails {\n\t\t\t\t\t\t\tdecoded.Policies = \"\"\n\t\t\t\t\t\t\tdecoded.Deciders = \"\"\n\t\t\t\t\t\t}\n\t\t\t\t\t\tkeys[i] = interface{}(decoded)\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Send to pumps\n\t\t\t\twriteToPumps(keys, s.secInterval)\n\t\t\t}\n\t\t// exit consumption cycle when receive SIGINT and SIGTERM signal\n\t\tcase &lt;-stopCh:\n\t\t\tlog.Info(\"stop purge loop\")\n\n\t\t\treturn nil\n\t\t}\n\t}\n}\n</code></pre><p>writeToPumps 函数通过调用 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/pump/server.go#L165-L213\">execPumpWriting</a> 函数，异步调用 pump 的 WriteData 函数写入数据。execPumpWriting 函数中有一些设计技巧，你可以注意下这两个：</p><ul>\n<li>将一些通用的处理，例如 Filters、Timeout、OmitDetailedRecording 放在 pump 之外处理，这样可以减少 pump 中代码的重复性。</li>\n<li>优雅关停。通过如下代码实现优雅关停功能：</li>\n</ul><pre><code class=\"language-go\">select {\n    case &lt;-stopCh:\n        log.Info(\"stop purge loop\")\n        return\n    default:\n}\n</code></pre><p>上面的代码需要放在 writeToPumps 之后，这样可以确保所有数据都成功写入 pumps 之后，再停止采集逻辑。</p><h3>关停服务：优雅关停数据采集服务</h3><p>在关停服务时，为了确保正在处理的数据被成功存储，还需要提供优雅关停功能。iam-pump 通过 channel 传递 SIGINT 和 SIGTERM 信号，当消费逻辑收到这两个信号后，会退出消费循环，见 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/pump/server.go#L58\">Run</a> 函数。代码如下：</p><pre><code class=\"language-plain\">func (s preparedPumpServer) Run(stopCh &lt;-chan struct{}) error {&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; ticker := time.NewTicker(time.Duration(s.secInterval) * time.Second)&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; defer ticker.Stop()&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; for {&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; select {&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; case &lt;-ticker.C:&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// 消费逻辑\n         ...\n        // exit consumption cycle when receive SIGINT and SIGTERM signal\n&nbsp; &nbsp; &nbsp; &nbsp; case &lt;-stopCh:&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; log.Info(\"stop purge loop\")&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; return nil\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; }\n}\n\n</code></pre><h2>总结</h2><p>这一讲，我主要介绍了如何将数据采集需求转化成一个数据采集模型，并从这个模型出发，设计出一个可扩展、高性能的数据采集服务，并通过 iam-pump 组件来落地该采集模型。</p><p>最后，我还想给你一个建议：在开发中，你也可以将一些功能抽象成一些通用的模型，并为该模型实现基本框架（引擎），然后将一些需要定制化的部分插件化。通过这种方式，可以设计出一个高扩展的服务，使得服务不仅能够满足现在的需求，还能够满足未来的需求。</p><h2>课后练习</h2><ol>\n<li>思考下，如何设计一个数据上报和数据采集应用，设计时有哪些点需要注意？</li>\n<li>动手练习下，启动 iam-authz-server 和 iam-pump 服务，验证整个流程。</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"31 | 数据流：通过iam-authz-server设计，看数据流服务的设计","id":404542},"right":{"article_title":"33 |  SDK 设计（上）：如何设计出一个优秀的 Go SDK？","id":406389}}},{"article_id":406389,"article_title":"33 |  SDK 设计（上）：如何设计出一个优秀的 Go SDK？","article_content":"<p>你好，我是孔令飞。接下来的两讲，我们来看下如何设计和实现一个优秀的Go SDK。</p><p>后端服务通过API接口对外提供应用的功能，但是用户直接调用API接口，需要编写API接口调用的逻辑，并且需要构造入参和解析返回的数据包，使用起来效率低，而且有一定的开发工作量。</p><p>在实际的项目开发中，通常会提供对开发者更友好的SDK包，供客户端调用。很多大型服务在发布时都会伴随着SDK的发布，例如腾讯云很多产品都提供了SDK：</p><p><img src=\"https://static001.geekbang.org/resource/image/e1/fa/e1bb8eb03c2f26f546710e95751c17fa.png?wh=1920x747\" alt=\"图片\"></p><p>既然SDK如此重要，那么如何设计一个优秀的Go SDK呢？这一讲我就来详细介绍一下。</p><h2>什么是SDK？</h2><p>首先，我们来看下什么是SDK。</p><p>对于SDK（Software Development Kit，软件开发工具包），不同场景下有不同的解释。但是对于一个Go后端服务来说，SDK通常是指<strong>封装了Go后端服务API接口的软件包</strong>，里面通常包含了跟软件相关的库、文档、使用示例、封装好的API接口和工具。</p><p>调用SDK跟调用本地函数没有太大的区别，所以可以极大地提升开发者的开发效率和体验。SDK可以由服务提供者提供，也可以由其他组织或个人提供。为了鼓励开发者使用其系统或语言，SDK通常都是免费提供的。</p><p>通常，服务提供者会提供不同语言的SDK，比如针对Python开发者会提供Python版的SDK，针对Go开发者会提供Go版的SDK。一些比较专业的团队还会有SDK自动生成工具，可以根据API接口定义，自动生成不同语言的SDK。例如，Protocol Buffers的编译工具protoc，就可以基于Protobuf文件生成C++、Python、Java、JavaScript、PHP等语言版本的SDK。阿里云、腾讯云这些一线大厂，也可以基于API定义，生成不同编程语言的SDK。</p><!-- [[[read_end]]] --><h2>SDK设计方法</h2><p>那么，我们如何才能设计一个好的SDK呢？对于SDK，不同团队会有不同的设计方式，我调研了一些优秀SDK的实现，发现这些SDK有一些共同点。根据我的调研结果，结合我在实际开发中的经验，我总结出了一套SDK设计方法，接下来就分享给你。</p><h3>如何给SDK命名？</h3><p>在讲设计方法之前，我先来介绍两个重要的知识点：SDK的命名方式和SDK的目录结构。</p><p>SDK的名字目前没有统一的规范，但比较常见的命名方式是 <code>xxx-sdk-go</code> / <code>xxx-sdk-python</code> / <code>xxx-sdk-java</code> 。其中， <code>xxx</code> 可以是项目名或者组织名，例如腾讯云在GitHub上的组织名为tencentcloud，那它的SDK命名如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/e2/1e/e269d5d0e19a73d45ccdf5f5561c611e.png?wh=1210x863\" alt=\"图片\"></p><h3>SDK的目录结构</h3><p>不同项目SDK的目录结构也不相同，但一般需要包含下面这些文件或目录。目录名可能会有所不同，但目录功能是类似的。</p><ul>\n<li><strong>README.md</strong>：SDK的帮助文档，里面包含了安装、配置和使用SDK的方法。</li>\n<li><strong>examples/sample/</strong>：SDK的使用示例。</li>\n<li><strong>sdk/</strong>：SDK共享的包，里面封装了最基础的通信功能。如果是HTTP服务，基本都是基于 <code>net/http</code> 包进行封装。</li>\n<li><strong>api</strong>：如果 <code>xxx-sdk-go</code> 只是为某一个服务提供SDK，就可以把该服务的所有API接口封装代码存放在api目录下。</li>\n<li><strong>services/{iam, tms}</strong> ：如果 <code>xxx-sdk-go</code> 中， <code>xxx</code> 是一个组织，那么这个SDK很可能会集成该组织中很多服务的API，就可以把某类服务的API接口封装代码存放在 <code>services/&lt;服务名&gt;</code>下，例如AWS的<a href=\"https://github.com/aws/aws-sdk-go/tree/main/service\">Go SDK</a>。</li>\n</ul><p>一个典型的目录结构如下：</p><pre><code class=\"language-bash\">├── examples            # 示例代码存放目录\n│   └── authz.go\n├── README.md           # SDK使用文档\n├── sdk                 # 公共包，封装了SDK配置、API请求、认证等代码\n│   ├── client.go\n│   ├── config.go\n│   ├── credential.go\n│   └── ...\n└── services            # API封装\n    ├── common\n    │   └── model\n    ├── iam             # iam服务的API接口\n    │   ├── authz.go\n    │   ├── client.go\n    │   └── ...\n    └── tms             # tms服务的API接口\n</code></pre><h3>SDK设计方法</h3><p>SDK的设计方法如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/9f/ca/9fb7aa8d3da4210223e9b0c87943e8ca.jpg?wh=1920x841\" alt=\"图片\"></p><p>我们可以通过Config配置创建客户端Client，例如 <code>func NewClient(config sdk.Config) (Client, error)</code>，配置中可以指定下面的信息。</p><ul>\n<li>服务的后端地址：服务的后端地址可以通过配置文件来配置，也可以直接固化在SDK中，推荐后端服务地址可通过配置文件配置。</li>\n<li>认证信息：最常用的认证方式是通过密钥认证，也有一些是通过用户名和密码认证。</li>\n<li>其他配置：例如超时时间、重试次数、缓存时间等。</li>\n</ul><p>创建的Client是一个结构体或者Go interface。这里我建议你使用interface类型，这样可以将定义和具体实现解耦。Client具有一些方法，例如 CreateUser、DeleteUser等，每一个方法对应一个API接口，下面是一个Client定义：</p><pre><code class=\"language-go\">type Client struct {\n    client *sdk.Request\n}\n\nfunc (c *Client) CreateUser(req *CreateUserRequest) (*CreateUserResponse, error) {\n    // normal code\n    resp := &amp;CreateUserResponse{}\n    err := c.client.Send(req, resp)\n    return resp, err\n}\n</code></pre><p>调用 <code>client.CreateUser(req)</code> 会执行HTTP请求，在 <code>req</code> 中可以指定HTTP请求的方法Method、路径Path和请求Body。 <code>CreateUser</code> 函数中，会调用 <code>c.client.Send(req)</code> 执行具体的HTTP请求。</p><p><code>c.client</code> 是 <code>*Request</code> 类型的变量，  <code>*Request</code> 类型的变量具有一些方法，可以根据传入的请求参数 <code>req</code> 和 <code>config</code> 配置构造出请求路径、认证头和请求Body，并调用 <code>net/http</code> 包完成最终的HTTP请求，最后将返回结果Unmarshal到传入的 <code>resp</code> 结构体中。</p><p>根据我的调研，目前有两种SDK设计方式可供参考，一种是各大公有云厂商采用的SDK设计方式，一种是Kubernetes client-go的设计方式。IAM项目分别实现了这两种SDK设计方式，但我还是更倾向于对外提供client-go方式的SDK，我会在下一讲详细介绍它。这两种设计方式的设计思路跟上面介绍的是一致的。</p><h2>公有云厂商采用的SDK设计方式</h2><p>这里，我先来简单介绍下公有云厂商采用的SDK设计模式。SDK架构如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/82/ce/82ebe90b0490b9a2a76e2f302dd896ce.jpg?wh=1920x866\" alt=\"图片\"></p><p>SDK框架分为两层，分别是API层和基础层。API层主要用来构建客户端实例，并调用客户端实例提供的方法来完成API请求，每一个方法对应一个API接口。API层最终会调用基础层提供的能力，来完成REST API请求。基础层通过依次执行构建请求参数（Builder）、签发并添加认证头（Signer）、执行HTTP请求（Request）三大步骤，来完成具体的REST API请求。</p><p>为了让你更好地理解公有云SDK的设计方式，接下来我会结合一些真实的代码，给你讲解API层和基础层的具体设计，SDK代码见<a href=\"https://github.com/marmotedu/medu-sdk-go\">medu-sdk-go</a>。</p><h3>API层：创建客户端实例</h3><p>客户端在使用服务A的SDK时，首先需要根据Config配置创建一个服务A的客户端Client，Client实际上是一个struct，定义如下：</p><pre><code class=\"language-go\">type Client struct {\n    sdk.Client\n}\n</code></pre><p>在创建客户端时，需要传入认证（例如密钥、用户名/密码）、后端服务地址等配置信息。例如，可以通过<a href=\"https://github.com/marmotedu/medu-sdk-go/blob/v1.0.0/services/iam/authz/client.go#L24-L29\">NewClientWithSecret</a>方法来构建一个带密钥对的客户端：</p><pre><code class=\"language-go\">func NewClientWithSecret(secretID, secretKey string) (client *Client, err error) {\n    client = &amp;Client{}\n    config := sdk.NewConfig().WithEndpoint(defaultEndpoint)\n    client.Init(serviceName).WithSecret(secretID, secretKey).WithConfig(config)\n    return\n}\n</code></pre><p>这里要注意，上面创建客户端时，传入的密钥对最终会在基础层中被使用，用来签发JWT Token。</p><p>Client有多个方法（Sender），例如 Authz等，每个方法代表一个API接口。Sender方法会接收AuthzRequest等结构体类型的指针作为输入参数。我们可以调用 <code>client.Authz(req)</code> 来执行REST API调用。可以在 <code>client.Authz</code> 方法中添加一些业务逻辑处理。<code>client.Authz</code> 代码如下：</p><pre><code class=\"language-go\">type AuthzRequest struct {\n&nbsp; &nbsp; *request.BaseRequest\n&nbsp; &nbsp; Resource *string `json:\"resource\"`\n&nbsp; &nbsp; Action *string `json:\"action\"`\n&nbsp; &nbsp; Subject *string `json:\"subject\"`\n&nbsp; &nbsp; Context *ladon.Context\n}\n\nfunc (c *Client) Authz(req *AuthzRequest) (resp *AuthzResponse, err error) {\n&nbsp; &nbsp; if req == nil {\n&nbsp; &nbsp; &nbsp; &nbsp; req = NewAuthzRequest()\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; resp = NewAuthzResponse()\n&nbsp; &nbsp; err = c.Send(req, resp)\n&nbsp; &nbsp; return\n}\n</code></pre><p>请求结构体中的字段都是指针类型的，使用指针的好处是可以判断入参是否有被指定，如果<code>req.Subject == nil</code> 就说明传参中没有Subject参数，如果<code>req.Subject != nil</code>就说明参数中有传Subject参数。根据某个参数是否被传入，执行不同的业务逻辑，这在Go API接口开发中非常常见。</p><p>另外，因为Client通过匿名的方式继承了基础层中的<a href=\"https://github.com/marmotedu/medu-sdk-go/blob/v1.0.0/sdk/client.go#L18-L24\">Client</a>：</p><pre><code class=\"language-go\">type Client struct {\n\tsdk.Client\n}\n</code></pre><p>所以，API层创建的Client最终可以直接调用基础层中的Client提供的<code>Send(req, resp)</code> 方法，来执行RESTful API调用，并将结果保存在 <code>resp</code> 中。</p><p>为了方便和API层的Client进行区分，我下面统一将基础层中的Client称为<strong>sdk.Client</strong>。</p><p>最后，一个完整的客户端调用示例代码如下：</p><pre><code class=\"language-go\">package main\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/ory/ladon\"\n\n\t\"github.com/marmotedu/medu-sdk-go/sdk\"\n\tiam \"github.com/marmotedu/medu-sdk-go/services/iam/authz\"\n)\n\nfunc main() {\n\tclient, _ := iam.NewClientWithSecret(\"XhbY3aCrfjdYcP1OFJRu9xcno8JzSbUIvGE2\", \"bfJRvlFwsoW9L30DlG87BBW0arJamSeK\")\n\n\treq := iam.NewAuthzRequest()\n\treq.Resource = sdk.String(\"resources:articles:ladon-introduction\")\n\treq.Action = sdk.String(\"delete\")\n\treq.Subject = sdk.String(\"users:peter\")\n\tctx := ladon.Context(map[string]interface{}{\"remoteIPAddress\": \"192.168.0.5\"})\n\treq.Context = &amp;ctx\n\n\tresp, err := client.Authz(req)\n\tif err != nil {\n\t\tfmt.Println(\"err1\", err)\n\t\treturn\n\t}\n\tfmt.Printf(\"get response body: `%s`\\n\", resp.String())\n\tfmt.Printf(\"allowed: %v\\n\", resp.Allowed)\n}\n</code></pre><h3>基础层：构建并执行HTTP请求</h3><p>上面我们创建了客户端实例，并调用了它的 <a href=\"https://github.com/marmotedu/medu-sdk-go/blob/v1.0.0/sdk/client.go#L61-L93\">Send</a> 方法来完成最终的HTTP请求。这里，我们来看下Send方法具体是如何构建HTTP请求的。</p><p>sdk.Client通过Send方法，完成最终的API调用，代码如下：</p><pre><code class=\"language-go\">func (c *Client) Send(req request.Request, resp response.Response) error {\n\tmethod := req.GetMethod()\n\tbuilder := GetParameterBuilder(method, c.Logger)\n\tjsonReq, _ := json.Marshal(req)\n\tencodedUrl, err := builder.BuildURL(req.GetURL(), jsonReq)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tendPoint := c.Config.Endpoint\n\tif endPoint == \"\" {\n\t\tendPoint = fmt.Sprintf(\"%s/%s\", defaultEndpoint, c.ServiceName)\n\t}\n\treqUrl := fmt.Sprintf(\"%s://%s/%s%s\", c.Config.Scheme, endPoint, req.GetVersion(), encodedUrl)\n\n\tbody, err := builder.BuildBody(jsonReq)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tsign := func(r *http.Request) error {\n\t\tsigner := NewSigner(c.signMethod, c.Credential, c.Logger)\n\t\t_ = signer.Sign(c.ServiceName, r, strings.NewReader(body))\n\t\treturn err\n\t}\n\n\trawResponse, err := c.doSend(method, reqUrl, body, req.GetHeaders(), sign)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn response.ParseFromHttpResponse(rawResponse, resp)\n}\n</code></pre><p>上面的代码大体上可以分为四个步骤。</p><p><strong>第一步，Builder：构建请求参数。</strong></p><p>根据传入的AuthzRequest和客户端配置Config，构造HTTP请求参数，包括请求路径和请求Body。</p><p>接下来，我们来看下如何构造HTTP请求参数。</p><ol>\n<li>HTTP请求路径构建</li>\n</ol><p>在创建客户端时，我们通过<a href=\"https://github.com/marmotedu/medu-sdk-go/blob/v1.0.0/services/iam/authz/authz.go#L32-L42\">NewAuthzRequest</a>函数创建了 <code>/v1/authz</code> REST API接口请求结构体AuthzRequest，代码如下：</p><pre><code class=\"language-go\">func NewAuthzRequest() (req *AuthzRequest) {&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; req = &amp;AuthzRequest{&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; BaseRequest: &amp;request.BaseRequest{&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; URL:&nbsp; &nbsp; &nbsp;\"/authz\",&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Method:&nbsp; \"POST\",&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Header:&nbsp; nil,&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Version: \"v1\",&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; },&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; }&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; return&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n}\n</code></pre><p>可以看到，我们创建的 <code>req</code> 中包含了API版本（Version）、API路径（URL）和请求方法（Method）。这样，我们就可以在Send方法中，构建出请求路径：</p><pre><code class=\"language-go\">endPoint := c.Config.Endpoint&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\nif endPoint == \"\" {&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; endPoint = fmt.Sprintf(\"%s/%s\", defaultEndpoint, c.ServiceName)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n}&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\nreqUrl := fmt.Sprintf(\"%s://%s/%s%s\", c.Config.Scheme, endPoint, req.GetVersion(), encodedUrl)&nbsp;\n</code></pre><p>上述代码中，c.Config.Scheme=http/https、endPoint=iam.api.marmotedu.com:8080、req.GetVersion()=v1和encodedUrl，我们可以认为它们等于/authz。所以，最终构建出的请求路径为<code>http://iam.api.marmotedu.com:8080/v1/authz</code> 。</p><ol start=\"2\">\n<li>HTTP请求Body构建</li>\n</ol><p>在<a href=\"https://github.com/marmotedu/medu-sdk-go/blob/v1.0.0/sdk/parameter_builder.go#L68-L86\">BuildBody</a>方法中构建请求Body。BuildBody会将 <code>req</code> Marshal成JSON格式的string。HTTP请求会以该字符串作为Body参数。</p><p><strong>第二步，Signer：签发并添加认证头。</strong></p><p>访问IAM的API接口需要进行认证，所以在发送HTTP请求之前，还需要给HTTP请求添加认证Header。</p><p>medu-sdk-go 代码提供了JWT和HMAC两种认证方式，最终采用了JWT认证方式。JWT认证签发方法为<a href=\"https://github.com/marmotedu/medu-sdk-go/blob/v1.0.0/sdk/signer.go#L108-L113\">Sign</a>，代码如下：</p><pre><code class=\"language-go\">func (v1 SignatureV1) Sign(serviceName string, r *http.Request, body io.ReadSeeker) http.Header {\n\ttokenString := auth.Sign(v1.Credentials.SecretID, v1.Credentials.SecretKey, \"medu-sdk-go\", serviceName+\".marmotedu.com\")\n\tr.Header.Set(\"Authorization\", fmt.Sprintf(\"Bearer %s\", tokenString))\n\treturn r.Header\n\n}\n</code></pre><p><code>auth.Sign</code> 方法根据SecretID和SecretKey签发JWT Token。</p><p>接下来，我们就可以调用<a href=\"https://github.com/marmotedu/medu-sdk-go/blob/v1.0.0/sdk/client.go#L95-L112\">doSend</a>方法来执行HTTP请求了。调用代码如下：</p><pre><code class=\"language-go\">rawResponse, err := c.doSend(method, reqUrl, body, req.GetHeaders(), sign)\nif err != nil {&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; return err&nbsp; &nbsp; &nbsp;\n}&nbsp;\n</code></pre><p>可以看到，我们传入了HTTP请求方法 <code>method</code> 、HTTP请求URL  <code>reqUrl</code> 、HTTP请求Body  <code>body</code>，以及用来签发JWT Token的 <code>sign</code> 方法。我们在调用 <code>NewAuthzRequest</code> 创建 <code>req</code> 时，指定了HTTP Method，所以这里的 <code>method := req.GetMethod()</code> 、reqUrl和请求Body都是通过Builder来构建的。</p><p><strong>第三步，Request：执行H<strong><strong>T</strong></strong>T<strong><strong>P</strong></strong>请求。</strong></p><p>调用<a href=\"https://github.com/marmotedu/medu-sdk-go/blob/v1.0.0/sdk/client.go#L95-L112\">doSend</a>方法执行HTTP请求，doSend通过调用 <code>net/http</code> 包提供的 <code>http.NewRequest</code> 方法来发送HTTP请求，执行完HTTP请求后，会返回 <code>*http.Response</code> 类型的Response。代码如下：</p><pre><code class=\"language-go\">func (c *Client) doSend(method, url, data string, header map[string]string, sign SignFunc) (*http.Response, error) {\n&nbsp; &nbsp; client := &amp;http.Client{Timeout: c.Config.Timeout}\n\n&nbsp; &nbsp; req, err := http.NewRequest(method, url, strings.NewReader(data))\n&nbsp; &nbsp; if err != nil {\n&nbsp; &nbsp; &nbsp; &nbsp; c.Logger.Errorf(\"%s\", err.Error())\n&nbsp; &nbsp; &nbsp; &nbsp; return nil, err\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; c.setHeader(req, header)\n\n&nbsp; &nbsp; err = sign(req)\n&nbsp; &nbsp; if err != nil {\n&nbsp; &nbsp; &nbsp; &nbsp; return nil, err\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; return client.Do(req)\n}\n</code></pre><p><strong>第四步，处理H<strong><strong>TT</strong></strong>P<strong><strong>请求</strong></strong>返回结果。</strong></p><p>调用doSend方法返回 <code>*http.Response</code> 类型的Response后，Send方法会调用<a href=\"https://github.com/marmotedu/medu-sdk-go/blob/v1.0.0/sdk/response/response.go#L37-L52\">ParseFromHttpResponse</a>函数来处理HTTP Response，ParseFromHttpResponse函数代码如下：</p><pre><code class=\"language-go\">func ParseFromHttpResponse(rawResponse *http.Response, response Response) error {\n\tdefer rawResponse.Body.Close()\n\tbody, err := ioutil.ReadAll(rawResponse.Body)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif rawResponse.StatusCode != 200 {\n\t\treturn fmt.Errorf(\"request fail with status: %s, with body: %s\", rawResponse.Status, body)\n\t}\n\n\tif err := response.ParseErrorFromHTTPResponse(body); err != nil {\n\t\treturn err\n\t}\n\n\treturn json.Unmarshal(body, &amp;response)\n}\n</code></pre><p>可以看到，在ParseFromHttpResponse函数中，会先判断HTTP Response中的StatusCode是否为200，如果不是200，则会报错。如果是200，会调用传入的resp变量提供的<a href=\"https://github.com/marmotedu/medu-sdk-go/blob/v1.0.0/sdk/response/response.go#L26-L35\">ParseErrorFromHTTPResponse</a>方法，来将HTTP Response的Body Unmarshal到resp变量中。<br>\n通过以上四步，SDK调用方调用了API，并获得了API的返回结果 <code>resp</code> 。</p><p>下面这些公有云厂商的SDK采用了此设计模式：</p><ul>\n<li>腾讯云SDK：<a href=\"https://github.com/TencentCloud/tencentcloud-sdk-go\">tencentcloud-sdk-go</a>。</li>\n<li>AWS SDK：<a href=\"https://github.com/aws/aws-sdk-go\">aws-sdk-go</a>。</li>\n<li>阿里云SDK：<a href=\"https://github.com/aliyun/alibaba-cloud-sdk-go\">alibaba-cloud-sdk-go</a>。</li>\n<li>京东云SDK：<a href=\"https://github.com/jdcloud-api/jdcloud-sdk-go\">jdcloud-sdk-go</a>。</li>\n<li>Ucloud SDK：<a href=\"https://github.com/ucloud/ucloud-sdk-go\">ucloud-sdk-go</a>。</li>\n</ul><p>IAM公有云方式的SDK实现为 <a href=\"https://github.com/marmotedu/medu-sdk-go\">medu-sdk-go</a>。</p><p>此外，IAM还设计并实现了Kubernetes client-go方式的Go SDK：<a href=\"https://github.com/marmotedu/marmotedu-sdk-go\">marmotedu-sdk-go</a>，marmotedu-sdk-go也是IAM Go SDK所采用的SDK。下一讲中，我会具体介绍marmotedu-sdk-go的设计和实现。</p><h2>总结</h2><p>这一讲，我主要介绍了如何设计一个优秀的Go SDK。通过提供SDK，可以提高API调用效率，减少API调用难度，所以大型应用通常都会提供SDK。不同团队有不同的SDK设计方法，但目前比较好的实现是公有云厂商采用的SDK设计方式。</p><p>公有云厂商的SDK设计方式中，SDK按调用顺序从上到下可以分为3个模块，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/b9/a9/b9bd3020ae56f6bb49bc3a38bcaf64a9.jpg?wh=1920x878\" alt=\"图片\"></p><p>Client构造SDK客户端，在构造客户端时，会创建请求参数 <code>req</code> ， <code>req</code> 中会指定API版本、HTTP请求方法、API请求路径等信息。</p><p>Client会请求Builder和Signer来构建HTTP请求的各项参数：HTTP请求方法、HTTP请求路径、HTTP认证头、HTTP请求Body。Builder和Signer是根据 <code>req</code> 配置来构造这些HTTP请求参数的。</p><p>构造完成之后，会请求Request模块，Request模块通过调用 <code>net/http</code> 包，来执行HTTP请求，并返回请求结果。</p><h2>课后练习</h2><ol>\n<li>思考下，如何实现可以支持多个API版本的SDK包，代码如何实现？</li>\n<li>这一讲介绍了一种SDK实现方式，在你的Go开发生涯中，还有没有一些更好的SDK实现方法？欢迎在留言区分享。</li>\n</ol><p>期待你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"32 | 数据处理：如何高效处理应用程序产生的数据？","id":405524},"right":{"article_title":"34 | SDK 设计（下）：IAM项目Go SDK设计和实现","id":407186}}},{"article_id":407186,"article_title":"34 | SDK 设计（下）：IAM项目Go SDK设计和实现","article_content":"<p>你好，我是孔令飞。</p><p>上一讲，我介绍了公有云厂商普遍采用的SDK设计方式。其实，还有一些比较优秀的SDK设计方式，比如 Kubernetes的 <a href=\"https://github.com/kubernetes/client-go\">client-go</a> SDK设计方式。IAM项目参考client-go，也实现了client-go风格的SDK：<a href=\"https://github.com/marmotedu/marmotedu-sdk-go\">marmotedu-sdk-go</a>。</p><p>和 <a href=\"https://time.geekbang.org/column/article/406389\">33讲</a> 介绍的SDK设计方式相比，client-go风格的SDK具有以下优点：</p><ul>\n<li>大量使用了Go interface特性，将接口的定义和实现解耦，可以支持多种实现方式。</li>\n<li>接口调用层级跟资源的层级相匹配，调用方式更加友好。</li>\n<li>多版本共存。</li>\n</ul><p>所以，我更推荐你使用marmotedu-sdk-go。接下来，我们就来看下marmotedu-sdk-go是如何设计和实现的。</p><h2>marmotedu-sdk-go设计</h2><p>和medu-sdk-go相比，marmotedu-sdk-go的设计和实现要复杂一些，但功能更强大，使用体验也更好。</p><p>这里，我们先来看一个使用SDK调用iam-authz-server  <code>/v1/authz</code> 接口的示例，代码保存在<a href=\"https://github.com/marmotedu/marmotedu-sdk-go/blob/v1.0.3/examples/authz_clientset/main.go\"> marmotedu-sdk-go/examples/authz_clientset/main.go</a>文件中：</p><pre><code class=\"language-go\">package main\n\nimport (\n\t\"context\"\n\t\"flag\"\n\t\"fmt\"\n\t\"path/filepath\"\n\n\t\"github.com/ory/ladon\"\n\n\tmetav1 \"github.com/marmotedu/component-base/pkg/meta/v1\"\n\t\"github.com/marmotedu/component-base/pkg/util/homedir\"\n\n\t\"github.com/marmotedu/marmotedu-sdk-go/marmotedu\"\n\t\"github.com/marmotedu/marmotedu-sdk-go/tools/clientcmd\"\n)\n\nfunc main() {\n\tvar iamconfig *string\n\tif home := homedir.HomeDir(); home != \"\" {\n\t\tiamconfig = flag.String(\n\t\t\t\"iamconfig\",\n\t\t\tfilepath.Join(home, \".iam\", \"config\"),\n\t\t\t\"(optional) absolute path to the iamconfig file\",\n\t\t)\n\t} else {\n\t\tiamconfig = flag.String(\"iamconfig\", \"\", \"absolute path to the iamconfig file\")\n\t}\n\tflag.Parse()\n\n\t// use the current context in iamconfig\n\tconfig, err := clientcmd.BuildConfigFromFlags(\"\", *iamconfig)\n\tif err != nil {\n\t\tpanic(err.Error())\n\t}\n\n\t// create the clientset\n\tclientset, err := marmotedu.NewForConfig(config)\n\tif err != nil {\n\t\tpanic(err.Error())\n\t}\n\n\trequest := &amp;ladon.Request{\n\t\tResource: \"resources:articles:ladon-introduction\",\n\t\tAction:&nbsp; &nbsp;\"delete\",\n\t\tSubject:&nbsp; \"users:peter\",\n\t\tContext: ladon.Context{\n\t\t\t\"remoteIP\": \"192.168.0.5\",\n\t\t},\n\t}\n\n\t// Authorize the request\n\tfmt.Println(\"Authorize request...\")\n\tret, err := clientset.Iam().AuthzV1().Authz().Authorize(context.TODO(), request, metav1.AuthorizeOptions{})\n\tif err != nil {\n\t\tpanic(err.Error())\n\t}\n\n\tfmt.Printf(\"Authorize response: %s.\\n\", ret.ToString())\n}\n</code></pre><!-- [[[read_end]]] --><p>在上面的代码示例中，包含了下面的操作。</p><ul>\n<li>首先，调用 <code>BuildConfigFromFlags</code> 函数，创建出SDK的配置实例config；</li>\n<li>接着，调用 <code>marmotedu.NewForConfig(config)</code> 创建了IAM项目的客户端 <code>clientset</code> ;</li>\n<li>最后，调用以下代码请求 <code>/v1/authz</code> 接口执行资源授权请求：</li>\n</ul><pre><code class=\"language-go\">ret, err := clientset.Iam().AuthzV1().Authz().Authorize(context.TODO(), request, metav1.AuthorizeOptions{})&nbsp; &nbsp;&nbsp;\nif err != nil {&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n    panic(err.Error())&nbsp; &nbsp;&nbsp;\n}&nbsp; &nbsp;&nbsp;\n\nfmt.Printf(\"Authorize response: %s.\\n\", ret.ToString())\n</code></pre><p>调用格式为<code>项目客户端.应用客户端.服务客户端.资源名.接口</code> 。</p><p>所以，上面的代码通过创建项目级别的客户端、应用级别的客户端和服务级别的客户端，来调用资源的API接口。接下来，我们来看下如何创建这些客户端。</p><h3>marmotedu-sdk-go客户端设计</h3><p>在讲客户端创建之前，我们先来看下客户端的设计思路。</p><p>Go项目的组织方式是有层级的：<strong>Project -&gt; Application -&gt; Service</strong>。marmotedu-sdk-go很好地体现了这种层级关系，使得SDK的调用更加易懂、易用。marmotedu-sdk-go的层级关系如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/3a/21/3a4721afa7fe365c0954019087d82021.jpg?wh=2248x1043\" alt=\"\"></p><p>marmotedu-sdk-go定义了3类接口，分别代表了项目、应用和服务级别的API接口：</p><pre><code class=\"language-go\">// 项目级别的接口\ntype Interface interface {\n    Iam() iam.IamInterface\n    Tms() tms.TmsInterface\n}\n\n// 应用级别的接口\ntype IamInterface interface {\n    APIV1() apiv1.APIV1Interface\n    AuthzV1() authzv1.AuthzV1Interface\n}\n\n// 服务级别的接口\ntype APIV1Interface interface {\n    RESTClient() rest.Interface\n    SecretsGetter\n    UsersGetter\n    PoliciesGetter\n}\n\n// 资源级别的客户端\ntype SecretsGetter interface {\n    Secrets() SecretInterface\n}\n\n// 资源的接口定义\ntype SecretInterface interface {\n    Create(ctx context.Context, secret *v1.Secret, opts metav1.CreateOptions) (*v1.Secret, error)\n    Update(ctx context.Context, secret *v1.Secret, opts metav1.UpdateOptions) (*v1.Secret, error)\n    Delete(ctx context.Context, name string, opts metav1.DeleteOptions) error\n    DeleteCollection(ctx context.Context, opts metav1.DeleteOptions, listOpts metav1.ListOptions) error\n    Get(ctx context.Context, name string, opts metav1.GetOptions) (*v1.Secret, error)\n    List(ctx context.Context, opts metav1.ListOptions) (*v1.SecretList, error)\n    SecretExpansion\n}\n</code></pre><p><code>Interface</code> 代表了项目级别的接口，里面包含了 <code>Iam</code> 和 <code>Tms</code>  两个应用； <code>IamInterface</code> 代表了应用级别的接口，里面包含了api（iam-apiserver）和authz（iam-authz-server）两个服务级别的接口。api和authz服务中，又包含了各自服务中REST资源的CURD接口。</p><p>marmotedu-sdk-go通过 <code>XxxV1</code> 这种命名方式来支持不同版本的API接口，好处是可以在程序中同时调用同一个API接口的不同版本，例如：</p><p><code>clientset.Iam().AuthzV1().Authz().Authorize()</code>  、<code>clientset.Iam().AuthzV2().Authz().Authorize()</code> 分别调用了 <code>/v1/authz</code> 和 <code>/v2/authz</code>  两个版本的API接口。</p><p>上述关系也可以从目录结构中反映出来，marmotedu-sdk-go目录设计如下（只列出了一些重要的文件）：</p><pre><code class=\"language-bash\">├── examples                        # 存放SDK的使用示例\n├── Makefile                        # 管理SDK源码，静态代码检查、代码格式化、测试、添加版权信息等\n├── marmotedu\n│   ├── clientset.go                # clientset实现，clientset中包含多个应用，多个服务的API接口\n│   ├── fake                        # clientset的fake实现，主要用于单元测试\n│   └── service                     # 按应用进行分类，存放应用中各服务API接口的具体实现\n│       ├── iam                     # iam应用的API接口实现，包含多个服务\n│       │   ├── apiserver           # iam应用中，apiserver服务的API接口，包含多个版本\n│       │   │   └── v1              # apiserver v1版本API接口\n│       │   ├── authz               # iam应用中，authz服务的API接口\n│       │   │   └── v1              # authz服务v1版本接口\n│       │   └── iam_client.go       # iam应用的客户端，包含了apiserver和authz 2个服务的客户端\n│       └── tms                     # tms应用的API接口实现\n├── pkg                             # 存放一些共享包，可对外暴露\n├── rest                            # HTTP请求的底层实现\n├── third_party                     # 存放修改过的第三方包，例如：gorequest\n└── tools\n    └── clientcmd                   # 一些函数用来帮助创建rest.Config配置\n</code></pre><p>每种类型的客户端，都可以通过以下相似的方式来创建：</p><pre><code class=\"language-go\">config, err := clientcmd.BuildConfigFromFlags(\"\", \"/root/.iam/config\")\nclientset, err := xxxx.NewForConfig(config)\n</code></pre><p><code>/root/.iam/config</code> 为配置文件，里面包含了服务的地址和认证信息。<code>BuildConfigFromFlags</code> 函数加载配置文件，创建并返回 <code>rest.Config</code> 类型的配置变量，并通过 <code>xxxx.NewForConfig</code> 函数创建需要的客户端。<code>xxxx</code> 是所在层级的client包，例如 iam、tms。</p><p>marmotedu-sdk-go客户端定义了3类接口，这可以带来两个好处。</p><p>第一，API接口调用格式规范，层次清晰，可以使API接口调用更加清晰易记。</p><p>第二，可以根据需要，自行选择客户端类型，调用灵活。举个例子，在A服务中需要同时用到iam-apiserver 和 iam-authz-server提供的接口，就可以创建应用级别的客户端IamClient，然后通过 <code>iamclient.APIV1()</code> 和 <code>iamclient.AuthzV1()</code> ，来切换调用不同服务的API接口。</p><p>接下来，我们来看看如何创建三个不同级别的客户端。</p><h3>项目级别客户端创建</h3><p><code>Interface</code> 对应的客户端实现为<a href=\"https://github.com/marmotedu/marmotedu-sdk-go/blob/v1.0.2/marmotedu/clientset.go#L20-L23\">Clientset</a>，所在的包为 <a href=\"https://github.com/marmotedu/marmotedu-sdk-go/tree/v1.0.2/marmotedu\">marmotedu-sdk-go/marmotedu</a>，Clientset客户端的创建方式为：</p><pre><code class=\"language-go\">config, err := clientcmd.BuildConfigFromFlags(\"\", \"/root/.iam/config\")\nclientset, err := marmotedu.NewForConfig(config)\n</code></pre><p>调用方式为 <code>clientset.应用.服务.资源名.接口</code> ，例如：</p><pre><code class=\"language-go\">rsp, err := clientset.Iam().AuthzV1().Authz().Authorize()\n</code></pre><p>参考示例为 <a href=\"https://github.com/marmotedu/marmotedu-sdk-go/blob/v1.0.3/examples/authz_clientset/main.go\">marmotedu-sdk-go/examples/authz_clientset/main.go</a>。</p><h3>应用级别客户端创建</h3><p><code>IamInterface</code> 对应的客户端实现为<a href=\"https://github.com/marmotedu/marmotedu-sdk-go/blob/v1.0.2/marmotedu/service/iam/iam_client.go#L22-L25\">IamClient</a>，所在的包为 <a href=\"https://github.com/marmotedu/marmotedu-sdk-go/tree/v1.0.2/marmotedu/service/iam\">marmotedu-sdk-go/marmotedu/service/iam</a>，IamClient客户端的创建方式为：</p><pre><code class=\"language-go\">config, err := clientcmd.BuildConfigFromFlags(\"\", \"/root/.iam/config\")\niamclient,, err := iam.NewForConfig(config)\n</code></pre><p>调用方式为 <code>iamclient.服务.资源名.接口</code> ，例如：</p><pre><code class=\"language-go\">rsp, err := iamclient.AuthzV1().Authz().Authorize()\n</code></pre><p>参考示例为 <a href=\"https://github.com/marmotedu/marmotedu-sdk-go/blob/v1.0.2/examples/authz_iam/main.go\">marmotedu-sdk-go/examples/authz_iam/main.go</a>。</p><h3>服务级别客户端创建</h3><p><code>AuthzV1Interface</code> 对应的客户端实现为<a href=\"https://github.com/marmotedu/marmotedu-sdk-go/blob/v1.0.2/marmotedu/service/iam/authz/v1/authz_client.go#L21-L23\">AuthzV1Client</a>，所在的包为 <a href=\"https://github.com/marmotedu/marmotedu-sdk-go/tree/v1.0.2/marmotedu/service/iam/authz/v1\">marmotedu-sdk-go/marmotedu/service/iam/authz/v1</a>，AuthzV1Client客户端的创建方式为：</p><pre><code class=\"language-go\">config, err := clientcmd.BuildConfigFromFlags(\"\", \"/root/.iam/config\")\nclient, err := v1.NewForConfig(config)\n</code></pre><p>调用方式为 <code>client.资源名.接口</code> ，例如：</p><pre><code class=\"language-go\">rsp, err := client.Authz().Authorize()\n</code></pre><p>参考示例为 <a href=\"https://github.com/marmotedu/marmotedu-sdk-go/blob/v1.0.3/examples/authz/main.go\">marmotedu-sdk-go/examples/authz/main.go</a>。</p><p>上面我介绍了marmotedu-sdk-go的客户端创建方法，接下来我们再来看下，这些客户端具体是如何执行REST API请求的。</p><h2>marmotedu-sdk-go的实现</h2><p>marmotedu-sdk-go的实现和medu-sdk-go一样，也是采用分层结构，分为API层和基础层。如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/c4/b2/c40439c97998a01758923394116c33b2.jpg?wh=2248x2097\" alt=\"\"></p><p><a href=\"https://github.com/marmotedu/marmotedu-sdk-go/blob/v1.0.2/rest/client.go#L95-L105\">RESTClient</a>是整个SDK的核心，RESTClient向下通过调用<a href=\"https://github.com/marmotedu/marmotedu-sdk-go/blob/v1.0.2/rest/request.go#L28-L50\">Request</a>模块，来完成HTTP请求方法、请求路径、请求体、认证信息的构建。Request模块最终通过调用<a href=\"https://github.com/parnurzeal/gorequest\">gorequest</a>包提供的方法，完成HTTP的POST、PUT、GET、DELETE等请求，获取HTTP返回结果，并解析到指定的结构体中。RESTClient向上提供 <code>Post()</code> 、 <code>Put()</code> 、 <code>Get()</code> 、 <code>Delete()</code> 等方法来供客户端完成HTTP请求。</p><p>marmotedu-sdk-go提供了两类客户端，分别是RESTClient客户端和基于RESTClient封装的客户端。</p><ul>\n<li>RESTClient：Raw类型的客户端，可以通过指定HTTP的请求方法、请求路径、请求参数等信息，直接发送HTTP请求，例如 <code>client.Get().AbsPath(\"/version\").Do().Into()</code> 。</li>\n<li>基于RESTClient封装的客户端：例如AuthzV1Client、APIV1Client等，执行特定REST资源、特定API接口的请求，方便开发者调用。</li>\n</ul><p>接下来，我们具体看下如何创建RESTClient客户端，以及Request模块的实现。</p><h3>RESTClient客户端实现</h3><p>我通过下面两个步骤，实现了RESTClient客户端。</p><p><strong>第一步，创建</strong><a href=\"https://github.com/marmotedu/marmotedu-sdk-go/blob/v1.0.2/rest/config.go#L29-L60\">rest.Config</a><strong>类型的变量。</strong></p><p><a href=\"https://github.com/marmotedu/marmotedu-sdk-go/blob/v1.0.2/tools/clientcmd/client_config.go#L190-L203\">BuildConfigFromFlags</a>函数通过加载yaml格式的配置文件，来创建 <code>rest.Config</code> 类型的变量，加载的yaml格式配置文件内容为：</p><pre><code class=\"language-yaml\">apiVersion: v1\nuser:\n  #token: # JWT Token\n  username: admin # iam 用户名\n  password: Admin@2020 # iam 密码\n  #secret-id: # 密钥 ID\n  #secret-key: # 密钥 Key\n  client-certificate: /home/colin/.iam/cert/admin.pem # 用于 TLS 的客户端证书文件路径\n  client-key: /home/colin/.iam/cert/admin-key.pem # 用于 TLS 的客户端 key 文件路径\n  #client-certificate-data:\n  #client-key-data:\n\nserver:\n  address: https://127.0.0.1:8443 # iam api-server 地址\n  timeout: 10s # 请求 api-server 超时时间\n  #max-retries: # 最大重试次数，默认为 0\n  #retry-interval: # 重试间隔，默认为 1s\n  #tls-server-name: # TLS 服务器名称\n  #insecure-skip-tls-verify: # 设置为 true 表示跳过 TLS 安全验证模式，将使得 HTTPS 连接不安全\n  certificate-authority: /home/colin/.iam/cert/ca.pem # 用于 CA 授权的 cert 文件路径\n  #certificate-authority-data:\n</code></pre><p>在配置文件中，我们可以指定服务的地址、用户名/密码、密钥、TLS证书、超时时间、重试次数等信息。</p><p>创建方法如下：</p><pre><code class=\"language-go\">config, err := clientcmd.BuildConfigFromFlags(\"\", *iamconfig)&nbsp; &nbsp;&nbsp;\nif err != nil {&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; panic(err.Error())&nbsp; &nbsp;&nbsp;\n}&nbsp;&nbsp;\n</code></pre><p>这里的代码中，<code>*iamconfig</code> 是yaml格式的配置文件路径。<code>BuildConfigFromFlags</code> 函数中，调用<a href=\"https://github.com/marmotedu/marmotedu-sdk-go/blob/v1.0.3/tools/clientcmd/loader.go#L32-L56\">LoadFromFile</a>函数来解析yaml配置文件。LoadFromFile最终是通过 <code>yaml.Unmarshal</code> 的方式来解析yaml格式的配置文件的。</p><p><strong>第二步，根据rest.Config类型的变量，创建RESTClient客户端。</strong></p><p>通过<a href=\"https://github.com/marmotedu/marmotedu-sdk-go/blob/v1.0.2/rest/config.go#L191-L237\">RESTClientFor</a>函数来创建RESTClient客户端：</p><pre><code class=\"language-go\">func RESTClientFor(config *Config) (*RESTClient, error) {\n    ...\n    baseURL, versionedAPIPath, err := defaultServerURLFor(config)\n    if err != nil {\n        return nil, err\n    }\n\n    // Get the TLS options for this client config\n    tlsConfig, err := TLSConfigFor(config)\n    if err != nil {\n        return nil, err\n    }\n\n    // Only retry when get a server side error.\n    client := gorequest.New().TLSClientConfig(tlsConfig).Timeout(config.Timeout).\n        Retry(config.MaxRetries, config.RetryInterval, http.StatusInternalServerError)\n    // NOTICE: must set DoNotClearSuperAgent to true, or the client will clean header befor http.Do\n    client.DoNotClearSuperAgent = true\n\n    ...\n\n    clientContent := ClientContentConfig{\n        Username:           config.Username,\n        Password:           config.Password,\n        SecretID:           config.SecretID,\n        SecretKey:          config.SecretKey,\n        ...\n    }\n\n    return NewRESTClient(baseURL, versionedAPIPath, clientContent, client)\n}\n</code></pre><p>RESTClientFor函数调用<a href=\"https://github.com/marmotedu/marmotedu-sdk-go/blob/v1.0.2/rest/url_utils.go#L69-L81\">defaultServerURLFor(config)</a>生成基本的HTTP请求路径：baseURL=http://127.0.0.1:8080，versionedAPIPath=/v1。然后，通过<a href=\"https://github.com/marmotedu/marmotedu-sdk-go/blob/v1.0.2/rest/config.go#L241-L298\">TLSConfigFor</a>函数生成TLS配置，并调用 <code>gorequest.New()</code> 创建gorequest客户端，将客户端配置信息保存在变量中。最后，调用<a href=\"https://github.com/marmotedu/marmotedu-sdk-go/blob/v1.0.2/rest/client.go#L109-L130\">NewRESTClient</a>函数创建RESTClient客户端。</p><p>RESTClient客户端提供了以下方法，来供调用者完成HTTP请求：</p><pre><code class=\"language-go\">func (c *RESTClient) APIVersion() scheme.GroupVersion\nfunc (c *RESTClient) Delete() *Request\nfunc (c *RESTClient) Get() *Request\nfunc (c *RESTClient) Post() *Request\nfunc (c *RESTClient) Put() *Request\nfunc (c *RESTClient) Verb(verb string) *Request\n</code></pre><p>可以看到，RESTClient提供了 <code>Delete</code> 、 <code>Get</code> 、 <code>Post</code> 、 <code>Put</code> 方法，分别用来执行HTTP的DELETE、GET、POST、PUT方法，提供的 <code>Verb</code> 方法可以灵活地指定HTTP方法。这些方法都返回了 <code>Request</code> 类型的变量。<code>Request</code> 类型的变量提供了一些方法，用来完成具体的HTTP请求，例如：</p><pre><code class=\"language-go\">  type Response struct {\n&nbsp; &nbsp; Allowed bool&nbsp; &nbsp;`json:\"allowed\"`\n&nbsp; &nbsp; Denied&nbsp; bool&nbsp; &nbsp;`json:\"denied,omitempty\"`\n&nbsp; &nbsp; Reason&nbsp; string `json:\"reason,omitempty\"`\n&nbsp; &nbsp; Error&nbsp; &nbsp;string `json:\"error,omitempty\"`\n}\n\nfunc (c *authz) Authorize(ctx context.Context, request *ladon.Request, opts metav1.AuthorizeOptions) (result *Response, err error) {\n&nbsp; &nbsp; result = &amp;Response{}&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; err = c.client.Post().\n&nbsp; &nbsp; &nbsp; &nbsp; Resource(\"authz\").\n&nbsp; &nbsp; &nbsp; &nbsp; VersionedParams(opts).\n&nbsp; &nbsp; &nbsp; &nbsp; Body(request).\n&nbsp; &nbsp; &nbsp; &nbsp; Do(ctx).\n&nbsp; &nbsp; &nbsp; &nbsp; Into(result)\n\n&nbsp; &nbsp; return\n}\n</code></pre><p>上面的代码中， <code>c.client</code> 是RESTClient客户端，通过调用RESTClient客户端的 <code>Post</code> 方法，返回了 <code>*Request</code> 类型的变量。</p><p><code>*Request</code> 类型的变量提供了 <code>Resource</code> 和 <code>VersionedParams</code> 方法，来构建请求HTTP URL中的路径 <code>/v1/authz</code> ；通过 <code>Body</code> 方法，指定了HTTP请求的Body。</p><p>到这里，我们分别构建了HTTP请求需要的参数：HTTP Method、请求URL、请求Body。所以，之后就可以调用 <code>Do</code> 方法来执行HTTP请求，并将返回结果通过 <code>Into</code> 方法保存在传入的result变量中。</p><h3>Request模块实现</h3><p>RESTClient客户端的方法会返回Request类型的变量，Request类型的变量提供了一系列的方法用来构建HTTP请求参数，并执行HTTP请求。</p><p>所以，Request模块可以理解为最底层的通信层，我们来看下Request模块具体是如何完成HTTP请求的。</p><p>我们先来看下<a href=\"https://github.com/marmotedu/marmotedu-sdk-go/blob/v1.0.3/rest/request.go#L28-L50\">Request结构体</a>的定义：</p><pre><code class=\"language-go\">type RESTClient struct {&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; // base is the root URL for all invocations of the client&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; base *url.URL&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; // group stand for the client group, eg: iam.api, iam.authz&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; group string&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; // versionedAPIPath is a path segment connecting the base URL to the resource root&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; versionedAPIPath string&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; // content describes how a RESTClient encodes and decodes responses.&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; content ClientContentConfig&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; Client&nbsp; *gorequest.SuperAgent&nbsp; &nbsp;&nbsp;\n}\n\ntype Request struct {\n\tc *RESTClient\n\n\ttimeout time.Duration\n\n\t// generic components accessible via method setters\n\tverb&nbsp; &nbsp; &nbsp; &nbsp;string\n\tpathPrefix string\n\tsubpath&nbsp; &nbsp; string\n\tparams&nbsp; &nbsp; &nbsp;url.Values\n\theaders&nbsp; &nbsp; http.Header\n\n\t// structural elements of the request that are part of the IAM API conventions\n\t// namespace&nbsp; &nbsp; string\n\t// namespaceSet bool\n\tresource&nbsp; &nbsp; &nbsp;string\n\tresourceName string\n\tsubresource&nbsp; string\n\n\t// output\n\terr&nbsp; error\n\tbody interface{}\n}&nbsp;&nbsp;\n</code></pre><p>再来看下Request结构体提供的方法：</p><pre><code class=\"language-go\">func (r *Request) AbsPath(segments ...string) *Request\nfunc (r *Request) Body(obj interface{}) *Request\nfunc (r *Request) Do(ctx context.Context) Result\nfunc (r *Request) Name(resourceName string) *Request\nfunc (r *Request) Param(paramName, s string) *Request\nfunc (r *Request) Prefix(segments ...string) *Request\nfunc (r *Request) RequestURI(uri string) *Request\nfunc (r *Request) Resource(resource string) *Request\nfunc (r *Request) SetHeader(key string, values ...string) *Request\nfunc (r *Request) SubResource(subresources ...string) *Request\nfunc (r *Request) Suffix(segments ...string) *Request\nfunc (r *Request) Timeout(d time.Duration) *Request\nfunc (r *Request) URL() *url.URL\nfunc (r *Request) Verb(verb string) *Request\nfunc (r *Request) VersionedParams(v interface{}) *Request\n</code></pre><p>通过Request结构体的定义和使用方法，我们不难猜测出：Request模块通过 <code>Name</code> 、 <code>Resource</code> 、 <code>Body</code> 、 <code>SetHeader</code> 等方法来设置Request结构体中的各个字段。这些字段最终用来构建出一个HTTP请求，并通过 <code>Do</code> 方法来执行HTTP请求。</p><p>那么，如何构建并执行一个HTTP请求呢？我们可以通过以下5步，来构建并执行HTTP请求：</p><ol>\n<li>构建HTTP URL；</li>\n<li>构建HTTP Method；</li>\n<li>构建HTTP Body；</li>\n<li>执行HTTP请求；</li>\n<li>保存HTTP返回结果。</li>\n</ol><p>接下来，我们就来具体看下Request模块是如何构建这些请求参数，并发送HTTP请求的。</p><p><strong>第一步，构建HTTP URL。</strong></p><p>首先，通过<a href=\"https://github.com/marmotedu/marmotedu-sdk-go/blob/v1.0.3/rest/url_utils.go#L69-L81\">defaultServerURLFor</a>函数返回了<code>http://iam.api.marmotedu.com:8080</code> 和 <code>/v1</code> ，并将二者分别保存在了Request类型结构体变量中 <code>c</code> 字段的 <code>base</code> 字段和 <code>versionedAPIPath</code> 字段中。</p><p>通过 <a href=\"https://github.com/marmotedu/marmotedu-sdk-go/blob/v1.0.3/rest/request.go#L379-L416\">Do</a> 方法执行HTTP时，会调用<a href=\"https://github.com/marmotedu/marmotedu-sdk-go/blob/v1.0.3/rest/request.go#L392\">r.URL()</a>方法来构建请求URL。 <code>r.URL</code> 方法中，通过以下代码段构建了HTTP请求URL：</p><pre><code class=\"language-go\">func (r *Request) URL() *url.URL {\n&nbsp; &nbsp; p := r.pathPrefix\n&nbsp; &nbsp; if len(r.resource) != 0 {\n&nbsp; &nbsp; &nbsp; &nbsp; p = path.Join(p, strings.ToLower(r.resource))\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; if len(r.resourceName) != 0 || len(r.subpath) != 0 || len(r.subresource) != 0 {\n&nbsp; &nbsp; &nbsp; &nbsp; p = path.Join(p, r.resourceName, r.subresource, r.subpath)\n&nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; finalURL := &amp;url.URL{}\n&nbsp; &nbsp; if r.c.base != nil {\n&nbsp; &nbsp; &nbsp; &nbsp; *finalURL = *r.c.bas\n&nbsp; &nbsp; }\n&nbsp;\n&nbsp; &nbsp; finalURL.Path = p\n    ...&nbsp; &nbsp;&nbsp;\n}\n</code></pre><p><code>p := r.pathPrefix</code> 和 <code>r.c.base</code> ，是通过 <code>defaultServerURLFor</code> 调用返回的 <code>v1</code> 和 <code>http://iam.api.marmotedu.com:8080</code> 来构建的。</p><p><code>resourceName</code> 通过 <code>func (r *Request) Resource(resource string) *Request</code> 来指定，例如 <code>authz</code> 。</p><p>所以，最终我们构建的请求URL为 <code>http://iam.api.marmotedu.com:8080/v1/authz</code> 。</p><p><strong>第二步，构建HTTP Method。</strong></p><p>HTTP Method通过RESTClient提供的 <code>Post</code> 、<code>Delete</code> 、<code>Get</code> 等方法来设置，例如：</p><pre><code class=\"language-go\">func (c *RESTClient) Post() *Request {&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; return c.Verb(\"POST\")&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n}\n\nfunc (c *RESTClient) Verb(verb string) *Request {&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; return NewRequest(c).Verb(verb)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n}\n</code></pre><p><code>NewRequest(c).Verb(verb)</code> 最终设置了Request结构体的 <code>verb</code> 字段，供 <code>Do</code> 方法使用。</p><p><strong>第三步，构建HTTP Body。</strong></p><p>HTTP Body通过Request结构体提供的Body方法来指定：</p><pre><code class=\"language-go\">func (r *Request) Body(obj interface{}) *Request {&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; if v := reflect.ValueOf(obj); v.Kind() == reflect.Struct {&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; r.SetHeader(\"Content-Type\", r.c.content.ContentType)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; }&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; r.body = obj&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; return r&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n}&nbsp;\n</code></pre><p><strong>第四步，执行HTTP请求。</strong></p><p>通过Request结构体提供的Do方法来执行具体的HTTP请求，代码如下：</p><pre><code class=\"language-go\">func (r *Request) Do(ctx context.Context) Result {\n\tclient := r.c.Client\n\tclient.Header = r.headers\n\n\tif r.timeout &gt; 0 {\n\t\tvar cancel context.CancelFunc\n\t\tctx, cancel = context.WithTimeout(ctx, r.timeout)\n\n\t\tdefer cancel()\n\t}\n\n\tclient.WithContext(ctx)\n\n\tresp, body, errs := client.CustomMethod(r.verb, r.URL().String()).Send(r.body).EndBytes()\n\tif err := combineErr(resp, body, errs); err != nil {\n\t\treturn Result{\n\t\t\tresponse: &amp;resp,\n\t\t\terr:&nbsp; &nbsp; &nbsp; err,\n\t\t\tbody:&nbsp; &nbsp; &nbsp;body,\n\t\t}\n\t}\n\n\tdecoder, err := r.c.content.Negotiator.Decoder()\n\tif err != nil {\n\t\treturn Result{\n\t\t\tresponse: &amp;resp,\n\t\t\terr:&nbsp; &nbsp; &nbsp; err,\n\t\t\tbody:&nbsp; &nbsp; &nbsp;body,\n\t\t\tdecoder:&nbsp; decoder,\n\t\t}\n\t}\n\n\treturn Result{\n\t\tresponse: &amp;resp,\n\t\tbody:&nbsp; &nbsp; &nbsp;body,\n\t\tdecoder:&nbsp; decoder,\n\t}\n}\n</code></pre><p>在Do方法中，使用了Request结构体变量中各个字段的值，通过 <code>client.CustomMethod</code> 来执行HTTP请求。 <code>client</code> 是 <code>*gorequest.SuperAgent</code> 类型的客户端。</p><p><strong>第五步，保存HTTP返回结果。</strong></p><p>通过Request结构体的 <code>Into</code> 方法来保存HTTP返回结果：</p><pre><code class=\"language-go\">func (r Result) Into(v interface{}) error {\n&nbsp; &nbsp; if r.err != nil {&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; return r.Error()\n&nbsp; &nbsp; }&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; if r.decoder == nil {&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; return fmt.Errorf(\"serializer doesn't exist\")\n&nbsp; &nbsp; }&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; if err := r.decoder.Decode(r.body, &amp;v); err != nil {\n&nbsp; &nbsp; &nbsp; &nbsp; return err&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; }&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; return nil&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n}\n</code></pre><p><code>r.body</code> 是在Do方法中，执行完HTTP请求后设置的，它的值为HTTP请求返回的Body。</p><h3>请求认证</h3><p>接下来，我再来介绍下marmotedu-sdk-go另外一个比较核心的功能：请求认证。</p><p>marmotedu-sdk-go支持两种认证方式：</p><ul>\n<li>Basic认证：通过给请求添加 <code>Authorization: Basic xxxx</code> 来实现。</li>\n<li>Bearer认证：通过给请求添加 <code>Authorization: Bearer xxxx</code> 来实现。这种方式又支持直接指定JWT Token，或者通过指定密钥对由SDK自动生成JWT Token。</li>\n</ul><p>Basic认证和Bearer认证，我在 <a href=\"https://time.geekbang.org/column/article/398410\">25讲</a>介绍过，你可以返回查看下。</p><p>认证头是RESTClient客户端发送HTTP请求时指定的，具体实现位于<a href=\"https://github.com/marmotedu/marmotedu-sdk-go/blob/v1.0.2/rest/request.go#L53-L102\">NewRequest</a>函数中：</p><pre><code class=\"language-go\">switch {\n    case c.content.HasTokenAuth():\n        r.SetHeader(\"Authorization\", fmt.Sprintf(\"Bearer %s\", c.content.BearerToken))\n    case c.content.HasKeyAuth():\n        tokenString := auth.Sign(c.content.SecretID, c.content.SecretKey, \"marmotedu-sdk-go\", c.group+\".marmotedu.com\")\n        r.SetHeader(\"Authorization\", fmt.Sprintf(\"Bearer %s\", tokenString))\n    case c.content.HasBasicAuth():\n        // TODO: get token and set header\n        r.SetHeader(\"Authorization\", \"Basic \"+basicAuth(c.content.Username, c.content.Password))\n}\n</code></pre><p>上面的代码会根据配置信息，自动判断使用哪种认证方式。</p><h2>总结</h2><p>这一讲中，我介绍了Kubernetes client-go风格的SDK实现方式。和公有云厂商的SDK设计相比，client-go风格的SDK设计有很多优点。</p><p>marmotedu-sdk-go在设计时，通过接口实现了3类客户端，分别是项目级别的客户端、应用级别的客户端和服务级别的客户端。开发人员可以根据需要，自行创建客户端类型。</p><p>marmotedu-sdk-go通过<a href=\"https://github.com/marmotedu/marmotedu-sdk-go/blob/v1.0.2/rest/config.go#L191-L237\">RESTClientFor</a>，创建了RESTClient类型的客户端，RESTClient向下通过调用<a href=\"https://github.com/marmotedu/marmotedu-sdk-go/blob/v1.0.2/rest/request.go#L28-L50\">Request</a>模块，来完成HTTP请求方法、请求路径、请求体、认证信息的构建。Request模块最终通过调用<a href=\"https://github.com/parnurzeal/gorequest\">gorequest</a>包提供的方法，完成HTTP的POST、PUT、GET、DELETE等请求，获取HTTP返回结果，并解析到指定的结构体中。RESTClient向上提供 <code>Post()</code> 、 <code>Put()</code> 、 <code>Get()</code> 、 <code>Delete()</code> 等方法，来供客户端完成HTTP请求。</p><h2>课后练习</h2><ol>\n<li>阅读<a href=\"https://github.com/marmotedu/marmotedu-sdk-go/blob/v1.0.3/rest/url_utils.go#L69-L81\">defaultServerURLFor</a>源码，思考下defaultServerURLFor是如何构建请求地址 <code>http://iam.api.marmotedu.com:8080</code> 和API版本 <code>/v1</code> 的。</li>\n<li>使用<a href=\"https://github.com/parnurzeal/gorequest\">gorequest</a>包，编写一个可以执行以下HTTP请求的示例：</li>\n</ol><pre><code class=\"language-bash\">curl -XPOST http://example.com/v1/user -d '{\"username\":\"colin\",\"address\":\"shenzhen\"}'\n</code></pre><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"33 |  SDK 设计（上）：如何设计出一个优秀的 Go SDK？","id":406389},"right":{"article_title":"35 | 效率神器：如何设计和实现一个命令行客户端工具？","id":407922}}},{"article_id":407922,"article_title":"35 | 效率神器：如何设计和实现一个命令行客户端工具？","article_content":"<p>你好，我是孔令飞。今天我们来聊聊，如何实现一个命令行客户端工具。</p><p>如果你用过Kubernetes、Istio、etcd，那你一定用过这些开源项目所提供的命令行工具：kubectl、istioctl、etcdctl。一个 <code>xxx</code> 项目，伴随着一个 <code>xxxctl</code> 命令行工具，这似乎已经成为一种趋势，在一些大型系统中更是常见。提供 <code>xxxctl</code> 命令行工具有这两个好处：</p><ul>\n<li>实现自动化：可以通过在脚本中调用 <code>xxxctl</code> 工具，实现自动化。</li>\n<li>提高效率：通过将应用的功能封装成命令和参数，方便运维、开发人员在Linux服务器上调用。</li>\n</ul><p>其中，kubectl命令设计的功能最为复杂，也是非常优秀的命令行工具，IAM项目的iamctl客户端工具就是仿照kubectl来实现的。这一讲，我就通过剖析iamctl命令行工具的实现，来介绍下如何实现一个优秀的客户端工具。</p><h2>常见客户端介绍</h2><p>在介绍iamctl命令行工具的实现之前，我们先来看下常见的客户端。</p><p>客户端又叫用户端，与后端服务相对应，安装在客户机上，用户可以使用这些客户端访问后端服务。不同的客户端面向的人群不同，所能提供的访问能力也有差异。常见的客户端有下面这几种：</p><ul>\n<li>前端，包括浏览器、手机应用；</li>\n<li>SDK；</li>\n<li>命令行工具；</li>\n<li>其他终端。</li>\n</ul><!-- [[[read_end]]] --><p>接下来，我就来分别介绍下。</p><p>浏览器和手机应用提供一个交互界面供用户访问后端服务，使用体验最好，面向的人群是最终的用户。这两类客户端也称为前端。前端由前端开发人员进行开发，并通过API接口，调用后端的服务。后端开发人员不需要关注这两类客户端，只需要关注如何提供API接口即可。</p><p>SDK（Software Development Kit）也是一个客户端，供开发者调用。开发者调用API时，如果是通过HTTP协议，需要编写HTTP的调用代码、HTTP请求包的封装和返回包的解封，还要处理HTTP的状态码，使用起来不是很方便。SDK其实是封装了API接口的一系列函数集合，开发者通过调用SDK中的函数调用API接口，提供SDK主要是方便开发者调用，减少工作量。</p><p>命令行工具是可以在操作系统上执行的一个二进制程序，提供了一种比SDK和API接口更方便快捷的访问后端服务的途径，供运维或者开发人员在服务器上直接执行使用，或者在自动化脚本中调用。</p><p>还有其他各类客户端，这里我列举一些常见的。</p><ul>\n<li>终端设备：POS机、学习机、智能音箱等。</li>\n<li>第三方应用程序：通过调用API接口或者SDK，调用我们提供的后端服务，从而实现自身的功能。</li>\n<li>脚本：脚本中通过API接口或者命令行工具，调用我们提供的后端服务，实现自动化。</li>\n</ul><p>这些其他的各类客户端，都是通过调用API接口使用后端服务的，它们跟前端一样，也不需要后台开发人员开发。</p><p>需要后台开发人员投入工作量进行研发的客户端是SDK和命令行工具。这两类客户端工具有个调用和被调用的顺序，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/e9/91/e97e547bec77dc7129615b11792f1291.jpg?wh=1920x568\" alt=\"图片\"></p><p>你可以看到，命令行工具和SDK最终都是通过API接口调用后端服务的，通过这种方式可以保证服务的一致性，并减少为适配多个客户端所带来的额外开发工作量。</p><h2>大型系统客户端（xxxctl）的特点</h2><p>通过学习kubectl、istioctl、etcdctl这些优秀的命令行工具，可以发现一个大型系统的命令行工具，通常具有下面这些特点：</p><ul>\n<li>支持命令和子命令，命令/子命名有自己独有的命令行参数。</li>\n<li>支持一些特殊的命令。比如支持completion命令，completion命令可以输出bash/zsh自动补全脚本，实现命令行及参数的自动补全。还支持 version命令，version命令不仅可以输出客户端的版本，还可以输出服务端的版本（如果有需要）。</li>\n<li>支持全局option，全局option可以作为所有命令及子命令的命令行参数。</li>\n<li>支持-h/help，-h/help可以打印xxxctl的帮助信息，例如：</li>\n</ul><pre><code class=\"language-bash\">$ iamctl -h\niamctl controls the iam platform, is the client side tool for iam platform.\n\n&nbsp;Find more information at:\nhttps://github.com/marmotedu/iam/blob/master/docs/guide/en-US/cmd/iamctl/iamctl.md\n\nBasic Commands:\n&nbsp; info&nbsp; &nbsp; &nbsp; &nbsp; Print the host information\n&nbsp; color&nbsp; &nbsp; &nbsp; &nbsp;Print colors supported by the current terminal\n&nbsp; new&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Generate demo command code\n&nbsp; jwt&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;JWT command-line tool\n\nIdentity and Access Management Commands:\n&nbsp; user&nbsp; &nbsp; &nbsp; &nbsp; Manage users on iam platform\n&nbsp; secret&nbsp; &nbsp; &nbsp; Manage secrets on iam platform\n&nbsp; policy&nbsp; &nbsp; &nbsp; Manage authorization policies on iam platform\n\nTroubleshooting and Debugging Commands:\n&nbsp; validate&nbsp; &nbsp; Validate the basic environment for iamctl to run\n\nSettings Commands:\n&nbsp; set&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Set specific features on objects\n&nbsp; completion&nbsp; Output shell completion code for the specified shell (bash or zsh)\n\nOther Commands:\n&nbsp; version&nbsp; &nbsp; &nbsp;Print the client and server version information\n\nUsage:\n&nbsp; iamctl [flags] [options]\n\nUse \"iamctl &lt;command&gt; --help\" for more information about a given command.\nUse \"iamctl options\" for a list of global command-line options (applies to all commands).\n</code></pre><ul>\n<li>支持 <code>xxxctl help [command | command subcommand] [command | command subcommand] -h</code> ，打印命令/子命令的帮助信息，格式通常为 <code>命令描述 + 使用方法</code>  。例如：</li>\n</ul><pre><code class=\"language-bash\">$ istioctl help register\nRegisters a service instance (e.g. VM) joining the mesh\n&nbsp;\nUsage:\n&nbsp; istioctl register &lt;svcname&gt; &lt;ip&gt; [name1:]port1 [name2:]port2 ... [flags]\n</code></pre><p>除此之外，一个大型系统的命令行工具还可以支持一些更高阶的功能，例如：支持命令分组，支持配置文件，支持命令的使用example，等等。</p><p>在Go生态中，如果我们要找一个符合上面所有特点的命令行工具，那非<a href=\"https://github.com/kubernetes/kubernetes/blob/master/cmd/kubectl/\">kubectl</a>莫属。因为我今天要重点讲的iamctl客户端工具，就是仿照它来实现的，所以这里就不展开介绍kubectl了，不过还是建议你认真研究下kubectl的实现。</p><h2>iamctl的核心实现</h2><p>接下来，我就来介绍IAM系统自带的iamctl客户端工具，它是仿照kubectl来实现的，能够满足一个大型系统客户端工具的需求。我会从iamctl的功能、代码结构、命令行选项和配置文件解析4个方面来介绍。</p><h3>iamctl的功能</h3><p>iamctl将命令进行了分类。这里，我也建议你对命令进行分类，因为通过分类，不仅可以协助你理解命令的用途，还能帮你快速定位某类命令。另外，当命令很多时，分类也可以使命令看起来更规整。</p><p>iamctl实现的命令如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/1d/da/1dee217f8be94ae1c3c1d9b29d627eda.jpg?wh=1920x1696\" alt=\"图片\"></p><p>更详细的功能，你可以参考 <code>iamctl -h</code> 。我建议你在实现xxxctl工具时，考虑实现下面这几个功能。</p><ul>\n<li>API功能：平台具有的API功能，都能通过xxxctl方便地进行调用。</li>\n<li>工具：一些使用IAM系统时有用的功能，比如签发JWT Token。</li>\n<li>version、completion、validate命令。</li>\n</ul><h3>代码结构</h3><p>iamctl工具的main函数位于<a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/cmd/iamctl/iamctl.go\">iamctl.go</a>文件中。命令的实现存放在<a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/iamctl/cmd/cmd.go\">internal/iamctl/cmd/cmd.go</a>文件中。iamctl的命令统一存放在<a href=\"https://github.com/marmotedu/iam/tree/v1.0.6/internal/iamctl/cmd\">internal/iamctl/cmd</a>目录下，每个命令都是一个Go包，包名即为命令名，具体实现存放在 <code>internal/iamctl/cmd/&lt;命令&gt;/&lt;命令&gt;.go</code> 文件中。如果命令有子命令，则子命令的实现存放在 <code>internal/iamctl/cmd/&lt;命令&gt;/&lt;命令&gt;_&lt;子命令&gt;.go</code> 文件中。</p><p>使用这种代码组织方式，即使是在命令很多的情况下，也能让代码井然有序，方便定位和维护代码。</p><h3>命令行选项</h3><p>添加命令行选项的代码在<a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/iamctl/cmd/cmd.go#L41-L130\">NewIAMCtlCommand</a>函数中，核心代码为：</p><pre><code class=\"language-go\">flags := cmds.PersistentFlags()\n...&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\niamConfigFlags := genericclioptions.NewConfigFlags(true).WithDeprecatedPasswordFlag().WithDeprecatedSecretFlag()\niamConfigFlags.AddFlags(flags)&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\nmatchVersionIAMConfigFlags := cmdutil.NewMatchVersionFlags(iamConfigFlags)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\nmatchVersionIAMConfigFlags.AddFlags(cmds.PersistentFlags())\n</code></pre><p><code>NewConfigFlags(true)</code> 返回带有默认值的参数，并通过 <code>iamConfigFlags.AddFlags(flags)</code> 添加到cobra的命令行flag中。</p><p><code>NewConfigFlags(true)</code> 返回结构体类型的值都是指针类型，这样做的好处是：程序可以判断出是否指定了某个参数，从而可以根据需要添加参数。例如：可以通过 <code>WithDeprecatedPasswordFlag()</code> 和 <code>WithDeprecatedSecretFlag()</code> 添加密码和密钥认证参数。</p><p><code>NewMatchVersionFlags</code> 指定是否需要服务端版本和客户端版本一致。如果不一致，在调用服务接口时会报错。</p><h3>配置文件解析</h3><p>iamctl需要连接iam-apiserver，来完成用户、策略和密钥的增删改查，并且需要进行认证。要完成这些功能，需要有比较多的配置项。这些配置项如果每次都在命令行选项指定，会很麻烦，也容易出错。</p><p>最好的方式是保存到配置文件中，并加载配置文件。加载配置文件的代码位于NewIAMCtlCommand函数中，代码如下：</p><pre><code>_ = viper.BindPFlags(cmds.PersistentFlags())\ncobra.OnInitialize(func() {\n    genericapiserver.LoadConfig(viper.GetString(genericclioptions.FlagIAMConfig), &quot;iamctl&quot;)\n})  \n\n</code></pre><p>iamctl会按以下优先级加载配置文件：</p><ol>\n<li>命令行参 <code>--iamconfig</code> 指定的配置文件。</li>\n<li>当前目录下的iamctl.yaml文件。</li>\n<li><code>$HOME/.iam/iamctl.yaml</code> 文件。</li>\n</ol><p>这种加载方式具有两个好处。首先是可以手动指定不同的配置文件，这在多环境、多配置下尤为重要。其次是方便使用，可以把配置存放在默认的加载路径中，在执行命令时，就不用再指定 <code>--iamconfig</code> 参数。</p><p>加载完配置文件之后，就可以通过 <code>viper.Get&lt;Type&gt;()</code> 函数来获取配置。例如，iamctl使用了以下 <code>viper.Get&lt;Type&gt;</code> 方法：</p><p><img src=\"https://static001.geekbang.org/resource/image/8b/42/8bce5d0b9ab45b5238d70b73175cf642.png?wh=1920x813\" alt=\"图片\"></p><h2>iamctl中子命令是如何构建的？</h2><p>讲完了iamctl命令行工具的核心实现，我们再来看看iamctl命令行工具中，子命令是如何构建的。</p><p>命令行工具的核心是命令，有很多种方法可以构建一个命令，但还是有一些比较好的构建方法，值得我们去参考。接下来，我来介绍下如何用比较好的方式去构建命令。</p><h3>命令构建</h3><p>命令行工具的核心能力是提供各类命令，来完成不同功能，每个命令构建的方式可以完全不同，但最好能按相同的方式去构建，并抽象成一个模型。如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/1e/93/1e78d2f387be0bcbae573d486e391e93.jpg?wh=1920x916\" alt=\"图片\"></p><p>你可以将一个命令行工具提供的命令进行分组。每个分组包含多个命令，每个命令又可以具有多个子命令，子命令和父命令在构建方式上完全一致。</p><p>每个命令可以按下面的四种方式构建。具体代码你可以参考<a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/iamctl/cmd/user/user_update.go\">internal/iamctl/cmd/user/user_update.go</a>。</p><ul>\n<li>通过 <code>NewCmdXyz</code> 函数创建命令框架。 <code>NewCmdXyz</code> 函数通过创建一个 <code>cobra.Command</code> 类型的变量来创建命令；通过指定 <code>cobra.Command</code> 结构体类型的Short、Long、Example字段，来指定该命令的使用文档<code>iamctl -h</code> 、详细使用文档<code>iamctl xyz -h</code> 和使用示例。</li>\n<li>通过 <code>cmd.Flags().XxxxVar</code> 来给该命令添加命令行选项。</li>\n<li>为了在不指定命令行参数时，能够按照默认的方式执行命令，可以通过 <code>NewXyzOptions</code> 函数返回一个设置了默认选项的 <code>XyzOptions</code> 类型的变量。</li>\n<li><code>XyzOptions</code> 选项具有 Complete 、Validate 和 Run 三个方法，分别完成选项补全、选项验证和命令执行。命令的执行逻辑可以在 <code>func (o *XyzOptions) Run(args []string) error</code> 函数中编写。</li>\n</ul><p>按相同的方式去构建命令，抽象成一个通用模型，这种方式有下面四个好处。</p><ul>\n<li>减少理解成本：理解一个命令的构建方式，就可以理解其他命令的构建方式。</li>\n<li>提高新命令的开发效率：可以复用其他命令的开发框架，新命令只需填写业务逻辑即可。</li>\n<li>自动生成命令：可以按照规定的命令模型，自动生成新的命令。</li>\n<li>易维护：因为所有的命令都来自于同一个命令模型，所以可以保持一致的代码风格，方便后期维护。</li>\n</ul><h3>自动生成命令</h3><p>上面讲到，自动生成命令模型的好处之一是可以自动生成命令，下面让我们来具体看下。</p><p>iamctl自带了命令生成工具，下面我们看看生成方法，一共可以分成5步。这里假设生成 <code>xyz</code> 命令。</p><p>第一步，新建一个 <code>xyz</code> 目录，用来存放 <code>xyz</code> 命令源码：</p><pre><code class=\"language-bash\">$ mkdir internal/iamctl/cmd/xyz\n</code></pre><p>第二步，在xyz目录下，使用 <code>iamctl new</code> 命令生成 <code>xyz</code> 命令源码：</p><pre><code class=\"language-bash\">$ cd internal/iamctl/cmd/xyz/\n$ iamctl new xyz\nCommand file generated: xyz.go\n</code></pre><p>第三步，将 <code>xyz</code>  命令添加到root命令中，假设 <code>xyz</code> 属于 <code>Settings Commands</code> 命令分组。</p><p>在 <code>NewIAMCtlCommand</code> 函数中，找到 <code>Settings Commands</code> 分组，将 <code>NewCmdXyz</code> 追加到Commands数组后面：</p><pre><code class=\"language-go\">&nbsp; &nbsp; &nbsp; &nbsp;{\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Message: \"Settings Commands:\",\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Commands: []*cobra.Command{\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; set.NewCmdSet(f, ioStreams),\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; completion.NewCmdCompletion(ioStreams.Out, \"\"),\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; xyz.NewCmdXyz(f, ioStreams),\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; },\n&nbsp; &nbsp; &nbsp; &nbsp; },&nbsp;\n</code></pre><p>第四步，编译iamctl：</p><pre><code class=\"language-bash\">$ make build BINS=iamctl  \n</code></pre><p>第五步，测试：</p><pre><code class=\"language-bash\">$ iamctl xyz -h\nA longer description that spans multiple lines and likely contains examples and usage of using your command. For\nexample:\n&nbsp;\n&nbsp;Cobra is a CLI library for Go that empowers applications. This application is a tool to generate the needed files to\nquickly create a Cobra application.\n&nbsp;\nExamples:\n&nbsp; # Print all option values for xyz\n&nbsp; iamctl xyz marmotedu marmotedupass\n&nbsp;\nOptions:\n&nbsp; -b, --bool=false: Bool option.\n&nbsp; -i, --int=0: Int option.\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; --slice=[]: String slice option.\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; --string='default': String option.\n&nbsp;\nUsage:\n&nbsp; iamctl xyz USERNAME PASSWORD [options]\n&nbsp;\nUse \"iamctl options\" for a list of global command-line options (applies to all commands).\n$ iamctl xyz marmotedu marmotedupass\nThe following is option values:\n==&gt; --string: default(complete)\n==&gt; --slice: []\n==&gt; --int: 0\n==&gt; --bool: false\n&nbsp;\nThe following is args values:\n==&gt; username: marmotedu\n==&gt; password: marmotedupass\n</code></pre><p>你可以看到，经过短短的几步，就添加了一个新的命令 <code>xyz</code> 。 <code>iamctl new</code> 命令不仅可以生成不带子命令的命令，还可以生成带有子命令的命令，生成方式如下：</p><pre><code class=\"language-bash\">$ iamctl new -g xyz\nCommand file generated: xyz.go\nCommand file generated: xyz_subcmd1.go\nCommand file generated: xyz_subcmd2.go\n</code></pre><h3>命令自动补全</h3><p>cobra会根据注册的命令自动生成补全脚本，可以补全父命令、子命令和选项参数。在bash下，可以按下面的方式配置自动补全功能。</p><p>第一步，生成自动补全脚本：</p><pre><code class=\"language-bash\">$ iamctl completion bash &gt; ~/.iam/completion.bash.inc\n</code></pre><p>第二步，登陆时加载bash，自动补全脚本：</p><pre><code class=\"language-bash\">$ echo \"source '$HOME/.iam/completion.bash.inc'\" &gt;&gt; $HOME/.bash_profile\n$ source $HOME/.bash_profile\n</code></pre><p>第三步，测试自动补全功能：</p><pre><code class=\"language-bash\">$ iamctl xy&lt;TAB&gt; # 按TAB键，自动补全为：iamctl xyz\n$ iamctl xyz --b&lt;TAB&gt; # 按TAB键，自动补全为：iamctl xyz --bool\n</code></pre><h3>更友好的输出</h3><p>在开发命令时，可以通过一些技巧来提高使用体验。我经常会在输出中打印一些彩色输出，或者将一些输出以表格的形式输出，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/74/42/74ef80708c853c20811e1e7bed7bde42.png?wh=651x226\" alt=\"图片\"></p><p>这里，使用 <code>github.com/olekukonko/tablewriter</code> 包来实现表格功能，使用 <code>github.com/fatih/color</code> 包来打印带色彩的字符串。具体使用方法，你可以参考<a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/iamctl/cmd/validate/validate.go\">internal/iamctl/cmd/validate/validate.go</a>文件。</p><p><code>github.com/fatih/color</code> 包可以给字符串标示颜色，字符串和颜色的对应关系可通过 <code>iamctl color</code> 来查看，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/47/b9/47593869e1b10b15a35e16c661d818b9.png?wh=991x672\" alt=\"图片\"></p><h2>iamctl是如何进行API调用的？</h2><p>上面我介绍了iamctl命令的构建方式，那么这里我们再来看下iamctl是如何请求服务端API接口的。</p><p>Go后端服务的功能通常通过API接口来对外暴露，一个后端服务可能供很多个终端使用，比如浏览器、命令行工具、手机等。为了保持功能的一致性，这些终端都会调用同一套API来完成相同的功能，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/fb/bb/fb6de4f63454dd6471e023d73b8548bb.jpg?wh=1920x742\" alt=\"图片\"></p><p>如果命令行工具需要用到后端服务的功能，也需要通过API调用的方式。理想情况下，Go后端服务对外暴露的所有API功能，都可以通过命令行工具来完成。一个API接口对应一个命令，API接口的参数映射到命令的参数。</p><p>要调用服务端的API接口，最便捷的方法是通过SDK来调用，对于一些没有实现SDK的接口，也可以直接调用。所以，在命令行工具中，需要支持以下两种调用方式：</p><ul>\n<li>通过SDK调用服务端 API 接口。</li>\n<li>直接调用服务端的API接口（本专栏是REST API接口）。</li>\n</ul><p>iamctl通过<a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/iamctl/cmd/cmd.go#L82\">cmdutil.NewFactory</a>创建一个 <code>Factory</code> 类型的变量 <code>f</code> ， <code>Factory</code> 定义为：</p><pre><code class=\"language-go\">type Factory interface {\n&nbsp; &nbsp; genericclioptions.RESTClientGetter\n&nbsp; &nbsp; IAMClientSet() (*marmotedu.Clientset, error)\n&nbsp; &nbsp; RESTClient() (*restclient.RESTClient, error)\n}\n</code></pre><p>将变量 <code>f</code> 传入到命令中，在命令中使用Factory接口提供的 <code>RESTClient()</code> 和 <code>IAMClientSet()</code> 方法，分别返回RESTful API客户端和SDK客户端，从而使用客户端提供的接口函数。代码可参考<a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/iamctl/cmd/version/version.go\">internal/iamctl/cmd/version/version.go</a>。</p><h3>客户端配置文件</h3><p>如果要创建RESTful API客户端和SDK的客户端，需要调用 <code>f.ToRESTConfig()</code> 函数返回 <code>*github.com/marmotedu/marmotedu-sdk-go/rest.Config</code> 类型的配置变量，然后再基于 <code>rest.Config</code> 类型的配置变量创建客户端。</p><p><code>f.ToRESTConfig</code> 函数最终是调用<a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/pkg/cli/genericclioptions/config_flags.go#L92-L98\">toRawIAMConfigLoader</a>函数来生成配置的，代码如下：</p><pre><code class=\"language-go\">func (f *ConfigFlags) toRawIAMConfigLoader() clientcmd.ClientConfig {\n&nbsp; &nbsp; config := clientcmd.NewConfig()\n&nbsp; &nbsp; if err := viper.Unmarshal(&amp;config); err != nil {\n&nbsp; &nbsp; &nbsp; &nbsp; panic(err)\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; return clientcmd.NewClientConfigFromConfig(config)\n}\n</code></pre><p><code>toRawIAMConfigLoader</code> 返回 <code>clientcmd.ClientConfig</code> 类型的变量， <code>clientcmd.ClientConfig</code> 类型提供了 <code>ClientConfig</code> 方法，用来返回<code>*rest.Config</code>类型的变量。</p><p>在 <code>toRawIAMConfigLoader</code> 函数内部，通过 <code>viper.Unmarshal</code> 将viper中存储的配置解析到 <code>clientcmd.Config</code> 类型的结构体变量中。viper中存储的配置，是在cobra命令启动时通过LoadConfig函数加载的，代码如下（位于 <code>NewIAMCtlCommand</code> 函数中）：</p><pre><code class=\"language-go\">cobra.OnInitialize(func() {&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; genericapiserver.LoadConfig(viper.GetString(genericclioptions.FlagIAMConfig), \"config\")\n})&nbsp;\n</code></pre><p>你可以通过 <code>--config</code> 选项，指定配置文件的路径。</p><h3>SDK调用</h3><p>通过<a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/iamctl/cmd/util/factory_client_access.go#L41-L47\">IAMClient</a>返回SDK客户端，代码如下：</p><pre><code class=\"language-go\">func (f *factoryImpl) IAMClient() (*iam.IamClient, error) {\n\tclientConfig, err := f.ToRESTConfig()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn iam.NewForConfig(clientConfig)\n}\n</code></pre><p><code>marmotedu.Clientset</code> 提供了iam-apiserver的所有接口。</p><h3>REST API调用</h3><p>通过<a href=\"https://github.com/marmotedu/iam/blob/v1.0.6/internal/iamctl/cmd/util/factory_client_access.go#L49-L56\">RESTClient()</a>返回RESTful API客户端，代码如下：</p><pre><code class=\"language-go\">func (f *factoryImpl) RESTClient() (*restclient.RESTClient, error) {\n\tclientConfig, err := f.ToRESTConfig()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tsetIAMDefaults(clientConfig)\n\treturn restclient.RESTClientFor(clientConfig)\n}\n</code></pre><p>可以通过下面的方式访问RESTful API接口：</p><pre><code class=\"language-go\">serverVersion *version.Info\n\nclient, _ := f.RESTClient()\nif err := client.Get().AbsPath(\"/version\").Do(context.TODO()).Into(&amp;serverVersion); err != nil {\n&nbsp; &nbsp; return err\n}\n</code></pre><p>上面的代码请求了iam-apiserver的/version接口，并将返回结果保存在 <code>serverVersion</code> 变量中。</p><h2>总结</h2><p>这一讲，我主要剖析了iamctl命令行工具的实现，进而向你介绍了如何实现一个优秀的客户端工具。</p><p>对于一个大型系统 <code>xxx</code> 来说，通常需要有一个 <code>xxxctl</code> 命令行工具， <code>xxxctl</code> 命令行工具可以方便开发、运维使用系统功能，并能实现功能自动化。</p><p>IAM项目参考kubectl，实现了命令行工具 iamctl。iamctl集成了很多功能，我们可以通过iamctl子命令来使用这些功能。例如，我们可以通过iamctl对用户、密钥和策略进行CURD操作；可以设置iamctl自动补全脚本；可以查看IAM系统的版本信息。甚至，你还可以使用 <code>iamctl new</code> 命令，快速创建一个iamctl子命令模板。</p><p>iamctl使用了cobra、pflag、viper包来构建，每个子命令又包含了一些基本的功能，例如短描述、长描述、使用示例、命令行选项、选项校验等。iamctl命令可以加载不同的配置文件，来连接不同的客户端。iamctl通过SDK调用、REST API调用两种方式来调用服务端API接口。</p><h2>课后练习</h2><ol>\n<li>尝试在 <code>iamctl</code> 中添加一个 <code>cliprint</code> 子命令，该子命令会读取并打印命令行选项。</li>\n<li>思考下，还有哪些好的命令行工具构建方式，欢迎在留言区分享。</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"34 | SDK 设计（下）：IAM项目Go SDK设计和实现","id":407186},"right":{"article_title":"36 | 代码测试（上）：如何编写 Go 语言单元测试和性能测试用例？","id":408529}}},{"article_id":408529,"article_title":"36 | 代码测试（上）：如何编写 Go 语言单元测试和性能测试用例？","article_content":"<p>你好，我是孔令飞。</p><p>从今天开始，我们就进入了服务测试模块，这一模块主要介绍如何测试我们的Go项目。</p><p>在Go项目开发中，我们不仅要开发功能，更重要的是确保这些功能稳定可靠，并且拥有一个不错的性能。要确保这些，就要对代码进行测试。开发人员通常会进行单元测试和性能测试，分别用来测试代码的功能是否正常和代码的性能是否满足需求。</p><p>每种语言通常都有自己的测试包/模块，Go语言也不例外。在Go中，我们可以通过<code>testing</code>包对代码进行单元测试和性能测试。这一讲，我会用一些示例来讲解如何编写单元测试和性能测试用例，下一讲则会介绍如何编写其他的测试类型，并介绍 IAM 项目的测试用例。</p><h2>如何测试 Go 代码？</h2><p>Go语言有自带的测试框架<code>testing</code>，可以用来实现单元测试（T类型）和性能测试（B类型），通过<code>go test</code>命令来执行单元测试和性能测试。</p><p>go test 执行测试用例时，是以go包为单位进行测试的。执行时需要指定包名，比如<code>go test 包名</code>，如果没有指定包名，默认会选择执行命令时所在的包。go test在执行时，会遍历以<code>_test.go</code>结尾的源码文件，执行其中以<code>Test</code>、<code>Benchmark</code>、<code>Example</code>开头的测试函数。</p><p>为了演示如何编写测试用例，我预先编写了4个函数。假设这些函数保存在test目录下的<code>math.go</code>文件中，包名为<code>test</code>，math.go代码如下：</p><!-- [[[read_end]]] --><pre><code class=\"language-go\">package test\n\nimport (\n\t\"fmt\"\n\t\"math\"\n\t\"math/rand\"\n)\n\n// Abs returns the absolute value of x.\nfunc Abs(x float64) float64 {\n\treturn math.Abs(x)\n}\n\n// Max returns the larger of x or y.\nfunc Max(x, y float64) float64 {\n\treturn math.Max(x, y)\n}\n\n// Min returns the smaller of x or y.\nfunc Min(x, y float64) float64 {\n\treturn math.Min(x, y)\n}\n\n// RandInt returns a non-negative pseudo-random int from the default Source.\nfunc RandInt() int {\n\treturn rand.Int()\n}\n</code></pre><p>在这一讲后面的内容中，我会演示如何编写测试用例，来对这些函数进行单元测试和性能测试。下面让我们先来看下测试命名规范。</p><h2>测试命名规范</h2><p>在我们对Go代码进行测试时，需要编写测试文件、测试函数、测试变量，它们都需要遵循一定的规范。这些规范有些来自于官方，有些则来自于社区。这里，我分别来介绍下测试文件、包、测试函数和测试变量的命名规范。</p><h3>测试文件的命名规范</h3><p>Go的测试文件名必须以<code>_test.go</code>结尾。例如，如果我们有一个名为<code>person.go</code>的文件，那它的测试文件必须命名为<code>person_test.go</code>。这样做是因为，Go需要区分哪些文件是测试文件。这些测试文件可以被go test命令行工具加载，用来测试我们编写的代码，但会被Go的构建程序忽略掉，因为Go程序的运行不需要这些测试代码。</p><h3>包的命名规范</h3><p>Go的测试可以分为白盒测试和黑盒测试。</p><ul>\n<li><strong>白盒测试：</strong>将测试和生产代码放在同一个Go包中，这使我们可以同时测试Go包中可导出和不可导出的标识符。当我们编写的单元测试需要访问Go包中不可导出的变量、函数和方法时，就需要编写白盒测试用例。</li>\n<li><strong>黑盒测试：</strong>将测试和生产代码放在不同的Go包中。这时，我们仅可以测试Go包的可导出标识符。这意味着我们的测试包将无法访问生产代码中的任何内部函数、变量或常量。</li>\n</ul><p>在白盒测试中，Go的测试包名称需要跟被测试的包名保持一致，例如：<code>person.go</code>定义了一个<code>person</code>包，则<code>person_test.go</code>的包名也要为<code>person</code>，这也意味着<code>person.go</code>和<code>person_test.go</code>都要在同一个目录中。</p><p>在黑盒测试中，Go的测试包名称需要跟被测试的包名不同，但仍然可以存放在同一个目录下。比如，<code>person.go</code>定义了一个<code>person</code>包，则<code>person_test.go</code>的包名需要跟<code>person</code>不同，通常我们命名为<code>person_test</code>。</p><p>如果不是需要使用黑盒测试，我们在做单元测试时要尽量使用白盒测试。一方面，这是go test工具的默认行为；另一方面，使用白盒测试，我们可以测试和使用不可导出的标识符。</p><p>测试文件和包的命名规范，由Go语言及go test工具来强制约束。</p><h3>函数的命名规范</h3><p>测试用例函数必须以<code>Test</code>、<code>Benchmark</code>、<code>Example</code>开头，例如<code>TestXxx</code>、<code>BenchmarkXxx</code>、<code>ExampleXxx</code>，<code>Xxx</code>部分为任意字母数字的组合，首字母大写。这是由Go语言和go test工具来进行约束的，<code>Xxx</code>一般是需要测试的函数名。</p><p>除此之外，还有一些社区的约束，这些约束不是强制的，但是遵循这些约束会让我们的测试函数名更加易懂。例如，我们有以下函数：</p><pre><code class=\"language-go\">package main\n\ntype Person struct {\n\tage  int64\n}\n\nfunc (p *Person) older(other *Person) bool {\n\treturn p.age &gt; other.age\n}\n</code></pre><p>很显然，我们可以把测试函数命名为<code>TestOlder</code>，这个名称可以很清晰地说明它是<code>Older</code>函数的测试用例。但是，如果我们想用多个测试用例来测试<code>TestOlder</code>函数，这些测试用例该如何命名呢？也许你会说，我们命名为<code>TestOlder1</code>、<code>TestOlder2</code>不就行了？</p><p>其实，还有其他更好的命名方法。比如，这种情况下，我们可以将函数命名为<code>TestOlderXxx</code>，其中<code>Xxx</code>代表<code>Older</code>函数的某个场景描述。例如，<code>strings.Compare</code>函数有如下测试函数：<code>TestCompare</code>、<code>TestCompareIdenticalString</code>、<code>TestCompareStrings</code>。</p><h3>变量的命名规范</h3><p>Go语言和go test没有对变量的命名做任何约束。但是，在编写单元测试用例时，还是有一些规范值得我们去遵守。</p><p>单元测试用例通常会有一个实际的输出，在单元测试中，我们会将预期的输出跟实际的输出进行对比，来判断单元测试是否通过。为了清晰地表达函数的实际输出和预期输出，可以将这两类输出命名为<code>expected/actual</code>，或者<code>got/want</code>。例如：</p><pre><code class=\"language-go\">if c.expected != actual {\n  t.Fatalf(\"Expected User-Agent '%s' does not match '%s'\", c.expected, actual)\n}\n</code></pre><p>或者：</p><pre><code class=\"language-go\">if got, want := diags[3].Description().Summary, undeclPlural; got != want {\n  t.Errorf(\"wrong summary for diagnostic 3\\ngot:  %s\\nwant: %s\", got, want)\n}\n</code></pre><p>其他的变量命名，我们可以遵循Go语言推荐的变量命名方法，例如：</p><ul>\n<li>Go中的变量名应该短而不是长，对于范围有限的局部变量来说尤其如此。</li>\n<li>变量离声明越远，对名称的描述性要求越高。</li>\n<li>像循环、索引之类的变量，名称可以是单个字母（i）。如果是不常见的变量和全局变量，变量名就需要具有更多的描述性。</li>\n</ul><p>上面，我介绍了Go测试的一些基础知识。接下来，我们来看看如何编写单元测试用例和性能测试用例。</p><h2>单元测试</h2><p>单元测试用例函数以 <code>Test</code> 开头，例如 <code>TestXxx</code> 或 <code>Test_xxx</code> （ <code>Xxx</code> 部分为任意字母数字组合，首字母大写）。函数参数必须是 <code>*testing.T</code>，可以使用该类型来记录错误或测试状态。</p><p>我们可以调用 <code>testing.T</code> 的 <code>Error</code> 、<code>Errorf</code> 、<code>FailNow</code> 、<code>Fatal</code> 、<code>FatalIf</code> 方法，来说明测试不通过；调用 <code>Log</code> 、<code>Logf</code> 方法来记录测试信息。函数列表和相关描述如下表所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/b3/ab/b374d392abfe62459d2c22e6ff76c0ab.jpg?wh=1920x1570\" alt=\"图片\"></p><p>下面的代码是两个简单的单元测试函数（函数位于文件<a href=\"https://github.com/marmotedu/gopractise-demo\">math_test.go</a>中）：</p><pre><code class=\"language-go\">func TestAbs(t *testing.T) {\n    got := Abs(-1)\n    if got != 1 {\n        t.Errorf(\"Abs(-1) = %f; want 1\", got)\n    }\n}\n\nfunc TestMax(t *testing.T) {\n    got := Max(1, 2)\n    if got != 2 {\n        t.Errorf(\"Max(1, 2) = %f; want 2\", got)\n    }\n}\n</code></pre><p>执行<code>go test</code>命令来执行如上单元测试用例：</p><pre><code class=\"language-go\">$ go test\nPASS\nok      github.com/marmotedu/gopractise-demo/31/test    0.002s\n</code></pre><p><code>go test</code>命令自动搜集所有的测试文件，也就是格式为<code>*_test.go</code>的文件，从中提取全部测试函数并执行。<br>\ngo test还支持下面三个参数。</p><ul>\n<li>-v，显示所有测试函数的运行细节：</li>\n</ul><pre><code class=\"language-go\">$ go test -v\n=== RUN   TestAbs\n--- PASS: TestAbs (0.00s)\n=== RUN   TestMax\n--- PASS: TestMax (0.00s)\nPASS\nok      github.com/marmotedu/gopractise-demo/31/test    0.002s\n</code></pre><ul>\n<li>-run &lt; regexp&gt;，指定要执行的测试函数：</li>\n</ul><pre><code class=\"language-go\">$ go test -v -run='TestA.*'\n=== RUN   TestAbs\n--- PASS: TestAbs (0.00s)\nPASS\nok      github.com/marmotedu/gopractise-demo/31/test    0.001s\n</code></pre><p>上面的例子中，我们只运行了以<code>TestA</code>开头的测试函数。</p><ul>\n<li>-count N，指定执行测试函数的次数：</li>\n</ul><pre><code class=\"language-go\">$ go test -v -run='TestA.*' -count=2\n=== RUN   TestAbs\n--- PASS: TestAbs (0.00s)\n=== RUN   TestAbs\n--- PASS: TestAbs (0.00s)\nPASS\nok      github.com/marmotedu/gopractise-demo/31/test    0.002s\n</code></pre><h3>多个输入的测试用例</h3><p>前面介绍的单元测试用例只有一个输入，但是很多时候，我们需要测试一个函数在多种不同输入下是否能正常返回。这时候，我们可以编写一个稍微复杂点的测试用例，用来支持多输入下的用例测试。例如，我们可以将<code>TestAbs</code>改造成如下函数：</p><pre><code class=\"language-go\">func TestAbs_2(t *testing.T) {\n    tests := []struct {\n        x    float64\n        want float64\n    }{\n        {-0.3, 0.3},\n        {-2, 2},\n        {-3.1, 3.1},\n        {5, 5},\n    }\n\n    for _, tt := range tests {\n        if got := Abs(tt.x); got != tt.want {\n            t.Errorf(\"Abs() = %f, want %v\", got, tt.want)\n        }\n    }\n}\n</code></pre><p>上述测试用例函数中，我们定义了一个结构体数组，数组中的每一个元素代表一次测试用例。数组元素的的值包含输入和预期的返回值：</p><pre><code class=\"language-go\">tests := []struct {\n    x    float64\n    want float64\n}{\n    {-0.3, 0.3},\n    {-2, 2},\n    {-3.1, 3.1},\n    {5, 5},\n}\n</code></pre><p>上述测试用例，将被测函数放在for循环中执行：</p><pre><code class=\"language-go\">   for _, tt := range tests {\n        if got := Abs(tt.x); got != tt.want {\n            t.Errorf(\"Abs() = %f, want %v\", got, tt.want)\n        }\n    }\n</code></pre><p>上面的代码将输入传递给被测函数，并将被测函数的返回值跟预期的返回值进行比较。如果相等，则说明此次测试通过，如果不相等则说明此次测试不通过。通过这种方式，我们就可以在一个测试用例中，测试不同的输入和输出，也就是不同的测试用例。如果要新增一个测试用例，根据需要添加输入和预期的返回值就可以了，这些测试用例都共享其余的测试代码。</p><p>上面的测试用例中，我们通过<code>got != tt.want</code>来对比实际返回结果和预期返回结果。我们也可以使用<code>github.com/stretchr/testify/assert</code>包中提供的函数来做结果对比，例如：</p><pre><code class=\"language-go\">func TestAbs_3(t *testing.T) {\n    tests := []struct {\n        x    float64\n        want float64\n    }{\n        {-0.3, 0.3},\n        {-2, 2},\n        {-3.1, 3.1},\n        {5, 5},\n    }\n\n    for _, tt := range tests {\n        got := Abs(tt.x)\n        assert.Equal(t, got, tt.want)\n    }\n}\n</code></pre><p>使用<code>assert</code>来对比结果，有下面这些好处：</p><ul>\n<li>友好的输出结果，易于阅读。</li>\n<li>因为少了<code>if got := Xxx(); got != tt.wang {}</code>的判断，代码变得更加简洁。</li>\n<li>可以针对每次断言，添加额外的消息说明，例如<code>assert.Equal(t, got, tt.want, \"Abs test\")</code>。</li>\n</ul><p>assert包还提供了很多其他函数，供开发者进行结果对比，例如<code>Zero</code>、<code>NotZero</code>、<code>Equal</code>、<code>NotEqual</code>、<code>Less</code>、<code>True</code>、<code>Nil</code>、<code>NotNil</code>等。如果想了解更多函数，你可以参考<code>go doc github.com/stretchr/testify/assert</code>。</p><h3>自动生成单元测试用例</h3><p>通过上面的学习，你也许可以发现，测试用例其实可以抽象成下面的模型：</p><p><img src=\"https://static001.geekbang.org/resource/image/8f/fa/8f06e0a1bf2638a9255467a29e6dfcfa.jpg?wh=1920x688\" alt=\"图片\"></p><p>用代码可表示为：</p><pre><code class=\"language-go\">func TestXxx(t *testing.T) {\n    type args struct {\n        // TODO: Add function input parameter definition.\n    }\n\n    type want struct {\n         // TODO: Add function return parameter definition.\n    }\n    tests := []struct {\n        name string\n        args args\n        want want\n    }{\n        // TODO: Add test cases.\n    }\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            if got := Xxx(tt.args); got != tt.want {\n                t.Errorf(\"Xxx() = %v, want %v\", got, tt.want)\n            }\n        })\n    }\n}\n</code></pre><p>既然测试用例可以抽象成一些模型，那么我们就可以基于这些模型来自动生成测试代码。Go社区中有一些优秀的工具可以自动生成测试代码，我推荐你使用<a href=\"https://github.com/cweill/gotests\">gotests</a>工具。</p><p>下面，我来讲讲gotests工具的使用方法，可以分成三个步骤。</p><p>第一步，安装gotests工具：</p><pre><code class=\"language-bash\">$ go get -u github.com/cweill/gotests/...\n</code></pre><p>gotests命令执行格式为：<code>gotests [options] [PATH] [FILE] ...</code>。gotests可以为<code>PATH</code>下的所有Go源码文件中的函数生成测试代码，也可以只为某个<code>FILE</code>中的函数生成测试代码。</p><p>第二步，进入测试代码目录，执行gotests生成测试用例：</p><pre><code class=\"language-bash\">$ gotests -all -w .\n</code></pre><p>上面的命令会为当前目录下所有Go源码文件中的函数生成测试代码。</p><p>第三步，添加测试用例：</p><p>生成完测试用例，你只需要添加需要测试的输入和预期的输出就可以了。下面的测试用例是通过gotests生成的：</p><pre><code class=\"language-go\">func TestUnpointer(t *testing.T) {\n    type args struct {\n        offset *int64\n        limit  *int64\n    }\n    tests := []struct {\n        name string\n        args args\n        want *LimitAndOffset\n    }{\n        // TODO: Add test cases.\n    }\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            if got := Unpointer(tt.args.offset, tt.args.limit); !reflect.DeepEqual(got, tt.want) {\n                t.Errorf(\"Unpointer() = %v, want %v\", got, tt.want)\n            }\n        })\n    }\n}\n</code></pre><p>我们只需要补全<code>TODO</code>位置的测试数据即可，补全后的测试用例见<a href=\"https://github.com/marmotedu/iam/blob/v1.0.8/internal/pkg/util/gormutil/gorm_test.go\">gorm_test.go</a>文件。</p><h2>性能测试</h2><p>上面，我讲了用来测试代码的功能是否正常的单元测试，接下来我们来看下性能测试，它是用来测试代码的性能是否满足需求的。</p><p>性能测试的用例函数必须以<code>Benchmark</code>开头，例如<code>BenchmarkXxx</code>或<code>Benchmark_Xxx</code>（ <code>Xxx</code> 部分为任意字母数字组合，首字母大写）。</p><p>函数参数必须是<code>*testing.B</code>，函数内以<code>b.N</code>作为循环次数，其中<code>N</code>会在运行时动态调整，直到性能测试函数可以持续足够长的时间，以便能够可靠地计时。下面的代码是一个简单的性能测试函数（函数位于文件<a href=\"https://github.com/marmotedu/gopractise-demo/blob/master/test/math_test.go\">math_test.go</a>中）：</p><pre><code class=\"language-go\">func BenchmarkRandInt(b *testing.B) {\n    for i := 0; i &lt; b.N; i++ {\n        RandInt()\n    }\n}\n</code></pre><p><code>go test</code>命令默认不会执行性能测试函数，需要通过指定参数<code>-bench &lt;pattern&gt;</code>来运行性能测试函数。<code>-bench</code>后可以跟正则表达式，选择需要执行的性能测试函数，例如<code>go test -bench=\".*\"</code>表示执行所有的压力测试函数。执行<code>go test -bench=\".*\"</code>后输出如下：</p><pre><code class=\"language-bash\">$ go test -bench=\".*\"\ngoos: linux\ngoarch: amd64\npkg: github.com/marmotedu/gopractise-demo/31/test\nBenchmarkRandInt-4      97384827                12.4 ns/op\nPASS\nok      github.com/marmotedu/gopractise-demo/31/test    1.223s\n</code></pre><p>上面的结果只显示了性能测试函数的执行结果。<code>BenchmarkRandInt</code>性能测试函数的执行结果如下：</p><pre><code class=\"language-bash\">BenchmarkRandInt-4   \t90848414\t        12.8 ns/op\n</code></pre><p>每个函数的性能执行结果一共有3列，分别代表不同的意思，这里用上面的函数举例子：</p><ul>\n<li><code>BenchmarkRandInt-4</code>，<code>BenchmarkRandInt</code>表示所测试的测试函数名，4表示有4个CPU线程参与了此次测试，默认是<code>GOMAXPROCS</code>的值。</li>\n<li><code>90848414</code> ，说明函数中的循环执行了<code>90848414</code>次。</li>\n<li><code>12.8 ns/op</code>，说明每次循环的执行平均耗时是 <code>12.8</code> 纳秒，该值越小，说明代码性能越高。</li>\n</ul><p>如果我们的性能测试函数在执行循环前，需要做一些耗时的准备工作，我们就需要重置性能测试时间计数，例如：</p><pre><code class=\"language-go\">func BenchmarkBigLen(b *testing.B) {\n    big := NewBig()\n    b.ResetTimer()\n    for i := 0; i &lt; b.N; i++ {\n        big.Len()\n    }\n}\n</code></pre><p>当然，我们也可以先停止性能测试的时间计数，然后再开始时间计数，例如：</p><pre><code class=\"language-go\">func BenchmarkBigLen(b *testing.B) {\n\tb.StopTimer() // 调用该函数停止压力测试的时间计数\n\tbig := NewBig()\n\tb.StartTimer() // 重新开始时间\n\tfor i := 0; i &lt; b.N; i++ {\n\t\tbig.Len()\n\t}\n}\n</code></pre><p>B类型的性能测试还支持下面 4 个参数。</p><ul>\n<li>benchmem，输出内存分配统计：</li>\n</ul><pre><code class=\"language-bash\">$ go test -bench=\".*\" -benchmem\ngoos: linux\ngoarch: amd64\npkg: github.com/marmotedu/gopractise-demo/31/test\nBenchmarkRandInt-4      96776823                12.8 ns/op             0 B/op          0 allocs/op\nPASS\nok      github.com/marmotedu/gopractise-demo/31/test    1.255s\n</code></pre><p>指定了<code>-benchmem</code>参数后，执行结果中又多了两列： 0 B/op，表示每次执行分配了多少内存（字节），该值越小，说明代码内存占用越小；0 allocs/op，表示每次执行分配了多少次内存，该值越小，说明分配内存次数越少，意味着代码性能越高。</p><ul>\n<li>benchtime，指定测试时间和循环执行次数（格式需要为Nx，例如100x）：</li>\n</ul><pre><code class=\"language-bash\">$ go test -bench=\".*\" -benchtime=10s # 指定测试时间\ngoos: linux\ngoarch: amd64\npkg: github.com/marmotedu/gopractise-demo/31/test\nBenchmarkRandInt-4&nbsp; &nbsp; &nbsp; 910328618&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;13.1 ns/op\nPASS\nok&nbsp; &nbsp; &nbsp; github.com/marmotedu/gopractise-demo/31/test&nbsp; &nbsp; 13.260s\n$ go test -bench=\".*\" -benchtime=100x # 指定循环执行次数\ngoos: linux\ngoarch: amd64\npkg: github.com/marmotedu/gopractise-demo/31/test\nBenchmarkRandInt-4&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;100&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 16.9 ns/op\nPASS\nok&nbsp; &nbsp; &nbsp; github.com/marmotedu/gopractise-demo/31/test&nbsp; &nbsp; 0.003s\n</code></pre><ul>\n<li>cpu，指定GOMAXPROCS。</li>\n<li>timeout，指定测试函数执行的超时时间：</li>\n</ul><pre><code class=\"language-bash\">$ go test -bench=\".*\" -timeout=10s\ngoos: linux\ngoarch: amd64\npkg: github.com/marmotedu/gopractise-demo/31/test\nBenchmarkRandInt-4      97375881                12.4 ns/op\nPASS\nok      github.com/marmotedu/gopractise-demo/31/test    1.224s\n</code></pre><h2>总结</h2><p>代码开发完成之后，我们需要为代码编写单元测试用例，并根据需要，给一些函数编写性能测试用例。Go语言提供了 <code>testing</code> 包，供我们编写测试用例，并通过 <code>go test</code> 命令来执行这些测试用例。</p><p>go test在执行测试用例时，会查找具有固定格式的Go源码文件名，并执行其中具有固定格式的函数，这些函数就是测试用例。这就要求我们的测试文件名、函数名要符合 <code>go test</code> 工具的要求：Go的测试文件名必须以 <code>_test.go</code> 结尾；测试用例函数必须以 <code>Test</code> 、 <code>Benchmark</code> 、 <code>Example</code> 开头。此外，我们在编写测试用例时，还要注意包和变量的命名规范。</p><p>Go项目开发中，编写得最多的是单元测试用例。单元测试用例函数以 <code>Test</code> 开头，例如 <code>TestXxx</code> 或 <code>Test_xxx</code> （<code>Xxx</code> 部分为任意字母数字组合，首字母大写）。函数参数必须是 <code>*testing.T</code> ，可以使用该类型来记录错误或测试状态。我们可以调用 <code>testing.T</code> 的 <code>Error</code> 、<code>Errorf</code> 、<code>FailNow</code> 、<code>Fatal</code> 、<code>FatalIf</code> 方法，来说明测试不通过；调用 <code>Log</code> 、<code>Logf</code> 方法来记录测试信息。</p><p>下面是一个简单的单元测试函数：</p><pre><code class=\"language-go\">func TestAbs(t *testing.T) {\n&nbsp; &nbsp; got := Abs(-1)\n&nbsp; &nbsp; if got != 1 {\n&nbsp; &nbsp; &nbsp; &nbsp; t.Errorf(\"Abs(-1) = %f; want 1\", got)\n&nbsp; &nbsp; }\n}\n</code></pre><p>编写完测试用例之后，可以使用 <code>go test</code> 命令行工具来执行这些测试用例。<br>\n此外，我们还可以使用<a href=\"https://github.com/cweill/gotests\">gotests</a>工具，来自动地生成单元测试用例，从而减少编写测试用例的工作量。</p><p>我们在Go项目开发中，还经常需要编写性能测试用例。性能测试用例函数必须以<code>Benchmark</code>开头，以<code>*testing.B</code> 作为函数入参，通过 <code>go test -bench &lt;pattern&gt;</code> 运行。</p><h2>课后练习</h2><ol>\n<li>编写一个 <code>PrintHello</code> 函数，该函数会返回 <code>Hello World</code> 字符串，并编写单元测试用例，对 <code>PrintHello</code> 函数进行测试。</li>\n<li>思考一下，哪些场景下采用白盒测试，哪些场景下采用黑盒测试？</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"35 | 效率神器：如何设计和实现一个命令行客户端工具？","id":407922},"right":{"article_title":"37 | 代码测试（下）：Go 语言其他测试类型及 IAM 测试介绍","id":409307}}},{"article_id":409307,"article_title":"37 | 代码测试（下）：Go 语言其他测试类型及 IAM 测试介绍","article_content":"<p>你好，我是孔令飞。</p><p><a href=\"https://time.geekbang.org/column/article/408529\">上一讲</a>，我介绍了Go中的两类测试：单元测试和性能测试。在Go中，还有一些其他的测试类型和测试方法，值得我们去了解和掌握。此外，IAM项目也编写了大量测试用例，这些测试用例使用了不同的编写方法，你可以通过学习IAM的测试用例来验证你学到的测试知识。</p><p>今天，我就来介绍下Go 语言中的其他测试类型：示例测试、TestMain函数、Mock测试、Fake测试等，并且介绍下IAM项目是如何编写和运行测试用例的。</p><h2>示例测试</h2><p>示例测试以<code>Example</code>开头，没有输入和返回参数，通常保存在<code>example_test.go</code>文件中。示例测试可能包含以<code>Output:</code>或者<code>Unordered output:</code>开头的注释，这些注释放在函数的结尾部分。<code>Unordered output:</code>开头的注释会忽略输出行的顺序。</p><p>执行<code>go test</code>命令时，会执行这些示例测试，并且go test会将示例测试输出到标准输出的内容，跟注释作对比（比较时将忽略行前后的空格）。如果相等，则示例测试通过测试；如果不相等，则示例测试不通过测试。下面是一个示例测试（位于example_test.go文件中）：</p><pre><code class=\"language-go\">func ExampleMax() {\n    fmt.Println(Max(1, 2))\n    // Output:\n    // 2\n}\n</code></pre><!-- [[[read_end]]] --><p>执行go test命令，测试<code>ExampleMax</code>示例测试：</p><pre><code class=\"language-bash\">$ go test -v -run='Example.*'\n=== RUN   ExampleMax\n--- PASS: ExampleMax (0.00s)\nPASS\nok      github.com/marmotedu/gopractise-demo/31/test    0.004s\n</code></pre><p>可以看到<code>ExampleMax</code>测试通过。这里测试通过是因为<code>fmt.Println(Max(1, 2))</code>向标准输出输出了<code>2</code>，跟<code>// Output:</code>后面的<code>2</code>一致。</p><p>当示例测试不包含<code>Output:</code>或者<code>Unordered output:</code>注释时，执行<code>go test</code>只会编译这些函数，但不会执行这些函数。</p><h3>示例测试命名规范</h3><p>示例测试需要遵循一些命名规范，因为只有这样，Godoc才能将示例测试和包级别的标识符进行关联。例如，有以下示例测试（位于example_test.go文件中）：</p><pre><code class=\"language-go\">package stringutil_test\n\nimport (\n    \"fmt\"\n\n    \"github.com/golang/example/stringutil\"\n)\n\nfunc ExampleReverse() {\n    fmt.Println(stringutil.Reverse(\"hello\"))\n    // Output: olleh\n}\n</code></pre><p>Godoc将在<code>Reverse</code>函数的文档旁边提供此示例，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/d8/93/d8ae5e99fe1d159e9b3ba1f815b24693.png?wh=540x374\" alt=\"图片\"></p><p>示例测试名以<code>Example</code>开头，后面可以不跟任何字符串，也可以跟函数名、类型名或者<code>类型_方法名</code>，中间用下划线<code>_</code>连接，例如：</p><pre><code class=\"language-go\">func Example() { ... } // 代表了整个包的示例\nfunc ExampleF() { ... } // 函数F的示例\nfunc ExampleT() { ... } // 类型T的示例\nfunc ExampleT_M() { ... } // 方法T_M的示例\n</code></pre><p>当某个函数/类型/方法有多个示例测试时，可以通过后缀来区分，后缀必须以小写字母开头，例如：</p><pre><code class=\"language-go\">func ExampleReverse()\nfunc ExampleReverse_second()\nfunc ExampleReverse_third()\n</code></pre><h3>大型示例</h3><p>有时候，我们需要编写一个大型的示例测试，这时候我们可以编写一个整文件的示例（whole file example），它有这几个特点：文件名以<code>_test.go</code>结尾；只包含一个示例测试，文件中没有单元测试函数和性能测试函数；至少包含一个包级别的声明；当展示这类示例测试时，godoc会直接展示整个文件。例如：</p><pre><code class=\"language-go\">package sort_test\n\nimport (\n    \"fmt\"\n    \"sort\"\n)\n\ntype Person struct {\n    Name string\n    Age  int\n}\n\nfunc (p Person) String() string {\n    return fmt.Sprintf(\"%s: %d\", p.Name, p.Age)\n}\n\n// ByAge implements sort.Interface for []Person based on\n// the Age field.\ntype ByAge []Person\n\nfunc (a ByAge) Len() int           { return len(a) }\nfunc (a ByAge) Swap(i, j int)      { a[i], a[j] = a[j], a[i] }\nfunc (a ByAge) Less(i, j int) bool { return a[i].Age &lt; a[j].Age }\n\nfunc Example() {\n    people := []Person{\n        {\"Bob\", 31},\n        {\"John\", 42},\n        {\"Michael\", 17},\n        {\"Jenny\", 26},\n    }\n\n    fmt.Println(people)\n    sort.Sort(ByAge(people))\n    fmt.Println(people)\n\n    // Output:\n    // [Bob: 31 John: 42 Michael: 17 Jenny: 26]\n    // [Michael: 17 Jenny: 26 Bob: 31 John: 42]\n}\n</code></pre><p>一个包可以包含多个whole file example，一个示例一个文件，例如<code>example_interface_test.go</code>、<code>example_keys_test.go</code>、<code>example_search_test.go</code>等。</p><h2>TestMain函数</h2><p>有时候，我们在做测试的时候，可能会在测试之前做些准备工作，例如创建数据库连接等；在测试之后做些清理工作，例如关闭数据库连接、清理测试文件等。这时，我们可以在<code>_test.go</code>文件中添加<code>TestMain</code>函数，其入参为<code>*testing.M</code>。</p><p><code>TestMain</code>是一个特殊的函数（相当于main函数），测试用例在执行时，会先执行<code>TestMain</code>函数，然后可以在<code>TestMain</code>中调用<code>m.Run()</code>函数执行普通的测试函数。在<code>m.Run()</code>函数前面我们可以编写准备逻辑，在<code>m.Run()</code>后面我们可以编写清理逻辑。</p><p>我们在示例测试文件<a href=\"https://github.com/marmotedu/gopractise-demo/blob/master/test/math_test.go\">math_test.go</a>中添加如下TestMain函数：</p><pre><code class=\"language-go\">func TestMain(m *testing.M) {\n    fmt.Println(\"do some setup\")\n    m.Run()\n    fmt.Println(\"do some cleanup\")\n}\n</code></pre><p>执行go test，输出如下：</p><pre><code class=\"language-bash\">$ go test -v\ndo some setup\n=== RUN   TestAbs\n--- PASS: TestAbs (0.00s)\n...\n=== RUN   ExampleMax\n--- PASS: ExampleMax (0.00s)\nPASS\ndo some cleanup\nok  \tgithub.com/marmotedu/gopractise-demo/31/test\t0.006s\n</code></pre><p>在执行测试用例之前，打印了<code>do some setup</code>，在测试用例运行完成之后，打印了<code>do some cleanup</code>。</p><p>IAM项目的测试用例中，使用TestMain函数在执行测试用例前连接了一个fake数据库，代码如下（位于<a href=\"https://github.com/marmotedu/iam/blob/v1.0.8/internal/apiserver/service/v1/user_test.go\">internal/apiserver/service/v1/user_test.go</a>文件中）：</p><pre><code class=\"language-go\">func TestMain(m *testing.M) {\n    fakeStore, _ := fake.NewFakeStore()\n    store.SetClient(fakeStore)\n    os.Exit(m.Run())\n}\n</code></pre><p>单元测试、性能测试、示例测试、TestMain函数是go test支持的测试类型。此外，为了测试在函数内使用了Go Interface的函数，我们还延伸出了Mock测试和Fake测试两种测试类型。</p><h2>Mock测试</h2><p>一般来说，单元测试中是不允许有外部依赖的，那么也就是说，这些外部依赖都需要被模拟。在Go中，一般会借助各类Mock工具来模拟一些依赖。</p><p>GoMock是由Golang官方开发维护的测试框架，实现了较为完整的基于interface的Mock功能，能够与Golang内置的testing包良好集成，也能用于其他的测试环境中。GoMock测试框架包含了GoMock包和mockgen工具两部分，其中GoMock包用来完成对象生命周期的管理，mockgen工具用来生成interface对应的Mock类源文件。下面，我来分别详细介绍下GoMock包和mockgen工具，以及它们的使用方法。</p><h3>安装GoMock</h3><p>要使用GoMock，首先需要安装GoMock包和mockgen工具，安装方法如下:</p><pre><code class=\"language-bash\">$ go get github.com/golang/mock/gomock\n$ go install github.com/golang/mock/mockgen\n</code></pre><p>下面，我通过一个<strong>获取当前Golang最新版本的例子</strong>，来给你演示下如何使用GoMock。示例代码目录结构如下（目录下的代码见<a href=\"https://github.com/marmotedu/gopractise-demo/tree/master/gomock\">gomock</a>）：</p><pre><code class=\"language-bash\">tree .\n.\n├── go_version.go\n├── main.go\n└── spider\n    └── spider.go\n</code></pre><p><code>spider.go</code>文件中定义了一个<code>Spider</code>接口，<code>spider.go</code>代码如下：</p><pre><code class=\"language-go\">package spider\n\ntype Spider interface {\n    GetBody() string\n}\n</code></pre><p><code>Spider</code>接口中的GetBody方法可以抓取<code>https://golang.org</code>首页的<code>Build version</code>字段，来获取Golang的最新版本。</p><p>我们在<code>go_version.go</code>文件中，调用<code>Spider</code>接口的<code>GetBody</code>方法，<code>go_version.go</code>代码如下：</p><pre><code class=\"language-go\">package gomock\n\nimport (\n    \"github.com/marmotedu/gopractise-demo/gomock/spider\"\n)\n\nfunc GetGoVersion(s spider.Spider) string {\n    body := s.GetBody()\n    return body\n}\n</code></pre><p><code>GetGoVersion</code>函数直接返回表示版本的字符串。正常情况下，我们会写出如下的单元测试代码：</p><pre><code class=\"language-go\">func TestGetGoVersion(t *testing.T) {\n    v := GetGoVersion(spider.CreateGoVersionSpider())\n    if v != \"go1.8.3\" {\n        t.Error(\"Get wrong version %s\", v)\n    }\n}\n</code></pre><p>上面的测试代码，依赖<code>spider.CreateGoVersionSpider()</code>返回一个实现了<code>Spider</code>接口的实例（爬虫）。但很多时候，<code>spider.CreateGoVersionSpider()</code>爬虫可能还没有实现，或者在单元测试环境下不能运行（比如，在单元测试环境中连接数据库），这时候<code>TestGetGoVersion</code>测试用例就无法执行。</p><p>那么，如何才能在这种情况下运行<code>TestGetGoVersion</code>测试用例呢？这时候，我们就可以通过Mock工具，Mock一个爬虫实例。接下来我讲讲具体操作。</p><p>首先，用 GoMock 提供的mockgen工具，生成要 Mock 的接口的实现，我们在gomock目录下执行以下命令：</p><pre><code class=\"language-bash\">$ mockgen -destination spider/mock/mock_spider.go -package spider github.com/marmotedu/gopractise-demo/gomock/spider Spider\n</code></pre><p>上面的命令会在<code>spider/mock</code>目录下生成<code>mock_spider.go</code>文件：</p><pre><code class=\"language-bash\">$ tree .\n.\n├── go_version.go\n├── go_version_test.go\n├── go_version_test_traditional_method.go~\n└── spider\n    ├── mock\n    │&nbsp;&nbsp; └── mock_spider.go\n    └── spider.go\n</code></pre><p><code>mock_spider.go</code>文件中，定义了一些函数/方法，可以支持我们编写<code>TestGetGoVersion</code>测试函数。这时候，我们的单元测试代码如下（见<a href=\"https://github.com/marmotedu/gopractise-demo/blob/master/gomock/go_version_test.go\">go_version_test.go</a>文件）：</p><pre><code class=\"language-go\">package gomock\n\nimport (\n\t\"testing\"\n\n\t\"github.com/golang/mock/gomock\"\n\n\tspider \"github.com/marmotedu/gopractise-demo/gomock/spider/mock\"\n)\n\nfunc TestGetGoVersion(t *testing.T) {\n\tctrl := gomock.NewController(t)\n\tdefer ctrl.Finish()\n\n\tmockSpider := spider.NewMockSpider(ctrl)\n\tmockSpider.EXPECT().GetBody().Return(\"go1.8.3\")\n\tgoVer := GetGoVersion(mockSpider)\n\n\tif goVer != \"go1.8.3\" {\n\t\tt.Errorf(\"Get wrong version %s\", goVer)\n\t}\n}\n</code></pre><p>这一版本的<code>TestGetGoVersion</code>通过GoMock， Mock了一个<code>Spider</code>接口，而不用去实现一个<code>Spider</code>接口。这就大大降低了单元测试用例编写的复杂度。通过Mock，很多不能测试的函数也变得可测试了。</p><p>通过上面的测试用例，我们可以看到，GoMock 和<a href=\"https://time.geekbang.org/column/article/408529\">上一讲</a>介绍的testing单元测试框架可以紧密地结合起来工作。</p><h3>mockgen工具介绍</h3><p>上面，我介绍了如何使用 GoMock 编写单元测试用例。其中，我们使用到了<code>mockgen</code>工具来生成 Mock代码，<code>mockgen</code>工具提供了很多有用的功能，这里我来详细介绍下。</p><p><code>mockgen</code>工具是 GoMock 提供的，用来Mock一个Go接口。它可以根据给定的接口，来自动生成Mock代码。这里，有两种模式可以生成Mock代码，分别是源码模式和反射模式。</p><ol>\n<li>源码模式</li>\n</ol><p>如果有接口文件，则可以通过以下命令来生成Mock代码：</p><pre><code class=\"language-bash\">$ mockgen -destination spider/mock/mock_spider.go -package spider -source spider/spider.go\n</code></pre><p>上面的命令，Mock了<code>spider/spider.go</code>文件中定义的<code>Spider</code>接口，并将Mock代码保存在<code>spider/mock/mock_spider.go</code>文件中，文件的包名为<code>spider</code>。</p><p>mockgen工具的参数说明见下表：</p><p><img src=\"https://static001.geekbang.org/resource/image/e7/9c/e72102362e2ae3225e868f125654689c.jpg?wh=1920x1210\" alt=\"图片\"></p><ol start=\"2\">\n<li>反射模式</li>\n</ol><p>此外，mockgen工具还支持通过使用反射程序来生成 Mock 代码。它通过传递两个非标志参数，即导入路径和逗号分隔的接口列表来启用，其他参数和源码模式共用，例如：</p><pre><code class=\"language-bash\">$ mockgen -destination spider/mock/mock_spider.go -package spider github.com/marmotedu/gopractise-demo/gomock/spider Spider\n</code></pre><h3>通过注释使用mockgen</h3><p>如果有多个文件，并且分散在不同的位置，那么我们要生成Mock文件的时候，需要对每个文件执行多次mockgen命令（这里假设包名不相同）。这种操作还是比较繁琐的，mockgen还提供了一种通过注释生成Mock文件的方式，此时需要借助<code>go generate</code>工具。</p><p>在接口文件的代码中，添加以下注释（具体代码见<a href=\"https://github.com/marmotedu/gopractise-demo/blob/master/gomock/spider/spider.go#L3\">spider.go</a>文件）：</p><pre><code class=\"language-go\">//go:generate mockgen -destination mock_spider.go -package spider github.com/cz-it/blog/blog/Go/testing/gomock/example/spider Spider\n</code></pre><p>这时候，我们只需要在<code>gomock</code>目录下，执行以下命令，就可以自动生成Mock代码：</p><pre><code class=\"language-bash\">$ go generate ./...\n</code></pre><h3>使用Mock代码编写单元测试用例</h3><p>生成了Mock代码之后，我们就可以使用它们了。这里我们结合<code>testing</code>来编写一个使用了Mock代码的单元测试用例。</p><p><strong>首先，</strong>需要在单元测试代码里创建一个Mock控制器：</p><pre><code class=\"language-go\">ctrl := gomock.NewController(t)\n</code></pre><p>将<code>*testing.T</code>传递给GoMock ，生成一个<code>Controller</code>对象，该对象控制了整个Mock的过程。在操作完后，还需要进行回收，所以一般会在<code>NewController</code>后面defer一个Finish，代码如下：</p><pre><code class=\"language-go\">defer ctrl.Finish()\n</code></pre><p><strong>然后，</strong>就可以调用Mock的对象了：</p><pre><code class=\"language-go\">mockSpider := spider.NewMockSpider(ctrl)\n</code></pre><p>这里的<code>spider</code>是mockgen命令里面传递的包名，后面是<code>NewMockXxxx</code>格式的对象创建函数，<code>Xxx</code>是接口名。这里，我们需要传递控制器对象进去，返回一个Mock实例。</p><p><strong>接着，</strong>有了Mock实例，我们就可以调用其断言方法<code>EXPECT()</code>了。</p><p>gomock采用了链式调用法，通过<code>.</code>连接函数调用，可以像链条一样连接下去。例如：</p><pre><code class=\"language-go\">mockSpider.EXPECT().GetBody().Return(\"go1.8.3\")\n</code></pre><p>Mock一个接口的方法，我们需要Mock该方法的入参和返回值。我们可以通过参数匹配来Mock入参，通过Mock实例的 <code>Return</code> 方法来Mock返回值。下面，我们来分别看下如何指定入参和返回值。</p><p>先来看如何指定入参。如果函数有参数，我们可以使用参数匹配来指代函数的参数，例如：</p><pre><code class=\"language-go\">mockSpider.EXPECT().GetBody(gomock.Any(), gomock.Eq(\"admin\")).Return(\"go1.8.3\")\n</code></pre><p>gomock支持以下参数匹配：</p><ul>\n<li>gomock.Any()，可以用来表示任意的入参。</li>\n<li>gomock.Eq(value)，用来表示与 value 等价的值。</li>\n<li>gomock.Not(value)，用来表示非 value 以外的值。</li>\n<li>gomock.Nil()，用来表示 None 值。</li>\n</ul><p>接下来，我们看如何指定返回值。</p><p><code>EXPECT()</code>得到Mock的实例，然后调用Mock实例的方法，该方法返回第一个<code>Call</code>对象，然后可以对其进行条件约束，比如使用Mock实例的 <code>Return</code> 方法约束其返回值。<code>Call</code>对象还提供了以下方法来约束Mock实例：</p><pre><code class=\"language-go\">func (c *Call) After(preReq *Call) *Call // After声明调用在preReq完成后执行\nfunc (c *Call) AnyTimes() *Call // 允许调用次数为 0 次或更多次\nfunc (c *Call) Do(f interface{}) *Call // 声明在匹配时要运行的操作\nfunc (c *Call) MaxTimes(n int) *Call // 设置最大的调用次数为 n 次\nfunc (c *Call) MinTimes(n int) *Call // 设置最小的调用次数为 n 次\nfunc (c *Call) Return(rets ...interface{}) *Call //  // 声明模拟函数调用返回的值\nfunc (c *Call) SetArg(n int, value interface{}) *Call // 声明使用指针设置第 n 个参数的值\nfunc (c *Call) Times(n int) *Call // 设置调用次数为 n 次\n</code></pre><p>上面列出了多个 <code>Call</code> 对象提供的约束方法，接下来我会介绍3个常用的约束方法：指定返回值、指定执行次数和指定执行顺序。</p><ol>\n<li>指定返回值</li>\n</ol><p>我们可以提供调用<code>Call</code>的<code>Return</code>函数，来指定接口的返回值，例如：</p><pre><code class=\"language-go\">mockSpider.EXPECT().GetBody().Return(\"go1.8.3\")\n</code></pre><ol start=\"2\">\n<li>指定执行次数</li>\n</ol><p>有时候，我们需要指定函数执行多少次，例如：对于接受网络请求的函数，计算其执行了多少次。我们可以通过<code>Call</code>的<code>Times</code>函数来指定执行次数：</p><pre><code class=\"language-go\">mockSpider.EXPECT().Recv().Return(nil).Times(3)\n</code></pre><p>上述代码，执行了三次Recv函数，这里gomock还支持其他的执行次数限制：</p><ul>\n<li>AnyTimes()，表示执行0到多次。</li>\n<li>MaxTimes(n int)，表示如果没有设置，最多执行n次。</li>\n<li>MinTimes(n int)，表示如果没有设置，最少执行n次。</li>\n</ul><ol start=\"3\">\n<li>指定执行顺序</li>\n</ol><p>有时候，我们还要指定执行顺序，比如要先执行 Init 操作，然后才能执行Recv操作：</p><pre><code class=\"language-go\">initCall := mockSpider.EXPECT().Init()\nmockSpider.EXPECT().Recv().After(initCall)\n</code></pre><p>最后，我们可以使用<code>go test</code>来测试使用了Mock代码的单元测试代码：</p><pre><code class=\"language-bash\">$ go test -v\n=== RUN   TestGetGoVersion\n--- PASS: TestGetGoVersion (0.00s)\nPASS\nok  \tgithub.com/marmotedu/gopractise-demo/gomock\t0.002s\n</code></pre><h2>Fake测试</h2><p>在Go项目开发中，对于比较复杂的接口，我们还可以Fake一个接口实现，来进行测试。所谓Fake测试，其实就是针对接口实现一个假（fake）的实例。至于如何实现Fake实例，需要你根据业务自行实现。例如：IAM项目中iam-apiserver组件就实现了一个fake store，代码见<a href=\"https://github.com/marmotedu/iam/tree/v1.0.8/internal/apiserver/store/fake\">fake</a>目录。因为这一讲后面的IAM项目测试实战部分有介绍，所以这里不再展开讲解。</p><h2>何时编写和执行单元测试用例？</h2><p>上面，我介绍了Go代码测试的基础知识，这里我再来分享下在做测试时一个比较重要的知识点：何时编写和执行单元测试用例。</p><h3>编码前：TDD</h3><p><img src=\"https://static001.geekbang.org/resource/image/48/b2/4830b21b55d194eccf1ec74637ee3eb2.png?wh=538x516\" alt=\"图片\"></p><p>Test-Driven Development，也就是测试驱动开发，是敏捷开发的⼀项核心实践和技术，也是⼀种设计方法论。简单来说，TDD原理就是：开发功能代码之前，先编写测试用例代码，然后针对测试用例编写功能代码，使其能够通过。这样做的好处在于，通过测试的执行代码肯定满足需求，而且有助于面向接口编程，降低代码耦合，也极大降低了bug的出现几率。</p><p>然而，TDD的坏处也显而易见：由于测试用例是在进行代码设计之前写的，很有可能限制开发者对代码的整体设计；并且，由于TDD对开发⼈员要求非常高，体现的思想跟传统开发思维也不⼀样，因此实施起来比较困难；此外，因为要先编写测试用例，TDD也可能会影响项目的研发进度。所以，在客观情况不满足的情况下，不应该盲目追求对业务代码使用TDD的开发模式。</p><h3>与编码同步进行：增量</h3><p>及时为增量代码写单测是一种良好的习惯。一方面是因为，此时我们对需求有一定的理解，能够更好地写出单元测试来验证正确性。并且，在单测阶段就发现问题，而不是等到联调测试中才发现，修复的成本也是最小的。</p><p>另一方面，在写单测的过程中，我们也能够反思业务代码的正确性、合理性，推动我们在实现的过程中更好地反思代码的设计，并及时调整。</p><h3>编码后：存量</h3><p>在完成业务需求后，我们可能会遇到这种情况：因为上线时间比较紧张、没有单测相关规划，开发阶段只手动测试了代码是否符合功能。</p><p>如果这部分存量代码出现较大的新需求，或者维护已经成为问题，需要大规模重构，这正是推动补全单测的好时机。为存量代码补充上单测，一方面能够推进重构者进一步理解原先的逻辑，另一方面也能够增强重构者重构代码后的信心，降低风险。</p><p>但是，补充存量单测可能需要再次回忆理解需求和逻辑设计等细节，而有时写单测的人并不是原编码的设计者，所以编码后编写和执行单元测试用例也有一定的不足。</p><h2>测试覆盖率</h2><p>我们写单元测试的时候应该想得很全面，能够覆盖到所有的测试用例，但有时也会漏过一些 case，Go提供了cover工具来统计测试覆盖率。具体可以分为两大步骤。</p><p>第一步，生成测试覆盖率数据：</p><pre><code class=\"language-bash\">$ go test -coverprofile=coverage.out\ndo some setup\nPASS\ncoverage: 40.0% of statements\ndo some cleanup\nok  \tgithub.com/marmotedu/gopractise-demo/test\t0.003s\n</code></pre><p>上面的命令在当前目录下生成了<code>coverage.out</code>覆盖率数据文件。</p><p><img src=\"https://static001.geekbang.org/resource/image/3c/01/3c11a0d41d6ed736f364c1693a2eff01.png?wh=1920x366\" alt=\"图片\"></p><p>第二步，分析覆盖率文件：</p><pre><code class=\"language-bash\">$ go tool cover -func=coverage.out\ndo some setup\nPASS\ncoverage: 40.0% of statements\ndo some cleanup\nok  \tgithub.com/marmotedu/gopractise-demo/test\t0.003s\n[colin@dev test]$ go tool cover -func=coverage.out\ngithub.com/marmotedu/gopractise-demo/test/math.go:9:\tAbs\t\t100.0%\ngithub.com/marmotedu/gopractise-demo/test/math.go:14:\tMax\t\t100.0%\ngithub.com/marmotedu/gopractise-demo/test/math.go:19:\tMin\t\t0.0%\ngithub.com/marmotedu/gopractise-demo/test/math.go:24:\tRandInt\t\t0.0%\ngithub.com/marmotedu/gopractise-demo/test/math.go:29:\tFloor\t\t0.0%\ntotal:\t\t\t\t\t\t\t(statements)\t40.0%\n</code></pre><p>在上述命令的输出中，我们可以查看到哪些函数没有测试，哪些函数内部的分支没有测试完全。cover工具会根据被执行代码的行数与总行数的比例计算出覆盖率。可以看到，Abs和Max函数的测试覆盖率为100%，Min和RandInt的测试覆盖率为0。</p><p>我们还可以使用<code>go tool cover -html</code>生成<code>HTML</code>格式的分析文件，可以更加清晰地展示代码的测试情况：</p><pre><code class=\"language-bash\">$ go tool cover -html=coverage.out -o coverage.html\n</code></pre><p>上述命令会在当前目录下生成一个<code>coverage.html</code>文件，用浏览器打开<code>coverage.html</code>文件，可以更加清晰地看到代码的测试情况，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/f0/5e/f089f5d44ba06f052c1c46c858c2b75e.png?wh=1524x1075\" alt=\"\"></p><p>通过上图，我们可以知道红色部分的代码没有被测试到，可以让我们接下来有针对性地添加测试用例，而不是一头雾水，不知道需要为哪些代码编写测试用例。</p><p>在Go项目开发中，我们往往会把测试覆盖率作为代码合并的一个强制要求，所以需要在进行代码测试时，同时生成代码覆盖率数据文件。在进行代码测试时，可以通过分析该文件，来判断我们的代码测试覆盖率是否满足要求，如果不满足则代码测试失败。</p><h2>IAM项目测试实战</h2><p>接下来，我来介绍下IAM项目是如何编写和运行测试用例的，你可以通过IAM项目的测试用例，加深对上面内容的理解。</p><h3>IAM项目是如何运行测试用例的？</h3><p>首先，我们来看下IAM项目是如何执行测试用例的。</p><p>在IAM项目的源码根目录下，可以通过运行<code>make test</code>执行测试用例，<code>make test</code>会执行<code>iam/scripts/make-rules/golang.mk</code>文件中的<code>go.test</code>伪目标，规则如下：</p><pre><code class=\"language-makefile\">.PHONY: go.test\ngo.test: tools.verify.go-junit-report\n  @echo \"===========&gt; Run unit test\"\n  @set -o pipefail;$(GO) test -race -cover -coverprofile=$(OUTPUT_DIR)/coverage.out \\\\\n    -timeout=10m -short -v `go list ./...|\\\n    egrep -v $(subst $(SPACE),'|',$(sort $(EXCLUDE_TESTS)))` 2&gt;&amp;1 | \\\\\n    tee &gt;(go-junit-report --set-exit-code &gt;$(OUTPUT_DIR)/report.xml)\n  @sed -i '/mock_.*.go/d' $(OUTPUT_DIR)/coverage.out # remove mock_.*.go files from test coverage\n  @$(GO) tool cover -html=$(OUTPUT_DIR)/coverage.out -o $(OUTPUT_DIR)/coverage.html\n</code></pre><p>在上述规则中，我们执行<code>go test</code>时设置了超时时间、竞态检查，开启了代码覆盖率检查，覆盖率测试数据保存在了<code>coverage.out</code>文件中。在Go项目开发中，并不是所有的包都需要单元测试，所以上面的命令还过滤掉了一些不需要测试的包，这些包配置在<code>EXCLUDE_TESTS</code>变量中：</p><pre><code class=\"language-makefile\">EXCLUDE_TESTS=github.com/marmotedu/iam/test github.com/marmotedu/iam/pkg/log github.com/marmotedu/iam/third_party github.com/marmotedu/iam/internal/pump/storage github.com/marmotedu/iam/internal/pump github.com/marmotedu/iam/internal/pkg/logger\n</code></pre><p>同时，也调用了<code>go-junit-report</code>将go test的结果转化成了xml格式的报告文件，该报告文件会被一些CI系统，例如Jenkins拿来解析并展示结果。上述代码也同时生成了coverage.html文件，该文件可以存放在制品库中，供我们后期分析查看。</p><p>这里需要注意，Mock的代码是不需要编写测试用例的，为了避免影响项目的单元测试覆盖率，需要将Mock代码的单元测试覆盖率数据从<code>coverage.out</code>文件中删除掉，<code>go.test</code>规则通过以下命令删除这些无用的数据：</p><pre><code class=\"language-bash\">sed -i '/mock_.*.go/d' $(OUTPUT_DIR)/coverage.out # remove mock_.*.go files from test coverage\n</code></pre><p>另外，还可以通过<code>make cover</code>来进行单元测试覆盖率测试，<code>make cover</code>会执行<code>iam/scripts/make-rules/golang.mk</code>文件中的<code>go.test.cover</code>伪目标，规则如下：</p><pre><code class=\"language-makefile\">.PHONY: go.test.cover\ngo.test.cover: go.test\n  @$(GO) tool cover -func=$(OUTPUT_DIR)/coverage.out | \\\\\n    awk -v target=$(COVERAGE) -f $(ROOT_DIR)/scripts/coverage.awk\n</code></pre><p>上述目标依赖<code>go.test</code>，也就是说执行单元测试覆盖率目标之前，会先进行单元测试，然后使用单元测试产生的覆盖率数据<code>coverage.out</code>计算出总的单元测试覆盖率，这里是通过<a href=\"https://github.com/marmotedu/iam/blob/v1.0.8/scripts/coverage.awk\">coverage.awk</a>脚本来计算的。</p><p>如果单元测试覆盖率不达标，Makefile会报错并退出。可以通过Makefile的<a href=\"https://github.com/marmotedu/iam/blob/master/scripts/make-rules/common.mk#L39-L41\">COVERAGE</a>变量来设置单元测试覆盖率阈值。</p><p>COVERAGE的默认值为60，我们也可以在命令行手动指定，例如：</p><pre><code class=\"language-bash\">$ make cover COVERAGE=80\n</code></pre><p>为了确保项目的单元测试覆盖率达标，需要设置单元测试覆盖率质量红线。一般来说，这些红线很难靠开发者的自觉性去保障，所以好的方法是将质量红线加入到CICD流程中。</p><p>所以，在<code>Makefile</code>文件中，我将<code>cover</code>放在<code>all</code>目标的依赖中，并且位于build之前，也就是<code>all: gen add-copyright format lint cover build</code>。这样每次当我们执行make时，会自动进行代码测试，并计算单元测试覆盖率，如果覆盖率不达标，则停止构建；如果达标，继续进入下一步的构建流程。</p><h3>IAM项目测试案例分享</h3><p>接下来，我会给你展示一些IAM项目的测试案例，因为这些测试案例的实现方法，我在<a href=\"https://time.geekbang.org/column/article/408529\">36讲</a> 和这一讲的前半部分已有详细介绍，所以这里，我只列出具体的实现代码，不会再介绍这些代码的实现方法。</p><ol>\n<li>单元测试案例</li>\n</ol><p>我们可以手动编写单元测试代码，也可以使用gotests工具生成单元测试代码。</p><p>先来看手动编写测试代码的案例。这里单元测试代码见<a href=\"https://github.com/marmotedu/iam/blob/v1.0.8/pkg/log/log_test.go#L52-L62\">Test_Option</a>，代码如下：</p><pre><code class=\"language-go\">func Test_Option(t *testing.T) {\n    fs := pflag.NewFlagSet(\"test\", pflag.ExitOnError)\n    opt := log.NewOptions()\n    opt.AddFlags(fs)\n\n    args := []string{\"--log.level=debug\"}\n    err := fs.Parse(args)\n    assert.Nil(t, err)\n\n    assert.Equal(t, \"debug\", opt.Level)\n}\n</code></pre><p>上述代码中，使用了<code>github.com/stretchr/testify/assert</code>包来对比结果。</p><p>再来看使用gotests工具生成单元测试代码的案例（Table-Driven 的测试模式）。出于效率上的考虑，IAM项目的单元测试用例，基本都是使用gotests工具生成测试用例模板代码，并基于这些模板代码填充测试Case的。代码见<a href=\"https://github.com/marmotedu/iam/blob/v1.0.8/internal/apiserver/service/v1/service_test.go\">service_test.go</a>文件。</p><ol start=\"2\">\n<li>性能测试案例</li>\n</ol><p>IAM项目的性能测试用例，见<a href=\"https://github.com/marmotedu/iam/blob/v1.0.8/internal/apiserver/service/v1/user_test.go#L27-L41\">BenchmarkListUser</a>测试函数。代码如下：</p><pre><code class=\"language-go\">func BenchmarkListUser(b *testing.B) {\n\topts := metav1.ListOptions{\n\t\tOffset: pointer.ToInt64(0),\n\t\tLimit:  pointer.ToInt64(50),\n\t}\n\tstoreIns, _ := fake.GetFakeFactoryOr()\n\tu := &amp;userService{\n\t\tstore: storeIns,\n\t}\n\n\tfor i := 0; i &lt; b.N; i++ {\n\t\t_, _ = u.List(context.TODO(), opts)\n\t}\n}\n</code></pre><ol start=\"3\">\n<li>示例测试案例</li>\n</ol><p>IAM项目的示例测试用例见<a href=\"https://github.com/marmotedu/errors/blob/v1.0.2/example_test.go\">example_test.go</a>文件。<code>example_test.go</code>中的一个示例测试代码如下：</p><pre><code class=\"language-go\">func ExampleNew() {\n\terr := New(\"whoops\")\n\tfmt.Println(err)\n\n\t// Output: whoops\n}\n</code></pre><ol start=\"4\">\n<li>TestMain测试案例</li>\n</ol><p>IAM项目的TestMain测试案例，见<a href=\"https://github.com/marmotedu/iam/blob/v1.0.8/internal/apiserver/service/v1/user_test.go\">user_test.go</a>文件中的<code>TestMain</code>函数：</p><pre><code class=\"language-go\">func TestMain(m *testing.M) {\n    _, _ = fake.GetFakeFactoryOr()\n    os.Exit(m.Run())\n}\n</code></pre><p><code>TestMain</code>函数初始化了fake Factory，然后调用<code>m.Run</code>执行测试用例。</p><ol start=\"5\">\n<li>Mock测试案例</li>\n</ol><p>Mock代码见<a href=\"https://github.com/marmotedu/iam/blob/v1.0.8/internal/apiserver/service/v1/mock_service.go\">internal/apiserver/service/v1/mock_service.go</a>，使用Mock的测试用例见<a href=\"https://github.com/marmotedu/iam/blob/v1.0.8/internal/apiserver/controller/v1/user/create_test.go\">internal/apiserver/controller/v1/user/create_test.go</a>文件。因为代码比较多，这里建议你打开链接，查看测试用例的具体实现。</p><p>我们可以在IAM项目的根目录下执行以下命令，来自动生成所有的Mock文件：</p><pre><code class=\"language-bash\">$ go generate ./...\n</code></pre><ol start=\"6\">\n<li>Fake测试案例</li>\n</ol><p>fake store代码实现位于<a href=\"https://github.com/marmotedu/iam/tree/v1.0.8/internal/apiserver/store/fake\">internal/apiserver/store/fake</a>目录下。fake store的使用方式，见<a href=\"https://github.com/marmotedu/iam/blob/v1.0.8/internal/apiserver/service/v1/user_test.go\">user_test.go</a>文件：</p><pre><code class=\"language-go\">func TestMain(m *testing.M) {\n    _, _ = fake.GetFakeFactoryOr()\n    os.Exit(m.Run())\n}\n\nfunc BenchmarkListUser(b *testing.B) {\n    opts := metav1.ListOptions{\n        Offset: pointer.ToInt64(0),\n        Limit:  pointer.ToInt64(50),\n    }\n    storeIns, _ := fake.GetFakeFactoryOr()\n    u := &amp;userService{\n        store: storeIns,\n    }\n\n    for i := 0; i &lt; b.N; i++ {\n        _, _ = u.List(context.TODO(), opts)\n    }\n}\n</code></pre><p>上述代码通过<code>TestMain</code>初始化fake实例（<a href=\"https://github.com/marmotedu/iam/blob/v1.0.8/internal/apiserver/store/store.go#L12-L17\">store.Factory</a>接口类型）：</p><pre><code class=\"language-go\">func GetFakeFactoryOr() (store.Factory, error) {\n    once.Do(func() {\n        fakeFactory = &amp;datastore{\n            users:    FakeUsers(ResourceCount),\n            secrets:  FakeSecrets(ResourceCount),\n            policies: FakePolicies(ResourceCount),\n        }\n    })\n\n    if fakeFactory == nil {\n        return nil, fmt.Errorf(\"failed to get mysql store fatory, mysqlFactory: %+v\", fakeFactory)\n    }\n\n    return fakeFactory, nil\n}\n</code></pre><p><code>GetFakeFactoryOr</code>函数，创建了一些fake users、secrets、policies，并保存在了<code>fakeFactory</code>变量中，供后面的测试用例使用，例如BenchmarkListUser、Test_newUsers等。</p><h2>其他测试工具/包</h2><p>最后，我再来分享下Go项目测试中常用的工具/包，因为内容较多，我就不详细介绍了，如果感兴趣你可以点进链接自行学习。我将这些测试工具/包分为了两类，分别是测试框架和Mock工具。</p><h3>测试框架</h3><ul>\n<li><a href=\"https://github.com/stretchr/testify\">Testify框架</a>：Testify是Go test的预判工具，它能让你的测试代码变得更优雅和高效，测试结果也变得更详细。</li>\n<li><a href=\"https://github.com/smartystreets/goconvey\">GoConvey框架</a>：GoConvey是一款针对Golang的测试框架，可以管理和运行测试用例，同时提供了丰富的断言函数，并支持很多 Web 界面特性。</li>\n</ul><h3>Mock工具</h3><p>这一讲里，我介绍了Go官方提供的Mock框架GoMock，不过还有一些其他的优秀Mock工具可供我们使用。这些Mock工具分别用在不同的Mock场景中，我在 <a href=\"https://time.geekbang.org/column/article/384648\">10讲</a>中已经介绍过。不过，为了使我们这一讲的测试知识体系更加完整，这里我还是再提一次，你可以复习一遍。</p><ul>\n<li><a href=\"https://github.com/DATA-DOG/go-sqlmock\">sqlmock</a>：可以用来模拟数据库连接。数据库是项目中比较常见的依赖，在遇到数据库依赖时都可以用它。</li>\n<li><a href=\"https://github.com/jarcoal/httpmock\">httpmock</a>：可以用来Mock HTTP请求。</li>\n<li><a href=\"https://github.com/bouk/monkey\">bouk/monkey</a>：猴子补丁，能够通过替换函数指针的方式来修改任意函数的实现。如果golang/mock、sqlmock和httpmock这几种方法都不能满足我们的需求，我们可以尝试用猴子补丁的方式来Mock依赖。可以这么说，猴子补丁提供了单元测试 Mock 依赖的最终解决方案。</li>\n</ul><h2>总结</h2><p>这一讲，我介绍了除单元测试和性能测试之外的另一些测试方法。</p><p>除了示例测试和TestMain函数，我还详细介绍了Mock测试，也就是如何使用GoMock来测试一些在单元测试环境下不好实现的接口。绝大部分情况下，可以使用GoMock来Mock接口，但是对于一些业务逻辑比较复杂的接口，我们可以通过Fake一个接口实现，来对代码进行测试，这也称为Fake测试。</p><p>此外，我还介绍了何时编写和执行测试用例。我们可以根据需要，选择在编写代码前、编写代码中、编写代码后编写测试用例。</p><p>为了保证单元测试覆盖率，我们还应该为整个项目设置单元测试覆盖率质量红线，并将该质量红线加入到CICD流程中。我们可以通过 <code>go test -coverprofile=coverage.out</code> 命令来生成测试覆盖率数据，通过<code>go tool cover -func=coverage.out</code> 命令来分析覆盖率文件。</p><p>IAM项目中使用了大量的测试方法和技巧来测试代码，为了加深你对测试知识的理解，我也列举了一些测试案例，供你参考、学习和验证。具体的测试案例，你可以返回前面查看下。</p><p>除此之外，我们还可以使用其他一些测试框架，例如Testify框架和GoConvey框架。在Go代码测试中，我们最常使用的是Go官方提供的Mock框架GoMock，但仍然有其他优秀的Mock工具，可供我们在不同场景下使用，例如sqlmock、httpmock、bouk/monkey等。</p><h2>课后习题</h2><ol>\n<li>请使用 <a href=\"https://github.com/DATA-DOG/go-sqlmock\">sqlmock</a> 来Mock一个GORM数据库实例，并完成GORM的CURD单元测试用例编写。</li>\n<li>思考下，在Go项目开发中，还有哪些优秀的测试框架、测试工具、Mock工具以及测试技巧？欢迎你在留言区分享。</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"36 | 代码测试（上）：如何编写 Go 语言单元测试和性能测试用例？","id":408529},"right":{"article_title":"38｜性能分析（上）：如何分析 Go 语言代码的性能？","id":410205}}},{"article_id":410205,"article_title":"38｜性能分析（上）：如何分析 Go 语言代码的性能？","article_content":"<p>你好，我是孔令飞。</p><p>作为开发人员，我们一般都局限在功能上的单元测试中，对一些性能上的细节往往不会太关注。但是，如果我们在上线的时候对项目的整体性能没有一个全面的了解，随着请求量越来越大，可能会出现各种各样的问题，比如CPU占用高、内存使用率高、请求延时高等。为了避免这些性能瓶颈，我们在开发的过程中需要通过一定的手段，来对程序进行性能分析。</p><p>Go语言已经为开发者内置了很多性能调优、监控的工具和方法，这大大提升了我们profile分析的效率，借助这些工具，我们可以很方便地对Go程序进行性能分析。在Go语言开发中，开发者基本都是通过内置的<code>pprof</code>工具包来进行性能分析的。</p><p>在进行性能分析时，我们会先借助一些工具和包，生成性能数据文件，然后再通过<code>pprof</code>工具分析性能数据文件，从而分析代码的性能。那么接下来，我们就分别来看下如何执行这两步操作。</p><h2>生成性能数据文件</h2><p>要查看性能数据，需要先生成性能数据文件。生成性能数据文件有三种方法，分别是通过命令行、通过代码和通过<code>net/http/pprof</code>包。这些工具和包会分别生成CPU和内存性能数据。</p><p>接下来，我们就来看下这三种方法分别是如何生成性能数据文件的。</p><h3>通过命令行生成性能数据文件</h3><!-- [[[read_end]]] --><p>我们可以使用<code>go test -cpuprofile</code>来生成性能测试数据。进入<a href=\"https://github.com/marmotedu/iam/tree/v1.0.8/internal/apiserver/service/v1\">internal/apiserver/service/v1</a>目录，执行以下命令：</p><pre><code class=\"language-bash\">$ go test -bench=\".*\" -cpuprofile cpu.profile -memprofile mem.profile\ngoos: linux\ngoarch: amd64\npkg: github.com/marmotedu/iam/internal/apiserver/service/v1\ncpu: AMD EPYC Processor\nBenchmarkListUser-8   \t     280\t   4283077 ns/op\nPASS\nok  \tgithub.com/marmotedu/iam/internal/apiserver/service/v1\t1.798s\n</code></pre><p>上面的命令会在当前目录下生成3个文件：</p><ul>\n<li>v1.test，测试生成的二进制文件，进行性能分析时可以用来解析各种符号。</li>\n<li>cpu.profile，CPU性能数据文件。</li>\n<li>mem.profile，内存性能数据文件。</li>\n</ul><h3>通过代码生成性能数据文件</h3><p>我们还可以使用代码来生成性能数据文件，例如<a href=\"https://github.com/marmotedu/gopractise-demo/blob/master/pprof/pprof.go\">pprof.go</a>文件：</p><pre><code class=\"language-go\">package main\n\nimport (\n\t\"os\"\n\t\"runtime/pprof\"\n)\n\nfunc main() {\n\tcpuOut, _ := os.Create(\"cpu.out\")\n\tdefer cpuOut.Close()\n\tpprof.StartCPUProfile(cpuOut)\n\tdefer pprof.StopCPUProfile()\n\n\tmemOut, _ := os.Create(\"mem.out\")\n\tdefer memOut.Close()\n\tdefer pprof.WriteHeapProfile(memOut)\n\n\tSum(3, 5)\n\n}\n\nfunc Sum(a, b int) int {\n\treturn a + b\n}\n</code></pre><p>运行<code>pprof.go</code>文件：</p><pre><code class=\"language-bash\">$ go run pprof.go\n</code></pre><p>运行<code>pprof.go</code>文件后，会在当前目录生成<code>cpu.profile</code>和<code>mem.profile</code>性能数据文件。</p><h3>通过<code>net/http/pprof</code>生成性能数据文件</h3><p>如果要分析HTTP Server的性能，我们可以使用<code>net/http/pprof</code>包来生成性能数据文件。</p><p>IAM项目使用Gin框架作为HTTP引擎，所以IAM项目使用了<code>github.com/gin-contrib/pprof</code>包来启用HTTP性能分析。<code>github.com/gin-contrib/pprof</code>包是<code>net/http/pprof</code>的一个简单封装，通过封装使pprof的功能变成了一个Gin中间件，这样可以根据需要加载pprof中间件。</p><p><code>github.com/gin-contrib/pprof</code>包中的<a href=\"https://github.com/gin-contrib/pprof/blob/v1.3.0/pprof.go\">pprof.go</a>文件中有以下代码：</p><pre><code class=\"language-go\">func Register(r *gin.Engine, prefixOptions ...string) {\n    prefix := getPrefix(prefixOptions...)\n\n    prefixRouter := r.Group(prefix)\n    {\n        ...\n        prefixRouter.GET(\"/profile\", pprofHandler(pprof.Profile))\n        ...\n    }\n}\n\nfunc pprofHandler(h http.HandlerFunc) gin.HandlerFunc {\n    handler := http.HandlerFunc(h)\n    return func(c *gin.Context) {\n        handler.ServeHTTP(c.Writer, c.Request)\n    }\n}\n</code></pre><p>通过上面的代码，你可以看到<code>github.com/gin-contrib/pprof</code>包将<code>net/http/pprof.Profile</code>转换成了<code>gin.HandlerFunc</code>，也就是Gin中间件。</p><p>要开启HTTP性能分析，只需要在代码中注册pprof提供的HTTP Handler即可（位于<a href=\"https://github.com/marmotedu/iam/blob/v1.0.8/internal/pkg/server/genericapiserver.go#L75-L77\">internal/pkg/server/genericapiserver.go</a>文件中）：</p><pre><code class=\"language-go\">// install pprof handler\nif s.enableProfiling {\n    pprof.Register(s.Engine)\n}\n</code></pre><p>上面的代码根据配置<code>--feature.profiling</code>来判断是否开启HTTP性能分析功能。我们开启完HTTP性能分析，启动HTTP服务iam-apiserver后，即可访问<code>http:// x.x.x.x:8080/debug/pprof</code>（<code>x.x.x.x</code>是Linux服务器的地址）来查看profiles信息。profiles信息如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/6a/6b/6a5fc33b87b6322162c39e9209b6396b.png?wh=1520x1170\" alt=\"图片\"></p><p>我们可以通过以下命令，来获取CPU性能数据文件：</p><pre><code class=\"language-bash\">$ curl http://127.0.0.1:8080/debug/pprof/profile -o cpu.profile\n</code></pre><p>执行完上面的命令后，需要等待30s，pprof会采集这30s内的性能数据，我们需要在这段时间内向服务器连续发送多次请求，请求的频度可以根据我们的场景来决定。30s之后，<code>/debug/pprof/profile</code>接口会生成CPU profile文件，被curl命令保存在当前目录下的cpu.profile文件中。</p><p>同样的，我们可以执行以下命令来生成内存性能数据文件：</p><pre><code class=\"language-bash\">$ curl http://127.0.0.1:8080/debug/pprof/heap -o mem.profile\n</code></pre><p>上面的命令会自动下载heap文件，并被curl命令保存在当前目录下的mem.profile文件中。</p><p>我们可以使用<code>go tool pprof  [mem|cpu].profile</code>命令来分析HTTP接口的CPU和内存性能。我们也可以使用命令<code>go tool pprof http://127.0.0.1:8080/debug/pprof/profile</code>，或者<code>go tool pprof http://127.0.0.1:8080/debug/pprof/heap</code>，来直接进入pprof工具的交互Shell中。<code>go tool pprof</code>会首先下载并保存CPU和内存性能数据文件，然后再分析这些文件。</p><p>通过上面的三种方法，我们生成了cpu.profile和mem.profile，接下来我们就可以使用<code>go tool pprof</code>来分析这两个性能数据文件，进而分析我们程序的CPU和内存性能了。下面，我来具体讲讲性能分析的过程。</p><h2>性能分析</h2><p>使用<code>go tool pprof</code>，来对性能进行分析的流程，你可以参考下图：</p><p><img src=\"https://static001.geekbang.org/resource/image/d4/da/d41d03c41283ea00308682a9yy0400da.jpg?wh=1920x665\" alt=\"图片\"></p><p>接下来，我先给你介绍下pprof工具，再介绍下如何生成性能数据，最后再分别介绍下CPU和内存性能分析方法。</p><h3>pprof工具介绍</h3><p><a href=\"https://github.com/google/pprof\">pprof</a>是一个Go程序性能分析工具，用它可以访问并分析性能数据文件，它还会根据我们的要求，提供高可读性的输出信息。Go在语言层面上集成了profile采样工具，只需在代码中简单地引入<code>runtime/pprof</code>或者<code>net/http/pprof</code>包，即可获取程序的profile文件，并通过profile文件来进行性能分析。</p><p><code>net/http/pprof</code>基于<code>runtime/pprof</code>包进行封装，并在 HTTP 端口上暴露出来。</p><h3>生成性能数据</h3><p>我们在做性能分析时，主要是对内存和CPU性能进行分析。为了分析内存和CPU的性能，我们需要先生成性能数据文件。在 IAM 源码中，也有包含性能测试的用例，下面我会借助 IAM 源码中的性能测试用例，来介绍如何分析程序的性能。</p><p>进入<a href=\"https://github.com/marmotedu/iam/tree/v1.0.8/internal/apiserver/service/v1\">internal/apiserver/service/v1</a>目录，user_test.go文件包含了性能测试函数 <a href=\"https://github.com/marmotedu/iam/blob/v1.0.8/internal/apiserver/service/v1/user_test.go#L27-L41\">BenchmarkListUser</a>，执行以下命令来生成性能数据文件：</p><pre><code class=\"language-bash\">$ go test -benchtime=30s -benchmem -bench=\".*\" -cpuprofile cpu.profile -memprofile mem.profile\ngoos: linux\ngoarch: amd64\npkg: github.com/marmotedu/iam/internal/apiserver/service/v1\ncpu: AMD EPYC Processor\nBenchmarkListUser-8   \t     175\t 204523677 ns/op\t   15331 B/op\t     268 allocs/op\nPASS\nok  \tgithub.com/marmotedu/iam/internal/apiserver/service/v1\t56.514s\n</code></pre><p>上面的命令会在当前目录下产生<code>cpu.profile</code>、<code>mem.profile</code>性能数据文件，以及<code>v1.test</code>二进制文件。接下来，我们基于<code>cpu.profile</code>、<code>mem.profile</code>、<code>v1.test</code>文件来分析代码的CPU和内存性能。为了获取足够的采样数据，我们将benchmark时间设置为<code>30s</code>。</p><p>在做性能分析时，我们可以采取不同的手段来分析性能，比如分析采样图、分析火焰图，还可以使用<code>go tool pprof</code>交互模式，查看函数CPU和内存消耗数据。下面我会运用这些方法，来分析CPU性能和内存性能。</p><h3>CPU性能分析</h3><p>在默认情况下，Go语言的运行时系统会以100 Hz的的频率对CPU使用情况进行采样，也就是说每秒采样100次，每10毫秒采样一次。每次采样时，会记录正在运行的函数，并统计其运行时间，从而生成CPU性能数据。</p><p>上面我们已经生成了CPU性能数据文件<code>cpu.profile</code>，接下来会运用上面提到的三种方法来分析该性能文件，优化性能。</p><p><strong>方法一：分析采样图</strong></p><p>要分析性能，最直观的方式当然是看图，所以首先我们需要生成采样图，生成过程可以分为两个步骤。</p><p><strong>第一步</strong>，确保系统安装了<code>graphviz</code>：</p><pre><code class=\"language-bash\">$ sudo yum -y install graphviz.x86_64\n</code></pre><p><strong>第二步</strong>，执行<code>go tool pprof</code>生成调用图：</p><pre><code class=\"language-bash\">$ go tool pprof -svg cpu.profile &gt; cpu.svg  # svg 格式\n$ go tool pprof -pdf cpu.profile &gt; cpu.pdf # pdf 格式\n$ go tool pprof -png cpu.profile &gt; cpu.png # png 格式\n</code></pre><p>以上命令会生成<code>cpu.pdf</code>、<code>cpu.svg</code>和<code>cpu.png</code>文件，文件中绘制了函数调用关系以及其他采样数据。如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/a7/0c/a737e4d5f25775150545558872aa9e0c.png?wh=438x1259\" alt=\"图片\"></p><p>这张图片由有向线段和矩形组成。<strong>我们先来看有向线段的含义。</strong></p><p>有向线段描述了函数的调用关系，矩形包含了CPU采样数据。从图中，我们看到没箭头的一端调用了有箭头的一端，可以知道<code>v1.(*userService).List</code>函数调用了<code>fake.(*policies).List</code>。</p><p>线段旁边的数字<code>90ms</code>则说明，<code>v1.(*userService).List</code>调用<code>fake.(*policies).List</code>函数，在采样周期内，一共耗用了<code>90ms</code>。通过函数调用关系，我们可以知道某个函数调用了哪些函数，并且调用这些函数耗时多久。</p><p>这里，我们再次解读下图中调用关系中的重要信息：</p><p><img src=\"https://static001.geekbang.org/resource/image/70/32/70e964bc6d8f0b28d434cce47c4e1132.png?wh=835x818\" alt=\"图片\"></p><p><code>runtime.schedule</code>的累积采样时间（140ms）中，有10ms来自于<code>runtime.goschedImpl</code>函数的直接调用，有70ms来自于<code>runtime.park_m</code>函数的直接调用。这些数据可以说明<code>runtime.schedule</code>函数分别被哪些函数调用，并且调用频率有多大。也因为这个原因，函数<code>runtime.goschedImpl</code>对函数<code>runtime.schedule</code>的调用时间必定小于等于函数<code>runtime.schedule</code>的累积采样时间。</p><p><strong>我们再来看下矩形里的采样数据。</strong>这些矩形基本都包含了3类信息：</p><ul>\n<li>函数名/方法名，该类信息包含了包名、结构体名、函数名/方法名，方便我们快速定位到函数/方法，例如<code>fake(*policies)List</code>说明是fake包，policies结构体的List方法。</li>\n<li>本地采样时间，以及它在采样总数中所占的比例。本地采样时间是指采样点落在该函数中的总时间。</li>\n<li>累积采样时间，以及它在采样总数中所占的比例。累积采样时间是指采样点落在该函数，以及被它直接或者间接调用的函数中的总时间。</li>\n</ul><p>我们可以通过<code>OutDir</code>函数来解释本地采样时间和累积采样时间这两个概念。<code>OutDir</code>函数如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/f5/a5/f55c738c09471094a9a8498e9b73faa5.png?wh=1020x558\" alt=\"图片\"></p><p>整个函数的执行耗时，我们可以认为是累积采样时间，包含了白色部分的代码耗时和红色部分的函数调用耗时。白色部分的代码耗时，可以认为是本地采样时间。</p><p>通过累积采样时间，我们可以知道函数的总调用时间，累积采样时间越大，说明调用它所花费的CPU时间越多。但你要注意，这并不一定说明这个函数本身是有问题的，也有可能是函数所调用的函数性能有瓶颈，这时候我们应该根据函数调用关系顺藤摸瓜，去寻找这个函数直接或间接调用的函数中最耗费CPU时间的那些。</p><p>如果函数的本地采样时间很大，就说明这个函数自身耗时（除去调用其他函数的耗时）很大，这时候需要我们分析这个函数自身的代码，而不是这个函数直接或者间接调用函数的代码。</p><p>采样图中，矩形框面积越大，说明这个函数的累积采样时间越大。那么，如果一个函数分析采样图中的矩形框面积很大，这时候我们就要认真分析了，因为很可能这个函数就有需要优化性能的地方。</p><p><strong>方法二：分析火焰图</strong></p><p>上面介绍的采样图，其实在分析性能的时候还不太直观，这里我们可以通过生成火焰图，来更直观地查看性能瓶颈。火焰图是由Brendan Gregg大师发明的专门用来把采样到的堆栈轨迹（Stack Trace）转化为直观图片显示的工具，因整张图看起来像一团跳动的火焰而得名。</p><p><code>go tool pprof</code>提供了<code>-http</code>参数，可以使我们通过浏览器浏览采样图和火焰图。执行以下命令：</p><pre><code class=\"language-bash\">$ go tool pprof -http=\"0.0.0.0:8081\" v1.test cpu.profile\n</code></pre><p>然后访问<code>http://x.x.x.x:8081/</code>（<code>x.x.x.x</code>是执行<code>go tool pprof</code>命令所在服务器的IP地址），则会在浏览器显示各类采样视图数据，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/91/9d/91dab469d3d61dd4302d3ef5d483609d.png?wh=1920x679\" alt=\"图片\"></p><p>上面的UI页面提供了不同的采样数据视图：</p><ul>\n<li>Top，类似于 linux top 的形式，从高到低排序。</li>\n<li>Graph，默认弹出来的就是该模式，也就是上一个图的那种带有调用关系的图。</li>\n<li>Flame Graph：pprof 火焰图。</li>\n<li>Peek：类似于 Top 也是从高到底的排序。</li>\n<li>Source：和交互命令式的那种一样，带有源码标注。</li>\n<li>Disassemble：显示所有的总量。</li>\n</ul><p>接下来，我们主要来分析火焰图。在UI界面选择<strong>Flame Graph（VIEW -&gt; Flame Graph）</strong>，就会展示火焰图，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/33/e9/33e427f1a2419e0420e9ef8e9ddd69e9.png?wh=1920x609\" alt=\"图片\"></p><p>火焰图主要有下面这几个特征：</p><ul>\n<li>每一列代表一个调用栈，每一个格子代表一个函数。</li>\n<li>纵轴展示了栈的深度，按照调用关系从上到下排列。最下面的格子代表采样时，正在占用CPU的函数。</li>\n<li>调用栈在横向会按照字母排序，并且同样的调用栈会做合并，所以一个格子的宽度越大，说明这个函数越可能是瓶颈。</li>\n<li>火焰图格子的颜色是随机的暖色调，方便区分各个调用信息。</li>\n</ul><p>查看火焰图时，格子越宽的函数，就越可能存在性能问题，这时候，我们就可以分析该函数的代码，找出问题所在。</p><p><strong>方法三：用</strong><code>go tool pprof</code><strong>交互模式查看详细数据</strong></p><p>我们可以执行<code>go tool pprof</code>命令，来查看CPU的性能数据文件：</p><pre><code class=\"language-bash\">$ go tool pprof v1.test cpu.profile\nFile: v1.test\nType: cpu\nTime: Aug 17, 2021 at 2:17pm (CST)\nDuration: 56.48s, Total samples = 440ms ( 0.78%)\nEntering interactive mode (type \"help\" for commands, \"o\" for options)\n(pprof)\n</code></pre><p><code>go tool pprof</code>输出了很多信息：</p><ul>\n<li>File，二进制可执行文件名称。</li>\n<li>Type，采样文件的类型，例如cpu、mem等。</li>\n<li>Time，生成采样文件的时间。</li>\n<li>Duration，程序执行时间。上面的例子中，程序总执行时间为<code>37.43s</code>，采样时间为<code>42.37s</code>。采样程序在采样时，会自动分配采样任务给多个核心，所以总采样时间可能会大于总执行时间。</li>\n<li>(pprof)，命令行提示，表示当前在<code>go tool</code>的<code>pprof</code>工具命令行中，<code>go tool</code>还包括<code>cgo</code>、<code>doc</code>、<code>pprof</code>、<code>trace</code>等多种命令。</li>\n</ul><p>执行<code>go tool pprof</code>命令后，会进入一个交互shell。在这个交互shell中，我们可以执行多个命令，最常用的命令有三个，如下表所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/d1/98/d10a2c6cbfa4e35fc4efc9a3760d1b98.jpg?wh=1920x1196\" alt=\"图片\"></p><p>我们在交互界面中执行<code>top</code>命令，可以查看性能样本数据：</p><pre><code class=\"language-bash\">(pprof) top\nShowing nodes accounting for 350ms, 79.55% of 440ms total\nShowing top 10 nodes out of 47\n      flat  flat%   sum%        cum   cum%\n     110ms 25.00% 25.00%      110ms 25.00%  runtime.futex\n      70ms 15.91% 40.91%       90ms 20.45%  github.com/marmotedu/iam/internal/apiserver/store/fake.(*policies).List\n      40ms  9.09% 50.00%       40ms  9.09%  runtime.epollwait\n      40ms  9.09% 59.09%      180ms 40.91%  runtime.findrunnable\n      30ms  6.82% 65.91%       30ms  6.82%  runtime.write1\n      20ms  4.55% 70.45%       30ms  6.82%  runtime.notesleep\n      10ms  2.27% 72.73%      100ms 22.73%  github.com/marmotedu/iam/internal/apiserver/service/v1.(*userService).List\n      10ms  2.27% 75.00%       10ms  2.27%  runtime.checkTimers\n      10ms  2.27% 77.27%       10ms  2.27%  runtime.doaddtimer\n      10ms  2.27% 79.55%       10ms  2.27%  runtime.mallocgc\n</code></pre><p>上面的输出中，每一行表示一个函数的信息。pprof程序中最重要的命令就是topN，这个命令用来显示profile文件中最靠前的N个样本（sample），top命令会输出多行信息，每一行代表一个函数的采样数据，默认按<code>flat%</code>排序。输出中，各列含义如下：</p><ul>\n<li>flat：采样点落在该函数中的总时间。</li>\n<li>flat%：采样点落在该函数中时间的百分比。</li>\n<li>sum%：前面所有行的flat%的累加值，也就是上一项的累积百分比。</li>\n<li>cum：采样点落在该函数中的，以及被它调用的函数中的总时间。</li>\n<li>cum%：采样点落在该函数中的，以及被它调用的函数中的总次数百分比。</li>\n<li>函数名。</li>\n</ul><p>上面这些信息，可以告诉我们函数执行的时间和耗时排名，我们可以根据这些信息，来判断哪些函数可能有性能问题，或者哪些函数的性能可以进一步优化。</p><p>这里想提示下，如果执行的是<code>go tool pprof mem.profile</code>，那么上面的各字段意义是类似的，只不过这次不是时间而是内存分配大小（字节）。</p><p>执行<code>top</code>命令默认是按<code>flat%</code>排序的，在做性能分析时，我们需要先按照<code>cum</code>来排序，通过<code>cum</code>，我们可以直观地看到哪个函数总耗时最多，然后再参考该函数的本地采样时间和调用关系，来判断是该函数性能耗时多，还是它调用的函数耗时多。</p><p>执行<code>top -cum</code>输出如下：</p><pre><code class=\"language-bash\">(pprof) top20 -cum\nShowing nodes accounting for 280ms, 63.64% of 440ms total\nShowing top 20 nodes out of 47\n      flat  flat%   sum%        cum   cum%\n         0     0%     0%      320ms 72.73%  runtime.mcall\n         0     0%     0%      320ms 72.73%  runtime.park_m\n         0     0%     0%      280ms 63.64%  runtime.schedule\n      40ms  9.09%  9.09%      180ms 40.91%  runtime.findrunnable\n     110ms 25.00% 34.09%      110ms 25.00%  runtime.futex\n      10ms  2.27% 36.36%      100ms 22.73%  github.com/marmotedu/iam/internal/apiserver/service/v1.(*userService).List\n         0     0% 36.36%      100ms 22.73%  github.com/marmotedu/iam/internal/apiserver/service/v1.BenchmarkListUser\n         0     0% 36.36%      100ms 22.73%  runtime.futexwakeup\n         0     0% 36.36%      100ms 22.73%  runtime.notewakeup\n         0     0% 36.36%      100ms 22.73%  runtime.resetspinning\n         0     0% 36.36%      100ms 22.73%  runtime.startm\n         0     0% 36.36%      100ms 22.73%  runtime.wakep\n         0     0% 36.36%      100ms 22.73%  testing.(*B).launch\n         0     0% 36.36%      100ms 22.73%  testing.(*B).runN\n      70ms 15.91% 52.27%       90ms 20.45%  github.com/marmotedu/iam/internal/apiserver/store/fake.(*policies).List\n      10ms  2.27% 54.55%       50ms 11.36%  runtime.netpoll\n      40ms  9.09% 63.64%       40ms  9.09%  runtime.epollwait\n         0     0% 63.64%       40ms  9.09%  runtime.modtimer\n         0     0% 63.64%       40ms  9.09%  runtime.resetForSleep\n         0     0% 63.64%       40ms  9.09%  runtime.resettimer (inline)\n</code></pre><p>从上面的输出可知，<code>v1.BenchmarkListUser</code>、<code>testing.(*B).launch</code>、<code>testing.(*B).runN</code>的本地采样时间占比分别为<code>0%</code>、<code>0%</code>、<code>0%</code>，但是三者的累积采样时间占比却比较高，分别为<code>22.73%</code>、<code>22.73%</code>、<code>22.73%</code>。</p><p>本地采样时间占比很小，但是累积采样时间占比很高，说明这3个函数耗时多是因为调用了其他函数，它们自身几乎没有耗时。根据采样图，我们可以看到函数的调用关系，具体如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/b0/4c/b0b7624a7922cea801de63b865f6ed4c.jpg?wh=1920x437\" alt=\"图片\"></p><p>从采样图中，可以知道最终<code>v1.BenchmarkListUser</code>调用了<code>v1.(*userService).List</code>函数。<code>v1.(*userService).List</code>函数是我们编写的函数，该函数的本地采样时间占比为<code>2.27%</code>，但是累积采样时间占比却高达<code>22.73%</code>，说明<code>v1.(*userService).List</code>调用其他函数耗用了大量的CPU时间。</p><p>再观察采样图，可以看出<code>v1.(*userService).List</code>耗时久是因为调用了<code>fake.(*policies).List</code>函数。我们也可以通过<code>list</code>命令查看函数内部的耗时情况：</p><p><img src=\"https://static001.geekbang.org/resource/image/81/23/81765c7e56cb45d03a0a61de5835d823.png?wh=1920x576\" alt=\"图片\"></p><p><code>list userService.*List</code>会列出<code>userService</code>结构体<code>List</code>方法内部代码的耗时情况，从上图也可以看到，<code>u.store.Policies().List</code>耗时最多。<code>fake.(*policies).List</code>的本地采样时间占比为<code>15.91%</code>，说明<code>fake.(*policies).List</code>函数本身可能存在瓶颈。走读<code>fake.(*policies).List</code>代码可知，该函数是查询数据库的函数，查询数据库会有延时。继续查看<code>v1.(*userService).List</code>代码，我们可以发现以下调用逻辑：</p><pre><code class=\"language-go\">func (u *userService) ListWithBadPerformance(ctx context.Context, opts metav1.ListOptions) (*v1.UserList, error) {\n    ...\n    for _, user := range users.Items {\n        policies, err := u.store.Policies().List(ctx, user.Name, metav1.ListOptions{})\n        ...\n        })\n    }\n    ...\n}\n</code></pre><p>我们在<code>for</code>循环中，串行调用了<code>fake.(*policies).List</code>函数，每一次循环都会调用有延时的<code>fake.(*policies).List</code>函数。多次调用，<code>v1.(*userService).List</code>函数的耗时自然会累加起来。</p><p>现在问题找到了，那我们怎么优化呢？你可以利用CPU多核特性，开启多个goroutine，这样我们的查询耗时就不是串行累加的，而是取决于最慢一次的<code>fake.(*policies).List</code>调用。优化后的<code>v1.(*userService).List</code>函数代码见<a href=\"https://github.com/marmotedu/iam/blob/v1.0.8/internal/apiserver/service/v1/user.go#L43-L110\">internal/apiserver/service/v1/user.go</a>。用同样的性能测试用例，测试优化后的函数，结果如下：</p><pre><code class=\"language-bash\">$ go test -benchtime=30s -benchmem -bench=\".*\" -cpuprofile cpu.profile -memprofile mem.profile\ngoos: linux\ngoarch: amd64\npkg: github.com/marmotedu/iam/internal/apiserver/service/v1\ncpu: AMD EPYC Processor\nBenchmarkListUser-8   \t    8330\t   4271131 ns/op\t   26390 B/op\t     484 allocs/op\nPASS\nok  \tgithub.com/marmotedu/iam/internal/apiserver/service/v1\t36.179s\n</code></pre><p>上面的代码中，ns/op为<code>4271131 ns/op</code>，可以看到和第一次的测试结果<code>204523677 ns/op</code>相比，性能提升了<code>97.91%</code>。</p><p>这里注意下，为了方便你对照，我将优化前的<code>v1.(*userService).List</code>函数重命名为<code>v1.(*userService).ListWithBadPerformance</code>。</p><h3>内存性能分析</h3><p>Go语言运行时，系统会对程序运行期间的所有堆内存分配进行记录。不管在采样的哪一时刻，也不管堆内存已用字节数是否有增长，只要有字节被分配且数量足够，分析器就会对它进行采样。</p><p>内存性能分析方法和CPU性能分析方法比较类似，这里就不再重复介绍了。你可以借助前面生成的内存性能数据文件<code>mem.profile</code>自行分析。</p><p>接下来，给你展示下内存优化前和优化后的效果。在<code>v1.(*userService).List</code>函数（位于<a href=\"https://github.com/marmotedu/iam/blob/v1.0.8/internal/apiserver/service/v1/user.go#L43-L110\">internal/apiserver/service/v1/user.go</a>文件中）中，有以下代码：</p><pre><code class=\"language-go\">infos := make([]*v1.User, 0)\nfor _, user := range users.Items {\n    info, _ := m.Load(user.ID)\n    infos = append(infos, info.(*v1.User))\n}\n</code></pre><p>此时，我们运行<code>go test</code>命令，测试下内存性能，作为优化后的性能数据，进行对比：</p><pre><code class=\"language-bash\">$ go test -benchmem -bench=\".*\" -cpuprofile cpu.profile -memprofile mem.profile\ngoos: linux\ngoarch: amd64\npkg: github.com/marmotedu/iam/internal/apiserver/service/v1\ncpu: AMD EPYC Processor\nBenchmarkListUser-8   \t     278\t   4284660 ns/op\t   27101 B/op\t     491 allocs/op\nPASS\nok  \tgithub.com/marmotedu/iam/internal/apiserver/service/v1\t1.779s\n</code></pre><p><code>B/op</code>和<code>allocs/op</code>分别为<code>27101 B/op</code>和<code>491 allocs/op</code>。</p><p>我们通过分析代码，发现可以将<code>infos := make([]*v1.User, 0)</code>优化为<code>infos := make([]*v1.User, 0, len(users.Items))</code>，来减少Go切片的内存重新分配的次数。优化后的代码为：</p><pre><code class=\"language-go\">//infos := make([]*v1.User, 0)\ninfos := make([]*v1.User, 0, len(users.Items))\nfor _, user := range users.Items {\n    info, _ := m.Load(user.ID)\n    infos = append(infos, info.(*v1.User))\n}\n</code></pre><p>再执行<code>go test</code>测试下性能：</p><pre><code class=\"language-bash\">$ go test -benchmem -bench=\".*\" -cpuprofile cpu.profile -memprofile mem.profile\ngoos: linux\ngoarch: amd64\npkg: github.com/marmotedu/iam/internal/apiserver/service/v1\ncpu: AMD EPYC Processor\nBenchmarkListUser-8   \t     276\t   4318472 ns/op\t   26457 B/op\t     484 allocs/op\nPASS\nok  \tgithub.com/marmotedu/iam/internal/apiserver/service/v1\t1.856s\n</code></pre><p>优化后的<code>B/op</code>和<code>allocs/op</code>分别为<code>26457 B/op</code>和<code>484 allocs/op</code>。跟第一次的<code>27101 B/op</code>和<code>491 allocs/op</code>相比，内存分配次数更少，每次分配的内存也更少。</p><p>我们可以执行<code>go tool pprof</code>命令，来查看CPU的性能数据文件：</p><pre><code class=\"language-bash\">$ go tool pprof v1.test mem.profile\nFile: v1.test\nType: alloc_space\nTime: Aug 17, 2021 at 8:33pm (CST)\nEntering interactive mode (type \"help\" for commands, \"o\" for options)\n(pprof)\n</code></pre><p>该命令会进入一个交互界面，在交互界面中执行top命令，可以查看性能样本数据，例如：</p><pre><code class=\"language-bash\">(pprof) top\nShowing nodes accounting for 10347.32kB, 95.28% of 10859.34kB total\nShowing top 10 nodes out of 52\n      flat  flat%   sum%        cum   cum%\n 3072.56kB 28.29% 28.29%  4096.64kB 37.72%  github.com/marmotedu/iam/internal/apiserver/service/v1.(*userService).List.func1\n 1762.94kB 16.23% 44.53%  1762.94kB 16.23%  runtime/pprof.StartCPUProfile\n 1024.52kB  9.43% 53.96%  1024.52kB  9.43%  go.uber.org/zap/buffer.NewPool.func1\n 1024.08kB  9.43% 63.39%  1024.08kB  9.43%  time.Sleep\n  902.59kB  8.31% 71.70%   902.59kB  8.31%  compress/flate.NewWriter\n  512.20kB  4.72% 76.42%  1536.72kB 14.15%  github.com/marmotedu/iam/internal/apiserver/service/v1.(*userService).List\n  512.19kB  4.72% 81.14%   512.19kB  4.72%  runtime.malg\n  512.12kB  4.72% 85.85%   512.12kB  4.72%  regexp.makeOnePass\n  512.09kB  4.72% 90.57%   512.09kB  4.72%  github.com/marmotedu/iam/internal/apiserver/store/fake.FakeUsers\n  512.04kB  4.72% 95.28%   512.04kB  4.72%  runtime/pprof.allFrames\n</code></pre><p>上面的内存性能数据，各字段的含义依次是：</p><ul>\n<li>flat，采样点落在该函数中的总内存消耗。</li>\n<li>flat% ，采样点落在该函数中的百分比。</li>\n<li>sum% ，上一项的累积百分比。</li>\n<li>cum ，采样点落在该函数，以及被它调用的函数中的总内存消耗。</li>\n<li>cum%，采样点落在该函数，以及被它调用的函数中的总次数百分比。</li>\n<li>函数名。</li>\n</ul><h2>总结</h2><p>在Go项目开发中，程序性能低下时，我们需要分析出问题所在的代码。Go语言提供的 <code>go tool pprof</code> 工具可以支持我们分析代码的性能。我们可以通过两步来分析代码的性能，分别是生成性能数据文件和分析性能数据文件。</p><p>Go中可以用来生成性能数据文件的方式有三种：通过命令行生成性能数据文件、通过代码生成性能数据文件、通过 <code>net/http/pprof</code> 生成性能数据文件。</p><p>生成性能数据文件之后，就可以使用 <code>go tool pprof</code> 工具来分析性能数据文件了。我们可以分别获取到CPU和内存的性能数据，通过分析就可以找到性能瓶颈。有3种分析性能数据文件的方式，分别是分析采样图、分析火焰图和用 <code>go tool pprof</code> 交互模式查看详细数据。因为火焰图直观高效，所以我建议你多使用火焰图来分析性能。</p><h2>课后练习</h2><ol>\n<li>思考下，为什么“函数<code>runtime.goschedImpl</code>对函数<code>runtime.schedule</code>的调用时间必定小于等于函数<code>runtime.schedule</code>的累积采样时间”？</li>\n<li>你在Go项目开发中，还有哪些比较好的性能分析思路和方法？欢迎在留言区分享。</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"37 | 代码测试（下）：Go 语言其他测试类型及 IAM 测试介绍","id":409307},"right":{"article_title":"39｜性能分析（下）：API Server性能测试和调优实战","id":410920}}},{"article_id":410920,"article_title":"39｜性能分析（下）：API Server性能测试和调优实战","article_content":"<p>你好，我是孔令飞。</p><p>上一讲，我们学习了如何分析Go代码的性能。掌握了性能分析的基本知识之后，这一讲，我们再来看下如何分析API接口的性能。</p><p>在API上线之前，我们需要知道API的性能，以便知道API服务器所能承载的最大请求量、性能瓶颈，再根据业务对性能的要求，来对API进行性能调优或者扩缩容。通过这些，可以使API稳定地对外提供服务，并且让请求在合理的时间内返回。这一讲，我就介绍如何用wrk工具来测试API Server接口的性能，并给出分析方法和结果。</p><h2>API性能测试指标</h2><p>API性能测试，往大了说其实包括API框架的性能和指定API的性能。不过，因为指定API的性能跟该API具体的实现（比如有无数据库连接，有无复杂的逻辑处理等）有关，我认为脱离了具体实现来探讨单个API的性能是毫无意义的，所以这一讲只探讨API框架的性能。</p><p>用来衡量API性能的指标主要有3个：</p><ul>\n<li>并发数（Concurrent）：并发数是指某个时间范围内，同时在使用系统的用户个数。广义上的并发数是指同时使用系统的用户个数，这些用户可能调用不同的API；严格意义上的并发数是指同时请求同一个API的用户个数。这一讲我们讨论的并发数是严格意义上的并发数。</li>\n<li>每秒查询数（QPS）：每秒查询数QPS是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。QPS = 并发数 / 平均请求响应时间。</li>\n<li>请求响应时间（TTLB）：请求响应时间指的是从客户端发出请求到得到响应的整个时间。这个过程从客户端发起的一个请求开始，到客户端收到服务器端的响应结束。在一些工具中，请求响应时间通常会被称为TTLB（Time to last byte，意思是从发送一个请求开始，到客户端收到最后一个字节的响应为止所消费的时间）。请求响应时间的单位一般为“秒”或“毫秒”。</li>\n</ul><!-- [[[read_end]]] --><p>这三个指标中，衡量API性能的最主要指标是QPS，但是在说明QPS时，需要指明是多少并发数下的QPS，否则毫无意义，因为不同并发数下的QPS是不同的。举个例子，单用户100 QPS和100用户100 QPS是两个不同的概念，前者说明API可以在一秒内串行执行100个请求，而后者说明在并发数为100的情况下，API可以在一秒内处理100个请求。当QPS相同时，并发数越大，说明API性能越好，并发处理能力越强。</p><p>在并发数设置过大时，API同时要处理很多请求，会频繁切换上下文，而真正用于处理请求的时间变少，反而使得QPS会降低。并发数设置过大时，请求响应时间也会变长。API会有一个合适的并发数，在该并发数下，API的QPS可以达到最大，但该并发数不一定是最佳并发数，还要参考该并发数下的平均请求响应时间。</p><p>此外，在有些API接口中，也会测试API接口的TPS（Transactions Per Second，每秒事务数）。一个事务是指客户端向服务器发送请求，然后服务器做出反应的过程。客户端在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数。</p><p>那么，TPS和QPS有什么区别呢？如果是对一个查询接口（单场景）压测，且这个接口内部不会再去请求其他接口，那么TPS=QPS，否则，TPS≠QPS。如果是对多个接口（混合场景）压测，假设N个接口都是查询接口，且这个接口内部不会再去请求其他接口，QPS=N*TPS。</p><h2>API性能测试方法</h2><p>Linux下有很多Web性能测试工具，常用的有Jmeter、AB、Webbench和wrk。每个工具都有自己的特点，IAM项目使用wrk来对API进行性能测试。wrk非常简单，安装方便，测试结果也相对专业，并且可以支持Lua脚本来创建更复杂的测试场景。下面，我来介绍下wrk的安装方法和使用方法。</p><h3>wrk安装方法</h3><p>wrk的安装很简单，一共可分为两步。</p><p>第一步，Clone wrk repo：</p><pre><code class=\"language-bash\">$ git clone https://github.com/wg/wrk\n</code></pre><p>第二步，编译并安装：</p><pre><code class=\"language-bash\">$ cd wrk\n$ make\n$ sudo cp ./wrk /usr/bin\n</code></pre><h3>wrk使用简介</h3><p>这里我们来看下wrk的使用方法。wrk使用起来不复杂，执行<code>wrk --help</code>可以看到wrk的所有运行参数：</p><pre><code class=\"language-bash\">$ wrk --help\nUsage: wrk &lt;options&gt; &lt;url&gt;\n  Options:\n    -c, --connections &lt;N&gt;  Connections to keep open\n    -d, --duration    &lt;T&gt;  Duration of test\n    -t, --threads     &lt;N&gt;  Number of threads to use\n\n    -s, --script      &lt;S&gt;  Load Lua script file\n    -H, --header      &lt;H&gt;  Add header to request\n        --latency          Print latency statistics\n        --timeout     &lt;T&gt;  Socket/request timeout\n    -v, --version          Print version details\n\n  Numeric arguments may include a SI unit (1k, 1M, 1G)\n  Time arguments may include a time unit (2s, 2m, 2h)\n</code></pre><p>常用的参数有下面这些：</p><ul>\n<li>-t，线程数（线程数不要太多，是核数的2到4倍就行，多了反而会因为线程切换过多造成效率降低）。</li>\n<li>-c，并发数。</li>\n<li>-d，测试的持续时间，默认为10s。</li>\n<li>-T，请求超时时间。</li>\n<li>-H，指定请求的HTTP Header，有些API需要传入一些Header，可通过wrk的-H参数来传入。</li>\n<li>–latency，打印响应时间分布。</li>\n<li>-s，指定Lua脚本，Lua脚本可以实现更复杂的请求。</li>\n</ul><p>然后，我们来看一个wrk的测试结果，并对结果进行解析。</p><p>一个简单的测试如下（确保iam-apiserver已经启动，并且开启了健康检查）：</p><pre><code class=\"language-bash\">$ wrk -t144 -c30000 -d30s -T30s --latency http://10.0.4.57:8080/healthz\nRunning 30s test @ http://10.0.4.57:8080/healthz\n  144 threads and 30000 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency   508.77ms  604.01ms   9.27s    81.59%\n    Req/Sec   772.48      0.94k   10.45k    86.82%\n  Latency Distribution\n     50%  413.35ms\n     75%  948.99ms\n     90%    1.33s\n     99%    2.44s\n  2276265 requests in 30.10s, 412.45MB read\n  Socket errors: connect 1754, read 40, write 0, timeout 0\nRequests/sec:  75613.16\nTransfer/sec:     13.70MB\n</code></pre><p>下面是对测试结果的解析。</p><ul>\n<li>144 threads and 30000 connections：用144个线程模拟20000个连接，分别对应-t和-c参数。</li>\n<li>Thread Stats是线程统计，包括Latency和Req/Sec。\n<ul>\n<li>Latency：响应时间，有平均值、标准偏差、最大值、正负一个标准差占比。</li>\n<li>Req/Sec：每个线程每秒完成的请求数, 同样有平均值、标准偏差、最大值、正负一个标准差占比。</li>\n</ul>\n</li>\n<li>Latency Distribution是响应时间分布。\n<ul>\n<li>50%：50%的响应时间为413.35ms。</li>\n<li>75%：75%的响应时间为948.99ms。</li>\n<li>90%：90%的响应时间为1.33s。</li>\n<li>99%：99%的响应时间为2.44s。</li>\n</ul>\n</li>\n<li>2276265 requests in 30.10s, 412.45MB read：30.10s完成的总请求数（2276265）和数据读取量（412.45MB）。</li>\n<li>Socket errors: connect 1754, read 40, write 0, timeout 0：错误统计，会统计connect连接失败请求个数（1754）、读失败请求个数、写失败请求个数、超时请求个数。</li>\n<li>Requests/sec：QPS。</li>\n<li>Transfer/sec：平均每秒读取13.70MB数据（吞吐量）。</li>\n</ul><h2>API Server性能测试实践</h2><p>接下来，我们就来测试下API Server的性能。影响API Server性能的因素有很多，除了iam-apiserver自身的原因之外，服务器的硬件和配置、测试方法、网络环境等都会影响。为了方便你对照性能测试结果，我给出了我的测试环境配置，你可以参考下。</p><ul>\n<li>客户端硬件配置：1核4G。</li>\n<li>客户端软件配置：干净的<code>CentOS&nbsp;Linux&nbsp;release&nbsp;8.2.2004&nbsp;(Core)</code>。</li>\n<li>服务端硬件配置：2核8G。</li>\n<li>服务端软件配置：干净的<code>CentOS&nbsp;Linux&nbsp;release&nbsp;8.2.2004&nbsp;(Core)</code>。</li>\n<li>测试网络环境：腾讯云VPC内访问，除了性能测试程序外，没有其他资源消耗型业务程序。</li>\n</ul><p>测试架构如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/7d/c4/7df51487bc7b761d79247a5d547745c4.jpg?wh=2248x575\" alt=\"\"></p><h3>性能测试脚本介绍</h3><p>在做API Server的性能测试时，需要先执行wrk，生成性能测试数据。为了能够更直观地查看性能数据，我们还需要以图表的方式展示这些性能数据。这一讲，我使用 <code>gnuplot</code> 工具来自动化地绘制这些性能图，为此我们需要确保Linux服务器已经安装了 <code>gnuplot</code> 工具。你可以通过以下方式安装：</p><pre><code class=\"language-bash\">$ sudo yum -y install gnuplot\n</code></pre><p>在这一讲的测试中，我会绘制下面这两张图，通过它们来观测和分析API Server的性能。</p><ul>\n<li>QPS &amp; TTLB图：<code>X</code>轴为并发数（Concurrent），<code>Y</code>轴为每秒查询数（QPS）和请求响应时间（TTLB）。</li>\n<li>成功率图：<code>X</code>轴为并发数（Concurrent），<code>Y</code>轴为请求成功率。</li>\n</ul><p>为了方便你测试API接口性能，我将性能测试和绘图逻辑封装在<a href=\"https://github.com/marmotedu/iam/blob/v1.0.8/scripts/wrktest.sh\">scripts/wrktest.sh</a>脚本中，你可以在iam源码根目录下执行如下命令，生成性能测试数据和性能图表：</p><pre><code class=\"language-bash\">$ scripts/wrktest.sh http://10.0.4.57:8080/healthz\n</code></pre><p>上面的命令会执行性能测试，记录性能测试数据，并根据这些性能测试数据绘制出QPS和成功率图。</p><p>接下来，我再来介绍下wrktest.sh性能测试脚本，并给出一个使用示例。</p><p>wrktest.sh性能测试脚本，用来测试API Server的性能，记录测试的性能数据，并根据性能数据使用gnuplot绘制性能图。</p><p>wrktest.sh也可以对比前后两次的性能测试结果，并将对比结果通过图表展示出来。wrktest.sh会根据CPU的核数自动计算出适合的wrk启动线程数（<code>-t</code>）：<code>CPU核数 * 3</code>。</p><p>wrktest.sh默认会测试多个并发下的API性能，默认测试的并发数为<code>200 500 1000 3000 5000 10000 15000 20000 25000 50000</code>。你需要根据自己的服务器配置选择测试的最大并发数，我因为服务器配置不高（主要是<code>8G</code>内存在高并发下，很容易就耗尽），最大并发数选择了<code>50000</code>。如果你的服务器配置够高，可以再依次尝试下测试 <code>100000</code> 、<code>200000</code> 、<code>500000</code> 、<code>1000000</code> 并发下的API性能。</p><p>wrktest.sh的使用方法如下：</p><pre><code class=\"language-bash\">$ scripts/wrktest.sh -h\n\nUsage: scripts/wrktest.sh [OPTION] [diff] URL\nPerformance automation test script.\n\n  URL                    HTTP request url, like: http://10.0.4.57:8080/healthz\n  diff                   Compare two performance test results\n\nOPTIONS:\n  -h                     Usage information\n  -n                     Performance test task name, default: apiserver\n  -d                     Directory used to store performance data and gnuplot graphic, default: _output/wrk\n\nReprot bugs to &lt;colin404@foxmail.com&gt;.\n</code></pre><p>wrktest.sh提供的命令行参数介绍如下。</p><ul>\n<li>URL：需要测试的API接口。</li>\n<li>diff：如果比较两次测试的结果，需要执行wrktest.sh diff <data1> <data2>。</data2></data1></li>\n<li>-n：本次测试的任务名，wrktest.sh会根据任务名命名生成的文件。</li>\n<li>-d：输出文件存放目录。</li>\n<li>-h：打印帮助信息。</li>\n</ul><p>下面，我来展示一个wrktest.sh使用示例。</p><p>wrktest.sh的主要功能有两个，分别是运行性能测试并获取结果和对比性能测试结果。下面我就分别介绍下它们的具体使用方法。</p><ol>\n<li>运行性能测试并获取结果</li>\n</ol><p>执行如下命令：</p><pre><code class=\"language-bash\">$ scripts/wrktest.sh http://10.0.4.57:8080/healthz\nRunning wrk command: wrk -t3 -d300s -T30s --latency -c 200 http://10.0.4.57:8080/healthz\nRunning wrk command: wrk -t3 -d300s -T30s --latency -c 500 http://10.0.4.57:8080/healthz\nRunning wrk command: wrk -t3 -d300s -T30s --latency -c 1000 http://10.0.4.57:8080/healthz\nRunning wrk command: wrk -t3 -d300s -T30s --latency -c 3000 http://10.0.4.57:8080/healthz\nRunning wrk command: wrk -t3 -d300s -T30s --latency -c 5000 http://10.0.4.57:8080/healthz\nRunning wrk command: wrk -t3 -d300s -T30s --latency -c 10000 http://10.0.4.57:8080/healthz\nRunning wrk command: wrk -t3 -d300s -T30s --latency -c 15000 http://10.0.4.57:8080/healthz\nRunning wrk command: wrk -t3 -d300s -T30s --latency -c 20000 http://10.0.4.57:8080/healthz\nRunning wrk command: wrk -t3 -d300s -T30s --latency -c 25000 http://10.0.4.57:8080/healthz\nRunning wrk command: wrk -t3 -d300s -T30s --latency -c 50000 http://10.0.4.57:8080/healthz\n\nNow plot according to /home/colin/_output/wrk/apiserver.dat\nQPS graphic file is: /home/colin/_output/wrk/apiserver_qps_ttlb.png\nSuccess rate graphic file is: /home/colin/_output/wrk/apiserver_successrate.pngz\n</code></pre><p>上面的命令默认会在<code>_output/wrk/</code>目录下生成3个文件：</p><ul>\n<li>apiserver.dat，wrk性能测试结果，每列含义分别为并发数、QPS 平均响应时间、成功率。</li>\n<li>apiserver_qps_ttlb.png，QPS&amp;TTLB图。</li>\n<li>apiserver_successrate.png，成功率图。</li>\n</ul><p>这里要注意，请求URL中的IP地址应该是腾讯云VPC内网地址，因为通过内网访问，不仅网络延时最低，而且还最安全，所以真实的业务通常都是内网访问的。</p><ol start=\"2\">\n<li>对比性能测试结果</li>\n</ol><p>假设我们还有另外一次API性能测试，测试数据保存在 <code>_output/wrk/http.dat</code> 文件中。</p><p>执行如下命令，对比两次测试结果：</p><pre><code class=\"language-bash\">$ scripts/wrktest.sh diff _output/wrk/apiserver.dat _output/wrk/http.dat\n</code></pre><p><code>apiserver.dat</code>和<code>http.dat</code>是两个需要对比的Wrk性能数据文件。上述命令默认会在<code>_output/wrk</code>目录下生成下面这两个文件：</p><ul>\n<li>apiserver_http.qps.ttlb.diff.png，QPS &amp; TTLB对比图。</li>\n<li>apiserver_http.success_rate.diff.png，成功率对比图。</li>\n</ul><h3>关闭Debug配置选项</h3><p>在测试之前，我们需要关闭一些Debug选项，以免影响性能测试。</p><p>执行下面这两步操作，修改iam-apiserver的配置文件：</p><ul>\n<li>将<code>server.mode</code>设置为release，<code>server.middlewares</code>去掉dump、logger中间件。</li>\n<li>将<code>log.level</code>设置为info，<code>log.output-paths</code>去掉stdout。</li>\n</ul><p>因为我们要在执行压力测试时分析程序的性能，所以需要设置<code>feature.profiling</code>为true，以开启性能分析。修改完之后，重新启动iam-apiserver。</p><h3>使用wrktest.sh测试IAM API接口性能</h3><p>关闭Debug配置选项之后，就可以执行<code>wrktest.sh</code>命令测试API性能了（默认测试的并发数为<code>200 500 1000 3000 5000 10000 15000 20000 25000 50000</code>）:</p><pre><code class=\"language-bash\">$ scripts/wrktest.sh http://10.0.4.57:8080/healthz\n</code></pre><p>生成的QPS &amp; TTLB图和成功率图分别如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/0a/0f/0aca3648e72974c5a32c2fbcfea8670f.png?wh=640x480\" alt=\"图片\" title=\"QPS &amp;平均响应时间图\"></p><p>上图中，<code>X</code>轴为并发数（Concurrent），<code>Y</code>轴为每秒查询数（QPS）和请求响应时间（TTLB）。</p><p><img src=\"https://static001.geekbang.org/resource/image/a2/5d/a2d7866536ee96327a10614dd332475d.png?wh=640x480\" alt=\"\" title=\"成功率图\"></p><p>上图中，<code>X</code>轴为并发数（Concurrent），<code>Y</code>轴为请求成功率。</p><p>通过上面两张图，你可以看到，API Server在并发数为<code>200</code>时，QPS最大；并发数为<code>500</code>，平均响应时间为<code>56.33ms</code>，成功率为 <code>100.00%</code> 。在并发数达到<code>1000</code>时，成功率开始下降。一些详细数据从图里看不到，你可以直接查看<code>apiserver.dat</code>文件，里面记录了每个并发下具体的QPS、TTLB和成功率数据。</p><p>现在我们有了API Server的性能数据，那么该API Server的QPS处于什么水平呢？一方面，你可以根据自己的业务需要来对比；另一方面，可以和性能更好的Web框架进行对比，总之需要有个参照。</p><p>这里用net/http构建最简单的HTTP服务器，使用相同的测试工具和测试服务器，测试性能并作对比。HTTP服务源码为（位于文件<a href=\"https://github.com/marmotedu/iam/blob/v1.0.8/tools/httptest/main.go\">tools/httptest/main.go</a>中）：</p><pre><code class=\"language-go\">package main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"net/http\"\n)\n\nfunc main() {\n\thttp.HandleFunc(\"/healthz\", func(w http.ResponseWriter, r *http.Request) {\n\t\tmessage := `{\"status\":\"ok\"}`\n\t\tfmt.Fprint(w, message)\n\t})\n\n\taddr := \":6667\"\n\tfmt.Printf(\"Serving http service on %s\\n\", addr)\n\tlog.Fatal(http.ListenAndServe(addr, nil))\n}\n</code></pre><p>我们将上述HTTP服务的请求路径设置为<code>/healthz</code>，并且返回<code>{\"status\":\"ok\"}</code>，跟API Server的接口返回数据完全一样。通过这种方式，你可以排除因为返回数据大小不同而造成的性能差异。</p><p>可以看到，该HTTP服务器很简单，只是利用<code>net/http</code>包最原生的功能，在Go中几乎所有的Web框架都是基于<code>net/http</code>包封装的。既然是封装，肯定比不上原生的性能，所以我们要把它跟用<code>net/http</code>直接启动的HTTP服务接口的性能进行对比，来衡量我们的API Server性能。</p><p>我们需要执行相同的wrk测试，并将结果跟API Server的测试结果进行对比，将对比结果绘制成对比图。具体对比过程可以分为3步。</p><p>第一步，启动HTTP服务。</p><p>在iam源码根目录下执行如下命令：</p><pre><code class=\"language-bash\">$ go run tools/httptest/main.go\n</code></pre><p>第二步，执行<code>wrktest.sh</code>脚本，测试该HTTP服务的性能：</p><pre><code class=\"language-bash\">$ scripts/wrktest.sh -n http http://10.0.4.57:6667/healthz\n</code></pre><p>上述命令会生成  <code>_output/wrk/http.dat</code> 文件。</p><p>第三步，对比两次性能测试数据：</p><pre><code class=\"language-bash\">$ scripts/wrktest.sh diff _output/wrk/apiserver.dat _output/wrk/http.dat\n</code></pre><p>生成的两张对比图表，如下所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/51/f4/51eacf20d190080bf8b42e2f43yy00f4.png?wh=640x480\" alt=\"图片\" title=\"QPS &amp;平均响应时间对比\"></p><p><img src=\"https://static001.geekbang.org/resource/image/e1/99/e1cc646da40036a44e5300ed2bef8999.png?wh=640x480\" alt=\"图片\" title=\"成功率对比\"></p><p>通过上面两张对比图，我们可以看出，API Server在QPS、响应时间和成功率上都不如原生的HTTP Server，特别是QPS，最大QPS只有原生HTTP Server 最大QPS的<code>13.68%</code>，性能需要调优。</p><h2>API Server性能分析</h2><p>上面，我们测试了API接口的性能，如果性能不合预期，我们还需要分析性能数据，并优化性能。</p><p>在分析前我们需要对API Server加压，在加压的情况下，API接口的性能才更可能暴露出来，所以继续执行如下命令：</p><pre><code class=\"language-bash\">$ scripts/wrktest.sh http://10.0.4.57:8080/healthz\n</code></pre><p>在上述命令执行压力测试期间，可以打开另外一个Linux终端，使用<code>go tool pprof</code>工具分析HTTP的profile文件：</p><pre><code class=\"language-bash\">$ go tool pprof http://10.0.4.57:8080/debug/pprof/profile\n</code></pre><p>执行完<code>go tool pprof</code>后，因为需要采集性能数据，所以该命令会阻塞30s。</p><p>在pprof交互shell中，执行<code>top -cum</code>查看累积采样时间，我们执行<code>top30 -cum</code>，多观察一些函数：</p><pre><code class=\"language-bash\">(pprof) top20 -cum\nShowing nodes accounting for 32.12s, 39.62% of 81.07s total\nDropped 473 nodes (cum &lt;= 0.41s)\nShowing top 20 nodes out of 167\n(pprof) top30 -cum\nShowing nodes accounting for 11.82s, 20.32% of 58.16s total\nDropped 632 nodes (cum &lt;= 0.29s)\nShowing top 30 nodes out of 239\n      flat  flat%   sum%        cum   cum%\n     0.10s  0.17%  0.17%     51.59s 88.70%  net/http.(*conn).serve\n     0.01s 0.017%  0.19%     42.86s 73.69%  net/http.serverHandler.ServeHTTP\n     0.04s 0.069%  0.26%     42.83s 73.64%  github.com/gin-gonic/gin.(*Engine).ServeHTTP\n     0.01s 0.017%  0.28%     42.67s 73.37%  github.com/gin-gonic/gin.(*Engine).handleHTTPRequest\n     0.08s  0.14%  0.41%     42.59s 73.23%  github.com/gin-gonic/gin.(*Context).Next (inline)\n     0.03s 0.052%  0.46%     42.58s 73.21%  .../internal/pkg/middleware.RequestID.func1\n         0     0%  0.46%     41.02s 70.53%  .../internal/pkg/middleware.Context.func1\n     0.01s 0.017%  0.48%     40.97s 70.44%  github.com/gin-gonic/gin.CustomRecoveryWithWriter.func1\n     0.03s 0.052%  0.53%     40.95s 70.41%  .../internal/pkg/middleware.LoggerWithConfig.func1\n     0.01s 0.017%  0.55%     33.46s 57.53%  .../internal/pkg/middleware.NoCache\n     0.08s  0.14%  0.69%     32.58s 56.02%  github.com/tpkeeper/gin-dump.DumpWithOptions.func1\n     0.03s 0.052%  0.74%     24.73s 42.52%  github.com/tpkeeper/gin-dump.FormatToBeautifulJson\n     0.02s 0.034%  0.77%     22.73s 39.08%  github.com/tpkeeper/gin-dump.BeautifyJsonBytes\n     0.08s  0.14%  0.91%     16.39s 28.18%  github.com/tpkeeper/gin-dump.format\n     0.21s  0.36%  1.27%     16.38s 28.16%  github.com/tpkeeper/gin-dump.formatMap\n     3.75s  6.45%  7.72%     13.71s 23.57%  runtime.mallocgc\n     ...\n</code></pre><p>因为<code>top30</code>内容过多，这里只粘贴了耗时最多的一些关联函数。从上面的列表中，可以看到有ServeHTTP类的函数，这些函数是gin/http自带的函数，我们无需对此进行优化。</p><p>还有这样一些函数：</p><pre><code class=\"language-go\">.../gin.(*Context).Next (inline)\n.../internal/pkg/middleware.RequestID.func1\n.../internal/pkg/middleware.Context.func1\ngithub.com/gin-gonic/gin.CustomRecoveryWithWriter.func1\n.../internal/pkg/middleware.LoggerWithConfig.func1\n.../internal/pkg/middleware.NoCache\ngithub.com/tpkeeper/gin-dump.DumpWithOptions.func1\n</code></pre><p>可以看到，<code>middleware.RequestID.func1</code>、<code>middleware.Context.func1</code>、<code>gin.CustomRecoveryWithWriter.func1</code>、<code>middleware.LoggerWithConfig.func1</code>等，这些耗时较久的函数都是我们加载的Gin中间件。这些中间件消耗了大量的CPU时间，所以我们可以选择性加载这些中间件，删除一些不需要的中间件，来优化API Server的性能。<br>\n假如我们暂时不需要这些中间件，也可以通过配置iam-apiserver的配置文件，将<code>server.middlewares</code>设置为空或者注释掉，然后重启iam-apiserver。重启后，再次执行<code>wrktest.sh</code>测试性能，并跟原生的HTTP Server性能进行对比，对比结果如下面2张图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/7b/c2/7bc94be0d44a5ac54cd0e199d2612ec2.png?wh=640x480\" alt=\"图片\" title=\"QPS &amp;平均响应时间对比\"></p><p><img src=\"https://static001.geekbang.org/resource/image/88/a7/88e9fdfe7ba14061e979d0195b45cca7.png?wh=640x480\" alt=\"图片\" title=\"成功率对比\"></p><p>可以看到，删除无用的Gin中间件后，API Server的性能有了很大的提升，并发数为<code>200</code>时性能最好，此时QPS为<code>47812</code>，响应时间为<code>4.33``ms</code>，成功率为<code>100.00``%</code>。在并发数为<code>50000</code>的时候，其QPS是原生HTTP Server的<code>75.02%</code>。</p><h3>API接口性能参考</h3><p>不同团队对API接口的性能要求不同，同一团队对每个API接口的性能要求也不同，所以并没有一个统一的数值标准来衡量API接口的性能，但可以肯定的是，性能越高越好。我根据自己的研发经验，在这里给出一个参考值（并发数可根据需要选择），如下表所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/58/7c/581fc922afedaf36379c5a5d723ebd7c.jpg?wh=2248x585\" alt=\"\"></p><h2>API Server性能测试注意事项</h2><p>在进行API Server性能测试时，要考虑到API Server的性能影响因素。影响API Server性能的因素很多，大致可以分为两类，分别是Web框架的性能和API接口的性能。另外，在做性能测试时，还需要确保测试环境是一致的，最好是一个干净的测试环境。</p><h3>Web框架性能</h3><p>Web框架的性能至关重要，因为它会影响我们的每一个API接口的性能。</p><p>在设计阶段，我们会确定所使用的Web框架，这时候我们需要对Web框架有个初步的测试，确保我们选择的Web框架在性能和稳定性上都足够优秀。当整个Go后端服务开发完成之后，在上线之前，我们还需要对Web框架再次进行测试，确保按照我们最终的使用方式，Web框架仍然能够保持优秀的性能和稳定性。</p><p>我们通常会通过API接口来测试Web框架的性能，例如健康检查接口<code>/healthz</code>。我们需要保证该API接口足够简单，API接口里面不应该掺杂任何逻辑，只需要象征性地返回一个很小的返回内容即可。比如，这一讲中我们通过<code>/healthz</code>接口来测试Web框架的性能：</p><pre><code class=\"language-go\">s.GET(\"/healthz\", func(c *gin.Context) {\n    core.WriteResponse(c, nil, map[string]string{\"status\": \"ok\"})\n})\n</code></pre><p>接口中只调用了<code>core.WriteResponse</code>函数，返回了<code>{\"status\":\"ok\"}</code>。这里使用<code>core.WriteResponse</code>函数返回请求数据，而不是直接返回<code>ok</code>字符串，这样做是为了保持API接口返回格式统一。</p><h3>API接口性能</h3><p>除了测试Web框架的性能，我们还可能需要测试某些重要的API接口，甚至所有API接口的性能。为了测试API接口在真实场景下的接口性能，我们会使用wrk这类HTTP压力测试工具，来模拟多个API请求，进而分析API的性能。</p><p>因为会模拟大量的请求，这时候测试写类接口，例如<code>Create</code>、<code>Update</code>、<code>Delete</code>等会存在一些问题，比如可能在数据库中插入了很多数据，导致磁盘空间被写满或者数据库被压爆。所以，针对写类接口，我们可以借助单元测试，来测试其性能。根据我的开发经验，写类接口通常不会有性能问题，反而读类接口更可能遇到性能问题。针对读类接口，我们可以使用wrk这类HTTP压力测试工具来进行测试。</p><h3>测试环境</h3><p>在做性能/压力测试时，为了不影响生产环境，要确保在测试环境进行压测，并且测试环境的网络不能影响到生产环境的网络。另外，为了更好地进行性能对比和分析，也要保证我们的测试方法和测试环境是一致的。这就要求我们最好将性能测试自动化，并且每次在同一个测试环境进行测试。</p><h2>总结</h2><p>在项目上线前，我们需要对API接口进行性能测试。通常API接口的性能延时要小于 <code>500ms</code> ，如果大于这个值，需要考虑优化性能。在进行性能测试时，需要确保每次测试都有一个一致的测试环境，这样不同测试之间的数据才具有可对比性。这一讲中，我推荐了一个比较优秀的性能测试工具 <code>wrk</code> ，我们可以编写shell脚本，将wrk的性能测试数据自动绘制成图，方便我们查看、对比性能。</p><p>如果发现API接口的性能不符合预期，我们可以借助 <code>go tool pprof</code> 工具来分析性能。在 <code>go tool pprof</code> 交互界面，执行 <code>top -cum</code> 命令查看累积采样时间，根据累积采样时间确定影响性能的代码，并优化代码。优化后，再进行测试，如果不满足，继续分析API接口的性能。如此往复，直到API接口的性能满足预期为止。</p><h2>课后练习</h2><ol>\n<li>选择一个项目，并使用wrktest.sh脚本测试其API接口，分析并优化API接口的性能。</li>\n<li>思考下，在你的工作中，还有没有其他好的API接口性能分析方法，欢迎在留言区分享讨论。</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"38｜性能分析（上）：如何分析 Go 语言代码的性能？","id":410205},"right":{"article_title":"40 | 软件部署实战（上）：部署方案及负载均衡、高可用组件介绍","id":411663}}},{"article_id":411663,"article_title":"40 | 软件部署实战（上）：部署方案及负载均衡、高可用组件介绍","article_content":"<p>你好，我是孔令飞。</p><p>接下来，我们就进入到这门课的最后一个模块，服务部署部分的学习。在这一模块中，我会带着你一步一步地部署一个生产级可用的IAM应用。</p><p>在 <a href=\"https://time.geekbang.org/column/article/378082\">03讲</a> 中，我们快速在单机上部署了IAM系统，但这样的系统缺少高可用、弹性扩容等能力，是很脆弱的，遇到流量波峰、发布变更很容易出问题。在系统真正上线前，我们需要重新调整部署架构，来保证我们的系统具有负载均衡、高可用、弹性伸缩等核心运维能力。</p><p>考虑到你手中的系统资源有限，这一模块会尽量简单地展示如何部署一个相对高可用的IAM系统。按照我讲的部署方法，基本上可以上线一个中小型的系统。</p><p>在这一模块中，我会介绍两种部署方式。</p><p>第一种是传统的部署方式，基于物理机/虚拟机来部署，容灾、弹性伸缩能力要部署人员自己实现。第二种是容器化部署方式，基于Docker、Kubernetes来部署，容灾、弹性伸缩等能力，可以借助Kubernetes自带的能力来实现。</p><p>接下来的三讲，我们先来看下传统的部署方式，也就是如何基于虚拟机来部署IAM应用。今天我主要讲跟IAM部署相关的两个组件，Nginx + Keepalived的相关功能。</p><h2>部署方案</h2><p>先来整体看下我们的部署方案。</p><p>这里，我采用Nginx + Keepalived来部署一个高可用的架构，同时将组件都部署在内网，来保证服务的安全和性能。</p><!-- [[[read_end]]] --><p>部署需要两台物理机/虚拟机，组件之间通过内网访问。所需的服务器如下表所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/e0/1d/e0a3323831768fbe7f45085ca4a53a1d.jpg?wh=1920x719\" alt=\"图片\"></p><p>两台服务器均为腾讯云CVM，VIP（Virtual IP，虚拟IP）为<code>10.0.4.99</code>。部署架构如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/fc/9d/fc5331a780d45a7de6223d6ff3c86f9d.jpg?wh=1920x1197\" alt=\"图片\"></p><p>这里我来具体介绍下图中的部署架构。部署采用的这两台CVM服务器，一主一备，它们共享同一个VIP。同一时刻，VIP只在一台主设备上生效，当主服务器出现故障时，备用服务器会自动接管VIP，继续提供服务。</p><p>主服务器上部署了<code>iam-apiserver</code>、<code>iam-authz-server</code>、<code>iam-pump</code>和数据库<code>mongodb</code>、<code>redis</code>、<code>mysql</code>。备服务器部署了<code>iam-apiserver</code>、<code>iam-authz-server</code>和<code>iam-pump</code>。备服务器中的组件通过内网<code>10.0.4.20</code>访问主服务器中的数据库组件。</p><p>主备服务器同时安装了Keepalived和Nginx，通过Nginx的反向代理功能和负载均衡功能，实现后端服务<code>iam-apiserver</code>和<code>iam-authz-server</code>的高可用，通过Keepalived实现Nginx的高可用。</p><p>我们通过给虚拟IP绑定腾讯云弹性公网IP，从而使客户端可以通过外网IP访问内网的Nginx服务器（<code>443</code>端口），如果想通过域名访问内网，还可以申请域名指向该弹性公网IP。</p><p>通过以上部署方案，我们可以实现一个具有较高可用性的IAM系统，它主要具备下面这几个能力。</p><ul>\n<li>高性能：可以通过Nginx的负载均衡功能，水平扩容IAM服务，从而实现高性能。</li>\n<li>具备容灾能力：通过Nginx实现IAM服务的高可用，通过Keepalived实现Nginx的高可用，从而实现核心组件的高可用。</li>\n<li>具备水平扩容能力：通过Nginx的负载均衡功能，实现IAM服务的水平扩容。</li>\n<li>高安全性：将所有组件部署在内网，客户端只能通过<code>VIP:443</code>端口访问Nginx服务，并且通过开启TLS认证和JWT认证，保障服务有一个比较高的安全性。因为是腾讯云CVM，所以也可以借助腾讯云的能力再次提高服务器的安全性，比如安全组、DDoS防护、主机安全防护、云监控、云防火墙等。</li>\n</ul><p>这里说明下，为了简化IAM应用的安装配置过程，方便你上手实操，有些能力，例如数据库高可用、进程监控和告警、自动伸缩等能力的构建方式，这里没有涉及到。这些能力的构建方式，你可以在日后的工作中慢慢学习和掌握。</p><p>接下来，我们看下这个部署方案中用到的两个核心组件，Nginx和Keepalived。我会介绍下它们的安装和配置方法，为你下一讲的学习做准备。</p><h2>Nginx安装和配置</h2><h3>Nginx功能简介</h3><p>这里先简单介绍下Nginx。Nginx是一个轻量级、高性能、开源的HTTP服务器和反向代理服务器。IAM系统使用了Nginx反向代理和负载均衡的功能，下面我就来分别介绍下。</p><p>为什么需要反向代理呢？在实际的生产环境中，服务部署的网络（内网）跟外部网络（外网）通常是不通的，这就需要一台既能够访问内网又能够访问外网的服务器来做中转，这种服务器就是反向代理服务器。Nginx作为反向代理服务器，简单的配置如下：</p><pre><code class=\"language-plain\">server {\n&nbsp; &nbsp; listen&nbsp; &nbsp; &nbsp; 80;\n&nbsp; &nbsp; server_name&nbsp; iam.marmotedu.com;\n&nbsp; &nbsp; client_max_body_size 1024M;\n\n&nbsp; &nbsp; location / {\n&nbsp; &nbsp; &nbsp; &nbsp; proxy_set_header Host $http_host;\n&nbsp; &nbsp; &nbsp; &nbsp; proxy_set_header X-Forwarded-Host $http_host;\n&nbsp; &nbsp; &nbsp; &nbsp; proxy_set_header X-Real-IP $remote_addr;\n&nbsp; &nbsp; &nbsp; &nbsp; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n&nbsp; &nbsp; &nbsp; &nbsp; proxy_pass&nbsp; http://127.0.0.1:8080/;\n&nbsp; &nbsp; &nbsp; &nbsp; client_max_body_size 100m;\n&nbsp; &nbsp; }\n}\n</code></pre><p>Nginx的反向代理功能，能够根据不同的配置规则转发到不同的后端服务器上。假如我们在IP为<code>x.x.x.x</code>的服务器上，用上面说的Nginx配置启动Nginx，当我们访问<code>http://x.x.x.x:80/</code>时，会将请求转发到<code>http://127.0.0.1:8080/</code>。<code>listen      80</code>指定了Nginx服务器的监听端口，<code>proxy_pass  http://127.0.0.1:8080/</code>则指定了转发路径。</p><p>Nginx另一个常用的功能是七层负载均衡。所谓的负载均衡，就是指当Nginx收到一个HTTP请求后，会根据负载策略将请求转发到不同的后端服务器上。比如iam-apiserver部署在两台服务器A和B上，当请求到达Nginx后，Nginx会根据A和B服务器上的负载情况，将请求转发到负载较小的那台服务器上。</p><p>这里要求iam-apiserver是无状态的服务。Nginx有多种负载均衡策略，可以满足不同场景下的负载均衡需求。</p><h3><strong>Nginx安装步骤</strong></h3><p>接下来，我就来介绍下如何安装和配置Nginx。</p><p>我们分别在<code>10.0.4.20</code>和<code>10.0.4.21</code>服务器上执行如下步骤，安装Nginx。</p><p>在CentOS 8.x系统上，我们可以使用yum命令来安装，具体安装过程可以分为下面4个步骤。</p><p>第一步，安装Nginx：</p><pre><code class=\"language-bash\">$ sudo yum -y install nginx\n</code></pre><p>第二步，确认Nginx安装成功：</p><pre><code class=\"language-bash\">$ nginx -v\nnginx version: nginx/1.14.1\n</code></pre><p>第三步，启动Nginx，并设置开机启动：</p><pre><code class=\"language-bash\">$ sudo systemctl start nginx\n$ sudo systemctl enable nginx\n</code></pre><p>Nginx默认监听<code>80</code>端口，启动Nginx前要确保<code>80</code>端口没有被占用。当然，你也可以通过修改Nginx配置文件<code>/etc/nginx/nginx.conf</code>修改Nginx监听端口。</p><p>第四步，查看Nginx启动状态：</p><pre><code class=\"language-bash\">$ systemctl status nginx\n</code></pre><p>输出中有<code>active (running)</code>字符串，说明成功启动。如果Nginx启动失败，你可以查看<code>/var/log/nginx/error.log</code>日志文件，定位错误原因。</p><h2>Keepalived安装和配置</h2><p>Nginx自带负载均衡功能，并且当Nginx后端某个服务器故障后，Nginx会自动剔除该服务器，将请求转发到可用的服务器，通过这种方式实现后端API服务的高可用。但是 Nginx是单点的，如果Nginx挂了，后端的所有服务器就都不能访问，所以在实际生产环境中，也需要对Nginx做高可用。</p><p>业界最普遍采用的方法是通过Keepalived对前端Nginx实现高可用。Keepalived + Nginx的高可用方案具有服务功能强大、维护简单等特点。</p><p>接下来，我们来看下如何安装和配置Keepalived。</p><h3>Keepalived安装步骤</h3><p>我们分别在<code>10.0.4.20</code>和<code>10.0.4.21</code>服务器上执行下面5个步骤，安装Keepalived。</p><p>第一步，下载Keepalived的最新版本（这门课安装了当前的最新版本 <code>2.1.5</code>）：</p><pre><code class=\"language-bash\">$ wget https://www.keepalived.org/software/keepalived-2.1.5.tar.gz\n</code></pre><p>第二步，安装Keepalived：</p><pre><code class=\"language-bash\">$ sudo yum -y install openssl-devel # keepalived依赖OpenSSL，先安装依赖\n$ tar -xvzf keepalived-2.1.5.tar.gz\n$ cd keepalived-2.1.5\n$ ./configure --prefix=/usr/local/keepalived\n$ make\n$ sudo make install\n</code></pre><p>第三步，配置Keepalived：</p><pre><code class=\"language-bash\">$ sudo mkdir /etc/keepalived # 安装后，默认没有创建/etc/keepalived目录\n$ sudo cp /usr/local/keepalived/etc/keepalived/keepalived.conf  /etc/keepalived/keepalived.conf\n$ sudo cp /usr/local/keepalived/etc/sysconfig/keepalived /etc/sysconfig/keepalived\n</code></pre><p>Keepalived的systemd uint配置，默认使用了<code>/usr/local/keepalived/etc/sysconfig/keepalived</code>作为其<code>EnvironmentFile</code>，我们还需要把它修改为<code>/etc/sysconfig/keepalived</code>文件。编辑<code>/lib/systemd/system/keepalived.service</code>文件，设置<code>EnvironmentFile</code>，值如下：</p><pre><code class=\"language-bash\">EnvironmentFile=-/etc/sysconfig/keepalived\n</code></pre><p>第四步，启动Keepalived，并设置开机启动：</p><pre><code class=\"language-bash\">$ sudo systemctl start keepalived\n$ sudo systemctl enable keepalived\n</code></pre><p>这里要注意，Keepalived启动时不会校验配置文件是否正确，所以我们要小心修改配置，防止出现意想不到的问题。</p><p>第五步，查看Keepalived的启动状态：</p><pre><code class=\"language-bash\">$ systemctl status keepalived\n</code></pre><p>输出中有<code>active (running)</code>字符串，说明成功启动。Keepalived的日志保存在<code>/var/log/messages</code>中，你有需要的话可以查看。</p><h3>Keepalived配置文件解析</h3><p>Keepalived的默认配置文件为<code>/etc/keepalived/keepalived.conf</code>，下面是一个Keepalived配置：</p><pre><code class=\"language-plain\"># 全局定义，定义全局的配置选项\nglobal_defs {\n# 指定keepalived在发生切换操作时发送email，发送给哪些email\n# 建议在keepalived_notify.sh中发送邮件\n&nbsp; notification_email {\n&nbsp; &nbsp; acassen@firewall.loc\n&nbsp; }\n&nbsp; notification_email_from Alexandre.Cassen@firewall.loc # 发送email时邮件源地址\n&nbsp; &nbsp; smtp_server 192.168.200.1 # 发送email时smtp服务器地址\n&nbsp; &nbsp; smtp_connect_timeout 30 # 连接smtp的超时时间\n&nbsp; &nbsp; router_id VM-4-21-centos # 机器标识，通常可以设置为hostname\n&nbsp; &nbsp; vrrp_skip_check_adv_addr # 如果接收到的报文和上一个报文来自同一个路由器，则不执行检查。默认是跳过检查\n&nbsp; &nbsp; vrrp_garp_interval 0 # 单位秒，在一个网卡上每组gratuitous arp消息之间的延迟时间，默认为0\n&nbsp; &nbsp; vrrp_gna_interval 0 # 单位秒，在一个网卡上每组na消息之间的延迟时间，默认为0\n}\n# 检测脚本配置\nvrrp_script checkhaproxy\n{\n&nbsp; script \"/etc/keepalived/check_nginx.sh\" # 检测脚本路径\n&nbsp; &nbsp; interval 5 # 检测时间间隔（秒）\n&nbsp; &nbsp; weight 0 # 根据该权重改变priority，当值为0时，不改变实例的优先级\n}\n# VRRP实例配置\nvrrp_instance VI_1 {\n&nbsp; state BACKUP&nbsp; # 设置初始状态为'备份'\n&nbsp; &nbsp; interface eth0 # 设置绑定VIP的网卡，例如eth0\n&nbsp; &nbsp; virtual_router_id 51&nbsp; # 配置集群VRID，互为主备的VRID需要是相同的值\n&nbsp; &nbsp; nopreempt&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# 设置非抢占模式，只能设置在state为backup的节点上\n&nbsp; &nbsp; priority 50 # 设置优先级，值范围0～254，值越大优先级越高，最高的为master\n&nbsp; &nbsp; advert_int 1 # 组播信息发送时间间隔，两个节点必须设置一样，默认为1秒\n# 验证信息，两个节点必须一致\n&nbsp; &nbsp; authentication {\n&nbsp; &nbsp; &nbsp; auth_type PASS # 认证方式，可以是PASS或AH两种认证方式\n&nbsp; &nbsp; &nbsp; &nbsp; auth_pass 1111 # 认证密码\n&nbsp; &nbsp; }\n&nbsp; unicast_src_ip 10.0.4.21&nbsp; # 设置本机内网IP地址\n&nbsp; &nbsp; unicast_peer {\n&nbsp; &nbsp; &nbsp; 10.0.4.20&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# 对端设备的IP地址\n&nbsp; &nbsp; }\n# VIP，当state为master时添加，当state为backup时删除\n&nbsp; virtual_ipaddress {\n&nbsp; &nbsp; 10.0.4.99 # 设置高可用虚拟VIP，如果是腾讯云的CVM，需要填写控制台申请到的HAVIP地址。\n&nbsp; }\n&nbsp; notify_master \"/etc/keepalived/keepalived_notify.sh MASTER\" # 当切换到master状态时执行脚本\n&nbsp; &nbsp; notify_backup \"/etc/keepalived/keepalived_notify.sh BACKUP\" # 当切换到backup状态时执行脚本\n&nbsp; &nbsp; notify_fault \"/etc/keepalived/keepalived_notify.sh FAULT\" # 当切换到fault状态时执行脚本\n&nbsp; &nbsp; notify_stop \"/etc/keepalived/keepalived_notify.sh STOP\" # 当切换到stop状态时执行脚本\n&nbsp; &nbsp; garp_master_delay 1&nbsp; &nbsp; # 设置当切为主状态后多久更新ARP缓存\n&nbsp; &nbsp; garp_master_refresh 5&nbsp; &nbsp;# 设置主节点发送ARP报文的时间间隔\n&nbsp; &nbsp; # 跟踪接口，里面任意一块网卡出现问题，都会进入故障(FAULT)状态\n&nbsp; &nbsp; track_interface {\n&nbsp; &nbsp; &nbsp; eth0\n&nbsp; &nbsp; }\n&nbsp; # 要执行的检查脚本\n&nbsp; track_script {\n&nbsp; &nbsp; checkhaproxy\n&nbsp; }\n}\n</code></pre><p>这里解析下配置文件，大致分为下面4个部分。</p><ul>\n<li>global_defs：全局定义，定义全局的配置选项。</li>\n<li>vrrp_script checkhaproxy：检测脚本配置。</li>\n<li>vrrp_instance VI_1：VRRP实例配置。</li>\n<li>virtual_server：LVS配置。如果没有配置LVS+Keepalived，就不用设置这个选项。这门课中，我们使用Nginx代替LVS，所以无需配置<code>virtual_server</code>（配置示例中不再展示）。</li>\n</ul><p>只有在网络故障或者自身出问题时，Keepalived才会进行VIP切换。但实际生产环境中，我们往往使用Keepalived来监控其他进程，当业务进程出故障时切换VIP，从而保障业务进程的高可用。</p><p>为了让Keepalived感知到Nginx的运行状况，我们需要指定<code>vrrp_script</code>脚本，<code>vrrp_script</code>脚本可以根据退出码，判断Nginx进程是否正常，<code>0</code>正常，非<code>0</code>不正常。当不正常时，Keepalived会进行VIP切换。为了实现业务进程的监控，我们需要设置<code>vrrp_script</code>和<code>track_script</code>：</p><pre><code class=\"language-plain\">vrrp_script checkhaproxy\n{\n&nbsp; &nbsp; script \"/etc/keepalived/check_nginx.sh\"\n&nbsp; &nbsp; interval 3\n&nbsp; &nbsp; weight -20\n}\n\nvrrp_instance test\n{\n&nbsp; &nbsp; ...\n&nbsp; &nbsp; track_script\n&nbsp; &nbsp; {\n&nbsp; &nbsp; &nbsp; &nbsp; checkhaproxy\n&nbsp; &nbsp; }\n&nbsp; &nbsp; ...\n}\n</code></pre><p>这里，我介绍下上面配置中的一些配置项。</p><ul>\n<li>script：指定脚本路径。</li>\n<li>interval：表示Keepalived执行脚本的时间间隔（秒）。</li>\n<li>weight：检测权重，可以改变<code>priority</code>的值。例如，<code>-20</code>表示检测失败时，优先级<code>-20</code>，成功时不变。<code>20</code>表示检测成功时，优先级<code>+20</code>，失败时不变。</li>\n</ul><h2>总结</h2><p>今天我主要讲了跟IAM部署相关的两个组件，Nginx + Keepalived的相关功能。</p><p>我们可以基于物理机/虚拟机来部署IAM应用，在部署IAM应用时，需要确保整个应用具备高可用和弹性扩缩容能力。你可以通过Nginx的反向代理功能和负载均衡功能实现后端服务iam-apiserver和iam-authz-server的高可用，通过Keepalived实现Nginx的高可用，通过Nginx + Keepalived组合，来实现IAM应用的高可用和弹性伸缩能力。</p><h2>课后练习</h2><ol>\n<li>Keepalived的主备服务器要接在同一个交换机上。思考下，如果交换机故障，如何实现整个系统的高可用？</li>\n<li>iam-pump是有状态的服务，思考下，如何实现iam-pump的高可用？</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"39｜性能分析（下）：API Server性能测试和调优实战","id":410920},"right":{"article_title":"41 | 软件部署实战（中）：IAM 系统生产环境部署实战","id":412483}}},{"article_id":412483,"article_title":"41 | 软件部署实战（中）：IAM 系统生产环境部署实战","article_content":"<p>你好，我是孔令飞。</p><p>上一讲，我介绍了IAM部署用到的两个核心组件，Nginx和Keepalived。那么这一讲，我们就来看下，如何使用Nginx和Keepalived来部署一个高可用的IAM应用。下一讲，我再介绍下IAM应用安全和弹性伸缩能力的构建方式。</p><p>这一讲，我们会通过下面四个步骤来部署IAM应用：</p><ol>\n<li>在服务器上部署IAM应用中的服务。</li>\n<li>配置Nginx，实现反向代理功能。通过反向代理，我们可以通过Nginx来访问部署在内网的IAM服务。</li>\n<li>配置Nginx，实现负载均衡功能。通过负载均衡，我们可以实现服务的水平扩缩容，使IAM应用具备高可用能力。</li>\n<li>配置Keepalived，实现Nginx的高可用。通过Nginx + Keepalived的组合，可以实现整个应用架构的高可用。</li>\n</ol><h2>部署IAM应用</h2><p>部署一个高可用的IAM应用，需要至少两个节点。所以，我们按照先后顺序，分别在<code>10.0.4.20</code>和<code>10.0.4.21</code>服务器上部署IAM应用。</p><h3>在<code>10.0.4.20</code>服务器上部署IAM应用</h3><p>首先，我来介绍下如何在<code>10.0.4.20</code>服务器上部署IAM应用。</p><p>我们要在这个服务器上部署如下组件：</p><ul>\n<li>iam-apiserver</li>\n<li>iam-authz-server</li>\n<li>iam-pump</li>\n<li>MariaDB</li>\n<li>Redis</li>\n<li>MongoDB</li>\n</ul><!-- [[[read_end]]] --><p>这些组件的部署方式，<a href=\"https://time.geekbang.org/column/article/378082\">03讲</a> 有介绍，这里就不再说明。</p><p>此外，我们还需要设置MariaDB，给来自于<code>10.0.4.21</code>服务器的数据库连接授权，授权命令如下：</p><pre><code class=\"language-bash\">$ mysql -hlocalhost -P3306 -uroot -proot # 先以root用户登陆数据库\nMariaDB [(none)]&gt; grant all on iam.* TO iam@10.0.4.21 identified by 'iam1234';\nQuery OK, 0 rows affected (0.000 sec)\n\nMariaDB [(none)]&gt; flush privileges;\nQuery OK, 0 rows affected (0.000 sec)\n</code></pre><h3>在<code>10.0.4.21</code>服务器上部署IAM应用</h3><p>然后，在<code>10.0.4.21</code>服务器上安装好iam-apiserver、iam-authz-server 和 iam-pump。这些组件通过<code>10.0.4.20</code> IP地址，连接<code>10.0.4.20</code>服务器上的MariaDB、Redis和MongoDB。</p><h2>配置Nginx作为反向代理</h2><p>假定要访问的API Server和IAM Authorization Server的域名分别为<code>iam.api.marmotedu.com</code>和<code>iam.authz.marmotedu.com</code>，我们需要分别为iam-apiserver和iam-authz-server配置Nginx反向代理。整个配置过程可以分为5步（在<code>10.0.4.20</code>服务器上操作）。</p><p><strong>第一步，配置iam-apiserver。</strong></p><p>新建Nginx配置文件<code>/etc/nginx/conf.d/iam-apiserver.conf</code>，内容如下：</p><pre><code class=\"language-plain\">server {\n&nbsp; &nbsp; listen&nbsp; &nbsp; &nbsp; &nbsp;80;\n&nbsp; &nbsp; server_name&nbsp; iam.api.marmotedu.com;\n&nbsp; &nbsp; root&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;/usr/share/nginx/html;\n&nbsp; &nbsp; location / {\n&nbsp; &nbsp; \tproxy_set_header X-Forwarded-Host $http_host;\n&nbsp; &nbsp; \tproxy_set_header X-Real-IP $remote_addr;\n&nbsp; &nbsp; \tproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n&nbsp; &nbsp; \tproxy_pass&nbsp; http://127.0.0.1:8080/;\n&nbsp; &nbsp; \tclient_max_body_size 5m;\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; error_page 404 /404.html;\n&nbsp; &nbsp; &nbsp; &nbsp; location = /40x.html {\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; error_page 500 502 503 504 /50x.html;\n&nbsp; &nbsp; &nbsp; &nbsp; location = /50x.html {\n&nbsp; &nbsp; }\n}\n</code></pre><p>有几点你在配置时需要注意，这里说明下。</p><ul>\n<li><code>server_name</code>需要为<code>iam.api.marmotedu.com</code>，我们通过<code>iam.api.marmotedu.com</code>访问iam-apiserver。</li>\n<li>iam-apiserver默认启动的端口为<code>8080</code>。</li>\n<li>由于Nginx默认允许客户端请求的最大单文件字节数为<code>1MB</code>，实际生产环境中可能太小，所以这里将此限制改为5MB（<code>client_max_body_size 5m</code>）。如果需要上传图片之类的，可能需要设置成更大的值，比如<code>50m</code>。</li>\n<li>server_name用来说明访问Nginx服务器的域名，例如<code>curl -H 'Host: iam.api.marmotedu.com' http://x.x.x.x:80/healthz</code>，<code>x.x.x.x</code>为Nginx服务器的IP地址。</li>\n<li>proxy_pass表示反向代理的路径。因为这里是本机的iam-apiserver服务，所以IP为<code>127.0.0.1</code>。端口要和API服务端口一致，为<code>8080</code>。</li>\n</ul><p>最后还要提醒下，因为 Nginx 配置选项比较多，跟实际需求和环境有关，所以这里的配置是基础的、未经优化的配置，在实际生产环境中需要你再做调节。</p><p><strong>第二步，配置iam-authz-server。</strong></p><p>新建Nginx配置文件<code>/etc/nginx/conf.d/iam-authz-server.conf</code>，内容如下：</p><pre><code class=\"language-plain\">server {\n&nbsp; &nbsp; listen&nbsp; &nbsp; &nbsp; &nbsp;80;\n&nbsp; &nbsp; server_name&nbsp; iam.authz.marmotedu.com;\n&nbsp; &nbsp; root&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;/usr/share/nginx/html;\n&nbsp; &nbsp; location / {\n&nbsp; &nbsp; \tproxy_set_header X-Forwarded-Host $http_host;\n&nbsp; &nbsp; \tproxy_set_header X-Real-IP $remote_addr;\n&nbsp; &nbsp; \tproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n&nbsp; &nbsp; \tproxy_pass&nbsp; http://127.0.0.1:9090/;\n&nbsp; &nbsp; \tclient_max_body_size 5m;\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; error_page 404 /404.html;\n&nbsp; &nbsp; &nbsp; &nbsp; location = /40x.html {\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; error_page 500 502 503 504 /50x.html;\n&nbsp; &nbsp; &nbsp; &nbsp; location = /50x.html {\n&nbsp; &nbsp; }\n}\n</code></pre><p>下面是一些配置说明。</p><ul>\n<li>server_name需要为<code>iam.authz.marmotedu.com</code>，我们通过<code>iam.authz.marmotedu.com</code>访问iam-authz-server。</li>\n<li>iam-authz-server默认启动的端口为<code>9090</code>。</li>\n<li>其他配置跟<code>/etc/nginx/conf.d/iam-apiserver.conf</code>一致。</li>\n</ul><p><strong>第三步，配置完Nginx后，重启Nginx：</strong></p><pre><code class=\"language-bash\">$ sudo systemctl restart nginx\n</code></pre><p><strong>第四步，在/etc/hosts中追加下面两行：</strong></p><pre><code class=\"language-bash\">127.0.0.1 iam.api.marmotedu.com\n127.0.0.1 iam.authz.marmotedu.com\n</code></pre><p><strong>第五步，发送HTTP请求：</strong></p><pre><code class=\"language-bash\">$ curl http://iam.api.marmotedu.com/healthz\n{\"status\":\"ok\"}\n$ curl http://iam.authz.marmotedu.com/healthz\n{\"status\":\"ok\"}\n</code></pre><p>我们分别请求iam-apiserver和iam-authz-server的健康检查接口，输出了<code>{\"status\":\"ok\"}</code>，说明我们可以成功通过代理访问后端的API服务。</p><p>在用curl请求<code>http://iam.api.marmotedu.com/healthz</code>后，后端的请求流程实际上是这样的：</p><ol>\n<li>因为在<code>/etc/hosts</code>中配置了<code>127.0.0.1 iam.api.marmotedu.com</code>，所以请求<code>http://iam.api.marmotedu.com/healthz</code>实际上是请求本机的Nginx端口（<code>127.0.0.1:80</code>）。</li>\n<li>Nginx在收到请求后，会解析请求，得到请求域名为<code>iam.api.marmotedu.com</code>。根据请求域名去匹配 Nginx的server配置，匹配到<code>server_name  iam.api.marmotedu.com;</code>配置。</li>\n<li>匹配到server后，把请求转发到该server的<code>proxy_pass</code>路径。</li>\n<li>等待API服务器返回结果，并返回客户端。</li>\n</ol><h2>配置Nginx作为负载均衡</h2><p>这门课采用Nginx轮询的负载均衡策略转发请求。负载均衡需要至少两台服务器，所以会分别在<code>10.0.4.20</code>和<code>10.0.4.21</code>服务器上执行相同的操作。下面我分别来介绍下如何配置这两台服务器，并验证配置是否成功。</p><h3><code>10.0.4.20</code>服务器配置</h3><p>登陆<code>10.0.4.20</code>服务器，在<code>/etc/nginx/nginx.conf</code>中添加upstream配置，配置过程可以分为3步。</p><p><strong>第一步，在</strong><code>/etc/nginx/nginx.conf</code><strong>中添加upstream：</strong></p><pre><code class=\"language-plain\">http {\n&nbsp; &nbsp; log_format&nbsp; main&nbsp; '$remote_addr - $remote_user [$time_local] \"$request\" '\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; '$status $body_bytes_sent \"$http_referer\" '\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n\n&nbsp; &nbsp; access_log&nbsp; /var/log/nginx/access.log&nbsp; main;\n\n&nbsp; &nbsp; sendfile&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; on;\n&nbsp; &nbsp; tcp_nopush&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; on;\n&nbsp; &nbsp; tcp_nodelay&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;on;\n&nbsp; &nbsp; keepalive_timeout&nbsp; &nbsp;65;\n&nbsp; &nbsp; types_hash_max_size 2048;\n\n&nbsp; &nbsp; include&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;/etc/nginx/mime.types;\n&nbsp; &nbsp; default_type&nbsp; &nbsp; &nbsp; &nbsp; application/octet-stream;\n\n&nbsp; &nbsp; # Load modular configuration files from the /etc/nginx/conf.d directory.\n&nbsp; &nbsp; # See http://nginx.org/en/docs/ngx_core_module.html#include\n&nbsp; &nbsp; # for more information.\n&nbsp; &nbsp; include /etc/nginx/conf.d/*.conf;\n&nbsp; &nbsp; upstream iam.api.marmotedu.com {\n&nbsp; &nbsp; &nbsp; &nbsp; server 127.0.0.1:8080\n&nbsp; &nbsp; &nbsp; &nbsp; server 10.0.4.21:8080\n&nbsp; &nbsp; }\n&nbsp; &nbsp; upstream iam.authz.marmotedu.com {\n&nbsp; &nbsp; &nbsp; &nbsp; server 127.0.0.1:9090\n&nbsp; &nbsp; &nbsp; &nbsp; server 10.0.4.21:9090\n&nbsp; &nbsp; }\n}\n</code></pre><p>配置说明：</p><ul>\n<li>upstream是配置在<code>/etc/nginx/nginx.conf</code>文件中的<code>http{ … }</code>部分的。</li>\n<li>因为我们要分别为iam-apiserver和iam-authz-server配置负载均衡，所以我们创建了两个upstream，分别是<code>iam.api.marmotedu.com</code>和<code>iam.authz.marmotedu.com</code>。为了便于识别，upstream名称和域名最好保持一致。</li>\n<li>在upstream中，我们需要分别添加所有的iam-apiserver和iam-authz-server的后端（<code>ip:port</code>），本机的后端为了访问更快，可以使用<code>127.0.0.1:&lt;port&gt;</code>，其他机器的后端，需要使用<code>&lt;内网&gt;:port</code>，例如<code>10.0.4.21:8080</code>、<code>10.0.4.21:9090</code>。</li>\n</ul><p><strong>第二步，修改proxy_pass。</strong></p><p>修改<code>/etc/nginx/conf.d/iam-apiserver.conf</code>文件，将<code>proxy_pass</code>修改为：</p><pre><code class=\"language-plain\">proxy_pass http://iam.api.marmotedu.com/;\n</code></pre><p>修改<code>/etc/nginx/conf.d/iam-authz-server.conf</code>文件，将<code>proxy_pass</code>修改为：</p><pre><code class=\"language-plain\">proxy_pass http://iam.authz.marmotedu.com/;\n</code></pre><p>当Nginx转发到<code>http://iam.api.marmotedu.com/</code>域名时，会从<code>iam.api.marmotedu.com</code> upstream配置的后端列表中，根据负载均衡策略选取一个后端，并将请求转发过去。转发<code>http://iam.authz.marmotedu.com/</code>域名的逻辑也一样。</p><p><strong>第三步，配置完Nginx后，重启Nginx：</strong></p><pre><code class=\"language-bash\">$ sudo systemctl restart nginx\n</code></pre><p>最终配置好的配置文件，你可以参考下面这些（保存在<a href=\"https://github.com/marmotedu/iam/tree/v1.0.8/configs/ha/10.0.4.20\">configs/ha/10.0.4.20</a>目录下）：</p><ul>\n<li>nginx.conf：<a href=\"https://github.com/marmotedu/iam/blob/v1.0.8/configs/ha/10.0.4.20/nginx.conf\">configs/ha/10.0.4.20/nginx.conf</a>。</li>\n<li>iam-apiserver.conf：<a href=\"https://github.com/marmotedu/iam/blob/v1.0.8/configs/ha/10.0.4.20/iam-apiserver.conf\">configs/ha/10.0.4.20/iam-apiserver.conf</a>。</li>\n<li>iam-authz-server.conf：<a href=\"https://github.com/marmotedu/iam/blob/v1.0.8/configs/ha/10.0.4.20/iam-authz-server.conf\">configs/ha/10.0.4.20/iam-authz-server.conf</a>。</li>\n</ul><h3><code>10.0.4.21</code>服务器配置</h3><p>登陆<code>10.0.4.21</code>服务器，在<code>/etc/nginx/nginx.conf</code>中添加upstream配置。配置过程可以分为下面4步。</p><p><strong>第一步，在</strong><code>/etc/nginx/nginx.conf</code><strong>中添加upstream：</strong></p><pre><code class=\"language-plain\">http {\n&nbsp; &nbsp; log_format&nbsp; main&nbsp; '$remote_addr - $remote_user [$time_local] \"$request\" '\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; '$status $body_bytes_sent \"$http_referer\" '\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n\n&nbsp; &nbsp; access_log&nbsp; /var/log/nginx/access.log&nbsp; main;\n\n&nbsp; &nbsp; sendfile&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; on;\n&nbsp; &nbsp; tcp_nopush&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; on;\n&nbsp; &nbsp; tcp_nodelay&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;on;\n&nbsp; &nbsp; keepalive_timeout&nbsp; &nbsp;65;\n&nbsp; &nbsp; types_hash_max_size 2048;\n\n&nbsp; &nbsp; include&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;/etc/nginx/mime.types;\n&nbsp; &nbsp; default_type&nbsp; &nbsp; &nbsp; &nbsp; application/octet-stream;\n\n&nbsp; &nbsp; # Load modular configuration files from the /etc/nginx/conf.d directory.\n&nbsp; &nbsp; # See http://nginx.org/en/docs/ngx_core_module.html#include\n&nbsp; &nbsp; # for more information.\n&nbsp; &nbsp; include /etc/nginx/conf.d/*.conf;\n&nbsp; &nbsp; upstream iam.api.marmotedu.com {\n&nbsp; &nbsp; &nbsp; &nbsp; server 127.0.0.1:8080\n&nbsp; &nbsp; &nbsp; &nbsp; server 10.0.4.20:8080\n&nbsp; &nbsp; }\n&nbsp; &nbsp; upstream iam.authz.marmotedu.com {\n&nbsp; &nbsp; &nbsp; &nbsp; server 127.0.0.1:9090\n&nbsp; &nbsp; &nbsp; &nbsp; server 10.0.4.20:9090\n&nbsp; &nbsp; }\n}\n</code></pre><p>upstream中，需要配置<code>10.0.4.20</code>服务器上的iam-apiserver和iam-authz-server的后端，例如<code>10.0.4.20:8080</code>、<code>10.0.4.20:9090</code>。</p><p><strong>第二步，创建</strong><code>/etc/nginx/conf.d/iam-apiserver.conf</code><strong>文件</strong>（iam-apiserver的反向代理+负载均衡配置），内容如下：</p><pre><code class=\"language-plain\">server {\n&nbsp; &nbsp; listen&nbsp; &nbsp; &nbsp; &nbsp;80;\n&nbsp; &nbsp; server_name&nbsp; iam.api.marmotedu.com;\n&nbsp; &nbsp; root&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;/usr/share/nginx/html;\n&nbsp; &nbsp; location / {\n&nbsp; &nbsp; \tproxy_set_header X-Forwarded-Host $http_host;\n&nbsp; &nbsp; \tproxy_set_header X-Real-IP $remote_addr;\n&nbsp; &nbsp; \tproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n&nbsp; &nbsp; \tproxy_pass&nbsp; http://iam.api.marmotedu.com/;\n&nbsp; &nbsp; \tclient_max_body_size 5m;\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; error_page 404 /404.html;\n&nbsp; &nbsp; &nbsp; &nbsp; location = /40x.html {\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; error_page 500 502 503 504 /50x.html;\n&nbsp; &nbsp; &nbsp; &nbsp; location = /50x.html {\n&nbsp; &nbsp; }\n}\n</code></pre><p><strong>第三步，创建</strong><code>/etc/nginx/conf.d/iam-authz-server</code><strong>文件</strong>（iam-authz-server的反向代理+负载均衡配置），内容如下：</p><pre><code class=\"language-plain\">server {\n&nbsp; &nbsp; listen&nbsp; &nbsp; &nbsp; &nbsp;80;\n&nbsp; &nbsp; server_name&nbsp; iam.authz.marmotedu.com;\n&nbsp; &nbsp; root&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;/usr/share/nginx/html;\n&nbsp; &nbsp; location / {\n&nbsp; &nbsp; \tproxy_set_header X-Forwarded-Host $http_host;\n&nbsp; &nbsp; \tproxy_set_header X-Real-IP $remote_addr;\n&nbsp; &nbsp; \tproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n&nbsp; &nbsp; \tproxy_pass&nbsp; http://iam.authz.marmotedu.com/;\n&nbsp; &nbsp; \tclient_max_body_size 5m;\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; error_page 404 /404.html;\n&nbsp; &nbsp; &nbsp; &nbsp; location = /40x.html {\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; error_page 500 502 503 504 /50x.html;\n&nbsp; &nbsp; &nbsp; &nbsp; location = /50x.html {\n&nbsp; &nbsp; }\n}\n\n</code></pre><p><strong>第四步，配置完Nginx后，重启Nginx：</strong></p><pre><code class=\"language-bash\">$ sudo systemctl restart nginx\n</code></pre><p>最终配置好的配置文件，你可以参考下面这些（保存在<a href=\"https://github.com/marmotedu/iam/tree/v1.0.8/configs/ha/10.0.4.21\">configs/ha/10.0.4.21</a>目录下）：</p><ul>\n<li>nginx.conf：<a href=\"https://github.com/marmotedu/iam/blob/v1.0.8/configs/ha/10.0.4.21/nginx.conf\">configs/ha/10.0.4.21/nginx.conf</a>。</li>\n<li>iam-apiserver.conf：<a href=\"https://github.com/marmotedu/iam/blob/v1.0.8/configs/ha/10.0.4.21/iam-apiserver.conf\">configs/ha/10.0.4.21/iam-apiserver.conf</a>。</li>\n<li>iam-authz-server.conf：<a href=\"https://github.com/marmotedu/iam/blob/v1.0.8/configs/ha/10.0.4.21/iam-authz-server.conf\">configs/ha/10.0.4.21/iam-authz-server.conf</a>。</li>\n</ul><h3>测试负载均衡</h3><p>上面，我们配置了Nginx负载均衡器，这里我们还需要测试下是否配置成功。</p><p><strong>第一步，执行测试脚本（</strong><a href=\"https://github.com/marmotedu/iam/blob/v1.0.8/test/nginx/loadbalance.sh\">test/nginx/loadbalance.sh</a><strong>）：</strong></p><pre><code class=\"language-bash\">#!/usr/bin/env bash\n\nfor domain in iam.api.marmotedu.com iam.authz.marmotedu.com\ndo\n  for n in $(seq 1 1 10)\n  do\n    echo $domain\n    nohup curl http://${domain}/healthz &amp;&gt;/dev/null &amp;\n  done\ndone\n</code></pre><p><strong>第二步，分别查看iam-apiserver和iam-authz-server的日志。</strong></p><p>这里我展示下iam-apiserver的日志（iam-authz-server的日志你可自行查看）。</p><p><code>10.0.4.20</code>服务器的iam-apiserver日志如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/58/26/58d072c92552fa3068e3ef3acd0ed726.png?wh=1920x498\" alt=\"图片\"></p><p><code>10.0.4.21</code>服务器的iam-apiserver日志如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/19/85/199066c65ff60007f80f3c2dyy11c785.png?wh=1920x482\" alt=\"图片\"></p><p>通过上面两张图，你可以看到<code>10.0.4.20</code>和<code>10.0.4.21</code>各收到<code>5</code>个<code>/healthz</code>请求，说明负载均衡配置成功。</p><h2>配置Keepalived</h2><p>在 <a href=\"https://time.geekbang.org/column/article/411663\">40讲</a>，我们分别在<code>10.0.4.20</code>和<code>10.0.4.21</code>服务器上安装了Keepalived。这里，我来介绍下如何配置Keepalived，实现Nginx的高可用。为了避免故障恢复时，VIP切换造成的服务延时，这一讲采用Keepalived的非抢占模式。</p><p>配置Keepalived的流程比较复杂，分为创建腾讯云HAVIP、主服务器配置、备服务器配置、测试Keepalived、VIP绑定公网IP和测试公网访问六大步，每一步中都有很多小步骤，下面我们来一步步地看下。</p><h3><strong>第一步：创建腾讯云HAVIP</strong></h3><p>公有云厂商的普通内网IP，出于安全考虑（如避免ARP欺骗等），不支持主机通过ARP宣告IP 。如果用户直接在<code>keepalived.conf</code>文件中指定一个普通内网IP为virtual IP，当Keepalived将virtual IP从MASTER机器切换到BACKUP机器时，将无法更新IP和MAC地址的映射，而需要调API来进行IP切换。所以，这里的VIP需要申请腾讯云的HAVIP。</p><p>申请的流程可以分为下面4步：</p><ol>\n<li>登录私有网络控制台<strong>。</strong></li>\n<li>在左侧导航栏中，选择【IP与网卡】&gt;【高可用虚拟IP】。</li>\n<li>在HAVIP管理页面，选择所在地域，单击【申请】。</li>\n<li>在弹出的【申请高可用虚拟IP】对话框中输入名称，选择HAVIP所在的私有网络和子网等信息，单击【确定】即可。</li>\n</ol><p>这里选择的私有网络和子网，需要和<code>10.0.4.20</code>、<code>10.0.4.21</code>相同。HAVIP 的 IP 地址可以自动分配，也可以手动填写，这里我们手动填写为10.0.4.99。申请页面如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/a4/11/a49d6e7e080d658392dbb144a1560811.png?wh=827x1016\" alt=\"图片\"></p><h3>第二步：主服务器配置</h3><p>进行主服务器配置，可以分为两步。</p><p><strong>首先，修改Keepalived配置文件。</strong></p><p>登陆服务器<code>10.0.4.20</code>，编辑<code>/etc/keepalived/keepalived.conf</code>，修改配置，修改后配置内容如下（参考：<a href=\"https://github.com/marmotedu/iam/blob/v1.0.8/configs/ha/10.0.4.20/keepalived.conf\">configs/ha/10.0.4.20/keepalived.conf</a>）：</p><pre><code class=\"language-bash\"># 全局定义，定义全局的配置选项\nglobal_defs {\n# 指定keepalived在发生切换操作时发送email，发送给哪些email\n# 建议在keepalived_notify.sh中发送邮件\n  notification_email {\n    acassen@firewall.loc\n  }\n  notification_email_from Alexandre.Cassen@firewall.loc # 发送email时邮件源地址\n    smtp_server 192.168.200.1 # 发送email时smtp服务器地址\n    smtp_connect_timeout 30 # 连接smtp的超时时间\n    router_id VM-4-20-centos # 机器标识，通常可以设置为hostname\n    vrrp_skip_check_adv_addr # 如果接收到的报文和上一个报文来自同一个路由器，则不执行检查。默认是跳过检查\n    vrrp_garp_interval 0 # 单位秒，在一个网卡上每组gratuitous arp消息之间的延迟时间，默认为0\n    vrrp_gna_interval 0 # 单位秒，在一个网卡上每组na消息之间的延迟时间，默认为0\n}\n# 检测脚本配置\nvrrp_script checkhaproxy\n{\n  script \"/etc/keepalived/check_nginx.sh\" # 检测脚本路径\n    interval 5 # 检测时间间隔（秒）\n    weight 0 # 根据该权重改变priority，当值为0时，不改变实例的优先级\n}\n# VRRP实例配置\nvrrp_instance VI_1 {\n  state BACKUP  # 设置初始状态为'备份'\n    interface eth0 # 设置绑定VIP的网卡，例如eth0\n    virtual_router_id 51  # 配置集群VRID，互为主备的VRID需要是相同的值\n    nopreempt               # 设置非抢占模式，只能设置在state为backup的节点上\n    priority 100 # 设置优先级，值范围0～254，值越大优先级越高，最高的为master\n    advert_int 1 # 组播信息发送时间间隔，两个节点必须设置一样，默认为1秒\n# 验证信息，两个节点必须一致\n    authentication {\n      auth_type PASS # 认证方式，可以是PASS或AH两种认证方式\n        auth_pass 1111 # 认证密码\n    }\n  unicast_src_ip 10.0.4.20  # 设置本机内网IP地址\n    unicast_peer {\n      10.0.4.21             # 对端设备的IP地址\n    }\n# VIP，当state为master时添加，当state为backup时删除\n  virtual_ipaddress {\n    10.0.4.99 # 设置高可用虚拟VIP，如果是腾讯云的CVM，需要填写控制台申请到的HAVIP地址。\n  }\n  notify_master \"/etc/keepalived/keepalived_notify.sh MASTER\" # 当切换到master状态时执行脚本\n    notify_backup \"/etc/keepalived/keepalived_notify.sh BACKUP\" # 当切换到backup状态时执行脚本\n    notify_fault \"/etc/keepalived/keepalived_notify.sh FAULT\" # 当切换到fault状态时执行脚本\n    notify_stop \"/etc/keepalived/keepalived_notify.sh STOP\" # 当切换到stop状态时执行脚本\n    garp_master_delay 1    # 设置当切为主状态后多久更新ARP缓存\n    garp_master_refresh 5   # 设置主节点发送ARP报文的时间间隔\n    # 跟踪接口，里面任意一块网卡出现问题，都会进入故障(FAULT)状态\n    track_interface {\n      eth0\n    }\n  # 要执行的检查脚本\n  track_script {\n    checkhaproxy\n  }\n}\n</code></pre><p>这里有几个注意事项：</p><ul>\n<li>确保已经配置了garp相关参数。因为Keepalived依赖ARP报文更新IP信息，如果缺少这些参数，会导致某些场景下主设备不发送ARP，进而导致通信异常。garp相关参数配置如下：</li>\n</ul><pre><code class=\"language-plain\">garp_master_delay 1\ngarp_master_refresh 5\n</code></pre><ul>\n<li>确定没有采用 strict 模式，即需要删除vrrp_strict配置。</li>\n<li>配置中的<code>/etc/keepalived/check_nginx.sh</code>和<code>/etc/keepalived/keepalived_notify.sh</code>脚本文件，可分别拷贝自<a href=\"https://github.com/marmotedu/iam/blob/v1.0.8/scripts/check_nginx.sh\">scripts/check_nginx.sh</a>和<a href=\"https://github.com/marmotedu/iam/blob/v1.0.8/scripts/keepalived_notify.sh\">scripts/keepalived_notify.sh</a>。</li>\n</ul><p><strong>然后，重启Keepalived：</strong></p><pre><code class=\"language-bash\">$ sudo systemctl restart keepalived\n</code></pre><h3>第三步：备服务器配置</h3><p>进行备服务器配置也分为两步。</p><p><strong>首先，修改Keepalived配置文件。</strong></p><p>登陆服务器<code>10.0.4.21</code>，编辑<code>/etc/keepalived/keepalived.conf</code>，修改配置，修改后配置内容如下（参考：<a href=\"https://github.com/marmotedu/iam/blob/v1.0.8/configs/ha/10.0.4.21/keepalived.conf\">configs/ha/10.0.4.21/keepalived.conf</a>）：</p><pre><code class=\"language-plain\"># 全局定义，定义全局的配置选项\nglobal_defs {\n# 指定keepalived在发生切换操作时发送email，发送给哪些email\n# 建议在keepalived_notify.sh中发送邮件\n&nbsp; notification_email {\n&nbsp; &nbsp; acassen@firewall.loc\n&nbsp; }\n&nbsp; notification_email_from Alexandre.Cassen@firewall.loc # 发送email时邮件源地址\n&nbsp; &nbsp; smtp_server 192.168.200.1 # 发送email时smtp服务器地址\n&nbsp; &nbsp; smtp_connect_timeout 30 # 连接smtp的超时时间\n&nbsp; &nbsp; router_id VM-4-21-centos # 机器标识，通常可以设置为hostname\n&nbsp; &nbsp; vrrp_skip_check_adv_addr # 如果接收到的报文和上一个报文来自同一个路由器，则不执行检查。默认是跳过检查\n&nbsp; &nbsp; vrrp_garp_interval 0 # 单位秒，在一个网卡上每组gratuitous arp消息之间的延迟时间，默认为0\n&nbsp; &nbsp; vrrp_gna_interval 0 # 单位秒，在一个网卡上每组na消息之间的延迟时间，默认为0\n}\n# 检测脚本配置\nvrrp_script checkhaproxy\n{\n&nbsp; script \"/etc/keepalived/check_nginx.sh\" # 检测脚本路径\n&nbsp; &nbsp; interval 5 # 检测时间间隔（秒）\n&nbsp; &nbsp; weight 0 # 根据该权重改变priority，当值为0时，不改变实例的优先级\n}\n# VRRP实例配置\nvrrp_instance VI_1 {\n&nbsp; state BACKUP&nbsp; # 设置初始状态为'备份'\n&nbsp; &nbsp; interface eth0 # 设置绑定VIP的网卡，例如eth0\n&nbsp; &nbsp; virtual_router_id 51&nbsp; # 配置集群VRID，互为主备的VRID需要是相同的值\n&nbsp; &nbsp; nopreempt&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# 设置非抢占模式，只能设置在state为backup的节点上\n&nbsp; &nbsp; priority 50 # 设置优先级，值范围0～254，值越大优先级越高，最高的为master\n&nbsp; &nbsp; advert_int 1 # 组播信息发送时间间隔，两个节点必须设置一样，默认为1秒\n# 验证信息，两个节点必须一致\n&nbsp; &nbsp; authentication {\n&nbsp; &nbsp; &nbsp; auth_type PASS # 认证方式，可以是PASS或AH两种认证方式\n&nbsp; &nbsp; &nbsp; &nbsp; auth_pass 1111 # 认证密码\n&nbsp; &nbsp; }\n&nbsp; unicast_src_ip 10.0.4.21&nbsp; # 设置本机内网IP地址\n&nbsp; &nbsp; unicast_peer {\n&nbsp; &nbsp; &nbsp; 10.0.4.20&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# 对端设备的IP地址\n&nbsp; &nbsp; }\n# VIP，当state为master时添加，当state为backup时删除\n&nbsp; virtual_ipaddress {\n&nbsp; &nbsp; 10.0.4.99 # 设置高可用虚拟VIP，如果是腾讯云的CVM，需要填写控制台申请到的HAVIP地址。\n&nbsp; }\n&nbsp; notify_master \"/etc/keepalived/keepalived_notify.sh MASTER\" # 当切换到master状态时执行脚本\n&nbsp; &nbsp; notify_backup \"/etc/keepalived/keepalived_notify.sh BACKUP\" # 当切换到backup状态时执行脚本\n&nbsp; &nbsp; notify_fault \"/etc/keepalived/keepalived_notify.sh FAULT\" # 当切换到fault状态时执行脚本\n&nbsp; &nbsp; notify_stop \"/etc/keepalived/keepalived_notify.sh STOP\" # 当切换到stop状态时执行脚本\n&nbsp; &nbsp; garp_master_delay 1&nbsp; &nbsp; # 设置当切为主状态后多久更新ARP缓存\n&nbsp; &nbsp; garp_master_refresh 5&nbsp; &nbsp;# 设置主节点发送ARP报文的时间间隔\n&nbsp; &nbsp; # 跟踪接口，里面任意一块网卡出现问题，都会进入故障(FAULT)状态\n&nbsp; &nbsp; track_interface {\n&nbsp; &nbsp; &nbsp; eth0\n&nbsp; &nbsp; }\n&nbsp; # 要执行的检查脚本\n&nbsp; track_script {\n&nbsp; &nbsp; checkhaproxy\n&nbsp; }\n}\n</code></pre><p><strong>然后，重启Keepalived：</strong></p><pre><code class=\"language-bash\">$ sudo systemctl restart keepalived\n</code></pre><h3>第四步：测试Keepalived</h3><p>上面的配置中，<code>10.0.4.20</code>的优先级更高，所以正常情况下<code>10.0.4.20</code>将被选择为主节点，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/54/79/54968f40707b779e2ab70d3ab5a53479.png?wh=1920x500\" alt=\"图片\"></p><p>接下来，我们分别模拟一些故障场景，来看下配置是否生效。</p><p><strong>场景1：Keepalived故障</strong></p><p>在<code>10.0.4.20</code>服务器上执行<code>sudo systemctl stop keepalived</code>模拟Keepalived故障，查看VIP，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/2a/ee/2a57e958bd9fce3b9c842c1cf09c48ee.png?wh=1920x544\" alt=\"图片\"></p><p>可以看到，VIP从<code>10.0.4.20</code>服务器上，漂移到了<code>10.0.4.21</code>服务器上。查看<code>/var/log/keepalived.log</code>，可以看到<code>10.0.4.20</code>服务器新增如下一行日志：</p><pre><code class=\"language-plain\">[2020-10-14 14:01:51] notify_stop\n</code></pre><p><code>10.0.4.21</code>服务器新增如下日志：</p><pre><code class=\"language-plain\">[2020-10-14 14:01:52] notify_master\n</code></pre><p><strong>场景2：Nginx故障</strong></p><p>在<code>10.0.4.20</code>和<code>10.0.4.21</code>服务器上分别执行<code>sudo systemctl restart keepalived</code>，让VIP漂移到<code>10.0.4.20</code>服务器上。</p><p>在<code>10.0.4.20</code>服务器上，执行 <code>sudo systemctl stop nginx</code> 模拟Nginx故障，查看VIP，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/2a/ee/2a57e958bd9fce3b9c842c1cf09c48ee.png?wh=1920x544\" alt=\"图片\"></p><p>可以看到，VIP从<code>10.0.4.20</code>服务器上，漂移到了<code>10.0.4.21</code>服务器上。查看<code>/var/log/keepalived.log</code>，可以看到<code>10.0.4.20</code>服务器新增如下一行日志：</p><pre><code class=\"language-plain\">[2020-10-14 14:02:34] notify_fault\n</code></pre><p><code>10.0.4.21</code> 服务器新增如下日志：</p><pre><code class=\"language-plain\">[2020-10-14 14:02:35] notify_master\n</code></pre><p><strong>场景3：Nginx恢复</strong></p><p>基于<strong>场景2</strong>，在<code>10.0.4.20</code>服务器上执行<code>sudo systemctl start nginx</code>恢复Nginx，查看VIP，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/2a/ee/2a57e958bd9fce3b9c842c1cf09c48ee.png?wh=1920x544\" alt=\"图片\"></p><p>可以看到，VIP仍然在<code>10.0.4.21</code>服务器上，没有被<code>10.0.4.20</code>抢占。查看<code>/var/log/keepalived.log</code>，可以看到<code>10.0.4.20</code>服务器新增如下一行日志：</p><pre><code class=\"language-plain\">[2020-10-14 14:03:44] notify_backup\n</code></pre><p><code>10.0.4.21</code>服务器没有新增日志。</p><h3>第五步：VIP绑定公网IP</h3><p>到这里，我们已经成功配置了Keepalived + Nginx的高可用方案。但是，我们的VIP是内网，还不能通过外网访问。这时候，我们需要将VIP绑定一个外网IP，供外网访问。在腾讯云上，可通过绑定弹性公网IP来实现外网访问，需要先申请公网IP，然后将VIP绑定弹性公网IP。下面我来讲讲具体步骤。</p><p>申请公网IP：</p><ol>\n<li>登录<strong>私有网络控制台。</strong></li>\n<li>在左侧导航栏中，选择【IP与网卡】&gt;【弹性公网IP】。</li>\n<li>在弹性公网IP管理页面，选择所在地域，单击【申请】。</li>\n</ol><p>将VIP绑定弹性公网IP：</p><ol>\n<li>登录<strong>私有网络控制台</strong>。</li>\n<li>在左侧导航栏中，选择【IP与网卡】&gt;【高可用虚拟】。</li>\n<li>单击需要绑定的HAVIP所在行的【绑定】。</li>\n<li>在弹出界面中，选择需要绑定的公网IP即可，如下图所示：</li>\n</ol><p><img src=\"https://static001.geekbang.org/resource/image/83/62/83bc9f4595325e9d339e7c3269aa3462.png?wh=1388x666\" alt=\"图片\"></p><p>绑定的弹性公网IP是<code>106.52.252.139</code>。</p><p>这里提示下，腾讯云平台中，如果HAVIP没有绑定实例，绑定HAVIP的EIP会处于闲置状态，按<code>¥0.2/小时</code> 收取闲置费用。所以，你需要正确配置高可用应用，确保绑定成功。</p><h3>第六步：测试公网访问</h3><p>最后，你可以通过执行如下命令来测试：</p><pre><code class=\"language-bash\">$ curl -H\"Host: iam.api.marmotedu.com\" http://106.52.252.139/healthz -H\"iam.api.marmotedu.com\"\n{\"status\":\"ok\"}\n</code></pre><p>可以看到，我们可以成功通过公网访问后端的高可用服务。到这里，我们成功部署了一个可用性很高的IAM应用。</p><h2>总结</h2><p>今天，我主要讲了如何使用Nginx和Keepalived，来部署一个高可用的IAM应用。</p><p>为了部署一个高可用的IAM应用，我们至少需要两台服务器，并且部署相同的服务iam-apiserver、iam-authz-server、iam-pump。而且，选择其中一台服务器部署数据库服务：MariaDB、Redis、MongoDB。</p><p>为了安全和性能，iam-apiserver、iam-authz-server、iam-pump服务都是通过内网来访问数据库服务的。这一讲，我还介绍了如何配置Nginx来实现负载均衡，如何配置Keepalived来实现Nginx的高可用。</p><h2>课后练习</h2><ol>\n<li>思考下，当前部署架构下如果iam-apiserver需要扩容，可以怎么扩容？</li>\n<li>思考下，当VIP切换时，如何实现告警功能，给系统运维人员告警？</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"40 | 软件部署实战（上）：部署方案及负载均衡、高可用组件介绍","id":411663},"right":{"article_title":"42 | 软件部署实战（下）：IAM系统安全加固、水平扩缩容实战","id":413279}}},{"article_id":413279,"article_title":"42 | 软件部署实战（下）：IAM系统安全加固、水平扩缩容实战","article_content":"<p>你好，我是孔令飞。</p><p>这一讲和前面两讲，都是介绍如何基于物理机/虚拟机来部署IAM的。在前面两讲，我们了解了如何部署一个高可用的 IAM 应用，今天就再来看看IAM 应用安全和弹性伸缩能力的构建方式。在这一讲中，我会带你加固IAM应用的安全性，并介绍如何具体执行扩缩容步骤。</p><p>接下来，我们先来看下如何加固IAM应用的安全性。</p><h2>IAM应用安全性加固</h2><p>iam-apiserver、iam-authz-server、MariaDB、Redis和MongoDB这些服务，都提供了绑定监听网卡的功能。我们可以将这些服务绑定到内网网卡上，从而只接收来自于内网的请求，通过这种方式，可以加固我们的系统。</p><p>我们也可以通过iptables来实现类似的功能，通过将安全问题统一收敛到iptables规则，可以使我们更容易地维护安全类设置。</p><p>这门课通过iptables来加固系统，使系统变得更加安全。下面，我先来对iptables工具进行一些简单的介绍。</p><h3>iptables简介</h3><p>iptables是Linux下最优秀的防火墙工具，也是Linux内核中netfilter网络子系统用户态的工具。</p><p>netfilter提供了一系列的接口，在一个到达本机的数据包，或者经本机转发的数据包流程中添加了一些可供用户操作的点，这些点被称为HOOK点。通过在HOOK点注册数据包处理函数，可以实现数据包转发、数据包过滤、地址转换等功能。</p><!-- [[[read_end]]] --><p>用户通过iptables工具定义各种规则，这些规则通过iptables传给内核中的netfilter。最终，netfilter会根据规则对网络包进行过滤。Linux系统一般会默认安装iptables软件。防火墙根据iptables里的规则，对收到的网络数据包进行处理。</p><p>iptables里的数据组织结构分为表、链、规则。</p><ul>\n<li><strong>表（tables）:</strong>表可以提供特定的功能，每个表里包含多个链。iptables里面一共有5个表，分别是filter、nat、mangle、raw、security。这些表，分别用来实现包过滤、网络地址转换、包重构、数据追踪处理和SELinux标记设置。</li>\n<li><strong>链（chains）:</strong>链是数据包传播的路径，每一条链中可以有一个或多个规则。当一个数据包到达一个链时，iptables会从链中第一条规则开始，检查该数据包是否满足规则所定义的条件。如果满足，就会根据该条规则所定义的方法，处理该数据包。否则，就继续检查下一条规则。如果该数据包不符合链中任一条规则，iptables就会根据该链预先定义的默认策略来处理数据包。</li>\n<li><strong>规则（rules）：</strong>规则存储在内核空间的信息包过滤表中，用来描述“如果数据包满足所描述的条件，就按照要求处理这个数据包，如果不满足，就判断下一条规则”。</li>\n</ul><p>其中，iptables中表和链的种类及其功能，如下表所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/11/0f/112df7eb9a1258dd61e3bd0e0b6b210f.png?wh=2248x1941\" alt=\"\"></p><p>上面的表格中，五张表的处理是有顺序的。当数据包到达某一条链时，会按照RAW、MANGLE、NAT、FILTER、SECURITY的顺序进行处理。</p><p>到这里，我介绍了关于iptables的一些基础知识，但这还远远不够。要想使用iptables来加固你的系统，你还需要掌握iptables工具的使用方法。接下来，我先来介绍下iptables是如何处理网络数据包的。</p><h3>网络数据包处理流程</h3><p>网络数据包的处理流程如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/9e/bb/9ece7f3001c022790f1fd1a0yy1246bb.jpg?wh=2248x1414\" alt=\"\"></p><p>具体可以分为两个步骤。</p><p>第一步，当数据包进入网卡后，它首先进入PREROUTING链，根据目的IP判断是否转发出去。</p><p>第二步分为两种情况：如果数据包目的地是本机，它会到达INPUT链。到达后，任何进程都会收到它。本机上的程序可以发送数据包，这些数据包会经过OUTPUT链，然后经POSTROUTING链输出；如果数据包是要转发出去，并且内核允许转发，那么数据包会经过FORWARD链，最后从POSTROUTING链输出。</p><h3>iptables工具使用方式介绍</h3><p>iptables的功能强大，所以使用方法也非常多样。这里，我来介绍下iptables工具的使用方式，并给出一些使用示例。</p><ol>\n<li>命令格式</li>\n</ol><p>iptables的语法格式为：</p><pre><code class=\"language-bash\">iptables [-t 表名] 命令选项 [链名] [条件匹配] [-j 目标动作或跳转]\n</code></pre><p>下面是一个iptables的使用示例：</p><pre><code class=\"language-bash\">iptables -t nat -I PREROUTING -p tcp --dport 8080 -j DNAT --to 10.0.4.88\n</code></pre><p>这里对上面涉及到的一些参数进行说明。</p><ul>\n<li>表名/链名：指定iptables命令所操作的表/链。</li>\n<li>命令选项：指定处理iptables规则的方式，例如插入、增加、删除、查看等。</li>\n<li>条件匹配：指定对符合条件的数据包进行处理。</li>\n<li>目标动作或跳转：防火墙处理数据包的方式。</li>\n</ul><p>iptables的命令选项又分为管理控制选项和通用选项。</p><p>管理控制选项如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/6d/b2/6d37f77b4cee31eea694cc588ayy3cb2.png?wh=2248x2323\" alt=\"\"></p><p>通用选项如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/0b/ae/0b38f3ba2d722ccf3274a0ae0a5f79ae.png?wh=2248x1498\" alt=\"\"></p><p>处理数据包的方式（目标动作或跳转）有多种，具体如下表所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/f7/dc/f796fc7905c88cf0461f4464cec8cddc.png?wh=2248x1625\" alt=\"\"></p><p>上面，我介绍了iptables工具的使用方式。因为内容有点多，你可能仍然不知道如何使用iptables工具。没关系，接下来你可以结合我举的一些例子来看下。</p><ol start=\"2\">\n<li>命令示例</li>\n</ol><p>下面的命令示例，默认使用了 <code>FILTER</code> 表，也即规则存放在 <code>FILTER</code>  表中，相当于每一条iptables命令都添加了<code>-t filter</code> 参数。</p><ol>\n<li>拒绝进入防火墙的所有ICMP协议数据包：</li>\n</ol><pre><code class=\"language-bash\">$ iptables -I INPUT -p icmp -j REJECT\n</code></pre><ol start=\"2\">\n<li>允许防火墙转发除ICMP协议以外的所有数据包：</li>\n</ol><pre><code class=\"language-bash\">$ iptables -A FORWARD -p ! icmp -j ACCEPT\n</code></pre><ol start=\"3\">\n<li>拒绝转发来自192.168.1.10主机的数据，允许转发来自192.168.0.0/24网段的数据：</li>\n</ol><pre><code class=\"language-bash\">$ iptables -A FORWARD -s 192.168.1.11 -j REJECT\n$ iptables -A FORWARD -s 192.168.0.0/24 -j ACCEPT\n</code></pre><ol start=\"4\">\n<li>丢弃从外网接口（eth1）进入防火墙本机的源地址为私网地址的数据包：</li>\n</ol><pre><code class=\"language-bash\">$ iptables -A INPUT -i eth1 -s 192.168.0.0/16 -j DROP\n$ iptables -A INPUT -i eth1 -s 172.16.0.0/12 -j DROP\n$ iptables -A INPUT -i eth1 -s 10.0.0.0/8 -j DROP\n</code></pre><ol start=\"5\">\n<li>只允许管理员从202.13.0.0/16网段使用SSH远程登录防火墙主机：</li>\n</ol><pre><code class=\"language-bash\">$ iptables -A INPUT -p tcp --dport 22 -s 202.13.0.0/16 -j ACCEPT\n$ iptables -A INPUT -p tcp --dport 22 -j DROP\n</code></pre><ol start=\"6\">\n<li>允许本机开放从TCP端口20-1024提供的应用服务：</li>\n</ol><pre><code class=\"language-bash\">$ iptables -A INPUT -p tcp --dport 20:1024 -j ACCEPT\n$ iptables -A OUTPUT -p tcp --sport 20:1024 -j ACCEPT\n</code></pre><ol start=\"7\">\n<li>允许转发来自192.168.0.0/24局域网段的DNS解析请求数据包：</li>\n</ol><pre><code class=\"language-bash\">$ iptables -A FORWARD -s 192.168.0.0/24 -p udp --dport 53 -j ACCEPT\n$ iptables -A FORWARD -d 192.168.0.0/24 -p udp --sport 53 -j ACCEPT\n</code></pre><ol start=\"8\">\n<li>禁止其他主机ping防火墙主机，但是允许从防火墙上ping其他主机：</li>\n</ol><pre><code class=\"language-bash\">$ iptables -I INPUT -p icmp --icmp-type Echo-Request -j DROP\n$ iptables -I INPUT -p icmp --icmp-type Echo-Reply -j ACCEPT\n$ iptables -I INPUT -p icmp --icmp-type destination-Unreachable -j ACCEPT\n</code></pre><ol start=\"9\">\n<li>禁止转发来自MAC地址为00：0C：29：27：55：3F的数据包和主机的数据包：</li>\n</ol><pre><code class=\"language-bash\">$ iptables -A FORWARD -m mac --mac-source 00:0c:29:27:55:3F -j DROP\n</code></pre><ol start=\"10\">\n<li>对外开放TCP端口20、21、25、110，以及被动模式FTP端口1250-1280：</li>\n</ol><pre><code class=\"language-bash\">$ iptables -A INPUT -p tcp -m multiport --dport 20,21,25,110,1250:1280 -j ACCEPT\n</code></pre><ol start=\"11\">\n<li>禁止转发源IP地址为192.168.1.20-192.168.1.99的TCP数据包：</li>\n</ol><pre><code class=\"language-bash\">$ iptables -A FORWARD -p tcp -m iprange --src-range 192.168.1.20-192.168.1.99 -j DROP\n</code></pre><ol start=\"12\">\n<li>禁止转发与正常TCP连接无关的非syn请求数据包：</li>\n</ol><pre><code class=\"language-bash\">$ iptables -A FORWARD -m state --state NEW -p tcp ! --syn -j DROP\n</code></pre><ol start=\"13\">\n<li>拒绝访问防火墙的新数据包，但允许响应连接或与已有连接相关的数据包：</li>\n</ol><pre><code class=\"language-bash\">$ iptables -A INPUT -p tcp -m state --state NEW -j DROP\n$ iptables -A INPUT -p tcp -m state --state ESTABLISHED,RELATED -j ACCEPT\n</code></pre><ol start=\"14\">\n<li>只开放本机的web服务（80）、FTP(20、21、20450-20480)，放行外部主机发往服务器其他端口的应答数据包，将其他入站数据包都进行丢弃处理：</li>\n</ol><pre><code class=\"language-bash\">$ iptables -I INPUT -p tcp -m multiport --dport 20,21,80 -j ACCEPT\n$ iptables -I INPUT -p tcp --dport 20450:20480 -j ACCEPT\n$ iptables -I INPUT -p tcp -m state --state ESTABLISHED -j ACCEPT\n$ iptables -P INPUT DROP\n</code></pre><p>到这里，我们已经了解了iptables的功能，下面来看看如何使用iptables来加固IAM应用。我把它分成内网不安全和内网安全两种情况。</p><h3>IAM安全加固（内网不安全）</h3><p>在设置iptables规则之前，我们需要先梳理系统的访问关系，然后根据这些访问关系设置iptables规则。访问关系如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/9a/8d/9a9b8d4283410dc842505f258128d78d.jpg?wh=2248x1386\" alt=\"\"></p><p>你可以看到，IAM系统服务互访关系分为下面这4种：</p><ul>\n<li>允许公网客户端访问Nginx的80和443端口。</li>\n<li>Keepalived服务之间能够互发VRRP协议包。</li>\n<li>Nginx访问各节点上iam-apiserver、iam-authz-server和iam-pump组件开启的HTTP/HTTPS/GRPC服务。</li>\n<li>iam服务可以从各节点访问Redis、MariaDB、MongoDB数据库。</li>\n</ul><p>这里，我们假定IAM系统部署在一个非常大的内网中，该内网部署了很多其他团队的服务，有很多其他团队的研发、测试等人员在内网中执行各种操作。也就是说，我们处在一个不安全的内网中。这时候，如果要加固我们的系统，最安全的方式是屏蔽掉未知的来源IP。</p><p>内网不安全的情况下，加固系统可以分为3大步骤，每个步骤中又有一些小步骤。另外，需要新增节点或者删除节点时，也需要进行一些变更操作。下面我们来具体看下。</p><p><strong>第一步，设置防火墙规则。</strong></p><p>基于上面说到的几种互访关系，我们可以在各个节点上设置iptables规则来加固系统。我将这些规则设置编写成了go工具，用来自动生成设置这些规则的shell脚本。</p><p>具体设置的过程可以分为5步。</p><ol>\n<li>进入iam项目源码根目录。</li>\n<li>配置accesss.yaml（工具根据此配置，自动生成iptables设置脚本），内容如下（位于<a href=\"https://github.com/marmotedu/iam/blob/v1.0.8/configs/access.yaml\">configs/access.yaml</a>文件）：</li>\n</ol><pre><code class=\"language-yaml\"># 允许登录SSH节点的来源IP，可以是固定IP(例如10.0.4.2)，也可以是个网段，0.0.0.0/0代表不限制来源IP\nssh-source: 10.0.4.0/24\n\n# IAM应用节点列表（来源IP）\nhosts:\n  - 10.0.4.20\n  - 10.0.4.21\n\n# 来源IP可以访问的应用端口列表（iam-apiserver, iam-authz-server, iam-pump对外暴露的的端口）\nports:\n  - 8080\n  - 8443\n  - 9090\n  - 9443\n  - 7070\n\n# 来源IP可以访问的数据库端口列表（Redis, MariaDB, MongoDB）\ndbports:\n  - 3306\n  - 6379\n  - 27017\n</code></pre><p>上面的配置中，我们指定了允许登陆机器的子网、Nginx需要访问的端口列表和各节点需要访问的数据库端口列表。</p><ol start=\"3\">\n<li>生成iptables初始化脚本：</li>\n</ol><pre><code class=\"language-bash\">$ go run tools/geniptables/main.go -c access.yaml -t app -a -o firewall.sh\n$ ls firewall.sh\nfirewall.sh\n</code></pre><p>你可以打开firewall.sh文件，查看该脚本设置的规则。<br>\n4. 将firewall.sh脚本拷贝到10.0.4.20和10.0.4.21节点执行：</p><pre><code class=\"language-bash\">$ scp firewall.sh root@10.0.4.20:/tmp/\n$ scp firewall.sh root@10.0.4.21:/tmp/\n</code></pre><p>登陆10.0.4.20和10.0.4.21机器，执行<code>/tmp/firewall.sh</code>。</p><ol start=\"5\">\n<li>在10.0.4.20（数据库节点）节点上，设置iptables规则，以允许各节点访问：</li>\n</ol><p>因为数据库节点也位于10.0.4.20节点，所以只需要添加新的rule，并将<code>iptables -A INPUT -j DROP</code>规则放到最后执行即可。</p><pre><code class=\"language-bash\">$ go run tools/geniptables/main.go -c access.yaml -t db -o addrules.sh\n</code></pre><p>然后，将addrules.sh脚本拷贝到10.0.4.20节点执行。</p><p>注意，因为iptables是按顺序进行规则过滤的，所以需要将<code>iptables -A INPUT -j DROP</code>规则放在新设置规则的后面，否则执行不到新设置的规则。你可以在设置完iptables规则之后，执行下面的命令来将DROP放到最后：</p><pre><code class=\"language-bash\">iptables -A INPUT -j LOG --log-level 7 --log-prefix \"Default Deny\"\niptables -A INPUT -j DROP\n</code></pre><p>生成的addrules.sh脚本加入以上设置。</p><p><strong>第二步，设置重启自动加载iptables规则。</strong></p><p>前面我们在各个节点设置了iptables规则，但是这些规则在系统重启后会丢失。为了使系统重启后自动重新设置这些规则，我们需要将当前的iptables规则保存起来，让系统重启时自动加载。需要进行下面两个步骤。</p><ol>\n<li>保存现有的规则：</li>\n</ol><pre><code class=\"language-bash\">$ sudo iptables-save &gt; /etc/sysconfig/iptables\n</code></pre><ol start=\"2\">\n<li>添加下面的命令行到/etc/rc.d/rc.local文件中：</li>\n</ol><pre><code class=\"language-bash\">$ iptables-restore &lt; /etc/sysconfig/iptables\n</code></pre><p><strong>第三步，自动化。</strong></p><p>在上面的步骤中，我们自动生成了iptables规则，并手动登陆到节点进行设置。你肯定也发现了，整个流程手动操作过多，容易出错，效率还低。你可以参考设置过程，将这些设置工作自动化，比如编写脚本，一键刷新所有节点的iptables规则。</p><p>另外，我们再来看下在新增节点和删除节点两种场景下，如何设置iptables规则。</p><p><strong>场景1：新增节点</strong></p><p>如果我们要扩容一个节点，也需要在新节点设置防火墙规则，并在数据库节点设置防火墙规则允许来自新节点的访问。</p><p>假如我们新增一个10.0.4.22节点，这里要设置防火墙规则，需要下面的4个步骤。</p><ol>\n<li>编辑access.yaml，在hosts列表下新增10.0.4.22节点IP。编辑后内容如下：</li>\n</ol><pre><code class=\"language-yaml\"># 允许登录SSH节点的来源IP，可以是固定IP(例如10.0.4.2)，也可以是个网段，0.0.0.0/0代表不限制来源IP\nssh-source: 10.0.4.0/24\n\n# IAM应用节点列表（来源IP）\nhosts:\n  - 10.0.4.20\n  - 10.0.4.21\n  - 10.0.4.22\n\n# 来源IP可以访问的应用端口列表（iam-apiserver, iam-authz-server, iam-pump对外暴露的的端口）\nports:\n  - 8080\n  - 8443\n  - 9090\n  - 9443\n  - 7070\n\n# 来源IP可以访问的数据库端口列表（Redis, MariaDB, MongoDB）\ndbports:\n  - 3306\n  - 6379\n  - 27017\n</code></pre><ol start=\"2\">\n<li>在10.0.4.22节点设置iptables规则：</li>\n</ol><pre><code class=\"language-bash\">$ go run tools/geniptables/main.go -c access.yaml -t app -a -o firewall.sh\n</code></pre><p>将firewall.sh脚本拷贝到10.0.4.22节点，并执行。</p><ol start=\"3\">\n<li>在已有节点新增规则，允许来自10.0.4.22的 Nginx服务的访问：</li>\n</ol><pre><code class=\"language-bash\">$ go run tools/geniptables/main.go -c access.yaml -t app 10.0.4.22 -o addrules.sh\n</code></pre><p>将addrules.sh脚本拷贝到存量节点，并执行。</p><ol start=\"4\">\n<li>在数据库节点新增iptables规则，以允许来自新节点的访问：</li>\n</ol><pre><code class=\"language-bash\">$ go run tools/geniptables/main.go -c access.yaml -t db 10.0.4.22 -o addrules.sh\n</code></pre><p>将addrules.sh脚本拷贝到10.0.4.20节点执行即可。</p><p><strong>场景2：删除节点。</strong></p><p>如果我们要删除一个节点，需要在保留的节点和数据库节点中，将该节点的访问权限删除。假如我们要删除10.0.4.22节点，设置防火墙规则需要下面3个步骤。</p><ol>\n<li>在保留节点删除10.0.4.22节点访问权限：</li>\n</ol><pre><code class=\"language-bash\">$ go run tools/geniptables/main.go -c access.yaml -t app --delete 10.0.4.22 -o delete.sh\n</code></pre><p>将delete.sh脚本拷贝到保留节点（10.0.4.20，10.0.4.21），并执行。</p><ol start=\"2\">\n<li>在数据库节点删除10.0.4.22节点访问权限：</li>\n</ol><pre><code class=\"language-bash\">$ go run tools/geniptables/main.go -c access.yaml -t db --delete 10.0.4.22 -o delete.sh\n</code></pre><p>将delete.sh脚本拷贝到10.0.4.20节点执行即可。</p><ol start=\"3\">\n<li>将下线的节点从access.yaml文件中的hosts部分删除。</li>\n</ol><h3>IAM安全加固（内网安全）</h3><p>这里，我们来看第二种情况：假定我们系统部署在一个安全的内网环境中，这时候加固系统就会变得异常简单，只需要允许来源IP为内网IP的客户端访问我们提供的各类端口即可。在我们设置完iptables规则之后，后续再新增或者删除节点，就不需要再做变更了。</p><p>具体可以分为5个步骤。</p><p><strong>第一步，进入iam项目源码根目录。</strong></p><p><strong>第二步，配置accesss.yaml</strong>（工具根据此配置，自动生成iptables设置脚本），内容如下（<a href=\"https://github.com/marmotedu/iam/blob/v1.0.8/configs/access.yaml\">configs/access.yaml</a>文件）：</p><pre><code class=\"language-yaml\"># 允许登录SSH节点的来源IP，可以是固定IP(例如10.0.4.2)，也可以是个网段，0.0.0.0/0代表不限制来源IP\nssh-source: 10.0.4.0/24\n\n# 来源IP可以访问的应用端口列表（iam-apiserver, iam-authz-server, iam-pump对外暴露的的端口）\nports:\n  - 8080\n  - 8443\n  - 9090\n  - 9443\n  - 7070\n\n# 来源IP可以访问的数据库端口列表（Redis, MariaDB, MongoDB）\ndbports:\n  - 3306\n  - 6379\n  - 27017\n</code></pre><p>上面配置中，我们仅仅指定了IAM服务端口和数据库端口。</p><p><strong>第三步，生成iptables初始化脚本：</strong></p><pre><code class=\"language-bash\">$ go run tools/geniptables/main.go -c access.yaml -t app --cidr=10.0.4.0/24 -a -o firewall.sh\n$ ls firewall.sh\nfirewall.sh\n</code></pre><p><strong>第四步，将firewall.sh脚本拷贝到10.0.4.20和10.0.4.21节点执行：</strong></p><pre><code class=\"language-bash\">$ scp firewall.sh root@10.0.4.20:/tmp/\n$ scp firewall.sh root@10.0.4.21:/tmp/\n</code></pre><p>登陆10.0.4.20和10.0.4.21机器执行 <code>/tmp/firewall.sh</code> 。</p><p><strong>第五步，在10.0.4.20（数据库节点）节点上，设置iptables规则，以允许各节点访问。</strong></p><p>因为数据库节点也位于10.0.4.20节点，所以只需要添加新的rule，并将 <code>iptables -A INPUT -j DROP</code> 规则放到最后执行即可。</p><pre><code class=\"language-bash\">$ go run tools/geniptables/main.go -c access.yaml -t db --cidr=10.0.4.0/24 -o addrules.sh\n</code></pre><p>然后，将 <code>addrules.sh</code> 脚本拷贝到10.0.4.20节点执行。</p><p>如果要增加节点，你只需要重新执行第三步，生成firewall.sh脚本，并将firewall.sh脚本拷贝到新节点上执行即可。删除节点，则不需要做任何操作。</p><p>接下来，我们再来看下如何对IAM应用进行弹性伸缩操作。</p><h2>弹性伸缩</h2><p>弹性伸缩包括扩容和缩容。扩容是指当业务量越来越大时，能够很容易地增加计算节点，来分散工作负载，从而实现计算等能力的扩展。缩容是指当业务量变小时，能够很容易地减少计算节点，从而减小成本。</p><p>在系统上线初期，通常业务量不会很大，但是随着产品的迭代，用户量的增多，系统承载的请求量会越来越多，系统承载的压力也会越来越大。这时，就需要我们的系统架构有能力进行水平扩容，以满足业务需求，同时避免因为系统负载过高造成系统雪崩。</p><p>一些电商系统，在双11这类促销活动之前会提前扩容计算节点，以应对即将到来的流量高峰。但是活动过后，流量会逐渐下降，这时就需要我们的系统有能力进行缩容，以减少计算节点，从而节省成本。</p><p>一个可伸缩的系统架构，是我们在进行系统设计时必须要保证的。如果系统不具有伸缩性，那么当我们后期需要扩缩容时，就需要对代码进行大改，不仅会增加额外的工作量，还会拖累产品的迭代速度。而且你想想，改完之后还要测试，发布之后，还可能因为代码变更引入Bug。总之，不具伸缩性的系统架构可以说是后患无穷。</p><p>IAM系统在设计之初就考虑到了系统的伸缩能力，我们可以很容易地对系统进行扩缩容。下面，我来分别介绍下如何对系统进行扩容和缩容。</p><h3>系统扩容</h3><p>系统扩容的步骤很简单，你只需要进行下面这5步：</p><ol>\n<li>根据需要申请计算节点，如无特殊需求，计算节点的配置、操作系统等要跟已有的节点保持一致。</li>\n<li>在新的节点上部署iam-apiserver、iam-authz-server、iam-pump，部署方式跟部署其他节点一样。</li>\n<li>在新节点部署Nginx，并将新节点的IP加入到已有所有节点的Nginx upstream配置中，重启Nginx。</li>\n<li>在新节点部署Keepalived，并将新节点的IP加入到已有所有节点的unicast_peer配置中，重启Keepalived。</li>\n<li>修改iptables规则，并刷新所有机器的iptables。</li>\n</ol><h3>系统缩容</h3><p>系统缩容是系统扩容的逆向操作，也是5个步骤：</p><ol>\n<li>根据需要，确定要删除的节点。</li>\n<li>关闭待删除节点的iam-apiserver、iam-authz-server、iam-pump服务。</li>\n<li>从所有保留节点的Nginx upstream配置中，删除待删除节点的IP地址, 重启Nginx。</li>\n<li>从所有保留节点的Keepalived unicast_peer配置中，删除待删除节点的IP地址, 重启Keepalived。</li>\n<li>修改iptables规则，并刷新所有保留机器的iptables。</li>\n</ol><h2>总结</h2><p>安全对于应用软件来说至关重要，在部署应用时，也一定要评估应用的安全性，并采取一定的措施来保证安全性。</p><p>在进行软件部署时，保证应用安全性最简单有效的方式是使用iptables规则来加固系统。实现思路也很简单，就是使用iptables规则，只允许特定来源的IP访问特定的端口。</p><p>在业务正式上线之后，可能会遇到业务高峰期或低峰期。业务高峰期，可能需要添加机器，提高系统的吞吐量，可以在新机器上安装需要扩容的服务组件，并安装和配置好Nginx和Keepalived，之后将该服务器添加到Nginx的upstream中。在业务低峰期时，可以将服务器从Nginx的upstream列表中移除，并关停IAM应用的服务。</p><h2>课后练习</h2><ol>\n<li>请根据这一讲学习的内容，再增扩容一台机器。</li>\n<li>思考下，你在应用部署时，还有哪些比较好的应用安全加固方法，欢迎在留言区分享。</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"41 | 软件部署实战（中）：IAM 系统生产环境部署实战","id":412483},"right":{"article_title":"43｜技术演进（上）：虚拟化技术演进之路","id":414159}}},{"article_id":414159,"article_title":"43｜技术演进（上）：虚拟化技术演进之路","article_content":"<p>你好，我是孔令飞。</p><p>在前面的三讲中，我介绍了传统应用的部署方式。但是，随着软件架构进入云原生时代，我们越来越多地使用云原生架构来构建和部署我们的应用。为了给你演示如何使用云原生化的方式来部署IAM应用，接下来我会介绍如何基于Kubernetes来部署IAM应用。</p><p>在Kubernetes集群中部署IAM应用，会涉及到一些重要的云原生技术，例如Docker、Kubernetes、微服务等。另外，云原生架构中还包含了很多其他的技术。为了让你提前了解后面部署需要的相关技术，同时比较通透地了解当前最火热的云原生架构，这一讲我就采用技术演进的思路，来详细讲解下云原生技术栈的演进中的虚拟化技术演进部分。</p><p>因为这一讲涉及的技术栈很多，所以我会把重点放在演进过程上，不会详细介绍每种技术的具体实现原理和使用方法。如果你感兴趣，可以自行学习，也可以参考我为你整理的这个资料：<a href=\"https://github.com/marmotedu/awesome-books#%E4%BA%91%E8%AE%A1%E7%AE%97\">awesome-books</a>。</p><p>在讲这个演进过程之前，我们先来看下这个问题：我们为什么使用云？</p><h2>我们为什么使用云？</h2><p>使用云的原因其实很简单，我们只是想在云上部署一个能够对外稳定输出业务能力的服务，这个服务以应用的形态部署在云上。为了启动一个应用，我们还需要申请系统资源。此外，我们还需要确保应用能够快速迭代和发布，出故障后能够快速恢复等，这就需要我们对应用进行生命周期管理。</p><!-- [[[read_end]]] --><p>应用、系统资源、应用生命周期管理这3个维度就构成了我们对云的所有诉求，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/yy/eb/yyea295d642681444a004d55e8d73eeb.png?wh=1920x1010\" alt=\"图片\"></p><p>接下来的两讲，我就围绕着这3个维度，来给你详细介绍下每个维度的技术演进。这一讲，我会先介绍下系统资源维度的技术演进。在44讲，我会再介绍下应用维度和应用生命周期管理维度的技术演进。</p><p>当前有3种系统资源形态，分别是物理机、虚拟机和容器，这3种系统资源形态都是围绕着虚拟化来演进的。所以，介绍系统资源技术的演进，其实就是介绍虚拟化技术的演进。</p><p>接下来，我们就来看下虚拟化技术是如何演进的。</p><h2>虚拟化技术的演进</h2><p>虚拟化这个概念，其实在20世纪60年代就已经出现了。但因为技术、场景等限制，虚拟化技术曾沉寂过一段时间，直到21世纪虚拟机出现，虚拟化技术又迎来了一波爆发期，并逐渐走向成熟。</p><p>那么，什么是虚拟化技术呢？简单来讲，就是把计算机上的硬件、系统资源划分为逻辑组的技术，由此生成的仅仅是一个逻辑角度的视图。通过虚拟化技术，我们可以在一台计算机上运行多个虚拟机进程，进而发挥计算机硬件的最大利用率。</p><p>虚拟化分为很多种，例如操作系统虚拟化、存储虚拟化、网络虚拟化、桌面虚拟化等。其中，最重要的是操作系统虚拟化，支撑操作系统虚拟化的是底层CPU、内存、存储、网络等的虚拟化，这些资源我们统称为计算资源。</p><p>因为计算资源的虚拟化在虚拟化领域占主导地位，所以很多时候我们说虚拟化技术演进，其实就是在说计算资源技术的演进。在我看来，虚拟化技术的演进过程如下：物理机阶段 -&gt; 虚拟机阶段 -&gt; 容器阶段（Docker + Kubernetes） -&gt; Serverless阶段。</p><h3>物理机阶段</h3><p>上面我提到虚拟化技术包含很多方面，但是整个虚拟化技术是围绕着CPU虚拟化技术来演进的。这是因为，内存虚拟化、I/O虚拟化的正确实现，都依赖于对内存、I/O中一些敏感指令的正确处理，这就涉及到CPU虚拟化，所以CPU虚拟化是虚拟化技术的核心。因此，这一讲我会围绕着CPU虚拟化的演进，来讲解虚拟化技术的演进。这里，我先来介绍一下物理机阶段CPU的相关知识。</p><p>CPU是由一系列指令集构成的，这些指令集主要分为两种，分别是特权指令集和非特权指令集。特权指令集是指那些可以改变系统状态的指令集，非特权指令集是指那些不会影响系统状态的指令集。我举个例子你就明白了：写内存是特权指令集，因为它可以改变系统的状态；读内存是非特权指令集，因为它不会影响系统的状态。</p><p>因为非特权指令集可能会影响整个系统，所以芯片厂商在x86架构上又设计了一种新模式，保护模式，这个模式可以避免非特权指令集非法访问系统资源。</p><p>保护模式是通过Ring来实现的。在x86架构上，一共有4个Ring，不同的Ring有不同的权限级别：Ring 0有最高的权限，可以操作所有的系统资源，Ring 3的权限级别最低。Kernel运行在Ring 0上，Application运行在Ring 3上。Ring 3的Application如果想请求系统资源，需要通过system call调用Ring 0的内核功能，来申请系统资源。</p><p>这种方式有个好处：可以避免Applicaiton直接请求系统资源，影响系统稳定性。通过具有更高权限级的Kernel统一调度、统一分配资源，可以使整个系统更高效，更安全。</p><p>x86架构的Ring和调用关系如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/7e/8d/7e2868cd62baae3154bc4e8957e9b48d.png?wh=1920x708\" alt=\"图片\"></p><p>在物理机阶段，对外提供物理资源，这种资源提供方式面临很多问题，例如成本高，维护麻烦、需要建机房、安装制冷设备、服务器不方便创建、销毁等等。所以在云时代，和物理机相比，我们用得更多的是虚拟机。下面我们就来看虚拟机阶段。</p><h3>虚拟机阶段</h3><p>这里，在讲虚拟化技术之前，我想先介绍下x86的虚拟化漏洞，CPU虚拟化技术的演进也主要是围绕着解决这个漏洞来演进的。</p><h4>虚拟化漏洞</h4><p>一个虚拟化环境分为三个部分，分别是硬件、虚拟机监控器（又叫VMM，Virtual Machine Manager），还有虚拟机。</p><p>你可以把虚拟机看作物理机的一种高效隔离的复制，它具有三个特性：同质、高效、资源受控。这三个特点决定了不是所有体系都可以虚拟化，比如目前我们用得最多的x86架构，就不是一个可虚拟化的架构，我们称之为虚拟化漏洞。</p><p>在虚拟化技术产生后，诞生了一个新的概念：敏感指令。敏感指令是指可以操作特权资源的指令，比如修改虚拟机运行模式、物理机状态，读写敏感寄存器/内存等。显然，所有的特权指令都是敏感指令，但不是所有的敏感指令都是特权指令。特权指令和敏感指令的关系，可以简单地用这张图来表示：</p><p><img src=\"https://static001.geekbang.org/resource/image/30/6a/30da714fc8341600f558817789a9096a.png?wh=1920x1942\" alt=\"图片\"></p><p>在一个可虚拟化的架构中，所有的敏感指令应该都是特权指令。x86架构中有些敏感指令不是特权指令，最简单的例子是企图访问或修改虚拟机模式的指令。所以，x86架构是有虚拟化漏洞的。</p><h4>Hypervisor技术的演进</h4><p>为了解决x86架构的虚拟化漏洞，衍生出了一系列的虚拟化技术，这些虚拟化技术中最核心的是Hypervisor技术。所以接下来，我就介绍下Hypervisor技术的演进。</p><p>Hypervisor，也称为虚拟机监控器 VMM，可用于创建和运行虚拟机 （VM）。它是一种中间软件层，运行在基础物理服务器和操作系统之间，可允许多个操作系统和应用共享硬件。通过让Hypervisor以虚拟化的方式共享系统资源（如内存、CPU资源），一台主机计算机可以支持多台客户机虚拟机。</p><p>Hypervisor、物理机和虚拟机的关系如下图：</p><p><img src=\"https://static001.geekbang.org/resource/image/2d/7f/2d471ca14d50b80ffcd421c8719cf17f.png?wh=1920x1080\" alt=\"图片\"></p><p>按时间顺序，Hypervisor技术的发展依次经历了下面3个阶段：</p><ol>\n<li>软件辅助的完全虚拟化（Software-assisted full virtualization）：该虚拟化技术在1999年出现，里面又包含了解释执行（如Bochs）、扫描与修补（如VirtualBox）、二进制代码翻译（如Vmware、Qemu）三种技术。</li>\n<li>半虚拟化（Para-virtualization）：该虚拟化技术在2003年出现，也叫类虚拟化技术，典型的Hypervisor代表是Xen。</li>\n<li>硬件辅助的完全虚拟化（Hardware-assistant full virtualization ）：该虚拟化技术在2006年出现，典型的Hypervisor代表是KVM。当前普遍使用的主流虚拟化技术，就是以KVM为代表的硬件辅助的完全虚拟化。</li>\n</ol><p>下面，我就来简单介绍下这三个阶段。</p><p><strong>先来看第一个阶段，软件辅助的完全虚拟化</strong>，它又分为解释执行、扫描与修补、二进制代码翻译三个演进阶段。</p><ol>\n<li>解释执行</li>\n</ol><p>简单地说，解释执行的过程就是取一条指令，模拟出这条指令的执行效果，再取下一条指令。这种技术因为思路比较简单，所以容易实现，复杂度低。执行时，编译好的二进制代码是不会被载入到物理CPU直接运行的，而是由解释器逐条解码，再调入对应的函数来模拟指令的功能。解释过程如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/9d/c7/9d6c29e788e62ec16115d02a7f0807c7.png?wh=1920x1180\" alt=\"图片\"></p><p>因为每一条指令都要模拟，所以就解决了虚拟化漏洞，同时也可以模拟出一个异构的CPU结构，比如在x86架构上模拟出一个ARM架构的虚拟机。也正是因为每一条指令都需要模拟，不区别对待，导致这种技术的性能很低。</p><ol start=\"2\">\n<li>扫描与修补</li>\n</ol><p>由于解释执行性能损失很大，再加上虚拟机中模拟的虚拟CPU和物理CPU的体系结构相同（同质），这样大多数指令可以直接在物理CPU上运行。因此，CPU虚拟化过程中，可以采用更优化的模拟技术来弥补虚拟化漏洞。</p><p>扫描与修补技术就是通过这种方式，让大多数指令直接在物理CPU上运行，而把操作系统中的敏感指令替换为跳转指令，或者会陷入到VMM中去的指令。这样，VMM一旦运行到敏感指令，控制流就会进入VMM中，由VMM代为模拟执行。过程如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/f0/4e/f0fdb92c7c1fedc3bbedc90d411d314e.png?wh=1920x1460\" alt=\"图片\"></p><p>使用这种方式，因为大部分指令不需要模拟，可以直接在CPU上运行，所以性能损失相对较小，实现起来比较简单。</p><ol start=\"3\">\n<li>二进制代码翻译</li>\n</ol><p>这个算是软件辅助的完全虚拟化的主流方式了，早期的VMware用的就是这个技术。二进制代码翻译会在VMM中开辟一段缓存，将翻译好的代码放在缓存中。在执行到某条指令的时候，直接从内存中找到这条指令对应的翻译后的指令，然后在CPU上执行。</p><p>在性能上，二进制代码翻译跟扫描与修补技术各有长短，但是实现方式最为复杂。它的过程如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/ba/1a/ba3962c283c567d6f20c8d780930d41a.jpg?wh=1920x1698\" alt=\"图片\"></p><p>看到这里，你可能会对模拟和翻译这两个概念有疑惑，我在这里解释下模拟和翻译的区别：模拟是将A动作模拟成B动作，而翻译是将A指令翻译成B指令，二者是有本质不同的。</p><p><strong>然后，我们来看Hypervisor技术发展的第二个阶段，Para-virtualization。</strong></p><p>软件辅助的完全虚拟化对x86的指令做了翻译或者模拟，在性能上，多多少少都会有些损失，而这些性能损失在一些生产级的场景是不可接受的。所以，在2003年出现了Para-virtualization技术，也叫半虚拟化/类虚拟化。和之前的虚拟化技术相比，Para-virtualization在性能上有了大幅度的提升，甚至接近于原生的物理机。</p><p>Para-virtualization的大概原理是这样的：Hypervisor运行在Ring 0中，修改客户机操作系统内核，将其中的敏感指令换成hypercall。hypercall是一个可以直接跟VMM通信的函数，这样就绕过了虚拟化的漏洞（相当于所有敏感指令都被VMM捕获了），同时不存在模拟和翻译的过程，所以性能是最高的。这个过程如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/6e/77/6ea013e621c58fb78d444449fb55f977.png?wh=1920x902\" alt=\"图片\"></p><p>因为要修改操作系统，所以不能模拟一些闭源的操作系统，比如Windows系列。另外，修改客户机操作系统内核还是有些开发和维护工作量的。所以，随着硬件辅助完全虚拟化技术的成熟，Para-virtualization也逐渐被替换掉了。</p><p><strong>然后，我们来看Hypervisor技术发展的第三个阶段，<strong><strong>硬件辅助的完全虚拟化</strong></strong>。</strong></p><p>在2006年，Intel和AMD分别在硬件层面支持了虚拟化，比如Intel的VT-X技术和AMD的SVM。它们的核心思想都是引入新运行模式，可以理解为增加了一个新的CPU Ring -1，权限比Ring 0 还高，使VMM运行在Ring -1下，客户机内核运行在Ring 0下。</p><p>通常情况下，客户机的核心指令可以直接下达到计算机系统硬件执行，不需要经过VMM。当客户机执行到敏感指令的时候，CPU会从硬件层面截获这部分敏感指令，并切换到VMM，让VMM来处理这部分敏感指令，从而绕开虚拟化漏洞。具体如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/e6/91/e60585ea58107b48af2815a3fd552591.png?wh=1920x929\" alt=\"图片\"></p><p>因为CPU是从硬件层面支持虚拟化的，性能要比软件模拟更高，同时硬件虚拟化可以不用去修改操作系统。所以，即使是现在，硬件辅助的完全虚拟化也是主流的虚拟化方式。</p><p>接下来我们来看虚拟化技术演进的第三阶段，容器阶段。</p><h3>容器阶段</h3><p>2005年，诞生了一种新的虚拟化技术，容器技术。容器是一种轻量级的虚拟化技术，能够在单一主机上提供多个隔离的操作系统环境，通过一系列的命名空间隔离进程，每个容器都有唯一的可写文件系统和资源配额。</p><h4>容器引擎Docker</h4><p>容器技术的的代表项目就是Docker，Docker是Docker公司在2013年推出的容器项目，因为轻量、易用的特点，迅速得到了大规模的使用。Docker的大规模应用使得系统资源的形态由虚拟机阶段进入到了容器阶段。</p><p>基于Docker容器化技术，开发者可以打包他们的应用以及依赖和配置到一个可移植的容器中，然后发布到任何流行的 Linux/Windows 机器上。开发者无需关注底层系统、环境依赖，这使得容器成为部署单个微服务的最理想的工具。</p><p>Docker通过Linux Namespace技术来进行资源隔离，通过Cgroup技术来进行资源分配，具有更高的资源利用率。Docker跟宿主机共用一个内核，不需要模拟整个操作系统，所以具有更快的启动时间。在Docker镜像中，已经打包了所有的依赖和配置，这样就可以在不同环境有一个一致的运行环境，所以能够支持更快速的迁移。另外，Docker的这些特性也促进了DevOps技术的发展。</p><p>我这里拿Docker和虚拟机来做个对比，让你感受下Docker的强大。二者的架构对比如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/7e/98/7e24d5667f4d41724c9cc0ab6fee5398.png?wh=1920x822\" alt=\"图片\"></p><p>可以看到，Container相比于虚拟机，不用模拟出一个完整的操作系统，非常轻量。因此，和虚拟机相比，容器具有下面这些优势：</p><p><img src=\"https://static001.geekbang.org/resource/image/65/5c/65049ffd61b12de9fcd5ccf8f684385c.png?wh=1920x1209\" alt=\"图片\"></p><p>从这张表格里你可以看到，在启动时间、硬盘占用量、性能、系统支持量、资源使用率、环境配置这些方面，Docker和虚拟机相比具有巨大的优势。这些优势，使得Docker成为比虚拟机更流行的应用部署媒介。</p><p>也许这时你想问了：Docker就这么好，一点缺点都没有吗？显然不是的，Docker也有自己的局限性。</p><p>我们先来看一下生产环境的Docker容器是什么样的：一个生产环境的容器数量可能极其庞大，关系错综复杂，并且生产环境的应用可能天生就是集群化的，具备高可用、负载均衡等能力。Docker更多是用来解决单个服务的部署问题，无法解决生产环境中的这些问题。并且，不同节点间的Docker容器无法相互通信。</p><p>不过，这些问题都可以通过容器编排技术来解决。业界目前也有很多优秀的容器编排技术，比较受欢迎的有Kubernetes、Mesos、Docker Swarm、Rancher等。这两年，随着Kubernetes的发展壮大，Kubernetes已经成为容器编排的事实标准。</p><h4>容器编排技术Kubernetes</h4><p>因为我们后面会基于Kubernetes来部署IAM应用，所以这里我会详细介绍下Kubernetes服务编排技术。</p><p>Kubernetes是Google开源的一个容器编排技术（编排也可以简单理解为调度、管理），用于容器化应用的自动化部署、扩展和管理。它的前身是Google内部的Borg项目。Kubernetes的主要特性有网络通信、服务发现与负载均衡、滚动更新 &amp; 回滚、自愈、安全配置管理、资源管理、自动伸缩、监控、服务健康检查等。</p><p>Kubernetes通过这些特性，解决了生产环境中Docker存在的问题。Kubernetes和Docker相辅相成，Kubernetes的成功也使Docker有了更大规模的使用，最终使得 Docker 成为比虚拟机更流行的计算资源提供方式。</p><p>接下来，我围绕着下面这张架构图来介绍K8S（Kubernetes）的基本概念：</p><p><img src=\"https://static001.geekbang.org/resource/image/ee/7c/ee25460fdbc4b257440dd4f6b109237c.jpg?wh=1920x1149\" alt=\"图片\"></p><p>Kubernetes采用的是Master-Worker架构模式。其中，Master节点是Kubernetes最重要的节点，里面部署了Kubernetes的核心组件，这些核心组件共同构成了Kubernetes的Control Plane（控制面板）。而Worker，也就是图中的Node Cluster，就是节点集群。其中，每一个Node就是具体的计算资源，它既可以是一台物理服务器，也可以是虚拟机。</p><p>我们先来介绍下Master节点上的组件。</p><ul>\n<li><strong>Kube API Server：</strong>提供了资源操作的唯一入口，并提供认证、授权、访问控制、API 注册和发现等机制。</li>\n<li><strong>Kube Scheduler：</strong>负责资源的调度，按照预定的调度策略将 Pod 调度到相应的机器上。</li>\n<li><strong>Kube Controller Manager：</strong>负责维护集群的状态，比如故障检测、自动扩展、滚动更新等。</li>\n<li><strong>Cloud Controller Manager：</strong>这个组件是在Kubernetes 1.6版本加入的与基础云提供商交互的控制器。</li>\n<li><strong>Etcd：</strong>分布式的K-V存储，独立于Kubernetes的开源组件。主要存储关键的元数据，支持水平扩容保障元数据的高可用性。基于Raft算法实现强一致性，独特的watch机制是Kubernetes设计的关键。</li>\n</ul><p>介绍完了Master，再看看每一个Kubernetes Node需要有哪些组件。</p><ul>\n<li><strong>Kubelet：</strong>负责维持容器的生命周期，同时也负责 volume（CVI）和网络（CNI）的管理。</li>\n<li><strong>kube-proxy：</strong>kube-proxy是集群中每个节点上运行的网络代理，维护节点上的网络规则，它允许从集群的内部或外部网络与Pod进行网络通信，并负责为 Service 提供集群内部的服务发现和负载均衡。</li>\n<li><strong>Container Runtime：</strong>负责镜像管理以及 Pod 和容器的真正运行（CRI），默认的容器运行时为 Docker。</li>\n</ul><p>上面那张架构图里的Service、Deployment、Pod等，都不算是组件，而是属于Kubernetes资源对象，我们稍后再做介绍。这里我先简单介绍下架构图的UI dashboard和 kubectl。</p><ul>\n<li>UI dashboard是Kubernetes官方提供的web控制面板，可以对集群进行各种控制，直接与API Server进行交互，其实就是API Server暴露出来的可视化接口。在这里可以直观地创建Kubernetes对象、查看Pod运行状态等。UI dashboard界面如下图所示：</li>\n</ul><p><img src=\"https://static001.geekbang.org/resource/image/5c/49/5c6acce4e90048e63426b9e896be8b49.png?wh=1920x1148\" alt=\"图片\"></p><ul>\n<li>kubectl是Kubernetes的客户端工具，提供了非常多的命令、子命令、命令行选项，支持开发或运维人员在命令行快速操作Kubernetes集群，例如对各类Kubernetes资源进行增删改查操作，给资源打标签，等等。下面是执行<code>kubectl describe service iam-pump</code>命令获取<code>iam-pump</code>详细信息的命令行截图：</li>\n</ul><p><img src=\"https://static001.geekbang.org/resource/image/60/38/6046e3586eefce16b923aebbf0de2538.png?wh=1269x721\" alt=\"图片\"></p><p>Kubernetes有多种多样的Objects，如果要查看所有Objects的Kind，可以使用命令<code>kubectl api-resources</code>。我们通过这些Objects来完成Kubernetes各类资源的创建、删除等操作。因为我们这一讲的核心目的是介绍云原生技术的演进，所以不会详细介绍Kubernetes资源对象的使用方式。你如果感兴趣，可以查看<a href=\"https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/kubernetes-objects/\">Kubernetes官方文档</a>。</p><p>我这里简单介绍一下<strong>Kubernetes对象</strong>的一些基本信息，以及在架构图中出现的Deployment、Pod、Service三种对象。</p><p>下面是一个典型的Kubernetes对象YAML描述文件：</p><pre><code class=\"language-yaml\">apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\n  labels:\n    name: nginx\nspec:\n  # ...\n</code></pre><p>在这个描述文件中，apiVersion和kind共同决定了当前YAML配置文件应该由谁来处理，前者表示描述文件使用的 API 组，后者表示一个 API 组中的一个资源类型。这里的 <code>v1</code> 和 <code>Pod</code> 表示的就是核心 API 组 <code>api/v1</code> 中的 <code>Pod</code> 类型对象。</p><p>metadata则是一些关于该对象的元数据，其中主要有<code>name</code>、<code>namespace</code>、<code>labels</code>、<code>annotations</code>。其中， <code>name</code> 需要在 <code>namespace</code> 下唯一，成为这个对象的唯一标识。<code>label</code>和<code>annotations</code>分别是这个对象的一些标签和一些注解，前者用于筛选，后者主要用来标注提示性的信息。</p><p>接下来，我再介绍下Pod、Deployment、Service 这3种对象。</p><ol>\n<li>Pod</li>\n</ol><p>Pod是Kubernetes中运行的最小的、最简单的计算单元，我觉得Pod也是Kubernetes最核心的对象。Pod中可以指定运行多个Containers，可以挂载volume来实现部署有状态的服务，这些都在<code>spec</code>中被指定。</p><p>对于任意类型的对象，<code>spec</code>都是用来描述开发人员或运维人员对这个对象所期望的状态的，对于不同类型的对象，<code>spec</code>有不同的子属性。</p><p>下面是一个Pod示例，我们在YAML描述文件里指定了期望Pod运行的Docker镜像和命令：</p><pre><code class=\"language-yaml\">apiVersion: v1\nkind: Pod\nmetadata:\n  name: busybox\n  labels:\n    app: busybox\nspec:\n  containers:\n  - image: busybox\n    command:\n      - sleep\n      - \"3600\"\n    imagePullPolicy: IfNotPresent\n    name: busybox\n  restartPolicy: Always\n</code></pre><ol start=\"2\">\n<li>Deployment</li>\n</ol><p>一般来说，我们不会直接部署Pod，而是部署一个Deployment或者StatefulSet之类的Kubernetes对象。Deployment一般是无状态服务；StatefulSet一般是有状态服务，会使用volume来持久化数据。下面是一个部署两个Pod的示例：</p><pre><code class=\"language-yaml\">apiVersion: apps/v1 # for versions before 1.9.0 use apps/v1beta2\nkind: Deployment\nmetadata:\n  name: my-nginx\nspec:\n  selector:\n    matchLabels:\n      run: my-nginx\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        run: my-nginx\n    spec:\n      containers:\n      - name: my-nginx\n        image: nginx\n        ports:\n        - containerPort: 80\n</code></pre><ol start=\"3\">\n<li>Service</li>\n</ol><p>Service是Kubernetes中另一个常见的对象，它的作用是作为一组Pod的负载均衡器，利用selector将Service和Pod关联起来。</p><p>下面这个示例里，使用的是<code>run: my-nginx</code>这个label。这个Service绑定的就是上面那个Deployment部署的nginx服务器：</p><pre><code class=\"language-yaml\">apiVersion: v1\nkind: Service\nmetadata:\n  name: my-nginx\n  labels:\n    run: my-nginx\nspec:\n  ports:\n  - port: 80\n    protocol: TCP\n  selector:\n    run: my-nginx\n</code></pre><p>最后我还想介绍下<strong>基于Kubernetes的容器云平台</strong>。各大公有云厂商，都有基于Kubernetes的容器管理平台，目前国内容器服务平台做得比较好的有<a href=\"https://cloud.tencent.com/document/product/457/6759\">腾讯云容器服务TKE</a>、<a href=\"https://help.aliyun.com/product/85222.html\">阿里云容器服务ACK</a>。</p><p>TKE基于原生 Kubernetes ，提供以容器为核心的解决方案，解决用户开发、测试及运维过程的环境问题，帮助用户降低成本、提高效率。腾讯云容器服务 TKE 完全兼容原生 Kubernetes API，并扩展了腾讯云的云硬盘、负载均衡等 Kubernetes 插件，同时以腾讯云私有网络为基础，实现了高可靠、高性能的网络方案。</p><h3>Serverless阶段</h3><p>容器阶段之后，虚拟化技术的演进方向是什么呢？我们接着来看下Serverless阶段。</p><p>在2014年的时候，AWS推出了Lambda服务，这是一个Serverless服务。从此，Serverless越来越引人注意，成为了这几年最受关注的技术。我先介绍下什么是Serverless。</p><p>Serverless直译过来就是无服务器，无服务器并不代表Serverless真的不需要服务器，只不过服务器的管理，以及资源的分配部分对用户不可见，而是由平台开发商维护。Serverless不是具体的一个编程框架、类库或者工具，它是一种软件系统架构思想和方法。它的核心思想是：用户无需关注支撑应用服务运行的底层资源，比如CPU、内存和数据库等，只需要关注自己的业务开发就行了。</p><p>Serverless具有很多特点，核心特点主要有下面这几个。</p><ul>\n<li>无穷弹性计算能力：根据请求，自动水平扩容实例，拥有近乎无限的扩容能力。</li>\n<li>“零”运维：不需要申请和运维服务器。</li>\n<li>极致的伸缩能力：能够根据CPU、内存、请求量等指标敏感地弹性伸缩，并支持缩容到 0。</li>\n<li>按量计费：真正按使用量去计费。</li>\n</ul><p>在我看来，Serverless有3种技术形态，分别是云函数、Serverless容器、BaaS（Backend as a Service），如下图：</p><p><img src=\"https://static001.geekbang.org/resource/image/cb/19/cba931763a846ab8008e5600cd6e5419.jpg?wh=1920x641\" alt=\"图片\"></p><p>这3种Serverless技术形态中，Serverless容器是核心，云函数和BaaS起辅助作用。Serverless容器可以承载业务的核心架构，云函数则可以很好地适配触发器场景，BaaS则可以满足我们对各种其他Serverless组件的需求，例如Serverless数据库、Serverless存储等。</p><p>这3种技术形态，各大公用云厂商都早已有相应的产品，其中比较优秀的产品是腾讯云推出的Serverless产品，SCF、EKS和TDSQL-C。下面我分别介绍下。</p><ul>\n<li><a href=\"https://cloud.tencent.com/document/product/457/39804\">EKS</a>：弹性容器服务（Elastic Kubernetes Service）是腾讯云容器服务推出的无需用户购买节点即可部署工作负载的服务模式。EKS 完全兼容原生 Kubernetes，支持使用原生方式购买及管理资源，按照容器真实使用的资源量计费。</li>\n<li><a href=\"https://cloud.tencent.com/document/product/583\">SCF</a>：云函数（Serverless Cloud Function）是腾讯云为企业和开发者们提供的无服务器执行环境，帮助你在无需购买和管理服务器的情况下运行代码。你只需使用平台支持的语言编写核心代码，并设置代码运行的条件，就能在腾讯云基础设施上弹性、安全地运行代码。</li>\n<li><a href=\"https://cloud.tencent.com/document/product/1003/30488\">TDSQL-C</a>：云原生数据库（Cloud Native Database TDSQL-C）是腾讯云自研的新一代高性能高可用的企业级分布式云数据库，具有高吞吐量、高可靠性等优点。</li>\n</ul><p>我们开始的时候提到，应用、系统资源、应用生命周期管理这3个维度构成了我们对云的所有诉求。那么到这里，系统资源维度的技术演进我就介绍完了。下一讲，我会介绍应用维度和应用生命周期管理维度的技术演进。</p><h2>总结</h2><p>这一讲，我主要通过虚拟化技术的演进，介绍了系统资源维度的技术演进。</p><p>虚拟化技术的演进流程为：物理机阶段 -&gt; 虚拟机阶段 -&gt; 容器阶段 -&gt; Serverless阶段。其中，物理机到虚拟机阶段的演进技术，主要是为了解决x86架构的虚拟化漏洞。要虚拟CPU、内存和I/O，就需要捕获其中的敏感指令，防止这些敏感指令修改系统状态，影响系统的稳定性。x86架构有些敏感指令不是特权指令，导致这些指令可以从客户机中直接在物理CPU上执行，从而可能会影响系统状态。所以，我们说x86架构是有虚拟化漏洞的。</p><p>在虚拟机阶段，又诞生了3种不同的虚拟化技术，分别是软件辅助的完全虚拟化、半虚拟化和硬件辅助的完全虚拟化。因为硬件辅助的完全虚拟化技术不需要修改客户机内核，并且有着接近物理机的性能，所以成为当前的虚拟化主流技术，并以KVM为事实技术标准。</p><p>因为容器技术比虚拟机更加轻量，再加上Docker、Kubernetes项目的诞生，使得大规模使用容器技术变得可行，所以这几年系统资源的提供形态已经由虚拟机转变成了容器。</p><p>系统资源的最终形态，我认为会是Serverless。Serverless技术中，又分为3种技术形态：云函数、Serverless容器和BaaS。在业务架构Serverless化的过程中，整个部署架构会以Serverless容器为主，云函数为辅。</p><h2>课后练习</h2><ol>\n<li>Docker的隔离性比虚拟机弱一些，思考下，有没有一种更好的方式，既可以快速启动一个轻量级的容器，又拥有比Docker更好的隔离性？</li>\n<li>思考下，如何将一个普通的Kubernetes集群，转变为Serverless化的Kubernetes集群。</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"42 | 软件部署实战（下）：IAM系统安全加固、水平扩缩容实战","id":413279},"right":{"article_title":"44｜技术演进（下）：软件架构和应用生命周期技术演进之路","id":414856}}},{"article_id":414856,"article_title":"44｜技术演进（下）：软件架构和应用生命周期技术演进之路","article_content":"<p>你好，我是孔令飞。</p><p>应用、系统资源、应用生命周期管理这 3 个维度，构成了我们对云的所有诉求。上一讲，我从系统资源维度，介绍了虚拟化技术的演进之路。这一讲，我会介绍下应用维度和应用生命周期管理维度的技术演进。</p><p>应用软件架构是用来构建应用的，不同的软件架构，构建应用的方式、效率，以及所构建应用的可维护度、性能都是不同的。随着技术的不断更新迭代，应用软件架构也在不断往前演进。这一讲我们就来看看，应用软件架构都有哪些，这些软件架构都有什么特点，以及它们之间是如何演进的。</p><p>至于应用生命周期管理维度，我在 <a href=\"https://time.geekbang.org/column/article/384021\">09讲</a> 中已经介绍了应用生命周期管理技术的演进，这一讲也会再补充一些核心的技术，比如日志、监控告警、调用链等。</p><p>接下来，我们就先来看下软件架构的演进之路。</p><h2>软件架构的演进</h2><p>软件架构技术演进如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/f1/cd/f17c948f69e84efef776ee367a145dcd.jpg?wh=2248x618\" alt=\"\"></p><p>最开始，我们使用单体架构来构建应用，后面逐渐演进为SOA架构。不管是单体架构，还是SOA架构，都很难满足互联网时代应用快速迭代的诉求。所以，在互联网时代，应用软件架构又演进成了微服务架构。当前我们正处在微服务架构阶段，也有很多团队的业务正在尝试使用Service Mesh替代微服务架构中的一些功能。</p><p>随着Serverless云函数的诞生，也诞生了一种新的软件架构，FaaS架构。这里我先简单介绍下它，后面再详细讲。FaaS架构因为限制多、使用场景局限，目前还仅仅适用于云函数这种系统资源形态，我个人认为它不会成为未来主流的软件架构。还要说明下，业界目前并没有FaaS软件架构这个说法，大家说到FaaS，一般指的都是云函数这种技术形态。这里为了方便描述，我们先这样表达。</p><!-- [[[read_end]]] --><p>接下来，我仍然以技术演进的思路，来介绍下这些软件架构。首先来看下最早的单体架构。</p><h3>单体架构</h3><p>在最早的时候，我们用的软件架构是单体架构。在单体架构中，我们会将应用程序的所有功能都存放在一个代码仓库中，并且发布时，也是发布整个代码仓库的代码和功能。</p><p>在单体架构中，应用软件一般会包含四层，分别是表示层、业务逻辑层、数据访问层、数据库，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/cd/a9/cde65byyc639286dbb27ac6a6abd8da9.jpg?wh=2248x3110\" alt=\"\"></p><p>这里简单介绍下每层的功能。</p><ul>\n<li>表示层：用于直接和用户交互，通常是网页、UI界面。</li>\n<li>业务逻辑层：用来进行业务逻辑处理。使用表示层传来的参数，进行业务逻辑处理，并将结果返回给表示层。</li>\n<li>数据访问层：用来操作数据库，通常包括数据的CURD操作。例如，从数据库中查询用户信息，或者往数据库增加一条用户记录。</li>\n<li>数据库：存储数据的物理介质。我们通过数据访问层来访问数据库中的数据。</li>\n</ul><p>单体架构的优点是应用开发简单，技术单一，测试、部署相对简单明了。因此它比较适合用户访问量较小的应用服务端。但它的缺陷也是非常明显的。随着业务的发展，项目越来越大，单体架构会带来开发效率低、发布周期长、维护困难、稳定性差、扩展性差等问题。另外，单体架构的技术栈也不易扩展，只能在原有的基础上，不断地进行局部优化。</p><h3>SOA架构</h3><p>为了解决单体架构在业务代码变大时带来的各种问题，SOA架构出现了。</p><p>SOA架构是面向服务的软件架构，它的核心理念是：基于SOA的架构思想，将重复共用的功能抽取为组件，以服务的方式给各系统提供服务，服务之间通过ESB企业服务总线进行通信。如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/73/5c/73c40dab7430b1b5d320944b1d13515c.jpg?wh=2248x2489\" alt=\"\"></p><p>SOA架构中，主要有两个角色，分别是服务提供者和服务消费者。服务消费者可以通过发送消息来调用购买商品、申请售后的服务，这些消息由ESB总线转换后，发送给对应的服务，实现 SOA 服务之间的交互通信。</p><p>SOA架构主要适用于大型软件服务企业对外提供服务的场景，至于一般业务场景就并不适用了。这是因为，SOA服务的定义、注册和调用都需要繁琐的编码或者配置来实现，并且ESB总线也容易导致系统的单点风险，并拖累整体性能。</p><h3>微服务架构</h3><p>在互联网时代，越来越多的企业推出了面向普通大众的网站和应用。这些企业没有能力，也没有必要构建和维护ESB企业服务总线。于是，基于SOA架构，又演进出了微服务架构。</p><p>微服务架构由Matrin Fowler在2014年提出，它的理念是将业务系统彻底地组件化和服务化，形成多个可以独立开发、部署和维护的服务或应用的集合。微服务之间采用RESTful等轻量的传输协议，来应对更快的需求变更和更短的开发迭代周期。如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/a2/8f/a2d303433462c384322a4342ff10fe8f.jpg?wh=2248x1984\" alt=\"\"></p><p>微服务架构提出得比较早，但在这几年才逐渐流行起来。这是什么原因呢？一方面，微服务架构基于自身的特点，确实能够解决其他软件架构中存在的一些问题；另一方面，Docker + Kubernetes等云原生技术这几年也发展了起来，能够很好地支撑微服务的部署和生命周期管理。</p><p>总体来说，微服务架构有下面这几个特点：</p><ul>\n<li>微服务遵循单一原则，每个微服务负责一个独立的上下文边界；</li>\n<li>微服务架构提供的服务之间采用 RESTful 等轻量协议传输，比 ESB 更轻量；</li>\n<li>每个服务都有自己独立的业务开发活动和周期；</li>\n<li>微服务一般使用容器技术独立部署，运行在自己的独立进程中，合理分配其所需的系统资源。这样，开发者就可以更加方便地制定每个服务的优化方案，提高系统可维护性。</li>\n</ul><p>微服务架构有很多优点，但也存在着问题。因为一个应用被拆分成一个个的微服务，随着微服务的增多，就会引入一些问题，比如微服务过多导致服务部署复杂。微服务的分布式特点也带来了一些复杂度，比如需要提供服务发现能力、调用链难以追踪、测试困难，等等。服务之间相互依赖，有可能形成复杂的依赖链路，往往单个服务异常，其他服务都会受到影响，出现服务雪崩效应。</p><p>目前业界针对这些问题也有一些标准的解决方案，比如，可以通过Kubernetes、Helm和CI/CD技术，解决微服务部署复杂的问题。至于微服务的分布式特点所带来的复杂性，可以通过一些微服务开发框架来解决。一些业界比较知名的微服务开发框架，比如Spring Cloud和Dubbo，已经很好地解决了上面的问题。另外，云原生相关的技术也可以解决微服务调用链跟踪复杂、故障排障困难等问题。</p><p>另外，在我的日常开发中，经常会有开发者把SOA架构和微服务架构给搞混，所以我在这里再来介绍下二者的相同点和不同点。</p><p>微服务架构是SOA架构设计思想的另一种实现方式，这是二者相同的地方。至于区别，主要有三个。理解了下面这三点，以后你在开发中就很容易区分它们了。</p><ul>\n<li>SOA中的服务，其实只能属于某个应用的服务之一，微服务中的服务则是一个独立的服务，可以被多个应用共用。</li>\n<li>SOA强调尽可能多地共享，而微服务强调尽可能少地共享。</li>\n<li>SOA架构中，服务之间通过ESB来通信，而微服务中，服务之间通过轻量化机制，比如RESTful来实现通信。</li>\n</ul><h3>Service Mesh</h3><p>在讲微服务的时候，我提到微服务架构的一些问题可以通过一些微服务开发框架来解决，比如Spring Cloud和Dubbo。但这里也有个问题：这些框架通常是侵入式的，比如语言只能限制在Java，并且开发的时候要按框架的指定方式来开发。这个理念跟微服务的独立技术栈也是相反的。</p><p>2017年底Service Mesh（服务网格）的出现解决了这个问题，它是一种非侵入式技术，可以提供服务之间的网络调用、限流、熔断和服务监控等功能。Service Mesh类似于TCP/IP协议，无需应用层感知，开发者只需要开发应用程序即可。所以，Service Mesh是致力于解决服务间通讯的基础设施层，它具有下面这几个特点：</p><ul>\n<li>应用程序间通讯的中间层。</li>\n<li>轻量级网络代理。</li>\n<li>非侵入式，应用程序无感知。</li>\n<li>可以将服务治理功能，例如重试、超时、监控、链路追踪、服务发现等功能，以及服务本身解耦。</li>\n</ul><p>Service Mesh目前的发展比较火热，社区有很多优秀的Service Mesh开源项目，例如 <a href=\"https://github.com/istio/istio\">Istio</a> 、<a href=\"https://github.com/linkerd/linkerd2\">Linkerd</a> 等。当前最受欢迎的开源项目是Istio。</p><p>Istio是一个完全开源的服务网格，作为透明的一层接入到现有的分布式应用程序里，提供服务治理等功能。它也是一个平台，拥有可以集成任何日志、遥测和策略系统的 API 接口。</p><p>Istio的大概实现原理是：每个服务都会被注入一个Sidecar（边车）组件，服务之间通信是先通过Sidecar，然后Sidecar再将流量转发给另一个服务。因为所有流量都经过一个Sidecar，所以可以通过Sidecar实现很多功能，比如认证、限流、调用链等。同时还有一个控制面，控制面通过配置Sidecar来实现各种服务治理功能。</p><p>目前Istio的最新版本是1.8，1.8版本的Istio架构图如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/1b/96/1b47b53095c5baa73609b90834ec3996.jpg?wh=2248x1579\" alt=\"\"></p><p>从图中你可以看到，Istio主要包含两大平面。一个是数据平面（Data plane），由Envoy Proxy充当的Sidecar组成。另一个是控制平面（Control plane），主要由三大核心组件Pilot、Citadel、Galley组成。下面，我来分别介绍下这三大核心组件的功能。</p><ul>\n<li>Pilot：主要用来管理部署在Istio服务网格中的Envoy代理实例，为它们提供服务发现、流量管理以及弹性功能，比如A/B测试、金丝雀发布、超时、重试、熔断等。</li>\n<li>Citadel：Istio的核心安全组件，负责服务的密钥和数字证书管理，用于提供自动生成、分发、轮换及撤销密钥和数据证书的功能。</li>\n<li>Galley：负责向Istio的其他组件提供支撑功能，可以理解为Istio的配置中心，它用于校验进入网络配置信息的格式内容正确性，并将这些配置信息提供给Pilot。</li>\n</ul><h3>FaaS架构</h3><p>这几年，以云函数为代表的Serverless技术异常火爆。伴随着Serverless技术的发展，一个新的软件开发模式也诞生了，这就是FaaS架构。</p><p>FaaS架构提供了一种比微服务更加服务碎片化的软件架构模式。简单来说，FaaS架构就是把之前一个完整的业务拆分成一个个Function来部署，通过事件来触发底层Function的执行。</p><p>Function里可能会调用第三方组件，比如数据库、消息队列服务等，这些第三方组件在Serverless架构中，统称为BaaS（Backend as a Serivce）。BaaS把这些后端的服务能力抽象成API让用户调用，用户不需要关注这些后端组件的高可用、扩缩容等运维层面的点，只需要去使用就可以了。</p><p>下面是FaaS架构的示意图：</p><p><img src=\"https://static001.geekbang.org/resource/image/23/43/2388ed22bf86c5f73b06f89ded610b43.jpg?wh=2248x775\" alt=\"\"></p><p>从这张图里你可以看到，用户通过浏览器、手机、小程序等客户端请求触发器服务，例如API网关、COS对象存储、CLS日志等。这些触发器服务在收到来自用户的请求之后，会触发它们所绑定的云函数，云函数会根据请求量等数据，实时启动多个并发实例。在触发云函数时，也会传递参数给云函数，并在云函数中使用这些参数，进行一些业务逻辑处理。例如，调用第三方的服务，将处理结果保存在后端数据库中。</p><p>在我看来，FaaS架构未来不会成为主流，更多的是存在于云函数的场景中。我这么说是因为，如果将应用拆分成一个个Function，这些Function的部署、维护，以及之间的通信会是一个巨大的挑战，从目前来看，还不存在解决这种挑战的技术和条件。另外，FaaS架构也不适合承载一些较重的业务逻辑，比如还没法大规模迁移企业的应用系统。</p><h2>应用生命周期管理技术：监控告警、日志、调用链</h2><p>在这门课的 <a href=\"https://time.geekbang.org/column/article/384021\">09讲</a> 中，我已经详细介绍了应用生命周期管理技术的演进。这里我们可以再回顾一下：应用生命周期，最开始主要是通过研发模式来管理的，按时间线先后出现了瀑布模式、迭代模式、敏捷模式。接着，为了解决研发模式中的一些痛点，出现了另一种管理技术，也就是 CI/CD 技术。随着 CI/CD 技术的成熟，又催生了另一种更高级的管理技术 DevOps。</p><p>其他的细节内容，如果有遗忘，你可以返回 <a href=\"https://time.geekbang.org/column/article/384021\">09讲</a> 再复习一下，这里就不再重复介绍了。接下来，对于应用生命周期管理技术，我会补充一些之前没有讲到的重要技术，包括下面这三个：</p><ul>\n<li>监控告警组件，Prometheus；</li>\n<li>统一日志管理框架，EFK；</li>\n<li>调用链跟踪组件，Jaeger。</li>\n</ul><p>需要说明的是，这些技术之间不存在演进关系，而是平级的，共同作为应用生命周期管理技术的补充。</p><h3>监控告警组件：Prometheus</h3><p>对于应用来说，监控告警功能是必不可少的一项功能，能够让开发者或运维人员及时感知到程序异常，并及时修复。另外，监控也能够收集一些有用的数据，供后面的运营分析使用。云原生技术栈中，也有很多开源的优秀监控告警项目，例如 Zabbix、Prometheus等，其中最受欢迎的是<a href=\"https://github.com/prometheus/prometheus\">Prometheus</a>。</p><p>Prometheus是一款开源的、自带时序数据库的监控告警系统。目前，Prometheus已经成为Kubernetes集群中监控告警系统的标配。它具有下面这几个特点：</p><ul>\n<li>强大的多维度数据模型；</li>\n<li>在多维度上灵活地查询语言；</li>\n<li>不依赖分布式存储，单主节点工作；</li>\n<li>通过基于HTTP的pull方式，采集时序数据；</li>\n<li>可以通过Push Gateway进行时序列数据推送；</li>\n<li>可以通过服务发现或者静态配置，去获取要采集的目标服务器；</li>\n<li>多种可视化图表及仪表盘支持(Grafana)。</li>\n</ul><p>Prometheus的架构如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/04/04/0428cf195e1c7e8c2fd024c87bc3a904.jpg?wh=2248x1416\" alt=\"\"></p><p>从上图可以看出，Prometheus 的主要模块包括Prometheus Server、Exporters、Pushgateway、Alertmanager 以及Grafana图形界面。这些模块，有些是可选的，有些是必选的，大部分组件使用Golang编写。下面我来分别介绍下。</p><ul>\n<li>Prometheus Server（必选）：Prometheus的核心服务，会定期从Jobs/exporters或者Pushgateway中拉取监控数据，并将时间序列（time-series）数据保存TSDB中，TSDB是一个时间序列数据库。</li>\n<li>Client Library（必选）: Prometheus的客户端，应用程序使用Client Library，可以很方便地生成metrics，并暴露一个API接口，供Prometheus server从中拉取（pull）metrics数据。</li>\n<li>Pushgateway（可选）: 接收短期的Jobs（Short-lived）推送（push）过来的metrics数据并缓存，供Prometheus server定期来pull这些监控数据。</li>\n<li>Exporters（可选）: 以agent的形式运行在需要采集监控数据的应用服务器上，收集应用程序监控数据，并提供API接口，供Prometheus server 来 pull metrics数据。</li>\n<li>Alertmanager（可选）: Prometheus的告警组件，接收来自于Prometheus server的alerts，将这些alerts去重、分组，并往配置的接收目的地发送告警。</li>\n<li>Grafana（可选）：Grafana是一款跨平台、开源的可视化数据展示工具，可以用来统计和展示Prometheus监控数据，并带有告警功能，采用Go语言开发。</li>\n</ul><p>Prometheus大致的工作流程是：</p><ol>\n<li>Prometheus Server 定期从配置好的 jobs 或者 Exporters 中拉 metrics，或者接收来自 Pushgateway 的 metrics，再或者从其他的 Prometheus Server 中拉 metrics。</li>\n<li>Prometheus Server 在本地存储收集到的 metrics，并运行已经定义好的 alert.rules，记录新的时间序列，或者向 Alertmanager 推送警报。</li>\n<li>Alertmanager 根据配置文件，对接收到的警报进行处理，发出告警。</li>\n<li>Grafana在图形界面中，可视化地展示采集数据。</li>\n</ol><p>Prometheus会将所有采集到的样本数据以时间序列的方式保存在内存数据库中，并且定时保存到硬盘上。time-series是按照时间戳和值的序列顺序存放的。每条time-series通过指标名称(metrics name)和一组标签集(labelset)命名，如下所示：</p><pre><code>&lt;--------------- metric ---------------------&gt;&lt;-timestamp -&gt;&lt;-value-&gt;\nhttp_request_total{status=&quot;200&quot;, method=&quot;GET&quot;}@1434417560938 =&gt; 94355\nhttp_request_total{status=&quot;200&quot;, method=&quot;GET&quot;}@1434417561287 =&gt; 94334\n\nhttp_request_total{status=&quot;404&quot;, method=&quot;GET&quot;}@1434417560938 =&gt; 38473\nhttp_request_total{status=&quot;404&quot;, method=&quot;GET&quot;}@1434417561287 =&gt; 38544\n\nhttp_request_total{status=&quot;200&quot;, method=&quot;POST&quot;}@1434417560938 =&gt; 4748\nhttp_request_total{status=&quot;200&quot;, method=&quot;POST&quot;}@1434417561287 =&gt; 4785\n</code></pre><p>在time-series中的每一个点，我们称为一个样本（sample）。样本由下面三个部分组成。</p><ul>\n<li>指标(metric)：metric name和描述当前样本特征的labelsets。</li>\n<li>时间戳(timestamp)：一个精确到毫秒的时间戳。</li>\n<li>样本值(value)： 一个folat64的浮点型数据，表示当前样本的值。</li>\n</ul><h3>统一日志管理框架：EFK</h3><p>我们通过监控告警服务感知到程序异常，这时候需要开发者或者运维人员介入排障。排障最有效的手段，是查看日志。所以，对于一个应用来说，一个优秀的日志系统也是必不可少的功能。</p><p>在一个大型的分布式系统中，有很多组件，这些组件分别部署在不同的服务器上。如果系统出故障，需要查看日志排障。这时候，你可能需要登陆不同的服务器，查看不同组件的日志，这个过程是非常繁琐、低效的，也会导致排障时间变长。故障时间越久，意味着给客户带来的损失越大。</p><p>所以，在一个大型系统中，传统的日志查看手段已经满足不了我们的需求了。这时候，我们需要有一个针对分布式系统的日志解决方案。当前，业界有不少成熟的分布式日志解决方案，其中使用最多的是EFK日志解决方案。甚至可以说，EFK已经成为分布式日志解决方案的事实标准。</p><p>EFK中包含三个开源的软件，分别是Elasticsearch、FlieBeat、Kibana。下面，我来介绍下这三个开源软件：</p><ul>\n<li>Elasticsearch：简称ES，是一个实时的、分布式的搜索引擎，通常用来索引和搜索大规模的日志数据，并支持全文、结构化的搜索。</li>\n<li>FlieBeat：轻量的数据采集组件，以agent的方式运行在需要采集日志的服务器上。FlieBeat采集指定的文件，并上报给ES。如果采集日志量大，也可以上报给Kafka，再由其他组件消费Kafka中的日志并转储到ES中。</li>\n<li>Kibana：用于展示ES中存储的日志数据，支持通过图表进行高级数据分析及展示。</li>\n</ul><p>EFK的架构图如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/64/10/64c523c18ee7d86382db3aea06bf8b10.jpg?wh=2248x669\" alt=\"\"></p><p>通过Filebeat采集所在服务器上各服务组件的日志，并上传到Kafka中。Logstash消费Kafka中的日志，过滤后上报给Elasticsearch进行存储。最后，通过Kibana可视化平台来检索这些日志。Kibana是通过调用Elasticsearch提供的API接口，来检索日志数据的。</p><p>当Filebeat的日志生产速度和Logstash的日志消费速度不匹配时，中间的Kafka服务，会起到削峰填谷的作用。</p><h3>调用链跟踪组件：Jaeger</h3><p>在云原生架构中，应用普遍采用微服务。一个应用包含多个微服务，微服务之间会相互调用，这会给排障带来很大的挑战。比如，当我们通过前端访问应用报错时，我们根本不知道具体哪个服务、哪个步骤出问题了。所以这时候，应用就需要有分布式链路追踪能力。目前，业界也有多种分布式链路追踪系统，但用得最多的是<a href=\"https://github.com/jaegertracing/jaeger\">Jaeger</a>。</p><p>Jaeger是Uber推出的一款开源分布式追踪系统，兼容OpenTracing API。这里我们先来介绍两个概念：</p><ul>\n<li><a href=\"https://opentracing.io/\">OpenTracing</a>：它是一套开源的调用链追踪标准，通过提供厂商无关、平台无关的API，来支持开发人员方便地添加/更换追踪系统的实现。</li>\n<li>分布式追踪系统：用于记录请求范围内的信息，是我们排查系统问题和系统性能的利器。分布式追踪系统种类繁多，但核心步骤都有三个，分别是代码埋点、数据存储和查询展示。</li>\n</ul><p>Jaeger架构图如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/09/01/09dc7ae3eb2a32381b3940e8f8743901.png?wh=2239x1202\" alt=\"\"></p><p>Jaeger中有7个关键组件，下面我来具体介绍下。</p><ul>\n<li>instrument：将应用程序与jaeger-client装载起来，从而使应用程序可以上报调用链数据到Jaeger。</li>\n<li>jaeger-client：Jaeger的客户端SDK，负责收集并发送应用程序的调用链数据到jaeger-agent。</li>\n<li>jaeger-agent：接收并汇聚Span数据，并将这些数据上报给jaeger-collector。</li>\n<li>jaeger-collector：从jaeger-agent收集traces信息，并通过处理管道处理这些信息，最后写入后端存储。jaeger-collector是无状态的组件，可以根据需要水平扩缩容。</li>\n<li>Data Store：Jaeger的后端存储组件。目前，支持cassandra、elasticsearch。</li>\n<li>jaeger-ui：jaeger的前端界面，用于展示调用链等信息。</li>\n<li>jaeger-query：用于从存储中检索trace，并提供给jaeger-ui。</li>\n</ul><p>下面，我通过一个Jaeger官方提供的<a href=\"https://www.jaegertracing.io/docs/1.25/getting-started/#all-in-one\">All in One教程</a>来让你更好地理解Jaeger。具体可以分成两个操作步骤。</p><p>第一步，使用<code>jaeger-all-in-one</code>安装Jaeger服务：</p><pre><code>$ wget https://github.com/jaegertracing/jaeger/releases/download/v1.25.0/jaeger-1.25.0-linux-amd64.tar.gz\n$ tar -xvzf jaeger-1.25.0-linux-amd64.tar.gz\n$ mv jaeger-1.25.0-linux-amd64/* $HOME/bin\n$ jaeger-all-in-one --collector.zipkin.host-port=:9411\n</code></pre><p>第二步，启动一个<a href=\"https://github.com/jaegertracing/jaeger/tree/master/examples/hotrod\">HotROD</a>示例应用，产生调用链：</p><pre><code>$ example-hotrod all # 第 1) 我们已经安装了 example-hotrod 命令\n</code></pre><p>访问<code>http://$IP:16686/search</code>可以查找调用链（IP是Jaeger部署的服务器IP地址），如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/68/17/682b4c1ca9c9fd180f913aa12deb7817.jpg?wh=2249x1011\" alt=\"\"></p><p>查询到调用链列表后，可以点击任意一个调用链，查看其详细的调用过程，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/b5/ff/b5afaefacfa0f87ecfb13774532ef8ff.jpg?wh=2249x1274\" alt=\"\"></p><p>具体如何使用Jaeger来记录调用链，你可以参考Jaeger官方给出的<a href=\"https://github.com/jaegertracing/jaeger/tree/master/examples/hotrod\">hotrod</a>示例。</p><h2>总结</h2><p>最后，我们通过下面这张图，来对整个云技术的演进之路做个整体性的回顾：</p><p><img src=\"https://static001.geekbang.org/resource/image/3e/12/3e3d5f421525c321e06a5a360dcd6012.jpg?wh=2221x1313\" alt=\"\"></p><p>通过这张图你可以看到，每种技术并不是孤立存在的，而是相互促进的。在物理机阶段，我们用的是瀑布开发模式和单体架构；在虚拟机阶段，用得比较多的是敏捷开发模式和SOA架构；在容器这个阶段，则使用CI/CD的开发模式和微服务架构。</p><p>在Serverless阶段，软件架构仍然采用微服务，不过在一些触发器场景，也可能会编写一些FaaS架构的函数，部署在类似腾讯云云函数这样的FaaS平台上；底层系统资源主要使用Serverless容器，并配合Kubernetes资源编排技术。在一些触发器场景中，也可能会使用云函数。应用程序中的第三方服务（BaaS），也都是越来越Serverless化的服务。应用生命周期管理技术也会演进为CI/CD/CO这种模式，其中CI/CD更加智能化，自动化程度更高。</p><p>这张图里，阴影部分是我们当前所处的阶段：容器技术得到了大规模普及，业界也在积极探索Serverless技术，并取得了卓有成效的结果。</p><h2>课后练习</h2><ol>\n<li>了解下Kubernetes的声明式API机制，并思考下，微服务架构之后的软件架构可能是什么样的？</li>\n<li>动手搭建一个Prometheus服务，产生一些数据，并配置Grafana，最终可视化地展示这些监控数据。</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"43｜技术演进（上）：虚拟化技术演进之路","id":414159},"right":{"article_title":"45｜基于Kubernetes的云原生架构设计","id":415606}}},{"article_id":415606,"article_title":"45｜基于Kubernetes的云原生架构设计","article_content":"<p>你好，我是孔令飞。</p><p>前面两讲，我们一起看了云技术的演进之路。软件架构已经进入了云原生时代，云原生架构是当下最流行的软件部署架构。那么这一讲，我就和你聊聊什么是云原生，以及如何设计一种基于Kubernetes的云原生部署架构。</p><h2>云原生简介</h2><p>云原生包含的概念很多，对于一个应用开发者来说，主要关注点是如何开发应用，以及如何部署应用。所以，这里我在介绍云原生架构的时候，会主要介绍应用层的云原生架构设计和系统资源层的云原生架构设计。</p><p>在设计云原生架构时，应用生命周期管理层的云原生技术，我们主要侧重在使用层面，所以这里我就不详细介绍应用生命周期管理层的云原生架构了。后面的云原生架构鸟瞰图中会提到它，你可以看看。</p><p>另外，在介绍云原生时，也总是绕不开云原生计算基金会。接下来，我们就先来简单了解下CNCF基金会。</p><h3>CNCF（云原生计算基金会）简介</h3><p><a href=\"https://www.cncf.io/\">CNCF</a>（Cloud Native Computing Foundation，云原生计算基金会），2015年由谷歌牵头成立，目前已有一百多个企业与机构作为成员，包括亚马逊、微软、思科、红帽等巨头。CNCF致力于培育和维护一个厂商中立的开源社区生态，用以推广云原生技术。</p><p>CNCF目前托管了非常多的开源项目，其中有很多我们耳熟能详的项目，例如 Kubernetes、Prometheus、Envoy、Istio、etcd等。更多的项目，你可以参考CNCF公布的<a href=\"https://landscape.cncf.io/images/landscape.png\">Cloud Native Landscape</a>，它给出了云原生生态的参考体系，如下图所示：</p><!-- [[[read_end]]] --><p><img src=\"https://static001.geekbang.org/resource/image/5e/32/5ef7aa9e514ac27b6474165c745dfe32.jpg?wh=2248x1282\" alt=\"\"></p><h3>什么是云原生？</h3><p>CNCF官方在2018年发布了云原生v1.0，并给出了定义：</p><blockquote>\n<p>“云原生技术有利于各组织在公有云、私有云和混合云等新型动态环境中，构建和运行可弹性扩展的应用。云原生的代表技术包括容器、服务网格、微服务、不可变基础设施和声明式API。 这些技术能够构建容错性好、易于管理和便于观察的松耦合系统。结合可靠的自动化手段，云原生技术使工程师能够轻松地对系统作出频繁和可预测的重大变更。”</p>\n</blockquote><p>简单点说，云原生（Cloud Native）是一种构建和运行应用程序的方法，是一套技术体系和方法论。云原生中包含了3个概念，分别是技术体系、方法论和云原生应用。整个云原生技术栈是围绕着Kubernetes来构建的，具体包括了以下核心技术栈：</p><p><img src=\"https://static001.geekbang.org/resource/image/8f/66/8fc9dc16d99e7f2949813fe109986266.jpg?wh=2248x911\" alt=\"\"></p><p>这里来介绍下这些核心技术栈的基本内容。</p><ul>\n<li><strong>容器</strong>：Kubernetes的底层计算引擎，提供容器化的计算资源。</li>\n<li><strong>微服务</strong>：一种软件架构思想，用来构建云原生应用。</li>\n<li><strong>服务网格</strong>：建立在Kubernetes之上，作为服务间通信的底座，提供强大的服务治理功能。</li>\n<li><strong>声明式 API</strong> ：一种新的软件开发模式，通过描述期望的应用状态，来使系统更加健壮。</li>\n<li><strong>不可变基础设施</strong>：一种新的软件部署模式，应用实例一旦被创建，便只能重建不能更新，是现代运维的基础。</li>\n</ul><p>在 <a href=\"https://time.geekbang.org/column/article/414159\">43讲</a> 和 <a href=\"https://time.geekbang.org/column/article/414856\">44讲</a> 中，我介绍了容器、服务网格和微服务，这里再补充介绍下不可变基础设施和声明式API。</p><p><strong>不可变基础设施</strong>（Immutable Infrastructure）的构想，是由Chad Fowler 于 2013 年提出的。具体来说就是：一个应用程序的实例，一旦被创建，就会进入只读的状态，后面如果想变更这个应用程序的实例，只能重新创建一个新的实例。通过这种模式，可以确保应用程序实例的一致性，这使得落地DevOps更加容易，并可以有效减少运维人员管理配置的负担。</p><p><strong>声明式API</strong>是指我们通过工具描述期望的应用状态，并由工具保障应用一直处在我们期望的状态。</p><p>Kubernetes的API设计，就是一种典型的声明式API。例如，我们在创建Deployment时，在Kubernetes YAML文件中声明应用的副本数为<code>2</code>，即设置<code>replicas: 2</code>，Deployment Controller就会确保应用的副本数一直为<code>2</code>。也就是说，如果当前副本数大于<code>2</code>，Deployment Controller会删除多余的副本；如果当前副本数小于<code>2</code>，会创建新的副本。</p><p>声明式设计是一种设计理念，同时也是一种工作模式，它使得你的系统更加健壮。分布式系统环境可能会出现各种不确定的故障，面对这些组件故障，如果使用声明式 API ，你只需要查看对应组件的 API 服务器状态，再确定需要执行的操作即可。</p><h3>什么是云原生应用？</h3><p>上面，我介绍了什么是云原生，接下来再介绍下什么是云原生应用。</p><p>整体来看，云原生应用是指生而为云的应用，应用程序从设计之初就考虑到了云的环境，可以在云上以最佳姿势运行，充分利用和发挥云平台提供的各种能力。具体来看，云原生应用具有以下三大特点：</p><ul>\n<li>从应用生命周期管理维度来看，使用DevOps和CI/CD的方式，进行开发和交付。</li>\n<li>从应用维度来看，以微服务原则进行划分设计。</li>\n<li>从系统资源维度来看，采用Docker + Kubernetes的方式来部署。</li>\n</ul><p>看完上面的介绍，你应该已经对云原生和云原生应用有了一定的理解，接下来我就介绍一种云原生架构实现。因为云原生内容很多，所以这里的介绍只是起到抛砖引玉的作用，让你对云原生架构有初步的理解。至于在具体业务中如何设计云原生架构，你还需要根据业务、团队和技术栈等因素综合考虑。</p><h2>云原生架构包含很多内容，如何学习？</h2><p>云原生架构中包含了很多概念、技术，那么我们到底如何学习呢？在前面的两讲中，我分别从系统资源层、应用层、应用生命周期管理层介绍了云技术。这3个层次基本上构成了整个云计算的技术栈。</p><p>今天，我仍然会从这三个层次入手，来对整个云原生架构设计进行相对完整的介绍。每个层次涉及到的技术很多，这一讲我只介绍每一层的核心技术，通过这些核心技术来看每一层的构建方法。</p><p>另外，因为应用生命周期管理层涉及到的技术栈非常多，所以今天不会详细讲解每种生命周期管理技术的实现原理，但会介绍它们提供的能力。</p><p>除了功能层面的架构设计之外，我们还要考虑部署层面的架构设计。对于云原生架构的部署，通常我们需要关注以下两点：</p><ul>\n<li>容灾能力：容灾能力是指应用程序遇到故障时的恢复能力。在互联网时代，对应用的容灾能力有比较高的要求。理想情况是系统在出现故障时，能够无缝切换到另外一个可用的实例上，继续提供服务，并做到用户无感知。但在实际开发中，无缝切换在技术上比较难以实现，所以也可以退而求其次，允许系统在一定时间内不可用。通常这个时间需要控制在秒级，例如5s。容灾能力可以通过负载均衡、健康检查来实现。</li>\n<li>扩缩容能力：扩缩容能力指的是系统能够根据需要扩缩容，可以手动扩缩容，也可以自动扩缩容。互联网时代对扩缩容能力的要求也比较高，需要实现自动扩缩容。我们可以基于一些自定义指标，例如CPU使用率、内存使用率等来自动扩缩容。扩容也意味着能够承载更多的请求，提高系统的吞吐量；缩容，意味着能够节省成本。扩缩容能力的实现，需要借助于负载均衡和监控告警能力。</li>\n</ul><p>容灾能力和扩缩容能力都属于高可用能力。也就是说，在部署层面，需要我们的架构具备高可用能力。</p><p>接下来，我就重点介绍下系统资源层和应用层的云原生架构设计，并简单介绍下应用生命周期管理层的核心功能构建。在介绍完架构设计之后，我还会介绍下这些层面的高可用架构设计。</p><h2>系统资源层的云原生架构设计</h2><p>先来看系统资源层面的云原生架构设计。对于一个系统来说，系统资源的架构是需要优先考虑的。在云原生架构中，当前的业界标准是通过Docker提供系统资源（例如CPU、内存等），通过Kubernetes来编排Docker容器。Docker和Kubernetes的架构，我在<a href=\"https://time.geekbang.org/column/article/414159\">43讲</a>中介绍过，这里我主要介绍下系统资源层面的高可用架构设计。</p><p>基于Docker+Kubernetes的方案，高可用架构是通过Kubernetes高可用架构来实现的。要实现整个Kubernetes集群的高可用，我们需要分别实现以下两类高可用：</p><ul>\n<li>Kubernetes集群的高可用。</li>\n<li>Kubernetes集群中所部署应用的高可用。</li>\n</ul><p>我们来分别看下这两个高可用方案。</p><h3>Kubernetes集群高可用方案设计</h3><p>通过<a href=\"https://time.geekbang.org/column/article/414159\">43讲</a>的学习，我们知道Kubernetes由kube-apiserver、kube-controller-manager、kube-scheduler、cloud-controller-manager、etcd、kubelet、kube-proxy、container runtime 8大核心组件组成。</p><p>其中，kube-apiserver、kube-controller-manager、kube-scheduler、cloud-controller-manager、etcd通常部署在master节点，kubelet、kube-proxy、container runtime 部署在Node节点上。实现Kubernetes集群的高可用，需要分别实现这8大核心组件的高可用。</p><p>Kubernetes集群的高可用架构图如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/76/3f/7667b9f5a88e61487fce2374400d823f.jpg?wh=2248x1466\" alt=\"\"></p><p>上面图片展示的方案中，所有管理节点都部署了kube-apiserver、kube-controller-manager、kube-scheduler、etcd等组件。kube-apiserver均与本地的etcd进行通信，etcd在三个节点间同步数据；而kube-controller-manager、kube-scheduler和cloud-controller-manager，也只与本地的kube-apiserver进行通信，或者通过负载均衡访问。</p><p>一个Kubernetes集群中有多个<strong>Node节点</strong>，当一个Node节点故障时，Kubernetes的调度组件kube-controller-manager会将Pod调度到其他节点上，并将故障节点的Pod在其他可用节点上重建。也就是说，只要集群中有两个以上的节点，当其中一个Node故障时，整个集群仍然能够正常提供服务。换句话说，集群的<strong>kubelet、kube-proxy、container runtime组件</strong>可以是单点的，不用实现这些组件的高可用。</p><p>接下来，我们来看下<strong>Master节点</strong>各组件是如何实现高可用的。先来说下<strong>kube-apiserver组件的高可用方案设计</strong>。</p><p>因为kube-apiserver是一个无状态的服务，所以可以通过部署多个kube-apiserver实例，其上挂载负载均衡的方式来实现。其他所有需要访问kube-apiserver的组件，都通过负载均衡来访问，以此实现kube-apiserver的高可用。</p><p>kube-controller-manager、cloud-controller-manager和kube-scheduler因为是有状态的服务，所以它们的高可用能力不能通过负载均衡来实现。kube-controller-manager/kube-scheduler/cloud-controller-manager通过–leader-elect=true参数开启分布式锁机制，来进行leader election。</p><p>你可以创建多个kube-controller-manager/kube-scheduler/cloud-controller-manager实例，同一时刻只有一个实例能够获取到锁，成为leader，提供服务。如果当前leader故障，其他实例感知到leader故障之后会自动抢锁，成为leader继续提供服务。通过这种方式，我们实现了kube-controller-manager/kube-scheduler/cloud-controller-manager组件的高可用。</p><p>当kube-apiserver、kube-controller-manager、kube-scheduler、cloud-controller-manager故障时，我们期望这些组件能够自动恢复，这时候可以将这些组件以Static Pod的方式进行部署，这样当Pod故障时，上述实例就能够自动被拉起。</p><p><strong>etcd的高可用方案</strong>有下面这3种思路：</p><ul>\n<li>使用独立的etcd集群，独立的etcd集群自带高可用能力。</li>\n<li>在每个Master节点上，使用Static Pod来部署etcd，多个节点上的etcd实例数据相互同步。每个kube-apiserver只与本Master节点的etcd通信。</li>\n<li>使用CoreOS提出的self-hosted方案，将etcd集群部署在kubernetes集群中，通过kubernetes集群自身的容灾能力来实现etcd的高可用。</li>\n</ul><p>这三种思路，需要你根据实际需要进行选择，在实际生产环境中，第二种思路用得最多。</p><p>到这里，我们就实现了整个Kubernetes集群的高可用。接下来，我们来看下Kubernetes集群中，应用的高可用是如何实现的。</p><h3>Kubernetes应用的高可用</h3><p>Kubernetes自带了应用高可用能力。在Kubernetes中，应用以Pod的形式运行。你可以通过Deployment/StatefulSet来创建应用，并在Deployment/StatefulSet中指定多副本和Pod的健康检查方式。当Pod健康检查失败时，Deployment/StatefulSet的控制器（ReplicaSet）会自动销毁故障Pod，并创建一个新的Pod，替换故障的Pod。</p><p>你可能会问：当Pod故障时，怎么才能避免请求被调度到已故障的Pod上，造成请求失败？这里我也详细介绍下。</p><p>在Kubernetes中，我们可以通过Kubernetes Service或者负载均衡来访问这些Pod。当通过负载均衡来访问Pod时，负载均衡后端的RS（Real Server）实例其实就是Pod。我们创建了多个Pod，负载均衡可以自动根据Pod的健康状况来进行负载。</p><p>接下来，我们主要看下这个问题：当通过Kubernetes Service访问Pod时，如何实现高可用？</p><p>高可用原理如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/65/cd/65dab9a3f07d5afed29aa616db14bdcd.jpg?wh=2248x1266\" alt=\"\"></p><p>在Kubernetes中，我们可以给每个Pod打上标签（Label），标签是一个key-value对，例如<code>label: app=Nginx</code>。当我们访问Service时，Service会根据它配置的Label Selector，匹配具有相同Label的Pod，并将这些Pod的endpoint地址作为其后端RS。</p><p>举个例子，你可以看看上面的图片：Service的Label Selector是Labels<code>app=Nginx</code>，这样就会选择我们创建的具有<code>label: app=Nginx</code>的3个Pod实例。这时候，Service会根据其负载均衡策略，选取一个Pod将请求流量转发过去。当其中一个Pod故障时，Kubernetes会自动将故障Pod的endpoint从Service后端对应的RS列表中剔除。</p><p>由Deployment创建的ReplicaSet，这时候也会发现有一个Pod故障，健康的Pod实例数变为<code>2</code>，这时候跟其期望的值<code>3</code>不匹配，就会自动创建一个新的健康Pod，替换掉故障的Pod。因为新Pod满足Service的Label Selector，所以新Pod的endpoint会被Kubernetes自动添加到Service对应的endpoint列表中。</p><p>通过上面这些操作，Service后端的RS中，故障的Pod IP被新的、健康的Pod IP所替换，通过Service访问的后端Pod就都是健康的。这样，就通过Service实现了应用的高可用。</p><p>从上面的原理分析中，我们也可以发现，Service本质上是一个负载均衡器。</p><p>Kubernetes还提供了滚动更新（RollingUpdate）机制，来确保在发布时服务正常可用。这个机制的大致原理是：在更新时，先创建一个Pod，再销毁一个Pod，依次循环，直到所有的Pod都更新完成。在更新时，我们还可以控制每次更新的Pod数，以及最小可用的Pod数。</p><p>接下来，我们再来看下应用层的云原生架构设计和高可用设计。</p><h2>应用层的云原生架构设计</h2><p>在云原生架构中，我们采用微服务架构来构建应用。所以，这里我主要围绕着微服务架构的构建方式来介绍。先和你谈谈我对微服务的理解。</p><p>从本质上来说，微服务是一个轻量级的Web服务，只不过在微服务场景下，我们通常考虑的不是单个微服务，而是更多地考虑由多个微服务组成的应用。也就是说，一个应用由多个微服务组成，多个微服务就带来了一些单个Web服务不会面临的问题，例如部署复杂、排障困难、服务依赖复杂、通信链路长，等等。</p><p>在微服务场景下，除了编写单个微服务（轻量级的Web服务）之外，我们更多是要专注于解决应用微服务化所带来的挑战。所以，在我看来，微服务架构设计包括两个重要内容：</p><ul>\n<li>单个微服务的构建方式；</li>\n<li>解决应用微服务化带来的挑战。</li>\n</ul><h3>微服务实现</h3><p>我们可以通过两种方式来构建微服务：</p><ul>\n<li>采用Gin、Echo等轻量级Web框架。</li>\n<li>采用微服务框架，例如 <a href=\"https://github.com/go-chassis/go-chassis\">go-chassis</a>、<a href=\"https://github.com/asim/go-micro\">go-micro</a>、<a href=\"https://github.com/go-kit/kit\">go-kit</a>等。</li>\n</ul><p>如果要解决应用微服务化带来的挑战，我们需要采用多种技术和手段，每种技术和手段会解决一个或一部分挑战。</p><p>综上，在我看来，微服务本质上是一个轻量级的Web服务，但又包含一系列的技术和手段，用来解决应用微服务化带来的挑战。微服务的技术栈如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/7a/65/7a860825662bb93f93c51c00efbdeb65.jpg?wh=2248x1158\" alt=\"\"></p><p>不同的技术栈可以由不同的方式来实现，并解决不同的问题：</p><ul>\n<li>监控告警、日志、CI/CD、分布式调度，可以由Kubernetes平台提供的能力来实现。</li>\n<li>服务网关、权限验证、负载均衡、限流/熔断/降级，可以由网关来实现，例如Tyk网关。</li>\n<li>进程间通信、REST/RPC序列化，可以借助Web框架来实现，例如Gin、Go Chassis、gRPC、Sprint Cloud。</li>\n<li>分布式追踪可以由Jaeger来实现。</li>\n<li>统一配置管理可以由Apollo配置中心来实现。</li>\n<li>消息队列可以由NSQ、Kafka、RabbitMQ来实现。</li>\n</ul><p>上面的服务注册/服务发现，有3种实现方式：</p><ul>\n<li>通过Kubernetes Service来进行服务注册/服务发现，Kubernetes自带服务注册/服务发现功能。使用此方式，我们不需要额外的开发。</li>\n<li>通过服务中心来实现服务注册/服务发现功能。采用这种方式，需要我们开发并部署服务中心，服务中心通常可以使用etcd/consul/mgmet来实现，使用etcd的较多。</li>\n<li>通过网关，来进行服务注册/服务发现。这种情况下，可以将服务信息直接上报给网关服务，也可以将服务信息上报到一个服务中心，例如etcd中，再由网关从服务中心中获取。</li>\n</ul><p>这里要注意，原生的Kubernetes集群是不支持监控告警、日志、CI/CD等功能的。我们在使用Kubernetes集群时，通常会使用一个基于Kubernetes开发而来的Kubernetes平台，例如腾讯云容器服务TKE。</p><p>在Kubernetes平台中，通常会基于一些优秀的开源项目，进行二次开发，来实现平台的监控告警、日志、CI/CD等功能。</p><ul>\n<li>监控告警：基于Prometheus来实现。</li>\n<li>日志：基于EFK日志解决方案来实现。</li>\n<li>CI/CD：可以自己研发，也可以基于优秀的开源项目来实现，例如 drone。</li>\n</ul><h3>微服务架构设计</h3><p>上面我介绍了如何实现微服务，这里我再来具体讲讲，上面提到的各个组件/功能是如何有机组合在一起，共同构建一个微服务应用的。下面是微服务的架构图：</p><p><img src=\"https://static001.geekbang.org/resource/image/02/yy/020fa7eccc352d03b78b57a1dbfc75yy.jpg?wh=2248x2168\" alt=\"\"></p><p>在上图中，我们将微服务应用层部署在Kubernetes集群中，在Kubernetes集群之上，可以构建微服务需要的其他功能，例如监控告警、CI/CD、日志、调用链等。这些功能共同完成应用的生命周期管理。</p><p>我们在微服务的最上面挂载负载均衡。客户端，例如移动端应用、Web应用、API调用等，都通过负载均衡来访问微服务。</p><p>微服务在启动时会将自己的endpoint信息（通常是<code>ip:port</code>格式）上报到服务中心。微服务也会定时上报自己的心跳到服务中心。在服务中心中，我们可以监控微服务的状态，剔除不健康的微服务，获取微服务之间的访问数据，等等。如果要通过网关调用微服务，或者需要使用网关做负载均衡，那我们还需要网关从服务中心中获取微服务的endpoint信息。</p><h3>微服务高可用架构设计</h3><p>我们再来看下如何设计微服务应用的高可用能力。</p><p>我们可以把所有微服务组件以Deployment/StatefulSet的形式部署在Kubernetes集群中，副本数至少设置为两个，更新方式为滚动更新，设置服务的监控检查，并通过Kubernetes Service或者负载均衡的方式访问服务。这样，我们就可以不用做任何改造，直接使用Kubernetes自有的容灾能力，实现微服务架构的高可用。</p><h2>云原生架构鸟瞰图</h2><p>上面，我介绍了系统资源层和应用层的云原生架构设计，但还不能构成整个云原生架构设计。这里，我通过一张云原生架构鸟瞰图，来整体介绍下云原生架构的设计方案。</p><p><img src=\"https://static001.geekbang.org/resource/image/05/b5/05c7cb8fd6c524242229ab9ea6c9b1b5.jpg?wh=2248x1470\" alt=\"\"></p><p>上图的云原生架构分为4层，除了前面提到的系统资源层、应用层、应用生命周期管理层之外，又加了统一接入层。接下来，我来介绍下这些层在云原生架构中的作用。</p><p>在最下面的<strong>系统资源层</strong>，我们除了提供传统的计算资源（物理机、虚拟机）之外，还可以提供容器化的计算资源和高可用的存储服务。其中，容器化的计算资源是基于传统的物理机/虚拟机来构建的。</p><p>在云原生架构中，我们更应该使用容器化的计算资源，通过Docker容器技术来隔离并对外提供计算资源，通过Kubernetes来编排容器。Docker + Kubernetes的组合使用，可以构建出一个非常优秀的系统资源层。这个系统资源层，自带了资源管理、容器调度、自动伸缩、网络通信、服务发现、健康检查等企业应用需要的核心能力。</p><p>在云原生时代，这些系统资源除了具有容器化、轻量化的特点之外，还越来越倾向于朝着Serverless化的方向去构建：系统资源免申请、免运维，按需计费，具备极致的弹性伸缩能力，并能够缩容到0。Serverless化的系统资源，可以使开发者只聚焦在应用层的应用功能开发上，而不用再把时间浪费在系统层的运维工作上。</p><p>在系统资源层之上，就可以构建我们的<strong>应用层</strong>了。云原生架构中，应用的构建方式，基本上都是采用的微服务架构。开发一个微服务应用，我们可以使用微服务框架，也可以不使用。二者的区别是，微服务框架替我们完成了服务治理相关功能，让我们不需要再开发这些功能。</p><p>在我看来，这一点有利有弊。好处当然是节省了开发工作量。至于坏处，主要有两方面：一方面，在实现方式和实现思路上，微服务框架所集成的服务治理功能并不一定是最适合我们的方案。另一方面，使用微服务框架还意味着我们的应用会跟微服务框架耦合，不能自由选择服务治理技术和方式。所以，在实际开发中，你应该根据需要，自行选择微服务的构建方式。</p><p>一般来说，一个微服务框架中，至少集成了这些服务治理功能：配置中心、调用链追踪、日志系统、监控、服务注册/服务发现。</p><p>再往上，我们就实现了<strong>统一接入层</strong>。统一接入层中包含了负载均衡和网关两个组件，其中负载均衡作为服务的唯一入口，供API、Web浏览器、手机终端等客户端访问。通过负载均衡，可以使我们的应用在故障时，能够自动切换实例，在负载过高时能够水平扩容。负载均衡下面还对接了网关，网关提供了一些通用能力，例如安全策略、路由策略、流量策略、统计分析、API管理等能力。</p><p>最后，我们还可以构建一系列的应用生命周期管理技术，例如服务编排、配置管理、日志、存储、审计、监控告警、消息队列、分布式链路追踪。这些技术中，一些可以基于Kubernetes，集成在我们的Kubernetes平台中，另一些则可以单独构建，供所有产品接入。</p><h2>公有云版云原生架构</h2><p>上面我们提到，云原生架构涉及到很多的技术栈。如果公司有能力，可以选择自己开发；如果觉得人力不够、成本太高，也可以使用公有云厂商已经开发好的云原生基础设施。使用云厂商的云原生基础设施，好处很明显：这些基础设施专业、稳定、免开发、免运维。</p><p>为了补全云原生架构设计版图，这里我也介绍一个公用云版的云原生架构设计。那么，公有云厂商会提供哪些云原生基础设施呢？这里我介绍下腾讯云提供的云原生解决方案。解决方案全景如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/44/20/4473c11e51fa0976d91202fc7c836020.jpg?wh=2249x1068\" alt=\"\"></p><p>可以看到，<strong>腾讯云提供了全栈的云原生能力。</strong></p><p>腾讯云基于底层的云原生能力，提供了一系列的云原生解决方案。这些解决方案，是已经设计好的云原生架构构建方案，可以帮助企业快速落地云原生架构，例如混合云解决方案、AI解决方案、IoT解决方案等。</p><p>那么，腾讯云底层提供了哪些云原生能力呢？我们一起来看下。</p><p>在应用层，通过TSF微服务平台，我们可以实现微服务的构建，以及微服务的服务治理能力。另外，还提供了更多的应用构建架构，例如：</p><ul>\n<li>Serverless Framework，可以构建Serverless应用。</li>\n<li>CloudBase，云原生一体化应用开发平台，可以快速构建小程序、Web、移动应用。</li>\n<li>…</li>\n</ul><p>在系统资源层，腾讯云提供了多种计算资源提供形态。例如：通过TKE，可以创建原生的Kubernetes集群；通过EKS，可以创建Serverless化的Kubernetes集群；通过<a href=\"https://github.com/superedge/superedge\">TKE-Edge</a>，可以创建能够纳管边缘节点的Kubernetes集群。此外，还提供了开源容器服务平台<a href=\"https://github.com/tkestack/tke\">TKEStack</a>，TKEStack是一个非常优秀的容器云平台，在代码质量、稳定性、平台功能等方面，都在开源的容器云平台中处于龙头地位，也欢迎你Star。</p><p>在应用生命周期管理这一层，提供了云原生的etcd、Prometheus服务。此外，还提供了CLS日志系统，供你保存并查询应用日志；提供了云监控，供你监控自己的应用程序；提供了容器镜像服务（TCR），用来保存Docker镜像；提供了CODING DevOps平台，用来支持应用的CI/CD；提供了调用链跟踪服务（TDW），用来展示微服务的调用链。</p><p>在统一接入层，腾讯云提供了功能强大的API网关。此外，还提供了多种Serverless化的中间件服务，例如消息队列TDMQ、云原生数据库TDSQL等。</p><p>所有这些云原生基础设施，都有共同的特点，就是免部署、免运维。换句话说，在腾讯云，你可以只专注于使用编程语言编写你的业务逻辑，其他的一切都交给腾讯云来搞定。</p><h2>总结</h2><p>云原生架构设计，包含了系统资源层、应用层、统一接入层和应用生命周期管理层4层。</p><p>在系统资源层，可以采用Docker + Kubernetes的方式来提供计算资源。我们所有的应用和应用生命周期管理相关的服务，都可以部署在Kubernetes集群中，利用Kubernetes集群的能力实现服务发现/服务注册、弹性伸缩、资源调度等核心能力。</p><p>在应用层，可以采用微服务架构，来构建我们的应用。具体构建时，我们可以根据需要，采用类似Gin这种轻量级的Web框架来构建应用，然后再实现旁路的服务治理功能；也可以采用集成了很多服务治理功能的微服务框架，例如 go-chassis、go-micro等。</p><p>因为我们采用了微服务架构，为了能够将微服务的一些功能，例如：认证授权、限流等功能最大化的复用，我们又提供了统一接入层。可以通过API网关、负载均衡、服务网格等技术来构建统一接入层。</p><p>在应用生命周期管理这一层，我们可以实现一些云原生的管理平台，例如 DevOps、监控告警、日志、配置中心等，并使我们的应用以云原生化的方式接入这些平台，使用这些平台提供的能力。</p><p>最后，我还介绍了腾讯云的云原生基础设施。通过腾讯云提供的云原生能力，你可以专注于使用编程语言编写你的业务逻辑，其他的各种云原生能力，都可以交给云厂商来帮你实现。</p><h2>课后练习</h2><ol>\n<li>思考下，服务注册/服务发现的3种实现方式中，哪种方法适用于你的项目，为什么？</li>\n<li>思考下，在设计云原生架构时，还需要考虑哪些重要的点？欢迎你在留言区分享。</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"44｜技术演进（下）：软件架构和应用生命周期技术演进之路","id":414856},"right":{"article_title":"46 | 如何制作Docker镜像？","id":417216}}},{"article_id":417216,"article_title":"46 | 如何制作Docker镜像？","article_content":"<p>你好，我是孔令飞。</p><p>要落地云原生架构，其中的一个核心点是通过容器来部署我们的应用。如果要使用容器来部署应用，那么制作应用的Docker镜像就是我们绕不开的关键一步。今天，我就来详细介绍下如何制作Docker镜像。</p><p>在这一讲中，我会先讲解下Docker镜像的构建原理和方式，然后介绍Dockerfile的指令，以及如何编写Dockerfile文件。最后，介绍下编写Dockerfile文件时要遵循的一些最佳实践。</p><h2>Docker镜像的构建原理和方式</h2><p>首先，我们来看下Docker镜像构建的原理和方式。</p><p>我们可以用多种方式来构建一个Docker镜像，最常用的有两种：</p><ul>\n<li>通过<code>docker commit</code>命令，基于一个已存在的容器构建出镜像。</li>\n<li>编写Dockerfile文件，并使用<code>docker build</code>命令来构建镜像。</li>\n</ul><p>上面这两种方法中，镜像构建的底层原理是相同的，都是通过下面3个步骤来构建镜像：</p><ol>\n<li>基于原镜像，启动一个Docker容器。</li>\n<li>在容器中进行一些操作，例如执行命令、安装文件等。由这些操作产生的文件变更都会被记录在容器的存储层中。</li>\n<li>将容器存储层的变更commit到新的镜像层中，并添加到原镜像上。</li>\n</ol><p>下面，我们来具体讲解这两种构建Docker镜像的方式。</p><!-- [[[read_end]]] --><h3>通过<code>docker commit</code>命令构建镜像</h3><p>我们可以通过<code>docker commit</code>来构建一个镜像，命令的格式为<code>docker commit [选项] [&lt;仓库名&gt;[:&lt;标签&gt;]]</code>。</p><p>下图中，我们通过4个步骤构建了Docker镜像<code>ccr.ccs.tencentyun.com/marmotedu/iam-apiserver-amd64:test</code>：</p><p><img src=\"https://static001.geekbang.org/resource/image/23/11/23619b513ff043792c7374acf7781d11.png?wh=1920x344\" alt=\"图片\"></p><p>具体步骤如下：</p><ol>\n<li>执行<code>docker ps</code>获取需要构建镜像的容器ID <code>48d1dbb89a7f</code>。</li>\n<li>执行<code>docker pause 48d1dbb89a7f</code>暂停<code>48d1dbb89a7f</code>容器的运行。</li>\n<li>执行<code>docker commit 48d1dbb89a7f ccr.ccs.tencentyun.com/marmotedu/iam-apiserver-amd64:test</code>，基于容器ID <code>48d1dbb89a7f</code>构建Docker镜像。</li>\n<li>执行<code>docker images ccr.ccs.tencentyun.com/marmotedu/iam-apiserver-amd64:test</code>，查看镜像是否成功构建。</li>\n</ol><p>这种镜像构建方式通常用在下面两个场景中：</p><ul>\n<li>构建临时的测试镜像；</li>\n<li>容器被入侵后，使用<code>docker commit</code>，基于被入侵的容器构建镜像，从而保留现场，方便以后追溯。</li>\n</ul><p>除了这两种场景，我不建议你使用<code>docker commit</code>来构建生产现网环境的镜像。我这么说的主要原因有两个：</p><ul>\n<li>使用<code>docker commit</code>构建的镜像包含了编译构建、安装软件，以及程序运行产生的大量无用文件，这会导致镜像体积很大，非常臃肿。</li>\n<li>使用<code>docker commit</code>构建的镜像会丢失掉所有对该镜像的操作历史，无法还原镜像的构建过程，不利于镜像的维护。</li>\n</ul><p>下面，我们再来看看如何使用<code>Dockerfile</code>来构建镜像。</p><h3>通过<code>Dockerfile</code>来构建镜像</h3><p>在实际开发中，使用<code>Dockerfile</code>来构建是最常用，也最标准的镜像构建方法。<code>Dockerfile</code>是Docker用来构建镜像的文本文件，里面包含了一系列用来构建镜像的指令。</p><p><code>docker build</code>命令会读取<code>Dockerfile</code>的内容，并将<code>Dockerfile</code>的内容发送给Docker引擎，最终Docker引擎会解析<code>Dockerfile</code>中的每一条指令，构建出需要的镜像。</p><p><code>docker build</code>的命令格式为<code>docker build [OPTIONS] PATH | URL | -</code>。<code>PATH</code>、<code>URL</code>、<code>-</code>指出了构建镜像的上下文（context），context中包含了构建镜像需要的<code>Dockerfile</code>文件和其他文件。默认情况下，Docker构建引擎会查找context中名为<code>Dockerfile</code>的文件，但你可以通过<code>-f, --file</code>选项，手动指定<code>Dockerfile</code>文件。例如：</p><pre><code class=\"language-bash\"> $ docker build -f Dockerfile -t ccr.ccs.tencentyun.com/marmotedu/iam-apiserver-amd64:test .\n</code></pre><p>使用Dockerfile构建镜像，本质上也是通过镜像创建容器，并在容器中执行相应的指令，然后停止容器，提交存储层的文件变更。和用<code>docker commit</code>构建镜像的方式相比，它有三个好处：</p><ul>\n<li>Dockerfile 包含了镜像制作的完整操作流程，其他开发者可以通过 Dockerfile 了解并复现制作过程。</li>\n<li>Dockerfile 中的每一条指令都会创建新的镜像层，这些镜像可以被 Docker Daemnon 缓存。再次制作镜像时，Docker 会尽量复用缓存的镜像层（using cache），而不是重新逐层构建，这样可以节省时间和磁盘空间。</li>\n<li>Dockerfile 的操作流程可以通过<code>docker image history [镜像名称]</code>查询，方便开发者查看变更记录。</li>\n</ul><p>这里，我们通过一个示例，来详细介绍下通过<code>Dockerfile</code>构建镜像的流程。</p><p><strong>首先，</strong>我们需要编写一个<code>Dockerfile</code>文件。下面是iam-apiserver的<a href=\"https://github.com/marmotedu/iam/blob/v1.0.8/build/docker/iam-apiserver/Dockerfile\">Dockerfile</a>文件内容：</p><pre><code class=\"language-dockerfile\">FROM centos:centos8\nLABEL maintainer=\"&lt;colin404@foxmail.com&gt;\"\n\nRUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime\nRUN echo \"Asia/Shanghai\" &gt; /etc/timezone\n\nWORKDIR /opt/iam\nCOPY iam-apiserver /opt/iam/bin/\n\nENTRYPOINT [\"/opt/iam/bin/iam-apiserver\"]\n</code></pre><p>这里选择<code>centos:centos8</code>作为基础镜像，是因为<code>centos:centos8</code>镜像中包含了基本的排障工具，例如<code>vi</code>、<code>cat</code>、<code>curl</code>、<code>mkdir</code>、<code>cp</code>等工具。</p><p><strong>接着，</strong>执行<code>docker build</code>命令来构建镜像：</p><pre><code class=\"language-bash\">$ docker build -f Dockerfile -t ccr.ccs.tencentyun.com/marmotedu/iam-apiserver-amd64:test .\n</code></pre><p>执行<code>docker build</code>后的构建流程为：</p><p><strong>第一步</strong>，<code>docker build</code>会将context中的文件打包传给Docker daemon。如果context中有<code>.dockerignore</code>文件，则会从上传列表中删除满足<code>.dockerignore</code>规则的文件。</p><p>这里有个例外，如果<code>.dockerignore</code>文件中有<code>.dockerignore</code>或者<code>Dockerfile</code>，<code>docker build</code>命令在排除文件时会忽略掉这两个文件。如果指定了镜像的tag，还会对repository和tag进行验证。</p><p><strong>第二步</strong>，<code>docker build</code>命令向Docker server发送HTTP请求，请求Docker server构建镜像，请求中包含了需要的context信息。</p><p><strong>第三步</strong>，Docker server接收到构建请求之后，会执行以下流程来构建镜像：</p><ol>\n<li>创建一个临时目录，并将context中的文件解压到该目录下。</li>\n<li>读取并解析Dockerfile，遍历其中的指令，根据命令类型分发到不同的模块去执行。</li>\n<li>Docker构建引擎为每一条指令创建一个临时容器，在临时容器中执行指令，然后commit容器，生成一个新的镜像层。</li>\n<li>最后，将所有指令构建出的镜像层合并，形成build的最后结果。最后一次commit生成的镜像ID就是最终的镜像ID。</li>\n</ol><p>为了提高构建效率，<code>docker build</code>默认会缓存已有的镜像层。如果构建镜像时发现某个镜像层已经被缓存，就会直接使用该缓存镜像，而不用重新构建。如果不希望使用缓存的镜像，可以在执行<code>docker build</code>命令时，指定<code>--no-cache=true</code>参数。</p><p>Docker匹配缓存镜像的规则为：遍历缓存中的基础镜像及其子镜像，检查这些镜像的构建指令是否和当前指令完全一致，如果不一样，则说明缓存不匹配。对于<code>ADD</code>、<code>COPY</code>指令，还会根据文件的校验和（checksum）来判断添加到镜像中的文件是否相同，如果不相同，则说明缓存不匹配。</p><p>这里要注意，缓存匹配检查不会检查容器中的文件。比如，当使用<code>RUN apt-get -y update</code>命令更新了容器中的文件时，缓存策略并不会检查这些文件，来判断缓存是否匹配。</p><p>最后，我们可以通过<code>docker history</code>命令来查看镜像的构建历史，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/f3/06/f32a0e2f90a36995a561747519897806.png?wh=1854x345\" alt=\"图片\"></p><h3>其他制作镜像方式</h3><p>上面介绍的是两种最常用的镜像构建方式，还有一些其他的镜像创建方式，这里我简单介绍两种。</p><ol>\n<li>通过<code>docker save</code>和<code>docker load</code>命令构建</li>\n</ol><p><code>docker save</code>用来将镜像保存为一个tar文件，<code>docker load</code>用来将tar格式的镜像文件加载到当前机器上，例如：</p><pre><code class=\"language-bash\"># 在 A 机器上执行，并将 nginx-v1.0.0.tar.gz 复制到 B 机器\n$ docker save nginx | gzip &gt; nginx-v1.0.0.tar.gz\n\n# 在 B 机器上执行\n$ docker load -i nginx-v1.0.0.tar.gz\n</code></pre><p>通过上面的命令，我们就在机器B上创建了<code>nginx</code>镜像。</p><ol start=\"2\">\n<li>通过<code>docker export</code>和<code>docker import</code>命令构建</li>\n</ol><p>我们先通过<code>docker export</code> 保存镜像，再通过<code>docker import</code> 加载镜像，具体命令如下：</p><pre><code class=\"language-bash\"># 在 A 机器上执行，并将 nginx-v1.0.0.tar.gz 复制到 B 机器\n$ docker export nginx &gt; nginx-v1.0.0.tar.gz\n\n# 在 B 机器上执行\n$ docker import - nginx:v1.0.0 nginx-v1.0.0.tar.gz\n</code></pre><p>通过<code>docker export</code>导出的镜像和通过<code>docker save</code>保存的镜像相比，会丢失掉所有的镜像构建历史。在实际生产环境中，我不建议你通过<code>docker save</code>和<code>docker export</code>这两种方式来创建镜像。我比较推荐的方式是：在A机器上将镜像push到镜像仓库，在B机器上从镜像仓库pull该镜像。</p><h2>Dockerfile指令介绍</h2><p>上面，我介绍了一些与Docker镜像构建有关的基础知识。在实际生产环境中，我们标准的做法是通过Dockerfile来构建镜像，这就要求你会编写Dockerfile文件。接下来，我就详细介绍下如何编写Dockerfile文件。</p><p>Dockerfile指令的基本格式如下：</p><pre><code class=\"language-dockerfile\"># Comment\nINSTRUCTION arguments\n</code></pre><p><code>INSTRUCTION</code>是指令，不区分大小写，但我的建议是指令都大写，这样可以与参数进行区分。Dockerfile中，以 <code>#</code> 开头的行是注释，而在其他位置出现的 <code>#</code> 会被当成参数，例如：</p><pre><code class=\"language-dockerfile\"># Comment\nRUN echo 'hello world # dockerfile'\n</code></pre><p>一个Dockerfile文件中包含了多条指令，这些指令可以分为5类。</p><ul>\n<li>定义基础镜像的指令：<strong>FROM</strong>；</li>\n<li>定义镜像维护者的指令：<strong>MAINTAINER</strong>（可选）；</li>\n<li>定义镜像构建过程的指令：<strong>COPY</strong>、ADD、<strong>RUN</strong>、USER、<strong>WORKDIR</strong>、ARG、<strong>ENV</strong>、VOLUME、<strong>ONBUILD</strong>；</li>\n<li>定义容器启动时执行命令的指令：<strong>CMD</strong>、<strong>ENTRYPOINT</strong>；</li>\n<li>其他指令：EXPOSE、HEALTHCHECK、STOPSIGNAL。</li>\n</ul><p>其中，加粗的指令是编写Dockerfile时经常用到的指令，需要你重点了解下。我把这些常用Dockerfile指令的介绍放在了GitHub上，你可以看看这个<a href=\"https://github.com/marmotedu/geekbang-go/blob/master/Dockerfile%E6%8C%87%E4%BB%A4%E8%AF%A6%E8%A7%A3.md\">Dockerfile指令详解</a>。</p><p>下面是一个Dockerfile示例：</p><pre><code class=\"language-dockerfile\"># 第一行必须指定构建该镜像所基于的容器镜像\nFROM centos:centos8\n\n# 维护者信息\nMAINTAINER Lingfei Kong &lt;colin404@foxmail.com&gt;\n\n# 镜像的操作指令\nRUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime\nRUN echo \"Asia/Shanghai\" &gt; /etc/timezone\nWORKDIR /opt/iam\nCOPY iam-apiserver /opt/iam/bin/\n\n# 容器启动时执行指令\nENTRYPOINT [\"/opt/iam/bin/iam-apiserver\"]\n</code></pre><p>Docker会顺序解释并执行Dockerfile中的指令，并且第一条指令必须是<code>FROM</code>，<code>FROM</code> 用来指定构建镜像的基础镜像。接下来，一般会指定镜像维护者的信息。后面是镜像操作的指令，最后会通过<code>CMD</code>或者<code>ENTRYPOINT</code>来指定容器启动的命令和参数。</p><h2>Dockerfile最佳实践</h2><p>上面我介绍了Dockerfile的指令，但在编写Dockerfile时，只知道这些指令是不够的，还不能编写一个合格的Dockerfile。我们还需要遵循一些编写 Dockerfile的最佳实践。这里，我总结了一份编写 Dockerfile的最佳实践清单，你可以参考。</p><ol>\n<li>\n<p>建议所有的Dockerfile指令大写，这样做可以很好地跟在镜像内执行的指令区分开来。</p>\n</li>\n<li>\n<p>在选择基础镜像时，尽量选择官方的镜像，并在满足要求的情况下，尽量选择体积小的镜像。目前，Linux镜像大小有以下关系：<code>busybox &lt; debian &lt; centos &lt; ubuntu</code>。最好确保同一个项目中使用一个统一的基础镜像。如无特殊需求，可以选择使用<code>debian:jessie</code>或者<code>alpine</code>。</p>\n</li>\n<li>\n<p>在构建镜像时，删除不需要的文件，只安装需要的文件，保持镜像干净、轻量。</p>\n</li>\n<li>\n<p>使用更少的层，把相关的内容放到一个层，并使用换行符进行分割。这样可以进一步减小镜像的体积，也方便查看镜像历史。</p>\n</li>\n<li>\n<p>不要在Dockerfile中修改文件的权限。因为如果修改文件的权限，Docker在构建时会重新复制一份，这会导致镜像体积越来越大。</p>\n</li>\n<li>\n<p>给镜像打上标签，标签可以帮助你理解镜像的功能，例如：<code>docker build -t=\"nginx:3.0-onbuild\"</code>。</p>\n</li>\n<li>\n<p><code>FROM</code>指令应该包含tag，例如使用<code>FROM debian:jessie</code>，而不是<code>FROM debian</code>。</p>\n</li>\n<li>\n<p>充分利用缓存。Docker构建引擎会顺序执行Dockerfile中的指令，而且一旦缓存失效，后续命令将不能使用缓存。为了有效地利用缓存，需要尽量将所有的Dockerfile文件中相同的部分都放在前面，而将不同的部分放在后面。</p>\n</li>\n<li>\n<p>优先使用<code>COPY</code>而非<code>ADD</code>指令。和<code>ADD</code>相比，<code>COPY</code> 功能简单，而且也够用。<code>ADD</code>可变的行为会导致该指令的行为不清晰，不利于后期维护和理解。</p>\n</li>\n<li>\n<p>推荐将<code>CMD</code>和<code>ENTRYPOINT</code>指令结合使用，使用execl格式的<code>ENTRYPOINT</code>指令设置固定的默认命令和参数，然后使用<code>CMD</code>指令设置可变的参数。</p>\n</li>\n<li>\n<p>尽量使用Dockerfile共享镜像。通过共享Dockerfile，可以使开发者明确知道Docker镜像的构建过程，并且可以将Dockerfile文件加入版本控制，跟踪起来。</p>\n</li>\n<li>\n<p>使用<code>.dockerignore</code>忽略构建镜像时非必需的文件。忽略无用的文件，可以提高构建速度。</p>\n</li>\n<li>\n<p>使用多阶段构建。多阶段构建可以大幅减小最终镜像的体积。例如，<code>COPY</code>指令中可能包含一些安装包，安装完成之后这些内容就废弃掉。下面是一个简单的多阶段构建示例：</p>\n</li>\n</ol><pre><code class=\"language-dockerfile\">FROM golang:1.11-alpine AS build\n\n# 安装依赖包\nRUN go get github.com/golang/mock/mockgen\n\n# 复制源码并执行build，此处当文件有变化会产生新的一层镜像层\nCOPY . /go/src/iam/\nRUN go build -o /bin/iam\n\n# 缩小到一层镜像\nFROM busybox\nCOPY --from=build /bin/iam /bin/iam\nENTRYPOINT [\"/bin/iam\"]\nCMD [\"--help\"]\n</code></pre><h2>总结</h2><p>如果你想使用Docker容器来部署应用，那么就需要制作Docker镜像。今天，我介绍了如何制作Docker镜像。</p><p>你可以使用这两种方式来构建Docker镜像：</p><ul>\n<li>通过 <code>docker commit</code> 命令，基于一个已存在的容器构建出镜像。</li>\n<li>通过编写Dockerfile文件，并使用 <code>docker build</code> 命令来构建镜像。</li>\n</ul><p>这两种方法中，镜像构建的底层原理是相同的：</p><ol>\n<li>\n<p>基于原镜像启动一个Docker容器。</p>\n</li>\n<li>\n<p>在容器中进行一些操作，例如执行命令、安装文件等，由这些操作产生的文件变更都会被记录在容器的存储层中。</p>\n</li>\n<li>\n<p>将容器存储层的变更commit到新的镜像层中，并添加到原镜像上。</p>\n</li>\n</ol><p>此外，我们还可以使用 <code>docker save</code> / <code>docker load</code> 和 <code>docker export</code> / <code>docker import</code> 来复制Docker镜像。</p><p>在实际生产环境中，我们标准的做法是通过Dockerfile来构建镜像。使用Dockerfile构建镜像，就需要你编写Dockerfile文件。Dockerfile支持多个指令，这些指令可以分为5类，对指令的具体介绍你可以再返回复习一遍。</p><p>另外，我们在构建Docker镜像时，也要遵循一些最佳实践，具体你可以参考我给你总结的最佳实践清单。</p><h2>课后练习</h2><ol>\n<li>\n<p>思考下，为什么在编写Dockerfile时，“把相关的内容放到一个层，使用换行符 <code>\\</code> 进行分割”可以减小镜像的体积？</p>\n</li>\n<li>\n<p>尝试一下，为你正在开发的应用编写Dockerfile文件，并成功构建出Docker镜像。</p>\n</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"45｜基于Kubernetes的云原生架构设计","id":415606},"right":{"article_title":"47 | 如何编写Kubernetes资源定义文件？","id":418009}}},{"article_id":418009,"article_title":"47 | 如何编写Kubernetes资源定义文件？","article_content":"<p>你好，我是孔令飞。</p><p>在接下来的48讲，我会介绍如何基于腾讯云EKS来部署IAM应用。EKS其实是一个标准的Kubernetes集群，在Kubernetes集群中部署应用，需要编写Kubernetes资源的YAML（Yet Another Markup Language）定义文件，例如Service、Deployment、ConfigMap、Secret、StatefulSet等。</p><p>这些YAML定义文件里面有很多配置项需要我们去配置，其中一些也比较难理解。为了你在学习下一讲时更轻松，这一讲我们先学习下如何编写Kubernetes YAML文件。</p><h2>为什么选择YAML格式来定义Kubernetes资源？</h2><p>首先解释一下，我们为什么使用YAML格式来定义Kubernetes的各类资源呢？这是因为YAML格式和其他格式（例如XML、JSON等）相比，不仅能够支持丰富的数据，而且结构清晰、层次分明、表达性极强、易于维护，非常适合拿来供开发者配置和管理Kubernetes资源。</p><p>其实Kubernetes支持YAML和JSON两种格式，JSON格式通常用来作为接口之间消息传递的数据格式，YAML格式则用于资源的配置和管理。YAML和JSON这两种格式是可以相互转换的，你可以通过在线工具<a href=\"https://www.json2yaml.com/convert-yaml-to-json\">json2yaml</a>，来自动转换YAML和JSON数据格式。</p><!-- [[[read_end]]] --><p>例如，下面是一个YAML文件中的内容：</p><pre><code class=\"language-yaml\">apiVersion: v1\nkind: Service\nmetadata:\n  name: iam-apiserver\nspec:\n  clusterIP: 192.168.0.231\n  externalTrafficPolicy: Cluster\n  ports:\n  - name: https\n    nodePort: 30443\n    port: 8443\n    protocol: TCP\n    targetPort: 8443\n  selector:\n    app: iam-apiserver\n  sessionAffinity: None\n  type: NodePort\n</code></pre><p>它对应的JSON格式的文件内容为：</p><pre><code class=\"language-json\">{\n  \"apiVersion\": \"v1\",\n  \"kind\": \"Service\",\n  \"metadata\": {\n    \"name\": \"iam-apiserver\"\n  },\n  \"spec\": {\n    \"clusterIP\": \"192.168.0.231\",\n    \"externalTrafficPolicy\": \"Cluster\",\n    \"ports\": [\n      {\n        \"name\": \"https\",\n        \"nodePort\": 30443,\n        \"port\": 8443,\n        \"protocol\": \"TCP\",\n        \"targetPort\": 8443\n      }\n    ],\n    \"selector\": {\n      \"app\": \"iam-apiserver\"\n    },\n    \"sessionAffinity\": \"None\",\n    \"type\": \"NodePort\"\n  }\n}\n</code></pre><p>我就是通过<code>json2yaml</code>在线工具，来转换YAML和JSON的，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/0f/02/0ffac271b296d1cc407941cfc3139702.png?wh=1920x780\" alt=\"图片\"></p><p>在编写Kubernetes资源定义文件的过程中，如果因为YAML格式文件中的配置项缩进太深，导致不容易判断配置项的层级，那么，你就可以将其转换成JSON格式，通过JSON格式来判断配置型的层级。</p><p>如果想学习更多关于YAML的知识，你可以参考<a href=\"https://yaml.org/spec/1.2/spec.html\">YAML 1.2 (3rd Edition)</a>。这里，可以先看看我整理的YAML基本语法：</p><ul>\n<li>属性和值都是大小写敏感的。</li>\n<li>使用缩进表示层级关系。</li>\n<li>禁止使用Tab键缩进，只允许使用空格，建议两个空格作为一个层级的缩进。元素左对齐，就说明对齐的两个元素属于同一个级别。</li>\n<li>使用 <code>#</code> 进行注释，直到行尾。</li>\n<li><code>key: value</code>格式的定义中，冒号后要有一个空格。</li>\n<li>短横线表示列表项，使用一个短横线加一个空格；多个项使用同样的缩进级别作为同一列表。</li>\n<li>使用 <code>---</code> 表示一个新的YAML文件开始。</li>\n</ul><p>现在你知道了，Kubernetes支持YAML和JSON两种格式，它们是可以相互转换的。但鉴于YAML格式的各项优点，我建议你使用YAML格式来定义Kubernetes的各类资源。</p><h2>Kubernetes 资源定义概述</h2><p>Kubernetes中有很多内置的资源，常用的资源有Deployment、StatefulSet、ConfigMap、Service、Secret、Nodes、Pods、Events、Jobs、DaemonSets等。除此之外，Kubernetes还有其他一些资源。如果你觉得Kubernetes内置的资源满足不了需求，还可以自定义资源。</p><p>Kubernetes的资源清单可以通过执行以下命令来查看：</p><pre><code class=\"language-bash\">$ kubectl api-resources\nNAME                              SHORTNAMES   APIVERSION                        NAMESPACED   KIND\nbindings                                       v1                                true         Binding\ncomponentstatuses                 cs           v1                                false        ComponentStatus\nconfigmaps                        cm           v1                                true         ConfigMap\nendpoints                         ep           v1                                true         Endpoints\nevents                            ev           v1                                true         Event\n</code></pre><p>上述输出中，各列的含义如下。</p><ul>\n<li>NAME：资源名称。</li>\n<li>SHORTNAMES：资源名称简写。</li>\n<li>APIVERSION：资源的API版本，也称为group。</li>\n<li>NAMESPACED：资源是否具有Namespace属性。</li>\n<li>KIND：资源类别。</li>\n</ul><p>这些资源有一些共同的配置，也有一些特有的配置。这里，我们先来看下这些资源共同的配置。</p><p>下面这些配置是Kubernetes各类资源都具备的：</p><pre><code class=\"language-yaml\">---\napiVersion: &lt;string&gt; # string类型，指定group的名称，默认为core。可以使用 `kubectl api-versions` 命令，来获取当前kubernetes版本支持的所有group。\nkind: &lt;string&gt; # string类型，资源类别。\nmetadata: &lt;Object&gt; # 资源的元数据。\n  name: &lt;string&gt; # string类型，资源名称。\n  namespace: &lt;string&gt; # string类型，资源所属的命名空间。\n  lables: &lt; map[string]string&gt; # map类型，资源的标签。\n  annotations: &lt; map[string]string&gt; # map类型，资源的标注。\n  selfLink: &lt;string&gt; # 资源的 REST API路径，格式为：/api/&lt;group&gt;/namespaces/&lt;namespace&gt;/&lt;type&gt;/&lt;name&gt;。例如：/api/v1/namespaces/default/services/iam-apiserver\nspec: &lt;Object&gt; # 定义用户期望的资源状态（disired state）。\nstatus: &lt;Object&gt; # 资源当前的状态，以只读的方式显示资源的最近状态。这个字段由kubernetes维护，用户无法定义。\n</code></pre><p>你可以通过<code>kubectl explain &lt;object&gt;</code>命令来查看Object资源对象介绍，并通过<code>kubectl explain &lt;object1&gt;.&lt;object2&gt;</code>来查看<code>&lt;object1&gt;</code>的子对象<code>&lt;object2&gt;</code>的资源介绍，例如：</p><pre><code class=\"language-bash\">$ kubectl explain service\n$ kubectl explain service.spec\n$ kubectl explain service.spec.ports\n</code></pre><p>Kubernetes资源定义YAML文件，支持以下数据类型：</p><ul>\n<li>string，表示字符串类型。</li>\n<li>object，表示一个对象，需要嵌套多层字段。</li>\n<li>map[string]string，表示由key:value组成的映射。</li>\n<li>[]string，表示字串列表。</li>\n<li>[]object，表示对象列表。</li>\n<li>boolean，表示布尔类型。</li>\n<li>integer，表示整型。</li>\n</ul><h2>常用的Kubernetes资源定义</h2><p>上面说了，Kubernetes中有很多资源，其中Pod、Deployment、Service、ConfigMap这4类是比较常用的资源，我来一个个介绍下。</p><h3>Pod资源定义</h3><p>下面是一个Pod的YAML定义：</p><pre><code class=\"language-yaml\">apiVersion: v1   # 必须 版本号， 常用v1  apps/v1\nkind: Pod\t # 必须\nmetadata:  # 必须，元数据\n  name: string  # 必须，名称\n  namespace: string # 必须，命名空间，默认上default,生产环境为了安全性建议新建命名空间分类存放\n  labels:   # 非必须，标签，列表值\n    - name: string\n  annotations:  # 非必须，注解，列表值\n    - name: string\nspec:  # 必须，容器的详细定义\n  containers:  #必须，容器列表，\n    - name: string　　　#必须，容器1的名称\n      image: string\t\t#必须，容器1所用的镜像\n      imagePullPolicy: [Always|Never|IfNotPresent]  #非必须，镜像拉取策略，默认是Always\n      command: [string]  # 非必须 列表值，如果不指定，则是一镜像打包时使用的启动命令\n      args:　[string] # 非必须，启动参数\n      workingDir: string # 非必须，容器内的工作目录\n      volumeMounts: # 非必须，挂载到容器内的存储卷配置\n        - name: string  # 非必须，存储卷名字，需与【@1】处定义的名字一致\n          readOnly: boolean #非必须，定义读写模式，默认是读写\n      ports: # 非必须，需要暴露的端口\n        - name: string  # 非必须 端口名称\n          containerPort: int  # 非必须 端口号\n          hostPort: int # 非必须 宿主机需要监听的端口号，设置此值时，同一台宿主机不能存在同一端口号的pod， 建议不要设置此值\n          proctocol: [tcp|udp]  # 非必须 端口使用的协议，默认是tcp\n      env: # 非必须 环境变量\n        - name: string # 非必须 ，环境变量名称\n          value: string  # 非必须，环境变量键值对\n      resources:  # 非必须，资源限制\n        limits:  # 非必须，限制的容器使用资源的最大值，超过此值容器会推出\n          cpu: string # 非必须，cpu资源，单位是core，从0.1开始\n          memory: string 内存限制，单位为MiB,GiB\n        requests:  # 非必须，启动时分配的资源\n          cpu: string \n          memory: string\n      livenessProbe:   # 非必须，容器健康检查的探针探测方式\n        exec: # 探测命令\n          command: [string] # 探测命令或者脚本\n        httpGet: # httpGet方式\n          path: string  # 探测路径，例如 http://ip:port/path\n          port: number  \n          host: string  \n          scheme: string\n          httpHeaders:\n            - name: string\n              value: string\n          tcpSocket:  # tcpSocket方式，检查端口是否存在\n            port: number\n          initialDelaySeconds: 0 #容器启动完成多少秒后的再进行首次探测，单位为s\n          timeoutSeconds: 0  #探测响应超时的时间,默认是1s,如果失败，则认为容器不健康，会重启该容器\n          periodSeconds: 0  # 探测间隔时间，默认是10s\n          successThreshold: 0  # \n          failureThreshold: 0\n        securityContext:\n          privileged: false\n        restartPolicy: [Always|Never|OnFailure]  # 容器重启的策略，\n        nodeSelector: object  # 指定运行的宿主机\n        imagePullSecrets:  # 容器下载时使用的Secrets名称，需要与valumes.secret中定义的一致\n          - name: string\n        hostNetwork: false\n        volumes: ## 挂载的共享存储卷类型\n          - name: string  # 非必须，【@1】\n          emptyDir: {}\n          hostPath:\n            path: string\n          secret:  # 类型为secret的存储卷，使用内部的secret内的items值作为环境变量\n            secrectName: string\n            items:\n              - key: string\n                path: string\n            configMap:  ## 类型为configMap的存储卷\n              name: string\n              items:\n                - key: string\n                  path: string\n</code></pre><p>Pod是Kubernetes中最重要的资源，我们可以通过Pod YAML定义来创建一个Pod，也可以通过DaemonSet、Deployment、ReplicaSet、StatefulSet、Job、CronJob来创建Pod。</p><h3>Deployment资源定义</h3><p>Deployment资源定义YAML文件如下：</p><pre><code class=\"language-yaml\">apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels: # 设定资源的标签\n    app: iam-apiserver\n  name: iam-apiserver\n  namespace: default\nspec:\n  progressDeadlineSeconds: 10 # 指定多少时间内不能完成滚动升级就视为失败，滚动升级自动取消\n  replicas: 1 # 声明副本数，建议 &gt;= 2\n  revisionHistoryLimit: 5 # 设置保留的历史版本个数，默认是10\n  selector: # 选择器\n    matchLabels: # 匹配标签\n      app: iam-apiserver # 标签格式为key: value对\n  strategy: # 指定部署策略\n    rollingUpdate:\n      maxSurge: 1 # 最大额外可以存在的副本数，可以为百分比，也可以为整数\n      maxUnavailable: 1 # 表示在更新过程中能够进入不可用状态的 Pod 的最大值，可以为百分比，也可以为整数\n    type: RollingUpdate # 更新策略，包括：重建(Recreate)、RollingUpdate(滚动更新)\n  template: # 指定Pod创建模板。注意：以下定义为Pod的资源定义\n    metadata: # 指定Pod的元数据\n      labels: # 指定Pod的标签\n        app: iam-apiserver\n    spec:\n      affinity:\n        podAntiAffinity: # Pod反亲和性，尽量避免同一个应用调度到相同Node\n          preferredDuringSchedulingIgnoredDuringExecution: # 软需求\n          - podAffinityTerm:\n              labelSelector:\n                matchExpressions: # 有多个选项，只有同时满足这些条件的节点才能运行 Pod\n                - key: app\n                  operator: In # 设定标签键与一组值的关系，In、NotIn、Exists、DoesNotExist\n                  values:\n                  - iam-apiserver\n              topologyKey: kubernetes.io/hostname\n            weight: 100 # weight 字段值的范围是1-100。\n      containers:\n      - command: # 指定运行命令\n        - /opt/iam/bin/iam-apiserver # 运行参数\n        - --config=/etc/iam/iam-apiserver.yaml\n        image: ccr.ccs.tencentyun.com/lkccc/iam-apiserver-amd64:v1.0.6 # 镜像名，遵守镜像命名规范\n        imagePullPolicy: Always # 镜像拉取策略。IfNotPresent：优先使用本地镜像；Never：使用本地镜像，本地镜像不存在，则报错；Always：默认值，每次都重新拉取镜像\n        # lifecycle: # kubernetes支持postStart和preStop事件。当一个容器启动后，Kubernetes将立即发送postStart事件；在容器被终结之前，Kubernetes将发送一个preStop事件\n        name: iam-apiserver # 容器名称，与应用名称保持一致\n        ports: # 端口设置\n        - containerPort: 8443 # 容器暴露的端口\n          name: secure # 端口名称\n          protocol: TCP # 协议，TCP和UDP\n        livenessProbe: # 存活检查，检查容器是否正常，不正常则重启实例\n          httpGet: # HTTP请求检查方法\n            path: /healthz # 请求路径\n            port: 8080 # 检查端口\n            scheme: HTTP # 检查协议\n          initialDelaySeconds: 5 # 启动延时，容器延时启动健康检查的时间\n          periodSeconds: 10 # 间隔时间，进行健康检查的时间间隔\n          successThreshold: 1 # 健康阈值，表示后端容器从失败到成功的连续健康检查成功次数\n          failureThreshold: 1 # 不健康阈值，表示后端容器从成功到失败的连续健康检查成功次数\n          timeoutSeconds: 3 # 响应超时，每次健康检查响应的最大超时时间\n        readinessProbe: # 就绪检查，检查容器是否就绪，不就绪则停止转发流量到当前实例\n          httpGet: # HTTP请求检查方法\n            path: /healthz # 请求路径\n            port: 8080 # 检查端口\n            scheme: HTTP # 检查协议\n          initialDelaySeconds: 5 # 启动延时，容器延时启动健康检查的时间\n          periodSeconds: 10 # 间隔时间，进行健康检查的时间间隔\n          successThreshold: 1 # 健康阈值，表示后端容器从失败到成功的连续健康检查成功次数\n          failureThreshold: 1 # 不健康阈值，表示后端容器从成功到失败的连续健康检查成功次数\n          timeoutSeconds: 3 # 响应超时，每次健康检查响应的最大超时时间\n        startupProbe: # 启动探针，可以知道应用程序容器什么时候启动了\n          failureThreshold: 10\n          httpGet:\n            path: /healthz\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 3\n        resources: # 资源管理\n          limits: # limits用于设置容器使用资源的最大上限,避免异常情况下节点资源消耗过多\n            cpu: \"1\" # 设置cpu limit，1核心 = 1000m\n            memory: 1Gi # 设置memory limit，1G = 1024Mi\n          requests: # requests用于预分配资源,当集群中的节点没有request所要求的资源数量时,容器会创建失败\n            cpu: 250m # 设置cpu request\n            memory: 500Mi # 设置memory request\n        terminationMessagePath: /dev/termination-log # 容器终止时消息保存路径\n        terminationMessagePolicy: File # 仅从终止消息文件中检索终止消息\n        volumeMounts: # 挂载日志卷\n        - mountPath: /etc/iam/iam-apiserver.yaml # 容器内挂载镜像路径\n          name: iam # 引用的卷名称\n          subPath: iam-apiserver.yaml # 指定所引用的卷内的子路径，而不是其根路径。\n        - mountPath: /etc/iam/cert\n          name: iam-cert\n      dnsPolicy: ClusterFirst\n      restartPolicy: Always # 重启策略，Always、OnFailure、Never\n      schedulerName: default-scheduler # 指定调度器的名字\n      imagePullSecrets: # 在Pod中设置ImagePullSecrets只有提供自己密钥的Pod才能访问私有仓库\n        - name: ccr-registry # 镜像仓库的Secrets需要在集群中手动创建\n      securityContext: {} # 指定安全上下文\n      terminationGracePeriodSeconds: 5 # 优雅关闭时间，这个时间内优雅关闭未结束，k8s 强制 kill\n      volumes: # 配置数据卷，类型详见https://kubernetes.io/zh/docs/concepts/storage/volumes\n      - configMap: # configMap 类型的数据卷\n          defaultMode: 420 #权限设置0~0777，默认0664\n          items:\n          - key: iam-apiserver.yaml\n            path: iam-apiserver.yaml\n          name: iam # configmap名称\n        name: iam # 设置卷名称，与volumeMounts名称对应\n      - configMap:\n          defaultMode: 420\n          name: iam-cert\n        name: iam-cert\n</code></pre><p>在部署时，你可以根据需要来配置相应的字段，常见的需要配置的字段为：<code>labels</code>、<code>name</code>、<code>namespace</code>、<code>replicas</code>、<code>command</code>、<code>imagePullPolicy</code>、<code>container.name</code>、<code>livenessProbe</code>、<code>readinessProbe</code>、<code>resources</code>、<code>volumeMounts</code>、<code>volumes</code>、<code>imagePullSecrets</code>等。</p><p>另外，在部署应用时，经常需要提供配置文件，供容器内的进程加载使用。最常用的方法是挂载ConfigMap到应用容器中。那么，如何挂载ConfigMap到容器中呢？</p><p>引用 ConfigMap 对象时，你可以在 volume 中通过它的名称来引用。你可以自定义 ConfigMap 中特定条目所要使用的路径。下面的配置就显示了如何将名为 <code>log-config</code> 的 ConfigMap 挂载到名为 <code>configmap-pod</code> 的 Pod 中：</p><pre><code class=\"language-yaml\">apiVersion: v1\nkind: Pod\nmetadata:\n  name: configmap-pod\nspec:\n  containers:\n    - name: test\n      image: busybox\n      volumeMounts:\n        - name: config-vol\n          mountPath: /etc/config\n  volumes:\n    - name: config-vol\n      configMap:\n        name: log-config\n        items:\n          - key: log_level\n            path: log_level\n</code></pre><p><code>log-config</code> ConfigMap 以卷的形式挂载，并且存储在 <code>log_level</code> 条目中的所有内容都被挂载到 Pod 的<code>/etc/config/log_level</code> 路径下。 请注意，这个路径来源于卷的 <code>mountPath</code> 和 <code>log_level</code> 键对应的<code>path</code>。</p><p>这里需要注意，在使用 ConfigMap 之前，你首先要创建它。接下来，我们来看下ConfigMap定义。</p><h3>ConfigMap资源定义</h3><p>下面是一个ConfigMap YAML示例：</p><pre><code class=\"language-yaml\">apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: test-config4\ndata: # 存储配置内容\n  db.host: 172.168.10.1 # 存储格式为key: value\n  db.port: 3306\n</code></pre><p>可以看到，ConfigMap的YAML定义相对简单些。假设我们将上述YAML文件保存在了<code>iam-configmap.yaml</code>文件中，我们可以执行以下命令，来创建ConfigMap：</p><pre><code class=\"language-bash\">$ kubectl create -f iam-configmap.yaml\n</code></pre><p>除此之外，kubectl命令行工具还提供了3种创建ConfigMap的方式。我来分别介绍下。</p><p>1）通过<code>--from-literal</code>参数创建</p><p>创建命令如下：</p><pre><code class=\"language-bash\">$ kubectl create configmap iam-configmap --from-literal=db.host=172.168.10.1 --from-literal=db.port='3306'\n</code></pre><p>2）通过<code>--from-file=&lt;文件&gt;</code>参数创建</p><p>创建命令如下：</p><pre><code class=\"language-bash\">$ echo -n 172.168.10.1 &gt; ./db.host\n$ echo -n 3306 &gt; ./db.port\n$ kubectl create cm iam-configmap --from-file=./db.host --from-file=./db.port\n</code></pre><p><code>--from-file</code>的值也可以是一个目录。当值是目录时，目录中的文件名为key，目录的内容为value。</p><p>3）通过<code>--from-env-file</code>参数创建</p><p>创建命令如下：</p><pre><code class=\"language-bash\">$ cat &lt;&lt; EOF &gt; env.txt\ndb.host=172.168.10.1\ndb.port=3306\nEOF\n$ kubectl create cm iam-configmap --from-env-file=env.txt\n</code></pre><h3>Service资源定义</h3><p>Service 是 Kubernetes 另一个核心资源。通过创建 Service，可以为一组具有相同功能的容器应用提供一个统一的入口地址，并且将请求负载到后端的各个容器上。Service资源定义YAML文件如下：</p><pre><code class=\"language-yaml\">apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app: iam-apiserver\n  name: iam-apiserver\n  namespace: default\nspec:\n  clusterIP: 192.168.0.231 # 虚拟服务地址\n  externalTrafficPolicy: Cluster # 表示此服务是否希望将外部流量路由到节点本地或集群范围的端点\n  ports: # service需要暴露的端口列表\n  - name: https #端口名称\n    nodePort: 30443 # 当type = NodePort时，指定映射到物理机的端口号\n    port: 8443 # 服务监听的端口号\n    protocol: TCP # 端口协议，支持TCP和UDP，默认TCP\n    targetPort: 8443 # 需要转发到后端Pod的端口号\n  selector: # label selector配置，将选择具有label标签的Pod作为其后端RS\n    app: iam-apiserver\n  sessionAffinity: None # 是否支持session\n  type: NodePort # service的类型，指定service的访问方式，默认为clusterIp\n</code></pre><p>上面，我介绍了常用的Kubernetes YAML的内容。我们在部署应用的时候，是需要手动编写这些文件的。接下来，我就讲解一些在编写过程中常用的编写技巧。</p><h2>YAML文件编写技巧</h2><p>这里我主要介绍三个技巧。</p><p>1）使用在线的工具来自动生成模板YAML文件。</p><p>YAML文件很复杂，完全从0开始编写一个YAML定义文件，工作量大、容易出错，也没必要。我比较推荐的方式是，使用一些工具来自动生成所需的YAML。</p><p>这里我推荐使用<a href=\"https://k8syaml.com/\">k8syaml</a>工具。<code>k8syaml</code>是一个在线的YAML生成工具，当前能够生成Deployment、StatefulSet、DaemonSet类型的YAML文件。<code>k8syaml</code>具有默认值，并且有对各字段详细的说明，可以供我们填参时参考。</p><p>2）使用<code>kubectl run</code>命令获取YAML模板：</p><pre><code class=\"language-yaml\">$ kubectl run --dry-run=client --image=nginx nginx -o yaml &gt; my-nginx.yaml\n$ cat my-nginx.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  creationTimestamp: null\n  labels:\n    run: nginx\n  name: nginx\nspec:\n  containers:\n  - image: nginx\n    name: nginx\n    resources: {}\n  dnsPolicy: ClusterFirst\n  restartPolicy: Always\nstatus: {}\n</code></pre><p>然后，我们可以基于这个模板，来修改配置，形成最终的YAML文件。</p><p>3）导出集群中已有的资源描述。</p><p>有时候，如果我们想创建一个Kubernetes资源，并且发现该资源跟集群中已经创建的资源描述相近或者一致的时候，可以选择导出集群中已经创建资源的YAML描述，并基于导出的YAML文件进行修改，获得所需的YAML。例如：</p><pre><code class=\"language-bash\">$ kubectl get deployment iam-apiserver -o yaml &gt; iam-authz-server.yaml\n</code></pre><p>接着，修改<code>iam-authz-server.yaml</code>。通常，我们需要删除Kubernetes自动添加的字段，例如<code>kubectl.kubernetes.io/last-applied-configuration</code>、<code>deployment.kubernetes.io/revision</code>、<code>creationTimestamp</code>、<code>generation</code>、<code>resourceVersion</code>、<code>selfLink</code>、<code>uid</code>、<code>status</code>。</p><p>这些技巧可以帮助我们更好地编写和使用Kubernetes YAML。</p><h2>使用Kubernetes YAML时的一些推荐工具</h2><p>接下来，我再介绍一些比较流行的工具，你可以根据自己的需要进行选择。</p><h3>kubeval</h3><p><a href=\"https://github.com/instrumenta/kubeval\">kubeval</a>可以用来验证Kubernetes YAML是否符合Kubernetes API模式。</p><p>安装方法如下：</p><pre><code class=\"language-bash\">$ wget https://github.com/instrumenta/kubeval/releases/latest/download/kubeval-linux-amd64.tar.gz\n$ tar xf kubeval-linux-amd64.tar.gz\n$ mv kubeval $HOME/bin\n</code></pre><p>安装完成后，我们对Kubernetes YAML文件进行验证：</p><pre><code class=\"language-bash\">$ kubeval deployments/iam.invalid.yaml\nERR  - iam/templates/iam-configmap.yaml: Duplicate 'ConfigMap' resource 'iam' in namespace ''\n</code></pre><p>根据提示，查看<code>iam.yaml</code>，发现在<code>iam.yaml</code>文件中，我们定义了两个同名的<code>iam</code> ConfigMap：</p><pre><code class=\"language-yaml\">apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: iam\ndata:\n  {}\n---\n# Source: iam/templates/iam-configmap.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: iam\ndata:\n  iam-: \"\"\n  iam-apiserver.yaml: |\n    ...\n</code></pre><p>可以看到，使用<code>kubeval</code>之类的工具，能让我们在部署的早期，不用访问集群就能发现YAML文件的错误。</p><h3>kube-score</h3><p><a href=\"https://github.com/zegl/kube-score\">kube-score</a>能够对Kubernetes YAML进行分析，并根据内置的检查对其评分，这些检查是根据安全建议和最佳实践而选择的，例如：</p><ul>\n<li>以非Root用户启动容器。</li>\n<li>为Pods设置健康检查。</li>\n<li>定义资源请求和限制。</li>\n</ul><p>你可以按照这个方法安装：</p><pre><code class=\"language-bash\">$ go get github.com/zegl/kube-score/cmd/kube-score\n</code></pre><p>然后，我们对Kubernetes YAML进行评分：</p><pre><code class=\"language-bash\">$ kube-score score -o ci deployments/iam.invalid.yaml\n[OK] iam-apiserver apps/v1/Deployment\n[OK] iam-apiserver apps/v1/Deployment\n[OK] iam-apiserver apps/v1/Deployment\n[OK] iam-apiserver apps/v1/Deployment\n[CRITICAL] iam-apiserver apps/v1/Deployment: The pod does not have a matching NetworkPolicy\n[CRITICAL] iam-apiserver apps/v1/Deployment: Container has the same readiness and liveness probe\n[CRITICAL] iam-apiserver apps/v1/Deployment: (iam-apiserver) The pod has a container with a writable root filesystem\n[CRITICAL] iam-apiserver apps/v1/Deployment: (iam-apiserver) The container is running with a low user ID\n[CRITICAL] iam-apiserver apps/v1/Deployment: (iam-apiserver) The container running with a low group ID\n[OK] iam-apiserver apps/v1/Deployment\n...\n</code></pre><p>检查的结果有<code>OK</code>、<code>SKIPPED</code>、<code>WARNING</code>和<code>CRITICAL</code>。<code>CRITICAL</code>是需要你修复的；<code>WARNING</code>是需要你关注的；<code>SKIPPED</code>是因为某些原因略过的检查；<code>OK</code>是验证通过的。</p><p>如果你想查看详细的错误原因和解决方案，可以使用<code>-o human</code>选项，例如：</p><pre><code class=\"language-bash\">$ kube-score score -o human deployments/iam.invalid.yaml\n</code></pre><p>上述命令会检查YAML资源定义文件，如果有不合规的地方会报告级别、类别以及错误详情，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/04/f6/0498529693c6d15c9d9d45cbyy866cf6.png?wh=1920x827\" alt=\"图片\"></p><h3></h3><p>当然，除了kubeval、kube-score这两个工具，业界还有其他一些Kubernetes检查工具，例如<a href=\"https://github.com/stelligent/config-lint\">config-lint</a>、<a href=\"https://github.com/cloud66-oss/copper\">copper</a>、<a href=\"https://github.com/open-policy-agent/conftest\">conftest</a>、<a href=\"https://github.com/FairwindsOps/polaris\">polaris</a>等。</p><p>这些工具，我推荐你这么来选择：首先，使用kubeval工具做最基本的YAML文件验证。验证通过之后，我们就可以进行更多的测试。如果你没有特别复杂的YAML验证要求，只需要用到一些最常见的检查策略，这时候可以使用kube-score。如果你有复杂的验证要求，并且希望能够自定义验证策略，则可以考虑使用copper。当然，<code>polaris</code>、<code>config-lint</code>、<code>copper</code>也值得你去尝试下。</p><h2>总结</h2><p>今天，我主要讲了如何编写Kubernetes YAML文件。</p><p>YAML格式具有丰富的数据表达能力、清晰的结构和层次，因此被用于Kubernetes资源的定义文件中。如果你要把应用部署在Kubernetes集群中，就要创建多个关联的K8s资源，如果要创建K8s资源，目前比较多的方式还是编写YAML格式的定义文件。</p><p>这一讲我介绍了K8s中最常用的四种资源（Pod、Deployment、Service、ConfigMap）的YAML定义的写法，你可以常来温习。</p><p>另外，在编写YAML文件时，也有一些技巧。比如，可以通过在线工具<a href=\"https://k8syaml.com/\">k8syaml</a>来自动生成初版的YAML文件，再基于此YAML文件进行二次修改，从而形成终版。</p><p>最后，我还给你分享了编写和使用Kubernetes YAML时，社区提供的多种工具。比如，kubeval可以校验YAML，kube-score可以给YAML文件打分。了解了如何编写Kubernetes YAML文件，下一讲的学习相信你会进行得更顺利。</p><h2>课后练习</h2><ol>\n<li>思考一下，如何将ConfigMap中的Key挂载到同一个目录中，文件名为Key名？</li>\n<li>使用kubeval检查你正在或之前从事过的项目的K8s YAML定义文件，查看报错，并修改和优化。</li>\n</ol><p>欢迎你在留言区和我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"46 | 如何制作Docker镜像？","id":417216},"right":{"article_title":"48 | 基于腾讯云 EKS 的容器化部署实战","id":418711}}},{"article_id":418711,"article_title":"48 | 基于腾讯云 EKS 的容器化部署实战","article_content":"<p>你好，我是孔令飞。</p><p>在 <a href=\"https://time.geekbang.org/column/article/415606\">45讲</a>中，我介绍了一种基于Kubernetes的云原生架构设计方案。在云原生架构中，我们是通过Docker + Kubernetes来部署云原生应用的。那么这一讲，我就手把手教你如何在Kubernetes集群中部署好IAM应用。因为步骤比较多，所以希望你能跟着我完成每一个操作步骤。相信在实操的过程中，你也会学到更多的知识。</p><h2>准备工作</h2><p>在部署IAM应用之前，我们需要做以下准备工作：</p><ol>\n<li>开通腾讯云容器服务镜像仓库。</li>\n<li>安装并配置Docker。</li>\n<li>准备一个Kubernetes集群。</li>\n</ol><h3>开通腾讯云容器服务镜像仓库</h3><p>在Kubernetes集群中部署IAM应用，需要从镜像仓库下载指定的IAM镜像，所以首先需要有一个镜像仓库来托管IAM的镜像。我们可以选择将IAM镜像托管到<a href=\"https://hub.docker.com/\">DockerHub</a>上，这也是docker运行时默认获取镜像的地址。</p><p>但因为DockerHub服务部署在国外，国内访问速度很慢。所以，我建议将IAM镜像托管在国内的镜像仓库中。这里我们可以选择腾讯云提供的镜像仓库服务，访问地址为<a href=\"https://console.cloud.tencent.com/tke2/registry\">容器镜像服务个人版</a>。</p><p>如果你已经有腾讯云的镜像仓库，可以忽略腾讯云镜像仓库开通步骤。</p><p>在开通腾讯云镜像仓库之前，你需要<a href=\"https://cloud.tencent.com/document/product/378/17985\">注册腾讯云账号</a>，并完成<a href=\"https://cloud.tencent.com/document/product/378/3629\">实名认证</a>。</p><!-- [[[read_end]]] --><p>开通腾讯云镜像仓库的具体步骤如下：</p><p><strong>第一步，开通个人版镜像仓库。</strong></p><ol>\n<li>\n<p>登录<a href=\"https://console.cloud.tencent.com/tke2\">容器服务控制台</a>，选择左侧导航栏中的【镜像仓库】&gt;【<a href=\"https://console.cloud.tencent.com/tke2/registry/user/self\">个人版</a>】。</p>\n</li>\n<li>\n<p>根据以下提示，填写相关信息，并单击<strong>【开通】</strong>进行初始化。如下图所示：</p>\n</li>\n</ol><p><img src=\"https://static001.geekbang.org/resource/image/1d/8c/1d4bdfe89bc049d224e7002c23a0ea8c.png?wh=1920x569\" alt=\"图片\"></p><ul>\n<li><strong>用户名：</strong>默认是当前用户的账号ID，是你登录到腾讯云Docker镜像仓库的身份，可在 <a href=\"https://console.cloud.tencent.com/developer\">账号信息</a> 页面获取。</li>\n<li><strong>密码：</strong>是你登录到腾讯云 Docker 镜像仓库的凭证。</li>\n</ul><p>这里需要你记录用户名及密码，用于推送及拉取镜像。假如我们开通的镜像仓库，用户名为<code>10000099xxxx</code>，密码为<code>iam59!z$</code>。</p><p>这里要注意，<code>10000099xxxx</code><strong>要替换成你镜像仓库的用户名。</strong></p><p><strong>第二步，登录到腾讯云Registry</strong><strong>（镜像仓库）。</strong></p><p>在我们开通完Registry，就可以登录Registry了。可以通过以下命令来登录腾讯云Registry：</p><pre><code class=\"language-bash\">$ docker login --username=[username] ccr.ccs.tencentyun.com\n</code></pre><p>这里的username是腾讯云账号 ID，开通时已注册，可在 <a href=\"https://console.cloud.tencent.com/developer\">账号信息</a> 页面获取。docker命令会在后面安装。<br>\n<strong>第三步，新建镜像仓库命名空间</strong><strong>。</strong></p><p>如果想使用镜像仓库，那么你首先需要创建一个用来创建镜像的命名空间。上一步，我们开通了镜像仓库，就可以在“命名空间”页签新建命名空间了，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/1e/5a/1e79852fdc5ee1a094bd42efdf21015a.png?wh=1920x522\" alt=\"图片\"></p><p>上图中，我们创建了一个叫<code>marmotedu</code>的命名空间。</p><p>这里，镜像仓库服务、命名空间、镜像仓库、标签这几个概念你可能弄不清楚。接下来，我详细介绍下四者的关系，关系如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/ab/3b/abe8358d3ea2851bc32c80fd9519c63b.jpg?wh=2248x1581\" alt=\"\"></p><p>先来看下我们使用镜像仓库的格式：<code>&lt;镜像仓库服务地址&gt;/&lt;命名空间&gt;/&lt;镜像仓库&gt;:&lt;标签&gt;</code>，例如<code>ccr.ccs.tencentyun.com/marmotedu/iam-apiserver-amd64:v1.1.0</code>。</p><p>如果想使用一个Docker镜像，我们首先需要开通一个镜像仓库服务（Registry），镜像仓库服务都会对外提供一个固定的地址供你访问。在Registry中，我们（User）可以创建一个或多个命名空间（Namespace），命名空间也可以简单理解为镜像仓库逻辑上的一个分组。</p><p>接下来，就可以在Namespace中创建一个或多个镜像仓库，例如<code>iam-apiserver-amd64</code>、<code>iam-authz-server-amd64</code>、<code>iam-pump-amd64</code>等。针对每一个镜像仓库，又可以创建多个标签（Tag），例如<code>v1.0.1</code>、<code>v1.0.2</code>等。</p><p><code>&lt;镜像仓库&gt;:&lt;标签&gt;</code>又称为镜像。镜像又分为私有镜像和公有镜像，公有镜像可供所有能访问Registry的用户下载使用，私有镜像只提供给通过授权的用户使用。</p><h3>安装Docker</h3><p>开通完镜像仓库之后，我们还需要安装Docker，用来构建和测试Docker镜像。下面我来讲解下具体的安装步骤。</p><p><strong>第一步，安装Docker前置条件检查。</strong></p><p>需要确保CentOS系统启用了<code>centos-extras</code> yum源，默认情况下已经启用，检查方式如下：</p><pre><code class=\"language-bash\">$ cat /etc/yum.repos.d/CentOS-Extras.repo\n# Qcloud-Extras.repo\n\n[extras]\nname=Qcloud-$releasever - Extras\nbaseurl=http://mirrors.tencentyun.com/centos/$releasever/extras/$basearch/os/\ngpgcheck=1\nenabled=1\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-Qcloud-8\n</code></pre><p>如果<code>/etc/yum.repos.d/CentOS-Extras.repo</code>文件存在，且文件中<code>extras</code>部分的<code>enabled</code>配置项值为<code>1</code>，说明已经启用了<code>centos-extras</code> yum源。如果<code>/etc/yum.repos.d/CentOS-Extras.repo</code> 文件不存在，或者<code>enabled</code> 不为1，则需要创建<code>/etc/yum.repos.d/CentOS-Extras.repo</code> 文件，并将上述内容复制进去。</p><p><strong>第二步，安装docker。</strong></p><p>Docker官方文档 <a href=\"https://docs.docker.com/engine/install/centos/\">Install Docker Engine on CentOS</a>提供了3种安装方法:</p><ul>\n<li>通过Yum源安装。</li>\n<li>通过RPM包安装</li>\n<li>通过脚本安装。</li>\n</ul><p>这里，我们选择最简单的安装方式：<strong>通过Yum源安装</strong>。它具体又分为下面3个步骤。</p><ol>\n<li>安装docker。</li>\n</ol><pre><code class=\"language-bash\">$ sudo yum install -y yum-utils # 1. 安装 `yum-utils` 包，该包提供了 `yum-config-manager` 工具\n$ sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo # 2. 安装 `docker-ce.repo` yum 源\n$ sudo yum-config-manager --enable docker-ce-nightly docker-ce-test # 3. 启用 `nightly` 和 `test` yum 源\n$ sudo yum install -y docker-ce docker-ce-cli containerd.io # 4. 安装最新版本的 docker 引擎和 containerd\n</code></pre><ol start=\"2\">\n<li>启动docker。</li>\n</ol><p>可以通过以下命令来启动 docker：</p><pre><code class=\"language-bash\">$ sudo systemctl start docker\n</code></pre><p>docker的配置文件是 <code>/etc/docker/daemon.json</code> ，这个配置文件默认是没有的，需要我们手动创建：</p><pre><code class=\"language-bash\">$ sudo tee /etc/docker/daemon.json &lt;&lt; EOF\n{\n&nbsp; \"bip\": \"172.16.0.1/24\",\n&nbsp; \"registry-mirrors\": [],\n&nbsp; \"graph\": \"/data/lib/docker\"\n}\nEOF\n</code></pre><p>这里，我来解释下常用的配置参数。</p><ul>\n<li>registry-mirrors：仓库地址，可以根据需要修改为指定的地址。</li>\n<li>graph：镜像、容器的存储路径，默认是/var/lib/docker。如果你的 <code>/</code> 目录存储空间满足不了需求，需要设置graph为更大的目录。</li>\n<li>bip：指定容器的IP网段。</li>\n</ul><p>配置完成后，需要重启Docker：</p><pre><code class=\"language-bash\">$ sudo systemctl restart docker\n</code></pre><ol start=\"3\">\n<li>测试Docker是否安装成功。</li>\n</ol><pre><code class=\"language-bash\">$ sudo docker run hello-world\nUnable to find image 'hello-world:latest' locally\nlatest: Pulling from library/hello-world\nb8dfde127a29: Pull complete\nDigest: sha256:0fe98d7debd9049c50b597ef1f85b7c1e8cc81f59c8d623fcb2250e8bec85b38\nStatus: Downloaded newer image for hello-world:latest\n...\nHello from Docker!\nThis message shows that your installation appears to be working correctly.\n....\n</code></pre><p><code>docker run hello-world</code>命令会下载<code>hello-world</code>镜像，并启动容器，打印安装成功提示信息后退出。</p><p>这里注意，如果你通过Yum源安装失败，可以尝试Docker官方文档 <a href=\"https://docs.docker.com/engine/install/centos/\">Install Docker Engine on CentOS</a>提供的其他方式安装。</p><p><strong>第三步，安装后配置。</strong></p><p>安装成功后，我们还需要做一些其他配置。主要有两个，一个是配置docker，使其可通过<code>non-root</code>用户使用，另一个是配置docker开机启动。</p><ol>\n<li>使用<code>non-root</code>用户操作Docker</li>\n</ol><p>我们在Linux系统上操作，为了安全，需要以普通用户的身份登录系统并执行操作。所以，我们需要配置docker，使它可以被<code>non-root</code>用户使用。具体配置方法如下：</p><pre><code class=\"language-bash\">$ sudo groupadd docker # 1. 创建`docker`用户组\n$ sudo usermod -aG docker $USER # 2. 将当前用户添加到`docker`用户组下\n$ newgrp docker # 3. 重新加载组成员身份\n$ docker run hello-world # 4. 确认能够以普通用户使用docker\n</code></pre><p>如果在执行 <code>sudo groupadd docker</code> 时报 <code>groupadd: group 'docker' already exists</code> 错误，说明 <code>docker</code> 组已经存在了，可以忽略这个报错。</p><p>如果你在将用户添加到 docker 组之前，使用sudo运行过docker命令，你可能会看到以下错误：</p><pre><code class=\"language-plain\">WARNING: Error loading config file: /home/user/.docker/config.json -\nstat /home/user/.docker/config.json: permission denied\n</code></pre><p>这个错误，我们可以通过删除<code>~/.docker/</code>目录来解决，或者通过以下命令更改<code>~/.docker/</code>目录的所有者和权限：</p><pre><code class=\"language-bash\">$ sudo chown \"$USER\":\"$USER\" /home/\"$USER\"/.docker -R\n$ sudo chmod g+rwx \"$HOME/.docker\" -R\n</code></pre><ol start=\"2\">\n<li>配置docker开机启动</li>\n</ol><p>大部分Linux发行版（RHEL、CentOS、Fedora、Debian、Ubuntu 16.04及更高版本）使用systemd来管理服务，包括指定开启时启动的服务。在Debian和Ubuntu上，Docker默认配置为开机启动。</p><p>在其他系统，我们需要手动配置Docker开机启动，配置方式如下（分别需要配置docker和containerd服务）：</p><p>要在引导时为其他发行版自动启动 Docker 和 Containerd，你可以使用以下命令：</p><pre><code class=\"language-bash\">$ sudo systemctl enable docker.service # 设置 docker 开机启动\n$ sudo systemctl enable containerd.service # 设置 containerd 开机启动\n</code></pre><p>如果要禁止<code>docker</code>、<code>containerd</code>开启启动，可以用这个命令：</p><pre><code class=\"language-bash\">$ sudo systemctl disable docker.service # 禁止 docker 开机启动\n$ sudo systemctl disable containerd.service # 禁止 containerd 开机启动\n</code></pre><h3>准备一个Kubernetes集群</h3><p>安装完Docker之后，我们还需要一个Kubernetes集群，来调度docker容器。安装Kubernetes集群极其复杂，这里选择一种最简单的方式来准备一个Kubernetes集群：购买一个腾讯云弹性集群（EKS）。</p><p>如果你想自己搭建Kubernetes集群，这里建议你购买3台腾讯云CVM机器，并参照<a href=\"https://github.com/opsnull/follow-me-install-kubernetes-cluster\">follow-me-install-kubernetes-cluster</a>教程来一步步搭建Kubernetes集群，CVM机器建议的最小配置如下：<br>\n<img src=\"https://static001.geekbang.org/resource/image/88/0b/885d2431e7f2d9bcd02b32d33yye930b.jpg?wh=1920x876\" alt=\"\"></p><h4>EKS简介</h4><p>我先简单介绍一下EKS是什么。EKS（Elastic Kubernetes Service）即腾讯云弹性容器服务，是腾讯云容器服务推出的无须用户购买节点即可部署工作负载的服务模式。它完全兼容原生的 Kubernetes，支持使用原生方式创建及管理资源，按照容器真实的资源使用量计费。弹性容器服务 EKS 还扩展支持腾讯云的存储及网络等产品，同时确保用户容器的安全隔离，开箱即用。</p><h4>EKS费用</h4><p>那它是如何收费呢？EKS 是全托管的Serverless Kubernetes 服务，不会收取托管的 Master、etcd 等资源的费用。弹性集群内运行的工作负载采用后付费的按量计费模式，费用根据实际配置的资源量按使用时间计算。也就是说：<strong>Kubernetes集群本身是免费的，只有运行工作负载，消耗节点资源时收费。</strong></p><p>EKS有3种计费模式：预留券、按量计费、竞价模式，这里我建议选择<strong>按量计费</strong>。按量计费，支持按秒计费，按小时结算，随时购买随时释放，从专栏学习的角度来说，费用是最低的。EKS 会根据工作负载申请的 CPU、内存数值以及工作负载的运行时间来核算费用，具体定价，你可以参考：<a href=\"https://buy.cloud.tencent.com/price/eks\">定价|弹性容器服务</a>。</p><p>这里我通过例子来说明一下费用问题，IAM应用会部署4个Deployment，每个Deployment一个副本：</p><ul>\n<li>iam-apiserver：IAM REST API服务，提供用户、密钥、策略资源的CURD功能的API接口。</li>\n<li>iam-authz-server：IAM资源授权服务，对外提供资源授权接口。</li>\n<li>iam-pump：IAM数据清洗服务，从Redis中获取授权日志，处理后保存在MongoDB中。</li>\n<li>iamctl：IAM应用的测试服务，登陆iamctl Pod可以执行iamctl命令和smoke测试脚本，完成对IAM应用的运维和测试。</li>\n</ul><p>上述4个Deployment中的<strong>Pod配置均为0.25核、512Mi内存</strong>。</p><p>这里，我们根据EKS的费用计算公式 <code>费用 = 相关计费项配置 × 资源单位时间价格 × 运行时间</code> 计算IAM部署一天的费用：</p><pre><code>总费用 = (4 x 1) x (0.25 x 0.12 + 0.5 x 0.05) x 24 = 4.8 元\n</code></pre><p>也就是按最低配置部署IAM应用，运行一天的费用是4.8元（一瓶水的钱，就能学到如何将IAM应用部署在Kubernetes平台上，很值！）。你可能想这个计算公式里每个数值都代表什么呢？我来解释一下，其中：</p><ul>\n<li>(4 x 1)：Kubernetes Pod总个数（一共是4个Deployment，每个Pod 1个副本）。</li>\n<li>0.25 x 0.12：连续运行1小时的CPU配置费用。</li>\n<li>0.5 x 0.05：连续运行1小时的内存配置费用。</li>\n<li>24：24小时，也即一天。</li>\n</ul><p>这里需要注意，为了帮助你节省费用，上述配置都是最低配置。在实际生产环境中，建议的配置如下：<br>\n<img src=\"https://static001.geekbang.org/resource/image/1d/35/1d20c7eeb9dba8f53194969b0da5e835.jpg?wh=1920x718\" alt=\"\"><br>\n因为iam-pump组件是有状态的，并且目前没有实现抢占机制，所以副本数需要设置为1。</p><p>另外，Intel按量计费的配置费用见下图：</p><p><img src=\"https://static001.geekbang.org/resource/image/64/59/64a5f89f4cbea95e50691455a06b1e59.png?wh=1372x226\" alt=\"图片\"></p><p>在这里有个很重要的事情提醒你：<strong>学完本节课，销毁这些Deployment，避免被继续扣费。建议腾讯云账户余额不要超过50元。</strong></p><h4>申请EKS集群</h4><p>了解了EKS以及费用相关的问题，接下来我们看看如何申请EKS集群。你可以通过以下5步来申请EKS集群。在正式申请前，请先确保腾讯云账户有大于 <strong>10 元</strong>的账户余额，否则在创建和使用EKS集群的过程中可能会因为费用不足而报错。</p><ol>\n<li>创建腾讯云弹性集群</li>\n</ol><p>具体步骤如下：</p><p>首先，登录容器服务控制台，选择左侧导航栏中的【<a href=\"https://console.cloud.tencent.com/tke2/ecluster\">弹性集群</a>】。<br>\n然后，在页面上方选择需创建弹性集群的地域，并单击【新建】。在“创建弹性集群”页面，根据以下提示设置集群信息。如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/37/8c/3740a98a6140b9c85517bdd27f30268c.png?wh=1920x950\" alt=\"图片\"></p><p>页面中各选择项的意思，我来给你解释一下：</p><ul>\n<li><strong>集群名称：</strong>创建的弹性集群名称，不超过60个字符。</li>\n<li><strong>Kubernetes版本：</strong>弹性集群支持1.12以上的多个 Kubernetes 版本选择，建议选择最新的版本。</li>\n<li><strong>所在地域：</strong>建议你根据所在地理位置选择靠近的地域，可降低访问延迟，提高下载速度。</li>\n<li><strong>集群网络：</strong>已创建的弹性集群 VPC 网络，你可以选择私有网络中的子网用于弹性集群的容器网络，详情请见 <a href=\"https://cloud.tencent.com/document/product/215/20046\">私有网络（VPC）</a> 。</li>\n<li><strong>容器网络：</strong>为集群内容器分配在容器网络地址范围内的 IP 地址。弹性集群的 Pod 会直接占用 VPC 子网 IP，请尽量选择 IP 数量充足且与其他产品使用无冲突的子网。</li>\n<li><strong>Service CIDR：</strong>集群的 ClusterIP Service 默认分配在所选 VPC 子网中，请尽量选择 IP 数量充足且与其他产品使用无冲突的子网。</li>\n<li><strong>集群描述：</strong>创建集群的相关信息，该信息将显示在“集群信息”页面。</li>\n</ul><p>设置完成后，单击【完成】即可开始创建，可在“弹性集群”列表页面查看集群的创建进度。</p><p>等待弹性集群创建完成，创建完成后的弹性集群页面如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/1c/3e/1c533956986531f0245b27864f17dc3e.png?wh=1920x376\" alt=\"图片\"></p><p>我们创建的弹性集群ID为<strong>cls-dc6sdos4</strong>。</p><ol start=\"2\">\n<li>开启外网访问</li>\n</ol><p>如果想访问EKS集群，需要先开启EKS的外网访问能力，开启方法如下：</p><p>登录容器服务控制台 -&gt; 选择左侧导航栏中的【<a href=\"https://console.cloud.tencent.com/tke2/ecluster\">弹性集群</a>】 -&gt; 进入<strong>cls-dc6sdos4</strong> 集群的详情页中 -&gt; 选择【基本信息】 -&gt; 点击【外网访问】按钮。如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/23/c6/235679797980de87432a0d4b05dd83c6.png?wh=1920x764\" alt=\"图片\"></p><p>这里要注意，开启外网访问时，为了安全，需要设置允许访问kube-apiserver的IP段。为了避免不必要的错误，外网访问地址我们设置为<code>0.0.0.0/0</code>  。如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/ea/21/ea627942e5a432401e5959ee90c06221.png?wh=920x441\" alt=\"图片\"></p><p>注意，只有测试时才可这么设置为 <code>0.0.0.0/0</code> ，如果是生产环境，建议严格限制可以访问kube-apiserver的来源IP。</p><ol start=\"3\">\n<li>安装kubectl命令行工具</li>\n</ol><p>如果要访问EKS（标准的Kubernetes集群），比较高效的方式是通过Kubernetes提供的命令行工具kubectl来访问。所以，还需要安装kubectl工具。</p><p>安装方式如下：</p><pre><code class=\"language-bash\">$ curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\n$ mkdir -p $HOME/bin\n$ mv kubectl $HOME/bin\n$ chmod +x $HOME/bin/kubectl\n</code></pre><p>具体可参考<a href=\"https://kubernetes.io/docs/tasks/tools/install-kubectl/\">安装和设置 kubectl</a>。<br>\n你可以通过以下命令来配置kubectl的bash自动补全：</p><pre><code class=\"language-bash\">$ kubectl completion bash &gt; $HOME/.kube-completion.bash\n$ echo 'source $HOME/.kube-completion.bash' &gt;&gt; ~/.bashrc\n$ bash\n</code></pre><ol start=\"4\">\n<li>下载并安装kubeconfig</li>\n</ol><p>安装完kubectl工具之后，需要配置kubectl所读取的配置文件。</p><p>这里注意，在上一步，我们开启了外网访问，开启后EKS会生成一个kubeconfig配置（ <code>kubeconfig</code> 即为kubectl的配置文件）。我们可以从页面下载并安装。</p><p>在弹性集群的基本信息页面，点击【复制】按钮，复制kubeconfig文件内容，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/bc/bf/bc314604334dd56b7337a905c9b6bfbf.png?wh=1775x731\" alt=\"图片\"></p><p>复制后，将粘贴板的内容保存在<code>$HOME/.kube/config</code>文件中。需要先执行<code>mkdir -p $HOME/.kube</code>创建<code>.kube</code>目录，再将粘贴版中的内容写到 <code>config</code> 文件中。</p><p>你可以通过以下命令，来测试kubectl工具是否成功安装和配置：</p><pre><code class=\"language-bash\">$ kubectl get nodes\nNAME                    STATUS   ROLES    AGE    VERSION\neklet-subnet-lowt256k   Ready    &lt;none&gt;   2d1h   v2.5.21\n</code></pre><p>如果输出了Kubernetes的eklet节点，并且节点状态为<strong>Ready</strong>，说明Kubernetes集群运行正常，并且kubectl安装和配置正确。</p><ol start=\"5\">\n<li>EKS集群开通集群内服务访问外网能力</li>\n</ol><p>因为IAM应用中的数据库：MariaDB、Redis、MongoDB可能需要通过外网访问，所以还需要开通EKS中Pod访问外网的能力。</p><p>EKS支持通过配置 <a href=\"https://cloud.tencent.com/document/product/215/4975\">NAT 网关</a> 和 <a href=\"https://cloud.tencent.com/document/product/215/4954\">路由表</a> 来实现集群内服务访问外网。具体开启步骤，需要你查看腾讯云官方文档：<a href=\"https://cloud.tencent.com/document/product/457/48710\">通过 NAT 网关访问外网</a>。</p><p>在开通过程中有以下两点需要你注意：</p><ul>\n<li>在<strong>创建指向 NAT 网关的路由表</strong>步骤中，目的端要选择：0.0.0.0/0。</li>\n<li>在<strong>关联子网至路由表</strong>步骤中，只关联创建EKS集群时选择的子网。</li>\n</ul><p>如果你的数据库需要通过外网访问，这里一定要确保EKS集群成功开通集群内服务访问外网能力，否则部署IAM应用时会因为访问不了数据库而失败。</p><h2>安装IAM应用</h2><p>上面，我们开通了镜像仓库、安装了Docker引擎、安装和配置了Kubernetes集群，那么接下来，我们就来看下如何将IAM应用部署到Kubernetes集群中。</p><p>假设IAM项目仓库根目录路径为 <code>$IAM_ROOT</code>，具体安装步骤如下：</p><ol>\n<li>配置<code>scripts/install/environment.sh</code></li>\n</ol><p><code>scripts/install/environment.sh</code>文件中包含了各类自定义配置。你可能需要配置跟数据库相关的配置（当然，也可以都使用默认值）：</p><ul>\n<li>MariaDB配置：environment.sh文件中以<code>MARIADB_</code>开头的变量。</li>\n<li>Redis配置：environment.sh文件中以<code>REDIS_</code>开头的变量。</li>\n<li>MongoDB配置：environment.sh文件中以<code>MONGO_</code>开头的变量。</li>\n</ul><p>其他配置，使用默认值。</p><ol start=\"2\">\n<li>创建IAM应用的配置文件</li>\n</ol><pre><code class=\"language-bash\">$ cd ${IAM_ROOT}\n$ make gen.defaultconfigs # 生成iam-apiserver、iam-authz-server、iam-pump、iamctl组件的默认配置文件\n$ make gen.ca # 生成 CA 证书\n</code></pre><p>上述命令会将IAM的配置文件存放在这个<code>${IAM_ROOT}/_output/configs/</code>目录下。</p><ol start=\"3\">\n<li>创建IAM命名空间</li>\n</ol><p>我们将IAM应用涉及到的各类资源，都创建在<code>iam</code>命名空间中。将IAM资源创建在独立的命名空间中，不仅方便维护，还可以有效避免影响其他Kubernetes资源。</p><pre><code class=\"language-bash\">$ kubectl create namespace iam\n</code></pre><ol start=\"4\">\n<li>将IAM各服务的配置文件，以ConfigMap资源的形式保存在Kubernetes集群中</li>\n</ol><pre><code class=\"language-bash\">$ kubectl -n iam create configmap iam --from-file=${IAM_ROOT}/_output/configs/\n$ kubectl -n iam get configmap iam\nNAME   DATA   AGE\niam    4      13s\n</code></pre><p>执行<code>kubectl -n iam get configmap iam</code>命令，可以成功获取创建的<code>iam</code> configmap。</p><p>如果你觉得每次执行<code>kubectl</code>命令都要指定<code>-n iam</code>选项很繁琐，你可以使用以下命令，将<code>kubectl</code>上下文环境中的命名空间指定为<code>iam</code>。设置后，执行<code>kubectl</code>命令，默认在<code>iam</code>命名空间下执行：</p><pre><code class=\"language-bash\">$ kubectl config set-context `kubectl config current-context` --namespace=iam\n</code></pre><ol start=\"5\">\n<li>将IAM各服务使用的证书文件，以ConfigMap资源的形式创建在Kubernetes集群中</li>\n</ol><pre><code class=\"language-bash\">$ kubectl -n iam create configmap iam-cert --from-file=${IAM_ROOT}/_output/cert\n$ kubectl -n iam get configmap iam-cert\nNAME       DATA   AGE\niam-cert   14     12s\n</code></pre><p>执行<code>kubectl -n iam get configmap iam-cert</code>命令，可以成功获取创建的<code>iam-cert</code> configmap。</p><ol start=\"6\">\n<li>创建镜像仓库访问密钥</li>\n</ol><p>在准备阶段，我们开通了腾讯云镜像仓库服务（访问地址为ccr.ccs.tencentyun.com），并创建了用户<code>10000099xxxx</code>，其密码为<code>iam59!z$</code>。</p><p>接下来，我们就可以创建docker-registry secret。Kubernetes在下载Docker镜像时，需要docker-registry secret来进行认证。创建命令如下：</p><pre><code class=\"language-bash\">$ kubectl -n iam create secret docker-registry ccr-registry --docker-server=ccr.ccs.tencentyun.com --docker-username=10000099xxxx --docker-password='iam59!z$'\n</code></pre><ol start=\"7\">\n<li>创建Docker镜像，并Push到镜像仓库</li>\n</ol><p>将镜像Push到CCR镜像仓库，需要确保你已经登录到腾讯云CCR镜像仓库，如果没登录，可以执行以下命令来登录：</p><pre><code class=\"language-bash\">$ docker login --username=[username] ccr.ccs.tencentyun.com\n</code></pre><p>执行 <code>make push</code> 命令构建镜像，并将镜像Push到CCR镜像仓库：</p><pre><code class=\"language-bash\">$ make push REGISTRY_PREFIX=ccr.ccs.tencentyun.com/marmotedu VERSION=v1.1.0\n</code></pre><p>上述命令，会构建iam-apiserver-amd64、iam-authz-server-amd64、iam-pump-amd64、iamctl-amd64 四个镜像，并将这些镜像Push到腾讯云镜像仓库的<code>marmotedu</code>命名空间下。</p><p>构建的镜像如下：</p><pre><code class=\"language-bash\">$ docker images|grep marmotedu\nccr.ccs.tencentyun.com/marmotedu/iam-pump-amd64           v1.1.0   e078d340e3fb        10 seconds ago      244MB\nccr.ccs.tencentyun.com/marmotedu/iam-apiserver-amd64      v1.1.0   5e90b67cc949        2 minutes ago       239MB\nccr.ccs.tencentyun.com/marmotedu/iam-authz-server-amd64   v1.1.0   6796b02be68c        2 minutes ago       238MB\nccr.ccs.tencentyun.com/marmotedu/iamctl-amd64             v1.1.0   320a77d525e3        2 minutes ago       235MB\n</code></pre><ol start=\"8\">\n<li>修改 <code>${IAM_ROOT}/deployments/iam.yaml</code> 配置</li>\n</ol><p>这里请你注意，如果在上一个步骤中，你构建的镜像tag不是 <code>v1.1.0</code> ，那么你需要修改  <code>${IAM_ROOT}/deployments/iam.yaml</code> 文件，并将iam-apiserver-amd64、 iam-authz-server-amd64、 iam-pump-amd64、iamctl-amd64 镜像的tag修改成你构建镜像时指定的tag。</p><ol start=\"9\">\n<li>部署IAM应用</li>\n</ol><pre><code class=\"language-bash\">$ kubectl -n iam apply -f ${IAM_ROOT}/deployments/iam.yaml\n</code></pre><p>执行上述命令，会在<code>iam</code>命令空间下，创建一系列Kubernetes资源，可以使用以下命令，来获取这些资源的状态：</p><pre><code class=\"language-bash\">$ kubectl -n iam get all\nNAME                                    READY   STATUS    RESTARTS   AGE\npod/iam-apiserver-d8dc48596-wkhpl       1/1     Running   0          94m\npod/iam-authz-server-6bc899c747-fbpbk   1/1     Running   0          94m\npod/iam-pump-7dcbfd4f59-2w9vk           1/1     Running   0          94m\npod/iamctl-6fc46b8ccb-gs62l             1/1     Running   1          98m\n\nNAME                       TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE\nservice/iam-apiserver      ClusterIP   192.168.0.174   &lt;none&gt;        8443/TCP,8080/TCP,8081/TCP   101m\nservice/iam-authz-server   ClusterIP   192.168.0.76    &lt;none&gt;        9443/TCP,9090/TCP            101m\nservice/iam-pump           ClusterIP   192.168.0.155   &lt;none&gt;        7070/TCP                     101m\n\nNAME                               READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/iam-apiserver      1/1     1            1           101m\ndeployment.apps/iam-authz-server   1/1     1            1           101m\ndeployment.apps/iam-pump           1/1     1            1           101m\ndeployment.apps/iamctl             1/1     1            1           101m\n\nNAME                                          DESIRED   CURRENT   READY   AGE\nreplicaset.apps/iam-apiserver-d8dc48596       1         1         1       101m\nreplicaset.apps/iam-authz-server-6bc899c747   1         1         1       101m\nreplicaset.apps/iam-pump-7dcbfd4f59           1         1         1       101m\nreplicaset.apps/iamctl-6fc46b8ccb             1         1         1       101m\n</code></pre><p>我们看到<code>pod/iam-apiserver-d8dc48596-wkhpl</code>、<code>pod/iam-authz-server-6bc899c747-fbpbk</code>、<code>pod/iam-pump-7dcbfd4f59-2w9vk</code>、<code>pod/iamctl-6fc46b8ccb-gs62l</code> 4个Pod都处在<code>Running</code>状态，说明服务都成功启动。</p><h2>测试IAM应用</h2><p>我们在<code>iam</code>命令空间下创建了一个测试Deployment <code>iamctl</code>。你可以登陆<code>iamctl</code> Deployment所创建出来的Pod，执行一些运维操作和冒烟测试。登陆命令如下：</p><pre><code class=\"language-bash\">$ kubectl -n iam exec -it `kubectl -n iam get pods -l app=iamctl | awk '/iamctl/{print $1}'` -- bash\n</code></pre><p>登陆到<code>iamctl-xxxxxxxxxx-xxxxx</code> Pod中后，就可以执行运维操作和冒烟测试了。</p><ol>\n<li>运维操作</li>\n</ol><p>在iamctl容器中，你可以使用iamctl工具提供的各类功能，iamctl以子命令的方式对外提供功能。命令执行效果见下图：</p><p><img src=\"https://static001.geekbang.org/resource/image/44/7e/4460dfd5cd7f7fae5cbb0c64e605367e.png?wh=1920x433\" alt=\"图片\"></p><ol start=\"2\">\n<li>冒烟测试</li>\n</ol><pre><code class=\"language-bash\"># cd /opt/iam/scripts/install\n# ./test.sh iam::test::smoke\n</code></pre><p>如果<code>./test.sh iam::test::smoke</code>命令，打印的输出中，最后一行为<code>congratulations, smoke test passed!</code>字符串，说明IAM应用安装成功。如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/b9/2e/b9688e6b0609571a06401da412b63d2e.png?wh=1920x603\" alt=\"图片\"></p><h2>销毁EKS集群及其资源</h2><p>好了，到这里，你已经成功在EKS集群中部署了IAM应用，EKS的使命也就完成了。接下来，为避免账户被持续扣费，需要删除EKS内的资源和集群。</p><ol>\n<li>删除EKS内创建的IAM资源</li>\n</ol><pre><code class=\"language-bash\">$ kubectl delete namespace iam\n</code></pre><p>因为删除Namespace会删除Namespace下的所有资源，所以上述命令执行时间会久点。</p><ol start=\"2\">\n<li>删除EKS集群</li>\n</ol><p>首先，登录容器服务控制台，选择左侧导航栏中的【<a href=\"https://console.cloud.tencent.com/tke2/ecluster\">弹性集群</a>】。<br>\n然后，选择创建的EKS集群：cls-dc6sdos4，点击最右侧的【删除】按钮，删除EKS集群。如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/05/95/05db9d9aca0a2a06e0a9a9faf37c4695.png?wh=1920x455\" alt=\"图片\"></p><h2>总结</h2><p>云原生架构设计中，需要将IAM应用部署到Kubernetes集群中。所以，首先需要你准备一个Kubernetes集群。你可以自己购买腾讯云CVM机器搭建Kubernetes集群，但这种方式费用高、操作复杂。所以，我建议你直接申请一个EKS集群来部署IAM应用。</p><p>EKS集群是一个标准的Kubernetes集群，可以快速申请，并免运维。EKS集群只收取实际的资源使用费用。在专栏学习过程中，部署IAM应用期间产生的资源使用费用其实是很低的，所以推荐使用这种方式来部署IAM应用。</p><p>有了Kubernetes集群，就可以直接通过以下命令来部署整个IAM应用：</p><pre><code class=\"language-bash\">$ kubectl -n iam apply -f ${IAM_ROOT}/deployments/iam.yaml\n</code></pre><p>应用部署起来之后，我们可以登陆到<code>iamctl-xxxxxxxxxx-xxxxx</code>Pod，并执行以下命令来测试整个IAM应用是否被成功部署：</p><pre><code class=\"language-bash\"># cd /opt/iam/scripts/install\n# ./test.sh iam::test::smoke\n</code></pre><h2>课后练习</h2><ol>\n<li>思考下，如何将MariaDB、MongoDB、Redis实现容器化？</li>\n<li>思考下，如何更相信IAM应用中的iam-apiserver服务，试着更新这个服务。</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"47 | 如何编写Kubernetes资源定义文件？","id":418009},"right":{"article_title":"49 | 服务编排（上）：Helm服务编排基础知识","id":420940}}},{"article_id":420940,"article_title":"49 | 服务编排（上）：Helm服务编排基础知识","article_content":"<p>你好，我是孔令飞。</p><p>我们将应用部署在Kubernetes时，可能需要创建多个服务。我就见过一个包含了40多个微服务的超大型应用，每个服务又包含了多个Kubernetes资源，比如 Service、Deployment、StatefulSet、ConfigMap等。相同的应用又要部署在不同的环境中，例如测试环境、预发环境、现网环境等，也就是说应用的配置也不同。</p><p>对于一个大型的应用，如果基于YAML文件一个一个地部署Kubernetes资源，是非常繁琐、低效的，而且这些YAML文件维护起来极其复杂，还容易出错。那么，有没有一种更加高效的方式？比如，像Docker镜像一样，将应用需要的Kubernetes资源文件全部打包在一起，通过这个包来整体部署和管理应用，从而降低应用部署和维护的复杂度。</p><p>答案是有。我们可以通过Helm Chart包来管理这些Kubernetes文件，并通过<code>helm</code>命令，基于Chart包来创建和管理应用。</p><p>接下来，我就来介绍下Helm的基础知识，并给你演示下如何基于Helm部署IAM应用。</p><h2>Helm基础知识介绍</h2><p>Helm目前是Kubernetes服务编排事实上的标准。Helm提供了多种功能来支持Kubernetes的服务编排，例如 <code>helm</code> 命令行工具、Chart包、Chart仓库等。下面，我就来详细介绍下。</p><!-- [[[read_end]]] --><h3>Helm是什么？</h3><p>Helm是Kubernetes的包管理器，类似于Python的 <code>pip</code> ，centos的 <code>yum</code> 。Helm主要用来管理Chart包。Helm Chart包中包含一系列YAML格式的Kubernetes资源定义文件，以及这些资源的配置，可以通过Helm Chart包来整体维护这些资源。</p><p>Helm也提供了一个<code>helm</code>命令行工具，该工具可以基于Chart包一键创建应用，在创建应用时，可以自定义Chart配置。应用发布者可以通过Helm打包应用、管理应用依赖关系、管理应用版本，并发布应用到软件仓库；对于使用者来说，使用Helm后不需要编写复杂的应用部署文件，可以非常方便地在Kubernetes上查找、安装、升级、回滚、卸载应用程序。</p><p>Helm最新的版本是v3，Helm3以Helm2的核心功能为基础，对Chart repo、发行版管理、安全性和library Charts进行了改进。和Helm2比起来，Helm3最明显的变化是删除了Tiller（Helm2 是一种 Client-Server 结构，客户端称为 Helm，服务器称为 Tiller）。Helm3还新增了一些功能，并废弃或重构了Helm2的部分功能，与Helm2不再兼容。此外，Helm3还引入了一些新的实验功能，包括OCI支持。</p><p>Helm3架构图如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/9b/59/9bb9e2d495d8fbe5eab4d02d407c8059.jpg?wh=1920x1083\" alt=\"图片\"></p><p>上面的架构图中，核心是Helm Client（<code>helm</code>命令）和Helm Chart包。<code>helm</code>命令可以从<code>Chart Repository</code>中下载Helm Chart包，读取<code>kubeconfig</code>文件，并构建kube-apiserver REST API接口的HTTP请求。通过调用Kubernetes提供的REST API接口，将Chart包中包含的所有以YAML格式定义的Kubernetes资源，在Kubernetes集群中创建。</p><p>这些资源以Release的形式存在于Kubernetes集群中，每个Release又包含多个Kubernetes资源，例如Deployment、Pod、Service等。</p><h3>Helm中的三大基本概念</h3><p>要学习和使用Helm，一定要了解Helm中的三大基本概念，Helm的所有操作基本都是围绕着这些概念来进行的。下面我来介绍下Helm的三大基本概念。</p><ul>\n<li><strong>Chart：</strong> 代表一个Helm包。它包含了在Kubernetes集群中运行应用程序、工具或服务所需的所有YAML格式的资源定义文件。</li>\n<li><strong>Repository（仓库）：</strong> 它是用来存放和共享 Helm Chart的地方，类似于存放源码的GitHub的Repository，以及存放镜像的Docker的Repository。</li>\n<li><strong>Release：</strong>它是运行在 Kubernetes 集群中的 Chart 的实例。一个Chart通常可以在同一个集群中安装多次。每一次安装都会创建一个新的 Release。</li>\n</ul><h3>我们为什么要使用Helm？</h3><p>现在你对Helm已经有了一定了解，这里我再来详细介绍下为什么要使用Helm。</p><p>先来看下传统的应用部署模式：</p><p><img src=\"https://static001.geekbang.org/resource/image/c1/c4/c1f54e347b5db7850b57815abed99ec4.jpg?wh=1920x966\" alt=\"图片\"></p><p>我们有测试环境、预发环境、现网环境三个环境，每个环境中部署一个应用A，应用A中包含了多个服务，每个服务又包含了自己的配置，不同服务之间的配置有些是共享的，例如<code>配置A</code>。</p><p>每个服务由一个复杂的Kubernetes YAML格式的文件来定义并创建，可以看到如果靠传统的方式，去维护这些YAML格式文件，并在不同环境下使用不同的配置去创建应用，是一件非常复杂的工作，并且后期YAML文件和Kubernetes集群中部署应用的维护都很复杂。随着微服务规模越来越大，会面临以下挑战：</p><ul>\n<li>微服务化服务数量急剧增多，给服务管理带来了极大的挑战。</li>\n<li>服务数量急剧增多，增加了管理难度，对运维部署是一种挑战。</li>\n<li>服务数量的增多，对服务配置管理也提出了更高的要求。</li>\n<li>随着服务数量增加，服务依赖关系也变得更加复杂，服务依赖关系的管理难度增大。</li>\n<li>在环境信息管理方面，在新环境快速部署一个复杂应用变得更加困难。</li>\n</ul><p>所以，我们需要一种更好的方式，来维护和管理这些YAML文件和Kubernetes中部署的应用。Helm可以帮我们解决上面这些问题。</p><p>接下来，我们来看下Helm是如何解决这些问题的。</p><p>在Helm中，可以理解为主要包含两类文件：模板文件和配置文件。模板文件通常有多个，配置文件通常有一个。Helm的模板文件基于<code>text/template</code>模板文件，提供了更加强大的模板渲染能力。Helm可以将配置文件中的值渲染进模板文件中，最终生成一个可以部署的Kubernetes YAML格式的资源定义文件，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/ff/86/ffcc4eaf4071e19e2e0d317b1c536486.png?wh=1920x936\" alt=\"图片\"></p><p>上图中，我们将以下配置渲染进了模板中，生成了Kubernetes YAML文件：</p><pre><code class=\"language-yaml\">replicas: 2\ntag: latest\ncommon:\n    username: colin\n    password: iam1234\n</code></pre><p>所以在Helm中，部署一个应用可以简化为<code>Chart模板（多个服务） + Chart配置 -&gt; 应用</code>，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/bb/6b/bb87b8562102525d4c2yy0b0314ac46b.jpg?wh=1920x995\" alt=\"图片\"></p><p>Chart模板一个应用只用编写一次，可以重复使用。在部署时，可以指定不同的配置，从而将应用部署在不同的环境中，或者在同一环境中部署不同配置的应用。</p><h2>Helm 基本操作实战</h2><p>上面，我介绍了Helm的一些基础知识，这里我们再来学习下如何使用Helm对应用进行生命周期管理。</p><h3>前置条件</h3><p>在开始之前，你需要确保你有一个可以使用的Kubernetes集群。目前最方便快捷、最经济的方式是申请一个腾讯云EKS集群。至于如何申请和访问，你可以参考 <a href=\"https://time.geekbang.org/column/article/418711\">48讲</a> “准备一个Kubernetes集群”部分的教程。这里再提醒下，<strong>用完集群后，记得删除集群资源，免得被持续扣费</strong>。</p><h3>安装Helm</h3><p>Helm提供了多种安装方式，在能连通外网的情况下，可以通过脚本来安装，安装命令如下：</p><pre><code class=\"language-bash\">$ mkdir -p $HOME/bin\n$ wget https://get.helm.sh/helm-v3.6.3-linux-amd64.tar.gz\n$ tar -xvzf helm-v3.6.3-linux-amd64.tar.gz\n$ mv linux-amd64/helm $HOME/bin\n$ chmod +x $HOME/bin/helm\n$ helm version\nversion.BuildInfo{Version:\"v3.6.3\", GitCommit:\"d506314abfb5d21419df8c7e7e68012379db2354\", GitTreeState:\"clean\", GoVersion:\"go1.16.5\"}\n</code></pre><p>如果执行<code>helm version</code>可以成功打印出 <code>helm</code> 命令的版本号，说明Helm安装成功。</p><p>Helm各版本安装包地址见 <a href=\"https://github.com/helm/helm/releases\">Helm Releases</a>。</p><p>安装完<code>helm</code>命令后，可以安装<code>helm</code>命令的自动补全脚本。假如你用的shell是<code>bash</code>，安装方法如下：</p><pre><code class=\"language-bash\">$ helm completion bash &gt; $HOME/.helm-completion.bash\n$ echo 'source $HOME/.helm-completion.bash' &gt;&gt; ~/.bashrc\n$ bash\n</code></pre><p>执行 <code>helm comp&lt;TAB&gt;</code>，就会自动补全为<code>helm completion</code>。</p><h3>Helm快速入门</h3><p>你可以通过以下六个步骤，来快速创建一个Chart应用。</p><p><strong>第一步，初始化一个Helm Chart仓库。</strong></p><p>安装完Helm之后，就可以使用 <code>helm</code> 命令添加一个Chart仓库。类似于用来托管Docker镜像的DockerHub、用来托管代码的GitHub，Chart包也有一个托管平台，当前比较流行的Chart包托管平台是<a href=\"https://artifacthub.io/packages/search?kind=0\">Artifact Hub</a>。</p><p>Artifact Hub上有很多Chart仓库，我们可以添加需要的Chart仓库，这里我们添加BitNami提供的Chart仓库：</p><pre><code class=\"language-bash\">$ helm repo add bitnami https://charts.bitnami.com/bitnami # 添加 Chart Repository\n$ helm repo list # 查看添加的 Repository 列表\n</code></pre><p>添加完成后，我们可以通过<code>helm search</code>命令，来查询需要的Chart包。<code>helm search</code>支持两种不同的查询方式，这里我来介绍下。</p><ul>\n<li><code>helm search repo&lt;keyword&gt;</code>：从你使用 <code>helm repo add</code> 添加到本地 Helm 客户端中的仓库里查找。该命令基于本地数据进行搜索，无需连接外网。</li>\n<li><code>helm search hub&lt;keyword&gt;</code>：从 Artifact Hub 中查找并列出 Helm Charts。 Artifact Hub中存放了大量的仓库。</li>\n</ul><p>Helm 搜索使用模糊字符串匹配算法，所以你可以只输入名字的一部分。下面是一个<code>helm search</code>的示例：</p><pre><code class=\"language-bash\">$ helm search repo bitnami\nNAME                                        \tCHART VERSION\tAPP VERSION  \tDESCRIPTION\nbitnami/bitnami-common                      \t0.0.9        \t0.0.9        \tDEPRECATED Chart with custom templates used in ...\nbitnami/airflow                             \t10.2.8       \t2.1.2        \tApache Airflow is a platform to programmaticall...\nbitnami/apache                              \t8.6.1        \t2.4.48       \tChart for Apache HTTP Server\nbitnami/argo-cd                             \t1.0.2        \t2.0.5        \tDeclarative, GitOps continuous delivery tool fo...\nbitnami/aspnet-core                         \t1.3.14       \t3.1.18       \tASP.NET Core is an open-source framework create...\nbitnami/cassandra                           \t8.0.2        \t4.0.0        \tApache Cassandra is a free and open-source dist...\nbitnami/cert-manager                        \t0.1.15       \t1.5.1        \tCert Manager is a Kubernetes add-on to automate...\n# ... and many more\n</code></pre><p><strong>第二步，安装一个示例Chart。</strong></p><p>查询到自己需要的Helm Chart后，就可以通过<code>helm install</code>命令来安装一个Chart。<code>helm install</code>支持从多种源进行安装：</p><ul>\n<li>Chart的Repository。</li>\n<li>本地的Chart Archive，例如<code>helm install foo foo-1.0.0.tgz</code>。</li>\n<li>一个未打包的Chart路径，例如<code>helm install foo path/to/foo</code>。</li>\n<li>一个完整的URL，例如<code>helm install foo https://example.com/charts/foo-1.0.0.tgz</code>。</li>\n</ul><p>这里，我们选择通过<code>bitnami/mysql</code> Chart包来安装一个MySQL应用。你可以执行 <code>helm show chart bitnami/mysql</code> 命令，来简单了解这个Chart的基本信息。 或者，你也可以执行 <code>helm show all bitnami/mysql</code>，获取关于该Chart的所有信息。</p><p>接下来，就可以使用<code>helm install</code>命令来安装这个Chart包了。安装命令如下：</p><pre><code class=\"language-bash\">$ helm repo update              # Make sure we get the latest list of charts\n$ helm install bitnami/mysql --generate-name\nNAME: mysql-1629528555\nLAST DEPLOYED: Sat Aug 21 14:49:19 2021\nNAMESPACE: default\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\nNOTES: ...\n</code></pre><p>在上面的例子中，我们通过安装<code>bitnami/mysql</code>这个Chart，创建了一个<code>mysql-1629528555</code> Release。<code>--generate-name</code>参数告诉Helm自动为这个Release命名。</p><p>在安装过程中，Helm 客户端会打印一些有用的信息，包括哪些资源已经被创建，Release当前的状态，以及你是否还需要执行额外的配置步骤。例如，从上述例子的输出中，你可以获取到数据库的Root密码、登陆方式、更新方式等信息。</p><p>安装完之后，你可以使用 <code>helm status</code> 来追踪Release 的状态。</p><p>每当你执行 <code>helm install</code> 的时候，都会创建一个新的发布版本。所以一个Chart在同一个集群里面可以被安装多次，每一个都可以被独立地管理和升级。</p><p><code>helm install</code>命令会将templates渲染成最终的Kubernetes能够识别的YAML格式，然后安装到Kubernetes集群中。</p><p><code>helm install</code> 功能非常强大，想了解更多功能，你可以参考这个指南：<a href=\"https://helm.sh/zh/docs/intro/using_helm\">使用 Helm</a>。</p><p><strong>第三步，安装前自定义 Chart。</strong></p><p>上一步中的安装方式只会使用 Chart 的默认配置选项，很多时候我们需要自定义 Chart 来指定我们想要的配置。使用 <code>helm show values</code> 可以查看 Chart 中的可配置选项：</p><pre><code class=\"language-bash\">$ helm show values bitnami/mysql # 为了方便展示，我删除了 `helm show values`输出中的`#`注释\n# ... and many more\narchitecture: standalone\nauth:\n  rootPassword: \"\"\n  database: my_database\n  username: \"\"\n  password: \"\"\n  replicationUser: replicator\n  replicationPassword: \"\"\n  existingSecret: \"\"\n  forcePassword: false\n  usePasswordFiles: false\n  customPasswordFiles: {}\ninitdbScripts: {}\n# ... and many more\n</code></pre><p>然后，你可以使用 YAML 格式的文件，覆盖上述任意配置项，并在安装过程中使用该文件。</p><pre><code class=\"language-bash\">$ echo '{auth.database: iam, auth.username: iam, auth.password: iam59!z$}' &gt; values.yaml\n$ helm install bitnami/mysql -f values.yaml --generate-name\n</code></pre><p>上述命令将为 MySQL 创建一个名称为 <code>iam</code> 的默认用户，密码为<code>iam59!z$</code>，并且授予该用户访问新建的 <code>iam</code> 数据库的权限。Chart 中的其他默认配置保持不变。</p><p>安装过程中，有两种传递配置数据的方式。</p><ul>\n<li><code>-f, --values</code>：使用 YAML 文件覆盖配置。可以指定多次，优先使用最右边的文件。</li>\n<li><code>--set</code>：通过命令行的方式对指定配置项进行覆盖。</li>\n</ul><p>如果同时使用两种方式，则 <code>--set</code> 中的值会被合并到 <code>--values</code> 中，但是 <code>--set</code> 中的值优先级更高。在<code>--set</code>中覆盖的内容会被保存在 ConfigMap 中。你可以通过 <code>helm get values &lt;release-name&gt;</code> 来查看指定 Release 中 <code>--set</code> 设置的值，也可以通过运行 <code>helm upgrade</code> 并指定 <code>--reset-values</code> 字段，来清除 <code>--set</code>中设置的值。</p><p><strong>这里我讲解下<code>--set</code>的格式和限制。</strong></p><p><code>--set</code> 选项使用<code>0</code>或多个<code>key-value</code> 对。最简单的用法类似于<code>--set name=value</code>，等价于下面这个 YAML 格式：</p><pre><code class=\"language-yaml\">name: value\n</code></pre><p>多个值之间使用逗号分割，因此<code>--set a=b,c=d</code> 的 YAML 表示是：</p><pre><code class=\"language-yaml\">a: b\nc: d\n</code></pre><p><code>--set</code>还支持更复杂的表达式。例如，<code>--set outer.inner=value</code> 被转换成了：</p><pre><code class=\"language-yaml\">outer:\n  inner: value\n</code></pre><p>列表使用花括号<code>{}</code>来表示。例如，<code>--set name={a, b, c}</code> 被转换成了：</p><pre><code class=\"language-yaml\">name:\n  - a\n  - b\n  - c\n</code></pre><p>从 2.5.0 版本开始，我们可以使用数组下标的语法来访问列表中的元素了。例如 <code>--set servers[0].port=80</code> 就变成了：</p><pre><code class=\"language-yaml\">servers:\n  - port: 80\n</code></pre><p>多个值也可以通过这种方式来设置。<code>--set servers[0] [0].host=``marmotedu</code> 变成了：</p><pre><code class=\"language-yaml\">servers:\n  - port: 80\n    host: marmotedu\n</code></pre><p>如果需要在 <code>--set</code> 中使用特殊字符，你可以使用反斜线来进行转义，比如<code>--set name=value1\\,value2</code> 就变成了：</p><pre><code class=\"language-yaml\">name: \"value1,value2\"\n</code></pre><p>如果是深层嵌套的数据结构，可能很难用<code>--set</code> 来表达，更多内容你可以参考 <a href=\"https://helm.sh/docs/chart_template_guide/values_files/\">Values 文件</a>。</p><p><strong>第四步，查看当前集群安装了哪些Release。</strong></p><p>通过<code>helm list</code>可以查看当前集群、当前Namespace下安装的Release列表：</p><pre><code class=\"language-bash\">$ helm list\nNAME            \tNAMESPACE\tREVISION\tUPDATED                                \tSTATUS  \tCHART      \tAPP VERSION\nmysql-1629528555\tdefault  \t1       \t2021-08-21 14:49:19.101935218 +0800 CST\tdeployed\tmysql-8.8.4\t8.0.26\nmysql-1629529348\tdefault  \t1       \t2021-08-21 15:02:32.079969128 +0800 CST\tdeployed\tmysql-8.8.4\t8.0.26\n</code></pre><p>可以看到，我们创建了两个Release，这些Release位于<code>default</code>命名空间中。上述命令，也列出了Release的更新时间、状态、Chart的版本等。</p><p><strong>第五步，升级 Release，并且在失败时恢复。</strong></p><p>部署完应用之后，后续还可能升级应用，可以通过<code>helm upgrade</code>命令来升级应用。升级操作会基于已有的Release，根据提供的信息进行升级。Helm在更新时，只会变更有更改的内容。</p><p>例如，这里我们升级<code>mysql-1629528555</code>，变更它的Root密码：</p><pre><code class=\"language-bash\">$ helm upgrade mysql-1629528555 bitnami/mysql --set auth.rootPassword='iam59!z$'\n</code></pre><p>在上面的例子中，<code>mysql-1629528555</code> 这个 Release 使用相同的 Chart 进行升级，但使用了一个新的<code>rootPassword</code>配置。</p><p>我们可以使用 <code>helm get values</code> 命令，来看看配置值是否真的生效了：</p><pre><code class=\"language-bash\">$ helm get values mysql-1629528555\nUSER-SUPPLIED VALUES:\nauth:\n  rootPassword: iam59!z$\n</code></pre><p>可以看到<code>rootPassword</code> 的新值已经被部署到集群中了。</p><p>假如发布失败，我们也很容易通过 <code>helm rollback [RELEASE] [REVISION]</code> 命令，回滚到之前的发布版本。</p><pre><code class=\"language-yaml\">$ helm rollback mysql-1629528555 1\n</code></pre><p>上面这条命令将我们的<code>mysql-1629528555</code>回滚到了它最初的版本。Release 版本其实是一个增量修订（revision）。 每当发生了一次安装、升级或回滚操作，revision 的值就会加<code>1</code>。第一次 revision 的值永远是<code>1</code>。</p><p>我们可以使用 <code>helm history [RELEASE]</code> 命令来查看一个特定 Release 的修订版本号：</p><pre><code class=\"language-bash\">$ helm history mysql-1629528555\nREVISION\tUPDATED                 \tSTATUS    \tCHART      \tAPP VERSION\tDESCRIPTION\n1       \tSat Aug 21 14:49:19 2021\tsuperseded\tmysql-8.8.4\t8.0.26     \tInstall complete\n2       \tSat Aug 21 15:14:45 2021\tdeployed  \tmysql-8.8.4\t8.0.26     \tUpgrade complete\n</code></pre><p>你还可以指定一些其他的选项，来自定义 Helm 在安装、升级、回滚期间的行为。这里，我介绍一些常用的参数，供你参考。</p><ul>\n<li><code>--timeout</code>：一个 Go duration 类型的值，用来表示等待 Kubernetes 命令完成的超时时间，默认值为 <code>5m0s</code>。</li>\n<li><code>--no-hooks</code>：不运行当前命令的钩子。</li>\n<li><code>--wait</code>：表示必须要等到所有的 Pods 都处于 ready 状态、PVC 都被绑定、Deployments处在 ready 状态的Pods 个数达到最小值（Desired减去 maxUnavailable），才会标记该 Release 为成功。最长等待时间由 <code>--timeout</code> 值指定。如果达到超时时间，Release 将被标记为 <code>FAILED</code>。</li>\n</ul><p>这里需要注意，当 Deployment 的 replicas 被设置为1，但其滚动升级策略中的<code>maxUnavailable</code> 没有被设置为<code>0</code>时，<code>--wait</code> 将返回就绪，因为已经满足了最小 ready Pod 数。</p><p><strong>第六步，卸载Release。</strong></p><p>你可以使用<code>helm uninstall</code>命令卸载一个Release：</p><pre><code class=\"language-bash\">$ helm  uninstall mysql-1629528555\n</code></pre><p>上述命令会从Kubernetes卸载 <code>mysql-1629528555</code>， 它将删除和该版本关联的所有资源（Service、Deployment、Pod、ConfigMap等），包括该Release的所有版本历史。</p><p>如果你在执行 <code>helm uninstall</code> 的时候提供<code>--keep-history</code> 选项， Helm将会保存版本历史。 你可以通过<code>helm status</code>命令查看该版本的信息：</p><pre><code class=\"language-bash\">$ helm status mysql-1629528555\nStatus: UNINSTALLED\n...\n</code></pre><p>因为 <code>--keep-history</code> 选项会让Helm跟踪你的版本（即使你卸载了它们），所以你可以审计集群历史，甚至使用 <code>helm rollback</code> 回滚版本。</p><h3>Helm命令</h3><p>上面我介绍了Helm的一些命令的用法，如果你想查看Helm提供的所有命令，可以执行<code>helm help</code>。或者，你也可以执行<code>helm &lt;subcommand&gt; -h</code>来查看某个子命令的用法，例如：</p><pre><code class=\"language-bash\">$ helm get -h\n\nThis command consists of multiple subcommands which can be used to\nget extended information about the release, including:\n\n- The values used to generate the release\n- The generated manifest file\n- The notes provided by the chart of the release\n- The hooks associated with the release\n\nUsage:\n  helm get [command]\n# ... and many more\n</code></pre><p>我整理了一份命令列表，供你参考：</p><p><img src=\"https://static001.geekbang.org/resource/image/c4/bb/c4fa82cf7bf7fc5c98314419b1e0febb.png?wh=1920x4212\" alt=\"图片\"></p><p>上面这些命令中，有些提供了子命令和命令行参数，具体你可以执行<code>helm &lt;subcommand&gt; -h</code>来查看。</p><h2>总结</h2><p>今天，我介绍了Helm的基础知识，并给你演示了如何基于Helm部署IAM应用。</p><p>当一个应用包含了很多微服务时，手动在Kubernetes集群中部署、升级、回滚这些微服务是一件非常复杂的工作。这时候，我们就需要一个服务编排方案来编排这些服务，从而提高服务部署和维护的效率。</p><p>目前业界提供了多种服务编排方案，其中最流行的是Helm，Helm已经成为一个事实上的Kubernetes服务编排标准。</p><p>在Helm中，有Chart、Repository和Release三大基本概念。Chart 代表一个Helm包，里面包含了运行Kubernetes应用需要的所有资源定义YAML文件；Repository是Chart仓库，用来存放和共享 Helm Chart；Release是运行在 Kubernetes 集群中的 Chart 的实例。</p><p>我们可以通过&nbsp; <code>helm install [NAME] [CHART] [flags]</code> 来安装一个Chart包；通过 <code>helm upgrade [RELEASE] [CHART] [flags]</code> 来更新一个Helm Release；通过 <code>helm uninstall RELEASE_NAME [...] [flags]</code> 来卸载一个Helm Release。另外，<code>helm</code> 命令行工具还提供了其他的功能，你可以再回顾一遍。</p><h2>课后练习</h2><ol>\n<li>思考下，如果使用Helm创建服务，是否会存在先启动服务，再创建服务配置，从而导致服务启动时加载配置失败的问题？如果有，Helm可以怎样解决这个问题？</li>\n<li>尝试将IAM应用制作成一个Chart包，并通过Helm安装。</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"48 | 基于腾讯云 EKS 的容器化部署实战","id":418711},"right":{"article_title":"50 | 服务编排（下）：基于Helm的服务编排部署实战","id":421843}}},{"article_id":421843,"article_title":"50 | 服务编排（下）：基于Helm的服务编排部署实战","article_content":"<p>你好，我是孔令飞。</p><p>上一讲，我介绍了 Helm 的基础知识，并带着你部署了一个简单的应用。掌握Helm的基础知识之后，今天我们就来实战下，一起通过Helm部署一个IAM应用。</p><p>通过Helm部署IAM应用，首先需要制作IAM Chart包，然后通过Chart包来一键部署IAM应用。在实际开发中，我们需要将应用部署在不同的环境中，所以我也会给你演示下如何在多环境中部署IAM应用。</p><h2>制作IAM Chart包</h2><p>在部署IAM应用之前，我们首先需要制作一个IAM Chart包。</p><p>我们假设IAM项目源码根目录为<code>${IAM_ROOT}</code>，进入 <code>${IAM_ROOT}/deployments</code>目录，在该目录下创建Chart包。具体创建流程分为四个步骤，下面我来详细介绍下。</p><p><strong>第一步，</strong>创建一个模板Chart。</p><p>Chart是一个组织在文件目录中的集合，目录名称就是Chart名称（没有版本信息）。你可以看看这个 <a href=\"https://helm.sh/zh/docs/topics/charts\">Chart 开发指南</a> ，它介绍了如何开发你自己的Chart。</p><p>不过，这里你也可以使用 <code>helm create</code> 命令来快速创建一个模板Chart，并基于该Chart进行修改，得到你自己的Chart。创建命令如下：</p><!-- [[[read_end]]] --><pre><code class=\"language-bash\">$ helm create iam\n</code></pre><p><code>helm create iam</code>会在当前目录下生成一个<code>iam</code>目录，里面存放的就是Chart文件。Chart目录结构及文件如下：</p><pre><code class=\"language-bash\">$ tree -FC iam/\n├── charts/                            # [可选]: 该目录中放置当前Chart依赖的其他Chart\n├── Chart.yaml                         # YAML文件，用于描述Chart的基本信息，包括名称版本等\n├── templates/                         # [可选]: 部署文件模版目录，模版使用的值来自values.yaml和由Tiller提供的值\n│&nbsp;&nbsp; ├── deployment.yaml                # Kubernetes Deployment object\n│&nbsp;&nbsp; ├── _helpers.tpl                   # 用于修改Kubernetes objcet配置的模板\n│&nbsp;&nbsp; ├── hpa.yaml                       # Kubernetes HPA object\n│&nbsp;&nbsp; ├── ingress.yaml                   # Kubernetes Ingress object\n│&nbsp;&nbsp; ├── NOTES.txt                      # [可选]: 放置Chart的使用指南\n│&nbsp;&nbsp; ├── serviceaccount.yaml\n│&nbsp;&nbsp; ├── service.yaml\n│&nbsp;&nbsp; └── tests/                         # 定义了一些测试资源\n│&nbsp;&nbsp;     └── test-connection.yaml\n└── values.yaml                        # Chart的默认配置文件\n</code></pre><p>上面的目录中，有两个比较重要的文件：</p><ul>\n<li>Chart.yaml 文件</li>\n<li>templates目录</li>\n</ul><p>下面我来详细介绍下这两个文件。<strong>我们先来看Chart.yaml 文件。</strong></p><p>Chart.yaml用来描述Chart的基本信息，包括名称、版本等，内容如下：</p><pre><code class=\"language-yaml\">apiVersion: Chart API 版本 （必需）\nname: Chart名称 （必需）\nversion: 语义化版本（必需）\nkubeVersion: 兼容Kubernetes版本的语义化版本（可选）\ndescription: 对这个项目的一句话描述（可选）\ntype: Chart类型 （可选）\nkeywords:\n  - 关于项目的一组关键字（可选）\nhome: 项目home页面的URL （可选）\nsources:\n  - 项目源码的URL列表（可选）\ndependencies: # chart 必要条件列表 （可选）\n  - name: Chart名称 (nginx)\n    version: Chart版本 (\"1.2.3\")\n    repository: （可选）仓库URL (\"https://example.com/charts\") 或别名 (\"@repo-name\")\n    condition: （可选） 解析为布尔值的YAML路径，用于启用/禁用Chart(e.g. subchart1.enabled )\n    tags: # （可选）\n      - 用于一次启用/禁用 一组Chart的tag\n    import-values: # （可选）\n      - ImportValue 保存源值到导入父键的映射。每项可以是字符串或者一对子/父列表项\n    alias: （可选） Chart中使用的别名。当你要多次添加相同的Chart时会很有用\nmaintainers: # （可选）\n  - name: 维护者名字 （每个维护者都需要）\n    email: 维护者邮箱 （每个维护者可选）\n    url: 维护者URL （每个维护者可选）\nicon: 用作icon的SVG或PNG图片URL （可选）\nappVersion: 包含的应用版本（可选）。不需要是语义化，建议使用引号\ndeprecated: 不被推荐的Chart（可选，布尔值）\nannotations:\n  example: 按名称输入的批注列表 （可选）.\n</code></pre><p><strong>我们再来看下<strong><strong>templates目录</strong></strong>这个文件。</strong></p><p>templates目录中包含了应用中各个Kubernetes资源的YAML格式资源定义模板，例如：</p><pre><code class=\"language-yaml\">apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app: {{ .Values.pump.name }}\n  name: {{ .Values.pump.name }}\nspec:\n  ports:\n  - name: http\n    protocol: TCP\n    {{- toYaml .Values.pump.service.http| nindent 4 }}\n  selector:\n    app: {{ .Values.pump.name }}\n  sessionAffinity: None\n  type: {{ .Values.serviceType }}\n</code></pre><p><code>{{ .Values.pump.name }}</code>会被<code>deployments/iam/values.yaml</code>文件中<code>pump.name</code>的值替换。上面的模版语法扩展了 Go <code>text/template</code>包的语法：</p><pre><code class=\"language-yaml\"># 这种方式定义的模版，会去除test模版尾部所有的空行\n{{- define \"test\"}}\n模版内容\n{{- end}}\n\n# 去除test模版头部的第一个空行\n{{- template \"test\" }}\n</code></pre><p>下面是用于YAML文件前置空格的语法：</p><pre><code class=\"language-bash\"># 这种方式定义的模版，会去除test模版头部和尾部所有的空行\n{{- define \"test\" -}}\n模版内容\n{{- end -}}\n\n# 可以在test模版每一行的头部增加4个空格，用于YAML文件的对齐\n{{ include \"test\" | indent 4}}\n</code></pre><p>最后，这里有三点需要你注意：</p><ul>\n<li>Chart名称必须是小写字母和数字，单词之间可以使用横杠<code>-</code>分隔，Chart名称中不能用大写字母，也不能用下划线，<code>.</code>号也不行。</li>\n<li>尽可能使用<a href=\"https://semver.org/\">SemVer 2</a>来表示版本号。</li>\n<li>YAML 文件应该按照双空格的形式缩进(一定不要使用tab键)。</li>\n</ul><p><strong>第二步，</strong>编辑 <code>iam</code> 目录下的Chart文件。</p><p>我们可以基于<code>helm create</code>生成的模板Chart来构建自己的Chart包。这里我们添加了创建iam-apiserver、iam-authz-server、iam-pump、iamctl服务需要的YAML格式的Kubernetes资源文件模板：</p><pre><code class=\"language-bash\">$ ls -1 iam/templates/*.yaml\niam/templates/hpa.yaml                                   # Kubernetes HPA模板文件\niam/templates/iam-apiserver-deployment.yaml              # iam-apiserver服务deployment模板文件\niam/templates/iam-apiserver-service.yaml                 # iam-apiserver服务service模板文件\niam/templates/iam-authz-server-deployment.yaml           # iam-authz-server服务deployment模板文件\niam/templates/iam-authz-server-service.yaml              # iam-authz-server服务service模板文件\niam/templates/iamctl-deployment.yaml                     # iamctl服务deployment模板文件\niam/templates/iam-pump-deployment.yaml                   # iam-pump服务deployment模板文件\niam/templates/iam-pump-service.yaml                      # iam-pump服务service模板文件\n</code></pre><p>模板的具体内容，你可以查看<a href=\"https://github.com/marmotedu/iam/tree/v1.1.0/deployments/iam/templates\">deployments/iam/templates/</a>。</p><p>在编辑 Chart 时，我们可以通过 <code>helm lint</code> 验证格式是否正确，例如：</p><pre><code class=\"language-bash\">$ helm lint iam\n==&gt; Linting iam\n\n1 chart(s) linted, 0 chart(s) failed\n</code></pre><p><code>0 chart(s) failed</code> 说明当前Iam Chart包是通过校验的。</p><p><strong>第三步，</strong>修改Chart的配置文件，添加自定义配置。</p><p>我们可以编辑<code>deployments/iam/values.yaml</code>文件，定制自己的配置。具体配置你可以参考<a href=\"https://github.com/marmotedu/iam/blob/v1.1.0/deployments/iam/values.yaml\">deployments/iam/values.yaml</a>。</p><p>在修改 <code>values.yaml</code> 文件时，你可以参考下面这些最佳实践。</p><ul>\n<li>变量名称以小写字母开头，单词按驼峰区分，例如<code>chickenNoodleSoup</code>。</li>\n<li>给所有字符串类型的值加上引号。</li>\n<li>为了避免整数转换问题，将整型存储为字符串更好，并用 <code>{{ int $value }}</code> 在模板中将字符串转回整型。</li>\n<li><code>values.yaml</code>中定义的每个属性都应该文档化。文档字符串应该以它要描述的属性开头，并至少给出一句描述。例如：</li>\n</ul><pre><code class=\"language-yaml\"># serverHost is the host name for the webserver\nserverHost: example\n# serverPort is the HTTP listener port for the webserver\nserverPort: 9191\n</code></pre><p>这里需要注意，所有的Helm内置变量都以大写字母开头，以便与用户定义的value进行区分，例如<code>.Release.Name</code>、<code>.Capabilities.KubeVersion</code>。</p><p>为了安全，values.yaml中只配置Kubernetes资源相关的配置项，例如Deployment副本数、Service端口等。至于iam-apiserver、iam-authz-server、iam-pump、iamctl组件的配置文件，我们创建单独的ConfigMap，并在Deployment中引用。</p><p><strong>第四步，</strong>打包Chart，并上传到Chart仓库中。</p><p>这是一个可选步骤，可以根据你的实际需要来选择。如果想了解具体操作，你可以查看 <a href=\"https://helm.sh/zh/docs/topics/chart_repository\">Helm chart 仓库</a>获取更多信息。</p><p>最后，IAM应用的Chart包见<a href=\"https://github.com/marmotedu/iam/tree/v1.1.0/deployments/iam\">deployments/iam</a>。</p><h2>IAM Chart部署</h2><p>上面，我们制作了IAM应用的Chart包，接下来我们就使用这个Chart包来一键创建IAM应用。IAM Chart部署一共分为10个步骤，你可以跟着我一步步操作下。</p><p><strong>第一步，</strong>配置<code>scripts/install/environment.sh</code>。</p><p><code>scripts/install/environment.sh</code>文件中包含了各类自定义配置，你主要配置下面这些跟数据库相关的就可以，其他配置使用默认值。</p><ul>\n<li>MariaDB配置：environment.sh文件中以<code>MARIADB_</code>开头的变量。</li>\n<li>Redis配置：environment.sh文件中以<code>REDIS_</code>开头的变量。</li>\n<li>MongoDB配置：environment.sh文件中以<code>MONGO_</code>开头的变量。</li>\n</ul><p><strong>第二步，</strong>创建IAM应用的配置文件。</p><pre><code class=\"language-bash\">$ cd ${IAM_ROOT}\n$ make gen.defaultconfigs # 生成iam-apiserver、iam-authz-server、iam-pump、iamctl组件的默认配置文件\n$ make gen.ca # 生成 CA 证书\n</code></pre><p>上面的命令会将IAM的配置文件存放在目录<code>${IAM_ROOT}/_output/configs/</code>下。</p><p><strong>第三步，</strong>创建 <code>iam</code> 命名空间。</p><p>我们将IAM应用涉及到的各类资源都创建在<code>iam</code>命名空间中。将IAM资源创建在独立的命名空间中，不仅方便维护，还可以有效避免影响其他Kubernetes资源。</p><pre><code class=\"language-bash\">$ kubectl create namespace iam\n</code></pre><p><strong>第四步，</strong>将IAM各服务的配置文件，以ConfigMap资源的形式保存在Kubernetes集群中。</p><pre><code class=\"language-bash\">$ kubectl -n iam create configmap iam --from-file=${IAM_ROOT}/_output/configs/\n$ kubectl -n iam get configmap iam\nNAME   DATA   AGE\niam    4      13s\n</code></pre><p><strong>第五步，</strong>将IAM各服务使用的证书文件，以ConfigMap资源的形式保存在Kubernetes集群中。</p><pre><code class=\"language-bash\">$ kubectl -n iam create configmap iam-cert --from-file=${IAM_ROOT}/_output/cert\n$ kubectl -n iam get configmap iam-cert\nNAME       DATA   AGE\niam-cert   14     12s\n</code></pre><p><strong>第六步，</strong>创建镜像仓库访问密钥。</p><p>在准备阶段，我们开通了<a href=\"http://ccr.ccs.tencentyun.com\">腾讯云镜像仓库服务</a>，并创建了用户<code>10000099``xxxx</code>，密码为<code>iam59!z$</code>。</p><p>接下来，我们就可以创建docker-registry secret了。Kubernetes在下载Docker镜像时，需要docker-registry secret来进行认证。创建命令如下：</p><pre><code class=\"language-bash\">$ kubectl -n iam create secret docker-registry ccr-registry --docker-server=ccr.ccs.tencentyun.com --docker-username=10000099xxxx --docker-password='iam59!z$'\n</code></pre><p><strong>第七步，</strong>创建Docker镜像，并Push到镜像仓库。</p><pre><code class=\"language-bash\">$ make push REGISTRY_PREFIX=ccr.ccs.tencentyun.com/marmotedu VERSION=v1.1.0\n</code></pre><p><strong>第八步，</strong>安装IAM Chart包。</p><p>在<a href=\"https://time.geekbang.org/column/article/420940\">49讲</a>里，我介绍了4种安装Chart包的方法。这里，我们通过未打包的IAM Chart路径来安装，安装方法如下：</p><pre><code class=\"language-bash\">$ cd ${IAM_ROOT}\n$ helm -n iam install iam deployments/iam\nNAME: iam\nLAST DEPLOYED: Sat Aug 21 17:46:56 2021\nNAMESPACE: iam\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\n</code></pre><p>执行 <code>helm install</code> 后，Kubernetes会自动部署应用，等到IAM应用的Pod都处在 <code>Running</code> 状态时，说明IAM应用已经成功安装：</p><pre><code class=\"language-bash\">$ kubectl -n iam get pods|grep iam\niam-apiserver-cb4ff955-hs827&nbsp; &nbsp; &nbsp; &nbsp; 1/1&nbsp; &nbsp; &nbsp;Running&nbsp; &nbsp;0&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 66s\niam-authz-server-7fccc7db8d-chwnn&nbsp; &nbsp;1/1&nbsp; &nbsp; &nbsp;Running&nbsp; &nbsp;0&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 66s\niam-pump-78b57b4464-rrlbf&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;1/1&nbsp; &nbsp; &nbsp;Running&nbsp; &nbsp;0&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 66s\niamctl-59fdc4995-xrzhn&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1/1&nbsp; &nbsp; &nbsp;Running&nbsp; &nbsp;0&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 66s\n</code></pre><p><strong>第九步，</strong>测试IAM应用。</p><p>我们通过<code>helm install</code>在<code>iam</code>命令空间下创建了一个测试Deployment <code>iamctl</code>。你可以登陆<code>iamctl</code> Deployment所创建出来的Pod，执行一些运维操作和冒烟测试。登陆命令如下：</p><pre><code class=\"language-bash\">$ kubectl -n iam exec -it `kubectl -n iam get pods -l app=iamctl | awk '/iamctl/{print $1}'` -- bash\n</code></pre><p>登陆到<code>iamctl-xxxxxxxxxx-xxxxx</code> Pod中后，你就可以执行运维操作和冒烟测试了。</p><p><strong>先来看运维操作。</strong>iamctl工具以子命令的方式对外提供功能，你可以使用它提供的各类功能，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/69/y2/693f608aa571cbfd6e06c8cfdb242yy2.png?wh=1920x337\" alt=\"图片\"></p><p><strong>再来看冒烟测试：</strong></p><pre><code class=\"language-bash\"># cd /opt/iam/scripts/install\n# ./test.sh iam::test::smoke\n</code></pre><p>如果<code>./test.sh iam::test::smoke</code>命令打印的输出中，最后一行为<code>congratulations, smoke test passed!</code>字符串，就说明IAM应用安装成功。如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/9d/8c/9dcc557952b3586f7b37b065bf2bd58c.png?wh=1920x314\" alt=\"图片\"></p><p><strong>第十步，</strong>销毁EKS集群的资源。</p><pre><code class=\"language-bash\">$ kubectl delete namespace iam\n</code></pre><p>你可以根据需要选择是否删除EKS集群，如果不需要了就可以选择删除。</p><h2>IAM应用多环境部署</h2><p>在实际的项目开发中，我们需要将IAM应用部署到不同的环境中，不同环境的配置文件是不同的，那么IAM项目是如何进行多环境部署的呢？</p><p>IAM项目在<a href=\"\">configs</a>目录下创建了多个Helm values文件（格式为<code>values-{envName}-env.yaml</code>）：</p><ul>\n<li>values-test-env.yaml，测试环境Helm values文件。</li>\n<li>values-pre-env.yaml，预发环境Helm values文件。</li>\n<li>values-prod-env.yaml，生产环境Helm values文件。</li>\n</ul><p>在部署IAM应用时，我们在命令行指定<code>-f</code>参数，例如：</p><pre><code class=\"language-bash\">$ helm -n iam install -f configs/values-test-env.yaml iam deployments/iam # 安装到测试环境。\n</code></pre><h2>总结</h2><p>这一讲，我们通过 <code>helm create iam</code> 创建了一个模板Chart，并基于这个模板Chart包进行了二次开发，最终创建了IAM应用的Helm Chart包：<a href=\"https://github.com/marmotedu/iam/tree/v1.1.0/deployments/iam\">deployments/iam</a>。</p><p>有了Helm Chart包，我们就可以通过 <code>helm -n iam install iam deployments/iam</code> 命令来一键部署好整个IAM应用。当IAM应用中的所有Pod都处在 <code>Running</code> 状态后，说明IAM应用被成功部署。</p><p>最后，我们可以登录iamctl容器，执行 <code>test.sh iam::test::smoke</code> 命令，来对IAM应用进行冒烟测试。</p><h2>课后练习</h2><ol>\n<li>试着在Helm Chart中加入MariaDB、MongoDB、Redis模板，通过Helm一键部署好整个IAM应用。</li>\n<li>试着通过 <code>helm</code> 命令升级、回滚和删除IAM应用。</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"49 | 服务编排（上）：Helm服务编排基础知识","id":420940},"right":{"article_title":"51 | 基于 GitHub Actions 的 CI 实战","id":422735}}},{"article_id":422735,"article_title":"51 | 基于 GitHub Actions 的 CI 实战","article_content":"<p>你好，我是孔令飞。这是本专栏正文的最后一讲了，恭喜你坚持到了最后！</p><p>在Go项目开发中，我们要频繁地执行静态代码检查、测试、编译、构建等操作。如果每一步我们都手动执行，效率低不说，还容易出错。所以，我们通常借助CI系统来自动化执行这些操作。</p><p>当前业界有很多优秀的CI系统可供选择，例如 <a href=\"https://circleci.com/\">CircleCI</a>、<a href=\"https://travis-ci.org/\">TravisCI</a>、<a href=\"https://github.com/jenkinsci/jenkins\">Jenkins</a>、<a href=\"https://coding.net/\">CODING</a>、<a href=\"https://github.com/features/actions\">GitHub Actions</a> 等。这些系统在设计上大同小异，为了减少你的学习成本，我选择了相对来说容易实践的GitHub Actions，来给你展示如何通过CI来让工作自动化。</p><p>这一讲，我会先介绍下GitHub Actions及其用法，再向你展示一个CI示例，最后给你演示下IAM是如何构建CI任务的。</p><h2>GitHub Actions的基本用法</h2><p>GitHub Actions是GitHub为托管在github.com站点的项目提供的持续集成服务，于2018年10月推出。</p><p>GitHub Actions具有以下功能特性：</p><ul>\n<li>提供原子的actions配置和组合actions的workflow配置两种能力。</li>\n<li>全局配置基于<a href=\"https://help.github.com/en/articles/migrating-github-actions-from-hcl-syntax-to-yaml-syntax\">YAML配置</a>，兼容主流CI/CD工具配置。</li>\n<li>Actions/Workflows基于<a href=\"https://help.github.com/en/articles/events-that-trigger-workflows\">事件触发</a>，包括Event restrictions、Webhook events、Scheduled events、External events。</li>\n<li>提供可供运行的托管容器服务，包括Docker、VM，可运行Linux、macOS、Windows主流系统。</li>\n<li>提供主流语言的支持，包括Node.js、Python、Java、Ruby、PHP、Go、Rust、.NET。</li>\n<li>提供实时日志流程，方便调试。</li>\n<li>提供<a href=\"https://help.github.com/en/articles/about-github-actions#discovering-actions-in-the-github-community\">平台内置的Actions</a>与第三方提供的Actions，开箱即用。</li>\n</ul><!-- [[[read_end]]] --><h3>GitHub Actions的基本概念</h3><p>在构建持续集成任务时，我们会在任务中心完成各种操作，比如克隆代码、编译代码、运行单元测试、构建和发布镜像等。GitHub把这些操作称为Actions。</p><p>Actions在很多项目中是可以共享的，GitHub允许开发者将这些可共享的Actions上传到<a href=\"https://github.com/marketplace?type=actions\">GitHub的官方Actions市场</a>，开发者在Actions市场中可以搜索到他人提交的 Actions。另外，还有一个 <a href=\"https://github.com/sdras/awesome-actions\">awesome actions</a> 的仓库，里面也有不少的Action可供开发者使用。如果你需要某个 Action，不必自己写复杂的脚本，直接引用他人写好的 Action 即可。整个持续集成过程，就变成了一个 Actions 的组合。</p><p>Action其实是一个独立的脚本，可以将Action存放在GitHub代码仓库中，通过<code>&lt;userName&gt;/&lt;repoName&gt;</code>的语法引用 Action。例如，<code>actions/checkout@v2</code>表示<code>https://github.com/actions/checkout</code>这个仓库，tag是v2。<code>actions/checkout@v2</code>也代表一个 Action，作用是安装 Go编译环境。GitHub 官方的 Actions 都放在 <a href=\"https://github.com/actions\">github.com/actions</a> 里面。</p><p>GitHub Actions 有一些自己的术语，下面我来介绍下。</p><ul>\n<li>workflow（工作流程）：一个  <code>.yml</code>  文件对应一个 workflow，也就是一次持续集成。一个 GitHub 仓库可以包含多个 workflow，只要是在  <code>.github/workflow</code>  目录下的  <code>.yml</code>  文件都会被 GitHub 执行。</li>\n<li>job（任务）：一个 workflow 由一个或多个 job 构成，每个 job 代表一个持续集成任务。</li>\n<li>step（步骤）：每个 job 由多个 step 构成，一步步完成。</li>\n<li>action（动作）：每个 step 可以依次执行一个或多个命令（action）。</li>\n<li>on：一个 workflow 的触发条件，决定了当前的 workflow 在什么时候被执行。</li>\n</ul><h3>workflow文件介绍</h3><p>GitHub Actions 配置文件存放在代码仓库的<code>.github/workflows</code>目录下，文件后缀为<code>.yml</code>，支持创建多个文件，文件名可以任意取，比如<code>iam.yml</code>。GitHub 只要发现<code>.github/workflows</code>目录里面有<code>.yml</code>文件，就会自动运行该文件，如果运行过程中存在问题，会以邮件的形式通知到你。</p><p>workflow 文件的配置字段非常多，如果你想详细了解，可以查看<a href=\"https://docs.github.com/cn/actions/reference/workflow-syntax-for-github-actions\">官方文档</a>。这里，我来介绍一些基本的配置字段。</p><ol>\n<li><code>name</code></li>\n</ol><p><code>name</code>字段是 workflow 的名称。如果省略该字段，默认为当前 workflow 的文件名。</p><pre><code class=\"language-yaml\">name: GitHub Actions Demo\n</code></pre><ol start=\"2\">\n<li><code>on</code></li>\n</ol><p><code>on</code>字段指定触发 workflow 的条件，通常是某些事件。</p><pre><code class=\"language-yaml\">on: push\n</code></pre><p>上面的配置意思是，<code>push</code>事件触发 workflow。<code>on</code>字段也可以是事件的数组，例如:</p><pre><code class=\"language-yaml\">on: [push, pull_request]\n</code></pre><p>上面的配置意思是，<code>push</code>事件或<code>pull_request</code>事件都可以触发 workflow。</p><p>想了解完整的事件列表，你可以查看<a href=\"https://docs.github.com/en/actions/reference/events-that-trigger-workflows\">官方文档</a>。除了代码库事件，GitHub Actions 也支持外部事件触发，或者定时运行。</p><ol start=\"3\">\n<li><code>on.&lt;push|pull_request&gt;.&lt;tags|branches&gt;</code></li>\n</ol><p>指定触发事件时，我们可以限定分支或标签。</p><pre><code class=\"language-yaml\">on:\n  push:\n    branches:\n      - master\n</code></pre><p>上面的配置指定，只有<code>master</code>分支发生<code>push</code>事件时，才会触发 workflow。</p><ol start=\"4\">\n<li><code>jobs.&lt;job_id&gt;.name</code></li>\n</ol><p>workflow 文件的主体是<code>jobs</code>字段，表示要执行的一项或多项任务。</p><p><code>jobs</code>字段里面，需要写出每一项任务的<code>job_id</code>，具体名称自定义。<code>job_id</code>里面的<code>name</code>字段是任务的说明。</p><pre><code class=\"language-yaml\">jobs:\n  my_first_job:\n    name: My first job\n  my_second_job:\n    name: My second job\n</code></pre><p>上面的代码中，<code>jobs</code>字段包含两项任务，<code>job_id</code>分别是<code>my_first_job</code>和<code>my_second_job</code>。</p><ol start=\"5\">\n<li><code>jobs.&lt;job_id&gt;.needs</code></li>\n</ol><p><code>needs</code>字段指定当前任务的依赖关系，即运行顺序。</p><pre><code class=\"language-yaml\">jobs:\n  job1:\n  job2:\n    needs: job1\n  job3:\n    needs: [job1, job2]\n</code></pre><p>上面的代码中，<code>job1</code>必须先于<code>job2</code>完成，而<code>job3</code>等待<code>job1</code>和<code>job2</code>完成后才能运行。因此，这个 workflow 的运行顺序为：<code>job1</code>、<code>job2</code>、<code>job3</code>。</p><ol start=\"6\">\n<li><code>jobs.&lt;job_id&gt;.runs-on</code></li>\n</ol><p><code>runs-on</code>字段指定运行所需要的虚拟机环境，它是必填字段。目前可用的虚拟机如下：</p><ul>\n<li>ubuntu-latest、ubuntu-18.04或ubuntu-16.04。</li>\n<li>windows-latest、windows-2019或windows-2016。</li>\n<li>macOS-latest或macOS-10.14。</li>\n</ul><p>下面的配置指定虚拟机环境为<code>ubuntu-18.04</code>。</p><pre><code class=\"language-yaml\">runs-on: ubuntu-18.04\n</code></pre><ol start=\"7\">\n<li><code>jobs.&lt;job_id&gt;.steps</code></li>\n</ol><p><code>steps</code>字段指定每个 Job 的运行步骤，可以包含一个或多个步骤。每个步骤都可以指定下面三个字段。</p><ul>\n<li><code>jobs.&lt;job_id&gt;.steps.name</code>：步骤名称。</li>\n<li><code>jobs.&lt;job_id&gt;.steps.run</code>：该步骤运行的命令或者 action。</li>\n<li><code>jobs.&lt;job_id&gt;.steps.env</code>：该步骤所需的环境变量。</li>\n</ul><p>下面是一个完整的 workflow 文件的范例：</p><pre><code class=\"language-yaml\">name: Greeting from Mona\non: push\n\njobs:\n  my-job:\n    name: My Job\n    runs-on: ubuntu-latest\n    steps:\n    - name: Print a greeting\n      env:\n        MY_VAR: Hello! My name is\n        FIRST_NAME: Lingfei\n        LAST_NAME: Kong\n      run: |\n        echo $MY_VAR $FIRST_NAME $LAST_NAME.\n</code></pre><p>上面的代码中，<code>steps</code>字段只包括一个步骤。该步骤先注入三个环境变量，然后执行一条 Bash 命令。</p><ol start=\"8\">\n<li><code>uses</code></li>\n</ol><p><code>uses</code> 可以引用别人已经创建的 actions，就是上面说的 actions 市场中的 actions。引用格式为<code>userName/repoName@verison</code>，例如<code>uses: actions/setup-go@v1</code>。</p><ol start=\"9\">\n<li><code>with</code></li>\n</ol><p><code>with</code> 指定actions的输入参数。每个输入参数都是一个键/值对。输入参数被设置为环境变量，该变量的前缀为 <code>INPUT_</code>，并转换为大写。</p><p>这里举个例子：我们定义 <code>hello_world</code> 操作所定义的三个输入参数（<code>first_name</code>、<code>middle_name</code> 和 <code>last_name</code>），这些输入变量将被 <code>hello-world</code> 操作作为 <code>INPUT_FIRST_NAME</code>、<code>INPUT_MIDDLE_NAME</code> 和 <code>INPUT_LAST_NAME</code> 环境变量使用。</p><pre><code class=\"language-yaml\">jobs:\n  my_first_job:\n    steps:\n      - name: My first step\n        uses: actions/hello_world@master\n        with:\n          first_name: Lingfei\n          middle_name: Go\n          last_name: Kong\n</code></pre><ol start=\"10\">\n<li><code>run</code></li>\n</ol><p><code>run</code>指定执行的命令。可以有多个命令，例如：</p><pre><code class=\"language-yaml\">- name: Build\n      run: |\n      go mod tidy\n      go build -v -o helloci .\n</code></pre><ol start=\"11\">\n<li><code>id</code></li>\n</ol><p><code>id</code>是step的唯一标识。</p><h2>GitHub Actions的进阶用法</h2><p>上面，我介绍了GitHub Actions的一些基本知识，这里我再介绍下GitHub Actions的进阶用法。</p><h3>为工作流加一个Badge</h3><p>在action的面板中，点击<code>Create status badge</code>就可以复制Badge的Markdown内容到README.md中。</p><p>之后，我们就可以直接在README.md中看到当前的构建结果：</p><p><img src=\"https://static001.geekbang.org/resource/image/45/af/453a97b0776281873dee5671c53347af.png?wh=1280x765\" alt=\"图片\"></p><h3>使用构建矩阵</h3><p>如果我们想在多个系统或者多个语言版本上测试构建，就需要设置构建矩阵。例如，我们想在多个操作系统、多个Go版本下跑测试，可以使用如下workflow配置：</p><pre><code class=\"language-yaml\">name: Go Test\n\non: [push, pull_request]\n\njobs:\n\n  helloci-build:\n    name: Test with go ${{ matrix.go_version }} on ${{ matrix.os }}\n    runs-on: ${{ matrix.os }}\n\n    strategy:\n      matrix:\n        go_version: [1.15, 1.16]\n        os: [ubuntu-latest, macOS-latest]\n\n    steps:\n\n      - name: Set up Go ${{ matrix.go_version }}\n        uses: actions/setup-go@v2\n        with:\n          go-version: ${{ matrix.go_version }}\n        id: go\n</code></pre><p>上面的workflow配置，通过<code>strategy.matrix</code>配置了该工作流程运行的环境矩阵（格式为<code>go_version.os</code>）：<code>ubuntu-latest.1.15</code>、<code>ubuntu-latest.1.16</code>、<code>macOS-latest.1.15</code>、<code>macOS-latest.1.16</code>。也就是说，会在4台不同配置的服务器上执行该workflow。</p><h3>使用Secrets</h3><p>在构建过程中，我们可能需要用到<code>ssh</code>或者<code>token</code>等敏感数据，而我们不希望这些数据直接暴露在仓库中，此时就可以使用<code>secrets</code>。</p><p>我们在对应项目中选择<code>Settings</code>-&gt; <code>Secrets</code>，就可以创建<code>secret</code>，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/c0/d3/c00b11a1709838c1a205ace7976768d3.png?wh=1920x1046\" alt=\"图片\"></p><p>配置文件中的使用方法如下：</p><pre><code class=\"language-yaml\">name: Go Test\non: [push, pull_request]\njobs:\n  helloci-build:\n    name: Test with go\n    runs-on: [ubuntu-latest]\n    environment:\n      name: helloci\n    steps:\n      - name: use secrets\n        env:\n          super_secret: ${{ secrets.YourSecrets }}\n</code></pre><p>secret name不区分大小写，所以如果新建secret的名字是name，使用时用 <code>secrets.name</code> 或者 <code>secrets.Name</code> 都是可以的。而且，就算此时直接使用 <code>echo</code> 打印 <code>secret</code> , 控制台也只会打印出<code>*</code>来保护secret。<br>\n这里要注意，你的secret是属于某一个环境变量的，所以要指明环境的名字：<code>environment.name</code>。上面的workflow配置中的<code>secrets.YourSecrets</code>属于<code>helloci</code>环境。</p><h3>使用Artifact保存构建产物</h3><p>在构建过程中，我们可能需要输出一些构建产物，比如日志文件、测试结果等。这些产物可以使用Github Actions Artifact 来存储。你可以使用<a href=\"https://github.com/actions/upload-artifact\">action/upload-artifact</a> 和 <a href=\"https://github.com/actions/download-artifact\">download-artifact</a> 进行构建参数的相关操作。</p><p>这里我以输出Jest测试报告为例来演示下如何保存Artifact产物。Jest测试后的测试产物是coverage：</p><pre><code class=\"language-yaml\">steps:\n      - run: npm ci\n      - run: npm test\n\n      - name: Collect Test Coverage File\n        uses: actions/upload-artifact@v1.0.0\n        with:\n          name: coverage-output\n          path: coverage\n</code></pre><p>执行成功后，我们就能在对应action面板看到生成的Artifact：</p><p><img src=\"https://static001.geekbang.org/resource/image/4c/66/4c4a8d6aec12a5dd1cdc80d238472566.png?wh=1280x208\" alt=\"图片\"></p><h2>GitHub Actions实战</h2><p>上面，我介绍了GitHub Actions的用法，接下来我们就来实战下，看下使用GitHub Actions的6个具体步骤。</p><p><strong>第一步，</strong>创建一个测试仓库。</p><p>登陆<a href=\"https://github.com/\">GitHub官网</a>，点击<strong>New repository</strong>创建，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/6d/a0/6d76d02f0418671a32f5346fccf616a0.png?wh=1920x810\" alt=\"图片\"></p><p>这里，我们创建了一个叫<code>helloci</code>的测试项目。</p><p><strong>第二步，</strong>将新的仓库 clone 下来，并添加一些文件：</p><pre><code class=\"language-bash\">$ git clone https://github.com/marmotedu/helloci\n</code></pre><p>你可以克隆<a href=\"https://github.com/marmotedu/helloci\">marmotedu/helloci</a>，并将里面的文件拷贝到你创建的项目仓库中。</p><p><strong>第三步，</strong>创建GitHub Actions workflow配置目录：</p><pre><code class=\"language-bash\">$ mkdir -p .github/workflows                     \n</code></pre><p><strong>第四步，</strong>创建GitHub Actions workflow配置。</p><p>在<code>.github/workflows</code>目录下新建<code>helloci.yml</code>文件，内容如下：</p><pre><code class=\"language-yaml\">name: Go Test\n\non: [push, pull_request]\n\njobs:\n\n  helloci-build:\n    name: Test with go ${{ matrix.go_version }} on ${{ matrix.os }}\n    runs-on: ${{ matrix.os }}\n    environment:\n      name: helloci\n\n    strategy:\n      matrix:\n        go_version: [1.16]\n        os: [ubuntu-latest]\n\n    steps:\n\n      - name: Set up Go ${{ matrix.go_version }}\n        uses: actions/setup-go@v2\n        with:\n          go-version: ${{ matrix.go_version }}\n        id: go\n\n      - name: Check out code into the Go module directory\n        uses: actions/checkout@v2\n\n      - name: Tidy\n        run: |\n          go mod tidy\n\n      - name: Build\n        run: |\n          go build -v -o helloci .\n\n      - name: Collect main.go file\n        uses: actions/upload-artifact@v1.0.0\n        with:\n          name: main-output\n          path: main.go\n\n      - name: Publish to Registry\n        uses: elgohr/Publish-Docker-GitHub-Action@master\n        with:\n          name: ccr.ccs.tencentyun.com/marmotedu/helloci:beta  # docker image 的名字\n          username: ${{ secrets.DOCKER_USERNAME}} # 用户名\n          password: ${{ secrets.DOCKER_PASSWORD }} # 密码\n          registry: ccr.ccs.tencentyun.com # 腾讯云Registry\n          dockerfile: Dockerfile # 指定 Dockerfile 的位置\n          tag_names: true # 是否将 release 的 tag 作为 docker image 的 tag\n</code></pre><p>上面的workflow文件定义了当GitHub仓库有<code>push</code>、<code>pull_request</code>事件发生时，会触发GitHub Actions工作流程，流程中定义了一个任务（Job）<code>helloci-build</code>，Job中包含了多个步骤（Step），每个步骤又包含一些动作（Action）。</p><p>上面的workflow配置会按顺序执行下面的6个步骤。</p><ol>\n<li>准备一个Go编译环境。</li>\n<li>从<a href=\"https://github.com/marmotedu/helloci\">marmotedu/helloci</a>下载源码。</li>\n<li>添加或删除缺失的依赖包。</li>\n<li>编译Go源码。</li>\n<li>上传构建产物。</li>\n<li>构建镜像，并将镜像push到<code>ccr.ccs.tencentyun.com/marmotedu/helloci:beta</code>。</li>\n</ol><p><strong>第五步，</strong>在push代码之前，我们需要先创建<code>DOCKER_USERNAME</code>和<code>DOCKER_PASSWORD</code> secret。</p><p>其中，<code>DOCKER_USERNAME</code>保存腾讯云镜像服务（CCR）的用户名，<code>DOCKER_PASSWORD</code>保存CCR的密码。我们将这两个secret保存在<code>helloci</code> Environments中，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/c0/d3/c00b11a1709838c1a205ace7976768d3.png?wh=1920x1046\" alt=\"图片\"></p><p><strong>第六步，</strong>将项目push到GitHub，触发workflow工作流：</p><pre><code class=\"language-bash\">$ git add .\n$ git push origin master\n</code></pre><p>打开我们的仓库 Actions 标签页，可以发现GitHub Actions workflow正在执行：</p><p><img src=\"https://static001.geekbang.org/resource/image/1a/8a/1afb7860d68635c5e3eaba4ff8da208a.png?wh=1920x691\" alt=\"图片\"></p><p>等workflow执行完，点击 <strong>Go Test</strong> 进入构建详情页面，在详情页面能够看到我们的构建历史：</p><p><img src=\"https://static001.geekbang.org/resource/image/a4/95/a4b83a122379db4f2fe9538afdfb5a95.png?wh=1920x701\" alt=\"图片\"></p><p>然后，选择其中一个构建记录，查看其运行详情（具体可参考<a href=\"https://github.com/marmotedu/helloci/actions/runs/1144156183\">chore: update step name Go Test #10</a>）：</p><p><img src=\"https://static001.geekbang.org/resource/image/48/4f/481f64aabccf30ed61d0a7c85ab30d4f.png?wh=1920x1084\" alt=\"图片\"></p><p>你可以看到，<code>Go Test</code>工作流程执行了6个Job，每个Job执行了下面这些自定义Step：</p><ol>\n<li>Set up Go 1.16。</li>\n<li>Check out code into the Go module directory。</li>\n<li>Tidy。</li>\n<li>Build。</li>\n<li>Collect main.go file。</li>\n<li>Publish to Registry。</li>\n</ol><p>其他步骤是GitHub Actions自己添加的步骤：<code>Setup Job</code>、<code>Post Check out code into the Go module directory</code>、<code>Complete job</code>。点击每一个步骤，你都能看到它们的详细输出。</p><h2>IAM GitHub Actions实战</h2><p>接下来，我们再来看下IAM项目的GitHub Actions实战。</p><p>假设IAM项目根目录为 <code>${IAM_ROOT}</code>，它的workflow配置文件为：</p><pre><code class=\"language-bash\">$ cat ${IAM_ROOT}/.github/workflows/iamci.yaml\nname: IamCI\n\non:\n  push:\n    branchs:\n    - '*'\n  pull_request:\n    types: [opened, reopened]\n\njobs:\n\n  iamci:\n    name: Test with go ${{ matrix.go_version }} on ${{ matrix.os }}\n    runs-on: ${{ matrix.os }}\n    environment:\n      name: iamci\n\n    strategy:\n      matrix:\n        go_version: [1.16]\n        os: [ubuntu-latest]\n\n    steps:\n\n      - name: Set up Go ${{ matrix.go_version }}\n        uses: actions/setup-go@v2\n        with:\n          go-version: ${{ matrix.go_version }}\n        id: go\n\n      - name: Check out code into the Go module directory\n        uses: actions/checkout@v2\n\n      - name: Run go modules Tidy\n        run: |\n          make tidy\n\n      - name: Generate all necessary files, such as error code files\n        run: |\n          make gen\n\n      - name: Check syntax and styling of go sources\n        run: |\n          make lint\n\n      - name: Run unit test and get test coverage\n        run: |\n          make cover\n\n      - name: Build source code for host platform\n        run: |\n          make build\n\n      - name: Collect Test Coverage File\n        uses: actions/upload-artifact@v1.0.0\n        with:\n          name: main-output\n          path: _output/coverage.out\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v1\n\n      - name: Login to DockerHub\n        uses: docker/login-action@v1\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n      - name: Build docker images for host arch and push images to registry\n        run: |\n          make push\n</code></pre><p>上面的workflow依次执行了以下步骤：</p><ol>\n<li>设置Go编译环境。</li>\n<li>下载IAM项目源码。</li>\n<li>添加/删除不需要的Go包。</li>\n<li>生成所有的代码文件。</li>\n<li>对IAM源码进行静态代码检查。</li>\n<li>运行单元测试用例，并计算单元测试覆盖率是否达标。</li>\n<li>编译代码。</li>\n<li>收集构建产物<code>_output/coverage.out</code>。</li>\n<li>配置Docker构建环境。</li>\n<li>登陆DockerHub。</li>\n<li>构建Docker镜像，并push到DockerHub。</li>\n</ol><p>IamCI workflow运行历史如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/2b/b0/2b542f9101be0c3a83576fb99bf882b0.png?wh=1920x844\" alt=\"图片\"></p><p>IamCI workflow的其中一次工作流程运行结果如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/e9/6a/e9ebf13fdb6e4f41a1b00406e646ec6a.png?wh=1920x887\" alt=\"图片\"></p><h2>总结</h2><p>在Go项目开发中，我们需要通过CI任务来将需要频繁操作的任务自动化，这不仅可以提高开发效率，还能减少手动操作带来的失误。这一讲，我选择了最易实践的GitHub Actions，来给你演示如何构建CI任务。</p><p>GitHub Actions支持通过push事件来触发CI流程。一个CI流程其实就是一个workflow，workflow中包含多个任务，这些任务是可以并行执行的。一个任务又包含多个步骤，每一步又由多个动作组成。动作（Action）其实是一个命令/脚本，用来完成我们指定的任务，如编译等。</p><p>因为GitHub Actions内容比较多，这一讲只介绍了一些核心的知识，更详细的GitHub Actions教程，你可以参考 <a href=\"https://docs.github.com/cn/actions\">官方中文文档</a>。</p><h2>课后练习</h2><ol>\n<li>使用CODING实现IAM的CI任务，并思考下：GitHub Actions和CODING在CI任务构建上，有没有本质的差异？</li>\n<li>这一讲，我们借助GitHub Actions实现了CI，请你结合前面所学的知识，实现IAM的CD功能。欢迎提交Pull Request。</li>\n</ol><p>这是我们这门课的最后一次练习题了，欢迎把你的思考和想法分享在留言区，也欢迎把课程分享给你的同事、朋友，我们一起交流，一起进步。</p>","neighbors":{"left":{"article_title":"50 | 服务编排（下）：基于Helm的服务编排部署实战","id":421843},"right":{"article_title":"特别放送 | 给你一份清晰、可直接套用的Go编码规范","id":385440}}},{"article_id":385440,"article_title":"特别放送 | 给你一份清晰、可直接套用的Go编码规范","article_content":"<p>你好，我是孔令飞。</p><p>我们在上一讲学习了“写出优雅Go项目的方法论”，那一讲内容很丰富，是我多年Go项目开发的经验沉淀，需要你多花一些时间好好消化吸收。吃完大餐之后，咱们今天来一期特别放送，就是上一讲我提到过的编码规范。这一讲里，为了帮你节省时间和精力，我会给你一份清晰、可直接套用的 Go 编码规范，帮助你编写一个高质量的 Go 应用。</p><p>这份规范，是我参考了Go官方提供的编码规范，以及Go社区沉淀的一些比较合理的规范之后，加入自己的理解总结出的，它比很多公司内部的规范更全面，你掌握了，以后在面试大厂的时候，或者在大厂里写代码的时候，都会让人高看你一眼，觉得你code很专业。</p><p>这份编码规范中包含代码风格、命名规范、注释规范、类型、控制结构、函数、GOPATH 设置规范、依赖管理和最佳实践九类规范。如果你觉得这些规范内容太多了，看完一遍也记不住，这完全没关系。你可以多看几遍，也可以在用到时把它翻出来，在实际应用中掌握。这篇特别放送的内容，更多是作为写代码时候的一个参考手册。</p><h2>1. 代码风格</h2><h3>1.1 代码格式</h3><ul>\n<li>\n<p>代码都必须用 <code>gofmt</code> 进行格式化。</p>\n</li>\n<li>\n<p>运算符和操作数之间要留空格。</p>\n</li>\n<li>\n<p>建议一行代码不超过120个字符，超过部分，请采用合适的换行方式换行。但也有些例外场景，例如import行、工具自动生成的代码、带tag的struct字段。</p>\n</li>\n<li>\n<p>文件长度不能超过800行。</p>\n</li>\n<li>\n<p>函数长度不能超过80行。</p>\n</li>\n<li>\n<p>import规范</p>\n<ul>\n<li>代码都必须用 goimports进行格式化（建议将代码Go代码编辑器设置为：保存时运行 goimports）。<br>\n- 不要使用相对路径引入包，例如 import …/util/net 。<br>\n- 包名称与导入路径的最后一个目录名不匹配时，或者多个相同包名冲突时，则必须使用导入别名。</li>\n</ul>\n</li>\n</ul><!-- [[[read_end]]] --><pre><code>// bad\n\t&quot;github.com/dgrijalva/jwt-go/v4&quot;\n\n\t//good\n\tjwt &quot;github.com/dgrijalva/jwt-go/v4&quot;\n</code></pre><ul style=\"list-style: none;\">\n   <li>\n      <ul>\n<li style=\"margin-left: 23px; padding-left: 17px\">导入的包建议进行分组，匿名包的引用使用一个新的分组，并对匿名包引用进行说明。</li>\n      </ul>\n   </li>\n</ul><pre><code>\timport (\n\t\t// go 标准包\n\t\t&quot;fmt&quot;\n\n\t\t// 第三方包\n\t    &quot;github.com/jinzhu/gorm&quot;\n\t    &quot;github.com/spf13/cobra&quot;\n\t    &quot;github.com/spf13/viper&quot;\n\n\t\t// 匿名包单独分组，并对匿名包引用进行说明\n\t    // import mysql driver\n\t    _ &quot;github.com/jinzhu/gorm/dialects/mysql&quot;\n\n\t\t// 内部包\n\t    v1 &quot;github.com/marmotedu/api/apiserver/v1&quot;\n\t    metav1 &quot;github.com/marmotedu/apimachinery/pkg/meta/v1&quot;\n\t    &quot;github.com/marmotedu/iam/pkg/cli/genericclioptions&quot;\n\t)\n</code></pre><h3>1.2 声明、初始化和定义</h3><ul>\n<li>当函数中需要使用到多个变量时，可以在函数开始处使用var声明。在函数外部声明必须使用 <code>var</code> ，不要采用 <code>:=</code> ，容易踩到变量的作用域的问题。</li>\n</ul><pre><code>var (\n\tWidth  int\n\tHeight int\n)\n</code></pre><ul>\n<li>在初始化结构引用时，请使用&amp;T{}代替new(T)，以使其与结构体初始化一致。</li>\n</ul><pre><code>// bad\nsptr := new(T)\nsptr.Name = &quot;bar&quot;\n\n// good\nsptr := &amp;T{Name: &quot;bar&quot;}\n</code></pre><ul>\n<li>struct 声明和初始化格式采用多行，定义如下。</li>\n</ul><pre><code>type User struct{\n    Username  string\n    Email     string\n}\n\nuser := User{\n\tUsername: &quot;colin&quot;,\n\tEmail: &quot;colin404@foxmail.com&quot;,\n}\n</code></pre><ul>\n<li>相似的声明放在一组，同样适用于常量、变量和类型声明。</li>\n</ul><pre><code>// bad\nimport &quot;a&quot;\nimport &quot;b&quot;\n\n// good\nimport (\n  &quot;a&quot;\n  &quot;b&quot;\n)\n</code></pre><ul>\n<li>尽可能指定容器容量，以便为容器预先分配内存，例如：</li>\n</ul><pre><code>v := make(map[int]string, 4)\nv := make([]string, 0, 4)\n</code></pre><ul>\n<li>在顶层，使用标准var关键字。请勿指定类型，除非它与表达式的类型不同。</li>\n</ul><pre><code>// bad\nvar _s string = F()\n\nfunc F() string { return &quot;A&quot; }\n\n// good\nvar _s = F()\n// 由于 F 已经明确了返回一个字符串类型，因此我们没有必要显式指定_s 的类型\n// 还是那种类型\n\nfunc F() string { return &quot;A&quot; }\n</code></pre><ul>\n<li>对于未导出的顶层常量和变量，使用_作为前缀。</li>\n</ul><pre><code>// bad\nconst (\n  defaultHost = &quot;127.0.0.1&quot;\n  defaultPort = 8080\n)\n\n// good\nconst (\n  _defaultHost = &quot;127.0.0.1&quot;\n  _defaultPort = 8080\n)\n</code></pre><ul>\n<li>嵌入式类型（例如 mutex）应位于结构体内的字段列表的顶部，并且必须有一个空行将嵌入式字段与常规字段分隔开。</li>\n</ul><pre><code>// bad\ntype Client struct {\n  version int\n  http.Client\n}\n\n// good\ntype Client struct {\n  http.Client\n\n  version int\n}\n</code></pre><h3>1.3 错误处理</h3><ul>\n<li><code>error</code>作为函数的值返回，必须对<code>error</code>进行处理，或将返回值赋值给明确忽略。对于<code>defer xx.Close()</code>可以不用显式处理。</li>\n</ul><pre><code>func load() error {\n\t// normal code\n}\n\n// bad\nload()\n\n// good\n _ = load()\n</code></pre><ul>\n<li><code>error</code>作为函数的值返回且有多个返回值的时候，<code>error</code>必须是最后一个参数。</li>\n</ul><pre><code>// bad\nfunc load() (error, int) {\n\t// normal code\n}\n\n// good\nfunc load() (int, error) {\n\t// normal code\n}\n</code></pre><ul>\n<li>尽早进行错误处理，并尽早返回，减少嵌套。</li>\n</ul><pre><code>// bad\nif err != nil {\n\t// error code\n} else {\n\t// normal code\n}\n\n// good\nif err != nil {\n\t// error handling\n\treturn err\n}\n// normal code\n</code></pre><ul>\n<li>如果需要在 if 之外使用函数调用的结果，则应采用下面的方式。</li>\n</ul><pre><code>// bad\nif v, err := foo(); err != nil {\n\t// error handling\n}\n\n// good\nv, err := foo()\nif err != nil {\n\t// error handling\n}\n</code></pre><ul>\n<li>错误要单独判断，不与其他逻辑组合判断。</li>\n</ul><pre><code>// bad\nv, err := foo()\nif err != nil || v  == nil {\n\t// error handling\n\treturn err\n}\n\n// good\nv, err := foo()\nif err != nil {\n\t// error handling\n\treturn err\n}\n\nif v == nil {\n\t// error handling\n\treturn errors.New(&quot;invalid value v&quot;)\n}\n</code></pre><ul>\n<li>如果返回值需要初始化，则采用下面的方式。</li>\n</ul><pre><code>v, err := f()\nif err != nil {\n    // error handling\n    return // or continue.\n}\n// use v\n</code></pre><ul>\n<li>\n<p>错误描述建议</p>\n<ul>\n<li>告诉用户他们可以做什么，而不是告诉他们不能做什么。</li>\n<li>当声明一个需求时，用must 而不是should。例如，must be greater than 0、must match regex ‘[a-z]+’。</li>\n<li>当声明一个格式不对时，用must not。例如，must not contain。</li>\n<li>当声明一个动作时用may not。例如，may not be specified when otherField is empty、only name may be specified。</li>\n<li>引用文字字符串值时，请在单引号中指示文字。例如，ust not contain ‘…’。</li>\n<li>当引用另一个字段名称时，请在反引号中指定该名称。例如，must be greater than <code>request</code>。</li>\n<li>指定不等时，请使用单词而不是符号。例如，must be less than 256、must be greater than or equal to 0 (不要用 larger than、bigger than、more than、higher than)。</li>\n<li>指定数字范围时，请尽可能使用包含范围。</li>\n<li>建议 Go 1.13 以上，error 生成方式为 <code>fmt.Errorf(\"module xxx: %w\", err)</code>。</li>\n<li>错误描述用小写字母开头，结尾不要加标点符号，例如：</li>\n</ul>\n</li>\n</ul><pre><code>\t// bad\n\terrors.New(&quot;Redis connection failed&quot;)\n\terrors.New(&quot;redis connection failed.&quot;)\n\n\t// good\n\terrors.New(&quot;redis connection failed&quot;)\n</code></pre><h3>1.4 panic处理</h3><ul>\n<li>在业务逻辑处理中禁止使用panic。</li>\n<li>在main包中，只有当程序完全不可运行时使用panic，例如无法打开文件、无法连接数据库导致程序无法正常运行。</li>\n<li>在main包中，使用 <code>log.Fatal</code> 来记录错误，这样就可以由log来结束程序，或者将panic抛出的异常记录到日志文件中，方便排查问题。</li>\n<li>可导出的接口一定不能有panic。</li>\n<li>包内建议采用error而不是panic来传递错误。</li>\n</ul><h3>1.5 单元测试</h3><ul>\n<li>单元测试文件名命名规范为 <code>example_test.go</code>。</li>\n<li>每个重要的可导出函数都要编写测试用例。</li>\n<li>因为单元测试文件内的函数都是不对外的，所以可导出的结构体、函数等可以不带注释。</li>\n<li>如果存在 <code>func (b *Bar) Foo</code> ，单测函数可以为 <code>func TestBar_Foo</code>。</li>\n</ul><h3>1.6 类型断言失败处理</h3><p>type assertion 的单个返回值针对不正确的类型将产生 panic。请始终使用 “comma ok”的惯用法。</p><pre><code>// bad\nt := n.(int)\n\n// good\nt, ok := n.(int)\nif !ok {\n\t// error handling\n}\n// normal code\n</code></pre><h2>2. 命名规范</h2><p>命名规范是代码规范中非常重要的一部分，一个统一的、短小的、精确的命名规范可以大大提高代码的可读性，也可以借此规避一些不必要的Bug。</p><h3>2.1 包命名</h3><ul>\n<li>包名必须和目录名一致，尽量采取有意义、简短的包名，不要和标准库冲突。</li>\n<li>包名全部小写，没有大写或下划线，使用多级目录来划分层级。</li>\n<li>项目名可以通过中划线来连接多个单词。</li>\n<li>包名以及包所在的目录名，不要使用复数，例如，是<code>net/url</code>，而不是<code>net/urls</code>。</li>\n<li>不要用 common、util、shared 或者 lib 这类宽泛的、无意义的包名。</li>\n<li>包名要简单明了，例如 net、time、log。</li>\n</ul><h3>2.2 函数命名</h3><ul>\n<li>函数名采用驼峰式，首字母根据访问控制决定使用大写或小写，例如：MixedCaps或者mixedCaps。</li>\n<li>代码生成工具自动生成的代码(如xxxx.pb.go)和为了对相关测试用例进行分组，而采用的下划线(如TestMyFunction_WhatIsBeingTested)排除此规则。</li>\n</ul><h3>2.3 文件命名</h3><ul>\n<li>文件名要简短有意义。</li>\n<li>文件名应小写，并使用下划线分割单词。</li>\n</ul><h3>2.4 结构体命名</h3><ul>\n<li>采用驼峰命名方式，首字母根据访问控制决定使用大写或小写，例如MixedCaps或者mixedCaps。</li>\n<li>结构体名不应该是动词，应该是名词，比如 Node、NodeSpec。</li>\n<li>避免使用Data、Info这类无意义的结构体名。</li>\n<li>结构体的声明和初始化应采用多行，例如：</li>\n</ul><pre><code>// User 多行声明\ntype User struct {\n    Name  string\n    Email string\n}\n\n// 多行初始化\nu := User{\n    UserName: &quot;colin&quot;,\n    Email:    &quot;colin404@foxmail.com&quot;,\n}\n</code></pre><h3>2.5 接口命名</h3><ul>\n<li>\n<p>接口命名的规则，基本和结构体命名规则保持一致：</p>\n<ul>\n<li>单个函数的接口名以 “er\"”作为后缀（例如Reader，Writer），有时候可能导致蹩脚的英文，但是没关系。</li>\n<li>两个函数的接口名以两个函数名命名，例如ReadWriter。</li>\n<li>三个以上函数的接口名，类似于结构体名。</li>\n</ul>\n</li>\n</ul><p>例如：</p><pre><code>\t// Seeking to an offset before the start of the file is an error.\n\t// Seeking to any positive offset is legal, but the behavior of subsequent\n\t// I/O operations on the underlying object is implementation-dependent.\n\ttype Seeker interface {\n\t    Seek(offset int64, whence int) (int64, error)\n\t}\n\n\t// ReadWriter is the interface that groups the basic Read and Write methods.\n\ttype ReadWriter interface {\n\t    Reader\n\t    Writer\n\t}\n</code></pre><h3>2.6 变量命名</h3><ul>\n<li>\n<p>变量名必须遵循<strong>驼峰式</strong>，首字母根据访问控制决定使用大写或小写。</p>\n</li>\n<li>\n<p>在相对简单（对象数量少、针对性强）的环境中，可以将一些名称由完整单词简写为单个字母，例如：</p>\n<ul>\n<li>user 可以简写为 u；</li>\n<li>userID 可以简写 uid。</li>\n</ul>\n</li>\n<li>\n<p>特有名词时，需要遵循以下规则：</p>\n<ul>\n<li>如果变量为私有，且特有名词为首个单词，则使用小写，如 apiClient。</li>\n<li>其他情况都应当使用该名词原有的写法，如 APIClient、repoID、UserID。</li>\n</ul>\n</li>\n</ul><p>下面列举了一些常见的特有名词。</p><pre><code>// A GonicMapper that contains a list of common initialisms taken from golang/lint\nvar LintGonicMapper = GonicMapper{\n    &quot;API&quot;:   true,\n    &quot;ASCII&quot;: true,\n    &quot;CPU&quot;:   true,\n    &quot;CSS&quot;:   true,\n    &quot;DNS&quot;:   true,\n    &quot;EOF&quot;:   true,\n    &quot;GUID&quot;:  true,\n    &quot;HTML&quot;:  true,\n    &quot;HTTP&quot;:  true,\n    &quot;HTTPS&quot;: true,\n    &quot;ID&quot;:    true,\n    &quot;IP&quot;:    true,\n    &quot;JSON&quot;:  true,\n    &quot;LHS&quot;:   true,\n    &quot;QPS&quot;:   true,\n    &quot;RAM&quot;:   true,\n    &quot;RHS&quot;:   true,\n    &quot;RPC&quot;:   true,\n    &quot;SLA&quot;:   true,\n    &quot;SMTP&quot;:  true,\n    &quot;SSH&quot;:   true,\n    &quot;TLS&quot;:   true,\n    &quot;TTL&quot;:   true,\n    &quot;UI&quot;:    true,\n    &quot;UID&quot;:   true,\n    &quot;UUID&quot;:  true,\n    &quot;URI&quot;:   true,\n    &quot;URL&quot;:   true,\n    &quot;UTF8&quot;:  true,\n    &quot;VM&quot;:    true,\n    &quot;XML&quot;:   true,\n    &quot;XSRF&quot;:  true,\n    &quot;XSS&quot;:   true,\n}\n</code></pre><ul>\n<li>若变量类型为bool类型，则名称应以Has，Is，Can或Allow开头，例如：</li>\n</ul><pre><code>var hasConflict bool\nvar isExist bool\nvar canManage bool\nvar allowGitHook bool\n</code></pre><ul>\n<li>局部变量应当尽可能短小，比如使用buf指代buffer，使用i指代index。</li>\n<li>代码生成工具自动生成的代码可排除此规则(如xxx.pb.go里面的Id)</li>\n</ul><h3>2.7 常量命名</h3><ul>\n<li>常量名必须遵循驼峰式，首字母根据访问控制决定使用大写或小写。</li>\n<li>如果是枚举类型的常量，需要先创建相应类型：</li>\n</ul><pre><code>// Code defines an error code type.\ntype Code int\n\n// Internal errors.\nconst (\n    // ErrUnknown - 0: An unknown error occurred.\n    ErrUnknown Code = iota\n    // ErrFatal - 1: An fatal error occurred.\n    ErrFatal\n)\n</code></pre><h3>2.8 Error的命名</h3><ul>\n<li>Error类型应该写成FooError的形式。</li>\n</ul><pre><code>type ExitError struct {\n\t// ....\n}\n</code></pre><ul>\n<li>Error变量写成ErrFoo的形式。</li>\n</ul><pre><code>var ErrFormat = errors.New(&quot;unknown format&quot;)\n</code></pre><h2>3. 注释规范</h2><ul>\n<li>每个可导出的名字都要有注释，该注释对导出的变量、函数、结构体、接口等进行简要介绍。</li>\n<li>全部使用单行注释，禁止使用多行注释。</li>\n<li>和代码的规范一样，单行注释不要过长，禁止超过 120 字符，超过的请使用换行展示，尽量保持格式优雅。</li>\n<li>注释必须是完整的句子，以需要注释的内容作为开头，句点作为结尾，格式为 <code>// 名称 描述.</code> 。例如：</li>\n</ul><pre><code>// bad\n// logs the flags in the flagset.\nfunc PrintFlags(flags *pflag.FlagSet) {\n\t// normal code\n}\n\n// good\n// PrintFlags logs the flags in the flagset.\nfunc PrintFlags(flags *pflag.FlagSet) {\n\t// normal code\n}\n</code></pre><ul>\n<li>\n<p>所有注释掉的代码在提交code review前都应该被删除，否则应该说明为什么不删除，并给出后续处理建议。</p>\n</li>\n<li>\n<p>在多段注释之间可以使用空行分隔加以区分，如下所示：</p>\n</li>\n</ul><pre><code>// Package superman implements methods for saving the world.\n//\n// Experience has shown that a small number of procedures can prove\n// helpful when attempting to save the world.\npackage superman\n</code></pre><h3>3.1 包注释</h3><ul>\n<li>每个包都有且仅有一个包级别的注释。</li>\n<li>包注释统一用 <code>//</code> 进行注释，格式为 <code>// Package 包名 包描述</code> ，例如：</li>\n</ul><pre><code>// Package genericclioptions contains flags which can be added to you command, bound, completed, and produce\n// useful helper functions.\npackage genericclioptions\n</code></pre><h3>3.2 变量/常量注释</h3><ul>\n<li>每个可导出的变量/常量都必须有注释说明，格式为<code>// 变量名 变量描述</code>，例如：</li>\n</ul><pre><code>// ErrSigningMethod defines invalid signing method error.\nvar ErrSigningMethod = errors.New(&quot;Invalid signing method&quot;)\n</code></pre><ul>\n<li>出现大块常量或变量定义时，可在前面注释一个总的说明，然后在每一行常量的前一行或末尾详细注释该常量的定义，例如：</li>\n</ul><pre><code>// Code must start with 1xxxxx.    \nconst (                         \n    // ErrSuccess - 200: OK.          \n    ErrSuccess int = iota + 100001    \n                                                   \n    // ErrUnknown - 500: Internal server error.    \n    ErrUnknown    \n\n    // ErrBind - 400: Error occurred while binding the request body to the struct.    \n    ErrBind    \n                                                  \n    // ErrValidation - 400: Validation failed.    \n    ErrValidation \n)\n</code></pre><h3>3.3 结构体注释</h3><ul>\n<li>每个需要导出的结构体或者接口都必须有注释说明，格式为 <code>// 结构体名 结构体描述.</code>。</li>\n<li>结构体内的可导出成员变量名，如果意义不明确，必须要给出注释，放在成员变量的前一行或同一行的末尾。例如：</li>\n</ul><pre><code>// User represents a user restful resource. It is also used as gorm model.\ntype User struct {\n    // Standard object's metadata.\n    metav1.ObjectMeta `json:&quot;metadata,omitempty&quot;`\n\n    Nickname string `json:&quot;nickname&quot; gorm:&quot;column:nickname&quot;`\n    Password string `json:&quot;password&quot; gorm:&quot;column:password&quot;`\n    Email    string `json:&quot;email&quot; gorm:&quot;column:email&quot;`\n    Phone    string `json:&quot;phone&quot; gorm:&quot;column:phone&quot;`\n    IsAdmin  int    `json:&quot;isAdmin,omitempty&quot; gorm:&quot;column:isAdmin&quot;`\n}\n</code></pre><h3>3.4 方法注释</h3><ul>\n<li>每个需要导出的函数或者方法都必须有注释，格式为<code>// 函数名 函数描述.</code>，例如：</li>\n</ul><pre><code>// BeforeUpdate run before update database record.\nfunc (p *Policy) BeforeUpdate() (err error) {\n\t// normal code\n\treturn nil\n}\n</code></pre><h3>3.5 类型注释</h3><ul>\n<li>每个需要导出的类型定义和类型别名都必须有注释说明，格式为 <code>// 类型名 类型描述.</code> ，例如：</li>\n</ul><pre><code>// Code defines an error code type.\ntype Code int\n</code></pre><h2>4. 类型</h2><h3>4.1 字符串</h3><ul>\n<li>空字符串判断。</li>\n</ul><pre><code>// bad\nif s == &quot;&quot; {\n    // normal code\n}\n\n// good\nif len(s) == 0 {\n    // normal code\n}\n</code></pre><ul>\n<li>[]byte/string相等比较。</li>\n</ul><pre><code>// bad\nvar s1 []byte\nvar s2 []byte\n...\nbytes.Equal(s1, s2) == 0\nbytes.Equal(s1, s2) != 0\n\n// good\nvar s1 []byte\nvar s2 []byte\n...\nbytes.Compare(s1, s2) == 0\nbytes.Compare(s1, s2) != 0\n</code></pre><ul>\n<li>复杂字符串使用raw字符串避免字符转义。</li>\n</ul><pre><code>// bad\nregexp.MustCompile(&quot;\\\\.&quot;)\n\n// good\nregexp.MustCompile(`\\.`)\n</code></pre><h3>4.2 切片</h3><ul>\n<li>空slice判断。</li>\n</ul><pre><code>// bad\nif len(slice) = 0 {\n    // normal code\n}\n\n// good\nif slice != nil &amp;&amp; len(slice) == 0 {\n    // normal code\n}\n</code></pre><p>上面判断同样适用于map、channel。</p><ul>\n<li>声明slice。</li>\n</ul><pre><code>// bad\ns := []string{}\ns := make([]string, 0)\n\n// good\nvar s []string\n</code></pre><ul>\n<li>slice复制。</li>\n</ul><pre><code>// bad\nvar b1, b2 []byte\nfor i, v := range b1 {\n   b2[i] = v\n}\nfor i := range b1 {\n   b2[i] = b1[i]\n}\n\n// good\ncopy(b2, b1)\n</code></pre><ul>\n<li>slice新增。</li>\n</ul><pre><code>// bad\nvar a, b []int\nfor _, v := range a {\n    b = append(b, v)\n}\n\n// good\nvar a, b []int\nb = append(b, a...)\n</code></pre><h3>4.3 结构体</h3><ul>\n<li>struct初始化。</li>\n</ul><p>struct以多行格式初始化。</p><pre><code>type user struct {\n\tId   int64\n\tName string\n}\n\nu1 := user{100, &quot;Colin&quot;}\n\nu2 := user{\n    Id:   200,\n    Name: &quot;Lex&quot;,\n}\n</code></pre><h2>5. 控制结构</h2><h3>5.1 if</h3><ul>\n<li>if 接受初始化语句，约定如下方式建立局部变量。</li>\n</ul><pre><code>if err := loadConfig(); err != nil {\n\t// error handling\n\treturn err\n}\n</code></pre><ul>\n<li>if 对于bool类型的变量，应直接进行真假判断。</li>\n</ul><pre><code>var isAllow bool\nif isAllow {\n\t// normal code\n}\n</code></pre><h3>5.2 for</h3><ul>\n<li>采用短声明建立局部变量。</li>\n</ul><pre><code>sum := 0\nfor i := 0; i &lt; 10; i++ {\n    sum += 1\n}\n</code></pre><ul>\n<li>不要在 for 循环里面使用 defer，defer只有在函数退出时才会执行。</li>\n</ul><pre><code>// bad\nfor file := range files {\n\tfd, err := os.Open(file)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer fd.Close()\n\t// normal code\n}\n\n// good\nfor file := range files {\n\tfunc() {\n\t\tfd, err := os.Open(file)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tdefer fd.Close()\n\t\t// normal code\n\t}()\n}\n</code></pre><h3>5.3 range</h3><ul>\n<li>如果只需要第一项（key），就丢弃第二个。</li>\n</ul><pre><code>for key := range keys {\n// normal code\n}\n</code></pre><ul>\n<li>如果只需要第二项，则把第一项置为下划线。</li>\n</ul><pre><code>sum := 0\nfor _, value := range array {\n    sum += value\n}\n</code></pre><h3>5.4 switch</h3><ul>\n<li>必须要有default。</li>\n</ul><pre><code>switch os := runtime.GOOS; os {\n    case &quot;linux&quot;:\n        fmt.Println(&quot;Linux.&quot;)\n    case &quot;darwin&quot;:\n        fmt.Println(&quot;OS X.&quot;)\n    default:\n        fmt.Printf(&quot;%s.\\n&quot;, os)\n}\n</code></pre><h3>5.5 goto</h3><ul>\n<li>业务代码禁止使用 <code>goto</code> 。</li>\n<li>框架或其他底层源码尽量不用。</li>\n</ul><h2>6. 函数</h2><ul>\n<li>\n<p>传入变量和返回变量以小写字母开头。</p>\n</li>\n<li>\n<p>函数参数个数不能超过5个。</p>\n</li>\n<li>\n<p>函数分组与顺序</p>\n<ul>\n<li>函数应按粗略的调用顺序排序。</li>\n<li>同一文件中的函数应按接收者分组。</li>\n</ul>\n</li>\n<li>\n<p>尽量采用值传递，而非指针传递。</p>\n</li>\n<li>\n<p>传入参数是 map、slice、chan、interface ，不要传递指针。</p>\n</li>\n</ul><h3>6.1 函数参数</h3><ul>\n<li>如果函数返回相同类型的两个或三个参数，或者如果从上下文中不清楚结果的含义，使用命名返回，其他情况不建议使用命名返回，例如：</li>\n</ul><pre><code>func coordinate() (x, y float64, err error) {\n\t// normal code\n}\n</code></pre><ul>\n<li>传入变量和返回变量都以小写字母开头。</li>\n<li>尽量用值传递，非指针传递。</li>\n<li>参数数量均不能超过5个。</li>\n<li>多返回值最多返回三个，超过三个请使用 struct。</li>\n</ul><h3>6.2 defer</h3><ul>\n<li>当存在资源创建时，应紧跟defer释放资源(可以大胆使用defer，defer在Go1.14版本中，性能大幅提升，defer的性能损耗即使在性能敏感型的业务中，也可以忽略)。</li>\n<li>先判断是否错误，再defer释放资源，例如：</li>\n</ul><pre><code>rep, err := http.Get(url)\nif err != nil {\n    return err\n}\n\ndefer resp.Body.Close()\n</code></pre><h3>6.3 方法的接收器</h3><ul>\n<li>推荐以类名第一个英文首字母的小写作为接收器的命名。</li>\n<li>接收器的命名在函数超过20行的时候不要用单字符。</li>\n<li>接收器的命名不能采用me、this、self这类易混淆名称。</li>\n</ul><h3>6.4 嵌套</h3><ul>\n<li>嵌套深度不能超过4层。</li>\n</ul><h3>6.5 变量命名</h3><ul>\n<li>变量声明尽量放在变量第一次使用的前面，遵循就近原则。</li>\n<li>如果魔法数字出现超过两次，则禁止使用，改用一个常量代替，例如：</li>\n</ul><pre><code>// PI ...\nconst Prise = 3.14\n\nfunc getAppleCost(n float64) float64 {\n\treturn Prise * n\n}\n\nfunc getOrangeCost(n float64) float64 {\n\treturn Prise * n\n}\n</code></pre><h2>7.   GOPATH 设置规范</h2><ul>\n<li>Go 1.11 之后，弱化了 GOPATH 规则，已有代码（很多库肯定是在1.11之前建立的）肯定符合这个规则，建议保留 GOPATH 规则，便于维护代码。</li>\n<li>建议只使用一个 GOPATH，不建议使用多个 GOPATH。如果使用多个GOPATH，编译生效的 bin 目录是在第一个 GOPATH 下。</li>\n</ul><h2>8. 依赖管理</h2><ul>\n<li>Go 1.11 以上必须使用 Go Modules。</li>\n<li>使用Go Modules作为依赖管理的项目时，不建议提交vendor目录。</li>\n<li>使用Go Modules作为依赖管理的项目时，必须提交go.sum文件。</li>\n</ul><h2>9. 最佳实践</h2><ul>\n<li>尽量少用全局变量，而是通过参数传递，使每个函数都是“无状态”的。这样可以减少耦合，也方便分工和单元测试。</li>\n<li>在编译时验证接口的符合性，例如：</li>\n</ul><pre><code>type LogHandler struct {\n  h   http.Handler\n  log *zap.Logger\n}\nvar _ http.Handler = LogHandler{}\n</code></pre><ul>\n<li>服务器处理请求时，应该创建一个context，保存该请求的相关信息（如requestID），并在函数调用链中传递。</li>\n</ul><h3>9.1 性能</h3><ul>\n<li>string 表示的是不可变的字符串变量，对 string 的修改是比较重的操作，基本上都需要重新申请内存。所以，如果没有特殊需要，需要修改时多使用 []byte。</li>\n<li>优先使用 strconv 而不是 fmt。</li>\n</ul><h3>9.2 注意事项</h3><ul>\n<li>append 要小心自动分配内存，append 返回的可能是新分配的地址。</li>\n<li>如果要直接修改 map 的 value 值，则 value 只能是指针，否则要覆盖原来的值。</li>\n<li>map 在并发中需要加锁。</li>\n<li>编译过程无法检查 interface{} 的转换，只能在运行时检查，小心引起 panic。</li>\n</ul><h2>总结</h2><p>这一讲，我向你介绍了九类常用的编码规范。但今天的最后，我要在这里提醒你一句：规范是人定的，你也可以根据需要，制定符合你项目的规范。这也是我在之前的课程里一直强调的思路。但同时我也建议你采纳这些业界沉淀下来的规范，并通过工具来确保规范的执行。</p><p>今天的内容就到这里啦，欢迎你在下面的留言区谈谈自己的看法，我们下一讲见。</p>","neighbors":{"left":{"article_title":"51 | 基于 GitHub Actions 的 CI 实战","id":422735},"right":{"article_title":"特别放送 | 给你一份Go项目中最常用的Makefile核心语法","id":389115}}},{"article_id":389115,"article_title":"特别放送 | 给你一份Go项目中最常用的Makefile核心语法","article_content":"<p>你好，我是孔令飞。今天，我们更新一期特别放送作为“加餐”，希望日常催更的朋友们食用愉快。</p><p>在第 <a href=\"https://time.geekbang.org/column/article/388920\"><strong>14讲</strong></a>  里<strong>，</strong>我强调了熟练掌握Makefile语法的重要性，还推荐你去学习陈皓老师编写的<a href=\"https://github.com/seisman/how-to-write-makefile\">《跟我一起写 Makefile》 (PDF 重制版)</a>。也许你已经点开了链接，看到那么多Makefile语法，是不是有点被“劝退”的感觉？</p><p>其实在我看来，虽然Makefile有很多语法，但不是所有的语法都需要你熟练掌握，有些语法在Go项目中是很少用到的。要编写一个高质量的Makefile，首先应该掌握一些核心的、最常用的语法知识。这一讲我就来具体介绍下Go项目中常用的Makefile语法和规则，帮助你快速打好最重要的基础。</p><p>Makefile文件由三个部分组成，分别是Makefile规则、Makefile语法和Makefile命令（这些命令可以是Linux命令，也可以是可执行的脚本文件）。在这一讲里，我会介绍下Makefile规则和Makefile语法里的一些核心语法知识。在介绍这些语法知识之前，我们先来看下如何使用Makefile脚本。</p><h2>Makefile的使用方法</h2><p>在实际使用过程中，我们一般是先编写一个Makefile文件，指定整个项目的编译规则，然后通过Linux make命令来解析该Makefile文件，实现项目编译、管理的自动化。</p><!-- [[[read_end]]] --><p>默认情况下，make命令会在当前目录下，按照GNUmakefile、makefile、Makefile文件的顺序查找Makefile文件，一旦找到，就开始读取这个文件并执行。</p><p>大多数的make都支持“makefile”和“Makefile”这两种文件名，但<strong>我建议使用“Makefile”</strong>。因为这个文件名第一个字符大写，会很明显，容易辨别。make也支持 <code>-f</code> 和 <code>--file</code> 参数来指定其他文件名，比如 <code>make -f golang.mk</code> 或者 <code>make --file golang.mk</code> 。</p><h2>Makefile规则介绍</h2><p>学习Makefile，最核心的就是学习Makefile的规则。规则是Makefile中的重要概念，它一般由目标、依赖和命令组成，用来指定源文件编译的先后顺序。Makefile之所以受欢迎，核心原因就是Makefile规则，因为Makefile规则可以自动判断是否需要重新编译某个目标，从而确保目标仅在需要时编译。</p><p>这一讲我们主要来看Makefile规则里的规则语法、伪目标和order-only依赖。</p><h3>规则语法</h3><p>Makefile的规则语法，主要包括target、prerequisites和command，示例如下：</p><pre><code>target ...: prerequisites ...\n    command\n\t  ...\n\t  ...\n</code></pre><p><strong>target，</strong>可以是一个object file（目标文件），也可以是一个执行文件，还可以是一个标签（label）。target可使用通配符，当有多个目标时，目标之间用空格分隔。</p><p><strong>prerequisites，</strong>代表生成该target所需要的依赖项。当有多个依赖项时，依赖项之间用空格分隔。</p><p><strong>command</strong>，代表该target要执行的命令（可以是任意的shell命令）。</p><ul>\n<li>在执行command之前，默认会先打印出该命令，然后再输出命令的结果；如果不想打印出命令，可在各个command前加上<code>@</code>。</li>\n<li>command可以为多条，也可以分行写，但每行都要以tab键开始。另外，如果后一条命令依赖前一条命令，则这两条命令需要写在同一行，并用分号进行分隔。</li>\n<li>如果要忽略命令的出错，需要在各个command之前加上减号<code>-</code>。</li>\n</ul><p><strong>只要targets不存在，或prerequisites中有一个以上的文件比targets文件新，那么command所定义的命令就会被执行，从而产生我们需要的文件，或执行我们期望的操作。</strong></p><p>我们直接通过一个例子来理解下Makefile的规则吧。</p><p>第一步，先编写一个hello.c文件。</p><pre><code>#include &lt;stdio.h&gt;\nint main()\n{\n  printf(&quot;Hello World!\\n&quot;);\n  return 0;\n}\n</code></pre><p>第二步，在当前目录下，编写Makefile文件。</p><pre><code>hello: hello.o\n\tgcc -o hello hello.o\n\nhello.o: hello.c\n\tgcc -c hello.c\n\nclean:\n\trm hello.o\n</code></pre><p>第三步，执行make，产生可执行文件。</p><pre><code>$ make\ngcc -c hello.c\ngcc -o hello hello.o\n$ ls\nhello  hello.c  hello.o  Makefile\n</code></pre><p>上面的示例Makefile文件有两个target，分别是hello和hello.o，每个target都指定了构建command。当执行make命令时，发现hello、hello.o文件不存在，就会执行command命令生成target。</p><p>第四步，不更新任何文件，再次执行make。</p><pre><code>$ make\nmake: 'hello' is up to date.\n</code></pre><p>当target存在，并且prerequisites都不比target新时，不会执行对应的command。</p><p>第五步，更新hello.c，并再次执行make。</p><pre><code>$ touch hello.c\n$ make\ngcc -c hello.c\ngcc -o hello hello.o\n</code></pre><p>当target存在，但 prerequisites 比 target 新时，会重新执行对应的command。</p><p>第六步，清理编译中间文件。</p><p>Makefile一般都会有一个clean伪目标，用来清理编译中间产物，或者对源码目录做一些定制化的清理：</p><pre><code>$ make clean\nrm hello.o\n</code></pre><p>我们可以在规则中使用通配符，make 支持三个通配符：*，?和~，例如：</p><pre><code>objects = *.o\nprint: *.c\n    rm *.c\n</code></pre><h3>伪目标</h3><p>接下来我们介绍下Makefile中的伪目标。Makefile的管理能力基本上都是通过伪目标来实现的。</p><p>在上面的Makefile示例中，我们定义了一个clean目标，这其实是一个伪目标，也就是说我们不会为该目标生成任何文件。因为伪目标不是文件，make 无法生成它的依赖关系，也无法决定是否要执行它。</p><p>通常情况下，我们需要显式地标识这个目标为伪目标。在Makefile中可以使用<code>.PHONY</code>来标识一个目标为伪目标：</p><pre><code>.PHONY: clean\nclean:\n    rm hello.o\n</code></pre><p>伪目标可以有依赖文件，也可以作为“默认目标”，例如：</p><pre><code>.PHONY: all\nall: lint test build\n</code></pre><p>因为伪目标总是会被执行，所以其依赖总是会被决议。通过这种方式，可以达到<strong>同时执行所有依赖项</strong>的目的。</p><h3>order-only依赖</h3><p>在上面介绍的规则中，只要prerequisites中有任何文件发生改变，就会重新构造target。但是有时候，我们希望<strong>只有当prerequisites中的部分文件改变时，才重新构造target。</strong>这时，你可以通过order-only prerequisites实现。</p><p>order-only prerequisites的形式如下：</p><pre><code>targets : normal-prerequisites | order-only-prerequisites\n    command\n    ...\n    ...\n</code></pre><p>在上面的规则中，只有第一次构造targets时，才会使用order-only-prerequisites。后面即使order-only-prerequisites发生改变，也不会重新构造targets。</p><p>只有normal-prerequisites中的文件发生改变时，才会重新构造targets。这里，符号“ | ”后面的prerequisites就是order-only-prerequisites。</p><p>到这里，我们就介绍了Makefile的规则。接下来，我们再来看下Makefile中的一些核心语法知识。</p><h2>Makefile语法概览</h2><p>因为Makefile的语法比较多，这一讲只介绍Makefile的核心语法，以及 IAM项目的Makefile用到的语法，包括命令、变量、条件语句和函数。因为Makefile没有太多复杂的语法，你掌握了这些知识点之后，再在实践中多加运用，融会贯通，就可以写出非常复杂、功能强大的Makefile文件了。</p><h3>命令</h3><p>Makefile支持Linux命令，调用方式跟在Linux系统下调用命令的方式基本一致。默认情况下，make会把正在执行的命令输出到当前屏幕上。但我们可以通过在命令前加<code>@</code>符号的方式，禁止make输出当前正在执行的命令。</p><p>我们看一个例子。现在有这么一个Makefile：</p><pre><code>.PHONY: test\ntest:\n    echo &quot;hello world&quot;\n</code></pre><p>执行make命令：</p><pre><code>$ make test\necho &quot;hello world&quot;\nhello world\n</code></pre><p>可以看到，make输出了执行的命令。很多时候，我们不需要这样的提示，因为我们更想看的是命令产生的日志，而不是执行的命令。这时就可以在命令行前加<code>@</code>，禁止make输出所执行的命令：</p><pre><code>.PHONY: test\ntest:\n    @echo &quot;hello world&quot;\n</code></pre><p>再次执行make命令：</p><pre><code>$ make test\nhello world\n</code></pre><p>可以看到，make只是执行了命令，而没有打印命令本身。这样make输出就清晰了很多。</p><p>这里，<strong>我建议在命令前都加</strong><code>@</code>符号，禁止打印命令本身，以保证你的Makefile输出易于阅读的、有用的信息。</p><p>默认情况下，每条命令执行完make就会检查其返回码。如果返回成功（返回码为0），make就执行下一条指令；如果返回失败（返回码非0），make就会终止当前命令。很多时候，命令出错（比如删除了一个不存在的文件）时，我们并不想终止，这时就可以在命令行前加 <code>-</code> 符号，来让make忽略命令的出错，以继续执行下一条命令，比如：</p><pre><code>clean:\n    -rm hello.o\n</code></pre><h3>变量</h3><p>变量，可能是Makefile中使用最频繁的语法了，Makefile支持变量赋值、多行变量和环境变量。另外，Makefile还内置了一些特殊变量和自动化变量。</p><p>我们先来看下最基本的<strong>变量赋值</strong>功能。</p><p>Makefile也可以像其他语言一样支持变量。在使用变量时，会像shell变量一样原地展开，然后再执行替换后的内容。</p><p>Makefile可以通过变量声明来声明一个变量，变量在声明时需要赋予一个初值，比如<code>ROOT_PACKAGE=github.com/marmotedu/iam</code>。</p><p>引用变量时可以通过<code>$()</code>或者<code>${}</code>方式引用。我的建议是，用<code>$()</code>方式引用变量，例如<code>$(ROOT_PACKAGE)</code>，也建议整个makefile的变量引用方式保持一致。</p><p>变量会像bash变量一样，在使用它的地方展开。比如：</p><pre><code>GO=go\nbuild:\n    $(GO) build -v .\n</code></pre><p>展开后为：</p><pre><code>GO=go\nbuild:\n    go build -v .\n</code></pre><p>接下来，我给你介绍下Makefile中的4种变量赋值方法。</p><ol>\n<li><code>=</code> 最基本的赋值方法。</li>\n</ol><p>例如：</p><pre><code>BASE_IMAGE = alpine:3.10\n</code></pre><p>使用 <code>=</code> 进行赋值时，要注意下面这样的情况：</p><pre><code>A = a\nB = $(A) b\nA = c\n</code></pre><p>B最后的值为 c b，而不是a b。也就是说，在用变量给变量赋值时，右边变量的取值，取的是最终的变量值。</p><ol start=\"2\">\n<li><code>:=</code>直接赋值，赋予当前位置的值。</li>\n</ol><p>例如：</p><pre><code>A = a\nB := $(A) b\nA = c\n</code></pre><p>B最后的值为 a b。通过 <code>:=</code> 的赋值方式，可以避免 <code>=</code> 赋值带来的潜在的不一致。</p><ol start=\"3\">\n<li><code>?=</code> 表示如果该变量没有被赋值，则赋予等号后的值。</li>\n</ol><p>例如：</p><pre><code>PLATFORMS ?= linux_amd64 linux_arm64\n</code></pre><ol start=\"4\">\n<li><code>+=</code>表示将等号后面的值添加到前面的变量上。</li>\n</ol><p>例如：</p><pre><code>MAKEFLAGS += --no-print-directory\n</code></pre><p>Makefile还支持<strong>多行变量</strong>。可以通过define关键字设置多行变量，变量中允许换行。定义方式为：</p><pre><code>define 变量名\n变量内容\n...\nendef\n</code></pre><p>变量的内容可以包含函数、命令、文字或是其他变量。例如，我们可以定义一个USAGE_OPTIONS变量：</p><pre><code>define USAGE_OPTIONS\n\nOptions:\n  DEBUG        Whether to generate debug symbols. Default is 0.\n  BINS         The binaries to build. Default is all of cmd.\n  ...\n  V            Set to 1 enable verbose build. Default is 0.\nendef\n</code></pre><p>Makefile还支持<strong>环境变量</strong>。在Makefile中，有两种环境变量，分别是Makefile预定义的环境变量和自定义的环境变量。</p><p>其中，自定义的环境变量可以覆盖Makefile预定义的环境变量。默认情况下，Makefile中定义的环境变量只在当前Makefile有效，如果想向下层传递（Makefile中调用另一个Makefile），需要使用export关键字来声明。</p><p>下面的例子声明了一个环境变量，并可以在下层Makefile中使用：</p><pre><code>...\nexport USAGE_OPTIONS\n...\n</code></pre><p>此外，Makefile还支持两种内置的变量：特殊变量和自动化变量。</p><p><strong>特殊变量</strong>是make提前定义好的，可以在makefile中直接引用。特殊变量列表如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/c1/1d/c1cba21aaed2eb0117yyb0470byy641d.png?wh=1052x978\" alt=\"\"></p><p>Makefile还支持<strong>自动化变量</strong>。自动化变量可以提高我们编写Makefile的效率和质量。</p><p>在Makefile的模式规则中，目标和依赖文件都是一系列的文件，那么我们如何书写一个命令，来完成从不同的依赖文件生成相对应的目标呢？</p><p>这时就可以用到自动化变量。所谓自动化变量，就是这种变量会把模式中所定义的一系列的文件自动地挨个取出，一直到所有符合模式的文件都取完为止。这种自动化变量只应出现在规则的命令中。Makefile中支持的自动化变量见下表。</p><p><img src=\"https://static001.geekbang.org/resource/image/13/12/13ec33008eaff973c0dd854a795ff712.png?wh=1263x1303\" alt=\"\"></p><p>上面这些自动化变量中，<code>$*</code>是用得最多的。<code>$*</code> 对于构造有关联的文件名是比较有效的。如果目标中没有模式的定义，那么 <code>$*</code> 也就不能被推导出。但是，如果目标文件的后缀是make所识别的，那么 <code>$*</code> 就是除了后缀的那一部分。例如：如果目标是foo.c ，因为.c是make所能识别的后缀名，所以 <code>$*</code> 的值就是foo。</p><h3>条件语句</h3><p>Makefile也支持条件语句。这里先看一个示例。</p><p>下面的例子判断变量<code>ROOT_PACKAGE</code>是否为空，如果为空，则输出错误信息，不为空则打印变量值：</p><pre><code>ifeq ($(ROOT_PACKAGE),)\n$(error the variable ROOT_PACKAGE must be set prior to including golang.mk)\nelse\n$(info the value of ROOT_PACKAGE is $(ROOT_PACKAGE))\nendif\n</code></pre><p>条件语句的语法为：</p><pre><code># if ...\n&lt;conditional-directive&gt;\n&lt;text-if-true&gt;\nendif\n# if ... else ...\n&lt;conditional-directive&gt;\n&lt;text-if-true&gt;\nelse\n&lt;text-if-false&gt;\nendif\n</code></pre><p>例如，判断两个值是否相等：</p><pre><code>ifeq 条件表达式\n...\nelse\n...\nendif\n</code></pre><ul>\n<li>ifeq表示条件语句的开始，并指定一个条件表达式。表达式包含两个参数，参数之间用逗号分隔，并且表达式用圆括号括起来。</li>\n<li>else表示条件表达式为假的情况。</li>\n<li>endif表示一个条件语句的结束，任何一个条件表达式都应该以endif结束。</li>\n<li><conditional-directive>表示条件关键字，有4个关键字：ifeq、ifneq、ifdef、ifndef。</conditional-directive></li>\n</ul><p>为了加深你的理解，我们分别来看下这4个关键字的例子。</p><ol>\n<li>ifeq：条件判断，判断是否相等。</li>\n</ol><p>例如：</p><pre><code>ifeq (&lt;arg1&gt;, &lt;arg2&gt;)\nifeq '&lt;arg1&gt;' '&lt;arg2&gt;'\nifeq &quot;&lt;arg1&gt;&quot; &quot;&lt;arg2&gt;&quot;\nifeq &quot;&lt;arg1&gt;&quot; '&lt;arg2&gt;'\nifeq '&lt;arg1&gt;' &quot;&lt;arg2&gt;&quot;\n</code></pre><p>比较arg1和arg2的值是否相同，如果相同则为真。也可以用make函数/变量替代arg1或arg2，例如 <code>ifeq ($(origin ROOT_DIR),undefined)</code> 或 <code>ifeq ($(ROOT_PACKAGE),)</code> 。origin函数会在之后专门讲函数的一讲中介绍到。</p><ol start=\"2\">\n<li>ifneq：条件判断，判断是否不相等。</li>\n</ol><pre><code>ifneq (&lt;arg1&gt;, &lt;arg2&gt;)\nifneq '&lt;arg1&gt;' '&lt;arg2&gt;'\nifneq &quot;&lt;arg1&gt;&quot; &quot;&lt;arg2&gt;&quot;\nifneq &quot;&lt;arg1&gt;&quot; '&lt;arg2&gt;'\nifneq '&lt;arg1&gt;' &quot;&lt;arg2&gt;&quot;\n</code></pre><p>比较arg1和arg2的值是否不同，如果不同则为真。</p><ol start=\"3\">\n<li>ifdef：条件判断，判断变量是否已定义。</li>\n</ol><pre><code>ifdef &lt;variable-name&gt;\n</code></pre><p>如果<variable-name>值非空，则表达式为真，否则为假。<variable-name>也可以是函数的返回值。</variable-name></variable-name></p><ol start=\"4\">\n<li>ifndef：条件判断，判断变量是否未定义。</li>\n</ol><pre><code>ifndef &lt;variable-name&gt;\n</code></pre><p>如果<variable-name>值为空，则表达式为真，否则为假。<variable-name>也可以是函数的返回值。</variable-name></variable-name></p><h3>函数</h3><p>Makefile同样也支持函数，函数语法包括定义语法和调用语法。</p><p><strong>我们先来看下自定义函数。</strong> make解释器提供了一系列的函数供Makefile调用，这些函数是Makefile的预定义函数。我们可以通过define关键字来自定义一个函数。自定义函数的语法为：</p><pre><code>define 函数名\n函数体\nendef\n</code></pre><p>例如，下面这个自定义函数：</p><pre><code>define Foo\n    @echo &quot;my name is $(0)&quot;\n    @echo &quot;param is $(1)&quot;\nendef\n</code></pre><p>define本质上是定义一个多行变量，可以在call的作用下当作函数来使用，在其他位置使用只能作为多行变量来使用，例如：</p><pre><code>var := $(call Foo)\nnew := $(Foo)\n</code></pre><p>自定义函数是一种过程调用，没有任何的返回值。可以使用自定义函数来定义命令的集合，并应用在规则中。</p><p><strong>再来看下预定义函数。</strong> 刚才提到，make编译器也定义了很多函数，这些函数叫作预定义函数，调用语法和变量类似，语法为：</p><pre><code>$(&lt;function&gt; &lt;arguments&gt;)\n</code></pre><p>或者</p><pre><code>${&lt;function&gt; &lt;arguments&gt;}\n</code></pre><p><code>&lt;function&gt;</code>是函数名，<code>&lt;arguments&gt;</code>是函数参数，参数间用逗号分割。函数的参数也可以是变量。</p><p>我们来看一个例子：</p><pre><code>PLATFORM = linux_amd64\nGOOS := $(word 1, $(subst _, ,$(PLATFORM)))\n</code></pre><p>上面的例子用到了两个函数：word和subst。word函数有两个参数，1和subst函数的输出。subst函数将PLATFORM变量值中的_替换成空格（替换后的PLATFORM值为linux amd64）。word函数取linux amd64字符串中的第一个单词。所以最后GOOS的值为linux。</p><p>Makefile预定义函数能够帮助我们实现很多强大的功能，在编写Makefile的过程中，如果有功能需求，可以优先使用这些函数。如果你想使用这些函数，那就需要知道有哪些函数，以及它们实现的功能。</p><p>常用的函数包括下面这些，你需要先有个印象，以后用到时再来查看。</p><p><img src=\"https://static001.geekbang.org/resource/image/96/5f/96da0853e8225a656d2c0489e544865f.jpg?wh=2248x3692\" alt=\"\"></p><h2>引入其他Makefile</h2><p>除了Makefile规则、Makefile语法之外，Makefile还有很多特性，比如可以引入其他Makefile、自动生成依赖关系、文件搜索等等。这里我再介绍一个IAM项目的Makefile用到的重点特性：引入其他Makefile。</p><p>在 <a href=\"https://time.geekbang.org/column/article/388920\"><strong>14讲</strong></a> 中，我们介绍过Makefile要结构化、层次化，这一点可以通过<strong>在项目根目录下的Makefile中引入其他Makefile</strong>来实现。</p><p>在Makefile中，我们可以通过关键字include，把别的makefile包含进来，类似于C语言的<code>#include</code>，被包含的文件会插入在当前的位置。include用法为<code>include &lt;filename&gt;</code>，示例如下：</p><pre><code>include scripts/make-rules/common.mk\ninclude scripts/make-rules/golang.mk\n</code></pre><p>include也可以包含通配符<code>include scripts/make-rules/*</code>。make命令会按下面的顺序查找makefile文件：</p><ol>\n<li>如果是绝对或相对路径，就直接根据路径include进来。</li>\n<li>如果make执行时，有<code>-I</code>或<code>--include-dir</code>参数，那么make就会在这个参数所指定的目录下去找。</li>\n<li>如果目录<code>&lt;prefix&gt;/include</code>（一般是<code>/usr/local/bin</code>或<code>/usr/include</code>）存在的话，make也会去找。</li>\n</ol><p>如果有文件没有找到，make会生成一条警告信息，但不会马上出现致命错误，而是继续载入其他的文件。一旦完成makefile的读取，make会再重试这些没有找到或是不能读取的文件。如果还是不行，make才会出现一条致命错误信息。如果你想让make忽略那些无法读取的文件继续执行，可以在include前加一个减号<code>-</code>，如<code>-include &lt;filename&gt;</code>。</p><h2>总结</h2><p>在这一讲里，为了帮助你编写一个高质量的Makefile，我重点介绍了Makefile规则和Makefile语法里的一些核心语法知识。</p><p>在讲Makefile规则时，我们主要学习了规则语法、伪目标和order-only依赖。掌握了这些Makefile规则，你就掌握了Makefile中最核心的内容。</p><p>在介绍Makefile的语法时，我只介绍了Makefile的核心语法，以及 IAM项目的Makefile用到的语法，包括命令、变量、条件语句和函数。你可能会觉得这些语法学习起来比较枯燥，但还是那句话，工欲善其事，必先利其器。希望你能熟练掌握Makefile的核心语法，为编写高质量的Makefile打好基础。</p><p>今天的内容就到这里啦，欢迎你在下面的留言区谈谈自己的看法，我们下一讲见。</p>","neighbors":{"left":{"article_title":"特别放送 | 给你一份清晰、可直接套用的Go编码规范","id":385440},"right":{"article_title":"特别放送 | Go Modules依赖包管理全讲","id":416397}}},{"article_id":416397,"article_title":"特别放送 | Go Modules依赖包管理全讲","article_content":"<p>你好，我是孔令飞。今天我们更新一期特别放送作为加餐。</p><p>在Go项目开发中，依赖包管理是一个非常重要的内容，依赖包处理不好，就会导致编译失败。而且Go的依赖包管理有一定的复杂度，所以，我们有必要系统学习下Go的依赖包管理工具。</p><p>这一讲，我会首先介绍下Go依赖包管理工具的历史，并详细介绍下目前官方推荐的依赖包管理方案Go Modules。Go Modules主要包括了 <code>go mod</code> 命令行工具、模块下载机制，以及两个核心文件go.mod和go.sum。另外，Go Modules也提供了一些环境变量，用来控制Go Modules的行为。这一讲，我会分别介绍下这些内容。</p><p>在正式开始讲解这些内容之前，我们先来对Go Modules有个基本的了解。</p><h2>Go Modules简介</h2><p>Go Modules是Go官方推出的一个Go包管理方案，基于vgo演进而来，具有下面这几个特性：</p><ul>\n<li>可以使包的管理更加简单。</li>\n<li>支持版本管理。</li>\n<li>允许同一个模块多个版本共存。</li>\n<li>可以校验依赖包的哈希值，确保包的一致性，增加安全性。</li>\n<li>内置在几乎所有的go命令中，包括<code>go get</code>、<code>go build</code>、<code>go install</code>、<code>go run</code>、<code>go test</code>、<code>go list</code>等命令。</li>\n<li>具有Global Caching特性，不同项目的相同模块版本，只会在服务器上缓存一份。</li>\n</ul><!-- [[[read_end]]] --><p>在Go1.14版本以及之后的版本，Go官方建议在生产环境中使用Go Modules。因此，以后的Go包管理方案会逐渐统一到Go Modules。与Go Modules相关的概念很多，我在这里把它们总结为“6-2-2-1-1”，这一讲后面还会详细介绍每个概念。</p><ul>\n<li>六个环境变量：<code>GO111MODULE</code>、<code>GOPROXY</code>、<code>GONOPROXY</code>、<code>GOSUMDB</code>、<code>GONOSUMDB</code>、<code>GOPRIVATE</code>。</li>\n<li>两个概念：Go module proxy和Go checksum database。</li>\n<li>两个主要文件：go.mod和go.sum。</li>\n<li>一个主要管理命令：go mod。</li>\n<li>一个build flag。</li>\n</ul><h2>Go包管理的历史</h2><p>在具体讲解Go Modules之前，我们先看一下Go包管理的历史。从Go推出之后，因为没有一个统一的官方方案，所以出现了很多种Go包管理方案，比较混乱，也没有彻底解决Go包管理的一些问题。Go包管理的历史如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/34/e5/348d772b26940f721c6fb907f6833be5.jpg?wh=2248x739\" alt=\"\"></p><p>这张图展示了Go依赖包管理工具经历的几个发展阶段，接下来我会按时间顺序重点介绍下其中的五个阶段。</p><h3><strong>Go1.5版本前：GOPATH</strong></h3><p>在Go1.5版本之前，没有版本控制，所有的依赖包都放在GOPATH下。采用这种方式，无法实现包的多版本管理，并且包的位置只能局限在GOPATH目录下。如果A项目和B项目用到了同一个Go包的不同版本，这时候只能给每个项目设置一个GOPATH，将对应版本的包放在各自的GOPATH目录下，切换项目目录时也需要切换GOPATH。这些都增加了开发和实现的复杂度。</p><h3><strong>Go1.5版本：Vendoring</strong></h3><p>Go1.5推出了vendor机制，并在Go1.6中默认启用。在这个机制中，每个项目的根目录都可以有一个vendor目录，里面存放了该项目的Go依赖包。在编译Go源码时，Go优先从项目根目录的vendor目录查找依赖；如果没有找到，再去GOPATH下的vendor目录下找；如果还没有找到，就去GOPATH下找。</p><p>这种方式解决了多GOPATH的问题，但是随着项目依赖的增多，vendor目录会越来越大，造成整个项目仓库越来越大。在vendor机制下，一个中型项目的vendor目录有几百M的大小一点也不奇怪。</p><h3>“百花齐放”：多种Go依赖包管理工具出现</h3><p>这个阶段，社区也出现了很多Go依赖包管理的工具，这里我介绍三个比较有名的。</p><ul>\n<li>Godep：解决包依赖的管理工具，Docker、Kubernetes、CoreOS等Go项目都曾用过godep来管理其依赖。</li>\n<li>Govendor：它的功能比Godep多一些，通过vendor目录下的<code>vendor.json</code>文件来记录依赖包的版本。</li>\n<li>Glide：相对完善的包管理工具，通过<code>glide.yaml</code>记录依赖信息，通过<code>glide.lock</code>追踪每个包的具体修改。</li>\n</ul><p>Govendor、Glide都是在Go支持vendor之后推出的工具，Godep在Go支持vendor之前也可以使用。Go支持vendor之后，Godep也改用了vendor模式。</p><h3>Go1.9版本：Dep</h3><p>对于从0构建项目的新用户来说，Glide功能足够，是个不错的选择。不过，Golang 依赖管理工具混乱的局面最终由官方来终结了：Golang官方接纳了由社区组织合作开发的Dep，作为official experiment。在相当长的一段时间里，Dep作为标准，成为了事实上的官方包管理工具。</p><p>因为Dep已经成为了official experiment的过去时，现在我们就不必再去深究了，让我们直接去了解谁才是未来的official experiment吧。</p><h3>Go1.11版本之后：Go Modules</h3><p>Go1.11版本推出了Go Modules机制，Go Modules基于vgo演变而来，是Golang官方的包管理工具。在Go1.13版本，Go语言将Go Modules设置为默认的Go管理工具；在Go1.14版本，Go语言官方正式推荐在生产环境使用Go Modules，并且鼓励所有用户从其他的依赖管理工具迁移过来。至此，Go终于有了一个稳定的、官方的Go包管理工具。</p><p>到这里，我介绍了Go依赖包管理工具的历史，下面再来介绍下Go Modules的使用方法。</p><h2>包（package）和模块（module）</h2><p>Go程序被组织到Go包中，Go包是同一目录中一起编译的Go源文件的集合。在一个源文件中定义的函数、类型、变量和常量，对于同一包中的所有其他源文件可见。</p><p>模块是存储在文件树中的Go包的集合，并且文件树根目录有go.mod文件。go.mod文件定义了模块的名称及其依赖包，每个依赖包都需要指定导入路径和语义化版本（Semantic Versioning），通过导入路径和语义化版本准确地描述一个依赖。</p><p>这里要注意，<code>\"module\" != \"package\"</code>，模块和包的关系更像是集合和元素的关系，包属于模块，一个模块是零个或者多个包的集合。下面的代码段，引用了一些包：</p><pre><code class=\"language-go\">import (\n    // Go 标准包\n    \"fmt\"\n\n    // 第三方包\n    \"github.com/spf13/pflag\"\n\n    // 匿名包\n     _ \"github.com/jinzhu/gorm/dialects/mysql\"\n\n     // 内部包\n    \"github.com/marmotedu/iam/internal/apiserver\"\n)\n</code></pre><p>这里的<code>fmt</code>、<code>github.com/spf13/pflag</code>和<code>github.com/marmotedu/iam/internal/apiserver</code>都是Go包。Go中有4种类型的包，下面我来分别介绍下。</p><ul>\n<li>Go标准包：在Go源码目录下，随Go一起发布的包。</li>\n<li>第三方包：第三方提供的包，比如来自于github.com的包。</li>\n<li>匿名包：只导入而不使用的包。通常情况下，我们只是想使用导入包产生的副作用，即引用包级别的变量、常量、结构体、接口等，以及执行导入包的<code>init()</code>函数。</li>\n<li>内部包：项目内部的包，位于项目目录下。</li>\n</ul><p>下面的目录定义了一个模块：</p><pre><code class=\"language-bash\">$ ls hello/\ngo.mod  go.sum  hello.go  hello_test.go  world\n</code></pre><p>hello目录下有一个go.mod文件，说明了这是一个模块，该模块包含了hello包和一个子包world。该目录中也包含了一个go.sum文件，该文件供Go命令在构建时判断依赖包是否合法。这里你先简单了解下，我会在下面讲go.sum文件的时候详细介绍。</p><h2>Go Modules 命令</h2><p>Go Modules的管理命令为<code>go mod</code>，<code>go mod</code>有很多子命令，你可以通过<code>go help mod</code>来获取所有的命令。下面我来具体介绍下这些命令。</p><ul>\n<li>download：下载go.mod文件中记录的所有依赖包。</li>\n<li>edit：编辑go.mod文件。</li>\n<li>graph：查看现有的依赖结构。</li>\n<li>init：把当前目录初始化为一个新模块。</li>\n<li>tidy：添加丢失的模块，并移除无用的模块。默认情况下，Go不会移除go.mod文件中的无用依赖。当依赖包不再使用了，可以使用<code>go mod tidy</code>命令来清除它。</li>\n<li>vendor：将所有依赖包存到当前目录下的vendor目录下。</li>\n<li>verify：检查当前模块的依赖是否已经存储在本地下载的源代码缓存中，以及检查下载后是否有修改。</li>\n<li>why：查看为什么需要依赖某模块。</li>\n</ul><h2>Go Modules开关</h2><p>如果要使用Go Modules，在Go1.14中仍然需要确保Go Modules特性处在打开状态。你可以通过环境变量GO111MODULE来打开或者关闭。GO111MODULE有3个值，我来分别介绍下。</p><ul>\n<li>auto：在Go1.14版本中是默认值，在<code>$GOPATH/src</code>下，且没有包含go.mod时则关闭Go Modules，其他情况下都开启Go Modules。</li>\n<li>on：启用Go Modules，Go1.14版本推荐打开，未来版本会设为默认值。</li>\n<li>off：关闭Go Modules，不推荐。</li>\n</ul><p>所以，如果要打开Go Modules，可以设置环境变量<code>export GO111MODULE=on</code>或者<code>export GO111MODULE=auto</code>，建议直接设置<code>export GO111MODULE=on</code>。</p><p>Go Modules使用语义化的版本号，我们开发的模块在发布版本打tag的时候，要注意遵循语义化的版本要求，不遵循语义化版本规范的版本号都是无法拉取的。</p><h2>模块下载</h2><p>在执行 <code>go get</code> 等命令时，会自动下载模块。接下来，我会介绍下go命令是如何下载模块的。主要有三种下载方式：</p><ul>\n<li>通过代理下载；</li>\n<li>指定版本号下载；</li>\n<li>按最小版本下载。</li>\n</ul><h3>通过代理来下载模块</h3><p>默认情况下，Go命令从VCS（Version Control System，版本控制系统）直接下载模块，例如 GitHub、Bitbucket、Bazaar、Mercurial或者SVN。</p><p>在Go 1.13版本，引入了一个新的环境变量GOPROXY，用于设置Go模块代理（Go module proxy）。模块代理可以使Go命令直接从代理服务器下载模块。GOPROXY默认值为<code>https://proxy.golang.org,direct</code>，代理服务器可以指定多个，中间用逗号隔开，例如<code>GOPROXY=https://proxy.golang.org,https://goproxy.cn,direct</code>。当下载模块时，会优先从指定的代理服务器上下载。如果下载失败，比如代理服务器不可访问，或者HTTP返回码为<code>404</code>或<code>410</code>，Go命令会尝试从下一个代理服务器下载。</p><p>direct是一个特殊指示符，用来指示Go回源到模块的源地址(比如GitHub等)去抓取 ，当值列表中上一个Go module proxy返回404或410，Go会自动尝试列表中的下一个，遇见direct时回源，遇见EOF时终止，并抛出类似<code>invalid version: unknown revision...</code>的错误。 如果<code>GOPROXY=off</code>，则Go命令不会尝试从代理服务器下载模块。</p><p>引入Go module proxy会带来很多好处，比如：</p><ul>\n<li>国内开发者无法访问像golang.org、gopkg.in、go.uber.org这类域名，可以设置GOPROXY为国内可以访问的代理服务器，解决依赖包下载失败的问题。</li>\n<li>Go模块代理会永久缓存和存储所有的依赖，并且这些依赖一经缓存，不可更改，这也意味着我们不需要再维护一个vendor目录，也可以避免因为维护vendor目录所带来的存储空间占用。</li>\n<li>因为依赖永久存在于代理服务器，这样即使模块从互联网上被删除，也仍然可以通过代理服务器获取到。</li>\n<li>一旦将Go模块存储在Go代理服务器中，就无法覆盖或删除它，这可以保护开发者免受可能注入相同版本恶意代码所带来的攻击。</li>\n<li>我们不再需要VCS工具来下载依赖，因为所有的依赖都是通过HTTP的方式从代理服务器下载。</li>\n<li>因为Go代理通过HTTP独立提供了源代码（.zip存档）和go.mod，所以下载和构建Go模块的速度更快。因为可以独立获取go.mod（而之前必须获取整个仓库），所以解决依赖也更快。</li>\n<li>当然，开发者也可以设置自己的Go模块代理，这样开发者可以对依赖包有更多的控制，并可以预防VCS停机所带来的下载失败。</li>\n</ul><p>在实际开发中，我们的很多模块可能需要从私有仓库拉取，通过代理服务器访问会报错，这时候我们需要将这些模块添加到环境变量GONOPROXY中，这些私有模块的哈希值也不会在checksum database中存在，需要将这些模块添加到GONOSUMDB中。一般来说，我建议直接设置GOPRIVATE环境变量，它的值将作为GONOPROXY和GONOSUMDB的默认值。</p><p>GONOPROXY、GONOSUMDB和GOPRIVATE都支持通配符，多个域名用逗号隔开，例如<code>*.example.com,github.com</code>。</p><p>对于国内的Go开发者来说，目前有3个常用的GOPROXY可供选择，分别是官方、七牛和阿里云。</p><p>官方的GOPROXY，国内用户可能访问不到，所以我更推荐使用七牛的<code>goproxy.cn</code>，<code>goproxy.cn</code>是七牛云推出的非营利性项目，它的目标是为中国和世界上其他地方的Go开发者提供一个免费、可靠、持续在线，且经过 CDN 加速的模块代理。</p><h3>指定版本号下载</h3><p>通常，我们通过<code>go get</code>来下载模块，下载命令格式为<code>go get &lt;package[@version]&gt;</code>，如下表所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/63/92/63fbbf7cf8b67af85aa4e7ce76a99392.jpg?wh=2248x2048\" alt=\"\"></p><p>你可以使用<code>go get -u</code>更新package到latest版本，也可以使用<code>go get -u=patch</code>只更新小版本，例如从<code>v1.2.4</code>到<code>v1.2.5</code>。</p><h3>按最小版本下载</h3><p>一个模块往往会依赖许多其他模块，并且不同的模块也可能会依赖同一个模块的不同版本，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/00/46/00794e3487e63d9d3302bfe977af6d46.jpg?wh=2248x1212\" alt=\"\"></p><p>在上述依赖中，模块A依赖了模块B和模块C，模块B依赖了模块D，模块C依赖了模块D和模块F，模块D又依赖了模块E。并且，同模块的不同版本还依赖了对应模块的不同版本。</p><p>那么Go Modules是如何选择版本的呢？Go Modules 会把每个模块的依赖版本清单都整理出来，最终得到一个构建清单，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/4f/f2/4f83ffe8125d75764c5f8069a73966f2.jpg?wh=2248x1148\" alt=\"\"></p><p>上图中，rough list和final list的区别在于重复引用的模块 D（<code>v1.3</code>、<code>v1.4</code>），最终清单选用了D的<code>v1.4</code>版本。</p><p>这样做的主要原因有两个。第一个是语义化版本的控制。因为模块D的<code>v1.3</code>和<code>v1.4</code>版本变更都属于次版本号的变更，而在语义化版本的约束下，<code>v1.4</code>必须要向下兼容<code>v1.3</code>，因此我们要选择高版本的<code>v1.4</code>。</p><p>第二个是模块导入路径的规范。主版本号不同，模块的导入路径就不一样。所以，如果出现不兼容的情况，主版本号会改变，例如从v1变为v2，模块的导入路径也就改变了，因此不会影响v1版本。</p><h2>go.mod和go.sum介绍</h2><p>在Go Modules中，go.mod和go.sum是两个非常重要的文件，下面我就来详细介绍这两个文件。</p><h3>go.mod文件介绍</h3><p>go.mod文件是Go Modules的核心文件。下面是一个go.mod文件示例：</p><pre><code class=\"language-bash\">module github.com/marmotedu/iam\n\ngo 1.14\n\nrequire (\n\tgithub.com/AlekSi/pointer v1.1.0\n\tgithub.com/appleboy/gin-jwt/v2 v2.6.3\n\tgithub.com/asaskevich/govalidator v0.0.0-20200428143746-21a406dcc535\n\tgithub.com/gin-gonic/gin v1.6.3\n\tgithub.com/golangci/golangci-lint v1.30.0 // indirect\n\tgithub.com/google/uuid v1.0.0\n    github.com/blang/semver v3.5.0+incompatible\n    golang.org/x/text v0.3.2\n)\n\nreplace (\n    github.com/gin-gonic/gin =&gt; /home/colin/gin\n    golang.org/x/text v0.3.2 =&gt; github.com/golang/text v0.3.2\n)\n\nexclude (\n    github.com/google/uuid v1.1.0\n)\n</code></pre><p>接下来，我会从go.mod语句、go.mod版本号、go.mod文件修改方法三个方面来介绍go.mod。</p><ol>\n<li>go.mod语句</li>\n</ol><p>go.mod文件中包含了4个语句，分别是module、require、replace 和 exclude。下面我来介绍下它们的功能。</p><ul>\n<li>module：用来定义当前项目的模块路径。</li>\n<li>go：用来设置预期的Go版本，目前只是起标识作用。</li>\n<li>require：用来设置一个特定的模块版本，格式为<code>&lt;导入包路径&gt; &lt;版本&gt; [// indirect]</code>。</li>\n<li>exclude：用来从使用中排除一个特定的模块版本，如果我们知道模块的某个版本有严重的问题，就可以使用exclude将该版本排除掉。</li>\n<li>replace：用来将一个模块版本替换为另外一个模块版本。格式为 <code>$module =&gt; $newmodule</code> ，<code>$newmodule</code>可以是本地磁盘的相对路径，例如<code>github.com/gin-gonic/gin =&gt; ./gin</code>。也可以是本地磁盘的绝对路径，例如<code>github.com/gin-gonic/gin =&gt; /home/lk/gin</code>。还可以是网络路径，例如<code>golang.org/x/text v0.3.2 =&gt; github.com/golang/text v0.3.2</code>。</li>\n</ul><p>这里需要注意，虽然我们用<code>$newmodule</code>替换了<code>$module</code>，但是在代码中的导入路径仍然为<code>$module</code>。replace在实际开发中经常用到，下面的场景可能需要用到replace：</p><ul>\n<li>在开启Go Modules后，缓存的依赖包是只读的，但在日常开发调试中，我们可能需要修改依赖包的代码来进行调试，这时可以将依赖包另存到一个新的位置，并在go.mod中替换这个包。</li>\n<li>如果一些依赖包在Go命令运行时无法下载，就可以通过其他途径下载该依赖包，上传到开发构建机，并在go.mod中替换为这个包。</li>\n<li>在项目开发初期，A项目依赖B项目的包，但B项目因为种种原因没有push到仓库，这时也可以在go.mod中把依赖包替换为B项目的本地磁盘路径。</li>\n<li>在国内访问golang.org/x的各个包都需要翻墙，可以在go.mod中使用replace，替换成GitHub上对应的库，例如<code>golang.org/x/text v0.3.0 =&gt; github.com/golang/text v0.3.0</code>。</li>\n</ul><p>有一点要注意，exclude和replace只作用于当前主模块，不影响主模块所依赖的其他模块。</p><ol start=\"2\">\n<li>go.mod版本号</li>\n</ol><p>go.mod文件中有很多版本号格式，我知道在平时使用中，有很多开发者对此感到困惑。这里，我来详细说明一下。</p><ul>\n<li>如果模块具有符合语义化版本格式的tag，会直接展示tag的值，例如 <code>github.com/AlekSi/pointer v1.1.0</code> 。</li>\n<li>除了v0和v1外，主版本号必须显试地出现在模块路径的尾部，例如<code>github.com/appleboy/gin-jwt/v2 v2.6.3</code>。</li>\n<li>对于没有tag的模块，Go命令会选择master分支上最新的commit，并根据commit时间和哈希值生成一个符合语义化版本的版本号，例如<code>github.com/asaskevich/govalidator v0.0.0-20200428143746-21a406dcc535</code>。</li>\n<li>如果模块名字跟版本不符合规范，例如模块的名字为<code>github.com/blang/semver</code>，但是版本为 <code>v3.5.0</code>（正常应该是<code>github.com/blang/semver/v3</code>），go会在go.mod的版本号后加<code>+incompatible</code>表示。</li>\n<li>如果go.mod中的包是间接依赖，则会添加<code>// indirect</code>注释，例如<code>github.com/golangci/golangci-lint v1.30.0 // indirect</code>。</li>\n</ul><p>这里要注意，Go Modules要求模块的版本号格式为<code>v&lt;major&gt;.&lt;minor&gt;.&lt;patch&gt;</code>，如果<code>&lt;major&gt;</code>版本号大于1，它的版本号还要体现在模块名字中，例如模块<code>github.com/blang/semver</code>版本号增长到<code>v3.x.x</code>，则模块名应为<code>github.com/blang/semver/v3</code>。</p><p>这里再详细介绍下出现<code>// indirect</code>的情况。原则上go.mod中出现的都是直接依赖，但是下面的两种情况只要出现一种，就会在go.mod中添加间接依赖。</p><ul>\n<li>直接依赖未启用Go Modules：如果模块A依赖模块B，模块B依赖B1和B2，但是B没有go.mod文件，则B1和B2会记录到A的go.mod文件中，并在最后加上<code>// indirect</code>。</li>\n<li>直接依赖go.mod文件中缺失部分依赖：如果模块A依赖模块B，模块B依赖B1和B2，B有go.mod文件，但是只有B1被记录在B的go.mod文件中，这时候B2会被记录到A的go.mod文件中，并在最后加上<code>// indirect</code>。</li>\n</ul><ol start=\"3\">\n<li>go.mod文件修改方法</li>\n</ol><p>要修改go.mod文件，我们可以采用下面这三种方法：</p><ul>\n<li>Go命令在运行时自动修改。</li>\n<li>手动编辑go.mod文件，编辑之后可以执行<code>go mod edit -fmt</code>格式化go.mod文件。</li>\n<li>执行go mod子命令修改。</li>\n</ul><p>在实际使用中，我建议你采用第三种修改方法，和其他两种相比不太容易出错。使用方式如下：</p><pre><code class=\"language-bash\">go mod edit -fmt  # go.mod 格式化\ngo mod edit -require=golang.org/x/text@v0.3.3  # 添加一个依赖\ngo mod edit -droprequire=golang.org/x/text # require的反向操作，移除一个依赖\ngo mod edit -replace=github.com/gin-gonic/gin=/home/colin/gin # 替换模块版本\ngo mod edit -dropreplace=github.com/gin-gonic/gin # replace的反向操作\ngo mod edit -exclude=golang.org/x/text@v0.3.1 # 排除一个特定的模块版本\ngo mod edit -dropexclude=golang.org/x/text@v0.3.1 # exclude的反向操作\n</code></pre><h3>go.sum文件介绍</h3><p>Go会根据go.mod文件中记载的依赖包及其版本下载包源码，但是下载的包可能被篡改，缓存在本地的包也可能被篡改。单单一个go.mod文件，不能保证包的一致性。为了解决这个潜在的安全问题，Go Modules引入了go.sum文件。</p><p>go.sum文件用来记录每个依赖包的hash值，在构建时，如果本地的依赖包hash值与<code>go.sum</code>文件中记录的不一致，则会拒绝构建。go.sum中记录的依赖包是所有的依赖包，包括间接和直接的依赖包。</p><p>这里提示下，为了避免已缓存的模块被更改，<code>$GOPATH/pkg/mod</code>下缓存的包是只读的，不允许修改。</p><p>接下来我从go.sum文件内容、go.sum文件生成、校验三个方面来介绍go.sum。</p><ol>\n<li>go.sum文件内容</li>\n</ol><p>下面是一个go.sum文件的内容：</p><pre><code class=\"language-bash\">golang.org/x/text v0.0.0-20170915032832-14c0d48ead0c h1:qgOY6WgZOaTkIIMiVjBQcw93ERBE4m30iBm00nkL0i8=\ngolang.org/x/text v0.0.0-20170915032832-14c0d48ead0c/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\nrsc.io/quote v1.5.2 h1:w5fcysjrx7yqtD/aO+QwRjYZOKnaM9Uh2b40tElTs3Y=\nrsc.io/quote v1.5.2/go.mod h1:LzX7hefJvL54yjefDEDHNONDjII0t9xZLPXsUe+TKr0=\nrsc.io/sampler v1.3.0 h1:7uVkIFmeBqHfdjD+gZwtXXI+RODJ2Wc4O7MPEh/QiW4=\nrsc.io/sampler v1.3.0/go.mod h1:T1hPZKmBbMNahiBKFy5HrXp6adAjACjK9JXDnKaTXpA=\n</code></pre><p>go.sum文件中，每行记录由模块名、版本、哈希算法和哈希值组成，如<code>&lt;module&gt; &lt;version&gt;[/go.mod] &lt;algorithm&gt;:&lt;hash&gt;</code>。目前，从Go1.11到Go1.14版本，只有一个算法SHA-256，用h1表示。</p><p>正常情况下，每个依赖包会包含两条记录，分别是依赖包所有文件的哈希值和该依赖包go.mod的哈希值，例如：</p><pre><code class=\"language-bash\">rsc.io/quote v1.5.2 h1:w5fcysjrx7yqtD/aO+QwRjYZOKnaM9Uh2b40tElTs3Y=\nrsc.io/quote v1.5.2/go.mod h1:LzX7hefJvL54yjefDEDHNONDjII0t9xZLPXsUe+TKr0=\n</code></pre><p>但是，如果一个依赖包没有go.mod文件，就只记录依赖包所有文件的哈希值，也就是只有第一条记录。额外记录go.mod的哈希值，主要是为了在计算依赖树时不必下载完整的依赖包版本，只根据go.mod即可计算依赖树。</p><ol start=\"2\">\n<li>go.sum文件生成</li>\n</ol><p>在Go Modules开启时，如果我们的项目需要引入一个新的包，通常会执行<code>go get</code>命令，例如：</p><pre><code class=\"language-bash\">$ go get rsc.io/quote\n</code></pre><p>当执行<code>go get rsc.io/quote</code>命令后，<code>go get</code>命令会先将依赖包下载到<code>$GOPATH/pkg/mod/cache/download</code>，下载的依赖包文件名格式为<code>$version.zip</code>，例如<code>v1.5.2.zip</code>。</p><p>下载完成之后，<code>go get</code>会对该zip包做哈希运算，并将结果存在<code>$version.ziphash</code>文件中，例如<code>v1.5.2.ziphash</code>。如果在项目根目录下执行<code>go get</code>命令，则<code>go get</code>会同时更新go.mod和go.sum文件。例如，go.mod新增一行<code>require rsc.io/quote v1.5.2</code>，go.sum新增两行：</p><pre><code class=\"language-bash\">rsc.io/quote v1.5.2 h1:w5fcysjrx7yqtD/aO+QwRjYZOKnaM9Uh2b40tElTs3Y=\nrsc.io/quote v1.5.2/go.mod h1:LzX7hefJvL54yjefDEDHNONDjII0t9xZLPXsUe+TKr0=\n</code></pre><ol start=\"3\">\n<li>校验</li>\n</ol><p>在我们执行构建时，go命令会从本地缓存中查找所有的依赖包，并计算这些依赖包的哈希值，然后与go.sum中记录的哈希值进行对比。如果哈希值不一致，则校验失败，停止构建。</p><p>校验失败可能是因为本地指定版本的依赖包被修改过，也可能是go.sum中记录的哈希值是错误的。但是Go命令倾向于相信依赖包被修改过，因为当我们在go get依赖包时，包的哈希值会经过校验和数据库（checksum database）进行校验，校验通过才会被加入到go.sum文件中。也就是说，go.sum文件中记录的哈希值是可信的。</p><p>校验和数据库可以通过环境变量<code>GOSUMDB</code>指定，<code>GOSUMDB</code>的值是一个web服务器，默认值是<code>sum.golang.org</code>。该服务可以用来查询依赖包指定版本的哈希值，保证拉取到的模块版本数据没有经过篡改。</p><p>如果设置<code>GOSUMDB</code>为<code>off</code>，或者使用<code>go get</code>的时候启用了<code>-insecure</code>参数，Go就不会去对下载的依赖包做安全校验，这存在一定的安全隐患，所以我建议你开启校验和数据库。如果对安全性要求很高，同时又访问不了<code>sum.golang.org</code>，你也可以搭建自己的校验和数据库。</p><p>值得注意的是，Go checksum database可以被Go module proxy代理，所以当我们设置了<code>GOPROXY</code>后，通常情况下不用再设置<code>GOSUMDB</code>。还要注意的是，go.sum文件也应该提交到你的 Git 仓库中去。</p><h2>模块下载流程</h2><p>上面，我介绍了模块下载的整体流程，还介绍了go.mod和go.sum这两个文件。因为内容比较多，这里用一张图片来做个总结：</p><p><img src=\"https://static001.geekbang.org/resource/image/8b/8d/8b92e53cebd4373f8c41fdbe9328ba8d.jpg?wh=2248x1077\" alt=\"\"></p><p>最后还想介绍下Go&nbsp;modules的全局缓存。Go&nbsp;modules中，相同版本的模块只会缓存一份，其他所有模块公用。目前，所有模块版本数据都缓存在 <code>$GOPATH/pkg/mod</code> 和 <code>$GOPATH/pkg/sum</code> 下，未来有可能移到 <code>$GOCACHE/mod</code> 和 <code>$GOCACHE/sum</code> 下，我认为这可能发生在 <code>GOPATH</code> 被淘汰后。你可以使用 <code>go&nbsp;clean&nbsp;-modcache</code> 清除所有的缓存。</p><h2>总结</h2><p>Go依赖包管理是Go语言中一个重点的功能。在Go1.11版本之前，并没有官方的依赖包管理工具，业界虽然存在多个Go依赖包管理方案，但效果都不理想。直到Go1.11版本，Go才推出了官方的依赖包管理工具，Go Modules。这也是我建议你在进行Go项目开发时选择的依赖包管理工具。</p><p>Go Modules提供了 <code>go mod</code> 命令，来管理Go的依赖包。 <code>go mod</code> 有很多子命令，这些子命令可以完成不同的功能。例如，初始化当前目录为一个新模块，添加丢失的模块，移除无用的模块，等等。</p><p>在Go Modules中，有两个非常重要的文件：go.mod和go.sum。go.mod文件是Go Modules的核心文件，Go会根据go.mod文件中记载的依赖包及其版本下载包源码。go.sum文件用来记录每个依赖包的hash值，在构建时，如果本地的依赖包hash值与go.sum文件中记录的不一致，就会拒绝构建。</p><p>Go在下载依赖包时，可以通过代理来下载，也可以指定版本号下载。如果不指定版本号，Go Modules会根据自定义的规则，选择最小版本来下载。</p><h2>课后练习</h2><ol>\n<li>思考下，如果不提交go.sum，会有什么风险？</li>\n<li>找一个没有使用Go Modules管理依赖包的Go项目，把它的依赖包管理方式切换为Go Modules。</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"特别放送 | 给你一份Go项目中最常用的Makefile核心语法","id":389115},"right":{"article_title":"特别放送 | IAM排障指南","id":419674}}},{"article_id":419674,"article_title":"特别放送 | IAM排障指南","article_content":"<p>你好，我是孔令飞。</p><p>今天我们更新一期特别放送作为加餐。在部署和使用IAM的过程中，难免会出现一些异常(也称为故障、问题)。这时候，就需要我们能够定位故障，并修复故障。这里，我总结了一些IAM的排障方法，以及一些常见故障的解决方法，供你参考。</p><h2>如何排障？</h2><p>首先，我们需要发现问题，然后定位问题。我们可能需要经过多轮分析排查才能定位到问题的根因，最后去解决问题。排障流程如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/73/0f/7330d836e7c4b5052c79bbd365abdd0f.jpg?wh=2248x535\" alt=\"\"></p><p>如果想排查问题并解决问题，你还需要具备这两个基本能力：能够理解错误日志的内容；根据错误日志，找出解决方案。</p><p>我们举个例子来说吧。有以下错误：</p><pre><code class=\"language-bash\">[going@dev iam]$ mysql -h127.0.0.1 -uroot -p'iam59!z$'\nbash: /usr/bin/mysql: 没有那个文件或目录\n[going@dev iam]$\n</code></pre><p>对于这个错误，我们首先来理解错误内容：mysql命令没有找到，说明没有安装mysql，或者安装mysql失败。</p><p>那么，我们的解决方案就是重新执行 <a href=\"https://time.geekbang.org/column/article/378082\">03讲</a> 中安装MariaDB的步骤：</p><pre><code class=\"language-bash\">$ cd $IAM_ROOT\n$ ./scripts/install/mariadb.sh iam::mariadb::install\n</code></pre><!-- [[[read_end]]] --><p>接下来，我会以<code>iam-apiserver</code>服务为例，给你演示下具体如何排障并解决问题。</p><h3>发现问题</h3><p>要排障，首先我们需要发现问题。我们通常用下面这几种方式来发现问题。</p><ul>\n<li>检查服务状态：启动iam-apiserver服务后，执行<code>systemctl status iam-apiserver</code> 发现iam-apiserver启动失败，即<code>Active</code>的值不为<code>active (running)</code>。</li>\n<li>功能异常：访问iam-apiserver服务，功能异常或者报错，例如接口返回值跟预期不一样等。</li>\n<li>日志报错：在iam-apiserver的日志中发现一些<code>WARN</code>、<code>ERROR</code>、<code>PANIC</code>、<code>FATAL</code>等级别的错误日志。</li>\n</ul><h3>定位问题</h3><p>发现问题之后，就需要我们定位出问题的根本原因。我们可以通过下面这三种方式来定位问题。</p><ul>\n<li>查看日志，它是最简单的排障方式。</li>\n<li>使用Go调试工具Delve来定位问题。</li>\n<li>添加Debug日志，从程序入口处跟读代码，在关键位置处打印Debug日志，来定位问题。</li>\n</ul><p>在定位问题的过程中，我们可以采用“顺藤摸瓜”的思路去排查问题。比如，我们的程序执行流程是：A -&gt; B -&gt; … -&gt; N。其中A、B、N都可以理解为一个排查点。所谓的排查点，就是需要在该处定位问题的点，这些点可能是导致问题的根因所在。</p><p>在排障过程中，你可以根据最上层的日志报错，找到下一个排查点B。如果经过定位，发现B没有问题，那继续根据程序执行流程，找下一个排查点排查问题。如此反复，直到找到最终的排查点，也就是出问题的根因N，N即为Bug点。执行流程如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/cc/6d/cc26b83cb2177106695e1a9f7f09ae6d.jpg?wh=2248x931\" alt=\"\"></p><h3></h3><p>下面，我们来具体看看这三种定位问题的方法。</p><h4>查看日志定位问题</h4><p>我们首先应该通过日志来定位问题，这是最简单高效的方式。要通过日志来定位问题，你不仅要会看日志，还要能读懂日志，也就是理解日志报错的原因。</p><p>下面我来具体讲解用这种方法定位问题的步骤。</p><p><strong>第一步，确保服务运行正常。</strong></p><p>你可以通过执行 <code>systemctl status</code> 命令来查看服务的运行状况：</p><pre><code class=\"language-bash\">$ systemctl status iam-apiserver\n● iam-apiserver.service - IAM APIServer\n   Loaded: loaded (/etc/systemd/system/iam-apiserver.service; enabled; vendor preset: disabled)\n   Active: activating (auto-restart) (Result: exit-code) since Thu 2021-09-09 13:47:56 CST; 2s ago\n     Docs: https://github.com/marmotedu/iam/blob/master/init/README.md\n  Process: 119463 ExecStart=/opt/iam/bin/iam-apiserver --config=/etc/iam/iam-apiserver.yaml (code=exited, status=1/FAILURE)\n  Process: 119461 ExecStartPre=/usr/bin/mkdir -p /var/log/iam (code=exited, status=0/SUCCESS)\n  Process: 119460 ExecStartPre=/usr/bin/mkdir -p /data/iam/iam-apiserver (code=exited, status=0/SUCCESS)\n Main PID: 119463 (code=exited, status=1/FAILURE)\n</code></pre><p>可以看到，<code>Active</code>不是<code>active (running)</code>，说明iam-apiserver服务没有正常运行。从上面输出中的<code>Process: 119463 ExecStart=/opt/iam/bin/iam-apiserver --config=/etc/iam/iam-apiserver.yaml (code=exited, status=1/FAILURE)</code>信息中，我们可以获取以下信息：</p><ul>\n<li>iam-apiserver服务启动命令为<code>/opt/iam/bin/iam-apiserver --config=/etc/iam/iam-apiserver.yaml</code>。</li>\n<li><code>/opt/iam/bin/iam-apiserver</code>加载的配置文件为<code>/etc/iam/iam-apiserver.yaml</code>。</li>\n<li><code>/opt/iam/bin/iam-apiserver</code>命令执行失败，退出码为1，其进程ID为<code>119463</code>。</li>\n</ul><p>这里注意，<code>systemctl status</code>会将超过一定长度的行的后半部分用省略号替代，如果想查看完整的信息，可以追加<code>-l</code>参数，也就是<code>systemctl status -l</code>来查看。</p><p>既然iam-apiserver命令启动失败，那我们就需要查看iam-apiserver启动时的日志，看看有没有一些报错日志。</p><p>接下来，就进入<strong>第二步，查看</strong><code>iam-apiserver</code><strong>运行日志。</strong></p><p>这里提一句，如果你对systemd不了解，也可以趁机恶补一波。你可以参考阮一峰大佬的两篇博客：<a href=\"https://www.ruanyifeng.com/blog/2016/03/systemd-tutorial-commands.html\">Systemd 入门教程：命令篇</a>和<a href=\"https://www.ruanyifeng.com/blog/2016/03/systemd-tutorial-part-two.html\">Systemd 入门教程：实战篇</a>。</p><p>那么如何查看呢？我们有3种查看方式，我在下面按优先级顺序排列了下。你在定位问题和查看日志时，按优先级3选1即可，1 &gt; 2 &gt; 3。</p><ol>\n<li>通过<code>journalctl -u iam-apiserver</code>查看。</li>\n<li>通过iam-apiserver日志文件查看。</li>\n<li>通过console查看。</li>\n</ol><p>下面我来分别介绍下这三种查看方式。</p><p>先来看优先级最高的方式，通过<code>journalctl -u iam-apiserver</code>查看。</p><p>systemd 提供了自己的日志系统，称为 journal。我们可以使用<code>journalctl</code>命令来读取journal日志。<code>journalctl</code>提供了<code>-u</code>选项来查看某个 Unit 的日志，提供了<code>_PID</code>来查看指定进程ID的日志。在<strong>第一步</strong>中，我们知道服务启动失败的进程ID为<code>119463</code>。执行以下命令来查看这次启动的日志：</p><pre><code class=\"language-bash\">$ sudo journalctl _PID=119463\n-- Logs begin at Thu 2021-09-09 09:12:25 CST, end at Thu 2021-09-09 14:40:48 CST. --\n...\nSep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]: 2021-09-09 13:47:56.727        INFO        apiserver        gorm@v1.21.12/gorm.go:202        mysql/mysql.go:75[error] faile&gt;\nSep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]: 2021-09-09 13:47:56.727        FATAL        apiserver        apiserver/server.go:139        Failed to get cache instance: g&gt;\nSep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]: github.com/marmotedu/iam/internal/apiserver.(*completedExtraConfig).New\nSep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]:         /home/going/workspace/golang/src/github.com/marmotedu/iam/internal/apiserver/server.go:139\nSep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]: github.com/marmotedu/iam/internal/apiserver.createAPIServer\nSep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]:         /home/going/workspace/golang/src/github.com/marmotedu/iam/internal/apiserver/server.go:66\nSep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]: github.com/marmotedu/iam/internal/apiserver.Run\nSep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]:         /home/going/workspace/golang/src/github.com/marmotedu/iam/internal/apiserver/run.go:11\nSep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]: github.com/marmotedu/iam/internal/apiserver.run.func1\nSep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]:         /home/going/workspace/golang/src/github.com/marmotedu/iam/internal/apiserver/app.go:46\nSep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]: github.com/marmotedu/iam/pkg/app.(*App).runCommand\nSep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]:         /home/going/workspace/golang/src/github.com/marmotedu/iam/pkg/app/app.go:278\nSep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]: github.com/spf13/cobra.(*Command).execute\nSep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]:         /home/going/workspace/golang/pkg/mod/github.com/spf13/cobra@v1.2.1/command.go:856\nSep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]: github.com/spf13/cobra.(*Command).ExecuteC\nSep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]:         /home/going/workspace/golang/pkg/mod/github.com/spf13/cobra@v1.2.1/command.go:974\nSep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]: github.com/spf13/cobra.(*Command).Execute\nSep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]:         /home/going/workspace/golang/pkg/mod/github.com/spf13/cobra@v1.2.1/command.go:902\nSep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]: github.com/marmotedu/iam/pkg/app.(*App).Run\nSep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]:         /home/going/workspace/golang/src/github.com/marmotedu/iam/pkg/app/app.go:233\nSep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]: main.main\nSep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]:         /home/going/workspace/golang/src/github.com/marmotedu/iam/cmd/iam-apiserver/apiserver.go:24\nSep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]: runtime.main\nSep 09 13:47:56 VM-200-70-centos iam-apiserver[119463]:         /home/going/go/go1.16.2/src/runtime/proc.go:225\nlines 10-54/54 (END)\n</code></pre><p>从上面的日志中，我们找到了服务启动失败的原因：<code>iam-apiserver</code>启动时，发生了<code>FATAL</code>级别的错误。到这里，你已经初步定位到问题原因了。</p><p>我们再来看通过iam-apiserver日志文件查看的方式。</p><p>作为一个企业级的实战项目，iam-apiserver的日志当然是会记录到日志文件中的。在<strong>第一步</strong>中，我们通过<code>systemctl status iam-apiserver</code>输出的信息，知道了iam-apiserver启动时加载的配置文件为<code>/etc/iam/iam-apiserver.yaml</code>。所以，我们可以通过iam-apiserver的配置文件iam-apiserver.yaml中的<code>log.output-paths</code>配置项，查看记录日志文件的位置：</p><pre><code class=\"language-yaml\">log:\n    name: apiserver # Logger的名字\n    development: true # 是否是开发模式。如果是开发模式，会对DPanicLevel进行堆栈跟踪。\n    level: debug # 日志级别，优先级从低到高依次为：debug, info, warn, error, dpanic, panic, fatal。\n    format: console # 支持的日志输出格式，目前支持console和json两种。console其实就是text格式。\n    enable-color: true # 是否开启颜色输出，true:是，false:否\n    disable-caller: false # 是否开启 caller，如果开启会在日志中显示调用日志所在的文件、函数和行号\n    disable-stacktrace: false # 是否在panic及以上级别禁止打印堆栈信息\n    output-paths: /var/log/iam/iam-apiserver.log,stdout # 支持输出到多个输出，逗号分开。支持输出到标准输出（stdout）和文件。\n    error-output-paths: /var/log/iam/iam-apiserver.error.log # zap内部(非业务)错误日志输出路径，多个输出，逗号分开\n</code></pre><p>可以看到，iam-apiserver将日志分别记录到了<code>/var/log/iam/iam-apiserver.log</code>和<code>stdout</code>中。所以，我们可以通过查看<code>/var/log/iam/iam-apiserver.log</code>日志文件，来查看报错信息：</p><pre><code class=\"language-bash\">$ tail -25 /var/log/iam/iam-apiserver.log\n...\n2021-09-09 15:42:35.231\tINFO\tapiserver\tserver/genericapiserver.go:88\tGET    /version --&gt; github.com/marmotedu/iam/internal/pkg/server.(*GenericAPIServer).InstallAPIs.func2 (10 handlers)\n2021-09-09 15:42:35.232\tINFO\tapiserver\tgorm@v1.21.12/gorm.go:202\tmysql/mysql.go:75[error] failed to initialize database, got error dial tcp 127.0.0.1:3309: connect: connection refused\n2021-09-09 15:42:35.232\tFATAL\tapiserver\tapiserver/server.go:139\tFailed to get cache instance: got nil cache server\ngithub.com/marmotedu/iam/internal/apiserver.(*completedExtraConfig).New\n\t/home/going/workspace/golang/src/github.com/marmotedu/iam/internal/apiserver/server.go:139\ngithub.com/marmotedu/iam/internal/apiserver.createAPIServer\n\t/home/going/workspace/golang/src/github.com/marmotedu/iam/internal/apiserver/server.go:66\ngithub.com/marmotedu/iam/internal/apiserver.Run\n\t/home/going/workspace/golang/src/github.com/marmotedu/iam/internal/apiserver/run.go:11\ngithub.com/marmotedu/iam/internal/apiserver.run.func1\n\t/home/going/workspace/golang/src/github.com/marmotedu/iam/internal/apiserver/app.go:46\ngithub.com/marmotedu/iam/pkg/app.(*App).runCommand\n\t/home/going/workspace/golang/src/github.com/marmotedu/iam/pkg/app/app.go:278\ngithub.com/spf13/cobra.(*Command).execute\n\t/home/going/workspace/golang/pkg/mod/github.com/spf13/cobra@v1.2.1/command.go:856\ngithub.com/spf13/cobra.(*Command).ExecuteC\n\t/home/going/workspace/golang/pkg/mod/github.com/spf13/cobra@v1.2.1/command.go:974\ngithub.com/spf13/cobra.(*Command).Execute\n\t/home/going/workspace/golang/pkg/mod/github.com/spf13/cobra@v1.2.1/command.go:902\ngithub.com/marmotedu/iam/pkg/app.(*App).Run\n\t/home/going/workspace/golang/src/github.com/marmotedu/iam/pkg/app/app.go:233\nmain.main\n\t/home/going/workspace/golang/src/github.com/marmotedu/iam/cmd/iam-apiserver/apiserver.go:24\nruntime.main\n\t/home/going/go/go1.16.2/src/runtime/proc.go:225\n</code></pre><p>我们再来看最后一种查看方式，通过console查看。</p><p>当然，我们也可以直接通过console来看日志，这就需要我们在Linux终端前台运行iam-apiserver（在<strong>第一步</strong>中，我们已经知道了启动命令）：</p><pre><code class=\"language-bash\">$ sudo /opt/iam/bin/iam-apiserver --config=/etc/iam/iam-apiserver.yaml\n...\n2021-09-09 15:47:00.660\tINFO\tapiserver\tserver/genericapiserver.go:88\tGET    /debug/pprof/mutex --&gt; github.com/gin-contrib/pprof.pprofHandler.func1 (10 handlers)\n2021-09-09 15:47:00.660\tINFO\tapiserver\tserver/genericapiserver.go:88\tGET    /debug/pprof/threadcreate --&gt; github.com/gin-contrib/pprof.pprofHandler.func1 (10 handlers)\n2021-09-09 15:47:00.660\tINFO\tapiserver\tserver/genericapiserver.go:88\tGET    /version --&gt; github.com/marmotedu/iam/internal/pkg/server.(*GenericAPIServer).InstallAPIs.func2 (10 handlers)\n2021-09-09 15:47:00.661\tINFO\tapiserver\tgorm@v1.21.12/gorm.go:202\tmysql/mysql.go:75[error] failed to initialize database, got error dial tcp 127.0.0.1:3309: connect: connection refused\n2021-09-09 15:47:00.661\tFATAL\tapiserver\tapiserver/server.go:139\tFailed to get cache instance: got nil cache server\ngithub.com/marmotedu/iam/internal/apiserver.(*completedExtraConfig).New\n\t/home/going/workspace/golang/src/github.com/marmotedu/iam/internal/apiserver/server.go:139\ngithub.com/marmotedu/iam/internal/apiserver.createAPIServer\n\t/home/going/workspace/golang/src/github.com/marmotedu/iam/internal/apiserver/server.go:66\ngithub.com/marmotedu/iam/internal/apiserver.Run\n\t/home/going/workspace/golang/src/github.com/marmotedu/iam/internal/apiserver/run.go:11\ngithub.com/marmotedu/iam/internal/apiserver.run.func1\n\t/home/going/workspace/golang/src/github.com/marmotedu/iam/internal/apiserver/app.go:46\ngithub.com/marmotedu/iam/pkg/app.(*App).runCommand\n\t/home/going/workspace/golang/src/github.com/marmotedu/iam/pkg/app/app.go:278\ngithub.com/spf13/cobra.(*Command).execute\n\t/home/going/workspace/golang/pkg/mod/github.com/spf13/cobra@v1.2.1/command.go:856\ngithub.com/spf13/cobra.(*Command).ExecuteC\n\t/home/going/workspace/golang/pkg/mod/github.com/spf13/cobra@v1.2.1/command.go:974\ngithub.com/spf13/cobra.(*Command).Execute\n\t/home/going/workspace/golang/pkg/mod/github.com/spf13/cobra@v1.2.1/command.go:902\ngithub.com/marmotedu/iam/pkg/app.(*App).Run\n\t/home/going/workspace/golang/src/github.com/marmotedu/iam/pkg/app/app.go:233\nmain.main\n\t/home/going/workspace/golang/src/github.com/marmotedu/iam/cmd/iam-apiserver/apiserver.go:24\nruntime.main\n\t/home/going/go/go1.16.2/src/runtime/proc.go:225\n</code></pre><p>通过上面这3种查看方式，我们均能初步定位到服务异常的原因。</p><h4>使用Go调试工具Delve来定位问题</h4><p>查看日志是最简单的排障方式，通过查看日志，我们可能定位出问题的根本原因，这种情况下问题就能得到快速的解决。但有些情况下，我们通过日志并不一定能定位出问题，例如：</p><ul>\n<li>程序异常，但是没有错误日志。</li>\n<li>日志有报错，但只能判断问题的面，还不能精准找到问题的根因。</li>\n</ul><p>遇到上面这两种情况，我们都需要再进一步地定位问题。这时候，我们可以使用Delve调试工具来尝试定位问题。Delve工具的用法你可以参考 <a href=\"https://github.com/marmotedu/geekbang-go/blob/master/Delve%E4%BD%BF%E7%94%A8%E8%AF%A6%E8%A7%A3.md\">Delve使用详解</a>。</p><h4>添加Debug日志定位问题</h4><p>如果使用 Delve 工具仍然没有定位出问题，接下来你可以尝试最原始的方法：添加Debug日志来定位问题。这种方法具体可以分为两个步骤。</p><p><strong>第一步，在关键代码段添加Debug日志。</strong></p><p>你需要根据自己对代码的理解来决定关键代码段。如果不确定哪段代码出问题，可以从请求入口处添加Debug日志，然后跟着代码流程一步步往下排查，并在需要的地方添加Debug日志。</p><p>例如，通过排查日志，我们定位到<code>internal/apiserver/server.go:139</code>位置的代码导致程序FATAL，FATAL原因是<code>Failed to get cache instance: got nil cache server</code>。<code>cache server</code>是<code>nil</code>，说明<code>cache server</code>没有被初始化。查看<code>cache server</code>初始化函数：</p><pre><code class=\"language-go\">func GetCacheInsOr(store store.Factory) (*Cache, error) {\n    if store != nil {\n        once.Do(func() {\n            cacheServer = &amp;Cache{store}\n        })\n    }\n\n    if cacheServer == nil {\n        return nil, fmt.Errorf(\"got nil cache server\")\n    }\n\n    return cacheServer, nil\n}\n</code></pre><p>我们不难分析出，是<code>store == nil</code>导致<code>cacheServer</code>没有被初始化。再来看下store的初始化代码，并加一些Debug日志，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/cc/15/cc50c340e4ff0e5401b3d89430456b15.png?wh=1669x1025\" alt=\"图片\"></p><p>我们添加完Debug代码后，就可以重新编译并运行程序了。</p><p>这里有个小技巧：可以在错误返回的位置添加Debug日志，这样能大概率帮助你定位到出错的位置，例如：</p><pre><code class=\"language-go\">if err != nil {\n  log.Debugf(\"DEBUG POINT - 1: %v\", err)\n  return err\n}\n</code></pre><p><strong>第二步，重新编译源码，并启动。</strong></p><p>这里为了调试、看日志方便，我们直接在Linux终端的前端运行iam-apiserver：</p><pre><code class=\"language-bash\">$ sudo /opt/iam/bin/iam-apiserver --config=/etc/iam/iam-apiserver.yaml\n</code></pre><p>查看我们添加的Debug日志打印的内容，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/61/03/61f31a4b9e45ed9079470e928f7d3b03.png?wh=1920x265\" alt=\"图片\"></p><p>从Debug日志中，可以看到用来创建MySQL实例的端口是错误的，正确的端口应该是<code>3306</code>，而不是<code>3309</code>。MySQL服务器的端口是在iam-apiserver.yaml中配置的。修改iam-apiserver.yaml为正确的配置，并启动：</p><pre><code class=\"language-bash\">$ sudo /opt/iam/bin/iam-apiserver --config=/etc/iam/iam-apiserver.yaml\n</code></pre><p>再次查看console日志，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/f7/9d/f72b766b7504016259bef04eb03dac9d.png?wh=1920x271\" alt=\"图片\"></p><p>可以看到问题已经修复，<code>dbIns</code>不为<code>nil</code>，程序正常运行：</p><pre><code class=\"language-bash\">$ systemctl status iam-apiserver\n● iam-apiserver.service - IAM APIServer\n   Loaded: loaded (/etc/systemd/system/iam-apiserver.service; enabled; vendor preset: disabled)\n   Active: active (running) since Thu 2021-09-09 20:48:18 CST; 17s ago\n     Docs: https://github.com/marmotedu/iam/blob/master/init/README.md\n  Process: 255648 ExecStartPre=/usr/bin/mkdir -p /var/log/iam (code=exited, status=0/SUCCESS)\n  Process: 255647 ExecStartPre=/usr/bin/mkdir -p /data/iam/iam-apiserver (code=exited, status=0/SUCCESS)\n Main PID: 255650 (iam-apiserver)\n    Tasks: 5 (limit: 23724)\n   Memory: 7.3M\n   CGroup: /system.slice/iam-apiserver.service\n           └─255650 /opt/iam/bin/iam-apiserver --config=/etc/iam/iam-apiserver.yaml\n</code></pre><p>在这里，<code>Active</code>为<code>active (running)</code>状态。</p><p>因为这些Debug日志能够协助你定位问题，从侧面说明这些日志是有用的，所以你可以保留这些Debug日志调用代码。</p><h3>解决问题</h3><p>在定位问题阶段，我们已经找到了问题的原因，接下来就可以根据自己对业务、底层代码实现的掌握和理解，修复这个问题了。至于怎么修复，你需要结合具体情况来判断，并没有统一的流程和方法论，这里就不多介绍了。</p><p>上面，我介绍了排查问题的思路和方法。接下来，我来向你展示9个在部署和使用IAM系统时容易遇到的问题，并提供解决方法。这些问题基本上都是由服务器环境引起的。</p><h2>IAM常见故障及解决办法</h2><p><strong>问题一：</strong>安装neovim，报 <code>No match for argument: neovim</code> 错误。</p><p>解决方法是安装 EPEL 源：</p><pre><code class=\"language-bash\">$ sudo yum install https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm\n</code></pre><p><strong>问题二：</strong>安装protoc-gen-go失败（超时、报错等）。</p><p>这个故障出现，可能是因为你当前服务器所在的网络环境无法访问<code>github.com</code>，或者访问<code>github.com</code>速度太慢。</p><p>解决方法是手动编译安装，方法如下：</p><pre><code class=\"language-bash\">$ git clone --depth 1 https://github.com/golang/protobuf $GOPATH/src/github.com/golang/protobuf\n$ cd $GOPATH/src/github.com/golang/protobuf/protoc-gen-go\n$ go install -v .\n</code></pre><p><strong>问题三：</strong>遇到<code>xxx: permission denied</code>这类的错误。</p><p>出现这种错误，是因为你没有权限执行当前的操作。解决方法是排查自己是否有权限执行当前操作。如果没有权限，需要你切换到有权限的用户，或者放弃执行当前操作。</p><p>为了说明问题，这里我举一个错误例子，并给出排查思路。例子的错误日志如下：</p><pre><code class=\"language-bash\">[going@VM-8-9-centos /]$ go get -u github.com/golang/protobuf/protoc-gen-go\ngo: could not create module cache: mkdir /golang: permission denied\n[going@VM-8-9-centos /]$ sudo go get -u github.com/golang/protobuf/protoc-gen-go\nsudo: go: command not found\n</code></pre><p>上述错误中， 一共报了两个错误，分别是<code>mkdir /golang: permission denied</code>和<code>sudo: go: command not found</code>。我们先来看<code>mkdir /golang: permission denied</code>错误。</p><p>通过命令行提示符<code>$</code>可以知道，当前登陆用户是普通用户；通过报错<code>mkdir /golang: permission denied</code>可以知道<code>go get -u github.com/golang/protobuf/protoc-gen-go</code>命令底层执行了<code>mkdir /golang</code>，因为普通用户没有写<code>/</code> 目录的权限，所以会报权限错误。解决方法是切换到用户的目录下，执行<code>go get -u</code>命令。</p><p>我们再来看下<code>sudo: go: command not found</code>错误。<code>sudo</code>命令会将命令执行的环境切换到<code>root</code>用户，<code>root</code>用户显然是没有安装<code>go</code>命令的，所以会导致<code>command not found</code>错误。解决方式是去掉 <code>sudo</code> ，直接执行 <code>$ go get -u xxx</code> 。</p><p><strong>问题四：</strong>VimIDE使用过程中，报各类错误。</p><p>这里的报错原因跟环境有关系，安装VimIDE时的系统环境、包的版本等等，都可能会导致使用VimIDE报错。因为错误类型太多，没法一一说明，所以我建议你忽略这些错误，其实完全不影响后面的学习。</p><p><strong>问题五：</strong>访问iam-authz-server的<code>/v1/authz</code>接口报<code>{\"code\":100202,\"message\":\"Signature is invalid\"}</code>。</p><p>这时可能是签发的Token有问题，建议重新执行以下5个步骤：</p><ol>\n<li>重新登陆系统，并获取访问令牌：</li>\n</ol><pre><code class=\"language-bash\">$ token=`curl -s -XPOST -H'Content-Type: application/json' -d'{\"username\":\"admin\",\"password\":\"Admin@2021\"}' http://127.0.0.1:8080/login | jq -r .token`\n</code></pre><p>如果没有安装<code>jq</code>命令，可以执行<code>sudo yum -y install jq</code>命令来安装。</p><ol start=\"2\">\n<li>创建授权策略：</li>\n</ol><pre><code class=\"language-bash\">$ curl -s -XPOST -H\"Content-Type: application/json\" -H\"Authorization: Bearer $token\" -d'{\"metadata\":{\"name\":\"authztest\"},\"policy\":{\"description\":\"One policy to rule them all.\",\"subjects\":[\"users:&lt;peter|ken&gt;\",\"users:maria\",\"groups:admins\"],\"actions\":[\"delete\",\"&lt;create|update&gt;\"],\"effect\":\"allow\",\"resources\":[\"resources:articles:&lt;.*&gt;\",\"resources:printer\"],\"conditions\":{\"remoteIPAddress\":{\"type\":\"CIDRCondition\",\"options\":{\"cidr\":\"192.168.0.1/16\"}}}}}' http://127.0.0.1:8080/v1/policies\n</code></pre><ol start=\"3\">\n<li>创建密钥，并从命令的输出中提取secretID 和 secretKey：</li>\n</ol><pre><code class=\"language-bash\">$ curl -s -XPOST -H\"Content-Type: application/json\" -H\"Authorization: Bearer $token\" -d'{\"metadata\":{\"name\":\"authztest\"},\"expires\":0,\"description\":\"admin secret\"}' http://127.0.0.1:8080/v1/secrets\n{\"metadata\":{\"id\":23,\"name\":\"authztest\",\"createdAt\":\"2021-04-08T07:24:50.071671422+08:00\",\"updatedAt\":\"2021-04-08T07:24:50.071671422+08:00\"},\"username\":\"admin\",\"secretID\":\"ZuxvXNfG08BdEMqkTaP41L2DLArlE6Jpqoox\",\"secretKey\":\"7Sfa5EfAPIwcTLGCfSvqLf0zZGCjF3l8\",\"expires\":0,\"description\":\"admin secret\"}\n</code></pre><ol start=\"4\">\n<li>生成访问 iam-authz-server 的 Token</li>\n</ol><p>iamctl 提供了 <code>jwt sigin</code> 命令，你可以根据 <code>secretID</code> 和 <code>secretKey</code> 签发 Token，方便你使用。签发Token的具体命令如下：</p><pre><code class=\"language-bash\">$ iamctl jwt sign ZuxvXNfG08BdEMqkTaP41L2DLArlE6Jpqoox 7Sfa5EfAPIwcTLGCfSvqLf0zZGCjF3l8 # iamctl jwt sign $secretID $secretKey\neyJhbGciOiJIUzI1NiIsImtpZCI6Ilp1eHZYTmZHMDhCZEVNcWtUYVA0MUwyRExBcmxFNkpwcW9veCIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXV0aHoubWFybW90ZWR1LmNvbSIsImV4cCI6MTYxNzg0NTE5NSwiaWF0IjoxNjE3ODM3OTk1LCJpc3MiOiJpYW1jdGwiLCJuYmYiOjE2MTc4Mzc5OTV9.za9yLM7lHVabPAlVQLCqXEaf8sTU6sodAsMXnmpXjMQ\n</code></pre><ol start=\"5\">\n<li>测试资源授权是否通过：</li>\n</ol><pre><code class=\"language-bash\">$ curl -s -XPOST -H'Content-Type: application/json' -H'Authorization: Bearer eyJhbGciOiJIUzI1NiIsImtpZCI6Ilp1eHZYTmZHMDhCZEVNcWtUYVA0MUwyRExBcmxFNkpwcW9veCIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJpYW0uYXV0aHoubWFybW90ZWR1LmNvbSIsImV4cCI6MTYxNzg0NTE5NSwiaWF0IjoxNjE3ODM3OTk1LCJpc3MiOiJpYW1jdGwiLCJuYmYiOjE2MTc4Mzc5OTV9.za9yLM7lHVabPAlVQLCqXEaf8sTU6sodAsMXnmpXjMQ' -d'{\"subject\":\"users:maria\",\"action\":\"delete\",\"resource\":\"resources:articles:ladon-introduction\",\"context\":{\"remoteIPAddress\":\"192.168.0.5\"}}' http://127.0.0.1:9090/v1/authz\n{\"allowed\":true}\n</code></pre><p><strong>问题六：</strong>执行<code>iamctl user list</code>报<code>error: {\"code\":100207,\"message\":\"Permission denied\"}</code>。</p><p>出现这种情况，可能是密码没有配置正确。</p><p>你可以看下<code>$HOME/.iam/iamctl.yaml</code>配置文件中的用户名和密码配置的是不是admin，以及admin的密码是否是<code>Admin@2021</code>。</p><p><strong>问题七：</strong>在创建用户时报<code>{\"code\":100101,\"message\":\"Database error\"}</code>错误。</p><p>出现这种情况，可能是用户名重了，建议换个新的用户名再次创建。</p><p><strong>问题八：</strong>报<code>No such file or directory</code>、<code>command not found</code>、<code>permission denied</code>错误。</p><p>遇到这类错误，要根据提示排查和解决问题。</p><ul>\n<li><code>No such file or directory</code>：确认文件是否存在，不存在的原因是什么。</li>\n<li><code>command not found</code>：确认命令是否存在，如果不存在，可以重新安装命令。</li>\n<li><code>permission denied</code>：确认是否有操作权限，如果没有，要切换到有权限的用户或者目录。</li>\n</ul><p><strong>问题九：</strong>报<code>iam-apiserver.service</code>、<code>/opt/iam/bin/iam-apiserver</code>、<code>/etc/iam/iam-apiserver.yaml</code>文件不存在。</p><p>我来介绍下这些文件的作用。</p><ul>\n<li><code>/etc/systemd/system/iam-apiserver.service</code>：iam-apiserver的sysmted Unit文件。</li>\n<li><code>/opt/iam/bin/iam-apiserver</code>：iam-apiserver的二进制启动命令。</li>\n<li><code>/etc/iam/iam-apiserver.yaml</code>：iam-apiserver的配置文件。</li>\n</ul><p>如果某个文件不存在，那就需要你重新安装这些文件。我来分别介绍这三个文件的安装方法。</p><p><code>/etc/systemd/system/iam-apiserver.service</code>安装方法：</p><pre><code class=\"language-bash\">$ cd $IAM_ROOT\n$ ./scripts/genconfig.sh scripts/install/environment.sh init/iam-apiserver.service &gt; iam-apiserver.service\n$ sudo mv iam-apiserver.service /etc/systemd/system/\n</code></pre><p><code>/opt/iam/bin/iam-apiserver</code>安装方法：</p><pre><code class=\"language-bash\">$ cd $IAM_ROOT\n$ source scripts/install/environment.sh\n$ make build BINS=iam-apiserver\n$ sudo cp _output/platforms/linux/amd64/iam-apiserver ${IAM_INSTALL_DIR}/bin\n</code></pre><p><code>/etc/iam/iam-apiserver.yaml</code>安装方法：</p><pre><code class=\"language-bash\">$ cd $IAM_ROOT\n$ ./scripts/genconfig.sh scripts/install/environment.sh configs/iam-apiserver.yaml &gt; iam-apiserver.yaml\n$ sudo mv iam-apiserver.yaml ${IAM_CONFIG_DIR}\n</code></pre><h2>总结</h2><p>这一讲，我以<code>iam-apiserver</code>服务为例，向你介绍了排障的基本流程：发现问题 -&gt; 定位问题 -&gt; 解决问题。</p><p>你可以通过三种方式来发现问题。</p><ul>\n<li>检查服务状态：启动iam-apiserver服务后，执行<code>systemctl status iam-apiserver</code> 发现iam-apiserver启动失败，即<code>Active</code>的值不为<code>active (running)</code>。</li>\n<li>功能异常：访问iam-apiserver服务，功能异常或者报错，例如接口返回值跟预期不一样；接口报错。</li>\n<li>日志报错：在iam-apiserver的日志中发现一些<code>WARN</code>、<code>ERROR</code>、<code>PANIC</code>、<code>FATAL</code>等高级别的错误日志。</li>\n</ul><p>发现问题之后，你可以通过查看日志、使用Go调试工具Delve和添加Debug日志这三种方式来定位问题。</p><ul>\n<li>查看日志：查看日志是最简单的排障方式。</li>\n<li>使用Go调试工具Delve来定位问题。</li>\n<li>添加Debug日志：从程序入口处跟读代码，在关键位置处打印Debug日志，来定位问题。</li>\n</ul><p>找到问题根因之后，就要解决问题。你需要根据自己对业务、底层代码实现的掌握和理解，解决这个问题。</p><p>最后，我向你展示了9个在部署和使用IAM系统时容易遇到的问题，并提供了解决方法，希望能给你一些切实的帮助。</p><h2>课后练习</h2><ol>\n<li>思考下，如何查找iam-apiserver的systemd Unit文件的路径？</li>\n<li>执行以下命令：</li>\n</ol><pre><code class=\"language-bash\">$ token=`curl -s -XPOST -H'Content-Type: application/json' -d'{\"username\":\"admin\",\"password\":\"Admin@2021\"}' http://127.0.0.1:8080/login | jq -r .token`\n$ echo $token\n</code></pre><p>可以获取<code>token</code>，但发现<code>token</code>值为空。请给出你的排障流程和方法。</p><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"特别放送 | Go Modules依赖包管理全讲","id":416397},"right":{"article_title":"特别放送 | Go Modules实战","id":420325}}},{"article_id":420325,"article_title":"特别放送 | Go Modules实战","article_content":"<p>你好，我是孔令飞。</p><p>今天我们更新一期特别放送作为加餐。在 <a href=\"https://time.geekbang.org/column/article/416397\">特别放送 | Go Modules依赖包管理全讲</a>中，我介绍了Go Modules的知识，里面内容比较多，你可能还不知道具体怎么使用Go Modules来为你的项目管理Go依赖包。</p><p>这一讲，我就通过一个具体的案例，带你一步步学习Go Modules的常见用法以及操作方法，具体包含以下内容：</p><ol>\n<li>准备一个演示项目。</li>\n<li>配置Go Modules。</li>\n<li>初始化Go包为Go模块。</li>\n<li>Go包依赖管理。</li>\n</ol><h2>准备一个演示项目</h2><p>为了演示Go Modules的用法，我们首先需要一个Demo项目。假设我们有一个hello的项目，里面有两个文件，分别是hello.go和hello_test.go，所在目录为<code>/home/lk/workspace/golang/src/github.com/marmotedu/gopractise-demo/modules/hello</code>。</p><p>hello.go文件内容为：</p><pre><code class=\"language-go\">package hello\n\nfunc Hello() string {\n\treturn \"Hello, world.\"\n}\n</code></pre><p>hello_test.go文件内容为：</p><pre><code class=\"language-go\">package hello\n\nimport \"testing\"\n\nfunc TestHello(t *testing.T) {\n\twant := \"Hello, world.\"\n\tif got := Hello(); got != want {\n\t\tt.Errorf(\"Hello() = %q, want %q\", got, want)\n\t}\n}\n</code></pre><!-- [[[read_end]]] --><p>这时候，该目录包含了一个Go包，但还不是Go模块，因为没有go.mod件。接下来，我就给你演示下，如何将这个包变成一个Go模块，并执行Go依赖包的管理操作。这些操作共有10个步骤，下面我们来一步步看下。</p><h2>配置Go Modules</h2><ol>\n<li>打开Go Modules</li>\n</ol><p>确保Go版本<code>&gt;=go1.11</code>，并开启Go Modules，可以通过设置环境变量<code>export GO111MODULE=on</code>开启。如果你觉得每次都设置比较繁琐，可以将<code>export GO111MODULE=on</code>追加到文件<code>$HOME/.bashrc</code>中，并执行 <code>bash</code> 命令加载到当前shell环境中。</p><ol start=\"2\">\n<li>设置环境变量</li>\n</ol><p>对于国内的开发者来说，需要设置<code>export GOPROXY=https://goproxy.cn,direct</code>，这样一些被墙的包可以通过国内的镜像源安装。如果我们有一些模块存放在私有仓库中，也需要设置GOPRIVATE环境变量。</p><p>因为Go Modules会请求Go Checksum Database，Checksum Database国内也可能会访问失败，可以设置<code>export GOSUMDB=off</code>来关闭Checksum校验。对于一些模块，如果你希望不通过代理服务器，或者不校验<code>checksum</code>，也可以根据需要设置GONOPROXY和GONOSUMDB。</p><h2>初始化Go包为Go模块</h2><ol start=\"3\">\n<li>创建一个新模块</li>\n</ol><p>你可以通过<code>go mod init</code>命令，初始化项目为Go Modules。 <code>init</code> 命令会在当前目录初始化并创建一个新的go.mod文件，也代表着创建了一个以项目根目录为根的Go Modules。如果当前目录已经存在go.mod文件，则会初始化失败。</p><p>在初始化Go Modules时，需要告知<code>go mod init</code>要初始化的模块名，可以指定模块名，例如<code>go mod init github.com/marmotedu/gopractise-demo/modules/hello</code>。也可以不指定模块名，让<code>init</code>自己推导。下面我来介绍下推导规则。</p><ul>\n<li>如果有导入路径注释，则使用注释作为模块名，比如：</li>\n</ul><pre><code class=\"language-bash\">package hello // import \"github.com/marmotedu/gopractise-demo/modules/hello\"\n</code></pre><p>则模块名为<code>github.com/marmotedu/gopractise-demo/modules/hello</code>。</p><ul>\n<li>如果没有导入路径注释，并且项目位于GOPATH路径下，则模块名为绝对路径去掉<code>$GOPATH/src</code>后的路径名，例如<code>GOPATH=/home/lk/workspace/golang</code>，项目绝对路径为<code>/home/colin/workspace/golang/src/github.com/marmotedu/gopractise-demo/modules/hello</code>，则模块名为<code>github.com/marmotedu/gopractise-demo/modules/hello</code>。</li>\n</ul><p>初始化完成之后，会在当前目录生成一个go.mod文件：</p><pre><code class=\"language-bash\">$ cat go.mod\nmodule github.com/marmotedu/gopractise-demo/modules/hello\n\ngo 1.14\n</code></pre><p>文件内容表明，当前模块的导入路径为<code>github.com/marmotedu/gopractise-demo/modules/hello</code>，使用的Go版本是<code>go 1.14</code>。</p><p>如果要新增子目录创建新的package，则package的导入路径自动为 <code>模块名/子目录名</code> ：<code>github.com/marmotedu/gopractise-demo/modules/hello/&lt;sub-package-name&gt;</code>，不需要在子目录中再次执行<code>go mod init</code>。</p><p>比如，我们在hello目录下又创建了一个world包<code>world/world.go</code>，则world包的导入路径为<code>github.com/marmotedu/gopractise-demo/modules/hello/world</code>。</p><h2>Go包依赖管理</h2><ol start=\"4\">\n<li>增加一个依赖</li>\n</ol><p>Go Modules主要是用来对包依赖进行管理的，所以这里我们来给hello包增加一个依赖<code>rsc.io/quote</code>：</p><pre><code class=\"language-go\">package hello\n\nimport \"rsc.io/quote\"\n\nfunc Hello() string {\n\treturn quote.Hello()\n}\n</code></pre><p>运行<code>go test</code>：</p><pre><code class=\"language-bash\">$ go test\ngo: finding module for package rsc.io/quote\ngo: downloading rsc.io/quote v1.5.2\ngo: found rsc.io/quote in rsc.io/quote v1.5.2\ngo: downloading rsc.io/sampler v1.3.0\nPASS\nok  \tgithub.com/google/addlicense/golang/src/github.com/marmotedu/gopractise-demo/modules/hello\t0.003s\n</code></pre><p>当go命令在解析源码时，遇到需要导入一个模块的情况，就会去go.mod文件中查询该模块的版本，如果有指定版本，就导入指定的版本。</p><p>如果没有查询到该模块，go命令会自动根据模块的导入路径安装模块，并将模块和其最新的版本写入go.mod文件中。在我们的示例中，<code>go test</code>将模块<code>rsc.io/quote</code>解析为<code>rsc.io/quote v1.5.2</code>，并且同时还下载了<code>rsc.io/quote</code>模块的两个依赖模块：<code>rsc.io/quote</code>和<code>rsc.io/sampler</code>。只有直接依赖才会被记录到go.mod文件中。</p><p>查看go.mod文件：</p><pre><code class=\"language-bash\">module github.com/marmotedu/gopractise-demo/modules/hello\n\ngo 1.14\n\nrequire rsc.io/quote v1.5.2\n</code></pre><p>再次执行<code>go test</code>：</p><pre><code class=\"language-bash\">$ go test\nPASS\nok  \tgithub.com/marmotedu/gopractise-demo/modules/hello\t0.003s\n</code></pre><p>当我们再次执行<code>go test</code>时，不会再下载并记录需要的模块，因为go.mod目前是最新的，并且需要的模块已经缓存到了本地的<code>$GOPATH/pkg/mod</code>目录下。可以看到，在当前目录还新生成了一个go.sum文件：</p><pre><code class=\"language-bash\">$ cat go.sum\ngolang.org/x/text v0.0.0-20170915032832-14c0d48ead0c h1:qgOY6WgZOaTkIIMiVjBQcw93ERBE4m30iBm00nkL0i8=\ngolang.org/x/text v0.0.0-20170915032832-14c0d48ead0c/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\nrsc.io/quote v1.5.2 h1:w5fcysjrx7yqtD/aO+QwRjYZOKnaM9Uh2b40tElTs3Y=\nrsc.io/quote v1.5.2/go.mod h1:LzX7hefJvL54yjefDEDHNONDjII0t9xZLPXsUe+TKr0=\nrsc.io/sampler v1.3.0 h1:7uVkIFmeBqHfdjD+gZwtXXI+RODJ2Wc4O7MPEh/QiW4=\nrsc.io/sampler v1.3.0/go.mod h1:T1hPZKmBbMNahiBKFy5HrXp6adAjACjK9JXDnKaTXpA=\n</code></pre><p><code>go test</code>在执行时，还可以添加<code>-mod</code>选项，比如<code>go test -mod=vendor</code>。<code>-mod</code>有3个值，我来分别介绍下。</p><ul>\n<li>readonly：不更新go.mod，任何可能会导致go.mod变更的操作都会失败。通常用来检查go.mod文件是否需要更新，例如用在CI或者测试场景。</li>\n<li>vendor：从项目顶层目录下的vendor中导入包，而不是从模块缓存中导入包，需要确保vendor包完整准确。</li>\n<li>mod：从模块缓存中导入包，即使项目根目录下有vendor目录。</li>\n</ul><p>如果<code>go test</code>执行时没有<code>-mod</code>选项，并且项目根目录存在vendor目录，go.mod中记录的go版本大于等于<code>1.14</code>，此时<code>go test</code>执行效果等效于<code>go test -mod=vendor</code>。<code>-mod</code>标志同样适用于go build、go install、go run、go test、go list、go vet命令。</p><ol start=\"5\">\n<li>查看所有依赖模块</li>\n</ol><p>我们可以通过<code>go list -m all</code>命令查看所有依赖模块：</p><pre><code class=\"language-bash\">$ go list -m all\ngithub.com/marmotedu/gopractise-demo/modules/hello\ngolang.org/x/text v0.0.0-20170915032832-14c0d48ead0c\nrsc.io/quote v1.5.2\nrsc.io/sampler v1.3.0\n</code></pre><p>可以看出，除了<code>rsc.io/quote v1.5.2</code>外，还间接依赖了其他模块。</p><ol start=\"6\">\n<li>更新依赖</li>\n</ol><p>通过<code>go list -m all</code>，我们可以看到模块依赖的<code>golang.org/x/text</code>模块版本是<code>v0.0.0</code>，我们可以通过<code>go get</code>命令，将其更新到最新版本，并观察测试是否通过：</p><pre><code class=\"language-bash\">$ go get golang.org/x/text\ngo: golang.org/x/text upgrade =&gt; v0.3.3\n$ go test\nPASS\nok  \tgithub.com/marmotedu/gopractise-demo/modules/hello\t0.003s\n</code></pre><p><code>go test</code>命令执行后输出PASS说明升级成功，再次看下<code>go list -m all</code>和go.mod文件：</p><pre><code class=\"language-bash\">$ go list -m all\ngithub.com/marmotedu/gopractise-demo/modules/hello\ngolang.org/x/text v0.3.3\ngolang.org/x/tools v0.0.0-20180917221912-90fa682c2a6e\nrsc.io/quote v1.5.2\nrsc.io/sampler v1.3.0\n$ cat go.mod\nmodule github.com/marmotedu/gopractise-demo/modules/hello\n\ngo 1.14\n\nrequire (\n\tgolang.org/x/text v0.3.3 // indirect\n\trsc.io/quote v1.5.2\n)\n</code></pre><p>可以看到，<code>golang.org/x/text</code>包被更新到最新的tag版本(<code>v0.3.3</code>)，并且同时更新了go.mod文件。<code>// indirect</code>说明<code>golang.org/x/text</code>是间接依赖。现在我们再尝试更新<code>rsc.io/sampler</code>并测试：</p><pre><code class=\"language-bash\">$ go get rsc.io/sampler\ngo: rsc.io/sampler upgrade =&gt; v1.99.99\ngo: downloading rsc.io/sampler v1.99.99\n$ go test\n--- FAIL: TestHello (0.00s)\n    hello_test.go:8: Hello() = \"99 bottles of beer on the wall, 99 bottles of beer, ...\", want \"Hello, world.\"\nFAIL\nexit status 1\nFAIL\tgithub.com/marmotedu/gopractise-demo/modules/hello\t0.004s\n</code></pre><p>测试失败，说明最新的版本<code>v1.99.99</code>与我们当前的模块不兼容，我们可以列出<code>rsc.io/sampler</code>所有可用的版本，并尝试更新到其他版本：</p><pre><code class=\"language-bash\">$ go list -m -versions rsc.io/sampler\nrsc.io/sampler v1.0.0 v1.2.0 v1.2.1 v1.3.0 v1.3.1 v1.99.99\n\n# 我们尝试选择一个次新的版本v1.3.1\n$ go get rsc.io/sampler@v1.3.1\ngo: downloading rsc.io/sampler v1.3.1\n$ go test\nPASS\nok  \tgithub.com/marmotedu/gopractise-demo/modules/hello\t0.004s\n</code></pre><p>可以看到，更新到<code>v1.3.1</code>版本，测试是通过的。<code>go get</code>还支持多种参数，如下表所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/2b/f6/2b80e94c1e91bb18dea9c20695b25bf6.jpg?wh=2248x1496\" alt=\"\"></p><ol start=\"7\">\n<li>添加一个新的major版本依赖</li>\n</ol><p>我们尝试添加一个新的函数<code>func Proverb</code>，该函数通过调用<code>rsc.io/quote/v3</code>的<code>quote.Concurrency</code>函数实现。</p><p>首先，我们在hello.go文件中添加新函数：</p><pre><code class=\"language-go\">package hello\n\nimport (\n\t\"rsc.io/quote\"\n\tquoteV3 \"rsc.io/quote/v3\"\n)\n\nfunc Hello() string {\n\treturn quote.Hello()\n}\n\nfunc Proverb() string {\n\treturn quoteV3.Concurrency()\n}\n</code></pre><p>在hello_test.go中添加该函数的测试用例：</p><pre><code class=\"language-go\">func TestProverb(t *testing.T) {\n    want := \"Concurrency is not parallelism.\"\n    if got := Proverb(); got != want {\n        t.Errorf(\"Proverb() = %q, want %q\", got, want)\n    }\n}\n</code></pre><p>然后执行测试：</p><pre><code class=\"language-bash\">$ go test\ngo: finding module for package rsc.io/quote/v3\ngo: found rsc.io/quote/v3 in rsc.io/quote/v3 v3.1.0\nPASS\nok  \tgithub.com/marmotedu/gopractise-demo/modules/hello\t0.003s\n</code></pre><p>测试通过，可以看到当前模块同时依赖了同一个模块的不同版本<code>rsc.io/quote</code>和<code>rsc.io/quote/v3</code>：</p><pre><code class=\"language-bash\">$ go list -m rsc.io/q...\nrsc.io/quote v1.5.2\nrsc.io/quote/v3 v3.1.0\n</code></pre><ol start=\"8\">\n<li>升级到不兼容的版本</li>\n</ol><p>在上一步中，我们使用<code>rsc.io/quote v1</code>版本的<code>Hello()</code>函数。按照语义化版本规则，如果我们想升级<code>major</code>版本，可能面临接口不兼容的问题，需要我们变更代码。我们来看下<code>rsc.io/quote/v3</code>的函数：</p><pre><code class=\"language-bash\">$ go doc rsc.io/quote/v3\npackage quote // import \"github.com/google/addlicense/golang/pkg/mod/rsc.io/quote/v3@v3.1.0\"\n\nPackage quote collects pithy sayings.\n\nfunc Concurrency() string\nfunc GlassV3() string\nfunc GoV3() string\nfunc HelloV3() string\nfunc OptV3() string\n</code></pre><p>可以看到，<code>Hello()</code>函数变成了<code>HelloV3()</code>，这就需要我们变更代码做适配。因为我们都统一模块到一个版本了，这时候就不需要再为了避免重名而重命名模块，所以此时hello.go内容为：</p><pre><code class=\"language-go\">package hello\n\nimport (\n\t\"rsc.io/quote/v3\"\n)\n\nfunc Hello() string {\n\treturn quote.HelloV3()\n}\n\nfunc Proverb() string {\n\treturn quote.Concurrency()\n}\n</code></pre><p>执行<code>go test</code>：</p><pre><code class=\"language-bash\">$ go test\nPASS\nok  \tgithub.com/marmotedu/gopractise-demo/modules/hello\t0.003s\n</code></pre><p>可以看到测试成功。</p><ol start=\"9\">\n<li>删除不使用的依赖</li>\n</ol><p>在上一步中，我们移除了<code>rsc.io/quote</code>包，但是它仍然存在于<code>go list -m all</code>和go.mod中，这时候我们要执行<code>go mod tidy</code>清理不再使用的依赖：</p><pre><code class=\"language-bash\">$ go mod tidy\n[colin@dev hello]$ cat go.mod\nmodule github.com/marmotedu/gopractise-demo/modules/hello\n\ngo 1.14\n\nrequire (\n\tgolang.org/x/text v0.3.3 // indirect\n\trsc.io/quote/v3 v3.1.0\n\trsc.io/sampler v1.3.1 // indirect\n)\n</code></pre><ol start=\"10\">\n<li>使用vendor</li>\n</ol><p>如果我们想把所有依赖都保存起来，在Go命令执行时不再下载，可以执行<code>go mod vendor</code>，该命令会把当前项目的所有依赖都保存在项目根目录的vendor目录下，也会创建<code>vendor/modules.txt</code>文件，来记录包和模块的版本信息：</p><pre><code class=\"language-bash\">$ go mod vendor\n$ ls\ngo.mod  go.sum  hello.go  hello_test.go  vendor  world\n</code></pre><p>到这里，我就讲完了Go依赖包管理常用的10个操作。</p><h2>总结</h2><p>这一讲中，我详细介绍了如何使用Go Modules来管理依赖，它包括以下Go Modules操作：</p><ol>\n<li>打开Go Modules；</li>\n<li>设置环境变量；</li>\n<li>创建一个新模块；</li>\n<li>增加一个依赖；</li>\n<li>查看所有依赖模块；</li>\n<li>更新依赖；</li>\n<li>添加一个新的major版本依赖；</li>\n<li>升级到不兼容的版本；</li>\n<li>删除不使用的依赖。</li>\n<li>使用vendor。</li>\n</ol><h2>课后练习</h2><ol>\n<li>\n<p>思考下，如何更新项目的所有依赖到最新的版本？</p>\n</li>\n<li>\n<p>思考下，如果我们的编译机器访问不了外网，如何通过Go Modules下载Go依赖包？</p>\n</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>","neighbors":{"left":{"article_title":"特别放送 | IAM排障指南","id":419674},"right":{"article_title":"特别放送 | 分布式作业系统设计和实现","id":469884}}},{"article_id":469884,"article_title":"特别放送 | 分布式作业系统设计和实现","article_content":"<p>你好，我是孔令飞，我们又见面了。结课并不意味着结束，我非常高兴能持续把好的内容分享给你，也希望你能继续在留言区与我保持交流，分享你的学习心得和实践经验。</p><p>今天这一讲，我们来聊聊如何设计分布式作业系统。在实际的Go项目开发中，我们经常会遇到下面这两个功能需求：</p><ul>\n<li>想定时执行某个任务，例如在每天上午10:00清理数据库中的无用数据。</li>\n<li>轮训数据库表的某个字段，根据字段的状态，进行一些异步的业务逻辑处理。比如，监听到 <code>table_xxx.status = 'pending'</code> 时，执行异步的初始化流程，完成之后设置 <code>table_xxx.status='normal'</code> 。</li>\n</ul><p>这两个在Go项目开发中非常常见、基础的功能需求，通常可以通过作业系统来实现。IAM为了解决这种常见的功能需求，也开发了自己的作业系统。今天这一讲，我们就来看下IAM是如何实现作业系统的。</p><h2>任务分类</h2><p>在介绍作业系统之前，这里先来看下任务的分类。理解任务的分类，有助于我们理解作业系统执行的任务类型，进而有助于我们设计作业系统。</p><p>在我看来，任务可以分为下面3类。</p><ul>\n<li>定时任务：定时任务会在指定的时间点固定执行。只要到达执行任务的时间点，就会执行任务，而<strong>不管上一次任务是否完成</strong>。</li>\n<li>间隔任务：<strong>上一次任务执行完</strong>，间隔一段时间（如5秒、5分钟），再继续执行下一次任务。</li>\n<li>间隔性定时任务：间隔任务的变种，从上一次任务开始执行时计时，<strong>只要间隔时间一到</strong>，便执行下一次任务，而<strong>不管上一次任务是否完成</strong>。</li>\n</ul><!-- [[[read_end]]] --><p>定时任务好理解，但间隔任务和间隔性定时任务不太好区分，它们的区别是：间隔任务会等待上一次任务执行完，间隔一段时间再执行下一次任务。而间隔性定时任务不会等待上一次任务执行完，只要间隔时间一到，便执行下一次任务。</p><p>三者的区别如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/cf/dd/cf323871d6946c31a82de6679c1178dd.jpg?wh=1920x1266\" alt=\"图片\"></p><p>在实际的项目开发中，我们经常会遇到这3类任务的需求。</p><h2>作业系统的常见实现</h2><p>在开始介绍IAM作业系统实现之前，有必要先介绍一下如何执行一个间隔/定时任务。只有了解了这些，才能更好地设计IAM的作业系统。通常来说，我们可以通过以下4种方式，来执行一个间隔/定时任务：</p><ol>\n<li>基于<code>time</code> 包提供的方法（例如<code>time.Sleep</code>、<code>time.Ticker</code>等 ）自己开发执行间隔/定时任务的服务。</li>\n<li>一些Go包支持执行间隔/定时任务，可以直接使用这些Go包来执行间隔/定时任务，免去了自己开发作业调度部分的代码，例如<code>github.com/robfig/cron</code> 。</li>\n<li>借助Linux的crontab执行定时任务。</li>\n<li>使用开源的作业系统，并通过作业系统来执行间隔/定时任务，例如 <a href=\"https://github.com/distribworks/dkron\">distribworks/dkron</a>。</li>\n</ol><p>上述4种方法，每一种都有自己的优缺点。采用第一种方法的话，因为一切都要从0开始实现，开发工作量大、开发效率低。我认为，因为已经有很多优秀的cron包可供使用了，没必要自己从0开发，可以直接使用这些cron包来执行周期/定时任务。IAM项目便采用了这种方法。</p><p>接下来，我先介绍下第三种和第四种方法：使用Linux crontab和使用开源的Go作业系统。然后，我们再来重点看看IAM项目采用的第二种方法。</p><h3>Linux crontab</h3><p>crontab是Linux系统自带的定时执行工具，可以在无需人工干预的情况下运行作业。crontab通过crond进程来提供服务，crond进程每分钟会定期检查是否有要执行的任务，如果有，则自动执行该任务。crond进程通过读取crontab配置，来判断是否有任务执行，以及何时执行。</p><p>crond进程会在下面这3个位置查找crontab配置文件。</p><ul>\n<li><code>/var/spool/cron/</code>：该目录存放用户（包括root）的crontab任务，每个任务以登录名命名，比如 <code>colin</code> 用户创建的crontab任务对应的文件就是<code>/var/spool/cron/colin</code>。</li>\n<li><code>/etc/crontab</code>：该目录存放由系统管理员创建并维护的crontab任务。</li>\n<li><code>/etc/cron.d/</code>：该目录存放任何要执行的crontab任务。cron进程执行时，会自动扫描该目录下的所有文件，按照文件中的时间设定执行后面的命令。</li>\n</ul><p>可以看到，如果想执行一个crontab任务，就需要确保crond运行，并配置crontab任务。具体分为以下两步：</p><p><strong>第一步，确保crond进程正在运行。</strong></p><p>执行以下命令，查看crond进程运行状态：</p><pre><code class=\"language-bash\">$ systemctl status crond\n● crond.service - Command Scheduler\n   Loaded: loaded (/usr/lib/systemd/system/crond.service; enabled; vendor preset: enabled)\n   Active: active (running) since Wed 2021-11-17 07:11:27 CST; 2 days ago\n Main PID: 9182 (crond)\n    Tasks: 1\n   Memory: 728.0K\n   CGroup: /system.slice/crond.service\n           └─9182 /usr/sbin/crond -n\n</code></pre><p><code>Active: active (running)</code>说明crond进程正在运行，否则可以执行<code>systemctl start crond</code>启动crond进程。</p><p><strong>第二步，配置crontab任务。</strong></p><p>可以通过<code>crontab -e</code>来编辑配置文件，例如执行<code>crontab -e</code>后进入vi交互界面，并配置以下crontab任务：</p><pre><code class=\"language-bash\"># 每分钟输出时间到文件 /tmp/test.txt\n*  *  *  *  * echo `date` &gt;&gt; /tmp/test.txt\n\n# 每隔 2 分钟同步一次互联网时间\n*/2 * * * * /usr/bin/ntpstat time.windows.com &gt; /dev/null 2&gt;&amp;1\n</code></pre><p>编辑后的配置文件保存在<code>/var/spool/cron/$USER</code>文件中。你可以通过<code>crontab -l</code>或者<code>sudo cat /var/spool/cron/$USER</code>来查看，例如：</p><pre><code class=\"language-bash\">$ crontab -l\n# 每分钟输出时间到文件/tmp/test.txt\n*  *  *  *  * echo `date` &gt;&gt; /tmp/test.txt\n\n# 每隔 2 分钟同步一次互联网时间\n*/2 * * * * /usr/bin/ntpstat time.windows.com &gt; /dev/null 2&gt;&amp;1\n</code></pre><p>如果想删除所有的crontab任务，你可以执行<code>crontab -r</code>命令。</p><p>配置的crontab任务需要遵循crontab的时间格式，格式如下：</p><pre><code class=\"language-bash\">.---------------- minute (0 - 59)    \n|  .------------- hour (0 - 23)    \n|  |  .---------- day of month (1 - 31)    \n|  |  |  .------- month (1 - 12) OR jan,feb,mar,apr ...    \n|  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat    \n|  |  |  |  |    \n*  *  *  *  * &lt;command to be executed&gt;\n</code></pre><p>可以看到，crontab只能精确到分钟，不能精确到秒。</p><p>下面是一些常用的crontab时间格式，你可以参考，来加深理解：</p><pre><code class=\"language-bash\"># 每分钟执行一次 &lt;command&gt;            \n* * * * * &lt;command&gt; # * 代表所有可能的值\n\n# 每隔一小时执行一次 &lt;command&gt;\n* */1 * * * &lt;command&gt; # / 表示频率\n\n# 每小时的 15 和 30 分各执行一次 &lt;command&gt;\n15,45 * * * * &lt;command&gt; # , 表示并列\n\n# 在每天上午 8- 11 时中间每小时 15，45 分各执行一次 &lt;command&gt;\n15,45 8-11 * * * &lt;command&gt; # - 表示范围\n\n# 每个星期一的上午 8 点到 11 点的第 3 和第 15 分钟执行一次 &lt;command&gt;\n3,15 8-11 * * 1 &lt;command&gt;\n\n# 每隔两天的上午 8 点到 11 点的第 3 和第 15 分钟执行一次 &lt;command&gt;\n3,15 8-11 */2 * * &lt;command&gt;\n</code></pre><p>使用crontab执行周期/定时任务的优点是不用做任何开发，只需要配置crontab任务即可。至于缺点也很明显，主要有下面这几个：</p><ul>\n<li>不能精确到秒。</li>\n<li><command></command> 需要手动编写可执行命令。这些可执行命令跟项目分离，没办法复用项目提供的包、函数等能力。如果想执行跟项目关系紧密的作业，开发起来不方便。</li>\n<li>单点，如果crond进程异常，周期/定时任务就没法继续执行。你可能想说：可以在两台机器上配置并执行相同的周期/定时任务。但是这样做会有问题，因为两台机器同时执行相同的任务，可能会彼此造成冲突或状态不一致。</li>\n<li>没办法实现间隔任务和间隔性定时任务。</li>\n</ul><h3>使用开源的作业系统</h3><p>除了使用Linux系统自带的crontab之外，我们还可以使用一些业界优秀的开源作业系统。这里，我列出了一些比较受欢迎的Go语言开发的作业系统。之所以只选择Go语言开发的项目，一方面是想丰富你的Go语言生态，另一方面，同种语言也有助于你学习、改造这些项目。</p><ul>\n<li><a href=\"https://github.com/distribworks/dkron\">distribworks/dkron</a>。dkron是一个分布式、启动迅速、带容错机制的定时作业系统，支持crontab表达式。它具有下面这些核心特性。\n<ul>\n<li>易用：可以通过易操作、漂亮的Web界面来管理作业。</li>\n<li>可靠：具备容错机制，一个节点不可用，其他节点可继续执行作业。</li>\n<li>高可扩展性：能够处理大量的计划作业和数千个节点。</li>\n</ul>\n</li>\n<li><a href=\"https://github.com/ouqiang/gocron\">ouqiang/gocron</a>。gocron是国人开发的轻量级定时任务集中调度和管理系统, 用于替代Linux-crontab。它具有下面这些核心特性。\n<ul>\n<li>具有Web界面管理定时任务。</li>\n<li>支持crontab时间格式，并精确到秒。</li>\n<li>支持shell命令和HTTP请求两种任务格式。</li>\n<li>具有任务超时机制、任务依赖机制、任务执行失败可重试机制。</li>\n<li>支持查看任务执行日志，并支持用邮件、Slack、Webhook等方式通知任务执行结果。</li>\n</ul>\n</li>\n<li><a href=\"https://github.com/shunfei/cronsun\">shunfei/cronsun</a>。cronsun 是一个分布式作业系统，单个节点同 crontab 近似。它具有下面这些核心特性。\n<ul>\n<li>具有Web界面，方便对多台服务器上的定时任务进行集中式管理。</li>\n<li>任务调度时间粒度支持到秒级别。</li>\n<li>任务执行失败可重试。</li>\n<li>任务可靠性保障（从N个节点里面挑一个可用节点来执行任务）。</li>\n<li>任务日志查看。</li>\n<li>任务失败邮件告警（也支持自定义http告警接口）。</li>\n</ul>\n</li>\n</ul><p>那么，这么多的开源项目该如何选择呢？这里建议你选择 <code>distribworks/dkron</code> 。原因是 <code>distribworks/dkron</code>  Star数很多，而且功能齐全易用、文档丰富。当然，在实际开发中，你最好也对其他开源项目进行调研，根据需要选择一个最适合自己的开源项目。</p><p>使用这些作业系统的优点是不用开发、功能比crontab更强大，有些还是分布式的作业系统，具备容灾能力。但缺点也很明显：</p><ul>\n<li>这些作业系统支持的任务种类有限，比如一般会支持通过shell脚本及发送HTTP请求的方式来执行任务。不管哪种方式，实现都跟项目分离，在开发跟项目结合紧密的任务插件时不是很简单、高效。</li>\n<li>很多时候我们只会使用其中一部分能力，或者仅有一到两个项目会使用到这类系统，但我们还要部署并维护这些作业系统，工作量大，收益小。</li>\n<li>没办法实现间隔任务。</li>\n</ul><p>使用Linux的crontab和使用开源的Go作业系统，这两种方法的缺点都很明显。鉴于这些缺点，IAM系统选择使用现有的cron库封装自己的任务框架，并基于这个框架开发任务。IAM项目选择了<a href=\"https://github.com/robfig/cron\">robfig/cron</a>库，原因是cron库Star数最多，且功能丰富、使用简单。另外IAM还使用<code>github.com/go-redsync/redsync</code>实现了基于Redis的分布式互斥锁。所以，在开始介绍IAM作业系统实现前，我先来简单介绍下如何使用这两个包。</p><h2><code>github.com/robfig/cron</code>使用介绍</h2><p><code>github.com/robfig/cron</code>是一个可以实现类似Linux crontab定时任务的cron包，但是cron包支持到秒。</p><h3>cron包支持的时间格式</h3><p>cron包支持crontab格式和固定间隔格式这两种时间格式，下面我来分别介绍下。</p><p>crontab格式的时间格式，支持的匹配符跟crontab保持一致。时间格式如下：</p><pre><code class=\"language-bash\"> ┌─────────────second 范围 (0 - 60)\n │ ┌───────────── min (0 - 59)\n │ │ ┌────────────── hour (0 - 23)\n │ │ │ ┌─────────────── day of month (1 - 31)\n │ │ │ │ ┌──────────────── month (1 - 12)\n │ │ │ │ │ ┌───────────────── day of week (0 - 6) (0 to 6 are Sunday to\n │ │ │ │ │ │                  Saturday)\n │ │ │ │ │ │\n │ │ │ │ │ │\n * * * * * *   \n</code></pre><p>第二种是固定间隔格式，例如<code>@every &lt;duration&gt;</code>。<code>duration</code>是一个可以被<code>time.ParseDuration</code>解析的字符串，例如<code>@every 1h30m10s</code>表示任务每隔1小时30分10秒会被执行。这里要注意，间隔不考虑任务的运行时间。例如，如果任务需要3分钟运行，并且计划每5分钟运行一次，则每次运行之间只有2分钟的空闲时间。</p><h3>cron包使用示例</h3><p>cron包的使用方法也很简单，下面是一个简单的使用示例：</p><pre><code class=\"language-go\">package main\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/robfig/cron/v3\"\n)\n\nfunc helloCron() {\n\tfmt.Println(\"hello cron\")\n}\n\nfunc main() {\n\tfmt.Println(\"starting go cron...\")\n\n\t// 创建一个cron实例\n\tcron := cron.New(cron.WithSeconds(), cron.WithChain(cron.SkipIfStillRunning(nil), cron.Recover(nil)))\n\n\t// 添加一个定时任务\n\tcron.AddFunc(\"*  *  *  *  *  *\", helloCron)\n\n\t// 启动计划任务\n\tcron.Start()\n\n\t// 关闭着计划任务, 但是不能关闭已经在执行中的任务.\n\tdefer cron.Stop()\n\n\tselect {} // 查询语句，保持程序运行，在这里等同于for{}\n}\n</code></pre><p>在上面的代码中，通过 <code>cron.New</code> 函数调用创建了一个 <code>cron</code> 实例；接下来通过 <code>cron</code> 实例的 <code>AddFunc</code> 方法，给 <code>cron</code> 实例添加了一个定时任务：每分钟执行一次 <code>helloCron</code> 函数；最后通过 <code>cron</code> 实例的 <code>Start</code> 方法启动定时任务。在程序退出时，还执行了 <code>cron.Stop()</code> 关闭定时任务。</p><h3>拦截器</h3><p>cron包还支持安装一些拦截器，这些拦截器可以实现以下功能：</p><ul>\n<li>从任务的panic中恢复（<code>cron.Recover()</code>）。</li>\n<li>如果上一次任务尚未完成，则延迟下一次任务的执行（<code>cron.DelayIfStillRunning()</code>）。</li>\n<li>如果上一次任务尚未完成，则跳过下一次任务的执行（<code>cron.SkipIfStillRunning()</code>）。</li>\n<li>记录每个任务的调用（<code>cron.WithLogger()</code>）。</li>\n<li>任务完成时通知。</li>\n</ul><p>如果想使用这些拦截器，只需要在创建cron实例时，传入相应的Option即可，例如：</p><pre><code class=\"language-go\">cron := cron.New(cron.WithSeconds(), cron.WithChain(cron.SkipIfStillRunning(nil), cron.Recover(nil)))\n</code></pre><h2><code>github.com/go-redsync/redsync</code>使用介绍</h2><p>redsync可以实现基于Redis的分布式锁，使用起来也比较简单，我们直接来看一个使用示例：</p><pre><code class=\"language-go\">package main\n\nimport (\n\tgoredislib \"github.com/go-redis/redis/v8\"\n\t\"github.com/go-redsync/redsync/v4\"\n\t\"github.com/go-redsync/redsync/v4/redis/goredis/v8\"\n)\n\nfunc main() {\n\t// Create a pool with go-redis (or redigo) which is the pool redisync will\n\t// use while communicating with Redis. This can also be any pool that\n\t// implements the `redis.Pool` interface.\n\tclient := goredislib.NewClient(&amp;goredislib.Options{\n\t\tAddr: \"localhost:6379\",\n\t})\n\tpool := goredis.NewPool(client) // or, pool := redigo.NewPool(...)\n\n\t// Create an instance of redisync to be used to obtain a mutual exclusion\n\t// lock.\n\trs := redsync.New(pool)\n\n\t// Obtain a new mutex by using the same name for all instances wanting the\n\t// same lock.\n\tmutexname := \"my-global-mutex\"\n\tmutex := rs.NewMutex(mutexname)\n\n\t// Obtain a lock for our given mutex. After this is successful, no one else\n\t// can obtain the same lock (the same mutex name) until we unlock it.\n\tif err := mutex.Lock(); err != nil {\n\t\tpanic(err)\n\t}\n\n\t// Do your work that requires the lock.\n\n\t// Release the lock so other processes or threads can obtain a lock.\n\tif ok, err := mutex.Unlock(); !ok || err != nil {\n\t\tpanic(\"unlock failed\")\n\t}\n}\n</code></pre><p>上面的代码，创建了一个 <code>redsync.Redsync</code> 实例，并使用 <code>redsync.Redsync</code> 提供的 <code>NewMutex</code> 方法，创建了一个分布式锁实例 <code>mutex</code>。通过 <code>mutex.Lock()</code> 加锁，通过 <code>mutex.Unlock()</code> 释放锁。</p><h2>IAM作业系统特点</h2><p>在开发IAM的作业系统之前，我们需要先梳理好IAM要实现的任务。IAM需要实现以下两个间隔任务：</p><ul>\n<li>每隔一段时间从 <code>policy_audit</code> 表中清理超过指定天数的授权策略。</li>\n<li>每隔一段时间禁用超过指定天数没有登录的用户。</li>\n</ul><p>结合上面提到的作业系统的缺点，这里将我们需要设计的作业系统的特点总结如下：</p><ul>\n<li>分布式的作业系统，当有多个实例时，确保同一时刻只有1个实例在工作。</li>\n<li>跟项目契合紧密，能够方便地复用项目提供的包、函数等能力，提高开发效率。</li>\n<li>能够执行定时任务、间隔任务、间隔性定时任务这3种类型的任务。</li>\n<li>可插件化地加入新的周期/定时任务。</li>\n</ul><h2>IAM作业系统实现</h2><p>介绍完IAM作业系统使用到的两个Go包和IAM作业系统的特点，下面我来正式讲解IAM作业系统的实现。</p><p>IAM的作业系统服务名叫iam-watcher。watcher是观察者的意思，里面的任务主要是感知一些状态，并执行相应的任务，所以叫watcher。iam-watcher main函数位于<a href=\"https://github.com/marmotedu/iam/blob/v1.2.0/cmd/iam-watcher/watcher.go\">cmd/iam-watcher/watcher.go</a>文件中。应用框架跟iam-apiserver、iam-authz-server、iam-pump保持高度一致，这里就不再介绍了。</p><p>整个iam-watcher服务的核心实现位于<a href=\"https://github.com/marmotedu/iam/blob/v1.2.0/internal/watcher/server.go\">internal/watcher/server.go</a>文件中，在server.go文件中调用了<a href=\"https://github.com/marmotedu/iam/blob/v1.2.0/internal/watcher/watcher.go#L33\">newWatchJob</a>，创建了一个<code>github.com/robfig/cron.Cron</code>类型的cron实例，<code>newWatchJob</code> 代码如下：</p><pre><code class=\"language-go\">func newWatchJob(redisOptions *genericoptions.RedisOptions, watcherOptions *options.WatcherOptions) *watchJob {    \n    logger := cronlog.NewLogger(log.SugaredLogger())                                                               \n\n    client := goredislib.NewClient(&amp;goredislib.Options{                     \n        Addr:     fmt.Sprintf(\"%s:%d\", redisOptions.Host, redisOptions.Port),    \n        Username: redisOptions.Username,                                         \n        Password: redisOptions.Password,    \n    })                                                                  \n\n    pool := goredis.NewPool(client)                                                                            \n    rs := redsync.New(pool)                                                \n\n    cron := cron.New(                                                             \n        cron.WithSeconds(),                     \n        cron.WithChain(cron.SkipIfStillRunning(logger), cron.Recover(logger)),                                      \n    )                                                                             \n\n    return &amp;watchJob{                                             \n        Cron:   cron,                                                            \n        config: watcherOptions,                                                   \n        rs:     rs,                             \n    }                                                             \n}\n</code></pre><p>上述代码创建了以下两种类型的实例。</p><ul>\n<li><code>github.com/robfig/cron.Cron</code>：基于<code>github.com/robfig/cron</code>包实现的作业系统，可以支持定时任务、间隔任务、间隔性定时任务 3种类型的任务。</li>\n<li><code>github.com/go-redsync/redsync.Redsync</code>：基于Redis的分布式互斥锁。</li>\n</ul><p>这里需要注意，创建cron实例时需要增加<code>cron.SkipIfStillRunning()</code> Option，<code>SkipIfStillRunning</code>可以使cron任务在上一个任务还没执行完时，跳过下一个任务的执行，以此实现间隔任务的效果。</p><p>创建实例后，通过<a href=\"https://github.com/marmotedu/iam/blob/v1.2.0/internal/watcher/watcher.go\">addWatchers()</a>来注册cron任务。<code>addWatchers</code> 函数代码如下：</p><pre><code class=\"language-go\">func (w *watchJob) addWatchers() *watchJob {                            \n    for name, watcher := range watcher.ListWatchers() {\n        // log with `{\"watcher\": \"counter\"}` key-value to distinguish which watcher the log comes from.\n        ctx := context.WithValue(context.Background(), log.KeyWatcherName, name)\n\n        if err := watcher.Init(ctx, w.rs.NewMutex(name, redsync.WithExpiry(2*time.Hour)), w.config); err != nil {\n            log.Panicf(\"construct watcher %s failed: %s\", name, err.Error())    \n        }                                                              \n\n        _, _ = w.AddJob(watcher.Spec(), watcher)                            \n    }           \n\n    return w                                    \n}  \n</code></pre><p>上述函数会调用<code>watcher.ListWatchers()</code>列出所有的watcher，并在for循环中将这些watcher添加到cron调度引擎中。watcher定义如下：</p><pre><code class=\"language-go\">type IWatcher interface {                                               \n    Init(ctx context.Context, rs *redsync.Mutex, config interface{}) error\n    Spec() string                                                                                      \n    cron.Job                                                                    \n}\n\ntype Job interface {                                                    \n    Run()                                                                 \n}\n</code></pre><p>也就是说，一个watcher是实现了以下3个方法的结构体：</p><ul>\n<li><code>Init()</code>，用来初始化wacther。</li>\n<li><code>Spec()</code>，用来返回Cron实例的时间格式，支持Linux crontab时间格式和<code>@every 1d</code>类型的时间格式。</li>\n<li><code>Run()</code>，用来运行任务。</li>\n</ul><p>IAM实现了两个watcher：</p><ul>\n<li><a href=\"https://github.com/marmotedu/iam/blob/v1.2.0/internal/watcher/watcher/task/watcher.go\">task</a>：禁用超过<code>X</code>天还没有登录过的用户，<code>X</code>可由iam-watcher.yaml配置文件中的<code>watcher.task.max-inactive-days</code>配置项来配置。</li>\n<li><a href=\"https://github.com/marmotedu/iam/blob/v1.2.0/internal/watcher/watcher/clean/watcher.go\">clean</a>：清除<code>policy_audit</code>表中超过<code>X</code>天数后的授权策略，<code>X</code>可由iam-watcher.yaml配置文件中的<code>watcher.clean.max-reserve-days</code>配置项来配置。<br>\n创建完cron实例后，就可以在<a href=\"https://github.com/marmotedu/iam/blob/v1.2.0/internal/watcher/server.go#L62\">Run函数</a>中启动cron任务。Run函数代码如下：</li>\n</ul><pre><code class=\"language-plain\">func (s preparedWatcherServer) Run() error {\n\tstopCh := make(chan struct{})\n\ts.gs.AddShutdownCallback(shutdown.ShutdownFunc(func(string) error {\n\t\t// wait for running jobs to complete.\n\t\tctx := s.cron.Stop()\n\t\tselect {\n\t\tcase &lt;-ctx.Done():\n\t\t\tlog.Info(\"cron jobs stopped.\")\n\t\tcase &lt;-time.After(3 * time.Minute):\n\t\t\tlog.Error(\"context was not done after 3 minutes.\")\n\t\t}\n\t\tstopCh &lt;- struct{}{}\n\n\t\treturn nil\n\t}))\n\n\t// start shutdown managers\n\tif err := s.gs.Start(); err != nil {\n\t\tlog.Fatalf(\"start shutdown manager failed: %s\", err.Error())\n\t}\n\n\tlog.Info(\"star to run cron jobs.\")\n\ts.cron.Start()\n\n\t// blocking here via channel to prevents the process exit.\n\t&lt;-stopCh\n\n\treturn nil\n}\n</code></pre><p>上述代码，通过<code>s.cron.Start()</code>代码调用来启动cron实例，执行cron任务。</p><p>这里需要注意，我们还需要实现优雅关停功能，也就是当程序结束时，等待正在执行的作业都结束后，再终止进程。<code>s.cron.Stop()</code>会返回<code>context.Context</code>类型的变量，用来告知调用者cron任务何时结束，以使调用者终止进程。在cron任务都执行完毕或者超时3分钟后，会往 <code>stopCh</code> 通道中写入一条message，<code>&lt;-stopCh</code> 会结束阻塞状态，进而退出iam-watcher进程。</p><h2>task watcher实现解读</h2><p>task watcher的实现位于<a href=\"https://github.com/marmotedu/iam/blob/v1.2.0/internal/watcher/watcher/task/watcher.go\">internal/watcher/watcher/task/watcher.go</a>文件中，该文件定义了一个<code>taskWatcher</code>结构体：</p><pre><code class=\"language-go\">type taskWatcher struct {    \n    ctx             context.Context    \n    mutex           *redsync.Mutex    \n    maxInactiveDays int          \n}\n</code></pre><p><code>taskWatcher</code>实现了<a href=\"https://github.com/marmotedu/iam/blob/v1.2.0/internal/watcher/watcher/registry.go#L17\">IWatcher</a>接口。在程序启动时，通过 <code>init</code> 函数将<code>taskWatcher</code>注册到<a href=\"https://github.com/marmotedu/iam/blob/v1.2.0/internal/watcher/watcher/registry.go\">internal/watcher/watcher/registry.go</a>中定义的全局变量<code>registry</code>中，通过<code>func ListWatchers() map[string]IWatcher</code>函数返回所有注册的watcher。</p><p>这里需要注意，所有的watcher在<code>internal/watcher/watcher/all/all.go</code>文件中以匿名包的形式被导入，从而触发watcher所在包的init函数的执行。init函数通过调用<code>watcher.Register(\"clean\", &amp;cleanWatcher{})</code>将watcher注册到<code>registry</code>变量中。<code>all.go</code>文件中导入匿名包代码如下：</p><pre><code class=\"language-go\">import (                                                           \n    _ \"github.com/marmotedu/iam/internal/watcher/watcher/clean\"    \n    _ \"github.com/marmotedu/iam/internal/watcher/watcher/task\"    \n)  \n</code></pre><p>这样做的好处是，不需要修改任何iam-watcher的框架代码，就可以插件化地注册一个新的watcher。不改动iam-watcher的主体代码，能够使我们以最小的改动添加一个新的watcher。例如，我们需要新增一个 <code>cleansecret</code>  watcher，只需要执行以下两步即可：</p><ol>\n<li>在<code>internal/watcher/watcher</code>目录下新建一个<code>cleansecret</code>目录，并实现<code>cleanSecretWatcher</code>。</li>\n<li>在<code>internal/watcher/watcher/all/all.go</code>文件中以匿名的形式导入<code>github.com/marmotedu/iam/internal/watcher/watcher/cleansecret</code>包。<br>\n在<code>taskWatcher</code>的<a href=\"https://github.com/marmotedu/iam/blob/v1.2.0/internal/watcher/watcher/task/watcher.go#L27\">Run()</a>方法中，我们通过以下代码，来确保即使有多个iam-watcher实例，也只有一个task watcher在执行：</li>\n</ol><pre><code class=\"language-go\">    if err := tw.mutex.Lock(); err != nil {               \n        log.L(tw.ctx).Info(\"taskWatcher already run.\")    \n\n        return    \n    }                 \n    defer func() {                                      \n        if _, err := tw.mutex.Unlock(); err != nil {    \n            log.L(tw.ctx).Errorf(\"could not release taskWatcher lock. err: %v\", err)    \n\n            return    \n        }    \n    }()\n</code></pre><p>我们在<code>taskWatcher</code>的<code>Run()</code>方法中，查询出所有的用户，并对比<code>loginedAt</code>字段中记录的时间和当前时间，来判断是否需要禁止用户。<code>loginedAt</code>字段记录了用户最后一次登录的时间。</p><p>通过task watcher的实现，可以看到：在task watcher中，我们使用了IAM项目提供的<code>mysql.GetMySQLFactoryOr</code>函数、log包，以及Options配置，这使我们可以很方便地开发一个跟项目紧密相关的任务。</p><h2>总结</h2><p>在Go项目开发中，我们经常会需要执行一些间隔/定时任务，这时我们就需要一个作业系统。我们可以使用Linux提供的crontab执行定时任务，还可以自己搭建一个作业系统，并在上面执行我们的间隔/定时任务。但这些方法都有一些缺点，比如跟项目独立、无法执行间隔任务等。所以，这时候比较好的方式是基于开源的优秀cron包，来实现一个作业系统，并基于这个作业系统开发任务插件。</p><p>IAM基于<code>github.com/robfig/cron</code>包和<code>github.com/go-redsync/redsync</code>包，实现了自己的分布式作业系统iam-watcher。iam-watcher可以插件化地添加定时任务、间隔任务、间隔性定时任务。至于它的具体实现，你可以跟读iam-watcher服务的代码，其main函数位于<a href=\"https://github.com/marmotedu/iam/blob/v1.2.0/cmd/iam-watcher/watcher.go\">cmd/iam-watcher/watcher.go</a>文件中。</p><h2>课后练习</h2><ol>\n<li>思考一下：在日常工作中，除了定时任务、间隔任务、间隔性定时任务外，还有没有其他类型的任务需求？欢迎在评论区分享。</li>\n<li>尝试实现一个新的watcher，用来从secret表中删除过期的secret。<br>\n欢迎你在留言区与我交流讨论。如果这一讲对你有帮助，也欢迎分享给你身边的朋友。</li>\n</ol>","neighbors":{"left":{"article_title":"特别放送 | Go Modules实战","id":420325},"right":{"article_title":"直播加餐｜如何从小白进阶成 Go 语言专家？","id":499240}}},{"article_id":499240,"article_title":"直播加餐｜如何从小白进阶成 Go 语言专家？","article_content":"<p>你好，我是孔令飞，我们又见面了。</p><p>关于 Go 语言的学习经验和项目实战，我最近又有了一些新的思考和总结。因此，3月31号晚上，我在极客时间做了一场直播，主题是“<span class=\"orange\">如何从小白进阶成 Go 语言专家</span>”。直播的回放记录和 PPT 在<a href=\"https://pan.baidu.com/s/1eKKhR1V47qivSWcmy60a7Q?pwd=drkg\">这里</a>，你可以自行下载查看、回顾。</p><p>在这场直播中，除了我们这门课里已经涉及的内容，我还分享了从小白到 Go 专家的完整学习路径，以及基于声明式编程范式的软件架构。作为一名具有多年Go项目开发经验的工程师，我将 Go 语言能力由低到高划分为初级、中级、高级、资深、专家 5 个级别。在这次直播中，我分享了每个阶段对应的高效学习方法，帮助你在Go进阶之路上加速前进。并且，我还分享了一种基于声明式编程范式的软件架构，这种软件架构随着Kubernetes的流行，也越来越受欢迎。</p><p>结课并不意味着结束，我非常高兴能持续把好的内容分享给你，也希望你能继续在留言区与我保持交流，分享你的学习心得和实践经验。</p><!-- [[[read_end]]] -->","neighbors":{"left":{"article_title":"特别放送 | 分布式作业系统设计和实现","id":469884},"right":{"article_title":"结束语 | 如何让自己的 Go 研发之路走得更远？","id":423538}}},{"article_id":423538,"article_title":"结束语 | 如何让自己的 Go 研发之路走得更远？","article_content":"<p>你好，我是孔令飞。不知不觉，我们的这段Go学习之旅就要走到终点了。</p><p>首先，恭喜你耐心看完了整个专栏，相信你一定学到了不少知识。还要特别感谢那些常常向我反馈问题、提出改进建议的同学。因为有你们，这门课才能越来越完善，和你们的交流也让我获益良多。</p><p>先和你分享下我做这门课的一些“心路历程”。在过去的5年里，我不断学习，从一个Go新手一步步向Go老鸟迈进。在学习的过程中，我遇到了很多困难，也收获了一些心得。因为我是一个热爱分享的人，也特别想把这些困难的解决方法，以及沉淀下来的学习心得分享给更多的人，所以才有了这门课。</p><p>俗话说，活到老学到老，在Go研发的道路上，我跟你一样仍然是个学生。既然是学生，就有知识盲区，在写专栏的过程中，我很怕因为自己水平不够误导大家。所以，在前期我做足了调研，几乎把专栏中每一个大知识块儿的业内实现都翻了个底朝天，就是为了构建一个专业的知识体系。这门课最终的质量基本符合当初的预期，也算是没辜负我熬的那些夜和掉的无数根头发了。</p><p>这里就用一张图片来概括这个历时一年的过程吧：</p><p><img src=\"https://static001.geekbang.org/resource/image/8c/e9/8cc0bc147ed8e1386d8163de304434e9.jpg?wh=1920x875\" alt=\"图片\"></p><p>希望这些呈现给你的具体数据，可以让你对自己所学知识的专业度抱有更多的信心。</p><p>陪你走完这一程Go学习之旅是我的荣幸，这门课虽然结束了，但你的学习和成长之路才刚刚开始。那么，如何在Go研发之路上走得更远呢？</p><!-- [[[read_end]]] --><p>在我看来，<strong>一个Go开发者的完整职业生涯，会经历开发者阶段、架构师阶段、创业者阶段</strong>：</p><p><img src=\"https://static001.geekbang.org/resource/image/83/5b/830031yy640c6c29eb2113148f29d05b.jpg?wh=1920x1135\" alt=\"图片\"></p><p>处于这三个不同的阶段，你要扮演的角色也是不同的。</p><ol>\n<li>开发者阶段：在这个阶段，你可以使用Go语言，完成产品经理、领导分配的各种开发任务，中间会掺杂一些架构设计的工作，但这些架构设计通常局限在跟开发任务相关的范围内。</li>\n<li>架构师阶段：在这个阶段，你已经熟练或者精通Go语言的基本语法，并能够驾轻就熟地使用Go语言开发出一个大型的应用。除此之外，你还能从系统资源层面、应用层面、应用生命周期管理层面来设计整个系统架构，最终构建出一个高性能、高可靠、可维护、可扩展的能够满足产品需求的应用。</li>\n<li>创业者阶段：在开发者阶段和架构师阶段，你本质上还是一个技术导向的从业人员。但在创业者这个阶段，你的重心已经从技术转向产品，成为整个业务线的负责人。这不是因为技术不重要，而是因为你已经有了深厚的技术积累。这时候，技术对你来说更多是一种用来创造优秀产品的工具。</li>\n</ol><p>其实，在开发者阶段和架构师阶段，我们的最终目的也是开发一个产品，但和创业者阶段的侧重点有所不同。在开发者阶段，我们主要是完成技术Leader分配的任务；在架构师阶段，我们则更多地扮演一个技术Leader的角色，是底层技术的主导者和决策者，拥有更大的话语权和职责。在这两个阶段，我们还应该通过学习，不断地补全自己的Go技术生态，最终尽可能地将整个Go技术生态中的点和面装入脑海中。</p><p>要完成开发者 -&gt; 架构师 -&gt; 创业者的角色转变，你就需要在日常的工作中不断学习、思考和实践。而学习，是最基础，也最重要的一个环节。因为这门课是一个技术专栏，所以接下来我们就重点看三个阶段中的前两个，聊聊<strong>如何学习，才能使自己成为一名优秀的开发者，然后成功晋级到一位优秀的架构师</strong>。</p><h2>开发者阶段</h2><p>作为一名Go开发者，首先你会进入开发者阶段。在开发者阶段，我们可以通过三个步骤，来成为一名优秀的Go开发工程师。需要说明下，这三步虽然是由浅入深的，但是可以并行。你不用学完所有基础语法知识才研究优秀项目、上手实战，可以根据需要穿插进行。</p><h3>第一步：基础语法学习</h3><p>我们可以精读一到两本经典的Go语言基础教程，这里我向你推荐两本书：<a href=\"https://book.douban.com/subject/27044219/\">《Go程序设计语言》</a>和<a href=\"https://book.douban.com/subject/11577300/\">《Go语言编程》</a>。</p><p>如果你还有时间和精力，还可以再看两本关于场景化编程的书籍：<a href=\"https://book.douban.com/subject/27016236/\">《Go 并发编程实战》（第2版）</a>和<a href=\"https://book.douban.com/subject/27204133/\">《Go Web编程》</a>。</p><p><img src=\"https://static001.geekbang.org/resource/image/eb/85/ebaf72e28afab675046962ede7291685.png?wh=1920x695\" alt=\"图片\"></p><p>你可以先通读《Go程序设计语言》这本书，掌握Go的基础语法。在学习的过程中，你可能会遇到一些知识点不太理解，或者看了就忘的情况，没关系，先坚持学习完。如果你还有精力，可以选择继续读《Go语言编程》这本书。这两本书啃下来，你就有了充足的Go基础语法储备，为下一步的研究优秀项目打下了坚实的基础。</p><h3>第二步：认真研究一个优秀的项目</h3><p>有了一定的Go基础语法储备后，就该认真研究一个优秀的项目了。你不仅要学习项目中包含的知识，还要学习它的构建思路。我们来看下工作年限和开发能力的关系：</p><p><img src=\"https://static001.geekbang.org/resource/image/ef/12/ef95ab3d5a427e631fa72854b95e6f12.jpg?wh=1920x1226\" alt=\"图片\"></p><p>如上图所示，工作年限和开发能力之间是一个抛物线关系：刚开始的时候，随着工作年限的增长，开发能力会提升得很快；但是，当工作年限增长到一定程度，开发能力的增长就放缓了。这是因为，到达一定工作年限后，我们更多是去反复使用已有的知识和经验积累，所以开发能力提升有限。</p><p>那么如何才能提高开发能力的天花板呢？在我看来，这时应该去认真研究下如何构建一个优秀的项目，来扩充自己的知识和经验库。一次学习，整个研发生涯都会受益。《Go 语言项目开发实战》就是一门带你研究优秀项目的课程，只要你充分消化吸收了这门课的知识，相信你的Go项目研发能力已经得到了极大的提升。</p><h3>第三步：项目实战</h3><p>对优秀项目有了一定研究之后，你应该以需求为驱动，通过实践来加深对Go基础语法的掌握和理解。</p><p>在实践的过程中，用需求来驱动学习，不仅效率是最高的，而且学习的过程也是工作产出的过程，可以说是一箭双雕。这里又有3个问题：</p><ul>\n<li>需求从哪里来？</li>\n<li>如何查找优秀的开源项目？</li>\n<li>如何进行二次开发？</li>\n</ul><p>接下来，我们就分别看下这3个问题。</p><h4><strong>问题一：需求从哪里来？</strong></h4><p>在我看来，需求来源于工作。这些需求可以是产品经理交给你的某一个具体产品需求，也可以是能够帮助团队提高工作效率的工具，还可以是能够提高自己工作效率的工具。</p><p>总之，如果有明确的工作需求最好，如果没有明确的需求，我们就要创造需求。我们可以思考工作中的痛点、难点，并将它们转化成需求。比如，团队发布版本，每次都是人工发布，需要登陆到不同的服务器，部署不同的组件和配置。这样效率低不说，还容易因为人为失误造成现网故障。这时候，你就可以将这些痛点抽象成一个需求：开发一个版本发布系统。</p><p>有了需求，接下来我们就要完成它，也就是进入到实践环节。那么如何实践呢？在我看来精髓在于两个字：<strong>“抄”<strong>和</strong>“改”</strong>。</p><p>上面，我们抽象出了一个需求：开发一个版本发布系统。如果自己从0开发出一套版本发布系统，工作量无疑是巨大的。而且，以我们这个阶段的水平，即使花费了很多时间开发出一个版本发布系统，这个系统在功能和代码质量上也无法跟一些优秀的开源版本发布系统相比。</p><p>所以，这时候最好的方法就是在GitHub上找到一个优秀的版本发布系统，并基于这个系统进行二次开发。这样，你不仅能学习到一个优秀开源项目的设计和实现，还能够以最快的速度完成版本发布系统的开发。</p><h4><strong>问题二：如何查找优秀的开源项目？</strong></h4><p>那么，就到了我们刚才说的第二个问题：如何查找优秀的开源项目？放在这里，就是如何在GitHub上找到优秀的版本发布系统。</p><p>下面，我把我自己的方法分享给你。我主要通过5个步骤来搜索，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/56/74/5624815009e0d39706a3a293fc815274.png?wh=1920x881\" alt=\"图片\"></p><p>这里我结合图片，具体说明下这5个步骤。</p><ol>\n<li><strong>在GitHub搜索栏中按语言搜索：</strong><code>language:go 版本发布</code>中，<code>language:go</code>说明我们要搜索语言类型为Go语言的项目；<code>版本发布</code>是我们搜索项目时的关键词。这个关键词对搜索结果影响很大，需要你合理填写。这里有个技巧，如果搜索<code>版本发布</code> ，搜索出的项目很少，那么可以减少关键词再次搜索，比如搜索<code>发布</code>。</li>\n<li><strong>GitHub搜索页面的 <code>Sort options</code> 选择 <code>Most stars</code> ：</strong> 因为GitHub项目很多，我们不可能看完所有搜索出来的项目，所以这里我们要选择性地去查看。你可以通过<code>Most stars</code>进行排序，一般来说Star数越多说明项目越受欢迎，而受欢迎的原因很可能是整个项目在同类项目中比较优秀。根据我之前的搜索经验，一些Star数少的项目也可能很优秀，最终还是需要你根据自己的理解去判断。</li>\n<li><strong>看描述：</strong>因为项目比较多，我们不可能认真去研究每个项目，所以要快速了解项目，最简单的方式是先看描述。如果描述符合预期，那么可以将这个项目在新的浏览器Tab页打开，或者将项目地址保存起来，等初步筛选完所有项目后，再详细查看这个项目的README以及代码。</li>\n<li><strong>看项目名字：</strong>一些优秀的项目可能没有描述，这时候可以通过项目的名字来判断。</li>\n<li><strong>根据Code做筛选：</strong>如果我们搜索的项目很冷门，搜索GitHub后只有寥寥几个搜索结果，而且搜索出的项目也不是我们期望的。那么这时候，你可以从<code>Code</code>中来筛选。</li>\n</ol><p>通过上面这5步，我们初步搜索出了匹配的项目，并知道了如何对这些项目做初步的筛选。接下来，你就需要按页来筛选页面中的开源项目，然后从第1页一直筛选到第100页。GitHub一页默认会展示10个开源项目，所以，如果按照这种方法，最终你可能需要调研<code>10 * 100 = 1000</code>个开源项目。当然，也不一定每次都要从第1页一直看到第100页，如果后面的项目明显都跟预期的需求不匹配，可以不用再继续看了。</p><p>研究完GitHub上的开源项目，这时候我还建议你通过<a href=\"https://libs.garden/go\">libs.garden</a>，再查找一些开源项目。libs.garden的主要功能是库（在 Go 中叫包）和应用的评分网站，是按不同维度去评分的，例如增长速度（根据新增 Star 数排序）、受欢迎程度（按 Star 数排序）、活跃度等。</p><p>libs.garden 包含了很多编程语言的评分，包括 Go 语言，地址为<a href=\"https://libs.garden/go\"> https://libs.garden/go</a>。你可以通过以下3步查找需要的开源项目：</p><ol>\n<li>打开 <a href=\"https://libs.garden/go\">https://libs.garden/go</a>；</li>\n<li>根据我们需要的功能判断其类别，Go 的所有类别可以参考<a href=\"https://libs.garden/go/categories\">这个链接</a> 。例如，配置文件解析应该属于 Config 类；</li>\n<li>打开所属类别，根据 Popular 进行排序，如下图所示：</li>\n</ol><p><img src=\"https://static001.geekbang.org/resource/image/0d/b7/0dfdbbd4a837234443fb5f0d6fe7f5b7.png?wh=1291x753\" alt=\"图片\"></p><p>执行完这三步，我们就从上图的第 1 行开始，根据 Repository 的描述判断当前 Repository 有没有可能是我们要找的包。如果有，就打开 Repository，阅读它的README.md 来进一步判断。如果判断出可能是我们要找的包，并且各方面都还可以，就 clone 下来，根据其 README.md 中的帮助文档，编写代码并测试其功能。</p><p>研究完上一个 Repository 之后，我们继续根据排序，以相同的方法研究第 2 个 Repository，并以此类推，直到找到满意的包，或者GitHub Star 数小于某个预期值为止。用这样的方法，我们应该可以找到符合要求的优秀开源包，而且该开源包极有可能是“最”优秀的包。</p><p>此外，GitHub 上的 <a href=\"https://github.com/avelino/awesome-go\">awesome-go</a> 项目也根据分类记录了很多包和工具，你也可以在这个项目中寻找。我的建议是优先从GitHub上找，再在 libs.garden 上找，最后再参考 awesome-go项目。</p><p>到这里，我们已经通过自己的调研，找到了一堆GitHub上的开源项目。为什么我们要找这么多开源项目呢？主要目的有两个：</p><ul>\n<li>确保自己基于一个最优的开源项目来进行二次开发，一开始便站上至高点。</li>\n<li>填充自己脑海中的Go生态图。</li>\n</ul><p>不过，这些开源项目只是经过了初步筛选，里面有很多是不满足我们需求的，甚至可能跟我们的需求完全不一致。所以，我们还需要进行二次筛选，可以通过精读开源项目的README来筛选。如果有必要，并且项目部署简单，你也可以部署这个开源项目，亲自体验一下。</p><p>经过第二次的筛选，我们已经筛选出了一些能够满足要求的优秀开源项目。这时候，我们还需要再经过一轮筛选。这轮筛选，我们要从各方面来对比这些开源项目，并从中选出一个最合适的开源项目，来进行二次开发。这个开源项目，你可以自信地跟你老板说它是一个最优解。</p><h4>问题三：如何<strong>进行二次开发？</strong></h4><p>接下来，你就可以基于这个项目进行二次开发，最终出色地完成设定的需求。那么如何对选定的项目进行二次开发呢？我总结了5个步骤：</p><ol>\n<li>手动编译、部署这个开源项目。</li>\n<li>阅读项目的README文档，跟着README文档使用这个开源项目，至少运行一遍核心功能。</li>\n<li>阅读核心逻辑源码，在不清楚的地方，可以添加一些  fmt.Printf 函数，来协助你理解代码。</li>\n<li>在你理解了项目的核心逻辑或者架构之后，就可以尝试添加/修改一些匹配自己项目需求的功能，添加后编译、部署，并调试。</li>\n<li>二次开发完之后，你还需要思考下后续要不要同步社区的代码，如果需要，如何同步代码。</li>\n</ol><p>在你通过“抄”和“改”完成需求之后，记得还要编写文档，并找个合适的时机在团队中分享你的收获和产出。这点很重要，可以将你的学习输入变成工作产出。</p><p>看到这里，你可能想说：我开发一个项目而已，调研这么多项目，花这么多时间，值得吗？我觉得是值得的，因为这种学习方式会带来下面这几个好处。</p><ul>\n<li>最优解：你可以很有底气地跟老板说，这个方案在这个类别就是业界No.1。</li>\n<li>高效：基于已有项目进行二次开发，可以提高开发和学习效率。</li>\n<li>产出：在学习的过程中，也有工作产出。个人成长、工作贡献可以一起获得。</li>\n<li>知识积累：为今后的开发生涯积累项目库和代码库。GitHub就是一个大的代码仓库，里面几乎囊括了你开发过程中需要的所有技术实现。你需要做的其实就是找到其中的最优实现，并升级成自己的实现。这是一个从量变到质变的过程，最终，你的研发模式会变成<code>Ctrl + C</code> + <code>Ctrl + V</code>。这首先意味着你的开发工作会越来越轻松；另外，你<code>Ctrl + C</code>的是一个优秀的开源项目或代码，<code>Ctrl + V</code>的是经过你改进后的代码，这就意味着，你基于这个开源项目或代码二次开发后的实现一定是 <code>(你, GitHub最优解)</code> 二元组中最好的一个实现。</li>\n</ul><p>到这里，我就完整讲述了开发者阶段的“三步走”学习法，这三步分别是基础语法学习、研究一个优秀项目和进行项目实战。用这种方法进行学习，你不仅能非常高效地开发出一个优秀的功能，而且也能得到老板的认可，最终使你在年底绩效考核时顺利拿到优秀员工称号。</p><h2>架构师阶段</h2><p>在开发者阶段，你通过自己的努力成为一名优秀的Go开发工程师之后，可能会遇到职业瓶颈。这时候，你突破瓶颈的最好方式就是转型架构师（需要说明下，这里的架构师是技术架构师，而不是售前架构师）。架构师有很多方向，在云原生技术时代，转型为云原生架构师对学Go语言的我们来说是一个不错的选择。现在的我也在这个道路上前进，期待和你一起成长。</p><p>要成为云原生架构师，首先要学习云原生技术。云原生技术有很多，我推荐的学习路线如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/1d/db/1dd9dd6357bbaef297fec7ff6eeb3bdb.jpg?wh=1920x698\" alt=\"图片\"></p><p>通过学习微服务、Docker、Kubernetes、Knative、Prometheus、Jaeger、EFK、DevOps这些技术，你可以掌握云原生中的核心技术栈；通过学习KVM、Istio、Kafka、Etcd、Tyk，你可以补全你的云原生核心技术栈。如果你还有精力，还可以再学习下TKEStask、Consul、Cilium、OpenShift这些项目。下面，我给你介绍一些不错的参考资料。</p><ul>\n<li>微服务：<a href=\"https://book.douban.com/subject/26772677/\">《微服务设计》</a></li>\n<li>Docker：<a href=\"https://book.douban.com/subject/30329430/\">《Docker技术入门与实战》（第3版）</a>、<a href=\"https://book.douban.com/subject/26894736/\">《Docker ——容器与容器云》（第2版）</a></li>\n<li>Kubernetes ： <a href=\"https://book.douban.com/subject/33444476/\">《Kubernetes权威指南：从Docker到Kubernetes实践全接触》（第4版）</a>、<a href=\"https://book.douban.com/subject/30333237/\">《基于Kubernetes的容器云平台实战》</a></li>\n<li>Knative：<a href=\"https://knative.dev/docs/\">Knative Documentation</a></li>\n<li>Prometheus：<a href=\"https://prometheus.io/docs/introduction/overview/\">Prometheus Documentation</a></li>\n<li>Jaeger ：<a href=\"https://www.jaegertracing.io/docs/1.26/\">Jaeger Documentation</a></li>\n<li>KVM：<a href=\"https://book.douban.com/subject/25743939/\">《KVM虚拟化技术 : 实战与原理解析》</a></li>\n<li>Istio：<a href=\"https://book.douban.com/subject/34438220/\">《云原生服务网格Istio：原理、实践、架构与源码解析》</a></li>\n<li>Kafka：<a href=\"https://book.douban.com/subject/30221096/\">《Apache Kafka实战》</a>、<a href=\"https://book.douban.com/subject/27038473/\">《Apache Kafka源码剖析》</a></li>\n<li>Etcd：<a href=\"https://time.geekbang.org/column/intro/391\">etcd实战课</a></li>\n<li>Tyk：<a href=\"https://tyk.io/docs/apim/open-source/\">Tyk Open Source</a></li>\n<li>TKEStask：<a href=\"https://tkestack.github.io/docs/\">TKEStack Documentation</a></li>\n<li>Consul：<a href=\"https://www.consul.io/docs\">Consul Documentation</a></li>\n<li>Cilium：<a href=\"https://docs.cilium.io/\">Cilium Documentation</a></li>\n<li>OpenShift ：<a href=\"https://book.douban.com/subject/27088186/\">《开源容器云OpenShift：构建基于Kubernetes的企业应用云平台》</a></li>\n</ul><p>如果需要的话，你还可以参考我整理的<a href=\"https://github.com/marmotedu/awesome-books\">awesome-books</a>，里面有更全面的参考资料。</p><p>学习了上面的技术之后，你其实已经具备了一名云原生架构师需要的技术基础，能够比较全面地构建整个云原生技术栈。接下来你需要做的，就是在工作中积极主动地承担更多的架构工作，你在团队中的角色会慢慢地从一名开发者转变成一名架构师。</p><p>在架构师阶段，你应该继续学习，但这时候学习的侧重点不再是具体深入的技术细节。这不是因为细节不重要，而是因为以你当前的技术能力，只要简单了解，你就能知道具体是怎么构建的。这个阶段，你学习的重点是增强自己的架构能力。你可以通过很多方式来使自己拥有这些能力，我推荐下面这几种：</p><ul>\n<li>调研竞品，了解竞品的架构设计和实现方式。</li>\n<li>参加技术峰会，学习其他企业的优秀架构设计，例如ArchSummit全球架构师峰会、QCon等。</li>\n<li>参加公司内外组织的技术分享，了解最前沿的技术、架构和解决方案。</li>\n<li>关注一些优秀的技术公众号，学习其中高质量的技术文章。</li>\n<li>作为一名创造者，通过积极思考，设计出符合当前业务的优秀架构。</li>\n</ul><p>需要注意，在架构师阶段你仍然是一名技术开发者，一定不能脱离代码。你可以通过下面这几个方法，让自己保持Code能力：</p><ul>\n<li>以Coder的身份参与一些核心代码的研发。</li>\n<li>以Reviewer的身份Review成员提交的PR。</li>\n<li>工作之余，阅读项目其他成员开发的源码。</li>\n<li>关注一些优秀的开源项目，调研、部署并试用。</li>\n</ul><h2>创业者阶段</h2><p>成为了一名优秀的架构师，就意味着你已经，或者将要触碰到技术的天花板了，那这时候如何突破呢？</p><p>在我看来，一个比较好的方向是突破技术的圈子，把技术当成一种工具，用这个工具来创造一个优秀的产品。这时候，你其实已经从一个技术人员转型成为一个创业者。这个时候的天花板，对你来说可以是无限高的：你可以通过努力，成为公司的经理、总裁甚至CEO，也可以成为行业TOP公司的创始人。</p><p>至于如何扮演好一个创业者角色，内容太多，变化也太多，而且跟本专栏的技术性质不匹配，所以这里就索性留一些空白，等着你来填充。总之，那时候就是：技术在手，天下我有！</p><h2>写在最后</h2><p>感谢你陪我走完了这段历时4个月的Go学习之旅。不过，站在终点的你可以看到，你的Go研发之路才刚刚开始。希望我今天分享的这些学习和工作心得，能帮你在这条路上走得更远。</p><p>看到这里，你可能觉得我们之间的关系就这样结束了？不，没有结束，你可以通过下面这两步继续跟我保持联系，继续探讨如何开发Go项目，以及课程中的一些疑难问题。</p><ul>\n<li>步骤一：请给这门课的<a href=\"https://github.com/marmotedu/iam\">实战项目</a> <strong>点个Star</strong>。IAM项目会持续升级维护，这个Star绝对不亏！</li>\n<li>步骤二：如果还有关于课程的问题需要咨询，或者想了解我熬夜写完专栏，发际线依然坚挺的秘诀（不点Star不分享，哈哈），可以加我微信，WeChat：<code>echo bmlnaHRza29uZw==|base64 -d</code> 。</li>\n</ul><p>最后，我还给你准备了一个<a href=\"https://jinshuju.net/f/o1nVPp\">调查问卷</a>。题目不多，大概两分钟就可以填完，主要是想听一下你对这门课的看法和建议。期待你的反馈！<br>\n<a href=\"https://jinshuju.net/f/o1nVPp\"><img src=\"https://static001.geekbang.org/resource/image/fc/e1/fc9610a599691da13d617a4a2c61b5e1.jpg?wh=1142x801\" alt=\"\"></a></p>","neighbors":{"left":{"article_title":"直播加餐｜如何从小白进阶成 Go 语言专家？","id":499240},"right":{"article_title":"期末考试｜《Go语言项目开发实战》满分试卷，等你来挑战！","id":423545}}},{"article_id":423545,"article_title":"期末考试｜《Go语言项目开发实战》满分试卷，等你来挑战！","article_content":"<p>你好，我是孔令飞。</p><p>《Go语言项目开发实战》已经结课了。非常感谢你一直以来的认真学习和支持！</p><p>为了帮你检验自己的学习效果，我特意给你准备了一套结课测试题。这套测试题一共有 20 道，包括 3 道多选和 17 道单选，考点都来自于我们前面讲到的重要知识。快点击下面按钮开始测试吧！<br>\n<a href=\"http://time.geekbang.org/quiz/intro?act_id=972&exam_id=2794\"><img src=\"https://static001.geekbang.org/resource/image/28/a4/28d1be62669b4f3cc01c36466bf811a4.png?wh=1142*201\" alt=\"\"></a></p><p>最后，我还给你准备了一个<a href=\"https://jinshuju.net/f/o1nVPp\">调查问卷</a>。题目不多，大概两分钟就可以填完，主要是想听一下你对这门课的看法和建议。期待你的反馈！<br>\n<a href=\"https://jinshuju.net/f/o1nVPp\"><img src=\"https://static001.geekbang.org/resource/image/fc/e1/fc9610a599691da13d617a4a2c61b5e1.jpg?wh=1142x801\" alt=\"\"></a></p><!-- [[[read_end]]] -->","neighbors":{"left":{"article_title":"结束语 | 如何让自己的 Go 研发之路走得更远？","id":423538},"right":[]}}]