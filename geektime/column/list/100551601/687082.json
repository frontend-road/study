{"id":687082,"title":"27｜重复消费：高并发场景下怎么保证消息不会重复消费？","content":"<p>你好，我是大明。今天我们来讨论一个在消息队列里面非常常见的话题——重复消费。</p><p>通过前面几节课的学习，我相信你已经发现了，很多方案都会引起一个问题：消息重复发送或者重复消费。而解决的思路基本上一致，就是把消费者设计成幂等的。也就是说，同一个消息，不管消费多少次，系统状态都是一样的。</p><p>另外一个经常和幂等联系在一起的话题就是重试。就像你在微服务部分接触到的那样，为了提高可用性，我们经常会引入各种重试机制。而重试的一个前提就是重试的动作必须是幂等的。所以，在面试中幂等是一个绕不开的话题。只不过大部分人在讨论幂等的时候，只能想到使用唯一索引，而且即便回答唯一索引，也很难深入。</p><p>所以今天我就带你从重复消费讨论到幂等，最后给出一个非常强大的高并发幂等方案，确保你在面试的时候可以赢得竞争优势。</p><h2>布隆过滤器</h2><p>布隆过滤器（Bloom Filter）是一种数据结构，它可以用于检索一个元素是否在一个集合里。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是存在假阳性的问题，还有对于删除操作不是很友好。</p><p>布隆过滤器的基本思路是当集合加入某个元素的时候，通过哈希算法把元素映射到比特数组的 N 个点，把对应的比特位设置成 1。</p><p><img src=\"https://static001.geekbang.org/resource/image/5f/87/5fbcbde15331c56b13f6d8b31f808987.png?wh=1920x927\" alt=\"图片\"></p><p>在查找的时候，只需要看对应的比特位是不是 1，就可以粗略判断集合里有没有这个元素。</p><!-- [[[read_end]]] --><ul>\n<li>如果查询的元素对应的 N 个点都是 1，那么这个元素<strong>可能</strong>存在。如果布隆过滤器认为一个元素存在，但是实际上并不存在，也叫做假阳性。</li>\n</ul><p><img src=\"https://static001.geekbang.org/resource/image/7d/2b/7d7c6d626f25e363db78bd8cb4900a2b.png?wh=1920x1081\" alt=\"图片\"></p><ul>\n<li>任何一个点是 0，那么这个元素必然不存在。</li>\n</ul><p>因此布隆过滤器经常和其他手段结合在一起判断某个元素在不在。它在判断某个元素必定不存在的场景下，效果非常好。</p><p>和布隆过滤器类似的还有 bit array，也叫做 bit map。它也是用一个比特位来代表元素是否存在，1 代表存在，0 代表不存在。它和布隆过滤器的核心区别是它不需要哈希函数，因为它的值本身就是一个数字。比如说，你的用户 ID 是数字，那么你就可以把 ID 当成 bit array 的下标，对应位置的比特位是 1。</p><p><img src=\"https://static001.geekbang.org/resource/image/a0/5a/a075bf11593815e08c9357b636ff785a.png?wh=1920x705\" alt=\"图片\"></p><p>并且，bit array 不存在假阳性的说法，它的判断是精确的。</p><h2>重复消费的可能原因</h2><p>重复消费的可能原因有2种。</p><ol>\n<li>生产者重复发送。比如说你的业务在发送消息的时候，收到了一个超时响应，这个时候你很难确定这个消息是否真的发送出去了，那么你就会考虑重试，重试就可能导致同一个消息发送了多次。</li>\n<li>消费者重复消费。比如说你在处理消息完毕之后，准备提交了。这个时候突然宕机了，没有提交。等恢复过来，你会再次消费同一个消息。</li>\n</ol><p>在避免重复消费的实践中你就记住一个原则：<strong>一定要把消费逻辑设计成幂等的</strong>。你的微服务也要尽可能设计成幂等的，这样上游就可以利用重试来提高可用性了。另外我要说明一点，现在大多数消息中间件都声称自己实现了恰好一次（exactly once）语义，都是依赖于重试和幂等来达成的。</p><h2>面试准备</h2><p>在面试前，你需要弄清楚一些信息。</p><ul>\n<li>你负责的业务里面有没有接口或消费者是要求幂等的？如果有，你是如何解决幂等的？</li>\n<li>如果你依赖于唯一索引来解决幂等，那么这部分的写流量有多大？</li>\n<li>如果你依赖于唯一索引来解决幂等，那么你是怎么保证业务操作和将数据插入到唯一索引是同时成功，或者同时失败的？</li>\n<li>你或者你的同事有没有因为没有设计幂等，或者幂等方案有问题而引起线上事故？如果有，你是怎么解决的？</li>\n<li>你的业务是否使用过布隆过滤器，如果有，当时用来解决什么问题？</li>\n</ul><p>重复消费、重试、幂等是我们设计系统的时候经常要解决的问题，所以你可以在项目介绍或者自我介绍的时候主动提起你设计过比较复杂的幂等解决方案。还有在面试过程中，如果你和面试官聊到了布隆过滤器，那么你可以主动提起你用布隆过滤器实现过幂等方案。类似地，聊到了 bit array 也可以提起你的幂等方案。当你们聊到 Redis 的 key 过期时间该怎么确定的时候，你可以用幂等方案里的 Redis key 过期时间的计算方式来作为例子。</p><p>下面我们来看一下关于重复消费的基本面试思路。</p><h2>基本思路</h2><p>在面试的时候，不管你是提到重试还是提到重复消费，面试官大概率都会问你怎么解决幂等的问题，你可以先介绍一个简单的思路，就是<strong>利用唯一索引</strong>。</p><blockquote>\n<p>最简单的幂等方案就是利用唯一索引。比如说在业务处理的时候，先根据消息内容往业务表里面插入一条数据，而这个业务表上有唯一索引。如果插入成功了就说明这个消息没有被处理过，可以继续处理。如果插入的时候出现了唯一索引错误，那就说明这个消息之前被处理过了。</p>\n</blockquote><p>如果想要用这个简单的方案刷出亮点，就需要补充足够多的细节。第一个亮点就是深入讨论究竟是怎么将数据插入到唯一索引的。</p><h3>本地事务将数据插入到唯一索引</h3><p>在这个方案里面，当我第一次处理请求的时候，我把数据插入到唯一索引成功了，万一我后面处理业务失败了怎么办？</p><p><img src=\"https://static001.geekbang.org/resource/image/a0/3c/a0b4cf1256bd63c362fbb7885386f03c.png?wh=1920x841\" alt=\"图片\"></p><p>这个时候你应该使用<strong>事务</strong>。也就是说，你收到消息之后就开启一个本地事务。在这个本地事务里面你会同时完成业务操作和将数据插入到唯一索引这两个操作，然后提交。当然，很多情况下这个插入唯一索引的操作本身就是你业务操作的一部分。</p><p><img src=\"https://static001.geekbang.org/resource/image/52/f4/5253acb25af6da0a4298ab70c2ab7df4.png?wh=1920x924\" alt=\"图片\"></p><p>在这种机制之下，只会出现一种情况，就是事务提交了，但是提交消息失败了。显然你会再次消费同一条消息，但因为你的事务都已经提交了，所以你下次消费的时候就会遇到唯一索引冲突的错误。</p><p><img src=\"https://static001.geekbang.org/resource/image/2b/fd/2b366df0ba1c34ff505626eca10cd8fd.png?wh=1920x1082\" alt=\"图片\"></p><p>如果你没有提交本地事务呢？那就说明你这个消息消费本身就失败了，应该再次重试。所以你可以进一步补充这个细节。</p><blockquote>\n<p>要使用唯一索引，最好的方式是把唯一索引和业务操作组合在一起，做成一个事务。也就是在收到消息的时候先开启事务，把数据插入到唯一索引，然后执行业务操作，最后提交事务。提交事务之后，就认为业务已经成功了，就算接下来提交消息失败了也没关系，因为后面重复请求还是会被唯一索引拦下来。不过万一不能使用本地事务，比如说在分库分表的条件下，那么解决方案就会更加麻烦。</p>\n</blockquote><p>这最后一句可以把话题引向另一个亮点。</p><h3>非本地事务将数据插入到唯一索引</h3><p>如果没有本地事务，业务操作和将数据插入到唯一索引的操作就不能看作是一个整体，无法保证要么都成功，要么都失败。这时候，只能追求最终一致性，依赖于一个第三方来检测了。</p><p>这种情况下整个方案的执行步骤也不一样，它分成3步。</p><ol>\n<li>把数据插入到唯一索引，但是这个时候状态被标记为初始状态。注意这一步一定要先执行，这是避免重复处理的关键。</li>\n<li>执行业务操作。</li>\n<li>将唯一索引对应的数据标记为完成状态。</li>\n</ol><p>出问题的地方就是第二步成功了，但是第三步失败了。这时候你就需要使用一个异步检测系统，这个异步检测系统会<strong>定时扫描</strong>唯一索引的表，然后再去扫描业务表。这个时候会有两种情况。</p><ul>\n<li>如果业务表的数据表明业务操作已经处理成功了，那么这个异步检测系统就会把唯一索引更新为成功状态。</li>\n</ul><p><img src=\"https://static001.geekbang.org/resource/image/2c/58/2c9229d32016fede98b4bf7e2a383a58.png?wh=1920x825\" alt=\"图片\"></p><ul>\n<li>如果业务表的数据表明业务操作没有成功，那么异步检测系统可以直接触发重试。</li>\n</ul><p><img src=\"https://static001.geekbang.org/resource/image/b6/57/b604dcb080624a6240fea5ec82735b57.png?wh=1920x1081\" alt=\"图片\"></p><p>所以你抓住关键词<strong>异步检测</strong>来回答。</p><blockquote>\n<p>在不能使用本地事务的时候，实现幂等就更加麻烦了，因为我们不能再把业务操作和将数据插入到唯一索引这两步做成原子操作。所以我们的解决方案是追求最终一致性，基本步骤是这样的。首先把数据插入到唯一索引里面，避免重复消费，这个时候数据保持在初始化状态。然后执行业务操作，执行业务操作之后，把唯一索引里的数据更新为成功状态。<br>\n&nbsp;<br>\n那么会出问题的地方就是第二步成功了，但是第三步失败了。在这种场景下，需要启动一个异步检测系统定时扫描初始状态的唯一索引数据。这个异步检测系统会检测唯一索引的数据和业务数据，判断是否一致。如果不一致，那么如果这个时候业务操作已经成功，那么就把唯一索引的数据标注为成功；如果这个时候业务失败了，那么就应该触发重试。</p>\n</blockquote><p>到这一步，我觉得就算是单纯用唯一索引这个解决方案来面试，你也可以和其他面试者已经拉开差距了。不过我还有一个更加强大的方案，能让你的优势更加明显。</p><h2>亮点方案：布隆过滤器 + Redis + 唯一索引</h2><p>这里我给你一个非常高级的方案，这个方案综合运用了大数据处理中常见的布隆过滤器、Redis 和唯一索引。从思路上来说，就是四个字<strong>层层削流</strong>。从目标上来说，就是<strong>确保到达数据库的流量最小化</strong>。</p><p>前面的基本方案里我们讨论的是使用唯一索引，并且提及了这种方案的缺陷，就是性能完全取决于数据库的性能。很明显，数据库是撑不住高并发的，尤其是高并发写流量。所以我们就要想尽一切办法让流量在到达数据库之前就返回了。</p><p>这时候我们就需要一个高效的数据结构，帮助我们判断某个请求或者消息是否已经被处理过了。布隆过滤器就非常适合用来解决这个问题。但是布隆过滤器本身存在假阳性的问题。也就是说，一个消息明明没有被处理过，但是布隆过滤器可能误报你处理过了。所以我们可以在布隆过滤器之后再加一个 Redis，存储近期处理过的业务 key。</p><p>所以整个流程就变成了图片中展示的这样。</p><p><img src=\"https://static001.geekbang.org/resource/image/31/27/31de9d54e0d922179e27234d8a02yy27.png?wh=1920x1081\" alt=\"图片\"></p><p>在面试的时候你可以先介绍下这个方案的基本流程。</p><blockquote>\n<p>我在公司设计过一个高并发的幂等方案。这个幂等方案需要用到布隆过滤器、Redis 和唯一索引。方案的基本思路是，如果依赖于数据库唯一索引来判断幂等，那么数据库撑不住高并发。所以我们就想办法在使用唯一索引之前，尽可能先削减流量。这个场景就非常适合使用布隆过滤器。而为了避免假阳性的问题，进一步降低发送到数据库的流量，在布隆过滤器和数据库之间再引入一个 Redis。<br>\n&nbsp;<br>\n基本流程是这样的：<br>\n&nbsp;<br>\n首先，一个请求过来的时候，我们会利用布隆过滤器来判断它有没有被处理过。如果布隆过滤器说没有处理过，那么就确实没有被处理过，可以直接处理。如果布隆过滤器说处理过（可能是假阳性），那么就要执行下一步。<br>\n&nbsp;<br>\n第二步就是利用 Redis 存储近期处理过的 key。如果 Redis 里面有这个 key，说明它的确被处理过了，直接返回，否则进入第三步。这一步的关键就是 key 的过期时间应该是多长。<br>\n&nbsp;<br>\n第三步则是利用唯一索引，如果唯一索引冲突了，那么就代表已经处理过了。这个唯一索引一般就是业务的唯一索引，并不需要额外创建一个索引。<br>\n面试官大概率会先问你布隆过滤器的基本知识，然后追问其中的一些细节，现在我们一个一个看。</p>\n</blockquote><h3>更新顺序</h3><p>第一个问题：业务方第一次处理完这个请求，我们该怎么更新这个系统？先更新布隆过滤器，还是先更新 Redis，或者是先更新数据库的唯一索引？</p><p>答案是先更新数据库的唯一索引，因为数据库里的数据是最准确的。</p><blockquote>\n<p>如果业务方是第一次执行这个请求，它需要把更新数据库的操作放到自己的业务本地事务里面。等业务方提交的时候，一起提交。在数据库事务提交之后，再去更新布隆过滤器和 Redis。这时候失败了影响也不大，因为最终重复请求被处理的时候，会因为唯一索引冲突而报错，这时候我们就知道这个请求是重复请求了。</p>\n</blockquote><p><img src=\"https://static001.geekbang.org/resource/image/b7/e8/b7c4f76e9bf9da92e61786baf1637ee8.png?wh=1920x1081\" alt=\"图片\"></p><p>后面无论是先更新布隆过滤器，还是先更新 Redis，或者并发更新，都是可以的，这一点不太重要。</p><p>可以说这个方案最终都是要依靠唯一索引来兜底的。也就是说不管什么原因导致布隆过滤器或者 Redis 没生效，只要跑到了插入唯一索引这一步，都可以确保你最终不会重复处理消息或者请求。</p><h3>Redis key 的过期时间</h3><p>刚刚我提到了一个关键点，就是 key 的过期时间应该多长这个问题。简单来说，Redis 的作用就是在布隆过滤器之后进一步削减流量，而 key 的过期时间就决定了削减流量的效果，所以只需要确保重复请求过来的时候，这个 key 还没过期就可以了。</p><p>如果面试官问起来，你可以这么回答。</p><blockquote>\n<p>Redis  这一步是为了进一步削减流量，关键就是要确保重复请求过来的时候，key 还没过期。举个例子，假如说预计某个特定业务的重试请求会在 10 分钟内到达，那么可以把过期时间设置成 11 分钟，多出来的一分钟就是余量。</p>\n</blockquote><p>这个地方你也可以进一步总结一下。</p><blockquote>\n<p>但是如果并发非常高，以至于 key 非常多，也要考虑 Redis 能不能放下这么多 key。另外一个就是有些业务的重试间隔非常长，比如说一小时，这就不太适合引入 Redis 了。可以考虑使用这个方案的简化版本。</p>\n</blockquote><h3>简化方案</h3><p>这个三合一的方案，也可以简化成二合一方案。第一种就是布隆过滤器+唯一索引。这种方案就比较适合重试间隔非常大的业务。</p><p><img src=\"https://static001.geekbang.org/resource/image/55/41/552c4cbdcb6693486b589344da509a41.png?wh=1920x1081\" alt=\"图片\"></p><p>还可以简化成Redis + 唯一索引，如果 Redis 资源足够，而且数据库性能比较差，那么这个方案要更好一点。</p><p><img src=\"https://static001.geekbang.org/resource/image/e2/2b/e23ab1e80b43ac7760a1794d6522192b.png?wh=1920x1081\" alt=\"图片\"></p><p>你可以介绍一下这两个方案。</p><blockquote>\n<p>如果说业务并发不是特别高，或者说不想用这么复杂的方案，那么可以考虑使用简化方案。<br>\n&nbsp;<br>\n第一种简化方案就是只用布隆过滤器和唯一索引。如果 Redis 资源不足，又或者重复请求间隔太长，导致使用 Redis 的效果不好，那么就比较适合用这个简化方案。第二种简化方案就是只用 Redis 和唯一索引。Redis 资源多，又或者担心布隆过滤器的假阳性问题，就可以采用这个方案。</p>\n</blockquote><p>最后总结一下。</p><blockquote>\n<p>其实最开始的时候我是建议用第一个简化方案的，后面如果发现假阳性问题非常严重，那么就可以引入 Redis。</p>\n</blockquote><p>接下来，我们从优化性能的角度来看，第一个可以考虑的就是本地布隆过滤器。</p><h3>本地布隆过滤器</h3><p>当看到本地两个字的时候，我不知道你有没有想起前面很多节课里面，我都提过类似的解决方案。这里我要再一次使用本地内存来进一步提高性能了。整体思路是利用一致性哈希等类型的算法执行负载均衡，确保同一个 key 的请求落到同一个实例上，那么我就可以在这台机器上使用基于本地内存的布隆过滤器了。</p><p><img src=\"https://static001.geekbang.org/resource/image/bd/40/bd6afdd990029bd961e3f939c2f36840.png?wh=1920x1081\" alt=\"图片\"></p><p>当然，在消息队列的场景下，这个问题就变成了在发消息的时候要把同一个业务的消息发到同一个分区。这样就可以在消费者身上使用基于本地内存的布隆过滤器了。</p><p><img src=\"https://static001.geekbang.org/resource/image/95/c7/955c47ae7337bbe8da388cba1bfb86c7.png?wh=1920x944\" alt=\"图片\"></p><p>而在使用了本地布隆过滤器之后，也可以考虑把 Redis 替换为本地内存。不过一般来说本地内存不多的话，还是使用 Redis 比较好。因为能够通过布隆过滤器的请求就已经是少数了，不值得浪费宝贵的本地内存换取一点点性能的提升。</p><p>所以你可以进一步阐述这个方案，抓住关键词<strong>本地布隆过滤器</strong>。</p><blockquote>\n<p>在性能要求非常苛刻的情况下，可以考虑使用本地布隆过滤器，但是这要和负载均衡结合在一起使用。比如说在消息消费的场景下，应该要求生产者把同一个 key 的消息都发到同一个分区上，这样对应的消费者就可以使用本地布隆过滤器了。</p>\n</blockquote><p>紧接着你可以补充一段话，关键词就是<strong>重建本地布隆过滤器</strong>。</p><blockquote>\n<p>本地布隆过滤器在服务器重新启动之后，重建起来也很简单，基本上有两种思路。一种就是不用重建，直接处理新请求。在处理新请求的过程中，逐步重建起布隆过滤器。这种思路适合时效性很强的请求，比如说今天就不可能收到昨天的重复请求这种场景。<br>\n&nbsp;<br>\n另外一种思路就是利用过去一段时间的数据，比如说我预计我今天收到的重复请求最多来自三天前，那么我就用这三天内处理过的请求来构建布隆过滤器。<br>\n&nbsp;<br>\n布隆过滤器不准确也没关系，反正有唯一索引兜底，只需要小心不要让太多流量最终落到唯一索引上就可以。</p>\n</blockquote><p>使用本地布隆过滤器就已经很快了，但如果你还想进一步提高性能，那么就可以考虑下使用布隆过滤器的替代品。</p><h2>布隆过滤器的替代品</h2><p>在一些场景下，你可以用更加高效的数据结构 —— bit array。如果 key 本身就是数字，比如数据库某张表的自增主键，像这种情况下，bit array 性能更好，并且更能节省内存。</p><p>那么你面试有两种策略，一种策略就是直接在前面介绍方案的基本流程的时候，你就把布隆过滤器换成 bit array。另外一种策略就是补充说明，强调这个方案<strong>可以自由切换到 bit array 上</strong>。</p><blockquote>\n<p>我这里还在布隆过滤器这边做了一个抽象，也就是说，对于一些业务，其实我这里可以把布隆过滤器换成 bit array 的结构。比如说某个业务要求判断幂等，用的就是业务的自增主键，那么他们就可以使用 bit array 这个实现来判断幂等。这里也有一个小技巧，就是假如说自增主键的起点是 N，那么在 bit array 的第一位就可以表示为 N，第二位表示为 N + 1，这样就能进一步节省内存。</p>\n</blockquote><p>最后的小技巧是平时我使用 bit array 的时候使用的。有些时候为了防止竞争对手猜到自己的业务量，自增主键不是从 0 开始的，又或者在使用分布式 ID 的时候，ID 也不是从 0 开始的。假如说最小的 ID 是 5,000,000。那么 bit arry 里的第一个比特位就可以表示为  5,000,000，第二个比特位就表示为 5,000,001。</p><p>到这一步，幂等相关的内容你就已经刷到极致了。</p><h2>面试思路总结</h2><p>最后我们来总结一下这节课的内容。最开始我给你介绍了布隆过滤器，这是你理解后面方案的关键。然后我们分析了一下重复消费的可能原因，一个是生产者重复发送，另一个是消费者重复消费。</p><p>总的来说，解决重复消费的思路就一条：<strong>让消费者做到幂等</strong>。所以问题就是怎么做到幂等。那么最简单的方案就是<strong>唯一索引</strong>，然后我们深入分析了<strong>有本地事务和没有本地事务这两种情况下怎么将数据插入到唯一索引。</strong></p><p>最后我给出了一个<strong>布隆过滤器 + Redis + 唯一索引的方案</strong>，这个方案是真正能撑住高并发的幂等方案。你要理解它的基本步骤，然后在面试过程中深入讨论如何更新系统、Redis 的 key 过期时间、简化方案、本地布隆过滤器、布隆过滤器的替代品这几个点，赢得面试的竞争优势。</p><p><img src=\"https://static001.geekbang.org/resource/image/29/9a/29819e0d5b0430b7c2ef56b790a7c49a.jpg?wh=2502x2125\" alt=\"\"></p><h2>思考题</h2><p>最后请你来思考2个问题。</p><ul>\n<li>我在基本思路的唯一索引部分画了一张图，关键点是在 RR 隔离级别下重复请求的插入操作会被阻塞。那么如果隔离级别不是 RR 的话，你觉得会发生什么？</li>\n<li>如果你的流量中，几乎不存在重复请求，比如说重复请求占比不到 1%，那么你觉得最后一个方案的效果如何？</li>\n</ul><p>欢迎你把你思考后的结果分享到评论区，也欢迎你把这节课分享给需要的朋友，我们下节课再见！</p>","comments":[{"had_liked":false,"id":379743,"user_name":"shuff1e","can_delete":false,"product_type":"c1","uid":1756280,"ip_address":"北京","ucode":"85601271951B5A","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83ep075ibtmxMf3eOYlBJ96CE9TEelLUwePaLqp8M75gWHEcM3za0voylA0oe9y3NiaboPB891rypRt7w/132","comment_is_top":false,"comment_ctime":1692367012,"is_pvip":false,"replies":[{"id":138339,"content":"嘿嘿，感谢感谢。你还可以考虑将同一个 Key 的都打过去一个分区，然后直接就不需要锁了。小心 rebalance 问题就可以。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1692528874,"ip_address":"广东","comment_id":379743,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"之前遇到过类似场景，QPS不高，用了一个分布式的悲观锁，同一个key的请求都会竞争这个分布式锁，只有竞争成功的才会继续往下执行。\n没有想到过布隆过滤机，bit array，再加上redis的方案，可能是场景也不太一样。\n不过也不得不感叹一句，人外有人，天外有天，大明老师还是对这种case做了一个系统的分析。","like_count":7,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":626092,"discussion_content":"嘿嘿，感谢感谢。你还可以考虑将同一个 Key 的都打过去一个分区，然后直接就不需要锁了。小心 rebalance 问题就可以。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1692528874,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":389917,"user_name":"下一夜的风","can_delete":false,"product_type":"c1","uid":1105539,"ip_address":"广东","ucode":"5CA4C5F34522C8","user_header":"https://static001.geekbang.org/account/avatar/00/10/de/83/691d146f.jpg","comment_is_top":false,"comment_ctime":1713883702,"is_pvip":false,"replies":[{"id":141976,"content":"嘿嘿，你发现了一个优化的手段。布隆过滤器重建的时候会有比较大问题，所以你可以考虑在重建的时候直接创建一个新的布隆过滤器，用新老布隆过滤器运行一段时间，然后删除老的布隆过滤器，切换到新的布隆过滤器。\n\n这样会比较好一些，可以规避突然重建的时候，没有数据导致大量请求穿透到数据库。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1715230729,"ip_address":"广东","comment_id":389917,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"redis 的布隆过滤器是不是也需要定时重建，不然假阳性会越来越严重？","like_count":5,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":644396,"discussion_content":"嘿嘿，你发现了一个优化的手段。布隆过滤器重建的时候会有比较大问题，所以你可以考虑在重建的时候直接创建一个新的布隆过滤器，用新老布隆过滤器运行一段时间，然后删除老的布隆过滤器，切换到新的布隆过滤器。\n\n这样会比较好一些，可以规避突然重建的时候，没有数据导致大量请求穿透到数据库。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1715230729,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":379718,"user_name":"humor","can_delete":false,"product_type":"c1","uid":1181867,"ip_address":"浙江","ucode":"9B48C4C7BEC92C","user_header":"https://static001.geekbang.org/account/avatar/00/12/08/ab/caec7bca.jpg","comment_is_top":false,"comment_ctime":1692342525,"is_pvip":false,"replies":[{"id":138351,"content":"好处就是挡住绝大部分重复请求。也就是说，如果你基本没有重复请求，那么这个方案就没啥用。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1692542467,"ip_address":"广东","comment_id":379718,"utype":1}],"discussion_count":14,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"布隆过滤器 + 唯一索引的方案，不管走不走布隆过滤器，都会校验是否发生唯一冲突，那么布隆过滤器的意义是什么呢？因为每个消息都还会校验一下数据库的唯一性，有没有布隆过滤器对数据库来说都一样啊","like_count":5,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":626108,"discussion_content":"好处就是挡住绝大部分重复请求。也就是说，如果你基本没有重复请求，那么这个方案就没啥用。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1692542467,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":4,"child_discussions":[{"author":{"id":1164066,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c3/22/2d41fda1.jpg","nickname":"来呀，造作啊","note":"","ucode":"15AF3C66CFA7CB","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":627232,"discussion_content":"就算走布隆过滤器也还有假阳性的问题，还是去校验是否发生唯一冲突，这不是没有拦住么？","likes_number":5,"is_delete":false,"is_hidden":false,"ctime":1693905684,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":626108,"ip_address":"广东","group_id":0},"score":627232,"extra":""},{"author":{"id":2962485,"avatar":"","nickname":"yichen","note":"","ucode":"D83F6738AC6988","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":636214,"discussion_content":"如果是布隆过滤器+唯一索引的话，好像还是每一个重复请求都得去校验唯一索引吧？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1705835556,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":626108,"ip_address":"广东","group_id":0},"score":636214,"extra":""},{"author":{"id":2962485,"avatar":"","nickname":"yichen","note":"","ucode":"D83F6738AC6988","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":636215,"discussion_content":"就像文中 布隆过滤器+唯一索引 的那个流程图，不管是哪个分支，最后都会走向校验唯一索引","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1705835791,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":626108,"ip_address":"广东","group_id":0},"score":636215,"extra":""}]},{"author":{"id":1432755,"avatar":"https://static001.geekbang.org/account/avatar/00/15/dc/b3/1e09c2d5.jpg","nickname":"Homto","note":"","ucode":"EBA8CDB9FC4AFD","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":625981,"discussion_content":"插个眼，有同样的问题","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1692374441,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"四川","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2571871,"avatar":"","nickname":"Geek_175c29","note":"","ucode":"3FEAA79F93CFC0","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":651934,"discussion_content":"有点疑惑，我直接插入。如果报唯一索引冲突，就是重复的。不处理。不是更简单点","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1727774475,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"湖北","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1521585,"avatar":"https://static001.geekbang.org/account/avatar/00/17/37/b1/bb6ea9b7.jpg","nickname":"Mario","note":"","ucode":"C9B9220C5A8F5B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":625988,"discussion_content":"主要是为了削减并发流量，减轻数据库的压力","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1692407787,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"江苏","group_id":0},"score":2,"extra":"","child_discussion_number":5,"child_discussions":[{"author":{"id":3720570,"avatar":"https://static001.geekbang.org/account/avatar/00/38/c5/7a/c03cb56e.jpg","nickname":"一弦一柱思华年","note":"","ucode":"36F8086A275AA7","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1521585,"avatar":"https://static001.geekbang.org/account/avatar/00/17/37/b1/bb6ea9b7.jpg","nickname":"Mario","note":"","ucode":"C9B9220C5A8F5B","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":631101,"discussion_content":"为啥可以减轻数据库压力？布隆过滤器判断存在和不存在都会走到唯一索引吧，布隆过滤器判断不存在时需要把key插入到DB，判断存在时也要走到唯一索引兜底。。那问题就来了，怎么体现减轻数据库压力的？","likes_number":5,"is_delete":false,"is_hidden":false,"ctime":1699320032,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":625988,"ip_address":"广东","group_id":0},"score":631101,"extra":""},{"author":{"id":3601364,"avatar":"https://static001.geekbang.org/account/avatar/00/36/f3/d4/86a99ae0.jpg","nickname":"哆啦a喵","note":"","ucode":"AE5E51BB43753D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":3720570,"avatar":"https://static001.geekbang.org/account/avatar/00/38/c5/7a/c03cb56e.jpg","nickname":"一弦一柱思华年","note":"","ucode":"36F8086A275AA7","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":644022,"discussion_content":"判断存在不一定需要唯一索引兜底呀。\n\n我理解这里就是一个层层过滤的思想，举个不一定恰当的例子，布隆过滤器接受100%的流量，其中30%是不存在的数据，这样30%的流量直接插入mysql就好了。\n\nredis接受70%的流量进行过滤，发现这70%里有10%的假阳性，于是这10%的流量也直接插入mysql就行了。\n\n剩余的60%流量因为已经存在就不需要再插入mysql，通过唯一索引过滤了。这样数据库的流量也就减少了60%，当然40%的流量中还是会有个别重复数据，依然需要唯一索引兜一下底。\n\n而层层过滤的目的其实是性能最佳的布隆过滤器先接受100%流量，性能还不错的redis接受70%流量，性能最差的mysql只需要处理真正需要插入的那40%流量就可以了。\n\n但我是觉得，一般的业务还真用不到这么复杂的场景，这个还是面向面试学习，一般的去重用个redis key应该就ok了。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1714899554,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":631101,"ip_address":"北京","group_id":0},"score":644022,"extra":""},{"author":{"id":3601364,"avatar":"https://static001.geekbang.org/account/avatar/00/36/f3/d4/86a99ae0.jpg","nickname":"哆啦a喵","note":"","ucode":"AE5E51BB43753D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":3720570,"avatar":"https://static001.geekbang.org/account/avatar/00/38/c5/7a/c03cb56e.jpg","nickname":"一弦一柱思华年","note":"","ucode":"36F8086A275AA7","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":644025,"discussion_content":"感觉对于重复数据少的场景，收益很低，看看老师方便的话能不能解答一下。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1714899892,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":631101,"ip_address":"北京","group_id":0},"score":644025,"extra":""}]},{"author":{"id":1367048,"avatar":"https://static001.geekbang.org/account/avatar/00/14/dc/08/64f5ab52.jpg","nickname":"陈斌","note":"","ucode":"B639AB5F6AA03D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":625983,"discussion_content":"布隆过滤器可以提前判断出索引不冲突的情况，可以规避大部门流量进去数据库。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1692376576,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":380796,"user_name":"Geek_48fcdf","can_delete":false,"product_type":"c1","uid":3694113,"ip_address":"北京","ucode":"A8A52020242D2B","user_header":"","comment_is_top":false,"comment_ctime":1694160208,"is_pvip":false,"replies":[{"id":138626,"content":"一个是结合前面的一致性哈希负载均衡，这样使用本地的布隆过滤器效果还可以。\n\n如果使用 Redis 的话，确实是难以避免两次 Redis 操作。也可以考虑使用 lua 脚本直接封装。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1694181945,"ip_address":"广东","comment_id":380796,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"布隆+redis+唯一键方案里，布隆过滤器如果使用机器内存则那么无法解决分布式问题，如果使用redis存就得查两次redis，这里的布隆过滤器怎么个部署才有意义？","like_count":2,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":627476,"discussion_content":"一个是结合前面的一致性哈希负载均衡，这样使用本地的布隆过滤器效果还可以。\n\n如果使用 Redis 的话，确实是难以避免两次 Redis 操作。也可以考虑使用 lua 脚本直接封装。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1694181945,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":380326,"user_name":"江 Nina","can_delete":false,"product_type":"c1","uid":1655563,"ip_address":"北京","ucode":"18E41503CC43C2","user_header":"https://static001.geekbang.org/account/avatar/00/19/43/0b/7688f18c.jpg","comment_is_top":false,"comment_ctime":1693381055,"is_pvip":false,"replies":[{"id":138535,"content":"可以啊，这就是我在后面提到的，你可以用 bitmap 取代布隆过滤器。\n\n不过bitmap 之后其实没太大必要接 Redis 了，因为 bitmap 咩有假阳性。也就是说，Bitmap 说有就是有，没有就是没有。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1693488116,"ip_address":"广东","comment_id":380326,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"感觉布隆过滤器的假阳性坑挺大的，面试的时候能否这么设计呢：bitmap数组 + redis + mysql唯一索引，作为两点方案呢，因为大多数业务的用的唯一约束都是数字感觉。","like_count":2,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":626916,"discussion_content":"可以啊，这就是我在后面提到的，你可以用 bitmap 取代布隆过滤器。\n\n不过bitmap 之后其实没太大必要接 Redis 了，因为 bitmap 咩有假阳性。也就是说，Bitmap 说有就是有，没有就是没有。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1693488116,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":1655563,"avatar":"https://static001.geekbang.org/account/avatar/00/19/43/0b/7688f18c.jpg","nickname":"江 Nina","note":"","ucode":"18E41503CC43C2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":626967,"discussion_content":"明白了谢谢老师","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1693540843,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":626916,"ip_address":"北京","group_id":0},"score":626967,"extra":""}]}]},{"had_liked":false,"id":388157,"user_name":"天天有吃的","can_delete":false,"product_type":"c1","uid":1604355,"ip_address":"福建","ucode":"6267FE8E68DEE5","user_header":"https://static001.geekbang.org/account/avatar/00/18/7b/03/03583011.jpg","comment_is_top":false,"comment_ctime":1709526228,"is_pvip":false,"replies":[{"id":141341,"content":"布隆过滤器是全量的，所以你有多少数据，就有多长，甚至还要长一些，因为要考虑冲突的问题（假阳性）。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1709714321,"ip_address":"广东","comment_id":388157,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"老师请问下，redis中的布隆过滤器长度是默认的，还是自己设置的呢？如果是自己设置的，多少长度合适呢？我想有没有一种情况位数组所有的元素都是1，那么布隆过滤器不是没用了？redis中会自动扩容吗？","like_count":1,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":638586,"discussion_content":"布隆过滤器是全量的，所以你有多少数据，就有多长，甚至还要长一些，因为要考虑冲突的问题（假阳性）。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1709714321,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":383034,"user_name":"Lum","can_delete":false,"product_type":"c1","uid":3231352,"ip_address":"江苏","ucode":"7EF828425E685A","user_header":"https://static001.geekbang.org/account/avatar/00/31/4e/78/ee4e12cc.jpg","comment_is_top":false,"comment_ctime":1698329176,"is_pvip":false,"replies":[{"id":139763,"content":"赞！\n这边你说“但是未提交的数据仍然可以被其他事务读取到”是不是写错了？这个应该是 Read Uncommitted 吧？","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1699283986,"ip_address":"广东","comment_id":383034,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"Read Committed 隔离级别下：如果两个事务同时插入相同的数据，那么后提交的事务会被阻塞，等待先提交的事务完成后才能继续执行。这是因为 Read Committed 隔离级别只保证了读取到的数据是已经提交的，但是未提交的数据仍然可以被其他事务读取到。\n\nRepeatable Read 隔离级别下：如果两个事务同时插入相同的数据，那么后提交的事务会被回滚，因为 Repeatable Read 隔离级别保证了事务在执行过程中多次读取同一个数据时，得到的结果是一致的。如果有重复的插入操作，则会破坏这个一致性，因此后提交的事务会被回滚。","like_count":1,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":631078,"discussion_content":"赞！\n这边你说“但是未提交的数据仍然可以被其他事务读取到”是不是写错了？这个应该是 Read Uncommitted 吧？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1699283986,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":380451,"user_name":"Geek8004","can_delete":false,"product_type":"c1","uid":2328971,"ip_address":"中国香港","ucode":"B3828F6414BDB0","user_header":"","comment_is_top":false,"comment_ctime":1693625762,"is_pvip":false,"replies":[{"id":138600,"content":"这里有一个区别。你业务上的成功和系统上成功。\n\n举个例子来说，如果插入唯一索引之后，你的业务逻辑执行失败了，但是这是符合你的系统的预期的，这在这里也叫做业务成功=。=。\n\n也就是说，只要你的业务执行了，根据输入是成功与失败，这里不关心的。\n\n在异步检测系统里面，它只检测初始状态，然后去对比你的业务实际执行情况，执行更新。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1693896047,"ip_address":"广东","comment_id":380451,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"非本地事务将数据插入到唯一索引的第二步处理业务逻辑,第三步将唯一索引对应的数据标记为完成状态.其中第二部为什么不可能失败呀,为什么只可能是第三步将唯一索引对应的数据标记为完成状态会失败? 假如处理业务逻辑里面 有调接口,或者插入数据到别的库表","like_count":1,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":627208,"discussion_content":"这里有一个区别。你业务上的成功和系统上成功。\n\n举个例子来说，如果插入唯一索引之后，你的业务逻辑执行失败了，但是这是符合你的系统的预期的，这在这里也叫做业务成功=。=。\n\n也就是说，只要你的业务执行了，根据输入是成功与失败，这里不关心的。\n\n在异步检测系统里面，它只检测初始状态，然后去对比你的业务实际执行情况，执行更新。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1693896047,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":379749,"user_name":"陈斌","can_delete":false,"product_type":"c1","uid":1367048,"ip_address":"广东","ucode":"B639AB5F6AA03D","user_header":"https://static001.geekbang.org/account/avatar/00/14/dc/08/64f5ab52.jpg","comment_is_top":false,"comment_ctime":1692377305,"is_pvip":false,"replies":[{"id":138410,"content":"哈哈哈哈，问题 2 可能出乎你的预料，重复请求占比 1% 的话，你只能挡住这 1% 的重复请求。\n\n你可能会奇怪，这不就是寄了吗？但是你要知道，如果你连正常的流量都处理不了，就不用谈别的了。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1692892975,"ip_address":"广东","comment_id":379749,"utype":1}],"discussion_count":4,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"问题1:\n\n如果隔离级别不是RR，就会出现在插入成功唯一索引之后，业务操作完成之后提交事务可能会出现失败的情况，导致因为索引冲突而引起的不必要的回滚。如果隔离级别为RR的话，就不会出现上述情况。\n\n问题2:\n\n老师您说的最后一种方案我认为是：布隆过滤器 + redis + 唯一索引方案\n重复请求占比为百分之1的话，该方案可以将近99%的流量挡在布隆过滤器 与 redis 层级，当然前提是redis的键值失效时间设置合理或者说重复请求的间隔时间很短或者说布隆过滤器没有出现假阳性，此时系统可以承受高并发流量。\n\n\n\n\n\n","like_count":1,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":626425,"discussion_content":"哈哈哈哈，问题 2 可能出乎你的预料，重复请求占比 1% 的话，你只能挡住这 1% 的重复请求。\n\n你可能会奇怪，这不就是寄了吗？但是你要知道，如果你连正常的流量都处理不了，就不用谈别的了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1692892975,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2770150,"avatar":"https://static001.geekbang.org/account/avatar/00/2a/44/e6/2c97171c.jpg","nickname":"sheep","note":"","ucode":"DAC2036F08CE27","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":635069,"discussion_content":"问题2典型的缓存穿透问题吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1704372673,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2328971,"avatar":"","nickname":"Geek8004","note":"","ucode":"B3828F6414BDB0","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":626894,"discussion_content":"为什么RR的隔离模式下面,提交事务失败了不会造成回滚呀.我理解只要事务提交失败的话,首次插入的唯一索引都会失败.","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1693472147,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"中国香港","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1239350,"avatar":"https://static001.geekbang.org/account/avatar/00/12/e9/36/f62471c5.jpg","nickname":"不诉离殇","note":"","ucode":"4F7BB1220ECED7","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":626861,"discussion_content":"mysql 5.6.21 实测 有唯一索引冲突的时候 rc模式下 后一个事务任然会被阻塞。\n\nmysql&gt; CREATE TABLE `t` (\n    -&gt;   `id` int(11) NOT NULL AUTO_INCREMENT,\n    -&gt;   `a` int(11) NOT NULL  ,\n    -&gt;   PRIMARY KEY (`id`),\n    -&gt;   UNIQUE KEY `a` (`a`)\n    -&gt; ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\nQuery OK, 0 rows affected (0.03 sec)\n\n事务A：\nmysql&gt; select @@tx_isolation;\n+----------------+\n| @@tx_isolation |\n+----------------+\n| READ-COMMITTED |\n+----------------+\n1 row in set (0.00 sec)\n\nmysql&gt; begin;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&gt; insert into t values(1,1);\nQuery OK, 1 row affected (0.00 sec)\n\n事务B：\nmysql&gt; select @@tx_isolation;\n+----------------+\n| @@tx_isolation |\n+----------------+\n| READ-COMMITTED |\n+----------------+\n1 row in set (0.00 sec)\nmysql&gt; begin;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql&gt; insert into t values(1,1);\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\n\n查看锁\n\nmysql&gt; select * from INNODB_LOCKS;\n+------------------------+-------------+-----------+-----------+---------------+------------+------------+-----------+----------+-----------+\n| lock_id                | lock_trx_id | lock_mode | lock_type | lock_table    | lock_index | lock_space | lock_page | lock_rec | lock_data |\n+------------------------+-------------+-----------+-----------+---------------+------------+------------+-----------+----------+-----------+\n| 19481992465:382044:3:2 | 19481992465 | S         | RECORD    | `zy_test`.`t` | PRIMARY    |     382044 |         3 |        2 | 1         |\n| 19481990396:382044:3:2 | 19481990396 | X         | RECORD    | `zy_test`.`t` | PRIMARY    |     382044 |         3 |        2 | 1         |\n+------------------------+-------------+-----------+-----------+---------------+------------+------------+-----------+----------+-----------+\n2 rows in set (0.00 sec)","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1693450199,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"四川","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":390250,"user_name":"哆啦a喵","can_delete":false,"product_type":"c1","uid":3601364,"ip_address":"北京","ucode":"AE5E51BB43753D","user_header":"https://static001.geekbang.org/account/avatar/00/36/f3/d4/86a99ae0.jpg","comment_is_top":false,"comment_ctime":1714899734,"is_pvip":false,"replies":[{"id":141965,"content":"是的。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1715229958,"ip_address":"广东","comment_id":390250,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"老师好，想咨询一下，这里我理解一般场景下如果不会出现高并发的重复消息，或者虽然高并发，但是消息重复的概率很低的话，使用这套架构的收益就很小了？","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":644385,"discussion_content":"是的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1715229958,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":390237,"user_name":"智商未成年","can_delete":false,"product_type":"c1","uid":1672749,"ip_address":"广东","ucode":"B39D13750DB255","user_header":"https://static001.geekbang.org/account/avatar/00/19/86/2d/90c206fe.jpg","comment_is_top":false,"comment_ctime":1714825364,"is_pvip":false,"replies":[{"id":141962,"content":"都可以，你看你需要。布隆过滤器主要是过滤重复请求。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1715228842,"ip_address":"广东","comment_id":390237,"utype":1}],"discussion_count":2,"race_medal":0,"score":3,"product_id":100551601,"comment_content":"没太get到布隆过滤器存在的意义，布隆过滤器存在假阳性问题，无论消息是否为重复消息，都需要到redis&#47;db进行唯一性校验。那感觉是不是可以直接使用redis对业务key加分布式锁基本上能避免重复消费的问题。","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":644382,"discussion_content":"都可以，你看你需要。布隆过滤器主要是过滤重复请求。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1715228843,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2037522,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/YbUxEV3741vKZAiasOXggWucQbmicJwIjg3HDE58oyibYXbSop9QQFqZ7X6OhynDoo6rDHwzK8njSeJjN9hx3pJXg/132","nickname":"黄堃健","note":"","ucode":"B4AD5250A41B3A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":645811,"discussion_content":"老师，布隆过滤器的作用只有在不存在重复消息的情况下，无需经过mysql的唯一索引判断，挡住一部分的流量。 ","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1716819316,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":390010,"user_name":"瀚海","can_delete":false,"product_type":"c1","uid":2062203,"ip_address":"上海","ucode":"E64C22F3F6D285","user_header":"https://static001.geekbang.org/account/avatar/00/1f/77/7b/338c4617.jpg","comment_is_top":false,"comment_ctime":1714099799,"is_pvip":false,"replies":[{"id":141974,"content":"你用 Kafka 怎么去重？如果是消费者这边去重，还是走到唯一索引这个老路上。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1715230612,"ip_address":"广东","comment_id":390010,"utype":1}],"discussion_count":2,"race_medal":0,"score":3,"product_id":100551601,"comment_content":"感觉重复消息相对量较小，而且大概率只有最近一段时间内会重复     布隆+redis+唯一索引，压力大多还是在数据库，流量大，数据库顶不住的           是不是可以布隆+redis, redis只存储最近一段时间数据来减少数据量，kafka消息处理根据业务遇到这段时间之前的数据直接丢弃             是否可行？  就是尽量避免引入数据库，数据库面对大数据量能力有限","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":644394,"discussion_content":"你用 Kafka 怎么去重？如果是消费者这边去重，还是走到唯一索引这个老路上。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1715230612,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":1,"child_discussions":[{"author":{"id":2062203,"avatar":"https://static001.geekbang.org/account/avatar/00/1f/77/7b/338c4617.jpg","nickname":"瀚海","note":"","ucode":"E64C22F3F6D285","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":644411,"discussion_content":"老师       不是用kafka去重      是把最近处理过得放入redis, 处理消息时先查下redis,看是否处理过    避免流量打在数据库上判重             一般场景，应该只有最近一段时间内的消息才会重复过来   是不是用redis判重就可以行？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1715231325,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":644394,"ip_address":"上海","group_id":0},"score":644411,"extra":""}]}]},{"had_liked":false,"id":384710,"user_name":"ilake","can_delete":false,"product_type":"c1","uid":1502716,"ip_address":"日本","ucode":"DF451C2288A54E","user_header":"","comment_is_top":false,"comment_ctime":1701378736,"is_pvip":false,"replies":[{"id":140341,"content":"我个人认为这种说法也没问题。并且，这两者加的锁也是有差别的。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1701846670,"ip_address":"广东","comment_id":384710,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100551601,"comment_content":"&gt; 关键点是在 RR 隔离级别下重复请求的插入操作会被阻塞。那么如果隔离级别不是 RR 的话，你觉得会发生什么？\n- 在 Repeatable Read（RR）隔离级别下，事务会在一开始就发现阻塞，因为在事务开始时，就会锁定读取的数据，确保了事务期间不会有其他事务修改这些数据。\n\n- 在 Read Committed（RC）隔离级别下，事务是在稍后才发现阻塞的，因为它们在读取数据时不会锁定行，只有在稍后尝试修改数据时，如果发现有其他事务已经修改了相同的数据，才会发生阻塞\n\n同樣都會被阻塞，只是時間點不同。\n請問這樣理解正確嗎？","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":633117,"discussion_content":"我个人认为这种说法也没问题。并且，这两者加的锁也是有差别的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1701846670,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":383761,"user_name":"Geek8004","can_delete":false,"product_type":"c1","uid":2328971,"ip_address":"广东","ucode":"B3828F6414BDB0","user_header":"","comment_is_top":false,"comment_ctime":1699584380,"is_pvip":false,"replies":[{"id":140362,"content":"对，重复请求不多效果就不好。至于比例多少，你可以自己根据业务来评估。我举个例子，如果你的数据库负载不高，那么你都不需要这个方案。如果你的数据库负载本身就很高了，那么你就算有一点点重复流量，也可以考虑加上去。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1701847825,"ip_address":"广东","comment_id":383761,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100551601,"comment_content":"布隆过滤器+redis+mysql 解决幂等消费问题的时候,假如重复的消息百分之2是不是就没多大用处? 重复消息到达百分是多少才能用这个方案.大概是什么样的场景配置可以用到这个场景;","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":633139,"discussion_content":"对，重复请求不多效果就不好。至于比例多少，你可以自己根据业务来评估。我举个例子，如果你的数据库负载不高，那么你都不需要这个方案。如果你的数据库负载本身就很高了，那么你就算有一点点重复流量，也可以考虑加上去。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1701847826,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":383581,"user_name":"一弦一柱思华年","can_delete":false,"product_type":"c1","uid":3720570,"ip_address":"广东","ucode":"36F8086A275AA7","user_header":"https://static001.geekbang.org/account/avatar/00/38/c5/7a/c03cb56e.jpg","comment_is_top":false,"comment_ctime":1699318768,"is_pvip":false,"replies":[{"id":140360,"content":"1. 使用 DB 兜底还可以有效防止节点崩溃，或者 Redis 崩溃的问题\n2. 一般设计布隆过滤器的时候，都会默认这个布隆过滤器能装下所有的数据，毕竟布隆过滤器本身消耗资源不多，所以至少我是没删除过布隆过滤器。不过这算是一个很好的思路，学习了。\n3. 主要是体现在重复请求的时候，可以避免 DB 操作。所以我说这个方案如果重复请求比例不高的时候，其实也没那么好用。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1701847671,"ip_address":"广东","comment_id":383581,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100551601,"comment_content":"老师您好，请问如果用bit array，加上一致性哈希负载均衡，是不是可以不用DB兜底了呢，因为不存在假阳性问题；另外，这个布隆过滤器是不是需要定期清空啊，如果时间久了，布隆过滤器里的每一位都设置为了1，那得到的结果就永远是存在了，此时布隆过滤器就失效了。还有一个疑惑点：布隆过滤器+唯一索引的方案，布隆过滤器判断不存在的话，是不是也需要把key插入到DB，这样的话，判断存在和不存在都涉及DB更新，削流作用是怎么体现的呢","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":633137,"discussion_content":"1. 使用 DB 兜底还可以有效防止节点崩溃，或者 Redis 崩溃的问题\n2. 一般设计布隆过滤器的时候，都会默认这个布隆过滤器能装下所有的数据，毕竟布隆过滤器本身消耗资源不多，所以至少我是没删除过布隆过滤器。不过这算是一个很好的思路，学习了。\n3. 主要是体现在重复请求的时候，可以避免 DB 操作。所以我说这个方案如果重复请求比例不高的时候，其实也没那么好用。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1701847671,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":381878,"user_name":"ZhiguoXue_IT","can_delete":false,"product_type":"c1","uid":2639055,"ip_address":"山西","ucode":"EAA83F53B54520","user_header":"https://static001.geekbang.org/account/avatar/00/28/44/cf/791d0f5e.jpg","comment_is_top":false,"comment_ctime":1696083072,"is_pvip":false,"replies":[{"id":139227,"content":"并没啥问题，就是直接用。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1696923150,"ip_address":"广东","comment_id":381878,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100551601,"comment_content":"老师请教一下，如果不是rr，唯一索引依然能用呢，有什么问题吗？","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":629295,"discussion_content":"并没啥问题，就是直接用。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1696923150,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":380199,"user_name":"tyro","can_delete":false,"product_type":"c1","uid":1955472,"ip_address":"广东","ucode":"D35A80546E7A2F","user_header":"https://static001.geekbang.org/account/avatar/00/1d/d6/90/2b949521.jpg","comment_is_top":false,"comment_ctime":1693197851,"is_pvip":false,"replies":[{"id":138549,"content":"看上去就都是阻塞啊，哈哈哈哈，不过底层细节上有一些不同，主要和锁机制有关。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1693489423,"ip_address":"广东","comment_id":380199,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100551601,"comment_content":"老师关于思考题1\n我在除串行外的三种隔离级别测试，重复请求都会阻塞。没有区别啊\n求解惑🙏","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":626931,"discussion_content":"看上去就都是阻塞啊，哈哈哈哈，不过底层细节上有一些不同，主要和锁机制有关。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1693489423,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":379779,"user_name":"peter","can_delete":false,"product_type":"c1","uid":1058183,"ip_address":"北京","ucode":"261C3FC001DE2D","user_header":"https://static001.geekbang.org/account/avatar/00/10/25/87/f3a69d1b.jpg","comment_is_top":false,"comment_ctime":1692497617,"is_pvip":false,"replies":[{"id":138413,"content":"是一种数据结构，有多种实现，可以本地实现，也可以借助 Redis 来实现。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1692893402,"ip_address":"广东","comment_id":379779,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100551601,"comment_content":"布隆过滤器具体是什么？是个DLL？或者一个jar包？另外，bit array具体是什么？是个数据类型吗？","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":626428,"discussion_content":"是一种数据结构，有多种实现，可以本地实现，也可以借助 Redis 来实现。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1692893402,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":379771,"user_name":"TimJuly","can_delete":false,"product_type":"c1","uid":1065064,"ip_address":"北京","ucode":"56FE7BF7447DEA","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eooNCNEO0vhRiagdrCnNW2LWzzV4g5tXJ9KkTu9hegCTx6lBrA06AZ3Uylb2wdKjvtrmZUWkKKHTGA/132","comment_is_top":false,"comment_ctime":1692456246,"is_pvip":false,"replies":[{"id":138411,"content":"1. 不要用长事务……政治正确但是无用的屁话。你可以考虑切割成几个小事务，然后引入重试机制，寻求最终一致性。你也可以给事务设置超时时间，这样超过时间限制的事务就直接回滚了。\n2. 什么锁？是唯一索引那里的锁吗？这里，理论上来说，这个超时时间是你预期别的业务的执行时间。这可以参考后续我分布式锁里讲到的，分布式锁拿锁应该等待多久。\n3. 数据库性能这边我没有评估过，但是如果你业务并发很高，重复请求很多的话，确实影响很大。另外一个影响是，第二个消息等待锁的时候，一直拿着这个数据库连接。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1692893360,"ip_address":"广东","comment_id":379771,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100551601,"comment_content":"如果处理逻辑比较复杂时间比较长，那么这个这将是一个长事务\n1、长事务对 MySQL 的压力如何解决？\n2、第二个并发的消息进来了，此时会进入锁等待，如果超时时间设置的不合理，有可能把应用拖挂，那么超时设置多久比较合理？\n3、第二个消息等待锁时会不会触发 MySQL 的死锁检测？会对数据库性能产生多大影响？","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":626426,"discussion_content":"1. 不要用长事务……政治正确但是无用的屁话。你可以考虑切割成几个小事务，然后引入重试机制，寻求最终一致性。你也可以给事务设置超时时间，这样超过时间限制的事务就直接回滚了。\n2. 什么锁？是唯一索引那里的锁吗？这里，理论上来说，这个超时时间是你预期别的业务的执行时间。这可以参考后续我分布式锁里讲到的，分布式锁拿锁应该等待多久。\n3. 数据库性能这边我没有评估过，但是如果你业务并发很高，重复请求很多的话，确实影响很大。另外一个影响是，第二个消息等待锁的时候，一直拿着这个数据库连接。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1692893360,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":379732,"user_name":"　扬帆丶启航　","can_delete":false,"product_type":"c1","uid":1235282,"ip_address":"福建","ucode":"4079D0889CD86C","user_header":"https://static001.geekbang.org/account/avatar/00/12/d9/52/73351eab.jpg","comment_is_top":false,"comment_ctime":1692351495,"is_pvip":false,"replies":[{"id":138340,"content":"要求业务方绕开这个唯一索引重试。相当于，除了没有插入唯一索引这个动作，其它都是一样的。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1692528916,"ip_address":"广东","comment_id":379732,"utype":1}],"discussion_count":2,"race_medal":0,"score":3,"product_id":100551601,"comment_content":"非本地事务唯一索引方案中，异步检测系统检测执行到业务失败后触发重试。这里的重试时直接执行业务方法还是直接再重新发送一条请求到消息队列中。如果是直接发送一条消息到消息队列中，在消费的时候不是还会触发唯一索引冲突吗?","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":626093,"discussion_content":"要求业务方绕开这个唯一索引重试。相当于，除了没有插入唯一索引这个动作，其它都是一样的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1692528916,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":1239350,"avatar":"https://static001.geekbang.org/account/avatar/00/12/e9/36/f62471c5.jpg","nickname":"不诉离殇","note":"","ucode":"4F7BB1220ECED7","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":626856,"discussion_content":"异步重试的时候会不会出现一种情况，之前消费消息的业务处理逻辑还没处理完 此时异步程序检测到记录的状态值为初始值，因为正常的业务流程没完成，业务比较也发现业务没有完成，然后发起重试 这样就导致业务其实还是执行了多次？ 另外怎么进行业务是不是真的完成了的检测呢？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1693448597,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":626093,"ip_address":"四川","group_id":0},"score":626856,"extra":""}]}]},{"had_liked":false,"id":379709,"user_name":"进击的和和","can_delete":false,"product_type":"c1","uid":2986043,"ip_address":"四川","ucode":"8978AF077FA6AD","user_header":"https://static001.geekbang.org/account/avatar/00/2d/90/3b/791d0f5e.jpg","comment_is_top":false,"comment_ctime":1692331011,"is_pvip":false,"replies":[{"id":138341,"content":"1. 你这个可以放大试试嘛？\n2. 坦白说，我也想不到更加合适的方案了。应该说完全不使用唯一索引的东西，还是比较难想到的。当然，别的中间件的具备排它性和持久化的类似机制应该也可以。\n3. 你最终插入唯一索引应该还是冲突了吧？\n4. 赞！咆哮位图这个东西我还真没试过，有机会可以尝试一下。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1692529152,"ip_address":"广东","comment_id":379709,"utype":1}],"discussion_count":2,"race_medal":0,"score":4,"product_id":100551601,"comment_content":"作者你好\n(1)结尾总结的图看不清哈\n(2)除了唯一索引还有什么方式解决重复消费吗?\n(3)那么如果隔离级别不是 RR 的话，你觉得会发生什么?我把隔离级别设置成了rc,第二个事务提交了并未报错,不过数据还是第一个视图提交的数据。\n(4)如果你的流量中，几乎不存在重复请求，比如说重复请求占比不到 1%，那么你觉得最后一个方案的效果如何?这里会浪费空间,可以用咆哮位图嘛","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":626094,"discussion_content":"1. 你这个可以放大试试嘛？\n2. 坦白说，我也想不到更加合适的方案了。应该说完全不使用唯一索引的东西，还是比较难想到的。当然，别的中间件的具备排它性和持久化的类似机制应该也可以。\n3. 你最终插入唯一索引应该还是冲突了吧？\n4. 赞！咆哮位图这个东西我还真没试过，有机会可以尝试一下。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1692529153,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":2986043,"avatar":"https://static001.geekbang.org/account/avatar/00/2d/90/3b/791d0f5e.jpg","nickname":"进击的和和","note":"","ucode":"8978AF077FA6AD","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":626124,"discussion_content":"1.编辑已替换高清图了哈\n3.应该是的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1692578495,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":626094,"ip_address":"四川","group_id":0},"score":626124,"extra":""}]}]},{"had_liked":false,"id":395146,"user_name":"超级费事儿","can_delete":false,"product_type":"c1","uid":1434114,"ip_address":"四川","ucode":"FD873FF4ADAA5F","user_header":"https://static001.geekbang.org/account/avatar/00/15/e2/02/488aec70.jpg","comment_is_top":false,"comment_ctime":1729589900,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100551601,"comment_content":"真实使用的时候，重复请求真的不多，所以使用布隆过滤+redis+mysql的方案最终还是mysql的唯一索引抗住了所有。","like_count":1},{"had_liked":false,"id":395290,"user_name":"强庚","can_delete":false,"product_type":"c1","uid":2109653,"ip_address":"北京","ucode":"D0525C40848705","user_header":"","comment_is_top":false,"comment_ctime":1730102317,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100551601,"comment_content":"老师想请教一下，关于一致性哈希将相同key的请求落在一个实例上，生产一般是怎么做的。遇到的服务一般是多实例部署在k8s上的，想要针对某个请求特定字段的参数进行一致性哈希一般是改哪里，改k8s吗","like_count":0},{"had_liked":false,"id":394541,"user_name":"Zen","can_delete":false,"product_type":"c1","uid":1044292,"ip_address":"湖北","ucode":"32DB75B62FE095","user_header":"https://static001.geekbang.org/account/avatar/00/0f/ef/44/5e172496.jpg","comment_is_top":false,"comment_ctime":1727093116,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100551601,"comment_content":"有一个疑问，为何要用rr隔离级别呢？\n在已经存在1 2 3的情况下，先来事务1 插入4，再来事务2尝试插入5， 事务2会被阻塞么？ 会不会因为阻塞反倒拉低性能","like_count":0},{"had_liked":false,"id":390648,"user_name":"itschenxiang","can_delete":false,"product_type":"c1","uid":1519547,"ip_address":"四川","ucode":"7D90194AC52435","user_header":"https://static001.geekbang.org/account/avatar/00/17/2f/bb/f663ac5a.jpg","comment_is_top":false,"comment_ctime":1715851971,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100551601,"comment_content":"老师，这里说的“在避免重复消费的实践中你就记住一个原则：一定要把消费逻辑设计成幂等的。”，幂等是指什么，是指消息队列消息的幂等（比如一条消息通过唯一索引方式避免重复消费），还是指还要考虑生产者重试发送重复消息的情况呢？","like_count":0},{"had_liked":false,"id":390361,"user_name":"达芬奇","can_delete":false,"product_type":"c1","uid":2451310,"ip_address":"北京","ucode":"B174F5347557B3","user_header":"https://static001.geekbang.org/account/avatar/00/25/67/6e/ec7299ec.jpg","comment_is_top":false,"comment_ctime":1715214795,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100551601,"comment_content":"老师，你的文章写得非常好","like_count":0},{"had_liked":false,"id":389145,"user_name":"tg1","can_delete":false,"product_type":"c1","uid":1220495,"ip_address":"北京","ucode":"C2F5C729B788D0","user_header":"https://static001.geekbang.org/account/avatar/00/12/9f/8f/5fe6fef2.jpg","comment_is_top":false,"comment_ctime":1711681082,"is_pvip":false,"replies":null,"discussion_count":4,"race_medal":0,"score":4,"product_id":100551601,"comment_content":"这布隆过滤器有啥用啊？存在假阳性问题不是100%可靠，还要走一遍唯一索引校验😂","like_count":0,"discussions":[{"author":{"id":2025093,"avatar":"","nickname":"Geek_1903ed","note":"","ucode":"42B6DAE6AE6561","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":649619,"discussion_content":"我能想到的一个有用场景是消息回溯，正常业务场景下这套方案感觉作用很小，哪来那么多重复的消息投递","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1723646405,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3864871,"avatar":"","nickname":"Geek_304156","note":"","ucode":"81FDF888FF029E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":640827,"discussion_content":"可以挡住一部分到达MySQL的请求","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1711899383,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":2,"child_discussions":[{"author":{"id":1672749,"avatar":"https://static001.geekbang.org/account/avatar/00/19/86/2d/90c206fe.jpg","nickname":"智商未成年","note":"","ucode":"B39D13750DB255","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":3864871,"avatar":"","nickname":"Geek_304156","note":"","ucode":"81FDF888FF029E","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":643958,"discussion_content":"1. 如果是布隆+mysql的设计，就无法挡住的，因为布隆存在假阳性的问题，无论是否为重复消息，最终都需要到mysql进行唯一性校验。\n2. 如果是布隆+redis+mysql的设置，重复消息的过滤也是在redis/db层去解决 \n个人感觉布隆没有起到流量过滤的作用。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1714825843,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":640827,"ip_address":"广东","group_id":0},"score":643958,"extra":""},{"author":{"id":2037522,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/YbUxEV3741vKZAiasOXggWucQbmicJwIjg3HDE58oyibYXbSop9QQFqZ7X6OhynDoo6rDHwzK8njSeJjN9hx3pJXg/132","nickname":"黄堃健","note":"","ucode":"B4AD5250A41B3A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1672749,"avatar":"https://static001.geekbang.org/account/avatar/00/19/86/2d/90c206fe.jpg","nickname":"智商未成年","note":"","ucode":"B39D13750DB255","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":645812,"discussion_content":"布隆过滤器，在这种情况下生效，非重复请求，直接查询布隆过滤器，不用走mysql查询， 不知道我的理解是否正确","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1716819473,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":643958,"ip_address":"广东","group_id":0},"score":645812,"extra":""}]}]}]}