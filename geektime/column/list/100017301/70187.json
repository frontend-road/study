{"id":70187,"title":"29 | 堆的应用：如何快速获取到Top 10最热门的搜索关键词？","content":"<p>搜索引擎的热门搜索排行榜功能你用过吗？你知道这个功能是如何实现的吗？实际上，它的实现并不复杂。搜索引擎每天会接收大量的用户搜索请求，它会把这些用户输入的搜索关键词记录下来，然后再离线地统计分析，得到最热门的Top 10搜索关键词。</p><p>那请你思考下，<strong><span class=\"orange\">假设现在我们有一个包含10亿个搜索关键词的日志文件，如何能快速获取到热门榜Top 10的搜索关键词呢？</span></strong></p><p>这个问题就可以用堆来解决，这也是堆这种数据结构一个非常典型的应用。上一节我们讲了堆和堆排序的一些理论知识，今天我们就来讲一讲，堆这种数据结构几个非常重要的应用：优先级队列、求Top K和求中位数。</p><h2>堆的应用一：优先级队列</h2><p>首先，我们来看第一个应用场景：优先级队列。</p><p>优先级队列，顾名思义，它首先应该是一个队列。我们前面讲过，队列最大的特性就是先进先出。不过，在优先级队列中，数据的出队顺序不是先进先出，而是按照优先级来，优先级最高的，最先出队。</p><p>如何实现一个优先级队列呢？方法有很多，但是用堆来实现是最直接、最高效的。这是因为，堆和优先级队列非常相似。一个堆就可以看作一个优先级队列。很多时候，它们只是概念上的区分而已。往优先级队列中插入一个元素，就相当于往堆中插入一个元素；从优先级队列中取出优先级最高的元素，就相当于取出堆顶元素。</p><!-- [[[read_end]]] --><p>你可别小看这个优先级队列，它的应用场景非常多。我们后面要讲的很多数据结构和算法都要依赖它。比如，赫夫曼编码、图的最短路径、最小生成树算法等等。不仅如此，很多语言中，都提供了优先级队列的实现，比如，Java的PriorityQueue，C++的priority_queue等。</p><p>只讲这些应用场景比较空泛，现在，我举两个具体的例子，让你感受一下优先级队列具体是怎么用的。</p><h3>1.合并有序小文件</h3><p>假设我们有100个小文件，每个文件的大小是100MB，每个文件中存储的都是有序的字符串。我们希望将这些100个小文件合并成一个有序的大文件。这里就会用到优先级队列。</p><p>整体思路有点像归并排序中的合并函数。我们从这100个文件中，各取第一个字符串，放入数组中，然后比较大小，把最小的那个字符串放入合并后的大文件中，并从数组中删除。</p><p>假设，这个最小的字符串来自于13.txt这个小文件，我们就再从这个小文件取下一个字符串，放到数组中，重新比较大小，并且选择最小的放入合并后的大文件，将它从数组中删除。依次类推，直到所有的文件中的数据都放入到大文件为止。</p><p>这里我们用数组这种数据结构，来存储从小文件中取出来的字符串。每次从数组中取最小字符串，都需要循环遍历整个数组，显然，这不是很高效。有没有更加高效方法呢？</p><p>这里就可以用到优先级队列，也可以说是堆。我们将从小文件中取出来的字符串放入到小顶堆中，那堆顶的元素，也就是优先级队列队首的元素，就是最小的字符串。我们将这个字符串放入到大文件中，并将其从堆中删除。然后再从小文件中取出下一个字符串，放入到堆中。循环这个过程，就可以将100个小文件中的数据依次放入到大文件中。</p><p>我们知道，删除堆顶数据和往堆中插入数据的时间复杂度都是O(logn)，n表示堆中的数据个数，这里就是100。是不是比原来数组存储的方式高效了很多呢？</p><h3>2.高性能定时器</h3><p>假设我们有一个定时器，定时器中维护了很多定时任务，每个任务都设定了一个要触发执行的时间点。定时器每过一个很小的单位时间（比如1秒），就扫描一遍任务，看是否有任务到达设定的执行时间。如果到达了，就拿出来执行。</p><p><img src=\"https://static001.geekbang.org/resource/image/b0/e7/b04656d27fd0ba112a38a28c892069e7.jpg?wh=1142*484\" alt=\"\"></p><p>但是，这样每过1秒就扫描一遍任务列表的做法比较低效，主要原因有两点：第一，任务的约定执行时间离当前时间可能还有很久，这样前面很多次扫描其实都是徒劳的；第二，每次都要扫描整个任务列表，如果任务列表很大的话，势必会比较耗时。</p><p>针对这些问题，我们就可以用优先级队列来解决。我们按照任务设定的执行时间，将这些任务存储在优先级队列中，队列首部（也就是小顶堆的堆顶）存储的是最先执行的任务。</p><p>这样，定时器就不需要每隔1秒就扫描一遍任务列表了。它拿队首任务的执行时间点，与当前时间点相减，得到一个时间间隔T。</p><p>这个时间间隔T就是，从当前时间开始，需要等待多久，才会有第一个任务需要被执行。这样，定时器就可以设定在T秒之后，再来执行任务。从当前时间点到（T-1）秒这段时间里，定时器都不需要做任何事情。</p><p>当T秒时间过去之后，定时器取优先级队列中队首的任务执行。然后再计算新的队首任务的执行时间点与当前时间点的差值，把这个值作为定时器执行下一个任务需要等待的时间。</p><p>这样，定时器既不用间隔1秒就轮询一次，也不用遍历整个任务列表，性能也就提高了。</p><h2>堆的应用二：利用堆求Top K</h2><p>刚刚我们学习了优先级队列，我们现在来看，堆的另外一个非常重要的应用场景，那就是“求Top K问题”。</p><p>我把这种求Top K的问题抽象成两类。一类是针对静态数据集合，也就是说数据集合事先确定，不会再变。另一类是针对动态数据集合，也就是说数据集合事先并不确定，有数据动态地加入到集合中。</p><p>针对静态数据，如何在一个包含n个数据的数组中，查找前K大数据呢？我们可以维护一个大小为K的小顶堆，顺序遍历数组，从数组中取出数据与堆顶元素比较。如果比堆顶元素大，我们就把堆顶元素删除，并且将这个元素插入到堆中；如果比堆顶元素小，则不做处理，继续遍历数组。这样等数组中的数据都遍历完之后，堆中的数据就是前K大数据了。</p><p>遍历数组需要O(n)的时间复杂度，一次堆化操作需要O(logK)的时间复杂度，所以最坏情况下，n个元素都入堆一次，时间复杂度就是O(nlogK)。</p><p>针对动态数据求得Top K就是实时Top K。怎么理解呢？我举一个例子。一个数据集合中有两个操作，一个是添加数据，另一个询问当前的前K大数据。</p><p>如果每次询问前K大数据，我们都基于当前的数据重新计算的话，那时间复杂度就是O(nlogK)，n表示当前的数据的大小。实际上，我们可以一直都维护一个K大小的小顶堆，当有数据被添加到集合中时，我们就拿它与堆顶的元素对比。如果比堆顶元素大，我们就把堆顶元素删除，并且将这个元素插入到堆中；如果比堆顶元素小，则不做处理。这样，无论任何时候需要查询当前的前K大数据，我们都可以立刻返回给他。</p><h2>堆的应用三：利用堆求中位数</h2><p>前面我们讲了如何求Top K的问题，现在我们来讲下，如何求动态数据集合中的中位数。</p><p>中位数，顾名思义，就是处在中间位置的那个数。如果数据的个数是奇数，把数据从小到大排列，那第$\\frac{n}{2}+1$个数据就是中位数（注意：假设数据是从0开始编号的）；如果数据的个数是偶数的话，那处于中间位置的数据有两个，第$\\frac{n}{2}$个和第$\\frac{n}{2}+1$个数据，这个时候，我们可以随意取一个作为中位数，比如取两个数中靠前的那个，就是第$\\frac{n}{2}$个数据。</p><p><img src=\"https://static001.geekbang.org/resource/image/18/b6/1809157fdd804dd40a6a795ec30acbb6.jpg?wh=1142*550\" alt=\"\"></p><p>对于一组<strong>静态数据</strong>，中位数是固定的，我们可以先排序，第$\\frac{n}{2}$个数据就是中位数。每次询问中位数的时候，我们直接返回这个固定的值就好了。所以，尽管排序的代价比较大，但是边际成本会很小。但是，如果我们面对的是<strong>动态数据</strong>集合，中位数在不停地变动，如果再用先排序的方法，每次询问中位数的时候，都要先进行排序，那效率就不高了。</p><p><strong>借助堆这种数据结构，我们不用排序，就可以非常高效地实现求中位数操作。我们来看看，它是如何做到的？</strong></p><p>我们需要维护两个堆，一个大顶堆，一个小顶堆。大顶堆中存储前半部分数据，小顶堆中存储后半部分数据，且小顶堆中的数据都大于大顶堆中的数据。</p><p>也就是说，如果有n个数据，n是偶数，我们从小到大排序，那前$\\frac{n}{2}$个数据存储在大顶堆中，后$\\frac{n}{2}$个数据存储在小顶堆中。这样，大顶堆中的堆顶元素就是我们要找的中位数。如果n是奇数，情况是类似的，大顶堆就存储$\\frac{n}{2}+1$个数据，小顶堆中就存储$\\frac{n}{2}$个数据。</p><p><img src=\"https://static001.geekbang.org/resource/image/08/99/08c29d3e014a4baf5f8148c2271e6099.jpg?wh=1142*552\" alt=\"\"></p><p>我们前面也提到，数据是动态变化的，当新添加一个数据的时候，我们如何调整两个堆，让大顶堆中的堆顶元素继续是中位数呢？</p><p>如果新加入的数据小于等于大顶堆的堆顶元素，我们就将这个新数据插入到大顶堆；否则，我们就将这个新数据插入到小顶堆。</p><p>这个时候就有可能出现，两个堆中的数据个数不符合前面约定的情况：如果n是偶数，两个堆中的数据个数都是$\\frac{n}{2}$；如果n是奇数，大顶堆有$\\frac{n}{2}+1$个数据，小顶堆有$\\frac{n}{2}$个数据。这个时候，我们可以从一个堆中不停地将堆顶元素移动到另一个堆，通过这样的调整，来让两个堆中的数据满足上面的约定。</p><p><img src=\"https://static001.geekbang.org/resource/image/ae/b1/aee4dcaf9d34111870a1d66a6e109fb1.jpg?wh=1142*745\" alt=\"\"></p><p>于是，我们就可以利用两个堆，一个大顶堆、一个小顶堆，实现在动态数据集合中求中位数的操作。插入数据因为需要涉及堆化，所以时间复杂度变成了O(logn)，但是求中位数我们只需要返回大顶堆的堆顶元素就可以了，所以时间复杂度就是O(1)。</p><p>实际上，利用两个堆不仅可以快速求出中位数，还可以快速求其他百分位的数据，原理是类似的。还记得我们在“<a href=\"https://time.geekbang.org/column/article/39972\">为什么要学习数据结构与算法</a>”里的这个问题吗？“如何快速求接口的99%响应时间？”我们现在就来看下，利用两个堆如何来实现。</p><p>在开始这个问题的讲解之前，我先解释一下，什么是“99%响应时间”。</p><p>中位数的概念就是将数据从小到大排列，处于中间位置，就叫中位数，这个数据会大于等于前面50%的数据。99百分位数的概念可以类比中位数，如果将一组数据从小到大排列，这个99百分位数就是大于前面99%数据的那个数据。</p><p>如果你还是不太理解，我再举个例子。假设有100个数据，分别是1，2，3，……，100，那99百分位数就是99，因为小于等于99的数占总个数的99%。</p><p><img src=\"https://static001.geekbang.org/resource/image/bb/2d/bbb043d369eeef1bb7feadd28c6ea32d.jpg?wh=1142*298\" alt=\"\"></p><p>弄懂了这个概念，我们再来看99%响应时间。如果有100个接口访问请求，每个接口请求的响应时间都不同，比如55毫秒、100毫秒、23毫秒等，我们把这100个接口的响应时间按照从小到大排列，排在第99的那个数据就是99%响应时间，也叫99百分位响应时间。</p><p>我们总结一下，如果有n个数据，将数据从小到大排列之后，99百分位数大约就是第n*99%个数据，同类，80百分位数大约就是第n*80%个数据。</p><p>弄懂了这些，我们再来看如何求99%响应时间。</p><p>我们维护两个堆，一个大顶堆，一个小顶堆。假设当前总数据的个数是n，大顶堆中保存n*99%个数据，小顶堆中保存n*1%个数据。大顶堆堆顶的数据就是我们要找的99%响应时间。</p><p>每次插入一个数据的时候，我们要判断这个数据跟大顶堆和小顶堆堆顶数据的大小关系，然后决定插入到哪个堆中。如果这个新插入的数据比大顶堆的堆顶数据小，那就插入大顶堆；如果这个新插入的数据比小顶堆的堆顶数据大，那就插入小顶堆。</p><p>但是，为了保持大顶堆中的数据占99%，小顶堆中的数据占1%，在每次新插入数据之后，我们都要重新计算，这个时候大顶堆和小顶堆中的数据个数，是否还符合99:1这个比例。如果不符合，我们就将一个堆中的数据移动到另一个堆，直到满足这个比例。移动的方法类似前面求中位数的方法，这里我就不啰嗦了。</p><p>通过这样的方法，每次插入数据，可能会涉及几个数据的堆化操作，所以时间复杂度是O(logn)。每次求99%响应时间的时候，直接返回大顶堆中的堆顶数据即可，时间复杂度是O(1)。</p><h2>解答开篇</h2><p>学懂了上面的一些应用场景的处理思路，我想你应该能解决开篇的那个问题了吧。假设现在我们有一个包含10亿个搜索关键词的日志文件，如何快速获取到Top 10最热门的搜索关键词呢？</p><p>处理这个问题，有很多高级的解决方法，比如使用MapReduce等。但是，如果我们将处理的场景限定为单机，可以使用的内存为1GB。那这个问题该如何解决呢？</p><p>因为用户搜索的关键词，有很多可能都是重复的，所以我们首先要统计每个搜索关键词出现的频率。我们可以通过散列表、平衡二叉查找树或者其他一些支持快速查找、插入的数据结构，来记录关键词及其出现的次数。</p><p>假设我们选用散列表。我们就顺序扫描这10亿个搜索关键词。当扫描到某个关键词时，我们去散列表中查询。如果存在，我们就将对应的次数加一；如果不存在，我们就将它插入到散列表，并记录次数为1。以此类推，等遍历完这10亿个搜索关键词之后，散列表中就存储了不重复的搜索关键词以及出现的次数。</p><p>然后，我们再根据前面讲的用堆求Top K的方法，建立一个大小为10的小顶堆，遍历散列表，依次取出每个搜索关键词及对应出现的次数，然后与堆顶的搜索关键词对比。如果出现次数比堆顶搜索关键词的次数多，那就删除堆顶的关键词，将这个出现次数更多的关键词加入到堆中。</p><p>以此类推，当遍历完整个散列表中的搜索关键词之后，堆中的搜索关键词就是出现次数最多的Top 10搜索关键词了。</p><p>不知道你发现了没有，上面的解决思路其实存在漏洞。10亿的关键词还是很多的。我们假设10亿条搜索关键词中不重复的有1亿条，如果每个搜索关键词的平均长度是50个字节，那存储1亿个关键词起码需要5GB的内存空间，而散列表因为要避免频繁冲突，不会选择太大的装载因子，所以消耗的内存空间就更多了。而我们的机器只有1GB的可用内存空间，所以我们无法一次性将所有的搜索关键词加入到内存中。这个时候该怎么办呢？</p><p>我们在哈希算法那一节讲过，相同数据经过哈希算法得到的哈希值是一样的。我们可以根据哈希算法的这个特点，将10亿条搜索关键词先通过哈希算法分片到10个文件中。</p><p>具体可以这样做：我们创建10个空文件00，01，02，……，09。我们遍历这10亿个关键词，并且通过某个哈希算法对其求哈希值，然后哈希值同10取模，得到的结果就是这个搜索关键词应该被分到的文件编号。</p><p>对这10亿个关键词分片之后，每个文件都只有1亿的关键词，去除掉重复的，可能就只有1000万个，每个关键词平均50个字节，所以总的大小就是500MB。1GB的内存完全可以放得下。</p><p>我们针对每个包含1亿条搜索关键词的文件，利用散列表和堆，分别求出Top 10，然后把这个10个Top 10放在一块，然后取这100个关键词中，出现次数最多的10个关键词，这就是这10亿数据中的Top 10最频繁的搜索关键词了。</p><h2>内容小结</h2><p>我们今天主要讲了堆的几个重要的应用，它们分别是：优先级队列、求Top K问题和求中位数问题。</p><p>优先级队列是一种特殊的队列，优先级高的数据先出队，而不再像普通的队列那样，先进先出。实际上，堆就可以看作优先级队列，只是称谓不一样罢了。求Top K问题又可以分为针对静态数据和针对动态数据，只需要利用一个堆，就可以做到非常高效率地查询Top K的数据。求中位数实际上还有很多变形，比如求99百分位数据、90百分位数据等，处理的思路都是一样的，即利用两个堆，一个大顶堆，一个小顶堆，随着数据的动态添加，动态调整两个堆中的数据，最后大顶堆的堆顶元素就是要求的数据。</p><h2>课后思考</h2><p>有一个访问量非常大的新闻网站，我们希望将点击量排名Top 10的新闻摘要，滚动显示在网站首页banner上，并且每隔1小时更新一次。如果你是负责开发这个功能的工程师，你会如何来实现呢？</p><p>欢迎留言和我分享，我会第一时间给你反馈。</p>","comments":[{"had_liked":false,"id":45663,"user_name":"feifei","can_delete":false,"product_type":"c1","uid":1105431,"ip_address":"","ucode":"B1F8AE3AD82C51","user_header":"https://static001.geekbang.org/account/avatar/00/10/de/17/75e2b624.jpg","comment_is_top":false,"comment_ctime":1543740491,"is_pvip":false,"discussion_count":46,"race_medal":0,"score":"4322280840267","product_id":100017301,"comment_content":"有一个访问量非常大的新闻网站，我们希望将点击量排名 Top 10 的新闻摘要，滚动显示在网站首页 banner 上，并且每隔 1 小时更新一次。如果你是负责开发这个功能的工程师，你会如何来实现呢？<br><br>我的思路是这样子，<br>1，对每篇新闻摘要计算一个hashcode，并建立摘要与hashcode的关联关系，使用map存储，以hashCode为key，新闻摘要为值<br>2，按每小时一个文件的方式记录下被点击的摘要的hashCode<br>3，当一个小时结果后，上一个小时的文件被关闭，开始计算上一个小时的点击top10<br>4，将hashcode分片到多个文件中，通过对hashCode取模运算，即可将相同的hashCode分片到相同的文件中<br>5，针对每个文件取top10的hashCode，使用Map&lt;hashCode,int&gt;的方式，统计出所有的摘要点击次数，然后再使用小顶堆（大小为10）计算top10,<br>6，再针对所有分片计算一个总的top10,最后合并的逻辑也是使用小顶堆，计算top10<br>7，如果仅展示前一个小时的top10,计算结束<br>8，如果需要展示全天，需要与上一次的计算按hashCode进行合并，然后在这合并的数据中取top10<br>9，在展示时，将计算得到的top10的hashcode，转化为新闻摘要显示即可<br><br>老师，你讲的这些例子，我觉得对我的工作和学习很有帮助，于是我花了一个周末将这一章节，将你所讲的堆的应用示例，全部翻译成了代码，并做了相关的验证，感觉自己收获很多，我也将这块代码上传了github，欢迎老师你的指正，需要的同学，也可以一起交流，<br><br>1，合并有序小文件<br>https:&#47;&#47;github.com&#47;kkzfl22&#47;datastruct&#47;tree&#47;master&#47;src&#47;main&#47;java&#47;com&#47;liujun&#47;datastruct&#47;heap&#47;solution&#47;margeSmailFile<br>2，高性能定时器的应用<br>https:&#47;&#47;github.com&#47;kkzfl22&#47;datastruct&#47;tree&#47;master&#47;src&#47;main&#47;java&#47;com&#47;liujun&#47;datastruct&#47;heap&#47;solution&#47;highTimeSchedule<br>3，求topk<br>https:&#47;&#47;github.com&#47;kkzfl22&#47;datastruct&#47;tree&#47;master&#47;src&#47;main&#47;java&#47;com&#47;liujun&#47;datastruct&#47;heap&#47;solution&#47;topK<br>4，求中位数<br>https:&#47;&#47;github.com&#47;kkzfl22&#47;datastruct&#47;tree&#47;master&#47;src&#47;main&#47;java&#47;com&#47;liujun&#47;datastruct&#47;heap&#47;solution&#47;midnum<br>5 ,大文件的关键字的统计<br>https:&#47;&#47;github.com&#47;kkzfl22&#47;datastruct&#47;tree&#47;master&#47;src&#47;main&#47;java&#47;com&#47;liujun&#47;datastruct&#47;heap&#47;solution&#47;bigFileTopN<br><br>","like_count":1007,"discussions":[{"author":{"id":1205627,"avatar":"https://static001.geekbang.org/account/avatar/00/12/65/7b/66b9befd.jpg","nickname":"Hwan","note":"","ucode":"A728C6790511BD","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":61866,"discussion_content":"计算24小时的话，貌似有点问题，比如你是分别按照1小时求top10的，有可能两个小时的都是top11的，加起来可能就是这两个小时的前top10了","likes_number":19,"is_delete":false,"is_hidden":false,"ctime":1574784347,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":2,"child_discussions":[{"author":{"id":1603640,"avatar":"https://static001.geekbang.org/account/avatar/00/18/78/38/da3959cc.jpg","nickname":"一","note":"","ucode":"BCC6241C4CC6D1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1205627,"avatar":"https://static001.geekbang.org/account/avatar/00/12/65/7b/66b9befd.jpg","nickname":"Hwan","note":"","ucode":"A728C6790511BD","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":193684,"discussion_content":"同意","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1583160075,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":61866,"ip_address":""},"score":193684,"extra":""},{"author":{"id":1024164,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/a0/a4/b060c723.jpg","nickname":"阿斯蒂芬","note":"","ucode":"61D5E3BDA4EBC5","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1205627,"avatar":"https://static001.geekbang.org/account/avatar/00/12/65/7b/66b9befd.jpg","nickname":"Hwan","note":"","ucode":"A728C6790511BD","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":222449,"discussion_content":"楼主原文「8，如果需要展示全天，需要与上一次的计算按hashCode进行合并，然后在这合并的数据中取top10」\n感觉这里的意思是：用当前实时全量的HashMap来做top10，\n而不是「一小时前的全量Top10」与「这一小时内的top10+这一小时内的top10对应的历史访问量」合集来做top10\n如果这样理解是不是就没有问题了？","likes_number":6,"is_delete":false,"is_hidden":false,"ctime":1586145986,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":61866,"ip_address":""},"score":222449,"extra":""}]},{"author":{"id":1512642,"avatar":"https://static001.geekbang.org/account/avatar/00/17/14/c2/46ebe3a0.jpg","nickname":"侧耳倾听","note":"","ucode":"5BF2A2440B54F0","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":220584,"discussion_content":"这个方案理论上比较合理，实际生产环境可能不理想，一个新闻网站的链接数目也是海量的，如果用hash存储，本地内存就是一个考验，还有hash算法，hash装载因子的选择都比较有难度。我觉得利用成熟的中间件做缓存比较合适","likes_number":8,"is_delete":false,"is_hidden":false,"ctime":1585900793,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":3,"child_discussions":[{"author":{"id":1950487,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/c3/17/dc7b3246.jpg","nickname":"哎呦喂","note":"","ucode":"06C7FBEF976741","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1512642,"avatar":"https://static001.geekbang.org/account/avatar/00/17/14/c2/46ebe3a0.jpg","nickname":"侧耳倾听","note":"","ucode":"5BF2A2440B54F0","race_medal":0,"user_type":1,"is_pvip":true},"discussion":{"id":243888,"discussion_content":"你们怎么这么厉害，顶不住啊","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1587564006,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":220584,"ip_address":""},"score":243888,"extra":""},{"author":{"id":1652836,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epKJlW7sqts2ZbPuhMbseTAdvHWnrc4ficAeSZyKibkvn6qyxflPrkKKU3mH6XCNmYvDg11tB6y0pxg/132","nickname":"pc","note":"","ucode":"1AD538B9A900B6","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1512642,"avatar":"https://static001.geekbang.org/account/avatar/00/17/14/c2/46ebe3a0.jpg","nickname":"侧耳倾听","note":"","ucode":"5BF2A2440B54F0","race_medal":0,"user_type":1,"is_pvip":true},"discussion":{"id":263185,"discussion_content":"存的都是文件，而且也不是本地。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589185328,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":220584,"ip_address":""},"score":263185,"extra":""},{"author":{"id":1512642,"avatar":"https://static001.geekbang.org/account/avatar/00/17/14/c2/46ebe3a0.jpg","nickname":"侧耳倾听","note":"","ucode":"5BF2A2440B54F0","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1652836,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epKJlW7sqts2ZbPuhMbseTAdvHWnrc4ficAeSZyKibkvn6qyxflPrkKKU3mH6XCNmYvDg11tB6y0pxg/132","nickname":"pc","note":"","ucode":"1AD538B9A900B6","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":263893,"discussion_content":"上来不就是每篇新闻摘要计算一个hashcode，建立hashcode与摘要的关系，存哪儿？文件里？还不是本地，那真是太厉害了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589262508,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":263185,"ip_address":""},"score":263893,"extra":""}]},{"author":{"id":1237631,"avatar":"https://static001.geekbang.org/account/avatar/00/12/e2/7f/ad70b212.jpg","nickname":"Floyd","note":"","ucode":"FA0DCC22BE8C8F","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":37537,"discussion_content":"但是如果hash有冲突了，怎么办","likes_number":6,"is_delete":false,"is_hidden":false,"ctime":1571631009,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1235441,"avatar":"https://static001.geekbang.org/account/avatar/00/12/d9/f1/a00711f8.jpg","nickname":"X  W  z","note":"","ucode":"915BA1CF6090F7","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1237631,"avatar":"https://static001.geekbang.org/account/avatar/00/12/e2/7f/ad70b212.jpg","nickname":"Floyd","note":"","ucode":"FA0DCC22BE8C8F","race_medal":0,"user_type":1,"is_pvip":true},"discussion":{"id":333773,"discussion_content":"hash冲突问题\n1、把通过hash分文件，统计次数均摊到每次点击上了；\n如果存在数据库中，对应新闻每次点击+1，OK\n2、然后将数据均分n份，计算每个的top10，最后合并\n不知道有没有遗漏？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1607612738,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":37537,"ip_address":""},"score":333773,"extra":""}]},{"author":{"id":2033763,"avatar":"https://static001.geekbang.org/account/avatar/00/1f/08/63/383a2bb1.jpg","nickname":"陈sir","note":"","ucode":"BD4E28F6F7ADDD","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":327419,"discussion_content":"实际工作用缓存靠谱","likes_number":4,"is_delete":false,"is_hidden":false,"ctime":1605834287,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1210699,"avatar":"https://static001.geekbang.org/account/avatar/00/12/79/4b/740f91ca.jpg","nickname":"-W.LI-","note":"","ucode":"3556786538664F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":37188,"discussion_content":"redis的zset能解决这个问题么?","likes_number":4,"is_delete":false,"is_hidden":false,"ctime":1571540438,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":6,"child_discussions":[{"author":{"id":1693728,"avatar":"https://static001.geekbang.org/account/avatar/00/19/d8/20/258a1ddb.jpg","nickname":"Alan","note":"","ucode":"D92E79F4FE5A01","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1210699,"avatar":"https://static001.geekbang.org/account/avatar/00/12/79/4b/740f91ca.jpg","nickname":"-W.LI-","note":"","ucode":"3556786538664F","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":213502,"discussion_content":"我第一个念头也是Zset","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1585099775,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":37188,"ip_address":""},"score":213502,"extra":""},{"author":{"id":1433178,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJMzj0MHiaXBdDFp4E16qhu6PZlu6xkJRWgaoJXOeqMDDLqM4vcvUbnVLiactTypZkYibOg7okwm2TAQ/132","nickname":"Geek_921929","note":"","ucode":"26BF6978F040BF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1210699,"avatar":"https://static001.geekbang.org/account/avatar/00/12/79/4b/740f91ca.jpg","nickname":"-W.LI-","note":"","ucode":"3556786538664F","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":221322,"discussion_content":"必须可以啊，而且首推","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1586003224,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":37188,"ip_address":""},"score":221322,"extra":""},{"author":{"id":1652836,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epKJlW7sqts2ZbPuhMbseTAdvHWnrc4ficAeSZyKibkvn6qyxflPrkKKU3mH6XCNmYvDg11tB6y0pxg/132","nickname":"pc","note":"","ucode":"1AD538B9A900B6","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1210699,"avatar":"https://static001.geekbang.org/account/avatar/00/12/79/4b/740f91ca.jpg","nickname":"-W.LI-","note":"","ucode":"3556786538664F","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":263187,"discussion_content":"redis的话，应该是资源浪费比较大把。如果说每小时访问量有1G的数据量（key+value），就要花1Gredis内存来实现。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589185452,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":37188,"ip_address":""},"score":263187,"extra":""}]},{"author":{"id":1658706,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJeQVzYNLVuOv8IuxydsXuVXEUoqLmN0vpkiceZuU26KPOt05xuxCSnsbkgBu4q9qmibRfTOvCiaPGJg/132","nickname":"Qualifor","note":"","ucode":"8F42453286719C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":19742,"discussion_content":"链接失效了，能不能麻烦大佬重新分享一下呢？","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1569220107,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1251835,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/oiboHpgukqib2ASXeU0H7W1ibgRMqyrNE5KaWicicPEDy0ia8YdoneZAtvW0EFIiaqZJp2OS4dnweOgXaJ5EjJicicEqic5A/132","nickname":"覃钰栋","note":"","ucode":"19080C463658EF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1658706,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJeQVzYNLVuOv8IuxydsXuVXEUoqLmN0vpkiceZuU26KPOt05xuxCSnsbkgBu4q9qmibRfTOvCiaPGJg/132","nickname":"Qualifor","note":"","ucode":"8F42453286719C","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":407340,"discussion_content":"都在这个目录https://github.com/kkzfl22/datastruct/tree/master/src/main/java/com/liujun/datastruct/base/datastruct/heap/solution","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1634986236,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":19742,"ip_address":""},"score":407340,"extra":""}]},{"author":{"id":1609206,"avatar":"https://static001.geekbang.org/account/avatar/00/18/8d/f6/ea0f7f22.jpg","nickname":"陈明月","note":"","ucode":"8A1D7C5653BFEB","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":357002,"discussion_content":"还有一个关键问题是每小时更新一次，如何利用以往的数据就很重要了。\n可将这一小时的Top10与上一小时的Top10合并访问量，从这小于等于20条的新闻中计算Top10就可以了，无需合并所有新闻的访问量。","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1615724048,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":3,"child_discussions":[{"author":{"id":2409063,"avatar":"https://static001.geekbang.org/account/avatar/00/24/c2/67/379af284.jpg","nickname":"圙","note":"","ucode":"3CBDE42A6B5F13","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1609206,"avatar":"https://static001.geekbang.org/account/avatar/00/18/8d/f6/ea0f7f22.jpg","nickname":"陈明月","note":"","ucode":"8A1D7C5653BFEB","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":360411,"discussion_content":"存在问题吧 …比如前一个小时10～20的新闻也比较高 在后一个小时原10～20中也很高  但并非在前10中 而原前10在新的一个小时中比较靠后  新前10在过去一个小时比较低。那本应该高的新闻根本算不到了","likes_number":11,"is_delete":false,"is_hidden":false,"ctime":1616427853,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":357002,"ip_address":""},"score":360411,"extra":""},{"author":{"id":2694205,"avatar":"https://static001.geekbang.org/account/avatar/00/29/1c/3d/76465ee4.jpg","nickname":"摘星","note":"","ucode":"55D8CAFC938F91","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2409063,"avatar":"https://static001.geekbang.org/account/avatar/00/24/c2/67/379af284.jpg","nickname":"圙","note":"","ucode":"3CBDE42A6B5F13","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":410102,"discussion_content":"有道理！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1635600495,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":360411,"ip_address":""},"score":410102,"extra":""},{"author":{"id":2115387,"avatar":"https://static001.geekbang.org/account/avatar/00/20/47/3b/70198ceb.jpg","nickname":"Aibo","note":"","ucode":"2CE3E77BD2D014","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1609206,"avatar":"https://static001.geekbang.org/account/avatar/00/18/8d/f6/ea0f7f22.jpg","nickname":"陈明月","note":"","ucode":"8A1D7C5653BFEB","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":574707,"discussion_content":"要看想要的结果是小时top还是日top，如果是日top需要当天的数据计算top10","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1654269963,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":357002,"ip_address":""},"score":574707,"extra":""}]},{"author":{"id":1009813,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/68/95/ab15bd6b.jpg","nickname":"钟涵","note":"","ucode":"CE9041F1D94A2D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":339818,"discussion_content":"其实新闻的条目数量每天不会太大，不用分片也完全可以。","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1609815309,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1251016,"avatar":"https://static001.geekbang.org/account/avatar/00/13/16/c8/980776fc.jpg","nickname":"走马","note":"","ucode":"EEFE8F7590FFA4","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":7139,"discussion_content":"你这计算是实时的 ？ ","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1567400794,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1235441,"avatar":"https://static001.geekbang.org/account/avatar/00/12/d9/f1/a00711f8.jpg","nickname":"X  W  z","note":"","ucode":"915BA1CF6090F7","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":333800,"discussion_content":"讨论题：新闻点击率top10\n1、数据库存储，表结构：id ，新闻名，点击量，…\n2、每次点击，对应点击量+1\n3、定时器每隔1h执行，将表内容分隔成m份，每一份用一个线程用小顶堆计算top10。\n4、将m个top整合\n注意问题：\n1、表内容分隔m份，select id，times limit 1000 offset 1000 获取。\n疑问：数据库 这种语法的性能如何？\n2、事务隔离，防止查询到下一小时的表内容；可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。\n3、m为多少，可根据表数据量估值计算，一般系统表中有，但不准确；具体多少得参考实际情况，如一周中每小时的表数据量均值，每个线程的时间，期望的总时间\n希望 大佬批评指正！","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1607615473,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1647922,"avatar":"https://static001.geekbang.org/account/avatar/00/19/25/32/9a14d8f1.jpg","nickname":"JustR","note":"","ucode":"3CDBF1712BE317","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":38639,"discussion_content":"Github 404","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1571811995,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":3,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2878862,"avatar":"","nickname":"Geek_d89079","note":"","ucode":"75177B6DB13CAA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":546103,"discussion_content":"比你优秀的人比你还努力！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1642161318,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":3,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2744830,"avatar":"https://static001.geekbang.org/account/avatar/00/29/e1/fe/912c272e.jpg","nickname":"🇱","note":"","ucode":"A5A124F338F48C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":393028,"discussion_content":"很有帮助，谢谢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631232368,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":3,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2306058,"avatar":"https://static001.geekbang.org/account/avatar/00/23/30/0a/2cd6afa1.jpg","nickname":"浅池卧龙","note":"","ucode":"37F55BFD124EB4","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":388032,"discussion_content":"mark\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1628563948,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":3,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1133945,"avatar":"https://static001.geekbang.org/account/avatar/00/11/4d/79/803537db.jpg","nickname":"慢动作","note":"","ucode":"62C944F4A4D8AC","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":378070,"discussion_content":"第一步计算hashcode作为key，有hash冲突？文章会有id吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1623048486,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":3,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2413946,"avatar":"https://static001.geekbang.org/account/avatar/00/24/d5/7a/4a387fea.jpg","nickname":"Pink_Strawberry","note":"","ucode":"6A6E910C616D8A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":351551,"discussion_content":"m","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1614322499,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":3,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1959822,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/e7/8e/318cfde0.jpg","nickname":"Spoon","note":"","ucode":"2FF9193AD482C2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":349368,"discussion_content":"可以直接用Redis的ZSet？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1613137748,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":3,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2318607,"avatar":"https://static001.geekbang.org/account/avatar/00/23/61/0f/c759f367.jpg","nickname":"一闪一闪亮晶晶","note":"","ucode":"53A0C2E5FA8208","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":340045,"discussion_content":"1","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1609893235,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":3,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1204353,"avatar":"https://static001.geekbang.org/account/avatar/00/12/60/81/eaf6d0ac.jpg","nickname":"拉布拉多","note":"","ucode":"637A88D9F29F57","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":320785,"discussion_content":"mark。动手能力强，一周末能实现这么多。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1604478231,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":3,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2164554,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLc8iay7SThjDaND4WNn4jlK2L7fyPaFibzxUyS6UiaypQsMibIjhxONeChTuTHZEdjXk0CHEgRRjJKbA/132","nickname":"Geek_636e46","note":"","ucode":"E27F2B037B4C41","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":313338,"discussion_content":"...这么强的大佬也在学这个吗，我突然感到亚历山大","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1603034312,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":3,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1109640,"avatar":"https://static001.geekbang.org/account/avatar/00/10/ee/88/a890b41e.jpg","nickname":"chris","note":"","ucode":"6663E3E09457E3","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":217962,"discussion_content":"这才是真的学以致用👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1585590212,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":4,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1638187,"avatar":"","nickname":"Geek_94adb8","note":"","ucode":"B142F473E1A0B3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":159513,"discussion_content":"1，对每篇新闻摘要计算一个hashcode，并建立摘要与hashcode的关联关系，使用map存储，以hashCode为key，新闻摘要为值\n2，按每小时一个文件的方式记录下被点击的摘要的hashCode\n3，当一个小时结果后，上一个小时的文件被关闭，开始计算上一个小时的点击top10\n4，将hashcode分片到多个文件中，通过对hashCode取模运算，即可将相同的hashCode分片到相同的文件中\n5，针对每个文件取top10的hashCode，使用散列表(也可以使用HashMap)，统计出所有的摘要点击次数，然后再使用小顶堆（大小为10）计算top10,\n6，再针对所有分片计算一个总的top10,最后合并的逻辑也是使用小顶堆，计算top10\n7，如果仅展示前一个小时的top10,计算结束\n8，如果需要展示全天，需要与上一次的计算按hashCode进行合并，然后在这合并的数据中取top10\n9，在展示时，将计算得到的top10的hashcode，转化为新闻摘要显示即可","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1580701606,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":4,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1236079,"avatar":"https://static001.geekbang.org/account/avatar/00/12/dc/6f/5d86dbe9.jpg","nickname":"短迪大魔王","note":"","ucode":"37E8117E0495B8","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":158062,"discussion_content":"工程性非常强","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1580547777,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":4,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1200793,"avatar":"https://static001.geekbang.org/account/avatar/00/12/52/99/4a7f2fc9.jpg","nickname":"RyuGou","note":"","ucode":"8D424CB6005DD7","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":94848,"discussion_content":"怎么会是小顶堆呢，明明是大顶堆好吗","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1576993911,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":4,"extra":"","child_discussion_number":3,"child_discussions":[{"author":{"id":1252593,"avatar":"https://static001.geekbang.org/account/avatar/00/13/1c/f1/840ef7f9.jpg","nickname":"KKKKK","note":"","ucode":"E9DAF0FCCE898C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1200793,"avatar":"https://static001.geekbang.org/account/avatar/00/12/52/99/4a7f2fc9.jpg","nickname":"RyuGou","note":"","ucode":"8D424CB6005DD7","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":111301,"discussion_content":"找几个数试试看是需要大顶堆还是小顶堆","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1577790618,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":94848,"ip_address":""},"score":111301,"extra":""},{"author":{"id":1636659,"avatar":"https://static001.geekbang.org/account/avatar/00/18/f9/33/17246ab9.jpg","nickname":"Goslly","note":"","ucode":"8F868DAF3275CD","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1200793,"avatar":"https://static001.geekbang.org/account/avatar/00/12/52/99/4a7f2fc9.jpg","nickname":"RyuGou","note":"","ucode":"8D424CB6005DD7","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":139335,"discussion_content":"求topK用小顶堆；求bottomK用大顶堆","likes_number":8,"is_delete":false,"is_hidden":false,"ctime":1579275550,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":94848,"ip_address":""},"score":139335,"extra":""},{"author":{"id":1593762,"avatar":"https://static001.geekbang.org/account/avatar/00/18/51/a2/84e9efe2.jpg","nickname":"马祖晖","note":"","ucode":"7866916C8EF9DA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1200793,"avatar":"https://static001.geekbang.org/account/avatar/00/12/52/99/4a7f2fc9.jpg","nickname":"RyuGou","note":"","ucode":"8D424CB6005DD7","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":333273,"discussion_content":"求top k问题本质上只需要和top k列表中最小的元素做比较即可，所以用小顶堆获取这个集合的下界就行了，反之亦然。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1607493211,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":94848,"ip_address":""},"score":333273,"extra":""}]},{"author":{"id":1481811,"avatar":"https://static001.geekbang.org/account/avatar/00/16/9c/53/ade0afb0.jpg","nickname":"ub8","note":"","ucode":"0D937C3EAEB781","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":79224,"discussion_content":"链接失效了，能不能麻烦大佬重新分享一下呢？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1576069154,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":4,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1039475,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/dc/73/9ab38243.jpg","nickname":"xiaoxionga","note":"","ucode":"2BB02B54C31EBF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1481811,"avatar":"https://static001.geekbang.org/account/avatar/00/16/9c/53/ade0afb0.jpg","nickname":"ub8","note":"","ucode":"0D937C3EAEB781","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":91328,"discussion_content":"https://github.com/kkzfl22/datastruct/blob/master/src/main/java/com/liujun/datastruct/base/datastruct/heap/solution/bigFileTopN/BigFileTopN.java","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1576827412,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":79224,"ip_address":""},"score":91328,"extra":""}]},{"author":{"id":1610333,"avatar":"","nickname":"Geek_86533a","note":"","ucode":"6961C429E8953A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":4076,"discussion_content":"膜拜！","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1565095830,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":4,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":true,"id":44188,"user_name":"oatlmy","can_delete":false,"product_type":"c1","uid":1019438,"ip_address":"","ucode":"D5B0291801F902","user_header":"https://static001.geekbang.org/account/avatar/00/0f/8e/2e/abb7bfe3.jpg","comment_is_top":false,"comment_ctime":1543380110,"is_pvip":false,"replies":[{"id":"15774","content":"你理解的没错","user_name":"作者回复","comment_id":44188,"uid":"1190123","ip_address":"","utype":1,"ctime":1543403844,"user_name_real":"gg"}],"discussion_count":2,"race_medal":0,"score":"452514946190","product_id":100017301,"comment_content":"老师，请问为什么评价算法性能是根据时间和空间复杂度，而不是别的参数？是因为计算机结构是冯诺依曼体系，除了输入输出设备和控制器，就剩下运算器和存储器了吗？","like_count":106,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":430672,"discussion_content":"你理解的没错","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1543403844,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1547466,"avatar":"https://static001.geekbang.org/account/avatar/00/17/9c/ca/1b01098e.jpg","nickname":"Lee","note":"","ucode":"45CDD6604732AE","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":369819,"discussion_content":"厉害","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1619166523,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":43987,"user_name":"Miletos","can_delete":false,"product_type":"c1","uid":1240655,"ip_address":"","ucode":"024F1960181AC7","user_header":"https://static001.geekbang.org/account/avatar/00/12/ee/4f/b9ebc543.jpg","comment_is_top":false,"comment_ctime":1543362463,"is_pvip":false,"replies":[{"id":"15765","content":"1 你说的对 我改下 多谢指正<br>2 可以重复","user_name":"作者回复","comment_id":43987,"uid":"1190123","ip_address":"","utype":1,"ctime":1543403328,"user_name_real":"gg"}],"discussion_count":4,"race_medal":0,"score":"448219961247","product_id":100017301,"comment_content":"“如果新加入的数据小于等于大顶堆的堆顶元素，我们就将这个新数据插入到大顶堆；如果新加入的数据大于等于小顶堆的堆顶元素，我们就将这个新数据插入到小顶堆。”<br><br>1.  这里不太对劲，前文中说到，小顶堆的堆顶大于大顶堆的堆顶。<br><br>如果新进元素在小顶堆堆顶和大顶堆堆顶元素值之间，没有规定插入哪个堆。<br><br>我觉得，是不是只要判断一次就可以了。新进元素值大于等于小顶堆堆顶元素的，插入小顶堆，否则插入大顶堆。<br>当某一个堆数据过多时再重新移动堆顶元素。<br><br>2.  求中位数的源数据中，是否允许重复数据？","like_count":104,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":430582,"discussion_content":"1 你说的对 我改下 多谢指正\n2 可以重复","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1543403328,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1212873,"avatar":"https://static001.geekbang.org/account/avatar/00/12/81/c9/9194612b.jpg","nickname":"百里","note":"","ucode":"2CE96129AA7F78","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":73222,"discussion_content":"要插入的值, 大于等于小顶堆插入到小顶堆还是大顶堆应该是没关系的,只要判断两边的堆的数据严重不平衡则选择然一端的堆顶元素移动到另一个堆上.","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1575555672,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1295609,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJRFRX8kNzNet7FibNvtavbVpAwK09AhIhrib9k762qWtH6mre8ickP7hM5mgZC4ytr8NnmIfmAhxMSQ/132","nickname":"老大不小","note":"","ucode":"35BCDD3CB13467","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":582588,"discussion_content":"有个疑问，上一篇我们学了堆的插入与删除。这节课学了大顶堆与小顶堆，那么问题来了，如果是大顶堆，需要插入的数据比堆顶还要大，那是先删除堆顶之后堆排一次序，然后将新插入的数据放在最末，再向上堆化吗？\n\n是不是直接替换就可以，不需要堆化操作？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1659519196,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1135912,"avatar":"https://static001.geekbang.org/account/avatar/00/11/55/28/31b0cf2f.jpg","nickname":"黑色毛衣","note":"","ucode":"FF7E235F91BA5C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":6063,"discussion_content":"将hashcode分片到多个文件中，通过对hashCode取模运算，即可将相同的hashCode分片到相同的文件中\n\n这个相同的 hashcode 分片。。。hashcode 不一定一样，只是取模了以后一样；","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1566650549,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":49908,"user_name":"蔷薇骑士","can_delete":false,"product_type":"c1","uid":1246743,"ip_address":"","ucode":"09F0F8AF71C75C","user_header":"https://static001.geekbang.org/account/avatar/00/13/06/17/9e6ec02e.jpg","comment_is_top":false,"comment_ctime":1544787312,"is_pvip":false,"discussion_count":17,"race_medal":0,"score":"315077399920","product_id":100017301,"comment_content":"定时任务这个例子感觉有问题吧，定时任务是动态加入的，假设当前堆顶的任务是一个小时后的，难道这一个小时都不做扫描吗，随时可能会加入需要更早执行的任务","like_count":74,"discussions":[{"author":{"id":1332256,"avatar":"https://static001.geekbang.org/account/avatar/00/14/54/20/90ad5247.jpg","nickname":"NiceBen","note":"","ucode":"793679E3520E84","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":316691,"discussion_content":"如果发生堆化，直接再次计算一下任务执行时间就可以了，这应该不是个问题吧。","likes_number":12,"is_delete":false,"is_hidden":false,"ctime":1603440531,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1234751,"avatar":"https://static001.geekbang.org/account/avatar/00/12/d7/3f/e709bf7b.jpg","nickname":"周绪轩","note":"","ucode":"D5D64762B321EC","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":346,"discussion_content":"这个就相当于是向堆中插入一个数据，顺便 update 一下时间 T 罢了","likes_number":12,"is_delete":false,"is_hidden":false,"ctime":1561465453,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":7,"child_discussions":[{"author":{"id":1042164,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/BDxD1k4ibAUPcljPLwgsnobjTfk2TxPTzCLps2uoGbD3HGIiaUF7XGLUnBArTyAySJzia0R6GRhroYwfyVwniaiaibzg/132","nickname":"灰灰灰","note":"","ucode":"519DB0429C4A80","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1234751,"avatar":"https://static001.geekbang.org/account/avatar/00/12/d7/3f/e709bf7b.jpg","nickname":"周绪轩","note":"","ucode":"D5D64762B321EC","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":2240,"discussion_content":"负责扫描的线程已经因为1小时后执行处于休眠状态了，这种情况下update也没用吧，还是要等一小时后才能执行新加入的任务。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563381183,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":346,"ip_address":""},"score":2240,"extra":""},{"author":{"id":1044198,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ee/e6/f413a94f.jpg","nickname":"seven","note":"","ucode":"6A882EE9F3F31D","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1042164,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/BDxD1k4ibAUPcljPLwgsnobjTfk2TxPTzCLps2uoGbD3HGIiaUF7XGLUnBArTyAySJzia0R6GRhroYwfyVwniaiaibzg/132","nickname":"灰灰灰","note":"","ucode":"519DB0429C4A80","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":2341,"discussion_content":"扫描这个是用来执行定时器后续操作的，维护这个优先队列更新，会有另一套代码来维护。","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1563498767,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":2240,"ip_address":""},"score":2341,"extra":""},{"author":{"id":1030994,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/bb/52/50624a0f.jpg","nickname":"edc","note":"","ucode":"DD6CE24AEC115B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1042164,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/BDxD1k4ibAUPcljPLwgsnobjTfk2TxPTzCLps2uoGbD3HGIiaUF7XGLUnBArTyAySJzia0R6GRhroYwfyVwniaiaibzg/132","nickname":"灰灰灰","note":"","ucode":"519DB0429C4A80","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":3882,"discussion_content":"插入数据的时候，堆化后，如果堆顶元素有变化，清除原来的定时器，新建定时器","likes_number":16,"is_delete":false,"is_hidden":false,"ctime":1564922502,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":2240,"ip_address":""},"score":3882,"extra":""}]},{"author":{"id":2282960,"avatar":"https://static001.geekbang.org/account/avatar/00/22/d5/d0/97c8dc32.jpg","nickname":"大西几吃小兔兔","note":"","ucode":"44D75626C6DB57","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":347565,"discussion_content":"如果插入新任务后堆顶元素变化了，就取消之前的定时器，重开一个定时器。没变化就不动","likes_number":5,"is_delete":false,"is_hidden":false,"ctime":1612258837,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1197685,"avatar":"https://static001.geekbang.org/account/avatar/00/12/46/75/9f80409f.jpg","nickname":"追梦","note":"","ucode":"634A19055525B3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":318968,"discussion_content":"确实有问题，插入后需要更新notify（延迟唤醒或者直接唤醒都行）","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1603894198,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1205036,"avatar":"","nickname":"Dym","note":"","ucode":"7E521F01A4D823","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":15075,"discussion_content":"如果当前队头元素和我们新插入的元素相同时，就需要通过notify唤醒正在阻塞等待执行任务的线程","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1568802613,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1180708,"avatar":"https://static001.geekbang.org/account/avatar/00/12/04/24/15433419.jpg","nickname":"欲望之城","note":"","ucode":"B4560AA760B9E1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":559344,"discussion_content":"每新增一个任务更新堆顶后要清理之前的等待线程并重新生成等待线程，其实这样下来每秒定时扫一次堆顶也不是不可以。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1648713367,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2006453,"avatar":"https://static001.geekbang.org/account/avatar/00/1e/9d/b5/506dfd1a.jpg","nickname":"helloJay","note":"","ucode":"8ACEB7E62F90C5","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":275603,"discussion_content":"插入堆化后，如果有变动，刷新下次执行时间","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1590738729,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1983006,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/CV9kk5M26pdxvFhbrkicjZdC2qfZHb09MdccMTlgXhEHaSlrgvtpSXliaJlMbMvyiawJzv32GKXjYDZOz0lRLkSwQ/132","nickname":"Geek_20200427","note":"","ucode":"800B238957BF8A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":267227,"discussion_content":"这些知识哪里能看到？非科班","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589617805,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1866485,"avatar":"https://static001.geekbang.org/account/avatar/00/1c/7a/f5/54a5084b.jpg","nickname":"简单猫","note":"","ucode":"EA027D4C344E25","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":243860,"discussion_content":"插入并堆化就可以了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587562809,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1051363,"avatar":"https://static001.geekbang.org/account/avatar/00/10/0a/e3/9637bfdb.jpg","nickname":"Ricky Fung","note":"","ucode":"7AEA1F8EC4A088","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":183039,"discussion_content":"可以参考jdk中 ScheduledThreadPoolExecutor 源码实现","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1582465792,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":44269,"user_name":"守着云开","can_delete":false,"product_type":"c1","uid":1183885,"ip_address":"","ucode":"22220485396D0D","user_header":"https://static001.geekbang.org/account/avatar/00/12/10/8d/43edb2dd.jpg","comment_is_top":false,"comment_ctime":1543396827,"is_pvip":false,"discussion_count":10,"race_medal":0,"score":"211996794331","product_id":100017301,"comment_content":"10亿关键词分片之后 每个文件并不一定有1亿的关键词吧 老师","like_count":49,"discussions":[{"author":{"id":1549032,"avatar":"","nickname":"Zzz","note":"","ucode":"9323254354868B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":168475,"discussion_content":"如果是热门关键词，可能这个关键词出现了5亿次，这样hash分区后就会全落在一个文件里，就会导致不平衡，所以这个算法是有问题的","likes_number":6,"is_delete":false,"is_hidden":false,"ctime":1581583425,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":2,"child_discussions":[{"author":{"id":1204353,"avatar":"https://static001.geekbang.org/account/avatar/00/12/60/81/eaf6d0ac.jpg","nickname":"拉布拉多","note":"","ucode":"637A88D9F29F57","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1549032,"avatar":"","nickname":"Zzz","note":"","ucode":"9323254354868B","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":320789,"discussion_content":"赞。才注意到这个实际问题","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1604478603,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":168475,"ip_address":""},"score":320789,"extra":""},{"author":{"id":1782167,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/31/97/524bf2b2.jpg","nickname":"文过饰非","note":"","ucode":"F85FDB49F7DB39","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1204353,"avatar":"https://static001.geekbang.org/account/avatar/00/12/60/81/eaf6d0ac.jpg","nickname":"拉布拉多","note":"","ucode":"637A88D9F29F57","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":348610,"discussion_content":"其实是不存在这个问题的，因为一开始存不下的情况是把无重复的1亿关键词全放到了内存里。所以存不下的关键是“无重复”关键词的数量。换句话说，相同关键词不管出现多少次，在哈希表中也只存在一条记录，同一关键词重复出现了5亿次，最后只不过是将哈希表中这一关键词的值记录为5亿。更极端点，假定文中的10亿条关键词都是重复的，那么在哈希表中就只有一条记录，这条记录的值是10亿。","likes_number":17,"is_delete":false,"is_hidden":false,"ctime":1612666293,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":320789,"ip_address":""},"score":348610,"extra":""}]},{"author":{"id":1204353,"avatar":"https://static001.geekbang.org/account/avatar/00/12/60/81/eaf6d0ac.jpg","nickname":"拉布拉多","note":"","ucode":"637A88D9F29F57","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":320791,"discussion_content":"怎么去重？内存占用不超过1G吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1604478683,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":2282960,"avatar":"https://static001.geekbang.org/account/avatar/00/22/d5/d0/97c8dc32.jpg","nickname":"大西几吃小兔兔","note":"","ucode":"44D75626C6DB57","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1204353,"avatar":"https://static001.geekbang.org/account/avatar/00/12/60/81/eaf6d0ac.jpg","nickname":"拉布拉多","note":"","ucode":"637A88D9F29F57","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":347593,"discussion_content":"可以用布隆过滤器，占用内存很小","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1612263200,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":320791,"ip_address":""},"score":347593,"extra":""}]},{"author":{"id":1359701,"avatar":"https://static001.geekbang.org/account/avatar/00/14/bf/55/198c6104.jpg","nickname":"小伟","note":"","ucode":"124953423491E2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":173528,"discussion_content":"打开文件后，不一定一次把整个文件都load到内存，可以分片读取，处理完了再读下一片，类似poi。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1581857890,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1234975,"avatar":"https://static001.geekbang.org/account/avatar/00/12/d8/1f/c07a7575.jpg","nickname":"酸奶酸不酸","note":"","ucode":"E260BF354F6C6B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":167520,"discussion_content":"不好好听课","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1581505628,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1014550,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/7b/16/ca250e8c.jpg","nickname":"王木公","note":"","ucode":"F049AEBFA0338D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":70267,"discussion_content":"是的，每个文件不都是1亿个记录，其他评论中，作者有回复","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1575339901,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1284212,"avatar":"https://static001.geekbang.org/account/avatar/00/13/98/74/6edfe4c1.jpg","nickname":"icephobia","note":"","ucode":"CD383B35994331","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":46038,"discussion_content":"有两个文件里关键词应该接近8亿数据","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1573113532,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1472051,"avatar":"https://static001.geekbang.org/account/avatar/00/16/76/33/928ffd21.jpg","nickname":"AlexS","note":"","ucode":"3DA81A613CE645","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1284212,"avatar":"https://static001.geekbang.org/account/avatar/00/13/98/74/6edfe4c1.jpg","nickname":"icephobia","note":"","ucode":"CD383B35994331","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":50526,"discussion_content":"有8亿也没关系呀，又不是不重复的关键词有8亿个。重复的只占一个空间。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1573732096,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":46038,"ip_address":""},"score":50526,"extra":""}]}]},{"had_liked":false,"id":137518,"user_name":"丁丁历险记","can_delete":false,"product_type":"c1","uid":1661704,"ip_address":"","ucode":"A43829E454C067","user_header":"https://static001.geekbang.org/account/avatar/00/19/5b/08/b0b0db05.jpg","comment_is_top":false,"comment_ctime":1569759759,"is_pvip":false,"discussion_count":3,"race_medal":0,"score":"177663418895","product_id":100017301,"comment_content":"人生也需要维护一个优先级队列","like_count":41,"discussions":[{"author":{"id":1324314,"avatar":"https://static001.geekbang.org/account/avatar/00/14/35/1a/9fa38dc9.jpg","nickname":"子瞻","note":"","ucode":"5C26FF10934534","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":374202,"discussion_content":"真鸡汤","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1621063133,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1747163,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/a8/db/99c95736.jpg","nickname":"御风","note":"","ucode":"60304D17F8511A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":586778,"discussion_content":"这一碗我干了!","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1662511754,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2962599,"avatar":"https://static001.geekbang.org/account/avatar/00/2d/34/a7/52c4ea60.jpg","nickname":"年少挽滑稽世无双","note":"","ucode":"793DCBDE25A07B","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":574202,"discussion_content":"大师，我悟了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1653897842,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":45616,"user_name":"辉哥","can_delete":false,"product_type":"c1","uid":1236983,"ip_address":"","ucode":"21A65F4EE6CD04","user_header":"","comment_is_top":false,"comment_ctime":1543722577,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"164752479825","product_id":100017301,"comment_content":"思考题：1，维护两个散列表，一个是一小时新增的点击量的散列表，以新闻id为键，点击次数为值。一个是全部点击量的散列表。每隔一小时把新增的散列表的数据同步到全部点击量的散列表。然后把这小时内有变化的全部点击量的散列表的数据（即此小时有新增点击量的新闻数据）和我们维护的10个元素小顶堆堆顶进行比较，比堆顶的点击量大的，则使用该元素替换堆顶，再进行堆化。比堆顶点击量小的则不做处理。然后比较完，根据堆顶的10个元素的id，从数据库读取相应的新闻摘要显示在banner上。除此之外，还要把变化后的全部点击量散列表同步到数据库。因为保存的是新闻id，所以散列表长度不会很大，所占用的内存也不会很大。而每个小时新增的访问量的新闻id数也不会很多，毕竟很多人只会阅读热门消息。所以新增的点击量的新闻数据假设为k,则每小时同步小顶堆的时间负责度为o(klg 10);","like_count":38,"discussions":[{"author":{"id":1433178,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJMzj0MHiaXBdDFp4E16qhu6PZlu6xkJRWgaoJXOeqMDDLqM4vcvUbnVLiactTypZkYibOg7okwm2TAQ/132","nickname":"Geek_921929","note":"","ucode":"26BF6978F040BF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":221325,"discussion_content":"是的，只维护一个有限数量的堆即可，动态计算后比较替换","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586003548,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":52894,"user_name":"想当上帝的司机","can_delete":false,"product_type":"c1","uid":1239378,"ip_address":"","ucode":"D8251388854911","user_header":"https://static001.geekbang.org/account/avatar/00/12/e9/52/f07e9001.jpg","comment_is_top":false,"comment_ctime":1545548513,"is_pvip":false,"discussion_count":4,"race_medal":0,"score":"143279469281","product_id":100017301,"comment_content":"堆求topK的静态数据 应该是先把堆填满 再拿数组中的元素跟堆顶比较吧","like_count":33,"discussions":[{"author":{"id":1359701,"avatar":"https://static001.geekbang.org/account/avatar/00/14/bf/55/198c6104.jpg","nickname":"小伟","note":"","ucode":"124953423491E2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":173553,"discussion_content":"topK问题，堆不需要维护所有元素，只需要维护K个元素。依次遍历数组，如果比堆顶元素大且堆长大于K则删除堆顶再入堆，堆长不大于K则直接入堆；如果比堆顶元素小，则跳过不入堆。遍历结束后堆里的就是所需结果。\n说明下，一定要是小顶堆，堆顶是K里最小的，所以才有上述比对逻辑。 最终堆也是升序的，要按降序排的话，需要出堆后反转。","likes_number":6,"is_delete":false,"is_hidden":false,"ctime":1581858646,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1014550,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/7b/16/ca250e8c.jpg","nickname":"王木公","note":"","ucode":"F049AEBFA0338D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":70280,"discussion_content":"是的，搜一下类似的文章就会发现需要先把堆填满。作者最好在文中提一下","likes_number":4,"is_delete":false,"is_hidden":false,"ctime":1575341480,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1201054,"avatar":"https://static001.geekbang.org/account/avatar/00/12/53/9e/e932c1a8.jpg","nickname":"jing","note":"","ucode":"C0186996EBD25A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":218134,"discussion_content":"我理解也是要先填满的，不然如果拿到的第一个数据即为最大值，这个值做了堆顶，那么就永远不会有数据可以入堆","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1585622817,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1330065,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/N0NACGUr8dNAbN6BdiagPHBaB0EnyDsI9zWpwJteqTY38apOEnTOA7JkBAQnzYKJBgxu3Q8YMUILwLAB6camn4w/132","nickname":"Swing","note":"","ucode":"55FCA9ECEFBBEB","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":76860,"discussion_content":"建堆很快的，先 O(K)，然后剩下的n-k个元素 不一定全部要堆化，单独堆化一个也就是O(logK)，所以最差  也就是 O(k+(n-k)logk) --》O(n)\n这样算起来，上面最差也就是 像维护一个k数组 那样 O(klogk+k(n-k)) --》O(n)\n\n更比 直接全排序，那就是 O(nlogn) 要好 （因为线性排序适用性问题，忽略之）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1575862238,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":43999,"user_name":"豪华","can_delete":false,"product_type":"c1","uid":1132790,"ip_address":"","ucode":"324C41DF8CE956","user_header":"https://static001.geekbang.org/account/avatar/00/11/48/f6/aeb93f8a.jpg","comment_is_top":false,"comment_ctime":1543364060,"is_pvip":false,"replies":[{"id":"15711","content":"不会的 相同的关键词经过哈希之后只会到一台机器","user_name":"作者回复","comment_id":43999,"uid":"1190123","ip_address":"","utype":1,"ctime":1543370311,"user_name_real":"gg"}],"discussion_count":6,"race_medal":0,"score":"138982317532","product_id":100017301,"comment_content":"老师，分片求取前十是不是有bug，如果有一个关键词在每一组分片中都是前第十一位，在整个十亿中个数总和是第一位，是不是用分片求出了错误的结果呢？","like_count":32,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":430587,"discussion_content":"不会的 相同的关键词经过哈希之后只会到一台机器","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1543370311,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1591223,"avatar":"https://static001.geekbang.org/account/avatar/00/18/47/b7/b30472fd.jpg","nickname":"JerryZhu","note":"","ucode":"76850CD45786C1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":302613,"discussion_content":"最大的问题其实是 top 10 都在一个文件里","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1598970580,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1549032,"avatar":"","nickname":"Zzz","note":"","ucode":"9323254354868B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":168470,"discussion_content":"如果是热门关键词，可能这个关键词出现了5亿次，这样hash分区后就会全落在一个文件里，就会导致不平衡，所以这个算法是有问题的","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1581583278,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1359701,"avatar":"https://static001.geekbang.org/account/avatar/00/14/bf/55/198c6104.jpg","nickname":"小伟","note":"","ucode":"124953423491E2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1549032,"avatar":"","nickname":"Zzz","note":"","ucode":"9323254354868B","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":173578,"discussion_content":"极端点，5亿条都是同一个hashcode也没问题，聚合后在散列表里也就是一个kv对。大文件可以分片读。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1581859805,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":168470,"ip_address":""},"score":173578,"extra":""}]},{"author":{"id":1019588,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/8e/c4/8d1150f3.jpg","nickname":"Richie","note":"","ucode":"12314EF0347693","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":125043,"discussion_content":"因为哈希算法的特性决定了，相同数据经过哈希算法得到的哈希值是一样的，所以这些相同的关键词都会被放到相同的分片中。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1578469577,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1014550,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/7b/16/ca250e8c.jpg","nickname":"王木公","note":"","ucode":"F049AEBFA0338D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":269953,"discussion_content":"这就是哈希分片的牛逼之处，相同关键词肯定会被分到同一个机器","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589968142,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":69103,"user_name":"Aaaaaaaaaaayou","can_delete":false,"product_type":"c1","uid":1073601,"ip_address":"","ucode":"67BA315B87587D","user_header":"https://static001.geekbang.org/account/avatar/00/10/61/c1/93031a2a.jpg","comment_is_top":false,"comment_ctime":1550662328,"is_pvip":false,"replies":[{"id":"24610","content":"是的。","user_name":"作者回复","comment_id":69103,"uid":"1190123","ip_address":"","utype":1,"ctime":1550717012,"user_name_real":"gg"}],"discussion_count":2,"race_medal":0,"score":"134694648504","product_id":100017301,"comment_content":"topK 是不是应该先要填满堆，后面插入的时候再做删除操作","like_count":31,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":439950,"discussion_content":"是的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1550717012,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1485515,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/KB4590biaILdggH6ibRibQtlr7p2yONZCfeRK3QM9OSHrwyZrV8oSl5HuOHICl4lQtVoKgpHVydmxQ4peeYPmoIGA/132","nickname":"Chris","note":"","ucode":"712CD86AE8EB81","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":6235,"discussion_content":"首先第一步填满的过程，应该建立在有续数据集吧，不然建立两个堆就没有可比性了，静态数据直接排序就能就中位数，或者百分位数，所以这种结构应该主要针对动态数据集","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1566804914,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":45722,"user_name":"ZX","can_delete":false,"product_type":"c1","uid":1235583,"ip_address":"","ucode":"0D2622FE6D1774","user_header":"https://static001.geekbang.org/account/avatar/00/12/da/7f/8069035d.jpg","comment_is_top":false,"comment_ctime":1543759923,"is_pvip":false,"replies":[{"id":"16358","content":"是的啊 没有说过删除任意元素呢","user_name":"作者回复","comment_id":45722,"uid":"1190123","ip_address":"","utype":1,"ctime":1543801740,"user_name_real":"gg"}],"discussion_count":4,"race_medal":0,"score":"108917942323","product_id":100017301,"comment_content":"看了这一章，发现堆删除任意元素这个方法毫无意义啊。只有删除堆顶元素才有意义","like_count":25,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":431174,"discussion_content":"是的啊 没有说过删除任意元素呢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1543801740,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1455443,"avatar":"https://static001.geekbang.org/account/avatar/00/16/35/53/ead8c68c.jpg","nickname":"luckyncl","note":"","ucode":"D281CCAA72BD4B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":378932,"discussion_content":"有意义的，比如优先级队列，如果一个任务在排队，但是某种原因又取消了，那么就要从队列中去掉","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1623514795,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1438860,"avatar":"https://static001.geekbang.org/account/avatar/00/15/f4/8c/0866b228.jpg","nickname":"子房","note":"","ucode":"CB05938C248BB3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":350574,"discussion_content":"哈哈哈哈\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1613920253,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2261626,"avatar":"","nickname":"Geek_0386e5","note":"","ucode":"40AF296ED8CC3D","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":337240,"discussion_content":"HashHeap 就需要删除任意元素","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1608837155,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":113516,"user_name":"CathyLin","can_delete":false,"product_type":"c1","uid":1240546,"ip_address":"","ucode":"F7CDFF5E1A235F","user_header":"https://static001.geekbang.org/account/avatar/00/12/ed/e2/0e1c6c5a.jpg","comment_is_top":false,"comment_ctime":1563058043,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"104642273147","product_id":100017301,"comment_content":"还在继续赶大部队 LOL 但是不会放弃的！加油！<br>边做 Leetcode 边学习老师的课程有了更深刻的理解！<br>老师说的利用堆求 Top K 的应用对应于 Leetcode 973，大家有兴趣的可以去试一下！","like_count":24},{"had_liked":true,"id":117627,"user_name":"Leon📷","can_delete":false,"product_type":"c1","uid":1219496,"ip_address":"","ucode":"B9BBD1EFAAE5A2","user_header":"https://static001.geekbang.org/account/avatar/00/12/9b/a8/6a391c66.jpg","comment_is_top":false,"comment_ctime":1564103342,"is_pvip":false,"replies":[{"id":"43288","content":"赞，可行。","user_name":"作者回复","comment_id":117627,"uid":"1190123","ip_address":"","utype":1,"ctime":1564267441,"user_name_real":"王争"}],"discussion_count":7,"race_medal":0,"score":"91758416558","product_id":100017301,"comment_content":"之前遇到qq的一个面试题，一个用户的登录了qq，如果五分钟内用户没有检测到心跳包，就需要用户重新登录，登录后重新计时五分钟，是不是也用高等计时器来管理海量用户的计时登录问题，把qq号和时间五分钟当成堆节点，有心跳来就调整堆，把五分钟规定时间剩下最少的用户放在堆顶，后台线程每次扫描的时候取堆顶元素，然后计算剩余的等待时间，等规定时间到了，就取堆顶元素，判断是否为0，如果为0，就需要重新登录，一直取堆顶，直到取到不为0的元素，然后计算剩余等待时间，线程休眠，等到了规定时间再来，老师你看这个方案可行不","like_count":22,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":460060,"discussion_content":"赞，可行。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1564267441,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1114093,"avatar":"https://static001.geekbang.org/account/avatar/00/10/ff/ed/b2fc0e7c.jpg","nickname":"7","note":"","ucode":"10A6E57A027D42","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":252034,"discussion_content":"把qq号和时间五分钟当成堆节点；这句话的意思是以qq号为单位，每一个qq号建立一个小顶堆？你的心跳来了，是如何调整堆的？\n\n我的想法是这里直接采用hash表存下qq号和最近一次的心跳时间，后台线程定期(每隔10秒)遍历这个hash表，如果心跳或登录时间与当前时间差距小于5分钟，则保留，否则删除。来了心跳就直接put；hash表中只保留最近一次的心跳时间。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588136189,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":5,"child_discussions":[{"author":{"id":1254662,"avatar":"https://static001.geekbang.org/account/avatar/00/13/25/06/9f8f2b8e.jpg","nickname":"Glenn.G","note":"","ucode":"3E40E8625E2AAF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1114093,"avatar":"https://static001.geekbang.org/account/avatar/00/10/ff/ed/b2fc0e7c.jpg","nickname":"7","note":"","ucode":"10A6E57A027D42","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":260656,"discussion_content":"不可行吧，qq用户如此之多，一分钟一个包过来，你更新这个心跳的时间，系统就崩溃了。这个最好用分步方法。用session超时之类的办法解决","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1588877135,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":252034,"ip_address":""},"score":260656,"extra":""},{"author":{"id":1114093,"avatar":"https://static001.geekbang.org/account/avatar/00/10/ff/ed/b2fc0e7c.jpg","nickname":"7","note":"","ucode":"10A6E57A027D42","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1254662,"avatar":"https://static001.geekbang.org/account/avatar/00/13/25/06/9f8f2b8e.jpg","nickname":"Glenn.G","note":"","ucode":"3E40E8625E2AAF","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":260988,"discussion_content":"我说的这个是需要分区的，按照一致性hash分，一个机器只保存一部分qq用户，相同的id会被分到同一台机器。\n你说的分步方法是什么意思？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588924005,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":260656,"ip_address":""},"score":260988,"extra":""},{"author":{"id":1652836,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epKJlW7sqts2ZbPuhMbseTAdvHWnrc4ficAeSZyKibkvn6qyxflPrkKKU3mH6XCNmYvDg11tB6y0pxg/132","nickname":"pc","note":"","ucode":"1AD538B9A900B6","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1114093,"avatar":"https://static001.geekbang.org/account/avatar/00/10/ff/ed/b2fc0e7c.jpg","nickname":"7","note":"","ucode":"10A6E57A027D42","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":263204,"discussion_content":"1.遍历哈希表相当于遍历了全部的qq号，消耗有点大\n2.“调整堆”：修改元素的时间戳然后向下堆化。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1589187426,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":252034,"ip_address":""},"score":263204,"extra":""}]}]},{"had_liked":false,"id":128652,"user_name":"蚂蚁内推+v","can_delete":false,"product_type":"c1","uid":1050508,"ip_address":"","ucode":"24B10AEE54B3FD","user_header":"https://static001.geekbang.org/account/avatar/00/10/07/8c/0d886dcc.jpg","comment_is_top":false,"comment_ctime":1566924092,"is_pvip":false,"replies":[{"id":"48490","content":"维护数组有序的话，你用二分是可以查找的元素要插入的位置，但真正插入这个元素到这个位置的时候，你得搬移数据腾空间啊，这个复杂度就是O(n)了。<br><br>建堆虽然耗时，那只需要建一次堆，之后插入数据，只需要logk的时间复杂度的","user_name":"作者回复","comment_id":128652,"uid":"1190123","ip_address":"","utype":1,"ctime":1567378447,"user_name_real":"王争"}],"discussion_count":4,"race_medal":0,"score":"74581368124","product_id":100017301,"comment_content":"数据是动态的，为什么不能用数组呢？我们维护一个size为k的有序数组（用快排，复杂度是klogk，插入法建堆也是klogk），然后每来一个元素，就把数组的第一个元素比较，如果大就插入，如果小就舍弃。插入使用二分，也是logn。没感觉堆有什么好处啊？老师","like_count":17,"discussions":[{"author":{"id":2019799,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Rccaya3zw31Pxu1fRSiakKxjn7gBcXTyy7YE4BHVsGczceABMnKBRicrnxUlcptrOArQdj4hOP8AjRekrDvBx7KQ/132","nickname":"万政","note":"","ucode":"E59C2C660D6582","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":367502,"discussion_content":"快排是nlogn，建堆是nlogk；二分插入是logn + n（搬移数据要n），堆插入是logk。注意n和k的区别，n往往很大，k是往往很小的常数。","likes_number":4,"is_delete":false,"is_hidden":false,"ctime":1618377433,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":465040,"discussion_content":"维护数组有序的话，你用二分是可以查找的元素要插入的位置，但真正插入这个元素到这个位置的时候，你得搬移数据腾空间啊，这个复杂度就是O(n)了。\n\n建堆虽然耗时，那只需要建一次堆，之后插入数据，只需要logk的时间复杂度的","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1567378447,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":1027169,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ac/61/ae2ce8be.jpg","nickname":"dong","note":"","ucode":"B3671E4839EB08","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":535487,"discussion_content":"感谢老师时隔三年还来回复问题","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1638450602,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":465040,"ip_address":""},"score":535487,"extra":""}]},{"author":{"id":1330065,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/N0NACGUr8dNAbN6BdiagPHBaB0EnyDsI9zWpwJteqTY38apOEnTOA7JkBAQnzYKJBgxu3Q8YMUILwLAB6camn4w/132","nickname":"Swing","note":"","ucode":"55FCA9ECEFBBEB","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":76913,"discussion_content":"堆的方式，最坏时间复杂度是O(n) ，而你这个数组 平均情况就是O(n)，所以 堆好","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1575866817,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":49661,"user_name":"小花小黑的铲屎官","can_delete":false,"product_type":"c1","uid":1050823,"ip_address":"","ucode":"56061DCDD5EBE1","user_header":"https://static001.geekbang.org/account/avatar/00/10/08/c7/6b0cb046.jpg","comment_is_top":false,"comment_ctime":1544750657,"is_pvip":false,"replies":[{"id":"17895","content":"是的 你说的没错","user_name":"作者回复","comment_id":49661,"uid":"1190123","ip_address":"","utype":1,"ctime":1544754151,"user_name_real":"gg"}],"discussion_count":1,"race_medal":0,"score":"61674292801","product_id":100017301,"comment_content":"我们遍历这 10 亿个关键词，并且通过某个哈希算法对其求哈希值，然后哈希值同 10 取模，得到的结果就是这个搜索关键词应该被分到的文件编号。<br>这样并不能保证每个文件都是一亿条数据吧？可能多也可能少吧？","like_count":14,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":432707,"discussion_content":"是的 你说的没错","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1544754151,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":48134,"user_name":"攻城拔寨","can_delete":false,"product_type":"c1","uid":1053934,"ip_address":"","ucode":"CBC37183DAB6B2","user_header":"https://static001.geekbang.org/account/avatar/00/10/14/ee/d72a8222.jpg","comment_is_top":false,"comment_ctime":1544365405,"is_pvip":false,"replies":[{"id":"17168","content":"这需求...具体问题具体分析吧","user_name":"作者回复","comment_id":48134,"uid":"1190123","ip_address":"","utype":1,"ctime":1544406960,"user_name_real":"gg"}],"discussion_count":1,"race_medal":0,"score":"48789005661","product_id":100017301,"comment_content":"如果我要1%到99%响应时间，这样建的堆就有点多了","like_count":11,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":432042,"discussion_content":"这需求...具体问题具体分析吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1544406960,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":51248,"user_name":"Allen","can_delete":false,"product_type":"c1","uid":1241621,"ip_address":"","ucode":"57C92E14FF8F24","user_header":"https://static001.geekbang.org/account/avatar/00/12/f2/15/c5be3083.jpg","comment_is_top":false,"comment_ctime":1545142115,"is_pvip":false,"replies":[{"id":"18549","content":"👍 各有利弊吧","user_name":"作者回复","comment_id":51248,"uid":"1190123","ip_address":"","utype":1,"ctime":1545184795,"user_name_real":"gg"}],"discussion_count":1,"race_medal":0,"score":"44494815075","product_id":100017301,"comment_content":"高性能定时器，使用堆数据结构不一定是最优解，“环形队列”也许更好一点","like_count":10,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":433363,"discussion_content":"👍 各有利弊吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1545184795,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":44301,"user_name":"ALAN","can_delete":false,"product_type":"c1","uid":1240164,"ip_address":"","ucode":"70E3B1C730E63F","user_header":"https://static001.geekbang.org/account/avatar/00/12/ec/64/7403c694.jpg","comment_is_top":false,"comment_ctime":1543403714,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"35903142082","product_id":100017301,"comment_content":"1:建一个散射列表，key为点击网址，value为点击次数。散射列表通过从log中计算得来。<br>2:建一个10个数据的小顶堆，数据值为点击次数，扫描散射列表，新元素次数比堆顶元素大则删除堆顶元素，插入新元素，小则继续扫描散射列表。<br>3:扫描完整个散射列表后，即得到top 10点击量，将点击网址存储在数组A中。数组A一个小时更新一次。<br>4:散射列表实时更新，小顶堆也实时更新，以一小时为间隔，将小顶堆结果更新到数组A中。","like_count":8,"discussions":[{"author":{"id":1042685,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/e8/fd/abb7bfe3.jpg","nickname":"Langzi233","note":"","ucode":"5A21AC08FC089B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":205876,"discussion_content":"步骤2中，在扫描散列表的时候还会继续更新散列表，这个问题也要考虑下！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1584352990,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":216043,"user_name":"不需往后看","can_delete":false,"product_type":"c1","uid":1015410,"ip_address":"","ucode":"33EB4793C67B72","user_header":"https://static001.geekbang.org/account/avatar/00/0f/7e/72/3aeca403.jpg","comment_is_top":false,"comment_ctime":1589173282,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"31653944354","product_id":100017301,"comment_content":"用两个堆来求中位数这个学到了，很秀 😂，我有个形象点的理解，分享一下<br><br>想象：有两个锥形瓶, 灌满重量不同的小球，将大顶堆倒立，罗在小顶堆上面，整体看像一个沙漏⏳, 想象沙漏里装满了小球，根据大顶堆和小顶堆的规则，最上面的小球重量是最小的，最下面的小球重量是最大的，两个锥形瓶顶点交界处就是处于中间重量的小球，即中位数，插入元素就相当于把小球扔到沙漏里，沙漏会根据大顶堆和小顶堆的规则自动调整排列，这样堆顶处一直是中位数","like_count":7},{"had_liked":false,"id":163949,"user_name":"元","can_delete":false,"product_type":"c1","uid":1717444,"ip_address":"","ucode":"4576E15018EEA3","user_header":"https://static001.geekbang.org/account/avatar/00/1a/34/c4/08d9f349.jpg","comment_is_top":false,"comment_ctime":1576833077,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"31641604149","product_id":100017301,"comment_content":"高效定时器这个应用get！！！学习了，我打赌普通程序员都是直接一秒遍历所有任务的。学习了优先级队列就提升了水平。不愧为数据结构之美","like_count":8,"discussions":[{"author":{"id":1211898,"avatar":"https://static001.geekbang.org/account/avatar/00/12/7d/fa/4d1ccf80.jpg","nickname":"天意","note":"","ucode":"69B032C229036B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":220567,"discussion_content":"握爪，我就是那个普通程序员，捂脸笑.jpg\n","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1585898135,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1115041,"avatar":"https://static001.geekbang.org/account/avatar/00/11/03/a1/e6a0f60b.jpg","nickname":"Sid","note":"","ucode":"0461B574B2736B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":135178,"discussion_content":"握爪，我就是那个普通程序员，捂脸笑.jpg","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1579075904,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":52611,"user_name":"happiness","can_delete":false,"product_type":"c1","uid":1026587,"ip_address":"","ucode":"C5F25D57C7A1DC","user_header":"https://static001.geekbang.org/account/avatar/00/0f/aa/1b/b43c8519.jpg","comment_is_top":false,"comment_ctime":1545452618,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"27315256394","product_id":100017301,"comment_content":"方案前提，所有数据都保存在一台服务器的内存中，不考虑HA、数据更新冲突等情况。我们假设每条新闻都有一个全局唯一的新闻ID，使用hashmap(map_a)来保存每篇新闻的访问量，key为新闻ID，value为当前访问总次数。使用另一个hashmap(map_b)来保存一个周期内map_a中value值发生变化的key。<br><br>整个方案分为三个阶段，堆的初始化、hashmap实时变更、堆更新。<br>初始化阶段：建立一个大小为10的小顶堆，遍历此时的hashmap，完成堆的初始化。<br>hashmap实时变更阶段：保存在当前周期内，将map_a中value产生变化的key到map_b中。<br>堆更新阶段：在一个周期结束后，遍历map_b，并将map_a中保存的value与当前堆顶进行比较，如果大于堆顶，则删除堆顶，并插入该value，如果小于堆顶则不做处理。遍历完map_b之后，该堆保有了上个周期访问量top10的新闻id和value。最后清空map_b，为下一个周期作准备。最坏时间复杂度为O(nlog10)，其中n为map_b中key的数量。<br>","like_count":6},{"had_liked":false,"id":46788,"user_name":"程序员大天地","can_delete":false,"product_type":"c1","uid":1249001,"ip_address":"","ucode":"7A21F15FEE2D5B","user_header":"https://static001.geekbang.org/account/avatar/00/13/0e/e9/98b6ea61.jpg","comment_is_top":false,"comment_ctime":1543982421,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"27313786197","product_id":100017301,"comment_content":"思考题：<br>1、实时建立散列表，key是新闻的摘要，value是点击量；<br>2、建立一个10的小顶堆，每隔一个小时扫描一次散列表，根据点击量大小放入到小顶堆中，扫描完散列表后即出现Top10 的新闻点击量。","like_count":6},{"had_liked":false,"id":43976,"user_name":"Jerry银银","can_delete":false,"product_type":"c1","uid":1008404,"ip_address":"","ucode":"80DA1172A2360A","user_header":"https://static001.geekbang.org/account/avatar/00/0f/63/14/06eff9a4.jpg","comment_is_top":false,"comment_ctime":1543359484,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"27313163260","product_id":100017301,"comment_content":"早起的鸟儿读算法。<br><br><br>原理上跟统计热门搜索关键词类似。后台起一个定时任务，从最新被新点击的新闻日志文件中统计出每条新闻的点击量(也得类似于老师那样使用散列表)，然后建立和维护内存中大小为10的最大堆，这样网站点击次数Top10的新闻就被统计出来了。<br><br>这题也可以使用MapReduce算法","like_count":6,"discussions":[{"author":{"id":1268797,"avatar":"https://static001.geekbang.org/account/avatar/00/13/5c/3d/e8325811.jpg","nickname":"对白","note":"","ucode":"3183E5ADBC794B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":297018,"discussion_content":"应该是小顶堆吧？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1596728915,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1250807,"avatar":"https://static001.geekbang.org/account/avatar/00/13/15/f7/744720a2.jpg","nickname":"DriveMan_邱佳源","note":"","ucode":"A4C83BF07DEE7A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":8172,"discussion_content":"你真的是按时学习算法","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567819617,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":73940,"user_name":"懒猫","can_delete":false,"product_type":"c1","uid":1206544,"ip_address":"","ucode":"B4B567A11B491D","user_header":"https://static001.geekbang.org/account/avatar/00/12/69/10/275ae749.jpg","comment_is_top":false,"comment_ctime":1552039196,"is_pvip":false,"replies":[{"id":"27373","content":"你说的没错，先把K个元素一股脑放进去。","user_name":"作者回复","user_name_real":"gg","uid":"1190123","ctime":1552358145,"ip_address":"","comment_id":73940,"utype":1}],"discussion_count":2,"race_medal":0,"score":"23026875676","product_id":100017301,"comment_content":"”查找前K大数据呢？我们可以维护一个大小为K的小顶堆，顺序遍历数组，从数组中取出取数据与堆顶元素比较。如果比堆顶元素大，我们就把堆顶元素删除，并且将这个元素插入到堆中；如果比堆顶元素小，则不做处理，继续遍历数组。这样等数组中的数据都遍历完之后，堆中的数据就是前K大数据了。“，没人觉得这里有问题么，【如果比堆顶元素大，我们就把堆顶元素删除】，应该是如果比堆顶元素大，且堆已满的情况下才删除堆顶元素吧，否则只是比堆顶大，但堆未满，还是得插入。例如求top3，数组元素是5,6,2,4,1，按老师讲的就不是top3了","like_count":5,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":442350,"discussion_content":"你说的没错，先把K个元素一股脑放进去。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1552358145,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1359701,"avatar":"https://static001.geekbang.org/account/avatar/00/14/bf/55/198c6104.jpg","nickname":"小伟","note":"","ucode":"124953423491E2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":173615,"discussion_content":"仔细想想就知道堆长超过K才需要删除堆顶的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1581860783,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":168648,"user_name":"注定非凡","can_delete":false,"product_type":"c1","uid":1113597,"ip_address":"","ucode":"80673056E131B7","user_header":"https://static001.geekbang.org/account/avatar/00/10/fd/fd/326be9bb.jpg","comment_is_top":false,"comment_ctime":1578131365,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"18758000549","product_id":100017301,"comment_content":"应用一：<br>\t&lt;1&gt;：优先级队列<br>\t\t1，优先级队列，数据的出队顺序不是先进先出，而是而是按照优先级来，优先级最高的，最先出队。<br>\t\t2，实现一个优先级队列方法很多，但是用堆来实现是最直接，最高效的，这是因为堆和优先级队列非常相似。一个堆可以看作一个优先级队列，很多时候，他们只是概念上的区分。往优先级队列中插入一个元素，就相当于往堆中插入一个元素；从优先级队列中取出优先级最高的元素，就相当于取出堆顶元素。<br>\t\t3，优先级队列的应用广泛，如赫夫曼编码，图的最短路径，做小生成树的算法等等<br>\t\t<br>\t&lt;2&gt;：优先级队列应用一：合并有序小文件<br>\t\t假设：有100个小文件，每个文件大小为100MB，每个文件中储存的都是有序的字符串。现需要将这100个小文件合并成一个有序的大文件。<br>\t\t思路：<br>\t\t1，整体思路有点像归并排序中的合并函数，从100个文件中，各取第一个字符串，放入数组中，然后比较大小，把最小的那个字符串合并后的大文件中，并从数组中删除。<br>\t\t2，假设，最小的字符串来自于13.txt这个文件，就再次从这个文件找那个取下一个字符串，放到数组中，重新比较大小，并且选择最小的放入合并后的大文件，将它从数组中删除。依次类推，直到所有的文件中的数据都放入到大文件为止。<br>\t\t3，使用数组来存储从小文件中取出来的字符串，每次从数组中取最小字符串，都需要循环遍历整个数组，效率不高。<br>\t\t4，可以用到优先级队列，也可以说是堆。将从小文件中取出的字符串放入到小顶堆中，堆顶的元素就是优先级队列队首的元素，就是最小的字符串。<br>\t\t5，依次从小文件中取出下一个字符串，放入到堆中，循环这过程。<br>\t\t删除堆顶数据和往堆中插入数据的时间复杂度都是O(logn)，n表示堆中的数据个数，这里就是100\t<br>\t&lt;3&gt;：优先队列应用二：高性能定时器<br>\t\t假设：有一个定时器，定时器中维护了很多定时任务<br>\t\t1，每过1秒就扫描一遍任务列表做法太低效。原因1：任务的约定执行时间离当前时间可能还有很久，大量的扫描徒劳无功。原因2：每次都要扫描整个任务列表，若列表较大，会比较耗时。<br>\t\t2，针对这种文件，可用优先队列来解决。按照任务设定的执行时间，将这些任务存储在优先级队列中，队列首部（最小顶堆）存储的是最先执行的任务。<br>\t\t3，这样定时器就不用每隔一秒就扫描一遍任务列表了。它拿队首任务的执行时间点，与当前时间点相减，即可得到一个时间间隔T。<br>\t\t4，当T秒时间过去后，定时器取优先级队列中队首的任务执行，然后在计算新的队首任务的执行时间点和当前时间点的差值。<br>\t\t5，这样定时器就不用间隔1秒就轮询一次，也不用遍历整个任务列表，性能就提高了。<br><br>应用二：利用堆求Top K<br>\t求Topk的问题可抽象成两类：<br>\t\t1，针对静态数据<br>可以维护一个大小为k的小顶堆，顺序遍历数组，从数组中取出数据与堆顶元素比较。如果堆顶元素大，就将堆顶元素删除，并且将这个元素插入到堆中；如果比堆顶元素小则不做处理，继续遍历数组。这样等数组中的数据都遍历完之后，堆中的数据就是前k大数据了。<br>遍历数据需要O(n)的时间复杂度，一次堆化操作需要O(logk)的时间复杂度，最坏情况下，n个元素都入堆一次，时间复杂度就是O(nlogk)。<br><br>\t\t2，针对动态数据求得Topk就是实时Topk。<br>一个数据集合有两个操作，一个是添加数据，另一个询问当前的前k大数据。<br>可以维护一直都维护一个k大小的小顶堆，当有数据被添加到集合时，就那它与堆顶的元素对对比。如果比堆顶元素大，就把堆顶元素删除，并将这个元素插入到堆中，如果比堆顶元素小，这不处理。这样，无论任何时候需要查询当前的前k大数据，就都可以 立刻返回给他。<br><br>\t应用三：利用堆求中位数<br>\t\t1，对于一组静态数据，中位数是固定的，可以先排序，第n&#47;2个数据就是中位数。<br>\t\t2，对于动态数据集合，就无法先排序了，需要借助堆这种数据结构，我们不用排序，就可以非常高效的实现求中位数操作。<br>\t\t\t实现思路：<br>1，需要维护两个堆，大顶堆中存储前半部分数据，小顶堆中存储后半部分数据，且小顶堆中的数据都大于大顶堆中的数据。<br>2，即：如果有n个数据，n是偶数，从小到大排序，那前n&#47;2个数据存储在大顶堆中，后n&#47;2个数据存储在小顶堆中。这样，大顶堆中堆顶元素就是要找的中位数。<br>3，如果新加入的数据小于等于大顶堆的堆顶元素，就将这个数据插入到大顶堆；否则就插入小顶堆<br>4，当两个堆中的数据量不服和中位数的约定时，就从一个堆中不停的将堆顶的元素移动到另一个堆，重新让两个堆中数据满足上面的约定。<br>\t\t<br>于是，可以利用两个堆实现动态数据集合中求中位数的操作，插入数据因为涉及堆化，所以时间复杂度变成了O(logn)，但求中位数只需要返回大顶堆的堆顶元素就可以了，所以时间复杂度就是O(1)。<br>","like_count":4},{"had_liked":false,"id":65291,"user_name":"ferry","can_delete":false,"product_type":"c1","uid":1255187,"ip_address":"","ucode":"0A848FA96C3AD8","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJGOSxM1GIHX9Y2JIe7vGQ87rK8xpo5F03KmiaGyXeKnozZsicHeSZrbSlzUVhTOdDlXCkTrcYNIVJg/132","comment_is_top":false,"comment_ctime":1549201337,"is_pvip":false,"replies":[{"id":"24292","content":"快速排序只能应对静态数据；如果数据集合一直在变动，那堆肯定更适合了","user_name":"作者回复","user_name_real":"gg","uid":"1190123","ctime":1550542526,"ip_address":"","comment_id":65291,"utype":1}],"discussion_count":4,"race_medal":0,"score":"18729070521","product_id":100017301,"comment_content":"看完老师给出的三个应用后，我在想快速排序和堆排序时间复杂度相同，那么用快速排序替换堆排序可以吗？是考虑到堆排序时间复杂度的稳定性所以选择堆排序，还是因为别的原因呢？","like_count":4,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438389,"discussion_content":"快速排序只能应对静态数据；如果数据集合一直在变动，那堆肯定更适合了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1550542526,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1616981,"avatar":"https://static001.geekbang.org/account/avatar/00/18/ac/55/f7aec5c3.jpg","nickname":"白菜","note":"","ucode":"D4CF8392B3BCBE","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":39847,"discussion_content":"因为排序算法是让一组元素完整前后有序的，而堆只是保证了上限或者下限值。小顶堆堆顶就是最小值，大顶堆堆顶就是最大值。堆内其他的元素只是保证了父子节点的相对有序。这样建立K个元素的堆的复杂度是O(n),而排序K个元素的复杂度是O(nlogn)，建堆比排序更能节省时间。新的动态元素过来时，如果是入堆，堆化复杂度是O(logK)，但是如果是入有序数组，时间就是二分查找时间O(logK)+最坏元素挪动时间O(K)。","likes_number":5,"is_delete":false,"is_hidden":false,"ctime":1571998890,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1050508,"avatar":"https://static001.geekbang.org/account/avatar/00/10/07/8c/0d886dcc.jpg","nickname":"蚂蚁内推+v","note":"","ucode":"24B10AEE54B3FD","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":6499,"discussion_content":"数据是动态的，为什么不能用数组呢？我们维护一个size为k的有序数组（用快排，复杂度是klogk，插入法建堆也是klogk），然后每来一个元素，就把数组的第一个元素比较，如果大就插入，如果小就舍弃。插入使用二分，也是logn。没感觉堆有什么好处啊？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1566924069,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1042685,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/e8/fd/abb7bfe3.jpg","nickname":"Langzi233","note":"","ucode":"5A21AC08FC089B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1050508,"avatar":"https://static001.geekbang.org/account/avatar/00/10/07/8c/0d886dcc.jpg","nickname":"蚂蚁内推+v","note":"","ucode":"24B10AEE54B3FD","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":206424,"discussion_content":"数组的插入用二分查找（时间复杂度为O(logn)）只是找到了位置，然后，然后数组的插入是要挪动数据的，这个时间复杂度是O(n).....","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1584405108,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":6499,"ip_address":""},"score":206424,"extra":""}]}]},{"had_liked":false,"id":43977,"user_name":"Jerry银银","can_delete":false,"product_type":"c1","uid":1008404,"ip_address":"","ucode":"80DA1172A2360A","user_header":"https://static001.geekbang.org/account/avatar/00/0f/63/14/06eff9a4.jpg","comment_is_top":false,"comment_ctime":1543359933,"is_pvip":false,"replies":[{"id":"15712","content":"是我写错了 不好意思 马上修改","user_name":"作者回复","user_name_real":"gg","uid":"1190123","ctime":1543370380,"ip_address":"","comment_id":43977,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18723229117","product_id":100017301,"comment_content":"早起的鸟儿读算法。<br><br>文章中『解答开篇』部分，说是扫描1亿个热门关键词，这应该是错别字吧，应该是10亿个吧。看了好几遍，我应该没理解错吧😄<br><br>老师说使用散列表统计10亿个搜索关键词的频率，但是这里的约束条件是10亿个关键词中确实有很多重复，而且去重之后的数据，内存中是能够放得下的。如果单机内存放不下，应该就不能这么做了<br><br>---------------------------------------------------------<br><br>以上是我早上本来要留言的，但是并没有一字不漏的看完文章。我回头一想不对，文章中肯定会考虑到这个情况。当我看完，我就把以上留言删了。<br><br>唉，阅读时，犯了一个低级错误，记录在此，提醒自己","like_count":4,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":430578,"discussion_content":"是我写错了 不好意思 马上修改","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1543370380,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":116039,"user_name":"J.Smile","can_delete":false,"product_type":"c1","uid":1336475,"ip_address":"","ucode":"C4D98DFDBF7584","user_header":"https://static001.geekbang.org/account/avatar/00/14/64/9b/0b578b08.jpg","comment_is_top":false,"comment_ctime":1563776768,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"14448678656","product_id":100017301,"comment_content":"一看到应用场景的就来劲了哈哈","like_count":3},{"had_liked":false,"id":115083,"user_name":"Paul Shan","can_delete":false,"product_type":"c1","uid":1593140,"ip_address":"","ucode":"32D99989028284","user_header":"","comment_is_top":false,"comment_ctime":1563487351,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"14448389239","product_id":100017301,"comment_content":"对于百分数的问题，我个人更倾向于用红黑树加计数来实现，可以在log n的复杂度内求出任意百分位的元素，虽然红黑树本身比较复杂，但是有现成的实现，这种方法比较灵活。","like_count":3},{"had_liked":false,"id":46960,"user_name":"ECHO","can_delete":false,"product_type":"c1","uid":1237109,"ip_address":"","ucode":"08CDD0AC92E20C","user_header":"https://static001.geekbang.org/account/avatar/00/12/e0/75/1763638a.jpg","comment_is_top":false,"comment_ctime":1544009381,"is_pvip":false,"replies":[{"id":"16932","content":"有点类似","user_name":"作者回复","user_name_real":"gg","uid":"1190123","ctime":1544149021,"ip_address":"","comment_id":46960,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14428911269","product_id":100017301,"comment_content":"为了解决内存不够，而采用的“10 亿条搜索关键词先通过哈希算法分片到 10 个文件中” 这个思想是否类似 桶排序 的思想呢？ ","like_count":3,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":431619,"discussion_content":"有点类似","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1544149021,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":44132,"user_name":"蚂蚁内推+v","can_delete":false,"product_type":"c1","uid":1050508,"ip_address":"","ucode":"24B10AEE54B3FD","user_header":"https://static001.geekbang.org/account/avatar/00/10/07/8c/0d886dcc.jpg","comment_is_top":false,"comment_ctime":1543372046,"is_pvip":false,"replies":[{"id":"15777","content":"没太看懂你说的 用优先级是为了效率","user_name":"作者回复","user_name_real":"gg","uid":"1190123","ctime":1543404073,"ip_address":"","comment_id":44132,"utype":1}],"discussion_count":4,"race_medal":0,"score":"14428273934","product_id":100017301,"comment_content":"王老师  第一点合并有序小文件 为什么要用到优先级队列 和 堆还是不理解。两个比最小取出合并，只要两个数组是有序就可以了，快排成有序，从小到大比较合并，不可以吗，为什么要用到优先级队列，方便老师解答下吗","like_count":3,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":430643,"discussion_content":"没太看懂你说的 用优先级是为了效率","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1543404073,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1330065,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/N0NACGUr8dNAbN6BdiagPHBaB0EnyDsI9zWpwJteqTY38apOEnTOA7JkBAQnzYKJBgxu3Q8YMUILwLAB6camn4w/132","nickname":"Swing","note":"","ucode":"55FCA9ECEFBBEB","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":76908,"discussion_content":"老哥，思考有误。。\nk个数据建堆是O(k)，之后剩下的n-k个元素 依次比较 是否 入堆堆化，\n最差情况 全部参与堆化，也就是 O((n-k)logk)，\n最终 最差复杂度 是 O(n) \n\n其他方式 比如 有序数组 O(n) 或者 直接全排序O(nlogn) , 都不如这个\n","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1575866545,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1014550,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/7b/16/ca250e8c.jpg","nickname":"王木公","note":"","ucode":"F049AEBFA0338D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":70289,"discussion_content":"不明白你说的意思。本质是100个有序数组合并成一个大的有序数组。\n\n简单的办法文中也有提到，维护一个长度为100数组m。在100个文件中各取一条最小的数据放入m，遍历数组m找到最小值k，放入大数组中，并将k在m中删除，从k所在的文件中继续找下一个最小的数值放入m中。遍历数组m找最小值的时间复杂度是O(n)\n\n使用优先级队列（堆）可以替代遍历数组m找最小值k的工作。具体步骤是\n1. 仍从100个文件中取出最小的100个数据，构建一个小顶堆，时间复杂度为100 * O(logn) = O(logn)\n2. 堆顶元素即为最小值k，放入大数组中，并删除堆顶元素。删除操作时间复杂度为O(logn)\n3. 到k所在文件继续取最小的值，插入堆中。插入操作时间复杂度为O(logn)\n4. 重复2、3步骤\n\n总时间复杂度仍是O(logn)，比O(n)性能高","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1575342597,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1114093,"avatar":"https://static001.geekbang.org/account/avatar/00/10/ff/ed/b2fc0e7c.jpg","nickname":"7","note":"","ucode":"10A6E57A027D42","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":251986,"discussion_content":"合并有序小文件\n令 X = ((n-100)+(n-101)+...+1)\n令 Y = (100+99+..+1)\n先把从每个文件中拿出第一个，一次放在数组中；三种方式都会使用\n\n如果直接合并，老师说的方法是每次来都遍历这100个元素，找到最小的，所以时间复杂度 = O(X*100 + Y)； 后面100个数据排序使用比较，最快为100*log100；如果每次都选去最小的，等于 Y； \n\n如果使用堆，100个数据建堆是O(100)，之后剩下的n-100个元素依次比较，都是有序文件了，时间复杂度为O(X*log100)；最后在从堆中拿出100个数据为 (log100+log99+..+log1)；所以时间复杂度 = O(100) + O(X*log100) + (log100+log99+..+log1)\n\n如果先对这100个数据进行排序，比较排序中最快100*log100，后面再遍历n-100个元素，使用插入排序（在数据已经有序的情况下，使用插排），每次取最小的（在头部）;\n最差每次都在末尾，所以时间复杂度 = O(100*log100) + O(100*X) + O(X*拷贝99个元素的时间 = X * 99) + O(100)剩下的100个元素直接按照从头到尾的方式取；\n最好每次都插在头，所以时间复杂度 = O(100*log100) + O((X))+ O(100)剩下的100个元素直接按照从头到尾的方式取\n平均下来，100个位置，都有可能发生，在某个位置的概率是 1/100 * Y；所以时间复杂度 = O(100*log100) + O(1/100 * Y * X) + O(X* 拷贝1/100 * Y个元素的时间 = X * 1/100 * Y) + O(100)剩下的100个元素直接按照从头到尾的方式取；\n\n不知道我分析的有没有问题","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588132002,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":44125,"user_name":"aof","can_delete":false,"product_type":"c1","uid":1062864,"ip_address":"","ucode":"5815D63C4926BC","user_header":"https://static001.geekbang.org/account/avatar/00/10/37/d0/26975fba.jpg","comment_is_top":false,"comment_ctime":1543371554,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"14428273442","product_id":100017301,"comment_content":"Hadoop、Spark入门demo——wordcount了解下","like_count":3},{"had_liked":false,"id":111424,"user_name":"拯救地球好累","can_delete":false,"product_type":"c1","uid":1339022,"ip_address":"","ucode":"7643439601EF4C","user_header":"https://static001.geekbang.org/account/avatar/00/14/6e/8e/5d309a85.jpg","comment_is_top":false,"comment_ctime":1562556131,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10152490723","product_id":100017301,"comment_content":"应用场景：TopK&amp;查找百分位数&amp;优先队列问题<br>优先队列应用场景示例：赫夫曼编码&amp;最小生成树&amp;最短路径&amp;合并小文件&amp;高性能定时器<br>（我们会发现，很多优先队列的应用场景往往会结合贪心算法，贪心算法会关注当前最优的元素，而这种最优的筛选往往可以通过优先队列这种数据结构来实现）<br>TopK问题的解决方案：堆||快速排序<br>查找百分位数的解决方案：两个按百分位配比的大顶堆和小顶堆<br>排序问题分类：静态数据排序&amp;动态数据排序","like_count":2},{"had_liked":false,"id":108706,"user_name":"莫小鹏","can_delete":false,"product_type":"c1","uid":1158881,"ip_address":"","ucode":"0EE0654FD0FB85","user_header":"https://static001.geekbang.org/account/avatar/00/11/ae/e1/78701ecf.jpg","comment_is_top":false,"comment_ctime":1561861207,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10151795799","product_id":100017301,"comment_content":"https:&#47;&#47;leetcode-cn.com&#47;problems&#47;find-median-from-data-stream&#47;<br>数据流的中位数，leetcode上面的题目，用到了大顶堆和小顶堆","like_count":2},{"had_liked":false,"id":91620,"user_name":"Monday","can_delete":false,"product_type":"c1","uid":1250907,"ip_address":"","ucode":"77B9BACC783598","user_header":"https://static001.geekbang.org/account/avatar/00/13/16/5b/83a35681.jpg","comment_is_top":false,"comment_ctime":1557062078,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10146996670","product_id":100017301,"comment_content":"最近看PriorityBlockingQueue源码，offer与poll的底层就是使用的堆这种数据结构。看此类的代码联系到了了本章的内容，理解起来就爽歪歪了😊😊","like_count":2},{"had_liked":false,"id":85577,"user_name":"xfan","can_delete":false,"product_type":"c1","uid":1315147,"ip_address":"","ucode":"48ED8D498D7F56","user_header":"https://static001.geekbang.org/account/avatar/00/14/11/4b/fa64f061.jpg","comment_is_top":false,"comment_ctime":1555131070,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"10145065662","product_id":100017301,"comment_content":"不用分片的，直接分文件而不用hash,将10亿个分存到10个文件乃至100个文件","like_count":2,"discussions":[{"author":{"id":1254530,"avatar":"https://static001.geekbang.org/account/avatar/00/13/24/82/b5808a60.jpg","nickname":"李冲","note":"","ucode":"C8C12308B0FDDA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":4952,"discussion_content":"如果同一个关键词被拆分到不同文件，缩小规模就没有意义了。hash确保的是完整性，不是为了拆分均衡","likes_number":5,"is_delete":false,"is_hidden":false,"ctime":1565856958,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2359194,"avatar":"https://static001.geekbang.org/account/avatar/00/23/ff/9a/f7d84a69.jpg","nickname":"Andrew.Fang","note":"","ucode":"1D754BBFC223F4","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":342414,"discussion_content":"你没法全局统计一个关键字出现场的次数啊。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1610677469,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":63003,"user_name":"被吹落的风","can_delete":false,"product_type":"c1","uid":1242309,"ip_address":"","ucode":"AF62645E386A7B","user_header":"https://static001.geekbang.org/account/avatar/00/12/f4/c5/39f2acfd.jpg","comment_is_top":false,"comment_ctime":1548225182,"is_pvip":false,"replies":[{"id":"22481","content":"我描述的可能引起你误解了。并不是去掉。我的意思是不重复的可能只有1000万。","user_name":"作者回复","user_name_real":"gg","uid":"1190123","ctime":1548405515,"ip_address":"","comment_id":63003,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10138159774","product_id":100017301,"comment_content":"老师，我有一事不明，请赐教：“对这 10 亿个关键词分片之后，每个文件都只有 1 亿的关键词，去除掉重复的，可能就只有 1000 万个”，这里为啥要会去掉重复的呢，文件里确实真实存在着重复数据啊，每个文件大于1G。","like_count":2,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":437435,"discussion_content":"我描述的可能引起你误解了。并不是去掉。我的意思是不重复的可能只有1000万。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1548405515,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":50212,"user_name":"Geek_5258f8","can_delete":false,"product_type":"c1","uid":1209313,"ip_address":"","ucode":"4EC60AE0C23CBE","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIbas4S4X5W15njMeoEPPSyBZRX37nrTXbMFFeHghXl4Slk6WXE7oq5yxoNnukYfcOQs00RAvUmEA/132","comment_is_top":false,"comment_ctime":1544924312,"is_pvip":false,"replies":[{"id":"18574","content":"当然是堆了","user_name":"作者回复","user_name_real":"gg","uid":"1190123","ctime":1545186210,"ip_address":"","comment_id":50212,"utype":1}],"discussion_count":2,"race_medal":0,"score":"10134858904","product_id":100017301,"comment_content":"topk用快排与小堆哪个更快？","like_count":2,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":432916,"discussion_content":"当然是堆了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1545186210,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1201054,"avatar":"https://static001.geekbang.org/account/avatar/00/12/53/9e/e932c1a8.jpg","nickname":"jing","note":"","ucode":"C0186996EBD25A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":218139,"discussion_content":"这个是不是可以用有序度来估一下，如果是快排的话，那就要所有的数据都变为有序的；如果是堆的话，只需要保证 k 个数在堆中，甚至这 k 个数之间也不用保证它们是有序的。所以总体估量，应该是堆交换次数少，所以是堆更快","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1585623547,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":44082,"user_name":"吴宇晨","can_delete":false,"product_type":"c1","uid":1199968,"ip_address":"","ucode":"F8F45B7067DF6D","user_header":"https://static001.geekbang.org/account/avatar/00/12/4f/60/049a20e9.jpg","comment_is_top":false,"comment_ctime":1543367825,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10133302417","product_id":100017301,"comment_content":"可以先用散列表存帖子和点击数的关系，然后每一小时定时遍历散列表用文中的方法，往大小为10的小顶堆插数据？","like_count":2},{"had_liked":false,"id":44072,"user_name":"P@tricK","can_delete":false,"product_type":"c1","uid":1233716,"ip_address":"","ucode":"293B2B3261A793","user_header":"https://static001.geekbang.org/account/avatar/00/12/d3/34/5dee4f70.jpg","comment_is_top":false,"comment_ctime":1543367214,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10133301806","product_id":100017301,"comment_content":"思考题：<br>1. 用散列表存储每个链接的点击数<br>2. 用优先级队列实现高性能定时器，在初始化和处理函数时更新插入1小时的定时器<br>3. 利用堆，将散列表中的链接根据点击次数求top10","like_count":2},{"had_liked":false,"id":329356,"user_name":"篂篂点点","can_delete":false,"product_type":"c1","uid":2644570,"ip_address":"","ucode":"475010AFAFA285","user_header":"https://static001.geekbang.org/account/avatar/00/28/5a/5a/29c8c4d6.jpg","comment_is_top":false,"comment_ctime":1641299514,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5936266810","product_id":100017301,"comment_content":"堆的应用：<br>\t1.开篇问题：现有一个包含10亿个搜索关键词的日志文件，如何能快速获取到热门榜top10的歌曲。<br>\t2.优先队列问题：<br>\t\t定义：队列是先进先出，优先队列是优先级最高的数据先出。<br>\t\t用途：<br>\t\t\t1.合并有序小文件。<br>\t\t\t假设我们有 100 个小文件，每个文件的大小是 100MB，每个文件中存储的都是”有序“的字符串。\t\t<br>\t\t\t思路：<br>\t\t\t\t1.从这100个文件中，各取第一个字符，放到数组中，比较大小，将最小的那个字符串放入合并后的大文件中，并从数组删除。<br>\t\t\t\t2.假设最小的字符串来自第1个文件，就再从这个小文件中取下一个字符串，放到数组，重新比较大小，选择最小的放到合并后的大文件中。<br>\t\t\t\t3.重复上述过程，直至遍历完所有的文件。<br>\t\t\t\t优化：数组每次选最小的字符串入大文件都需要遍历数组，可以用小顶堆。每次和小顶堆的堆顶元素比较。<br>\t3.高性能定时器问题：<br>\t\t定义：有一批任务，要在不同的时间点执行。<br>\t\t粗暴：每过1s去遍历所有的任务,符合则去执行。这样子浪费资源。<br>\t\t优化：<br>\t\t\t1.遍历所有的时间点，按照时间点的前后，组成一个小顶堆。堆顶元素就是最先执行的任务。<br>\t\t\t2.不需要每1s去扫描一遍任务列表。当前时间和堆顶时间点，做差，得到时间段T。<br>\t\t\t3.定时器设为T秒后去执行这个任务。<br>\t\t\t4.执行完任务后，重新堆化。<br>\t\t\t5.取堆顶元素重复上述操作。<br>\t4.利用堆求topK：<br>\t\t定义：此问题分为两类，一类是针对静态数据，一类是针对动态数据。<br>\t\t静态：1.数组排序，元素为奇数时：n+1&#47;2，元素为偶数时n&#47;2，时间复杂度O(nlogn)。<br>\t\t\t  2.先取前K个元素组建小顶堆，然后遍历剩余元素，大于堆顶元素则删除堆顶元素，插入新元素。遍历所有元素则得到topK的元素。<br>\t\t动态：3.采用上述小顶堆的形式。每次插入数据时，先入集合，然后和小顶堆的堆顶元素比较，大于则删除堆顶，新元素入堆。<br>\t\t\t  4.就可以实时的去取topK元素。<br>\t5.取中位数<br>\t\t定义：假设n个元素，n为奇数时：n+1&#47;2，元素为偶数时n&#47;2为中位数。<br>\t\t静态：1.先排序，然后取中位数。<br>\t\t动态：假设还是按照1去做，每次都需要排序，带价太大。<br>\t\t\t  2.先维护一个节点数量为n&#47;2或n+1&#47;2的小顶堆，然后遍历完成数组剩下的元素，大于堆顶元素则入堆，小于则判断下一个元素。<br>\t\t\t    小顶堆的堆顶元素就是中位数。每次插入数据和堆顶元素比较，大于则删除堆顶元素，新元素入堆并堆化，小于则不处理堆。<br>\t6.取&quot;99% 响应时间&quot;<br>\t\t定义：99百分位数的概念可以类比中位数，如果将一组数据从小到大排列，这个 99 百分位数就是大于前面 99% 数据的那个数据。<br>\t\t动态：1.99%本身不确定数据个数，假设数据个数是n，取数组前99%*n的数据维护一个小顶堆。<br>\t\t\t  2.然后继续遍历1%*n的数据，大于堆顶元素则入堆，小于则判断下一个元素。<br>\t\t\t  3.每次新增元素，重复过程2<br>\t开篇解答:<br>\t\t构建大小为10的初始小顶堆，遍历数组的所有元素，小于堆顶元素则不处理，大于则删除堆顶元素，入堆新元素并堆化。<br>\t进阶：10亿词条，设不重复的有1亿条。每个词条50字节。则最少需要5GB内存，现在我们只有1GB的内存。<br>\t\t  概述:将10亿个词条通过hash算法分片到10个文件中。<br>\t\t  具体:1.创建10个空文件1到10，遍历10亿关键词，通过哈希算法对其求哈希值，然后哈希值对10取模，得到的是这个搜索关键词应该被分到的文件编号。<br>\t\t\t   2.每个文件都有一亿个关键词，去除掉重复的，可能就只有 1000 万个，每个关键词平均 50 个字节，所以总的大小就是 500MB。<br>\t\t\t   3.我们针对每个包含1亿条搜索关键词的文件，利用散列表和堆，分别求出Top10，然后获得10个top10，这一百个关键词中取出最多的10个关键词<br>\t\t\t   就得到了top10<br>\t<br>\t\t\t ","like_count":1},{"had_liked":false,"id":214880,"user_name":"欧阳洲","can_delete":false,"product_type":"c1","uid":1986708,"ip_address":"","ucode":"94606A6315F2BA","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKT9Tk01eiaQ9aAhszthzGm6lwruRWPXia1YYFozctrdRvKg0Usp8NbwuKBApwD0D6Fty2tib3RdtFJg/132","comment_is_top":false,"comment_ctime":1588841247,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"5883808543","product_id":100017301,"comment_content":"王老师，请教一下：中位数问题，只维护一个堆，堆顶元素不就是中位数了吗，为什么需要维护2个堆呢，是因为n为偶数的时候，中位数有2个吗？","like_count":1,"discussions":[{"author":{"id":1334855,"avatar":"https://static001.geekbang.org/account/avatar/00/14/5e/47/b8d03d92.jpg","nickname":"TigerLee","note":"","ucode":"45E3F608AF7A85","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":531407,"discussion_content":"维护2个堆的场景针对动态数据的! 在数据频繁添加场景下,如果你采用topK的方式，每次添加就需要遍历整个数据集合来拿中位数性能不高，时间复杂度是O(NLogK)。 采用2个堆, 就无需遍历整个数据集合了，只需动态维护2个堆性能更优时间复杂度O(logN)。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1637305289,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"user_type\":1}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1248326,"avatar":"https://static001.geekbang.org/account/avatar/00/13/0c/46/dfe32cf4.jpg","nickname":"多选参数","note":"","ucode":"B2294D80AB075F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":294238,"discussion_content":"我是这么理解的，如果只维护一个堆，那么当之后调整堆的时候，也就是确保两个堆的数量是按照比例来的时候，你是需要从另一个堆中取数据的。如果不维护两个堆，你在调整的时候，需要对不是堆中的顺序取最小等，而维护堆则会很方便。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1595837336,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":205982,"user_name":"Geek_ty","can_delete":false,"product_type":"c1","uid":1587280,"ip_address":"","ucode":"F8178B6B09D628","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epZhOmpZpicOzalVU7kibd59dMJc25N9cfGu9icBAIUPzYNYDedtzlYHZBiazaYiadgqvlotrjM4CA6KOQ/132","comment_is_top":false,"comment_ctime":1586767497,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5881734793","product_id":100017301,"comment_content":"你好，我想请教一下关于最小堆做高性能定时器的问题，为什么在tcp中没有使用呢？当每秒需要添加百万级定时器的时候，是不是最小堆有性能瓶颈？","like_count":1},{"had_liked":false,"id":190897,"user_name":"静心","can_delete":false,"product_type":"c1","uid":1335457,"ip_address":"","ucode":"EB264FA6519FDA","user_header":"https://static001.geekbang.org/account/avatar/00/14/60/a1/8f003697.jpg","comment_is_top":false,"comment_ctime":1584706832,"is_pvip":true,"discussion_count":0,"race_medal":5,"score":"5879674128","product_id":100017301,"comment_content":"关于10 亿个搜索关键词的日志文件，获取Tok 10关键热词的问题。<br>如果采用哈希后同10取模分成10个文件的做法，是不是有可能会造成某个文件过大？","like_count":1},{"had_liked":false,"id":169035,"user_name":"尜尜人物","can_delete":false,"product_type":"c1","uid":1551325,"ip_address":"","ucode":"81F926DA5BA72C","user_header":"https://static001.geekbang.org/account/avatar/00/17/ab/dd/173953f7.jpg","comment_is_top":false,"comment_ctime":1578246323,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5873213619","product_id":100017301,"comment_content":"这里就可以用到优先级队列，也可以说是堆。我们将从小文件中取出来的字符串放入到小顶堆中，那堆顶的元素，也就是优先级队列队首的元素，就是最小的字符串。我们将这个字符串放入到大文件中，并将其从堆中删除。然后再从小文件中取出下一个字符串，放入到堆中。循环这个过程，就可以将 100 个小文件中的数据依次放入到大文件中。<br>----<br>这段话有一句“然后再从小文件中取出下一个字符串，放入到堆中”改成“然后再从取出的堆顶元素所在的小文件中取出下一个字符串，放入到堆中”会更好理解。","like_count":1},{"had_liked":false,"id":116049,"user_name":"10^100个邱怡霖","can_delete":false,"product_type":"c1","uid":1517246,"ip_address":"","ucode":"414414618FA93A","user_header":"https://static001.geekbang.org/account/avatar/00/17/26/be/c7249aea.jpg","comment_is_top":false,"comment_ctime":1563778807,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5858746103","product_id":100017301,"comment_content":"top k的题目 leetcoed215","like_count":1},{"had_liked":false,"id":98872,"user_name":"Geek_596356","can_delete":false,"product_type":"c1","uid":1532047,"ip_address":"","ucode":"E74326916B3878","user_header":"","comment_is_top":false,"comment_ctime":1559111184,"is_pvip":false,"replies":[{"id":"35627","content":"是的","user_name":"作者回复","user_name_real":"王争","uid":"1190123","ctime":1559176076,"ip_address":"","comment_id":98872,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5854078480","product_id":100017301,"comment_content":"如果使用散列表，出现散列冲突后，怎么办？再借助链表和红黑树吗？","like_count":1,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":451874,"discussion_content":"是的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1559176076,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":80968,"user_name":"好运连连","can_delete":false,"product_type":"c1","uid":1105081,"ip_address":"","ucode":"2A339281321E2A","user_header":"https://static001.geekbang.org/account/avatar/00/10/dc/b9/946b181d.jpg","comment_is_top":false,"comment_ctime":1553765805,"is_pvip":false,"replies":[{"id":"29410","content":"因为数据是动态的","user_name":"作者回复","user_name_real":"王争","uid":"1190123","ctime":1553769404,"ip_address":"","comment_id":80968,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5848733101","product_id":100017301,"comment_content":"老师，看得有点迷糊，topk问题，为什么不用快排呢？是因为动态数据这一原因吗？根本原因是什么呢？","like_count":1,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":445031,"discussion_content":"因为数据是动态的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1553769404,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":74161,"user_name":"鱼星草","can_delete":false,"product_type":"c1","uid":1123975,"ip_address":"","ucode":"066E61BA6BE4EF","user_header":"https://static001.geekbang.org/account/avatar/00/11/26/87/31c785a3.jpg","comment_is_top":false,"comment_ctime":1552121929,"is_pvip":false,"replies":[{"id":"27368","content":"😓 你就不能自己动动脑子啊","user_name":"作者回复","user_name_real":"gg","uid":"1190123","ctime":1552357793,"ip_address":"","comment_id":74161,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5847089225","product_id":100017301,"comment_content":"求topK这块有问题，维护一个大小为k的小顶堆，但是你的描述中连第一个堆顶元素是什么都没有描述清楚，初始的K个元素到底是那几个？怎么计算？","like_count":1,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":442472,"discussion_content":"😓 你就不能自己动动脑子啊","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1552357793,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":47940,"user_name":"蚂蚁内推+v","can_delete":false,"product_type":"c1","uid":1050508,"ip_address":"","ucode":"24B10AEE54B3FD","user_header":"https://static001.geekbang.org/account/avatar/00/10/07/8c/0d886dcc.jpg","comment_is_top":false,"comment_ctime":1544261629,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5839228925","product_id":100017301,"comment_content":"Netty底层的ScheduledTaskQueue就是一个优先队列应用在定时器的例子","like_count":1},{"had_liked":false,"id":44845,"user_name":"张勇","can_delete":false,"product_type":"c1","uid":1234450,"ip_address":"","ucode":"B08F8E7F802D81","user_header":"https://static001.geekbang.org/account/avatar/00/12/d6/12/6a5e6841.jpg","comment_is_top":false,"comment_ctime":1543499490,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5838466786","product_id":100017301,"comment_content":"老师，你是否也能开一些大型的课？不仅限于这种方式，线上实操课","like_count":1},{"had_liked":false,"id":44250,"user_name":"邵靖隆","can_delete":false,"product_type":"c1","uid":1237861,"ip_address":"","ucode":"ECD90C45A9C2E4","user_header":"https://static001.geekbang.org/account/avatar/00/12/e3/65/f3553a48.jpg","comment_is_top":false,"comment_ctime":1543394462,"is_pvip":false,"replies":[{"id":"15768","content":"这个插入排序的部分可以不用计算时间复杂度 比较规模很小","user_name":"作者回复","user_name_real":"gg","uid":"1190123","ctime":1543403475,"ip_address":"","comment_id":44250,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5838361758","product_id":100017301,"comment_content":"老师，我问一个关于排序的问题<br>如果在归并排序中，当切分出的子列长度小于10时不再对其继续递归归并排序，而改用插入排序。<br>这样的组合算法，其时间复杂度如何计算？","like_count":1,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":430693,"discussion_content":"这个插入排序的部分可以不用计算时间复杂度 比较规模很小","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1543403475,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1359701,"avatar":"https://static001.geekbang.org/account/avatar/00/14/bf/55/198c6104.jpg","nickname":"小伟","note":"","ucode":"124953423491E2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":173619,"discussion_content":"这个想法不错，可以参考timsort，工业级别的稳定排序算法，不同场景用不同的排序算法。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1581860976,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":44237,"user_name":"夏天","can_delete":false,"product_type":"c1","uid":1067966,"ip_address":"","ucode":"86D4EF12621E2F","user_header":"https://static001.geekbang.org/account/avatar/00/10/4b/be/f8768be4.jpg","comment_is_top":false,"comment_ctime":1543391683,"is_pvip":false,"replies":[{"id":"15769","content":"比如？","user_name":"作者回复","user_name_real":"gg","uid":"1190123","ctime":1543403487,"ip_address":"","comment_id":44237,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5838358979","product_id":100017301,"comment_content":"感觉用堆能解决的问题,换成其他数据结构也能解决","like_count":1,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":430688,"discussion_content":"比如？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1543403487,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":44215,"user_name":"꧁꫞꯭高꯭峰꯭꫞꧂","can_delete":false,"product_type":"c1","uid":1235060,"ip_address":"","ucode":"27A29D5F949A0B","user_header":"https://static001.geekbang.org/account/avatar/00/12/d8/74/399c5d99.jpg","comment_is_top":false,"comment_ctime":1543386178,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5838353474","product_id":100017301,"comment_content":"静态数据查找k大的数据 java实现<br>public class HeapTest {<br>\tpublic static void main(String[] args) {<br>\t\tInteger[] target = { 2, 3, 5, 8, 11, 22, 97, 98, 33, 44, 55, 66, 77, 88, 99, 100, 12, 13, 14, 15, 16, 17, 18, 19, 20 };<br>\t\tQueue&lt;Integer&gt; queue = new PriorityQueue&lt;Integer&gt;(5);<br>\t\tqueue.addAll(Arrays.asList(1, 2, 3, 4, 5));<br>\t\tfor (Integer num : target) {<br>\t\t\tInteger top = queue.peek();<br>\t\t\tif (num &gt;= top) {<br>\t\t\t\tqueue.poll();<br>\t\t\t\tqueue.add(num);<br>\t\t\t}<br>\t\t}<br><br>\t\tfor (Integer integer : queue) {<br>\t\t\tSystem.out.println(integer);<br>\t\t}<br>\t}<br><br>}","like_count":1},{"had_liked":false,"id":44078,"user_name":"蒋礼锐","can_delete":false,"product_type":"c1","uid":1248897,"ip_address":"","ucode":"25E042066A1427","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/gM1ibHKPkrs5DSIp4aIuQ9jnYtNicc2tdG244PbaSvKw5jO9DWrhWghcVM1Y5Iq2QSpzLBUeWZQLhARst51z35mA/132","comment_is_top":false,"comment_ctime":1543367556,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"5838334852","product_id":100017301,"comment_content":"需要一个散列表维护新闻对象，每个新闻对象至少需要维护下列几个字段，1 新闻摘要 2 新闻阅读次数(如果内存有限制分片处理) 3 新闻刷新时间(如果另外有定时器也可不用这个字段)。4 新闻链接<br><br>动态维护一个包含10个对象的小顶堆，每次有新闻被浏览时进行，去散列表中找到新闻对应的阅读次数，如果大于小顶堆的堆顶元素，则将堆顶元素删除，并重新堆化。复杂度为log10<br><br>1小时刷新就可以对比堆顶元素的刷新时间与当前时间间隔。<br><br>每1小时获取top10时，将堆排序后输出，复杂度10log10，<br><br>但是有个疑问，因为阅读新闻的人很多，如果同一时间有大量的人在阅读不同的新闻，如何保证数据的一致性呢？也就是这个堆和那个hash表对每个用户来说都一样。想到一种办法是用队列储存同一时间的新闻请求，然后再一个一个事务操作。我是前端，对数据储存这一块不太熟，还请老师或社友指正。","like_count":1,"discussions":[{"author":{"id":1359701,"avatar":"https://static001.geekbang.org/account/avatar/00/14/bf/55/198c6104.jpg","nickname":"小伟","note":"","ucode":"124953423491E2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":173633,"discussion_content":"新闻的topK不需要强一致性，10分钟一次就足够了，每次权量统计一次。如果需要秒刷的，那用实时流计算吧。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1581861195,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":44034,"user_name":"行者","can_delete":false,"product_type":"c1","uid":1063734,"ip_address":"","ucode":"EA31201A7C5AE1","user_header":"https://static001.geekbang.org/account/avatar/00/10/3b/36/2d61e080.jpg","comment_is_top":false,"comment_ctime":1543365884,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"5838333180","product_id":100017301,"comment_content":"针对这个动态点击top 10问题，如果继续仅仅统计top 10是有问题的，因为可能当前的top 11在接下来的时间内突然变为了热搜；所以要多统计多一点 top50 或 top100；然后更隔1小时统计增量日志，更新top n，然后在获取最新的top 10。","like_count":1,"discussions":[{"author":{"id":1359701,"avatar":"https://static001.geekbang.org/account/avatar/00/14/bf/55/198c6104.jpg","nickname":"小伟","note":"","ucode":"124953423491E2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":173696,"discussion_content":"如果某个新闻每次都排100+，那么每次都不会进你的排名。但12小时后，累计点击量可能会进top10，比如前top100都变化不大，那这个统计就不准确。\n除非第一次保留全量统计结果，后面再增量累计，这样最终top10结果才准确。\n当然，新闻的时效性强，大概率不会出现上述情况，且新闻top10的准确性需求也不高，故你的做法在计算资源不足或top10功能优先级不高时也是可行的。👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1581862582,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":359034,"user_name":"111","can_delete":false,"product_type":"c1","uid":3109487,"ip_address":"北京","ucode":"D6E8E83A118A3E","user_header":"https://static001.geekbang.org/account/avatar/00/2f/72/6f/44c10658.jpg","comment_is_top":false,"comment_ctime":1665192801,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1665192801","product_id":100017301,"comment_content":"总结：<br>关于堆的应用，优先级队列<br><br>思考：<br>1. 使用可持续的hash将关键词进行分片<br>2. 每次新的点击量进行分片存储，同时每个文件建立一个小顶堆记录前10的数据，每一次新的点击量出现就更新相应文件的小顶堆<br>3. 如果小顶堆有更新，一小时后就将所有小顶堆拿来一起比较合并成一个10容量小顶堆","like_count":0},{"had_liked":false,"id":357280,"user_name":"creasylai19","can_delete":false,"product_type":"c1","uid":1128420,"ip_address":"广东","ucode":"F9B04060FCFD3F","user_header":"https://static001.geekbang.org/account/avatar/00/11/37/e4/5d7a32c6.jpg","comment_is_top":false,"comment_ctime":1663131475,"is_pvip":false,"discussion_count":0,"race_medal":1,"score":"1663131475","product_id":100017301,"comment_content":"课后思考题挺适合做系统设计题的。因为有很多不明确的，都是语言和面试官沟通确认的。比如数据量，比如存储系统……最后才是算法","like_count":0},{"had_liked":false,"id":356581,"user_name":"TheTingTings","can_delete":false,"product_type":"c1","uid":1245528,"ip_address":"四川","ucode":"729CCE441856F5","user_header":"https://static001.geekbang.org/account/avatar/00/13/01/58/1788a7e6.jpg","comment_is_top":false,"comment_ctime":1662437188,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1662437188","product_id":100017301,"comment_content":"如果hash算法不够散列，导致10亿数据另外9亿数据（都为不相同的key）都有冲突，都分布到文件0中，剩余1亿分布到文件1...9。<br>这样，当计算文件0时，用hashMap去存key，9亿不同的key，50B*9亿=40G，存key都会撑爆内存，导致无法统计 key:频次 。<br>所以这里的关键是不是要hash足够散列？","like_count":0},{"had_liked":false,"id":354796,"user_name":"Allan","can_delete":false,"product_type":"c1","uid":1310388,"ip_address":"北京","ucode":"8DA4DBECC2C45C","user_header":"https://static001.geekbang.org/account/avatar/00/13/fe/b4/295338e7.jpg","comment_is_top":false,"comment_ctime":1660791771,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1660791771","product_id":100017301,"comment_content":"课后题：这个访问量很大的网站，因为量很大，而且是1小时刷一次，所以没必要实时计算了。<br>思路1：将网站信息存入数据仓库，通过hql进行分析计算出top10的摘要就可以了，然后定时任务一小时刷一下，然后数据发送到前端。这样就没用用到我们的堆结构。<br>思路2：java后台也是一个定时器，因为量很大，所以我们将接过来的数据根据hash分别分配到n个文件中，然后计算的时候也是跟老师说的方式，计算每个文件的topk，然后n个topk再比较计算出最后的topk的思路。","like_count":0},{"had_liked":false,"id":337814,"user_name":"Today","can_delete":false,"product_type":"c1","uid":1235000,"ip_address":"","ucode":"4FA397F0BD8C6E","user_header":"https://static001.geekbang.org/account/avatar/00/12/d8/38/41027bda.jpg","comment_is_top":false,"comment_ctime":1647075501,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1647075501","product_id":100017301,"comment_content":"这一节学习到了不少厉害的方法：<br>1. 海量数据哈希分片，减少计算内存<br>2. 使用哈希表进行数据去重<br>3. topk问题直接维护一个k位大小的小顶堆，能够动态获取topk<br>4. 中位数或者百分比分隔问题，直接建立对应的小，大顶堆，分别维护即可<br>5. 合并k个有序数组使用小顶堆类似归并排序处理<br>6. 复习了以前二分查找，快排，哈希函数的知识，堆的最大好处是动态数据的有序处理很强","like_count":0},{"had_liked":false,"id":334348,"user_name":"陈阳","can_delete":false,"product_type":"c1","uid":2653715,"ip_address":"","ucode":"C8E676C967D23A","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKib3vNM6TPT1umvR3TictnLurJPKuQq4iblH5upgBB3kHL9hoN3Pgh3MaR2rjz6fWgMiaDpicd8R5wsAQ/132","comment_is_top":false,"comment_ctime":1644895541,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1644895541","product_id":100017301,"comment_content":"topk中 如果动态集合里面的数据值是有变动的，而不是添加的， 这个时候是不是就不太好用顶堆的来解决了","like_count":0},{"had_liked":false,"id":324477,"user_name":"dong","can_delete":false,"product_type":"c1","uid":1027169,"ip_address":"","ucode":"B3671E4839EB08","user_header":"https://static001.geekbang.org/account/avatar/00/0f/ac/61/ae2ce8be.jpg","comment_is_top":false,"comment_ctime":1638451713,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1638451713","product_id":100017301,"comment_content":"对 10 亿个关键词用 hash 分片成 10 份文件，则相同的关键词会被分到同一个文件，不同文件不会存在相同的关键词，是否可以用同一个小顶堆处理这10个分片？就不用对10个分片分别用堆求 top10 再比较这 100 个？","like_count":0},{"had_liked":false,"id":322616,"user_name":"贾飞雨","can_delete":false,"product_type":"c1","uid":1321770,"ip_address":"","ucode":"CBD8FD331B4173","user_header":"https://static001.geekbang.org/account/avatar/00/14/2b/2a/63af9b35.jpg","comment_is_top":false,"comment_ctime":1637501570,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1637501570","product_id":100017301,"comment_content":"学习完好友收获啊!","like_count":0},{"had_liked":false,"id":312943,"user_name":"🌴林子洛","can_delete":false,"product_type":"c1","uid":2744724,"ip_address":"","ucode":"DE0C88D16AADF8","user_header":"https://static001.geekbang.org/account/avatar/00/29/e1/94/2c5e62d1.jpg","comment_is_top":false,"comment_ctime":1632133802,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1632133802","product_id":100017301,"comment_content":"第二次阅读，发现自己以前真是囫囵吞枣。。每次复习都是新的感受，好好加油<br>","like_count":0},{"had_liked":false,"id":310949,"user_name":"Miki","can_delete":false,"product_type":"c1","uid":1712219,"ip_address":"","ucode":"09C0E4E0641CDF","user_header":"https://static001.geekbang.org/account/avatar/00/1a/20/5b/05516921.jpg","comment_is_top":false,"comment_ctime":1630998697,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1630998697","product_id":100017301,"comment_content":"求中位数算法用什么数据结构呢？用数组得不断扩容","like_count":0},{"had_liked":false,"id":306128,"user_name":"promise。","can_delete":false,"product_type":"c1","uid":1761643,"ip_address":"","ucode":"DD1289EBF69607","user_header":"https://static001.geekbang.org/account/avatar/00/1a/e1/6b/8792d601.jpg","comment_is_top":false,"comment_ctime":1628394365,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1628394365","product_id":100017301,"comment_content":"合并有序的小文件这个题目，每个小文件里面的数据元素允许重复吗 比如第一个文件[1,3,5,7,9],第二个文件[2,3,5,7,9]","like_count":0},{"had_liked":false,"id":305235,"user_name":"Geek_842f07","can_delete":false,"product_type":"c1","uid":2698987,"ip_address":"","ucode":"ED772AF755FE7E","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/WP4Ge8ABcINFkccKaNYKibicFnI0JAoojBBAUGrichNeRAgzm5RGbHG7GqYrFX3ELEzenuEbicQHJy2HZ72RxSOuMA/132","comment_is_top":false,"comment_ctime":1627888985,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1627888985","product_id":100017301,"comment_content":"1. 合并有序小文件，这个问题如果到最后小文件为空了，要怎么处理呢？","like_count":0},{"had_liked":false,"id":305231,"user_name":"Geek_842f07","can_delete":false,"product_type":"c1","uid":2698987,"ip_address":"","ucode":"ED772AF755FE7E","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/WP4Ge8ABcINFkccKaNYKibicFnI0JAoojBBAUGrichNeRAgzm5RGbHG7GqYrFX3ELEzenuEbicQHJy2HZ72RxSOuMA/132","comment_is_top":false,"comment_ctime":1627887978,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1627887978","product_id":100017301,"comment_content":"问题和如何快速找到Top10最热门的搜索关键词类似，实现过程也类似，最后只需要每隔一个小时更新结果即可","like_count":0},{"had_liked":false,"id":300257,"user_name":"GeekTerry","can_delete":false,"product_type":"c1","uid":2611431,"ip_address":"","ucode":"7C05FA14D90FC4","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/guTSzEA3CV4YicMQlZEW4POWiaKtlDljrPzLY8dIESpicQBs9XfTu7dicz9THUm7InBf4NZNeLI3X4WHRxDKyjCkKw/132","comment_is_top":false,"comment_ctime":1625065555,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1625065555","product_id":100017301,"comment_content":"“我们针对每个包含 1 亿条搜索关键词的文件，利用散列表和堆，分别求出 Top 10，然后把这个 10 个 Top 10 放在一块，然后取这 100 个关键词中，出现次数最多的 10 个关键词，这就是这 10 亿数据中的 Top 10 最频繁的搜索关键词了。” <br><br>這段有點值得思考的地方：如果單詞 “xyz” 在每個文件都排名第 11 名，也許合併所有文件之後，“xyz” 的總排名可以擠進前十名","like_count":0},{"had_liked":false,"id":299361,"user_name":"Allan","can_delete":false,"product_type":"c1","uid":1310388,"ip_address":"","ucode":"8DA4DBECC2C45C","user_header":"https://static001.geekbang.org/account/avatar/00/13/fe/b4/295338e7.jpg","comment_is_top":false,"comment_ctime":1624593795,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1624593795","product_id":100017301,"comment_content":"课后题：是当日的top10？还是需要加上历史的top10？肯定是下架的摘要就不需要了。1、如果今日，即使访问量很大，一个新网网站能有多少个url，300算多吧。那么300url，放入内容也不是很大。直接用大顶堆存入300个，没访问一次就给这个url+1即可。最后一小时一次输出top10就可以了。2、如果历史，那么我们每天需要统计一下历史的结果，也就是离线+实时。实时的数据完全可以写入es等一些方便统计的存储，到了一个小时，我们去触发一下任务，统计一下，然后返回给前端展示就可以了。","like_count":0},{"had_liked":false,"id":297877,"user_name":"海崖","can_delete":false,"product_type":"c1","uid":2552745,"ip_address":"","ucode":"9D42E0B0D30A56","user_header":"https://static001.geekbang.org/account/avatar/00/26/f3/a9/bb9d8450.jpg","comment_is_top":false,"comment_ctime":1623829461,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1623829461","product_id":100017301,"comment_content":"叮~打卡","like_count":0},{"had_liked":false,"id":293983,"user_name":"ding","can_delete":false,"product_type":"c1","uid":1014401,"ip_address":"","ucode":"54AF950B3CA740","user_header":"https://static001.geekbang.org/account/avatar/00/0f/7a/81/69874318.jpg","comment_is_top":false,"comment_ctime":1621668063,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1621668063","product_id":100017301,"comment_content":"“<br>我们针对每个包含 1 亿条搜索关键词的文件，利用散列表和堆，分别求出 Top 10，然后把这个 10 个 Top 10 放在一块，然后取这 100 个关键词中，出现次数最多的 10 个关键词，这就是这 10 亿数据中的 Top 10 最频繁的搜索关键词了。<br>”<br><br>为什么是10个top10呢？ 10个top5可以吗？","like_count":0},{"had_liked":false,"id":291535,"user_name":"Zzz~","can_delete":false,"product_type":"c1","uid":2422718,"ip_address":"","ucode":"83985BEE1DD49D","user_header":"https://static001.geekbang.org/account/avatar/00/24/f7/be/c6a2fd84.jpg","comment_is_top":false,"comment_ctime":1620352227,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1620352227","product_id":100017301,"comment_content":"求中位数的那一个一定要建两个堆么，建一个大顶堆不可以么，比如有11个，就建一个有6个数据的大顶堆，堆顶就是中位数，12个就取堆顶和第二大的数据","like_count":0},{"had_liked":false,"id":291316,"user_name":"双木公子","can_delete":false,"product_type":"c1","uid":1116567,"ip_address":"","ucode":"751885864D3AB7","user_header":"https://static001.geekbang.org/account/avatar/00/11/09/97/4314e2d8.jpg","comment_is_top":false,"comment_ctime":1620203431,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1620203431","product_id":100017301,"comment_content":"留言高赞的实现暂时只看了两个，后面有时间再补上吧，先刷刷后面的内容","like_count":0},{"had_liked":false,"id":290467,"user_name":"编号","can_delete":false,"product_type":"c1","uid":1037836,"ip_address":"","ucode":"1633A363592A1A","user_header":"https://static001.geekbang.org/account/avatar/00/0f/d6/0c/df0d5152.jpg","comment_is_top":false,"comment_ctime":1619577977,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1619577977","product_id":100017301,"comment_content":"“对这 10 亿个关键词分片之后，每个文件都只有 1 亿的关键词，去除掉重复的，可能就只有 1000 万个，每个关键词平均 50 个字节，所以总的大小就是 500MB”，总觉得怪怪的。<br>1. 如果一开始就能估算去重后的总容量，那最开始就不应该分文件存储吧。如果不能估算去重后的总容量，那不应该分机器来存吗<br>2. 如果用多个文件来存储，那每次从10亿个数据中拿出一个关键词，计算hash，分派到对应文件，更新关键词的查询数量时，都需要把对应文件重新读取进内存，更新散列表，重新写入文件，这样岂不是贼慢","like_count":0},{"had_liked":false,"id":288131,"user_name":"守拙","can_delete":false,"product_type":"c1","uid":1738326,"ip_address":"","ucode":"F594B2DA3F6D4F","user_header":"https://static001.geekbang.org/account/avatar/00/1a/86/56/509535da.jpg","comment_is_top":false,"comment_ctime":1618313572,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1618313572","product_id":100017301,"comment_content":"100个小文件 优先队列的例子, 直接把100个小文件全扔到大文件里, 然后对大文件执行堆排不就可以了吗.","like_count":0},{"had_liked":false,"id":288084,"user_name":"帝江","can_delete":false,"product_type":"c1","uid":1590610,"ip_address":"","ucode":"93CBA4E4D05DA5","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/B9vSOjMc2a86kYA8R5yDkVdFiaj2JeBZ1PuI9oUKhbnvuZwuibdUam6FTcGzDaiaFdk2GWJveUGhfCVpv4KaOdicoQ/132","comment_is_top":false,"comment_ctime":1618293558,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1618293558","product_id":100017301,"comment_content":"有点体悟:<br>堆是拆分成多个的有序队列.拆分以后排序压力小了.利用了分治思想.","like_count":0},{"had_liked":false,"id":287001,"user_name":"椰子Tyshawn","can_delete":false,"product_type":"c1","uid":1241147,"ip_address":"","ucode":"137F129D2AB3FC","user_header":"https://static001.geekbang.org/account/avatar/00/12/f0/3b/f5c4cd81.jpg","comment_is_top":false,"comment_ctime":1617721247,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1617721247","product_id":100017301,"comment_content":"class MedianFinder {<br>    PriorityQueue&lt;Integer&gt; queue1;<br>    PriorityQueue&lt;Integer&gt; queue2;<br><br><br>    &#47;** initialize your data structure here. *&#47;<br>    public MedianFinder() {<br>        queue1 = new PriorityQueue&lt;&gt;((k1, k2) -&gt; k2 - k1);<br>        queue2 = new PriorityQueue&lt;&gt;();<br>    }<br><br>    public void addNum(int num) {<br>        queue1.add(num);<br><br>        int n = queue1.size()+queue2.size();<br>        if((n%2==0 &amp;&amp; queue1.size() &gt; n&#47;2) || (n%2!=0 &amp;&amp; queue1.size() &gt; n&#47;2+1)){<br>            queue2.add(queue1.poll());<br>        }<br>        <br>        if(!queue2.isEmpty() &amp;&amp; queue1.peek() &gt; queue2.peek()){<br>            queue1.add(queue2.poll());<br>            queue2.add(queue1.poll());<br>        }<br>    }<br><br>    public double findMedian() {<br>        int n = queue1.size() + queue2.size();<br>        if(n%2==0){<br>            return (queue1.peek()*1.0+queue2.peek()*1.0)&#47;2;<br>        }else{<br>            return queue1.peek();<br>        }<br>    }<br>}","like_count":0},{"had_liked":false,"id":285769,"user_name":"随风","can_delete":false,"product_type":"c1","uid":1476862,"ip_address":"","ucode":"037CE3554D8AB9","user_header":"https://static001.geekbang.org/account/avatar/00/16/88/fe/c18a85fe.jpg","comment_is_top":false,"comment_ctime":1617007019,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1617007019","product_id":100017301,"comment_content":"对这 10 亿个关键词分片之后，每个文件都只有 1 亿的关键词，去除掉重复的，可能就只有 1000 万个，每个关键词平均 50 个字节，所以总的大小就是 500MB。1GB 的内存完全可以放得下。这个不严谨吧，完全有可能两亿关键字都是相同的，那有个文件就包含两亿数据，按照50个字节算就是1g内存了。","like_count":0,"discussions":[{"author":{"id":1526355,"avatar":"https://static001.geekbang.org/account/avatar/00/17/4a/53/063f9d17.jpg","nickname":"moonfox","note":"","ucode":"902BFF40EFA9FA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":363006,"discussion_content":"不是把文件放入内存，而是去重后，放入内存。计算下个文件时，把占用的内存清空，在放入这个文件去重后的内容。读取文件不用一起行载入，可以按行按批次多次载入","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617091547,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":285488,"user_name":"a解code","can_delete":false,"product_type":"c1","uid":1850206,"ip_address":"","ucode":"A9DA207611BF78","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/AyUEibEbicwMib9XSYFxDd13rIj5xMLCAwlEogd1c2bwW7Dwof0AQkRaSS5FrEK0Cg0s36ZnVZK2GW37WlVjzbydQ/132","comment_is_top":false,"comment_ctime":1616837106,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1616837106","product_id":100017301,"comment_content":"作者，你好，看了利用堆来解决中位数的解决方案，我试想着把这个思路用来解决大数据集下的中位数求解，发现分布式思路是解不通的，而网上的一般解法是 将数据进行样本分析，分桶，将数据机不断缩小，获得中位数，不知道 你的看法是什么，求分享，谢谢","like_count":0},{"had_liked":false,"id":282244,"user_name":"imfan","can_delete":false,"product_type":"c1","uid":1350883,"ip_address":"","ucode":"5D7915497BF072","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKUxOIyH4hiaTCwEiazeWrEP6W5fOibrDCbmS9VdPWg95Sm1MnkI4rtMbq1OqlU9QCfa6icichgpxDicrOA/132","comment_is_top":false,"comment_ctime":1615172804,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1615172804","product_id":100017301,"comment_content":"求中位数那个题  为什么不只维护一个大顶堆，然后在维护一个 所有数量，当大顶堆数据超过数量限制了，就移除 n个堆顶元素直至符合数量限制<br>这样不就快很多了吗？","like_count":0,"discussions":[{"author":{"id":1132178,"avatar":"https://static001.geekbang.org/account/avatar/00/11/46/92/28d929fc.jpg","nickname":"Zero霖","note":"","ucode":"36A11EB2F4E570","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":580651,"discussion_content":"因为动态数据，新插入数据，会引起上1次中位数位置变化，这时就涉及数据移动","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1658305292,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":280856,"user_name":"罗耀龙@坐忘","can_delete":false,"product_type":"c1","uid":1917663,"ip_address":"","ucode":"3CEA258DE7F3C7","user_header":"https://static001.geekbang.org/account/avatar/00/1d/42/df/a034455d.jpg","comment_is_top":false,"comment_ctime":1614426221,"is_pvip":true,"discussion_count":0,"race_medal":5,"score":"1614426221","product_id":100017301,"comment_content":"茶艺师学编程<br><br>思考题<br>这应该能套用使用小顶堆处理topk问题。时间复杂度是O（nlog K）。","like_count":0},{"had_liked":false,"id":278939,"user_name":"Geek_676ef6","can_delete":false,"product_type":"c1","uid":1237182,"ip_address":"","ucode":"4DF557B0818E21","user_header":"https://static001.geekbang.org/account/avatar/00/12/e0/be/09173bc8.jpg","comment_is_top":false,"comment_ctime":1613471614,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1613471614","product_id":100017301,"comment_content":"对于更新频率是t-1hour可以像老师说的处理搜索关键字那样散列计数后用小顶堆求topk。<br>如果对实时性要求高的只能流式统计pv吧","like_count":0},{"had_liked":false,"id":277997,"user_name":"muse","can_delete":false,"product_type":"c1","uid":2365071,"ip_address":"","ucode":"43B0C82639E39F","user_header":"https://static001.geekbang.org/account/avatar/00/24/16/8f/c1baee96.jpg","comment_is_top":false,"comment_ctime":1612694762,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1612694762","product_id":100017301,"comment_content":"文中“中位数，顾名思义，就是处在中间位置的那个数。如果数据的个数是奇数，把数据从小到大排列，那第 n&#47;2​+1 个数据就是中位数（注意：假设数据是从 0 开始编号的）”这处是不是笔误了？<br>如果数据从0编号，且个数是奇数，那么中位数应该是n&#47;2吧，从1编号才是n&#47;2+1","like_count":0},{"had_liked":false,"id":277612,"user_name":"king","can_delete":false,"product_type":"c1","uid":1100439,"ip_address":"","ucode":"FFC090D0EF1F80","user_header":"https://static001.geekbang.org/account/avatar/00/10/ca/97/5042c207.jpg","comment_is_top":false,"comment_ctime":1612491508,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1612491508","product_id":100017301,"comment_content":"课后思考题，需求不明确，top10是总点击量呢，还是前一个小时的点击量呢？还是每个小时都统计一次这个小时内的呢？堆在这里我是觉得不是很好统计，看了评论很多偏向理解为每个小时内都统计一次，但基本都没有处理重复的情况，比如上次上榜了，这个小时内它的点击量又是前10，那么堆里面有两个数据都是指向同一个文章摘要了，虽然可能他们点击数不一样","like_count":0},{"had_liked":false,"id":274655,"user_name":"Allan","can_delete":false,"product_type":"c1","uid":1310388,"ip_address":"","ucode":"8DA4DBECC2C45C","user_header":"https://static001.geekbang.org/account/avatar/00/13/fe/b4/295338e7.jpg","comment_is_top":false,"comment_ctime":1611112911,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1611112911","product_id":100017301,"comment_content":"本来想简单写一下，看到一楼的留言，让我感触很深。认真的人真的很帅！！","like_count":0},{"had_liked":false,"id":273795,"user_name":"Andrew.Fang","can_delete":false,"product_type":"c1","uid":2359194,"ip_address":"","ucode":"1D754BBFC223F4","user_header":"https://static001.geekbang.org/account/avatar/00/23/ff/9a/f7d84a69.jpg","comment_is_top":false,"comment_ctime":1610680211,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1610680211","product_id":100017301,"comment_content":"课后思考有答案吗？点击量排名是一天的累计还是一个小时的累计，还是一月的累计。<br>这个和网站怎么存储有关吧。如果网站服务器能在内存中处理那么大的数据量可以如下处理。如果文件存储怎么存储的。知道这些才能决定后续怎么处理。题设太少，只能知己假设几种情况，分别应对。<br>假设可以全部内存处理，使用Map存储摘要(或者对应的URL,没说清楚可不可以)和访问次数，每次访问对应摘要的访问次数+1：<br>0.初始时进行一次全局的扫描，使用小根堆找到TOP10，得到根值level<br>1.之后每次访问当有次数增加之前没超过level，增加之后超过的记录到一个摘要队列keyqueue中，从而得到一个不重复的摘要队列<br>2.当到达一个小时时，只需遍历摘要队列keyqueue，依次替换堆根再调整，就能得到新的TOP10<br>以上达到访问和计算TOP10时的最佳计算平衡","like_count":0},{"had_liked":false,"id":271022,"user_name":"陌.寒哲","can_delete":false,"product_type":"c1","uid":1147711,"ip_address":"","ucode":"B7079FF211D712","user_header":"https://static001.geekbang.org/account/avatar/00/11/83/3f/bc2ea80d.jpg","comment_is_top":false,"comment_ctime":1609373906,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1609373906","product_id":100017301,"comment_content":"十亿关键字取top10的问题，如果按文中的思路做完，得到了10个使用最多的hashcode，但是hash是不可逆的。这解决方案还是没完成任务呢，得到10个hashcode并不知道到底哪10个关键词是热搜的","like_count":0},{"had_liked":false,"id":269179,"user_name":"Adam","can_delete":false,"product_type":"c1","uid":1517838,"ip_address":"","ucode":"965DCD693E752B","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK36t2flfxhzKygfLfdIHbK99M9D9w3v3bwAHUibJSFAs1ibswf7hbhkqL321k5SUjfiaWkkHeRBlibNA/132","comment_is_top":false,"comment_ctime":1608549095,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1608549095","product_id":100017301,"comment_content":"top问题 基本上思路就是围绕 小根堆 大根堆 来做。有时候需要结合hash表来一起存储数据的状态","like_count":0},{"had_liked":false,"id":267167,"user_name":"X  W  z","can_delete":false,"product_type":"c1","uid":1235441,"ip_address":"","ucode":"915BA1CF6090F7","user_header":"https://static001.geekbang.org/account/avatar/00/12/d9/f1/a00711f8.jpg","comment_is_top":false,"comment_ctime":1607615178,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1607615178","product_id":100017301,"comment_content":"讨论题：新闻点击率top10<br>1、数据库存储，表结构：id ，新闻名，点击量，…<br>2、每次点击，对应点击量+1<br>3、定时器每隔1h执行，将表内容分隔成m份，每一份用一个线程用小顶堆计算top10。<br>4、将m个top10整合<br>注意问题：<br>1、表内容分隔m份，select id，times limit 1000 offset 1000 获取。<br>疑问：数据库 这种语法的性能如何？待验证<br>2、事务隔离，防止查询到下一小时的表内容；可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。","like_count":0},{"had_liked":false,"id":266462,"user_name":"推车的老王","can_delete":false,"product_type":"c1","uid":1832751,"ip_address":"","ucode":"568A2E436CCFBE","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/HrblKDLM0uaYNgJo3ZbG3qzgvpq15vRDKadOkvktJuI6sWf4kUymXXXCM4ibicLcek22qAkd5oysSEVCTZuZJXGA/132","comment_is_top":false,"comment_ctime":1607346782,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1607346782","product_id":100017301,"comment_content":"es根据时间进行精确到小时分index，然后实时查，或者用redis的zset根据时间精确到小时分key，然后实时查。","like_count":0},{"had_liked":false,"id":260789,"user_name":"Joker","can_delete":false,"product_type":"c1","uid":1241567,"ip_address":"","ucode":"C42E11098E1B38","user_header":"https://static001.geekbang.org/account/avatar/00/12/f1/df/8ba04bec.jpg","comment_is_top":false,"comment_ctime":1605106800,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1605106800","product_id":100017301,"comment_content":"针对合并有序小文件的应用，有点不太明白，有人能说下详细的过程吗？从建堆到删除元素和插入元素的完成过程","like_count":0},{"had_liked":false,"id":260233,"user_name":"橙子橙","can_delete":false,"product_type":"c1","uid":2249227,"ip_address":"","ucode":"CD51367A14D955","user_header":"https://static001.geekbang.org/account/avatar/00/22/52/0b/50bf0f05.jpg","comment_is_top":false,"comment_ctime":1604966940,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1604966940","product_id":100017301,"comment_content":"topk: &quot;以一直都维护一个 K 大小的小顶堆，当有数据被添加到集合中时，我们就拿它与堆顶的元素对比。如果比堆顶元素大，我们就把堆顶元素删除，并且将这个元素插入到堆中&quot;<br><br>这里发现比堆顶大, 可以直接将该元素替换到堆顶, 执行一次heapify操作吧? <br>不用先删除堆顶, 再插入, 这样需要两次heapfiy操作.","like_count":0},{"had_liked":false,"id":259855,"user_name":"HelloWorld","can_delete":false,"product_type":"c1","uid":1704828,"ip_address":"","ucode":"5F01EAF21BA301","user_header":"https://static001.geekbang.org/account/avatar/00/1a/03/7c/87cc51c7.jpg","comment_is_top":false,"comment_ctime":1604857818,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1604857818","product_id":100017301,"comment_content":"维护一个k大小的小顶堆，和维护一个k大小的有序数组有什么区别？一定要用堆结构？王老师能否解答下？","like_count":0},{"had_liked":false,"id":258918,"user_name":"攻城狮","can_delete":false,"product_type":"c1","uid":1197444,"ip_address":"","ucode":"7D2C2836052C4C","user_header":"https://static001.geekbang.org/account/avatar/00/12/45/84/4b309ba9.jpg","comment_is_top":false,"comment_ctime":1604580846,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1604580846","product_id":100017301,"comment_content":"感觉延时队列也是优先级队列的应用","like_count":0},{"had_liked":false,"id":258538,"user_name":"拉布拉多","can_delete":false,"product_type":"c1","uid":1204353,"ip_address":"","ucode":"637A88D9F29F57","user_header":"https://static001.geekbang.org/account/avatar/00/12/60/81/eaf6d0ac.jpg","comment_is_top":false,"comment_ctime":1604476520,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1604476520","product_id":100017301,"comment_content":"怎么去掉重复的关键词？用Linux命令 uniq吗？那linux 这个命令对1亿个记录，或者10亿的记录这么大的文件是怎么实现去重的？也得一次性读进内存吧？那问题又来了。","like_count":0},{"had_liked":false,"id":252750,"user_name":"youyou.L","can_delete":false,"product_type":"c1","uid":1796438,"ip_address":"","ucode":"B3DB0D0700EEAC","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/zlWt0lPDicdib5BTUbuwA3wLLUuejtZ5icGu3DHMBPd6PicXOdhZ3zYFts8VkXjjyQuxzUJas2w5OTmx3icWKiaZM1Vg/132","comment_is_top":false,"comment_ctime":1602474208,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1602474208","product_id":100017301,"comment_content":"思考题：<br>实现方式：记录每个新闻访问的日志，通过定时任务，每小时计算一次top10访问量的新闻，然后更新到网站首页的banner上。<br>计算top10访问量的方法：虽然访问量非常大，但是新闻数量并不会非常大，正常来说每天更新100个新闻已经是很多了，一年下来也就30000多条新闻，所以可以直接使用一个散列表来存储全部新闻的访问频次，key为新闻id，value为访问频次。接着遍历散列表，每次与只包含10个元素的小顶堆的堆顶元素进行比较，若比堆顶元素大，则插入该元素，并且删除堆顶元素，直到遍历完整个hash表，最后把小顶堆的新闻id更新到首页的banner上。<br>为什么不用动态更新的方法，如果使用动态更新，主要有两个问题，一个是并发更新堆的线程安全问题，另一个是首页banner切换的问题。由于访问量非常大，每个网站被访问时都要先去更新散列表上的频率次数，这里要使用锁来解决线程安全的问题，性能下架，然后再与堆顶元素比较，更新堆，更新堆也需要锁，整体性能并不好，导致新闻访问体验下降。第二个问题是，仍然需要定时任务去更新网站首页的banner。<br><br>","like_count":0},{"had_liked":false,"id":251634,"user_name":"前人种树","can_delete":false,"product_type":"c1","uid":1307269,"ip_address":"","ucode":"64D1B7F87B03E2","user_header":"https://static001.geekbang.org/account/avatar/00/13/f2/85/7d3ce959.jpg","comment_is_top":false,"comment_ctime":1601736509,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1601736509","product_id":100017301,"comment_content":"hello，问下既然Top（n&#47;2）通过一个堆可以计算出中位数（Topk问题），为啥要通过两个堆（一个大堆和一个小堆来计算？）不太理机","like_count":0},{"had_liked":false,"id":250596,"user_name":"jack","can_delete":false,"product_type":"c1","uid":1898292,"ip_address":"","ucode":"A2253AC8570C5E","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/jibauP3icEFic4w56L2ddVghL7h2gGKhFdW8lBfE9rpwwRgzUKkLFY9wb4w70AXz7retME96a6EBRTA0LvSLn0ib8A/132","comment_is_top":false,"comment_ctime":1601166140,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1601166140","product_id":100017301,"comment_content":"“建立TOP10的堆”+“动态维护TOP10的堆”；建堆：统计出到发布TOP10排行榜时刻前1h之内点击量为TOP10的新闻摘要，根据点击量的TOP10构建大小为10的最小堆；动态维护：以堆顶新闻摘要的点击量为判断基准，在发布排行榜时刻之前的任何时刻若有某条新闻摘要的点击量超过“入堆的最小标准”——首先立马删除堆顶元素，其次将该新闻摘要入堆，然后重新堆化发布排行榜TOP10的最小堆；如此循环，则可实现动态地在网站首页banner 上滚动显示每1小时点击量TOP10的新闻摘要。","like_count":0},{"had_liked":false,"id":247403,"user_name":"夜空咏叹调","can_delete":false,"product_type":"c1","uid":1189074,"ip_address":"","ucode":"CC9350BCF218CD","user_header":"https://static001.geekbang.org/account/avatar/00/12/24/d2/a5e272ce.jpg","comment_is_top":false,"comment_ctime":1599702394,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1599702394","product_id":100017301,"comment_content":"老师，其实我一开始看到求中位数要用到两个堆就很疑惑，直接用一个顶堆不能实现么？因为在查找的时候基本都是在大顶堆上操作，小顶堆只是存储数据。最多就是在动态插入的时候用到小顶堆元素数量对大顶堆数量进行调整，这样用数组，栈（只要能快速查出元素数量的数据结构）替代也可以么？","like_count":0},{"had_liked":false,"id":244776,"user_name":"极客学子","can_delete":false,"product_type":"c1","uid":1149510,"ip_address":"","ucode":"40051597564EB7","user_header":"https://static001.geekbang.org/account/avatar/00/11/8a/46/71747b18.jpg","comment_is_top":false,"comment_ctime":1598673514,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1598673514","product_id":100017301,"comment_content":"用户点击访问某个新闻时，如果是该新闻首次被访问，则将该新闻的链接映射一个 hashcode ，将映射关系存储在文件中，然后在数据库中记录新闻链接的hashcode以它的初始访问次数1，往后每次被访问就更新数据库的访问次数字段，同时在内存中缓存一个长度为10的小顶堆，当某个新闻的访问次数大于小顶堆的最小值就删除堆顶元素然后将这个访问次数入堆，每隔一个小时就将小顶堆的数据对应文件中的链接更新到网站首页banner上。","like_count":0},{"had_liked":false,"id":243942,"user_name":"minsky","can_delete":false,"product_type":"c1","uid":1351075,"ip_address":"","ucode":"7296ECA064E89B","user_header":"https://static001.geekbang.org/account/avatar/00/14/9d/a3/79fc9017.jpg","comment_is_top":false,"comment_ctime":1598334696,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1598334696","product_id":100017301,"comment_content":"文中 1. 合并有序小文件  用小顶堆来实现的时候，数据加入之后会进行堆化处理，那移除堆顶元素的时候怎么知道移除的是哪个文件的元素呢? 如果不需要知道是移除的是哪个文件，怎么知道该从哪个文件读入下一个字符串？ ","like_count":0},{"had_liked":false,"id":242305,"user_name":"汪宇跃 - Kenny","can_delete":false,"product_type":"c1","uid":1010110,"ip_address":"","ucode":"AA097EE55CA597","user_header":"https://static001.geekbang.org/account/avatar/00/0f/69/be/ca3a9db1.jpg","comment_is_top":false,"comment_ctime":1597665707,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1597665707","product_id":100017301,"comment_content":"有些时候总想这种数据结构什么时候能用上啊，这不感觉用得恰到好处……有种两块拼图“卡吧”对上的感觉","like_count":0},{"had_liked":false,"id":240342,"user_name":"酸辣土豆丝","can_delete":false,"product_type":"c1","uid":1751234,"ip_address":"","ucode":"0E3E4AFB31E1E6","user_header":"https://static001.geekbang.org/account/avatar/00/1a/b8/c2/d1904d74.jpg","comment_is_top":false,"comment_ctime":1596871147,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1596871147","product_id":100017301,"comment_content":"对堆有了一个清晰的认识","like_count":0},{"had_liked":false,"id":237459,"user_name":"多选参数","can_delete":false,"product_type":"c1","uid":1248326,"ip_address":"","ucode":"B2294D80AB075F","user_header":"https://static001.geekbang.org/account/avatar/00/13/0c/46/dfe32cf4.jpg","comment_is_top":false,"comment_ctime":1595837880,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1595837880","product_id":100017301,"comment_content":"针对课后思考题，我一开始想到的是实时维护，也就是来一个点击量，调整一下这个堆，但是发现访问量很大的时候，每次访问一下我都得调整一下。这还真不如，一小时按需调整一次。","like_count":0},{"had_liked":false,"id":226070,"user_name":"Geek_69cfd7","can_delete":false,"product_type":"c1","uid":2007777,"ip_address":"","ucode":"BFC4B586FA65F7","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/orTaVwTib3ribTl5wibBQPniclzNVJMXCDw4ic4P2Q3A6MBEyuqg5AY46o4SPmIKm8vgIqnUzzqbEhIfQRQBtY7q6JQ/132","comment_is_top":false,"comment_ctime":1591945499,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1591945499","product_id":100017301,"comment_content":"堆应用场景：<br>      O(logn) 插入即有序<br>","like_count":0},{"had_liked":false,"id":226050,"user_name":"Geek_69cfd7","can_delete":false,"product_type":"c1","uid":2007777,"ip_address":"","ucode":"BFC4B586FA65F7","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/orTaVwTib3ribTl5wibBQPniclzNVJMXCDw4ic4P2Q3A6MBEyuqg5AY46o4SPmIKm8vgIqnUzzqbEhIfQRQBtY7q6JQ/132","comment_is_top":false,"comment_ctime":1591936524,"is_pvip":true,"discussion_count":1,"race_medal":0,"score":"1591936524","product_id":100017301,"comment_content":"老师，取中位数那里不能只维护一个n&#47;2+1的最大堆吗，感觉两个堆虽然容易理解但是浪费空间","like_count":0,"discussions":[{"author":{"id":1248326,"avatar":"https://static001.geekbang.org/account/avatar/00/13/0c/46/dfe32cf4.jpg","nickname":"多选参数","note":"","ucode":"B2294D80AB075F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":294241,"discussion_content":"我是这么理解的，如果只维护一个堆，那么当之后调整堆的时候，也就是确保两个堆的数量是按照比例来的时候，你是需要从另一个堆中取数据的。如果不维护两个堆，你在调整的时候，需要对不是堆中的顺序取最小等，而维护堆则会很方便。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1595837531,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":224703,"user_name":"Geek_e43088","can_delete":false,"product_type":"c1","uid":1981682,"ip_address":"","ucode":"96A9BC9FAD4AB7","user_header":"https://static001.geekbang.org/account/avatar/00/1e/3c/f2/60f8786b.jpg","comment_is_top":false,"comment_ctime":1591513800,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1591513800","product_id":100017301,"comment_content":"我们针对每个包含 1 亿条搜索关键词的文件，利用散列表和堆，分别求出 Top 10，然后把这个 10 个 Top 10 放在一块，然后取这 100 个关键词中，出现次数最多的 10 个关键词，这就是这 10 亿数据中的 Top 10 最频繁的搜索关键词了         ","like_count":0},{"had_liked":false,"id":224662,"user_name":"🐻🐻","can_delete":false,"product_type":"c1","uid":1027203,"ip_address":"","ucode":"424120B74390CC","user_header":"https://static001.geekbang.org/account/avatar/00/0f/ac/83/4c1a18de.jpg","comment_is_top":false,"comment_ctime":1591500025,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1591500025","product_id":100017301,"comment_content":"需要解决的问题: <br>1. 访问日志的存储；<br>   因为访问日志非常大, 导致访问日志单机无法存储； 启用一致性hash算法，将日志分散至不同的机器；并且根据大小&#47;时间 进行文件的切割;  文件大小可以定为:100MB, 时间可以定为1小时; 两个条件时或的关系;<br>2. 近一个小时访问次数的计算；<br>    与收集日志的一样，启用多台机器，从日志文件里面提取: {hashcode, id, 访问次数};只有当hashcode &amp; id 一致时，才对计数进行+1；hashcode主要的作用是散列; 加上id是为了防止hashcode冲突; <br>3. 近一个小时内,  Top 10的新闻摘要;<br>   收集日志访问次数的同事，根据访问次数在每台机器上构造Top10的小顶堆； 当访问次数大于小顶堆 堆顶时，从小顶堆中删除堆顶元素，将数据放入小顶堆中;<br>   汇总各个分析机器的Top10的小顶堆，构造全局小顶堆；<br>4. 根据全局小顶堆的计算值, 获取堆中的 ID&amp;次数；按照顺序循环展示在首页 ","like_count":0},{"had_liked":false,"id":221584,"user_name":"Ivan.Qi","can_delete":false,"product_type":"c1","uid":1099170,"ip_address":"","ucode":"36F46A4D1F0EAA","user_header":"https://static001.geekbang.org/account/avatar/00/10/c5/a2/4ece341b.jpg","comment_is_top":false,"comment_ctime":1590544399,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1590544399","product_id":100017301,"comment_content":"刚好复习到这一节，发一下之前实现的代码<br>1，合并有序小文件<br>\thttps:&#47;&#47;github.com&#47;Ivanqi&#47;algorithm&#47;tree&#47;master&#47;heap&#47;mergeSamilFile<br>2，高性能定时器的应用<br>\thttps:&#47;&#47;github.com&#47;Ivanqi&#47;algorithm&#47;tree&#47;master&#47;heap&#47;highTimeSchedule<br>3，求topk<br>\thttps:&#47;&#47;github.com&#47;Ivanqi&#47;algorithm&#47;tree&#47;master&#47;heap&#47;topk<br>4，求中位数<br>\thttps:&#47;&#47;github.com&#47;Ivanqi&#47;algorithm&#47;tree&#47;master&#47;heap&#47;midnum<br>5 大文件的关键字的统计<br>\thttps:&#47;&#47;github.com&#47;Ivanqi&#47;algorithm&#47;tree&#47;master&#47;heap&#47;bigFileTopN","like_count":0},{"had_liked":false,"id":221491,"user_name":"你在不远的未来","can_delete":false,"product_type":"c1","uid":1318404,"ip_address":"","ucode":"5B34C8BD03B71A","user_header":"https://static001.geekbang.org/account/avatar/00/14/1e/04/f902047e.jpg","comment_is_top":false,"comment_ctime":1590508192,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1590508192","product_id":100017301,"comment_content":"问题：<br>     有一个访问量非常大的新闻网站，我们希望将点击量排名 Top 10 的新闻摘要，滚动显示在网站首页 banner 上，并且每隔 1 小时更新一次。如果你是负责开发这个功能的工程师，你会如何来实现呢？<br>解决思路：<br>提示： 解决问题这里的top 10是，上1个小时之内的访问top 10，而非历史所有访问的top 10，数仓中是不一样的。<br>将nginx访问日志进行处理，提取新闻ID，一次访问记录ID -&gt; 1到log文件中，将log文件打散到n台服务器当中，每台服务器获取top 10，最终再合并所有服务器的top 10生成最终的top 10。这个思路其实就是大数据或者MapReduce的top思路。<br>","like_count":0},{"had_liked":false,"id":218922,"user_name":"亢（知行合一的路上）","can_delete":false,"product_type":"c1","uid":1347013,"ip_address":"","ucode":"958AF7C96EB9E8","user_header":"https://static001.geekbang.org/account/avatar/00/14/8d/c5/898b13b4.jpg","comment_is_top":false,"comment_ctime":1589898722,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1589898722","product_id":100017301,"comment_content":"真是得活学活用，咋就没想到堆可以作为优先级队列呢😓","like_count":0},{"had_liked":false,"id":217928,"user_name":"John","can_delete":false,"product_type":"c1","uid":1020861,"ip_address":"","ucode":"E4ADF8488953FB","user_header":"https://static001.geekbang.org/account/avatar/00/0f/93/bd/f3977ebb.jpg","comment_is_top":false,"comment_ctime":1589664174,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1589664174","product_id":100017301,"comment_content":"应用二利用堆求TopK: 描述solution的部分略微有点快, 我觉得应该把Array的前K个数据初始化为1个小顶堆, 然后再里边Array后面的部分[k, n)来与小顶堆进行比较.","like_count":0},{"had_liked":false,"id":216549,"user_name":"Geek_ac7784","can_delete":false,"product_type":"c1","uid":1981613,"ip_address":"","ucode":"62F0E5E6D6F4BA","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/8Dj4ugujXwY24G8pcpgDFGiciarXetG3ItQ4M9mSQMLyRdRRXEXXJVfib48mGUQAu87QcvImwyJIVJlEFeEguV44w/132","comment_is_top":false,"comment_ctime":1589281180,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1589281180","product_id":100017301,"comment_content":"学习笔记:<br>1. 优先队列<br>    合并有序n个小文件：n个文件依次遍历，找出n个字符中最小的，放入大文件。优先队列用在快速查找n个数的最小值上。<br>    高性能定时器：所有任务按时间组成小顶堆。堆顶为最先要发生的事。定时器只定这一个。到点就执行它，把它从顶堆中删除，然后将剩余的堆化。<br>2. top k<br>    静态：简单，维护大小为k的小顶堆。<br>    动态：维护大小为k的小顶堆，新元素只与堆顶最小的比，超过他就删除他，把新的加入堆。<br>3. 中位数问题：<br>    静态：反正静态，先排序在求呗<br>    动态：一个大顶堆，一个小顶堆，大顶堆的数据应该小于小顶堆。也就是说大顶堆存储了前半部分数据，小顶堆存储了后半部分数据。这样两个堆顶大只都是中位数。动态维护两个数组。如果数据小于大顶堆顶，就插入小顶堆(这里老师有问题，说明了专家都及时搞不清，思路比具体实现重要)。然后，判断大小顶堆的数量关系是否满足1:1(求99分位点则是99:1)<br>开题篇：<br>10亿调数据会重复的，1亿条不重复，也会占据5G空间，所以要将数据分片，且相同数据分到一个文件里面。哎?哈希算法。<br>然后对每个文件进行求topk。最后对所有文件的top k 求 top k<br>思考题：<br>首先想到top k 的堆<br>问题跟10亿个日志文件类似，只不过日志需要自己统计每条数据的次数，但是这里，网站应该给统计了每条新闻的访问次数。看到评论1 想了那么多，好像与日志那个问题重复了。只需要维护一个topk 的小顶堆，然后依次遍历所有新闻的数据，大于堆顶数据的数据替代掉堆顶，然后堆化就行。","like_count":0},{"had_liked":false,"id":214977,"user_name":"拉普达","can_delete":false,"product_type":"c1","uid":1930686,"ip_address":"","ucode":"0E524C0D99B2A0","user_header":"https://static001.geekbang.org/account/avatar/00/1d/75/be/6f3ab95e.jpg","comment_is_top":false,"comment_ctime":1588862488,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1588862488","product_id":100017301,"comment_content":"1、建立记录网页点击数量的对象，包含3个元素：网页链接、链接哈希值和点击次数，并根据其哈希值mod K的值，将其分散记录在K个数据库表或文件中。K的大小根据网页总数和机器内存确定。<br>2、内存中记录1小时以来新增的网页点击情况，1小时结束后更新上述K个文件。<br>3、针对每个文件，建立大小为10的小顶堆，得到10×K个网页，从中去除前10个即可。","like_count":0},{"had_liked":false,"id":214383,"user_name":"Allan","can_delete":false,"product_type":"c1","uid":1310388,"ip_address":"","ucode":"8DA4DBECC2C45C","user_header":"https://static001.geekbang.org/account/avatar/00/13/fe/b4/295338e7.jpg","comment_is_top":false,"comment_ctime":1588736177,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1588736177","product_id":100017301,"comment_content":"60天攻克算法打卡行动第24天<br><br>学习内容 :堆的应用：如何快速获取到Top 10最热门的搜索关键词？<br><br>掌握堆这3个非常重要的应用，我们就能从海量数据中快速获取热门关键词，实现搜索引擎的热门搜索排行榜功能。<br><br>1.堆的应用一：优先级队列<br>-&gt;合并大文件 小顶堆<br>-&gt;定时器 小顶堆 顶的第一个节点就是要执行的第一个定时任务<br>问题：程序是怎么知道T时间后开始运行堆，这段时间我想肯定是有一个程序在不断的进行读取堆顶的时间与当前时间做对比吧？堆顶的优势也就是不用一直遍历整个任务，而只是读取堆顶元素就可以了这一点吧？<br>2.堆的应用二：利用堆求 Top K<br>-&gt;静态数据，我建立一个k 位的小顶堆，堆数据进行遍历与堆顶比较，比顶大则进入堆，删除数组值，否则不变。继续遍历数组直到结束，那么小顶堆就是topK元素。遍历数组是O（n），建堆O（logk），最坏情况 O(nlogk)<br>-&gt;动态数据，<br>3.堆的应用三：利用堆求中位数<br>-&gt;静态数据，直接 n&#47;2 n&#47;2+1偶数；奇数 n&#47;2 + 1<br>-&gt;动态数据，我们需要维护两个堆 小顶堆，大顶堆。小顶堆存后部分，大顶堆存前部分，小顶堆全部大于大顶堆。那么大顶堆的堆顶元素就是我们要找的中位数。动态加入的元素，与大顶堆的堆顶元素比较，大于堆顶去小顶堆，否则进入大顶堆。为了保持平衡，我们还需要不断的移动数据让两个堆一样多。<br>解题开篇： 遍历10亿的数据？如何遍历，不是说了都超过1G了吗？内存怎么能放的下这1亿个关键字？这一点还是比较不清楚的。<br>课后思考：我们维护一个k位大顶堆，每个被点击的新闻摘要其实都有一个id，那么每次点击都会给它加1，同理是同步到数据库的，可以redis等。这个id加1后要与我们的大顶堆堆顶元素对比，如果大，那么就进入，如果小那么就不变。那么一个小时把大顶堆的数据渲染到页面就可以。","like_count":0},{"had_liked":false,"id":213912,"user_name":"默默","can_delete":false,"product_type":"c1","uid":1006635,"ip_address":"","ucode":"AF798B9D327F24","user_header":"https://static001.geekbang.org/account/avatar/00/0f/5c/2b/8b771383.jpg","comment_is_top":false,"comment_ctime":1588588762,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1588588762","product_id":100017301,"comment_content":"首先建立新闻摘要与新闻编号间的dict，如{1: content1; 2:content2...}。<br>每小时生成一个新闻点击记录日志文件。针对小时日志文件，将新闻编号 mod 10，存入10个文件中(需要根据日志文件大小选择合适的分区文件数，这里假设10)。对10个分区文件，分别利用散列表和堆求TOP 10文件编号。最后合并10个堆中数据，从这100个数中选出TOP 10编号.将编号对应的新闻摘要，展示出来。","like_count":0},{"had_liked":false,"id":213075,"user_name":"void","can_delete":false,"product_type":"c1","uid":1145429,"ip_address":"","ucode":"502ED161F271B3","user_header":"https://static001.geekbang.org/account/avatar/00/11/7a/55/2f4055f6.jpg","comment_is_top":false,"comment_ctime":1588297583,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1588297583","product_id":100017301,"comment_content":"&quot;维护一个大小为 K 的小顶堆，顺序遍历数组，从数组中取出数据与堆顶元素比较。如果比堆顶元素大，我们就把堆顶元素删除，并且将这个元素插入到堆中；如果比堆顶元素小，则不做处理&quot;<br>这个有点不太理解。假如原始数据是从大到小排列的的，那么第一个数据作为堆顶，那后边所有数据都不会比它大，遍历完数组之后堆里只有第一个元素。","like_count":0},{"had_liked":false,"id":206826,"user_name":"梅端","can_delete":false,"product_type":"c1","uid":1525335,"ip_address":"","ucode":"FEC08731457770","user_header":"https://static001.geekbang.org/account/avatar/00/17/46/57/fe38a6db.jpg","comment_is_top":false,"comment_ctime":1586941842,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1586941842","product_id":100017301,"comment_content":"堆的实现没什么问题，却发现堆的使用还有如此多的玄机，涨知识了。","like_count":0},{"had_liked":false,"id":203644,"user_name":"zeor","can_delete":false,"product_type":"c1","uid":1888276,"ip_address":"","ucode":"20DA6DB3527D21","user_header":"https://static001.geekbang.org/account/avatar/00/1c/d0/14/50782491.jpg","comment_is_top":false,"comment_ctime":1586245827,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1586245827","product_id":100017301,"comment_content":"老师您好，定时器这个例子，没太明白，堆定的数什么时候去取，还有要是同时有多个相同的数在堆顶怎么处理？","like_count":0,"discussions":[{"author":{"id":1010914,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEIgYQgM25OaLGNWPUg5NSrQuCrPNicHqNgB9lsJGMalNU18sibF4cdYxKPuwgVsIc1m5ha5voHrY9Lg/132","nickname":"jacoffee","note":"","ucode":"B3BFD39138400B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":562620,"discussion_content":"堆顶元素正常去取就行了， 因为存储是任务还有多久才执行，每次去检查栈顶元素的时候，这个时间会变化的，也就是越来越小(离执行时间越来越近)。如果还不到执行时间，可以等待一会儿再去检查。Java中的延时队列DelayQueue就是基于PriorityQueue实现的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1649857019,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":199247,"user_name":"zhimin","can_delete":false,"product_type":"c1","uid":1312130,"ip_address":"","ucode":"DF6DFBEF6FA297","user_header":"https://static001.geekbang.org/account/avatar/00/14/05/82/51cd0a50.jpg","comment_is_top":false,"comment_ctime":1585484349,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1585484349","product_id":100017301,"comment_content":"access日志 ， 相同的uri （注意做日志分类处理，排除掉非热点类的点击如首页列表页之类的）进行hashcode取模放入相应的小文件中，依次获取每个uri的点击量。然后对每个分片进行小顶堆10排序。","like_count":0},{"had_liked":false,"id":198385,"user_name":"何磊","can_delete":false,"product_type":"c1","uid":1047604,"ip_address":"","ucode":"78934C3ED4A342","user_header":"https://static001.geekbang.org/account/avatar/00/0f/fc/34/c733b116.jpg","comment_is_top":false,"comment_ctime":1585448928,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1585448928","product_id":100017301,"comment_content":"思路如下：<br>1. 会有一个地方存储每篇新闻的点击量，比如MySQL或者Redis；类似：new_id=&gt;click_num<br>2. 建立一个TOP10的小顶堆在内存中<br>3. 每1小时统计点击量时，更新小顶堆元素<br>这保证取出操作是O(1)","like_count":0,"discussions":[{"author":{"id":1397031,"avatar":"https://static001.geekbang.org/account/avatar/00/15/51/27/f0dd6f19.jpg","nickname":"老白","note":"","ucode":"39881175152D49","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":230689,"discussion_content":"那还不如直接用redis统计，复杂度也不高，还稳定","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586762653,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":197002,"user_name":"SteelHuaSheng","can_delete":false,"product_type":"c1","uid":1396126,"ip_address":"","ucode":"BC8127FC5207FC","user_header":"https://static001.geekbang.org/account/avatar/00/15/4d/9e/04ec08bf.jpg","comment_is_top":false,"comment_ctime":1585331071,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1585331071","product_id":100017301,"comment_content":"打卡！感受到数据结构这个锤子的厉害了。要是笨办法乱想，这业务我是实现不了了。还要加把劲啊。","like_count":0},{"had_liked":false,"id":195873,"user_name":"Simple life","can_delete":false,"product_type":"c1","uid":1571460,"ip_address":"","ucode":"1902D7F72FB43F","user_header":"https://static001.geekbang.org/account/avatar/00/17/fa/84/f01d203a.jpg","comment_is_top":false,"comment_ctime":1585220422,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1585220422","product_id":100017301,"comment_content":"求前K大和找中位数其实也是一个意思了","like_count":0},{"had_liked":false,"id":190796,"user_name":"小谢","can_delete":false,"product_type":"c1","uid":1879476,"ip_address":"","ucode":"82D54A61D2FDB9","user_header":"https://static001.geekbang.org/account/avatar/00/1c/ad/b4/e4dcd4d7.jpg","comment_is_top":false,"comment_ctime":1584692905,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1584692905","product_id":100017301,"comment_content":"经过了这章节学习深刻感觉到堆的魅力","like_count":0},{"had_liked":false,"id":189519,"user_name":"獨自去遠方","can_delete":false,"product_type":"c1","uid":1503941,"ip_address":"","ucode":"E246B33F397441","user_header":"https://static001.geekbang.org/account/avatar/00/16/f2/c5/2a441c27.jpg","comment_is_top":false,"comment_ctime":1584524524,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1584524524","product_id":100017301,"comment_content":"堆的应用<br>    假设现在我们有一个包含 10 亿个搜索关键词的日志文件，如何能快速获取到热门榜 Top 10 的搜索关键词呢？<br>        散列表<br>        10的大顶堆<br><br><br>    优先级队列：<br>        特性：<br>            数据的出队顺序不是先进先出，而是按照优先级来，优先级最高的，最先出队。<br>        应用场景：赫夫曼编码、图的最短路径、最小生成树算法等等<br><br>        合并有序小文件<br>            使用小顶堆，<br>            1. 每个文件取出一个元素，建堆，然后将堆顶元素取出放入大文件<br>            2. 再从上一步堆顶元素所在的文件删除取出下一个元素取出放到堆顶，进行堆化<br>            3. 重复之前的步骤，直到堆清空<br><br>        高性能定时器<br>            取堆首任务，设定定时任务<br><br>    利用堆求TOP K<br>        维护一个大小为K的堆<br>        静态数据集合<br><br>        动态数据集合<br><br><br>    利用堆求中位数<br>        维护一个大顶堆和一个小顶堆<br>        移动两个堆顶的元素，让两个堆的数量保持一致<br><br>        调整大小顶堆的数量，可以获取不同比例的数据","like_count":0},{"had_liked":false,"id":189105,"user_name":"斐波那契","can_delete":false,"product_type":"c1","uid":1464006,"ip_address":"","ucode":"85E2EBC01392B1","user_header":"https://static001.geekbang.org/account/avatar/00/16/56/c6/0b449bc6.jpg","comment_is_top":false,"comment_ctime":1584455626,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1584455626","product_id":100017301,"comment_content":"老师 有个问题 现在开发都是系统开发 有时候排序可以让数据库帮我们完成 那问题是 是让数据库帮我们排序好还是我们把数据取出来在程序里排序好呢","like_count":0},{"had_liked":false,"id":189089,"user_name":"chenzesam","can_delete":false,"product_type":"c1","uid":1045011,"ip_address":"","ucode":"34E76BB9C7618D","user_header":"https://static001.geekbang.org/account/avatar/00/0f/f2/13/3ee5a9b4.jpg","comment_is_top":false,"comment_ctime":1584455092,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1584455092","product_id":100017301,"comment_content":"这个挺有用的，赞👍🏻","like_count":0},{"had_liked":false,"id":184446,"user_name":"天，很蓝 ～","can_delete":false,"product_type":"c1","uid":1339242,"ip_address":"","ucode":"081D57F7CECC37","user_header":"https://static001.geekbang.org/account/avatar/00/14/6f/6a/b0d7987b.jpg","comment_is_top":false,"comment_ctime":1583316580,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1583316580","product_id":100017301,"comment_content":"求中位数没必要维护两个堆吧，计算好堆的大小，一个堆也能实现啊","like_count":0,"discussions":[{"author":{"id":1238436,"avatar":"https://static001.geekbang.org/account/avatar/00/12/e5/a4/e16dca6a.jpg","nickname":"阿凯文","note":"","ucode":"F17CF201E74849","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":297752,"discussion_content":"我也觉得","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1597047698,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":182021,"user_name":"谢真","can_delete":false,"product_type":"c1","uid":1124650,"ip_address":"","ucode":"8C3402DE107C9F","user_header":"https://static001.geekbang.org/account/avatar/00/11/29/2a/9079f152.jpg","comment_is_top":false,"comment_ctime":1582694213,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1582694213","product_id":100017301,"comment_content":"先用hash分片把访问点击量统计，然后构建一个数量为10的堆和另外数据的一个堆，TOP10数据放入10的堆中，每隔一小时对有变化的数据刷新一次","like_count":0},{"had_liked":false,"id":181820,"user_name":"凉人。","can_delete":false,"product_type":"c1","uid":1659177,"ip_address":"","ucode":"4DB16004A62015","user_header":"https://static001.geekbang.org/account/avatar/00/19/51/29/24739c58.jpg","comment_is_top":false,"comment_ctime":1582639441,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1582639441","product_id":100017301,"comment_content":"1 针对静态数据和动态数据的看法<br>    1 静态数据和动态数据求解方式是一致的<br>    2 动态数据的数据呈现未知性<br>    3 动态数据结果可变,静态不可变<br>2 针对静态数据求中位数 <br>    静态数据求中位数的方法,使用快速排序的方式,可以在不排序完整的情况取得中位数","like_count":0},{"had_liked":false,"id":175075,"user_name":"短迪大魔王","can_delete":false,"product_type":"c1","uid":1236079,"ip_address":"","ucode":"37E8117E0495B8","user_header":"https://static001.geekbang.org/account/avatar/00/12/dc/6f/5d86dbe9.jpg","comment_is_top":false,"comment_ctime":1580548318,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1580548318","product_id":100017301,"comment_content":"这节课和hash的应用让我受益颇多","like_count":0},{"had_liked":false,"id":174630,"user_name":"wu","can_delete":false,"product_type":"c1","uid":1443515,"ip_address":"","ucode":"A085FE6743FEB1","user_header":"https://static001.geekbang.org/account/avatar/00/16/06/bb/0d70099d.jpg","comment_is_top":false,"comment_ctime":1580303102,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1580303102","product_id":100017301,"comment_content":"老师， Top 10 最热关键词的解法有问题。局部最优不一定是全局最优。每个文件的top11若是同一个关键词，可能这个top10会进入到汇总的top10中。","like_count":0},{"had_liked":false,"id":172492,"user_name":"飘到站","can_delete":false,"product_type":"c1","uid":1796339,"ip_address":"","ucode":"0C9A9521061127","user_header":"https://static001.geekbang.org/account/avatar/00/1b/68/f3/57456c44.jpg","comment_is_top":false,"comment_ctime":1579189257,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1579189257","product_id":100017301,"comment_content":"记录下自己不成熟的想法:<br>        1. 访问量非常大，需要分布访问。将新闻的唯一标识做一致性哈希到一百台服务中，这样某一个新闻的访问次数只会统计到其中的一台服务中，维护本服务中所有新闻访问次数至散列表。所有服务做小顶堆求各自负责新闻的Top10。<br>        2. 所有存活服务每小时上报自己Top10，有总服务对100服务上报的Top10做最终Top10。 或总服务每小时获取存活服务的Top10，做最终Top10。<br>        3. 一个新闻只会在一个服务中访问，正好可以做缓存。进而做cdn，只是访问统计操作进服务。<br>        4. 使用哈希环保证服务的动态扩展，删减。","like_count":0},{"had_liked":false,"id":168275,"user_name":"自信来自成功的体验","can_delete":false,"product_type":"c1","uid":1358428,"ip_address":"","ucode":"BD12277AF8BC45","user_header":"https://static001.geekbang.org/account/avatar/00/14/ba/5c/b666bce0.jpg","comment_is_top":false,"comment_ctime":1578040695,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1578040695","product_id":100017301,"comment_content":"我的数据是固定的 ，然后用priority_queue 性能会比快排效率高吗","like_count":0},{"had_liked":false,"id":168261,"user_name":"自信来自成功的体验","can_delete":false,"product_type":"c1","uid":1358428,"ip_address":"","ucode":"BD12277AF8BC45","user_header":"https://static001.geekbang.org/account/avatar/00/14/ba/5c/b666bce0.jpg","comment_is_top":false,"comment_ctime":1578039765,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1578039765","product_id":100017301,"comment_content":"老师 你好， c++的priority_queue可以实现堆， 但是没有指定长度，这个是不是效率低","like_count":0},{"had_liked":false,"id":166616,"user_name":"Chris","can_delete":false,"product_type":"c1","uid":1689346,"ip_address":"","ucode":"50A51AE2110A7A","user_header":"https://static001.geekbang.org/account/avatar/00/19/c7/02/8346ebf6.jpg","comment_is_top":false,"comment_ctime":1577521234,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1577521234","product_id":100017301,"comment_content":"王争老师，将 10 亿条占据约5GB的搜索关键词通过哈希算法分片的工作，内存为 1GB单机可以完成吗，这里的1GB内存是指RAM还是ROM啊，这里被搞糊涂了。","like_count":0,"discussions":[{"author":{"id":1689346,"avatar":"https://static001.geekbang.org/account/avatar/00/19/c7/02/8346ebf6.jpg","nickname":"Chris","note":"","ucode":"50A51AE2110A7A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":107486,"discussion_content":"内存在这里指的是内部存储，相对于外部存储是很小的，将大量数据进行哈希分片是空间复杂度是o（1），为原地处理算法，因为不同数据数据间处理是分割开的，空间复杂度指的是内存条的存储占用，排序算法对n个数进行归并排序是要求记录数据进行merge的所以是o（n），而冒泡，快排原地排序的空间复杂度就是o（1），跟输入数据量无关","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577583954,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":165508,"user_name":"SteveYang","can_delete":false,"product_type":"c1","uid":1754829,"ip_address":"","ucode":"C42BCA4F40A9EF","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKCbnOvEatUN4ysE2cl6zJNoAJVXXuQVhicQ1jxh6Z2Towrmmc1I6PndaicuQQ0RyyJPyJQicv4tSib9Q/132","comment_is_top":false,"comment_ctime":1577248286,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1577248286","product_id":100017301,"comment_content":"建立10个元素的堆，以新闻id为key，访问次数为value，用散列表统计，更新堆，输出堆即为前10访问量的新闻，每小时更新一个散列表和堆。","like_count":0},{"had_liked":false,"id":164453,"user_name":"seven","can_delete":false,"product_type":"c1","uid":1180307,"ip_address":"","ucode":"55CE5F60051F89","user_header":"https://static001.geekbang.org/account/avatar/00/12/02/93/44672231.jpg","comment_is_top":false,"comment_ctime":1576996720,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1576996720","product_id":100017301,"comment_content":"1.用hash算法将点击产生的日志进行分片存储<br>2.将不同的文件中的日志，用到hashmap来存放不同的不同文章的点击数量，然后按照点击量来来生成top10的大顶堆<br>3.有新的日志产生的时候，更新大顶堆<br>4.用到堆中的优先级队列功能的高速的定时器，没有小时合并所有的大顶堆，最后生成整个网站的top10","like_count":0},{"had_liked":false,"id":163959,"user_name":"港","can_delete":false,"product_type":"c1","uid":1122464,"ip_address":"","ucode":"35931FC6198180","user_header":"https://static001.geekbang.org/account/avatar/00/11/20/a0/1fca96c0.jpg","comment_is_top":false,"comment_ctime":1576834421,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1576834421","product_id":100017301,"comment_content":"1. 首先存储新闻摘要的空间太大，将新闻再要映射为哈希值，使用map建立key为哈希值的与摘要的映射关系。<br>2. 每一个小时形成一个文件记录被点击的摘要的哈希值，<br>3. 一小时结束后，开始计算上一个小时文件所记录的点击top10。<br>4. 先通过哈希算法将摘要的哈希值分片到不同文件中<br>5. 对于分片而成的不同文件，利用散列表统计摘要的点击量，然后对每个文件利用小顶堆计算top10<br>6. 合并分片文件，使用小顶堆计算总的top10<br>7. 使用map展示上一个小时的top10<br>8. 如果是展示全天的，需要在地不中就与前23个小时的合并，并且删去一天之前的数据<br>","like_count":0},{"had_liked":false,"id":163698,"user_name":"book尾汁","can_delete":false,"product_type":"c1","uid":1446375,"ip_address":"","ucode":"AE2B8DFC643ACC","user_header":"https://static001.geekbang.org/account/avatar/00/16/11/e7/044a9a6c.jpg","comment_is_top":false,"comment_ctime":1576768708,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1576768708","product_id":100017301,"comment_content":"1 对访问的URI进行散列算法，将其存入哈希表中，key为哈希值，value的初始值为1，每次请求先判断是否在哈希表中已有对应的记录，如果有就将记录数+1，没有就随机一定的概率写到哈希表中（减少hash表的大小）<br>2 对哈希表中的数据进行遍历，根据value构建一个大小为10的大顶堆，并记录当前堆的最小值及其哈希值<br>3 有新的访问记录时，对url做hash，并将其更新到散列表中，然后判断其hash值是否大于当前堆的最小值，如果大于的话就将其push入堆中。","like_count":0},{"had_liked":false,"id":162907,"user_name":"分清云淡","can_delete":false,"product_type":"c1","uid":1269873,"ip_address":"","ucode":"7045AE6BF72D31","user_header":"https://static001.geekbang.org/account/avatar/00/13/60/71/895ee6cf.jpg","comment_is_top":false,"comment_ctime":1576630449,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1576630449","product_id":100017301,"comment_content":"我有个问题 为什么前面中位数的问题 要用两个堆 而不是一个 存整个的 数组存放（用数组实现的堆）取值 时间复杂度 是常数 但是两个堆 的维护 一定省时间么？<br>另外 在大量数据情况下 求99%的时候 保留99%的堆 也没什么实际意义吧","like_count":0,"discussions":[{"author":{"id":1269873,"avatar":"https://static001.geekbang.org/account/avatar/00/13/60/71/895ee6cf.jpg","nickname":"分清云淡","note":"","ucode":"7045AE6BF72D31","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":86882,"discussion_content":"补充一下 我理解 这里面的99%主要是想 满足数据补偿 但是 这个补偿范围 比 筛查值大了两个数量级 是不是太大了（实际这个数据只要拿到1%的边界 基本就可以了）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1576630875,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":162533,"user_name":"Panda🐟","can_delete":false,"product_type":"c1","uid":1002401,"ip_address":"","ucode":"C6007A3192516A","user_header":"https://static001.geekbang.org/account/avatar/00/0f/4b/a1/c2719a5a.jpg","comment_is_top":false,"comment_ctime":1576550387,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1576550387","product_id":100017301,"comment_content":"思考题解答(没说内容量级，假设内容总量级在内存容量内)<br>1-散列表维护点击记录，每次点击记录+1<br>2-维护10个元素的小顶堆<br>3-每小时遍历一次堆外新闻大于堆顶则入堆，小于则继续遍历","like_count":0},{"had_liked":false,"id":162477,"user_name":"梦想的优惠券","can_delete":false,"product_type":"c1","uid":1257418,"ip_address":"","ucode":"D3B44F6C618CA7","user_header":"https://static001.geekbang.org/account/avatar/00/13/2f/ca/cbce6e94.jpg","comment_is_top":false,"comment_ctime":1576544374,"is_pvip":false,"discussion_count":0,"race_medal":4,"score":"1576544374","product_id":100017301,"comment_content":"打卡","like_count":0},{"had_liked":false,"id":159167,"user_name":"百里","can_delete":false,"product_type":"c1","uid":1212873,"ip_address":"","ucode":"2CE96129AA7F78","user_header":"https://static001.geekbang.org/account/avatar/00/12/81/c9/9194612b.jpg","comment_is_top":false,"comment_ctime":1575550938,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1575550938","product_id":100017301,"comment_content":"这 10 亿个关键词分片之后，每个文件都只有 1 亿的关键词，去除掉重复的，可能就只有 1000 万个, 每个文件1亿关键字,占5个G的大小, 如何做到去掉重复只有1000万个. 这个过程应该使用HASH去重才行吧.","like_count":0},{"had_liked":false,"id":158153,"user_name":"王木公","can_delete":false,"product_type":"c1","uid":1014550,"ip_address":"","ucode":"F049AEBFA0338D","user_header":"https://static001.geekbang.org/account/avatar/00/0f/7b/16/ca250e8c.jpg","comment_is_top":false,"comment_ctime":1575339384,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1575339384","product_id":100017301,"comment_content":"有一个低级的问题咨询，10亿条记录无法存储到内存中，那在使用哈希算法分片时，不也得一次性将10亿条数据读到内存，依次进行哈希计算和分片吗？<br>还是说每次都去磁盘中读取文件中的1条记录到内存中？","like_count":0},{"had_liked":false,"id":152202,"user_name":"王加武","can_delete":false,"product_type":"c1","uid":1665471,"ip_address":"","ucode":"DDCFE578C6C428","user_header":"https://static001.geekbang.org/account/avatar/00/19/69/bf/50a824a4.jpg","comment_is_top":false,"comment_ctime":1573913050,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1573913050","product_id":100017301,"comment_content":"老师，我刚好听到第29节，但是我一直有一个困惑，到底我们学习数据结构是写代重要还是熟悉它的特点，应用场景等等这些重要呢？很多数据结构的知识点我会分析，我自己也经常找一些问题摸索研究到底使用什么数据就够才能达到性能最优，我之前也刷过一些数据结构的题目，但是一直存在这样的疑惑，希望您好好的给个指导，这样我也能少走弯路，希望您看到了可以指导一下！谢谢老师","like_count":0},{"had_liked":false,"id":152150,"user_name":"wyf2317","can_delete":false,"product_type":"c1","uid":1236837,"ip_address":"","ucode":"7F3E61A6188B39","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/ub4icibeRLzff8Nf6ORsolib9KHtmeu3d4cCCAFd3Xgah3v78WfDYQB7WKq9iaIPXPwHBxw7mkBP9wYxDGMT9m1Rbw/132","comment_is_top":false,"comment_ctime":1573892797,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1573892797","product_id":100017301,"comment_content":"维护一个小顶堆，对大小为10。<br>第一次堆无数据时：将存量数据统计一次，初始化堆。<br>将新闻URL求hash值，作为key。点击量作为v。进行存储。<br>定时或实时更新点击次数，并查询是否大于堆顶。若大于则更新堆。","like_count":0},{"had_liked":false,"id":149279,"user_name":"无悔","can_delete":false,"product_type":"c1","uid":1182912,"ip_address":"","ucode":"C2FCC77510B738","user_header":"https://static001.geekbang.org/account/avatar/00/12/0c/c0/1abdd0ca.jpg","comment_is_top":false,"comment_ctime":1573181869,"is_pvip":false,"replies":[{"id":"57574","content":"github上搜wangzheng0822","user_name":"作者回复","user_name_real":"王争","uid":"1190123","ctime":1573339138,"ip_address":"","comment_id":149279,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1573181869","product_id":100017301,"comment_content":"老师您的github地址是多少，想看看您的实现","like_count":0,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":473802,"discussion_content":"github上搜wangzheng0822","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1573339138,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":146869,"user_name":"剑八","can_delete":false,"product_type":"c1","uid":1297630,"ip_address":"","ucode":"0A09F41DB8A4E7","user_header":"https://static001.geekbang.org/account/avatar/00/13/cc/de/e28c01e1.jpg","comment_is_top":false,"comment_ctime":1572682280,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1572682280","product_id":100017301,"comment_content":"看量级，估算内存使用量，将问题分解成n个数据集文件(每个数据集存储成一个map，key就是新闻的唯一值，value就是对应点击量)，分别求top10，然后再做聚合<br>具体每个数据集可以并行不同机器或线程去求解<br>每个数据集求top10可以用：新闻点击量维护一个map结构+小顶堆top10存储结构来做。<br>工程上用记点击新闻后我们可以用rocketmq异步形式写入到n个数据集文件，这部分我们可以考虑5分钟将内存中的新闻点击量写入到文件。<br>小顶堆top10的更新也是接收到异步用户点击事件来做更新，如果当前新闻事件点击数大于堆项，则删除堆顶元素，将这个新事件插入到堆中。<br>","like_count":0},{"had_liked":false,"id":145956,"user_name":"wind","can_delete":false,"product_type":"c1","uid":1507189,"ip_address":"","ucode":"5EC77AEB18130E","user_header":"https://static001.geekbang.org/account/avatar/00/16/ff/75/9c1b2ece.jpg","comment_is_top":false,"comment_ctime":1572406468,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"1572406468","product_id":100017301,"comment_content":"二刷。合并小文件取下个字符串时，还需判断是取哪个小文件。应该是放入大文件字符串对应的原小文件。","like_count":0,"discussions":[{"author":{"id":1206935,"avatar":"https://static001.geekbang.org/account/avatar/00/12/6a/97/9422bf31.jpg","nickname":"TTY","note":"","ucode":"D097636D322215","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":51923,"discussion_content":"我也有这个疑问，怎么判断从小顶堆中删除的元素来源于哪个小文件？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1573968819,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1014550,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/7b/16/ca250e8c.jpg","nickname":"王木公","note":"","ucode":"F049AEBFA0338D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1206935,"avatar":"https://static001.geekbang.org/account/avatar/00/12/6a/97/9422bf31.jpg","nickname":"TTY","note":"","ucode":"D097636D322215","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":70292,"discussion_content":"可能需要额外的空间来维护元素与文件之间的关联关系","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1575342744,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":51923,"ip_address":""},"score":70292,"extra":""}]}]},{"had_liked":false,"id":140786,"user_name":"Joiner","can_delete":false,"product_type":"c1","uid":1071941,"ip_address":"","ucode":"7F67D4C325E71F","user_header":"https://static001.geekbang.org/account/avatar/00/10/5b/45/5dc5437e.jpg","comment_is_top":false,"comment_ctime":1571048698,"is_pvip":false,"replies":[{"id":"54537","content":"没问题的。我们讲用堆求topk默认是不动态删除数据的，只有添加操作。","user_name":"作者回复","user_name_real":"王争","uid":"1190123","ctime":1571095519,"ip_address":"","comment_id":140786,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1571048698","product_id":100017301,"comment_content":"老师，利用堆求 Top K 这个案例中，尽管文章中已经说明动态数据是动态的加入数据，但我还是想知道如果动态的删除数据，是不是还得检查删除的数据是否在堆中，那么有两点：<br>1.最坏情况需要把堆中数据都遍历一遍。<br>2.如果在，需要删除该数据后基于当前数据重新生成堆。<br>这两点我的理解有问题吗？","like_count":0,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":470556,"discussion_content":"没问题的。我们讲用堆求topk默认是不动态删除数据的，只有添加操作。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1571095519,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":140428,"user_name":"Pyer","can_delete":false,"product_type":"c1","uid":1159237,"ip_address":"","ucode":"8287EFD2268211","user_header":"https://static001.geekbang.org/account/avatar/00/11/b0/45/f0a63850.jpg","comment_is_top":false,"comment_ctime":1570938165,"is_pvip":false,"replies":[{"id":"54528","content":"去重最省内存的方式就是先排序，然后顺序扫描去重。","user_name":"作者回复","user_name_real":"王争","uid":"1190123","ctime":1571094507,"ip_address":"","comment_id":140428,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1570938165","product_id":100017301,"comment_content":"我有个问题，对这 10 亿个关键词分片之后，每个文件都只有 1 亿的关键词,去除掉重复的，可能就只有 1000 万个。<br>这个去重怎么去重?比如你一个文件有1亿个词，那么对这个文件去重话，会不会很耗内存，如果内存不够的话??","like_count":0,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":470385,"discussion_content":"去重最省内存的方式就是先排序，然后顺序扫描去重。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1571094507,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":138139,"user_name":"李","can_delete":false,"product_type":"c1","uid":1025478,"ip_address":"","ucode":"044D5C47939824","user_header":"https://static001.geekbang.org/account/avatar/00/0f/a5/c6/5ead3889.jpg","comment_is_top":false,"comment_ctime":1570062127,"is_pvip":false,"replies":[{"id":"53767","content":"分成小文件，一次只读一个小文件到内存的","user_name":"作者回复","user_name_real":"王争","uid":"1190123","ctime":1570660498,"ip_address":"","comment_id":138139,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1570062127","product_id":100017301,"comment_content":"对这 10 亿个关键词分片之后，每个文件都只有 1 亿的关键词，去除掉重复的，可能就只有 1000 万个，每个关键词平均 50 个字节，所以总的大小就是 500MB。1GB 的内存完全可以放得下。<br>每个500m，一共10个，一共还是5g啊？好像1g也不够。是不是我哪里理解有误啊","like_count":0,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":469403,"discussion_content":"分成小文件，一次只读一个小文件到内存的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570660498,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":135343,"user_name":"LorraineLiu","can_delete":false,"product_type":"c1","uid":1507990,"ip_address":"","ucode":"28204A24749B69","user_header":"https://static001.geekbang.org/account/avatar/00/17/02/96/a7cc7944.jpg","comment_is_top":false,"comment_ctime":1569134217,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1569134217","product_id":100017301,"comment_content":"这个问题可以分为三个部分：<br>1. 初始化<br>2. 数据更新<br>3. 展示<br><br>1.初始化： 这个阶段，是把历史数据里的新闻和点击量做一个初始化dict， key为news_id ,value为点击量的统计值<br>利用第一个dict，建立top10的小顶堆，小顶堆的数据为top10的初始化数据<br>2. 再建立一个更新dict，key为在当前一个小时内被访问的news_id，value为当前一小时内的访问量。<br>每次到更新时间，都针对更新dict里的keys，合并新增的点击量到初始化dict里。然后对于所有更新dict的key的最新初始化里的value，与小顶堆的堆顶元素的value进行对比，更新小顶堆<br>初始化更新dict<br>3.展示最新的小顶堆元素。<br>","like_count":0},{"had_liked":false,"id":135072,"user_name":"Magic","can_delete":false,"product_type":"c1","uid":1272047,"ip_address":"","ucode":"FD9CEDAA419EB0","user_header":"https://static001.geekbang.org/account/avatar/00/13/68/ef/6264ca3d.jpg","comment_is_top":false,"comment_ctime":1568996554,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1568996554","product_id":100017301,"comment_content":"记录过去一小时点击过的所有新闻摘要的点击数，然后遍历这些点击数，和上一个小时的top10进行比较和排序","like_count":0},{"had_liked":false,"id":129925,"user_name":"建强","can_delete":false,"product_type":"c1","uid":1397126,"ip_address":"","ucode":"62B03D0E0C64EC","user_header":"https://static001.geekbang.org/account/avatar/00/15/51/86/b5fd8dd8.jpg","comment_is_top":false,"comment_ctime":1567328253,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1567328253","product_id":100017301,"comment_content":"思考题：<br>维护一个大小为10的小顶堆，堆中存贮的是新闻摘要及其点击量，堆的排序依据是新闻摘要的点击量，每当网站中的某条新闻的点击量发生变化时，就比较该新闻点击量和堆顶的新闻点击量，如果大于堆顶点击量，则删除堆顶新闻，并把该新闻摘要插入堆中。这样每隔一小时就把直接把堆中的10个新闻摘要依次显示出来。","like_count":0},{"had_liked":false,"id":127603,"user_name":"Xinming","can_delete":false,"product_type":"c1","uid":1454945,"ip_address":"","ucode":"F7330DD975D248","user_header":"https://static001.geekbang.org/account/avatar/00/16/33/61/da6d8713.jpg","comment_is_top":false,"comment_ctime":1566747263,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1566747263","product_id":100017301,"comment_content":"感谢老师~这集课程听得挺爽","like_count":0},{"had_liked":false,"id":125254,"user_name":"DullBird","can_delete":false,"product_type":"c1","uid":1110494,"ip_address":"","ucode":"80E2FD5F9687CB","user_header":"https://static001.geekbang.org/account/avatar/00/10/f1/de/3ebcbb3f.jpg","comment_is_top":false,"comment_ctime":1566132090,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1566132090","product_id":100017301,"comment_content":"问题:<br>1. topK,10亿分成10个文件，1个文件1亿，去重之后1000万字符.(疑问: 这里也有可能去重了还是1亿，解决思路、继续往小了分)<br>2. 思考题的问题，击量排名 Top 10，我理解是近一小时内的点击量top10,或者近一天的点击量top10，有一个时间的界限。解决思路认同点赞第一的同学。","like_count":0},{"had_liked":false,"id":115081,"user_name":"Paul Shan","can_delete":false,"product_type":"c1","uid":1593140,"ip_address":"","ucode":"32D99989028284","user_header":"","comment_is_top":false,"comment_ctime":1563487028,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1563487028","product_id":100017301,"comment_content":"top10访问思考题，每小时更新一次是一个静态数据求前十的问题，可以用大小为10的小顶堆，当数据超过10的时候就删除最小元素。如果所有数据能放入内存的话也可以建大顶堆，然后依次从堆中取出10条。","like_count":0},{"had_liked":false,"id":115080,"user_name":"Paul Shan","can_delete":false,"product_type":"c1","uid":1593140,"ip_address":"","ucode":"32D99989028284","user_header":"","comment_is_top":false,"comment_ctime":1563486324,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1563486324","product_id":100017301,"comment_content":"对于静态数据求top k的方法还有一种用大顶堆的思路，建堆然后取出前k个，复杂度是 n+k* lgn ,当k远小于n的时候，复杂度可近似看作n。","like_count":0},{"had_liked":false,"id":115008,"user_name":"飞向云端","can_delete":false,"product_type":"c1","uid":1211201,"ip_address":"","ucode":"CABC1A02ED6F47","user_header":"https://static001.geekbang.org/account/avatar/00/12/7b/41/85796e32.jpg","comment_is_top":false,"comment_ctime":1563451085,"is_pvip":false,"replies":[{"id":"42199","content":"那就放到一块，稍微改造下。","user_name":"作者回复","user_name_real":"王争","uid":"1190123","ctime":1563575218,"ip_address":"","comment_id":115008,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1563451085","product_id":100017301,"comment_content":"上面用堆处理定时任务，如果同一时刻有很多任务需要处理，这个时候怎么办","like_count":0,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":458924,"discussion_content":"那就放到一块，稍微改造下。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563575218,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":110870,"user_name":"John","can_delete":false,"product_type":"c1","uid":1020861,"ip_address":"","ucode":"E4ADF8488953FB","user_header":"https://static001.geekbang.org/account/avatar/00/0f/93/bd/f3977ebb.jpg","comment_is_top":false,"comment_ctime":1562381833,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1562381833","product_id":100017301,"comment_content":"10億關鍵詞的題目我感覺老師想說的是一種模糊算法 取一個差不多接近真實答案的辦法吧 如果對的話 就剛好給一些不太明白的同學解惑了 這個辦法的核心是解決內存不夠的問題 但是模糊的地方在於<br>1. 雖然沒有用內存 但這10個文件是外借了硬盤 我們把硬盤讀IO並不看做佔用內存<br>2. 有的同學提到 hash之後分配去文件 未必是平均分配 所以我們說是模糊算法 或者說是平均算法 一個極端的例子是 10億的詞都是一樣的 都是極客 <br>3. 這樣的Top100也是一個平均出來的Top100 很可能第100個詞 並不如那些沒有進任何前十的某個詞 正所謂高手在民間<br>其他的請其他同學補充 但大概意思是 這個辦法雖然並不能完全切合原來的題目要求和大家心中的預設 但是思想上是一個工業可行的實踐性辦法 謝謝","like_count":0},{"had_liked":false,"id":104055,"user_name":"那样的月色","can_delete":false,"product_type":"c1","uid":1237353,"ip_address":"","ucode":"23B1298C465D2C","user_header":"https://static001.geekbang.org/account/avatar/00/12/e1/69/0db70c84.jpg","comment_is_top":false,"comment_ctime":1560605490,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1560605490","product_id":100017301,"comment_content":"这里就可以用到优先级队列，也可以说是堆。我们将从小文件中取出...<br>你有100个小文件，从哪一个小文件中取出呢。这里没有说明白。。。。","like_count":0},{"had_liked":false,"id":103918,"user_name":"王多鱼","can_delete":false,"product_type":"c1","uid":1480189,"ip_address":"","ucode":"6F289F7A4F41BB","user_header":"https://static001.geekbang.org/account/avatar/00/16/95/fd/5aa00179.jpg","comment_is_top":false,"comment_ctime":1560565454,"is_pvip":false,"replies":[{"id":"37643","content":"自己研究下吧，貌似不是的。","user_name":"作者回复","user_name_real":"王争","uid":"1190123","ctime":1560641004,"ip_address":"","comment_id":103918,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1560565454","product_id":100017301,"comment_content":"操作系统的定时器是不是也是使用堆来实现的？","like_count":0,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454056,"discussion_content":"自己研究下吧，貌似不是的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1560641004,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":103775,"user_name":"windcaller","can_delete":false,"product_type":"c1","uid":1514157,"ip_address":"","ucode":"1CA3E849805770","user_header":"https://static001.geekbang.org/account/avatar/00/17/1a/ad/faf1bf19.jpg","comment_is_top":false,"comment_ctime":1560507665,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1560507665","product_id":100017301,"comment_content":"定时任务这个我也觉得有问题，比如下次扫描时1h，但是添加了一个半小时后的任务，那岂不是第一次执行不到了","like_count":0},{"had_liked":false,"id":97978,"user_name":"wordMan","can_delete":false,"product_type":"c1","uid":1335088,"ip_address":"","ucode":"3C8A681EF5E278","user_header":"https://static001.geekbang.org/account/avatar/00/14/5f/30/4ae82e16.jpg","comment_is_top":false,"comment_ctime":1558858237,"is_pvip":false,"replies":[{"id":"35215","content":"如果不计算重复的，就可能只有1000万个。去除掉这个词你可能理解错了。","user_name":"作者回复","user_name_real":"王争","uid":"1190123","ctime":1559007211,"ip_address":"","comment_id":97978,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1558858237","product_id":100017301,"comment_content":"“对这 10 亿个关键词分片之后，每个文件都只有 1 亿的关键字，去除掉重复的，可能就只有 1000 万个”， 不太明白这里为什么要去掉重复的，如果重复的去掉了，后续怎么计算同一个关键字的总的搜索次数<br><br><br>","like_count":0,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":451500,"discussion_content":"如果不计算重复的，就可能只有1000万个。去除掉这个词你可能理解错了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1559007211,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":96714,"user_name":"sunsweet","can_delete":false,"product_type":"c1","uid":1027879,"ip_address":"","ucode":"787F9E1EC6A67E","user_header":"https://static001.geekbang.org/account/avatar/00/0f/af/27/76489618.jpg","comment_is_top":false,"comment_ctime":1558491989,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1558491989","product_id":100017301,"comment_content":"大开眼界，吴军老师曾经讲过，没看明白，在这理解了","like_count":0},{"had_liked":false,"id":96504,"user_name":"danvid","can_delete":false,"product_type":"c1","uid":1270415,"ip_address":"","ucode":"84C50611B1DEA5","user_header":"https://static001.geekbang.org/account/avatar/00/13/62/8f/c0f40d98.jpg","comment_is_top":false,"comment_ctime":1558435967,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1558435967","product_id":100017301,"comment_content":"问题：<br>点击量可以通过日志或者缓存记录(数据量大可以进行缓存分片)，每隔一个小时生成扫描一个K堆，同时生成一个新的散列表存储在文件中，用于累计旧数据","like_count":0},{"had_liked":false,"id":91947,"user_name":"天下行走","can_delete":false,"product_type":"c1","uid":1462449,"ip_address":"","ucode":"73A4CD8BB91235","user_header":"https://wx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLfrbMvhKQYhxP6ziaHaj4KUNRzst8u7BZsWUsazK8oTLXcNH6sDGITl6icy3IiaGFe9Iiae12LuTrF1g/132","comment_is_top":false,"comment_ctime":1557142449,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1557142449","product_id":100017301,"comment_content":"使用优先队列合并有序小文件真的是太棒了<br><br>","like_count":0},{"had_liked":false,"id":86632,"user_name":"Lucus","can_delete":false,"product_type":"c1","uid":1198800,"ip_address":"","ucode":"CE8EB70CB9D9F1","user_header":"https://static001.geekbang.org/account/avatar/00/12/4a/d0/d319c44a.jpg","comment_is_top":false,"comment_ctime":1555415634,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1555415634","product_id":100017301,"comment_content":"思考题：<br>假设在每个小时结束后统计访问日志，因为新闻网站新闻不会太多，业务上每个新闻用ID记录，可以直接用散列表统计每个新闻被访问的次数。统计完后再用堆统计出topk，最后在用ID找到新闻摘要就可以了","like_count":0},{"had_liked":false,"id":85667,"user_name":"康斯坦丁","can_delete":false,"product_type":"c1","uid":1368096,"ip_address":"","ucode":"C130E800E8D5C9","user_header":"https://static001.geekbang.org/account/avatar/00/14/e0/20/003190c1.jpg","comment_is_top":false,"comment_ctime":1555168131,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1555168131","product_id":100017301,"comment_content":"1 维护一个新闻摘要-点击次数的 哈希表,  和维护一个10个元素的小顶堆.<br>2 每点击一次新闻摘要， 更新该新闻摘要的点击次数， 判断<br>\t2.1 是否已在小顶堆中，如果在就不处理。 如果不在判断点击次数是否大于堆顶，如果大于堆顶，删除堆顶，并将该新闻插入堆中.<br>3 每隔一个小时，取堆中的10个元素，显示在banner上.","like_count":0},{"had_liked":false,"id":85323,"user_name":"正是那朵玫瑰","can_delete":false,"product_type":"c1","uid":1048261,"ip_address":"","ucode":"73D630B654573F","user_header":"https://static001.geekbang.org/account/avatar/00/0f/fe/c5/3467cf94.jpg","comment_is_top":false,"comment_ctime":1555036929,"is_pvip":false,"replies":[{"id":"31009","content":"原理上，可以只用一个定时器，不停的更新下次唤醒的时间。","user_name":"作者回复","user_name_real":"王争","uid":"1190123","ctime":1555380335,"ip_address":"","comment_id":85323,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1555036929","product_id":100017301,"comment_content":"老师好，实现高性能定时器的时候每次判断下一次需要间隔的时间执行时都要重新启动一个新的定时器么？这样是不是会比较好资源？","like_count":0,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":446630,"discussion_content":"原理上，可以只用一个定时器，不停的更新下次唤醒的时间。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1555380335,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":83359,"user_name":"未来的胡先森","can_delete":false,"product_type":"c1","uid":1234682,"ip_address":"","ucode":"AFF193AC0E2E6C","user_header":"https://static001.geekbang.org/account/avatar/00/12/d6/fa/1f5bf642.jpg","comment_is_top":false,"comment_ctime":1554544728,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1554544728","product_id":100017301,"comment_content":"课后思考：<br>1、首先后端维护一张散列表，将所有被点击新闻摘要信息存储，以新闻摘要为键 (key)，点击次数为值 (value)，实时更新。<br>2、维护一个容量为 10 的小顶堆，根据新闻的点击量放入堆中。实时更新。<br>3、前端页面每到 1 小时向后端请求 1 次数据，后端将堆中存储的排名前十对应的 key（即新闻摘要），返回前端页面。<br>","like_count":0},{"had_liked":false,"id":78786,"user_name":"何妨","can_delete":false,"product_type":"c1","uid":1385377,"ip_address":"","ucode":"EC3983BFF7992A","user_header":"https://static001.geekbang.org/account/avatar/00/15/23/a1/b08f3ee7.jpg","comment_is_top":false,"comment_ctime":1553240654,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1553240654","product_id":100017301,"comment_content":"有一个访问量非常大的新闻网站，我们希望将点击量排名 Top 10 的新闻摘要，滚动显示在网站首页 banner 上，并且每隔 1 小时更新一次。如果你是负责开发这个功能的工程师，你会如何来实现呢？<br><br>PS:总感觉师讲的问题解决方法太过笼统，希望能给出真正开发环境怎么解决。<br><br>针对课后问题，Top1的 feifei 答的很不错但我不是很懂这种文件分片的方法。<br>真实环境下如果让我开发，我的思路是：<br>1.使用Redis Hash类型存储点击量 其中 key=每篇新闻唯一id  value=点击量，新闻的每次点击会实时更新Redis存储<br>2.每小时定时 使用Top K 方法 统计出 Top 10 存入 Top 10 对应数据表中<br>3. 提供接口供前端请求访问<br><br>不知道这种方法应对海量数据是否可行，请老师指正","like_count":0},{"had_liked":false,"id":77471,"user_name":"好人","can_delete":false,"product_type":"c1","uid":1439552,"ip_address":"","ucode":"8BA995A57F7E1A","user_header":"https://static001.geekbang.org/account/avatar/00/15/f7/40/cba812dc.jpg","comment_is_top":false,"comment_ctime":1552954110,"is_pvip":false,"replies":[{"id":"28297","content":"1。空了就可以不用扫描了。可以用个数组记录下哪些文件不空<br>2. 需要记录字符串跟文件的对应关系","user_name":"作者回复","user_name_real":"gg","uid":"1190123","ctime":1552958772,"ip_address":"","comment_id":77471,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1552954110","product_id":100017301,"comment_content":"老师，在合并有序小文件中，当某个小文件中的字符串空了的时候，数组就多出了空格，这种情况是把最后一个放入这个空格中，然后继续进行堆化吗？这是不是每次都要扫描一遍哪个是空了？而且是不是需要建立一个字符串与文件的联系，让知道是哪个文件的字符串被写入写入到大文件中了。","like_count":0,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":443738,"discussion_content":"1。空了就可以不用扫描了。可以用个数组记录下哪些文件不空\n2. 需要记录字符串跟文件的对应关系","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1552958772,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":77455,"user_name":"乐凡","can_delete":false,"product_type":"c1","uid":1239260,"ip_address":"","ucode":"918C9997EB6537","user_header":"https://static001.geekbang.org/account/avatar/00/12/e8/dc/32e78f02.jpg","comment_is_top":false,"comment_ctime":1552930476,"is_pvip":false,"replies":[{"id":"28289","content":"你说的这个是数据已经存储在数组中了。有可能数据是动态的，我们事先不知道有多少数据。","user_name":"作者回复","user_name_real":"gg","uid":"1190123","ctime":1552958475,"ip_address":"","comment_id":77455,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1552930476","product_id":100017301,"comment_content":"老师，利用堆求topK那边的堆的创建可能没有讲的很直白，我的理解是小顶堆的K个元素是直接从数组中获取，比如获取该数组的前K个元素，创建一个小顶堆，然后从数组的K+1个元素进行遍历，一次和小顶堆的堆顶元素也就是最小的元素进行比较。","like_count":0,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":443730,"discussion_content":"你说的这个是数据已经存储在数组中了。有可能数据是动态的，我们事先不知道有多少数据。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1552958475,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":77003,"user_name":"麦呆小石头","can_delete":false,"product_type":"c1","uid":1229254,"ip_address":"","ucode":"1F21C9FBE2057C","user_header":"https://static001.geekbang.org/account/avatar/00/12/c1/c6/1456274a.jpg","comment_is_top":false,"comment_ctime":1552800520,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1552800520","product_id":100017301,"comment_content":"课后思考：“每隔 1 小时更新一次&quot;这个描述，有3种理解：<br>1，展示离当前时刻最近一小时的top。例如：13：30 看到的是12：30~13：30这个小时的榜单。有滑动窗口的概念。计算topK时计算量会更大。<br>2，展示固定小时的topK。例如，12：00~13：00这个时间段内，任何时候看到的都是12：00~当前时间的榜单。计算量也不小。<br>3，展示上一个小时的topK。例如：12：00~13：00这个时间段内，看到的是11：00~12：00的topK。计算量都在整点时刻。<br><br>不同的逻辑，对应生产环境中不同的实现方式和计算性能要求。","like_count":0},{"had_liked":false,"id":76482,"user_name":"李小草","can_delete":false,"product_type":"c1","uid":1240476,"ip_address":"","ucode":"83DAA0BFDC2068","user_header":"https://static001.geekbang.org/account/avatar/00/12/ed/9c/7afa883f.jpg","comment_is_top":false,"comment_ctime":1552617632,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1552617632","product_id":100017301,"comment_content":" 首页可以利用上面讲的求Top K的方法求出Top K，就是维护一个Top K的小顶堆，这个小顶堆是实时的，每当有一条新数据时就从散列表中查找，找到就次数加1并与堆顶关键词比较，如果出现次数比堆顶搜索关键词的次数多，那就删除堆顶的关键词，将这个出现次数更多的关键词加入到堆中。一个小时以后需要更新时直接取这个小顶堆去展示就可以了。（这样其实就可以实时更新到屏幕上了，不受时间局限。）","like_count":0},{"had_liked":false,"id":76323,"user_name":"搬砖的孟达","can_delete":false,"product_type":"c1","uid":1201067,"ip_address":"","ucode":"8F280479C2C83D","user_header":"https://static001.geekbang.org/account/avatar/00/12/53/ab/20f1f4e8.jpg","comment_is_top":false,"comment_ctime":1552572604,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1552572604","product_id":100017301,"comment_content":"点赞最多的好强。","like_count":0},{"had_liked":false,"id":74358,"user_name":"devil","can_delete":false,"product_type":"c1","uid":1259625,"ip_address":"","ucode":"BB6090411BAA23","user_header":"https://static001.geekbang.org/account/avatar/00/13/38/69/864569a4.jpg","comment_is_top":false,"comment_ctime":1552201716,"is_pvip":false,"replies":[{"id":"27361","content":"文中暂时不考虑你说的OOM的情况。","user_name":"作者回复","user_name_real":"gg","uid":"1190123","ctime":1552356693,"ip_address":"","comment_id":74358,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1552201716","product_id":100017301,"comment_content":"求中位数这个，动态数据，数据会越来多。两个堆无限增长会把内存吃完OOM，有没有什么优化办法，一直没想到。","like_count":0,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":442547,"discussion_content":"文中暂时不考虑你说的OOM的情况。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1552356693,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":73967,"user_name":"懒猫","can_delete":false,"product_type":"c1","uid":1206544,"ip_address":"","ucode":"B4B567A11B491D","user_header":"https://static001.geekbang.org/account/avatar/00/12/69/10/275ae749.jpg","comment_is_top":false,"comment_ctime":1552048856,"is_pvip":false,"replies":[{"id":"27374","content":"不会的。","user_name":"作者回复","user_name_real":"gg","uid":"1190123","ctime":1552358204,"ip_address":"","comment_id":73967,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1552048856","product_id":100017301,"comment_content":"通过hash取模分到10个文件中，再从10个文件中取出排名前10的再合并，如果2号文件里第十一多的关键词比1号文件里第十的还多，2号文件里的十一多的这个就漏掉了吧，是这样吗","like_count":0,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":442363,"discussion_content":"不会的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1552358204,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":72774,"user_name":"QQ怪","can_delete":false,"product_type":"c1","uid":1211223,"ip_address":"","ucode":"1A39B8433D9208","user_header":"https://static001.geekbang.org/account/avatar/00/12/7b/57/a9b04544.jpg","comment_is_top":false,"comment_ctime":1551715222,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1551715222","product_id":100017301,"comment_content":"在实战中有点用，以后会多看看","like_count":0},{"had_liked":false,"id":72358,"user_name":"江城子","can_delete":false,"product_type":"c1","uid":1004484,"ip_address":"","ucode":"28A2D7DEAE3337","user_header":"https://static001.geekbang.org/account/avatar/00/0f/53/c4/df86decb.jpg","comment_is_top":false,"comment_ctime":1551595790,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1551595790","product_id":100017301,"comment_content":"感觉堆和数组相比，主要是遍历搜索的时候更有效率，不需要去每一个都遍历，更有目的性，在需要频繁比较目标元素与一个已经排好序的数组的时候，堆的效率远远大于数组。尤其是已知排好序的数组里面元素较多时，比较次数大大降低。感觉跟跳表有点像。","like_count":0},{"had_liked":false,"id":72192,"user_name":"1024","can_delete":false,"product_type":"c1","uid":1086407,"ip_address":"","ucode":"DCC31F6EC54F43","user_header":"https://static001.geekbang.org/account/avatar/00/10/93/c7/86352ccc.jpg","comment_is_top":false,"comment_ctime":1551532800,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1551532800","product_id":100017301,"comment_content":"由堆的应用，引发的思考：堆区别与数组，是在数据结构的构建上，在更新（插入、删除）时，始终维护”堆“这种结构。维护带来的时间成本是O(logn)，数组是O(log1)，带来的查询效率提升从数组的O(nlogn)、O(n) 到O(logn)<br>而堆与其他结构，跳表、散列表等的区别是：维护的结构的不同，使用场景不同而已<br>各种数据结构的存储最后都归结于存储在连续内存存储（数组）或非连续内存存储(链表）","like_count":0},{"had_liked":false,"id":71241,"user_name":"denlaku","can_delete":false,"product_type":"c1","uid":1226083,"ip_address":"","ucode":"0D9530F8F70F75","user_header":"https://static001.geekbang.org/account/avatar/00/12/b5/63/eb77573f.jpg","comment_is_top":false,"comment_ctime":1551311202,"is_pvip":false,"replies":[{"id":"25512","content":"不需要初始化啊。","user_name":"作者回复","user_name_real":"gg","uid":"1190123","ctime":1551318245,"ip_address":"","comment_id":71241,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1551311202","product_id":100017301,"comment_content":"大顶堆小顶堆求中位数有问题。怎么初始化这两个堆才合理呢。","like_count":0,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":441063,"discussion_content":"不需要初始化啊。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1551318245,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":71028,"user_name":"Phoenix","can_delete":false,"product_type":"c1","uid":1005368,"ip_address":"","ucode":"C51BE4C948755B","user_header":"https://static001.geekbang.org/account/avatar/00/0f/57/38/ba6a106f.jpg","comment_is_top":false,"comment_ctime":1551248722,"is_pvip":false,"replies":[{"id":"25452","content":"性能会有差别的。","user_name":"作者回复","user_name_real":"gg","uid":"1190123","ctime":1551249930,"ip_address":"","comment_id":71028,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1551248722","product_id":100017301,"comment_content":"感觉高性能定时器，并不一定需要堆来实现，任何有序的数据结构都可以实现，不知道我理解是否正确，还请老师批评指正","like_count":0,"discussions":[{"author":{"id":1190123,"avatar":"https://static001.geekbang.org/account/avatar/00/12/28/eb/af064421.jpg","nickname":"王争","note":"","ucode":"2B611BE0E0EDD4","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":440947,"discussion_content":"性能会有差别的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1551249930,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":70344,"user_name":"yu","can_delete":false,"product_type":"c1","uid":1138645,"ip_address":"","ucode":"56856DCC0C8387","user_header":"https://static001.geekbang.org/account/avatar/00/11/5f/d5/2fec2911.jpg","comment_is_top":false,"comment_ctime":1551081320,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1551081320","product_id":100017301,"comment_content":"我觉得开篇思考题应该这样解决，最开始的时候就将10亿条数据分片为10个文件，每个文件一亿条数据，然后再分别将这十个文件使用哈希函数去重，将去重结果建立长度为10的最大堆，最终直接将这十个最大堆结果取出排序截取前十的结果即为最终所求的top10.不知道老师看法如何","like_count":0},{"had_liked":false,"id":69102,"user_name":"Aaaaaaaaaaayou","can_delete":false,"product_type":"c1","uid":1073601,"ip_address":"","ucode":"67BA315B87587D","user_header":"https://static001.geekbang.org/account/avatar/00/10/61/c1/93031a2a.jpg","comment_is_top":false,"comment_ctime":1550662327,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1550662327","product_id":100017301,"comment_content":"topK 是不是应该先要填满堆，后面插入的时候再做删除操作","like_count":0},{"had_liked":false,"id":68273,"user_name":"泉","can_delete":false,"product_type":"c1","uid":1099760,"ip_address":"","ucode":"914709BE802A8D","user_header":"https://static001.geekbang.org/account/avatar/00/10/c7/f0/aa2e0749.jpg","comment_is_top":false,"comment_ctime":1550474972,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1550474972","product_id":100017301,"comment_content":"堆应用:优先级队列，topk，中位数。","like_count":0},{"had_liked":false,"id":67126,"user_name":"Toon","can_delete":false,"product_type":"c1","uid":1256136,"ip_address":"","ucode":"16189FD3A4B03B","user_header":"","comment_is_top":false,"comment_ctime":1550095543,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1550095543","product_id":100017301,"comment_content":"这个问题要用map reduce做，只需要建一个top10的表，每次有人点击链接的时候就update这个表","like_count":0},{"had_liked":false,"id":62584,"user_name":"Holly陈","can_delete":false,"product_type":"c1","uid":1055655,"ip_address":"","ucode":"CBF36A96E1D2D3","user_header":"https://static001.geekbang.org/account/avatar/00/10/1b/a7/43e5dfbc.jpg","comment_is_top":false,"comment_ctime":1548117323,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1548117323","product_id":100017301,"comment_content":"动态数据求top K 的处理感觉有点问题。原文“如果比堆顶元素大，我们就把堆顶元素删除，并且将这个元素插入到堆中；如果比堆顶元素小，则不做处理。” 因为是动态数据，假如一开始就碰到一个超大数据，那这个堆可能永远都不会饱满，也不会有 TOP K啦","like_count":0},{"had_liked":false,"id":61642,"user_name":"毛启圣","can_delete":false,"product_type":"c1","uid":1330056,"ip_address":"","ucode":"233DA95ED28C11","user_header":"https://static001.geekbang.org/account/avatar/00/14/4b/88/272b4562.jpg","comment_is_top":false,"comment_ctime":1547741178,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1547741178","product_id":100017301,"comment_content":"应该需要数据库保存上次计算后所有搜索关键字次数。然后在计算当前一小时内所有关键字次数。当前小时内出现的所有关键字或之前的top-10 组成一个集合。对这个集合内元素的总搜索次数进行求top-10。最后更新1小时内出现的所有关键字搜索次数到数据库。","like_count":0},{"had_liked":false,"id":61033,"user_name":"海水","can_delete":false,"product_type":"c1","uid":1191244,"ip_address":"","ucode":"68D7E454CC0819","user_header":"https://static001.geekbang.org/account/avatar/00/12/2d/4c/983ce1b9.jpg","comment_is_top":false,"comment_ctime":1547606177,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1547606177","product_id":100017301,"comment_content":"直接用flink是不是能更好的满足需求","like_count":0},{"had_liked":false,"id":59390,"user_name":"李靖峰","can_delete":false,"product_type":"c1","uid":1139247,"ip_address":"","ucode":"AA4DE3E91A1FFA","user_header":"https://static001.geekbang.org/account/avatar/00/11/62/2f/6fe8ee9e.jpg","comment_is_top":false,"comment_ctime":1547361887,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1547361887","product_id":100017301,"comment_content":"对于求分为数的问题，如果用数据用数组存储的话，每次改动做一次排序和用两个堆比有什么劣势呢","like_count":0},{"had_liked":false,"id":58350,"user_name":"黄世仁","can_delete":false,"product_type":"c1","uid":1254911,"ip_address":"","ucode":"840C31DA4B5FAA","user_header":"","comment_is_top":false,"comment_ctime":1547042655,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1547042655","product_id":100017301,"comment_content":"在合并小文件这个部分，在PriorityQueue里不仅要保存当前的Char，还要保存当前的Char从哪个文件里来的，否则当某个Char从堆顶端dequeue后，程序就不知道该从哪个文件里往堆里查新的Char了<br>因为我们可能会有五个文件内容是<br>file1:1111111111<br>file2:2222222<br>file3:3333333<br>file4:4444444<br>file5:5555555<br><br>必须知道最开始的时候PriorityQueue里的值是12345，当第一次1没dequeue后，还要继续从file1里去补充新的Char<br><br>我写了一个Scala的实现，在https:&#47;&#47;github.com&#47;email2liyang&#47;algo&#47;commit&#47;62328ba803b546404be00bab75825a132053c1ba<br>请指正","like_count":0},{"had_liked":false,"id":56238,"user_name":"匆匆","can_delete":false,"product_type":"c1","uid":1333414,"ip_address":"","ucode":"4DB39C6CD5743B","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/H8NxrljQXliccaT5fjdXJQYS3ou3Z9ykAuKw6EgicicEA9L4jQLz3h85P0odgDSaK0cA9oTyUKibbiagdNvnHuuV5mQ/132","comment_is_top":false,"comment_ctime":1546410559,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1546410559","product_id":100017301,"comment_content":"堆的应用<br><br>应用一：优先级队列<br>思想简单总结：将优先级的之分的数据存入堆中（小顶堆或者大顶堆），堆顶即优先级最搞的数据，当需要的时候直接取堆顶，然后堆顶补充下一优先级数据，由于堆堆顶插入或者删除数据时间复杂度都是O(logn)，所以效率很高。<br><br>例1：合并有序小文件。加入由100个小文件，每个文件中存放的都是一些有序的字符串片段，如果要合并成一个大文件，用常规的数组取字符串需要遍历整个数组，若将从小文件中取出来的字符串放到小顶堆中，每次取堆顶字符串然后删除，效率提高。<br><br>例2：高性能定时器。若有个定时器维护了很多定时任务，定时器每隔1秒就要扫描一边任务列表看有没有到时间要执行的，效率就很低。如果把任务时间按优先级放进堆中。定时器只计算对于堆顶任务的时间差，到时间了取触发然后删除堆顶，再计算下一个堆顶的时间差，到时间再触发。效率提高。<br><br>应用二：利用堆求Top K<br>思想简答总结：求top K问题分成两类，一类是对于静态数据，思路是我们先维护一个大小位K的小顶堆，然后遍历数据，每个数据同堆顶元素比较，如果比堆顶元素小则不处理，否则替换堆顶元素。遍历完后堆中数据就是前K大数据了。动态数据一样，只是会有元素添加，那么就将添加的元素同堆顶元素作比较即可。这样无论合适要前K大元素都能立刻返回给它。<br><br>应用三：求中位数。这个用到了再看。。","like_count":0},{"had_liked":false,"id":55244,"user_name":"seamoontime","can_delete":false,"product_type":"c1","uid":1235304,"ip_address":"","ucode":"09E36EAE215355","user_header":"https://static001.geekbang.org/account/avatar/00/12/d9/68/38703855.jpg","comment_is_top":false,"comment_ctime":1546075242,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1546075242","product_id":100017301,"comment_content":"求中位数时，维护两个堆，一个大顶堆，一个小顶堆，这两个堆是怎么创建的。是先排序已有的数据再创建两个堆，然后不断地添加新数据吗。<br><br>","like_count":0,"discussions":[{"author":{"id":1047733,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/fc/b5/ac717737.jpg","nickname":"肖臧","note":"","ucode":"4FAC9FF54DD6A0","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435,"discussion_content":"大顶堆和小顶堆的初始化是动态建立的。你可以理解为从零开始建立一个大顶堆和一个小顶堆，把需要求解中位数的数组里的数据，顺序的放入大顶堆或者小顶堆，放数据的规则其实就是老师说的动态调整规则。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561555019,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":53625,"user_name":"王鸿运","can_delete":false,"product_type":"c1","uid":1068577,"ip_address":"","ucode":"14AF7B485D29A1","user_header":"https://static001.geekbang.org/account/avatar/00/10/4e/21/700586eb.jpg","comment_is_top":false,"comment_ctime":1545702073,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1545702073","product_id":100017301,"comment_content":"对搜索关键词的统计可以利用trie树，这样字符串的公共前缀就可以公用内存了","like_count":0},{"had_liked":false,"id":52936,"user_name":"雄哼哼","can_delete":false,"product_type":"c1","uid":1079380,"ip_address":"","ucode":"A9C9FA98357D4A","user_header":"https://static001.geekbang.org/account/avatar/00/10/78/54/0aafbf5e.jpg","comment_is_top":false,"comment_ctime":1545554327,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1545554327","product_id":100017301,"comment_content":"这篇总结的不错","like_count":0},{"had_liked":false,"id":52455,"user_name":"追风者","can_delete":false,"product_type":"c1","uid":1055092,"ip_address":"","ucode":"879BC372A6B605","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIjUDIRQ0gRiciax3Wo78c5rVjuWDiaw4ibcCiby8xiaMXJh5ibjU5242vfCGOK4ehibe1IKyxex2A4IX4XSA/132","comment_is_top":false,"comment_ctime":1545385531,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1545385531","product_id":100017301,"comment_content":"1.每隔一小时收集一次点击日志，然后对日志文件中的新闻url做hash取模，比如mod 10，生成10个小文件。<br>2.然后利用哈希表对每个小文件的url做word count。<br>3.对于每个小文件，构建一个大小为10的小顶堆，存储top10的url。<br>4.用数组存储这10个小顶堆的数据，利用归并排序进行排序。<br>5.取出top10，展示banner。","like_count":0},{"had_liked":false,"id":50950,"user_name":"陈道恒","can_delete":false,"product_type":"c1","uid":1189021,"ip_address":"","ucode":"07A0695DEFA270","user_header":"https://static001.geekbang.org/account/avatar/00/12/24/9d/ba45ff4a.jpg","comment_is_top":false,"comment_ctime":1545092977,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1545092977","product_id":100017301,"comment_content":"这一篇收获很大，完全没打瞌睡。","like_count":0},{"had_liked":false,"id":49805,"user_name":"色即是空","can_delete":false,"product_type":"c1","uid":1189638,"ip_address":"","ucode":"46B8975ED087B8","user_header":"https://static001.geekbang.org/account/avatar/00/12/27/06/7ab75a5b.jpg","comment_is_top":false,"comment_ctime":1544771913,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1544771913","product_id":100017301,"comment_content":"1、优先级队列；<br>如：赫夫曼树、图的最短路径‘最小生成树算法<br>合并100个小文件到一个大文件：读取一个，比较，选择最小放入大文件，用堆的方式可以有效的提高速度（从O(n) ---O(logn)）<br>高性能定时器；对于需要执行的队列先后排序<br><br>2、Top K；<br>维护一个K长度的堆，时间复杂度O(nlogK)<br><br>3、 中位数<br>99%响应时间<br>通过维护两个堆实现中位数和99%响应时间的提取","like_count":0},{"had_liked":false,"id":49581,"user_name":"桂","can_delete":false,"product_type":"c1","uid":1188837,"ip_address":"","ucode":"658E79A26B64A4","user_header":"https://static001.geekbang.org/account/avatar/00/12/23/e5/6cca9bcf.jpg","comment_is_top":false,"comment_ctime":1544721449,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1544721449","product_id":100017301,"comment_content":"思考题：<br>假设该网站有一亿条新闻，一亿条新闻存在多个文件里，例如一万个文件，那么每个文件存1万条新闻，每条新闻摘要的字段有id、内容、点击次数，第一个文件存的是id为1-10000的新闻，第二个文件存的是id为10001-20000的新闻，以此类推，当有新闻被点击时，我们根据被点击的新闻id，到对应的文件里查找到该新闻，实时累加点击次数。<br>同时，我们根据1万个文件，对应维护1万个top10小顶堆，当有新闻被点击时，如果该新闻属于分文件top10中的新闻，则直接累加次数，如果不属于，累加完次数后，还要和小顶堆的堆定元素的次数比较大小，如果大于堆顶元素，则删除堆顶元素，插入该最新点击的新闻并堆化。<br>那么，每到1小时，要计算出总Top10的时候，我们把1万个top10堆，合并成一个top10堆，拿到总top10的id，到对应的文件里拿具体的新闻摘要即可。<br><br>内存占用： 1万个top10小顶堆，及10万个元素，每个元素包含id和点击次数，假设都是long型，即共2*8*100000个字节 = 1.5M。<br><br>点击新闻时的时间分析：<br>1、如果采用数据库表的形式存储分片数据，点击新闻时的点击数累加和维护分文件top10堆的时间基本可以忽略。<br>2、每一个小时，计算总Top10的时间复杂度O(logn)","like_count":0},{"had_liked":false,"id":49512,"user_name":".&#47;+-@YOU","can_delete":false,"product_type":"c1","uid":1248827,"ip_address":"","ucode":"14CCC17DDFFDB6","user_header":"https://static001.geekbang.org/account/avatar/00/13/0e/3b/42288ae6.jpg","comment_is_top":false,"comment_ctime":1544702893,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1544702893","product_id":100017301,"comment_content":"1. 合并有序小文件：这个例子中“往堆中插入数据的时间复杂度都是 O(logn)，n 表示100。”这里n也不一定是100吧，有可能是99、98、97...3这几种情况吧（当有的文件已经先被处理完了）<br><br>极客时间版权所有: https:&#47;&#47;time.geekbang.org&#47;column&#47;article&#47;70187","like_count":0},{"had_liked":false,"id":47902,"user_name":"xavier","can_delete":false,"product_type":"c1","uid":1243128,"ip_address":"","ucode":"2F7918EA37ED9F","user_header":"https://static001.geekbang.org/account/avatar/00/12/f7/f8/3c0a6854.jpg","comment_is_top":false,"comment_ctime":1544251586,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1544251586","product_id":100017301,"comment_content":"原来RT-Thread嵌入式系统里面的定时器，就用的文中提到的高性能定时器。感谢老师的讲解。","like_count":0},{"had_liked":false,"id":47505,"user_name":"Leoorz","can_delete":false,"product_type":"c1","uid":1030657,"ip_address":"","ucode":"8912628AD6ADE0","user_header":"https://static001.geekbang.org/account/avatar/00/0f/ba/01/5ce8ce0b.jpg","comment_is_top":false,"comment_ctime":1544148544,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1544148544","product_id":100017301,"comment_content":"老师，看完  合并‘有序’小文件  那节，并未感觉对有序有什么要求，这个‘有序’要求的点在哪里哩？","like_count":0},{"had_liked":false,"id":46874,"user_name":"DigDeeply","can_delete":false,"product_type":"c1","uid":1239008,"ip_address":"","ucode":"113F4D755A1FEC","user_header":"https://static001.geekbang.org/account/avatar/00/12/e7/e0/33521e13.jpg","comment_is_top":false,"comment_ctime":1543995427,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1543995427","product_id":100017301,"comment_content":"这篇不错，通读了一遍，感觉有点意思，我的代码实践还没练习到这章。后续一定把这篇的实例好好实践下。🤗","like_count":0},{"had_liked":false,"id":45209,"user_name":"拥翠湖","can_delete":false,"product_type":"c1","uid":1125888,"ip_address":"","ucode":"F75EC81EDD7254","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eol56Kczota5r0kFQORibLPWnuerPgOHHmSuE2XrdcP1tYjia5rEBickgMlfErMibSUeQRXpLnaib3ySEA/132","comment_is_top":false,"comment_ctime":1543561123,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1543561123","product_id":100017301,"comment_content":"合并有序小文件，把拿出来的值可以放入一个有序数组中进行比较，以后每次从文件中拿一个元素进行二分查找放入数组中，然后拿第一个元素放入大文件中，这个时间复杂度也是logn，也可以不用堆吧？","like_count":0},{"had_liked":false,"id":45207,"user_name":"Wy 🐠","can_delete":false,"product_type":"c1","uid":1261176,"ip_address":"","ucode":"F37AAED71DBAC3","user_header":"https://static001.geekbang.org/account/avatar/00/13/3e/78/0654bcc1.jpg","comment_is_top":false,"comment_ctime":1543560750,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1543560750","product_id":100017301,"comment_content":"“对于一组静态数据，中位数是固定的，我们可以先排序” 好像不需要排序呀，之前的章节讲过求第k大的数可以用类似快排思想的快速选择方法，时间复杂度O(n)，这个求中位数只需要k=n&#47;2(如果数据个数是偶数)就好了","like_count":0},{"had_liked":false,"id":45068,"user_name":"这么写的闫","can_delete":false,"product_type":"c1","uid":1246059,"ip_address":"","ucode":"95B0D1E1A094C8","user_header":"https://static001.geekbang.org/account/avatar/00/13/03/6b/f31d4538.jpg","comment_is_top":false,"comment_ctime":1543543030,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1543543030","product_id":100017301,"comment_content":"哈哈，这一节有意思","like_count":0},{"had_liked":false,"id":45058,"user_name":"Ryoma","can_delete":false,"product_type":"c1","uid":1130590,"ip_address":"","ucode":"7F692369239692","user_header":"https://static001.geekbang.org/account/avatar/00/11/40/5e/b8fada94.jpg","comment_is_top":false,"comment_ctime":1543541830,"is_pvip":true,"discussion_count":0,"race_medal":2,"score":"1543541830","product_id":100017301,"comment_content":"关于课后问题这部分，因为热搜会随着时间不断变化，我觉得它属于动态数据的一个变种。但是我目前的思路还只停留在TopK的问题上，对于这种类型的动态更新（比如一个小时更新一次），现在脑中没有效率高的处理办法，每个小时重新建立堆的效率感觉有点低，老师是否能指点一下","like_count":0},{"had_liked":false,"id":44799,"user_name":"Jerry银银","can_delete":false,"product_type":"c1","uid":1008404,"ip_address":"","ucode":"80DA1172A2360A","user_header":"https://static001.geekbang.org/account/avatar/00/0f/63/14/06eff9a4.jpg","comment_is_top":false,"comment_ctime":1543494461,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1543494461","product_id":100017301,"comment_content":"明天应该到图了吧。   好期待呀！ ","like_count":0},{"had_liked":false,"id":44796,"user_name":"hot","can_delete":false,"product_type":"c1","uid":1237803,"ip_address":"","ucode":"567921754BE860","user_header":"https://static001.geekbang.org/account/avatar/00/12/e3/2b/c6de8f27.jpg","comment_is_top":false,"comment_ctime":1543494409,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1543494409","product_id":100017301,"comment_content":"我们可以维护一个大小为 K 的小顶堆？ 这是啥意思啊<br><br>","like_count":0},{"had_liked":false,"id":44761,"user_name":"小文同学","can_delete":false,"product_type":"c1","uid":1001893,"ip_address":"","ucode":"48F2AEB989C12A","user_header":"https://static001.geekbang.org/account/avatar/00/0f/49/a5/e4c1c2d4.jpg","comment_is_top":false,"comment_ctime":1543487576,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1543487576","product_id":100017301,"comment_content":"记录点击日志，每一小时读取一次小时日志用于计算top-k问题。<br>","like_count":0},{"had_liked":false,"id":44596,"user_name":"他在她城断了弦","can_delete":false,"product_type":"c1","uid":1242521,"ip_address":"","ucode":"3D91CA87B64C8B","user_header":"https://static001.geekbang.org/account/avatar/00/12/f5/99/454b17c1.jpg","comment_is_top":false,"comment_ctime":1543461137,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1543461137","product_id":100017301,"comment_content":"老师后面会讲AVL树吗？","like_count":0},{"had_liked":false,"id":44580,"user_name":"老杨同志","can_delete":false,"product_type":"c1","uid":1246199,"ip_address":"","ucode":"3F334F0CFD3DE6","user_header":"https://static001.geekbang.org/account/avatar/00/13/03/f7/3a493bec.jpg","comment_is_top":false,"comment_ctime":1543459130,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1543459130","product_id":100017301,"comment_content":"@美团点评技术团队<br>你提的问题“<br>王老师 第一点合并有序小文件 为什么要用到优先级队列 和 堆还是不理解。两个比最小取出合并，只要两个数组是有序就可以了，快排成有序，从小到大比较合并，不可以吗，为什么要用到优先级队列，方便老师解答下吗“ 我是这样理解的。<br>两个有序文件的合并是可以直接比较大小的，类似归并排序的合并。但是老师的方法适合于几十个，上个百个有序文件的合并，多个数字求最大直接遍历是O(n),放到堆里是O(logn)。<br>多个文件两两合并，最后也能合并成一个，但是要生成多个中间临时文件，效率低。","like_count":0},{"had_liked":false,"id":44475,"user_name":"Kong","can_delete":false,"product_type":"c1","uid":1211315,"ip_address":"","ucode":"D1BB2649F1CF84","user_header":"https://static001.geekbang.org/account/avatar/00/12/7b/b3/37b2b73d.jpg","comment_is_top":false,"comment_ctime":1543452285,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1543452285","product_id":100017301,"comment_content":"关于把5G文件分片成10个文件的问题，有点不明白，内存只有1G，是怎么做到把整个文件读到内存中再通过hash算法去分片的？请老师解惑","like_count":0},{"had_liked":false,"id":44430,"user_name":"Jeremy","can_delete":false,"product_type":"c1","uid":1171998,"ip_address":"","ucode":"F342D2EC14773C","user_header":"https://static001.geekbang.org/account/avatar/00/11/e2/1e/ea3a0366.jpg","comment_is_top":false,"comment_ctime":1543444626,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1543444626","product_id":100017301,"comment_content":"思考题：<br>1.全量统计摘要和对应的点击率<br>2.用hashheap(小顶堆，按点击率建堆)计算topK；使用hash table定位摘要，用heap对点击率排序<br>3.每小时增量统计摘要和对应的点击率<br>4.用过去一小时的点击率，修改当前hashheap。时间复杂度：找到对应摘要用O(1)，增加或修改点击率后heapify用O(logk)","like_count":0},{"had_liked":false,"id":44311,"user_name":"纯洁的憎恶","can_delete":false,"product_type":"c1","uid":1130512,"ip_address":"","ucode":"5E9757DE6F45DF","user_header":"https://static001.geekbang.org/account/avatar/00/11/40/10/b6bf3c3c.jpg","comment_is_top":false,"comment_ctime":1543404897,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1543404897","product_id":100017301,"comment_content":"用堆实现动态变化的优先级队列，可以在动态保证队列次序的前提下，以O（logn）的时间复杂度完成出队和入队操作。通过大顶堆和小顶堆实现动态查找中位数和百分位数的方法尤为巧妙。<br><br>课前思考题与课后思考题的类型近似，解决方法也可以相同。我能想到的新闻与新闻的点击率都是动态变化的，不仅需要实时更新新闻摘要与点击率，还要每过一个小时，做一遍哈希分片、分片TOPK、合并TOPK。有没有更快捷、简便的方法呢？","like_count":0},{"had_liked":false,"id":44217,"user_name":"猫头鹰爱拿铁","can_delete":false,"product_type":"c1","uid":1105958,"ip_address":"","ucode":"24266B58968428","user_header":"https://static001.geekbang.org/account/avatar/00/10/e0/26/4942a09e.jpg","comment_is_top":false,"comment_ctime":1543386529,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1543386529","product_id":100017301,"comment_content":"思考题：访问量很大，有可能超过Integer.Max。考虑先使用队列存储用户的新闻请求，如果队列数满了就再起一个队列。那么存储用户新闻请求队列的数据结构可以考虑linkedblockingqueque&lt;linkedblockingqueue&lt;News&gt;&gt;。一个队列满了也差不多有48gb数据（(16+8)*2^31&#47;1024^3，大概21亿请求）接着就是对数据进行处理。如果是单机处理，真的很困难，那么得考虑数据量超过多少时序列化，存储到磁盘上。然后再取出数据进行排序。这个方法不是很好，io很影响性能。那么可以换一个方式，考虑对数据分片用多台计算机进行分布式的计算。首先news.hashcode%计算机数量，将news划分到不同的机子上处理，可以利用散列表，计算&lt;news,count&gt;,遍历的时候建立size为10的小顶堆。如果散列表遍历的数量大于堆顶数据，则移除，添加散列表的这个数据。每台计算机这样计算得到小顶堆后拿出自己出现最多的10个news（小顶堆）每隔一小时进行汇总再进行比较得到最多的10个news。","like_count":0},{"had_liked":false,"id":44193,"user_name":"komo0104","can_delete":false,"product_type":"c1","uid":1084059,"ip_address":"","ucode":"90C40C69F7CC93","user_header":"https://static001.geekbang.org/account/avatar/00/10/8a/9b/feb182d3.jpg","comment_is_top":false,"comment_ctime":1543381221,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1543381221","product_id":100017301,"comment_content":"每条新闻都在数据库里维护点击量。<br>每小时把日志中的增量数据一次性统计并更新到数据库。<br>将更新了点击次数的新闻与原本的top10进行比较，用priorityqueue实现。","like_count":0},{"had_liked":false,"id":44105,"user_name":"Jsoulan","can_delete":false,"product_type":"c1","uid":1133856,"ip_address":"","ucode":"2FA0997D2D77DE","user_header":"https://static001.geekbang.org/account/avatar/00/11/4d/20/02a1d4ac.jpg","comment_is_top":false,"comment_ctime":1543369327,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1543369327","product_id":100017301,"comment_content":"如何在一个包含 n 个数据的数组中，查找前 K 大数据呢？我们可以维护一个大小为 K 的小顶堆，顺序遍历数组，从数组中取出取数据与堆顶元素比较。如果比堆顶元素大，我们就把堆顶元素删除，并且将这个元素插入到堆中；如果比堆顶元素小，则不做处理，继续遍历数组。<br><br>数据比堆顶元素大，是不是应该堆空间满了的时候才删除堆顶，如果堆不满，就直接将元素插入堆中","like_count":0},{"had_liked":false,"id":44102,"user_name":"凡","can_delete":false,"product_type":"c1","uid":1041878,"ip_address":"","ucode":"BCF83BE1D434D4","user_header":"https://static001.geekbang.org/account/avatar/00/0f/e5/d6/37a1be71.jpg","comment_is_top":false,"comment_ctime":1543369240,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1543369240","product_id":100017301,"comment_content":"看到最后那个1G取top10的例子，很佩服笔者的算法运用能力呀！怎么才能有这么融会贯通的算法能力呢？","like_count":0},{"had_liked":false,"id":44096,"user_name":"拉欧","can_delete":false,"product_type":"c1","uid":1206605,"ip_address":"","ucode":"40996A8093A95F","user_header":"https://static001.geekbang.org/account/avatar/00/12/69/4d/81c44f45.jpg","comment_is_top":false,"comment_ctime":1543368832,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1543368832","product_id":100017301,"comment_content":"可以用Redis的zset直接实现","like_count":0},{"had_liked":false,"id":44084,"user_name":"Demter","can_delete":false,"product_type":"c1","uid":1158439,"ip_address":"","ucode":"BE3B6F726916CE","user_header":"https://static001.geekbang.org/account/avatar/00/11/ad/27/5556ae50.jpg","comment_is_top":false,"comment_ctime":1543368032,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1543368032","product_id":100017301,"comment_content":"讲得很清楚","like_count":0},{"had_liked":false,"id":44010,"user_name":"vortual","can_delete":false,"product_type":"c1","uid":1258515,"ip_address":"","ucode":"1161CD103110C0","user_header":"https://static001.geekbang.org/account/avatar/00/13/34/13/d43ff5ed.jpg","comment_is_top":false,"comment_ctime":1543364908,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1543364908","product_id":100017301,"comment_content":"兄弟，你们先走，我随后就到……","like_count":0},{"had_liked":false,"id":44008,"user_name":"hughieyu","can_delete":false,"product_type":"c1","uid":1206690,"ip_address":"","ucode":"FC1A64B2BAB784","user_header":"https://static001.geekbang.org/account/avatar/00/12/69/a2/c30ac459.jpg","comment_is_top":false,"comment_ctime":1543364772,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1543364772","product_id":100017301,"comment_content":"1.当点击时先用散列表计数，key是新闻唯一id<br><br>2.用索引堆(小顶堆)存储topK的数据，依据次数排序，然后从散列表取出当前点击数据，根据索引，也就是唯一的id判断这条新闻是否已经在堆中存在，如果存在则更新，如果不存在，则看堆中元素数量是否已经等于k，如果小于直接插入，否则和堆顶元素比较，如果大于堆顶元素就删除堆顶元素，然后将此元素插入，否则本次操作结束。<br><br>3.取出的时候直接取出就好。<br><br>问题<br>1.不用索引堆如何高效去重？<br><br>第一次回答，大神勿喷","like_count":0},{"had_liked":false,"id":44007,"user_name":"hughieyu","can_delete":false,"product_type":"c1","uid":1206690,"ip_address":"","ucode":"FC1A64B2BAB784","user_header":"https://static001.geekbang.org/account/avatar/00/12/69/a2/c30ac459.jpg","comment_is_top":false,"comment_ctime":1543364771,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1543364771","product_id":100017301,"comment_content":"1.当点击时先用散列表计数，key是新闻唯一id<br><br>2.用索引堆(小顶堆)存储topK的数据，依据次数排序，然后从散列表取出当前点击数据，根据索引，也就是唯一的id判断这条新闻是否已经在堆中存在，如果存在则更新，如果不存在，则看堆中元素数量是否已经等于k，如果小于直接插入，否则和堆顶元素比较，如果大于堆顶元素就删除堆顶元素，然后将此元素插入，否则本次操作结束。<br><br>3.取出的时候直接取出就好。<br><br>问题<br>1.不用索引堆如何高效去重？<br><br>第一次回答，大神勿喷","like_count":0},{"had_liked":false,"id":43990,"user_name":"失火的夏天","can_delete":false,"product_type":"c1","uid":1241770,"ip_address":"","ucode":"10C6E66EB2A65F","user_header":"https://static001.geekbang.org/account/avatar/00/12/f2/aa/32fc0d54.jpg","comment_is_top":false,"comment_ctime":1543362600,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1543362600","product_id":100017301,"comment_content":"个人思路是定时任务+哈希表+小顶堆，定时任务配小顶堆，top10也是一个小顶堆的处理","like_count":0}]}