{"id":496746,"title":"14 | 百科应用系统设计：机房被火烧了系统还能访问吗？","content":"<p>你好，我是李智慧。</p><p>百科知识应用网站是互联网应用中一个重要的类别。很多人上网是为了获取知识，而互联网上的信息良莠并存，相对说来，百科知识应用网站能为普通人提供较为可信的信息。因此，百科知识网站虽然功能单一、设计简单，但是依然撑起了互联网的一片天空：维基百科是全球访问量TOP10的网站，百度百科是百度的核心产品之一。</p><p>我们准备开发一个供全球用户使用的百科知识应用系统，系统名称为“Wepedia”。</p><p>Wepedia的功能比较简单，只有编辑词条和搜索查看词条这两个核心功能。但是Wepedia的设计目标是支撑每日10亿次以上的访问压力。因此设计目标主要是简单、高效地支持高并发访问，以及面对全球用户时保证$\\small 7\\times24$小时高可用。</p><h2>概要设计</h2><p>Wepedia的整体架构，也就是简化的部署模型如图。</p><p><img src=\"https://static001.geekbang.org/resource/image/c5/07/c54a096ec9ab2ea396a3a41f1ed0cf07.jpg?wh=1920x1319\" alt=\"图片\"></p><p>在梳理Wepedia整体逻辑之前，先说明下架构图中核心组件的作用。</p><p><img src=\"https://static001.geekbang.org/resource/image/44/04/4498948b93aa7c8c0cb1fb25d1b54704.jpg?wh=1920x1976\" alt=\"图片\"></p><p>用户在Web端查看一个百科词条的时候，首先通过GeoDNS进行域名解析，得到离用户最近的数据中心所属的CDN服务器的IP地址。用户浏览器根据这个IP地址访问CDN服务器，如果CDN服务器上缓存有用户访问的词条内容，就直接返回给用户；如果没有，CDN会访问和自己在同一个区域的Wepedia的数据中心服务器。</p><!-- [[[read_end]]] --><p>准确地说，CDN访问的是Wepedia数据中心负载均衡服务器LVS的IP地址。请求到达LVS后，LVS会将该请求分发到某个Nginx服务器上。Nginx收到请求后，也查找自己服务器上是否有对应的词条内容，如果没有，就将请求发送给第二级LVS负载均衡服务器。</p><p>接着，第二级LVS将请求分发给某个Apache服务器，Apache会调用PHP程序处理该请求。PHP程序访问Redis服务器集群，确认是否有该词条的对象。如果有，就将该对象封装成HTML响应内容，返回给用户；如果没有，就访问MySQL数据库来查找该词条的数据内容。PHP程序一方面会将MySQL返回的数据构造成对象，然后封装成HTML返回用户，一方面会将该对象缓存到Redis。</p><p>如果用户的HTTP请求是一个图片，那么Nginx则会访问LightHttp服务器，获取图片内容。</p><p>因为Nginx缓存着词条内容，那么当词条编辑者修改了词条内容时，Nginx缓存的词条内容就会成为脏数据。解决这个问题通常有两种方案，一种是设置失效时间，到了失效时间，缓存内容自动失效，Nginx重新从Apache获取最新的内容。但是这种方案并不适合Wepedia的场景，因为词条内容不会经常被编辑，频繁失效没有意义，只是增加了系统负载压力；而且，在失效时间到期前，依然有脏数据的问题。</p><p>Wepedia为了解决Nginx缓存失效的问题，采用了另一种解决方案：失效通知。词条编辑者修改词条后，Invalidation notification模块就会通知所有Nginx服务器，该词条内容失效，进而从缓存中删除它。这样，当用户访问的时候，就不会得到脏数据了。</p><p><strong>多数据中心架构</strong></p><p>Wepedia在全球部署多个数据中心，可以就近为用户提供服务。因为即使是最快的光纤网络，从地球一端访问另一端的数据中心，在通信链路上的延迟就需要近150ms。</p><p>$\\small （地球周长4万KM\\div2）\\div光速30万KM/s\\times请求响应2次通信\\approx133ms$</p><p>150ms是一个人类能够明显感知的卡顿时间。再加上服务器的处理时间，用户的响应等待时间可能会超过1秒钟，而页面加载时间超过1秒钟，用户就会明显不耐烦。多数据中心架构可以通过GeoDNS为用户选择最近的数据中心服务器，减少网络通信延迟，提升用户体验。</p><p>另一方面，多数据中心还具有容灾备份功能，如果因为天灾或者人祸导致某个数据中心机房不可用，那么用户还可以访问其他数据中心，保证Wepedia是可用的。</p><p>但是多数据中心需要解决<strong>数据一致性</strong>的问题：如果词条编辑者修改词条内容，只记录在距离自己最近的数据中心，那么这份数据就会和其他数据中心的不一致。所以，Wepedia需要在多个数据中心之间进行数据同步，用户不管访问哪个数据中心，看到的词条内容都应该是一样的。</p><p>Wepedia的多数据中心架构如图。</p><p><img src=\"https://static001.geekbang.org/resource/image/8c/18/8cfc983d9368ed7c931026b96953e218.jpg?wh=1920x1742\" alt=\"图片\"></p><p>Wepedia的多数据中心架构为一主多从架构，即一个主数据中心，多个从数据中心。如果用户请求是Get请求（读请求），那么请求就会在该数据中心处理。如果请求是Post请求（写请求），那么请求到达Nginx的时候，Nginx会判断自己是否为主数据中心，如果是，就直接在该数据中心处理请求；如果不是，Nginx会将该Post请求转发给主数据中心。</p><p>通过这种方式，主数据中心根据Post请求更新数据库后，再通过Canal组件将更新同步给其他所有从数据中心的MySQL，从而使所有数据中心的数据保持一致。同样，LightHttp中的图片数据也进行同步，开发LightHttp插件，将收到的图片，发送给所有从数据中心。</p><p>数据中心之间采用类似ZooKeeper的选主策略进行通信，如果主数据中心不可用，其他数据中心会重新选举一个主数据中心。而如果某个从数据中心失火了，用户请求域名解析到其他数据中心即可。</p><p>这种多数据中心架构虽然使词条编辑操作的时间变长，但是由于Wepedia的绝大多数请求都是Get请求（Get与Post请求比超过1000：1），因此对系统的整体影响并不很大。同时用一种简单、廉价的方式实现多数据中心的数据一致性，开发和运维成本都比较低。</p><h2>详细设计</h2><p>作为一个百科服务类网站，Wepedia 主要面临的挑战是：应对来自全球各地的巨量并发的词条查询请求。因此详细设计重点关注Wepedia的性能优化。</p><h4>前端性能优化</h4><p>前端是指应用服务器（也就是 PHP 服务器）之前的部分，包括 DNS 服务、 CDN 服务、反向代理服务、静态资源服务等。对 Wepedia 而言，80% 以上的用户请求可以通过前端服务返回，请求根本不会到达应用服务器，这也就使得网站最复杂、最有挑战的PHP应用服务端和存储端压力骤减。</p><p>Wepedia 前端架构的核心是反向代理服务器 Nginx 集群，大约需要部署数十台服务器。请求通过 LVS 负载均衡地分发到每台 Nginx 服务器，热点词条被缓存在这里，大量请求可直接返回响应，减轻应用负载压力。而Nginx 缓存 不能命中的请求，会再通过 LVS 发送到 Apache 应用服务器集群。</p><p>在反向代理 Nginx 之前，是 CDN 服务，它对于 Wepedia 性能优化功不可没。因为用户查询的词条大部分集中在比重很小的热点词条上，这些词条内容页面缓存在 CDN 服务器上，而 CDN 服务器又部署在离用户浏览器最近的地方，用户请求直接从 CDN 返回，响应速度非常快，这些请求甚至根本不会到达 Wepedia 数据中心的 Nginx 服务器，服务器压力减小，节省的资源可以更快地处理其他未被 CDN 缓存的请求。</p><p>Wepedia CDN 缓存的几条准则：</p><ol>\n<li>内容页面不包含动态信息，以免页面内容缓存很快失效或者包含过时信息。</li>\n<li>每个内容页面有唯一的 REST 风格的 URL，以便 CDN 快速查找并避免重复缓存。</li>\n<li>在 HTML 响应头写入缓存控制信息，通过应用控制内容是否缓存及缓存有效期等。</li>\n</ol><h4><strong>服务端性能优化</strong></h4><p>服务端主要是 PHP 服务器，这里是业务逻辑的核心部分，运行的模块都比较复杂笨重，需要消耗较多的资源，Wepedia 需要将最好的服务器部署在这里（和数据库配置一样的服务器），从硬件上改善性能。</p><p>除了硬件改善，Wepedia 还需要使用其他开源组件对应用层进行优化：</p><ol>\n<li>使用 APC，这是一个 PHP 字节码缓存模块，可以加速代码执行，减少资源消耗。</li>\n<li>使用 Tex 进行文本格式化，特别是将科学公式内容转换成图片格式。</li>\n<li>替换 PHP 的字符串查找函数 strtr()，使用更优化的算法重构。</li>\n</ol><h4>存储端性能优化</h4><p>包括缓存、存储、数据库等被应用服务器依赖的服务都可以归类为存储端服务。存储端服务通常是一些有状态的服务，即需要进行数据存储。这些服务大多建立在网络通信和磁盘操作基础上，是性能的瓶颈，也是性能优化的关键环节。</p><p>存储端优化最主要的手段是使用缓存，将热点数据缓存在分布式缓存系统的内存中，加速应用服务器的数据读操作速度，减轻存储和数据库服务器的负载。</p><p>Wepedia 的缓存使用策略如下：</p><ol>\n<li>热点特别集中的数据直接缓存到应用服务器的本地内存中，因为要占用应用服务器的内存且每台服务器都需要重复缓存这些数据，因此这些数据量很小，但是读取频率极高。</li>\n<li>缓存数据的内容尽量是应用服务器可以直接使用的格式，比如 HTML 格式，以减少应用服务器从缓存中获取数据后解析构造数据的代价。</li>\n<li>使用缓存服务器存储 session 对象。</li>\n</ol><p>作为存储核心数据资产的 MySQL 数据库，需要做如下优化：</p><ol>\n<li>使用较大的服务器内存。在 Wepedia 应用场景中，增加内存比增加其他资源更能改善 MySQL 性能。</li>\n<li>使用 RAID5 磁盘阵列以加速磁盘访问。</li>\n<li>使用MySQL 主主复制及主从复制，保证数据库写入高可用，并将读负载分散在多台服务器。</li>\n</ol><h2>小结</h2><p>高可用架构中的各种策略，基本上都是针对一个数据中心内的系统架构、针对服务器级别的软硬件故障而进行设计的。但如果整个数据中心都不可用，比如数据中心所在城市遭遇了地震，机房遭遇了火灾或者停电，不管我们架构的设计多么的高可用，应用依然是不可用的。</p><p>为了解决这个问题，同时也为了提高系统的处理能力、改善用户体验，很多大型互联网应用都采用了异地多活的多机房架构策略，也就是说将数据中心分布在多个不同地点的机房里，这些机房都可以对外提供服务。用户可以连接任何一个机房进行访问，这样每个机房都可以提供完整的系统服务，即使某一个机房不可使用，系统也不会宕机，依然保持可用。</p><h2>思考题</h2><p>词条编辑者修改词条的时候，可能会同时修改（新增）词条文本和图片。而数据从主数据中心同步到多个从数据中心的时候，数据库同步可能和图片同步时间不一致，导致用户查看词条的时候，图片无法加载或者图片和文本内容不一致。</p><p>如何解决这个问题？</p><p>附1：阿里巴巴在十几年前，也遇到数据和图片同步不一致的问题，后来解决这个问题的开发工程师晋升为阿里集团副总裁，欢迎有志于成为副总裁的同学思考下这个问题。</p><p>附2：阿里当年遇到并解决这个问题的系统：<a href=\"https://github.com/alibaba/otter\">https://github.com/alibaba/otter</a></p><p>附3：阿里当年解决这个问题的工程师访谈：<a href=\"https://www.infoq.cn/article/pl-alibaba\">https://www.infoq.cn/article/pl-alibaba</a></p><p>欢迎在评论区分享你的思考，我们共同进步。</p>","comments":[{"had_liked":false,"id":340483,"user_name":"ABC","can_delete":false,"product_type":"c1","uid":1054958,"ip_address":"","ucode":"7501AD9C0C4A70","user_header":"https://static001.geekbang.org/account/avatar/00/10/18/ee/a1ed60d1.jpg","comment_is_top":false,"comment_ctime":1648858517,"is_pvip":false,"replies":[{"id":"124622","content":"没有比较过两者，如果是事实的话，我觉得可能原因是MySQL的社区更庞大，资料更完善，历史更悠久。 <br><br>本质上两个都是商品，决定市场占有率的因素有很多。一个新商品要抢占老商品的市场，好一点是不够的，必须要好好几倍，甚至要好一个数量级才行。成功的例子redis干掉memcached，智能机干掉功能机；没成功的例子更多，典型的基于JVM的各种语言，都动不了Java的地位。","user_name":"作者回复","user_name_real":"编辑","uid":"1007349","ctime":1649211033,"ip_address":"","comment_id":340483,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10238793109","product_id":100105701,"comment_content":"老师，请教个问题。在很多地方都提到PostgreSQL比 MySQL好用的多，但为什么现在主要还是用MySQL用的多一些呢？","like_count":2,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":560142,"discussion_content":"没有比较过两者，如果是事实的话，我觉得可能原因是MySQL的社区更庞大，资料更完善，历史更悠久。 \n\n本质上两个都是商品，决定市场占有率的因素有很多。一个新商品要抢占老商品的市场，好一点是不够的，必须要好好几倍，甚至要好一个数量级才行。成功的例子redis干掉memcached，智能机干掉功能机；没成功的例子更多，典型的基于JVM的各种语言，都动不了Java的地位。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1649211033,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":355376,"user_name":"ball","can_delete":false,"product_type":"c1","uid":2804063,"ip_address":"北京","ucode":"C20917ACD5F006","user_header":"https://static001.geekbang.org/account/avatar/00/2a/c9/5f/db8073d3.jpg","comment_is_top":false,"comment_ctime":1661324733,"is_pvip":false,"replies":[{"id":"129357","content":"谢谢指教，学习了~","user_name":"作者回复","user_name_real":"编辑","uid":"1007349","ctime":1661409609,"ip_address":"北京","comment_id":355376,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1661324733","product_id":100105701,"comment_content":"老师想问下，php为什么要跑在apache上。似乎nginx + fpm方式更常用一些？","like_count":0,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":585230,"discussion_content":"谢谢指教，学习了~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1661409609,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京"},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":346757,"user_name":"雪碧心拔凉","can_delete":false,"product_type":"c1","uid":1161522,"ip_address":"","ucode":"D13EEBAA0F443B","user_header":"https://static001.geekbang.org/account/avatar/00/11/b9/32/84346d4a.jpg","comment_is_top":false,"comment_ctime":1653403035,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1653403035","product_id":100105701,"comment_content":"编辑的时候，图片就已经上传了，最后只是保存文章内容而已就行吧，内容里面有对应图片地址。不太明白为啥一定要同时上传图片和保存文章内容呢？","like_count":0,"discussions":[{"author":{"id":1014665,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/7b/89/34f2cbcc.jpg","nickname":"杨宇","note":"","ucode":"EB74DF6E269F03","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":574283,"discussion_content":"题干中说了“数据从主数据中心同步到多个从数据中心的时候”","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1653958307,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":344584,"user_name":"neohope","can_delete":false,"product_type":"c1","uid":1043475,"ip_address":"","ucode":"C0268F6E7E2B6E","user_header":"https://static001.geekbang.org/account/avatar/00/0f/ec/13/49e98289.jpg","comment_is_top":false,"comment_ctime":1651656960,"is_pvip":true,"replies":[{"id":"125783","content":"库存服务这样对数据一致性有强要求的场景，建议多数据中心之间采用主从结构，类似文中设计，库存写操作只能到主数据中心完成","user_name":"作者回复","user_name_real":"编辑","uid":"1007349","ctime":1651720063,"ip_address":"","comment_id":344584,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1651656960","product_id":100105701,"comment_content":"老师好，想咨询您一个问题：<br>在多个数据中心之间，保持数据库的双A同步时，otter的单项回环补救机制，确实可以保证双中心数据最终是一致的。<br>但在一些极端情况下，业务上要如何处理的呢。比如：<br>货物A，双地库存一致都为200，同一时刻杭州卖了150件，US库也卖了150件，扣库存都可以成功，但最终超卖了。这种情况，业务上要如何处理的呢。<br>感谢！","like_count":0,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":570262,"discussion_content":"库存服务这样对数据一致性有强要求的场景，建议多数据中心之间采用主从结构，类似文中设计，库存写操作只能到主数据中心完成","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1651720063,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1043475,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ec/13/49e98289.jpg","nickname":"neohope","note":"","ucode":"C0268F6E7E2B6E","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":570302,"discussion_content":"感谢老师解惑。之前我们几个也讨论过类似问题，大家也都是倾向于不同的业务采用不同的手段来保证一致性。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1651728627,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":344511,"user_name":"neohope","can_delete":false,"product_type":"c1","uid":1043475,"ip_address":"","ucode":"C0268F6E7E2B6E","user_header":"https://static001.geekbang.org/account/avatar/00/0f/ec/13/49e98289.jpg","comment_is_top":false,"comment_ctime":1651599277,"is_pvip":true,"replies":[{"id":"125785","content":"这个方案也是可行的，只是在查询词条时候的复杂度和性能都不太好，数据一致的问题需要在正常业务逻辑中处理，耦合性也不太好。<br><br>Otter的做法是在数据同步的时候进行检查，如果有图片，就把数据和图片打包在一个同步块内进行同步，保证数据和图片是一致的。同时把这部分逻辑放在数据同步的时候实现，对正常业务流程没有影响，耦合性更加友好一点。","user_name":"作者回复","user_name_real":"编辑","uid":"1007349","ctime":1651720418,"ip_address":"","comment_id":344511,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1651599277","product_id":100105701,"comment_content":"对当前场景，可否这样：<br>1、每次上传图片时，都生成一个唯一文件UUID，词条中仅记录图片的唯一UUID。<br>2、在服务器返回词条时，先通过文件UUID判断是否完成同步，如果完成同步拼接本地服务地址，如果没有完成同步拼接主站点地址。<br>3、服务器还可以直接缓存网页，对于已经同步全部图片的，设置较长超时时间。对于没有完成全部图片同步的，设置较短超时时间。<br>4、刷新页面缓存时，判断MD5码，如果页面变动，主动通知CDN等，原页面失效；或直接推送新版本。<br>5、缓存页面时，可以前1%热点话题放内存，前5%话题放到SSD<br>6、 Tex公式转图片，可以用类似逻辑","like_count":0,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":570265,"discussion_content":"这个方案也是可行的，只是在查询词条时候的复杂度和性能都不太好，数据一致的问题需要在正常业务逻辑中处理，耦合性也不太好。\n\nOtter的做法是在数据同步的时候进行检查，如果有图片，就把数据和图片打包在一个同步块内进行同步，保证数据和图片是一致的。同时把这部分逻辑放在数据同步的时候实现，对正常业务流程没有影响，耦合性更加友好一点。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1651720418,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1043475,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ec/13/49e98289.jpg","nickname":"neohope","note":"","ucode":"C0268F6E7E2B6E","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":570301,"discussion_content":"嗯，这样解耦一下确实好不少。数据同步的实现逻辑虽然复杂，但同步功能内聚在一起，逐步可以产品化；而且对后续业务影响就很小，业务代码变更时也不会相互影响。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1651728465,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":344221,"user_name":"刘峰","can_delete":false,"product_type":"c1","uid":1033913,"ip_address":"","ucode":"6173110C17FEDA","user_header":"https://static001.geekbang.org/account/avatar/00/0f/c6/b9/e1734265.jpg","comment_is_top":false,"comment_ctime":1651377534,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1651377534","product_id":100105701,"comment_content":"主中心节点有一个特殊域名，数据存储里图片链接使用该域名。词条数据同步到从中心时，查询词条中相关图片链接本地是否存在，如果存在就把域名替换为统一域名;否则链接使用主中心域名返回给用户。图片同步成功后，更新本地词条对应的缓存中的数据，更新图片域名为统一域名。","like_count":0},{"had_liked":false,"id":342971,"user_name":"test","can_delete":false,"product_type":"c1","uid":1065849,"ip_address":"","ucode":"9A4973E591DD12","user_header":"https://static001.geekbang.org/account/avatar/00/10/43/79/18073134.jpg","comment_is_top":false,"comment_ctime":1650554471,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1650554471","product_id":100105701,"comment_content":"如果不对则回源去主服务器取","like_count":0},{"had_liked":false,"id":342833,"user_name":"殷志鹏","can_delete":false,"product_type":"c1","uid":1108219,"ip_address":"","ucode":"6D6CBFCA90C19D","user_header":"https://static001.geekbang.org/account/avatar/00/10/e8/fb/5ba80331.jpg","comment_is_top":false,"comment_ctime":1650501703,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1650501703","product_id":100105701,"comment_content":"思考题 有个字段来表示是都同步成功，先判断从库有几个，同步到从库后，从库回调主库来修改字段同步成功","like_count":0},{"had_liked":false,"id":340804,"user_name":"花轮君","can_delete":false,"product_type":"c1","uid":1044639,"ip_address":"","ucode":"A4F27CC1C38D3B","user_header":"https://static001.geekbang.org/account/avatar/00/0f/f0/9f/6689d26e.jpg","comment_is_top":false,"comment_ctime":1649151638,"is_pvip":true,"replies":[{"id":"124611","content":"很不错的思路。这个方案虽然检查版本号对响应性能有影响，而且数据同步延迟也会更长，但确实可以保证数据的准确性。","user_name":"作者回复","user_name_real":"编辑","uid":"1007349","ctime":1649209395,"ip_address":"","comment_id":340804,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1649151638","product_id":100105701,"comment_content":"思考题,是否将词条内容以及照片都设定对应的版本号,进行读取数据的时候只展示最新相同版本的数据,保证展示的数据的准确性","like_count":0,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":560125,"discussion_content":"很不错的思路。这个方案虽然检查版本号对响应性能有影响，而且数据同步延迟也会更长，但确实可以保证数据的准确性。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1649209395,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":340482,"user_name":"ABC","can_delete":false,"product_type":"c1","uid":1054958,"ip_address":"","ucode":"7501AD9C0C4A70","user_header":"https://static001.geekbang.org/account/avatar/00/10/18/ee/a1ed60d1.jpg","comment_is_top":false,"comment_ctime":1648858396,"is_pvip":false,"replies":[{"id":"124620","content":"赞，很不错的思路","user_name":"作者回复","user_name_real":"编辑","uid":"1007349","ctime":1649210524,"ip_address":"","comment_id":340482,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1648858396","product_id":100105701,"comment_content":"还有另外一个思路，如果图片不大，可以base64转码，直接和词条存在一起，但这会导致相同图片出现冗余数据。","like_count":0,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":560137,"discussion_content":"赞，很不错的思路","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1649210525,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":340481,"user_name":"ABC","can_delete":false,"product_type":"c1","uid":1054958,"ip_address":"","ucode":"7501AD9C0C4A70","user_header":"https://static001.geekbang.org/account/avatar/00/10/18/ee/a1ed60d1.jpg","comment_is_top":false,"comment_ctime":1648858318,"is_pvip":false,"replies":[{"id":"124619","content":"这个方案没有达到异地多活的目标啊，可用性和性能都没有改善","user_name":"作者回复","user_name_real":"编辑","uid":"1007349","ctime":1649210486,"ip_address":"","comment_id":340481,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1648858318","product_id":100105701,"comment_content":"老师，可以图片服务器集群存储，然后各个数据中心不同步图片，直接从图片服务器集群访问图片吗","like_count":0,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":560136,"discussion_content":"这个方案没有达到异地多活的目标啊，可用性和性能都没有改善","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1649210486,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":340178,"user_name":"dao","can_delete":false,"product_type":"c1","uid":1087879,"ip_address":"","ucode":"4181FB270462CF","user_header":"https://static001.geekbang.org/account/avatar/00/10/99/87/98ebb20e.jpg","comment_is_top":false,"comment_ctime":1648645133,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1648645133","product_id":100105701,"comment_content":"思考题：<br>词条保存时，图片 URI 可以使用类似 “&#47;词条ID&#47;图片文件名”，图片文件名由图片内容的 hash 码组成，这样当词条数据同步到不同的数据中心，即使图片资源文件还没有同步，也不会影响用户访问。因为加载词条时访问的是 CDN ，如果 CDN 没有图片资源文件会回源。（回源需要设置到不同的数据中心）","like_count":0},{"had_liked":false,"id":339724,"user_name":"Lance-Yanh","can_delete":false,"product_type":"c1","uid":2925298,"ip_address":"","ucode":"2869845EFFBBDA","user_header":"https://static001.geekbang.org/account/avatar/00/2c/a2/f2/db06a8bc.jpg","comment_is_top":false,"comment_ctime":1648322056,"is_pvip":false,"replies":[{"id":"124219","content":"很不错的方案，不过，编辑词条是高并发的，你的方案我担心会导致数据串行处理，数据同步延时太长了。","user_name":"作者回复","user_name_real":"作者","uid":"1007349","ctime":1648434842,"ip_address":"","comment_id":339724,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1648322056","product_id":100105701,"comment_content":"从数据中心重放DDL的时候同步或异步检查图片是否同步完成，进一步确定是否延时重放DDL或主动同步完图片再重放。这样可以吗？老师","like_count":0,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":558680,"discussion_content":"很不错的方案，不过，编辑词条是高并发的，你的方案我担心会导致数据串行处理，数据同步延时太长了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1648434842,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":339611,"user_name":"javaadu","can_delete":false,"product_type":"c1","uid":1000519,"ip_address":"","ucode":"8C0B140F1C8992","user_header":"https://static001.geekbang.org/account/avatar/00/0f/44/47/3ddb94d0.jpg","comment_is_top":false,"comment_ctime":1648223151,"is_pvip":true,"replies":[{"id":"124210","content":"赞，具体实现细节呢，如何绑定？如何同步数据？","user_name":"作者回复","user_name_real":"编辑","uid":"1007349","ctime":1648433296,"ip_address":"","comment_id":339611,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1648223151","product_id":100105701,"comment_content":"思考题，图片和文字属于某一个词条，那就将这个词条作为数据同步的最小粒度，利用词条信息将文本和图片绑定在一起","like_count":0,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":558664,"discussion_content":"赞，具体实现细节呢，如何绑定？如何同步数据？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1648433296,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":339031,"user_name":"丘振标","can_delete":false,"product_type":"c1","uid":1069232,"ip_address":"","ucode":"5CD61A35D45186","user_header":"https://static001.geekbang.org/account/avatar/00/10/50/b0/467af279.jpg","comment_is_top":false,"comment_ctime":1647866497,"is_pvip":true,"replies":[{"id":"123925","content":"你括号中提到的问题还真是问题，在主数据中心，写入图片和写入数据的服务器都不是同一组服务器，也就说，主数据中心自己都不知道自己的图片和数据是不是都写入完成了，如何做顺序同步呢？<br><br>而且ZooKeeper是不能并发写的，而Wepedia是高并发写需求的，逐一顺序同步这个恐怕也不能接受。","user_name":"作者回复","user_name_real":"作者","uid":"1007349","ctime":1647913321,"ip_address":"","comment_id":339031,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1647866497","product_id":100105701,"comment_content":"感觉思考题本质上是要解决分布式环境下，数据同步的顺序性问题，对于词条的文本和图片，在主数据中心提交的时候，一般会按照先保存图片然后再更新文本的顺序(否则，在主数据中心这里，就算不存在同步的因素，也会有问题)，因此，这里应该有个统一的同步系统按顺序将变更逐一提交到从数据中心，有点类似zookeeper的master节点逐一同步数据到其他follower的原理，只要保证了同步系统同步数据的顺序性，思考题中说的问题应该就可以解决了","like_count":0,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":557633,"discussion_content":"你括号中提到的问题还真是问题，在主数据中心，写入图片和写入数据的服务器都不是同一组服务器，也就说，主数据中心自己都不知道自己的图片和数据是不是都写入完成了，如何做顺序同步呢？\n\n而且ZooKeeper是不能并发写的，而Wepedia是高并发写需求的，逐一顺序同步这个恐怕也不能接受。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1647913321,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":339016,"user_name":"启程","can_delete":false,"product_type":"c1","uid":1388780,"ip_address":"","ucode":"A0D505AA06B581","user_header":"https://static001.geekbang.org/account/avatar/00/15/30/ec/849b6b91.jpg","comment_is_top":false,"comment_ctime":1647859956,"is_pvip":false,"replies":[{"id":"123922","content":"原文：Wepedia 的多数据中心架构为一主多从架构，即一个主数据中心，多个从数据中心。数据中心之间采用类似 ZooKeeper 的选主策略进行通信，如果主数据中心不可用，其他数据中心会重新选举一个主数据中心。","user_name":"作者回复","user_name_real":"编辑","uid":"1007349","ctime":1647912858,"ip_address":"","comment_id":339016,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1647859956","product_id":100105701,"comment_content":"主数据中心有几个？是多个吗？主主之间怎么写数据，是谁来负责选择哪个主数据中心写入，同时主主之间数据怎样同步，老师能详细解答一下吗","like_count":0,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":557629,"discussion_content":"原文：Wepedia 的多数据中心架构为一主多从架构，即一个主数据中心，多个从数据中心。数据中心之间采用类似 ZooKeeper 的选主策略进行通信，如果主数据中心不可用，其他数据中心会重新选举一个主数据中心。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1647912858,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":339015,"user_name":"👽","can_delete":false,"product_type":"c1","uid":1274117,"ip_address":"","ucode":"D313AF941B412D","user_header":"https://static001.geekbang.org/account/avatar/00/13/71/05/db554eba.jpg","comment_is_top":false,"comment_ctime":1647859538,"is_pvip":false,"replies":[{"id":"123927","content":"问题描述虽然用“数据一致”，其实想表达的意思是数据库数据和图片数据一致，真正的意思其实是“数据完整”，用分布式数据一致性的方案解决我感觉可能不是合适的。","user_name":"作者回复","user_name_real":"编辑","uid":"1007349","ctime":1647913766,"ip_address":"","comment_id":339015,"utype":1}],"discussion_count":3,"race_medal":0,"score":"1647859538","product_id":100105701,"comment_content":"我觉得核心处理原理的话，raft协议。etcd和zookeeper使用的协议。<br><br>保障数据一致性的解决方案。<br><br>所有的节点之间有一个选主的流程。非主节点只允许读操作。并且，每一条数据都会有一个版本号，主节点修改或者创建数据时，会同步通知非主节点，当所有的非主节点都告知主节点数据更新成功时，才会返回这条最新的数据。<br><br>但是，因为其数据强一致性的保障，牺牲了很多性能。这种方式是否合理也是一个问题。","like_count":0,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":557636,"discussion_content":"问题描述虽然用“数据一致”，其实想表达的意思是数据库数据和图片数据一致，真正的意思其实是“数据完整”，用分布式数据一致性的方案解决我感觉可能不是合适的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1647913767,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":2,"child_discussions":[{"author":{"id":1274117,"avatar":"https://static001.geekbang.org/account/avatar/00/13/71/05/db554eba.jpg","nickname":"👽","note":"","ucode":"D313AF941B412D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":557761,"discussion_content":"因为我的理解，这个数据完整性，我感觉现在貌似不算一个问题。现在的主流解决方案（比如我刚刚试了一下Infoq）：\n\n图片插入或者粘贴到当前编辑框的时候，前端就会发起请求，将图片上传到后台，这个过程是异步的，图片上传过程中你还可以继续编辑文字内容。等图片上传成功以后，会返回图片地址，前端会用网络图片路径替换本地图片路径。\n\n最后提交保存到数据库到，只是文本资源。实际解决方案其实就是，在最后提交文本到时候，图片已经上传成功，并替换了正在编辑到文本路径。\n\n\n如果，一定要同时提交图片+文本。可以尝试后台将数据拆解。拆成一对多。文本资源，对应一个资源列表，资源列表里有资源的状态。每一个需要上传到资源，给一个唯一标识。上传成功之后，通知更新这个资源等状态，等所有资源都已经上传完成的时候，替换文本数据中的图片资源为返回的网络地址，这时才会正式使这个文本数据生效。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1647957785,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":557636,"ip_address":""},"score":557761,"extra":""},{"author":{"id":1014665,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/7b/89/34f2cbcc.jpg","nickname":"杨宇","note":"","ucode":"EB74DF6E269F03","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1274117,"avatar":"https://static001.geekbang.org/account/avatar/00/13/71/05/db554eba.jpg","nickname":"👽","note":"","ucode":"D313AF941B412D","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":574287,"discussion_content":"题干中说了“数据从主数据中心同步到多个从数据中心的时候”","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1653958495,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":557761,"ip_address":""},"score":574287,"extra":""}]}]},{"had_liked":false,"id":338974,"user_name":"奔浪","can_delete":false,"product_type":"c1","uid":2915106,"ip_address":"","ucode":"537B9FB02F5EA0","user_header":"https://static001.geekbang.org/account/avatar/00/2c/7b/22/2a810977.jpg","comment_is_top":false,"comment_ctime":1647845541,"is_pvip":true,"replies":[{"id":"123905","content":"不错，有两个小问题<br>方案1：如何判断图片同步完成呢？图片和数据同步是各自独立的，图片自己并不知道自己被哪个数据引用，而图片和数据也是在高并发同时有很多在更新的。<br>方案2：虽然不知道一张图片如何整合文本文件和图片，但是我觉得这个方案挺靠谱的~~~","user_name":"作者回复","user_name_real":"编辑","uid":"1007349","ctime":1647860488,"ip_address":"","comment_id":338974,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1647845541","product_id":100105701,"comment_content":"原因:由于图片资源同步数据时耗时较长导致同步数据时有可能图文不符，或者图片资源干脆加载不到，   个人愚见:<br>        方案一是否可以先进行图片同步文本类型先等等 等待图片同步完成后再写入数据库，因为文本写入与同步较快，像这种软件一般应该是富文本编辑器吧？在同步文本数据时内有img标签资源地址，这样在同步过程中，要么访问到是老资源，要么就是新资源。<br>        方案二是否将文本文件与图片资源整合成一张图片资源，这样就不存在具体是先同步图还是先同步文本问题，当然次方案十分消耗资源","like_count":0,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":557559,"discussion_content":"不错，有两个小问题\n方案1：如何判断图片同步完成呢？图片和数据同步是各自独立的，图片自己并不知道自己被哪个数据引用，而图片和数据也是在高并发同时有很多在更新的。\n方案2：虽然不知道一张图片如何整合文本文件和图片，但是我觉得这个方案挺靠谱的~~~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1647860488,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":338942,"user_name":"peter","can_delete":false,"product_type":"c1","uid":1058183,"ip_address":"","ucode":"261C3FC001DE2D","user_header":"https://static001.geekbang.org/account/avatar/00/10/25/87/f3a69d1b.jpg","comment_is_top":false,"comment_ctime":1647824057,"is_pvip":true,"replies":[{"id":"123904","content":"1 单机缓存能力强不强，就是看缓存程序的实现算法优不优。Redis和Nginx是程序，CDN是一个技术方案；Redis只用作缓存，Nginx用途可多了，三者不好比较啊。<br>2 是系统中的一个子系统，需要自己开发，部署独立的服务器。<br>3 数据同步延迟导致的数据中心之间的数据不一致，在百科应用场景下，业务上不认为这是脏数据。<br>4 是的，画图简化了，需要消费者。<br>5 敢这么说话的都是大佬~~~ wepedia这么设计其实是借鉴了wikipedia<br>","user_name":"作者回复","user_name_real":"编辑","uid":"1007349","ctime":1647859356,"ip_address":"","comment_id":338942,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1647824057","product_id":100105701,"comment_content":"请教老师几个问题啊：<br>Q1：CDN、Nginx、Redis缓存能力比较？<br>本文架构中，CDN、Nginx、Redis的作用主要是缓存。那么，这三种谁的单机缓存能力最强？<br>我的猜测是：1 单机缓存能力：Redis 》 CDN 》Nginx。2 Redis和CDN靠机器数量提高缓存能力。<br>Q2：Invalidation Notificatin，是Apache应用服务器的一个模块？还是一个独立的服务器？<br>Q3：多数据中心同步时，未同步完时，通过从数据中心读，会读到脏数据，怎么处理？<br>Q4：MQ可以直接到MySQL吗？<br>多数据中心架构图中，MySQL用canal同步；在从数据中心内部，MQ直接到MySQL，这个只是为了方便而画的示意图吗？<br> 我的理解： 1 MQ不能直接到MySQL，即MySQL不能直接作为MQ的消费者；2 中间需要一个应用来连接两者。也就是说，需要开发一个应用，来消费MQ中的数据，然后写入MySQL。<br>Q5：应用服务器为什么用Apache + PHP？ <br>据说PHP是最差的语言。为什么要选择一个差的组合？<br>我是用Java，对PHP不是很了解，只是听说不太好。<br>Q6：除了Lighttpd，还有哪些常见的图片服务器？哪个最好？<br>Q7：MySQL服务器的内存一般设置多大？ 16G吗？<br>Q8：刚看了一个面试题的文章“淘宝7天自动确认收货，怎么实现”？文中提到了几种方法，但没有讲定时任务这种方法，难道不能用定时任务吗？","like_count":0,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":557556,"discussion_content":"1 单机缓存能力强不强，就是看缓存程序的实现算法优不优。Redis和Nginx是程序，CDN是一个技术方案；Redis只用作缓存，Nginx用途可多了，三者不好比较啊。\n2 是系统中的一个子系统，需要自己开发，部署独立的服务器。\n3 数据同步延迟导致的数据中心之间的数据不一致，在百科应用场景下，业务上不认为这是脏数据。\n4 是的，画图简化了，需要消费者。\n5 敢这么说话的都是大佬~~~ wepedia这么设计其实是借鉴了wikipedia\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1647859357,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1061991,"avatar":"https://static001.geekbang.org/account/avatar/00/10/34/67/06a7f9be.jpg","nickname":"while (1)等;","note":"","ucode":"BAEC7258D65B69","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":591989,"discussion_content":"据说php是最好的语言","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1667008563,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"江苏"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}