{"id":764260,"title":"06｜云环境实战：快速启动Kubernetes集群","content":"<p>你好，我是潘野。</p><p>前面的课程里，我们学习了云原生的基本组成技术，现代化的云原生技术架构如何管理以及公有云的基本特点等内容。你可能觉得前面的知识偏理论，眼睛看会了、脑袋明白了，但是手还不会。</p><p>从这一章开始，我为你设计了一系列的实验，从易到难、循序渐进地带你实战演练，最终形成一套可以用在生产环境的基础架构自动化管理方式。除了提高实践水平，你还能加深对不可变基础设施、混合云管理等理论的理解。</p><p>这一讲我们会利用Terraform工具，在AWS中启动一个Kubernetes集群，帮你尽快熟悉现代IaC面向资源的管理方式。</p><h2>前期准备工作</h2><p>为什么我们选择公有云AWS作为课程的实践环境呢？</p><p>因为它提供了完整的IaaS API与文档，更方便我们学习实践。而且无论是哪个云厂商，提供的功能都差不多。即便你所在的团队是自建机房，多数也会采用像Openstack、VMware这样的IaaS解决方案，哪怕API或操作跟公有云略有差别，使用方法和思路也基本一致。</p><p>好，下面正式进入实战环节，我们先从配置本地环境开始。我们选用一台Ubuntu 22.04的虚拟机作为基础操作环境。</p><p>首先，我们需要安装AWS的命令行工具AWS CLI。如果你使用的是Mac OS或者Windows系统，可以参照AWS的<a href=\"https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html\">官方文档</a>来配置你的环境，这里我们只列出Linux环境的配置命令。</p><!-- [[[read_end]]] --><pre><code class=\"language-plain\">curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\nunzip awscliv2.zip\nsudo ./aws/install\n</code></pre><p>当AWS CLI工具安装成功之后，别忘了检查一下版本输出。</p><pre><code class=\"language-plain\">root@devops:~/aws# /usr/local/bin/aws --version\naws-cli/2.8.1 Python/3.9.11 Linux/5.15.0-48-generic exe/x86_64.ubuntu.22 prompt/off\n</code></pre><p>接下来，我们在IAM中新建一个USER，并且生成一个access key。AWS 的 IAM 是身份和访问管理的缩写，是一种 Web 服务，可以帮助你安全地控制对 AWS 资源的访问。我们借助 IAM，可以集中管理控制用户可访问哪些 AWS 资源的权限。</p><p>对于初次接触公有云环境的同学，我建议使用admin权限，这样能帮你在后续学习中减少一些权限问题。<strong>但是要注意，这并不是一个正确的做法，不能在生产环境中使用。</strong>关于IAM的安全部分，后续章节我再详细讲解。</p><p><img src=\"https://static001.geekbang.org/resource/image/b6/0d/b66a1086ea54f80215788a96c9b04b0d.jpg?wh=2900x1836\" alt=\"\"></p><p>当你完成了新用户的创建以及赋权之后，就需要在AWS CLI工具中完成配置。配置的内容也很简单，将你上一步获取到的Access ID和Key填入即可。</p><pre><code class=\"language-plain\">root@devops:~# aws configure\nAWS Access Key ID [None]: AKIAY6CN....\nAWS Secret Access Key [None]: 482iR9LP3bbCV.....BmZi/Q\nDefault region name [None]: us-east-2\nDefault output format [None]:\n</code></pre><h2>使用tfenv管理Terraform版本</h2><p>之前的课程里，我们虽然了解了Terraform的一些基本操作，但是在实际工作中，当你接手前人的代码，还是会遇到后面这类困难。</p><ul>\n<li>因为Terraform在不同的版本存在一些兼容性问题，在version.tf中需要使用某个特定版本的Terraform。</li>\n<li>代码年久失修，仍在使用某个很老的Terraform版本，缺少一些新版本的特性。</li>\n</ul><p>这时候你就需要一个Terraform版本管理工具，帮助你在不同的版本中切换。这里我们需要用到 <code>tfenv</code> 来帮助我们管理Terraform的版本，它的GitHub的地址是这个：<a href=\"https://github.com/tfutils/tfenv\">https://github.com/tfutils/tfenv</a>。</p><p>如果你没有用过tfenv，可以参考<a href=\"https://github.com/tfutils/tfenv#manual\">官方提供的方法</a>进行安装。tfenv的核心用法就是将远程的不同版本Terraform下载下来，然后通过改变环境变量来切换成指定版本。当你装好tfenv之后，可以使用list-remote参数来查看所有的terraform的版本号，并指定所需要的版本。</p><pre><code class=\"language-plain\">root@devops:~# tfenv list-remote\n</code></pre><p>然后，你可以使用latest的参数安装最新版本，也可以安装指定版本。</p><pre><code class=\"language-plain\">root@devops:~# tfenv install latest\nInstalling Terraform v1.3.2\nDownloading release tarball from https://releases.hashicorp.com/terraform/1.3.2/terraform_1.3.2_linux_amd64.zip\n############################################################################################################################################################################################## 100.0%\nDownloading SHA hash file from https://releases.hashicorp.com/terraform/1.3.2/terraform_1.3.2_SHA256SUMS\nNot instructed to use Local PGP (/root/.tfenv/use-{gpgv,gnupg}) &amp; No keybase install found, skipping OpenPGP signature verification\nArchive:&nbsp; /tmp/tfenv_download.cTS98Z/terraform_1.3.2_linux_amd64.zip\n&nbsp; inflating: /root/.tfenv/versions/1.3.2/terraform\nInstallation of terraform v1.3.2 successful. To make this your default version, run 'tfenv use 1.3.2'\n</code></pre><pre><code class=\"language-plain\">root@devops:~/infra-automation/terraform/eks/example# tfenv install 1.2.0\nInstalling Terraform v1.2.0\nDownloading release tarball from https://releases.hashicorp.com/terraform/1.2.0/terraform_1.2.0_linux_amd64.zip\n############################################################################################################################################################################################## 100.0%\nDownloading SHA hash file from https://releases.hashicorp.com/terraform/1.2.0/terraform_1.2.0_SHA256SUMS\nNot instructed to use Local PGP (/root/.tfenv/use-{gpgv,gnupg}) &amp; No keybase install found, skipping OpenPGP signature verification\nArchive:&nbsp; /tmp/tfenv_download.TpmQi9/terraform_1.2.0_linux_amd64.zip\n&nbsp; inflating: /root/.tfenv/versions/1.2.0/terraform\nInstallation of terraform v1.2.0 successful. To make this your default version, run 'tfenv use 1.2.0'\nroot@devops:~/infra-automation/terraform/eks/example# tfenv use 1.2.0\nSwitching default version to v1.2.0\nDefault version (when not overridden by .terraform-version or TFENV_TERRAFORM_VERSION) is now: 1.2.0\nroot@devops:~/infra-automation/terraform/eks/example#\n</code></pre><h2>课程代码的概述</h2><p>我在GitHub上建立了一个cloudnative-automation的组织，所有的课程代码，实现方式都会展现在这个组织中。</p><p>首先，你需要从GitHub上将课程代码clone到本地，链接是<a href=\"https://github.com/cloudnative-automation/eks-cluster/tree/example\">https://github.com/cloudnative-automation/eks-cluster/tree/example</a>。</p><p>我给你简单讲解下example里的文件分别是什么作用。</p><p><code>versions.tf</code> 定义了与Terraform相关的参数，比如版本号、使用模块的版本等等，这里我们将Terraform的版本设置为1.2，AWS模块的版本设置为4.15。</p><pre><code class=\"language-plain\">terraform {\n&nbsp; required_providers {\n&nbsp;&nbsp;&nbsp; aws = {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; source&nbsp; = \"hashicorp/aws\"\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; version = \"~&gt; 4.15.0\"\n&nbsp;&nbsp;&nbsp; }\n\n&nbsp;&nbsp;&nbsp; random = {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; source&nbsp; = \"hashicorp/random\"\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; version = \"3.1.0\"\n&nbsp;&nbsp;&nbsp; }\n&nbsp; }\n\n&nbsp; required_version = \"~&gt; 1.2.0\"\n}\n</code></pre><p><code>variables.tf</code> 包含一个区域变量，控制着在哪里创建EKS集群。这里面有一些参数我们在前面的aws configure里配置过，那么在<code>variables.tf</code> 配置的参数会去覆盖前面aws configure配置的参数。</p><p>再来看 <code>vpc.tf</code> ，它能为我们提供一个VPC、子网和可用区。为了不影响用户现有的云环境和资源，我们可以利用vpc.tf创建一个新的VPC。</p><p>在vpc.tf中我们需要配置两个网段，一个专门为内网服务，另一个为外网服务，但是有两个地方要注意。</p><ol>\n<li>网段不能重复。</li>\n<li>子网掩码建议不要低于24，EKS的CNI网络会从VPC的subnet里取IP，所以集群越大，需要的IP越多。</li>\n</ol><pre><code class=\"language-plain\">&nbsp; private_subnets = [\"10.0.1.0/24\", \"10.0.2.0/24\", \"10.0.3.0/24\"]\n&nbsp; public_subnets&nbsp; = [\"10.0.4.0/24\", \"10.0.5.0/24\", \"10.0.6.0/24\"]\n</code></pre><p>接着是 <code>security-groups.tf</code> ，它规定了EKS集群将使用的安全组。在这里，我们为每个node group都配置了规则策略，你可以根据你实际需求来放行端口，比如这个例子里放行的就是22端口。</p><pre><code class=\"language-plain\">resource \"aws_security_group\" \"node_group_one\" {\n&nbsp; name_prefix = \"node_group_one\"\n&nbsp; vpc_id&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; = module.vpc.vpc_id\n&nbsp; ingress {\n&nbsp;&nbsp;&nbsp; from_port = 22\n&nbsp;&nbsp;&nbsp; to_port&nbsp;&nbsp; = 22\n&nbsp;&nbsp;&nbsp; protocol&nbsp; = \"tcp\"\n&nbsp;&nbsp;&nbsp; cidr_blocks = [\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \"10.0.0.0/8\",\n&nbsp;&nbsp;&nbsp; ]\n&nbsp; }\n}\n</code></pre><p>最后来看 <code>eks-cluster.tf</code> ，这里我们可以使用AWS EKS模块来配置EKS集群和其他所需资源，包括自动扩展组、安全组、IAM角色和IAM策略。</p><p>这里面有几个参数需要你注意。</p><p><code>cluster_version</code> 定义了这个集群的版本，我们需要在AWS上确认我们可以使用哪些版本。在样例中我使用的是1.22这个大版本。</p><p><code>ami_type</code> 表示你要选择什么类型的操作系统镜像。我曾在第三讲带你了解过专门为容器设计的操作系统—— Bottlerocket，建议在这里选择使用Bottlerocket。如果你对容器还不太熟悉，也可以选择Amazon Linux作为操作系统。</p><p><code>instance_types</code> 是一个列表，你可以加入多种机型。这里注意，尽管公有云厂商准备了大量的服务器，但是它们不是万能的。我们经常会遇到在某个region、某种机型可以购买的数量吃紧的状况，所以建议多加几种类型的机器。</p><p><code>min_size, max_size, desired_size</code> 定义了集群最少机器数量、最多机器数量以及默认机器数量。</p><h2>启动集群</h2><p>在讲解完代码之后，我们来启动一个Kubernetes集群。</p><p>首先通过命令行进入example的目录，执行 <code>terraform init</code> 这条命令。init命令会根据你配置文件里的要求，将相对应的Terraform模块下载到本地。</p><pre><code class=\"language-plain\">root@devops:~/infra-automation/terraform/eks/example# terraform init\nInitializing modules...\nDownloading registry.terraform.io/terraform-aws-modules/eks/aws 18.26.6 for eks...\n- eks in .terraform/modules/eks\n- eks.eks_managed_node_group in .terraform/modules/eks/modules/eks-managed-node-group\n- eks.eks_managed_node_group.user_data in .terraform/modules/eks/modules/_user_data\n- eks.fargate_profile in .terraform/modules/eks/modules/fargate-profile\nDownloading registry.terraform.io/terraform-aws-modules/kms/aws 1.0.2 for eks.kms...\n- eks.kms in .terraform/modules/eks.kms\n- eks.self_managed_node_group in .terraform/modules/eks/modules/self-managed-node-group\n- eks.self_managed_node_group.user_data in .terraform/modules/eks/modules/_user_data\nDownloading registry.terraform.io/terraform-aws-modules/vpc/aws 3.14.2 for vpc...\n- vpc in .terraform/modules/vpc\n\nInitializing the backend...\n\nInitializing provider plugins...\n- Reusing previous version of hashicorp/tls from the dependency lock file\n- Reusing previous version of hashicorp/cloudinit from the dependency lock file\n- Reusing previous version of hashicorp/aws from the dependency lock file\n- Reusing previous version of hashicorp/random from the dependency lock file\n- Reusing previous version of hashicorp/kubernetes from the dependency lock file\n- Installing hashicorp/cloudinit v2.2.0...\n- Installed hashicorp/cloudinit v2.2.0 (signed by HashiCorp)\n- Installing hashicorp/aws v4.15.1...\n- Installed hashicorp/aws v4.15.1 (signed by HashiCorp)\n- Installing hashicorp/random v3.1.0...\n- Installed hashicorp/random v3.1.0 (signed by HashiCorp)\n- Installing hashicorp/kubernetes v2.12.1...\n- Installed hashicorp/kubernetes v2.12.1 (signed by HashiCorp)\n- Installing hashicorp/tls v3.4.0...\n- Installed hashicorp/tls v3.4.0 (signed by HashiCorp)\n\nTerraform has made some changes to the provider dependency selections recorded\nin the .terraform.lock.hcl file. Review those changes and commit them to your\nversion control system if they represent changes you intended to make.\n\nTerraform has been successfully initialized!\n\nYou may now begin working with Terraform. Try running \"terraform plan\" to see\nany changes that are required for your infrastructure. All Terraform commands\nshould now work.\n\nIf you ever set or change modules or backend configuration for Terraform,\nrerun this command to reinitialize your working directory. If you forget, other\ncommands will detect it and remind you to do so if necessary.\n</code></pre><p>当模块初始化完毕之后，我们就可以使用 <code>terraform apply</code> 命令来创建一个EKS集群。这步动作可能需要几分钟到十几分钟不等，时长取决于整个环境在前面是否有过初始化。</p><pre><code class=\"language-plain\">root@devops:~/infra-automation/terraform/eks/example# terraform apply\nPlan: 56 to add, 0 to change, 0 to destroy.\n\nChanges to Outputs:\n&nbsp; + cluster_endpoint&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; = (known after apply)\n&nbsp; + cluster_id&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; = (known after apply)\n&nbsp; + cluster_name&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; = (known after apply)\n&nbsp; + cluster_security_group_id = (known after apply)\n&nbsp; + region&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; = \"us-east-2\"\n\nDo you want to perform these actions?\n&nbsp; Terraform will perform the actions described above.\n&nbsp; Only 'yes' will be accepted to approve.\n\n&nbsp; Enter a value: yes\n\nrandom_string.suffix: Creating...\nrandom_string.suffix: Creation complete after 0s [id=4hrTXxaD]\n</code></pre><p>完成apply动作以后，terraform会将集群的地址、ID、name都打印在终端。此时需要你记录下这些信息。因为之后我们要用到这些信息来生成kubeconfig，从而连接集群。</p><pre><code class=\"language-plain\">Apply complete! Resources: 56 added, 0 changed, 0 destroyed.\n\nOutputs:\n\ncluster_endpoint = \"https://4D58C6B2B0213AA1FB0925F950CEB497.gr7.us-east-2.eks.amazonaws.com\"\ncluster_id = \"education-eks-4hrTXxaD\"\ncluster_name = \"education-eks-4hrTXxaD\"\ncluster_security_group_id = \"sg-0ffee9cb0c254f781\"\nregion = \"us-east-2\"\nroot@devops:~/infra-automation/terraform/eks/example#\n</code></pre><p>同时，我们在AWS的console上查询一下，看看集群是否建立成功。如果出现后面这样的截图就表示建立成功了。</p><p><img src=\"https://static001.geekbang.org/resource/image/a7/d9/a7010443833d593dc1e46fc176f920d9.jpg?wh=1027x504\" alt=\"\"></p><p>当我们看到集群的状态是绿色标记“活动”的时候，代表此时我们已经获得了一个可以使用的Kubernetes集群。</p><p>接下来我们来配置集群的kubeconfig，此时我们需要用到AWS CLI这个工具，它会帮我们把EKS的配置下载到本地 <code>.kube/config</code> 中。</p><pre><code class=\"language-plain\">root@devops:~# aws eks --region us-east-2 update-kubeconfig --name education-eks-4hrTXxaD\nAdded new context arn:aws:eks:us-east-2:614342226570:cluster/education-eks-4hrTXxaD to /root/.kube/conroot@devops:~/infra-automation/terraform/eks/example# terraform initfig\n</code></pre><p>现在，你用kubectl这个命令就可以看到这个集群情况了。</p><pre><code class=\"language-plain\">root@devops:~# kubectl get node\nNAME&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;STATUS&nbsp; &nbsp;ROLES&nbsp; &nbsp; AGE&nbsp; &nbsp; &nbsp;VERSION\nip-10-0-1-65.us-east-2.compute.internal&nbsp; &nbsp; Ready&nbsp; &nbsp; &lt;none&gt;&nbsp; &nbsp;4m9s&nbsp; &nbsp; v1.22.12-eks-ba74326\nip-10-0-2-92.us-east-2.compute.internal&nbsp; &nbsp; Ready&nbsp; &nbsp; &lt;none&gt;&nbsp; &nbsp;4m24s&nbsp; &nbsp;v1.22.12-eks-ba74326\nip-10-0-3-141.us-east-2.compute.internal&nbsp; &nbsp;Ready&nbsp; &nbsp; &lt;none&gt;&nbsp; &nbsp;4m19s&nbsp; &nbsp;v1.22.12-eks-ba74326\nroot@devops:~#\n</code></pre><p>这样我们就通过IaC的方式得到了一个全新的Kuberentes集群。</p><h2>集群升级</h2><p>接下来，我们继续结合实例，看看如何给集群升级，这是Kubernetes集群管理的高频操作。</p><p>之前的配置中， <code>cluster_version</code> 是1.22。需要升级集群时，我们只需要改写下面的配置，将cluster_version从1.22改成1.23。</p><pre><code class=\"language-plain\">&nbsp; version = \"18.26.6\"\n\n&nbsp; cluster_name&nbsp; &nbsp; = local.cluster_name\n&nbsp; cluster_version = \"1.23\"\n\n&nbsp; vpc_id&nbsp; &nbsp; &nbsp;= module.vpc.vpc_id\n</code></pre><p>然后，我们再跑一次terraform apply，即可自动完成集群版本的升级。</p><pre><code class=\"language-plain\">root@devops:~/infra-automation/terraform/eks/example# terraform apply\n\n... (省略了一些输出)...\n\nDo you want to perform these actions?\n&nbsp; Terraform will perform the actions described above.\n&nbsp; Only 'yes' will be accepted to approve.\n\n&nbsp; Enter a value: yes\n\nmodule.eks.aws_eks_cluster.this[0]: Modifying... [id=education-eks-4hrTXxaD]\nmodule.eks.aws_eks_cluster.this[0]: Still modifying... [id=education-eks-4hrTXxaD, 10s elapsed]\nmodule.eks.aws_eks_cluster.this[0]: Still modifying... [id=education-eks-4hrTXxaD, 20s elapsed]\nmodule.eks.aws_eks_cluster.this[0]: Still modifying... [id=education-eks-4hrTXxaD, 30s elapsed]\nmodule.eks.aws_eks_cluster.this[0]: Still modifying... [id=education-eks-4hrTXxaD, 40s elapsed]\nmodule.eks.aws_eks_cluster.this[0]: Still modifying... [id=education-eks-4hrTXxaD, 50s elapsed]\nmodule.eks.aws_eks_cluster.this[0]: Still modifying... [id=education-eks-4hrTXxaD, 1m0s elapsed]\nmodule.eks.aws_eks_cluster.this[0]: Still modifying... [id=education-eks-4hrTXxaD, 1m10s elapsed]\nmodule.eks.aws_eks_cluster.this[0]: Still modifying... [id=education-eks-4hrTXxaD, 1m20s elapsed]\nmodule.eks.aws_eks_cluster.this[0]: Still modifying... [id=education-eks-4hrTXxaD, 1m30s elapsed]\n</code></pre><p>我们在AWS的Console上可以观察到，集群现在的状态是正在更新。</p><p><img src=\"https://static001.geekbang.org/resource/image/0c/b9/0cc4024b819ae9f9f651a462cc373fb9.jpg?wh=2900x1404\" alt=\"\"></p><p>因为AWS的EKS升级的原理是加一台新的EC2节点，然后将老的EC2节点下线，所以整个升级的时间取决于你集群的大小。集群越大，升级时间越久。</p><p>等待一段时间后，集群就顺利升级到1.23这个版本了。</p><p><img src=\"https://static001.geekbang.org/resource/image/0c/75/0cc9d1255535de6fcf948f50422a9975.jpg?wh=2900x1308\" alt=\"\"></p><h2>总结</h2><p>如果你在AWS的页面里探索过，就会发现你几乎不可能在页面上通过点点点的方式，顺利点出一个EKS集群。这是因为AWS在设计上，倾向让用户使用代码来管理云上的资源。</p><p>这一讲我们通过Terraform这个工具，熟悉了管理<strong>云资源的代码结构和关键参数</strong>，成功创建了一个EKS集群。然而对初学者来说，还是会卡在怎么写模块、怎么看懂代码上。这一讲我重点带你熟悉了核心代码和关键参数。更详细的代码解释和分析，你可以参考我为你准备的 <a href=\"https://github.com/cloudnative-automation/eks-cluster\">GitHub代码</a>，还可以自行查阅<a href=\"https://developer.hashicorp.com/terraform/tutorials?product_intent=terraform\">Terraform官方文档</a>。</p><p>除了Terraform之外，社区里还有不少工具能帮我们用代码方式管理云上资源。比如后起之秀 <a href=\"https://www.pulumi.com\">Pulumi</a>，基于Kubernetes方式 <a href=\"https://www.crossplane.io/\">Crossplane</a>，它们都可以做到一套代码管理多云的方式。你如果感兴趣可以课后自行探索。</p><p>其实无论是哪种工具，基本思路都是<strong>使用代码描述如何分配和使用资源，然后通过工具框架调用</strong></p><p><strong>IaaS API，最终获得我们所需的资源</strong>。希望你能举一反三，参考这一讲学到的管理思路，套用到其他公用云甚至私有云的资源管理上。</p><p>现在我们是手动执行代码来获得资源的，这显然并没完全达到自动化的要求。那如果我们想通过一些手段，比如DevOps的CI/CD来自动化执行这些代码获得资源，该怎么做呢？后续课程里我会继续和你探讨这个话题，敬请期待。</p><h2>思考题</h2><p>今天，我们使用了Terraform在公有云中启动了一个Kubernetes集群。但实际工作中，公司里只有一个集群的情况极少，往往我们面对十多个、甚至上百个Kubernetes集群，那么我们要如何管理多个集群的Terraform代码呢？</p><p>欢迎你在留言区和我交流探讨，我们下一讲见！</p>","comments":[{"had_liked":false,"id":389517,"user_name":"Geek_45a572","can_delete":false,"product_type":"c1","uid":3654504,"ip_address":"陕西","ucode":"B0503B2F0D8A6D","user_header":"","comment_is_top":false,"comment_ctime":1712761020,"is_pvip":false,"replies":[{"id":141698,"content":"Hi 同学你好\n\n我在课程中的案例是为了能够让计算&#47;网络&#47;存储三块内容在一个例子中体现，所以放在了eks的模块中。\n\n在生产环境中，我建议你将网络相关的配置单独放在一个目录，单独运行CI&#47;CD管理和配置，eks通过变量或者hard code也可以引用你建好的VPC&#47;subnet，因为VPC&#47;subnet的在建好之后配置变动很小。那RDS也同理。\n\n你可以按需拆份，也可以按需合并，比如你启用一个eks集群，这个集群中的应用是需要S3 bucket，你也可以将eks和bucket放在一个模块中管理。\n\n我们基于GitOps的模式，精细管理云资源配置，各类资源的管理方式是非常类似的。","user_name":"作者回复","user_name_real":"编辑","uid":1043450,"ctime":1712767239,"ip_address":"上海","comment_id":389517,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100758001,"comment_content":"老师您好，有一个场景，我的vpc使用tf创建之后。创建了rds也使用了这个vpc.  因为是在eks创建的脚本中写的vpc. 我此时释放eks，那么这个vpc也被释放了这个问题应该如何处理？","like_count":1,"discussions":[{"author":{"id":1043450,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/eb/fa/5dc2bcae.jpg","nickname":"潘野","note":"","ucode":"5B60CCA6C00359","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":641567,"discussion_content":"Hi 同学你好\n\n我在课程中的案例是为了能够让计算/网络/存储三块内容在一个例子中体现，所以放在了eks的模块中。\n\n在生产环境中，我建议你将网络相关的配置单独放在一个目录，单独运行CI/CD管理和配置，eks通过变量或者hard code也可以引用你建好的VPC/subnet，因为VPC/subnet的在建好之后配置变动很小。那RDS也同理。\n\n你可以按需拆份，也可以按需合并，比如你启用一个eks集群，这个集群中的应用是需要S3 bucket，你也可以将eks和bucket放在一个模块中管理。\n\n我们基于GitOps的模式，精细管理云资源配置，各类资源的管理方式是非常类似的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1712767239,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":389649,"user_name":"发条橙","can_delete":false,"product_type":"c1","uid":3875922,"ip_address":"上海","ucode":"F52E4EB1F9A3C9","user_header":"https://static001.geekbang.org/account/avatar/00/3b/24/52/4e1f33d0.jpg","comment_is_top":false,"comment_ctime":1713168369,"is_pvip":false,"replies":[{"id":141773,"content":"Hi，同学你好\n\n报错中关键词是InvalidClientTokenId，再检查检查access token和key","user_name":"作者回复","user_name_real":"编辑","uid":1043450,"ctime":1713200630,"ip_address":"上海","comment_id":389649,"utype":1}],"discussion_count":3,"race_medal":0,"score":2,"product_id":100758001,"comment_content":"$ terraform apply\n╷\n│ Error: error configuring Terraform AWS Provider: error validating provider credentials: error calling sts:GetCallerIdentity: operation error STS: GetCallerIdentity, https response error StatusCode: 403, RequestID: afe63bae-7f5f-45b2-a3b5-80364f4a5f34, api error InvalidClientTokenId: The security token included in the request is invalid.\n│ \n│   with provider[&quot;registry.terraform.io&#47;hashicorp&#47;aws&quot;],\n│   on main.tf line 11, in provider &quot;aws&quot;:\n│   11: provider &quot;aws&quot; {\n","like_count":0,"discussions":[{"author":{"id":1043450,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/eb/fa/5dc2bcae.jpg","nickname":"潘野","note":"","ucode":"5B60CCA6C00359","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":642003,"discussion_content":"Hi，同学你好\n\n报错中关键词是InvalidClientTokenId，再检查检查access token和key","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1713200630,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1057056,"avatar":"https://static001.geekbang.org/account/avatar/00/10/21/20/1299e137.jpg","nickname":"秋天","note":"","ucode":"A7E1D953EF7E17","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":653526,"discussion_content":"也遇到了这个问题，解决不了，token和key没问题","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1731058678,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"天津","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3875922,"avatar":"https://static001.geekbang.org/account/avatar/00/3b/24/52/4e1f33d0.jpg","nickname":"发条橙","note":"","ucode":"F52E4EB1F9A3C9","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":642133,"discussion_content":"检查了是对的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1713338311,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":389433,"user_name":"Eason Lau","can_delete":false,"product_type":"c1","uid":1035123,"ip_address":"上海","ucode":"51C987C477F1F0","user_header":"https://static001.geekbang.org/account/avatar/00/0f/cb/73/9eb7c992.jpg","comment_is_top":false,"comment_ctime":1712547422,"is_pvip":false,"replies":[{"id":141682,"content":"Hi Eason,\n\n在nodegroup里可以指定数量，大小，代码见这里\nhttps:&#47;&#47;github.com&#47;cloudnative-automation&#47;eks-cluster&#47;blob&#47;main&#47;eks-cluster.tf#L20-L28\n\neks做完实验之后可以用terraform destroy删掉，用的时候再apply。不过eks的确不像azure的aks有关闭集群的功能，不用的时候关掉，只收取一些磁盘的费用。","user_name":"作者回复","user_name_real":"编辑","uid":1043450,"ctime":1712670657,"ip_address":"上海","comment_id":389433,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100758001,"comment_content":"老师请问你在创建过程中有在哪里指定node的数量么？\n另外就是eks集群是不是得挺贵啊？自己做实验的话😭","like_count":0,"discussions":[{"author":{"id":1043450,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/eb/fa/5dc2bcae.jpg","nickname":"潘野","note":"","ucode":"5B60CCA6C00359","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":641466,"discussion_content":"Hi Eason,\n\n在nodegroup里可以指定数量，大小，代码见这里\nhttps://github.com/cloudnative-automation/eks-cluster/blob/main/eks-cluster.tf#L20-L28\n\neks做完实验之后可以用terraform destroy删掉，用的时候再apply。不过eks的确不像azure的aks有关闭集群的功能，不用的时候关掉，只收取一些磁盘的费用。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1712670657,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":389415,"user_name":"🐭 🐹 🐭 🐹 🐭","can_delete":false,"product_type":"c1","uid":2772251,"ip_address":"河南","ucode":"44B3C088B96C12","user_header":"https://static001.geekbang.org/account/avatar/00/2a/4d/1b/062941b4.jpg","comment_is_top":false,"comment_ctime":1712481925,"is_pvip":false,"replies":[{"id":141685,"content":"Hi，同学你好\n\n文章中举例是以单集群为例，多个集群其实方法一样，只不过加入不同的变量即可。","user_name":"作者回复","user_name_real":"编辑","uid":1043450,"ctime":1712671192,"ip_address":"上海","comment_id":389415,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100758001,"comment_content":"为什么现在遇到的场景基本上是一个集群呢？是因为私有云的原因吗","like_count":0,"discussions":[{"author":{"id":1043450,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/eb/fa/5dc2bcae.jpg","nickname":"潘野","note":"","ucode":"5B60CCA6C00359","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":641469,"discussion_content":"Hi，同学你好\n\n文章中举例是以单集群为例，多个集群其实方法一样，只不过加入不同的变量即可。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1712671192,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":390108,"user_name":"首富手记","can_delete":false,"product_type":"c1","uid":1286588,"ip_address":"江苏","ucode":"879DED4078303C","user_header":"https://static001.geekbang.org/account/avatar/00/13/a1/bc/ef0f26fa.jpg","comment_is_top":false,"comment_ctime":1714376647,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100758001,"comment_content":"多集群管理的时候，就把每个集群的差异地方抽出来 用变量的方式来管理应该就可以了","like_count":0},{"had_liked":false,"id":389385,"user_name":"良凯尔","can_delete":false,"product_type":"c1","uid":1806492,"ip_address":"广东","ucode":"8204DA338BA8F4","user_header":"https://static001.geekbang.org/account/avatar/00/1b/90/9c/288e4db2.jpg","comment_is_top":false,"comment_ctime":1712371324,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100758001,"comment_content":"针对Kubernetes集群的生命周期管理，比如说部署集群、扩容节点等等操作，使用Kubernetes SIGs 的 Cluster API（基于k8s CRD的方式来管理Kubernetes集群）会更加方便，众多云厂商都提供了自己的provider，使得可以基于不同云厂商的基础设施来部署Kubernetes集群；    ","like_count":0}]}