{"id":67968,"title":"07 | 为什么说MapReduce既是编程模型又是计算框架？","content":"<p>在Hadoop问世之前，其实已经有了分布式计算，只是那个时候的分布式计算都是专用的系统，只能专门处理某一类计算，比如进行大规模数据的排序。很显然，这样的系统无法复用到其他的大数据计算场景，每一种应用都需要开发与维护专门的系统。而Hadoop  MapReduce的出现，使得大数据计算通用编程成为可能。我们只要遵循MapReduce编程模型编写业务处理逻辑代码，就可以运行在Hadoop分布式集群上，无需关心分布式计算是如何完成的。也就是说，我们只需要关心业务逻辑，不用关心系统调用与运行环境，这和我们目前的主流开发方式是一致的。</p><p>请你先回忆一下，在前面<a href=\"http://time.geekbang.org/column/article/65106\">专栏第4期</a>我们讨论过，大数据计算的核心思路是移动计算比移动数据更划算。既然计算方法跟传统计算方法不一样，移动计算而不是移动数据，那么用传统的编程模型进行大数据计算就会遇到很多困难，因此Hadoop大数据计算使用了一种叫作MapReduce的编程模型。</p><p>其实MapReduce编程模型并不是Hadoop原创，甚至也不是Google原创，但是Google和Hadoop创造性地将MapReduce编程模型用到大数据计算上，立刻产生了神奇的效果，看似复杂的各种各样的机器学习、数据挖掘、SQL处理等大数据计算变得简单清晰起来。</p><!-- [[[read_end]]] --><p>今天我们就来聊聊<span class=\"orange\">Hadoop解决大规模数据分布式计算的方案——MapReduce</span>。</p><p>在我看来，<strong>MapReduce既是一个编程模型，又是一个计算框架</strong>。也就是说，开发人员必须基于MapReduce编程模型进行编程开发，然后将程序通过MapReduce计算框架分发到Hadoop集群中运行。我们先看一下作为编程模型的MapReduce。</p><p>为什么说MapReduce是一种非常简单又非常强大的编程模型？</p><p>简单在于其编程模型只包含Map和Reduce两个过程，map的主要输入是一对&lt;Key, Value&gt;值，经过map计算后输出一对&lt;Key, Value&gt;值；然后将相同Key合并，形成&lt;Key, Value集合&gt;；再将这个&lt;Key, Value集合&gt;输入reduce，经过计算输出零个或多个&lt;Key, Value&gt;对。</p><p>同时，MapReduce又是非常强大的，不管是关系代数运算（SQL计算），还是矩阵运算（图计算），大数据领域几乎所有的计算需求都可以通过MapReduce编程来实现。</p><p>下面，我以WordCount程序为例，一起来看下MapReduce的计算过程。</p><p>WordCount主要解决的是文本处理中词频统计的问题，就是统计文本中每一个单词出现的次数。如果只是统计一篇文章的词频，几十KB到几MB的数据，只需要写一个程序，将数据读入内存，建一个Hash表记录每个词出现的次数就可以了。这个统计过程你可以看下面这张图。</p><p><img src=\"https://static001.geekbang.org/resource/image/fc/1d/fc8d1ca01c9a81bb75c16dcd504c281d.png?wh=846*218\" alt=\"\"></p><p>如果用Python语言，单机处理WordCount的代码是这样的。</p><pre><code># 文本前期处理\nstrl_ist = str.replace('\\n', '').lower().split(' ')\ncount_dict = {}\n# 如果字典里有该单词则加1，否则添加入字典\nfor str in strl_ist:\nif str in count_dict.keys():\n    count_dict[str] = count_dict[str] + 1\n    else:\n        count_dict[str] = 1\n</code></pre><p>简单说来，就是建一个Hash表，然后将字符串里的每个词放到这个Hash表里。如果这个词第一次放到Hash表，就新建一个Key、Value对，Key是这个词，Value是1。如果Hash表里已经有这个词了，那么就给这个词的Value  +  1。</p><p>小数据量用单机统计词频很简单，但是如果想统计全世界互联网所有网页（数万亿计）的词频数（而这正是Google这样的搜索引擎的典型需求），不可能写一个程序把全世界的网页都读入内存，这时候就需要用MapReduce编程来解决。</p><p>WordCount的MapReduce程序如下。</p><pre><code>public class WordCount {\n\n  public static class TokenizerMapper\n       extends Mapper&lt;Object, Text, Text, IntWritable&gt;{\n\n    private final static IntWritable one = new IntWritable(1);\n    private Text word = new Text();\n\n    public void map(Object key, Text value, Context context\n                    ) throws IOException, InterruptedException {\n      StringTokenizer itr = new StringTokenizer(value.toString());\n      while (itr.hasMoreTokens()) {\n        word.set(itr.nextToken());\n        context.write(word, one);\n      }\n    }\n  }\n\n  public static class IntSumReducer\n       extends Reducer&lt;Text,IntWritable,Text,IntWritable&gt; {\n    private IntWritable result = new IntWritable();\n\n    public void reduce(Text key, Iterable&lt;IntWritable&gt; values,\n                       Context context\n                       ) throws IOException, InterruptedException {\n      int sum = 0;\n      for (IntWritable val : values) {\n        sum += val.get();\n      }\n      result.set(sum);\n      context.write(key, result);\n    }\n  }\n}\n</code></pre><p>你可以从这段代码中看到，MapReduce版本WordCount程序的核心是一个map函数和一个reduce函数。</p><p>map函数的输入主要是一个&lt;Key, Value&gt;对，在这个例子里，Value是要统计的所有文本中的一行数据，Key在一般计算中都不会用到。</p><pre><code>public void map(Object key, Text value, Context context\n                    )\n</code></pre><p>map函数的计算过程是，将这行文本中的单词提取出来，针对每个单词输出一个&lt;word,  1&gt;这样的&lt;Key, Value&gt;对。</p><p>MapReduce计算框架会将这些&lt;word , 1&gt;收集起来，将相同的word放在一起，形成&lt;word , &lt;1,1,1,1,1,1,1…&gt;&gt;这样的&lt;Key, Value集合&gt;数据，然后将其输入给reduce函数。</p><pre><code>public void reduce(Text key, Iterable&lt;IntWritable&gt; values,\n                       Context context\n                       ) \n</code></pre><p>这里reduce的输入参数Values就是由很多个1组成的集合，而Key就是具体的单词word。</p><p>reduce函数的计算过程是，将这个集合里的1求和，再将单词（word）和这个和（sum）组成一个&lt;Key, Value&gt;，也就是&lt;word, sum&gt;输出。每一个输出就是一个单词和它的词频统计总和。</p><p>一个map函数可以针对一部分数据进行运算，这样就可以将一个大数据切分成很多块（这也正是HDFS所做的），MapReduce计算框架为每个数据块分配一个map函数去计算，从而实现大数据的分布式计算。</p><p>假设有两个数据块的文本数据需要进行词频统计，MapReduce计算过程如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/55/ba/5571ed29c5c2254520052adceadf9cba.png?wh=1378*298\" alt=\"\"></p><p>以上就是MapReduce编程模型的主要计算过程和原理，但是这样一个MapReduce程序要想在分布式环境中执行，并处理海量的大规模数据，还需要一个计算框架，能够调度执行这个MapReduce程序，使它在分布式的集群中并行运行，而这个计算框架也叫MapReduce。</p><p>所以，当我们说MapReduce的时候，可能指编程模型，也就是一个MapReduce程序；也可能是指计算框架，调度执行大数据的分布式计算。关于MapReduce计算框架，我们下期再详细聊。</p><h2>小结</h2><p>总结一下，今天我们学习了MapReduce编程模型。这个模型既简单又强大，简单是因为它只包含Map和Reduce两个过程，强大之处又在于它可以实现大数据领域几乎所有的计算需求。这也正是MapReduce这个模型令人着迷的地方。</p><p>说起模型，我想跟你聊聊我的体会。</p><p>模型是人们对一类事物的概括与抽象，可以帮助我们更好地理解事物的本质，更方便地解决问题。比如，数学公式是我们对物理与数学规律的抽象，地图和沙盘是我们对地理空间的抽象，软件架构图是软件工程师对软件系统的抽象。</p><p>通过抽象，我们更容易把握事物的内在规律，而不是被纷繁复杂的事物表象所迷惑，更进一步深刻地认识这个世界。通过抽象，伽利略发现力是改变物体运动的原因，而不是使物体运动的原因，为全人类打开了现代科学的大门。</p><p>这些年，我自己认识了很多优秀的人，他们各有所长、各有特点，但是无一例外都有个共同的特征，就是<strong>对事物的洞察力</strong>。他们能够穿透事物的层层迷雾，直指问题的核心和要害，不会犹豫和迷茫，轻松出手就搞定了其他人看起来无比艰难的事情。有时候光是看他们做事就能感受到一种美感，让人意醉神迷。</p><p><strong>这种洞察力就是来源于他们对事物的抽象能力</strong>，虽然我不知道这种能力缘何而来，但是见识了这种能力以后，我也非常渴望拥有对事物的抽象能力。所以在遇到问题的时候，我就会停下来思考：这个问题为什么会出现，它揭示出来背后的规律是什么，我应该如何做。甚至有时候会把这些优秀的人带入进思考：如果是戴老师、如果是潘大侠，他会如何看待、如何解决这个问题。通过这种不断地训练，虽然和那些最优秀的人相比还是有巨大的差距，但是仍然能够感受到自己的进步，这些小小的进步也会让自己产生大大的快乐，一种不荒废光阴、没有虚度此生的感觉。</p><p>我希望你也能够不断训练自己，遇到问题的时候，停下来思考一下：这些现象背后的规律是什么。有时候并不需要多么艰深的思考，仅仅就是停一下，就会让你察觉到以前不曾注意到的一些情况，进而发现事物的深层规律。这就是洞察力。</p><h2>思考题</h2><p>对于这样一张数据表</p><p><img src=\"https://static001.geekbang.org/resource/image/a6/76/a699fae32164f0c37e03e50bfeec6e76.png?wh=220*234\" alt=\"\"></p><p>如果存储在HDFS中，每一行记录在HDFS对应一行文本，文本格式是</p><pre><code>1,25\n2,25\n1,32\n2,25\n</code></pre><p>根据上面WordCount的示例，请你写一个MapReduce程序，得到下面这条SQL的计算结果。</p><pre><code>SELECT pageid, age, count(1) FROM pv_users GROUP BY pageid, age;\n</code></pre><p>TIPS：如何用MapReduce实现SQL计算，我们在后面还会进一步讨论。</p><p>欢迎你写下自己的思考或疑问，与我和其他同学一起讨论。</p><p></p>","comments":[{"had_liked":false,"id":38605,"user_name":"落叶飞逝的恋","can_delete":false,"product_type":"c1","uid":1046429,"ip_address":"","ucode":"F9A95DB28BCF1E","user_header":"https://static001.geekbang.org/account/avatar/00/0f/f7/9d/be04b331.jpg","comment_is_top":false,"comment_ctime":1542083000,"is_pvip":false,"discussion_count":10,"race_medal":0,"score":"366614303160","product_id":100020201,"comment_content":"老师，我是个大数据的初学者，因为这个专栏是从零入门的，但是目前的我还不知道如何在自己机器上安装哪些软件？如何操作？因为这些问题没解决，所以没办法真切的体会到文中的处理单词统计大数据的魅力。所以希望老师能讲下必备软件的安装的内容，及操作环节。谢谢","like_count":86,"discussions":[{"author":{"id":1370659,"avatar":"https://static001.geekbang.org/account/avatar/00/14/ea/23/508f71e3.jpg","nickname":"Jefitar","note":"","ucode":"D7ED9F32ADA5B1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":57010,"discussion_content":"我觉得这个课程不适合初学者","likes_number":8,"is_delete":false,"is_hidden":false,"ctime":1574558133,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1359701,"avatar":"https://static001.geekbang.org/account/avatar/00/14/bf/55/198c6104.jpg","nickname":"小伟","note":"","ucode":"124953423491E2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":166557,"discussion_content":"自行去hadoop官网下载安装包，按照手册安装。wordcount是quickstart手册里的一个例子，有详细的编码和执行说明，按图索骥就好了。如果这些动手能力都没有，那么需要锻炼，1天不行就2天，2天不行就1周，直到锻炼出来为止。","likes_number":6,"is_delete":false,"is_hidden":false,"ctime":1581411265,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1339820,"avatar":"https://static001.geekbang.org/account/avatar/00/14/71/ac/8295e3e7.jpg","nickname":"书忆江南","note":"","ucode":"90776A7CE06D66","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":254029,"discussion_content":"已在某二线大厂工作接近一年，我是从《Hadoop权威指南》（第四版）零基础入门的，下面这两篇博客是我的Hadoop安装与配置总结，现在已经在搞Spark源码定制开发了\nhttps://blog.csdn.net/qq_33588730/article/details/81123614\nhttps://blog.csdn.net/qq_33588730/article/details/81228315","likes_number":5,"is_delete":false,"is_hidden":false,"ctime":1588288372,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1033169,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/c3/d1/bdf895bf.jpg","nickname":"penng","note":"","ucode":"6087CFCB0AC434","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1339820,"avatar":"https://static001.geekbang.org/account/avatar/00/14/71/ac/8295e3e7.jpg","nickname":"书忆江南","note":"","ucode":"90776A7CE06D66","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":314711,"discussion_content":"厉害","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1603188489,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":254029,"ip_address":""},"score":314711,"extra":""}]},{"author":{"id":1523579,"avatar":"https://wx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLoc8YBNXIiblszCUadC2ZicLiavDibFuH5r8FM8E8tN9H6h1QGCTU0I63z1SNZxXfyuicMWrq0yXXEBnA/132","nickname":"sunyuan","note":"","ucode":"2B1D9DA6E58E80","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":88703,"discussion_content":"这课适合在大数据各种组建中挣扎，想要好好梳理大数据历史和原理的人","likes_number":5,"is_delete":false,"is_hidden":false,"ctime":1576726435,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1309726,"avatar":"https://static001.geekbang.org/account/avatar/00/13/fc/1e/1e48fd05.jpg","nickname":"极无宪","note":"","ucode":"B86438E0930A95","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":139590,"discussion_content":"我想把上面的问答题给弄出来，安装了MyEclipse,但是复制进去之后好多报错?\n报错就咋了，一个个解决，老师这个例子是缺少了引用，那些类是老师自己写的，还是需要引用哪些库？对于一个只有java初步了解的人来说，有点懵。\n我想老师讲这门课是在培养架构师，而不是给对于java或者编程只有初步了解的人看的。\n虽然我有C#的编程基础，为了学好这门课，我还是得去学习一下java的相关知识，虽然我想用C#能够实现？那我为什么不直接用C#实现呢？如果我用C#去实现，但是我不可能实现整个Hadoop吧，哪里不会学哪里吧？网上资料那么多，多搜索一下就好了！刚开始的时候有点难，多下点功夫，等这门课程学完之后一定会收获很多的吧！同学们加油呀！","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1579306089,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3199726,"avatar":"","nickname":"Geek_e4b244","note":"","ucode":"819BBABC05175B","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":590327,"discussion_content":"这课，我觉得比较适合做数据产品经理的人，或者做数据中台产品的人。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1665659108,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"河南"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1483115,"avatar":"https://static001.geekbang.org/account/avatar/00/16/a1/6b/f5f94a6f.jpg","nickname":"Growing Quiet","note":"","ucode":"ADA66BF76802B6","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":581488,"discussion_content":"不是课程出了问题，而是教育出了问题","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1658811299,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1102245,"avatar":"https://static001.geekbang.org/account/avatar/00/10/d1/a5/2bbedc3b.jpg","nickname":"over","note":"","ucode":"FE272AC19842D3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":395910,"discussion_content":"有没有hadoop的docker?","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1632363046,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1185926,"avatar":"https://static001.geekbang.org/account/avatar/00/12/18/86/3599130b.jpg","nickname":"dany","note":"","ucode":"0990375202642F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":47574,"discussion_content":"老师也不回复一下","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1573369236,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":38592,"user_name":"intuition","can_delete":false,"product_type":"c1","uid":1083657,"ip_address":"","ucode":"94D61C78277850","user_header":"https://static001.geekbang.org/account/avatar/00/10/89/09/d660509d.jpg","comment_is_top":false,"comment_ctime":1542078677,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"207700508885","product_id":100020201,"comment_content":"李老师的文章已经不仅仅局限于技术本身 更多的是对人生的的思考 如何去成为一个思考者才是我们所追求的目标","like_count":49},{"had_liked":false,"id":38576,"user_name":"大数据技术与数仓","can_delete":false,"product_type":"c1","uid":1113520,"ip_address":"","ucode":"7F4DD013061A5E","user_header":"https://static001.geekbang.org/account/avatar/00/10/fd/b0/30007f3c.jpg","comment_is_top":false,"comment_ctime":1542076282,"is_pvip":false,"replies":[{"id":"13864","content":"👍🏻","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1542112360,"ip_address":"","comment_id":38576,"utype":1}],"discussion_count":2,"race_medal":0,"score":"143275997050","product_id":100020201,"comment_content":"package com.company.sparkcore<br><br>import org.apache.log4j.{Level, Logger}<br>import org.apache.spark.{SparkConf, SparkContext}<br><br>object CountPVByGroup {<br>  def main(args: Array[String]): Unit = {<br>    val conf = new SparkConf()<br>      .setAppName(CountPVByGroup.getClass.getSimpleName)<br>      .setMaster(&quot;local&quot;)<br>    Logger.getLogger(&quot;org.apache.spark&quot;).setLevel(Level.OFF)<br>    Logger.getLogger(&quot;org.apache.hadoop&quot;).setLevel(Level.OFF)<br>    val sc = new SparkContext(conf)<br>    val lines = sc.textFile(&quot;file:&#47;&#47;&#47;e:&#47;pv_users.txt&quot;)<br>    &#47;&#47;拼接成（1_25,1）的形式<br>    val newKeyValue =  lines.map(_.split(&quot;,&quot;)).map(pvdata =&gt; ((pvdata(0)+ &quot;_&quot; + pvdata(1)),1))<br>   &#47;&#47;对上述KV进行统计<br>    val pvcount = newKeyValue.reduceByKey(_ + _)<br>    &#47;&#47;将拼接符号去掉，组合成形如(1,25,1)的形式<br>    val pvid_age_count = pvcount.map(newkv =&gt; (newkv._1.split(&quot;_&quot;)(0),newkv._1.split(&quot;_&quot;)(1),newkv._2))<br>    &#47;&#47;结果输出<br>&#47;&#47;    (1,25,1)<br>&#47;&#47;    (2,25,2)<br>&#47;&#47;    (1,32,1)<br>    pvid_age_count.collect().foreach(println)<br>  }<br><br>}","like_count":34,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":428751,"discussion_content":"👍🏻","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1542112360,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2518863,"avatar":"https://static001.geekbang.org/account/avatar/00/26/6f/4f/3cf1e9c4.jpg","nickname":"钱鹏 Allen","note":"","ucode":"7E95E82C0717DA","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":392300,"discussion_content":"厉害，运行的时候发现自己数组中断越界，没想到是存入的文件不是以逗号分割开来的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1630938202,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":40039,"user_name":"朱国伟","can_delete":false,"product_type":"c1","uid":1083343,"ip_address":"","ucode":"A8547956D9C372","user_header":"https://static001.geekbang.org/account/avatar/00/10/87/cf/7bec93d8.jpg","comment_is_top":false,"comment_ctime":1542450073,"is_pvip":true,"replies":[{"id":"14437","content":"👍🏻","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1542525229,"ip_address":"","comment_id":40039,"utype":1}],"discussion_count":1,"race_medal":0,"score":"117506567065","product_id":100020201,"comment_content":"单机安装伪hadoop集群<br>见：https:&#47;&#47;hadoop.apache.org&#47;docs&#47;stable&#47;hadoop-project-dist&#47;hadoop-common&#47;SingleCluster.html<br>注：在Mac中安装遇到了一些问题 但是google一下就能解决 恕不一一道来<br><br>思考题解答步骤<br>cat pv_users<br>1,25<br>2,25<br>1,32<br>2,25<br><br># 导入该文件到dfs中<br>bin&#47;hdfs dfs -put pv_users pv_users<br><br># 因为每一行只有pageid, age并且中间没有空格 可以直接利用hadoop自带的wordcount程序<br># 读取dfs中的pv_user文件 进行统计 然后将结果输出到pv_users_count中<br>bin&#47;yarn jar share&#47;hadoop&#47;mapreduce&#47;hadoop-mapreduce-examples-2.9.1.jar wordcount pv_users pv_users_count<br># 读取统计结果<br>bin&#47;hdfs dfs -cat pv_users_count&#47;part-r-00000<br>1,25\t1<br>1,32\t1<br>2,25\t2<br>","like_count":28,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":429346,"discussion_content":"👍🏻","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1542525229,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":38462,"user_name":"无形","can_delete":false,"product_type":"c1","uid":1016889,"ip_address":"","ucode":"B740E2A68A17A5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/84/39/c8772466.jpg","comment_is_top":false,"comment_ctime":1542040271,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"83146418895","product_id":100020201,"comment_content":"把pageID和age当做key计算出现的次数并做汇总，然后对key排序，输出排序后的key和其对应的总次数","like_count":20},{"had_liked":false,"id":42446,"user_name":"喜笑延开","can_delete":false,"product_type":"c1","uid":1240321,"ip_address":"","ucode":"DBF645D2129460","user_header":"https://static001.geekbang.org/account/avatar/00/12/ed/01/997432f3.jpg","comment_is_top":false,"comment_ctime":1542956089,"is_pvip":false,"replies":[{"id":"15187","content":"👍🏻","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1542969055,"ip_address":"","comment_id":42446,"utype":1}],"discussion_count":1,"race_medal":0,"score":"78852367417","product_id":100020201,"comment_content":"不能光想，必须动手实践：<br>## Mapper<br>public class PageMapper extends Mapper&lt;LongWritable,Text,Text,IntWritable&gt; {<br>    @Override<br>    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {<br>        String data = value.toString();<br>        String[] words = data.split(&quot;\\n&quot;);<br>        for (String word : words) {<br>            context.write(new Text(word), new IntWritable(1));<br>        }<br>    }<br>}<br>## Reducer<br>public class PageReducer extends Reducer&lt;Text,IntWritable,Text,IntWritable&gt; {<br>    @Override<br>    protected void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException {<br>        int total=0;<br>        for (IntWritable value : values) {<br>            total=total+value.get();<br>        }<br>        context.write(key, new IntWritable(total));<br>    }<br>}<br>##  Main<br>public class PageMain {<br>    public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException {<br>        Job job = Job.getInstance();<br>        job.setJarByClass(PageMain.class);<br><br>        job.setMapperClass(PageMapper.class);<br>        job.setMapOutputKeyClass(Text.class);<br>        job.setMapOutputValueClass(IntWritable.class);<br><br>        job.setReducerClass(PageReducer.class);<br>        job.setOutputKeyClass(Text.class);<br>        job.setOutputValueClass(IntWritable.class);<br><br>        FileInputFormat.setInputPaths(job,new Path(args[0]));<br>        FileOutputFormat.setOutputPath(job, new Path(args[1]));<br><br>        job.waitForCompletion(true);<br><br><br>    }<br>}<br><br>## 命令行<br>hadoop jar page-1.0-SNAPSHOT.jar PageMain &#47;input&#47;page  &#47;output5<br>ps：第一次运行报错了~~（不练不知道）<br>错误：Initialization of all the collectors failed. Error in last collector was :interface javax.xml.soap.<br>原因：编写Main的时候，Text的引用import错了，习惯了弹出提示直接确定~应该导入`import org.apache.hadoop.io.Text;`","like_count":19,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":430095,"discussion_content":"👍🏻","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1542969055,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":39396,"user_name":"有铭","can_delete":false,"product_type":"c1","uid":1046302,"ip_address":"","ucode":"2C7CB36CA5C04C","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/3XbCueYYVWTiclv8T5tFpwiblOxLphvSZxL4ujMdqVMibZnOiaFK2C5nKRGv407iaAsrI0CDICYVQJtiaITzkjfjbvrQ/132","comment_is_top":false,"comment_ctime":1542264448,"is_pvip":false,"replies":[{"id":"14138","content":"map函数输入的key，表示这行数据在文件中的偏移量，通常忽略掉","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1542293472,"ip_address":"","comment_id":39396,"utype":1}],"discussion_count":3,"race_medal":0,"score":"70261741184","product_id":100020201,"comment_content":"我想问一下那个计算过程的示意图里map输入部分，上面的是0，12，下面是0，13，是啥意思？","like_count":17,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":429047,"discussion_content":"map函数输入的key，表示这行数据在文件中的偏移量，通常忽略掉","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1542293472,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1117889,"avatar":"https://static001.geekbang.org/account/avatar/00/11/0e/c1/e2a9cbc1.jpg","nickname":"jinhaoqi","note":"","ucode":"767929B4AF93A6","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":2464,"discussion_content":"偏移量是指什么？\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563675708,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1409705,"avatar":"https://static001.geekbang.org/account/avatar/00/15/82/a9/5c64c6b0.jpg","nickname":"苏木春夏冬","note":"","ucode":"4D19AB2AEC9C2E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1117889,"avatar":"https://static001.geekbang.org/account/avatar/00/11/0e/c1/e2a9cbc1.jpg","nickname":"jinhaoqi","note":"","ucode":"767929B4AF93A6","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":234646,"discussion_content":"当前行挪几个位置能读到value","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586980805,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":2464,"ip_address":""},"score":234646,"extra":""}]}]},{"had_liked":false,"id":38504,"user_name":"一箭中的","can_delete":false,"product_type":"c1","uid":1025729,"ip_address":"","ucode":"9D18662C5CCF7A","user_header":"https://static001.geekbang.org/account/avatar/00/0f/a6/c1/d4e6147e.jpg","comment_is_top":false,"comment_ctime":1542069062,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"53081676614","product_id":100020201,"comment_content":"将pageid和 age拼接成字符串当做一个key，然后通过Map和Reduce计算即可得出对应的count","like_count":13},{"had_liked":false,"id":151041,"user_name":"Zend","can_delete":false,"product_type":"c1","uid":1053921,"ip_address":"","ucode":"80EBB0B6772E27","user_header":"https://static001.geekbang.org/account/avatar/00/10/14/e1/ee5705a2.jpg","comment_is_top":false,"comment_ctime":1573646560,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"44523319520","product_id":100020201,"comment_content":"--Map输入--<br>1,25<br>2,25<br>1,32<br>2,25<br>--Map计算后的结果为Map输出--<br>&lt;&lt;1,25&gt;,1&gt;<br>&lt;&lt;2,25&gt;,1&gt;<br>&lt;&lt;1,32&gt;,1&gt;<br>&lt;&lt;2,25&gt;,1&gt;<br>--MapReduce计算框架处理后的结果为Reduce输入--<br>&lt;&lt;1,25&gt;,&lt;1&gt;&gt;<br>&lt;&lt;2,25&gt;,&lt;1,1&gt;&gt;<br>&lt;&lt;1,32&gt;,&lt;1&gt;&gt;<br>--Reduce计算后的结果为Reduce输出--<br>&lt;&lt;1,25&gt;,1&gt;<br>&lt;&lt;2,25&gt;,2&gt;<br>&lt;&lt;1,32&gt;,1&gt;","like_count":11},{"had_liked":false,"id":38662,"user_name":"小辉辉","can_delete":false,"product_type":"c1","uid":1189661,"ip_address":"","ucode":"9FF25E25C85350","user_header":"https://static001.geekbang.org/account/avatar/00/12/27/1d/1cb36854.jpg","comment_is_top":false,"comment_ctime":1542099768,"is_pvip":false,"replies":[{"id":"13858","content":"👍🏻","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1542111829,"ip_address":"","comment_id":38662,"utype":1}],"discussion_count":1,"race_medal":0,"score":"44491772728","product_id":100020201,"comment_content":"java8中的流式框架也用的MapReduce，之前一直没理解用MapReduce的意义何在，今天突然顿悟。<br>软件中很多思想和设计都是通用的，今天接触一种新东西，明天说不定在其它地方又能碰到，又能加深一遍印象。所以说学得多了，很多时间就可以融会贯通了。","like_count":11,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":428772,"discussion_content":"👍🏻","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1542111829,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":38616,"user_name":"Ahikaka","can_delete":false,"product_type":"c1","uid":1045146,"ip_address":"","ucode":"B3A678567E40A9","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/vhOPEib27xAuTycN0eQekLzsCe9zwcTTcrOb98cIfpgibgcweZBDN38tIicABibuZBwah9jnGVr02H2Zjuue1fLfEQ/132","comment_is_top":false,"comment_ctime":1542084954,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"44491757914","product_id":100020201,"comment_content":"老师能不能推荐些学大数据的书籍，博客，网站 。","like_count":10,"discussions":[{"author":{"id":1339820,"avatar":"https://static001.geekbang.org/account/avatar/00/14/71/ac/8295e3e7.jpg","nickname":"书忆江南","note":"","ucode":"90776A7CE06D66","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":254032,"discussion_content":"《Hadoop权威指南》（第四版）、《Spark权威指南》\n适合初学者学习hadoop的书籍？ - 书忆江南的回答 - 知乎\nhttps://www.zhihu.com/question/278070602/answer/878291281\n有什么关于 Spark 的书推荐？ - 书忆江南的回答 - 知乎\nhttps://www.zhihu.com/question/23655827/answer/1039397401","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588289088,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":39503,"user_name":"糊糊","can_delete":false,"product_type":"c1","uid":1067825,"ip_address":"","ucode":"74875CB3A84E18","user_header":"https://static001.geekbang.org/account/avatar/00/10/4b/31/c1ce2abc.jpg","comment_is_top":false,"comment_ctime":1542291972,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"31607063044","product_id":100020201,"comment_content":"mapreduce核心思想就跟传统的SQL中的group by一样","like_count":7},{"had_liked":false,"id":39487,"user_name":"呆猫","can_delete":false,"product_type":"c1","uid":1228759,"ip_address":"","ucode":"69E256E6A19225","user_header":"https://static001.geekbang.org/account/avatar/00/12/bf/d7/9e2c8648.jpg","comment_is_top":false,"comment_ctime":1542288286,"is_pvip":false,"replies":[{"id":"14174","content":"谢谢","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1542332078,"ip_address":"","comment_id":39487,"utype":1}],"discussion_count":1,"race_medal":0,"score":"27312092062","product_id":100020201,"comment_content":"文章真的是看的赏心悦目，尤其是那段描述抽象的文字😃","like_count":6,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":429081,"discussion_content":"谢谢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1542332078,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":38531,"user_name":"李二木","can_delete":false,"product_type":"c1","uid":1103091,"ip_address":"","ucode":"30E03BB84ADB27","user_header":"https://static001.geekbang.org/account/avatar/00/10/d4/f3/129d6dfe.jpg","comment_is_top":false,"comment_ctime":1542071612,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"27311875388","product_id":100020201,"comment_content":"看到这个问题，我在想我在怎么想？","like_count":6},{"had_liked":false,"id":38630,"user_name":"老男孩","can_delete":false,"product_type":"c1","uid":1134514,"ip_address":"","ucode":"CEC6D47412F620","user_header":"https://static001.geekbang.org/account/avatar/00/11/4f/b2/1e8b5616.jpg","comment_is_top":false,"comment_ctime":1542090418,"is_pvip":false,"replies":[{"id":"13859","content":"是的","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1542111896,"ip_address":"","comment_id":38630,"utype":1}],"discussion_count":1,"race_medal":0,"score":"23016926898","product_id":100020201,"comment_content":"老师关于抽象是洞察事物本质的总结很精辟。关于思考题，我的思路是把pageid+age作为map函数计算key值，value分别是1。然后reduce再根据key对value的集合进行sum。就可以得出sql的结果。","like_count":5,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":428762,"discussion_content":"是的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1542111896,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":38694,"user_name":"明天更美好","can_delete":false,"product_type":"c1","uid":1180696,"ip_address":"","ucode":"F036B8718938BE","user_header":"https://static001.geekbang.org/account/avatar/00/12/04/18/4b02510f.jpg","comment_is_top":false,"comment_ctime":1542108571,"is_pvip":false,"replies":[{"id":"14037","content":"你可能需要一个完整的技术架构方案，而不只是HBASE能不能搞定的问题，建议你看下我写另一本书《大型网站技术架构：核心原理与案例分析》，专栏后面也会对大数据架构有各个角度的探讨，欢迎持续关注","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1542244924,"ip_address":"","comment_id":38694,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18721977755","product_id":100020201,"comment_content":"对于大数据来说是盲区，如果应用直接往hbase中写可以吗？2.5万的并发。hbase可以满足我们的查询需求吗？还有日志分析","like_count":4,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":428778,"discussion_content":"你可能需要一个完整的技术架构方案，而不只是HBASE能不能搞定的问题，建议你看下我写另一本书《大型网站技术架构：核心原理与案例分析》，专栏后面也会对大数据架构有各个角度的探讨，欢迎持续关注","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1542244924,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":38572,"user_name":"Lambda","can_delete":false,"product_type":"c1","uid":1032807,"ip_address":"","ucode":"0B0CCFC0991B10","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eobHCkMA1WJgZZYRfHqXDeIwybVwSxNGFAWWSunYVNLiaKia6q3rVkG7P8tl4ZcNRI7iaxdZhVckroVA/132","comment_is_top":false,"comment_ctime":1542075729,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"18721944913","product_id":100020201,"comment_content":"好像中间拉下了 shuffle ","like_count":4},{"had_liked":false,"id":55857,"user_name":"小成","can_delete":false,"product_type":"c1","uid":1350143,"ip_address":"","ucode":"1BC685767B0FBD","user_header":"https://static001.geekbang.org/account/avatar/00/14/99/ff/046495bb.jpg","comment_is_top":false,"comment_ctime":1546330268,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"14431232156","product_id":100020201,"comment_content":"老师，我是大数据初学者，除了编程语言本身的，可以推荐一些书籍或者资料辅助这个专栏的学习吗，像hadoop相关类的，这期的代码看不懂了。","like_count":3},{"had_liked":false,"id":41560,"user_name":"无处不在","can_delete":false,"product_type":"c1","uid":1157533,"ip_address":"","ucode":"BB535BC6F448F4","user_header":"https://static001.geekbang.org/account/avatar/00/11/a9/9d/bdfd9e58.jpg","comment_is_top":false,"comment_ctime":1542805941,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"14427707829","product_id":100020201,"comment_content":"这个如果在复杂或者高级一点，就需要用mapreduce的序列化对象作为key的功能去实现了，最近也在学习大数据，学的时候感觉找到了sql的本质，记得公司前年的项目就是手写了一堆js函数，实现了mongodb的类似sql的分组聚合操作。<br>后续可以开设视频的专栏就更好了","like_count":3},{"had_liked":false,"id":39132,"user_name":"曾海飞","can_delete":false,"product_type":"c1","uid":1137487,"ip_address":"","ucode":"5FACE924E0211B","user_header":"https://static001.geekbang.org/account/avatar/00/11/5b/4f/d4030e6b.jpg","comment_is_top":false,"comment_ctime":1542195192,"is_pvip":false,"replies":[{"id":"14016","content":"map任务有很多，所以map任务输出的key全部合并在一起才能reduce，请看下期文章。","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1542239144,"ip_address":"","comment_id":39132,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14427097080","product_id":100020201,"comment_content":"为什么相同key的合并是形成&lt;key, value集合&gt;而不是直接形成一个&lt;key,  value reduce后的结果&gt;呢？后者不是效率更高吗？","like_count":3,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":428932,"discussion_content":"map任务有很多，所以map任务输出的key全部合并在一起才能reduce，请看下期文章。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1542239144,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":41146,"user_name":"牛油果","can_delete":false,"product_type":"c1","uid":1047154,"ip_address":"","ucode":"897D927418C609","user_header":"https://static001.geekbang.org/account/avatar/00/0f/fa/72/5c801d71.jpg","comment_is_top":false,"comment_ctime":1542732439,"is_pvip":true,"replies":[{"id":"14780","content":"谢谢，共勉。","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1542763930,"ip_address":"","comment_id":41146,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10132667031","product_id":100020201,"comment_content":"后面一段话，一看就是好人，好老师。","like_count":3,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":429712,"discussion_content":"谢谢，共勉。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1542763930,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":39173,"user_name":"ward-wolf","can_delete":false,"product_type":"c1","uid":1031845,"ip_address":"","ucode":"BC41D01301263A","user_header":"https://static001.geekbang.org/account/avatar/00/0f/be/a5/df917d18.jpg","comment_is_top":false,"comment_ctime":1542202936,"is_pvip":false,"replies":[{"id":"14017","content":"是的","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1542239184,"ip_address":"","comment_id":39173,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10132137528","product_id":100020201,"comment_content":"我的思路和前面几个同学的类似，就是把文本直接当做key，value使用数字统计，最后就是通过reduce统计出现次数了","like_count":2,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":428952,"discussion_content":"是的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1542239184,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":245888,"user_name":"珠闪闪","can_delete":false,"product_type":"c1","uid":1300447,"ip_address":"","ucode":"45BE0D586A3839","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eov38ZkwCyNoBdr5drgX0cp2eOGCv7ibkhUIqCvcnFk8FyUIS6K4gHXIXh0fu7TB67jaictdDlic4OwQ/132","comment_is_top":false,"comment_ctime":1599102594,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5894069890","product_id":100020201,"comment_content":"为智慧老师的文字而激动。让我对工作 学习和生活有了更多的思考。<br><br>关注模型，遇见问题努力去抽象。<br><br>遇见事情停下来思考一下。这个问题为什么会出现，背后的规律是什么，如何解决这个问题。<br><br>当每件事情停下来想一下，就会让自己察觉到以前不曾注意的一些情况，进而发现事物深层的规律，这就是洞察力<br><br>","like_count":2},{"had_liked":false,"id":72676,"user_name":"落叶飞逝的恋","can_delete":false,"product_type":"c1","uid":1046429,"ip_address":"","ucode":"F9A95DB28BCF1E","user_header":"https://static001.geekbang.org/account/avatar/00/0f/f7/9d/be04b331.jpg","comment_is_top":false,"comment_ctime":1551691133,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"5846658429","product_id":100020201,"comment_content":"回过头来继续看文章，目前使用的是这个搭建的阿里云伪集群<br>http:&#47;&#47;archive.cloudera.com&#47;cdh5&#47;cdh&#47;5&#47;hadoop-2.6.0-cdh5.7.0&#47;","like_count":1,"discussions":[{"author":{"id":1880782,"avatar":"https://static001.geekbang.org/account/avatar/00/1c/b2/ce/5638be2b.jpg","nickname":"Flychen","note":"","ucode":"4029A8F1D3C361","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":390345,"discussion_content":"这个还需要用户密码登录信息","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1629792779,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":39032,"user_name":"万东海","can_delete":false,"product_type":"c1","uid":1192844,"ip_address":"","ucode":"1723F7BC82913C","user_header":"https://static001.geekbang.org/account/avatar/00/12/33/8c/7363897a.jpg","comment_is_top":false,"comment_ctime":1542175547,"is_pvip":false,"replies":[{"id":"14014","content":"对","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1542238967,"ip_address":"","comment_id":39032,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5837142843","product_id":100020201,"comment_content":"思考题的答案就是老师文中的吗? <br>把 <br>1,25<br>2,25<br>1,32<br>2,25<br>直接当成单词理解","like_count":1,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":428884,"discussion_content":"对","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1542238967,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":38611,"user_name":"无形","can_delete":false,"product_type":"c1","uid":1016889,"ip_address":"","ucode":"B740E2A68A17A5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/84/39/c8772466.jpg","comment_is_top":false,"comment_ctime":1542084247,"is_pvip":true,"replies":[{"id":"13860","content":"可以这样理解","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1542112004,"ip_address":"","comment_id":38611,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5837051543","product_id":100020201,"comment_content":"感觉大数据处理和需要汇总处理结果的多线程有点类似，任务分发到多个线程，并行处理，等到所有线程处理完毕汇总结果再统一处理返回，不知道理解的对不对","like_count":1,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":428757,"discussion_content":"可以这样理解","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1542112004,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":338696,"user_name":"长期规划","can_delete":false,"product_type":"c1","uid":1019332,"ip_address":"","ucode":"5EF65E9115834B","user_header":"https://static001.geekbang.org/account/avatar/00/0f/8d/c4/6f97daea.jpg","comment_is_top":false,"comment_ctime":1647669899,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1647669899","product_id":100020201,"comment_content":"之前也断断续续看过Hadoop，但一直没搞明白整个流程。今天终于明白了，Map函数映射后的数据，会由MapReduce框架聚合，聚合为列表，然后传给Reduce函数，由它使用聚合方法聚合。","like_count":0},{"had_liked":false,"id":327301,"user_name":"*其","can_delete":false,"product_type":"c1","uid":2859880,"ip_address":"","ucode":"B1B0A47CEDECC3","user_header":"https://static001.geekbang.org/account/avatar/00/2b/a3/68/e913d823.jpg","comment_is_top":false,"comment_ctime":1640054302,"is_pvip":false,"replies":[{"id":"119473","content":"如果只是安装的话，不高，个人电脑就可以","user_name":"作者回复","user_name_real":"编辑","uid":"1007349","ctime":1640573214,"ip_address":"","comment_id":327301,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1640054302","product_id":100020201,"comment_content":"安装Hadoop的各种组件对硬件配置要求很高吧","like_count":0,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":541807,"discussion_content":"如果只是安装的话，不高，个人电脑就可以","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1640573215,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":324329,"user_name":"Geek3607","can_delete":false,"product_type":"c1","uid":2811567,"ip_address":"","ucode":"E16DFE1A65119C","user_header":"","comment_is_top":false,"comment_ctime":1638372330,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1638372330","product_id":100020201,"comment_content":"假设这四个数据放在了四个服务器上，则有<br>map过程<br>1、<br>1 25，1<br>2 25，1<br>1 32，1<br>2 25，1<br>2、整理变成<br>1 25，1<br>2 25 ，1，1<br>1 32，1<br><br>reduce后<br>1 25，1<br>2 25，2<br>1 32，1","like_count":0},{"had_liked":false,"id":324244,"user_name":"hujihu33","can_delete":false,"product_type":"c1","uid":1078729,"ip_address":"","ucode":"686860FE2DFABB","user_header":"https://static001.geekbang.org/account/avatar/00/10/75/c9/fb23007c.jpg","comment_is_top":false,"comment_ctime":1638347328,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1638347328","product_id":100020201,"comment_content":"map: &lt;(1,25),&lt;1&gt;&gt;,&lt;(2,25),&lt;1,1&gt;&gt;,&lt;(1,32),&lt;1&gt;&gt;","like_count":0},{"had_liked":false,"id":323148,"user_name":"骆驼、","can_delete":false,"product_type":"c1","uid":1443660,"ip_address":"","ucode":"252ECDB1524867","user_header":"https://static001.geekbang.org/account/avatar/00/16/07/4c/f9852f8f.jpg","comment_is_top":false,"comment_ctime":1637744070,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1637744070","product_id":100020201,"comment_content":"public static class ReadMapper extends Mapper&lt;Object, Text, Text, Text&gt; {<br>        @Override<br>        protected void map(Object key, Text value, Context context) throws IOException, InterruptedException {<br>            context.write(value,new Text(&quot;1&quot;));<br>        }<br>    }<br><br>    public static class WriteReducer extends Reducer&lt;Text,Text,Text,Text&gt;{<br>        @Override<br>        protected void reduce(Text key, Iterable&lt;Text&gt; values, Context context) throws IOException, InterruptedException {<br>            int sum = 0;<br>            for (Text value : values) {<br>                sum+=Integer.valueOf(value.toString()).intValue();<br>            }<br>            String outKey = key.toString()+&quot;,&quot;+sum;<br>            context.write(new Text(outKey),new Text(&quot;&quot;));<br>        }<br>    }","like_count":1},{"had_liked":false,"id":281519,"user_name":"极客人","can_delete":false,"product_type":"c1","uid":2445847,"ip_address":"","ucode":"D492AA710F6D4E","user_header":"","comment_is_top":false,"comment_ctime":1614772051,"is_pvip":false,"replies":[{"id":"102304","content":"大部分大数据软件都是Java或者基于JVM的语言编写的。","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1614915532,"ip_address":"","comment_id":281519,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1614772051","product_id":100020201,"comment_content":"老师，文章中的代码是Java语言写的吗，因为我是0基础的，看不懂上面的代码，是否需要去补充基本的语言编程基础？","like_count":1,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":516428,"discussion_content":"大部分大数据软件都是Java或者基于JVM的语言编写的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1614915532,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":265365,"user_name":"Geek_964b0f","can_delete":false,"product_type":"c1","uid":2295031,"ip_address":"","ucode":"D6AEDAEF609020","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/sQV132p5s2Nicia1wJPiafJtMP5ic0kwpzntdkibInNScCeic0ZvDE7y90nCM7rGDaZ2DiaRlYjhoplOpJVGlbibkToAPg/132","comment_is_top":false,"comment_ctime":1606878593,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1606878593","product_id":100020201,"comment_content":"https:&#47;&#47;hadoop.apache.org&#47;docs&#47;current&#47;hadoop-mapreduce-client&#47;hadoop-mapreduce-client-core&#47;MapReduceTutorial.html#Example:_WordCount_v1.0<br><br>课程代码来源。<br><br>在专栏上复制老师给的代码，0基础搞真的不太行，从找对应的maven依赖再到找包导入，最后main里面的测试代码仍然是无从下手。","like_count":1},{"had_liked":false,"id":250355,"user_name":"Geek_1a0e29","can_delete":false,"product_type":"c1","uid":1478573,"ip_address":"","ucode":"DFFDEA3A9A23D5","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKBS8Xf2qLLpEe6eXkkTr7PPK0WeyHZe7NzP8S8pUGyyfO5SkSSx9E5S4qdtcINAmdfdSXUKWusvA/132","comment_is_top":false,"comment_ctime":1601036443,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1601036443","product_id":100020201,"comment_content":"和我想的一样，任何高深复杂的技术都有一个极其简单优雅的模型！大道至简真的不是说说而已！","like_count":0},{"had_liked":false,"id":231437,"user_name":"Run_dream","can_delete":false,"product_type":"c1","uid":1373602,"ip_address":"","ucode":"1BD4AAFCE72B99","user_header":"https://static001.geekbang.org/account/avatar/00/14/f5/a2/8a470344.jpg","comment_is_top":false,"comment_ctime":1593676354,"is_pvip":false,"discussion_count":0,"race_medal":1,"score":"1593676354","product_id":100020201,"comment_content":"本质上和wordcount一样的<br>import java.io.IOException;<br>import java.util.StringTokenizer;<br><br>import org.apache.hadoop.conf.Configuration;<br>import org.apache.hadoop.fs.Path;<br>import org.apache.hadoop.io.IntWritable;<br>import org.apache.hadoop.io.Text;<br>import org.apache.hadoop.mapreduce.Job;<br>import org.apache.hadoop.mapreduce.Mapper;<br>import org.apache.hadoop.mapreduce.Reducer;<br>import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;<br>import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;<br><br>public class PageView {<br>\tpublic static class TokenizerMapper extends Mapper&lt;Object, Text, Text, IntWritable&gt; {<br>\t\tprivate final static IntWritable one = new IntWritable(1);<br>\t\tprivate Text word = new Text();<br><br>\t\tpublic void map(Object key, Text value, Context context) throws IOException, InterruptedException {<br>\t\t\tStringTokenizer itr = new StringTokenizer(value.toString());<br>\t\t\twhile (itr.hasMoreTokens()) {<br>\t\t\t\tword.set(itr.nextToken());<br>\t\t\t\tcontext.write(word, one);<br>\t\t\t}<br>\t\t}<br>\t}<br><br>\tpublic static class IntSumReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {<br>\t\tprivate IntWritable result = new IntWritable();<br><br>\t\tpublic void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context)<br>\t\t\t\tthrows IOException, InterruptedException {<br>\t\t\tint sum = 0;<br>\t\t\tfor (IntWritable val : values) {<br>\t\t\t\tsum += val.get();<br>\t\t\t}<br>\t\t\tresult.set(sum);<br>\t\t\tcontext.write(key, result);<br>\t\t}<br>\t}<br><br>\tpublic static void main(String[] args) throws Exception {<br>\t\tConfiguration conf = new Configuration();<br>\t\tJob job = Job.getInstance(conf, &quot;page view&quot;);<br>\t\tjob.setJarByClass(PageView.class);<br>\t\tjob.setMapperClass(TokenizerMapper.class);<br>\t\tjob.setCombinerClass(IntSumReducer.class);<br>\t\tjob.setReducerClass(IntSumReducer.class);<br>\t\tjob.setOutputKeyClass(Text.class);<br>\t\tjob.setOutputValueClass(IntWritable.class);<br>\t\tFileInputFormat.addInputPath(job, new Path(args[0]));<br>\t\tFileOutputFormat.setOutputPath(job, new Path(args[1]));<br>\t\tSystem.exit(job.waitForCompletion(true) ? 0 : 1);<br>\t}<br>}<br>","like_count":0},{"had_liked":false,"id":189785,"user_name":"做你的线程","can_delete":false,"product_type":"c1","uid":1920691,"ip_address":"","ucode":"8D8EA8927381BE","user_header":"https://static001.geekbang.org/account/avatar/00/1d/4e/b3/f5f24e3a.jpg","comment_is_top":false,"comment_ctime":1584549013,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1584549013","product_id":100020201,"comment_content":"老师你好，如何用python代替java实习功能呢","like_count":0},{"had_liked":false,"id":171493,"user_name":"淤白","can_delete":false,"product_type":"c1","uid":1206503,"ip_address":"","ucode":"D1E65DC40DAF68","user_header":"https://static001.geekbang.org/account/avatar/00/12/68/e7/ee47d0e2.jpg","comment_is_top":false,"comment_ctime":1578930954,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1578930954","product_id":100020201,"comment_content":"将 pageid, age 拼接成一个 key，用于 map 操作计算出现的次数，然后用 reduce 做统计。","like_count":0},{"had_liked":false,"id":164801,"user_name":"InfoQ_e077cb303519","can_delete":false,"product_type":"c1","uid":1390669,"ip_address":"","ucode":"2CCA309DB2EF46","user_header":"https://wx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLAK6F4BFT5ewhJEeZrjmRx5HxP8tvnNpJcpLlotHiadp0s6aL3d7LfMHEuQP6tibu80wUy8micVu4oQ/132","comment_is_top":false,"comment_ctime":1577093174,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1577093174","product_id":100020201,"comment_content":"抽象问题，洞悉本质，深有同感","like_count":0},{"had_liked":false,"id":156809,"user_name":"Coding小先","can_delete":false,"product_type":"c1","uid":1051563,"ip_address":"","ucode":"965B1CC757E026","user_header":"https://static001.geekbang.org/account/avatar/00/10/0b/ab/0e2857e5.jpg","comment_is_top":false,"comment_ctime":1574961368,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1574961368","product_id":100020201,"comment_content":"弄了个这个，对这个开发有了大概的了解<br><br>    public static class TokenizerMapper extends Mapper&lt;Object, Text, Text, IntWritable&gt; {<br>        private Text id = new Text();<br>        private IntWritable num = new IntWritable();<br><br>        public void map(Object key, Text value, Context context) throws IOException, InterruptedException {<br>            &#47;&#47; 按照 回车 空格 制表符 等截断 传入的 value<br>            StringTokenizer itr = new StringTokenizer(value.toString());<br>            while (itr.hasMoreTokens()) {<br>                &#47;&#47; 再根据 , 切割一行记录<br>                StringTokenizer str = new StringTokenizer(itr.nextToken().toString(), &quot;,&quot;);<br>                &#47;&#47; id 的值<br>                id.set(str.nextToken());<br>                &#47;&#47; 销量的值 转换为整型<br>                num.set(Integer.parseInt(str.nextToken().toString()));<br>                &#47;&#47; 写入 Map<br>                context.write(id, num);<br>            }<br>      ","like_count":0},{"had_liked":false,"id":138400,"user_name":"我是谁","can_delete":false,"product_type":"c1","uid":1168322,"ip_address":"","ucode":"0CEE16C25F4B23","user_header":"https://static001.geekbang.org/account/avatar/00/11/d3/c2/3f32b93b.jpg","comment_is_top":false,"comment_ctime":1570197864,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1570197864","product_id":100020201,"comment_content":"老师  大数据运行环境能否介绍下呢？","like_count":0},{"had_liked":false,"id":136705,"user_name":"钱","can_delete":false,"product_type":"c1","uid":1009652,"ip_address":"","ucode":"2C92A243A463D4","user_header":"https://static001.geekbang.org/account/avatar/00/0f/67/f4/9a1feb59.jpg","comment_is_top":false,"comment_ctime":1569494123,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1569494123","product_id":100020201,"comment_content":"1、本文核心观点：<br>1-1：大数据计算的核心思路是移动计算比移动数据更划算。<br>1-2：MapReduce 既是一个编程模型，又是一个计算框架。也就是说，开发人员必须基于 MapReduce 编程模型进行编程开发，然后将程序通过 MapReduce 计算框架分发到 Hadoop 集群中运行。当我们说 MapReduce 的时候，可能指编程模型，也就是一个 MapReduce 程序；也可能是指计算框架，调度执行大数据的分布式计算。<br>1-3：这些年，我自己认识了很多优秀的人，他们各有所长、各有特点，但是无一例外都有个共同的特征，就是对事物的洞察力。他们能够穿透事物的层层迷雾，直指问题的核心和要害，不会犹豫和迷茫，轻松出手就搞定了其他人看起来无比艰难的事情。有时候光是看他们做事就能感受到一种美感，让人意醉神迷。<br>1-4：我希望你也能够不断训练自己，遇到问题的时候，停下来思考一下：这些现象背后的规律是什么。有时候并不需要多么艰深的思考，仅仅就是停一下，就会让你察觉到以前不曾注意到的一些情况，进而发现事物的深层规律。这就是洞察力。<br><br>老师呀！你说的抽象能力或者洞察力，也是我缺少的，我夫人常说让我学编程真是难为我啦！因为，我很努力的看书学习，但我的水平却不咋滴！我自己也能意识到了这一点，看的书时间一长就记不得了，大概只有一个模糊的印象，而且速度也慢，看李运化说他一年能看50本技术书，平均每周一本书，像XXX权威指南我一般至少一两个月才能看完一本。感觉自己好愚钝啊！<br><br>MapReduce 计算过程如下图所示，请问老师图中map的输入0&#47;12&#47;0&#47;13是什么意思？<br>另外，感觉MapReduce确实神奇，现在还未体会到她怎么做到，不管是关系代数运算（SQL 计算），还是矩阵运算（图计算），大数据领域几乎所有的计算需求都可以通过 MapReduce 编程来实现？","like_count":0},{"had_liked":false,"id":126223,"user_name":"长期规划","can_delete":false,"product_type":"c1","uid":1019332,"ip_address":"","ucode":"5EF65E9115834B","user_header":"https://static001.geekbang.org/account/avatar/00/0f/8d/c4/6f97daea.jpg","comment_is_top":false,"comment_ctime":1566351313,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1566351313","product_id":100020201,"comment_content":"这应该是分治的算法思想","like_count":0},{"had_liked":false,"id":108441,"user_name":"乐毅","can_delete":false,"product_type":"c1","uid":1348052,"ip_address":"","ucode":"6361ADC9B0E8D5","user_header":"https://static001.geekbang.org/account/avatar/00/14/91/d4/3785c799.jpg","comment_is_top":false,"comment_ctime":1561773480,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1561773480","product_id":100020201,"comment_content":"李老师的课讲得很好，对于很多初学者可以先了解编程语言层面上的map&#47;reduce ,比如ES6或Python中的map&#47;reduce函数，java中的stream lambda, 然后自己搭建学习环境，这当然需要了解linux和计算机网络等基础知识，再去编程实现老师讲的demo. 最重要的是一遍看不懂，再看第二遍第三遍甚至更多遍。","like_count":0},{"had_liked":false,"id":100399,"user_name":"深色覆盖浅色","can_delete":false,"product_type":"c1","uid":1033502,"ip_address":"","ucode":"47695FE55D5DB5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/c5/1e/eb8cad6e.jpg","comment_is_top":false,"comment_ctime":1559546413,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1559546413","product_id":100020201,"comment_content":"在文中WordCount的基础上，把map函数第11行改成StringTokenizer itr = new StringTokenizer(key.toString() + “,” + value.toString()); 就可以实现pageid+age分组了吧<br>","like_count":0},{"had_liked":false,"id":94869,"user_name":"KellyMi","can_delete":false,"product_type":"c1","uid":1205142,"ip_address":"","ucode":"A1577537B819E8","user_header":"https://static001.geekbang.org/account/avatar/00/12/63/96/a9f97631.jpg","comment_is_top":false,"comment_ctime":1557913641,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1557913641","product_id":100020201,"comment_content":"学习总结：<br>map函数是对每个需要计算的东西（例子中的word、思考题中的一行sql记录，key值一般不用）单独统计，每次只记一个；而reduce函数是对每个key（例子中的word、思考题中的一行sql记录）对应的values分别做个数统计。对于sql思考题来说，reduce不用改，map函数中的itr改成单个数据库服务器上sql返回的结果集，word改为单行String类型的记录（如“2,25”）就可以。","like_count":0},{"had_liked":false,"id":89330,"user_name":"gkb111","can_delete":false,"product_type":"c1","uid":1224217,"ip_address":"","ucode":"9B3154BCC9046B","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLLUic3XzxET3L3QXxcTbeg96GMx1HkiaiaZdudchmOmtPnuEPHK5vYEeMkvJR098XljMbXDialYib3z6w/132","comment_is_top":false,"comment_ctime":1556155151,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1556155151","product_id":100020201,"comment_content":"洞察力，抽象事物，发现底层的规律","like_count":0},{"had_liked":false,"id":65391,"user_name":"杰之7","can_delete":false,"product_type":"c1","uid":1297232,"ip_address":"","ucode":"F7DA2E21085332","user_header":"https://static001.geekbang.org/account/avatar/00/13/cb/50/66d0bd7f.jpg","comment_is_top":false,"comment_ctime":1549331672,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1549331672","product_id":100020201,"comment_content":"通过这一节的复习，重新理解了Mapreude作为数据编程模型和计算框架的作用。<br><br>Mapreduce分成两个部分，Map和reduce两阶段，两阶段都是通过&lt;key，value&gt;的形成输入要计算的内容，计算框架负责将数据源传入给Map和Reduce阶段。Map通过计算之后将key,value(集合)通过计算框架传入给reduce,reduce将value(sum)汇总得到结果。在大数据中，对于多块数据，用HDFS分块得到。最后，可以就MR处理的结算结果用SQL语句进行查询统计计算。<br><br>这就是这讲总结的内容，当然，代码中设计到Python和Java的一些内容，这是作为计算机数据技术的基础，同样也需要我们有好的掌握，对之后问题的解决会非常有帮助。","like_count":0},{"had_liked":false,"id":51570,"user_name":"swift","can_delete":false,"product_type":"c1","uid":1156148,"ip_address":"","ucode":"B243DCD10B04F0","user_header":"https://static001.geekbang.org/account/avatar/00/11/a4/34/0ab08db6.jpg","comment_is_top":false,"comment_ctime":1545201372,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1545201372","product_id":100020201,"comment_content":"文章例子中的统计词数的map函数，value只是单纯地计1。如果先用单机算法（比如前面的哈希表算法）统计出当前输入文本片段的每个字的个数后再返回，这样在REDUCE步骤累加也可以吧？ 似乎还能减轻框架合并KEY的负担？哪种写法更合理？","like_count":0},{"had_liked":false,"id":45907,"user_name":"小渐","can_delete":false,"product_type":"c1","uid":1071554,"ip_address":"","ucode":"C9D17E29297417","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/ZmIcra83qKic2ter9A5mn5aiaRx0dQ4WpZ40QPr1oGNQlzwNZVE6USo60xx69URkm9SpeO6ayH6SyQTyVX1JP0eg/132","comment_is_top":false,"comment_ctime":1543816451,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1543816451","product_id":100020201,"comment_content":"如果map是数据的预处理，然后reduce是对数据预处理之后的求和。那么两个map处理之后的结果如果要做去重应该怎么办呢？比如一个map里面一个uid 1 ，另外一个map也是uid 1，reduce 求和出来uid是2。但是实际上去重后是1呀。","like_count":0},{"had_liked":false,"id":45366,"user_name":"石头","can_delete":false,"product_type":"c1","uid":1142419,"ip_address":"","ucode":"DC24472A35EA40","user_header":"https://static001.geekbang.org/account/avatar/00/11/6e/93/6fef7aaa.jpg","comment_is_top":false,"comment_ctime":1543619546,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1543619546","product_id":100020201,"comment_content":"抽象能力的训练:这个问题为什么会出现？背后的规律是什么？应该怎么做？","like_count":0},{"had_liked":false,"id":44135,"user_name":"Aron","can_delete":false,"product_type":"c1","uid":1236669,"ip_address":"","ucode":"6C07E662DB77C5","user_header":"https://static001.geekbang.org/account/avatar/00/12/de/bd/a2ea7801.jpg","comment_is_top":false,"comment_ctime":1543372294,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1543372294","product_id":100020201,"comment_content":"map输出key value，reduce的输入是key，value list,这种转换是框架完成的吗","like_count":0},{"had_liked":false,"id":43884,"user_name":"allan","can_delete":false,"product_type":"c1","uid":1142819,"ip_address":"","ucode":"CA0BE868AA9FF5","user_header":"https://static001.geekbang.org/account/avatar/00/11/70/23/972dcd30.jpg","comment_is_top":false,"comment_ctime":1543318011,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1543318011","product_id":100020201,"comment_content":"我是一名应届生，是 Linux C&#47;C++ 开发，最近找到的工作是大数据相关的，经理对我说开发用的语言还是 C++，但我了解到像 Hadoop 就是 Java&#47;Python，所以想问下企业里面有自己的一套工具吗？还是直接就是用的 Hadoop？谢谢。","like_count":0},{"had_liked":false,"id":41147,"user_name":"牛油果","can_delete":false,"product_type":"c1","uid":1047154,"ip_address":"","ucode":"897D927418C609","user_header":"https://static001.geekbang.org/account/avatar/00/0f/fa/72/5c801d71.jpg","comment_is_top":false,"comment_ctime":1542732722,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1542732722","product_id":100020201,"comment_content":"戴老师、潘大侠是哪两位上仙，说出来让我们也去学习一下啊。","like_count":0},{"had_liked":false,"id":41010,"user_name":"探索无止境","can_delete":false,"product_type":"c1","uid":1044178,"ip_address":"","ucode":"91D2A9907DFA79","user_header":"https://static001.geekbang.org/account/avatar/00/0f/ee/d2/7024431c.jpg","comment_is_top":false,"comment_ctime":1542712753,"is_pvip":false,"replies":[{"id":"14790","content":"Java执行效率更高","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1542765130,"ip_address":"","comment_id":41010,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1542712753","product_id":100020201,"comment_content":"老师，大数据python,java都可以，有没有说哪个语言会更具备优势？","like_count":0,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":429671,"discussion_content":"Java执行效率更高","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1542765130,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":38850,"user_name":"六七少年","can_delete":false,"product_type":"c1","uid":1294566,"ip_address":"","ucode":"F7205BC7BDA645","user_header":"https://static001.geekbang.org/account/avatar/00/13/c0/e6/c6600e06.jpg","comment_is_top":false,"comment_ctime":1542154311,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1542154311","product_id":100020201,"comment_content":"讲师的课件很棒，就是更新慢了些，能不能加快点节奏，特别期待后面的进阶章节","like_count":0},{"had_liked":false,"id":38816,"user_name":"亭亭亭","can_delete":false,"product_type":"c1","uid":1283931,"ip_address":"","ucode":"DFD135FDEA79EA","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJF2gTFBleTUHJtpV4KeyMGdiaycVkrX1JgZJITFfmUa4xWyiapicRF7h0Ur4YI5IdDJ9N43Q6ey8vyA/132","comment_is_top":false,"comment_ctime":1542146199,"is_pvip":false,"replies":[{"id":"14013","content":"可参考后续hive一期专栏","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1542238912,"ip_address":"","comment_id":38816,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1542146199","product_id":100020201,"comment_content":"如果是non additive的结果，map reduce 怎么计算呢","like_count":0,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":428821,"discussion_content":"可参考后续hive一期专栏","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1542238912,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":38686,"user_name":"明天更美好","can_delete":false,"product_type":"c1","uid":1180696,"ip_address":"","ucode":"F036B8718938BE","user_header":"https://static001.geekbang.org/account/avatar/00/12/04/18/4b02510f.jpg","comment_is_top":false,"comment_ctime":1542106100,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1542106100","product_id":100020201,"comment_content":"李老师，我是一个学员，最近公司有个需求搞的我头疼，所以请教您一下，我们接口并发很大，日志一天2T，领导要求保留最近半年的日志，而且其他应用调我们，一月总有那么几次问题，我们需要根据日志定位问题，所以要经常查询。可能还要分析，比如最近三个月谋省份应用调我们某个接口多少，成功率多大等，我们资源有16台物理机，16核128G内存50T存储  我想用elk这个能抗住吗？半年下来将近400T了。但是用大数据能满足我们的需求吗？希望您能给我个建议","like_count":0},{"had_liked":false,"id":38632,"user_name":"Reiser","can_delete":false,"product_type":"c1","uid":1078669,"ip_address":"","ucode":"E5DBBBA2F86FCE","user_header":"https://static001.geekbang.org/account/avatar/00/10/75/8d/c6a2a048.jpg","comment_is_top":false,"comment_ctime":1542090796,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1542090796","product_id":100020201,"comment_content":"MapReduce 的编程模型让我想到了快速排序的分治思想","like_count":0},{"had_liked":false,"id":38627,"user_name":"观弈道人","can_delete":false,"product_type":"c1","uid":1016905,"ip_address":"","ucode":"F3BB619A33C605","user_header":"https://static001.geekbang.org/account/avatar/00/0f/84/49/47d48fd0.jpg","comment_is_top":false,"comment_ctime":1542088598,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1542088598","product_id":100020201,"comment_content":"后面那段表述很棒","like_count":0},{"had_liked":false,"id":38622,"user_name":"lyshrine","can_delete":false,"product_type":"c1","uid":1058278,"ip_address":"","ucode":"497551F047A5C6","user_header":"https://static001.geekbang.org/account/avatar/00/10/25/e6/a69cff76.jpg","comment_is_top":false,"comment_ctime":1542087288,"is_pvip":false,"replies":[{"id":"13863","content":"Hadoop支持Java，也支持Python，编写MapReduce程序","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1542112224,"ip_address":"","comment_id":38622,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1542087288","product_id":100020201,"comment_content":"老师，看您用的python举例，请问mapduce的编程语言是什么呢，各种语言都行吗？","like_count":0,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":428760,"discussion_content":"Hadoop支持Java，也支持Python，编写MapReduce程序","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1542112224,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":38483,"user_name":"shaker","can_delete":false,"product_type":"c1","uid":1271555,"ip_address":"","ucode":"D43FD1CDAFF9FA","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTISicpsLbj7rPEkmcVKdExIw4ezlhIiaRpddTIptDJCQvmFCF0QCp6HNHuTyrJicJOdcR1bMebIG3kUg/132","comment_is_top":false,"comment_ctime":1542065767,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1542065767","product_id":100020201,"comment_content":"具体实现跟WordCount差不多，只是key变为pageId+age","like_count":0},{"had_liked":false,"id":38461,"user_name":"无形","can_delete":false,"product_type":"c1","uid":1016889,"ip_address":"","ucode":"B740E2A68A17A5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/84/39/c8772466.jpg","comment_is_top":false,"comment_ctime":1542039980,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1542039980","product_id":100020201,"comment_content":"看老师的文字也是一种美的享受😜ོ","like_count":0}]}