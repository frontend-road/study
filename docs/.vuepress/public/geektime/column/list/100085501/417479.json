{"id":417479,"title":"07｜回归分析：怎样用模型预测用户的生命周期价值？","content":"<p>你好，我是黄佳。</p><p>首先，恭喜你成功通过“获客关”。在获客关中，我们把互联网电商“易速鲜花”的用户们分成了高、中、低三个价值组，你还记得这个项目是属于监督学习还是无监督学习吗？没错，是无监督学习。</p><p>今天，我们开启“变现关”的挑战。而且我们将进入更为常见、更主流的机器学习应用场景，监督学习的实战。更确切地说，这是用监督学习解决回归问题的一次实战。</p><p><img src=\"https://static001.geekbang.org/resource/image/fb/aa/fb47103938cab174b7093479f02485aa.jpg?wh=2284x1033\" alt=\"\"></p><p>监督学习，主要应用于回归和分类两大场景，分别可以用来预测数值和进行分类判断，这两类问题也是我们课程的两大重点。在这节课中，你就能够学到用回归来进行数值预测的方法了。因为这是监督学习项目，所以，我们会完全跟着前面讲的“机器学习实战5步”来走。</p><h1>定义问题</h1><p>请你想象一下，你刚为客户做了分组画像，老板推门而入：“价值分组这个项目做得不错嘛！现在有这么一个新需求，你看看你这边还有什么idea。”</p><p>他继续说道：“你也知道，现在流量太贵了，拉新成本平均下来每注册一个用户我几乎要花接近500元。我是这么想的。500元，说贵也贵，说不贵也不贵，关键还是要看这些用户能给我们带来多大价值、多大回报，你说对吧？要是多数人用我们的App，用几次就不用了，订花的总消费甚至比500元还少，那就没什么意思了。所以，你看能不能根据历史数据，预测一下新用户未来一两年的消费总额？”</p><!-- [[[read_end]]] --><p>好，那现在我们来分析一下这个问题。其实，这个问题的实质是计算一个用户使用某产品的过程中消费总量是多少。比如某类手机App，用户的平均使用长度是两年左右，那么两年内用户在App上消费所产生的总收益就是用户的生命周期价值，英文是Lifetime Value，简称LTV，有时我们也叫CLV（Customer Lifetime Value）。</p><p>请你想想看，如果你得到一个新用户的成本是500元，看上去是很贵，但如果这个人在你的店铺买花的钱预计会超过万元，那么扣除进货成本和获客成本，你还是赚到了，ROI高嘛。</p><p><img src=\"https://static001.geekbang.org/resource/image/c0/b7/c0267aa171088a27f6c00470749749b7.png?wh=415x239\" alt=\"\" title=\"用户的LTV越高，我们ROI越高\"></p><p>所以，我们的目标就是通过现有数据，找到一个能预测出用户生命周期价值的模型，来指导我们获客的成本，避免超出回报的盲目投入。</p><p>那对于这个问题，我们还是会使用上一个项目中的原始数据集，你在<a href=\"https://github.com/huangjia2019/geektime/tree/main/%E5%8F%98%E7%8E%B0%E5%85%B307\">这里</a>就能下载到。拿到数据集后，我们就可以开始数据的预处理工作了。</p><h1>数据预处理</h1><p>通过前面的课程，我想你应该已经想到：“用户生命周期价值”是一种连续性数值，对这种连续性数值的预测，属于一个回归问题。那么，在数据预处理阶段，我们就要确定把哪些特征字段输入到回归模型中。</p><p><img src=\"https://static001.geekbang.org/resource/image/7b/e9/7bf08c35eecd0e311942269c801296e9.png?wh=709x161\" alt=\"\"></p><p>我们看到，这个数据集的字段包括订单号、产品码、消费日期、产品说明、数量（订单）、单价、用户码和城市。那么，哪些字段和用户的LTV相关呢？</p><p>很显然，像订单号、用户码、产品说明这些信息，肯定和用户的LTV值是不相关的。你可能会说，用户所在的“城市”这个字段，也许和用户的消费能力有一定的关联。</p><p>这看起来有一定的道理。不过，像“北京”、“上海”这样的文本字段肯定不能直接被输入回归模型，如果要考虑城市信息，也应该转换为0、1的哑变量值，再输入模型。也就是说转换成“是否北京”(值是0或1)，“是否上海”（值是0或1），“是否深圳”（值是0或1）……</p><p>你看，这样一下子就增加了好多个特征，而且对这个数据集来说，城市对于LTV值的影响其实并不大。综合这些因素，在这个项目中，我们就不考虑“城市”这个字段了。</p><p>看到这，你也许会想：那这么说的话，用户的消费金额肯定和LTV非常相关，可是，用户的消费金额不就是LTV本身嘛，用自己去预测自己，这样的模型有什么意义呢？</p><p>这个想法没错，用户的消费金额确实是和LTV最为相关的变量。不过，我们要做两个小调整，来解答你的困惑。</p><p>第一个调整是，我们可以考虑用头3个月的消费金额，而不是全部一整年的消费金额，来预测用户后续一年或两年的“价值”。这样，根据历史数据搭建起模型后，对于新注册的用户，我们只需要观察其头3个月的表现，就能够预测他今后一、两年的消费总量。如果某类App用户平均使用长度是一年或两年的话，这也就是该用户的生命周期价值。</p><p>第二个调整是，用我们在前两节课中学到的R、F、M值来做特征变量，这就避免了单一维度建模的局限性。在RMF用户分组中，我们不仅可以得到消费金额，还能得到新近度、消费频率。这些层级把消费频率、最近消费日期这些非数值变量转化成了数值变量，而且这些数值与用户的LTV也都密切相关。</p><p>因此，<strong>在我们的模型中，可以用头3个月的R、F、M这3个数值作为特征，也就是回归模型的自变量。而回归模型所要预测的因变量，即数据集的标签，就是一年的总消费额，你可以认为它就是用户的LTV。</strong></p><p>我要说明一下，这里的3个月、12个月都只是思路上的示意，我们不去考虑用户平均会使用该App一年还是两年、三年。在不同业务场景中，计算RFM特征值的时间区间和LTV的时间区间可以视情况而定。</p><p>下面我们要做的就是数据清洗，这其中包括删除不符合逻辑的负值、查看有没有缺失值、添加每个订单的总价字段等。这部分内容和上一讲的类似，我就不再重复了，你如果不清楚，可以去回顾<a href=\"https://time.geekbang.org/column/article/416824\">上一讲</a>的内容。</p><p>在数据预处理阶段，唯一不同的就是，当前项目需要显示数据集的时间跨度，因为我们要拆分出头3个月的数据作为输入特征，并且只考虑12月的总消费金额作为LTV，所以我们要通过数据集的时间跨度来把它分为两部分，一部分用来构建RFM特征（头３个月），另一部分用来构建LTV这个标签（整个1２个月）。</p><ol>\n<li><strong>整理数据集记录的时间范围</strong></li>\n</ol><p>通过这段代码，我可以知道当前数据集一共覆盖了多长的时间。</p><pre><code class=\"language-typescript\">import numpy as np #导入NumPy\nimport pandas as pd #导入Pandas\ndf_sales = pd.read_csv('易速鲜花订单记录.csv') #载入数据\nprint('日期范围: %s ~ %s' % (df_sales['消费日期'].min(), df_sales['消费日期'].max())) #显示日期范围（格式转换前）\ndf_sales['消费日期'] = pd.to_datetime(df_sales['消费日期']) #转换日期格式\nprint('日期范围: %s ~ %s' % (df_sales['消费日期'].min(), df_sales['消费日期'].max()))#显示日期范围\n</code></pre><p>输出如下：</p><pre><code class=\"language-typescript\">日期范围（格式转化前）: 1/1/2021 10:11 ~ 9/9/2020 9:20\n日期范围（格式转化后）: 2020-06-01 09:09:00 ~ 2021-06-09 12:31:00\n</code></pre><p>结果显示，数据集中的时间跨度是从2020年6月到2021年6月9号。</p><p>因为我们希望求的是整年的LTV，所以，这里我们把不完整的2021年6月份的数据删除：</p><pre><code class=\"language-typescript\">df_sales = df_sales.loc[df_sales['消费日期'] &lt; '2021-06-01'] #只保留整月数据\nprint('日期范围: %s ~ %s' % (df_sales['消费日期'].min(), df_sales['消费日期'].max())) #显示日期范围\n</code></pre><p>输出如下：</p><pre><code class=\"language-typescript\">日期范围（删除不完整的月份）: 2020-06-01 09:09:00 ~ 2021-05-31 17:39:00\n</code></pre><p>目前的数据集中，共包含了整整12个月的数据。下面，我们开始构建机器学习数据集的特征和标签字段。</p><ol start=\"2\">\n<li><strong>构建特征和标签</strong></li>\n</ol><p>基于前面的分析，我们用前3个月的R、F、M值作为特征字段，然后把整个12个月的消费金额视为LTV，作为标签字段。</p><p>首先，我们把头3个月的销售数据拆分出来，形成独立的df_sales_3m对象。这部分数据将是对用户LTV预测的依据。</p><pre><code class=\"language-typescript\">df_sales_3m = df_sales[(df_sales.消费日期 &gt; '2020-06-01') &amp; (df_sales.消费日期 &lt;= '2020-08-30')] #构建仅含头三个月数据的数据集\ndf_sales_3m.reset_index(drop=True) #重置索引\n</code></pre><p>接下来，我们创建以用户码为主键的df_user_LTV对象，利用头3个月的数据，构建R、F、M层级，形成新特征。具体的思路和步骤，我们在<a href=\"https://time.geekbang.org/column/article/415910\">第5讲</a>中讲解过，我就不啰嗦了：</p><pre><code class=\"language-typescript\">df_user_LTV = pd.DataFrame(df_sales['用户码'].unique()) #生成以用户码为主键的结构\ndf_user_LTV.columns = ['用户码'] #设定字段名\ndf_user_LTV.head() #显示头几行数据\ndf_R_value = df_sales_3m.groupby('用户码').消费日期.max().reset_index() #找到每个用户的最近消费日期，构建df_R_value对象\ndf_R_value.columns = ['用户码','最近购买日期'] #设定字段名\ndf_R_value['R值'] = (df_R_value['最近购买日期'].max() - df_R_value['最近购买日期']).dt.days #计算最新日期与上次消费日期的天数\ndf_user_LTV = pd.merge(df_user_LTV, df_R_value[['用户码','R值']], on='用户码') #把上次消费距最新日期的天数（R值）合并至df_user结构\ndf_F_value = df_sales_3m.groupby('用户码').消费日期.count().reset_index() #计算每个用户消费次数，构建df_F_value对象\ndf_F_value.columns = ['用户码','F值'] #设定字段名\ndf_user_LTV = pd.merge(df_user_LTV, df_F_value[['用户码','F值']], on='用户码') #把消费频率(F值)整合至df_user结构\ndf_M_value = df_sales_3m.groupby('用户码').总价.sum().reset_index() #计算每个用户三个月消费总额，构建df_M_value对象\ndf_M_value.columns = ['用户码','M值'] #设定字段名\ndf_user_LTV = pd.merge(df_user_LTV, df_M_value, on='用户码') #把消费总额整合至df_user结构\ndf_user_LTV #显示用户表结构\n</code></pre><p>最后，我们输出显示df_user_LTV对象，就会看到头三个月的R值、F值、M值都已经作为特征，存到我们的数据集df_user_LTV中了。到这里，特征构建完毕。</p><p><img src=\"https://static001.geekbang.org/resource/image/43/y2/430c2cdae13627cf5be68674cc1d4yy2.png?wh=211x167\" alt=\"\"></p><p>下面我们再来看怎么构建数据集的标签。</p><p>我们说过，标签，就是我们需要去预测或者判断的东西。而机器学习，就是通过已知来预测未知，通过训练数据集来寻找规律，发现特征和标签之间的联系。所以，我们下一步要做的，就是把LTV值加入到df_user_LTV中，这样数据集才完整。</p><p>我们先根据一整年的数据计算出每一个用户的LTV值，也就是12个月的总消费金额：</p><pre><code class=\"language-typescript\">df_user_1y = df_sales.groupby('用户码')['总价'].sum().reset_index() #计算每个用户整年消费总额，构建df_user_1y对象\ndf_user_1y.columns = ['用户码','年度LTV'] #设定字段名\ndf_user_1y.head() #显示头几行数据\ndf_LTV = pd.merge(df_user_LTV, df_user_1y, on='用户码', how='left') #构建整体LTV训练数据集\ndf_LTV #显示df_LTV\n</code></pre><p>然后，再把得到的LTV值整合到之前构建的df_user_LTV中，就形成了完整的、带标签的LTV数据集。</p><p><img src=\"https://static001.geekbang.org/resource/image/93/ea/93e42f2785abde4cdfbac43a48a088ea.png?wh=280x351\" alt=\"\"></p><p>现在，在这个数据集中，R、F、M值来自于头3个月收集的数据，是模型的特征；LTV值来自于整年的数据，是模型的标签。这非常符合我们的目标：<strong>用短期数据，来预测用户的长期价值</strong>。</p><p>数据集形成之后，你会发现用户的数量从原来的981个减少到了361个，这是因为在头三个月出现过消费行为的用户数就只有361个。所以，我们后续基于这361个用户的数据来开展机器学习建模就可以了。</p><ol start=\"3\">\n<li><strong>创建特征集和标签集</strong></li>\n</ol><p>刚刚我们把特征和标签整合在一起，是为了形成完整的数据集。不过，标签集和特征集要分别输入机器学习模型，所以要分别创建。</p><p>我们先来构建特征集X：</p><pre><code class=\"language-typescript\">X = df_LTV.drop(['用户码','年度LTV'],axis=1) #特征集\nX.head() #显示特征集\n</code></pre><p>在这段代码中，我们除了移除了LTV值之外，还移除了用户码字段。因为用户码对于回归模型的训练毫无意义，而且用户码也是数字，会对模型形成干扰。如果不移除的话，机器就会把它也视作一个变量，认为15291比15100大，这显然不合逻辑。<br>\n然后，我们再来构建标签集y。这里多说一句，在机器学习中，特征集的X大写，标签集的y小写，似乎是个惯例。这可能是因为通常情况下，X是一个向量，而y是一个数值。</p><pre><code class=\"language-typescript\">y = df_LTV['年度LTV'] #标签集\ny.head() #显示标签集\n</code></pre><p>构建好特征集和标签集后，我们就可以把它们拆分为训练集、验证集和测试集了。</p><ol start=\"4\">\n<li><strong>拆分训练集、验证集和测试集</strong></li>\n</ol><p>我们用scikit-learn工具包中的拆分工具train_test_split，进行拆分：</p><pre><code class=\"language-typescript\">from sklearn.model_selection import train_test_split\n# 先拆分训练集和其它集\nX_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=0.7,random_state = 36)\n# 再把其它集拆分成验证集和测试集&nbsp;\nX_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5,random_state = 36)\n</code></pre><p>请你注意，这里我做了两重的拆分，至于为什么要这样做，你可以回顾下<a href=\"https://time.geekbang.org/column/article/414504\">第三讲</a>的内容。</p><p>最后，我们得到的数据集X_train、X_valid和X_test的字段，与X中的字段还是一样，y_train、y_valid、y_test中的字段和y的也一样，只是它们的行数发生了改变：</p><ul>\n<li>X_train是288行×4列；</li>\n<li>y_train是288行×1列；</li>\n<li>X_valid是73行×4列；</li>\n<li>y_valid是73行×1列；</li>\n<li>X_test是73行×4列；</li>\n<li>y_test是73行×1列。</li>\n</ul><p>好，到这里，我们的数据准备工作就全部完成啦。在这个项目中，这部分工作几乎占了大头，好在我们已经攻克，下面我们一起进入选算法并创建模型的环节。</p><h1>选择算法创建模型</h1><p>因为这是一个回归问题，所以，在模型类型的选择方面，我们肯定使用的是回归算法。这是基于问题本身的性质而确定的，毋庸置疑。</p><p>不过我们说过，在机器学习中，能够解决回归问题的常见算法有不少：</p><p><img src=\"https://static001.geekbang.org/resource/image/84/34/844348a55550d08968ffb1d0dcaf3a34.jpg?wh=2248x1265\" alt=\"\"></p><p>一般来说，我们在解决具体问题的时候，会选择多种算法进行建模，相互比较之后，再确定比较适合的模型。由于篇幅所限，我们不会使用上述全部算法建立模型，这里我会带你比较3种算法的效率：最基本的线性回归模型、决策树模型和随机森林模型（你可以自己试着使用其它的算法创建别的模型）。</p><p>线性回归我们已经用过了，它是通过梯度下降找到最优的权重和模型偏置的最基本的回归算法。这里，我会用它做为一个基准模型，把其它模型的结果与其相比较，来确定优劣。</p><p>而决策树算法，简单地说是从样本数据的特征属性中，通过学习简单的决策规则，也就是我们耳熟能详的IF ELSE规则，来预测目标变量的值。这个算法的核心是划分点的选择和输出值的确定。</p><p>下面，我给你画了一张图，来帮你理解决策树是怎么进行判断预测的。</p><p><img src=\"https://static001.geekbang.org/resource/image/be/db/be2728ac9936a4c2dd1692c227dfffdb.jpg?wh=2248x2885\" alt=\"\"></p><p>你可以看到，这种算法是根据两个特征$x_{1}$和$x_{2}$的值，以及标签y的取值，来对二维平面上的区域进行精准分割，以确定从特征到标签的映射规则。根据树的深度和分叉时所选择的特征的不同，我们可以训练出很多棵不一样的树来。</p><p>而随机森林呢，就是由多棵决策树构成的集成学习算法。它既能用于分类问题，也能用于回归问题。而且无论是解决哪类问题，它都是相对优秀的算法。在训练模型的过程中，随机森林会构建多个决策树，如果解决的是分类问题，那么它的输出类别是由个别树输出的类别的众数而定；如果解决的是回归问题，那么它会对多棵树的预测结果进行平均。</p><p>关于集成学习，我后面还会单独拿出来给你讲解。现在你只需要知道，随机森林纠正了决策树过度拟合其训练集的问题，在很多情况下它都能有不错的表现。这里的“过拟合”，其实就是说模型对训练集的模拟过头了，反而不太适合验证集和测试集。</p><p>下面我们导入并创建线性回归模型、决策树模型和随机森林模型。</p><pre><code class=\"language-typescript\">from sklearn.linear_model import LinearRegression #导入线性回归模型\nfrom sklearn.tree import DecisionTreeRegressor #导入决策树回归模型\nfrom sklearn.ensemble import RandomForestRegressor #导入随机森林回归模型\nmodel_lr = LinearRegression() #创建线性回归模型\nmodel_dtr = DecisionTreeRegressor() #创建决策树回归模型\nmodel_rfr = RandomForestRegressor() #创建随机森林回归模型\n</code></pre><p>在代码中，有几个缩写我解释一下：</p><ul>\n<li>lr是Linear Regression（线性回归）的缩写；</li>\n<li>dtr是Decision Tree Regresssor（决策树回归）的缩写；</li>\n<li>rfr是Random Forest Regressor（随机森林回归）的缩写。</li>\n</ul><p>对于决策树和随机森林算法来说，它们既有回归算法（Regressor），也有分类算法（Classifer）。以后，我们用到分类模型的时候，我就会把决策树分类模型命名为model_dtc，把随机森林分类模型命名为model_rfc，其中的“c”就代表Classifer。</p><p>创建好模型之后，我们就可以开始训练机器了。</p><h1>训练模型</h1><p>我们直接对线性回归、决策树模型和随机森林模型进行训练、拟合：</p><pre><code class=\"language-typescript\">model_lr.fit(X_train, y_train) #拟合线性回归模型\nmodel_dtr.fit(X_train, y_train) #拟合决策树模型\nmodel_rfr.fit(X_train, y_train) #拟合随机森林模型\n</code></pre><p>你不要小看上面这几个简单的<strong>fit语句，这是模型进行自我学习的关键过程</strong>。我们前面说了，在线性回归算法中，机器是通过梯度下降，逐步减少数据集拟合过程中的损失，让线性函数对特征到标签的模拟越来越贴切。而在决策树模型中，算法是通过根据特征值选择划分点来确定输出值的；在随机森林算法中，机器则是生成多棵决策树，并通过Bagging的方法得到最终的预测模型。</p><p>不过，拟合之后的模型是否有效，我们还无法确定，需要进行验证集上的预测并验证预测结果。</p><h1>评估模型</h1><p>下面我们用这三种模型对验证集分别进行预测。</p><pre><code class=\"language-typescript\">y_valid_preds_lr = model_lr.predict(X_valid) #用线性回归模型预测验证集\ny_valid_preds_dtr = model_dtr.predict(X_valid) #用决策树模型预测验证集\ny_valid_preds_rfr = model_rfr.predict(X_valid) #用随机森林模型预测验证集\n</code></pre><p>为了看看这些模型预测的LTV值是否大体上靠谱，我们先来随机选择其中一行数据，看看模型的预测结果。</p><pre><code class=\"language-typescript\">X_valid.iloc[2] #随便选择一个数据\n</code></pre><p>这行数据的特征如下：</p><pre><code class=\"language-typescript\">R值       1.00\nF值     153.00\nM值    1413.83\nName: 163, dtype: float64\n</code></pre><p>然后，我们再显示一下三个模型对这一行数据所预测的LTV值，以及该用户的LTV真值。</p><pre><code class=\"language-typescript\">print('真值:', y_valid.iloc[2])&nbsp; #真值\nprint('线性回归预测值:', y_valid_preds_lr[2])&nbsp; #线性回归模型预测值\nprint('决策树预测值:', y_valid_preds_dtr[2])&nbsp; #决策树模型预测值\nprint('随机森林预测值:', y_valid_preds_rfr[2]) #随机森林模型预测值\n</code></pre><p>输出：</p><pre><code class=\"language-typescript\">真值: 4391.9399999999905\n线性回归预测值: 7549.22894678151\n决策树预测值: 4243.209999999997\n随机森林预测值: 4704.671799999999\n</code></pre><p>可以看到，相对而言，对这个数据点来说，决策树和随机森林所预测的y值更接近真值。</p><p>当然，一个数据点接近真值完全不能说明问题，我们还是要用$R^2$、MSE等评估指标在验证集上做整体的评估，比较模型的优劣。</p><p>下面我们用$R^2$指标，来评估模型的预测准确率：</p><pre><code class=\"language-typescript\">from sklearn.metrics import r2_score,   median_absolute_error #导入Sklearn评估模块\nprint('验证集上的R平方分数-线性回归: %0.4f' % r2_score(y_valid, model_lr.predict(X_valid)))\nprint('验证集上的R平方分数-决策树: %0.4f' % r2_score(y_valid, model_dtr.predict(X_valid)))\nprint('验证集上的R平方分数-随机森林: %0.4f' % r2_score(y_valid, model_rfr.predict(X_valid)))\n</code></pre><p>输出如下：</p><pre><code class=\"language-plain\">验证集上的R平方分数-线性回归: 0.4333\n验证集上的R平方分数-决策树: 0.3093\n验证集上的R平方分数-随机森林: 0.4677\n</code></pre><p>我们把这个结果用图表来显示一下，会更加直观：</p><p><img src=\"https://static001.geekbang.org/resource/image/47/69/477cb3f996975aa3475c6397bab40569.png?wh=384x267\" alt=\"\"></p><p>我们可以看到，在都没有经过任何参数设定的情况下，和线性回归、决策树相比，随机森林算法显示出了更好的预测能力。</p><p>最后，我们在随机森林上面运行测试集，并绘制出预测值和真值之间的散点图：</p><pre><code>y_test_preds_rfr = model_rfr.predict(X_test) #用模型预随机森林模型预测验证集\nplt.scatter(y_test, y_test_preds) #预测值和实际值的散点图\nplt.plot([0, max(y_test)], [0, max(y_test_preds)],   color='gray', lw=1, linestyle='--') #绘图\nplt.xlabel('实际值') #X轴\nplt.ylabel('预测值') #Y轴\nplt.title('实际值 vs. 预测值') #标题\n</code></pre><p>输出如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/ff/96/ffa9daf7d1b7c0f9697c08bb6a1f3696.png?wh=1000x699\" alt=\"\"></p><p>我们希望实际值和预测值基本上是相等的（预测值越接近真值，则误差越小）。举例来说，图中一个全年消费12000元的用户，所预测出来的LTV值，也在12000元左右。这样的情况越多，就表明模型越准确。</p><p>现在有了这个机器学习模型，我们再回过头看一下，在这一讲的开始，老板提出的问题：如何判断获客成本是否过高？根据模型预测结果，我们可以进一步观察处于R、F、M各个层级中的用户，看他们的LTV值大概是多少，这样就不难得知每个层级的获客成本应该控制在什么范围了。</p><p>对于高RFM价值的客户来说，我们可以适当多投入获客成本；而对于低RFM价值的客户，我们就要严格控制获客成本了。所以，根据这个模型，我们可以得出一个<strong>获客成本的指导区间</strong>。而且，通过该模型，我们<strong>还可以便捷地计算出每个新用户的LTV值。</strong></p><h1>总结一下</h1><p>好，今天这一讲到这里就结束了，我们来回顾一下你在这节课中学到了什么。</p><p>在这一讲中，我们应用机器学习的实战5步，解决了一个回归问题。在这一过程中，最重要的部分是构建特征，也就是把原始数据，转化成R值、F值和M值，来作为新特征进行机器学习。而<strong>这个过程本身就是一个很有意思的特征工程</strong>。</p><p><img src=\"https://static001.geekbang.org/resource/image/77/9f/7780d2ec6af77dd8f482d9551e65d49f.png?wh=616x424\" alt=\"\"></p><p>在模型选择的方面，我们使用普通的线性回归算法作为基准模型。然后，再拿其它的算法（这里我们选择的是决策树和随机森林）与之比较，从而找出更优的算法。请你注意，这里所谓的更优，仅针对于当前的场景而言，并不是说随机森林算法就一定优于线性回归算法。</p><p>当然，一般来说，随机森林简单且容易解释。如果对于任何一个特定问题，你能找到比随机森林还好的算法，那么就可以说是相当成功了。</p><p>在这次实战中，我们只是简单地调用模型，还并没有进行任何的参数优化步骤。以后，我们还会对随机森林算法做调优的工作。</p><h1>思考题</h1><p>这节课就到这里了，最后，我给你留3个思考题：</p><ol>\n<li>在这次实战中，我们放弃了用户所在的“城市”这个信息，请你使用Pandas中的get_dummies这个工具，来添加“城市”相关的哑变量，然后添加到特征集中，输入模型。</li>\n</ol><p><strong>提示</strong>：</p><pre><code class=\"language-typescript\">city = pd.get_dummies(df_sales.城市, prefix='城市')\ndf_sales = pd.concat([df_sales, city], axis=1)\n</code></pre><ol start=\"2\">\n<li>其实，SVM和朴素贝叶斯也可以解决回归问题，请你使用这两种算法（或其它回归算法）来尝试解决这个问题，然后比较各个算法的优劣。</li>\n</ol><p><strong>提示</strong>：</p><pre><code class=\"language-plain\">from sklearn.svm import SVR\nfrom sklearn.linear_model import BayesianRidge\n</code></pre><ol start=\"3\">\n<li>在验证时，我选择了$R^2$作为回归问题的评估指标，你能否尝试使用均方误差、中值绝对误差等评估指标，来验证我们的模型呢？</li>\n</ol><p><strong>提示</strong>：除了$R^2$是越大越好之外，其它评估指标都是越小越好。</p><pre><code class=\"language-plain\">from sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import median_absolute_error\n</code></pre><p>欢迎你在留言区分享你的想法和收获，我在留言区等你。如果这节课帮到了你，也欢迎你把这节课分享给自己的朋友。我们下一讲再见！</p><p><img src=\"https://static001.geekbang.org/resource/image/5a/fa/5af212b016be19f8742bafbdd35b26fa.jpg?wh=2284x1149\" alt=\"\"></p>","neighbors":{"left":{"article_title":"06 | 聚类分析：如何用RFM给电商用户做价值分组画像？","id":416824},"right":{"article_title":"08 | 模型优化（上）：怎么用特征工程提高模型效率？","id":418354}},"comments":[{"had_liked":false,"id":311896,"user_name":"GAC·DU","can_delete":false,"product_type":"c1","uid":1385403,"ip_address":"","ucode":"7847FBE1C13740","user_header":"https://static001.geekbang.org/account/avatar/00/15/23/bb/a1a61f7c.jpg","comment_is_top":true,"comment_ctime":1631525205,"is_pvip":true,"replies":[{"id":"113014","content":"关于这个数据点的预测值和真值。这里有几个方面的考量。第一，我们的数据量比较小，只有几百个用户的数据。要得到更健壮的模型，需要很大量的数据。第二，从数据的角度，这个数据点他的前三个月和后12个月消费行为变化比较大。这个用户应该是前面消费很少，后期消费突然增多。那么，从我们这个示例模型的建模方式来说，对这种类型的用户，预测的就会很不准确，可以从特征选择、建模的方法来考虑有没有新的 idea。<br><br>其实啊，要预测未来的数值，理论上虽可行，但一定要做好有巨大误差的准备。这和预测股价类似，理论上模型可能预测一个上升趋势，但是实际上可能因为特殊因素突然大幅下跌。","user_name":"作者回复","comment_id":311896,"uid":"1809833","ip_address":"","utype":1,"ctime":1631531732,"user_name_real":"黄佳"}],"discussion_count":1,"race_medal":0,"score":"9.2233720513712005e+18","product_id":100085501,"comment_content":"真值: 14389.900000000007<br>线性回归预测值: 150.00460000000007<br>决策树预测值: 106.2<br>随机森林预测值: 150.00460000000007<br>验证集上的R平方分数-线性回归: 0.3002<br>验证集上的R平方分数-决策树: 0.3391<br>验证集上的R平方分数-随机森林: 0.3353<br>老师，我复现了一下代码，但是真值和预测值偏差较大，对于这种问题，老师的解决问题思路是什么啊？","like_count":3,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526784,"discussion_content":"关于这个数据点的预测值和真值。这里有几个方面的考量。第一，我们的数据量比较小，只有几百个用户的数据。要得到更健壮的模型，需要很大量的数据。第二，从数据的角度，这个数据点他的前三个月和后12个月消费行为变化比较大。这个用户应该是前面消费很少，后期消费突然增多。那么，从我们这个示例模型的建模方式来说，对这种类型的用户，预测的就会很不准确，可以从特征选择、建模的方法来考虑有没有新的 idea。\n\n其实啊，要预测未来的数值，理论上虽可行，但一定要做好有巨大误差的准备。这和预测股价类似，理论上模型可能预测一个上升趋势，但是实际上可能因为特殊因素突然大幅下跌。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631531732,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":311814,"user_name":"For Uuuuu","can_delete":false,"product_type":"c1","uid":2763064,"ip_address":"","ucode":"3123E415CE8799","user_header":"https://static001.geekbang.org/account/avatar/00/2a/29/38/9c0edffc.jpg","comment_is_top":true,"comment_ctime":1631490083,"is_pvip":false,"replies":[{"id":"112970","content":"有，欢迎加群，方式见课程介绍链接。<br>https:&amp;#47;&amp;#47;time.geekbang.org&amp;#47;column&amp;#47;intro&amp;#47;438","user_name":"作者回复","comment_id":311814,"uid":"1809833","ip_address":"","utype":1,"ctime":1631498418,"user_name_real":"作者"}],"discussion_count":2,"race_medal":0,"score":"9.2233720513712005e+18","product_id":100085501,"comment_content":"有交流群吗？","like_count":3,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526753,"discussion_content":"有，欢迎加群，方式见课程介绍链接。\nhttps:&#47;&#47;time.geekbang.org&#47;column&#47;intro&#47;438","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631498418,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1590623,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eqGaJsoQicG7Bp8cUjUkevAp5Sm8ZXy5vl5TVk4CDrq5UAoI9VicK5wwjCdk66FVRbGziaWXHgO52l1Q/132","nickname":"Geek_06d12d","note":"","ucode":"1C5172C3BBAEC3","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":589567,"discussion_content":"课程介绍里没看到呀","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1665130337,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"浙江"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":311853,"user_name":"在路上","can_delete":false,"product_type":"c1","uid":1402511,"ip_address":"","ucode":"6E31908EFE1107","user_header":"https://static001.geekbang.org/account/avatar/00/15/66/8f/02be926d.jpg","comment_is_top":true,"comment_ctime":1631506588,"is_pvip":false,"replies":[{"id":"112979","content":"&quot;写Demo的时候发现sklearn库非常强大，测试不同算法的效果非常容易。&quot; ---- 太棒了，你发现了这一点，这个课程就没有白学了。用好它！😍","user_name":"作者回复","comment_id":311853,"uid":"1809833","ip_address":"","utype":1,"ctime":1631507901,"user_name_real":"黄佳"}],"discussion_count":1,"race_medal":0,"score":"9.2233720427812004e+18","product_id":100085501,"comment_content":"佳哥好，加上SVM和朴素贝叶斯算法之后R^2值为：<br>```<br>验证集上的R平方分数-线性回归: 0.4333<br>验证集上的R平方分数-决策树: 0.3286<br>验证集上的R平方分数-随机森林: 0.5130<br>验证集上的R平方分数-SVM: -0.1085<br>验证集上的R平方分数-朴素贝叶斯: 0.4417<br>```<br>可以看到朴素贝叶斯算法的效果也不错，SVM算法的效果则很差。写Demo的时候发现sklearn库非常强大，测试不同算法的效果非常容易。<br><br>回归问题的评估指标有很多种，R^2、均方误差、中值绝对误差有什么区别呢？首先是取标准值，是数据集的中值，还是数据集加总后的平均值。然后是误差的计算，距离标准值越大，结果以什么样的形式放大，是差值的绝对值，还是差值的平方，平方意味结果被显著的放大，差值越大的数据影响越大。最后是消除原始数据离散的影响，这体现在R^2计算公式的分母中，原始数据离散程度越高，很可能会导致预测结果的波动越大。","like_count":1,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526773,"discussion_content":"&amp;quot;写Demo的时候发现sklearn库非常强大，测试不同算法的效果非常容易。&amp;quot; ---- 太棒了，你发现了这一点，这个课程就没有白学了。用好它！😍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631507901,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":311824,"user_name":"李冀","can_delete":false,"product_type":"c1","uid":1212032,"ip_address":"","ucode":"F393FA203B834C","user_header":"https://static001.geekbang.org/account/avatar/00/12/7e/80/be05419a.jpg","comment_is_top":true,"comment_ctime":1631495689,"is_pvip":false,"replies":[{"id":"112969","content":"对的。总结的好。RFM主要用于观察老用户，然后促进在老用户身上的营收增长，精细化运营。<br><br>在拉新过程中，也就是起到一些估计指导意义，大概估计一批新用户有可能带来的平均回报吧。","user_name":"作者回复","comment_id":311824,"uid":"1809833","ip_address":"","utype":1,"ctime":1631498351,"user_name_real":"黄佳"}],"discussion_count":1,"race_medal":0,"score":"9.2233720427812004e+18","product_id":100085501,"comment_content":"“通过不同RFM层级就可以确定不同的获客成本”。但花钱引流时不知道RFM值啊，再建立一个渠道、城市到RFM的模型？感觉初期RFM到LTV的关系对促活更有指导意义，而不是拉新","like_count":1,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526758,"discussion_content":"对的。总结的好。RFM主要用于观察老用户，然后促进在老用户身上的营收增长，精细化运营。\n\n在拉新过程中，也就是起到一些估计指导意义，大概估计一批新用户有可能带来的平均回报吧。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631498351,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":312316,"user_name":"青松","can_delete":false,"product_type":"c1","uid":2746821,"ip_address":"","ucode":"B98F744AF1135B","user_header":"https://static001.geekbang.org/account/avatar/00/29/e9/c5/7ecb497f.jpg","comment_is_top":false,"comment_ctime":1631744938,"is_pvip":false,"replies":[{"id":"113227","content":"有啊，所有的jupyter notebook我不是都上载到GitHub里面了么。https:&#47;&#47;github.com&#47;huangjia2019&#47;geektime<br>","user_name":"作者回复","comment_id":312316,"uid":"1809833","ip_address":"","utype":1,"ctime":1631864466,"user_name_real":"黄佳"}],"discussion_count":1,"race_medal":0,"score":"10221679530","product_id":100085501,"comment_content":"这个课程有jupyter notebook格式的文档吗？想一边教学一边实践","like_count":2,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526935,"discussion_content":"有啊，所有的jupyter notebook我不是都上载到GitHub里面了么。https://github.com/huangjia2019/geektime\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631864466,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":338251,"user_name":"松饼Muffin","can_delete":false,"product_type":"c1","uid":2938616,"ip_address":"","ucode":"1FCE9E6E4F9C8C","user_header":"https://static001.geekbang.org/account/avatar/00/2c/d6/f8/cb21b43c.jpg","comment_is_top":false,"comment_ctime":1647393228,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"5942360524","product_id":100085501,"comment_content":"老师， 想到一个问题， 客户的第一次购买时间（即获客时间）并不都 是从2020年6月1号开始， 所以要选取特征值（客户前三个月的ＲＦＭ）是不是以该客户第一次购买后的三个月内的数值更公平些？同理，　标签值（客户１２个月的购买金额）是不是也用自从该客户第一次购买以来的１２个月内的总购买金额为妥？","like_count":1,"discussions":[{"author":{"id":2938616,"avatar":"https://static001.geekbang.org/account/avatar/00/2c/d6/f8/cb21b43c.jpg","nickname":"松饼Muffin","note":"","ucode":"1FCE9E6E4F9C8C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":557085,"discussion_content":"老师， 然后我用这个口径， 选取第一次购买日期在一年前的客户（只有132个）， 然后用每个客户自己前三个月的购买金额和购买频次做为特征值， 他们 一年内的购买金额做为标签值， 这样做出来决策树和随机森林的R2_SCORE竟然都 等于1 ， 线性回归的是0.88，这可能吗？是因为数据太少吗（只是132个购买时间超过一年的）？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1647656997,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":359013,"user_name":"Geek_06d12d","can_delete":false,"product_type":"c1","uid":1590623,"ip_address":"浙江","ucode":"1C5172C3BBAEC3","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eqGaJsoQicG7Bp8cUjUkevAp5Sm8ZXy5vl5TVk4CDrq5UAoI9VicK5wwjCdk66FVRbGziaWXHgO52l1Q/132","comment_is_top":false,"comment_ctime":1665153348,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1665153348","product_id":100085501,"comment_content":"预测值和老师贴的相差较大，看了下老师在github上的代码，发现再清洗的时候没有把数量小于0的给清洗掉。","like_count":0},{"had_liked":false,"id":357713,"user_name":"Null","can_delete":false,"product_type":"c1","uid":1382587,"ip_address":"北京","ucode":"A7D4DF2A43C7D8","user_header":"https://static001.geekbang.org/account/avatar/00/15/18/bb/9299fab1.jpg","comment_is_top":false,"comment_ctime":1663577728,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1663577728","product_id":100085501,"comment_content":"老师非常感谢这么优秀的课程，有几处建议和请求了。<br>个人觉得用模型去score，print(&#39;验证集上的R平方分数-线性回归: %0.4f&#39; % model_lr.score(x_valid, y_valid))，学员更容易记住和理解。不用去记一个函数。延续了model的fit，predict，score一惯性。<br><br>另外，数据分为  train, valid, test。感觉是不是有些多余，感觉valid也在做的是test的事呢。只分为train和test就好了吧。文章最后的真实值和预测值用valid数据也是没问题的。","like_count":0},{"had_liked":false,"id":344063,"user_name":"Amaplan","can_delete":false,"product_type":"c1","uid":2765794,"ip_address":"","ucode":"FF7AD4404EC462","user_header":"","comment_is_top":false,"comment_ctime":1651218581,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1651218581","product_id":100085501,"comment_content":"问题二代码:<br>from sklearn.metrics import explained_variance_score,\\<br>mean_absolute_error,mean_squared_error,median_absolute_error,r2_score<br>print(&#39;数据梯度提升回归树模型的平均绝对误差为：&#39;,<br>     mean_absolute_error(y_valid,model_br.predict(X2_valid)))<br>print(&#39;数据梯度提升回归树模型的均方误差为：&#39;,<br>     mean_squared_error(y_valid,model_br.predict(X2_valid)))<br>print(&#39;数据梯度提升回归树模型的中值绝对误差为：&#39;,<br>     median_absolute_error(y_valid,model_br.predict(X2_valid)))<br>print(&#39;数据梯度提升回归树模型的可解释方差值为：&#39;,<br>     explained_variance_score(y_valid,model_br.predict(X2_valid)))<br>print(&#39;数据梯度提升回归树模型的R方值为：&#39;,<br>     r2_score(y_valid,model_br.predict(X2_valid)))","like_count":0},{"had_liked":false,"id":342082,"user_name":"云师兄","can_delete":false,"product_type":"c1","uid":1205777,"ip_address":"","ucode":"EB19F80070FE23","user_header":"https://static001.geekbang.org/account/avatar/00/12/66/11/f7408e3e.jpg","comment_is_top":false,"comment_ctime":1650007952,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1650007952","product_id":100085501,"comment_content":"验证集上的R平方分数-线性回归: 0.4333<br>验证集上的R平方分数-决策树: 0.0872<br>验证集上的R平方分数-随机森林: 0.5570<br>验证集上的R平方分数-svm: -0.1085<br>验证集上的R平方分数-朴素贝叶斯: 0.4417<br>验证集上的均方误差分数-线性回归: 12613369.9850<br>验证集上的均方误差分数-决策树: 20317437.8453<br>验证集上的均方误差分数-随机森林: 9861013.6327<br>验证集上的均方误差分数-svm: 24671639.1382<br>验证集上的均方误差分数-朴素贝叶斯: 12425693.7186<br>验证集上的中值绝对误差分数-线性回归: 759.1022<br>验证集上的中值绝对误差分数-决策树: 1137.9000<br>验证集上的中值绝对误差分数-随机森林: 637.8602<br>验证集上的中值绝对误差分数-svm: 903.3303<br>验证集上的中值绝对误差分数-朴素贝叶斯: 763.8333","like_count":0},{"had_liked":false,"id":333530,"user_name":"Geek_9acbe3","can_delete":false,"product_type":"c1","uid":2334994,"ip_address":"","ucode":"A5C75032EE0122","user_header":"","comment_is_top":false,"comment_ctime":1644395320,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"1644395320","product_id":100085501,"comment_content":"构建前三个月RFM值的时候报错，有小伙伴知道什么情况不？<br>AttributeError                            Traceback (most recent call last)<br>&lt;ipython-input-6-cdf870b083b2&gt; in &lt;module&gt;<br>      9 df_F_value.columns = [&#39;用户码&#39;,&#39;F值&#39;] #设定字段名<br>     10 df_user_LTV = pd.merge(df_user_LTV, df_F_value[[&#39;用户码&#39;,&#39;F值&#39;]], on=&#39;用户码&#39;) #把消费频率(F值)整合至df_user结构<br>---&gt; 11 df_M_value = df_sales_3m.groupby(&#39;用户码&#39;).总价.sum().reset_index() #计算每个用户三个月消费总额，构建df_M_value对象<br>     12 df_M_value.columns = [&#39;用户码&#39;,&#39;M值&#39;] #设定字段名<br>     13 df_user_LTV = pd.merge(df_user_LTV, df_M_value, on=&#39;用户码&#39;) #把消费总额整合至df_user结构<br><br>C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py in __getattr__(self, attr)<br>    750             return self[attr]<br>    751 <br>--&gt; 752         raise AttributeError(<br>    753             f&quot;&#39;{type(self).__name__}&#39; object has no attribute &#39;{attr}&#39;&quot;<br>    754         )<br><br>AttributeError: &#39;DataFrameGroupBy&#39; object has no attribute &#39;总价&#39;","like_count":0,"discussions":[{"author":{"id":2765794,"avatar":"","nickname":"Amaplan","note":"","ucode":"FF7AD4404EC462","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":568375,"discussion_content":"上表11行前面加上\ndf_sales_3m[&#39;总价&#39;]=df_sales_3m[&#39;数量&#39;]*df_sales_3m[&#39;单价&#39;]","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1651119866,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1346402,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/bmgpp5wc8GLmOdHNQccSgrunK0VdIicB6rpTHXCTF5xEkm2YvPHOX2DwNt2EqTzJ70JD41h0u5qW4R0yXRY1ZCg/132","nickname":"Eazow","note":"","ucode":"D81D8FF2B2FF0D","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":557655,"discussion_content":"需要在df_sales加个总价字段：\ndf_sales[&#34;总价&#34;] = df_sales[&#34;单价&#34;] * df_sales[&#34;数量&#34;]\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1647917924,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":328274,"user_name":"trust","can_delete":false,"product_type":"c1","uid":1935244,"ip_address":"","ucode":"E96EB585FE1BD7","user_header":"","comment_is_top":false,"comment_ctime":1640652646,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1640652646","product_id":100085501,"comment_content":"老师，前三个月付费是0的用户也是需要分摊成本的不，为啥要把这部分人去掉呢，这样会不会让得出来的投放成本变大呢？<br>第二个问题是rfm三个特征还是都需要做共线性判断哒","like_count":0,"discussions":[{"author":{"id":2334994,"avatar":"","nickname":"Geek_9acbe3","note":"","ucode":"A5C75032EE0122","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":550118,"discussion_content":"有可能是因为9月以后才注册的，因此前三个月没有交易数据，不排除有6月注册9月才开始消费的客户，但是一方面概率比较小（一般首次注册下载app都会跟随消费），另一方面牺牲这一部分数据，减少一部分样本量，可以免去额外识别注册时间的麻烦？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1644390314,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":323618,"user_name":"鼎","can_delete":false,"product_type":"c1","uid":1038780,"ip_address":"","ucode":"44BBCCBA901121","user_header":"https://static001.geekbang.org/account/avatar/00/0f/d9/bc/a2803bb7.jpg","comment_is_top":false,"comment_ctime":1638025086,"is_pvip":false,"replies":[{"id":"118525","content":"我的理解决策树在训练集上是可以达到1的，测试集也达到1就奇怪了。","user_name":"作者回复","comment_id":323618,"uid":"1809833","ip_address":"","utype":1,"ctime":1639499539,"user_name_real":"编辑"}],"discussion_count":2,"race_medal":0,"score":"1638025086","product_id":100085501,"comment_content":"佳哥好，我将城市作为自变量，引入 city = pd.get_dummies(df_sales.城市, prefix=&#39;城市&#39;)<br>结果显示R2数基本为1，基本上完全预测正确，但应该是不太可能的，不知道是哪里出了问题？<br><br>“验证集上的R平方分数-线性回归: 0.9102<br>验证集上的R平方分数-决策树: 1.0000<br>验证集上的R平方分数-随机森林: 1.0000“","like_count":0,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":538775,"discussion_content":"我的理解决策树在训练集上是可以达到1的，测试集也达到1就奇怪了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1639499539,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2235373,"avatar":"https://static001.geekbang.org/account/avatar/00/22/1b/ed/c9ed26f5.jpg","nickname":"🐼","note":"","ucode":"C62E6D9867FE90","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":569021,"discussion_content":"怎么把城市变量引入啊 可以教教我吗","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1651291082,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":320936,"user_name":"曲**","can_delete":false,"product_type":"c1","uid":2056349,"ip_address":"","ucode":"133BF185E099A5","user_header":"https://static001.geekbang.org/account/avatar/00/1f/60/9d/574a9fa0.jpg","comment_is_top":false,"comment_ctime":1636586486,"is_pvip":false,"replies":[{"id":"116881","content":"用真实业务数据建模，捕捉出业务的趋势，发现对运营有价值的信息，就算上是具有实际应用价值。举个例子，银行的反欺诈系统，如果在上百万条数据中，找到几百条可能存在问题的交易，让业务部门去筛查。这就产生了价值。因为它把要查的数据从几百万这么多大大缩小了，减轻了业务的负担。","user_name":"作者回复","comment_id":320936,"uid":"1809833","ip_address":"","utype":1,"ctime":1637076483,"user_name_real":"编辑"}],"discussion_count":1,"race_medal":0,"score":"1636586486","product_id":100085501,"comment_content":"老师我看了楼上的留言，根据demo作出的偏差较大。想问一下，什么程度的方案才具有实际应用的价值？","like_count":0,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":530484,"discussion_content":"用真实业务数据建模，捕捉出业务的趋势，发现对运营有价值的信息，就算上是具有实际应用价值。举个例子，银行的反欺诈系统，如果在上百万条数据中，找到几百条可能存在问题的交易，让业务部门去筛查。这就产生了价值。因为它把要查的数据从几百万这么多大大缩小了，减轻了业务的负担。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1637076483,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":317481,"user_name":"shatu","can_delete":false,"product_type":"c1","uid":2760732,"ip_address":"","ucode":"27077AA35B8C22","user_header":"https://static001.geekbang.org/account/avatar/00/2a/20/1c/de379ed1.jpg","comment_is_top":false,"comment_ctime":1634810397,"is_pvip":false,"replies":[{"id":"116898","content":"笔误，应该是model_rfr。会修正。","user_name":"作者回复","comment_id":317481,"uid":"1809833","ip_address":"","utype":1,"ctime":1637080121,"user_name_real":"编辑"}],"discussion_count":2,"race_medal":0,"score":"1634810397","product_id":100085501,"comment_content":"最后绘图随机森林（rfr）的预测结果为什么要用线性回归（lr）的模型？<br>y_test_preds_rfr = model_lr.predict(X_test) #用模型预随机森林模型预测验证集","like_count":0,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":530536,"discussion_content":"笔误，应该是model_rfr。会修正。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1637080121,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2813087,"avatar":"https://static001.geekbang.org/account/avatar/00/2a/ec/9f/7fa3bf00.jpg","nickname":"Elaine","note":"","ucode":"BC35964F85B55B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":413295,"discussion_content":"我也看到这个了，应该是typo","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1636440534,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":316619,"user_name":"dao","can_delete":false,"product_type":"c1","uid":1087879,"ip_address":"","ucode":"4181FB270462CF","user_header":"https://static001.geekbang.org/account/avatar/00/10/99/87/98ebb20e.jpg","comment_is_top":false,"comment_ctime":1634455582,"is_pvip":true,"replies":[{"id":"114681","content":"如果没有指定随机种子，那么每次训练集、验证集的分割都不同。我们案例数据集小，这种数据分割不同造成的影响就大。<br>如果每次都指定相同的随机种子，你会发现，一部分模型（如线性回归）的结果一直不变。另一部分模型（如随机森林）本身带有随机性，结果仍然可能不同。","user_name":"作者回复","comment_id":316619,"uid":"1809833","ip_address":"","utype":1,"ctime":1634537978,"user_name_real":"黄佳"}],"discussion_count":1,"race_medal":0,"score":"1634455582","product_id":100085501,"comment_content":"老师，回归算法每次训练出来的结果是不同的？这是否是因为训练集分隔的随机性造成的？","like_count":0,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":528438,"discussion_content":"如果没有指定随机种子，那么每次训练集、验证集的分割都不同。我们案例数据集小，这种数据分割不同造成的影响就大。\n如果每次都指定相同的随机种子，你会发现，一部分模型（如线性回归）的结果一直不变。另一部分模型（如随机森林）本身带有随机性，结果仍然可能不同。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1634537978,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":313444,"user_name":"青松","can_delete":false,"product_type":"c1","uid":2746821,"ip_address":"","ucode":"B98F744AF1135B","user_header":"https://static001.geekbang.org/account/avatar/00/29/e9/c5/7ecb497f.jpg","comment_is_top":false,"comment_ctime":1632445652,"is_pvip":false,"replies":[{"id":"113678","content":"谢谢指出这个问题，的确，我重跑一遍，得出的是：<br><br>X_train - 253； X_valid - 54；X_test - 55<br><br>一共：362行数据。我回头把文档调整一下。<br>","user_name":"作者回复","comment_id":313444,"uid":"1809833","ip_address":"","utype":1,"ctime":1632759477,"user_name_real":"黄佳"}],"discussion_count":1,"race_medal":0,"score":"1632445652","product_id":100085501,"comment_content":"原文中：<br>X_train 是 288 行×4 列；<br>y_train 是 288 行×1 列；<br>X_valid 是 73 行×4 列；<br>y_valid 是 73 行×1 列；<br>X_test 是 73 行×4 列；<br>y_test 是 73 行×1 列。<br>这个有问题，一共361的样本，361*0.7=255（X_train），361*0.3*0.5= 54(或者55）（X_valid和X_test)","like_count":0,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527354,"discussion_content":"谢谢指出这个问题，的确，我重跑一遍，得出的是：\n\nX_train - 253； X_valid - 54；X_test - 55\n\n一共：362行数据。我回头把文档调整一下。\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1632759477,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":313162,"user_name":"青松","can_delete":false,"product_type":"c1","uid":2746821,"ip_address":"","ucode":"B98F744AF1135B","user_header":"https://static001.geekbang.org/account/avatar/00/29/e9/c5/7ecb497f.jpg","comment_is_top":false,"comment_ctime":1632299744,"is_pvip":false,"replies":[{"id":"113681","content":"跟着数据和代码跑，删除负值后，我得到362个数据。不过，这也并不那么重要，掌握回归分析方法就好🎅","user_name":"作者回复","comment_id":313162,"uid":"1809833","ip_address":"","utype":1,"ctime":1632759587,"user_name_real":"黄佳"}],"discussion_count":1,"race_medal":0,"score":"1632299744","product_id":100085501,"comment_content":"构建特征和标签 这节中我怎么得到370个数量集呢？？","like_count":0,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527252,"discussion_content":"跟着数据和代码跑，删除负值后，我得到362个数据。不过，这也并不那么重要，掌握回归分析方法就好🎅","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1632759587,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":312125,"user_name":"Jove","can_delete":false,"product_type":"c1","uid":1234583,"ip_address":"","ucode":"82CEFDC5F66073","user_header":"https://static001.geekbang.org/account/avatar/00/12/d6/97/035a237b.jpg","comment_is_top":false,"comment_ctime":1631631610,"is_pvip":true,"replies":[{"id":"113230","content":"好问题好问题。<br>评估标准不同，是有可能导致不同的结果的，你想一想：我们按照“采光情况”和“噪音大小”来评估房子，不会得到一样的分数，对不？这就是具体情况具体分析，你比较看重哪个指标。这就是不同的评估标准存在的意义。<br><br>那么，对于回归问题来说，简单来说R方更常用，算是一个基本公认的比较好的标准吧。","user_name":"作者回复","comment_id":312125,"uid":"1809833","ip_address":"","utype":1,"ctime":1631864662,"user_name_real":"黄佳"}],"discussion_count":4,"race_medal":0,"score":"1631631610","product_id":100085501,"comment_content":"1、<br>df_C_value = (df_sales.groupby(&#39;用户码&#39;)[[&#39;城市_上海&#39;,&#39;城市_北京&#39;, &#39;城市_广州&#39;, &#39;城市_成都&#39;, &#39;城市_深圳&#39;, &#39;城市_苏州&#39;, &#39;城市_西安&#39;]].sum() &gt; 1)<br>df_LTV = pd.merge(df_LTV, df_C_value, on=&#39;用户码&#39;)<br><br>2、以下为添加城市维度<br>验证集上的R平方分数-线性回归: 0.5627<br>验证集上的R平方分数-决策树: 0.8694<br>验证集上的R平方分数-随机森林: 0.7361<br>验证集上的R平方分数-SVM: -0.0777<br>验证集上的R平方分数-朴素贝叶斯: 0.5872<br><br>验证集上的中值绝对误差分数-线性回归: 741.8732<br>验证集上的中值绝对误差分数-决策树: 758.0300<br>验证集上的中值绝对误差分数-随机森林: 685.0138<br>验证集上的中值绝对误差分数-SVM: 931.4885<br>验证集上的中值绝对误差分数-朴素贝叶斯: 763.8012<br><br>验证集上的均方差误差分数-线性回归: 22805033.1514<br>验证集上的均方差误差分数-决策树: 6812124.3173<br>验证集上的均方差误差分数-随机森林: 13761994.3462<br>验证集上的均方差误差分数-SVM: 56202432.0296<br>验证集上的均方差误差分数-朴素贝叶斯: 21528518.5128<br><br>ps: 不同评估方法对结果不同，R平方：决策树；中值：SVM；均方差：SVM。<br>疑问如何各个评估标准结果都不一样，该如何选择模型呢？","like_count":0,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526870,"discussion_content":"好问题好问题。\n评估标准不同，是有可能导致不同的结果的，你想一想：我们按照“采光情况”和“噪音大小”来评估房子，不会得到一样的分数，对不？这就是具体情况具体分析，你比较看重哪个指标。这就是不同的评估标准存在的意义。\n\n那么，对于回归问题来说，简单来说R方更常用，算是一个基本公认的比较好的标准吧。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631864662,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1038780,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/d9/bc/a2803bb7.jpg","nickname":"鼎","note":"","ucode":"44BBCCBA901121","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":533992,"discussion_content":"df_sales_3m.groupby(&#39;用户码&#39;)[[&#39;城市_上海&#39;,&#39;城市_北京&#39;, &#39;城市_广州&#39;, &#39;城市_成都&#39;, &#39;城市_深圳&#39;, &#39;城市_苏州&#39;, &#39;城市_西安&#39;]].sum()&gt;1)  这块sum()&gt;1是出于什么考虑？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1638065642,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1087879,"avatar":"https://static001.geekbang.org/account/avatar/00/10/99/87/98ebb20e.jpg","nickname":"dao","note":"","ucode":"4181FB270462CF","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":404885,"discussion_content":"不过由于用户的城市应该是固定的，所以使用12个月和前3个月数据应该是一样的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1634447601,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1087879,"avatar":"https://static001.geekbang.org/account/avatar/00/10/99/87/98ebb20e.jpg","nickname":"dao","note":"","ucode":"4181FB270462CF","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":404884,"discussion_content":"这里的城市哑变量取值是否也应该只计算前3个月的数据 ？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1634447416,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":311990,"user_name":"谦","can_delete":false,"product_type":"c1","uid":2417283,"ip_address":"","ucode":"9AA072153D7A09","user_header":"https://static001.geekbang.org/account/avatar/00/24/e2/83/e2888084.jpg","comment_is_top":false,"comment_ctime":1631585744,"is_pvip":true,"replies":[{"id":"113138","content":"在模型移植这方面，我的经验就相对有限一些。因为大的项目组中，负责建模和负责模型部署，或者模型移植复现的是两组人。让我来查阅一下相关方面的资料，然后在后面做一些分享。😁","user_name":"作者回复","comment_id":311990,"uid":"1809833","ip_address":"","utype":1,"ctime":1631725848,"user_name_real":"黄佳"}],"discussion_count":1,"race_medal":0,"score":"1631585744","product_id":100085501,"comment_content":"sklearn很好用，不过在实际项目中我经常需要把训练好的模型移植到其他平台上，例如用c语言重新实现一次预测模型，一般来说svm移植比较简单，找到coef_和intercept_，复制一下就可以。决策树相对麻烦一点，要递归遍历整棵树，输出特征和阈值。随机森林或者使用决策树的adaboost就要遍历很多棵树。想请问佳哥在预测模型的移植和应用上有没有一些经验可以分享一下？谢谢😊","like_count":0,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526823,"discussion_content":"在模型移植这方面，我的经验就相对有限一些。因为大的项目组中，负责建模和负责模型部署，或者模型移植复现的是两组人。让我来查阅一下相关方面的资料，然后在后面做一些分享。😁","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631725848,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":311826,"user_name":"李冀","can_delete":false,"product_type":"c1","uid":1212032,"ip_address":"","ucode":"F393FA203B834C","user_header":"https://static001.geekbang.org/account/avatar/00/12/7e/80/be05419a.jpg","comment_is_top":false,"comment_ctime":1631495833,"is_pvip":false,"replies":[{"id":"113040","content":"无一定之规，机器学习建模时通常都会尝试多种可用的模型。","user_name":"作者回复","user_name_real":"黄佳","uid":"1809833","ctime":1631551004,"ip_address":"","comment_id":311826,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1631495833","product_id":100085501,"comment_content":"哪些模型适合用哪种度量值，这个有最佳实践吗","like_count":0,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526759,"discussion_content":"无一定之规，机器学习建模时通常都会尝试多种可用的模型。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631551004,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]}]}