{"id":654414,"title":"24｜Stable Diffusion：最热门的开源AI画图工具","content":"<p>你好，我是徐文浩。</p><p><a href=\"https://time.geekbang.org/column/article/653489\">上一讲</a>，我们一起体验了CLIP这个多模态的模型。在这个模型里，我们已经能够把一段文本和对应的图片关联起来了。看到文本和图片的关联，想必你也能联想到过去半年非常火热的“文生图”（Text-To-Image）的应用浪潮了。相比于在大语言模型里OpenAI的一枝独秀。文生图领域就属于百花齐放了，OpenAI陆续发表了DALL-E和 <a href=\"https://labs.openai.com/\">DALL-E 2</a>，Google也不甘示弱地发表了 <a href=\"https://imagen.research.google/\">Imagen</a>，而市场上实际被用得最多、反馈最好的用户端产品是 <a href=\"https://midjourney.com/home/\">Midjourney</a>。</p><p>不过，在整个技术社区里，最流行的产品则是Stable Diffusion。因为它是一个完全开源的产品，我们不仅可以调用Stable Diffusion内置的模型来生成图片，还能够下载社区里其他人训练好的模型来生成图片。我们不仅可以通过文本来生成图片，还能通过图片来生成图片，通过文本来编辑图片。</p><p>那么今天这一讲，我们就来看看如何使用Stable Diffusion，做到上面这些事情。</p><h2>使用Stable Diffusion生成图片</h2><h3>文生图</h3><p>可能你还没怎么体验过文生图的应用，那我们先用几行最简单的代码体验一下。在这一讲里，我建议一定要用Colab或者其他的GPU环境，因为用CPU来执行的话，速度会慢到让人无法接受。</p><!-- [[[read_end]]] --><p>安装依赖包：</p><pre><code class=\"language-python\">%pip install diffusers accelerate transformers\n</code></pre><p>代码：</p><pre><code class=\"language-python\">from diffusers import DiffusionPipeline\npipeline = DiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\npipeline.to(\"cuda\")\nimage = pipeline(\"a photograph of an astronaut riding a horse\").images[0]\nimage\n</code></pre><p>输出结果：<br>\n<img src=\"https://static001.geekbang.org/resource/image/72/57/7217f995c7fd7143ef6807d8e0dfc057.png?wh=512x512\" alt=\"图片\"></p><p>代码非常简单，只有寥寥几行。这里，我们使用了Huggingface的Diffusers库，通过DiffusionPipeline加载了RunwayML的stable-diffusion-v1-5的模型。然后，指定了这个Pipeline使用CUDA也就是利用GPU来进行计算。最后向这个Pipeline输入了一段文本，通过这段文本我们就生成了一张图片。</p><p>这里，我们画的是在Stable Diffusion里非常经典的一张“宇航员在太空骑马”的图片。之所以画这么一张图片，是为了证明我们并不是通过“搜索”的方式找到一张已经存在的图片。比如，上一讲里我们介绍过CLIP模型，其实就可以完成从文本到图片的搜索功能。而Stable Diffusion，是真的让AI“画”出来一张新的图片。毕竟，以前宇航员也从来没有在太空骑过马，也不可能有人拍下过这样的照片。</p><h3>Stable Diffusion的基本原理</h3><p>Stable Diffusion生成的图片效果的确不错，相信你也很好奇这个事情的原理是什么。其实，Stable Diffusion背后不是单独的一个模型，而是由多个模型组合而成的。整个Stable Diffusion文生图的过程是由这样三个核心模块组成的。</p><ul>\n<li>第一个模块是一个Text-Encoder，把我们输入的文本变成一个向量。实际使用的就是我们上一讲介绍的CLIP模型。因为CLIP模型学习的是文本和图像之间的关系，所以得到的这个向量既理解了文本的含义，又能和图片的信息关联起来。</li>\n<li>第二个是Generation模块，顾名思义是一个图片信息生成模块。这里也有一个机器学习模型，叫做UNet，还有一个调度器（Scheduler），用来一步步地去除噪声。这个模块的工作流程是先往前面的用CLIP模型推理出来的向量里添加很多噪声，再通过UNet+Scheduler逐渐去除噪声，最后拿到了一个新的张量。这个张量可以认为是一个尺寸上缩小了的图片信息向量，里面隐含了我们要生成的图片信息。</li>\n<li>最后一个模块，则是Decoder或者叫做解码器。背后也是一个机器学习的模型，叫做VAE。它会根据第二步的返回结果把这个图像信息还原成最终的图片。</li>\n</ul><p>这个过程，你可以结合Stable Diffusion相关论文里的一张模型架构图来看。</p><p><img src=\"https://static001.geekbang.org/resource/image/4c/cb/4ca19441686120b9c28c8d5ba11baacb.png?wh=598x310\" alt=\"图片\"></p><p>这样听起来可能有点太理论了，那我们还是看看具体的代码和图片生成的过程吧，这样就比较容易理解图片是怎么生成的了。</p><p>我们先把DiffusionPipeline打印出来，看看它内部是由哪些部分组成的。</p><pre><code class=\"language-python\">pipeline\n</code></pre><p>输出结果：</p><pre><code class=\"language-python\">StableDiffusionPipeline {\n  \"_class_name\": \"StableDiffusionPipeline\",\n  \"_diffusers_version\": \"0.15.1\",\n  \"feature_extractor\": [\n    \"transformers\",\n    \"CLIPFeatureExtractor\"\n  ],\n  \"requires_safety_checker\": true,\n  \"safety_checker\": [\n    \"stable_diffusion\",\n    \"StableDiffusionSafetyChecker\"\n  ],\n  \"scheduler\": [\n    \"diffusers\",\n    \"PNDMScheduler\"\n  ],\n  \"text_encoder\": [\n    \"transformers\",\n    \"CLIPTextModel\"\n  ],\n  \"tokenizer\": [\n    \"transformers\",\n    \"CLIPTokenizer\"\n  ],\n  \"unet\": [\n    \"diffusers\",\n    \"UNet2DConditionModel\"\n  ],\n  \"vae\": [\n    \"diffusers\",\n    \"AutoencoderKL\"\n  ]\n}\n</code></pre><p>这个对象里面有3部分。</p><ol>\n<li>Tokenizer和Text_Encoder，就是我们上面说的把文本变成向量的Text Encoder。可以看到我们这里用的模型就是上一讲的CLIP模型。</li>\n<li>UNet和Scheduler，就是对文本向量以及输入的噪声进行噪声去除的组件，也就是Generation模块。这里用的是UNet2DConditionModel模型，还把PNDMScheduler用作了去除噪声的调度器。</li>\n<li>VAE，也就是解码器（Decoder），这里用的是AutoencoderKL，它会根据上面生成的图片信息最后还原出一张高分辨率的图片。</li>\n</ol><p>剩下的feature_extractor，可以用来提取图像特征，如果我们不想文生图，想要图生图，它就会被用来把我们输入的图片的特征提取成为向量。而safety_checker则是用来检查生成内容，避免生成具有冒犯性的图片。</p><p>接下来，我们就自己来组合一下这些模型，来把整个图片生成的过程给演示出来。首先，我们把上面Stable Diffusion 1.5需要的模型组件都加载出来。</p><pre><code class=\"language-python\">from transformers import CLIPTextModel, CLIPTokenizer\nfrom diffusers import AutoencoderKL, UNet2DConditionModel, PNDMScheduler\n\nvae = AutoencoderKL.from_pretrained(\"runwayml/stable-diffusion-v1-5\", subfolder=\"vae\")\ntokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\ntext_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\")\nunet = UNet2DConditionModel.from_pretrained(\"runwayml/stable-diffusion-v1-5\", subfolder=\"unet\")\nscheduler = PNDMScheduler.from_pretrained(\"runwayml/stable-diffusion-v1-5\", subfolder=\"scheduler\")\n\ntorch_device = \"cuda\"\nvae.to(torch_device)\ntext_encoder.to(torch_device)\nunet.to(torch_device)\n</code></pre><p><strong>注意，对应的CLIPTokenizer和CLIPTextModel的名字并不是stable-diffusion-v1-5，如果使用Diffusers库的Pipeline的话，可以从模型里面对应模块的 <a href=\"https://huggingface.co/runwayml/stable-diffusion-v1-5/blob/main/text_encoder/config.json\">config.json</a> 读取到它们。</strong></p><p>然后，我们把接下来生成图片的参数初始化一下，包括文本、对应的图片分辨率，以及一系列模型中需要使用的超参数。</p><pre><code class=\"language-python\">import torch\n\nprompt = [\"a photograph of an astronaut riding a horse\"]\nheight = 512  # default height of Stable Diffusion\nwidth = 512  # default width of Stable Diffusion\nnum_inference_steps = 25  # Number of denoising steps\nguidance_scale = 7.5  # Scale for classifier-free guidance\ngenerator = torch.manual_seed(42)  # Seed generator to create the inital latent noise\nbatch_size = len(prompt)\n</code></pre><p>然后，我们把对应的输入文本变成一个向量，然后再根据一个空字符串生成一个“无条件”的向量，最后把两个向量拼接在一起。我们实际生成图片的过程，就是逐渐从这个无条件的向量向输入文本表示的向量靠拢的过程。</p><pre><code class=\"language-python\">text_input = tokenizer(\n    prompt, padding=\"max_length\", max_length=tokenizer.model_max_length, truncation=True, return_tensors=\"pt\"\n)\n\nwith torch.no_grad():\n    text_embeddings = text_encoder(text_input.input_ids.to(torch_device))[0]\n\nmax_length = text_input.input_ids.shape[-1]\nuncond_input = tokenizer([\"\"] * batch_size, padding=\"max_length\", max_length=max_length, return_tensors=\"pt\")\nuncond_embeddings = text_encoder(uncond_input.input_ids.to(torch_device))[0]\n\ntext_embeddings = torch.cat([uncond_embeddings, text_embeddings])\n</code></pre><p>然后，我们可以先生成一系列随机噪声。</p><pre><code class=\"language-python\">latents = torch.randn(\n    (batch_size, unet.in_channels, height // 8, width // 8),\n    generator=generator,\n)\nlatents = latents.to(torch_device)\n\nlatents = latents * scheduler.init_noise_sigma\n</code></pre><p>接下来就是生成图片的代码了，我们先定义两个函数，它们会分别显示Generation模块生成出来的图片信息，以及Decoder模块还原出来的最终图片。</p><pre><code class=\"language-python\">import PIL\nimport torch\nimport numpy as np\nfrom PIL import Image\nfrom IPython.display import display\n\ndef display_denoised_sample(sample, i):\n    image_processed = sample.cpu().permute(0, 2, 3, 1)\n    image_processed = (image_processed + 1.0) * 127.5\n    image_processed = image_processed.numpy().astype(np.uint8)\n\n    image_pil = PIL.Image.fromarray(image_processed[0])\n    display(f\"Denoised Sample @ Step {i}\")\n    display(image_pil)\n    return image_pil\n\ndef display_decoded_image(latents, i):\n  # scale and decode the image latents with vae\n  latents = 1 / 0.18215 * latents\n  with torch.no_grad():\n    image = vae.decode(latents).sample\n    image = (image / 2 + 0.5).clamp(0, 1)\n    image = image.detach().cpu().permute(0, 2, 3, 1).numpy()\n    images = (image * 255).round().astype(\"uint8\")\n    pil_images = [Image.fromarray(image) for image in images]\n    display(f\"Decoded Image @ step {i}\")\n    display(pil_images[0])\n    return pil_images[0]\n</code></pre><p>最后，我们通过Diffusion算法一步一步来生成图片就好了。我们根据前面指定的参数，循环了25步，每一步都通过Scheduler和UNet来进行图片去噪声的操作。并且每5步都把对应去噪后的图片信息，以及解码后还原的图片显示出来。</p><pre><code class=\"language-python\">from tqdm.auto import tqdm\n\nscheduler.set_timesteps(num_inference_steps)\n\ndenoised_images = []\ndecoded_images = []\nfor i, t in enumerate(tqdm(scheduler.timesteps)):\n    # expand the latents if we are doing classifier-free guidance to avoid doing two forward passes.\n    latent_model_input = torch.cat([latents] * 2)\n\n    latent_model_input = scheduler.scale_model_input(latent_model_input, timestep=t)\n\n    # predict the noise residual\n    with torch.no_grad():\n        noise_pred = unet(latent_model_input, t, encoder_hidden_states=text_embeddings).sample\n\n    # perform guidance\n    noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n    noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n\n    # compute the previous noisy sample x_t -&gt; x_t-1\n    latents = scheduler.step(noise_pred, t, latents).prev_sample\n    if i % 5 == 0:\n      denoised_image = display_denoised_sample(latents, i)\n      decoded_image = display_decoded_image(latents, i)\n      denoised_images.append(denoised_image)\n      decoded_images.append(decoded_image)\n</code></pre><p>输出结果：</p><pre><code class=\"language-plain\">Denoised Sample @ Step 0\n</code></pre><p><img src=\"https://static001.geekbang.org/resource/image/e8/77/e8fa98c88172482a84f3dbfeb0ecdf77.png?wh=64x64\" alt=\"图片\"></p><pre><code class=\"language-plain\">Decoded Image @ step 0\n</code></pre><p><img src=\"https://static001.geekbang.org/resource/image/e2/b9/e2ef3c2972d3b73a3c93976ce19a6fb9.png?wh=512x512\" alt=\"图片\"></p><pre><code class=\"language-plain\">Denoised Sample @ Step 5\n</code></pre><p><img src=\"https://static001.geekbang.org/resource/image/7e/c1/7e385e61f741f470c490c39d41b0c3c1.png?wh=64x64\" alt=\"图片\"></p><pre><code class=\"language-plain\">Decoded Image @ step 5\n</code></pre><p><img src=\"https://static001.geekbang.org/resource/image/b8/dd/b81cb29b003412c80519c7b9f01baedd.png?wh=512x512\" alt=\"图片\"></p><pre><code class=\"language-plain\">Denoised Sample @ Step 10\n</code></pre><p><img src=\"https://static001.geekbang.org/resource/image/fd/06/fd262baafbb52271b0d906d00a167c06.png?wh=64x64\" alt=\"图片\"></p><pre><code class=\"language-plain\">Decoded Image @ step 10\n</code></pre><p><img src=\"https://static001.geekbang.org/resource/image/a6/22/a6be734e2813e80b8bd8b936c0741a22.png?wh=512x512\" alt=\"图片\"></p><pre><code class=\"language-plain\">Denoised Sample @ Step 15\n</code></pre><p><img src=\"https://static001.geekbang.org/resource/image/04/8c/04e1da57c913da86b83a6e30ddc1338c.png?wh=64x64\" alt=\"图片\"></p><pre><code class=\"language-plain\">Decoded Image @ step 15\n</code></pre><p><img src=\"https://static001.geekbang.org/resource/image/88/88/888d083873245d5b08780f52d8990788.png?wh=512x512\" alt=\"图片\"></p><pre><code class=\"language-plain\">Denoised Sample @ Step 20\n</code></pre><p><img src=\"https://static001.geekbang.org/resource/image/8a/b3/8a8ee2751036cfe7yy6e2c0d70104bb3.png?wh=64x64\" alt=\"图片\"></p><pre><code class=\"language-plain\">Decoded Image @ step 20\n</code></pre><p><img src=\"https://static001.geekbang.org/resource/image/8f/f7/8f094d4deacec42876201388c2ab24f7.png?wh=512x512\" alt=\"图片\"></p><pre><code class=\"language-plain\">Denoised Sample @ Step 25\n</code></pre><p><img src=\"https://static001.geekbang.org/resource/image/6a/a3/6a4c08550f36f249ac495e4f966a90a3.png?wh=64x64\" alt=\"图片\"></p><pre><code class=\"language-plain\">Decoded Image @ step 25\n</code></pre><p><img src=\"https://static001.geekbang.org/resource/image/e3/37/e3de66377a02e3db266ced384de8b337.png?wh=512x512\" alt=\"图片\"></p><p>运行完程序，你就可以看到我们的图片是如何一步步从完全的噪点还原成一张图片的了。而且你仔细观察，还可以看到Generation生成的图像信息，类似于Decoder还原出来的图像信息的轮廓。这是因为U-Net其实是一个图片语义分割的模型。</p><p>而如果我们打印一下生成的图片的维度，你也可以看到，Generation生成的图像信息分辨率只有64x64，而我们还原出来的图片分辨率是512x512。</p><pre><code class=\"language-plain\">print(latents.shape)\nlatents = 1 / 0.18215 * latents\nwith torch.no_grad():\n    image = vae.decode(latents).sample\n    print(image.shape)\n</code></pre><p>输出结果：</p><pre><code class=\"language-plain\">torch.Size([1, 4, 64, 64])\ntorch.Size([1, 3, 512, 512])\n</code></pre><h3>图生图</h3><p>相信你已经理解了这个Stable Diffusion生成图片的过程，以及过程里每个模块的工作了。那你应该比较容易理解如何通过Stable Diffusion实现图生图了，我们下面就来具体看一看。</p><p>当然，这一次我们就不用自己一步步调用各个模块来实现图生图了。我们可以直接使用Diffusers库里自带的Pipeline。</p><pre><code class=\"language-plain\">import torch\nfrom PIL import Image\nfrom io import BytesIO\n\nfrom diffusers import StableDiffusionImg2ImgPipeline\n\ndevice = \"cuda\"\nmodel_id_or_path = \"runwayml/stable-diffusion-v1-5\"\npipe = StableDiffusionImg2ImgPipeline.from_pretrained(model_id_or_path, torch_dtype=torch.float16)\npipe = pipe.to(device)\n\nimage_file = \"./data/sketch-mountains-input.jpg\"\n\ninit_image = Image.open(image_file).convert(\"RGB\")\ninit_image = init_image.resize((768, 512))\n\nprompt = \"A fantasy landscape, trending on artstation\"\n\nimages = pipe(prompt=prompt, image=init_image, strength=0.75, guidance_scale=7.5).images\n\ndisplay(init_image)\ndisplay(images[0])\n</code></pre><p>输出结果：<br>\n<img src=\"https://static001.geekbang.org/resource/image/d2/2c/d262d17cb96yyd721eeca30c70e40c2c.png?wh=768x512\" alt=\"图片\"></p><p><img src=\"https://static001.geekbang.org/resource/image/71/e4/712c084e85b258ceeb2ca64c8d043fe4.png?wh=768x512\" alt=\"图片\"></p><p>对应的代码也非常简单，我们把Pipeline换成了StableDiffusionImg2ImgPipeline，此外除了输入一段文本之外，我们还提供了一张草稿图。然后，你可以看到对应生成的图片的轮廓，就类似于我们提供的草稿图。而图片的内容风格，则是按照我们文本提示语的内容生成的。</p><p>StableDiffusionImg2ImgPipeline的生成过程，其实和我们之前拆解的一步步生成图片的过程是相同的。<strong>唯一的一个区别是，我们其实不是从一个完全随机的噪声开始的，而是把对应的草稿图，通过VAE的编码器，变成图像生成信息，又在上面加了随机的噪声。</strong>所以，去除噪音的过程中，对应的草稿图的轮廓就会逐步出现了。而在一步步生成图片的过程中，内容又会向我们给出的提示语的内容来学习。</p><p>而如果我们换一下提示语，就能更改生成的具体内容。比如我们想换成宫崎骏的风格，并且希望后面高耸的不是山，而是城堡，出现的图片还是相同的轮廓，但是用不同的内容。我在下面给出了一个代码示例，你可以自己看一看。</p><pre><code class=\"language-plain\">prompt = \"ghibli style, a fantasy landscape with castles\"\nimages = pipe(prompt=prompt, image=init_image, strength=0.75, guidance_scale=7.5).images\n\ndisplay(init_image)\ndisplay(images[0])\n</code></pre><p>输出结果：<br>\n<img src=\"https://static001.geekbang.org/resource/image/bb/ff/bb7a09c91feda214ee71a57d3ab479ff.png?wh=768x512\" alt=\"图片\"></p><p><img src=\"https://static001.geekbang.org/resource/image/b8/de/b8c0054e8abc08a5657f8a6f9c6afede.png?wh=768x512\" alt=\"图片\"></p><h3>更多使用方法</h3><p>理解了Stable Diffusion的基本框架，你可以试一试更多相关的Pipeline的用法。比如，除了引导内容生成的提示语，我们还可以设置一个负面的提示语（negative prompt），也就是排除一些内容。</p><pre><code class=\"language-plain\">prompt = \"ghibli style, a fantasy landscape with castles\"\nnegative_prompt = \"river\"\nimages = pipe(prompt=prompt, negative_prompt=negative_prompt, image=init_image, strength=0.75, guidance_scale=7.5).images\n\ndisplay(images[0])\n</code></pre><p>输出结果：<br>\n<img src=\"https://static001.geekbang.org/resource/image/2b/1c/2b9ce1b91e306d256fc29dc13d68d51c.png?wh=768x512\" alt=\"图片\"></p><p>可以看到，我们希望在图片里面尽量排除“River”。而新生成的图片，右边就没有了任何类似于河流的内容，而中间蓝色的部分也更像一个排水渠而不是自然的河流。负面提示语并不会改变模型的结构。它其实就是把原先的“无条件”向量，替换成了负面提示语的向量。这样，模型就尽可能从负面的提示语文本内容中向我们正面的提示语文本内容学习，也就是尽量远离负面提示语的内容。</p><p>同样，我们还可以通过Stable Diffusion来提升图片的分辨率，只不过需要一个单独的模型。这个模型就是专门在一个高低分辨率的图片组合上训练出来的。对应的UNet和VAE的模型是和原始的Stable Diffusion不一样的。</p><pre><code class=\"language-plain\">from diffusers import StableDiffusionUpscalePipeline\n\n# load model and scheduler\nmodel_id = \"stabilityai/stable-diffusion-x4-upscaler\"\npipeline = StableDiffusionUpscalePipeline.from_pretrained(\n    model_id, revision=\"fp16\", torch_dtype=torch.float16\n)\npipeline = pipeline.to(\"cuda\")\n\n# let's download an  image\nlow_res_img_file = \"./data/low_res_cat.png\"\nlow_res_img = Image.open(low_res_img_file).convert(\"RGB\")\nlow_res_img = low_res_img.resize((128, 128))\n\nprompt = \"a white cat\"\n\nupscaled_image = pipeline(prompt=prompt, image=low_res_img).images[0]\n\nlow_res_img_resized = low_res_img.resize((512, 512))\n\ndisplay(low_res_img_resized)\ndisplay(upscaled_image)\n</code></pre><p>输出结果：<br>\n<img src=\"https://static001.geekbang.org/resource/image/f4/c4/f47e50c28203eb7a0d8f7667f69023c4.png?wh=512x512\" alt=\"图片\"></p><p><img src=\"https://static001.geekbang.org/resource/image/2b/b6/2be70a657f415b11489afa86639faeb6.png?wh=512x512\" alt=\"图片\"></p><p>如果我们打印一下pipeline，对应的模型的组件还是相同的。</p><pre><code class=\"language-plain\">pipeline\n</code></pre><p>输出结果：</p><pre><code class=\"language-plain\">StableDiffusionUpscalePipeline {\n  \"_class_name\": \"StableDiffusionUpscalePipeline\",\n  \"_diffusers_version\": \"0.15.1\",\n  \"low_res_scheduler\": [\n    \"diffusers\",\n    \"DDPMScheduler\"\n  ],\n  \"max_noise_level\": 350,\n  \"scheduler\": [\n    \"diffusers\",\n    \"DDIMScheduler\"\n  ],\n  \"text_encoder\": [\n    \"transformers\",\n    \"CLIPTextModel\"\n  ],\n  \"tokenizer\": [\n    \"transformers\",\n    \"CLIPTokenizer\"\n  ],\n  \"unet\": [\n    \"diffusers\",\n    \"UNet2DConditionModel\"\n  ],\n  \"vae\": [\n    \"diffusers\",\n    \"AutoencoderKL\"\n  ]\n}\n</code></pre><p>但是如果你去看对应模型的配置文件，可以看到 <a href=\"https://huggingface.co/stabilityai/stable-diffusion-x4-upscaler/blob/main/vae/config.json\">VAE</a> 和 <a href=\"https://huggingface.co/stabilityai/stable-diffusion-x4-upscaler/blob/main/unet/config.json\">UNet</a> 里使用的模型都是不一样的。</p><h2>使用社区里的其他模型</h2><p>在这个过程中，你可以看到Stable Diffusion并不是指某一个特定的模型，而是指一类模型结构。因为Stable Diffusion是完全开源的，所以你大可以利用自己的数据去训练一个属于自己的模型。事实上，市面上开源训练出来的Stable Diffusion的模型非常多，也已经有了像 <a href=\"https://civitai.com/\">CIVITAI</a> 这样的分享Stable Diffusion模型的平台。</p><p><img src=\"https://static001.geekbang.org/resource/image/a1/4d/a119771cc79yyf74d283a195c663c04d.png?wh=1240x1213\" alt=\"图片\" title=\"CIVITAI 里有用户们自己训练的各种风格的模型\"></p><p>我们可以去CIVITAI的网站，找到我们喜欢的模型。比如我们专门找一个二次元的模型 <a href=\"https://civitai.com/models/4468/counterfeit-v25\">counterfeit-V2.5</a>。在对应的模型页面，我们可以看到它直接就包含了Huggingface里面的模型。</p><p><img src=\"https://static001.geekbang.org/resource/image/2c/15/2cd2d729e7ac70e0f829c319d85a1715.png?wh=1240x730\" alt=\"图片\"></p><p>所以我们就可以直接通过Diffuers库来调用这个模型。</p><pre><code class=\"language-plain\">pipeline.to(\"cuda\")\n\nprompt = \"((masterpiece,best quality)),1girl, solo, animal ears, rabbit, barefoot, knees up, dress, sitting, rabbit ears, short sleeves, looking at viewer, grass, short hair, smile, white hair, puffy sleeves, outdoors, puffy short sleeves, bangs, on ground, full body, animal, white dress, sunlight, brown eyes, dappled sunlight, day, depth of field\"\nnegative_prompt = \"EasyNegative, extra fingers,fewer fingers,\"\nimage = pipeline(prompt=prompt, negative_prompt=negative_prompt).images[0]\nimage\n</code></pre><p>输出结果：</p><p><img src=\"https://static001.geekbang.org/resource/image/03/50/03041115b93c8d53ed71fd2ff7fcf750.png?wh=512x512\" alt=\"图片\"></p><p>当然，不是所有CIVITAI里的模型都在Huggingface上提供了自己的模型版本。默认CIVITAI的模型，往往只是提供了一个模型权重文件。你可以使用现在最流行的 <a href=\"https://github.com/AUTOMATIC1111/stable-diffusion-webui\">Stable-Diffusion-Web-UI 应用</a>来使用这个模型权重文件。你可以把Web-UI在本地部署起来，它会提供一个图形界面让你不用写代码就可以直接调整各种参数来生成图片。</p><p><img src=\"https://static001.geekbang.org/resource/image/61/1d/616244d69ed59bb3e8935ec7fbfba91d.png?wh=1236x966\" alt=\"图片\" title=\"来自 stable-diffusion-web-ui 的图形界面\"></p><p><a href=\"https://github.com/civitai/civitai/wiki\">CIVITAI 的 Wiki</a> 里面也详细提供了在Stable-Diffusion-Web-UI里面使用模型的步骤，你可以照着这个步骤多拿几个模型试试看。</p><h2>小结</h2><p>好了，这就是今天的主要内容，最后我们一起来回顾一下。</p><p>这一讲，我带着你体验了一下Stable Diffusion这个图片生成的开源模型。我们不仅通过Diffusers这个封装好的Python库，体验了文生图、图生图、提升图片分辨率等一系列应用，也深入到Stable Diffusion的模型内部，理解了整个模型的结构，还看到我们是如何一步步从一张全是噪点的图片，逐渐去除噪声变成一张可用的图片的。</p><p>在体验了基础的模型之后，我们也一起尝试了一下其他爱好者自己生成的模型。这也是下一讲我们要介绍的重点内容。我们会了解到如何通过 LoRa 这样的算法进行模型微调，以及如何通过ControlNet让我们生成的图片更加可控。</p><h2>思考题</h2><p>最后，按照惯例还是给你留一道思考题。除了今天给你演示的这些应用之外，HuggingFace还提供了很多实战场景。比如，你就可以通过 <a href=\"https://huggingface.co/docs/diffusers/using-diffusers/inpaint\">StableDiffusionInpaintPipeline</a>，用一个遮照图片和一段提示语来修改图片画面中的某一部分元素。</p><p>你可以照着<a href=\"https://huggingface.co/docs/diffusers/using-diffusers/inpaint\">官方文档</a>，体验一下这个功能，研究一下源代码，想想这个功能是如何通过Stable Diffusion的模型结构实现的。欢迎你把你体验之后的感受以及思考后的结果分享在评论区，也欢迎你把这一讲分享给感兴趣的朋友，我们下一讲再见！</p><h2>推荐阅读</h2><p>这一讲里，我们只是简单介绍了一下Stable Diffusion的模型结构。其实，无论是DALL-E 2还是Imagen，采用的图片生成方式都是和Stable Diffusion类似的。如果你想要深入了解一下这些模型的结构，可以去看一下B站里面“跟李沐学AI”里面对于 <a href=\"https://www.bilibili.com/video/BV17r4y1u77B/?spm_id_from=333.999.0.0\">DALL-E 2 论文的讲解</a>。</p>","neighbors":{"left":{"article_title":"23｜OpenClip：让我们搞清楚图片说了些什么","id":653489},"right":{"article_title":"25｜ControlNet：让你的图拥有一个“骨架”","id":655496}},"comments":[{"had_liked":false,"id":373857,"user_name":"东方奇骥","can_delete":false,"product_type":"c1","uid":1354850,"ip_address":"四川","ucode":"DEE7085F7E55A4","user_header":"https://static001.geekbang.org/account/avatar/00/14/ac/62/37912d51.jpg","comment_is_top":false,"comment_ctime":1683267308,"is_pvip":false,"replies":[{"id":136856,"content":"来自GPT-4的回答：\n\n“Stable Diffusion是一种生成模型，它通过在数据上加入噪声，并在随后的步骤中逐渐减少这种噪声，来生成新的数据样本。这种方法的灵感来自物理学中的扩散过程，这就是它的名称中包含&quot;Diffusion&quot;的原因。扩散过程通常涉及到随机性和梯度下降，它们都在Stable Diffusion模型中找到了体现。\n\n现在我们来看为什么这样做：\n\n保留原有数据的复杂性：直接从原始数据生成新的数据样本可能非常困难，因为原始数据的复杂性和多样性。通过在数据上加入噪声，我们可以让模型从一个相对简单的分布（如高斯噪声分布）开始工作，然后逐渐通过减少噪声，使得新的数据样本逐渐接近于原始数据的复杂分布。\n\n使模型更健壮：在训练过程中添加和减少噪声可以作为一种正则化技术，帮助防止模型过拟合。它强迫模型在不同的噪声级别下都能正确地进行预测，从而提高模型的泛化能力。\n\n反向生成：噪声的逐渐减少实际上是对数据生成过程的逆向模拟。这意味着，我们不仅可以从原始数据生成新的数据样本，而且还可以反过来，从新的数据样本反推其可能的原始数据。\n\n这就是为什么Stable Diffusion模型会首先在数据上加入噪声，然后逐渐减少噪声的原因。这种方法可以帮助模型更好地理解和复现原始数据的复杂性和多样性。”","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1684749920,"ip_address":"上海","comment_id":373857,"utype":1}],"discussion_count":3,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"老师，为什么要加了噪声，再去除噪声？","like_count":9,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":619036,"discussion_content":"来自GPT-4的回答：\n\n“Stable Diffusion是一种生成模型，它通过在数据上加入噪声，并在随后的步骤中逐渐减少这种噪声，来生成新的数据样本。这种方法的灵感来自物理学中的扩散过程，这就是它的名称中包含&#34;Diffusion&#34;的原因。扩散过程通常涉及到随机性和梯度下降，它们都在Stable Diffusion模型中找到了体现。\n\n现在我们来看为什么这样做：\n\n保留原有数据的复杂性：直接从原始数据生成新的数据样本可能非常困难，因为原始数据的复杂性和多样性。通过在数据上加入噪声，我们可以让模型从一个相对简单的分布（如高斯噪声分布）开始工作，然后逐渐通过减少噪声，使得新的数据样本逐渐接近于原始数据的复杂分布。\n\n使模型更健壮：在训练过程中添加和减少噪声可以作为一种正则化技术，帮助防止模型过拟合。它强迫模型在不同的噪声级别下都能正确地进行预测，从而提高模型的泛化能力。\n\n反向生成：噪声的逐渐减少实际上是对数据生成过程的逆向模拟。这意味着，我们不仅可以从原始数据生成新的数据样本，而且还可以反过来，从新的数据样本反推其可能的原始数据。\n\n这就是为什么Stable Diffusion模型会首先在数据上加入噪声，然后逐渐减少噪声的原因。这种方法可以帮助模型更好地理解和复现原始数据的复杂性和多样性。”","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684749920,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1953765,"avatar":"","nickname":"Geek_d54869","note":"","ucode":"CF55462EF65B9E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":649233,"discussion_content":"加噪的过程，可以理解为模型学习在不同噪声强度扰动下图片的特征信息，以便能准确还原出图片内容，增强模型的理解力和鲁棒性。而生成过程，则是基于学习成果一步步去噪，并且注入prompt文本语义信息，让图片与prompt更吻合。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1723018055,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1253652,"avatar":"https://static001.geekbang.org/account/avatar/00/13/21/14/423a821f.jpg","nickname":"Steven","note":"","ucode":"3FE64459842015","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":617375,"discussion_content":"训练吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683534426,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"辽宁","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":373957,"user_name":"peter","can_delete":false,"product_type":"c1","uid":1058183,"ip_address":"北京","ucode":"261C3FC001DE2D","user_header":"https://static001.geekbang.org/account/avatar/00/10/25/87/f3a69d1b.jpg","comment_is_top":false,"comment_ctime":1683379403,"is_pvip":false,"replies":[{"id":136855,"content":"1. Stable Diffusion用了多个模型组合啊。其中输入的Prompt转换成向量直接用的CLIP模型\n2. 这个是训练过程，可以理解为通过增加噪声和模型训练，我们就学会了怎么从一个随机噪声的信息复原出一张图片的能力。\n3. 如果有GPU，本机可以运行，不然建议使用Colab的在线GPU环境\n4. 可以啊，可以看看后面的VisualChatGPT\n3， ","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1684749793,"ip_address":"上海","comment_id":373957,"utype":1}],"discussion_count":5,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"请教老师几个问题：\nQ1：stable Diffusion采用的CLIP是自身的吗？还是调用chatGPT？\nQ2：先加噪声，再去掉，有什么意义？吃一口再吐一口，有意思吗？\n“先往前面的用 CLIP 模型推理出来的向量里添加很多噪声，再通过 UNet+Scheduler 逐渐去除噪声，最后拿到了一个新的张量”。\nQ3：本课的代码是在本机上运行的吗？我的笔记本上是普通配置，能运行并生成图吗？（或者，图的生成是调用了某个服务器？）\nQ4：可以对图片进行加工吗？ 比如在一个照片的头上加一个帽子。","like_count":2,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":619035,"discussion_content":"1. Stable Diffusion用了多个模型组合啊。其中输入的Prompt转换成向量直接用的CLIP模型\n2. 这个是训练过程，可以理解为通过增加噪声和模型训练，我们就学会了怎么从一个随机噪声的信息复原出一张图片的能力。\n3. 如果有GPU，本机可以运行，不然建议使用Colab的在线GPU环境\n4. 可以啊，可以看看后面的VisualChatGPT\n3， ","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684749793,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1514261,"avatar":"https://static001.geekbang.org/account/avatar/00/17/1b/15/75c16cb5.jpg","nickname":"朱朱","note":"","ucode":"889FBF262D5DDD","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":618644,"discussion_content":"Q1: CLIP 是一个开源模型，这里当然不会和 GPT 有关系；\nQ2: 加噪声和去除噪声的目的为了让模型能在很复杂的环境下（可以去看下高斯噪声，可以理解为把图片撕碎丢掉很多碎片但是还要让模型能认识）识别图片，从而加大预测图片的准确性;\nQ3: 最好是用 Colab，不推荐用个人机器，需要看你的显卡配置能不能达到要求；\nQ4：当然可以，类似于把模糊图片做高清是一样的道理","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1684403970,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2397945,"avatar":"https://static001.geekbang.org/account/avatar/00/24/96/f9/e52955e1.jpg","nickname":"吴亮","note":"","ucode":"CEB3995975654C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":618443,"discussion_content":"是2个完全不同的系统","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684244078,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2397945,"avatar":"https://static001.geekbang.org/account/avatar/00/24/96/f9/e52955e1.jpg","nickname":"吴亮","note":"","ucode":"CEB3995975654C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":618440,"discussion_content":"是2个完全不同的系统","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684243156,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2397945,"avatar":"https://static001.geekbang.org/account/avatar/00/24/96/f9/e52955e1.jpg","nickname":"吴亮","note":"","ucode":"CEB3995975654C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":618439,"discussion_content":"chatgpt和stable diffution ","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684243117,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":374168,"user_name":"一叶","can_delete":false,"product_type":"c1","uid":3577168,"ip_address":"福建","ucode":"21E5455D0814E5","user_header":"https://static001.geekbang.org/account/avatar/00/36/95/50/01199ae9.jpg","comment_is_top":false,"comment_ctime":1683676099,"is_pvip":false,"replies":[{"id":136858,"content":"找找看国内是否有镜像？以前清华有","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1684752175,"ip_address":"上海","comment_id":374168,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"老师 如何 手动把模型下载,然后再上传到服务器 ? 我服务器本地liunx的,发现下载很慢..... DiffusionPipeline.from_pretrained","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":619041,"discussion_content":"找找看国内是否有镜像？以前清华有","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684752175,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1082338,"avatar":"https://static001.geekbang.org/account/avatar/00/10/83/e2/297518ab.jpg","nickname":"佳佳的爸","note":"","ucode":"9D4FE7C3552087","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":638149,"discussion_content":"huggingface将所有下载的模型都缓存在 $HOME/.cache\\huggingface/hub目录下，如果在windows运行，目录是c:\\windows\\%当前登陆的用户名%\\.cache\\huggingface\\hub,  可以去HF官网先搜索到对应的模型文件，下载到这个缓存目录。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1709280238,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":374074,"user_name":"厚积薄发","can_delete":false,"product_type":"c1","uid":1206674,"ip_address":"北京","ucode":"8640C07176C249","user_header":"https://static001.geekbang.org/account/avatar/00/12/69/92/69c2c135.jpg","comment_is_top":false,"comment_ctime":1683556549,"is_pvip":false,"replies":[{"id":136874,"content":"课程里单个任务Colab里T4的16GB内存应该是够的。\n\n当然如果你需要别的模型，GPU显存不够就需要更大显存的GPU甚至多卡了。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1684753863,"ip_address":"上海","comment_id":374074,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB \nalready allocated; 10.81 MiB free; 13.46 GiB reserved in total by PyTorch) If reserved memory is &gt;&gt; allocated \nmemory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \nPYTORCH_CUDA_ALLOC_CONF   老师，colab gpu不够了，默认的16g不够，是不是需要购买更大的gpu","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":619063,"discussion_content":"课程里单个任务Colab里T4的16GB内存应该是够的。\n\n当然如果你需要别的模型，GPU显存不够就需要更大显存的GPU甚至多卡了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684753863,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1481283,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJcEKI64IovCBe0XvmatsRjRI3AYdBzicjqHHWsDXb5vAG0V4rgg2Gv6XRFOfD6lMhDN9Eud6bRTqw/132","nickname":"Geek_71a740","note":"","ucode":"ABBE2C9927301C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":619478,"discussion_content":"内存不够可以试试DiffusionPipeline.from_pretrained(&#34;./stable-diffusion-v1-5/&#34;,torch_dtype=torch.float16)","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1685160217,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":373903,"user_name":"Oli张帆","can_delete":false,"product_type":"c1","uid":1338098,"ip_address":"北京","ucode":"6E60A370C3C14A","user_header":"https://static001.geekbang.org/account/avatar/00/14/6a/f2/db90fa96.jpg","comment_is_top":false,"comment_ctime":1683329696,"is_pvip":false,"replies":[{"id":136841,"content":"如果是有人部署了一个付费的space然后开放出来让大家用，那就是部署的人买单\n如果是HF官方提供的Space或者Inference API，就是HF官方给钱\n\n并没有那么多免费的算力可以用，免费开放的GPU资源很少的，最多让你试一下API，大家排队慢慢用而已","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1684748557,"ip_address":"上海","comment_id":373903,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"请教一下老师，结合您之前讲的HuggingFace，我可以通过HuggingFace，免费调用Stable Diffusion的接口，来产生大量的图片。那这整个流程中需要的大量算力，是谁来买单的呢？","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":619019,"discussion_content":"如果是有人部署了一个付费的space然后开放出来让大家用，那就是部署的人买单\n如果是HF官方提供的Space或者Inference API，就是HF官方给钱\n\n并没有那么多免费的算力可以用，免费开放的GPU资源很少的，最多让你试一下API，大家排队慢慢用而已","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684748557,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1066542,"avatar":"https://static001.geekbang.org/account/avatar/00/10/46/2e/c5827ea5.jpg","nickname":"initlife","note":"","ucode":"6F0E2D9B0EAEBC","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":617234,"discussion_content":"如果是你的本机就是你的电脑买单，如果是colab，就是用云算力，可能要付费","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683389651,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":373885,"user_name":"Toni","can_delete":false,"product_type":"c1","uid":3206957,"ip_address":"瑞士","ucode":"E6B2FACCC1E000","user_header":"https://static001.geekbang.org/account/avatar/00/30/ef/2d/757bb0d3.jpg","comment_is_top":false,"comment_ctime":1683288324,"is_pvip":false,"replies":[{"id":136828,"content":"👍","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1684741749,"ip_address":"上海","comment_id":373885,"utype":1}],"discussion_count":10,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"1. 使用 GPU 无疑会加快图像的生成，但实在没有办法使用 GPU 时，就用 CPU，只要将下面代码中的 &quot;cuda&quot; 改成 &quot;cpu&quot; 即可，慢比没有强。\n\npipeline.to(&quot;cuda&quot;) =&gt; pipeline.to(&quot;cpu&quot;) \n---------------------\nfrom diffusers import DiffusionPipeline\npipeline = DiffusionPipeline.from_pretrained(&quot;runwayml&#47;stable-diffusion-v1-5&quot;)\npipeline.to(&quot;cpu&quot;)\n\nimage = pipeline(&quot;Sports car, road, rural areas, blue sky, white clouds, endless grassland in the background&quot;).images[0]\nimage\n\n--------------\n生成上面的图在 cpu 条件下约10分钟。\n\n2. 描述图像的 prompt 如果太长会报错， 比如\nToken indices sequence length is longer than the specified maximum sequence length for this model (161 &gt; 77). \n\n程序会继续运行，但输出结果是黑板。\nPotential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and&#47;or seed.\n\nprompt 中的 Token 数超过限定时，要停止运行，以节省时间。","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":618995,"discussion_content":"👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684741749,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1253652,"avatar":"https://static001.geekbang.org/account/avatar/00/13/21/14/423a821f.jpg","nickname":"Steven","note":"","ucode":"3FE64459842015","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":617137,"discussion_content":"老机器 710显卡跑不起来，用 CPU 跑生成一次快 20 分钟了  :(","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1683340750,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"辽宁","group_id":0},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":3206957,"avatar":"https://static001.geekbang.org/account/avatar/00/30/ef/2d/757bb0d3.jpg","nickname":"Toni","note":"","ucode":"E6B2FACCC1E000","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1253652,"avatar":"https://static001.geekbang.org/account/avatar/00/13/21/14/423a821f.jpg","nickname":"Steven","note":"","ucode":"3FE64459842015","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":618415,"discussion_content":"搭建 Automatic1111 ，在其上用 CPU，生成 512x512 的图约七，八分钟，可以一试。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684234398,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":617137,"ip_address":"瑞士","group_id":0},"score":618415,"extra":""}]},{"author":{"id":3206957,"avatar":"https://static001.geekbang.org/account/avatar/00/30/ef/2d/757bb0d3.jpg","nickname":"Toni","note":"","ucode":"E6B2FACCC1E000","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":617209,"discussion_content":"@白菜: 是在 jupyter-lab 还是在 colab 上? 最后一行代码是什么?","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683381364,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"瑞士","group_id":0},"score":2,"extra":"","child_discussion_number":5,"child_discussions":[{"author":{"id":2230467,"avatar":"https://static001.geekbang.org/account/avatar/00/22/08/c3/bf4fe285.jpg","nickname":"白菜","note":"","ucode":"C3AE527ECE970E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":3206957,"avatar":"https://static001.geekbang.org/account/avatar/00/30/ef/2d/757bb0d3.jpg","nickname":"Toni","note":"","ucode":"E6B2FACCC1E000","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":617265,"discussion_content":"我是在自己机器上运行的，iterm2","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683441299,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":617209,"ip_address":"北京","group_id":0},"score":617265,"extra":""},{"author":{"id":2230467,"avatar":"https://static001.geekbang.org/account/avatar/00/22/08/c3/bf4fe285.jpg","nickname":"白菜","note":"","ucode":"C3AE527ECE970E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":3206957,"avatar":"https://static001.geekbang.org/account/avatar/00/30/ef/2d/757bb0d3.jpg","nickname":"Toni","note":"","ucode":"E6B2FACCC1E000","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":617266,"discussion_content":"from diffusers import DiffusionPipeline\npipeline = DiffusionPipeline.from_pretrained(&#34;runwayml/stable-diffusion-v1-5&#34;)\npipeline.to(&#34;cpu&#34;)\n\nimage = pipeline(&#34;Sports car, road, rural areas, blue sky, white clouds, endless grassland in the background&#34;).images[0]\nimage","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683441331,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":617209,"ip_address":"北京","group_id":0},"score":617266,"extra":""},{"author":{"id":3206957,"avatar":"https://static001.geekbang.org/account/avatar/00/30/ef/2d/757bb0d3.jpg","nickname":"Toni","note":"","ucode":"E6B2FACCC1E000","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2230467,"avatar":"https://static001.geekbang.org/account/avatar/00/22/08/c3/bf4fe285.jpg","nickname":"白菜","note":"","ucode":"C3AE527ECE970E","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":617284,"discussion_content":"在 jupyter-lab 或 colab 上运行上面代码时，最后一行的 image 就是将上一行的 image = pipeline(...).images[0] 刚形成的图像显示出来。我使用的是Windows 11。\n在 iTerm2 上显示图像，有不同的方法，试试将最后一行的 image 改成 image.show()。Windows 下这将打开图片浏览器窗口，显示图像。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1683460383,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":617266,"ip_address":"瑞士","group_id":0},"score":617284,"extra":""}]},{"author":{"id":2230467,"avatar":"https://static001.geekbang.org/account/avatar/00/22/08/c3/bf4fe285.jpg","nickname":"白菜","note":"","ucode":"C3AE527ECE970E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":617192,"discussion_content":"这个图片输出到哪了？我是在命令行里运行的，命令行不能显示图片啊，也没有地方输出图片，是我运行的方式不对吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683371827,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":373870,"user_name":"Jack","can_delete":false,"product_type":"c1","uid":1297112,"ip_address":"广东","ucode":"F3863DAEF449D5","user_header":"https://static001.geekbang.org/account/avatar/00/13/ca/d8/b109ed85.jpg","comment_is_top":false,"comment_ctime":1683275969,"is_pvip":false,"replies":[{"id":136829,"content":"可以多试试使用不同的随机数seed，不同随机数的差别很大，我也是挑了一个好看的放出来。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1684741785,"ip_address":"上海","comment_id":373870,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"第一次运行“a photograph of an astronaut riding a horse”，只有马，没有宇航员，多运行几次就有了，不过图片没有老师的好看","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":618996,"discussion_content":"可以多试试使用不同的随机数seed，不同随机数的差别很大，我也是挑了一个好看的放出来。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684741785,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1253652,"avatar":"https://static001.geekbang.org/account/avatar/00/13/21/14/423a821f.jpg","nickname":"Steven","note":"","ucode":"3FE64459842015","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":617136,"discussion_content":"我第一次运行，只有宇航员，没有马","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683340637,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"辽宁","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":373854,"user_name":"Jacob.C","can_delete":false,"product_type":"c1","uid":1070253,"ip_address":"广东","ucode":"034998E7A7CCD1","user_header":"https://static001.geekbang.org/account/avatar/00/10/54/ad/6ee2b7cb.jpg","comment_is_top":false,"comment_ctime":1683264138,"is_pvip":false,"replies":[{"id":136830,"content":"Colab下用GPU T4跑，一般在5-20秒之间吧。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1684741846,"ip_address":"上海","comment_id":373854,"utype":1}],"discussion_count":3,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"老师可以讲一下，colab 上，跑这个太空人骑马要运行耗时多久吗？","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":618997,"discussion_content":"Colab下用GPU T4跑，一般在5-20秒之间吧。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684741846,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1430132,"avatar":"https://static001.geekbang.org/account/avatar/00/15/d2/74/7861f504.jpg","nickname":"马听","note":"","ucode":"93D83CB5FAE5AD","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":617158,"discussion_content":"我尝试的是20多秒","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1683355330,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3617247,"avatar":"https://static001.geekbang.org/account/avatar/00/37/31/df/caace193.jpg","nickname":"陈波","note":"","ucode":"D8881782CED835","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":617389,"discussion_content":"跑一下就知道了，很快","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683538366,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"四川","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":373840,"user_name":"Geek_7ee455","can_delete":false,"product_type":"c1","uid":1527581,"ip_address":"浙江","ucode":"76C69F26B0F653","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/270T9KAFd4oCxXXB1giaMDaJuTQVib8gPt77VkM5dbS3hW60kwTNnxMYpVibwWVdnASCrymBbwT7HI77URia0KUylw/132","comment_is_top":false,"comment_ctime":1683254374,"is_pvip":false,"replies":[{"id":136826,"content":"可以啊，如果是新的M1&#47;M2芯片的Mac的话，Intel CPU的因为显卡的原因不确定行不行。\n\nApple官方给了解决方案 https:&#47;&#47;huggingface.co&#47;docs&#47;diffusers&#47;optimization&#47;mps","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1684741720,"ip_address":"上海","comment_id":373840,"utype":1}],"discussion_count":4,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"老师,在mac上能自己部署一套stable diffusion吗","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":618993,"discussion_content":"可以啊，如果是新的M1/M2芯片的Mac的话，Intel CPU的因为显卡的原因不确定行不行。\n\nApple官方给了解决方案 https://huggingface.co/docs/diffusers/optimization/mps","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684741720,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1248128,"avatar":"https://static001.geekbang.org/account/avatar/00/13/0b/80/a0533acb.jpg","nickname":"勇.Max","note":"","ucode":"AE5DBC10805A9B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":619130,"discussion_content":"我用老师推荐的示例代码在colab上还是跑不起来，apple m1芯片。RuntimeError: PyTorch is not linked with support for mps devices，在chatgpt搜解决方案推荐!pip install --upgrade torch torchvision，执行完之后依然不行。 这个还有什么解决方案吗？colab如果不花钱也是用的本地资源？那在colab运行代码和在本地jupyter-lab上运行有何区别呢？\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684810881,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"澳大利亚","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1231908,"avatar":"https://static001.geekbang.org/account/avatar/00/12/cc/24/8988304f.jpg","nickname":"方维","note":"","ucode":"0E50A1BECD1746","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":617064,"discussion_content":"能，我最近跑起来了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683287711,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1520703,"avatar":"https://static001.geekbang.org/account/avatar/00/17/34/3f/4b6cd370.jpg","nickname":"Viktor","note":"","ucode":"DCAFD1DD5C6A0C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1231908,"avatar":"https://static001.geekbang.org/account/avatar/00/12/cc/24/8988304f.jpg","nickname":"方维","note":"","ucode":"0E50A1BECD1746","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":617122,"discussion_content":"运行快不快？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683334897,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":617064,"ip_address":"四川","group_id":0},"score":617122,"extra":""}]}]},{"had_liked":false,"id":375577,"user_name":"莹","can_delete":false,"product_type":"c1","uid":1020356,"ip_address":"美国","ucode":"395C6C4191B091","user_header":"https://static001.geekbang.org/account/avatar/00/0f/91/c4/40609b81.jpg","comment_is_top":false,"comment_ctime":1685682482,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"直接新建一个colab notebook后默认不是用的GPU，运行代码出错了&quot;RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http:&#47;&#47;www.nvidia.com&#47;Download&#47;index.aspx&quot;\n\n遇到同样错误的小伙伴记得在Runtime菜单里选择Change runtime type，选择GPU, T4。我遇到了在运行也不成功的情况，这时可以再在Runtime菜单里选择Restart runtime或者Restart and run all。这样，我遇到的错误就解决了。","like_count":1},{"had_liked":false,"id":387233,"user_name":"Amark","can_delete":false,"product_type":"c1","uid":1121326,"ip_address":"陕西","ucode":"E5F48633654002","user_header":"https://static001.geekbang.org/account/avatar/00/11/1c/2e/93812642.jpg","comment_is_top":false,"comment_ctime":1706758440,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"为啥有的图片跟文字不符，文字描述有啥要求吗","like_count":0},{"had_liked":false,"id":384057,"user_name":"小理想。","can_delete":false,"product_type":"c1","uid":2238528,"ip_address":"北京","ucode":"EDC35A907570DB","user_header":"https://static001.geekbang.org/account/avatar/00/22/28/40/82d748e6.jpg","comment_is_top":false,"comment_ctime":1700192537,"is_pvip":false,"replies":null,"discussion_count":2,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"大家没遇到huggingface完全访问不了的情况吗？","like_count":0,"discussions":[{"author":{"id":1082338,"avatar":"https://static001.geekbang.org/account/avatar/00/10/83/e2/297518ab.jpg","nickname":"佳佳的爸","note":"","ucode":"9D4FE7C3552087","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":638147,"discussion_content":"huggingface 在国内访问的话 需要翻墙","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1709279153,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3811644,"avatar":"https://static001.geekbang.org/account/avatar/00/3a/29/3c/5e539b12.jpg","nickname":"深腾","note":"","ucode":"D119FD13BBC2E9","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":635528,"discussion_content":"你现在解决了吗，我想加你问方法","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1704935854,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"福建","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":378445,"user_name":"昵称C","can_delete":false,"product_type":"c1","uid":1234963,"ip_address":"北京","ucode":"1BB2D537942DC2","user_header":"https://static001.geekbang.org/account/avatar/00/12/d8/13/082013bc.jpg","comment_is_top":false,"comment_ctime":1690268935,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"思考题有做出来的吗？老师有答案吗？\n","like_count":0},{"had_liked":false,"id":376596,"user_name":"和某欢","can_delete":false,"product_type":"c1","uid":2120663,"ip_address":"美国","ucode":"5E0F27533597F1","user_header":"https://static001.geekbang.org/account/avatar/00/20/5b/d7/d88c1850.jpg","comment_is_top":false,"comment_ctime":1687058698,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"老师，colab如何引入Counterfeit-V3.0 这个模型呢？示例代码没看懂，运行的时候报 NameError: name &#39;pipeline&#39; is not defined.","like_count":0},{"had_liked":false,"id":375019,"user_name":"勇.Max","can_delete":false,"product_type":"c1","uid":1248128,"ip_address":"澳大利亚","ucode":"AE5DBC10805A9B","user_header":"https://static001.geekbang.org/account/avatar/00/13/0b/80/a0533acb.jpg","comment_is_top":false,"comment_ctime":1684811029,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"请问下老师colab的在线GPU环境是不是跟本地的macos(m1)也有一定关系？不太理解为啥m1跑colab为啥还要修改成cpu的方式","like_count":0},{"had_liked":false,"id":375018,"user_name":"勇.Max","can_delete":false,"product_type":"c1","uid":1248128,"ip_address":"澳大利亚","ucode":"AE5DBC10805A9B","user_header":"https://static001.geekbang.org/account/avatar/00/13/0b/80/a0533acb.jpg","comment_is_top":false,"comment_ctime":1684810916,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"我用老师推荐的示例代码(https:&#47;&#47;huggingface.co&#47;docs&#47;diffusers&#47;optimization&#47;mps)在colab上还是跑不起来，apple m1芯片。RuntimeError: PyTorch is not linked with support for mps devices，在chatgpt搜解决方案推荐!pip install --upgrade torch torchvision，执行完之后依然不行。 这个还有什么解决方案吗？colab如果不花钱也是用的本地资源？那在colab运行代码和在本地jupyter-lab上运行有何区别呢？","like_count":0},{"had_liked":false,"id":373890,"user_name":"piboye","can_delete":false,"product_type":"c1","uid":1066752,"ip_address":"广东","ucode":"7CFD8712857A85","user_header":"https://static001.geekbang.org/account/avatar/00/10/47/00/3202bdf0.jpg","comment_is_top":false,"comment_ctime":1683293696,"is_pvip":true,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"李沐的课程太好了","like_count":0},{"had_liked":false,"id":373835,"user_name":"Santiago","can_delete":false,"product_type":"c1","uid":3572315,"ip_address":"山西","ucode":"E7301F6A5076DC","user_header":"https://static001.geekbang.org/account/avatar/00/36/82/5b/df97e03c.jpg","comment_is_top":false,"comment_ctime":1683247690,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"学习打卡\n","like_count":0}]}