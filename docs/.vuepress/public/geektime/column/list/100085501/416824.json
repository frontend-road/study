{"id":416824,"title":"06 | 聚类分析：如何用RFM给电商用户做价值分组画像？","content":"<p>你好，我是黄佳。欢迎来到零基础实战机器学习。</p><p>在上一讲中，我们从一份互联网电商“易速鲜花”的历史订单数据集中，求出了每一个用户的R、F、M值。你可能会问，从这些值中，我们又能看出什么有价值的信息呢？</p><p>别着急，在这一讲中，我们继续往前走，看看如何从这些枯燥且不容易观察的数据中，得到更为清晰的用户分组画像。通过这节课，我希望你能理解聚类算法的原理和最优化过程，这可以帮你建立起针对问题选择算法的直觉。</p><h1>怎么给用户分组比较合适？</h1><p>这是我们在上节课中得出的用户层级表，表中有每位用户的R、F、M值。</p><p><img src=\"https://static001.geekbang.org/resource/image/13/c2/13bc1375b789e5173ce3016b84a01dc2.png?wh=260x208\" alt=\"\"></p><p>这里，我们希望看看R值、F值和M值的分布情况，以便为用户分组作出指导。代码是接着上一讲的基础上继续构建，我就不全部贴上来了，完整的代码和数据集请你从<a href=\"https://github.com/huangjia2019/geektime/tree/main/%E8%8E%B7%E5%AE%A2%E5%85%B306\">这里</a>下载。</p><pre><code class=\"language-typescript\">df_user['R值'].plot(kind='hist', bins=20, title = '新进度分布直方图') #R值直方图\n</code></pre><pre><code class=\"language-typescript\">df_user.query('F值 &lt; 800')['F值'].plot(kind='hist', bins=50, title = '消费频率分布直方图') #F值直方图\n</code></pre><pre><code class=\"language-typescript\">df_user.query('M值 &lt; 20000')['M值'].plot(kind='hist', bins=50, title = '消费金额分布直方图') #M值直方图\n</code></pre><!-- [[[read_end]]] --><p>分别输出如下结果：</p><p><img src=\"https://static001.geekbang.org/resource/image/ce/0d/ced0dbdyy646yy9ac0963a325ab7ba0d.png?wh=383x262\" alt=\"\"><img src=\"https://static001.geekbang.org/resource/image/14/19/14100de8f515c80181bb703cb9663a19.png?wh=383x262\" alt=\"\"><img src=\"https://static001.geekbang.org/resource/image/0b/d5/0bf0ddf6fb046dd5fd7867f3ee4b99d5.png?wh=383x262\" alt=\"\"></p><p>可以看到，我们求出的R值、F值和M值的覆盖区间都很大。就拿R值来说，有的用户7天前购物，R值为7；有的用户70天前购物，R值为70；还有的用户187天前购物，R值为187。</p><p>那现在问题来了，如果说我们的目标是根据R值把用户分为几个不同的价值组，那么怎么分组比较合适呢？</p><p>其实，这个问题又可以拆分为两个子问题：</p><ol>\n<li>分成多少个组比较好？</li>\n<li>从哪个值到哪个值归为第一组（比如0-30天是一组），从哪个值到哪个值归为第二组（比如30天-70天是一组）？</li>\n</ol><p>对于这两个问题的答案，有人肯定会说，可以凭借经验来人为确定。比如说，把用户分为高、中、低三个组，比如R值为0到50的分为一个组，50到150的分为一组，150天以上的归为一组。</p><p>这样的人为分组似乎也可以，但它存在一些弊端：首先，分组的准确性完全取决于人的经验，如果分得不准，效果就不好。其次，人为分组是静态的，如果用户情况变化了，我们还是用同样的区间来分组，就不是很合适。</p><p>那怎么办呢？我想你已经猜到了，其实该怎么分组，我们说了不算，要数据说了算。所以，要解决这个问题，还是要通过机器学习算法，根据数据的实际情况来动态地确定分组。因为只有这样的模型才是动态的，才能长期投入使用。</p><p>坚定了这一点后，我们考虑一下选什么算法来建立模型。</p><h1>聚类算法中的K-Means算法</h1><p>首先，我们要搞清楚，给用户做分组画像属于监督学习问题，还是无监督学习问题？我们要通过历史订单数据来给用户分组，这是没有任何已知标签可以做参照的，数据集中并没有一个字段指明用户的价值是“高”还是“低”，所以这显然是一个无监督学习问题。</p><p>在无监督学习中，聚类和降维是两种最常见的算法，不过它们应用场景很不一样。聚类我们说过了，主要可以用来做分组；而降维，则是通过数学变换，将原始高维属性空间转变为一个低维“子空间”，它本质上是通过最主要的几个特征维度实现对数据的描述。很显然，我们的问题适合用聚类算法来解决。</p><p>聚类算法可以让机器把数据集中的样本按照特征的性质分组，不过它只是帮我们把数据特征彼此邻近的用户聚成一组（这里的组称为聚类的簇）。而这里说的“特征彼此邻近”，指的这些用户的数据特征在坐标系中有更短的向量空间距离。也就是说，<strong>聚类算法是把空间位置相近的特征数据归为同一组。</strong></p><p><img src=\"https://static001.geekbang.org/resource/image/04/89/04df8ab44fd06507930b312bf3647889.png?wh=287x295\" alt=\"\" title=\"聚类算法把空间位置相近的数据归为同一组\"></p><p>不过，请你注意，聚类算法本身并不知道哪一组用户是高价值，哪一组用户是低价值。分完组之后，我们还要根据机器聚类的结果，人为地给这些用户组贴标签，看看哪一组价值高，哪一组价值低。我这里把这种人为贴标签的过程称为“<strong>聚类后概念化</strong>”。等你学完这节课，就能更清楚我为什么要做“聚类后概念化”了。</p><p>搞清楚问题适合用聚类算法解决还不够，因为聚类的算法可不止一种，我们还要进一步确定采用哪一个算法。这里我直接选用K-Means（K-均值）算法了，因为这个算法不仅简洁，而且效率也高，是我们最常用的聚类算法。像文档归类、欺诈行为检测、用户分组等等这些场景，我们往往都能用到。</p><p>说到这里，你也许很疑惑：在监督学习中，模型都是要依赖于标签才能创建出来，这无监督学习怎么就这么聪明，能在没有标签的情况下自动给数据点分组？下面我就带你探寻其中的奥秘。</p><p>在K-Means算法中，“K”是一个关键。K代表聚类的簇（也就是组）的个数。比如说，我们想把M值作为特征，将用户分成3个簇（即高、中、低三个用户组），那这里的K值就是3，并且需要我们人工指定。</p><p>指定K的数值后，K-Means算法会在数据中随机挑选出K个数据点，作为簇的质心（centroid），这些质心就是未来每一个簇的中心点，算法会根据其它数据点和它的距离来进行聚类。</p><p>挑选出质心后，K-Means算法会遍历每一个数据点，计算它们与每一个质心的距离（比如欧式距离）。数据点离哪个质心近，就跟哪个质心属于一类。</p><p>遍历结束后，每一个质心周围就都聚集了很多数据点，这时候啊，算法会在数据簇中选择更靠近中心的质心，如果原来随机选择的质心不合适，就会让它下岗。</p><p>在整个聚类过程中，为了选择出更好的质心，“挑选质心”和“遍历数据点与质心的距离”会不断重复，直到质心的移动变化很小了，或者说固定不变了，那K-Means算法就可以停止了。</p><p>我用下面的图来帮助你理解质心在聚类过程中逐渐移动到最佳位置，以及簇的形成过程：</p><p><img src=\"https://static001.geekbang.org/resource/image/e9/0b/e9042e10d793c15de377e6d904f7280b.jpg?wh=2284x1165\" alt=\"\" title=\"聚类中心（质心）的移动和簇形成的过程\"></p><p>理解了聚类算法的原理，我们继续来思考一个问题：我们前面说K值需要人工指定，那怎么在算法的辅助下确定K值呢？</p><h1>手肘法选取K值</h1><p>其实，在事先并不是很确定分成多少组比较合适的情况下，“手肘法”（elbow method）可以帮我们决定，在某一批数据点中，数据分为多少组比较合适。这里我要特别说明一下，尽管我们前面说要把用户分为高、中、低三个价值组，但是R、F、M的值却可以分成很多组，并不一定都是3组。</p><p>手肘法是通过聚类算法的损失值曲线来直观确定簇的数量。损失值曲线，就是以图像的方法绘出，取每一个K值时，各个数据点距离质心的平均距离。如下图所示，当K取值很小的时候，整体损失很大，也就是说各个数据点距离质心的距离特别大。而随着K的增大，损失函数的值会在逐渐收敛之前出现一个拐点。此时的K值就是一个比较好的值。</p><p><img src=\"https://static001.geekbang.org/resource/image/9b/66/9ba43dc8c0dc4060eb281e7dbf253d66.jpg?wh=2284x783\" alt=\"\" title=\"手肘法——确定最佳K值\n\"></p><p>你看图中，损失随着簇的个数而收敛的曲线大概像个手臂，最佳K值的点像是一个手肘，这就是为什么我们会叫它“手肘法”的原因。</p><p>下面我们就用代码找出R值的手肘点。请你注意，这里我会先定义一个找手肘点的函数，因为后面在对R值、F值和M值聚类的过程中，我们都要用到这个函数。</p><pre><code class=\"language-plain\">from sklearn.cluster import KMeans #导入KMeans模块\ndef show_elbow(df): #定义手肘函数\n&nbsp;&nbsp;&nbsp; distance_list = [] #聚质心的距离（损失）\n&nbsp;&nbsp;&nbsp; K = range(1,9) #K值范围\n&nbsp;&nbsp;&nbsp; for k in K:\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; kmeans = KMeans(n_clusters=k, max_iter=100) #创建KMeans模型\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; kmeans = kmeans.fit(df) #拟合模型\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; distance_list.append(kmeans.inertia_) #创建每个K值的损失\n&nbsp;&nbsp;&nbsp; plt.plot(K, distance_list, 'bx-') #绘图\n&nbsp;&nbsp;&nbsp; plt.xlabel('k') #X轴\n&nbsp;&nbsp;&nbsp; plt.ylabel('距离均方误差') #Y轴\n&nbsp;&nbsp;&nbsp; plt.title('k值手肘图') #标题\n</code></pre><p>在这段代码中，核心部分是拟合kmeans模型之后，通过&nbsp;kmeans.inertia_计算损失值。损失会随着K值的增大而逐渐减小，而那个拐点就是手肘。</p><p>然后我们调用下面这个函数，显示R值、F值和M值聚类的K值手肘图：</p><pre><code class=\"language-typescript\">show_elbow(df_user[['R值']]) #显示R值聚类K值手肘图\n</code></pre><pre><code class=\"language-typescript\">show_elbow(df_user[['F值']]) #显示F值聚类K值手肘图\n</code></pre><pre><code class=\"language-typescript\">show_elbow(df_user[['M值']]) #显示M值聚类K值手肘图\n</code></pre><p>输出如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/01/c8/01ae89f69241886271d539632b95d9c8.jpg?wh=2284x592\" alt=\"\" title=\"R、F和M值的K值手肘图\"></p><p>可以看到，R、F、M值的拐点大概都在2到4之间附近，这就意味着我们把用户分成2、3、4个组都行。这里我选择3作为R值的簇的个数，选择4作为F值的簇的个数，选择3作为M值的簇的个数。</p><p>那到这里为止呢，我们已经选定好了算法，并确定了R、F、M每个特征下簇的个数，也就是K值。接下来我们就可以开始创建聚类模型了。</p><h1>创建和训练模型</h1><p>前面说了，我们在手肘附近选择3作为R的K值，所以我们创建模型是把n_clusters参数，也就是簇的个数指定为3。这样，聚类算法会把用户的R值分为三个层次。对于F、M，我们也根据对应的K值做类似的操作：</p><pre><code class=\"language-plain\">from sklearn.cluster import KMeans #导入KMeans模块\nkmeans_R = KMeans(n_clusters=3) #设定K=3\nkmeans_F = KMeans(n_clusters=4) #设定K=4\nkmeans_M = KMeans(n_clusters=4) #设定K=4\n</code></pre><p>这样，我们就在程序中创建了一个K-Means聚类模型。<br>\n创建好模型后，我们借助fit方法，用R值的数据，训练模型。</p><pre><code class=\"language-plain\">kmeans_R.fit(df_user[['R值']]) #拟合模型\nkmeans_F.fit(df_user[['F值']]) #拟合模型\nkmeans_M.fit(df_user[['M值']]) #拟合模型\n</code></pre><p>我们不是第一次见到fit这个方法了，fit，翻译成中文就叫做拟合模型。基本上所有的机器学习模型都是用fit语句来进行模型训练的。</p><h1>使用模型进行聚类，并给用户分组</h1><p>模型训练好了，现在我们就用它给R、F、M值聚类。</p><ol>\n<li><strong>给R、F、M值聚类</strong></li>\n</ol><p>我们先用kmeans模型中的predict方法给R值聚类。“predict”翻译成中文是“预测”，不过作为无监督学习方法，它其实就是使用模型进行聚类，而且，也不需要进一步的评估过程。这也是监督学习和无监督学习不一样的地方。</p><pre><code class=\"language-plain\">df_user['R值层级'] = kmeans_R.predict(df_user[['R值']]) #通过聚类模型求出R值的层级\ndf_user.head() #显示头几行数据\n</code></pre><p>这段代码的输出如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/11/54/11162b81068b36511b6120e7dfbbff54.png?wh=167x163\" alt=\"\"></p><p>输出显示，这个聚类结果被附加到了用户层级表中，也就是说在用户层级表中的“用户码”、“R值”字段后面出现了“R值层级”这个字段，也就是将R值聚类后各个簇的号码。</p><p>下面我们用groupby语句来看看0、1、2这几个簇的用户基本统计数据：</p><pre><code class=\"language-plain\">df_user.groupby('R值层级')['R值'].describe() #R值层级分组统计信息\n</code></pre><p>这段代码的输出如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/6a/39/6a4375097ce237d709c9d1882697b039.png?wh=523x147\" alt=\"\"></p><p>这里有一个奇怪的现象，不知道你有没有观察到？</p><p>如果你注意看0、1和2这三个簇，也就是三个组，就会发现形成的簇没有顺序。你看，0群的用户最多670个人，均值显示他们平均购物间隔是31天，上次购物距今是0天到94天，这是相对频繁的购物用户群。</p><p>1群的用户平均购物间隔为295天，上次购物距现在是231天到372天，这是在休眠中的用户；而2群的用户平均购货间隔则变成了157天，介于两者之间，他们上次购物距今是从95天到225天。你会发现这个从０到２的顺序既不是升序，也不是降序。</p><p>这其实是聚类这种算法本身的问题。聚类，作为一种无监督学习算法，是不知道顺序的重要性的，它只是盲目地把用户分群（按照其空间距离的临近性），而不管每个群的具体意义，因此也就没有排序的功能。这也就是我前面说的“聚类后概念化”的具体意思。聚类并不知道那组人的价值高低，所以也就无法确定顺序，需要我们人为来排序。</p><ol start=\"2\">\n<li><strong>为聚类的层级做排序</strong></li>\n</ol><p>那么，下面我们就用一段代码，把聚类的结果做一个排序，让0、1、2这三个组体现出价值的高低。这段代码稍微有点长，不过我给出了详细的注释，你可以看一下：</p><pre><code class=\"language-typescript\">#定义一个order_cluster函数为聚类排序\ndef order_cluster(cluster_name, target_name,df,ascending=False):\n&nbsp;&nbsp;&nbsp; new_cluster_name = 'new_' + cluster_name #新的聚类名称\n&nbsp;&nbsp;&nbsp; df_new = df.groupby(cluster_name)[target_name].mean().reset_index() #按聚类结果分组，创建df_new对象\n&nbsp;&nbsp;&nbsp; df_new = df_new.sort_values(by=target_name,ascending=ascending).reset_index(drop=True) #排序\n&nbsp;&nbsp;&nbsp; df_new['index'] = df_new.index #创建索引字段\n&nbsp;&nbsp;&nbsp; df_new = pd.merge(df,df_new[[cluster_name,'index']], on=cluster_name) #基于聚类名称把df_new还原为df对象，并添加索引字段\n&nbsp;&nbsp;&nbsp; df_new = df_new.drop([cluster_name],axis=1) #删除聚类名称\n&nbsp;&nbsp;&nbsp; df_new = df_new.rename(columns={\"index\":cluster_name}) #将索引字段重命名为聚类名称字段\n&nbsp;&nbsp;&nbsp; return df_new #返回排序后的df_new对象\n</code></pre><p>在上述代码中，为聚类做排序的是order_cluster函数。那么接下来，我们再调用这个order_cluster函数，把用户表重新排序。我们知道，消费天数间隔的均值越小，用户的价值就越高，所以我们在这里采用降序，也就是把ascending参数设为False：</p><pre><code class=\"language-typescript\">df_user = order_cluster('R值层级', 'R值', df_user, False) #调用簇排序函数\ndf_user = df_user.sort_values(by='用户码',ascending=True).reset_index(drop=True) #根据用户码排序\ndf_user.head() #显示头几行数据\n</code></pre><p>此时，各用户的层级值就发生了变化，比如用户14688的簇编号从1变成了2，因为这个用户7天前曾经购物，其R值相对偏低，放在高分的2层级是合适的。其实，上面的代码中，我们并没有改变用户的分组，而只是改变了每一个簇的编号，这样层级关系就能体现出来了。</p><p>下面我们重新显示各个层级的信息：</p><pre><code class=\"language-typescript\">df_user.groupby('R值层级')['R值'].describe() #R值层级分组统计信息\n</code></pre><p>输出如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/93/7c/93b9d8c72da873dc6fae6643f5d6787c.png?wh=477x136\" alt=\"\"></p><p>你会看到，此时各个簇已经形成了次序。0层级的用户，平均新近度是298天，1层级的用户，平均新近度是157天，而R值最高的用户组（2层级），平均新近度仅有32天。这说明用户上一次消费距今的天数越少，其R值的价值越高。</p><p>R值聚类做好后，我们按照同样的方法可以根据用户购买频率给F值做聚类，并用刚才定义的order_cluster函数为聚类之后的簇进行排序，确定层级。因为消费次数越多，价值越高，所以我们把order_cluster 函数的ascending参数设定为True，也就是升序：</p><pre><code class=\"language-typescript\">df_user['F值层级'] = kmeans_F.predict(df_user[['F值']]) #通过聚类模型求出F值的层级\ndf_user = order_cluster('F值层级', 'F值',df_user,True) #调用簇排序函数\ndf_user.groupby('F值层级')['F值'].describe() #F值层级分组统计信息\n</code></pre><p>输出如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/b1/a9/b17366087ca2f0f32eba40cd5d78c9a9.png?wh=534x165\" alt=\"\"></p><p>上图显示，经过了排序的层级中，0级用户的购买频率均值为32次，1级的用户消费频率均值为153次，2级用户消费频率均值达到416次，而2级用户的消费频率均值高达1295次，不过这个簇中只有7个用户。</p><p>还是一样，我们重新为用户层级表排序，并显示df_user对象，也就是用户层级表的当前状态。</p><pre><code class=\"language-typescript\">df_user = df_user.sort_values(by='用户码',ascending=True).reset_index(drop=True) #根据用户码排序\ndf_user.head()\n</code></pre><p>输出如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/98/73/98c934ee43fe2a944153152dc9a85c73.png?wh=250x161\" alt=\"\"></p><p>最后，我们依葫芦画瓢，给M值做聚类，并且对聚类的结果做排序，分出层级。因为代码和R值、F值聚类十分相似，我就直接给出所有代码，不再说明了。</p><pre><code class=\"language-typescript\">df_user['M值层级'] = kmeans_M.predict(df_user[['M值']]) #通过聚类模型求出M值的层级\ndf_user = order_cluster('M值层级', 'M值',df_user,True) #调用簇排序函数\ndf_user.groupby('M值层级')['M值'].describe() #M值层级分组统计信息\ndf_user = df_user.sort_values(by='用户码',ascending=True).reset_index(drop=True) #根据用户码排序\ndf_user.head() #显示头几行数据\n</code></pre><p>最终结果：</p><p><img src=\"https://static001.geekbang.org/resource/image/53/12/5361ee46fcfyya3dbd39e54281e33c12.png?wh=383x159\" alt=\"\"></p><p>好，那到这里为止，R、F、M的聚类工作就全部完成了，并且我们还划分了层级！在当前的用户层级表中，已经包含了这三个维度的层级，最终的用户分层就可以以此为基础来确定了。</p><h1>为用户整体分组画像</h1><p>我们这里采用简单叠加的方法把R、F、M三个层级的值相加，用相加后得到的值，作为总体价值，来给用户进行最终的分层。当然了，如果你对其中某一个指标看得比较重，也可以加权之后再相加。</p><p>具体来讲，我们用下面的代码来创建相加之后的层级，即总分字段。</p><pre><code class=\"language-typescript\">df_user['总分'] = df_user['R值层级'] + df_user['F值层级'] + df_user['M值层级'] #求出每个用户RFM总分\n</code></pre><p>因为R值有3个层级（0，1，2），F值有4个层级（0，1，2，3），M值有4个层级（0，1，2，3），我们把三个维度的值相加，那每一个用户的得分有可能是0到8当中的某一个值，也就是说出现了9个层次。</p><p>我这里就按照下面的规则，来确定用户最终的价值分层。当然了，你也可以尝试用其它的阈值来确定你的价值分层。</p><ul>\n<li>0-2分，低价值用户</li>\n<li>3-4分，中价值用户</li>\n<li>5-8分，高价值用户</li>\n</ul><p>什么意思呢？举例来说，就是如果一个用户在R值拿到了2分，在新近度这个维度为高价值用户，但是在消费频率和消费金额这两个维度都只拿到0分，那么最后得分就为2，总体只能评为低价值用户。</p><p>下面这段代码便是根据总分，来确定出每一个用户的总体价值的。</p><pre><code class=\"language-typescript\">#在df_user对象中添加总体价值这个字段\ndf_user.loc[(df_user['总分']&lt;=2) &amp; (df_user['总分']&gt;=0), '总体价值'] = '低价值'&nbsp;\ndf_user.loc[(df_user['总分']&lt;=4) &amp; (df_user['总分']&gt;=3), '总体价值'] = '中价值'&nbsp;\ndf_user.loc[(df_user['总分']&lt;=8) &amp; (df_user['总分']&gt;=5), '总体价值'] = '高价值'\ndf_user #显示df_user\n</code></pre><p>我们再次输出df_user对象，看一看最终的用户层级表：</p><p><img src=\"https://static001.geekbang.org/resource/image/8b/aa/8b98da066d42e514b4d54f4c4ec62daa.png?wh=484x348\" alt=\"\"></p><p>此时，980个用户的R、F、M层级，还有总体价值的层级都非常清楚了。对于每一个用户，我们都可以迅速定位到他的价值。那到这里，我们就成功地完成了为“易速鲜花”公司做用户价值分组的工作。</p><p>现在，有了用户的价值分组标签，我们就可以做很多进一步的分析，比如说选取R、F、M中任意两个维度，并把高、中、低价值用户的散点图进行呈现：</p><pre><code class=\"language-typescript\">#显示高、中、低价值组分布散点图（F值与M值）\nplt.scatter(df_user.query(\"总体价值 == '高价值'\")['F值'],\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; df_user.query(\"总体价值 == '高价值'\")['M值'],c='g',marker='*')\nplt.scatter(df_user.query(\"总体价值 == '中价值'\")['F值'],\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; df_user.query(\"总体价值 == '中价值'\")['M值'],marker=8)\nplt.scatter(df_user.query(\"总体价值 == '低价值'\")['F值'],\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; df_user.query(\"总体价值 == '低价值'\")['M值'],c='r')\n各价值组的用户分布散点图如下图所示：\n\n</code></pre><p><img src=\"https://static001.geekbang.org/resource/image/28/d5/286a4d8050b94f746ac61533372d11d5.png?wh=555x345\" alt=\"\"></p><p>借此，我们可以发现，高价值用户（绿色五星）覆盖在消费频率较高的区域，和F值相关度高。而在总消费金额大于5000元的用户中，中高价值的用户（绿色五星和红色圆点）都有。</p><p>当然，作为运营部门的一员，你还可以通过对新老用户的价值分组，制定出更有针对性的获客、营销、推广等运营方案。</p><h1>总结一下</h1><p>好啦，到这里，我们就成功闯过了“获客”这个关卡。现在来回顾一下这一讲中的重点内容。</p><p>在这一讲中， 我们理解了聚类算法的原理，学会了如何用手肘法选择K值，以及如何用K-均值算法来给R值、F值和M值做聚类。</p><p>我要再次强调的是，聚类只是负责把空间距离相近的数据点分成不同的簇，它并不知道每一个簇代表的具体含义。比如说，我们用K-Means算法给R值分成三个簇，这并不表示0比1价值低，1比2价值低。此时的0、1、2都是聚类随机分配的编号，具体分组排序的工作我们还要单独去完成。</p><p>在K值的选择方面呢，手肘法可以帮我们直观地显示出聚类过程中整体损失的“拐点”，我们可以在拐点或者拐点附近选择K值，确定把数据分成多少个“簇”（也就是多少个组）。</p><p>最后，我们还讲到用K-均值算法来给R值做聚类，这也非常简单，就是创建模型、拟合模型、用模型进行聚类，这些过程加一块也就是几行代码的事儿，你不用有负担。</p><p>掌握了上述这些内容，你就可以用K-Means算法这种无监督学习算法给任何数据集做聚类，来解决其它类似的问题了，比如根据学生的考试成绩，为学生分组聚类等等。</p><h1>思考题</h1><p>这节课就到这里了，我给你留两个思考题：</p><ol>\n<li>对于K-Means算法，X特征数据集的输入，可以不止一个维度。为了给R、F、M分别分层，在这节课中我给这三者单独做了聚类。你能不能试着把R、F、M三个特征同时输入K-Means算法，为用户整体做聚类呢？此外，你还能不能想到些其它的为用户分组画像的方法呢？</li>\n<li>聚类算法的应用场景其实很广，包括给图像的颜色簇量化分组、给文本分组等等，在你的工作和生活中，你还能够想到，或者曾用过哪些可以通过聚类解决的问题？请你分享一下。</li>\n</ol><p>欢迎你在留言区和我分享你的观点，如果你认为这节课的内容有收获，也欢迎把它分享给你的朋友，我们下一讲再见！</p><p><img src=\"https://static001.geekbang.org/resource/image/81/c1/814f8483b103c69295e54c9d87c7d6c1.jpg?wh=2284x1136\" alt=\"\"></p>","neighbors":{"left":{"article_title":"05 | 数据探索：怎样从数据中找到用户的RFM值？","id":415910},"right":{"article_title":"07｜回归分析：怎样用模型预测用户的生命周期价值？","id":417479}},"comments":[{"had_liked":false,"id":312062,"user_name":"Jove","can_delete":false,"product_type":"c1","uid":1234583,"ip_address":"","ucode":"82CEFDC5F66073","user_header":"https://static001.geekbang.org/account/avatar/00/12/d6/97/035a237b.jpg","comment_is_top":false,"comment_ctime":1631610810,"is_pvip":true,"replies":[{"id":"113083","content":"这......这.....这简直是太棒了。三维RFM图看起来更直观。漂亮。<br><br>感谢Jove同学对于信贷场景的分享！","user_name":"作者回复","user_name_real":"黄佳","uid":"1809833","ctime":1631622450,"ip_address":"","comment_id":312062,"utype":1}],"discussion_count":3,"race_medal":0,"score":"83235989434","product_id":100085501,"comment_content":"1、绘制三维图<br>df_user[&#39;三维价值&#39;] = KMeans(n_clusters=3).fit(df_user[[&#39;R值&#39;, &#39;F值&#39;, &#39;M值&#39;]]).predict(df_user[[&#39;R值&#39;, &#39;F值&#39;, &#39;M值&#39;]])<br><br>ax = plt.subplot(111, projection=&#39;3d&#39;)<br>ax.scatter(df_user.query(&quot;三维价值 == 0&quot;)[&#39;F值&#39;],<br>           df_user.query(&quot;三维价值 == 0&quot;)[&#39;R值&#39;],<br>           df_user.query(&quot;三维价值 == 0&quot;)[&#39;M值&#39;], c=&#39;y&#39;)<br>ax.scatter(df_user.query(&quot;三维价值 == 1&quot;)[&#39;F值&#39;],<br>           df_user.query(&quot;三维价值 == 1&quot;)[&#39;R值&#39;],<br>           df_user.query(&quot;三维价值 == 1&quot;)[&#39;M值&#39;], c=&#39;r&#39;)<br>ax.scatter(df_user.query(&quot;三维价值 == 2&quot;)[&#39;F值&#39;],<br>           df_user.query(&quot;三维价值 == 2&quot;)[&#39;R值&#39;],<br>           df_user.query(&quot;三维价值 == 2&quot;)[&#39;M值&#39;], c=&#39;g&#39;)<br><br>ax.set_zlabel(&#39;F&#39;)  # 坐标轴<br>ax.set_ylabel(&#39;R&#39;)<br>ax.set_xlabel(&#39;M&#39;)<br>plt.show()<br><br>2、我从事的行业的是信贷，也可以从用户征信情况、借贷金额、违约次数等来聚合为用户划分评级","like_count":20,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526850,"discussion_content":"这......这.....这简直是太棒了。三维RFM图看起来更直观。漂亮。\n\n感谢Jove同学对于信贷场景的分享！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631622450,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":2930368,"avatar":"https://static001.geekbang.org/account/avatar/00/2c/b6/c0/5dad741f.jpg","nickname":"小陌白","note":"","ucode":"DC380CC0F47835","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":568188,"discussion_content":"三个一起聚簇感觉好像不太好把握权重，三个特征被同等对待了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1651074336,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":526850,"ip_address":""},"score":568188,"extra":""}]},{"author":{"id":2733378,"avatar":"https://static001.geekbang.org/account/avatar/00/29/b5/42/a720ea27.jpg","nickname":"张子睿","note":"","ucode":"9C4C6408A8B65C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":533967,"discussion_content":"代码最后一段这么写会不会更贴切些\nax.set_zlabel(&#39;M&#39;)  # 坐标轴\nax.set_ylabel(&#39;R&#39;)\nax.set_xlabel(&#39;F&#39;)","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1638030896,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":311437,"user_name":"吴悦","can_delete":false,"product_type":"c1","uid":1403508,"ip_address":"","ucode":"E3E99474206BF4","user_header":"https://static001.geekbang.org/account/avatar/00/15/6a/74/c39efead.jpg","comment_is_top":false,"comment_ctime":1631238234,"is_pvip":false,"replies":[{"id":"112862","content":"同学们的问题总是会引导我剧透后面的内容。。。<br><br>在sklearn中，同学所说的无量纲化英文被称为特征的缩放(Scaler)，把大的数值压缩到小的范围，或者改变数值的分布状态等。具体的方法和工具很多，包括标准化，归一化，居中，规范化等等不同的手段（这些手段的名词也容易混淆）：<br><br>1）StandardScaler工具，标准化缩放，是对数据特征分布的转换，目标是使其符合正态分布(均值为0，方差为1)。对于某些模型，如果数据特征不符合正态分布的话，就影响机器学习效率。<br><br>2）MinMaxScaler工具，是把特征的值压缩到给定的最小值和最大值之间，通常在0和1之间，有负值的话就是-1到1，因此也叫归一化。归一化不会改变数据的分布状态。在sklearn中，通过MinMaxScaler进行标准化缩放。某些模型，比如神经网络，就非常喜欢归一化之后的特征数据。<br><br>3）RobustScaler工具，基于百分位数的缩放，能消除这个过程消除了数据中的离群值的影响，但转换后的特征值的结果范围比之前的更大，所以RobustScaler之后，通常还结合归一化缩放器一起使用，再把数据压缩一下。<br><br>4）Normalizer工具，规范化缩放，则是将样本缩放为具有单位范数的过程，这可能仅适用于某些各个维度都是One-Hot编码的数据集，应用场景较少。<br><br>不同数据集适用不同工具。<br><br>这些我们以后要讲。","user_name":"作者回复","user_name_real":"黄佳","uid":"1809833","ctime":1631252702,"ip_address":"","comment_id":311437,"utype":1}],"discussion_count":1,"race_medal":0,"score":"40285943898","product_id":100085501,"comment_content":"多维数据输入时怎么做 无量纲化好呀","like_count":10,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526602,"discussion_content":"同学们的问题总是会引导我剧透后面的内容。。。\n\n在sklearn中，同学所说的无量纲化英文被称为特征的缩放(Scaler)，把大的数值压缩到小的范围，或者改变数值的分布状态等。具体的方法和工具很多，包括标准化，归一化，居中，规范化等等不同的手段（这些手段的名词也容易混淆）：\n\n1）StandardScaler工具，标准化缩放，是对数据特征分布的转换，目标是使其符合正态分布(均值为0，方差为1)。对于某些模型，如果数据特征不符合正态分布的话，就影响机器学习效率。\n\n2）MinMaxScaler工具，是把特征的值压缩到给定的最小值和最大值之间，通常在0和1之间，有负值的话就是-1到1，因此也叫归一化。归一化不会改变数据的分布状态。在sklearn中，通过MinMaxScaler进行标准化缩放。某些模型，比如神经网络，就非常喜欢归一化之后的特征数据。\n\n3）RobustScaler工具，基于百分位数的缩放，能消除这个过程消除了数据中的离群值的影响，但转换后的特征值的结果范围比之前的更大，所以RobustScaler之后，通常还结合归一化缩放器一起使用，再把数据压缩一下。\n\n4）Normalizer工具，规范化缩放，则是将样本缩放为具有单位范数的过程，这可能仅适用于某些各个维度都是One-Hot编码的数据集，应用场景较少。\n\n不同数据集适用不同工具。\n\n这些我们以后要讲。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631252702,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":311473,"user_name":"在路上","can_delete":false,"product_type":"c1","uid":1402511,"ip_address":"","ucode":"6E31908EFE1107","user_header":"https://static001.geekbang.org/account/avatar/00/15/66/8f/02be926d.jpg","comment_is_top":false,"comment_ctime":1631248412,"is_pvip":false,"replies":[{"id":"112865","content":"谢谢精辟的分享，皆是宝贵的经验之谈，对我亦有启发！三人行，必有我师！大家也是我的老师，我这儿也祝愿大家工作生活愉快。<br><br>对，文本部分，我这儿需要按照表格中跑出来的值进行调整一下，把二者对应上。谢谢你的细心！！","user_name":"作者回复","user_name_real":"黄佳","uid":"1809833","ctime":1631258067,"ip_address":"","comment_id":311473,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18811117596","product_id":100085501,"comment_content":"佳哥好，今天是教师节，祝你节日快乐。我看了下kmeans的API，fit函数支持多维数组，应该可以把RFM三个维度的值同时传给fit进行拟合，而不是把RFM三个维度的值降维到一个值进行拟合，通过predict函数就可能直接得到聚类后的层级，从predict函数的名称可以得知，它不仅能计算训练集的聚类层级，也能预测新数据的聚类层级。<br>我从事游戏行业，策划会根据玩家充值金额来定义大中小R，充值区间的定义全凭经验，如果用今天教的k-means方法就非常合适。我最近在学习大数据，想统计HDSF上文件大小的分布情况，也可以用k-means算法。<br>最后说一下我发现这节课的文本和表格的部分数据有出入。文本：上次购物距今是0天到91天，表格：是94天。文本：0层级的用户平均新近度是295天，表格：是298天。文本：R值最高的用户组（2层级）平均新近度仅有31天，表格：是32天。","like_count":5,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526622,"discussion_content":"谢谢精辟的分享，皆是宝贵的经验之谈，对我亦有启发！三人行，必有我师！大家也是我的老师，我这儿也祝愿大家工作生活愉快。\n\n对，文本部分，我这儿需要按照表格中跑出来的值进行调整一下，把二者对应上。谢谢你的细心！！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631258067,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":355728,"user_name":"Geek_maxwell","can_delete":false,"product_type":"c1","uid":1446442,"ip_address":"浙江","ucode":"15FBD7BE46AC81","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epbtcXw5PHzibHcXlupLmnZOYXBLR10U4Hvn5tib14EYlkMBERYgGlgZ63BxgFSBTQmUErfSXibcKl6w/132","comment_is_top":false,"comment_ctime":1661696693,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1661696693","product_id":100085501,"comment_content":"kmeans = kmeans.fit(df) #拟合模型 这个好像不能重新赋值给kmeans， 不然后面的kmeans.inertia_就没有了","like_count":0},{"had_liked":false,"id":348426,"user_name":"庞亮","can_delete":false,"product_type":"c1","uid":1566610,"ip_address":"","ucode":"E2FFB00F2ED229","user_header":"","comment_is_top":false,"comment_ctime":1655099311,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1655099311","product_id":100085501,"comment_content":"“最后，我们还讲到用 K- 均值算法来给 R 值做聚类，这也非常简单，就是创建模型、拟合模型、用模型进行聚类，这些过程加一块也就是几行代码的事儿，你不用有负担。”<br>这句说了两遍","like_count":0},{"had_liked":false,"id":343248,"user_name":"Yaohong","can_delete":false,"product_type":"c1","uid":2940266,"ip_address":"","ucode":"AEFBFFF143AA24","user_header":"https://static001.geekbang.org/account/avatar/00/2c/dd/6a/c47ef5aa.jpg","comment_is_top":false,"comment_ctime":1650725652,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1650725652","product_id":100085501,"comment_content":"请问 order_cluster函数中new_cluster_name = &#39;new_&#39; + cluster_name #新的聚类名称，这个有什么作用？后面分组中用mean()方法而不用max（）方法有什么考量？","like_count":0},{"had_liked":false,"id":337945,"user_name":"松饼Muffin","can_delete":false,"product_type":"c1","uid":2938616,"ip_address":"","ucode":"1FCE9E6E4F9C8C","user_header":"https://static001.geekbang.org/account/avatar/00/2c/d6/f8/cb21b43c.jpg","comment_is_top":false,"comment_ctime":1647171127,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1647171127","product_id":100085501,"comment_content":" 老师， 我算出来的`R值` 是 timedelta64[ns] 格式， 如`70 days 20:39:00`, 如何转成70呢？我是用很土的方法硬转，应该有更优雅的办法吧？<br> RFM[&#39;recency&#39;] = RFM[&#39;recency&#39;] .astype(&#39;str&#39;).str.split(&#39; days&#39;).str.get(0).astype(&#39;int&#39;)","like_count":0},{"had_liked":false,"id":336585,"user_name":"Geek_7ba002","can_delete":false,"product_type":"c1","uid":2930857,"ip_address":"","ucode":"43A4969BCAFEF3","user_header":"","comment_is_top":false,"comment_ctime":1646225897,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1646225897","product_id":100085501,"comment_content":"这节课让我真正理解了什么是聚类","like_count":0},{"had_liked":false,"id":336584,"user_name":"Geek_7ba002","can_delete":false,"product_type":"c1","uid":2930857,"ip_address":"","ucode":"43A4969BCAFEF3","user_header":"","comment_is_top":false,"comment_ctime":1646225867,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1646225867","product_id":100085501,"comment_content":"这堂课我真正理解了sklearn","like_count":0},{"had_liked":false,"id":316224,"user_name":"小强","can_delete":false,"product_type":"c1","uid":2034712,"ip_address":"","ucode":"D1B0DA58E4D969","user_header":"https://static001.geekbang.org/account/avatar/00/1f/0c/18/298a0eab.jpg","comment_is_top":false,"comment_ctime":1634206145,"is_pvip":false,"replies":[{"id":"116869","content":"https:&amp;#47;&amp;#47;github.com&amp;#47;huangjia2019&amp;#47;geektime","user_name":"作者回复","user_name_real":"编辑","uid":"1809833","ctime":1637074062,"ip_address":"","comment_id":316224,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1634206145","product_id":100085501,"comment_content":"这章的代码在哪可以看到","like_count":0,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":530436,"discussion_content":"https://github.com/huangjia2019/geektime","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1637074062,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":312385,"user_name":"蝶舞清风寒","can_delete":false,"product_type":"c1","uid":2753090,"ip_address":"","ucode":"2818B4BE7DCC16","user_header":"https://static001.geekbang.org/account/avatar/00/2a/02/42/e8ef9639.jpg","comment_is_top":false,"comment_ctime":1631781897,"is_pvip":false,"replies":[{"id":"113355","content":"没问题可以的，整体聚类之后结果如何，是否如实反映出用户价值分组情况呢。","user_name":"作者回复","user_name_real":"黄佳","uid":"1809833","ctime":1632068452,"ip_address":"","comment_id":312385,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1631781897","product_id":100085501,"comment_content":"R、F、M 三个特征同时输入 K-Means 算法，为用户整体做聚类程序代码如下，是否正确呢？<br>train_x=df_user[[&quot;R值&quot;,&quot;F值&quot;,&quot;M值&quot;]]#将RFM数值转变为训练数据<br># 规范化到[0,1]空间<br>min_max_scaler=preprocessing.MinMaxScaler()<br>train_x=min_max_scaler.fit_transform(train_x)<br>kmeans_RFM = KMeans(n_clusters=3) #设定K=3<br>kmeans_RFM.fit(train_x) #拟合模型<br>RFM_label = kmeans_RFM.predict(train_x) #通过聚类模型求出R值的层级<br>df_user[&#39;标签&#39;]= RFM_label #通过聚类模型求出R值的层级<br>df_user = order_cluster(&#39;标签&#39;, [&quot;R值&quot;,&quot;F值&quot;,&quot;M值&quot;], df_user, False) #调用簇排序函数<br>df_user = df_user.sort_values(by=&#39;用户码&#39;,ascending=True).reset_index(drop=True) #根据用户码排序<br>","like_count":0,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526955,"discussion_content":"没问题可以的，整体聚类之后结果如何，是否如实反映出用户价值分组情况呢。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1632068452,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2938616,"avatar":"https://static001.geekbang.org/account/avatar/00/2c/d6/f8/cb21b43c.jpg","nickname":"松饼Muffin","note":"","ucode":"1FCE9E6E4F9C8C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":556463,"discussion_content":"这里可能要做个转换，R值是越小越好，F，M是越大越好,　所以是不是得先把他们调成同样越大越好或越小越好，再一起用ascending =True or False?　","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1647393396,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}