[{"article_id":505735,"article_title":"开篇词｜你现在所写的每一行代码，都是未来的遗留系统","article_content":"<p>你好，我是姚琪琳，来自Thoughtworks，很高兴在极客时间与你相遇。</p><p>先做个自我介绍，我做过程序员、架构师、技术负责人、技术教练、咨询师，角色一直在变化，但幸运的是始终可以有机会写写代码。业余时间也喜欢翻译，曾经翻译过大大小小十来本技术书籍。</p><p>这15年的职业生涯，虽然我尝试了种种工作，但总结起来我大部分的时间都在和遗留系统打交道。既有开发历史已经接近20年的系统，也有刚上线没几年的系统，当然也有开发了十来年，但看上去十分美好的、所谓的“遗留”系统。</p><p>在这个深坑中摸爬滚打了多年之后，我在遗留系统开发、治理和改造的过程中积累了大量的一手经验，现在我决定把我和团队的经验分享出来，帮助深陷在遗留系统的泥潭中无法自拔的你。</p><p>你可能会说，你当前所在的项目上并没有遗留系统，所有的系统都生机勃勃、一片祥和。不过，根据这些年和遗留系统打交道的经验，我基本可以告诉你，表面的祥和之下，可能暗藏波涛。</p><h2>你现在所写的每一行代码，都是未来的遗留系统</h2><p>我的同事，重构和微服务的缔造者，软件开发领域的泰斗，Martin Fowler曾经说过<a href=\"https://martinfowler.com/bliki/StranglerFigApplication.html\">这样一句话</a>：</p><blockquote>\n<p>Let’s face it, all we are doing is writing tomorrow’s legacy software today.</p>\n</blockquote><!-- [[[read_end]]] --><p>是的，可以毫不夸张地说，<strong>你现在所写的每一行代码，都是未来的遗留系统</strong>。</p><p>这听上去有点让人沮丧，但却是血淋淋的事实。每一种技术的诞生和流行，都有它的时代背景，当这个背景不存在时，也就失去了它生存的土壤。因此你现在所纠结的每一项技术选型，到五年以后都会过时成为遗留产物。</p><p>曾经作为行业标准的IOE，现在人人唯恐避之不及；风靡一时的SOA，也最终被微服务所取代；而如果以后云服务进一步发展，大型服务的部署和演进不再是瓶颈，单体会不会重新流行？谁知道呢。</p><p>看到这里，你还会觉得遗留系统跟自己没关系吗？即使你现在没有工作在遗留系统上，你也很快就要工作在它上面了。</p><p>而随着技术的发展，被遗留系统左右的可不仅仅是开发者个人，还有你所在的企业。我想你一定听说过数字化转型！那些曾经为企业立下汗马功劳的IT系统（也就是遗留系统），此刻反而成为了数字化转型的绊脚石。这是为什么呢？</p><p>概括来说就是，IT能力支撑不了企业的市场需求，技术跟不上业务。一个简单的流程更改，都需要很久才能上线；新的数字渠道来临时，系统更是无法支持。不仅如此，有些系统甚至连最基本的可用性都无法满足，动不动就打不开、报错，甚至无法完成业务，用户体验也非常差。面对这样的痛点，系统现代化势在必行。</p><p>有太多在遗留系统上折腾的案例，改造的过程声势浩大，结果却令人扼腕。有的开启专项，抽调精英，大刀阔斧地进行整改；有的则干脆重写，企图替换原有系统。但这些行动大多都以失败而告终：有的改造完了仍然无法满足业务，新写的系统也好不到哪去，只不过是又一个遗留系统罢了。</p><p>在亲眼目睹了这些惨案之后，我愈发觉得有必要把我的经验分享给你和你的组织了。</p><h2>你的系统真的不是遗留系统吗？</h2><p>也许看到这里你还是感觉遗留系统和你无关。要么觉得我手上的系统才两三年，算不上遗留系统，要么立志“让我维护遗留系统就辞职”。</p><p>对于第一种想法，你敢打包票自己的系统不是遗留系统吗？很多人以为存在时间很长的就是遗留系统，但这其实是个误区。</p><p>时间长短并不能作为衡量遗留系统的标准。有些系统虽然刚开发不久，但你工作起来还是有各种不爽，比如：</p><ul>\n<li>代码质量一言难尽，改个需求或做维护经常加班，让你恨不得推翻重写；</li>\n<li>架构混乱，模块之间职责不明，一个需求需要修改四五个服务；</li>\n<li>CI/CD运转不畅，经常莫名其妙地挂掉，每次升级、上线都一拖再拖；</li>\n<li>团队结构不稳定，人员变动频繁；大家都在拼命开发新需求，没人关心技术债；</li>\n<li>……</li>\n</ul><p>如果以上问题你都自信满满，那我就要拿出杀手锏了。</p><p>你的代码有测试吗？你平时开发新需求时会写测试吗？你在修改bug时会补测试吗？经过这样的灵魂三问，你还有自信坚持说自己的系统不是遗留系统吗？</p><p>《修改代码的艺术》一书的作者Michael Feathers说过，“没有测试的代码都是遗留代码”。在我们越来越强调软件系统质量内建的今天，仍然有很多系统甚至很多刚刚开发的新系统，由于各种原因不写测试。有的说工期太紧，没时间写；有的说系统原来就没测试，我新加的这么几行代码没必要写。其实每种借口都禁不起推敲，都是在为自己不会写测试来打马虎眼。</p><p>软件系统本身就是一个不断熵增的过程，代码逐渐从有序变得无序。如果没有测试的严防死守，熵增的过程就会慢慢加快，代码很快就会变得混乱不堪。</p><p>前段时间在硅谷有个新闻，一位华裔开发人员受不了同事不写单元测试，所以愤然离开了这家在国内赫赫有名的大厂。这家大厂的做法和国内的很多互联网公司一样，用大量的昂贵的人工测试，去替代廉价的自动化测试。不是说这样不可行，但问题是它的投入产出比非常低，并且十分低效的。而且是把软件开发这个智力劳动，当成了体力劳动密集型的工作。在我看来，这不但是对软件工作者的嘲讽和亵渎，而且无视了熵增定律，迟早要付出代价。</p><p>至于第二种想法“让我维护遗留系统就辞职”。如果你是公司的CTO或者架构师，你还会这么想吗？</p><p>技术之路走到后来，你需要更深的技术与业务洞察，更丰富的理论和实战经验。</p><p>比如我在代码现代化部分介绍的代码重构，难道你平时写代码不重构吗？显然不是，重构已经成为了开发人员必备的甚至是融入血液的技能。不会重构，怎么好意思跟人打招呼。</p><p>再比如在架构现代化部分介绍的抽象分支模式，不也正是我们在日常开发时会频繁使用的模式吗？每当我们提取一个接口来隔离某个变化方向，其实就是一个抽象分支。想想看，你是不是早就习惯了一个接口加一个Impl类的结构了呢（当然，我并不推荐盲目使用接口 + Impl类的结构）？</p><p>我的这些经验之谈，并不仅适用于遗留系统开发。像三个原则和四个现代化中的各种模式，其实都是开发新系统常常要用到的。</p><h2>课程安排</h2><p>谈了这么多，无非就是表达一个观点：作为工程师，我们比想象中距离遗留系统更近。与其逃避躲闪，不如把它作为我们技术进阶的磨刀石和垫脚石。</p><p>在这个专栏里，我会先给你介绍一下我心中的遗留系统现代化的定义。然后按照我最喜欢的技术书籍之一《敏捷软件开发：原则、模式和实践》那样，将遗留系统现代化的各种知识总结为原则、模式和实践。</p><p>你一定会好奇为什么叫遗留系统“现代化”，而不是业界常说的“改造”。我其实是有意回避了这个词，因为这个词“重过程”、“轻结果”。我见过太多遗留系统改造之后并没有什么变化，甚至越改越糟。这也是我总结遗留系统现代化三原则的原因。只有遵循这些原则，才能有的放矢，才不会偏离方向。</p><p>这三个原则分别是<strong>以降低认知负载为前提、以假设驱动为指引、以增量演进为手段</strong>。</p><p>它们是大多数遗留系统改造项目中容易忽视的部分。很多系统的改造都只针对局部问题，缺乏全局的认知和系统的视角。</p><p>比如重构代码是为了什么？只是为了提升可读性吗？拆分模块是为了什么？只是为了架构整洁吗？为什么耗时一年的改造上线之后因为bug太多而不得不被叫停，最后不了了之？相信在学完原则篇后，你能找到答案。</p><p>而模式则包含很多了，它们有的来源于网络上或书上，我在实际工作中使用之后感觉受益匪浅，于是拿出来夹带着我自己的理解展示给你。像Michael Feathers提出的<strong>接缝</strong>模式、Martin Fowler提出的<strong>扩张-收缩</strong>模式、Eric Evans提出的<strong>气泡上下文</strong>模式等等。这些大师总结的模式，我用起来的感觉就是两个字：真香。</p><p>这些模式，有的则来自于我和同事在实战一线处理完各种疑难杂症后，总结出来的套路，它们适合去解决不同种类的问题。比如为遗留代码添加测试的<strong>决策表</strong>模式，以及为了更好地持续集成而使用的<strong>七步提交法</strong>。即使你不在遗留系统上工作，这些知识也能丰富你的工具箱，使你成为解决问题的高手。</p><p><img src=\"https://static001.geekbang.org/resource/image/21/ef/216d75abcd69352fec044138befd9bef.jpg?wh=11533x6020\" alt=\"\"></p><p>而最后的实践部分，我将带着你一起对一个典型的遗留系统进行现代化。这期间会遇到种种问题，我们一起把前面提到的原则和模式使用起来，武装我们的双手，并且还会对各种模式进行变体，以使其更加适配我们要解决的问题。相信我们一定可以兵来将挡、水来土掩。</p><p><img src=\"https://static001.geekbang.org/resource/image/3e/6e/3e5f39d0b9a91f9cd858d7d2830f2b6e.jpg?wh=1920x876\" alt=\"图片\"></p><h2>写在最后</h2><p>技术可以流行一时，但终将被淘汰，而方法论却可以像陈年老酒一样愈久弥香。我也曾经像你一样，对于新技术趋之若鹜，但最后发现，只有掌握了解决问题的方法，才能不惧任何问题。那些不同的技术，只不过是同一种方法下的不同思路罢了。</p><p>总之，我把我解决遗留系统难题的方法总结了出来，尽管它有些地方与你现在所使用的技术并不完全一致，但学会了这些知识，对平时的开发和设计都是非常有帮助的。毕竟，虽然要解决的问题不同，但方法却殊途同归。</p><p>我们的遗留系统现代化列车即将启程，希望你和我一起学习进步！</p>","neighbors":{"left":[],"right":{"article_title":"01｜遗留系统之殇：为什么要对遗留系统进行现代化？","id":505740}}},{"article_id":505740,"article_title":"01｜遗留系统之殇：为什么要对遗留系统进行现代化？","article_content":"<p>你好，我是姚琪琳。</p><p>不知道你是否跟曾经的我一样，身处一个遗留系统的漩涡之中，每天为毫无头绪的代码和混乱不堪的架构发愁。一个新的需求来了，都不知道从哪儿开始改起，即便看似简单的需求都要很久才能上线。</p><p>假如你也如此，请不要悲伤，也不要心急，其中有很多妥善的应对之法，我会在这个专栏中一一交付给你。</p><p>但在此之前啊，我想我们是不是得先明确一下，到底什么样的系统才能称之为遗留系统呢？它存在哪些问题，复杂在哪里？</p><p>这节课我们就来一探究竟，好为我们后面深入学习遗留系统奠定一个良好的基础。同时，我们也可以看看在高成本的现代化改造之下，为什么遗留系统还要迎难而上？</p><h2>关于遗留系统的误区</h2><p>请你先思考这样一个问题：假如一个系统七八年了，它是不是个遗留系统？</p><p>系统的时间长等同于就是遗留系统，这是很多人的一个误区。虽然大多数遗留系统确实是存在的时间很长，但并不等于时间长的都是遗留系统。</p><p>这里分享一个我的项目经历。我之前曾在一个项目上工作6年多，这是一个有着12年历史的老项目。</p><p>它的技术栈最初是.NET Framework，现在已经有部分迁移到了.NET Core；它最初是单体架构，现在是一个小单体加多个微服务；它从第一行代码开始就使用TDD的方式开发，至今已经有30000多个不同类型的测试；它一开始使用SVN来管理源代码，不过早在十年前就被迁移到了Git；它从第一天就有CI/CD相伴，并且一直坚持基于主干开发的分支策略，每个月都有稳定的版本发布；它没有一行注释，但是任何开发人员都能通过阅读源代码快速了解系统的实现，也就是说代码质量相当高……</p><!-- [[[read_end]]] --><p>这个系统历时12年之久，比很多公司活的时间都长。那它是遗留系统吗？答案是否定的。因为它的代码质量高、架构合理、自动化测试丰富、DevOps成熟度也高，各种技术、工具都是相对先进的，怎么能说是遗留系统呢？</p><p>这里我还想请你进一步思考一下：存在时间短的系统就不是遗留系统吗？</p><p>仍然拿我个人经历过的一个项目来举例。它是07年左右开发完成的，当我10年加入项目组的时候发现，它仍旧是基于JDK 1.4的（那个时候Java 6已经发布4年了），很多Java的新特性都无法使用。它是一个C/S结构的软件，前端基于Java富客户端，后端是一个大单体向前端提供RPC服务；它没有一行测试，每改一行代码都提心吊胆，有时为了不影响别的功能，只好把代码复制一份，加入自己的逻辑，这就导致了大量的重复代码；每次发布日期都是一拖再拖，而部署到生产环境上的war包，甚至在是开发机器上打包的……</p><p>别看这个系统只开发完3年，但毫不客气地说，它从刚开发完毕的那一刻起，恐怕就是个遗留系统。它的代码质量差、架构不可演进、没有自动化测试、缺乏DevOps，各种技术、工具也十分落后、老旧，这样的系统，即使刚开发完，也是遗留系统。</p><p>那么从上面的描述看，你大概已经发现了我判断遗留系统的几个维度：<strong>代码、架构、测试、DevOps以及技术和工具</strong>。</p><p>所以说啊，时间长短并不是衡量遗留系统的标准。代码质量差、架构混乱、没有测试、纯手工的DevOps（或运维）、老旧的技术和工具，才是遗留系统的真正特点。</p><p>接下来我们就从这些特点出发，逐一分析一下它们都造成了哪些问题。</p><h2>遗留系统的特点和问题</h2><p>首先就是代码质量差。我们说优秀的代码都是相似的，而糟糕的代码则各有各的糟糕之处。</p><p>我曾治理过一个有着6000行代码的单个方法，至今印象深刻。其中包含6个大的if/else块，每个块中大概有1000行左右的代码，这6个1000行的代码只有十分细小的差别。显然是开发人员为了偷懒，不敢在原代码上改动，于是复制出来加入自己的逻辑。他倒是图省事儿了，但是对于维护人员来说简直是噩梦。正所谓编码一时爽，维护火葬场。</p><p>其次是架构，这也是遗留系统的重灾区。一个软件架构的作用，是要解决多个业务模块之间的协作问题。但如果架构混乱，多个模块之间往复调用，数据也是随意访问，模块之间的边界就会变得模糊，数据所有权也会变得含糊。试想一下，如果一张表被10个模块访问，谁能说得清这张表到底属于哪个模块呢？</p><p>下图是一家银行的核心应用系统模块之间的交互图，我想没有一个人愿意工作在这样的系统上吧？</p><p><img src=\"https://static001.geekbang.org/resource/image/24/ae/240594a8fb368884641cc981beed27ae.png?wh=1200x688\" alt=\"图片\"></p><p>综合来看，代码和架构的质量差会导致遗留系统的维护成本相当高昂。这里的维护就包括：新需求的添加、线上Bug的修改，以及为了维护系统运行所需投入的软硬件和人力等。</p><p>我说这些可不是空穴来风，IEEE就曾报道过，2010年以来，全世界在IT产品和服务上的支出达到了35万亿美元。其中四分之三用于运营和维护现有的IT系统，至少有2.5万亿用于尝试替换旧系统，其中差不多三分之一的资金都打了水漂（这个报道详情你感兴趣的话，可以看<a href=\"https://spectrum.ieee.org/computing/it/inside-hidden-world-legacy-it-systems\">这里</a>）。</p><p>企业在遗留系统上的投入巨大，却没能得到相称的回报。很多资金只是用来维持系统的现状，却不能让它们变得更好。</p><p>更严重的是，代码和架构的落后还会导致系统在合规和安全方面的问题。</p><p>随着我国法律法规的健全，软件系统的合规性越来越重要，而一个面对任何需求都难以实现的遗留系统，要想进行修改以符合新的法律法规，是难上加难的事情。去年我国正式施行了《中华人民共和国数据安全法》（即中国的GDPR），明确规定了软件系统的数据安全规范。如果不能依法进行系统的整改，将面临法律的制裁。</p><p>而在遗留系统开始构建的时候，可能就没有考虑太多的安全性。随着新的攻击手段越来越丰富，遗留系统的安全性越来越脆弱，企业也很难对此投资去专门改善安全性。</p><p>然后我们接着看缺乏甚至没有测试所造成的问题。在一个遗留系统上添加新需求简直如履薄冰，当你好不容易找到要修改的位置，敲了几行代码感觉可以了的时候，系统的另一个功能可能会因为你的这几行代码而崩溃。</p><p>而一个线上Bug想要找到元凶，可能会难如登天，一方面缺乏有效的日志难以定位（很多遗留系统的日志是打在命令行里的），另一方面修复了一个Bug也可能会导致更多的Bug。</p><p>这时就体现出自动化测试的重要性了。我不知道你的系统里有没有或者有多少测试，总之我在那个有着30000多个自动化测试的项目上修复一个Bug的过程是这样的：</p><p>1.先在本地复现Bug，找到产生这个Bug的业务场景；<br>\n2.为这个业务场景添加一个自动化测试并运行，发现这个测试是失败的；<br>\n3.修改代码，让这个新增的测试通过；<br>\n4.运行所有的测试，确保所有的测试通过。</p><p>经过这一系列操作，我就可以有十分有信心地宣布，这个Bug被我修复了，而且在目前测试覆盖的场景下没有引入新的Bug。但对于没有测试的遗留系统，在测试人员告知测试通过之前，我简直是胆战心惊。</p><p>那遗留系统落后的DevOps手段会造成哪些问题呢？</p><p>这会造成重大的安全隐患。像我前面举的那个例子，部署到生产环境的安装包是本地打出来的，就是非常严重的安全问题。不知你是否记得几年前著名的XCodeGhost事件，开发人员使用非官方渠道下载的注入了恶意代码的XCode，并用这样的XCode打包App，上传到了App Store上。结果下载了这种App的手机信息就被窃取了。</p><p>这里多说两句，这次事件延伸到我们的日常工作中也是有值得深思之处的。</p><p>一是不要从非官方渠道下载开发工具，但这个教训直到现在仍然没有引起足够的重视，仍然有很多团队使用的付费开发工具不是从官方渠道下载的。二是不要在开发机器上打包部署到非开发环境（特别是生产环境）上，要通过CI/CD来编译、打包和部署（当然CI/CD上的工具也必须是从官方渠道下载）。这就是DevOps的作用之一。</p><p>最后，技术和工具也可能存在很大的安全漏洞（比如前段时间爆雷的log4j）。新的系统虽然也存在这样的风险，但是非常容易补救。反观遗留系统的工具升级，那就举步维艰了，原因也很简单，投入产出比合不来。</p><p>另外，落后的技术和工具也使得遗留系统难以与新系统集成。基于Delphi、PowerBuilder、VB或Lotus Notes那一代的桌面应用，就是很好的例子。新的开发团队在面临遗留系统集成的时候，往往都是唯恐避之不及。这样的系统也使得自己所拥有的企业核心数据成为孤岛，难以与其他系统互联。</p><h2>什么是遗留系统？</h2><p>说了这么多，我们似乎已经有了一个很具体的关于遗留系统的画像了，参考如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/29/e5/2956b29efbd201cf8ecabab096fe0ae5.jpg?wh=1920x840\" alt=\"图片\"></p><p>那是不是可以进一步抽象一下概念了呢？</p><p>很简单，不妨直接看看维基百科是如何定义的吧：</p><blockquote>\n<p>在计算机领域，遗留系统是一种使用旧的方法和技术的、过时的，却仍旧在使用的计算机系统。</p>\n</blockquote><p>而Gartner给出的定义是：</p><blockquote>\n<p>基于过时技术但对日常运营至关重要的信息系统。</p>\n</blockquote><p>嗯，有信息重合，我们找找关键字：<strong>旧的、过时的、重要的、仍在使用的</strong>……</p><p>这里找找对应的例子，辅助下理解。不知道你是否看过一些医疗类型的美剧，还记得发生危急情况时，医院是如何通知医生们的吗？是使用寻呼机——一个在现实生活中已经寿终正寝了快20年的古老的通信设备。</p><p>难道美国的通信设施如此落后吗？当然不是，诞生了iPhone和Android的美国怎么可能通信落后呢？真正落后的是医院的急救寻呼系统。这些系统往往有着六七十年的历史，很难被替换。它就完美符合上面的所有关键字：旧、过时、重要、仍在使用。</p><p>还有Windows XP系统，尽管它很经典，但微软在2014年就已宣布不再维护了。不过直到现在，我们仍然能在很多ATM机上看到它的踪影。</p><p>到这，我们已经完全明确了遗留系统的定义以及它所带来的问题，所以你觉得一个遗留系统还有保留的价值吗？为什么我们没有替换甚至丢弃，还要继续维护，并为其打上重要的标签呢？</p><h2>遗留系统的现代化价值</h2><p>原因有很多。首先，<strong>可能是成本太高了，企业不愿意投入资源去改进；也可能是因为积重难返，根本改不动。</strong>而遗留系统往往都是企业的核心业务系统，支撑着整个企业的业务运营，这样的系统就算问题再多，也是不可替代的。</p><p><strong>其次，遗留系统蕴含了大量的数据资产。</strong>遗留系统中的数据虽然很难与其他系统进行集成，但这部分数据的价值又是巨大的。企业的新系统常常不得不在这些数据的基础之上去构建，其他系统要想获得遗留系统中的数据，就必须对遗留系统进行修改，所以很多团队为了避免修改代码就会去寻求数据库层面的复制和同步，这也是一个选择。</p><p><strong>另外，遗留系统中还藏匿着丰富的业务知识。</strong>由于业务人员长期使用并且养成了习惯，很多软件系统已经与业务融为一体，很难区分哪些是真正的业务，哪些是系统的设计。而由于系统历时太久，已经失去了能够正确描述系统现状的文档，所以到最后只有遗留系统的代码才能够准确表达系统的行为，以及与之对应的业务知识。</p><p>系统改造，有可为有可不为，而对于遗留系统来说，结合其现代化价值，看上去更像是一种不得不为。所谓现代化，其实就是从代码、架构、DevOps和团队结构这四个方面来对遗留系统进行治理。</p><p>既然不能对遗留系统听之任之，我们就要下决心迎难而上，掌握主动权，否则当问题真正出现时就为时已晚了。</p><p>举个例子，疫情期间，美国大量人口失业，但上世纪80年代建造的失业系统无法及时发放失业福利，他们的国税局系统则更加老旧，是60年代建造的，总共需要20个星期的时间才能为符合条件的纳税人发放疫情补贴。</p><p>我们看到的是，在全球疫情这种黑天鹅事件发生时，一方面，高响应力的公司能够快速推出像疫情地图、行程码这种全新的服务，以造福社会服务大众；而一方面，陈旧的遗留系统却在拖着整个时代的后腿。</p><p>用巴菲特的话说就是，当潮水退去之后，你才知道谁在裸泳。</p><p>如果说不得不为，那怎么为之更好呢？</p><p>在数字化时代，每家企业都应该意识到科技是核心竞争力，要依赖科技去重塑业务、创造新的商业模式，创造数字化收益。也就是我们常说的Tech@Core。</p><p>很多互联网公司的数字化基因是与生俱来的，它们能够根据当前的形式和热点迅速地开启一个全新的商业模式并站稳脚跟。比如在疫情下买菜难的问题，很多公司就迅速推出了买菜App。</p><p>然而与此同时，对于传统企业来说，与上下游客户和供应商合作的数字化需求其实也是在不断增多的。以汽车保险这个行业为例，与车主、4S店、汽车制造商、交管系统等等合作方之间，存在着大量的互联需求，这里面有很多商机。一个有雄心的企业是不可能用一个落后的遗留系统去应对这些挑战的。</p><p><img src=\"https://static001.geekbang.org/resource/image/16/0b/165f49aa7fd90fdaa8133c72c120ea0b.jpg?wh=1920x1253\" alt=\"图片\" title=\"图片来源网络\"></p><p>所以，迎难而上是必须的，让老旧、过时的遗留系统变得现代化也是必须的，这样才能更好地为企业的战略和运营服务。</p><h2>总结</h2><p>总结一下今天的内容。</p><p>我们从业界对遗留系统的定义中总结出了4个关键字：<strong>旧、过时、重要、仍在使用</strong>。然而人们对于遗留系统的认识存在一个普遍的误区，即时间长的系统就是遗留系统。</p><p>事实并非如此。有些系统时间虽长，但如果一直坚持现代化的开发方式，在代码质量、架构合理性、测试策略、DevOps等方面都保持先进性，这样的系统就像陈年的老酒一样，历久弥香。而有些系统虽然刚刚开发完成，但如果在上述几个方面都做得不好，我们也可以把它叫做遗留系统。</p><p>遗留系统在维护成本、合规性、安全性、集成性等方面都会给企业造成巨大的负担，但同时也蕴含着丰富的数据和业务资产。我们应该对遗留系统进行现代化，让它重新焕发青春。</p><p>那么遗留系统的现代化都包含哪些方面呢，<a href=\"https://time.geekbang.org/column/article/506570\">下节课</a>我们就揭晓谜题。</p><h2>思考题</h2><p>如果你现在正工作在遗留系统上，你或你的团队最大的痛点是什么？你们又是如何解决这些痛点的？</p><p>期待你的分享，我们可以在留言区进行互动交流！如果今天的学习让你有所收获，也欢迎把课程分享给有需要的朋友，我们下节课再见！</p>","neighbors":{"left":{"article_title":"开篇词｜你现在所写的每一行代码，都是未来的遗留系统","id":505735},"right":{"article_title":"02 | 遗留系统现代化：遗留系统的四化建设","id":506570}}},{"article_id":506570,"article_title":"02 | 遗留系统现代化：遗留系统的四化建设","article_content":"<p>你好，我是姚琪琳。</p><p>上节课，我们学习了什么是遗留系统，对于老旧、过时，但又十分重要、不可替代的遗留系统，听之任之只会埋下隐患，真正出现问题就为时已晚了。</p><p>不过在动手改造遗留系统之前，我们先要找准方向。其实相比遗留系统“治理”、“改造”，我们更强调的是“现代化（Modernization）”，也就是把遗留系统变为现代化的系统。这也是国际上更通用的提法。用“Legacy System Modernization”这个关键词，在Google上能搜到1380万条结果。</p><p>很多团队在对遗留系统进行“改造”或者“现代化”的时候，往往会陷入一个误区，就是盲目引入各种时髦的新技术，仿佛“新”就代表着“好”，就代表着方向正确。</p><p>比如我们耳熟能详、近年来愈发流行的微服务架构，有些团队也不管自己的项目适不适合，上来就把一个“大泥球”式的遗留系统肢解成了几十个微服务。更有甚者，一个遗留系统拆成了几百个微服务，有些甚至一张表的“增、删、查、改”居然被拆成了四个服务。架构似乎“现代化”了，运维人员却“哭”了。</p><p>那遗留系统现代化的正确方向到底是什么呢？结合上节课的分析，遗留系统在代码、架构、测试、DevOps方面存在诸多问题，我们在此基础上，将代码和测试合并（因为它们说的都是代码的质量），并引入开发团队这个维度，就得到了遗留系统现代化的四个方向：<strong>代码现代化、架构现代化、DevOps现代化和团队结构现代化</strong>。</p><!-- [[[read_end]]] --><h2>代码现代化</h2><p>代码现代化顾名思义，就是把遗留系统中丑陋的“祖传”代码重构成职责清晰、结构良好的优质代码。</p><p>之所以说遗留系统中的代码是“祖传”的，是因为它和其他祖传的东西类似，都是历史悠久、且不敢轻举妄动的。而之所以不敢轻举妄动，就是因为缺乏测试，无法快速验证修改的正确性。而大多数情况下，之所以没有测试，又是因为代码写得不可测。可测试的代码和代码的测试是相互依存的，其中一个做到了，另一个也很容易做到，而如果其中一个没有做到，另一个也必然无法做到。</p><p><strong>因此代码现代化的首要任务，就是对遗留系统的代码进行安全的可测试化重构</strong>。</p><p>在正常情况下，重构应该是在充分的自动化测试的保护下进行的。但对于没有测试的代码，我们只能“硬着头皮”去做一些相对来说比较安全的重构，将代码重构成可以写测试的程度，然后再补上大量的测试，进而在有充分测试覆盖的情况下，进行更广泛更深入的重构。</p><p>后面的课程我还会详细讲解如何进行可测试化重构，但在这里我想先举一个小例子，来让你有个感性认识。比如下面的代码，我想测试if的逻辑，当Dao的方法返回一个null时，这段代码会抛出一个异常。</p><pre><code class=\"language-java\">public class EmployeeService {\n  public EmployeeDto getEmployeeDto(long employeeId) {\n    EmployeeDao employeeDao = new EmployeeDao();\n    // 访问数据库获取一个Employee\n    Employee employee = employeeDao.getEmployeeById(employeeId);\n    if (employee == null) {\n      throw new EmployeeNotFoundException(employeeId);\n    }\n    return convertToEmployeeDto(employee);\n  }\n}\n</code></pre><p>看到这样的代码，你可能会说，这质量还行啊，可读性不错，职责也比较清晰。的确是这样，但这样的代码却是不可测的。因为EmployeeDao内部会访问数据库，从中读取出一个Employee对象。而这个EmployeeDao是在方法内通过new的方式直接构造的，就意味着这个方法对EmployeeDao的依赖是固定的，无法解耦的。</p><p>要知道在单元测试中，我们是不可能直接访问真实的数据库的，因此要想测试这样的方法，只能先对它进行可测试化重构，也就是先将它重构为可测试的代码。</p><p>什么样的代码叫可测试的呢？比如下面这样：</p><pre><code class=\"language-java\">public class EmployeeService {\n  private EmployeeDao employeeDao;\n  public EmployeeService(EmployeeDao employeeDao) {\n    this.employeeDao = employeeDao;\n  }\n\n  public EmployeeDto getEmployeeDto(long employeeId) {\n    Employee employee = employeeDao.getEmployeeById(employeeId);\n    if (employee == null) {\n      throw new EmployeeNotFoundException(employeeId);\n    }\n    return convertToEmployeeDto(employee);\n  }\n}\n</code></pre><p>通过这次重构，我们把会访问数据库的EmployeeDao提取成类的私有字段，通过构造函数传入到EmployeeService中来，在getEmployeeDto方法中，就可以直接使用这个EmployeeDao实例，不用再去构造了。由于传入的EmployeeDao并不是EmployeeService构造的，所以后者对前者的依赖就不是固定的，是可以解耦的。</p><p>如果我们传入EmployeeService的是一个new出来的EmployeeDao，那和原来的方法一样，仍然会去访问数据库；如果传入的是一个EmployeeDao的子类，而这个子类不会去访问数据库，那么getEmployeeDto这个方法就不会直接访问数据库，它就变成可测试的了。比如我们传入这样的一个子类：</p><pre><code class=\"language-java\">public class InMemoryEmployeeDao extends EmployeeDao {\n  @Override\n  public Employee getEmployeeById(long employeeId) {\n    return null;\n  }\n}\n</code></pre><p>这样，想测试原方法中if的代码逻辑就非常方便了。</p><p>这里我们使用的重构手法叫做<strong>提取接缝（Extract Seem）</strong>，至于什么是接缝，以及还有哪些可测试化重构的手法先按下不表，后面课里我会细说，你先有个初步印象就好。</p><p>当代码可测了，我们就可以为它们添加足够的测试，提供质量保障。然后，在测试的保障下进行安全的重构。接下来要做的就是将“祖传”代码重构得让人耳目一新。当代码结构良好了，再实现下一个代码现代化的目标，也就是良好的分层结构。</p><h2>架构现代化</h2><p>遗留系统现代化的第二个方向是架构现代化。看到“架构现代化”这几个字，有些同学很自然地就想到了微服务架构或云原生架构。然而我们前面说过，新不代表正确。在团队的开发能力、DevOps能力和运维能力不足的时候，引入微服务，反而会将团队推向更痛苦的深渊。</p><p>有时候我们常常把软件系统比作一个城市，把系统架构和城市建设做类比。随着城市的发展和扩张，以前处于城市边缘的农村，反而会被周围新建的高楼大厦包裹成为一个城中村。治理这些城中村，就叫“改造老城区”。</p><p>有时候老城区的设计和规划会暴露出一些问题，不足以满足城市的发展。比如市政府通过一些集中的招商引资后，很多企业都要来这里建厂，但老城区显然没有足够的空间。这时候很多城市都会新建一个城区，有些地方叫开发区，有些地方干脆直接就叫新区。我们将这称之为“建设新城区”。</p><p>同样，遗留系统的架构现代化，我们也可以分成“改造老城区”和“建设新城区”两类模式。</p><p><strong>改造老城区模式是指对遗留系统内部的模块进行治理、让模块内部结构合理、模块之间职责清晰的一系列模式。</strong>前端方面包括单页应用注入、微前端等，后端包括抽象分支、扩张与收缩等，数据库端包括变更数据所有权、将数据库作为契约等。</p><p><img src=\"https://static001.geekbang.org/resource/image/03/41/038a1616b382744261c92ed7945e0c41.jpg?wh=3840x1859\" alt=\"\"></p><p><strong>建设新城区模式是指将遗留系统内部的某个模块拆分到外面，或将新需求实现在遗留系统外部的一系列模式。</strong>包括绞杀植物、冒泡上下文等。为了对新建立的新城区予以各种支持，老城区还可以通过提供API、变动数据捕获、事件拦截等各种模式，与新城区进行集成。</p><p><img src=\"https://static001.geekbang.org/resource/image/63/21/63015b42d785dd8328ef1a618624d521.jpg?wh=1920x992\" alt=\"图片\"></p><p>看到这么多专业名词，你可能应接不暇，别担心，后面课里这些内容都会详细展开。总之，只有“改造老城区”和“建设新城区”齐头并进，遗留系统架构的现代化版图才算完整。</p><h2>DevOps现代化</h2><p>代码和架构现代化了，DevOps的现代化也不能落后。它对项目的重要性不言而喻，如果没有现代化的DevOps平台，代码和架构现代化所带来的优势，就无法淋漓尽致地体现出来。</p><p>假如在代码和架构优化后，需求的开发时间缩短了一倍，那么大家对于新需求上线的时间点自然也有新的期待。然而落后的DevOps水平反而会让这个时间变得更长，因为单体架构变成微服务了，DevOps的难度增加了。</p><p>DevOps的历史虽然只有短短十几年，但最近几年的发展势头却很足。大大小小的公司都开始了DevOps转型，很多项目都声称自己建立了持续集成流水线，但实际上很多都是只见其形不见其神，只学其表不学其里。</p><p>而遗留系统的状况就更惨不忍睹了，它们几乎没有任何的自动化，或仅仅是一两句简单的构建命令。像我在第一节课里举的例子那样，在开发机上打包、靠人工用移动硬盘部署的项目还比比皆是。因此，遗留系统的DevOps现代化与其说是一种改进，不如说是从0到1的建设。这一部分可以和代码、架构的治理并行，甚至可以更早。先把平台搭起来，再逐步往上添加内容。对于大多数遗留系统来说，有一个可以对代码进行构建、打包的流水线，就已经是极大的进步了。</p><p>要从头开始搭建一个DevOps平台，包括代码、构建、测试、打包、发布、配置、监控等多个方面。这其中的代码和测试有一部分是和代码现代化重叠的，代码现代化的课里我会一并说给你听。剩下的几个部分再专门用一节课来详细讲述。</p><h2>团队结构现代化</h2><p>如果说代码、架构和DevOps的现代化还好理解的话，那这个团队结构现代化是个什么东西？其实很多时候，一个开发团队的结构是否合理，决定了这个团队的交付效率、产品质量，甚至项目成败，而很多人还没有对此产生足够的重视。</p><p>近年来有一本新书，叫做Team Topologies，中文直译就是团队拓扑。一上市便引起了不小的轰动。它将团队放到了软件开发的第一位，提出了四种团队拓扑结构和三种团队交互模式。四种团队拓扑包括业务流团队、复杂子系统团队、平台团队和赋能团队。三种团队交互模式包括协作、服务和促进。我们在进行开发团队的组织结构规划时，应该参考这四种团队拓扑。去年这本书的中文版——《高效能团队模式》也已经上市了。</p><p>我们对于团队结构的现代化，基本上是围绕这本书的内容展开的。因为我发现，遗留系统中团队的问题，有时比遗留系统本身更大。比如很多遗留系统可能只有一两个人在维护，在他们遇到困难的时候根本得不到团队的支持；再比如一些遗留系统的“老人”对系统比较熟悉，因此任何新启动的专项治理小组都会邀请他们加入，导致这些人的变动十分频繁，上下文切换的成本极其高昂。</p><p>团队拓扑不仅对遗留系统至关重要，对一个新系统如何组建开发团队、团队之间如何沟通协作也是至关重要的，后面我专门用一节课为你详细展开。</p><h2>小结</h2><p>今天我们学习了遗留系统的四个现代化。</p><p>也许你已经发现了，这样做本质上就是<strong>将先进的、现代化的软件开发方法应用到遗留系统上</strong>，让遗留系统重获新生、保持活力。是的，日光之下并无新事。遗留系统之所以成为遗留的，就是因为既缺乏现代化的软件开发方法，又没有随着潮流的发展而不断演进。<br>\n<img src=\"https://static001.geekbang.org/resource/image/c2/e4/c2c9b09b10109abec6189df04a8b5ee4.jpg?wh=9470x7437\" alt=\"\" title=\"遗留系统的四个现代化\"></p><p>遗憾的是，这里还应该引入一个“需求现代化”，但是在权衡之后我将它删除了。因为一个企业里的需求方与开发方是不同的部门，要想进行需求的现代化，必然要让需求部门参与进来。然而国内很多企业的需求部门和开发部门，还无法亲密无间地展开合作。我们甚至有信心对开发部门内部的团队结构进行重组，但却没信心让需求人员改变工作习惯。</p><p>无论如何，在做到代码、架构、DevOps、团队结构四个现代化之后，遗留系统的现代化之路就算基本成功了。不过，在着手对这四个方面进行治理之前，我们还需要先掌握遗留系统现代化的三个原则。即：</p><p>1.以降低认知负载为前提<br>\n2.以假设驱动为指引<br>\n3.以增量演进为手段</p><p>这是我在工作中总结出来的，我们在遗留系统现代化中的许多举措，都符合这三个原则。忽视了它们，四个现代化之路很可能背道而驰。<a href=\"https://time.geekbang.org/column/article/507513\">下节课</a>我们就从修改需求的场景出发，聊一聊为啥要遵循“以降低认知负载为前提”这个原则。</p><h2>思考题</h2><p>感谢你学完了这节课的内容，今天的思考题是这样的：</p><p>你所在的遗留系统架构是什么样的？如果是单体架构，是否打算将其拆分为微服务？打算怎么拆？如果是分布式架构（不一定是微服务），是如何运维的？</p><p>欢迎你在留言区留下你的思考，我们一起交流讨论。</p>","neighbors":{"left":{"article_title":"01｜遗留系统之殇：为什么要对遗留系统进行现代化？","id":505740},"right":{"article_title":"03｜以降低认知负载为前提：为什么遗留系统这么难搞？","id":507513}}},{"article_id":507513,"article_title":"03｜以降低认知负载为前提：为什么遗留系统这么难搞？","article_content":"<p>你好，我是姚琪琳。</p><p>前两节课，我们分别介绍了为什么要对遗留系统进行现代化，以及遗留系统现代化的四个方向和三个原则。从这节课开始，我们将逐一讲解这三个原则。今天先来看看第一个原则：以降低认知负载为前提。</p><p>你可能会问，认知负载对改造遗留系统有什么帮助呢？别着急，学完这节课的内容，你自然就明白了。</p><h2>怎样理解认知负载？</h2><p>作为开发人员，不管是不是工作在遗留系统上，我想你都一定面临过来自业务方或项目经理的灵魂拷问：为什么这个需求这么简单，不过是多一项在下拉菜单，你们却开发这么长时间，要我做绝对不超过半天！言语中透露出一丝对于你工作能力的质疑，或是上班摸鱼的揣度。</p><p>然而实际情况真的如此吗？你恨不得翻出代码逐行展示给他看。来来来，你以为只是下拉框多了一项，实际上前后端都要加上；后端还要改五个服务，有两个我本地从未部署；搭环境调服务就用了一天，改代码修bug又是两天半；别问我为什么修了两天bug，因为实际上服务要改六个；我已经连续加班三个晚上，你要觉得你行下次你上……</p><p>玩笑归玩笑，但类似的battle我相信每个同学都经历过。你在面对这样的质疑时，内心肯定是很委屈的。但是你是否思考过这里面的真正原因？</p><p>你可能会说，是架构不合理，新增一个下拉项要改五六个服务；是DevOps工具不好用或根本没有，在本地部署新服务搭环境要很长时间；是系统知识严重缺失，不知道要改哪些地方以至于漏掉了一个服务……</p><!-- [[[read_end]]] --><p>虽然这些问题确实增加了工作难度，但是对于项目上的老人不是这样啊，他们改起来仍然游刃有余，没部署过的服务也能轻松调通。你可能会辩驳，这是系统太复杂，对新人不友好，而老人都已经熟悉了。</p><p>是的，没错，你说对了。但这里面有个更专业的术语，叫做认知负载。认知负载（Cognitive Load）是认知心理学家John Sweller在上世纪80年代所创建的理论，是指从事一件工作所要使用的脑力劳动的总和。简单来说，就是你可以用认知负载衡量你牺牲了多少脑细胞。</p><p>认知负载一共分为三种类型，内在认知负载、外在认知负载和相关认知负载。对于它们的定义和对比，我汇总了一张表。</p><p><img src=\"https://static001.geekbang.org/resource/image/6a/9b/6a9fdcc5da58e60c384d12ccd57e819b.jpg?wh=4000x1820\" alt=\"\"></p><p>从表中我们可以看到，内在认知负载是你掌握一门技能所必须要付出的努力，虽然不同的技能难度不同，但只要选择了一个，它的大小就固定了，掌握得不够必然就无法胜任工作。外在认知负载是信息的呈现方式，是我们着重要降低的，信息的呈现自然应该越简单越好。而相关认知负载是在构建概念时要了解的知识，是要尽可能增加的，因为这些知识越多越有利于我们的工作。</p><p>也就是说，<strong>我们要完成一项工作，就要在内在认知负载一定的前提下，尽量减少外在认知负载，增加相关认知负载</strong>。以软件开发为例，要完成这项工作，就要在掌握开发技能的前提下，尽量简化与开发需求本身无关的细节，而去了解尽可能多的业务知识。</p><p>看到这里，你就能充分理解为啥架构不合理、DevOps工具不好用以及系统知识匮乏，都会导致你改个“芝麻大”的需求都要加班加点，没错，罪魁祸首就是外在认知负载。</p><p>结合前面的例子，我们逐一分析：一个小需求都要改很多地方，说明模块划分时，可能一起发生变化的部分没有内聚在一起，而是分离到了不同模块和层级，架构向开发者呈现系统的方式过于复杂，增加了外在认知负载；DevOps工具不好用，意味着工具向开发者呈现的部署任务方式太复杂；同理，没人能把一个需求要改哪些地方都说清楚，说明系统知识早已藏身代码深处，不陪葬一把头发深入研究代码，别想拿到这些知识。</p><p>而项目里的“老人们”早已经消化掉了这些外在认知负载。我相信他们在刚加入项目时，也一定经历过你的这些崩溃时刻。</p><p>还有一点就是，有些时候一些知识或实践，看上去在当下增加了外在认知负载，但实际上长远来看，是可以大大降低外在认知负载的。</p><p>比如测试驱动开发，一开始上手的时候，绝大多数开发人员可能都不会写代码了，软件开发的外在认知负载一下子大了很多。但如果你把它当做一项技能（也就是内在认知负载）去不断学习、刻意练习的话，熟能生巧之后，就会大大降低写代码的整体认知负载，而且还提升了软件的质量（因为有很多自动化测试），降低了业务知识获取的难度（测试可以看成是有效的文档）。</p><h2>遗留系统中的认知负载</h2><p>那么遗留系统中的外在认知负载都有哪些呢？第一节课我们介绍过遗留系统的特点，代码质量差、架构不合理、测试不充分、DevOps水平低，其实都会导致外在认知负载增加。</p><p><strong>不过，遗留系统最大的认知负载其实是无处可寻的业务知识。</strong>我们第一节课介绍过，遗留系统中的蕴含着丰富的业务资产，但由于种种原因，导致这个资产并不那么容易获得。</p><p>遗留系统在构建的时候，往往会有成百上千页的需求、设计文档，这些的确能准确描述当时的系统状态。然而随着时间的更迭、需求的演化，当前的系统已经和构建时不可同日而语，且不同阶段的文档往往无法很好地保留下来，这就造成了业务知识的缺失。</p><p>即使所有文档都保存完好，也很难有人能完完整整地阅读下来。而且，也没有人能保证系统的实现和文档的描述是完全吻合的。</p><p>你可能会问，不是还有人吗？去问问需求人员或者业务分析人员啊。遗憾的是，对于时间不太长的遗留系统，也许还能找到人，但稍长一点的，可能人影都找不到了。有的离职了，有的升职了，有的可能是第三方供应商开发的，现在已经不合作了。即使有些知识可以在开发人员之间口口相传下来，但是也是严重失真的，没人能确保它的正确性。</p><p>下图是事件风暴的发明者Alberto Brandolini在讲述知识的分布时用到的图，我想它也同样适合描述知识传递过程。结合图片可以看到，有些知识只有曾经工作在它上面的某一个人知道，有些知识得去问Bob，而有些知识就像一个谜。</p><p><img src=\"https://static001.geekbang.org/resource/image/eb/21/eb807c20f9bb7b0d25dd9b23ab0bf521.jpg?wh=1920x1016\" alt=\"图片\"></p><p>如果系统中包含自动化测试，尤其是那种描述一个端到端业务的自动化测试，某种意义上是可以被看作有效文档的。但对于遗留系统来说，这样的测试太罕见了，不提也罢。</p><p>很明显，想通过历史文档、咨询相关者，以及自动化测试等手段理清业务，都不靠谱。其实，要想捋清一个遗留系统的业务，唯一有效的方式就是“扒代码”。</p><p>把代码掰开揉碎了仔细阅读，弄清楚每一行的意图，直到搞清楚这一块代码所要表达的业务逻辑。但这种方法同时又是非常低效的，因为遗留系统的代码质量往往惨不忍睹，想靠人工的方式来梳理代码理清业务，是几乎不可能完成的任务。</p><p>经过这一番描述，你应该弄清楚了遗留系统中业务知识难以获取的原因。因为它们是以“质量很差的代码”这种形式向人呈现出来的，因此有着非常高的外在认知负载。</p><p>这里你可能会有疑问，前面不是还说业务知识是相关认知负载，需要增加吗？这里为什么又说业务知识是遗留系统最大的认知负载，需要降低呢？其实这里说的，隐藏在遗留系统隐秘角落的业务知识，是指它们呈现的方式不友好，提高了外在认知负载，而这恰恰是我们需要降低的。</p><p><strong>遗留系统的第二大认知负载，是同样难以获取的系统知识</strong>。这里的系统知识是指系统的具体实现细节，包括模块的划分、架构的取舍，以及每一个技术决策的原因。这些知识也同样很难有文档可以一窥究竟，更遗憾的是，连代码都无法体现出每一个细节。</p><p>给我印象深刻的是我曾经治理的一段代码，有一行用Thread.sleep(5000)等待了5秒钟。我问遍团队的每一个人，都不知道这行代码的用意，于是就当做无用代码删掉了。没想到几天之后系统崩溃了，原来这行代码的前面几百行，有一处调用链很深的代码触发了一个后台任务，等待5秒钟的目的就是等这个后台任务跑完，然后后面的代码就可以用这个后台任务所生成的数据了。删掉这行等待代码，后续的代码就失败了。</p><p>还记得我第一节课的吐槽吗？糟糕的代码各有各的糟糕之处。但这段代码的问题并不在于它有多糟糕，而是在于没有人知道它为什么糟糕。这种代码存在于系统之中，就带来了非常高的外在认知负载。</p><p>这些高认知负载的系统知识，会导致我们的需求开发走向“魔改”。所谓“魔改”，就是魔幻般地修改，这种情况下，没人能说清楚一个新需求应该改哪里，更没法保证改了这些，是否就覆盖了全部要改的内容。</p><p>至此，我们已经知道了遗留系统之所以这么“难搞”，就是因为过高的外在认知负载。人们在遗留系统上工作的时候，所付出的脑力劳动比正常系统要多得多，因此只要能大致测试通过，就会凑合着上线，而没有精力去偿还欠下的债务、改善外在认知负载。如此恶性循环，导致遗留系统的外在认知负载越来越高，修改起来越来越难。</p><p>我们进行遗留系统的整治，其实就是要尽力降低遗留系统的外在认知负载。外在认知负载降低了，开发起来容易了，痛点自然就解决了。</p><h2>以降低认知负载为前提</h2><p><strong>以降低外在认知负载为前提的意思就是，我们进行遗留系统现代化时，所做的任何举措都应该是能够降低外在认知负载的</strong>。</p><p>现在回顾<a href=\"https://xn--yfr16a528c0pp4fap15gjp7o\">第二节课</a>的“四化建设”——代码现代化、架构现代化、DevOps现代化和团队结构现代化，你会发现这四大方向其实都有利于降低团队外在认知负载。</p><p>比如对代码进行重构、改善代码的可读性，可以降低阅读代码的难度，实际上就是降低代码的认知负载；对单体架构进行拆分，分解成多个小的、更加内聚的微服务，每个服务可以独立部署和演进，实际上就是在降低业务和系统的认知负载；还有优化持续集成流水线，让开发人员提交代码之后就不必随时关注后续的步骤，轻装上阵；再比如对团队结构进行优化，让每个团队只关注少量大小适中的业务模块，以降低认知负载。</p><p>没错，降低认知负载这一原则不光能作为方向指引，落到微观操作层，同样能帮助你科学预判改造过程中的每个决策。</p><p>比如在进行微服务拆分时，是应该先对代码进行模块化分解，再进而拆分出独立的服务，还是应该直接拆分出服务，再对耦合的部分进行解耦呢？代码分层改造时，是应该改造成分层架构，还是六边形架构或整洁架构呢？优化分支策略时，是应该基于主干开发，还是应该使用特性分支呢？前端应该改造成React还是Vue？改造过程如何回退？</p><p>在遗留系统现代化的过程中，如果以常规的技术视角去看待上述问题，可能很多类似的技术决策都很难找到具有说服力的依据，最后只好拍拍脑袋，随便决定一个，或者看架构师自己的喜好。实际上只要我们掌握了“降低外在认知负载”这个原则，我们就可以把技术性的问题轻松转换成人的问题，然后去分析看看，到底哪个选项更有利于降低团队的认知负载，更容易被团队所接受，更容易实现。</p><p>很多时候，遗留系统的现代化项目以失败告终，或举步维艰，都是因为很多决定和举措非但不能降低认知负载，反倒增加了认知负载。以高认知负载的方案去解决高认知负载的问题，最终必将导致项目做不下去，人也疲惫不堪。</p><p>其实<strong>不止是遗留系统现代化，我们所有的工作都应该尽量去降低外在认知负载，从而简化工作本身</strong>。</p><p>比如敏捷开发方法就是一套很好的可以降低外在认知负载的方法。几个月甚至几年的交付周期，所承载的内容会让人不堪重负；而只有两周的迭代，则能让人轻装上阵。一份动辄几百页的需求文档，会让人不知所措；而只有一两页的故事卡，则能让人更轻松地聚焦于眼前的工作。</p><p>领域驱动开发（DDD）也是行之有效的降低外在认知负载的方法论。形成统一语言、拆分限界上下文，都是为了使沟通更加容易、工作更加聚焦。还有目前大厂比较流行的研发工程效能，其本质说白了也是为了降低外在认知负载。</p><p>从这个角度出发，灵活应用这个原则，以前很多悬而未决的疑难杂症，很多靠“视情况而定”、“具体问题具体分析”等“托词”搪塞过去的问题，是不是一下子就豁然开朗了？</p><h2>总结</h2><p>总结一下今天的内容。我们介绍了认知负载的三个分类：内在认知负载、外在认知负载和相关认知负载。我把它们的特点以及和软件开发特别是遗留系统的关系总结一下，方便你复习：</p><ul>\n<li>内在认知负载是指从事一项工作必须付出的努力，比如学习Java知识、前端知识等；</li>\n<li>外在认知负载是指知识呈现的形式，代码越糟糕、越难读，外在认知负载越高；</li>\n<li>相关认知负载是指人们要学习一个知识所要付出的努力，在软件开发领域就特指业务知识。<br>\n<img src=\"https://static001.geekbang.org/resource/image/ce/8e/ce4b36145ce6ca0f6f5da1e139a3208e.jpg?wh=1920x991\" alt=\"图片\"></li>\n</ul><p>其中，外在认知负载是我们最痛恨的，一定要尽可能地降低。我们在做遗留系统现代化的时候，所有的决策在制定之前都要思考一下，是否有利于降低当前的外在认知负载。可以说，将遗留系统的外在认知负载降到最低，遗留系统的现代化工作也就完成了。</p><p>为了方便后面课程的讲述，我将统一用“认知负载”来代替具体的分类。至于到底是哪一种类型的认知负载，就不是那么特别重要了。你只需要判断一下，<strong>当前这个事物、活动、决策所增加的认知负载是否更有利于我们完成当前和以后的工作</strong>。如果有利（比如学习更多的业务知识），就增加这种认知负载；如果不利（比如读一篇晦涩难懂的需求文档），就减少这种认知负载。</p><p><a href=\"https://time.geekbang.org/column/article/508559\">下一节课</a>我们就来看看在遗留系统中，如何来降低业务知识和系统知识难以获取的认知负载。</p><h2>思考题</h2><p>感谢你认真学完了这节课的内容，今天的思考题是两道开放式的问题：</p><p>1.你项目上的分支策略是什么样的？是基于主干开发，还是特性分支，或者其他分支策略？你认为哪种方式更能降低外在认知负载？</p><p>2.你项目上的哪些实践是有意无意地降低了外在认知负载的？又有哪些实践增加了外在认知负载？</p><p>欢迎你在留言区留下你的思考，我们一起交流讨论。也欢迎你把这节课分享给其他工作在遗留系统上的朋友，让我们一起帮助他们走出泥潭。</p>","neighbors":{"left":{"article_title":"02 | 遗留系统现代化：遗留系统的四化建设","id":506570},"right":{"article_title":"04 | 如何降低认知负载：活的文档能救命","id":508559}}},{"article_id":508559,"article_title":"04 | 如何降低认知负载：活的文档能救命","article_content":"<p>你好，我是姚琪琳。</p><p>在第三节课，我带你了解了认知心理学中的一个概念——认知负载。这个看似与软件开发毫无瓜葛的知识，实际上却决定了软件系统的成败。因此在遗留系统现代化中，我们把“以降低认知负载为前提”作为首要原则。</p><p>有些同学这时就会问了，你总说认知负载如何如何，降低认知负载又是多么重要，那怎么才能真正降低认知负载呢？别着急，我们今天就来看看有哪些方法能降低认知负载。其中最重要的工具，就是活文档。</p><h2>什么是活文档</h2><p>活文档（living document），顾名思义，就是指活着的文档，也就是<strong>在持续编辑和更新的文档，有时候也叫长青文档或动态文档。</strong>比如维基百科中的一个词条，随时都有人更新和维护，这就是一个活文档。与之相对的是静态文档，也就是一旦产生就不会更新的文档，比如大英百科全书中的一个条目。</p><p>你可以想象一下，在软件开发过程中，无论是瀑布模式还是敏捷，我们拿到的需求文档或故事卡是“维基百科”还是“大英百科”呢？我想大多数情况可能是，在最终需求还没有敲定时还是“维基百科”，也就是还会随时更新，而一旦敲定开始开发后，就变成了“大英百科”，再也不会更新了吧。</p><p>然而随着需求的不断叠加，“大英百科”作为当时系统的一个“快照”，早就已经失去了时效性。只有将不同时段、不同模块的文档片段合并在一起，才能得到当前系统的快照。但这个合并放在现实中是很难操作的。</p><!-- [[[read_end]]] --><p>正是因为发现了这样的问题，《实例化需求》一书的作者Gojko Adzic将活文档的概念引入到了软件开发当中；而去年出版的《活文档——与代码共同演进》一书，又在此基础上对活文档如何落地做了系统指导。我强烈建议你读一下这两本书，虽然它们的出版相隔近10年，但讲述的内容却一样非常有帮助。</p><p><img src=\"https://static001.geekbang.org/resource/image/bf/3f/bff365a6ea8e9f2207acdb03cd25123f.jpg?wh=1920x1168\" alt=\"图片\"></p><h2>如何用活文档挖掘业务知识</h2><p>了解了活文档的概念，我们来看一下它是如何降低遗留系统的认知负载的。</p><h3>为遗留代码添加注解</h3><p>先来看看下面这段虚构的遗留代码（抱歉我实在编不出更糟糕的代码了……），在没有任何文档的情况下，我们如何理解这段代码的意思呢？</p><pre><code class=\"language-java\">public class EmployeeService {\n  public void createEmployee(long employeeId) { /*...*/ }\n  public void updateEmployee(long employeeId) { /*...*/ }\n  public void deleteEmployee(long employeeId) { /*...*/ }\n  public EmployeeDto queryEmployee(long employeeId) { /*...*/ }\n  public void assignWork(long employeeId, long ticketId) {\n    // 获取员工\n    EmployeeDao employeeDao = new EmployeeDao();\n    EmployeeModel employee = employeeDao.getEmployeeById(employeeId);\n    if (employee == null) {\n      throw new RuntimeException(\"员工不存在\");\n    }\n    // 获取工单\n    WorkTicketDao workTicketDao = new EmployeeDao();\n    WorkTicketModel workTicket = workTicketDao.getWorkTicketById(ticketId);\n    if (workTicket == null) {\n      throw new RuntimeException(\"工单不存在\");\n    }\n\n    // 校验是否可以将员工分配到工单上\n    if ((employee.getEmployeeType() != 6 &amp;&amp; employee.getEmployeeStatus() == 3)\n          || (employee.getEmployeeType() == 5 &amp;&amp; workTicket.getTicketType() == \"2\")) {\n      throw new RuntimeException(\"员工类型与工单不匹配，不能将员工分配到工单上\");\n    }\n\n    if (!isWorkTicketLocked(workTicket)) {\n      if (!isWorkTicketInitialized(workTicket)) {\n        throw new RuntimeException(\"工单尚未初始化\");\n      }\n    }\n    \n    // ...\n  }\n\n  public void cancelWork(long employeeId, long ticketId) { /*...*/ }\n}\n</code></pre><p>如果每个方法都很长，这样一个类就会愈发不可读，从中理解业务知识的难度也越来越大，这就是我们上节课提到的认知负载过高。</p><p>如果把这种代码转化为下面的脑图，是不是一下子就清晰许多了呢？</p><p><img src=\"https://static001.geekbang.org/resource/image/7f/c0/7f5908e2cef28e5063d855207648f4c0.jpg?wh=1920x1371\" alt=\"图片\"></p><p>阅读代码时，我们是以线性的方式逐行阅读的，这样的信息进入大脑后，就会处理成上面这样的树状信息，方便理解和记忆。但当代码过于复杂的时候，这个处理过程就会需要更多的脑力劳动，导致过高的认知负载。</p><p>我们可以通过在代码中加入活文档的方式，来降低认知负载。其实要得到上面的脑图，只需要在代码中加入一些简单的注解：</p><pre><code class=\"language-java\">@Chapter(\"员工服务\")\npublic class EmployeeService {\n  @Doc(\"员工创建\")\n  public void createEmployee(long employeeId) { /*...*/ }\n  @Doc(\"员工修改\")\n  public void updateEmployee(long employeeId) { /*...*/ }\n  @Doc(\"员工删除\")\n  public void deleteEmployee(long employeeId) { /*...*/ }\n  @Doc(\"获取员工信息\")\n  public EmployeeDto queryEmployee(long employeeId) { /*...*/ }\n  @Doc(\"给员工分配工单\")\n  public void assignWork(long employeeId, long ticketId) { /*...*/}\n  @Doc(\"撤销工单分配\")\n  public void cancelWork(long employeeId, long ticketId) { /*...*/ }\n}\n</code></pre><p>然后，我们编写一个工具，它可以基于这些注解来生成根节点和二级节点，并将方法中抛出的异常作为叶子节点。</p><p>这么做的原因是，虽然遗留系统中的很多文档和代码注释已经不是最新的了，但这些异常信息往往会直接抛出去展示给用户看，是为数不多的、可以从代码中直接提取的有效信息。</p><p>当然这样做也有一定局限性，因为异常信息中可能包含一些运行时数据。比如“ID为12345的员工不存在”这样的异常信息，是由“ID为 + employeeId + 的员工不存在”这样的字符串拼接而成，静态扫描字节码，是无法得出这些运行时数据的。但即使只在叶子节点中显示“ID为 %s 的员工不存在”这样的信息，也已经非常有用了。</p><p>通过这样的工具，我们可以把一个非常复杂的业务代码，转化为下面这样的脑图（为了过滤掉敏感信息，我故意将图片做了模糊处理）。</p><p><img src=\"https://static001.geekbang.org/resource/image/3f/28/3fa116f8091ed99234edc4f2ef21bb28.jpg?wh=574x506\" alt=\"图片\"></p><p>这段业务代码总共有5000多行，一行一行地去阅读代码会让人抓狂，但有了这样的脑图，认知负载简直降低了一个数量级。</p><p>看到这里，你一定对这个工具十分感兴趣了。但是很遗憾，这个自研的工具目前还没有开源。一旦开源，我将在专栏写一篇加餐，详细介绍这个可以解救你于水火的工具。</p><p>不过它的原理其实十分简单，想必你也已经猜到了，就是扫描Java字节码，获取到用注解标记的代码，然后再进一步分析得到异常信息，组织成树形结构，再生成一些中间文档，并通过一些绘图引擎绘制出来。</p><p>在实际操作过程中，只需要有一个人通读一次代码，哪怕花上几个礼拜的时间，但只要能理出一个业务模块的基本逻辑，添加上注解，就可以通过图形化的方式来展示代码结构。其他人不需要再次这么痛苦地阅读代码了，可谓一劳永逸，效率会大大提升。</p><p>这么做还有一个好处是，当新的需求来临时，开发人员可以迅速定位到要修改的地方，不需要再去扒一遍代码了。传统的代码和文档最大的问题是，代码是代码，文档是文档，彼此分离。</p><p>代码和文档的关联关系储存在开发人员脑子里，这样认知负载比较高。当开发人员看到一份新的需求文档时，需要搜索一下脑子里的记忆，才能想起来这部分内容是在代码的什么位置。</p><p>然而人脑不是电脑，这种记忆是十分不靠谱的，搜索定位的过程也十分低效。而上面这样的脑图就和代码很好地结合了起来，可以说找到文档，就找到了代码，非常有效地降低了认知负载。</p><p>这么做的第三个好处是有利于团队协作。业务分析师、开发人员、测试人员都可以围绕这样一份文档来讨论需求、设计测试用例。</p><h3>实例化需求最好的工件就是活文档</h3><p>除了在代码中添加注解，并分析代码生成各种可视化的图表之外，用实例化需求的方式编写的测试也是一种活文档。所谓实例化需求，实际上指的是<strong>以现实中的例子来描述需求，而不是抽象的描述</strong>。</p><p>怎么理解呢？在生活中我们会遇到很多文字描述，比如产品说明书、合同文本、法律法规等。这些描述大多数时候都是抽象的，普通人读起来很难理解，甚至引起歧义。如果抽象的说明能够配几个具体的示例，认知负载就会大大降低。软件开发中的需求描述也是如此。</p><p>让我印象非常深刻的是，在刚加入Thoughtworks没几天的时候，曾经跟着BA和其他开发人员找客户对一个关于用户权限的需求，大概是不同的用户在不同的场景下，能看到一个页面中的哪些字段。</p><p>那位BA没有像我之前见过的BA那样，写一大篇文档，而是简单地把界面打印了出来了好几张，每张纸上注明场景，用马克笔把不能看到的字段打个大叉划掉。</p><p>就这样，他用最简单的方式，在5分钟内就快速确认了所有的需求，客户也对这种直观的方式非常满意。这些纸随后就给了我们开发人员，我们根本没必要再去看需求文档了，因为需求已经以如此实例化的方式展示给我们了。</p><p>这就是典型的实例化需求。我们在开发时，可以将这种需求转换为测试，这种以实例化方式描述的测试，也是一种活文档。它们不但很好地展示了业务知识，而且是随代码更新的。</p><p>比如上面的给员工分配工单的例子，按实例化需求的方式，可以写出一系列组织良好的测试，如下所示：</p><pre><code class=\"language-java\">@Test\npublic void should_be_able_to_assign_work_to_an_employee() {}\n@Test\npublic void should_not_assign_work_to_when_employee_not_exist() {}\n@Test\npublic void should_not_assign_work_when_ticket_not_exist() {}\n@Test\npublic void should_not_assign_work_when_employee_type_and_ticket_type_not_match() {}\n@Test\npublic void should_not_assign_work_when_ticket_is_not_initialized() {}\n</code></pre><p>怎么样？是不是一目了然？其实我们就是将需求文档的描述转换成了测试的方法名。</p><p>读到测试，就相当于读到了需求文档；测试通过，就相当于需求完成了。以后如果需求有了变更，只需要同步修改测试的名称即可。这时候，测试是和代码共同演进的，也就是活文档。</p><p>在某些框架下运行上面的测试，还能帮我们去掉中间的下划线，这就更像是文档了。如果愿意，你还可以用中文去写方法名，阅读起来会更友好，尽管我强烈建议不要这样做。我们在后面讲到代码现代化的时候，再来详细讨论单元测试如何编写和组织。</p><p>如果一个遗留系统的每个功能都具有这样的测试，那么业务知识也就不再难以获得了，整个系统的认知负载也没有那么高了。</p><h2>用依赖分析工具展示系统知识</h2><p>工具除了能挖掘业务知识，还能揭示系统知识。我们在<a href=\"https://time.geekbang.org/column/article/507513\">上一节课</a>讲过，遗留系统的两大认知负载，是无处可寻的业务知识和难以获取的系统知识。经过多年的腐化，类与类之间、包与包之间、模块与模块之间、服务与服务之间分别是什么样的依赖关系呢？</p><p>这就好像我们来到一个陌生的城市时，对这个城市的行政区域、大街小巷都不了解。如果我们想从一个地方到另一个地方，应该怎么办呢？最好的办法就是搞一张当地的地图（当然你也可以用地图App），有了地图的指引，就不会迷路了。</p><p>同样，我们可以通过<strong>依赖分析工具</strong>，建立一张遗留系统的地图，这样就可以快速知道一个业务是由哪些模块组成的。市面上存在很多做系统依赖分析的工具，如Backstage、Aplas、Honeycom、Systems、Coca等等。感兴趣的同学可以去了解一下。</p><p><img src=\"https://static001.geekbang.org/resource/image/f3/19/f3dc7f21a847c81fd95dc335751dbc19.jpg?wh=1920x1263\" alt=\"图片\" title=\"图片来自Aplas官网\"></p><p>但我们也会发现，有时这些工具并不能解决我们的全部问题。比如在做系统的数据拆分时，我希望知道一个API调用都访问了哪些表，从而评估工作量。这种定制化的需求很多工具都无法满足，不过不要灰心，发挥我们开发人员优势的时候又到了。没有轮子，我们就造一个出来。</p><p>其实这种根据入口点获取表名的逻辑并不复杂，只需要遍历语法树，把所有执行SQL语句的点都找出来，然后分析它的语句中包含哪些表就可以了。</p><p>对于<strong>存储过程或函数</strong>，我们也可以找到执行它们的点，获得存储过程或函数的名称，然后再根据名称找到对应的SQL文件，再做类似的分析。当然，这要求我们首先要治理好编写在数据库中的存储过程和函数治理，将DDL（Data Definition Language）迁移到代码库中，进行版本化。这样分析工具定位起来才方便。</p><p>对于<strong>复杂的入口方法</strong>，你可能会得到一幅相当大的列表或脑图，它虽然能列出全部内容，但读起来仍然很费劲。这时候我们有两个办法。一是重构复杂的入口方法，抽取出若干小的方法，再以小方法为入口点做分析。二是修改分析工具，直接分析存储过程或函数。如果存储过程或函数过大，也可以进一步拆分。</p><p>除此之外，我们还可以提出很多有用的需求，继续改进分析工具。比如分析不同模块之间所依赖的对方的表有哪些，这对于数据拆分也是非常有帮助的。</p><h2>总结</h2><p>今天我们学习了降低认知负载的一种非常有用的方法：活文档。很多同学可能是第一次听说这个概念，但如果你的项目里用实例化需求的方式去组织单元测试，你其实已经在使用活文档了。</p><p>虽然遗留系统中可能没有太多的测试，但我们仍然可以通过向代码中添加注解的方式来编写活文档，并通过工具来实现图形化展示，将遗留系统中无处可寻的业务知识暴露在你面前。</p><p>除此之外，我们还可以使用依赖分析工具来挖掘系统知识，同样也可以用图形化的方式来帮助我们理清系统内的依赖关系。这对我们开发新需求或推动代码和架构的现代化都非常有帮助。</p><p>能够降低认知负载的方法、工具和实践还有很多，我们后面的课再慢慢介绍吧。</p><p>《活文档》这本书在介绍遗留系统的“文档破产”时，是这样描述遗留系统的，我也想把这段话分享给你：</p><blockquote>\n<p>遗留系统里充满了知识，但通常是加密的，而且我们已经丢失了秘钥。没有测试，我们就无法对遗留系统的预期行为做出清晰的定义。没有一致的结构，我们就必须猜测它是如何设计的、为什么这么设计以及应该如何演进。没有谨慎的命名，我们就必须猜测和推断变量、方法和类的含义，以及每段代码负责的任务。</p>\n</blockquote><p>虽然遗留系统是“文档破产”的，是“加密”的，但是只要我们掌握了活文档这个“破译工具”，就可以一步一步破解出那些隐匿在系统深处的知识。</p><h2>思考题</h2><p>感谢你学完了这节课的内容。我想此刻的你，一定会对课程中提到的活文档工具十分感兴趣。今天的思考题就请你来分享一下，如果是你，会如何设计和开发这样的一个工具呢？</p><p>欢迎你在评论区留下你的观点，我会尽量回复你们的问题。也欢迎你把文章分享你的朋友和同事，让我们一起来降低认知负载。</p>","neighbors":{"left":{"article_title":"03｜以降低认知负载为前提：为什么遗留系统这么难搞？","id":507513},"right":{"article_title":"05 | 以假设驱动为指引：如何评价遗留系统的现代化成果？","id":509535}}},{"article_id":509535,"article_title":"05 | 以假设驱动为指引：如何评价遗留系统的现代化成果？","article_content":"<p>你好，我是姚琪琳。</p><p>前两节课，我们学习了遗留系统现代化的第一个原则：以降低认知负载为前提，以及能够显著降低认知负载的利器——活文档。今天我们就来看看遗留系统现代化的第二个原则：<strong>以假设驱动为指引</strong>。</p><p>我们很多人在做遗留系统现代化的时候呢，总觉得它是一个十分复杂的技术问题。本来嘛，无论是代码的重构、架构的拆分，还是DevOps平台的搭建或技术栈的升级，无一不是技术活动。</p><p>下面我来分享一个我早年间的经历，看看能不能颠覆你的想法。</p><h2>脱离业务的技术改进都是耍流氓</h2><p>十年前，我曾经试图去主导一次技术改进，希望将一个遗留系统上的JDK从1.4升级到5。你可以想象一下，使用Java 1.4开发是一个什么样的情形，没有stream、没有泛型，甚至没有枚举，实现一个简单的功能都需要好几行代码（当然现在的Java也没好到哪去……），在这样的项目上工作简直痛不欲生。</p><p>我当时做了充分的调研，制定了详细的计划，以确保升级过程的平滑。然而这样一个看起来很“正常”的改进却被部门领导叫停了。</p><p>他的理由是，系统刚刚上线不久，一两年内不会有很多的新需求，旧JDK导致的开发痛点并不明显。而业务方也没有明确提出，未来要提升开发效率以支撑更多的需求。所以，这样的改进，虽然看上去在技术上十分必要，但在业务上优先级却没那么高。</p><!-- [[[read_end]]] --><p>这番话一语点醒梦中人。在“怎么改”这件事儿上，我当时的确做了不少功课，但偏偏“要不要改”这个关键问题脱离了业务，所以成了单方面的“技术自嗨”。这种改进虽说从技术上看十分必要，但业务上优先级却没那么高。</p><p>这个翻车案例告诉我们，<strong>技术要为业务服务。</strong>业务不需要的话，技术升级没有任何意义。做好了，业务方面也感知不到；做不好，很有可能导致项目失败，可谓费力不讨好。</p><p>那么，到底如何做，才能让技术更好地为业务服务呢？</p><p>如果一个遗留系统平时用的人不多，需求也不多，一两个开发人员完全能够应付得来，这种情况还需要技术的更新换代吗？其实对于这样的系统，最好的方案就是保持原样，根本不需要做什么升级和优化，因为它所带来的业务价值太小，投入产出比过低。</p><p>但面对使用人数众多、需求纷至沓来的遗留系统，想要让业务方充分感知到技术迭代带来的好处，又该怎么办呢？这时候假设驱动的方法就派上用场了。我们先说说假设驱动是什么，又该怎样应用。</p><h2>什么是假设驱动？</h2><p>假设驱动实际上是一种科学的研究方法，在面对一个问题时，我们先要分析问题，然后试着提出一种阐述或者假设，去解释我们的发现。接着就到了实验环节，如果实验结果满足假设，就证明我们的理论是正确的。</p><p>假设驱动的思想在数学、物理、生物等科学领域都是十分常见的方法，比如哥德巴赫猜想、量子力学等，最初都是通过假设的方式提出来，并在后期通过实验加以证明或验证的。</p><p>实验是科学研究的基础，但并不是只有在实验室里才能做。在软件开发领域，我们同样可以做实验，这就是<strong>假设驱动开发（Hypothesis-Driven Development，简称HDD）</strong>。</p><p>《持续交付》的作者Jez Humble曾经说过：</p><blockquote>\n<p>“验证业务模式或产品理念的最低效的方法，是构建完整的产品以查看设想中的需求是否真实存在”。</p>\n</blockquote><p>我们在构建一个产品或功能之前，应该先扪心自问：“我们应该构建它吗？理由是什么？”然后开展最廉价、最快速的实验，通过用户研究，验证设想的功能是否会产生预想的业务成果。</p><p>在一个产品处于探索、复杂和不确定的阶段时，我们更需要的是假设，而不是传统的需求。也就是说，我们假设一个功能上线之后会得到一个什么样的结果，然后等功能上线后，再去验证是否得到了这样的结果，从而得出结论和提取知识。</p><p><img src=\"https://static001.geekbang.org/resource/image/bf/60/bf108d0f6034379c385e884c3ee06160.png?wh=1400x761\" alt=\"图片\"></p><p>我们可以看到，以假设驱动的方式去构建产品，可以将用户的反馈纳入到开发过程中来，让每一个需求的效果都可以度量。</p><p>比如对于一个电子商城的App，我们假设如果在商品的展示页面中加入视频功能，商品的销量就会增加10%。之后我们就开始开发视频功能，上线之后通过A/B测试做实验对比，看看是否加入了视频功能的商品，销量真的会增加10%。</p><p><img src=\"https://static001.geekbang.org/resource/image/12/46/121e2d8f47d3ac3d118968b5f1a22a46.jpg?wh=1920x1457\" alt=\"图片\"></p><p>你可能会说，我公司的商品展示页面也有视频功能，但就是按照普通需求去开发的，这跟假设驱动开发的方式有什么区别吗？其实区别是很明显的。</p><p>一个需求总是要解决一个业务问题的，电商平台不会平白无故开发一个视频功能，背后要解决的问题，就是提升商品销量。但以普通需求的方式提出来，我们就不会特意做度量，等到上线后发现没达成这个目标，也就不了了之了。</p><p>你可以回忆一下，你所在的系统中，有多少费时费力开发完但却没人用的功能？它们中大多数都是因为没达成预想的假设。这是巨大的浪费。</p><p>而<strong>如果以假设驱动的方式进行开发，我可以在某个方向上快速验证，如果假设不成立，就立即止损，不再追加投资。这样整个过程就显得十分精益了</strong>。</p><p>还拿商品页的视频功能为例，我可以先开发一个极其简单的版本快速上线，在对比发现真的对销量有提升效果后，再来逐步优化整个方案，比如延长视频时间、提高视频清晰度，甚至把直播带货时该商品的介绍剪辑下来，放到商品页等等。这样不断迭代，每一步都通过假设驱动，并不断验证假设，得到能带来最多客户价值的方案。</p><h2>在遗留系统中应用假设驱动开发</h2><p>既然新功能开发上，我们可以借助假设驱动实现“多快好省”，那遗留系统现代化是不是同样适用呢？答案是肯定的。</p><p>在遗留系统现代化的过程中，我们接收到的任务，呈现形式往往也是需求或者故事卡，得到的也都是一个技术结果而不是业务结果。比如重构某段代码来提升可读性，或者添加测试来提高某个模块的单元测试覆盖率。这样的技术任务是很难验收的，而且上线之后，业务方无法很容易地感知它所带来的价值。</p><p>这时我们可以将假设驱动开发引入到遗留系统现代化中来，将那些以“As…I want…So that…”或“Given…When…Then…”编写的故事卡和验收条件，改为下面这种形式：</p><blockquote>\n<p>我们相信&lt;某个功能&gt;<br>\n将&lt;产生某种结果&gt;<br>\n当&lt;我们看到某种可度量的信号&gt;时，我们就有信心沿着这个方向继续下去</p>\n</blockquote><p>举个例子来说就是：</p><blockquote>\n<p>我们相信，为&lt;库存模块添加单元测试&gt;<br>\n将&lt;提升库存模块的内建质量&gt;<br>\n当&lt;我们看到库存模块新需求的bug数量连续三个月降低&gt;时，我们就有信心沿着这个方向继续下去</p>\n</blockquote><p>你看，如果只添加单元测试，而不拿出添加完测试后的数据，业务方就无法直观看到这样做的好处，这样的改进也很难获得他们认可。但如果我拿着一份图表，向业务方展示连续三个月降低的bug数，他们一定会非常开心，并支持我们的下一步计划。</p><p>在开发软件时，我们主张<a href=\"https://time.geekbang.org/column/article/268129\">关注成效而非产出</a>，在遗留系统现代化过程中，同样也应该关注成效，而不仅仅是做了哪些改进。在上面的例子中，添加完测试后的测试数量和覆盖率就是产出，而bug数降低就是成效。</p><p>如果只注重产出，我们就会更关注团队都完成了哪些技术改进，考核维度是工作量。这样能快速完成的工作优先级会更高，改进带来的业务价值反而被忽视；但如果注重成效，我们更关注改进如何服务于业务，考核维度变成某项改进，在多大程度上能<strong>提高用户效率</strong>，并在上线后关注相关指标的变化。</p><p>关注成效，不但可以激励我们去找出可以衡量业务价值的指标，也能帮助我们避免一些价值不大的技术改进。</p><p>还拿添加单元测试举例，如果只是为了产出，那我们关注的就是提高测试数量和测试覆盖率，当这样的度量指标，落到团队头上去真正执行时，他们就会想出一些匪夷所思的方式。</p><p>比如给Java类的getter/setter添加测试，那产出的测试数量是惊人的，但却对降低bug数量完全没有任何帮助，是毫无价值的。这就像如果用代码行数去评价开发人员的工作，就会多出很多无用代码一样。</p><p>说到这，我们明确了关注成效的必要性，下一步就是把“成效”转化成更明确的指标，这样才能更好地建立假设。</p><h2>明确目标和度量指标</h2><p>在以假设驱动的方式推动遗留系统现代化时，首要工作就是确定目标。没有目标的工作会让我们变成无头苍蝇，到处乱撞。以下图为例，我们通常可以制定这样四个维度的目标。</p><p><img src=\"https://static001.geekbang.org/resource/image/b4/63/b48084a4f769af2973c271f24b751063.jpg?wh=1920x979\" alt=\"图片\"></p><p>1.业务敏捷：系统快速响应市场变化和新兴机会的能力，比如一个需求从提出到上线的时间；</p><p>2.运营效率：系统提升价值流效率的能力，比如一个业务从开始办理到办理完成的时间；</p><p>3.客户洞见：系统理解和解释客户数据、行为和反馈的能力，比如前面提到的，客户对于商品视频和直播等特性的敏感程度，我们应该如何去解释；</p><p>4.系统韧性与弹性：云时代对于系统的基本要求。</p><p>确定好目标，接下来就是制定各个目标的度量指标了。软件度量是很多项目都欠缺的一环，缺少了度量，就没有办法对我们的系统做出有效的评价。因此有必要在这里重点讲一讲。</p><p>以业务敏捷为例，我们可以进一步细化成3个维度、6个指标。然后再讨论出某项遗留系统现代化的举措实施之后，能带来怎样的数据变化。等交付之后，再收集度量数据，并把数据可视化。</p><p><img src=\"https://static001.geekbang.org/resource/image/f8/fa/f87eb8467a6e180503047fc417b5e6fa.jpg?wh=1920x807\" alt=\"图片\"></p><p>对于其他维度的指标，我在这里举一些例子。你可以根据自己项目的实际情况，定制更适合的指标。</p><p>运营效率主要看某个业务条线的技术改进，会对该业务带来哪些效率提升。比如银行贷款业务，从借贷申请到发放贷款的间隔时间，就是一个不错的指标；而对于保险公司的投保业务，可以选择从投保申请到核保完成的时间。</p><p>客户洞见，主要看技术改进能否帮助系统更好地理解客户行为。这一点乍听上去有点虚，我来举个例子你就明白了。</p><p>很多电商系统都有秒杀功能，在客户秒杀时会造成大量的并发请求，有时甚至会拖垮服务器。这种把客户秒杀行为与系统吞吐量做关联的能力，就是客户洞见。那么给系统“上云”，或者引入缓存，都是可以提升吞吐量的方案，最终服务于优化秒杀体验这个目的。</p><p>你可能觉得，这个例子这么简单，哪算得上什么“洞见”嘛！</p><p>其实，所谓客户洞见，就是要求我们站在客户视角去理解客户。有些可能很好理解，有些却不是那么直观。比如以地图的形式显示订单的运送路线和状态，可以显著地降低客户的投诉率。这里面隐含的一个客户洞见就是，客户非常关注包裹的物流信息，而地图的形式比文字列表的形式更能让客户安心。</p><p><img src=\"https://static001.geekbang.org/resource/image/4a/d5/4aea0be02082d5bce447197d57b29fd5.jpg?wh=1148x780\" alt=\"图片\"></p><p>系统韧性和弹性的指标就很多了，比如平均恢复时间、平均故障时间等、每秒请求数、每秒事务数等。</p><p>在确定这些指标时，我们可以通过正推的方式（即某项技术改进可以改善哪些指标）推导指标，也可以通过逆推的方式来寻找解决方案（即想要改善某个指标，都可以通过哪些技术改进来实现）。</p><p>举个例子，我们希望优化DevOps平台，就可以用部署频率这个指标来评价优化的结果；我们希望减少线上bug数量，也可以逆推出提高测试覆盖率、加强代码评审、拆分模块以降低认知负载等质量内建的手段。</p><p>不同目标维度的指标可以是重合的，比如服务恢复时长，既可作为业务敏捷维度的指标，也可作为系统韧性与弹性的指标；一项技术改进也可能带来多个指标的变化。</p><p>在制定度量指标时，还要注意的一点是，<strong>要尽量使用相对的数据，避免使用绝对的数据</strong>。比如一次交付周期内的bug数就是一个绝对的数字，它在有些情况下有意义，但在某些情况下可能就没有意义。</p><p>比如某个需求特别大，需要横跨几个交付周期，在前几个交付周期时不会上线，这时bug数自然就少。等最后一个交付周期上线时，可能一下子就会多出不少bug。通过这样绝对的数据，就不能推出“前几个交付周期质量高，最后一个交付周期质量差”的结论。我们把指标换成bug数和上线需求数的比值，就可以避免这种偏差。</p><p>实际上，bug数与需求数的比值也并不十全十美的，因为bug的严重程度、修复难度都不相同，需求的大小、紧急程度和难易程度也不相同。这时可以用“行bug数”来代替“需求bug数”，但不同代码行的难度显然也是不同的，但扩大代码行的数量就可以拉平这种差别，比如“每千行代码的bug数”。</p><p>你还可以将bug的特点和需求的特点作为权重，引入到整个评价体系中来。不过如果你的项目上还没有任何度量，我建议你先把简单的度量体系搭建起来，等想要更精准度量的时候，再引入具体系数也不迟。</p><p>想要了解更多关于软件指标和度量的内容，推荐你看看《精益软件度量》这本书。</p><p>指标制定好之后，等各项改进任务以增量（下节课再讲什么是增量）上线之后，我们就可以开始收集数据，持续度量了。需要牢记的是，<strong>一定要把度量结果用各种图表可视化出来</strong>。</p><p>一方面，这可以向开发团队展示改造的成果以及给公司带来的价值，以前开发人员可能只知道我在哪里添加了什么代码，但并不知道这几行代码给公司带来了什么样的价值。另一方面也把改造的过程向业务部门、运营部门、市场部门透明，让他们了解并支持我们的工作。</p><p>有了可度量的指标，遗留系统的假设驱动开发就成为了可能。我们在开始一项改进任务时，首先要对相关指标的变化做一个假设，等改进任务的部分交付之后，再收集相应的指标数据，以验证假设。</p><p>如果数据是朝着假设的方向变动的，我们就有理由继续投资后续的改进；如果数据变化不明显或是向相反的方向变化，就要停下来仔细研究一下原因了。</p><p><strong>以假设驱动为指引的遗留系统现代化，就是说我们所做的所有现代化任务，都应该能够提升这些指标</strong>。这些指标就像灯塔一样，引领着我们朝着正确的方向前行。</p><h2>小结</h2><p>今天我们介绍了遗留系统现代化的第二个原则：以假设驱动为指引。假设驱动开发是精益里的一个概念，不过迁移到遗留系统现代化中也完全适用。Thoughtworks的技术雷达中有一个条目就是<a href=\"https://www.thoughtworks.com/radar/techniques/hypothesis-driven-legacy-renovation\">假设驱动的遗留系统改造</a>，讲的就是类似的技术。</p><p>假设驱动开发与传统的需求式开发不同，它先对要达成的目标做一个假设，这个目标其实才是我们真正要解决的问题。然后根据假设制定解决方案，也就是我们平时开发时所面对的需求。</p><p>不同于传统需求式开发，并不是功能验收上线之后就算完成了，而是还要验证假设，看看所收集到的数据是否支持我们的假设，从而帮助我们更好地演进产品。</p><p>不以假设驱动，遗留系统现代化的很多技术改进就会盲目开展，最后忘了初心，走错了方向。</p><p>在应用假设驱动开发时，你首先要根据自己的项目制定一些目标，然后再根据目标建立度量体系。这样，所有的技术改进都可以围绕这些指标展开了。</p><p>在建立度量指标时要尽量避免绝对的数值，而要尽量用数据的比值。比值更能体现数据的相对性，比绝对的数值更能减少误差。</p><p>最后，要记得把数据可视化出来，可以打印出来贴在墙上，也可以用一个大显示器立在团队旁边。它们一方面可以激励团队成员，另一方面也是向业务方展示工作的成果，让他们相信，一个看上去很技术向的改进任务，也能给业务带来巨大的价值。</p><p><a href=\"https://time.geekbang.org/column/article/510594\">下节课</a>，我们会讲<strong>以增量演进为手段</strong>这个原则，它能有效指导我们在确定完指标之后，在行动上如何一步一步实现这些目标，敬请期待。</p><h2>思考题</h2><p>感谢你学完了这节课的内容，今天的思考题是：你的项目是否存在盲目做技术改进的情况？你们的改进在上线之后是否在用指标来度量呢？都有哪些指标？</p><p>欢迎把你项目上遗留系统现代化的心得和经验分享出来，也希望你把这节课分享给你的朋友，我们一起进步。</p>","neighbors":{"left":{"article_title":"04 | 如何降低认知负载：活的文档能救命","id":508559},"right":{"article_title":"06 | 以增量演进为手段：为什么历时一年的改造到头来是一场空？","id":510594}}},{"article_id":510594,"article_title":"06 | 以增量演进为手段：为什么历时一年的改造到头来是一场空？","article_content":"<p>你好，我是姚琪琳。</p><p>今天我们来聊聊遗留系统现代化中的HOW，也就是第三个原则，以增量演进为手段。</p><p>很多团队在一阵大张旗鼓的遗留系统改造后，终于迎来了最终的“梭哈”时刻。尽管事先可能在各种测试环境测过无数遍了，但上线生产环境仍然如履薄冰。</p><p>和遗留系统项目“相爱相杀”十几年，我可以肯定地告诉你，这种一次性交付的大规模遗留系统改造，几乎不可能一上线就成功，必然会有各种或大或小的问题，甚至导致不得不全量回滚，交付日期一拖再拖。哪怕你的“战前准备”历时一年，甚至更久，到头还是一地鸡毛。</p><p>你可能会有疑问，你见过很多大厂的案例，都是一次性上线的。没错，的确是这样，但大厂之所以有勇气这么做，是因为他们有很强的人力、物力支撑，客观条件允许这么做。对于资源有限的小公司、小项目，还是应该衡量一下改造的难度和运维的能力，以控制风险为主。</p><p>怎么控制风险呢？我的答案是增量演进。这节课，我带你把这个概念搞通透，顺便演示下代码和架构的增量演进怎么做。</p><h2>什么是增量演进？</h2><p>什么是增量？什么又是演进呢？这要从演进式架构开始说起。</p><p>我在北美的同事Neal Ford和Rebecca Parsons，在《演进式架构》这本书中给演进式架构下了精准的定义：<strong>支持跨多个维度的引导性增量变更的架构</strong>。</p><!-- [[[read_end]]] --><p>这么多的限定词，你乍一听挺懵，别急，我给你解释一下就清楚了。其中，多维度是指技术、数据、安全、运维等不同的看待架构的视角；引导性是指在<strong>适应度函数</strong>的引导下，向着正确的方向演进架构；而增量变更是指以小步快跑的方式，细粒度地构建和部署软件，同时在一定程度上允许新旧两种实现并行运行。</p><p>我这里说的遗留系统中的增量演进，借鉴了演进式架构中“增量”的概念。我们可以把已有的遗留系统作为“存量”，而每一次的优化、改进作为“增量”。“演进”则要求我们将这些增量划分成非常小的粒度。这些小的增量也可以随时部署到各种环境来进行验证，每次验证的最小单元都是这些小的增量，而不是整个的改造结果。</p><p>同时，新改进的实现和老的实现是并存的，一旦在验证时发现问题，可以随时回退到老实现。</p><p>因此，<strong>增量演进是指，以增量的方式，不断向明确的目标前进的过程</strong>。</p><p>虽然理论上，可演进的架构才更容易实现小的增量变更，但大多数遗留系统的架构显然不是可演进的。这时候我们怎么实现相对细粒度的增量交付呢？我们从代码和架构两个维度为例，具体分析一下。</p><h2>代码的增量演进</h2><p>在代码现代化方面，我们的主要目标包括三类：修补测试、代码重构、代码分层。接下来我将以代码重构为例，向你演示如何实现增量演进。</p><p>下面的代码来自《代码整洁之道》第2章“有意义的命名”，Bob大叔举了这样一个例子来吐槽糟糕的命名。这段代码来自一个扫雷游戏，想实现获取所有被标记过的单元格的目的。</p><pre><code class=\"language-java\">public List&lt;int[]&gt; getThem() {\n　List&lt;int[]&gt; list1 = new ArrayList&lt;int[]&gt;();\n　for (int[] x : theList)\n　　 if (x[0] == 4)\n　　　 list1.add(x);\n　return list1;\n}\n</code></pre><p>然而你不难发现，这段代码的坏味道远不止getThem、theList这种<strong>晦涩的命名</strong>，还包括<strong>魔法数字</strong>、<strong>基本类型偏执</strong>等。</p><p>面对如此多的坏味道，我相信对代码有洁癖的你，已经摩拳擦掌准备重构了吧？但是请别急，如果你直接改代码，在没有测试的情况下，有信心保证正百分之百正确吗？</p><p>在遗留系统中，到处充斥着这样的糟糕代码，而且没有测试覆盖。我们可以选择先补测试，然后再开始重构。这也是我强烈推荐的方式，因为这样的步子迈得更稳、更扎实。</p><p>但有时代码本身并不可测，还要先完成可测试化改造。我的初衷就是单纯地重构这段代码，现在又要可测试化，又要加测试，似乎外延越来越广了，工作量也随之越来越大。有没有办法不用加测试，也能安全地重构呢，并且完成增量式交付呢？答案是肯定的。</p><p>这种方法其实很简单，就是<strong>先把代码复制出来一份</strong>，<strong>在复制的代码处进行重构</strong>。等重构完毕，再通过某种开关，来控制新旧代码的切换。在测试时，可以通过开关来做A/B测试，从而确保重构的正确性。</p><p>除了复制代码的方式外，还有一种更巧妙的方法来实现无测试的安全重构，并完成增量交付。这里我先卖个关子，等到后面的模式篇再来介绍这种方法。</p><p>重构完的代码可以像下面这样，只有一行，十分精练：</p><pre><code class=\"language-java\">public List&lt;Cell&gt; getFlaggedCells()  {\n  return gameBoard.stream().filter(c -&gt; c.isFlagged()).collect(toList());\n}\n</code></pre><p>在这里我就不介绍具体的重构过程了，<strong>毕竟我们的重点是增量交付。</strong>重构代码的方法，我们后面模式篇再展开讲，这里也顺便推荐郑晔的《<a href=\"https://time.geekbang.org/column/intro/100068401?tab=catalog\">代码之丑</a>》专栏。</p><p>在原方法的调用端，我们可以像这样引入开关，来实现这个增量：</p><pre><code class=\"language-java\">List&lt;int[]&gt; cells;\nList&lt;Cell&gt; cellsRefactored;\nif (toggleOff) {\n  cells = getThem();\n  // 其他代码\n}\nelse {\n  cellsRefactored = getFlaggedCells();\n  // 其他代码\n}\n</code></pre><p>开关的值通常都写到配置文件，或存储在数据库里。我们可以通过修改这个配置，不断验证新代码的行为是否和旧代码完全一致。直到经过了充分的测试，我们有了十足的信心，再来删掉开关，将旧代码完全删除。</p><p>我的同事，《<a href=\"https://time.geekbang.org/column/intro/100036501?tab=catalog\">说透中台</a>》专栏的作者王健，曾经把这种重构手法总结为“<strong>十六字心法</strong>”，非常形象、贴切：</p><blockquote>\n<p>旧的不变，新的创建。一步切换，旧的再见。</p>\n</blockquote><p>“旧的不变”是指先不动旧方法；“新的创建”是指创建一个跟原来方法功能相同的新方法，你可以通过先复制再重构的方式，来得到这个新方法，也就是整个系统的一个增量；“一步切换”是指，在充分测试之后，新的方法可以完全替代旧方法了，就将开关切换到新方法上；“旧的再见”则意味着删除旧方法以及相应的开关，一个演进到此也就结束了。</p><p>你会发现，这十六字心法不光适用于代码重构，也可以推广、复用，用在架构、安全、性能等其他维度，作为增量演进的指导方针。</p><h2>架构的增量演进</h2><p>如果说代码的重构还可以在短时间内完成并上线，那架构的重新设计就很难一蹴而就了。这其实就更加需要小步上线，随时验证了。</p><p>你可能会说：“骗人的吧？你要是说代码的改动可以小步前进，我还相信，但是架构调整这么大的动作，怎么可能增量演进呢？”这其实就是我们一直想要强调的，越是大的改进，越要频繁上线去验证，不要等到最后来个“大惊喜”。</p><p>对于架构或系统的替换，Martin Fowler提出了<strong>绞杀植物模式</strong>。这源于他一次在澳大利亚旅行时发现的奇观，一棵巨大的古树被榕树的藤蔓缠绕，许多年以后最终被榕树所取代。</p><p>“老马”（国内对于Martin Fowler的昵称）想到了一种与之类似的系统替换的方式，也就是新建一个系统，让它与旧系统并存且缓慢增长，直到某一天完全取代旧的系统。于是，老马就给这种方法起了一个名字，叫绞杀植物模式。</p><p>这里稍微说个题外话，这个模式一开始的名字是Strangler，国内通常的翻译是“绞杀者模式”。2019年老马在个人网站上修订了这篇博客，将模式重新命名为Strangler Fig。原因是这个模式虽然越来越流行，但是名字太血腥太暴力。Strangler Fig直译成中文是绞杀无花果，听上去有点莫名其妙。其实Strangler本身就有绞杀植物的含义，因此我个人倾向于把这个模式翻译为绞杀植物模式。</p><p>使用绞杀植物模式最主要的好处，就是降低风险。作为绞杀植物的新系统可以稳定提供价值，并且频繁发布。你还可以很好地监控它的状态和进度。</p><p>这种新旧系统或架构同时存在、同时运行、逐渐替换的方式，就是我们的增量演进所追求的目标。</p><p>假设我们有这样一个单体系统，包含员工、财务和薪酬三个模块，其中员工和薪酬模块都会调用通知模块来发送邮件或短信。上游服务或前端页面通过HTTP API来访问不同的模块。</p><p><img src=\"https://static001.geekbang.org/resource/image/cb/6c/cbda599236da28ff9a9a35763bed276c.jpg?wh=1920x1110\" alt=\"图片\"></p><p>如果我们希望将薪酬模块迁移到独立的服务中，应该如何使用绞杀植物模式，以增量演进的方式做拆分呢？</p><p>我们可以分四步完成拆分。</p><p>第一步，<strong>建立开关</strong>。要实现增量演进，开关是必不可少的。一方面可以通过开关来控制A/B测试，以验证功能不被破坏，另一方面一旦新实现有问题，也能迅速回退到旧实现。</p><p>你可以将这个开关实现在API调用薪酬模块的地方，当开关打开的时候，调用新的薪酬服务，当开关关闭的时候，仍然调用已有的薪酬模块。这个开关可以是粗粒度的一个开关，也可以是细粒度的每个功能点一个开关。我建议你把开关尽可能设小一些，在实战中这种方式可以获得更小的增量演进和回滚。</p><p><img src=\"https://static001.geekbang.org/resource/image/9e/c7/9e6c3ecee98743aebe30a142e3c559c7.jpg?wh=1920x995\" alt=\"图片\"></p><p>现在的薪酬服务还是一个空壳，没有任何实现。如果打开开关，应该得到一个501 Not Implemented错误。</p><p>第二步，<strong>增量迁移</strong>。按迭代逐步将薪酬模块的功能迁移到薪酬服务中。假设我们需要4个迭代来完成全部的迁移工作，迭代0的工作主要是为开发开关和搭建新服务的脚手架，其余迭代就可以按计划来迁移不同的功能了。</p><p><img src=\"https://static001.geekbang.org/resource/image/dc/b8/dcdcee412c348eb0bc3f495782e26ab8.jpg?wh=1920x1116\" alt=\"图片\"></p><p>在这一步，我建议你从迭代0开始，就把薪酬服务部署到生产环境中。虽然迭代0中的薪酬服务还没有任何功能，但这可以让你先测试整个部署的过程，以及服务的连通性。否则你就要在迭代1交付的时候既测试部署，又测试功能了。</p><p>你可能会注意到，我们虽然在迭代0<strong>部署</strong>了薪酬服务，但是开关并不会打开，因此并不意味着<strong>交付</strong>了薪酬服务的功能。我们将软件部署和软件交付（或软件发布）的概念做了区分，相信你能体会到它们之间的差别。</p><p>从迭代1开始，就会有迁移完成的增量发布到薪酬服务中了，你可以打开开关来测试这一部分的功能。</p><p>第三步，<strong>并行运行</strong>。对于有一定规模的架构演进，我强烈建议你将开关和旧代码保留一段时间，让新旧代码并行运行几个迭代。</p><p>对于遗留系统来说，这样做好处是利用新旧实现并行的这段时间，让隐藏的坑逐步浮现出来，直到我们对新实现有十足信心。这里说的“隐藏的坑”意思是指，隐藏在代码和架构深处的，那些任何人都不曾知道的问题。它们随时可能会暴露出来。多并行一段时间，可以让“子弹飞一会儿”，看看是否能够暴露出这些问题。</p><p><strong>并行运行</strong>和绞杀植物模式一样，也是一种常用的架构现代化模式，我们会在模式篇里详细介绍。</p><p>第四步，<strong>代码清理</strong>。删除旧代码和开关，切记不要忘了这一步。很多遗留系统的架构演进都没有完成这一步，导致很多无用的代码留在系统中。它们除了给人带来迷惑之外没有任何用处。</p><p>完成这四步之后，我们就实现了架构的增量演进过程。你会发现，架构的增量演进与代码的增量演进一样，也完美契合了“旧的不变，新的创建，一步切换，旧的再见”这十六字心法。</p><h2>小结</h2><p>又到了总结的时候。为什么历时很久的遗留系统改造会以失败而告终呢？一是因为直到最后一刻才上线，失去了持续验证的机会；二是上线后发现有问题，只能硬着头皮热修复，或者整体回滚，缺乏细粒度的回退机制。</p><p>而增量演进原则可以有效解决这个问题。它一方面鼓励我们持续交付改造的功能或新的实现，不断在生产环境验证；另一方面拥有细粒度的开关，也使得回退变得十分灵活，一旦发现问题，我们只需要关闭引起问题的那个开关即可。</p><p>在<strong>以增量演进为手段</strong>这个原则的指导下，我对代码和架构的演进步骤做了比较详细的演示。此外，在软件系统的其他维度，如数据、安全、性能、运维等，也可以用同样的方式完成改进。</p><p>增量演进的思想不仅体现在遗留系统现代化之中，我们平时做设计的时候，也应该遵循增量演进的思想。一方面给予回退的可能，小步地上线，另一方面，也可以先上线一个简单的方案，然后再随着遇到的问题去不断演进这个方案。</p><p>我发现很多架构师在设计一个方案时喜欢一步到位，但这其实是错误的。这个世界上根本不存在完美的架构，所有的架构都应该是通过不断演进而浮现出来的，在演进的过程中我们应该根据当前上下文和约束的改变而不断调整，最终得到一个“差不多的”或者“刚刚好”的架构。</p><p>而一步到位的思想，轻则导致过度设计，重则完全走错了方向，因为没能尽早上线去收集反馈。虽然很多一步到位的决策，最后结果是走对了方向，那也不能说明你有眼光，只能说明你运气好。</p><p>另外，我还剧透了绞杀植物模式、并行运行模式等遗留系统现代化模式。想要了解更多的模式，欢迎你继续学习接下来的模式篇。</p><p>到此为止，我讲完了遗留系统现代化的三大原则。从<a href=\"https://time.geekbang.org/column/article/511924\">下节课</a>开始，我们将进入模式篇的学习，你将在这一部分看到很多似曾相识的模式，它们是进行遗留系统现代化强有力的工具和方法。</p><h2>思考题</h2><p>感谢你学完了今天的内容，我给你留了三道思考题，你可以任选一个或者多个说说想法：</p><p>1.在你的项目中，是如何做代码和架构的重构的？是否曾经使用过类似增量演进的方式呢？期待你分享一下自己团队经验。</p><p>2.除了复制代码并重构之外，我在文中还提到了另外一种方法，用来在无测试的情况下完成安全重构，你想到是什么了吗？</p><p>3.在架构的增量演进一节中，单体系统中的薪酬模块对通知模块是有依赖的，那么新的薪酬服务拆分出去之后，应该如何实现对外发通知的功能呢？</p><p>欢迎你在评论区留下你的思考，也欢迎你把这节课分享给你的同事和朋友，我们一起讨论、进步。</p>","neighbors":{"left":{"article_title":"05 | 以假设驱动为指引：如何评价遗留系统的现代化成果？","id":509535},"right":{"article_title":"07 | 遗留系统现代化的五种策略：重构还是重写？这是一个问题","id":511924}}},{"article_id":511924,"article_title":"07 | 遗留系统现代化的五种策略：重构还是重写？这是一个问题","article_content":"<p>你好，我是姚琪琳。</p><p>从今天开始，我们正式进入模式篇的学习。这一部分我会带你学习代码、架构、DevOps、团队结构四个现代化中的各种模式，这些模式是我们实战的理论基础，希望你能牢牢掌握。</p><p>不过深入学习这些模式前，今天我们先从重构和重写的“两难”问题说起。到底是重构，还是重写？这是一个困扰着很多团队的问题。</p><p>重构吧，遗留系统积重难返，重构之路遥遥无期，三年、五年时间，可能也只是刚开了个头，还不如重写。</p><p>但重写就真的比重构好吗？遗留系统中最难获取的就是业务知识。当你问起一块业务时，得到的回答往往是：“没有文档”、“没人知道”或者“只能看代码”……没有业务，或者说没有需求，怎么可能构建出来一个新的系统呢？</p><p>那我们到底应该如何应对呢？除了重构和重写，还有没有其他方式呢？</p><h2>遗留系统现代化的五种策略</h2><p>Gartner在19年曾经有<a href=\"https://www.gartner.com/smarterwithgartner/7-options-to-modernize-legacy-systems\">一篇报道</a>，提出了遗留系统现代化的七种方案。我把这七种方案做了整合，把它们整理成后面这五种策略。它们各有各的特点，而且分别对应不同场景，你要根据项目自身情况选择不同的策略或组合。然后，再应用后面要讲的模式来落地。</p><h3>Encapsulate</h3><p>第一种策略是<strong>Encapsulate</strong>，也就是<strong>将遗留系统中的数据或者功能封装成API，供外部调用</strong>。</p><!-- [[[read_end]]] --><p>我们在<a href=\"https://time.geekbang.org/column/article/505740\">第一节课</a>里提到过，遗留系统中蕴含着丰富的数据资产，但是因为技术和工具落后，导致它难以与新系统集成，这些数据被封印在遗漏系统中，成了数据孤岛。比如早期的银行或民航软件，很多都是部署在大型机上的。企业非常希望开发手机App，这样才能更好地为客户服务，但却很难访问到主机上的这些数据。</p><p>同样地，遗留系统中还有一些功能十分重要，其他外部系统需要这些能力来构建业务。比如一些公文流转的工作流，可能构建在基于Lotus Notes的办公系统中，但如果企业想要开发移动办公App，并在App中复用这套工作流，也是困难重重。</p><p>问题虽然棘手，但事到临头，工程师们总要想办法应对。结合刚才说的情况，我们可以封装这些数据和功能，形成API，供这些移动App或其他外部系统使用。如果遗留系统本身就是基于Web的，可以在Web系统上直接构建API；如果不是，可以选择构建一个全新的Web API来部署并提供服务。</p><p>这样做的好处是，以较低的成本和风险，尽可能满足外部系统的需求。你无需对遗留系统做较大的修改，只是增加一些API而已。遗留系统本身不会被优化，但它可以通过这些API对外提供能力。</p><p>还有一种情况，我也建议你使用封装的策略，那就是当你有一个第三方系统，希望扩展它的功能，但只能访问它的数据库，却无法修改代码的时候。</p><p>这时有些团队采用的方式就是直接连它的数据库，并在已有的系统中基于这些数据构建新的功能。我不建议你这么做，直接连数据库固然简单，但由于你可以访问它所有的表和列，距离混乱也就剩一步之遥了。</p><p>我建议你基于这个第三方系统的数据库构建一个Web API，来向其他的系统提供你想提供的数据和功能，而不是暴露全部的数据。</p><p>我这里也稍微剧透下，封装的策略落到具体应用的时候，衍生出了很多相关模式，比如<strong>数据API模式</strong>、<strong>功能API模式</strong>等等。我会在后面的课里再详细展开。</p><h3>Replatform</h3><p>第二种策略是<strong>Replatform</strong>，也就是<strong>替换运行时平台</strong>。这种策略不需要对代码大动干戈，只需要改动很小一部分。到了新的平台后，软件的功能和特性仍然保持不变。</p><p>比如，很多银行或民航软件还是基于COBOL的主机系统，把它们从大型机上迁移到Linux或Windows环境，就会甩掉昂贵的主机成本。</p><p>再比如，早年间开始构建的系统，由于种种原因，很多是基于商业软件的，想升级，就要花一大笔预算。很多企业为了节省这部分开支，会尽量避免升级，也导致系统最终变成了遗留系统。你可以通过Replatform策略来解除对商业软件的依赖，例如用Tomcat来替换WebLogic。</p><p>或者像.NET这种技术栈，也十分有必要从.NET Framework迁移到.NET Core或者.NET 5。而Python从2升级到3、JDK的大版本升级等等，也都属于Replatform。</p><p>在使用Replatform时，你只需要对代码做少量更改，以适配新的平台。这样，只通过较小的成本就可以降低基础设施的成本，并提高性能。</p><p>还有一种迁移我认为也可以看做是Replatform，虽然它并不是替换运行时平台。那就是迁移代码版本管理工具。比如你把代码从SVN迁移到Git中，不需要修改任何功能代码，但却可以享受新的代码管理平台带来的好处。</p><h3>Rehost</h3><p>第三种策略是<strong>Rehost</strong>，也就是<strong>将应用程序或组件部署到其他基础设施中</strong>，如虚拟主机、容器或云。这种策略完全不需要修改代码，而只需要迁移部署的环境，甚至都不需要重新编译，因此这种迁移方法也有个很形象的别名，叫做“lift and shift”，就是原封不动地拎起来，转移到别的地方去。</p><p>我举个例子来说明，如果你的公司有一个SAP的ERP系统，可以将它从本地的数据中心迁移到AWS或GCP中。</p><p>Rehost可以让你在完全不修改已有系统的情况下，快速上云，体验云环境带来的弹性、安全性和高性能，并且迁移过程也能做到很平滑。然而由于没有任何适配，也就无法充分利用云原生的优势，因此还需要对系统内部的代码和架构做进一步调整，比如将单体架构拆分为可以独立运维的微服务。</p><h3>Refactor/Rearchitect</h3><p>第四种策略是<strong>Refactor和Rearchitect</strong>，它们是指<strong>在不改变系统外部行为的前提下，对代码或架构进行调整、优化，以偿还拖欠已久的技术债务、改善非功能需求、提升系统健康度</strong>。</p><p><strong>Refactor主要是指代码级别的重构</strong>，比如你可能用Sonar等代码扫描工具，扫描出了很多代码坏味道、缺陷或隐患，修复这些问题的过程就属于Refactor。这和我们平时说的代码重构基本上是一个意思。</p><p><strong>Rearchitect是指架构级别的重构</strong>，它包含两层意思。第一层比较好理解，就是指从单体架构到分布式架构的这种架构调整。第二层是指不改变部署单元之间的关系，而是对单个或多个部署单元内部进行模块化或分层重构。由于这种模块化和分层也会涉及很多代码的调整，所以这种Rearchitect往往会和Refactor同时进行。</p><p>后面你学到代码和架构现代化的内容时，会看到很多Refactor/Rearchitect相关的模式。这些也往往是遗留系统现代化中最有挑战，也最有意思的部分。</p><h3>Rebuild/Replace</h3><p>第五种策略是<strong>Rebuild和Replace</strong>，都是指<strong>对遗留系统进行替换</strong>。它们两个替换的范围和程度不同。<strong>Rebuild</strong>可能是<strong>对应用程序的某个组件或某个服务的重新设计或重写</strong>，但会保留其原有的业务范围和业务规则。而<strong>Replace</strong>是指<strong>彻底淘汰应用程序的所有组件，去构建或购买新的软件</strong>，同时会考虑添加新的业务需求或移除某些旧的业务需求。</p><p>我在<a href=\"https://time.geekbang.org/column/article/505740\">第一节课</a>提到过，遗留系统中的业务知识是严重缺失的，不仅没有遗留下来的文档供我们查阅，也没有任何一个人能说清楚全部的业务细节。在这样的基础上实施Rebuild或Replace，风险和成本都是相当高的，但相对来说，收益也是最高的，一旦替换成功，就可以彻底摆脱原来的遗留系统了。</p><p>下图是对上面五种策略的一个总结，你可以从中看出它们的收益、风险和成本（用面积表示）：</p><p><img src=\"https://static001.geekbang.org/resource/image/73/bf/735968254f34d2eecbe73f5f0bed34bf.jpg?wh=3122x1870\" alt=\"\"></p><h3>其他策略</h3><p>除了上面的几种策略以外，对于遗留系统来说还有一些应对策略可以选择。不过由于不涉及到代码、架构或运行环境的变更，我没有把它们作为遗留系统现代化的策略。</p><p>其中一种是Retain，即保持系统当前的状态不做任何修改或更新。对于尚可满足使用的遗留系统来说，这无疑是风险和成本最低的策略。我在<a href=\"https://time.geekbang.org/column/article/509535\">第五节课</a>说过，使用人数不多、需求很少、只需要一两个人维护的遗留系统，就可以使用这种策略。</p><p>还有一种是Retire，就是评估完工作量、使用情况和业务价值之后，选择完全停止使用的一种策略。有的时候系统已经没有什么人用了，或者类似的功能在其他系统中可以替代，你就可以选择让这个旧系统彻底退休了。</p><h2>你应该选择什么样的策略？</h2><p>面对如此眼花缭乱的策略，你恐怕更加无所适从了吧？别担心，接下来我就来帮你梳理一下如何选择。</p><p>到底是Replatform还是Rehost？是Refactor还是Rebuild？是Rearchitect还是Replace？其实，我们还是要依据目标和系统现状做判断。</p><p>先看最终目标，第五节课我列出了企业遗留系统现代化的四个目标，即业务敏捷、运营效率、客户洞见、系统韧性与弹性。</p><p>对于业务敏捷来说，Replatform和Rehost通过替换运行时环境和上云可以提升部署频率，特别是Rehost可以显著提升系统在遇到故障时的恢复时间；Refactor/Rearchitect通过改善代码和架构的质量，可以缩短需求交付周期，减少线上问题数量；而Rebuild/Replace由于在某种程度上做了替换，也可以大幅度提升业务的响应力和交付质量。</p><p>对于运营效率来说，Refactor/Rearchitect和Rebuild/Replace都可以提升价值流效率。而要想改善客户洞见，最有效的方式还是Rebuild/Replace。在系统韧性与弹性方面，Rehost显然是不二之选。</p><p>我们要结合当前遗留系统的现状和想要提升的目标，做综合判断，对于不同的模块，也可以选择不同的策略组合，来实现一个完整的业务目标。</p><p>比如遗留系统中的有些业务，需要提供7x24小时的高可用服务，类似银行转账、保险报案等模块。但这些模块很有可能还位于单体的“大泥球”中，和其他模块有着剪不断、理还乱的关系。</p><p>为了支撑这些需求，我们可以先采用Rearchitect的模块化策略，结解耦模块之间的关系；然后再用Rearchitect的服务化策略，将这些模块拆分成独立的服务；最后再用Rehost策略将这些服务部署到云上，以提升系统的可用性。</p><p>当然，如果由于系统耦合严重，模块化改造很难实施，你也可以选择用Rebuild策略重写这一部分模块。</p><p>再比如一个部署在WAS v6上的Java Web遗留系统，由于只支持Java EE 1.4，技术栈严重落后，已经很难在市场上招到人来维护了。</p><p>这时，可以先选择Replatform策略，将WAS替换为较新版本的Tomcat，以摆脱昂贵的商业软件；然后再次使用Replatform升级Java的版本，包括所依赖的第三方工具，这样就完成了整个技术栈的升级。</p><p>如果企业认为当前遗留系统已经彻底无法满足业务的需要，且具备足够的资源来构建新的系统，就可以使用Replace策略来彻底替换旧系统。同时，在遗留系统并不是很大，但重要性又相对很高的情况下，也可以考虑Rebuild/Replace。</p><p>这里我一直没有提Encapsulate这种策略，是因为它有自己独特的适用场景，也就是与其他外部系统集成的时候。</p><h2>小结</h2><p>又到了总结的时刻。今天我们学习了遗留系统现代化的几种策略，不同的策略有不同的适用场景，我把它们总结到了一张表中。</p><p><img src=\"https://static001.geekbang.org/resource/image/ec/d6/ecd8ff1b982116d6ff91e4f5bebb5cd6.jpg?wh=1920x1135\" alt=\"图片\"></p><p>你要记住的是，一定要根据项目的情况来选择不同的策略组合。不要上来就大张旗鼓地重构或重写，一定要弄清楚想要的是什么。除了重构和重写，你其实还有很多选择。</p><p>从<a href=\"https://time.geekbang.org/column/article/512658\">下节课</a>开始，我们马上进入各种模式的学习了，你准备好了吗？</p><h2>思考题</h2><p>感谢你学完了今天的内容。我给你留的作业是这样的：</p><p>假设你是一个项目的技术负责人，你的项目基于.NET Framework 4.6.1，而该版本即将在这个月（2022年4月）“寿终正寝”。为了避免潜在的安全风险，你不得不将.NET版本进行升级（假设系统当前部署在Windows虚拟机上）。</p><p>这时你有以下三个选择：</p><p>1.升级到.NET Framework 4.6.2版本，几乎不用对代码做任何修改，只需要升级一下各个部署环境的虚拟机即可，保守估计三天之内也能完成升级并上线。</p><p>2.升级到最新的.NET Fremework 4.8版本，可以获得更长的技术支持，还能使用新版语言的特性，以提升开发效率。但有些旧的第三方库并不支持4.8，需要升级或替换。你可能需要两周到一个月的时间来完成全部升级。</p><p>3.升级到.NET 5，以充分享受跨平台和容器化的优势，系统也将彻底摆脱Windows的束缚。但代码需要改动的地方很多，几乎所有第三方依赖也都需要升级。预计需要五到六个月的时间才能搞定。</p><p>你会做出什么样的选择呢？补充一句，如果你不熟悉.NET的版本和特性，可以自行搜索一下。</p><p>本次作业没有正确答案，在我看来，任何一个选择都是可以接受的。你可以根据自己的思考给出答案，并说明理由。必要的时候，也可以自己添加一些约束条件，来支持自己的选择。</p><p>期待你的分享。如果你觉得今天这节课对你有帮助，别忘了分享给你的同事和朋友，说不定就能帮他解决一个难题。</p><p><a href=\"http://url\"></a></p>","neighbors":{"left":{"article_title":"06 | 以增量演进为手段：为什么历时一年的改造到头来是一场空？","id":510594},"right":{"article_title":"08 | 代码现代化：你的代码可测吗？","id":512658}}},{"article_id":512658,"article_title":"08 | 代码现代化：你的代码可测吗？","article_content":"<p>你好，我是姚琪琳。</p><p>从今天开始，我将用三讲来介绍代码现代化的主要模式。它们大体的脉络是这样的：</p><p>1.先对代码做可测试化重构，并添加测试；<br>\n2.在测试的保护下，安全地重构；<br>\n3.在测试的保护下，将代码分层。</p><p>我们今天先来看看如何让代码变得可测，这是遗留系统现代化的基本功，希望你重视起来。</p><p>一个软件的自动化测试，可以从内部表达这个软件的质量，我们通常管它叫做<strong>内建质量（Build Quality In）</strong>。</p><p>然而国内的开发人员普遍缺乏编写自动化测试的能力，一方面是认为没什么技术含量，另一方面是觉得质量是测试人员的工作，与自己无关。然而你有没有想过，正是因为这样的误区，才导致软件的质量越来越差，系统也一步步沦为了遗留系统。</p><p>我虽然在第六节课分享了可以不加测试就重构代码的方法，但添加测试再重构的方法更加扎实，一步一个脚印。</p><h2>你的代码可测吗？</h2><p>我们先来看看不可测的代码都长什么样，分析出它们不可测的原因，再“按方抓药”。</p><p>可测的代码很相似，而不可测的代码各有各的不可测之处。我在<a href=\"https://time.geekbang.org/column/article/506570\">第二节课</a>举过一个不可测代码的例子，现在我们来一起复习一下：</p><pre><code class=\"language-java\">public class EmployeeService {\n  public EmployeeDto getEmployeeDto(long employeeId) {\n    EmployeeDao employeeDao = new EmployeeDao();\n    // 访问数据库获取一个Employee\n    Employee employee = employeeDao.getEmployeeById(employeeId);\n    // 其他代码  \n  }\n}\n</code></pre><!-- [[[read_end]]] --><p>这段代码之所以不可测，是因为在方法内部直接初始化了一个可以访问数据库的Dao类，要想测试这个方法，就必须访问数据库了。倒不是说所有测试都不能连接数据库，但大多数直连数据库的测试跑起来都太慢了，而且数据的准备也会相当麻烦。</p><p>这属于不可测代码的第一种类型：<strong>在方法中构造了不可测的对象</strong>。</p><p>我们再来看一个例子，与上面的代码非常类似：</p><pre><code class=\"language-java\">public class EmployeeService {\n  public EmployeeDto getEmployeeDto(long employeeId) {\n    // 访问数据库获取一个Employee\n    Employee employee = EmploeeDBHelper.getEmployeeById(employeeId);\n    // 其他代码\n  }\n}\n</code></pre><p>这段代码同样是不可测的，它<strong>在方法中调用了不可测的静态方法</strong>，因为这个静态方法跟前面的实例方法一样，也访问了数据库。</p><p>除了不能在测试中访问真实数据库以外，也不要在测试中访问其他需要部署的中间件、服务等，它们也会给测试带来极大的不便。</p><p>在测试中，我们通常把被测的元素（可能是组件、类、方法等）叫做SUT（System Under Test），把SUT所依赖的组件叫做DOC（Depended-on Component）。导致<strong>SUT无法测试的原因</strong>，通常都是<strong>DOC在当前的测试上下文中不可用</strong>。</p><p>DOC不可用的原因通常有三种：</p><p>1.不能访问。比如DOC访问了数据库或其他需要部署的中间件、服务等，而本地环境没有这些组件，也很难部署这些组件。</p><p>2.不是当前测试期望的返回值。即使本地能够访问这些组件，但它们却无法返回我们想要的值。比如我们想要获取ID为1的员工信息，但数据库中却并没有这条数据。</p><p>3.执行这些DOC的方法会引发不想要的副作用。比如更新数据库，会破坏已有数据，影响其他测试。另外连接数据库，还会导致测试执行时间变长，这也是一种副作用。</p><p>要让SUT可测，就得让DOC可用，有哪些办法呢？</p><h2>如何让代码变得可测？</h2><p>其实很简单，就是要让DOC的行为可变。这种变化可以让DOC在测试时不再直接访问数据库或其他组件，从而变得“可以访问”、“能返回期望的值”以及“不会产生副作用”。</p><p>如何才能让DOC的行为可变呢？如果DOC是静态的或是在SUT内构造的，那自然不可改变。所以，我们要让DOC的构造和SUT本身分离，SUT只需使用外部构造好的DOC的实例，而不用关心它的构造。</p><p>这种<strong>可以让DOC的行为发生改变的位置</strong>，叫做<strong>接缝（seam）</strong>，这是Michael Feathers在《修改代码的艺术》这本书里提出来的。</p><p>接缝这个隐喻非常形象，如果是一整块没有接缝的布料，你就无法做任何改动，它始终就是一块平面的布料。有了接缝，你不但可以连接不同的布料，还可以改变一块布的方向，从平面变得立体。有了接缝，身为“裁缝”的我们才可以充分发挥想象力，制作出各种丰富多彩的成品。</p><p>我把这种在<strong>SUT中创建接缝从而使SUT变得可测的方式</strong>，叫做<strong>提取接缝模式</strong>。</p><p>想要用好这个模式，我们需要了解何处下剪子，针法选什么合适。也就是接缝的位置和类型，下面我们就结合代码例子分别看看。</p><h3>接缝的位置</h3><p>我在第二节课介绍了一种提取接缝模式的应用，也就是把EmployeeDao提取成EmployeeService的字段，并通过EmployeeService的<strong>构造函数注入</strong>进来。</p><pre><code class=\"language-java\">public class EmployeeService {\n  private EmployeeDao employeeDao;\n  public EmployeeService(EmployeeDao employeeDao) {\n    this.employeeDao = employeeDao;\n  }\n\n  public EmployeeDto getEmployeeDto(long employeeId) {\n    Employee employee = employeeDao.getEmployeeById(employeeId);\n    // 其他代码\n  }\n}\n</code></pre><p>除了构造函数，接缝也可以位于<strong>方法参数</strong>中，即：</p><pre><code class=\"language-java\">public class EmployeeService {\n  public EmployeeDto getEmployeeDto(long employeeId, EmployeeDao employeeDao) {\n    Employee employee = employeeDao.getEmployeeById(employeeId);\n    // 其他代码\n  }\n}\n</code></pre><p>如果你使用了依赖注入工具（比如Spring），也可以给字段加@Autowired注解，这样接缝的位置就成了<strong>字段</strong>。对于这三种接缝位置，我更倾向于构造函数，因为它更方便，而且与具体的工具无关。</p><p>学习完接缝的位置，我们再来看看接缝的类型。</p><h3>接缝的类型</h3><p><strong>接缝的类型</strong>是指，<strong>通过什么样的方式来改变DOC的行为</strong>。第二节课中，提取完接缝后，我创建了一个EmployeeDao的子类，这个子类重写了getEmployeeById的默认行为，从而让这个DOC返回了我们“期望的值”。</p><pre><code class=\"language-java\">public class InMemoryEmployeeDao extends EmployeeDao {\n  @Override\n  public Employee getEmployeeById(long employeeId) {\n    return null;\n  }\n}\n</code></pre><p>我把这种<strong>通过继承DOC来改变默认行为</strong>的接缝类型叫做<strong>对象接缝</strong>。</p><p>除此之外，还可以将原来的EmployeeDao类重命名为DatabaseEmployeeDao，并提取出一个EmployeeDao接口。然后再让InMemoryEmployeeDao类实现EmployeeDao接口。</p><pre><code class=\"language-java\">public interface EmployeeDao {\n    Employee getEmployeeById(long employeeId);\n}\n</code></pre><p>在EmployeeService中，我们仍然通过构造函数来提供这个接缝，代码基本上可以保持不变。这样，我们和对象接缝一样，只需要在构造EmployeeService的时候传入InMemoryEmployeeDao就可以改变默认的行为，之后的测试也更方便。</p><p>这种<strong>通过将DOC提取为接口，并用其他实现类来改变默认行为</strong>的接缝类型，就叫做<strong>接口接缝</strong>。</p><p>如果你的代码依赖的是一个接口，那么这种依赖或者说耦合就是很松散的。在接口本身不发生改变的前提下，不管是修改实现了该接口的类，还是添加了新的实现类，使用接口的代码都不会受到影响。</p><h3>新生和外覆</h3><p>提取了接缝，你就可以对遗留代码添加测试了。但这时你可能会说，虽然接缝很好，但是很多复杂的代码依赖了太多东西，一个个都提取接缝的话，需要很长时间，但无奈工期太紧，不允许这么做啊。</p><p>不要紧，《修改代码的艺术》中还介绍了两种不用提取接缝就能编写可测代码的模式，也就是<strong>新生（sprout）<strong>和</strong>外覆（wrap）</strong>。</p><p>假设我们有这样一段代码，根据传入的开始和结束时间，计算这段时间内所有员工的工作时间：</p><pre><code class=\"language-java\">public class EmployeeService {\n    public Map&lt;Long, Integer&gt; getWorkTime(LocalDate startDate, LocalDate endDate) {\n        EmployeeDao employeeDao = new EmployeeDao();\n        List&lt;Employee&gt; employees = employeeDao.getAllEmployees();\n        Map&lt;Long, Integer&gt; workTimes = new HashMap&lt;&gt;();\n        for(Employee employee : employees) {\n            WorkTimeDao workTimeDao = new WorkTimeDao();\n            int workTime = workTimeDao.getWorkTimeByEmployeeId(employee.getEmployeeId(), startDate, endDate);\n            workTimes.put(employee.getEmployeeId(), workTime);\n        }\n        return workTimes;\n    }\n}\n</code></pre><p>我知道这段代码有很多槽点，但更痛的现实状况是：你根本没有时间去优化，因为新的需求已经来了，并且明天就要提测。</p><p>需求是这样的，业务人员拿到工时的报表后发现，有很多员工的工时都是0，原来他们早就离职了。现在要求你修改一下代码，过滤掉那些离职的员工。</p><p>如果不需要写测试，这样的需求对你来说就是小事一桩，你一定轻车熟路。</p><p>你可以在EmployeeDao中添加一个新的查询数据库的方法getAllActiveEmployees，只返回在职的Employee。也可以仍然使用getAllEmployees，并在内存中进行过滤。</p><pre><code class=\"language-java\">public class EmployeeService {\n    public Map&lt;Long, Integer&gt; getWorkTime(LocalDate startDate, LocalDate endDate) {\n        EmployeeDao employeeDao = new EmployeeDao();\n        List&lt;Employee&gt; employees = employeeDao.getAllEmployees()\n                .stream()\n                .filter(e -&gt; e.isActive())\n                .collect(toList());\n        // 其他代码\n    }\n}\n</code></pre><p>这样的修改不仅在遗留系统中，即使在所谓的新系统中，也是十分常见的。需求要求加一个过滤条件，那我就加一个过滤条件就好了。</p><p>然而，这样的代码仍然是不可测的，你加了几行代码，但你加的代码也是不可测的，系统没有因你的代码而变得更好，反而更糟了。</p><p>更好的做法是添加一个<strong>新生方法</strong>，去执行过滤操作，而不是在原来的方法内去过滤。</p><pre><code class=\"language-java\">public class EmployeeService {\n    public Map&lt;Long, Integer&gt; getWorkTime(LocalDate startDate, LocalDate endDate) {\n        EmployeeDao employeeDao = new EmployeeDao();\n        List&lt;Employee&gt; employees = filterInactiveEmployees(employeeDao.getAllEmployees());\n        // 其他代码\n    }\n    public List&lt;Employee&gt; filterInactiveEmployees(List&lt;Employee&gt; employees) {\n        return employees.stream().filter(e -&gt; e.isActive()).collect(toList());\n    }\n}\n</code></pre><p>这样一来，新生方法是可测的，你可以对它添加测试，以验证过滤逻辑的正确性。原来的方法虽然仍然不可测，但我们也没有让它变得更糟。</p><p>除了<strong>新生</strong>，你还可以使用<strong>外覆</strong>的方式来让新增加的功能可测。比如下面这段计算员工薪水的代码。</p><pre><code class=\"language-java\">public class EmployeeService {\n    public BigDecimal calculateSalary(long employeeId) {\n        EmployeeDao employeeDao = new EmployeeDao();\n        Employee employee = employeeDao.getEmployeeById();\n        return SalaryEngine.calculateSalaryForEmployee(employee);\n    }\n}\n</code></pre><p>如果我们现在要添加一个新的功能，有些调用端在计算完薪水后，需要立即给员工发短信提醒，而且其他调用端则保持不变。你脑子里可能有无数种实现方式，但最简单的还是直接在这段代码里添加一个<strong>新生</strong>方法，用来通知员工。</p><pre><code class=\"language-java\">public class EmployeeService {\n    public BigDecimal calculateSalary(long employeeId, bool needToNotify) {\n        EmployeeDao employeeDao = new EmployeeDao();\n        Employee employee = employeeDao.getEmployeeById();\n        BigDecimal salary = SalaryEngine.calculateSalaryForEmployee(employee);\n        notifyEmployee(employee, salary, needToNotify);\n        return salary;\n    }\n}\n</code></pre><p>这的确非常方便，但将needToNotify这种标志位一层层地传递下去，是典型的代码坏味道<a href=\"https://martinfowler.com/bliki/FlagArgument.html\">FlagArgument</a>。你也可以在调用端根据情况去通知员工，但那样对调用端的修改又太多太重，是典型的霰弹式修改。</p><p>最好的方式是在原有方法的基础上<strong>外覆</strong>一个新的方法calculateSalaryAndNotify，它会先调用原有方法，然后再调用通知方法。</p><pre><code class=\"language-java\">public BigDecimal calculateSalary(long employeeId) {\n    // ...\n}\npublic BigDecimal calculateSalaryAndNotify(long employeeId) {\n    BigDecimal salary = calculateSalary(employeeId);\n    notifyEmployee(employeeId, salary);\n    return salary;\n}\npublic void notifyEmployee(long employeeId, BigDecimal salary) {\n    // 通知员工\n}\n</code></pre><p>通过这样的修改，调用端只需要根据情况选择调用哪个方法即可，这样的改动量最少。同时你还可以单独测试notifyEmployee，以确保这部分逻辑是正确的。</p><p>通过新生和外覆两种模式，我们新编写的代码就是可测的了。而通过提取接缝，旧代码的可测试化重构也可以基本搞定。接下来，我将通过构造函数注入和接口接缝演示一下，如何为这个EmployeeService编写测试。</p><h2>为代码添加测试</h2><p>我们先来回顾一下现在EmployeeService的完整代码：</p><pre><code class=\"language-java\">public class EmployeeService {\n    private EmployeeDao employeeDao;\n    public EmployeeService(EmployeeDao employeeDao) {\n        this.employeeDao = employeeDao;\n    }\n    public EmployeeDto getEmployeeDto(long employeeId) {\n        Employee employee = employeeDao.getEmployeeById(employeeId);\n        if (employee == null) {\n            throw new EmployeeNotFoundException(employeeId);\n        }\n        return convertToEmployeeDto(employee);\n    }\n}\n</code></pre><p>我们要添加的测试是当EmployeeDao的getEmployeeById方法返回一个null的时候，EmployeeService的getEmployeeDto方法会抛出一个异常。</p><pre><code class=\"language-java\">public class EmployeeServiceTest {\n    @Test\n    public void should_throw_employee_not_found_exception_when_employee_not_exists() {\n        EmployeeService employeeService = new EmployeeService(new InMemoryEmployeeDao());\n        EmployeeNotFoundException exception = assertThrows(EmployeeNotFoundException.class,\n            () -&gt; employeeService.getEmployeeDto(1L));\n        assertEquals(exception.getEmployeeId(), 1L);\n    }\n}\n</code></pre><p>我们在测试中使用的InMemoryEmployeeDao，实际上就是一种<strong>测试替身（Test Double）</strong>。但是它只返回了null，有点单一，想测试正常的情况就没法用了。如果想让这个方法返回不同的值，再添加一个EmployeeDao的实现着实有点麻烦。这时可以使用Mock框架，让它可以针对不同的测试场景返回不同的值。</p><pre><code class=\"language-java\">@Test\npublic void should_return_correct_employee_when_employee_exists() {\n    EmployeeDao mockEmployeeDao = Mockito.mock(EmployeeDao.class);\n    when(mockEmployeeDao.getEmployeeById(1L)).thenReturn(givenEmployee(\"John Smith\"));\n    EmployeeService employeeService = new EmployeeService(mockEmployeeDao);\n    EmployeeDto employeeDto = employeeService.getEmployeeDto(1L);\n    \n    assertEquals(1L, employeeDto.getEmployeeId());\n    assertEquals(\"John Smith\", employeeDto.getName());\n}\n</code></pre><p>这里我们使用了Mockito这个Java中最流行的Mock框架。想了解更多关于测试替身和Mock框架的知识，可以参考郑晔老师的<a href=\"https://time.geekbang.org/column/article/408762\">专栏文章</a>。</p><p>好了，代码也可测了，我们也知道怎么写测试了，那么应该按什么样的思路去添加测试呢？上面这种简单的例子，我相信你肯定是知道要怎么加测试，但是遗留系统中的那些“祖传”代码真的是什么样的都有，对于这种复杂代码，应该怎么去添加测试呢？</p><h3>决策表模式</h3><p>我们以著名的<a href=\"https://github.com/emilybache/GildedRose-Refactoring-Kata\">镶金玫瑰重构道场</a>的代码为例，来说明如何为复杂遗留代码添加测试。</p><pre><code class=\"language-java\">public void updateQuality() {\n   for (int i = 0; i &lt; items.length; i++) {\n       if (!items[i].name.equals(\"Aged Brie\")\n               &amp;&amp; !items[i].name.equals(\"Backstage passes to a TAFKAL80ETC concert\")) {\n           if (items[i].quality &gt; 0) {\n               if (!items[i].name.equals(\"Sulfuras, Hand of Ragnaros\")) {\n                   items[i].quality = items[i].quality - 1;\n               }\n           }\n       } else {\n           if (items[i].quality &lt; 50) {\n               items[i].quality = items[i].quality + 1;\n\n               if (items[i].name.equals(\"Backstage passes to a TAFKAL80ETC concert\")) {\n                   if (items[i].sellIn &lt; 11) {\n                       if (items[i].quality &lt; 50) {\n                           items[i].quality = items[i].quality + 1;\n                       }\n                   }\n\n                   if (items[i].sellIn &lt; 6) {\n                       if (items[i].quality &lt; 50) {\n                           items[i].quality = items[i].quality + 1;\n                       }\n                   }\n               }\n           }\n       }\n\n       if (!items[i].name.equals(\"Sulfuras, Hand of Ragnaros\")) {\n           items[i].sellIn = items[i].sellIn - 1;\n       }\n\n       if (items[i].sellIn &lt; 0) {\n           if (!items[i].name.equals(\"Aged Brie\")) {\n               if (!items[i].name.equals(\"Backstage passes to a TAFKAL80ETC concert\")) {\n                   if (items[i].quality &gt; 0) {\n                       if (!items[i].name.equals(\"Sulfuras, Hand of Ragnaros\")) {\n                           items[i].quality = items[i].quality - 1;\n                       }\n                   }\n               } else {\n                   items[i].quality = items[i].quality - items[i].quality;\n               }\n           } else {\n               if (items[i].quality &lt; 50) {\n                   items[i].quality = items[i].quality + 1;\n               }\n           }\n       }\n   }\n}\n</code></pre><p>这是非常典型的遗留代码，if/else满天飞，可谓眼花缭乱；而且分支的规则不统一，有的按名字去判断，有的按数量去判断。</p><p>对于这种分支条件较多的代码，我们可以梳理需求文档（如果有的话）和代码，找出所有的路径，根据每个路径下各个字段的数据和最终的值，制定一张决策表，如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/63/d1/6357f689162820db3d22623e38aacbd1.jpg?wh=1920x1667\" alt=\"图片\"></p><p>比如第一行，我们要测的是，系统每天会自动给所有商品的保质期和品质都减1，那么给出的条件是商品类型为normal，保质期为4天，品质为1，所期望的行为是保质期和品质都减少1。而第二行则是测试，当保质期减为0之后，品质会双倍地减少。以此类推，我们一共梳理出18个测试场景。</p><p>你会看到，这种决策表不但清晰地提供了所有测试用例，而且给出了相应的数据，你可以很轻松地基于它来构建整个方法的测试。</p><h2>测试的类型和组织</h2><p>说完了如何添加测试，我们接下来看看可以添加哪些类型的测试。</p><p>Mike Cohn在十几年前曾经提出过著名的“<a href=\"https://martinfowler.com/bliki/TestPyramid.html\">测试金字塔</a>”理论，将测试划分为三个层次。从上到下分别是：UI测试、服务测试和单元测试。它们累加在一起，就像一个金字塔一样。需要指出的是，遗留系统很难应用测试金字塔，但我们还是有必要先来看看这三层测试都包含哪些内容。</p><p><img src=\"https://static001.geekbang.org/resource/image/4d/48/4da7cb2739ac48ff731184f91c728f48.jpg?wh=1920x1106\" alt=\"图片\"></p><p>其中，最顶层的UI测试是指从页面点击到数据库访问的端到端测试，用自动化的方式去模拟用户或测试人员的行为。</p><p>早年间的所谓自动化测试大多都属于这种。但这样的测试十分不稳定，一个简单的页面调整就可能导致测试失败。</p><p>尽管现在很多工具推出了headless的方式，可以绕开页面，但它们仍然运行得很慢。而且还需要与很多服务、工具集成起来，环境的搭建也是个问题。所以UI测试位于测试金字塔的顶端，即只需要少量的这种测试，来验证服务和中间件等相互之间的访问是正常的。</p><p>需要指出的是，UI测试并不是针对前端元素或组件的测试。后者其实是前端的单元测试。</p><p>中间这层的服务测试也是某种意义的端到端测试，但它避开了UI的复杂性，而是直接去测试UI会访问的API。也有人管这种测试叫集成测试。它可以直接访问数据库，也可以用H2或SQLite等文件或内存数据库代替；它也可以直接访问其他服务，也可以用<a href=\"https://github.com/dreamhead/moco\">Moco</a>等工具来模拟服务的行为。</p><p>这种测试的好处是，可以测试API级别的端到端行为，不管内部的代码如何重构，只要API的契约保持不变，测试就不需要修改。</p><p>最底层的单元测试就是对某个方法的测试，平时开发同学写的大多是这方面的测试。测试金字塔的建议是，尽可能多地写单元测试，它编写成本低、运行速度快，是整个测试金字塔的基座。</p><p>对于方法内用到的DOC，你可以用测试替身来替换。对于在多大程度上使用测试替身，有两种不同的观点。</p><p>一种观点认为不管任何依赖都应该使用测试替身来代替；一种观点则认为只要DOC不访问数据库、不访问文件系统、不访问进程外的服务或中间件，就可以不用测试替身。前者的学名叫solitary unit test，我管它叫“<strong>社恐症单元测试</strong>”；后者学名叫做sociable unit test，我管它叫“<strong>交际花单元测试</strong>”。</p><p>到底应该使用哪种类型的单元测试呢？这一点并没有定论，支持每种类型的人都不少。我个人更倾向于交际花单测，因为这样写起来更容易，而且对重构很友好。</p><h2>遗留系统中的测试策略</h2><p>学完了测试金字塔，你是不是已经准备按照由少到多的关系，在遗留系统中补测试了呢？先别急，遗留代码有很多特点，导致它们并不适合完全应用测试金字塔来组织测试。</p><p>首先，遗留系统的很多业务逻辑位于数据库的存储过程或函数中，代码只是用来传递参数而已。这样一来单元测试根本测不到什么东西。你也不能在服务测试（或API测试）中使用内存数据库，因为要在这些数据库中复制原数据库中的存储过程或函数，可能会有很多语法不兼容。</p><p>其次，遗留系统的很多业务还位于前端页面中，位于JSP、PHP、ASP的标签之中。这部分逻辑也是没法用单元测试来覆盖的。而服务测试脱离了页面，显然也无法覆盖。</p><p>因此，如果你的遗留系统在前端和数据库中都有不少业务逻辑，就可以多写一些UI测试，它们可以端到端地覆盖这些业务逻辑。你可以从系统中最重要的业务开始编写UI测试。</p><p>然而，UI测试毕竟十分不稳定，运行起来也很慢，当数量上来后这些缺点就会被放大。这时候你可以多编写一些服务测试。</p><p>对于数据库中的业务逻辑，你可以搭建一些基础设施，让开发人员可以在测试中直连数据库，并方便地编写集成测试。这些基础设施包括：</p><ul>\n<li>一个数据库镜像，可以快速在本地或远端做初始化；需要将数据库容器化，满足开发和测试人员使用个人数据库的需求。</li>\n<li>一个数据复制工具，可以方便地从其他测试环境拉取数据到这个镜像，以方便数据的准备；可以考虑通过CI/CD来实现数据的复制。</li>\n</ul><p>除此之外，你可能还需要一个数据对比工具，用来帮你在重构完代码后，比较数据库的状态。比如将一个存储过程或函数中的逻辑迁移到Java代码中的时候，要验证迁移的正确性，只跑通集成测试是远远不够的，还要全方位地比较数据库中相关表的数据，以防漏掉一些不起眼的地方。</p><p>对于前端中的业务逻辑，你可以先重构这些逻辑，将它们迁移到后端中（我将在第十三节课详细讲解如何迁移），然后再编写单元测试或服务测试。</p><p>这时的测试策略有点像一个钻石的形状。</p><p><img src=\"https://static001.geekbang.org/resource/image/5e/c5/5ea17f429b5b6f1a3397238448b49ac5.jpg?wh=1920x1066\" alt=\"图片\"></p><p>确定好了测试的类型，还有一些测试编写方面的小细节我想跟你分享。</p><p>第一个细节是测试的命名。关于测试命名，不同书籍中都有不同的推荐，但我更倾向于像<a href=\"https://time.geekbang.org/column/article/508559\">第四节课</a>中介绍的那样，用“实例化需求”的方式，从业务角度来命名测试，使得测试可以和代码一起演进，成为活文档。</p><p>第二个细节是测试的组织。当测试变多时，如果不好好对测试进行分组，很快就会变得杂乱无章。这样的测试即使是活文档，也会增加认知负载。</p><p>最好的方法是，将单个类的测试都放在同一个包中，将不同方法的测试放在单独的测试类里。而对于同一个方法，要先写它Happy path的测试，再写Sad path。记住一个口诀：<strong>先简单，再复杂；先正常，再异常</strong>。也就是测试的场景要先从简单的开始，逐步递进到复杂的情况；而测试的用例要先写正常的Case，再逐步递进到异常的Case。</p><h2>小结</h2><p>今天学习的知识比较密集，需要好好总结一下。</p><p>我们首先学习了<strong>接缝的位置</strong>和<strong>接缝的类型</strong>。接缝的位置是指那些可以让DOC的行为发生改变的位置，有构造函数、方法参数、字段三种；而接缝的类型则是说改变DOC行为的方式，包括对象接缝和接口接缝。</p><p>遗留代码中有了接缝，就可以着手写测试了。然而复杂的遗留代码很难去梳理清楚头绪，我想你推荐用<strong>决策表</strong>的方式，将测试用例一一列出来。</p><p>在遗留系统中，如果存储过程中包含大量的业务逻辑，传统的金字塔型的测试策略可能并不适合，你可以多写一些端到端的UI测试，以及与数据库交互的集成测试（服务测试）。这时的测试策略呈现一个钻石的形状。</p><p><img src=\"https://static001.geekbang.org/resource/image/5e/c5/5ea17f429b5b6f1a3397238448b49ac5.jpg?wh=1920x1066\" alt=\"图片\"></p><p>最后我想说的是，自动化测试是代码不可或缺的一部分，忽视了测试，即使是新系统，也在向着遗留系统的不归路上冲刺。然而技术社区对于测试的态度总是十分漠视，多年来不曾改观。</p><p>有一次我的同事在某语言群里询问，是否有人愿意给一个开源框架添加测试，然而大家想的却是什么“技术进步性”。</p><p><img src=\"https://static001.geekbang.org/resource/image/9d/2f/9dbed940418bc71d3ebc11fbc0a3d02f.jpg?wh=1920x1351\" alt=\"图片\"></p><p>开发人员如果忽视编写自动化测试，就放弃了将质量内建到软件（也就是自己证明自己质量）的机会，把质量的控制完全托付给了测试人员。这种靠人力去保证质量的方式，永远也不可能代表“技术先进性”。</p><p>有的时候你可能觉得，我就是写了一行代码，加不加测试无所谓吧？反正原来也没有测试。但是，希望你不要这么想，更不要这么做。犯罪心理学中有一个“破窗效应”，意思是说如果一栋楼有几扇窗户是破的，用不了几天所有的窗户都会破掉。这是一个加速熵增的过程，没有测试的系统，就是那座破了窗户的大楼。</p><p>你要记住的是“童子军原则”，也就是当露营结束离开的时候，要打扫营地，让它比你来的时候更干净。你写了一行代码，并把这一行代码的测试加上，你就没有去打破一扇新的窗户，而是让系统比你写代码之前变得更好了。这便是引入了一个负熵，让你的系统从无序向着有序迈出了一步。</p><p>莫以恶小而为之，莫以善小而不为。</p><h2>思考题</h2><p>感谢你听完我的絮絮叨叨，希望今天的课程能唤醒你写测试的意愿。今天的思考题请你分享一段你项目中的代码，并聊一聊你准备如何给它添加测试，别忘了给代码脱敏。</p><p>如果你觉得今天的课程对你有帮助，请把它分享给你的同事和朋友，我们一起来写测试吧。</p>","neighbors":{"left":{"article_title":"07 | 遗留系统现代化的五种策略：重构还是重写？这是一个问题","id":511924},"right":{"article_title":"09 | 代码现代化：如何将一个300行的方法重构为3行？","id":513599}}},{"article_id":513599,"article_title":"09 | 代码现代化：如何将一个300行的方法重构为3行？","article_content":"<p>你好，我是姚琪琳。</p><p>在上节课里，我们学习了如何对遗留代码做可测试化重构，并添加测试。有了测试的保障，接下来就可以大胆地开始重构“烂代码”了。</p><p>在重构了大量遗留代码后，我终于找到了两个最实用的方法，这节课我就带你认识这两种重构遗留代码的利器，我把它们称为“倚天剑”和“屠龙刀”，可以帮你劈开一团乱麻式的代码。</p><p>我曾经用这两种模式将一个300行代码重构为3行。是不是感觉很神奇？</p><h2>基于坏味道的重构</h2><p>在此之前，我先来简单絮叨两句我们重构代码的原则，就是<strong>基于坏味道来重构</strong>。也就是说，我们在重构时，要尽量先去识别《重构》中总结的二十几种坏味道，再用书中对应的重构手法去重构。</p><p>你可能会质疑，要不要这么教条啊？这其实并不是教条。Martin Fowler已经“阅码无数”，甚至可能比我吃的饭都多。他总结出来的坏味道已经足够典型，对应的重构手法也足够好用。我也承认我的智商远不如他，那为什么不能拿来主义呢？</p><p>和第六节课学习代码增量演进时一样，在重构代码之前，我还是先带你识别坏味道，然后再重构。遗留系统的代码，简直是最具代表性的“代码坏味道大观园”。</p><p>尽管重构起来挑战重重，但攻克它们又令人上瘾、着迷、欲罢不能。我这样安排，是为了授之以渔（即重构的方法），而不光是授之以鱼（即重构好的方法）。</p><!-- [[[read_end]]] --><p>准备好了吗？我们开始。</p><h2>倚天剑：拆分阶段</h2><p>我们先来见识见识重构遗留代码的倚天剑，<strong>拆分阶段（Split Phase）</strong>。这是Martin Fowler在《重构（第2版）》中新提出的一种重构手法。当我第一次看到这个手法的介绍时，简直茅塞顿开（当然，我第一次看到《重构》中的很多内容时，都是这个状态）。它解决了我在面临遗留代码时最头疼的问题。</p><p><img src=\"https://static001.geekbang.org/resource/image/03/76/034d1bcaef664422de2971ed7af8a076.png?wh=1920x1088\" alt=\"图片\"></p><p>遗留代码最大的问题就是方法过长。方法长了之后，前后几代开发人员不停往里塞东西，有的加在这里，有的加在那里，导致最后谁都无法分清到底方法做了几件事情。我们都说，方法长了就不是<strong>单一职责（SRP）</strong>了，但更要命的是，由于代码过于混乱，你甚至说不清楚到底有哪些职责。</p><p>拆分阶段就像倚天剑一样，轻巧地把方法到底做了几件事情给拎清楚，把相关的代码组织到一起。</p><p>比如，大多数情况下，一个方法都在处理这样的三个阶段：第一，校验、转换传入的数据；第二，根据传入或转换后的数据，完成业务处理；第三，准备要返回的数据并返回。其中第二个阶段如果过于复杂，还可以拆分成更多的小步骤。</p><p>现在我们来举一个例子。以下代码来自一个拆分阶段的重构Kata，它出自《重构（第2版）》的第1章，作者对原来的代码做了一些简化，使之更适合拆分阶段的重构练习。你可以在<a href=\"https://github.com/gregorriegler/refactoring-split-phase\">GitHub</a>上找到完整的代码。</p><pre><code class=\"language-java\">public class TheatricalPlayers {\n   public String print(Invoice invoice) {\n       var totalAmount = 0;\n       var volumeCredits = 0;\n       var result = String.format(\"Statement for %s\\n\", invoice.customer);\n\n       NumberFormat format = NumberFormat.getCurrencyInstance(Locale.US);\n\n       for (var perf : invoice.performances) {\n           var play = perf.play;\n           var thisAmount = 40000;\n           if (perf.audience &gt; 30) {\n               thisAmount += 1000 * (perf.audience - 30);\n           }\n\n           var thisCredits = Math.max(perf.audience - 30, 0);\n           if (\"comedy\".equals(play.type)) thisCredits += Math.floor((double) perf.audience / 5);\n\n           totalAmount += thisAmount;\n           volumeCredits += thisCredits;\n       }\n       \n       result += String.format(\"Amount owed is %s\\n\", format.format(totalAmount / 100));\n       result += String.format(\"You earned %s credits\\n\", volumeCredits);\n       return result;\n   }\n}\n</code></pre><p>我们一起来看看它有哪些坏味道。</p><p>它计算了演出的总费用以及观众量积分（volume credits，根据到场的观众数量来计算的积分，下次客户再请剧团演出的时候，可以用这个积分获得折扣），并且对这两项数据进行格式化并返回。</p><p>看到这样的描述，估计你的第一反应就是，它违反了<strong>单一职责原则（SRP）</strong>。没错，一个方法承担了计算总费用、计算观众量积分和格式化信息这三个职责。然而我更喜欢用《重构》中介绍的坏味道<strong>发散式变化（divergent change）</strong>来评价它。</p><p><strong>一个类或方法应该只有一个引起它变化的原因</strong>，而对于这个方法来说，显然有三个。如果计算费用的逻辑发生变化，比如观众的基数从30改成了50；如果计算积分的逻辑发生变化，比如演出悲剧也有相应的积分；如果格式化的逻辑发生变化，比如用HTML来输出清单，你都需要修改这个方法。引起它变化的原因，不是一个，而是三个。</p><p>对于这个坏味道，《重构》的建议是，如果不同的变化方向形成了先后顺序，就用<strong>拆分阶段</strong>手法将它们分开。我们来看看该怎么操作。</p><p>首先，在开始正式重构之前，我建议你先运行一下所有的测试，确保通过。</p><p>再仔细观察这段代码，你会发现，很多变量的声明和使用的位置离得非常远。这是遗留代码的典型特点。一方面，一些古老的编程语言或编程风格，以及某些大学课程，要求你把方法内的所有变量都声明在方法开头。另一方面，由于代码经手的人太多，很多人会有意无意将自己的代码插入到变量的声明和使用之间。</p><p>但你应该清楚的是，我们更倾向于<strong>给局部变量更小的作用域</strong>，也就是在使用它之前再声明。</p><p>我们先把result和format两个变量的声明往下挪，挪到result使用之前。仅此一步，你其实已经完成了拆分阶段的部分内容，把格式化部分的逻辑择了出来。</p><p>别忘了运行测试。虽然只有这一步，你几乎可以100%确认没有问题，但你仍然需要运行一下测试，养成好习惯。</p><pre><code class=\"language-java\">public class TheatricalPlayers {\n   public String print(Invoice invoice) {\n       var totalAmount = 0;\n       var volumeCredits = 0;\n       \n       for (var perf : invoice.performances) {\n           var play = perf.play;\n           var thisAmount = 40000;\n           if (perf.audience &gt; 30) {\n               thisAmount += 1000 * (perf.audience - 30);\n           }\n\n           var thisCredits = Math.max(perf.audience - 30, 0);\n           if (\"comedy\".equals(play.type)) thisCredits += Math.floor((double) perf.audience / 5);\n\n           totalAmount += thisAmount;\n           volumeCredits += thisCredits;\n       }\n       \n       var result = String.format(\"Statement for %s\\n\", invoice.customer);\n       NumberFormat format = NumberFormat.getCurrencyInstance(Locale.US);\n       result += String.format(\"Amount owed is %s\\n\", format.format(totalAmount / 100));\n       result += String.format(\"You earned %s credits\\n\", volumeCredits);\n       return result;\n   }\n}\n</code></pre><p>第二步，来看看for循环里面吧。play变量也和使用它的地方差了6行的距离，你一定二话不说，也往下移。但是等等，再仔细观察一下，其实只有一个地方在使用这个play，干脆不用移动了，直接内联（inline）吧。</p><p>注意，我说的移动一行代码和内联，包括后面的提取方法和移动方法，在大多数IDE中都是有快捷键的。我强烈建议你<strong>记住并熟练运用这些快捷键</strong>，它们可以使你事半功倍。后面讲解“屠龙刀”时会专门说说快捷键。</p><p>第三步，计算thisAmount的代码已经集中在了一起，这也是拆分阶段的阶段性成果。不要迟疑，把它们提取成一个方法，彻底和下面的代码划清界限。我们来看看，现在的代码变成了什么样子：</p><pre><code class=\"language-java\">public String print(Invoice invoice) {\n    var totalAmount = 0;\n    var volumeCredits = 0;\n\n    for (var perf : invoice.performances) {\n        int thisAmount = getThisAmount(perf);\n        \n        var thisCredits = Math.max(perf.audience - 30, 0);\n        if (\"comedy\".equals(perf.play.type)) thisCredits += Math.floor((double) perf.audience / 5);\n        \n        totalAmount += thisAmount;\n        volumeCredits += thisCredits;\n    }\n    \n    // format代码\n}\n</code></pre><p>第四步，把totalAmount的累加代码上移，让使用thisAmount和声明thisAmount的代码挨在一起。这时你会发现，thisAmount也只有这一处调用，完全可以内联。你可能正发愁这个变量名不知道怎么改好，这样一内联，它就不见了，真是一了百了。</p><p>第五步，重复上面的第三、四步，把计算thisCredits的方法提取出来，并内联thisCredits。这时for循环内部，只剩短短的两行代码了。</p><pre><code class=\"language-java\">for (var perf : invoice.performances) {\n    totalAmount += getThisAmount(perf);\n    volumeCredits += getThisCredits(perf);\n}\n</code></pre><p>是不是已经很清爽了？但其实还有改进空间，不要停止脚步，我们继续。变量totalAmount和valumeCredits的声明和使用还是分离的，而且它们在循环内部赋值，在循环后面使用，这样的变量似乎只能在循环前面声明。</p><p>第六步，复制一下这个for循环，分别删掉两个for中的volumeCredits和totalAmount的赋值语句，用两个for循环分别计算totalAmount和volumeCredits。对这一步你可能有异议，本来一个循环变为了两个，性能变差了呀。的确，性能是变差了那么一点点，但这一点点性能损失与它所带来的可读性提升相比，根本不值一提。</p><p>第七步，把totalAmount和volumeCredits的声明和各自的for循环移到一起，形成下面这样的形式：</p><pre><code class=\"language-java\">public String print(Invoice invoice) {\n    var totalAmount = 0;\n    for (var perf : invoice.performances) {\n        totalAmount += getThisAmount(perf);\n    }\n    \n    var volumeCredits = 0;\n    for (var perf : invoice.performances) {\n        volumeCredits += getThisCredits(perf);\n    }\n    \n    var result = String.format(\"Statement for %s\\n\", invoice.customer);\n    var format = NumberFormat.getCurrencyInstance(Locale.US);\n    result += String.format(\"Amount owed is %s\\n\", format.format(totalAmount / 100));\n    result += String.format(\"You earned %s credits\\n\", volumeCredits);\n    return result;\n}\n</code></pre><p>到这一步，我们基本完成了拆分阶段的重构。代码本来是一团乱麻，被倚天剑劈成了三段，分别负责计算totalAmount、计算volumeCredits和格式化输出结果。代码已经相当清爽了。</p><p>讲到这，其实你会发现，拆分阶段不过就是重新组织代码，把跟某个逻辑相关的语句，从原先分散的各处拎出来，统统合并在一起。你可以用空行隔开不同阶段，也可以抽取出方法，这样就能让原方法显得更简洁一些。</p><p>因此，第八步，把各个阶段提取成单独的方法，彻底完成重构。</p><pre><code class=\"language-java\">public String print(Invoice invoice) {\n    int totalAmount = getTotalAmount(invoice);\n    int volumeCredits = getVolumeCredits(invoice);\n    return getResult(invoice, totalAmount, volumeCredits);\n}\n</code></pre><p>总结一下我们重构这段代码的八个步骤，如下图：</p><p><img src=\"https://static001.geekbang.org/resource/image/ef/5a/efa27a11abf8f6112c5cfc130841765a.jpg?wh=6580x4220\" alt=\"\" title=\"拆分阶段\"></p><p>把一个长方法拆分成多个阶段，并抽取成小的方法，这样做不但能使代码异常整洁，而且在你需要修改的时候，只需找到相关的小方法，而完全不需要去关心其他小方法内的细节，从而降低了<strong>认知负载</strong>。</p><p>拆分阶段不仅适用于代码拆分，而且也可以用于存储过程和函数的拆分，我们后面在实战篇里还会看到这个模式。</p><p>展示了倚天剑，是时候掏出屠龙刀了，它可以将职责不相关的代码彻底斩断关系。</p><h2>屠龙刀：方法对象</h2><p><strong>方法对象（Method Object）</strong>是极限编程和TDD之父Kent Beck在《实现模式》中提出的一种模式。Kent Beck甚至直言，这是他最喜爱的模式之一。</p><p>所谓方法对象，就是指<strong>只包含一个方法的对象</strong>，这个方法就是该对象主要的业务逻辑。如果你不知道如何隔离不同的职责，就可以“无脑”地使用方法对象模式，将不同职责都提取到不同的方法对象中。</p><p>我们仍然以上面介绍的代码为例来介绍方法对象。拆分阶段完成之后的完整代码如下：</p><pre><code class=\"language-java\">public class TheatricalPlayers {\n    public String print(Invoice invoice) {\n        int totalAmount = getTotalAmount(invoice);\n        int volumeCredits = getVolumeCredits(invoice);\n        return getResult(invoice, totalAmount, volumeCredits);\n    }\n    \n    private int getTotalAmount(Invoice invoice) {\n        var totalAmount = 0;\n        for (var perf : invoice.performances) {\n            totalAmount += getThisAmount(perf);\n        }\n        return totalAmount;\n    }\n    \n    private int getThisAmount(Performance perf) {\n        var thisAmount = 40000;\n        if (perf.audience &gt; 30) {\n            thisAmount += 1000 * (perf.audience - 30);\n        }\n        return thisAmount;\n    }\n    private int getVolumeCredits(Invoice invoice) {\n        var volumeCredits = 0;\n        for (var perf : invoice.performances) {\n            volumeCredits += getThisCredits(perf);\n        }\n        return volumeCredits;\n    }\n    \n    private int getThisCredits(Performance perf) {\n        var thisCredits = Math.max(perf.audience - 30, 0);\n        if (\"comedy\".equals(perf.play.type)) thisCredits += Math.floor((double) perf.audience / 5);\n        return thisCredits;\n    }\n    \n    private String getResult(Invoice invoice, int totalAmount, int volumeCredits) {\n        var result = String.format(\"Statement for %s\\n\", invoice.customer);\n        var format = NumberFormat.getCurrencyInstance(Locale.US);\n        result += String.format(\"Amount owed is %s\\n\", format.format(totalAmount / 100));\n        result += String.format(\"You earned %s credits\\n\", volumeCredits);\n        return result;\n    }\n}\n</code></pre><p>代码的坏味道仍然是<strong>发散式变化</strong>，只不过从方法级别变成了类级别，当三个阶段的任何一个逻辑发生变化的时候，你都需要修改这个类。</p><p>我们要做的就是把getTotalAmount、getVolumeCredits和getResult三个方法都移动到不同的方法对象中。</p><p>你可能会说，这有何难？我最擅长的就是Copy&amp;Paste了。先别急着按Ctrl（Cmd）+ C，IDE普遍提供了强大的重构工具支持，如果不能物尽其用，简直就是暴殄天物了。你完全可以全都使用重构工具来自动完成这些重构，甚至都不需要碰鼠标。</p><p>我在这里就以Mac版的IntelliJ IDEA来演示一下，如何只用键盘就安全地实现移动方法的重构。仔细看好，不要眨眼。</p><p>我们先来移动getTotalAmount这个方法。由于它还调用了getThisAmount，所以必须连带着把它也移走。为了避免这个麻烦，你可以选择先把getThisAmount内联，这样就只需要移动一个方法了。</p><p>你可以把光标放到getThisAmount的方法定义处或者调用处，然后按Cmd+Opt+N，在弹出的对话框中选择“Inline all and remove the method”。</p><p>下一步，按下Opt+F1，唤出选择视图的菜单，再按回车选择第一个Project View，这时焦点正好在TheatricalPlayers类上。你可以按Cmd+N在相同的包内创建一个新类，名字就叫TotalAmountCalculator吧。</p><p>Kent Beck在书中介绍方法对象时说，<strong>可以用方法名的变形作为类名</strong>。如果方法名叫complexCalculation，那么类名就可以叫ComplexCalculator。我们这里的方法叫做getTotalAmount，按同样的思路应该叫TotalAmountGetter，但这个名字并不好，因为getTotalAmount这个名字本身就不好，其实应该叫calculateTotalAmount。</p><p>创建完类之后，IDE会帮我们打开这个类，然而我现在并不打算对这个类做修改。你可以按Ctrl+Tab跳回到TheatricalPlayers类中，把光标放到getTotalAmount方法签名上，按Cmd+F6来修改它的签名，将刚刚创建的TotalAmountCalculator作为方法的参数，在参数默认值的文本框中，可以填new TotalAmountCalculator()。</p><p>按下回车，方法的签名就改好了。你可能会问，为什么要把新建的类作为方法参数呢？方法内又没有用到，这不是多此一举吗？不用急，你很快就会发现原因了。</p><p>接下来就是见证奇迹的时刻。把光标放到getTotalAmount的方法名上，按下F6，会弹出移动方法的对话框，你要选择一个对象来移动你的方法。由于我们想把方法移动到新建的TotalAmountCalculator中，所以当然要选这个。按下回车，getTotalAmount方法就被神奇地移动到了TotalAmountCalculator中。</p><p>现在你应该明白了为什么要把TotalAmountCalculator放到方法参数中了吧？因为要移动方法时，需要选择一个位置，这个位置就是这个方法所依赖的类。放到方法参数中就相当于让它依赖了TotalAmountCalculator，这样你才能在后续移动方法时，选择TotalAmountCalculator作为移动的目标。</p><p>接下来，你可以用同样的方式来移动getVolumeCredits和getResult方法，这里就不一一演示了。完成之后的代码如下：</p><pre><code class=\"language-java\">public String print(Invoice invoice) {\n    int totalAmount = new TotalAmountCalculator().getTotalAmount(invoice);\n    int volumeCredits = new VolumeCreditsCalculator().getVolumeCredits(invoice);\n    return new ResultFormatter().getResult(invoice, totalAmount, volumeCredits);\n}\n</code></pre><p>由于我们是在方法中直接构造的这些DOC，你可以把它们<strong>提取成接缝</strong>，通过构造函数进行注入。我们再做一些重命名，把看着不爽的方法名通通改掉。</p><pre><code class=\"language-java\">public class TheatricalPlayers {\n    private TotalAmountCalculator totalAmountCalculator;\n    private VolumeCreditsCalculator volumeCreditsCalculator;\n    private ResultFormatter resultFormatter;\n    \n    public TheatricalPlayers(TotalAmountCalculator totalAmountCalculator, VolumeCreditsCalculator volumeCreditsCalculator, ResultFormatter resultFormatter) {\n        this.totalAmountCalculator = totalAmountCalculator;\n        this.volumeCreditsCalculator = volumeCreditsCalculator;\n        this.resultFormatter = resultFormatter;\n    }\n    \n    public String print(Invoice invoice) {\n        int totalAmount = totalAmountCalculator.calculate(invoice);\n        int volumeCredits = volumeCreditsCalculator.calculate(invoice);\n        return resultFormatter.format(invoice, totalAmount, volumeCredits);\n    }\n}\n\n</code></pre><p>到这里，方法对象的重构就全部完成了。它就像屠龙刀一样，彻底劈开了不同职责之间的联系，让它们各自位于自己的方法对象里。</p><p>我在重构了大量遗留代码之后发现，虽然不同代码最终的样子不尽相同，但过程中似乎都包含了方法对象。有些可能会进一步重构成行为型的设计模式，有些就干脆以方法对象为终点。可以说，方法对象，是设计模式的中间步骤。</p><p><img src=\"https://static001.geekbang.org/resource/image/1a/51/1a49223e13ac1e0b399216d7110d4451.jpg?wh=7369x4737\" alt=\"\" title=\"方法对象\"></p><p>我们用快捷键秀操作的过程就到此为止了。我强烈建议你跟着文稿，实际操练一遍，体会快捷键编程带来的快感。</p><p><img src=\"https://static001.geekbang.org/resource/image/19/11/198f254a1bd8537bedf2f5347b0fb311.jpg?wh=1920x1178\" alt=\"图片\" title=\"IntelliJ IDEA常用快捷键速记表\"></p><p>我创建了两个关于快捷键的小测验，一个是<a href=\"https://jinshuju.net/f/RD0T8r\">Mac版</a>，一个是<a href=\"https://jinshuju.net/f/KHJfng\">Windows版</a>，你可以刻意练习一下。</p><p>这样做的好处是，每一个步骤都是IDE自动完成的，是比较安全的。即使在没有测试的情况下，也能相对安全地完成重构。当然，我这可不是鼓励你在没有测试的情况下就去重构，这只是万不得已的情况。</p><p>用快捷键来操作，也是IntelliJ IDEA的正确打开方式，它可以大大提高你的开发效率，让你的手速能够跟上你的思维。如果你熟练的话，整个重构过程不超过1分钟就能完成，省去了各种上下文切换的成本，比如键鼠切换、Tab页切换等。</p><h2>重构结束了吗？</h2><p>有人可能认为重构已经结束了，但如果你对代码有洁癖，就不能容忍坏味道的存在。我们虽然提取出了三个方法对象，但代码仍然有问题。</p><p>下面我再提供两种不同的重构方向。你可以来比较一下。</p><h3>重构到策略模式</h3><p>仔细观察TotalAmountCalculator和VolumeCreditsCalculator，你会发现，它们的方法签名非常类似，都是接受一个Invoice参数，返回一个int。这种坏味道叫做<strong>异曲同工的类（Alternative Classes with Different Interfaces）</strong>，我们可以提取接口，让这两个类实现同一个接口：</p><pre><code class=\"language-java\">public interface InvoiceCalculator {\n    int calculate(Invoice invoice);\n}\n</code></pre><p>TheatricalPlayers将变成：</p><pre><code class=\"language-java\">public class TheatricalPlayers {\n    private InvoiceCalculator totalAmountCalculator;\n    private InvoiceCalculator volumeCreditsCalculator;\n    private ResultFormatter resultFormatter;\n    \n    public TheatricalPlayers(InvoiceCalculator totalAmountCalculator, InvoiceCalculator volumeCreditsCalculator, ResultFormatter resultFormatter) {\n        this.totalAmountCalculator = totalAmountCalculator;\n        this.volumeCreditsCalculator = volumeCreditsCalculator;\n        this.resultFormatter = resultFormatter;\n    }\n    \n    // print方法\n}\n\n</code></pre><p>现在，不同的calculator都实现了同一个接口，我们貌似重构到了策略模式。看过《重构与模式》的人可能会暗喜，重构到设计模式可是重构的最高境界啊，我的代码貌似向着“整洁”的方向又迈进了一大步。然而真的是这样吗？我们先来看看另一种重构思路。</p><h3>重构到领域模型</h3><p>我们看看TotalAmountCalculator这个方法对象，它只依赖Invoice类，并且本身没有任何数据。这种大量依赖外部数据，而不依赖自己内部数据的坏味道，叫做<strong>依恋情结（Feature Envy）</strong>。我们可以直接将方法移动到Invoice内部。用上面学到的快捷键，按一下F6就可以搞定。</p><p>移动之后的Invoice类如下所示：</p><pre><code class=\"language-java\">public class Invoice {\n    // 其他代码\n    \n    int calculate() {\n        var totalAmount = 0;\n        for (var perf : performances) {\n            var thisAmount = 40000;\n            if (perf.audience &gt; 30) {\n                thisAmount += 1000 * (perf.audience - 30);\n            }\n            totalAmount += thisAmount;\n        }\n        return totalAmount;\n    }\n}\n</code></pre><p>这时这个方法再叫calculate就不合适了，我们把它改回getTotalAmount，如果你不喜欢get为前缀的名字，也可以叫calculateTotalAmount。</p><p>你还会发现，移动到Invoice中来之后，这个方法就只依赖Performance了，Invoice不过是遍历了多个Performance而已。你可以提取计算单个Performance的Amount的方法，看看会发生什么。</p><pre><code class=\"language-java\">int calculateTotalAmount() {\n    var totalAmount = 0;\n    for (var perf : performances) {\n        int thisAmount = getThisAmount(perf);\n        totalAmount += thisAmount;\n    }\n    return totalAmount;\n}\nprivate int getThisAmount(Performance perf) {\n    var thisAmount = 40000;\n    if (perf.audience &gt; 30) {\n        thisAmount += 1000 * (perf.audience - 30);\n    }\n    return thisAmount;\n}\n</code></pre><p>你会发现getThisAmount方法只依赖Performance，这又是<strong>依恋情结</strong>坏味道。同样的，可以把方法移动到Performance内来消除。移动完之后，calculateTotalAmount变为：</p><pre><code class=\"language-java\">int calculateTotalAmount() {\n    var totalAmount = 0;\n    for (var perf : performances) {\n        int thisAmount = perf.calculateAmount();\n        totalAmount += thisAmount;\n    }\n    return totalAmount;\n}\n</code></pre><p>这时你还可以充分发挥Java stream的语法特性，将for循环也消除掉：</p><pre><code class=\"language-java\">int calculateTotalAmount() {\n    return performances.stream().mapToInt(Performance::calculateAmount).sum();\n}\n</code></pre><p>同样的，VolumeCreditsCalculator方法也存在依恋情结坏味道，可以用同样的方式来重构。都完成后，TheatricalPlayers类的print方法将如下所示：</p><pre><code class=\"language-java\">public String print(Invoice invoice) {\n    int totalAmount = invoice.calculateTotalAmount();\n    int volumeCredits = invoice.calculateVolumeCredits();\n    return resultFormatter.getResult(invoice, totalAmount, volumeCredits);\n}\n</code></pre><p>这时，你可以将totalAmount和volumeCredits内联，这样方法就剩下了一行。它的职责就只剩下了格式化结果，因为计算totalAmount和volumeCredits的逻辑已经被隔离在了Invoice中。那么当前方法和ResultFormatter的职责也重叠了，我们可以把这个getResult方法也内联掉。</p><pre><code class=\"language-java\">public String print(Invoice invoice) {\n    var format = NumberFormat.getCurrencyInstance(Locale.US);\n    var result = String.format(\"Statement for %s\\n\", invoice.customer);\n    result += String.format(\"Amount owed is %s\\n\", format.format(invoice.calculateTotalAmount() / 100));\n    result += String.format(\"You earned %s credits\\n\", invoice.calculateVolumeCredits());\n    return result;\n}\n</code></pre><p>我们把重构出来的三个方法对象，居然又全部消除掉了！</p><p>为什么产生了“消消乐”一样的效果呢？这是因为我们把计算的逻辑都放到了Invoice和Performance对象中，就没有必要引入其他的算法类（方法对象）了。这种<strong>把数据行为都放在对象中</strong>的模式，叫做<strong>领域模型模式</strong>。我们将在下节课详细介绍。</p><p>比较一下上面提到的两种重构方向，你觉得哪种更适合当前的代码呢？我的答案是第二种。</p><p>第一种重构虽然看上去像是“策略模式”，但实际上策略接口的两个实现类并不是相互替换的关系，而是“毫无关系”。所有行为型模式的共同特点是，不同的行为可以根据某些条件相互替换，直白点说就是，要有if/else，才能体现出这些替换。而代码中的TotalAmountCalculator和VolumeCreditsCalculator虽然都叫calculator，但没有if/else，它们在原方法中是顺序执行的，不能相互替换。</p><p>你必须对所有代码坏味道和模式非常熟悉，才能找到正确的重构方向。重构到设计模式固然美好，但并不一定就是最终目标，有时候你可能会用错设计模式，有时候会过度设计。重构到一个刚刚好的状态，没有明显的坏味道，就足够了。</p><h2>小结</h2><p>终于学完了今天的课程，希望你学完的感受是“大呼过瘾”。有时候重构的感觉就是这样，比实际写代码更让人身心愉悦。</p><p>我今天为你展示了重构遗留代码的倚天剑和屠龙刀，希望它们能助你在遗留系统的荆棘之中，杀出一条血路。其实重构手法和模式还有很多很多，我之所以认为这两个特别实用，是因为在重构了大量遗留代码后，我发现<strong>拆分阶段</strong>和<strong>方法对象</strong>是必不可少的中间步骤。</p><p>当你通过这两种方式完成了初步重构之后，还要审视一下代码，根据坏味道实现下一步的重构。</p><p>我还在介绍方法对象的时候，穿插了如何使用快捷键来完成重构。你可能会觉得记住额外的快捷键属于外在认知负载，其实不然。它们能够提高你的工作效率，而且一旦记住并且熟练掌握，就能一劳永逸。这种知识属于内在认知负载，是我们完成工作必须具备的技能。</p><p>重构手法也好，快捷键也罢，都不是什么奇技淫巧，而是像玄铁重剑一样，重剑无锋，大巧不工。它们应该融化在每一个开发人员的血液里。如果你还不熟悉，就抓紧练起来吧。</p><p>无他，唯手熟尔。</p><h2>思考题</h2><p>感谢你学完了今天的内容，希望你能通过书籍和博客去学习一下其他的重构手法和模式。今天的课后作业，还是请你来贴一段项目中的实际代码，我们一起来分析一下其中的坏味道，并通过坏味道来驱动我们重构。</p><p>如果你觉得今天的课程对你有帮助，请把它分享给你的同事和朋友，我们一起来重构吧。下节课，我们继续挑战代码的分层重构，敬请期待。</p>","neighbors":{"left":{"article_title":"08 | 代码现代化：你的代码可测吗？","id":512658},"right":{"article_title":"10 | 代码现代化 ：代码的分层重构","id":514479}}},{"article_id":514479,"article_title":"10 | 代码现代化 ：代码的分层重构","article_content":"<p>你好，我是姚琪琳。</p><p>上节课，我带你学习了重构遗留代码的倚天剑和屠龙刀，也就是<strong>拆分阶段</strong>和<strong>方法对象。</strong>面对遗留代码，它们是披荆斩棘的利器。</p><p>不过，单块逻辑的代码重构好了之后，我们还要迎接新的挑战。今天我们就来看看如何重构整体的代码，也就是如何对代码分层。</p><h2>遗留系统中常见的模式</h2><p>我还记得大学时做的编程作业，用VB6做一个学校图书馆的借书系统。当时的做法十分“朴素”，在点击“借阅”按钮的事件处理器中，我直接读取借书列表中的书籍ID，然后连接数据库，执行一条update语句，把这些书籍的借阅者字段改成当前的学生ID。</p><p>后来，我看到了Eric Evans的《领域驱动设计》这本书，才发现这种做法就是书中介绍的<strong>Smart UI模式</strong>。它虽然简单好理解，但归根结底还是一种面向过程的编程思想。一旦逻辑变得更复杂，这种模式的问题就会凸显出来。</p><p>举个最简单的例子，比如借书前需要校验学生的类型，本科生最多可以借3本，而研究生最多可以借10本。如果本科生借阅了5本书，在点击按钮的时候就会弹出错误消息。我们用伪代码来表示就是：</p><pre><code class=\"language-java\">var bookCount = bookDataTable.count\nvar studentType = DB.query(\"SELECT TYPE FROM STUDENTS WHERE ID = \" + studentId)\nif (studentType = \"本科生\" &amp;&amp; bookCount &gt; 3)\n  MessageBox.error(\"本科生一次最多借阅3本图书\")\nif (studentType = \"研究生\" &amp;&amp; bookCount &gt; 10)\n  MessageBox.error(\"研究生一次最多借阅10本图书\")\n\nfor(var book in bookDataTable.values)\n  DB.update(\"UPDATE BOOKS SET BORROWER_ID = \" + studentId + \" WHERE BOOK_ID = \" + book.id)\n</code></pre><!-- [[[read_end]]] --><p>也许只是添加这几行代码，你并不觉是什么大问题，但紧接着教师的借阅数量也需要校验，讲师和教授的借阅数量也会有不同的限制。当逻辑越来越复杂，这种过程式的代码就只能向一个地方堆代码。即使可以抽一些函数出来，也只能是杯水车薪。</p><p>其实还有更严重的问题：由于将界面展示、业务逻辑、数据库访问都放在一个文件中，<strong>发散式变化</strong>的坏味道十分严重。调整界面布局要改这个文件，修改业务逻辑要改这个文件，甚至修改表名、列名也要修改这个文件。</p><p>除了早期的桌面客户端应用，还有在JSP和ASP中直接写业务逻辑并访问数据库的，也属于Smart UI。除此之外，Martin Fowler在《企业应用架构模式》还提出了<strong>事务脚本（Transaction Script）模式</strong>。该模式分离了用户界面和业务逻辑，但仍然还是按数据的方式去组织业务，没有建立对象模型。</p><p>为了改善这种状况，人们开始重构这种模式。将界面逻辑、业务逻辑和数据库访问分离开来，形成了UI、Service、Dao这样的三层结构。</p><p><img src=\"https://static001.geekbang.org/resource/image/d3/c3/d39636411e3263c192453a7c5495c8c3.jpg?wh=1920x1256\" alt=\"图片\"></p><p>上面的代码也就变成了下面这样（让我们从伪代码切换回Java）。</p><pre><code class=\"language-java\">// UI层\nBookService bookService = new BookService();\nbookService.borrowBook(userData, bookDataList);\n\n// Service层\nif (\"教师\".equals(userData.getType())) {\n  if (\"讲师\".equals(userData.getLevel()) || \"助教\".equals(userData.getLevel())) {\n    if (bookDataList.count() &gt; 20) {\n      throw new BookBorrowException(\"讲师和助教一次最多借阅20本图书\");\n    }\n  }\n  else if (\"教授\".equals(userData.getLevel()) || \"副教授\".equals(userData.getLevel())) {\n    if (bookDataList.count() &gt; 50) {\n      throw new BookBorrowException(\"教授和副教授一次最多借阅50本图书\");\n    }\n  }\n}\nelse if (\"学生\".equals(userData.getType())) {\n  if (\"本科生\".equals(userData.getLevel())) {\n    if (bookDataList.count() &gt; 3) {\n      throw new BookBorrowException(\"本科生一次最多借阅3本图书\");\n    }\n  }\n  else if (\"研究生\".equals(userData.getLevel())) {\n    if (bookDataList.count() &gt; 10) {\n      throw new BookBorrowException(\"研究生一次最多借阅50本图书\");\n    }\n  }\n}\nBookDao bookDao = new BookDao();\nbookDao.borrowBook(userData.getUserId(), bookDataList)\n\n// Dao层\nfor(var book in bookDataList)\n  DB.update(\"UPDATE BOOKS SET BORROWER_ID = \" + userId + \" WHERE BOOK_ID = \" + book.getId())\n</code></pre><p>感觉是不是跟你平时编写的代码十分类似？</p><p>然而在我看来，这样的分层仍然是过程式的，和事务脚本相比，并没有本质区别。它虽然在Service层向Dao层传递数据时使用了对象，但这种不含任何行为的<strong>贫血模型</strong>也只是起了数据传递的作用。</p><p>而且，像代码中的UserData和BookData所定义的位置往往都是很随意的，有时定义在UI层，有时定义在Service层，有时定义在Dao层。上面图中所画的箭头只是代表了数据流动的方向，而不是对象依赖的方向。</p><p>这种模式最大的问题在于，当逻辑变得复杂时，服务层的代码会变得越来越臃肿，不同的服务之间也很难相互调用和复用逻辑，每一个服务类都将变成上帝类（God Class）。</p><h2>领域模型</h2><p>随着面向对象编程范式的流行，越来越多的人倾向于<strong>用对象为要解决的问题建立模型（Domain Model）</strong>，<strong>用对象来描述问题中的不同元素</strong>。<strong>元素中所有的数据和行为都将在对象中有所体现</strong>。也就是说，我们不再用过程来控制逻辑，而是将逻辑分别放入不同的对象中。</p><p>对于上面借书的例子，如果我们把各种判断借书数量是否合规的逻辑，放到不同的User对象中去，将书籍借阅的逻辑，也就是设置书籍借阅状态的逻辑，放到Book中去，就会得到这样的代码：</p><pre><code class=\"language-java\">public abstract class User {\n    public abstract void borrow(Book[] books);\n}\n\npublic class UndergraduateStudent extends User {\n    @Override\n    public void borrow(Book[] books) {\n        if (books.length &gt; 3) {\n            throw new BookBorrowException(\"本科生一次最多借阅3本图书\");\n        }\n        for(Book book : books) {\n          book.lendTo(this);\n        }\n    }\n}\n\npublic class Book {\n    public void lendTo(User user) {\n        status = BookStatus.LEND_OUT;\n        borrowerId = user.getId();\n    }\n}\n</code></pre><p>可以看到，这段代码充分利用了面向对象继承和封装的优势，分解了原来的复杂逻辑，将其分散到不同的对象中去。</p><p>乍一看你也许有点困惑，因为逻辑十分分散，而且想看懂一个业务场景，要在不同的对象之间来回跳转，远不如过程式代码那样直观。而且还会有各种纠结的地方，比如到底是“人借阅书”，还是“书借给人”。</p><p>但这其实就是面向对象的优雅之处，它对客观世界进行了建模，但是并不需要完全去照搬客观世界。</p><p>“人借阅书”还是“书借给人”并不重要，重要的是如何更顺畅地编写代码。比如在我的例子中，既有“人借阅书”，又有“书借给人”。“人借阅书”是为了解决在借阅时的校验问题，“书借给人”是为了将人的信息标记在书上。</p><p>在了解了领域模型模式后，你一定迫不及待地想把事务脚本模式的代码都重构成领域模型了吧？这个重构过程中，你可能分辨不出自己的代码到底属于哪种模式。我可以教你一个小技巧，就是看你要获取一个值的时候，是<strong>从对象中获取</strong>，还是<strong>直接从数据库中查询</strong>。</p><p>比如你想查询一本书是否被借出了，你查询数据库BOOKS表，如果BORROWER_ID这个字段为空，就返回1，那这就是事务脚本模式：</p><pre><code class=\"language-java\">String sql = \"SELECT COUNT(*) FROM BOOKS WHERE BOOK_ID = :bookId AND BORROWER_ID IS NULL\";\"\n\nboolean isBorrowed = DB.query(sql) == 0;\n</code></pre><p>这种处理方式把数据和模型割裂开了，而且IS NULL和==0大概率会把人搞晕，认知负载非常高。</p><p>如果你用SQL去获取一个模型，然后在代码中判断getBorrowerId方法的返回值是否为空，那就是贫血模型模式：</p><pre><code class=\"language-java\">String sql = \"SELECT * FROM BOOKS WHERE BOOK_ID = :bookId\";\nBook book = DB.query(sql);\nif (book.getBorrowerId() != null) { }\n</code></pre><p>这种处理方式把模型当做数据的载体，比单纯的事务脚本要好很多。但是所有判断逻辑都会落在客户端代码处。</p><p>如果你用SQL去获取一个模型，然后调用模型的isBorrowed方法来判断书籍是否被借出，就是领域模型模式：</p><pre><code class=\"language-java\">String sql = \"SELECT * FROM BOOKS WHERE BOOK_ID = :bookId\";\nBook book = DB.query(sql);\nif (book.isBorrowed()) { }\n</code></pre><p>这种处理方式把模型当做数据和行为的载体，把行为封装在了领域模型内部。</p><p><strong>领域模型最重要的一点是，要随着业务的变化而不断演进</strong>。尽管上面的模型对于大学编程课的作业，可能还说得过去，但真实的借阅场景显然更复杂。</p><p>比如，我希望查询一本书籍的所有借阅历史。再比如，书籍的借阅是有有效期的，当有效期快到了的时候，我希望给用户发短信提醒，有效期过了就会有相应的惩罚逻辑。当“借阅”这个名词在业务的描述中频繁出现时，就是一种要为它建模的信号了。</p><p>对于现在的模型来说，“借阅”体现在Book对象的borrowerId这个字段上。你也可以继续在Book上添加validTo这种字段来表示借阅的有效期，但显然借阅历史是无法表示出来的。对于持久化来讲，借阅历史的多条数据显然无法用书籍的一条数据来表示。</p><p>这时，我们就需要为“借阅”来单独建模了。作为书籍和用户之间的关联关系，它其实是某种<strong>关联对象（Association Object）</strong>。</p><pre><code class=\"language-java\">public class Borrowing {\n  private User user;\n  private Book book;\n}\n\npublic class User {\n  private List&lt;Borrowing&gt; borrowings;\n  public void borrow(Book[] books) {\n    for(Book book : books)\n      borrowings.add(new Borrowing(this, book));\n  }\n}\n</code></pre><p>当Borrowing这个模型建立起来后，它就可以持久化起来作为借阅的历史记录，也可以在它上面添加各种业务字段，如有效期等。</p><h2>数据映射器和仓库</h2><p>你可能注意到了，在上面的代码中，我并没有添加任何数据访问相关的逻辑。这也是领域模型模式的一个难点。<strong>领域模型中的字段需要与数据库中的表字段进行双向映射</strong>，通常来说，你可以继续使用之前的Dao来实现这种映射。</p><p>例如当一个借阅发生时，你可以：</p><pre><code class=\"language-java\">public class BorrowingDao {\n  public void insert(Borrowing borrowing) {\n    String sql = \"INSERT INTO BORROWINGS...\";\n    // 执行SQL\n  }\n}\n</code></pre><p>我们把这种方式叫做<strong>数据映射器（Data Mapper）模式</strong>，它<strong>分离了领域模型和数据库访问代码的细节，也封装了数据映射的细节</strong>。</p><p>然而不管是叫BorrowingDao还是BorrowingMapper，都暗示了它们与数据库的关系。在领域模型中，我们往往希望模型更加“干净”，希望使用的是一种和数据访问无关的组件。</p><p>另一方面，这种模式也导致表和领域对象的一一对应。在简单的业务场景下这并不是问题，但在复杂的情况下，你就无法设计出合理的模型。比如上面的例子，一个借阅就是一个Borrowing，这时你很可能放弃给User和Book建模，而直接去构建Borrowing模型，这就又回到<strong>事务脚本</strong>的老路上去了。</p><p>还有一点就是，当查询的需求变得复杂时，数据映射器就显得力不从心了。</p><p>这时我们需要使用的是<strong>仓库（Repository）模式</strong>，让它来负责协调领域模型和数据映射器。仓库模式又被翻译为资源库或者仓储，不过我更倾向于翻译为仓库。在领域驱动设计中，构造一个新的复杂的领域模型时，我们可以使用<strong>工厂（Factory）模式</strong>，那工厂“生产”出来的“产品”，自然要放到仓库中了。</p><p>Repository还有一层意思，就是“知识库”或“智囊团”。之所以把它放在数据映射器之前，就是因为它比数据映射器更懂得如何去查询领域对象，你可以基于它来设计任何你想要的查询。</p><p>仓库的接口与集合的接口十分接近，你可以向仓库中添加对象，也可以从中删除对象，就好像是在操作内存中的集合一样。而实际上，真正执行操作的，是封装在仓库内部的数据映射器。仓库不过是提供了一个更加面向对象的方式，将领域对象和数据访问隔离开来。</p><pre><code class=\"language-java\">public class UserRepository {\n  public void add(User user) { }\n  public void save(User user) { }\n  public User findById(long userId) { }\n}\n</code></pre><p>你还可以为各个仓库创建接口，定义在领域对象所在的包中。将仓库的实现类和数据映射器定义在一起，这样领域模型不依赖任何数据访问的组件，就显得十分整洁了。</p><p>在使用仓库模式时，我们只从领域对象的源头操作。我们不会去对Borrowing创建一个BorrowingRepository，而是将Borrowing放到User内部，然后通过UserRepository去获取User，进而获取到当前User所有的Borrowing。</p><p>这么做的原因是，Borrowing只是一个关联对象，并不是一个所谓的“源头”。如果用领域驱动设计中的术语来说就是，Borrowing不是一个<strong>聚合根（Aggregate Root）</strong>。你也可以将这个“源头”理解为工厂模式创建出来的产品。你要去仓库中取的是一个产品（聚合根），而不是这个产品的某个零件（关联对象）。这也是为什么在DDD中，仓库只是针对聚合根的，只有聚合根才有仓库，聚合根上的其他实体或值对象是没有仓库的。</p><p>最后，由于仓库的接口是面向集合的，复杂查询自然也不在话下。</p><p>我们在实际设计时，为了实现依赖倒置，即领域层不依赖数据访问组件，可以将仓库的接口定义在领域层，而将实现类和数据映射器定义在数据访问层。</p><h2>应用服务</h2><p>解决了业务逻辑和数据访问分离的问题，我们把目光向“前”看，看看业务逻辑之前的逻辑应该如何处理。</p><p>一个软件系统，除了业务逻辑之外，还存在一些非业务的逻辑。比如用户认证、事务、日志记录等。像前面说过的如果一个借阅快到期了就发送通知，这种对于第三方（短信通知）服务的编排，也属于这类逻辑。Martin Fowler等人把这类逻辑叫做<strong>应用逻辑（Application Logic）</strong>。你可以理解成是因为有了应用程序，才会有的逻辑。</p><p>为了把业务逻辑和应用逻辑分离，我们可以使用<strong>服务层（Service Layer）模式</strong>。它是一组在领域模型之上构建的<strong>应用服务（Application Service）</strong>，用来处理某个业务场景相关的应用逻辑。</p><p>从某种意义上，也可以认为服务层是对领域模型的封装，可以对UI层提供更加友好的接口。由于它跟业务场景一一对应，所以Bob大叔在整洁架构里，管它叫做<strong>用例（Usecase）</strong>。</p><p>对于短信通知的场景，应用服务的代码如下所示：</p><pre><code class=\"language-java\">public class BorrowingValidityService {\n  public void validate(long userId) {\n    User user = userRepository.findById(userId);\n    for(Borrowing borrowing : users.allBorowings()) {\n      if(!borrowing.isValid()) {\n        notificationService.send(new BorrowingInvalidMessage(borrowing.getBook()));\n      }\n    }\n  }\n}\n</code></pre><p>注意，判断一个借阅是否有效属于业务逻辑，而在无效时发送短信则属于应用逻辑，要在应用服务中处理。这相当于，领域模型提供了判断借阅是否有效的能力，而如何使用这种能力，是应用逻辑来决定的，不同的场景有不同的用法。</p><p>而对于借阅的应用服务，代码如下：</p><pre><code class=\"language-java\">public class BorrowService {\n  public void borrow(long userId, long[] bookIds) {\n    User user = userRepository.findById(userId);\n    Book[] books = bookRepository.findByIds(bookIds);\n    user.borrow(books);\n    userRepository.update(user);\n  }\n}\n</code></pre><p>我们在应用服务中，通过仓库获取领域模型，调用领域模型中的方法，然后再通过仓库更新领域模型。</p><p>如果你了解领域驱动设计（DDD），一定会相当熟悉应用服务、领域模型、仓库这些模式。但这些模式并不只属于DDD。在DDD诞生之前，这些模式就已经存在了，《企业应用架构模式》中甚至还提出了很多可以替代的模式。DDD只是把这些模式进行组合，形成了一套以领域模型模式为基础的最佳实践。</p><p><img src=\"https://static001.geekbang.org/resource/image/5y/4d/5yy3d4bcb26dd4yyc15dc82c7343ac4d.jpg?wh=1920x1138\" alt=\"图片\"></p><h2>小结</h2><p>我们今天从遗留系统中常见的代码样例说起，将一个事务脚本一步步重构成了DDD中常见的分层架构。这期间穿插着介绍了领域模型、数据映射器、仓库、应用服务等多种模式。不管你的系统位于这个路线的哪个阶段，你都应该有能力把它重构好。</p><p>你可能会说，你的项目业务没有这么复杂，事务脚本也能解决绝大部分应用场景。没错，事务脚本本身就是一种解决领域逻辑位置的模式，但以我的经验，这条路最终会走向混乱。</p><p>有的时候，你之所以觉得业务没那么复杂，是因为在脑子里将业务映射成了数据库表，那么写出的代码自然是事务脚本。如果你不用大脑做这一层映射，而是先将业务直接反映到领域模型中，然后再用代码去实现到数据库表的映射，往往情况就会有所好转。</p><p>你应该刻意培养自己领域建模的意识，如果没有这种意识，那么绝大多数软件对你来说，都只不过是CRUD。</p><p><a href=\"https://time.geekbang.org/column/article/514516\">下节课</a>我们开启架构现代化的挑战，从建设新城区说起，敬请期待。</p><h2>思考题</h2><p>感谢你学完了今天的内容，今天的思考题是这样的。请你把自己的项目对号入座，看看属于哪种模式，你们有没有计划去重构它们呢 ？</p><p>感谢你学完了今天的课程，欢迎你把它分享给你的同事或朋友，我们一起来重构遗留代码。</p>","neighbors":{"left":{"article_title":"09 | 代码现代化：如何将一个300行的方法重构为3行？","id":513599},"right":{"article_title":"11 | 架构现代化 ：在气泡上下文中打造你的新城区","id":514516}}},{"article_id":514516,"article_title":"11 | 架构现代化 ：在气泡上下文中打造你的新城区","article_content":"<p>你好，我是姚琪琳。</p><p>前面三节课，我们学习了代码现代化的多种模式。从这节课开始，我们继续学习如何实现架构现代化。</p><p>需要说明的是，这四个现代化并不是层层递进的关系，而是既可以同时进行，也可以颠倒顺序。</p><p>比如，你既可以先重构代码，再拆分架构，也可以先拆分架构，再重构代码。同时，也可以重组团队结构，专门拉出一个平台团队去搭建DevOps平台。</p><p>我在第二节课和你探讨架构现代化时，曾经用“建设新城区”和“改造老城区”做了一个类比，今天我们就来详细讲讲在“建设新城区”时，都有哪些模式。</p><h2>绞杀植物模式</h2><p>我选择把绞杀植物模式作为架构现代化的第一个模式，因为它的思想影响了很多其他模式，包括气泡上下文、扩张-收缩、修缮者等等。</p><p><a href=\"https://martinfowler.com/bliki/StranglerFigApplication.html\">绞杀植物模式</a><strong>（Strangler Fig）</strong>，这是Martin Fowler在2004年左右提出的，它是一种用新系统替换旧系统的模式。我们在<a href=\"https://time.geekbang.org/column/article/511924\">第七节课</a>学习的遗留系统现代化的五种策略，其中就有Rebuild/Replace策略，绞杀植物模式就是针对这种策略的。</p><p>很多团队在选择了Rebuild/Replace策略后，往往希望一股脑地构建出新的系统或服务，然后直接替换，而忽略了增量演进这个原则。这样做的后果就是，新构建的系统或服务，与原系统有很大差异，甚至根本不可用。</p><!-- [[[read_end]]] --><p>绞杀植物模式描述了绞杀植物是如何工作的。像榕树、无花果树这类绞杀植物，会从宿主植物的头部播种，慢慢向下生长，直到插入土中，长出自己的根。几年甚至几十年过后，这些绞杀植物最终会杀死自己的宿主，占据宿主原来的位置，完成“谋权篡位”。</p><p><img src=\"https://static001.geekbang.org/resource/image/a8/17/a8c5e6a80a22ee8356568a9b15033317.jpg?wh=1990x1954\" alt=\"\" title=\"图片来自：https://martinfowler.com/bliki/StranglerFigApplication.html\"></p><p>我们在替换一个软件系统时也是一样，应该在旧系统旁边搭建一个新系统，让它缓慢增长，与旧系统同时存在，逐步地“绞杀”旧系统。这个“逐步”的意思，其实就是<strong>增量演进</strong>。“同时存在”指的是<strong>并行运行</strong>。</p><p>我们在<a href=\"https://time.geekbang.org/column/article/510594\">第六节课</a>我们讲过一个例子，演示如何用绞杀植物模式来增量演进和并行运行，你可以去复习一下。</p><p>绞杀植物模式不但可以用来替换旧系统，也可以替换一个服务或模块，或者像我们例子中介绍的那样，用独立的服务来替换单体中的模块。</p><p>我的前同事乔梁，在他的著作《持续交付2.0》里总结了这种模式的利弊。它有三个优势：第一，不会遗漏原有需求；第二，可以稳定地提供价值，频繁地交付版本，更好地监控其改造进展。第三，避免“闭门造车”。</p><p>劣势主要来自迭代的风险和成本，绞杀的时间跨度会很大，存在一定风险，而且还会产生一定的迭代成本。</p><p>总之，绞杀植物模式的这种新旧共存、并行运行、小步快跑、逐步替换的思想，你在之后的很多模式里还会找到相似的影子。</p><p>如果拿城市建设来打比方的话，绞杀植物模式就类似于城市迁址。我们在搭建好新址的基础设施（代码库、运行环境、脚手架、配置等）后，就可以把居民（代码）迁移到新址中。但这个过程也应该是逐步进行的，如果一股脑全部搬迁过去，可能就会造成混乱。</p><p>就像明成祖迁都北平，建紫禁城建了三年，迁都仅用了几个月，结果诸事不利，差点被儿子迁回南京。倘若一部分一部分地迁移居民，让先去的那些人逐渐处理掉那些混乱，等全部搬过去之后，就会好很多吧。</p><h2>气泡上下文</h2><p>逐步替换的下一招就是气泡上下文，我还是先和你聊聊它从何而来。</p><p>领域驱动设计的创造者Eric Evans在2013年发表了<a href=\"https://www.domainlanguage.com/wp-content/uploads/2016/04/GettingStartedWithDDDWhenSurroundedByLegacySystemsV1.pdf\">一篇文章</a>，介绍了如何在遗留系统中应用DDD。</p><p>多年来，在落地DDD战术设计的时候，人们往往倾向于选择一个“干净”的<strong>限界上下文（Bounded Context）</strong>。然而在遗留系统中，这种“干净”的上下文可遇不可求，这就导致在遗留系统中应用DDD十分困难。人们只能在Rebuild/Replace的时候，在新的系统中应用DDD战术设计。</p><p>为了能够在遗留系统中使用DDD，Eric在文章中提出了四种模式，其中第一种就是<strong>气泡上下文（Bubble Context）模式</strong>。这里的气泡，指的是用<strong>防腐层（Anticorruption Layer）<strong>隔离开的一个小的</strong>限界上下文</strong>，这个上下文用于特殊的开发目的，并且不打算长期使用。它就像是一个悬浮在遗留系统之上的气泡一样，十分“干净”，却一捅就破。</p><p>什么是防腐层呢？它是Eric在《领域驱动设计》一书中提出的模式，顾名思义是为了隔离不同上下文之间模型不匹配的问题，避免一个上下文中的模型渗透到另一个上下文中。</p><p>当你遇到一个新的需求时，可以评估这个需求，如果它适合的话，可以不在遗留系统中开发这个需求，而是将它放到气泡上下文中，在一个全新的环境内开发这个需求。由于防腐层隔离了遗留系统，因此你可以在气泡中相对自由地进行领域建模，而不必受到遗留系统的限制。</p><p><img src=\"https://static001.geekbang.org/resource/image/56/b4/5629b31198f92c205c228cff8272e7b4.jpg?wh=1665x1026\" alt=\"图片\"></p><p>然而，Eric的气泡上下文是没有自己的数据库的，只能访问遗留系统中的数据库。为此，它提出了<strong>基于防腐层的仓库（ACL-backed Repository）模式</strong>，即在仓库中调用防腐层，由防腐层去直接访问遗留系统数据库。</p><p>我们上节课学过，仓库模式用起来就像是内存中的集合，所以会让人觉得，气泡上下文中真的有自己的数据一样。这样一来，气泡上下文中的开发者就可以专注于业务逻辑开发，而不必关心数据从哪儿来，大大降低了认知负载。</p><p>当然，如果你不想让领域层中的仓库依赖防腐层，就可以将仓库的接口定义在领域层，将仓库的实现类定义在防腐层，以实现依赖倒置。</p><p>就像一些新企业建厂办公（DDD落地），老城区的空间不够或者条件不适合。那么就会建立一个新城区（气泡上下文），按照更适合这些企业需求的方式规划和布局（应用DDD的各种战术模式）。当新城区需要供电供水供暖（数据）时，就拉一条新的管线（基于防腐层的仓库）从老城区来获取这些资源。</p><h2>自治气泡</h2><p>显然，这样的方式是不可能长久的。新需求中必然有需要建新表的时候，如果仍然建立在遗留系统中，就会让遗留系统更加混乱。就像新城区的人多了，却还要跑到老城区的医院和学校去，这就太麻烦了。因此，Eric提出了第二种模式：<strong>自治气泡（Autonomous Bubble）</strong>。</p><p>顾名思义，自治气泡就是<strong>能够自治的气泡，它有自己的数据库，与遗留系统是弱耦合的</strong>。它不再直接访问遗留系统的数据和服务，而是通过<strong>同步防腐层（Synchronizing ACL）</strong>，将遗留系统中的数据同步到自治气泡中。同步的方式可以是轻量级的每日同步脚本，也可以是消息或领域事件。</p><p><img src=\"https://static001.geekbang.org/resource/image/af/69/af242e070c0a093f7b1f4549867d3769.jpg?wh=1920x1223\" alt=\"图片\"></p><p>这就像是新城区中建好了水电气厂，也建好了医院、学校等其他基础设施（数据库），但是工厂的员工、医院的医生、学校的老师（数据）仍然住在老城区，他们需要每天辛苦地通勤到新城区工作（同步数据）。</p><p>你会发现，这种自治气泡非常接近于微服务架构中的一个服务，都有独立的数据库，能够独立演进，与其他服务通过事件等机制进行弱耦合地通信。只不过在微服务架构中，还可以通过API来访问其他服务。而在原始的自治气泡模式中，是彻底隔断了API调用这种方式的。</p><h3>变动数据捕获</h3><p>要想在自治气泡中同步数据，Eric给出的原始方案是用定期脚本或领域事件。其实还有一种方式是<strong>变动数据捕获（Change Data Capture）模式</strong>，简称CDC。它能识别和跟踪数据库中的数据变动，并捕获这种变动，完成一系列后续处理，比如：将变动内容发布到一个事件总线中，再由气泡上下文去消费这个事件，从而同步数据；或者干脆直接连接其他数据库进行同步。</p><p>一般来说，有两种捕获变动数据的方法。</p><p>一种是使用<strong>数据库触发器</strong>。大多数关系型数据库都支持触发器，尤其是Oracle这类数据库，还能在触发器中调用外部服务，做起同步来尤其简单。</p><p>但我要提醒你，使用触发器一定要慎重，如果一个系统有一两个触发器还不算大问题，但有些系统（尤其是遗留系统）就是构建在大量的触发器之上的。这简直就是灾难，因为它们很难管理，你根本不知道一个数据变化会触发哪些行为，以至于无法搞清楚系统是如何工作的。基于大量数据库触发器的系统，认知负载太高了。</p><p>另一种捕获数据的方式是使用一个单独的工具，来<strong>轮询数据库的事务日志</strong>。由于日志本身包含了数据的变动，你根本不需要去解析。工具本身也运行在单独的进程中，也不用担心和数据库产生耦合和竞争。轮询事务日志的做法，可以称得上是最整洁的CDC方案。</p><p>在将单体应用拆分为微服务的时候，CDC是一个经常会使用到的模式。但在微服务架构下，它就有点不合时宜了。因为它把服务内部的数据泄露到了事件总线中，破坏了封装。更好的方式还是应该让服务来发布领域事件（Domain Event）到事件总线中，其他服务来消费领域事件，而不是变动的数据。比如一个订单开始配送了，应该由物流服务发布一个“订单已配送”事件，而不是由CDC来发布一个订单表中，一行数据的变化情况。</p><h3>事件拦截</h3><p>如果你的遗留系统是<strong>事件驱动的架构（Event-Driven Architecture）</strong>，那么恭喜你，你的自治气泡上下文甚至整个架构现代化的工作都轻松了不少。你可以使用<strong>事件拦截（Event Interception）模式</strong>来取代CDC，实现气泡中的数据同步。</p><p>Martin Fowler早在2004年就<a href=\"https://www.martinfowler.com/bliki/EventInterception.html\">提出了这种模式</a>，作为构建绞杀植物应用的一种落地方案。你可以拦截一些系统中已有的事件，为它们编写新的监听程序，来进行数据的同步或开始连带的业务处理。必要的时候也可以在遗留系统中补充一些缺失的事件。</p><h3>遗留系统封装API</h3><p>无论是在气泡上下文中使用基于防腐层的仓库，还是在自治气泡中使用同步防腐层，其实都很别扭。如果你的遗留系统是一个Web系统，可以方便地添加API，最简洁的方式是<strong>将遗留系统封装为若干个API</strong>，对外提供业务能力，供各个气泡上下文访问。</p><p>但你仍然需要在气泡上下文中提供一个防腐层，只不过这个防腐层不再直连遗留系统的数据库，而是去访问遗留系统封装的API。</p><p><img src=\"https://static001.geekbang.org/resource/image/74/17/745775db753279a31bf82f2e206bd417.jpg?wh=1920x1077\" alt=\"图片\"></p><p>在封装API时，强烈建议你新写API，不要复用那些老的API。一方面老API是为特定的页面而编写的，很难被其他气泡复用。另一方面，即使能复用，老页面与气泡的需求变化方向和速率也是不同的，很可能出现为了满足老页面的需求变化而改了API，结果气泡上下文中的功能被破坏了。</p><p>如果你的遗留系统不是基于Web的，就会稍微麻烦一些了。如果还想应用这种模式，可以新建立一个服务，直连遗留系统数据库，对外提供各种API。但这会造成大量的代码和业务的重复，你需要仔细斟酌。</p><p>在应用了<strong>遗留系统封装API模式</strong>后，自治气泡就更像是一个微服务了。它有自己的数据库，对于依赖的数据通过API来访问。当然如果遗留系统本身是基于事件的，你还可以充分利用事件机制，来实现服务之间的松耦合。</p><p>这就像是新城区建设得差不多了，有了自己的水电气厂和医院学校，甚至连工人医生和老师（数据）都住在新城区了（独立的数据库），但对于某些特殊场景，如高端的商场、电影院等，你仍然需要时不时去一趟老城区（调用API）。</p><h2>小结</h2><p>总结一下今天的内容。我们从Martin Fowler“灵光一现”发明的绞杀植物模式出发，接着学习了Eric Evans发明的气泡上下文和自治气泡模式，以及在气泡中可以使用的数据同步和访问方式，包括变动数据捕获、事件拦截和遗留系统封装API。</p><p><img src=\"https://static001.geekbang.org/resource/image/79/0c/790ca7d61fdfd53e47e124d847eyye0c.jpg?wh=1920x832\" alt=\"图片\"></p><p>从气泡上下文，到自治气泡，再到微服务，这其实描述了一个新需求落地成微服务的演进路线。一步到位地去开发一个微服务，认知负载偏高，而且你可能也并不需要。我们按需演进地去开发，认知负载就会低得多，也更容易得到一个刚刚好的架构。</p><p>有很多新需求都可以通过气泡上下文来构建，比如报表、问卷、评分等。在着手开发类似这样的需求前，作为架构师，你应该思考一下：是否仍然在遗留系统中进行开发，是否可以新建一个服务来开发。</p><p>这样可以和遗留系统划清界限、保持隔离。新的服务可以更好地规划和设计，遗留系统也没有变得更糟。这有点类似我们在代码现代化中介绍的新生和外覆方法，它们自己是可测的，同时也没有影响到旧方法。</p><p>气泡上下文一开始可能不需要自己的数据库，只需要从遗留系统中获取数据即可。慢慢地随着需求的迭代，开始有了自己的数据，就可以用自治气泡的方式让它拥有自己的数据库，并通过变动数据捕获或事件拦截的方式来同步遗留系统中的数据，或通过API来访问遗留系统的功能。</p><p>我曾经在项目中使用过很多次气泡上下文模式，当时并不知道这是一种模式，只是想把这种看似与遗留系统不太相干的需求放在外面，不要再和遗留系统纠缠在一起了。没想到用起来效果还真的挺不错。</p><p>无论是绞杀植物还是气泡，以及之前课程里提到的接缝、工厂、仓库，包括新老城区建设等等，其实都是一种隐喻。隐喻不但有助于我们理解概念，还能激发我们在看似不相关的场景中，发现相似点的这种概念性思维（Conceptual Thinking）。</p><p>最后请允许我感叹一句，像Martin Fowler这种看到绞杀植物绞杀了宿主的现象，从而联想到遗留系统也应该以这样的方式进行替换，真的是把概念性思维发挥到了极致啊。</p><p><a href=\"https://time.geekbang.org/column/article/515274\">下一节课</a>，我们继续新城区的建设，来学习如何从一个遗留系统的大泥球单体架构，一步步演进到微服务。</p><h2>思考题</h2><p>感谢你学完了今天的内容，今天的作业请你分享一下，你的项目中是否有意无意使用过气泡上下文来开发新的需求呢？如果有，你们如何处理数据问题呢？</p><p>期待你的分享。 如果你觉得这节课对你有帮助，别忘了分享给你的同事和朋友，我们一起打造新城区。</p>","neighbors":{"left":{"article_title":"10 | 代码现代化 ：代码的分层重构","id":514479},"right":{"article_title":"12 | 架构现代化 ：微服务，你准备好了吗？","id":515274}}},{"article_id":515274,"article_title":"12 | 架构现代化 ：微服务，你准备好了吗？","article_content":"<p>你好，我是姚琪琳。</p><p>上节课我们学习了架构现代化的新城区模式，今天我们继续聊新城区。</p><p>我们在<strong>自治气泡模式</strong>的基础上，通过<strong>事件拦截</strong>来实现数据同步，给气泡和遗留系统之间又加上<strong>API访问</strong>这个通信渠道。这时的自治气泡就和真正的微服务差不多了。</p><p><img src=\"https://static001.geekbang.org/resource/image/86/27/86aa636dc670e25f4a819dcb07111127.jpg?wh=1633x923\" alt=\"图片\"></p><p>有了这种模式，在开发一个全新的需求时，你就可以将新需求实现在新的服务中，通过防腐层和遗留系统隔离，达到自治的目的。这样，新服务可以更好地演进，不受遗留系统的影响；遗留系统也不会因为新需求的增加而带来太多修改。</p><p>然而，单体真的不好吗？微服务一定是目标架构吗？</p><h2>单体和微服务应该如何取舍？</h2><p>这个问题众说纷纭，我先挑几个有代表性的咱们看看。</p><p>早在2015年，Martin Fowler就撰文强调，即使你知道系统会大到值得去使用微服务，也应该<a href=\"https://martinfowler.com/bliki/MonolithFirst.html\">单体先行</a>；然而Stefan Tilkov却说如果你的目标是一个微服务架构，就<a href=\"https://martinfowler.com/articles/dont-start-monolith.html\">不要从单体开始</a>；C4模型的作者Simon Brown的<a href=\"http://www.codingthearchitecture.com/2014/07/06/distributed_big_balls_of_mud.html\">观点</a>则是，如果你连单体都构建不好，凭什么认为微服务就是你想找的答案呢？</p><p>最“气人”的就是《微服务设计》的作者Sam Newman，在被问到应该何时使用微服务时，他的<a href=\"https://www.youtube.com/watch?v=GBTdnfD6s5Q\">回答</a>是：应该在你有足够理由的时候。</p><p><img src=\"https://static001.geekbang.org/resource/image/56/75/564defe704db22e19916929bdb33d675.jpg?wh=1850x1071\" alt=\"图片\"></p><p>这简直让人抓狂，大牛们的观点要么针锋相对，要么似是而非，那到底应该如何取舍呢？我想你也应该为此困惑过吧？</p><!-- [[[read_end]]] --><p>直到有一天，我在网上看到<a href=\"https://www.youtube.com/watch?v=haejb5rzKsM\">一条视频</a>，是Matthew Skelton和Manuel Pais在伦敦一个技术大会上的演讲，题目是：Monoliths vs Microservices is Missing the Point—Start with Team Cognitive Load。我一下子豁然开朗，正好在这里和你分享分享，帮你捅破“窗户纸”。</p><p>单体有单体的好处，微服务也有微服务的好处。同时，选择了任何一种，也都要面对它所带来的问题。所以，单纯从纯技术角度说哪个好，是没有意义的。同样是微服务，有些团队如虎添翼，有些团队却步履蹒跚。这一切的背后并不是技术本身在搞怪，而是人，是团队的认知负载。</p><p>Martin Fowler和Sam Newman们无法用语言表达出来的模棱两可，被如此轻描淡写地化解。就仿佛一个置身四维空间的神，在低头嘲笑三维空间中渺小的人类。这是一个彻彻底底的降维打击。</p><p>也就是说，我们的判断依据不应该是技术本身，而应该是团队的认知负载。哪一种方案对当前团队来说认知负载低，哪一种就更有可能成功。</p><p>我再说得具体些，比如一个包含10个模块的单体系统，目前共有10个开发人员，如果按模块拆分成微服务，平均每个人要维护一个服务，这就超出了人的认知负载。</p><p>正确的方案可能要这样演进：先拆出一个不太大的服务，抽出2到3名开发人员组成新的团队来维护它，然后再慢慢扩张团队，并逐渐拆出新的服务，直到形成一个5到9人的团队维护一个服务这样的比例为止。</p><h2>单体向微服务的演进</h2><p>说完了如何做取舍，现在来聊聊在确定了要拆分之后，我们应该如何演进。</p><h3>大泥球单体架构</h3><p>单体架构往往都是<strong>“大泥球”（Big Ball of Mud）</strong>，这也是遗留系统最常见的情况。</p><p>大泥球架构可能也分一些层次，如常见的三层或四层结构。但它的内部就不忍直视了，特别是业务逻辑层内部，各个模块的边界十分模糊，往往是你调用我，我调用它，它又调用你，循环往复，错综复杂；持久层也好不到哪去，本应属于不同模块的表之间join来join去，形成一张大网。</p><p><img src=\"https://static001.geekbang.org/resource/image/02/yy/02abb1dc594dbb05187a2c20769542yy.jpg?wh=1920x1243\" alt=\"图片\"></p><p>大泥球并不是一种架构风格，也没有人一开始就想构建一个这样的架构，它们只是从简单的分层架构中逐渐腐化而成的。对于小型的、简单的软件来说，选择分层架构没什么不好。只是随着业务的演进，架构没有得到很好地守护，才一步步变成了大泥球。</p><h3>基于组件的单体架构</h3><p>要想改善大泥球架构，最重要的就是把业务模块之间的耦合解开，消除掉模块间的相互依赖关系。同时，也要将数据的所有权分开，让不同的模块拥有不同的数据。这种类型的单体架构我们称之为<strong>基于组件的单体架构</strong>。</p><p><img src=\"https://static001.geekbang.org/resource/image/6c/6a/6c53c70458cyy598730b2b554c70c66a.jpg?wh=1920x1243\" alt=\"图片\"></p><p>当然，要达到这样的理想情况实际很难。因为一个模块想不依赖另一个模块的数据，这不太可能。比如销售模块不可能不依赖库存数据。</p><p>在大泥球中的做法，当然是在销售模块中直接访问库存表，但在基于组件的单体架构中，我们要让库存模块提供一个外部模块可以访问的接口（非Web API），销售模块通过防腐层去调用这个接口，转换成销售业务所需要的库存数据。这样，销售模块就不再直接依赖库存数据表了。</p><p>这种模块之间虽然也有依赖，但比起销售模块依赖库存模块的库存对象来说，还是要好出不少的。它通过防腐层对不同模块进行了隔离，一个模块中模型的修改，不会影响到另一个模块。</p><p>如果大泥球的模块之间比较好解耦，你就可以先将其中一个模块解耦出来，再逐步把其他模块也一一照方抓药。如果没有系统弹性等方面的非功能需求，那么基于组件的单体架构，就是一个比较理想的架构形态了。我常常用“分而不拆”来形容这种架构风格。</p><h3>基于服务的分布式架构</h3><p>当单体内的模块清晰之后，你会发现一些模块描述的是一个大的业务领域，你可以尝试按业务领域给这些模块分组，将它们拆分出来，形成服务。这种架构叫做<strong>基于服务的分布式架构</strong>。Mark Richards和Neal Ford在《软件架构：架构模式、特征及实践指南》这本书中详细介绍了这种架构。</p><p>相对微服务而言，这时的服务是粗粒度的，Neal管它叫做<strong>领域服务</strong>，你要注意这里的领域服务概念，它和DDD中的领域服务并不一样。这里的领域服务是指，<strong>由描述同一块业务领域的多个模块所组成的服务</strong>。比如保险行业的理赔是一个业务领域，它可能由报案、受理、理算、结案等多个模块组成。</p><p>这些服务往往都只有一个用户界面层和数据库。当然，如果数据库成为瓶颈的话，也有可能需要对数据库进行拆分。这里也预告一下，数据库的常见解耦方法，我们在后面的第十五节课和实践篇中再详细展开。</p><p><img src=\"https://static001.geekbang.org/resource/image/e0/20/e0d51a4a7318c6b0921a4c8ce358b420.jpg?wh=1920x1243\" alt=\"图片\"></p><p><strong>基于服务的分布式架构既可以作为一个过渡架构，也可以作为目标架构</strong>。它是一种粗粒度的微服务架构，每个服务都可以独立部署，并包含一个特定领域的所有业务逻辑。你可以自行决定哪些领域需要进一步细化，哪些保持粗粒度就足够满足需求了。</p><p>这种过渡架构优势是什么？一方面，这种架构享受了一部分可扩展性和高可用性，这是分布式架构带来的“增益buff”。同时，由于服务数量并不会很多，也不会像微服务架构那样，带来太多的系统复杂性和运维负担。</p><p>有意思的是，很多项目号称做到了微服务架构，其实质上只是这种基于服务的分布式架构而已。</p><h3>微服务架构</h3><p>如果基于服务的分布式架构仍然无法满足需求，比如同一服务中，不同模块之间弹性需求的差异越来越大，那我们就不得不对模块继续拆分。</p><p>比如理赔领域中的报案模块，需要7x24小时的高可用服务，以支撑客户的自助报案。但其他模块则没有这种需求。当各个模块及其数据库的弹性边界都不同时，就拆分出了微服务架构。</p><p><img src=\"https://static001.geekbang.org/resource/image/6f/yy/6f6d7a4991d13f81c23aafefd66babyy.jpg?wh=1920x1128\" alt=\"图片\"></p><p>在微服务架构下，<strong>业务边界</strong>变得<strong>十分清晰</strong>，<strong>每个服务可以独立部署和演进</strong>，并且<strong>可以选择不同的技术栈</strong>。一个团队只负责一个或少量的服务（业务模块），可以更好地守护住这个服务不被外界腐化。同时由于关注点比较聚焦，认知负载也得到了降低。</p><p>很多人觉得不同技术栈这一点并没有多吸引人，可能是因为并没有看到适用场景，反而是有些人盲目地引入多语言，用不同编程语言去开发相似的业务，凭空增加了很多认知负载。多语言开发是指让不同的语言去处理各自擅长的领域，比如用Python去处理算法，用Scala去处理数据。但如果没有特殊需求，只是凭喜好来混合使用多种技术栈，那简直就是多此一举。</p><p>微服务架构虽然降低了开发人员的认知负载，但却提升了运维人员的认知负载。它实际上是用运维复杂度来置换开发复杂度。开发人员所面对的内容少了，更加聚焦了，但运维人员却从以前运维一个单体服务，变为运维几个甚至几十个上百个微服务。这需要强有力的DevOps文化作为支撑。</p><p>所以，如果你的团队不具备这样的能力和文化，最好不要引入微服务。我们把那种无视团队认知负载，只因为技术先进性而盲目拆分微服务的行为，叫做<a href=\"https://www.thoughtworks.com/radar/techniques/microservice-envy\">微服务强迫症（Microservice Envy）</a>。</p><h2>遗留系统的架构应该如何演进？</h2><p>我们刚才说了很多种架构风格，那到底什么样的架构适合遗留系统呢？如果你的系统目前是一个大泥球单体架构，且已经明确体现出一些问题，比如代码越来越混乱，那就要考虑改进架构了。</p><p>Neal Ford在他的新书《Software Architecture: The Hard Parts》中提出了一个架构解耦的决策树，非常适合辅助你来决定采取什么策略应对遗留系统的架构。</p><p><img src=\"https://static001.geekbang.org/resource/image/7e/8c/7ee273927836c8ae9b1faa38c710a58c.jpg?wh=1774x1080\" alt=\"图片\"></p><p>从这个决策树中可以看出，你首先需要判断，系统是否适合进行模块化？如果不适合，就保留单体架构不动。那如何判断是否适合呢？Neal给出了一些模块化的驱动因素：</p><p><img src=\"https://static001.geekbang.org/resource/image/ba/b1/ba4a46960e03233b56f809ab2dbc57b1.jpg?wh=1774x1080\" alt=\"图片\"></p><p>你可以从可用性、可扩展性、可部署性、可测试性、可维护性几个方面来判断。如果你的系统对这些指标有着比较高的要求，就是适合模块化的；如果并不关心，就可以保留单体结构不变。不过，恐怕很少有系统会不关心这些指标吧。</p><p>如果系统适合模块化，下一步还要判断代码库是否可拆分，也就是是否有可能把一个大泥球代码库拆分成多个小的代码库。Neal在书中给出了三种代码的特征指标来辅助我们判断，分别是：传入传出耦合（Afferent and Efferent Coupling）、抽象性和不稳定性，以及和主序列的距离。这三个指标在课程中就不展开讲了，感兴趣的同学可以去翻翻书。</p><p>如果代码库可拆分，下一步就是判断系统的各个模块之间是否具有清晰的组件边界。如果有，就可以选择<strong>基于组件的分解（Compnent-based Decomposition）模式</strong>，否则可以使用<strong>战术分叉（Tactical Forking）模式</strong>。</p><h3>基于组件的分解</h3><p>基于组件的分解模式适合将单体架构迁移到基于服务的分布式架构上，这往往是我们迈向微服务架构的第一步。</p><p>如果你目前的系统是基于组件的单体架构，轻而易举就能使用这种模式。但如果你的系统仍然是大泥球，但是组件边界相对来说还算比较清晰，也可以使用这种模式。</p><p>Neal在《Software Architecture: The Hard Parts》中介绍了6种组件分解模式，我来简单给你盘点一下：</p><p>1.识别和调整组件大小：统计各个模块的代码语句数，拆分那些过于庞大的组件，使所有组件的语句数趋于一致。</p><p>2.收集公共领域组件：在基于组件的单体架构中，很多组件的功能是类似的，比如邮件通知和短信通知，或者订单通知模块和物流通知模块。识别这些模块并进行合并，有助于消除重复。</p><p>3.展平组件：让组件中的类都位于叶子节点的包中，不要出现孤儿类（即类和其他包平级）。</p><p>4.明确组件依赖：分析组件之间的依赖关系。</p><p>5.构建领域组件：在逻辑上将属于同一领域的组件组合在一起。</p><p>6.创建领域服务：当组件的大小适中、结构扁平，并且按领域分组后，就可以在此基础上拆分出领域服务，构建基于服务的分布式架构了。</p><p><img src=\"https://static001.geekbang.org/resource/image/fc/26/fcdf9b29f03673e710655681d7909326.jpg?wh=1920x1382\" alt=\"图片\" title=\"图片来源：《Software Architecture: The Hard Parts》\"></p><p>需要引起注意的是，在微服务或基于服务的分布式架构中，它们的服务都是这种按组件或领域组件来划分的，它们描述的是业务而不是数据。我见过很多架构师在设计服务的时候，不是按业务划分，而是按比较复杂的实体对象来划分。比如员工服务或商品服务，就只包含员工或商品的增删查改。</p><p>这样的服务我们称之为<a href=\"https://www.michaelnygard.com/blog/2017/12/the-entity-service-antipattern\">实体服务（Entity Service）</a>，是一种典型的反模式。要完成一个简单的业务场景，需要有一个编排服务来编排多个实体服务，这导致业务逻辑位于编排服务中，而不是微服务中；一个常见的业务需求，都可能会涉及多个实体服务的修改，这就导致服务无法独立部署，只能多个服务或整体一起部署。</p><p>这样一来，就跟单体架构没有区别了，甚至更糟，因为它还是分布式的。我们管这种架构叫做<strong>分布式单体（Distributed Monolith）</strong>。</p><p>遗憾的是，网上很多微服务的示例，包括<a href=\"https://spring.io/blog/2015/07/14/microservices-with-spring\">Spring</a> 和<a href=\"https://docs.microsoft.com/en-us/dotnet/architecture/microservices/multi-container-microservice-net-applications/data-driven-crud-microservice\">微软</a>的示例，其实都是分布式单体。当然，它们主要是想描述如何搭建和运维一个服务，但你要长个心眼儿，千万不要以为这样的服务就是微服务的样板，并且盲目效仿。</p><h3>战术分叉</h3><p>如果一个大泥球单体架构中，连相对清晰的组件边界都没有，所有代码混在一起，这种情况拆分起来会十分困难。</p><p>通常来说，当我们考虑从一个大的整体中，把一个小的部分挪出去的时候，方法都是“拆”。但当“拆”不动的时候，你可以变换一下思路，用“删”的方式来实现拆分。这种模式，就叫做<strong>战术分叉</strong>。</p><p>怎么删呢？我们先把系统整体复制一份，然后在复制出来的系统中删掉不需要的代码，保留下来的就是我们希望拆分出来的部分了。</p><p><img src=\"https://static001.geekbang.org/resource/image/0d/05/0dc2e2c5e65d8c04015d814eb1e5f705.jpg?wh=1920x796\" alt=\"图片\"></p><p>在系统之上，你需要构建一个反向代理，根据请求来判断，需要转发给原来的系统，还是复制出来的分叉系统。</p><p><img src=\"https://static001.geekbang.org/resource/image/54/42/54f3ea8c4471f468a50731408f206542.jpg?wh=1523x864\" alt=\"图片\"></p><p>在使用战术分叉之前，你需要先对大泥球加以梳理。尽管代码可能无法体现出很好的模块化，但业务领域还是有边界的。我们可以使用服务蓝图、用户故事地图等工具，来识别企业的业务领域，然后选择一个希望“分叉”出去的<strong>业务能力</strong>。</p><p>在实际操作中，我发现这种模式非常有用。因为很少有系统能够做到真正的模块化，更多的遗留系统现状是，有大体的业务模块，但从代码层面上看，模块之间耦合过于严重，很难通过基于组件的分解模式来拆分。</p><p>采用战术分叉时，开发团队可以立即开始工作，不需要事先做太多的分析。而且在开发人员看来，删代码总是比提取代码要容易得多。但这也会导致两边的系统或服务都不可能删得太干净，相当于从一个大泥球中剔出来一个小泥球，等服务可以独立部署之后，还是会有很多善后工作要做。</p><h2>小结</h2><p>又到了总结的时候。今天这节课，我们学习了应该如何选择遗留系统的目标架构，到底是单体合适，还是微服务合适呢？看起来“二选一”的题目，我们还有更适合自己业务的隐藏选择么？</p><p>拆与不拆，要看认知负载。拆成什么样，要按步骤演进。除了微服务，基于组件的单体架构和基于服务的分布式架构也有可能是大泥球单体的最终目标，如何取舍主要还是看业务上是否具有弹性需求。在拆分时，你可以使用基于组件的分解和战术分叉两种模式。</p><p>微服务是个非常庞大的话题，很难在一节课中体现所有内容。为了更好地帮助你解决遗留系统里的症结，我针对性地选择了遗留系统里常见的架构问题，带你了解业界的经典战术，以及我和团队实践得来的有效方法，希望对你有帮助。</p><p>最后我想奉劝你一句，拆分微服务一定要想清楚为什么要拆。逻辑上分离（分）和在逻辑分离的基础上再做物理上隔离（拆）是两件事，解决的也是两个问题。</p><p>前一个解决的是知识边界封装和解耦的问题，后一个是想要物理隔离后的一些优势（如技术异构、弹性边界、可用性隔离、安全分级隔离、服务级别的独立交付等）。大部分的拆分都承担了后者的成本，但是做的是前者的事儿，没享受到后者的好处。</p><p><a href=\"https://time.geekbang.org/column/article/516170\">下节课</a>起，我们会深入到遗留系统的单体内部，一起学习改造老城区的实用模式，敬请期待。</p><h2>思考题</h2><p>感谢你学完了今天的内容。今天的作业是这样的，请你来描述一下目前你所在的项目属于哪一种架构，是单体还是基于组件的单体？是基于服务的分布式架构还是微服务？你们在架构演进的过程中采用的是什么方式？</p><p>期待你的分享。如果你觉得今天这节课对你有帮助，别忘了分享给你的同事和朋友，我们一起来拆分单体。</p>","neighbors":{"left":{"article_title":"11 | 架构现代化 ：在气泡上下文中打造你的新城区","id":514516},"right":{"article_title":"13 | 架构现代化 ：如何改造老城区前端？","id":516170}}},{"article_id":516170,"article_title":"13 | 架构现代化 ：如何改造老城区前端？","article_content":"<p>你好，我是姚琪琳。</p><p>前面两节课，我们学习了架构现代化中建设新城区的一些模式。从这节课开始，我们来聊聊改造老城区相关的模式。</p><p>我们先回顾下什么是“改造老城区”。改造老城区模式是指对遗留系统内部的模块进行治理，让模块内部结构合理、模块之间职责清晰的一系列模式。也就是说，在遗留系统的单体内部，我们应该如何更好地治理架构。</p><p>我们按照从“前”往“后”的顺序，先从前端开始。</p><h2>遗留系统的前端</h2><p>在第十节课我们学习了一种架构反模式——Smart UI，它是遗留系统最常见的前端模式。以Java Web项目为例，它们往往在JSP页面中掺杂着大量的JavaScript、Java和HTML代码。其中最致命的就是Java代码，因为它们可以随意访问后端的代码，甚至访问数据库。我们重构前端代码最主要的工作，就是移除这些Java代码。</p><p>前端的遗留代码和后端的遗留代码一样，也是坏味道的重灾区。Martin Fowler在《重构（第2版）》中，用JavaScript重写了所有代码示例，这对于前端开发人员是相当友好的。它能帮助你识别出JavaScript中的坏味道，并重构这些代码。</p><p>要重构前端代码，最好也要优先添加测试。但不幸的是，已有的前端测试工具对基于框架（Angular、React、Vue）的JavaScript代码是相对友好的，但遗留系统中的前端代码，既有JavaScript又有Java，很难用前端工具去编写单元测试。</p><!-- [[[read_end]]] --><p>这里我推荐你编写一些E2E测试，来覆盖端到端的场景。或者使用<a href=\"https://htmlunit.sourceforge.io\">HtmlUnit</a> 这样的工具，通过编写Java代码来测试JSP。但实际上HtmlUnit也属于某种程度的E2E测试。</p><h2>重构前端代码</h2><p>前端JSP代码的重构和后端有相似之处，但也有很多不同。我的同事王万德和胡英荣开源了一套端（前端JSP）到端（后端Java API）的遗留JSP<a href=\"https://github.com/yingrong/leave-jsp\">改造方案</a>，包括重构前后的代码对比。我将以这个代码库的代码为示例，给你讲解一下如何重构前端代码。</p><p>我们对于遗留JSP代码的重构，可以分成以下八个步骤。每个步骤都可以小步迭代，增量演进。</p><h3>第一步，梳理业务</h3><p>要想重构前端代码，你必须先搞懂它的含义。类似代码现代化时，我们用活文档工具去理清一个场景，要重构前端代码，你也得先梳理它的业务含义，搞清楚它到底做了哪些事情。遗憾的是，针对前端的活文档工具，现在我还没发现哪种比较好，因为前端有多种语言交织在一起，分析起来太麻烦。</p><p>不过好在前端并不像后端代码那样调用链很深，很多前端代码都是围绕一个页面来展开的，相对来说还算内聚，梳理起来也更容易一些。</p><h3>第二步，模块化</h3><p>梳理完业务逻辑，下一步就是对前端代码进行模块化。这里的模块化是指，按职责把原先冗长的JSP页面拆分出来，分解成多个小的JSP页面，比如header、footer、content等，并将它们include到大页面中。</p><p>开发人员在编写JSP时，很少有这种模块化的思想，导致所有的东西都写到一个文件里。随着页面逻辑越来越复杂，页面里的各种代码越来越多，文件也越来越大。我甚至见过很多超出64KB限制的JSP文件。</p><p>模块化怎么实现，我们结合例子来分析分析。从下面这段to-do list的代码示例，可以很明显地看出它由4个部分组成：一个包含若干hidden字段的form、一个包含一段文字的header、一个包含to-do列表的section和一个包含删除按钮的footer：</p><pre><code class=\"language-xml\">&lt;% List&lt;Todo&gt; todoList = (List&lt;Todo&gt;) request.getAttribute(\"todoList\"); %&gt;\n&lt;section class=\"todoapp\"&gt;\n    &lt;form name=\"todoForm\" action=\"\" method=\"post\"&gt;\n        &lt;input type=\"hidden\" name=\"sAction\"/&gt;\n        &lt;input type=\"hidden\" name=\"title\"/&gt;\n        &lt;input type=\"hidden\" name=\"id\"/&gt;\n    &lt;/form&gt;\n    &lt;header class=\"header\"&gt;\n        &lt;h1&gt;todos&lt;/h1&gt;\n        &lt;input class=\"new-todo\" placeholder=\"What needs to be done?\" autofocus&gt;\n    &lt;/header&gt;\n    &lt;section class=\"main\"&gt;\n        &lt;input id=\"toggle-all\" class=\"toggle-all\" type=\"checkbox\"&gt;\n        &lt;label for=\"toggle-all\"&gt;Mark all as complete&lt;/label&gt;\n        &lt;ul class=\"todo-list\"&gt;\n            &lt;% for (int i = 0; i &lt; todoList.size(); i++) {\n                Todo todo = todoList.get(i);\n            %&gt;\n            &lt;li &lt;%if (todo.getCompleted()) {%&gt; class=\"completed\"&lt;%}%&gt; data-id=\"&lt;%=todo.getId()%&gt;\"&gt;\n                &lt;div class=\"view\" id=\"todo_&lt;%=todo.getId()%&gt;\"&gt;\n                    &lt;input class=\"toggle\" id=\"todo_toggle_&lt;%=todo.getId()%&gt;\" onchange=\"toogle(this)\"\n                           type=\"checkbox\" &lt;%if (todo.getCompleted()) {%&gt; checked &lt;%}%&gt; /&gt;\n                    &lt;label&gt;&lt;%=todo.getTitle()%&gt;\n                    &lt;/label&gt;\n                    &lt;button class=\"destroy\" onclick=\"deleteTodo(this)\"&gt;&lt;/button&gt;\n                &lt;/div&gt;\n                &lt;%--            &lt;input class=\"edit\" value=\"&lt;%=todo.getTitle()%&gt;\"&gt;--%&gt;\n            &lt;/li&gt;\n            &lt;%}%&gt;\n        &lt;/ul&gt;\n    &lt;/section&gt;\n    &lt;footer class=\"footer\"&gt;\n        &lt;%\n            boolean hasCompleted = false;\n            for (Todo todo : todoList) {\n                if (todo.getCompleted()) {\n                    hasCompleted = true;\n                    break;\n                }\n            }\n        %&gt;\n        &lt;%if(hasCompleted) {%&gt;\n           &lt;button class=\"clear-completed\" onclick=\"deleteCompletedTodo()\"&gt;Clear completed&lt;/button&gt;\n        &lt;%}%&gt;\n    &lt;/footer&gt;\n&lt;/section&gt;\n</code></pre><p>对于这段代码，我们就可以将它提取成4个小的JSP页面，重构之后的代码就相当清爽了。</p><pre><code class=\"language-xml\">&lt;section class=\"todoapp\"&gt;\n    &lt;%@ include file=\"todoForm.jspf\" %&gt;\n    &lt;jsp:include page=\"todoHeader.jsp\"/&gt;\n    &lt;jsp:include page=\"todoList.jsp\"/&gt;\n    &lt;jsp:include page=\"todoFooter.jsp\" /&gt;\n&lt;/section&gt;\n</code></pre><h3>第三步，重构JSP中的JavaScript代码</h3><p>将页面拆小后，我们还要继续重构各个小页面中的JavaScript代码。</p><p>长函数是遗留系统前端最常见的坏味道。早年开发JSP页面的都不是专业的前端开发，很多都是赶鸭子上架的后端开发人员，去写一些相对简单的JavaScript代码。或者是不知道怎么写某个页面元素的联动效果，就去论坛复制一大堆代码过来，稍加修改，只要代码能跑就敢提交，很少会清理和重构代码。这些操作导致业务逻辑、显示逻辑和控件操作杂糅在一起，根本没法维护。</p><p>面对这种混乱的代码，我们更要确保思路清晰。你可以按职责来将它分解为若干个小的函数，每个函数只做一件事情。这有点类似于代码重构中的拆分阶段（可以回顾<a href=\"https://time.geekbang.org/column/article/513599\">第九节课</a>），只不过拆分出来的是不同的职责，而不是一个职责的不同阶段。</p><p>下面这段代码是一个页面校验的函数，大体业务是，某家公司在组织团建时需要选择一个团建活动，而不同的团建活动之间有一些校验逻辑。具体的说明可以参考<a href=\"https://github.com/yingrong/leave-jsp/blob/main/src/main/webapp/long_method/before/selectActivity.jsp\">这里</a>。</p><pre><code class=\"language-javascript\">function clickActivityCheck(activityCheckedObject, packageId, activityId) {\n    if (activityCheckedObject.checked) {\n        var countInput = document.getElementById(\"activity_\" + activityId + \"_count\");\n        var count = !countInput.value ? -1 : parseInt(countInput.value);\n        if (count &lt; 1 || count &gt; 50) {\n            alert(\"参加人数必须在1到50之间！\");\n            activityCheckedObject.checked = false;\n            return;\n        }\n        if (activityId === 1) {\n            var checkBox2 = document.getElementById(\"activity_2\");\n            if (checkBox2 &amp;&amp; checkBox2.checked) {\n                alert(\"冬奥两日游和户外探险一日游不能同时选择！\");\n                activityCheckedObject.checked = false;\n                return;\n            }\n        }\n        if (activityId === 2) {\n            var checkBox1 = document.getElementById(\"activity_1\");\n            if (checkBox1 &amp;&amp; checkBox1.checked) {\n                alert(\"户外探险一日游和冬奥两日游不能同时选择！\");\n                activityCheckedObject.checked = false;\n                return;\n            }\n        }\n        if (activityId === 5) {\n            var checkBox1 = document.getElementById(\"activity_1\");\n            if (!checkBox1 || !checkBox1.checked) {\n                alert(\"选择住宿前必须选择冬奥两日游！\");\n                activityCheckedObject.checked = false;\n                return;\n            }\n        }\n        var result = createActivity(activityCheckedObject, packageId, activityId);\n        if (!result.success) {\n            alert(result.errorMessage);\n            activityCheckedObject.checked = false;\n            return;\n        }\n    } else {\n        var countInput = document.getElementById(\"activity_\" + activityId + \"_count\");\n        countInput.value = \"\";\n        activityCheckedObject.checked = false;\n        if (activityId === 1) {\n            var checkBox5 = document.getElementById(\"activity_5\");\n            if (checkBox5 &amp;&amp; checkBox5.checked) {\n                checkBox5.click();\n            }\n        }\n        cancelActivity(activityCheckedObject, packageId, activityId);\n    }\n</code></pre><p>这段代码有点长，不过我稍微解释一下你就清楚了。<br>\n在选择团建活动的时候，用户可以在“冬奥两日游”、“户外探险一日游”、“唱歌”、“吃饭”、“住宿”等活动中做出选择。</p><p>在勾选checkbox的时候，会触发这个函数来进行校验。它首先会校验所填的人数，然后校验所选活动之间的关系，比如冬奥和户外探险不能同时选择，选住宿则必须选冬奥。此外，当取消勾选的时候，也会触发一个联动逻辑，也就是取消冬奥的时候，会连带着一起取消住宿。</p><p>题面分析完了，你想到重构的思路了么？你脑海里涌现的第一个想法可能是这样的：可以将每个if都抽取成函数。但这样抽取出来的函数仍然有很多重复代码，逻辑并没有得到简化，而且页面元素的读写和业务判断还是混杂在一起的。仔细观察你会发现，所有的校验逻辑可以大体上分为3种：校验人数、校验互斥的活动、校验有依赖的活动。</p><p>对校验逻辑做了抽象之后，就可以把代码重构为下面这个样子：</p><pre><code class=\"language-javascript\">function validateActivities(activityId) {\n    var result = validateCount(activityId);\n    if (result.success) {\n        result = validateMutexActivities(activityId);\n        if (result.success) {\n            result = validateReliedActivities(activityId);\n        }\n    }\n    return result;\n}\n\nfunction selectActivity(activityId) {\n    var result = validateActivities(activityId);\n    if (result.success) {\n        result = createActivity(activityId);\n    }\n    return result;\n}\n\nfunction clickActivityCheck(activityId) {\n    let activityInfoRow = new ActivityInfoRow(activityId);\n    if (activityInfoRow.isChecked()) {\n        var result = selectActivity(activityId);\n        if (!result.success) {\n            alert(result.errorMessage);\n            activityInfoRow.setChecked(false);\n        }\n    } else {\n        unSelectActivity(activityInfoRow, activityId);\n    }\n}\n</code></pre><p>注意，这里面还提取了一个ActivityInRow对象，用于保存每一行的活动元素。这样，我们就把页面元素和判断逻辑分离出来了。</p><h3>第四步，移除JSP中的Java代码</h3><p>JSP中，用&lt;% %&gt;括起来的Java代码叫做Scriptlet，正是这样的代码，把JSP变成了Smart UI。其实早在JSTL和EL诞生的时候，就不再推荐使用Scriptlet了。然而十几年来，情况不曾改观，反倒是新型前端框架的兴起，使前后端彻底分离，才遏制住了Scriptlet的滥用之势。</p><p>但对于遗留系统来说，Scriptlet仍然泛滥成灾，重构前端代码的重点，就是移除它们。JSP中的Scriptlet大致可以分为这么几类：</p><p>1.对所有请求执行相同的Java代码，如权限验证。这类Scriptlet可以迁移到后端，写到一个Filter里。<br>\n2.直接与数据库交互的Java代码，如从数据库中查询出数据并显示在table中，或登录页面中验证用户名和密码等。这类Java代码其实处理的都是GET/POST请求，也可以迁移到后端，实现一个新的Servlet，将代码迁移到doGet/doPost中。<br>\n3.控制页面显示逻辑的Java代码，如上面to-do的例子中，从后端拿到一个Todo对象的列表，然后遍历这个列表，用&lt;li&gt;便签展示出来。</p><p>对于第三种Java代码，你可以用JSTL和EL来替换，就像下面这样：</p><pre><code class=\"language-javascript\">&lt;section class=\"main\"&gt;\n    &lt;ul&gt;\n        &lt;c:forEach var=\"todoItem\" items=\"${todoList}\"&gt;\n            &lt;li&gt;${todoItem.title}&lt;/li&gt;\n        &lt;/c:forEach&gt;\n    &lt;/ul&gt;\n&lt;/section&gt;\n</code></pre><p>完成替换后，JSP中就只剩下了HTML、JavaScript和JSTL，已经相当清爽了。如果你的工作就只是移除Java，那么到此就可以告一段落。</p><p>但如果目标是前后端分离，彻底告别JSP，你可能会希望使用纯JavaScript来替换。这时候就可以先保留这部分Scriptlet，等下一步引入前端框架的时候，再来替换。</p><h3>第五步，引入前端框架</h3><p>当Java代码移除之后，我们再引入前端框架。比如对于todoList这个模块，引入Vue后的代码就变成了下面这样：</p><pre><code class=\"language-javascript\">&lt;%\n    List&lt;Todo&gt; todoList = (List&lt;Todo&gt;) request.getAttribute(\"todoList\");\n    ObjectMapper objectMapper = new ObjectMapper();\n    String todoListString = objectMapper.writeValueAsString(todoList);\n%&gt;\n&lt;div id=\"todoListContainer\"&gt;&lt;/div&gt;\n&lt;script&gt;\n    (function () {\n        var todos = JSON.parse('&lt;%=todoListString%&gt;');\n        new Vue({\n            el: \"#todoListContainer\",\n            data: function () {\n                return {\n                    todos\n                }\n            },\n            template:`\n&lt;section class=\"main\" v-show=\"todos.length\"&gt;\n    &lt;ul class=\"todo-list\"&gt;\n        &lt;li v-for=\"todo in todos\" :key=\"todo.id\" :class=\"{completed: todo.completed}\"&gt;\n            &lt;div class=\"view\"&gt;\n                &lt;input class=\"toggle\" v-model=\"todo.completed\" type=\"checkbox\" @change=\"toggleComplted(todo)\"/&gt;\n                &lt;label&gt;{{todo.title}}&lt;/label&gt;\n                &lt;button class=\"destroy\" @click=\"deleteTodo(todo)\"&gt;&lt;/button&gt;\n            &lt;/div&gt;\n        &lt;/li&gt;\n    &lt;/ul&gt;\n&lt;/section&gt;\n            `,\n            methods: {\n                toggleComplted: function (todo) {\n                    var sAction = \"markDone\";\n                    if (!todo.completed) {\n                        sAction = \"markUnfinished\";\n                    }\n                    rootPage.toggleTodo(todo.id, sAction);\n                },\n                deleteTodo: function (todo) {\n                    rootPage.deleteTodo(todo.id);\n                }\n            }\n        });\n    })();\n&lt;/script&gt;\n</code></pre><p>注意，我们这里只是使用脚本的方式引入了Vue。要想更好地使用前端框架，你还需要对这些代码进行组件化和工程化。为了实现小步前进，我们把这两部分内容交给第六和第七步。</p><h3>第六步，前端组件化</h3><p>引入前端框架之后，我们就可以进一步重构，将前面拆分出来的各个模块转换为组件。比如上面的Vue可以转换为下面这样的组件：</p><pre><code class=\"language-plain\">var todoListComponent = {\n    props:{\n        todos: {\n            type: Array\n        }\n    },\n    template:`\n&lt;section class=\"main\" v-show=\"todos.length\"&gt;\n    &lt;ul class=\"todo-list\"&gt;\n        &lt;li v-for=\"todo in todos\" :key=\"todo.id\" :class=\"{completed: todo.completed}\"&gt;\n            &lt;div class=\"view\"&gt;\n                &lt;input class=\"toggle\" v-model=\"todo.completed\" type=\"checkbox\" @change=\"toggleComplted(todo)\"/&gt;\n                &lt;label&gt;{{todo.title}}&lt;/label&gt;\n                &lt;button class=\"destroy\" @click=\"deleteTodo(todo)\"&gt;&lt;/button&gt;\n            &lt;/div&gt;\n        &lt;/li&gt;\n    &lt;/ul&gt;\n&lt;/section&gt;\n            `,\n    methods: {\n        toggleComplted: function (todo) {\n            var sAction = \"markDone\";\n            if (!todo.completed) {\n                sAction = \"markUnfinished\";\n            }\n            this.$emit(\"toggle-todo\", todo.id, sAction);\n        },\n        deleteTodo: function (todo) {\n            this.$emit(\"delete-todo\", todo.id);\n        }\n    }\n}\n</code></pre><p>在index.jsp文件中，就可以使用这种方式来引用这个组件：</p><pre><code class=\"language-javascript\">&lt;div id=\"app\"&gt;\n    &lt;todo-list-component :todos=\"todos\" v-on:toggle-todo=\"toggleCompleted\" v-on:delete-todo=\"deleteTodo\" &gt;\n    &lt;/todo-list-component&gt;\n&lt;/div&gt;\n</code></pre><p>此时组件的初始化数据还是从request中获取的，要把它们替换成对后端的Ajax调用。这需要你改造一下原有的Servlet，让原本在request中设置attribute的Servlet返回json：</p><pre><code class=\"language-java\">ObjectMapper objectMapper = new ObjectMapper();\nPrintWriter out = response.getWriter();\nresponse.setContentType(\"application/json;charset=UTF-8\");\nresponse.setCharacterEncoding(\"UTF-8\");\nresponse.setStatus(HttpServletResponse.SC_OK);\nList&lt;Todo&gt; todoList = todoRepository.getTodoList();\nout.write(objectMapper.writeValueAsString(todoList));\nout.flush();\n</code></pre><p>这时，前端页面中的所有Scriptlet都清除干净了，你可以将文件名的后缀从jsp改为html了。</p><h3>第七步，前端工程化</h3><p>我们上一步虽然将小模块都转换成了前端组件，但它们还是通过&lt;script&gt;的方式引入到页面中的，只能说是个半成品。要构建一个现代化的前端应用，工程化是必不可少的。</p><p>对于上面的例子，我们引入Vue CLI，它能更好地管理Vue组件。比如之前的todoList.js，将会变成下面这样的TodoList.vue：</p><pre><code class=\"language-java\">&lt;template&gt;\n  &lt;section class=\"main\" v-show=\"todos.length\"&gt;\n    &lt;ul class=\"todo-list\"&gt;\n      &lt;li v-for=\"todo in todos\" :key=\"todo.id\" :class=\"{completed: todo.completed}\"&gt;\n        &lt;div class=\"view\"&gt;\n          &lt;input class=\"toggle\" v-model=\"todo.completed\" type=\"checkbox\" @change=\"toggleComplted(todo)\"/&gt;\n          &lt;label&gt;{{todo.title}}&lt;/label&gt;\n          &lt;button class=\"destroy\" @click=\"deleteTodo(todo)\"&gt;&lt;/button&gt;\n        &lt;/div&gt;\n      &lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/section&gt;\n&lt;/template&gt;\n&lt;script&gt;\nimport $ from 'jquery';\nexport default {\n  name: \"TodoList\",\n  props:{\n    todos: {\n      type: Array\n    }\n  },\n  methods: {\n    toggleComplted: function (todo) {\n      console.log(\"toggleComplted \")\n      console.log(todo)\n      var sAction = \"markDone\";\n      if (!todo.completed) {\n        sAction = \"markUnfinished\";\n      }\n      $.ajax({\n        url: \"/todo-list/ajax?sAction=\" + sAction,\n        method: 'post',\n        data: {\n          id: todo.id\n        },\n        error: function () {\n          todo.completed = !todo.completed;\n        }\n      })\n    },\n    deleteTodo: function (todo) {\n      var _this = this;\n      $.ajax({\n        url: \"/todo-list/ajax?sAction=delete\",\n        method: 'post',\n        data: {\n          id: todo.id\n        },\n        success: function () {\n          _this.$emit('delete-todo', todo.id);\n        }\n      })\n    }\n  }\n}\n&lt;/script&gt;\n</code></pre><p>第五步到第七步这三步，如果要改造的页面比较多，无法在一个交付周期内改造完成。你就可以采取这种<a href=\"https://www.thoughtworks.com/radar/techniques/spa-injection\">单页应用注入（SPA Injection）</a>的方式来逐步地完成替换。</p><p>它与绞杀植物模式的思想类似，都是一种以新替旧的方法。只不过与绞杀植物由外及内（outside-in）的替换方式不同，单页应用注入是由内及外（inside-out）的。它把SPA注入到JSP内部，先替换一个局部的组件，然后再慢慢扩散，直到替换完全部功能。通过这种方式，我们就能让SPA和老的JSP共存，更有利于增量演进。</p><h3>第八步，API治理</h3><p>完成了前面的七个步骤，前端的工作基本上告一段落，接下来要治理的就是后端的API了。在第七步，我们已经将部分Servlet改造成了对Ajax调用友好的API，但这还不够，你可以更进一步，将它们改写为REST API，并且对后端进行分层，以消除事务脚本。这就比较接近<a href=\"https://time.geekbang.org/column/article/514479\">第十节课</a>代码分层重构的内容了。</p><h2>微服务架构下的前端</h2><p>前端代码的重构是个浩大的工程，持续的时间会很长。因此我通常不建议直接重构遗留系统的所有前端代码，而是以后端的微服务拆分为契机，拆分出来哪些模块，就重构哪些模块的前端。这样重构的范围会更小，拆分出来的服务从前到后也都是现代化的。</p><p>但这样一来会出现一个问题，老的页面仍然是JSP的，而新的页面已经组件化工程化了，如何集成呢？你可以使用<a href=\"https://martinfowler.com/articles/micro-frontends.html\">微前端（Micro frontend）</a>技术。</p><p>微服务是把庞大的单体应用分解成小的、认知负载低的服务，从而将“大事化小，小事化了”。微前端也是同样的思路，它将一个单体的前端应用拆分为多个小型的前端应用，并通过某种方式聚合到一起。各个前端应用可以独立运行、开发和部署。</p><p>对于这一部分的内容，推荐你参考我的同事黄峰达开源的一套微前端框架<a href=\"https://github.com/phodal/mooa\">Mooa</a>，还有跟它配套套的<a href=\"https://github.com/phodal/microfrontends\">微前端解决方案文档</a>。</p><h2>小结</h2><p>又到了总结的时候。</p><p>今天我们学习了遗留系统前端的特点，以及前端重构的八个步骤， 分别是：梳理业务、模块化、重构JavaScript、移除Scriptlet、引入前端框架、前端组件化、前端工程化和API治理。</p><p><img src=\"https://static001.geekbang.org/resource/image/c6/4a/c671068a2e4f5c26e57a93a9728ecc4a.jpg?wh=1920x512\" alt=\"图片\"></p><p>最后，为了在旧页面中更好地集成新的前端组件，我还带你粗略地了解了微前端技术。</p><p>在重构前端的时候，对开发人员的要求是很高的。如果他只会前端，可能无法移除Scriptlet；如果只会后端，也许可以按重构Java代码的方式重构JavaScript，但却很难对前端进行组件化和工程化，更别提什么微前端。</p><p>作为架构师或重构负责人的你，这时候需要带领不同能力的人一起攻关，必要的时候可以让他们结对，以发挥不同人的特长。</p><p>前端的治理就像是对老城区中的“老破小”小区粉刷了一遍外墙，让它变得好看了一些。但实际上，你还是需要好好整治一下内部结构（后端代码），否则就是虚有其表。<a href=\"https://time.geekbang.org/column/article/517058\">下节课</a>我们就来学习一下，如何治理老城区的后端架构。</p><h2>思考题</h2><p>感谢你学完了今天的内容，我今天在讲解的过程中故意遗漏了一点，那就是如何遵循<strong>以增量演进为手段</strong>这个原则，不知道你是否看出来了。要想更好地对前端遗留代码进行增量演进，除了小步替换以外，还需要在出现问题时能够及时回退。</p><p>你能说说如何实现前端的回退吗？如果需要，可以回过头去复习一下<a href=\"https://time.geekbang.org/column/article/510594\">第六节课</a>的内容。期待你的分享。</p><p>欢迎你在评论区留下你的思考，也欢迎你把这节课分享给你的同事和朋友，我们一起重构前端。</p>","neighbors":{"left":{"article_title":"12 | 架构现代化 ：微服务，你准备好了吗？","id":515274},"right":{"article_title":"14 | 架构现代化 ：如何改造老城区后端？","id":517058}}},{"article_id":517058,"article_title":"14 | 架构现代化 ：如何改造老城区后端？","article_content":"<p>你好，我是姚琪琳。</p><p>在上一节课中，我们学习了如何重构遗留系统的前端，一共分成了八个步骤，其中最后一个步骤是API治理。这其实就是去重构遗留系统的后端。</p><p>在第九、十节课，我们已经从代码层面讲解了如何重构和分层。而这节课，我们主要会从架构层面，带你看看在面对一个新需求或技术改进的时候，如何更好地重构和组织后端代码。</p><p>如果说在气泡上下文中开发新的需求，类似于老城区旁边建设一个新城区，那么在遗留系统中开发新的需求，就类似于在老城区内部开发新的楼盘。这就必然要涉及到拆迁的问题。</p><p>拆迁终归是一个声势浩大的工程，居民要先搬到别的地方，再拆除旧的建筑，盖起新的楼宇，一番折腾之后，老居民才能搬进新家。不过软件的好处就在于它是“软”的，不需要这么费劲儿。你可以很容易地复制、删除和添加新的代码，轻松地实现一个架构的变迁。</p><h2>修缮者</h2><p>绞杀植物模式适合于用新的系统和服务，替换旧的系统或旧系统中的一个模块。在旧系统内部，也可以使用类似的思想来替换一个模块，只不过这个模块仍然位于旧系统中，而不是外部。我们把这种方式叫做<strong>修缮者模式</strong>。</p><p><img src=\"https://static001.geekbang.org/resource/image/4e/4a/4efdb7aa98481f6096a665cfd514484a.jpg?wh=1920x584\" alt=\"图片\"><br>\n在修缮时，我们通过开关隔离旧系统待修缮的部分，并采用新的方式修改。在修缮的过程中，模块仍然能通过开关对外提供完整功能。</p><!-- [[[read_end]]] --><p>这就好比是在老城区中修路，如果断路施工对交通的影响就太大了。更常见的做法是修缮其中的半条路，留另外半条来维持交通。不过，这必然会造成一定的拥堵。但在软件中就好办多了，我们可以将道路（待修缮的模块）“复制”出来一份，以保障通行正常。等原道路修缮好之后，再删除掉复制出来的道路即可。</p><p>我曾经用修缮者模式去修复过一个性能问题。当时一个API的请求特别慢，我在本地修好后，在生产环境改观不大。我推测这应该是数据分布导致的问题，本地环境的数据分布无法准确模拟生产环境。但当时的安全策略不允许我们访问生产数据库。</p><p>于是，接下来做调优时，我并没有直接修改这个API，而是将API复制了一份出来，一个用来维持老的功能，一个用来性能调优。同时添加了一个针对这个API的Filter，根据开关来决定要调用哪个API。通过收集调优API中的日志，不断地优化，直到解决性能问题。这时再清理掉旧API、Filter和开关。</p><p>这样做的好处是，由于你无法预测修缮过程中会产生哪些问题，这种通过开关保留回退余地的方法，显然是更灵活的。</p><p>上节课在学习前端重构时，我留的思考题是如何实现前端的增量演进和随时回退，其实也是这种修缮者模式的思想。将所有要修改的页面复制出来一份，然后再加入开关，就可以放心地重构页面了。</p><p>在第六节课讲代码增量演进时，我给你举的那个例子，就是在没有单元测试的情况下，通过修缮者的方式来重构的。我们把代码复制出来，重构完之后，通过开关在调用端切换，以完成A/B测试，从而实现安全地重构。</p><pre><code class=\"language-java\">// 旧方法\npublic List&lt;int[]&gt; getThem() {\n　List&lt;int[]&gt; list1 = new ArrayList&lt;int[]&gt;();\n　for (int[] x : theList)\n　　 if (x[0] == 4)\n　　　 list1.add(x);\n　return list1;\n}\n// 新方法\npublic List&lt;Cell&gt; getFlaggedCells()  {\n  return gameBoard.stream().filter(c -&gt; c.isFlagged()).collect(toList());\n}\n// 调用端\nList&lt;int[]&gt; cells;\nList&lt;Cell&gt; cellsRefactored;\nif (toggleOff) {\n  cells = getThem();\n  // 其他代码\n}\nelse {\n  cellsRefactored = getFlaggedCells();\n  // 其他代码\n}\n</code></pre><p>当时我卖了一个关子，说还有一种更优雅的重构方式，你还记得吗？</p><h2>抽象分支</h2><p>这种优雅的方式就是，把要重构的方法重构成一个<strong>方法对象</strong>，然后提取出一个接口，待重构的方法是接口的一个实现，重构后的方法是另一个实现。按这种方式重构之后的代码如下所示：</p><pre><code class=\"language-java\">public interface CellsProvider {\n  List&lt;int[]&gt; getCells();\n}\n\npublic class OldCellsProvider implements CellsProvider {\n  @Override\n  public List&lt;int[]&gt; getCells() {\n    List&lt;int[]&gt; list1 = new ArrayList&lt;int[]&gt;();\n    for (int[] x : theList)\n      if (x[0] == 4)\n        list1.add(x);\n    return list1;\n  }\n}\npublic class NewCellsProvider implements CellsProvider {\n  @Override\n  public List&lt;int[]&gt; getCells() {\n    return gameBoard.stream().filter(c -&gt; c.isFlagged()).map(c -&gt; c.getArray()).collect(toList());\n  }\n}\n</code></pre><p>在调用端，你只需要通过工厂模式，来根据开关得到CellIndexesProvider的不同实现，其余的代码都保持不变。在通过A/B测试之后，再删除旧的实现和开关。</p><p>这种方法不但可以进行安全地重构，还可以用新的实现替换旧的实现，完成功能或技术的升级。我们把这种模式叫做<a href=\"https://martinfowler.com/bliki/BranchByAbstraction.html\">抽象分支（Branch by Absctration）</a>。</p><p>当我们进行大的技术改动时，通常需要花费较长的时间。比如用MyBatis替换Hibernate，或用Kafka替换RabbitMQ。</p><p>传统的做法是，在当前的产品代码分支上创建一个新的分支，大规模去重写。这个分支发布之前要经历很长一段时间，直到最后全部修改完成后，才能把分支合并到产品代码分支上。更糟糕的是，这样做合并时的代码冲突会非常严重，而且架构调整后，首次上线大概率会出问题，交付风险非常高，无法做到增量演进。</p><p>为了解决这样的问题，Martin Fowler提出了抽象分支模式。可以在不创建真实分支的情况下，通过技术手段，将大的重构项目分解成多个小步骤，每个小步骤都不会破坏功能，都是可以交付的，这样就可以逐步完成架构的调整。</p><p><img src=\"https://static001.geekbang.org/resource/image/63/5e/63cbe62a638d900d6acb31aa3081775e.jpg?wh=1690x810\" alt=\"图片\"></p><p>它的基本步骤是这样的。先为旧实现创建一个抽象层，让旧的模块去实现这个抽象层。注意<strong>，这里的抽象层并不一定是接口，有可能是一系列接口或抽象类</strong>。</p><p>然后，让部分调用端代码依赖这个抽象层，而不是旧的模块。同样要注意，<strong>这个替换是逐步进行的</strong>，不是一次性全部替换掉。等全部调用端都依赖抽象层后，开始编写新的实现，并让部分模块使用新的实现。这个过程也是逐步进行的，一方面可以更好地验证新实现，另一方面也可以随时回退。当全部调用端都使用新的实现后，再删除旧的实现。</p><p>有的时候你需要让新旧实现同时存在，对不同的调用端提供不同的实现，这也是很常见的情况。</p><p>由于新代码一直可以工作，因此你可以不断提交、不断交付、不断验证。</p><p>在实际工作中，抽象分支的运用还是非常广泛的。我以前曾经面对过一个技术改动，在初始化Redis的时候，改为从配置文件中读取密码，而不是从数据库中读取密码。对于这样一个替换，你可能直接三下五除二就完成了，但我领悟了抽象分支之后，发现可以用更加优雅的方式实现这个替换。我把整个思考和实现的过程写成了一篇<a href=\"https://mp.weixin.qq.com/s/X_7RC567aYrrO_MzykmdRQ\">博客</a>，你可以当做加餐，阅读一下。</p><h2>扩张与收缩</h2><p>有的时候我们要修改的是接口本身（这里的接口是指方法的参数和返回值），这时候就不太容易通过抽象分支去替换了。</p><p>我们还是拿前面第六节课用过的例子做讲解，以前返回的是List&lt;int[]&gt;，而现在我们想打破这个接口，返回List<cell>。因为List&lt;int[]&gt;仍然存在严重的基本类型偏执的坏味道，而且本来已经提取了Cell类，又通过getArray返回数组，简直是多此一举。</cell></p><p>这时你可以使用<a href=\"https://martinfowler.com/bliki/ParallelChange.html\">扩张-收缩（expand-contract）模式</a>，也叫<strong>并行修改（Parallel Change）模式</strong>。它一般包含三个步骤，即扩张、迁移和收缩。这里的扩张是指建立新的接口，它相比原来旧的代码新增了一些东西，因此叫做“扩张”；而收缩是指删除旧的接口，它比之前减少了一些东西，因此叫“收缩”。</p><p>一般来说，它会在类的内部新建一些方法，以提供新的接口（即扩张），然后再逐步让调用端使用新的接口（即迁移），当所有调用端都使用新的接口后，就删除旧的接口（即收缩）。</p><p>拿刚才这个例子来说，提取完方法对象后的代码如下所示：</p><pre><code class=\"language-java\">public class CellsProvider {\n  public List&lt;int[]&gt; getCells() {\n    List&lt;int[]&gt; list1 = new ArrayList&lt;int[]&gt;();\n    for (int[] x : theList)\n      if (x[0] == 4)\n        list1.add(x);\n    return list1;\n  }\n}\n</code></pre><p>你可以在这个方法对象中进行扩张，新增一个方法，以提供不同的接口：</p><pre><code class=\"language-java\">public class CellsProvider {\n  public List&lt;int[]&gt; getCells() {\n    // 旧方法\n  }\n  public List&lt;Cell&gt; getFlaggedCells() {\n    return theList.stream().filter(c -&gt; c.isFlagged()).collect(toList());\n  }\n}\n</code></pre><p>然后，我们让调用端都调用这个新的getFlaggedCells方法，而不是旧的getCells方法。在替换的过程中，新老方法是同时存在的，这也是为什么这个模式也叫并行修改。</p><p>等所有调用端都修改完毕，就可以删掉旧方法了。</p><p><img src=\"https://static001.geekbang.org/resource/image/36/ba/362de65418e023394bd7ce1bc6c1baba.jpg?wh=1920x929\" alt=\"图片\"></p><p>在老城区改造的过程中，这种扩张与收缩模式也是很常见的。去年我所在的城市完成了一次取暖线路改造，从以前的小区锅炉房供暖改成了全市的热力供暖。施工方并没有将小区内旧的供暖管道直接连到市政热力的管线上，而是在旧的管线旁边新铺了一条管线（即扩张），连接到市政管线。</p><p>在供暖期，两条管线是并行运行的，一旦新管线发生问题，可以很快地切回旧的小区供暖。等并行运行一段时间后，判断新管线没问题了，再重新挖沟，拆除旧管线（即收缩）。</p><p>有的时候市民不理解为什么天天挖坑，但实际上这么做，都是为了保障供暖的安全性和高可用性啊。</p><h2>再谈接缝</h2><p>如果你够细心，一定会发现在抽象分支中，我们提取的接口其实是一个<strong>接缝</strong>。没错，<strong>接缝不但可以用来在测试中替换已有的实现，它本身其实也是一个业务变化的方向</strong>。在开发过程中，你需要时刻去关注接缝，关注这种可能会产生变化的地方。</p><p>比如你的项目中使用了RabbitMQ作为消息中间件，发送和接受消息的代码和RabbitMQ的SDK紧密耦合，这会带来两方面隐患，一方面当你想替换MQ的时候，需要修改全部调用点，另一方面，它也不好写测试。</p><p>当你意识到它其实是一个接缝的时候，就可以很轻松地通过一系列接口来隔离SDK。当需要替换MQ的时候，只需要提供一套新的实现类。这时的实现类应该叫做<strong>适配器（Adaptor）</strong>，它其实也起到了防腐层的作用。而在单元测试中，你可以通过测试替身构建一组Fake的实现类，以提供内存中的MQ功能。</p><p>这样的方案，既优雅又灵活。</p><p>除了代码中蕴含着很多接缝，架构中也存在接缝。延续上面MQ替换的例子，因为有很多在途的消息还没有处理，这种技术迁移很难做到不停机地丝滑切换。</p><p>这时你可以利用这个<strong>架构接缝</strong>，使用事件拦截模式，将发往RabbitMQ中的消息也同步发给新的MQ（比如Kafaka）。</p><p>同时，消费端可以通过幂等API，来消除重复消费造成的问题。这样一来，系统中就有两个消息中间件同时存在，同时提供消息机制。当基础设施搭建好之后，就可以实现新老MQ的无缝切换了。</p><h2>小结</h2><p>又到了总结的时候。我们今天学习了不少用于替换旧实现的模式。修缮者模式和绞杀植物类似，可以用来改善单体内的某个模块。抽象分支模式可以通过一个抽象，优雅地替换旧的实现。而扩张收缩模式主要用于接口无法向后兼容的情况，一张一缩，一个接口就改造完了。</p><p>同时，除了代码中的接缝，架构中也存在接缝，你可以利用它们来实现架构中的替换。</p><p>无论是绞杀植物、修缮者、抽象分支还是扩张收缩，它们在实施的过程中，都允许新旧实现并存，这种思想叫做<strong>并行运行（Parallel Run</strong>）。这是我们贯彻增量演进原则的基本思想，希望你能牢牢记住。</p><p>我们说的绞杀植物、气泡上下文、修缮者、抽象分支、扩张收缩、并行运行等模式，其实概念上都差不多，之所以叫不同的名字，是因为它们解决的是不同的问题。比如绞杀植物模式解决的是新老系统的替换，修缮者模式解决的是一个服务内部模块的替换，而气泡上下文专门用于将新需求和老系统隔离开来。</p><p><img src=\"https://static001.geekbang.org/resource/image/cb/6b/cb88b22aa60de6224abe96325592a66b.jpg?wh=1920x799\" alt=\"图片\"></p><p>这就像不同的设计模式虽然叫不同的名字，但构造型模式用来解决不同场景下的对象构造，行为型模式用来处理不同场景下的行为选择。你必须深刻理解这些模式，才能做出正确的选择。</p><p>最后，我不得不再次感叹我的同事王健对于各种模式的高度抽象，他的十六字心法如余音绕梁，三日不绝。</p><blockquote>\n<p>旧的不变，新的创建，一步切换，旧的，再见。</p>\n</blockquote><h2>思考题</h2><p>感谢你学完了今天的内容。今天的题目是这样的，请你来描述一下你当前所开发的需求是什么样的？你是否识别出了一些接缝？它能否利用抽象分支来开发？</p><p>期待你的分享。如果你觉得这节课对你有帮助，别忘了分享给你的同事和朋友，我们一起改造老城区。</p>","neighbors":{"left":{"article_title":"13 | 架构现代化 ：如何改造老城区前端？","id":516170},"right":{"article_title":"15 | 架构现代化：如何拆分数据？","id":517959}}},{"article_id":517959,"article_title":"15 | 架构现代化：如何拆分数据？","article_content":"<p>你好，我是姚琪琳。</p><p>前面我们用四节课的篇幅，学习了架构现代化中，新老城区建设的种种模式。今天我们就来看看如何拆分数据，这个场景在建设新老城区，甚至与其他城市（外部系统）交互时都非常重要。</p><p>作为开发人员，你理想中的业务数据存储方式是什么样呢？当然是负责一个业务的数据都在一张或几张名称相关的表中，这样通过名称我们就可以一目了然，查找起来很方便。</p><p>不过很遗憾，现实有时候总是事与愿违，遗留系统中负责处理一个业务的数据，有的放在这张表，有的放在那张表，总是不在一起，名称甚至都没关系；而一张表中也有可能存放几种业务的数据。要想治理遗留系统的数据，就需要对这些数据加以拆分、重组，今天我们就来聊聊拆分、重组涉及到的各种模式。</p><h2>共享数据库</h2><p>如果你问我，拆分数据的第一个模式是什么？我的回答就是：不要拆分。</p><p>不拆分真的可行么？这需要先分析一下拆分的必要性。遗留系统的数据拆分是个认知负载非常高的工作，不同的数据混杂在一起，具有不同业务含义的数据也往往存放于一张表中，要想彻底拆分干净十分不容易。</p><p>如果你不需要不停机更新（大多数企业的业务系统其实都不需要）、没有严苛的可用性和弹性需求，或者数据量没有大到无法接受的程度，就没有必要拆分数据库。</p><!-- [[[read_end]]] --><p>这时，<strong>共享数据库（Shared Database）<strong>也是一个可以接受的选择。我在<a href=\"https://time.geekbang.org/column/article/515274\">第十二节课</a>分享了</strong>基于服务的分布式架构</strong>，就是一种共享数据库的分布式架构。</p><p><img src=\"https://static001.geekbang.org/resource/image/91/6b/910e51dc730d7fba4e2c753d7f2bd26b.jpg?wh=1920x1090\" alt=\"图片\"></p><p>共享的数据分成两种情况。第一种是不同的服务访问同一数据库的不同Schema，第二种是不同的服务访问同一数据库的同一Schema。</p><p>第一种情况相当理想，因为不同业务领域的数据在逻辑上是隔离的，数据的所有权非常清晰。一个服务如果想访问其他服务的数据，在发现Schema不同后，一般不会跨Schema去读表，而是通过代码依赖或者数据库视图来访问。</p><p>第二种情况要差一些，所有模块都可以随意访问任意的表，操作这些数据的业务逻辑散落在各个服务中，你很难知道一张表到底归谁所有。</p><p>正如Sam Newman所说，一个服务，不管是粗粒度的领域服务还是微服务，都可以看成是行为和状态的组合，它封装了一个或多个状态机。这些状态其实就是数据，如果改变这些数据的行为分散在系统的不同位置，你其实很难正确实现这个状态机。</p><p>对于第二种情况，你应该尽量避免，或者只是作为一个过渡阶段，最终仍然要按逻辑或者物理的方式来隔离不同的数据。</p><h2>数据库视图</h2><p>还有一种场景，外部系统需要连接你的数据库来读写它所需要的数据，这里要你要绝对避免共享数据库。因为在这种情况下，数据的所有权将不再仅属于当前系统，不同的团队都能随意修改数据，很快就会变得混乱不堪，不同系统间的集成也会成为大问题。</p><p>这时你可以采取的一种方式是，为不同的外部系统创建不同的Schema，在Schema中提供<strong>数据库视图（Database View）</strong>，这些视图访问主Schema中的表。这样一来，外部系统就能以只读的方式访问你的数据了。</p><p>由于视图提供的是全部数据的一个有限的子集，外部系统只能访问你想让它访问的数据，比如部分表以及表中的部分字段，其他数据得以隐藏。这样就能最大程度地避免数据所有权的模糊。</p><p><img src=\"https://static001.geekbang.org/resource/image/d2/a2/d24eea29cf9d339759fece1784a38fa2.jpg?wh=1920x1090\" alt=\"图片\"></p><h2>数据库包装服务</h2><p>可以访问数据库视图的，不仅仅是外部系统，还可以包括气泡上下文中的基于防腐层的仓库。但视图的方式只能提供只读数据，如果外部系统希望写入数据，应该如何处理呢？</p><p>你可以对数据库进行一层薄薄的封装，形成一个服务，将数据库的细节隐藏在这个<strong>数据库包装服务（Database Wrapping Service）</strong>之后，将数据库依赖转换成服务依赖。通过在数据库外放置一个明确的包装层，你可以很清楚地知道哪些数据是属于你的，哪些数据是别人的。</p><p><img src=\"https://static001.geekbang.org/resource/image/a0/ec/a070bc0d65d899c07af0c6c0b5074aec.jpg?wh=1920x1090\" alt=\"图片\"></p><p>如果你的系统是基于Web的，你甚至可以在原系统之中去开发这个包装服务。但我还是建议你，最好把它当做一个气泡上下文，去开发一个全新的服务，不要让本就混乱的遗留系统雪上加霜。如果你的遗留系统不是基于Web的，那就更推荐使用这种模式了。</p><p>数据库包装服务除了可以提供写能力外，在读能力上也比数据库视图更灵活。你提供的并不局限于一张表或表中的部分字段，还可以提供更加复杂的数据映射。</p><p>这种包装服务看似很薄，但它也可以作为一个中间步骤，为后续更深入的数据拆分打下基础。</p><h2>报表数据库</h2><p>如果你的外部系统或气泡上下文是一个报表系统或服务，需要读取大量的数据，数据库包装服务的方法就不太适用了。因为这个包装服务的所有权是你的，而不是外部系统的，它们无法灵活地定制查询。</p><p>而数据库视图也有点力不从心，因为业务数据和报表的流量都压在一个数据库上，这显然不是你想看到的。</p><p>更好的方式是使用<strong>报表数据库（Reporting Database）模式</strong>，它会为报表这类只读的服务单独构建一个数据库。</p><p>这个数据库可以是业务数据库的远程复本，也可以是一个完全不同的、更适合报表的数据结构（如大宽表），并通过某种方式来做数据的转换和映射。对于后一种实现，你可以使用与业务数据库完全异构的数据库，这样更加灵活。但它也带来了一定的开销，就是你需要自己去实现一个数据映射的工具。</p><p><img src=\"https://static001.geekbang.org/resource/image/7c/12/7c66ffa33c8ced5da6766e0d08275712.jpg?wh=1920x1090\" alt=\"图片\"></p><p>报表数据库模式有时也叫做<strong>数据库即服务接口（Database-as-a-Service Interface）</strong>，因为这种思想已经远远不止用于报表这个单一场景了。随着大数据的兴起，很多数据项目也使用类似的方式，将业务数据映射到数据仓库或数据湖中，再由数据流水线去进行处理。</p><h2>变更数据所有权</h2><p>到目前为止，我们学习的四种模式，都是基于一个共享的数据库，并没有涉及到拆分数据库这个真正棘手的问题。之所以先讲四种共享数据库模式，是想让你知道，在不拆分数据库的情况下，你也有一些方案可以选择。</p><p>如果要拆分数据，最简单的场景就是在基于服务的分布式架构中，不同服务访问单体数据库中的不同Schema。因为不同业务领域的数据已经由Schema隔离开了，你只需要少量改动，就可以将不同Schema中的数据迁移到单独的数据库中。</p><p>如果不同服务访问的是单体数据库中的相同Schema，就会麻烦得多，因为数据并没有从逻辑上进行隔离。但简单的情况怎样处理，我们已经知道了，那稍微复杂一些的情况就好办了，只要把它转换成简单的情况就可以了。所以我们只需要把同一Schema下的数据，用Schema隔离开。</p><p>那新的问题就来了，怎么隔离呢？不同的领域服务访问的表都是交织在一起的，根本不知道哪些表属于哪个领域服务或组件。</p><p>其实，你可以回忆一下<a href=\"https://time.geekbang.org/column/article/515274\">第十二节课</a>的内容，如果组件之间边界不明显，我们可以使用<strong>战术分叉</strong>的方式将“拆”变为“删”。其实数据拆分也是一样的，你也可以将整个Schema复制一份，在新的Schema中删除相应的领域服务没有访问到的表，剩下的就是与领域服务有关的所有表了。</p><p><img src=\"https://static001.geekbang.org/resource/image/72/30/723deedaf3e552f032f73eb93874a730.jpg?wh=1920x1090\" alt=\"图片\"></p><p>接下来，我们再对访问的表做个分组处理。需要依据的原则是，<strong>谁写数据谁就拥有这张表。</strong>因此，我们可以把执行写操作的表，当作是真正归属于当前领域服务的，保持不动即可；而只读的表应该归其他领域服务，所以我们可以把这些表调整成视图。</p><p>如果目标是拆分Schema，到这一步就差不多结束了。但如果目标是独立的数据库，你还要在独立的数据库中将这些视图转换为表，将原数据库中的数据冗余到新库中，并通过<strong>CDC</strong>和<strong>事件拦截</strong>等方式同步数据。</p><p>如果不想冗余数据，你还可以<strong>将连表查询转换为API调用</strong>。具体来说就是，拆分新库和老库中不同表的连表查询，提取出新库的查询，在单体或其他领域服务中把老库的表封装成API。然后在独立出来的领域服务中，把新库的数据和调用API得到的数据组装起来。</p><p>在封装老库的API时，你可以使用<strong>数据库包装服务模式</strong>，也可以使用更加开放的<strong>聚合API模式</strong>。后者不像前者那样只提供基础的CRUD服务，而是将一个聚合的所有操作都暴露为API。</p><p>比如在订单服务中，下完一个订单后，会连带着对库存表进行操作。用数据库包装服务的话，库存服务就会封装一个修改库存表的API，而聚合API则会提供一个减库存的API。两者乍看上去似乎差别不大，但其实体现出了完全不同的封装策略。</p><p>这种将混杂在一起的数据拆分出来，各自归属各自服务的过程，叫做<strong>变更数据所有权（Change Data Ownership）</strong>。</p><p>在这个过程中，我们有的时候是在A中先查出数据，然后调用B得到B的数据，然后在A中进行组合；有的时候是在A中查出部分数据，根据这些数据去调用B，得到最终结果。到底怎么调用其实不重要，只要数据的所有权划分清楚了就好。</p><h2>在应用中同步数据</h2><p>在拆分数据的时候，你的出发点可能并不是解耦，而是想换一个更加合适的数据库，来解决特定的问题。比如社交领域中的好友关系，你可能想用图数据库来替换关系型数据库，来得到更好的查询性能。</p><p>我建议你先拆再换，而不要想着一次性连拆带换。我们做遗留系统现代化这种高认知负载的任务，尤其要记住的一点就是，一次只做一件事，将认知负载降到最低。</p><p>那么当数据库拆分出来之后，如何切换到异构数据库呢？我这里教给你一个比较稳妥的办法——<strong>在应用中同步数据</strong>。让我们来看看它的增量演进方案，一共分四步。</p><p>第一步，批量地复制数据。如果老库在业务上是允许停机的，可以直接停机导数据。如果不允许停机，在复制数据的过程中会产生新的数据。这就需要通过CDC等方式来保证这部分变动也能同步到新库中。</p><p>第二步，同时写入新旧两个库，但只从旧库中读数据。由于新库刚刚部署不久，很可能会出问题，所以我们要在应用程序中“<strong>双写</strong>”新旧两个库，以确保两个库中都有同样的业务数据。一旦新库出现问题，业务也不至于受影响。</p><p>第三步，同时写入新旧两个库，但只从新库中读数据。当我们对新库的基础设施有了信心之后，就可以把读操作也转移到新库中。这时我们仍然双写数据，因此出现任何问题都可以回退。</p><p>第四步，当新旧两库同时运行一段时间后，我们对新库的方方面面都有了十足的信心，此时就可以删掉旧库（或Schema），彻底迁移到新库中了。</p><p>除了做异构数据库的迁移，这种方式也同样适用于拆分微服务时的数据解耦。为了保证拆分数据的正确性，在增量演进的时候，也必然需要保证新旧两个库的数据同步。在同步时，由于有开关的存在，因此我们需要在新旧系统中都实现数据的双写。</p><p>除此之外，该模式也可以用于先拆数据再拆服务的情况。我们拆分服务的时候，有时会先拆代码，再拆数据库，有时则反之，先拆数据库再拆代码。你一定困惑了吧，如果是你，该怎么选择呢？</p><h2>先拆代码还是先拆数据库？</h2><p>如果我们的目标是微服务架构，那么只有代码和数据库都拆分出来且独立部署了，整个任务才算结束。因此拆分工作，你就有三种顺序可选：先拆数据库、先拆代码或同时拆分。</p><p>拆分数据库（包括拆分成单独的库或拆分出新的Schema），意味着以前的事务性操作会变成非事务的，你需要访问新旧两个库，然后在代码中对数据进行集成。这会造成新旧两个库的不一致。</p><p>虽然早晚都会遇到这样的问题，但我仍然建议你先拆分代码，因为拆分代码的认知负载相对低一些，采用战术分叉的方式拆分，也会更简单。</p><p>这能让你快速得到一些短期收益，比如代码的解耦、服务的独立部署。而且从单体到基于服务的分布式架构这条演进路线，也是十分清晰和成熟的。你可以随时停止，随时重启。</p><p>而数据库拆分则要困难得多，一旦先拆数据库，又发现很长时间看不到收益，团队的士气会严重受挫。</p><p>不过无论如何，我都不建议你同时拆分。一次只做一件事，是我们的原则。有些架构师可能还希望在拆分数据库的同时重新设计数据库，增加或修改一些表，我通常都建议他们不要贪心，保持克制，尽量先拆再改。</p><p>一次做多件事，任务的范围会越来越发散，导致最终迷失方向，忘了初心。遗留系统本身就是认知负载非常高的系统，不要再人为地增加认知负载了。</p><h2>小结</h2><p>又到了总结的时候。今天我们学习了拆分遗留系统的数据时，可以选用的一系列模式，结合前面课程里讲过的一些内容，我特意为你总结了两张表格用于回顾重点。</p><p>第一张表是在拆分数据库时，可用于数据同步的几种模式：</p><p><img src=\"https://static001.geekbang.org/resource/image/16/ab/16aa52e4b4fc30f2dbd92f5d0eb31cab.jpg?wh=1920x797\" alt=\"图片\"></p><p>第二张表是在拆分服务时，可用于数据共享的几种模式：</p><p><img src=\"https://static001.geekbang.org/resource/image/00/8a/001167da9423818eb78e813266f5158a.jpg?wh=1920x1070\" alt=\"图片\"></p><p>数据库的解耦，是我们无论如何都会面对的问题，也是架构现代化中最困难最复杂的部分。很多时候，代码的拆分其实就相当于数据的拆分。希望你能牢记这些模式，用它们指导你的日常工作。</p><p>到此为止，我们用五节课的时间学习了架构现代化的种种模式，相信它们可以指导你对遗留系统的前端、后端、架构和数据进行演进。<a href=\"https://time.geekbang.org/column/article/518816\">下节课</a>，我们一起来聊聊DevOps现代化相关的内容，敬请期待。</p><h2>思考题</h2><p>感谢你学完了今天的内容，今天的思考题是这样的，请你分享一下你在项目中拆分数据库的过程，是否使用了我前面讲到的某些模式？整个过程是否是增量演进的？</p><p>期待你的分享，如果你觉得这节课对你有帮助，别忘了分享给你的同事和朋友，我们一起拆分数据库。</p>","neighbors":{"left":{"article_title":"14 | 架构现代化 ：如何改造老城区后端？","id":517058},"right":{"article_title":"16｜DevOps现代化： 从持续构建到持续集成","id":518816}}},{"article_id":518816,"article_title":"16｜DevOps现代化： 从持续构建到持续集成","article_content":"<p>你好，我是姚琪琳。</p><p>前面我们用八节课的篇幅，一起学习了代码现代化和架构现代化的众多模式。掌握了这些遗留系统代码和架构的治理方法，应对遗留系统的挑战你是不是也更有信心了？</p><p>不过只治理代码和架构还不够，我们希望修改后的代码可以“火速”部署到生产环境里，这样才能提高整个端到端的交付效率，让每次改动工作都能及时得到反馈，尽快验证效果。</p><h2>遗留系统的构建方式</h2><p>遗憾的是，遗留系统的特点之一就是DevOps相当落后，甚至可以说完全没有。</p><p>在遗留系统中，一次上线前构建过程可能是这样的：一位打包专员，在本地或远程的机器上拉取代码，完成集成、打包和测试的工作，并准备手动部署。这时，即使再紧急的代码提交都会被拒绝，因为一个干净的打包环境来之不易，新引入的代码会导致所有的流程重来一遍，对打包专员来说是相当痛苦的。</p><p>这样的过程死板、低效、容易出错，一点也体现不出软件中“软”的特点（即灵活）。所以，后来市面上出现了越来越多的自动构建工具，可以自动拉取代码、构建、集成、打包和部署，甚至还能运行自动化测试，这简直就是打包专员们的福音。</p><p>但是，如果只是在打包和部署时使用这些工具，那真是大材小用了。而且，这样也没有解决软件开发中最难解决的问题之一，就是多人协作的情况下，代码集成的问题。</p><!-- [[[read_end]]] --><p>这里的集成是指，<strong>将多个人的工作成果合并在一起，并验证这些合并后的代码是否达到了一定的质量要求，是否可以工作的过程</strong>。</p><p>Kent Beck早在上世纪90年代就提出了<strong>持续集成</strong>的概念，即集成的频率越高越好，极限情况下就是持续地每时每刻都在集成。你可能会问，真的需要这样吗？</p><p>我来给你举个例子。相信你肯定有类似的经历，如果家里一周不扫地，再扫地时就会发现很多尘土，每次大扫除也变得十分辛苦。但如果你每天都坚持扫地，每次的工作就不会有很多，因为灰尘的积累时间只有短短的一天。这其实就是<strong>极限编程</strong>的理念：<strong>越是痛苦的事情，就越要频繁地去做</strong>，这样每次做的时候就没有那么痛苦。</p><p>集成是软件开发中很痛苦的事情，因为会发生很多不可预知的情况，很容易就要花费比原始编程更多的时间。越长时间不集成，不可预知的事情就越多，消耗的时间就越长。因此我们就要更加频繁地去集成，这样每次集成就不会那么痛苦了。</p><p>对于遗留系统来说，如果连自动化的流水线都还不存在，那么你的首要任务，就是先打造这样一条流水线，先做到持续构建。</p><h2>持续构建</h2><p>持续构建是指，每次代码提交都会触发一次构建工作，并执行一些相关任务。这个过程由持续集成工具自动化完成，大致过程如下：</p><p>1.开发人员将代码提交（PUSH）到远程代码仓库；<br>\n2.持续集成服务器按一定时间间隔（比如1分钟）轮询代码仓库，以便及时发现代码变更；<br>\n3.如果发现了代码变更，持续集成服务器就将代码拉取（PULL）到自己本地；<br>\n4.持续集成服务器按照指定的构建脚本执行各项任务，包括编译、单元测试、代码扫描、安全扫描、打包等；<br>\n5.任务执行完毕后，会把结果（成功或失败）反馈给开发团队。<br>\n有了持续构建，就能解决遗留系统最头疼的问题之一：不知道从哪去找可以部署到各个环境的软件包。打包部署不再依赖于打包专员的手工操作，大大缩短和简化了部署流程。</p><h3>在遗留系统中引入持续构建</h3><p>你可以使用Jenkins或GoCD这样的开源持续集成工具，来搭建持续集成服务器。也可以搭配上BitBucket或GitLab之类的源代码管理工具，来提供Pull Request和Code Review等其他功能。</p><p>我建议你选用Atlassian公司的三件套：BitBucket、Jira和Confluence。可以将代码管理、需求管理和知识管理打通，补齐遗留系统中缺失的这些内容。当然，其他替代工具也是完全没有问题的。</p><p>很多时候，遗留系统的代码体量过于庞大，想要在本地构建一次需要很长时间，甚至会内存溢出。你当然可以从代码和架构层面通过拆分代码库来解决，但这无法解决燃眉之急。更快速的方式是，在合并代码的时候，触发Web Hook，让持续集成服务器在远端的特性分支上先执行一次构建，用这次构建来替代本地的构建。然后合并代码，并在合并后的目标分支上再执行一次构建。</p><p>代码的构建解决了，下一步就是解决数据库的迁移脚本。在遗留系统中，往往各个环境中的数据库都不完全相同，因为各个环境都可能有手工改动的痕迹。因此你第一步要做的，就是以生产库为标准，统一所有环境数据库的DDL，并以此作为基线。然后将后续的所有DDL和DML都通过Flayway管理起来，并版本化。</p><p>遗留系统要做到单次构建（如每日构建）还是相对容易的，但要想做到“持续”构建，开发人员就必须改变之前的一些工作习惯。就拿提交代码来说，很多开发人员会等到所有的代码都编写完成，才进行一次提交。这样，代码冲突的风险非常高，很可能出现代码写了两天，合并就用了半天的尴尬情况。如果每个人都这样，就无法做到每天构建多次的目标。</p><h3>任务分解</h3><p>要避免这种局面，开发人员就要对自己编写的代码做出良好的规划，分解出若干小的任务，每个任务都能在很短的时间内完成（比如15分钟、40分钟，或者是一个番茄钟的时间），而且任务最好是按照一个功能的端到端的场景来划分，而不要按技术层级去划分。</p><p>为什么不推荐按技术层级划分呢？比如在开发一个需求时，大多数开发人员都是这样的：先修改数据库层，看看是否需要增加表或字段；再开发数据访问层，对新增加的表或字段编写映射代码；然后编写服务层的代码，这时可能才真正接触业务逻辑；接下来是Controller，可能要添加新的API或修改已有的API；最后，可能还会涉及到一些前端的修改。</p><p>如果按照这样的顺序去开发，每次完成的小任务都是不能提交的，因为新的场景没有开发完，而旧的场景又可能被新添加的代码破坏。</p><p>正确的做法是按端到端的方式去分解任务，一个任务完成一个简单的业务场景。每个任务开发完毕，一个端到端的小场景就开发完了，你可以针对这个小场景写单元测试，也可以在本地环境进行自测。然后就可以提交（commit）代码了。</p><p>比如你要开发一个简单的登录功能，那么可以这样做任务分解：</p><p>1.用户可以使用用户名和密码来登录网站<br>\n2.用户名不存在，则登录失败<br>\n3.密码错误，则登录失败</p><p>你会看到，我是从一个端到端的业务场景来描述一个任务的，而不是我要修改Service层的那几个方法。完成第一个任务可能要耗费一些时间，搭建一些基础代码，而后面的任务就像是对第一个任务的增强，就像是一种迭代式的演进过程。</p><p>多个小任务完成之后，你感觉差不多了，就可以更新一下远端的代码，解决一下冲突，然后PUSH。这时每个commit都覆盖了一个小的场景，是系统的一个增量，是可以交付的。</p><p>这就好像是创作一幅水粉画，你首先需要画出大概的轮廓，再逐层往上叠加各种颜料，直到最后完成。这个过程中，每一次叠加别人都可能看出整体大致的样子，给出修改意见。而如果你一开始就只精雕细琢局部一小部分，别人可能根本不知道你画的是什么。</p><p>更多关于任务分解的内容，你可以参考郑晔的在《10x程序员工作法》专栏中的<a href=\"https://time.geekbang.org/column/article/77913\">文章</a>。</p><h3>小步提交</h3><p>上面提到的按分解的任务开发并且提交的方式，就是<strong>小步提交</strong>。有些人理解小步提交就是指每次commit尽量少的代码，这其实是错误的。如果你提交的内容很少，但却破坏了编译和测试，这样的提交也是不合格的，因为它没有办法PUSH，没法做到持续提交。</p><p>真正的小步提交是指，每个commit都完成了一个端到端的功能点，因此都是可以PUSH到代码仓库的。如果愿意，你可以针对这个commit进行验证、测试甚至部署。只有这样，最终才能做到真正的持续交付。</p><p>在提交代码时，我的同事们早年总结了一套行之有效的<strong>七步提交法</strong>，它的过程是这样的：</p><p>1.PULL最新代码，确保在最新的代码基础上开始开发；<br>\n2.本地编写代码；<br>\n3.本地构建：本地执行编译和单元测试等，以确保新编写的代码是可以工作的；<br>\n4.PULL最新代码：需要先检查CI状态，如果是绿色则可以PULL；<br>\n5.本地构建：再次执行编译和单元测试，以确保新编写的代码和最新代码可以成功集成；<br>\n6.PUSH代码：将本地修改PUSH到远端服务器；<br>\n7.流水线构建：触发CI流水线进行构建，并监控流水线状态，直到通过。</p><p>对于第二步编写的代码，既可以是与一个需求相关的若干commit，也可以小到仅仅是一个commit。在这个commit中，既要包含功能代码，也要包含测试。</p><p>不要害怕编写测试，如果你的任务分解是基于业务场景的，而测试是根据分解的任务编写的，你会发现这一切就会变得很容易，甚至测试驱动开发也是很自然而然的事情。在此，我再次推荐徐昊的《<a href=\"https://time.geekbang.org/column/intro/100109401\">TDD项目实战70讲</a>》。</p><h3>质量门禁</h3><p>持续构建的过程不仅仅是对最新的代码进行编译和打包，还要进行一定的质量检查，也就是<strong>质量门禁</strong>。效率最高的检查手段就是单元测试，它运行快，反馈快，可以在本地运行，能让你在第一时间知道自己的代码是否破坏了其他功能，或者是否达到了单元测试覆盖率的要求。</p><p>第八节课我们讲过，遗留系统很可能没法直接做单元测试。你可以先对代码进行可测试化重构，再添加单元测试。但这将是一个十分漫长的过程，因此在搭建遗留系统的持续集成流水线时，可以先跳过这一步骤，等有了单元测试之后，再加到流水线中来。</p><p>除了单元测试，代码扫描也是一种检查质量的有效方式。你可以使用SonarQube这样的工具对代码进行静态扫描，检查代码的规范和各种潜在的错误。一方面它能为我们敲响警钟，提升代码质量，另一方面也可以让Code Review更专注在代码的设计上。</p><p>一般来说，代码扫描的结果如果超过某个配置的阈值，就会阻断整个持续集成流水线。但对于遗留系统来说，可能会扫出成千上万个代码漏洞。这时你可以选择不阻断流水线，只将扫描结果作为参考，也可以将某个结果作为基线，来验证新提交的代码是否包含新的漏洞。</p><p>如果你的遗留系统在DevOps方面还是一张白纸，我建议你先引入工具和平台，做到持续构建。在持续构建时，也可以考虑自身情况，进行一些剪裁，比如去除单元测试覆盖率检查，去除代码扫描，只做代码的编译和打包。这样虽然看上去很单薄，但引入工具本身已经前进了一大步。对很多遗留系统来说，能做到这一步，已经相当不容易了。</p><p>等到团队适应了新的工作方式，我们再逐步添加质量门禁和其他DevOps实践，做到持续集成。</p><h2>持续集成</h2><p>持续集成包含持续构建的所有步骤，并且在它后面还增加了部署到某个环境的流程，比如部署到测试环境，并且进行冒烟测试、接口测试等。同时，在这个阶段，你还可以优化一下流水线，进一步提升效率。</p><h3>分级构建</h3><p>持续集成流水线的重要作用之一就是快速反馈。对于编译不通过、测试失败、代码风格不符合标准等问题，我们都希望第一时间看到流水线失败，继而根据日志去分析失败原因，快速修复。</p><p>但遗留系统的代码库往往很庞大，仅仅编译可能就会很长时间，如果再跑测试和代码扫描，我们得到反馈的时间就会大大拉长。</p><p>Martin Fowler在《<a href=\"https://martinfowler.com/articles/continuousIntegration.html\">持续集成</a>》一文中提出了<strong>次级构建</strong>的概念，即对构建进行分级，把那些执行速度快、反馈质量高的步骤放到一级构建中，将执行速度慢的步骤放到次级构建环节。</p><p>比如单元测试执行的速度很快，就可以放到较早的构建环节；而集成测试很慢，就可以放到次级构建；对于代码扫描这种更慢的构建，甚至可以使用单独的流水线，在每天晚上执行一遍。</p><p>只有把不同构建过程按执行速度和反馈效果拆分为不同阶段，整个构建或集成过程才更像是一条真正的流水线。</p><p>在真正的工业流水线上，工人们围绕一个制品（artifact）进行组装，一个工人完成工作后，就把制品传递给下一个工人。这就好像是一个构建阶段结束后，把制品传递给下一个构建阶段。</p><h3>制品晋级</h3><p>持续集成流水线的产物也叫做<strong>制品（artifact）</strong>，有时也翻译为工件。一次代码轮询所触发的流水线构建，只会产生一个制品。在持续集成的时候，可以把构建阶段产生的软件包作为制品，存入制品库中。在需要部署的时候，会从制品库中抽取最新的制品。</p><p>通常来说，不同的测试环境有各自的制品库，当一个制品满足了相应环境的要求后，就可以<strong>晋级</strong>到这个环境中。</p><p>举个例子，一次提交在成功构建后产生的制品，经历了单元测试、代码扫描等质量门禁，才会进入QA制品库。这时这个制品就可以部署到QA环境中。在QA环境通过QA测试后，方能进入UAT制品库，进而部署到UAT环境。以此类推，如果该制品通过了所有非生产环境的验证，就可以进入PROD制品库，作为部署到生产环境的候选制品了。</p><p>这种<strong>制品晋级</strong>的机制，是持续集成和持续交付的基础。很多号称做到持续交付的项目，其实只不过是交付的频率高一些而已，根本没有制品晋级的机制，并不是持续交付。</p><p>遗留系统在一开始做持续构建时，可以先不做制品晋级，只把制品作为部署的候选包。等其他DevOps实践慢慢丰富以后，再考虑实现制品晋级。</p><h2>小结</h2><p>今天我们学习了如何在一个没有持续集成流水线的遗留系统中，逐步搭建基础设施，从持续构建开始，慢慢做到持续集成的初级阶段。</p><p>这其中包含很多工作习惯的改变，比如任务分解、小步提交等，一开始你可能并不适应，但要知道，只有做好任务分解，才能做到小步提交，才能做到持续提交代码并持续构建。这些都是DevOps文化的一部分。一个遗留系统要想真正做好DevOps现代化，就必须转变思想，摒弃成见，彻底拥抱DevOps。</p><p>这节课的七步提交法，我也为你准备了图解，供你参考。</p><p><img src=\"https://static001.geekbang.org/resource/image/91/30/914c4ebe9c05b11a0b75ddb896211430.jpg?wh=1920x1280\" alt=\"图片\"></p><p>在做到持续构建之后，你可以逐步引入分级构建、制品晋级等实践，慢慢向持续集成演进。当然，要想真正做到持续集成，团队需要转变的东西还很多，我们就留到<a href=\"https://time.geekbang.org/column/article/519664\">下节课</a>来讲解吧。</p><h2>思考题</h2><p>感谢你学完了今天的内容，今天的思考题是，请你分享一下现在项目的DevOps实践，并分析一下是属于哪个阶段？是持续构建？还是持续集成？</p><p>期待你的分享，如果你觉得这节课对你有帮助，别忘了分享给你的同事和朋友，我们一起转换思维，拥抱DevOps。</p>","neighbors":{"left":{"article_title":"15 | 架构现代化：如何拆分数据？","id":517959},"right":{"article_title":"17 | DevOps现代化：从持续集成到持续部署","id":519664}}},{"article_id":519664,"article_title":"17 | DevOps现代化：从持续集成到持续部署","article_content":"<p>你好，我是姚琪琳。</p><p>上节课，我们讲了任务分解、小步提交、质量门禁、分级构建、制品晋级等DevOps实践，它们都可以看做是持续集成的基础。只有做好任务分解和小步提交，才能放心大胆地PUSH代码，触发持续构建；只有通过质量门禁，才能得到一个有信心的制品；分级构建可以让我们更加快速地得到反馈；而制品晋级才真正地让持续集成流水线流动起来。</p><p>不过，有了一个初始版本的DevOps持续集成流水线还不够，今天我们就继续聊聊DevOps现代化的高阶话题，即如何从持续集成演进到持续部署和持续交付。</p><p>开始学习之前，我想给你提个醒。这节课内容相当长（特别是分支策略这里），本可以拆成两篇甚至三篇。但为了让你一次看个够，我还是决定不拆分。如果你耐心看完，一定可以从根本上理解从持续集成到持续部署的关键知识点。毕竟只有筑牢基础，未来DevOps实践里才可能大展身手。</p><h2>持续集成</h2><p>要想做到真正的持续集成，需要一个与之匹配的代码分支策略。这方面的话题历来就十分有争议，我来说说我的观点。</p><h3>分支策略：特性分支or基于主干开发？</h3><p>要说现在国内最流行的分支策略，非<strong>特性分支（Feature Branch）</strong>莫属，它还有一个更响亮的名字—— <a href=\"https://nvie.com/posts/a-successful-git-branching-model\">GitFlow</a>。不过，虽然名字叫GitFlow，但它并不是Git官方推荐的做法，而只是Vincent Driessen的发明创造而已。</p><!-- [[[read_end]]] --><p><img src=\"https://static001.geekbang.org/resource/image/33/7f/3372788180ae5b197ab713b21ebac17f.jpg?wh=1295x742\" alt=\"图片\" title=\"图片来源：https://medium.com/@rafavinnce/gitflow-branch-guide-8a523360c053\"></p><p>不过，国内很多团队刚刚开始使用持续集成工具，其分支策略是在GitFlow基础上的某种变形。</p><p>比如，每个开发人员在开发一个特性时，都会在主分支上拉出自己的特性分支；等开发完成后再合并到QA分支，当持续集成流水线运行成功，制品会部署到QA环境；当QA测试通过后，开发人员再把自己的特性分支合并到UAT分支，进行UAT测试……以此类推，当各个测试环境都测试通过后，再把特性分支合并到发布分支。</p><p>你可以看出，这样的方式是不可能做到制品晋级的。</p><h4>特性分支带来的问题</h4><p>不管是GitFlow，还是这种变形的特性分支都会造成很多问题。</p><p>首先最大的问题就是<strong>质量隐患</strong>，因为缺少制品晋级的机制，即使所有的特性分支在各测试环境都得到了充分验证，也无法100%保证，所有特性分支合并到发布分支后的制品是可靠的。毕竟只有经过多个环境层层检验的同一个制品，才能让我们放心部署。</p><p>另外，特性分支的好处之一是，可以在发布之前灵活选择哪些特性延迟上线，方法就是不把这个特性分支合并到发布分支。但这同样有很严重的质量隐患。在其他测试环境所测试的制品都包含这个特性分支的代码，但发布分支中的制品却不包含，你必须对所有特性重新测试才能确保它们的正确性。然而这一步却常常被忽略，人们普遍认为只要特性被单独测过了，集成后就仍然是正确的。</p><p>其次，特性分支只有在特性开发完毕后才会合并代码，这样就<strong>无法实现小步提交和持续构建</strong>，更不要说持续集成了。在每个开发周期的前几天，团队成员都刚刚起步，没有代码提交，持续集成服务器可能都不会执行任何构建任务，资源闲置。而在中后期，大家密集地合并代码，又可能导致资源不够用。</p><p>第三，由于合并的时机比较晚，常常会造成大规模的<strong>合并冲突</strong>，不仅如此，在向每个环境的分支上合并时，都要解决一遍合并冲突，十分痛苦。说好的痛苦的事情频繁做呢？有时候为了避免冲突，很多开发人员会选择不去修改原有代码，而是将代码复制出来，只加入自己的修改，造成了大量代码重复。</p><p>乍看上去有点像我们已经讲过的种种模式，但它只“扩张”，不“收缩”，实际上只能增加混乱。而且重构代码是最有可能造成大规模冲突的。我们不得不面对旷日持久的代码合并，彼此合并代码时的怨声载道，这种状况下心情和效率自然都好不了。</p><p>久而久之，团队重构代码的意愿也会逐渐消退，代码质量也就越来越糟，新系统又会向着遗留系统的不归路大步流星。</p><p>最后，由于开发人员在开发完一个需求并合并到QA分支后，就开始着手开发下一个需求了。但此时他还需要时刻想着，将原来的特性分支在不同的时间点合并到其他测试分支，就这样在不同的分支上下文之间来回切换，开发人员除了开发需求外，脑子里还要想着各种跟开发无关的东西，<strong>认知负载相当高</strong>。</p><p>这种分支策略，表面上看是把不同的特性分支当成沙箱，帮助多个开发人员在隔离的环境下并行开发，但实际上它<strong>把软件开发这个团队活动割裂为单个开发人员的单人行为，与DevOps的价值观背道而驰</strong>。说白了，选择等一个需求完全开发完毕再合并，就已经和持续集成渐行渐远了。</p><p>近年来国内流行的 <a href=\"https://developer.aliyun.com/article/573549\">AoneFlow</a> 分支策略其实也无法解决上述问题，它虽然允许频繁提交代码，但由于要保持本地分支的“干净”，你只能将代码合并到release分支，却不能把release的代码合并（或rebase）到本地。也就是说，代码只在远端集成，本地不能集成。这就导致你每次的合并都将十分头疼。</p><p>而且，当临时有需求延迟发布或者干脆砍掉的时候，虽然AoneFlow的重建发布分支很快，但你想想，这个新发布分支中的所有特性是不是还需要重新测试？</p><p>你可能会说，它们之前已经测过了。但那是在有延迟发布的那个需求代码的基础上测试的，摘掉这些代码后，就不需要测试了吗？对于开发人员，重建分支是分分钟的事情，但对于测试人员，就又得加班加点重测一遍。<a href=\"https://mp.weixin.qq.com/s/u4nzBMhZeSce_tUI6WbWKw\">说好的团队为质量负责呢？</a></p><h4>最理想的分支策略：基于主干开发</h4><p>在我看来，最理想的分支策略是<a href=\"https://trunkbaseddevelopment.com\">基于主干开发（Trunk Based Development）</a>。这其实是SVN时代就流行的开发方式。在最新的 <a href=\"https://cloud.google.com/blog/products/devops-sre/announcing-dora-2021-accelerate-state-of-devops-report\">2021 DevOps年度报告</a>中，仍然把基于主干开发作为必备的DevOps能力。同时，在刚刚上市的《加速：企业数字化转型的24项核心能力》这本书中，也推荐了基于主干开发。</p><p>为什么值得推荐，我们先看看这种策略的一般流程。</p><ul>\n<li>持续提交：开发人员每日持续提交当天开发的代码，持续构建和集成；</li>\n<li>冲突处理：每次提交代码，都会先rebase远端的master代码，这让开发人员有机会在本地解决当前的冲突；</li>\n<li>制品晋级：提交的代码经过持续集成流水线产生制品，该制品不断晋级，最终成为生产环境的部署候选。</li>\n<li>延迟发布的特性处理：在一开始就预警这种风险，并使用<strong>特性开关（Feature Toggle）</strong>来进行控制，如果需要延迟，就将开关关闭，只部署但并不交付这个特性，由于开关关闭的场景早就在多个环境下验证过了，测试人员也不需要加班。</li>\n</ul><p>因为采用了基于业务场景的任务分解和小步提交，理论上每个commit都能提供业务价值，也是可以部署和交付的。</p><p>由于代码直接PUSH，你根本不用在本地建立分支，而直接在本地的主干分支上开发即可。每一个commit都是可以提交甚至交付的，所以无需担心其他高优先级的工作影响本地分支。你可以立即PUSH当前已经commit的代码，着手新的工作。即使有时当前代码无法提交，也可以建立一个临时分支，或者暂时stash代码。</p><p>而我们一直头疼的冲突处理也被分解了，它内嵌到每次提交代码中，因为团队日常始终在频繁多次地解决这些冲突，所以冲突都不会太大。</p><p>在这种策略下，所有的代码变更（包括revert的代码）都会走一遍流水线，产生新的制品，这也是一种增量的思想。而不是像其他策略那样，靠是否合并到特定分支来决定代码的去留。</p><p>你会发现，只有做好任务分解和小步提交，才能做到持续PUSH代码；只有写好单元测试，才有信心PUSH代码；只有引入特性开关，才能无所畏惧地PUSH代码。主干开发和上节课讲的诸多DevOps实践是一脉相承的。</p><p>然而很多团队认为主干开发的门槛太高，任务分解、小步提交、单元测试、特性开关这些实践对开发人员要求过高，普通的团队无法达到这样的要求。但我认为这并不是人员能力的问题，因为很多互联网大厂也无法做到这一点，是他们的能力不行吗？显然不是。这其实是团队文化的问题。</p><h3>DevOps文化</h3><p>DevOps其实不是一个角色，而是一种文化，一种价值观。任务分解、小步提交等实践与其说是开发技能，不如说是团队协作、快速反馈等价值观在技术实践上的投影。我们拿持续集成流水线的纪律来举个例子。</p><p>一般持续集成做得好的团队，都会贯彻这样的流水线纪律：</p><ul>\n<li>如果当前CI的状态是红色，则禁止提交新的代码</li>\n<li>如果15分钟内不能快速修复，就revert刚才PUSH的代码，重新提交</li>\n<li>尽量频繁地触发CI，比如一天N次</li>\n<li>CI失败不过夜</li>\n<li>一旦提交代码，要监控CI状态，直到全部通过（或提交构建通过，次级构建开始），才能着手其他工作</li>\n</ul><p><img src=\"https://static001.geekbang.org/resource/image/80/1c/8063ba54a187d54565afa866f627531c.jpg?wh=1920x1319\" alt=\"图片\"></p><p>这样的纪律背后，隐藏的是团队协作、责任共享、快速反馈的DevOps价值观。CI是团队的CI，一个人把CI“搞挂了”，其他人就不能再次提交，要等他修复；如果短时间无法修复，则revert代码，不要影响其他人；尽量频繁地提交代码，让其他人可以跟你的代码更早地集成；CI失败如果过夜，第二天早上早来的同事就无法提交代码；负责任地监控CI状态，得到失败的反馈后第一时间着手修复；只有修复了或revert了，才是有效的反馈，如果置之不理，则是无效的反馈。</p><p>而基于特性分支开发，代码提交频率低且代码量大，导致CI挂掉的可能性非常高。为了避免影响其他人提交，开发团队只能退而为每次提交提供单独的CI服务器。团队协作进一步割裂，产出的制品也无法部署。</p><p>如果DevOps文化没有融入整个团队，那么各种DevOps实践都会打折扣，充其量也就是能做到用工具来辅助构建和打包，无法做到持续构建和持续集成。</p><p>我曾在一个50~80人的开发团队中工作6年，团队中三年以下工作经验的初级开发人员超过半数，然而基于主干开发的分支策略运转良好。所以这根本不是能力的问题，而是文化的问题、意愿的问题、魄力的问题。</p><h3>需求管理</h3><p>当然主干分支+特性开关的策略并不是毫无缺点的，特别是当需求变化较大，多个特性开关并存且存在交叉的情况下，这些都有可能成为定时炸弹。这时，需求管理就需要变革了。</p><p>一方面，有可能不会上线的需求要提前预警，让开发人员准备特性开关。另一方面，要把需求的粒度砍小。</p><p>为什么要砍小呢？我们可以从开发侧来倒推。我们所提倡的任务分解和小步提交，前提就是需求的粒度足够小，这样代码提交的粒度才能随之变小。</p><p>如果还是传统的大需求，这中间自然需要一个拆解过程，把需求从粗粒度拆分成细粒度，进而分解成足够小的开发任务。不过拆分需求并非开发人员擅长的，而是需求分析人员的本职工作。</p><p>再者，如果一个大需求需要几个月开发完成，需求方就只能在最后阶段才能看到做成了什么样子。一旦与想要的不符，就要推倒重来，造成了巨大的浪费。细粒度的需求可以在早期就向客户展示部分已完成的内容，确保方向的正确性。</p><p>这时，需求管理不但要需求分析人员转变工作方式，连需求方都要一并加入，用细粒度的用户故事替代落后的需求文档。</p><h3>Code Review</h3><p>还有一个影响持续集成的原因，是目前普遍存在的基于Pull Request的Code Review方式。</p><p>你的团队是不是这样做Code Review的？开发人员开发完特性，commit完代码，申请一个Pull Request，并选择一个高级开发人员进行Code Review。这名高级开发人员在Review完成后，才会合并代码，触发持续集成流水线。</p><p>你发现这样做的问题了吗？你根本不知道你提交的代码在什么时候合并，什么时候触发CI。提完PR后，你会跟自己的代码“失联”多久是未知的。于是你着手其他工作，等发现CI挂掉，又不得不切换回上个特性分支修复。</p><p>而在基于主干的分支策略下，代码是直接PUSH的，而无需使用PR。你可以立即得到CI的反馈。秉承极限编程的理念，既然Code Review是好的，那么就频繁地去做。</p><p>所以,可以尝试每日Code Review。每天一个固定的时间，团队成员围在一台显示器前或者会议室的大电视前，集体Code Review，每个人都能知道其他人在做的事情，尽早知道是否会影响自己的开发，也能在其他人遇到困难的时候，第一时间伸手帮忙。</p><p>为了实现更高效的Code Review，你还可以在commit代码的时候使用一些小技巧。</p><p>比如在使用并行运行模式的时候，你需要复制代码。你可以在复制完代码后立即commit一次，然后再在复制后的代码上修改，继续commit。这样做的好处是，第二次commit和第一次commit的代码是可以看出差别的，有利于Code Review。否则，如果复制出来直接修改，那么就只能看到修改后的代码，无法diff你的修改了。</p><h2>持续部署</h2><p>当团队内部形成了良好的DevOps文化之后，你就可以考虑加快部署频率了。</p><h3>高频发布</h3><p><a href=\"https://puppet.com/resources/report/2017-state-devops-report\">2017年的DevOps年度报告</a>中指出，Amazon和Netflix每天的部署次数高达数千次。报告还给出了高效组织的部署频次约为每天4次，每年1460次；中等组织每年部署32次；而低效组织每年部署7次。</p><p>你可能会问，每天可以部署这么多次，有什么好处呢？其实，这种高频发布跟任务分解、小步提交等实践，都遵循了增量演进的思想。部署的频率越高，每次部署的风险和成本也越低，部署时间和Bug修复的时间也越少。此外，由于你能更快速地得到真实用户的反馈，也能及时调整产品演进的方向。</p><h3>自动化部署</h3><p>要做到高频次地发布，首先要实现部署的自动化，也就是在持续集成流水线中加上部署的阶段。这样，每一次代码PUSH所触发的集成，最终都能部署到服务器上。</p><p>在遗留系统中，部署总是最头疼的问题。通常需要一个专门的发布团队，停机数小时甚至更久，按照部署手册依次进行抽取软件包、准备并执行数据库脚本、复制文件等操作。</p><p>而要做到自动化部署，你需要为每个阶段准备部署脚本，使用部署流水线来管理部署的过程，对不同的环境也尽量使用同一套部署脚本，并把脚本纳入到代码版本管理中。</p><p>在尝试之初，你可以只把持续部署到测试环境这条链路打通。毕竟对于大多数系统，还是需要经过手动测试，才能部署到生产环境的。但即使你只能做到每一行代码提交都能持续部署到测试环境，也已经超越了绝大多数软件项目。</p><h3>低风险发布</h3><p>其次，要构建低风险发布策略，将发布风险降到最低。低风险发布策略，是指在部署过程中不要影响正常的业务行为，要让用户无感知；一旦部署失败，需要尽快回滚到正常状态，尽量减少对客户的影响。</p><p>低风险发布策略包括蓝绿部署、滚动部署、金丝雀发布等。</p><p><strong>蓝绿部署（blue-green deployment）</strong>是指准备两套完全一样的运行环境，即生产环境（蓝环境）和预生产环境（绿环境）。</p><p>在部署时，先在绿环境中部署，并测试验收。在确认没有问题后，再将请求引流到绿环境，而蓝环境则仍然保持旧版本。当确定新版的部署没有问题后，绿环境升级为生产环境，而蓝环境则变为预生产环境，等待下次部署。</p><p>由于蓝绿部署并不会造成停机，新的生产数据一直在产生，这样就会给环境切换造成一定的困难。</p><p>因此，很多蓝绿部署方案都会采用共享数据库的方式，同时对数据迁移脚本做兼容性处理，让共享的数据库可以应对新旧两个版本的系统。比如在修改字段时使用扩张-收缩模式，先增加字段，并做数据迁移。这样，数据库就可以运行在新旧两个版本上了。当新版本确认没问题后，在下次部署的时候再删掉老字段。</p><p><img src=\"https://static001.geekbang.org/resource/image/83/39/8345bc6a0a51147479fc5016af8dae39.jpg?wh=1920x1145\" alt=\"图片\" title=\"图片来源于网络：https://dev.to/mostlyjason/intro-to-deployment-strategies-blue-green-canary-and-more-3a3\"></p><p>蓝绿部署需要准备两个完全一样的环境，有没有比它更节省资源的策略呢？</p><p>这种策略就是<strong>滚动部署（rolling deployment）</strong>，即在服务集群中选择一个或多个服务单元，先对这些服务单元进行部署，然后投入使用，并开始部署其他服务单元。如此循环直到所有单元都部署完毕。</p><p><img src=\"https://static001.geekbang.org/resource/image/fd/e7/fd3416a2e8d894286415ea63b1a8f9e7.jpg?wh=1920x1014\" alt=\"图片\" title=\"图片来源于网络：https://dev.to/mostlyjason/intro-to-deployment-strategies-blue-green-canary-and-more-3a3\"></p><p>上面的两种部署方式是从物理的角度隔离新旧版本，而<a href=\"https://martinfowler.com/bliki/CanaryRelease.html\">金丝雀发布（Canary Release）策略</a>则引入了用户的维度。比如在蓝绿部署或滚动部署中引入了新版本后，并不是将所有流量都引流到新版本，而是只对一小部分用户开放，以快速验证，从而降低发布风险。</p><p><img src=\"https://static001.geekbang.org/resource/image/73/84/73660c57ece798f00b1667d7d4907b84.jpg?wh=1920x1279\" alt=\"图片\" title=\"图片来源于网络：https://dev.to/mostlyjason/intro-to-deployment-strategies-blue-green-canary-and-more-3a3\"></p><p>在实际操作中，可以让生产环境的测试用户作为金丝雀用户，测试人员在生产环境进行测试和验证，这样能在一定程度上做到QA in Production。这时你会发现，你可能都不需要那么多的测试环境了。</p><p>金丝雀发布还可以延伸成为灰度发布，即当金丝雀用户验证通过后，不立即开发给全部用户，而是按照一定阶段逐步开放给所有用户。有的时候你会发现，你和别人用着同样版本的手机App，但却没有别人的功能，那可能就是还没有“灰度”到你。</p><h3>应用回滚</h3><p>哪怕我们已经将发布风险降到最低，也不代表零风险。当发布出现问题的时候，要及时将系统“回滚”到上一个稳定的版本。</p><p>这里说的“回滚”并不是指像数据库回滚事务那样，从逻辑上逆向执行一遍所有代码增量；也不是指revert所有这次部署的代码提交，重新走一遍流水线，产生新的制品，进而部署，而是指部署上一个稳定的版本。这个稳定版本是相对可靠的，没必要产生新的制品了。</p><p>但这时可能会需要一定程度的人工介入，如果你的流水线执行速度相当快、质量相当高，也可以revert代码并重新产生制品。</p><p>如果发生问题的部分包含特性开关，也可以关闭开关来规避问题。同时，数据库的结构要做到向下兼容。一般回滚部署时，只回滚应用程序，而不要回滚数据库，否则会造成数据丢失等问题。</p><p>就算你只做到了持续部署到测试环境，低风险发布策略和应用回滚也是有必要的，毕竟在如此高频的发布下，测试人员的工作是不能被阻塞的。</p><h2>小结</h2><p>总结一下今天的内容。我们首先用了不少篇幅讨论了分支策略。这是一个充满争议的话题，每次对于 <a href=\"https://insights.thoughtworks.cn/gitflow-consider-harmful\">GitFlow的批判</a>，都会引发<a href=\"https://ruby-china.org/topics/29263\">热议</a>。因此，我也只是抛出我的观点，如果你有不同想法，欢迎在评论区留下你的想法。</p><p>你会发现，<strong>只有应用了主干开发，遗留系统现代化的增量演进原则才能更好地贯彻</strong>。每次增量演进都能及时PUSH到主干，从而过一遍持续集成流水线，并部署到各个环境。而如果是特性分支策略，你会不自觉地等着全部完成后再合并代码。</p><p>灵活的分支功能是Git的一大亮点，但它并不是为了开发特性而设计的。利用特性分支在本地长期保存多份代码版本，这是对Git分支的滥用，增加了不必要的认知负载。</p><p>虽然应用主干开发也具备一定的认知负载，但这些都属于内在认知负载，一旦掌握就一劳永逸。而不像特性分支所带来的外在认知负载那样，需要时刻想着这个想着那个。</p><p>另外还要说的一点是，<strong>不要因为忌惮代码合并而回避代码重构</strong>。</p><p>此外，我们还介绍了团队协作、责任共享、快速反馈的DevOps文化，以及要适应这种文化，需要在需求管理方面做出的转变。</p><p>我这里总结了一个对于持续集成的建议，希望你和团队能够不畏艰难，勇于尝试：</p><p><img src=\"https://static001.geekbang.org/resource/image/18/74/184215fda70752849781306e948a0874.jpg?wh=1920x997\" alt=\"图片\"></p><p>最后，我们还学习了持续部署相关的内容。尽管遗留系统看上去离做到持续部署还很遥远，但低风险发布和应用回滚等策略对遗留系统现代化是非常有价值的。</p><p>比如我们常说的增量演进原则，以及抽象分支、扩张收缩模式的应用，在测试和交付时都会用到蓝绿部署和灰度发布等低风险发布策略。而一旦发生问题，就会关闭开关，将应用回滚。</p><p>到这里，我们关于DevOps现代化的内容就全部讲完了。从单次构建，到持续构建，到持续集成，到持续部署和持续交付，这是一条漫长又美好的演进之旅。</p><p><img src=\"https://static001.geekbang.org/resource/image/0b/72/0b9ab3582d67a432e506df04859d5472.jpg?wh=1920x884\" alt=\"图片\"></p><p>现在国内很多传统企业都开始做DevOps转型，这是一个好现象，也是企业遗留系统现代化，以及数字化转型的必经之路。</p><p><a href=\"https://time.geekbang.org/column/article/520553\">下节课</a>，我们一起来学习最后一个现代化：团队结构现代化。一起来看看为什么遗留系统需要调整团队结构。</p><h2>思考题</h2><p>感谢你学完了今天的内容，今天的思考题请你分享一下你们团队的分支策略，它们有哪些优点和缺点？解决了哪些问题，又带来了哪些问题？</p><p>期待你的分享，如果你觉得这节课对你有帮助，别忘了分享给你的同事和朋友，我们一起拥抱DevOps。</p>","neighbors":{"left":{"article_title":"16｜DevOps现代化： 从持续构建到持续集成","id":518816},"right":{"article_title":"18 | 团队结构现代化 ：从组件团队到Spotify模型","id":520553}}},{"article_id":520553,"article_title":"18 | 团队结构现代化 ：从组件团队到Spotify模型","article_content":"<p>你好，我是姚琪琳。</p><p>前面我们一起学习了现代化的三个方向：代码现代化、架构现代化和DevOps现代化，这三个方向都跟技术相关。接下来我们会学习遗留系统现代化的最后一个方向——团队结构现代化。</p><p>这个方向跟管理有关，但无论你是掌控全局的CTO、架构师，还是身处遗留系统一线战队的队员，都有必要了解现代化团队结构是什么样子的。这是因为遗留系统的现代化，除了技术调整，也离不开人的因素。</p><p>在我和团队过去大量的实践当中，我们总会发现，维护遗留系统的团队，结构往往并不合理。直接后果就是给软件开发的质量与速度拖后腿，长远来看，还会让我们的架构规划无法落地，回到满是泥潭的老路上。</p><h2>遗留系统中的团队结构</h2><p>你可以对照一下你所在的开发团队，看看跟后面的情况是否类似。</p><p>整个研发部门大体分为业务部、开发部、测试部和运维部。开发部门又可以细分成前端组、后端组、DBA组和架构组，不同部门或小组分别向不同的领导汇报。</p><p>除了这些常规、稳定的配置，还有一些为了灵活应变才组建的部门。比如本来没有DBA，但因为某段时间频繁产生数据库性能问题，而临时起意组建了一支DBA小组。而开发部内部也经常因为要开发新的项目，从各个组成抽调成员，而当项目完成之后，团队就原地解散。</p><!-- [[[read_end]]] --><p>总之，你会发现每个小组团队人员十分不稳定：有可能某个开发人员上个星期还在开发A模块，而这个星期就被分配去开发B模块了；有可能某个测试人员昨天还在测系统C，而今天则去测以前从来没接触过的系统D。</p><p><img src=\"https://static001.geekbang.org/resource/image/04/e7/047448759971c6d9eb7af97d904231e7.jpg?wh=1920x964\" alt=\"图片\"></p><p>这些现象我们或多或少都见过，甚至你都习以为常了。那这样的团队规划有什么问题吗？当然有。</p><p>首先，按照技术或职能（functional）来划分团队或部门，无形中增加了组织壁垒，造成了不必要的沟通成本。因为一个围绕用户构建的需求，必然是跨越多个技术组件的。一个本来完整的端到端的需求，因为团队按技术分组，不得不被分为前端部分、后端部分、数据库部分，一个小需求的联调和验收就要涉及到三个部门、五个不同团队的人。</p><p>回忆一下前面的课程，这种不能促进工作的顺利展开，反而使参与者需要付出额外脑力劳动的现象叫什么来着？没错，这就是外在认知负载（可以回看<a href=\"https://time.geekbang.org/column/article/507513\">第三节课</a>），是我们一定要降低的。</p><p>其次，随意的团队划分看似合理，但你仔细琢磨一下，不难发现实际是目的合理，手段存疑。因为我们的目的是解决研发痛点问题（比如前面说的数据库问题），这个目标成立，但组建DBA团队这个手段会造成额外的沟通成本，在我们看似解决了一个问题的同时，又带来了新问题。</p><p>第三，频繁地变换团队成员，知识就得不到沉淀，对系统和人都是如此。系统频繁变换维护者，所以没有人对这个系统熟悉，也没有人愿意为它付出更多的努力，因为所有人都知道过不了多久就会离开这个项目；人频繁变换系统，导致团队成员对每个系统都是浅尝辄止，没法深入研究，更不要说偿还技术债了。</p><p>像测试人员频繁变换所测试的系统这种事情，在拥有独立测试团队的组织中是十分常见的，因为需要为不同的项目调配测试资源。但实际上测试人员应该是最了解系统的那个人，频繁变化系统会使他们丧失这种能力。</p><h2>组件团队</h2><p>组织壁垒导致沟通成本上升，频繁变换团队造成知识流失，那什么样的组织结构才适合软件开发呢？</p><p>为了解决人员频繁变动和知识流失问题，很多组织自发地形成了<strong>组件团队（Component Team）</strong>。即一个固定的团队负责维护一个组件，在团队内部可以形成关于该组件的知识闭环。</p><p>组件团队又分为两种，一种是技术组件团队，一种是业务组件团队。前者按照前端、后端、数据端这样不同的技术来划分，而后者则是按照不同的业务模块来划分。</p><p>技术组件团队显然无法做到业务知识的沉淀和传递，而且需求又是以业务的形式展示给开发团队的。因此，要完成一个需求，必然涉及到不同技术组件团队之间的频繁沟通。前面提到的遗留系统中的团队结构，大多都是这种技术组件团队。</p><p>业务组件团队相对来说比较内聚，团队成员包括前后端和DBA，可以很好地在组内协作，完成一个针对该业务组件的需求。我们后面提到组件团队，都是指这种业务组件团队。</p><p>因为组件团队是长期存在的，这就可以解决知识沉淀的问题，团队成员也更容易形成默契，减少沟通成本。组件团队也是跨职能的，而不是单一职能。</p><p>跨职能是指，业务分析人员、前端开发人员、后端开发人员、DBA、架构师和测试人员等不同职能角色都在同一团队中（有些角色可以兼任）。这进一步解决了沟通问题，同时跨职能的人组成的单个团队，不同身份的团队成员之间不再对立，而是共同为该组件负责。</p><p>如果你的遗留系统还是按照技术组件来划分，建议你推动变革，先想办法让它按业务组件划分。</p><h2>特性团队</h2><p>不过即使我们已经按业务组件划分了，遇到一个稍微大一点的需求，也可能横跨多个业务组件，还是会导致多组件团队的沟通协作。有时候业务分析师会把这样的需求按业务组件拆分，但最终的集成和联调仍然是比较头疼的问题。</p><p>为了解决这一问题，Jeff De Luca等人提出了<strong>特性团队（Feature Team）</strong>的概念。特性团队是指一个长期存在的、跨职能的团队，团队成员一起完成多个端到端的用户特性。</p><p>特性团队和组件团队一样，也是长期存在且跨职能的，因此容易形成知识沉淀，也不会出现组织壁垒。而由于一个特性（即需求）会横跨多个业务模块，他们也不像组件团队那样需要横向沟通，自己在组内就能完成这个需求。</p><p>通过下面这张图，我们可以直观对比一下组件团队和特性团队：</p><p><img src=\"https://static001.geekbang.org/resource/image/8f/62/8f90693e4eb4ee9b2fcc7a6a4d0f9062.png?wh=1920x982\" alt=\"图片\" title=\"图片来源于网络：https://www.visual-paradigm.com/tw/scrum/feature-team-vs-component-team-in-agile/\"></p><p>可以看到，组件团队虽然只需要维护自己的组件，但对于每一个特性，都需要跨团队沟通；特性团队虽然每次都要修改多个组件，但却不需要团队之间的沟通和协作。对于前者，这种沟通带来的成本就是外在认知负载，而对于后者，这种了解多个组件的上下文就是内在认知负载。外在认知负载要尽量减少，而内在认知负载只需要一次性掌握，就能长期受益。</p><p>在实际操作层面，一个特性团队所完成的特性，常常都属于同一个业务领域或模块，这时就接近组件团队了。但他们同时也具备跨越多个组件来完成需求的能力，不需要从业务端进行拆分。</p><p>随着时间的推移，特性团队这项实践也被吸收到其他敏捷方法论中，现在也叫全职能团队或跨职能团队，名字虽然不一样，但意思都差不多。如果你的项目还不是特性团队，建议你最好想办法先让它按特性来分组。</p><h2>康威定律</h2><p>如果组件团队和特性团队长期聚焦于某一业务领域，这样的领域演进成一个模块或者独立服务的可能性就会大大提升。背后其实是<a href=\"https://en.wikipedia.org/wiki/Conway%27s_law\">康威定律（Conway’s Law）</a>在起作用。</p><p>康威定律的意思是，<strong>一个组织所设计的软件系统的结构，与组织的沟通结构是完全一致的</strong>。也就是说，如果按技术组件来划分团队边界，完成沟通协作，就会出现UI层、业务逻辑层和数据库层这样的技术分层结构。如果按业务领域划分，那么就会出现按业务来划分的模块或服务，比如订单服务、库存服务、用户中心等。</p><p>多年以来，康威定律一直在默默起着作用，如果团队按技术分组，却希望设计一个微服务架构，最终都会走向无尽的深渊。遗留系统中的那种团队结构，必然会导致大泥球架构。</p><h2>Spotify模型</h2><p>特性团队并不是终点，我们继续推演未来可能的发展。由于特性团队内部是全职能的，时间长了就会越来越自治，关于当前特性或模块的很多架构决策，团队都能自行讨论决定。</p><p>但特性团队也存在一些问题。当项目越来越大，规模化的特性团队如何组织，就变得十分棘手了；而且特性团队数量变多后，不同团队对相同技术栈的使用规范和最佳实践也会不同，这也给技术管理带来了一定的挑战；此外，技术人员还是更倾向于聚在一起更有利于个人成长，如果一个特性团队只有一到两名前端开发人员，他们自然会觉得成长受限。</p><p>差不多十年前，Spotify公司推出的<a href=\"https://blog.crisp.se/wp-content/uploads/2012/11/SpotifyScaling.pdf\">Spotify模型</a>成功支撑了上百人的规模化敏捷团队，受到各大公司的效仿。我来给你简单介绍一下。</p><p><img src=\"https://static001.geekbang.org/resource/image/f4/09/f44a04e2ac11d7909ec90b4ceda30809.jpg?wh=1920x1209\" alt=\"图片\" title=\"图片来源于网络：https://blog.crisp.se/wp-content/uploads/2012/11/SpotifyScaling.pdf\"></p><p>Spotify模型中的基本开发单元是<strong>小队（Squad）</strong>，它类似于特性团队，也是跨职能、自治的开发小组，由6~12人组成。当小队越来越多时，负责同一个业务模块的小队就组成了一个<strong>部落（Tribe）</strong>，人数通常不超过<a href=\"https://en.wikipedia.org/wiki/Dunbar's_number\">邓巴数</a>。部落首领（Tribe Lead）负责协调各个小队以保持一致。</p><p>虽然小队和部落是自治的，但不同小队和部落之间保持技术的一致性也很重要，这可以在公司内部就某一技术达成规范。这时，专注于不同技术的人可以跨小队来组成<strong>分会（Chapter）</strong>，如测试分会、架构分会、前端分会等。分会成员会定期凑在一起，讨论专业领域的知识和近期遇到的挑战。</p><p>除了分会，Spotify模型中还有一个更松散的组织，即<strong>协会（Guild）</strong>。它更像是一个兴趣小组，聚集了一些热爱分享的人，可能讨论的内容与当前工作并没有直接关系。</p><p>分会和协会有助于团队成为一个技术氛围浓厚的学习型组织。因为有了分会和协会，小队成员在技术上就不会觉得孤立无援了。而且一个优秀的小队成员，既可以在小队内部起作用，也有机会通过分会、协会建立跨团队的影响力。</p><p>Spotify模型固然美好，但并不是所有公司都能效仿的，搞不好很可能东施效颦。最尴尬的是，连Spotify都声称<a href=\"https://www.agility11.com/blog/2020/6/22/spotify-doesnt-use-the-spotify-model\">他们并没有很好地落地Spotify模型</a>。</p><p>但我确实在一个80人左右的项目中亲身实践过，当时整个团队分为8个小队、3个部落，还有前端分会、性能分会、架构分会、测试分会、DevOps分会，以及数据协会、开源协会等自组织的技术社区。当时整个团队士气高涨、战斗力极强，每个成员既有归属感，也每天都在成长，真是十分美好的旧时光。</p><p>为什么Spotify模型会有问题呢？我们<a href=\"https://time.geekbang.org/column/article/521118\">下节课</a>接着说。</p><h2>小结</h2><p>总结一下今天的内容。我们展示了遗留系统中普遍存在的单职能团队和技术组件团队，以及一些不好的习惯，比如团队成员和结构的频繁变更。</p><p>也许很多人觉得开发团队的“反复横跳”是拥抱变化，其实根本不是，这是在制造混乱。<strong>真正的拥抱变化是以不变的团队成员和结构，应对需求的万般变化。</strong></p><p>接着我们又学习了组件团队、特性团队和Spotify模型，这是近三十年来关于软件团队组织结构方面为数不多的理论。你可以根据自己遗留系统的现状，看看哪种模型适合自己的团队。因为不同的模型解决的是不同的问题，组件团队解决的是知识传承的问题，特性团队解决的是跨团队沟通的问题，而Spotify模型解决的是规模化场景下的组织问题。</p><p><img src=\"https://static001.geekbang.org/resource/image/21/e8/211e68a8fff1f48548a38fd1eb9487e8.jpg?wh=1920x743\" alt=\"图片\"></p><p>这里面我还穿插着介绍了一下康威定律，这其实是个非常神奇的定律，在无数的软件组织中印证过。因此，如果你发现你的组织结构和应用的目标架构不相符，你就要思考一下如何撬动组织变革了。</p><p>而这，就是<strong>逆康威定律</strong>。这个问题我会留到<a href=\"https://time.geekbang.org/column/article/521118\">下节课</a>再展开，敬请期待。</p><h2>思考题</h2><p>感谢你学完了今天的内容，今天的思考题是，请你来分享一下你所在团队结构是什么样的，是职能团队、组件团队，还是特性团队？或者你们已经进阶到Spotify模型了？你们的软件架构，是否是组织架构的映射？你们的组织结构，是否影响了架构的演进？</p><p>期待你的分享，如果你觉得这节课对你有帮助，别忘了分享给你的同事和朋友，我们一起推动组织变革。</p>","neighbors":{"left":{"article_title":"17 | DevOps现代化：从持续集成到持续部署","id":519664},"right":{"article_title":"19 | 团队结构现代化： 团队拓扑学","id":521118}}},{"article_id":521118,"article_title":"19 | 团队结构现代化： 团队拓扑学","article_content":"<p>你好，我是姚琪琳。</p><p>上节课，我们学习了遗留系统中最常见的单职能团队和技术组件团队，它们带来了很多问题。这些问题都体现在了软件的架构上，导致了大泥球架构，或按技术分层的多层架构。然后，我们深入讲解了可以解决这些问题的一些团队结构，如组件团队、特性团队和Spotify模型。</p><p>今天，我们来看看最近这几年来新诞生的组织结构模型——团队拓扑学（Team Topologies）。</p><h2>团队拓扑</h2><p>尽管组件团队、特性团队和Spotify模型，都为团队的组成提供了不错的建议，但团队的类型应该是什么样并没有一致的标准。如果所有团队都是特性团队，专注在某一个业务领域，那么业务领域开始变得复杂时，仍然僵化地专注于功能特性就会导致一些问题。</p><p>比如一个支付平台，它除了有源源不断的业务需求外，还有很多技术相关的事情要做，如数据的同步、分布式事务，或业务的回滚、对冲等。</p><p>假设按照系统的复杂度来判断，需要三十个人来维护这个平台，要是按照特性团队的思路来进行组织，就会分为三个特性团队，它们做着完全类似的业务开发。而对于复杂的技术问题，就可能无人问津了。尽管有了分会和协会可以一定程度上缓解，但这种自组织社区的执行力显然还不够。</p><p>这时，我们应该从<strong>团队优先（Team First）</strong>的角度去思考，将任务按照不同的复杂度来进行分解，并据此来创建团队。比如对于高复杂度的任务，应该建立一个以解决这些问题为KPI的专门团队，只有这样的团队才能真正解决这些复杂的问题。</p><!-- [[[read_end]]] --><p>有时候我们会觉得，团队无法满足开发的需要，是因为成员的能力不行，因此重点对人进行赋能，增加他的内在认知负载。但其实有可能是团队结构不合理，导致外在认知负载过高。</p><p>Matthew Skelton和Manuel Pais提出的<a href=\"https://teamtopologies.com\">团队拓扑学（Team Topologies）</a>，就从这一角度对团队的组成和沟通模式进行了大胆的尝试。</p><p><img src=\"https://static001.geekbang.org/resource/image/b3/27/b37f538799231cef80d74915000ba027.jpg?wh=1920x1369\" alt=\"图片\"></p><h3>团队拓扑类型</h3><p>他们提出了四种团队拓扑类型和三种交互模式。接下来我们就来重点学习一下。</p><p>第一种团队拓扑类型是<strong>业务流团队（Stream-aligned Team）</strong>，这里的“流”是指与业务、领域或组织能力对齐的工作流程，业务流团队的工作有可能是一个产品或服务，也可能是一组特性、一个用户旅程或一个用户画像。他们有能力快速、安全、独立地构建和交付用户价值，而不用将部分工作交给其他团队。</p><p>业务流团队是最主要的团队拓扑类型，你可以将它理解为特性团队，或Spotify中的小队，负责核心的价值交付。其他团队拓扑类型都是为了减轻业务流团队的负担，降低他们的认知负载而演进出来的。</p><p>比如，一个遗留系统想做微服务拆分，这是一项高难度的架构迁移工作。业务流团队的成员每天处于高强度的交付压力之下，根本没有时间去调研、探索和学习。这时候就诞生了第二种团队拓扑类型——<strong>赋能团队（Enabling Team）</strong>，它由特定技术领域或产品领域的专家组成。</p><p>赋能团队里的这些专家可以开展调研，尝试不同的方案，寻找最佳实践。然后对业务流团队进行赋能，使他们不需要太多的努力，就能具备拆分微服务的能力，大大降低了认知负载。</p><p>赋能团队并不会亲力亲为地解决具体技术问题，这些问题还是由业务流团队来处理。赋能团队主要关注的是，对组织中的所有业务流团队能力的提升。</p><p>相比Spotify模型中的分会和协会等松散的技术社区，赋能团队的工作内容更聚焦，可以有效地帮助业务流团队，解决某方面能力欠缺的问题。</p><p>不知道你的项目中是否有这样的模块，它的业务逻辑十分复杂，要想熟悉和理解需要极高的认知负载。比如视频的编解码、复杂的数学模型、语音识别算法等等。这时通常的解决办法是，由该领域的专家组成一个固定的团队，来维护这个复杂的模块。这种团队拓扑类型，就叫做<strong>复杂子系统团队（Complicated-Subsystem Team）</strong>。</p><p>在遗留系统中，如果有些复杂的计算位于存储过程，转换成Java十分困难，而且效率也不一定高。这时候可以考虑把它整体隔离出去，构建一个复杂子系统，再相应去组建一个复杂子系统团队，专门来维护它。团队自己可以决定是保持不变，还是将存储过程慢慢演进成代码。</p><p>业务流团队在和复杂子系统交互时，只需要使用复杂子系统团队提供的API，而不用费力地去理解这个复杂模块，同样可以降低认知负载。</p><p>然而有的时候，业务流团队不止需要访问复杂的业务模块，还要和一些组织内部的基础设施打交道，比如CI/CD服务器、各种容器和中间件等。</p><p>比如一个刚刚做到持续构建的遗留系统，很可能持续集成服务器并不稳定，动不动就会挂掉，但业务流团队没有精力去解决这些问题。这时候你需要的是第四种团队拓扑类型——<strong>平台团队（Platform Team）</strong>。它们负责解决底层问题，让业务流团队可以更专注于业务开发。</p><p>可以看到，<strong>团队拓扑的出发点是团队的认知负载</strong>，它所倡导的团队结构是认知负载最低的。它并没有尝试从不同的技术层面去解决团队的认知负载问题，这个角度仍然是在跨职能的业务流团队内部，通过不同的技术角色来解决的。因为业务流团队的成员虽然技术栈不同，但解决的都是价值流交付的问题。</p><p>团队拓扑建立了一个更高层次的抽象，按照技术和业务不同的复杂度，以及不同的团队目标来划分团队结构。</p><p>这是一种权衡。因为对个人来说，认知负载最低的一定是只从事自己最擅长的工作，也就是位于技术组件团队或职能团队中。但由于一个业务总是跨技术层级的，这就增加了沟通成本，导致了外在认知负载的升高；另一方面，特性团队虽然能很好地解决沟通问题，但不同层级的技术问题仍然会增加他们的认知负载，使他们无法专注在业务交付上，身心俱疲。</p><p>团队拓扑正是从这个角度，引入了另外三种团队类型，来解决特性团队的各种问题。</p><h3>团队交互模式</h3><p>在学习了四种团队拓扑类型之后，你可能会问，这些团队之间是如何交互的呢？团队拓扑学中给出了三种交互模式，分别是协作、服务和促进。</p><p><img src=\"https://static001.geekbang.org/resource/image/1c/5f/1c22c18d654d5cef43d942f0511b395f.jpg?wh=1920x581\" alt=\"图片\"></p><p><strong>协作（Collaboration）</strong>是指一个团队与另一个团队紧密合作。</p><p>比如前面提到的，业务流团队通过API来访问复杂子系统，当新的需求需要复杂子系统提供新的功能时，业务流团队就需要和复杂子系统团队通力合作，来完成这个需求；再比如一个用户登录功能，也需要业务流团队和平台团队的协作，业务流团队负责开发面向用户的界面和相应的后台，平台团队负责开发认证与鉴权功能，或者与其他单点登录系统集成。</p><p>协作也会增加沟通成本，但这种成本是系统的复杂性所导致的，并不是像按技术分组那样，是人为因素导致的。</p><p><strong>服务（X-as-a-Service）</strong>是指使用或提供某种服务，而尽量减少协作。比如如果复杂子系统已经提供了完成需求所用的API，业务流团队就无需与复杂子系统团队协作；如果平台团队已经封装好了用户认证和鉴权的所有功能，业务流团队也只需要“拿来主义”即可。由于API或服务开箱即用，业务流团队无需关注底层的实现细节，就可以快速地实现功能。</p><p><strong>促进（Facilitating）</strong>是指帮助其他团队清除障碍。这是赋能团队主要的交互模式，他们对外部团队提供支持和赋能，来提升他们的生产力和效率。</p><p><img src=\"https://static001.geekbang.org/resource/image/6f/ab/6fbd661c4d3cb6172790c104fd74b4ab.jpg?wh=1920x1105\" alt=\"图片\"></p><h2>逆康威定律</h2><p>学习完了特性团队、Spotify模型和团队拓扑，你可能会问，适合遗留系统的团队结构到底是什么样的呢？</p><p>我们前面提到了康威定律，即团队的结构会影响到系统的架构。假如你的系统包含四个团队，每个团队都包含前端和后端开发，而仅有一个DBA负责数据库变更。那么根据康威定律，你得到的软件架构一定是，拥有四个独立的应用，包含各自独立的用户界面和服务端，而它们共享一个单体数据库。</p><p><img src=\"https://static001.geekbang.org/resource/image/08/04/08be5d71ffe5fe4b8dd4944a74eb8304.jpg?wh=1920x800\" alt=\"图片\"></p><p>如果你在保持团队结构不变的情况下，企图拆分数据库，一定是办不到的。即使勉强拆分出来，也会很快腐化。正确的做法应该是，顺应康威定律，为每个团队配备一名DBA，然后再拆分数据库。每个应用的数据库由单独的DBA去维护，才能保证它不会腐化。</p><p>这种为得到理想的架构而改变团队结构的做法，叫做<a href=\"https://www.thoughtworks.com/radar/techniques/inverse-conway-maneuver\">逆康威定律（Inverse Conway Maneuver）</a>。也就是说，你想得到什么样的架构，就先把组织结构调整成那个样子，以此来推动组织变革。</p><p>在遗留系统中，你需要根据自己的目标架构来调整组织结构，同时参考特性团队、Spotify模型和团队拓扑。</p><p>康威定律不但会影响到架构形态，还会影响到架构师的技术决策。我发现很多架构师在做方案时，总是期望一步到位，这样会给原本简单的方案带来很多复杂度。</p><p>更合理的方式应该是，先用简单的方式run起来，尽早上线去交付价值，等发现问题再去修补和演进。这样更符合增量演进的原则，也更容易得到一个“刚刚好的架构”。而“一步到位”的想法则更容易导致过度设计。</p><p>产生“一步到位”这种想法的根本原因是什么？表面上，是架构师在做设计的时候可能不会想到那么多，只是一种先入为主或者说习惯的想法，但实际上背后可能隐藏着康威定律。</p><p>如果你有一个独立的团队去维护一个服务，这个团队能有足够的人力、有足够的上下文去守护这个服务的架构，你就会更倾向于构建一个可演进的架构。但如果团队接下来有哪些人你不确定，他们有没有能力演进同样不确定，那么主观上我们就会不自觉地倾向一步到位式的设计。因为如果现在不做，以后就可能没机会了。</p><p>如果你是项目的负责人，希望你能够主动改变团队的结构，以得到理想中的架构，并且潜移默化地改变团队中的各项技术决策。</p><h2>小结</h2><p>总结一下今天的内容。我们学习了近年来提出的一种全新的团队结构模型——团队拓扑学。我之所以在它后面加了一个“学”字，是因为它相比特性团队和Spotify模型，更接近一门学问。它提出的团队认知负载和团队优先的理念，更是超前于这个时代。</p><p>组件团队、特性团队、Spotify模型或团队拓扑，它们并不是相互替换的关系，而是可以按需合并和剪裁的。它们面向的问题域不同、目标不同、出发点不同，因此不存在谁比谁高明的情况。</p><p>我还准备了一张表格，总结几种讲过的团队类型，你可以做个参考。<br>\n<img src=\"https://static001.geekbang.org/resource/image/81/0c/810d309a3522da96889dec23f98df60c.jpg?wh=1920x959\" alt=\"图片\"></p><p>你应该根据自己团队的实际问题，找出合适的方案。比如你可以以特性团队为基础，并为几个特性团队配备平台团队和赋能团队，这样的几个团队组成一个部落，同时也有跨团队的各种技术社区。</p><p>比如很多组织的开发团队忙于需求开发，根本没有时间思考流程改进。这时候我们想推动类似主干开发这类实践，是很难有进展的，因为它需要很多配套的基础设施，开发团队没有时间去做这些。</p><p>业务部门也只要看到需求上线就行，根本不关心流程改进，毕竟开发的痛点跟他们没关系。业务方总是把开发团队当成工具人，而不是合作者。</p><p>现在很多大厂开始组建工程效能部门，负责开发工具、优化流程、改进基础设施，一定程度上解放了开发部门。虽然很难说这种工程效能部门是属于赋能团队还是平台团队，但至少都是在解决业务流团队平时没时间解决的痛点问题，为他们服务。这就是一种非常有价值的探索。</p><p>同时要记住的是，团队结构也要不断演进。虽然以不变应万变很酷，但当“应付”不了的时候，还是应当“应变”。因为业务在变化，架构自然需要跟着变化以支撑业务，那么根据逆康威定律，你也要调整团队结构，以支撑新的架构。</p><h2>思考题</h2><p>感谢你学完了今天的内容，今天的思考题是，请你来分享一下你所在团队的组成是什么样的？有没有类似赋能团队或平台团队这样的组织？你们是否会根据目标架构而演进自己的团队结构？</p><p>期待你的分享，如果你觉得这节课对你有帮助，别忘了分享给你的同事和朋友，我们一起来推动组织变革。</p>","neighbors":{"left":{"article_title":"18 | 团队结构现代化 ：从组件团队到Spotify模型","id":520553},"right":{"article_title":"20｜启动：如何开启一个遗留系统现代化项目？","id":521807}}},{"article_id":521807,"article_title":"20｜启动：如何开启一个遗留系统现代化项目？","article_content":"<p>你好，我是姚琪琳。</p><p>从今天开始，我们的课程将进入一个全新的环节。之前，我们学习了遗留系统四个现代化的诸多模式和理论，然而纸上得来终觉浅，现在的你一定摩拳擦掌跃跃欲试，准备在项目中大显身手了吧？</p><p>不过别急，你可以先跟着我，一起在一个虚拟的遗留系统中实践一番，将三大原则和各种模式一一落地，并结合实际情况做出调整，以适应项目和团队。</p><p>今天是这个实践系列的第一节课，如何启动一个遗留系统现代化项目。</p><h2>项目背景</h2><p>说来有点唏嘘，国内遗留系统的重灾区，恰恰是那些最早拥抱信息化的行业，比如电信、银行、保险、民航等。它们早年身先士卒，投资金、投人力，建设了信息化系统，没想到多年以后反而成为了限制业务发展的遗留系统。</p><p>这些遗留系统都在各方面都存在着许多共性：</p><ul>\n<li>代码量巨大且质量不高</li>\n<li>前端普遍使用用ASP、JSP等服务端渲染技术，在页面中内嵌了大量业务逻辑</li>\n<li>数据库中存在大量存储过程和函数</li>\n<li>单体“大泥球”架构</li>\n<li>系统缺乏文档和知识，新人很难上手</li>\n<li>几乎没有DevOps</li>\n</ul><p>我们这个虚拟案例是一个车险行业的业务系统，它具备以上所有特点，使用JSP技术，数据库是Oracle，存储过程的代码量占整体代码量的三分之一左右。那么在开始现代化之前，你需要做哪些前期准备呢？</p><!-- [[[read_end]]] --><h2>业务梳理</h2><p>作为架构师，你可能并不熟悉每一个业务模块的具体内容，但不了解业务是无法设计出合理架构的。因此，你需要先对整体业务进行梳理，划分出业务的边界，才能进一步设计组件和服务。你还需要沟通好业务方，请他们派出各个业务模块的领域专家跟你一起梳理。当然，你也同样需要业务分析师、质量分析师和资深开发人员。</p><p>有很多梳理业务的方法和工具，像用户旅程、用户故事地图等，它们可以帮助你理解业务流程、梳理业务架构。这其实也是一个降低外在认知负载、提升相关认知负载的过程。</p><p>梳理好的投保和理赔业务的用户旅程（这里是一个简化版的用户旅程，忽略了痛点和心情曲线，我们的目标是梳理业务流程，而不是寻找用户痛点）大致如下所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/51/88/5121cee08137263a89aa96fc5ba3e288.jpg?wh=1920x821\" alt=\"图片\"><br>\n<img src=\"https://static001.geekbang.org/resource/image/1f/61/1f92c3aca86ac3095cb0a73190aef861.jpg?wh=1920x821\" alt=\"图片\"></p><h2>战略建模与架构设计</h2><p>接下来，我们需要以用户旅程为蓝本，对整个系统进行战略建模，目的是设计出目标架构。</p><p>战略建模同样有很多工具可用，常见的有事件风暴、动名词法，以及刚刚兴起的领域故事会。在这个案例里，我们使用动名词法。</p><p><strong>动名词建模法</strong>是指通过梳理业务需求、识别关键领域名词、识别命令动词，并将名词动词进行关联，从而形成统一语言、提取模型的建模过程。</p><p>其中，<strong>领域名词</strong>是指在业务操作中出现的名词，通常是业务操作的对象，比如“订单”，“商品”等。&nbsp;而<strong>命令动词</strong>是指作用于领域名词的动作，使用业务语言描述（区别于CRUD），比如“下单”，“订购”等。</p><p>在实战中，我们将整个建模过程分为以下七个步骤。</p><p><img src=\"https://static001.geekbang.org/resource/image/c7/f3/c7eff9cee380bea989305258764f50f3.jpg?wh=1920x679\" alt=\"图片\"></p><p>其中，前四个步骤属于业务梳理，后三个步骤属于架构设计。</p><h3>步骤一：识别动名词</h3><p>在这一步中，我们跟领域专家一起，进一步详细分析用户旅程中的每一个业务阶段。按照业务时序，讨论业务步骤，以达成一致的理解。梳理完毕后，将动词和名词按照业务相关性组织到一起。</p><p><img src=\"https://static001.geekbang.org/resource/image/0a/9b/0ayya883fc0348ef99be627ca316d59b.jpg?wh=1895x746\" alt=\"图片\"></p><p>在这一过程中，我们可以和领域专家澄清很多缩略的业务术语。比如核保，拆分成命令动词和领域名词，应该是审核投保单，承保应该是承接投保单，缴费应该是缴纳保费，报案应该是申报案件申请，结案应该是结束案件……</p><p>澄清这些术语很重要。比如核保和承保，字面上理解是审核和承接保单，但实际业务中却是投保单。</p><p>通过和领域专家的沟通，你才会明白，保单才是保险公司和投保人之间的合同，而投保单只是一个投保申请。因此，保单和投保单很明显是两个领域名词，建立的模型也肯定是不一样的。再比如缴费这个术语，在投保上下文里代表的是缴纳保费，但在其他上下文里，可能是缴纳其他费用。</p><p>越早澄清这些容易引起歧义的名词，就越容易形成统一语言，避免误解。</p><h3>步骤二：识别角色</h3><p><strong>角色</strong>是命令动作的发起者，比如“代理人”、“承保岗”、“查勘岗”，也可以是一个系统，比如微信小程序、支付宝等。</p><p>通过识别角色，我们可以进一步了解命令动作是如何参与到业务中的。另外，不同角色的需求和变化频率往往不同，这有助于我们设计边界更加合理的架构。</p><h3>步骤三：寻找缺失概念</h3><p><strong>缺失的概念</strong>是指业务人员没有明确提到的概念，但是缺失后很可能影响业务的完整性和可追溯性。</p><p>缺失的可能是名词，比如已经识别出来了某个动词，但却没有找到与之对应的名词，你需要找到这个名词，并补充到模型中；缺失的也可能是动词，业务人员没有明确提到，但缺失了某一动词后，名词的生命周期就不完整，这样的动词也需要补充到模型中。</p><p>比如在步骤一提到的投保和缴费，就都是行为，没有对应的名词，找到投保单和保费的概念，就弥补了缺失的名词。再比如赔款这个名词，只有“支付”这一个动词与之对应，显然生命周期是不完整的，应该补充“生成赔款”这一动作。</p><h3>步骤四：去除噪音</h3><p>与前一步“寻找缺失的概念”相反，这一步是要去除或忽略无用的信息（噪音）。通常需求⽂档或者业务人员的描述会涉及到很多细节，但并不是所有的内容都和建模相关。在实施过程中需要有针对性地甄别，避免噪音对模型的干扰，降低后续设计过程的复杂度。</p><p>在建模时不需要关注的噪音通常包括：</p><ul>\n<li>无需记录的线下操作：有些行为并不会影响系统的数据或状态，因此不需要被系统记录。比如投保人提供投保单材料、上级人工核保、打印保单、清分单据等。</li>\n<li>查询操作：和数据查询相关的操作，如数据展示、数据导出、数据过滤查询等。</li>\n<li>字段说明：业务验证错误时的提示语、出错信息等。</li>\n</ul><p>经过这四个步骤，我们完成了业务梳理，部分的领域名词和命令动词如下所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/1d/48/1d99b7f961791e4c93b870f7ff681648.jpg?wh=1920x641\" alt=\"图片\"></p><h3>步骤五：区分基础能力与运营能力</h3><p>对于一个大型的复杂系统，我们需要将它分解成更小、更简单的部分。借鉴Unix操作系统“分离策略与机制”的设计原则和DDD战略设计方法，我们将业务能力分为基础能力和运营能力。</p><p><strong>基础能力</strong>通常提供原子能力，它们不依赖于编排能力，且变化的频率很低；<strong>运营能力</strong>是在基础能力之上，企业想要健康运作而需要的能力，它们的变化频率很高。</p><p>在这一步中，我们要区分已经汇总的动名词对儿，并将它们按照基础能力和运营能力分成两层。</p><p><img src=\"https://static001.geekbang.org/resource/image/e2/3e/e242bdb9c3638d711b04d0410267353e.jpg?wh=1920x775\" alt=\"图片\"></p><h3>步骤六：识别核心基础能力</h3><p>对于像保险业务系统这样的大型复杂系统，其基础能力可能仍然过大，需要进一步分解。按照Gartner的 <a href=\"https://www.gartner.com/en/information-technology/glossary/pace-layered-application-strategy\">PACE Layered Application Strategy</a>，对于基础能力里稳定性（或变动频率）不同的部分，我们可以再次划分，识别出核心基础能力。</p><p><strong>核心基础能力</strong>是指反映业务本质，实现业务价值所必须的最小能力集合。在识别核心基础能力的时候，你可以遵循这样三个原则：</p><ul>\n<li>稳定性原则：即找出反映业务本质的部分。业务本质通常是最稳定的，而与用户的交互通常是不稳定的。</li>\n<li>最小化原则：即尽可能做减法，非必要不做加法。</li>\n<li>完备性原则：即核心基础能力应该是完备的，能够独立实现业务价值。</li>\n</ul><p>以保险业务为例，不论其渠道端（柜台、互联网、移动端）怎么变化，不论实现技术怎么变化，其业务本质仍然围绕保单展开的，包括保单的费用和服务（案件、赔款）。在识别出业务本质后，我们的业务名词就可以分解为这样的三层。</p><p><img src=\"https://static001.geekbang.org/resource/image/de/4b/dedbc2c3b34bb3d2fd1bc18d4b7fc14b.jpg?wh=1920x877\" alt=\"图片\"></p><h3>步骤七：设计分层架构</h3><p>当我们把业务名词分层之后，就可以着手设计目标架构了。在这里，我们把这些业务名词理解为一个业务模块或组件中的核心模型，并以这些名词作为模块或组件的名称。</p><p>对于企业的业务系统，我们可以粗略地设计为三个层次：接入层、运营作业层和核心能力层。</p><p>接入层一般为UI系统、API Gateway或BFF等，比如手机App、微信小程序等。运营作业层是指围绕业务价值所展开的运营活动和作业管理。</p><p>我们在这里把前面的运营能力层和基础能力层合并，来作为运营作业层。核心能力层是实现业务价值所必须的最小能力集合，是企业运营的本质。比如保险行业就是保单和保费，而银行则是围绕账户所展开的金额和状态的管理。</p><p>除此之外，业务系统还需要对接一些企业已有的公共服务，比如产品中心、银行对接、客户管理、权限管理等，也需要与一些外部系统进行交互。</p><p>最终的目标架构如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/4f/e2/4fa6d7e272ffa17b6cf5d59004feb2e2.jpg?wh=1920x840\" alt=\"图片\"></p><p>当然，这只是一个假想的保险业务系统，我们仅仅做了其中部分业务的粗略梳理，并不是什么行业标准。你要重点学习的是这种战略建模和架构设计的方法。</p><h2>选择试点</h2><p>有了战略模型和架构设计后，我们接下来要选择一个试点进行遗留系统现代化。</p><p>在做数字化转型时，我们常常会选择一个<strong>精益切片（Thin Slice）</strong>作为试点，而不是全盘地转型。遗留系统现代化同样可以借鉴这种方法，对架构进行垂直的切割，将业务的所有元素整合成一个价值交付部分，能够提供完整的价值。</p><p>除了业务价值，你还需要考虑试点的复杂度。你可以使用一些工具，全盘分析整个遗留系统，一方面可以得出一些质量指标，比如缺陷数、坏味道数等，评估代码质量。另一方面也能得出模块间的依赖关系，了解系统的复杂度。</p><p>对于代码质量，推荐你使用流行的SonarQube。对于架构，向你推荐我们公司的开源工具 <a href=\"https://archguard.org\">ArchGuard</a>。</p><p>什么样的切片才适合做试点呢？这需要你权衡业务价值和复杂度。业务价值高的，往往很复杂，不好做；而简单的，又可能没有价值。</p><p>所以要尽量选择既能提供一定业务价值，复杂度又不是很高的切片。因为复杂度太高的话，进展会很慢，容易让团队和各方干系人失去信心和耐心。</p><p>而相对简单的模块则更容易成功，可以给业务带来实惠，给团队增加信心，同时可以总结出来各种经验和套路，供下一个切片使用。</p><p>在综合评估了业务价值和复杂度这两个维度后，我们选择核保模块作为试点。下图中阴影覆盖的部分，就是一个切片。</p><p><img src=\"https://static001.geekbang.org/resource/image/9d/0c/9d850bb4a7bca8d894e131f0b626e00c.jpg?wh=1920x858\" alt=\"图片\"></p><h2>以假设驱动为指引选择现代化方向</h2><p>选择完试点，你还需要选择要对试点所采取的遗留系统现代化方向。是重构代码，还是添加测试？是拆分模块，还是拆分服务？这些都是可行的方向，你需要选择的是最可能实现更大业务价值的那些。</p><p>这时候我们需要以假设驱动为指引，帮我们找到价值最大的方向。</p><p>比如从业务敏捷这个维度，我们需要缩短需求交付周期、扩大需求吞吐量。以前30人天开发完成的需求，能否缩短到20天？以前一个迭代交付5个需求，能否再增加1个？如果业务方更关注业务响应力，你可能需要将这个模块拆分成相对独立的服务。</p><p>另一方面，如果平时这块业务Bug比较多，需求方更希望改善它的质量，那你可能需要对代码添加各种级别的测试（参考<a href=\"https://time.geekbang.org/column/article/512658\">第八节课</a>）。</p><p>指标的重要性和优先级确立以后，你需要与业务方达成一致，并选择可以支撑这些指标的工作。就本案例而言，业务方更关注业务响应力，因此我们选择将核保模块拆分为微服务。</p><h2>确定目标架构</h2><p>对于试点的目标架构，你其实无需关注太多细节。我们虽然通过战略建模，梳理出了整个系统的大致架构分层，但这其实还是对于问题域（Problem Space）的分析。</p><p>具体解决方案域（Solution Space），这些模块是微服务，还是几个模块合并成基于服务的架构，其实都不需要在现阶段给出答案。</p><p>遗留系统是复杂的，架构应该是慢慢演进的。一个负责任的架构师，是不可能仅仅在几天的业务梳理和战略建模之后，就给出最终的确切架构的。</p><p>对于核保模块这个试点，我们的目标架构十分简单，就是把它拆分出来，形成一个微服务。<br>\n<img src=\"https://static001.geekbang.org/resource/image/85/a0/85715a7757924b077741385aafec3aa0.jpg?wh=1920x957\" alt=\"\"></p><h2>制定架构演进计划</h2><p>虽然目标架构的形态十分直观，但演进计划却并不简单。这是一个将遗留系统的微服务拆分这个复杂问题，拆解成多个简单问题的过程，最终让任何一个普通的开发人员，都能够胜任其中的一个简单任务。</p><p>在制定计划时，你需要考虑以下几个方面：</p><p>首先，代码如何拆分。在遗留系统中，各个业务模块的边界是否清晰？是否可以使用基于组件的分解？或者是一个结结实实的大泥球，只能使用战术分叉？对于这部分内容，你可以复习一下<a href=\"https://time.geekbang.org/column/article/515274\">第十二节课</a>的内容。本案例的模块边界十分模糊，所以我们最终决定采用战术分叉方式。</p><p>其次，数据如何拆分。是暂时不拆分，和遗留系统共享单体数据库？还是使用单体封装的数据库服务？或者变更数据所有权，并在应用中同步数据？关于这部分，你可以复习<a href=\"https://time.geekbang.org/column/article/517959\">第十五节课</a>的内容。本案例最终选择的是拆分数据。</p><p>第三，如何增量迭代。按照增量演进原则，我们不能采取长期改造、一次性上线的交付方式，而应该是每个迭代都交付一部分增量。那么对于服务拆分，应该如何迭代？是按页面交付？还是按API交付？</p><p>在这个案例里，考虑到页面过于复杂，包含很多按钮，而每个按钮都对应一个后端API，我们选择按API交付，这样粒度更小。</p><p>第四，组建拆分小组。你需要和项目负责人沟通好资源，给你一个5~9人的开发团队。如果遗留系统的团队结构是业务组件团队，则最好就是从维护核保这个组件的团队中抽调一些人。如果是特性团队，则最好是经常做核保特性的团队。</p><p>最糟的情况是技术组件团队，你需要选择一些对核保业务比较熟悉的开发人员。另外，一定要配备一到两名专职测试拆分结果的测试人员，不要给他们分配其他测试工作。我们在第十八节课中介绍过，这样会让测试人员在不同上下文之间频繁切换，增加他们的认知负载。</p><p>第五，干系人如何管理。你需要与业务方、项目负责人、业务分析师、其他架构师、核心开发人员、测试人员建立紧密的联系，获得他们的支持和帮助。</p><p>做好这几个方面，你就可以开始按迭代增量演进了。</p><h2>按迭代增量演进</h2><p>迭代0是增量演进中最重要的迭代，有很多事情要在这个迭代完成。</p><p>第一，创建全新的核保代码库。按照战术分叉的方法，将遗留单体的代码全量复制到核保代码库中，并将与核保无关的代码删除。</p><p>第二，创建全新的核保数据库。对于数据，你也可以使用战术分叉方法，将全量数据复制过来再删除掉无关的表，或者利用Oracle的特性，使用DB Link，先远程访问单体数据库中的内容。具体方法我们后面的课程再展开。</p><p>第三，搭建核保服务的持续集成流水线。如果遗留系统已经有了持续集成流水线，可以复用。如果没有，可以只搭建一个最简单的流水线，只包含构建和打包功能。</p><p>第四，将持续集成流水线打出来的包部署到各个环境中。部署完之后，可以通过API工具测试部署是否成功。</p><p>第五，建立开关机制。将流量引流到新的服务中，以验证真实场景下的连通性。</p><p>第六，计划迭代1要改造的API。从迭代1开始，增量演进就将进入一个稳定的交付阶段，你需要在每个迭代结束前，计划好下个迭代要完成的工作。</p><p>第七，制定开发工序。要将复杂的任务简单化，你需要制定一个普通开发人员可以遵循的开发清单。</p><p>比如用活文档工具进行业务梳理、添加API的开关并验证、在单体中的老API上添加@Deprecated注解、Java代码怎么拆分、存储过程怎么拆分、JSP中的代码如何处理、如何测试、如何寻求帮助等等。开发工序应该尽可能详细，以降低普通开发人员的认知负载。</p><p>由于迭代0的工作量巨大，你可以相对延长迭代0的时间。比如一个迭代是两周，你可以把迭代0延长到一个月，以确保这些内容顺利完成和交付。</p><p>从迭代1开始，你就可以按增量来演进了。下节课起，我们将一同挑战增量演进阶段会遇到的种种难题。我会在模式篇讲过的种种模式的基础上，结合项目实际情况，将这些难题一一化解。</p><h3>关于估算</h3><p>在改造时，一个绕不过去的话题就是需要多长时间。对于正常的功能开发，工作量的估算可能还比较准确，但是对于遗留系统现代化，想准确估算出具体的时间节点是难上加难。</p><p>因为遗留系统现代化是一个复杂问题，会有很多不确定的东西时不时冒出来，比如人员变动、临时添加的紧急需求、代码和架构本身未知的复杂度等等。</p><p>不过，这和业务方的诉求是矛盾的，业务方想知道到底需要多少预算，来评估风险、衡量ROI。然而，如果迫于业务方的压力而随意拍脑袋给一个人天（比如10人天就是1个人工作10天，或者2个人工作5天），反而是不专业的。这时最好的答案就是坦诚地说：我还不知道。</p><p>正因为如此，你才更应该选取一个小的精益切片，并且将功能开关锁定在一个小的API上。因为开发的规模变小了，估算可能还相对容易一些。</p><p>你应该快速做出一个小的增量，证明这是可行的，给团队、领导和业务方以信心。然后根据做出的这个增量的工作量去估算其他增量。</p><p>你也可以让业务方来比较一下，希望开发给出一个一年的承诺，最后一次性上线全部承诺，还是不做出具体承诺，但是一年内每个月都能看到一个具体的进展，并且随时可以中止（因为是增量且可回退的）。如果业务方选择后者，那么他们就不会再纠结于一次性知道全部费用了。</p><h2>小结</h2><p>总结一下今天的内容。这是我们实战篇的第一节课，我们一起讨论了如何开启一个遗留系统现代化项目。</p><p>我们花了不少篇幅去梳理开启项目的步骤，你需要先对不熟悉的业务进行梳理，得到初步的用户旅程或用户故事地图；再通过动名词法等工具，对系统进行战略建模，并设计出目标架构；然后选择一个端到端的业务进行试点，并以假设驱动的方式寻找合适的现代化方案；接下来是确定目标架构以及制定演进计划，并按照计划逐个迭代地增量演进；最后，每个迭代都需要得到充分验证，我将在第二十五节课详细介绍这一部分内容。</p><p>我们的目标很明确，就是要把核保业务从单体大泥球架构中拆分出来，形成具有独立数据库的微服务。这已经是个非常艰巨的任务了。因此你一定要记住，一次只做一件事。</p><p>有时候你可能既想拆分微服务，又要进行代码重构，或者既要拆分数据，又想重新设计不合理的数据库，这些都是我不推荐的。你可以把它们排进计划，等一件事彻底做完再做另一件，而不要企图并行完成。因为认知负载太高了，什么都想做，最终什么也做不成。</p><p><a href=\"https://time.geekbang.org/column/article/522486\">下节课</a>，我们即将开启具体的现代化工作，敬请期待。</p><h2>思考题</h2><p>感谢你学完了今天的内容，今天的思考题是，如果按照假设驱动的原则，我们最终选择的不是微服务拆分而是代码重构，你应该制定什么样的演进计划？如何增量迭代？</p><p>期待你的分享，如果你觉得这节课对你有帮助，别忘了分享给你的同事和朋友，我们一起开始一个遗留系统现代化项目吧。</p>","neighbors":{"left":{"article_title":"19 | 团队结构现代化： 团队拓扑学","id":521118},"right":{"article_title":"21｜微服务拆分（一）：迈出遗留系统现代化第一步","id":522486}}},{"article_id":522486,"article_title":"21｜微服务拆分（一）：迈出遗留系统现代化第一步","article_content":"<p>你好，我是姚琪琳。</p><p>在前面的课程中，我们结合案例讲解了如何启动一个遗留系统现代化项目。从这节课起，我们将重点介绍项目启动之后的内容，也就是具体的现代化工作。</p><p>当我们完成了项目的战略设计，大体设计出目标架构，又根据系统的现状，决定采用“<strong>战术分叉</strong>”的方式进行微服务拆分之后，接下来的难点就变成了“如何拆分”的问题。</p><p>我们会用四节课的篇幅来讲解如何拆分，分别覆盖代码拆分、数据库拆分、存储过程拆分和一些其他注意事项。这节课我们先来看看如何拆分代码。</p><h2>拆分目标与演进计划</h2><p>我们先来回顾一下上节课所制定的架构目标和演进计划。</p><p><img src=\"https://static001.geekbang.org/resource/image/b7/58/b7d8522135d6828d1e6e178yyfac5b58.jpg?wh=1920x957\" alt=\"图片\"></p><p>我们的目标是<strong>将核保模块从遗留的单体应用中剥离出来，形成一个独立的微服务</strong>。这意味着，我们不仅要将代码拆分出来，放到全新的代码库中，数据库也要从原来的单体数据库中独立出来。以前可以随意访问的代码和数据库表，都要通过某种方式完成解耦</p><p>最终核保服务和遗留单体服务之间的关系，可能会像下图这样：</p><p><img src=\"https://static001.geekbang.org/resource/image/4a/39/4a52f2af770e24bc6880d94a9750c239.jpg?wh=1920x1174\" alt=\"图片\"></p><p>接下来我们就来看看如何演进。</p><h2>基于反向代理的特性开关</h2><p>我们先通过战术分叉，将单体中的核保模块（包括数据库）以及它所依赖的其他代码都完全复制出来，放到一个全新的Maven module或代码库中，并引入Spring Boot或其他Web框架。这部分工作可能会比较繁琐，但并不太复杂。</p><!-- [[[read_end]]] --><p>这时候，所有的请求还都是指向遗留系统的，要想验证分叉出来的服务是否正确，需要将请求引流到新服务中。应该如何引流呢？我们来看今天的第一个实践：反向代理。</p><h3>增量交付的粒度</h3><p>在微服务拆分的过程中，我们要贯彻“<strong>以增量演进为手段</strong>”的原则，因此要确保整个拆分的过程是增量交付的，并且是可回退的。</p><p>对于增量交付，粒度上应该怎么灵活控制呢？可以粗一些到功能级别，即一次交付一个功能场景的改造，也可以细一些到API级别，甚至更细到方法级别。</p><p>不过根据我的经验，<strong>API级别是最合适的</strong>。功能级别粒度较粗，可能很难在一个交付周期内完成，无法增量迭代；方法级别又太琐碎，且控制开关的代码对业务代码的侵入较多。</p><p>当然，你在制定自己的增量交付计划时，还是要根据项目的实际情况去选择。比如每个功能都很小，只有一两个API，那也可以按功能级别进行控制。而如果某个API十分复杂，包含很多方法，也可以对这些方法添加开关。</p><p>API级别的增量交付要求我们一次改造一个端到端的请求，并进行独立的测试和上线。我们可以在一个交付周期内（如两周或四周）计划好要改造的若干API，并在上线截止日前完成开发和测试。</p><h3>实现“特性开关”</h3><p>在回退机制上，我们需要建立一个开关，当改造后的核保服务中的API发生问题的时候，能够回退到老的单体服务中。这有点类似于在开发功能时使用的“特性开关”。之后的第二十四节课，我还会详细分享更多在代码中使用特性开关的实践。</p><p>怎么实现这种开关呢？由于目前所有请求都是指向单体服务的，我们可以在单体服务中加入一个“反向代理”层，当一个请求进入单体服务中时，会先判断当前的请求是否由开关控制。</p><p>如果有开关且处于打开状态，就将请求重定向到新的核保服务中，否则就仍然访问单体中的旧代码。如果你的遗留系统中，在单体服务之外已经有了API Gateway，那当然就要把这个反向代理放在API Gateway中了。</p><p><img src=\"https://static001.geekbang.org/resource/image/69/4c/698e9907314b9c82f665949f81ab624c.jpg?wh=1920x1172\" alt=\"图片\"></p><p>这种反向代理的实现方式有很多。因为专栏里的案例是一个基于Servlet的JSP遗留系统，因此可以使用Filter的方式实现。开关可以存储在DB中，也可以放在配置文件里。下面是一个可以参考的代码实现：</p><pre><code class=\"language-java\">public class ReverseProxyFilter implements Filter {\n  @Override\n  public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) \n      throws IOException, ServletException {\n    // 根据request获取toggle状态\n    if (toggleOn) {\n      // 包装request\n      // 转发到核保服务\n      // 得到核保服务返回的响应\n      // 填充到response\n      return;\n    }\n    // 继续执行其他filter\n  }\n}\n</code></pre><p>在开关打开的时候，我们需要包装和转换当前的ServletRequeset，然后转发到核保服务。在得到核保服务的响应后，再次转换数据并填充到response中。在做请求转发的时候，可以使用OkHttpClient这样的工具。你可以思考一下，为什么要做这样的转换，为什么不能直接转发ServletRequest呢？</p><p>当反向代理功能实现完成之后，这段代码就可以上线做验证了。我们可以给任意核保模块的API设置开关，并打开开关，验证该请求是否能够正常完成。你看，我们为了保证增量演进所引入的功能，它本身也是按增量去交付的。</p><p>如果你对前面课程提到的架构现代化的一些模式掌握得很扎实，可能已经发现了，这里面我们其实使用的是“<strong>绞杀植物模式</strong>”（可以回顾<a href=\"https://time.geekbang.org/column/article/514516\">第十一节课</a>）。</p><p>我们通过开关和反向代理，让新服务和单体中的旧模块共存。当新服务中要改造的API，完成对单体中其他代码和数据库的解耦之后，就可以上线，并打开开关做验证了。</p><p>如果新服务中的API有问题，产生了bug，就关闭开关，让请求依然指向单体中的旧模块，确保系统的正常运行。如果新服务中的API稳定运行了一段时间后，没有出现问题，我们对这次改造有了信心，就可以删除开关，让新服务中的API完全取代单体中的旧模块，从而完成这次“绞杀”。我们就这样逐个API地去绞杀，直到单体中的旧模块被新服务彻底代替。</p><p>看到这里，相信你已经对改造具体的API跃跃欲试了吧？先别急，我们来看看数据怎么处理，也就是实现数据同步。</p><h2>建立数据同步机制</h2><p>为什么需要做到数据同步呢？我们不妨从业务角度做个分析。</p><p>战术分叉只是将数据库复制了一份出来，但旧的单体服务仍在运行，所以总会有新的核保数据源源不断地写入核保相关的表中。如果这部分数据没有出现在新的核保库中，那么前面我们设置的开关就是无法打开的，因为数据不全，无法正常开展业务。</p><p>为了真正享有反向代理带来的随时可以回退的好处，我们必须建立某种数据同步机制，让写入旧核保表中的数据也能同步到新的核保库中，反之亦然。这样才能保证，开关无论打开还是关闭，看到的数据都能保持一致。</p><p>回忆一下我们建设新老城区的隐喻，这就好比是新城区中没有自来水厂，我们从老城区拉一条管线过去给新城区供水一样。</p><p><img src=\"https://static001.geekbang.org/resource/image/8b/b7/8b05e2eff30300yy7fe763806d25dab7.jpg?wh=1920x1229\" alt=\"图片\"></p><p>如何建立这种同步机制呢？</p><p>说到同步，你可能最先想到的就是<strong>事件拦截</strong>，这当然是非常有效且一劳永逸的方式。每一个数据变化的点，都会触发一个事件，并持久化到消息中间件中，事件的消费方通过消费这个事件来实现数据的同步。</p><p>如果你的系统中已经存在了消息中间件，并且有足够的事件，那么恭喜你，你是幸运的。然而大多数遗留系统是没有这些事件的，要想补齐所有事件来得到全部数据的修改点，工作量可能会超出服务拆分本身。</p><p>在这种时候，还是推荐你使用<strong>变动数据捕获（CDC）</strong>的方式来同步数据。建议你使用事务日志轮询，而不要使用触发器，因为需要捕获的数据很多，触发器多了会变得混乱。</p><p>你要记住的是，不但要做单体库到新库的同步，也要做新库到单体库的反向同步。为什么要做这种反向同步呢？因为当开关打开时，请求重定向给了新的核保服务，数据也写到了新的核保库中，此时的单体库中是没有这些数据的。这时关闭开关，数据就“丢失”了。</p><p>事件拦截和CDC的相关内容，你可以复习一下<a href=\"https://time.geekbang.org/column/article/514516\">第十一节课</a>。</p><p>还有一种方法，我们可以在单体服务和核保服务中对数据库进行“双写”，也就是既写入新的核保库，同时也写入旧的单体库，这样无论开关是否打开，都能保证两边的数据一致。</p><p>当然，双写的时候不能让核保服务直接访问单体数据库（否则我们做微服务拆分以及数据所有权的拆分就都没意义了），而应该在遗留单体中为单体库建立一系列<strong>数据库包装服务</strong>，来提供对单体数据库的读写访问。我们把这类API称为<strong>数据API</strong>。</p><p><img src=\"https://static001.geekbang.org/resource/image/bd/00/bdce4cbdb4a23da323cc729dd2686700.jpg?wh=1920x1357\" alt=\"图片\"></p><p>尽管某种程度上来说数据API只是一个壳子，它还是会调用已有的旧代码去修改数据，不过双向CDC或双写的方式显然也增加了不少团队认知负载。我们再想想看，还有没有更简单的方法呢？</p><p>当然是有的，但这些方案都存在一定的局限性，需要根据项目实际情况来选择，我们一起来看一下后面这两种方案。</p><p>1.如果拆分出来的服务是<strong>只读</strong>的，我们可以在单体库中为相关的表创建<strong>视图</strong>，让新服务直接访问这些视图。当所有API改造完成之后，我们再根据这些视图，在新库中创建数据表，将数据一次性迁移到这些表中。</p><p>2.如果数据库是像Oracle这种包含类似DBLink技术的，我们可以在新库中创建同义词，通过DBLink指向旧库中的表，这样无论是读写都可以正常完成。当所有API改造完成后，我们根据所创建的同义词，在新库中创建表并迁移数据。</p><p><img src=\"https://static001.geekbang.org/resource/image/f5/07/f566b0374118bba3c39a9c0fab918607.jpg?wh=1990x1230\" alt=\"\"></p><p>上述两种方案可能看起来都不是特别完美，相当于一个微服务通过某种方式，访问了它不应该访问的数据库。但不要忘了，这只是改造过程中的中间步骤。</p><p>当全部改造完成后，这种临时的基础设施（视图或同义词）就会被删除，所以完全不必纠结。另外，这样简单的方式，能让我们比较容易地获取原单体库中的数据，是符合“<strong>以降低认知负载为前提</strong>”这个原则的。</p><p>在这个案例中，虽然核保服务对于核保数据既包含读取，也包含写入，不能使用视图的方式，但由于数据库是Oracle，我们可以使用同义词的方式来实现双向同步。</p><p>建立好回退和数据同步机制之后，就可以逐个API做改造了。虽然我们已经通过战术分叉，将核保模块从单体中复制了一份到新的核保服务中，但核保服务中的代码还是对原单体有着很强的依赖。我们需要将各个API逐一改造，解除对于非核保代码的依赖。</p><h2>用API调用取代代码依赖</h2><p>我们先来看这样的一段位于核保服务中的代码。这里说明一下，为了聚焦于主要的问题，我对代码进行了大量的精简，实际遗留系统中的代码很可能比这要复杂很多，但解决思路是一致的。后面出现的代码也是如此。</p><pre><code class=\"language-java\">// 核保服务中的代码 - UnderwriteApplicationService.java\npublic UnderwriteApplicationDto getUnderwriteApplication(long policyId) {\n  UnderwriteApplicationDao underwriteApplicationDao = new UnderwriteApplicationDao();\n  UnderwriteApplicationModel underwriteApplicationModel = underwriteApplicationDao.getUnderwriteApplication(policyId);\n  PolicyDao policyDao = new PolicyDao();\n  PolicyModel policyModel = policyDao.getPolicy(policyId);\n  return getUnderwriteApplicationDto(underwriteApplicationModel, policyModel);\n}\n</code></pre><p>这段代码先通过UnderwriteApplicationDao获取核保申请数据（核保申请就是指一个正处于核保过程中的保单），然后通过PolicyDao获取保单数据，之后将这两个数据进行整合，得到我们想要返回的DTO。</p><p>可以看到，前面这段代码虽然位于核保服务中，但除了依赖了核保服务中的代码（即获取核保申请）之外，还依赖了本应属于单体中的代码（即获取保单），这就是我们在拆分的过程中会遇到的最典型的代码耦合，只有把这些耦合点全部解除，新的核保服务才能彻底摆脱对于单体的二进制依赖。因此下一步我们要做的就是把对于获取保单代码的依赖进行解耦。</p><p>我们的解决方案非常的简单直观。简单总结就是三步走：</p><p>1.调自己；</p><p>2.调服务；</p><p>3.组数据。</p><p><img src=\"https://static001.geekbang.org/resource/image/8c/db/8c56234086125ce90d29f755c87e2bdb.jpg?wh=1920x1263\" alt=\"图片\"></p><p>我们首先让核保服务调用自己的数据库拿到核保申请数据。然后在单体中创建一个新的API，让它返回保单数据，在核保服务中的防腐层（ACL）中调用这个API，拿到保单数据。最后，在原来的代码处对两部分数据进行组合。由于这个新建的API也是为了给核保服务提供数据，我们仍然将其称为数据API。</p><p>改造后的代码类似下面这种：</p><pre><code class=\"language-java\">// 核保服务中的代码 - UnderwriteApplicationService.java\npublic UnderwriteApplicationDto getUnderwriteApplication(long policyId) {\n  UnderwriteApplicationDao underwriteApplicationDao = new UnderwriteApplicationDao();\n  UnderwriteApplicationModel underwriteApplicationModel = underwriteApplicationDao.getUnderwriteApplication(policyId);\n  // 核保服务中的防腐层，调用单体中的API来获取保单信息\n  PolicyServiceProvider policyServiceProvider = new PolicyServiceProvider();\n  PolicyModel policyModel = policyServiceProvider.getPolicy(policyId);\n  return getUnderwriteApplicationDto(underwriteApplication, policyModel);\n}\n\n// 核保服务中的防腐层 - PolicyServiceProvider.java\npublic PolicyModel getPolicy(long policyId) {\n  MonolithApiClient apiClient = new MonolithApiClient();\n  PolicyDto policyDto = apiClient.getPolicy(policyId);\n  return convertToPolicyModel(policyDto);\n}\n\n// 单体服务中的新API - PolicyController.java\npublic PolicyDto getPolicy(long policyId) {\n  PolicyDao policyDao = new PolicyDao();\n  PolicyModel policyModel = policyDao.getPolicy(policyId);\n  return convertToPolicyDto(policyModel);\n}\n</code></pre><p>有同学可能会问，为什么要建立这样一个防腐层呢？直接在原来的位置调用API不行吗？这样做不是多此一举吗？</p><p>我们在这里添加防腐层的主要目的，其实是为了解除对于API调用部分的依赖，并对获取到的数据进行转换，从用于数据传输的DTO，转回我们代码处所需要的Model。这样的防腐层可以有效防止业务代码的腐坏，把会发生变动的部分隔离在外面。</p><p>你可能还会问，上面的代码有很多坏味道（比如一些命名的问题和可测试性的问题），为什么不重构？答案是因为要分离关注点。我们现在关注的是架构解耦，并不是代码重构。一旦因为重构导致当前改造的范围扩大，就无法完成既定的交付目标了。</p><p>你可能还想到一个问题，就是这里是否可以使用<strong>抽象分支</strong>来进行增量重构，即将UnderwriteApplicationService提取成一个接口，将原来的类作为旧实现，再写一个新实现来解耦。</p><p>其实是没有必要的。因为我们在最上层已经通过特性开关来实现了这个“分支”，就没有必要在代码级别再使用抽象分支了。也就是说，我们使用了<strong>绞杀植物模式</strong>用服务替换旧模块，代码已经复制出来一份了，在复制出来的这部分中，就没必要再使用<strong>修缮者模式</strong>了。</p><h2>小结</h2><p>总结一下今天的课程。基于上节课的单体系统，我们开始着手拆分代码，不过这节课只前进了一小步，后面还有三节课的内容等着你。但今天这一小步却十分重要，因为“反向代理”和“数据同步”是后面几节课的基础，微服务拆分的方方面面都离不开这两个实践。</p><p>如果你的数据库是Oracle，强烈建议你使用基于DBLink的同义词来进行“数据同步”。</p><p>其实严格来说，这并不算是同步，而只是一种转换，但它可以让你暂时不用考虑数据的问题，降低了认知负载的同时，还能帮你梳理数据的所有权。等代码解耦完成，你会发现，在核保库中所创建的同义词，都是需要拆分到核保库中的数据表。</p><p>除此之外，我还分享了“用API取代代码依赖”，这也是比较基础的一个实践，是代码解耦的基本方法。后面的课程里要讲的数据访问解耦、存储过程解耦等，都使用了和这个实践类似的方法。</p><h2>思考题</h2><p>感谢你学完了今天的课程，今天的思考题我在文中已经给出了。也就是在通过开关进行反向代理的时候，为什么要将当前的ServletRequest做一下转换，再转发给核保服务呢？为什么不能直接调用request.sendRedirect方法直接转发呢？</p><p>欢迎你在留言区跟我交流互动，也推荐你把今天的内容分享给更多同事、朋友，我们一起来拆分单体。</p>","neighbors":{"left":{"article_title":"20｜启动：如何开启一个遗留系统现代化项目？","id":521807},"right":{"article_title":"22｜微服务拆分（二）：三招搞定数据库表解耦","id":523160}}},{"article_id":523160,"article_title":"22｜微服务拆分（二）：三招搞定数据库表解耦","article_content":"<p>你好，我是姚琪琳。</p><p>上节课，我们学习了微服务拆分之初，需要搭建好的两个基础设施，一个是基于开关的反向代理，另一个是数据同步机制。有了这两个设施做保障，接下来就可以大刀阔斧地一一拆解了。</p><p>除此之外，我们还讲了如何用API来取代代码依赖。你可能已经发现了，这个实践与其说是解决了对于单体代码的依赖，不如说是解决了对于单体数据库的依赖。</p><p>诚然，对于保险系统以及大多数这种数据密集型系统来说，所有的操作最终都将体现到数据库上。在这类系统的改造过程中，最不好解决的问题莫过于数据库表的解耦了。</p><p>这种面向数据库编程在21世纪初的国内是十分流行的，像Delphi、VB等都提供了很方便的数据库连接组件，而PowerBuilder更是推出了可以直连数据库的DataWindow，将数据的访问和展示耦合在了一起。</p><p>在这样的大背景下，将所有逻辑都放在客户端组件的Smart UI模式，以及将业务逻辑和数据访问逻辑混杂的“事务脚本模式”为什么如此流行，也就不难理解了。然而随着业务的发展，这种模式的弊病也越来越明显，很多团队都意识到了这个问题并着手解决。但在遗留系统中，这样的代码还是随处可见。</p><p>在微服务拆分的过程中，如何界定数据库表的所有权，进而拆分给不同的服务，就成了最为棘手的工作。这节课我们一起继续探索遗留系统的改造实践，按照从易到难的顺序，分别学习三种行之有效的方法，帮你搞定数据库表的解耦。</p><!-- [[[read_end]]] --><h2>第一招：用API调用取代连表查询</h2><p>在<a href=\"https://time.geekbang.org/column/article/522486\">上一节课</a>的代码示例中，我们分别用PolicyDao和UnderwriteApplicationDao去查询保单和核保申请数据，再组合成我们需要的核保申请数据并返回。</p><p>然而，在大多数遗留系统中，模块对于数据的所有权边界往往是很模糊的，也就是说，在任何模块中都可以随意访问本属于其他模块的数据。</p><p>所以，对于这样的代码，真实情况往往是这样：使用一个连表查询，一次性查出所有想要的数据。</p><pre><code class=\"language-java\">// 核保服务中的代码 - UnderwriteApplicationService.java\npublic UnderwriteApplicationDto getUnderwriteApplication(long policyId) {\n  UnderwriteApplicationDao underwriteApplicationDao = new UnderwriteApplicationDao();\n  UnderwriteApplicationModel underwriteApplicationModel = underwriteApplicationDao.getUnderwriteApplication(policyId);\n  return getUnderwriteApplicationDto(underwriteApplicationModel);\n}\n\n// 核保服务中的代码 - UnderwriteApplicationDao.java\npublic UnderwriteApplicationModel getUnderwriteApplication(long policyId) {\n  String sql = \"SELECT * FROM TBL_UNDERWRITE_APPLICATION UC, TBL_POLICY P WHERE UC.POLICY_ID = P.ID AND P.ID = :policyId\";\n  return executeSqlAndConvertToUnderwriteApplicationModel(sql, policyId);\n}\n</code></pre><p>注意，我们忽略了具体的执行SQL语句的框架，它可能直接使用了JDBC，也可能使用了MyBatis，这并不是重点。重点是如何拆分这样一个SQL语句。</p><p>在这条SQL语句中，TBL_UNDERWRITE_APPLICATION是指核保申请所对应的表，显然它应该属于核保数据库，而TBL_POLICY是保单所对应的表，应该留在单体库中。</p><p>怎么拆分呢？其实要拆分这样的连表查询并不难，我们的方案和上节课处理代码依赖问题采用的方法类似，也是通过API的方式来替换。</p><p><img src=\"https://static001.geekbang.org/resource/image/8c/db/8c56234086125ce90d29f755c87e2bdb.jpg?wh=1920x1263\" alt=\"图片\"></p><p>具体来说仍然是三步走，即调自己、调服务、组数据。最终的代码也几乎与解决代码依赖的方案一样，这里就不重复说了，你可以回顾第二十一节课。</p><p>用API调用取代连表查询和上节课的用API调用取代代码依赖，都用到了两种前面学到的模式，分别是改造老城区的<strong>变更数据所有权模式</strong>，和建设新城区中的<strong>数据库包装服务模式</strong>。</p><p>在核保服务和单体服务的分权之争中，开发人员作为裁判做了这样一件事儿：把保单数据的访问功能从核保服务那里剥离出来，核保服务不再拥有这部分数据的所有权，而是转给单体服务。</p><p>当然了，在现阶段拆分出来的数据，会暂且放在统一的数据API中，至于到底划到单体中哪个模块，不是我们现阶段应该关注的。这里为了变更数据所有权，我们采用把数据库封装为API的方式。获取保单数据的API仅仅是个提供数据库数据的接口，不包含任何业务逻辑。</p><p>到这里，简单的数据解耦我们就能轻松应对了。但遗留系统的代码千奇百怪，各种数据库表的连表查询更是百怪千奇，接下来咱们就来迎战更高难的复杂查询。</p><h2>第二招：为复杂查询建立单独的数据库</h2><p>下面这张图是我从一个真实的遗留系统中提取出来的SQL语句，我对具体的内容做了模糊处理，但重要的是了解它的长度和复杂度。</p><p><img src=\"https://static001.geekbang.org/resource/image/51/9e/51e1ea23177d429d794a75d736d7b29e.jpg?wh=1920x3324\" alt=\"图片\"></p><p>这种复杂查询在遗留系统中屡见不鲜，我甚至在有的项目中遇到过需要十几张A4纸才能完整打印的SQL语句。</p><p>如果非要硬来，对上面这种复杂SQL也用API调用来替换，那成本和风险都是相当高的，而且有些甚至是做不到的。比如有些查询会把分页逻辑也写在SQL语句里，但如果WHERE条件中包含单体服务中的表，把这个依赖转换成API查询，然后在内存中再去过滤，分页就会乱掉。</p><p>那么对于类似这样的复杂查询应该如何处理呢？你可以针对这样的查询，提取一个单独的查询数据库出来。</p><p><img src=\"https://static001.geekbang.org/resource/image/70/20/70f66ee0ccf812282b18yy7fa1382f20.jpg?wh=1920x1260\" alt=\"图片\"></p><p>我们新建一个独立的数据库，把核保和单体数据库中的数据都同步到这个数据库中，核保服务可以直接连接到该库中进行查询操作。由于该库包含了查询所需的全部表，因此SQL语句甚至不需要做任何修改，只需要区分查询和修改数据库的连接地址就可以了。</p><p>这样在一定程度上还实现了<strong>读写分离</strong>。在未来剥离单体服务中对于核保表的依赖时，也可以让单体服务访问查询数据库。以后再从单体中继续剥离其他服务时，也同样可以复用这个库，可谓一举多得。</p><p>有同学可能会问，多个微服务共享一个数据库，这不是典型的反模式吗？注意这里我们共享的并不是业务数据，而是查询数据，是只读的。它并不需要独立演进。</p><p>比如如果单体库独立进行了修改，并且不需要让核保服务知道，查询库就不需要跟着修改，反之亦然。而如果单体库的修改需要通知核保服务做出相应的修改，可能就需要同时修改查询库，并且重新部署，这也是很正常的情况，因为反正都需要重新部署核保服务。</p><p>最重要的是，我们通过新的、单独的查询数据库，极大地降低了认知负载，再也不需要去修改复杂的SQL语句了。回顾一下第十五节课的内容，这其实就是<strong>报表数据库模式</strong>。</p><h2>第三招：冗余数据</h2><p>除了单独的查询数据库，还有一种方式是将复杂查询所用到的数据，都冗余到核保库中。这样，复杂SQL仍然不需要做修改，改造的成本也非常低。</p><p><img src=\"https://static001.geekbang.org/resource/image/13/e0/132f74cc8a437d3d47e3ac78cca2dbe0.jpg?wh=1920x1303\" alt=\"图片\"></p><p>都有哪些数据需要冗余到核保服务中呢？表面上看，是核保服务中，所有查询SQL中所涉及到的表和字段的并集。不过实际上，我们应该先把这些表和字段分类，对不同的类别采取不同的处理策略。</p><h3>快照数据的冗余</h3><p><strong>第一种类型是快照数据</strong>。快照数据是指那些只关心数据当时的状态，而不关心数据后续变化的场景。我们可以把这类数据存储（或缓存）在消费端，一方面需要这些数据的时候就不需要远程获取了，提升了性能，另一方面当远程服务宕机的时候，也不至于影响消费端服务。</p><p>关于这类数据，我们最常见的就是微信头像更新。你一定发现了，在点击好友头像的时候会更新一下头像，平时我们看到的都是他以前用的头像，这个头像就是本地存储的一个快照。</p><p>平时我们聊天和视频，头像是否是最新的我们并不关心，等到点击头像的时候再更新，我们也不会觉得有啥问题。相反，如果一定要保持头像的实时更新，对每一个手机客户端来说，都是非常严重的资源消耗。</p><p>遗留系统中其实也存在类似的数据。比如每个核保申请都有一个核保员对其进行核保。假设某个核保员叫张三，后来改名为李四，我们是希望由他核保的历史核保申请信息上，显示的仍然是张三，还是改名后的李四呢？如果仍然可以显示张三，那么我们就说核保申请上的核保员姓名这个信息，可以存储为快照数据。</p><p>按照大多数遗留系统的设计，核保申请表上存储的就是员工表的主键。当员工（核保员也是员工，因此信息存储在员工表里）改名后，连表查出来的员工姓名肯定会发生改变。我们在做服务拆分的时候，可以用API调用来取代这个连表查询，从而得到员工的新姓名。</p><p>但当查询极其复杂，无法用API调用来取代的时候，你就可以回过头来想想，某个核保申请上的核保员姓名，是否必须是最新的，是否可以仅存一份快照数据而没必要更新。</p><p>冗余数据放在哪？我们有两种处理方法。</p><p>第一种方法是冗余到主表上。比如核保申请表上本来存储的是员工主键，现在可以增加一列姓名。在创建核保申请时，同时插入员工的主键和姓名。在查询时，不通过员工主键连表查询员工表，而是直接查出姓名。采取这种方法时，需要对原有SQL进行少量修改。</p><p>第二种方式是冗余到新表中。有时候要冗余的某张表的字段会很多，比如除了员工姓名，可能还需要员工号、员工级别、员工所在分公司等。</p><p>除此之外，还包括申请核保的员工信息、保单的投保人信息、被保人信息等等。如果这些字段都冗余到主表，就会喧宾夺主，关注点不聚焦。因此我们可以把这些字段分别冗余到不同的新表中。</p><p><img src=\"https://static001.geekbang.org/resource/image/50/9b/500da652ddc9b91a6e85c3a6d1d36d9b.jpg?wh=1920x829\" alt=\"图片\"></p><p>值得注意的是，新表的名称应该根据业务去命名，而不能跟原表的名称一样。像申请人、核保员都来自原来的员工表，我们没有办法在核保库中建一个员工表，来解决这两份数据的快照。</p><p>因此我们要建一张核保申请人表，一张核保申请核保员表，分别来存储申请人和核保员的快照数据。在快照表中，不再像原表那样以员工ID为主键，而应该以核保表的主键为主键，将原来的一对多关系改为一对一。采取这种方法时，原有SQL的改动就更少了，可能只需要改一下表名。</p><h3>业务数据的冗余</h3><p><strong>第二种需要冗余的数据是业务数据</strong>。业务数据与快照数据不同，它的变化会影响到当前业务，因此不能按快照进行冗余。比如被保人的年龄在申请的时候填错了，进行了修改，如果还是以快照数据来存储，在核保服务中就无法得到新的年龄，就会得出不同的核保结论。</p><p>因此对于冗余到核保库中的业务数据，必须进行同步，以得到最新值。同步方式可以参见第二十一节课的内容。</p><p>在实际项目中，必须与业务人员一起讨论哪些数据是快照数据，哪些数据是业务数据。这一点开发人员是决定不了的，必须由业务人员来决定，但开发人员可以给出一些建议。比如业务人员在得知要将核保员姓名改成快照的时候，他们和开发人员之间很可能会发生这样的对话：</p><p>业务人员：系统使用了很多年，都是随时可以查出最新的核保员姓名，这么改不符合业务（注意这里可能并不是真正的业务，而是软件系统培养出来的操作习惯，开发人员要善于捕捉这一点）。</p><p>开发人员：那我们想想在纸质办公时代，核保员就是在核保申请上签个字或盖个章，证明是他操作的核保申请。这个签章其实就是快照，他当时叫什么名字，签章就是什么名字，以后改名了当时的签章也不会变了，不是吗？</p><p>业务人员若有所思：……</p><p>开发人员趁热打铁：所以快照才是真正符合业务的，对吗？</p><p>业务人员：纸质时代签名盖章很可能是无奈之举，我们引入软件系统不就是为了带来这些便利吗？而且像报表之类的功能，比如按核保员名称去查询他所核保的所有核保申请，如果改名了就查不出来了，会非常不方便。</p><p>开发人员：您说的很有道理，报表这里我们会特殊处理以满足功能，但是在当前这个复杂查询的场景里，我们是否可以只查出当时的快照呢？</p><p>业务人员：可以吧……</p><p>这当然是一个假想的偏理想化的对话情景，真实的情况下要想说服业务人员可能相当困难，因为看问题的视角不同。但也是非常值得去尝试的，因为一旦存储成快照数据，的确会给服务拆分带来极大的便利，显著地降低认知负载。</p><p>注意，以上两种类型的数据，我们都只需要冗余我们用到的字段，不需要的字段就没必要冗余了。</p><p>在第一次创建主表数据（即核保申请）的时候，我们可以连带着把所要冗余的快照数据和业务数据，一起插入到核保库的相应表中。当业务数据发生变化的时候，再通过同步机制将其同步到核保库中。</p><h3>参考数据的冗余</h3><p><strong>第三种需要冗余的数据是参考数据</strong>，即Reference Data。参考数据是指那些对其他数据进行分类的数据，如国家的名称和缩写（如CHN、USA等）、机场的三字码（如PEK、DAX等）、货币代码（如CNY、USD等）。这些数据都是静态不变，或变化很慢的数据，因此也有人称之为静态数据。</p><p>在单体的遗留系统中，这类参考数据往往存储在单体的数据库或配置文件中，只有单体服务可以访问到。在从单体向外拆分微服务的时候，这类参考数据也是需要冗余的，否则拆分出来的服务就无法使用了。</p><p>不管参考数据存储在数据库还是配置文件中，我们都可以直接在新服务中也创建一份，直接使用即可。这是认知负载最低的解决方案。如果由于某种原因导致参考数据发生了变化，直接在两个库或配置文件中都进行修改就可以了，毕竟这种情况发生的概率很低，没有必要在它们之间建立同步机制。</p><p>当然更理想的方式是将参考数据加载到缓存中，供多个服务使用，这样就没有必要冗余了。如果遗留系统原来就是这么做的，当然可以直接复用。但如果不是，就没有必要非按照理想的方式来，毕竟这需要额外的工作量。</p><p>我们在遗留系统现代化的过程中，要切忌这种发散式的思维方式。本来目标是服务拆分，结果却引入了参考数据治理这个新的任务，导致工作不聚焦，工作范围扩大。</p><h2>小结</h2><p>今天的内容讲完了，我们做个总结。</p><p>我为你梳理了一张表格，对比了拆分查询SQL的三种方案，以及上面没有提到的一些优势和不足。你可以结合自己的实际需求，对照表格选择更合理的方案。</p><p><img src=\"https://static001.geekbang.org/resource/image/9c/f2/9cdaf73cd4072290b70336d2c6ec91f2.jpg?wh=1920x886\" alt=\"图片\"></p><p>上面我们介绍的解耦数据库表的方法都是基于查询的SQL，对于INSERT、UPDATE和DELETE的SQL，我们也可以用API调用来取代，这里就不详细介绍了。</p><h2>思考题</h2><p>感谢你学完了今天的课程，今天的思考题是这样的：假设我们要将员工信息冗余到核保服务的数据库中，以下两种方式各有哪些优缺点呢？他们所对应的SQL语句有什么区别？</p><p>方案一：</p><p>TBL_UNDERWRITE_APPLICATION（核保申请表）</p><p><img src=\"https://static001.geekbang.org/resource/image/9f/7d/9ffd7afd512559c6dea84323f7b8147d.jpg?wh=1920x698\" alt=\"图片\"></p><p>方案二：</p><p>TBL_UNDERWRITE_APPLICATION（核保申请表）</p><p><img src=\"https://static001.geekbang.org/resource/image/44/5d/44638231df64d762736bf1e22cca9b5d.jpg?wh=1920x847\" alt=\"图片\"></p><p>TBL_EMPLOYEE（员工表）</p><p><img src=\"https://static001.geekbang.org/resource/image/a3/0a/a3ee3113a531144651738824ccb7e00a.jpg?wh=1920x712\" alt=\"图片\"></p><p>欢迎你在留言区跟我交流互动。如果你身边有朋友遇到解耦数据库表的困惑，也推荐你把这节课分享给他。</p>","neighbors":{"left":{"article_title":"21｜微服务拆分（一）：迈出遗留系统现代化第一步","id":522486},"right":{"article_title":"23｜微服务拆分（三）：如何拆分存储过程？","id":523851}}},{"article_id":523851,"article_title":"23｜微服务拆分（三）：如何拆分存储过程？","article_content":"<p>你好，我是姚琪琳。</p><p>上节课我们学习了解耦数据库表的三种方法，单体架构拆分的挑战又下一城。</p><p>虽然在遗留系统中，用Java直接调用SQL语句十分常见，但真正的大Boss，是调用链很深的存储过程。</p><p>在十几二十年前，将业务逻辑写在数据库的存储过程或函数中是一种潮流。虽然这种潮流有着当时的历史背景，但在现在看来显然是“最差实践”了。如果遗留系统中存在大量的存储过程，该如何应对呢？我们今天就来学习这方面的内容。</p><h2>将存储过程或函数封装成API</h2><p>在遗留系统中，存储过程和函数往往用来封装复杂的业务逻辑。比如“审核核保申请”这样一个功能，可能会修改二十多张表。这里的表有的与核保相关，也有的与核保关系并不大，比如保单表。</p><p>然而用存储过程或函数来编写业务逻辑的风气一旦形成，很多简单的业务逻辑，比如对单张或少量表的修改，开发人员也会自然而然放到存储过程或函数里。</p><p>我曾经见过用数据库函数来比较时间前后关系的自定义函数，明明任何一门编程语言都提供了这种基本功能，但当时的开发人员却偏偏钟爱SQL，真的是难以理解。</p><p>这样一来，真正的代码反而变成了薄薄的一层胶水，真的是面向数据库编程啊。看到这你先别忙着叹气，我们一起理理思路，争取“分而治之”。</p><!-- [[[read_end]]] --><p>对于十分简单的存储过程或函数（如比较时间前后关系），我们可以将它们改造成代码。这个改造过程不会太难，我就不展开说了。</p><p>对于只涉及少量表的存储过程和函数，我们首先要分析它里面的表的所有权属于谁。主要分成三种情况。</p><ul>\n<li>\n<p>第一种情况：如果全都是与核保业务相关的表，就可以把整个存储过程或函数复制到核保库中，让核保服务的代码直接访问。</p>\n</li>\n<li>\n<p>第二种情况：如果全都是非核保业务相关的表，就可以<strong>将其封装为数据API</strong>，让核保服务调用，具体方式和步骤与上节课的第一招“用API调用取代连表查询”类似。</p>\n</li>\n<li>\n<p>第三种情况：如果既包含与核保业务相关的表，又包含不相关的表，就要先将其拆分成相关和不相关的两部分存储过程或函数，再分别应用上面两种处理方式来处理。</p>\n</li>\n</ul><p>在拆分存储过程和函数的时候，必然会涉及到一些修改。特别是拆分出来的多个存储过程或函数之间，会依赖彼此数据的情况。</p><p>比如下面这个与审核核保申请相关的存储过程（为了突出重点，我做了一定简化）：</p><pre><code class=\"language-sql\">PROCEDURE APPROVE_UNDERWRITE(I_UW_ID IN NUMBER) AS\n  V_UNDERWRITE_APPLICATION TBL_UNDERWRITE_APPLICATION%ROWTYPE;\nBEGIN\n  -- 更新核保申请表\n  UPDATE TBL_UNDERWRITE_APPLICATION \n    SET UNDERWRITE_STATUS = 2 \n        -- 其他字段赋值\n    WHERE UNDERWRITE_ID = I_UW_ID;\n  SELECT * INTO V_UNDERWRITE_APPLICATION WHERE UNDERWRITE_ID = I_UW_ID;\n  -- 更新保单表\n  UPDATE TBL_POLICY \n    SET POLICY_STATUS = V_UNDERWRITE_APPLICATION.POLICY_STATUS\n        -- 其他字段赋值\n    WHERE POLICY_ID = V_UNDERWRITE_APPLICATION.POLICY_ID\nEND APPROVE_UNDERWRITE;\n</code></pre><p>这段存储过程大体上可以拆分为两个阶段，第一个阶段是修改核保申请表，第二个阶段是用修改后的核保申请数据来更新保单表。如果存储过程中的SQL语句和方法一样，也存在代码交织、混乱不堪的情况，你可以复习一下<a href=\"https://time.geekbang.org/column/article/513599\">第九节课</a>讲的<strong>拆分阶段</strong>模式，它也可以应用到存储过程的重构中。</p><p>这个存储过程原本是位于单体数据库中的，我们要对其进行拆分，就要将访问核保表的部分迁移到核保库中：</p><pre><code class=\"language-sql\">-- 核保库中新增的存储过程\nPROCEDURE APPROVE_UNDERWRITE(I_UW_ID IN NUMBER) AS\nBEGIN\n  UPDATE TBL_UNDERWRITE_APPLICATION\n    SET UNDERWRITE_STATUS = 2 \n        -- 其他字段赋值\n    WHERE UNDERWRITE_ID = I_UW_ID;\nEND APPROVE_UNDERWRITE;\n</code></pre><p>但是在原存储过程中就不能直接查询核保申请表了，需要对它进行改写，在调用该存储过程的地方通过API获得核保申请数据，然后再将核保申请数据作为参数传递给这个存储过程。如果数据库支持PL/SQL，我们可以<strong>引入对象类型来进行参数传递</strong>。</p><pre><code class=\"language-sql\">-- 新建的对象类型\nCREATE OR REPLACE TYPE OBJ_UNDERWRITE_APPLICATION AS OBJECT\n(\n  UNDERWRITE_ID NUMBER, POLICY_ID NUMBER, UNDERWRITE_STATUS VARCHAR2(1), -- 其他字段\n  CONSTRUCTOR FUNCTION OBJ_UNDERWRITE_APPLICATION RETURN SELF AS RESULT,\n  CONSTRUCTOR FUNCTION OBJ_UNDERWRITE_APPLICATION(POLICY_ID IN NUMBER, POLICY_ID IN NUMBER, UNDERWRITE_STATUS IN VARCHAR2) RETURN SELF AS RESULT\n);\n-- 单体库中复制出来的原存储过程修改之后\nPROCEDURE APPROVE_UNDERWRITE(V_UNDERWRITE_APPLICATION AS OBJ_UNDERWRITE_APPLICATION)) AS\nBEGIN\n  UPDATE TBL_POLICY \n    SET POLICY_STATUS = V_UNDERWRITE_APPLICATION.POLICY_STATUS\n        -- 其他字段赋值\n    WHERE POLICY_ID = V_UNDERWRITE_APPLICATION.POLICY_ID\nEND APPROVE_UNDERWRITE;\n</code></pre><p>别忘了，我们要把原来的存储过程复制一份出来，不能在原存储过程上直接修改，否则就无法回退了。</p><p>这样一来，调用这个存储过程的代码就变成了这样：</p><pre><code class=\"language-java\">-- 调用上面存储过程的Java代码\nObject[] underwriteApplicationFields = new Object[] { underwriteApplicationDto.getPolicyId(), /*...*/ };\nConnection connection = getConnection();\n-- 在Java中，与对象类型对应的是Struct\nStruct underwriteApplicationStruct = connection.createStruct(\"OBJ_UNDERWRITE_APPLICATION\", underwriteApplicationFields);\nStatement statement = connection.prepareCall(\"{ CALL APPROVE_UNDERWRITE(:underwriteApplication) }\");\nstatement.setObject(\"underwriteApplication\", underwriteApplicationStruct);\nstatement.execute();\n</code></pre><p>以上存储过程我们都可以先在单体数据库中实现，然后在核保库中建立同义词，来访问单体库中的存储过程。</p><p>对于表很少的简单情况，还算比较好拆分。当表又多，关系又错综复杂的时候，就比较棘手了。我们接下来就看看这种情况如何应对。</p><h2>拆分复杂存储过程或函数</h2><p>遗留系统中的存储过程和函数往往是很复杂的，有的时候会涉及到几十甚至上百张表也不为过。我们分情况讨论一下要如何进行拆分。</p><p><strong>第一种情况是SQL的执行彼此之间没有前后顺序关系</strong>。有些存储过程和函数虽然也涉及到很多表，但实际上它们的执行顺序是可以调换的，彼此之间没有依赖关系，先执行谁后执行谁不会影响最终的结果。</p><p>这时候只需要完成下面四步即可：</p><p>1.调整SQL的执行顺序，按数据的所有权进行分组，也就是将涉及单体库表的和涉及核保库表的SQL语句分组；</p><p>2.从与单体库表相关的SQL语句中，提取出一个新的存储过程或函数，并封装成数据API；</p><p>3.在核保服务的防腐层代码中，分别调用数据API和只包含核保库表的那个存储过程或函数（因为它们的执行顺序无关，所以这里调用的前后顺序也无所谓）；</p><p>4.如果涉及到参数传递，就引入对象类型。</p><p><img src=\"https://static001.geekbang.org/resource/image/13/88/132fe02eb69aacf6c5c4518b79b83c88.jpg?wh=1920x1093\" alt=\"图片\"></p><p>我们仍然拿审核核保申请的存储过程举例，假设它由以下三个子存储过程组成，各个子存储过程之间没有先后顺序：</p><pre><code class=\"language-sql\">PROCEDURE APPROVE_UNDERWRITE(I_UW_ID IN NUMBER) AS\n  V_POLICY_ID NUMBER;\nBEGIN\n  UPDATE_POLICY_FOR_APPROVAL(I_UW_ID);\n  SELECT POLICY_ID INTO V_POLICY_ID FROM TBL_UNDERWRITE_APPLICATION WHERE UNDERWRITE_ID = I_UW_ID;\n  UPDATE_UNDERWRITE_APPLICATION_FOR_APPROVAL(V_POLICY_ID);\n  UPDATE_POLICY_PRODUCT_FOR_APPROVAL(V_POLICY_ID);\nEND APPROVE_UNDERWRITE;\n</code></pre><p>按上面的步骤改写完之后就变成了两个，分别位于单体和核保的数据库中：</p><pre><code class=\"language-sql\">-- 单体库中的存储过程\nPROCEDURE APPROVE_UNDERWRITE(I_POLICY_ID IN NUMBER) AS\nBEGIN\n  UPDATE_POLICY_FOR_APPROVAL(I_POLICY_ID);\n  UPDATE_POLICY_PRODUCT_FOR_APPROVAL(I_POLICY_ID);\nEND FINISH_UNDERWRITE;\n-- 核保库中的存储过程\nPROCEDURE APPROVE_UNDERWRITE(I_UW_ID IN NUMBER) AS\nBEGIN\n  UPDATE_UNDERWRITE_APPLICATION_FOR_APPROVAL(I_UW_ID);\nEND FINISH_UNDERWRITE;\n</code></pre><p>而核保中的原API就改为了先执行核保内的存储过程，再通过API来调用单体库中的存储过程：</p><pre><code class=\"language-java\">public void approveUnderwrite(long underwriteId) {\n  // 调用本地存储过程\n  Connection connection = getConnection();\n  Statement statement = connection.prepareCall(\"{ CALL APPROVE_UNDERWRITE(:underwriteId) }\");\n  statement.setLong(\"underwriteId\", underwriteId);\n  statement.execute();\n  // 通过API调用远程存储过程\n  PolicyServiceProvider policyService = new PolicyServiceProvider();\n  policyService.approveUnderwrite(underwriteId);\n}\n</code></pre><p><strong>第二种情况是SQL的执行有前后顺序关系</strong>，比如后面的SQL会依赖到前面SQL的执行结果。这个时候就相当麻烦，并没有好的解决方案，只能按照下面这样的顺序拆分：</p><p>1.将众多SQL按数据的所有权拆分成一组一组的小块，每一小块的内部是顺序无关的；</p><p>2.将这些小块抽取成不同的存储过程或函数；</p><p>3.将属于单体库的存储过程或函数逐一封装成数据API，将属于核保库的存储过程或函数复制到核保库中；</p><p>4.然后再按照原存储过程或函数内部的顺序，在核保服务的防腐层代码中去逐个调用这些API和属于核保库的存储过程或函数；</p><p>5.如果涉及到参数传递，就引入对象类型。</p><p><img src=\"https://static001.geekbang.org/resource/image/07/ee/07b2def89ec817714e0cac6d5779bbee.jpg?wh=1920x1043\" alt=\"图片\"></p><p>对于复杂的存储过程和函数除了拆分本身的工作量外，最重要的就是要确定它们之间的相互依赖关系。对于这一点，并没有非常好的方法，只能耐心加细心。</p><h2>用重试来取代回滚</h2><p>在前面介绍的诸多实践中，我们把大量的SQL语句转换成了API调用。表面上看，它们的执行结果是相同的，但实质上我们已经把很多事务性的操作，转换成了非事务性的。比如在审核核保申请时，本来我们是在一个数据库事务中，修改核保申请表和保单表，任何一个修改失败都会导致整个操作的回滚。</p><p>但这样的修改在解决老问题的同时，也会给我们带来新问题：当把对保单表的修改替换成远程API调用后，情况就变得复杂起来。</p><p>在代码直接修改完毕后，如果我们不做任何调整，原来的事务所包裹的除了执行SQL的代码之外，还包括了调用远程API的代码。这是应该避免的。因为远程API的调用相对来说是不稳定的，有可能耗时过长，也有可能执行成功了，但由于网络问题返回了错误的响应。前者会导致长事务，后者会导致错误的回滚。这时我们就要把调用API的代码从事务中挪出来。</p><p>但这样虽然解决了长事务的问题，回滚又变得麻烦了。如果API调用真的失败了，需要回滚前面的SQL，我们可以编写一个补偿性的SQL来对冲它。但如果API调用是假失败，该怎么处理呢？有的时候，我们甚至无从知道到底是真失败还是假失败。</p><p>作为聪明的开发者，实在解不出答案的时候，我们可以尝试直接“改题目”，也就是回溯问题本身（遵循第一性原理），看看能不能换道题解答。要解决在远程调用失败的情况下本地SQL的回滚问题，不如重新思考一下，这两步操作是否必须在一个事务下？</p><p>单体系统中的代码为了方便，很多有关、无关的批量SQL操作，都会无脑地放入一个事务中，靠数据库提供的提交和回滚功能来进行流程控制。但这些批量操作是否在业务上必须是事务的，恐怕没有人去深究。我们在改造这样的代码时，不妨来把这一课补上，以方便拆分事务。</p><p>还拿审核核保申请这个功能来举例。在修改了核保申请的状态后，要在保单表中也回写一个状态，以前这两步操作位于同一个事务中。但仔细思考并且与业务人员讨论后，我们就会发现，保单表状态是否写入成功，不应该影响当前核保申请的正常核保业务。</p><p>假想一下在线下操作中可能发生的场景：核保员在审核完核保申请之后，在核保申请上填上核保意见、日期并签字盖章，然后在投保单上填上核保意见、日期并签字盖章。我能因为签投保单时笔没水了，就把刚签完的投保单撤销吗？这显然是荒谬的。</p><p>事实上只有在DDD的一个限界上下文内，操作才应该是事务性的。跨限界上下文的调用，都不应该是事务性的，否则就说明限界上下文的划分有问题。在进行微服务拆分之前，既然我们已经把核保作为一个限界上下文了，就说明它与单体的交互就不应该再具有事务性了。</p><p>我们可以选择当API调用失败之后，不管是真失败还是假失败，都可以采取不断重试的方式保证数据的最终一致性。不过这时要注意的一个问题是，<strong>需要重试的API本身必须是幂等的</strong>，即多次重复调用后产生的结果是一致的。否则，多次重试后产生了多个结果，就会造成数据错误。</p><p>如果讨论之后，业务人员还是认为应该保证数据的实时性和一致性，并且限界上下文的划分在大多数情况下也是合理的，这时候就不得不引入分布式事务来解决了。关于分布式事务，极客时间上有很多相关课程，你可以自行拓展学习。但值得说一句的是，分布式事务的解决方案会给整体拆分过程带来极大的认知负载，不到万不得已，不建议采用。</p><p>通过前面的课程，你一定已经清楚了，<strong>将代码依赖或数据依赖改为API依赖，是我们进行服务拆分的最基本手段</strong>。然而API调用有时又会带来新的问题，接下来我就分享两个实践，帮你避免这些问题。</p><h2>用批量API取代单次API</h2><p>在遗留系统中，可能存在下面这样的循环：</p><pre><code class=\"language-java\">for(long productId : request.getSelectedProductIds()) {\n  ProductDao productDao = new ProductDao();\n  ProductModel product = productDao.getProductById(productId);\n  // 针对单个险种给出核保结论\n  // ...\n}\n</code></pre><p>如果直接使用API调用取代代码依赖这个实践，将会得到这样的代码：</p><pre><code class=\"language-java\">for(long productId : request.getSelectedProductIds()) {\n  ProductServiceProvider productServiceProvider = new ProductServiceProvider();\n  ProductModel product = productServiceProvider.getProductById(productId);\n  // 针对单个险种给出核保结论\n  // ...\n}\n</code></pre><p>这段代码功能上没有任何问题，但会导致潜在的性能问题，因为它在一个循环内部多次调用了同一个API，列表中的元素越多，API调用就越多。</p><p>有的时候我们这么做只是为了复用已有的API（比如这个ProductServiceProvider.getProductById），或者说为了尽量少地在遗留系统中添加新的API，或者就是单纯的没有在code review的时候发现问题。这样的代码一旦上线，就很难复查，直到发现性能问题。</p><p>这时候我们需要增加一个新的批量API，一次性查询出所有后续要用到的对象，然后再进入循环中去逐个处理：</p><pre><code class=\"language-java\">ProductServiceProvider productServiceProvider = new ProductServiceProvider();\nList&lt;ProductModel&gt; products = productServiceProvider.getProducts(request.getSelectedProductIds());\nfor(ProductModel product : products) {\n  // 针对单个险种给出核保结论\n  // ...\n}\n</code></pre><p>用这种批量的API来取代单次的API，可以很容易地解决性能问题。</p><h2>将同步API调用改为异步事件</h2><p>之前我们说了，用同步的API调用来取代代码依赖或数据库表依赖，会对性能造成一定影响，特别是依赖较复杂需要改成多次API调用的情况。而且当API调用失败时，用代码实现的重试机制也不够灵活。这里我向你推荐一种在分布式系统中常见的解决方案，也就是事件机制。</p><p>前面课程里我们讲过事件实现数据同步有时候是不现实的，因为遗留系统中的事件缺得太多，无法满足数据同步的要求。但是用事件来实现异步调用，还是可以胜任的。</p><p>我们将调用API的地方改为抛出一个事件，发送到消息中间件上，然后在消费端消费这个事件，从而完成原本由API完成的工作。</p><p><img src=\"https://static001.geekbang.org/resource/image/f0/1a/f0c8a81ce5621585b57f72fc1e38yy1a.jpg?wh=1920x1233\" alt=\"图片\"></p><h2></h2><h2>小结</h2><p>总结一下今天的内容，我们学习了如何拆分存储过程和函数，总体思路还是转换成API调用，但对于过于复杂的场景，转换成API调用的工作也并不轻松。此外，我还分享了一些数据拆分时的小技巧，包括以重试的方式来代替回滚操作、用批量API来取代单次API的循环调用，以及用异步事件来取代同步API。</p><p>有些时候存储过程过于复杂，你可能考虑把它们转换成Java代码。我劝你一定要慎重。并不是说不能这么做，只是这样做的认知负载仍然是相当高的，你应该根据实际情况，先去寻找相对认知负载低的方案。</p><p>数据拆分是遗留系统拆分最复杂的部分，没有轻松的解决方案。而且不同的遗留系统现状也不同，需要具体问题具体分析。今天的课程只包含一些通用的方案，不过我们在实践中总结了一些针对特定场景的技巧，之后我将邀请我的同事以加餐的形式为你分享。</p><h2>思考题</h2><p>感谢你学完了今天的内容，今天的思考题是，对于复杂的存储过程拆分，你有没有其他思路？</p><p>期待你的分享，如果你觉得这节课对你有帮助，别忘了分享给你的同事和朋友，我们一起开始拆分存储过程。</p>","neighbors":{"left":{"article_title":"22｜微服务拆分（二）：三招搞定数据库表解耦","id":523160},"right":{"article_title":"24｜微服务拆分（四）：其他话题","id":524615}}},{"article_id":524615,"article_title":"24｜微服务拆分（四）：其他话题","article_content":"<p>你好，我是姚琪琳。</p><p>在前面三节课，我们分别讲解了如何拆分代码、数据库表和存储过程。可以说，掌握了这三个方向的拆分技巧，微服务拆分就不在话下了。不过除此之外，还有一些非常重要的点，如果不注意，会造成巨大的认知负载，影响拆分的进度。这些点包括：</p><ul>\n<li>微服务拆分和新业务需求如何兼顾？</li>\n<li>如何避免其他团队的改动影响我们的改造？</li>\n<li>一个API如果几个月还改不完怎么办？</li>\n<li>数据所有权拆分完成后，如何做数据迁移？</li>\n<li>……</li>\n</ul><p>这一讲，我们就来看看这些问题如何解决，权且看做是对前面三讲的查缺补漏吧。</p><h2>需求管理</h2><p>我们知道，系统都是在不断向前发展的，即使遗留系统也不例外。那么当团队正在如火如荼地推进微服务拆分的时候，又有源源不断的新需求要上线，这时候应该怎么办呢？</p><p>我们在拆分初期最重要的一件事，就是要和业务方协商好，尽量不要给拆分的模块添加新的需求。比如我们要拆分核保服务，那么就尽量在拆分期间不要添加核保相关的新需求。否则，拆分工作就会变得相当麻烦。</p><p>如果新的需求交给拆分团队之外的特性团队去开发，由于他们并不熟悉拆分团队的工作内容和进展情况，会造成严重的代码冲突，团队之间沟通协作的成本也相当高。而如果新的需求交给拆分团队来做，又会减缓拆分团队的开发进度。</p><!-- [[[read_end]]] --><p>当然，尽量不添加新需求并不代表一定不能添加。当需求十分紧急，优先级高于微服务拆分的时候，还是要添加的。这时候，我的建议是由拆分团队负责这个新需求的开发，避免和其他团队的沟通协作，以降低认知负载。</p><h2>双改新需求</h2><p>那么，拆分团队应该如何开发这个高优先级的业务需求呢？如何兼顾业务开发和拆分任务呢？</p><p>不要慌，由于我们使用了战术分叉和细粒度开关，面对需求和改造冲突的时候，可以做到丝滑地切换。</p><p>我们首先要分析一下，这个需求需要改动哪部分代码。主要有以下三种情况：</p><p>1.需要改动的代码还没有在微服务中改造。这是最理想的情况，只需要在单体服务中开发需求即可，然后用单体中的新代码覆盖核保服务中的旧代码。</p><p>2.需要改动的代码已经在微服务中改造完毕。这时候稍微麻烦一些，需要同时修改单体服务和微服务两部分代码，来实现这个需求，也就是“双改”。这样可以保证在开关打开或关闭的情况下，需求都能被满足。</p><p>3.需要改动的代码部分已经改造，部分还没有改造。这也没有什么，综合应用上面两种方案，对已经改造的部分进行“双改”，没有改造的部分“单改”即可。</p><p>对于需要全部或部分“双改”的需求，测试人员需要记住的是，一定要同时测试和对比开关打开和关闭两种情况，只有行为一致且正确才能通过。</p><h2>CODE OWNERS</h2><p>除了新需求，还有一种潜在的风险值得引起注意，就是单体中的核保代码很有可能被其他团队修改。如果我们不能在上线之前知道代码被修改了，就会导致开关打开和关闭的行为会不一致，造成问题。</p><p>如何在上线之前知道这件事呢？我们前面的课程说过，在遗留系统现代化之前，要通知所有干系人我们即将开始的工作，一方面是向业务方展示我们的工作以及即将产生的价值，另一方面也是让其他开发团队知道我们正在做的事情，修改这部分代码时需要通知我们。</p><p>当然，人的记忆始终是不靠谱的，要想真正做到没有遗漏，需要一些自动化机制来确保万无一失。很多基于Git的源代码管理工具，都会提供Code Owner功能，这样的功能就能帮我们实现自动化机制。</p><p>当相关的代码被修改时，它会根据配置，自动将一些人加为Pull Request（PR）的评审人。比如下面这行配置，当核保目录下的代码发生修改时，我就会成为PR的评审人，绝不会漏掉任何一行修改。</p><pre><code class=\"language-plain\">underwrite/ @yaoqilin\n</code></pre><p>不仅是我们在改造的核保代码，有时候我们也会修改与其他模块公用的代码，这些也要加上Code Owner。这时可以将前面的路径设置为文件名。</p><p>然而遗留系统的代码往往动辄几千行，这样的文件被修改了，我们被迫去review，结果看了半天发现与核保业务半毛钱关系都没有，这就让人很沮丧了。这时候有一个小技巧，可以帮助我们减少review的工作量。</p><p>对于很长的代码文件，我们可以先进行安全重构，应用<strong>方法对象模式</strong>（可以回顾<a href=\"https://time.geekbang.org/column/article/513599\">第九节课</a>），把要修改的代码提取成一个方法，再移动到一个类中。然后在新类中将方法复制一份，在其中一个方法上实现我们的改造，用于开关打开的时候调用；另一个方法保持原样，用于开关关闭的时候。然后对新的文件添加code owner。其他开发人员只有在修改我们提取出来的新文件时，才需要我们来review，这样就极大地降低了工作量。</p><p>不仅是代码，存储过程也可以采用同样的方式。在拆分一个存储过程之前，先把它复制到一个新的SQL文件中，并只对这个新文件添加code owner。</p><p>但你会发现，这种方法不适用于特性分支的分支策略。如果我们的拆分任务，都是在特性分支上开发的，完成之后才提PR合并代码，那么别人可能已经对你改造的API做了修改，而且这时合并代码不会引起任何冲突。而你的code owner配置也刚刚合并上去，别人的修改不会自动通知你。</p><p>因此要想很好地使用code owner技巧，以及更好地与其他团队合作，就必须频繁地提交代码，和其他团队的代码彼此频繁地集成。</p><h2>在业务代码中使用特性开关</h2><p>我在课程中曾经无数次提到过特性开关，像这个案例这样使用绞杀植物模式，通过反向代理中的开关来控制访问哪个API；或者在没有测试的保护下，使用扩张-收缩模式重构代码，通过代码内部的开关来实现A/B测试。</p><p>在微服务拆分的时候，我们有时也需要在代码内部使用开关，来控制使用新、旧哪部分代码。</p><p>我们要彻底将核保数据库拆分出去，就要让数据各归其主。前面课程里我们主要讲了原核保模块中的代码对非核保表的所有权的释放。除此之外，单体中的其他模块还有不少代码在访问核保的数据表，这部分数据的所有权同样需要处理，但处理后的代码仍然留在单体服务中，不需要拆分出去。</p><p>这时，我们仍然可以使用反向代理来控制新旧代码的分发。只不过在开关打开的时候，反向代理仍然会重定向到单体服务内部，一个我们复制出来的API中（这个API甚至很可能和原API位于同一个controller类），而不再是重定向到核保服务中。</p><p>而且，虽然我们在项目初期和业务方达成一致的是，尽量减少核保模块的业务变更，但这并不包括其他模块。因此单体中各个模块业务的需求变更可能会很频繁。</p><p>如果一个API的需求发生了变更，而我们又对它添加了API级别的开关，那么双改和code owner的工作量都会非常巨大。有没有办法减少这部分工作量呢？当然有。我们可以把开关的判断放在需要改造的地方，也就是业务代码中，让需要双改的代码紧紧挨着，这样一来认知负载就大大降低了。</p><p>比如单体服务中的理赔模块有一个提交二次核保的功能，它会直接向核保的表中插入数据。我们在改造这个API时，自然是希望将插入核保数据的代码替换成调用核保服务的某个API，但这个理赔API如何实现增量地交付呢？也就是说，一旦发现改造的代码出现了bug，应该如何做到及时回退呢？</p><pre><code class=\"language-java\">// ClaimController.java - 理赔API\npublic void applyUnderwrite() {\n  // claim = 理赔\n  ClaimDao claimDao = new ClaimDao();\n  claimDao.updateClaim();\n  UnderwriteApplicationDao underwriteApplicationDao = new UnderwriteApplicationDao();\n  underwriteApplicationDao.insertUnderwriteApplication();\n}\n</code></pre><p>我们可以在需要改动的位置引入开关：</p><pre><code class=\"language-java\">public void applyUnderwrite() {\n  ClaimDao claimDao = new ClaimDao();\n  claimDao.updateClaim();\n  if (CLAIM_APPLY_UNDERWRITE_TOGGLE_ON) {\n    // 当开关打开的时候，调用核保服务\n    UnderwriteServiceProvider underwriteServiceProvider = new UnderwriteServiceProvider();\n    underwriteServiceProvider.applyUnderwrite();\n  }\n  else {\n    // 当开关关闭的时候，仍然访问单体库中的核保表\n    UnderwriteApplicationDao underwriteApplicationDao = new UnderwriteApplicationDao();\n    underwriteApplicationDao.insertUnderwriteApplication();\n  }  \n}\n</code></pre><p>这种方法也并不是十全十美的，因为当代码异常复杂的时候，一个方法的不同位置可能会引入很多开关判断。而且如果需要前后挪动代码，很有可能判断开关不同状态的代码会分散到不同的位置，这时就会显得有些失控了：</p><pre><code class=\"language-java\">public void applyUnderwrite() {\n  ClaimDao claimDao = new ClaimDao();\n  claimDao.updateClaim();\n  if (CLAIM_APPLY_UNDERWRITE_TOGGLE_ON) {\n    UnderwriteServiceProvider underwriteServiceProvider = new UnderwriteServiceProvider();\n    underwriteServiceProvider.applyUnderwrite();\n  }\n  // 其他代码\n  // ...  \n  \n  // 判断开关关闭的代码与判断开关打开的代码距离很远\n  if (!CLAIM_APPLY_UNDERWRITE_TOGGLE_ON) {\n    UnderwriteApplicationDao underwriteApplicationDao = new UnderwriteApplicationDao();\n    underwriteApplicationDao.insertUnderwriteApplication();\n  }  \n}\n</code></pre><p>面对这种情况，我们就需要在团队内部展开讨论，是灵活一点针对不同复杂度的API采用不同的开关策略（即复杂的API在反向代理中加入开关，简单的API在改动处加入开关）？还是保持一致的开关策略从而避免混乱？我们应该把这个决定权交给团队的成员，而团队成员的判断依据则应该是，对自己来说哪种方式的认知负载更低。</p><h2>拆分大的改造任务</h2><p>前面我们讲过<strong>用开发工序来降低认知负载</strong>，就是因为一个改造任务（比如改造一个API）要涉及很多方面，要梳理业务流程、确定改造重点、制定改造方案、实施改造方案、本地验证等等，把任务拆解成工序，可以帮助我们聚焦当前的小任务，降低认知负载。</p><p>在我们之前的设计中，一个API的改造任务是由一个开发人员完成的。但遗留系统中往往存在一些难度非常高的API，不但涉及大量的代码依赖，而且代码和存储过程的深处，还存在着大量的数据库表依赖。这样的API很可能一两个月都改造不完。</p><p>这时候我们要灵活安排，由若干开发人员组成一个攻坚小组，指定一个owner来负责这个API的交付。他将组织组内人员开展讨论、制定方案、拆分任务、分配工作，将一个大的改造任务，拆解成若干小的、可以在几天时间内完成的小任务。比如一个API可能包含10处需要解耦的地方，就可以拆分成10个小任务。等这些小任务都开发完毕，owner负责将代码集成，并进行内测。</p><p>这么做的目的除了降低认知负载，也是为了能够更快速地完成一些事情，得到一些正向反馈，避免一个人长时间地耗在一个大任务上，消耗着体力，也消磨了意志。</p><p>值得注意的是，这时拆分的小任务是无法作为增量独立交付的，需要整体大任务完全改造完毕后一起交付。其实也不是完全不能独立交付，只是代价比较大，需要引入很多更细粒度的开关，引入不必要的认知负载。</p><h2>数据迁移</h2><p>当所有的API都已经改造完毕，数据的所有权都各自就位后，在我们的案例中，还剩下一件事需要做，就是数据迁移，把当前位于单体数据库中的与核保业务相关的表，以及需要冗余到核保库中的表，都迁移到核保数据库中。</p><p>由于我们使用了DBLink，因此在拆分API时不需要考虑数据迁移，而只需要在单体数据库中先建立视图，再在核保数据库中建立同义词，指向单体库中的视图即可：</p><pre><code class=\"language-sql\">-- 在单体数据库中创建被保人视图\nCREATE OR REPLACE VIEW V_UNDERWRITE_INSURED AS\n  SELECT NAME, GENDER, DATE_OF_BIRTH, SOCIAL_SECURITY_NO\n  FROM TBL_CUSTOMER C, TBL_UNDERWRITE_APPLICATION U\n  WHERE C.ID = U.INSURED_ID\n\n-- 在核保数据库中创建同义词\nCREATE SYNONYM V_UNDERWRITE_INSURED\nFOR V_UNDERWRITE_INSURED@monolithLocation\n</code></pre><p>这样我们就把整个拆分工作分成了三个部分：基于战术分叉的代码拆分、基于数据所有权的数据拆分以及数据迁移。其中代码拆分和数据迁移是可以在一个迭代中做完的，而数据拆分则是逐个API在多个迭代中增量交付的。</p><p>这时我们的数据在物理上仍然位于单体数据库中，当所有API改造完成后，就要在最后一个迭代中做数据迁移了。</p><p>迁移的脚本其实还是非常简单的，与建立视图的脚本十分类似，这里就不再赘述了。</p><p>如果你的数据库无法使用DBLink，在拆分数据所有权时，可以在单体库中建立这种视图，让核保服务的代码仍然访问单体数据库中的核保表和其他表的视图，然后再做数据迁移即可。</p><p>这是我们发现的认知负载最低的数据拆分和迁移方案。</p><h2>What’s Next?</h2><p>当迁移了数据之后，我们的微服务拆分就完成了。接下来该做些什么呢？</p><p>短期内，你需要根据上线后的数据，验证在项目初期所制定的假设：看看核保业务的响应力和吞吐量是否有了提升，是否达到了当初制定的目标。</p><p>如果没有达到目标，我们需要评估一下是哪里的问题，是否需要后续的工作。比如，我们虽然拆分出了微服务，但是秉承一次只做一件事的原则，并没有对代码做任何重构，代码的认知负载仍然很高，会成为影响需求响应力和吞吐量的罪魁祸首。那么后续就要继续对代码做重构，以及设计领域模型。</p><p>如果达到了目标，核保服务就可以进入常态化开发和维护的节奏了。可以让拆分团队留下一部分人维护这个服务，组成一个业务流团队。另一部分人因为有了拆分经验，可以组成一个赋能团队，去带领另外一个业务流团队，拆分下一个服务。</p><p>这样，每个精益切片做下来，整个项目组就会多出一些具备拆分能力的开发人员，总结出新的拆分经验。整个遗留系统就从一个架构越来越混乱、人员越来越挣扎的恶性循环，变成了架构越来越健康、人员能力越来越强的良性循环。</p><h2>小结</h2><p>又到了总结的时候，今天我们学习了在改造的过程中需要注意的一些事项，既包括需求管理相关的，也包括用技术手段来避免沟通协作时产生的纰漏，还包括将大任务拆小，以及最后逃不过的数据迁移。<br>\n<img src=\"https://static001.geekbang.org/resource/image/4f/27/4fc365a6c5b2f5fff2f94ba26a355c27.jpg?wh=6733x5278\" alt=\"\"></p><p>你会发现，我们的大多数解决方案和技巧都是为了降低认知负载。比如由拆分团队来负责该模块高优先级需求的开发，表面上看拆分团队的工作量似乎变大了，但由于避免了跨团队的沟通协作，其实是降低了认知负载。再比如拆分出新的文件添加code owner、对于复杂任务继续拆分，以及通过DBLink和视图延迟数据迁移，都很好地贯彻了<strong>以降低认知负载为前提</strong>这个原则。</p><p>到目前为止，我们用四节课的内容学习了拆分微服务时的各种问题和解决方案。其实，每次增量演进时，都需要测试人员验证我们的改造是否正确，是否和改造之前完全一致。<a href=\"https://time.geekbang.org/column/article/524966\">下节课</a>我们就来聊聊这方面的内容。</p><h2>思考题</h2><p>感谢你学完了今天的课程，今天的思考题请你来聊聊你是否在项目中做过微服务拆分？你有没有什么经验和技巧想要分享呢？</p><p>期待你的分享，如果你觉得这节课对你有帮助，别忘了分享给你的同事和朋友，我们下节课见。</p>","neighbors":{"left":{"article_title":"23｜微服务拆分（三）：如何拆分存储过程？","id":523851},"right":{"article_title":"25｜成果验证：如何评价遗留系统现代化项目的成败？","id":524966}}},{"article_id":524966,"article_title":"25｜成果验证：如何评价遗留系统现代化项目的成败？","article_content":"<p>你好，我是姚琪琳。</p><p>前面我们用了四节课的时间，解决了在拆分遗留系统时会遇到的种种难题。接下来就到了“提交答卷”的重要时刻，也就是遗留系统现代化的成果验证。</p><p>如果团队费时费力做完了改造，就撤出或解散了，没有后续的数据追踪和指标度量，改造成效就无法很好地展示出来。这样，领导和业务方对成效的感知就会很弱，下次可能就不会再投入资源做类似的改造了。</p><p>编筐编篓，全在收口，这节课我们就来聊聊成果验证的方法，让你的遗留系统改造项目在掌声中落下帷幕。</p><h2>功能验证</h2><p>首先，当一个任务改造完成后，我们需要对它进行功能方面的测试，以确保改造后的功能和改造前的功能是一致的。</p><p>这种不改变软件外在行为的“改造”其实就是重构，只不过不是代码级别，而是<strong>架构级别的重构</strong>。通常，代码级别的重构我们会用单元测试来保证重构的正确性，那对于这种架构级别的重构，应该如何来保证呢？</p><h3>并行核对</h3><p>我们前面的课程中一直在说，要基于特性开关做人工的A/B测试。其实<a href=\"https://en.wikipedia.org/wiki/A/B_testing\">A/B测试</a>原本是用于用户体验分析的，收集用户对A、B两个软件版本的真实反馈来进行选择。我们这里将其作为验证重构正确性的工具，算是扩大了它的外延。</p><p>其实这种方法有一个专门的名词，叫做<a href=\"https://www.thoughtworks.com/radar/techniques/parallel-run-with-reconciliation\">并行核对（Parallel Run with Reconciliation）</a>。只不过手工进行的并行核对还是略显麻烦，更好的方式是将该过程自动化。</p><!-- [[[read_end]]] --><p>GitHub在重构自己的遗留代码的时候，为了对比方便，开发了<a href=\"https://github.com/github/scientist\">Scientist</a>这个并行核对工具。虽然它本身只支持Ruby，不过也有了多种语言的移植版本。这个工具尤其适合那种使用扩张-收缩模式来进行重构的代码。但它也有相当大的局限，比如不能验证代码的副作用，然而毫无副作用的遗留代码是少之又少的。</p><p>要想更好地自动化并行核对，我还是建议自己手动开发一个适合自己遗留系统的工具。我在课程中屡次提到自己开发工具，你可能会望而却步，其实这并没有多难。因为你只需要开发一个能满足自己遗留系统的工具即可，不需要尽善尽美。</p><p>除了全自动化的并行核对，你还可以进行一些半自动化的并行核对，下面我们就来看看都有哪些手段。</p><h3>E2E测试</h3><p>我们在<a href=\"https://time.geekbang.org/column/article/292667\">第八节课</a>中提到过，遗留系统的测试策略应该是个钻石型，其中最上层就是E2E测试。它们可以模拟真实用户的行为，用来验证从页面到数据库的所有环节。</p><p><img src=\"https://static001.geekbang.org/resource/image/5e/c5/5ea17f429b5b6f1a3397238448b49ac5.jpg?wh=1920x1066\" alt=\"图片\"></p><p>在不少团队中，编写E2E测试是测试人员的工作。因此使用E2E测试进行并行核对的好处是，可以在拆分团队拆分API时，由测试人员并行地去编写E2E测试，这样就节省了大量的时间。</p><p>之所以说使用E2E测试进行并行核对是半自动化的，是因为在运行时需要手动调整一下开关。比如测试人员在编写E2E测试时，是基于开关关闭的旧代码来写的。等重构的代码提测之后，测试人员手动打开开关，再次运行测试。如果测试仍然通过，我们就认为重构没有破坏原有的功能。</p><p>如果你的遗留系统已经搭建了持续集成流水线，你也可以在重构的代码提交之后，在持续集成流水线中打开开关，并运行E2E测试。</p><h3>集成测试</h3><p>然而我们主要想测试的部分是后端代码和数据，而且E2E测试的反馈相对来说还是有些滞后，如果想在开发阶段就能做并行核对，那就需要开发人员在重构阶段编写测试了。</p><p>由于我们的增量是一个API，要验证这个API，最直接的方式就是对这个API编写测试。你可以使用Spring Boot等工具来编写针对API的集成测试，对于RESET API来说，还是十分方便的。但我们的案例是普通的Servlet，写起来就有些麻烦了。</p><p>这时，我们可以再退一步，放弃测试HTTP相关的内容（因为这一部分本来也不会发生变化），而是直接测试请求所映射的Servlet中的方法。如果这个方法很薄，只是将逻辑委托给了另一个Service，那么直接测试那个Service会更方便。</p><p>要想做到并行核对，你需要将测试复制成两份，一份位于单体服务中，用来测试旧的Servlet，一份位于核保服务中，用来测试新的Servlet。这两份测试略微有些不同，因为在核保服务中的测试需要mock掉对于单体服务的依赖。</p><pre><code class=\"language-java\">// 核保服务中的测试\n@Test\npublic void should_approve_underwrite_application_succesfully() {\n  PolicyServiceProvider policyService = mock(PolicyServiceProvider.class);\n  when(policyService.approveUnderwriteApplication(1L)).thenReturn(/*...*/);\n  UnderwriteApplicationService sut = new UnderwriteApplicationService(policyService);\n  sut.approve(1L);\n\n  UnderwriteApplication uw = getUnderwriteApplicationFromDB(1L);\n  assertEquals(\"2\", uw.getStatus());\n  verify(policyService).approveUnderwriteApplication(1L);\n}\n\n// 单体服务中的测试\n@Test\npublic void should_approve_underwrite_application_succesfully() {\n  UnderwriteApplicationService sut = new UnderwriteApplicationService(policyService);\n  sut.approve(1L);\n\n  UnderwriteApplication uw = getUnderwriteApplicationFromDB(1L);\n  assertEquals(\"2\", uw.getStatus());\n  Policy policy = getPolicyFromDB(1L);\n  assertEquals(today(), policy.getUnderwriteDate());\n  \n}\n</code></pre><p>这种测试的好处是，会连带着测试SQL语句和存储过程，覆盖遗留系统中大多数的业务逻辑。我们在第八节课讲过，要编写这样的数据库集成测试，需要搭建一些基础设施，包括远端的数据库镜像，以及可以从其他环境快速拉取数据的工具。</p><h3>数据对比</h3><p>然而，像上面这样只验证数据库中的部分数据（核保申请的状态、保单的核保日期），在遗留系统中可能还不够。</p><p>因为遗留系统的数据操作往往十分繁琐，表面上看，我们只是修改了核保申请和保单两张表，但实际上在存储过程中可能涉及了几十张表的修改。要想在每个测试场景中都找出相关的表和修改的字段，对这些字段的值一一对比，工作量十分巨大。</p><p>这时你可以考虑直接对比数据库中的数据。比如在开关关闭状态下运行测试，得到当前的数据库快照，接着打开开关，再次运行测试并记录快照，然后比较这两种状态下的数据快照是否完全一致。只有数据库完全一致，才能100%证明重构的正确性。</p><p>但是这样全量的数据对比可能会十分耗时，你可以对它进行优化。因为我们的测试其实是白盒的，你可以通过<strong>活文档工具</strong>快速了解API所涉及的表，然后只去比较这些表的数据。你还可以给出这些表中的主键值，只针对部分行数据做比较，这样能进一步提升执行速度。</p><p>但你也会发现，要想提升测试的执行速度，就必须提供更多的数据，而这就会带来额外的工作量。你可以针对你的系统情况，找出一个平衡点。</p><p>我的前同事吴雪峰开源了一个针对Oracle的<a href=\"https://github.com/XuefengWu/dbdiff\">数据库对比工具</a>，感兴趣的同学可以研究一下。</p><h3>动态开关工具</h3><p>其实，手写一个开关判断逻辑是很简单的。但除此之外，你还可以选择使用工具。</p><p>在动态开关工具中，最流行的恐怕就是<a href=\"https://www.togglz.org\">Togglz</a>了，它不但提供了多种配置方式，更是允许只匹配指定的用户，这就为灰度发布提供了可能。</p><p>最近几年，Feature Toggle as a Service开始流行起来。它们大多数都提供了多语言的支持，并包含友好的用户界面。你可以基于这些服务，很好地管理特性开关。这些服务包括<a href=\"https://configcat.com\">ConfigCat</a>、<a href=\"https://github.com/checkr/flagr\">Flagr</a>、<a href=\"https://flagger.app\">Flagger</a>等。</p><h2>发布到生产环境</h2><p>前面我们解决了本地和测试环境的验证问题，当功能测试完成后，就可以发布到生产环境了。这时候为了将发布风险降低到最小，你可以使用蓝绿部署、灰度发布等高频发布技术，缩小发布影响的范围。</p><p>如果你的遗留系统还没有这些基础设施，也不必担心，你可以在开关上做一些手脚，仅对配置的用户才生效。比如将测试用户的ID硬编码到开关判断的逻辑中，或者配置在数据库或配置文件里。只有当session中的用户信息和配置的信息匹配时，才将请求转发给核保服务。或者，你也可以直接使用上面提到的Togglz。</p><p>这样，你就可以仅对这些测试账号打开开关，由测试人员在生产环境再测试一遍，对产生的数据变化进行对比。测试通过后，再逐步放开用户。由于新旧服务两边都在双写数据，所以你可以放心地控制开关状态。</p><p>还有一个可能会影响验证方案的因素，是<strong>系统目前的部署状态</strong>。比如银行、保险的业务系统，最早可能是分区域部署的，每个省份或地区都会部署相同的、但彼此独立的应用和数据库。这对于跨区域业务来说可能不太友好，但对于遗留系统现代化来说，却歪打正着，是个利好消息。在改造完成后，你可以找一个用户比较少，流量比较少的区域进行验证，以降低风险。</p><h2>假设验证</h2><p>当所有API的功能都在生产环境验证成功后，下一步要做的就是验证我们最初的假设是否成立。</p><p>在第二十节课我说过，之所以选择核保模块的微服务拆分作为遗留系统现代化试点，是因为业务方更关注核保模块的业务响应力。这个假设可以分解为两个指标，即需求交付前置时间（lead time）和需求吞吐量。</p><p>那么我们就有两方面的数据需要收集并对比：</p><p>1.服务拆分前后，一个需求从开发接手到上线的时间。<br>\n2.服务拆分前后，每个交付周期内可以完成的需求总数。</p><p>在收集数据时一定要注意，需求有大有小，有难有易，因此不同的需求之间是很难直接对比的。以前在遗留系统中，对于需求的估算可能更多是靠经验。而现在，你可以参考很多科学的估算方法。比如<a href=\"https://www.knowledgehut.com/blog/agile/t-shirt-sizing-use-to-estimate-delivery\">T-Shirt Size估算法</a>，将需求按大小分为S、M、L、XL等级别，以方便排期。</p><p>在度量时，你可以给不同size的需求设置权重，来进行统计。比如一个交付周期内的需求吞吐量可以这么计算：假设S、M、L、XL的权重分别为1、2、3、5（<a href=\"https://www.mountaingoatsoftware.com/blog/why-the-fibonacci-sequence-works-well-for-estimating\">斐波那契数列</a>），将每个需求转换成各自对应的权重（用w表示），并求和。用公式表示就是：</p><p>$$\\sum_{1}^{n}{w}$$</p><p>而需求的交付前置时间可以用单个需求的前置时间除以权重，得到单位权重的前置时间。再将多个需求累加，以排除干扰因素。用公式表示就是：</p><p>$$\\sum_{1}^{n}{\\frac{t_{n}}{w}}$$</p><p>如果团队使用<a href=\"https://www.scaledagileframework.com/agile-release-train\">交付火车</a>这样的交付方式，有着固定交付周期，那么我们也可以用开发前置时间（即需求从开始开发到开发完成的时间）来代替。</p><p>在统计数据时，不要忘了将它们可视化出来，比如用下面这种折线图来展示核保服务上线前后的需求吞吐量和前置时间。<br>\n<img src=\"https://static001.geekbang.org/resource/image/07/bf/07d8b34b8389f06f03ed11d3eacd12bf.jpg?wh=1920x1296\" alt=\"图片\"><br>\n<img src=\"https://static001.geekbang.org/resource/image/98/52/985d65e1b9470a6eaae14942ef0b5c52.jpg?wh=1920x1335\" alt=\"图片\"></p><p>注意，在服务刚上线时，数据可能会变糟，因为可能要修复一些Bug，团队也可能对这种开发方式不太适应。但随着时间变长，因新服务上线造成的Bug越来越少，团队也越来越适应，所有的数据都会慢慢向好的方向发展。</p><p>你可以用大屏幕轮播这些图表，或者打印出来贴在墙上。团队成员看到这样的图表会感到自己的努力得到了成效；而业务人员也会很开心，因为他们的投资得到了回报。</p><h2>小结</h2><p>又到了总结的时候。今天这节课是我们实战篇的最后一节，我们聊了聊在上线前后如何验证功能，以及在正式交付后如何验证我们最初的假设。</p><p>我总结了一幅图，可以帮你加深对这节课的理解。</p><p><img src=\"https://static001.geekbang.org/resource/image/58/b0/589301a70bf22a10406d52501ef3eab0.jpg?wh=1920x1137\" alt=\"图片\"></p><p>有效的成果验证既能鼓舞团队士气，又能让领导和业务方感受到改造的价值，还能为你后续的改造安排打下良好的试点基础和团队实力。</p><p>遗留系统现代化长路漫漫，千万不要因为这些比较容易做却没有做的小事儿，而半途而废啊。</p><p>到此为止，我们的遗留系统微服务拆分案例的讲解就告一段落了。你可能感觉自己的项目概况与我所介绍的案例相差甚远，很多实战经验用不上。这其实是很正常的。</p><p><strong>实践经验，只是理论知识在落地过程中的“本地化”。任何一套经验，都有它的适用范围，并不是普天下皆准的真理。</strong></p><p>在拆分案例讲解中，我力求把分析过程和选型经验融入其中，就是为了让你适应这种现代化理论落地到实践的思维转换。你要做的，是熟练掌握模式篇所介绍的那些模式，并以遗留系统现代化的三大原则作为指导，去完成四个现代化方向上的各种工作。</p><h2>思考题</h2><p>感谢你学完了今天的内容，今天的思考题是，你的项目是否做过遗留系统改造的成果度量？如果有的话，能否分享一下你们的经验？</p><p>期待你的分享，如果你觉得这节课对你有帮助，别忘了分享给你的同事和朋友，我们一起来检验遗留系统的现代化成果吧。</p>","neighbors":{"left":{"article_title":"24｜微服务拆分（四）：其他话题","id":524615},"right":{"article_title":"结束语｜技术终将老去，但好在你还年轻","id":525871}}},{"article_id":525871,"article_title":"结束语｜技术终将老去，但好在你还年轻","article_content":"<p>你好，我是姚琪琳。</p><p>首先，恭喜你学完了《遗留系统现代化实战课》这个专栏。不知道你学完的感受是怎样的？</p><p>每每看到你们在留言区的分享和肯定，看到自己用心写出来的文字得到了回响，我就觉得所有的付出和努力，都是值得的。</p><p>现在我们回过头看专栏中讲到的各个理论，无论是认知负载、假设驱动、演进式架构，还是代码重构、测试策略、绞杀植物、扩张收缩、微服务架构、持续集成、团队拓扑……你也许已经发现了，都是现成的理论。它们有些是专为遗留系统而设计的，有些虽然不是，但我认为也同样适用于遗留系统。我不是一个发明者，而只是一个搬运工，仅此而已。</p><p><strong>作为一个知识的搬运工，对我来说，写这个专栏其实是一件“枯燥”的事情。</strong></p><p>说它枯燥，是因为我们技术人员天生就爱去做“有技术含量”的事情。而整天面对文档码字儿，会被认为是没什么技术含量的工作。尤其是你不得不去梳理躲在脑子里各个角落的知识碎片，梳理之后，还需要有条理、有逻辑地表述出来。</p><p>写极客时间的专栏尤其如此，它要求语言通俗易懂，像跟你在唠家常。我一开始在试写时很不习惯，但好在都坚持了下来。</p><p>但是也正因为坚持下来了，我才品尝到“枯燥”之后的回甘。几个月折腾下来，受益者不只是你，还有我。如果不是这个机会，我可能永远也不会这样去总结，把自己过去十五年的工作经验，把这些看似毫不相干的理论，提炼输出成系统化的专栏，为你解决遗留系统现代化问题提供参考。</p><!-- [[[read_end]]] --><p>我也得承认能这么做总结不是一件简单的事。因为很多人在遇到一个问题的时候，更愿意去研究能够解决这个问题的工具。但特定的工具掌握了，下次碰见类似但不完全一样的问题，可能还是解决不了。因为他根本没有了解问题的本质。</p><p>道家的“道”、“法”、“术”、“器”特别适合来解释这个现象。简单来说，“道”是指思维、原则，是问题的本质；“法”是指方法、策略，是解决问题的方法论、原则和导向；“术”是指技术、技能，是解决问题的方法和套路；“器”是指工具、资源，是解决问题的技巧。</p><p>我们对于工具的痴迷和狂热，对应的就是“器”的这个阶段。但这并不是说它不重要，而是说，你不应该只关注“器”就满足了，而应该更关注“道”和“法”。</p><p>从“器”开始，慢慢向“术”、“法”、“道”去延伸，了解事物的本质，然后触类旁通，不用花多少时间就能熟悉其他“术”和“器”。这就是一个非常不错的学习路径，也是我能够把自己多年经验、各种理论结合整合在一起的原因。</p><p>对应到遗留系统现代化，这方面的“道”、“法”、“术”、“器”是这样的：以降低认知负载为前提、以假设驱动为指引、以增量演进为手段这三大原则，是“道”；四个现代化方向中的众多模式，是“法”；实战篇里的各种实践，是“术”；而各节课中穿插介绍的一些工具，是“器”。</p><p><img src=\"https://static001.geekbang.org/resource/image/78/e1/78f4766a022ccba557aa76efee9d88e1.jpg?wh=1920x1032\" alt=\"图片\"></p><p>你会发现，我最重视的就是“道”和“法”，其次是它们在实践中的应用，也就是“术”，而作为“器”的那些工具，我大多都是点到为止。不是“器”不重要，而是你不必纠结“器”的细节，应当把有限的时间花在更有价值的本质和原则上。</p><p><strong>为什么说看透本质，把握原则更有价值呢？</strong>这里再给你分享一个我的小故事。</p><p>Thoughtworks的开发团队是“敏捷原生”的，在这样的团队中耳濡目染了几年后，我作为咨询小白，参与了一个敏捷咨询项目。</p><p>当时我自以为深谙敏捷，没想到在和客户交流的时候发现，自己连一些基本的Scrum术语都不清楚，而客户则很多都拿到了Scrum Master认证。当时我的自信一下子就跌到了谷底，感觉应该回炉重造。</p><p>然而随着交流的深入，我发现他们虽然拿到了证书，熟悉那些工具，但实际上并不了解敏捷的本质和价值观，因此只要不是书本上或培训中讲过的内容，就不知道对不对，不敢尝试了。而我则引经据典、旁征博引，客户无不恍然大悟、心服首肯。</p><p>后来我的同事评价说，你只是不知道自己知道罢了。这就是深入掌握了“道”和“法”，即使不清楚具体的“术”和“器”，也一样能所向披靡，就像是手中无剑、心中有剑一样。</p><p>这就像靠刷题去准备高考，虽然这种自下而上的学习方式有可能取得好成绩，但你会发现那些真正的学霸都是熟练掌握各种公理定理，靠推导来做题的。他们不用刷太多题，也能把题做对。因此这种自上而下的学习方法，关注“道”和“法”，认识问题本质，把握规律原则的路径，才是真正高效的、聪明的方法。</p><p>在专栏讲解中，我也更偏向这种思考方式。希望这个专栏，能够帮你认识到遗留系统问题的本质，把握住更为本质的原则与模式。</p><p>这些原则和模式，包括一开始梳理问题时所使用的方法，都是遗留系统在构建之初所缺失的。</p><p><strong>我们做遗留系统现代化，其实就是给遗留系统补上这落下的一课。亡羊补牢，犹未晚矣。</strong></p><p>分享了很多学习的方法，最后我也想和你聊一聊学习的心态。</p><p>IT技术是在不断向前发展的，新技术层出不穷，各种语言也是一个版本接一个版本，就连书籍都会出新版本，那一个架构、设计和理论又怎么可能一成不变呢？</p><p>一套理论，要想达到MECE（相互独立且完全穷尽）是很难的，因为任何一个复杂问题都不可能一开始就找出所有的关键点。就像一个遗留系统的解决方案，也是通过不断增量演进浮现出来的一样，遗留系统现代化的原则和模式也是不断演进慢慢完善的。</p><p>你可能疑惑专栏里提到三个原则就够了吗？这四个现代化方向是全的吗？掌握了这些，我就能一往无前了么？我的回答很简单，当然不是。我们应该抱着一个开放的心态，去学习一切跟遗留系统有关的知识。再通过不断总结和实践，去迭代自己的知识体系。</p><p>无论是遗留系统的工程难题，还是工程师的学习成长，都是一个长期主义的实践，都需要耐心、恒心、信心和用心。</p><p>所有人都对新技术趋之若鹜，生怕没有赶上这一班车而被时代所淘汰，这就是浮躁的典型表现。就拿我们常常讨论的35岁危机来说，本来35岁是一个职业生涯刚刚步入正轨、风华正茂的年纪，我们正要一展身手，基于之前的积累，开始从学习和输入转向更多的释放和输出。怎么就成了要么财务自由、别墅靠海，要么优化解聘、打包走人的分水岭了呢？</p><p>很多人都不愿意工作在遗留系统上，觉得没有技术含量。但想成为一个遗留系统专家，你需要多专、全专。从前端到数据库，从代码到架构，从测试到运维，从业务分析到团队管理，从数字化转型到认知心理学……建立了这样全面系统的知识体系，你才能在复杂的问题面前，临危不乱，应对自如。</p><p>看到这些内容，你还敢说没有技术含量吗？要进行方方面面的治理，具备从前到后的经验，怎么也得35岁起步吧？</p><p>就像我在开篇词说的那样，你现在所写的每一行代码，都是未来的遗留系统。任何一项技术（“术”和“器”），五年后都会过时。只有那些软件设计的原则和模式（“道”和“法”）是长盛不衰、永远年轻的。你只要熟练掌握这些原则和模式，就能轻松应对技术的更新换代。作为架构师或开发人员的你，无论是25、35还是55，都是年轻的。</p><p><strong>我们不但要让自己的系统保持长青，也要让自己，永远年轻。</strong></p><p>后会有期，希望我的专栏对你有启发。最后的最后，我想听听你学习这个专栏的感受，希望你花几分钟填一下后面的<a href=\"https://jinshuju.net/f/QVpM6L\">毕业问卷</a>。</p><p><a href=\"https://jinshuju.net/f/QVpM6L\"><img src=\"https://static001.geekbang.org/resource/image/1d/b4/1d3d897c6dfeb4a2b7ecb984677d7db4.jpg?wh=1142x801\" alt=\"图片\"></a></p>","neighbors":{"left":{"article_title":"25｜成果验证：如何评价遗留系统现代化项目的成败？","id":524966},"right":[]}}]