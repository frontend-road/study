{"id":318703,"title":"25 | 评估指标：我们可以用哪些指标来衡量模型的好坏？","content":"<p>你好，我是王喆。今天，我们来学习推荐模型的评估指标。</p><p>上节课，我们讲了五种评估方法，清楚了它们都是怎么把样本分割为训练集和测试集的。但是只分割样本是远远不够的，为了比较模型效果的好坏，还得用一些指标进行衡量。就像我们工作中经常说，我的模型提高了“一个点”的效果，那所谓的“一个点”指的是什么呢？它其实说的就是，我们的模型在一些经典的推荐指标上提升了1%的效果，这节课我就带你来捋一捋这些经典的推荐评估指标。</p><h2>低阶评估指标</h2><p>我按照指标计算的难易程度，和评估的全面性，把推荐系统的评估指标可以分成低阶评估指标和高阶评估指标两大类。对于低阶评估指标来说，准确率、精确率与召回率、对数损失、均方根误差，这四个指标在推荐模型评估中最常用，计算起来也最容易。所以，我们就先来学习一下这几个低阶评估指标的具体含义。</p><h3>1. 准确率</h3><p>准确率 (Accuracy)是指分类正确的样本占总样本个数的比例，公式1就是：$\\text {Accuracy}=\\frac{n_{\\text {correct }}}{n_{\\text {total }}}$。</p><p>其中，  ncorrect是正确分类的样本个数， ntotal是样本的总数。</p><!-- [[[read_end]]] --><p>准确率是分类任务中非常直观的评价指标，可解释性也很强，但它也存在明显的缺陷，就是当不同类别的样本比例非常不均衡的时候，占比大的类别往往成为影响准确率的最主要因素。比如，负样本占99%，那么分类器把所有样本都预测为负样本也可以获得99%的准确率。</p><p>在之前的课程中，我们经常把推荐问题看作是一个点击率预估型的分类问题。这个时候，我们就可以用准确率来衡量推荐模型的好坏。但在实际的推荐场景中，我们往往会生成一个推荐列表，而不是用所谓的分类正不正确来衡量最终的效果，那我们该怎么评估一个推荐列表的效果呢？这个时候，我们就会利用到精确率和召回率这两个指标。</p><h3>2. 精确率与召回率</h3><p>我这里所说的<strong>精确率（Precision）指的是分类正确的正样本个数占分类器判定为正样本个数的比例，召回率（Recall）是分类正确的正样本个数占真正的正样本个数的比例</strong>。</p><p>在推荐列表中，通常没有一个确定的阈值来把预测结果直接判定为正样本或负样本，而是采用Top N  排序结果的精确率（Precision@N）和召回率（Recall@N）来衡量排序模型的性能。具体操作，就是认为模型排序的前N个结果就是模型判定的正样本，然后分别计算Precision@N和Recall@N。</p><p>事实上，精确率和召回率其实是矛盾统一的一对指标。这是什么意思呢？就是，为了提高精确率，模型需要尽量在“更有把握”时把样本预测为正样本，但此时，我们往往会因为过于保守而漏掉很多“没有把握”的正样本，导致召回率降低。</p><p>那有没有一个指标能综合地反映精确率和召回率的高低呢？其实是有的，那就是F1-score。F1-score的定义是精确率和召回率的调和平均值，具体的定义你可以看看下面的公式2。F1-score的值越高，就证明模型在精确率和召回率的整体表现上越好。</p><p>$$<br>\n\\mathrm{F} 1=\\frac{2 \\cdot \\text { precision } \\cdot \\text { recall }}{\\text { precision }+\\text { recall }}<br>\n$$</p><h3>3. 对数损失</h3><p>接着，我们来说一说对数损失（Logloss）这个评估指标。</p><p>首先，在一个二分类问题中，对数损失函数的定义就是下面的公式3。<br>\n$$<br>\n-\\frac{1}{N} \\sum_{i=1}^{N}\\left(y_{i} \\log P_{\\mathrm{i}}+\\left(1-y_{i}\\right) \\log \\left(1-P_{i}\\right)\\right)<br>\n$$</p><p>在这个公式中，$y_{i}$是输入实例 $x_{i}$ 的真实类别, $p_{i}$是预测输入实例 $x_{i}$  是正样本的概率，$N$是样本总数。</p><p>而面对多分类问题的时候，对数损失函数定义就变成了下面公式4的样子：</p><p>$$<br>\n\\text { Multi-LogLoss }=-\\frac{1}{n} \\sum_{i=1}^{n} \\sum_{j=1}^{m} y_{i, j} \\log \\left(p_{i, j}\\right)<br>\n$$</p><p>如果你仔细看公式就会发现，二分类和多分类模型的Logloss其实就是我们之前讲过的逻辑回归和Softmax模型的损失函数，而大量深度学习模型的输出层正是逻辑回归或Softmax，因此，采用Logloss作为评估指标能够非常直观地反映模型损失函数的变化。所以在训练模型的过程中，我们在每一轮训练中都会输出Logloss，来观察模型的收敛情况。</p><h3>4. 均方根误差</h3><p>刚才我们说的准确率、精确率、召回率、LogLoss都是针对分类模型指定的指标。分类模型就是指预测某个样本属于哪个类别的模型，最典型的就是点击率预估模型。除了这类分类模型以外，还有回归模型，它是用来预测一个连续值，比如预测某个用户对某个电影会打多少分，这就是一个回归模型。</p><p>那我们对于回归模型有什么合适的评估指标吗？对于回归模型来说，最常用的评估指标就是<strong>均方根误差</strong>（RMSE，Root Mean Square Error）。它的公式是求预测值跟真实值之间差值的均方根：</p><p>$$<br>\n\\mathrm{RMSE}=\\sqrt{\\frac{\\sum_{i=1}^{n}\\left(y_{i}-\\hat{y}_{l}\\right)^{2}}{n}}<br>\n$$</p><p>这个公式中，$y_{i}$是第i个样本点的真实值，$ \\hat{y}_{l}$是第i个样本点的预测值，n是样本点的个数。那么均方根误差越小，当然就证明这个回归模型预测越精确。</p><p>总的来说，我们刚才说的这四个评估指标，虽然在推荐系统中最常用，计算起来也最简单，但它们反应的结果还不够精确和全面。</p><p>比如说，精确率和召回率可以反应模型在Top n个排序结果上的表现，但我们要知道，在真正的推荐问题中，n的值是变化的，因为用户可能会通过不断的翻页、下滑来拉取更多的推荐结果，这就需要有更高阶的评估指标来衡量模型在不同数量推荐结果上的综合性能。所以，我们接下来再讲几个非常流行，也非常权威的高阶评估指标。</p><h2>高阶评估指标</h2><p>那在高阶评估指标部分，我会给你讲P-R曲线、ROC曲线、平均精度均值，这三个最常用的评估指标。</p><h3>1. P-R曲线</h3><p>首先，我要说的是P-R曲线，这里的P就是我们之前学过的精确率Precision，R就是召回率Recall。刚才我们说了，为了综合评价一个推荐模型的好坏，不仅要看模型在一个Top n值下的精确率和召回率，还要看到模型在不同N取值下的表现，甚至最好能绘制出一条n从1到N，准确率和召回率变化的曲线。这条曲线就是P-R曲线。</p><p>P-R曲线的横轴是召回率，纵轴是精确率。对于一个推荐模型来说，它的P-R曲线上的一个点代表“在某一阈值下，模型将大于该阈值的结果判定为正样本，将小于该阈值的结果判定为负样本时，整体结果对应的召回率和精确率”。整条P-R曲线是通过从高到低移动正样本阈值生成的。如图1所示，它画了两个测试模型，模型A和模型B的对比曲线。其中，实线代表模型A的P-R曲线，虚线代表模型B的P-R曲线。</p><p><img src=\"https://static001.geekbang.org/resource/image/27/40/27c1669b30da6817fc7275354fc1ff40.jpg?wh=1180*1032\" alt=\"\"></p><p>从图中我们可以看到，在召回率接近0时，模型A的精确率是0.9，模型B的精确率是1。这说明模型B预测的得分前几位的样本全部是真正的正样本，而模型A即使是得分最高的几个样本也存在预测错误的情况。</p><p>然而，随着召回率的增加，两个模型的精确率整体上都有所下降。特别是当召回率在0.6附近时，模型A的精确率反而超过了模型B。这就充分说明了，只用一个点的精确率和召回率是不能全面衡量模型性能的，只有通过P-R曲线的整体表现，才能对模型进行更全面的评估。</p><p>虽然P-R曲线能全面衡量模型的性能，但是它总归是一条曲线，不是一个数字，我们很难用它直接来判断模型的好坏。那有没有一个指标能用来衡量P-R曲线的优劣呢？当然是有的，这个指标就是AUC(Area Under Curve)，曲线下面积。顾名思义，AUC指的是P-R曲线下的面积大小，因此计算AUC值只需要沿着P-R曲线横轴做积分。AUC越大，就证明推荐模型的性能越好。</p><h3>2. ROC曲线</h3><p>接着，我们再来介绍第二个高阶指标，ROC曲线，它也是一个非常常用的衡量模型综合性能的指标。ROC曲线的全称是the Receiver Operating Characteristic曲线，中文名为“受试者工作特征曲线”。ROC曲线最早诞生于军事领域，而后在医学领域应用甚广，“受试者工作特征曲线”这一名称也正是来源于医学领域。</p><p>ROC曲线的横坐标是False Positive Rate（FPR，假阳性率），纵坐标是True Positive Rate （TPR，真阳性率）。这两个名字读上去就有点拗口，我们还是通过它们的定义来理解一下  ：</p><p>$$<br>\n\\mathrm{FPR}=\\frac{\\mathrm{FP}}{N}, T P R=\\frac{\\mathrm{TP}}{P}<br>\n$$</p><p>在公式中，P指的是真实的正样本数量，N是真实的负样本数量；TP指的是P个正样本中被分类器预测为正样本的个数，FP指的是N个负样本中被分类器预测为正样本的个数。但我估计你看了这个定义，可能还是不好理解这个ROC曲线是怎么得到的。没关系，我们真正去画一条ROC曲线，你就明白了。</p><p>和P-R曲线一样，ROC曲线也是通过不断移动模型正样本阈值生成的。假设测试集中一共有20个样本，模型的输出如下表所示，表中第一列为样本序号，Class为样本的真实标签，Score为模型输出的样本为正的概率，样本按照预测概率从高到低排序。在输出最终的正例、负例之前，我们需要指定一个阈值，并且设定预测概率大于该阈值的样本会被判为正例，小于该阈值的会被判为负例。</p><p>比如，我们指定0.9为阈值，那么只有第一个样本会被预测为正例，其他全部都是负例。这里的阈值也被称为 “截断点”。</p><p><img src=\"https://static001.geekbang.org/resource/image/4c/66/4c7f89a6717e0d272527a77a5fe64266.jpeg?wh=1920*1080\" alt=\"\"></p><p>接下来，我们要做的就是动态地调整截断点，从最高的得分开始（实际上是从正无穷开始，对应着ROC曲线的零点），逐渐调整到最低得分。每一个截断点都会对应一个FPR和TPR的值，在ROC图上绘制出每个截断点对应的位置，再连接每个点之后，我们就能得到最终的ROC曲线了。那么ROC曲线上的点具体应该怎么确定呢？</p><p>我们来看几个例子，当截断点选择为正无穷的时候，模型会把全部样本预测为负例，那FP和TP必然都为0，FPR和TPR也都为0，因此曲线的第一个点就是 (0,0) 。当把截断点调整为0.9的时候，模型预测1号样本为正样本，并且这个样本也确实是正样本。因此，在20个样本中，当TP=1，所有正例数量P=10的时候，TPR=TP/P=1/10。</p><p>我们还可以看到，这个例子里没有预测错的正样本，也就是说当FP=0，负样本总数N=10的时候，FPR=FP/N=0/10=0，对应着ROC图上的点(0,0.1)。</p><p><img src=\"https://static001.geekbang.org/resource/image/a5/e6/a54e03043e1dca53a47d601c7b2e51e6.jpg?wh=1334*1226\" alt=\"\"></p><p>其实，还有一种更直观的绘制ROC曲线的方法。首先，我们根据样本标签统计出正负样本的数量，假设正样本数量为P，负样本数量为N。然后，我们把横轴的刻度间隔设置为1/N，纵轴的刻度间隔设置为1/P。接着，我们再根据模型输出的预测概率对样本进行从高到低的排序。</p><p>最后，依次遍历样本。同时，从零点开始绘制ROC曲线，每遇到一个正样本就沿纵轴方向绘制一个刻度间隔的曲线，每遇到一个负样本就沿横轴方向绘制一个刻度间隔的曲线，直到遍历完所有样本，曲线最终停在 (1,1) 这个点，整个ROC曲线就绘制完成了。</p><p>在绘制完ROC曲线后，我们也可以像P-R曲线一样，计算出 ROC曲线的AUC，AUC越高，推荐模型的效果就越好。</p><h3>3. 平均精度均值</h3><p>最后，我们来说平均精度均值mAP（mAP，mean average precision）这个高阶指标，它除了在推荐系统中比较常用，在信息检索领域也很常用。mAP其实是对平均精度（AP，average precision）的再次平均，因此在计算mAP前，我们需要先学习什么是平均精度AP。</p><p>假设，推荐系统对某一用户测试集的排序结果是1, 0, 0, 1, 1, 1。其中，1代表正样本，0代表负样本。接下来，我们就按照之前学过的方法，计算这个序列中每个位置上的precision@N。你可以自己先试着计算一下，也可以直接看我下面计算好的结果。</p><p><img src=\"https://static001.geekbang.org/resource/image/f9/bb/f91acb00e50aa1f273cc1610148953bb.jpeg?wh=1507*789\" alt=\"\" title=\"每个位置的precision@N值\"></p><p>计算平均精度AP的时候，我们只取正样本处的precision进行平均，根据得到的表格AP =（1/1 + 2/4 + 3/5 + 4/6）/4 = 0.6917。接下来，我们再来看什么是mAP。</p><p>如果推荐系统对测试集中的每个用户都进行样本排序，那么每个用户都会计算出一个AP值，再对所有用户的AP值进行平均，就得到了mAP。也就是说，mAP是对精确度平均的平均。</p><p>这里就需要注意了，mAP的计算方法和P-R曲线、ROC曲线的计算方法是完全不同的，因为mAP需要对每个用户的样本进行分用户排序，而P-R曲线和ROC曲线均是对全量测试样本进行排序。这一点在实际操作中是需要注意的。</p><h2>合理选择评估指标</h2><p>到这里，这节课的7个评估指标我们就讲完了。如果你是第一次接触它们，可能现在已经有点茫然了。事实上，除了这些评估指标，还有很多其他的推荐系统指标，比如归一化折扣累计收益（Normalized Discounted Cumulative Gain,NDCG）、覆盖率（Coverage）、多样性（Diversity）等等。那面对这么多评估指标，你肯定想问，我们应该怎么选择它们呢？</p><p>很可惜，这次又是一个开放式的问题，评估指标的选择同样没有标准答案。但我还是会把一些经验性的选择总结出来，希望能够帮助到你。</p><p>比如，在对推荐模型的离线评估中，大家默认的权威指标是ROC曲线的AUC。但AUC评估的是整体样本的ROC曲线，所以我们往往需要补充分析mAP，或者对ROC曲线进行一些改进，我们可以先绘制分用户的ROC，再进行用户AUC的平均等等。</p><p>再比如，在评估CTR模型效果的时候，我们可以采用准确率来进行初步的衡量，但我们很有可能会发现，不管什么模型，准确率都在95%以上。仔细查看数据我们会发现，由于现在电商点击率、视频点击率往往都在1%-10%之间。也就是说，90%以上都是负样本，因此准确率这个指标就不能够精确地反应模型的效果了。这时，我们就需要加入精确率和召回率指标进行更精确的衡量，比如我们采用了Precision@20和Recall@20这两个评估指标，但它终究只衡量了前20个结果的精确率和召回率。</p><p>如果我们要想看到更全面的指标，就要多看看Precision@50和Recall@50，Precision@100和Recall@100，甚至逐渐过渡到P-R曲线。</p><p>总的来说，评估指标的选择不是唯一的，而是一个动态深入，跟你评测的“深度”紧密相关的过程。而且，在真正的离线实验中，虽然我们要通过不同角度评估模型，但也没必要陷入“完美主义”和“实验室思维”的误区，选择过多指标评估模型，更没有必要为了专门优化某个指标浪费过多时间。</p><p>离线评估的目的在于快速定位问题，快速排除不可行的思路，为线上评估找到“靠谱”的候选者。因此，我们根据业务场景选择2~4个有代表性的离线指标，进行高效率的离线实验才是离线评估正确的“打开方式”。</p><h2>小结</h2><p>这节课，我们重点介绍了模型离线评估中使用的评估指标。我把它们分成了两部分，简单直接的低阶评估指标，还有复杂全面的高阶评估指标。</p><p>低阶评估指标主要包括准确率，精确率，召回率和均方根误差。<strong>准确率是指分类正确的样本占总样本个数的比例，精确率指的是分类正确的正样本个数占分类器判定为正样本个数的比例</strong>，<strong>召回率是分类正确的正样本个数占真正的正样本个数的比例，而均方根误差</strong>的定义是预测值跟真实值之间差值的均方根。</p><p>高阶指标包括P-R曲线，ROC曲线和平均精度均值。P-R曲线的横坐标是召回率，纵坐标是精确率；ROC曲线的横坐标是假阳性率，纵坐标是真阳性率。P-R曲线和ROC曲线的绘制都不容易，我希望你能多看几遍我在课程中讲的例子，巩固一下。最后是平均精度均值mAP，这个指标是对每个用户的精确率均值的再次平均。</p><p>最后，为了方便你记忆和对比，我也把所有指标的概念都总结在了文稿的表格里，你可以去看看。</p><p><img src=\"https://static001.geekbang.org/resource/image/e1/1a/e1a0566473b367633f0d18346608661a.jpeg?wh=1920*1080\" alt=\"\"></p><h2>课后问题</h2><p>对于我们今天学到的P-R曲线和ROC曲线，你觉得它们的优缺点分别是什么呢？在正负样本分布极不均衡的情况下，你觉得哪个曲线的表现会更稳定、更权威一点？</p><p>期待在留言区看到你对这节课的思考，我们下节课见！</p>","neighbors":{"left":{"article_title":"24 | 离线评估：常用的推荐系统离线评估方法有哪些？","id":317319},"right":{"article_title":"特别加餐｜TensorFlow的模型离线评估实践怎么做？","id":319768}},"comments":[{"had_liked":false,"id":270120,"user_name":"Geek_b86285","can_delete":false,"product_type":"c1","uid":2164898,"ip_address":"","ucode":"78AF704922A5D4","user_header":"https://static001.geekbang.org/account/avatar/00/21/08/a2/346431a9.jpg","comment_is_top":false,"comment_ctime":1608939754,"is_pvip":false,"replies":[{"id":"97895","content":"非常好，这也是我们实验和实践中更喜欢用ROC的原因。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1608959235,"ip_address":"","comment_id":270120,"utype":1}],"discussion_count":3,"race_medal":0,"score":"130457958634","product_id":100060801,"comment_content":"ROC曲线，FPR=FP​&#47;N,TPR=TP​&#47;P，当我们将负样本复制10倍时，TPR显然不会变，FPR是负样本中被预测为正样本的比例，这其实也是不变的，那整个ROC曲线也就没有变。PR曲线，精确率P=TP&#47;(TP+FP)，TP不变，FP增大，而召回率R没有变，显然ROC曲线更稳定一些","like_count":31,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":512524,"discussion_content":"非常好，这也是我们实验和实践中更喜欢用ROC的原因。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1608959235,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2156292,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/4icayE3ic5IA7RWwZcrxpMZE4T1WViakEgPsDC3UnhZwU83ad65IjmxPficy0vNZz6Q6vCiclnmyBDc5IYf7soHAXrQ/132","nickname":"Geek_790c43","note":"","ucode":"FFFAE0636A91EF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":379262,"discussion_content":"是的因为复制10遍，第一遍fp第二遍还是fp，所以fp也是十倍。 所以precision时候fp增加了十倍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1623795966,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2417428,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q3auHgzwzM63HXWOkicDuxKlwdEbzyCialRZWrjxJDFMicBahQlSQW5ibXcfYHnkpocb4SDPvBZ1M1VzBxK2bIlgVQ/132","nickname":"Geek_d44f3c","note":"","ucode":"961D7F6BBC9C01","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":374780,"discussion_content":"为什么负样本复制十倍时，FPR不变呢？ 这时候N变成了十倍，是假定FP也变成了十倍吗","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1621345292,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":266744,"user_name":"张弛 Conor","can_delete":false,"product_type":"c1","uid":2208459,"ip_address":"","ucode":"193EBA4A64BAB3","user_header":"https://static001.geekbang.org/account/avatar/00/21/b2/cb/9c6c7bf7.jpg","comment_is_top":false,"comment_ctime":1607477538,"is_pvip":false,"replies":[{"id":"96916","content":"非常好。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1607560480,"ip_address":"","comment_id":266744,"utype":1}],"discussion_count":4,"race_medal":0,"score":"53147085090","product_id":100060801,"comment_content":"P-R曲线的优点是能够表现精确率与召回率平衡的过程，缺点是无法显示明确的阈值，且缺乏对TN的考量。ROC曲线不仅能表现假阳性率与真阳性率的平衡，还可以表现出具体的阈值，也考量了TN，但缺乏对FN的考量。在正负样本不均衡的情况下，FN会较大，FP会较小，因此正样本性能的改进主要在于降低FN，P-R曲线中的召回率更关注FN，所以使用P-R曲线更好。","like_count":13,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":511371,"discussion_content":"非常好。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1607560480,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1658932,"avatar":"https://static001.geekbang.org/account/avatar/00/19/50/34/172342fd.jpg","nickname":"吴十一","note":"","ucode":"47232ED3225081","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":342421,"discussion_content":"在正负样本不均衡的情况下，FN会较大，FP会较小，因此正样本性能的改进主要在于降低FN，P-R曲线中的召回率更关注FN，所以使用P-R曲线更好\n-----------ROC曲线里面TPR就是召回率，如果是因为更关注FN，ROC曲线不也可以么？为啥说因为关注FN所以P-R曲线更好呢？","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1610678737,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2208459,"avatar":"https://static001.geekbang.org/account/avatar/00/21/b2/cb/9c6c7bf7.jpg","nickname":"张弛 Conor","note":"","ucode":"193EBA4A64BAB3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":343177,"discussion_content":"谢谢指出的问题！真阳率中确实包含了对FN的考量，其实主要比较的应该是ROC的假阳率和P-R的精确率，我是觉得在样本不均衡的情况，重点在于改善FP，但是由于TN可能较大，所以假阳率并不能很敏感的反应FP的改善，但是P-R的精确率可能会更敏感的反馈FP的变化。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1610962303,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2414687,"avatar":"","nickname":"Geek_f30bcb","note":"","ucode":"69996919542668","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":348973,"discussion_content":"roc 是不受样本不均匀影响的。 ","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1612831694,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":294433,"user_name":"PatrickPro2","can_delete":false,"product_type":"c1","uid":1868000,"ip_address":"","ucode":"DAF4F0EBF27762","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/9A1GRhjFcicWeSs9SmA1ib7Ft0017LLdgIw6o9q1hzmD7rX8PYTHZ2gaC3xn0CdlGriaoGPqpqGDk7UTjfZTHKrHg/132","comment_is_top":false,"comment_ctime":1621940139,"is_pvip":false,"replies":[{"id":"108153","content":"离线主要用AUC和gAUC。但工业界离线指标主要是参考作用，最重要的还是在线指标。<br><br>diversity比较重要，但一般是secondary metric，一般不作为主要优化的指标","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1623875989,"ip_address":"","comment_id":294433,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18801809323","product_id":100060801,"comment_content":"老师，工业界在用指标评估排序列表结果时，最最常用的指标是啥？我上学期上了cmu的搜索引擎这门课，我们教授说MAP和NDCG是最常用的，其中NDCG应该是效果最好的，因为NDCG考虑到了每个数的实际相关性和模型预测出的排序顺序。<br>我还有个问题：Diversity在推荐系统中重要吗？如果重要的话，是不是除了以上这些指标，还需要用到诸如Precision-Intent aware@K和alpha-NDCG这些指标进一步分析模型效果呢？","like_count":5,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":520651,"discussion_content":"离线主要用AUC和gAUC。但工业界离线指标主要是参考作用，最重要的还是在线指标。\n\ndiversity比较重要，但一般是secondary metric，一般不作为主要优化的指标","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1623875989,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":267047,"user_name":"那时刻","can_delete":false,"product_type":"c1","uid":1150927,"ip_address":"","ucode":"B0D150856C3A4A","user_header":"https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg","comment_is_top":false,"comment_ctime":1607581332,"is_pvip":false,"replies":[{"id":"96978","content":"赞","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1607649461,"ip_address":"","comment_id":267047,"utype":1}],"discussion_count":1,"race_medal":1,"score":"14492483220","product_id":100060801,"comment_content":"提供一个通过confusion matrix理解precision，recall， roc的文章，https:&#47;&#47;www.biostat.wisc.edu&#47;~page&#47;rocpr.pdf，大家可以参考一下","like_count":3,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":511494,"discussion_content":"赞","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1607649461,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":266825,"user_name":"Sebastian","can_delete":false,"product_type":"c1","uid":1797634,"ip_address":"","ucode":"62E6FC13DB00E3","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/55lYKUdcPFgUHibRYmaRiaBdrsmnLGOHdPp4OicjBh197X0vyGa9qAwruEqicAPuUgibXO4Lz5jLudlcbtsqq2p3CpA/132","comment_is_top":false,"comment_ctime":1607498761,"is_pvip":false,"replies":[{"id":"96912","content":"这个问题还挺有意思。当然是没有标准了，你想怎么比较都行，越是fine grain比较，越能比出东西。<br><br>像你说的情况，我们居然发现两个模型在不同时段的效果有不同，如果这个pattern比较固定的话，为什么我们不能把他们综合起来使用，形成一个time based model呢？这不是我们通过评估发现的改进点吗？","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1607560368,"ip_address":"","comment_id":266825,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14492400649","product_id":100060801,"comment_content":"老师，想额外问一个关于CTR指标计算的问题：在AB测试中，如何合理的比较AB测试中两者的CTR指标呢？会不会一天内，某个时间段A桶的CTR高于B桶，但是某个时间段A桶又小于B桶，那这种该如何比较AB哪个算法更好？","like_count":4,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":511404,"discussion_content":"这个问题还挺有意思。当然是没有标准了，你想怎么比较都行，越是fine grain比较，越能比出东西。\n\n像你说的情况，我们居然发现两个模型在不同时段的效果有不同，如果这个pattern比较固定的话，为什么我们不能把他们综合起来使用，形成一个time based model呢？这不是我们通过评估发现的改进点吗？","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1607560368,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":279254,"user_name":"小强","can_delete":false,"product_type":"c1","uid":2398148,"ip_address":"","ucode":"C3D1215867302D","user_header":"https://static001.geekbang.org/account/avatar/00/24/97/c4/6c92c78a.jpg","comment_is_top":false,"comment_ctime":1613696978,"is_pvip":false,"replies":[{"id":"101708","content":"正样本比较好说，就是你定义的一些正向的行为，比如点击、播放、购买等等。负样本其实看你的选择了，有纯random的，也有曝光未点击等等。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1614046295,"ip_address":"","comment_id":279254,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10203631570","product_id":100060801,"comment_content":"在实际工作中，一般是如何定义正样本和负样本的呢？首先，这个正样本和负样本应该是应用户而异吧？其次，以电影推荐为例，对于某个用户A，我们是把用户A之前看过的电影都定义成正样本，然后没有看过的电影都标记为负样本嘛？还是有其他什么方法？","like_count":2,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":515678,"discussion_content":"正样本比较好说，就是你定义的一些正向的行为，比如点击、播放、购买等等。负样本其实看你的选择了，有纯random的，也有曝光未点击等等。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1614046295,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":267304,"user_name":"JustDoDT","can_delete":false,"product_type":"c1","uid":1127175,"ip_address":"","ucode":"6AF0B80F00EAEF","user_header":"https://static001.geekbang.org/account/avatar/00/11/33/07/8f351609.jpg","comment_is_top":false,"comment_ctime":1607675732,"is_pvip":false,"replies":[{"id":"97066","content":"ROC曲线，P-R曲线是对全量样本在一起排序，不区分用户，所以这里说是全量数据。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1607714950,"ip_address":"","comment_id":267304,"utype":1}],"discussion_count":2,"race_medal":0,"score":"10197610324","product_id":100060801,"comment_content":"个性化推荐，不是每个人的推荐结果都不一样吗。为啥说ROC、P-R是全量数据，我认为是针对每个人的全量物品推荐，文中的全量是指全量物品吗。mAP严格意义上说是用到了全量的用户和物品。","like_count":2,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":511590,"discussion_content":"ROC曲线，P-R曲线是对全量样本在一起排序，不区分用户，所以这里说是全量数据。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1607714950,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1127175,"avatar":"https://static001.geekbang.org/account/avatar/00/11/33/07/8f351609.jpg","nickname":"JustDoDT","note":"","ucode":"6AF0B80F00EAEF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":334077,"discussion_content":"懂了，但是具体提怎么操作代码还是不知道咋写。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1607737738,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":266761,"user_name":"那时刻","can_delete":false,"product_type":"c1","uid":1150927,"ip_address":"","ucode":"B0D150856C3A4A","user_header":"https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg","comment_is_top":false,"comment_ctime":1607481010,"is_pvip":false,"replies":[{"id":"96915","content":"是这样，如果有好的文章可以分享到留言区。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1607560458,"ip_address":"","comment_id":266761,"utype":1}],"discussion_count":1,"race_medal":1,"score":"10197415602","product_id":100060801,"comment_content":"感觉通过confusion matrix（混淆矩阵）理解precision，recall以及TPR，FPR会更加形象些","like_count":2,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":511378,"discussion_content":"是这样，如果有好的文章可以分享到留言区。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1607560458,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":316872,"user_name":"飞行器","can_delete":false,"product_type":"c1","uid":1887856,"ip_address":"","ucode":"B76D1914306B42","user_header":"","comment_is_top":false,"comment_ctime":1634583394,"is_pvip":false,"replies":[{"id":"114737","content":"比如一个点击率预估问题，所有点击样本就是所有的真正正样本的个数。<br><br>当然你无法列出真正的ground true，只能通过历史数据来评估。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1634604960,"ip_address":"","comment_id":316872,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5929550690","product_id":100060801,"comment_content":"老师好，召回率（Recall）是分类正确的正样本个数占真正的正样本个数的比例。但是在实际环境中对于召回率的计算比较困难吧，对于实际生产中海量的数据，很难找到所有真正正样本的个数吧？那如何进行离线评估召回率的计算呢？","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":528551,"discussion_content":"比如一个点击率预估问题，所有点击样本就是所有的真正正样本的个数。\n\n当然你无法列出真正的ground true，只能通过历史数据来评估。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1634604960,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":285192,"user_name":"努力学习","can_delete":false,"product_type":"c1","uid":2403862,"ip_address":"","ucode":"A0C4E599CF27D2","user_header":"","comment_is_top":false,"comment_ctime":1616661902,"is_pvip":false,"replies":[{"id":"103585","content":"这里面变量太多了，不同论文对于不同算法的实现方法肯定有细节上的差异，数据集，一些超参数的选取肯定也存在不同。所以在NDCG上表现不一致太正常了。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1616812479,"ip_address":"","comment_id":285192,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5911629198","product_id":100060801,"comment_content":"请问老师，归一化折扣累计收益（Normalized Discounted Cumulative Gain,NDCG）这个评价指标，我在看论文时发现 TOP K推荐随着K取值的增加，同几种算法在不同的论文里 NDCG有的随K增加而增加 有的随K增加而减小，请问这是什么原因？","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":517611,"discussion_content":"这里面变量太多了，不同论文对于不同算法的实现方法肯定有细节上的差异，数据集，一些超参数的选取肯定也存在不同。所以在NDCG上表现不一致太正常了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616812479,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":266821,"user_name":"fsc2016","can_delete":false,"product_type":"c1","uid":1255585,"ip_address":"","ucode":"5480F05703A974","user_header":"https://static001.geekbang.org/account/avatar/00/13/28/a1/fd2bfc25.jpg","comment_is_top":false,"comment_ctime":1607497721,"is_pvip":false,"replies":[{"id":"96913","content":"非常好","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1607560379,"ip_address":"","comment_id":266821,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5902465017","product_id":100060801,"comment_content":"在正负样本不均衡的情况下，roc曲线更加稳定和权威，更加稳定的反映模型本身的好坏。","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":511402,"discussion_content":"非常好","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1607560379,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":348074,"user_name":"jxxiao","can_delete":false,"product_type":"c1","uid":2866540,"ip_address":"","ucode":"801995ED5282EB","user_header":"","comment_is_top":false,"comment_ctime":1654705196,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1654705196","product_id":100060801,"comment_content":"以推荐业务为例，模型通常是以优化ctr和cvr为目标，但是业务指标可能是ARPU，这之间的gap怎么处理呢？","like_count":0},{"had_liked":false,"id":317808,"user_name":"飞行器","can_delete":false,"product_type":"c1","uid":1887856,"ip_address":"","ucode":"B76D1914306B42","user_header":"","comment_is_top":false,"comment_ctime":1634976395,"is_pvip":false,"replies":[{"id":"115469","content":"实际工作中也是用AUC，gAUC，logloss的方式评估，离线评估本身就是作为参考指数快速过滤一些不靠谱方案，不能想的太细，太完美化","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1635272367,"ip_address":"","comment_id":317808,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1634976395","product_id":100060801,"comment_content":"老师好，一个follow up的问题，就是当我们选取点击作为正样本的时候，是否会存在曝光偏差或者是不同用户点击不同的问题，即从用户A的角度考虑，item 1是点击作为正样本，但是从用户B考虑，item 1仅只是曝光样本，甚至对于用户B来说可能是一个hard case的负样本，那如果按照合并所有用户点击作为正样本进行评估的话（特别是recall），是否对于某一部分用户是没有代表性的？那如果采用类似gAUC的方式进行评估，数据又会太稀疏，正样本太少。对于这种情况，请教老师在实际工作中是否又一些经验可以借鉴？","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":528986,"discussion_content":"实际工作中也是用AUC，gAUC，logloss的方式评估，离线评估本身就是作为参考指数快速过滤一些不靠谱方案，不能想的太细，太完美化","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1635272367,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":313694,"user_name":"PiccoZ","can_delete":false,"product_type":"c1","uid":1058146,"ip_address":"","ucode":"6E34B1BF373DA0","user_header":"https://static001.geekbang.org/account/avatar/00/10/25/62/abb7bfe3.jpg","comment_is_top":false,"comment_ctime":1632622016,"is_pvip":false,"replies":[{"id":"113707","content":"现在的召回层也提倡按照最终的排序指标进行评估。但会更看重recall一些。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1632766708,"ip_address":"","comment_id":313694,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1632622016","product_id":100060801,"comment_content":"老师，这些评价指标是不是都针对精排，请问下召回侧应该使用什么评价指标呢","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527443,"discussion_content":"现在的召回层也提倡按照最终的排序指标进行评估。但会更看重recall一些。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1632766708,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":304720,"user_name":"Karty","can_delete":false,"product_type":"c1","uid":2692906,"ip_address":"","ucode":"7C754E1DE743B6","user_header":"https://static001.geekbang.org/account/avatar/00/29/17/2a/65c2b292.jpg","comment_is_top":false,"comment_ctime":1627566449,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1627566449","product_id":100060801,"comment_content":"老师您好，我想请教一下，新用户AUC较低，老用户AUC较高，一般是哪些原因造成的？","like_count":0},{"had_liked":false,"id":300410,"user_name":"小峰™ =エ=®","can_delete":false,"product_type":"c1","uid":1192678,"ip_address":"","ucode":"FA90A29D7C32F1","user_header":"https://static001.geekbang.org/account/avatar/00/12/32/e6/4417c3ce.jpg","comment_is_top":false,"comment_ctime":1625145376,"is_pvip":false,"replies":[{"id":"109386","content":"当然是可行的，非常常用的做法。但要在inference过程中做ctr calibration","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1626215411,"ip_address":"","comment_id":300410,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1625145376","product_id":100060801,"comment_content":"老师你好，针对现实数据集中点击率只有1~10%，训练集正负样本数量偏差的问题——使用样本平衡的方法，对负样本进行下采样来，最终实现训练集正负样本1:1，这样的方法是否可行？这样出来准确率是降低了，但模型对正样本的判定会更敏感些，不知道这样理解对不对？","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":522726,"discussion_content":"当然是可行的，非常常用的做法。但要在inference过程中做ctr calibration","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1626215411,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":1015918,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/80/6e/7f78292e.jpg","nickname":"无","note":"","ucode":"CF9F79815606F2","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":549701,"discussion_content":"请问做ctr calibration有些什么比较好的方法么? 或者参考资料?","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1644216383,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":522726,"ip_address":""},"score":549701,"extra":""}]}]},{"had_liked":false,"id":293760,"user_name":"idiot","can_delete":false,"product_type":"c1","uid":2526391,"ip_address":"","ucode":"D7A6E980B530B4","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/fcftgBsticCicEEkuzB0GTkHIocX62YVTSvnhR1c94sccj42lVaYXrmcZyhzUI3l9NcvuN1rXLhXt2eBrZZ0Tw7A/132","comment_is_top":false,"comment_ctime":1621524284,"is_pvip":true,"replies":[{"id":"106653","content":"一般是都有改进才进入线上实验。因为一般来说二者是有较强相关性的。如果一个升一个降，证明不是特别显著。当然模型评估没有统一的标准答案，更多根据自己的判断。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1621704080,"ip_address":"","comment_id":293760,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1621524284","product_id":100060801,"comment_content":"“以AUC为主，补充分析mAP”，这里是怎么个标准呢？auc和map都有改进才到后续实验，还是都没有明显下降就到后续实验？如果是前者，有升有降怎么办？","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":520344,"discussion_content":"一般是都有改进才进入线上实验。因为一般来说二者是有较强相关性的。如果一个升一个降，证明不是特别显著。当然模型评估没有统一的标准答案，更多根据自己的判断。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1621704080,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":289086,"user_name":"小强","can_delete":false,"product_type":"c1","uid":2398148,"ip_address":"","ucode":"C3D1215867302D","user_header":"https://static001.geekbang.org/account/avatar/00/24/97/c4/6c92c78a.jpg","comment_is_top":false,"comment_ctime":1618849414,"is_pvip":false,"replies":[{"id":"105064","content":"不是非常常见，但经常使用hit rate来去做一些辅助问题的定位，比如embedding的覆盖率，新用户的比例和效果等等，不是首要的参考指标。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1619112448,"ip_address":"","comment_id":289086,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1618849414","product_id":100060801,"comment_content":"请问Hit Rate，Average Reciprocal Hit Rate这一组指标在工业界中应用的是否常见啊？","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":518814,"discussion_content":"不是非常常见，但经常使用hit rate来去做一些辅助问题的定位，比如embedding的覆盖率，新用户的比例和效果等等，不是首要的参考指标。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1619112448,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":275234,"user_name":"灯灯灯","can_delete":false,"product_type":"c1","uid":2402565,"ip_address":"","ucode":"A801439F74127C","user_header":"https://static001.geekbang.org/account/avatar/00/24/a9/05/6822b8a5.jpg","comment_is_top":false,"comment_ctime":1611401939,"is_pvip":false,"replies":[{"id":"99961","content":"不区分用户指的是把所有样本在一起排序生成ROC曲线","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1611550550,"ip_address":"","comment_id":275234,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1611401939","product_id":100060801,"comment_content":"老师您好， 我还是不理解 ‘’ROC曲线，P-R曲线是对全量样本在一起排序，不区分用户‘’。不区分用户的话样本的真实标签如何确定呢？","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":514274,"discussion_content":"不区分用户指的是把所有样本在一起排序生成ROC曲线","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1611550550,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":267521,"user_name":"SecooHR","can_delete":false,"product_type":"c1","uid":2137388,"ip_address":"","ucode":"01C559CBEE207A","user_header":"","comment_is_top":false,"comment_ctime":1607783947,"is_pvip":false,"replies":[{"id":"97162","content":"是的，这里确实有笔误。会尽快更正，多谢！","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1607803074,"ip_address":"","comment_id":267521,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1607783947","product_id":100060801,"comment_content":"文章的FP 定义不对吧， FP 指的是 N 个负样本中被分类器预测为正样本的个数。<br><br>另外 P-R  ROC 可以参考 这个 http:&#47;&#47;blog.sina.com.cn&#47;s&#47;blog_17b9e19320102x7ru.html  ","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":511667,"discussion_content":"是的，这里确实有笔误。会尽快更正，多谢！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1607803074,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":267303,"user_name":"JustDoDT","can_delete":false,"product_type":"c1","uid":1127175,"ip_address":"","ucode":"6AF0B80F00EAEF","user_header":"https://static001.geekbang.org/account/avatar/00/11/33/07/8f351609.jpg","comment_is_top":false,"comment_ctime":1607675128,"is_pvip":false,"replies":[{"id":"97065","content":"右上角的TRP是 TP&#47;P = 1 因为右上角的TP的值一定等于P","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1607714914,"ip_address":"","comment_id":267303,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1607675128","product_id":100060801,"comment_content":"ROC曲线右上角的TRP是0÷0=1，可以这么理解吗。","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":511589,"discussion_content":"右上角的TRP是 TP/P = 1 因为右上角的TP的值一定等于P","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1607714914,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]}]}