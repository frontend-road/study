{"id":734943,"title":"24｜Rust图像识别：利用YOLOv8识别对象","content":"<p>你好，我是Mike。这节课我们来学习如何使用Rust对图片中的对象进行识别。</p><p>图像识别是计算机视觉领域中的重要课题，而计算机视觉又是AI的重要组成部分，相当于AI的眼睛。目前图像识别领域使用最广泛的框架是 YOLO，现在已经迭代到了v8版本。而基于Rust机器学习框架Candle，可以方便地实现YOLOv8算法。因此，这节课我们继续使用Candle框架来实现图片的识别。</p><p>Candle框架有一个示例，演示了YOLOv8的一个简化实现。我在此基础上，将这个源码中的示例独立出来，做成了一个单独的项目，方便你学习（查看<a href=\"https://github.com/miketang84/jikeshijian/tree/master/24-candle_yolov8\">代码地址</a>）。</p><p><span class=\"reference\">注：这节课的代码适用于 candle_core v0.3 版本。</span></p><h2>YOLO简介</h2><p>YOLO（You Only Look Once）是一种目标检测算法，它可以在一次前向传递中检测出图像中的所有物体的位置和类别。因为只需要看一次，YOLO被称为Region-free方法，相比于Region-based方法，YOLO不需要提前找到可能存在目标的区域（Region）。YOLO在2016年被提出，发表在计算机视觉顶会CVPR（Computer Vision and Pattern Recognition）上。YOLO对整个图片进行预测，并且它会一次性输出所有检测到的目标信息，包括类别和位置。</p><!-- [[[read_end]]] --><p>YOLO也使用神经网络进行图像识别，一般来说，如果是推理的话，我们需要一个神经网络的预训练模型文件。下面你会看到，在运行示例的时候，会自动从HuggingFace下载对应的预训练模型。</p><p>YOLOv8的模型结构比起之前的版本，会复杂一些，我们来看一下官方整理的图片。</p><p><img src=\"https://static001.geekbang.org/resource/image/9e/18/9eaeb50e93568443412d894bcfe87018.jpg?wh=3250x3402\" alt=\"\" title=\"图片来源：https://github.com/ultralytics/ultralytics/issues/189\"></p><p>这节课我们主要是去使用，不展开关于这个模型的讲解。目前官方的预训练模型分成5个。</p><ul>\n<li>N：nano。模型最小。探测速度最快，精度最低。</li>\n<li>S：small，模型比nano大。</li>\n<li>M：middle，模型比small大。</li>\n<li>L：large，模型比middle大，比x小。</li>\n<li>X：extra large，模型最大。探测速度最慢，精度最高。</li>\n</ul><p>在下面的示例中，我们可以通过参数来指定选择哪个模型。</p><h2>YOLOv8的能力</h2><p>YOLO发展到第8代已经很强大了。它可以对图像做分类、探测、分段、轨迹、姿势等。</p><p><img src=\"https://static001.geekbang.org/resource/image/a2/01/a26647d656430b8574405c35bcd94b01.png?wh=1920x480\" alt=\"图片\" title=\"图片来源：https://raw.githubusercontent.com/ultralytics/assets/main/im/banner-tasks.png\"></p><p>了解了YOLO的能力，下面我们开始实际用起来。</p><h2>动手实验</h2><p>下载源码：</p><pre><code class=\"language-plain\">git clone https://github.com/miketang84/jikeshijian\ncd jikeshijian/24-candle_yolov8\n</code></pre><h3>物体探测</h3><p>假设我们有这样一张图片。</p><p><img src=\"https://static001.geekbang.org/resource/image/44/b8/44442ec72a66cf7c88dd4be951d043b8.jpg?wh=800x533\" alt=\"图片\"></p><p>编译运行下面这行代码。</p><pre><code class=\"language-plain\">cargo run --release -- assets/football.jpg --which m\n</code></pre><p>请注意，这个运行过程中，会联网从HuggingFace上下载模型文件，需要科学上网环境。</p><p>运行输出：</p><pre><code class=\"language-plain\">$ cargo run --release -- assets/football.jpg --which m\nProxyChains-3.1 (http://proxychains.sf.net)\n&nbsp; &nbsp; Finished release [optimized] target(s) in 0.08s\n&nbsp; &nbsp; &nbsp;Running `target/release/candle_demo_yolov8 assets/football.jpg --which m`\nRunning on CPU, to run on GPU, build this example with `--features cuda`\nmodel loaded\nprocessing assets/football.jpg\ngenerated predictions Tensor[dims 84, 5460; f32]\nperson: Bbox { xmin: 0.15629578, ymin: 81.735344, xmax: 99.46689, ymax: 281.7202, confidence: 0.94353473, data: [] }\nperson: Bbox { xmin: 433.88196, ymin: 92.59643, xmax: 520.25476, ymax: 248.76715, confidence: 0.933658, data: [] }\nperson: Bbox { xmin: 569.20465, ymin: 34.737877, xmax: 639.8049, ymax: 269.4999, confidence: 0.927611, data: [] }\nperson: Bbox { xmin: 209.33649, ymin: 16.313568, xmax: 388.09424, ymax: 388.7763, confidence: 0.92696583, data: [] }\nperson: Bbox { xmin: 169.212, ymin: 15.2717285, xmax: 312.59946, ymax: 345.16046, confidence: 0.900463, data: [] }\nperson: Bbox { xmin: 626.709, ymin: 65.91608, xmax: 639.791, ymax: 86.72856, confidence: 0.33487964, data: [] }\nsports ball: Bbox { xmin: 417.45734, ymin: 315.16333, xmax: 484.62384, ymax: 372.86432, confidence: 0.93880117, data: [] }\nwriting \"assets/football.pp.jpg\"\n</code></pre><p>在 assets 目录下生成 football.pp.jpg 文件，打开后效果如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/da/07/da8d52a0e6677977701cfe339d2d3007.jpg?wh=800x533\" alt=\"图片\"></p><p>可以看到，Yolo 正确识别了6个人，和一个运动球。</p><h3>姿势探测</h3><p>我们来看一下，对同一张图片，运行姿势探测的效果。</p><pre><code class=\"language-plain\">cargo run --release -- assets/football.jpg --which m --task pose\n</code></pre><p>我们的工具在 assets 目录下生成 football.pp.jpg 文件，打开后效果如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/72/25/7239ed2af26ed0908560833838696025.png?wh=800x533\" alt=\"图片\"></p><p>效果是不是很cool。下面我们详细解释一下这次实战的代码。</p><h2>源码解释</h2><p>YOLOv8 神经网络模型的原理比较复杂，这节课我们主要讲解这个示例中Rust的用法，从中可以学到不少Rust相关知识。</p><pre><code class=\"language-plain\">// #[cfg(feature = \"mkl\")]\n// extern crate intel_mkl_src;\n\n// #[cfg(feature = \"accelerate\")]\n// extern crate accelerate_src;\n\nmod model;\nuse model::{Multiples, YoloV8, YoloV8Pose};\nmod coco_classes;\n\nuse candle_core::utils::{cuda_is_available, metal_is_available};\nuse candle_core::{DType, Device, IndexOp, Result, Tensor};\nuse candle_nn::{Module, VarBuilder};\nuse candle_transformers::object_detection::{non_maximum_suppression, Bbox, KeyPoint};\nuse clap::{Parser, ValueEnum};\nuse image::DynamicImage;\n\n// Keypoints as reported by ChatGPT :)\n// Nose\n// Left Eye\n// Right Eye\n// Left Ear\n// Right Ear\n// Left Shoulder\n// Right Shoulder\n// Left Elbow\n// Right Elbow\n// Left Wrist\n// Right Wrist\n// Left Hip\n// Right Hip\n// Left Knee\n// Right Knee\n// Left Ankle\n// Right Ankle\nconst KP_CONNECTIONS: [(usize, usize); 16] = [\n&nbsp; &nbsp; (0, 1),\n&nbsp; &nbsp; (0, 2),\n&nbsp; &nbsp; (1, 3),\n&nbsp; &nbsp; (2, 4),\n&nbsp; &nbsp; (5, 6),\n&nbsp; &nbsp; (5, 11),\n&nbsp; &nbsp; (6, 12),\n&nbsp; &nbsp; (11, 12),\n&nbsp; &nbsp; (5, 7),\n&nbsp; &nbsp; (6, 8),\n&nbsp; &nbsp; (7, 9),\n&nbsp; &nbsp; (8, 10),\n&nbsp; &nbsp; (11, 13),\n&nbsp; &nbsp; (12, 14),\n&nbsp; &nbsp; (13, 15),\n&nbsp; &nbsp; (14, 16),\n];\n\n\n\n// 获取设备，Cpu还是Cuda或Metal\npub fn get_device(cpu: bool) -&gt; Result&lt;Device&gt; {\n&nbsp; &nbsp; if cpu {\n&nbsp; &nbsp; &nbsp; &nbsp; Ok(Device::Cpu)\n&nbsp; &nbsp; } else if cuda_is_available() {\n&nbsp; &nbsp; &nbsp; &nbsp; Ok(Device::new_cuda(0)?)\n&nbsp; &nbsp; } else if metal_is_available() {\n&nbsp; &nbsp; &nbsp; &nbsp; Ok(Device::new_metal(0)?)\n&nbsp; &nbsp; } else {\n&nbsp; &nbsp; &nbsp; &nbsp; #[cfg(all(target_os = \"macos\", target_arch = \"aarch64\"))]\n&nbsp; &nbsp; &nbsp; &nbsp; {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; println!(\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"Running on CPU, to run on GPU(metal), build this example with `--features metal`\"\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; );\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; #[cfg(not(all(target_os = \"macos\", target_arch = \"aarch64\")))]\n&nbsp; &nbsp; &nbsp; &nbsp; {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; println!(\"Running on CPU, to run on GPU, build this example with `--features cuda`\");\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; Ok(Device::Cpu)\n&nbsp; &nbsp; }\n}\n// 报告对象探测的结果，以及用图像处理工具在图上画出来标注\npub fn report_detect(\n&nbsp; &nbsp; pred: &amp;Tensor,\n&nbsp; &nbsp; img: DynamicImage,\n&nbsp; &nbsp; w: usize,\n&nbsp; &nbsp; h: usize,\n&nbsp; &nbsp; confidence_threshold: f32,\n&nbsp; &nbsp; nms_threshold: f32,\n&nbsp; &nbsp; legend_size: u32,\n) -&gt; Result&lt;DynamicImage&gt; {\n&nbsp; &nbsp; let pred = pred.to_device(&amp;Device::Cpu)?;\n&nbsp; &nbsp; let (pred_size, npreds) = pred.dims2()?;\n&nbsp; &nbsp; let nclasses = pred_size - 4;\n&nbsp; &nbsp; \n&nbsp; &nbsp; let mut bboxes: Vec&lt;Vec&lt;Bbox&lt;Vec&lt;KeyPoint&gt;&gt;&gt;&gt; = (0..nclasses).map(|_| vec![]).collect();\n&nbsp; &nbsp; // 选出符合置信区间的结果\n&nbsp; &nbsp; for index in 0..npreds {\n&nbsp; &nbsp; &nbsp; &nbsp; let pred = Vec::&lt;f32&gt;::try_from(pred.i((.., index))?)?;\n&nbsp; &nbsp; &nbsp; &nbsp; let confidence = *pred[4..].iter().max_by(|x, y| x.total_cmp(y)).unwrap();\n&nbsp; &nbsp; &nbsp; &nbsp; if confidence &gt; confidence_threshold {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; let mut class_index = 0;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; for i in 0..nclasses {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if pred[4 + i] &gt; pred[4 + class_index] {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; class_index = i\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if pred[class_index + 4] &gt; 0. {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; let bbox = Bbox {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; xmin: pred[0] - pred[2] / 2.,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ymin: pred[1] - pred[3] / 2.,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; xmax: pred[0] + pred[2] / 2.,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ymax: pred[1] + pred[3] / 2.,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; confidence,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; data: vec![],\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; };\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bboxes[class_index].push(bbox)\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; non_maximum_suppression(&amp;mut bboxes, nms_threshold);\n\n&nbsp; &nbsp; // 在原图上标注，并打印标注的框的信息\n&nbsp; &nbsp; let (initial_h, initial_w) = (img.height(), img.width());\n&nbsp; &nbsp; let w_ratio = initial_w as f32 / w as f32;\n&nbsp; &nbsp; let h_ratio = initial_h as f32 / h as f32;\n&nbsp; &nbsp; let mut img = img.to_rgb8();\n&nbsp; &nbsp; let font = Vec::from(include_bytes!(\"roboto-mono-stripped.ttf\") as &amp;[u8]);\n&nbsp; &nbsp; let font = rusttype::Font::try_from_vec(font);\n&nbsp; &nbsp; for (class_index, bboxes_for_class) in bboxes.iter().enumerate() {\n&nbsp; &nbsp; &nbsp; &nbsp; for b in bboxes_for_class.iter() {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; println!(\"{}: {:?}\", coco_classes::NAMES[class_index], b);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; let xmin = (b.xmin * w_ratio) as i32;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; let ymin = (b.ymin * h_ratio) as i32;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; let dx = (b.xmax - b.xmin) * w_ratio;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; let dy = (b.ymax - b.ymin) * h_ratio;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if dx &gt;= 0. &amp;&amp; dy &gt;= 0. {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; imageproc::drawing::draw_hollow_rect_mut(\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &amp;mut img,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; imageproc::rect::Rect::at(xmin, ymin).of_size(dx as u32, dy as u32),\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; image::Rgb([255, 0, 0]),\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; );\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if legend_size &gt; 0 {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if let Some(font) = font.as_ref() {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; imageproc::drawing::draw_filled_rect_mut(\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &amp;mut img,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; imageproc::rect::Rect::at(xmin, ymin).of_size(dx as u32, legend_size),\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; image::Rgb([170, 0, 0]),\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; );\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; let legend = format!(\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"{}&nbsp; &nbsp;{:.0}%\",\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; coco_classes::NAMES[class_index],\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 100. * b.confidence\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; );\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; imageproc::drawing::draw_text_mut(\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &amp;mut img,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; image::Rgb([255, 255, 255]),\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; xmin,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ymin,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; rusttype::Scale::uniform(legend_size as f32 - 1.),\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; font,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &amp;legend,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; )\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; }\n&nbsp; &nbsp; Ok(DynamicImage::ImageRgb8(img))\n}\n// 报告姿态探测的结果，以及用图像处理工具在图上画出来标注\npub fn report_pose(\n&nbsp; &nbsp; pred: &amp;Tensor,\n&nbsp; &nbsp; img: DynamicImage,\n&nbsp; &nbsp; w: usize,\n&nbsp; &nbsp; h: usize,\n&nbsp; &nbsp; confidence_threshold: f32,\n&nbsp; &nbsp; nms_threshold: f32,\n) -&gt; Result&lt;DynamicImage&gt; {\n&nbsp; &nbsp; let pred = pred.to_device(&amp;Device::Cpu)?;\n&nbsp; &nbsp; let (pred_size, npreds) = pred.dims2()?;\n&nbsp; &nbsp; if pred_size != 17 * 3 + 4 + 1 {\n&nbsp; &nbsp; &nbsp; &nbsp; candle_core::bail!(\"unexpected pred-size {pred_size}\");\n&nbsp; &nbsp; }\n&nbsp; &nbsp; let mut bboxes = vec![];\n&nbsp; &nbsp; // 选出符合置信区间的结果\n&nbsp; &nbsp; for index in 0..npreds {\n&nbsp; &nbsp; &nbsp; &nbsp; let pred = Vec::&lt;f32&gt;::try_from(pred.i((.., index))?)?;\n&nbsp; &nbsp; &nbsp; &nbsp; let confidence = pred[4];\n&nbsp; &nbsp; &nbsp; &nbsp; if confidence &gt; confidence_threshold {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; let keypoints = (0..17)\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .map(|i| KeyPoint {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; x: pred[3 * i + 5],\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; y: pred[3 * i + 6],\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; mask: pred[3 * i + 7],\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; })\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .collect::&lt;Vec&lt;_&gt;&gt;();\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; let bbox = Bbox {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; xmin: pred[0] - pred[2] / 2.,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ymin: pred[1] - pred[3] / 2.,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; xmax: pred[0] + pred[2] / 2.,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ymax: pred[1] + pred[3] / 2.,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; confidence,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; data: keypoints,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; };\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bboxes.push(bbox)\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; let mut bboxes = vec![bboxes];\n&nbsp; &nbsp; non_maximum_suppression(&amp;mut bboxes, nms_threshold);\n&nbsp; &nbsp; let bboxes = &amp;bboxes[0];\n\n&nbsp; &nbsp; // 在原图上标注，并打印标注的框和姿势的信息\n&nbsp; &nbsp; let (initial_h, initial_w) = (img.height(), img.width());\n&nbsp; &nbsp; let w_ratio = initial_w as f32 / w as f32;\n&nbsp; &nbsp; let h_ratio = initial_h as f32 / h as f32;\n&nbsp; &nbsp; let mut img = img.to_rgb8();\n&nbsp; &nbsp; for b in bboxes.iter() {\n&nbsp; &nbsp; &nbsp; &nbsp; println!(\"{b:?}\");\n&nbsp; &nbsp; &nbsp; &nbsp; let xmin = (b.xmin * w_ratio) as i32;\n&nbsp; &nbsp; &nbsp; &nbsp; let ymin = (b.ymin * h_ratio) as i32;\n&nbsp; &nbsp; &nbsp; &nbsp; let dx = (b.xmax - b.xmin) * w_ratio;\n&nbsp; &nbsp; &nbsp; &nbsp; let dy = (b.ymax - b.ymin) * h_ratio;\n&nbsp; &nbsp; &nbsp; &nbsp; if dx &gt;= 0. &amp;&amp; dy &gt;= 0. {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; imageproc::drawing::draw_hollow_rect_mut(\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &amp;mut img,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; imageproc::rect::Rect::at(xmin, ymin).of_size(dx as u32, dy as u32),\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; image::Rgb([255, 0, 0]),\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; );\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; for kp in b.data.iter() {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if kp.mask &lt; 0.6 {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; let x = (kp.x * w_ratio) as i32;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; let y = (kp.y * h_ratio) as i32;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; imageproc::drawing::draw_filled_circle_mut(\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &amp;mut img,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (x, y),\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 2,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; image::Rgb([0, 255, 0]),\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; );\n&nbsp; &nbsp; &nbsp; &nbsp; }\n\n&nbsp; &nbsp; &nbsp; &nbsp; for &amp;(idx1, idx2) in KP_CONNECTIONS.iter() {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; let kp1 = &amp;b.data[idx1];\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; let kp2 = &amp;b.data[idx2];\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if kp1.mask &lt; 0.6 || kp2.mask &lt; 0.6 {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; imageproc::drawing::draw_line_segment_mut(\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &amp;mut img,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (kp1.x * w_ratio, kp1.y * h_ratio),\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (kp2.x * w_ratio, kp2.y * h_ratio),\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; image::Rgb([255, 255, 0]),\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; );\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; }\n&nbsp; &nbsp; Ok(DynamicImage::ImageRgb8(img))\n}\n// 选择模型尺寸\n#[derive(Clone, Copy, ValueEnum, Debug)]\nenum Which {\n&nbsp; &nbsp; N,\n&nbsp; &nbsp; S,\n&nbsp; &nbsp; M,\n&nbsp; &nbsp; L,\n&nbsp; &nbsp; X,\n}\n// 对象探测任务还是姿势探测任务\n#[derive(Clone, Copy, ValueEnum, Debug)]\nenum YoloTask {\n&nbsp; &nbsp; Detect,\n&nbsp; &nbsp; Pose,\n}\n// 命令行参数定义，基于Clap\n#[derive(Parser, Debug)]\n#[command(author, version, about, long_about = None)]\npub struct Args {\n&nbsp; &nbsp; /// 是否运行在CPU上面\n&nbsp; &nbsp; #[arg(long)]\n&nbsp; &nbsp; cpu: bool,\n\n&nbsp; &nbsp; /// 是否记录日志\n&nbsp; &nbsp; #[arg(long)]\n&nbsp; &nbsp; tracing: bool,\n\n&nbsp; &nbsp; /// 模型文件路径\n&nbsp; &nbsp; #[arg(long)]\n&nbsp; &nbsp; model: Option&lt;String&gt;,\n\n&nbsp; &nbsp; /// 用哪一个模型\n&nbsp; &nbsp; #[arg(long, value_enum, default_value_t = Which::S)]\n&nbsp; &nbsp; which: Which,\n\n&nbsp; &nbsp; images: Vec&lt;String&gt;,\n\n&nbsp; &nbsp; /// 模型置信门槛\n&nbsp; &nbsp; #[arg(long, default_value_t = 0.25)]\n&nbsp; &nbsp; confidence_threshold: f32,\n\n&nbsp; &nbsp; /// non-maximum suppression的阈值\n&nbsp; &nbsp; #[arg(long, default_value_t = 0.45)]\n&nbsp; &nbsp; nms_threshold: f32,\n\n&nbsp; &nbsp; /// 要执行的任务\n&nbsp; &nbsp; #[arg(long, default_value = \"detect\")]\n&nbsp; &nbsp; task: YoloTask,\n\n&nbsp; &nbsp; /// 标注的字体的大小\n&nbsp; &nbsp; #[arg(long, default_value_t = 14)]\n&nbsp; &nbsp; legend_size: u32,\n}\n\nimpl Args {\n&nbsp; &nbsp; fn model(&amp;self) -&gt; anyhow::Result&lt;std::path::PathBuf&gt; {\n&nbsp; &nbsp; &nbsp; &nbsp; let path = match &amp;self.model {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Some(model) =&gt; std::path::PathBuf::from(model),\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; None =&gt; {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; let api = hf_hub::api::sync::Api::new()?;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; let api = api.model(\"lmz/candle-yolo-v8\".to_string());\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; let size = match self.which {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Which::N =&gt; \"n\",\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Which::S =&gt; \"s\",\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Which::M =&gt; \"m\",\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Which::L =&gt; \"l\",\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Which::X =&gt; \"x\",\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; };\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; let task = match self.task {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; YoloTask::Pose =&gt; \"-pose\",\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; YoloTask::Detect =&gt; \"\",\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; };\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; api.get(&amp;format!(\"yolov8{size}{task}.safetensors\"))?\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; };\n&nbsp; &nbsp; &nbsp; &nbsp; Ok(path)\n&nbsp; &nbsp; }\n}\n\npub trait Task: Module + Sized {\n&nbsp; &nbsp; fn load(vb: VarBuilder, multiples: Multiples) -&gt; Result&lt;Self&gt;;\n&nbsp; &nbsp; fn report(\n&nbsp; &nbsp; &nbsp; &nbsp; pred: &amp;Tensor,\n&nbsp; &nbsp; &nbsp; &nbsp; img: DynamicImage,\n&nbsp; &nbsp; &nbsp; &nbsp; w: usize,\n&nbsp; &nbsp; &nbsp; &nbsp; h: usize,\n&nbsp; &nbsp; &nbsp; &nbsp; confidence_threshold: f32,\n&nbsp; &nbsp; &nbsp; &nbsp; nms_threshold: f32,\n&nbsp; &nbsp; &nbsp; &nbsp; legend_size: u32,\n&nbsp; &nbsp; ) -&gt; Result&lt;DynamicImage&gt;;\n}\n// Yolov8为对象探测的类型载体\nimpl Task for YoloV8 {\n&nbsp; &nbsp; fn load(vb: VarBuilder, multiples: Multiples) -&gt; Result&lt;Self&gt; {\n&nbsp; &nbsp; &nbsp; &nbsp; YoloV8::load(vb, multiples, /* num_classes=*/ 80)\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; fn report(\n&nbsp; &nbsp; &nbsp; &nbsp; pred: &amp;Tensor,\n&nbsp; &nbsp; &nbsp; &nbsp; img: DynamicImage,\n&nbsp; &nbsp; &nbsp; &nbsp; w: usize,\n&nbsp; &nbsp; &nbsp; &nbsp; h: usize,\n&nbsp; &nbsp; &nbsp; &nbsp; confidence_threshold: f32,\n&nbsp; &nbsp; &nbsp; &nbsp; nms_threshold: f32,\n&nbsp; &nbsp; &nbsp; &nbsp; legend_size: u32,\n&nbsp; &nbsp; ) -&gt; Result&lt;DynamicImage&gt; {\n&nbsp; &nbsp; &nbsp; &nbsp; report_detect(\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pred,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; img,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; w,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; h,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; confidence_threshold,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; nms_threshold,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; legend_size,\n&nbsp; &nbsp; &nbsp; &nbsp; )\n&nbsp; &nbsp; }\n}\n// YoloV8Pose为姿势探测的类型载体\nimpl Task for YoloV8Pose {\n&nbsp; &nbsp; fn load(vb: VarBuilder, multiples: Multiples) -&gt; Result&lt;Self&gt; {\n&nbsp; &nbsp; &nbsp; &nbsp; YoloV8Pose::load(vb, multiples, /* num_classes=*/ 1, (17, 3))\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; fn report(\n&nbsp; &nbsp; &nbsp; &nbsp; pred: &amp;Tensor,\n&nbsp; &nbsp; &nbsp; &nbsp; img: DynamicImage,\n&nbsp; &nbsp; &nbsp; &nbsp; w: usize,\n&nbsp; &nbsp; &nbsp; &nbsp; h: usize,\n&nbsp; &nbsp; &nbsp; &nbsp; confidence_threshold: f32,\n&nbsp; &nbsp; &nbsp; &nbsp; nms_threshold: f32,\n&nbsp; &nbsp; &nbsp; &nbsp; _legend_size: u32,\n&nbsp; &nbsp; ) -&gt; Result&lt;DynamicImage&gt; {\n&nbsp; &nbsp; &nbsp; &nbsp; report_pose(pred, img, w, h, confidence_threshold, nms_threshold)\n&nbsp; &nbsp; }\n}\n// 主体运行逻辑\npub fn run&lt;T: Task&gt;(args: Args) -&gt; anyhow::Result&lt;()&gt; {\n&nbsp; &nbsp; let device = get_device(args.cpu)?;\n&nbsp; &nbsp; // 选择模型尺寸，加载模型权重参数进来\n&nbsp; &nbsp; let multiples = match args.which {\n&nbsp; &nbsp; &nbsp; &nbsp; Which::N =&gt; Multiples::n(),\n&nbsp; &nbsp; &nbsp; &nbsp; Which::S =&gt; Multiples::s(),\n&nbsp; &nbsp; &nbsp; &nbsp; Which::M =&gt; Multiples::m(),\n&nbsp; &nbsp; &nbsp; &nbsp; Which::L =&gt; Multiples::l(),\n&nbsp; &nbsp; &nbsp; &nbsp; Which::X =&gt; Multiples::x(),\n&nbsp; &nbsp; };\n&nbsp; &nbsp; let model = args.model()?;\n&nbsp; &nbsp; let vb = unsafe { VarBuilder::from_mmaped_safetensors(&amp;[model], DType::F32, &amp;device)? };\n&nbsp; &nbsp; let model = T::load(vb, multiples)?;\n&nbsp; &nbsp; println!(\"model loaded\");\n&nbsp; &nbsp; for image_name in args.images.iter() {\n&nbsp; &nbsp; &nbsp; &nbsp; println!(\"processing {image_name}\");\n&nbsp; &nbsp; &nbsp; &nbsp; let mut image_name = std::path::PathBuf::from(image_name);\n&nbsp; &nbsp; &nbsp; &nbsp; let original_image = image::io::Reader::open(&amp;image_name)?\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .decode()\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .map_err(candle_core::Error::wrap)?;\n&nbsp; &nbsp; &nbsp; &nbsp; let (width, height) = {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; let w = original_image.width() as usize;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; let h = original_image.height() as usize;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if w &lt; h {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; let w = w * 640 / h;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; // \n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (w / 32 * 32, 640)\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; } else {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; let h = h * 640 / w;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (640, h / 32 * 32)\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; };\n&nbsp; &nbsp; &nbsp; &nbsp; let image_t = {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; let img = original_image.resize_exact(\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; width as u32,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; height as u32,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; image::imageops::FilterType::CatmullRom,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; );\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; let data = img.to_rgb8().into_raw();\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Tensor::from_vec(\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; data,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (img.height() as usize, img.width() as usize, 3),\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &amp;device,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; )?\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .permute((2, 0, 1))?\n&nbsp; &nbsp; &nbsp; &nbsp; };\n&nbsp; &nbsp; &nbsp; &nbsp; let image_t = (image_t.unsqueeze(0)?.to_dtype(DType::F32)? * (1. / 255.))?;\n&nbsp; &nbsp; &nbsp; &nbsp; let predictions = model.forward(&amp;image_t)?.squeeze(0)?;\n&nbsp; &nbsp; &nbsp; &nbsp; println!(\"generated predictions {predictions:?}\");\n&nbsp; &nbsp; &nbsp; &nbsp; let image_t = T::report(\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &amp;predictions,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; original_image,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; width,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; height,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; args.confidence_threshold,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; args.nms_threshold,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; args.legend_size,\n&nbsp; &nbsp; &nbsp; &nbsp; )?;\n&nbsp; &nbsp; &nbsp; &nbsp; image_name.set_extension(\"pp.jpg\");\n&nbsp; &nbsp; &nbsp; &nbsp; println!(\"writing {image_name:?}\");\n&nbsp; &nbsp; &nbsp; &nbsp; image_t.save(image_name)?\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; Ok(())\n}\n// 程序入口\npub fn main() -&gt; anyhow::Result&lt;()&gt; {\n&nbsp; &nbsp; use tracing_chrome::ChromeLayerBuilder;\n&nbsp; &nbsp; use tracing_subscriber::prelude::*;\n\n&nbsp; &nbsp; let args = Args::parse();\n\n&nbsp; &nbsp; let _guard = if args.tracing {\n&nbsp; &nbsp; &nbsp; &nbsp; let (chrome_layer, guard) = ChromeLayerBuilder::new().build();\n&nbsp; &nbsp; &nbsp; &nbsp; tracing_subscriber::registry().with(chrome_layer).init();\n&nbsp; &nbsp; &nbsp; &nbsp; Some(guard)\n&nbsp; &nbsp; } else {\n&nbsp; &nbsp; &nbsp; &nbsp; None\n&nbsp; &nbsp; };\n\n&nbsp; &nbsp; match args.task {\n&nbsp; &nbsp; &nbsp; &nbsp; YoloTask::Detect =&gt; run::&lt;YoloV8&gt;(args)?,\n&nbsp; &nbsp; &nbsp; &nbsp; YoloTask::Pose =&gt; run::&lt;YoloV8Pose&gt;(args)?,\n&nbsp; &nbsp; }\n&nbsp; &nbsp; Ok(())\n}\n</code></pre><p>我挑选里面一些重要的内容来讲解一下。</p><p>第7～8行，加载模型模块。YOLOv8的模型实现都放在这里面，它在Candle的平台基础上实现了一个简易版本的 Darknet 神经网络引擎。第9行，加载coco数据集分类表。YOLOv8对数据分成80种类别。你可以打开 coco_classes.rs 文件查看。</p><p>第11～14行，引入 Candle 基础组件。第15行引用clap赋能命令行功能。这个在上一讲中已经讲过了。第16行引入 image crate。我们在这个例子里处理图片使用的是 image 和 imageproc 两个 crate。</p><p>第36～53行是人体姿势的参数配置 ‎KP_CONNECTIONS。</p><p>第57～77行，是在 candle 中获取能使用的设备的函数。可以看到，Linux和Windows下我们可以使用 CUDA，mac下我们可以使用 Metal。</p><p>第79～167行，report_detect 是第一个任务，对象探测的业务代码。第169～258行，report_pose 是第二个任务，姿势探测的业务代码。这两个任务我们等会儿还会再说到。</p><p>第260～267行，定义选用哪个模型，分别对应前面讲到的 N、S、M、L、X。第269～273行，定义对象探测和姿势探测两个不同的任务。第275～311行，定义命令行参数对象Args，你可以关注一下各个字段的默认值。第313～336行，定义model函数，实际是加载到模型的正确路径，如果本地没有，就会从HuggingFace上下载。</p><p>第338～349行，定义Task trait，它依赖另外两个trait：Module和Sized。Module来自 <a href=\"https://docs.rs/candle-nn/latest/candle_nn/trait.Module.html\">candle_nn crate</a>，表示神经网络中的一个模块，有向前推理forward的功能。Sized来自 <a href=\"https://doc.rust-lang.org/std/marker/trait.Sized.html\">Rust std 标准库</a>，表示被实现的类型是固定尺寸的。</p><p>第351～375行，为YOLOv8实现Task trait，YOLOv8 就是我们用于目标探测的任务承载类型。第377～393，为YOLOv8Pose实现Task trait，YOLOv8Pose就是我们用于姿势探测的任务承载类型。</p><p>第395～459行是业务内容。第461～480行是main函数，里面做了一些日志配置，并且根据任务类型分配到YOLOv8或YOLOv8Pose两个不同的任务去。</p><p>我们看到，这里使用了 <code>run::&lt;YoloV8&gt;(args)</code> 这种写法，再对照run的函数签名：</p><pre><code class=\"language-plain\">pub fn run&lt;T: Task&gt;(args: Args) -&gt; anyhow::Result&lt;()&gt; {\n</code></pre><p>这个函数签名中有一个类型参数T，被Task约束。根据<a href=\"https://time.geekbang.org/column/article/724776\">第 10 讲</a>的内容，我们可以说类型T具有Task的能力。<code>::&lt;&gt;</code> 是 turbofish 语法，用来将具体的类型传递进函数的类型参数中。</p><p>进入 <code>run()</code> 函数中，我们继续看。第405、406行，根据指定的不同的模型，将预训练模型的内容加载成 model 实例。第407行有个 <code>T::load()</code> 写法，实际就是 YOLOv8 和 YOLOv8Pose 上都实现了 <code>load()</code> 关联函数，它定义在Task trait中。</p><p>然后第409行可以批量对多个图片进行操作，这个需要你在命令行中传参数指定。我们前面的示例只处理一张图片。然后下面第415～426行，是对图片尺寸的规约化处理。因为YOLOV8只能在640px x 640px 的图片上进行检测，所以需要在代码中预处理一下。</p><p>第427～440行是将处理后的图片加载成 Tensor 对象。第441～442行，执行推理预测。第444～452行，调用各自任务的汇报业务。第453～455行，生成处理后的图片，写入磁盘中。</p><p>第444行出现了 <code>T::report()</code>，解释跟前面一样，实际就是 YOLOv8 和 YOLOv8Pose 上都实现了 <code>report()</code> 关联函数，它定义在Task trait中。然后这个 <code>T::report()</code> 会进一步路由到 <code>report_detect()</code> 和 <code>report_pose()</code> 函数中，各自调用。</p><p>在各自的 report 函数中，会对上一步YOLOv8预测的边框值按置信区间进行筛选，然后对图片添加标注，也就是画那些线和框。这样就生成了我们看到的效果图的内存对象。</p><p>到这里为止，全部代码就讲解完成了。细节比较生硬，还是图片好玩！</p><h2>小结</h2><p>这节课我们使用Rust实现了Yolov8算法探测图像中的对象和人物的姿势。从实现过程来说，并不比Python版本的实现复杂多少。而且从部署上来讲，Rust编译后就一个二进制可执行文件，对于做成一个软件（后面两讲我们会讲如何用GUI界面）要方便很多。</p><p>另一方面，代码中对于函数的返回值，使用了 <code>anyhow::Result&lt;T&gt;</code>。上节课我们讲过，使用anyhow的返回类型能够大大减少我们的心智负担。</p><p>这个版本的Yolov8的算法，是实现在Candle框架这个平台上的，你可以研究一下 model.rs 文件，可以看到，代码量非常少。因为有了Candle的基础设施，实现一个新的神经网络算法其实非常简单。</p><p>以前，当我们想学习图像识别的时候，我们就得求助于Python或C++。以后你也可以使用Rust玩起来了，我以后会持续地输出关于Rust在AI领域的应用，你可以持续关注，我们一起推进Rust在AI领域的影响力。</p><h2>思考题</h2><p>请你开启 cuda 或 metal 特性尝试一下，使用不同的预训练模型看一下效果差异。另外你还可以换用不同的图片来测试一下各种识别效果。</p><p>欢迎你把你实验的结果分享到评论区，也欢迎你把这节课的内容分享给其他朋友，邀他一起学习Rust，我们下节课再见！</p>","comments":[{"had_liked":false,"id":387255,"user_name":"渡鸦10086","can_delete":false,"product_type":"c1","uid":2491000,"ip_address":"陕西","ucode":"58D72C8B5E9B98","user_header":"https://static001.geekbang.org/account/avatar/00/26/02/78/4d40b4b2.jpg","comment_is_top":false,"comment_ctime":1706781032,"is_pvip":false,"replies":[{"id":141163,"content":"👍","user_name":"作者回复","user_name_real":"编辑","uid":2186062,"ctime":1707198568,"ip_address":"四川","comment_id":387255,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100626901,"comment_content":"网页下载模型到本地后通过--models参数即可使用本地模型，比如\ncargo run --release -- assets&#47;football.jpg --which m --model .&#47;model&#47;yolov8m.safetensors","like_count":2,"discussions":[{"author":{"id":2186062,"avatar":"https://static001.geekbang.org/account/avatar/00/21/5b/4e/8e1f699e.jpg","nickname":"Mike Tang","note":"","ucode":"55775BCEDB5937","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":636897,"discussion_content":"👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1707198569,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"四川","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":388917,"user_name":"Jump","can_delete":false,"product_type":"c1","uid":1139482,"ip_address":"广东","ucode":"6C229DD3AE29A8","user_header":"https://static001.geekbang.org/account/avatar/00/11/63/1a/367ebeac.jpg","comment_is_top":false,"comment_ctime":1711162361,"is_pvip":false,"replies":[{"id":141748,"content":"👍你会了","user_name":"作者回复","user_name_real":"编辑","uid":2186062,"ctime":1713028632,"ip_address":"加拿大","comment_id":388917,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100626901,"comment_content":"启用cuda需要在cargo.toml里面开启特性\n[dependencies]\ncandle-core = {version= &quot;0.3.1&quot;,features=[&quot;cuda&quot;]}\ncandle-nn = {version= &quot;0.3.1&quot;,features=[&quot;cuda&quot;]}\ncandle-transformers = {version= &quot;0.3.1&quot;,features=[&quot;cuda&quot;]}","like_count":1,"discussions":[{"author":{"id":2186062,"avatar":"https://static001.geekbang.org/account/avatar/00/21/5b/4e/8e1f699e.jpg","nickname":"Mike Tang","note":"","ucode":"55775BCEDB5937","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":641830,"discussion_content":"👍你会了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1713028632,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"加拿大","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":388391,"user_name":"Geek_118351","can_delete":false,"product_type":"c1","uid":3842809,"ip_address":"四川","ucode":"EDAE2B93EA8B70","user_header":"","comment_is_top":false,"comment_ctime":1710121706,"is_pvip":false,"replies":[{"id":141472,"content":"看极客时间这边的安排哈。 对于rust ai的解决方案，我后续会持续输出，频率不定。","user_name":"作者回复","user_name_real":"编辑","uid":2186062,"ctime":1710434331,"ip_address":"加拿大","comment_id":388391,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100626901,"comment_content":"老师你好，会考虑出一个针对视频流的目标识别课程吗。","like_count":0,"discussions":[{"author":{"id":2186062,"avatar":"https://static001.geekbang.org/account/avatar/00/21/5b/4e/8e1f699e.jpg","nickname":"Mike Tang","note":"","ucode":"55775BCEDB5937","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":639283,"discussion_content":"看极客时间这边的安排哈。 对于rust ai的解决方案，我后续会持续输出，频率不定。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1710434331,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"加拿大","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":386488,"user_name":"Geek_e72251","can_delete":false,"product_type":"c1","uid":3733050,"ip_address":"广东","ucode":"894904DE2E6AC0","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/VF71Gcf2C2bjYPFCRv0TPfwhkJmT5WhtusltuaXQM0KMDibdallNFypqWV6v2FJ4bqNwzujiaF5LEDeia7JMZTTtw/132","comment_is_top":false,"comment_ctime":1704950927,"is_pvip":false,"replies":[{"id":140912,"content":"你可以在浏览器里面打开这个 https:&#47;&#47;huggingface.co&#47;lmz&#47;candle-yolo-v8&#47;tree&#47;main 下载模型文件，然后改 \nhttps:&#47;&#47;github.com&#47;rustai-solutions&#47;slint-yolov8-demo&#47;blob&#47;main&#47;src&#47;yolov8engine&#47;mod.rs#L307C41-L307C41\n实例的 model 字段为具体的路径，就是你本地目录的Path。正好可以练手一下哈。","user_name":"作者回复","user_name_real":"编辑","uid":2186062,"ctime":1705068538,"ip_address":"重庆","comment_id":386488,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100626901,"comment_content":"老师可以贴一段怎么从本地加载 yolo 模型的代码吗？实在下载不下来😮‍💨","like_count":0,"discussions":[{"author":{"id":2186062,"avatar":"https://static001.geekbang.org/account/avatar/00/21/5b/4e/8e1f699e.jpg","nickname":"Mike Tang","note":"","ucode":"55775BCEDB5937","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":635717,"discussion_content":"你可以在浏览器里面打开这个 https://huggingface.co/lmz/candle-yolo-v8/tree/main 下载模型文件，然后改 \nhttps://github.com/rustai-solutions/slint-yolov8-demo/blob/main/src/yolov8engine/mod.rs#L307C41-L307C41\n实例的 model 字段为具体的路径，就是你本地目录的Path。正好可以练手一下哈。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1705068538,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"重庆","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3733050,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/VF71Gcf2C2bjYPFCRv0TPfwhkJmT5WhtusltuaXQM0KMDibdallNFypqWV6v2FJ4bqNwzujiaF5LEDeia7JMZTTtw/132","nickname":"Geek_e72251","note":"","ucode":"894904DE2E6AC0","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":635656,"discussion_content":"已经解决了😃加个参数就行","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1705026980,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":386277,"user_name":"Geek_e72251","can_delete":false,"product_type":"c1","uid":3733050,"ip_address":"广东","ucode":"894904DE2E6AC0","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/VF71Gcf2C2bjYPFCRv0TPfwhkJmT5WhtusltuaXQM0KMDibdallNFypqWV6v2FJ4bqNwzujiaF5LEDeia7JMZTTtw/132","comment_is_top":false,"comment_ctime":1704431038,"is_pvip":false,"replies":[{"id":140795,"content":"可以像前面一节一样，用hf的工具从镜像下载。或者开全局代理下载","user_name":"作者回复","user_name_real":"编辑","uid":2186062,"ctime":1704497628,"ip_address":"重庆","comment_id":386277,"utype":1}],"discussion_count":5,"race_medal":0,"score":2,"product_id":100626901,"comment_content":"Error: request error: https:&#47;&#47;huggingface.co&#47;lmz&#47;candle-yolo-v8&#47;resolve&#47;main&#47;yolov8m.safetensors: Connection Failed: Connect error: connection timed out\n\nCaused by:\n    0: https:&#47;&#47;huggingface.co&#47;lmz&#47;candle-yolo-v8&#47;resolve&#47;main&#47;yolov8m.safetensors: Connection Failed: Connect error: connection timed out\n    1: connection timed out 一直下不来这个文件，可以提前下载下来然后放到项目里面吗？浏览器可以正常下载","like_count":0,"discussions":[{"author":{"id":2186062,"avatar":"https://static001.geekbang.org/account/avatar/00/21/5b/4e/8e1f699e.jpg","nickname":"Mike Tang","note":"","ucode":"55775BCEDB5937","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":635173,"discussion_content":"可以像前面一节一样，用hf的工具从镜像下载。或者开全局代理下载","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1704497628,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"重庆","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":1,"child_discussions":[{"author":{"id":3733050,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/VF71Gcf2C2bjYPFCRv0TPfwhkJmT5WhtusltuaXQM0KMDibdallNFypqWV6v2FJ4bqNwzujiaF5LEDeia7JMZTTtw/132","nickname":"Geek_e72251","note":"","ucode":"894904DE2E6AC0","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2186062,"avatar":"https://static001.geekbang.org/account/avatar/00/21/5b/4e/8e1f699e.jpg","nickname":"Mike Tang","note":"","ucode":"55775BCEDB5937","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":635209,"discussion_content":"开了全局代理也不行。我已经从浏览器下载下来了，应该放到哪个文件夹？或者修改哪个配置？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1704543939,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":635173,"ip_address":"广东","group_id":0},"score":635209,"extra":""}]},{"author":{"id":3227310,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/ibD5qS2OcJj7aWf4SVJFUVLicicDkSkmzTHRhTSd2cXKzYO1LRDwcoEOo7EjV8KFaSzmgqA1ZcXLWBUibHsKTovWHA/132","nickname":"Geek_706285","note":"","ucode":"22C6EAFEB84E04","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":635298,"discussion_content":"老哥我也碰到同样的问题了，我配置了代理和挂了全局都下载不了，然后不清楚std::path的具体路径该在哪，你后面结局了吗","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1704703556,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"","child_discussion_number":2,"child_discussions":[{"author":{"id":3733050,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/VF71Gcf2C2bjYPFCRv0TPfwhkJmT5WhtusltuaXQM0KMDibdallNFypqWV6v2FJ4bqNwzujiaF5LEDeia7JMZTTtw/132","nickname":"Geek_e72251","note":"","ucode":"894904DE2E6AC0","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":3227310,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/ibD5qS2OcJj7aWf4SVJFUVLicicDkSkmzTHRhTSd2cXKzYO1LRDwcoEOo7EjV8KFaSzmgqA1ZcXLWBUibHsKTovWHA/132","nickname":"Geek_706285","note":"","ucode":"22C6EAFEB84E04","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":635469,"discussion_content":"不知道 老师也没回答😮‍💨","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1704870052,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":635298,"ip_address":"广东","group_id":0},"score":635469,"extra":""},{"author":{"id":3733050,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/VF71Gcf2C2bjYPFCRv0TPfwhkJmT5WhtusltuaXQM0KMDibdallNFypqWV6v2FJ4bqNwzujiaF5LEDeia7JMZTTtw/132","nickname":"Geek_e72251","note":"","ucode":"894904DE2E6AC0","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":3227310,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/ibD5qS2OcJj7aWf4SVJFUVLicicDkSkmzTHRhTSd2cXKzYO1LRDwcoEOo7EjV8KFaSzmgqA1ZcXLWBUibHsKTovWHA/132","nickname":"Geek_706285","note":"","ucode":"22C6EAFEB84E04","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":635474,"discussion_content":"应该是下载下来用 标准库的 File 读取，只是不知道怎么读取🥲","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1704870718,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":635298,"ip_address":"广东","group_id":0},"score":635474,"extra":""}]}]},{"had_liked":false,"id":386036,"user_name":"凤  梨  🍍","can_delete":false,"product_type":"c1","uid":3801970,"ip_address":"广东","ucode":"9A019F064B79A5","user_header":"https://static001.geekbang.org/account/avatar/00/3a/03/72/666d9a55.jpg","comment_is_top":false,"comment_ctime":1703867428,"is_pvip":false,"replies":[{"id":140724,"content":"我代码里面有, 用 huggingface-cli 下载,指定镜像. 可以下载的.  转换格式的话可以用这个方案: https:&#47;&#47;github.com&#47;ToluClassics&#47;candle-tutorial","user_name":"作者回复","user_name_real":"编辑","uid":2186062,"ctime":1704170612,"ip_address":"重庆","comment_id":386036,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100626901,"comment_content":"pytorch怎么转safetensors，没工具下载不了外面的模型","like_count":0,"discussions":[{"author":{"id":2186062,"avatar":"https://static001.geekbang.org/account/avatar/00/21/5b/4e/8e1f699e.jpg","nickname":"Mike Tang","note":"","ucode":"55775BCEDB5937","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":634873,"discussion_content":"我代码里面有, 用 huggingface-cli 下载,指定镜像. 可以下载的.  转换格式的话可以用这个方案: https://github.com/ToluClassics/candle-tutorial","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1704170612,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"重庆","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3733050,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/VF71Gcf2C2bjYPFCRv0TPfwhkJmT5WhtusltuaXQM0KMDibdallNFypqWV6v2FJ4bqNwzujiaF5LEDeia7JMZTTtw/132","nickname":"Geek_e72251","note":"","ucode":"894904DE2E6AC0","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":636259,"discussion_content":"兄弟转成功了吗？这个教程对新手太不友好了🥲","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1705913400,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":385851,"user_name":"unistart","can_delete":false,"product_type":"c1","uid":1524770,"ip_address":"湖南","ucode":"C51E5D242530D2","user_header":"https://static001.geekbang.org/account/avatar/00/17/44/22/403a340a.jpg","comment_is_top":false,"comment_ctime":1703509911,"is_pvip":false,"replies":[{"id":140633,"content":"因为姿势探测好像只支持人。","user_name":"作者回复","user_name_real":"编辑","uid":2186062,"ctime":1703577837,"ip_address":"重庆","comment_id":385851,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100626901,"comment_content":"老师，我有一个问题就是猫猫那张图执行姿势探测任务时无法正确识别，这是为什么啊？\n\ncargo run --release -- assets&#47;cats.jpg --model candle-yolo-v8&#47;yolov8x-pose.safetensors --which x --task pose\n   Compiling candle_demo_yolov8 v0.1.0 (E:\\Project\\rust-jikeshijian\\24-candle_yolov8)\n    Finished release [optimized] target(s) in 12.69s\n     Running `target\\release\\candle_demo_yolov8.exe assets&#47;cats.jpg --model candle-yolo-v8&#47;yolov8x-pose.safetensors --which x --task pose`\nRunning on CPU, to run on GPU, build this example with `--features cuda`\nmodel loaded\nprocessing &quot;assets&#47;cats.jpg&quot;\ngenerated predictions Tensor[dims 56, 6300; f32]\nwriting &quot;assets&#47;cats.pp.jpg&quot;","like_count":0,"discussions":[{"author":{"id":2186062,"avatar":"https://static001.geekbang.org/account/avatar/00/21/5b/4e/8e1f699e.jpg","nickname":"Mike Tang","note":"","ucode":"55775BCEDB5937","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":634499,"discussion_content":"因为姿势探测好像只支持人。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1703577837,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"重庆","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":385671,"user_name":"蕨火","can_delete":false,"product_type":"c1","uid":2230590,"ip_address":"青海","ucode":"34AE1F36258BA4","user_header":"https://static001.geekbang.org/account/avatar/00/22/09/3e/5021e8a1.jpg","comment_is_top":false,"comment_ctime":1703073971,"is_pvip":false,"replies":[{"id":140565,"content":"训练yolo跟联网关系不大，可以先把预训练模型下载下来，准备好环境，再把网络断掉训练。训练的过程本身不依赖于网络，只是前期资料（初始模型文件，你的数据集，rust app编译好，等等）准备你得准备好。","user_name":"作者回复","user_name_real":"编辑","uid":2186062,"ctime":1703123499,"ip_address":"重庆","comment_id":385671,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100626901,"comment_content":"同问，不联网怎么做？","like_count":0,"discussions":[{"author":{"id":2186062,"avatar":"https://static001.geekbang.org/account/avatar/00/21/5b/4e/8e1f699e.jpg","nickname":"Mike Tang","note":"","ucode":"55775BCEDB5937","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":634241,"discussion_content":"训练yolo跟联网关系不大，可以先把预训练模型下载下来，准备好环境，再把网络断掉训练。训练的过程本身不依赖于网络，只是前期资料（初始模型文件，你的数据集，rust app编译好，等等）准备你得准备好。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1703123499,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"重庆","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":385580,"user_name":"My dream","can_delete":false,"product_type":"c1","uid":1077733,"ip_address":"四川","ucode":"2FEFB344230C17","user_header":"https://static001.geekbang.org/account/avatar/00/10/71/e5/bcdc382a.jpg","comment_is_top":false,"comment_ctime":1702950837,"is_pvip":false,"replies":[{"id":140562,"content":"这块儿还没有示例，简单的说，pytorch是怎么训练的，在candle中就对应的实现就行了。原理都是神经网络。Rust在AI这块儿还有大量的工作要做，而Rust社区后面会在这块儿投入巨大的精力。欢迎持续关注。","user_name":"作者回复","user_name_real":"编辑","uid":2186062,"ctime":1703123310,"ip_address":"重庆","comment_id":385580,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100626901,"comment_content":"用rust怎么训练录像资源啊？","like_count":0,"discussions":[{"author":{"id":2186062,"avatar":"https://static001.geekbang.org/account/avatar/00/21/5b/4e/8e1f699e.jpg","nickname":"Mike Tang","note":"","ucode":"55775BCEDB5937","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":634238,"discussion_content":"这块儿还没有示例，简单的说，pytorch是怎么训练的，在candle中就对应的实现就行了。原理都是神经网络。Rust在AI这块儿还有大量的工作要做，而Rust社区后面会在这块儿投入巨大的精力。欢迎持续关注。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1703123311,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"重庆","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":385579,"user_name":"My dream","can_delete":false,"product_type":"c1","uid":1077733,"ip_address":"四川","ucode":"2FEFB344230C17","user_header":"https://static001.geekbang.org/account/avatar/00/10/71/e5/bcdc382a.jpg","comment_is_top":false,"comment_ctime":1702950773,"is_pvip":false,"replies":[{"id":140561,"content":"训练yolo跟联网关系不大，可以先把预训练模型下载下来，准备好环境，再把网络断掉训练。训练的过程本身不依赖于网络，只是前期资料准备你得准备好。","user_name":"作者回复","user_name_real":"编辑","uid":2186062,"ctime":1703123210,"ip_address":"重庆","comment_id":385579,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100626901,"comment_content":"如果我们的电脑不联网的情况下，用yolo训练图片资源啊？","like_count":0,"discussions":[{"author":{"id":2186062,"avatar":"https://static001.geekbang.org/account/avatar/00/21/5b/4e/8e1f699e.jpg","nickname":"Mike Tang","note":"","ucode":"55775BCEDB5937","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":634237,"discussion_content":"训练yolo跟联网关系不大，可以先把预训练模型下载下来，准备好环境，再把网络断掉训练。训练的过程本身不依赖于网络，只是前期资料准备你得准备好。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1703123211,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"重庆","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3570665,"avatar":"","nickname":"Geek_72807e","note":"","ucode":"9E9A6277605048","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":634076,"discussion_content":"同问！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1702971638,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"山西","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":385578,"user_name":"My dream","can_delete":false,"product_type":"c1","uid":1077733,"ip_address":"四川","ucode":"2FEFB344230C17","user_header":"https://static001.geekbang.org/account/avatar/00/10/71/e5/bcdc382a.jpg","comment_is_top":false,"comment_ctime":1702950642,"is_pvip":false,"replies":[{"id":140560,"content":"你指的在自己的图片训练集上进行训练吗？目前网上有很多相关资料：https:&#47;&#47;zhuanlan.zhihu.com&#47;p&#47;650002512 https:&#47;&#47;blog.csdn.net&#47;weixin_45921929&#47;article&#47;details&#47;132450479  https:&#47;&#47;blog.csdn.net&#47;qq_40716944&#47;article&#47;details&#47;128648001 \nCandle这边资料现在非常少，毕竟是最新刚出的东西，还在飞速发展中。不过，后面我会在这块儿持续输出相关内容，包含yolov8的训练。欢迎持续关注。","user_name":"作者回复","user_name_real":"编辑","uid":2186062,"ctime":1703123117,"ip_address":"重庆","comment_id":385578,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100626901,"comment_content":"怎么使用yolo训练图片？请老师请一下","like_count":0,"discussions":[{"author":{"id":2186062,"avatar":"https://static001.geekbang.org/account/avatar/00/21/5b/4e/8e1f699e.jpg","nickname":"Mike Tang","note":"","ucode":"55775BCEDB5937","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":634236,"discussion_content":"你指的在自己的图片训练集上进行训练吗？目前网上有很多相关资料：https://zhuanlan.zhihu.com/p/650002512 https://blog.csdn.net/weixin_45921929/article/details/132450479  https://blog.csdn.net/qq_40716944/article/details/128648001 \nCandle这边资料现在非常少，毕竟是最新刚出的东西，还在飞速发展中。不过，后面我会在这块儿持续输出相关内容，包含yolov8的训练。欢迎持续关注。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1703123117,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"重庆","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]}]}