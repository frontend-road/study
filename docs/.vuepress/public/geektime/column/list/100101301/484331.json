{"id":484331,"title":"22 | 调用链追踪：集成 Sleuth 和 Zipkin，实现链路打标","content":"<p>你好，我是姚秋辰。</p><p>在上节课中，我们讲了链路追踪技术在线上故障排查中的重要作用，以及Sleuth是如何通过“打标记”来实现链路追踪的。</p><p>今天，我们就通过实战来落地一套完整的调用链追踪方案。在实战阶段，我会为你详细讲解Sleuth在调用链中传递标记信息的原理。为了进一步提高线上故障排查效率，我们还会搭建Zipkin组件作为链路追踪的数据可视化工具，并通过一条高可用的数据传输通道，借助RabbitMQ将日志信息从应用服务器传递到Zipkin服务器。当你学完这节课，你就可以掌握“调用链追踪”方案搭建的全过程了。</p><p>链路打标是整个调用链追踪方案的基础功能，所以我们就先从这里开始，在实战项目中集成Sleuth，实现日志打标动作。</p><h2>集成Sleuth实现链路打标</h2><p>我们的微服务模块在运行过程中会输出各种各样的日志信息，为了能在日志中打印出特殊的标记，我们需要将Sleuth的打标功能集成到各个微服务模块中。</p><p>Sleuth提供了一种无感知的集成方案，只需要添加一个依赖项，再做一些本地启动参数配置就可以开启打标功能了，整个过程不需要做任何的代码改动。</p><p>所以第一步，我们需要将Sleuth的依赖项添加到模板服务、优惠计算服务和用户服务的pom.xml文件中。具体代码如下。</p><!-- [[[read_end]]] --><pre><code class=\"language-xml\">&lt;!-- Sleuth依赖项 --&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre><p>第二步，我们打开微服务模块的application.yml配置文件，在配置文件中添加采样率和每秒采样记录条数。</p><pre><code class=\"language-yaml\">spring: \n  sleuth:\n    sampler:\n      # 采样率的概率，100%采样\n      probability: 1.0\n      # 每秒采样数字最高为1000\n      rate: 1000\n</code></pre><p>你可以从代码中看到，我在配置文件里设置了一个<strong>probability</strong>，它应该是一个0到1的浮点数，用来表示<strong>采样率</strong>。我这里设置的probability是1，就表示对请求进行100%采样。如果我们把probability设置成小于1的数，就说明有的请求不会被采样。如果一个请求未被采样，那么它将不会被调用链追踪系统Track起来。</p><p>你还会在代码中看到<strong>rate参数</strong>，它代表<strong>每秒最多可以对多少个Request进行采样</strong>。这有点像一个“限流”参数，如果超过这个阈值，服务请求仍然会被正常处理，但调用链信息不会被采样。</p><p>到这里，我们的Sleuth集成工作就已经搞定了。这时你只要启动项目，顺手调用几个API，就能在控制台的日志信息里看到Sleuth默认打印出来的Trace ID和Span ID。比如我这里调用了Customer服务的优惠券查询接口，在日志中，你可以看到两串随机生成的数字和字母混合的ID，其中排在前面的那个ID就是Trace ID，而后面则是Span ID。</p><pre><code class=\"language-plain\">DEBUG [coupon-customer-serv,69e433d6432522e4,936d8af942b703d2] 81584 \n--- [io-20002-exec-1] c.g.c.customer.feign.TemplateService：xxxx\n</code></pre><p>接下来问题来了，在跨服务的调用链中，你知道Sleuth是如何将这些标记从一个微服务传递给下一个微服务的吗？接下来我们就去看看Sleuth具体动了哪些手脚吧。</p><h2>Sleuth如何在调用链中传递标记</h2><p>以Customer微服务为例，在我们访问findCoupon接口查询优惠券的时候，用户微服务通过OpenFeign组件向Template微服务发起了一次查询请求。</p><p>Sleuth为了将Trace ID和Customer服务的Span ID传递给Template微服务，它在OpenFeign的环节动了一个手脚。Sleuth通过<strong>TracingFeignClient类</strong>，将一系列Tag标记塞进了OpenFeign构造的服务请求的Header结构中。</p><p>我在TracingFeignClient的类中打了一个Debug断点，将Request的Header信息打印了出来：</p><p><img src=\"https://static001.geekbang.org/resource/image/b4/40/b4f541ed4c9ed4ff35f39eb273e0ea40.png?wh=1104x626\" alt=\"图片\"></p><p>在这个Header结构中，我们可以看到有几个以X-B3开头的特殊标记，这个X-B3就是Sleuth的特殊接头暗号。其中X-B3-TraceId就是全局唯一的链路追踪ID，而X-B3-SpanId和X-B3-ParentSpandID分别是当前请求的单元ID和父级单元ID，最后的X-B3-Sampled则表示当前链路是否是一个已被采样的链路。通过Header里的这些信息，下游服务就完整地得到了上游服务的情报。</p><p>以上是Sleuth对OpenFeign动的手脚。为了应对调用链中可能出现的各种不同组件，Sleuth内部构造了各式各样的适配器，用来在不同组件中使用同样的接头暗号“X-B3-*”，这样就可以传递链路追踪的信息。如果你对这部分的源码感兴趣，你可以深入研究spring-cloud-sleuth-instrumentation和spring-cloud-sleuth-brave两个依赖包的源代码，了解更加详细的实现过程。</p><p>搞定了链路打标之后，我们怎样才能通过Trace ID来查询链路信息呢？这时就要找Zipkin来帮忙了。</p><h2>使用Zipkin收集并查看链路数据</h2><p>Zipkin是一个分布式的Tracing系统，它可以用来收集时序化的链路打标数据。通过Zipkin内置的UI界面，我们可以根据Trace ID搜索出一次调用链所经过的所有访问单元，并获取每个单元在当前服务调用中所花费的时间。</p><p>为了搭建一条高可用的链路信息传递通道，我将使用RabbitMQ作为中转站，让各个应用服务器将服务调用链信息传递给RabbitMQ，而Zipkin服务器则通过监听RabbitMQ的队列来获取调用链数据。相比于让微服务通过Web接口直连Zipkin，<strong>使用消息队列可以大幅提高信息的送达率和传递效率</strong>。</p><p>我画了一张图来帮你理解Zipkin和微服务之间是如何通信的，你可以参考一下。</p><p><img src=\"https://static001.geekbang.org/resource/image/0c/de/0c634a28570dee1e48166dcfd0413cde.jpg?wh=1920x706\" alt=\"图片\"></p><p>下面我来带你手动搭建Zikpin服务器。</p><h3>搭建Zipkin服务器</h3><p>首先，我们要下载一个Zipkin的可执行jar包，这里我推荐你使用2.23.9版本的Zipkin组件。你可以通过访问<a href=\"https://search.maven.org/remote_content?g=io.zipkin&a=zipkin-server&c=exec&v=2.23.9\">maven的中央仓库</a>下载zipkin-server-2.23.9-exec.jar文件，我已经将版本参数添加到了地址中，不过你可以将地址超链接复制出来，通过修改URL中的版本参数来下载指定版本。</p><p>搭建Zipkin有两种方式，一种是直接下载Jar包，这是官方推荐的标准集成方式；另一种是通过引入Zipkin依赖项的方式，在本地搭建一个Spring Boot版的Zipkin服务器。如果你需要对Zipkin做定制化开发，那么可以采取后一种方式。</p><p>接下来，我们需要在本地启动Zipkin服务器。我们打开命令行，在下载下来的jar包所在目录执行以下命令，就可以启动Zipkin服务器了。</p><pre><code class=\"language-plain\">java -jar zipkin-server-2.23.9-exec.jar --zipkin.collector.rabbitmq.addresses=localhost:5672\n</code></pre><p>要注意的是，我在命令行中设置了zipkin.collector.rabbitmq.addresses参数，所以Zipkin在启动阶段将尝试连接RabbitMQ，你需要<strong>确保RabbitMQ始终处于启动状态</strong>。Zipkin已经为我们内置了RabbitMQ的默认连接属性，如果没有特殊指定，那么Zipkin会使用guest默认用户登录RabbitMQ。如果你想要切换用户、指定默认监听队列或者设置连接参数，那么可以在命令行中添加以下参数进行配置。</p><p><img src=\"https://static001.geekbang.org/resource/image/89/65/898f9d17f9a5f31d586173d7ae1b4a65.jpg?wh=1920x769\" alt=\"图片\"></p><p>启动成功后，你可以在命令行看到Zipkin的特色Logo，以及一行Serving HTTP的运行日志。</p><p><img src=\"https://static001.geekbang.org/resource/image/85/a0/859711f37127fdyybc9abfa7ab5b8ca0.jpg?wh=1142x640\" alt=\"图片\"></p><p>最后，我们只需要验证消息监听队列是否已就位就可以了。我们使用guest账号登录RabbitMQ，并切换到“Queues”面板，如果Zipkin和RabbitMQ的对接一切正常，那么你会在Queues面板下看到一个名为zipkin的队列，如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/f2/40/f2d11231539c530b8438c9bb52423740.png?wh=798x377\" alt=\"图片\"></p><p>到这里，我们就完成了Zipkin服务器的创建。接下来，你还需要将应用程序生成的链路数据发送给Zipkin服务器。</p><h3>传送链路数据到Zipkin</h3><p>我在方案中使用RabbitMQ作为中转站来传递链路调用数据，因此应用程序并不需要直连Zipkin，而是需要接入到RabbitMQ，并将链路数据发布到RabbitMQ中的“zipkin”队列中就可以了。</p><p>首先，我们需要在每个微服务模块的pom.xml中添加Zipkin适配插件和Stream的依赖。其中，Stream是Spring Cloud中专门用来对接消息中间件的组件，我会在下个章节为你详细讲解它。</p><pre><code class=\"language-xml\">&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-cloud-sleuth-zipkin&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;!-- 提前剧透Stream --&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-cloud-stream-binder-rabbit&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre><p>接下来，我们需要将Zipkin的配置信息添加到每个微服务模块的application.yml文件中。</p><p>在配置项中，我通过zipkin.sender.type属性指定了传输类型为RabbitMQ，除了RabbitMQ以外，Zipkin适配器还支持ActiveMQ、Kafka和直连的方式，我推荐你<strong>使用Kafka和RabbitMQ来保证消息投递的可靠性和高并发性</strong>。我还通过spring.zipkin.rabbitmq属性声明了消息组件的连接地址和消息投递的队列名称。</p><pre><code class=\"language-yaml\">spring:\n  zipkin:\n    sender:\n      type: rabbit\n    rabbitmq:\n      addresses: 127.0.0.1:5672\n      queue: zipkin\n</code></pre><p>有一点你需要注意，<strong>在应用中指定的队列名称，一定要同Zipkin服务器所指定的队列名称保持一致</strong>，否则Zipkin无法消费链路追踪数据。</p><p>到这里，我们就完成了一套完整的链路追踪系统的搭建，是不是很简单呢？接下来，就可以把你的应用启动起来，通过Postman发起几个跨服务的调用了。我来带你去Zipkin上看一下可视化的链路追踪数据长啥样。</p><h3>查看链路追踪信息</h3><p>你可以在浏览器中打开localhost:9411进到Zipkin的首页，在首页中你可以通过各种搜索条件的组合，从服务、时间等不同维度查询调用链数据。</p><p>我在本地调用了Customer服务的订单价格试算接口，而Customer服务又相继调用了Template服务和Calculation服务，现在我就用一段小video来演示如何在Zipkin上查询调用链数据。</p><p><video poster=\"https://media001.geekbang.org/eb417b868fe24003b52471666d9b1a60/snapshots/c7192c3099ef46f68990d18ba7c86b45-00002.jpg\" preload=\"none\" controls=\"\"><source src=\"https://media001.geekbang.org/customerTrans/7e27d07d27d407ebcc195a0e78395f55/244f6a16-17eb524d776-0000-0000-01d-dbacd.mp4\" type=\"video/mp4\"><source src=\" https://media001.geekbang.org/94e01a984523460baf94bf0198fedcc1/05c7ad42a97f4df68522279f997cf31c-1cdd84c393bb44f29aca3886d30ff3e1-sd.m3u8\" type=\"application/x-mpegURL\"></video></p><p>在这段video中，我可以选择想要搜索的时间范围，还可以搜索包含特定服务的调用链。而在搜索结果中，当前调用链都访问了哪些微服务，你可以一目了然。</p><p>如果你知道了某个调用链的全局唯一Trace ID，那么你也可以通过这个Trace ID把一整条调用链路查出来。我又录了一段video来演示这个过程。在链路详情页面中，<strong>所有Span都以时间序列的先后顺序进行排布</strong>，你可以从链路中清晰地看到每个Span的开始、结束时间，以及处理用时。</p><p><video poster=\"https://media001.geekbang.org/9c76142c6ff5435dba8f273ed239d4bc/snapshots/15ae643c554543449fd9658a5ebb9374-00002.jpg\" preload=\"none\" controls=\"\"><source src=\"https://media001.geekbang.org/customerTrans/7e27d07d27d407ebcc195a0e78395f55/159cd0fe-17eb526b3d7-0000-0000-01d-dbacd.mp4\" type=\"video/mp4\"><source src=\" https://media001.geekbang.org/04fbed3f7ae947009c7302bb7613433f/66f4916778cc48608c2831388ff88fa1-567a2a5fa240dac16e48932deffa467f-sd.m3u8\" type=\"application/x-mpegURL\"></video></p><p>如果某个调用链出现了运行期异常，那么你可以从调用链中轻松看出异常发生在哪个阶段。比如下图中的调用链在OpenFeign调用Template服务的时候抛出了RuntimeException，相关Span在页面上已被标红，如果你点击Span详情，就可以看到具体的Error异常提示信息。</p><p><img src=\"https://static001.geekbang.org/resource/image/42/91/42ab09e0fec875117cfc361311793791.png?wh=1396x918\" alt=\"图片\"></p><p>除此之外，Zipkin还有一个很花哨的依赖报表功能，它会以图形化的方式展示某段时间内微服务之间的相互调用情况，如果两个微服务之间有调用关系，Zipkin就会用一条实线将两者关联起来，而实线上流动的小圆点则表示调用量的多少，圆点越多则表示这条链路的流量越多。而且，小圆点还会有红蓝两种颜色，其中红色表示调用失败，蓝色表示调用成功。</p><p>我录了一小段video，你可以感受一下依赖报表功能是怎么用的。<br>\n<video poster=\"https://media001.geekbang.org/65c2302e86f047d09e1fa1fb0f1cde9f/snapshots/1c66a146f7e94da3a34d6d7ecef056ef-00003.jpg\" preload=\"none\" controls=\"\"><source src=\"https://media001.geekbang.org/customerTrans/7e27d07d27d407ebcc195a0e78395f55/100bcc9a-17eb52726a0-0000-0000-01d-dbacd.mp4\" type=\"video/mp4\"><source src=\" https://media001.geekbang.org/882f0256cfc74c9eb500bcf054dfdb92/813dd99747c844d7aac80d9432aa8781-d24ff7ebf04db9f923a6e39cfe0edb69-sd.m3u8\" type=\"application/x-mpegURL\"></video></p><p>到这里，相信你已经对调用链追踪系统的搭建和使用十分了解了，现在让我们来回顾一下这节课的重点内容吧。</p><h2>总结</h2><p>今天我们通过集成Sleuth和Zipkin，搭建了一套完整的链路追踪系统。<strong>链路追踪的核心是“标记”</strong>，也就是Sleuth在链路中打上的Trace ID等标记，我推荐你从Sleuth的源码入手，了解一下Sleuth是如何为每个不同的组件编写适配器，完成打标和标记传递的。</p><p>Zipkin在默认情况下将链路数据保存在内存中，默认最多保存50000个Span数据，所以这种保存数据的方式是不能应用在生产环境中的。</p><p>Zipkin天然支持通过Cassandra、ElasticSearch和MySQL这三种方式保存数据，如果你想要将内存方式切换为其它数据源，则需要在启动命令中添加数据源的连接信息，相关启动参数可以在<a href=\"https://github.com/openzipkin/zipkin/blob/master/zipkin-server/src/main/resources/zipkin-server-shared.yml\">Sleuth的配置文件</a>中找到。在这个链接中，你可以在zipkin.storage节点下找到每个数据源的参数列表，通过zipkin.storage.type字段你可以指定Zipkin的数据源。</p><p>在Spring Boot 2.0之后，Zipkin的官方社区就不再推荐我们通过自定义的方式搭建Zipkin Server端了。除非有很特殊的定制需求，否则我还是推荐你使用zipkin的可执行jar包，并通过标准的启动参数来搭建Zipkin服务器。</p><h2>思考题</h2><p>根据<a href=\"https://github.com/openzipkin/zipkin/blob/master/zipkin-server/src/main/resources/zipkin-server-shared.yml\">Sleuth配置文件</a>中的参数定义，你能通过传入启动参数的方式，对Zipkin做一个改造，并使用MySQL作为数据源吗？欢迎你在评论区把自己的改造过程分享出来。</p><p>好啦，这节课就结束啦。欢迎你把这节课分享给更多对Spring Cloud感兴趣的朋友。我是姚秋辰，我们下节课再见！</p>","neighbors":{"left":{"article_title":"21 | Sleuth 体系架构：为什么微服务架构需要链路追踪？","id":484009},"right":{"article_title":"23 | 调用链追踪：如何通过 ELK 实现日志检索？","id":484447}},"comments":[{"had_liked":false,"id":333224,"user_name":"~","can_delete":false,"product_type":"c1","uid":2495621,"ip_address":"","ucode":"BE5E3BD6EE3665","user_header":"https://static001.geekbang.org/account/avatar/00/26/14/85/73e55be5.jpg","comment_is_top":false,"comment_ctime":1644220947,"is_pvip":false,"replies":[{"id":"121834","content":"满分作业诞生","user_name":"作者回复","user_name_real":"编辑","uid":"2819998","ctime":1644326856,"ip_address":"","comment_id":333224,"utype":1}],"discussion_count":1,"race_medal":0,"score":"36003959315","product_id":100101301,"comment_content":"https:&#47;&#47;github.com&#47;openzipkin&#47;zipkin&#47;blob&#47;master&#47;zipkin-storage&#47;mysql-v1&#47;src&#47;main&#47;resources&#47;mysql.sql <br>这是官方仓库中给的 MySQL 改造的脚本，创建一个 zipkin 的 db 库；之后可以从 https:&#47;&#47;github.com&#47;openzipkin&#47;zipkin&#47;blob&#47;16857b6cc3&#47;zipkin-server&#47;src&#47;main&#47;resources&#47;zipkin-server-shared.yml 配置文件中看到 mysql 的配置项，然后对照着之前老师给的命令，添加上 MySQL 的即可。<br>我的命令：<br>java -jar zipkin-server-2.23.9-exec.jar --STORAGE_TYPE=mysql --MYSQL_HOST=127.0.0.1 --MYSQL_TCP_PORT=3306 --MYSQL_USER=root --MYSQL_PASS=123456 --MYSQL_DB=zipkin --RABBIT_ADDRESSES=127.0.0.1:5672","like_count":9,"discussions":[{"author":{"id":2819998,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/07/9e/d2de2832.jpg","nickname":"姚半仙","note":"","ucode":"4C86AA5D6D8C39","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":550002,"discussion_content":"满分作业诞生","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1644326857,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":338216,"user_name":"yinwenping","can_delete":false,"product_type":"c1","uid":1088594,"ip_address":"","ucode":"90310F95D8B72F","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83er6ADlY3IFt3Rs1aVDyrTO2ytQZDiciaXVKgxCnsqZJUQHzH6I0I6PYvdoiaI6rkm7OLOxHia7t1icDyBQ/132","comment_is_top":false,"comment_ctime":1647355947,"is_pvip":false,"replies":[{"id":"123710","content":"取决你调用异步线程的方式，就拿ThreadPoolExecutor这种标准的线程池来说，你使用execute和submit都会产生不一样的结果，一个会公用trace另一个会重新生成trace id，这个例子它底层就取决于AsyncDefaultAutoConfiguration的具体实现。<br><br>使用spring代理线程池，或者scheduling线程池，都有不同的表现，同学需要结合sleuth源代码来了解具体行为","user_name":"作者回复","user_name_real":"编辑","uid":"2819998","ctime":1647522961,"ip_address":"","comment_id":338216,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18827225131","product_id":100101301,"comment_content":"这种traceid只是在两个服务直接适用吗？比如服务A调用服务B，而服务B内部时线程池处理的，线程池还能用A的traceid吗？","like_count":5,"discussions":[{"author":{"id":2819998,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/07/9e/d2de2832.jpg","nickname":"姚半仙","note":"","ucode":"4C86AA5D6D8C39","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":556819,"discussion_content":"取决你调用异步线程的方式，就拿ThreadPoolExecutor这种标准的线程池来说，你使用execute和submit都会产生不一样的结果，一个会公用trace另一个会重新生成trace id，这个例子它底层就取决于AsyncDefaultAutoConfiguration的具体实现。\n\n使用spring代理线程池，或者scheduling线程池，都有不同的表现，同学需要结合sleuth源代码来了解具体行为","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1647522961,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":347485,"user_name":"牛年榴莲","can_delete":false,"product_type":"c1","uid":1183703,"ip_address":"","ucode":"230C076193C6C0","user_header":"https://static001.geekbang.org/account/avatar/00/12/0f/d7/31d07471.jpg","comment_is_top":false,"comment_ctime":1654071293,"is_pvip":false,"replies":[{"id":"126736","content":"有的，zipkin其实是做tracing的，告警我们可以利用ELK这一层来做，比如ElastAlert集成ES，或者Kibana的sentinl插件。我们公司是使用Prometheus+grafana来做的","user_name":"作者回复","user_name_real":"编辑","uid":"2819998","ctime":1654238616,"ip_address":"","comment_id":347485,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5949038589","product_id":100101301,"comment_content":"Zipkin 好像不支持告警，有没有能根据链路追踪情况进行告警的组件呢？","like_count":1,"discussions":[{"author":{"id":2819998,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/07/9e/d2de2832.jpg","nickname":"姚半仙","note":"","ucode":"4C86AA5D6D8C39","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":574676,"discussion_content":"有的，zipkin其实是做tracing的，告警我们可以利用ELK这一层来做，比如ElastAlert集成ES，或者Kibana的sentinl插件。我们公司是使用Prometheus+grafana来做的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1654238616,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":333144,"user_name":"alex_lai","can_delete":false,"product_type":"c1","uid":1903459,"ip_address":"","ucode":"3057F2A593A6DB","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/m7fLWyJrnwEPoIefiaxusQRh6D1Nq7PCXA8RiaxkmzdNEmFARr5q8L4qouKNaziceXia92an8hzYa5MLic6N6cNMEoQ/132","comment_is_top":false,"comment_ctime":1644129531,"is_pvip":true,"replies":[{"id":"121837","content":"交换机会在项目启动的时候被底层的stream组件自动创建，当然了，如果手动创建也是可以的，注意绑定下交换机和队列即可","user_name":"作者回复","user_name_real":"编辑","uid":"2819998","ctime":1644327288,"ip_address":"","comment_id":333144,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5939096827","product_id":100101301,"comment_content":"rabbitmq的配置没有提 需要单独启动 配置queue<br>么？","like_count":1,"discussions":[{"author":{"id":2819998,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/07/9e/d2de2832.jpg","nickname":"姚半仙","note":"","ucode":"4C86AA5D6D8C39","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":550006,"discussion_content":"交换机会在项目启动的时候被底层的stream组件自动创建，当然了，如果手动创建也是可以的，注意绑定下交换机和队列即可","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1644327288,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":332899,"user_name":"peter","can_delete":false,"product_type":"c1","uid":1058183,"ip_address":"","ucode":"261C3FC001DE2D","user_header":"https://static001.geekbang.org/account/avatar/00/10/25/87/f3a69d1b.jpg","comment_is_top":false,"comment_ctime":1643794977,"is_pvip":true,"replies":[{"id":"121841","content":"Q1: 用户请求通常不直达gateway，前面用nginx、f5之类的网关层来接<br>Q2: 答案有一半已经在文章中了，同学可以参考TracingFeignClient，看一看它往请求的header里塞的这些ID，然后就能找到是怎么生成出来的<br>Q3: 时钟同步是线上运维团队的工作内容，确保集群时间同步，另外sleuth主要是通过span id + parent span id来确保先后顺序，即使时钟不对也能理清前后顺序。<br>Q4: 打标的答案也在文章中，TracingFeignClient这个类里面是打标过程，然后标通过MDC传入到底层日志组件里，最终输出","user_name":"作者回复","user_name_real":"编辑","uid":"2819998","ctime":1644327748,"ip_address":"","comment_id":332899,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5938762273","product_id":100101301,"comment_content":"下面四个问题是在第21篇提的，不过在21篇留言中没有发现，很奇怪。重新提一次。<br>老师新年快乐，请教四个问题：<br>Q1: 实际的线上系统，用户请求是直接到gateway吗？还是需要在gateway的前面加一个节点？如果需要，一般用什么？Nginx吗？<br>Q2：Sleuth是怎么产生TraceID、Span ID、Parent Span ID的？<br>Q3：时间同步问题：Sleuth通过时间来排序，如果不同服务所在机器的时间不是同步的，会有什么问题？怎么解决？<br>Q4：Sleuth是怎么实现“打标”的？怎么获取到微服务之间的调用信息的？又是怎么影响到日志组件(e.g,logback)的？通过拦截器实现的吗？","like_count":1,"discussions":[{"author":{"id":2819998,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/07/9e/d2de2832.jpg","nickname":"姚半仙","note":"","ucode":"4C86AA5D6D8C39","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":550010,"discussion_content":"Q1: 用户请求通常不直达gateway，前面用nginx、f5之类的网关层来接\nQ2: 答案有一半已经在文章中了，同学可以参考TracingFeignClient，看一看它往请求的header里塞的这些ID，然后就能找到是怎么生成出来的\nQ3: 时钟同步是线上运维团队的工作内容，确保集群时间同步，另外sleuth主要是通过span id + parent span id来确保先后顺序，即使时钟不对也能理清前后顺序。\nQ4: 打标的答案也在文章中，TracingFeignClient这个类里面是打标过程，然后标通过MDC传入到底层日志组件里，最终输出","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1644327748,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":332896,"user_name":"peter","can_delete":false,"product_type":"c1","uid":1058183,"ip_address":"","ucode":"261C3FC001DE2D","user_header":"https://static001.geekbang.org/account/avatar/00/10/25/87/f3a69d1b.jpg","comment_is_top":false,"comment_ctime":1643793642,"is_pvip":true,"replies":[{"id":"122272","content":"Q1: 是的应该是1000.注释写错了<br>Q2：根据概率随机采样，0.5就是采样50%<br>Q3：<br>A: 可以扩展<br>B: 通过AOP切面拦截feign.Client的调用","user_name":"作者回复","user_name_real":"编辑","uid":"2819998","ctime":1645080181,"ip_address":"","comment_id":332896,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5938760938","product_id":100101301,"comment_content":"Q1：&quot;# 每秒采样数字最高为100      rate: 1000&quot;<br>        注释为100，实际是1000，是笔误吗？<br>Q2：“如果我们把 probability 设置成小于 1 的数，就说明有的请求不会被采样”<br>       哪些会被采样？哪些不会被采样？<br>Q3：“在 OpenFeign 的环节动了一个手脚。Sleuth 通过 TracingFeignClient 类，将一系列 Tag 标记塞进了OpenFeign 构造的服务请求的 Header 结构中”<br>   A 如果一个组件，sleuth没有适配，能扩展吗？<br>   B Sleuth对OpenFeign的处理，是通过拦截器实现的吗？","like_count":1,"discussions":[{"author":{"id":2819998,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/07/9e/d2de2832.jpg","nickname":"姚半仙","note":"","ucode":"4C86AA5D6D8C39","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":551672,"discussion_content":"Q1: 是的应该是1000.注释写错了\nQ2：根据概率随机采样，0.5就是采样50%\nQ3：\nA: 可以扩展\nB: 通过AOP切面拦截feign.Client的调用","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1645080181,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":347789,"user_name":"吴少伟","can_delete":false,"product_type":"c1","uid":1944299,"ip_address":"","ucode":"B5EAB0012059DC","user_header":"","comment_is_top":false,"comment_ctime":1654431980,"is_pvip":false,"replies":[{"id":"127572","content":"不管它的底层技术是什么，只要Sleuth中有对应的适配器就可以识别上游的trace ID，这是对于需要互相调用的系统来说的。<br><br>对于任务调度，可以理解为本地启动的java程序，执行的时候也会初始化trace，但调度过程中你如果调用的下游服务，对方要在sleuth中支持适配才能识别上游trace","user_name":"作者回复","user_name_real":"编辑","uid":"2819998","ctime":1657104309,"ip_address":"","comment_id":347789,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1654431980","product_id":100101301,"comment_content":"追加一个问题：任务调度开始执行的时候，可以生成traceId等信息啊？ps：自己留言跑哪里去了。。。。咋找不到","like_count":0,"discussions":[{"author":{"id":2819998,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/07/9e/d2de2832.jpg","nickname":"姚半仙","note":"","ucode":"4C86AA5D6D8C39","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":578967,"discussion_content":"不管它的底层技术是什么，只要Sleuth中有对应的适配器就可以识别上游的trace ID，这是对于需要互相调用的系统来说的。\n\n对于任务调度，可以理解为本地启动的java程序，执行的时候也会初始化trace，但调度过程中你如果调用的下游服务，对方要在sleuth中支持适配才能识别上游trace","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1657104309,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":347788,"user_name":"吴少伟","can_delete":false,"product_type":"c1","uid":1944299,"ip_address":"","ucode":"B5EAB0012059DC","user_header":"","comment_is_top":false,"comment_ctime":1654431870,"is_pvip":false,"replies":[{"id":"127571","content":"日志系统对性能肯定是有些许损耗的，但带来的好处已经可以完全抵消这一丢丢损耗了，所以没得关系。<br><br>然后trace ID和span ID是可以在任何日志级别下打印出来的，只要设置log pattern就可以了","user_name":"作者回复","user_name_real":"编辑","uid":"2819998","ctime":1657104152,"ip_address":"","comment_id":347788,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1654431870","product_id":100101301,"comment_content":"老师咨询几个小问题：<br>1、必须要设置日志级别为debug吗?设置为info是否可以，已经集成了其他的日志收集器了，现在目的只想加上traceId和spanId信息。修改log的配置文件增加这个数据的参数，可以直接打印出来吗？<br>2、对性能是否有影响？","like_count":0,"discussions":[{"author":{"id":2819998,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/07/9e/d2de2832.jpg","nickname":"姚半仙","note":"","ucode":"4C86AA5D6D8C39","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":578966,"discussion_content":"日志系统对性能肯定是有些许损耗的，但带来的好处已经可以完全抵消这一丢丢损耗了，所以没得关系。\n\n然后trace ID和span ID是可以在任何日志级别下打印出来的，只要设置log pattern就可以了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1657104152,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":342576,"user_name":"寥若晨星","can_delete":false,"product_type":"c1","uid":1447739,"ip_address":"","ucode":"2E87E43687DE72","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eou1BMETumU21ZI4yiaLenOMSibzkAgkw944npIpsJRicmdicxlVQcgibyoQ00rdGk9Htp1j0dM5CP2Fibw/132","comment_is_top":false,"comment_ctime":1650351021,"is_pvip":false,"replies":[{"id":"125176","content":"链路图可以直接在zipkin的界面看到，展示实时流量","user_name":"作者回复","user_name_real":"编辑","uid":"2819998","ctime":1650416414,"ip_address":"","comment_id":342576,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1650351021","product_id":100101301,"comment_content":"我怎么记得要生成链路图，还要再下载一个jar包定时执行一下任务","like_count":0,"discussions":[{"author":{"id":2819998,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/07/9e/d2de2832.jpg","nickname":"姚半仙","note":"","ucode":"4C86AA5D6D8C39","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":565169,"discussion_content":"链路图可以直接在zipkin的界面看到，展示实时流量","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1650416414,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":340107,"user_name":"奔跑的蚂蚁","can_delete":false,"product_type":"c1","uid":2379253,"ip_address":"","ucode":"7348CA436144CB","user_header":"https://static001.geekbang.org/account/avatar/00/24/4d/f5/2e80aca6.jpg","comment_is_top":false,"comment_ctime":1648606056,"is_pvip":false,"replies":[{"id":"125171","content":"对滴，所有链路上的服务都要加上这个sleuth依赖，不然只会打log但trace链路会断掉","user_name":"作者回复","user_name_real":"编辑","uid":"2819998","ctime":1650416125,"ip_address":"","comment_id":340107,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1648606056","product_id":100101301,"comment_content":"请问老师  sleuth依赖 上下游服务器都要加嘛","like_count":0,"discussions":[{"author":{"id":2819998,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/07/9e/d2de2832.jpg","nickname":"姚半仙","note":"","ucode":"4C86AA5D6D8C39","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":565159,"discussion_content":"对滴，所有链路上的服务都要加上这个sleuth依赖，不然只会打log但trace链路会断掉","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1650416125,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":337685,"user_name":"蝴蝶","can_delete":false,"product_type":"c1","uid":1193167,"ip_address":"","ucode":"8019924D99182F","user_header":"https://static001.geekbang.org/account/avatar/00/12/34/cf/0a316b48.jpg","comment_is_top":false,"comment_ctime":1646971890,"is_pvip":true,"replies":[{"id":"123402","content":"sao的1B好么，下一节还有更sao的","user_name":"作者回复","user_name_real":"编辑","uid":"2819998","ctime":1646995254,"ip_address":"","comment_id":337685,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1646971890","product_id":100101301,"comment_content":"这个链路表报功能好sao啊，好强大","like_count":0,"discussions":[{"author":{"id":2819998,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/07/9e/d2de2832.jpg","nickname":"姚半仙","note":"","ucode":"4C86AA5D6D8C39","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":555628,"discussion_content":"sao的1B好么，下一节还有更sao的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1646995255,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":337516,"user_name":"奔跑的蚂蚁","can_delete":false,"product_type":"c1","uid":2379253,"ip_address":"","ucode":"7348CA436144CB","user_header":"https://static001.geekbang.org/account/avatar/00/24/4d/f5/2e80aca6.jpg","comment_is_top":false,"comment_ctime":1646878750,"is_pvip":false,"replies":[{"id":"123401","content":"web最好不要直连zipkin，从高可用的角度来讲，最好间接通过MQ来做转发。如果使用的rmq，只是底层依赖包做个替换，还有少量配置替换","user_name":"作者回复","user_name_real":"编辑","uid":"2819998","ctime":1646995196,"ip_address":"","comment_id":337516,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1646878750","product_id":100101301,"comment_content":"如果用的rocket mq 咋办，web 直连 zipkin 会产生什么大问题吗","like_count":0,"discussions":[{"author":{"id":2819998,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/07/9e/d2de2832.jpg","nickname":"姚半仙","note":"","ucode":"4C86AA5D6D8C39","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":555627,"discussion_content":"web最好不要直连zipkin，从高可用的角度来讲，最好间接通过MQ来做转发。如果使用的rmq，只是底层依赖包做个替换，还有少量配置替换","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1646995196,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":335349,"user_name":"Geek_7346b9","can_delete":false,"product_type":"c1","uid":2910894,"ip_address":"","ucode":"7FDD8955221B8C","user_header":"","comment_is_top":false,"comment_ctime":1645460496,"is_pvip":false,"replies":[{"id":"122646","content":"那Zipkin这一端的报错日志是什么","user_name":"作者回复","user_name_real":"编辑","uid":"2819998","ctime":1645631541,"ip_address":"","comment_id":335349,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1645460496","product_id":100101301,"comment_content":"请教下，我启动rabbitmq server 且成功启动后，当我尝试执行启动zipkin（按您给的参数一样），没有一次是成功的。每一次都是timeout问题，我查看了rabbitmq的日志，发现报了client unexpected close socket.而且时间很固定是5秒。请问是哪里问题？即便我配置了rabbitmq.collector.connection-timeout超过10秒，依旧报错","like_count":0,"discussions":[{"author":{"id":2819998,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/07/9e/d2de2832.jpg","nickname":"姚半仙","note":"","ucode":"4C86AA5D6D8C39","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":552911,"discussion_content":"那Zipkin这一端的报错日志是什么","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1645631541,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]}]}