{"id":131826,"title":"19 | 数据压缩：时间换空间的游戏","content":"<p>你好，我是李玥。</p><p>这节课我们一起来聊一聊数据压缩。我在前面文章中提到过，我曾经在一台配置比较高的服务器上，对Kafka做过一个极限的性能压测，想验证一下Kafka到底有多快。我使用的种子消息大小为1KB，只要是并发数量足够多，不开启压缩时，可以打满万兆网卡的全部带宽，TPS接近100万。开启压缩时，TPS可以达到2000万左右，吞吐量提升了大约20倍！</p><p>算术好的同学可能会立刻反驳我说，2000万TPS乘以1KB的消息大小，再把字节Byte转换成比特bit，换算成网络传输的带宽是200Gb/s，服务器网卡根本达不到这么大的传输带宽！</p><p>我们的测试服务器的网卡就是普通的万兆网卡，极限带宽也就是10Gb/s，压测时候的实际网络流量大概在7Gb/s左右。这里面，最重要的原因就是，我在测试的时候开启了Kafka的压缩功能。可以看到，对于Kafka来说，使用数据压缩，提升了大概几十倍的吞吐量。当然，在实际生产时，不太可能达到这么高的压缩率，但是合理地使用数据压缩，仍然可以做到提升数倍的吞吐量。</p><p>所以，<strong>数据压缩不仅能节省存储空间，还可以用于提升网络传输性能。</strong>这种使用压缩来提升系统性能的方法，不仅限于在消息队列中使用，我们日常开发的应用程序也可以使用。比如，我们的程序要传输大量的数据，或者要在磁盘、数据库中存储比较大的数据，这些情况下，都可以考虑使用数据压缩来提升性能，还能节省网络带宽和存储空间。</p><!-- [[[read_end]]] --><p>那如何在你的程序中使用压缩？应该选择什么样的压缩算法更适合我们的系统呢？这节课，我带你一起学习一下，使用数据压缩来提升系统性能的方法。</p><h2>什么情况适合使用数据压缩？</h2><p>在使用压缩之前，首先你需要考虑，当前这个场景是不是真的适合使用数据压缩。</p><p>比如，进程之间通过网络传输数据，这个数据是不是需要压缩呢？我和你一起来对比一下：</p><ul>\n<li>不压缩直接传输需要的时间是： 传输<strong>未压缩</strong>数据的耗时。</li>\n<li>使用数据压缩需要的时间是： 压缩耗时 + 传输<strong>压缩</strong>数据耗时 + 解压耗时。</li>\n</ul><p>到底是压缩快，还是不压缩快呢？其实不好说。影响的因素非常多，比如数据的压缩率、网络带宽、收发两端服务器的繁忙程度等等。</p><p>压缩和解压的操作都是计算密集型的操作，非常耗费CPU资源。如果你的应用处理业务逻辑就需要耗费大量的CPU资源，就不太适合再进行压缩和解压。</p><p>又比如说，如果你的系统的瓶颈是磁盘的IO性能，CPU资源又很闲，这种情况就非常适合在把数据写入磁盘前先进行压缩。</p><p>但是，如果你的系统读写比严重不均衡，你还要考虑，每读一次数据就要解压一次是不是划算。</p><p><strong>压缩它的本质是资源的置换，是一个时间换空间，或者说是CPU资源换存储资源的游戏。</strong></p><p>就像木桶的那个短板一样，每一个系统它都有一个性能瓶颈资源，可能是磁盘IO，网络带宽，也可能是CPU。如果使用压缩，能用长板来换一些短板，那总体上就能提升性能，这样就是划算的。如果用了压缩之后，短板更短了，那就不划算了，不如不用。</p><p>如果通过权衡，使用数据压缩确实可以提升系统的性能，接下来就需要选择合适的压缩算法。</p><h2>应该选择什么压缩算法？</h2><p>压缩算法可以分为有损压缩和无损压缩。有损压缩主要是用来压缩音视频，它压缩之后是会丢失信息的。我们这里讨论的全都是无损压缩，也就是说，数据经过压缩和解压过程之后，与压缩之前相比，是100%相同的。</p><p>数据为什么可以被压缩呢？各种各样的压缩算法又是怎么去压缩数据的呢？我举个例子来简单说明一下。</p><p>比如说，下面这段数据：</p><blockquote>\n<p>00000000000000000000</p>\n</blockquote><p>我来给你人肉压缩一下：</p><blockquote>\n<p>20个0</p>\n</blockquote><p>20个字符就被压缩成了4个字符，并且是可以无损还原的。当然，我举的例子比较极端，我的压缩算法也几乎没什么实用性，但是，这确实是一个压缩算法，并且和其他的压缩算法本质是没什么区别的。</p><p>目前常用的压缩算法包括：ZIP，GZIP，SNAPPY，LZ4等等。选择压缩算法的时候，主要需要考虑数据的压缩率和压缩耗时。一般来说，压缩率越高的算法，压缩耗时也越高。如果是对性能要求高的系统，可以选择压缩速度快的算法，比如LZ4；如果需要更高的压缩比，可以考虑GZIP或者压缩率更高的XZ等算法。</p><p>压缩样本对压缩速度和压缩比的影响也是比较大的，同样大小的一段数字和一段新闻的文本，即使是使用相同的压缩算法，压缩率和压缩时间的差异也是比较大的。所以，有的时候在选择压缩算法的之前，用系统的样例业务数据做一个测试，可以帮助你找到最合适的压缩算法。</p><p>在这里，我不会去给你讲某一种压缩算法，因为压缩算法都很复杂，一般来说也不需要我们来实现某种压缩算法，如果你感兴趣的话，可以去学习一下最经典压缩算法：哈夫曼编码（也叫霍夫曼编码，Huffman Coding）。</p><h2>如何选择合适的压缩分段？</h2><p>大部分的压缩算法，他们的区别主要是，对数据进行编码的算法，压缩的流程和压缩包的结构大致一样的。而在压缩过程中，你最需要了解的就是如何选择合适的压缩分段大小。</p><p>在压缩时，给定的被压缩数据它必须有确定的长度，或者说，是有头有尾的，不能是一个无限的数据流，<strong>如果要对流数据进行压缩，那必须把流数据划分成多个帧，一帧一帧的分段压缩。</strong></p><p>主要原因是，压缩算法在开始压缩之前，一般都需要对被压缩数据从头到尾进行一次扫描，扫描的目的是确定如何对数据进行划分和编码，一般的原则是重复次数多、占用空间大的内容，使用尽量短的编码，这样压缩率会更高。</p><p>另外，被压缩的数据长度越大，重码率会更高，压缩比也就越高。这个很好理解，比如我们这篇文章，可能出现了几十次“压缩”这个词，如果将整篇文章压缩，这个词的重复率是几十次，但如果我们按照每个自然段来压缩，那每段中这个词的重复率只有二三次。显然全文压缩的压缩率肯定高于分段压缩。</p><p>当然，分段也不是越大越好，实际上分段大小超过一定长度之后，再增加长度对压缩率的贡献就不太大了，这是一个原因。另外，过大的分段长度，在解压缩的时候，会有更多的解压浪费。比如，一个1MB大小的压缩文件，即使你只是需要读其中很短的几个字节，也不得不把整个文件全部解压缩，造成很大的解压浪费。</p><p>所以，你需要根据你的业务，选择合适的压缩分段，在压缩率、压缩速度和解压浪费之间找到一个合适的平衡。</p><p>确定了如何对数据进行划分和压缩算法之后，就可以进行压缩了，压缩的过程就是用编码来替换原始数据的过程。压缩之后的压缩包就是由这个编码字典和用编码替换之后的数据组成的。</p><p>这就是数据压缩的过程。解压的时候，先读取编码字典，然后按照字典把压缩编码还原成原始的数据就可以了。</p><h2>Kafka是如何处理消息压缩的？</h2><p>回过头来，我们再看一下Kafka它是如何来处理数据压缩的。</p><p>首先，Kafka是否开启压缩，这是可以配置，它也支持配置使用哪一种压缩算法。原因我们在上面说过，不同的业务场景是否需要开启压缩，选择哪种压缩算法是不能一概而论的。所以，Kafka的设计者把这个选择权交给使用者。</p><p>在开启压缩时，Kafka选择一批消息一起压缩，每一个批消息就是一个压缩分段。使用者也可以通过参数来控制每批消息的大小。</p><p>我们之前讲过，在Kafka中，生产者生成一个批消息发给服务端，在服务端中是不会拆分批消息的。那按照批来压缩，意味着，在服务端也不用对这批消息进行解压，可以整批直接存储，然后整批发送给消费者。最后，批消息由消费者进行解压。</p><p>在服务端不用解压，就不会耗费服务端宝贵的CPU资源，同时还能获得压缩后，占用传输带宽小，占用存储空间小的这些好处，这是一个非常聪明的设计。</p><p>在使用Kafka时，如果生产者和消费者的CPU资源不是特别吃紧，开启压缩后，可以节省网络带宽和服务端的存储空间，提升总体的吞吐量，一般都是个不错的选择。</p><h2>小结</h2><p>数据压缩，它本质上是用CPU资源换取存储资源，或者说是用压缩解压的时间来换取存储的空间，这个买卖是不是划算，需要你根据自己的情况先衡量一下。</p><p>在选择压缩算法的时候，需要综合考虑压缩时间和压缩率两个因素，被压缩数据的内容也是影响压缩时间和压缩率的重要因素，必要的时候可以先用业务数据做一个压缩测试，这样有助于选择最合适的压缩算法。</p><p>另外一个影响压缩率的重要因素是压缩分段的大小，你需要根据业务情况选择一个合适的分段策略，在保证不错的压缩率的前提下，尽量减少解压浪费。</p><p>最后，我们讲了一下Kafka它是如何处理消息压缩的。Kafka在生产者上，对每批消息进行压缩，批消息在服务端不解压，消费者在收到消息之后再进行解压。简单地说，Kafka的压缩和解压都是在客户端完成的。</p><h2>思考题</h2><p>课后，你可以去看一下RocketMQ的文档或者源代码，看一下，RocketMQ是怎么处理消息压缩的。然后和Kafka的压缩方式对比一下，想一想哪种处理方式更适合你的系统？</p><p>欢迎你在留言区把你的思考分享出来，如果有任何问题也欢迎你在留言区提问。</p><p>感谢阅读，如果你觉得这篇文章对你有一些启发，也欢迎把它分享给你的朋友。</p><p></p>","comments":[{"had_liked":false,"id":131159,"user_name":"姜戈","can_delete":false,"product_type":"c1","uid":1058972,"ip_address":"","ucode":"45C4BE93C8E4CC","user_header":"https://static001.geekbang.org/account/avatar/00/10/28/9c/73e76b19.jpg","comment_is_top":false,"comment_ctime":1567655638,"is_pvip":false,"replies":[{"id":49814,"content":"👍👍👍","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1567732255,"ip_address":"","comment_id":131159,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"RocketMq(rockmq-all 4.4.1-SNAPSHOT): 默认压缩大于4K的消息（可配置），压缩算法是zip，默认级别5（可配置），同样也是客户端做解压缩工作，服务端只存储；对于批量消息的压缩，目前并不支持。\n摘取DefaultMQProducerImpl.java 部分源码：\nprivate boolean tryToCompressMessage(final Message msg) {\n        if (msg instanceof MessageBatch) {\n            &#47;&#47;batch dose not support compressing right now\n            return false;\n        }\n        byte[] body = msg.getBody();\n        if (body != null) {\n            if (body.length &gt;= this.defaultMQProducer.getCompressMsgBodyOverHowmuch()) {\n                try {\n                    byte[] data = UtilAll.compress(body, zipCompressLevel);\n                    if (data != null) {\n                        msg.setBody(data);\n                        return true;\n                    }\n                } catch (IOException e) {\n                    log.error(&quot;tryToCompressMessage exception&quot;, e);\n                    log.warn(msg.toString());\n                }\n            }\n        }\n\n        return false;\n    }","like_count":68},{"had_liked":false,"id":134048,"user_name":"Standly","can_delete":false,"product_type":"c1","uid":1181055,"ip_address":"","ucode":"805CC5784D3F76","user_header":"https://static001.geekbang.org/account/avatar/00/12/05/7f/a7df049a.jpg","comment_is_top":false,"comment_ctime":1568728813,"is_pvip":false,"replies":[{"id":51434,"content":"只会解压header，消息体不会解压。","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1568769392,"ip_address":"","comment_id":134048,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"Kafka每个压缩过的消息集合在 Broker 端写入时都要发生解压缩操作，目的是为了对消息执行各种验证。\n好像是这样吧？","like_count":29,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":466316,"discussion_content":"👍👍👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567732255,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":131139,"user_name":"DFighting","can_delete":false,"product_type":"c1","uid":1233193,"ip_address":"","ucode":"F3BA2426FF8582","user_header":"https://static001.geekbang.org/account/avatar/00/12/d1/29/1b1234ed.jpg","comment_is_top":false,"comment_ctime":1567650067,"is_pvip":false,"replies":[{"id":49817,"content":"👍👍👍","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1567732550,"ip_address":"","comment_id":131139,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"一直学习算法都是空间换时间，但是在消息中间件和一些IO密集型的应用中还会有CPU计算资源换网络带宽&#47;磁盘IO，刚刚看了下RocketMQ源码，在DefaultMQPullConsumerlmpl.pullSyncImpl中会调用PullAPIWrapper.processPullResult，在这里会为压缩的消息进行解压缩。Producer端没找到压缩的源码，只是在checkMessage中会对消息体的长度进行限制，超过4K(网上查的)会抛出来MQClientException，猜测应该也是会压缩。也就是RocketMQ的压缩机制也是Producer压缩，Broker传输，Consumer解压缩，不同的是kaffka的压缩是基于一批一批消息的，对于CPU空闲较多的场景下会有更大的吞吐提升。","like_count":12,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":467599,"discussion_content":"只会解压header，消息体不会解压。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1568769392,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":131258,"user_name":"路途","can_delete":false,"product_type":"c1","uid":1581140,"ip_address":"","ucode":"A999998E04618B","user_header":"https://static001.geekbang.org/account/avatar/00/18/20/54/08c28585.jpg","comment_is_top":false,"comment_ctime":1567682516,"is_pvip":false,"replies":[{"id":49812,"content":"正常情况下，客户端每次拉消息都是整批拉取，不会出现你说的情况。如果是指定消费位置来消费，客户端在拉取整批消息之后，再计算一下批内的偏移量，把正确的消息返回给用户代码。","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1567731914,"ip_address":"","comment_id":131258,"utype":1}],"discussion_count":3,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"kafka压缩后它的offset如何计算，假如刚好要回溯的数据就在压缩包中offset如何计算","like_count":7,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":466307,"discussion_content":"👍👍👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567732550,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":131148,"user_name":"青舟","can_delete":false,"product_type":"c1","uid":1192732,"ip_address":"","ucode":"2651482AC0DEC6","user_header":"https://static001.geekbang.org/account/avatar/00/12/33/1c/59a4e803.jpg","comment_is_top":false,"comment_ctime":1567652209,"is_pvip":false,"replies":[{"id":49815,"content":"因为批消息还不支持压缩","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1567732276,"ip_address":"","comment_id":131148,"utype":1}],"discussion_count":3,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"RocketMQ 在DefaultMQProducerImpl.tryToCompressMessage中判断消息长度大于4Kb就进行压缩，压缩算法是zip（java.util.zip.Deflater）\n\n我注意到在发送时，会判断如果消息是一个批量消息（MessageBatch），就不开启压缩。这是为什么呢？","like_count":5,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":466312,"discussion_content":"因为批消息还不支持压缩","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567732276,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1058972,"avatar":"https://static001.geekbang.org/account/avatar/00/10/28/9c/73e76b19.jpg","nickname":"姜戈","note":"","ucode":"45C4BE93C8E4CC","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":7733,"discussion_content":"你看一下源码就知道了，当前rocketmq不支持批量消息压缩。（标注）\nprivate boolean tryToCompressMessage(final Message msg) {\n        if (msg instanceof MessageBatch) {\n            //batch dose not support compressing right now\n            //当前不支持压缩批消息\n            return false;\n        }\n        byte[] body = msg.getBody();\n        if (body != null) {\n            if (body.length >= this.defaultMQProducer.getCompressMsgBodyOverHowmuch()) {\n                try {\n                    byte[] data = UtilAll.compress(body, zipCompressLevel);\n                    if (data != null) {\n                        msg.setBody(data);\n                        return true;\n                    }\n                } catch (IOException e) {\n                    log.error(&#34;tryToCompressMessage exception&#34;, e);\n                    log.warn(msg.toString());\n                }\n            }\n        }\n\n        return false;\n    }","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1567656485,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1192732,"avatar":"https://static001.geekbang.org/account/avatar/00/12/33/1c/59a4e803.jpg","nickname":"青舟","note":"","ucode":"2651482AC0DEC6","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1058972,"avatar":"https://static001.geekbang.org/account/avatar/00/10/28/9c/73e76b19.jpg","nickname":"姜戈","note":"","ucode":"45C4BE93C8E4CC","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":7824,"discussion_content":"我就是看到这里不支持压缩，所以才想是什么原因导致它不支持压缩？","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1567685080,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":7733,"ip_address":"","group_id":0},"score":7824,"extra":""}]}]},{"had_liked":false,"id":131127,"user_name":"奕","can_delete":false,"product_type":"c1","uid":1005391,"ip_address":"","ucode":"73CEA468CE70C3","user_header":"https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg","comment_is_top":false,"comment_ctime":1567648120,"is_pvip":false,"replies":[{"id":49816,"content":"这个不能一概而论啊，你需要根据我这节课的讲的那些原则自己衡量一下。一般来说，如果消息体比较大，客户端的CPU不是很忙，开启压缩后都会有一定的性能提升。","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1567732519,"ip_address":"","comment_id":131127,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"现在系统使用的是rabbitmq，在发送数据时候使用的是protobuffer进行序列化，这时候还有必要开启压缩吗？如果开启了压缩会不会效果更好的？","like_count":2,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":466300,"discussion_content":"这个不能一概而论啊，你需要根据我这节课的讲的那些原则自己衡量一下。一般来说，如果消息体比较大，客户端的CPU不是很忙，开启压缩后都会有一定的性能提升。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1567732519,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":131767,"user_name":"北冥Master","can_delete":false,"product_type":"c1","uid":1014142,"ip_address":"","ucode":"EBCCEC79AFC5DF","user_header":"https://static001.geekbang.org/account/avatar/00/0f/79/7e/c38ac02f.jpg","comment_is_top":false,"comment_ctime":1567902892,"is_pvip":false,"replies":[{"id":50422,"content":"在发送端，批的大小是有参数控制的，不会过大。","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1567992832,"ip_address":"","comment_id":131767,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"如果是批消息，服务端不解压，直接返回给消费者端解压---如果批消息很大，一个批次几百上千呢？也是一次性返回给消费者端吗？这样岂不是影响并发消费，从而影响消费速度？","like_count":1,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":466613,"discussion_content":"在发送端，批的大小是有参数控制的，不会过大。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567992832,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":131071,"user_name":"leslie","can_delete":false,"product_type":"c1","uid":1324255,"ip_address":"","ucode":"798E7C1CC98CC2","user_header":"https://static001.geekbang.org/account/avatar/00/14/34/df/64e3d533.jpg","comment_is_top":false,"comment_ctime":1567631257,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"     老师提到了压缩：适当扩展一下，这个东西早期数据库备份其实经常会要去使用；个人的感受不是耗资源-是极度耗费资源，压缩比越大CPU越大，服务器做数据库备份压缩时基本上什么事情都做不了，尤其像oracle、sybase这种；sybase的备份策略更人性但是代价的权衡其实当时就、、、、、、\n     大多数情况下其实我们在做这种事情时不太可能单独什么事情都不做：可能生产环境还是会去选择Rockmq吧，毕竟中间件不像数据库-单独的服务器，cpu的资源使用上相对宽裕，尤其是对于中小型企业，硬件资源没有那么宽裕，Rockmq是个不错的选择，计算机组成原理的课程还是对于数据备份做了一些比较好的讲解，胡老师的课对kafka的压缩机制有讲解；综合下来我应当会选择Rockmq。\n     几门课程同时在跟-确实发现时间上蛮吃力，为了学习天天的业余生活活在闹钟之中：可能很多东西只能等完课了再进一步梳理；只能用刘超老师的学习法-第一遍先粗学了，第一遍还是希望明白是什么回事，什么场景怎么用；老师的消息队列课程与计算机组成原理、操作系统的关系更大些，同时跟这三门就已经挤压不出时间到kafka上了，完课的时候明白选什么，为什么选算是基本达到学习这门功课的基本目标吧，学习过程中为了明白原来而交叉去学习其它两门课所付出的时间代价其实远超与预期。\n     感谢老师的分享：期待老师下节课的分享。","like_count":37,"discussions":[{"author":{"id":3585239,"avatar":"","nickname":"Geek_fc724d","note":"","ucode":"684ACFE9CBBD8D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":613332,"discussion_content":"计算机组成原理是哪门课啊，怎么搜不到","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1681269791,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"江苏","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":187679,"user_name":"Ryoma","can_delete":false,"product_type":"c1","uid":1130590,"ip_address":"","ucode":"7F692369239692","user_header":"https://static001.geekbang.org/account/avatar/00/11/40/5e/b8fada94.jpg","comment_is_top":false,"comment_ctime":1584191406,"is_pvip":false,"replies":null,"discussion_count":2,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"关于 Kafka Broker 端对于压缩的处理，隔壁课程有不一样的讲解。如果 producer 端与 Broker 选择的压缩算法不一致，此时 Broker 只能先解压缩，然后再重新压缩。","like_count":5,"discussions":[{"author":{"id":1018177,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK9uWq1YjJ79IftTc4g4N2icNRLrLjibyia25iaBMWmpTmuq1Av62cP8oqf28ZjjgRMRGDcnLib69ZdVEQ/132","nickname":"L萧萧木叶","note":"","ucode":"78CABDECA48DE4","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":356481,"discussion_content":"请问是隔壁的哪个课程？我去瞅瞅","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1615607201,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1133014,"avatar":"https://static001.geekbang.org/account/avatar/00/11/49/d6/96894426.jpg","nickname":"lijava","note":"","ucode":"0B1B4396C0DAE8","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1018177,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK9uWq1YjJ79IftTc4g4N2icNRLrLjibyia25iaBMWmpTmuq1Av62cP8oqf28ZjjgRMRGDcnLib69ZdVEQ/132","nickname":"L萧萧木叶","note":"","ucode":"78CABDECA48DE4","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":589755,"discussion_content":"应该是kafka原理那个","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1665301013,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":356481,"ip_address":"北京","group_id":0},"score":589755,"extra":""}]}]},{"had_liked":false,"id":131334,"user_name":"张三","can_delete":false,"product_type":"c1","uid":1004092,"ip_address":"","ucode":"1155528FAE1546","user_header":"https://static001.geekbang.org/account/avatar/00/0f/52/3c/d6fcb93a.jpg","comment_is_top":false,"comment_ctime":1567727262,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"确实想到了霍夫曼编码，还有位图。","like_count":3},{"had_liked":false,"id":131159,"user_name":"姜戈","can_delete":false,"product_type":"c1","uid":1058972,"ip_address":"","ucode":"45C4BE93C8E4CC","user_header":"https://static001.geekbang.org/account/avatar/00/10/28/9c/73e76b19.jpg","comment_is_top":false,"comment_ctime":1567655638,"is_pvip":false,"replies":[{"id":49814,"content":"👍👍👍","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1567732255,"ip_address":"","comment_id":131159,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"RocketMq(rockmq-all 4.4.1-SNAPSHOT): 默认压缩大于4K的消息（可配置），压缩算法是zip，默认级别5（可配置），同样也是客户端做解压缩工作，服务端只存储；对于批量消息的压缩，目前并不支持。\n摘取DefaultMQProducerImpl.java 部分源码：\nprivate boolean tryToCompressMessage(final Message msg) {\n        if (msg instanceof MessageBatch) {\n            &#47;&#47;batch dose not support compressing right now\n            return false;\n        }\n        byte[] body = msg.getBody();\n        if (body != null) {\n            if (body.length &gt;= this.defaultMQProducer.getCompressMsgBodyOverHowmuch()) {\n                try {\n                    byte[] data = UtilAll.compress(body, zipCompressLevel);\n                    if (data != null) {\n                        msg.setBody(data);\n                        return true;\n                    }\n                } catch (IOException e) {\n                    log.error(&quot;tryToCompressMessage exception&quot;, e);\n                    log.warn(msg.toString());\n                }\n            }\n        }\n\n        return false;\n    }","like_count":68,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":466316,"discussion_content":"👍👍👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567732255,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":134048,"user_name":"Standly","can_delete":false,"product_type":"c1","uid":1181055,"ip_address":"","ucode":"805CC5784D3F76","user_header":"https://static001.geekbang.org/account/avatar/00/12/05/7f/a7df049a.jpg","comment_is_top":false,"comment_ctime":1568728813,"is_pvip":false,"replies":[{"id":51434,"content":"只会解压header，消息体不会解压。","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1568769392,"ip_address":"","comment_id":134048,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"Kafka每个压缩过的消息集合在 Broker 端写入时都要发生解压缩操作，目的是为了对消息执行各种验证。\n好像是这样吧？","like_count":29,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":467599,"discussion_content":"只会解压header，消息体不会解压。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1568769392,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":131139,"user_name":"DFighting","can_delete":false,"product_type":"c1","uid":1233193,"ip_address":"","ucode":"F3BA2426FF8582","user_header":"https://static001.geekbang.org/account/avatar/00/12/d1/29/1b1234ed.jpg","comment_is_top":false,"comment_ctime":1567650067,"is_pvip":false,"replies":[{"id":49817,"content":"👍👍👍","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1567732550,"ip_address":"","comment_id":131139,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"一直学习算法都是空间换时间，但是在消息中间件和一些IO密集型的应用中还会有CPU计算资源换网络带宽&#47;磁盘IO，刚刚看了下RocketMQ源码，在DefaultMQPullConsumerlmpl.pullSyncImpl中会调用PullAPIWrapper.processPullResult，在这里会为压缩的消息进行解压缩。Producer端没找到压缩的源码，只是在checkMessage中会对消息体的长度进行限制，超过4K(网上查的)会抛出来MQClientException，猜测应该也是会压缩。也就是RocketMQ的压缩机制也是Producer压缩，Broker传输，Consumer解压缩，不同的是kaffka的压缩是基于一批一批消息的，对于CPU空闲较多的场景下会有更大的吞吐提升。","like_count":12,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":466307,"discussion_content":"👍👍👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567732550,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":131258,"user_name":"路途","can_delete":false,"product_type":"c1","uid":1581140,"ip_address":"","ucode":"A999998E04618B","user_header":"https://static001.geekbang.org/account/avatar/00/18/20/54/08c28585.jpg","comment_is_top":false,"comment_ctime":1567682516,"is_pvip":false,"replies":[{"id":49812,"content":"正常情况下，客户端每次拉消息都是整批拉取，不会出现你说的情况。如果是指定消费位置来消费，客户端在拉取整批消息之后，再计算一下批内的偏移量，把正确的消息返回给用户代码。","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1567731914,"ip_address":"","comment_id":131258,"utype":1}],"discussion_count":3,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"kafka压缩后它的offset如何计算，假如刚好要回溯的数据就在压缩包中offset如何计算","like_count":7,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":466354,"discussion_content":"正常情况下，客户端每次拉消息都是整批拉取，不会出现你说的情况。如果是指定消费位置来消费，客户端在拉取整批消息之后，再计算一下批内的偏移量，把正确的消息返回给用户代码。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567731914,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1532404,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEIvUlicgrWtibbDzwhLw5cQrDSy2JuE1mVvmXq11KQIwpLicgDuWfpp9asE0VCN6HhibPDWn7wBc2lfmA/132","nickname":"a、","note":"","ucode":"590FE8DB111492","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":7901,"discussion_content":"kafka压缩消息，比如这批消息的offset是1024~1030总共7条，那么压缩后的消息格式会有一条，但是有两层，外层的offset是1030，外层的value里有7条记录，offset依次是0~7，解压缩后要重新计算这七条的offset，首先用内层的最后一条offset(7)－求的那条的offset(比如是0)，那么结果就是-6，然后再用外层的offset加上-6就是1024。以上参考＜深入理解kafka:核心设计与实现原理＞","likes_number":8,"is_delete":false,"is_hidden":false,"ctime":1567702284,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1049360,"avatar":"https://static001.geekbang.org/account/avatar/00/10/03/10/26f9f762.jpg","nickname":"Switch","note":"","ucode":"D8A7F7F6A0BEA9","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1532404,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEIvUlicgrWtibbDzwhLw5cQrDSy2JuE1mVvmXq11KQIwpLicgDuWfpp9asE0VCN6HhibPDWn7wBc2lfmA/132","nickname":"a、","note":"","ucode":"590FE8DB111492","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":39842,"discussion_content":"offset 依次是 0~7 应该是 0-6 吧\n用内层的最后一条 offset (7) 应该是 offset(6) 吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1571997576,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":7901,"ip_address":"","group_id":0},"score":39842,"extra":""}]}]},{"had_liked":false,"id":131148,"user_name":"青舟","can_delete":false,"product_type":"c1","uid":1192732,"ip_address":"","ucode":"2651482AC0DEC6","user_header":"https://static001.geekbang.org/account/avatar/00/12/33/1c/59a4e803.jpg","comment_is_top":false,"comment_ctime":1567652209,"is_pvip":false,"replies":[{"id":49815,"content":"因为批消息还不支持压缩","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1567732276,"ip_address":"","comment_id":131148,"utype":1}],"discussion_count":3,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"RocketMQ 在DefaultMQProducerImpl.tryToCompressMessage中判断消息长度大于4Kb就进行压缩，压缩算法是zip（java.util.zip.Deflater）\n\n我注意到在发送时，会判断如果消息是一个批量消息（MessageBatch），就不开启压缩。这是为什么呢？","like_count":5,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":466354,"discussion_content":"正常情况下，客户端每次拉消息都是整批拉取，不会出现你说的情况。如果是指定消费位置来消费，客户端在拉取整批消息之后，再计算一下批内的偏移量，把正确的消息返回给用户代码。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567731914,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1532404,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEIvUlicgrWtibbDzwhLw5cQrDSy2JuE1mVvmXq11KQIwpLicgDuWfpp9asE0VCN6HhibPDWn7wBc2lfmA/132","nickname":"a、","note":"","ucode":"590FE8DB111492","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":7901,"discussion_content":"kafka压缩消息，比如这批消息的offset是1024~1030总共7条，那么压缩后的消息格式会有一条，但是有两层，外层的offset是1030，外层的value里有7条记录，offset依次是0~7，解压缩后要重新计算这七条的offset，首先用内层的最后一条offset(7)－求的那条的offset(比如是0)，那么结果就是-6，然后再用外层的offset加上-6就是1024。以上参考＜深入理解kafka:核心设计与实现原理＞","likes_number":8,"is_delete":false,"is_hidden":false,"ctime":1567702284,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1049360,"avatar":"https://static001.geekbang.org/account/avatar/00/10/03/10/26f9f762.jpg","nickname":"Switch","note":"","ucode":"D8A7F7F6A0BEA9","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1532404,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEIvUlicgrWtibbDzwhLw5cQrDSy2JuE1mVvmXq11KQIwpLicgDuWfpp9asE0VCN6HhibPDWn7wBc2lfmA/132","nickname":"a、","note":"","ucode":"590FE8DB111492","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":39842,"discussion_content":"offset 依次是 0~7 应该是 0-6 吧\n用内层的最后一条 offset (7) 应该是 offset(6) 吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1571997576,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":7901,"ip_address":"","group_id":0},"score":39842,"extra":""}]}]},{"had_liked":false,"id":131127,"user_name":"奕","can_delete":false,"product_type":"c1","uid":1005391,"ip_address":"","ucode":"73CEA468CE70C3","user_header":"https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg","comment_is_top":false,"comment_ctime":1567648120,"is_pvip":false,"replies":[{"id":49816,"content":"这个不能一概而论啊，你需要根据我这节课的讲的那些原则自己衡量一下。一般来说，如果消息体比较大，客户端的CPU不是很忙，开启压缩后都会有一定的性能提升。","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1567732519,"ip_address":"","comment_id":131127,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"现在系统使用的是rabbitmq，在发送数据时候使用的是protobuffer进行序列化，这时候还有必要开启压缩吗？如果开启了压缩会不会效果更好的？","like_count":2,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":466312,"discussion_content":"因为批消息还不支持压缩","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567732276,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1058972,"avatar":"https://static001.geekbang.org/account/avatar/00/10/28/9c/73e76b19.jpg","nickname":"姜戈","note":"","ucode":"45C4BE93C8E4CC","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":7733,"discussion_content":"你看一下源码就知道了，当前rocketmq不支持批量消息压缩。（标注）\nprivate boolean tryToCompressMessage(final Message msg) {\n        if (msg instanceof MessageBatch) {\n            //batch dose not support compressing right now\n            //当前不支持压缩批消息\n            return false;\n        }\n        byte[] body = msg.getBody();\n        if (body != null) {\n            if (body.length >= this.defaultMQProducer.getCompressMsgBodyOverHowmuch()) {\n                try {\n                    byte[] data = UtilAll.compress(body, zipCompressLevel);\n                    if (data != null) {\n                        msg.setBody(data);\n                        return true;\n                    }\n                } catch (IOException e) {\n                    log.error(&#34;tryToCompressMessage exception&#34;, e);\n                    log.warn(msg.toString());\n                }\n            }\n        }\n\n        return false;\n    }","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1567656485,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1192732,"avatar":"https://static001.geekbang.org/account/avatar/00/12/33/1c/59a4e803.jpg","nickname":"青舟","note":"","ucode":"2651482AC0DEC6","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1058972,"avatar":"https://static001.geekbang.org/account/avatar/00/10/28/9c/73e76b19.jpg","nickname":"姜戈","note":"","ucode":"45C4BE93C8E4CC","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":7824,"discussion_content":"我就是看到这里不支持压缩，所以才想是什么原因导致它不支持压缩？","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1567685080,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":7733,"ip_address":"","group_id":0},"score":7824,"extra":""}]}]},{"had_liked":false,"id":131767,"user_name":"北冥Master","can_delete":false,"product_type":"c1","uid":1014142,"ip_address":"","ucode":"EBCCEC79AFC5DF","user_header":"https://static001.geekbang.org/account/avatar/00/0f/79/7e/c38ac02f.jpg","comment_is_top":false,"comment_ctime":1567902892,"is_pvip":false,"replies":[{"id":50422,"content":"在发送端，批的大小是有参数控制的，不会过大。","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1567992832,"ip_address":"","comment_id":131767,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"如果是批消息，服务端不解压，直接返回给消费者端解压---如果批消息很大，一个批次几百上千呢？也是一次性返回给消费者端吗？这样岂不是影响并发消费，从而影响消费速度？","like_count":1,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":466300,"discussion_content":"这个不能一概而论啊，你需要根据我这节课的讲的那些原则自己衡量一下。一般来说，如果消息体比较大，客户端的CPU不是很忙，开启压缩后都会有一定的性能提升。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1567732519,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":131071,"user_name":"leslie","can_delete":false,"product_type":"c1","uid":1324255,"ip_address":"","ucode":"798E7C1CC98CC2","user_header":"https://static001.geekbang.org/account/avatar/00/14/34/df/64e3d533.jpg","comment_is_top":false,"comment_ctime":1567631257,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"     老师提到了压缩：适当扩展一下，这个东西早期数据库备份其实经常会要去使用；个人的感受不是耗资源-是极度耗费资源，压缩比越大CPU越大，服务器做数据库备份压缩时基本上什么事情都做不了，尤其像oracle、sybase这种；sybase的备份策略更人性但是代价的权衡其实当时就、、、、、、\n     大多数情况下其实我们在做这种事情时不太可能单独什么事情都不做：可能生产环境还是会去选择Rockmq吧，毕竟中间件不像数据库-单独的服务器，cpu的资源使用上相对宽裕，尤其是对于中小型企业，硬件资源没有那么宽裕，Rockmq是个不错的选择，计算机组成原理的课程还是对于数据备份做了一些比较好的讲解，胡老师的课对kafka的压缩机制有讲解；综合下来我应当会选择Rockmq。\n     几门课程同时在跟-确实发现时间上蛮吃力，为了学习天天的业余生活活在闹钟之中：可能很多东西只能等完课了再进一步梳理；只能用刘超老师的学习法-第一遍先粗学了，第一遍还是希望明白是什么回事，什么场景怎么用；老师的消息队列课程与计算机组成原理、操作系统的关系更大些，同时跟这三门就已经挤压不出时间到kafka上了，完课的时候明白选什么，为什么选算是基本达到学习这门功课的基本目标吧，学习过程中为了明白原来而交叉去学习其它两门课所付出的时间代价其实远超与预期。\n     感谢老师的分享：期待老师下节课的分享。","like_count":37,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":466613,"discussion_content":"在发送端，批的大小是有参数控制的，不会过大。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567992832,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":187679,"user_name":"Ryoma","can_delete":false,"product_type":"c1","uid":1130590,"ip_address":"","ucode":"7F692369239692","user_header":"https://static001.geekbang.org/account/avatar/00/11/40/5e/b8fada94.jpg","comment_is_top":false,"comment_ctime":1584191406,"is_pvip":false,"replies":null,"discussion_count":2,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"关于 Kafka Broker 端对于压缩的处理，隔壁课程有不一样的讲解。如果 producer 端与 Broker 选择的压缩算法不一致，此时 Broker 只能先解压缩，然后再重新压缩。","like_count":5,"discussions":[{"author":{"id":3585239,"avatar":"","nickname":"Geek_fc724d","note":"","ucode":"684ACFE9CBBD8D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":613332,"discussion_content":"计算机组成原理是哪门课啊，怎么搜不到","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1681269791,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"江苏","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":131334,"user_name":"张三","can_delete":false,"product_type":"c1","uid":1004092,"ip_address":"","ucode":"1155528FAE1546","user_header":"https://static001.geekbang.org/account/avatar/00/0f/52/3c/d6fcb93a.jpg","comment_is_top":false,"comment_ctime":1567727262,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"确实想到了霍夫曼编码，还有位图。","like_count":3,"discussions":[{"author":{"id":1018177,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK9uWq1YjJ79IftTc4g4N2icNRLrLjibyia25iaBMWmpTmuq1Av62cP8oqf28ZjjgRMRGDcnLib69ZdVEQ/132","nickname":"L萧萧木叶","note":"","ucode":"78CABDECA48DE4","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":356481,"discussion_content":"请问是隔壁的哪个课程？我去瞅瞅","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1615607201,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1133014,"avatar":"https://static001.geekbang.org/account/avatar/00/11/49/d6/96894426.jpg","nickname":"lijava","note":"","ucode":"0B1B4396C0DAE8","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1018177,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK9uWq1YjJ79IftTc4g4N2icNRLrLjibyia25iaBMWmpTmuq1Av62cP8oqf28ZjjgRMRGDcnLib69ZdVEQ/132","nickname":"L萧萧木叶","note":"","ucode":"78CABDECA48DE4","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":589755,"discussion_content":"应该是kafka原理那个","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1665301013,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":356481,"ip_address":"北京","group_id":0},"score":589755,"extra":""}]}]},{"had_liked":false,"id":235555,"user_name":"xuanyuan","can_delete":false,"product_type":"c1","uid":1113737,"ip_address":"","ucode":"1EC79B9372868F","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTI2icbib62icXtibTkThtyRksbuJLoTLMts7zook2S30MiaBtbz0f5JskwYicwqXkhpYfvCpuYkcvPTibEaQ/132","comment_is_top":false,"comment_ctime":1595084615,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"印象中linux极限tps是百万级，后面就是内核成瓶颈了。200万一般需要用户态协议栈了","like_count":2},{"had_liked":false,"id":131102,"user_name":"业余草","can_delete":false,"product_type":"c1","uid":1126538,"ip_address":"","ucode":"99BDC1E629049D","user_header":"https://static001.geekbang.org/account/avatar/00/11/30/8a/b5ca7286.jpg","comment_is_top":false,"comment_ctime":1567644174,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"Kafka设计的很精妙，但是使用的场景局限性也很大。压缩是现代网络通信中必不可少的一环，也有不少专栏都写过了。","like_count":1},{"had_liked":false,"id":366588,"user_name":"nikoart","can_delete":false,"product_type":"c1","uid":1031336,"ip_address":"北京","ucode":"FF7AB24E25ABA9","user_header":"https://static001.geekbang.org/account/avatar/00/0f/bc/a8/810c8fd4.jpg","comment_is_top":false,"comment_ctime":1673946203,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"rocketmq默认消息体大于4k开启压缩，使用的是java.util.zip.Deflater工具","like_count":0},{"had_liked":false,"id":341084,"user_name":"再见理想","can_delete":false,"product_type":"c1","uid":1245999,"ip_address":"","ucode":"FAC88B3F6F6DFD","user_header":"https://static001.geekbang.org/account/avatar/00/13/03/2f/0a5e0751.jpg","comment_is_top":false,"comment_ctime":1649336871,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"数据压缩 通过时间换空间。\n在系统瓶颈在IO上，并且对cpu利用率不高时，可以选择对数据进行压缩后传输。\n但是数据 压缩&#47;解压缩的性能损耗也是我们应该注意的，\n需要根据数据的形态选择不同的压缩算法（不同的压缩比&#47;压缩效率）以及压缩分段。\n对数据压缩后传输可以有效地减少带宽不足对系统的影响，提升服务端的吞吐量。","like_count":0},{"had_liked":false,"id":337626,"user_name":"William Ning","can_delete":false,"product_type":"c1","uid":1592279,"ip_address":"","ucode":"4DB8D05E69E5F3","user_header":"https://static001.geekbang.org/account/avatar/00/18/4b/d7/f46c6dfd.jpg","comment_is_top":false,"comment_ctime":1646921140,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"文章与评论看完，还是要去回顾前面的知识点，以及其他的知识点。 要学的东西可真多，特别是这些知识如何融会贯通起来 -- 学习并思考着...","like_count":0},{"had_liked":false,"id":336194,"user_name":"Panmax","can_delete":false,"product_type":"c1","uid":1004871,"ip_address":"","ucode":"9D65E3B84C5519","user_header":"https://static001.geekbang.org/account/avatar/00/0f/55/47/d217c45f.jpg","comment_is_top":false,"comment_ctime":1646006300,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"如何理解「如果你的系统读写比严重不均衡，你还要考虑，每读一次数据就要解压一次是不是划算。」？","like_count":0},{"had_liked":false,"id":327551,"user_name":"朱延云","can_delete":false,"product_type":"c1","uid":1319759,"ip_address":"","ucode":"08E6EE2AB82DE9","user_header":"https://static001.geekbang.org/account/avatar/00/14/23/4f/3ce24bed.jpg","comment_is_top":false,"comment_ctime":1640166675,"is_pvip":false,"replies":null,"discussion_count":2,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"2000 万 TPS 乘以 1KB 的消息大小，再把字节 Byte 转换成比特 bit，换算成网络传输的带宽是 200Gb&#47;s\n\n不应该是 20Gb&#47;s 吗？\n","like_count":0,"discussions":[{"author":{"id":1256821,"avatar":"https://static001.geekbang.org/account/avatar/00/13/2d/75/e7c29de4.jpg","nickname":"wkq2786130","note":"","ucode":"0F3A9DF9928C67","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":587341,"discussion_content":"2000万QPS指的是单条消息维度的，实际上kafka是批处理的，按照(批处理)网络IO的QPS大概在100万QPS左右，甚至更小。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1662985882,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":234506,"user_name":"Sun Fei","can_delete":false,"product_type":"c1","uid":1032631,"ip_address":"","ucode":"092EC0992050BB","user_header":"https://static001.geekbang.org/account/avatar/00/0f/c1/b7/57f153f6.jpg","comment_is_top":false,"comment_ctime":1594708948,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"    private boolean tryToCompressMessage(final Message msg) {\n        if (msg instanceof MessageBatch) {\n            &#47;&#47;不支持批消息的压缩\n            return false;\n        }\n        byte[] body = msg.getBody();\n        if (body != null) {\n            &#47;&#47; compressMsgBodyOverHowmuch = 1024 * 4 \n            if (body.length &gt;= this.defaultMQProducer.getCompressMsgBodyOverHowmuch()) {\n                try {\n                    byte[] data = UtilAll.compress(body, zipCompressLevel);\n                    if (data != null) {\n                        msg.setBody(data);\n                        return true;\n                    }\n                } catch (IOException e) {\n                    log.error(&quot;tryToCompressMessage exception&quot;, e);\n                    log.warn(msg.toString());\n                }\n            }\n        }\n\n        return false;\n    }","like_count":0},{"had_liked":false,"id":135999,"user_name":"钱","can_delete":false,"product_type":"c1","uid":1009652,"ip_address":"","ucode":"2C92A243A463D4","user_header":"https://static001.geekbang.org/account/avatar/00/0f/67/f4/9a1feb59.jpg","comment_is_top":false,"comment_ctime":1569324415,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"压缩——以CPU计算资源换空间，以期减少网络带宽或磁盘存储空间，提高传输速率。老师，讲的20个0的例子很形象，如果夸张点2000个0就更能体会压缩的效果啦😄","like_count":0},{"had_liked":false,"id":132115,"user_name":"梦典","can_delete":false,"product_type":"c1","uid":1203920,"ip_address":"","ucode":"0A6F91068A13E8","user_header":"https://static001.geekbang.org/account/avatar/00/12/5e/d0/e676ac19.jpg","comment_is_top":false,"comment_ctime":1568024765,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"RockerMQ生产者压缩：\n压缩逻辑控制\n  DefaultMQProducerImpl#tryToCompressMessage\n    批消息，暂不支持\n    Message的body byte[] 超过 4K，开启压缩\n    压缩level默认5，启动参数-Drocketmq.message.compressLevel可以配置\n压缩数据处理\n  UtilAll#compress(final byte[] src, final int level)\n    使用JDK的\n      java.io.ByteArrayOutputStream\n      java.util.zip.Deflater\n      java.util.zip.DeflaterOutputStream\n","like_count":0,"discussions":[{"author":{"id":2861929,"avatar":"http://thirdwx.qlogo.cn/mmopen/2kpMNDYsSfCibibkl1x62jWodYGcwS2OZJhBW347gy4VsA1U8bUyBNxGx9XxMeWuAW98SpHYiaI470H1xziarib8YvYSB0ZnngbCW/132","nickname":"🐷杨磊磊","note":"","ucode":"858C3FBFF7F023","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612323,"discussion_content":"B=8b,  B约等于10b","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680599878,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"江苏","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1158930,"avatar":"https://static001.geekbang.org/account/avatar/00/11/af/12/8629c85e.jpg","nickname":"Tutu","note":"","ucode":"1F105484397134","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":546155,"discussion_content":"20GB，约等于200Gb","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1642178319,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":235555,"user_name":"xuanyuan","can_delete":false,"product_type":"c1","uid":1113737,"ip_address":"","ucode":"1EC79B9372868F","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTI2icbib62icXtibTkThtyRksbuJLoTLMts7zook2S30MiaBtbz0f5JskwYicwqXkhpYfvCpuYkcvPTibEaQ/132","comment_is_top":false,"comment_ctime":1595084615,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"印象中linux极限tps是百万级，后面就是内核成瓶颈了。200万一般需要用户态协议栈了","like_count":2,"discussions":[{"author":{"id":1256821,"avatar":"https://static001.geekbang.org/account/avatar/00/13/2d/75/e7c29de4.jpg","nickname":"wkq2786130","note":"","ucode":"0F3A9DF9928C67","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":587341,"discussion_content":"2000万QPS指的是单条消息维度的，实际上kafka是批处理的，按照(批处理)网络IO的QPS大概在100万QPS左右，甚至更小。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1662985882,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":131102,"user_name":"业余草","can_delete":false,"product_type":"c1","uid":1126538,"ip_address":"","ucode":"99BDC1E629049D","user_header":"https://static001.geekbang.org/account/avatar/00/11/30/8a/b5ca7286.jpg","comment_is_top":false,"comment_ctime":1567644174,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"Kafka设计的很精妙，但是使用的场景局限性也很大。压缩是现代网络通信中必不可少的一环，也有不少专栏都写过了。","like_count":1},{"had_liked":false,"id":366588,"user_name":"nikoart","can_delete":false,"product_type":"c1","uid":1031336,"ip_address":"北京","ucode":"FF7AB24E25ABA9","user_header":"https://static001.geekbang.org/account/avatar/00/0f/bc/a8/810c8fd4.jpg","comment_is_top":false,"comment_ctime":1673946203,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"rocketmq默认消息体大于4k开启压缩，使用的是java.util.zip.Deflater工具","like_count":0},{"had_liked":false,"id":341084,"user_name":"再见理想","can_delete":false,"product_type":"c1","uid":1245999,"ip_address":"","ucode":"FAC88B3F6F6DFD","user_header":"https://static001.geekbang.org/account/avatar/00/13/03/2f/0a5e0751.jpg","comment_is_top":false,"comment_ctime":1649336871,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"数据压缩 通过时间换空间。\n在系统瓶颈在IO上，并且对cpu利用率不高时，可以选择对数据进行压缩后传输。\n但是数据 压缩&#47;解压缩的性能损耗也是我们应该注意的，\n需要根据数据的形态选择不同的压缩算法（不同的压缩比&#47;压缩效率）以及压缩分段。\n对数据压缩后传输可以有效地减少带宽不足对系统的影响，提升服务端的吞吐量。","like_count":0},{"had_liked":false,"id":337626,"user_name":"William Ning","can_delete":false,"product_type":"c1","uid":1592279,"ip_address":"","ucode":"4DB8D05E69E5F3","user_header":"https://static001.geekbang.org/account/avatar/00/18/4b/d7/f46c6dfd.jpg","comment_is_top":false,"comment_ctime":1646921140,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"文章与评论看完，还是要去回顾前面的知识点，以及其他的知识点。 要学的东西可真多，特别是这些知识如何融会贯通起来 -- 学习并思考着...","like_count":0},{"had_liked":false,"id":336194,"user_name":"Panmax","can_delete":false,"product_type":"c1","uid":1004871,"ip_address":"","ucode":"9D65E3B84C5519","user_header":"https://static001.geekbang.org/account/avatar/00/0f/55/47/d217c45f.jpg","comment_is_top":false,"comment_ctime":1646006300,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"如何理解「如果你的系统读写比严重不均衡，你还要考虑，每读一次数据就要解压一次是不是划算。」？","like_count":0},{"had_liked":false,"id":327551,"user_name":"朱延云","can_delete":false,"product_type":"c1","uid":1319759,"ip_address":"","ucode":"08E6EE2AB82DE9","user_header":"https://static001.geekbang.org/account/avatar/00/14/23/4f/3ce24bed.jpg","comment_is_top":false,"comment_ctime":1640166675,"is_pvip":false,"replies":null,"discussion_count":2,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"2000 万 TPS 乘以 1KB 的消息大小，再把字节 Byte 转换成比特 bit，换算成网络传输的带宽是 200Gb&#47;s\n\n不应该是 20Gb&#47;s 吗？\n","like_count":0,"discussions":[{"author":{"id":2861929,"avatar":"http://thirdwx.qlogo.cn/mmopen/2kpMNDYsSfCibibkl1x62jWodYGcwS2OZJhBW347gy4VsA1U8bUyBNxGx9XxMeWuAW98SpHYiaI470H1xziarib8YvYSB0ZnngbCW/132","nickname":"🐷杨磊磊","note":"","ucode":"858C3FBFF7F023","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612323,"discussion_content":"B=8b,  B约等于10b","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680599878,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"江苏","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1158930,"avatar":"https://static001.geekbang.org/account/avatar/00/11/af/12/8629c85e.jpg","nickname":"Tutu","note":"","ucode":"1F105484397134","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":546155,"discussion_content":"20GB，约等于200Gb","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1642178319,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":234506,"user_name":"Sun Fei","can_delete":false,"product_type":"c1","uid":1032631,"ip_address":"","ucode":"092EC0992050BB","user_header":"https://static001.geekbang.org/account/avatar/00/0f/c1/b7/57f153f6.jpg","comment_is_top":false,"comment_ctime":1594708948,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"    private boolean tryToCompressMessage(final Message msg) {\n        if (msg instanceof MessageBatch) {\n            &#47;&#47;不支持批消息的压缩\n            return false;\n        }\n        byte[] body = msg.getBody();\n        if (body != null) {\n            &#47;&#47; compressMsgBodyOverHowmuch = 1024 * 4 \n            if (body.length &gt;= this.defaultMQProducer.getCompressMsgBodyOverHowmuch()) {\n                try {\n                    byte[] data = UtilAll.compress(body, zipCompressLevel);\n                    if (data != null) {\n                        msg.setBody(data);\n                        return true;\n                    }\n                } catch (IOException e) {\n                    log.error(&quot;tryToCompressMessage exception&quot;, e);\n                    log.warn(msg.toString());\n                }\n            }\n        }\n\n        return false;\n    }","like_count":0},{"had_liked":false,"id":135999,"user_name":"钱","can_delete":false,"product_type":"c1","uid":1009652,"ip_address":"","ucode":"2C92A243A463D4","user_header":"https://static001.geekbang.org/account/avatar/00/0f/67/f4/9a1feb59.jpg","comment_is_top":false,"comment_ctime":1569324415,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"压缩——以CPU计算资源换空间，以期减少网络带宽或磁盘存储空间，提高传输速率。老师，讲的20个0的例子很形象，如果夸张点2000个0就更能体会压缩的效果啦😄","like_count":0},{"had_liked":false,"id":132115,"user_name":"梦典","can_delete":false,"product_type":"c1","uid":1203920,"ip_address":"","ucode":"0A6F91068A13E8","user_header":"https://static001.geekbang.org/account/avatar/00/12/5e/d0/e676ac19.jpg","comment_is_top":false,"comment_ctime":1568024765,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"RockerMQ生产者压缩：\n压缩逻辑控制\n  DefaultMQProducerImpl#tryToCompressMessage\n    批消息，暂不支持\n    Message的body byte[] 超过 4K，开启压缩\n    压缩level默认5，启动参数-Drocketmq.message.compressLevel可以配置\n压缩数据处理\n  UtilAll#compress(final byte[] src, final int level)\n    使用JDK的\n      java.io.ByteArrayOutputStream\n      java.util.zip.Deflater\n      java.util.zip.DeflaterOutputStream\n","like_count":0}]}