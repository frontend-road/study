{"id":303430,"title":"13 | 模型服务：怎样把你的离线模型部署到线上？","content":"<p>你好，我是王喆。今天我们来讨论“模型服务”（Model Serving）。</p><p>在实验室的环境下，我们经常使用Spark MLlib、TensorFlow、PyTorch这些流行的机器学习库来训练模型，因为不用直接服务用户，所以往往得到一些离线的训练结果就觉得大功告成了。但在业界的生产环境中，模型需要在线上运行，实时地根据用户请求生成模型的预估值。这个把模型部署在线上环境，并实时进行模型推断（Inference）的过程就是模型服务。</p><p>模型服务对于推荐系统来说是至关重要的线上服务，缺少了它，离线的模型只能在离线环境里面“干着急”，不能发挥功能。但是，模型服务的方法可谓是五花八门，各个公司为了部署自己的模型也是各显神通。那么，业界主流的模型服务方法都有哪些，我们又该如何选择呢？</p><p>今天，我就带你学习主流的模型服务方法，并通过TensorFlow Serving把你的模型部署到线上。</p><h2>业界的主流模型服务方法</h2><p>由于各个公司技术栈的特殊性，采用不同的机器学习平台，模型服务的方法会截然不同，不仅如此，使用不同的模型结构和模型存储方式，也会让模型服务的方法产生区别。总的来说，那业界主流的模型服务方法有4种，分别是预存推荐结果或Embedding结果、预训练Embedding+轻量级线上模型、PMML模型以及TensorFlow Serving。接下来，我们就详细讲讲这些方法的实现原理，通过对比它们的优缺点，相信你会找到最合适自己业务场景的方法。</p><!-- [[[read_end]]] --><h3>预存推荐结果或Embedding结果</h3><p>对于推荐系统线上服务来说，最简单直接的模型服务方法就是在离线环境下生成对每个用户的推荐结果，然后将结果预存到以Redis为代表的线上数据库中。这样，我们在线上环境直接取出预存数据推荐给用户即可。</p><p>这个方法的优缺点都非常明显，我把它们总结在了下图中，你可以看看。</p><p><img src=\"https://static001.geekbang.org/resource/image/f7/78/f71c27199778404d97c7f228635ea278.jpeg?wh=1920*746\" alt=\"\" title=\"图1 预存推荐结果优缺点对比\"></p><p>由于这些优缺点的存在，这种直接存储推荐结果的方式往往只适用于用户规模较小，或者一些冷启动、热门榜单等特殊的应用场景中。</p><p>那如果在用户规模比较大的场景下，我们该怎么减少模型存储所需的空间呢？我们其实可以通过存储Embedding的方式来替代直接存储推荐结果。具体来说就是，我们先离线训练好Embedding，然后在线上通过相似度运算得到最终的推荐结果。</p><p>在前面的课程中，我们通过Item2vec、Graph Embedding等方法生成物品Embedding，再存入Redis供线上使用的过程，这就是预存Embedding的模型服务方法的典型应用。</p><p>由于，线上推断过程非常简单快速，因此，预存Embedding的方法是业界经常采用的模型服务手段。但它的局限性同样存在，由于完全基于线下计算出Embedding，这样的方式无法支持线上场景特征的引入，并且无法进行复杂模型结构的线上推断，表达能力受限。因此对于复杂模型，我们还需要从模型实时线上推断的角度入手，来改进模型服务的方法。</p><h3>预训练Embedding+轻量级线上模型</h3><p>事实上，直接预存Embedding的方法让模型表达能力受限这个问题的产生，主要是因为我们仅仅采用了“相似度计算”这样非常简单的方式去得到最终的推荐分数。既然如此，那我们能不能在线上实现一个比较复杂的操作，甚至是用神经网络来生成最终的预估值呢？当然是可行的，这就是业界很多公司采用的“预训练Embedding+轻量级线上模型”的模型服务方式。</p><p>详细一点来说，这样的服务方式指的是“<strong>用复杂深度学习网络离线训练生成Embedding，存入内存数据库，再在线上实现逻辑回归或浅层神经网络等轻量级模型来拟合优化目标</strong>”。</p><p>口说无凭，接下来，我们就来看一个业界实际的例子。我们先来看看下面这张模型结构图，这是阿里的推荐模型MIMN（Multi-channel user Interest Memory Network，多通道用户兴趣记忆网络）的结构。神经网络，才是真正在线上服务的部分。</p><p>仔细看这张图你会注意到，左边粉色的部分是复杂模型部分，右边灰色的部分是简单模型部分。看这张图的时候，其实你不需要纠结于复杂模型的结构细节，你只要知道左边的部分不管多复杂，它们其实是在线下训练生成的，而右边的部分是一个经典的多层神经网络，它才是真正在线上服务的部分。</p><p><img src=\"https://static001.geekbang.org/resource/image/1e/53/1e0c2a6c404786b709c5177f7d337553.jpg?wh=1920*965\" alt=\"\" title=\"图2 阿里的MIMN模型 （出自Practice on Long Sequential User Behavior Modeling for Click-Through Rate Prediction）\"></p><p>这两部分的接口在哪里呢？你可以看一看图中连接处的位置，有两个被虚线框框住的数据结构，分别是S(1)-S(m)和M(1)-M(m)。它们其实就是在离线生成的Embedding向量，在MIMN模型中，它们被称为“多通道用户兴趣向量”，这些Embedding向量就是连接离线模型和线上模型部分的接口。</p><p>线上部分从Redis之类的模型数据库中拿到这些离线生成Embedding向量，然后跟其他特征的Embedding向量组合在一起，扔给一个标准的多层神经网络进行预估，这就是一个典型的“预训练Embedding+轻量级线上模型”的服务方式。</p><p>它的好处显而易见，就是我们隔离了离线模型的复杂性和线上推断的效率要求，离线环境下，你可以尽情地使用复杂结构构建你的模型，只要最终的结果是Embedding，就可以轻松地供给线上推断使用。</p><h3>利用PMML转换和部署模型</h3><p>虽然Embedding+轻量级模型的方法既实用又高效，但它还是把模型进行了割裂，让模型不完全是End2End（端到端）训练+End2End部署这种最“完美”的方式。那有没有能够在离线训练完模型之后什么都不用做，直接部署模型的方式呢？当然是有的，也就是我接下来要讲的脱离于平台的通用模型部署方式，PMML。</p><p>PMML的全称是“预测模型标记语言”(Predictive Model Markup Language, PMML)，它是一种通用的以XML的形式表示不同模型结构参数的标记语言。在模型上线的过程中，PMML经常作为中间媒介连接离线训练平台和线上预测平台。</p><p>这么说可能还比较抽象。接下来，我就以Spark MLlib模型的训练和上线过程为例，来和你详细解释一下，PMML在整个机器学习模型训练及上线流程中扮演的角色。</p><p><img src=\"https://static001.geekbang.org/resource/image/83/8b/835f47b8c7eac3e18711c8c6e22dbd8b.jpeg?wh=1920*591\" alt=\"\" title=\"图3 Spark模型利用PMML的上线过程\"></p><p>图3中的例子使用了JPMML作为序列化和解析PMML文件的library（库），JPMML项目分为Spark和Java Server两部分。Spark部分的library完成Spark MLlib模型的序列化，生成PMML文件，并且把它保存到线上服务器能够触达的数据库或文件系统中，而Java Server部分则完成PMML模型的解析，生成预估模型，完成了与业务逻辑的整合。</p><p>JPMML在Java Server部分只进行推断，不考虑模型训练、分布式部署等一系列问题，因此library比较轻，能够高效地完成推断过程。与JPMML相似的开源项目还有MLeap，同样采用了PMML作为模型转换和上线的媒介。</p><p>事实上，JPMML和MLeap也具备Scikit-learn、TensorFlow等简单模型的转换和上线能力。我把<a href=\"https://github.com/jpmml\">JPMML</a>和<a href=\"https://github.com/combust/mleap\">MLeap</a>的项目地址放在这里，感兴趣的同学可以进一步学习和实践。</p><h3>TensorFlow Serving</h3><p>既然PMML已经是End2End训练+End2End部署这种最“完美”的方式了，那我们的课程中为什么不使用它进行模型服务呢？这是因为对于具有复杂结构的深度学习模型来说，PMML语言的表示能力还是比较有限的，还不足以支持复杂的深度学习模型结构。由于咱们课程中的推荐模型篇，会主要使用TensorFlow来构建深度学习推荐模型，这个时候PMML的能力就有点不足了。想要上线TensorFlow模型，我们就需要借助TensorFlow的原生模型服务模块，也就是TensorFlow Serving的支持。</p><p>从整体工作流程来看，TensorFlow Serving和PMML类工具的流程一致，它们都经历了模型存储、模型载入还原以及提供服务的过程。在具体细节上，TensorFlow在离线把模型序列化，存储到文件系统，TensorFlow Serving把模型文件载入到模型服务器，还原模型推断过程，对外以HTTP接口或gRPC接口的方式提供模型服务。</p><p>再具体到咱们的Sparrow Recsys项目中，我们会在离线使用TensorFlow的Keras接口完成模型构建和训练，再利用TensorFlow Serving载入模型，用Docker作为服务容器，然后在Jetty推荐服务器中发出HTTP请求到TensorFlow Serving，获得模型推断结果，最后推荐服务器利用这一结果完成推荐排序。</p><p><img src=\"https://static001.geekbang.org/resource/image/88/f4/882b2c61f630084e74427b724f64eef4.jpg?wh=1540*506\" alt=\"\" title=\"图4 Sparrow Recsys项目模型服务部分的架构\"></p><h2>实战搭建TensorFlow Serving模型服务</h2><p>好了，清楚了模型服务的相关知识，相信你对各种模型服务方法的优缺点都已经了然于胸了。刚才我们提到，咱们的课程选用了TensorFlow作为构建深度学习推荐模型的主要平台，并且选用了TensorFlow Serving作为模型服务的技术方案，它们可以说是整个推荐系统的核心了。那为了给之后的学习打下基础，接下来，我就带你搭建一个TensorFlow Serving的服务，把这部分重点内容牢牢掌握住。</p><p>总的来说，搭建一个TensorFlow Serving的服务主要有3步，分别是安装Docker，建立TensorFlow Serving服务，以及请求TensorFlow Serving获得预估结果。为了提高咱们的效率，我希望你能打开电脑跟着我的讲解和文稿里的指令代码，一块儿来安装。</p><h3>1. 安装Docker</h3><p>TensorFlow Serving最普遍、最便捷的服务方式就是使用Docker建立模型服务API。为了方便你后面的学习，我再简单说说Docker。Docker是一个开源的应用容器引擎，你可以把它当作一个轻量级的虚拟机。它可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的操作系统，比如Linux/Windows/Mac的机器上。Docker容器相互之间不会有任何接口，而且容器本身的开销极低，这就让Docker成为了非常灵活、安全、伸缩性极强的计算资源平台。</p><p>因为TensorFlow Serving对外提供的是模型服务接口，所以使用Docker作为容器的好处主要有两点，一是可以非常方便的安装，二是在模型服务的压力变化时，可以灵活地增加或减少Docker容器的数量，做到弹性计算，弹性资源分配。Docker的安装也非常简单，我们参考<a href=\"https://www.docker.com/get-started\">官网的教程</a>，像安装一个普通软件一样下载安装就好。</p><p>安装完Docker后，你不仅可以通过图形界面打开并运行Docker，而且可以通过命令行来进行Docker相关的操作。那怎么验证你是否安装成功了呢？只要你打开命令行输入docker --version命令，它能显示出类似“Docker version 19.03.13, build 4484c46d9d”这样的版本号，就说明你的Docker环境已经准备好了。</p><h3>2. 建立TensorFlow Serving服务</h3><p>Docker环境准备好之后，我们就可以着手建立TensorFlow Serving服务了。</p><p>首先，我们要利用Docker命令拉取TensorFlow Serving的镜像:</p><pre><code>\n# 从docker仓库中下载tensorflow/serving镜像\ndocker pull tensorflow/serving\n\n</code></pre><p>然后，我们再从TenSorflow的官方GitHub地址下载TensorFlow Serving相关的测试模型文件：</p><pre><code># 把tensorflow/serving的测试代码clone到本地\ngit clone https://github.com/tensorflow/serving\n# 指定测试数据的地址\nTESTDATA=&quot;$(pwd)/serving/tensorflow_serving/servables/tensorflow/testdata&quot;\n</code></pre><p>最后，我们在Docker中启动一个包含TensorFlow Serving的模型服务容器，并载入我们刚才下载的测试模型文件half_plus_two：</p><pre><code># 启动TensorFlow Serving容器，在8501端口运行模型服务API\ndocker run -t --rm -p 8501:8501 \\\n    -v &quot;$TESTDATA/saved_model_half_plus_two_cpu:/models/half_plus_two&quot; \\\n    -e MODEL_NAME=half_plus_two \\\n    tensorflow/serving &amp;\n</code></pre><p>在命令执行完成后，如果你在Docker的管理界面中看到了TenSorflow Serving容器，如下图所示，就证明TensorFlow Serving服务被你成功建立起来了。</p><p><img src=\"https://static001.geekbang.org/resource/image/35/3c/3539eccb2a57573a75902738c148fe3c.jpg?wh=1920*1213\" alt=\"\" title=\"图5 TensorFlow Serving容器的Docker启动管理界面\"></p><h3>3. 请求TensorFlow Serving获得预估结果</h3><p>最后，我们再来验证一下是否能够通过HTTP请求从TensorFlow Serving API中获得模型的预估结果。我们可以通过curl命令来发送HTTP POST请求到TensorFlow Serving的地址，或者利用Postman等软件来组装POST请求进行验证。</p><pre><code># 请求模型服务API\ncurl -d '{&quot;instances&quot;: [1.0, 2.0, 5.0]}' \\\n    -X POST http://localhost:8501/v1/models/half_plus_two:predict\n</code></pre><p>如果你看到了下图这样的返回结果，就说明TensorFlow Serving服务已经成功建立起来了。</p><pre><code># 返回模型推断结果如下\n# Returns =&gt; { &quot;predictions&quot;: [2.5, 3.0, 4.5] }\n</code></pre><p>如果对这整个过程还有疑问的话，你也可以参考TensorFlow Serving的<a href=\"https://www.tensorflow.org/tfx/serving/docker\">官方教程</a>。</p><p>不过，有一点我还想提醒你，这里我们只是使用了TensorFlow Serving官方自带的一个测试模型，来告诉你怎么准备环境。在推荐模型实战的时候，我们还会基于TensorFlow构建多种不同的深度学习模型，到时候TensorFlow Serving就会派上关键的用场了。</p><p>那对于深度学习推荐系统来说，我们只要选择TensorFlow Serving的模型服务方法就万无一失了吗？当然不是，它也有需要优化的地方。在搭建它的过程会涉及模型更新，整个Docker Container集群的维护，而且TensorFlow Serving的线上性能也需要大量优化来提高，这些工程问题都是我们在实践过程中必须要解决的。但是，它的易用性和对复杂模型的支持，还是让它成为上线TensorFlow模型的第一选择。</p><h2>小结</h2><p>业界主流的模型服务方法有4种，分别是预存推荐结果或Embeding结果、预训练Embeding+轻量级线上模型、利用PMML转换和部署模型以及TensorFlow Serving。</p><p>它们各有优缺点，为了方便你对比，我把它们的优缺点都列在了表格中，你可以看看。</p><p><img src=\"https://static001.geekbang.org/resource/image/51/52/51f65a9b9e10b0808338388e20217d52.jpeg?wh=1920*829\" alt=\"\"></p><p>我们之后的课程会重点使用TensorFlow Serving，它是End2End的解决方案，使用起来非常方便、高效，而且它支持绝大多数TensorFlow的模型结构，对于深度学习推荐系统来说，是一个非常好的选择。但它只支持TensorFlow模型，而且针对线上服务的性能问题，需要进行大量的优化，这是我们在使用时需要重点注意的。</p><p>在实践部分，我们一步步搭建起了基于Docker的TensorFlow Serving服务，这为我们之后进行深度学习推荐模型的上线打好了基础。整个搭建过程非常简单，相信你跟着我的讲解就可以轻松完成。</p><h2>课后思考</h2><p>我们今天讲了如此多的模型服务方式，你能结合自己的经验，谈一谈你是如何在自己的项目中进行模型服务的吗？除了我们今天说的，你还用过哪些模型服务的方法？</p><p>欢迎在留言区分享你的经验，也欢迎你把这节课分享出去，我们下节课见！</p>","neighbors":{"left":{"article_title":"12 | 局部敏感哈希：如何在常数时间内搜索Embedding最近邻？","id":301739},"right":{"article_title":"14 | 融会贯通：Sparrow RecSys中的电影相似推荐功能是如何实现的？","id":303641}},"comments":[{"had_liked":false,"id":274335,"user_name":"找大夫吗","can_delete":false,"product_type":"c1","uid":2346858,"ip_address":"","ucode":"3CFFC732A6F8E7","user_header":"https://static001.geekbang.org/account/avatar/00/23/cf/6a/42ee61a1.jpg","comment_is_top":false,"comment_ctime":1610969223,"is_pvip":false,"replies":[{"id":"99652","content":"是的，大量特征还是从hdfs或者一些数据仓库中去取的。这些特征因为不用高频更新，我想通过分级存储供线上使用就好了，比如高频用户的年龄特征放到redis里面，这应该不会影响线上服务效率。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1611096313,"ip_address":"","comment_id":274335,"utype":1}],"discussion_count":1,"race_medal":0,"score":"53150576775","product_id":100060801,"comment_content":"老师好 想问下模型部署到线上之后 把flink处理后的特征输入到模型，实时更新用户embedding时，如果需要用到像 ‘年龄’ 这样的基础数据 流处理平台无法提供，是不是以为着依然需要到HDFS去取‘年龄’特征，但是这样是不是会很影响线上服务的效率？ 有什么好的方案呢 ？","like_count":12,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":513982,"discussion_content":"是的，大量特征还是从hdfs或者一些数据仓库中去取的。这些特征因为不用高频更新，我想通过分级存储供线上使用就好了，比如高频用户的年龄特征放到redis里面，这应该不会影响线上服务效率。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1611096313,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":262454,"user_name":"Teddy","can_delete":false,"product_type":"c1","uid":1397457,"ip_address":"","ucode":"296160981C95C2","user_header":"https://static001.geekbang.org/account/avatar/00/15/52/d1/a0f5579e.jpg","comment_is_top":false,"comment_ctime":1605744858,"is_pvip":false,"replies":[{"id":"95223","content":"效率上讲肯定是1比较高效一些，但需要比较大的改动。2方便部署，确实比较浪费资源。如果可以投入比较多的时间精力，我建议去研究一下方法一，特别是在有大量embedding数据的时候，甚至可以把embedding从模型中单独提取出来，这样可以大幅减小模型大小，提高部署和serving的速度。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1605746741,"ip_address":"","comment_id":262454,"utype":1}],"discussion_count":3,"race_medal":0,"score":"53145352410","product_id":100060801,"comment_content":"老师好，模型部署通常需要进行预处理，如果使用tfserving方式部署，由于不是端到端，所以一次推导请求需要进行2次进程间通信，通信开销比较大。因此想了2种方案，1. 自己用c++&#47;go封装预处理,并且在进程中自行loadsavedmodel，这样就把预处理和模型计算放到一个进程处理，减少一次通信。2. 把预处理放入tfserving，运行到gpu机器上，但这种方式又担心浪费有限的gpu资源。并发量大的时候哪种方案好呢？","like_count":12,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509839,"discussion_content":"效率上讲肯定是1比较高效一些，但需要比较大的改动。2方便部署，确实比较浪费资源。如果可以投入比较多的时间精力，我建议去研究一下方法一，特别是在有大量embedding数据的时候，甚至可以把embedding从模型中单独提取出来，这样可以大幅减小模型大小，提高部署和serving的速度。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605746741,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2280216,"avatar":"https://static001.geekbang.org/account/avatar/00/22/cb/18/0139e086.jpg","nickname":"骚动","note":"","ucode":"EBEBF417C866D4","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":351318,"discussion_content":"我也想知道是什么预处理？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1614241671,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1367444,"avatar":"","nickname":"InfoQ_bb5278aeccff","note":"","ucode":"E70D5AFB8011B9","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":351042,"discussion_content":"&#34;模型部署通常需要进行预处理&#34;,这个预处理是指什么?特征的预处理?","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1614133248,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":258700,"user_name":"myrfy","can_delete":false,"product_type":"c1","uid":1169401,"ip_address":"","ucode":"2814BAE5D70098","user_header":"","comment_is_top":false,"comment_ctime":1604540137,"is_pvip":false,"replies":[{"id":"94155","content":"嗯嗯，再解释一下端到端。这里跟端上数据没关系，指的是训练完后，不用经过任何诸如拆分啊，提取特征和参数啊之类的特殊步骤，训练完直接部署，不用做什么改变。<br><br>这里的端到端是这个意思。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1604548531,"ip_address":"","comment_id":258700,"utype":1}],"discussion_count":1,"race_medal":0,"score":"53144147689","product_id":100060801,"comment_content":"老师您好，看到上面的介绍，对端到端的理解还不是很清楚。感觉上面介绍的pmml和tf serving都是单向的，从离线模型到线上服务，并没有体现出用端上数据反过来训练模型这个方向。是我对端对端的理解有偏差，还是框架不支持呢","like_count":12,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":508732,"discussion_content":"嗯嗯，再解释一下端到端。这里跟端上数据没关系，指的是训练完后，不用经过任何诸如拆分啊，提取特征和参数啊之类的特殊步骤，训练完直接部署，不用做什么改变。\n\n这里的端到端是这个意思。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1604548531,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":261277,"user_name":"Sebastian","can_delete":false,"product_type":"c1","uid":1797634,"ip_address":"","ucode":"62E6FC13DB00E3","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/55lYKUdcPFgUHibRYmaRiaBdrsmnLGOHdPp4OicjBh197X0vyGa9qAwruEqicAPuUgibXO4Lz5jLudlcbtsqq2p3CpA/132","comment_is_top":false,"comment_ctime":1605256180,"is_pvip":false,"replies":[{"id":"94814","content":"模型中加入曝光次数，或者根据曝光次数训练一个decay函数跟模型融合。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1605258325,"ip_address":"","comment_id":261277,"utype":1}],"discussion_count":3,"race_medal":0,"score":"44554929140","product_id":100060801,"comment_content":"老师好，关于推荐的机制策略里的疲劳度优化想从工程实践上想再多问一下：内容瀑布流里如何防止重复推荐？最简单的做法是直接过滤用户30分钟内曝光的内容，这种做法过于粗糙，而且忽略的用户的即时兴趣（比如点击过的内容关联的标签）。比较合适的做法是实时采集用户点击过的内容标签，根据标签再进行推荐，但是这种做法如何保证推荐内容不重复呢？从工程上有什么好的方法吗？","like_count":11,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509438,"discussion_content":"模型中加入曝光次数，或者根据曝光次数训练一个decay函数跟模型融合。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605258325,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2405529,"avatar":"https://static001.geekbang.org/account/avatar/00/24/b4/99/79a21147.jpg","nickname":"轩","note":"","ucode":"454CC1A0734A4C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":340246,"discussion_content":"我是存储了用户的曝光列表，过滤k级别的历史曝光。\n具体是两个曝光列表：\napp real曝光列表，app上报，storm处理写入redis，k级别过滤。过滤都是召回时直接过滤掉了。\n服务端 曝光列表 只存储几十个，服务端直接写redis，这是防止app没曝光(如过快滑动)，但上次请求已返回的内容，再次请求时被返回。\n当然我的需求是内容只允许曝光一次，看见重复内容，老板会找………\n至于点击 也存储了用户点击 用户的最近的点击，是我的特征，拿到最近点击的item id，查询相应的标签，然后当作用户的实时特征来看待。实际效果来看，这个特征非常重要。","likes_number":4,"is_delete":false,"is_hidden":false,"ctime":1609936451,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1809935,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/l3RGUX8aLnPLmsQsra0yU5d8m7Se5jdVpaC3bkb99FuY11BPQNAsH4MPXbZjCTia9VVwn8lnBnKLkdfSiabOgxKg/132","nickname":"Geek_e0d66a","note":"","ucode":"5078900C9CF936","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":392238,"discussion_content":"可以用布隆过滤器做推荐去重","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1630918372,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":275117,"user_name":"Geek_209909","can_delete":false,"product_type":"c1","uid":2404065,"ip_address":"","ucode":"A7CDEAA7F0DDC0","user_header":"","comment_is_top":false,"comment_ctime":1611313032,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"27381116808","product_id":100060801,"comment_content":"[已解决，分享一下给可能有需要的人]<br><br>我在Windows下的Git命令行里照着输入这些指令碰到了下面的问题，运行docker run那个指令报错：<br>E tensorflow_serving&#47;sources&#47;storage_path&#47;file_system_storage_path_source.cc:364] FileSystemStoragePathSource encountered a filesystem access error: Could not find base path &#47;models&#47;half_plus_two for servable half_plus_two<br>报错说找不到模型文件。<br><br>原因：$TESTDATA这里的路径前面是&quot;&#47;c:&#47;xxx&#47;&quot;这种，识别不了<br><br>解决方法：手动输入路径，把c盘前面的&#39;&#47;&#39;符号去掉，就本来是‘&#47;c:&#47;xxx&#47;xxx’改成‘c:&#47;xxx&#47;xxx’就可以了","like_count":6,"discussions":[{"author":{"id":1339856,"avatar":"https://wx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKS70PShNZaxpibFc1gWuvibbg3hXR4YKm3MkNgX0n56hWUicN0JfB2GQ6I9UicBfKABH6dkfVDPohA6Q/132","nickname":"香格里拉飞龙","note":"","ucode":"C1263416EE85E3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":402318,"discussion_content":"接楼上，curl就本文中提到的命令中，windows下引号需要转义，\ncurl -d &#39;{&#34;instances&#34;: [1.0, 2.0, 5.0]}&#39;\n变成curl -d &#34;{\\&#34;instances\\&#34;: [1.0, 2.0, 5.0]}&#34; ，后面不变","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633862451,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2681194,"avatar":"https://static001.geekbang.org/account/avatar/00/28/e9/6a/75fac0ef.jpg","nickname":"YY","note":"","ucode":"C2D1A21DC2CA16","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":383713,"discussion_content":"Windows 下curl转义可以参考https://stackoverflow.com/questions/58788793/curl-query-to-tensorflow-serving-model-to-predict-api-breaks","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1626214228,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":278963,"user_name":"Lin D.","can_delete":false,"product_type":"c1","uid":2201338,"ip_address":"","ucode":"CDCF664A54BD39","user_header":"https://static001.geekbang.org/account/avatar/00/21/96/fa/b8bc5857.jpg","comment_is_top":false,"comment_ctime":1613486172,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"23088322652","product_id":100060801,"comment_content":"如果是在windows环境下运行tensorflow serving 建议参考这个视频<br>https:&#47;&#47;www.youtube.com&#47;watch?v=uabNEQlpGM8","like_count":6,"discussions":[{"author":{"id":2681194,"avatar":"https://static001.geekbang.org/account/avatar/00/28/e9/6a/75fac0ef.jpg","nickname":"YY","note":"","ucode":"C2D1A21DC2CA16","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":383712,"discussion_content":"Windows环境需要添加Docker App里的Resource -> File Sharing","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1626213419,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":260544,"user_name":"Sebastian","can_delete":false,"product_type":"c1","uid":1797634,"ip_address":"","ucode":"62E6FC13DB00E3","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/55lYKUdcPFgUHibRYmaRiaBdrsmnLGOHdPp4OicjBh197X0vyGa9qAwruEqicAPuUgibXO4Lz5jLudlcbtsqq2p3CpA/132","comment_is_top":false,"comment_ctime":1605058803,"is_pvip":false,"replies":[{"id":"94634","content":"你的问题很好，但我觉得估计不好找到很高质量的资料，因为都是业界的一些工程手段。<br><br>我理解你说的流量控制应该是指对不同用户使用不同的模型或者策略生成推荐结果是吧？这是一个很好的降低复杂模型qps的角度，但我觉得更多是一个工程问题，需要你在实践中摸索总结。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1605079507,"ip_address":"","comment_id":260544,"utype":1}],"discussion_count":1,"race_medal":0,"score":"23079895283","product_id":100060801,"comment_content":"老师好，想问下在线服务是否会涉及一些推荐的机制策略？比如流量控制，多样性，疲劳度优化等等？流量控制一般又有什么手段实现？这方面有什么资料可以推荐吗？谢谢！","like_count":6,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509227,"discussion_content":"你的问题很好，但我觉得估计不好找到很高质量的资料，因为都是业界的一些工程手段。\n\n我理解你说的流量控制应该是指对不同用户使用不同的模型或者策略生成推荐结果是吧？这是一个很好的降低复杂模型qps的角度，但我觉得更多是一个工程问题，需要你在实践中摸索总结。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605079507,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":260059,"user_name":"fsc2016","can_delete":false,"product_type":"c1","uid":1255585,"ip_address":"","ucode":"5480F05703A974","user_header":"https://static001.geekbang.org/account/avatar/00/13/28/a1/fd2bfc25.jpg","comment_is_top":false,"comment_ctime":1604915643,"is_pvip":false,"replies":[{"id":"94492","content":"1.模型更新频率其实是根据你的观察确定的，比如有的公司模型可能一周才更新一次，因为发现提高更新频率也对效果没什么影响。<br><br>有的公司可能需要做实时训练，比如我知道国内某主流电商团队，更新的频率在20分钟级别。<br><br>所以根据你自己的测试结果调整，一般天级别的更新是可行的。<br><br>2. 是的。TensorFlow serving本身在高并发下有一定的性能问题，有一些坑，我知道各一线团队都在进行一些魔改。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1604966358,"ip_address":"","comment_id":260059,"utype":1}],"discussion_count":2,"race_medal":0,"score":"18784784827","product_id":100060801,"comment_content":"老师，有2个问题请教您。<br>1，模型的离线训练完，部署到线上，产生推荐结果，根据用户行为反馈数据，然后在更新模型。实际工作上模型更新频率是怎么样，是根据各推荐指标按需进行调整嘛<br>2，文中说TensorFlow serving部署后，需要考虑性能优化问题，这个主要是指推荐服务器高并发请求下，保证准确，及时产生推荐结果嘛","like_count":4,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509100,"discussion_content":"1.模型更新频率其实是根据你的观察确定的，比如有的公司模型可能一周才更新一次，因为发现提高更新频率也对效果没什么影响。\n\n有的公司可能需要做实时训练，比如我知道国内某主流电商团队，更新的频率在20分钟级别。\n\n所以根据你自己的测试结果调整，一般天级别的更新是可行的。\n\n2. 是的。TensorFlow serving本身在高并发下有一定的性能问题，有一些坑，我知道各一线团队都在进行一些魔改。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1604966358,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1556961,"avatar":"https://static001.geekbang.org/account/avatar/00/17/c1/e1/49ca8967.jpg","nickname":"Anthony","note":"","ucode":"2BFABDFAADBDC8","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":545531,"discussion_content":"每天都重新训练、更新模型成本会不会太大了？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1641987934,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":274803,"user_name":"嗅嗅的小胖🐷","can_delete":false,"product_type":"c1","uid":2314827,"ip_address":"","ucode":"BA38674A66792B","user_header":"https://static001.geekbang.org/account/avatar/00/23/52/4b/7a66598d.jpg","comment_is_top":false,"comment_ctime":1611162908,"is_pvip":false,"replies":[{"id":"99715","content":"一般来说原生的tfserving是肯定有延迟问题的。ps一般来说更轻量级，但很多模型也不好支持。总的来说serving是一个非常复杂的工程问题，没有银弹。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1611191888,"ip_address":"","comment_id":274803,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14496064796","product_id":100060801,"comment_content":"老师你好，如果是高并发大流量的场景下tfserving延迟会不会有问题，和普通的ps架构来讲那个会更好一些","like_count":3,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":514129,"discussion_content":"一般来说原生的tfserving是肯定有延迟问题的。ps一般来说更轻量级，但很多模型也不好支持。总的来说serving是一个非常复杂的工程问题，没有银弹。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1611191888,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":267097,"user_name":"Geek_3c29c3","can_delete":false,"product_type":"c1","uid":2203358,"ip_address":"","ucode":"3D2E73AB1D08FA","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLaoiaerNMy7eoSA5yfibPNhta51jkhPTTL1dD1HGlnjaGnFQ6Uzbbce82Kpnic3g1JlD7rtm41Y83PA/132","comment_is_top":false,"comment_ctime":1607595393,"is_pvip":false,"replies":[{"id":"96979","content":"我记得jpmml的官方文档上有描述相关的过程，基于我们的java server就可以实现这一过程。<br><br>我在我的项目 https:&#47;&#47;github.com&#47;wzhe06&#47;CTRmodel<br>中也有一些相关的部分，可以参考。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1607649557,"ip_address":"","comment_id":267097,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14492497281","product_id":100060801,"comment_content":"老师，你好，想问一下如果是sklearn的模型，上线就是PMML最合适不过了吧。sklearn导出到PMML格式的文件我会，后面服务器利用JPMML调用模型文件，编写预测逻辑，生成服务，然后并发调用，这一系列不太会操作，还有服务器怎么选择服务架构，对后端的东西不太熟悉，有相关的资料可以学习吗？","like_count":4,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":511504,"discussion_content":"我记得jpmml的官方文档上有描述相关的过程，基于我们的java server就可以实现这一过程。\n\n我在我的项目 https://github.com/wzhe06/CTRmodel\n中也有一些相关的部分，可以参考。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1607649557,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":306546,"user_name":"Geek_8a732a","can_delete":false,"product_type":"c1","uid":2723806,"ip_address":"","ucode":"97A312D97F7B91","user_header":"","comment_is_top":false,"comment_ctime":1628603600,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10218538192","product_id":100060801,"comment_content":"# 启动TensorFlow Serving容器，在8501端口运行模型服务API<br>docker run -t --rm  -p 8501:8501 -v &quot;C:\\Users\\Think\\serving\\tensorflow_serving\\servables\\tensorflow\\testdata\\saved_model_half_plus_two_cpu:&#47;models&#47;half_plus_two&quot; -e MODEL_NAME=half_plus_two tensorflow&#47;serving &#39;&amp;&#39;<br><br># 请求模型服务API<br>curl -Uri &#39;http:&#47;&#47;localhost:8501&#47;v1&#47;models&#47;half_plus_two:predict&#39; -Body &#39;{&quot;instances&quot;:[1.0, 2.0, 5.0]}&#39; -Method &#39;POST&#39;","like_count":3},{"had_liked":false,"id":282287,"user_name":"Alan","can_delete":false,"product_type":"c1","uid":2115316,"ip_address":"","ucode":"591A28E310A8F5","user_header":"https://static001.geekbang.org/account/avatar/00/20/46/f4/93b1275b.jpg","comment_is_top":false,"comment_ctime":1615187197,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10205121789","product_id":100060801,"comment_content":"建议：第一步初次安装的国内小伙伴，添加Docker 引擎源加快拉取数据：{<br>  &quot;experimental&quot;: true,<br>  &quot;debug&quot;: true,<br>  &quot;registry-mirrors&quot;: [<br>    &quot;http:&#47;&#47;hub-mirror.c.163.com&quot;<br>  ]<br>}<br>","like_count":2},{"had_liked":false,"id":273292,"user_name":"啊黄黄黄","can_delete":false,"product_type":"c1","uid":2406285,"ip_address":"","ucode":"1298EFB0C44A58","user_header":"https://static001.geekbang.org/account/avatar/00/24/b7/8d/b27b89cc.jpg","comment_is_top":false,"comment_ctime":1610526663,"is_pvip":false,"replies":[{"id":"99047","content":"没有好的解决方法，tf-serving的效率问题是业界非常棘手的问题，建议持续关注业界公布的一些tf-serving优化方案，虽然非常少。。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1610563147,"ip_address":"","comment_id":273292,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10200461255","product_id":100060801,"comment_content":"老师好，我现在排序过程中利用tf-serving加载模型，这里耗时很严重有什么好的方法可以解决的嘛？","like_count":2,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":513557,"discussion_content":"没有好的解决方法，tf-serving的效率问题是业界非常棘手的问题，建议持续关注业界公布的一些tf-serving优化方案，虽然非常少。。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1610563147,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":263442,"user_name":"旦旦","can_delete":false,"product_type":"c1","uid":2335787,"ip_address":"","ucode":"1BD8B120EB6B64","user_header":"https://static001.geekbang.org/account/avatar/00/23/a4/2b/c8f97136.jpg","comment_is_top":false,"comment_ctime":1606135240,"is_pvip":false,"replies":[{"id":"95617","content":"不是特别理解这个需求。tensorflow是离线的，spark集群也是离线的，为什么要把tensorflow模型部署到spark集群呢？","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1606181692,"ip_address":"","comment_id":263442,"utype":1}],"discussion_count":4,"race_medal":0,"score":"10196069832","product_id":100060801,"comment_content":"王喆老师好，想请问下tensorflow训练的深度模型想要离线部署到spark集群有什么好的解决办法吗？","like_count":2,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":510194,"discussion_content":"不是特别理解这个需求。tensorflow是离线的，spark集群也是离线的，为什么要把tensorflow模型部署到spark集群呢？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606181692,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":334058,"discussion_content":"比较出名的tensorflow on spark项目是这个 https://github.com/yahoo/TensorFlowOnSpark\n我没有实践过，可以尝试一下，也期待分享进展。","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1607716269,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2335787,"avatar":"https://static001.geekbang.org/account/avatar/00/23/a4/2b/c8f97136.jpg","nickname":"旦旦","note":"","ucode":"1BD8B120EB6B64","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":329856,"discussion_content":"抱歉王老师，是这样的，我们装有tensorflow的平台资源有限，暂时只能支持模型训练，如果对大量级的生产数据做预测，只能在spark集群做。 所以想看spark(pysprak/scala)加载tensorflow训练好的深度模型直接在spark集群做预测有没有可以参考的资料","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606469444,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1062196,"avatar":"","nickname":"Matrix09","note":"","ucode":"3169A0E7624BD7","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2335787,"avatar":"https://static001.geekbang.org/account/avatar/00/23/a4/2b/c8f97136.jpg","nickname":"旦旦","note":"","ucode":"1BD8B120EB6B64","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":413949,"discussion_content":"IBM的BigDL好像可以支持加载tf模型，你可以试试","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1636617861,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":329856,"ip_address":""},"score":413949,"extra":""}]}]},{"had_liked":false,"id":258328,"user_name":"Wiiki","can_delete":false,"product_type":"c1","uid":1797573,"ip_address":"","ucode":"037F2D44C087C5","user_header":"https://static001.geekbang.org/account/avatar/00/1b/6d/c5/c0665034.jpg","comment_is_top":false,"comment_ctime":1604387674,"is_pvip":false,"replies":[{"id":"94122","content":"估计还是TESTDATA的路径问题，参考这篇文章https:&#47;&#47;stackoverflow.com&#47;questions&#47;50540721&#47;docker-toolbox-error-response-from-daemon-invalid-mode-root-docker","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1604464685,"ip_address":"","comment_id":258328,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10194322266","product_id":100060801,"comment_content":"王老师，您好。我按照您说的步骤，在window7上面通过docker toolbox安装好了docker，然后在docker toolbox上pull tensorflow serving镜像。再把tensorflow测试模型文件下载到本地，并配置TESTDATA地址，然后docker run服务。最后报错了：error response form daemon: invalid mode: &#47;models&#47;half_plus_two。不知道是哪里出了问题，麻烦解答一下呀~  谢谢","like_count":2,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":508620,"discussion_content":"估计还是TESTDATA的路径问题，参考这篇文章https://stackoverflow.com/questions/50540721/docker-toolbox-error-response-from-daemon-invalid-mode-root-docker","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1604464685,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":337111,"user_name":"Geek_ad1a2b","can_delete":false,"product_type":"c1","uid":2172296,"ip_address":"","ucode":"079F67F8AEF2CE","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/WxqITTQCDjfhkfN1NuekibAQbDW3bEvXey40fNVkvAx877IQMmNYA98FA19iao3hLCfWlSCAkp4AFibAJMsh1n64A/132","comment_is_top":false,"comment_ctime":1646629513,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5941596809","product_id":100060801,"comment_content":"win10环境遇到以下问题，应该是由于不同系统间命令的差异导致的<br>（1）TESTDATA路径变量无法设置，可跳过这一步，在下面对应位置用绝对路径替代即可<br>（2）docker run命令，下面的可运行命令取自评论区，路径部分内容还要根据你的具体路径修改<br>docker run -t --rm -p 8501:8501 -v &quot;C:&#47;Users&#47;lenovo&#47;serving&#47;tensorflow_serving&#47;servables&#47;tensorflow&#47;testdata&#47;saved_model_half_plus_two_cpu:&#47;models&#47;half_plus_two&quot; -e MODEL_NAME=half_plus_two tensorflow&#47;serving &#39;&amp;&#39;<br>（3）crul命令<br>curl http:&#47;&#47;127.0.0.1:8501&#47;v1&#47;models&#47;half_plus_two:predict -d &quot;{\\&quot;instances\\&quot;: [1.0, 2.0, 5.0]}&quot;<br>参考于https:&#47;&#47;blog.csdn.net&#47;xxw52mao1&#47;article&#47;details&#47;98073095","like_count":2},{"had_liked":false,"id":319378,"user_name":"Geek_060174","can_delete":false,"product_type":"c1","uid":2453906,"ip_address":"","ucode":"0CD31443EF0653","user_header":"","comment_is_top":false,"comment_ctime":1635766341,"is_pvip":false,"replies":[{"id":"115826","content":"一般利用深度学习框架的checkpoint功能实现。巨头公司通过魔改TF或者pytorch来实现模型的流式训练。小公司很难有这种能力。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1635900860,"ip_address":"","comment_id":319378,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5930733637","product_id":100060801,"comment_content":"老师好。想问下如果既想用模型提供在线服务，又想根据新样本，实时更新这个在线模型。用什么架构比较合适呢？像老师课上讲到的这几种服务方式，比如pmml或者tf server，模型都是离线训练好的，可以实时根据用户动态更新吗。以最简单的lr或者fm模型为例，有没有办法让模型既提供可靠在线服务，又能根据到来的新数据实时更新呢？一般怎么做呢？","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":529615,"discussion_content":"一般利用深度学习框架的checkpoint功能实现。巨头公司通过魔改TF或者pytorch来实现模型的流式训练。小公司很难有这种能力。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1635900860,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":302430,"user_name":"菜鸟","can_delete":false,"product_type":"c1","uid":1690913,"ip_address":"","ucode":"46F58768896D77","user_header":"","comment_is_top":false,"comment_ctime":1626224155,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5921191451","product_id":100060801,"comment_content":"JPMML是AGPLv3开源协议，不论是否分发软件都要开源，即使是云服务。生产环境都不敢用，宁可造个轮子。","like_count":1},{"had_liked":false,"id":301209,"user_name":"longhx","can_delete":false,"product_type":"c1","uid":1206147,"ip_address":"","ucode":"581A3BD20D7A04","user_header":"https://static001.geekbang.org/account/avatar/00/12/67/83/2150e0e0.jpg","comment_is_top":false,"comment_ctime":1625575065,"is_pvip":false,"replies":[{"id":"109394","content":"一般不在tfserving内部去做，而是在recsys server内部准备好，然后传给tfserving","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1626215955,"ip_address":"","comment_id":301209,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5920542361","product_id":100060801,"comment_content":"tfserving方式怎么加载外部预先训练好的的embedding数据呢","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":522930,"discussion_content":"一般不在tfserving内部去做，而是在recsys server内部准备好，然后传给tfserving","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1626215955,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":277452,"user_name":"Sanders","can_delete":false,"product_type":"c1","uid":1697075,"ip_address":"","ucode":"3D460FEEDCDF34","user_header":"","comment_is_top":false,"comment_ctime":1612418760,"is_pvip":false,"replies":[{"id":"100818","content":"我觉得都没问题。有时候online service本身就是上百个容器，所以肯定没法放在一个容器里，所以具体的做法看工程需要吧。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1612599691,"ip_address":"","comment_id":277452,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5907386056","product_id":100060801,"comment_content":"09#中讲到的推荐服务和模型服务是怎么结合的？是不是两者运行在Jetty + TF Serving一个容器运行时中，他们之间通过localhost的方式进行GRPC调用？感觉这样虽然耦合度高一些，但是会减少网络通信开销。","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":515057,"discussion_content":"我觉得都没问题。有时候online service本身就是上百个容器，所以肯定没法放在一个容器里，所以具体的做法看工程需要吧。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1612599691,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":276162,"user_name":"徐子琨","can_delete":false,"product_type":"c1","uid":2111427,"ip_address":"","ucode":"89B6F27F57E31A","user_header":"https://static001.geekbang.org/account/avatar/00/20/37/c3/090a3519.jpg","comment_is_top":false,"comment_ctime":1611818330,"is_pvip":false,"replies":[{"id":"100608","content":"预存结果不只是存每个用户的结果 而是要存用户在各种情况下的很多结果 你再想想","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1612360593,"ip_address":"","comment_id":276162,"utype":1}],"discussion_count":3,"race_medal":0,"score":"5906785626","product_id":100060801,"comment_content":"老师好，预存推荐结果的缺点提到了用户规模大消耗存储资源的问题，有点疑惑不是很明白。不考虑多个场景复用特征，离线将所有推荐结果计算完存储在Redis中，假设每个用户返回的列表不是特别长（50左右），N个用户就存了N个长度为50的list。那么如果不用预存推荐结果这种方式，用户特征本身规模也是不小的，将所有用户的特征都存到Redis中的这个存储开销似乎并不比预存推荐结果小。另外我觉得预存推荐结果的缺点还有浪费离线计算资源，毕竟相比于在线inference，大部分推荐结果都是用不到的","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":514616,"discussion_content":"预存结果不只是存每个用户的结果 而是要存用户在各种情况下的很多结果 你再想想","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1612360593,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2454131,"avatar":"https://static001.geekbang.org/account/avatar/00/25/72/73/d707c8be.jpg","nickname":"MutouMan","note":"","ucode":"E2E78C6EE25E80","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":371932,"discussion_content":"我的理解是加上context特征，比如你去淘宝先选PS5，出来一个列表，再选XBOX, 又来一个列表，而且还有用户滑倒底，列表更新的问题。所以这个存储资源的消耗是根据你的应用规模指数增加。除非我们就固定一个服务，只推荐constant的物品。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1620083718,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1602315,"avatar":"https://static001.geekbang.org/account/avatar/00/18/73/0b/0f918fa2.jpg","nickname":"快乐小夜曲","note":"","ucode":"0E257D2EAAA499","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2454131,"avatar":"https://static001.geekbang.org/account/avatar/00/25/72/73/d707c8be.jpg","nickname":"MutouMan","note":"","ucode":"E2E78C6EE25E80","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":548219,"discussion_content":"我跟你有同样的疑惑。。。作者的意思应该是有很多context*user*item的组合空间非常巨大。。。但是我觉得不考虑那么复杂度组合，仅仅存每个用户最新的的推荐结果这种简化是完全ok的。。。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1643089969,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":371932,"ip_address":""},"score":548219,"extra":""}]}]},{"had_liked":false,"id":269594,"user_name":"romance","can_delete":false,"product_type":"c1","uid":1029768,"ip_address":"","ucode":"393DC641CCE86E","user_header":"https://static001.geekbang.org/account/avatar/00/0f/b6/88/e8deccbc.jpg","comment_is_top":false,"comment_ctime":1608709004,"is_pvip":false,"replies":[{"id":"97760","content":"这个你自己最了解。理论上任何方法都可以，看你的知识库中的知识数量，你系统的存储空间支不支持预存结果。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1608714270,"ip_address":"","comment_id":269594,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5903676300","product_id":100060801,"comment_content":"王老师，请教下，在做企业知识库系统时，想使用推荐系统给用户推荐知识，这个场景可以用“预存推荐结果或 Embedding 结果”这种方案吧？","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":512331,"discussion_content":"这个你自己最了解。理论上任何方法都可以，看你的知识库中的知识数量，你系统的存储空间支不支持预存结果。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1608714270,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":266114,"user_name":"花晨少年","can_delete":false,"product_type":"c1","uid":1098987,"ip_address":"","ucode":"6AA3537A6BA10E","user_header":"https://static001.geekbang.org/account/avatar/00/10/c4/eb/2285a345.jpg","comment_is_top":false,"comment_ctime":1607174179,"is_pvip":false,"replies":[{"id":"96665","content":"这是个好问题。tf serving并不是说不能做MIMN的end2end serving，而是因为MIMN做e2e serving太慢了，所以把它割裂成两部分，这是一个优化的过程。<br><br>这块没必要钻牛角尖，我们这里说的是tf serving有e2e serving的能力，真正的工业级环境，当然是要做各种优化的。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1607193890,"ip_address":"","comment_id":266114,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5902141475","product_id":100060801,"comment_content":"有个疑惑，请问tf serving怎么解决预训练embedding+轻量级预估的问题呢，如果用tf serving方案，MIMN不还是割裂的两部分吗，并不是端到端的啊。","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":511154,"discussion_content":"这是个好问题。tf serving并不是说不能做MIMN的end2end serving，而是因为MIMN做e2e serving太慢了，所以把它割裂成两部分，这是一个优化的过程。\n\n这块没必要钻牛角尖，我们这里说的是tf serving有e2e serving的能力，真正的工业级环境，当然是要做各种优化的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1607193890,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":347712,"user_name":"yudidi","can_delete":false,"product_type":"c1","uid":1202482,"ip_address":"","ucode":"70283DE39D86F5","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/ydFhHonicUQibGlAfsAYBibNOfSxpCG5cJNp9oRibTJm3TrxM7Hj4WPPCRE3vluZJb0TGQqpKCaBWLdmra5Su1KF5Q/132","comment_is_top":false,"comment_ctime":1654337297,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1654337297","product_id":100060801,"comment_content":"老师你好，我们用xlearn这个py框架训练了一个ffm，我要怎么用go读取这个模型，并提供在线的服务呢？","like_count":0},{"had_liked":false,"id":321713,"user_name":"m-rui","can_delete":false,"product_type":"c1","uid":2829048,"ip_address":"","ucode":"75C9CBB9580C88","user_header":"https://static001.geekbang.org/account/avatar/00/2b/2a/f8/1af3bba6.jpg","comment_is_top":false,"comment_ctime":1637023277,"is_pvip":false,"replies":[{"id":"116817","content":"自己去调研一下有没有相应的serving工具支持。我记得pytorch应该有pytorch serving可以支持","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1637025296,"ip_address":"","comment_id":321713,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1637023277","product_id":100060801,"comment_content":"老师请问下，如果是树比如lgbm和pytorch这种是的混合模型，应该怎样部署线上呢，似乎不能直接用tfserving或者pmml了？不是很了解后端…","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":530339,"discussion_content":"自己去调研一下有没有相应的serving工具支持。我记得pytorch应该有pytorch serving可以支持","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1637025296,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":321586,"user_name":"与光25","can_delete":false,"product_type":"c1","uid":2824532,"ip_address":"","ucode":"83910ED9ADA946","user_header":"https://static001.geekbang.org/account/avatar/00/2b/19/54/1547a58a.jpg","comment_is_top":false,"comment_ctime":1636959484,"is_pvip":false,"replies":[{"id":"116816","content":"TESTDATA是一个路径变量，你完全可以把全绝对路径输入到&quot;$TESTDATA&#47;saved_model_half_plus_two_cpu:&#47;models&#47;half_plus_two&quot; 这里，不使用TESTDATA变量","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1637025228,"ip_address":"","comment_id":321586,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1636959484","product_id":100060801,"comment_content":"老师，新手小白 不太懂 TESTDATA不是内部或外部命令,也不是可运行的程序是怎么回事啊？","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":530319,"discussion_content":"TESTDATA是一个路径变量，你完全可以把全绝对路径输入到&amp;quot;$TESTDATA/saved_model_half_plus_two_cpu:/models/half_plus_two&amp;quot; 这里，不使用TESTDATA变量","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1637025228,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":310456,"user_name":"คิดถึง ","can_delete":false,"product_type":"c1","uid":2735702,"ip_address":"","ucode":"205BA133D638C6","user_header":"https://static001.geekbang.org/account/avatar/00/29/be/56/6a2998ba.jpg","comment_is_top":false,"comment_ctime":1630660473,"is_pvip":false,"replies":[{"id":"112491","content":"如果模型文件没有生成的话，需要在训练模型之后自己生成","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1630692838,"ip_address":"","comment_id":310456,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1630660473","product_id":100060801,"comment_content":"老师好，我想问下您在online-&gt;recprocess-&gt;RecForYouProcess中实现的callNeuralCFTFServing方法，该这么调用呢？还有您的ncf模型文件保存在哪里了？","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526242,"discussion_content":"如果模型文件没有生成的话，需要在训练模型之后自己生成","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1630692838,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":306452,"user_name":"郭翊麟","can_delete":false,"product_type":"c1","uid":2438072,"ip_address":"","ucode":"BA37CAE065CF30","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/FydBiarFhvwAxkA2fL3IpEGcd31xAfo8WicAgxreCSbPgo0IdcHkAwZQDZDiaeAJg7u2UKqSEmzr8Mopf9lFY1IEw/132","comment_is_top":false,"comment_ctime":1628566755,"is_pvip":false,"replies":[{"id":"110986","content":"我这边可以，是不是因为国内github访问不稳定导致的？","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1628618331,"ip_address":"","comment_id":306452,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1628566755","product_id":100060801,"comment_content":"王老师 您好 JPMML和MLeap 的项目库链接 失效了，能否给一下网址","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":524772,"discussion_content":"我这边可以，是不是因为国内github访问不稳定导致的？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1628618331,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":299843,"user_name":"时不时充充电","can_delete":false,"product_type":"c1","uid":2453902,"ip_address":"","ucode":"F45712325DAE50","user_header":"https://static001.geekbang.org/account/avatar/00/25/71/8e/31458837.jpg","comment_is_top":false,"comment_ctime":1624882045,"is_pvip":false,"replies":[{"id":"109380","content":"各家基本都是自己做，自己形成一套成熟的mlops方案。也有提供类似方案的startup，但我没有看到特别成熟的一体化解决方案。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1626215193,"ip_address":"","comment_id":299843,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1624882045","product_id":100060801,"comment_content":"想问一下老师，业界有没有成熟的MLOps解决方案？","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":522559,"discussion_content":"各家基本都是自己做，自己形成一套成熟的mlops方案。也有提供类似方案的startup，但我没有看到特别成熟的一体化解决方案。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1626215193,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":294775,"user_name":"β","can_delete":false,"product_type":"c1","uid":2410273,"ip_address":"","ucode":"7709E405121059","user_header":"https://static001.geekbang.org/account/avatar/00/24/c7/21/6a8e267a.jpg","comment_is_top":false,"comment_ctime":1622086600,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1622086600","product_id":100060801,"comment_content":"问题是Windows下的命令行支持单双引号的问题。。。。。。。","like_count":0},{"had_liked":false,"id":294741,"user_name":"β","can_delete":false,"product_type":"c1","uid":2410273,"ip_address":"","ucode":"7709E405121059","user_header":"https://static001.geekbang.org/account/avatar/00/24/c7/21/6a8e267a.jpg","comment_is_top":false,"comment_ctime":1622079171,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1622079171","product_id":100060801,"comment_content":"在curl -d那块命令处，出现如下错误，&quot;error&quot;: &quot;JSON Parse error: Invalid value. at offset: 0&quot;，这个应该从哪里排查。。。我这种小白菜","like_count":0},{"had_liked":false,"id":294699,"user_name":"β","can_delete":false,"product_type":"c1","uid":2410273,"ip_address":"","ucode":"7709E405121059","user_header":"https://static001.geekbang.org/account/avatar/00/24/c7/21/6a8e267a.jpg","comment_is_top":false,"comment_ctime":1622047868,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1622047868","product_id":100060801,"comment_content":"git clone tf-serving不可用，failed，我从网上找的以下这个可以，接下来的步骤我还没试<br>git clone --recurse-submodules https:&#47;&#47;github.com&#47;tensorflow&#47;serving","like_count":0},{"had_liked":false,"id":289593,"user_name":"chouisbo","can_delete":false,"product_type":"c1","uid":2556309,"ip_address":"","ucode":"43E324C74A093F","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erB5iaXSFdfgPL0uH2teHssfVEjoI7lib9xiao57XpBIjiadlIq2rjh8K2jUmNRnteEpZiaA9IX37csowA/132","comment_is_top":false,"comment_ctime":1619091649,"is_pvip":false,"replies":[{"id":"105068","content":"非常好的建议，可能会在后续的课程中加入。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1619112657,"ip_address":"","comment_id":289593,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1619091649","product_id":100060801,"comment_content":"老师您好，期望能讲讲Inference部分模型量化，模型蒸馏方面的内容。","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":518962,"discussion_content":"非常好的建议，可能会在后续的课程中加入。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1619112657,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":286552,"user_name":"Peter","can_delete":false,"product_type":"c1","uid":1054531,"ip_address":"","ucode":"71ED7FAA6FF754","user_header":"https://static001.geekbang.org/account/avatar/00/10/17/43/1ef14026.jpg","comment_is_top":false,"comment_ctime":1617371877,"is_pvip":false,"replies":[{"id":"104127","content":"正常操作，在java load能满足的情况下这样明显效率更高。但确实存在很多模型无法Java load的情况，tfserving还是最终的解决方案。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1617532608,"ip_address":"","comment_id":286552,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1617371877","product_id":100060801,"comment_content":"之前使用tfserving来部署模型，但是担心rpc或者http网络传输带来的延时，就选择了用Java load 训练好的tf（仅支持1.15）模型来做推理，然后整个算法服务打包成docker镜像来处理。","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":518023,"discussion_content":"正常操作，在java load能满足的情况下这样明显效率更高。但确实存在很多模型无法Java load的情况，tfserving还是最终的解决方案。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617532608,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":275300,"user_name":"芝乎者也","can_delete":false,"product_type":"c1","uid":2410680,"ip_address":"","ucode":"7ACD6053DF4E55","user_header":"https://static001.geekbang.org/account/avatar/00/24/c8/b8/27e45560.jpg","comment_is_top":false,"comment_ctime":1611458247,"is_pvip":false,"replies":[{"id":"99962","content":"这个可能是一个个人的问题。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1611550595,"ip_address":"","comment_id":275300,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1611458247","product_id":100060801,"comment_content":"成功启动tensorflow servering之后，使用curl 命令来发送 HTTP POST 请求，报了以下错误，至今木有找到解决方案，不知道老师或者哪位大佬能教教我<br>curl: (3) bad range in URL position 2:<br>[1.0,","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":514302,"discussion_content":"这个可能是一个个人的问题。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1611550595,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1306192,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ee/50/ed7b9e19.jpg","nickname":"弦亚","note":"","ucode":"64536E913AE6AE","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":352217,"discussion_content":"我也出现类似问题bad range in column 2，但是用postman调用接口是正常的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1614652387,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":261190,"user_name":"浣熊当家","can_delete":false,"product_type":"c1","uid":1952248,"ip_address":"","ucode":"939F06050423E4","user_header":"https://static001.geekbang.org/account/avatar/00/1d/c9/f8/72955ef9.jpg","comment_is_top":false,"comment_ctime":1605237033,"is_pvip":false,"replies":[{"id":"94809","content":"这句是配置一个变量，如果不打的话，你把serving&#47;tensorflow_serving&#47;servables&#47;tensorflow&#47;testdata 的完整绝对路径替换后面命令的TESTDATA也可以","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1605257784,"ip_address":"","comment_id":261190,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1605237033","product_id":100060801,"comment_content":"很不好意思问老师一个小白的问题，下面这个TESTDATA这句命令也是直接在command Prompt里直接打么，我试了，得到错误信息“TESTDATA is not recognized as an internal or external command...” 是不是应该在别的地方打这句啊？<br>TESTDATA=&quot;$(pwd)&#47;serving&#47;tensorflow_serving&#47;servables&#47;tensorflow&#47;testdata&quot;","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509411,"discussion_content":"这句是配置一个变量，如果不打的话，你把serving/tensorflow_serving/servables/tensorflow/testdata 的完整绝对路径替换后面命令的TESTDATA也可以","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605257784,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2394803,"avatar":"","nickname":"Geek_ed807a","note":"","ucode":"58B4FBE343D512","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":339334,"discussion_content":"老哥你解决了吗？我也是小白遇到这个问题","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1609638972,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}