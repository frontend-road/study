{"id":423878,"title":"10 | 广播变量 & 累加器：共享变量是用来做什么的？","content":"<p>你好，我是吴磊。</p><p>今天是国庆第一天，首先祝你节日快乐。专栏上线以来，有不少同学留言说期待后续内容，所以国庆期间我们仍旧更新正文内容，让我们一起把基础知识模块收个尾。</p><p>学习过RDD常用算子之后，回顾这些算子，你会发现它们都是作用（Apply）在RDD之上的。RDD的计算以数据分区为粒度，依照算子的逻辑，Executors以相互独立的方式，完成不同数据分区的计算与转换。</p><p>不难发现，对于Executors来说，分区中的数据都是局部数据。换句话说，在同一时刻，隶属于某个Executor的数据分区，对于其他Executors来说是不可见的。</p><p>不过，在做应用开发的时候，总会有一些计算逻辑需要访问“全局变量”，比如说全局计数器，而这些全局变量在任意时刻对所有的Executors都是可见的、共享的。那么问题来了，像这样的全局变量，或者说共享变量，Spark又是如何支持的呢？</p><p>今天这一讲，我就来和你聊聊Spark共享变量。按照创建与使用方式的不同，Spark提供了两类共享变量，分别是广播变量（Broadcast variables）和累加器（Accumulators）。接下来，我们就正式进入今天的学习，去深入了解这两种共享变量的用法、以及它们各自的适用场景。</p><!-- [[[read_end]]] --><h2>广播变量（Broadcast variables）</h2><p>我们先来说说广播变量。广播变量的用法很简单，给定普通变量x，通过调用SparkContext下的broadcast API即可完成广播变量的创建，我们结合代码例子看一下。</p><pre><code class=\"language-scala\">val list: List[String] = List(\"Apache\", \"Spark\")\n&nbsp;\n// sc为SparkContext实例\nval bc = sc.broadcast(list)\n</code></pre><p>在上面的代码示例中，我们先是定义了一个字符串列表list，它包含“Apache”和“Spark”这两个单词。然后，我们使用broadcast函数来创建广播变量bc，bc封装的内容就是list列表。</p><pre><code class=\"language-scala\">// 读取广播变量内容\nbc.value\n// List[String] = List(Apache, Spark)\n&nbsp;\n// 直接读取列表内容\nlist\n// List[String] = List(Apache, Spark)\n</code></pre><p>使用broadcast API创建广播变量</p><p>广播变量创建好之后，通过调用它的value函数，我们就可以访问它所封装的数据内容。可以看到调用bc.value的效果，这与直接访问字符串列表list的效果是完全一致的。</p><p>看到这里，你可能会问：“明明通过访问list变量就可以直接获取字符串列表，为什么还要绕个大弯儿，先去封装广播变量，然后又通过它的value函数来获取同样的数据内容呢？”实际上，这是个非常好的问题，要回答这个问题，咱们需要做个推演，看看直接访问list变量会产生哪些弊端。</p><p>在前面的几讲中，我们换着花样地变更Word Count的计算逻辑。尽管Word Count都快被我们“玩坏了”，不过，一以贯之地沿用同一个实例，有助于我们通过对比迅速掌握新的知识点、技能点。因此，为了让你迅速掌握广播变量的“精髓”，咱们不妨“故技重施”，继续在Word Count这个实例上做文章。</p><h3>普通变量的痛点</h3><p>这一次，为了对比使用广播变量前后的差异，我们把Word Count变更为“定向计数”。</p><p>所谓定向计数，它指的是只对某些单词进行计数，例如，给定单词列表list，我们只对文件wikiOfSpark.txt当中的“Apache”和“Spark”这两个单词做计数，其他单词我们可以忽略。结合<a href=\"https://time.geekbang.org/column/article/415209\">第1讲</a>Word Count的完整代码，这样的计算逻辑很容易实现，如下表所示。</p><pre><code class=\"language-scala\">import org.apache.spark.rdd.RDD\nval rootPath: String = _\nval file: String = s\"${rootPath}/wikiOfSpark.txt\"\n// 读取文件内容\nval lineRDD: RDD[String] = spark.sparkContext.textFile(file)\n// 以行为单位做分词\nval wordRDD: RDD[String] = lineRDD.flatMap(line =&gt; line.split(\" \"))\n&nbsp;\n// 创建单词列表list\nval list: List[String] = List(\"Apache\", \"Spark\")\n// 使用list列表对RDD进行过滤\nval cleanWordRDD: RDD[String] = wordRDD.filter(word =&gt; list.contains(word))\n// 把RDD元素转换为（Key，Value）的形式\nval kvRDD: RDD[(String, Int)] = cleanWordRDD.map(word =&gt; (word, 1))\n// 按照单词做分组计数\nval wordCounts: RDD[(String, Int)] = kvRDD.reduceByKey((x, y) =&gt; x + y)\n// 获取计算结果\nwordCounts.collect\n// Array[(String, Int)] = Array((Apache,34), (Spark,63))\n</code></pre><p>将上述代码丢进spark-shell，我们很快就能算出，在wikiOfSpark.txt文件中，“Apache”这个单词出现了34次，而“Spark”则出现了63次。虽说得出计算结果挺容易的，不过知其然，还要知其所以然，接下来，咱们一起来分析一下，这段代码在运行时是如何工作的。</p><p><img src=\"https://static001.geekbang.org/resource/image/8d/49/8dd52d329d74d212cfa6b188cfea2b49.jpg?wh=1920x1140\" alt=\"图片\" title=\"定向计数中list变量的全网分发\"></p><p>如上图所示，list变量本身是在Driver端创建的，它并不是分布式数据集（如lineRDD、wordRDD）的一部分。因此，在分布式计算的过程中，Spark需要把list变量分发给每一个分布式任务（Task），从而对不同数据分区的内容进行过滤。</p><p>在这种工作机制下，如果RDD并行度较高、或是变量的尺寸较大，那么重复的内容分发就会引入大量的网络开销与存储开销，而这些开销会大幅削弱作业的执行性能。为什么这么说呢？</p><p>要知道，<strong>Driver端变量的分发是以Task为粒度的，系统中有多少个Task，变量就需要在网络中分发多少次</strong>。更要命的是，每个Task接收到变量之后，都需要把它暂存到内存，以备后续过滤之用。换句话说，在同一个Executor内部，多个不同的Task多次重复地缓存了同样的内容拷贝，毫无疑问，这对宝贵的内存资源是一种巨大的浪费。</p><p>RDD并行度较高，意味着RDD的数据分区数量较多，而Task数量与分区数相一致，这就代表系统中有大量的分布式任务需要执行。如果变量本身尺寸较大，大量分布式任务引入的网络开销与内存开销会进一步升级。<strong>在工业级应用中，RDD的并行度往往在千、万这个量级，在这种情况下，诸如list这样的变量会在网络中分发成千上万次，作业整体的执行效率自然会很差 </strong>。</p><p>面对这样的窘境，我们有没有什么办法，能够避免同一个变量的重复分发与存储呢？答案当然是肯定的，这个时候，我们就可以祭出广播变量这个“杀手锏”。</p><h3>广播变量的优势</h3><p>想要知道广播变量到底有啥优势，我们可以先用广播变量重写一下前面的代码实现，然后再做个对比，很容易就能发现广播变量为什么能解决普通变量的痛点。</p><pre><code class=\"language-scala\">import org.apache.spark.rdd.RDD\nval rootPath: String = _\nval file: String = s\"${rootPath}/wikiOfSpark.txt\"\n// 读取文件内容\nval lineRDD: RDD[String] = spark.sparkContext.textFile(file)\n// 以行为单位做分词\nval wordRDD: RDD[String] = lineRDD.flatMap(line =&gt; line.split(\" \"))\n&nbsp;\n// 创建单词列表list\nval list: List[String] = List(\"Apache\", \"Spark\")\n// 创建广播变量bc\nval bc = sc.broadcast(list)\n// 使用bc.value对RDD进行过滤\nval cleanWordRDD: RDD[String] = wordRDD.filter(word =&gt; bc.value.contains(word))\n// 把RDD元素转换为（Key，Value）的形式\nval kvRDD: RDD[(String, Int)] = cleanWordRDD.map(word =&gt; (word, 1))\n// 按照单词做分组计数\nval wordCounts: RDD[(String, Int)] = kvRDD.reduceByKey((x, y) =&gt; x + y)\n// 获取计算结果\nwordCounts.collect\n// Array[(String, Int)] = Array((Apache,34), (Spark,63))\n</code></pre><p>可以看到，代码的修改非常简单，我们先是使用broadcast函数来封装list变量，然后在RDD过滤的时候调用bc.value来访问list变量内容。<strong>你可不要小看这个改写，尽管代码的改动微乎其微，几乎可以忽略不计，但在运行时，整个计算过程却发生了翻天覆地的变化</strong>。</p><p><img src=\"https://static001.geekbang.org/resource/image/90/12/9050f159749465d0c9d3394f3335ee12.jpg?wh=1920x969\" alt=\"图片\" title=\"广播变量工作原理\"></p><p>在使用广播变量之前，list变量的分发是以Task为粒度的，而在使用广播变量之后，变量分发的粒度变成了以Executors为单位，同一个Executor内多个不同的Tasks只需访问同一份数据拷贝即可。换句话说，变量在网络中分发与存储的次数，从RDD的分区数量，锐减到了集群中Executors的个数。</p><p>要知道，在工业级系统中，Executors个数与RDD并行度相比，二者之间通常会相差至少两个数量级。在这样的量级下，广播变量节省的网络与内存开销会变得非常可观，省去了这些开销，对作业的执行性能自然大有裨益。</p><p>好啦，到现在为止，我们讲解了广播变量的用法、工作原理，以及它的优势所在。在日常的开发工作中，<strong>当你遇到需要多个Task共享同一个大型变量（如列表、数组、映射等数据结构）的时候，就可以考虑使用广播变量来优化你的Spark作业</strong>。接下来，我们继续来说说Spark支持的第二种共享变量：累加器。</p><h2>累加器（Accumulators）</h2><p>累加器，顾名思义，它的主要作用是全局计数（Global counter）。与单机系统不同，在分布式系统中，我们不能依赖简单的普通变量来完成全局计数，而是必须依赖像累加器这种特殊的数据结构才能达到目的。</p><p>与广播变量类似，累加器也是在Driver端定义的，但它的更新是通过在RDD算子中调用add函数完成的。在应用执行完毕之后，开发者在Driver端调用累加器的value函数，就能获取全局计数结果。按照惯例，咱们还是通过代码来熟悉累加器的用法。</p><p>聪明的你可能已经猜到了，我们又要对Word Count“动手脚”了。在第1讲的Word Count中，我们过滤掉了空字符串，然后对文件wikiOfSpark.txt中所有的单词做统计计数。</p><p>不过这一次，我们在过滤掉空字符的同时，还想知道文件中到底有多少个空字符串，这样我们对文件中的“脏数据”就能做到心中有数了。</p><p>注意，<strong>这里对于空字符串的计数，不是主代码逻辑，它的计算结果不会写入到Word Count最终的统计结果</strong>。所以，只是简单地去掉filter环节，是无法实现空字符计数的。</p><p>那么，你自然会问：“不把filter环节去掉，怎么对空字符串做统计呢？”别着急，这样的计算需求，正是累加器可以施展拳脚的地方。你可以先扫一眼下表的代码实现，然后我们再一起来熟悉累加器的用法。</p><pre><code class=\"language-scala\">import org.apache.spark.rdd.RDD\nval rootPath: String = _\nval file: String = s\"${rootPath}/wikiOfSpark.txt\"\n// 读取文件内容\nval lineRDD: RDD[String] = spark.sparkContext.textFile(file)\n// 以行为单位做分词\nval wordRDD: RDD[String] = lineRDD.flatMap(line =&gt; line.split(\" \"))\n&nbsp;\n// 定义Long类型的累加器\nval ac = sc.longAccumulator(\"Empty string\")\n&nbsp;\n// 定义filter算子的判定函数f，注意，f的返回类型必须是Boolean\ndef f(x: String): Boolean = {\nif(x.equals(\"\")) {\n// 当遇到空字符串时，累加器加1\nac.add(1)\nreturn false\n} else {\nreturn true\n}\n}\n&nbsp;\n// 使用f对RDD进行过滤\nval cleanWordRDD: RDD[String] = wordRDD.filter(f)\n// 把RDD元素转换为（Key，Value）的形式\nval kvRDD: RDD[(String, Int)] = cleanWordRDD.map(word =&gt; (word, 1))\n// 按照单词做分组计数\nval wordCounts: RDD[(String, Int)] = kvRDD.reduceByKey((x, y) =&gt; x + y)\n// 收集计数结果\nwordCounts.collect\n&nbsp;\n// 作业执行完毕，通过调用value获取累加器结果\nac.value\n// Long = 79\n</code></pre><p>与第1讲的Word Count相比，这里的代码主要有4处改动：</p><ul>\n<li>使用SparkContext下的longAccumulator来定义Long类型的累加器；</li>\n<li>定义filter算子的判定函数f，当遇到空字符串时，调用add函数为累加器计数；</li>\n<li>以函数f为参数，调用filter算子对RDD进行过滤；</li>\n<li>作业完成后，调用累加器的value函数，获取全局计数结果。</li>\n</ul><p>你不妨把上面的代码敲入到spark-shell里，直观体验下累加器的用法与效果，ac.value给出的结果是79，这说明以空格作为分隔符切割源文件wikiOfSpark.txt之后，就会留下79个空字符串。</p><p>另外，你还可以验证wordCounts这个RDD，它包含所有单词的计数结果，不过，你会发现它的元素并不包含空字符串，这与我们预期的计算逻辑是一致的。</p><p>除了上面代码中用到的longAccumulator，SparkContext还提供了doubleAccumulator和collectionAccumulator这两种不同类型的累加器，用于满足不同场景下的计算需要，感兴趣的话你不妨自己动手亲自尝试一下。</p><p>其中，doubleAccumulator用于对Double类型的数值做全局计数；而collectionAccumulator允许开发者定义集合类型的累加器，相比数值类型，集合类型可以为业务逻辑的实现，提供更多的灵活性和更大的自由度。</p><p>不过，就这3种累加器来说，尽管类型不同，但它们的用法是完全一致的。都是<strong>先定义累加器变量，然后在RDD算子中调用add函数，从而更新累加器状态，最后通过调用value函数来获取累加器的最终结果</strong>。</p><p>好啦，到这里，关于累加器的用法，我们就讲完了。在日常的开发中，当你遇到需要做全局计数的场景时，别忘了用上累加器这个实用工具。</p><h2>重点回顾</h2><p>今天的内容讲完了，我们一起来做个总结。今天这一讲，我们重点讲解了广播变量与累加器的用法与适用场景。</p><p>广播变量由Driver端定义并初始化，各个Executors以只读（Read only）的方式访问广播变量携带的数据内容。累加器也是由Driver定义的，但Driver并不会向累加器中写入任何数据内容，累加器的内容更新，完全是由各个Executors以只写（Write only）的方式来完成，而Driver仅以只读的方式对更新后的内容进行访问。</p><p>关于广播变量，你首先需要掌握它的基本用法。给定任意类型的普通变量，你都可以使用SparkContext下面的broadcast API来创建广播变量。接下来，在RDD的转换与计算过程中，你可以通过调用广播变量的value函数，来访问封装的数据内容，从而辅助RDD的数据处理。</p><p>需要额外注意的是，<strong>在Driver与Executors之间，普通变量的分发与存储，是以Task为粒度的，因此，它所引入的网络与内存开销，会成为作业执行性能的一大隐患</strong>。在使用广播变量的情况下，数据内容的分发粒度变为以Executors为单位。相比前者，广播变量的优势高下立判，它可以大幅度消除前者引入的网络与内存开销，进而在整体上提升作业的执行效率。</p><p>关于累加器，首先你要清楚它的适用场景，当你需要做全局计数的时候，累加器会是个很好的帮手。其次，你需要掌握累加器的具体用法，可以分为这样3步：</p><ol>\n<li>使用SparkContext下的[long | double | collection]Accumulator来定义累加器；</li>\n<li>在RDD的转换过程中，调用add函数更新累加器状态；</li>\n<li>在作业完成后，调用value函数，获取累加器的全局结果。</li>\n</ol><h2>每课一练</h2><ol>\n<li>在使用累加器对空字符串做全局计数的代码中，请你用普通变量去替换累加器，试一试，在不使用累加器的情况，能否得到预期的计算结果？</li>\n<li>累加器提供了Long、Double和Collection三种类型的支持，那么广播变量在类型支持上有限制吗？除了普通类型、集合类型之外，广播变量还支持其他类型吗？比如，Spark支持在RDD之上创建广播变量吗？</li>\n</ol><p>欢迎你在留言区跟我交流互动，也推荐你把这一讲的内容分享给你身边的朋友，说不定就能帮他解决一个难题。</p>","comments":[{"had_liked":false,"id":314607,"user_name":"Geek_2dfa9a","can_delete":false,"product_type":"c1","uid":1435535,"ip_address":"","ucode":"B5FE7971F5E773","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epGTSTvn7r4ibk1PuaUrSvvLdviaLcne50jbvvfiaxKkM5SLibeP6jibA2bCCQBqETibvIvcsOhAZlwS8kQ/132","comment_is_top":true,"comment_ctime":1633255639,"is_pvip":false,"replies":[{"id":"114053","content":"实验做的非常细致，有观察、有思考、思考很深入，赞👍，置顶🔝<br><br>先说Task串行、并行的问题，Task与Task之间，是并行的，Task内部，是串行。这个其实好理解，毕竟，一个Task占用一个CPU core，不存在并发上的物理条件~ <br><br>再者，特别同意你说的FAAS和打开视野，我对此深有同感~ 用你的话说，是Spark对于序列化和反序列化的支持。对我来说，Spark的调度系统，对我个人影响巨大，让我真正认识到分布式系统的玩法、特色和核心。在我看来，调度系统是学习Spark最应该学的部分，没有之一~ 当然，仁者见仁，大家的喜好和偏好都不同~ 就打开视野这方面，确实调度系统对于我个人的提升，或者说给我个人留下的印象，非常非常的深刻。<br><br>广播变量答的也很好~ RDD需要先collect，这一点其实想吐槽社区，完全可以做得跟DataFrame一样，直接封装就好了，非要开发者自行collect一波，然后再封装，麻烦！DataFrame就比较直接，Spark在背后帮开发者做了collect这一步，就开发者使用体验来说，还是要好些~","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1633613103,"ip_address":"","comment_id":314607,"utype":1}],"discussion_count":1,"race_medal":0,"score":"9.2233721200923996e+18","product_id":100090001,"comment_content":"1.使用普通变量是无法得到预期结果的，因为lambda里的必须是final型的变量，那这里我用两种方法做个测试：<br>首先是原子类，因字数限制，只放关键代码：<br>    var normal = new AtomicInteger(0)<br>    val  preRdd = wordRdd.filter(f =&gt;<br>      if(f.contains(&quot;scala&quot;)) {<br>        println(normal.incrementAndGet())<br>        false<br>      } else {<br>        true<br>      }<br>    )<br>    println(normal.get())<br>可以看到Executor运行过程中normal是会正常累加的，但是最后println(normal.get())打印出来是0，这里简单分析下，spark会把闭包序列化后<br>传递给Executor，然后Executor再把闭包反序列化后作用在RDD上。因此Driver里的normal变量和Executor里的normal变量是多个进程里的多个变量。<br>然后使用自定义类对象<br>class IntHolder(var value: Int) {}<br>测试，报了一个Exception in thread &quot;main&quot; org.apache.spark.SparkException: Task not serializable<br>从侧面也证明，闭包里的对象是要实现序列化的。变量是多个进程里的多个变量改进下再试，<br>class IntHolder(var value: Int) extends Serializable {}<br>发现每个Task都是从0开始计数，更说明每个Task里的对象是Driver丢过来的副本。这里我多想了下Task里的函数是串行执行还是并行执行的，如果我的IntHolder对象<br>不是线程安全的，那在Task里有无数据竞争？从我的例子看是串行运行的，但是一时找不到看哪些代码，请老师指正。<br>多讲两句，Spark闭包序列化和反序列化真的是很重要的知识，打开了我的视野，我感觉Spark是Faas一种非常巧妙的场景，函数式编程真的也很符合Spark<br>把函数作用在RDD上，存算分离的思路，UCB出品真的名不虚传。<br><br>2.Spark基本支持任何类型的广播变量，但是不支持RDD类型的广播变量，从代码中可以看到，有一个验证会判断变量是否为RDD类型，如果想要广播RDD类型的话，可以先<br>collect收集到driver，再作为普通集合广播。<br>  def broadcast[T: ClassTag](value: T): Broadcast[T] = {<br>    assertNotStopped()<br>    require(!classOf[RDD[_]].isAssignableFrom(classTag[T].runtimeClass),<br>      &quot;Can not directly broadcast RDDs; instead, call collect() and broadcast the result.&quot;)<br>    val bc = env.broadcastManager.newBroadcast[T](value, isLocal)<br>    val callSite = getCallSite<br>    logInfo(&quot;Created broadcast &quot; + bc.id + &quot; from &quot; + callSite.shortForm)<br>    cleaner.foreach(_.registerBroadcastForCleanup(bc))<br>    bc<br>  }","like_count":20,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527735,"discussion_content":"实验做的非常细致，有观察、有思考、思考很深入，赞👍，置顶🔝\n\n先说Task串行、并行的问题，Task与Task之间，是并行的，Task内部，是串行。这个其实好理解，毕竟，一个Task占用一个CPU core，不存在并发上的物理条件~ \n\n再者，特别同意你说的FAAS和打开视野，我对此深有同感~ 用你的话说，是Spark对于序列化和反序列化的支持。对我来说，Spark的调度系统，对我个人影响巨大，让我真正认识到分布式系统的玩法、特色和核心。在我看来，调度系统是学习Spark最应该学的部分，没有之一~ 当然，仁者见仁，大家的喜好和偏好都不同~ 就打开视野这方面，确实调度系统对于我个人的提升，或者说给我个人留下的印象，非常非常的深刻。\n\n广播变量答的也很好~ RDD需要先collect，这一点其实想吐槽社区，完全可以做得跟DataFrame一样，直接封装就好了，非要开发者自行collect一波，然后再封装，麻烦！DataFrame就比较直接，Spark在背后帮开发者做了collect这一步，就开发者使用体验来说，还是要好些~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633613103,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":314572,"user_name":"Geek_f39659","can_delete":false,"product_type":"c1","uid":1636568,"ip_address":"","ucode":"2206A8C590423C","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q3auHgzwzM6iagw7ct4ca3niaSEFNicu2wy2KuCibO6eiaRzoRGJb50WTrbkKQib9mTArnTr8jJUazO9O2ibLZNfjjl35cfCHkBPs7N/132","comment_is_top":false,"comment_ctime":1633234571,"is_pvip":false,"replies":[{"id":"114052","content":"没错，满分💯~","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1633610866,"ip_address":"","comment_id":314572,"utype":1}],"discussion_count":1,"race_medal":0,"score":"35992972939","product_id":100090001,"comment_content":"第一题： driver中声明的非广播变量，如果executor需要用的话，会给每一个分区拷贝一个副本，所以每个分区都会给自己的这份副本加一加一。最后这些副本随着executor 进程的结束就都丢失了。所以driver 中的这个变量仍然还是0.","like_count":9,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527723,"discussion_content":"没错，满分💯~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633610866,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":342693,"user_name":"Sun","can_delete":false,"product_type":"c1","uid":1111374,"ip_address":"","ucode":"5F3708EAFA3E1F","user_header":"https://static001.geekbang.org/account/avatar/00/10/f5/4e/c890155f.jpg","comment_is_top":false,"comment_ctime":1650421996,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"5945389292","product_id":100090001,"comment_content":"老师您好。关于第一题的实验，我使用自定义类，如下：<br>class MyCount implements Serializable{<br>    int num;<br>    public MyCount(){<br>        this.num = 0;<br>    }<br>    public void add(){<br>        this.num++;<br>    }<br>}<br>将它用于代替广播变量，是不行的，因为executor最后销毁了这些对象。<br>但是我将这个对象置为静态对象，放在Driver中再运行后，这个对象成功得到了最后的结果。<br>请问老师，为什么设置为静态对象就可以获取结果呢？静态对象在Driver和Executor是怎么一个工作机制？","like_count":1,"discussions":[{"author":{"id":1591216,"avatar":"https://static001.geekbang.org/account/avatar/00/18/47/b0/cf5529a0.jpg","nickname":"ThomasG","note":"","ucode":"C05D94E0A10662","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":584346,"discussion_content":"本地跑的还是集群跑的啊","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1660783496,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"北京"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":319198,"user_name":"welldo","can_delete":false,"product_type":"c1","uid":1598796,"ip_address":"","ucode":"D38E75364CD2E3","user_header":"https://static001.geekbang.org/account/avatar/00/18/65/4c/f7f86496.jpg","comment_is_top":false,"comment_ctime":1635667782,"is_pvip":false,"replies":[{"id":"115719","content":"哈哈，先赞👍一下老弟爱钻研的精神！！！<br><br>不过呢，所谓的漏洞说法有问题，证明更有问题，哈哈。根本原因还是，你的环境是单机、local，所以你怎么玩儿，都是单机的玩儿法。你比如这句：<br><br>bufferBroad.value.append(&quot;test&quot;)<br><br>推广到分布式的环境，肯定会报错的。所以说做实验的话，建议还是在分布式下去做，这样很多结论，才站得住脚~","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1635684591,"ip_address":"","comment_id":319198,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5930635078","product_id":100090001,"comment_content":"老师，广播变量有&quot;只读&quot; &#47; &quot;不可变&quot;特性，<br>但广播引用数据类型时, 广播的实际上是地址值，那么地址值肯定不可变，而地址值指向的内容是可变的;<br><br>我今天在idea和shell里做了一个测试，证明了这个说法是对的,<br>代码如下:<br>(scala-List是不可变的，所以代码里我用了可变的scala-ListBuffer)<br><br>var buffer: ListBuffer[String] = ListBuffer()<br>var bufferBroad = spark.sparkContext.broadcast(buffer)<br>val cleanWordRDD2: RDD[String] = wordRDD.filter(word =&gt; {<br>  if (bc.value.contains(word)) {\t\t&#47;&#47;bc是文章里的广播变量<br>\tbufferBroad.value.append(&quot;test&quot;)\t&#47;&#47;关键的一行<br>\ttrue<br>  } else {<br>\tfalse<br>  }<br>})<br><br>println(cleanWordRDD2.count())&#47;&#47;触发这条dag<br>println(buffer)\t\t\t\t&#47;&#47;97(34+63)个test<br>println(bufferBroad.value)\t&#47;&#47;97(34+63)个test<br><br>老师，这个说法和我的证明没有问题吧？<br>这个算不算“不可变”特性的漏洞 呢？","like_count":1,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":529541,"discussion_content":"哈哈，先赞👍一下老弟爱钻研的精神！！！\n\n不过呢，所谓的漏洞说法有问题，证明更有问题，哈哈。根本原因还是，你的环境是单机、local，所以你怎么玩儿，都是单机的玩儿法。你比如这句：\n\nbufferBroad.value.append(&amp;quot;test&amp;quot;)\n\n推广到分布式的环境，肯定会报错的。所以说做实验的话，建议还是在分布式下去做，这样很多结论，才站得住脚~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1635684591,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":319021,"user_name":"welldo","can_delete":false,"product_type":"c1","uid":1598796,"ip_address":"","ucode":"D38E75364CD2E3","user_header":"https://static001.geekbang.org/account/avatar/00/18/65/4c/f7f86496.jpg","comment_is_top":false,"comment_ctime":1635512167,"is_pvip":false,"replies":[{"id":"115674","content":"继承AccumulatorV2也是个方法，其实还蛮高级的~","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1635608492,"ip_address":"","comment_id":319021,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5930479463","product_id":100090001,"comment_content":"以前我写累加器，都是手动继承AccumulatorV2，现在找到更简单的方法了😁","like_count":2,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":529460,"discussion_content":"继承AccumulatorV2也是个方法，其实还蛮高级的~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1635608492,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":315785,"user_name":"火炎焱燚","can_delete":false,"product_type":"c1","uid":2767491,"ip_address":"","ucode":"DB11784DD94059","user_header":"https://static001.geekbang.org/account/avatar/00/2a/3a/83/74e3fabd.jpg","comment_is_top":false,"comment_ctime":1634000526,"is_pvip":false,"replies":[{"id":"114518","content":"赞👍，满分💯，又收获一份Python代码，感谢老弟！后续我们一起把代码整理到Github~","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1634136526,"ip_address":"","comment_id":315785,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5928967822","product_id":100090001,"comment_content":"python 版的代码对累加器这儿有些不一样，貌似没有longAccumulator，double之分，我这儿是这样的：<br><br>file=&#39;~~~~&#47;chapter01&#47;wikiOfSpark.txt&#39;<br>lineRDD=sc.textFile(file)<br>lineRDD.first() # 会打印出lineRDD的第一行： u&#39;Apache Spark&#39;，如果没有打印出来，则报错<br>wordRDD=lineRDD.flatMap(lambda line: line.split(&quot; &quot;))<br><br># 定义累加器<br>ac = sc.accumulator(0) # 这儿的定义方式不一样<br># 定义filter算子的判定函数f，注意，f的返回类型必须是Boolean<br>def f(x):<br>    if x==&#39;&#39;:<br>        ac.add(1)<br>        return False<br>    else:<br>        return True<br>    <br># 使用f对RDD进行过滤<br>cleanWordRDD = wordRDD.filter(f)<br>kvRDD=cleanWordRDD.map(lambda word:(word,1))<br>wordCounts=kvRDD.reduceByKey(lambda x,y:x+y)<br># 获取计算结果<br>wordCounts.collect()<br># 结果：[(&#39;Spark&#39;, 63), (&#39;Apache&#39;, 34)]<br># wordCounts.map(lambda (k,v):(v,k)).sortByKey(False).take(5)<br><br># 作业执行完毕，通过调用value获取累加器结果<br>ac.value<br># 79","like_count":1,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":528166,"discussion_content":"赞👍，满分💯，又收获一份Python代码，感谢老弟！后续我们一起把代码整理到Github~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1634136526,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":314531,"user_name":"GAC·DU","can_delete":false,"product_type":"c1","uid":1385403,"ip_address":"","ucode":"7847FBE1C13740","user_header":"https://static001.geekbang.org/account/avatar/00/15/23/bb/a1a61f7c.jpg","comment_is_top":false,"comment_ctime":1633179602,"is_pvip":true,"replies":[{"id":"114048","content":"非常赞~ 完美地复现了问题~ 这正是我想要的，哈哈~<br><br>关于第一题，代码写的没有任何问题，就是想让大家对比这里的  var n: Long = _ &#47;&#47; 全局变量，与累加器的区别所在。你的执行结果，完全符合预期，即本机跑，完全OK，但是，分布式环境就不行。这里我先不给老弟回复，老弟不妨花时间想想，没想明白的话，说明这一讲累加器没有吃透，再想想哈~ 想不清楚也不要紧，我们留言区继续讨论~<br><br>第二个问题的话，广播变量是read-only的，只能读，不能写，其实这里的问题，不是想问它和累加器的区别，而是想问，广播变量能不能封装RDD、DataFrame这种分布式数据集，答案是肯定的哈~ 除了普通变量，分布式数据集之上，也可以创建广播变量~","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1633601985,"ip_address":"","comment_id":314531,"utype":1}],"discussion_count":4,"race_medal":0,"score":"5928146898","product_id":100090001,"comment_content":"写程序测试了一下老师的第一个思考题，在本机的idea中可以得到正确的结果79，但是在spark- shell或者提交到yarn集群上结果却是0，好纠结，请老师解惑，代码如下。<br>第二个思考题，我认为广播变量是只读数据，参加计算时不能随着RDD一起变换形态破坏数据的一致性。<br><br>import org.apache.spark.sql.SparkSession<br><br>object BcAcOpt {<br><br>  var n: Long = _ &#47;&#47; 全局变量<br><br>  def main(args: Array[String]): Unit = {<br><br>    val spark = SparkSession.builder.master(&quot;local[*]&quot;).appName(&quot;board&quot;).getOrCreate()<br><br>    val lineRDD = spark.sparkContext.textFile(&quot;wikiOfSpark.txt&quot;)<br><br>    println(lineRDD.partitions.length)<br><br>    val wordRDD = lineRDD.flatMap(word =&gt; word.split(&quot; &quot;))<br><br>    val filterRDD = wordRDD.filter(acf)<br><br>    val kvRDD = filterRDD.map(word =&gt; (word, 1))<br><br>    val wordCount = kvRDD.reduceByKey((x, y) =&gt; x + y)<br><br>    wordCount.take(10)<br><br>    println(n)<br><br>    spark.stop()<br><br>  }<br><br>  def acf(word: String): Boolean = {<br>    if (&quot;&quot;.equals(word)) {<br>      n += 1<br>      false<br>    } else {<br>      true<br>    }<br>  }<br>}<br>","like_count":1,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527713,"discussion_content":"非常赞~ 完美地复现了问题~ 这正是我想要的，哈哈~\n\n关于第一题，代码写的没有任何问题，就是想让大家对比这里的  var n: Long = _ // 全局变量，与累加器的区别所在。你的执行结果，完全符合预期，即本机跑，完全OK，但是，分布式环境就不行。这里我先不给老弟回复，老弟不妨花时间想想，没想明白的话，说明这一讲累加器没有吃透，再想想哈~ 想不清楚也不要紧，我们留言区继续讨论~\n\n第二个问题的话，广播变量是read-only的，只能读，不能写，其实这里的问题，不是想问它和累加器的区别，而是想问，广播变量能不能封装RDD、DataFrame这种分布式数据集，答案是肯定的哈~ 除了普通变量，分布式数据集之上，也可以创建广播变量~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633601985,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1396945,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epaH1gHotWQukHnF2QtT2oK9hGvyLfSaKSzuC9XKH5aSWZj2KNrxYGJeNeVzIeAibzypibsmeicppGvA/132","nickname":"魂斗罗丶","note":"","ucode":"6BEA5CD3CCC2B7","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":535241,"discussion_content":"local模式下是driver，excutor在同一个进程里面的，driver变量n在不同的excutor没有随着task代码分发产生新的变量，是不是都不需要有task的代码分发。这个还需要看看","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1638372040,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2518863,"avatar":"https://static001.geekbang.org/account/avatar/00/26/6f/4f/3cf1e9c4.jpg","nickname":"钱鹏 Allen","note":"","ucode":"7E95E82C0717DA","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":400855,"discussion_content":"    val lineRDD = spark.sparkContext.textFile(&#34;wikiOfSpark.txt&#34;) //可能hdfs上的文件路径没写完全，或者没有此文件","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633446695,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1385403,"avatar":"https://static001.geekbang.org/account/avatar/00/15/23/bb/a1a61f7c.jpg","nickname":"GAC·DU","note":"","ucode":"7847FBE1C13740","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":2518863,"avatar":"https://static001.geekbang.org/account/avatar/00/26/6f/4f/3cf1e9c4.jpg","nickname":"钱鹏 Allen","note":"","ucode":"7E95E82C0717DA","race_medal":0,"user_type":1,"is_pvip":true},"discussion":{"id":400898,"discussion_content":"文件就在根目录下","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633479566,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":400855,"ip_address":""},"score":400898,"extra":""}]}]},{"had_liked":false,"id":354300,"user_name":"唐方刚","can_delete":false,"product_type":"c1","uid":3046392,"ip_address":"广东","ucode":"93DA58C3DCCF1B","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/ugib9sF9icd9dhibQoAA025hibbD5zgZTiaddLoeEH457hrkBBhtQK6qknTWt270rHCtBZqeqsbibtHghgjdkPx3DyIw/132","comment_is_top":false,"comment_ctime":1660270179,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1660270179","product_id":100090001,"comment_content":"广播变量是以executor为粒度分发的，那么累加器是怎么分发的？最终的结果又是怎么算出来的？","like_count":0},{"had_liked":false,"id":348878,"user_name":"杨帅","can_delete":false,"product_type":"c1","uid":1684811,"ip_address":"","ucode":"0A558B1BA62E44","user_header":"","comment_is_top":false,"comment_ctime":1655481809,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1655481809","product_id":100090001,"comment_content":"老师，我有一个问题：一个worker上可以有多个executor吗？在读取文件阶段，一个executor（一个进程）里可以有多个task（多个线程）读取不同分区（RDD的分区）的数据吗？那RDD的分区的定义是什么呢，是不同机器上的数据，还是？","like_count":0},{"had_liked":false,"id":340694,"user_name":"Spoon","can_delete":false,"product_type":"c1","uid":1959822,"ip_address":"","ucode":"2FF9193AD482C2","user_header":"https://static001.geekbang.org/account/avatar/00/1d/e7/8e/318cfde0.jpg","comment_is_top":false,"comment_ctime":1649051846,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1649051846","product_id":100090001,"comment_content":"共享变量Java版本<br>https:&#47;&#47;github.com&#47;Spoon94&#47;spark-practice&#47;blob&#47;master&#47;src&#47;main&#47;java&#47;com&#47;spoon&#47;spark&#47;core&#47;SharedVariableJob.java","like_count":0},{"had_liked":false,"id":319020,"user_name":"welldo","can_delete":false,"product_type":"c1","uid":1598796,"ip_address":"","ucode":"D38E75364CD2E3","user_header":"https://static001.geekbang.org/account/avatar/00/18/65/4c/f7f86496.jpg","comment_is_top":false,"comment_ctime":1635511851,"is_pvip":false,"replies":[{"id":"115675","content":"idea其实就是单机，单机上，用普通变量，和用累加器，效果是一样的。但是在分布式的环境下，高下立现","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1635608617,"ip_address":"","comment_id":319020,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1635511851","product_id":100090001,"comment_content":"老师，关于第一题，<br>我的答案：driver和executor是不一样的进程，普通变量会拷贝副本到executor上，<br>“原本”和“副本”没有任何关系，<br>spark-shell打印出来的是“原本”，数值是初始化时的值.<br><br>我的问题：为何idea能计算正确呢？","like_count":1,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":529459,"discussion_content":"idea其实就是单机，单机上，用普通变量，和用累加器，效果是一样的。但是在分布式的环境下，高下立现","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1635608617,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]}]}