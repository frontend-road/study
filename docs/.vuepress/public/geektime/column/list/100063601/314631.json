{"id":314631,"title":"10 | 数据处理框架：批处理还是流处理？","content":"<p>你好，我是郭朝斌。</p><p>在<a href=\"https://time.geekbang.org/column/article/308366\">第4讲</a>中，我分析了物联网系统的数据技术体系。它包括  5  个部分：数据源数据采集、数据传输、数据存储、数据处理和数据应用。</p><p>不过，这还只是一个整体的认识框架。数据技术体系涉及的内容很多，虽然我在第4讲已经介绍了<strong>数据应用</strong>中用到的分析方法和算法，但是你还需要在这个框架的基础上，继续了解其他几个部分的知识。</p><p>所以我会从今天开始，用连续3讲的篇幅，分别讲一讲数据处理、数据存储和数据传输涉及的技术。每一讲分别专注其中一个主题，把它们都剖析透。至于数据源的数据采集，它跟具体的行业应用有关，不同的行业差别很大，所以我们这门课就不展开讲了。</p><p><img src=\"https://static001.geekbang.org/resource/image/6c/38/6c871e4476c3aa93f37c9c3e030e1c38.jpg?wh=2700*1359\" alt=\"\"></p><h2>处理海量数据时的难题</h2><p>我们知道，数据分析需要用到很多算法，比如支持向量机和K-means。那么在物联网系统的应用中，我们要怎么使用这些算法呢？</p><p>你可能会想：这算什么问题？从文件中或者数据库中读取数据，然后使用一个算法工具，比如  Python 语言的机器学习框架 <strong>Sklearn</strong>（也称为 Scikit-Learn），不就可以快速应用算法处理数据了吗？</p><p>其实没有这么简单，因为这种方式一般只适合用来学习和做研究。在真实的物联网场景中，你面临的是海量的数据。当我们面对海量数据的处理时，一切就不是这么直接和简单了。先不说高效地处理，首先你面临的挑战就是，如何把高达几GB甚至数TB的数据直接读取到内存中计算，显然直接加载到内存是不现实。</p><!-- [[[read_end]]] --><p>所以，对于海量数据，我们要借助大数据处理技术。</p><h2>经典思路：MapReduce的分而治之</h2><p>那么，大数据处理技术是采用什么思路解决海量数据的处理任务的呢？</p><p>为了让你更好地理解，在解答这个问题之前，我想先跟你讲一个故事。</p><p>记得上大学的时候，为了提前体验一下工作招聘的流程，我参加过一些公司的笔试。笔试题目中有很多是关于<strong>大文件处理</strong>的，比如给你一个或者几个很大的文件，问你怎么找出其中出现频次  Top  100  的词。搜索引擎公司尤其爱出这种题。</p><p>对于这种问题，如果我们要提高处理的效率，就需要考虑<strong>“分而治之”</strong>的策略了：把数据分成几份，分配给几台计算机同时处理；每台计算机统计它负责的文件块中每个词出现频次，然后再将所有计算机统计的结果进行汇总，最终得到所有数据中最高频的100个词。</p><p>虽然这只是一道笔试题，但是它来源于搜索引擎公司真实的业务需求。搜索引擎需要对海量的网页内容进行处理，建立索引，计算权重。为此，工程师们要做很多事：</p><ul>\n<li>数据切分：把大文件分成小文件</li>\n<li>数据传输：把文件分发给可用的计算机</li>\n<li>结果汇总：把每台计算机的计算结果做汇总处理，得到最终结果</li>\n<li>容错处理：解决多台计算机协作过程中出现的机器故障</li>\n<li>灵活扩展：根据计算机临时的增加，随时调整计算任务的分配和汇总</li>\n</ul><p>显然，这不是一项轻松的工作，还涉及到很多分布式系统的技术。如果每次有不同需求的时候，我们都得重新走一遍这个过程，就要投入大量的时间和精力，太不划算了。</p><p>怎么解决这个问题呢？方法当然有很多。在大数据技术的早期，应用最广泛的方法是 MapReduce ，流行的原因很简单，就是分享和开源。</p><p>首先，<strong>谷歌</strong>（Google）基于公司内部的实践，在2004年发表了<strong>分布式计算框架</strong>的<a href=\"https://users.soe.ucsc.edu/~sbrandt/221/Papers/DataManagement/dean-osdi04.pdf\">论文</a>。这篇论文提出了 <strong>MapReduce</strong> 计算框架的设计思想，主要用于解决海量网页的索引生成问题。</p><p>接着，开源搜索引擎项目 <strong>Nutch</strong> 的开发人员，基于这个设计思想开发出了开源的  <a href=\"https://hadoop.apache.org/docs/r1.2.1/mapred_tutorial.html\"><strong>Hadoop MapReduce</strong></a>  实现。</p><p>MapReduce 是怎么设计的呢？其实他们的想法跟刚才那道笔试题的解法一样，也是分而治之。</p><p>具体来说，就是把数据分成相同大小的多份，然后相应地创建多个任务，并行地处理这些数据分片，这个的过程被定义为<strong>Map</strong>过程；接着，再将Map过程中生成的计算结果进行最终的汇总，生成输出结果，这个过程被定义为<strong>Reduce</strong>过程。</p><p>这两个过程合起来就是MapReduce了。</p><p>这个设计思路本身，还不是最关键的地方。更重要的是，它提供了一个<strong>框架</strong>，把与计算机硬件相关的容错和扩展功能都实现了。同时，它也提供了统一的开发接口，我们只需要基于业务目标，定制 Map 和 Reduce 的具体计算任务就行了。这就大大降低了我们分析海量数据的难度。</p><p>当出现一个好用的工具时，人们就会试图用它来解决一切问题。随着 MapReduce的流行，人们开始把它应用在各种场景中，而不仅仅是计算索引，比如执行 Hive  中的 HQL 查询（这是一种 SQL样式的交互式计算）。</p><p>这个时候，MapReduce就显得越来越“力不从心”了，原因主要有两个方面。</p><p>一方面，MapReduce的计算模型非常简单，只有Map和Reduce两种类型。就连对数据进行排序和分组这样简单且常见的任务时，都需要转换成Map和Reduce来进行；而像上面说到的  HQL 查询，更是需要使用多个 Map 和 Reduce过程才能实现。</p><p>这有点像函数调用。我们使用C、Java和Python这些高级语言的时候，直接引用函数名，填上函数参数就可以了。但是如果我们使用的是汇编语言，就需要自己写代码实现函数入参的压栈、返回地址压栈、跳转到函数代码的地址、执行完成后的出栈和返回等操作。</p><p>这非常不直观，也容易出错。</p><p>另一方面，MapReduce  是基于分布式文件系统  HDFS 来实现数据存取的。注意，不只是读取源数据和写入计算结果，包括中间的计算结果的存储和数据交换也是基于HDFS的。</p><p>HDFS  是磁盘上的文件系统，读写的效率要远远低于内存。HDFS之所以选择磁盘作为存储介质，是因为它出现的时代计算机内存还是很昂贵的。</p><p>这就导致 MapReduce的效率不高。</p><h2>高效率开源框架：以“快如闪电”为目标的Spark</h2><p>高效是工程师们一直追求的，不管是开发还是处理，我们都希望越快越好。为了实现高效，新的设计思想和数据处理框架开始出现，其中的翘楚是 Spark 项目。</p><p>那么，Spark是如何打造高效率框架的呢？</p><p>首先，在计算模型上，Spark 抛弃了MapReduce的两个过程模型，采用了<strong>DAG</strong>（Directed Acyclic Graph，有向无环图）模型。为什么采用DAG呢？我给你挖掘一下这背后的本质。</p><p>下面这张图展示了 MapReduce 处理数据时的数据流：</p><p><img src=\"https://static001.geekbang.org/resource/image/8f/da/8f34418d89dfa6318024444596206cda.jpg?wh=2700*1469\" alt=\"\"></p><p>学过数据结构和算法的你，一定知道这就是<strong>有向无环图</strong>。所以，采用DAG来描述数据处理的过程，应该说是反映了数据处理过程的本质。这样一方面开发人员可以更容易地描述复杂的计算逻辑，另一方面计算框架也能更方便地自动优化整个数据流，比如避免重复计算。</p><p>其次，Spark 的数据存取充分地利用了<strong>内存</strong>。</p><p>它的数据分片被称为<strong>Partition</strong>。然后它基于Partition，提出了<strong>RDD</strong>（Resilient Distributed Datasets，弹性分布式数据集）的概念。</p><p>所谓的<strong>“弹性”</strong>就是指，数据既可以存储在磁盘中，也可以存储在内存中，而且可以根据内存的使用情况动态调整存储位置。这就提高了计算的效率。</p><h2>另一种思路：为实时计算而生的流处理</h2><p>到这里，你可以想要问：怎么还没有说到批处理和流处理呢？</p><p>其实我刚才介绍的MapReduce就是批处理的经典思路和框架，而Spark就是目前更高效、更流行的数据批处理开源框架。</p><p>之所以没有在一开始的时候就提出来，是因为“批处理”这个概念一定是相对于其他处理方式来说的，比如流处理。如果后来没有流处理模式，我们也只会说“大数据处理”或者“分布式数据处理”，而不会专门定义一个批处理出来。</p><p>那流处理为什么会出现呢？当然是因为业务需求。随着社交网络的出现，产品中的个人<strong>信息流</strong>（Feeds）需要基于好友关系和好友的发布动态，快速地计算和显示出和本人有关系的信息。类似的需求还有个性化的广告和消息推送服务。</p><p>而在物联网中，当采集的数据传输到系统后，我们可能需要对数据进行一些预处理，处理之后再存储起来。</p><p>这些需求在现在的应用中很常见。它们的共同特点是，数据像流水一样流入系统，然后被处理，而数据的快速处理，也就是实时计算，是这个过程中的关键点。这就是流处理出现的背景。</p><p>那怎么实现呢？考虑到数据输入的速度和数据处理的速度不一定一致，我们可以按照一定的分配策略，将数据输入多个消息队列中缓存数据，每个消息队列由一个进程或者线程处理数据。</p><p>但是和我一开始提到的计算词语出现频次的例子一样，这种基于消息队列自己开发的系统，同样会遇到拓展性、容错性的问题；另外，还要保证消息队列中消息的可靠传输。</p><p>所以一些流处理框架开始出现，一方面解决这些问题，另一方面也给开发人员提供统一的开发接口，从而方便流处理的任务的开发和实现。</p><h2>流处理开源框架：Storm、Spark Streaming 和 Flink</h2><p>这其中最早的代表就是社交网络公司Twitter开发的<strong>Storm</strong>框架。</p><p>Storm的一个重要概念就是<strong>数据流</strong>（Stream）。相对于批处理针对数据块的处理方式，所谓的流处理，就是针对数据流的处理方式。Storm把Stream描述成是<strong>元组</strong>（Tuple）构成的一个无限的序列，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/84/40/840228bf5b3ffc00af6a890f10e31040.jpg?wh=2700*471\" alt=\"\"></p><p>Stream 从<strong>水龙头</strong>（Spout）中产生，也就是说，Spout把需要处理的数据转换为由Tuple构成的Stream。然后Stream经过<strong>转接头</strong>（Bolt）的处理，输出新的Stream。其中，Bolt的处理可以是过滤、函数操作、Join等任何操作。你可以参见下面的流程图示例：</p><p><img src=\"https://static001.geekbang.org/resource/image/4c/9a/4c251b0abc56d4f8438fd832ab94229a.jpg?wh=2700*969\" alt=\"\"></p><p>图片中的Spout、Bolt 和Stream共同构成了Storm中另一个重要概念，<strong>拓扑</strong>（Topology）。</p><p>你应该可以看出来Topology是一个DAG（有向无环图）。Storm框架中运行的正是一个个Topology，而且因为是流处理，它会一直运行直到被手动终止。</p><p>基本上和Storm同时出现的流处理开源框架是Spark Streaming。看到Spark Streaming，你可能疑惑，Spark的计算引擎不是基于RDD数据集，也就是<strong>数据块</strong>来处理数据的吗？它要怎么处理<strong>数据流</strong>呢？</p><p>其实无论是数据块还是数据流，都只是数据的不同使用和处理方式，它们之间是可以相互转换的。</p><p>这就像在一些编程语言标准库中的<strong>File</strong>操作接口，File本身在磁盘中是按照块存储的，但是File操作的接口可以按照流（Stream）的方式读写文件。同样地，用户键盘输入的Stream，或者通过网络连接Socket接收的数据流，也可以先缓存起来，然后作为整块的数据统一处理。</p><p>Spark Streaming 正是将数据流转换成一小段一小段的<strong>RDD</strong>。这些小段的RDD构成一个流式的RDD 序列，称为<strong>DStream</strong>，所以它的流处理被称为<strong>“微批处理”</strong>。</p><p><img src=\"https://static001.geekbang.org/resource/image/71/95/71yyf920db9b1619ee4ee700108fd995.jpg?wh=2700*421\" alt=\"\"></p><p>显然，它的实时性取决于每小段RDD的大小，实时性不如Storm框架；不过，这种方式也使它的吞吐能力要大于 Storm。</p><p>整体来看，你可以认为Spark（包括Spark Streaming）基于数据块的数据模型，同时提供了批处理和流处理的能力。</p><p>那么既然数据块和数据流可以相互转换，是否存在基于数据流的数据模型，然后同时支持批处理和流处理的开源框架呢？毕竟数据输入系统的本来方式就是数据流，这样理论上可以获得更好的实时性。</p><p>答案是有的，比如<strong>Flink</strong>。Flink将数据块作为一种特殊的数据流，通过从文件等持久存储系统中按照Stream（流）的方式读入和处理，来提供批处理的能力。在这个基础之上，Flink提供了统一的批处理和流处理框架，也就是所谓的<strong>“流批一体”</strong>的数据处理框架。</p><p>Flink虽然出现的时间不长，但凭借着优秀的设计，性能非常强，延迟可以低到微秒级别，是对实时计算性能要求的高的场景的理想选择。行业内，阿里云和腾讯云对于 Flink 的支持都非常好；很多企业也在实践中逐渐尝试使用Flink来替代Storm框架。</p><h2>小结</h2><p>总结一下，在这一讲中，我介绍了物联网系统的两类数据处理框架，顺便讲了很多大数据处理技术的起源和设计思想。这不是我想啰嗦，而是因为学习一个东西的时候，最有效的方式就是搞清楚它的底层原理，把握它的发展脉络。只有这样，每个知识点才能各归其位，遇到问题时你就可以顺藤摸瓜地去分析、去解决。</p><p>今天的重点，这里我再概括一下：</p><ol>\n<li>批处理适合海量静态数据的非实时处理，延迟比较高，也叫离线计算，主要用于离线报表、历史数据汇总等场景。</li>\n<li>流处理适合动态输入的流式数据的实时处理，延迟低，也叫实时计算，主要用于实时监控、趋势预测、实时推荐等场景。</li>\n<li>批处理可以选择的开源框架有Spark和Flink。至于Hadoop MapReduce，你了解一下基本原理就可以了，它在应用中应该已经被放弃了。当然，如果你有遗留系统仍然使用MapReduce，那就只能维护着，或者找机会迁移到新的框架。</li>\n<li>流处理的开源框架可以选择 Storm、 Spark Streaming和Flink等。</li>\n</ol><p>另外，我还做了一张思维导图，供你在使用中参考。</p><p><img src=\"https://static001.geekbang.org/resource/image/74/5c/74c223220482f0151a023fee44a8125c.jpg?wh=2700*1311\" alt=\"\"></p><p>技术的发展是需求推动的。随着互联网上网页数量的增多，从搜索引擎开始，大数据处理相关的技术经历了萌芽到成熟的快速发展过程，已经在电商推荐系统、广告营销、金融科技等领域得到广泛的应用。</p><p>未来随着物联网的发展，智能家居、智慧城市、工业物联网的领域应用越来越多，数据量更是极速膨胀。这一定会对大数据技术提出新的挑战和需求，新的计算框架也许也会出现，因此这是一个非常活跃的技术分支。不过，你在了解、学习新的框架时，都可以回到我这里讲的数据处理的本质来思考。</p><h2>思考题</h2><p>最后，给你留一个思考题吧。</p><p>这一讲我们讨论了很多批处理和流处理的内容，我们知道一个完整的业务系统，一般既需要批处理，也需要流处理，那这些不同的数据处理框架在系统中应该如何配合呢？或者说数据处理系统的架构应该是怎样的呢？</p><p>欢迎你在留言区谈一下自己的看法，或者分享一下你工作中应用的架构方式。如果你有朋友对物联网感兴趣，也欢迎你将本课程分享给他们，一起交流学习。</p>","neighbors":{"left":{"article_title":"09 | 边缘中心：物联网网关有多重要？","id":313631},"right":{"article_title":"11 | 数据存储：物联网中的数据库有哪些？","id":316274}},"comments":[{"had_liked":false,"id":265338,"user_name":"Rain","can_delete":false,"product_type":"c1","uid":1175329,"ip_address":"","ucode":"603DFFAC6A3755","user_header":"https://static001.geekbang.org/account/avatar/00/11/ef/21/69c181b8.jpg","comment_is_top":false,"comment_ctime":1606872684,"is_pvip":false,"replies":[{"id":"96558","content":"我是假设大家熟悉DAG这个数据结构哈，可以通过极客上的数据结构算法专栏了解。有时间这个度很难把握，说多了偏离主题，有人会觉得啰嗦。<br>这个说的意思是因为数据处理的流程就是一个有向无环图，所以用有向无环图来描述这个过程符合处理流程的本质。","user_name":"作者回复","user_name_real":"郭朝斌","uid":"2302171","ctime":1606969500,"ip_address":"","comment_id":265338,"utype":1}],"discussion_count":2,"race_medal":0,"score":"18786741868","product_id":100063601,"comment_content":"为什么采用 DAG 呢？我给你挖掘一下这背后的本质。感觉这里并没有“挖掘”出来呀ヾﾉ≧∀≦)o 没说清楚DAG有什么特点，所以才采用这个数据结构","like_count":4,"discussions":[{"author":{"id":2302171,"avatar":"https://static001.geekbang.org/account/avatar/00/23/20/db/b04f43dc.jpg","nickname":"郭朝斌","note":"","ucode":"2969986E1B3851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":510888,"discussion_content":"我是假设大家熟悉DAG这个数据结构哈，可以通过极客上的数据结构算法专栏了解。有时间这个度很难把握，说多了偏离主题，有人会觉得啰嗦。\n这个说的意思是因为数据处理的流程就是一个有向无环图，所以用有向无环图来描述这个过程符合处理流程的本质。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606969500,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1031970,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/bf/22/26530e66.jpg","nickname":"趁早","note":"","ucode":"949FB3AA250D80","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":338044,"discussion_content":"map reduce不也是有向无环图么","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1609160221,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":265020,"user_name":"ranger","can_delete":false,"product_type":"c1","uid":1000242,"ip_address":"","ucode":"01C26E1DEF77FE","user_header":"https://static001.geekbang.org/account/avatar/00/0f/43/32/3eeac151.jpg","comment_is_top":false,"comment_ctime":1606736869,"is_pvip":false,"replies":[{"id":"96418","content":"������<br>Google出品必是精品","user_name":"作者回复","user_name_real":"郭朝斌","uid":"2302171","ctime":1606868679,"ip_address":"","comment_id":265020,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18786606053","product_id":100063601,"comment_content":"推荐一个批流统一的编程框架：Apache Beam","like_count":4,"discussions":[{"author":{"id":2302171,"avatar":"https://static001.geekbang.org/account/avatar/00/23/20/db/b04f43dc.jpg","nickname":"郭朝斌","note":"","ucode":"2969986E1B3851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":510771,"discussion_content":"������\nGoogle出品必是精品","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606868679,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":279098,"user_name":"9ambition","can_delete":false,"product_type":"c1","uid":1704988,"ip_address":"","ucode":"E6463C18E8CF0B","user_header":"https://static001.geekbang.org/account/avatar/00/1a/04/1c/15c00997.jpg","comment_is_top":false,"comment_ctime":1613619858,"is_pvip":false,"replies":[{"id":"102056","content":"很好的分析","user_name":"作者回复","user_name_real":"郭朝斌","uid":"2302171","ctime":1614579215,"ip_address":"","comment_id":279098,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14498521746","product_id":100063601,"comment_content":"老师提到的这个问题，还是要先明确使用业务。<br>举个例子：我这里要建立一个室内气体质量检测系统。<br>需要用到批处理的部分：做历史数据展示，做离线展示，做周平均，月平均，年平均的数据展示。<br>需要用到流处理的部分：实时气体质量监测展示。<br>框架：根据需要展示的模块进行划分。","like_count":4,"discussions":[{"author":{"id":2302171,"avatar":"https://static001.geekbang.org/account/avatar/00/23/20/db/b04f43dc.jpg","nickname":"郭朝斌","note":"","ucode":"2969986E1B3851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":515622,"discussion_content":"很好的分析","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1614579215,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":266453,"user_name":"redheart","can_delete":false,"product_type":"c1","uid":1056181,"ip_address":"","ucode":"F3064EC93C1E69","user_header":"https://static001.geekbang.org/account/avatar/00/10/1d/b5/bedea324.jpg","comment_is_top":false,"comment_ctime":1607343828,"is_pvip":false,"replies":[{"id":"97106","content":"用了emoji表情，我在电脑Web上回复时有这个问题。现在基本在手机上回复哈。<br>不好意思，你可以把它们都看成笑脸😄","user_name":"作者回复","user_name_real":"郭朝斌","uid":"2302171","ctime":1607758341,"ip_address":"","comment_id":266453,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10197278420","product_id":100063601,"comment_content":"老师，你的回复是不是用了一些图形符号，在安卓上显示为乱码。之前的好多回复也是。","like_count":2,"discussions":[{"author":{"id":2302171,"avatar":"https://static001.geekbang.org/account/avatar/00/23/20/db/b04f43dc.jpg","nickname":"郭朝斌","note":"","ucode":"2969986E1B3851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":511273,"discussion_content":"用了emoji表情，我在电脑Web上回复时有这个问题。现在基本在手机上回复哈。\n不好意思，你可以把它们都看成笑脸😄","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1607758341,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":265765,"user_name":"一步","can_delete":false,"product_type":"c1","uid":1005391,"ip_address":"","ucode":"73CEA468CE70C3","user_header":"https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg","comment_is_top":false,"comment_ctime":1607006084,"is_pvip":true,"replies":[{"id":"97125","content":"是的，好软件有很强的生命力和成长性","user_name":"作者回复","user_name_real":"郭朝斌","uid":"2302171","ctime":1607765399,"ip_address":"","comment_id":265765,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5901973380","product_id":100063601,"comment_content":"kafka 就一个非常好的好用， 消息队列起家的 流处理平台","like_count":1,"discussions":[{"author":{"id":2302171,"avatar":"https://static001.geekbang.org/account/avatar/00/23/20/db/b04f43dc.jpg","nickname":"郭朝斌","note":"","ucode":"2969986E1B3851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":511034,"discussion_content":"是的，好软件有很强的生命力和成长性","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1607765399,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":336195,"user_name":"Geek_e34009","can_delete":false,"product_type":"c1","uid":1678432,"ip_address":"","ucode":"1D6FA1FB1411FB","user_header":"","comment_is_top":false,"comment_ctime":1646006907,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1646006907","product_id":100063601,"comment_content":"每节课都给老师点个赞","like_count":0},{"had_liked":false,"id":265467,"user_name":"zhouqin","can_delete":false,"product_type":"c1","uid":1005403,"ip_address":"","ucode":"88C28CE9B6AE88","user_header":"https://static001.geekbang.org/account/avatar/00/0f/57/5b/caacc46f.jpg","comment_is_top":false,"comment_ctime":1606905906,"is_pvip":false,"replies":[{"id":"96552","content":"问这个一般说明你的系统还不需要用到。但是系统已经采用很多分布式技术，当你需要从消息队列中实时处理数据时，自然会需要用到。","user_name":"作者回复","user_name_real":"郭朝斌","uid":"2302171","ctime":1606967483,"ip_address":"","comment_id":265467,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1606905906","product_id":100063601,"comment_content":"老师可以介绍下，flink，storm在什么场景&#47;规模下会用到。","like_count":0,"discussions":[{"author":{"id":2302171,"avatar":"https://static001.geekbang.org/account/avatar/00/23/20/db/b04f43dc.jpg","nickname":"郭朝斌","note":"","ucode":"2969986E1B3851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":510940,"discussion_content":"问这个一般说明你的系统还不需要用到。但是系统已经采用很多分布式技术，当你需要从消息队列中实时处理数据时，自然会需要用到。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606967483,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":265320,"user_name":"185","can_delete":false,"product_type":"c1","uid":1058880,"ip_address":"","ucode":"F27A4189CA4864","user_header":"https://static001.geekbang.org/account/avatar/00/10/28/40/c8fad3f7.jpg","comment_is_top":false,"comment_ctime":1606868724,"is_pvip":false,"replies":[{"id":"96559","content":"������","user_name":"作者回复","user_name_real":"郭朝斌","uid":"2302171","ctime":1606969545,"ip_address":"","comment_id":265320,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1606868724","product_id":100063601,"comment_content":"实时的需求，按流的方式处理数据；能延时的需求，以批为单位处理数据。","like_count":0,"discussions":[{"author":{"id":2302171,"avatar":"https://static001.geekbang.org/account/avatar/00/23/20/db/b04f43dc.jpg","nickname":"郭朝斌","note":"","ucode":"2969986E1B3851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":510876,"discussion_content":"������","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606969545,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":265082,"user_name":"Geek_2c8816","can_delete":false,"product_type":"c1","uid":1886592,"ip_address":"","ucode":"C3E39E07A541E3","user_header":"https://static001.geekbang.org/account/avatar/00/1c/c9/80/d69093bc.jpg","comment_is_top":false,"comment_ctime":1606755172,"is_pvip":false,"replies":[{"id":"96421","content":"极客App就有这样的课程阿。<br>建议你也可以再找大数据技术的书看看","user_name":"作者回复","user_name_real":"郭朝斌","uid":"2302171","ctime":1606869193,"ip_address":"","comment_id":265082,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1606755172","product_id":100063601,"comment_content":"老师可以推荐下 数据结构与算法  的书籍或课程吗？这一节看的懵懵懂懂的好多名词","like_count":0,"discussions":[{"author":{"id":2302171,"avatar":"https://static001.geekbang.org/account/avatar/00/23/20/db/b04f43dc.jpg","nickname":"郭朝斌","note":"","ucode":"2969986E1B3851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":510795,"discussion_content":"极客App就有这样的课程阿。\n建议你也可以再找大数据技术的书看看","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606869193,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1678641,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/ONIogicHLw4qYdzjVlm5SS75kqnmrdziadgOaHZNn8IGffSZ8xHTgOz0ZBzsFqyO5dsjF7JFs5LBXvHXSpC6eiaibg/132","nickname":"Geek_4c1353","note":"","ucode":"E86D3B067A3694","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":331272,"discussion_content":"这节课也就一个\ndag吧，主要是大数据方面的概念你不懂而已","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606820347,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}