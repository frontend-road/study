{"id":793659,"title":"16｜性能上如何优化数据查询？","content":"<p>你好，我是彭旭。</p><p>上一讲我们在StarRocks里选择了适合CDP的存储模型。这一讲我们来看看CDP的几个场景，在StarRocks下，能否优化、如何优化。</p><h2>CDP在StarRocks下的性能测试</h2><p>为了让你对StarRocks性能有一个更直观的感受，我们先来准备一下测试数据。</p><h3>数据准备</h3><p>上一讲，我们为CDP的几个表准备好了DDL语句，还剩下一个标签表没有定义。</p><p>但在讲数据如何分区的时候，我们推测的结论是可以用“标签值+用户唯一ID”作为分桶。所以，标签表最终具体建表DDL就像这样。</p><pre><code class=\"language-shell\">CREATE TABLE cdp_user_tag (\n    tag_id BIGINT NOT NULL COMMENT 'tag唯一标识符',\n    tag_value VARCHAR(128) NOT NULL  COMMENT 'tag值',\n    tag_name VARCHAR(32) NOT NULL  COMMENT 'tag名称',\n    unique_user_id BIGINT NOT NULL COMMENT '用户全局唯一ID，ONE-ID',\n    tag_category INT NOT NULL  COMMENT 'tag分类'\n)\nDUPLICATE KEY(tag_id,tag_value)\nPARTITION BY (tag_id)\nDISTRIBUTED BY HASH(tag_value,unique_user_id)\nPROPERTIES (\n\"replication_num\" = \"1\"\n);\n</code></pre><!-- [[[read_end]]] --><p>你可以在<a href=\"https://github.com/ZHAMoonlight/referencebook/blob/master/script/ls16_cdp.sql\">这里</a>找到完整的CDP建表DDL脚本。我也准备了一个<a href=\"https://pan.baidu.com/s/1Es3ffXjVKpZ73RJNPWWcsw?pwd=abw3\">测试数据集</a>，包含2千万用户与1亿的事件。或者你可以用我准备的<a href=\"https://github.com/ZHAMoonlight/referencebook/tree/master/python/ls6\">脚本</a>，自己生成测试数据。</p><p>准备好数据集后，你可以使用StarRocks提供的Stream Load，将数据导入StarRocks集群，比如下面的命令，将数据导入cdp_user_event事件表。</p><pre><code class=\"language-shell\">curl --location-trusted -u root: \\\n&nbsp; &nbsp; -H \"Expect:100-continue\" \\\n&nbsp; &nbsp; -H \"label:cdp_user_event_batch1\" \\\n&nbsp; &nbsp; -H \"column_separator:#\" \\\n    -H \"timeout:3000\" \\\n&nbsp; &nbsp; -T /Users/xupeng/workspace/python/bigdata/cdp/cdp_user_event_data_part1.csv -XPUT \\\n&nbsp; &nbsp; http://127.0.0.1:8030/api/cdp/cdp_user_event/_stream_load\n</code></pre><p>这段代码有三个需要注意的地方。首先，由于事件表存在JSON字段，所以这里的CSV的分隔符使用了#号，在cdp_user表数据导入时，记得把它修改为逗号。其次，由于数据量较大，所以我将通过timeout的参数从默认超时时间600秒改成了3000秒。另外，导入的地址为StarRocks的FE HTTP Port，默认为8030。</p><p>数据导入后，再来看一下如何用SQL生成CDP用户标签。</p><h3>SQL标签</h3><p>我们的事件表里面包含了用户的登录、消费，以及其他事件。在实际业务场景下，一般会基于登录、消费这两个事件构建用户的消费等级与活跃度标签。</p><p>比如用户消费等级标签。假定消费金额10万以上为高消费群体，5万到10万为中等消费群体，其它为低消费群体。那可以使用如下SQL，基于事件表，为所有用户构建消费等级标签。</p><pre><code class=\"language-shell\">INSERT INTO cdp_user_tag (tag_id, tag_value, tag_name, unique_user_id, tag_category)\nSELECT\n    1 as tag_id,\n    CASE\n        WHEN total_amount &gt;= 100000 THEN '高消费能力'\n        WHEN total_amount &gt;= 50000 THEN '中等消费能力'\n        ELSE '低消费能力'\n    END AS tag_value,\n    '消费能力标签' AS tag_name,\n    unique_user_id,\n    1 AS tag_category\nFROM (\n    SELECT e.unique_user_id, SUM(e.total_amount) AS total_amount\n    FROM cdp_user_event e\n    GROUP BY e.unique_user_id\n) AS subquery\n\n</code></pre><p>对于用户活跃度的计算，这里假定60天内活跃次数超过10次的为高活跃度用户，5次到10次的为中等活跃用户，5次以下的为低活跃用户，下面的SQL即为用户构建了活跃度标签。</p><pre><code class=\"language-shell\">INSERT INTO cdp_user_tag (tag_id, tag_value, tag_name, unique_user_id, tag_category)\nSELECT 2,\n           CASE\n               WHEN SUM(CASE WHEN DATEDIFF(CURRENT_TIMESTAMP(), e.event_time) &lt;= 60 THEN 1 ELSE 0 END) &gt;= 10 THEN '高活跃度'\n               WHEN SUM(CASE WHEN DATEDIFF(CURRENT_TIMESTAMP(), e.event_time) &lt;= 60 THEN 1 ELSE 0 END) &gt;= 5 THEN '中等活跃度'\n               ELSE '低活跃度'\n           END AS tag_value,\n           '活跃度标签' AS tag_name,\n           e.unique_user_id,\n           2 AS tag_category\n    FROM cdp_user_event e\n    GROUP BY e.unique_user_id\n</code></pre><p>在我的StarRocks测试集群里，包含了3台8核32G的服务器，部署了一个FE与3个BE，在执行这两条SQL生成标签时，服务器CPU会有1-2个核心瞬间压力较大，但是SQL基本都在秒到分钟级内执行完成。考虑到这两个SQL都需要扫描1亿数据量的表，然后插入2千万左右的数据，这个性能其实已经算是不错的了。</p><p>除了这两个标签之外，我还构建了性别、位置两个标签，具体构建标签的全部SQL都可以在<a href=\"https://github.com/ZHAMoonlight/referencebook/blob/master/script/ls16_cdp_tag_insert.sql\">这里</a>找到。最终标签表cdp_tag数据量约1.6亿行。</p><h3>SQL人群圈选</h3><p>标签准备好后，再来看一下第二个场景。我们以“给浏览过高端手机、女性、中消费、高活跃的用户群体推送一个100无门槛手机抵扣券”为例，怎么样通过SQL找出这部分人群呢？</p><p>假设高端手机的页面ID列表为[1100442,1749628,1960722,1869590,1674494]，使用如下SQL即可以圈出我们需要发送手机抵扣券的人群ID。</p><pre><code class=\"language-shell\">SELECT u.unique_user_id\nFROM cdp_user u\n         JOIN cdp_user_event e ON u.unique_user_id = e.unique_user_id\n         JOIN cdp_user_tag t1 ON u.unique_user_id = t1.unique_user_id\n         JOIN cdp_user_tag t2 ON u.unique_user_id = t2.unique_user_id\nWHERE u.gender = 2\n  AND e.event_type = 'browse'\n  AND e.page_id in (1100442,1749628,1960722,1869590,1674494)\n  AND t1.tag_id = 1\n  AND t1.tag_value = '中等消费能力'\n  AND t2.tag_id = 2\n  AND t2.tag_value = '高活跃度';\n</code></pre><p>在我的测试集群中，这个圈人的SQL其实也只用了1秒左右的时间就能输出结果，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/50/37/506d135e25e08629095e782a565c2137.png?wh=1365x639\" alt=\"图片\"></p><h2>StarRocks高性能原因</h2><p>好了，依托StarRocks提供的高性能，我们其实已经能够满足一个中等规模CDP的性能需求了。那么StarRocks是怎么做到的呢？ 其实有很多原因。</p><h3>基于代价的优化器CBO</h3><p>首先，StarRocks提供了基于Cascades 框架的CBO（Cost-based Optimizer）。</p><p>在RBO（Rule-based Optimizer）已经退出舞台的情况下，数据库存储引擎都已经采用了CBO来优化查询，选择最优的查询计划。</p><p>通过CBO分析各种数据信息，来评估成本，帮助在众多执行计划中选出最经济的方案，提高复杂查询的速度和效果。比如将谓词下推到具体的Scan算子上，减少需要扫描的数据；比如Join时，选择合适的驱动表，减少需要链接的数据量；比如分布式表Join的时候，选择合适的Join方式，是Broadcast Join还是Colocate Join。</p><h3>索引</h3><p>其次，还记得讲StarRocks数据模型时候表的排序列吗？StarRocks会自动构建一个基于排序列的稀疏索引，稀疏索引是一种索引结构，用于在数据库中快速查找记录。与普通索引不同的是，稀疏索引只包含部分记录的引用，而不是所有记录的引用。这样可以减少索引的大小，提高查询效率。在StarRocks中索引粒度是1024，也就是每1024行记录索引一条。</p><p>如果排序列过长，或者数量比较多，StarRocks会截取排序列的前36个字节作为索引，所以也叫做前缀索引，与关系型数据库一样，你需要将查询中常见的过滤字段放在排序列的前面。区分度越大，频次越高的查询字段应当被放置于更前面。</p><p>此外，StarRocks还可以显式地创建两种索引。</p><p>第一种是 <strong>bitmap位图索引</strong>。位图索引也出现在了很多关系型数据库中，bitmap就是一个由0和1组成的数组，每个位置上的数字只能是0或者1。数组中的每个位置对应数据表中的一行记录，根据该行记录的取值情况来确定该位置上的数字是0还是1。</p><p>位图索引适合用在基数较低，值大量重复的列、枚举类型的列，比如城市列。如果列基数较高，可以使用第二种布隆过滤器（Bloom Filter）索引。</p><p>前面课程我们已经详细介绍了布隆过滤器的原理，是用来快速判断表的数据文件中是否可能包含要查询的数据，如果不包含就跳过，从而减少扫描的数据量。</p><p>比如在我们的事件表，order_no这一列就用的是uuid，基数很高，所以非常适合使用布隆过滤器索引，你可以使用如下DDL为表cdp_event建立order_no列的布隆过滤器索引。</p><pre><code class=\"language-shell\">ALTER TABLE cdp_user_event SET (\"bloom_filter_columns\" = \"order_no\");\n</code></pre><p>使用布隆过滤器索引后，根据order_no查询，从下面的两张图可以看到性能大概提升了有50%以上。</p><p><img src=\"https://static001.geekbang.org/resource/image/cb/3e/cb17936d109169dcb404f431b8eaf53e.png?wh=1895x249\" alt=\"图片\"></p><p><img src=\"https://static001.geekbang.org/resource/image/db/2e/dbc413fb7bc61f89c63ab3ed5f0ec52e.png?wh=1895x282\" alt=\"图片\"></p><p>有意思的是，如果你对比创建布隆过滤器前后的执行计划，会发现执行计划没有任何变化。不过如果你查询前使用SET enable_profile = true; 开启Profile，你就可以在 <a href=\"http:///127.0.0.1:8030/query\">Web UI</a> 的查询列表里面找到SQL执行的profile。</p><p>从Profile里面可以看到一段布隆过滤器过滤掉了多少行数据的记录。</p><p><img src=\"https://static001.geekbang.org/resource/image/2e/20/2ef03f52995918b7fe2489867f10f120.png?wh=486x62\" alt=\"图片\"></p><p>和关系型数据库的索引方式相比，StarRocks更突出的地方是将索引融入到了表模型。所以在建表的时候，我们需要在如何分区、如何使用排序键上考虑得更多。</p><h3>Query Cache</h3><p>CBO与索引优化，能够让单条SQL性能得到很好的保障，但是对于OLAP数据库来说，对并发的支持相对没那么好。所以，StarRocks提供了Query Cache机制，让其对并发的支持得到了大大提升。</p><p>Query Cache 的作用是把查询过程中的本地聚合中间结果缓存在内存中，以在后续查询中复用。</p><p>值得注意的是，Query Cache和Query Result Cache不同。它缓存的是查询过程中的聚合中间结果而不是最终结果，因此大大提高了缓存的命中率。即使是不完全一致的查询，Query Cache 也能发挥加速作用。</p><p>Query Cache默认是关闭的，那什么时候可以开启Query Cache？举几个例子。</p><ol>\n<li>语义上等价的查询：比如有几个子查询被多个场景复用。</li>\n<li>扫描分区重合的查询：比如我们CDP事件表是基于事件时间列分区的，如果需要统计一段时间区间的每日销售额，会基于查询谓词“事件时间”来切割分区，并将分区聚合的中间结果缓存，这样相当于每个分区只需要统计一次，就能在各种日期区间的查询中被复用。</li>\n<li>查询的数据以按分区追加的形式导入，如果数据涉及到更新、删除，会导致缓存失效，不过如果以追加形式导入，StarRocks会维护一个多版本的缓存，多版本缓存机制会尝试把Query Cache中缓存的结果与磁盘上存储的增量数据合并，确保新查询能够获取到最新版本的Tablet数据。不过多版本缓存受限条件较多，比如更新模型、主键模型就不支持。</li>\n</ol><p>你可以使用如下命令来开启Query Cache。</p><pre><code class=\"language-shell\">--打开 Query Cache\nset enable_query_cache=true;\n--设置并行度pipeline_dop为较小值\nset pipeline_dop=1;\n</code></pre><p>这里有个pipeline_dop（Degree of Parallelism，并行度）的概念，如果分桶数量过小，当BE 需要处理的 Tablet 数量小于 pipeline_dop 参数的取值时，Query Cache 就无法生效。不过从3.0 版本开始，StarRocks就能支持根据查询并发度自适应调节 pipeline_dop。</p><h3>MPP分布式执行框架</h3><p>最后，StarRocks最重要也是最直接的一个性能提升点，就是使用MPP来充分利用集群的能力。</p><p>StarRocks 采用 MPP (Massively Parallel Processing) 分布式执行框架。通过将任务分散到多个节点上并行执行，充分利用所有执行节点的资源，提高数据处理速度和性能，而且查询性能能够随着集群水平扩展不断提升。</p><p><img src=\"https://static001.geekbang.org/resource/image/cd/8a/cd917a58ee6a1186073ece60d484ba8a.png?wh=1496x1006\" alt=\"\"></p><h2>小结</h2><p>当你选用合适的表模型、设计好分区分桶键后，StarRocks会基于排序列给你构建一个前缀索引，这个前缀索引跟关系型数据库的索引类似，此时只要你的查询条件带有分区分桶键或者排序列，一般就能够获得较好的性能，在上亿数据行的情况下，做到毫秒级的响应。</p><p>除了前缀索引外，StarRocks还支持bitmap与布隆过滤器索引，能够分别在低基数列场景与高基数列场景提升查询性能。</p><p>StarRocks拥有强大的CBO查询优化器，CBO通过采集统计表的行数、列数据大小、列基数等信息，基于这些信息进行代价估算，能够在数万级别的执行计划中，选择代价最低的执行计划，提升复杂查询的效率和性能。</p><p>当然，StarRocks还有很多其他优秀的点，比如支持物化视图加速查询、全面向量化引擎等能够在不同场景对性能有所帮助，所有这些设计组合起来，造就了性能强大的StarRocks引擎。</p><h2>思考题</h2><p>StarRocks稀疏索引的索引粒度是1024，为什么选择1024，可以更改这个值吗？更改了会有什么影响呢？</p><p>欢迎你在留言区和我交流。如果觉得有所收获，也可以把课程分享给更多的朋友一起学习。欢迎你加入我们的<a href=\"http://jinshuju.net/f/QX5mGO\">读者交流群</a>，我们下节课见！</p>","neighbors":{"left":{"article_title":"15｜数据存储上如何选用合适的表存储类型？","id":793500},"right":{"article_title":"17｜ClickHouse为什么会给人极致速度的印象？","id":794351}},"comments":[{"had_liked":false,"id":396621,"user_name":"阿光","can_delete":false,"product_type":"c1","uid":2415396,"ip_address":"广东","ucode":"D96511F2DF6FAB","user_header":"https://static001.geekbang.org/account/avatar/00/24/db/24/73e217f8.jpg","comment_is_top":false,"comment_ctime":1735110495,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100772701,"comment_content":"为什么选择 1024 作为索引粒度？\n选择 1024 作为索引粒度是一个折中的选择，主要考虑以下几个因素：\n\n查询性能：较小的索引粒度（例如 1024）可以提供较高的查询性能，因为它可以更精细地定位数据块，从而减少扫描的数据量。\n索引大小：较大的索引粒度（例如 4096 或更大）可以减少索引的存储空间，但可能会降低查询性能，因为需要扫描更多的数据行。\n内存使用：较小的索引粒度会增加索引的内存使用量，而较大的索引粒度则会减少内存使用。\n选择 1024 作为默认值是为了在查询性能和索引大小之间取得平衡。","like_count":0}]}