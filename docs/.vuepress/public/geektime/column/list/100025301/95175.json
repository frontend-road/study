{"id":95175,"title":"FAQ第一期 | 学习大规模数据处理需要什么基础？","content":"<p>你好，我是蔡元楠。</p><p>专栏上线已经一个月了，在这里我要先感谢大家的留言，留言的对答可以使我们互有补益。</p><p>这段时间，我发现留言中的很多问题都很有价值，希望你也可以看到。所以，我根据已发布的文章中的思考题，从留言中摘录了一些典型的、常见的问题做出答疑集锦，最终成为了今天你看到的“特别福利篇”。</p><h2>“<a href=\"https://time.geekbang.org/column/article/90067\">开篇词</a>”问题精选</h2><p>问题一：学习大规模数据处理需要有什么基础？</p><p><img src=\"https://static001.geekbang.org/resource/image/a6/05/a6b4f451fde7e70d80649889d4d9b005.jpg?wh=1057*1453\" alt=\"\"></p><p>这是一个很好的问题，虽然专栏已经更新了一个月，我还是要把这个开篇词中的提问放进来。就像你看到的那样，有好几位读者都问了类似的问题。</p><p>其实在最开始做专栏的内容设计时，我并没有对读者的知识背景作任何假设。</p><p>所以，即使是一些基础的技术概念，我也会举例解释一下（如果你已经会了可能会觉得啰嗦，这时候就需要你照顾一下其他同学了）。如果你有一些语言的编程经验（任何语言都可以）的话，看文章的理解速度会快一点。文章中会有一些示例代码，是用Python编写的。</p><p>但是在设计类型的案例中，我不觉得它对读者有特别的技术要求。</p><p>希望你在后面的阅读中提出建议，告诉我有哪些地方我讲得不够清楚，或者解释的过多，我会适当调整内容。</p><p>问题二：小型公司程序员学习大规模数据处理的意义？</p><p><img src=\"https://static001.geekbang.org/resource/image/76/8c/763eefc53ce0e3c4ce07240328c8358c.jpg?wh=1125*890\" alt=\"\"><br>\n这个问题问得很好。以客观条件来看，韩程的说法没有问题。</p><!-- [[[read_end]]] --><p>大规模的互联网公司天生数据量是要大一些的。但是，这并不意味着大数据处理只在大公司才能发挥价值。你也要考虑其他方面。</p><p>第一，对于公司来讲，小型互联网公司或者传统企业，并不是不需要数据处理技能，而是他们还没有从数据中挖掘business insight的意识，没有数据驱动决策的意识，甚至没有收集数据的意识。</p><p>举个我工作中见到的例子。比如，有些饲养奶牛的农户，他们几十年来根本不知道什么是数据。但是，当我们帮他们细致地搜集奶牛每天的活动数据，比如饮食、运动、作息、产奶，他们就能从中找到最经济（最优）的饲料投放方式。</p><p>第二，对于个人来讲，你就一定要看长期的职业发展，公司会从小变大，职位会从低变高。当你需要影响决策的时候，当你面临的数据量变多的时候，当你准备跳槽的时候，数据的处理能力都是至关重要的。</p><h2>“<a href=\"https://time.geekbang.org/column/article/90081\">第一讲</a>”问题精选</h2><p>思考题：如果你在Facebook负责处理用户数据，你会选择什么样的分片函数来保证均匀分布的数据分片？</p><p>我发现有很多精彩的回答。比如下图中的CountingStars同学，他的思路非常有意思。是把年龄的数值前后颠倒进行分片。</p><p><img src=\"https://static001.geekbang.org/resource/image/ba/33/bae98a0e4b3c21418dd769fe96532433.jpg?wh=1125*378\" alt=\"\"></p><p>还有这位Mark Lee，他认为可以使用身份证后面的随机数来进行分片，纯技术上看起来似乎可行。但要使用用户的身份ID的话，你还需要考虑是否符合法律、道德、隐私方面的问题。</p><p><img src=\"https://static001.geekbang.org/resource/image/a0/60/a079de51a78ea36f01bde3a30da5a560.jpg?wh=1125*460\" alt=\"\"></p><p>而Freud的想法是引用随机标记来保证数据分片的随机性。但这里要保证数据的均匀可重复才行。如果你在shard2上的任务失败，你需要能够还原出错的任务并进行重试。</p><p><img src=\"https://static001.geekbang.org/resource/image/ba/cc/ba4a945178f382ea11f4e32d24d7dacc.jpg?wh=1125*891\" alt=\"\"></p><p>榣山樵客把这几个回答可能出现的问题做了个总结。他的回复是一切有效降低十位数权重的哈希算法都是可行的。</p><p><img src=\"https://static001.geekbang.org/resource/image/fe/05/fe092ac4cf0ae0d9562c0a1796460605.jpg?wh=1124*1510\" alt=\"\"></p><p>倒置年龄可以明显改善分布不均的问题，但是也可能对某些单一热点无解，比如25岁的用户特别多的话还是会出问题。</p><p>随机分区可以做到均衡，但对combine、io等优化不够友好。还有一个缺点，是当分区任务失败，需要重新分区的时候，分区结果不再是deterministic的。如果某一台机器宕机了，你要如何重新分配原本属于这台机器上的用户数据？</p><p>先采样，再动态合并和拆分的实现过于复杂，效果可能不够稳定。</p><p>像他一样，在每个答案里都分别给出这个答案所存在的不足，这一点是我非常赞赏的。在开发设计中没有哪个答案是特别完美的，我们能做的是分析哪一个才是最符合自身应用需求，进而改善。</p><h2>“<a href=\"https://time.geekbang.org/column/article/90533\">第二讲</a>”问题精选</h2><p>第二讲中，我留下的思考题是“你现在正在使用的数据处理技术有什么问题？你有怎样的改进设计？”。</p><p>mjl在回答中阐述了他比较了解的Spark和Flink，总结得很好。</p><p><img src=\"https://static001.geekbang.org/resource/image/ca/68/ca8501842f112eea2ae8e8c4d8ed6d68.jpg?wh=1125*1681\" alt=\"\"></p><p>虽然原生Spark Streaming Model和Dataflow Model不一样，但是Cloudera Labs也有根据Dataflow Model的原理实现了Spark Dataflow，使得Beam也可以跑Spark runner。</p><p>而对于Flink来说的话，在0.10版本以后，它的DataStream API就已经是根据Dataflow Model的思想来重写了。</p><p>现在Flink也支持两套API，分别是DataStream版本的和Beam版本的。其实data Artisans一直都有和Google保持交流，希望未来两套Beam和Flink的API能达到统一。</p><p>最后赞一点，批处理是流处理的子集，这个观点我在第一讲的留言中也提到过。</p><p><a href=\"https://time.geekbang.org/column/article/91125\">第三讲</a>和<a href=\"https://time.geekbang.org/column/article/91166\">第四讲</a>中问题较为开放，与读者自身的工作内容强相关，很多都是大家在分享自己的经验，内容很丰富，这里篇幅不足，建议大家去原文的留言中看一看。</p><h2>“<a href=\"https://time.geekbang.org/column/article/91647\">第五讲</a>”问题精选</h2><p>第五讲中讲的主要是分布式处理系统的三个重要指标：扩展性，一致性和持久性。根据这个内容，3SKarl同学提问弱一致性和最终一致性的区别是什么。</p><p><img src=\"https://static001.geekbang.org/resource/image/d9/a4/d9d1829450683fbe555674c11dec61a4.jpg?wh=1125*1006\" alt=\"\"></p><p>这是个很棒的问题。简而言之，弱一致性是个很宽泛的概念，它是区别于强一致性而定义的。广义上讲，任何不是强一致的，而又有某种同步性的分布式系统，我们都可以说它是弱一致的。</p><p>而最终一致性是弱一致性的一个特例，而且是最常被各种分布式系统用到的一个特例。</p><p>其他的比如因果一致性、FIFO一致性等都可以看作是弱一致性的特例，不同弱一致性只是对数据不同步的容忍程度不同，但是经过一段时间，所有节点的数据都要求要一致。</p><p>学习专栏时，重要的是理解它们的区别。这部分知识是为了后边讲CAP理论服务的，实际的工作中也不会像考试考概念题一样，让你背写这些一致性的定义。</p><p><img src=\"https://static001.geekbang.org/resource/image/4a/54/4a5e3922d78ec17c269691cc49869e54.jpg?wh=1125*881\" alt=\"\"></p><p>hua168同学问的是强一致性的误差范围。这个问题非常有趣，强一致性并没有误差可言的，强一致性简单地说指的就是如果更新一条数据，那所有用户读取数据的时候必须都看到这条更新了的数据。</p><p>在这里我也想借着FAQ分享一个自己当年在面试Bloomberg的面试经历。</p><p>面试官给我出的题目是这样的：如果要设计Bloomberg的股票信息系统中的数据库系统，系统需要实时更新股票价格，而数据更新的写入量非常大，用户也需要读取最新的股票资讯，你会如何设计这套系统。</p><p>这个问题其实有很多的未知区域需要我们去和面试官去阐明，例如用户的Use Cases是什么？在此我就不一一展开了，在这里我只想分享一个和一致性相关的内容。</p><p>在和Bloomberg的Tech Lead讨论时我发现，原来他们的股票系统显示的股价并不是强一致性的，延迟范围是1分钟左右。</p><p>因为应用场景上，普通股民并不会需要实时关心每秒钟股票价格的动态，更多的是关心大盘走势。而金融巨头在操作股票的时候，更多只关心特定的几只股票，所以这些股票的价格通常对于他们来说会更新快一点。</p><p>所以说，很多现实生活上的实际应用和我们本来想象的并不太一样。</p><p>到这里，我们的第一期答疑就结束了。</p><p>就像我在专栏一开始的时候与你说的一样，我希望你能够积极与我互动。其实很多同样的问题会在不同的人身上重复出现，你不表达出来的话，可能永远也不知道，原来有那么多人曾经和你遇到过同样的困境。</p><p>如果你觉得有所收获，欢迎你把文章分享给你的朋友。</p><p></p>","comments":[{"had_liked":false,"id":96160,"user_name":"HomeyLiu","can_delete":false,"product_type":"c1","uid":1330141,"ip_address":"","ucode":"EF4CCB92C369B4","user_header":"https://static001.geekbang.org/account/avatar/00/14/4b/dd/41614582.jpg","comment_is_top":false,"comment_ctime":1558347103,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"40213052767","product_id":100025301,"comment_content":"数据均匀分片的核心是 哈希函数的设计。<br>如果你数据结构和算法不错的话，我觉得这是一个很简单的问题。<br>通过hashFunchiton（key）函数，输入key，输出hash值。<br><br>哈希函数设计的特点：<br>1》输入的key一样，得到的hash值肯定一样<br>2》输入的key不一样，得到的hash值可能一样，也就是hash冲突。<br>这个是评判一个哈希函数的好坏的重要标准。<br>冲突概率大的哈希函数肯定会引起严重的数据倾斜。极端的例子，<br>所有的key的hash值都一样，都跑到一个桶里面去了。<br><br>所以衡量一个哈希函数的好坏：<br>1》冲突要小。（例如用素数，还有模拟10进制，弄个26进制，abc可以编码为 0×26的0次方+1×26+2×26的2次方）<br>2》计算要快。常用位运算。<br>3》key哪怕很小的变动，输出的hash值差距越大越好。<br><br>有很多很经典的hash算法。<br><br>但是如果key一样hash值肯定一样。<br>所有key重复的数据很多的话，哈希函数是解决不了问题的。<br>必须对key进行组合，只要 组合后的key的重复的比率 不要<br>比 哈希冲突的概率 大太多就行。<br><br>","like_count":10},{"had_liked":false,"id":96353,"user_name":"朱同学","can_delete":false,"product_type":"c1","uid":1514233,"ip_address":"","ucode":"2EF7D5A051712C","user_header":"https://static001.geekbang.org/account/avatar/00/17/1a/f9/180f347a.jpg","comment_is_top":false,"comment_ctime":1558402450,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"18738271634","product_id":100025301,"comment_content":"刚入行时，师傅曾指导我，hash可以做随机，但是不能做key，因为不同平台hash算法可能是不一样的，类似需求推荐使用md5。","like_count":4},{"had_liked":false,"id":96217,"user_name":"火星人","can_delete":false,"product_type":"c1","uid":1295645,"ip_address":"","ucode":"CC7356EE4CF1D5","user_header":"https://static001.geekbang.org/account/avatar/00/13/c5/1d/1a301635.jpg","comment_is_top":false,"comment_ctime":1558359268,"is_pvip":false,"replies":[{"id":"37136","content":"谢谢你的留言！可以参考我在第22讲里所讲到的论文呀。","user_name":"作者回复","user_name_real":"Geek_88e0d7","uid":"1503187","ctime":1560295411,"ip_address":"","comment_id":96217,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14443261156","product_id":100025301,"comment_content":"老师，请以你专家级的视角，推荐5篇将来可能影响大数据发展趋势的论文吧！","like_count":3,"discussions":[{"author":{"id":1503187,"avatar":"","nickname":"Geek_88e0d7","note":"","ucode":"3E2596F3EB9165","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":450777,"discussion_content":"谢谢你的留言！可以参考我在第22讲里所讲到的论文呀。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1560295411,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":1}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":97206,"user_name":"sunsweet","can_delete":false,"product_type":"c1","uid":1027879,"ip_address":"","ucode":"787F9E1EC6A67E","user_header":"https://static001.geekbang.org/account/avatar/00/0f/af/27/76489618.jpg","comment_is_top":false,"comment_ctime":1558610068,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10148544660","product_id":100025301,"comment_content":"但是比特币交易平台就是实时的，那是怎么实现呢","like_count":2},{"had_liked":false,"id":96772,"user_name":"时间是最真的答案","can_delete":false,"product_type":"c1","uid":1183601,"ip_address":"","ucode":"B90F3EF769F865","user_header":"https://static001.geekbang.org/account/avatar/00/12/0f/71/9273e8a4.jpg","comment_is_top":false,"comment_ctime":1558502952,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10148437544","product_id":100025301,"comment_content":"感觉不是做大数据领域的同学，读这个专栏还是比较吃力的。专栏设计知识的很广，提升了大家的认识，但不懂大数据相关技术，没法实践，比如spark不懂如何部署，然后用自己所熟悉的需要去实践","like_count":2},{"had_liked":false,"id":96453,"user_name":"listen","can_delete":false,"product_type":"c1","uid":1502877,"ip_address":"","ucode":"B9FDCC1ED1F659","user_header":"https://static001.geekbang.org/account/avatar/00/16/ee/9d/3266d88b.jpg","comment_is_top":false,"comment_ctime":1558427505,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1558427505","product_id":100025301,"comment_content":"老师你好，我们是做学生学习情况的，现在要做实时，就是一节课的信息，是一个大json，1-10+M，其中嵌套多个json，由于各个子json的耦合性太强没办法分离，使用kafka的话一条数据太大了，数据是在OSS上，现在是先拉取到hdfs，<br>现在是发现3中方法，<br>1、java put到hdfs时，mq发送位置信息，sparkstreaming订阅，根据位置拉取<br>2、put 到hbase,sparkstreaming 扫描<br>3、使用sparkstreaming的textFileStream算子监控路径<br>三种方法没种都有很大的缺陷，老师能指点一下吗","like_count":0,"discussions":[{"author":{"id":1897610,"avatar":"","nickname":"Fiery","note":"","ucode":"CDB000687A6B14","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":203535,"discussion_content":"把json压缩成bson或者其它binary格式会小很多吧，而且kafka应该没有对message数据大小有限制吧？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1584050991,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}