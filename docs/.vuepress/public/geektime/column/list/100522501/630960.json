{"id":630960,"title":"19｜应用监控：如何使用埋点方式对应用监控？","content":"<p>你好，我是秦晓辉。</p><p>前面几讲我们主要是介绍了常见的中间件、数据库的监控，统称为组件监控，根据<a href=\"https://time.geekbang.org/column/article/624099\">第 9 讲</a>中我们对监控做的分类，还有应用和业务层面的监控没有介绍，接下来我会用两讲来介绍这部分内容。</p><blockquote>\n<p><span class=\"reference\">💡 因为业务指标的生成也需要应用程序侧来实现，所以这两个层面的监控可以统称为应用监控。</span></p>\n</blockquote><p>在指标监控的世界里，应用和业务层面的监控有两种典型手段，一种是在应用程序里埋点，另一种是分析日志，从日志中提取指标。埋点的方式性能更好，也更灵活，只是对应用程序有一定侵入性，而分析日志的话对应用程序侵入性较小，但由于链路较长、需要做文本分析处理，性能较差，需要更多算力支持。这一讲我们先来介绍第一种方式，使用埋点的方式做应用和业务监控。</p><h2>埋点方式介绍</h2><p>所谓的埋点，就是指应用程序内嵌了埋点的 SDK（一个 lib 库），然后在一些关键代码流程里调用 SDK 提供的方法，记录下各种关键指标。比如某个 HTTP 服务，提供了 10 个接口，每个接口的处理花费了多少毫秒，就可以作为指标记录下来。</p><p>你可能会疑惑，我的监控系统已经提供了 PUSH 接口了，比如 Prometheus 的 Pushgateway 组件，在应用程序里直接调用 Pushgateway 接口推数据不就行了吗？为什么还需要 SDK 呢？</p><!-- [[[read_end]]] --><p>核心原因是 SDK 可以帮我们封装一些通用的计算逻辑。比如有个指标是 Summary 类型（<a href=\"https://time.geekbang.org/column/article/620800\">第 2 讲</a>介绍过这个数据类型），可以提供某个接口99分位的延迟数据。如果没有 SDK，我们需要怎么做呢？每当这个接口响应一次请求，就记录一个延迟时间，然后存入一个内存数据结构，等到一个时间间隔，比如10秒钟，就把这段时间内所有的延迟数据排个序，然后取99分位的值，最后调用 Pushgateway 的接口推过去。很麻烦是不是？</p><p>我们需要准备这个数据结构，这个数据结构还需要线程安全。如果请求非常频繁，耗时数据很多，还得进行限制，比如这个数据结构只保存1000个耗时数据。然后到了时间间隔之后需要排序，还要组织成监控系统需要的数据格式，还需要调用 HTTP 接口推送数据。</p><p>而 SDK 就是做这些通用逻辑的，应用程序要做的，就是拿到延迟数据之后，调用 SDK 的方法告知 SDK，说又有一次新的接口调用，延迟数据是多少，哥们后续就交给你了，SDK 就能完成剩余所有的事情。</p><p>业界比较知名的跨语言埋点工具是 <a href=\"https://github.com/statsd/statsd\">StatsD</a> 和 <a href=\"https://prometheus.io/docs/instrumenting/clientlibs/\">Prometheus</a>。当然，有些语言有自己生态的常用工具，比如 Java 生态的 Micrometer，不过一般公司都会使用多种语言，这些跨语言的埋点方案通常使用频率会更高。所以，这一讲我会分别介绍这两个方式，让你有个全面的认识，我们先从 StatsD 开始。</p><h2>StatsD</h2><p>StatsD 开始被熟知是因为<a href=\"https://www.etsy.com/codeascraft/measure-anything-measure-everything/\">《Measure Anything, Measure Everything》</a>这篇文章，Etsy 的工程师使用 NodeJS 开源了这个<a href=\"https://github.com/statsd/statsd\">项目</a>。</p><p>StatsD 有个很大的特点是使用 UDP 传输协议，大部分计算逻辑都挪到了 StatsD 的 Server，SDK 层面的工作非常轻量。</p><p><img src=\"https://static001.geekbang.org/resource/image/94/0d/94e9f7d2251d6241bb0f83308810230d.png?wh=2396x824\" alt=\"\" title=\"StatsD 架构图\"></p><p>StatsD SDK 与 StatsD Server 之间通信使用的是UDP 协议，UDP 协议是 fire-and-forget，无需建立连接，即使 StatsD Server 挂了，也不影响应用程序，而对于延迟分布区间这样的计算逻辑，是在 StatsD Server 里计算的，也不会影响应用程序，所以整个 StatsD 的设计是非常轻量的，对应用程序基本没有影响。</p><p>由于 StatsD 相当知名，所以很多采集器都实现了 StatsD 的协议，比如 Telegraf、Datadog-agent，也就是说，图上的 StatsD Server 是可以换成 Telegraf 或 Datadog-agent 的。这样就不用部署太多进程，一个采集器包打天下，就拿 Telegraf 来说吧，替换后架构就变成了这样。</p><p><img src=\"https://static001.geekbang.org/resource/image/e4/fb/e45a7a5926bb491c5560bc16a5189cfb.png?wh=2126x1350\" alt=\"\"></p><p>下面我来演示一下，用一个小程序做个埋点，让你有个感性的认识。我们就把 Telegraf 当做 StatsD Server 来接收埋点数据，Telegraf 是 InfluxData 主导开源的监控采集器，我之前做过一次调研，调研笔记我也放在<a href=\"https://mp.weixin.qq.com/s/JeBa_YOJdsv_QOlCVDHdtw\">这里</a>，供你参考。</p><p>Telegraf 提供 StatsD 的 input 插件，在配置文件中搜索 inputs.statsd 就能找到相关的配置段了，里边有详尽的注释，我就不再赘述了，直接上配置样例。</p><pre><code class=\"language-yaml\">[[inputs.statsd]]\nprotocol = \"udp\"\nservice_address = \":8125\"\npercentiles = [50.0, 90.0, 99.0, 99.9, 99.95, 100.0]\nmetric_separator = \"_\"\n</code></pre><p>Telegraf重启之后就会在 8125 开启 UDP 监听，我们写的程序就可以往这个地址推送监控数据了。因为我对 Go 语言比较熟悉，所以这里我给你提供一个 Go 埋点的例子。</p><pre><code class=\"language-go\">package main\nimport (\n    \"fmt\"\n    \"math/rand\"\n    \"net/http\"\n    \"time\"\n    \"github.com/smira/go-statsd\"\n)\nvar client *statsd.Client\nfunc homeHandler(w http.ResponseWriter, r *http.Request) {\n    start := time.Now()\n    // random sleep\n    num := rand.Int31n(100)\n    time.Sleep(time.Duration(num) * time.Millisecond)\n    fmt.Fprintf(w, \"duration: %d\", num)\n    client.Incr(\"requests.counter,page=home\", 1)\n    client.PrecisionTiming(\"requests.latency,page=home\", time.Since(start))\n}\nfunc main() {\n    // init client\n    client = statsd.NewClient(\"localhost:8125\",\n        statsd.TagStyle(statsd.TagFormatInfluxDB),\n        statsd.MaxPacketSize(1400),\n        statsd.MetricPrefix(\"http.\"),\n        statsd.DefaultTags(statsd.StringTag(\"service\", \"n9e-webapi\"), statsd.StringTag(\"region\", \"bj\")),\n    )\n    defer client.Close()\n    http.HandleFunc(\"/\", homeHandler)\n    http.ListenAndServe(\":8000\", nil)\n}\n</code></pre><p>这个 Web 服务只有一个根路径，逻辑也很简单，就是随机 sleep 几十个毫秒当做业务处理时间。整体逻辑是这样的：首先，我们要通过 statsd.NewClient 初始化一个 StatsD 的客户端，参数中指定了 StatsD 的 Server 地址（在这个例子里就是 Telegraf 的 8125），指定了所有监控指标的前缀是 <code>http.</code>，还指定了两个全局 Tag，一个是 <code>service=n9e-webapi</code>，另一个是 <code>region=bj</code>。通过 TagStyle 指定要发送的是 InfluxDB 样式的标签。</p><p>然后，在请求的具体处理逻辑里上报了两个监控指标，一个是 <code>requests.counter</code>，另一个是 <code>requests.latency</code>，并为它们指定了一个指标级别的标签 <code>page=home</code>，整体看起来还是比较简单的。</p><p>Telegraf 支持多种 output 插件，可以使用比较快捷的 outputs.file 插件，把生成的指标写到 stdout，来验证效果。</p><pre><code class=\"language-go\">[[outputs.file]]\nfiles = [\"stdout\"]\n</code></pre><p>请求数量和请求延时都是典型的应用层面的监控指标，如果我们想要做业务指标监控，比如订单量监控，应该怎么做呢？其实逻辑是完全一样的，仿照 <code>requests.counter</code> 的写法，做一个订单量的指标，每次创建一个新订单的时候，就给订单量指标 <code>+1</code>。一般一个服务会部署多个实例，每个实例都统计了自己的订单量，要计算最近一分钟的订单数量的话，只需要在服务端使用 PromQL 做二次汇总计算。</p><p>StatsD 的埋点方式我们就介绍这么多，下面我们介绍一下 Prometheus 的埋点方式。</p><h2>Prometheus</h2><p>Prometheus 的埋点方式跟 StatsD 很像，对于请求数量和延迟这样的监控指标，也是在请求处理完成之后，调用 SDK 的方法进行记录的。不过，如果每个方法都要加这么几行代码就显得太冗余了，最好还是通过 AOP 的方式做一些切面逻辑，Nightingale 的 Webapi 模块就是这么干的，我直接用这个<a href=\"https://github.com/ccfos/nightingale\">代码</a>给你讲解。</p><p>Webapi 的职能是提供一系列 HTTP 接口给 JavaScript 调用，我们需要监控这些接口的调用量、成功率、延迟数据。埋点之前我们先规划一下标签，我们给每个 HTTP 接口规划 4 个标签。</p><ul>\n<li>service：服务名称，要求全局唯一，可以和其他服务区分开。</li>\n<li>code：HTTP 返回状态码，可以根据这个信息得知 4xx 的比例是多少，5xx 的比例是多少，计算成功率。</li>\n<li>path：接口路径，比如 <code>/api/v1/users</code> ，有时候我们会在接口路径中放置 URL 参数，比如 <code>/api/v1/user/23</code>、<code>/api/v1/user/12</code> 是请求 id 为 23 和 12 的用户信息。这个时候不能直接把这个 URL 作为接口路径的标签值，否则这个指标颗粒度就太细了，应该把接口路径的标签值设置成 <code>/api/v1/user/:id</code>。</li>\n<li>method：HTTP 方法，GET、POST、DELETE、PUT 等。</li>\n</ul><p>Prometheus 埋点需要提前把指标变量定义出来，我们使用一个单独的包来放置，你可以看一下<a href=\"https://github.com/ccfos/nightingale/blob/main/src/webapi/stat/stat.go\">相关代码</a>。</p><pre><code class=\"language-go\">package stat\n\nimport (\n\t\"time\"\n\n\t\"github.com/prometheus/client_golang/prometheus\"\n)\n\nconst Service = \"n9e-webapi\"\n\nvar (\n\tlabels = []string{\"service\", \"code\", \"path\", \"method\"}\n\n\tuptime = prometheus.NewCounterVec(\n\t\tprometheus.CounterOpts{\n\t\t\tName: \"uptime\",\n\t\t\tHelp: \"HTTP service uptime.\",\n\t\t}, []string{\"service\"},\n\t)\n\n\tRequestCounter = prometheus.NewCounterVec(\n\t\tprometheus.CounterOpts{\n\t\t\tName: \"http_request_count_total\",\n\t\t\tHelp: \"Total number of HTTP requests made.\",\n\t\t}, labels,\n\t)\n\n\tRequestDuration = prometheus.NewHistogramVec(\n\t\tprometheus.HistogramOpts{\n\t\t\tBuckets: []float64{.01, .1, 1, 10},\n\t\t\tName:&nbsp; &nbsp; \"http_request_duration_seconds\",\n\t\t\tHelp:&nbsp; &nbsp; \"HTTP request latencies in seconds.\",\n\t\t}, labels,\n\t)\n)\n\nfunc Init() {\n\t// Register the summary and the histogram with Prometheus's default registry.\n\tprometheus.MustRegister(\n\t\tuptime,\n\t\tRequestCounter,\n\t\tRequestDuration,\n\t)\n\n\tgo recordUptime()\n}\n\n// recordUptime increases service uptime per second.\nfunc recordUptime() {\n\tfor range time.Tick(time.Second) {\n\t\tuptime.WithLabelValues(Service).Inc()\n\t}\n}\n</code></pre><p>uptime 变量是顺手为之，统计进程启动了多长时间，不用太关注，RequestCounter 和 RequestDuration，分别统计请求流量和请求延迟。Init 方法是在 Webapi 模块进程初始化的时候调用，所以进程一起，就会自动注册好。</p><p>然后我们写一个 middleware，在请求进来的时候拦截一下，省得每个请求都要去统计，你可以看一下 middleware 方法的<a href=\"https://github.com/ccfos/nightingale/blob/main/src/webapi/router/router.go#L20\">代码</a>。</p><pre><code class=\"language-go\">func stat() gin.HandlerFunc {\n\t\treturn func(c *gin.Context) {\n\t\t\tstart := time.Now()\n\t\t\tc.Next()\n\t\n\t\t\tcode := fmt.Sprintf(\"%d\", c.Writer.Status())\n\t\t\tmethod := c.Request.Method\n\t\t\tlabels := []string{promstat.Service, code, c.FullPath(), method}\n\t\n\t\t\tpromstat.RequestCounter.WithLabelValues(labels...).Inc()\n\t\t\tpromstat.RequestDuration.WithLabelValues(labels...).Observe(float64(time.Since(start).Seconds()))\n\t\t}\n\t}\n</code></pre><p>有了这个 middleware 之后，new 出 gin 的 engine 的时候，就立马 Use 一下。</p><pre><code class=\"language-go\">...\nr := gin.New()\nr.Use(stat())\n...\n</code></pre><p>最后，监控数据要通过/metrics接口暴露出去，我们要暴露这个请求端点。</p><pre><code class=\"language-go\">import (\n\t...\n\t\"github.com/prometheus/client_golang/prometheus/promhttp\"\n)\nfunc configRoute(r *gin.Engine, version string) {\n\t...\n\tr.GET(\"/metrics\", gin.WrapH(promhttp.Handler()))\n}\n</code></pre><p>这样，每个 Webapi 接口的流量和成功率都可以监控到了。如果你也部署了 Nightingale，请求 Webapi（默认是18000）的&nbsp;/metrics&nbsp;接口看看返回的内容吧。</p><p>无论是StatsD，还是使用Prometheus，总之通过埋点我们采集到了监控指标。接下来这些数据如何进入监控服务端呢？我们看一下这个通路典型的构建方式。</p><h2>数据传输通路</h2><p>使用 StatsD 的埋点方式，数据通过 UDP 推给 Telegraf，Telegraf 推给后端监控系统。如果是通过 Prometheus 的方式来埋点，就是暴露 <code>/metrics</code> 接口，等待监控系统来拉。如果应用是部署在物理机或虚拟机上，直接通过本地的监控 agent 来拉取即可。如果应用是部署在 Kubernetes 的 Pod 里，则有两种办法来拉取数据，一个是 Sidecar 模式，一个是中心端服务发现的模式。下面这个示意图展示的是 Sidecar 模式。</p><p><img src=\"https://static001.geekbang.org/resource/image/13/d1/1309313e94e9a9f8a88344d74d3762d1.png?wh=2256x1232\" alt=\"\" title=\"Sidecar 模式\"></p><p>左侧 Pod1 里有两个容器，App 通过 StatsD 埋点，然后通过 UDP 推给 Telegraf，Telegraf 接收到数据之后做二次计算，把结果推给监控服务端；右侧 Pod2 里也有两个容器，App 通过 Prometheus SDK 埋点，暴露 <code>/metrics</code> 接口，Categraf 通过这个接口拉取数据，然后推给监控服务端。</p><p>这种方式的优点是比较灵活，Pod 内怎么做应用自己说了算。即使给 <code>/metrics</code> 接口增加一些认证鉴权、指标过滤、扩展标签的逻辑，都不影响其他的 Pod。数据是推给监控服务端的，监控服务端接收数据的组件可以做成无状态集群，前面架设负载均衡，整个架构非常简单、扩展性也很好。当然缺点也很明显，每个 Pod 里都伴生 Sidecar agent，浪费资源。</p><p>StatsD 埋点的方式只能使用 Sidecar模式传输数据，而Prometheus SDK 埋点还有第二种数据抓取方式：中心端服务发现模式。</p><p><img src=\"https://static001.geekbang.org/resource/image/a4/d8/a4e052ddd462710c05d2c21db88388d8.png?wh=1818x1324\" alt=\"图片\" title=\"中心端服务发现模式\"></p><p>每个应用容器都统一暴露 <code>/metrics</code> 接口，监控抓取器通过 Kubernetes 服务发现机制，找到所有的 Pod，分别抓取即可。不过，并不是所有的 Pod 都暴露指标数据，即使暴露了，接口路径也未必一定是 <code>/metrics</code>，这就需要有一个机制和规范，通过这个机制告诉指标抓取器，选择哪个类型的 Pod 抓数据，抓数据的时候使用哪个端口、哪个接口路径来抓。</p><p>一般我们使用 Pod 注解来承接这个规范，比如我们制定标准：所有想要被抓取监控数据的 Pod 都统一暴露如下注解。</p><pre><code class=\"language-go\">prometheus.io/scrape=true\nprometheus.io/metric_path=&lt;path&gt;\nprometheus.io/scrape_port=&lt;port&gt;\n</code></pre><p>然后我们就可以写抓取 Job 来抓取这类数据了，下面我给出一个样例。</p><pre><code class=\"language-yaml\">- job_name: \"kubernetes-pods\"\n  kubernetes_sd_configs:\n    - role: pod\n  relabel_configs:\n    # \"prometheus.io/scrape = true\" annotation.\n    - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]\n      action: keep\n      regex: true\n    # \"prometheus.io/metric_path = &lt;metric path&gt;\" annotation.\n    - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_metric_path]\n      action: replace\n      target_label: __metrics_path__\n      regex: (.+)\n    # \"prometheus.io/scrape_port = &lt;port&gt;\" annotation.\n    - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_scrape_port]\n      action: replace\n      regex: ([^:]+)(?::\\d+)?;(\\d+)\n      replacement: $1:$2\n      target_label: __address__\n    - action: labelmap\n      regex: __meta_kubernetes_pod_label_(.+)\n    - source_labels: [__meta_kubernetes_namespace]\n      action: replace\n      target_label: namespace\n    - source_labels: [__meta_kubernetes_pod_name]\n      action: replace\n      target_label: pod\n</code></pre><p>我们分析一下中心端服务发现机制的优缺点。优点很明显，不需要 sidecar 的 agent 了，大幅节省资源，缺点是所有的抓取规则都是统一的，不好为每个 Pod 单独指定一些认证机制、过滤规则等。不是说不能干，而是要做的话就得修改中心端这个统一的抓取规则，非常不方便，稍有不慎还容易改错，影响到别的Pod。</p><p>当然了，一般来说不提供这个灵活性也不是太大的问题，大家遵照一个统一的规范也挺好的，如果真的有某个 Pod 需要额外做一些灵活配置，大不了就不开那些注解，仍使用 sidecar 模式就好。这两种方式并不一定要二选一，同时并用也没有任何问题。</p><p>到这里，埋点监控的两种手段就都介绍完了，下面我们做一个小结。</p><h2>小结</h2><p>这一讲我们介绍了两种埋点监控应用的方式，一个是 StatsD，一个是 Prometheus，这两种方式都是跨语言的埋点方案，业界应用广泛。StatsD 是推模式，采用 UDP 协议，各类计算逻辑挪到了 StatsD Server 中，对应用本身不会造成影响。Prometheus 是拉模式，SDK 的逻辑跑在应用进程里，可能对应用造成一定影响，不过已经有很多公司做了生产验证，Prometheus 的 SDK 还是很稳定的，大可放心使用。</p><p>对于 Prometheus SDK 的埋点方案，有两种数据抓取方式，一个是 Sidecar 模式，灵活但是占用资源多；一个是中心端服务发现模式，不那么灵活但是资源占用得少，技术上没有非黑即白，建议你根据具体场景灵活选择。</p><p><img src=\"https://static001.geekbang.org/resource/image/8f/6c/8f8c77346f64b8f850798a08238c0a6c.jpg?wh=2197x1573\" alt=\"\"></p><h2>互动时刻</h2><p>对于 Prometheus SDK 埋点机制，在使用中心端抓取方式的时候，如果目标 Pod 量很大，单个抓取器就抓不过来了，这个时候就需要有个分片机制，用多个抓取器来抓，每个抓取器抓一部分指标。我们应该按照哪些维度做分片呢？具体配置样例是什么样子的？欢迎你留言分享，也欢迎你把今天的内容分享给你身边的朋友，邀他一起学习。我们下一讲再见！</p>","neighbors":{"left":{"article_title":"18｜组件监控：Kubernetes 控制面组件的关键指标与数据采集","id":630952},"right":{"article_title":"20｜应用监控：如何使用日志来监控应用？","id":632316}},"comments":[{"had_liked":false,"id":387451,"user_name":"明","can_delete":false,"product_type":"c1","uid":2529028,"ip_address":"广东","ucode":"1B46DA0B44A2E0","user_header":"https://static001.geekbang.org/account/avatar/00/26/97/04/cf3d517c.jpg","comment_is_top":false,"comment_ctime":1707297254,"is_pvip":false,"replies":[{"id":141247,"content":"嗯，trace 数据可以生成 span metrics。本专栏主要是讲指标监控所以没有提，实际三大类可观测性数据是可以相互转换的，比如 trace 可以生成 span metrics，日志中打印详尽的 access log 也可以分析出应用 metrics。","user_name":"作者回复","user_name_real":"编辑","uid":1001078,"ctime":1708584725,"ip_address":"北京","comment_id":387451,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100522501,"comment_content":"opentelemetry+opentelemetry protocol collector+spanmetrics connector针对主要库框架等进行自动注入，类似sdk，但可以说无侵入性的，也能做到老师要做的分位监控","like_count":0,"discussions":[{"author":{"id":1001078,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/46/76/67e111da.jpg","nickname":"巴辉特","note":"","ucode":"DCBB150A99548D","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":637513,"discussion_content":"嗯，trace 数据可以生成 span metrics。本专栏主要是讲指标监控所以没有提，实际三大类可观测性数据是可以相互转换的，比如 trace 可以生成 span metrics，日志中打印详尽的 access log 也可以分析出应用 metrics。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1708584725,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":371541,"user_name":"CDS","can_delete":false,"product_type":"c1","uid":1450236,"ip_address":"浙江","ucode":"A698ED3E6EA6E4","user_header":"https://static001.geekbang.org/account/avatar/00/16/20/fc/791d0f5e.jpg","comment_is_top":false,"comment_ctime":1680052467,"is_pvip":false,"replies":[{"id":135603,"content":"categraf 的 input.procstat 插件就可以哈，指定要监控的进程是什么，就可以采集进程的cpu、mem等信息","user_name":"作者回复","user_name_real":"编辑","uid":1001078,"ctime":1680176088,"ip_address":"北京","comment_id":371541,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100522501,"comment_content":"背景 \n1 同事不愿意埋点增加代码 \n2 目前只是希望看见系统（ubuntu 18.04）内各个进程的资源（cpu 内存）的大致趋势\n3 精度要求为秒级\n4 只监控本机 不监控其他机器\n\n请问如下方案是否可行\n使用Prometheus SDK http方式 拉取固定一个HTTP接口 （A服务上的）\nA服务通过端口查询pid 在使用top命令去查询资源使用情况\n\n如果可行 github上面有没有类似这样的项目\n如果不可行 是使用ebpf进行监控吗","like_count":0,"discussions":[{"author":{"id":1001078,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/46/76/67e111da.jpg","nickname":"巴辉特","note":"","ucode":"DCBB150A99548D","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":611572,"discussion_content":"categraf 的 input.procstat 插件就可以哈，指定要监控的进程是什么，就可以采集进程的cpu、mem等信息","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1680176088,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":1450236,"avatar":"https://static001.geekbang.org/account/avatar/00/16/20/fc/791d0f5e.jpg","nickname":"CDS","note":"","ucode":"A698ED3E6EA6E4","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1001078,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/46/76/67e111da.jpg","nickname":"巴辉特","note":"","ucode":"DCBB150A99548D","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":611577,"discussion_content":"主要是还想以后监控http请求这些 公司内部没得统一框架 所以也没有统一中间件层 各种框架实现一个中间件感觉又不太好","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680176600,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":611572,"ip_address":"浙江","group_id":0},"score":611577,"extra":""}]}]},{"had_liked":false,"id":370068,"user_name":"x","can_delete":false,"product_type":"c1","uid":1229769,"ip_address":"广东","ucode":"96C5BFB1449FFB","user_header":"https://static001.geekbang.org/account/avatar/00/12/c3/c9/a8e03342.jpg","comment_is_top":false,"comment_ctime":1678348554,"is_pvip":false,"replies":[{"id":134933,"content":"不会，这个大可放心","user_name":"作者回复","user_name_real":"编辑","uid":1001078,"ctime":1678438207,"ip_address":"北京","comment_id":370068,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100522501,"comment_content":"应用进程里的sdk一直在计算和保存数据，长期没有prometheus去访问它的&#47;metrics接口，会有内存问题吗","like_count":0,"discussions":[{"author":{"id":1001078,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/46/76/67e111da.jpg","nickname":"巴辉特","note":"","ucode":"DCBB150A99548D","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":608428,"discussion_content":"不会，这个大可放心","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1678438207,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":368879,"user_name":"peter","can_delete":false,"product_type":"c1","uid":1058183,"ip_address":"北京","ucode":"261C3FC001DE2D","user_header":"https://static001.geekbang.org/account/avatar/00/10/25/87/f3a69d1b.jpg","comment_is_top":false,"comment_ctime":1676860880,"is_pvip":false,"replies":[{"id":134430,"content":"1，是\n2，categraf目前不支持接收statsd协议的数据\n3，是应用引入lib\n4，开源的多，statsd和prom都挺多\n5，适用，但是端上，metrics没有那么关键，更应该引入sentry之类的方案做事件监控","user_name":"作者回复","user_name_real":"编辑","uid":1001078,"ctime":1677061254,"ip_address":"北京","comment_id":368879,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100522501,"comment_content":"请教老师几个问题：\nQ1：Pod 中的 Sidecar agent就是指Telegraf或Categraf吗？\nQ2：Sidecar方式的图中，StatsD用Telegraf;prometheus用Categraf，这是一种典型配置？还是说必须这样？（比如，Prometheus可以使用Telegraf吗？或者StatsD可以使用Categraf吗？）\nQ3：应用层埋点的Prometheus方式，是Prometheus自身具备的一个功能，不是另外的一个软件，对吗？\nQ4：老师经历的公司所用的应用层埋点方案，是用开源框架多还是自研的多？框架的话，是StatsD用得多还是Prometheus用得多？\nQ5：本文的两种埋点方案适用于移动端吗？\n比如安卓、iOS，可以用这两种方式吗？","like_count":0,"discussions":[{"author":{"id":1001078,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/46/76/67e111da.jpg","nickname":"巴辉特","note":"","ucode":"DCBB150A99548D","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":606301,"discussion_content":"1，是\n2，categraf目前不支持接收statsd协议的数据\n3，是应用引入lib\n4，开源的多，statsd和prom都挺多\n5，适用，但是端上，metrics没有那么关键，更应该引入sentry之类的方案做事件监控","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1677061254,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1332257,"avatar":"https://static001.geekbang.org/account/avatar/00/14/54/21/0bac2254.jpg","nickname":"橙汁","note":"","ucode":"EC3FF10D708C9D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":606101,"discussion_content":"感觉还是你看的不仔细。\n1. sidecar是一种形式，agent可以是任何应用比如收集日志时候可以是日志的组件。telegraf和catagraf只是两种收集器用那个选那个，无所谓看你心情哈哈哈可能不严谨，但意思是这么个意思。\n2. 因为statsd推送的数据telegraf有实现，所以就用它。要是catagraf也实现了那么也可用它。\n3. prom是可以当agent的，有规范在pod注解中规定抓取路径，是它功能\n4. 这个就需要老师回答了，我们是客户端用其他sdk 服务端没用","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1676946200,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":368881,"user_name":"Geek_1a3949","can_delete":false,"product_type":"c1","uid":2659191,"ip_address":"上海","ucode":"98113FDBBAAEBC","user_header":"","comment_is_top":false,"comment_ctime":1676863961,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100522501,"comment_content":"尝试回答一下课后题：\n\n分片可以使用Prometheus的hashmod，label选择尽量随机的，比如address，或者address+name等等\n\n- job_name: &quot;pods&quot;\n  ...\n  relabel_configs:\n  - source_labels: [__address__]\n    modulus: 3\n    target_label: __tmp_hash\n    action: hashmod\n  - source_labels: [__tmp_hash]\n    regex: 1\n    action: keep","like_count":5}]}