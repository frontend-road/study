{"id":648466,"title":"18｜流式生成与模型微调，打造极致的对话体验","content":"<p>你好，我是徐文浩。</p><p>在之前介绍llama-index和LangChain的几讲里面，我们学习了如何将大语言模型和你自己的知识库组合到一起来解决问题。这个方法中，我们不需要对我们使用的模型做任何调整，而是通过将我们的数据用Embedding向量索引起来，然后在使用的时候查询索引来解决问题。</p><p>不过，其实我们也完全可以利用我们自己的数据，创建一个新的模型来回答问题。这个方法，就是OpenAI提供的模型微调（Fine-tune）功能。这也是我们要探讨的大语言模型的最后一个主题。</p><h2>如何进行模型微调？</h2><p>模型微调，是因为无论是ChatGPT还是GPT-4都不是全知全能的AI。在很多垂直的领域，它的回答还是常常会出错。其中很大一部分原因，是它也缺少特定领域的训练数据。而如果我们有比较丰富的垂直领域的数据，那么就可以利用这些数据来“微调”一个特别擅长这个垂直领域的模型。在这个模型“微调”完成之后，我们就可以直接向模型提问了。而不用再像之前使用llama-index或者LangChain那样，先通过Embedding来查询相关资料，然后把查找到的资料也一并提交给OpenAI来获得所需要的答案。</p><p>OpenAI模型微调的过程，并不复杂。你只需要把数据提供给OpenAI就好了，对应的整个微调的过程是在云端的“黑盒子”里进行的。需要提供的数据格式是一个文本文件，每一行都是一个Prompt，以及对应这个Prompt的Completion接口会生成的内容。</p><!-- [[[read_end]]] --><p>就像下面的示例：</p><pre><code class=\"language-plain\">{\"prompt\": \"&lt;prompt text&gt;\", \"completion\": \"&lt;ideal generated text&gt;\"}\n{\"prompt\": \"&lt;prompt text&gt;\", \"completion\": \"&lt;ideal generated text&gt;\"}\n{\"prompt\": \"&lt;prompt text&gt;\", \"completion\": \"&lt;ideal generated text&gt;\"}\n...\n</code></pre><p>模型微调的过程，就是根据输入的内容，在原来的基础模型上训练。这个基础模型，就是我们<a href=\"https://time.geekbang.org/column/article/644790\">第 8 讲</a>介绍过的 Ada、Babbage、Curie和Davinci 其中的一个。每一个示例，都会导致基础模型原有参数发生变化。整个微调过程结束之后，变化后的参数就会被固定下来，变成一个只有你可以使用的新模型。</p><p>如果你提供了很多医疗行业的文本内容，那么微调出来的新模型就会拥有更多医疗领域的知识，以及对话的风格。而如果你给的是笑话大全，那么微调出来的模型就更擅长讲笑话。而且要注意，微调之后的模型，不仅有你用来微调的数据的相关知识，原先基础模型里面的绝大部分知识和能力它也还都保留着。</p><h2>来一个擅长写“历史英雄人物和奥特曼一起打怪兽”的AI</h2><p>那今天我们来微调一个什么样的模型呢？我周围有不少朋友家里都有孩子，都特别迷恋奥特曼打怪兽的故事。他们就向我提过一个需求，说能不能利用ChatGPT来做一个专门讲奥特曼打怪兽故事的应用。可以是可以，不过，为了让这个故事既能精彩一点，又有点教育意义，我们就再找一些历史上的英雄人物，赋予他们一些超能力，来和奥特曼一起打怪兽。而对应的故事数据，我们也用ChatGPT的模型来帮我们生成。</p><pre><code class=\"language-python\">import os,openai,backoff\nimport pandas as pd\n\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")\ndynasties= ['唐', '宋', '元', '明', '清', '汉', '魏', '晋', '南北朝']\nsuper_powers = ['隐形', '飞行', '读心术', '瞬间移动', '不死之身', '喷火']\nstory_types = ['轻松', '努力', '艰难']\n\n@backoff.on_exception(backoff.expo, openai.error.RateLimitError)\ndef gpt35(prompt, max_tokens=2048, temperature=0.5, top_p=1, frequency_penalty=0, presence_penalty=0):\n    response = openai.Completion.create(\n        engine=\"text-davinci-003\",\n        prompt=prompt,\n        max_tokens=max_tokens,\n        temperature=temperature,\n        top_p=top_p,\n        frequency_penalty=frequency_penalty,\n        presence_penalty=presence_penalty)\n    return response[\"choices\"][0][\"text\"]\n\ndef prepare_stories(dynasties, super_powers, story_types, output_file=\"data/ultraman_stories.csv\"):\n    df = pd.DataFrame()\n    repeat = 3\n    for dynasty in dynasties:\n        for super_power in super_powers:\n            for story_type in story_types:\n                   for i in range(repeat):\n                        prompt = f\"\"\"请你用中文写一段300字的故事，情节跌宕起伏，讲述一位{dynasty}朝时期的英雄人物，穿越到现代，拥有了{super_power}这样的超能力，通过{story_type}的战斗，帮助奥特曼一起打败了怪兽的故事。\"\"\"\n                        story = gpt35(prompt)\n                        row = {\"dynasty\": dynasty, \"super_power\": super_power, \"story_type\": story_type, \"story\": story}\n                        row = pd.DataFrame([row])\n                        df = pd.concat([df, row], axis=0, ignore_index=True)\n\n    df.to_csv(\"data/ultraman_stories.csv\")\n\nprepare_stories(dynasties, super_powers, story_types)\n</code></pre><p>这部分代码非常简单，我们定义了一系列朝代、超能力和故事的类型。然后通过三重循环，让AI根据这三者的组合来生成一系列故事。这些生成出来的故事，也就构成了我们用来微调模型的训练数据。因为数据量不大，我就直接用CSV把它存下来了。在这个过程中，数据是一条条生成的，比较慢，也比较消耗Token，你可以不用运行，直接拿我运行后生成的结果数据就好。</p><p>拿到了这些数据，我们就可以来微调模型了。我们之前已经通过pip安装了OpenAI的包，这里面自带了命令行工具，方便我们把对应的CSV格式的数据转换成微调模型所需要的JSONL格式的文件。</p><pre><code class=\"language-python\">df = pd.read_csv(\"data/ultraman_stories.csv\")\ndf['sub_prompt'] = df['dynasty'] + \",\" + df['super_power'] + \",\" + df['story_type']\nprepared_data = df.loc[:,['sub_prompt','story']]\nprepared_data.rename(columns={'sub_prompt':'prompt', 'story':'completion'}, inplace=True)\nprepared_data.to_csv('data/prepared_data.csv',index=False)\n\nimport subprocess\n\nsubprocess.run('openai tools fine_tunes.prepare_data --file data/prepared_data.csv --quiet'.split())\n</code></pre><p>输出结果：</p><pre><code class=\"language-python\">……\nWrote modified file to `data/prepared_data_prepared.jsonl`\nFeel free to take a look!\nNow use that file when fine-tuning:\n&gt; openai api fine_tunes.create -t \"data/prepared_data_prepared.jsonl\"\nAfter you’ve fine-tuned a model, remember that your prompt has to end with the indicator string ` -&gt;` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".\"]` so that the generated texts ends at the expected place.\nOnce your model starts training, it'll approximately take 8.82 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n\nCompletedProcess(args=['openai', 'tools', 'fine_tunes.prepare_data', '--file', 'data/prepared_data.csv', '--quiet'], returncode=0)\n</code></pre><p>上面的代码主要做了两个动作。首先，是对数据做了一些处理，来准备微调。对于微调，我们使用的Prompt不再是一个完整的句子，而是只用了“朝代”+“超能力”+“故事类型”拼接在一起的字符串，中间用逗号隔开。然后把这个字符串和生成的故事，用Prompt和Completion作为列名存储成了一个CSV。</p><p>其次，我们通过subprocess调用了命令行里的OpenAI工具，把上面的CSV文件，转化成了一个JSONL格式的文件。从输出的日志里面可以看到，这个文件叫做 data/prepared_data_prepared.jsonl。</p><p>如果我们打开这个JSONL文件看一眼，是下面这样的。</p><pre><code class=\"language-python\">{\"prompt\":\"唐,隐形,轻松 -&gt;\",\"completion\":\" \\n\\n一位叫做李明的英雄人物，出生在唐朝时期。他是一个勇敢的将军，在他的一生中，他打败了许多敌人，为自己的国家和人民做出了许多贡献。\\n\\n一天，李明意外被一道神秘的光束穿越到了现代。他发现自己拥有了超能力，可以隐形，可以飞行，可以发射光束，可以放出火焰，可以穿墙而过等等。\\n\\n李明发现，在现代，怪兽们正在摧毁地球，他决定和奥特曼一起，用自己的超能力，帮助奥特曼消灭怪兽们。\\n\\n于是，李明和奥特曼开始了一场艰苦的战斗，他们用自己的超能力，一招一式，击退了怪兽们，最终成功地拯救了地球。\\n\\n在这场战斗之后，地球上的人们都对李明充满了敬佩，他从此成为了一位英雄，他的事迹也被传颂了很久。李明也因此被永远铭记在人们心中，成为了一位不朽的英雄。.\"}\n{\"prompt\":\"唐,隐形,轻松 -&gt;\",\"completion\":\" \\n\\n这是一个关于英雄的故事，发生在唐朝时期的中国。一个叫李自成的勇士，他拥有过人的勇气，英勇的行为让他成为当时最受尊敬的人物。\\n\\n一天，李自成被一道神秘的光芒笼罩住，他突然发现自己似乎穿越时空，来到了现代。他惊讶地发现，自己竟然拥有了一种超能力，可以让自己隐形。\\n\\n李自成接受了这种超能力，他发现这种能力可以让自己变得更加强大，他决定利用这种能力来帮助人们。\\n\\n一次，李自成发现有一群怪兽正在破坏城市，他决定和奥特曼一起出动，利用自己的超能力，把怪兽一个个击败，最终成功拯救了城市，令众人欢呼雀跃。\\n\\n自此，李自成受到了众人的尊敬，他成为了这个城市的英雄，他也把自己的超能力用在了正义的事业上，为人们做出了许多贡献，他也成为了一个英雄。.\"}\n</code></pre><p>可以看到，转换后的数据文件，在Prompt的最后，多了一个“-&gt;”符号。而在Completion的开头，多了两个“\\n\\n”的换行，结尾则是多了一个“.”。这是为了方便我们后续在使用这个模型生成数据的时候，控制生成结果。未来在使用模型的时候，Prompt需要以“-&gt;\\n”这个提示符结束，并且将stop设置成“.”。这样，模型就会自然套用我们微调里的模式来生成文本。</p><p>有了准备好的数据，我们只要再通过subprocess调用OpenAI的命令行工具，来提交微调的指令就可以了。</p><pre><code class=\"language-python\">subprocess.run('openai api fine_tunes.create --training_file data/prepared_data_prepared.jsonl --model curie --suffix \"ultraman\"'.split())\n</code></pre><p>输出结果：</p><pre><code class=\"language-python\">Upload progress: 100%|██████████| 446k/446k [00:00&lt;00:00, 201Mit/s]\nUploaded file from data/prepared_data_prepared.jsonl: file-yn0BfnPmgvf7n0sfQzQRbbeE\nCreated fine-tune: ft-3oxkr1zBVB4fJWogJDDjQbr0\nStreaming events until fine-tuning is complete...\n(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n[2023-04-04 10:51:51] Created fine-tune: ft-3oxkr1zBVB4fJWogJDDjQbr0\n\nCompletedProcess(args=['openai', 'api', 'fine_tunes.create', '--training_file', 'data/prepared_data_prepared.jsonl', '--model', 'curie', '--suffix', '\"ultraman\"'], returncode=0)\n</code></pre><p>在这个微调的指令里面，我们指定了三个参数，分别是用来训练的数据文件、一个基础模型，以及生成模型的后缀。这里，我们选用了Curie作为基础模型，因为是讲奥特曼的故事，所以模型后缀我给它取了一个ultraman的名字。</p><p>我们的数据量不大，所以微调很快，几分钟就能完成。那接下来我们就可以使用这个模型了。我们可以通过下面的fine_tunes.list指令，找出所有我们微调的模型。</p><pre><code class=\"language-python\">subprocess.run('openai api fine_tunes.list'.split())\n</code></pre><p>输出结果：</p><pre><code class=\"language-python\">{\n  \"data\": [\n    {\n      \"created_at\": 1680576711,\n      \"fine_tuned_model\": \"curie:ft-bothub-ai:ultraman-2023-04-04-03-03-26\",\n      \"hyperparams\": {\n        \"batch_size\": 1,\n        \"learning_rate_multiplier\": 0.2,\n        \"n_epochs\": 4,\n        \"prompt_loss_weight\": 0.01\n      },\n      \"id\": \"ft-3oxkr1zBVB4fJWogJDDjQbr0\",\n      \"model\": \"curie\",\n      \"object\": \"fine-tune\",\n      \"organization_id\": \"YOUR_ORGANIZATION_ID\",\n      \"result_files\": [\n        {\n          \"bytes\": 107785,\n          \"created_at\": 1680577408,\n          \"filename\": \"compiled_results.csv\",\n          \"id\": \"RESULT_FILE_ID\",\n          \"object\": \"file\",\n          \"purpose\": \"fine-tune-results\",\n          \"status\": \"processed\",\n          \"status_details\": null\n...\n    }\n  ],\n  \"object\": \"list\"\n}\nCompletedProcess(args=['openai', 'api', 'fine_tunes.list'], returncode=0)\n</code></pre><p>在输出的JSON里面，你可以看到我们有一个fine_tuned_model字段，里面的值叫做“curie:ft-bothub-ai:ultraman-2023-04-04-03-03-26”，这个就是刚刚让OpenAI给我们微调完的模型。</p><p>这个模型的使用方法，和我们使用text-davinci-003之类的模型是一样的，只要在API里面把对应的model字段换掉就好了，对应的代码我也放在了下面。</p><pre><code class=\"language-python\">import os\nimport openai\n\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")\n\ndef write_a_story(prompt):\n    response = openai.Completion.create(\n        model=\"curie:ft-bothub-ai:ultraman-2023-04-04-03-03-26\",\n        prompt=prompt,\n        temperature=0.7,\n        max_tokens=2000,\n        top_p=1,\n        stop=[\".\"])\n    return response[\"choices\"][0][\"text\"]\n\nstory = write_a_story(\"宋,发射激光,艰难 -&gt;\\n\")\nprint(story)\n</code></pre><p>输出结果：</p><pre><code class=\"language-python\">宋朝时期，有一位叫林先生的英雄人物，他勇敢而又坚韧，曾经拯救过无数的人民，他的英勇表现让他赢得了众多的尊敬。\n一天，林先生突然发现自己穿越到了现代，他发现自己拥有了一种神奇的超能力，可以发射激光，他开始研究自己的能力，发现自己可以用激光来攻击敌人。\n林先生决定把自己的能力用来拯救人类，于是他和奥特曼一起出发，开始与怪兽作战。他们一路走来，林先生用他的激光来打击怪兽，奥特曼则用他的武器来打击怪兽。\n在一场艰苦的战斗中，林先生和奥特曼终于击败了怪兽，拯救了人类。林先生也因此获得了无数的赞誉，他也成为了一位传奇英雄。\n林先生的故事被传唱了几百年，他的英勇事迹也成为了一个永恒的传奇，让人们永远不忘。\n</code></pre><p>对应在调用模型的时候，我们使用的提示语就是“朝代”+“超能力”+“故事类型”，并且跟着“-&gt;\\n”，而stop则是设置成了“.”。</p><p>因为这是一个微调的模型，它不仅拥有我们训练数据提供的知识，也包括基础模型里的各种信息。所以我们使用的朝代、超能力和故事类型也可以是在之前微调数据里面没有出现过的。比如，上面的例子里，我们使用的超能力叫做“发射激光”，并不是我们拿来微调的数据里面有的一种超能力。你可以试试看，使用别的朝代、故事的类型，效果会是怎么样的。</p><pre><code class=\"language-python\">story = write_a_story(\"秦,龙卷风,辛苦 -&gt;\\n\")\nprint(story)\n</code></pre><p>输出结果：</p><pre><code class=\"language-python\">\n曾经有一位叫苏轼的英雄人物，他曾经英勇地抵抗过许多强大的敌人，拯救了许多被危险封印的百姓。他曾经在一次战争中发挥过自己的作用，赢得了许多胜利，被尊为英雄。\n然而，苏轼却在一次激烈的战斗中牺牲了，他的灵魂被封印在一个古老的石头里，隔着一层玻璃，一直沉睡了几百年。\n苏轼的灵魂在穿越时空，来到了现代，他发现自己拥有了一种超能力，这就是龙卷风，他可以使自己的身体具有超强的力量，甚至可以抵抗恶魔的攻击。\n苏轼在现代的世界里，发现了一种可怕的怪兽，它们正在摧毁着人类的家园，苏轼决定要拯救这个世界，于是他和奥特曼一起出发，开始了一场史诗般的战斗。\n在苏轼和奥特曼的帮助下，苏轼利用自己的超能力，一次次击退怪兽的攻击，最终他们成功地打败了怪兽，拯救了人类。\n苏轼的事迹在这里传唱了很久，他成为了一位永恒的英雄，他的故事也被传唱了下来，让人们永远不会忘记他的英勇事迹。\n</code></pre><h2>模型微调的成本考量</h2><p>细心的人可能注意到了，我们这里选用的基础模型是Curie，而不是效果最好的Davinci。之所以做出这样的选择，是出于成本的考虑。</p><p><img src=\"https://static001.geekbang.org/resource/image/22/b6/22d5be5879b0284b7cc6807a1e005fb6.png?wh=2270x986\" alt=\"\"></p><p>注：数据来源于 <a href=\"https://openai.com/pricing#language-models\">https://openai.com/pricing#language-models</a></p><p><strong>使用微调模型的成本要远远高于使用OpenAI内置的模型。</strong>以Davinci为基础微调的模型，使用的时候，每1000个Token的成本是0.12美元，是使用内置的text-davinci-003的6倍，是我们最常用的 gpt-3.5-turbo 的60倍。所以，如果只是一般的讲故事的应用，这个成本实在是太高了。就算是我们选择基于Curie微调，1000个Token的使用成本也在0.012美元，虽然比text-davinci-003要便宜，但也是gpt-3.5-turbo的6倍。</p><p>对于模型微调的效果，我们也可以通过一个OpenAI提供的命令fine_tunes.results来看。对应的，我们需要提供给它一个微调任务的id。这个id，可以在fine_tunes.list列出的fine_tunes模型的id参数里找到。</p><pre><code class=\"language-python\">subprocess.run('openai api fine_tunes.results -i ft-3oxkr1zBVB4fJWogJDDjQbr0'.split())\n</code></pre><p>输出结果：</p><pre><code class=\"language-python\">step,elapsed_tokens,elapsed_examples,training_loss,training_sequence_accuracy,training_token_accuracy\n1,625,1,0.8805545861742778,0.0,0.75\n2,1258,2,0.8059815050491868,0.0,0.7766830870279147\n3,1859,3,0.7964038042175758,0.0,0.7862068965517242\n4,2548,4,0.805052303553852,0.0,0.7774436090225564\n5,3197,5,0.7503930440556053,0.0,0.7808\n6,3846,6,0.7992317049403261,0.0,0.7770700636942676\n7,4775,7,0.6649006477473822,0.0,0.7927232635060639\n8,5432,8,0.6493354803676822,0.0,0.8049921996879875\n9,6265,9,0.6568901059838095,0.0,0.802937576499388\n10,7122,10,0.6578856167468091,0.0,0.8100358422939068\n11,7827,11,0.5687322367928961,0.0,0.8279411764705882\n12,8404,12,0.6334827334911788,0.0,0.8172043010752689\n13,9061,13,0.5771709139683721,0.0,0.825\n14,9822,14,0.6079089517825593,0.0,0.8100407055630936\n15,10399,15,0.6481047367374327,0.0,0.8154121863799283\n16,11208,16,0.5528688982071029,0.0,0.8352490421455939\n17,11913,17,0.6525803676480848,0.0,0.8093841642228738\n18,12546,18,0.5230526420679229,0.0,0.8363047001620746\n19,13163,19,0.6065665546680247,0.0,0.8236272878535774\n20,13796,20,0.5983224045073889,0.0,0.8199672667757774\n21,14549,21,0.6440337136896056,0.0,0.8267394270122783\n22,15190,22,0.6029605409912032,0.0,0.8110749185667753\n23,15759,23,0.5089513997451476,0.0,0.838475499092559\n24,16440,24,0.557213810807506,0.0,0.8265460030165912\n...\n1855,1228711,1855,0.2610049068084409,0.0,0.9219765929778934\n1856,1229312,1856,0.21196416716076574,0.0,0.9312714776632303\n1857,1229945,1857,0.14050147435694596,0.0,0.9556650246305419\n</code></pre><p>在这个命令的输出结果里，你可以在第二列elapsed_tokens看到训练消耗的Token数量。而最后一列 training_token_accuracy，则代表微调后的模型，成功预测微调的数据里下一个Token的准确率。在我们使用的这个例子里面，可以看到一开始准确率只有75%，但是随着训练数据迭代轮数的增加，准确率越来越高，达到了95%以上。</p><h2>增量训练，不断优化模型</h2><p>微调模型比较高昂的价格，限制了它的使用。<strong>不过，微调模型还有一个能力，就是我们可以在已经微调了的模型上根据新数据做进一步地微调。</strong>这个在很多垂直领域是非常有用，比如在医学、金融这样的领域，我们就可以不断收集新的数据，不断在前一个微调模型的基础之上继续微调我们的模型，让模型的效果越来越好。而这些领域往往也能承受更高一些的成本。</p><p>进一步地微调其实操作起来并不复杂，就是再准备一些数据，以之前已经微调好的模型为基础模型来操作就好了。</p><p>生成一些额外的数据：</p><pre><code class=\"language-python\">dynasties= ['秦', '五代', '隋']\nsuper_powers = ['龙卷风', '冰冻大海', '流星火雨']\nstory_types = ['轻松', '努力', '艰难', '勇敢', '辛苦']\n\nnew_stories = \"data/ultraman_stories_more.csv\"\nprepare_stories(dynasties, super_powers, story_types, repeat=3, output_file=new_stories)\n</code></pre><p>转换数据：</p><pre><code class=\"language-python\">df = pd.read_csv(new_stories)\ndf['sub_prompt'] = df['dynasty'] + \",\" + df['super_power'] + \",\" + df['story_type']\nprepared_data = df.loc[:,['sub_prompt','story']]\nprepared_data.rename(columns={'sub_prompt':'prompt', 'story':'completion'}, inplace=True)\nnew_stories_prepared = 'data/prepared_data_more.csv'\nprepared_data.to_csv(new_stories_prepared, index=False)\n\nsubprocess.run('openai tools fine_tunes.prepare_data --file data/prepared_data_more.csv --quiet'.split())\n</code></pre><p>继续微调：</p><pre><code class=\"language-python\">subprocess.run('openai api fine_tunes.create --training_file data/prepared_data_more_prepared.jsonl --model curie:ft-bothub-ai:ultraman-2023-04-04-03-03-26 --suffix \"ultraman\" --learning_rate_multiplier 0.2'.split())\n</code></pre><p>在原有的模型上微调的时候，我们要修改两个参数。</p><ol>\n<li>第一个是model参数，我们把Curie换成了我们刚才微调之后的模型<strong>curie:ft-bothub-ai:ultraman-2023-04-04-03-03-26</strong>。</li>\n<li>第二个是learning_rate_multiplier，这个参数的默认值是根据你的样本数量在0.05 到 0.2 不等。如果你继续微调的样本数要比之前微调的数据量小很多，你就可以调得大一点。</li>\n</ol><p>微调更新之后，模型的名称没有变，老的模型就被更新成了微调后的新模型，我们再来试一下这个新模型。</p><pre><code class=\"language-python\">fine_tuned = write_a_story(\"五代,流星火雨,艰难 -&gt;\\n\")\nprint(fine_tuned)\n</code></pre><p>输出结果：</p><pre><code class=\"language-python\">这是一个发生在一个古老的世界，一个叫做“六代”的世界。这个世界有着一种叫做“超能力”的特性，可以让人穿越时空，穿越到现代。\n一位叫做“英雄”的人物，他来自于六代，但他拥有了一种叫做“流星火雨”的超能力，他可以把自己的身体变成一个火焰，然后穿越时空，来到现代。\n他来到现代，发现这个世界变得越来越危险，有一种叫做“怪兽”的存在，他们想要毁灭这个世界。英雄决定帮助奥特曼一起打败怪兽，于是他们开始了一场激烈的战斗。\n英雄凭借着自己的超能力，以及奥特曼的力量，战胜了怪兽，拯救了这个世界。最后，英雄又一次穿越回六代，这次他拥有了一种叫做“流星火雨”的超能力，他可以把自己的身体变成一个火焰，然后穿越时空，拯救又一次六代。\n</code></pre><h2>流式生成</h2><p>通过模型微调，我们拥有了一个可以讲故事的AI模型。不过，故事生成的体验稍微有点差。它不像是我们在ChatGPT的Web界面里那样一个词一个词地蹦出来，就像一个真人在给你讲故事那样。不过要做到这一点也并不难，因为OpenAI的Completion接口是提供了这样返回结果的模式的，你只需要把代码小小地修改一下就好了。</p><pre><code class=\"language-python\">def write_a_story_by_stream(prompt):\n    response = openai.Completion.create(\n        model=\"curie:ft-bothub-ai:ultraman-2023-04-04-03-03-26\",\n        prompt=prompt,\n        temperature=0.7,\n        max_tokens=2000,\n        stream=True,\n        top_p=1,\n        stop=[\".\"])\n    return response\n\nresponse = write_a_story_by_stream(\"汉,冰冻大海,艰难 -&gt;\\n\")\n\nfor event in response:\n    event_text = event['choices'][0]['text']\n    print(event_text, end = '')\n</code></pre><p>输出结果：</p><pre><code class=\"language-python\">一位叫李英的汉朝时期的英雄人物，穿越到了现代，拥有了一种超能力，可以把自己的身体冰冻到极限，他发现自己可以拥有超越情感的力量，可以把任何人都冻僵，他也发现自己可以控制全局，可以控制时间，可以控制物质，可以控制情景，他发现自己可以控制一切，他变得更加强大。\n李英发现，地球正面临着一个叫做怪兽的强大敌人的威胁，他决定去帮助奥特曼一起打败怪兽。于是，他和奥特曼一起开始了一系列的战斗，他们一起抵抗着怪兽的攻击，最终，他们成功地消灭了怪兽，拯救了地球。\n李英受到了所有人的赞赏，他也成为了一个英雄，他的事迹被传颂了几百年，他的故事也被记录在历史书中，他也成为了一个永恒的传奇。\n</code></pre><p>我们在调用Completion接口的时候，启用了stream=True这个参数。然后对于返回结果，我们不再是直接拿到整个response然后打印出来。而是拿到一个可以通过迭代器访问的一系列events，每一个event都包含了一部分新生成的文本。你试着运行一下这段代码，就能体验到AI把一个个词吐给你，好像真的在实时讲故事一样的感觉了。</p><h2>小结</h2><p>好了，今天的课程到这里也就结束了。这一讲里，我们一起学习了OpenAI大语言模型里的最后两个功能。</p><p>第一个是模型微调，模型微调给我们提供了一个非常实用的能力，<strong>我们可以利用自己的数据，在OpenAI的基础模型上，调整模型参数生成一个新模型</strong>。这样我们就能够根据自己专有的垂直领域的数据，来生产一个专属于我们自己的模型。而且，我们可以根据新收集到的数据，不断在这个模型上继续微调迭代。不过，微调后的模型使用成本比较高，你需要自己核算一下，究竟是微调模型ROI比较高，还是使用前面的外部知识库的方式更划算一些。</p><p>在模型微调之外，我们还了解了OpenAI接口上的一个小功能，也就是<strong>流式地数据生成</strong>。通过开启流式地文本生成，我们可以交付给用户更好的交互体验。特别是在使用比较慢的模型，比如GPT-4，或者生成的文本很长的时候，效果特别明显。用户不需要等上几十秒才能看到结果。</p><p>那到这里，整个课程的大语言模型部分我们也就介绍完了。从最基本的两个API，Completion和Embedding开始，我为你介绍了各种各样的应用场景和使用方法。可以看到，现在的大语言模型几乎是“万能”的。下可以拿来做机器学习的输入数据，上可以直接让它自己决定调用什么API，怎么解决用户的问题。相信看到这里的你，已经掌握如何使用大语言模型了，接下来就要多想想在你的实际工作里如何把它用起来了。</p><h2>思考题</h2><p>这是大语言模型部分的最后一讲，所以我就多给你留一些练习题。</p><ol>\n<li>在这一讲生成数据的时候，我们一条条去生成故事特别慢，而且每个组合的故事都要生成三条，特别消耗Token。你想想这部分的代码，如何根据之前学到的内容优化一下呢？</li>\n<li>你能不能尝试通过流式处理，做一个讲故事的小应用？并且在界面上，用户能够看到故事真的是一个词儿一个词儿地蹦出来的。</li>\n<li>OpenAI的模型微调，其实还有很多更丰富的用法，比如可以拿来做分类，或者命名实体的提取。你可以去官网的 <a href=\"https://platform.openai.com/docs/guides/fine-tuning/specific-guidelines\">Specific Guidelines</a> 部分看一看，来试着微调一个模型，根据电商商品页的属性信息来写商品的详情描述。</li>\n</ol><p>欢迎你把你实现这个功能的方法，以及最后的效果体验分享到评论区，也欢迎你把这一讲分享给感兴趣的朋友，我们下一讲再见。</p><h2>推荐阅读</h2><p>OpenAI在自己的<a href=\"https://platform.openai.com/docs/guides/fine-tuning/weights-biases\">官方文档</a>里，推荐了通过 Weight & Bias 这个公司的产品，来追踪微调后的模型的实验、模型与数据集。Weight & Bias 也在自己的<a href=\"https://docs.wandb.ai/guides/integrations/openai?utm_source=wandb_docs&utm_medium=code&utm_campaign=OpenAI+API\">文档</a>里，提供了一个对WIT数据集进行模型微调的 <a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/openai/Fine_tune_GPT_3_with_Weights_%26_Biases.ipynb#scrollTo=Qnxnp5uZZQOi\">Notebook</a>，你有兴趣的话也可以去看一下。</p>","neighbors":{"left":{"article_title":"17 ｜ 让AI做决策，LangChain里的“中介”和“特工”","id":648461},"right":{"article_title":"19｜Whisper+ChatGPT：请AI代你听播客","id":649832}},"comments":[{"had_liked":false,"id":372888,"user_name":"金","can_delete":false,"product_type":"c1","uid":1559128,"ip_address":"广东","ucode":"48D0B5CB8E5F9E","user_header":"https://static001.geekbang.org/account/avatar/00/17/ca/58/6fe1854c.jpg","comment_is_top":false,"comment_ctime":1681770674,"is_pvip":false,"replies":[{"id":136250,"content":"这一讲的微调后的模型还是在OpenAI的云端的。基于开源模型自己用GPU微调，才能不使用openai。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1681793602,"ip_address":"上海","comment_id":372888,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"只要能加载微调后的模型，是不是就可以不用openai了？","like_count":6,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":614449,"discussion_content":"这一讲的微调后的模型还是在OpenAI的云端的。基于开源模型自己用GPU微调，才能不使用openai。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1681793602,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1186273,"avatar":"https://static001.geekbang.org/account/avatar/00/12/19/e1/a7fbc963.jpg","nickname":"Warren","note":"","ucode":"7518ED2E07AAF7","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":614406,"discussion_content":"gpt-3那四个模型可以微调的模型微调完之后，也只能通过openapi的接口来访问吧","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1681783795,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":373076,"user_name":"weiwei","can_delete":false,"product_type":"c1","uid":2429591,"ip_address":"浙江","ucode":"8AF2A0BD93010C","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJ5sXrTGCq7nlvg8bBzjWtgFU0bXnSiangWBF6Uss3lfnyHeEaplKDBaWWZQNMvhQVxLXyrEEw7rNw/132","comment_is_top":false,"comment_ctime":1681989162,"is_pvip":false,"replies":[{"id":136492,"content":"这个有专门的策略和算法啊，可以看看 anomaly detector 类型的策略和算法。\n\n可以看看kaggle比赛里面大家的解决方案找找思路？ https:&#47;&#47;www.kaggle.com&#47;ealaxi&#47;paysim1","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1683087300,"ip_address":"上海","comment_id":373076,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"徐老师，我们AI部门主要做 “异常数据检测”业务。就是离线把金融的异常数据捕获出来。\n之前这块是用规则引擎+人工审核来做的，人力成本挺大。\n\n这块业务，理论上能用fine tunning模型来做吗？","like_count":2,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":616729,"discussion_content":"这个有专门的策略和算法啊，可以看看 anomaly detector 类型的策略和算法。\n\n可以看看kaggle比赛里面大家的解决方案找找思路？ https://www.kaggle.com/ealaxi/paysim1","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683087300,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":372905,"user_name":"Oli张帆","can_delete":false,"product_type":"c1","uid":1338098,"ip_address":"北京","ucode":"6E60A370C3C14A","user_header":"https://static001.geekbang.org/account/avatar/00/14/6a/f2/db90fa96.jpg","comment_is_top":false,"comment_ctime":1681785943,"is_pvip":false,"replies":[{"id":136468,"content":"我个人主观的感觉是，更适合垂直领域的应用。比如你有大量的法律类的文书、金融类的文书等等，单独微调一个模型给自己用。\n\n能够承受相对高成本，并且有大量垂直语料的应用看起来比较合适。\n\n只是意图分析，我觉得不太需要微调语言生成模型，自己训练一个分类模型就好了。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1683084724,"ip_address":"上海","comment_id":372905,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"从成本的角度看，微调是不是更适合用来做意图分析的分类任务？我这样想的理由是，因为分类任务相对简单可以用比较便宜的模型来微调，第二，训练好之后，每次调用不必发大量context的提示，这样消耗的token会少很多。请老师指正。","like_count":2,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":616695,"discussion_content":"我个人主观的感觉是，更适合垂直领域的应用。比如你有大量的法律类的文书、金融类的文书等等，单独微调一个模型给自己用。\n\n能够承受相对高成本，并且有大量垂直语料的应用看起来比较合适。\n\n只是意图分析，我觉得不太需要微调语言生成模型，自己训练一个分类模型就好了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683084724,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":374613,"user_name":"朱朱","can_delete":false,"product_type":"c1","uid":1514261,"ip_address":"浙江","ucode":"889FBF262D5DDD","user_header":"https://static001.geekbang.org/account/avatar/00/17/1b/15/75c16cb5.jpg","comment_is_top":false,"comment_ctime":1684230332,"is_pvip":false,"replies":[{"id":136798,"content":"微调后的模型，不删除一直会在云端。但是每个人的模型是隔离的呀，你肯定是调用不了我微调的模型的。你需要自己微调一个才能调用。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1684723077,"ip_address":"新加坡","comment_id":374613,"utype":1}],"discussion_count":3,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"老师，请教下，微调之后的模型在 openai 的云端会存在多久，我直接用您微调后的模型，提示无法找到了","like_count":1,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":618934,"discussion_content":"微调后的模型，不删除一直会在云端。但是每个人的模型是隔离的呀，你肯定是调用不了我微调的模型的。你需要自己微调一个才能调用。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684723077,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"新加坡","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":2,"child_discussions":[{"author":{"id":1046302,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/3XbCueYYVWTiclv8T5tFpwiblOxLphvSZxL4ujMdqVMibZnOiaFK2C5nKRGv407iaAsrI0CDICYVQJtiaITzkjfjbvrQ/132","nickname":"有铭","note":"","ucode":"2C7CB36CA5C04C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":619614,"discussion_content":"那有个问题，我怎么看我自己，是否已经有微调过的模型？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1685344940,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":618934,"ip_address":"湖北","group_id":0},"score":619614,"extra":""},{"author":{"id":1953765,"avatar":"","nickname":"Geek_d54869","note":"","ucode":"CF55462EF65B9E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1046302,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/3XbCueYYVWTiclv8T5tFpwiblOxLphvSZxL4ujMdqVMibZnOiaFK2C5nKRGv407iaAsrI0CDICYVQJtiaITzkjfjbvrQ/132","nickname":"有铭","note":"","ucode":"2C7CB36CA5C04C","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":629317,"discussion_content":"文章有讲：我们可以通过下面的 fine_tunes.list 指令，找出所有我们微调的模型","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1696927559,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":619614,"ip_address":"北京","group_id":0},"score":629317,"extra":""}]}]},{"had_liked":false,"id":374009,"user_name":"蔡雪钧","can_delete":false,"product_type":"c1","uid":1206104,"ip_address":"北京","ucode":"87875F639999F0","user_header":"https://static001.geekbang.org/account/avatar/00/12/67/58/960b71b7.jpg","comment_is_top":false,"comment_ctime":1683484864,"is_pvip":false,"replies":[{"id":136876,"content":"是的，但是也有overfit过拟合导致其他方面能力变弱的风险。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1684754077,"ip_address":"上海","comment_id":374009,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"如果用 A，B，C三个垂直领域的数据做模型微调，那么微调后的模型是同时增强了A，B，C三块的能力么？比如把数理化的题喂给大模型，后面大模型是不是数理化整体都会变强？","like_count":1,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":619065,"discussion_content":"是的，但是也有overfit过拟合导致其他方面能力变弱的风险。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684754077,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":372828,"user_name":"一叶","can_delete":false,"product_type":"c1","uid":3577168,"ip_address":"中国台湾","ucode":"21E5455D0814E5","user_header":"https://static001.geekbang.org/account/avatar/00/36/95/50/01199ae9.jpg","comment_is_top":false,"comment_ctime":1681697656,"is_pvip":false,"replies":[{"id":136260,"content":"Callback一样可以啊。你在前端和后端建立一个Websocket，然后后端拿到Callback之后往前端Push消息就可以了。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1681794514,"ip_address":"上海","comment_id":372828,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"老师,问下,Langchain的流式生成似乎不支持迭代的显示方式,好像是通过callback来实现,但是这样在开发web的时候似乎就没办法做成应用了","like_count":1,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":614463,"discussion_content":"Callback一样可以啊。你在前端和后端建立一个Websocket，然后后端拿到Callback之后往前端Push消息就可以了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1681794514,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":1046259,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/f6/f3/69fdc9c8.jpg","nickname":"zgxx","note":"","ucode":"B6DA1BA1B3708A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":619188,"discussion_content":"流式，tools产生的tokens如何计算","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684851828,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":614463,"ip_address":"浙江","group_id":0},"score":619188,"extra":""}]}]},{"had_liked":false,"id":373016,"user_name":"stg609","can_delete":false,"product_type":"c1","uid":1073025,"ip_address":"浙江","ucode":"FB70A75A891BB8","user_header":"https://static001.geekbang.org/account/avatar/00/10/5f/81/1c614f4a.jpg","comment_is_top":false,"comment_ctime":1681918721,"is_pvip":false,"replies":[{"id":136498,"content":"一遇到就停止生成\n\n你可以试一下，那样的话，预处理过程生成的 stop word 会变","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1683088281,"ip_address":"上海","comment_id":373016,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"stop到底是怎么发挥作用的？一遇到stop的字符就停止生成了？如果我们喂给它的csv数据中就有很多. 会怎么样？","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":616735,"discussion_content":"一遇到就停止生成\n\n你可以试一下，那样的话，预处理过程生成的 stop word 会变","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683088281,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":372887,"user_name":"莱森","can_delete":false,"product_type":"c1","uid":3579284,"ip_address":"四川","ucode":"20635A5F900E24","user_header":"https://static001.geekbang.org/account/avatar/00/36/9d/94/c606d61d.jpg","comment_is_top":false,"comment_ctime":1681758262,"is_pvip":false,"replies":[{"id":136259,"content":"可以参看官方文档关于 Stream Response的支持\n\nhttps:&#47;&#47;python.langchain.com&#47;en&#47;latest&#47;modules&#47;models&#47;chat&#47;examples&#47;streaming.html","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1681794480,"ip_address":"上海","comment_id":372887,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"可以请教一下老师如果用了链式调用，怎么样才能更好地实现流式生成呢？","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":614462,"discussion_content":"可以参看官方文档关于 Stream Response的支持\n\nhttps://python.langchain.com/en/latest/modules/models/chat/examples/streaming.html","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1681794480,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":372865,"user_name":"Warren","can_delete":false,"product_type":"c1","uid":1186273,"ip_address":"广东","ucode":"7518ED2E07AAF7","user_header":"https://static001.geekbang.org/account/avatar/00/12/19/e1/a7fbc963.jpg","comment_is_top":false,"comment_ctime":1681734393,"is_pvip":true,"replies":[{"id":136249,"content":"这是一种方式，还有更多的办法。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1681793574,"ip_address":"上海","comment_id":372865,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"在这一讲生成数据的时候，我们一条条去生成故事特别慢，而且每个组合的故事都要生成三条，特别消耗 Token。你想想这部分的代码，如何根据之前学到的内容优化一下呢？\n是不是可以把completion接口的n设为3，一次返回3个故事，可以减少提交的token？","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":614448,"discussion_content":"这是一种方式，还有更多的办法。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1681793574,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":372826,"user_name":"zhihai.tu","can_delete":false,"product_type":"c1","uid":1045888,"ip_address":"上海","ucode":"61371EA3EF6988","user_header":"https://static001.geekbang.org/account/avatar/00/0f/f5/80/baddf03b.jpg","comment_is_top":false,"comment_ctime":1681696471,"is_pvip":true,"replies":[{"id":136252,"content":"当然可以啊，后面20讲会讲解如何接入TTS","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1681794063,"ip_address":"上海","comment_id":372826,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"能不能联动tts，把故事实时播报出来。","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":614454,"discussion_content":"当然可以啊，后面20讲会讲解如何接入TTS","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1681794063,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":372932,"user_name":"Toni","can_delete":false,"product_type":"c1","uid":3206957,"ip_address":"瑞士","ucode":"E6B2FACCC1E000","user_header":"https://static001.geekbang.org/account/avatar/00/30/ef/2d/757bb0d3.jpg","comment_is_top":false,"comment_ctime":1681820596,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"模型的微调(GPT fine-tuning)本质上就是将 GPT 过于宽泛化的处理调窄到某个特殊的范围，而这个在GPT大环境下的特殊范围需要使用满足一定条件的&#39;数据集&#39;来打造，可能还需要反复打造。\n\n读过并记住了全部牛津大字典，莎翁作品的 GPT，实力摆在那儿了，能聊，上知天文下晓地理，侃功盖世。但使用好 GPT 的超能力并不是一件容易事，尤其是当你并不满足于它的夸夸其谈，那么就微调吧。\n\n微调容易吗? 看怎么说了，用于微调的代码已经是简单到不能再简单了，不会编程照样上手，但要达到一特定目的，就不那么容易了。比如: 让 GPT 用鲁迅的笔法来生成一篇短文来抨击环保中的问题。难在以鲁迅的口吻。\n\n那就微调吧，喂给 GPT 大量鲁迅写的文章，让 GPT 再学习。本来想借老师这课讲故事的例子来试试将故事员变成鲁迅，但短时间内是无法完成了。\n\n既然无法微调，那就试试 GPT 中的 Prompt，提示词的本质就是收窄范围，与 fine-tuning 有异曲同工之妙。用 OpenAI 的 Completion 在 engine=&quot;text-davinci-003&quot; 的驱动下，生成了下面这段文例:\n\n&quot;垃圾分类，一种&#39;新时尚&#39;，连阿贵都在谈论它。每个人似乎都很努力，然而，在许多人的心中，它只不过是一种无聊的行为，他们只是为了显得出色而做。\n\n只有少数真正的尝试改变者，多数人只是在虚情假意下，把它当成一种&#39;潮流&#39;。\n\n追求&#39;时尚&#39;的&#39;环保&#39;是空洞的。与其虚情假意，不如从自身出发，努力去改变。&quot;\n\n还是太平淡，太啰嗦了。如何给出提示词使它更像鲁迅? 但也许鲁迅喜欢: &quot;你们的白话文讲得比我好。&quot;\n\n在无法微调时就尝试一下 Prompt。","like_count":8},{"had_liked":false,"id":378909,"user_name":"xuwei","can_delete":false,"product_type":"c1","uid":1164626,"ip_address":"上海","ucode":"07268C1743839F","user_header":"https://static001.geekbang.org/account/avatar/00/11/c5/52/63008fc7.jpg","comment_is_top":false,"comment_ctime":1690964693,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"openai微调太贵了，使用微调模型也太贵了。散了","like_count":2},{"had_liked":false,"id":372820,"user_name":"ACK","can_delete":false,"product_type":"c1","uid":1922378,"ip_address":"中国香港","ucode":"C5D09B18DEF151","user_header":"https://static001.geekbang.org/account/avatar/00/1d/55/4a/8a841200.jpg","comment_is_top":false,"comment_ctime":1681693696,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"我家孩子喜欢听恐龙大战奥特曼的故事。\n用 GPT-4 来直接生成吧，故事太老套，每次生成的情节很相近。还要人工来润色。","like_count":1,"discussions":[{"author":{"id":1023093,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/9c/75/525e53b1.jpg","nickname":"Hobby","note":"","ucode":"8954830380D44F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":615374,"discussion_content":"可以考虑加入不同儿童作家的风格，那么写出来的作品风格也就各异了。我帮我儿子改作文，就经常要GPT用不同的作家风格改写。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1682234027,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"瑞典","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":386198,"user_name":"SlgGrlGwy","can_delete":false,"product_type":"c1","uid":3193646,"ip_address":"广东","ucode":"D35076047897EC","user_header":"https://static001.geekbang.org/account/avatar/00/30/bb/2e/3e0bd0e1.jpg","comment_is_top":false,"comment_ctime":1704298598,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"Error: Invalid response object from API: &#39;{&quot;message&quot;:&quot;Invalid URL (GET &#47;v1&#47;files&#47;data&#47;prepared_data_prepared.jsonl)&quot;,&quot;type&quot;:&quot;invalid_request_error&quot;,&quot;param&quot;:null,&quot;code&quot;:null}&#39; (HTTP response code was 404) (HTTP status code: 404) 报这个错，怎么解决呢","like_count":0},{"had_liked":false,"id":381943,"user_name":"小理想。","can_delete":false,"product_type":"c1","uid":2238528,"ip_address":"北京","ucode":"EDC35A907570DB","user_header":"https://static001.geekbang.org/account/avatar/00/22/28/40/82d748e6.jpg","comment_is_top":false,"comment_ctime":1696255789,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"老师，为什么我的没有微调出模型，也没有报错，但是查看列表没有创建出模型\nsubprocess.run(&#39;openai tools fine_tunes.prepare_data --file data&#47;prepared_data.csv --quiet&#39;.split())","like_count":0},{"had_liked":false,"id":380001,"user_name":"Geek_0b68a4","can_delete":false,"product_type":"c1","uid":3582958,"ip_address":"四川","ucode":"ACBA7D54DA3CD9","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/nLTf90gG8icMt34D9KgqnLWRo6Fia6EwOd8v8jh1QyHlw8C959TeVeb3S9X9s2KrqK7CDTiblrO1axmFO61pecaLA/132","comment_is_top":false,"comment_ctime":1692801844,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"执行subprocess.run(&#39;openai api fine_tunes.list&#39;.split())后只输出了CompletedProcess(args=[&#39;openai&#39;, &#39;api&#39;, &#39;fine_tunes.list&#39;], returncode=0)  没有JSON，看不到微调模型代码，单独调用了下response = openai.FineTune.list()，输出response，看到training_files节点信息都有的，但是最终的fine_tuned_model字段是null的","like_count":0},{"had_liked":false,"id":379867,"user_name":"远方","can_delete":false,"product_type":"c1","uid":1922583,"ip_address":"上海","ucode":"0E2FCC59EDCAD4","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaELVtQAW8IIDLKcn36XM9noEfKuAKpJQrwruJzXeibDfmibIiawicj5vaoflct0LuTAiaKcmCY3gK9MknEw/132","comment_is_top":false,"comment_ctime":1692628183,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"我微调好的模型提示不存在？怎么回事","like_count":0},{"had_liked":false,"id":379799,"user_name":"Trueno","can_delete":false,"product_type":"c1","uid":2782649,"ip_address":"天津","ucode":"4B7F2D53E2B9E8","user_header":"https://static001.geekbang.org/account/avatar/00/2a/75/b9/6fbd82b2.jpg","comment_is_top":false,"comment_ctime":1692535447,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"这个能和自己的知识库结合吗，如果是更小的领域，那这种方式prompt就要包含很多数据了吧","like_count":0},{"had_liked":false,"id":377413,"user_name":"Geek_3caf06","can_delete":false,"product_type":"c1","uid":3662718,"ip_address":"北京","ucode":"D39902FD6ADDA6","user_header":"","comment_is_top":false,"comment_ctime":1688460791,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"subprocess.run(&#39;openai api fine_tunes.create --training_file data&#47;prepared_data_prepared.jsonl --model curie --suffix &quot;ultraman&quot;&#39;.split())\n这一步微调运行要多久，我的跑了6个多小时了还没跑完，是不哪里不正常？","like_count":0,"discussions":[{"author":{"id":1266751,"avatar":"https://static001.geekbang.org/account/avatar/00/13/54/3f/e9529259.jpg","nickname":"rocky","note":"","ucode":"41429C8BBF02CC","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":624189,"discussion_content":"跑完了吗？我也一直停在那","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1690282931,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"重庆","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":377013,"user_name":"呼呼","can_delete":false,"product_type":"c1","uid":1038798,"ip_address":"四川","ucode":"5D7B57C05B5D8C","user_header":"https://static001.geekbang.org/account/avatar/00/0f/d9/ce/4528cb4b.jpg","comment_is_top":false,"comment_ctime":1687839390,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"后面的这几讲都是针对openai的chatgpt了，如果使用其它如chatglm该怎么做呢？","like_count":0},{"had_liked":false,"id":375986,"user_name":"Geek_75e474","can_delete":false,"product_type":"c1","uid":3617372,"ip_address":"广东","ucode":"13FBB01641A807","user_header":"","comment_is_top":false,"comment_ctime":1686208159,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100541001,"comment_content":"老师说的ultraman_stories.csv在哪里可以获取","like_count":0},{"had_liked":false,"id":372863,"user_name":"树静风止","can_delete":false,"product_type":"c1","uid":1929509,"ip_address":"北京","ucode":"66089F1ECE811E","user_header":"https://static001.geekbang.org/account/avatar/00/1d/71/25/e9bad0b3.jpg","comment_is_top":false,"comment_ctime":1681733950,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100541001,"comment_content":"面向模型编程","like_count":0}]}