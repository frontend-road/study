{"id":264164,"title":"28 | 拍拍贷系统拆分项目案例","content":"<p><strong>课件和Demo地址</strong><br>\n<a href=\"https://gitee.com/geektime-geekbang/geektime-distributed\">https://gitee.com/geektime-geekbang/geektime-distributed</a></p>","comments":[{"had_liked":false,"id":236777,"user_name":"飞翔","can_delete":false,"product_type":"c3","uid":1068571,"ip_address":"","ucode":"65AF6AF292DAD6","user_header":"https://static001.geekbang.org/account/avatar/00/10/4e/1b/f4b786b9.jpg","comment_is_top":false,"comment_ctime":1595546251,"is_pvip":false,"replies":[{"id":87612,"content":"假设A是用户表，B是订单表，那么传统数据库做法，C用户订单表=A join B。\n\n如果采用数据分发+实时聚合方法，可以先建一张C表和一个实时聚合服务D，每次B表有数据变化(添加&#47;更新或者删除)，通过事务性发件箱或者CDC机制，将B表的变化发送给D，D可以根据C和A+B的变更，直接计算出并更新C。后面需要查找用户订单的时候，可以直接查C，不需要再Join。\n\n在拍拍贷系统拆分场景中，主要是为了避免数据迁移过程中的跨库join，所以把涉及迁移的相关数据分发一份给依赖的服务，这样依赖的服务可以在本地DB做join(当然也可以用实时聚合技术消除本地join)，这样对涉及迁移的数据就不是强依赖了，降低迁移的复杂度。","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1595691967,"ip_address":"","comment_id":236777,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100053601,"comment_content":"老师数据分发是怎么去join的？","like_count":5,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":502202,"discussion_content":"假设A是用户表，B是订单表，那么传统数据库做法，C用户订单表=A join B。\n\n如果采用数据分发+实时聚合方法，可以先建一张C表和一个实时聚合服务D，每次B表有数据变化(添加/更新或者删除)，通过事务性发件箱或者CDC机制，将B表的变化发送给D，D可以根据C和A+B的变更，直接计算出并更新C。后面需要查找用户订单的时候，可以直接查C，不需要再Join。\n\n在拍拍贷系统拆分场景中，主要是为了避免数据迁移过程中的跨库join，所以把涉及迁移的相关数据分发一份给依赖的服务，这样依赖的服务可以在本地DB做join(当然也可以用实时聚合技术消除本地join)，这样对涉及迁移的数据就不是强依赖了，降低迁移的复杂度。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1595691967,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":254716,"user_name":"what if","can_delete":false,"product_type":"c3","uid":1353380,"ip_address":"","ucode":"A47E207894810B","user_header":"https://static001.geekbang.org/account/avatar/00/14/a6/a4/902eb4db.jpg","comment_is_top":false,"comment_ctime":1603173112,"is_pvip":false,"replies":[{"id":93109,"content":"理论上应该按照业务领域或者团队边界进行拆分。实际拆分的时候，没有所谓比较好的拆分手段，很多时候都是见招拆招+简单粗暴+计划执行最能解决问题。","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1603378047,"ip_address":"","comment_id":254716,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100053601,"comment_content":"单体系统在做拆分时，可以有很多种不同的子系统定义和划分放弃，每种当时可能采取的分类聚类的范畴是不一样的，但是肯定会有一些是比较好的拆分，有一些是比较差的查分，老师有没有关于拆分的指导思想或者方法论，能够让我们获得相对好一些的拆分，比如从技术侧，从业务侧，从功能，从职能。","like_count":2,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":507500,"discussion_content":"理论上应该按照业务领域或者团队边界进行拆分。实际拆分的时候，没有所谓比较好的拆分手段，很多时候都是见招拆招+简单粗暴+计划执行最能解决问题。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1603378047,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":254711,"user_name":"what if","can_delete":false,"product_type":"c3","uid":1353380,"ip_address":"","ucode":"A47E207894810B","user_header":"https://static001.geekbang.org/account/avatar/00/14/a6/a4/902eb4db.jpg","comment_is_top":false,"comment_ctime":1603172784,"is_pvip":false,"replies":[{"id":93108,"content":"采用高性能消息队列+流计算，例如kafka-stream，同时设计要支持和接收最终一致性。另外做好性能监控告警+优化。","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1603377851,"ip_address":"","comment_id":254711,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100053601,"comment_content":"还有数据分发一般实时性比较差，对于实时性要求高的子系统应该怎么办","like_count":2,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":507496,"discussion_content":"采用高性能消息队列+流计算，例如kafka-stream，同时设计要支持和接收最终一致性。另外做好性能监控告警+优化。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1603377851,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":254710,"user_name":"what if","can_delete":false,"product_type":"c3","uid":1353380,"ip_address":"","ucode":"A47E207894810B","user_header":"https://static001.geekbang.org/account/avatar/00/14/a6/a4/902eb4db.jpg","comment_is_top":false,"comment_ctime":1603172685,"is_pvip":false,"replies":[{"id":93106,"content":"我们当时的实现是采用job定期比对，job定期跑(例如30秒跑一次)，先从源数据库获取增量时间范围内的数据，然后再去目标数据库获取增量数据，然后做两边数据的比对，比对有误则发出告警。这个job是基于xxl-job实现，xxl-job采用高可用部署，也有job监控日志和告警。所以健壮主要靠监控和告警。","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1603377732,"ip_address":"","comment_id":254710,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100053601,"comment_content":"老师，你说双写分布式事物一致性是由后台团队写程序实现的，我想知道这部分一致性检验的原理和非一致性数据的修复逻辑是怎样的，这部分一定程度上决定了双写是否能够保证一致性，应该是非常关键的对于业务系统，怎么保证这部分功能的健壮可靠","like_count":2,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":507495,"discussion_content":"我们当时的实现是采用job定期比对，job定期跑(例如30秒跑一次)，先从源数据库获取增量时间范围内的数据，然后再去目标数据库获取增量数据，然后做两边数据的比对，比对有误则发出告警。这个job是基于xxl-job实现，xxl-job采用高可用部署，也有job监控日志和告警。所以健壮主要靠监控和告警。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1603377732,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1353380,"avatar":"https://static001.geekbang.org/account/avatar/00/14/a6/a4/902eb4db.jpg","nickname":"what if","note":"","ucode":"A47E207894810B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":316592,"discussion_content":"感谢老师🌹","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1603429053,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":292641,"user_name":"Akira","can_delete":false,"product_type":"c3","uid":1066102,"ip_address":"","ucode":"A0BFD54A95012D","user_header":"https://static001.geekbang.org/account/avatar/00/10/44/76/a86cfd2a.jpg","comment_is_top":false,"comment_ctime":1620909449,"is_pvip":false,"replies":[{"id":106092,"content":"拆分服务的时候，尽量避免出现分布式事务的情况，如果两个服务涉及分布式事务，那么在拆的时候尽量合并作为一个服务一起拆出来，涉及分布式事务的操作也封装在一个接口中。\n\n只有在不得已情况下，才考虑引入分布式事务解决方案。\n","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1621178483,"ip_address":"","comment_id":292641,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100053601,"comment_content":"老师，拆分步骤一，拆分了服务，但是还没有拆分出数据库。其他应用从操作DB改成操作拆分出来的服务。这一阶段马上就会面临分布式事务问题。一般是先引入分布式解决方案后再进行拆分吗？","like_count":1,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":519901,"discussion_content":"拆分服务的时候，尽量避免出现分布式事务的情况，如果两个服务涉及分布式事务，那么在拆的时候尽量合并作为一个服务一起拆出来，涉及分布式事务的操作也封装在一个接口中。\n\n只有在不得已情况下，才考虑引入分布式事务解决方案。\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1621178483,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":262148,"user_name":"丁小明","can_delete":false,"product_type":"c3","uid":1207622,"ip_address":"","ucode":"CC23857B8D75D5","user_header":"https://static001.geekbang.org/account/avatar/00/12/6d/46/e16291f8.jpg","comment_is_top":false,"comment_ctime":1605622837,"is_pvip":false,"replies":[{"id":95197,"content":"阿里的rocketmq支持你说的这种mq带confirm的机制，业界实践反馈也可以保证双写一致性，当然mq本身的设计和实现会比较复杂。","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1605713738,"ip_address":"","comment_id":262148,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100053601,"comment_content":"数据双写采用mq的方式，如果mq有confirm机制，配合本地事物，是不是也能保证双写一致性呢？","like_count":1,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509705,"discussion_content":"阿里的rocketmq支持你说的这种mq带confirm的机制，业界实践反馈也可以保证双写一致性，当然mq本身的设计和实现会比较复杂。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605713738,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":3004587,"avatar":"","nickname":"Geek_31fd0d","note":"","ucode":"DDF0D9A4743FB9","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":572093,"discussion_content":"如果网络抖动，本地写mq的结果是否成功？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1652599357,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":509705,"ip_address":"","group_id":0},"score":572093,"extra":""}]}]},{"had_liked":false,"id":241345,"user_name":"叮叮董董","can_delete":false,"product_type":"c3","uid":1956208,"ip_address":"","ucode":"CF253F429760ED","user_header":"https://static001.geekbang.org/account/avatar/00/1d/d9/70/8c2e196d.jpg","comment_is_top":false,"comment_ctime":1597274581,"is_pvip":false,"replies":[{"id":89248,"content":"这个具体要看业务系统的情况，如果业务系统需要连多个DB，那么就需要支持多数据源。\n\n不管需不需要多数据源，揭耦拆分的一般步骤都是类似的。","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1597417570,"ip_address":"","comment_id":241345,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100053601,"comment_content":"1，2，3阶段需要系统支持多数据源吗","like_count":1,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":503718,"discussion_content":"这个具体要看业务系统的情况，如果业务系统需要连多个DB，那么就需要支持多数据源。\n\n不管需不需要多数据源，揭耦拆分的一般步骤都是类似的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1597417570,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":298814,"user_name":"独孤九剑","can_delete":false,"product_type":"c3","uid":2230909,"ip_address":"","ucode":"6C1253E2B8C1D4","user_header":"https://static001.geekbang.org/account/avatar/00/22/0a/7d/ac715471.jpg","comment_is_top":false,"comment_ctime":1624332855,"is_pvip":false,"replies":[{"id":108681,"content":"是的，数据同步分发（包括CDC）是重要的迁移手段。","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1624810943,"ip_address":"","comment_id":298814,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100053601,"comment_content":"数据库迁移和数据分发可以用阿里云的DTS服务","like_count":0,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":522252,"discussion_content":"是的，数据同步分发（包括CDC）是重要的迁移手段。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1624810943,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":292721,"user_name":"Akira","can_delete":false,"product_type":"c3","uid":1066102,"ip_address":"","ucode":"A0BFD54A95012D","user_header":"https://static001.geekbang.org/account/avatar/00/10/44/76/a86cfd2a.jpg","comment_is_top":false,"comment_ctime":1620951749,"is_pvip":false,"replies":[{"id":106093,"content":"这个新老DB如果要完全不停机的实时同步是比较难的，我们当时是可以停机的，在凌晨业务量小时公告停机，等没有了流量，DBA将老数据一把导入新DB，然后停机结束开始接入流量，这时候两边是双写，数据可以保证一致。\n","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1621180077,"ip_address":"","comment_id":292721,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100053601,"comment_content":"老师，迁移技术2的1\n老DB对新DB的补偿一般怎么做？\n老DB拷贝一份数据到新DB，只要老DB不停机，新DB总会有时间差导致数据不完全相同。\n","like_count":0,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":519934,"discussion_content":"这个新老DB如果要完全不停机的实时同步是比较难的，我们当时是可以停机的，在凌晨业务量小时公告停机，等没有了流量，DBA将老数据一把导入新DB，然后停机结束开始接入流量，这时候两边是双写，数据可以保证一致。\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1621180077,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":241881,"user_name":"Geek_zbvt62","can_delete":false,"product_type":"c3","uid":1046714,"ip_address":"","ucode":"81EA27ADD9EC1A","user_header":"https://static001.geekbang.org/account/avatar/00/0f/f8/ba/d28174a9.jpg","comment_is_top":false,"comment_ctime":1597485790,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100053601,"comment_content":"数据迁移的4个步骤太有价值了，很少见到其他文章中有提到，重点是每一步都可回滚到上一步","like_count":1}]}