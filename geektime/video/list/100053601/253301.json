{"id":253301,"title":"13 | PMQ 2.0的设计解析（下）","content":"<p><strong>课件和Demo地址</strong><br>\n<a href=\"https://gitee.com/geektime-geekbang/geektime-distributed\">https://gitee.com/geektime-geekbang/geektime-distributed</a></p>","comments":[{"had_liked":false,"id":232004,"user_name":"Johar","can_delete":false,"product_type":"c3","uid":1101969,"ip_address":"","ucode":"834136A6F64CDC","user_header":"https://static001.geekbang.org/account/avatar/00/10/d0/91/89123507.jpg","comment_is_top":false,"comment_ctime":1593829597,"is_pvip":false,"replies":[{"id":85642,"content":"1. 一组consumer可以组成一个消费者组，共同消费一个topic中的多个分区，具体每个消费者消费哪一个或者几个分区，这个由动态重平衡算法来决定，一般是尽可能平均分配。\n2. 对于同一个消费者组和同一个主题，每一个消费者可能会消费0个、1个或者多个分区，但是一个分区最多只能被一个消费者消费，不能被两个以上的消费者同时消费，会乱。但是对于不同消费者组的情况，同一个分区，可能被不同消费者组中的多个消费者同时消费，这时消费指针不同，不会乱。\n3. PMQ定期删除MySQL中老数据，采用的是物理删除。关于pg的问题，我没有直接碰到过，建议可以看这个stackexchange上的帖子：\nhttps:&#47;&#47;dba.stackexchange.com&#47;questions&#47;123627&#47;postgresql-data-files-have-size-more-than-data-itself","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1593871693,"ip_address":"","comment_id":232004,"utype":1}],"discussion_count":3,"race_medal":0,"score":2,"product_id":100053601,"comment_content":"波波老师，请教一下，1.PMQ怎么解决一组consumer消费一个topic的所有分区？\n2.另外一个分区被多个consumer消费的时候，有先有后，db中的数据怎么进行处理？\n3.db进行数据存储实际也是文件存储，删除已经消费的数据时，mysql是否会删除文件中的数据？还是将数据置为不可见？工作环境使用pg数据库，出现了表中的数据量不大，但是表文件达到十几个G，造成数据库操作很慢，这种场景有没有什么好处理方法，自动处理一下？","like_count":3,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":500470,"discussion_content":"1. 一组consumer可以组成一个消费者组，共同消费一个topic中的多个分区，具体每个消费者消费哪一个或者几个分区，这个由动态重平衡算法来决定，一般是尽可能平均分配。\n2. 对于同一个消费者组和同一个主题，每一个消费者可能会消费0个、1个或者多个分区，但是一个分区最多只能被一个消费者消费，不能被两个以上的消费者同时消费，会乱。但是对于不同消费者组的情况，同一个分区，可能被不同消费者组中的多个消费者同时消费，这时消费指针不同，不会乱。\n3. PMQ定期删除MySQL中老数据，采用的是物理删除。关于pg的问题，我没有直接碰到过，建议可以看这个stackexchange上的帖子：\nhttps://dba.stackexchange.com/questions/123627/postgresql-data-files-have-size-more-than-data-itself","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1593871693,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1101969,"avatar":"https://static001.geekbang.org/account/avatar/00/10/d0/91/89123507.jpg","nickname":"Johar","note":"","ucode":"834136A6F64CDC","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":288851,"discussion_content":"昨天查了一下，mysql可以通过OPTIMIZE TABLE 命，pg可以通过vaccuum命令","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1593911719,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":2259490,"avatar":"https://static001.geekbang.org/account/avatar/00/22/7a/22/45307c91.jpg","nickname":"墨白","note":"","ucode":"D884B9C0056C80","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1101969,"avatar":"https://static001.geekbang.org/account/avatar/00/10/d0/91/89123507.jpg","nickname":"Johar","note":"","ucode":"834136A6F64CDC","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":588151,"discussion_content":"这样就避免了7天前数据，物理删除以后，碎片空间不释放的情况，但是OPTIMIZE TABLE应该会锁表，对查询和插入都是个不可忽视的问题，相当于间接影响了消息队列的生产和消费","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1663576046,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":288851,"ip_address":"北京","group_id":0},"score":588151,"extra":""}]}]},{"had_liked":false,"id":230315,"user_name":"小祺","can_delete":false,"product_type":"c3","uid":1193548,"ip_address":"","ucode":"2819BCA9E71C9F","user_header":"https://static001.geekbang.org/account/avatar/00/12/36/4c/46c43cce.jpg","comment_is_top":false,"comment_ctime":1593346200,"is_pvip":false,"replies":[{"id":85371,"content":"1. 没有特别的事务控制，就是Auto Commit。\n2. 因为只有自增id一个索引(mysql对自增id索引有优化)，插入很快，即使到千万级，也未见明显性能下降。\n3. 是的，后台定期任务删除超过7天的老消息，通过自增id去两分找时间点，再通过id范围删除也很快。\n4. 是的，因为没有索引，通过biz_id的查询，仅限大致知道时间范围后，去做迭代遍历。实践中，可以考虑将消息写一份到ES建立索引，携程就是这么干的，效果还不错。因为是基于MySQL存储消息，可以考虑阿里Canal从MySQL的从节点去消费消息，再发送到ES建索引，这样对Master没有性能影响。\n5. PPD的数据库是用SSD，消息的存储性能对业务太关键，这点钱是值得花的，不必因小失大。\n","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1593618688,"ip_address":"","comment_id":230315,"utype":1}],"discussion_count":3,"race_medal":0,"score":2,"product_id":100053601,"comment_content":"1. 消息入库时有事务控制吗，特别是多生产者+批量写入的时候，如果有事务控制那性能为什么跟kafka接近？\n2. 表内数据量越来越多达到千万级甚至亿级的时候，写入的速度不会降低吗？\n3. 数据过期怎么做，难道要在亿级的表中做delete from xx  where date_time &lt; 7天前吗？\n4. 千万以上的表在查找消息的时候，搜索biz_id还没有索引无法保证查询性能吧？\n5. 物理数据库使用的是机械硬盘还是SSD，SSD的话作为消息队列来用成本有点高吧","like_count":3,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":499835,"discussion_content":"1. 没有特别的事务控制，就是Auto Commit。\n2. 因为只有自增id一个索引(mysql对自增id索引有优化)，插入很快，即使到千万级，也未见明显性能下降。\n3. 是的，后台定期任务删除超过7天的老消息，通过自增id去两分找时间点，再通过id范围删除也很快。\n4. 是的，因为没有索引，通过biz_id的查询，仅限大致知道时间范围后，去做迭代遍历。实践中，可以考虑将消息写一份到ES建立索引，携程就是这么干的，效果还不错。因为是基于MySQL存储消息，可以考虑阿里Canal从MySQL的从节点去消费消息，再发送到ES建索引，这样对Master没有性能影响。\n5. PPD的数据库是用SSD，消息的存储性能对业务太关键，这点钱是值得花的，不必因小失大。\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1593618688,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1961967,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/ef/ef/423c355b.jpg","nickname":"卡卡","note":"","ucode":"C49F9A580AC1F5","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":345917,"discussion_content":"喜欢这样的提问和回答，问题清晰明了，回答干脆利落。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1611814274,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1046552,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/f8/18/3e5e7db3.jpg","nickname":"Lorgine","note":"","ucode":"DB64E85327A252","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":287152,"discussion_content":"规划的时候一张表，差不多保存700百万的数据。删除的时候不是按照时间，是根据时间然后按照id  1000条的删除。消息入库没有事务。消息查询可以查丛库。这个查询是很低频的操作，对性能要求不高","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1593391731,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":235472,"user_name":"what if","can_delete":false,"product_type":"c3","uid":1353380,"ip_address":"","ucode":"A47E207894810B","user_header":"https://static001.geekbang.org/account/avatar/00/14/a6/a4/902eb4db.jpg","comment_is_top":false,"comment_ctime":1595050419,"is_pvip":false,"replies":[{"id":87052,"content":"在PMQ的设计中，一张表设计的容量是700～1000万，七天后删除老消息，实际使用中一般每日消息量都是&lt;=100万的(每日消息过多，可以进一步分区)。\n\n你可以算一下bigint，每天100万，要多少年才能用完，应该是几辈子也用不完的，到那个时候这个系统早已被新技术淘汰。\n\n","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1595175925,"ip_address":"","comment_id":235472,"utype":1}],"discussion_count":3,"race_medal":0,"score":2,"product_id":100053601,"comment_content":"波哥，mysql自增键的数据类型上限你是怎么处理的，考虑到日消息量级。比如int是21亿  bigint 是92000000000000000000+ 是否根据评估在有生之年不会达到id上限？\n","like_count":2,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":501736,"discussion_content":"在PMQ的设计中，一张表设计的容量是700～1000万，七天后删除老消息，实际使用中一般每日消息量都是&amp;lt;=100万的(每日消息过多，可以进一步分区)。\n\n你可以算一下bigint，每天100万，要多少年才能用完，应该是几辈子也用不完的，到那个时候这个系统早已被新技术淘汰。\n\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1595175925,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1046552,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/f8/18/3e5e7db3.jpg","nickname":"Lorgine","note":"","ucode":"DB64E85327A252","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":292207,"discussion_content":"一般一张表一天按100万记录存储，要用完bigint一张表要上万年","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1595140826,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1353380,"avatar":"https://static001.geekbang.org/account/avatar/00/14/a6/a4/902eb4db.jpg","nickname":"what if","note":"","ucode":"A47E207894810B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":312293,"discussion_content":"感谢老师解答","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1602654470,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":231539,"user_name":"罗裕666","can_delete":false,"product_type":"c3","uid":2051969,"ip_address":"","ucode":"7973EF6A209E43","user_header":"https://static001.geekbang.org/account/avatar/00/1f/4f/81/c1fa3c5b.jpg","comment_is_top":false,"comment_ctime":1593701202,"is_pvip":false,"replies":[{"id":85639,"content":"lag过大，一般可以通过多增加分区来分摊负载，既然增加分区了，当然可以适当增加消费者组中的消费者。","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1593870522,"ip_address":"","comment_id":231539,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100053601,"comment_content":"波波老师 我有一个疑问\n在我的理解中（rocketmq下），同一个group下，一个消息分区messageQueue只能对应一个消费者实例\n视频中说lag过大可以加入更多的消费者来提升消费的吞吐量，是怎么实现的呢","like_count":2,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":500340,"discussion_content":"lag过大，一般可以通过多增加分区来分摊负载，既然增加分区了，当然可以适当增加消费者组中的消费者。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1593870522,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":230885,"user_name":"大维","can_delete":false,"product_type":"c3","uid":1129620,"ip_address":"","ucode":"5FEAF1F0B48876","user_header":"https://static001.geekbang.org/account/avatar/00/11/3c/94/932231c2.jpg","comment_is_top":false,"comment_ctime":1593513817,"is_pvip":false,"replies":[{"id":85372,"content":"对，采用轮训polling，和Kafka一样。\n\n消息拉取采用一种简单退避策略，从50ms起步，然后以50ms为步长不断往上加，最大到5秒。步长和最大等待都是可以配置。","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1593618890,"ip_address":"","comment_id":230885,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100053601,"comment_content":"消费者在使用线程拉消息，这里拉的策略是不是轮询定时拉？如果是定时拉的话，这个拉取的时间间隔的设定有什么策略吗？","like_count":2,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":500061,"discussion_content":"对，采用轮训polling，和Kafka一样。\n\n消息拉取采用一种简单退避策略，从50ms起步，然后以50ms为步长不断往上加，最大到5秒。步长和最大等待都是可以配置。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1593618890,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":230382,"user_name":"空空如也","can_delete":false,"product_type":"c3","uid":1194238,"ip_address":"","ucode":"342F3A2C8A3C11","user_header":"https://static001.geekbang.org/account/avatar/00/12/38/fe/988bf0d9.jpg","comment_is_top":false,"comment_ctime":1593358349,"is_pvip":false,"replies":[{"id":85289,"content":"1. 在生产端，PMQ主要统计DB写入延迟，这个主要在Broker上埋点统计的。在消费端，PMQ主要统计DB读取延迟，这个主要在Consumer端埋点统计的。\n\n你说的那个方法，可以用来统计消息从生产进入DB到被消费者消费的延迟。这个在实践中我们发现意义并不大，因为只要消息不堆积(生产和消费速度匹配，或者消费速度&gt;生产速度)，基本上都是最多几十个ms的延迟。真正有价值的是最好消息堆积监控，也就是消费速度&lt;生产速度的情况，这个需要告警扩容。\n\n2. 堆积监控一般是后台线程异步去扫描数据库做的，发现异常则发邮件告警。当然可以发数据到Prometheus等监控系统，通过AlertManager或者Grafana等告警。","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1593531226,"ip_address":"","comment_id":230382,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100053601,"comment_content":"波哥，问两个问题\n1.推送消息的数量和DB延迟的数据采集是怎么做的呢？\n比如说DB延迟时间，需要在消息表中记录生产者产生消息时间戳，DB保存生产者消息时间戳，消费者成功提交偏移量时间戳吗？broker批量保存记录同时做聚合再保存到MySQL表中（如按分钟计算avg）还是有什么其他方案？\n2.DB延迟偏高和消息堆积告警怎么做的？\n是有一个监控程序轮序查询数据库还是通过grafana的alert功能做阈值的告警，触发邮件和短信通知\n谢谢老师","like_count":2,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":499860,"discussion_content":"1. 在生产端，PMQ主要统计DB写入延迟，这个主要在Broker上埋点统计的。在消费端，PMQ主要统计DB读取延迟，这个主要在Consumer端埋点统计的。\n\n你说的那个方法，可以用来统计消息从生产进入DB到被消费者消费的延迟。这个在实践中我们发现意义并不大，因为只要消息不堆积(生产和消费速度匹配，或者消费速度&amp;gt;生产速度)，基本上都是最多几十个ms的延迟。真正有价值的是最好消息堆积监控，也就是消费速度&amp;lt;生产速度的情况，这个需要告警扩容。\n\n2. 堆积监控一般是后台线程异步去扫描数据库做的，发现异常则发邮件告警。当然可以发数据到Prometheus等监控系统，通过AlertManager或者Grafana等告警。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1593531226,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":229808,"user_name":"何凌","can_delete":false,"product_type":"c3","uid":1139066,"ip_address":"","ucode":"659D0EA089AFA4","user_header":"https://static001.geekbang.org/account/avatar/00/11/61/7a/ec7c1881.jpg","comment_is_top":false,"comment_ctime":1593151993,"is_pvip":false,"replies":[{"id":84920,"content":"严格来讲是这样的。\n\n但是完全强一致的HA成本太高，对于PPD这个量级规模，MySQL主从HA&#47;最终一致是可以接收的。大不了挂了人肉修复一下，毕竟MySQL主挂是小概率事件。总体评估，人肉成本比完全强一致方案要低。","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1593270033,"ip_address":"","comment_id":229808,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100053601,"comment_content":"MySQL主从之间不是strong consistent的，如果没有partition之间的replication还是有丢数据的风险吧","like_count":2,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":499649,"discussion_content":"严格来讲是这样的。\n\n但是完全强一致的HA成本太高，对于PPD这个量级规模，MySQL主从HA/最终一致是可以接收的。大不了挂了人肉修复一下，毕竟MySQL主挂是小概率事件。总体评估，人肉成本比完全强一致方案要低。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1593270033,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":229638,"user_name":"不忘初心","can_delete":false,"product_type":"c3","uid":1117880,"ip_address":"","ucode":"5FE187B3F4EC39","user_header":"https://static001.geekbang.org/account/avatar/00/11/0e/b8/d91adbb3.jpg","comment_is_top":false,"comment_ctime":1593081659,"is_pvip":false,"replies":[{"id":84837,"content":"关于重平衡这块，PMQ 2.0做得是比较简单的，竞争协调就是就是通过元数据库DB记录状态来实现的，Broker都是状态的。\n\n后面有一节会讲PMQ 3.0的重平衡实现，有一个集中式协调器负责协调。\n\n","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1593190230,"ip_address":"","comment_id":229638,"utype":1}],"discussion_count":3,"race_medal":0,"score":2,"product_id":100053601,"comment_content":"多个Broker之间是怎么协调的，这块没讲呢。比如同一个ConsumerGroup的多个Consumer分别连接上了多个Broker，在竞争Partation的时候是怎么实现的。","like_count":2,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":499578,"discussion_content":"关于重平衡这块，PMQ 2.0做得是比较简单的，竞争协调就是就是通过元数据库DB记录状态来实现的，Broker都是状态的。\n\n后面有一节会讲PMQ 3.0的重平衡实现，有一个集中式协调器负责协调。\n\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1593190230,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1282833,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJl6JzQNBk6rFIiafk7SPAJJn1haeMgGiaVMSov0b90ywvcSvlFK5YERM4FhPibUicvlZdhsoucPcqZzA/132","nickname":"田","note":"","ucode":"86B1850CFE6572","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":286506,"discussion_content":"broker是无状态的啊哥，消费者组连上哪个consumer都无所谓，竞争partition是通过数据库表来实现的","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1593187789,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1046552,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/f8/18/3e5e7db3.jpg","nickname":"Lorgine","note":"","ucode":"DB64E85327A252","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":286240,"discussion_content":"在2.0中实际上要提前设置一个消费者组的实例数，有了这个数量就可以用数据库锁的方式进行抢占，先来先得。","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1593093521,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":229610,"user_name":"Jxin","can_delete":false,"product_type":"c3","uid":1251111,"ip_address":"","ucode":"4C03928388C413","user_header":"https://static001.geekbang.org/account/avatar/00/13/17/27/ec30d30a.jpg","comment_is_top":false,"comment_ctime":1593073251,"is_pvip":false,"replies":[{"id":84918,"content":"1. PMQ3.0是支持延迟消息的。基本思路就是添加到期时间字段，然后消费者拉的时候看时间有没有到。\n2. 消息主要按顺序插入和拉取，自增id是唯一主键，如果再加biz key索引，插入就会变慢。这个问题Cassandra&#47;HBase也是一样的，你用了id做主键，再弄其它主键就需要二级索引机制，会变慢。而且引入Cassandra&#47;HBase整个系统又变重了。如果真的需要高级查询，可以利用MySQL主从&#47;阿里Canal机制，按需把消息再发到ES建立索引就好了，携程就是这样玩的。\n3. Broker和存储的分离，Broker无状态可以水平扩展，是最大好处。另外MySQL的HA机制已经有成熟方案。\n4. 谢谢！","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1593269529,"ip_address":"","comment_id":229610,"utype":1}],"discussion_count":7,"race_medal":0,"score":2,"product_id":100053601,"comment_content":"1.后续会有关于任意延迟时间的延迟消息的内容吗？\n2.这里用mysql相对于时序数据库有什么好处吗，毕竟查消息时经常是时间区间的。然后key值索引没有，但key值查找的场景应该都会有的，如何去处理这个矛盾的？让业务方自己根据key值在业务系统定位到大致消息的时间区间再查？想想都有点蛋疼呀。\n3.消息存储用mysql实际上是一种存储分离，我也觉得mq往后应该是这个方向。让专业的人做专业的时。基于组合而不是造轮子。\n4.思路清晰接地气，棒。\n","like_count":1,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":499561,"discussion_content":"1. PMQ3.0是支持延迟消息的。基本思路就是添加到期时间字段，然后消费者拉的时候看时间有没有到。\n2. 消息主要按顺序插入和拉取，自增id是唯一主键，如果再加biz key索引，插入就会变慢。这个问题Cassandra/HBase也是一样的，你用了id做主键，再弄其它主键就需要二级索引机制，会变慢。而且引入Cassandra/HBase整个系统又变重了。如果真的需要高级查询，可以利用MySQL主从/阿里Canal机制，按需把消息再发到ES建立索引就好了，携程就是这样玩的。\n3. Broker和存储的分离，Broker无状态可以水平扩展，是最大好处。另外MySQL的HA机制已经有成熟方案。\n4. 谢谢！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1593269529,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1046552,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/f8/18/3e5e7db3.jpg","nickname":"Lorgine","note":"","ucode":"DB64E85327A252","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":286358,"discussion_content":"查询可以按照业务id查询也可以按照内容查询，多维度","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1593146799,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1046552,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/f8/18/3e5e7db3.jpg","nickname":"Lorgine","note":"","ucode":"DB64E85327A252","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":286237,"discussion_content":"消息存储库速度优先，所以除了主键，不能有其他的索引。消息消费的时候，可以按照id从主键查询。但是日常消息查询的时候，实例上可以从丛库查询。同时日常查询分业务id和内容查询，业务id查询，从从库查询问题不大，如果是内容查询可以限定时间。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1593093431,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":4,"child_discussions":[{"author":{"id":1251111,"avatar":"https://static001.geekbang.org/account/avatar/00/13/17/27/ec30d30a.jpg","nickname":"Jxin","note":"","ucode":"4C03928388C413","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1046552,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/f8/18/3e5e7db3.jpg","nickname":"Lorgine","note":"","ucode":"DB64E85327A252","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":286290,"discussion_content":"建立key值索引不一定要在mysql啊。异步冗余存储即可。存储的方式也没说一定就是从库呀，时序数据不也挺好。\n\n","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1593101470,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":286237,"ip_address":"","group_id":0},"score":286290,"extra":""},{"author":{"id":1046552,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/f8/18/3e5e7db3.jpg","nickname":"Lorgine","note":"","ucode":"DB64E85327A252","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1251111,"avatar":"https://static001.geekbang.org/account/avatar/00/13/17/27/ec30d30a.jpg","nickname":"Jxin","note":"","ucode":"4C03928388C413","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":286357,"discussion_content":"从维护性来说，实际上引入额外的东西增加了存储成本和维护成本。从真实情况看，从丛库查询可以满足需求。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1593146538,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":286290,"ip_address":"","group_id":0},"score":286357,"extra":""},{"author":{"id":1251111,"avatar":"https://static001.geekbang.org/account/avatar/00/13/17/27/ec30d30a.jpg","nickname":"Jxin","note":"","ucode":"4C03928388C413","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1046552,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/f8/18/3e5e7db3.jpg","nickname":"Lorgine","note":"","ucode":"DB64E85327A252","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":286359,"discussion_content":"成本这个东西。擅长的不同自然成本也不同。但终归，成本和体验要找到平衡。见仁见智的事。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1593147020,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":286357,"ip_address":"","group_id":0},"score":286359,"extra":""}]}]},{"had_liked":false,"id":290284,"user_name":"写点啥呢","can_delete":false,"product_type":"c3","uid":1065272,"ip_address":"","ucode":"C19032CF1C41BA","user_header":"https://static001.geekbang.org/account/avatar/00/10/41/38/4f89095b.jpg","comment_is_top":false,"comment_ctime":1619486197,"is_pvip":false,"replies":[{"id":106067,"content":"后台线程异步批量写入的。中间即使由于故障集群重启，消费者可能重复消费(因为之前的消费偏移可能没有及时保存)，所以是at lease once语义","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1621096273,"ip_address":"","comment_id":290284,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100053601,"comment_content":"请问老师，消费者偏移量保存在MySQL中的话，在高吞吐下是如何做的写入优化的呀？特别是消费者很多，吞吐量很大的时候对MySQL写入压力会很大。谢谢老师","like_count":0,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":519159,"discussion_content":"后台线程异步批量写入的。中间即使由于故障集群重启，消费者可能重复消费(因为之前的消费偏移可能没有及时保存)，所以是at lease once语义","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1621096273,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]}]}