{"id":421579,"title":"03 | The Google File System （一）： Master的三个身份","content":"<p>你好，我是徐文浩。从今天开始，我们就正式地来一起解读和学习大数据领域中，一些经典的论文。这节课，我们就从“<a href=\"https://storage.googleapis.com/pub-tools-public-publication-data/pdf/035fc972c796d33122033a0614bc94cff1527999.pdf\">The Google File System</a>”这篇论文开始。</p><p>这篇论文发表在2003年，现在来看，它算是一篇“老”论文了。然而在我第一次看到这篇论文的时候，它可代表着强大而神秘的黑科技。</p><p>在这篇论文发表之前，工业界的分布式系统最多也就是几十台服务器的MPI集群。而这篇GFS的论文一发表，一下子就拿出了一个运作在1000台服务器以上的分布式文件系统。并且这个文件系统，还会面临外部数百个并发访问的客户端，可以称得上是石破天惊。</p><p>当然，在18年后的今天，开源社区里的各种分布式系统，也都远比当初的GFS更加复杂、强大。回顾这篇18年前的论文，GFS可以说是“<strong>技术上辉煌而工程上保守</strong>”。说GFS技术上辉煌，是因为Google通过廉价的PC级别的硬件，搭建出了可以处理整个互联网网页数据的系统。而说GFS工程上保守，则是因为GFS没有“发明”什么特别的黑科技，而是在工程上做了大量的取舍（trade-off）。</p><h2>GFS的设计决策</h2><p>在我看来，GFS定了三个非常重要的设计原则，这三个原则带来了很多和传统的分布式系统研究大相径庭的设计决策。但是这三个原则又带来了大量工程上的实用性，使得GFS的设计思路后续被Hadoop这样的系统快速借鉴并予以实现。</p><!-- [[[read_end]]] --><p>那这三个原则是什么呢？接下来我就给你介绍介绍。</p><p><strong>第一个是以工程上“简单”作为设计原则。</strong></p><p>GFS直接使用了Linux服务上的普通文件作为基础存储层，并且选择了最简单的单Master设计。单Master让GFS的架构变得非常简单，避免了需要管理复杂的一致性问题。不过它也带来了很多限制，比如一旦Master出现故障，整个集群就无法写入数据，而恢复Master则需要运维人员手动操作，所以GFS其实算不上一个高可用的系统。</p><p>但另外一方面，GFS还是采用了Checkpoints、操作日志（Operation Logs）、影子Master（Shadow Master）等一系列的工程手段，来尽可能地保障整个系统的“可恢复（Recoverable）”，以及读层面的“可用性（Availability）”。</p><p>可以说，GFS是恪守“简单”这个原则而设计了第一版本的系统，并且在不破坏这个设计原则的情况下，通过上面一系列独立可插拔的工程策略，来进一步提高系统的可用性。</p><p><strong>第二个是根据硬件特性来进行设计取舍。</strong></p><p>2003年，大家都还在用机械硬盘，随机读写的性能很差，所以在GFS的设计中，重视的是顺序读写的性能，对随机写入的一致性甚至没有任何保障。</p><p>而你要知道，2003年的数据中心，各台机器的网卡带宽只有100MB，网络带宽常常是系统瓶颈。所以GFS在写数据的时候，选择了流水线式的数据传输，而没有选择树形的数据传输方式。更进一步地，GFS专门设计了一个Snapshot的文件复制操作，在文件复制的时候避免了数据在网络上传输。这些设计都是为了减少数据在网络上的传输，避免我们有限的网络带宽成为瓶颈。</p><p><strong>第三个是根据实际应用的特性，放宽了数据一致性（consistency）的选择。</strong></p><p>最后，论文里也提到，GFS是为了在廉价硬件上进行大规模数据处理而设计的。所以GFS的一致性相当宽松。GFS本身对于随机写入的一致性没有任何保障，而是把这个任务交给了客户端。对于追加写入（Append），GFS也只是作出了“至少一次（At Least Once）”这样宽松的保障。</p><p>可以说，GFS是一个基本没有什么一致性保障的文件系统。但即使是这样，通过在客户端库里面加上校验、去重这样的处理机制，GFS在大规模数据处理上已经算是足够好用了。</p><p>OK，那到这里，你应该就大致理解了GFS的设计决策。不过你也要清楚的是，这三个设计原则可远远没有以上我介绍的这么简单。所以接下来，我会通过三节课的时间，来带你分别剖析这三个重要的设计选择。</p><p>那么今天这节课，我们就先一起来看看第一个选择，也就是“简单”这个设计原则。</p><p><img src=\"https://static001.geekbang.org/resource/image/15/15/158149b378d1d5b383078b3ee3440915.jpg?wh=1920x947\" alt=\"图片\"></p><p>在这个设计原则下，我们会看到GFS是一个非常简单的单Master架构，但是这个Master其实有三种不同的身份，分别是：</p><ul>\n<li>相对于存储数据的Chunkserver，Master是一个目录服务；</li>\n<li>相对于为了灾难恢复的Backup Master，它是一个同步复制的主从架构下的主节点；</li>\n<li>相对于为了保障读数据的可用性而设立的Shadow Master，它是一个异步复制的主从架构下的主节点。</li>\n</ul><p>并且，这三种身份是依靠不同的独立模块完成的，互相之间并不干扰。所以，学完这一讲，你对常见的主从架构（Master-Slave）下的Master的职责，以及数据复制的模式也会有一个清晰的认识。</p><h2>Master的第一个身份：一个目录服务</h2><p>作为一个分布式文件系统，一个有几千台服务器跑在线上的真实系统，GFS的设计可以说是非常简单。</p><p>我给你举个例子。要把一个文件存在GFS上，其实和在Linux操作系统上很像，GFS一样会通过“命名空间+文件名”来定义一个文件。比如，我们可以把这一讲的录音文件存储在/data/geektime/bigdata/gfs01这样一个路径下。这样，所有GFS的客户端，都可以通过这个/data/geektime/bigdata命名空间加上gfs01这个文件名，去读或者写这个文件。</p><p><strong>那么，当我们的客户端，实际上要去读或者写这个gfs01文件的时候，这个文件是实际存放在哪个物理服务器上呢？以及我们的客户端，具体是怎么读到这个文件的呢？</strong></p><p>首先你要知道，在整个GFS中，有两种服务器，一种是<strong>master</strong>，也就是整个GFS中有且仅有一个的主控节点；第二种是<strong>chunkserver</strong>，也就是实际存储数据的节点。</p><p>而既然GFS是叫做分布式文件系统，那么这个文件，其实就可以不存储在同一个服务器上。</p><p>因此，在GFS里面，会把每一个文件按照64MB一块的大小，切分成一个个chunk。每个chunk都会有一个在GFS上的唯一的handle，这个handle其实就是一个编号，能够唯一标识出具体的chunk。然后每一个chunk，都会以一个文件的形式，放在chunkserver上。</p><p>而chunkserver，其实就是一台普通的Linux服务器，上面跑了一个用户态的GFS的chunkserver程序。这个程序，会负责和master以及GFS的客户端进行RPC通信，完成实际的数据读写操作。</p><p>当然，为了确保数据不会因为某一个chunkserver坏了就丢失了，每个chunk都会存上整整三份副本（replica）。其中一份是主数据（primary），两份是副数据（secondary），当三份数据出现不一致的时候，就以主数据为准。有了三个副本，不仅可以防止因为各种原因丢数据，还可以在有很多并发读取的时候，分摊系统读取的压力。</p><p><img src=\"https://static001.geekbang.org/resource/image/4c/2e/4ccb89f66276af2ce19c1fc83fdb432e.jpg?wh=2000x1504\" alt=\"\" title=\"文件会拆分成chunk放在不同的chunkserver上\"></p><p>如此一来，文件就被拆分成了一个个的chunk存在了chunkserver上。那么你可能还要问：<strong>GFS的客户端，怎么知道该去哪个chunkserver找自己要的文件呢？</strong></p><p>答案当然是问master啦。</p><p>首先，master里面会存放三种主要的元数据（metadata）：</p><ol>\n<li>文件和chunk的命名空间信息，也就是类似前面/data/geektime/bigdata/gfs01这样的路径和文件名；</li>\n<li>这些文件被拆分成了哪几个chunk，也就是这个全路径文件名到多个chunk handle的映射关系；</li>\n<li>这些chunk实际被存储在了哪些chunkserver上，也就是chunk handle到chunkserver的映射关系。</li>\n</ol><p><img src=\"https://static001.geekbang.org/resource/image/44/e2/440494242af83f78909bf836bbe1c0e2.jpg?wh=1920x982\" alt=\"图片\"></p><p>然后，<strong>当我们要通过一个客户端去读取GFS里面的数据的时候，需要怎么做呢？</strong>GFS会有以下三个步骤：</p><ol>\n<li>客户端先去问master，我们想要读取的数据在哪里。这里，客户端会发出两部分信息，一个是文件名，另一个则是要读取哪一段数据，也就是读取文件的offset及length。因为所有文件都被切成64MB大小的一个chunk了，所以根据offset和length，我们可以很容易地算出客户端要读取的数据在哪几个chunk里面。于是，客户端就会告诉master，我要哪个文件的第几个chunk。</li>\n<li>master拿到了这个请求之后，就会把这个chunk对应的所有副本所在的chunkserver，告诉客户端。</li>\n<li>等客户端拿到chunk所在的chunkserver信息后，客户端就可以直接去找其中任意的一个chunkserver读取自己所要的数据。</li>\n</ol><p>你可以参考下图所展示的客户端读取数据的整个过程指令流向。</p><p><img src=\"https://static001.geekbang.org/resource/image/71/95/7124aa76c1ec715b2a29613b5f065d95.jpg?wh=2000x1504\" alt=\"\" title=\"GFS里客户端读取数据的整个过程指令流向\"></p><p>这整个过程抽象一下，其实和Linux文件系统差不多。master<s>节点</s>和chunkserver这样两种节点的设计，其实和操作系统中的文件系统一脉相承。<strong>master就好像存储了所有inode信息的super block，而chunk就是文件系统中的一个个block。</strong>只不过chunk比block的尺寸大了一些，并且放在了很多台不同的机器上而已。我们通过master找到chunk的位置来读取数据，就好像操作系统里通过inode到block的位置，再从block里面读取数据。</p><p>所以，这个时候的master，其实就是一个“<strong>目录服务</strong>”，master本身不存储数据，而是只是存储目录这样的元数据。这个和我们的单机系统的设计思想是一样的。其实在计算机这个行业中，所有的系统都是从最简单、最底层的系统演化而来的。而这个课程中你看到的大部分的设计，其实都有这个特质。</p><h2>master的快速恢复性和可用性保障</h2><p>不过，简单不是没有代价的。</p><p>在这个设计下，你会发现GFS里面的master节点压力很大。在一个1000台服务器的集群里面，chunkserver有上千个，但master只有一个。几百个客户端并发读取的数据，虽然可以分摊到那1000个chunkserver的节点上，但是找到要读的文件的数据存放在哪里，都要去master节点里面去找。</p><p>所以，master节点的所有数据，都是<strong>保存在内存</strong>里的。这样，master的性能才能跟得上几百个客户端的并发访问。</p><p>但是数据放在内存里带来的问题，就是一旦master挂掉，数据就会都丢了。所以，master会通过记录操作日志和定期生成对应的Checkpoints进行持久化，也就是写到硬盘上。</p><p>这是为了确保在master里的这些数据，不会因为一次机器故障就丢失掉。当master节点重启的时候，就会先读取最新的Checkpoints，然后重放（replay）Checkpoints之后的操作日志，把master节点的状态恢复到之前最新的状态。这是最常见的存储系统会用到的<strong>可恢复机制</strong>。</p><p>当然，光有这些还不够，如果只是master节点重新启动一下，从Checkpoints和日志中恢复到最新状态自然是很快的。<strong>可要是master节点的硬件彻底故障了呢？</strong></p><p>你要知道，去数据中心重新更换硬件可不是几分钟的事情，所以GFS还为master准备好了几个“备胎”，也就是另外几台Backup Master。所有针对master的数据操作，都需要同样写到另外准备的这几台服务器上。只有当数据在master上操作成功，对应的操作记录刷新到硬盘上，并且这几个Backup Master的数据也写入成功，并把操作记录刷新到硬盘上，整个操作才会被视为操作成功。</p><p>这种方式，叫做数据的“<strong>同步复制</strong>”，是分布式数据系统里的一种典型模式。假如你需要一个高可用的MySQL集群，一样也可以采用同步复制的方式，在主从服务器之间同步数据。</p><p><img src=\"https://static001.geekbang.org/resource/image/19/c1/199f3ddb59c4d0a0233f9b71549a85c1.jpg?wh=1920x1444\" alt=\"图片\" title=\"在t1时间点上，客户端得到写入成功的返回，此时Master和Backup Master的数据是一致的，但是Shadow Master的数据，要到t2时间点才会追上来\"></p><p>而在同步复制这个机制之外，在集群外部还有监控master的服务在运行。如果只是master的进程挂掉了，那么这个监控程序会立刻重启master进程。而如果master所在的硬件或者硬盘出现损坏，那么这个监控程序就会在前面说的Backup Master里面找一个出来，启动对应的master进程，让它“备胎转正”，变成新的master。</p><p>而这个里面的数据，和原来的master其实一模一样。</p><p>不过，为了让集群中的其他chunkserver以及客户端不用感知这个变化，GFS通过一个规范名称（Canonical Name）来指定master，而不是通过IP地址或者Mac地址。这样，一旦要切换master，这个监控程序只需要修改DNS的别名，就能达到目的。有了这个机制，GFS的master就从之前的可恢复（Recoverable），进化成了能够<strong>快速恢复（Fast Recovery）</strong>。</p><p>不过，就算做到了快速恢复，我们还是不满足。毕竟，从监控程序发现master节点故障、启动备份节点上的master进程、读取Checkpoints和操作日志，仍然是一个几秒级别乃至分钟级别的过程。在这个时间段里，我们可能仍然有几百个客户端程序“嗷嗷待哺”，希望能够在GFS上读写数据。虽然作为单个master的设计，这个时候的确是没有办法去写入数据的。</p><p>但是Google的工程师还是想了一个办法，让我们这个时候还能够从GFS上读取数据。</p><p>这个办法就是加入一系列<strong>只读的“影子Master”</strong>，这些影子Master和前面的备胎不同，master写入数据并不需要等到影子Master也写入完成才返回成功。而是影子Master不断同步master输入的写入，尽可能保持追上master的最新状态。</p><p>这种方式，叫做数据的“<strong>异步复制</strong>”，是分布式系统里另一种典型模式。异步复制下，影子Master并不是和master的数据完全同步的，而是可能会有一些小小的延时。</p><p>影子Master会不断同步master里的数据，不过当master出现问题的时候，客户端们就可以从这些影子Master里找到自己想要的信息。当然，因为小小的延时，客户端有很小的概率，会读到一些过时的master里面的信息，比如命名空间、文件名等这些元数据。但你也要知道，这种情况其实只会发生在以下三个条件都满足的情况下：</p><ol>\n<li>第一个，是master挂掉了；</li>\n<li>第二个，是挂掉的master或者Backup Master上的Checkpoints和操作日志，还没有被影子Master同步完；</li>\n<li>第三个，则是我们要读取的内容，恰恰是在没有同步完的那部分操作上；</li>\n</ol><p><img src=\"https://static001.geekbang.org/resource/image/7a/2d/7a312ed6bda66ce6e8b112yyfb77c82d.jpg?wh=1920x1444\" alt=\"图片\"></p><p>相比于这个小小的可能性，影子Master让整个GFS在master快速恢复的过程中，虽然不能写数据，但仍然是完全可读的。至少在集群的读取操作上，GFS可以算得上是“高可用（High Availability）”的了。</p><h2>小结</h2><p>好了，相信到这里，你应该就对GFS的基本架构有一定的了解了。GFS并不是一篇有着大量新的研究发现的理论性的论文。恰恰相反，整个GFS的架构，是通过非常重要的工程原则来设计的，也就是<strong>尽量简单、需要考虑实际的硬件情况</strong>，以及<strong>针对实际的应用场景进行设计</strong>。</p><p>今天，我们重点围绕GFS的“简单性”，了解了GFS的基础架构设计。GFS采用了单Master架构，但是这个Master有着三重不同的含义。</p><p>首先，作为和chunkserver相对的master，它是一个目录服务。所有的元数据都会保留在我们的master里，而所有的数据会保存在chunkserver里。master存的就好比是inode信息，而chunkserver存的则是实际的block。</p><p>其次，为了保障系统在故障下的快速恢复能力和读数据的高可用性，GFS又对这个master添加了各种工程保障措施。这些措施，包括Checkpoints和操作日志、Backup Master、外部的监控程序，以及只读的影子 Master。在这个高可用场景下，Master是唯一可以写入数据的节点。Backup Master通过同步复制的方式从master同步数据，而影子Master则通过异步复制的方式来同步master的数据。</p><p>在这个场景下，Backup Master和影子Master其实是Master的Slave节点。如果我们把Master当成是一个MySQL数据库的主节点，那么Backup Master就是配置了高可用的同步复制的HA节点，而影子Master就是只配置了异步复制分担数据读取压力的readonly节点。</p><p>我希望你在学完这篇论文之后，也能够学以致用，<strong>当你日后在做系统设计的时候，就从“简单”开始，让系统更容易维护和迭代</strong>。同样的，你也一定会面临，你的master需要承担哪些职责、采用哪些数据复制方式的问题。</p><p>下节课，我会带你来看看GFS另外一个非常重要的设计原则，那就是根据实际硬件情况进行系统设计。你会发现，软件系统的设计，不是抽象的画画图纸，而是和我们设计汽车、飞机一样，需要考虑真实的物理硬件的性能和限制的。甚至有些设计，就是专门针对硬件的物理特性的。</p><h2>推荐阅读</h2><p>最后，专栏是你学习的起点，我非常推荐你去读一读GFS论文的原文。如果你觉得自己英文不够好，作为2003年的一篇“老”论文，网上也有大量的中文解读笔记，你都可以去翻一翻，我把论文的链接放在了<a href=\"https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/gfs-sosp2003.pdf\">这里</a>。当然，还有一个选择，就是去读一读借鉴了GFS的Hadoop上的HDFS的论文，我也把<a href=\"https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5496972\">链接</a>放在了这里。</p><p>除此之外，MIT的开放课程，分布式系统里的第三讲，就是针对GFS的专门讲解，你也可以去看一看他们的<a href=\"http://nil.csail.mit.edu/6.824/2020/video/3.html\">视频</a>，网上也能找到有中文字幕的版本。</p><h2>思考题</h2><p>在课程的最后，我来给你留两道思考题，你可以思考一下：</p><ol>\n<li>如果你读了论文原文，你应该看到GFS的客户端会在读取数据的过程中，把一些数据缓存了下来，那么它究竟缓存了哪些数据来减少频繁的网络往来？在这个缓存机制上，客户端有可能会读到过时的数据吗？</li>\n<li>我前面说了，master的数据都会通过操作日志和Checkpoints持久化在硬盘上。但这句话其实不完全正确，每个chunk存放在什么chunkserver上的这些元数据，master并不会持久化。读完论文之后，你能说说当master重启的时候，怎么重新拿到这个数据吗？</li>\n</ol><p>你可以把你的答案留在评论区，和大家一起探讨、交流，看看自己的理解是不是正确。</p>","comments":[{"had_liked":false,"id":313797,"user_name":"在路上","can_delete":false,"product_type":"c1","uid":1402511,"ip_address":"","ucode":"6E31908EFE1107","user_header":"https://static001.geekbang.org/account/avatar/00/15/66/8f/02be926d.jpg","comment_is_top":false,"comment_ctime":1632668614,"is_pvip":false,"replies":[{"id":"113907","content":"赞👍你真的很棒！","user_name":"作者回复","comment_id":313797,"uid":"1053568","ip_address":"","utype":1,"ctime":1633162064,"user_name_real":"徐文浩"}],"discussion_count":3,"race_medal":0,"score":"147661556678","product_id":100091101,"comment_content":"徐老师好，MIT 6.824的GFS那一讲的讲解框架是介绍分布式存储系统的矛盾、GFS的特点、内部结构和读写操作，一般介绍HDFS的书籍也是类似的流程。不过老师从简单性、考虑硬件性能、结合业务特点三个角度来谈GFS让我有了新的启发。在老师的鼓励下，今天我试着读了《The Google File System》的一部分，花了四个小时读完了INTRODUCTION和DESIGN OVERVIEW，体会到了一点论文的精辟，希望自己能坚持下去。<br><br>回到老师的问题，GFS client会缓存chunk对应的chunkserver地址，直到缓存信息过期或者文件重新打开。这种机制是否会读到过时的数据呢？论文中是这样说的，Since clients cache chunk locations, they may read from a stale replica before that information is refreshed ... as most of our files are append-only, a stale replica usually retures a premature end of chunk rather than outdated data. 也就是说，只会读不到最新的数据，不会读到过时的数据。<br><br>论文中的2.6.2 Chunk Locations讨论了chunk location的管理机制，chunkserver启动时上报chunk location information，之后再周期性上报。之所以这么设计，主要考虑两个原因。第一，消除master和chunkserver的同步问题，第二，chunkserver真正管理了chunk，对于chunk location拥有最终的话语权。","like_count":35,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527476,"discussion_content":"赞👍你真的很棒！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633162064,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1131300,"avatar":"https://static001.geekbang.org/account/avatar/00/11/43/24/3f9f7c70.jpg","nickname":"zixuan","note":"","ucode":"C72920DD05B074","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":541796,"discussion_content":"补充下，stale指没有和primary完成同步的chunk","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1640569603,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1300466,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJGMphabeneYXs9otkAtr67RvxJClDa7jPe7w8yExg4YaS2FGJruDKMj5yN1E90o6MFibnicH8gM0ibg/132","nickname":"hadoop_admin","note":"","ucode":"7EAFA775505C7E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":403569,"discussion_content":"我觉得不会读到过时的信息，但可能读不到数据，比如某些chunkserver 意外宕机了，那么这些chunk 可能就迁移到其他chunkserver上去了，如果client 端没有更新就会读不到正确的数据。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1634111415,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":313432,"user_name":"峰","can_delete":false,"product_type":"c1","uid":1056019,"ip_address":"","ucode":"C53CB64E8E7D19","user_header":"https://static001.geekbang.org/account/avatar/00/10/1d/13/31ea1b0b.jpg","comment_is_top":false,"comment_ctime":1632438537,"is_pvip":true,"replies":[{"id":"113912","content":"👍和论文里的说法基本一样。","user_name":"作者回复","comment_id":313432,"uid":"1053568","ip_address":"","utype":1,"ctime":1633162951,"user_name_real":"徐文浩"}],"discussion_count":1,"race_medal":0,"score":"53172046089","product_id":100091101,"comment_content":"<br>1. 为了减少master的压力，所以要缓存master上的元数据信息。应该会造成读过期数据，因为写入不可变，但支持追加写，对于追加写入的chunk的元数据，怎么同步到客户端缓存按照GFS简单性的原则怕是不想做了。<br><br>2. 每个chunkserver会上报自己拥有哪些chunk。原因的话，chunkserver必然有这个信息，如果master还持久化的话，突然冒出个数据一致性的问题得考虑，数据链路上也会更复杂。","like_count":13,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527348,"discussion_content":"👍和论文里的说法基本一样。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633162951,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":313436,"user_name":"pedro","can_delete":false,"product_type":"c1","uid":1200704,"ip_address":"","ucode":"F40C839DDFD599","user_header":"https://static001.geekbang.org/account/avatar/00/12/52/40/e57a736e.jpg","comment_is_top":false,"comment_ctime":1632443021,"is_pvip":false,"replies":[{"id":"113903","content":"是这样的，打个不一定恰当的比方，就像大家都在搞核理论的时候，Google炸了一枚核弹说核物理就是这样的。","user_name":"作者回复","comment_id":313436,"uid":"1053568","ip_address":"","utype":1,"ctime":1633160948,"user_name_real":"徐文浩"}],"discussion_count":1,"race_medal":0,"score":"48877083277","product_id":100091101,"comment_content":"mit6.824在讲GFS的时候说，GFS并没有什么理论创新，但是它一下子搞了1000多台机器的集群，对其它论文而言完全是降维打击，然后它就被会议接收了。","like_count":12,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527350,"discussion_content":"是这样的，打个不一定恰当的比方，就像大家都在搞核理论的时候，Google炸了一枚核弹说核物理就是这样的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633160948,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":313683,"user_name":"webmin","can_delete":false,"product_type":"c1","uid":1047014,"ip_address":"","ucode":"98B0CA882454E8","user_header":"https://static001.geekbang.org/account/avatar/00/0f/f9/e6/47742988.jpg","comment_is_top":false,"comment_ctime":1632621142,"is_pvip":true,"replies":[{"id":"113925","content":"👍","user_name":"作者回复","comment_id":313683,"uid":"1053568","ip_address":"","utype":1,"ctime":1633165277,"user_name_real":"徐文浩"}],"discussion_count":1,"race_medal":0,"score":"31697392214","product_id":100091101,"comment_content":"1. GFS客户端会在读取数据时，把文件其余块的元数据缓存在本地，因为是追加写已写入成功的元数据短期不会变化，再者从空间局部性的原理出发，读部分块后，大概率会要接下来读这个文件余下块，所以提前装载元数据也算是一种优化预测吧；<br><br>2. master重启后，会让chunkserver上报自己管理的chunk的meta信息，这样做可以我想是考虑到了在master关闭期间chunkserver本身会发生一些变化，比如chunkserver的主备发生切换或者因为运维需要调整了chunkserver的IP地址等吧。","like_count":8,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527436,"discussion_content":"👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633165277,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":313923,"user_name":"Geek_74dea9","can_delete":false,"product_type":"c1","uid":2760246,"ip_address":"","ucode":"14092EEBC08171","user_header":"","comment_is_top":false,"comment_ctime":1632743844,"is_pvip":false,"replies":[{"id":"113820","content":"回答正确，相信你一定仔细去看了论文。","user_name":"作者回复","comment_id":313923,"uid":"1053568","ip_address":"","utype":1,"ctime":1632917406,"user_name_real":"徐文浩"}],"discussion_count":1,"race_medal":0,"score":"18812613028","product_id":100091101,"comment_content":"chunk的位置信息并不会持久化，而是在master启动的时候， 让chunk server汇报给master","like_count":5,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527520,"discussion_content":"回答正确，相信你一定仔细去看了论文。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1632917406,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":344238,"user_name":"ahnselina","can_delete":false,"product_type":"c1","uid":1100888,"ip_address":"","ucode":"EE3B18BB9B7C11","user_header":"https://static001.geekbang.org/account/avatar/00/10/cc/58/c593587c.jpg","comment_is_top":false,"comment_ctime":1651390955,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"10241325547","product_id":100091101,"comment_content":"徐老师好，有个疑问：<br>Shadow master分担读压力的角色为什么不直接用backup master来分担呢？","like_count":2},{"had_liked":false,"id":314055,"user_name":"推推。","can_delete":false,"product_type":"c1","uid":1990393,"ip_address":"","ucode":"457992FB234357","user_header":"https://static001.geekbang.org/account/avatar/00/1e/5e/f9/ca88bdb8.jpg","comment_is_top":false,"comment_ctime":1632820090,"is_pvip":true,"replies":[{"id":"113916","content":"这部分可以读一下论文 4.3 部分，master和chunkserver之间有心跳<br><br>集群并不会“创建”新的trunk server，而是有新的硬件加入到trunk server，master可以根据策略去做rebalance。<br><br>如果有硬件下线，master也不关心如何恢复，他只会利用剩下的硬件来确保3份replica来保持可用性。","user_name":"作者回复","comment_id":314055,"uid":"1053568","ip_address":"","utype":1,"ctime":1633164410,"user_name_real":"徐文浩"}],"discussion_count":2,"race_medal":0,"score":"10222754682","product_id":100091101,"comment_content":"想问一下 master 如何更新 chunk server的状态和数据呢 如果有 chunk server failed了 如何建立一个新的trunk server 呢","like_count":3,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527559,"discussion_content":"这部分可以读一下论文 4.3 部分，master和chunkserver之间有心跳\n\n集群并不会“创建”新的trunk server，而是有新的硬件加入到trunk server，master可以根据策略去做rebalance。\n\n如果有硬件下线，master也不关心如何恢复，他只会利用剩下的硬件来确保3份replica来保持可用性。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633164410,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1009518,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/67/6e/f5ee46e8.jpg","nickname":"海滨","note":"","ucode":"F1B94D2DB944DC","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":399985,"discussion_content":"一般是chunk sever主动以心跳包的方式上报自己的状态。如果有chunk sever挂了，master不会去建立新的chunk sever，而是将这个挂掉chunk server上的文件chunk（通过其他文件chunk副本）迁移到其他chunk sever上。新chunk sever的建立，只能人工运维来操作","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1633131863,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":327073,"user_name":"zixuan","can_delete":false,"product_type":"c1","uid":1131300,"ip_address":"","ucode":"C72920DD05B074","user_header":"https://static001.geekbang.org/account/avatar/00/11/43/24/3f9f7c70.jpg","comment_is_top":false,"comment_ctime":1639903833,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"5934871129","product_id":100091101,"comment_content":"Shadow master分担读压力的角色为什么不能直接用backup master来承担呢？","like_count":1,"discussions":[{"author":{"id":1066964,"avatar":"https://static001.geekbang.org/account/avatar/00/10/47/d4/e216d06e.jpg","nickname":"mimiyk","note":"","ucode":"A12FAA6C327E3F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":570060,"discussion_content":"backup master日常只是接收数据落盘并不启动master进程, 要让它可用得启动进程读checkpoint重放后才能工作, 比较耗时. Shadow master则一直是活跃的.","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1651651655,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2313483,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eoxwOia66AoThuONdeGHK5ZA80QzfXgNSeolk72UWCC4ssw6oY7reZkmXsczvke42gfUONu17bk8Vw/132","nickname":"jackey90","note":"","ucode":"40F2251AF4D160","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":567067,"discussion_content":"我也有同样的疑问。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1650818331,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":320185,"user_name":"~~五浩~~","can_delete":false,"product_type":"c1","uid":2225465,"ip_address":"","ucode":"E25E5A029CAFED","user_header":"https://static001.geekbang.org/account/avatar/00/21/f5/39/4f3e5c0c.jpg","comment_is_top":false,"comment_ctime":1636111816,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"5931079112","product_id":100091101,"comment_content":"多个backup master同步操作，如何做到数据一致的，其实又是一个大问题！没有强一致算法，靠简单的二阶段提交，恐怕不行","like_count":1,"discussions":[{"author":{"id":1066752,"avatar":"https://static001.geekbang.org/account/avatar/00/10/47/00/3202bdf0.jpg","nickname":"piboye","note":"","ucode":"7CFD8712857A85","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":541449,"discussion_content":"有master，同步只是复制，复制本身不需要复杂算法，也不需要二阶段。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1640366453,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1066752,"avatar":"https://static001.geekbang.org/account/avatar/00/10/47/00/3202bdf0.jpg","nickname":"piboye","note":"","ucode":"7CFD8712857A85","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":541450,"discussion_content":"有master可以想象成单线串行处理，复制机制就是复制流水，确认机制只需要保证之前的都复制到了2份就可以返还客户端成功了。 流水你可以想象成一个tcp流，ack当成是确认，ack的序号就表示之前都成功了。不知道是否可以这么理解？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1640366840,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":313751,"user_name":"潇湘夜雨","can_delete":false,"product_type":"c1","uid":2775556,"ip_address":"","ucode":"7EBE77DF29E86E","user_header":"https://static001.geekbang.org/account/avatar/00/2a/5a/04/335e02fd.jpg","comment_is_top":false,"comment_ctime":1632647642,"is_pvip":false,"replies":[{"id":"113827","content":"潇湘夜雨同学，<br><br>你好，从我自己读论文的经验来看。读GFS，MapReduce和BigTable的论文，对于背景知识的要求不高。也比较容易读懂。<br><br>对于没有太多实际分布式系统经验的同学来说，主要的学习挑战，会在后续的Chubby，Spanner这些论文中。不过我会在里面补充足够的基础知识，让大家能够读懂这些看起来有些复杂的论文。","user_name":"作者回复","comment_id":313751,"uid":"1053568","ip_address":"","utype":1,"ctime":1632918543,"user_name_real":"徐文浩"}],"discussion_count":1,"race_medal":0,"score":"5927614938","product_id":100091101,"comment_content":"想请问下，看gfs三驾马车等论文需要啥前置知识吗，我正在学大数据相关技术与框架，对分布式不是很了解，看论文有点摸不着头脑","like_count":1,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527460,"discussion_content":"潇湘夜雨同学，\n\n你好，从我自己读论文的经验来看。读GFS，MapReduce和BigTable的论文，对于背景知识的要求不高。也比较容易读懂。\n\n对于没有太多实际分布式系统经验的同学来说，主要的学习挑战，会在后续的Chubby，Spanner这些论文中。不过我会在里面补充足够的基础知识，让大家能够读懂这些看起来有些复杂的论文。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1632918543,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":351484,"user_name":"日就月将","can_delete":false,"product_type":"c1","uid":2651148,"ip_address":"","ucode":"0F9BA55A2898FF","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/cabLXAUXiavXnEckAgo971o4l1CxP4L9wOV2eUGTyKBUicTib6gJyKV9iatM4GG1scz5Ym17GOzXWQEGzhE31tXUtQ/132","comment_is_top":false,"comment_ctime":1657845442,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1657845442","product_id":100091101,"comment_content":"我想请教一下，文中说的GFS 在写数据的时候，选择了流水线式的数据传输，而没有选择树形的数据传输方式。这两种传输方式的区别是什么，有什么资料可以了解一下这两种方式呢？","like_count":1},{"had_liked":false,"id":347520,"user_name":"Chloe","can_delete":false,"product_type":"c1","uid":1004953,"ip_address":"","ucode":"C4848ED5B35752","user_header":"https://static001.geekbang.org/account/avatar/00/0f/55/99/4bdadfd3.jpg","comment_is_top":false,"comment_ctime":1654109035,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1654109035","product_id":100091101,"comment_content":"刚学了两天，很喜欢老师的风格。课程内容刚刚好，即讲明白了来龙去脉，又激发了读原著的兴趣，谢谢老师","like_count":0},{"had_liked":false,"id":347519,"user_name":"Chao","can_delete":false,"product_type":"c1","uid":1152428,"ip_address":"","ucode":"CE995B39587D22","user_header":"https://static001.geekbang.org/account/avatar/00/11/95/ac/ff011d99.jpg","comment_is_top":false,"comment_ctime":1654104942,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1654104942","product_id":100091101,"comment_content":"1. 为了减少chuckserver之间的traffic，每个chunkserver需要缓存chunk的metadata，以及chunk的hash code，这样如果有更改的话可以直接比较hash code，如果一致，就代表不需要更新<br>2. master重新启动之后会ping每个chunk server，然后chunk server返回它自身缓存的metadada","like_count":0},{"had_liked":false,"id":335952,"user_name":"黄金果","can_delete":false,"product_type":"c1","uid":1456586,"ip_address":"","ucode":"329811FF99F4B8","user_header":"https://static001.geekbang.org/account/avatar/00/16/39/ca/cdc58834.jpg","comment_is_top":false,"comment_ctime":1645785001,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1645785001","product_id":100091101,"comment_content":"猜测:客户端希望读取数据的时候, 会询问 master 自己目标文件的 metadata, 猜测为了提高效率会缓存这部分数据<br>是否有可能会访问到过期的老数据?<br>有可能, 数据在后续的时间中有可能被别的用户操作<br><br>文件系统中的数据可以怎么操作呢? <br>修改文件内容- 貌似不支持修改文件内容吧<br>删除文件- 拿着老的 metadata 无法访问到数据, 影响不大<br>删除之后在添加文件-拿着老的 metadata 无法访问到数据, 但是文件实际存在内存中, 有影响<br><br>如何解决这个问题呢?<br>是否可以考虑为metadata 添加版本号, 客户端去 chunkserver 拿数据的时候发现版本比较落后可以去 master 获取最新的数据<br><br>有不对的地方还望指正,多谢","like_count":0},{"had_liked":false,"id":330617,"user_name":"阿橦木","can_delete":false,"product_type":"c1","uid":1104828,"ip_address":"","ucode":"06AB6A83A820A1","user_header":"https://static001.geekbang.org/account/avatar/00/10/db/bc/286e72d2.jpg","comment_is_top":false,"comment_ctime":1642071637,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1642071637","product_id":100091101,"comment_content":"客户端读取文件时，只发送文件名称和路径不可以吗？为何需要发送offset和length？","like_count":0,"discussions":[{"author":{"id":2419502,"avatar":"https://static001.geekbang.org/account/avatar/00/24/eb/2e/90fea784.jpg","nickname":"柒","note":"","ucode":"D41241629321A1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":583520,"discussion_content":"你又不用读整个文件，比如只读文件的某一行。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1660179590,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"上海"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":327941,"user_name":"dahai","can_delete":false,"product_type":"c1","uid":1762705,"ip_address":"","ucode":"9F866FC42DF9A8","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIVR2wY9icec2CGzZ4VKPdwK2icytM5k1tHm08qSEysFOgl1y7lk2ccDqSCvzibHufo2Cb9c2hjr0LIg/132","comment_is_top":false,"comment_ctime":1640409876,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1640409876","product_id":100091101,"comment_content":"关于为什么不启动备份master,而是启动影子master.原因是影子master是热数据，可以直接启动被使用，而备份master有部分需要重放的日志，无法立即启动。是这样么？","like_count":0},{"had_liked":false,"id":327923,"user_name":"piboye","can_delete":false,"product_type":"c1","uid":1066752,"ip_address":"","ucode":"7CFD8712857A85","user_header":"https://static001.geekbang.org/account/avatar/00/10/47/00/3202bdf0.jpg","comment_is_top":false,"comment_ctime":1640365913,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1640365913","product_id":100091101,"comment_content":"nvm内存，是可以加速这个master的性能吧","like_count":0},{"had_liked":false,"id":322403,"user_name":"Geek_4c2e3e","can_delete":false,"product_type":"c1","uid":2827756,"ip_address":"","ucode":"A6C35563483EC6","user_header":"","comment_is_top":false,"comment_ctime":1637370803,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1637370803","product_id":100091101,"comment_content":"课后思考题：<br>1:客户端缓存了chunk locations，可能会读到过时的数据，这个过时窗口受缓存项超时时间和下次打开文件的时机影响。原文：Since clients cache chunk locations, they may read from a stale replica before that information is refreshed. This window is limited by the cache entry’s timeout and the next open of the file, which purges from the cache all chunk information for that file.<br>2.轮询chunkserver。原文：The master does not keep a persistent record of which chunkservers have a replica of a given chunk. It simply polls chunkservers for that information at startup.","like_count":0},{"had_liked":false,"id":319620,"user_name":"fuyu","can_delete":false,"product_type":"c1","uid":1012551,"ip_address":"","ucode":"E2D00651A70E27","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIKVicSvNf6OFvv4m3ibfsYCIUxic41kODPa9cuGUJjPcBtryLBDljalIVUiaJKlkGEJtOMZ03XSFlx1w/132","comment_is_top":false,"comment_ctime":1635867519,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1635867519","product_id":100091101,"comment_content":"不过，为了让集群中的其他 chunkserver 以及客户端不用感知这个变化，GFS 通过一个规范名称（Canonical Name）来指定 master，而不是通过 IP 地址或者 Mac 地址。这样，一旦要切换 master，这个监控程序只需要修改 DNS 的别名，就能达到目的。有了这个机制，GFS 的 master 就从之前的可恢复（Recoverable），进化成了能够快速恢复（Fast Recovery）。<br><br><br>这个没明白什么意思？如果是域名，SDK 肯定会有缓存时间，没明白Canonical Name是什么意思","like_count":1},{"had_liked":false,"id":317480,"user_name":"阿甘","can_delete":false,"product_type":"c1","uid":1057843,"ip_address":"","ucode":"BC93175B70E05D","user_header":"https://static001.geekbang.org/account/avatar/00/10/24/33/bcf37f50.jpg","comment_is_top":false,"comment_ctime":1634809924,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1634809924","product_id":100091101,"comment_content":"master跟chunkserver之间没有心跳之类的协作吗？不会对挂掉的chunkserver进行映射修改或者数据迁移吗？","like_count":0},{"had_liked":false,"id":316027,"user_name":"hadoop_admin","can_delete":false,"product_type":"c1","uid":1300466,"ip_address":"","ucode":"7EAFA775505C7E","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJGMphabeneYXs9otkAtr67RvxJClDa7jPe7w8yExg4YaS2FGJruDKMj5yN1E90o6MFibnicH8gM0ibg/132","comment_is_top":false,"comment_ctime":1634111203,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"1634111203","product_id":100091101,"comment_content":"有一个问题没想明白，在GFS系统中，GFS 的客户端需要读某个文件，它向GFS 的master发生请求的时候只有文件名吧，它还不知道chunk的信息吧？文中 的请求中还带了chunk信息，没明白。","like_count":0,"discussions":[{"author":{"id":2207117,"avatar":"https://static001.geekbang.org/account/avatar/00/21/ad/8d/43cba089.jpg","nickname":"蓝色。","note":"","ucode":"005371B754F4DF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":556083,"discussion_content":"offset+size 是一种很常见的设计思路","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1647191091,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1066752,"avatar":"https://static001.geekbang.org/account/avatar/00/10/47/00/3202bdf0.jpg","nickname":"piboye","note":"","ucode":"7CFD8712857A85","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":541451,"discussion_content":"64m是固定的chunk大小，不是动态变化的，就像linux的页大小固定为16k，你想读offset的时候，就转换成对应的第几页","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1640367635,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":315024,"user_name":"Will","can_delete":false,"product_type":"c1","uid":1969213,"ip_address":"","ucode":"1F1B255267052C","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJIic0IdMZpPQ6c2nicqroRM2csjG7n2uUvHBtKxBl7mqwyibDhFmoIKBpqiazj8AzVpmicWXWq4MUwuaw/132","comment_is_top":false,"comment_ctime":1633662447,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1633662447","product_id":100091101,"comment_content":"可以问一下老师 GSF设计原则的图 是用什么软件画的？","like_count":0,"discussions":[{"author":{"id":1234202,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Gf2QrwPGnMxzibPQoVjgoRAFtpO2Sy8QUNqyNRHgwkkZjH9XT1nficRmQAYP40IxgjcM4yaxDicuadiaGCIyyJLWQA/132","nickname":"zs19940317","note":"","ucode":"CC4DE62F16B8D1","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":547951,"discussion_content":"xmind","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1642951401,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":314586,"user_name":"thomas","can_delete":false,"product_type":"c1","uid":1016777,"ip_address":"","ucode":"9AB945308F1B50","user_header":"https://static001.geekbang.org/account/avatar/00/0f/83/c9/5d03981a.jpg","comment_is_top":false,"comment_ctime":1633244143,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1633244143","product_id":100091101,"comment_content":"假设1个文件有3个副本(1个副本在一个chunkserver)， 有N个客户端来访问这个文件，如何保证这N个客户端的请求，能平均的分发到这3个chunkserver？是master会去做轮询，然后返回给客户端吗？","like_count":0},{"had_liked":false,"id":314545,"user_name":"火娃儿","can_delete":false,"product_type":"c1","uid":1252132,"ip_address":"","ucode":"2704841763FD70","user_header":"https://static001.geekbang.org/account/avatar/00/13/1b/24/1006c208.jpg","comment_is_top":false,"comment_ctime":1633192208,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1633192208","product_id":100091101,"comment_content":"GFS 的客户端会在读取数据的过程中，把一些数据缓存了下来，那么它究竟缓存了哪些数据来减少频繁的网络往来？在这个缓存机制上，客户端有可能会读到过时的数据吗？<br>应该是  缓存 之前 读取到的CHUNK 对应的 CHUNK SERVER 的对应关系。<br><br>能说说当 master 重启的时候，怎么重新拿到这个数据吗？<br>当MASTER 重启时候， 会找到 CHUNKSERVER, 重新 获取 CHUNKSERVER里面 保存的 CHUNK信息，以及各种SERVER自身配置 相关的信息，以防止 重启之后，CHUNKSERVER的 数据分布 产生了 改变。<br><br>","like_count":0},{"had_liked":false,"id":314493,"user_name":"Lebron","can_delete":false,"product_type":"c1","uid":1327057,"ip_address":"","ucode":"042295490BEBE1","user_header":"https://static001.geekbang.org/account/avatar/00/14/3f/d1/910a7dc9.jpg","comment_is_top":false,"comment_ctime":1633142922,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1633142922","product_id":100091101,"comment_content":"老师，在您介绍客户端读取影子Master也许会读取到过时信息的那张图片里，客户端与GFS Master的交互箭头是否写反了？我的理解是，客户端向GFS Master发送写入数据的请求，而GFS Master返回给客户端全部FLUST完成，写入成功的信息。","like_count":0},{"had_liked":false,"id":314485,"user_name":"海滨","can_delete":false,"product_type":"c1","uid":1009518,"ip_address":"","ucode":"F1B94D2DB944DC","user_header":"https://static001.geekbang.org/account/avatar/00/0f/67/6e/f5ee46e8.jpg","comment_is_top":false,"comment_ctime":1633131434,"is_pvip":true,"replies":[{"id":"113896","content":"👍","user_name":"作者回复","user_name_real":"徐文浩","uid":"1053568","ctime":1633159397,"ip_address":"","comment_id":314485,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1633131434","product_id":100091101,"comment_content":"1. 客户端应该会缓存请求过的文件对应的chunk sever的元数据信息，这部分数据占用大小很小非常适合缓存，缓存之后可以减少对master server的压力。<br>缓存的数据是可能过时的，我觉得主要分2种情况，一种是文件chunk对应的chunk sever变了，这个时候文件chunk一旦请求不到重新向master重新请求更新就可以了；还有一种情况数据更新了，比如文件对应的chunk数变多了，这种情况应该在chunk sever有相关机制来校验这种情况吧。<br><br>2. 还没有读过论文，我猜测应该是chunk sever主动上报的方式来使master重新拿到这个数据的吧","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527697,"discussion_content":"👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633159397,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":314469,"user_name":"融冰","can_delete":false,"product_type":"c1","uid":2073875,"ip_address":"","ucode":"FC01D3E6720A0F","user_header":"https://static001.geekbang.org/account/avatar/00/1f/a5/13/5fbde43f.jpg","comment_is_top":false,"comment_ctime":1633097719,"is_pvip":true,"replies":[{"id":"113915","content":"👍","user_name":"作者回复","user_name_real":"徐文浩","uid":"1053568","ctime":1633164220,"ip_address":"","comment_id":314469,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1633097719","product_id":100091101,"comment_content":"1. 客户端会缓存文件和 chunkserver 的映射，这个缓存会在时效结束或者文件被重新打开的时候失效<br>2. chunk 存放在什么 chunkserver 这个由 chunkserver 自己维护，master 重启的时候会跟所有 chunkserver 获取对应存储的 chunk","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527689,"discussion_content":"👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633164220,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":314306,"user_name":"ROY","can_delete":false,"product_type":"c1","uid":1296815,"ip_address":"","ucode":"FB99E4456D2E5F","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eoqEsRcQ5icwkgTDBX9JA8iaqohBdIGhxMXLFDSevEXqm5sAarw3hKeEHzxkoEJ5sx7plibcRPqmicAlQ/132","comment_is_top":false,"comment_ctime":1632967070,"is_pvip":false,"replies":[{"id":"113892","content":"不能算轮询，准备来说是各个chunkserver主动上报的。","user_name":"作者回复","user_name_real":"徐文浩","uid":"1053568","ctime":1633156393,"ip_address":"","comment_id":314306,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1632967070","product_id":100091101,"comment_content":"客户机保存控制流而不是数据流，当chunk有更新等操作时，会客户端和chunkserver之间建立的链接失效，必须重新从master获取<br>master失败的时候是用log快速恢复当时的状态的，而chunkserver上存放什么元数据应该是通过轮询各个chunkserver得到的吧","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527638,"discussion_content":"不能算轮询，准备来说是各个chunkserver主动上报的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633156393,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":313696,"user_name":"Geek_648c55","can_delete":false,"product_type":"c1","uid":2155951,"ip_address":"","ucode":"165A1D37E0B473","user_header":"","comment_is_top":false,"comment_ctime":1632623142,"is_pvip":false,"replies":[{"id":"113919","content":"是定期把当前master内存里的GFS的Metadata持久化下来，避免节点故障恢复的时候需要更多的时间。恢复的时候读这个metadata的checkpoint，然后replay部分日志就可以了，而不用replay所有的日志。<br><br>很多其他数据库也有类似的机制。","user_name":"作者回复","user_name_real":"徐文浩","uid":"1053568","ctime":1633164542,"ip_address":"","comment_id":313696,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1632623142","product_id":100091101,"comment_content":"gfs写操作更新内存和记录操作日志就算完成了是吧。用顺序写的操作日志，代替磁盘的随机读写，提升性能。但是，文中提到的checkpoint是指什么，是指已完成刷盘的指令位置？","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527444,"discussion_content":"是定期把当前master内存里的GFS的Metadata持久化下来，避免节点故障恢复的时候需要更多的时间。恢复的时候读这个metadata的checkpoint，然后replay部分日志就可以了，而不用replay所有的日志。\n\n很多其他数据库也有类似的机制。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633164542,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1009518,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/67/6e/f5ee46e8.jpg","nickname":"海滨","note":"","ucode":"F1B94D2DB944DC","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":399988,"discussion_content":"我的理解是这样的，GFS写操作的时候只会保证内存和操作日志刷盘完成。但是内存中文件与文件chunk handle的对应关系肯定需要落盘更新的，不然master服务挂掉之后只能从全量的操作日志里面replay了，这个工作量就非常大了。所以这里的checkpoint就是指当前磁盘中文件与文件chunk handle最新映射关系所对应的操作日志位置。\n你可以理解为文件与文件chunk映射关系有两份数据，一份在内存中由写操作流程来保证，是最新的数据，另一份在磁盘中通过异步的方式replay操作日志来更新，会有一点延迟。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1633133157,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":313691,"user_name":"Geek_648c55","can_delete":false,"product_type":"c1","uid":2155951,"ip_address":"","ucode":"165A1D37E0B473","user_header":"","comment_is_top":false,"comment_ctime":1632621790,"is_pvip":false,"replies":[{"id":"113902","content":"这个请看第二讲，专门一讲都在讲这个问题。","user_name":"作者回复","user_name_real":"徐文浩","uid":"1053568","ctime":1633160876,"ip_address":"","comment_id":313691,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1632621790","product_id":100091101,"comment_content":"所以 GFS 在写数据的时候，选择了流水线式的数据传输，而没有选择树形的数据传输方式。<br>什么是流水线式数据传输，什么又是树形数据传输？","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527441,"discussion_content":"这个请看第二讲，专门一讲都在讲这个问题。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633160876,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":313520,"user_name":"毛毛酱","can_delete":false,"product_type":"c1","uid":2031114,"ip_address":"","ucode":"056E939BD62D44","user_header":"","comment_is_top":false,"comment_ctime":1632472877,"is_pvip":false,"replies":[{"id":"113900","content":"写请求会直接有WAL先到硬盘，但是同步要更新内存里的BTREE<br><br>Checkpoints是因为当Master要恢复的时候不可能重放所有的历史日志，所以需要定时有checkpoints来减少进程挂掉后的恢复时间<br><br>是否是2PC提交论文里没有说。但是GFS和Hadoop 1.0不同，是有同步复制的Back Master，所以完全可以做2PC保障两边数据完全一致。","user_name":"作者回复","user_name_real":"徐文浩","uid":"1053568","ctime":1633160813,"ip_address":"","comment_id":313520,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1632472877","product_id":100091101,"comment_content":"问一个初级问题哈～ 老师说：“master 的数据都会通过操作日志和 Checkpoints 持久化在硬盘上”，具体是把什么数据持久化在硬盘上？ 比如，是“全路径文件名到多个 chunk handle 的映射关系“吗？这个不是在写请求时直接持久化在硬盘上吗？不是直接落盘的话，是采用的二段式提交？","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527374,"discussion_content":"写请求会直接有WAL先到硬盘，但是同步要更新内存里的BTREE\n\nCheckpoints是因为当Master要恢复的时候不可能重放所有的历史日志，所以需要定时有checkpoints来减少进程挂掉后的恢复时间\n\n是否是2PC提交论文里没有说。但是GFS和Hadoop 1.0不同，是有同步复制的Back Master，所以完全可以做2PC保障两边数据完全一致。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633160813,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]}]}