{"id":138724,"title":"25 | RocketMQ与Kafka中如何实现事务？","content":"<p>你好，我是李玥。</p><p>在之前《<a href=\"https://time.geekbang.org/column/article/111269\">04 | 如何利用事务消息实现分布式事务？</a>》这节课中，我通过一个小例子来和大家讲解了如何来使用事务消息。在这节课的评论区，很多同学都提出来，非常想了解一下事务消息到底是怎么实现的。不仅要会使用，还要掌握实现原理，这种学习态度，一直是我们非常提倡的，这节课，我们就一起来学习一下，在RocketMQ和Kafka中，事务消息分别是如何来实现的？</p><h2>RocketMQ的事务是如何实现的？</h2><p>首先我们来看RocketMQ的事务。我在之前的课程中，已经给大家讲解过RocketMQ事务的大致流程，这里我们再一起通过代码，重温一下这个流程。</p><pre><code>public class CreateOrderService {\n\n  @Inject\n  private OrderDao orderDao; // 注入订单表的DAO\b\n  @Inject\n  private ExecutorService executorService; //注入一个ExecutorService\n\n  private TransactionMQProducer producer;\n\n  // 初始化transactionListener 和 producer\n  @Init\n  public void init() throws MQClientException {\n    TransactionListener transactionListener = createTransactionListener();\n    producer = new TransactionMQProducer(&quot;myGroup&quot;);\n    producer.setExecutorService(executorService);\n    producer.setTransactionListener(transactionListener);\n    producer.start();\n  }\n\n  // 创建订单服务的请求入口\n  @PUT\n  @RequestMapping(...)\n  public boolean createOrder(@RequestBody CreateOrderRequest request) {\n    // 根据创建订单请求创建一条消息\n    Message msg = createMessage(request);\n    // 发送事务消息\n    SendResult sendResult = producer.sendMessageInTransaction(msg, request);\n    // 返回：事务是否成功\n    return sendResult.getSendStatus() == SendStatus.SEND_OK;\n  }\n\n  private TransactionListener createTransactionListener() {\n    return new TransactionListener() {\n      @Override\n      public LocalTransactionState executeLocalTransaction(Message msg, Object arg) {\n        CreateOrderRequest request = (CreateOrderRequest ) arg;\n        try {\n          // 执行本地事务创建订单\n          orderDao.createOrderInDB(request);\n          // 如果没抛异常说明执行成功，提交事务消息\n          return LocalTransactionState.COMMIT_MESSAGE;\n        } catch (Throwable t) {\n          // 失败则直接回滚事务消息\n          return LocalTransactionState.ROLLBACK_MESSAGE;\n        }\n      }\n      // 反查本地事务\n      @Override\n      public LocalTransactionState checkLocalTransaction(MessageExt msg) {、\n        // 从消息中获得订单ID\n        String orderId = msg.getUserProperty(&quot;orderId&quot;);\n\n        // 去数据库中查询订单号是否存在，如果存在则提交事务；\n        // 如果不存在，可能是本地事务失败了，也可能是本地事务还在执行，所以返回UNKNOW\n        //（PS：这里RocketMQ有个拼写错误：UNKNOW）\n        return orderDao.isOrderIdExistsInDB(orderId)?\n                LocalTransactionState.COMMIT_MESSAGE: LocalTransactionState.UNKNOW;\n      }\n    };\n  }\n\n    //....\n}\n</code></pre><p>在这个流程中，我们提供一个创建订单的服务，功能就是在数据库中插入一条订单记录，并发送一条创建订单的消息，要求写数据库和发消息这两个操作在一个事务内执行，要么都成功，要么都失败。在这段代码中，我们首先在init()方法中初始化了transactionListener和发生RocketMQ事务消息的变量producer。真正提供创建订单服务的方法是createOrder()，在这个方法里面，我们根据请求的参数创建一条消息，然后调用RocketMQ producer发送事务消息，并返回事务执行结果。</p><!-- [[[read_end]]] --><p>之后的createTransactionListener()方法是在init()方法中调用的，这里面直接构造一个匿名类，来实现RocketMQ的TransactionListener接口，这个接口需要实现两个方法：</p><ul>\n<li>executeLocalTransaction：执行本地事务，在这里我们直接把订单数据插入到数据库中，并返回本地事务的执行结果。</li>\n<li>checkLocalTransaction：反查本地事务，在这里我们的处理是，在数据库中查询订单号是否存在，如果存在则提交事务，如果不存在，可能是本地事务失败了，也可能是本地事务还在执行，所以返回UNKNOW。</li>\n</ul><p>这样，就使用RocketMQ的事务消息功能实现了一个创建订单的分布式事务。接下来我们一起通过RocketMQ的源代码来看一下，它的事务消息是如何实现的。</p><p>首先看一下在producer中，是如何来发送事务消息的：</p><pre><code>public TransactionSendResult sendMessageInTransaction(final Message msg,\n                                                      final LocalTransactionExecuter localTransactionExecuter, final Object arg)\n    throws MQClientException {\n    TransactionListener transactionListener = getCheckListener();\n    if (null == localTransactionExecuter &amp;&amp; null == transactionListener) {\n        throw new MQClientException(&quot;tranExecutor is null&quot;, null);\n    }\n    Validators.checkMessage(msg, this.defaultMQProducer);\n\n    SendResult sendResult = null;\n\n    // 这里给消息添加了属性，标明这是一个事务消息，也就是半消息\n    MessageAccessor.putProperty(msg, MessageConst.PROPERTY_TRANSACTION_PREPARED, &quot;true&quot;);\n    MessageAccessor.putProperty(msg, MessageConst.PROPERTY_PRODUCER_GROUP, this.defaultMQProducer.getProducerGroup());\n\n    // 调用发送普通消息的方法，发送这条半消息\n    try {\n        sendResult = this.send(msg);\n    } catch (Exception e) {\n        throw new MQClientException(&quot;send message Exception&quot;, e);\n    }\n\n    LocalTransactionState localTransactionState = LocalTransactionState.UNKNOW;\n    Throwable localException = null;\n    switch (sendResult.getSendStatus()) {\n        case SEND_OK: {\n            try {\n                if (sendResult.getTransactionId() != null) {\n                    msg.putUserProperty(&quot;__transactionId__&quot;, sendResult.getTransactionId());\n                }\n                String transactionId = msg.getProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX);\n                if (null != transactionId &amp;&amp; !&quot;&quot;.equals(transactionId)) {\n                    msg.setTransactionId(transactionId);\n                }\n\n                // 执行本地事务\n                if (null != localTransactionExecuter) {\n                    localTransactionState = localTransactionExecuter.executeLocalTransactionBranch(msg, arg);\n                } else if (transactionListener != null) {\n                    log.debug(&quot;Used new transaction API&quot;);\n                    localTransactionState = transactionListener.executeLocalTransaction(msg, arg);\n                }\n                if (null == localTransactionState) {\n                    localTransactionState = LocalTransactionState.UNKNOW;\n                }\n\n                if (localTransactionState != LocalTransactionState.COMMIT_MESSAGE) {\n                    log.info(&quot;executeLocalTransactionBranch return {}&quot;, localTransactionState);\n                    log.info(msg.toString());\n                }\n            } catch (Throwable e) {\n                log.info(&quot;executeLocalTransactionBranch exception&quot;, e);\n                log.info(msg.toString());\n                localException = e;\n            }\n        }\n        break;\n        case FLUSH_DISK_TIMEOUT:\n        case FLUSH_SLAVE_TIMEOUT:\n        case SLAVE_NOT_AVAILABLE:\n            localTransactionState = LocalTransactionState.ROLLBACK_MESSAGE;\n            break;\n        default:\n            break;\n    }\n\n    // 根据事务消息和本地事务的执行结果localTransactionState，决定提交或回滚事务消息\n    // 这里给Broker发送提交或回滚事务的RPC请求。\n    try {\n        this.endTransaction(sendResult, localTransactionState, localException);\n    } catch (Exception e) {\n        log.warn(&quot;local transaction execute &quot; + localTransactionState + &quot;, but end broker transaction failed&quot;, e);\n    }\n\n    TransactionSendResult transactionSendResult = new TransactionSendResult();\n    transactionSendResult.setSendStatus(sendResult.getSendStatus());\n    transactionSendResult.setMessageQueue(sendResult.getMessageQueue());\n    transactionSendResult.setMsgId(sendResult.getMsgId());\n    transactionSendResult.setQueueOffset(sendResult.getQueueOffset());\n    transactionSendResult.setTransactionId(sendResult.getTransactionId());\n    transactionSendResult.setLocalTransactionState(localTransactionState);\n    return transactionSendResult;\n}\n</code></pre><p>这段代码的实现逻辑是这样的：首先给待发送消息添加了一个属性PROPERTY_TRANSACTION_PREPARED，标明这是一个事务消息，也就是半消息，然后会像发送普通消息一样去把这条消息发送到Broker上。如果发送成功了，就开始调用我们之前提供的接口TransactionListener的实现类中，执行本地事务的方法executeLocalTransaction()来执行本地事务，在我们的例子中就是在数据库中插入一条订单记录。</p><p>最后，根据半消息发送的结果和本地事务执行的结果，来决定提交或者回滚事务。在实现方法endTransaction()中，producer就是给Broker发送了一个单向的RPC请求，告知Broker完成事务的提交或者回滚。由于有事务反查的机制来兜底，这个RPC请求即使失败或者丢失，也都不会影响事务最终的结果。最后构建事务消息的发送结果，并返回。</p><p>以上，就是RocketMQ在Producer这一端事务消息的实现，然后我们再看一下Broker这一端，它是怎么来处理事务消息和进行事务反查的。</p><p>Broker在处理Producer发送消息的请求时，会根据消息中的属性判断一下，这条消息是普通消息还是半消息：</p><pre><code>// ...\nif (traFlag != null &amp;&amp; Boolean.parseBoolean(traFlag)) {\n    // ...\n    putMessageResult = this.brokerController.getTransactionalMessageService().prepareMessage(msgInner);\n} else {\n    putMessageResult = this.brokerController.getMessageStore().putMessage(msgInner);\n}\n// ...\n</code></pre><p>这段代码在org.apache.rocketmq.broker.processor.SendMessageProcessor#sendMessage方法中，然后我们跟进去看看真正处理半消息的业务逻辑，这段处理逻辑在类org.apache.rocketmq.broker.transaction.queue.TransactionalMessageBridge中：</p><pre><code>public PutMessageResult putHalfMessage(MessageExtBrokerInner messageInner) {\n    return store.putMessage(parseHalfMessageInner(messageInner));\n}\n\nprivate MessageExtBrokerInner parseHalfMessageInner(MessageExtBrokerInner msgInner) {\n\n    // 记录消息的主题和队列，到新的属性中\n    MessageAccessor.putProperty(msgInner, MessageConst.PROPERTY_REAL_TOPIC, msgInner.getTopic());\n    MessageAccessor.putProperty(msgInner, MessageConst.PROPERTY_REAL_QUEUE_ID,\n        String.valueOf(msgInner.getQueueId()));\n    msgInner.setSysFlag(\n        MessageSysFlag.resetTransactionValue(msgInner.getSysFlag(), MessageSysFlag.TRANSACTION_NOT_TYPE));\n    // 替换消息的主题和队列为：RMQ_SYS_TRANS_HALF_TOPIC，0\n    msgInner.setTopic(TransactionalMessageUtil.buildHalfTopic());\n    msgInner.setQueueId(0);\n    msgInner.setPropertiesString(MessageDecoder.messageProperties2String(msgInner.getProperties()));\n    return msgInner;\n}\n</code></pre><p>我们可以看到，在这段代码中，RocketMQ并没有把半消息保存到消息中客户端指定的那个队列中，而是记录了原始的主题队列后，把这个半消息保存在了一个特殊的内部主题RMQ_SYS_TRANS_HALF_TOPIC中，使用的队列号固定为0。这个主题和队列对消费者是不可见的，所以里面的消息永远不会被消费。这样，就保证了在事务提交成功之前，这个半消息对消费者来说是消费不到的。</p><p>然后我们再看一下，RocketMQ是如何进行事务反查的：在Broker的TransactionalMessageCheckService服务中启动了一个定时器，定时从半消息队列中读出所有待反查的半消息，针对每个需要反查的半消息，Broker会给对应的Producer发一个要求执行事务状态反查的RPC请求，这部分的逻辑在方法org.apache.rocketmq.broker.transaction.AbstractTransactionalMessageCheckListener#sendCheckMessage中，根据RPC返回响应中的反查结果，来决定这个半消息是需要提交还是回滚，或者后续继续来反查。</p><p>最后，提交或者回滚事务实现的逻辑是差不多的，首先把半消息标记为已处理，如果是提交事务，那就把半消息从半消息队列中复制到这个消息真正的主题和队列中去，如果要回滚事务，这一步什么都不需要做，最后结束这个事务。这部分逻辑的实现在org.apache.rocketmq.broker.processor.EndTransactionProcessor这个类中。</p><h2>Kafka的事务和Exactly Once可以解决什么问题？</h2><p>接下来我们再说一下Kafka的事务。之前我们讲事务的时候说过，Kafka的事务解决的问题和RocketMQ是不太一样的。RocketMQ中的事务，它解决的问题是，确保执行本地事务和发消息这两个操作，要么都成功，要么都失败。并且，RocketMQ增加了一个事务反查的机制，来尽量提高事务执行的成功率和数据一致性。</p><p>而Kafka中的事务，它解决的问题是，确保在一个事务中发送的多条消息，要么都成功，要么都失败。注意，这里面的多条消息不一定要在同一个主题和分区中，可以是发往多个主题和分区的消息。当然，你可以在Kafka的事务执行过程中，加入本地事务，来实现和RocketMQ中事务类似的效果，但是Kafka是没有事务反查机制的。</p><p>Kafka的这种事务机制，单独来使用的场景不多。更多的情况下被用来配合Kafka的幂等机制来实现Kafka 的Exactly Once语义。我在之前的课程中也强调过，这里面的Exactly Once，和我们通常理解的消息队列的服务水平中的Exactly Once是不一样的。</p><p>我们通常理解消息队列的服务水平中的Exactly Once，它指的是，消息从生产者发送到Broker，然后消费者再从Broker拉取消息，然后进行消费。这个过程中，确保每一条消息恰好传输一次，不重不丢。我们之前说过，包括Kafka在内的几个常见的开源消息队列，都只能做到At Least Once，也就是至少一次，保证消息不丢，但有可能会重复。做不到Exactly Once。</p><p><img src=\"https://static001.geekbang.org/resource/image/ac/40/ac330e3e22b0114f5642491889510940.png?wh=354*91\" alt=\"\"></p><p>那Kafka中的Exactly Once又是解决的什么问题呢？它解决的是，在流计算中，用Kafka作为数据源，并且将计算结果保存到Kafka这种场景下，数据从Kafka的某个主题中消费，在计算集群中计算，再把计算结果保存在Kafka的其他主题中。这样的过程中，保证每条消息都被恰好计算一次，确保计算结果正确。</p><p><img src=\"https://static001.geekbang.org/resource/image/15/ff/15f8776de71b79cc232d8b60c3c24bff.png?wh=435*82\" alt=\"\"></p><p>举个例子，比如，我们把所有订单消息保存在一个Kafka的主题Order中，在Flink集群中运行一个计算任务，统计每分钟的订单收入，然后把结果保存在另一个Kafka的主题Income里面。要保证计算结果准确，就要确保，无论是Kafka集群还是Flink集群中任何节点发生故障，每条消息都只能被计算一次，不能重复计算，否则计算结果就错了。这里面有一个很重要的限制条件，就是数据必须来自Kafka并且计算结果都必须保存到Kafka中，才可以享受到Kafka的Excactly Once机制。</p><p>可以看到，Kafka的Exactly Once机制，是为了解决在“读数据-计算-保存结果”这样的计算过程中数据不重不丢，而不是我们通常理解的使用消息队列进行消息生产消费过程中的Exactly Once。</p><h2>Kafka的事务是如何实现的？</h2><p>那Kafka的事务又是怎么实现的呢？它的实现原理和RocketMQ的事务是差不多的，都是基于两阶段提交来实现的，但是实现的过程更加复杂。</p><p>首先说一下，参与Kafka事务的几个角色，或者说是模块。为了解决分布式事务问题，Kafka引入了事务协调者这个角色，负责在服务端协调整个事务。这个协调者并不是一个独立的进程，而是Broker进程的一部分，协调者和分区一样通过选举来保证自身的可用性。</p><p>和RocketMQ类似，Kafka集群中也有一个特殊的用于记录事务日志的主题，这个事务日志主题的实现和普通的主题是一样的，里面记录的数据就是类似于“开启事务”“提交事务”这样的事务日志。日志主题同样也包含了很多的分区。在Kafka集群中，可以存在多个协调者，每个协调者负责管理和使用事务日志中的几个分区。这样设计，其实就是为了能并行执行多个事务，提升性能。</p><p><img src=\"https://static001.geekbang.org/resource/image/c8/f4/c8c286a5e32ee324c8a32ba967d1f2f4.png?wh=1024*693\" alt=\"\"><br>\n（图片来源：<a href=\"https://www.confluent.io/blog/transactions-apache-kafka/\">Kafka官方</a>）</p><p>下面说一下Kafka事务的实现流程。</p><p>首先，当我们开启事务的时候，生产者会给协调者发一个请求来开启事务，协调者在事务日志中记录下事务ID。</p><p>然后，生产者在发送消息之前，还要给协调者发送请求，告知发送的消息属于哪个主题和分区，这个信息也会被协调者记录在事务日志中。接下来，生产者就可以像发送普通消息一样来发送事务消息，这里和RocketMQ不同的是，RocketMQ选择把未提交的事务消息保存在特殊的队列中，而Kafka在处理未提交的事务消息时，和普通消息是一样的，直接发给Broker，保存在这些消息对应的分区中，Kafka会在客户端的消费者中，暂时过滤未提交的事务消息。</p><p>消息发送完成后，生产者给协调者发送提交或回滚事务的请求，由协调者来开始两阶段提交，完成事务。第一阶段，协调者把事务的状态设置为“预提交”，并写入事务日志。到这里，实际上事务已经成功了，无论接下来发生什么情况，事务最终都会被提交。</p><p>之后便开始第二阶段，协调者在事务相关的所有分区中，都会写一条“事务结束”的特殊消息，当Kafka的消费者，也就是客户端，读到这个事务结束的特殊消息之后，它就可以把之前暂时过滤的那些未提交的事务消息，放行给业务代码进行消费了。最后，协调者记录最后一条事务日志，标识这个事务已经结束了。</p><p>我把整个事务的实现流程，绘制成一个简单的时序图放在这里，便于你理解。</p><p><img src=\"https://static001.geekbang.org/resource/image/27/fe/27742f00f70ead8c7194ef1aab503efe.png?wh=654*570\" alt=\"\"></p><p>总结一下Kafka这个两阶段的流程，准备阶段，生产者发消息给协调者开启事务，然后消息发送到每个分区上。提交阶段，生产者发消息给协调者提交事务，协调者给每个分区发一条“事务结束”的消息，完成分布式事务提交。</p><h2>小结</h2><p>这节课我分别讲解了Kafka和RocketMQ是如何来实现事务的。你可以看到，它们在实现事务过程中的一些共同的地方，它们都是基于两阶段提交来实现的事务，都利用了特殊的主题中的队列和分区来记录事务日志。</p><p>不同之处在于对处于事务中的消息的处理方式，RocketMQ是把这些消息暂存在一个特殊的队列中，待事务提交后再移动到业务队列中；而Kafka直接把消息放到对应的业务分区中，配合客户端过滤来暂时屏蔽进行中的事务消息。</p><p>同时你需要了解，RocketMQ和Kafka的事务，它们的适用场景是不一样的，RocketMQ的事务适用于解决本地事务和发消息的数据一致性问题，而Kafka的事务则是用于实现它的Exactly Once机制，应用于实时计算的场景中。</p><h2>思考题</h2><p>课后，请你根据我们课程中讲到的Kafka事务的实现流程，去Kafka的源代码中把这个事务的实现流程分析出来，将我们上面这个时序图进一步细化，绘制一个粒度到类和方法调用的时序图。然后请你想一下，如果事务进行过程中，协调者宕机了，那事务又是如何恢复的呢？欢迎你在评论区留言，写下你的想法。</p><p>感谢阅读，如果你觉得这篇文章对你有一些启发，也欢迎把它分享给你的朋友。</p><p></p>","neighbors":{"left":{"article_title":"24 | Kafka的协调服务ZooKeeper：实现分布式系统的“瑞士军刀”","id":137655},"right":{"article_title":"26 | MQTT协议：如何支持海量的在线IoT设备?","id":139968}},"comments":[{"had_liked":false,"id":215086,"user_name":"丁小明","can_delete":false,"product_type":"c1","uid":1207622,"ip_address":"","ucode":"CC23857B8D75D5","user_header":"https://static001.geekbang.org/account/avatar/00/12/6d/46/e16291f8.jpg","comment_is_top":false,"comment_ctime":1588902037,"is_pvip":false,"replies":[{"id":79937,"content":"是这样的。","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1589170720,"ip_address":"","comment_id":215086,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"也就是说其实kafka的Exactly Once模式，是kafka的consumer通过PID去实现了一个幂等操作，原理上来说是和at last once我们业务自己通过其他唯一ID实现幂等是一样的效果,并不是正真的只传输到客户端一次，而是重复传输实现了幂等。","like_count":25},{"had_liked":false,"id":216820,"user_name":"ξ！","can_delete":false,"product_type":"c1","uid":1636657,"ip_address":"","ucode":"F9797D21EBE10E","user_header":"https://static001.geekbang.org/account/avatar/00/18/f9/31/b75cc6d5.jpg","comment_is_top":false,"comment_ctime":1589349867,"is_pvip":false,"replies":[{"id":80330,"content":"考虑这种情况：\n\n1. 客户端提交了本地事务；\n2. 本地事务在数据库执行成功了。\n3. 这个时候客户端宕机了；\n\n这种情况下，就没法保证一致性了。","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1589461803,"ip_address":"","comment_id":216820,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"老师，如果本地事务是有返回值的话可不可以先执行本地事务如果有异常就抛出,再去执行发送消息,因为现在这么写获取不到执行完本地事务的结果呀","like_count":12,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":494309,"discussion_content":"是这样的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589170720,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":205056,"user_name":"二明儿","can_delete":false,"product_type":"c1","uid":1132657,"ip_address":"","ucode":"CFF4C5B67390DB","user_header":"https://static001.geekbang.org/account/avatar/00/11/48/71/bee9bca5.jpg","comment_is_top":false,"comment_ctime":1586517174,"is_pvip":false,"replies":[{"id":77035,"content":"大量未提交消息对客户端内存影响不大，因为Kafka客户端有一个固定大小的buffer用来保存拉取的消息。\n\n只要你遵循：先执行消费业务逻辑，再提交，这样的原则。\n\n即使客户端重启或者Rebalance，也不会丢消息。","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1586833208,"ip_address":"","comment_id":205056,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"老师好，请教个问题，kafka consumer将事务未提交的消息 在客户端过滤后不放行给业务代码消费，如果这样如果有大量未提交的消息对于客户端端内存会不会有影响？如果这个时候客户端重启或者发生reblance，offset已经提交会不会导致消息丢失？","like_count":7,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":494958,"discussion_content":"考虑这种情况：\n\n1. 客户端提交了本地事务；\n2. 本地事务在数据库执行成功了。\n3. 这个时候客户端宕机了；\n\n这种情况下，就没法保证一致性了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589461803,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1357950,"avatar":"https://static001.geekbang.org/account/avatar/00/14/b8/7e/a5b44325.jpg","nickname":"Howard Chow","note":"","ucode":"554D6A268D3C28","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":345258,"discussion_content":"楼主的意思可能是，执行本地事务，但先不提交，因为在执行事务期间是可能发生错误的，对于提交事务的流程仍然应该是先发送消息再提交本地事务。\n但个人觉得，仍然应该先发消息再执行事务，因为发消息涉及到的网络通讯会相对较耗时，本地事务如果先执行，那么可能在某些时候会导致锁行锁表时间拉长，容易导致死锁之类的事件发生。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1611707616,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":144460,"user_name":"weilai","can_delete":false,"product_type":"c1","uid":1134329,"ip_address":"","ucode":"716945DDC77CEA","user_header":"https://static001.geekbang.org/account/avatar/00/11/4e/f9/b12388bd.jpg","comment_is_top":false,"comment_ctime":1571928302,"is_pvip":true,"replies":[{"id":55712,"content":"以官网文档和代码为准吧，至少目前的版本是没有变化的。\n\nhttps:&#47;&#47;rocketmq.apache.org&#47;docs&#47;transaction-example&#47;","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1571970926,"ip_address":"","comment_id":144460,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"查好像很多博客都说阿里已经把RocketMQ的这个反查接口给干掉了？老师，是这样吗？遇到这种问题，您是怎么找到答案的？","like_count":6,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491369,"discussion_content":"大量未提交消息对客户端内存影响不大，因为Kafka客户端有一个固定大小的buffer用来保存拉取的消息。\n\n只要你遵循：先执行消费业务逻辑，再提交，这样的原则。\n\n即使客户端重启或者Rebalance，也不会丢消息。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586833208,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1522220,"avatar":"https://static001.geekbang.org/account/avatar/00/17/3a/2c/683ae4af.jpg","nickname":"豆花羹","note":"","ucode":"57D8F64988C305","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":565297,"discussion_content":"这样重启，会不会很容易造成重复消费？事务未提交消息后面的消息，假如已经消费了，是会被记录的么，还是只能从未提交消息再消费一轮。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1650433111,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":138072,"user_name":"jack","can_delete":false,"product_type":"c1","uid":1612614,"ip_address":"","ucode":"5A26761299F7AC","user_header":"https://static001.geekbang.org/account/avatar/00/18/9b/46/ad3194bd.jpg","comment_is_top":false,"comment_ctime":1570008825,"is_pvip":false,"replies":[{"id":53142,"content":"是这样的","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1570080587,"ip_address":"","comment_id":138072,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"老师，如果仅仅把kafka作为数据源，流计算的结果保存到了其他数据库中，是不是就用不到kafka的事务了呢？","like_count":6,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":471951,"discussion_content":"以官网文档和代码为准吧，至少目前的版本是没有变化的。\n\nhttps://rocketmq.apache.org/docs/transaction-example/","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1571970926,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1207622,"avatar":"https://static001.geekbang.org/account/avatar/00/12/6d/46/e16291f8.jpg","nickname":"丁小明","note":"","ucode":"CC23857B8D75D5","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":260734,"discussion_content":"其中有一个版本确实是干掉了，但是后来又加了回去","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588898525,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":135098,"user_name":"miniluo","can_delete":false,"product_type":"c1","uid":1397339,"ip_address":"","ucode":"5735B6DEE7902B","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/FheCgo4Ovibo0L1vAGgMdZkzQMm1GUMHMMqQ8aglufXaD2hW9z96DjQicAam723jOCZwXVmiaNiaaq4PLsf4COibZ5A/132","comment_is_top":false,"comment_ctime":1569025189,"is_pvip":false,"replies":[{"id":51959,"content":"会一直定时轮询，直到有结果或者超时。","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1569202010,"ip_address":"","comment_id":135098,"utype":1}],"discussion_count":4,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"老师，有个疑问：文中说到rocketmq#checkLocalTransaction这个方法反查到可能本地事务还在提交中就返回了unknow，那后续呢？还会通过定时轮询检查？求解，谢谢","like_count":6,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":469373,"discussion_content":"是这样的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570080587,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":138454,"user_name":"不惑ing","can_delete":false,"product_type":"c1","uid":1207079,"ip_address":"","ucode":"AF04E417D38027","user_header":"https://static001.geekbang.org/account/avatar/00/12/6b/27/8c964e52.jpg","comment_is_top":false,"comment_ctime":1570252991,"is_pvip":false,"replies":[{"id":53316,"content":"可以这么理解，Kafka没有RocketMQ的事务反查补偿机制。","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1570364576,"ip_address":"","comment_id":138454,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"&#39; Kafka 的事务则是用于实现它的 Exactly Once 机制，应用于实时计算的场景中。&#39;这句话的意思理解为kafka的事务针对本地事务和发消息一致性没有rocketmq好，但是也可以用，这样理解对吗？","like_count":5,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":468047,"discussion_content":"会一直定时轮询，直到有结果或者超时。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1569202010,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1181055,"avatar":"https://static001.geekbang.org/account/avatar/00/12/05/7f/a7df049a.jpg","nickname":"Standly","note":"","ucode":"805CC5784D3F76","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":40211,"discussion_content":"或者超过最大检查次数，这个次数可配置","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1572106069,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1094726,"avatar":"https://static001.geekbang.org/account/avatar/00/10/b4/46/686f5abe.jpg","nickname":"SnoWalker","note":"","ucode":"826A3DE7E3AEC9","race_medal":1,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":18264,"discussion_content":"你可以参考一下我写的这篇文章，对第二阶段事务提交与回查进行了源码解析，希望能帮到你。\nhttp://wuwenliang.net/2019/09/01/%E8%B7%9F%E6%88%91%E5%AD%A6RocektMQ%E4%B9%8B%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF%E6%8F%90%E4%BA%A4%E5%8F%8A%E5%9B%9E%E6%9F%A5%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/\n\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1569038246,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1094726,"avatar":"https://static001.geekbang.org/account/avatar/00/10/b4/46/686f5abe.jpg","nickname":"SnoWalker","note":"","ucode":"826A3DE7E3AEC9","race_medal":1,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":18263,"discussion_content":"broker会以默认一分钟为间隔，对消息状态为未提交的半消息进行定时回查，直到超时之前都会一直进行回查。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1569038180,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":145042,"user_name":"A9","can_delete":false,"product_type":"c1","uid":1053211,"ip_address":"","ucode":"76D07F8EBE8DD0","user_header":"https://static001.geekbang.org/account/avatar/00/10/12/1b/f62722ca.jpg","comment_is_top":false,"comment_ctime":1572168706,"is_pvip":false,"replies":[{"id":56033,"content":"一般来说不会，因为如果是已经关闭的事务，就不会再去读它对应的半消息了。\n\n由于事务的超时机制存在，一般来说，活动的事务的日志大多都在commit log的尾部。","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1572242607,"ip_address":"","comment_id":145042,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"请问老师，失败的半消息也是在commit log中存储着吧。如果失败的事务消息存储过多，会不会导致在读取commit log时频繁触发缺页？","like_count":3,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":469525,"discussion_content":"可以这么理解，Kafka没有RocketMQ的事务反查补偿机制。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570364576,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":135533,"user_name":"lmtoo","can_delete":false,"product_type":"c1","uid":1133918,"ip_address":"","ucode":"FCD5B9C941D448","user_header":"https://static001.geekbang.org/account/avatar/00/11/4d/5e/c5c62933.jpg","comment_is_top":false,"comment_ctime":1569205750,"is_pvip":false,"replies":[{"id":52055,"content":"事务结束消息就是一条特殊的消息，和普通消息一样保存在分区中。同普通消息一样，事务结束消息只要不被删除，就会一直存在。","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1569291096,"ip_address":"","comment_id":135533,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"kafka的第二阶段，事务协调者发送给每个分区的事务结束的消息，每个分区是怎么处理这个事务结束的消息的？这个事务结束的消息保存到哪儿了？是不是消费者挂机重启之后，事务结束的消息就没了？","like_count":3,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":468235,"discussion_content":"事务结束消息就是一条特殊的消息，和普通消息一样保存在分区中。同普通消息一样，事务结束消息只要不被删除，就会一直存在。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1569291096,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":232836,"user_name":"jian","can_delete":false,"product_type":"c1","uid":1185102,"ip_address":"","ucode":"21CDBBB8000F0C","user_header":"https://static001.geekbang.org/account/avatar/00/12/15/4e/4636a81d.jpg","comment_is_top":false,"comment_ctime":1594126672,"is_pvip":false,"replies":[{"id":86779,"content":"是这样的。","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1594901276,"ip_address":"","comment_id":232836,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"请问老师，这里说“消息发送完成后，生产者给协调者发送提交或回滚事务的请求，由协调者来开始两阶段提交，完成事务。第一阶段，协调者把事务的状态设置为“预提交”，并写入事务日志。到这里，实际上事务已经成功了，无论接下来发生什么情况，事务最终都会被提交。”假如协调者执行完第一阶段之后还没有执行第二阶段，这时候机器宕机或者进程被KILL掉了，是不是重启之后会继续执行第二阶段呢？","like_count":2,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":468235,"discussion_content":"事务结束消息就是一条特殊的消息，和普通消息一样保存在分区中。同普通消息一样，事务结束消息只要不被删除，就会一直存在。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1569291096,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":215086,"user_name":"丁小明","can_delete":false,"product_type":"c1","uid":1207622,"ip_address":"","ucode":"CC23857B8D75D5","user_header":"https://static001.geekbang.org/account/avatar/00/12/6d/46/e16291f8.jpg","comment_is_top":false,"comment_ctime":1588902037,"is_pvip":false,"replies":[{"id":79937,"content":"是这样的。","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1589170720,"ip_address":"","comment_id":215086,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"也就是说其实kafka的Exactly Once模式，是kafka的consumer通过PID去实现了一个幂等操作，原理上来说是和at last once我们业务自己通过其他唯一ID实现幂等是一样的效果,并不是正真的只传输到客户端一次，而是重复传输实现了幂等。","like_count":25,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":494309,"discussion_content":"是这样的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589170720,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":216820,"user_name":"ξ！","can_delete":false,"product_type":"c1","uid":1636657,"ip_address":"","ucode":"F9797D21EBE10E","user_header":"https://static001.geekbang.org/account/avatar/00/18/f9/31/b75cc6d5.jpg","comment_is_top":false,"comment_ctime":1589349867,"is_pvip":false,"replies":[{"id":80330,"content":"考虑这种情况：\n\n1. 客户端提交了本地事务；\n2. 本地事务在数据库执行成功了。\n3. 这个时候客户端宕机了；\n\n这种情况下，就没法保证一致性了。","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1589461803,"ip_address":"","comment_id":216820,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"老师，如果本地事务是有返回值的话可不可以先执行本地事务如果有异常就抛出,再去执行发送消息,因为现在这么写获取不到执行完本地事务的结果呀","like_count":12,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":494958,"discussion_content":"考虑这种情况：\n\n1. 客户端提交了本地事务；\n2. 本地事务在数据库执行成功了。\n3. 这个时候客户端宕机了；\n\n这种情况下，就没法保证一致性了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589461803,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1357950,"avatar":"https://static001.geekbang.org/account/avatar/00/14/b8/7e/a5b44325.jpg","nickname":"Howard Chow","note":"","ucode":"554D6A268D3C28","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":345258,"discussion_content":"楼主的意思可能是，执行本地事务，但先不提交，因为在执行事务期间是可能发生错误的，对于提交事务的流程仍然应该是先发送消息再提交本地事务。\n但个人觉得，仍然应该先发消息再执行事务，因为发消息涉及到的网络通讯会相对较耗时，本地事务如果先执行，那么可能在某些时候会导致锁行锁表时间拉长，容易导致死锁之类的事件发生。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1611707616,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":205056,"user_name":"二明儿","can_delete":false,"product_type":"c1","uid":1132657,"ip_address":"","ucode":"CFF4C5B67390DB","user_header":"https://static001.geekbang.org/account/avatar/00/11/48/71/bee9bca5.jpg","comment_is_top":false,"comment_ctime":1586517174,"is_pvip":false,"replies":[{"id":77035,"content":"大量未提交消息对客户端内存影响不大，因为Kafka客户端有一个固定大小的buffer用来保存拉取的消息。\n\n只要你遵循：先执行消费业务逻辑，再提交，这样的原则。\n\n即使客户端重启或者Rebalance，也不会丢消息。","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1586833208,"ip_address":"","comment_id":205056,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"老师好，请教个问题，kafka consumer将事务未提交的消息 在客户端过滤后不放行给业务代码消费，如果这样如果有大量未提交的消息对于客户端端内存会不会有影响？如果这个时候客户端重启或者发生reblance，offset已经提交会不会导致消息丢失？","like_count":7,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491369,"discussion_content":"大量未提交消息对客户端内存影响不大，因为Kafka客户端有一个固定大小的buffer用来保存拉取的消息。\n\n只要你遵循：先执行消费业务逻辑，再提交，这样的原则。\n\n即使客户端重启或者Rebalance，也不会丢消息。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586833208,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1522220,"avatar":"https://static001.geekbang.org/account/avatar/00/17/3a/2c/683ae4af.jpg","nickname":"豆花羹","note":"","ucode":"57D8F64988C305","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":565297,"discussion_content":"这样重启，会不会很容易造成重复消费？事务未提交消息后面的消息，假如已经消费了，是会被记录的么，还是只能从未提交消息再消费一轮。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1650433111,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":144460,"user_name":"weilai","can_delete":false,"product_type":"c1","uid":1134329,"ip_address":"","ucode":"716945DDC77CEA","user_header":"https://static001.geekbang.org/account/avatar/00/11/4e/f9/b12388bd.jpg","comment_is_top":false,"comment_ctime":1571928302,"is_pvip":true,"replies":[{"id":55712,"content":"以官网文档和代码为准吧，至少目前的版本是没有变化的。\n\nhttps:&#47;&#47;rocketmq.apache.org&#47;docs&#47;transaction-example&#47;","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1571970926,"ip_address":"","comment_id":144460,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"查好像很多博客都说阿里已经把RocketMQ的这个反查接口给干掉了？老师，是这样吗？遇到这种问题，您是怎么找到答案的？","like_count":6,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":471951,"discussion_content":"以官网文档和代码为准吧，至少目前的版本是没有变化的。\n\nhttps://rocketmq.apache.org/docs/transaction-example/","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1571970926,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1207622,"avatar":"https://static001.geekbang.org/account/avatar/00/12/6d/46/e16291f8.jpg","nickname":"丁小明","note":"","ucode":"CC23857B8D75D5","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":260734,"discussion_content":"其中有一个版本确实是干掉了，但是后来又加了回去","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588898525,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":138072,"user_name":"jack","can_delete":false,"product_type":"c1","uid":1612614,"ip_address":"","ucode":"5A26761299F7AC","user_header":"https://static001.geekbang.org/account/avatar/00/18/9b/46/ad3194bd.jpg","comment_is_top":false,"comment_ctime":1570008825,"is_pvip":false,"replies":[{"id":53142,"content":"是这样的","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1570080587,"ip_address":"","comment_id":138072,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"老师，如果仅仅把kafka作为数据源，流计算的结果保存到了其他数据库中，是不是就用不到kafka的事务了呢？","like_count":6,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":469373,"discussion_content":"是这样的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570080587,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":135098,"user_name":"miniluo","can_delete":false,"product_type":"c1","uid":1397339,"ip_address":"","ucode":"5735B6DEE7902B","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/FheCgo4Ovibo0L1vAGgMdZkzQMm1GUMHMMqQ8aglufXaD2hW9z96DjQicAam723jOCZwXVmiaNiaaq4PLsf4COibZ5A/132","comment_is_top":false,"comment_ctime":1569025189,"is_pvip":false,"replies":[{"id":51959,"content":"会一直定时轮询，直到有结果或者超时。","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1569202010,"ip_address":"","comment_id":135098,"utype":1}],"discussion_count":4,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"老师，有个疑问：文中说到rocketmq#checkLocalTransaction这个方法反查到可能本地事务还在提交中就返回了unknow，那后续呢？还会通过定时轮询检查？求解，谢谢","like_count":6,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":468047,"discussion_content":"会一直定时轮询，直到有结果或者超时。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1569202010,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1181055,"avatar":"https://static001.geekbang.org/account/avatar/00/12/05/7f/a7df049a.jpg","nickname":"Standly","note":"","ucode":"805CC5784D3F76","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":40211,"discussion_content":"或者超过最大检查次数，这个次数可配置","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1572106069,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1094726,"avatar":"https://static001.geekbang.org/account/avatar/00/10/b4/46/686f5abe.jpg","nickname":"SnoWalker","note":"","ucode":"826A3DE7E3AEC9","race_medal":1,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":18264,"discussion_content":"你可以参考一下我写的这篇文章，对第二阶段事务提交与回查进行了源码解析，希望能帮到你。\nhttp://wuwenliang.net/2019/09/01/%E8%B7%9F%E6%88%91%E5%AD%A6RocektMQ%E4%B9%8B%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF%E6%8F%90%E4%BA%A4%E5%8F%8A%E5%9B%9E%E6%9F%A5%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/\n\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1569038246,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1094726,"avatar":"https://static001.geekbang.org/account/avatar/00/10/b4/46/686f5abe.jpg","nickname":"SnoWalker","note":"","ucode":"826A3DE7E3AEC9","race_medal":1,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":18263,"discussion_content":"broker会以默认一分钟为间隔，对消息状态为未提交的半消息进行定时回查，直到超时之前都会一直进行回查。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1569038180,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":138454,"user_name":"不惑ing","can_delete":false,"product_type":"c1","uid":1207079,"ip_address":"","ucode":"AF04E417D38027","user_header":"https://static001.geekbang.org/account/avatar/00/12/6b/27/8c964e52.jpg","comment_is_top":false,"comment_ctime":1570252991,"is_pvip":false,"replies":[{"id":53316,"content":"可以这么理解，Kafka没有RocketMQ的事务反查补偿机制。","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1570364576,"ip_address":"","comment_id":138454,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"&#39; Kafka 的事务则是用于实现它的 Exactly Once 机制，应用于实时计算的场景中。&#39;这句话的意思理解为kafka的事务针对本地事务和发消息一致性没有rocketmq好，但是也可以用，这样理解对吗？","like_count":5,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":469525,"discussion_content":"可以这么理解，Kafka没有RocketMQ的事务反查补偿机制。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570364576,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":145042,"user_name":"A9","can_delete":false,"product_type":"c1","uid":1053211,"ip_address":"","ucode":"76D07F8EBE8DD0","user_header":"https://static001.geekbang.org/account/avatar/00/10/12/1b/f62722ca.jpg","comment_is_top":false,"comment_ctime":1572168706,"is_pvip":false,"replies":[{"id":56033,"content":"一般来说不会，因为如果是已经关闭的事务，就不会再去读它对应的半消息了。\n\n由于事务的超时机制存在，一般来说，活动的事务的日志大多都在commit log的尾部。","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1572242607,"ip_address":"","comment_id":145042,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"请问老师，失败的半消息也是在commit log中存储着吧。如果失败的事务消息存储过多，会不会导致在读取commit log时频繁触发缺页？","like_count":3,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":472222,"discussion_content":"一般来说不会，因为如果是已经关闭的事务，就不会再去读它对应的半消息了。\n\n由于事务的超时机制存在，一般来说，活动的事务的日志大多都在commit log的尾部。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1572242607,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":135533,"user_name":"lmtoo","can_delete":false,"product_type":"c1","uid":1133918,"ip_address":"","ucode":"FCD5B9C941D448","user_header":"https://static001.geekbang.org/account/avatar/00/11/4d/5e/c5c62933.jpg","comment_is_top":false,"comment_ctime":1569205750,"is_pvip":false,"replies":[{"id":52055,"content":"事务结束消息就是一条特殊的消息，和普通消息一样保存在分区中。同普通消息一样，事务结束消息只要不被删除，就会一直存在。","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1569291096,"ip_address":"","comment_id":135533,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"kafka的第二阶段，事务协调者发送给每个分区的事务结束的消息，每个分区是怎么处理这个事务结束的消息的？这个事务结束的消息保存到哪儿了？是不是消费者挂机重启之后，事务结束的消息就没了？","like_count":3,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":472222,"discussion_content":"一般来说不会，因为如果是已经关闭的事务，就不会再去读它对应的半消息了。\n\n由于事务的超时机制存在，一般来说，活动的事务的日志大多都在commit log的尾部。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1572242607,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":232836,"user_name":"jian","can_delete":false,"product_type":"c1","uid":1185102,"ip_address":"","ucode":"21CDBBB8000F0C","user_header":"https://static001.geekbang.org/account/avatar/00/12/15/4e/4636a81d.jpg","comment_is_top":false,"comment_ctime":1594126672,"is_pvip":false,"replies":[{"id":86779,"content":"是这样的。","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1594901276,"ip_address":"","comment_id":232836,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100032301,"comment_content":"请问老师，这里说“消息发送完成后，生产者给协调者发送提交或回滚事务的请求，由协调者来开始两阶段提交，完成事务。第一阶段，协调者把事务的状态设置为“预提交”，并写入事务日志。到这里，实际上事务已经成功了，无论接下来发生什么情况，事务最终都会被提交。”假如协调者执行完第一阶段之后还没有执行第二阶段，这时候机器宕机或者进程被KILL掉了，是不是重启之后会继续执行第二阶段呢？","like_count":2,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":500784,"discussion_content":"是这样的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1594901276,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":145578,"user_name":"我已经设置了昵称","can_delete":false,"product_type":"c1","uid":1364034,"ip_address":"","ucode":"ED672C5EBDBDC4","user_header":"https://static001.geekbang.org/account/avatar/00/14/d0/42/6fd01fb9.jpg","comment_is_top":false,"comment_ctime":1572319532,"is_pvip":false,"replies":[{"id":56294,"content":"在第30节课中会讲到Kafka事务的用途。","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1572397015,"ip_address":"","comment_id":145578,"utype":1}],"discussion_count":2,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"kafka的事务消息和rocketmq的只是比rocketmq少了个反查机制。忽略内部的实现，可以这么理解吧。可是老师貌似没有讲过如何使用kafka的事务消息呢","like_count":0},{"had_liked":false,"id":244358,"user_name":"Laputa","can_delete":false,"product_type":"c1","uid":1079345,"ip_address":"","ucode":"64C157042CF138","user_header":"https://static001.geekbang.org/account/avatar/00/10/78/31/c7f8d1db.jpg","comment_is_top":false,"comment_ctime":1598492202,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"文中提到的“Kafka 会在客户端的消费者中，暂时过滤未提交的事务消息。”，这里说的过滤具体是什么意思呢，一个分区里可以同时存在事务消息和非事务消息吗？如果可以同时存在，那这里的过滤会不会导致前面的事务消息没提交但后面的非事务消息被消费了？所以说文中提到的过滤是指客户端发现当前消费的消息是没提交的就一直卡在那直到提交或回滚吗？","like_count":2},{"had_liked":false,"id":354824,"user_name":"尔东橙","can_delete":false,"product_type":"c1","uid":1225224,"ip_address":"湖南","ucode":"0B013A49BC18DA","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/6LaITPQ4Lk5fZn8ib1tfsPW8vI9icTuSwAddiajVfibPDiaDvMU2br6ZT7K0LWCKibSQuicT7sIEVmY4K7ibXY0T7UQEiag/132","comment_is_top":false,"comment_ctime":1660807244,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"orderId 属性是不是要在createMessageRequest的时候给设置进去","like_count":1},{"had_liked":false,"id":354823,"user_name":"尔东橙","can_delete":false,"product_type":"c1","uid":1225224,"ip_address":"湖南","ucode":"0B013A49BC18DA","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/6LaITPQ4Lk5fZn8ib1tfsPW8vI9icTuSwAddiajVfibPDiaDvMU2br6ZT7K0LWCKibSQuicT7sIEVmY4K7ibXY0T7UQEiag/132","comment_is_top":false,"comment_ctime":1660806623,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"createMessage(request)内容是啥","like_count":1},{"had_liked":false,"id":309467,"user_name":"SinKitwah","can_delete":false,"product_type":"c1","uid":1478242,"ip_address":"","ucode":"BC39A39E17C95E","user_header":"https://static001.geekbang.org/account/avatar/00/16/8e/62/435148c1.jpg","comment_is_top":false,"comment_ctime":1630149652,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"我可以理解为这个kafka的事务主要作用点是在计算集群到kafka b的那一块吗？是不是把kafka a换成rocket mq也能达到一样的事务效果呢？","like_count":1},{"had_liked":false,"id":296041,"user_name":"Wheat Liu","can_delete":false,"product_type":"c1","uid":1260141,"ip_address":"","ucode":"7D99EA149B6DE8","user_header":"https://static001.geekbang.org/account/avatar/00/13/3a/6d/8b417c84.jpg","comment_is_top":false,"comment_ctime":1622714386,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"最喜欢这节课，老师指明源码位置之后，rocketmq的逻辑简单易懂","like_count":1},{"had_liked":false,"id":279273,"user_name":"Heaven","can_delete":false,"product_type":"c1","uid":1694207,"ip_address":"","ucode":"FA33FBCC66C911","user_header":"https://static001.geekbang.org/account/avatar/00/19/d9/ff/b23018a6.jpg","comment_is_top":false,"comment_ctime":1613702567,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"Kafka是将事务的控制全权交给了生产者,没有RMQ的反查稳定\n至于,宕机后如何恢复事务,Kafka在每一步的操作之后都进行录入到了日志中,大可不必担心从日志中恢复事务","like_count":1},{"had_liked":false,"id":249727,"user_name":"翠羽香凝","can_delete":false,"product_type":"c1","uid":1119933,"ip_address":"","ucode":"54F3762F0E545F","user_header":"https://static001.geekbang.org/account/avatar/00/11/16/bd/e14ba493.jpg","comment_is_top":false,"comment_ctime":1600772030,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"二阶段提交，最大的问题是，第二阶段协调者发送了commit消息后，部分参与者成功，其他参与者失败，而同时协调者又宕机的情况。在这种情况下，失败的参与者会长期锁定资源无法释放，不知道kafka是如何解决这个问题的？","like_count":1,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":472477,"discussion_content":"在第30节课中会讲到Kafka事务的用途。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1572397015,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1327799,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eoro1y5n7l1Gq1vpzCRP9RJyNn5MuUz23PjYgSRbZ0aW0acUPufet09Pd5PFknB6ibtjXVZ3cQibevQ/132","nickname":"怪物老爷","note":"","ucode":"AFF9FBDA8E2F22","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":42317,"discussion_content":"期待","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1572632736,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":234656,"user_name":"ipromiseu","can_delete":false,"product_type":"c1","uid":1159317,"ip_address":"","ucode":"775E2CC0E7CA69","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erbUHD8KH3mYz39QuHj5BXB06VqCus5WR4oHfNuSYdPVLno3Tq61yhMiaugxpMicKibDFQ4KwX7icoDWQ/132","comment_is_top":false,"comment_ctime":1594742110,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"请问老师，两种事务消息都只是保证【生产者发送消息，生产者完成业务逻辑，消费者收到消息】的原子性，如果想保证【生产者发送消息，生产者完成业务逻辑，消费者收到消息，消费者完成业务逻辑】的院子性呢？","like_count":1,"discussions":[{"author":{"id":1487584,"avatar":"https://static001.geekbang.org/account/avatar/00/16/b2/e0/d856f5a4.jpg","nickname":"余松","note":"","ucode":"89EC9CE3AD0281","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":291321,"discussion_content":"【生产者发送消息，生产者完成业务逻辑，消费者收到消息，消费者完成业务逻辑】这个后半部分没有保证的必要，因为MQ的应用场景本来就是为了解耦Producer和Consumer。所以上面介绍事物关注的都是Producer到Broker，而消费者完成业务逻辑，你只需后面的时间点实现“接收消息-处理业务-确认”就可以了。你可以认为是原子性退化到了最终一致性来解耦了Producer和Consumer。","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1594779457,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":362241,"user_name":"学无涯","can_delete":false,"product_type":"c1","uid":1254493,"ip_address":"北京","ucode":"252754F9FCFF0C","user_header":"https://static001.geekbang.org/account/avatar/00/13/24/5d/65e61dcb.jpg","comment_is_top":false,"comment_ctime":1668333360,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"为什么用Kafka作为数据源，计算结果保存到其他数据库，就用不到事务了呢","like_count":0},{"had_liked":false,"id":145578,"user_name":"我已经设置了昵称","can_delete":false,"product_type":"c1","uid":1364034,"ip_address":"","ucode":"ED672C5EBDBDC4","user_header":"https://static001.geekbang.org/account/avatar/00/14/d0/42/6fd01fb9.jpg","comment_is_top":false,"comment_ctime":1572319532,"is_pvip":false,"replies":[{"id":56294,"content":"在第30节课中会讲到Kafka事务的用途。","user_name":"作者回复","user_name_real":"李玥","uid":1501046,"ctime":1572397015,"ip_address":"","comment_id":145578,"utype":1}],"discussion_count":2,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"kafka的事务消息和rocketmq的只是比rocketmq少了个反查机制。忽略内部的实现，可以这么理解吧。可是老师貌似没有讲过如何使用kafka的事务消息呢","like_count":0,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":472477,"discussion_content":"在第30节课中会讲到Kafka事务的用途。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1572397015,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1327799,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eoro1y5n7l1Gq1vpzCRP9RJyNn5MuUz23PjYgSRbZ0aW0acUPufet09Pd5PFknB6ibtjXVZ3cQibevQ/132","nickname":"怪物老爷","note":"","ucode":"AFF9FBDA8E2F22","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":42317,"discussion_content":"期待","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1572632736,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":244358,"user_name":"Laputa","can_delete":false,"product_type":"c1","uid":1079345,"ip_address":"","ucode":"64C157042CF138","user_header":"https://static001.geekbang.org/account/avatar/00/10/78/31/c7f8d1db.jpg","comment_is_top":false,"comment_ctime":1598492202,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"文中提到的“Kafka 会在客户端的消费者中，暂时过滤未提交的事务消息。”，这里说的过滤具体是什么意思呢，一个分区里可以同时存在事务消息和非事务消息吗？如果可以同时存在，那这里的过滤会不会导致前面的事务消息没提交但后面的非事务消息被消费了？所以说文中提到的过滤是指客户端发现当前消费的消息是没提交的就一直卡在那直到提交或回滚吗？","like_count":2},{"had_liked":false,"id":354824,"user_name":"尔东橙","can_delete":false,"product_type":"c1","uid":1225224,"ip_address":"湖南","ucode":"0B013A49BC18DA","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/6LaITPQ4Lk5fZn8ib1tfsPW8vI9icTuSwAddiajVfibPDiaDvMU2br6ZT7K0LWCKibSQuicT7sIEVmY4K7ibXY0T7UQEiag/132","comment_is_top":false,"comment_ctime":1660807244,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"orderId 属性是不是要在createMessageRequest的时候给设置进去","like_count":1},{"had_liked":false,"id":354823,"user_name":"尔东橙","can_delete":false,"product_type":"c1","uid":1225224,"ip_address":"湖南","ucode":"0B013A49BC18DA","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/6LaITPQ4Lk5fZn8ib1tfsPW8vI9icTuSwAddiajVfibPDiaDvMU2br6ZT7K0LWCKibSQuicT7sIEVmY4K7ibXY0T7UQEiag/132","comment_is_top":false,"comment_ctime":1660806623,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"createMessage(request)内容是啥","like_count":1},{"had_liked":false,"id":309467,"user_name":"SinKitwah","can_delete":false,"product_type":"c1","uid":1478242,"ip_address":"","ucode":"BC39A39E17C95E","user_header":"https://static001.geekbang.org/account/avatar/00/16/8e/62/435148c1.jpg","comment_is_top":false,"comment_ctime":1630149652,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"我可以理解为这个kafka的事务主要作用点是在计算集群到kafka b的那一块吗？是不是把kafka a换成rocket mq也能达到一样的事务效果呢？","like_count":1},{"had_liked":false,"id":296041,"user_name":"Wheat Liu","can_delete":false,"product_type":"c1","uid":1260141,"ip_address":"","ucode":"7D99EA149B6DE8","user_header":"https://static001.geekbang.org/account/avatar/00/13/3a/6d/8b417c84.jpg","comment_is_top":false,"comment_ctime":1622714386,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"最喜欢这节课，老师指明源码位置之后，rocketmq的逻辑简单易懂","like_count":1},{"had_liked":false,"id":279273,"user_name":"Heaven","can_delete":false,"product_type":"c1","uid":1694207,"ip_address":"","ucode":"FA33FBCC66C911","user_header":"https://static001.geekbang.org/account/avatar/00/19/d9/ff/b23018a6.jpg","comment_is_top":false,"comment_ctime":1613702567,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"Kafka是将事务的控制全权交给了生产者,没有RMQ的反查稳定\n至于,宕机后如何恢复事务,Kafka在每一步的操作之后都进行录入到了日志中,大可不必担心从日志中恢复事务","like_count":1},{"had_liked":false,"id":249727,"user_name":"翠羽香凝","can_delete":false,"product_type":"c1","uid":1119933,"ip_address":"","ucode":"54F3762F0E545F","user_header":"https://static001.geekbang.org/account/avatar/00/11/16/bd/e14ba493.jpg","comment_is_top":false,"comment_ctime":1600772030,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"二阶段提交，最大的问题是，第二阶段协调者发送了commit消息后，部分参与者成功，其他参与者失败，而同时协调者又宕机的情况。在这种情况下，失败的参与者会长期锁定资源无法释放，不知道kafka是如何解决这个问题的？","like_count":1,"discussions":[{"author":{"id":1494880,"avatar":"https://static001.geekbang.org/account/avatar/00/16/cf/60/9100ad4f.jpg","nickname":"周星平","note":"","ucode":"1FDCB487392B03","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":312394,"discussion_content":"协调者有集群","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1602677334,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":234656,"user_name":"ipromiseu","can_delete":false,"product_type":"c1","uid":1159317,"ip_address":"","ucode":"775E2CC0E7CA69","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erbUHD8KH3mYz39QuHj5BXB06VqCus5WR4oHfNuSYdPVLno3Tq61yhMiaugxpMicKibDFQ4KwX7icoDWQ/132","comment_is_top":false,"comment_ctime":1594742110,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"请问老师，两种事务消息都只是保证【生产者发送消息，生产者完成业务逻辑，消费者收到消息】的原子性，如果想保证【生产者发送消息，生产者完成业务逻辑，消费者收到消息，消费者完成业务逻辑】的院子性呢？","like_count":1,"discussions":[{"author":{"id":1494880,"avatar":"https://static001.geekbang.org/account/avatar/00/16/cf/60/9100ad4f.jpg","nickname":"周星平","note":"","ucode":"1FDCB487392B03","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":312394,"discussion_content":"协调者有集群","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1602677334,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":362241,"user_name":"学无涯","can_delete":false,"product_type":"c1","uid":1254493,"ip_address":"北京","ucode":"252754F9FCFF0C","user_header":"https://static001.geekbang.org/account/avatar/00/13/24/5d/65e61dcb.jpg","comment_is_top":false,"comment_ctime":1668333360,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100032301,"comment_content":"为什么用Kafka作为数据源，计算结果保存到其他数据库，就用不到事务了呢","like_count":0,"discussions":[{"author":{"id":1487584,"avatar":"https://static001.geekbang.org/account/avatar/00/16/b2/e0/d856f5a4.jpg","nickname":"余松","note":"","ucode":"89EC9CE3AD0281","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":291321,"discussion_content":"【生产者发送消息，生产者完成业务逻辑，消费者收到消息，消费者完成业务逻辑】这个后半部分没有保证的必要，因为MQ的应用场景本来就是为了解耦Producer和Consumer。所以上面介绍事物关注的都是Producer到Broker，而消费者完成业务逻辑，你只需后面的时间点实现“接收消息-处理业务-确认”就可以了。你可以认为是原子性退化到了最终一致性来解耦了Producer和Consumer。","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1594779457,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":344462,"user_name":"陈斌","can_delete":false,"product_type":"c1","uid":1367048,"ip_address":"","ucode":"B639AB5F6AA03D","user_header":"https://static001.geekbang.org/account/avatar/00/14/dc/08/64f5ab52.jpg","comment_is_top":false,"comment_ctime":1651569930,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100032301,"comment_content":"Kafka事务的怎么使用呢，我这边刚好有一个topic A到 topic B的场景，我怎么利用Kafka的事务和幂等保证消息的 Exactly Once ?","like_count":0},{"had_liked":false,"id":344462,"user_name":"陈斌","can_delete":false,"product_type":"c1","uid":1367048,"ip_address":"","ucode":"B639AB5F6AA03D","user_header":"https://static001.geekbang.org/account/avatar/00/14/dc/08/64f5ab52.jpg","comment_is_top":false,"comment_ctime":1651569930,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100032301,"comment_content":"Kafka事务的怎么使用呢，我这边刚好有一个topic A到 topic B的场景，我怎么利用Kafka的事务和幂等保证消息的 Exactly Once ?","like_count":0}]}