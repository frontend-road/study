{"id":144529,"title":"17 | Cache：多级缓存架构在消息系统中的应用","content":"<p>你好，我是袁武林。</p><p>今天，我要带你了解的是一项在IM系统中相对比较通用的、使用比较高频的，而且对系统性能提升非常明显的技术：缓存。</p><p>说到缓存，你应该不陌生。相对于磁盘操作，基于内存的缓存对耗时敏感的高并发应用来说，在性能方面的提升是非常明显的。</p><p>下面是谷歌的技术奠基人杰夫·狄恩（Jeff Dean）给出的一些<a href=\"http://highscalability.com/numbers-everyone-should-know\">计算机相关的硬件指标</a>，虽然有些数据可能由于时间太久不够准确，但大致的量级基本还是一致的。</p><ul>\n<li>L1 cache reference 0.5 ns</li>\n<li>Branch mispredict 5 ns</li>\n<li>L2 cache reference 7 ns</li>\n<li>Mutex lock/unlock 100 ns</li>\n<li><span class=\"orange\">Main memory reference 100 ns</span></li>\n<li>Compress 1K bytes with Zippy 10,000 ns</li>\n<li>Send 2K bytes over 1 Gbps network 20,000 ns</li>\n<li><span class=\"orange\">Read 1 MB sequentially from memory 250,000 ns</span></li>\n<li>Round trip within same datacenter 500,000 ns</li>\n<li>Disk seek 10,000,000 ns</li>\n<li>Read 1 MB sequentially from network 10,000,000 ns</li>\n<li><span class=\"orange\">Read 1 MB sequentially from disk 30,000,000 ns</span></li>\n<li>Send packet CA-&gt;Netherlands-&gt;CA 150,000,000 ns</li>\n</ul><!-- [[[read_end]]] --><p>可以看到，同样是1MB的数据读取，从磁盘读取的耗时，比从内存读取的耗时相差近100倍，这也是为什么业界常说“处理高并发的三板斧是缓存、降级和限流”了。</p><p>使用缓存虽然能够给我们带来诸多性能上的收益，但存在一个问题是缓存的资源成本非常高。因此，在IM系统中对于缓存的使用，就需要我们左右互搏地在“缓存命中率”和“缓存使用量”两大指标间不断均衡。</p><p>在今天的课程中，我会围绕IM系统中缓存的使用，来聊一聊在使用过程中容易碰到的一些问题及相应的解决方案。</p><h2>缓存的分布式算法</h2><p>对于大规模分布式服务来说，大部分缓存的使用都是多实例分布式部署的。接下来，我们就先来了解一下缓存常见的两种分布式算法：取模求余与一致性哈希。</p><h3>取模求余</h3><p>取模求余的算法比较简单。比如说，用于存储消息内容的缓存，如果采用取模求余，就可以简单地使用消息ID对缓存实例的数量进行取模求余。</p><p>如下图所示：如果消息ID哈希后对缓存节点取模求余，余数是多少，就缓存到哪个节点上。<br>\n<img src=\"https://static001.geekbang.org/resource/image/48/0f/4852180eaec1be40c2c853ad4029300f.png?wh=1142*640\" alt=\"\"></p><p>取模求余的分布式算法在实现上非常简单。但存在的问题是：如果某一个节点宕机或者加入新的节点，节点数量发生变化后，Hash后取模求余的结果就可能和以前不一样了。由此导致的后果是：加减节点后，缓存命中率下降严重。</p><h3>一致性哈希</h3><p>为了解决这个问题，业界常用的另一种缓存分布式算法是一致性哈希。它是1997年麻省理工学院提出的一种算法，目前主要应用在分布式缓存场景中。</p><p>一致性哈希的算法是：把全量的缓存空间分成2的32次方个区域，这些区域组合成一个环形的存储结构；每一个缓存的消息ID，都可以通过哈希算法，转化为一个32位的二进制数，也就是对应这2的32次方个缓存区域中的某一个；缓存的节点也遵循同样的哈希算法（比如利用节点的IP来哈希），这些缓存节点也都能被映射到2的32次方个区域中的某一个。</p><p>那么，如何让消息ID和具体的缓存节点对应起来呢？</p><p>很简单，每一个映射完的消息ID，我们按顺时针旋转，找到离它最近的同样映射完的缓存节点，该节点就是消息ID对应的缓存节点。大概规则我画了一个图，你可以参考一下：<br>\n<img src=\"https://static001.geekbang.org/resource/image/44/a3/442f8d013b505343f702048fae4d33a3.png?wh=1142*768\" alt=\"\"></p><p><strong>那么，为什么一致性哈希能够解决取模求余算法下，加减节点带来的命中率突降的问题呢？</strong></p><p>结合上图，我们一起来看一下。假设已经存在了4个缓存节点，现在新增加一个节点5，那么本来相应会落到节点1的mid1和mid9，可能会由于节点5的加入，有的落入到节点5，有的还是落入到节点1；落入到新增的节点5的消息会被miss掉，但是仍然落到节点1的消息还是能命中之前的缓存的。</p><p>另外，其他的节点2、3、4对应的这些消息还是能保持不变的，所以整体缓存的命中率，相比取模取余算法波动会小很多。</p><p>同样，如果某一个节点宕机的话，一致性哈希也能保证，只会有小部分消息的缓存归属节点发生变化，大部分仍然能保持不变。</p><h3>数据倾斜</h3><p>一致性哈希既然解决了加减节点带来的命中率下降的问题，那么是不是这种算法，就是缓存分布式算法的完美方案呢？</p><p>这里我们会发现，一致性哈希算法中，如果节点比较少，会容易出现节点间数据不均衡的情况，发生数据倾斜；如果节点很多，相应的消息就能在多个节点上分布得更均匀。</p><p>但在实际的线上业务中，部署的缓存机器节点是很有限的。</p><p>所以，为了解决物理节点少导致节点间数据倾斜的问题，我们还可以引入虚拟节点，来人为地创造更多缓存节点，以此让数据分布更加均匀。</p><p>虚拟节点的大概实现过程，你可以参考下图：<br>\n<img src=\"https://static001.geekbang.org/resource/image/92/23/92b1c18cb841dc81a3989f37fa2e4f23.png?wh=1142*768\" alt=\"\"></p><p>我们为每一个物理节点分配多个虚拟节点，比如在上图这里，给节点1虚拟出4个节点。当消息进行缓存哈希定位时，如果落到了这个物理节点上的任意一个虚拟节点，那么就表示，真正的缓存存储位置在这个物理节点上，然后服务端就可以从这个物理节点上进行数据的读写了。</p><p>如上面这个例子，本来都落在节点3的4条消息mid4、mid5、mid6、mid7，在加入节点1的虚拟节点后，mid4和mid5落到了虚拟节点1-2上，这样mid4和mid5就被分配到物理节点1上了。可见，通过这种方式，能更好地打散数据的分布，解决节点间数据不平衡的问题。</p><h2>缓存热点问题</h2><p>通过一致性哈希配合虚拟节点，我们解决了节点快速扩容和宕机，导致命中率下降的问题及节点间数据倾斜的问题。但在IM的一些场景里，还可能会出现单一资源热点的问题。</p><p>比如，一个超级大V给他的粉丝群发了一篇精心编写的长文章，可能一瞬间服务端会有上万的文章阅读请求涌入。由于这些长文章都是作为富文本进行存储的，所以存储的数据较大，有的文章都超过1MB，而且用户还需要随时能够修改文章，也不好通过CDN来进行分发。</p><p>那么，我们如何去解决这种缓存热点问题呢？</p><h3>多级缓存架构-主从模式</h3><p>我以上面的“长文章流量热点”的例子来说明一下。为了防止文章下载阅读出现热点时，造成后端存储服务的压力太大，我们一般会通过缓存来进行下载时的加速。比如说，我们可以通过文章的唯一ID来进行哈希，并且通过缓存的一主多从模式来进行部署，主从模式的部署大概如下图：<br>\n<img src=\"https://static001.geekbang.org/resource/image/7e/77/7e6712af075d5f9458109f98ca704477.png?wh=1142*1240\" alt=\"\"></p><p>一般来说，主从模式下，主库只用于数据写入和更新，从库只用于数据读取。当然，这个也不是一定的。</p><p>比如，在写多读少的场景下，也可以让主库承担一部分的数据读取工作。当缓存的数据读取QPS比较大的情况下，可以通过增加从库的方式来提升整体缓存层的抗读取能力。</p><p>主从模式是最常见的、使用最多的缓存应用模式。但是主从模式在某些突发流量的场景下会存在一些问题，就比如刚刚提到的“长文章流量热点”问题。</p><p>我们对某篇长文章的唯一ID来进行哈希，在主从模式下，一篇文章只会映射到一个从库节点上。虽然能够通过增加从库副本数来提升服务端对一篇文章的读取能力，但由于文章大小比较大，即使是多从库副本，对于千兆网卡的从库实例机器来说，带宽层面也很难抗住这个热点。举个例子，单台机器120MB带宽，对于1MB大小的文章来说，如果QPS到1000的话，至少需要8个实例才可以抗住。</p><p>另外，多从库副本是对主库数据的完整拷贝，从成本上考虑也是非常不划算的。除了带宽问题，对于某些QPS很高的资源请求来说，如果采用的是单主单从结构，一旦从库宕机，瞬间会有大量请求直接穿透到DB存储层，可能直接会导致资源不可用。</p><h3>多级缓存架构-L1+主从模式</h3><p>为了解决主从模式下，单点峰值过高导致单机带宽和热点数据在从库宕机后，造成后端资源瞬时压力的问题，我们可以参考CPU和主存的结构，在主从缓存结构前面再增加一层L1缓存层。</p><p>L1缓存，顾名思义一般它的容量会比较小，用于缓存极热的数据。那么，为什么L1缓存可以解决主从模式下的带宽问题和穿透问题呢？</p><p>我们来看一下，L1+主从模式的部署和访问形式：<br>\n<img src=\"https://static001.geekbang.org/resource/image/12/22/12139029db75c111314ff0e402f21722.png?wh=1142*1540\" alt=\"\"></p><p>L1缓存作为最前端的缓存层，在用户请求的时候，会先从L1缓存进行查询。如果L1缓存中没有，再从主从缓存里查询，查询到的结果也会回种一份到L1缓存中。</p><p>与主从缓存模式不一样的地方是：L1缓存有分组的概念，一组L1可以有多个节点，每一组L1缓存都是一份全量的热数据，一个系统可以提供多组L1缓存，同一个数据的请求会轮流落到每一组L1里面。</p><p>比如同一个文章ID，第一次请求会落到第一组L1缓存，第二次请求可能就落到第二组L1缓存。通过穿透后的回种，最后每一组L1缓存，都会缓存到同一篇文章。通过这种方式，同一篇文章就有多个L1缓存节点来抗读取的请求量了。</p><p>而且，L1缓存一般采用LRU（Least Recently Used）方式进行淘汰，这样既能减少L1缓存的内存使用量，也能保证热点数据不会被淘汰掉。并且，采用L1+主从的双层模式，即使有某一层节点出现宕机的情况，也不会导致请求都穿透到后端存储上，导致资源出现问题。</p><h3>多级缓存架构-本地缓存+L1+主从的多层模式</h3><p>通过L1缓存+主从缓存的双层架构，我们用较少的资源解决了热点峰值的带宽问题和单点穿透问题。</p><p>但有的时候，面对一些极热的热点峰值，我们可能需要增加多组L1才能抗住带宽的需要。不过内存毕竟是比较昂贵的成本，所以有没有更好的平衡极热峰值和缓存成本的方法呢？</p><p>对于大部分请求量较大的应用来说，应用层机器的部署一般不会太少。如果我们的应用服务器本身也能够承担一部分数据缓存的工作，就能充分利用应用层机器的带宽和极少的内存，来低成本地解决带宽问题了。那么，这种方式是否可以实现呢？</p><p>答案是可以的，这种本地缓存+L1缓存+主从缓存的多级缓存模式，也是业界比较成熟的方案了。多级缓存模式的整体流程大概如下图：<br>\n<img src=\"https://static001.geekbang.org/resource/image/c8/d6/c87661167f77555e906ed2117ba9b5d6.png?wh=1142*1540\" alt=\"\"></p><p>本地缓存一般位于应用服务器的部署机器上，使用应用服务器本身的少量内存。它是应用层获取数据的第一道缓存，应用层获取数据时先访问本地缓存，如果未命中，再通过远程从L1缓存层获取，最终获取到的数据再回种到本地缓存中。</p><p>通过增加本地缓存，依托应用服务器的多部署节点，基本就能完全解决热点数据带宽的问题。而且，相比较从远程L1缓存获取数据，本地缓存离应用和用户设备更近，性能上也会更好一些。</p><p>但是使用本地缓存有一个需要考虑的问题，那就是数据的一致性问题。</p><p>还是以“长文章”为例。我们的服务端可能会随时接收到用户需要修改文章内容的请求，这个时候，对于本地缓存来说，由于应用服务器的部署机器随着扩缩容的改变，其数量不一定是固定的，所以修改后的数据如何同步到本地缓存中，就是一个比较复杂和麻烦的事情了。</p><p>要解决本地缓存一致性问题，业界比较折中的方式是：对本地缓存采用“短过期时间”的方式，来平衡本地缓存命中率和数据更新一致性的问题。比如说，针对“长文章”的本地缓存，我们可以采用5秒过期的策略，淘汰后再从中央缓存获取新的数据。这种方式对于大部分业务场景来说，在产品层面上也是都能接受的。</p><h2>小结</h2><p>好了，下面简单回顾一下今天课程的内容。</p><p>首先，我介绍了缓存在高并发应用中的重要性，以及在IM系统中使用的部分场景。然后再带你了解了缓存分布式的两种算法：取模求余和一致性哈希。</p><ul>\n<li><strong>取模求余算法</strong>在实现上非常简单，但存在的问题是，取模求余算法在节点扩容和宕机后会出现震荡，缓存命中率会严重降低。</li>\n<li><strong>一致性哈希算法</strong>解决了节点增删时震荡的问题，并通过虚拟节点的引入，缓解了<strong>“数据倾斜”</strong>的情况。</li>\n</ul><p>最后，我着重介绍了业界通用的三种分布式缓存的常见架构。</p><ul>\n<li><strong>一种是主从模式。</strong>简单的主从模式最常见，但是在面对峰值热点流量时，容易出现带宽问题，也存在缓存节点宕机后穿透到存储层的问题。</li>\n<li><strong>第二种是L1+主从模式</strong>。通过增加L1缓存层，以并行的多组小容量的L1缓存，解决了单一热点的带宽问题，也避免了单一节点宕机后容易穿透到DB存储层的情况。</li>\n<li><strong>最后一种是本地缓存+L1+主从的多层模式</strong>。作为低成本的解决方案，我们在L1+主从模式的基础上，引入了本地缓存。本地缓存依托应用服务器的本机少量内存，既提升了资源的有效利用，也彻底解决了带宽的问题。同时在性能方面，也比远程缓存获取更加优秀。对于本地缓存的数据一致性问题，我们可以通过“短过期时间”来平衡缓存命中率和数据一致性。</li>\n</ul><p>面对高并发业务带来的流量压力，我们不可否认的是，缓存的使用是目前为止最有效的提升系统整体性能的手段。作为系统优化的一把利器，如何用好这个强大的工具，是你需要去不断思考和学习的。希望今天介绍的这几种缓存使用的姿势，能够让你有所收获，并能在自己的业务中去尝试实践。</p><p><strong>最后给你留一道思考题：</strong></p><p>L1+主从模式下，如果热点数据都被L1缓存层拦截命中，会导致主从缓存层相应的这个热点数据，由于长时间得不到读取而被LRU淘汰掉。这样，如果下线L1缓存，还是会有不少的请求直接穿透到DB存储层。那么有没有办法，能够让主从缓存在有L1缓存层的情况下，依旧能保持数据热度？</p><p>以上就是今天课程的内容，欢迎你给我留言，我们可以在留言区一起讨论，感谢你的收听，我们下期再见。</p>","neighbors":{"left":{"article_title":"16 | APNs：聊一聊第三方系统级消息通道的事","id":143277},"right":{"article_title":"18 | Docker容器化：说一说IM系统中模块水平扩展的实现","id":145461}},"comments":[{"had_liked":false,"id":138580,"user_name":"那时刻","can_delete":false,"product_type":"c1","uid":1150927,"ip_address":"","ucode":"B0D150856C3A4A","user_header":"https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg","comment_is_top":false,"comment_ctime":1570347994,"is_pvip":false,"replies":[{"id":"53720","content":"本地缓存的一致性我课程中有讲哈，本地缓存只会从中央缓存回种，中央缓存数据有变化并不需要同步告知本地缓存。本地缓存通过短过期时间来重新从中央缓存回种。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1570624031,"ip_address":"","comment_id":138580,"utype":1}],"discussion_count":2,"race_medal":0,"score":"40225053658","product_id":100034901,"comment_content":"请问怎么保证local cache到cache master的数据一致性呢？毕竟local cache在分布式的服务器集群，会有同一个文档发到不同服务器local cache的情形。从图中看出，是某一个local cache负责同步数据到cache master么？或者我有什么误解？烦请指正","like_count":9,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":469581,"discussion_content":"本地缓存的一致性我课程中有讲哈，本地缓存只会从中央缓存回种，中央缓存数据有变化并不需要同步告知本地缓存。本地缓存通过短过期时间来重新从中央缓存回种。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570624031,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1147979,"avatar":"https://static001.geekbang.org/account/avatar/00/11/84/4b/e4738ba8.jpg","nickname":"delete is create","note":"","ucode":"A8C751219A7746","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":278945,"discussion_content":"如果分布式缓冲用的是redis，是否可以使用redis的发布订阅模式 通知客户端去更新缓冲？   因为多级缓冲还有一种场景是存放配置，这些配置一般都不咋变，没必要每次都访问redis，可以保存在本地缓冲中，这些配置一般都不咋变，如果时间设置的太短，那多级缓冲的意义就不明显了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1591262096,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":138257,"user_name":"小小小丶盘子","can_delete":false,"product_type":"c1","uid":1308056,"ip_address":"","ucode":"FCD4520F1EF872","user_header":"https://static001.geekbang.org/account/avatar/00/13/f5/98/45374bb9.jpg","comment_is_top":false,"comment_ctime":1570119627,"is_pvip":true,"replies":[{"id":"53277","content":"也是一种思路，不过实现上可能会比较复杂。另外可以考虑把master也加入到L1缓存层中，这样能保持数据热度。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1570275397,"ip_address":"","comment_id":138257,"utype":1}],"discussion_count":1,"race_medal":0,"score":"35929857995","product_id":100034901,"comment_content":"开线程定时访问热点数据，保证不被淘汰。","like_count":8,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":469456,"discussion_content":"也是一种思路，不过实现上可能会比较复杂。另外可以考虑把master也加入到L1缓存层中，这样能保持数据热度。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570275397,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":150364,"user_name":"好运连连","can_delete":false,"product_type":"c1","uid":1105081,"ip_address":"","ucode":"2A339281321E2A","user_header":"https://static001.geekbang.org/account/avatar/00/10/dc/b9/946b181d.jpg","comment_is_top":false,"comment_ctime":1573523052,"is_pvip":false,"replies":[{"id":"57915","content":"master加入到L1层主要是解决master的热点数据缓存得不到访问而被lru淘汰掉，如果这时L1挂了或者被下线，会穿透master对底层db产生压力。对于redis这种本身支持主从的缓存实现，master上过期了slave上也会过期，对于memcached这种本身不支持主从的缓存实现就需要人为来维护主从关系，数据也并不会从master同步到slave。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1573564375,"ip_address":"","comment_id":150364,"utype":1}],"discussion_count":2,"race_medal":0,"score":"23048359532","product_id":100034901,"comment_content":"为什么把master也当作L1可以解决热度问题？难道每一次master过期也会主动把从库的对应缓存删除？","like_count":5,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":474136,"discussion_content":"master加入到L1层主要是解决master的热点数据缓存得不到访问而被lru淘汰掉，如果这时L1挂了或者被下线，会穿透master对底层db产生压力。对于redis这种本身支持主从的缓存实现，master上过期了slave上也会过期，对于memcached这种本身不支持主从的缓存实现就需要人为来维护主从关系，数据也并不会从master同步到slave。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1573564375,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":1691181,"avatar":"https://static001.geekbang.org/account/avatar/00/19/ce/2d/33fdd230.jpg","nickname":"Sophia","note":"","ucode":"069868B84FBF40","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":547426,"discussion_content":"如果master 作为L1来使用，同时master 还担认着写的职责，高峰时， 可能会影响master 写性能吧~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1642669748,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":474136,"ip_address":""},"score":547426,"extra":""}]}]},{"had_liked":false,"id":139382,"user_name":"Geek_37e993","can_delete":false,"product_type":"c1","uid":1645048,"ip_address":"","ucode":"0E87EFA4B0D5F0","user_header":"","comment_is_top":false,"comment_ctime":1570624034,"is_pvip":false,"replies":[{"id":"53916","content":"有数据更新的时候会同步更新L1和master，虽然多组L1会导致多次更新的问题，但对于大部分读多写少的互联网场景来说刚更新不是一个频繁的操作，所以基本可控。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1570712001,"ip_address":"","comment_id":139382,"utype":1}],"discussion_count":2,"race_medal":0,"score":"18750493218","product_id":100034901,"comment_content":"请教一下，L1缓存和slave以及后端存储的数据一致性如何保证呢？","like_count":4,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":469918,"discussion_content":"有数据更新的时候会同步更新L1和master，虽然多组L1会导致多次更新的问题，但对于大部分读多写少的互联网场景来说刚更新不是一个频繁的操作，所以基本可控。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570712001,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1036317,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/d0/1d/8041d9a3.jpg","nickname":"看见猫","note":"","ucode":"39E09C1F765218","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":38212,"discussion_content":"如果L1或者master更新失败了，之后读的数据还是老的数据，有什么好的机制能将L1或master中老的数据淘汰掉吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1571744185,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":138943,"user_name":"clip","can_delete":false,"product_type":"c1","uid":1019244,"ip_address":"","ucode":"D0E142605A5BD5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/8d/6c/0c2a26c7.jpg","comment_is_top":false,"comment_ctime":1570514748,"is_pvip":true,"replies":[{"id":"53824","content":"不是哈，这里是说：对于主从缓存来说，从库拥有和主库一样的数据，所以靠不停扩展多个从库来解决某几个单key热点的问题很浪费。并不是说每个主从都有全量所有的业务数据，主从里的数据是根据hash规则来分片的，是全量数据的子集。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1570677985,"ip_address":"","comment_id":138943,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18750383932","product_id":100034901,"comment_content":"主从以及那边有点不明白。<br>为什么从库节点中有全部的数据？<br>某个节点有全量的数据却只有部分对象的查询分配到自己。<br>我理解的如果有全量数据那就直接循环着去不同节点中取不就行了吗，也就不需要缓存分布式算法了吧。","like_count":4,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":469710,"discussion_content":"不是哈，这里是说：对于主从缓存来说，从库拥有和主库一样的数据，所以靠不停扩展多个从库来解决某几个单key热点的问题很浪费。并不是说每个主从都有全量所有的业务数据，主从里的数据是根据hash规则来分片的，是全量数据的子集。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570677985,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":138652,"user_name":"大魔王汪汪","can_delete":false,"product_type":"c1","uid":1010680,"ip_address":"","ucode":"4B205CB52FC95F","user_header":"https://static001.geekbang.org/account/avatar/00/0f/6b/f8/b4da7936.jpg","comment_is_top":false,"comment_ctime":1570410236,"is_pvip":false,"replies":[{"id":"53719","content":"技术实现上基本一样，只不过L1主要解决热数据对master slave缓存的单点压力，也可以防止master slave缓存故障导致穿透db的问题。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1570623846,"ip_address":"","comment_id":138652,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14455312124","product_id":100034901,"comment_content":"老师L1缓存具体是实现和缓存层究竟有什么区别呢？还是说技术实现上本身没有区别，只不过存储目的不同？比如L1就是为了解决热数据的","like_count":3,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":469608,"discussion_content":"技术实现上基本一样，只不过L1主要解决热数据对master slave缓存的单点压力，也可以防止master slave缓存故障导致穿透db的问题。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570623846,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":141095,"user_name":"二进制之路","can_delete":false,"product_type":"c1","uid":1008395,"ip_address":"","ucode":"67C84B013147B1","user_header":"https://static001.geekbang.org/account/avatar/00/0f/63/0b/ad56aeb4.jpg","comment_is_top":false,"comment_ctime":1571113437,"is_pvip":false,"replies":[{"id":"54736","content":"L1的容量一般比从库容量小很多，但是会冗余多组，通过这种方式来承担极热点数据的访问，带宽上由于冗余多组来随机访问，所以带宽上自然相当于扩大了，另外由于容量都很小，也比扩从库成本上要更省。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1571225284,"ip_address":"","comment_id":141095,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10161048029","product_id":100034901,"comment_content":"对于L1解决带宽问题，感觉文中没讲太清楚。机器带宽和网卡有关系，相同配置的机器带宽一样。从库和L1如果机器数量一样，同样带宽是没问题的。也就是说L1在存储成本上有优势，带宽上没优势吧？","like_count":2,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":470667,"discussion_content":"L1的容量一般比从库容量小很多，但是会冗余多组，通过这种方式来承担极热点数据的访问，带宽上由于冗余多组来随机访问，所以带宽上自然相当于扩大了，另外由于容量都很小，也比扩从库成本上要更省。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1571225284,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":215776,"user_name":"piboye","can_delete":false,"product_type":"c1","uid":1066752,"ip_address":"","ucode":"7CFD8712857A85","user_header":"https://static001.geekbang.org/account/avatar/00/10/47/00/3202bdf0.jpg","comment_is_top":false,"comment_ctime":1589101451,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"5884068747","product_id":100034901,"comment_content":"可以用一个随机数，如果命中某个值就异步放量到master上。这样就有一定比例的访问到master了","like_count":1},{"had_liked":false,"id":148843,"user_name":"yic","can_delete":false,"product_type":"c1","uid":1201577,"ip_address":"","ucode":"C8DC471B7C28B8","user_header":"https://static001.geekbang.org/account/avatar/00/12/55/a9/5282a560.jpg","comment_is_top":false,"comment_ctime":1573094001,"is_pvip":false,"replies":[{"id":"57783","content":"L1缓存一般也是和主从缓存一样，采用中央缓存如memcached或者redis，只是在hash规则上和主从缓存有区别。<br>您指的主从关系变化是说节点数变化了还是主库切成从库了？如果是节点数发生了变化采用一致性hash是可以不需要干预的，如果是主从关系变化了一般需要及时调整L1的配置。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1573477635,"ip_address":"","comment_id":148843,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5868061297","product_id":100034901,"comment_content":"老师，有两个问题请教一下：<br>1. L1缓存业界一般是如何实现的？<br>2. 关于课后问题的解答，老师提供的思路是：“另外可以考虑把master也加入到L1缓存层中，这样能保持数据热度“。我想问一下，如果发生了主从关系变化呢？这时如何把master加入到L1缓存层呢？","like_count":1,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":473633,"discussion_content":"L1缓存一般也是和主从缓存一样，采用中央缓存如memcached或者redis，只是在hash规则上和主从缓存有区别。\n您指的主从关系变化是说节点数变化了还是主库切成从库了？如果是节点数发生了变化采用一致性hash是可以不需要干预的，如果是主从关系变化了一般需要及时调整L1的配置。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1573477635,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1201577,"avatar":"https://static001.geekbang.org/account/avatar/00/12/55/a9/5282a560.jpg","nickname":"yic","note":"","ucode":"C8DC471B7C28B8","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":51068,"discussion_content":"好的，谢谢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1573806872,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":148671,"user_name":"独酌相思解千愁","can_delete":false,"product_type":"c1","uid":1653628,"ip_address":"","ucode":"578995696A1482","user_header":"https://static001.geekbang.org/account/avatar/00/19/3b/7c/a977d9a9.jpg","comment_is_top":false,"comment_ctime":1573047287,"is_pvip":false,"replies":[{"id":"57779","content":"理论上应该可以，不过L1如果承载的是热点数据，那么对于更新主从缓存就会比较频繁，带来额外压力。一种简单的方法可以把主从缓存也作为一组L1加入，这样也能保证主从缓存里的数据热度。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1573476845,"ip_address":"","comment_id":148671,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5868014583","product_id":100034901,"comment_content":"对于思考题，将各级缓存的存活时间分级设定，L1最小，每当L1重新拉取数据时同时更新其他缓存层的相应热点数据。同时对于一段时间类使用比较频繁的数据可以按照一定规则增加其存活时间（或者权重） 不知道这样有可行性不","like_count":1,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":473571,"discussion_content":"理论上应该可以，不过L1如果承载的是热点数据，那么对于更新主从缓存就会比较频繁，带来额外压力。一种简单的方法可以把主从缓存也作为一组L1加入，这样也能保证主从缓存里的数据热度。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1573476845,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":148227,"user_name":"王蒙","can_delete":false,"product_type":"c1","uid":1642579,"ip_address":"","ucode":"AF623B848877AD","user_header":"https://static001.geekbang.org/account/avatar/00/19/10/53/2230bf9d.jpg","comment_is_top":false,"comment_ctime":1572960979,"is_pvip":false,"replies":[{"id":"57212","content":"QPS 1000的话整体流量就是1G，一般常见的千兆网卡单台机器单方向120MB带宽， 所以大概需要8台左右。<br>这里的流量是指网卡流量，http属于应用层的，所以是包括header和body的。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1573037109,"ip_address":"","comment_id":148227,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5867928275","product_id":100034901,"comment_content":"举个例子，单台机器 120MB 带宽，对于 1MB 大小的文章来说，如果 QPS 到 1000 的话，至少需要 8 个实例才可以抗住。<br><br>请问，8是怎么算的，有什么公式吗？<br>8个实例是指单台物理机，上面8个虚拟机，还是一台机器上部8个相同应用?<br>还有平时手机的流量是指http请求的request的请求头和body的大小吗，response的算吗?","like_count":1,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":473437,"discussion_content":"QPS 1000的话整体流量就是1G，一般常见的千兆网卡单台机器单方向120MB带宽， 所以大概需要8台左右。\n这里的流量是指网卡流量，http属于应用层的，所以是包括header和body的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1573037109,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":138526,"user_name":"卫江","can_delete":false,"product_type":"c1","uid":1101226,"ip_address":"","ucode":"DE2F7A6916F1A9","user_header":"https://static001.geekbang.org/account/avatar/00/10/cd/aa/33d48789.jpg","comment_is_top":false,"comment_ctime":1570291261,"is_pvip":false,"replies":[{"id":"53726","content":"嗯，这个也是一种实现方案，实现上可能会稍微麻烦一点。也可以考虑把master当做一组L1,也加入到L1层中来保证热度。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1570624508,"ip_address":"","comment_id":138526,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5865258557","product_id":100034901,"comment_content":"思考题，我感觉可以在L1层，根据访问的特定数据的频率，比如qps超过100就去后面缓存拉一下，这样一来实现简单，频率不高又能保证热数据不被淘汰，同时也可以作为L1缓存的数据更新保证数据一致性的实现方式。","like_count":1,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":469556,"discussion_content":"嗯，这个也是一种实现方案，实现上可能会稍微麻烦一点。也可以考虑把master当做一组L1,也加入到L1层中来保证热度。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570624508,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1691181,"avatar":"https://static001.geekbang.org/account/avatar/00/19/ce/2d/33fdd230.jpg","nickname":"Sophia","note":"","ucode":"069868B84FBF40","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":547427,"discussion_content":"好方案~ ","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1642669942,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":138339,"user_name":"孙凯","can_delete":false,"product_type":"c1","uid":1341397,"ip_address":"","ucode":"A7139BE8B54B7C","user_header":"https://static001.geekbang.org/account/avatar/00/14/77/d5/1441f02c.jpg","comment_is_top":false,"comment_ctime":1570171247,"is_pvip":false,"replies":[{"id":"53280","content":"实现上并不复杂，其实就是二次哈希的过程，比如将原来哈希到slave1的请求再采用round robin轮流打到多组L1上，这样就实现流量分散了。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1570276220,"ip_address":"","comment_id":138339,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5865138543","product_id":100034901,"comment_content":"老师能详细讲下L1级缓存怎么用么？","like_count":1,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":469492,"discussion_content":"实现上并不复杂，其实就是二次哈希的过程，比如将原来哈希到slave1的请求再采用round robin轮流打到多组L1上，这样就实现流量分散了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570276220,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":357714,"user_name":"追风筝的人","can_delete":false,"product_type":"c1","uid":1488020,"ip_address":"陕西","ucode":"2993D60F94C396","user_header":"https://static001.geekbang.org/account/avatar/00/16/b4/94/2796de72.jpg","comment_is_top":false,"comment_ctime":1663577954,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1663577954","product_id":100034901,"comment_content":"取模求余算法在实现上非常简单，但存在的问题是，取模求余算法在节点扩容和宕机后会出现震荡，缓存命中率会严重降低。<br>一致性哈希算法解决了节点增删时震荡的问题，并通过虚拟节点的引入，缓解了“数据倾斜”的情况。","like_count":0},{"had_liked":false,"id":245622,"user_name":"EveryDayIsNew","can_delete":false,"product_type":"c1","uid":1316926,"ip_address":"","ucode":"776B81EF6830FA","user_header":"https://static001.geekbang.org/account/avatar/00/14/18/3e/f8632713.jpg","comment_is_top":false,"comment_ctime":1599010807,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1599010807","product_id":100034901,"comment_content":"这种要是放弃L1缓存，然后检测出来热点key，之后把热点key加个几个随机数再散列给集群呢，这样集群的每个节点都理论上会有一份，加上一层L1缓存是不是复杂性高了呢","like_count":0},{"had_liked":false,"id":244164,"user_name":"stevensafin","can_delete":false,"product_type":"c1","uid":1053553,"ip_address":"","ucode":"CC692A740C5FD5","user_header":"https://static001.geekbang.org/account/avatar/00/10/13/71/3762b089.jpg","comment_is_top":false,"comment_ctime":1598414634,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1598414634","product_id":100034901,"comment_content":"L1Cache表示什么？用什么实现？和主从Cache的区别是什么？概念本身还是希望老师能够先解释清楚哈","like_count":0},{"had_liked":false,"id":240102,"user_name":"问题究竟系边度","can_delete":false,"product_type":"c1","uid":1095284,"ip_address":"","ucode":"CA4F2C9A84F867","user_header":"https://static001.geekbang.org/account/avatar/00/10/b6/74/c63449b1.jpg","comment_is_top":false,"comment_ctime":1596762858,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1596762858","product_id":100034901,"comment_content":"L1缓存可以参考知乎的已读服务架构，两层缓存的维度会不一样","like_count":0},{"had_liked":false,"id":224093,"user_name":"delete is create","can_delete":false,"product_type":"c1","uid":1147979,"ip_address":"","ucode":"A8C751219A7746","user_header":"https://static001.geekbang.org/account/avatar/00/11/84/4b/e4738ba8.jpg","comment_is_top":false,"comment_ctime":1591274098,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1591274098","product_id":100034901,"comment_content":"长轮训在集群中会不会出问题  比如你的长轮训是挂在了a节点  但是你要请求的数据是对方在b节点返回的","like_count":0},{"had_liked":false,"id":224045,"user_name":"delete is create","can_delete":false,"product_type":"c1","uid":1147979,"ip_address":"","ucode":"A8C751219A7746","user_header":"https://static001.geekbang.org/account/avatar/00/11/84/4b/e4738ba8.jpg","comment_is_top":false,"comment_ctime":1591262112,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1591262112","product_id":100034901,"comment_content":"如果分布式缓冲用的是redis，是否可以使用redis的发布订阅模式 通知客户端去更新缓冲？ 因为多级缓冲还有一种场景是存放配置，这些配置一般都不咋变，没必要每次都访问redis，可以保存在本地缓冲中，这些配置一般都不咋变，如果时间设置的太短，那多级缓冲的意义就不明显了。","like_count":0},{"had_liked":false,"id":215777,"user_name":"piboye","can_delete":false,"product_type":"c1","uid":1066752,"ip_address":"","ucode":"7CFD8712857A85","user_header":"https://static001.geekbang.org/account/avatar/00/10/47/00/3202bdf0.jpg","comment_is_top":false,"comment_ctime":1589101554,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1589101554","product_id":100034901,"comment_content":"一致性hash不讲谷歌的jumphash吗？我发现市面上的课程，都是老一套的环状的。","like_count":0},{"had_liked":false,"id":210853,"user_name":"tm1234","can_delete":false,"product_type":"c1","uid":1947612,"ip_address":"","ucode":"4042321C713186","user_header":"","comment_is_top":false,"comment_ctime":1587839094,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1587839094","product_id":100034901,"comment_content":"请问老师l1是只存热点文章吗，还是说他就是主从缓存的一个副本，存储所有数据？如果是只存热点的话是怎么实现的呢？","like_count":0},{"had_liked":false,"id":199978,"user_name":"天雨","can_delete":false,"product_type":"c1","uid":1937210,"ip_address":"","ucode":"77999C35E337EF","user_header":"https://static001.geekbang.org/account/avatar/00/1d/8f/3a/49d38340.jpg","comment_is_top":false,"comment_ctime":1585528084,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1585528084","product_id":100034901,"comment_content":"“在主从模式下，一篇文章只会映射到一个从库节点上。虽然能够通过增加从库副本数来提升服务端对一篇文章的读取能力”。想问一下老师，具体是怎么增加从库的副本数呢？如何能让新加的机子正好能落在这篇文章映射的节点上？谢谢","like_count":0},{"had_liked":false,"id":189076,"user_name":"芒果少侠","can_delete":false,"product_type":"c1","uid":1350159,"ip_address":"","ucode":"98D0BBB52BB80F","user_header":"https://static001.geekbang.org/account/avatar/00/14/9a/0f/da7ed75a.jpg","comment_is_top":false,"comment_ctime":1584453629,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1584453629","product_id":100034901,"comment_content":"请问下老师 L1缓存层怎么解决的带宽问题？如果请求量不变，那出网依然会占据带宽，不存在带宽消耗减少的优势吧？","like_count":0},{"had_liked":false,"id":184197,"user_name":"老船长","can_delete":false,"product_type":"c1","uid":1105224,"ip_address":"","ucode":"8B4D8B2B0C602A","user_header":"https://static001.geekbang.org/account/avatar/00/10/dd/48/e875e2bf.jpg","comment_is_top":false,"comment_ctime":1583245821,"is_pvip":false,"replies":[{"id":"72292","content":"结合广播通知是一个可行的方式，不过需要考虑某些台机器广播接收失败的情况，整体上方案会比较复杂。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1584085576,"ip_address":"","comment_id":184197,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1583245821","product_id":100034901,"comment_content":"本地缓存结合广播通知缓存失效，这个方式怎么样？","like_count":0,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":485925,"discussion_content":"结合广播通知是一个可行的方式，不过需要考虑某些台机器广播接收失败的情况，整体上方案会比较复杂。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1584085576,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":138551,"user_name":"Geek_e986e3","can_delete":false,"product_type":"c1","uid":1642716,"ip_address":"","ucode":"EF53D2DEA59A8F","user_header":"","comment_is_top":false,"comment_ctime":1570333205,"is_pvip":false,"replies":[{"id":"53721","content":"将master也加入到L1层主要是防止master里热数据被淘汰。L1是并列多组小容量的缓存，通过多组冗余来扛热数据，解决挡在master slave缓存前面。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1570624250,"ip_address":"","comment_id":138551,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1570333205","product_id":100034901,"comment_content":"老师 我看你说将master节点当作l1来用保证不过期。这样的话我能理解成l1实际上也就是容量缩小版的从节点吗？","like_count":0,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":469567,"discussion_content":"将master也加入到L1层主要是防止master里热数据被淘汰。L1是并列多组小容量的缓存，通过多组冗余来扛热数据，解决挡在master slave缓存前面。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570624250,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":138444,"user_name":"mgxian","can_delete":false,"product_type":"c1","uid":1014806,"ip_address":"","ucode":"7B7E77E6A83B87","user_header":"https://static001.geekbang.org/account/avatar/00/0f/7c/16/4d1e5cc1.jpg","comment_is_top":false,"comment_ctime":1570244725,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1570244725","product_id":100034901,"comment_content":"主从缓存层不使用lru算法淘汰数据 保存全量数据 内存不够 就使用SSD存储数据 比如 ssdb rocksdb leveldb","like_count":0},{"had_liked":false,"id":138433,"user_name":"探索无止境","can_delete":false,"product_type":"c1","uid":1044178,"ip_address":"","ucode":"91D2A9907DFA79","user_header":"https://static001.geekbang.org/account/avatar/00/0f/ee/d2/7024431c.jpg","comment_is_top":false,"comment_ctime":1570239096,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1570239096","product_id":100034901,"comment_content":"老师理论都已经清楚了，能否提供一个可落地的具体实现，比如L1缓存具体要怎么做？","like_count":0},{"had_liked":false,"id":138320,"user_name":"刘丹","can_delete":false,"product_type":"c1","uid":1081922,"ip_address":"","ucode":"66594D1C957E15","user_header":"https://static001.geekbang.org/account/avatar/00/10/82/42/8b04d489.jpg","comment_is_top":false,"comment_ctime":1570162797,"is_pvip":false,"replies":[{"id":"53279","content":"一般真实场景中来说是的，不过L1主要还是一种缓存架构，实现上没有限制的。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1570275599,"ip_address":"","comment_id":138320,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1570162797","product_id":100034901,"comment_content":"请问L1缓存是指redis、memcached这种网络缓存吗？","like_count":0,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":469481,"discussion_content":"一般真实场景中来说是的，不过L1主要还是一种缓存架构，实现上没有限制的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570275599,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":138258,"user_name":"东东🎈","can_delete":false,"product_type":"c1","uid":1326338,"ip_address":"","ucode":"D1BBE24CF76426","user_header":"https://static001.geekbang.org/account/avatar/00/14/3d/02/ecdb4e66.jpg","comment_is_top":false,"comment_ctime":1570121060,"is_pvip":false,"replies":[{"id":"53278","content":"有的uid是字符型的，所以通用做法就是先hash一下。<br>L1缓存一般自动lru成最热的数据。","user_name":"作者回复","user_name_real":"coldwalker","uid":"1297490","ctime":1570275518,"ip_address":"","comment_id":138258,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1570121060","product_id":100034901,"comment_content":"老师，hash(uid)%10和uid%10这两个有啥区别？然后L1空间很小，一般存放哪些类型的数据呢？","like_count":0,"discussions":[{"author":{"id":1297490,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epK1zyWib7IKYCoRSxIa6dDjrcyBqObGfj1lDVia1pOrSVxyltKI7RfGekdXPQNObwaBQg3gwvarlQA/132","nickname":"coldwalker","note":"","ucode":"AF9AF257A745C9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":469457,"discussion_content":"有的uid是字符型的，所以通用做法就是先hash一下。\nL1缓存一般自动lru成最热的数据。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570275518,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1008395,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/63/0b/ad56aeb4.jpg","nickname":"二进制之路","note":"","ucode":"67C84B013147B1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":33263,"discussion_content":"如果uid对10取模后，数据量比较偏向于某个库，则通过hash可以使数据更均匀","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1571113254,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}