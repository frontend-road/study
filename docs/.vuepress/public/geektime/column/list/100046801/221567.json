{"id":221567,"title":"19 | 跨系统实时同步数据，分布式事务是唯一的解决方案吗？","content":"<p>你好，我是李玥。</p><p>我们在《<a href=\"https://time.geekbang.org/column/article/217568\">15 | MySQL存储海量数据的最后一招：分库分表</a>》这节课中讲过，数据量太大的时候，单个存储节点存不下，那就只能把数据分片存储。</p><p>数据分片之后，我们对数据的查询就没那么自由了。比如订单表如果按照用户ID作为Sharding Key来分片，那就只能按照用户维度来查询。如果我是一个商家，我想查我店铺的订单，对不起，做不到了。（当然，强行查也不是不行，在所有分片上都查一遍，再把结果聚合起来，又慢又麻烦，实际意义不大。）</p><p>对于这样的需求，普遍的解决办法是用空间换时间，毕竟现在存储越来越便宜。再存一份订单数据到商家订单库，然后以店铺ID作为Sharding Key分片，专门供商家查询订单。</p><p>另外，之前我们在《<a href=\"https://time.geekbang.org/column/article/208675\">06 | 如何用Elasticsearch构建商品搜索系统</a>》这节课也讲到过，同样一份商品数据，如果我们是按照关键字搜索，放在ES里就比放在MySQL快了几个数量级。原因是，数据组织方式、物理存储结构和查询方式，对查询性能的影响是巨大的，而且海量数据还会指数级地放大这个性能差距。</p><p>所以，在大厂中，对于海量数据的处理原则，都是根据业务对数据查询的需求，反过来确定选择什么数据库、如何组织数据结构、如何分片数据，这样才能达到最优的查询性能。同样一份订单数据，除了在订单库保存一份用于在线交易以外，还会在各种数据库中，以各种各样的组织方式存储，用于满足不同业务系统的查询需求。像BAT这种大厂，它的核心业务数据，存个几十上百份是非常正常的。</p><!-- [[[read_end]]] --><p>那么问题来了，如何能够做到让这么多份数据实时地保持同步呢？</p><p>我们之前讲过分布式事务，可以解决数据一致性的问题。比如说，你可以用本地消息表，把一份数据实时同步给另外两、三个数据库，这样还可以接受，太多的话也是不行的，并且对在线交易业务还有侵入性，所以分布式事务是解决不了这个问题的。</p><p>今天这节课我们就来说一下，如何把订单数据实时、准确无误地同步到这么多异构的数据中去。</p><h2>使用Binlog和MQ构建实时数据同步系统</h2><p>早期大数据刚刚兴起的时候，大多数系统还做不到异构数据库实时同步，那个时候普遍的做法是，使用ETL工具定时同步数据，在T+1时刻去同步上一个周期的数据，然后再做后续的计算和分析。定时ETL对于一些需要实时查询数据的业务需求就无能为力了。所以，这种定时同步的方式，基本上都被实时同步的方式给取代了。</p><p>怎么来做这么大数据量、这么多个异构数据库的实时同步呢？你还记得我在《<a href=\"https://time.geekbang.org/column/article/217593\">17 | 大厂都是怎么做MySQL to Redis同步的</a>》这节课中讲到的方法吧？利用Canal把自己伪装成一个MySQL的从库，从MySQL实时接收Binlog然后写入Redis中。把这个方法稍微改进一下，就可以用来做异构数据库的同步了。</p><p>为了能够支撑下游众多的数据库，从Canal出来的Binlog数据肯定不能直接去写下游那么多数据库，一是写不过来，二是对于每个下游数据库，它可能还有一些数据转换和过滤的工作要做。所以需要增加一个MQ来解耦上下游。</p><p><img src=\"https://static001.geekbang.org/resource/image/df/d8/dfa37d67d87fc7c8a8de50681f8134d8.jpg?wh=3072*1366\" alt=\"\"></p><p>Canal从MySQL收到Binlog并解析成结构化数据之后，直接写入到MQ的一个订单Binlog主题中，然后每一个需要同步订单数据的业务方，都去订阅这个MQ中的订单Binlog主题，消费解析后的Binlog数据。在每个消费者自己的同步程序中，它既可以直接入库，也可以做一些数据转换、过滤或者计算之后再入库，这样就比较灵活了。</p><h2>如何保证数据同步的实时性</h2><p>这个方法看起来不难，但是非常容易出现性能问题。有些接收Binlog消息的下游业务，对数据的实时性要求比较高，不能容忍太高的同步时延。比如说，每个电商在大促的时候，都会有一个大屏幕，实时显示现在有多少笔交易，交易额是多少。这个东西都是给老板们看的，如果说大促的时候，你让老板们半小时之后才看到数字，那估计你就得走人了。</p><p>大促的时候，数据量大、并发高、数据库中的数据变动频繁，同步的Binlog流量也非常大。为了保证这个同步的实时性，整个数据同步链条上的任何一个环节，它的处理速度都必须得跟得上才行。我们一步一步分析可能会出现性能瓶颈的环节。</p><p>源头的订单库，如果它出现繁忙，对业务的影响就不只是大屏延迟了，那就影响到用户下单了，这个问题是数据库本身要解决的，这里我们不考虑。再顺着数据流向往下看，Canal和MQ这两个环节，由于没什么业务逻辑，性能都非常好。所以，<strong>一般容易成为性能瓶颈的就是消费MQ的同步程序</strong>，因为这些同步程序里面一般都会有一些业务逻辑，而且如果下游的数据库写性能跟不上，表象也是这个同步程序处理性能上不来，消息积压在MQ里面。</p><p>那我们能不能多加一些同步程序的实例数，或者增加线程数，通过增加并发来提升处理能力呢？这个地方的并发数，还真不是随便说扩容就可以就扩容的，我来跟你讲一下为什么。</p><p>我们知道，MySQL主从同步Binlog，是一个单线程的同步过程。为什么是单线程？原因很简单，在从库执行Binlog的时候，必须按顺序执行，才能保证数据和主库是一样的。<strong>为了确保数据一致性，Binlog的顺序很重要，是绝对不能乱序的。</strong> 严格来说，对于每一个MySQL实例，整个处理链条都必须是单线程串行执行，MQ的主题也必须设置为只有1个分区（队列），这样才能保证数据同步过程中的Binlog是严格有序的，写到目标数据库的数据才能是正确的。</p><p>那单线程处理速度上不去，消息越积压越多，这不无解了吗？其实办法还是有的，但是必须得和业务结合起来解决。</p><p>还是拿订单库来说啊，其实我们并不需要对订单库所有的更新操作都严格有序地执行，比如说A和B两个订单号不同的订单，这两个订单谁先更新谁后更新并不影响数据的一致性，因为这两个订单完全没有任何关系。但是同一个订单，如果更新的Binlog执行顺序错了，那同步出来的订单数据真的就错了。</p><p>也就是说，我们只要保证每个订单的更新操作日志的顺序别乱就可以了。这种一致性要求称为<strong>因果一致性（Causal Consistency）</strong>，有因果关系的数据之间必须要严格地保证顺序，没有因果关系的数据之间的顺序是无所谓的。</p><p>基于这个理论基础，我们就可以并行地来进行数据同步，具体的做法是这样的。</p><p>首先根据下游同步程序的消费能力，计算出需要多少并发；然后设置MQ中主题的分区（队列）数量和并发数一致。因为MQ是可以保证同一分区内，消息是不会乱序的，所以我们需要把具有因果关系的Binlog都放到相同的分区中去，就可以保证同步数据的因果一致性。对应到订单库就是，相同订单号的Binlog必须发到同一个分区上。</p><p>这是不是和之前讲过的数据库分片有点儿像呢？那分片算法就可以拿过来复用了，比如我们可以用最简单的哈希算法，Binlog中订单号除以MQ分区总数，余数就是这条Binlog消息发往的分区号。</p><p>Canal自带的分区策略就支持按照指定的Key，把Binlog哈希到下游的MQ中去，具体的配置可以看一下<a href=\"https://github.com/alibaba/canal/wiki/Canal-Kafka-RocketMQ-QuickStart\">Canal接入MQ的文档</a>。</p><h2>小结</h2><p>对于海量数据，必须要按照查询方式选择数据库类型和数据的组织方式，才能达到理想的查询性能。这就需要把同一份数据，按照不同的业务需求，以不同的组织方式存放到各种异构数据库中。因为数据的来源大多都是在线交易系统的MySQL数据库，所以我们可以利用MySQL的Binlog来实现异构数据库之间的实时数据同步。</p><p>为了能够支撑众多下游数据库实时同步的需求，可以通过MQ解耦上下游，Binlog先发送到MQ中，下游各业务方可以消费MQ中的消息再写入各自的数据库。</p><p>如果下游处理能力不能满足要求，可以增加MQ中的分区数量实现并发同步，但需要结合同步的业务数据特点，把具有因果关系的数据哈希到相同分区上，才能避免因为并发乱序而出现数据同步错误的问题。</p><h2>思考题</h2><p>在我们这种数据同步架构下，如果说下游的某个同步程序或数据库出了问题，需要把Binlog回退到某个时间点然后重新同步，这个问题该怎么解决？欢迎你在留言区与我讨论。</p><p>感谢你的阅读，如果你觉得今天的内容对你有帮助，也欢迎把它分享给你的朋友。</p>","neighbors":{"left":{"article_title":"18 | 分布式存储：你知道对象存储是如何保存图片文件的吗？","id":220609},"right":{"article_title":"20 | 如何在不停机的情况下，安全地更换数据库？","id":221658}},"comments":[{"had_liked":false,"id":204437,"user_name":"李玥","can_delete":false,"product_type":"c1","uid":1501046,"ip_address":"","ucode":"B19E91EE248591","user_header":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","comment_is_top":true,"comment_ctime":1586399853,"is_pvip":false,"discussion_count":6,"race_medal":0,"score":"9.2233721844701e+18","product_id":100046801,"comment_content":"Hi，我是李玥。<br><br>这里回顾一下上节课的思考题：<br><br>对象存储并不是基于日志来进行主从复制的。假设我们的对象存储是一主二从三个副本，采用半同步方式复制数据，也就是主副本和任意一个从副本更新成功后，就给客户端返回成功响应。主副本所在节点宕机之后，这两个从副本中，至少有一个副本上的数据是和宕机的主副本上一样的，我们需要找到这个副本作为新的主副本，才能保证宕机不丢数据。但是没有了日志，如果这两个从副本上的数据不一样，我们如何确定哪个上面的数据是和主副本一样新呢？<br><br>这个问题有些同学已经在留言区给出了答案，一般都是基于版本号来解决，在Leader上，KEY每更新一次，KEY的版本号就加1，版本号作为KV的一个属性，一并复制到从节点上，通过比较版本号就可以知道哪个节点上的数据是最新的。<br><br>另外，有的同学提出用比较时间戳的方式来解决这个问题。这个方法理论上可行，但实际上非常难实现，因为它要求集群上的每个节点的时钟都必须时刻保持同步，这个要求往往非常难达到。","like_count":35,"discussions":[{"author":{"id":1187478,"avatar":"https://static001.geekbang.org/account/avatar/00/12/1e/96/c735ad6b.jpg","nickname":"滩涂曳尾","note":"","ucode":"40F650F2A419D4","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":359885,"discussion_content":"备忘：es默认是全同步主从复制，不存在这个问题，使用insync allocation id来维护已经有效分片。如果是半同步主从复制，则使用“版本号”来解决这个问题，本质上就是es中的seqid，是索引级别递增的。","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1616316521,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1183070,"avatar":"https://static001.geekbang.org/account/avatar/00/12/0d/5e/18d85358.jpg","nickname":"宋","note":"","ucode":"396EB6F3210DE1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":347983,"discussion_content":"这里好像有个问题，我们应该有个地方存储日志才对。因为如果程序有bug，我们存储的数据主从都是错误的。如果没有日志的话，应该就无力回天了。所以我理解应该是存储副本的同时也存储日志。不知道理解对不对","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1612403242,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1000037,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/42/65/f444ea39.jpg","nickname":"grandcool","note":"","ucode":"7545E76CE3FEFC","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":274807,"discussion_content":"选择新的主副本时怎么获取到这个版本号啊","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1590624256,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1121758,"avatar":"https://static001.geekbang.org/account/avatar/00/11/1d/de/62bfa83f.jpg","nickname":"aoe","note":"","ucode":"1C6201EDB4E954","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":236676,"discussion_content":"如果运维能保证集群的时间误差范围在“雪花片算法”允许的误差之内，应该可以实现","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587114966,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":2,"child_discussions":[{"author":{"id":1002938,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/4d/ba/83e6dcbf.jpg","nickname":"skyline","note":"","ucode":"4E73F9049751F6","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1121758,"avatar":"https://static001.geekbang.org/account/avatar/00/11/1d/de/62bfa83f.jpg","nickname":"aoe","note":"","ucode":"1C6201EDB4E954","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":255105,"discussion_content":"说了非常难达到，另外运维不想背这个锅🤣🤣","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588379883,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":236676,"ip_address":""},"score":255105,"extra":""},{"author":{"id":1121758,"avatar":"https://static001.geekbang.org/account/avatar/00/11/1d/de/62bfa83f.jpg","nickname":"aoe","note":"","ucode":"1C6201EDB4E954","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1002938,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/4d/ba/83e6dcbf.jpg","nickname":"skyline","note":"","ucode":"4E73F9049751F6","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":255118,"discussion_content":"厉害的运维","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588380919,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":255105,"ip_address":""},"score":255118,"extra":""}]}]},{"had_liked":false,"id":204482,"user_name":"豆腐居士","can_delete":false,"product_type":"c1","uid":1100239,"ip_address":"","ucode":"F7C82FEB60C2B8","user_header":"https://static001.geekbang.org/account/avatar/00/10/c9/cf/af720d94.jpg","comment_is_top":false,"comment_ctime":1586405246,"is_pvip":false,"replies":[{"id":"76478","content":"1. 停掉Canel；<br>2. 等MQ中所有的消息都消费完了。<br>3. 扩容MQ分区数，增加消费者实例数量。<br>4. 重新启动Canel。","user_name":"作者回复","user_name_real":"李玥","uid":"1501046","ctime":1586426737,"ip_address":"","comment_id":204482,"utype":1}],"discussion_count":9,"race_medal":0,"score":"147615293310","product_id":100046801,"comment_content":"如果预估了分区（队列）数量之后 随着业务数据的增长 需要增加分区 提高并发 怎么去做扩容？<br>因为统一笔订单需要打到同一个分区上 ","like_count":35,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491197,"discussion_content":"1. 停掉Canel；\n2. 等MQ中所有的消息都消费完了。\n3. 扩容MQ分区数，增加消费者实例数量。\n4. 重新启动Canel。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1586426737,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1965699,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/fe/83/df562574.jpg","nickname":"慎独明强","note":"","ucode":"DC2F7F2C0C8F60","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":331694,"discussion_content":"新建一个topic，扩大分区数。原有topic往新topic写消息，都保证顺序即可","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1606954736,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1340702,"avatar":"https://static001.geekbang.org/account/avatar/00/14/75/1e/356dbf4a.jpg","nickname":"Spike","note":"","ucode":"9CE0EE743A89C2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":294668,"discussion_content":"kafka 是可以做到不停机扩容的。虽然我没用过 MQ，但是试想一下这样可不可以？首先创建一个新的 topic，该 topic 具有需要的 partitions 个数。生产者开始在新的 topic 创建完成后开始写入，消费者则消费完老的 topic 后则自动切换到新的 topic。原理上也是作者回复的流程，只是节省了扩容过程花费的时间","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1595952287,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1886331,"avatar":"https://static001.geekbang.org/account/avatar/00/1c/c8/7b/153181d7.jpg","nickname":"夜辉","note":"","ucode":"9421385F51FF9E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1340702,"avatar":"https://static001.geekbang.org/account/avatar/00/14/75/1e/356dbf4a.jpg","nickname":"Spike","note":"","ucode":"9CE0EE743A89C2","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":366541,"discussion_content":"切换MQ分区数有个反应时间\n搜了下方案，感觉只能尽可能缩短这个时间，尽量做到无感","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618108845,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":294668,"ip_address":""},"score":366541,"extra":""}]},{"author":{"id":1980201,"avatar":"https://static001.geekbang.org/account/avatar/00/1e/37/29/b3af57a7.jpg","nickname":"凯文小猪","note":"","ucode":"36D8AD0229547F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":367789,"discussion_content":"这个实际上就是传统处理消息堆积的例子 将堆积的消息先转发出去 发到同一个topic的不同分区里 等这波高峰过去后再慢慢处理掉","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618470704,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1886331,"avatar":"https://static001.geekbang.org/account/avatar/00/1c/c8/7b/153181d7.jpg","nickname":"夜辉","note":"","ucode":"9421385F51FF9E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":366542,"discussion_content":"消息累积过多，也是这个处理方案\n先申请机器，扩容消费\n完了再恢复","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618108899,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1764061,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/ea/dd/438c6847.jpg","nickname":"肖恩","note":"","ucode":"10BC79BA204AB5","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":269717,"discussion_content":"同问","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589941544,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1210265,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Gswh7ibY4tubXhp0BXOmV2pXZ3XsXic1d942ZMAEgWrRSF99bDskOTsG1g172ibORXxSCWTn9HWUX5vSSUVWU5I4A/132","nickname":"奔奔奔跑","note":"","ucode":"F86EC205DCAACE","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":267871,"discussion_content":"同问，如何做到不停机扩容","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589703338,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1100239,"avatar":"https://static001.geekbang.org/account/avatar/00/10/c9/cf/af720d94.jpg","nickname":"豆腐居士","note":"","ucode":"F7C82FEB60C2B8","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":226180,"discussion_content":"能不能做到不停业务？\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586426847,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":205571,"user_name":"木头发芽","can_delete":false,"product_type":"c1","uid":1419723,"ip_address":"","ucode":"657B381C5DA963","user_header":"https://static001.geekbang.org/account/avatar/00/15/a9/cb/a431bde5.jpg","comment_is_top":false,"comment_ctime":1586676052,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"100370923860","product_id":100046801,"comment_content":"有点像cpu取指令的冒险，如果当前指令后n条指令跟当前指令没有上下文依赖就可以放入指令流水里并行执行力。计算机科学的各种理论真是到处都在用，学好基础是关键","like_count":24},{"had_liked":false,"id":221230,"user_name":"Geek_772139","can_delete":false,"product_type":"c1","uid":1902221,"ip_address":"","ucode":"06FBB079BC38EB","user_header":"","comment_is_top":false,"comment_ctime":1590453011,"is_pvip":false,"replies":[{"id":"81727","content":"本身row格式的binlog就是幂等的，mq也要求消费者必须具备幂等性。<br><br>所以，自然就支持重置。","user_name":"作者回复","user_name_real":"李玥","uid":"1501046","ctime":1590559192,"ip_address":"","comment_id":221230,"utype":1}],"discussion_count":1,"race_medal":0,"score":"61719995155","product_id":100046801,"comment_content":"今把binlog回退到某个时间点开始重新同步，这个需要mq消费端的消费进度支持重置，重置到过去的某一个消费进度就可以了","like_count":15,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":496390,"discussion_content":"本身row格式的binlog就是幂等的，mq也要求消费者必须具备幂等性。\n\n所以，自然就支持重置。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1590559192,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":225174,"user_name":"VincentJiang","can_delete":false,"product_type":"c1","uid":1003276,"ip_address":"","ucode":"BAD9A9C824C876","user_header":"https://static001.geekbang.org/account/avatar/00/0f/4f/0c/bf76644b.jpg","comment_is_top":false,"comment_ctime":1591673371,"is_pvip":false,"replies":[{"id":"83098","content":"PG也有WAL，和MySQL的Binlog是类似的。<br><br>你可以参考一下这个开源项目：https:&#47;&#47;github.com&#47;debezium&#47;debezium","user_name":"作者回复","user_name_real":"李玥","uid":"1501046","ctime":1591790710,"ip_address":"","comment_id":225174,"utype":1}],"discussion_count":1,"race_medal":0,"score":"35951411739","product_id":100046801,"comment_content":"请问老师，如果应用跨云（AWS和阿里）部署，并且使用的数据库不是MySQL而是PG，有什么好方法可以实时这种跨云数据同步？","like_count":9,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":497765,"discussion_content":"PG也有WAL，和MySQL的Binlog是类似的。\n\n你可以参考一下这个开源项目：https://github.com/debezium/debezium","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1591790710,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":205254,"user_name":"飞翔","can_delete":false,"product_type":"c1","uid":1068571,"ip_address":"","ucode":"65AF6AF292DAD6","user_header":"https://static001.geekbang.org/account/avatar/00/10/4e/1b/f4b786b9.jpg","comment_is_top":false,"comment_ctime":1586577103,"is_pvip":true,"replies":[{"id":"77027","content":"一般Canal是不会成为瓶颈的，你想，MySQL的主从同步也是单线程的，正常情况下也都不会有延迟的。","user_name":"作者回复","user_name_real":"李玥","uid":"1501046","ctime":1586831918,"ip_address":"","comment_id":205254,"utype":1}],"discussion_count":3,"race_medal":0,"score":"35946315471","product_id":100046801,"comment_content":"老师 mq 可以有多个 sharding key 是订单号，这样同一个订单号就可以保证到同一个mq里边去，保证顺序，但是canal不还是必须只有一个 不会成为瓶颈嘛","like_count":8,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491434,"discussion_content":"一般Canal是不会成为瓶颈的，你想，MySQL的主从同步也是单线程的，正常情况下也都不会有延迟的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586831918,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1316926,"avatar":"https://static001.geekbang.org/account/avatar/00/14/18/3e/f8632713.jpg","nickname":"EveryDayIsNew","note":"","ucode":"776B81EF6830FA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":322519,"discussion_content":"貌似MySQl新版本支持多线程了吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1604757761,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1386818,"avatar":"https://static001.geekbang.org/account/avatar/00/15/29/42/43d4b1a8.jpg","nickname":"烫烫烫","note":"","ucode":"C06018670DE76A","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1316926,"avatar":"https://static001.geekbang.org/account/avatar/00/14/18/3e/f8632713.jpg","nickname":"EveryDayIsNew","note":"","ucode":"776B81EF6830FA","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":331025,"discussion_content":"MySQL从库写relay log一直是单线程的，读relay log到磁盘这个过程，起初也是单线程，后面的版本加了多线程。我看canal的描述，它收到MySQL的binlog后好像没有写relay log的过程，直接转发给MQ，内存操作是很快的；不过我也没看canal的源码，不确定说的对不对","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606748012,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":322519,"ip_address":""},"score":331025,"extra":""}]}]},{"had_liked":false,"id":204652,"user_name":"Simon","can_delete":false,"product_type":"c1","uid":1068163,"ip_address":"","ucode":"107606167D23E8","user_header":"https://static001.geekbang.org/account/avatar/00/10/4c/83/7788fc66.jpg","comment_is_top":false,"comment_ctime":1586436567,"is_pvip":true,"replies":[{"id":"77038","content":"一般使用MQ，也可以做到秒级延迟。","user_name":"作者回复","user_name_real":"李玥","uid":"1501046","ctime":1586833516,"ip_address":"","comment_id":204652,"utype":1}],"discussion_count":1,"race_medal":0,"score":"27356240343","product_id":100046801,"comment_content":"老师，请问下都用mq了还能是实时同步数据嘛？","like_count":6,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491244,"discussion_content":"一般使用MQ，也可以做到秒级延迟。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586833516,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":204465,"user_name":"此方彼方Francis","can_delete":false,"product_type":"c1","uid":1001390,"ip_address":"","ucode":"73E6C93CF1FE39","user_header":"https://static001.geekbang.org/account/avatar/00/0f/47/ae/0a5f7a56.jpg","comment_is_top":false,"comment_ctime":1586403750,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"23061240230","product_id":100046801,"comment_content":"这节课感觉可以和MySQL同步数据到redis那节合起来。","like_count":6,"discussions":[{"author":{"id":1000473,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/44/19/17fadc62.jpg","nickname":"郭蕾","note":"","ucode":"34F4C07D1C5FE8","race_medal":0,"user_type":8,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":233884,"discussion_content":"是的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586950836,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":210286,"user_name":"陆老师","can_delete":false,"product_type":"c1","uid":1203293,"ip_address":"","ucode":"0EA27C4755FF4A","user_header":"https://static001.geekbang.org/account/avatar/00/12/5c/5d/974b033f.jpg","comment_is_top":false,"comment_ctime":1587714348,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"18767583532","product_id":100046801,"comment_content":"越到后面，留言的越少了。下游的某个同步程序或数据库出了问题，可以抛出异常不确认消息，这样，等数据库好了，再次进行消费，不过这样性能会差点，数据也有延迟。如果不想影响多个系统共用的MQ，可以把数据再发送到某个业务系统单独的MQ中去，后续自己单独慢慢消费","like_count":5},{"had_liked":false,"id":331767,"user_name":"阿甘","can_delete":false,"product_type":"c1","uid":1057843,"ip_address":"","ucode":"BC93175B70E05D","user_header":"https://static001.geekbang.org/account/avatar/00/10/24/33/bcf37f50.jpg","comment_is_top":false,"comment_ctime":1642753921,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"10232688513","product_id":100046801,"comment_content":"&gt; MySQL 主从同步 Binlog，是一个单线程的同步过程。为什么是单线程？原因很简单，在从库执行 Binlog 的时候，必须按顺序执行，才能保证数据和主库是一样的。为了确保数据一致性，Binlog 的顺序很重要，是绝对不能乱序的。<br>这是以前的MySQL了。从MySQL 5.6 版本起可以开启并行复制功能（slave_parallel_workers &gt; 0）实现多库并行化复制；MySQL 5.7 引入了MTS（Enhanced Muti‐threadedslaves）来实现并行复制，不再有基于库的并行复制限制，5.7.2 又进行了优化，增加了参数slave_parallel_type。","like_count":3},{"had_liked":false,"id":207277,"user_name":"永不止步","can_delete":false,"product_type":"c1","uid":1098221,"ip_address":"","ucode":"B5228B7EDF5921","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIY8df9yV6vQjOMxv5xym070hFT2GWYELpqBhxSicQoq5IqBx6teS1xJaomkOBeuzv4vkXRJfibqcMw/132","comment_is_top":false,"comment_ctime":1587040929,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"10176975521","product_id":100046801,"comment_content":"重新同步的话，下游的消费者需要满足幂等性，保证同一条记录只处理一次","like_count":2},{"had_liked":false,"id":204425,"user_name":"那时刻","can_delete":false,"product_type":"c1","uid":1150927,"ip_address":"","ucode":"B0D150856C3A4A","user_header":"https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg","comment_is_top":false,"comment_ctime":1586398228,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10176332820","product_id":100046801,"comment_content":"使用MQ的消息回放功能？","like_count":2},{"had_liked":false,"id":328665,"user_name":"大碗碗小婉婉","can_delete":false,"product_type":"c1","uid":1887979,"ip_address":"","ucode":"A2F24BDBC5CDA9","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIveS9MIL9ngiczzS9Nb2SibL7rw9uVHZnwo0SVYvX3MvAKnL7JHupcG8lCNvnYbicC02F5xmLFvZlkg/132","comment_is_top":false,"comment_ctime":1640830764,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1640830764","product_id":100046801,"comment_content":"同步es也用mq吗，看官网有一个adapter","like_count":0},{"had_liked":false,"id":326543,"user_name":"凯文小猪","can_delete":false,"product_type":"c1","uid":1980201,"ip_address":"","ucode":"36D8AD0229547F","user_header":"https://static001.geekbang.org/account/avatar/00/1e/37/29/b3af57a7.jpg","comment_is_top":false,"comment_ctime":1639556843,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1639556843","product_id":100046801,"comment_content":"二刷课程 谈一下心得体会：<br>这里canal分发mq主题采用的思想 和lamport老爷子的happened before是一样的：<br>1.两个共识或事件如果有因果关系 那么应该将其组织成偏序关系 发往一个队列 。这一点正巧和现代mq的分区思想吻合<br>2.没有因果关系的事件 因为空间时刻特性无法确定先后关系 所以干脆就并行分发到不同分区 释放掉压力","like_count":1},{"had_liked":false,"id":288443,"user_name":"凯文小猪","can_delete":false,"product_type":"c1","uid":1980201,"ip_address":"","ucode":"36D8AD0229547F","user_header":"https://static001.geekbang.org/account/avatar/00/1e/37/29/b3af57a7.jpg","comment_is_top":false,"comment_ctime":1618470626,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1618470626","product_id":100046801,"comment_content":"感谢老师的精彩介绍 对于因果一致性有了全新的认识，对于解决工作中的实际问题有了自信。最后谈下老师的问题：实际上解决思路就和之前老师说的一样 就是定期做snapshot 再讲mq当做binlog 利用mq的消息回溯来来回回擦数据就行了。唯一要注意的是消费者要做好幂等 不过这应该是互联网开发最基本的要求了吧","like_count":0},{"had_liked":false,"id":249292,"user_name":"djfhchdh","can_delete":false,"product_type":"c1","uid":1484184,"ip_address":"","ucode":"E71D75328CE398","user_header":"https://static001.geekbang.org/account/avatar/00/16/a5/98/a65ff31a.jpg","comment_is_top":false,"comment_ctime":1600573014,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1600573014","product_id":100046801,"comment_content":"这个下游的同步程序需要支持binlog同步的幂等操作，对于同一条binlog消息，要保证幂等性。","like_count":0,"discussions":[{"author":{"id":1594215,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIG2aw6bmrrxPkrwIyStmZsfaYVHzYbP05A8V9LCa8ZnKl7yYb4zHTyicN5grp03nnpRqgQicpsaTxg/132","nickname":"STOREFEE","note":"","ucode":"CF660E3FF11D95","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":349749,"discussion_content":"可以具体说明一下这个问题的具体解决方案吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1613495389,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":246816,"user_name":"victor","can_delete":false,"product_type":"c1","uid":1189890,"ip_address":"","ucode":"A5E3481207FEB2","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/oniasL8UwocGW1ficLibdRdV0n7pOlwH4eYdlJibvqSiaFpgJe98Xgp6aq4pWj9J14EUI95UKGAHa3Opmo9YSE75a1w/132","comment_is_top":false,"comment_ctime":1599485156,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1599485156","product_id":100046801,"comment_content":"多张表合并成一张宽表是如何同步哪？","like_count":0},{"had_liked":false,"id":244515,"user_name":"苗","can_delete":false,"product_type":"c1","uid":1088710,"ip_address":"","ucode":"5ECCC6C855E541","user_header":"https://static001.geekbang.org/account/avatar/00/10/9c/c6/05a6798f.jpg","comment_is_top":false,"comment_ctime":1598545240,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1598545240","product_id":100046801,"comment_content":"客户端的多个线程，每个线程绑定一个队列并行处理吗？","like_count":0},{"had_liked":false,"id":213981,"user_name":"旅途","can_delete":false,"product_type":"c1","uid":1212902,"ip_address":"","ucode":"5022477E8E9441","user_header":"https://static001.geekbang.org/account/avatar/00/12/81/e6/6cafed37.jpg","comment_is_top":false,"comment_ctime":1588606992,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1588606992","product_id":100046801,"comment_content":"mq主题和并发数一致，然后下游把这些主题都监听吗?","like_count":0},{"had_liked":false,"id":204805,"user_name":"丁小明","can_delete":false,"product_type":"c1","uid":1207622,"ip_address":"","ucode":"CC23857B8D75D5","user_header":"https://static001.geekbang.org/account/avatar/00/12/6d/46/e16291f8.jpg","comment_is_top":false,"comment_ctime":1586477760,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1586477760","product_id":100046801,"comment_content":"mysql本身的多线程主从同步也是基于这个原理吧","like_count":0},{"had_liked":false,"id":204457,"user_name":"一步","can_delete":false,"product_type":"c1","uid":1005391,"ip_address":"","ucode":"73CEA468CE70C3","user_header":"https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg","comment_is_top":false,"comment_ctime":1586402672,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1586402672","product_id":100046801,"comment_content":"确定出现问题的时间点，然后把这个时间点之后的数据，全部再重新处理对应的 binlog ，然后再发送到对应的MQ中","like_count":0},{"had_liked":false,"id":204397,"user_name":"yasin","can_delete":false,"product_type":"c1","uid":1248702,"ip_address":"","ucode":"129D6B1B0A9A10","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Ltu4XZ6MHlbeVk4Kt8aU4kPH7KK6FlTPwK5K6S1zX4y2wTF7J86SzFrfj6dDYkk1icgyPKiacUw0rcJvXucwPSKw/132","comment_is_top":false,"comment_ctime":1586395805,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1586395805","product_id":100046801,"comment_content":"订单号的id应该是时间序列递增的，将回退那个时间点的id找到，删除下游表里大于这个id的记录，然后再进行同步。","like_count":0},{"had_liked":false,"id":204363,"user_name":"饭饭","can_delete":false,"product_type":"c1","uid":1097426,"ip_address":"","ucode":"EF6F6B5F6839F3","user_header":"https://static001.geekbang.org/account/avatar/00/10/be/d2/1400c368.jpg","comment_is_top":false,"comment_ctime":1586392145,"is_pvip":false,"replies":[{"id":"76482","content":"oracle 也有类似的归档日志。","user_name":"作者回复","user_name_real":"李玥","uid":"1501046","ctime":1586428976,"ip_address":"","comment_id":204363,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1586392145","product_id":100046801,"comment_content":"非mysql 同步呢，mysqlsever  oracle 是否有对应功能或同步工具?","like_count":0,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491155,"discussion_content":"oracle 也有类似的归档日志。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586428976,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]}]}