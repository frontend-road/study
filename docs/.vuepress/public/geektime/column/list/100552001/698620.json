{"id":698620,"title":"35｜从高级功能拆解4款主流MQ的架构设计与实现","content":"<p>你好，我是文强。</p><p>到了本节课，我们就讲完了功能篇的所有知识点了。下面我根据本阶段的课程内容，整理了一下4款主流消息队列所支持的功能清单。</p><p><img src=\"https://static001.geekbang.org/resource/image/b8/5c/b8e4438217c6d8cf3c62f4bb6017655c.jpg?wh=1882x672\" alt=\"\"></p><p>在上面的表格中，你会发现一个现象，Pulsar 支持的功能最多，RabbitMQ 和 RocketMQ 其次，Kafka支持的功能最少。原因我们在<a href=\"https://time.geekbang.org/column/article/670240\">第01讲</a>中说过，和它们自身的定位和发展历史有关。</p><p>接下来我们从功能出发，来分析一下这4款主流消息队列的原理和使用方式。先来个说明，这节课中的每个部分都是独立的，你可以挑感兴趣的内容进行学习。</p><h2>RabbitMQ</h2><p>RabbitMQ 支持顺序消息、定时和延时消息、事务消息、优先级队列、死信队列、WebSocket 等功能，但是不支持消息查询、幂等消息和Schema。</p><h3>顺序消息</h3><p>如下图所示，RabbitMQ 顺序消息的核心是底层 Queue 维度的顺序存储模型。图中将 RouteKey=A 绑定给 Queue1，把RouteKey=B绑定给Queue2。发送数据时只要给需要顺序的消息设置相同的RouteKey，就能保证这些消息是有序的。</p><p><img src=\"https://static001.geekbang.org/resource/image/46/0e/46a346e837b4a937b834545f2e9b5a0e.jpg?wh=4539x1619\" alt=\"\"></p><p>需要注意的是，这个路由关系是在定义 Exchange 时绑定的，代码示例如下：</p><pre><code class=\"language-plain\"># 创建 queue\nchannel.queue_declare(queue='route_queue1', \n                      exclusive=True, durable=True)\n\n# 绑定 queue到交换机，并指定 routing key \nchannel.queue_bind(exchange='direct_exchange', \n                  queue=\"route_queue1\", routing_key=routingKey)\n</code></pre><!-- [[[read_end]]] --><p>绑定完成 Exchange 和 Queue 的关系后，就可以将消息投递到Queue中。下面的示例表示，RouteKey 为 A 的数据都会保存到名为 route_queue1 的 Queue 中。</p><pre><code class=\"language-plain\">channel.basic_publish(exchange='direct_exchange',\n                      routing_key='A',\n                      body=('hello world').encode(),\n                     properties=pika.BasicProperties(delivery_mode=2))\n</code></pre><h3>定时和延时消息</h3><p>RabbitMQ 的定时和延时消息，有基于死信队列和集成延迟插件两种方案，这部分已经在<a href=\"https://time.geekbang.org/column/article/690417\">第29讲</a>中详细讲了，就不展开了。</p><h3>事务消息</h3><p>RabbitMQ 的事务是指生产的事务，是在 Channel 维度生效的。底层是两阶段事务的实现，包含开启事务、提交事务、回滚事务三个阶段。</p><p>在 Channel 维度开启事务后，在这条 Channel 中生产的消息不会立即被投递到目标Exchange，而是会先在一个临时的 Exchange 中保存数据。当提交事务后，再把数据投递到实际的 Exchagne 中。如果事务回滚，则将临时数据丢弃。</p><p>下面是 RabbitMQ 使用事务的示例，代码中最重要的就是开启事务（txSelect）、提交事务（txCommit）、回滚事务（txRollback）三个函数的使用。</p><pre><code class=\"language-plain\">Connection connection=null;\nChannel channel=null;\ntry {\n   connection = factory.newConnection(); //连接工厂创建连接\n   channel = connection.createChannel(); //创建信道\n   channel.txSelect(); //开启事务\n   channel.queueDeclare(QUEUE_NAME, false, \n            false, false, null);  //绑定队列\n   channel.basicPublish(\"\", QUEUE_NAME,\n            null, \"Hello World!\".getBytes(StandardCharsets.UTF_8));\n   channel.txCommit();   //提交事务\n   System.out.println(\" [x] Sent '\" + message + \"'\");\n} catch (Exception e){\n   e.printStackTrace();\n   channel.txRollback(); //回滚事务\n}\n</code></pre><h3>优先级队列</h3><p>RabbitMQ 的优先级队列在<a href=\"https://time.geekbang.org/column/article/691903\">第31讲</a>有详细说明，它的效果是保证优先级高的消息能有先被消费者消费到。它的底层是通过优先级堆（Priority Heap）的数据结构进行消息优先级的排序，然后在消费的时候优先返回给客户优先级高的消息。</p><p>下面是使用优先级的代码示例，核心点是创建优先级队列时指定最大优先级，然后发送消息时给每个消息设置优先级。每个消息的优先级不能超过队列的最大优先级。在消费的时候，优先级高的消息会被优先消费。</p><pre><code class=\"language-plain\">// 创建了名为 priority_queue 的优先级队列，其最大优先级为 10。 \nchannel.queue_declare(queue='priority_queue', arguments={'x-max-priority': 10})\n\n// 向优先级队列 priority_queue 发送了一个带有优先级为 5 的消息\nchannel.basic_publish(exchange='', routing_key='priority_queue', body='Hello World!', properties=pika.BasicProperties(priority=5))\n</code></pre><h3>死信队列</h3><p>RabbitMQ 支持死信队列的功能。它的作用是，如果遇到<strong>客户端发送消息被拒绝</strong>、<strong>消息过期没被消费</strong>、<strong>队列达到最大长度</strong>三种场景，消息会被投递到死信队列中。</p><p>和其他常见的实现方案不同的是，RabbitMQ 的死信队列是在 Broker 中闭环完成的，客户端不需要感知到死信队列的逻辑。</p><p>从使用上看，RabbitMQ 的死信队列的使用分为三步。</p><ol>\n<li>创建死信交换机，定义一个名为 dlx_direct 的 Exchange。</li>\n</ol><pre><code class=\"language-plain\">channel.exchange_declare(\n    exchange='dlx_direct', exchange_type=ExchangeType.direct)\n</code></pre><ol start=\"2\">\n<li>创建死信队列，并绑定到死信交换机。创建一个名为 dead_queue 的 Queue，并将这个 Queue 绑定到名为 dlx_direct 的 Exchange 中。</li>\n</ol><pre><code class=\"language-plain\"># 定义死信交换机\nchannel.queue_declare(queue='dead_queue')\n# 死信队列绑定到第一步创建的死信\nchannel.queue_bind(\n    queue='dead_queue', exchange='dlx_direct', routing_key='dead_queue')\n</code></pre><ol start=\"3\">\n<li>创建正常队列时，设置死信属性。创建一个名为 dxl_queue 的正常队列，并给它设置死信队列的属性，设置死信队列为 dlx_direct，路由 Key 为 dead_queue。</li>\n</ol><pre><code class=\"language-plain\">channel.queue_declare(\n    queue=\"dlx_queue\",\n    arguments={\n        'x-dead-letter-exchange': 'dlx_direct',\n        'x-dead-letter-routing-key': 'dead_queue'\n    })\n</code></pre><p>当完成这三步后，在生产端就生产消费消息即可，当遇到上面说的三种场景，数据就会自动变为死信消息，从而进入死信队列。</p><p>如果要消费到死信队列中的消息，则直接按照普通的消费逻辑去消费死信队列对应的 Queue 里面的消息即可。</p><h3>WebSocket</h3><p>我们在<a href=\"https://time.geekbang.org/column/article/696749\">第34讲</a>中讲到，WebSocket 协议的支持分为<strong>协议的设计</strong>、<strong>内核</strong> <strong>WebSocket Server</strong> <strong>的支持</strong>两部分。RabbitMQ 支持 WebSocket ，在协议设计层面是以 STOMP over WebSockets 和 MQTT over WebSockets 的形式实现的。即没有单独设计协议，而是直接使用 STOMP 和 MQTT 协议以 WebSocket 的形式通信。</p><p>从使用上，需要先启用对应的插件，开启 STOMP over WebSockets 和 MQTT over WebSockets 的插件。具体如下所示：</p><pre><code class=\"language-plain\">// 启用基于Stomp协议的websocket插件：\nrabbitmq-plugins enable rabbitmq_web_stomp\n\n// 启用基于MQTT协议的websocket 插件\nrabbitmq-plugins enable rabbitmq_web_mqtt\n</code></pre><p>启用插件后，直接使用对应的协议编解码，然后通过 WebSocket 协议和 RabbitMQ Broker 交互即可。代码示例如下：</p><pre><code class=\"language-plain\">var ws = new WebSocket('ws://127.0.0.1:15674/ws');\nvar client = Stomp.over(ws);\n</code></pre><p>上面的示例，客户端通过 URL ws://127.0.0.1:15674/ws  和 Broker 建立通信，然后通过STOMP 协议进行通信。如果需要了解更多细节，可以参考官方文档 <a href=\"https://www.rabbitmq.com/web-stomp.html\">STOMP over WebSockets</a> 和 <a href=\"https://www.rabbitmq.com/web-mqtt.html\">MQTT over WebSockets</a>。</p><h2>RocketMQ</h2><p>RabbitMQ 支持顺序消息、定时和延时消息、事务消息、死信队列、消息查询、Schema等功能，不支持幂等、优先级队列、WebSocket功能。</p><h3>顺序消息</h3><p>RocketMQ 的顺序消息是一个独立的功能，它是通过消息组（MessageGroup）来实现顺序消息的功能。发送顺序消息时，需要为每条消息设置归属的消息组，相同消息组的多条消息能保证顺序。</p><p>如下图所示，携带MessageGroup1、MessageGroup2、MessageGroup3、MessageGroup4的消息，会被哈希发送到不同的Queue，同一个消息组的消息会被发送到同一个Queue。</p><p><img src=\"https://static001.geekbang.org/resource/image/09/cc/0997cb87cb30de8ff2a8b197df51d9cc.png?wh=1587x843\" alt=\"\" title=\"图片来源：https://rocketmq.apache.org/zh/docs/featureBehavior/03fifomessage\"></p><p>下面是一个发送顺序消息的代码示例，代码的核心是 setMessageGroup 函数，给这条消息设置一个消息组 fifoGroup001，同一个消息组的消息会发送到同一个 Queue。</p><pre><code class=\"language-plain\"> //顺序消息发送。\nMessageBuilder messageBuilder = new MessageBuilderImpl();;\nMessage message = messageBuilder.setTopic(\"topic\")\n                //设置消息索引键，可根据关键字精确查找某条消息。\n                .setKeys(\"messageKey\")\n                //设置消息Tag，用于消费端根据指定Tag过滤消息。\n                .setTag(\"messageTag\")\n                //设置顺序消息的排序分组，该分组尽量保持离散，避免热点排序分组。\n                .setMessageGroup(\"fifoGroup001\")\n                //消息体。\n                .setBody(\"messageBody\".getBytes())\n                .build();\ntry {\n     //发送消息，需要关注发送结果，并捕获失败等异常\n     SendReceipt sendReceipt = producer.send(message);\n     System.out.println(sendReceipt.getMessageId());\n} catch (ClientException e) {\n     e.printStackTrace();\n}\n</code></pre><h3>定时和延时消息</h3><p>我们在<a href=\"https://time.geekbang.org/column/article/690417\">第29讲</a>讲了 RocketMQ 定时和延时消息的底层原理，这里我们补充几点使用注意事项。</p><ol>\n<li>定时时间指的是消息到期的时间，延时时间需要转换成消息的到期时间，即当前系统时间后的某一个时间戳，而不是一段延时时长。</li>\n<li>定时时间的格式是毫秒级的Unix时间戳，即需要将要设置的时刻转换成时间戳形式。</li>\n<li>定时时长最大值默认为24小时，不支持自定义修改。</li>\n<li>定时时间必须设置在定时时长范围内，超过范围则定时不生效，服务端会立即投递消息。</li>\n</ol><p>下面来看一个定时消息的示例，代码中最需要注意的是 setDeliveryTimestamp，它设置了这条消息在10分钟后可以被消费者消费到。</p><pre><code class=\"language-plain\">//定时/延时消息发送\nMessageBuilder messageBuilder = new MessageBuilderImpl();;\n//以下示例表示：延迟时间为10分钟之后的Unix时间戳。\nLong deliverTimeStamp = System.currentTimeMillis() + 10L * 60 * 1000;\nMessage message = messageBuilder.setTopic(\"topic\")\n      //设置消息索引键，可根据关键字精确查找某条消息。\n      .setKeys(\"messageKey\")\n      //设置消息Tag，用于消费端根据指定Tag过滤消息。\n      .setTag(\"messageTag\")\n      .setDeliveryTimestamp(deliverTimeStamp)\n      //消息体\n      .setBody(\"messageBody\".getBytes())\n      .build();\ntry {\n    //发送消息，需要关注发送结果，并捕获失败等异常。\n    SendReceipt sendReceipt = producer.send(message);\n    System.out.println(sendReceipt.getMessageId());\n} catch (ClientException e) {\n    e.printStackTrace();\n}\n</code></pre><h3>事务消息</h3><p>我们在<a href=\"https://time.geekbang.org/column/article/690858\">第30讲</a>讲了 RocketMQ 事务的原理。它是一种基于生产 + 本地事务的两阶段事务实现。</p><p>从使用上来看，需要分为创建消息类型为TRANSACTION的Topic和发送事务消息两步。</p><ol>\n<li>创建 Topic，并设置 Topic 的 message.type 的属性为 TRANSACTION，示例如下：</li>\n</ol><pre><code class=\"language-plain\">./bin/mqadmin updatetopic -n localhost:9876 -t TestTopic -c DefaultCluster -a +message.type=TRANSACTION\n</code></pre><ol start=\"2\">\n<li>在生产端发送事务消息。下面是官网提供的事务Demo，可以看到的步骤是：先在构建生产者的时候初始化一个本地事务，然后开启生产的事务，再根据本地事务的执行情况，判断是否提交事务。如果本地事务执行成功，就提交事务，否则就回滚事务。代码里面有详细的注释说明，可以看一下。</li>\n</ol><pre><code class=\"language-plain\">&nbsp; &nbsp; //演示demo，模拟订单表查询服务，用来确认订单事务是否提交成功。\n&nbsp; &nbsp; private static boolean checkOrderById(String orderId) {\n&nbsp; &nbsp; &nbsp; &nbsp; return true;\n&nbsp; &nbsp; }\n&nbsp; &nbsp; //演示demo，模拟本地事务的执行结果。\n&nbsp; &nbsp; private static boolean doLocalTransaction() {\n&nbsp; &nbsp; &nbsp; &nbsp; return true;\n&nbsp; &nbsp; }\n&nbsp; &nbsp; public static void main(String[] args) throws ClientException {\n&nbsp; &nbsp; &nbsp; &nbsp; ClientServiceProvider provider = new ClientServiceProvider();\n&nbsp; &nbsp; &nbsp; &nbsp; MessageBuilder messageBuilder = new MessageBuilderImpl();\n&nbsp; &nbsp; &nbsp; &nbsp; //构造事务生产者：事务消息需要生产者构建一个事务检查器，用于检查确认异常半事务的中间状态。\n&nbsp; &nbsp; &nbsp; &nbsp; Producer producer = provider.newProducerBuilder()\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .setTransactionChecker(messageView -&gt; {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /**\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;* 事务检查器一般是根据业务的ID去检查本地事务是否正确提交还是回滚，此处以订单ID属性为例。\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;* 在订单表找到了这个订单，说明本地事务插入订单的操作已经正确提交；如果订单表没有订单，说明本地事务已经回滚。\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;*/\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; final String orderId = messageView.getProperties().get(\"OrderId\");\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (Strings.isNullOrEmpty(orderId)) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; // 错误的消息，直接返回Rollback。\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; return TransactionResolution.ROLLBACK;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; return checkOrderById(orderId) ? TransactionResolution.COMMIT : TransactionResolution.ROLLBACK;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; })\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .build();\n&nbsp; &nbsp; &nbsp; &nbsp; //开启事务分支。\n&nbsp; &nbsp; &nbsp; &nbsp; final Transaction transaction;\n&nbsp; &nbsp; &nbsp; &nbsp; try {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; transaction = producer.beginTransaction();\n&nbsp; &nbsp; &nbsp; &nbsp; } catch (ClientException e) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; e.printStackTrace();\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; //事务分支开启失败，直接退出。\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; return;\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; Message message = messageBuilder.setTopic(\"topic\")\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; //设置消息索引键，可根据关键字精确查找某条消息。\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .setKeys(\"messageKey\")\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; //设置消息Tag，用于消费端根据指定Tag过滤消息。\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .setTag(\"messageTag\")\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; //一般事务消息都会设置一个本地事务关联的唯一ID，用来做本地事务回查的校验。\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .addProperty(\"OrderId\", \"xxx\")\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; //消息体。\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .setBody(\"messageBody\".getBytes())\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .build();\n&nbsp; &nbsp; &nbsp; &nbsp; //发送半事务消息\n&nbsp; &nbsp; &nbsp; &nbsp; final SendReceipt sendReceipt;\n&nbsp; &nbsp; &nbsp; &nbsp; try {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sendReceipt = producer.send(message, transaction);\n&nbsp; &nbsp; &nbsp; &nbsp; } catch (ClientException e) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; //半事务消息发送失败，事务可以直接退出并回滚。\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; return;\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; /**\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;* 执行本地事务，并确定本地事务结果。\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;* 1. 如果本地事务提交成功，则提交消息事务。\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;* 2. 如果本地事务提交失败，则回滚消息事务。\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;* 3. 如果本地事务未知异常，则不处理，等待事务消息回查。\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;*\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;*/\n&nbsp; &nbsp; &nbsp; &nbsp; boolean localTransactionOk = doLocalTransaction();\n&nbsp; &nbsp; &nbsp; &nbsp; if (localTransactionOk) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; try {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; transaction.commit();\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; } catch (ClientException e) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; // 业务可以自身对实时性的要求选择是否重试，如果放弃重试，可以依赖事务消息回查机制进行事务状态的提交。\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; e.printStackTrace();\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; } else {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; try {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; transaction.rollback();\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; } catch (ClientException e) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; // 建议记录异常信息，回滚异常时可以无需重试，依赖事务消息回查机制进行事务状态的提交。\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; e.printStackTrace();\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; }\n</code></pre><h3>死信队列</h3><p>跟 RabbitMQ 不同的是，RocketMQ 的事务是<strong>消费的事务</strong>。即当一条消息初次消费失败，消息队列会自动进行消息重试。达到最大重试次数后，若消费依然失败，则表明消费者在正常情况下无法正确地消费该消息，此时，消息队列不会立刻将消息丢弃，而是将其发送到该消费者对应的特殊队列中。</p><p>消费端使用死信队列代码示例如下，核心就是在消费的时候设置死信队列名称和消费者组名称。设置了这两个参数，当消费消息失败，则消息会被投递到设置好的死信队列中。</p><pre><code class=\"language-plain\"> // 1. 创建DefaultMQPushConsumer实例\nDefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"DLQ_CONSUMER\");\n// 2. 设置NameServer地址\nconsumer.setNamesrvAddr(\"127.0.0.1:9876\");\n// 3. 设置死信队列名\nconsumer.setDLQName(\"DLQ_NAME\");\n// 4. 设置处理死信队列消息的消费者组\nconsumer.setDLQConsumerGroup(\"DLQ_CONSUMER_GROUP\");\n// 5. 启动消费者实例，连接NameServer\nconsumer.start();\n}\n</code></pre><h3>消息查询</h3><p>RocketMQ 支持丰富的查询功能，它提供了根据<strong>根据 Offset、<strong><strong>根据时间戳</strong></strong>、消息 ID</strong> 三种类型的消息查询。</p><p>从技术上来看，都是通过构建二级索引的方式来提高数据查询的速度。详细的技术实现，可以回顾一下<a href=\"https://time.geekbang.org/column/article/693006\">第32讲</a>。</p><p>根据 Offset 查询消息的代码示例如下。即消费者通过调用 Consumer 的 Pull 方法来获取指定队列（MessageQueue）的指定偏移量位置（offset）的消息，同时可以设置拉取的数量。下面的示例表示在获取 <code>queue1</code> 中，偏移量是从 10 开始的往后 32 条消息。</p><pre><code class=\"language-plain\">// 设置偏移量\nlong offset = 10;\n while (true) {\n&nbsp; &nbsp; // 拉取消息\n&nbsp; &nbsp; PullResult pullResult =consumer.pull(\"queue1\", \"*\", offset, 32);\n&nbsp; &nbsp; System.out.println(pullResult);\n\n&nbsp; &nbsp; // 更新偏移量\n&nbsp; &nbsp; offset = pullResult.getNextBeginOffset();\n\n&nbsp; &nbsp; // 消费消息并设置延迟，模拟业务处理\n&nbsp; &nbsp; Thread.sleep(1000);\n}&nbsp;\n</code></pre><p>根据时间戳查询消息的示例如下，可以使用 consumer.searchOffset 方法获取与指定时间戳最近的消息偏移量（Offset），然后再根据 Offset 去获取到对应的消息。</p><pre><code class=\"language-plain\">// 设置查询消息的时间戳（毫秒）\nlong timestamp = System.currentTimeMillis() - (1000 * 60 * 60);\n\n// 获取与时间戳最近的消息偏移量\nlong offset = consumer.searchOffset(mq, timestamp);\n\nwhile (true) {\n&nbsp; &nbsp; // 拉取消息\n&nbsp; &nbsp; PullResult pullResult = consumer.pull(mq, \"*\", offset, 32);\n&nbsp; &nbsp; System.out.println(pullResult);\n    // 更新偏移量\n&nbsp; &nbsp; offset = pullResult.getNextBeginOffset();\n\n&nbsp; &nbsp;// 消费消息并设置延迟，模拟业务处理\n&nbsp; &nbsp; Thread.sleep(1000);\n}\n</code></pre><p>据消息 ID 查询消息示例如下， 它需要使用到 MQAdmin 来查询消息。下面代码表示查询消息 ID 为 <code>k1</code> 的消息的内容。</p><pre><code class=\"language-plain\">// 创建 DefaultMQAdminExt 对象\nDefaultMQAdminExt mqAdmin = new DefaultMQAdminExt();\n// 设置 NameServer 地址\nmqAdmin.setNamesrvAddr(\"localhost:9876\");\n// 启动\nmqAdmin.start();\n\n// 查询消息 ID\nString msgId = \"k1\";\n\n// 根据消息 ID 查询消息\nMessageExt message = mqAdmin.viewMessage(\"TopicTest\", msgId);\n\n// 输出消息内容\nif (message != null) {\n&nbsp; &nbsp; System.out.println(\"Message: \" + message);\n} else {\n&nbsp; &nbsp; System.out.println(\"Message not found.\");\n}\n</code></pre><h3>Schema</h3><p>当前 RocketMQ 消息体的数据格式没有限制。当上游数据类型变更后，如果下游没有及时修改代码。就有可能解析失败，从而导致链路异常。为了解决这个问题，RocektMQ 近期引入了 RocketMQ Schema 来规范上下游数据的传递。</p><p>我们在<a href=\"https://time.geekbang.org/column/article/693034\">第33讲</a>详细讲解了它的实现，如果需要了解更多，可以去 GitHub 仓库 <a href=\"https://github.com/apache/rocketmq-schema-registry\">Apache Rocektme Schema</a> 查看更多信息。</p><h2>Kafka</h2><p>Kafka 支持顺序消息、幂等、事务消息、消息查询、Schema等功能，不支持定时和延时消息、优先级队列、死信队列、WebSocket 等功能。</p><h3>顺序消息</h3><p>Kafka 实现的顺序消息是单个生产者维度的顺序消息，即多个生产者之间的数据是无法保证有序的。</p><p>单个生产者实现顺序消息也有以下两个限制：</p><ul>\n<li>如果 Topic 只有一个分区，那么消息会根据服务端收到的数据顺序存储，则数据就是分区有序的。</li>\n<li>如果 Topic 有多个分区，可以在生产端指定这一类消息的 Key，这类消息都用相同的 Key 进行消息发送，Kafka 会根据 Key 哈希取模选取其中一个分区进行存储，由于一个分区只能由一个消费者进行监听消费，此时消息就具有消息消费的顺序性了。</li>\n</ul><p>另外需要注意客户端参数 linger.ms 的设置。如果设置了 linger.ms 大于 0，则消息重传可能会导致消息无法保证有序。因此就需要把 linger.ms 设置为0，即表示数据立即发送。</p><blockquote>\n<p><span class=\"reference\">linger.ms 表示消息延迟发送的时间，它的用处是可以等待更多的消息组成 batch 发送。默认为 0 表示立即发送。当待发送的消息达到 batch.size 设置的大小时，不管是否达到 linger.ms 设置的时间，请求也会立即发送。 </span></p>\n</blockquote><p>下面代码示例是表示，通过在生产端设置 linger.ms 和消息 ID 为 <code>key1</code>，来保证消息是有序的。</p><pre><code class=\"language-plain\">Properties props = new Properties();\nprops.put(ProducerConfig.LINGER_MS_CONFIG, \"1000\");\n\nKafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);\n\nproducer.send(new ProducerRecord&lt;&gt;(topic, \n    \"key1\",\"\"code:1,message:\" + Time.SYSTEM.nanoseconds()));\n\n</code></pre><h3>幂等</h3><p>我们在<a href=\"https://time.geekbang.org/column/article/689235\">第28讲</a>讲过，Kafka 支持<strong>生产的幂等</strong>，即通过为每个生产者分配唯一的 ProducerID 和为这个生产者发送的消息分配一个自增的序号 SeqNum 来唯一标识这条消息。Broker 会根据 ProducerID 和 SeqNum 来实现消息的重复判断，从而保证消息不重复。</p><p>下面是生产者开启幂等的代码示例。如下所示，核心代码是设置 enable.idempotence 为 true，只要设置了这个参数，就相当于开启幂等了，使用起来非常简单。</p><pre><code class=\"language-plain\">Properties props = new Properties();\nprops.put(\"bootstrap.servers\", bootstrap);\nprops.put(\"retries\", 2); // 重试次数\nprops.put(\"batch.size\", 100); // 批量发送大小\nprops.put(\"buffer.memory\", 33554432); // 缓存大小，根据本机内存大小配置\nprops.put(\"linger.ms\", 1000); // 发送频率，满足任务一个条件发送\nprops.put(\"client.id\", clientId); // 发送端id,便于统计 \"token#sfdiewrnxkcvvulsdfsdfdsijuiewrewr\"\nprops.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\nprops.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\nprops.put(\"enable.idempotence\", true); // 设置幂等性\nKafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);\nLong startTime = Time.SYSTEM.milliseconds();\nInteger count = 0;\nwhile (true) {\n    try {\n        // 开启事务\n        // 发送消息到producer-syn\n        producer.send(new ProducerRecord&lt;&gt;(topic, \"msg1\");\n       \n    } catch (Exception e) {\n        e.printStackTrace();\n    }\n}\n</code></pre><h3>事务消息</h3><p>Kafka 的事务是两阶段事务的实现，主要保证的是生产的事务。它可以保证对多个分区写入操作的原子性，操作的原子性是指多个操作要么全部成功，要么全部失败，不存在部分成功、部分失败的可能。</p><p>为了使用事务，需要在客户端显式设置唯一的 transactional.id 参数并开启幂等特性。因此通过将 transactional.id 参数设置为非空从而开启事务特性的同时，需要将 enable.idempotence 设置为 true。如果用户将 enable.idempotence 设置为 false，则会报错。</p><p>下面是Kafka 生产事务的使用示例。核心代码就是 transactional.id 和 enable.idempotence 参数的配置，以及 beginTransaction、commitTransaction、abortTransaction 三个步骤。</p><pre><code class=\"language-plain\">Properties props = new Properties();\nprops.put(\"bootstrap.servers\", bootstrap);\nprops.put(\"retries\", 2); // 重试次数\nprops.put(\"batch.size\", 100); // 批量发送大小\nprops.put(\"buffer.memory\", 33554432); // 缓存大小，根据本机内存大小配置\nprops.put(\"linger.ms\", 1000); // 发送频率，满足任务一个条件发送\nprops.put(\"client.id\", \"producer-txn-test\"); // 发送端id,便于统计\nprops.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\nprops.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\nprops.put(\"transactional.id\", txnId); // 每台机器唯一\nprops.put(\"enable.idempotence\", true); // 设置幂等性\nKafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);\nproducer.initTransactions();\nLong startTime = Time.SYSTEM.milliseconds();\nInteger count = 0;\nwhile (true) {\n    try {\n        // 开启事务\n        producer.beginTransaction();\n        // 发送消息到producer-syn\n        producer.send(new ProducerRecord&lt;&gt;(topic, \"message\"));\n    } catch (Exception e) {\n        e.printStackTrace();\n        // 终止事务\n        producer.abortTransaction();\n    }\n}\n</code></pre><h3>消息查询</h3><p>从功能上来看，Kafka 支持按照 Offset 和时间戳查询消息。从内核的实现来看，技术原理跟<a href=\"https://time.geekbang.org/column/article/693006\">第32讲</a>讲的是一致的，通过构建 Offset 和时间戳的二级索引来加快数据查询的速度。二级索引底层在底层的数据结构如下所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/53/cb/53a022326eb615b9e7a48269e2632bcb.png?wh=1696x398\" alt=\"\"></p><p>.timeindex 索引的内容如下所示：</p><pre><code class=\"language-plain\">timestamp: 1693001346933 offset: 62369391\ntimestamp: 1693001346957 offset: 62369395\ntimestamp: 1693001347033 offset: 62369397\ntimestamp: 1693001420165 offset: 62369402\ntimestamp: 1693001420203 offset: 62369408\n</code></pre><p>.index 索引的内容如下所示：</p><pre><code class=\"language-plain\">offset: 62369391 position: 4462\noffset: 62369395 position: 9664\noffset: 62369397 position: 13986\noffset: 62369402 position: 18309\noffset: 62369408 position: 23699\noffset: 62369414 position: 29882\noffset: 62369418 position: 35910\n</code></pre><p>所以从原理上看，根据 Offset 查询数据，就是通过 Offset 找到数据在文件中的具体位置。根据时间查询数据，就是通过时间找到 Offset，然后再根据 Offset 找到对应的数据。具体的实现原理可以回顾一下<a href=\"https://time.geekbang.org/column/article/693006\">第32讲</a>。</p><h3>Schema</h3><p>Kafka 社区版本支持的 Schema 不是一个完整的功能。完整的 Schema 只有在 Kafka 的商业化公司 Confluent 提供的商业化版本的 Kafka 才支持。比如 Kafka Schema Registry 这个项目是在 Confluent 公司的仓库中的，并没有贡献给Apache。</p><p>不过我们可以来看一下 Kafka Schema 的架构图。</p><p><img src=\"https://static001.geekbang.org/resource/image/9d/a3/9ddd78744ba4b47cc551839e95e903a3.png?wh=1001x566\" alt=\"\" title=\"图片来源：https://docs.confluent.io/platform/current/schema-registry/fundamentals/index.html\"></p><p>参考图示，你会发现架构的核心是Schema Register，它用来存储 Schema 相关信息，每个Schema ID也有唯一的ID。Producer 和 Consumer 都会从 Schema Register 获取缓存相关的 Schema 信息来实现数据的编码、解码、校验。</p><p>Kafka Schema 整体的架构思路和<a href=\"https://time.geekbang.org/column/article/693034\">第33讲</a>基本一致，如果需要可以去回顾一下。另外，想了解更多关于 Kafka Schema 的信息，可以参考Confluent 官方文档 <a href=\"https://docs.confluent.io/platform/current/schema-registry/index.html\">Kafka Schema Register</a>。</p><h2>Pulsar</h2><p>Pulsar 支持顺序消息、幂等、定时和延时消息、事务消息、死信队列、消息查询、Schema、WebSocket 等功能，不支持优先级队列。</p><p>因为 Pulsar 的发展很快，功能点的代码和设计思路都有持续的迭代和演化。当前的总结可能很快就会过期，所以我们把 Pulsar 的实现和设计放在思考题。你可以先根据官网资料学习一下最新的设计和实现。</p><h2>总结</h2><p>总结下来，你会发现不同消息队列在功能方面的支持是很不一样的，侧重点各有不同。但是同一个功能的底层实现原理，大家的思路基本是一致的。</p><p>从用户的角度来看，功能是选型的核心。所以在业务消息类的场景，我会优先推荐你使用RabbitMQ 或 RocketMQ。在流方向的场景，我会推荐你使用Kafka。详细选型建议回顾一下<a href=\"https://time.geekbang.org/column/article/670580\">第02讲</a>。</p><p>要了解完整的 RabbitMQ 官方支持的功能，可以直接查看这个<a href=\"https://www.rabbitmq.com/documentation.html\">官方文档</a>，这里面有详细的说明。</p><p>最后我想说明的是，虽然 Pulsar 支持的功能是最多的，但并不代表 Pulsar 是最优解。选型除了功能外，稳定性也是重要的考虑点。Pulsar 因为迭代较快，目前还处于快速发展阶段，一些功能还在开发中，在使用时需要判断是否适合生产场景。</p><h2>思考题</h2><p>因为Pulsar 是一个定位消息和流一体、发展速度很快的消息队列，所以我们并未在正文中进行总结。不过我们在表格中总结了 Pulsar 在功能层面的支持点，现在请你根据表格中的各个功能去学习一下 Pulsar 在这些功能上的使用和实现。</p><p>提示： 这些内容在 Pulsar 官网文档都可以找到相关资料。</p><p>欢迎分享你的想法，如果觉得有收获，也欢迎你把这节课分享给感兴趣的朋友。我们下节课再见！</p><h2><span class=\"orange\">上节课思考闭环</span></h2><p><span class=\"orange\">为什么在讲生产消费协议时我们说“简单理解成 WebSocket 是基于HTTP的”，请你从 WebSocket 建立连接、数据交互的角度来尝试回答一下这个问题。</span></p><p><span class=\"reference\">WebSocket 建立连接的过程主要包括以下几个步骤：</span></p><p><span class=\"reference\">1. 客户端发起HTTP请求：客户端（通常是浏览器）首先向服务器发送一个HTTP请求，这个请求是一个标准的HTTP请求，但是包含一些特殊的头信息，比如 “Upgrade: websocket” 和“Connection: Upgrade”，这些信息告诉服务器，客户端希望建立一个WebSocket连接。</span></p><p><span class=\"reference\">2. 服务器响应：如果服务器支持WebSocket，并且同意建立连接，那么服务器会返回一个HTTP 101 Switching Protocols 的响应，这个响应也包含一些特殊的头信息，比如 “Upgrade: websocket” 和 “Connection: Upgrade”，这些信息告诉客户端，服务器已经切换到了WebSocket协议。</span></p><p><span class=\"reference\">3. 握手完成，建立连接：一旦服务器返回了101响应，那么握手过程就完成了，WebSocket连接就建立了。此时，客户端和服务器就可以通过这个连接进行全双工、实时的数据传输。</span></p><p><span class=\"reference\">这个过程被称为 WebSocket 握手。值得注意的是，虽然握手过程使用的是HTTP协议，但是一旦连接建立，数据传输就不再使用HTTP协议，而是使用WebSocket协议。</span></p><p><span class=\"reference\">所以说，WebSocket协议可以简单理解成是基于HTTP 协议的。</span></p>","neighbors":{"left":{"article_title":"34｜WebSocket：如何在消息队列内核中支持WebSocket？","id":696749},"right":{"article_title":"36｜云原生：业界MQ的计算存储分离是如何实现的？","id":699321}},"comments":[{"had_liked":false,"id":391519,"user_name":"快手阿修","can_delete":false,"product_type":"c1","uid":1381325,"ip_address":"广东","ucode":"D9E1B87B0EAA9A","user_header":"https://static001.geekbang.org/account/avatar/00/15/13/cd/a1429abe.jpg","comment_is_top":false,"comment_ctime":1718414666,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":3,"score":2,"product_id":100552001,"comment_content":"【勘误】RocketMQ开头的RabbitMQ =&gt; RocketMQ","like_count":0}]}