{"id":596644,"title":"02｜缓存一致：读多写少时，如何解决数据更新缓存不同步？","content":"<p>你好，我是徐长龙，我们继续来看用户中心性能改造的缓存技巧。</p><p>上节课我们对数据做了归类整理，让系统的数据更容易做缓存。为了降低数据库的压力，接下来我们需要逐步给系统增加缓存。所以这节课，我会结合用户中心的一些业务场景，带你看看如何使用临时缓存或长期缓存应对高并发查询，帮你掌握高并发流量下缓存数据一致性的相关技巧。</p><p>我们之前提到过，互联网大多数业务场景的数据都属于读多写少，在请求的读写比例中，写的比例会达到百分之一，甚至千分之一。</p><p>而对于用户中心的业务来说，这个比例会更大一些，毕竟用户不会频繁地更新自己的信息和密码，所以这种读多写少的场景特别适合做读取缓存。通过缓存可以大大降低系统数据层的查询压力，拥有更好的并发查询性能。但是，使用缓存后往往会碰到更新不同步的问题，下面我们具体看一看。</p><h2>缓存性价比</h2><p>缓存可以滥用吗？在对用户中心优化时，一开始就碰到了这个有趣的问题。</p><p>就像刚才所说，我们认为用户信息放进缓存可以快速提高性能，所以在优化之初，我们第一个想到的就是将用户中心账号信息放到缓存。这个表有2000万条数据，主要用途是在用户登录时，通过用户提交的账号和密码对数据库进行检索，确认用户账号和密码是否正确，同时查看账户是否被封禁，以此来判定用户是否可以登录：</p><!-- [[[read_end]]] --><pre><code class=\"language-sql\"># 表结构\nCREATE TABLE `accounts` (\n  `id` int(10) unsigned NOT NULL AUTO_INCREMENT,\n  `account` varchar(15) NOT NULL DEFAULT '',\n  `password` char(32) NOT NULL,\n  `salt` char(16) NOT NULL,\n  `status` tinyint(3) NOT NULL DEFAULT '0'\n  `update_time` int(10) NOT NULL DEFAULT '0',\n  `create_time` int(10) NOT NULL DEFAULT '0',\n  PRIMARY KEY (`id`),\n) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;\n\n# 登录查询\nselect id, account, update_time from accounts \nwhere account = 'user1'\nand password = '6b9260b1e02041a665d4e4a5117cfe16'\nand status = 1\n</code></pre><p>这是一个很简单的查询，你可能会想：如果我们将2000万的用户数据放到缓存，肯定能提供性能很好的服务。</p><p>这个想法是对的，但不全对，因为它的性价比并不高：这个表查询的场景主要用于账号登录，用户即使频繁登录，也不会造成太大的流量冲击。因此，缓存在大部分时间是闲置状态，我们没必要将并发不高的数据放到缓存当中，浪费我们的预算。</p><p>这就牵扯到了一个很核心的问题，<strong>我们做缓存是要考虑性价比的</strong>。如果我们费时费力地把一些数据放到缓存当中，但并不能提高系统的性能，反倒让我们浪费了大量的时间和金钱，那就是不合适的。我们需要评估缓存是否有效，一般来说，只有热点数据放到缓存才更有价值。</p><h2>临时热缓存</h2><p>推翻将所有账号信息放到缓存这个想法后，我们把目标放到会被高频查询的信息上，也就是用户信息。</p><p>用户信息的使用频率很高，在很多场景下会被频繁查询展示，比如我们在论坛上看到的发帖人头像、昵称、性别等，这些都是需要频繁展示的数据，不过这些数据的总量很大，全部放入缓存很浪费空间。</p><p>对于这种数据，我建议使用临时缓存方式，就是在用户信息第一次被使用的时候，同时将数据放到缓存当中，短期内如果再次有类似的查询就可以快速从缓存中获取。这个方式能有效降低数据库的查询压力。常见方式实现的<strong>临时缓存</strong>的代码如下：</p><pre><code class=\"language-go\">// 尝试从缓存中直接获取用户信息\nuserinfo, err := Redis.Get(\"user_info_9527\")\nif err != nil {\n  return nil, err\n}\n\n//缓存命中找到，直接返回用户信息\nif userinfo != nil {\n  return userinfo, nil\n}\n\n//没有命中缓存，从数据库中获取\nuserinfo, err := userInfoModel.GetUserInfoById(9527)\nif err != nil {\n  return nil, err\n}\n\n//查找到用户信息\nif userinfo != nil {\n  //将用户信息缓存，并设置TTL超时时间让其60秒后失效\n  Redis.Set(\"user_info_9527\", userinfo, 60)\n  return userinfo, nil\n}\n\n// 没有找到，放一个空数据进去，短期内不再问数据库\n// 可选，这个是用来预防缓存穿透查询攻击的\nRedis.Set(\"user_info_9527\", \"\", 30)\nreturn nil, nil\n</code></pre><p>可以看到，我们的数据只是临时放到缓存，等待60秒过期后数据就会被淘汰，如果有同样的数据查询需要，我们的代码会将数据重新填入缓存继续使用。这种临时缓存适合表中数据量大，但热数据少的情况，可以降低热点数据的压力。</p><p>而之所以给缓存设置数据TTL，是为了节省我们的内存空间。当数据在一段时间内不被使用后就会被淘汰，这样我们就不用购买太大的内存了。这种方式相对来说有极高的性价比，并且维护简单，很常用。</p><h2>缓存更新不及时问题</h2><p>临时缓存是有TTL的，如果60秒内修改了用户的昵称，缓存是不会马上更新的。最糟糕的情况是在60秒后才会刷新这个用户的昵称缓存，显然这会给系统带来一些不必要的麻烦。其实对于这种缓存数据刷新，可以分成几种情况，不同情况的刷新方式有所不同，接下来我给你分别讲讲。</p><h3>1.单条实体数据缓存刷新</h3><p>单条实体数据缓存更新是最简单的一个方式，比如我们缓存了9527这个用户的info信息，当我们对这条数据做了修改，我们就可以在数据更新时同步更新对应的数据缓存：</p><pre><code class=\"language-go\">Type UserInfo struct {\n\tId         int    `gorm:\"column:id;type:int(11);primary_key;AUTO_INCREMENT\" json:\"id\"`\n\tUid        int    `gorm:\"column:uid;type:int(4);NOT NULL\" json:\"uid\"`\n\tNickName   string `gorm:\"column:nickname;type:varchar(32) unsigned;NOT NULL\" json:\"nickname\"`\n\tStatus     int16  `gorm:\"column:status;type:tinyint(4);default:1;NOT NULL\" json:\"status\"`\n\tCreateTime int64  `gorm:\"column:create_time;type:bigint(11);NOT NULL\" json:\"create_time\"`\n\tUpdateTime int64  `gorm:\"column:update_time;type:bigint(11);NOT NULL\" json:\"update_time\"`\n}\n\n//更新用户昵称\nfunc (m *UserInfo)UpdateUserNickname(ctx context.Context, name string, uid int) (bool, int64, error) {\n\t//先更新数据库\n  ret, err := m.db.UpdateUserNickNameById(ctx, uid, name)\n\tif ret {\n        //然后清理缓存，让下次读取时刷新缓存，防止并发修改导致临时数据进入缓存\n        //这个方式刷新较快，使用很方便，维护成本低\n\t\tRedis.Del(\"user_info_\" + strconv.Itoa(uid))\n\t}\n\treturn ret, count, err\n}\n\n</code></pre><p>整体来讲就是先识别出被修改数据的ID，然后根据ID删除被修改的数据缓存，等下次请求到来时，再把最新的数据更新到缓存中，这样就会有效减少并发操作把脏数据带入缓存的可能性。</p><p>除此之外，我们也可以给队列发更新消息让子系统更新，还可以开发中间件把数据操作发给子系统，自行决定更新的数据范围。</p><p>不过，通过队列更新消息这一步，我们还会碰到一个问题——条件批量更新的操作无法知道具体有多少个ID可能有修改，常见的做法是：先用同样的条件把所有涉及的ID都取出来，然后update，这时用所有相关ID更新具体缓存即可。</p><h3>2. 关系型和统计型数据缓存刷新</h3><p>关系型或统计型缓存刷新有很多种方法，这里我给你讲一些最常用的。</p><p>首先是<strong>人工维护缓存方式</strong>。我们知道，关系型数据或统计结果缓存刷新存在一定难度，核心在于这些统计是由多条数据计算而成的。当我们对这类数据更新缓存时，很难识别出需要刷新哪些<strong>关联</strong>缓存。对此，我们需要人工在一个地方记录或者定义特殊刷新逻辑来实现相关缓存的更新。</p><p><img src=\"https://static001.geekbang.org/resource/image/0a/cc/0a1ea9f053fa3c3cb8byy041d2070ecc.jpg?wh=1920x1234\" alt=\"图片\" title=\"人工维护缓存\"></p><p>不过这种方式比较精细，<strong>如果刷新缓存很多，那么缓存更新会比较慢，并且存在延迟</strong>。而且人工书写还需要考虑如何查找到新增数据关联的所有ID，因为新增数据没有登记在ID内，人工编码维护会很麻烦。</p><p>除了人工维护缓存外，还有一种方式就是通过<strong>订阅数据库来找到ID数据变化。</strong>如下图，我们可以使用Maxwell或Canal，对MySQL的更新进行监控。</p><p><img src=\"https://static001.geekbang.org/resource/image/48/7f/4833ec768edc882d4f081338e00aee7f.jpg?wh=1920x775\" alt=\"图片\" title=\"通过记录ID关系刷新缓存\"></p><p>这样变更信息会推送到Kafka内，我们可以根据对应的表和具体的SQL确认更新涉及的数据ID，然后根据脚本内设定好的逻辑对相 关key进行更新。例如用户更新了昵称，那么缓存更新服务就能知道需要更新user_info_9527这个缓存，同时根据配置找到并且删除其他所有相关的缓存。</p><p>很显然，这种方式的好处是能及时更新简单的缓存，同时核心系统会给子系统广播同步数据更改，代码也不复杂；缺点是复杂的关联关系刷新，仍旧需要通过人工写逻辑来实现。</p><p>如果我们表内的数据更新很少，那么可以采用<strong>版本号缓存设计</strong>。</p><p>这个方式比较狂放：一旦有任何更新，整个表内所有数据缓存一起过期。比如对user_info表设置一个key，假设是user_info_version，当我们更新这个表数据时，直接对 user_info_version 进行incr +1。而在写入缓存时，同时会在缓存数据中记录user_info_version的当前值。</p><p>当业务要读取user_info某个用户的信息的时候，业务会同时获取当前表的version。如果发现缓存数据内的版本和当前表的版本不一致，那么就会更新这条数据。但如果version更新很频繁，就会严重降低缓存命中率，所以这种方案适合更新很少的表。</p><p>当然，我们还可以对这个表做一个范围拆分，比如按ID范围分块拆分出多个version，通过这样的方式来减少缓存刷新的范围和频率。</p><p><img src=\"https://static001.geekbang.org/resource/image/b9/11/b97a93c01cc98e68a01d73b920115311.jpg?wh=1920x1234\" alt=\"图片\" title=\"版本号方式刷新缓存\"></p><p>此外，关联型数据更新还可以通过识别<strong>主要实体ID</strong>来刷新缓存。这要保证其他缓存保存的key也是主要实体ID，这样当某一条关联数据发生变化时，就可以根据主要实体ID对所有缓存进行刷新。这个方式的缺点是，我们的缓存要能够根据修改的数据反向找到它关联的主体ID才行。</p><p><img src=\"https://static001.geekbang.org/resource/image/3d/c1/3dfccf998db897ea07705621a06323c1.jpg?wh=1920x854\" alt=\"图片\" title=\"通过主要实体ID刷新缓存\"></p><p>最后，我再给你介绍一种方式：<strong>异步脚本遍历数据库刷新所有相关缓存</strong>。这个方式适用于两个系统之间同步数据，能够减少系统间的接口交互；缺点是删除数据后，还需要人工删除对应的缓存，所以更新会有延迟。但如果能配合订阅更新消息广播的话，可以做到准同步。</p><p><img src=\"https://static001.geekbang.org/resource/image/2c/c8/2cd645766ac43cf90aa5ddd5258898c8.jpg?wh=1920x811\" alt=\"图片\" title=\"遍历数据库刷新缓存\"></p><h2>长期热数据缓存</h2><p>到这里，我们再回过头看看之前的临时缓存伪代码，它虽然能解决大部分问题，但是请你想一想，当TTL到期时，<strong>如果大量缓存请求没有命中，透传的流量会不会打沉我们的数据库？</strong>这其实就是行业里常提到的缓存穿透问题，如果缓存出现大规模并发穿透，那么很有可能导致我们服务宕机。</p><p>所以，数据库要是扛不住平时的流量，我们就不能使用<strong>临时缓存</strong>的方式去设计缓存系统，只能用<strong>长期缓存</strong>这种方式来实现<strong>热点缓存</strong>，以此避免缓存穿透打沉数据库的问题。不过，要想实现长期缓存，就需要我们人工做更多的事情来保持缓存和数据表数据的一致性。</p><p>要知道，长期缓存这个方式自NoSQL兴起后才得以普及使用，主要原因在于长期缓存的实现和临时缓存有所不同，它要求我们的业务<strong>几乎完全不走数据库</strong>，并且服务运转期间所需的数据都要能在缓存中找到，同时还要保证使用期间缓存不会丢失。</p><p>由此带来的问题就是，我们需要知道缓存中具体有哪些数据，然后提前对这些数据进行预热。当然，如果数据规模较小，那我们可以考虑把全量数据都缓存起来，这样会相对简单一些。</p><p>为了加深理解，同时展示特殊技巧，下面我们来看一种“临时缓存+长期热缓存”的一个有趣的实现，这种方式会有小规模缓存穿透，并且代码相对复杂，不过总体来说成本是比较低的：</p><pre><code class=\"language-go\">// 尝试从缓存中直接获取用户信息\nuserinfo, err := Redis.Get(\"user_info_9527\")\nif err != nil {\n  return nil, err\n}\n\n//缓存命中找到，直接返回用户信息\nif userinfo != nil {\n  return userinfo, nil\n}\n\n//set 检测当前是否是热数据\n//之所以没有使用Bloom Filter是因为有概率碰撞不准\n//如果key数量超过千个，建议还是用Bloom Filter\n//这个判断也可以放在业务逻辑代码中，用配置同步做\nisHotKey, err := Redis.SISMEMBER(\"hot_key\", \"user_info_9527\")\nif err != nil {\n  return nil, err\n}\n\n//如果是热key\nif isHotKey {\n  //没有找到就认为数据不存在\n  //可能是被删除了\n  return \"\", nil\n}\n\n//没有命中缓存，并且没被标注是热点，被认为是临时缓存，那么从数据库中获取\n//设置更新锁set user_info_9527_lock nx ex 5\n//防止多个线程同时并发查询数据库导致数据库压力过大\nlock, err := Redis.Set(\"user_info_9527_lock\", \"1\", \"nx\", 5)\nif !lock {\n  //没抢到锁的直接等待1秒 然后再拿一次结果，类似singleflight实现\n  //行业常见缓存服务，读并发能力很强，但写并发能力并不好\n  //过高的并行刷新会刷沉缓存\n  time.sleep( time.second)\n  //等1秒后拿数据，这个数据是抢到锁的请求填入的\n  //通过这个方式降低数据库压力\n  userinfo, err := Redis.Get(\"user_info_9527\")\n  if err != nil {\n    return nil, err\n  }\n  return userinfo,nil\n}\n\n//拿到锁的查数据库，然后填入缓存\nuserinfo, err := userInfoModel.GetUserInfoById(9527)\nif err != nil {\n  return nil, err\n}\n\n//查找到用户信息\nif userinfo != nil {\n  //将用户信息缓存，并设置TTL超时时间让其60秒后失效\n  Redis.Set(\"user_info_9527\", userinfo, 60)\n  return userinfo, nil\n}\n\n// 没有找到，放一个空数据进去，短期内不再问数据库\nRedis.Set(\"user_info_9527\", \"\", 30)\nreturn nil, nil\n</code></pre><p>可以看到，这种方式是长期缓存和临时缓存的混用。当我们要查询某个用户信息时，如果缓存中没有数据，长期缓存会直接返回没有找到，临时缓存则直接走更新流程。此外，我们的用户信息如果属于热点key，并且在缓存中找不到的话，就直接返回数据不存在。</p><p>在更新期间，为了防止高并发查询打沉数据库，我们将更新流程做了简单的singleflight（请求合并）优化，只有先抢到缓存更新锁的线程，才能进入后端读取数据库并将结果填写到缓存中。而没有抢到更新锁的线程先 sleep 1秒，然后直接读取缓存返回结果。这样可以保证后端不会有多个线程读取同一条数据，从而冲垮缓存和数据库服务（缓存的写并发没有读性能那么好）。</p><p>另外，hot_key列表（也就是长期缓存的热点key列表）会在多个Redis中复制保存，如果要读取它，随机找一个分片就可以拿到全量配置。</p><p>这些热缓存key，来自于统计一段时间内数据访问流量，计算得出的热点数据。那长期缓存的更新会异步脚本去定期扫描热缓存列表，通过这个方式来主动推送缓存，同时把TTL设置成更长的时间，来保证新的热数据缓存不会过期。当这个key的热度过去后，热缓存key就会从当前set中移除，腾出空间给其他地方使用。</p><p>当然，如果我们拥有一个很大的缓存集群，并且我们的数据都属于热数据，那么我们大可以脱离数据库，将数据都放到缓存当中直接对外服务，这样我们将获得更好的吞吐和并发。</p><p>最后，还有一种方式来缓解热点高并发查询，在每个业务服务器上部署一个小容量的Redis来保存热点缓存数据，通过脚本将热点数据同步到每个服务器的小Redis上，每次查询数据之前都会在本地小Redis查找一下，如果找不到再去大缓存内查询，通过这个方式缓解缓存的读取性能。</p><h2>总结</h2><p>通过这节课，我希望你能明白：不是所有的数据放在缓存就能有很好的收益，我们要从<strong>数据量</strong>、<strong>使用频率</strong>、<strong>缓存命中率</strong>三个角度去分析。读多写少的数据做缓存虽然能降低数据层的压力，但要根据一致性需求对其缓存的数据做更新。其中，单条实体数据最容易实现缓存更新，但是有条件查询的统计结果并不容易做到实时更新。</p><p>除此之外，如果数据库承受不了透传流量压力，我们需要将一些热点数据做成<strong>长期缓存</strong>，来防止大量请求穿透缓存，这样会影响我们的服务稳定。同时通过singleflight方式预防临时缓存被大量请求穿透，以防热点数据在从临时缓存切换成热点之前，击穿缓存，导致数据库崩溃。</p><p>读多写少的缓存技巧我还画了一张导图，如下所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/1f/cc/1f6bfb4a04342fbedc254a817e577dcc.jpg?wh=3330x2141\" alt=\"\"></p><h2>思考题</h2><p>1.使用Bloom Filter识别热点key时，有时会识别失误，进而导致数据没有找到，那么如何避免这种情况呢？</p><p>2.使用Bloom Filter只能添加新key，不能删除某一个key，如果想更好地更新维护，有什么其他方式吗？</p><p>欢迎你在留言区与我交流讨论，我们下节课见！</p>","comments":[{"had_liked":false,"id":360820,"user_name":"Daniel","can_delete":false,"product_type":"c1","uid":1020529,"ip_address":"北京","ucode":"282E09B3146501","user_header":"https://static001.geekbang.org/account/avatar/00/0f/92/71/9fd7cd7a.jpg","comment_is_top":true,"comment_ctime":1666875528,"is_pvip":true,"replies":[{"id":131283,"content":"你好，Daniel，很高兴收到你的留言\n\n第一种方法，如果使用集合检测也可以达到同样效果，你提到的方法缺陷在于not_hotkey会很大，这里需要记录所有不是hot key的所有key。目前bloomfilter只是个模糊筛选，用小量数据换更好的性能，但是他确实误判概率多一些。\n\n第二个问题也是一个办法，但是需要我们能够精准控制这一批数据过期时间，但是我们在这节课用它主要是为了判断本地缓存中是否有这个缓存，由于无法判断所以需要每次询问，会导致系统更加复杂。\n\n第三个问题 主要是访问量，我们可以将一些key 做一些count统计，数据埋点就足够了，机器学习和深度学习的QPS有些低，我印象里，一个1w元的显卡做发音评分，一秒钟只能处理4个请求，场景不太适合，有点小才大用了。","user_name":"作者回复","user_name_real":"编辑","uid":1004527,"ctime":1666941201,"ip_address":"北京","comment_id":360820,"utype":1}],"discussion_count":3,"race_medal":0,"score":2,"product_id":100309001,"comment_content":"1. 使用 Bloom Filter 识别热点 key 时，有时会识别失误，进而导致数据没有找到，那么如何避免这种情况呢？\n\n通过我的 “机器学习的经验”，我觉得是这个布隆过滤器的哈希算法有点过拟合了，也就是说容错率高了，在资金充足的情况下先试着调低“容错率“(超参数)提升容量试试（不知道工业界上布隆过滤器的容错率能设置成 0%吗？但后期可能随着数据量的增长也是一个无限扩容的”吞金兽“呀），但我感觉我这个想法在工业界应该不成立。\n\n第二种方法，我想到的是，如果这个 key 被误识别为”hotkey”的话，就在内存中记入“not_hotkey”列表，每次数据进来的时候，先用 缓存里的 not_hotkey里的列表来筛，要是不是hotkey就做成临时缓存，要是这个key是hotkey的话，就进行长期缓存来处理。\n\n\n2. 使用 Bloom Filter 只能添加新 key，不能删除某一个 key，如果想更好地更新维护，有什么其他方式吗？\n\n对于长时间不用的 key ，我认为可以设置一个“失效时间”，比如 一周内不用，就自动清除掉这个key。\n之后在新的一周，把失效的key清理出去，再重新整理好一个列表，重新更新一遍这个布隆过滤器的新的哈希算法表。\n（但感觉这个方法貌似不是最优的，也要在半夜用户量访问少的时间点去做变更处理）\n\n\n老师想请教一个问题，对于 hotkey （热点数据）这个工业界的评价标准是不是不同行业会不一样呀？\n比较想知道工业界上是用什么方法（一般统计方法？机器学习聚类？深度学习网络？）和工具（数据埋点？用户操作行为分析？），来做 “热点数据”的 判别的？ ","like_count":3,"discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":591934,"discussion_content":"你好，Daniel，很高兴收到你的留言\n\n第一种方法，如果使用集合检测也可以达到同样效果，你提到的方法缺陷在于not_hotkey会很大，这里需要记录所有不是hot key的所有key。目前bloomfilter只是个模糊筛选，用小量数据换更好的性能，但是他确实误判概率多一些。\n\n第二个问题也是一个办法，但是需要我们能够精准控制这一批数据过期时间，但是我们在这节课用它主要是为了判断本地缓存中是否有这个缓存，由于无法判断所以需要每次询问，会导致系统更加复杂。\n\n第三个问题 主要是访问量，我们可以将一些key 做一些count统计，数据埋点就足够了，机器学习和深度学习的QPS有些低，我印象里，一个1w元的显卡做发音评分，一秒钟只能处理4个请求，场景不太适合，有点小才大用了。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1666941202,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":2,"child_discussions":[{"author":{"id":1020529,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/92/71/9fd7cd7a.jpg","nickname":"Daniel","note":"","ucode":"282E09B3146501","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":591970,"discussion_content":"看了老师的评论，感觉老师的实战经验是真丰富呀，👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1666960019,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":591934,"ip_address":"海南","group_id":0},"score":591970,"extra":""},{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":1020529,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/92/71/9fd7cd7a.jpg","nickname":"Daniel","note":"","ucode":"282E09B3146501","race_medal":0,"user_type":1,"is_pvip":true},"discussion":{"id":592262,"discussion_content":"多多交流，拱手","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1667266849,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":591970,"ip_address":"北京","group_id":0},"score":592262,"extra":""}]}]},{"had_liked":false,"id":360693,"user_name":"peter","can_delete":false,"product_type":"c1","uid":1058183,"ip_address":"北京","ucode":"261C3FC001DE2D","user_header":"https://static001.geekbang.org/account/avatar/00/10/25/87/f3a69d1b.jpg","comment_is_top":true,"comment_ctime":1666764447,"is_pvip":false,"replies":[{"id":131231,"content":"你好，peter，又见面了，感谢你的留言～\nQ1:由于我们的大多数数据都是有时效性的，我们很少去做永久的内存缓存，毕竟内存还是很贵的，我们需要考虑性价比。长期缓存可以是一天，临时TTL是30秒。同时长期的更新是定期脚本刷新，临时是用到才会放进去一会儿。再来看，长期的访问很频繁，如果放开会导致数据库压力很大，但是临时的由于访问量小所以不用特意防击穿。\nQ2:如果缓存压力不大可以用一个，如果很大会再做个L1缓存，在每台业务服务器上，这样能缓解核心缓存压力。\nQ3：这个属于人工写代码，如我更新了用户的昵称，那么我会刷新这个用户的所有帖子的缓存，以及这个用户的所有最近留言缓存，以及这个用户的个人信息缓存。这是一种，还有一种就是你说的界面配置规则，但是这些都是要能快速定位的才可以。你可能会碰到，用户昵称以rick开头的账号有多少个，当我们改昵称为这个的时候，对于这种条件多样的，刷新哪个缓存不好确定，只能临时缓存30秒等他过期后刷新","user_name":"作者回复","user_name_real":"作者","uid":1004527,"ctime":1666781242,"ip_address":"北京","comment_id":360693,"utype":1}],"discussion_count":3,"race_medal":0,"score":2,"product_id":100309001,"comment_content":"请教老师几个问题：\nQ1：缓存都是有超时时间的，从这个意义上说，都是“临时”的，为什么本文还要分为“临时”缓存和“长期”缓存？\nQ2：“临时”缓存和“长期”缓存在实现上可以用同一个软件吗？\n比如，两者都可以用Redis实现？或者，“临时缓存”是用一个组件实现（非Redis）而“长期缓存”用Redis实现？ 或者，“临时缓存”在代码中实现而“长期缓存”用Redis？\nQ3：人工维护缓存，怎么操作？\n缓存数据一般都比较多，人工怎么能够维护一堆数据？具体是怎么操作的？ 有一个界面，通过此界面来操作吗？","like_count":6,"discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":591730,"discussion_content":"你好，peter，又见面了，感谢你的留言～\nQ1:由于我们的大多数数据都是有时效性的，我们很少去做永久的内存缓存，毕竟内存还是很贵的，我们需要考虑性价比。长期缓存可以是一天，临时TTL是30秒。同时长期的更新是定期脚本刷新，临时是用到才会放进去一会儿。再来看，长期的访问很频繁，如果放开会导致数据库压力很大，但是临时的由于访问量小所以不用特意防击穿。\nQ2:如果缓存压力不大可以用一个，如果很大会再做个L1缓存，在每台业务服务器上，这样能缓解核心缓存压力。\nQ3：这个属于人工写代码，如我更新了用户的昵称，那么我会刷新这个用户的所有帖子的缓存，以及这个用户的所有最近留言缓存，以及这个用户的个人信息缓存。这是一种，还有一种就是你说的界面配置规则，但是这些都是要能快速定位的才可以。你可能会碰到，用户昵称以rick开头的账号有多少个，当我们改昵称为这个的时候，对于这种条件多样的，刷新哪个缓存不好确定，只能临时缓存30秒等他过期后刷新","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1666781242,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":2,"child_discussions":[{"author":{"id":2314165,"avatar":"https://static001.geekbang.org/account/avatar/00/23/4f/b5/bd6140a5.jpg","nickname":"ARM","note":"","ucode":"788FD0DBD39B94","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":598208,"discussion_content":"请老师check一下我的理解对不对\nQ1：临时缓存是针对短时间内高频的查询接口，长期缓存是针对业务普遍的高频接口。\nQ2：这个应该是多级缓存，本地缓存+分布式缓存（都设置有效时间）\nQ3：这个还是更新数据库，在更新缓存的逻辑。只不过更新缓存是删除用户id下所有的缓存信息，下次再查询。（例如这些留言、帖子的缓存都会跟着删除，下次请求到再写进去）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1672668338,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":591730,"ip_address":"浙江","group_id":0},"score":598208,"extra":""},{"author":{"id":2899279,"avatar":"","nickname":"Geek_9b16ba","note":"","ucode":"F6699B108BC7DC","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":623975,"discussion_content":"老师，您好，请问为什么需要把帖子的缓存和用户头像的缓存放在一起，而不是分为查询帖子缓存，和查询用户信息缓存 两次查询呢\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1690102477,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":591730,"ip_address":"河北","group_id":0},"score":623975,"extra":""}]}]},{"had_liked":false,"id":361342,"user_name":"奕","can_delete":false,"product_type":"c1","uid":1005391,"ip_address":"北京","ucode":"73CEA468CE70C3","user_header":"https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg","comment_is_top":false,"comment_ctime":1667441053,"is_pvip":false,"replies":[{"id":131428,"content":"你好，很高兴收到你的回复，没错！确实Cuckoo Filter能够解决所有问题！同时补充提醒：他也有一些缺点使用的时候要注意，性能没有bf高，同时删除存在误删情况～","user_name":"作者回复","user_name_real":"编辑","uid":1004527,"ctime":1667447071,"ip_address":"北京","comment_id":361342,"utype":1}],"discussion_count":3,"race_medal":0,"score":2,"product_id":100309001,"comment_content":"1. Bloom Filter 存在误报，会把不是热点的 key 识别成热点key, 所以需要一个 0误报的算法，数据结构 所以 Cuckoo Filter 布谷鸟过滤器来了\n2. 可以定期或者其他策略 重新构造 Bloom Filter\n\n&gt; 其实上面的2个问题，都可以使用 Cuckoo Filter 来解决","like_count":4,"discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":592494,"discussion_content":"你好，很高兴收到你的回复，没错！确实Cuckoo Filter能够解决所有问题！同时补充提醒：他也有一些缺点使用的时候要注意，性能没有bf高，同时删除存在误删情况～","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1667447071,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1346708,"avatar":"https://static001.geekbang.org/account/avatar/00/14/8c/94/5282994c.jpg","nickname":"huolang","note":"","ucode":"FDC4A6B6151C5E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":594485,"discussion_content":"布谷鸟过滤器是0误报？我咋没查到是0误报","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1669091234,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":1346708,"avatar":"https://static001.geekbang.org/account/avatar/00/14/8c/94/5282994c.jpg","nickname":"huolang","note":"","ucode":"FDC4A6B6151C5E","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":599464,"discussion_content":"不是 0 误报，概率问题","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1673531218,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":594485,"ip_address":"北京","group_id":0},"score":599464,"extra":""}]}]},{"had_liked":false,"id":360692,"user_name":"传输助手","can_delete":false,"product_type":"c1","uid":1128987,"ip_address":"北京","ucode":"E81A629D2E565E","user_header":"https://static001.geekbang.org/account/avatar/00/11/3a/1b/ca87cde9.jpg","comment_is_top":false,"comment_ctime":1666764059,"is_pvip":false,"replies":[{"id":131221,"content":"你好，传输助手，很高兴收到你的留言，这里有一个前提，就是我们加缓存的服务基本都是读并发高的服务，对于MySQL主库来说，问题就是全局只有一个主库，所以他是单点，同时更脆弱，理论上这种读压力尽量不要压到主库上～","user_name":"作者回复","user_name_real":"编辑","uid":1004527,"ctime":1666771965,"ip_address":"北京","comment_id":360692,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100309001,"comment_content":"读取数据库设置缓存的时候，为了不受数据库主从延迟的影响，是不是需要强制读主库？","like_count":3,"discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":591706,"discussion_content":"你好，传输助手，很高兴收到你的留言，这里有一个前提，就是我们加缓存的服务基本都是读并发高的服务，对于MySQL主库来说，问题就是全局只有一个主库，所以他是单点，同时更脆弱，理论上这种读压力尽量不要压到主库上～","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1666771965,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3010811,"avatar":"","nickname":"jayqiyoung","note":"","ucode":"344AC280A3DBED","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":608461,"discussion_content":"如果强制读主，回写缓存。那从库就没用了。从库的作用就是抗读。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1678451566,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":364925,"user_name":"一颗苹果","can_delete":false,"product_type":"c1","uid":1155236,"ip_address":"北京","ucode":"4C8E706D567A59","user_header":"https://static001.geekbang.org/account/avatar/00/11/a0/a4/04dfe530.jpg","comment_is_top":false,"comment_ctime":1671710319,"is_pvip":false,"replies":[{"id":132880,"content":"你好，一颗苹果，很高兴收到你的思路，这是个不错的办法。简单翻译一下，hashmap的hash环如果不够大，很多key都会碰撞在一个hash块内，而碰撞在一起的数据会在hashmap块内用链表保存，链表每次查找都要遍历所以会有一定性能下降，所以如果key少链表小的话会很快，当然这里没提及hash计算的时间复杂度。","user_name":"作者回复","user_name_real":"编辑","uid":1004527,"ctime":1671755211,"ip_address":"北京","comment_id":364925,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100309001,"comment_content":"布隆过滤器的缺点，可以用hashmap那个链表解决，遇到冲突了延伸出一个链表，但得标注清楚这个元素是哪个key的。链表是空，直接set和普通布隆过滤器一样，不是空就追加一个元素（标注好哪个key）。删除的话遇到链表也遍历，根据匹配的key来删除。如果足够稀疏，那性能和一般布隆一样，数据越密集性能越下降。要准确性就只能牺牲性能来换吧","like_count":2,"discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":597370,"discussion_content":"你好，一颗苹果，很高兴收到你的思路，这是个不错的办法。简单翻译一下，hashmap的hash环如果不够大，很多key都会碰撞在一个hash块内，而碰撞在一起的数据会在hashmap块内用链表保存，链表每次查找都要遍历所以会有一定性能下降，所以如果key少链表小的话会很快，当然这里没提及hash计算的时间复杂度。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1671755211,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3564759,"avatar":"https://static001.geekbang.org/account/avatar/00/36/64/d7/ac360f3c.jpg","nickname":"爱学习的伊蕾娜","note":"","ucode":"AD4883EA3FCC5D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":642119,"discussion_content":"用hash和set的主要问题是：随着数据量增大，所需内存也会不断变大。布隆过滤器消耗内存刚开始就设置好了，一般不变，而且较少","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1713327314,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":360716,"user_name":"Elvis Lee","can_delete":false,"product_type":"c1","uid":2098270,"ip_address":"北京","ucode":"A4B26AFFE817FA","user_header":"https://static001.geekbang.org/account/avatar/00/20/04/5e/5d2e6254.jpg","comment_is_top":false,"comment_ctime":1666777540,"is_pvip":false,"replies":[{"id":131229,"content":"你好，Elvis Lee，很高兴收到你的留言，不建议这样使用bloomfilter，主要原因在于，他的识别和md5计算结果一样，有的时候不同的key返回的结果是一致的，所以这样是拿不到准确结果的。","user_name":"作者回复","user_name_real":"编辑","uid":1004527,"ctime":1666780674,"ip_address":"北京","comment_id":360716,"utype":1}],"discussion_count":4,"race_medal":0,"score":2,"product_id":100309001,"comment_content":"1. 使用 Bloom Filter 识别热点 key 时，有时会识别失误，进而导致数据没有找到，那么如何避免这种情况呢？\n布隆可以判断一定不存在的数据，那么是否可以认为，只要插入不成功，即为热数据，但在设计布隆的时候需要根据业务来设置好容量和容错率。同时布隆删除操作在生产上不建议，最好是持久化后用版本号去区分。如果是离线链路，更推荐生成布隆文件，推送去客户端。实时的,目前接触是保存在Redis,Redis7的版本好像已经不需要插件","like_count":2,"discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":591726,"discussion_content":"你好，Elvis Lee，很高兴收到你的留言，不建议这样使用bloomfilter，主要原因在于，他的识别和md5计算结果一样，有的时候不同的key返回的结果是一致的，所以这样是拿不到准确结果的。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1666780674,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2098270,"avatar":"https://static001.geekbang.org/account/avatar/00/20/04/5e/5d2e6254.jpg","nickname":"Elvis Lee","note":"","ucode":"A4B26AFFE817FA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":591835,"discussion_content":"个人觉得因为布隆是有一定容错性，所以布隆只能做到部分拦截。\n数据量从小到大的解决：数据库&lt;本地缓存&lt;Redis&lt;布隆\n暂时没有想到其他方式，请老师指点","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1666853986,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"","child_discussion_number":2,"child_discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":2098270,"avatar":"https://static001.geekbang.org/account/avatar/00/20/04/5e/5d2e6254.jpg","nickname":"Elvis Lee","note":"","ucode":"A4B26AFFE817FA","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":591944,"discussion_content":"cuckoo filter","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1666946377,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":591835,"ip_address":"北京","group_id":0},"score":591944,"extra":""},{"author":{"id":2098270,"avatar":"https://static001.geekbang.org/account/avatar/00/20/04/5e/5d2e6254.jpg","nickname":"Elvis Lee","note":"","ucode":"A4B26AFFE817FA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":592440,"discussion_content":"谢谢老师解答","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1667404651,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":591944,"ip_address":"上海","group_id":0},"score":592440,"extra":""}]}]},{"had_liked":false,"id":362077,"user_name":"hhh","can_delete":false,"product_type":"c1","uid":1524385,"ip_address":"北京","ucode":"C760576D6B76F5","user_header":"https://static001.geekbang.org/account/avatar/00/17/42/a1/3c7ca6e9.jpg","comment_is_top":false,"comment_ctime":1668132932,"is_pvip":false,"replies":[{"id":131714,"content":"你好，hhh，时间不是绝对的这个可以根据情况进行调整，以前我们普遍是200ms左右，相对的这个方式比直接打沉中心数据库好那么一点，前提我们前端服务器足够多。","user_name":"作者回复","user_name_real":"编辑","uid":1004527,"ctime":1668144267,"ip_address":"北京","comment_id":362077,"utype":1}],"discussion_count":5,"race_medal":0,"score":2,"product_id":100309001,"comment_content":"没有抢到锁的sleep 1s然后去查询，这样接口耗时不是就会肯定大于1s吗 ，假如超时配置小于1s，这次请求不是必定会超时嘛","like_count":1,"discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":593391,"discussion_content":"你好，hhh，时间不是绝对的这个可以根据情况进行调整，以前我们普遍是200ms左右，相对的这个方式比直接打沉中心数据库好那么一点，前提我们前端服务器足够多。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1668144267,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3167302,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLz44WGtTHNfNiaficzyiasJAQgLcSh6cVLsTpczlXxIlbBXNhAT1qKbM4OZRpcWP56KAp2fHiaJVsKGw/132","nickname":"Geek_eabafe","note":"","ucode":"4D94487320B33B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":593655,"discussion_content":"是不是可以用类似自旋的方式，没获到锁的线程，读取缓存，没有缓存sleep200ms，最多等1s","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1668416971,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"","child_discussion_number":3,"child_discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":3167302,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLz44WGtTHNfNiaficzyiasJAQgLcSh6cVLsTpczlXxIlbBXNhAT1qKbM4OZRpcWP56KAp2fHiaJVsKGw/132","nickname":"Geek_eabafe","note":"","ucode":"4D94487320B33B","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":594211,"discussion_content":"可以，这里的问题就是会随着时间拉长堆积的任务越来越多，容易把缓存刷挂","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1668870530,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":593655,"ip_address":"北京","group_id":0},"score":594211,"extra":""},{"author":{"id":3564759,"avatar":"https://static001.geekbang.org/account/avatar/00/36/64/d7/ac360f3c.jpg","nickname":"爱学习的伊蕾娜","note":"","ucode":"AD4883EA3FCC5D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":642120,"discussion_content":"可不可以每50ms刷一次，如果刷到了就直接返回，没刷到等50ms再刷，这样刷缓存的频率也不是很高","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1713327489,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":594211,"ip_address":"广东","group_id":0},"score":642120,"extra":""},{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":3564759,"avatar":"https://static001.geekbang.org/account/avatar/00/36/64/d7/ac360f3c.jpg","nickname":"爱学习的伊蕾娜","note":"","ucode":"AD4883EA3FCC5D","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":642139,"discussion_content":"容易出问题，如果线上出现故障，缓存一直没刷上，感受下每台机器上万个线程一起刷的场景","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1713343560,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":642120,"ip_address":"北京","group_id":0},"score":642139,"extra":""}]}]},{"had_liked":false,"id":360903,"user_name":"Geek_xbye50","can_delete":false,"product_type":"c1","uid":1006424,"ip_address":"北京","ucode":"0BF3780C247F22","user_header":"","comment_is_top":false,"comment_ctime":1666958282,"is_pvip":false,"replies":[{"id":131292,"content":"建议先自己尝试回答，课后题答案后续看回答情况再公布。","user_name":"编辑回复","user_name_real":"编辑","uid":1501385,"ctime":1667011334,"ip_address":"北京","comment_id":360903,"utype":2}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100309001,"comment_content":"老师！但是课后题有答疑篇吗？","like_count":1,"discussions":[{"author":{"id":1501385,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e8/c9/59bcd490.jpg","nickname":"听水的湖","note":"","ucode":"B1759F90165D81","race_medal":0,"user_type":8,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":591992,"discussion_content":"建议先自己尝试回答，课后题答案后续看回答情况再公布。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1667011335,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":8}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":388066,"user_name":"黄堃健","can_delete":false,"product_type":"c1","uid":2037522,"ip_address":"广东","ucode":"B4AD5250A41B3A","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/YbUxEV3741vKZAiasOXggWucQbmicJwIjg3HDE58oyibYXbSop9QQFqZ7X6OhynDoo6rDHwzK8njSeJjN9hx3pJXg/132","comment_is_top":false,"comment_ctime":1709275642,"is_pvip":false,"replies":[{"id":141314,"content":"是的，但是，这个方式可以减少大量计算，当误判后再用一个算法复核一下就好了","user_name":"作者回复","user_name_real":"编辑","uid":1004527,"ctime":1709367609,"ip_address":"天津","comment_id":388066,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100309001,"comment_content":"老师，看了留言：说用布谷鸟过滤器，f = fingerprint(x);\ni1 = hash(x);\ni2 = i1 ⊕ hash( f);\n但是 由于存的是指纹， 用的是hash算法，不排除  data1，data2 计算的tingerprint(x),hash(x) 都相同。 这样可能存在误删，也存在误判情况","like_count":0,"discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":638218,"discussion_content":"是的，但是，这个方式可以减少大量计算，当误判后再用一个算法复核一下就好了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1709367609,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"天津","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":388057,"user_name":"黄堃健","can_delete":false,"product_type":"c1","uid":2037522,"ip_address":"广东","ucode":"B4AD5250A41B3A","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/YbUxEV3741vKZAiasOXggWucQbmicJwIjg3HDE58oyibYXbSop9QQFqZ7X6OhynDoo6rDHwzK8njSeJjN9hx3pJXg/132","comment_is_top":false,"comment_ctime":1709261838,"is_pvip":false,"replies":[{"id":141306,"content":"你好，这里是因为如果我缓存的是一批符合特定条件的列表数据，其中有几个数据状态发生了改变，由于缓存是被动的，当基础数据发生变化，我无法准确知道当前还有那些缓存保存的是过去的数据，所以无法对他们进行更新，这对数据并发高且准确性要求高的上层服务来说很致命","user_name":"作者回复","user_name_real":"作者","uid":1004527,"ctime":1709266497,"ip_address":"北京","comment_id":388057,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100309001,"comment_content":"不过，通过队列更新消息这一步，我们还会碰到一个问题——条件批量更新的操作无法知道具体有多少个 ID 可能有修改\n\n这会有什么问题？ 一条条更新不就是可以吗？ 因为没有接触过这块，不理解为什么要合并更新？","like_count":0,"discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":638131,"discussion_content":"你好，这里是因为如果我缓存的是一批符合特定条件的列表数据，其中有几个数据状态发生了改变，由于缓存是被动的，当基础数据发生变化，我无法准确知道当前还有那些缓存保存的是过去的数据，所以无法对他们进行更新，这对数据并发高且准确性要求高的上层服务来说很致命","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1709266497,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":388020,"user_name":"Kris","can_delete":false,"product_type":"c1","uid":1206813,"ip_address":"辽宁","ucode":"0D01BE449E1EC8","user_header":"https://static001.geekbang.org/account/avatar/00/12/6a/1d/466e21a0.jpg","comment_is_top":false,"comment_ctime":1709175633,"is_pvip":false,"replies":[{"id":141304,"content":"你好，可以这么做，但是ES其实2C服务不稳定，特定的查询他会存在返回缓慢问题，并且返回限制1w条。另外有个机制要注意有时候全量统计是增量统计，这个优化统计数据给人错觉很快（但是第一次查询会很慢）所以不太稳定","user_name":"作者回复","user_name_real":"编辑","uid":1004527,"ctime":1709261182,"ip_address":"北京","comment_id":388020,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100309001,"comment_content":"您好，请教一个问题：\n对于长期缓存的实现方式 是否可以用es去做长期缓存并通过监听数据库的binlog然后通过kafka去做长期缓存的数据同步","like_count":0,"discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":638122,"discussion_content":"你好，可以这么做，但是ES其实2C服务不稳定，特定的查询他会存在返回缓慢问题，并且返回限制1w条。另外有个机制要注意有时候全量统计是增量统计，这个优化统计数据给人错觉很快（但是第一次查询会很慢）所以不太稳定","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1709261183,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":383440,"user_name":"Gojustforfun","can_delete":false,"product_type":"c1","uid":1187021,"ip_address":"北京","ucode":"7513A40F27344F","user_header":"https://static001.geekbang.org/account/avatar/00/12/1c/cd/8d552516.jpg","comment_is_top":false,"comment_ctime":1699027953,"is_pvip":true,"replies":[{"id":139746,"content":"你好，后面会有类似选择，这里是当系统链接数据库报错是否返回空，这里推荐是告诉获取方系统错误，因为如果系统故障，会以为这个人没有买过这个商品或者没有领取过礼物，那么这个里会引起其他问题","user_name":"作者回复","user_name_real":"作者","uid":1004527,"ctime":1699260062,"ip_address":"北京","comment_id":383440,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100309001,"comment_content":"&#47;&#47;没有命中缓存，从数据库中获取\nuserinfo, err := userInfoModel.GetUserInfoById(9527)\nif err != nil {\n    &#47;&#47; 这里不放入空值的缓存,还是有缓存穿透的问题 \n    return nil, err\n}","like_count":0,"discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":631036,"discussion_content":"你好，后面会有类似选择，这里是当系统链接数据库报错是否返回空，这里推荐是告诉获取方系统错误，因为如果系统故障，会以为这个人没有买过这个商品或者没有领取过礼物，那么这个里会引起其他问题","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1699260062,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":373140,"user_name":"L","can_delete":false,"product_type":"c1","uid":1289120,"ip_address":"上海","ucode":"ED1EF491CCFC95","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKibpqtH0ORBMSibtP6DzJ9yZmWzSxzv9ULPZmXyDrduib1fFkacNiakhOuOEOrUILFbA7jXQq2NEFKUg/132","comment_is_top":false,"comment_ctime":1682090070,"is_pvip":false,"replies":[{"id":136323,"content":"你好，L，这种情况下本身就很难两全，建议缩小业务场景。通用的情况下是在课程中我提到的两个技巧，一种是直接缓存用TTL更新，不过这个只能降低数据库压力，不能保证实时性。另外一种是每个表有个版本号，如果表有任何更新都会更新这个版本号，这个虽然实时但是缓存命中率很低。","user_name":"作者回复","user_name_real":"编辑","uid":1004527,"ctime":1682242261,"ip_address":"北京","comment_id":373140,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100309001,"comment_content":"其中，单条实体数据最容易实现缓存更新，但是有条件查询的统计结果并不容易做到实时更新。\n\n那有条件的查询结果 这个怎么设计缓存会比较好？ 既能有数据的实时性，也避免DB高并发","like_count":0,"discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":615389,"discussion_content":"你好，L，这种情况下本身就很难两全，建议缩小业务场景。通用的情况下是在课程中我提到的两个技巧，一种是直接缓存用TTL更新，不过这个只能降低数据库压力，不能保证实时性。另外一种是每个表有个版本号，如果表有任何更新都会更新这个版本号，这个虽然实时但是缓存命中率很低。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1682242261,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":372103,"user_name":"阿昕","can_delete":false,"product_type":"c1","uid":1012906,"ip_address":"浙江","ucode":"F3AD093B68E074","user_header":"https://static001.geekbang.org/account/avatar/00/0f/74/aa/178a6797.jpg","comment_is_top":false,"comment_ctime":1680739265,"is_pvip":false,"replies":[{"id":135804,"content":"你好，阿昕，定期刷新是不错的方式，新增也要考虑好，有个麻烦的地方是如何统计新的bf应该留下哪些key","user_name":"作者回复","user_name_real":"编辑","uid":1004527,"ctime":1680774211,"ip_address":"北京","comment_id":372103,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100309001,"comment_content":"思考题：1.在拿不到值时，从数据库获取一次，Bloom Filter主要用途是过滤无效请求；2.按时时间进行切割，创建新的Bloom Filter；","like_count":0,"discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612540,"discussion_content":"你好，阿昕，定期刷新是不错的方式，新增也要考虑好，有个麻烦的地方是如何统计新的bf应该留下哪些key","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680774211,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":372048,"user_name":"helllocn","can_delete":false,"product_type":"c1","uid":1069514,"ip_address":"北京","ucode":"3B6E10F7F607FA","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIx9A2J1pCWjjqR4sfnVK0HDGEwqJwbwDPic7Kic1cl6L2DiaAfmBSaaLlVM80SgnIoAjjHbZVbCwJfA/132","comment_is_top":false,"comment_ctime":1680656452,"is_pvip":false,"replies":[{"id":135803,"content":"你好，hellocn，这是个有趣的方式，不过我们要预估好计划保留多少个","user_name":"作者回复","user_name_real":"编辑","uid":1004527,"ctime":1680774152,"ip_address":"北京","comment_id":372048,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100309001,"comment_content":"基于hotkey的思考，是否可以考虑LRU-K的算法，这样其实我们也不用维护hotkey了，基于缓存命中率调整系统K值，不知道是否高并发的线上系统是否会使用","like_count":0,"discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612539,"discussion_content":"你好，hellocn，这是个有趣的方式，不过我们要预估好计划保留多少个","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680774152,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":368722,"user_name":"errocks","can_delete":false,"product_type":"c1","uid":1139982,"ip_address":"广东","ucode":"D59C3B21B81173","user_header":"https://static001.geekbang.org/account/avatar/00/11/65/0e/6dee8123.jpg","comment_is_top":false,"comment_ctime":1676611388,"is_pvip":false,"replies":[{"id":134369,"content":"有趣，不过这里有个问题，多个hash有点浪费cpu","user_name":"作者回复","user_name_real":"编辑","uid":1004527,"ctime":1676966783,"ip_address":"北京","comment_id":368722,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100309001,"comment_content":"是否可以同时用多个哈希方法，降低误判的概率，假设用了四种哈希算法，如果两个key的四次结果都相同概率会降低很多","like_count":0,"discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":606138,"discussion_content":"有趣，不过这里有个问题，多个hash有点浪费cpu","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1676966783,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":368405,"user_name":"dk.wu","can_delete":false,"product_type":"c1","uid":2938336,"ip_address":"广东","ucode":"E9091207B646DB","user_header":"https://static001.geekbang.org/account/avatar/00/2c/d5/e0/addca785.jpg","comment_is_top":false,"comment_ctime":1676297780,"is_pvip":false,"replies":[{"id":135051,"content":"要想做好最后提及设计实现会有点麻烦，需要经常确认同步情况","user_name":"作者回复","user_name_real":"编辑","uid":1004527,"ctime":1678757416,"ip_address":"北京","comment_id":368405,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100309001,"comment_content":"如果采用布隆过滤器，那热键的量级一般成千上万。\nQ1：（1）常规方案：可以将误判的key，单独存到redis的哈希中，这种量级小，作为补充进行判断。出现这种情况，改造成本和空间成本综合最小。\n（2）定制化方案：据了解有挺多基于布隆过滤器的变种。\nQ2：（1）可能已经存在基于布隆过滤器的变种，例如Cuckoo支持。\n（2）考虑业务层面，hotkey的变化不会太频繁，定时刷新的话，那么可以重新初始化调整hotkey集合后的一个布隆过滤器，进行切换，有点像蓝绿发布模式，整个开关。","like_count":0,"discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":608952,"discussion_content":"要想做好最后提及设计实现会有点麻烦，需要经常确认同步情况","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1678757416,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":361930,"user_name":"Geek_lucas","can_delete":false,"product_type":"c1","uid":2497779,"ip_address":"北京","ucode":"AF728FA8C856F7","user_header":"https://static001.geekbang.org/account/avatar/00/26/1c/f3/833ad47e.jpg","comment_is_top":false,"comment_ctime":1667981972,"is_pvip":false,"replies":[{"id":131852,"content":"你好，是说另外记录一个key来记录他是否是hot_key吗","user_name":"作者回复","user_name_real":"编辑","uid":1004527,"ctime":1668665659,"ip_address":"北京","comment_id":361930,"utype":1}],"discussion_count":2,"race_medal":0,"score":3,"product_id":100309001,"comment_content":"1、key--&gt;hotkey布隆--&gt;不存在--&gt;非hotkey--&gt;进入非hotkey布隆\n2、key--&gt;hotkey布隆--&gt;存在--&gt;可能是hotkey--&gt;非hotkey布隆--&gt;不存在--&gt;可能是hotkey，当做hotkey处理\n3、key--&gt;hotkey布隆--&gt;存在--&gt;可能是hotkey--&gt;非hotkey布隆--&gt;存在--&gt;可能是非hotkey，当做非hotkey处理","like_count":0,"discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":593943,"discussion_content":"你好，是说另外记录一个key来记录他是否是hot_key吗","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1668665659,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2938336,"avatar":"https://static001.geekbang.org/account/avatar/00/2c/d5/e0/addca785.jpg","nickname":"dk.wu","note":"","ucode":"E9091207B646DB","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":603797,"discussion_content":"双重布隆，减少异常概率？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1676295872,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":361929,"user_name":"Geek_lucas","can_delete":false,"product_type":"c1","uid":2497779,"ip_address":"北京","ucode":"AF728FA8C856F7","user_header":"https://static001.geekbang.org/account/avatar/00/26/1c/f3/833ad47e.jpg","comment_is_top":false,"comment_ctime":1667980786,"is_pvip":false,"replies":[{"id":131851,"content":"你好，第一种有缺陷，因为我们的数据集很大，比如亿的key，第二种其实有办法只是代价选择","user_name":"作者回复","user_name_real":"编辑","uid":1004527,"ctime":1668665609,"ip_address":"北京","comment_id":361929,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100309001,"comment_content":"1. 使用 Bloom Filter 识别热点 key 时，有时会识别失误，进而导致数据没有找到，那么如何避免这种情况呢？\n答：学习数据结构的时候，我记得布隆过滤器，如果判断一个key命中，那么他【可能】有，如果判断一个key没有命中，那么他【一定】没有。所以应该反着来用，就是用来判断一个key，如果在hotkey布隆过滤器中没有命中，它一定不是hotkey。\n\n\n2. 使用 Bloom Filter 只能添加新 key，不能删除某一个 key，如果想更好地更新维护，有什么其他方式吗？\n无","like_count":0,"discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":593942,"discussion_content":"你好，第一种有缺陷，因为我们的数据集很大，比如亿的key，第二种其实有办法只是代价选择","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1668665609,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":361182,"user_name":"SunshineBoy","can_delete":false,"product_type":"c1","uid":1160644,"ip_address":"北京","ucode":"FC54CD1815CCBA","user_header":"https://static001.geekbang.org/account/avatar/00/11/b5/c4/9148b40d.jpg","comment_is_top":false,"comment_ctime":1667296369,"is_pvip":false,"replies":[{"id":131364,"content":"你好，建议对象存储配合cdn缓存实现","user_name":"作者回复","user_name_real":"编辑","uid":1004527,"ctime":1667304656,"ip_address":"北京","comment_id":361182,"utype":1}],"discussion_count":3,"race_medal":0,"score":3,"product_id":100309001,"comment_content":"哈喽 大佬 redis适合做app中一级、二级页面降级方案的存储吗？如果存储的value比较大，有没有推荐的降级方案？","like_count":0,"discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":592320,"discussion_content":"你好，建议对象存储配合cdn缓存实现","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1667304656,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":2,"child_discussions":[{"author":{"id":1160644,"avatar":"https://static001.geekbang.org/account/avatar/00/11/b5/c4/9148b40d.jpg","nickname":"SunshineBoy","note":"","ucode":"FC54CD1815CCBA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":592370,"discussion_content":"老师，app每个页面聚合了很多基础服务接口，这些接口性能比较差，经常挂，所以把基础服务数据缓存下来。这些数据有分发策略，不同的用户看到的用户数据是不一样的数据，想做到server基础服务挂了用户无感知，想在server聚合层做降级方案，既想要服务可用性，也想要数据一致性。现在是把整个页面的动态数据做了一个大value，存储到redis，瓶颈是一到高峰期会出现codis链接池打满，即使扩容，后续qps增长还是会出现这种情况。看了老师的文章，也觉得方案不合理。对于这块，老师有什么好的想法？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1667359300,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":592320,"ip_address":"北京","group_id":0},"score":592370,"extra":""},{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":1160644,"avatar":"https://static001.geekbang.org/account/avatar/00/11/b5/c4/9148b40d.jpg","nickname":"SunshineBoy","note":"","ucode":"FC54CD1815CCBA","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":592539,"discussion_content":"数据拼合可以不在业务接口上做，可以参考下go的BFF设计，通过这个方式将多个接口数据并行聚合起来，然后展示给用户","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1667470506,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":592370,"ip_address":"北京","group_id":0},"score":592539,"extra":""}]}]},{"had_liked":false,"id":360947,"user_name":"Sky","can_delete":false,"product_type":"c1","uid":1392585,"ip_address":"北京","ucode":"4C5A5AB73E8B90","user_header":"https://static001.geekbang.org/account/avatar/00/15/3f/c9/1ccefb9a.jpg","comment_is_top":false,"comment_ctime":1667022972,"is_pvip":false,"replies":[{"id":131313,"content":"你好，sky，很高兴收到你的留言，这样数据库压力会更大，这时需要特殊做，后续会讲到强一致怎么做","user_name":"作者回复","user_name_real":"编辑","uid":1004527,"ctime":1667043768,"ip_address":"北京","comment_id":360947,"utype":1}],"discussion_count":1,"race_medal":0,"score":4,"product_id":100309001,"comment_content":"在更新期间，为了防止高并发查询打沉数据库，我们将更新流程做了简单的 singleflight（请求合并）优化，只有先抢到缓存更新锁的线程，才能进入后端读取数据库并将结果填写到缓存中。而没有抢到更新锁的线程先 sleep 1 秒，然后直接读取缓存返回结果。这样可以保证后端不会有多个线程读取同一条数据，从而冲垮缓存和数据库服务（缓存的写并发没有读性能那么好）。\n\n并发更新的时候，为了防止超卖等问题，是不是最好还要在sql中加上乐观锁CAS？","like_count":0,"discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":592043,"discussion_content":"你好，sky，很高兴收到你的留言，这样数据库压力会更大，这时需要特殊做，后续会讲到强一致怎么做","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1667043769,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":360908,"user_name":"不吃包子","can_delete":false,"product_type":"c1","uid":2269341,"ip_address":"北京","ucode":"5E0661EC355ED9","user_header":"","comment_is_top":false,"comment_ctime":1666964023,"is_pvip":false,"replies":[{"id":131315,"content":"你好，不吃包子，很高兴收到你的留言，布谷鸟过滤器是一个不错的解决方案，另外查找不到缓存空也不错～","user_name":"作者回复","user_name_real":"编辑","uid":1004527,"ctime":1667044793,"ip_address":"北京","comment_id":360908,"utype":1}],"discussion_count":2,"race_medal":0,"score":4,"product_id":100309001,"comment_content":"针对1.2的问题，\n搜索到了如下解决方案： 调整布隆过滤器参数或者用布谷鸟过滤器。\n我想说说我自己的看法，针对误判的情况，能不能再加一层缓存？比如说一个数据被误判为有，则去查询数据库了，这个时候为空，记到缓存里面，如果下次再访问该数据的时候，直接从缓存返回。针对问题2 同样也维护一个删除的缓存。","like_count":0,"discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":592047,"discussion_content":"你好，不吃包子，很高兴收到你的留言，布谷鸟过滤器是一个不错的解决方案，另外查找不到缓存空也不错～","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1667044793,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3214843,"avatar":"https://static001.geekbang.org/account/avatar/00/31/0d/fb/a5fef3f7.jpg","nickname":"移横为固","note":"","ucode":"ECA3065E8485B0","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":592527,"discussion_content":"架构领域里有一句几乎是最著名的话：没有什么架构问题是加一层解决不了的，如果不行就再加一层。再加2层布隆过滤器","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1667464794,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}