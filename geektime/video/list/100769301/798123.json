{"id":798123,"title":"30｜工具扩展：利用GPT-4o模型识别文字与图像","content":"<p>你知道吗？2024年5月14日凌晨，OpenAI发布了一个新模型，叫做GPT-4o。这个 “o” 代表的是 “omni”，意思是全能的大模型。它不仅能对话，还能识别图片中的文字、物体、人物以及场景，真是非常强大。</p><p>巧的是，这个发布时间正好和我准备这节课的时间差了一个月。而就在这周，OpenAI兑现了他们的承诺，让免费用户也能直接使用GPT-4o。于是，我立马开始深度体验这个新模型。现在GPT-4o已经全面开放了，所以我想和你聊聊我的使用感受。</p><p>通过我的分享，你不仅可以在上手之前对GPT-4o的能力有所了解，还能在使用其他模型遇到难题时，知道如何通过GPT-4o找到解决方法。准备好了吗？让我们一起来探索吧！</p><p>如果你把GPT-4o看作是GPT-4的升级版，那么你最应该关注的就是它的<strong>拍照识图和实时语音</strong>功能。这两项功能可是它的亮点！</p><p>我先和你聊聊GPT-4o的拍照识图功能在我的工作场景中的应用吧。</p><h2>GPT-4o在工作场景的应用</h2><p><strong>应用场景一：</strong><strong>通过GPT-4o从截图中提取表格数据。</strong></p><p>在我的工作中，经常需要做数据汇报。汇报的方式有很多，比如邮件、Excel、Word，还有一种是通过截图。前几种格式，你现在应该已经得心应手了，但如果是一张包含Excel数据的手机截图，那就需要大模型来准确识别和提取表格中的数据，并还原到表格里。</p>","comments":[]}