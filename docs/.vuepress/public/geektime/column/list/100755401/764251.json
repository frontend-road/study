{"id":764251,"title":"13｜构建基于TQA模式的AI Agent","content":"<p>你好，我是徐昊，今天我们来继续学习AI时代的软件工程。</p><p>上节课我们介绍了三种通过大语言模型（Large Language Model，LLM）辅助用户故事编写的形式：通过LLM提取不可言说的业务知识，修改用户故事以及补充完善验收条件。</p><p>这三种方式都需要使用到一种特殊的LLM交互模式TQA（Thought-Question-Answer），TQA的主要用途是收集人的反馈，用以提高生成内容的质量。TQA是从推理行动（Reason-Act，ReACT）演化出来的交互模式。那么今天我们就来学习如何构造一个TQA的AI Agent。</p><h2>推理行动（Reason-Act）</h2><p>ReAct是一种专门为了LLM能执行某些操作任务而设计的模式。举个例子，当LLM收到一个问题时，它可以选择执行一个动作来检索相关信息，然后利用检索到的信息来回答问题。通过ReAct，LLM可以超越其常规功能，利用自然语言推理解决复杂任务。</p><p>ReAct也是目前最热门的一个LLM模式。前一阵子（2023年底）大火的ChatGPT Plugin，还有Microsoft开源的Semantic Kernel都是基于ReAct模式。</p><p>一个典型的ReAct Prompting通常包含四个部分：</p><!-- [[[read_end]]] --><ul>\n<li>上下文提示：提示LLM当前解决问题的上下文是什么。这几乎在所有LLM提示模版中都会用到。目的是让LLM开始了解我们到底想让它做什么。</li>\n<li>ReAct步骤：推理和行动规划的步骤。在所有 ReAct 提示中，思考-行动-观察（Thought-Action-Observation）是一个标准顺序。然而在具体情况中，我们会使用更为具体的“思考 ”行为。</li>\n<li>推理：通过“根据现状进行思考和推理”这样的通用指令或“让我们一步步思考”这样的思维链提示来实现推理。这部分通常还会包含少样本示例（few shots example），以提供如何将理由与行动联系起来的准确提示。</li>\n<li>行动：最后一个关键信息是行动指令集，LLM可以从中选择一个行动来响应推理思考。</li>\n</ul><p>下面让我们看一个例子：</p><blockquote>\n<p>Answer the following questions as best you can. You have access to the following tools:<br>\n//尽你所能地回答下面的问题，你可以使用如下的工具<br>\n&nbsp;<br>\nsearch, calculate<br>\n//搜索，计算<br>\n&nbsp;<br>\nUse the following format:<br>\n//回答问题时，使用下面的格式<br>\n&nbsp;<br>\nQuestion: the input question you must answer<br>\n//问题：你必须回答的用户提问<br>\nThought: you should always think about what to do<br>\n//思考：你应该永远思考要做什么<br>\nAction: the action to take, should be one of [search, calculate]<br>\n//行动：你要采取的行动，应该是[搜索，计算]其中之一<br>\nAction Input: the input to the action<br>\n//行动输入：给予工具的输入是什么<br>\nObservation: the result of the action<br>\n//观察：行为的结果是什么<br>\n… (this Thought/Action/Action Input/Observation can repeat N times)<br>\n//…(思考/行动/行动输入/观察 可以循环多次）<br>\nThought: I now know the final answer<br>\n//思考：现在我知道了最终答案<br>\nFinal Answer: the final answer to the original input question<br>\n//最终结果：原始问题的最终结果是什么。<br>\n&nbsp;<br>\nBegin!<br>\n//开始！<br>\n&nbsp;<br>\nQuestion: 淘宝去年双十一的营业额，可以买多少瓶可乐<br>\nThought:</p>\n</blockquote><p>在上面这个提示词中，四部分分别对应的是：</p><ul>\n<li>上下文提示：尽可能回答用户提出的问题。</li>\n<li>ReAct步骤：Thought/Action/Action Input/Observation</li>\n<li>推理：就是展开解释Thought，Action，Action Input，Observation分别要做什么。</li>\n<li>行动：Search, Calculate</li>\n</ul><p>如果我们在ChatGPT中直接使用这个提示词，会得到如下结果：</p><p><img src=\"https://static001.geekbang.org/resource/image/8d/cf/8d34c09d686ff130f3606152dc3c85cf.jpg?wh=1323x1098\" alt=\"\"></p><p>可以看到，在一开始LLM就给出了解决问题的思路，先搜索淘宝的双十一的营业额，然后计算可以购买多少可乐。而这个思路则是根据我们提供的行动分解的。</p><p>因为我们并不能给ChatGPT提供可执行的行动（search，calculate），所以我们并没得到真正的结果，但是在这个过程中，ChatGPT展示了正确的思路以及在哪个环节需要去调用什么行为。</p><p>因此，ReAct模式也成为了LLM与其他工具交互的主要模式。这种由LLM推理并控制其他工具调用的方式，也被称作AI Agent。现在（2024年）主流的LLM框架几乎都支持构建以ReAct为核心的AI Agent。</p><p>我们上面例子里的提示词，就来自LangChain的ReAct模板：</p><blockquote>\n<p>Answer the following questions as best you can. You have access to the following tools:<br>\n&nbsp;<br>\n{tools}<br>\n&nbsp;<br>\nUse the following format:<br>\n&nbsp;<br>\nQuestion: the input question you must answer<br>\nThought: you should always think about what to do<br>\nAction: the action to take, should be one of [{tool_names}]<br>\nAction Input: the input to the action<br>\nObservation: the result of the action<br>\n… (this Thought/Action/Action Input/Observation can repeat N times)<br>\nThought: I now know the final answer<br>\nFinal Answer: the final answer to the original input question<br>\n&nbsp;<br>\nBegin!<br>\n&nbsp;<br>\nQuestion: {input}<br>\nThought:{agent_scratchpad}</p>\n</blockquote><p>而使用类似下面的代码，就可以真正运行这个agent（当然，需要提供真实的Tool，这部分请自行查阅LangChain或其他框架的文档）：</p><pre><code class=\"language-plain\">import openai\nimport os\nfrom langchain.llms import OpenAI\nfrom langchain.agents import load_tools\nfrom langchain.agents import initialize_agent\nfrom dotenv import load_dotenv\nload_dotenv()\n\nos.environ[\"OPENAI_API_KEY\"] = getpass()\nfrom langchain import OpenAI, Wikipedia\nfrom langchain.agents import initialize_agent, Tool\nfrom langchain.agents import AgentType\n\ntools = [\n    Tool(\n        name=\"Search\",\n        func=...,\n        description=\"useful for when you need to ask with search\"\n    ),\n    Tool(\n        name=\"Calculate\",\n        func=...,\n        description=\"useful for when you need to calculate\"\n    )\n]\nllm = OpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\nreact = initialize_agent(tools, llm, agent=AgentType.REACT_DOCSTORE, verbose=True)\nreact.run(\"淘宝去年双十一的营业额，可以买多少瓶可乐\")\n</code></pre><p>需要注意一点，目前与推理有关的提示词受基础语料的影响极大，因而不同语言编写的提示词推理效果有显著差异。对于ChatGPT而言，ReAct形式的提示词，用英语编写会有更好的结果。</p><h2>想-问-答（Thought-Question-Answer）</h2><p>理解了推理行动模式，那么想-问-答只不过提供了不同的响应步骤而已。那么用于验收条件编写的TQA提示词是这样的：</p><blockquote>\n<p>You are a business analyst who is familiar with specification by example.  I’m the domain expert.<br>\n//你是一个业务分析师，而我是领域专家<br>\n&nbsp;<br>\n===CONTEXT<br>\n{context}<br>\n===END OF CONTEXT<br>\n&nbsp;<br>\n===USER STORY<br>\n{story}<br>\n===END OF USER STORY<br>\n&nbsp;<br>\nExplain the user story as scenarios. Use the following format:<br>\n//使用 场景 解释用户故事，并遵循如下格式<br>\n&nbsp;<br>\nThought: you should always think about what is still uncertain about the user story. Ignore technical concerns.<br>\n//思考：你应该考虑用户故事中不清晰的部分。但忽略技术细节<br>\nQuestion: the question to ask to clarify the user story<br>\n//问题：提出问题帮助你澄清这个用户故事<br>\nAnswer: the answer I responded to the question<br>\n//回答：我给出答案<br>\n… (this Thought/Question/Answer repeat at least 3 times, at most 10 times)<br>\n//（Thought/Question/Answer 重复至少3次而不多于10次）<br>\nThought: I know enough to explain the user story<br>\n//思考：我已经对这个用户故事了解了足够多的内容<br>\nScenarios: List all possible scenarios with concrete example in<br>\nGiven/When/Then style<br>\n// 场景：列出所有场景。使用Given/When/Then的格式表述<br>\n{history}<br>\n{input}</p>\n</blockquote><p>这是一个典型的ReAct形式的提示词，四部分分别对应的是：</p><ul>\n<li>上下文提示：你是一个业务分析师，而我是领域专家。与一般的ReAct不同，我们的上下文提示中，还包含了业务背景和具体的用户故事。</li>\n<li>ReAct步骤：Thought/Question/Answer</li>\n<li>推理：就是展开解释Thought，Question，Answer分别要做什么。</li>\n<li>行动：行动只有一个，就是Answer（向人来问问题）。</li>\n</ul><p>此外，因为是连续发问，我们不希望LLM反复询问同一个问题，也需要保持记录之前提问的内容，所以包含了历史记录（{history}）。</p><p>同样，如果我们将这个提示词展开直接放入ChatGPT，并不会得到我们想要的效果：</p><p><img src=\"https://static001.geekbang.org/resource/image/a8/0f/a842f47f86126586f91139f2dd585b0f.jpg?wh=1396x7024\" alt=\"\"></p><p>可以看到ChatGPT进入了自问自答模式，并没有给人机会来提供真正的答案。想要实现人与LLM的互动问答，需要使用<strong>LLM API中的停止序列（Stop Sequence）</strong>。在模型生成内容的过程中，如果碰到指定的<strong>停止序列</strong>，模型就会停在那个位置。例如句子或列表的结尾，或者是问答环节中提问的部分。</p><p>显而易见，在TQA中，停止序列是 “<strong>Answer:</strong>”，也就是碰到需要等待用户给予反馈的时候停下，等用户输入完成之后，再继续后续的推理和任务。</p><p>对于不同的LLM API而言，停止序列的设定各有不同，请详细阅读文档。然后在前面给出的Agent例子中，替换提示词模板，就可以实现一个基于TQA的Agent了。</p><h2>小结</h2><p>一旦我们理解了ReAct和TQA背后的实现机制，对于它们是如何发出提问，并根据提问继续完成后续任务就有了充分的理解。这里我们需要注意的是，在TQA模式中，起到关键作用的除了ReAct之外，还有上下文和历史记录部分。</p><p>这也对应了我们在<a href=\"https://time.geekbang.org/column/article/763970\">上一节课</a>提到了三种回答方式：</p><ol>\n<li>模板中 {context} 表示了业务整体的解决方案：如果LLM提出的问题，包含了对于基础概念或流程的误解，<strong>那么我们要重新修改业务背景说明，</strong>也就是修改了模板中表示业务上下文的部分。</li>\n<li>模版中 {story} 表示了当前的用户故事：如果LLM提出的问题，包含了对于操作的误解，<strong>那么我们要重新修改用户故事，</strong>也就是修改了模板中表示用户故事的部分。</li>\n<li>模版中 {history} 表示之前回答过的历史记录：如果LLM提出的问题，仅仅是关于交互细节的，那么我们只需要在会话中回答这些细节就可以了，这些细节会被记入历史记录。</li>\n</ol><p>因而TQA一个很好的例子，它展示了我们如何在交互过程中利用特定的文本结构，构成有效的反馈。</p><h2>思考题</h2><p>请根据不同的用户故事场景（前台，API），改写TQA模板，增加LLM反馈的内容。</p><p>欢迎你在留言区分享自己的思考或疑惑，我们会把精彩内容置顶供大家学习讨论。</p>","comments":[{"had_liked":false,"id":389424,"user_name":"术子米德","can_delete":false,"product_type":"c1","uid":1898023,"ip_address":"日本","ucode":"382EA7E2AF0B56","user_header":"https://static001.geekbang.org/account/avatar/00/1c/f6/27/c27599ae.jpg","comment_is_top":false,"comment_ctime":1712529453,"is_pvip":true,"replies":[{"id":141663,"content":"thought是llm ","user_name":"作者回复","user_name_real":"编辑","uid":2537798,"ctime":1712539509,"ip_address":"北京","comment_id":389424,"utype":1}],"discussion_count":3,"race_medal":0,"score":2,"product_id":100755401,"comment_content":"🤔☕️🤔☕️🤔\n【R】TQA = &lt;想&gt;Thought-&lt;问&gt;Question-&lt;答&gt;Answer\n（an evolution of ReACT&lt;Thought&#47;Action&#47;Action Input&#47;Observation&gt;）\n用于：提取不可言说的业务知识、修改用户故事、补充完善验收条件。\n【Q】告诉LLM从哪方面想&lt;Thought&gt;，然后LLM根据上下文、进行推理后会向我发问&lt;Question&gt;，由我来回答&lt;Answer&gt;，再继续来几轮TQA，如此这般嘛？\n如果每轮的Answer由我来回答，那下一轮的Thought是我每次新给出，还是预定义要进行哪几方面的Thought？\n— by 术子米德@2024年4月7日","like_count":0,"discussions":[{"author":{"id":2537798,"avatar":"https://static001.geekbang.org/account/avatar/00/26/b9/46/758ecf4a.jpg","nickname":"徐八叉","note":"","ucode":"DA6D1EB08A7396","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":641345,"discussion_content":"thought是llm ","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1712539509,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":1,"child_discussions":[{"author":{"id":1898023,"avatar":"https://static001.geekbang.org/account/avatar/00/1c/f6/27/c27599ae.jpg","nickname":"术子米德","note":"","ucode":"382EA7E2AF0B56","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":2537798,"avatar":"https://static001.geekbang.org/account/avatar/00/26/b9/46/758ecf4a.jpg","nickname":"徐八叉","note":"","ucode":"DA6D1EB08A7396","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":641420,"discussion_content":"让LLM自己产生Thought Chain，这个意思嘛？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1712622462,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":641345,"ip_address":"浙江","group_id":0},"score":641420,"extra":""}]},{"author":{"id":1121758,"avatar":"https://static001.geekbang.org/account/avatar/00/11/1d/de/62bfa83f.jpg","nickname":"aoe","note":"","ucode":"1C6201EDB4E954","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":641363,"discussion_content":"llm会根据用户故事、上下文，你上一轮的答案继续发问，直到他没问题为止，或有了对第一次问题的解决方案","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1712555206,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":389545,"user_name":"范飞扬","can_delete":false,"product_type":"c1","uid":2721761,"ip_address":"广东","ucode":"A665DF46833A81","user_header":"https://static001.geekbang.org/account/avatar/00/29/87/e1/b3edcc09.jpg","comment_is_top":false,"comment_ctime":1712814767,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100755401,"comment_content":"实践出真知，直接用我的代码在本地跑起来～\n\n我把老师的方法和 Prompt 做了微调，不需要处理 history 和 Stop Sequence，也不需要手写OutputParser，感觉自己实现还是比较优雅的哈哈~\n\n代码在文章最后~：https:&#47;&#47;mp.weixin.qq.com&#47;s?__biz=Mzg3MDg5MzYyMA==&amp;mid=2247483961&amp;idx=1&amp;sn=792be3eb1c598edd8e256e86359aa398&amp;chksm=ce879362f9f01a74ead04c804e77f9a93e802f51c506cdb6520d641137c4db82576cdccfe255&amp;token=1482009703&amp;lang=zh_CN#rd","like_count":3},{"had_liked":false,"id":389609,"user_name":"范飞扬","can_delete":false,"product_type":"c1","uid":2721761,"ip_address":"浙江","ucode":"A665DF46833A81","user_header":"https://static001.geekbang.org/account/avatar/00/29/87/e1/b3edcc09.jpg","comment_is_top":false,"comment_ctime":1713057539,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100755401,"comment_content":"原文：模板中 {context} 表示了业务整体的解决方案。\n\n这里不准确，根据上一讲[1]， context 不仅包含了整体解决方案，还包含了用户旅程。\n\n\n[1] 12讲的原文：“ 为 LLM 提供整体解决方案和用户旅程作为业务背景说明；”","like_count":0},{"had_liked":false,"id":389529,"user_name":"范飞扬","can_delete":false,"product_type":"c1","uid":2721761,"ip_address":"广东","ucode":"A665DF46833A81","user_header":"https://static001.geekbang.org/account/avatar/00/29/87/e1/b3edcc09.jpg","comment_is_top":false,"comment_ctime":1712796911,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100755401,"comment_content":"思考题：请根据不同的用户故事场景（前台，API），改写 TQA 模板，增加 LLM 反馈的内容。\n\n首先，这个思考题我就没太搞懂，我是这么理解的：改写TQA模板，使 LLM 返回 API 文档。\n（不知道这样理解对嘛？）\n\n那么，对于这个思考题，我的想法是，修改Prompt的第一句和最后一句就可以了？\n\n比如，\n把“You are a business analyst who is familiar with specification by example. ” ，\n改成 “You are a software engineer expert who is familar with REST and other best practices in API design.”\n\n再把“Scenarios: List all possible scenarios with concrete example in Given&#47;When&#47;Then style”，\n改成“Final Answers: Output the API document using RAML format.”","like_count":0},{"had_liked":false,"id":389397,"user_name":"aoe","can_delete":false,"product_type":"c1","uid":1121758,"ip_address":"浙江","ucode":"1C6201EDB4E954","user_header":"https://static001.geekbang.org/account/avatar/00/11/1d/de/62bfa83f.jpg","comment_is_top":false,"comment_ctime":1712414988,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100755401,"comment_content":"TQA1 TQA2 包装成 bot 在 coze.com 上发布了「搜索路径 Bot Store -&gt; Learning -&gt; TQA」，效果没有直接使用 workflows 好「TQA2 的 bot 只有一轮就结束了， workflows 经过多轮才得出解决方案」\n\nTQA1 开始数据\ncontext\n作为学校的教职员工，我希望学生可以根据录取通知将学籍注册到教学计划上，从而我可以跟踪他们的获取学位的进度\n整个学籍管理系统是一个 Web 应用； 当教职员工发放录取通知时，会同步建立学生的账号；学生可以根据身份信息，查询自己的账号；在报道注册时，学生登录账号，按照录取通知书完成学年的注册；\n\nstory\n1. 我希望学生可以根据录取通知将学籍注册到教学计划上\n2. 作为学生，我希望登录之后接收到注册的通知，从而我可以不会错过学期注册的期限\n\nTQA2 拼接 history 数据\ncontext\n作为学校的教职员工，我希望学生可以根据录取通知将学籍注册到教学计划上，从而我可以跟踪他们的获取学位的进度\n整个学籍管理系统是一个 Web 应用； 当教职员工发放录取通知时，会同步建立学生的账号；学生可以根据身份信息，查询自己的账号；在报道注册时，学生登录账号，按照录取通知书完成学年的注册；\n\nstory\n1. 我希望学生可以根据录取通知将学籍注册到教学计划上\n2. 作为学生，我希望登录之后接收到注册的通知，从而我可以不会错过学期注册的期限\n\nhistory\n学生如何根据录取通知将学籍注册到教学计划上？登录教学系统后完成注册\n学生何时可以注册学籍？收到注册手机短信后\n学生如何登录账号来完成学年注册？使用手机号码登录注册\n学生如何查询自己的账号？使用手机号码查询或注册成功后分配到的学号\n学生注册学籍后，是否会收到通知？会收到手机短信通知\n学生如何知道学期注册的期限？30天内完成注册","like_count":0},{"had_liked":false,"id":389395,"user_name":"aoe","can_delete":false,"product_type":"c1","uid":1121758,"ip_address":"浙江","ucode":"1C6201EDB4E954","user_header":"https://static001.geekbang.org/account/avatar/00/11/1d/de/62bfa83f.jpg","comment_is_top":false,"comment_ctime":1712410939,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100755401,"comment_content":"coze 使用 2 个 workflows 半自动实现丐版 TQA\n\n1. TQA_1：根据 context、story 进行提问\n2. TQA_2：回答 TQA_1 的问题，并将回答手动录入 history，下一轮提问会知道上一轮的问题与答案\n3. 重复多次 TQA_2，直到得出解决方案\n\n测试数据\n\ncontext\n作为学校的教职员工，我希望学生可以根据录取通知将学籍注册到教学计划上，从而我可以跟踪他们的获取学位的进度\n整个学籍管理系统是一个 Web 应用； 当教职员工发放录取通知时，会同步建立学生的账号；学生可以根据身份信息，查询自己的账号；在报道注册时，学生登录账号，按照录取通知书完成学年的注册；\n\nstory\n1. 我希望学生可以根据录取通知将学籍注册到教学计划上\n2. 作为学生，我希望登录之后接收到注册的通知，从而我可以不会错过学期注册的期限\n\nTQA_2 中经过多轮循环得到了解决方案","like_count":0}]}