{"id":76307,"title":"11 | 数据科学家80%时间都花费在了这些清洗任务上？","content":"<p>我们在上一节中讲了数据采集，以及相关的工具使用，但做完数据采集就可以直接进行挖掘了吗？肯定不是的。</p><p>就拿做饭打个比方吧，对于很多人来说，热油下锅、掌勺翻炒一定是做饭中最过瘾的环节，但实际上炒菜这个过程只占做饭时间的20%，剩下80%的时间都是在做准备，比如买菜、择菜、洗菜等等。</p><p>在数据挖掘中，数据清洗就是这样的前期准备工作。对于数据科学家来说，我们会遇到各种各样的数据，在分析前，要投入大量的时间和精力把数据“<strong>整理裁剪</strong>”成自己想要或需要的样子。</p><p>为什么呢？因为我们采集到的数据往往有很多问题。</p><p>我们先看一个例子，假设老板给你以下的数据，让你做数据分析，你看到这个数据后有什么感觉呢？</p><p><img src=\"https://static001.geekbang.org/resource/image/5e/23/5e69b73b96c0d824240ac8035fe69723.png?wh=522*334\" alt=\"\"></p><p>你刚看到这些数据可能会比较懵，因为这些数据缺少标注。</p><p>我们在收集整理数据的时候，一定要对数据做标注，数据表头很重要。比如这份数据表，就缺少列名的标注，这样一来我们就不知道每列数据所代表的含义，无法从业务中理解这些数值的作用，以及这些数值是否正确。但在实际工作中，也可能像这个案例一样，数据是缺少标注的。</p><p>我简单解释下这些数据代表的含义。</p><p>这是一家服装店统计的会员数据。最上面的一行是列坐标，最左侧一列是行坐标。</p><p>列坐标中，第0列代表的是序号，第1列代表的会员的姓名，第2列代表年龄，第3列代表体重，第4~6列代表男性会员的三围尺寸，第7~9列代表女性会员的三围尺寸。</p><!-- [[[read_end]]] --><p>了解含义以后，我们再看下中间部分具体的数据，你可能会想，这些数据怎么这么“脏乱差”啊，有很多值是空的（NaN），还有空行的情况。</p><p>是的，这还仅仅是一家商店的部分会员数据，我们一眼看过去就能发现一些问题。日常工作中的数据业务会复杂很多，通常我们要统计更多的数据维度，比如100个指标，数据量通常都是超过TB、EB级别的，所以整个数据分析的处理难度是呈指数级增加的。这个时候，仅仅通过肉眼就很难找到问题所在了。</p><p>我举了这样一个简单的例子，带你理解在数据分析之前为什么要有数据清洗这个重要的准备工作。有经验的数据分析师都知道，<strong>好的数据分析师必定是一名数据清洗高手，要知道在整个数据分析过程中，不论是在时间还是功夫上，数据清洗大概都占到了80%</strong>。</p><h2>数据质量的准则</h2><p>在上面这个服装店会员数据的案例中，一看到这些数据，你肯定能发现几个问题。你是不是想知道，有没有一些准则来规范这些数据的质量呢？</p><p>准则肯定是有的。不过如果数据存在七八种甚至更多的问题，我们很难将这些规则都记住。有研究说一个人的短期记忆，最多可以记住7条内容或信息，超过7条就记不住了。而数据清洗要解决的问题，远不止7条，我们万一漏掉一项该怎么办呢？有没有一种方法，我们既可以很方便地记住，又能保证我们的数据得到很好的清洗，提升数据质量呢？</p><p>在这里，我将数据清洗规则总结为以下4个关键点，统一起来叫“<strong><span class=\"orange\">完全合一</span></strong>”，下面我来解释下。</p><ol>\n<li>\n<p><strong>完</strong>整性：单条数据是否存在空值，统计的字段是否完善。</p>\n</li>\n<li>\n<p><strong>全</strong>面性：观察某一列的全部数值，比如在Excel表中，我们选中一列，可以看到该列的平均值、最大值、最小值。我们可以通过常识来判断该列是否有问题，比如：数据定义、单位标识、数值本身。</p>\n</li>\n<li>\n<p><strong>合</strong>法性：数据的类型、内容、大小的合法性。比如数据中存在非ASCII字符，性别存在了未知，年龄超过了150岁等。</p>\n</li>\n<li>\n<p>唯<strong>一</strong>性：数据是否存在重复记录，因为数据通常来自不同渠道的汇总，重复的情况是常见的。行数据、列数据都需要是唯一的，比如一个人不能重复记录多次，且一个人的体重也不能在列指标中重复记录多次。</p>\n</li>\n</ol><p>在很多数据挖掘的教学中，数据准则通常会列出来7~8项，在这里我们归类成了“完全合一”4项准则，按照以上的原则，我们能解决数据清理中遇到的大部分问题，使得<strong>数据标准、干净、连续</strong>，为后续数据统计、数据挖掘做好准备。如果想要进一步优化数据质量，还需要在实际案例中灵活使用。</p><h2>清洗数据，一一击破</h2><p>了解了数据质量准则之后，我们针对上面服装店会员数据案例中的问题进行一一击破。</p><p>这里你就需要Python的Pandas工具了。这个工具我们之前介绍过。它是基于NumPy的工具，专门为解决数据分析任务而创建。Pandas 纳入了大量库，我们可以利用这些库高效地进行数据清理工作。</p><p>这里我补充说明一下，如果你对Python还不是很熟悉，但是很想从事数据挖掘、数据分析相关的工作，那么花一些时间和精力来学习一下Python是很有必要的。Python拥有丰富的库，堪称数据挖掘利器。当然了，数据清洗的工具也还有很多，这里我们只是以Pandas为例，帮你应用数据清洗准则，带你更加直观地了解数据清洗到底是怎么回事儿。</p><p>下面，我们就依照“完全合一”的准则，使用Pandas来进行清洗。</p><p><strong>1.  完整性</strong></p><p><strong>问题1：缺失值</strong></p><p>在数据中有些年龄、体重数值是缺失的，这往往是因为数据量较大，在过程中，有些数值没有采集到。通常我们可以采用以下三种方法：</p><ul>\n<li>\n<p>删除：删除数据缺失的记录；</p>\n</li>\n<li>\n<p>均值：使用当前列的均值；</p>\n</li>\n<li>\n<p>高频：使用当前列出现频率最高的数据。</p>\n</li>\n</ul><p>比如我们想对df[‘Age’]中缺失的数值用平均年龄进行填充，可以这样写：</p><pre><code>df['Age'].fillna(df['Age'].mean(), inplace=True)\n</code></pre><p>如果我们用最高频的数据进行填充，可以先通过value_counts获取Age字段最高频次age_maxf，然后再对Age字段中缺失的数据用age_maxf进行填充：</p><pre><code>age_maxf = train_features['Age'].value_counts().index[0]\ntrain_features['Age'].fillna(age_maxf, inplace=True)\n</code></pre><p><strong>问题2：空行</strong></p><p>我们发现数据中有一个空行，除了 index 之外，全部的值都是 NaN。Pandas 的 read_csv() 并没有可选参数来忽略空行，这样，我们就需要在数据被读入之后再使用 dropna() 进行处理，删除空行。</p><pre><code># 删除全空的行\ndf.dropna(how='all',inplace=True) \n</code></pre><p><strong>2.  全面性</strong></p><p><strong>问题：列数据的单位不统一</strong></p><p>观察weight列的数值，我们能发现weight 列的单位不统一。有的单位是千克（kgs），有的单位是磅（lbs）。</p><p>这里我使用千克作为统一的度量单位，将磅（lbs）转化为千克（kgs）：</p><pre><code># 获取 weight 数据列中单位为 lbs 的数据\nrows_with_lbs = df['weight'].str.contains('lbs').fillna(False)\nprint df[rows_with_lbs]\n# 将 lbs转换为 kgs, 2.2lbs=1kgs\nfor i,lbs_row in df[rows_with_lbs].iterrows():\n\t# 截取从头开始到倒数第三个字符之前，即去掉lbs。\n\tweight = int(float(lbs_row['weight'][:-3])/2.2)\n\tdf.at[i,'weight'] = '{}kgs'.format(weight) \n</code></pre><p><strong>3.  合理性</strong></p><p><strong>问题：非ASCII字符</strong></p><p>我们可以看到在数据集中 Firstname 和 Lastname 有一些非 ASCII 的字符。我们可以采用删除或者替换的方式来解决非ASCII问题，这里我们使用删除方法：</p><pre><code># 删除非 ASCII 字符\ndf['first_name'].replace({r'[^\\x00-\\x7F]+':''}, regex=True, inplace=True)\ndf['last_name'].replace({r'[^\\x00-\\x7F]+':''}, regex=True, inplace=True)\n</code></pre><p><strong>4.  唯一性</strong></p><p><strong>问题1：一列有多个参数</strong></p><p>在数据中不难发现，姓名列（Name）包含了两个参数 Firstname 和 Lastname。为了达到数据整洁目的，我们将 Name 列拆分成 Firstname 和 Lastname两个字段。我们使用Python的split方法，str.split(expand=True)，将列表拆成新的列，再将原来的 Name 列删除。</p><pre><code># 切分名字，删除源数据列\ndf[['first_name','last_name']] = df['name'].str.split(expand=True)\ndf.drop('name', axis=1, inplace=True)\n</code></pre><p><strong>问题2：重复数据</strong></p><p>我们校验一下数据中是否存在重复记录。如果存在重复记录，就使用 Pandas 提供的 drop_duplicates() 来删除重复数据。</p><pre><code># 删除重复数据行\ndf.drop_duplicates(['first_name','last_name'],inplace=True)\n</code></pre><p>这样，我们就将上面案例中的会员数据进行了清理，来看看清理之后的数据结果。怎么样？是不是又干净又标准？</p><p><img src=\"https://static001.geekbang.org/resource/image/71/fe/71001f8efb2692e77fa1285bcf7f91fe.png?wh=1441*398\" alt=\"\"></p><h2>养成数据审核的习惯</h2><p>现在，你是不是能感受到数据问题不是小事，上面这个简单的例子里都有6处错误。所以我们常说，现实世界的数据是“肮脏的”，需要清洗。</p><p>第三方的数据要清洗，自有产品的数据，也需要数据清洗。比如美团自身做数据挖掘的时候，也需要去除爬虫抓取，作弊数据等。可以说<strong>没有高质量的数据，就没有高质量的数据挖掘，而数据清洗是高质量数据的一道保障。</strong></p><p>当你从事这方面工作的时候，你会发现养成数据审核的习惯非常重要。而且越是优秀的数据挖掘人员，越会有“数据审核”的“职业病”。这就好比编辑非常在意文章中的错别字、语法一样。</p><p>数据的规范性，就像是你的作品一样，通过清洗之后，会变得非常干净、标准。当然了，这也是一门需要不断修炼的功夫。终有一天，你会进入这样一种境界：看一眼数据，差不多7秒钟的时间，就能知道这个数据是否存在问题。为了这一眼的功力，我们要做很多练习。</p><p>刚开始接触数据科学工作的时候，一定会觉得数据挖掘是件很酷、很有价值的事。确实如此，不过今天我还要告诉你，再酷炫的事也离不开基础性的工作，就像我们今天讲的数据清洗工作。对于这些基础性的工作，我们需要耐下性子，一个坑一个坑地去解决。</p><p>好了，最后我们来总结下今天的内容，你都收获了什么？</p><p><img src=\"https://static001.geekbang.org/resource/image/87/dd/87c0f81b493e99e715e9129cd3134bdd.jpg?wh=2249*1724\" alt=\"\"></p><p>学习完今天的内容后，给你留个小作业吧。下面是一个美食数据，如果你拿到下面的数据，按照我们今天讲的准则，你能找到几点问题？如果你来清洗这些数据，你打算怎样清洗呢？</p><p><img src=\"https://static001.geekbang.org/resource/image/34/fd/347fcfd86d83ff92923cbd01707a35fd.png?wh=523*355\" alt=\"\"></p><p>欢迎在留言区写下你的思考，如果你对今天“数据清洗”的内容还有疑问，也欢迎留言和我讨论。也欢迎点击“请朋友读”，把这篇文章分享给你的朋友或者同事。</p>","neighbors":{"left":{"article_title":"10丨Python爬虫：如何自动化下载王祖贤海报？","id":76001},"right":{"article_title":"12 | 数据集成：这些大号一共20亿粉丝？","id":76787}},"comments":[{"had_liked":false,"id":65444,"user_name":"third","can_delete":false,"product_type":"c1","uid":1025114,"ip_address":"","ucode":"9A37408A834F0B","user_header":"https://static001.geekbang.org/account/avatar/00/0f/a4/5a/e708e423.jpg","comment_is_top":false,"comment_ctime":1549361271,"is_pvip":false,"replies":[{"id":"64608","content":"感谢分享","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577622361,"ip_address":"","comment_id":65444,"utype":1}],"discussion_count":3,"race_medal":0,"score":"194822889591","product_id":100021701,"comment_content":"自己不知道有没有什么好的工具，所以就把图片上一个一个敲进去了。<br>数据.csv格式<br>链接：https:&#47;&#47;pan.baidu.com&#47;s&#47;1jNnUpntrlxFSubmna3HtXw <br>提取码：e9hc","like_count":45,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438453,"discussion_content":"感谢分享","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577622361,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1594560,"avatar":"https://static001.geekbang.org/account/avatar/00/18/54/c0/94dd77d2.jpg","nickname":"霍跑跑","note":"","ucode":"EF7454E2A0E031","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":2022,"discussion_content":"多谢先行者","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1563182048,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1028558,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b1/ce/3d7f253c.jpg","nickname":"Oreo0206:)","note":"","ucode":"2EA4965506E23C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":269928,"discussion_content":"感谢分享，但分享文件已经不存在了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589964593,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":58524,"user_name":"wonderland","can_delete":false,"product_type":"c1","uid":1362584,"ip_address":"","ucode":"ACA8577C9EDE88","user_header":"https://static001.geekbang.org/account/avatar/00/14/ca/98/a75e400b.jpg","comment_is_top":false,"comment_ctime":1547102914,"is_pvip":false,"replies":[{"id":"64790","content":"Good Job","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577625591,"ip_address":"","comment_id":58524,"utype":1}],"discussion_count":5,"race_medal":0,"score":"190525663938","product_id":100021701,"comment_content":"一、首先按照所讲的数据质量准则，数据存在的问题有：<br>1.&quot;完整性&quot;问题：数据有缺失，在ounces列的第三行存在缺失值<br>处理办法：可以用该列的平均值来填充此缺失值<br>2.“全面性”问题：food列的值大小写不统一<br>处理办法：统一改为小写<br>3.“合理性”问题：某一行的ounces值出现负值<br>处理办法：将该条数据记录删除<br>4.“唯一性”问题：food列大小写统一后会出现同名现象，<br>处理办法：需要将food列和animal列值均相同的数据记录进行合并到同一天记录中国","like_count":44,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":436107,"discussion_content":"Good Job","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577625591,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1402511,"avatar":"https://static001.geekbang.org/account/avatar/00/15/66/8f/02be926d.jpg","nickname":"在路上","note":"","ucode":"6E31908EFE1107","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":537103,"discussion_content":"总结的很棒!","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1638957084,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2546519,"avatar":"https://static001.geekbang.org/account/avatar/00/26/db/57/67084c71.jpg","nickname":"简单","note":"","ucode":"640B84253343AB","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":368974,"discussion_content":"同一天记录中国？什么鬼？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618892860,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2443427,"avatar":"https://static001.geekbang.org/account/avatar/00/25/48/a3/2df11999.jpg","nickname":"Boom clap!!!","note":"","ucode":"E9AF8ECB963239","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":366143,"discussion_content":"俩条数据怎么合并呢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617969746,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1040331,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/df/cb/81317179.jpg","nickname":"汪玉斌","note":"","ucode":"698975CA69D1E6","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":212277,"discussion_content":"总结的很棒!","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1584953632,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":85129,"user_name":"滢","can_delete":false,"product_type":"c1","uid":1221511,"ip_address":"","ucode":"971A6F20AF3F9A","user_header":"https://static001.geekbang.org/account/avatar/00/12/a3/87/c415e370.jpg","comment_is_top":false,"comment_ctime":1554986281,"is_pvip":false,"replies":[{"id":"64268","content":"滢同学很好的分享！","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577615723,"ip_address":"","comment_id":85129,"utype":1}],"discussion_count":6,"race_medal":0,"score":"151878841641","product_id":100021701,"comment_content":"原始数据链接：https:&#47;&#47;github.com&#47;onlyAngelia&#47;Read-Mark&#47;blob&#47;master&#47;数据分析&#47;geekTime&#47;data&#47;accountMessage.xlsx    （课程中讲解原始数据-点击view Raw即可下载）<br>课后练习原始数据: https:&#47;&#47;github.com&#47;onlyAngelia&#47;Read-Mark&#47;blob&#47;master&#47;数据分析&#47;geekTime&#47;data&#47;foodInformation.xlsx （点击View Raw下载）","like_count":35,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":446567,"discussion_content":"滢同学很好的分享！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577615723,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1995338,"avatar":"https://static001.geekbang.org/account/avatar/00/1e/72/4a/e916629c.jpg","nickname":"Ceci","note":"","ucode":"11F89A3FFA1232","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":264223,"discussion_content":"点击view Raw  总是无法访问此网站  为什么啊？","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1589295042,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1221511,"avatar":"https://static001.geekbang.org/account/avatar/00/12/a3/87/c415e370.jpg","nickname":"滢","note":"","ucode":"971A6F20AF3F9A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1995338,"avatar":"https://static001.geekbang.org/account/avatar/00/1e/72/4a/e916629c.jpg","nickname":"Ceci","note":"","ucode":"11F89A3FFA1232","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":284304,"discussion_content":"😂😂😂 在网页里点击view raw 不是直接弹下载嘛","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1592492746,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":264223,"ip_address":""},"score":284304,"extra":""}]},{"author":{"id":1903481,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/0b/79/4202ffc6.jpg","nickname":"🌕","note":"","ucode":"85899FCC7FB482","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":216627,"discussion_content":"谢谢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1585471118,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1019533,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/8e/8d/abb7bfe3.jpg","nickname":"Ed_Lee™","note":"","ucode":"06189702C9DE00","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":40262,"discussion_content":"感谢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1572142710,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1018526,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/8a/9e/94bdcdc5.jpg","nickname":"Noah","note":"","ucode":"A13DBCE8BA74CC","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":24640,"discussion_content":"非常感谢！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570205577,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":68589,"user_name":"晨星","can_delete":false,"product_type":"c1","uid":1361640,"ip_address":"","ucode":"435FEBF630BAB8","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eonMJazpAb9sj7ialYVsumyv9wC1F8RTHpmBPMgj7yNDmof7cpuONtultJc8NRlLyQ34uHjmxByfPg/132","comment_is_top":false,"comment_ctime":1550550890,"is_pvip":false,"replies":[{"id":"64532","content":"Good Job","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577621343,"ip_address":"","comment_id":68589,"utype":1}],"discussion_count":2,"race_medal":0,"score":"104629765994","product_id":100021701,"comment_content":"import pandas as pd<br>&quot;&quot;&quot;利用Pandas清洗美食数据&quot;&quot;&quot;<br><br># 读取csv文件<br>df = pd.read_csv(&quot;c.csv&quot;)<br><br>df[&#39;food&#39;] = df[&#39;food&#39;].str.lower()  # 统一为小写字母<br>df.dropna(inplace=True)  # 删除数据缺失的记录<br>df[&#39;ounces&#39;] = df[&#39;ounces&#39;].apply(lambda a: abs(a))  # 负值不合法，取绝对值<br><br># 查找food重复的记录，分组求其平均值<br>d_rows = df[df[&#39;food&#39;].duplicated(keep=False)]<br>g_items = d_rows.groupby(&#39;food&#39;).mean()<br>g_items[&#39;food&#39;] = g_items.index<br>print(g_items)<br><br># 遍历将重复food的平均值赋值给df<br>for i, row in g_items.iterrows():<br>    df.loc[df.food == row.food, &#39;ounces&#39;] = row.ounces<br>df.drop_duplicates(inplace=True)  # 删除重复记录<br><br>df.index = range(len(df))  # 重设索引值<br>print(df)","like_count":24,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":439740,"discussion_content":"Good Job","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577621343,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1187061,"avatar":"https://static001.geekbang.org/account/avatar/00/12/1c/f5/fd386689.jpg","nickname":"Venom","note":"","ucode":"2055AC6F322781","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":69199,"discussion_content":"厉害厉害","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1575270227,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":57473,"user_name":"Hot   Heat","can_delete":false,"product_type":"c1","uid":1235964,"ip_address":"","ucode":"EF8E2ADEB29BEA","user_header":"https://static001.geekbang.org/account/avatar/00/12/db/fc/8ddeaccb.jpg","comment_is_top":false,"comment_ctime":1546819915,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"87446165835","product_id":100021701,"comment_content":"可以给个样例数据的链接吗？自己动手操作一下","like_count":20},{"had_liked":false,"id":57686,"user_name":"aof","can_delete":false,"product_type":"c1","uid":1062864,"ip_address":"","ucode":"5815D63C4926BC","user_header":"https://static001.geekbang.org/account/avatar/00/10/37/d0/26975fba.jpg","comment_is_top":false,"comment_ctime":1546868657,"is_pvip":false,"replies":[{"id":"20936","content":"对的 一定要自己模拟操作下","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1547000948,"ip_address":"","comment_id":57686,"utype":1}],"discussion_count":1,"race_medal":0,"score":"70266345393","product_id":100021701,"comment_content":"这些东西，大家都一定要上手去实现一遍。最简单的就是，搞一个文本，把这些数据放进去，用Python读这个文本，转成dataframe，把老师讲的那些清洗相关的API都一个一个试一下，才会有体会，光看一遍真的没啥用的！<br>现在只是很少的几十条数据，等你真正去搞那些上亿的数据的时候，就知道核对数据是个多么复杂的事情了……","like_count":16,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435699,"discussion_content":"对的 一定要自己模拟操作下","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1547000948,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":64299,"user_name":"爱做梦的咸鱼","can_delete":false,"product_type":"c1","uid":1051256,"ip_address":"","ucode":"9D9642CF0752BB","user_header":"","comment_is_top":false,"comment_ctime":1548738106,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"48793378362","product_id":100021701,"comment_content":"建议老师涉及到数据集练习的可以把数据放在github上，方便我们做同步练习。","like_count":12},{"had_liked":false,"id":57568,"user_name":"auroroa","can_delete":false,"product_type":"c1","uid":1057164,"ip_address":"","ucode":"0FF44C9A40E8CD","user_header":"https://static001.geekbang.org/account/avatar/00/10/21/8c/f7a24bc5.jpg","comment_is_top":false,"comment_ctime":1546839199,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"48791479455","product_id":100021701,"comment_content":"最大的问题是不是没把数据的来源和目的描述清楚？😄","like_count":11},{"had_liked":false,"id":85004,"user_name":"滢","can_delete":false,"product_type":"c1","uid":1221511,"ip_address":"","ucode":"971A6F20AF3F9A","user_header":"https://static001.geekbang.org/account/avatar/00/12/a3/87/c415e370.jpg","comment_is_top":false,"comment_ctime":1554954750,"is_pvip":false,"replies":[{"id":"64273","content":"不错的分享","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577615835,"ip_address":"","comment_id":85004,"utype":1}],"discussion_count":2,"race_medal":0,"score":"35914693118","product_id":100021701,"comment_content":"觉得完全合一原则挺好，不过有些操作顺序是不是得更改一下，比如数值补全要在删除全空行之后，否则在补全的时候全空行也会补全。接下来总结在清洗过程中的问题：（1） 不知道Python2 执行情况如何，在用Python3进行数据清理的时候，对于女性三围数据补全的时候因为列中有空字符的存在，会提示‘must str not int’,需要自己过滤含有数值的有效数据进行mean()计算。  (2)生成的新列一般会自动补到后面，但first_name,last_name需要在第一列和第二列，所以要进行列移动或列交换。(3)在删除数据之后默认加载的索引会出现问题，需要自己更新索引","like_count":8,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":446527,"discussion_content":"不错的分享","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577615835,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1939199,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJ2I86HeBpalc1SlDpicfCxeHic4nAOa9anTmfKOWqjuto1Yib9sxW1zuIpc1pVtJQsiazpMxvnKQ2stg/132","nickname":"田杭","note":"","ucode":"B35F0FD63CFF78","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":285637,"discussion_content":"想请问一下，第（1）点应该怎么过滤含有数值的有效数据？还有第（3）点怎么更新索引？是需要自己手动写序号吗？求指点，多谢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1592900833,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":58069,"user_name":"nrvna","can_delete":false,"product_type":"c1","uid":1352764,"ip_address":"","ucode":"05830A97EF354D","user_header":"https://static001.geekbang.org/account/avatar/00/14/a4/3c/6d0a0cc8.jpg","comment_is_top":false,"comment_ctime":1546991448,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"35906729816","product_id":100021701,"comment_content":"jupyter notebook，python3<br><br>import pandas as pd<br>df = pd.read_csv(&quot;D:&#47;&#47;Data_for_sci&#47;food.csv&quot;)<br>df.index<br><br>df<br><br># Data cleaning for lowercase<br>df[&#39;food&#39;] = df[&#39;food&#39;].str.lower()<br>df<br><br># Delet NaN<br>df = df.dropna() <br>df.index = range(len(df)) # reset index<br>df<br><br># Get bacon&#39;s mean value and delet second one <br>df.loc[0,&#39;ounces&#39;] = df[df[&#39;food&#39;].isin([&#39;bacon&#39;])].mean()[&#39;ounces&#39;]<br>df.drop(df.index[4],inplace=True)<br>df.index = range(len(df)) # reset index<br>df<br><br>#Get pastrami&#39;s mean value and delet second one <br>df.loc[2,&#39;ounces&#39;] = df[df[&#39;food&#39;].isin([&#39;pastrami&#39;])].mean()[&#39;ounces&#39;]<br>df.drop(df.index[4],inplace=True)<br>df.index = range(len(df)) # reset index<br>df<br><br><br><br><br>","like_count":8},{"had_liked":false,"id":57551,"user_name":"桃园悠然在","can_delete":false,"product_type":"c1","uid":1017637,"ip_address":"","ucode":"704460D9CAD1CB","user_header":"https://static001.geekbang.org/account/avatar/00/0f/87/25/898dea4e.jpg","comment_is_top":false,"comment_ctime":1546831734,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"31611602806","product_id":100021701,"comment_content":"我的理解，不能对food列简单去重吧，而是规范ounces列数据后汇总或者保持原样，这可能使厨房食材消耗记录。数据清洗还是要结合完全合一+业务含义。","like_count":7},{"had_liked":false,"id":62095,"user_name":"小熊猫","can_delete":false,"product_type":"c1","uid":1257442,"ip_address":"","ucode":"7549BA17FFBAD4","user_header":"https://static001.geekbang.org/account/avatar/00/13/2f/e2/3640e491.jpg","comment_is_top":false,"comment_ctime":1547907912,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"27317711688","product_id":100021701,"comment_content":"将磅（lbs）转化为千克（kgs）：<br>感觉这个地方写复杂了，直接用正则表达式替换就行了<br>df[&#39;Weight&#39;].replace(&#39;lbs$&#39;, &#39;kgs&#39;, regex=True, inplace=True)","like_count":6,"discussions":[{"author":{"id":2058384,"avatar":"https://static001.geekbang.org/account/avatar/00/1f/68/90/ca86abe3.jpg","nickname":"CHEN","note":"","ucode":"5B9BA6F6C83F58","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":292715,"discussion_content":"你没进行单位换算吧？","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1595315990,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":57899,"user_name":"上官","can_delete":false,"product_type":"c1","uid":1353145,"ip_address":"","ucode":"037968A8E0C566","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJAeZ2VCia2y3bW9N7EMfgBqX8WClXUydwaXDPcK7Bm3XaMnMKx7q5ffA0UuTeJmEusxtQAibf8djCA/132","comment_is_top":false,"comment_ctime":1546937210,"is_pvip":false,"replies":[{"id":"20922","content":"截取从头开始到倒数第三个字符之前，即去掉lbs。","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1546999598,"ip_address":"","comment_id":57899,"utype":1}],"discussion_count":1,"race_medal":0,"score":"27316740986","product_id":100021701,"comment_content":"weight = int(float((lbs_row[&#39;weight&#39;][:-3])&#47;2.2)<br>老师好，这行代码中[：-3]的作用是什么啊？<br><br><br>","like_count":6,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435817,"discussion_content":"截取从头开始到倒数第三个字符之前，即去掉lbs。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1546999598,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":59084,"user_name":"周飞","can_delete":false,"product_type":"c1","uid":1073374,"ip_address":"","ucode":"F85FA236EB0C0D","user_header":"https://static001.geekbang.org/account/avatar/00/10/60/de/5c67895a.jpg","comment_is_top":false,"comment_ctime":1547297535,"is_pvip":false,"replies":[{"id":"64770","content":"Good Job","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577625297,"ip_address":"","comment_id":59084,"utype":1}],"discussion_count":1,"race_medal":0,"score":"23022134015","product_id":100021701,"comment_content":"完整性：ounces 列数据中存在NAN<br>全面性：food列数据中存在大小写不一致问题<br>合法性：ounces列数据存在负值<br>唯一性：food列数据存在重复<br># -*- coding: utf-8 -*<br>import pandas as pd<br>import numpy as np<br>from pandas import Series, DataFrame<br>df = pd.read_csv(&#39;.&#47;fooddata.csv&#39;)<br># 把ounces 列中的NaN替换为平均值<br>df[&#39;ounces&#39;].fillna(df[&#39;ounces&#39;].mean(), inplace=True)<br># 把food列中的大写字母全部转换为小写<br>df[&#39;food&#39;] = df[&#39;food&#39;].str.lower()<br># 把ounces 列中的负数转化为正数<br>df[&#39;ounces&#39;]= df[&#39;ounces&#39;].apply(lambda x: abs(x))<br>#删除food列中的重复值<br>df.drop_duplicates(&#39;food&#39;,inplace=True)<br>print (df)<br>","like_count":6,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":436295,"discussion_content":"Good Job","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577625297,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":66693,"user_name":"王彬成","can_delete":false,"product_type":"c1","uid":1015045,"ip_address":"","ucode":"386803B8FC2DD5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg","comment_is_top":false,"comment_ctime":1549981870,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"14434883758","product_id":100021701,"comment_content":"以下为对文中的案例进行编码操作，有三个问题请教<br>1、重量【‘weight’】一列的数据，如何利用平均值进行填充，因为该列是字符类型，无法求平均。目前采用高频数据填充<br>2、Pink Panther用户的三围数据如何填充？，我想利用对应性别的平均值填充<br>3、案例中，后6列不显示‘NaN’，是因为填充列‘空格’吗？<br>_____________________<br>import pandas as pd<br>## 导入数据<br>df=pd.read_csv(&#39;第11节数据.csv&#39;)<br>## 重命名列名columns<br>df.rename(columns={&#39;0&#39;:&#39;Number&#39;,&#39;1&#39;:&#39;Name&#39;,&#39;2&#39;:&#39;Age&#39;,&#39;3&#39;:&#39;Weight&#39;,&#39;4&#39;:&#39;m0006&#39;,&#39;5&#39;:&#39;m0612&#39;,&#39;6&#39;:&#39;m1218&#39;<br>                  ,&#39;7&#39;:&#39;f0006&#39;,&#39;8&#39;:&#39;f0612&#39;,&#39;9&#39;:&#39;f1218&#39;},inplace=True)<br><br>#2.全面性<br>#列数据统一单位<br># 获取weight 数据列中单位为lbs的数据<br>rows_with_lbs=df[&#39;Weight&#39;].str.contains(&#39;lbs&#39;).fillna(False)<br>print(df[rows_with_lbs])<br># 将lbs转换为kgs，2.2lbs=1kgs<br>for i,lbs_row in df[rows_with_lbs].iterrows():<br>    # 截取从头开始到倒数第三个字符之前，即去掉lbs<br>    weight=int(float(lbs_row[&#39;Weight&#39;][:-3])&#47;2.2)<br>    df.at[i,&#39;Weight&#39;]=&#39;{}kgs&#39;.format(weight)<br><br>#1.完整性<br># 删除全空的行<br>df.dropna(how=&#39;all&#39;,inplace=True)<br><br>##缺失值补充方式一<br>## df[‘Age’] 中缺失的数值用平均年龄进行填充<br>#df[&#39;Age&#39;].fillna(df[&#39;Age&#39;].mean(),inplace=True)<br><br>## 缺失值补充方式二<br>## 使用Age一列高频数据进行填充<br>age_maxf=df[&#39;Age&#39;].value_counts().index[0]<br>df[&#39;Age&#39;].fillna(age_maxf,inplace=True)<br><br>## 使用Weight一列高频数据进行填充<br>weight_maxf=df[&#39;Weight&#39;].value_counts().index[0]<br>df[&#39;Weight&#39;].fillna(weight_maxf,inplace=True)<br><br>#4.唯一性<br>#Name拆分为firstname和lastname<br>#切分名字，删除源数据列<br>df[[&#39;first_name&#39;,&#39;last_name&#39;]]=df[&#39;Name&#39;].str.split(expand=True)<br>df.drop(&#39;Name&#39;,axis=1,inplace=True)<br><br># 移动first_name和last_name这俩列<br>first_name=df.pop(&#39;first_name&#39;)<br>df.insert(1,&#39;first_name&#39;,first_name)<br>last_name=df.pop(&#39;last_name&#39;)<br>df.insert(2,&#39;last_name&#39;,last_name)<br><br>#删除重复数据行<br>df.drop_duplicates([&#39;first_name&#39;,&#39;last_name&#39;],inplace=True)<br><br>#3.合理性<br># 删除非ASCII字符<br>df[&#39;first_name&#39;].replace({r&#39;[^\\x00-\\x7F]+&#39;:&#39;&#39;},regex=True,inplace=True)<br>df[&#39;last_name&#39;].replace({r&#39;[^\\x00-\\x7F]+&#39;:&#39;&#39;},regex=True,inplace=True)<br><br>df<br>","like_count":3},{"had_liked":false,"id":58797,"user_name":"北方","can_delete":false,"product_type":"c1","uid":1114754,"ip_address":"","ucode":"D04589B652AC29","user_header":"https://static001.geekbang.org/account/avatar/00/11/02/82/abed70a0.jpg","comment_is_top":false,"comment_ctime":1547195220,"is_pvip":false,"replies":[{"id":"64777","content":"Good Job","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577625415,"ip_address":"","comment_id":58797,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14432097108","product_id":100021701,"comment_content":"#!&#47;usr&#47;bin&#47;env python<br># -*- coding:utf8 -*-<br># __author__ = &#39;北方姆Q&#39;<br># __datetime__ = 2019&#47;1&#47;11 15:53<br><br><br>import pandas as pd<br><br># 导入<br>df = pd.read_csv(&quot;.&#47;s11.csv&quot;)<br># 去除完全的空行<br>df.dropna(how=&#39;all&#39;, inplace=True)<br># 食物名切分并去掉原本列<br>df[[&quot;first_name&quot;, &quot;last_name&quot;]] = df[&quot;food&quot;].str.split(expand=True)<br>df.drop(&quot;food&quot;, axis=1, inplace=True)<br># 名称首字母大写<br>df[&quot;first_name&quot;] = df[&quot;first_name&quot;].str.capitalize()<br>df[&quot;last_name&quot;] = df[&quot;last_name&quot;].str.capitalize()<br># 以食物名为标准去重<br>df.drop_duplicates([&quot;first_name&quot;, &quot;last_name&quot;], inplace=True)<br><br>print(df)","like_count":3,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":436212,"discussion_content":"Good Job","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577625415,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":149128,"user_name":"qinggeouye","can_delete":false,"product_type":"c1","uid":1251536,"ip_address":"","ucode":"5B53EEDD7BEC9C","user_header":"https://static001.geekbang.org/account/avatar/00/13/18/d0/49b06424.jpg","comment_is_top":false,"comment_ctime":1573155240,"is_pvip":false,"replies":[{"id":"59815","content":"不错 把代码放到GitHub上是很好的方式","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1574756605,"ip_address":"","comment_id":149128,"utype":1}],"discussion_count":2,"race_medal":0,"score":"10163089832","product_id":100021701,"comment_content":"https:&#47;&#47;github.com&#47;qinggeouye&#47;GeekTime&#47;blob&#47;master&#47;DataAnalysis&#47;11_data_clean.py<br><br>import pandas as pd<br><br># 读取数据<br>data_init = pd.read_csv(&quot;.&#47;11_clothingStoreMembers.csv&quot;)<br><br># 清洗数据<br><br># 删除 &#39;\\t&#39; 列, 读取 csv 文件多了一列<br>data_init.drop(columns=&#39;\\t&#39;, inplace=True)<br># 重命名列名<br>data_init.rename(<br>    columns={&quot;0&quot;: &quot;SEQ&quot;, &quot;1&quot;: &quot;NAME&quot;, &quot;2&quot;: &quot;AGE&quot;, &quot;3&quot;: &quot;WEIGHT&quot;, &quot;4&quot;: &quot;BUST_M&quot;, &quot;5&quot;: &quot;WAIST_M&quot;, &quot;6&quot;: &quot;HIP_M&quot;,<br>             &quot;7&quot;: &quot;BUST_F&quot;, &quot;8&quot;: &quot;WAIST_F&quot;, &quot;9&quot;: &quot;HIP_F&quot;}, inplace=True)<br>print(data_init)<br><br># 1、完整性<br># 删除空行<br>data_init.dropna(how=&#39;all&#39;, inplace=True)<br><br># 4、唯一性<br># 一列多个参数切分<br>data_init[[&quot;FIRST_NAME&quot;, &quot;LAST_NAME&quot;]] = data_init[&quot;NAME&quot;].str.split(expand=True)<br>data_init.drop(&quot;NAME&quot;, axis=1, inplace=True)<br># 删除重复数据<br>data_init.drop_duplicates([&quot;FIRST_NAME&quot;, &quot;LAST_NAME&quot;], inplace=True)<br><br># 2、全面性<br># 列数据单位统一, 体重 WEIGHT 单位统一（lbs 英镑， kg 千克）<br>rows_with_lbs = data_init[&quot;WEIGHT&quot;].str.contains(&quot;lbs&quot;).fillna(False)<br>print(rows_with_lbs)<br># lbs 转为 kg<br>for i, lbs_row in data_init[rows_with_lbs].iterrows():<br>    weight = int(float(lbs_row[&quot;WEIGHT&quot;][:-3]) &#47; 2.2)<br>    data_init.at[i, &quot;WEIGHT&quot;] = &quot;{}kgs&quot;.format(weight)<br>print(data_init)<br><br># 3、合理性<br># 非 ASCII 字符转换，这里删除处理<br>data_init[&quot;FIRST_NAME&quot;].replace({r&#39;[^\\x00-\\x7F]+&#39;: &#39;&#39;}, regex=True, inplace=True)<br>data_init[&quot;LAST_NAME&quot;].replace({r&#39;[^\\x00-\\x7F]+&#39;: &#39;&#39;}, regex=True, inplace=True)<br><br># 1、完整性<br># 补充缺失值-均值补充<br>data_init[&quot;AGE&quot;].fillna(data_init[&quot;AGE&quot;].mean(), inplace=True)<br># 体重先去掉 kgs 的单位符号<br>data_init[&quot;WEIGHT&quot;].replace(&#39;kgs$&#39;, &#39;&#39;, regex=True, inplace=True)  # 不带单位符号 kgs<br>data_init[&quot;WEIGHT&quot;] = data_init[&quot;WEIGHT&quot;].astype(&#39;float&#39;)<br>data_init[&quot;WEIGHT&quot;].fillna(data_init[&quot;WEIGHT&quot;].mean(), inplace=True)<br><br>data_init.replace(&#39;-&#39;, 0, regex=True, inplace=True)  # 读取的 csv 数据多了&#39;-&#39;<br>data_init[&quot;WAIST_F&quot;] = data_init[&quot;WAIST_F&quot;].astype(&#39;float&#39;)<br>data_init[&quot;WAIST_F&quot;].fillna(data_init[&quot;WAIST_F&quot;].mean(), inplace=True)<br><br># 用最高频的数据填充<br>age_max_freq = data_init[&quot;AGE&quot;].value_counts().index[0]<br>print(age_max_freq)<br>data_init[&quot;AGE&quot;].fillna(age_max_freq, inplace=True)<br>print(data_init)","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":473745,"discussion_content":"不错 把代码放到GitHub上是很好的方式","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1574756605,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1320751,"avatar":"https://static001.geekbang.org/account/avatar/00/14/27/2f/48607919.jpg","nickname":"$KIiiijiii","note":"","ucode":"0F2F14A8956E9F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":414244,"discussion_content":"发现序号8的空行无法删除，因为他不是全空","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1636700697,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":91282,"user_name":"姜泮昌","can_delete":false,"product_type":"c1","uid":1107213,"ip_address":"","ucode":"89B63270BAE099","user_header":"https://static001.geekbang.org/account/avatar/00/10/e5/0d/b4258141.jpg","comment_is_top":false,"comment_ctime":1556963886,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10146898478","product_id":100021701,"comment_content":"在唯一性的最后一步，去重后还有重复数据啊，Huey McDuck有两条相同数据，这个有问题呢","like_count":2},{"had_liked":false,"id":61571,"user_name":"lingmacker","can_delete":false,"product_type":"c1","uid":1353113,"ip_address":"","ucode":"2B61674AD47F34","user_header":"https://static001.geekbang.org/account/avatar/00/14/a5/99/db2f6325.jpg","comment_is_top":false,"comment_ctime":1547724781,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"10137659373","product_id":100021701,"comment_content":"import pandas as pd<br><br><br>def wash_data():<br>    data = pd.read_excel(&quot;.&#47;data&#47;data.xlsx&quot;)<br>    data[&quot;food&quot;] = data[&quot;food&quot;].str.capitalize()  # 首字母大写<br>    data.fillna(0, inplace=True)<br>    data.drop_duplicates(&quot;food&quot;, inplace=True)  # 删除重复行<br>    <br>    data.to_excel(&quot;.&#47;data&#47;re_data.xlsx&quot;)<br><br><br>if __name__ == &#39;__main__&#39;:<br>    wash_data()<br><br><br>是不是清洗得太简单了。。。","like_count":2,"discussions":[{"author":{"id":1560486,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLs1FRrgeeEYvfZLvGqqgIS1bZamyMvUFsIr0qG4vV3nLDnUc7VGlNq2Rm3AHN7MHFDm8s88fvpcA/132","nickname":"Geek_ab1278","note":"","ucode":"BEFF06D7759A89","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":1052,"discussion_content":"需要针对food和animal 都重复的来删除","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562297162,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":61489,"user_name":"Chino","can_delete":false,"product_type":"c1","uid":1347181,"ip_address":"","ucode":"0240D89E5F74B4","user_header":"https://static001.geekbang.org/account/avatar/00/14/8e/6d/c68e07ef.jpg","comment_is_top":false,"comment_ctime":1547707617,"is_pvip":false,"replies":[{"id":"64708","content":"Good Job!","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577624548,"ip_address":"","comment_id":61489,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10137642209","product_id":100021701,"comment_content":"有一个问题 就是代码最后那里to_excel 如果参数的路径是指定的那种 就会报错显示filenotfound 搜了很久都没找到是什么原因 求解<br>另外感觉这一讲有好多点都没讲深入呀 下面代码是对课程中的样例进行清洗 感觉只能做到几小点了. 特别是在填充nan值的时候 一开始想着遍历每一个nan值 然后再特判列的类型进行填充的. 但是发现三围那里有个大问题 按理说三围应该是int类型 但是因为有- 这个东西的存在 搞的三围是object类型 一开始赋值的时候报错提示需要str 后来想把列的类型转换成int也失败了 还有好多地方都卡着了...<br>import pandas as pd<br>import numpy as np<br>from pandas import Series, DataFrame<br><br>data = DataFrame(pd.read_excel(&#39;~&#47;Desktop&#47;data.xlsx&#39;))<br><br>print(data)<br><br># 更改列名<br>data.rename(columns={0:&#39;序号&#39;,1:&#39;姓名&#39;,2:&#39;年龄&#39;,3:&#39;体重&#39;,4:&#39;男三围1&#39;,5:&#39;男三围2&#39;,6:&#39;男三围3&#39;,7:&#39;女三围1&#39;,8:&#39;女三围2&#39;,9:&#39;女三围3&#39;},inplace = True)<br><br># 去掉重复行<br>data = data.drop_duplicates()<br><br># 1.完整性<br># 填充缺失值<br>col = data.columns.values.tolist()<br>row = data._stat_axis.values.tolist()<br><br># 先把姓名的数据类型改成字符串<br>data[&#39;姓名&#39;] = data[&#39;姓名&#39;].astype(&#39;str&#39;) <br><br># 1.1 先清除空行<br>data.dropna(how = &#39;all&#39;, inplace = True)<br><br># 1.2 填充缺失值<br>age_maxf = data[&#39;年龄&#39;].value_counts().index[0]<br><br># 以年龄频率最大值来填充<br>data[&#39;年龄&#39;].fillna(age_maxf, inplace=True)<br><br># 2.全面性<br># 把体重单位为lbs的转化为kgs 2.2lbs = 1kgs<br># 把所有体重单位为lbs的记录存放在一起 (如果体重是nan则不要)<br>rows_with_lbs = data[&#39;体重&#39;].str.contains(&#39;lbs&#39;).fillna(False)<br><br>for i,lbs_row in data[rows_with_lbs].iterrows():<br>    weight = int(float(lbs_row[&#39;体重&#39;][:-3]) &#47; 2.2)<br>    # 第一个参数是y坐标(竖) 第二个参数是x坐标(横) <br>    data.at[i,&#39;体重&#39;] = &#39;{}kgs&#39;.format(weight)<br><br>print(data)<br><br># 把清洗后的数据输出<br>data.to_excel(&#39;CleanData.xlsx&#39;)<br># 会报错<br># data.to_excel(&#39;~&#47;Desktop&#47;CleanData.xlsx&#39;)","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":436887,"discussion_content":"Good Job!","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577624548,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":57649,"user_name":"奋斗","can_delete":false,"product_type":"c1","uid":1068400,"ip_address":"","ucode":"3A90F4F7EE329E","user_header":"https://static001.geekbang.org/account/avatar/00/10/4d/70/b4517c57.jpg","comment_is_top":false,"comment_ctime":1546859809,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10136794401","product_id":100021701,"comment_content":"老师你好！我是爬虫新手，在为机器翻译提供语料，爬取完数据很头疼，文本数据里有很多问题，老师针对文本类的数据怎么处理好那，pandas适用吗？谢谢了","like_count":2},{"had_liked":false,"id":57597,"user_name":"Tommy","can_delete":false,"product_type":"c1","uid":1354011,"ip_address":"","ucode":"98C30F99B5670D","user_header":"https://static001.geekbang.org/account/avatar/00/14/a9/1b/1f13e299.jpg","comment_is_top":false,"comment_ctime":1546845077,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10136779669","product_id":100021701,"comment_content":"脚本看不全啊","like_count":2},{"had_liked":false,"id":313904,"user_name":"picoasis","can_delete":false,"product_type":"c1","uid":1217329,"ip_address":"","ucode":"D5113416FF2B14","user_header":"https://static001.geekbang.org/account/avatar/00/12/93/31/abb7bfe3.jpg","comment_is_top":false,"comment_ctime":1632732817,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5927700113","product_id":100021701,"comment_content":"1. 完整性：对NaN数据进行处理，删除，或取均值，或最高频率值。<br>2. 全面性：food的名称不统一，容易引发歧义，是否代表不同的种类。确认是相同种类时，统一为首字母大写，或者统一小写。有其他含义的，改变名称为更加不易混淆的，或者增加其他数据列进行标识。<br>3. 合法性：没有特殊含义的情况下，ounces值不应为负值，可以考虑取绝对值，或作为无效数据删除此行。<br>4. 唯一性:一般地，将最左侧列作为索引，但此数据中最左侧列重复数据较多不合常规，因此不可直接去重，而是需要更多信息，来确认代表的业务含义。","like_count":1},{"had_liked":false,"id":70685,"user_name":"一语中的","can_delete":false,"product_type":"c1","uid":1320112,"ip_address":"","ucode":"E1A0EFCEAD83B4","user_header":"https://static001.geekbang.org/account/avatar/00/14/24/b0/a6e0b03a.jpg","comment_is_top":false,"comment_ctime":1551163790,"is_pvip":false,"replies":[{"id":"64502","content":"Good Job","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577620138,"ip_address":"","comment_id":70685,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5846131086","product_id":100021701,"comment_content":"#pd读取数据<br>df = pd.read_excel(&#39;testdata11.xlsx&#39;)<br>#1.完整性，ounces列NA值用平均值填充<br>df[&#39;ounces&#39;].fillna(df[&#39;ounces&#39;].mean(), inplace=True)<br>#2.全面性，统一food列大小写<br>df[&#39;food&#39;] = df[&#39;food&#39;].str.lower()<br>#3.合法性，ounces列负值取绝对值<br>df[&#39;ounces&#39;] = df[&#39;ounces&#39;].apply(lambda x: abs(x))<br>#4.唯一性.animal列有重复值<br>df.drop_duplicates(&#39;food&#39;, inplace=True)<br>#5.重新排序显示<br>df.reset_index(drop=True, inplace=True)<br>print(df)<br><br>","like_count":1,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":440771,"discussion_content":"Good Job","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577620138,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":70120,"user_name":"BGBiao","can_delete":false,"product_type":"c1","uid":1044353,"ip_address":"","ucode":"7DBB34AFC772CF","user_header":"https://static001.geekbang.org/account/avatar/00/0f/ef/81/74786f41.jpg","comment_is_top":false,"comment_ctime":1551000684,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5845967980","product_id":100021701,"comment_content":"## 首先样本数据集存在如下问题:<br>完整性: ounces列存在空值<br>全面性：<br>合理性: ounces列存在负值<br>唯一性: bacon美食存在多条记录，并且名称存在大小写，无法唯一区分一个食物信息<br>## 根据以上问题，可以做的数据清洗为：<br>1. 过滤异常数据行(删除ounces列为空和负值的行)<br>2.统一food字段命名使用小写<br>## 问题的本质: <br>其实个人认为问题的本质是数据思维和数据标准，如果单纯的给这样一份原始数据给数据分析人员，不提供上下文信息，那其实数据分析是很难做出效果的。比如按照我的清洗规则1清洗完成后数据如下:<br>           food  ounces  animal<br>0        bacon     4.0     pig<br>1  pulled pork     3.0     pig<br>2     Pastrami     6.0     cow<br>3  corned beef     7.5     cow<br>4        Bacon     8.0     pig<br>5    honey ham     5.0     pig<br>6     nova lox     6.0  salmon<br>虽然有bacon和Bacon可能是两种食物，但也很容易产生数据歧义，因为食物没有唯一标识。因此在有限的上下文环境中，数据分析可以做到如下数据集。<br>清洗过后的数据:<br>           food  ounces  animal      foodtag<br>0        Bacon     8.0     pig        bacon<br>1     Pastrami     6.0     cow     pastrami<br>2        bacon     4.0     pig        bacon<br>3  corned beef     7.5     cow  corned beef<br>4    honey ham     5.0     pig    honey ham<br>5     nova lox     6.0  salmon     nova lox<br>6  pulled pork     3.0     pig  pulled pork<br><br>## 相关codes(将以下代码直接黏贴，在python3环境中运行)<br>#!&#47;usr&#47;bin&#47;env python<br># env: python 3.X<br>import pandas as pd<br>import pandasql<br><br>data = {&#39;food&#39;:[&#39;bacon&#39;,&#39;pulled pork&#39;,&#39;bacon&#39;,&#39;Pastrami&#39;,&#39;corned beef&#39;,&#39;Bacon&#39;,&#39;pastrami&#39;,&#39;honey ham&#39;,&#39;nova lox&#39;],&#39;ounces&#39;:[4.0,3.0,None,6.0,7.5,8.0,-3.0,5.0,6.0],&#39;animal&#39;:[&#39;pig&#39;,&#39;pig&#39;,&#39;pig&#39;,&#39;cow&#39;,&#39;cow&#39;,&#39;pig&#39;,&#39;cow&#39;,&#39;pig&#39;,&#39;salmon&#39;]}<br><br>foods = pd.DataFrame(data)<br><br>print(&quot;原始数据集:\\n %s&quot; % foods)<br><br># 注意:因为上面的data是我自己构造的，数据类型是已知的，通常在处理数据前，应当先查看下数据结构，转换成统一数据类型<br>print(&quot;检查数据集每列的数据类型:\\n %s &quot; % foods.dtypes)<br><br># 删除空行<br>foods.dropna(axis=0,how=&#39;any&#39;,inplace=True)<br><br># 使用sql方式直接过滤异常数据<br><br>filterFoods = lambda sql: pandasql.sqldf(sql,globals())<br>sql = &#39;select * from foods where ounces &gt; 0&#39;<br>foodsnew = filterFoods(sql)<br>print(&quot;过滤掉异常数据行:\\n %s &quot; % foodsnew)<br><br>foodsnew[&#39;foodtag&#39;] = foodsnew[&#39;food&#39;].str.lower()<br><br>print(&quot;统一食物命名规范:\\n %s &quot; % foodsnew)<br><br># 最后可以使用sql进行按照food排序<br>sql2 = &quot;select * from foodsnew order by food&quot;<br>print(&quot;清洗过后的数据:\\n %s &quot; % filterFoods(sql2))<br><br><br><br>","like_count":1},{"had_liked":false,"id":68444,"user_name":"littlePerfect","can_delete":false,"product_type":"c1","uid":1243521,"ip_address":"","ucode":"99E8B9D004BE0D","user_header":"https://static001.geekbang.org/account/avatar/00/12/f9/81/54b1a5a8.jpg","comment_is_top":false,"comment_ctime":1550500505,"is_pvip":false,"replies":[{"id":"64536","content":"Good Sharing","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577621418,"ip_address":"","comment_id":68444,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5845467801","product_id":100021701,"comment_content":"import pandas as pd<br><br>df = pd.read_excel(&quot;E:\\data_analys_work&#47;food_data.xlsx&quot;)<br><br># 1. 完整性问题: 缺失值<br># df[&#39;ounces&#39;].fillna(df[&#39;ounces&#39;].mean(),inplace=True) # 平均值<br>ounces_maxf = df[&#39;ounces&#39;].value_counts().index[0] # 出现频率最高的值<br>df[&#39;ounces&#39;].fillna(ounces_maxf, inplace=True)<br><br># 2. 全面性问题: 列首字母不统一<br>df[&#39;food&#39;] = df[&#39;food&#39;].str.title()<br><br># 3. 合理性问题: 列数据的单位不统一<br>df[&#39;ounces&#39;] = df[&#39;ounces&#39;].apply(lambda x: abs(x))<br><br># 4. 唯一性问题: 食物重复出现,求和合并,并删除多余行<br># 没想出来.....<br>","like_count":1,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":439677,"discussion_content":"Good Sharing","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577621418,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":68236,"user_name":"草包雷","can_delete":false,"product_type":"c1","uid":1158255,"ip_address":"","ucode":"A6466D21248DF5","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEL8c2Tu3bibiaKQmS1rc58icJOsDKpCtYzhvMMr3YAYTHiboxCAG0CroejUibP0ALOQbzMWz6eyz49Ltcg/132","comment_is_top":false,"comment_ctime":1550463707,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5845431003","product_id":100021701,"comment_content":"import pandas as pd<br>df = pd.read_csv(&quot;c:&#47;&#47;leijin&#47;&#47;food.csv&quot;)<br>df.index<br>print (df)<br><br>df[&#39;ounces&#39;]= df[&#39;ounces&#39;].apply(lambda x: abs(x))<br>df[&#39;ounces&#39;].fillna(df[&#39;ounces&#39;].mean(),inplace=True)<br><br>df[&#39;food&#39;] = df[&#39;food&#39;].str.lower()<br>df.index=range(len(df))<br><br>print (df)<br>","like_count":1},{"had_liked":false,"id":66710,"user_name":"王彬成","can_delete":false,"product_type":"c1","uid":1015045,"ip_address":"","ucode":"386803B8FC2DD5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg","comment_is_top":false,"comment_ctime":1549984896,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5844952192","product_id":100021701,"comment_content":"##作业<br><br>import pandas as pd<br>df=pd.read_csv(&#39;第11节数据-2.csv&#39;)<br><br>## food一列，统一变为小写字母<br>df[&#39;food&#39;]=df[&#39;food&#39;].str.lower()<br><br>##删除重量为空值的一行<br>df=df.dropna()<br><br>##把ounces列中负数转换为正数<br>df[&#39;ounces&#39;]=df[&#39;ounces&#39;].apply(lambda x:abs(x))<br><br>#重新排列序号<br>df.index=range(len(df))<br>df","like_count":1},{"had_liked":false,"id":66574,"user_name":"王彬成","can_delete":false,"product_type":"c1","uid":1015045,"ip_address":"","ucode":"386803B8FC2DD5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg","comment_is_top":false,"comment_ctime":1549960817,"is_pvip":false,"replies":[{"id":"64584","content":"整理的不错","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577622020,"ip_address":"","comment_id":66574,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5844928113","product_id":100021701,"comment_content":"1、完整性：<br>在ounces一列，存在缺失值。处理步骤：删除，因为有重复值<br>2、全面性：<br>food列首字母大小写不统一。处理步骤：利用DataFrame.columns.str.lower()全部换成小写<br>3、合法性：<br>在重量一列，存在负数。处理步骤，删除<br>4、唯一性：<br>在食品名称一列，统一大小写后，存在重复值。处理：求和合并","like_count":1,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438842,"discussion_content":"整理的不错","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577622020,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":62742,"user_name":"胖猫","can_delete":false,"product_type":"c1","uid":1056791,"ip_address":"","ucode":"266AFE93BBBC78","user_header":"https://static001.geekbang.org/account/avatar/00/10/20/17/6ec9ae65.jpg","comment_is_top":false,"comment_ctime":1548146607,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5843113903","product_id":100021701,"comment_content":"#mac python3.6<br>import pandas as pd<br><br>df = pd.read_excel(&quot;.&#47;home_11.xlsx&quot;)<br><br>df.dropna(how=&quot;all&quot;, inplace=True)<br>df[&#39;food&#39;] = df[&#39;food&#39;].str.capitalize()<br>df[&#39;ounces&#39;] = df[&#39;ounces&#39;].apply(lambda x : abs(x))<br>df.fillna(df[&#39;ounces&#39;].mean(), inplace=True)<br>df.drop_duplicates(&#39;food&#39;, inplace=True)<br>print(df)<br>df.to_excel(&quot;.&#47;home_11_washed.xlsx&quot;)","like_count":1},{"had_liked":false,"id":61508,"user_name":"Chino","can_delete":false,"product_type":"c1","uid":1347181,"ip_address":"","ucode":"0240D89E5F74B4","user_header":"https://static001.geekbang.org/account/avatar/00/14/8e/6d/c68e07ef.jpg","comment_is_top":false,"comment_ctime":1547709454,"is_pvip":false,"replies":[{"id":"64707","content":"Good Job!","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577624541,"ip_address":"","comment_id":61508,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5842676750","product_id":100021701,"comment_content":"作业<br>import pandas as pd<br>import numpy as py<br>from pandas import Series, DataFrame<br><br>data = DataFrame(pd.read_excel(&#39;~&#47;Desktop&#47;HomeworkData.xlsx&#39;))<br><br># 把食物的名字统一大小写<br>data[&#39;food&#39;] = data[&#39;food&#39;].str.title()<br><br># 完整性<br># 填充空值<br>data[&#39;ounces&#39;].fillna(data[&#39;ounces&#39;].mean(), inplace = True)<br><br># 全面性<br># 没有发现问题<br><br># 合理性<br># ounces值应大于等于0 负值取绝对值<br>data[&#39;ounces&#39;][data[&#39;ounces&#39;] &lt; 0] = data[&#39;ounces&#39;][data[&#39;ounces&#39;] &lt; 0] * -1<br><br># 唯一性<br># 清除食物名重复的数据<br>data.drop_duplicates(&#39;food&#39;,inplace = True)<br><br>data.to_excel(&#39;HomeworkCleanData.xlsx&#39;)<br>","like_count":1,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":436891,"discussion_content":"Good Job!","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577624541,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":59984,"user_name":"雨先生的晴天","can_delete":false,"product_type":"c1","uid":1246015,"ip_address":"","ucode":"71850548322A1C","user_header":"https://static001.geekbang.org/account/avatar/00/13/03/3f/09308258.jpg","comment_is_top":false,"comment_ctime":1547434962,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5842402258","product_id":100021701,"comment_content":"老师 你好，按照您的方法我清理一下数据，有一些疑惑，希望能指正。<br>在 ‘服装店统计的会员数据’ 例子 最终清洗截图中，最后截图中，<br>No.1 为什么 Huey McDuck 出现了两次？ <br>No.2 为什么 Donald Duck 的体重数据 没有转化成Kgs?  <br>我试着按照例子，自己做了一边，发现以下代码，之修改成功了 Huey McDuck的体重数据，189lbs=85kg, <br><br>rows_with_lbs=df[&#39;weight&#39;].str.contains(&#39;lbs&#39;).fillna(False)<br>print df[rows_with_lbs]<br>weight = int(float(lbs_row[&#39;weight&#39;][:-3])&#47;2.2)<br>df.at[i,&#39;weight&#39;]=&#39;{}kgs&#39;.format(weight)<br>望您指正","like_count":1},{"had_liked":false,"id":57685,"user_name":"caidy","can_delete":false,"product_type":"c1","uid":1188783,"ip_address":"","ucode":"AEFB529C32C7EE","user_header":"https://static001.geekbang.org/account/avatar/00/12/23/af/84f4714e.jpg","comment_is_top":false,"comment_ctime":1546868631,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5841835927","product_id":100021701,"comment_content":"根据完全合一对数据进行清洗<br>1. 把有缺省值的删掉<br>2. 重量需要是正值，把负数的取绝对值<br>3. 把名称哪一类都改为小写<br>4. 去除重复行，或者因为是食物，可以把同样名字的食物加起来合成一行","like_count":1},{"had_liked":false,"id":57648,"user_name":"Viola","can_delete":false,"product_type":"c1","uid":1245457,"ip_address":"","ucode":"7E2E1A7654D877","user_header":"","comment_is_top":false,"comment_ctime":1546858912,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5841826208","product_id":100021701,"comment_content":"df[&#39;Age&#39;].fillna(df[&#39;Age&#39;].mean(), inplace=True)<br>老师好, 对于文中的例子，自己手动尝试了下，发现并不能运行成功，所以有个疑问，<br>在&#39;Age&#39;列数据清洗前，还存在NAN，这样去计算平均值（df[&#39;Age&#39;].mean())，可行吗？<br>另外有个建议：如果文中涉及到对数据的处理，可否把数据文件以附件或github链接的形式给出来，方便我们学习呢？","like_count":1},{"had_liked":false,"id":57605,"user_name":"跳跳","can_delete":false,"product_type":"c1","uid":1172803,"ip_address":"","ucode":"80B697B89E1A0B","user_header":"https://static001.geekbang.org/account/avatar/00/11/e5/43/7bc7cfe3.jpg","comment_is_top":false,"comment_ctime":1546846721,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5841814017","product_id":100021701,"comment_content":"1.从完整性考虑，有缺失值。可以填充平均值<br>2.从全面性考虑，food列首字母大小写不统一，建议规范<br>3.从合理性考虑，存在负值，修改为正值<br>4.从唯一性考虑有三个bacon，但是ounces存在不一致，考虑去掉含NAN的列","like_count":1},{"had_liked":false,"id":57537,"user_name":"Alexander","can_delete":false,"product_type":"c1","uid":1187008,"ip_address":"","ucode":"40226A2A3BCBC3","user_header":"https://static001.geekbang.org/account/avatar/00/12/1c/c0/25c15f45.jpg","comment_is_top":false,"comment_ctime":1546830445,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5841797741","product_id":100021701,"comment_content":"https:&#47;&#47;mubu.com&#47;doc&#47;7maWZgX_Gg<br>有空值，重复值，错值<br>先删掉重复值，然后把盎司用绝对值都变成正数，平均&#47;中位&#47;众数填充空值","like_count":1},{"had_liked":false,"id":351995,"user_name":"xiong","can_delete":false,"product_type":"c1","uid":1099375,"ip_address":"","ucode":"C1BFD9EF96372F","user_header":"https://static001.geekbang.org/account/avatar/00/10/c6/6f/ac3003fa.jpg","comment_is_top":false,"comment_ctime":1658317624,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1658317624","product_id":100021701,"comment_content":"当数据量过大的时候，如何做数据审查呢？","like_count":0},{"had_liked":false,"id":334601,"user_name":"lhs","can_delete":false,"product_type":"c1","uid":1252206,"ip_address":"","ucode":"41178CC21337FB","user_header":"https://static001.geekbang.org/account/avatar/00/13/1b/6e/1bc87ac8.jpg","comment_is_top":false,"comment_ctime":1645014460,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1645014460","product_id":100021701,"comment_content":"使用老师课程中讲到的完全合一规则，发现了以下问题：<br>1.1.ounces列存在NaN值和负数<br>2.food列首字母大小写不统一<br><br>主要数据信息代码如下:<br>def func_abs(df):<br>    return abs(df[&#39;ounces&#39;])<br><br>df[&#39;ounces&#39;] = df.apply(func_abs,axis=1)<br><br>#使用ounces的平均值进行填充Null值<br>df[&#39;ounces&#39;].fillna(df[&#39;ounces&#39;].mean(),inplace=True)<br><br>#统一food列为小写<br>df[&#39;food&#39;] = df[&#39;food&#39;].str.lower()","like_count":0},{"had_liked":false,"id":326639,"user_name":"Ronin","can_delete":false,"product_type":"c1","uid":2657638,"ip_address":"","ucode":"6A4AF619EDFD70","user_header":"https://static001.geekbang.org/account/avatar/00/28/8d/66/89202762.jpg","comment_is_top":false,"comment_ctime":1639615920,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1639615920","product_id":100021701,"comment_content":"1.完整性：第三行ounces存在缺失值，用所有列的平均值进行填充；<br>2.全面性：food属性大小写不统一，全部改为小写；<br>3.合理性：第七行ounces为负值，取绝对值即可；<br>4.唯一性：存在food和animal相同的数据，将这些数据合并，取这几条数据ounces的均值作为合并后的ounces。","like_count":0},{"had_liked":false,"id":310490,"user_name":"Kai","can_delete":false,"product_type":"c1","uid":1349659,"ip_address":"","ucode":"1930EED4331EEE","user_header":"https://static001.geekbang.org/account/avatar/00/14/98/1b/4a48bc4f.jpg","comment_is_top":false,"comment_ctime":1630677068,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1630677068","product_id":100021701,"comment_content":"import pandas as pd<br><br># Read data from csv, using regular expression to remove whitespaces<br>df = pd.read_csv(&#39;.&#47;11-exercise.csv&#39;, sep=r&#39;\\s*,\\s*&#39;, engine=&#39;python&#39;)<br><br># Lowercase all name in the food column<br>df[&#39;food&#39;] = df[&#39;food&#39;].str.lower()<br><br># Drop rows which have NaN value<br>df.dropna(inplace=True)<br><br># Use abs method to remove negative ounce value<br>df[&#39;ounces&#39;] = df[&#39;ounces&#39;].apply(abs)<br><br># Aggregate the ounces by name<br>df = df.groupby(df[&#39;food&#39;]).aggregate(<br>    {&#39;food&#39;: &#39;first&#39;, &#39;ounces&#39;: &#39;sum&#39;, &#39;animal&#39;: &#39;first&#39;})<br><br>df.index = range(len(df))<br><br>Final output<br>          food  ounces  animal<br>0        bacon    12.0     pig<br>1  corned beef     7.5     cow<br>2    honey ham     5.0     pig<br>3     nova lox     6.0  salmon<br>4     pastrami     9.0     cow<br>5  pulled pork     3.0     pig","like_count":0},{"had_liked":false,"id":302473,"user_name":"KokutoDa","can_delete":false,"product_type":"c1","uid":1189534,"ip_address":"","ucode":"2561207E84840E","user_header":"https://static001.geekbang.org/account/avatar/00/12/26/9e/836f603b.jpg","comment_is_top":false,"comment_ctime":1626233249,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1626233249","product_id":100021701,"comment_content":"老师，数据准册的「合理性」和「全面性」我感觉这俩差不多，常识判断是否合理。有什么区别吗？","like_count":0},{"had_liked":false,"id":295028,"user_name":"yang","can_delete":false,"product_type":"c1","uid":1940562,"ip_address":"","ucode":"67C86E09BA6E4B","user_header":"https://static001.geekbang.org/account/avatar/00/1d/9c/52/dc770378.jpg","comment_is_top":false,"comment_ctime":1622189056,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1622189056","product_id":100021701,"comment_content":"清洗的话，把ounces小于零的和空值的行去掉。","like_count":0},{"had_liked":false,"id":289623,"user_name":"Vim๑ºั","can_delete":false,"product_type":"c1","uid":2312293,"ip_address":"","ucode":"350C87C7AB96DC","user_header":"https://static001.geekbang.org/account/avatar/00/23/48/65/e8274238.jpg","comment_is_top":false,"comment_ctime":1619101570,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1619101570","product_id":100021701,"comment_content":"#python 3<br>&quot;&quot;&quot;<br>Created on Thu Apr 22 21:41:13 2021<br><br>@author: Yukka<br>数据问题<br><br>1.完整性<br>ounces 列存在空值--去除数据<br>2.全面性<br>food大小写不一致--改为一致，，并合并数据<br>3.合理性<br>负值--改为正值<br>4.唯一性<br>bacon，pastrami重复值--将food和animal列均相同列数据进行合并<br>&quot;&quot;&quot;<br>import pandas as pd<br>#步骤一 导入数据源<br>df = pd.read_csv(&quot;food-clean.csv&quot;)<br>print(&quot;原数据\\n&quot;,df)<br>#步骤二 将ounces列空值用均值填充<br>df[&#39;ounces&#39;].fillna(df[&#39;ounces&#39;].mean(), inplace=True)<br>print(&quot;空值处理\\n&quot;,df)<br>#步骤三 food列 大小写一致改为小写<br>df[&#39;food&#39;]=df[&#39;food&#39;].str.lower()<br>print(&quot;小写处理\\n&quot;,df)<br>#步骤四 负数正处理<br>df[&#39;ounces&#39;]=df[&#39;ounces&#39;].abs() <br>print(&quot;负数正处理\\n&quot;,df)<br>#步骤五 重复值bacon，pastrami 删除<br>df.drop_duplicates([&#39;food&#39;],inplace=True)<br>print(&quot;重复值删除\\n&quot;,df)","like_count":0},{"had_liked":false,"id":289622,"user_name":"Vim๑ºั","can_delete":false,"product_type":"c1","uid":2312293,"ip_address":"","ucode":"350C87C7AB96DC","user_header":"https://static001.geekbang.org/account/avatar/00/23/48/65/e8274238.jpg","comment_is_top":false,"comment_ctime":1619101538,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1619101538","product_id":100021701,"comment_content":"# -*- coding: utf-8 -*-<br>&quot;&quot;&quot;<br>Created on Thu Apr 22 21:41:13 2021<br><br>@author: Yukka<br>数据问题<br><br>1.完整性<br>ounces 列存在空值--去除数据<br>2.全面性<br>food大小写不一致--改为一致，，并合并数据<br>3.合理性<br>负值--改为正值<br>4.唯一性<br>bacon，pastrami重复值--将food和animal列均相同列数据进行合并<br>&quot;&quot;&quot;<br>import pandas as pd<br>#步骤一 导入数据源<br>df = pd.read_csv(&quot;food-clean.csv&quot;)<br>print(&quot;原数据\\n&quot;,df)<br>#步骤二 将ounces列空值用均值填充<br>df[&#39;ounces&#39;].fillna(df[&#39;ounces&#39;].mean(), inplace=True)<br>print(&quot;空值处理\\n&quot;,df)<br>#步骤三 food列 大小写一致改为小写<br>df[&#39;food&#39;]=df[&#39;food&#39;].str.lower()<br>print(&quot;小写处理\\n&quot;,df)<br>#步骤四 负数正处理<br>df[&#39;ounces&#39;]=df[&#39;ounces&#39;].abs() <br>print(&quot;负数正处理\\n&quot;,df)<br>#步骤五 重复值bacon，pastrami 删除<br>df.drop_duplicates([&#39;food&#39;],inplace=True)<br>print(&quot;重复值删除\\n&quot;,df)","like_count":0},{"had_liked":false,"id":287479,"user_name":"Boom clap!!!","can_delete":false,"product_type":"c1","uid":2443427,"ip_address":"","ucode":"E9AF8ECB963239","user_header":"https://static001.geekbang.org/account/avatar/00/25/48/a3/2df11999.jpg","comment_is_top":false,"comment_ctime":1617968229,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1617968229","product_id":100021701,"comment_content":"练习：import pandas as pd<br>df=pd.read_csv(&#39;shuju.csv&#39;)#导入数据集，我把数据放到了pycharm里<br>print(df)<br>df[&#39;food&#39;]=df[&#39;food&#39;].str.lower()# 把food列中的大写字母全部转换为小写<br>df =df.drop_duplicates()#删除food列中的重复值<br>def zheng(x):<br>    return abs(x)<br>df[&#39;ounces&#39;]=df[&#39;ounces&#39;].apply(zheng)# 把ounces 列中的负数转化为正数<br># 把ounces 列中的NaN替换为平均值<br>df[&#39;ounces&#39;].fillna(df[&#39;ounces&#39;].mean(),inplace=True)<br>df.dropna(how=&#39;all&#39;,inplace=True)<br>df.reset_index(drop=&#39;true&#39;,inplace=True)#给索引重新排序，这里好像也没用到<br>print(df)","like_count":0},{"had_liked":false,"id":277329,"user_name":"黃喻榆","can_delete":false,"product_type":"c1","uid":1924811,"ip_address":"","ucode":"644312AE93C490","user_header":"https://static001.geekbang.org/account/avatar/00/1d/5e/cb/ad85b408.jpg","comment_is_top":false,"comment_ctime":1612360063,"is_pvip":true,"replies":[{"id":"100859","content":"加油~","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1612704706,"ip_address":"","comment_id":277329,"utype":1}],"discussion_count":1,"race_medal":1,"score":"1612360063","product_id":100021701,"comment_content":"1. 完整性: 有一格缺失值<br>2. 全面性: 單位不統一，food欄位值有大小寫，不一致<br>3. 合理性: 若這是物料控管清單，負值可能是出貨，所以減少庫存。需要跟業主確認。<br>4. 唯一性: 若是出貨紀錄，就沒必要要求food欄位是唯一。","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":515007,"discussion_content":"加油~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1612704706,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":275182,"user_name":"要瘦的胖子👋🏼","can_delete":false,"product_type":"c1","uid":1527884,"ip_address":"","ucode":"598037BF56563C","user_header":"https://static001.geekbang.org/account/avatar/00/17/50/4c/22e7b5bf.jpg","comment_is_top":false,"comment_ctime":1611373632,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1611373632","product_id":100021701,"comment_content":"import pandas as pd<br><br>df = pd.read_excel(&#39;C:\\\\Users\\\\18371\\\\Downloads\\\\foodInformation.xlsx&#39;)<br>print(df)<br>print(&#39;*&#39;*100)<br><br># 改为小写字母<br>df[&#39;food&#39;] = df[&#39;food&#39;].str.lower()<br>print(df)<br>print(&#39;*&#39;*100)<br><br># 删除负数数据行<br>df.drop(df[df[&#39;ounces&#39;] &lt; 0].index, inplace=True)<br>print(df)<br>print(&#39;*&#39;*100)<br><br># 用平均数填充缺失记录<br>df[&#39;ounces&#39;].fillna(df[&#39;ounces&#39;].mean(), inplace=True)<br>print(df)<br>print(&#39;*&#39;*100)<br><br><br>d_rows = df[df[&#39;food&#39;].duplicated(keep=False)]<br>print(d_rows)<br>print(&#39;*&#39;*100)<br><br>print(df[&#39;ounces&#39;][df[&#39;food&#39;] == &#39;bacon&#39;])<br>print(df.loc[df[df[&#39;food&#39;] == &#39;bacon&#39;].index, &#39;ounces&#39;])<br>df.loc[df[df[&#39;food&#39;] == &#39;bacon&#39;].index, &#39;ounces&#39;] = d_rows[&#39;ounces&#39;].mean()<br>print(df)<br>print(&#39;*&#39;*100)<br><br># 删除重复记录<br>df.drop_duplicates(inplace=True)<br>print(df)<br>print(&#39;*&#39;*100)<br><br># 重设索引值<br>df.index = range(len(df))<br>print(df)<br><br># 结果<br>          food    ounces  animal<br>0        bacon  5.880952     pig<br>1  pulled port  3.000000     pig<br>2     pastrami  6.000000     cow<br>3  corned beef  7.500000     cow<br>4    honey ham  5.000000     pig<br>5     nova lox  6.000000  salmon<br><br>Process finished with exit code 0","like_count":0},{"had_liked":false,"id":265776,"user_name":"Hivan","can_delete":false,"product_type":"c1","uid":2254242,"ip_address":"","ucode":"3EC3D9C6BF9091","user_header":"https://static001.geekbang.org/account/avatar/00/22/65/a2/88aca8f7.jpg","comment_is_top":false,"comment_ctime":1607009694,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1607009694","product_id":100021701,"comment_content":"# 作业<br>import pandas as pd<br>from pandas import Series,DataFrame<br>import numpy as np<br><br>df = DataFrame(pd.read_excel(&#39;excel2.xlsx&#39;))<br><br># 处理NaN值<br>df[&#39;ounces&#39;].fillna(df[&#39;ounces&#39;].mean(), inplace=True)<br># 处理不正确的值<br>df[&#39;ounces&#39;] = abs(df[&#39;ounces&#39;])<br># 处理重复值<br>df.drop_duplicates([&#39;food&#39;], inplace=True)<br># 处理名称大小写<br>df[&#39;food&#39;] = df[&#39;food&#39;].str.capitalize()<br>df","like_count":0},{"had_liked":false,"id":250700,"user_name":"McKee Chen","can_delete":false,"product_type":"c1","uid":2037505,"ip_address":"","ucode":"F74B76542FAB65","user_header":"https://static001.geekbang.org/account/avatar/00/1f/17/01/1c5309a3.jpg","comment_is_top":false,"comment_ctime":1601198743,"is_pvip":false,"replies":[{"id":"103013","content":"非常棒！对某一列的文本字符串进行小写操作时，也可以使用df1[&#39;food&#39;].str.lower()","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1615999972,"ip_address":"","comment_id":250700,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1601198743","product_id":100021701,"comment_content":"#练习<br>我的思考：从excel中打开数据，对其空白值进行填充，然后对food列的值全部小写，再按food和animal对数据进行分类，计算ounces均值，最后数据输出成新的excel<br>import pandas as pd<br>import numpy as np<br>from pandas import Series,DataFrame<br>#建立数据表<br>df1 = pd.read_excel(r&#39;C:\\Users\\XXX\\Desktop\\0928.xlsx&#39;)<br>#用ounces.mean()填充空白值<br>df1[&#39;ounces&#39;].fillna(df1[&#39;ounces&#39;].mean(), inplace=True)<br>#将food列全部小写<br>for i in range(9):<br>    df1.at[i,&#39;food&#39;] = df1[&#39;food&#39;][i].lower()<br>#通过groupby对相同的food和animal求ounces均值<br>df1 = df1.groupby([df1[&#39;food&#39;],df1[&#39;animal&#39;]]).mean()<br>df1.to_excel(r&#39;C:\\Users\\XXX\\Desktop\\0928_1.xlsx&#39;)<br><br>老师讲的数据清洗非常易懂，得多加练习，才能熟能生巧，并要做到温故知新","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":506264,"discussion_content":"非常棒！对某一列的文本字符串进行小写操作时，也可以使用df1[&amp;#39;food&amp;#39;].str.lower()","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1615999972,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":245050,"user_name":"拾光","can_delete":false,"product_type":"c1","uid":2087581,"ip_address":"","ucode":"3F88BAB08EF775","user_header":"https://static001.geekbang.org/account/avatar/00/1f/da/9d/1f825568.jpg","comment_is_top":false,"comment_ctime":1598795206,"is_pvip":false,"replies":[{"id":"103495","content":"感谢分享，大家可以直接复制使用哦","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1616688513,"ip_address":"","comment_id":245050,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1598795206","product_id":100021701,"comment_content":"这是ocr识别的源数据，供实验用<br>[[&quot;bacon&quot;, 4.0, &quot;pig&quot;],<br>[&quot;pulled pork&quot;, 3.0, &quot;pig&quot;],<br>[&quot;bacon&quot;, NaN , &quot;pig&quot;],<br>[&quot;Pastrami&quot;, 6.0, &quot;cow&quot;],<br>[&quot;corned beef&quot;, 7.5, &quot;cow&quot;],<br>[&quot;Bacon&quot;, 8.0, &quot;pig&quot;],<br>[&quot;pastrami&quot;, 3.0, &quot;cow&quot;],<br>[&quot;honey ham&quot;, 5.0, &quot;pig&quot;],<br>[&quot;nova lox&quot;, 6.0, &quot;salmon&quot;]]","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":504777,"discussion_content":"感谢分享，大家可以直接复制使用哦","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616688513,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":232800,"user_name":"热河","can_delete":false,"product_type":"c1","uid":2047160,"ip_address":"","ucode":"7D0AC18CE97BFD","user_header":"https://static001.geekbang.org/account/avatar/00/1f/3c/b8/cd7dc389.jpg","comment_is_top":false,"comment_ctime":1594120765,"is_pvip":false,"replies":[{"id":"103520","content":"负数转正数可以使用pandas现成的API：df[&quot;ounces&quot;] = df[&quot;ounces&quot;].abs()","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1616694924,"ip_address":"","comment_id":232800,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1594120765","product_id":100021701,"comment_content":"import pandas as pd<br><br>file_path = &quot;.&#47;foodInformation.csv&quot;<br>df = pd.read_csv(file_path)<br>#数据清洗四项基本原则<br>#1、完整性：缺失、空行<br>#删除空行,how不写含有nan的行全部删除<br>df.dropna(how=&quot;all&quot;, inplace=True)<br><br>#均值替换<br>#df[&quot;ounces&quot;].fillna(df[&quot;ounces&quot;].mean(), inplace=True)<br>#高频替换<br>ou_maxf = df[&quot;ounces&quot;].value_counts().index[0]<br>df[&quot;ounces&quot;].fillna(ou_maxf, inplace=True)<br><br>#2、合法性：负数转为正数<br># for i in df[&quot;ounces&quot;]:<br>#     if i&lt;0:<br>#         i = abs(i)<br>df[&quot;ounces&quot;] = df[&quot;ounces&quot;].apply(lambda a: abs(a))<br><br>#合法性：统一大小写<br>df[&quot;food&quot;] = df[&quot;food&quot;].str.lower()<br><br>#唯一性：删除重复<br>df.drop_duplicates(&quot;food&quot;, inplace=True)<br><br>#排序<br>df_sort = df.sort_values(by=[&quot;ounces&quot;], axis=0, ascending=True)<br><br>print(df_sort)<br>","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":500772,"discussion_content":"负数转正数可以使用pandas现成的API：df[&amp;quot;ounces&amp;quot;] = df[&amp;quot;ounces&amp;quot;].abs()","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616694924,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":232799,"user_name":"热河","can_delete":false,"product_type":"c1","uid":2047160,"ip_address":"","ucode":"7D0AC18CE97BFD","user_header":"https://static001.geekbang.org/account/avatar/00/1f/3c/b8/cd7dc389.jpg","comment_is_top":false,"comment_ctime":1594120733,"is_pvip":false,"replies":[{"id":"103521","content":"df[&quot;ounces&quot;] = df[&quot;ounces&quot;].abs() 可以将所有DataFrame中的负数转为正数。","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1616694971,"ip_address":"","comment_id":232799,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1594120733","product_id":100021701,"comment_content":"import pandas as pd<br><br>file_path = &quot;.&#47;foodInformation.csv&quot;<br>df = pd.read_csv(file_path)<br>#数据清洗四项基本原则<br>#1、完整性：缺失、空行<br>#删除空行,how不写含有nan的行全部删除<br>df.dropna(how=&quot;all&quot;, inplace=True)<br><br>#均值替换<br>#df[&quot;ounces&quot;].fillna(df[&quot;ounces&quot;].mean(), inplace=True)<br>#高频替换<br>ou_maxf = df[&quot;ounces&quot;].value_counts().index[0]<br>df[&quot;ounces&quot;].fillna(ou_maxf, inplace=True)<br><br>#2、合法性：负数转为正数<br># for i in df[&quot;ounces&quot;]:<br>#     if i&lt;0:<br>#         i = abs(i)<br>df[&quot;ounces&quot;] = df[&quot;ounces&quot;].apply(lambda a: abs(a))<br><br>#合法性：统一大小写<br>df[&quot;food&quot;] = df[&quot;food&quot;].str.lower()<br><br>#唯一性：删除重复<br>df.drop_duplicates(&quot;food&quot;, inplace=True)<br><br>#排序<br>df_sort = df.sort_values(by=[&quot;ounces&quot;], axis=0, ascending=True)<br><br>print(df_sort)<br>","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":500771,"discussion_content":"df[&amp;quot;ounces&amp;quot;] = df[&amp;quot;ounces&amp;quot;].abs() 可以将所有DataFrame中的负数转为正数。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616694971,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":226764,"user_name":"As1m0v","can_delete":false,"product_type":"c1","uid":2035261,"ip_address":"","ucode":"279177F30FA011","user_header":"https://static001.geekbang.org/account/avatar/00/1f/0e/3d/ded8bc06.jpg","comment_is_top":false,"comment_ctime":1592198839,"is_pvip":false,"replies":[{"id":"103728","content":"不错！！！加油！！","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1617038085,"ip_address":"","comment_id":226764,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1592198839","product_id":100021701,"comment_content":"Python3 <br>Jupyter Notebook<br>练习题回答<br># 根据ounces列删除含有缺失值数据项<br>file2.dropna(subset = [&#39;ounces&#39;], inplace = True)<br><br># 将food列中每一行数据统一大小写<br>file2[&#39;food&#39;] = file2[&#39;food&#39;].str.lower()<br><br># 将ounces列中数据统一为正数(方法一)<br>file2[&#39;ounces&#39;] = file2[&#39;ounces&#39;].abs()<br><br># 将ounces列中异常数据删除(方法二)<br># 这种情况下，这一方法可以和第一条合并<br>#file2 = file2[file2[&#39;ounces&#39;]&gt;0]<br><br># 将具有相同food列值和animal列值的数据（可选）<br>file3 = file2.groupby([&#39;food&#39;,&#39;animal&#39;]).sum()","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":498356,"discussion_content":"不错！！！加油！！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617038085,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":224102,"user_name":"清风","can_delete":false,"product_type":"c1","uid":1987801,"ip_address":"","ucode":"5F99A1442E0390","user_header":"https://static001.geekbang.org/account/avatar/00/1e/54/d9/76a53118.jpg","comment_is_top":false,"comment_ctime":1591275449,"is_pvip":false,"replies":[{"id":"103738","content":"items = df.groupby(&#39;food&#39;).mean()<br>items[&#39;food&#39;] = items.index<br>可以合并为：<br>items = df.groupby(&#39;food&#39;, as_index=False).mean()<br><br>for 循环部分的代码，可以试试df = df.merge(items, on=&#39;food&#39;)","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1617039895,"ip_address":"","comment_id":224102,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1591275449","product_id":100021701,"comment_content":"import pandas as pd<br>import numpy as np<br>df = pd.DataFrame({&#39;food&#39;:[&#39;bacon&#39;, &#39;pulled pork&#39;, &#39;bacon&#39;, &#39;Pastrami&#39;, &#39;corned beef&#39;, &#39;Bacon&#39;, &#39;pastrami&#39;, &#39;honey ham&#39;, &#39;nova lox&#39;],<br>                  &#39;ounces&#39;:[4.0, 3.0, None, 6.0, 7.5, 8.0, -3.0, 5.0, 6.0],<br>                  &#39;animal&#39;:[&#39;pig&#39;, &#39;pig&#39;, &#39;pig&#39;, &#39;cow&#39;, &#39;cow&#39;, &#39;pig&#39;, &#39;cow&#39;, &#39;pig&#39;, &#39;salmon&#39;]},<br>                 columns=[&#39;food&#39;, &#39;ounces&#39;, &#39;animal&#39;])<br>df<br>df.isnull().any()<br># 处理None值 赋值为高频词<br># 这里初始处理时按赋值 后来发现删除可能更好一点<br># df[&#39;ounces&#39;].fillna(df[&#39;ounces&#39;].value_counts().index[0], inplace=True)<br>df.dropna(inplace=True)<br># 把负值赋值为6.0<br># df[&#39;ounces&#39;].where(df[&#39;ounces&#39;] &gt; 0, df[&#39;ounces&#39;].value_counts().index[0])<br># 绝对值处理<br>df[&#39;ounces&#39;] = df[&#39;ounces&#39;].apply(lambda x:abs(x))<br>df<br>df[&#39;food&#39;] = df[&#39;food&#39;].str.lower()<br>items = df.groupby(&#39;food&#39;).mean()<br>items[&#39;food&#39;] = items.index<br>for i, row in items.iterrows():<br>    df.loc[df[&#39;food&#39;] == row[&#39;food&#39;],&#39;ounces&#39;] = row[&#39;ounces&#39;]<br>df.drop_duplicates(inplace=True)<br>df.reset_index(inplace=True, drop=True)<br>df","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":497366,"discussion_content":"items = df.groupby(&amp;#39;food&amp;#39;).mean()\nitems[&amp;#39;food&amp;#39;] = items.index\n可以合并为：\nitems = df.groupby(&amp;#39;food&amp;#39;, as_index=False).mean()\n\nfor 循环部分的代码，可以试试df = df.merge(items, on=&amp;#39;food&amp;#39;)","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617039895,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":207130,"user_name":"骑行的掌柜J","can_delete":false,"product_type":"c1","uid":1474214,"ip_address":"","ucode":"3163102651C653","user_header":"https://static001.geekbang.org/account/avatar/00/16/7e/a6/4e331ef4.jpg","comment_is_top":false,"comment_ctime":1587012135,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1587012135","product_id":100021701,"comment_content":"https:&#47;&#47;blog.csdn.net&#47;weixin_41013322&#47;article&#47;details&#47;105510187  终于开启二刷重整陈老师的课程中漏掉的知识点 希望对大家有用！😁","like_count":0},{"had_liked":false,"id":206915,"user_name":"夕子","can_delete":false,"product_type":"c1","uid":1916066,"ip_address":"","ucode":"4115ABE599B2F4","user_header":"https://static001.geekbang.org/account/avatar/00/1d/3c/a2/09a2215c.jpg","comment_is_top":false,"comment_ctime":1586956374,"is_pvip":false,"replies":[{"id":"103981","content":"不错","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1617291501,"ip_address":"","comment_id":206915,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1586956374","product_id":100021701,"comment_content":"（1）完整性：ounces列存在空值NaN<br>清洗方式：用均值填充<br>（2）全面性：food列大小写不统一<br>清洗方式：统一为小写<br>（3）合理性：ounces列存在负值<br>清洗方式：判断是否合理，若不合理，删除或者均值填充<br>（4）唯一性：food列有重复<br>清洗方式：去重","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491949,"discussion_content":"不错","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617291501,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":206277,"user_name":"哎哟哟","can_delete":false,"product_type":"c1","uid":1619213,"ip_address":"","ucode":"8E8C2899B73DF8","user_header":"https://static001.geekbang.org/account/avatar/00/18/b5/0d/df1f17b5.jpg","comment_is_top":false,"comment_ctime":1586833419,"is_pvip":false,"replies":[{"id":"103985","content":"可以试试装anaconda，使用conda的虚拟环境，可以省去很多环境上的问题。","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1617292012,"ip_address":"","comment_id":206277,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1586833419","product_id":100021701,"comment_content":"1，第四行第二列缺失数据，需删除。<br>2，倒数第3行第2列数据不合法，需删除。<br>3，重复数据，bacon有3条数据、pastrami有2行数据，如果数据有效需合并，否则删除。<br>4，food列有大小写，需统一替换。<br><br>操作步骤：先删除空值、不合法数据。替换大小写，合并有效数据、删除重复数据。<br><br>环境就整了几天结果还是没搞定，pyCharm装第三方库顺利的时候真简单，一旦有问题各种复杂，最后用Spyder跑了【晨星】同学的代码终于跑通了，差点又死在环境上。。。","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491737,"discussion_content":"可以试试装anaconda，使用conda的虚拟环境，可以省去很多环境上的问题。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617292012,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":200150,"user_name":"Geek_樗","can_delete":false,"product_type":"c1","uid":1920476,"ip_address":"","ucode":"F6D9D29ED521F8","user_header":"https://static001.geekbang.org/account/avatar/00/1d/4d/dc/4695da88.jpg","comment_is_top":false,"comment_ctime":1585550918,"is_pvip":false,"replies":[{"id":"104331","content":"哈哈，学完就可以摆脱这种烦恼了","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1617903111,"ip_address":"","comment_id":200150,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1585550918","product_id":100021701,"comment_content":"刚开始接触这个工作时，就因为不注意数据的整洁，犯了不少笑话。跑出来的报表数据吓死个人。","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":489948,"discussion_content":"哈哈，学完就可以摆脱这种烦恼了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617903111,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":196659,"user_name":"十六。","can_delete":false,"product_type":"c1","uid":1935100,"ip_address":"","ucode":"DD4A02E3D904D5","user_header":"","comment_is_top":false,"comment_ctime":1585300567,"is_pvip":false,"replies":[{"id":"104223","content":"Good Job","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1617731565,"ip_address":"","comment_id":196659,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1585300567","product_id":100021701,"comment_content":"import pandas as pd<br>from pandas import Series,DataFrame<br><br>df = pd.read_csv(&#39;dws&#47;foodInfo.csv&#39;)<br># 首先 通过学习的数据分析的‘完全合一’简单清洗定理来分析数据<br># 数据存在空值（空值可以删除或是使用均值填入，此处我们删除）、大小写不一、单位不合理存在负数<br># 首先去除导入进来时多出和行<br>df = df.dropna()<br>df = df.drop(df[df[&#39;ounces&#39;] &lt; 0].index)<br>df[&#39;food&#39;] = df[&#39;food&#39;].str.lower()<br># 对数据进行重新行索引<br>df.index = range(len(df))<br># df.reindex(index=list(range(len(df))))<br>df<br><br>\tfood\tounces\tanimal<br>0\tbacon\t4.0\tpig<br>1\tpulled port\t3.0\tpig<br>2\tpastrami\t6.0\tcow<br>3\tcorned beef\t7.5\tcow<br>4\tbacon\t8.0\tpig<br>5\thoney ham\t5.0\tpig<br>6\tnova lox\t6.0\tsalmon<br><br><br>","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":489353,"discussion_content":"Good Job","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617731565,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":195806,"user_name":"pyall","can_delete":false,"product_type":"c1","uid":1928703,"ip_address":"","ucode":"6C2A8DB86EE8FB","user_header":"https://static001.geekbang.org/account/avatar/00/1d/6d/ff/d5d14e2c.jpg","comment_is_top":false,"comment_ctime":1585216161,"is_pvip":false,"replies":[{"id":"104347","content":"Good Job!!!","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1617904222,"ip_address":"","comment_id":195806,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1585216161","product_id":100021701,"comment_content":"整理思路：<br>1、删掉无效数据（整行），并填充缺失值<br>2、添加性别列，填充性别值<br>3、合并三维（三列）数据<br>4、重命名表头字段名称<br>5、第3列统一标准单位，且数字化<br><br>&quot;&quot;&quot;<br>import pandas as pd<br>import numpy as np<br>import matplotlib.pyplot as plt<br><br>path = r&quot;E:\\accountMessage.xlsx&quot;<br><br>df = pd.read_excel(path)<br>df.columns #Index([&#39;\\t&#39;, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=&#39;object&#39;)<br>#df.drop([&#39;&#39;])<br>df = df[[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]<br>#1、删掉空值（整行）<br>df.dropna(axis=0,how=&#39;all&#39;,inplace = True)<br><br>#重命名表头字段名称<br>df = df.rename(columns = {0:&#39;id&#39;,1:&#39;Name&#39;,2:&#39;Age&#39;,3:&#39;Weight&#39;})<br>df[&#39;Age&#39;] = df[&#39;Age&#39;].fillna(round(df[&#39;Age&#39;].mean(),0)) #使用平均数填充<br>df[&#39;Age&#39;].value_counts().index[0]#使用频数最高的数填充<br><br><br>#2、添加性别列，填充性别值<br>df[&#39;sex&#39;]=&#39;&#39;<br>df[&#39;sex&#39;][df[4]==&quot;-&quot;]=&#39;female&#39;<br>df[&#39;sex&#39;][df[4]!=&quot;-&quot;]=&#39;male&#39;<br><br>#3、合并三维（三列）数据<br>df[df==&#39;-&#39;]=0<br>df2 = df.replace(&#39;-&#39;,0)<br>df2[&#39;d1&#39;] =df2[4] +df2[7]<br>df2[&#39;d2&#39;] =df2[5] +df2[8]<br>df2[&#39;d3&#39;] =df2[6] +df2[9]<br><br>df3 = df2.drop([4,5,6,7,8,9],axis=1)<br>df3 = df2.drop([4]) #默认删除行数据<br><br>#5、第3列统一标准单位，且数字化<br>#1磅(lb)=0.4535924公斤(kg)<br><br>df3.isnull().sum()<br><br>#数字与字母分开,分成两列<br>df3[&#39;Weight&#39;].str.replace(&#39;s&#39;,&quot;z&quot;)<br>df3[&#39;w_unit&#39;] = df3[&#39;Weight&#39;].str[-3:]<br>df3[&#39;w_new&#39;] = df3[&#39;Weight&#39;].str[:-3].astype(float)<br><br>#转化单位数值<br>df3[&#39;w_kg&#39;] = 0<br>#不执行<br>df3[df3[&#39;w_unit&#39;]==&#39;lbs&#39;].loc[:,&#39;w_kg&#39;] = df3[&#39;w_new&#39;]*0.4535924<br>#执行成功<br>df3.loc[:,&#39;w_kg&#39;][df3[&#39;w_unit&#39;]==&#39;lbs&#39;] = df3[&#39;w_new&#39;]*0.4535924<br>df3.loc[:,&#39;w_kg&#39;][df3[&#39;w_unit&#39;]==&#39;kgs&#39;] = df3[&#39;w_new&#39;]","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":489159,"discussion_content":"Good Job!!!","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617904222,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":193772,"user_name":"周铭宇","can_delete":false,"product_type":"c1","uid":1911388,"ip_address":"","ucode":"19C800CFC4F1F1","user_header":"","comment_is_top":false,"comment_ctime":1584960637,"is_pvip":false,"replies":[{"id":"104354","content":"Good Job","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1617904565,"ip_address":"","comment_id":193772,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1584960637","product_id":100021701,"comment_content":"data = {&#39;food&#39;:[&#39;bacon&#39;,&#39;pulled pork&#39;,&#39;bacon&#39;,&#39;Pastrami&#39;,&#39;couned beef&#39;,&#39;bacon&#39;,&#39;pastrami&#39;,&#39;honey ham&#39;,&#39;nova lox&#39;],<br>        &#39;ounces&#39;:[4.0,3.0,None,6.0,7.5,8.0,-3.0,5.0,6.0],<br>        &#39;animal&#39;:[&#39;pig&#39;,&#39;pig&#39;,&#39;pig&#39;,&#39;cow&#39;,&#39;cow&#39;,&#39;pig&#39;,&#39;cow&#39;,&#39;pig&#39;,&#39;salmon&#39;,]}<br><br>df1 = DataFrame(data)<br>df1.columns = df1.columns.str.title() # 大写开头<br>df1[&#39;Food&#39;] = df1[&#39;Food&#39;].str.title()<br>df1[&#39;Ounces&#39;].fillna(df1[&#39;Ounces&#39;].mean(),inplace=True) # 填充空值<br>df1[&#39;Ounces&#39;] = df1[&#39;Ounces&#39;].apply(lambda a:abs(a)) # 替换负值<br>df1.sort_values([&#39;Food&#39;],ascending=[False],inplace=True) # 重新排序<br>df1.index = range(len(df1)) <br>indexArray = [0]<br>for i in range(1,df1[&#39;Food&#39;].count()): <br>    indexArray.append(i)<br>df1[&#39;Id&#39;] = indexArray<br>pysqldf = lambda sql: sqldf(sql, globals())<br>data1 = {&#39;Food&#39;:[&#39;0&#39;]}<br>lastResult = DataFrame(data1) # 创建一个新的数据 用来判断是否为重复数据<br>repeatArray = []<br>for i in range(0,df1[&#39;Food&#39;].count()): # 找出列值均相同行<br>    sql = &quot;select * from df1 where Animal = &#39;{}&#39; AND Food = &#39;{}&#39;&quot;.format(df1[&#39;Animal&#39;][i],df1[&#39;Food&#39;][i])<br>    result = DataFrame(pysqldf(sql))<br>    if len(result) != 1:<br>        if result[&#39;Food&#39;][0] != lastResult[&#39;Food&#39;][0]: # 判断是否数据<br>            lastResult = result<br>            repeatArray.append(result)<br><br><br><br>def calculate(result): # 计算平均数<br>    mean = 0.0;<br>    for i in range(0,result[&#39;Food&#39;].count()):<br>        mean = result[&#39;Ounces&#39;][i] + mean<br><br>    mean = mean &#47; result[&#39;Food&#39;].count()<br>    return mean<br><br>def replaceOunces(result,mean): # 将平均数改为Ounces的值<br><br>    for i in range(0,result[&#39;Food&#39;].count()):<br>        resultId = result[&#39;Id&#39;][i]<br>        df1.Ounces[df1[&#39;Id&#39;]==resultId]=mean<br><br><br>for i in range(0,len(repeatArray)): # 初次清洗<br>    mean = calculate(repeatArray[i])<br>    replaceOunces(repeatArray[i],mean)<br><br>df1.drop([&#39;Id&#39;],axis=1,inplace=True) #删除<br>df1.drop_duplicates(inplace=True) # 去重<br>print(df1)<br><br>&#39;&#39;&#39;<br>输出结果<br>          Food    Ounces  Animal<br>0  Pulled Pork  3.000000     pig<br>1     Pastrami  4.500000     cow<br>3     Nova Lox  6.000000  salmon<br>4    Honey Ham  5.000000     pig<br>5  Couned Beef  7.500000     cow<br>6        Bacon  5.520833     pig<br><br>&#39;&#39;&#39;","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":488653,"discussion_content":"Good Job","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617904565,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":179756,"user_name":"will","can_delete":false,"product_type":"c1","uid":1750093,"ip_address":"","ucode":"A36CADCB62BFB5","user_header":"https://static001.geekbang.org/account/avatar/00/1a/b4/4d/f072c7f9.jpg","comment_is_top":false,"comment_ctime":1582092729,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1582092729","product_id":100021701,"comment_content":"data={&quot;food&quot;:[&quot;bacon&quot;,&quot;pulled pork&quot;,&quot;bacon&quot;,&quot;Pastrami&quot;,&quot;corned beef&quot;,&quot;Bacon&quot;,&quot;pastrami&quot;,&quot;honey ham&quot;,&quot;nova lox&quot;],&quot;ounces&quot;:[4,3,np.nan,6,7.5,8,-3,5,6],<br>      &quot;animal&quot;:[&quot;pig&quot;,&quot;pig&quot;,&quot;pig&quot;,&quot;cow&quot;,&quot;cow&quot;,&quot;pig&quot;,&quot;cow&quot;,&quot;pig&quot;,&quot;salmon&quot;]}<br>df3=pd.DataFrame(data,columns=[&quot;food&quot;,&quot;ounces&quot;,&quot;animal&quot;])<br>df3[&quot;ounces&quot;]=abs(df3[&quot;ounces&quot;].values)<br>df3.fillna(int(df3[&quot;ounces&quot;].mean()),inplace=True)<br>df3[&quot;food&quot;]=df3[&quot;food&quot;].str.title()<br>df3.drop_duplicates([&quot;food&quot;,&quot;ounces&quot;],inplace=True)","like_count":0},{"had_liked":false,"id":176506,"user_name":"鱼非子","can_delete":false,"product_type":"c1","uid":1818595,"ip_address":"","ucode":"BB76AE2CB4D680","user_header":"https://static001.geekbang.org/account/avatar/00/1b/bf/e3/2aa8ec84.jpg","comment_is_top":false,"comment_ctime":1581074389,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1581074389","product_id":100021701,"comment_content":"看着男女的三围尺寸的6列很扎心，于是做了一些简单处理。<br>import numpy as np<br>import pandas as pd<br>import matplotlib.pyplot as plt<br><br>df = pd.DataFrame(data)<br><br>#删除空行和重复值<br>df.drop_duplicates(&#39;name&#39;,inplace= True)<br>df.dropna(how=&#39;all&#39;,inplace= True)<br><br>#填充年龄的缺失值<br>df[&#39;age&#39;].fillna(df[&#39;age&#39;].mean())<br><br><br>#对体重进行换算<br># 获取 weight 数据列中单位为 lbs 的数据<br>rows_with_lbs = df[&#39;weight&#39;].str.contains(&#39;lbs&#39;).fillna(False)<br>#print (df[rows_with_lbs])<br># 将 lbs转换为 kgs, 2.2lbs=1kgs<br>for i,lbs_row in df[rows_with_lbs].iterrows():<br>  # 截取从头开始到倒数第三个字符之前，即去掉lbs。<br>  weight = int(float(lbs_row[&#39;weight&#39;][:-3])&#47;2.2)<br>  df.at[i,&#39;weight&#39;] = &#39;{}kgs&#39;.format(weight)<br><br><br>for i,sex_row in df.iterrows():<br>    sex = (sex_row[&#39;m0&#39;]+sex_row[&#39;m0&#39;]+sex_row[&#39;m0&#39;]) &gt;0<br>    if sex:<br>        df.at[i,&#39;sex&#39;] = &quot;man&quot;<br>    else:<br>        df.at[i,&#39;sex&#39;] = &quot;woman&quot;<br><br>for i,sex_row in df.iterrows():<br>    if sex_row[&#39;sex&#39;] == &quot;man&quot;:<br>        df.at[i, &#39;00&#39;] = sex_row[&#39;m0&#39;]<br>        df.at[i, &#39;11&#39;] = sex_row[&#39;m1&#39;]<br>        df.at[i, &#39;22&#39;] = sex_row[&#39;m2&#39;]<br>    else:<br>        df.at[i, &#39;00&#39;] = sex_row[&#39;w0&#39;]<br>        df.at[i, &#39;11&#39;] = sex_row[&#39;w1&#39;]<br>        df.at[i, &#39;22&#39;] = sex_row[&#39;w2&#39;]<br>    <br>df.drop([&#39;m0&#39;,&#39;m1&#39;,&#39;m2&#39;,&#39;w0&#39;,&#39;w1&#39;,&#39;w2&#39;],axis=1,inplace=True)<br>print(df)<br><br>结果如下：<br>              name   age weight    sex    00    11    22<br>0     mickey mouse  56.0  70kgs    man  72.0  69.0  71.0<br>1      donald duck  34.0  70kgs  woman  85.0  84.0  76.0<br>2       mini mouse  16.0   None  woman  65.0  69.0  72.0<br>3   scrooge mcduck   NaN  78kgs    man  78.0  79.0  72.0<br>4     pink panther  54.0  90kgs  woman  69.0   NaN  75.0<br>5      huey mcduck  52.0  85kgs  woman  68.0  75.0  72.0<br>6     dewey dcduck  19.0  56kgs  woman  71.0  78.0  75.0<br>7       scoopy doo  32.0  78kgs    man  78.0  76.0  75.0<br>10    louie mcduck  12.0  45kgs  woman  92.0  95.0  87.0<br><br>","like_count":0},{"had_liked":false,"id":172501,"user_name":"李璇","can_delete":false,"product_type":"c1","uid":1795522,"ip_address":"","ucode":"F311CD7B6F8680","user_header":"https://static001.geekbang.org/account/avatar/00/1b/65/c2/9ecbb0b2.jpg","comment_is_top":false,"comment_ctime":1579193321,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1579193321","product_id":100021701,"comment_content":"如果数据很多可以用info看一下缺失情况<br>food首字母大写<br>用bacon的均值填充bacon缺失值<br>将负数ounce列删除<br><br>import pandas as pd<br>import os<br>os.chdir(&#39;C:\\\\Users\\\\Violette\\\\Desktop\\\\&#39;)<br>data=pd.read_csv(&#39;11作业数据.csv&#39;,encoding=&#39;UTF-8&#39;)<br>data.info()<br>data.food.str.capitalize()<br>mean_ounce=data[(data[&#39;food&#39;]==&#39;Bacon&#39;)&amp;(data[&#39;ounces&#39;].notnull())][&#39;ounces&#39;].mean()<br>data.loc[data[&#39;ounces&#39;].isnull(),&#39;ounces&#39;]=mean_ounce<br>data= data.drop(data[data.ounces &lt; 0].index).reindex()","like_count":0},{"had_liked":false,"id":171799,"user_name":"苹果","can_delete":false,"product_type":"c1","uid":1761988,"ip_address":"","ucode":"5D0FA9D8560FD8","user_header":"https://static001.geekbang.org/account/avatar/00/1a/e2/c4/25acaa38.jpg","comment_is_top":false,"comment_ctime":1579014726,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1579014726","product_id":100021701,"comment_content":"# -*- coding: utf-8 -*-<br>import numpy<br>import pandas as pd<br>import os<br><br>os.chdir(&#39;E:\\\\C-05-数据分析实战\\\\01基础篇\\\\数据清理材料&#39;)<br>df = pd.read_excel(&#39;.\\\\accountMessage.xlsx&#39;)<br>df.drop(columns=[0,&#39;\\t&#39;],inplace = True)<br>df.rename(columns={1:&#39;name&#39;,2:&#39;age&#39;,3:&#39;weights&#39;,4:&#39;m0006&#39;,5:&#39;m0612&#39;,6:&#39;m1218&#39;,7:&#39;f0006&#39;,8:&#39;f0612&#39;,9:&#39;f1218&#39;},inplace=True)<br>df[&#39;age&#39;].fillna(df[&#39;age&#39;].mean(),inplace=True)<br>#用体重的众数填入空值<br>df[&#39;weights&#39;].fillna(df[&#39;weights&#39;].value_counts().index[0] , inplace=True )<br>#删除所用空值<br>df.dropna(how=&#39;all&#39;,inplace=True)<br>rows_with_lbs = df[&#39;weights&#39;].str.contains(&#39;lbs&#39;)<br># print(df[rows_with_lbs].iterrows())<br># exit()<br>#统一单位为千克<br>for i ,lbs_row in df[rows_with_lbs].iterrows():<br>    weight = int(float(lbs_row[&#39;weights&#39;][:-3])&#47;2.2)<br>    df.at[i,&#39;weights&#39;] = &#39;{}kgs&#39;.format(weight)<br>df.replace({r&#39;[^\\x00-\\x7F]+&#39;:&#39;&#39;},regex=True)<br># df[&#39;f0612&#39;].fillna(df[&#39;f0612&#39;].mean())<br>df[[&#39;first_name&#39;,&#39;last_name&#39;]] = df[&#39;name&#39;].str.split(expand=True)<br>df.drop(&#39;name&#39;,axis=1,inplace=True)<br># df.drop(columns=[&#39;name&#39;],inplace=True)<br>df.drop_duplicates([&#39;first_name&#39;,&#39;last_name&#39;],inplace=True)<br>df.drop(index=[8],inplace=True)<br>columns = list(df)<br>columns.insert(0,columns.pop(columns.index(&#39;last_name&#39;)))<br>columns.insert(0,columns.pop(columns.index(&#39;first_name&#39;)))<br>df = df.ix[:,columns]<br>#f0612用平均数填充空值<br>f0612_rows = df[&#39;f0612&#39;].str.isalnum().fillna(True)<br>f0612_mean = df[f0612_rows][&#39;f0612&#39;].mean()<br>df[&#39;f0612&#39;].fillna(f0612_mean,inplace=True)<br>df.replace(&#39;-&#39;,&#39;&#39;,inplace=True)<br>df.reindex(range(df.shape[0]),method = &#39;bfill&#39;)<br>print (df)<br><br>df.to_excel(&#39;.\\\\new_Message.xlsx&#39;)<br>","like_count":0},{"had_liked":false,"id":152066,"user_name":"Ling","can_delete":false,"product_type":"c1","uid":1022786,"ip_address":"","ucode":"EE15D1ABDB073B","user_header":"https://static001.geekbang.org/account/avatar/00/0f/9b/42/aeb79b35.jpg","comment_is_top":false,"comment_ctime":1573868581,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1573868581","product_id":100021701,"comment_content":"# jupyter notebook <br># python 3<br><br>import pandas as pd<br><br>columns = [&quot;food&quot;,&quot;ounces&quot;,&quot;animal&quot;]<br><br>value = {&quot;food&quot;:[&quot;bacon&quot;,&quot;pulled pork&quot;,&quot;bacon&quot;,&quot;Pastrami&quot;,&quot;corned beef&quot;,&quot;Bacon&quot;,&quot;pastrami&quot;,&quot;honey ham&quot;,&quot;nova lox&quot;],<br>        &quot;ounces&quot;:[4.0,3.0,None,6.0,7.5,8.0,-3.0,5.0,6.0],<br>        &quot;animal&quot;:[&quot;pig&quot;,&quot;pig&quot;,&quot;pig&quot;,&quot;cow&quot;,&quot;cow&quot;,&quot;pig&quot;,&quot;cow&quot;,&quot;pig&quot;,&quot;salmon&quot;]}<br><br>df = pd.DataFrame(value,columns=columns)<br><br># 删除负值<br>df = df[df[&quot;ounces&quot;] &gt; 0]<br><br># 使用均值填充空值<br>df.fillna(df.ounces.mean())<br><br># food 列进行大小写转化<br>df.food = df.food.str.title()<br><br># 一致化<br>df = pd.DataFrame(df.groupby(by=[&quot;food&quot;,&quot;animal&quot;])[&quot;ounces&quot;].sum())","like_count":0},{"had_liked":false,"id":133878,"user_name":"卢嘉敏","can_delete":false,"product_type":"c1","uid":1293670,"ip_address":"","ucode":"64E17B0637EB86","user_header":"https://static001.geekbang.org/account/avatar/00/13/bd/66/bf0cfd22.jpg","comment_is_top":false,"comment_ctime":1568689721,"is_pvip":false,"replies":[{"id":"53361","content":"文字相对数值就比较困难了，除非是离散变量，比如“男”“女”这种的，当离散变量的可选项比较少的情况下，可以按照高频值的方式进行补全，当然你也可以根据那条数据自身的情况，选择适合的补全方式","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1570428121,"ip_address":"","comment_id":133878,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1568689721","product_id":100021701,"comment_content":"文字的缺失该如何实现数据清洗","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":467542,"discussion_content":"文字相对数值就比较困难了，除非是离散变量，比如“男”“女”这种的，当离散变量的可选项比较少的情况下，可以按照高频值的方式进行补全，当然你也可以根据那条数据自身的情况，选择适合的补全方式","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570428121,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":126229,"user_name":"杨陆伟","can_delete":false,"product_type":"c1","uid":1108457,"ip_address":"","ucode":"3BC968447406EB","user_header":"https://static001.geekbang.org/account/avatar/00/10/e9/e9/1f95e422.jpg","comment_is_top":false,"comment_ctime":1566351551,"is_pvip":true,"replies":[{"id":"53412","content":"赞 不过数据清洗通常是个反复的过程，也就是清洗了一部分数据之后重新检查，然后再找到新的问题继续清洗，所以数据量大的时候，就像找Bug一样，花费的时间也很多","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1570435043,"ip_address":"","comment_id":126229,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1566351551","product_id":100021701,"comment_content":"微服务架构提供数据的微服务中也可以吸纳数据清洗的思想","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":463895,"discussion_content":"赞 不过数据清洗通常是个反复的过程，也就是清洗了一部分数据之后重新检查，然后再找到新的问题继续清洗，所以数据量大的时候，就像找Bug一样，花费的时间也很多","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570435043,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":124710,"user_name":"杨宝强","can_delete":false,"product_type":"c1","uid":1189290,"ip_address":"","ucode":"B2352D7EA24F31","user_header":"https://static001.geekbang.org/account/avatar/00/12/25/aa/ced0170d.jpg","comment_is_top":false,"comment_ctime":1565949170,"is_pvip":false,"replies":[{"id":"63519","content":"Good Job","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577516450,"ip_address":"","comment_id":124710,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1565949170","product_id":100021701,"comment_content":"data = {<br>        &quot;ID&quot;: [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, None, 9.0,  10.0],<br>        &quot;name&quot;: [&#39;Mickey Mouse&#39;, &#39;Donald Dunck&#39;, &#39;Mini Mouse&#39;, &#39;Scrooge McDuck&#39;, &#39;Pink Panther&#39;, &#39;Huey  McDuck&#39;, &#39;Dewey McDuck&#39;, &#39;Scoopy Doo&#39;, None, &#39;Huey  McDuck&#39;, &#39;Louie McDuck&#39;],<br>        &quot;age&quot;: [56.0, 34.0, 16.0, None, 54.0, 52.0, 19.0, 32.0, None, 52.0, 12.0],<br>        &quot;weight&quot;: [&#39;70kgs&#39;, &#39;154.89lbs&#39;, None, &#39;78kgs&#39;, &#39;198.658lbs&#39;, &#39;189lbs&#39;, &#39;56kgs&#39;, &#39;78kgs&#39;, None, &#39;189lbs&#39;, &#39;45kgs&#39;],<br>        &quot;m0006&quot;: [72.0, None, None, 78, None, None, None, 78.0, None, None, None],<br>        &quot;m0612&quot;: [69, None, None, 79, None, None, None, 76, None, None, None],<br>        &quot;m1218&quot;: [71.0, None, None, 72, None, None, None, 75.0, None, None, None],<br>        &quot;f0006&quot;: [None, 85, 65, None, 69, 68, 71, None, None, 68, 92],<br>        &quot;f0612&quot;: [None, 84, 69, None, None, 75, 78, None, None, 75, 95],<br>        &quot;f1218&quot;: [None, 76, 72, None, 75, 72, 75, None, None, 72, 87]<br>}","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":463290,"discussion_content":"Good Job","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577516450,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1308516,"avatar":"https://static001.geekbang.org/account/avatar/00/13/f7/64/03d8154f.jpg","nickname":"可乐泡枸杞","note":"","ucode":"C709B781DF0456","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":8318,"discussion_content":"好人呐， 我读了前面几楼github里的数据后 一直无法重命名。。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567915685,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":122338,"user_name":"噼里啪啦啪啦噼里噼里啪啦","can_delete":false,"product_type":"c1","uid":1109143,"ip_address":"","ucode":"2A4B86D38F7E11","user_header":"https://static001.geekbang.org/account/avatar/00/10/ec/97/58e7bc9a.jpg","comment_is_top":false,"comment_ctime":1565343102,"is_pvip":false,"replies":[{"id":"63561","content":"Good Job","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577518227,"ip_address":"","comment_id":122338,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1565343102","product_id":100021701,"comment_content":"#coding = utf-8<br><br>&#39;&#39;&#39;<br>下面是对肉类数据进行清洗的练习<br><br>我们看到数据，有以下需要关注的：<br>1. 食物名称中首字母有大写有小写<br>2. 有很多重复数据，需要合并<br>&#39;&#39;&#39;<br><br>import pandas<br>import pandas as pd <br>from pandas import Series, DataFrame<br><br>df = DataFrame(pd.read_excel(r&#39;F:\\Work\\open_courses\\Data_Analysis_by_python\\clean_data\\foodInformation.xlsx&#39;))<br><br>print(df)<br>print(&#39;---------------------------------------------&#39;)<br><br><br>&#39;&#39;&#39;<br>首先将食物名称调整成统一的大小写<br>&#39;&#39;&#39;<br>df[&#39;food&#39;] = df[&#39;food&#39;].str.capitalize()<br>print(df)<br>print(&#39;---------------------------------------------&#39;)<br>&#39;&#39;&#39;<br>找到相同的项，对数据进行合并<br>1. 首先针对food对df进行分组，并进行数据合并<br>2. 对分组后的数据进行重新DataFrame转换，形成新的DataFrame<br>3. 对原来的dataframe进行处理，去重+去除没有意义的列<br>4. 两个dataframe合并<br>&#39;&#39;&#39;<br>#对数据进行分组<br>groupbyObj = df.groupby(df[&#39;food&#39;]).sum()<br>print(groupbyObj)<br>print(&#39;---------------------------------------------&#39;)<br>#对分组后的数据进行DataFrame化<br>new_df = groupbyObj.reset_index()<br>print(new_df)<br>print(&#39;---------------------------------------------&#39;)<br>#将原有的数据表进行去重,并删除ounces列<br>df.drop_duplicates([&#39;food&#39;], inplace=True)<br>df = df.reindex(range(df.shape[0]), method = &#39;bfill&#39;)<br>df.drop(columns = [&#39;ounces&#39;], inplace = True)<br>print(df)<br>print(&#39;---------------------------------------------&#39;)<br>#两个DataFrame合并<br>result = pd.merge(df, new_df, on = &#39;food&#39;)<br>print(result)<br><br>#打印<br>#result.to_csv(r&#39;F:\\Work\\open_courses\\Data_Analysis_by_python\\clean_data\\foodInformation_new.csv&#39;)","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":462212,"discussion_content":"Good Job","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577518227,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":122011,"user_name":"别离","can_delete":false,"product_type":"c1","uid":1207234,"ip_address":"","ucode":"6584C14756B8B0","user_header":"https://static001.geekbang.org/account/avatar/00/12/6b/c2/c61137eb.jpg","comment_is_top":false,"comment_ctime":1565268172,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1565268172","product_id":100021701,"comment_content":"         food  ounces  animal<br>0        bacon     4.0     pig<br>1  pulled pork     3.0     pig<br>2        bacon     NaN     pig<br>3     Pastrami     6.0     cow<br>4  corned beef     7.5     cow<br>5        Bacon     8.0     pig<br>6     pastrami    -3.0     cow<br>7    honey ham     5.0     pig<br>8     nova lox     6.0  salmon","like_count":0},{"had_liked":false,"id":119462,"user_name":"王张","can_delete":false,"product_type":"c1","uid":1526391,"ip_address":"","ucode":"8153B5532B2C62","user_header":"https://static001.geekbang.org/account/avatar/00/17/4a/77/754a127b.jpg","comment_is_top":false,"comment_ctime":1564595211,"is_pvip":false,"replies":[{"id":"63601","content":"多谢分享","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577520588,"ip_address":"","comment_id":119462,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1564595211","product_id":100021701,"comment_content":"#_*_ coding:utf-8 _*_<br>import pandas as pd<br>data = {&#39;ounces&#39;:[4.0,3.0,None,6.0,7.5,8.0,-3.0,5.0,6.0],&#39;animal&#39;:[&#39;pig&#39;,&#39;pig&#39;,&#39;pig&#39;,&#39;cow&#39;,&#39;cow&#39;,&#39;pig&#39;,&#39;cow&#39;,&#39;pig&#39;,&#39;salmon&#39;]}<br>df=pd.DataFrame(data,index=[&#39;bacon&#39;,&#39;pulled pork&#39;,&#39;bacon&#39;,&#39;Pastrami&#39;,&#39;corned beef&#39;,&#39;bacon&#39;,&#39;Pastrami&#39;,&#39;honey ham&#39;,&#39;nova lox&#39;],columns=[&#39;ounces&#39;,&#39;animal&#39;])<br>print(df)<br>df.to_excel(&#39;data1.xlsx&#39;)<br>------------------------<br>你们要的数据","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":460913,"discussion_content":"多谢分享","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577520588,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":118924,"user_name":"建强","can_delete":false,"product_type":"c1","uid":1397126,"ip_address":"","ucode":"62B03D0E0C64EC","user_header":"https://static001.geekbang.org/account/avatar/00/15/51/86/b5fd8dd8.jpg","comment_is_top":false,"comment_ctime":1564470177,"is_pvip":false,"replies":[{"id":"63610","content":"Good Job","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577521036,"ip_address":"","comment_id":118924,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1564470177","product_id":100021701,"comment_content":"1.&quot;food&quot;列数据大小写不统一，清洗方法：统一转换成小写。<br>2.&quot;ounces&quot;列数据有缺失值，用平均值填充。<br>3.&quot;ounces&quot;列有一行数据是-3，不合理数据，转换为正数。<br>4.&quot;food&quot;列中，值=&quot;bacon&quot;、&quot;pastrami&quot;的行有重复，可考虑把这些重复行进行合并处理。<br><br>以上是我能发现的几点问题，请老师指正。","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":460665,"discussion_content":"Good Job","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577521036,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":111600,"user_name":"xqs42b","can_delete":false,"product_type":"c1","uid":1590102,"ip_address":"","ucode":"E1B85D10E44672","user_header":"https://static001.geekbang.org/account/avatar/00/18/43/56/3572a20c.jpg","comment_is_top":false,"comment_ctime":1562571147,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1562571147","product_id":100021701,"comment_content":"老师，有答案吗？？我想知道我的想法有没有啥问题！","like_count":0},{"had_liked":false,"id":104481,"user_name":"TONY","can_delete":false,"product_type":"c1","uid":1068130,"ip_address":"","ucode":"632E2309166536","user_header":"","comment_is_top":false,"comment_ctime":1560763515,"is_pvip":false,"replies":[{"id":"64092","content":"Good Job","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577609159,"ip_address":"","comment_id":104481,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1560763515","product_id":100021701,"comment_content":"import pandas as pd<br>import numpy as np<br>df = pd.read_csv(&quot;.&#47;foods.csv&quot;)<br>df.columns = df.columns.str.strip() #去掉列名空格，否则影响后续对列的操作；<br>df[&#39;food&#39;] = df[&#39;food&#39;].str.strip() #去掉food列名称空格，否则影响对名称的操作；<br>df[&#39;food&#39;] = df[&#39;food&#39;].str.capitalize() # 对food名称首字母大写<br>df[&#39;ounces&#39;] = df[&#39;ounces&#39;].apply(lambda a: abs(a)) #对ounces列负值取绝对值<br>df.fillna(df.mean(),inplace = True) #在取绝对值后用列平均值填充NaN值<br>df<br>df.drop_duplicates(&#39;food&#39;,inplace = True)  #删除food列重复数据<br>df<br>df.to_csv(&#39;.&#47;foods.csv&#39;)  #将结果写回csv<br>print(df)","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454288,"discussion_content":"Good Job","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577609159,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":98816,"user_name":"Kyle","can_delete":false,"product_type":"c1","uid":1258042,"ip_address":"","ucode":"96DE706AAC9D97","user_header":"https://static001.geekbang.org/account/avatar/00/13/32/3a/2d8a2c67.jpg","comment_is_top":false,"comment_ctime":1559099722,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1559099722","product_id":100021701,"comment_content":"根据完全合一的法则来说，那么完整性：ounces列出现了缺失值，全面性：name列名称命名大小写不统一，合法性：ounces列出现了负值，唯一性：食物行出现了重复的值，不知道以哪行为主。","like_count":0},{"had_liked":false,"id":92455,"user_name":"忘矢","can_delete":false,"product_type":"c1","uid":1513551,"ip_address":"","ucode":"FAFD133BC2F6E4","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLVjETMtKViaoBEibZH2nS7jb4521k2ZsJHtkYnq4mglU8Jju6GiczexAZWpbXtQVico2c12JPSPaWpbA/132","comment_is_top":false,"comment_ctime":1557277107,"is_pvip":false,"replies":[{"id":"64196","content":"也可以，有4600万条数据量，你也可以采用Python来处理，就需要用一些方法了，比如分chunk（块）读取，然后操作","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577614056,"ip_address":"","comment_id":92455,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1557277107","product_id":100021701,"comment_content":"请问老师，上亿条记录的数据量也适合用Python来作清洗吗？","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":449267,"discussion_content":"也可以，有4600万条数据量，你也可以采用Python来处理，就需要用一些方法了，比如分chunk（块）读取，然后操作","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577614056,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":90242,"user_name":"冯德章","can_delete":false,"product_type":"c1","uid":1184025,"ip_address":"","ucode":"EF2343BE787C82","user_header":"https://static001.geekbang.org/account/avatar/00/12/11/19/6e0c5c9e.jpg","comment_is_top":false,"comment_ctime":1556457716,"is_pvip":false,"replies":[{"id":"64209","content":"总结不错","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577614249,"ip_address":"","comment_id":90242,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1556457716","product_id":100021701,"comment_content":"1.数据清洗是数据分析的基础，数据准确性决定结果准确性。<br><br>2.数据清洗占数据挖掘工作量80，<br><br>3.数据清洗，完全合一原则。<br>完整性，确保没有空值。<br>全面性，确认单位，数据质量<br>合法性，数据是否遵从自然规律。<br>唯一性，去除重复数据。<br>4.数据结果检核习惯。","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":448437,"discussion_content":"总结不错","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577614249,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":89498,"user_name":"翟小童","can_delete":false,"product_type":"c1","uid":1466144,"ip_address":"","ucode":"F0A6814C6E75D9","user_header":"https://static001.geekbang.org/account/avatar/00/16/5f/20/fa838240.jpg","comment_is_top":false,"comment_ctime":1556185893,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1556185893","product_id":100021701,"comment_content":"path = r&quot;d:&#47;exam.txt&quot;<br>df = pd.read_csv(path, sep=&#39;\\t&#39;)<br>df[&#39;food&#39;] = df[&#39;food&#39;].str.lower()  # food列转换为小写<br>print(df[&#39;ounces&#39;].isnull().value_counts())#统计空得数量<br>df = df.dropna()  # 删除空行<br>df.loc[df[df[&#39;ounces&#39;] &lt; 0].index, &#39;ounces&#39;] = df[df[&#39;food&#39;].isin([&#39;pastrami&#39;])][&#39;ounces&#39;].mean()  # 取平均值赋值给异常值<br># print(df)<br>df.groupby(&#39;food&#39;).mean()  # 计算每种食物的平均值<br>df.drop_duplicates([&#39;food&#39;, &#39;animal&#39;], inplace=True)# 删除重复数据行<br>df.index = range(len(df))","like_count":0},{"had_liked":false,"id":85661,"user_name":"青石","can_delete":false,"product_type":"c1","uid":1215531,"ip_address":"","ucode":"B0056AD6453322","user_header":"https://static001.geekbang.org/account/avatar/00/12/8c/2b/3ab96998.jpg","comment_is_top":false,"comment_ctime":1555165683,"is_pvip":false,"replies":[{"id":"64264","content":"Good Job","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577615664,"ip_address":"","comment_id":85661,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1555165683","product_id":100021701,"comment_content":"#!usr&#47;bin&#47;python3<br># -*- coding:utf-8 -*-<br><br>import os<br>import numpy as np<br>import pandas as pd<br><br><br>path = &#39;&#47;Users&#47;albert.ming.xu&#47;Downloads&#47;11.data.xlsx&#39;<br>new_path = os.path.splitext(path)[0] + &#39;_new&#39; + os.path.splitext(path)[1]<br>data_type = {&#39;food&#39;: np.str, &#39;ounces&#39;: np.float, &#39;animal&#39;: np.str}<br><br>df = pd.read_excel(path, sheet_name=0, header=0, dtype=data_type)<br><br># 统一food名称为小写字母<br>df[&#39;food&#39;] = df[&#39;food&#39;].str.lower()<br># 单位取绝对值<br>df[&#39;ounces&#39;] = df[&#39;ounces&#39;].abs()<br># 将ounces列的空行填充为平均值<br>df[&#39;ounces&#39;].fillna(df[&#39;ounces&#39;].mean(), inplace=True)<br># 删除任意字段包含空值的数据<br>df.dropna(how=&#39;any&#39;, axis=0, inplace=True)<br># 删除food字段出现重复的行，但bacon最后会存在三行数据，ounces分别是4.0、5.31、8.0，最后保留哪个数据更好是个问题<br>df.drop_duplicates(&#39;food&#39;, inplace=True)<br><br>df.to_excel(new_path, float_format=&quot;%.2f&quot;)<br>","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":446756,"discussion_content":"Good Job","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577615664,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":85072,"user_name":"滢","can_delete":false,"product_type":"c1","uid":1221511,"ip_address":"","ucode":"971A6F20AF3F9A","user_header":"https://static001.geekbang.org/account/avatar/00/12/a3/87/c415e370.jpg","comment_is_top":false,"comment_ctime":1554971253,"is_pvip":false,"replies":[{"id":"64270","content":"Good Job","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577615774,"ip_address":"","comment_id":85072,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1554971253","product_id":100021701,"comment_content":"录入的原始数据链接：<br>关于练习：首先把这份数据当做食材消耗，单位为盎司（当然对业务的理解有多种）。 （1）对于这份数据NaN值应该删除，不能进行补全；（2）如果是食材消耗，负数的存在也是合理的，不用对齐求绝对值（3）重复的原始数据不能删除，应该是汇总后再进行删除，以下是代码，Python3.6 IDLE <br>&gt;&gt;&gt; import pandas as pd<br>&gt;&gt;&gt; from pandas import Series,DataFrame<br>&gt;&gt;&gt; df = DataFrame(pd.read_excel(&#39;&#47;Users&#47;apple&#47;Desktop&#47;GitHubProject&#47;Read mark&#47;数据分析&#47;geekTime&#47;data&#47;foodInformation.xlsx&#39;))<br>&gt;&gt;&gt; print (df)<br>          food  ounces  animal<br>0        bacon     4.0     pig<br>1  pulled port     3.0     pig<br>2        bacon     NaN     pig<br>3     Pastrami     6.0     cow<br>4  corned beef     7.5     cow<br>5        Bacon     8.0     pig<br>6     pastrami    -3.0     cow<br>7    honey ham     5.0     pig<br>8     nova lox     6.0  salmon<br>#删除空值<br>&gt;&gt;&gt; df.dropna(inplace=True)<br>#food一栏全部换成小写<br>&gt;&gt;&gt; df[&#39;food&#39;]=df[&#39;food&#39;].str.lower()<br> #查找food重复记录，分组求其总和<br>&gt;&gt;&gt; food_rows = df[df[&#39;food&#39;].duplicated(keep=False)]<br>&gt;&gt;&gt; food_items=food_rows.groupby(&#39;food&#39;).sum()<br>&gt;&gt;&gt; food_items[&#39;food&#39;]=food_items.index<br>#数据赋值替换<br>&gt;&gt;&gt; for i,row in food_items.iterrows():<br>\tdf.loc[df[&#39;food&#39;]==row[&#39;food&#39;],&#39;ounces&#39;]=row[&#39;ounces&#39;]<br>#删除重复<br>&gt;&gt;&gt; df.drop_duplicates(inplace=True)<br>#重新生成索引<br>&gt;&gt;&gt; df.index=range(df.shape[0])<br>&gt;&gt;&gt; print (df)<br>          food  ounces  animal<br>0        bacon    12.0     pig<br>1  pulled port     3.0     pig<br>2     pastrami     3.0     cow<br>3  corned beef     7.5     cow<br>4    honey ham     5.0     pig<br>5     nova lox     6.0  salmon<br>","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":446547,"discussion_content":"Good Job","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577615774,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":84023,"user_name":"FeiFei","can_delete":false,"product_type":"c1","uid":1045586,"ip_address":"","ucode":"01CD655DD4E56C","user_header":"https://static001.geekbang.org/account/avatar/00/0f/f4/52/10c4d863.jpg","comment_is_top":false,"comment_ctime":1554770580,"is_pvip":false,"replies":[{"id":"64288","content":"哈哈哈 很好的分享","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577616120,"ip_address":"","comment_id":84023,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1554770580","product_id":100021701,"comment_content":"80％时间需要在数据清洗上。<br>担心公司不能给予那么多时间来做这件事。","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":446220,"discussion_content":"哈哈哈 很好的分享","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577616120,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":78367,"user_name":"『G YaQi』","can_delete":false,"product_type":"c1","uid":1461694,"ip_address":"","ucode":"D378F0C8D0EFD0","user_header":"https://static001.geekbang.org/account/avatar/00/16/4d/be/c04c9eac.jpg","comment_is_top":false,"comment_ctime":1553133810,"is_pvip":false,"replies":[{"id":"64389","content":"Good Job","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577618204,"ip_address":"","comment_id":78367,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1553133810","product_id":100021701,"comment_content":"import pandas as pd<br>from pandas import Series, DataFrame<br><br># 读入数据<br>data = DataFrame(pd.read_excel(&#39;C:\\\\Users\\\\Administrator\\\\Desktop\\\\food.xlsx&#39;))<br><br># 删除异常值所在行<br>rst = data[data[&#39;ounces&#39;] &lt; 0].index.tolist()<br>data.drop(index=rst, inplace=True)<br><br># 食物名字小写<br>data[&#39;food&#39;] = data[&#39;food&#39;].str.lower()<br><br># 以均值填充空值<br>data[&#39;ounces&#39;].fillna(int(data[&#39;ounces&#39;].mean()), inplace=True)<br><br># 重置索引<br>data = data.reset_index(drop=True)<br><br>print(data)","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":444067,"discussion_content":"Good Job","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577618204,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":71434,"user_name":"王","can_delete":false,"product_type":"c1","uid":1084336,"ip_address":"","ucode":"44A968CB371704","user_header":"https://static001.geekbang.org/account/avatar/00/10/8b/b0/38aadfa0.jpg","comment_is_top":false,"comment_ctime":1551342311,"is_pvip":false,"replies":[{"id":"64490","content":"一个含义","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577620009,"ip_address":"","comment_id":71434,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1551342311","product_id":100021701,"comment_content":"第三个规则，合值得是合理性还是合法性呢？","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":441146,"discussion_content":"一个含义","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577620009,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":64508,"user_name":"方人其","can_delete":false,"product_type":"c1","uid":1197200,"ip_address":"","ucode":"CF44EBC59493E1","user_header":"https://static001.geekbang.org/account/avatar/00/12/44/90/33ec20bf.jpg","comment_is_top":false,"comment_ctime":1548813595,"is_pvip":false,"replies":[{"id":"64627","content":"千万级别是可以的，前提是你可以采用分块的方式来操作，chunksize","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577622649,"ip_address":"","comment_id":64508,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1548813595","product_id":100021701,"comment_content":"pandas适合多大的数据量清洗？十万级别？百万级别?千万级别？亿级别？？","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438036,"discussion_content":"千万级别是可以的，前提是你可以采用分块的方式来操作，chunksize","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577622649,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":62623,"user_name":"圆圆的大食客","can_delete":false,"product_type":"c1","uid":1361827,"ip_address":"","ucode":"B5B87E08869507","user_header":"https://static001.geekbang.org/account/avatar/00/14/c7/a3/1e2f9f5a.jpg","comment_is_top":false,"comment_ctime":1548121648,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1548121648","product_id":100021701,"comment_content":"import pandas as pd<br>df = pd.read_csv(&quot;D:\\\\Learning\\\\Data 45 Lessons\\practice11.csv&quot;)<br><br># fill NaN as average<br>df[&#39;ounces&#39;].fillna(df[&#39;ounces&#39;].mean(), inplace = True)<br><br>#Delete blank line<br>df.dropna(how = &quot;all&quot;, inplace = True)<br><br>#Capitalize food name<br>df[&#39;food&#39;]=df[&#39;food&#39;].str.capitalize()<br><br>#Change negative value to positive value<br>df[&#39;ounces&#39;]= df[&#39;ounces&#39;].apply(lambda x: abs(x))<br><br>#Delete duplicates<br>df.drop_duplicates([&#39;food&#39;], inplace=True)<br><br>print (df)","like_count":0},{"had_liked":false,"id":61870,"user_name":"李沛欣","can_delete":false,"product_type":"c1","uid":1362695,"ip_address":"","ucode":"98874954230D95","user_header":"https://static001.geekbang.org/account/avatar/00/14/cb/07/e34220d6.jpg","comment_is_top":false,"comment_ctime":1547824257,"is_pvip":false,"replies":[{"id":"64694","content":"加油~！","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577624346,"ip_address":"","comment_id":61870,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1547824257","product_id":100021701,"comment_content":"完整性，全面性，合理性，一致性。<br><br>现实世界的数据是肮脏的，需要我们把它们清洗干净。<br><br>除了简单的处理外，还可以用pandas。<br><br>周末可以键盘敲起来了。","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":437023,"discussion_content":"加油~！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577624346,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":61458,"user_name":"LI.T.F","can_delete":false,"product_type":"c1","uid":1357691,"ip_address":"","ucode":"DDC0AB13CA605F","user_header":"https://static001.geekbang.org/account/avatar/00/14/b7/7b/0893dbd9.jpg","comment_is_top":false,"comment_ctime":1547702227,"is_pvip":false,"replies":[{"id":"64710","content":"Good Job~","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577624564,"ip_address":"","comment_id":61458,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1547702227","product_id":100021701,"comment_content":"只发现了三点错误：<br>1.食物名称有的首字母大写，有的没有大写<br>2.盅司这一列中有NAN<br>3.盅司列有负数<br><br>数据清理：<br>1.食物列首字母大写<br>2.盅司列用平均数代替NAN<br>3.盅司列的负数变成正数","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":436876,"discussion_content":"Good Job~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577624564,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":60972,"user_name":"Neo","can_delete":false,"product_type":"c1","uid":1090494,"ip_address":"","ucode":"44B46DEA4EC71F","user_header":"https://static001.geekbang.org/account/avatar/00/10/a3/be/31086596.jpg","comment_is_top":false,"comment_ctime":1547599919,"is_pvip":false,"replies":[{"id":"64730","content":"Python也可以处理大量的数据，选择Python是因为用的人多，而且工具包完善，走前人走的路，不需要重复造轮子","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577624840,"ip_address":"","comment_id":60972,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1547599919","product_id":100021701,"comment_content":"使用py做数据清洗，数据量大小有限制吗？tb级也是全部加载到内存中处理？还是使用大数据技术？选择使用py是因为他有数据处理的库，并且是方便处理少量数据的工具，是吗？","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":436689,"discussion_content":"Python也可以处理大量的数据，选择Python是因为用的人多，而且工具包完善，走前人走的路，不需要重复造轮子","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577624840,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":60595,"user_name":"lee4","can_delete":false,"product_type":"c1","uid":1021495,"ip_address":"","ucode":"36F82406C58075","user_header":"https://static001.geekbang.org/account/avatar/00/0f/96/37/abb7bfe3.jpg","comment_is_top":false,"comment_ctime":1547517423,"is_pvip":false,"replies":[{"id":"64737","content":"Good Job","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577624921,"ip_address":"","comment_id":60595,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1547517423","product_id":100021701,"comment_content":"重点还要看数据使用的场景和目的。<br>根据现有信息，有可能采取以下行动：<br><br>1. 将food一列内容写法统一，例如大小写<br>2. food一列不宜去重，可能需要另行建立index<br>3. ounces一列将Nan去除，或填充为0 并另行建立indicator标识数据缺失<br>4. ounces一列将负值去除，或取绝对值<br>5. animal一列可以考虑将分类转换为数值型indicator","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":436555,"discussion_content":"Good Job","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577624921,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":58200,"user_name":"夏落若","can_delete":false,"product_type":"c1","uid":1129160,"ip_address":"","ucode":"FAF9968E9B52CE","user_header":"https://static001.geekbang.org/account/avatar/00/11/3a/c8/b85eeb42.jpg","comment_is_top":false,"comment_ctime":1547009660,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1547009660","product_id":100021701,"comment_content":"用 scrapy 爬取了安居客武汉租房的数据2950条，有需要的去下载：https:&#47;&#47;download.csdn.net&#47;download&#47;weidan0302&#47;10905156，如果需要代码，可以联系我","like_count":0},{"had_liked":false,"id":57838,"user_name":"讲究人","can_delete":false,"product_type":"c1","uid":1352482,"ip_address":"","ucode":"52C0F496A65350","user_header":"https://wx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKGVWwZB0EwdiajI80w0pIkMRCZGUoAweqG9gVE5hkqkTkZfjTSia7Y9CpAcGMrKTo3UAbHktsFrhYQ/132","comment_is_top":false,"comment_ctime":1546923688,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1546923688","product_id":100021701,"comment_content":"老师，讲义中的数据有提供下载地址吗？","like_count":0},{"had_liked":false,"id":57712,"user_name":"wolf|▍奇葩","can_delete":false,"product_type":"c1","uid":1283222,"ip_address":"","ucode":"04B1BB06CF446E","user_header":"https://static001.geekbang.org/account/avatar/00/13/94/96/520185f0.jpg","comment_is_top":false,"comment_ctime":1546873766,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1546873766","product_id":100021701,"comment_content":"客观说在极客买了好几个课程这个课程帮助最大，很好的帮我梳理了思路，能再快点看到新课就好了，陈老师加油~~","like_count":0},{"had_liked":false,"id":57657,"user_name":"JingZ","can_delete":false,"product_type":"c1","uid":1023464,"ip_address":"","ucode":"6F97895B2CC375","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/wJphZ3HcvhjVUyTWCIsCugzfQY5NAy6VJ0XoPLibDlcHWMswFmFe678zd0lUjFETia80NQhyQcVnGDlKgKPcRGyw/132","comment_is_top":false,"comment_ctime":1546862766,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1546862766","product_id":100021701,"comment_content":"#2019&#47;1&#47;7 Pandas数据清理<br><br>假设场景是食品采购环境，根据“完全合一”原则，问题和清洗如下（代码实践）：<br><br>1、ounces缺失值 -&gt; NaN用“0”替换<br>2、ounces不合理值 -&gt; -3用“3”替换（考虑可能输入者的输入错误，采购多点比少点好，当然成本这儿分析时稍忽略下）<br>3、food列数据大小写 -&gt;统一首字母为大写（感觉不需要像人名字那种分开两列）<br>4、animal列感觉需要将同类放一起进行排序 -&gt;cow&#47;pig&#47;salmon的英语字母顺序","like_count":0},{"had_liked":false,"id":57595,"user_name":"梁林松","can_delete":false,"product_type":"c1","uid":1144766,"ip_address":"","ucode":"FA032C3B4E245E","user_header":"https://static001.geekbang.org/account/avatar/00/11/77/be/1f2409e8.jpg","comment_is_top":false,"comment_ctime":1546844738,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1546844738","product_id":100021701,"comment_content":"1， food 可以改为 food name<br>2,倒数第3行-3.0和正数第3行NAN需要去除。<br>3，统一大小写。<br>4，合并同类项（正数 1 ，3， 6行）（正数 4，7 行）。<br>5，把 ounce 和 animal 左右对调，让单位在最右端。<br><br>","like_count":0},{"had_liked":false,"id":57566,"user_name":"auroroa","can_delete":false,"product_type":"c1","uid":1057164,"ip_address":"","ucode":"0FF44C9A40E8CD","user_header":"https://static001.geekbang.org/account/avatar/00/10/21/8c/f7a24bc5.jpg","comment_is_top":false,"comment_ctime":1546838724,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1546838724","product_id":100021701,"comment_content":"1、完整性问题，含有了 NA 值，因为有重复记录，根据数据来源描述可判断取同名称记录下的其他行该列不为空的数值<br>2、全面性问题，food 列首字母大小写不一致，可统一为小写<br>3、合理性问题，含有 onuces 为负值的记录，因为已有该名称食物数据，可剔除该行<br>4、唯一性问题，统一名称大小写后有同名食物，合并记录在满足数据合理性完整性条件下分别对各列取最优值<br>当然数据量少和数据量大的时候处理方式可能不一样","like_count":0},{"had_liked":false,"id":57556,"user_name":"浩然","can_delete":false,"product_type":"c1","uid":1295043,"ip_address":"","ucode":"D1FB4E3E7ADE5F","user_header":"https://static001.geekbang.org/account/avatar/00/13/c2/c3/da31c9c2.jpg","comment_is_top":false,"comment_ctime":1546833328,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1546833328","product_id":100021701,"comment_content":"删掉负值行，pig的空值用pig的平均数填充","like_count":0},{"had_liked":false,"id":57495,"user_name":"梅破知春近","can_delete":false,"product_type":"c1","uid":1189241,"ip_address":"","ucode":"A9FCC5B1ED6E0A","user_header":"https://static001.geekbang.org/account/avatar/00/12/25/79/c7bcdefc.jpg","comment_is_top":false,"comment_ctime":1546822927,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1546822927","product_id":100021701,"comment_content":"首先food列文本都改为小写，.lower()，对food列去重，去重规则为第二列优先保留大于0的数值，优先保留非NA值，去重后检验是否还有NA，填充NA值。","like_count":0},{"had_liked":false,"id":57485,"user_name":"无法言喻.","can_delete":false,"product_type":"c1","uid":1322328,"ip_address":"","ucode":"7F375BE388D4FC","user_header":"https://static001.geekbang.org/account/avatar/00/14/2d/58/aa35c402.jpg","comment_is_top":false,"comment_ctime":1546821718,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1546821718","product_id":100021701,"comment_content":"大小写 重复值 空值 分类数值化 <br>有之前讲解的服装店会员的csv吗？","like_count":0},{"had_liked":false,"id":57475,"user_name":"Python","can_delete":false,"product_type":"c1","uid":1276314,"ip_address":"","ucode":"969500D2A88AE6","user_header":"https://static001.geekbang.org/account/avatar/00/13/79/9a/4f907ad6.jpg","comment_is_top":false,"comment_ctime":1546820550,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1546820550","product_id":100021701,"comment_content":"直接把负三，以及空值那两行删除，因为她们既是food的重复行，也是不合格的数据","like_count":0},{"had_liked":false,"id":57451,"user_name":"許敲敲","can_delete":false,"product_type":"c1","uid":1046681,"ip_address":"","ucode":"6486466820E7BF","user_header":"https://static001.geekbang.org/account/avatar/00/0f/f8/99/8e760987.jpg","comment_is_top":false,"comment_ctime":1546793174,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1546793174","product_id":100021701,"comment_content":"food都小写后 去重，重量都取绝对值，再填充NA值。","like_count":0},{"had_liked":false,"id":57445,"user_name":"蜘蛛的梦呓","can_delete":false,"product_type":"c1","uid":1190207,"ip_address":"","ucode":"42FF5C7FF4D2E1","user_header":"https://static001.geekbang.org/account/avatar/00/12/29/3f/ae7718f6.jpg","comment_is_top":false,"comment_ctime":1546792554,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1546792554","product_id":100021701,"comment_content":"首先，统一列名，把列名都改为小写。<br>然后，异常处理，去掉不合常理的数值(负数)，空值删除或用平均数填充。<br>最后，去重，删除重复列。","like_count":0}]}