{"id":373070,"title":"26 | Join Hints指南：不同场景下，如何选择Join策略？","content":"<p>你好，我是吴磊。</p><p>在数据分析领域，数据关联可以说是最常见的计算场景了。因为使用的频率很高，所以Spark为我们准备了非常丰富的关联形式，包括Inner Join、Left Join、Right Join、Anti Join、Semi Join等等。</p><p>搞懂不同关联形式的区别与作用，可以让我们快速地实现业务逻辑。不过，这只是基础，要想提高数据关联场景下Spark应用的执行性能，更为关键的是我们要能够深入理解Join的实现原理。</p><p>所以今天这一讲，我们先来说说，单机环境中Join都有哪几种实现方式，它们的优劣势分别是什么。理解了这些实现方式，我们再结合它们一起探讨，分布式计算环境中Spark都支持哪些Join策略。对于不同的Join策略，Spark是怎么做取舍的。</p><h2>Join的实现方式详解</h2><p>到目前为止，数据关联总共有3种Join实现方式。按照出现的时间顺序，分别是嵌套循环连接（NLJ，Nested Loop Join ）、排序归并连接（SMJ，Shuffle Sort Merge Join）和哈希连接（HJ，Hash Join）。接下来，我们就借助一个数据关联的场景，来分别说一说这3种Join实现方式的工作原理。</p><p>假设，现在有事实表orders和维度表users。其中，users表存储用户属性信息，orders记录着用户的每一笔交易。两张表的Schema如下：</p><!-- [[[read_end]]] --><pre><code>// 订单表orders关键字段\nuserId, Int\nitemId, Int\nprice, Float\nquantity, Int\n \n// 用户表users关键字段\nid, Int\nname, String\ntype, String //枚举值，分为头部用户和长尾用户\n</code></pre><p>我们的任务是要基于这两张表做内关联（Inner Join），同时把用户名、单价、交易额等字段投影出来。具体的SQL查询语句如下表：</p><pre><code>//SQL查询语句\nselect orders.quantity, orders.price, orders.userId, users.id, users.name\nfrom orders inner join users on orders.userId = users.id\n</code></pre><p>那么，对于这样一个关联查询，在3种不同的Join实现方式下，它是如何完成计算的呢？</p><h3>NLJ的工作原理</h3><p>对于参与关联的两张数据表，我们通常会根据它们扮演的角色来做区分。其中，体量较大、主动扫描数据的表，我们把它称作外表或是驱动表；体量较小、被动参与数据扫描的表，我们管它叫做内表或是基表。那么，NLJ是如何关联这两张数据表的呢？</p><p><strong>NLJ是采用“嵌套循环”的方式来实现关联的。</strong>也就是说，NLJ会使用内、外两个嵌套的for循环依次扫描外表和内表中的数据记录，判断关联条件是否满足，比如例子中的orders.userId = users.id，如果满足就把两边的记录拼接在一起，然后对外输出。</p><p><img src=\"https://static001.geekbang.org/resource/image/be/13/be0774ffca24f9c20caa2ef6bd88d013.jpg?wh=2829*1431\" alt=\"\" title=\"Nested Loop Join示意图\"></p><p>在这个过程中，外层的for循环负责遍历外表中的每一条数据，如图中的步骤1所示。而对于外表中的每一条数据记录，内层的for循环会逐条扫描内表的所有记录，依次判断记录的Join Key是否满足关联条件，如步骤2所示。假设，外表有M行数据，内表有N行数据，那么<strong>NLJ算法的计算复杂度是O(M * N)</strong>。不得不说，尽管NLJ实现方式简单而又直接，但它的执行效率实在让人不敢恭维。</p><h3>SMJ的工作原理</h3><p>正是因为NLJ极低的执行效率，所以在它推出之后没多久之后，就有人用排序、归并的算法代替NLJ实现了数据关联，这种算法就是SMJ。<strong>SMJ的思路是先排序、再归并。</strong>具体来说，就是参与Join的两张表先分别按照Join Key做升序排序。然后，SMJ会使用两个独立的游标对排好序的两张表完成归并关联。</p><p><img src=\"https://static001.geekbang.org/resource/image/e2/b2/e2a8f8d1b2572ff456fa83a3f25ccbb2.jpg?wh=1183*1048\" alt=\"\" title=\"Sort Merge Join示意图\"></p><p>SMJ刚开始工作的时候，内外表的游标都会先锚定在两张表的第一条记录上，然后再对比游标所在记录的Join Key。对比结果以及后续操作主要分为3种情况：</p><ol>\n<li>外表Join Key等于内表Join Key，满足关联条件，把两边的数据记录拼接并输出，然后把外表的游标滑动到下一条记录</li>\n<li>外表Join Key小于内表Join Key，不满足关联条件，把外表的游标滑动到下一条记录</li>\n<li>外表Join Key大于内表Join Key，不满足关联条件，把内表的游标滑动到下一条记录</li>\n</ol><p>SMJ正是基于这3种情况，不停地向下滑动游标，直到某张表的游标滑到头，即宣告关联结束。对于SMJ中外表的每一条记录，由于内表按Join Key升序排序，且扫描的起始位置为游标所在位置，因此<strong>SMJ算法的计算复杂度为O(M + N)</strong>。</p><p>不过，SMJ计算复杂度的降低，仰仗的是两张表已经事先排好序。要知道，排序本身就是一项非常耗时的操作，更何况，为了完成归并关联，参与Join的两张表都需要排序。因此，SMJ的计算过程我们可以用“先苦后甜”来形容。苦的是要先花费时间给两张表做排序，甜的是有序表的归并关联能够享受到线性的计算复杂度。</p><h3>HJ的工作原理</h3><p>考虑到SMJ对排序的要求比较苛刻，所以后来又有人提出了效率更高的关联算法：HJ。HJ的设计初衷非常明确：<strong>把内表扫描的计算复杂度降低至O(1)</strong>。把一个数据集合的访问效率提升至O(1)，也只有Hash Map能做到了。也正因为Join的关联过程引入了Hash计算，所以它叫HJ。</p><p><img src=\"https://static001.geekbang.org/resource/image/5c/e4/5c81d814591eba9d08e6a3174ffe22e4.jpg?wh=3960*1659\" alt=\"\"></p><p>HJ的计算分为两个阶段，分别是Build阶段和Probe阶段。在Build阶段，基于内表，算法使用既定的哈希函数构建哈希表，如上图的步骤1所示。哈希表中的Key是Join Key应用（Apply）哈希函数之后的哈希值，表中的Value同时包含了原始的Join Key和Payload。</p><p>在Probe阶段，算法遍历每一条数据记录，先是使用同样的哈希函数，以动态的方式（On The Fly）计算Join Key的哈希值。然后，用计算得到的哈希值去查询刚刚在Build阶段创建好的哈希表。如果查询失败，说明该条记录与维度表中的数据不存在关联关系；如果查询成功，则继续对比两边的Join Key。如果Join Key一致，就把两边的记录进行拼接并输出，从而完成数据关联。</p><h2>分布式环境下的Join</h2><p>掌握了这3种最主要的数据关联实现方式的工作原理之后，在单机环境中，无论是面对常见的Inner Join、Left Join、Right Join，还是不常露面的Anti Join、Semi Join，你都能对数据关联的性能调优做到游刃有余了。</p><p>不过，你也可能会说：“Spark毕竟是个分布式系统，光学单机实现有什么用呀？”</p><p>所谓万变不离其宗，实际上，<strong>相比单机环境，分布式环境中的数据关联在计算环节依然遵循着NLJ、SMJ和HJ这3种实现方式，只不过是增加了网络分发这一变数</strong>。在Spark的分布式计算环境中，数据在网络中的分发主要有两种方式，分别是Shuffle和广播。那么，不同的网络分发方式，对于数据关联的计算又都有哪些影响呢？</p><p>如果采用Shuffle的分发方式来完成数据关联，那么外表和内表都需要按照Join Key在集群中做全量的数据分发。因为只有这样，两个数据表中Join Key相同的数据记录才能分配到同一个Executor进程，从而完成关联计算，如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/b1/28/b1b2a574eb7ef33e2315f547ecdc0328.jpg?wh=5124*1599\" alt=\"\"></p><p>如果采用广播机制的话，情况会大有不同。在这种情况下，Spark只需要把内表（基表）封装到广播变量，然后在全网进行分发。由于广播变量中包含了内表的<strong>全量数据</strong>，因此体量较大的外表只要“待在原地、保持不动”，就能轻松地完成关联计算，如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/b3/2a/b3c5ab392c2303bf7923488623b4022a.jpg?wh=5094*1695\" alt=\"\"></p><p>不难发现，结合Shuffle、广播这两种网络分发方式和NLJ、SMJ、HJ这3种计算方式，对于分布式环境下的数据关联，我们就能组合出6种Join策略，如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/e9/48/e9bf1720ac13289a9e49e0f33a334548.jpg?wh=1989*1149\" alt=\"\"></p><p>这6种Join策略，对应图中6个青色圆角矩形，从上到下颜色依次变浅，它们分别是Cartesian Product Join、Shuffle Sort Merge Join和Shuffle Hash Join。也就是采用Shuffle机制实现的NLJ、SMJ和HJ，以及Broadcast Nested Loop Join、Broadcast Sort Merge Join和Broadcast Hash Join。</p><p><strong>从执行性能来说，6种策略从上到下由弱变强。</strong>相比之下，CPJ的执行效率是所有实现方式当中最差的，网络开销、计算开销都很大，因而在图中的颜色也是最深的。BHJ是最好的分布式数据关联机制，网络开销和计算开销都是最小的，因而颜色也最浅。此外，你可能也注意到了，Broadcast Sort Merge Join被标记成了灰色，这是因为Spark并没有选择支持Broadcast + Sort Merge Join这种组合方式。</p><p>那么问题来了，明明是6种组合策略，为什么Spark偏偏没有支持这一种呢？要回答这个问题，我们就要回过头来对比SMJ与HJ实现方式的差异与优劣势。</p><p>相比SMJ，HJ并不要求参与Join的两张表有序，也不需要维护两个游标来判断当前的记录位置，只要基表在Build阶段构建的哈希表可以放进内存，HJ算法就可以在Probe阶段遍历外表，依次与哈希表进行关联。</p><p>当数据能以广播的形式在网络中进行分发时，说明被分发的数据，也就是基表的数据足够小，完全可以放到内存中去。这个时候，相比NLJ、SMJ，HJ的执行效率是最高的。因此，在可以采用HJ的情况下，Spark自然就没有必要再去用SMJ这种前置开销比较大的方式去完成数据关联。</p><h2>Spark如何选择Join策略？</h2><p>那么，在不同的数据关联场景中，对于这5种Join策略来说，也就是CPJ、BNLJ、SHJ、SMJ以及BHJ，Spark会基于什么逻辑取舍呢？我们来分两种情况进行讨论，分别是等值Join，和不等值Join。</p><h3>等值Join下，Spark如何选择Join策略？</h3><p>等值Join是指两张表的Join Key是通过等值条件连接在一起的。在日常的开发中，这种Join形式是最常见的，如t1 inner join t2 on <strong>t1.id = t2.id</strong>。</p><p><strong>在等值数据关联中，Spark会尝试按照BHJ &gt; SMJ &gt; SHJ的顺序依次选择Join策略。</strong>在这三种策略中，执行效率最高的是BHJ，其次是SHJ，再次是SMJ。其中，SMJ和SHJ策略支持所有连接类型，如全连接、Anti Join等等。BHJ尽管效率最高，但是有两个前提条件：一是连接类型不能是全连接（Full Outer Join）；二是基表要足够小，可以放到广播变量里面去。</p><p>那为什么SHJ比SMJ执行效率高，排名却不如SMJ靠前呢？这是个非常好的问题。我们先来说结论，相比SHJ，Spark优先选择SMJ的原因在于，SMJ的实现方式更加稳定，更不容易OOM。</p><p>回顾HJ的实现机制，在Build阶段，算法根据内表创建哈希表。在Probe阶段，为了让外表能够成功“探测”（Probe）到每一个Hash Key，哈希表要全部放进内存才行。坦白说，这个前提还是蛮苛刻的，仅这一点要求就足以让Spark对其望而却步。要知道，在不同的计算场景中，数据分布的多样性很难保证内表一定能全部放进内存。</p><p>而且在Spark中，SHJ策略要想被选中必须要满足两个先决条件，这两个条件都是对数据尺寸的要求。<strong>首先，外表大小至少是内表的3倍。其次，内表数据分片的平均大小要小于广播变量阈值。</strong>第一个条件的动机很好理解，只有当内外表的尺寸悬殊到一定程度时，HJ的优势才会比SMJ更显著。第二个限制的目的是，确保内表的每一个数据分片都能全部放进内存。</p><p>和SHJ相比，SMJ没有这么多的附加条件，无论是单表排序，还是两表做归并关联，都可以借助磁盘来完成。内存中放不下的数据，可以临时溢出到磁盘。单表排序的过程，我们可以参考Shuffle Map阶段生成中间文件的过程。在做归并关联的时候，算法可以把磁盘中的有序数据用合理的粒度，依次加载进内存完成计算。这个粒度可大可小，大到以数据分片为单位，小到逐条扫描。</p><p>正是考虑到这些因素，相比SHJ，Spark SQL会优先选择SMJ。事实上，在配置项spark.sql.join.preferSortMergeJoin默认为True的情况下，Spark SQL会用SMJ策略来兜底，确保作业执行的稳定性，压根就不会打算去尝试SHJ。开发者如果想通过配置项来调整Join策略，需要把这个参数改为False，这样Spark SQL才有可能去尝试SHJ。</p><h3>不等值Join下，Spark如何选择Join策略？</h3><p>接下来，我们再来说说不等值Join，它指的是两张表的Join Key是通过不等值条件连接在一起的。不等值Join其实我们在以前的例子中也见过，比如像查询语句t1 inner join t2 on <strong>t1.date &gt; t2.beginDate and t1.date &lt;= t2.endDate</strong>，其中的关联关系是依靠不等式连接在一起的。</p><p><strong>由于不等值Join只能使用NLJ来实现，因此Spark SQL可选的Join策略只剩下BNLJ和CPJ。</strong>在同一种计算模式下，相比Shuffle，广播的网络开销更小。显然，在两种策略的选择上，Spark SQL一定会按照BNLJ &gt; CPJ的顺序进行尝试。当然，BNLJ生效的前提自然是内表小到可以放进广播变量。如果这个条件不成立，那么Spark SQL只好委曲求全，使用笨重的CPJ策略去完成关联计算。</p><h2>开发者能做些什么？</h2><p>最后，我们再来聊聊，面对上述的5种Join策略，开发者还能做些什么呢？通过上面的分析，我们不难发现，Spark SQL对于这些策略的取舍也基于一些既定的规则。所谓计划赶不上变化，预置的规则自然很难覆盖多样且变化无常的计算场景。因此，当我们掌握了不同Join策略的工作原理，结合我们对于业务和数据的深刻理解，完全可以自行决定应该选择哪种Join策略。</p><p><img src=\"https://static001.geekbang.org/resource/image/94/b8/9436f0f9352ffa381b238be57d2ecdb8.jpeg?wh=1920*1080\" alt=\"\"></p><p>在最新发布的3.0版本中，Spark为开发者提供了多样化的Join Hints，允许你把专家经验凌驾于Spark SQL的选择逻辑之上。<strong>在满足前提条件的情况下，如等值条件、连接类型、表大小等等，Spark会优先尊重开发者的意愿，去选取开发者通过Join Hints指定的Join策略。</strong>关于Spark 3.0支持的Join Hints关键字，以及对应的适用场景，我把它们总结到了如上的表格中，你可以直接拿来参考。</p><p>简单来说，你可以使用两种方式来指定Join Hints，一种是通过SQL结构化查询语句，另一种是使用DataFrame的DSL语言，都很方便。至于更全面的讲解，你可以去<a href=\"https://time.geekbang.org/column/article/360837\">第13讲</a>看看，这里我就不多说了。</p><h2>小结</h2><p>这一讲，我们从数据关联的实现原理，到Spark SQL不同Join策略的适用场景，掌握这些关键知识点，对于数据关联场景中的性能调优至关重要。</p><p>首先，你需要掌握3种Join实现机制的工作原理。为了方便你对比，我把它们总结在了下面的表格里。</p><p><img src=\"https://static001.geekbang.org/resource/image/86/bc/86bb13a5b7b96da4f5128df8b54b96bc.jpeg?wh=1920*864\" alt=\"\"></p><p>掌握了3种关联机制的实现原理，你就能更好地理解Spark SQL的Join策略。结合数据的网络分发方式（Shuffle和广播），Spark SQL支持5种Join策略，按照执行效率排序就是BHJ &gt; SHJ &gt; SMJ &gt; BNLJ &gt; CPJ。同样，为了方便对比，你也可以直接看下面的表格。</p><p><img src=\"https://static001.geekbang.org/resource/image/7b/9e/7be7f01b383463f804a2db74a68d5e9e.jpeg?wh=1920*716\" alt=\"\"></p><p>最后，当你掌握了不同Join策略的工作原理，结合对于业务和数据的深刻理解，实际上你可以自行决定应该选择哪种Join策略，不必完全依赖Spark SQL的判断。</p><p>Spark为开发者提供了多样化的Join Hints，允许你把专家经验凌驾于Spark SQL的选择逻辑之上。比如，当你确信外表比内表大得多，而且内表数据分布均匀，使用SHJ远比默认的SMJ效率高得多的时候，你就可以通过指定Join Hints来强制Spark SQL按照你的意愿去选择Join策略。</p><h2>每日一练</h2><ol>\n<li>如果关联的场景是事实表Join事实表，你觉得我们今天讲的Sort Merge Join实现方式还适用吗？如果让你来设计算法的实现步骤，你会怎么做？</li>\n<li>你觉得，不等值Join可以强行用Sort Merge Join和Hash Join两种机制来实现吗？为什么？</li>\n</ol><p>期待在留言区看到你的思考和答案，我们下一讲见！</p>","neighbors":{"left":{"article_title":"25 | Spark 3.0（二）：DPP特性该怎么用？","id":372234},"right":{"article_title":"27 | 大表Join小表：广播变量容不下小表怎么办？","id":373089}},"comments":[{"had_liked":false,"id":292454,"user_name":"kingcall","can_delete":false,"product_type":"c1","uid":1056982,"ip_address":"","ucode":"508884DC684B5B","user_header":"https://static001.geekbang.org/account/avatar/00/10/20/d6/b9513db0.jpg","comment_is_top":false,"comment_ctime":1620828246,"is_pvip":false,"replies":[{"id":"105901","content":"到位~<br><br>1. Shuffle Sort Merge Join，对于“大表Join大表”来说，是最稳定的实现方式，不过关于“大表Join大表”，咱们还是有一些调优手段的，这块可以关注28、29讲哈~<br><br>2. 确实，排序和构建hash table本身成了开销，在不等值的情况下，已经没有任何意义。","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1620860887,"ip_address":"","comment_id":292454,"utype":1}],"discussion_count":1,"race_medal":0,"score":"27390632022","product_id":100073401,"comment_content":"回答：<br>问题1：个人觉得SMJ 就是用在两张大表上的关联才有意思啊，也就是事实表 Join 事实表，但是这里要求是等值关联，如果是不等值关联就只能CPJ<br>问题2：可以分情况讨论一下，但是肯定是可以实现的<br>    1. != 这样的关联，Sort Merge Join 和 Hash Join 都是不划算的，但是是可以实现的。<br>    2. 大于等于、小于等于 、大于 、小于 Sort Merge Join 还是有可取之处的，但是还是考虑到了排序的成本，但是这个地方有一个问题那就是我们的shuffle输出的数据的本身就是有序的啊，所以我觉得 Sort Merge Join 是可以的，Hash Join 就算了，其实可以看出来hash 只适合等值，这是取决于hash 本身的特点的。","like_count":7,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":519837,"discussion_content":"到位~\n\n1. Shuffle Sort Merge Join，对于“大表Join大表”来说，是最稳定的实现方式，不过关于“大表Join大表”，咱们还是有一些调优手段的，这块可以关注28、29讲哈~\n\n2. 确实，排序和构建hash table本身成了开销，在不等值的情况下，已经没有任何意义。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1620860887,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":306648,"user_name":"louis","can_delete":false,"product_type":"c1","uid":1535795,"ip_address":"","ucode":"E5C06FB94C3C6A","user_header":"https://static001.geekbang.org/account/avatar/00/17/6f/33/8a26a19a.jpg","comment_is_top":false,"comment_ctime":1628656479,"is_pvip":false,"replies":[{"id":"111316","content":"非常好的问题~ 同意你的说法，更严谨，确实是应该每个分片都能放入内存，才是更严谨的要求。<br><br>不过，这种说法的可操作性不强，因为我们很难确认，每个数据分片的大小，更难确认的是，每个分片都能刚好放进内存。<br><br>“内表数据分片的平均大小要小于广播变量阈值”，这种说法，实际上是一种“不准确”但是操作性更强的办法，计算分片的平均大小还是比较容易的，再者广播变量阈值其实是个很好的“参照系”。如果分片平均大小能够比广播阈值还要小，那么大概率SHJ能够顺利地执行成功。<br><br>你说的对，这里跟广播没有任何关系，跟广播阈值作对比，更多地是给大家一个明确的“参照系”。为什么选它呢？因为，在大多数情况下，咱们都会在广播阈值上“精打细算”，对它的设置都会比较谨慎，所以拿他做参照，会比较稳妥一些。<br><br>不过，话说回来，严格来说，就是应该按照你说的，确保所有分片，可以放进内存。","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1629107121,"ip_address":"","comment_id":306648,"utype":1}],"discussion_count":1,"race_medal":0,"score":"23103492959","product_id":100073401,"comment_content":"SHJ的第二个条件，“内表数据分片的平均大小要小于广播变量阈值”。<br>这里为什么是广播变量阈值，这里不涉及广播啊？不应该是内表的每一个数据分片都恰好放入执行内存中。","like_count":6,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":524857,"discussion_content":"非常好的问题~ 同意你的说法，更严谨，确实是应该每个分片都能放入内存，才是更严谨的要求。\n\n不过，这种说法的可操作性不强，因为我们很难确认，每个数据分片的大小，更难确认的是，每个分片都能刚好放进内存。\n\n“内表数据分片的平均大小要小于广播变量阈值”，这种说法，实际上是一种“不准确”但是操作性更强的办法，计算分片的平均大小还是比较容易的，再者广播变量阈值其实是个很好的“参照系”。如果分片平均大小能够比广播阈值还要小，那么大概率SHJ能够顺利地执行成功。\n\n你说的对，这里跟广播没有任何关系，跟广播阈值作对比，更多地是给大家一个明确的“参照系”。为什么选它呢？因为，在大多数情况下，咱们都会在广播阈值上“精打细算”，对它的设置都会比较谨慎，所以拿他做参照，会比较稳妥一些。\n\n不过，话说回来，严格来说，就是应该按照你说的，确保所有分片，可以放进内存。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1629107121,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":294015,"user_name":"快跑","can_delete":false,"product_type":"c1","uid":1564645,"ip_address":"","ucode":"90ED7E6D40C58E","user_header":"https://static001.geekbang.org/account/avatar/00/17/df/e5/65e37812.jpg","comment_is_top":false,"comment_ctime":1621678940,"is_pvip":false,"replies":[{"id":"106636","content":"好问题，一个个来说。<br><br>先说第一个，是的，Join的操作是发生在Reduce阶段，原因其实很简单，就是两张表Join Keys相同的records，要分发到同一个Executors进程，这样才能完成关联计算。一旦两表的records进入到同一个Executors，这个时候就是看采用什么实现机制了，也就是hash join，sort merge join，还是nested loop join。<br><br>第二个， 其实是反过来的，就是如果Spark选择Shuffle SMJ策略，那么map阶段就会按照（partitionId，Join Key）来排序。但如果采用了Shuffle Hash Join的策略，Map阶段只需要对partitionId做排序就可以，不需要对Join Key做排序，计算复杂度还是会有所降低的。<br><br>第三个问题，超级好的问题，对于CPJ，它其实就不再是简单的Shuffle过程了，一般的Shuffle过程，是每份数据只分发一次。但对于CPJ，就像你说的，它是数据集的全网分发。理想情况下，一张表“待在原地、保持不动”，而另一张表的所有数据分片，都需要在全网每个Executors中全都分发一遍，这也是Cartesian Product Join这个名字的由来，就是笛卡尔积么，非常变态加夸张的计算复杂度。所以不到万不得已，要尽量离CPJ远远地~","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1621695253,"ip_address":"","comment_id":294015,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18801548124","product_id":100073401,"comment_content":"老师你好，产生了几个疑问，请帮忙看看我理解的对么<br>1、从MapReduce阶段来看JOIN，带Shuffle的Join应该都发生在Reduce阶段？<br><br>2、经过Shuffle后的数据不就已经是排序的么，这样子使用SMJ是不是比SHJ少了Hash计算，也减少构建Hash的内存开销。<br><br>3、不等值连接的情况，BNLJ不生效的时候，采用CPJ策略时候，JOIN发生在Reduce阶段？ 这个时候数据不都分散在各个节点么。 其中一个节点的数据怎么跟其他节点的数据比较呢。<br>这个时候不仅仅是数据逻辑上要Nested Loop。就连数据也需要通过网络挨个节点传输一遍么","like_count":5,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":520465,"discussion_content":"好问题，一个个来说。\n\n先说第一个，是的，Join的操作是发生在Reduce阶段，原因其实很简单，就是两张表Join Keys相同的records，要分发到同一个Executors进程，这样才能完成关联计算。一旦两表的records进入到同一个Executors，这个时候就是看采用什么实现机制了，也就是hash join，sort merge join，还是nested loop join。\n\n第二个， 其实是反过来的，就是如果Spark选择Shuffle SMJ策略，那么map阶段就会按照（partitionId，Join Key）来排序。但如果采用了Shuffle Hash Join的策略，Map阶段只需要对partitionId做排序就可以，不需要对Join Key做排序，计算复杂度还是会有所降低的。\n\n第三个问题，超级好的问题，对于CPJ，它其实就不再是简单的Shuffle过程了，一般的Shuffle过程，是每份数据只分发一次。但对于CPJ，就像你说的，它是数据集的全网分发。理想情况下，一张表“待在原地、保持不动”，而另一张表的所有数据分片，都需要在全网每个Executors中全都分发一遍，这也是Cartesian Product Join这个名字的由来，就是笛卡尔积么，非常变态加夸张的计算复杂度。所以不到万不得已，要尽量离CPJ远远地~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1621695253,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":318676,"user_name":"To_Drill","can_delete":false,"product_type":"c1","uid":1415245,"ip_address":"","ucode":"7E6FFAF1986EC8","user_header":"https://static001.geekbang.org/account/avatar/00/15/98/4d/582d24f4.jpg","comment_is_top":false,"comment_ctime":1635388323,"is_pvip":false,"replies":[{"id":"115574","content":"对的，没错！","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1635425480,"ip_address":"","comment_id":318676,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10225322915","product_id":100073401,"comment_content":"老师您好，有个疑问想请教下，如果选择了SMJ，那么在map端shuffle的输出文件中是按partitionID和key排序的，但是map端不应该只是局部数据的排序嘛，当reduce端拉取各个输出文件的时候还是会做一次全局排序（粒度为partition）的吧？如果是这样的话那么map端的排序只是加快了后续reduce端全局排序的效率，而不是map端排序了之后reduce端就不需要排序了是吧？","like_count":2,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":529341,"discussion_content":"对的，没错！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1635425480,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":292497,"user_name":"斯盖丸","can_delete":false,"product_type":"c1","uid":1168504,"ip_address":"","ucode":"B881D14B028F14","user_header":"https://static001.geekbang.org/account/avatar/00/11/d4/78/66b3f2a2.jpg","comment_is_top":false,"comment_ctime":1620860014,"is_pvip":false,"replies":[{"id":"105923","content":"没有区别哈~<br><br>小表Join大表，掉过来不就是大表Join小表么？其实不论谁Join谁，其实优化器都是会做区分的。不过通常来说，在形式上，我们把外表（驱动表）放左边，而内表（基表）放右边，所以专栏里面，在描述的时候，都是“大表Join小表”。","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1620887855,"ip_address":"","comment_id":292497,"utype":1}],"discussion_count":6,"race_medal":0,"score":"10210794606","product_id":100073401,"comment_content":"老师一般SQL的教程里都是join的优化方法之一是小表join大表，但我看Spark里你都是大表join小表，在大数据里谁join谁要紧吗，感觉好像无所谓？","like_count":2,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":519853,"discussion_content":"没有区别哈~\n\n小表Join大表，掉过来不就是大表Join小表么？其实不论谁Join谁，其实优化器都是会做区分的。不过通常来说，在形式上，我们把外表（驱动表）放左边，而内表（基表）放右边，所以专栏里面，在描述的时候，都是“大表Join小表”。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1620887855,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1179298,"avatar":"https://static001.geekbang.org/account/avatar/00/11/fe/a2/5252a278.jpg","nickname":"对方正在输入。。。","note":"","ucode":"7B0DEB4D9B43D2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":374144,"discussion_content":"左连接的话小表得放右边，右连接的话小表得放左边","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1621041950,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":2,"child_discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":1179298,"avatar":"https://static001.geekbang.org/account/avatar/00/11/fe/a2/5252a278.jpg","nickname":"对方正在输入。。。","note":"","ucode":"7B0DEB4D9B43D2","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":375926,"discussion_content":"正解~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1621870706,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":374144,"ip_address":""},"score":375926,"extra":""},{"author":{"id":1789481,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/4e/29/adcb78e7.jpg","nickname":"静心","note":"","ucode":"B80DE4B5C923D3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1179298,"avatar":"https://static001.geekbang.org/account/avatar/00/11/fe/a2/5252a278.jpg","nickname":"对方正在输入。。。","note":"","ucode":"7B0DEB4D9B43D2","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":414030,"discussion_content":"why?","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1636639009,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":374144,"ip_address":""},"score":414030,"extra":""}]},{"author":{"id":1018685,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/8b/3d/0c3a2fd4.jpg","nickname":"偶尔复活下","note":"","ucode":"18B1D525CD50D3","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":536046,"discussion_content":"新版本会自行优化，所以大小表放哪边都可以。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1638665054,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2304851,"avatar":"https://static001.geekbang.org/account/avatar/00/23/2b/53/1adc2037.jpg","nickname":"风向决定发型","note":"","ucode":"7EE798C3ADFC11","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":410776,"discussion_content":"因为基表无法被广播，所以spark中大表join小表会好","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1635774600,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":292417,"user_name":"zxk","can_delete":false,"product_type":"c1","uid":1221195,"ip_address":"","ucode":"4BB2BD9D2BCD04","user_header":"https://static001.geekbang.org/account/avatar/00/12/a2/4b/b72f724f.jpg","comment_is_top":false,"comment_ctime":1620812378,"is_pvip":false,"replies":[{"id":"105899","content":"满分💯<br><br>第一题答得尤其好，这道题的初衷就是鼓励大家发散思维，大开脑洞，去思考更多的实现方式~ 你说的实现方式，我觉得蛮有意思，算法复杂度介于NLJ和SMJ之间，也就是O（M*logN），前置开销是一次排序，这种实现其实还是能适配一些场景的~ 666~<br><br>第二题分析的很到位，强行用SMJ的时候，排序就成了“戴斗笠打雨伞”，多此一举。（其实我特别想说，脱了裤子放屁，不过不太文雅，哈哈）","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1620859221,"ip_address":"","comment_id":292417,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10210746970","product_id":100073401,"comment_content":"1. 可以对 Sort Merge Join 做一个变种，例如一个表排序，一个表不排序，不排序的表作为驱动表，排序的表可以通过二分查找等方式快速定位驱动表的 Join Key。<br>2. 也可以强行实现，但 Sort Merge Join 方面的排序就会变得毫无意义，同时 Sort Merge Join、Hash Join 的时间复杂度也并未降低，反而带来了额外的排序开销与内存开销。","like_count":3,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":519820,"discussion_content":"满分💯\n\n第一题答得尤其好，这道题的初衷就是鼓励大家发散思维，大开脑洞，去思考更多的实现方式~ 你说的实现方式，我觉得蛮有意思，算法复杂度介于NLJ和SMJ之间，也就是O（M*logN），前置开销是一次排序，这种实现其实还是能适配一些场景的~ 666~\n\n第二题分析的很到位，强行用SMJ的时候，排序就成了“戴斗笠打雨伞”，多此一举。（其实我特别想说，脱了裤子放屁，不过不太文雅，哈哈）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1620859221,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":292313,"user_name":"Bennan","can_delete":false,"product_type":"c1","uid":2427818,"ip_address":"","ucode":"8B6EE3DCBB1356","user_header":"https://static001.geekbang.org/account/avatar/00/25/0b/aa/09c1215f.jpg","comment_is_top":false,"comment_ctime":1620781491,"is_pvip":false,"replies":[{"id":"105900","content":"没错，大表Join大表最稳定的方式，确实就是Shuffle <br> Sort Merge Join。同时如果Map阶段计算按照（partitionId，join key）排好序的话，后续Reduce阶段可以直接做SMJ的计算，相当于前置条件已经满足。<br><br>第二题说的没错，排序、构建哈希表本身成了开销、多此一举~","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1620860620,"ip_address":"","comment_id":292313,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5915748787","product_id":100073401,"comment_content":"1.两张事实表最好的等值连接方式就是smj，可以让map端输出的时候先进行排序，reduce拉取数据的时候就可以对两个表的多个数据流进行join操作<br>2可以强行使用smj和hj，但是这样并没有意义，因为最后join还是m*n的复杂度(当时如果是大于或者小于的连接方式，在进行连接的可以优化一下)，而smj会带来额外的排序开销，hj要求内存能够放得下并且需要构建hash表","like_count":1,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":519770,"discussion_content":"没错，大表Join大表最稳定的方式，确实就是Shuffle \n Sort Merge Join。同时如果Map阶段计算按照（partitionId，join key）排好序的话，后续Reduce阶段可以直接做SMJ的计算，相当于前置条件已经满足。\n\n第二题说的没错，排序、构建哈希表本身成了开销、多此一举~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1620860620,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":345309,"user_name":"C2H4","can_delete":false,"product_type":"c1","uid":2212841,"ip_address":"","ucode":"2F8B3F47208329","user_header":"https://static001.geekbang.org/account/avatar/00/21/c3/e9/8cb4e2e5.jpg","comment_is_top":false,"comment_ctime":1652186493,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1652186493","product_id":100073401,"comment_content":"请教一个问题,为什么BHJ的连接类型不能是全连接呢","like_count":0},{"had_liked":false,"id":321034,"user_name":"七夏、","can_delete":false,"product_type":"c1","uid":2839761,"ip_address":"","ucode":"58535A9EAAA97A","user_header":"https://static001.geekbang.org/account/avatar/00/2b/54/d1/d548f376.jpg","comment_is_top":false,"comment_ctime":1636626379,"is_pvip":false,"replies":[{"id":"116596","content":"在没有开启AQE的情况下，你说的这种情况，不会广播，因为210M的A表，超过了广播阈值。<br><br>但是，如果开启了AQE，自动Join策略调整，AQE会把原本的Shuffle Join转化为Broadcast Join，这部分细节，可以看前面AQE的那一讲（24讲）哈~<br>","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1636646057,"ip_address":"","comment_id":321034,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1636626379","product_id":100073401,"comment_content":"老师您好，有个问题需要您答惑下：<br>关于spark sql 中的广播机制，spark是会将满足条件的原表广播还是过滤后的结果表呢？ <br>比如 关联 A表 A的大小为210M 但是广播机制是以hdfs 200M大小为阈值的，这个时候是不会被广播的，那如果我在A表做了 where 条件后 过滤后的A表只有120M，这个时候会被广播么？","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":530193,"discussion_content":"在没有开启AQE的情况下，你说的这种情况，不会广播，因为210M的A表，超过了广播阈值。\n\n但是，如果开启了AQE，自动Join策略调整，AQE会把原本的Shuffle Join转化为Broadcast Join，这部分细节，可以看前面AQE的那一讲（24讲）哈~\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1636646057,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":294253,"user_name":"天翼","can_delete":false,"product_type":"c1","uid":2459638,"ip_address":"","ucode":"82153820B786E0","user_header":"https://static001.geekbang.org/account/avatar/00/25/87/f6/bc199560.jpg","comment_is_top":false,"comment_ctime":1621850896,"is_pvip":false,"replies":[{"id":"106772","content":"是的，主要是表大小，通常来说，大多数数据库引擎，都会把尺寸比较大的表，当作外表、或者说驱动表；而尺寸较小的表，当作内表、也叫基表。","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1621866762,"ip_address":"","comment_id":294253,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1621850896","product_id":100073401,"comment_content":"请教一个问题，主动扫描的作为外表，被动参与扫描的表叫做内表，主动与被动是怎么区分的呢？","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":520573,"discussion_content":"是的，主要是表大小，通常来说，大多数数据库引擎，都会把尺寸比较大的表，当作外表、或者说驱动表；而尺寸较小的表，当作内表、也叫基表。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1621866762,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":2673906,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJG2MT85PrpeLzBcusbvaOgJtJFVXoibNBxNaGiaRczM6ZyHotpH588u4ORk2h6wia6PUUWic1euQfA1A/132","nickname":"姚晓华","note":"","ucode":"E87112F64FABA8","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":554072,"discussion_content":"老师，是不是说反了呢，外表数据量小，循环次数少不是更好吗，谢谢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1646205550,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":520573,"ip_address":""},"score":554072,"extra":""}]}]},{"had_liked":false,"id":293396,"user_name":"辰","can_delete":false,"product_type":"c1","uid":2172635,"ip_address":"","ucode":"2E898EAC5AA141","user_header":"https://static001.geekbang.org/account/avatar/00/21/26/db/27724a6f.jpg","comment_is_top":false,"comment_ctime":1621383101,"is_pvip":false,"replies":[{"id":"106331","content":"大小表放哪边其实没关系的，Spark SQL在优化阶段会自行判断。实际上两张表重要的是“大、小”，而不是“左、右”，对于Spark SQL优化引擎来说，大小重要，左右不重要。我们之所以区分左右，主要是为了叙述方便而已~","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1621434810,"ip_address":"","comment_id":293396,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1621383101","product_id":100073401,"comment_content":"老师，斯盖丸同学的大表join小表，在spark中，大表作为驱动表放在左边，那和放在右边有效率影响吗？还是不成文的规范，第二点，在hive中，小表是放在左边的，如果足够小的话，hive会自动把小表放进内存中，相当于广播变量了","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":520194,"discussion_content":"大小表放哪边其实没关系的，Spark SQL在优化阶段会自行判断。实际上两张表重要的是“大、小”，而不是“左、右”，对于Spark SQL优化引擎来说，大小重要，左右不重要。我们之所以区分左右，主要是为了叙述方便而已~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1621434810,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":293134,"user_name":"斯盖丸","can_delete":false,"product_type":"c1","uid":1168504,"ip_address":"","ucode":"B881D14B028F14","user_header":"https://static001.geekbang.org/account/avatar/00/11/d4/78/66b3f2a2.jpg","comment_is_top":false,"comment_ctime":1621237545,"is_pvip":false,"replies":[{"id":"106414","content":"这个听上去有点蹊跷，也就是说，maxResultSize=5G，autoBroadcastThreshold=3G，在这种情况下，在尝试创建广播变量的时候报错，对吧？报的错误是maxResultSize超出阈值限制？<br><br>结合现象的话，我觉得有一种可能是，对于数据集大小，Spark判断其小于3G，但实际上它的尺寸是6G，这个时候Spark还是会尝试创建广播变量，但是实际广播变量尺寸很大，超过了maxResultSize，所以会报你说的错误。<br><br>所以这里的关键是，你要广播的数据集，大小究竟是多大？这个可以用我们之前说的方法去计算、验证一下，然后再来判断，咱们的猜测是不是对的。对于数据集尺寸的预估，Spark确实有“看走眼”的时候，并不是每次都能做到十分精确。","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1621509226,"ip_address":"","comment_id":293134,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1621237545","product_id":100073401,"comment_content":"老师，问个生产上的问题，我把autoBroadcastThreshold值调到了3g，然后就遇到了spark.driver.maxResultSize超出最大值的错误。该值默认1g，我调到了5g，已经大于autoBroadcastThreshold的3g了，可为什么还报错，请问生产上这两个参数的最佳实践该怎么互相指定呢？","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":520089,"discussion_content":"这个听上去有点蹊跷，也就是说，maxResultSize=5G，autoBroadcastThreshold=3G，在这种情况下，在尝试创建广播变量的时候报错，对吧？报的错误是maxResultSize超出阈值限制？\n\n结合现象的话，我觉得有一种可能是，对于数据集大小，Spark判断其小于3G，但实际上它的尺寸是6G，这个时候Spark还是会尝试创建广播变量，但是实际广播变量尺寸很大，超过了maxResultSize，所以会报你说的错误。\n\n所以这里的关键是，你要广播的数据集，大小究竟是多大？这个可以用我们之前说的方法去计算、验证一下，然后再来判断，咱们的猜测是不是对的。对于数据集尺寸的预估，Spark确实有“看走眼”的时候，并不是每次都能做到十分精确。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1621509226,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":292986,"user_name":"aof","can_delete":false,"product_type":"c1","uid":1062864,"ip_address":"","ucode":"5815D63C4926BC","user_header":"https://static001.geekbang.org/account/avatar/00/10/37/d0/26975fba.jpg","comment_is_top":false,"comment_ctime":1621141806,"is_pvip":false,"replies":[{"id":"106276","content":"我同意你的说法，就是从统计概率来说，在扫描的时候会有一定的提升，不过SMJ有个前提哦，那就是参与Join的两表要提前排序，这个开销还是蛮大的~","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1621411779,"ip_address":"","comment_id":292986,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1621141806","product_id":100073401,"comment_content":"第二题，如果使用SMJ实现不等值Join，比如在大于或小于的关联条件下，排序还是有些用处的，因为拿一个表的Join key去另一个表扫描的时候，遍历到不满足条件的记录时，就可以不用继续遍历了。但是如果不排序，每次都是无脑全部遍历，虽然在计算时间复杂度的时候可能还是一样的，但是，按概率来讲，多数时候，实际的遍历记录是不一样的，还是有性能提升的。","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":520035,"discussion_content":"我同意你的说法，就是从统计概率来说，在扫描的时候会有一定的提升，不过SMJ有个前提哦，那就是参与Join的两表要提前排序，这个开销还是蛮大的~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1621411779,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":292443,"user_name":"Fendora范东_","can_delete":false,"product_type":"c1","uid":1187106,"ip_address":"","ucode":"63EE9DBEE08D70","user_header":"https://static001.geekbang.org/account/avatar/00/12/1d/22/f04cea4c.jpg","comment_is_top":false,"comment_ctime":1620823181,"is_pvip":false,"replies":[{"id":"105898","content":"分析的很到位~<br><br>1. Shuffle sort merge join 在Shuffle Joins里面确实是最稳定的实现方式了。不过对于“大表Join大表”来说，其实咱们还是有一些优化手段的，这块可以关注下28、29讲哈~<br><br>2. 没错，就是这么回事~","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1620858709,"ip_address":"","comment_id":292443,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1620823181","product_id":100073401,"comment_content":"问题回答<br>1.等值条件时，内外表任意大小都可以用SMJ，只不过当内表比较小或者内表平均分片小于阈值时，有性能更好的BHJ与SHJ可以选择。特别是大表join大表时，不满足使用其他两个的条件，SMJ就是最优解。<br><br>大表join大表，我理解目前最好的方式就是Shuffle sort merge join<br><br>2.不等值条件可以强行用SMJ，那他的时间复杂度又变成了O(M*N)，两表前期排序也没有太大意义。","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":519832,"discussion_content":"分析的很到位~\n\n1. Shuffle sort merge join 在Shuffle Joins里面确实是最稳定的实现方式了。不过对于“大表Join大表”来说，其实咱们还是有一些优化手段的，这块可以关注下28、29讲哈~\n\n2. 没错，就是这么回事~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1620858709,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]}]}