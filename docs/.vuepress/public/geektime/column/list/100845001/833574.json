{"id":833574,"title":"01｜Agent的前辈：Function Calling","content":"<p>你好，我是邢云阳。</p><p>自2023年3月 ChatGPT 在中国爆火以来，大模型已经悄然改变了许多人的提问方式，尤其是在互联网圈子里。从以前的“有问题，Google 一下”，到现在的“先问问大模型”，这种转变反映了技术对日常生活的深远影响，比如图中这位女士就将 ChatGPT 使用的淋漓尽致。</p><p><img src=\"https://static001.geekbang.org/resource/image/d6/23/d608212c2ebb73c43ee94353f6021923.jpg?wh=968x961\" alt=\"\"></p><p>但是在使用过程中，我们会发现，有时大模型并不是万能的，它会一本正经的给出错误答案，业界把这种现象称之为“幻觉”。比如我问 ChatGPT-4o 一个它肯定不会的问题。</p><p><img src=\"https://static001.geekbang.org/resource/image/12/ce/126d324784yy8bfb4d2ff9fc66475fce.png?wh=1221x505\" alt=\"图片\"></p><p>我们会发现，大模型给出了看似正确实则“废话”的答案。</p><p>再比如，我问一道小学一二年级的数学题：</p><p><img src=\"https://static001.geekbang.org/resource/image/34/6e/342d4b45a41122d6868b5686d546586e.png?wh=1183x264\" alt=\"图片\"></p><p>我们很容易知道1+2+3+4-5-6=-1，但大模型给我们的答案是0。</p><p>“幻觉”出现的原因其实很简单。我们知道作为人类来说，即使是才高八斗，学富五车，也不可能什么都懂，于是就有这样一种人，为了面子，在遇到不会的问题时，也要强行给出一个模模糊糊的答案，我们称之为不懂装懂。</p><p>同样，作为大模型，训练数据是有限的，特别是对于一些垂直领域以及实时性的问题，例如附近哪有加油站？今天的茅台股票多少钱一股？大模型是无法给出正确的回答的。那大模型为什么也处理不了小学数学题呢？这是因为大模型的训练方法是通过学习语言的结构和模式，使得其能够生成与人类语言相似的文本，而不是针对数学问题这种精确逻辑做的训练，因此它的数学能力很弱。</p><!-- [[[read_end]]] --><p>我们应如何解决这类问题呢？OpenAI 公司为了能让大模型与外界进行交互，发明了 Function Calling 机制，即可以在向大模型提问时，给大模型提供一些工具（函数），由大模型根据需要，自行选择合适的工具，从而解决问题。</p><p>接下来，我将使用Go语言，为你演示一下 Function Calling 功能，我们就以加法减法工具为例，让大模型通过工具来进行数学运算。</p><h2>代码实战前置工作</h2><h3>环境准备</h3><ul>\n<li>运行环境：Windows/Linux</li>\n<li>Go版本：1.19</li>\n<li>LLM：阿里云 qwen-turbo</li>\n<li>SDK：go-openai v1.32.0</li>\n</ul><p>考虑到使用 OpenAI 的模型，需要科学上网，且购买 API 的调用额度，需要美国信用卡支付。因此我们选择国内模型作为替代演示。如果有同学想了解如何使用 OpenAI API ，可留言区留言评论，我们不在课程中展示。</p><h3>通义千问大模型开通</h3><p>阿里云通义千问提供了比较丰富的大模型产品供用户使用，且其请求方式是兼容 OpenAI SDK 的。本小节实战所使用的模型是通义千问中最便宜的 qwen-turbo 模型。如何开通服务，可参考官网教程<a href=\"https://help.aliyun.com/zh/dashscope/opening-service?spm=a2c22.12281978.0.0.4d59588ebiflN0\">开通DashScope并创建API-KEY_模型服务灵积(DashScope)-阿里云帮助中心 (aliyun.com)</a> 。</p><h2>代码实战演示</h2><h3>模型环境变量配置</h3><p>当我们获取了通义千问大模型的 api_key 之后，为了保密和调用方便，可以将其配置到环境变量。</p><p>以 Windows 系统为例，我的电脑-&gt;右键属性-&gt;高级系统设置-&gt;环境变量，在系统变量中点击新建。</p><p><img src=\"https://static001.geekbang.org/resource/image/94/89/94c2859904708be8205faba30011bc89.png?wh=1030x472\" alt=\"图片\"></p><p>输入变量名和 api_key 的值即可。</p><p>接下来我们开始写初始化 OpenAI 客户端的代码。</p><p>首先将 go-openai sdk 下载下来。</p><pre><code class=\"language-plain\">go get github.com/sashabaranov/go-openai\n</code></pre><p>之后，开始初始化一个 OpenAI 客户端，需要填充 token 和 baseurl 两项，用于客户端与大模型服务器的连接。</p><pre><code class=\"language-go\">func NewOpenAiClient() *openai.Client {\n&nbsp; &nbsp; token := os.Getenv(\"DashScope\")\n&nbsp; &nbsp; dashscope_url := \"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n&nbsp; &nbsp; config := openai.DefaultConfig(token)\n&nbsp; &nbsp; config.BaseURL = dashscope_url\n\n\n&nbsp; &nbsp; return openai.NewClientWithConfig(config)\n}\n</code></pre><p>由于通义千问大模型是兼容 OpenAI 的，因此可以使用 OpenAI SDK 初始化大模型客户端。使用 os 包从环境变量中获取 api_key。</p><h3>Chat Completions</h3><p>我们在演示工具选择之前，首先需要把和大模型对话的基础代码写好。这就要用到 Chat Completions。Chat Completions 是 OpenAI SDK 提供的一次性对话的方法，我们使用它可以完成和大模型的对话。</p><p>在与大模型的对话过程中，会有三种基础角色，用来让大模型清楚某句话是谁说的。</p><ul>\n<li>\n<p>system：系统角色，可以理解为全局变量或前置条件，设置上这个角色之后，就会规定大模型的聊天范围，业界通常称之为“人设”。</p>\n</li>\n<li>\n<p>user：人类角色，代表这句话是人类说的。在包括 LangChain 在内的很多框架和场景下，user 角色也会被写成 human。</p>\n</li>\n<li>\n<p>assistant：AI角色，代表这句话是大模型给我们的返回。在包括 LangChain 在内的很多框架和场景下，assistant 角色也会被写成 AI。</p>\n</li>\n</ul><p>我举一个例子，演示一下使用以上三种角色完成一次 Chat Completions。</p><pre><code class=\"language-plain\">system: 你是一个足球领域的专家，请尽可能地帮我回答与足球相关的问题。\nuser: C罗是哪个国家的足球运动员？\nassistant: 葡萄牙\n</code></pre><p>如果想要实现多轮对话效果，则需要每一次都带着历史对话提问，例如：</p><pre><code class=\"language-plain\">system: 你是一个足球领域的专家，请尽可能地帮我回答与足球相关的问题。\nuser: C罗是哪个国家的足球运动员？\nassistant: 葡萄牙\nuser: 内马尔呢？\n</code></pre><p>虽然最后一次人类的提问“内马尔呢”是一个模糊提问，但由于存在历史对话，因此大模型可以理解用户的提问的意思是“内马尔是哪个国家的足球运动员？”</p><p>理解了三种角色后，我们开始写代码。</p><pre><code class=\"language-go\">func Chat(message []openai.ChatCompletionMessage) openai.ChatCompletionMessage {\n&nbsp; &nbsp; c := NewOpenAiClient()\n&nbsp; &nbsp; rsp, err := c.CreateChatCompletion(context.TODO(), openai.ChatCompletionRequest{\n&nbsp; &nbsp; &nbsp; &nbsp; Model: &nbsp; &nbsp;\"qwen-plus\",\n&nbsp; &nbsp; &nbsp; &nbsp; Messages: message,\n&nbsp; &nbsp; })\n&nbsp; &nbsp; if err != nil {\n&nbsp; &nbsp; &nbsp; &nbsp; log.Println(err)\n&nbsp; &nbsp; &nbsp; &nbsp; return openai.ChatCompletionMessage{}\n&nbsp; &nbsp; }\n\n\n&nbsp; &nbsp; return rsp.Choices[0].Message\n}\n</code></pre><p>在这个函数中，首先我获取了 OpenAI 客户端，之后通过客户端调用了 CreateChatCompletion 方法。该方式是完成一次与大模型的 Chat。该方法的返回值 rsp，便是大模型的回复。</p><p>在这次 Chat Compleetion 中，我使用的模型是 qwen-plus，message 即向大模型发送的消息。message 的类型是一个 openai.ChatCompletionMessage 切片。</p><p>openai.ChatCompletionMessage包含了多个字段，其中有两个基础字段为：</p><pre><code class=\"language-go\">Role &nbsp; &nbsp; &nbsp; &nbsp; string `json:\"role\"`\nContent &nbsp; &nbsp; &nbsp;string `json:\"content\"`\n</code></pre><p>role 代表角色，content 代表对话内容。</p><p>openai.ChatCompletionMessage为切片类型，是因为考虑到会有历史消息，因此我们需要构建一个历史消息存储器来存储历史对话。核心代码如下：</p><pre><code class=\"language-go\">var MessageStore ChatMessages\ntype ChatMessages []openai.ChatCompletionMessage\n\n\nfunc (cm *ChatMessages) AddFor(role string, msg string) {\n&nbsp; &nbsp; *cm = append(*cm, openai.ChatCompletionMessage{\n&nbsp; &nbsp; &nbsp; &nbsp; Role: &nbsp; &nbsp;role,\n&nbsp; &nbsp; &nbsp; &nbsp; Content: msg,\n&nbsp; &nbsp; })\n}\n\n\nfunc (cm *ChatMessages) ToMessage() []openai.ChatCompletionMessage {\n&nbsp; &nbsp; ret := make([]openai.ChatCompletionMessage, len(*cm))\n&nbsp; &nbsp; for index, c := range *cm {\n&nbsp; &nbsp; &nbsp; &nbsp; ret[index] = c\n&nbsp; &nbsp; }\n&nbsp; &nbsp; return ret\n}\n</code></pre><p>在上述代码中，我们定义了历史消息存储器MessageStore，其本质是一个用于存放各类角色对话内容的 openai.ChatCompletionMessage 切片。并编写了 AddFor 方法，用于添加各类角色的对话内容，最后编写了 ToMessage 方法，用于取出存储器中的所有消息。</p><p>完成了以上编码后，我们可以测试一下和大模型对话的效果了。</p><pre><code class=\"language-go\">func main() {\n&nbsp; &nbsp; ai.MessageStore.AddFor(ai.RoleSystem, \"你是一个足球领域的专家，请尽可能地帮我回答与足球相关的问题。\")\n&nbsp; &nbsp; ai.MessageStore.AddFor(ai.RoleUser, \"C罗是哪个国家的足球运动员？\")\n&nbsp; &nbsp; ai.MessageStore.AddFor(ai.RoleAssistant, \"C罗是葡萄牙足球运动员。\")\n&nbsp; &nbsp; ai.MessageStore.AddFor(ai.RoleUser, \"内马尔呢？\")\n\n\n&nbsp; &nbsp; response := ai.Chat(ai.MessageStore.ToMessage())\n&nbsp; &nbsp; fmt.Println(response.Content)\n}\n</code></pre><p>输出：</p><pre><code class=\"language-go\">内马尔是巴西足球运动员。\n</code></pre><p>在上面的例子中，大模型成功的根据对话历史，理解了“内马尔呢？”表达的真正含义。</p><h3>Function Calling</h3><p>由于 Function Calling 功能是 OpenAI 公司发明的，因此我们定义工具需要遵循 OpenAI SDK 的规范。规范如下：</p><pre><code class=\"language-go\">const (\n&nbsp; &nbsp; ToolTypeFunction ToolType = \"function\"\n)\n\n\ntype Tool struct {\n&nbsp; &nbsp; Type &nbsp; &nbsp; ToolType &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;`json:\"type\"`\n&nbsp; &nbsp; Function *FunctionDefinition `json:\"function,omitempty\"`\n}\n\n\ntype FunctionDefinition struct {\n&nbsp; &nbsp; Name &nbsp; &nbsp; &nbsp; &nbsp;string `json:\"name\"`\n&nbsp; &nbsp; Description string `json:\"description,omitempty\"`\n&nbsp; &nbsp; Parameters any `json:\"parameters\"`\n}\n</code></pre><p>规范还是很简单的，包含了工具类型 Type 和工具定义 Function 两个部分，其实工具类型是写死的 “fuction”。工具定义包含名称 Name、描述 Description 以及参数 Parameters 三个部分。</p><p>接下来我来定义一个加法工具，给你做一下演示。</p><pre><code class=\"language-go\">var AddToolDefine = openai.Tool{\n&nbsp; &nbsp; Type: \"function\",\n&nbsp; &nbsp; Function: &amp;openai.FunctionDefinition{\n&nbsp; &nbsp; &nbsp; &nbsp; Name: \"AddTool\",\n&nbsp; &nbsp; &nbsp; &nbsp; Description: `\n&nbsp; &nbsp; &nbsp; &nbsp; Use this tool for addition calculations.\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; example:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1+2 =?\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; then Action Input is: 1,2\n&nbsp; &nbsp; &nbsp; &nbsp; `,\n&nbsp; &nbsp; &nbsp; &nbsp; Parameters: `{\"type\":\"object\",\"properties\":{\"numbers\":{\"type\":\"array\",\"items\":{\"type\":\"integer\"}}}}`,\n&nbsp; &nbsp; },\n}\n</code></pre><p>在我的工具定义的 Description 部分，我不仅写清楚了 AddTool 工具的作用，还举了一个例子，这样可以让大模型更好地理解。在Parameters部分，我使用了标准的 json schema 方式编写了参数名称、类型等，这样也有助于大模型准确理解。</p><p>在定义好工具后，我们需要在向大模型提问时，带上工具，因此 Chat Completions 增加了两个参数，一个是 Tools，用于接收 []openai.tool 列表；另一个参数是ToolChoice，用于设置让大模型使用工具还是不使用工具，一般设置为 “auto”，意思是让大模型自己根据实际情况选择是否调用工具。修改后的 chat 函数代码如下：</p><pre><code class=\"language-go\">func ToolsChat(message []openai.ChatCompletionMessage, tools []openai.Tool) openai.ChatCompletionMessage {\n&nbsp; &nbsp; c := NewOpenAiClient()\n&nbsp; &nbsp; rsp, err := c.CreateChatCompletion(context.TODO(), openai.ChatCompletionRequest{\n&nbsp; &nbsp; &nbsp; &nbsp; Model: &nbsp; &nbsp; &nbsp;\"qwen-turbo\",\n&nbsp; &nbsp; &nbsp; &nbsp; Messages: &nbsp; message,\n&nbsp; &nbsp; &nbsp; &nbsp; Tools: &nbsp; &nbsp; &nbsp;tools,\n&nbsp; &nbsp; &nbsp; &nbsp; ToolChoice: \"auto\",\n&nbsp; &nbsp; })\n&nbsp; &nbsp; if err != nil {\n&nbsp; &nbsp; &nbsp; &nbsp; log.Println(err)\n&nbsp; &nbsp; &nbsp; &nbsp; return openai.ChatCompletionMessage{}\n&nbsp; &nbsp; }\n\n\n&nbsp; &nbsp; return rsp.Choices[0].Message\n}\n</code></pre><p>有了这些基础，我们就可以向大模型提问，测试工具选择了。我们让大模型计算一下\"1+2=?\"</p><pre><code class=\"language-go\">func main() {\n&nbsp; &nbsp; toolsList := make([]openai.Tool, 0)\n&nbsp; &nbsp; toolsList = append(toolsList, tools.AddToolDefine, tools.SubToolDefine\n)\n\n\n&nbsp; &nbsp; prompt := \"1+2=? Just give me a number result\"\n&nbsp; &nbsp; ai.MessageStore.AddFor(ai.RoleUser, prompt)\n\n\n&nbsp; &nbsp; response := ai.ToolsChat(ai.MessageStore.ToMessage(), toolsList)\n&nbsp; &nbsp; toolCall := response.ToolCalls\n\n\n&nbsp; &nbsp; fmt.Println(\"大模型的回复是: \", response.Content)\n&nbsp; &nbsp; fmt.Println(\"大模型选择的工具是: \", toolCalls)\n}\n</code></pre><p>输出：</p><pre><code class=\"language-go\">大模型的回复是:&nbsp;&nbsp;\n大模型选择的工具是:&nbsp; [{0xc000284520 call_f31f9091de504216a3a84d function {AddTool {\"numbers\": [1, 2]}}}]\n</code></pre><p>可以看到大模型选择了工具 AddTool，并将参数按照我们的要求拆解成了 [1, 2] 这样一个切片。只要大模型选择了工具，则其回复就会是空字符串。</p><p>测试到这里，我们可以初步理解所谓大模型“调用”工具的机制。其实就是将工具用文字描述清楚，并和问题一起发送给大模型，由大模型判断选择哪个工具能解决问题。因此其实 Function Calling 这个表述我个人感觉并不准确，或许叫 Function Selecting 会更加没有歧义。</p><p><strong>这里我们可以得出两个结论：</strong></p><ol>\n<li>\n<p><strong>工具的定义也是 prompt，也就是要消耗</strong> <strong>token</strong> <strong>的。</strong></p>\n</li>\n<li>\n<p><strong>大模型只能选择使用工具！而不能调用工具！真正调用工具的仍然是人类！</strong></p>\n</li>\n</ol><p>最后我们看一下，人类如何调用工具，并将结果反馈给大模型，从而辅助大模型完成任务。</p><p>OpenAI 的 SDK 文档给出了说明，经过我简化后，方法如下：</p><pre><code class=\"language-json\">#1. 将提问存储到MessageStore\n{\"role\": \"user\", \"content\": \"1+2=? Just give me a number result\"}\n\n\n#开始进行第一轮提问....\n#得到大模型返回\n\n\n#2. 将大模型的返回，存储到MessageStore\n{\"role\": \"assistant\", \"content\": \"\", \"tool_calls\": [{0xc000284520 call_f31f9091de504216a3a84d function {AddTool {\"numbers\": [1, 2]}}}]\n}\n\n\n#3. 将工具调用信息，存储到MessageStore\n{\"role\": \"tool\", \"content\": \"3\", \"name\": \"AddTool\", \"tool_call_id\": \"call_f31f9091de504216a3a84d\"}\n\n\n#4. 开始进行第二轮提问，将上述所有Mesage，发送给大模型\n#得到大模型返回\n\n\n</code></pre><p>可以看到，相比正常的 user assistant 的多轮对话模式，Function Calling 的对话模式，只是略有不同，不同点在于第一要将大模型选择的工具添加到 assistant 对话中，第二是要在assistant 之后添加 tool 角色的消息，用于存储工具调用结果、工具名称以及 id。</p><p>理解了原理后，我们来看代码：</p><pre><code class=\"language-go\">if toolCalls != nil {\n&nbsp; &nbsp; var result int\n&nbsp; &nbsp; var args tools.InputArgs\n&nbsp; &nbsp; err := json.Unmarshal([]byte(toolCalls[0].Function.Arguments), &amp;args)\n&nbsp; &nbsp; if err != nil {\n&nbsp; &nbsp; &nbsp; &nbsp; log.Fatalln(\"json unmarshal err: \", err.Error())\n&nbsp; &nbsp; }\n\n\n&nbsp; &nbsp; if toolCalls[0].Function.Name == tools.AddToolDefine.Function.Name {\n&nbsp; &nbsp; &nbsp; &nbsp; result = tools.AddTool(args.Numbers)\n&nbsp; &nbsp; } else if toolCalls[0].Function.Name == tools.SubToolDefine.Function.Name {\n&nbsp; &nbsp; &nbsp; &nbsp; result = tools.SubTool(args.Numbers)\n&nbsp; &nbsp; }\n\n\n&nbsp; &nbsp; fmt.Println(\"函数计算结果: \", result)\n&nbsp; &nbsp; ai.MessageStore.AddFor(ai.RoleAssistant, response.Content, toolCalls)\n&nbsp; &nbsp; ai.MessageStore.AddForTool(string(result), toolCalls[0].Function.Name, toolCalls[0].ID)\n\n\n&nbsp; &nbsp; response := ai.ToolsChat(ai.MessageStore.ToMessage(), toolsList)\n\n\n&nbsp; &nbsp; fmt.Println(\"大模型的最终回复: \", response.Content)\n}\n</code></pre><p>首先判断一下大模型有没有调用工具，如果调用了，则从 toolCalls[0].Function.Arguments 中解析出函数入参。之后根据工具名称，调用相应的工具函数。最后按照上文中 OpenAI 规定的格式，将对应的 assistant 以及 tool 消息填好，反馈给大模型。</p><p>输出：</p><pre><code class=\"language-json\">函数计算结果:&nbsp; 3\n大模型的最终回复:&nbsp; 1 + 2 = 3\n</code></pre><h2>总结</h2><p>本节课我在开篇用了两个小例子为你展示了大模型不是万能的，大模型也有自身的弱点以及无法解决的问题，让你体验了一下什么是业界常说的“幻觉”。</p><p>OpenAI 公司为了解决这些问题，想到了让大模型与外界环境交互的破解之法，因此提出了 Function Calling 机制，并在 SDK 中进行了支持，在迅速成为了行业标杆做法后，其他公司包括国内公司的大模型，也对该机制进行了兼容，因此我们可以使用 OpenAI SDK 配合阿里云的通义千问大模型体验该机制。</p><p>最后我用一个加法小例子，为你展示了 Function Calling 的代码应如何写，并介绍了其前置基础 Chat Completion。本节课的代码已公开在 GitHub 上，链接为：<a href=\"https://github.com/xingyunyang01/Geek/tree/main/function-calling\">Geek/function-calling at main · xingyunyang01/Geek (github.com)</a></p><h2>思考题</h2><p>我在课程中的代码，为你演示了 “1+2=？” 这个小例子，如果是计算 “1+2+3+4-5-6=?” 呢？代码该如何编写？大模型能否给出正确的回答？</p><p>欢迎你在留言区展示你的思考过程，我们一起探讨。如果你觉得这节课的内容对你有帮助的话，也欢迎你分享给其他朋友，我们下节课再见！</p>","neighbors":{"left":{"article_title":"开篇词｜AI+云原生：孔明与刘备的互相成就","id":833565},"right":{"article_title":"02｜Agent的原理：什么是AI Agent？","id":833757}},"comments":[{"had_liked":false,"id":396592,"user_name":"刘蕾","can_delete":false,"product_type":"c1","uid":1899996,"ip_address":"斯洛伐克","ucode":"984D2C7E286DA1","user_header":"https://static001.geekbang.org/account/avatar/00/1c/fd/dc/8c394a51.jpg","comment_is_top":false,"comment_ctime":1735038356,"is_pvip":false,"replies":[{"id":143959,"content":"同学，你好！首先牢记文中的一个概念，大模型只能选择工具，向人类反馈，但不能执行工具调用（运行代码），真正执行工具调用（运行代码）的是人类。文中的例子中，喂给大模型的tools定义，是用文字对工具的名称，作用，参数的描述（其实就是prompt）。之后大模型选择工具返回后，我们可以在response.ToolCalls中拿到大模型选的什么工具。之后由人类执行工具调用，也就是文中最后一个代码块的这几行代码。\nif toolCalls[0].Function.Name == tools.AddToolDefine.Function.Name { result = tools.AddTool(args.Numbers) } else if toolCalls[0].Function.Name == tools.SubToolDefine.Function.Name { result = tools.SubTool(args.Numbers) }\n\nAddTool和SubTool就是真正执行加减法的函数。\n\n人类执行函数得到结果后，再下一轮对话中反馈给大模型，然后由大模型给出答案。\n\n可以去github上查看我的完整代码，加强理解哦。","user_name":"作者回复","user_name_real":"编辑","uid":1943646,"ctime":1735103399,"ip_address":"山东","comment_id":396592,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100845001,"comment_content":"没看懂，Tool里面没有定义加法实现。还是用大语言模型给出结果，这样用function call有什么好处?","like_count":2,"discussions":[{"author":{"id":1943646,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/a8/5e/791d0f5e.jpg","nickname":"最后的风之子","note":"","ucode":"45D5487480A5D2","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":655498,"discussion_content":"同学，你好！首先牢记文中的一个概念，大模型只能选择工具，向人类反馈，但不能执行工具调用（运行代码），真正执行工具调用（运行代码）的是人类。文中的例子中，喂给大模型的tools定义，是用文字对工具的名称，作用，参数的描述（其实就是prompt）。之后大模型选择工具返回后，我们可以在response.ToolCalls中拿到大模型选的什么工具。之后由人类执行工具调用，也就是文中最后一个代码块的这几行代码。\nif toolCalls[0].Function.Name == tools.AddToolDefine.Function.Name { result = tools.AddTool(args.Numbers) } else if toolCalls[0].Function.Name == tools.SubToolDefine.Function.Name { result = tools.SubTool(args.Numbers) }\n\nAddTool和SubTool就是真正执行加减法的函数。\n\n人类执行函数得到结果后，再下一轮对话中反馈给大模型，然后由大模型给出答案。\n\n可以去github上查看我的完整代码，加强理解哦。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1735103399,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"山东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]}]}