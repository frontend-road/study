{"id":73644,"title":"23 | 大数据基准测试可以带来什么好处？","content":"<p>2012年的时候，Hadoop已经日趋成熟，Intel的大数据团队也正准备寻找新的技术研究方向。当时，我们对比测试了多个新出来的大数据技术产品，最终选择了Spark重点跟进参与。现在看来，这是一个明智的决定，作出这个决定是基于大数据基准测试，而使用的对比测试工具就是我今天要讲的<span class=\"orange\">大数据基准测试工具HiBench</span>。</p><p>大数据作为一个生态体系，不但有各种直接进行大数据处理的平台和框架，比如HDFS、MapReduce、Spark，还有很多周边的支撑工具，而大数据基准测试工具就是其中一个大类。</p><h2>大数据基准测试的应用</h2><p>大数据基准测试的主要用途是对各种大数据产品进行测试，检验大数据产品在不同硬件平台、不同数据量、不同计算任务下的性能表现。</p><p>上面这样讲大数据基准测试的用途可能比较教条，我举两个例子你就能明白它的应用有多么重要了。</p><p>还是回到2012年，当时Hive只能做离线的SQL查询计算，无法满足数据分析师实时交互查询的需求，业界需要一款更快的ad hoc query（即席查询，一种非预设查询的SQL访问）工具。在这种情况下，Cloudera推出了准实时SQL查询工具Impala。Impala兼容Hive的Hive QL语法和Hive MetaSotre，也支持Hive存储在HDFS的数据表，但是放弃了Hive较慢的MapReduce执行引擎，而是基于MPP（Massively Parallel Processing，大规模并行处理）的架构思想重新开发了自己的执行引擎，从而获得更快的查询速度。</p><!-- [[[read_end]]] --><p>由于Cloudera在大数据领域的巨大权威，加上人们对快速SQL查询的期待，Impala在刚推出的时候，受到大数据业界的极大瞩目。当时，我也立即用四台服务器部署了一个小集群，利用大数据基准测试工具HiBench对Impala和Hive做了一个对比测试。</p><p><img src=\"https://static001.geekbang.org/resource/image/96/9b/961e6cc96cb0beb649d96bd21ed62b9b.png?wh=1920*811\" alt=\"\"></p><p>但是经过对比测试以后，我发现情况并不乐观。Impala性能有优势的地方在于聚合查询，也就是用group by查询的SQL语句；而对于连接查询，也就是用join查询的SQL语句性能表现很差。我进一步阅读Impala的源代码，对设计原理和架构进行分析后，得出了自己的看法，我认为适合Impala的应用场景有两类：</p><ul>\n<li>\n<p>一类是简单统计查询，对单表数据进行聚合查询，查看数据分布规律。</p>\n</li>\n<li>\n<p>一类是预查询，在进行全量数据的SQL查询之前，对抽样数据进行快速交互查询，验证数据分析师对数据的判断，方便数据分析师后续设计全量数据的查询SQL，而全量数据的SQL还是要运行在Hive上。</p>\n</li>\n</ul><p>这样Impala就有点尴尬了，它的定位似乎只是Hive的附属品。这就好比Impala是餐前开胃菜和餐后甜点，而正餐依然是Hive。</p><p>但是Cloudera却对Impala寄予厚望，后来我和Cloudera的工程师聊天，得知他们投入了公司近一半的工程师到Impala的开发上，我还是有点担心。事实上，这么多年过去了，Impala经过不断迭代，相比最开始的性能有了很大改进，但是我想，Impala依然没有承担起Cloudera对它的厚望。</p><p>跟Impala相对应的是，同样是2012年，Intel大数据团队用大数据基准测试工具HiBench对Spark和MapReduce做了对比测试后发现，Spark运行性能有令人吃惊的表现。当时Intel大数据团队的负责人戴老师（Jason Dai）立即飞到美国，跟当时开发Spark的UC Berkeley的AMP实验室交流，表示Intel愿意参与到Spark的开发中。Spark也极其希望有业界巨头能够参与其中，开发代码尚在其次，重要的是有了Intel这样的巨头背书，Spark会进一步得到业界的认可和接受。</p><p>所以Intel成了Spark最早的参与者，加速了Spark的开发和发展。当2013年Spark加入Apache的开源计划，并迅速成为Apache的顶级项目，风靡全球的大数据圈子时，Intel作为早期参与者，也得到了业界的肯定，使Intel在大数据领域可以保持持续的影响力。</p><p>在这个案例里，所有各方都是赢家，Spark、Intel、Apache，乃至整个大数据行业，我作为Intel参与Spark早期开发的工程师，也都因此而受益。这也是我关于工作的一个观点：好的工作不光是对公司有利，对员工也是有利的。工作不是公司在压榨员工的过程，而是公司创造价值，同时员工实现自我价值的过程。</p><p>而如何才能创造出好的工作也不只是公司的责任，主要还是要靠员工自己，去发现哪些事情能够让自己、公司、社会都获益，然后去推动这些事情的落实，虽然有的时候推动比发现更困难。同时拥有发现和推动能力的人，毫无例外都是一些出类拔萃的人，比如专栏前面也提到的Intel的戴老师，这些人都是我工作的榜样。</p><h2>大数据基准测试工具HiBench</h2><p>大数据基准测试工具有很多，今天我重点为你介绍前面我多次提到的，也是Intel推出的大数据基准测试工具<a href=\"http://github.com/intel-hadoop/HiBench\">HiBench</a>。</p><p>HiBench内置了若干主要的大数据计算程序作为基准测试的负载（workload）。</p><ul>\n<li>\n<p>Sort，对数据进行排序大数据程序。</p>\n</li>\n<li>\n<p>WordCount，前面多次提到过，词频统计大数据计算程序。</p>\n</li>\n<li>\n<p>TeraSort，对1TB数据进行排序，最早是一项关于软件和硬件的计算力的竞赛，所以很多大数据平台和硬件厂商进行产品宣传的时候会用TeraSort成绩作为卖点。</p>\n</li>\n<li>\n<p>Bayes分类，机器学习分类算法，用于数据分类和预测。</p>\n</li>\n<li>\n<p>k-means聚类，对数据集合规律进行挖掘的算法。</p>\n</li>\n<li>\n<p>逻辑回归，数据进行预测和回归的算法。</p>\n</li>\n<li>\n<p>SQL，包括全表扫描、聚合操作（group by）、连接操作（join）几种典型查询SQL。</p>\n</li>\n<li>\n<p>PageRank，Web排序算法。</p>\n</li>\n</ul><p>此外还有十几种常用大数据计算程序，支持的大数据框架包括MapReduce、Spark、Storm等。</p><p>对于很多非大数据专业人士而言，HiBench的价值不在于对各种大数据系统进行基准测试，而是学习大数据、验证自己大数据平台性能的工具。</p><p>对于一个刚刚开始入门大数据的工程师而言，在自己的电脑上部署了一个伪分布式的大数据集群可能并不复杂，对着网上的教程，顺利的话不到1个小时就可以拥有自己的大数据集群。</p><p>但是，接下来呢？开发MapReduce程序、打包、部署、运行，可能这里每一步都会遇到很多挫折。即使一切顺利，但顾名思义对于“大数据”来说，需要大量的数据才有意义，那数据从哪儿来呢？如果想用一些更复杂的应用体验下大数据的威力，可能遇到的挫折就更多了，所以很多人在安装了Hadoop以后，然后就放弃了大数据。</p><p>对于做大数据平台的工程师，如果等到使用者来抱怨自己维护的大数据平台不稳定、性能差的时候，可能就有点晚了，因为这些消息可能已经传到老板那里了。所以必须自己不停地跑一些测试，了解大数据平台的状况。</p><p>有了HiBench，这些问题都很容易就可以解决，HiBench内置了主要的大数据程序，支持多种大数据产品。最重要的是使用特别简单，初学者可以把HiBench当作学习工具，可以很快运行起各种数据分析和机器学习大数据应用。大数据工程师也可以用HiBench测试自己的大数据平台，验证各种大数据产品的性能。</p><p>HiBench使用非常简单，只需要三步：</p><p>1.配置，配置要测试的数据量、大数据运行环境和路径信息等基本参数。</p><p>2.初始化数据，生成准备要计算的数据，比如要测试1TB数据的排序，那么就生成1TB数据。</p><p>3.执行测试，运行对应的大数据计算程序。</p><p>具体初始化和执行命令也非常简单，比如要生成数据，只需要运行bin目录下对应workload的prepare.sh就可以自动生成配置大小的数据。</p><pre><code>bin/workloads/micro/terasort/prepare/prepare.sh\n</code></pre><p>要执行大数据计算，运行run.sh就可以了。</p><pre><code>bin/workloads/micro/terasort/hadoop/run.sh\nbin/workloads/micro/terasort/spark/run.sh\n</code></pre><h2>小结</h2><p>同一类技术问题的解决方案绝不会只有一个，技术产品也不会只有一个，比如大数据领域，从Hadoop到Spark再到Flink，各种大数据产品层出不穷，那么如何对比测试这些大数据产品，在不同的应用场景中它们各自的优势是什么？这个时候就需要用到基准测试工具，通过基准测试工具，用最小的成本得到我们想测试的结果。</p><p>所以除了大数据，在很多技术领域都有基准测试，比如数据库、操作系统、计算机硬件等。前几年手机领域的竞争聚焦在配置和性能上，各路发烧友们比较手机优劣的时候，口头禅就是“跑个分试试”，这也是一种基准测试。</p><p>因此基准测试对这些产品而言至关重要，甚至攸关生死。得到业界普遍认可的基准测试工具就是衡量这些产品优劣的标准，如果能使基准测试对自己的产品有利，更是涉及巨大的商业利益。我在Intel开始做SQL引擎开发，后来做Spark开发，需要调查各种数据库和大数据的基准测试工具，也就是在那个时候，我发现华为这家公司还是很厉害的，在很多基准测试标准的制定者和开发者名单中，都能看到华为的名字，而且几乎是唯一的中国公司。</p><p>有时候我们想要了解一个大数据产品的性能和用法，看了各种资料花了很多时间，最后得到的可能还是一堆不靠谱的N手信息。但自己跑一个基准测试，也许就几分钟的事，再花点时间看看测试用例，从程序代码到运行脚本，很快就能了解其基本用法，更加省时、高效。</p><h2>思考题</h2><p>今天文章的Impala VS Hive的基准测试报告里，发现当数量很大的时候做join查询，Impala会失去响应，是因为Impala比Hive更消耗内存，当内存不足时，就会失去响应。你能否从Impala的架构和技术原理角度分析为什么Impala比Hive更消耗内存？</p><p>欢迎你点击“请朋友读”，把今天的文章分享给好友。也欢迎你写下自己的思考或疑问，与我和其他同学一起讨论。</p><p></p>","neighbors":{"left":{"article_title":"22 | 从阿里内部产品看海量数据处理系统的设计（下）：架构与创新","id":73268},"right":{"article_title":"24 | 从大数据性能测试工具Dew看如何快速开发大数据系统","id":74031}},"comments":[{"had_liked":false,"id":51788,"user_name":"顾仲贤","can_delete":false,"product_type":"c1","uid":1107515,"ip_address":"","ucode":"2E2516A8916716","user_header":"https://static001.geekbang.org/account/avatar/00/10/e6/3b/2d14b5e1.jpg","comment_is_top":false,"comment_ctime":1545250413,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"130394269293","product_id":100020201,"comment_content":"当时有好友在Cloudera工作，聊起过Impala开发。Impala其实就是一个MPP的database execution engine, 但很多地方不成熟。最大的问题就是不支持spilling. 所以才导致很多operation会吃光内存，比如hash join, group by aggregation或sorting (一个趣事，Impala在执行order by语句会强制要求有limit语句)。但Hive是mapreduce engine本质对内存需求不大。","like_count":31},{"had_liked":false,"id":52707,"user_name":"阿神","can_delete":false,"product_type":"c1","uid":1014761,"ip_address":"","ucode":"E34BA27C101E9F","user_header":"https://static001.geekbang.org/account/avatar/00/0f/7b/e9/5955aa73.jpg","comment_is_top":false,"comment_ctime":1545483386,"is_pvip":false,"replies":[{"id":"19272","content":"spark的内存策略更多样，可以在内存不足时使用磁盘。最重要的，spark的rdd lineage，可以使spark针对一个分片进行溯源重建，容错能力非常强。","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1545617312,"ip_address":"","comment_id":52707,"utype":1}],"discussion_count":1,"race_medal":0,"score":"70264960122","product_id":100020201,"comment_content":"spark也是耗内存的，怎么就不会失去响应？","like_count":17,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":433953,"discussion_content":"spark的内存策略更多样，可以在内存不足时使用磁盘。最重要的，spark的rdd lineage，可以使spark针对一个分片进行溯源重建，容错能力非常强。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1545617312,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":85925,"user_name":"盖饭","can_delete":false,"product_type":"c1","uid":1436162,"ip_address":"","ucode":"5D108A9B89C3CF","user_header":"https://static001.geekbang.org/account/avatar/00/15/ea/02/c415b163.jpg","comment_is_top":false,"comment_ctime":1555293495,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"48799933751","product_id":100020201,"comment_content":"看来很多人都跟不上了，已经完全不是从0开始了😁","like_count":12},{"had_liked":false,"id":125305,"user_name":"Geek_8c4277","can_delete":false,"product_type":"c1","uid":1448066,"ip_address":"","ucode":"D68861FEE25660","user_header":"","comment_is_top":false,"comment_ctime":1566143511,"is_pvip":false,"replies":[{"id":"46430","content":"能解决问题就没问题~~<br>可以关注下ES","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1566300795,"ip_address":"","comment_id":125305,"utype":1}],"discussion_count":2,"race_medal":0,"score":"14451045399","product_id":100020201,"comment_content":"遇到大量数据的分组问题：有上亿条记录，十几个字段，需支持任意几个字段group by，还能分页查看与几秒响应，研究过一些方案，多数都只支持topN，要么就是响应慢，我们计划开发模块进行数据预生成，缺点就是组合多，老师觉得我们的思路有问题吗？","like_count":4,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":463521,"discussion_content":"能解决问题就没问题~~\n可以关注下ES","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1566300795,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1448066,"avatar":"","nickname":"Geek_8c4277","note":"","ucode":"D68861FEE25660","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":5583,"discussion_content":"已经考虑过es，也只能topN","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1566362006,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":55333,"user_name":"青铜5 周群力","can_delete":false,"product_type":"c1","uid":1111965,"ip_address":"","ucode":"EA80B442EC8A68","user_header":"https://static001.geekbang.org/account/avatar/00/10/f7/9d/c7295d17.jpg","comment_is_top":false,"comment_ctime":1546135600,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"14431037488","product_id":100020201,"comment_content":"老师能否推荐下性能优化、基准测试这方面更深入的书或其他学习资料?看了这几期有很多困惑，比如spark性能测试为啥选的是一个视频处理程序，为啥不用基准测试程序呢","like_count":4},{"had_liked":false,"id":68707,"user_name":"细小软也会有梦想","can_delete":false,"product_type":"c1","uid":1401292,"ip_address":"","ucode":"DAA235248904D9","user_header":"https://static001.geekbang.org/account/avatar/00/15/61/cc/82758c26.jpg","comment_is_top":false,"comment_ctime":1550581773,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10140516365","product_id":100020201,"comment_content":"我们公司都是跑TPCH和TPCDS进行跑分。","like_count":3},{"had_liked":false,"id":51800,"user_name":"ヾ(◍°∇°◍)ﾉﾞ","can_delete":false,"product_type":"c1","uid":1044175,"ip_address":"","ucode":"89545632BDA56E","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJOBwR7MCVqwZbPA5RQ2mjUjd571jUXUcBCE7lY5vSMibWn8D5S4PzDZMaAhRPdnRBqYbVOBTJibhJg/132","comment_is_top":false,"comment_ctime":1545264163,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5840231459","product_id":100020201,"comment_content":"这也许就是前面李老师说的抽象能力的体现吧。spark做的类似mapreduce的通用计算而且体验上非常好。这点很重要。而impala和presto由于过于关注响应时延 ，导致其关注的需求并不太通用,同时它的确解决了一些场景比spark好。但是场景太局限","like_count":2},{"had_liked":false,"id":258413,"user_name":"雄鹰","can_delete":false,"product_type":"c1","uid":1786819,"ip_address":"","ucode":"67E0C4BDE7F6F2","user_header":"https://static001.geekbang.org/account/avatar/00/1b/43/c3/2c53acd7.jpg","comment_is_top":false,"comment_ctime":1604417422,"is_pvip":true,"replies":[{"id":"94244","content":"免密登录是大数据集群运维的常规手段，CDH集群管理也是要求免密登录的。","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1604629851,"ip_address":"","comment_id":258413,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1604417422","product_id":100020201,"comment_content":"老师你好，利用HiBench测试Hadoop的基准测试时，集群服务器之间必须要设置成ssh免密登录吗？","like_count":0,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":508644,"discussion_content":"免密登录是大数据集群运维的常规手段，CDH集群管理也是要求免密登录的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1604629851,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":199438,"user_name":"Geek_b8928e","can_delete":false,"product_type":"c1","uid":1926597,"ip_address":"","ucode":"96E4ABE3F2F145","user_header":"","comment_is_top":false,"comment_ctime":1585489117,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1585489117","product_id":100020201,"comment_content":"大数据基准测试的主要用途是对各种大数据产品进行测试，检验大数据产品在不同硬件平台、不同数据量、不同计算任务下的性能表现。<br>HiBench 内置了若干主要的大数据计算程序作为基准测试的负载（workload）。<br>Sort，对数据进行排序大数据程序。<br>WordCount，词频统计大数据计算程序。<br>TeraSort，对 1TB 数据进行排序。<br>Bayes 分类，机器学习分类算法，用于数据分类和预测。<br>k-means 聚类，对数据集合规律进行挖掘的算法。<br>逻辑回归，数据进行预测和回归的算法。<br>SQL，包括全表扫描、聚合操作（group by）、连接操作（join）几种典型查询 SQL。<br>PageRank，Web 排序算法。","like_count":0},{"had_liked":false,"id":192202,"user_name":"小熊","can_delete":false,"product_type":"c1","uid":1634686,"ip_address":"","ucode":"9E4CD1DA292076","user_header":"https://static001.geekbang.org/account/avatar/00/18/f1/7e/8925aba5.jpg","comment_is_top":false,"comment_ctime":1584843032,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1584843032","product_id":100020201,"comment_content":"一直很想学习大数据方面的知识，看到极客时间有这个课程就马上订阅了。看到老师的一些经历，对我也很有触动，向老师学习，继续努力","like_count":0},{"had_liked":false,"id":137286,"user_name":"钱","can_delete":false,"product_type":"c1","uid":1009652,"ip_address":"","ucode":"2C92A243A463D4","user_header":"https://static001.geekbang.org/account/avatar/00/0f/67/f4/9a1feb59.jpg","comment_is_top":false,"comment_ctime":1569677848,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1569677848","product_id":100020201,"comment_content":"基准测试——就是对一个产品全方位的各种测试，用于评估这个东西在各方面的性能情况。<br>HiBench值得尝试。<br>数据量比较大时Impala的join就不行了，猜测她的join操作会把数据都拿到内存中关联，即使内存不足了也不留一些活命，自己把自己活动空间给挤没啦！","like_count":1},{"had_liked":false,"id":52588,"user_name":"aof","can_delete":false,"product_type":"c1","uid":1062864,"ip_address":"","ucode":"5815D63C4926BC","user_header":"https://static001.geekbang.org/account/avatar/00/10/37/d0/26975fba.jpg","comment_is_top":false,"comment_ctime":1545446623,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1545446623","product_id":100020201,"comment_content":"数据计算，中间结果都是放在内存，如果数据量大了之后，内存就不够用了","like_count":0}]}