{"id":803829,"title":"02｜从0到1快速搭建RAG应用","content":"<blockquote>\n<p><span class=\"reference\">本门课程为精品小课，不标配音频</span></p>\n</blockquote><p>你好，我是常扬。</p><p>上节课我们详细探讨了RAG（Retrieval-Augmented Generation, 检索增强生成）的技术背景、应用场景以及技术流程。这节课我们将进入代码实战，<strong>从0到1快速搭建RAG应用</strong>。我们会使用广泛流行的开源库搭建核心框架，完成RAG流程的代码构建。后续课程将基于这节课的实战项目，进一步深入分析各流程的核心技术细节及应用优化，提供更多技术选型的建议和实战代码。</p><p>这节课代码实战内容包括技术框架的介绍与选型、开发环境搭建与技术库安装、RAG流程的代码实现。所有相关代码我都会公开在Gitee平台上，供你参考和使用。</p><h2>技术框架与选型</h2><p>我们先来探讨RAG技术的框架与选型问题。我们课程中的选型并非适用于所有场景的最佳方案，而是基于当前广泛应用和流行的技术模块。关于这些模块的具体特点以及可能的替代选型，我们会在后续课程中进行详细分析与解读。</p><p><strong>RAG技术框架：LangChain</strong></p><p>LangChain是专为开发基于大型语言模型（LLM）应用而设计的全面框架，其核心目标是简化开发者的构建流程，使其能够高效创建LLM驱动的应用。</p><p><strong>索引流程 - 文档解析模块：pypdf</strong></p><p>pypdf是一个开源的Python库，专门用于处理PDF文档。pypdf支持PDF文档的创建、读取、编辑和转换操作，能够有效提取和处理文本、图像及页面内容。</p><!-- [[[read_end]]] --><p><strong>索引流程 - 文档分块模块：RecursiveCharacterTextSplitter</strong></p><p>采用LangChain默认的文本分割器-RecursiveCharacterTextSplitter。该分割器通过层次化的分隔符（从双换行符到单字符）拆分文本，旨在保持文本的结构和连贯性，优先考虑自然边界如段落和句子。</p><p><strong>索引/检索流程 - 向量化模型：bge-small-zh-v1.5</strong></p><p>bge-small-zh-v1.5是由北京人工智能研究院（BAAI，智源）开发的开源向量模型。虽然模型体积较小，但仍然能够提供高精度和高效的中文向量检索。该模型的向量维度为512，最大输入长度同样为512。</p><p><strong>索引/检索流程 - 向量库：Faiss</strong></p><p>Faiss全称Facebook AI Similarity Search，由Facebook AI Research团队开源的向量库，因其稳定性和高效性在向量检索领域广受欢迎。</p><p><strong>生成流程 - 大语言模型：通义千问 Qwen</strong></p><p>通义千问Qwen是阿里云推出的一款超大规模语言模型，支持多轮对话、文案创作、逻辑推理、多模态理解以及多语言处理，在模型性能和工程应用中表现出色。采用云端API服务，注册有1,000,000 token的免费额度。</p><p>上述选型在RAG流程图中的应用如下所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/65/c0/65a9694a63bdb6108504f9586c0a05c0.jpg?wh=1920x866\" alt=\"图片\"></p><ul>\n<li><strong>LangChain：</strong>提供用于构建LLM RAG的应用程序框架。</li>\n<li><strong>索引流程：</strong>使用 <strong>pypdf</strong> 对文档进行解析并提取信息；随后，采用 <strong>RecursiveCharacterTextSplitter</strong> 对文档内容进行分块（chunks）；最后，利用 <strong>bge-small-zh-v1.5</strong> 将分块内容进行向量化处理，并将生成的向量存储在 <strong>Faiss</strong> 向量库中。</li>\n<li><strong>检索流程：</strong>使用 <strong>bge-small-zh-v1.5</strong> 对用户的查询（Query）进行向量化处理；然后，通过 <strong>Faiss</strong> 向量库对查询向量和文本块向量进行相似度匹配，从而检索出与用户查询最相似的前 <strong>top-k</strong> 个文本块（chunk）。</li>\n<li><strong>生成流程：</strong>通过设定提示模板（Prompt），将用户的查询与检索到的参考文本块组合输入到 <strong>Qwen</strong> 大模型中，生成最终的 RAG 回答。</li>\n</ul><h2>开发环境与技术库</h2><p>我们采用Python编程语言，Python版本3.8及以上，运行于Linux操作系统下。结合上述的技术框架与选型，我们的开发环境需要按照以下步骤进行准备：</p><ol>\n<li><strong>创建并激活虚拟环境</strong>：目的是隔离项目依赖，避免项目之间冲突。先在命令行窗口中执行指令定位到具体的RAG项目文件夹，然后在命令行中执行以下指令：</li>\n</ol><pre><code class=\"language-plain\">python3 -m venv rag_env  # 创建名为rag_env的虚拟环境\nsource rag_env/bin/activate  # 激活虚拟环境\n</code></pre><ol start=\"2\">\n<li><strong>安装技术依赖库</strong>：包括langchain、langchain_community LLM RAG的技术框架及其扩展，pypdf 处理PDF文档的解析库，sentence-transformers 运行指定文本嵌入模型 bge-small-zh-v1.5 的模型库，faiss-cpu 高效相似度搜索的 Faiss 向量库，dashscope 与阿里云Qwen大模型API的集成库。</li>\n</ol><p>首先，升级pip版本，以确保兼容性，在命令行中执行以下指令：</p><pre><code class=\"language-plain\">pip install --upgrade pip  # 升级pip版本以确保兼容性\n</code></pre><p>然后，安装上述技术依赖库，在命令行中执行以下指令：</p><pre><code class=\"language-plain\">pip install langchain langchain_community pypdf sentence-transformers faiss-cpu dashscope\n</code></pre><p>如果无法连接，可以使用国内镜像站点，在命令行中执行以下指令：</p><pre><code class=\"language-plain\">pip install langchain langchain_community pypdf sentence-transformers faiss-cpu dashscope -i https://pypi.tuna.tsinghua.edu.cn/simple&nbsp;\n</code></pre><ol start=\"3\">\n<li><strong>下载bge-small-zh-v1.5模型</strong>：该模型的文件已包含在 Gitee 上托管的项目中的 <strong>bge-small-zh-v1.5</strong> 文件夹内，你可以直接下载到RAG项目的根目录中，模型大小95.8M，在命令行中执行以下指令：</li>\n</ol><pre><code class=\"language-plain\">git clone https://gitee.com/techleadcy/rag_app.git\n</code></pre><p>下载过程需要一些时间，不要关闭命令行窗口。下载完成后，检查 rag_app 项目中 bge-small-zh-v1.5 文件夹中是否包含pytorch_model.bin文件。该库中同时包含了本讲的RAG核心流程代码rag_app_lesson2.py及测试PDF文档test_lesson2.pdf。</p><ol>\n<li><strong>准备测试 PDF 文档</strong>：Gitee 上托管的项目中包含一份名为 test_lesson2.pdf 的数字化转型报告。这个报告涵盖了数字化转型的背景和意义、案例分析，以及制造业、零售业、金融业的数字化转型等章节。你也可以替换成自己的 PDF 文件，并更改查询问题，体验 RAG 应用的效果。</li>\n</ol><p>完成以上步骤后，RAG应用开发所需的环境及技术依赖库就已准备就绪。</p><h2>RAG核心流程代码</h2><p>在实战过程中，你不仅可以快速构建RAG应用，还能够在研发过程中深入理解其背后的技术逻辑与核心原理。为此，我在代码的每一行添加了必要的注释，并对每段流程代码进行了归纳和解释，旨在通过实战代码增强你对RAG技术的理解。</p><p>整个流程代码分为模块库的引入、索引流程、检索流程、生成流程以及测试代码几部分进行精细讲解，具体的代码位于Gitee项目库中的rag_app_lesson2.py文件中。</p><p><strong>模块库的引入</strong></p><pre><code class=\"language-plain\">from langchain_community.document_loaders import PyPDFLoader # PDF文档提取\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter # 文档拆分chunk\nfrom sentence_transformers import SentenceTransformer # 加载和使用Embedding模型\nimport faiss # Faiss向量库\nimport numpy as np # 处理嵌入向量数据，用于Faiss向量检索\nimport dashscope #调用Qwen大模型\nfrom http import HTTPStatus #检查与Qwen模型HTTP请求状态\n\nimport os # 引入操作系统库，后续配置环境变量与获得当前文件路径使用\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" # 不使用分词并行化操作, 避免多线程或多进程环境中运行多个模型引发冲突或死锁\n\n# 设置Qwen系列具体模型及对应的调用API密钥，从阿里云百炼大模型服务平台获得\nqwen_model = \"qwen-turbo\"\nqwen_api_key = \"your_api_key\"\n</code></pre><p>阿里云百炼大模型服务平台获取的<strong>Qwen大模型</strong>的API密钥流程如下：</p><ol>\n<li>打开<a href=\"https://www.aliyun.com/product/bailian\">阿里云百炼大模型服务平台</a> ，点击立即开通，登陆阿里云/支付宝/钉钉账号；</li>\n<li>点击模型广场，搜索 通义千问-Turbo，点击API 调用示例；</li>\n<li>点击查看我的API-KEY，继续点击弹出框中的查看，复制API-KEY，将API-KEY替换代码中qwen_api_key = “your_api_key”；</li>\n<li>点击模型详情，可以看到模型Model英文名称，赋值qwen_model参数。可以看到剩余额度，当前阿里云提供1,000,000次的免费模型额度；</li>\n<li>如果需要尝试其他模型，可以对应赋值上述代码中qwen_model参数及qwen_api_key参数。</li>\n</ol><p>以上代码导入了我们在RAG流程中需要使用的核心模块及大模型参数等配置，这些模块和配置将在后续的索引、检索和生成流程中调用使用。</p><p><strong>索引流程</strong></p><pre><code class=\"language-plain\">def load_embedding_model():\n    \"\"\"\n    加载bge-small-zh-v1.5模型\n    :return: 返回加载的bge-small-zh-v1.5模型\n    \"\"\"\n    print(f\"加载Embedding模型中\")\n    # SentenceTransformer读取绝对路径下的bge-small-zh-v1.5模型，非下载\n    embedding_model = SentenceTransformer(os.path.abspath('rag_app/bge-small-zh-v1.5'))\n    print(f\"bge-small-zh-v1.5模型最大输入长度: {embedding_model.max_seq_length}\") \n    return embedding_model\n\n\ndef indexing_process(pdf_file, embedding_model):\n    \"\"\"\n    索引流程：加载PDF文件，并将其内容分割成小块，计算这些小块的嵌入向量并将其存储在FAISS向量数据库中。\n    :param pdf_file: PDF文件路径\n    :param embedding_model: 预加载的嵌入模型\n    :return: 返回Faiss嵌入向量索引和分割后的文本块原始内容列表\n    \"\"\"\n    # PyPDFLoader加载PDF文件，忽略图片提取\n    pdf_loader = PyPDFLoader(pdf_file, extract_images=False)\n    # 配置RecursiveCharacterTextSplitter分割文本块库参数，每个文本块的大小为512字符（非token），相邻文本块之间的重叠128字符（非token）\n    text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=512, chunk_overlap=128\n    )\n    # 加载PDF文档,提取所有页的文本内容\n    pdf_content_list = pdf_loader.load()\n    # 将每页的文本内容用换行符连接，合并为PDF文档的完整文本\n    pdf_text = \"\\n\".join([page.page_content for page in pdf_content_list])\n    print(f\"PDF文档的总字符数: {len(pdf_text)}\") \n\n    # 将PDF文档文本分割成文本块Chunk\n    chunks = text_splitter.split_text(pdf_text)\n    print(f\"分割的文本Chunk数量: {len(chunks)}\") \n\n    # 文本块转化为嵌入向量列表，normalize_embeddings表示对嵌入向量进行归一化，用于准确计算相似度\n    embeddings = []\n    for chunk in chunks:\n        embedding = embedding_model.encode(chunk, normalize_embeddings=True)\n        embeddings.append(embedding)\n\n    print(\"文本块Chunk转化为嵌入向量完成\")\n\n    # 将嵌入向量列表转化为numpy数组，Faiss向量库操作需要numpy数组输入\n    embeddings_np = np.array(embeddings)\n\n    # 获取嵌入向量的维度（每个向量的长度）\n    dimension = embeddings_np.shape[1]\n\n    # 使用余弦相似度创建FAISS索引\n    index = faiss.IndexFlatIP(dimension)\n    # 将所有的嵌入向量添加到FAISS索引中，后续可以用来进行相似性检索\n    index.add(embeddings_np)\n\n    print(\"索引过程完成.\")\n\n    return index, chunks\n</code></pre><p>上述代码实现了RAG技术中的索引流程，首先使用 <strong>PyPDFLoader</strong> 加载并预处理PDF文档，将其内容提取并合并为完整文本。接着，利用 <strong>RecursiveCharacterTextSplitter</strong> 将文本分割为每块512字符（非token）、重叠128字符（非token）的文本块，并通过预加载的 <strong>bge-small-zh-v1.5</strong> 嵌入模型将这些文本块转化为归一化的嵌入向量。最终，这些嵌入向量被存储在基于余弦相似度的 <strong>Faiss</strong> 向量库中，以支持后续的相似性检索和生成任务。</p><p>为更清晰地展示RAG流程的各个细节，当前代码未涉及多文档处理、嵌入模型的效率优化与并行处理。此外，<strong>Faiss</strong> 向量目前仅在内存中存储，未考虑持久化存储问题。以及文档解析、文本分块、嵌入模型与向量库的技术选型，后续课程将逐步深入探讨，并以上述代码作为基础，持续优化。</p><p><strong>检索流程</strong></p><pre><code class=\"language-plain\">def retrieval_process(query, index, chunks, embedding_model, top_k=3):\n    \"\"\"\n    检索流程：将用户查询Query转化为嵌入向量，并在Faiss索引中检索最相似的前k个文本块。\n    :param query: 用户查询语句\n    :param index: 已建立的Faiss向量索引\n    :param chunks: 原始文本块内容列表\n    :param embedding_model: 预加载的嵌入模型\n    :param top_k: 返回最相似的前K个结果\n    :return: 返回最相似的文本块及其相似度得分\n    \"\"\"\n    # 将查询转化为嵌入向量，normalize_embeddings表示对嵌入向量进行归一化\n    query_embedding = embedding_model.encode(query, normalize_embeddings=True)\n    # 将嵌入向量转化为numpy数组，Faiss索引操作需要numpy数组输入\n    query_embedding = np.array([query_embedding])\n\n    # 在 Faiss 索引中使用 query_embedding 进行搜索，检索出最相似的前 top_k 个结果。\n    # 返回查询向量与每个返回结果之间的相似度得分（在使用余弦相似度时，值越大越相似）排名列表distances，最相似的 top_k 个文本块在原始 chunks 列表中的索引indices。\n    distances, indices = index.search(query_embedding, top_k)\n\n    print(f\"查询语句: {query}\")\n    print(f\"最相似的前{top_k}个文本块:\")\n\n    # 输出查询出的top_k个文本块及其相似度得分\n    results = []\n    for i in range(top_k):\n        # 获取相似文本块的原始内容\n        result_chunk = chunks[indices[0][i]]\n        print(f\"文本块 {i}:\\n{result_chunk}\") \n\n        # 获取相似文本块的相似度得分\n        result_distance = distances[0][i]\n        print(f\"相似度得分: {result_distance}\\n\")\n\n        # 将相似文本块存储在结果列表中\n        results.append(result_chunk)\n\n    print(\"检索过程完成.\")\n    return results\n</code></pre><p>上述代码实现了RAG技术中的检索流程。首先，用户的查询（Query）被预加载的 <strong>bge-small-zh-v1.5</strong> 嵌入模型转化为归一化的嵌入向量，进一步转换为 <strong>numpy</strong> 数组以适配 <strong>Faiss</strong> 向量库的输入格式。然后，利用 <strong>Faiss</strong> 向量库中的向量检索功能，计算查询向量与存储向量之间的余弦相似度，从而筛选出与查询最相似的前 <strong>top_k</strong> 个文本块。这些文本块及其相应的相似度得分被逐一输出，相似文本块存储在结果列表中，最终返回供后续生成过程使用。</p><p><strong>生成流程</strong></p><pre><code class=\"language-plain\">def generate_process(query, chunks):\n    \"\"\"\n    生成流程：调用Qwen大模型云端API，根据查询和文本块生成最终回复。\n    :param query: 用户查询语句\n    :param chunks: 从检索过程中获得的相关文本块上下文chunks\n    :return: 返回生成的响应内容\n    \"\"\"\n    # 设置Qwen系列具体模型及对应的调用API密钥，从阿里云大模型服务平台百炼获得\n    llm_model = qwen_model\n    dashscope.api_key = qwen_api_key\n\n    # 构建参考文档内容，格式为“参考文档1: \\n 参考文档2: \\n ...”等\n    context = \"\"\n    for i, chunk in enumerate(chunks):\n        context += f\"参考文档{i+1}: \\n{chunk}\\n\\n\"\n\n    # 构建生成模型所需的Prompt，包含用户查询和检索到的上下文\n    prompt = f\"根据参考文档回答问题：{query}\\n\\n{context}\"\n    print(f\"生成模型的Prompt: {prompt}\")\n\n    # 准备请求消息，将prompt作为输入\n    messages = [{'role': 'user', 'content': prompt}]\n\n    # 调用大模型API云服务生成响应\n    try:\n        responses = dashscope.Generation.call(\n            model = llm_model,\n            messages=messages,\n            result_format='message',  # 设置返回格式为\"message\"\n            stream=True,              # 启用流式输出\n            incremental_output=True   # 获取流式增量输出\n        )\n        # 初始化变量以存储生成的响应内容\n        generated_response = \"\"\n        print(\"生成过程开始:\")\n        # 逐步获取和处理模型的增量输出\n        for response in responses:\n            if response.status_code == HTTPStatus.OK:\n                content = response.output.choices[0]['message']['content']\n                generated_response += content\n                print(content, end='')  # 实时输出模型生成的内容\n            else:\n                print(f\"请求失败: {response.status_code} - {response.message}\")\n                return None  # 请求失败时返回 None\n        print(\"\\n生成过程完成.\")\n        return generated_response\n    except Exception as e:\n        print(f\"大模型生成过程中发生错误: {e}\")\n        return None\n</code></pre><p>上述代码实现了RAG流程中的生成过程。首先，结合用户查询与检索到的文本块内容组织成大模型提示词（Prompt）。随后，代码通过调用 <strong>Qwen 大模型云端 API</strong>，将构建好的Prompt发送给大模型，并利用流式输出的方式逐步获取模型生成的响应内容，实时输出并汇总为最终的生成结果。</p><p><strong>测试脚本</strong></p><pre><code class=\"language-plain\">def main():\n    print(\"RAG过程开始.\")\n\n    query=\"下面报告中涉及了哪几个行业的案例以及总结各自面临的挑战？\"\n    embedding_model = load_embedding_model()\n\n    # 索引流程：加载PDF文件，分割文本块，计算嵌入向量，存储在FAISS向量库中（内存）\n    index, chunks = indexing_process('rag_app/test_lesson2.pdf', embedding_model)\n\n    # 检索流程：将用户查询转化为嵌入向量，检索最相似的文本块\n    retrieval_chunks = retrieval_process(query, index, chunks, embedding_model)\n\n    # 生成流程：调用Qwen大模型生成响应\n    generate_process(query, retrieval_chunks)\n\n    print(\"RAG过程结束.\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre><p>在命令行窗口中执行指令定位到具体的RAG项目文件夹，在命令行中执行以下指令即可开始RAG应用测试：</p><pre><code class=\"language-plain\">source rag_env/bin/activate  # 激活虚拟环境\npython rag_app/rag_app_lesson2.py # 执行RAG应用脚本\n</code></pre><p>测试代码通过 <code>main()</code> 函数串联各个步骤，从索引到生成，确保RAG的各个环节顺畅执行，准确完成“下面报告中涉及了哪几个行业的案例以及总结各自面临的挑战？”的RAG问答任务。</p><p>正确运行结果如下所示：</p><pre><code class=\"language-plain\">RAG过程开始.\n加载Embedding模型中\nbge-small-zh-v1.5模型最大输入长度token: 512\nPDF文档的总字符数: 9135\n分割的文本Chunk数量: 24\n文本块Chunk转化为嵌入向量完成\n索引过程完成.\n\n查询语句: 下面报告中涉及了哪几个行业的案例以及总结各自面临的挑战？\n最相似的前3个文本块:\n文本块 0: 面的数字化转型。2.3.2面临的挑战：......相似度得分: 0.5915016531944275\n文本块 1: ...... 相似度得分: 0.5728524327278137\n文本块 2: ...... 相似度得分: 0.5637902617454529\n检索过程完成.\n\n生成模型的Prompt: 根据参考文档回答问题：下面报告中涉及了哪几个行业的案例以及总结各自面临的挑战？\n参考文档1: 面的数字化转型。2.3.2面临的挑战...\n参考文档2: ......\n参考文档3: ......\n\n生成过程开始:\n参考文档中涉及了三个行业的案例及其面临的挑战：\n1.### 制造业...... 2. ### 零售业......  3. ### 金融业......\n### 数字化转型解决方案概述\n-**制造业**：...... -**零售业**：...... -**金融业**：......\n这些案例强调了不同行业在数字化转型过程中面临的独特挑战......\n生成过程完成.\nRAG过程结束.\n</code></pre><h2>总结</h2><p>这节课我通过代码实战向你展示了RAG技术的完整实现过程，涵盖了<strong>索引、检索、生成</strong>三个核心流程。上述代码已公开在Gitee代码仓库中，链接地址为：<a href=\"https://gitee.com/techleadcy/rag_app\">https://gitee.com/techleadcy/rag_app</a>。</p><p>技术选型方面，我们选择了 LangChain 作为核心框架，结合 pypdf 用于PDF文档解析，RecursiveCharacterTextSplitter 用于文本分块，bge-small-zh-v1.5 作为嵌入模型，Faiss 作为向量检索库，以及阿里云的Qwen大模型用于生成任务。</p><p>代码实战中，我们依次完成了嵌入模型的加载、PDF文档的解析与文本分块、向量化嵌入与Faiss向量库的构建、用户查询的检索匹配，以及最终的生成模型调用。</p><p>这节课的实战内容为后续课程奠定了基础，后续课程将深入讲解每个技术流程的细节，并在此实战项目基础上对代码进行持续优化和迭代。</p><h2>思考题</h2><p>我们基于上述技术组件快速搭建了RAG应用，实现了其核心流程。然而，在真实的应用场景中，可能还需要补充一些关键组件才能更好、更优地满足用户需求，需要补充哪些关键组件呢？欢迎你在留言区补充，描述它们的作用，我们共同完善RAG应用效果，如果你觉得这节课的内容对你有帮助的话，也欢迎你分享给其他朋友，我们下节课再见！</p>","neighbors":{"left":{"article_title":"01｜RAG的场景及技术原理","id":803750},"right":{"article_title":"03｜RAG 索引（一）：文档解析技术","id":804324}},"comments":[{"had_liked":false,"id":395139,"user_name":"张申傲","can_delete":false,"product_type":"c1","uid":1182372,"ip_address":"北京","ucode":"22D46BC529BA8A","user_header":"https://static001.geekbang.org/account/avatar/00/12/0a/a4/828a431f.jpg","comment_is_top":false,"comment_ctime":1729579280,"is_pvip":false,"replies":[{"id":143483,"content":"点赞👍","user_name":"作者回复","user_name_real":"编辑","uid":3954065,"ctime":1729650872,"ip_address":"上海","comment_id":395139,"utype":1}],"discussion_count":1,"race_medal":2,"score":2,"product_id":100804101,"comment_content":"第2讲打卡~\n对本节课的代码进行了重构：将整体流程拆分成了initiator、indexer、retriever、generator和app模块，并使用LangChain的BaseChatModel、Embeddings、VectorStore组件对相关功能进行了重写。欢迎大家一起交流：https:&#47;&#47;gitee.com&#47;zhangshenao&#47;happy-rag&#47;tree&#47;master&#47;RAG%E5%BF%AB%E9%80%9F%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98&#47;1-%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BARAG%E5%BA%94%E7%94%A8 ","like_count":2,"discussions":[{"author":{"id":3954065,"avatar":"https://static001.geekbang.org/account/avatar/00/3c/55/91/e3c96b88.jpg","nickname":"常扬","note":"","ucode":"11B62CDABBE875","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":652800,"discussion_content":"点赞👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1729650872,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":394069,"user_name":"无处不在","can_delete":false,"product_type":"c1","uid":1157533,"ip_address":"北京","ucode":"BB535BC6F448F4","user_header":"https://static001.geekbang.org/account/avatar/00/11/a9/9d/bdfd9e58.jpg","comment_is_top":false,"comment_ctime":1725707973,"is_pvip":false,"replies":[{"id":143081,"content":"RAG的本质是检索，不仅知识库问答。AI Search是一个广泛场景。Agent你说的是对的，RAG除了本身独立做知识库问答、AI search场景外，就是作为一个功能组件，镶嵌到场景流程中，可以在agent中，也可以在我们现有业务流程需要结合独有知识、实时知识做智能推理的业务场景。","user_name":"作者回复","user_name_real":"编辑","uid":3954065,"ctime":1726012704,"ip_address":"上海","comment_id":394069,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100804101,"comment_content":"感谢老师的讲解，我用智普AI也可以运行了，代码如下：\n # 调用大模型API云服务生成响应\n    try:\n        # 调用智普大模型处理\n        client = ZhipuAI(api_key=&quot;&quot;) \n        responses = client.chat.completions.create(\n            model=&quot;glm-4-flash&quot;,  # 填写需要调用的模型编码\n            messages=messages,\n            stream=True\n        )\n\n        # 初始化变量以存储生成的响应内容\n        generated_response = &quot;&quot;\n        print(&quot;生成过程开始:&quot;)\n        # 逐步获取和处理模型的增量输出\n        for chunk in responses:\n            \n            content = chunk.choices[0].delta.content;\n            generated_response += content\n            print(content, end=&#39;&#39;)  # 实时输出模型生成的内容\n          \n        print(&quot;\\n生成过程完成.&quot;)\n        return generated_response\n    except Exception as e:\n        print(f&quot;大模型生成过程中发生错误: {e}&quot;)\n        return None\n我一直有个疑问，就是感觉RAG好像就是做知识库之类的有重大价值，除了知识库我想了解下对于我们做后端研发的同学，如何把这个东西在企业中更好落地，目前我感觉企业中好像就是通过AI Agent之类的作为结合RAG的使用。","like_count":1,"discussions":[{"author":{"id":3954065,"avatar":"https://static001.geekbang.org/account/avatar/00/3c/55/91/e3c96b88.jpg","nickname":"常扬","note":"","ucode":"11B62CDABBE875","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":650982,"discussion_content":"RAG的本质是检索，不仅知识库问答。AI Search是一个广泛场景。Agent你说的是对的，RAG除了本身独立做知识库问答、AI search场景外，就是作为一个功能组件，镶嵌到场景流程中，可以在agent中，也可以在我们现有业务流程需要结合独有知识、实时知识做智能推理的业务场景。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1726012704,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":393949,"user_name":"grok","can_delete":false,"product_type":"c1","uid":1341502,"ip_address":"美国","ucode":"4744AB3FA28FE2","user_header":"https://static001.geekbang.org/account/avatar/00/14/78/3e/f60ea472.jpg","comment_is_top":false,"comment_ctime":1725418694,"is_pvip":false,"replies":[{"id":143048,"content":"感谢！分享给更多海外的开发者。","user_name":"作者回复","user_name_real":"编辑","uid":3954065,"ctime":1725626283,"ip_address":"上海","comment_id":393949,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100804101,"comment_content":"海外用户，试着开通了阿里云，但是没有任何免费额度。。  perplexity pro每个月会赠送5刀的API credit.  核心代码如下 (在 `generate_process()`)：\n```\n    client = OpenAI(api_key=YOUR_API_KEY, base_url=&quot;https:&#47;&#47;api.perplexity.ai&quot;)\n\n    # chat completion with streaming\n    try:\n        response_stream = client.chat.completions.create(\n            model=&quot;llama-3.1-70b-instruct&quot;,\n            messages=messages,\n            stream=True,\n        )\n\n        # Initialize variable to store the generated response content\n        generated_response = &quot;&quot;\n        print(&quot;生成过程开始:&quot;)\n\n        # Process the model&#39;s incremental output\n        for chunk in response_stream:\n            if chunk.choices[0].delta.content is not None:\n                content = chunk.choices[0].delta.content\n                generated_response += content\n                print(content, end=&#39;&#39;)  # 实时输出模型生成的内容\n\n        print(&quot;\\n生成过程完成.&quot;)\n        return generated_response\n```","like_count":1,"discussions":[{"author":{"id":3954065,"avatar":"https://static001.geekbang.org/account/avatar/00/3c/55/91/e3c96b88.jpg","nickname":"常扬","note":"","ucode":"11B62CDABBE875","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":650800,"discussion_content":"感谢！分享给更多海外的开发者。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1725626283,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":393753,"user_name":"grok","can_delete":false,"product_type":"c1","uid":1341502,"ip_address":"美国","ucode":"4744AB3FA28FE2","user_header":"https://static001.geekbang.org/account/avatar/00/14/78/3e/f60ea472.jpg","comment_is_top":false,"comment_ctime":1724797821,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":2,"product_id":100804101,"comment_content":"补充以下关键组件:\n\n1. 向量数据库持久化存储:将索引结果持久化存储,避免每次重新构建索引,提高效率。\n\n2. 多模态输入处理:支持图像、音频等多模态输入,扩展应用场景。\n\n3. 上下文管理:维护对话历史,实现多轮交互的连贯性。\n\n4. 知识图谱集成:结合知识图谱,增强语义理解和推理能力。\n\n5. 实时数据同步:与外部数据源实时同步,保证信息时效性。\n\n6. 隐私保护机制:对敏感信息进行脱敏和访问控制。\n\n7. 可解释性模块:提供检索和生成过程的解释,增强可信度。\n\n8. 自适应学习:根据用户反馈动态调整检索策略和生成参数。","like_count":15,"discussions":[{"author":{"id":3954065,"avatar":"https://static001.geekbang.org/account/avatar/00/3c/55/91/e3c96b88.jpg","nickname":"常扬","note":"","ucode":"11B62CDABBE875","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":650344,"discussion_content":"点赞，基于你的组件，我也做一下流程分类，帮助大家更加理解RAG流程。向量数据库的持久化存储、多模态输入处理、实时数据同步、知识图谱集成、隐私保护机制属于索引阶段，提升了该阶段的信息管理、数据来源、实时性、关联性和安全性；可解释性模块和自适应学习属于检索阶段，注重提升该阶段的可解释性和召回率；上下文管理则归属于生成阶段，强化了生成阶段的记忆信息整合。","likes_number":4,"is_delete":false,"is_hidden":false,"ctime":1724812729,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":393792,"user_name":"Geek_5eea3f","can_delete":false,"product_type":"c1","uid":3829785,"ip_address":"河北","ucode":"0EEACB5A9BD1EA","user_header":"","comment_is_top":false,"comment_ctime":1724908210,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":2,"product_id":100804101,"comment_content":"运行代码有这样的错误请问如何解决：大模型生成过程中发生错误: HTTPSConnectionPool(host=&#39;dashscope.aliyuncs.com&#39;, port=443): Max retries exceeded with url: &#47;api&#47;v1&#47;services&#47;aigc&#47;text-generation&#47;generation (Caused by ProxyError(&#39;Unable to connect to proxy&#39;, SSLError(SSLZeroReturnError(6, &#39;TLS&#47;SSL connection has been closed (EOF) (_ssl.c:1135)&#39;))))\n","like_count":1,"discussions":[{"author":{"id":3954065,"avatar":"https://static001.geekbang.org/account/avatar/00/3c/55/91/e3c96b88.jpg","nickname":"常扬","note":"","ucode":"11B62CDABBE875","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":650405,"discussion_content":"与阿里云大模型连接网络报错，可能性比较多，是否开了代理/VPN，是否网络本身有问题等。 ping dashscope.aliyuncs.com 测试一下，如果返回 Request timeout for icmp_seq，则明确是网络相关。调整代理、VPN、网络等，再进行 ping dashscope.aliyuncs.com 测试，如果返回 4 bytes from 47.93.243.29: icmp_seq=0 ttl=89 time=44.247 ms类似消息，则表示网络问题恢复，可以正常调用。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1724920130,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}