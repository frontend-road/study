{"id":672152,"title":"06｜存储：如何提升存储模块的性能和可靠性？","content":"<p>你好，我是文强。</p><p>上一节我们讲了消息队列存储模块的功能实现，今天我们来讲存储模块的性能优化。</p><p>存储模块的性能优化，核心要解决的其实就是两个问题：“写得快”和“读得快”。这两个问题如何解决呢？我们从四点和存储性能优化有关的基础理论讲起。</p><ul>\n<li>内存读写的效率高于硬盘读写</li>\n<li>批量读写的效率高于单条读写</li>\n<li>顺序读写的效率高于随机读写</li>\n<li>数据复制次数越多，效率越低</li>\n</ul><h2>提升写入操作的性能</h2><p>上一节我们讲到，消息队列的数据最终是存储在文件中的，数据写入需要经过内存，最终才到硬盘，所以写入优化就得围绕<strong>内存和硬盘</strong>展开。写入性能的提高主要有缓存写、批量写、顺序写三个思路，这里对比来讲。</p><p><img src=\"https://static001.geekbang.org/resource/image/fb/8c/fbcdcb4b79bb26755a7ec015561aef8c.jpg?wh=4514x1387\" alt=\"\"></p><h3>1. 缓存写和批量写</h3><p>在计算机理论基础中，计算机多级存储模型的层级越高，代表速度越快（同时容量也越小，价格也越贵），也就是说写入速度从快到慢分别是：寄存器 &gt; 缓存 &gt; 主存 &gt; 本地存储 &gt; 远程存储。</p><p><img src=\"https://static001.geekbang.org/resource/image/13/bc/1301ac45580086ef1bf13fbaa21381bc.jpg?wh=3228x1488\" alt=\"\"></p><p>所以基于理论1和2：</p><ul>\n<li>内存读写的效率高于硬盘读写</li>\n<li>批量读写的效率高于单条读写</li>\n</ul><p>写入优化的主要思路之一是：<strong>将数据写入到速度更快的内存中，等积攒了一批数据，再批量刷到硬盘中。</strong></p><p>平时我们在一些技术文章看到的“数据先写入PageCache，再批量刷到硬盘”，说的就是这个思路。PageCache指操作系统的页缓存，简单理解就是内存，通过缓存读写数据可以避免直接对硬盘进行操作，从而提高性能。</p><!-- [[[read_end]]] --><p><img src=\"https://static001.geekbang.org/resource/image/77/76/77b396170d405d0bf82b489781yyd276.jpg?wh=3228x1488\" alt=\"\"></p><p>具体来说就是把硬盘中的数据缓存到内存中，这样对硬盘的访问就变成了对内存的访问。然后再通过一定的策略，把缓存中的数据刷回到硬盘。一般情况下，内存数据是自动批量刷到硬盘的，这个逻辑对应用是透明的。</p><p>把缓存数据刷回到硬盘，一般有“按照空间占用比例”、“时间周期扫描”和“手动强制刷新”三种策略。操作系统内核提供了前两种处理策略，不需要应用程序感知。我们具体了解一下。</p><p><strong>按空间占用比例刷新</strong>是指当系统内存中的“脏”数据大于某个阈值时会将数据刷新到硬盘。操作系统提供了两个配置项。</p><ul>\n<li>“脏”数据在内存中的占比（dirty_background_ratio）</li>\n<li>“脏”数据的绝对的字节数（dirty_background_bytes）</li>\n</ul><p>当这两个配置超过阈值，就会触发刷新操作。如果两者同时设置，则以绝对字节数为更高优先级。</p><p><strong>按时间周期刷新</strong>是指根据配置好的时间，周期性刷新数据到硬盘。主要通过脏页存活时间（dirty_expire_seconds) 和刷新周期（dirty_writeback_centisecs）两个参数来配置。两个配置默认都是1/100，也就说时间间隔为每秒100次，根据刷新周期的配置周期性执行刷新，刷新会检查脏页的存活时间是否超过配置的最大存活时间，如果是则刷入硬盘。</p><p>同时，操作系统也提供了第三种方法<strong>程序手动强制刷新</strong>，你可以通过系统提供的sync()/msync()/fsync() 调用来强制刷新缓存。通过操作系统的参数配置，在Java 代码中，通过Java.NIO包中FileChannel提供的write()和 force()方法，实现写缓存和强制刷新缓存。代码参考：</p><pre><code class=\"language-plain\">FileChannel channel = fin.getChannel();\nfile.write(buf)\nfile.force(true)\n</code></pre><p>通过 FileChannel 提供的write()方法写数据时，FileChannel 把数据写入到缓存就会返回成功，然后依赖操作系统的缓存更新策略，将数据刷新到硬盘。我们也可以在代码中调用FileChannel 提供的 force() 方法，把数据立即刷入刷盘中以免丢失。</p><p>基本所有的消息队列在写入时用的都是这个方案，比如 Kafka、RocketMQ、Pulsar 就是先写入缓存，然后依赖操作系统的策略刷新数据到硬盘。</p><p>消息队列一般会同时提供：是否同步刷盘、刷盘的时间周期、刷盘的空间比例三个配置项，让业务根据需要调整自己的刷新策略。从性能的角度看，异步刷新肯定是性能最高的，同步刷新是可靠性最高的。</p><h3>2. 随机写和顺序写</h3><p>写入操作的性能优化，我们还有最后一条基础理论没用上：顺序读写的效率高于随机读写。这里有两个问题很细节。</p><p>首先，你要理解顺序写和随机写是针对谁的？我们所说的都是针对硬盘的，是整个操作系统和硬盘的关系，而不是单文件和硬盘的关系。</p><p>明白了这一点，我们看下一个问题，“单文件顺序写入硬盘”和“多文件顺序写入硬盘”，从硬盘的角度看都是顺序读写吗？</p><p>单文件顺序写入硬盘很简单，硬盘控制器只需在连续的存储区域写入数据，对硬盘来讲，数据就是顺序写入的。</p><p><img src=\"https://static001.geekbang.org/resource/image/6d/8a/6dbbd839d4a939a7479cb0787fdbed8a.jpg?wh=3228x1488\" alt=\"\"></p><p>多文件顺序写入硬盘，系统中有很多文件同时写入，这个时候从硬盘的视角看，你会发现操作系统同时对多个不同的存储区域进行操作，硬盘控制器需要同时控制多个数据的写入，所以从硬盘的角度是随机写的。</p><blockquote>\n<p><span class=\"reference\">这里的硬盘控制器只是一个抽象，它包含CPU调度、硬盘驱动、DMA设备、写入调度算法等具体底层实现。</span></p>\n</blockquote><p><img src=\"https://static001.geekbang.org/resource/image/73/93/73b1524828e269f8f9f57d7169118f93.jpg?wh=3228x1488\" alt=\"\"></p><p>所以，在消息队列中，实现随机写和顺序写的核心就是<strong>数据存储结构的设计</strong>。</p><p>上节课我们讲过数据存储结构设计有两个思路：每个Partition/Queue单独一个存储文件，每台节点上所有Partition/Queue的数据都存储在同一个文件。</p><p>第一种方案，对单个文件来说读和写都是顺序的，性能最高，但当文件很多且都有读写，在硬盘层面就会退化为随机读写，性能会下降很多。第二种方案，因为只有一个文件，不存在文件过多的情况，写入层面一直都会是顺序的，性能一直很高。所以为了提高写的性能，我们最好使用第二种方案。</p><h2>提升写入操作的可靠性</h2><p>因为消息队列基本都采用数据先写入缓存、再写入硬盘的方案，所以有丢失数据的风险，比如数据还没刷新到硬盘中时，机器就异常重启了，数据就丢失了。</p><p>为了提高数据可靠性，在消息队列的存储模块中，一般会通过三种处理手段：同步刷盘、WAL预写日志、多副本备份，进一步提升数据的可靠性。</p><h3>1. 同步刷盘</h3><p>同步刷盘指每条数据都同步刷盘，等于回到了直接写硬盘的逻辑，一般通过写入数据后调用force()操作来完成数据刷盘。这种方案无法利用内存写入速度的优势，效率会降低很多。</p><p><img src=\"https://static001.geekbang.org/resource/image/73/b4/73157d635d126aeb23346f29b35758b4.jpg?wh=3228x1488\" alt=\"\"></p><p>一般消息队列都会开放这个配置项，默认批量刷盘，但有丢失数据的风险。如果业务需要修改为直接刷盘的策略来提高数据的可靠性，则会有一定的性能降低。至于如何提高同步刷盘的性能，我们在第18讲中还会展开细讲，敬请期待。</p><h3>2. WAL</h3><p>WAL（预写日志）指在写数据之前先写日志，当出现数据丢失时通过日志来恢复数据，避免数据丢失。</p><p>讲到这里，估计有同学有疑问了，WAL日志需要写入持久存储，业务数据也要写入缓存，多了一步，性能会不会降低呢？</p><p><img src=\"https://static001.geekbang.org/resource/image/27/8d/277100c7c4155fd6074ee6a068652f8d.jpg?wh=3228x1488\" alt=\"\"></p><p>没错，从理论来看，WAL机制肯定会比直接写入缓存中的性能低。但我们实际落地的时候往往可以通过一些手段来优化，降低影响，达到性能要求。</p><p>因为在消息队列中，消息数据的数据量是非常大的，我们不可能直接使用非常高性能的持久存储设备，成本太高。虽然WAL日志需要极高的写入性能，但是数据量一般很小，而且是可顺序存储的、可预测的（根据配置的缓存大小和更新策略可明确计算）。</p><p>所以<strong>在实际落地中，我们可以采取WAL日志盘和实际数据盘分离的策略，提升WAL日志的写入速度</strong>。具体就是让WAL数据盘是高性能、低容量的数据盘，数据盘是性能较低、容量较大的数据盘，如果出现数据异常，就通过WAL日志进行数据恢复。这样，给WAL日志选择合适的设备，再加上并行读写等代码优化手段，性能损失就可控了，甚至可以忽略。</p><p>不过，这个方案也有缺点，在实际部署运维过程中，我们需要单独给WAL日志分配高性能的数据盘并进行相关处理配置，运维成本相对较高。</p><p>但强制刷盘、WAL预写日志这两种方案，都是指单机维度的可靠性保证。而我们在实际运维过程中，单机是不可靠的，都需要通过分布式的多副本存储来保证数据的高可靠，也就有了第三种方案。</p><h3>3. 多副本的备份</h3><p>多副本的备份就是将数据拷贝到多台节点，每台节点都写入到内存中，从而完成数据的可靠性存储。因为单机层面也是把数据写入到内存中就记录写入成功，单机层面也可能出现数据丢失，所以核心思路是同时在多台节点中缓存数据，只要不是多台节点同时重启，数据就可以恢复。</p><p><img src=\"https://static001.geekbang.org/resource/image/14/f1/14d282ecd3cae4a3895a6f84f99dbdf1.jpg?wh=3228x1488\" alt=\"\"></p><p>好处是可以在分布式存储的基础上做优化，通过多台缓存的手段来降低数据丢失的概率。但是如果所有节点在同一时刻重启，数据还是有可能丢失的，无法保证百分百的数据高可靠。</p><p>从消息队列业界的存储方案来看，方案一所有产品都会支持，方案二和方案三一般会选一种支持，Kakfa、RabbitMQ、RocketMQ用的是第三种，Pulsar用的是第二种。</p><p>接下来我们看如何提升读取操作的性能。</p><h2>提升读取操作的性能</h2><p>提高读取的性能主要有读热数据、顺序读、批量读、零拷贝四个思路。</p><h3>1. 冷读和热读</h3><p>经过写优化后，数据先经过内存缓存，再批量刷到硬盘上，而且根据消息队列的特性，数据都是单分区顺序读写的。所以我们在读取数据的时候，有冷读和热读两种场景。</p><p>热读是指消息数据本身还在缓存中，读取数据是从内存中获取，此时性能最高，不需要经过硬盘。冷读是指消息数据刷到硬盘中了，并且数据已经被换页换出缓存了，此时读取数据需要从硬盘读取。</p><p><img src=\"https://static001.geekbang.org/resource/image/f0/5b/f06da30e248cb19e19b87be271d4375b.jpg?wh=3228x1488\" alt=\"\"></p><p>Java 中使用代码实现读缓存很简单，只需要使用Java.NIO包中的FileChannel.read数据。</p><pre><code class=\"language-plain\">ByteBuffer buffer = ByteBuffer.allocate(1024);\nint byteRead = channel.read(buffer);\n</code></pre><p>理想情况，肯定全部是热读最好，因为性能最高。但是在代码层面，我们是无法控制冷读或热读的，只能通过配置更大的内存，尽量保证缓存中保留更多的数据，从而提高热读的概率。</p><h3>2. 顺序读、随机读、批量读</h3><p>为了实现大吞吐，在消费的时候服务端都会支持批量读的能力。为了能尽快返回数据给客户端，服务端都会实现数据的预读机制。在读取数据的时候，也读取客户下一步可能会用的数据，预先加载到内存中，以便更快返回数据。</p><p>数据的预读分为两种：硬盘层面预读、应用程序的预读。</p><p>硬盘层面的预读，是在连续的地址空间中读取数据。<strong>但具体实现，我们在程序中无法控制，这和数据目录存储结构设计有关。</strong></p><p><img src=\"https://static001.geekbang.org/resource/image/bc/3f/bc73ea61da11b845c5701eef7561c93f.jpg?wh=3228x1932\" alt=\"\"></p><p>之前讲了两种数据存储目录结构设计。方案一在读取的过程中，因为数据是连续存储的，数据预读非常方便，只要在硬盘上读取连续的数据块即可，不需要在程序上做逻辑处理，性能最高。</p><p>方案二需要根据分区上的数据索引，在具体存储文件的不同位置读取数据。数据可能是连续的，也可能是不连续的。这种情况下硬盘的预读就很有随机性，大部分情况下在硬盘看来就是随机读。性能比第一种方案低。</p><p>应用程序的预读就比较简单，一般通过程序中的逻辑关系，提前通过调度去硬盘读取数据（可能是连续的也可能是不连续的）。因为消息队列的数据是分区有序的，当读取到某条数据时，手动读取后面的一个批次的数据就可以了。这种方案需要程序去控制，比如read(0)时，要同时读read(1,10)的数据，相对繁琐，并且性能较低。</p><p>对比来看，理想情况下，肯定是硬盘层面的顺序预读的性能最高，所以针对读取操作，方案一更合适。</p><h3>3. 零拷贝原理和使用方式</h3><p>零拷贝这个词你肯定很熟悉，但具体是什么含义可能很难说上来。我们用一张流程图来理解，看从硬盘读取数据并发送给网卡的过程。</p><p><img src=\"https://static001.geekbang.org/resource/image/80/d7/80ecda9234bcc260018618a578ea6cd7.jpg?wh=2737x1782\" alt=\"\"></p><p>如上图所示，在正常读取数据的过程中，数据要经过五步，硬盘 -&gt; ReadBuffer -&gt; 应用程序 -&gt; SocketBuffer -&gt; 网卡设备，四次复制。因为数据在复制过程耗费资源和时间，会降低性能，所以优化流程最重要的是减少数据复制的次数和资源损耗。</p><p>值得注意的是，零拷贝指的是数据在内核空间和用户空间之间的拷贝次数，即图中的第2步和第3步。如果只有1和4两步，没有执行2和3的话，那么内核空间和用户空间之间的拷贝次数就是零，“零拷贝”的零指的是这个次数“零”，因此是零拷贝。</p><p>为了解决复制次数带来的性能损耗，“零拷贝”这个概念就被提出来了。<strong>主要思路是通过减少数据复制次数、减少上下文（内核态和用户态）切换次数、通过DMA（直接内存）代替 CPU 完成数据读写，来解决复制和资源损耗的问题。</strong></p><p><img src=\"https://static001.geekbang.org/resource/image/ab/d7/ab6480e91f47f254dd11505c522d3ed7.jpg?wh=2737x1782\" alt=\"\"></p><p>图中红色的线，就是通过零拷贝相关技术优化后的效果。</p><ul>\n<li>将数据复制链路缩短成了：硬盘 -&gt; ReadBuffer -&gt; 网卡设备，复制次数从四次减为两次。</li>\n<li>用户空间和内核空间之间的数据复制需要进行上下文切换，优化完复制链路后，数据只在内核空间复制传输，就可以减少两次上下文切换。</li>\n<li>通过DMA 来搬运数据，使数据复制不需要通过 CPU，释放CPU。</li>\n</ul><blockquote>\n<p><span class=\"reference\">DMA 全称是直接内存存取。简单理解就是在IO设备和内存之间传递数据时，数据搬运工作全部交给 DMA 控制器，CPU不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务，从而释放CPU。</span></p>\n</blockquote><p>零拷贝主要用于在消费的时候提升性能，具体有两种实现方式：<strong>mmap+write 和 sendfile</strong>。</p><p>mmap是一种内存映射文件的方法，把文件或者其他对象映射到进程的地址空间，修改内存文件也会同步修改，这样就减少了一次数据拷贝。所以，我们不需要把数据拷贝到用户空间，修改后再回写到内核空间。</p><p><img src=\"https://static001.geekbang.org/resource/image/fe/bd/fe2405cfbbd7e75ec8e970ec719e2ebd.jpg?wh=2737x1782\" alt=\"\"></p><p>正常的“读取数据并发送”流程是通过read + write完成的，比如：</p><pre><code class=\"language-plain\">  read(file, tmp_buf, len);\n  write(socket, tmp_buf, len);\n</code></pre><p>而操作系统层面的 read()，系统在调用的过程中，会把内核缓冲区的数据拷贝到用户的缓冲区里，为了减少这一步开销，我们可以用 mmap() 替换 read() 系统调用函数。比如：</p><pre><code class=\"language-plain\">buf = mmap(file, len);\nwrite(sockfd, buf, len);\n</code></pre><p>在Java代码中，实现mmap的方法很简单，使用Java NIO包的FileChannel的map方法即可。</p><pre><code class=\"language-plain\">FileChannel fc = f.getChannel();\nMappedByteBuffer buf = fc.map(FileChannel.MapMode.READ_WRITE, 0, 200)\n</code></pre><p>另外一种实现思路 sendfile，是指Linux内核提供的一个系统调用 sendfile() ，它可以将数据从一个文件描述符传输到另一个文件描述符。之前图中的红色线路就是通过senfile系统调用和DMA技术，将四次的数据复制次数变为了两次，提高了性能。</p><p>在 Java 中也可以使用零拷贝技术，主要是在 NIO FileChannel 类中。</p><ul>\n<li>transferTo() 方法：可以将数据从 FileChannel 直接传输到另外一个 Channel。</li>\n<li>transferFrom() 方法：可以将数据从 Channel 传输到 FileChannel。</li>\n</ul><p>几乎所有的消息队列在消费时都使用了sendfile的调用，因为它配合DMA技术至少可以提升一倍的消费速度。</p><h2>通过硬件和系统优化提升性能</h2><p>讲到这里，我们谈的都是软件层面的优化。但在实际的运营部署中，性能的提升也得靠硬件的支持。接下来我们看如何提升硬件和系统的性能。</p><p>从硬件和系统优化提升性能的角度，主要可以通过提升硬件配置（如内存或硬盘）、配置多盘读写、配置硬盘阵列三个手段来提高集群的性能。</p><h3>1. 提升硬件配置</h3><p>为了提高热度的概率，直接配备更大的机器内存，性能提升最明显。</p><p>另外，消息队列是一款非常重视IO的组件，使用更快的硬盘IO设备，提高单机的吞吐能力，也能快速提升性能。硬盘类型很多，比如物理机部署下的机械盘、SSD、NVMe SSD，以及在云环境部署的各种规格的云盘。核心衡量指标主要有三个：IOPS、吞吐量、延时，这些指标越好，性能越高。</p><h3>2. 配置多盘读写</h3><p>系统层面，我们可以通过在机器上挂多块硬盘提升单机的硬盘吞吐能力。这种方案要内核支持这个机制，在部署的时候进行相关配置才能生效。</p><p><img src=\"https://static001.geekbang.org/resource/image/40/b1/4079a61a512454b8e20091690cdb48b1.jpg?wh=2737x1782\" alt=\"\"></p><p>一般实现思路是在消息队列的内核支持多目录读写的能力，将不同的文件或者不同的数据段调度存放在不同硬盘设备对应的挂载目录中。此时在数据的写入和读取的过程中，就可以同时利用到多块盘的吞吐和存储。</p><h3>3. 配置 RAID 和 LVM 硬盘阵列</h3><p>多目录读写的问题是多块盘之间无法共享IO能力和存储空间，当遇到数据倾斜时，在单机层面会出现性能和容量瓶颈。Linux提供了RAID硬盘阵列和LVM 逻辑卷管理两种方式，通过串联多块盘的读写能力和容量，提升硬盘的性能和吞吐能力（具体的硬盘阵列构建你可以参考<a href=\"https://www.infoq.cn/article/xsAkegr9N0VExtFaY8W0\">这篇文章</a>）。</p><p><img src=\"https://static001.geekbang.org/resource/image/48/7e/488b385cf99b0ba6797aa5ed408d027e.jpg?wh=2737x1782\" alt=\"\"></p><h2>总结</h2><p>写入性能优化的核心是缓存写、批量写、顺序写。</p><p>内存的写性能比任何硬盘都高，通过先写内存、后批量刷新数据到硬盘，可以降低硬盘的写入次数，从而提升写入性能。在写缓存的过程中，要注意数据的可靠性，我们可以通过同步刷盘、副本同步、WAL机制等手段提高性能和可靠性。写入的时候，顺序写的性能比随机写的性能高，顺序写的核心是数据存储目录结构的设计。</p><p>读操作的性能提升，主要依赖热读、顺序读、批量读、零拷贝四种手段。</p><p>热读主要依赖可用内存的大小。批量读指一次IO操作尽可能读取更多的数据，避免多次的数据IO操作。数据预读分为硬盘预读和应用程序预读两类，主要思路都是提前读取数据缓存到内存中，提高热读的命中率。和写入一样，顺序读的核心也是数据存储目录结构的设计。</p><p>零拷贝主要用来提升消费的性能，它只是一个概念，不是一门具体的技术。核心思路是<strong>减少复制和上下文切换的次数，通过DMA技术释放 CPU 的工作量</strong>，从而提升消费性能。底层的实现主要涉及mmap内存映射、sendfile系统调用、DMA直接内存读取三种技术手段。Java代码的实现，mmap和sendfile的操作都在NIO FileChannel类中，对应map、transferTo、transferFrom三个方法的使用。DMA技术在代码中无法控制，依赖于操作系统的实现。</p><p>另外，在硬件和操作系统层面，我们还可以通过提升硬件的规格和类型、配置多盘读写、配置RAID和LVM硬盘阵列三种手段来提高性能。</p><h2>思考题</h2><p>数据的批量写入，如果不用PageCache的缓存刷新机制，我们可以在应用程序中管理数据完成批量写入吗？如果可以怎么实现？优缺点是什么？</p><p>欢迎留言参与讨论，如果觉得今天的内容对你有帮助，也欢迎分享给身边的朋友一起学习。</p><h2><span class=\"orange\">上节课思考闭环</span></h2><p><span class=\"orange\">如果让你从头实现一个消息队列的存储模块，你的思考路径是什么？</span></p><p><span class=\"reference\">1. 首先需要想有哪些数据需要存储？最主要的是不是消息数据？</span></p><p><span class=\"reference\">2. 消息数据怎么存呢？按照Topic维度存还是分区维度存呢？</span></p><p><span class=\"reference\">3. 如果是分区，那分区数据怎么存呢？每个分区一个文件，还是所有分区存到一个文件。得去看看业界都是怎么做的，这两个方案的优劣是什么。</span></p><p><span class=\"reference\">4. 数据文件会很大，可能几个TB、几十个TB，这些数据是不是需要分段呢？是的话要怎么分段？</span></p><p><span class=\"reference\">5. 如果数据分段了，要根据什么分段呢？分段后应该怎么定位到消息内容呢？</span></p><p><span class=\"reference\">6. 消息队列的数据都需要清理，业界一般都有哪些清理机制，各自的优劣都是啥？这些清理都是怎么实现的呢？</span></p>","comments":[{"had_liked":false,"id":377394,"user_name":"张申傲","can_delete":false,"product_type":"c1","uid":1182372,"ip_address":"北京","ucode":"22D46BC529BA8A","user_header":"https://static001.geekbang.org/account/avatar/00/12/0a/a4/828a431f.jpg","comment_is_top":false,"comment_ctime":1688440766,"is_pvip":false,"replies":[{"id":137637,"content":"1.  是的，需要清理机制，不然数据会一直膨胀。从清理机制上来看，可以是按照时间删除的机制。因为在当前消息队列场景中，WAL的一个作用就是用来做数据丢失的recover。需要recover的数据是写入PageCache，但是还没有写入到硬盘的数据。这部分数据一般不大，而且持续的时间也很短。比如我们配置了异步刷盘，每秒刷一次，理论上我们WAL的数据只需要保留最近1s。 但是一般wal还会用来将随机写转为顺序写的功能。 所以，时间一般是根据自己的架构来设置的。\n2. 可以监控的。热读的监控主要是监控pageCache的使用。 所以，你可以用linux 的sar命令来监控PageCache。","user_name":"作者回复","user_name_real":"编辑","uid":1299071,"ctime":1689044883,"ip_address":"广东","comment_id":377394,"utype":1}],"discussion_count":1,"race_medal":2,"score":2,"product_id":100552001,"comment_content":"本篇的内容是可以复用到大多数系统中的通用优化方案，包括缓存、顺序I&#47;O、WAL机制、Batch机制等等。\n请教下强哥：\n1. WAL日志一般也需要一些清理机制吧，不然日志逐渐膨胀可能也会影响磁盘IO。比如MySQL的redo log是类似Ring Buffer结构的固定大小的文件，写满后会直接覆盖；而Redis的aof日志是用的rewrite机制来做compact。那么Pulsar是如何处理WAL日志过大的问题呢？\n2. 热读的缓存命中率一般会有监控吗？如果有是怎么做的呢？","like_count":6,"discussions":[{"author":{"id":1299071,"avatar":"https://static001.geekbang.org/account/avatar/00/13/d2/7f/a3d193ea.jpg","nickname":"许文强(LoboXu)","note":"","ucode":"8D6AB35808A88C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":623103,"discussion_content":"1.  是的，需要清理机制，不然数据会一直膨胀。从清理机制上来看，可以是按照时间删除的机制。因为在当前消息队列场景中，WAL的一个作用就是用来做数据丢失的recover。需要recover的数据是写入PageCache，但是还没有写入到硬盘的数据。这部分数据一般不大，而且持续的时间也很短。比如我们配置了异步刷盘，每秒刷一次，理论上我们WAL的数据只需要保留最近1s。 但是一般wal还会用来将随机写转为顺序写的功能。 所以，时间一般是根据自己的架构来设置的。\n2. 可以监控的。热读的监控主要是监控pageCache的使用。 所以，你可以用linux 的sar命令来监控PageCache。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1689044884,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":377386,"user_name":"Geek_0710c9","can_delete":false,"product_type":"c1","uid":3217761,"ip_address":"河北","ucode":"9353F29D1213F6","user_header":"","comment_is_top":false,"comment_ctime":1688430663,"is_pvip":false,"replies":[{"id":137547,"content":"在我看来，WAL主要有两个功能：\n1.  随机写转为顺序写，提高写入效率。\n2. 防止数据丢失，在系统异常的时候用来恢复数据，当checkpoint用的。\n因为MQ本身是顺序写的，所以1作用不是特别大。\n文章是在可靠性部分讲到了WAL，是为了保证数据的不丢失，可恢复的。","user_name":"作者回复","user_name_real":"编辑","uid":1299071,"ctime":1688488250,"ip_address":"广东","comment_id":377386,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100552001,"comment_content":"WAL 的 讲解感觉不太对，WAL 主要的作用是把随机写转为顺序写，主要用在采用 b+树作为存储结构的数据库中，比如 mysql 。\n\n现代的 mq（例如 kafka） 和数据库 （例如 tidb，底层数据 rocksdb ），采用 LSM SSTable 结构进行数据存储，本身就是采用追加的形式，顺序写能力强劲，不需要 WAL","like_count":3,"discussions":[{"author":{"id":1299071,"avatar":"https://static001.geekbang.org/account/avatar/00/13/d2/7f/a3d193ea.jpg","nickname":"许文强(LoboXu)","note":"","ucode":"8D6AB35808A88C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":622644,"discussion_content":"在我看来，WAL主要有两个功能：\n1.  随机写转为顺序写，提高写入效率。\n2. 防止数据丢失，在系统异常的时候用来恢复数据，当checkpoint用的。\n因为MQ本身是顺序写的，所以1作用不是特别大。\n文章是在可靠性部分讲到了WAL，是为了保证数据的不丢失，可恢复的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1688488250,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2292255,"avatar":"","nickname":"TKF","note":"","ucode":"167E911262E166","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":635057,"discussion_content":"bookkeeper了解下","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1704357326,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":377975,"user_name":"Geek_3a2d3a","can_delete":false,"product_type":"c1","uid":2911890,"ip_address":"湖北","ucode":"490B8960D6B1B2","user_header":"","comment_is_top":false,"comment_ctime":1689608259,"is_pvip":false,"replies":[{"id":137802,"content":"这门课的定位实战偏少，主要是从消息队列的底层原理和设计思路出发的，哪里觉得收获感不足可以进一步向讲师提问哦～感谢建议！","user_name":"编辑回复","user_name_real":"编辑","uid":1356014,"ctime":1689770071,"ip_address":"北京","comment_id":377975,"utype":2}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100552001,"comment_content":"有没有实战的案例，光讲不实战感觉有点生疏","like_count":1,"discussions":[{"author":{"id":1356014,"avatar":"https://static001.geekbang.org/account/avatar/00/14/b0/ee/7409a0d3.jpg","nickname":"冬青","note":"","ucode":"14576781B499FB","race_medal":0,"user_type":8,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":623743,"discussion_content":"这门课的定位实战偏少，主要是从消息队列的底层原理和设计思路出发的，哪里觉得收获感不足可以进一步向讲师提问哦～感谢建议！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1689770071,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":8}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":378371,"user_name":"康伯德","can_delete":false,"product_type":"c1","uid":2809246,"ip_address":"北京","ucode":"467D81046D8414","user_header":"https://static001.geekbang.org/account/avatar/00/2a/dd/9e/732759ad.jpg","comment_is_top":false,"comment_ctime":1690161452,"is_pvip":false,"replies":[{"id":138019,"content":"你好啊，这个问题我说一下我自己的理解。\n\n在我看来，零拷贝指的是数据在内核空间和用户空间之间的拷贝次数为0。所以在我看来它是一个概念，不是一门具体的技术。\n\nsendfile 作用是在两个文件描述符中直接传递数据，数据传递全部在内核完成，不经过内核空间。所以严格意义上来说它就是零拷贝的一种实现。\n\n从业务的角度，如果要通过零拷贝的概念来提高性能，还得配合dma技术，来实现直接把数据从readbuffer发送到网卡设备，从而提高性能。\n\n所以，sendfile 可以理解就是零拷贝。","user_name":"作者回复","user_name_real":"编辑","uid":1299071,"ctime":1690788735,"ip_address":"广东","comment_id":378371,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100552001,"comment_content":"老师，请教一下问题，为什么Linux的普通拷贝不用零拷贝，比如sendfile，如果mmap我还理解，毕竟需要建立映射，但sendfile呢？总比普通拷贝要好吧","like_count":0,"discussions":[{"author":{"id":1299071,"avatar":"https://static001.geekbang.org/account/avatar/00/13/d2/7f/a3d193ea.jpg","nickname":"许文强(LoboXu)","note":"","ucode":"8D6AB35808A88C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":624627,"discussion_content":"你好啊，这个问题我说一下我自己的理解。\n\n在我看来，零拷贝指的是数据在内核空间和用户空间之间的拷贝次数为0。所以在我看来它是一个概念，不是一门具体的技术。\n\nsendfile 作用是在两个文件描述符中直接传递数据，数据传递全部在内核完成，不经过内核空间。所以严格意义上来说它就是零拷贝的一种实现。\n\n从业务的角度，如果要通过零拷贝的概念来提高性能，还得配合dma技术，来实现直接把数据从readbuffer发送到网卡设备，从而提高性能。\n\n所以，sendfile 可以理解就是零拷贝。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1690788735,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":377485,"user_name":"3.0的A7","can_delete":false,"product_type":"c1","uid":1211991,"ip_address":"北京","ucode":"23C5F02B45CE39","user_header":"https://static001.geekbang.org/account/avatar/00/12/7e/57/8c1051b6.jpg","comment_is_top":false,"comment_ctime":1688561669,"is_pvip":false,"replies":[{"id":137565,"content":"是的，所以这里在编码层面需要考虑这个问题。通过编码技巧来解决这个问题。正常的思路是先WAL，再写数据。\n\n如果为了提升并发度，那么就得在编码层面做很多recover的措施。比如wal写入失败，消息数据写入成功时，如何处理。","user_name":"作者回复","user_name_real":"编辑","uid":1299071,"ctime":1688698211,"ip_address":"广东","comment_id":377485,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100552001,"comment_content":"WAL的方式，如果WAL写入就失败的话，是不是这个消息算生产失败了？","like_count":0,"discussions":[{"author":{"id":1299071,"avatar":"https://static001.geekbang.org/account/avatar/00/13/d2/7f/a3d193ea.jpg","nickname":"许文强(LoboXu)","note":"","ucode":"8D6AB35808A88C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":622818,"discussion_content":"是的，所以这里在编码层面需要考虑这个问题。通过编码技巧来解决这个问题。正常的思路是先WAL，再写数据。\n\n如果为了提升并发度，那么就得在编码层面做很多recover的措施。比如wal写入失败，消息数据写入成功时，如何处理。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1688698211,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":377357,"user_name":"文敦复","can_delete":false,"product_type":"c1","uid":1195258,"ip_address":"四川","ucode":"B8F4A6BD5D7805","user_header":"https://static001.geekbang.org/account/avatar/00/12/3c/fa/e2990931.jpg","comment_is_top":false,"comment_ctime":1688380452,"is_pvip":false,"replies":[{"id":137510,"content":"1. 是的，就是指内核态到用户态之间的拷贝次数是零次。\n2. 是的，零拷贝只是一个概念。DMA，sendfile，MMAP 都是实现零拷贝的手段。","user_name":"作者回复","user_name_real":"编辑","uid":1299071,"ctime":1688393879,"ip_address":"广东","comment_id":377357,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100552001,"comment_content":"1. 对于零拷贝而言，这里的零指的应该是内核态到用户态之间的零次吧? 实际上还是有2次的，硬盘 -&gt; 内核 -&gt; 网卡\n2. DMA，sendfile，MMAP 都是实现零拷贝的手段？\n这样理解对不对？\n","like_count":0,"discussions":[{"author":{"id":1299071,"avatar":"https://static001.geekbang.org/account/avatar/00/13/d2/7f/a3d193ea.jpg","nickname":"许文强(LoboXu)","note":"","ucode":"8D6AB35808A88C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":622549,"discussion_content":"1. 是的，就是指内核态到用户态之间的拷贝次数是零次。\n2. 是的，零拷贝只是一个概念。DMA，sendfile，MMAP 都是实现零拷贝的手段。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1688393879,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":377356,"user_name":"文敦复","can_delete":false,"product_type":"c1","uid":1195258,"ip_address":"四川","ucode":"B8F4A6BD5D7805","user_header":"https://static001.geekbang.org/account/avatar/00/12/3c/fa/e2990931.jpg","comment_is_top":false,"comment_ctime":1688380283,"is_pvip":false,"replies":[{"id":137589,"content":"第一点没问题。\n第二点的准确描述是，在大部分情况下，是读强 + 写强。\n\n只有在某些极端场景，分区数很多 + 每个分区都同时在读写的时候，就会降低读和写的性能。因为在硬盘层面，大量的多个文件的读写，就会造成随机读写。\n\n这种极端场景，在业务中遇到的概率相对较低一些。","user_name":"作者回复","user_name_real":"编辑","uid":1299071,"ctime":1688795055,"ip_address":"广东","comment_id":377356,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100552001,"comment_content":"对于统一的日志文件和每个分区各自的日志文件对比而言。\n1.统一的日志文件，写强（顺序写），读弱（不同分区可能存在在文件不同的位置，为随机读）\n2.每个分区独立的日志文件，读强（可以顺序预读），但是写弱（文件分散随机写）\n大概是这个意思吧？","like_count":0,"discussions":[{"author":{"id":1299071,"avatar":"https://static001.geekbang.org/account/avatar/00/13/d2/7f/a3d193ea.jpg","nickname":"许文强(LoboXu)","note":"","ucode":"8D6AB35808A88C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":622900,"discussion_content":"第一点没问题。\n第二点的准确描述是，在大部分情况下，是读强 + 写强。\n\n只有在某些极端场景，分区数很多 + 每个分区都同时在读写的时候，就会降低读和写的性能。因为在硬盘层面，大量的多个文件的读写，就会造成随机读写。\n\n这种极端场景，在业务中遇到的概率相对较低一些。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1688795055,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":393878,"user_name":"糖糖丸","can_delete":false,"product_type":"c1","uid":1347921,"ip_address":"北京","ucode":"79762E88808283","user_header":"https://static001.geekbang.org/account/avatar/00/14/91/51/3da9420d.jpg","comment_is_top":false,"comment_ctime":1725246925,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100552001,"comment_content":"WAL日志为什么数据量很小？难道会比消息数据本身的数据量更小吗？为什么呢","like_count":0},{"had_liked":false,"id":390187,"user_name":"jack","can_delete":false,"product_type":"c1","uid":1940707,"ip_address":"浙江","ucode":"4335C603F32FF6","user_header":"https://static001.geekbang.org/account/avatar/00/1d/9c/e3/2ca8c794.jpg","comment_is_top":false,"comment_ctime":1714620628,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100552001,"comment_content":"老师，请教个问题：如果只是一个单文件写的话，并行度是不是没那么高？如果文件数量和写入的性能是不是类似 请求并发和请求延迟的关系？有个曲线，顶部是最大值","like_count":0},{"had_liked":false,"id":381208,"user_name":"shan","can_delete":false,"product_type":"c1","uid":1321027,"ip_address":"河南","ucode":"DD7C79B1211E68","user_header":"https://static001.geekbang.org/account/avatar/00/14/28/43/5062a59b.jpg","comment_is_top":false,"comment_ctime":1694793008,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100552001,"comment_content":"总结\n\n写入操作性能提升方式\n1. 缓存写和批量写\n   将数据先写入操作系统页缓存PageCache中（缓存写），积攒一批数据后刷到硬盘中，一般消息队列会提供是否同步刷盘、刷盘的时间周期、刷盘的空间比例三个配置项，根据配置来决定何时刷盘。\n2. 顺序写\n   对于单文件顺序写比较简单，多文件写入硬盘，硬盘控制器需要同时控制多个数据的写入，从硬盘角度看是随机写。所以随机写还是顺序写依赖消息队列的存储结构设计，比如RocketMQ将每个消息队列的数据都存储到一个CommitLog文件就可以实现顺序写。\n\n\n读取操作性能提升方式\n1. 热读：数据进行预热，将数据先从硬盘读取到内存中；\n2. 顺序读、随机读、批量读：还是依赖于数据预读，分为硬盘层面预读和应用程序的预读。\n   硬盘层面预读依赖数据的存储结构设计。\n   应用程序的预读，提前通过调度去硬盘读取数据（可能是连续的也可能是不连续的）。\n3. 零拷贝：通过减少数据的拷贝次数、减小上下文切换来提升读取性能，比如RocketMQ使用mmap方式来提高CommitLog的读写性能；\n\n硬件和系统优化提升性能\n1. 提升硬件配置：比如配备更大的机器内存；\n2. 配置多盘读写：通过在机器上挂多块硬盘提升单机的硬盘吞吐能力；\n3. 配置RAID和LVM硬盘阵列，串联多块盘提升硬盘的性能和吞吐能力；\n\n数据可靠性保证\n（1）同步刷盘：数据写入后立刻调用force()操作完成数据刷盘，效率会比较低。\n（2）WAL（预写日志）：写数据之前先写日志，当出现数据丢失时通过日志来恢复数据，避免数据丢失。\n（3）多副本备份：将数据拷贝到多台节点，通过分布式的多副本存储来保证数据的高可靠。\n方案一所有产品都会支持，方案二和方案三一般会选一种支持，Kakfa、RabbitMQ、RocketMQ 用的是第三种，Pulsar 用的是第二种。\n","like_count":0},{"had_liked":false,"id":379295,"user_name":"takumi","can_delete":false,"product_type":"c1","uid":1439928,"ip_address":"上海","ucode":"780B10D8BEBDA6","user_header":"https://static001.geekbang.org/account/avatar/00/15/f8/b8/0398768b.jpg","comment_is_top":false,"comment_ctime":1691674189,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100552001,"comment_content":"多副本备份是写入到内存，但是内存一般都是易失性存储，如果当节点重启的时候，数据就没了，是否可以通过写入到磁盘上保证可靠性？","like_count":0},{"had_liked":false,"id":377536,"user_name":"cykuo","can_delete":false,"product_type":"c1","uid":1157644,"ip_address":"北京","ucode":"3D1218976BF0BF","user_header":"https://static001.geekbang.org/account/avatar/00/11/aa/0c/6a65f487.jpg","comment_is_top":false,"comment_ctime":1688655350,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":3,"product_id":100552001,"comment_content":"mmp使用了内存映射，在read的时候减少了一次内存拷贝，但是最后write的时候不还是拷贝了一次么？","like_count":0,"discussions":[{"author":{"id":1180636,"avatar":"https://static001.geekbang.org/account/avatar/00/12/03/dc/ba203066.jpg","nickname":"张三","note":"","ucode":"6ED330F5A4DBD2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":626964,"discussion_content":"wirte是指将数据写到网卡设备了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1693535171,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}