{"id":217593,"title":"17 | 大厂都是怎么做MySQL to Redis同步的?","content":"<p>你好，我是李玥。</p><p>之前我们在《<a href=\"https://time.geekbang.org/column/article/213230\">11 | MySQL如何应对高并发（一）：使用缓存保护MySQL</a>》这一节课中，讲到了Read/Write Through和Cache Aside这几种更新缓存的策略，这几种策略都存在缓存穿透的可能，如果缓存没有命中，那就穿透缓存去访问数据库获取数据。</p><p>一般情况下，只要我们做好缓存预热，这个缓存的命中率很高，能穿透缓存打到数据库上的请求比例就非常低，这些缓存的策略都是没问题的。但是如果说，我们的Redis缓存服务的是一个超大规模的系统，那就又不一样了。</p><p>今天这节课，我们来说一下，在超大规模系统中缓存会面临什么样的问题，以及应该使用什么样的策略来更新缓存。</p><h2>缓存穿透：超大规模系统的不能承受之痛</h2><p>我们上节课讲到了如何构建Redis集群，由于集群可以水平扩容，那只要集群足够大，理论上支持海量并发也不是问题。但是，因为并发请求的数量这个基数太大了，即使有很小比率的请求穿透缓存，打到数据库上请求的绝对数量仍然不小。加上大促期间的流量峰值，还是存在缓存穿透引发雪崩的风险。</p><p>那这个问题怎么解决呢？其实方法你也想得到，不让请求穿透缓存不就行了？反正现在存储也便宜，只要你买得起足够多的服务器，Redis集群的容量就是无限的。不如把全量的数据都放在Redis集群里面，处理读请求的时候，干脆只读Redis，不去读数据库。这样就完全没有“缓存穿透”的风险了，实际上很多大厂它就是这么干的。</p><!-- [[[read_end]]] --><p>在Redis中缓存全量的数据，又引发了一个新的问题，那就是，如何来更新缓存中的数据呢？因为我们取消了缓存穿透的机制，这种情况下，从缓存读到数据可以直接返回，如果没读到数据，那就只能返回错误了！所以，当系统更新数据库的数据之后，必须及时去更新缓存。</p><p>说到这儿，又绕回到那个老问题上了：怎么保证Redis中的数据和数据库中的数据同步更新？我们之前讲过用分布式事务来解决数据一致性的问题，但是这些方法都不太适合用来更新缓存，<strong>因为分布式事务，对数据更新服务有很强的侵入性</strong>。我们拿下单服务来说，如果为了更新缓存增加一个分布式事务，无论我们用哪种分布式事务，或多或少都会影响下单服务的性能。还有一个问题是，如果Redis本身出现故障，写入数据失败，还会导致下单失败，等于是降低了下单服务性能和可用性，这样肯定不行。</p><p><strong>对于像订单服务这类核心的业务，一个可行的方法是，我们启动一个更新订单缓存的服务，接收订单变更的MQ消息，然后更新Redis中缓存的订单数据。</strong>因为这类核心的业务数据，使用方非常多，本来就需要发消息，增加一个消费订阅基本没什么成本，订单服务本身也不需要做任何更改。</p><p><img src=\"https://static001.geekbang.org/resource/image/7c/8e/7cec502808318409dbc719c0b1cbbc8e.jpg?wh=1142*658\" alt=\"\"></p><p>唯一需要担心的一个问题是，如果丢消息了怎么办？因为现在消息是缓存数据的唯一来源，一旦出现丢消息，缓存里缺失的那条数据永远不会被补上。所以，必须保证整个消息链条的可靠性，不过好在现在的MQ集群，比如像Kafka或者RocketMQ，它都有高可用和高可靠的保证机制，只要你正确配置好，是可以满足数据可靠性要求的。</p><p>像订单服务这样，本来就有现成的数据变更消息可以订阅，这样更新缓存还是一个不错的选择，因为实现起来很简单，对系统的其他模块完全没有侵入。</p><h2>使用Binlog实时更新Redis缓存</h2><p>如果我们要缓存的数据，本来没有一份数据更新的MQ消息可以订阅怎么办？很多大厂都采用的，也是更通用的解决方案是这样的。</p><p>数据更新服务只负责处理业务逻辑，更新MySQL，完全不用管如何去更新缓存。负责更新缓存的服务，把自己伪装成一个MySQL的从节点，从MySQL接收Binlog，解析Binlog之后，可以得到实时的数据变更信息，然后根据这个变更信息去更新Redis缓存。</p><p><img src=\"https://static001.geekbang.org/resource/image/91/12/918380c0e43de2f4ef7ad5e8e9d5d212.jpg?wh=1142*639\" alt=\"\"></p><p>这种收Binlog更新缓存的方案，和刚刚我们讲到的，收MQ消息更新缓存的方案，其实它们的实现思路是一样的，都是异步订阅实时数据变更信息，去更新Redis。只不过，直接读取Binlog这种方式，它的通用性更强。不要求订单服务再发订单消息了，订单更新服务也不用费劲去解决“发消息失败怎么办？”这种数据一致性问题了。</p><p>而且，在整个缓存更新链路上，减少了一个收发MQ的环节，从MySQL更新到Redis更新的时延更短，出现故障的可能性也更低，所以很多大厂更青睐于这种方案。</p><p>这个方案唯一的缺点是，实现订单缓存更新服务有点儿复杂，毕竟不像收消息，拿到的直接就是订单数据，解析Binlog还是挺麻烦的。</p><p>有很多开源的项目就提供了订阅和解析MySQL Binlog的功能，下面我们以比较常用的开源项目<a href=\"https://github.com/alibaba/canal\">Canal</a>为例，来演示一下如何实时接收Binlog更新Redis缓存。</p><p>Canal模拟MySQL 主从复制的交互协议，把自己伪装成一个MySQL的从节点，向MySQL主节点发送dump请求，MySQL收到请求后，就会开始推送Binlog给Canal，Canal解析Binlog字节流之后，转换为便于读取的结构化数据，供下游程序订阅使用。下图是Canal的工作原理：</p><p><img src=\"https://static001.geekbang.org/resource/image/45/e4/452211795717190e55c5b0ff2ab208e4.jpg?wh=1142*546\" alt=\"\"></p><p>在我们这个示例中，MySQL和Redis都运行在本地的默认端口上，MySQL的端口为3306，Redis的端口为6379。为了便于大家操作，我们还是以《<a href=\"https://time.geekbang.org/column/article/206544\">04 | 事务：账户余额总是对不上账，怎么办？</a>》这节课中的账户余额表account_balance作为演示数据。</p><p>首先，下载并解压Canal 最新的1.1.4版本到本地：</p><pre><code>wget https://github.com/alibaba/canal/releases/download/canal-1.1.4/canal.deployer-1.1.4.tar.gz\ntar zvfx canal.deployer-1.1.4.tar.gz\n</code></pre><p>然后来配置MySQL，我们需要在MySQL的配置文件中开启Binlog，并设置Binlog的格式为ROW格式。</p><pre><code>[mysqld]\nlog-bin=mysql-bin # 开启Binlog\nbinlog-format=ROW # 设置Binlog格式为ROW\nserver_id=1 # 配置一个ServerID\n</code></pre><p>给Canal开一个专门的MySQL用户并授权，确保这个用户有复制Binlog的权限：</p><pre><code>CREATE USER canal IDENTIFIED BY 'canal';  \nGRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'canal'@'%';\nFLUSH PRIVILEGES;\n</code></pre><p>重启一下MySQL，确保所有的配置生效。重启后检查一下当前的Binlog文件和位置：</p><p><img src=\"https://static001.geekbang.org/resource/image/01/8f/01293d0ccc372418f3e01c785e204b8f.png?wh=1436*310\" alt=\"\"></p><p>记录下File和Position两列的值，然后我们来配置Canal。编辑Canal的实例配置文件canal/conf/example/instance.properties，以便让Canal连接到我们的MySQL上。</p><pre><code>canal.instance.gtidon=false\n\n\n# position info\ncanal.instance.master.address=127.0.0.1:3306\ncanal.instance.master.journal.name=binlog.000009\ncanal.instance.master.position=155\ncanal.instance.master.timestamp=\ncanal.instance.master.gtid=\n\n\n# username/password\ncanal.instance.dbUsername=canal\ncanal.instance.dbPassword=canal\ncanal.instance.connectionCharset = UTF-8\ncanal.instance.defaultDatabaseName=test\n# table regex\ncanal.instance.filter.regex=.*\\\\..\n</code></pre><p>这个配置文件需要配置MySQL的连接地址、库名、用户名和密码之外，还需要配置canal.instance.master.journal.name和canal.instance.master.position这两个属性，取值就是刚刚记录的File和Position两列。然后就可以启动Canal服务了：</p><pre><code>canal/bin/startup.sh\n</code></pre><p>启动之后看一下日志文件canal/logs/example/example.log，如果里面没有报错，就说明启动成功并连接到我们的MySQL上了。</p><p>Canal服务启动后，会开启一个端口（11111）等待客户端连接，客户端连接上Canal服务之后，可以从Canal服务拉取数据，每拉取一批数据，正确写入Redis之后，给Canal服务返回处理成功的响应。如果发生客户端程序宕机或者处理失败等异常情况，Canal服务没收到处理成功的响应，下次客户端来拉取的还是同一批数据，这样就可以保证顺序并且不会丢数据。</p><p>接下来我们来开发账户余额缓存的更新程序，以下的代码都是用Java语言编写的：</p><pre><code>while (true) {\n    Message message = connector.getWithoutAck(batchSize); // 获取指定数量的数据\n    long batchId = message.getId();\n    try {\n        int size = message.getEntries().size();\n        if (batchId == -1 || size == 0) {\n            Thread.sleep(1000);\n        } else {\n            processEntries(message.getEntries(), jedis);\n        }\n\n\n        connector.ack(batchId); // 提交确认\n    } catch (Throwable t) {\n        connector.rollback(batchId); // 处理失败, 回滚数据\n    }\n}\n</code></pre><p>这个程序逻辑也不复杂，程序启动并连接到Canal服务后，就不停地拉数据，如果没有数据就睡一会儿，有数据就调用processEntries方法处理更新缓存。每批数据更新成功后，就调用ack方法给Canal服务返回成功响应，如果失败抛异常就回滚。下面是processEntries方法的主要代码：</p><pre><code>for (CanalEntry.RowData rowData : rowChage.getRowDatasList()) {\n    if (eventType == CanalEntry.EventType.DELETE) { // 删除\n        jedis.del(row2Key(&quot;user_id&quot;, rowData.getBeforeColumnsList()));\n    } else if (eventType == CanalEntry.EventType.INSERT) { // 插入\n        jedis.set(row2Key(&quot;user_id&quot;, rowData.getAfterColumnsList()), row2Value(rowData.getAfterColumnsList()));\n    } else { // 更新\n        jedis.set(row2Key(&quot;user_id&quot;, rowData.getAfterColumnsList()), row2Value(rowData.getAfterColumnsList()));\n    }\n}\n</code></pre><p>这里面根据事件类型来分别处理，如果MySQL中的数据删除了，就删除Redis中对应的数据。如果是更新和插入操作，那就调用Redis的SET命令来写入数据。</p><p>把这个账户缓存更新服务启动后，我们来验证一下，我们在账户余额表插入一条记录：</p><pre><code>mysql&gt; insert into account_balance values (888, 100, NOW(), 999);\n</code></pre><p>然后来看一下Redis缓存：</p><pre><code>127.0.0.1:6379&gt; get 888\n&quot;{\\&quot;log_id\\&quot;:\\&quot;999\\&quot;,\\&quot;balance\\&quot;:\\&quot;100\\&quot;,\\&quot;user_id\\&quot;:\\&quot;888\\&quot;,\\&quot;timestamp\\&quot;:\\&quot;2020-03-08 16:18:10\\&quot;}&quot;\n</code></pre><p>可以看到数据已经自动同步到Redis中去了。我把这个示例的完整代码放在了<a href=\"https://github.com/liyue2008/canal-to-redis-example\">GitHub</a>上供你参考。</p><h2>小结</h2><p>在处理超大规模并发的场景时，由于并发请求的数量非常大，即使少量的缓存穿透，也有可能打死数据库引发雪崩效应。对于这种情况，我们可以缓存全量数据来彻底避免缓存穿透问题。</p><p>对于缓存数据更新的方法，可以订阅数据更新的MQ消息来异步更新缓存，更通用的方法是，把缓存更新服务伪装成一个MySQL的从节点，订阅MySQL的Binlog，通过Binlog来更新Redis缓存。</p><p>需要特别注意的是，无论是用MQ还是Canal来异步更新缓存，对整个更新服务的数据可靠性和实时性要求都比较高，数据丢失或者更新慢了，都会造成Redis中的数据与MySQL中数据不同步。在把这套方案应用到生产环境中去的时候，需要考虑一旦出现不同步问题时的降级或补偿方案。</p><h2>思考题</h2><p>课后请你思考一下，如果出现缓存不同步的情况，在你负责的业务场景下，该如何降级或者补偿？欢迎你在留言区与我讨论。</p><p>感谢你的阅读，如果你觉得今天的内容对你有帮助，也欢迎把它分享给你的朋友。</p>","comments":[{"had_liked":false,"id":203573,"user_name":"李玥","can_delete":false,"product_type":"c1","uid":1501046,"ip_address":"","ucode":"B19E91EE248591","user_header":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","comment_is_top":true,"comment_ctime":1586235118,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"9.2233721372253e+18","product_id":100046801,"comment_content":"Hi，我是李玥。<br><br>这里回顾一下上节课的思考题：<br><br>课后请你再去看一下 HDFS，它在解决分片、复制和高可用这几方面，哪些是“抄作业”，哪些又是自己独创的。<br><br>HDFS集群的构成，和我们之前讲解的几个分布式存储集群是类似的。主要分为NameNode，也就是存放元数据和负责路由的节点，以及用于存放文件数据的DataNode。在HDFS中，大文件同样被划分为多个块，每个块会有多个副本来保证数据可靠性。但HDFS没有采用复制状态机的方式去同步数据，这块它实现了自己的复制算法，感兴趣的同学可以进一步去了解一下。","like_count":23},{"had_liked":false,"id":202270,"user_name":"每天晒白牙","can_delete":false,"product_type":"c1","uid":1004698,"ip_address":"","ucode":"A1B102CD933DEA","user_header":"https://static001.geekbang.org/account/avatar/00/0f/54/9a/76c0af70.jpg","comment_is_top":false,"comment_ctime":1585956277,"is_pvip":false,"discussion_count":11,"race_medal":0,"score":"259283994037","product_id":100046801,"comment_content":"我们的系统也采用了 canal 监听 binlog 变更来异步更新 ES 和 redis 中的数据的方式<br><br>不过我们的方案多了3个步骤<br>1.canal 把消息发到 kafka 中，应用程序监听 topic<br>2.应用程序收到消息后，根据 id 重新读 mysql<br>3.增加定时任务来对比数据库和 ES ，redis 中的数据<br>https:&#47;&#47;mp.weixin.qq.com&#47;s&#47;DPBgXftVE_cigSzzpA484w","like_count":60,"discussions":[{"author":{"id":2028941,"avatar":"","nickname":"Geek1254","note":"","ucode":"BC2F7756A0676D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":391420,"discussion_content":"使用Kafka需要考虑消息顺序吧","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1630459418,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1433535,"avatar":"https://static001.geekbang.org/account/avatar/00/15/df/bf/96b50d1e.jpg","nickname":"😚 46","note":"","ucode":"EED0EBBBF80A43","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":271951,"discussion_content":"用了binlog就没必要再用mq了吧","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1590226812,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1623409,"avatar":"https://static001.geekbang.org/account/avatar/00/18/c5/71/f7c43b49.jpg","nickname":"风向北吹","note":"","ucode":"2FD0BC5159E1C1","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":221680,"discussion_content":"如果数据库中的数据量大，定时任务怎么去比对数据啊，是按表的更新时间字段增量比吗？另外定时任务间隔周期怎么定的","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1586046033,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1608643,"avatar":"https://static001.geekbang.org/account/avatar/00/18/8b/c3/bf036d99.jpg","nickname":"砥砺奋进","note":"","ucode":"2F12FD10F749AD","race_medal":1,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":584529,"discussion_content":"一样","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1660895364,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1886331,"avatar":"https://static001.geekbang.org/account/avatar/00/1c/c8/7b/153181d7.jpg","nickname":"夜辉","note":"","ucode":"9421385F51FF9E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":366451,"discussion_content":"基于binlog监听或基于MQ发送消息，使用其中一种方式就可以了吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618065339,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1092169,"avatar":"https://static001.geekbang.org/account/avatar/00/10/aa/49/51790edb.jpg","nickname":"落尘kira","note":"","ucode":"D203B519E43F85","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":340445,"discussion_content":"我们使用的是1的方式，但消息中其实保存了该条记录的所有数据（比如JSON体），consumer自行解析；不过由于有些记录本身比较大，这点需要做量的限制，这时候通常consumer需要自行通过id获取原纪录","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1610008051,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1053136,"avatar":"https://static001.geekbang.org/account/avatar/00/10/11/d0/aefbaf52.jpg","nickname":"我是小白007","note":"","ucode":"31499977DB27C6","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":319137,"discussion_content":"微信的图没法放大，还有其他地方分享吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1603952081,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1983187,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLnLia14uMsD4PxicQsAy0aqqW56mWJBImeSF2cDFVnd1icbM72F8PlUDrL99O9MF1f2Lmm8ALJ3PJfQ/132","nickname":"zry","note":"","ucode":"63E18B73002FDC","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":284546,"discussion_content":"居然遇到了同学。。。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1592552629,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1004698,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/54/9a/76c0af70.jpg","nickname":"每天晒白牙","note":"","ucode":"A1B102CD933DEA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1983187,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLnLia14uMsD4PxicQsAy0aqqW56mWJBImeSF2cDFVnd1icbM72F8PlUDrL99O9MF1f2Lmm8ALJ3PJfQ/132","nickname":"zry","note":"","ucode":"63E18B73002FDC","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":284554,"discussion_content":"你是哪位呀，留下姓名","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1592554992,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":284546,"ip_address":""},"score":284554,"extra":""}]},{"author":{"id":1049208,"avatar":"https://static001.geekbang.org/account/avatar/00/10/02/78/23c56bce.jpg","nickname":"james","note":"","ucode":"5701899403917C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":250155,"discussion_content":"你这根据id 再读就耦合了多个服务","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587995007,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1363834,"avatar":"https://static001.geekbang.org/account/avatar/00/14/cf/7a/51951b07.jpg","nickname":"微笑","note":"","ucode":"6E8E2964D0191F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":234341,"discussion_content":"为什么要对比  不直接更新🤔","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586963006,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":220173,"user_name":"learn more","can_delete":false,"product_type":"c1","uid":1128702,"ip_address":"","ucode":"0EF628B2E0F95E","user_header":"https://static001.geekbang.org/account/avatar/00/11/38/fe/00ddeb81.jpg","comment_is_top":false,"comment_ctime":1590196479,"is_pvip":false,"replies":[{"id":"81464","content":"写不放在Redis中有几个原因：<br><br>1. Redis不是可靠的存储，存在丢数据的风险；<br>2. Redis不支持事务；<br>3. Redis的查询能力太弱，没法满足各种各样的业务需求。","user_name":"作者回复","user_name_real":"李玥","uid":"1501046","ctime":1590369009,"ip_address":"","comment_id":220173,"utype":1}],"discussion_count":3,"race_medal":0,"score":"91784509695","product_id":100046801,"comment_content":"老师你好，这种方案是不是数据写走MySQL，数据读走redis？如果是这样的话，是不是高并发的写也会出现问题？问一下，为什么不把读写全部放到redis操作呢？这样读和写都得到改善，最后使用消息队列批量从redis获取数据同步MySQL，希望得到老师的解答，谢谢。","like_count":21,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":496066,"discussion_content":"写不放在Redis中有几个原因：\n\n1. Redis不是可靠的存储，存在丢数据的风险；\n2. Redis不支持事务；\n3. Redis的查询能力太弱，没法满足各种各样的业务需求。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1590369009,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":1039466,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/dc/6a/b5478b65.jpg","nickname":"Ab","note":"","ucode":"8E9261782F025D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":561951,"discussion_content":"老师，是不是  redis的写能力太弱，不能满足业务需求？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1649752813,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":496066,"ip_address":""},"score":561951,"extra":""}]},{"author":{"id":1433535,"avatar":"https://static001.geekbang.org/account/avatar/00/15/df/bf/96b50d1e.jpg","nickname":"😚 46","note":"","ucode":"EED0EBBBF80A43","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":271960,"discussion_content":"1. redis空间比mysql小很多，不适合存储大量数据\n2. redis不支持事务，涉及交易的业务不能直接用redis做","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1590228425,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":202302,"user_name":"Dovelol","can_delete":false,"product_type":"c1","uid":1253384,"ip_address":"","ucode":"9B5DDF7720F307","user_header":"https://static001.geekbang.org/account/avatar/00/13/20/08/bc06bc69.jpg","comment_is_top":false,"comment_ctime":1585964748,"is_pvip":false,"replies":[{"id":"76048","content":"这种情况需要先做一次全量同步，之后再开启binlog做增量同步。","user_name":"作者回复","user_name_real":"李玥","uid":"1501046","ctime":1586222803,"ip_address":"","comment_id":202302,"utype":1}],"discussion_count":2,"race_medal":0,"score":"87485310668","product_id":100046801,"comment_content":"老师好，用binlog方式同步mysql数据到redis，如果是已经在线运行很久的表数据，也适合转到这个方案吗？需要把之前的数据全部同步到redis中，重要的是该从binlog中的哪个位置开始呢。","like_count":20,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":490551,"discussion_content":"这种情况需要先做一次全量同步，之后再开启binlog做增量同步。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586222803,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1207622,"avatar":"https://static001.geekbang.org/account/avatar/00/12/6d/46/e16291f8.jpg","nickname":"丁小明","note":"","ucode":"CC23857B8D75D5","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":221291,"discussion_content":"类似mysql的主从同步，你必须先初始化一份数据，记录binlogid，等初始化完了从记录的binglogid开始","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1585999718,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":203055,"user_name":"Mq","can_delete":false,"product_type":"c1","uid":1178359,"ip_address":"","ucode":"041F572AFAB275","user_header":"https://static001.geekbang.org/account/avatar/00/11/fa/f7/91ac44c5.jpg","comment_is_top":false,"comment_ctime":1586132943,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"74600576975","product_id":100046801,"comment_content":"1.可以增加一个对账功能，对数据库跟缓存的数据，数据最好有个版本号或时间，把不一致把数据库的数据刷进缓存<br>2.提供刷用户缓存的服务，对投訴用户可以优先刷下","like_count":17},{"had_liked":false,"id":211193,"user_name":"😚 46","can_delete":false,"product_type":"c1","uid":1433535,"ip_address":"","ucode":"EED0EBBBF80A43","user_header":"https://static001.geekbang.org/account/avatar/00/15/df/bf/96b50d1e.jpg","comment_is_top":false,"comment_ctime":1587912367,"is_pvip":false,"replies":[{"id":"78785","content":"绝对避免是很难做到的，更多的是想办法去减轻这个影响。比如Redis配置一主一从的高可用方式。","user_name":"作者回复","user_name_real":"李玥","uid":"1501046","ctime":1588048912,"ip_address":"","comment_id":211193,"utype":1}],"discussion_count":1,"race_medal":0,"score":"61717454511","product_id":100046801,"comment_content":"“还有一个问题是，如果 Redis 本身出现故障，写入数据失败，还会导致下单失败，等于是降低了下单服务性能和可用性，这样肯定不行。”<br>看到这段话，想问老师一个问题，应该如何避免 Redis 本身的故障对系统造成的影响呢？","like_count":14,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493217,"discussion_content":"绝对避免是很难做到的，更多的是想办法去减轻这个影响。比如Redis配置一主一从的高可用方式。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588048912,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":202977,"user_name":"C J J","can_delete":false,"product_type":"c1","uid":1002287,"ip_address":"","ucode":"603AA1417BD0DE","user_header":"https://static001.geekbang.org/account/avatar/00/0f/4b/2f/186918b4.jpg","comment_is_top":false,"comment_ctime":1586096636,"is_pvip":false,"replies":[{"id":"76066","content":"就行MySQL主从同步时延一样，只能接受它。一般这个时延都是毫米级的，不会对业务有很大影响。","user_name":"作者回复","user_name_real":"李玥","uid":"1501046","ctime":1586224038,"ip_address":"","comment_id":202977,"utype":1}],"discussion_count":1,"race_medal":0,"score":"61715638780","product_id":100046801,"comment_content":"全量数据缓存，缓存同步有个时间差，请问老师这该如何处理？","like_count":14,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":490720,"discussion_content":"就行MySQL主从同步时延一样，只能接受它。一般这个时延都是毫米级的，不会对业务有很大影响。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586224038,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":203530,"user_name":"飞翔","can_delete":false,"product_type":"c1","uid":1068571,"ip_address":"","ucode":"65AF6AF292DAD6","user_header":"https://static001.geekbang.org/account/avatar/00/10/4e/1b/f4b786b9.jpg","comment_is_top":false,"comment_ctime":1586228119,"is_pvip":true,"replies":[{"id":"76484","content":"Canal也支持主备的方式来解决高可用的问题。","user_name":"作者回复","user_name_real":"李玥","uid":"1501046","ctime":1586429295,"ip_address":"","comment_id":203530,"utype":1}],"discussion_count":1,"race_medal":0,"score":"53125835671","product_id":100046801,"comment_content":"老师 canal 是不是也的做的集群 防止它当机了 redis 不同步了","like_count":12,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":490886,"discussion_content":"Canal也支持主备的方式来解决高可用的问题。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586429295,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":202276,"user_name":"芒果","can_delete":false,"product_type":"c1","uid":1124278,"ip_address":"","ucode":"5AD71E7F9FC738","user_header":"https://static001.geekbang.org/account/avatar/00/11/27/b6/e53c17ee.jpg","comment_is_top":false,"comment_ctime":1585957476,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"44535630436","product_id":100046801,"comment_content":"思考题我的想法是：<br>1.如果缓存存在不同步的情况，那么客户端的数据就不是最新数据。如果用户不能接受数据不同步（比如：刚刚下的订单但是购物记录里面没有），作为用户一般都会进行手动刷新，服务端接收到用户手动刷新的请求时，直接去查数据库，然后通过老师之前讲的cache aside pattern的方式更新缓存。<br>2.为了防止手动刷新的请求太多，减少对数据库的压力，可以考虑对这个接口做一个限流。通过监控这个接口，如果长时间访问压力都很大，那么很有可能是缓存同步出现了问题。这时候赶紧上线解决问题吧。<br>其他的暂时也没想到什么了，期待听听老师的思路。","like_count":10},{"had_liked":false,"id":203208,"user_name":"C J J","can_delete":false,"product_type":"c1","uid":1002287,"ip_address":"","ucode":"603AA1417BD0DE","user_header":"https://static001.geekbang.org/account/avatar/00/0f/4b/2f/186918b4.jpg","comment_is_top":false,"comment_ctime":1586156433,"is_pvip":false,"replies":[{"id":"76068","content":"MQ消费的时候有自动重试机制，并且不建议这个地方加重试次数的限制。如果Redis故障，就让同步卡在那儿，等Redis恢复之后，就可以继续同步，这样不会丢数据。","user_name":"作者回复","user_name_real":"李玥","uid":"1501046","ctime":1586224423,"ip_address":"","comment_id":203208,"utype":1}],"discussion_count":2,"race_medal":0,"score":"31650927505","product_id":100046801,"comment_content":"老师，我还有个疑问。用mq去更新缓存数据，如若上面所说Redis出现故障，这应如何处理？我想到的是重试机制，但超过次数应当如何处理？","like_count":7,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":490799,"discussion_content":"MQ消费的时候有自动重试机制，并且不建议这个地方加重试次数的限制。如果Redis故障，就让同步卡在那儿，等Redis恢复之后，就可以继续同步，这样不会丢数据。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586224423,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2734978,"avatar":"https://static001.geekbang.org/account/avatar/00/29/bb/82/1f2df018.jpg","nickname":"努力向前","note":"","ucode":"7921FFCC91FBD8","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":388755,"discussion_content":"赞同老师的说法，不能进行重试。原因是：我们对数据库的操作都是严格有序的。比如，在数据库中，对同一个记录，先进行一个新增的操作，再进行另外一个更新操作。在去MQ中更新缓存的时候，如果在消费第一个新增的操作消息时，消费消息失败了。假如这时候使用重试机制。如果在重试第一个操作期间，第二个操作又来了，那么很有可能对第二个操作在Redis中执行成功了。此时再继续重试第一个操作，这时候的情况是：第二个更新操作没有在Redis中执行成功，因为这条记录压根就不存在。那么第一个操作在Redis中新增成功。这时候就会出现Redis和MySQL双写不一致。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1628936448,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":202502,"user_name":"川杰","can_delete":false,"product_type":"c1","uid":1099750,"ip_address":"","ucode":"815211E1D698E6","user_header":"https://static001.geekbang.org/account/avatar/00/10/c7/e6/11f21cb4.jpg","comment_is_top":false,"comment_ctime":1585996979,"is_pvip":false,"replies":[{"id":"76053","content":"一般批量查询的时候可以用Redis的集合数据结构，比如SET，SET中的Value可以保存交易编号，而不用保存交易数据。","user_name":"作者回复","user_name_real":"李玥","uid":"1501046","ctime":1586223166,"ip_address":"","comment_id":202502,"utype":1}],"discussion_count":2,"race_medal":0,"score":"31650768051","product_id":100046801,"comment_content":"老师好，想问一个redis很基础的问题。<br>假设我们要对交易数据进行缓存。后端调用时，既有根据交易编号查找单个对象的方法，又有查询批量交易的方法。那我该怎么缓存交易数据呢？<br>利用key-value的方式可以解决根据交易编号查找的情况。那批量查询怎么处理？用队列吗？如果用队列，那岂不是一个交易数据要缓存两遍？（一个是队列，一个是key-value）<br>请回答下，谢谢","like_count":7,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":490601,"discussion_content":"一般批量查询的时候可以用Redis的集合数据结构，比如SET，SET中的Value可以保存交易编号，而不用保存交易数据。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586223166,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1433535,"avatar":"https://static001.geekbang.org/account/avatar/00/15/df/bf/96b50d1e.jpg","nickname":"😚 46","note":"","ucode":"EED0EBBBF80A43","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":271958,"discussion_content":"redisson有 mutliSetMap 可以了解一下","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1590227937,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":202731,"user_name":"一剑","can_delete":false,"product_type":"c1","uid":1022127,"ip_address":"","ucode":"93ADD5B5215D4C","user_header":"https://static001.geekbang.org/account/avatar/00/0f/98/af/3945cea4.jpg","comment_is_top":false,"comment_ctime":1586059012,"is_pvip":false,"replies":[{"id":"76058","content":"这里面需要注意一下，Binlog中记录的是“数据变化”，而不仅仅是数据。","user_name":"作者回复","user_name_real":"李玥","uid":"1501046","ctime":1586223511,"ip_address":"","comment_id":202731,"utype":1}],"discussion_count":1,"race_medal":0,"score":"27355862788","product_id":100046801,"comment_content":"这里有个问题，就是我们一般是把计算结果缓存到redis，但是基于日志的同步方式是直接同步了原始表数据，这中间是不是少了一环？","like_count":6,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":490666,"discussion_content":"这里面需要注意一下，Binlog中记录的是“数据变化”，而不仅仅是数据。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586223511,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":207582,"user_name":"aoe","can_delete":false,"product_type":"c1","uid":1121758,"ip_address":"","ucode":"1C6201EDB4E954","user_header":"https://static001.geekbang.org/account/avatar/00/11/1d/de/62bfa83f.jpg","comment_is_top":false,"comment_ctime":1587112438,"is_pvip":false,"discussion_count":4,"race_medal":0,"score":"23061948918","product_id":100046801,"comment_content":"原来大厂是这样避免缓存穿透的！有钱任性","like_count":5,"discussions":[{"author":{"id":1049017,"avatar":"https://static001.geekbang.org/account/avatar/00/10/01/b9/73435279.jpg","nickname":"学习学个屁","note":"","ucode":"DF2D61E6FB2FCE","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":318695,"discussion_content":"所以叫他大厂 啊","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1603808787,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1484184,"avatar":"https://static001.geekbang.org/account/avatar/00/16/a5/98/a65ff31a.jpg","nickname":"djfhchdh","note":"","ucode":"E71D75328CE398","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":306943,"discussion_content":"毕竟是大厂","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1600424746,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":2,"child_discussions":[{"author":{"id":1121758,"avatar":"https://static001.geekbang.org/account/avatar/00/11/1d/de/62bfa83f.jpg","nickname":"aoe","note":"","ucode":"1C6201EDB4E954","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1484184,"avatar":"https://static001.geekbang.org/account/avatar/00/16/a5/98/a65ff31a.jpg","nickname":"djfhchdh","note":"","ucode":"E71D75328CE398","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":306984,"discussion_content":"我已经不记得他们是怎么避免的了……","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1600439194,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":306943,"ip_address":""},"score":306984,"extra":""},{"author":{"id":1474954,"avatar":"https://static001.geekbang.org/account/avatar/00/16/81/8a/15a96a64.jpg","nickname":"Gatsby","note":"","ucode":"5DBFDA12556BDB","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1121758,"avatar":"https://static001.geekbang.org/account/avatar/00/11/1d/de/62bfa83f.jpg","nickname":"aoe","note":"","ucode":"1C6201EDB4E954","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":578912,"discussion_content":"那再看一遍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1657089091,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":306984,"ip_address":""},"score":578912,"extra":""}]}]},{"had_liked":false,"id":213260,"user_name":"Lywane","can_delete":false,"product_type":"c1","uid":1446512,"ip_address":"","ucode":"2B0027AA069CE9","user_header":"https://static001.geekbang.org/account/avatar/00/16/12/70/10faf04b.jpg","comment_is_top":false,"comment_ctime":1588342152,"is_pvip":false,"replies":[{"id":"79194","content":"它使用MySQL主从同步的协议来从主库接收Binlog，对于主库“看起来，缓存更新服务就像是一个从库一样”。","user_name":"作者回复","user_name_real":"李玥","uid":"1501046","ctime":1588514082,"ip_address":"","comment_id":213260,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18768211336","product_id":100046801,"comment_content":"求问老师，&quot;负责更新缓存的服务，把自己伪装成一个 MySQL 的从节点，从 MySQL 接收 Binlog，解析 Binlog 之后，可以得到实时的数据变更信息，然后根据这个变更信息去更新 Redis 缓存。&quot;<br><br>什么叫伪装呀？还是说负责更新的服务本身就是mysql从节点之一？","like_count":4,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493723,"discussion_content":"它使用MySQL主从同步的协议来从主库接收Binlog，对于主库“看起来，缓存更新服务就像是一个从库一样”。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588514082,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":211780,"user_name":"sea520","can_delete":false,"product_type":"c1","uid":1508621,"ip_address":"","ucode":"C943EAD079B2A4","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIm5rlbJ4HdXLbxmflvW0FW4rTyLcDzHLGDJUJic9W3f1KibWY7mAj9dxUIEVlxDyjwRXEX54KXEn5g/132","comment_is_top":false,"comment_ctime":1588003701,"is_pvip":false,"replies":[{"id":"78795","content":"第一个问题，如果你能定义好冷热数据的严格界限（对于一条数据，在任何一个节点判断冷热的结果都是相同的，并且这个判断不能依赖于本地时钟），是可以做到的。但在实际生产中，很难做到“定义好冷热数据的严格界限”。<br><br>第二个问题，不推荐二个存储互相更新数据，这样很难保证数据一致性。","user_name":"作者回复","user_name_real":"李玥","uid":"1501046","ctime":1588050665,"ip_address":"","comment_id":211780,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18767872885","product_id":100046801,"comment_content":"如何只把mysql中的部分热数据更新到redis呢，而不是全部?<br>如何只把redis中的部分冷数据更新到mysql呢？","like_count":4,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493363,"discussion_content":"第一个问题，如果你能定义好冷热数据的严格界限（对于一条数据，在任何一个节点判断冷热的结果都是相同的，并且这个判断不能依赖于本地时钟），是可以做到的。但在实际生产中，很难做到“定义好冷热数据的严格界限”。\n\n第二个问题，不推荐二个存储互相更新数据，这样很难保证数据一致性。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588050665,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":210852,"user_name":"sea520","can_delete":false,"product_type":"c1","uid":1508621,"ip_address":"","ucode":"C943EAD079B2A4","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIm5rlbJ4HdXLbxmflvW0FW4rTyLcDzHLGDJUJic9W3f1KibWY7mAj9dxUIEVlxDyjwRXEX54KXEn5g/132","comment_is_top":false,"comment_ctime":1587838751,"is_pvip":false,"replies":[{"id":"78566","content":"理论上可以把同步程序伪装者Redis的一个从节点，从Redis接收更新命令，但很少有系统这么做。原因是Redis的性能比MySQL要高出很多，这个数据同步很可能由于MySQL的性能问题，延迟很多。","user_name":"作者回复","user_name_real":"李玥","uid":"1501046","ctime":1587951568,"ip_address":"","comment_id":210852,"utype":1}],"discussion_count":3,"race_medal":0,"score":"14472740639","product_id":100046801,"comment_content":"想问下redis数据同步mysql该怎么做么呢？","like_count":3,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493129,"discussion_content":"理论上可以把同步程序伪装者Redis的一个从节点，从Redis接收更新命令，但很少有系统这么做。原因是Redis的性能比MySQL要高出很多，这个数据同步很可能由于MySQL的性能问题，延迟很多。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587951568,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1128702,"avatar":"https://static001.geekbang.org/account/avatar/00/11/38/fe/00ddeb81.jpg","nickname":"learn more","note":"","ucode":"0EF628B2E0F95E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":271800,"discussion_content":"redis是一条条命令执行，同步到MySQL的时候不一定要一条条去更新MySQL，可以在程序里解析，解析多条之后再批量操作MySQL，这样是不是就可以缓解MySQL的写性能了","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1590196652,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1886331,"avatar":"https://static001.geekbang.org/account/avatar/00/1c/c8/7b/153181d7.jpg","nickname":"夜辉","note":"","ucode":"9421385F51FF9E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1128702,"avatar":"https://static001.geekbang.org/account/avatar/00/11/38/fe/00ddeb81.jpg","nickname":"learn more","note":"","ucode":"0EF628B2E0F95E","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":366456,"discussion_content":"这不算同步吧，如果这个场景满足的话直接异步","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618065961,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":271800,"ip_address":""},"score":366456,"extra":""}]}]},{"had_liked":false,"id":203605,"user_name":"正在减肥的胖籽。","can_delete":false,"product_type":"c1","uid":1033728,"ip_address":"","ucode":"99E2E4DF599236","user_header":"https://static001.geekbang.org/account/avatar/00/0f/c6/00/683bb4f0.jpg","comment_is_top":false,"comment_ctime":1586240419,"is_pvip":false,"replies":[{"id":"76483","content":"在这种情况下，Redis需要做主从来保证高可用，不设数据过期时间，最好还要有补偿机制。","user_name":"作者回复","user_name_real":"李玥","uid":"1501046","ctime":1586429138,"ip_address":"","comment_id":203605,"utype":1}],"discussion_count":4,"race_medal":0,"score":"14471142307","product_id":100046801,"comment_content":"数据同步到redis中，但是redis突然down丢失一些数据，或者redis也会设置缓存时间。那么还是会打到库中？老师你们这里的方案是?或者说你们的redis过期时间怎么平衡？","like_count":3,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":490909,"discussion_content":"在这种情况下，Redis需要做主从来保证高可用，不设数据过期时间，最好还要有补偿机制。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586429138,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1183552,"avatar":"https://static001.geekbang.org/account/avatar/00/12/0f/40/e838871e.jpg","nickname":"zk_207","note":"","ucode":"196D92ECC8540D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":225783,"discussion_content":"我们这不设置过期时间，根据Redis过期策略自动删除缓存，因为之前遇到过缓存失效，差点线上事故","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1586396855,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1210265,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Gswh7ibY4tubXhp0BXOmV2pXZ3XsXic1d942ZMAEgWrRSF99bDskOTsG1g172ibORXxSCWTn9HWUX5vSSUVWU5I4A/132","nickname":"奔奔奔跑","note":"","ucode":"F86EC205DCAACE","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":350736,"discussion_content":"这个需要分场景讨论；简单说下，就是使用singleflight就会把数据库负载降低很多；如果说流量更大的话，就要涉及到了降级，熔断了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1613994637,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1033728,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/c6/00/683bb4f0.jpg","nickname":"正在减肥的胖籽。","note":"","ucode":"99E2E4DF599236","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":226316,"discussion_content":"那内存的速度不是飞快的涨。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586431936,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":225383,"user_name":"衹是一支歌","can_delete":false,"product_type":"c1","uid":1456239,"ip_address":"","ucode":"9FC36529C9FD2E","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/iaZdMmzM0Vfass2ukHOqGgSBbtJMwb4NxDvLdN3R67iczzPVdtF0F0WS0abvls3edQpOVxaUJBmlr2YxHzUpveIQ/132","comment_is_top":false,"comment_ctime":1591749474,"is_pvip":false,"replies":[{"id":"83099","content":"这是NoSQL固有的限制，没办法。<br><br>只能是将最常用的C端查询打到缓存上，其他的查询再想其它办法处理。","user_name":"作者回复","user_name_real":"李玥","uid":"1501046","ctime":1591790897,"ip_address":"","comment_id":225383,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10181684066","product_id":100046801,"comment_content":"数据更新到缓存中，结构不一样了，有的关联查询怎么做呢。","like_count":2,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":497831,"discussion_content":"这是NoSQL固有的限制，没办法。\n\n只能是将最常用的C端查询打到缓存上，其他的查询再想其它办法处理。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1591790897,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":222808,"user_name":"水蒸蛋","can_delete":false,"product_type":"c1","uid":1809160,"ip_address":"","ucode":"6F7F853A4BF901","user_header":"https://static001.geekbang.org/account/avatar/00/1b/9b/08/27ac7ecd.jpg","comment_is_top":false,"comment_ctime":1590916601,"is_pvip":false,"replies":[{"id":"82358","content":"对于硬件的需求其实还好。目前主流的X86服务器256GB内存是比较正常的配置，10台就可以达到2.5T内存了。SSD也基本上是标配，很少新采购的服务器还使用传统机械硬盘了。<br><br>一般大型互联网公司服务器规模，约在几万台起步。","user_name":"作者回复","user_name_real":"李玥","uid":"1501046","ctime":1591151385,"ip_address":"","comment_id":222808,"utype":1}],"discussion_count":3,"race_medal":0,"score":"10180851193","product_id":100046801,"comment_content":"老师，请问下现在的数据量都是T级别的，那如果同步到redis这么大的量不是要T级别的内存，这个要多大的集群规模，而且不便宜啊，这个是不是还会加入ssd之类的？","like_count":3,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":496925,"discussion_content":"对于硬件的需求其实还好。目前主流的X86服务器256GB内存是比较正常的配置，10台就可以达到2.5T内存了。SSD也基本上是标配，很少新采购的服务器还使用传统机械硬盘了。\n\n一般大型互联网公司服务器规模，约在几万台起步。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1591151385,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1691516,"avatar":"https://static001.geekbang.org/account/avatar/00/19/cf/7c/2e99d0ad.jpg","nickname":"一新","note":"","ucode":"1915C6C655C31F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":281608,"discussion_content":"被大厂的有钱深深折服","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1591776221,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1886331,"avatar":"https://static001.geekbang.org/account/avatar/00/1c/c8/7b/153181d7.jpg","nickname":"夜辉","note":"","ucode":"9421385F51FF9E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":366463,"discussion_content":"主流的X86服务器的硬件参数在哪看？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618067335,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":205210,"user_name":"new life","can_delete":false,"product_type":"c1","uid":1447866,"ip_address":"","ucode":"B817AC3909102B","user_header":"https://static001.geekbang.org/account/avatar/00/16/17/ba/c56aa720.jpg","comment_is_top":false,"comment_ctime":1586571272,"is_pvip":true,"discussion_count":1,"race_medal":0,"score":"10176505864","product_id":100046801,"comment_content":"1、感觉使用 canal 通过binlog 的方式，防止了缓存穿透，起到了数据最终一致性的作用，但在缓存数据的时效性方面不能保证；<br>2、通过binlog同步的数据库，应该是专门为缓存使用的吧，否则数据库里数据量很大，会占用Redis大量缓存；<br>3、思考:如果发现数据不一致，应该触发更新缓存的操作，并且限制只有一个线程去更新；","like_count":2,"discussions":[{"author":{"id":2734978,"avatar":"https://static001.geekbang.org/account/avatar/00/29/bb/82/1f2df018.jpg","nickname":"努力向前","note":"","ucode":"7921FFCC91FBD8","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":388716,"discussion_content":"问题，如何发现数据不一致？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1628925313,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":202398,"user_name":"leslie","can_delete":false,"product_type":"c1","uid":1324255,"ip_address":"","ucode":"798E7C1CC98CC2","user_header":"https://static001.geekbang.org/account/avatar/00/14/34/df/64e3d533.jpg","comment_is_top":false,"comment_ctime":1585983820,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5880951116","product_id":100046801,"comment_content":"这其中其实有个坑：redis与mysql之间的设置，多少合适？太小访问太频繁，太大更新不及时。<br>电商中哪些业务的刷新频率的设置这个确实。。。","like_count":1},{"had_liked":false,"id":202257,"user_name":"饭团","can_delete":false,"product_type":"c1","uid":1332557,"ip_address":"","ucode":"E24F240CC91BE8","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erbY9UsqHZhhVoI69yXNibBBg0TRdUVsKLMg2UZ1R3NJxXdMicqceI5yhdKZ5Ad6CJYO0XpFHlJzIYQ/132","comment_is_top":false,"comment_ctime":1585945298,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5880912594","product_id":100046801,"comment_content":"学到了，哈哈！之前一直看有解析binlog日志的做法！","like_count":1},{"had_liked":false,"id":360077,"user_name":"距离30米","can_delete":false,"product_type":"c1","uid":1516600,"ip_address":"四川","ucode":"5566D9AB9E47DE","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/wBjvGCCZmO0Bic0DrnG466y6hwPkibGevAV6E6FPfQEricvw5toL7a2HSgjhI83cCiadrUibIyVibkgbbMOHVxo7HA8Q/132","comment_is_top":false,"comment_ctime":1666164910,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1666164910","product_id":100046801,"comment_content":"采用canal的话，我认为是业务要接受数据有些许的延迟的，是最终一致性的方式","like_count":0},{"had_liked":false,"id":347119,"user_name":"Geek.N","can_delete":false,"product_type":"c1","uid":2744271,"ip_address":"","ucode":"E4893C3C512FB2","user_header":"https://static001.geekbang.org/account/avatar/00/29/df/cf/6e0dbfe5.jpg","comment_is_top":false,"comment_ctime":1653726144,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1653726144","product_id":100046801,"comment_content":"请问老师如果有大量更新请求打在mysql数据库上这种情况该如何解决？","like_count":0,"discussions":[{"author":{"id":1520538,"avatar":"https://static001.geekbang.org/account/avatar/00/17/33/9a/f295dea5.jpg","nickname":"李正g","note":"","ucode":"A7BEA03BB6537A","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":581382,"discussion_content":"之前课程说了， 分库分表","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1658747331,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":337931,"user_name":"Jerry","can_delete":false,"product_type":"c1","uid":1622887,"ip_address":"","ucode":"F8C5EED655B8D6","user_header":"https://static001.geekbang.org/account/avatar/00/18/c3/67/568181d7.jpg","comment_is_top":false,"comment_ctime":1647163968,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1647163968","product_id":100046801,"comment_content":"请教一下老师，我现在有个需求，是从redis实时同步数据到mysql，或者间隔性1分钟同步一次也行，有什么比较好的方案吗？","like_count":0},{"had_liked":false,"id":327325,"user_name":"麦耀锋","can_delete":false,"product_type":"c1","uid":1401327,"ip_address":"","ucode":"077DA831185C01","user_header":"https://static001.geekbang.org/account/avatar/00/15/61/ef/ac5e914d.jpg","comment_is_top":false,"comment_ctime":1640067071,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1640067071","product_id":100046801,"comment_content":"对于canal，因为只针对mysql，如果要更加通用的，是否采用支持CDC的一些组件，例如Debzium、flinkx、flink-cdc？","like_count":0},{"had_liked":false,"id":322881,"user_name":"董俊俊","can_delete":false,"product_type":"c1","uid":1297887,"ip_address":"","ucode":"732300A779660B","user_header":"https://static001.geekbang.org/account/avatar/00/13/cd/df/c520d418.jpg","comment_is_top":false,"comment_ctime":1637642305,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1637642305","product_id":100046801,"comment_content":"如何解决查表法中这个表数据量过大的问题啊？","like_count":0},{"had_liked":false,"id":291338,"user_name":"王泓斌","can_delete":false,"product_type":"c1","uid":1975582,"ip_address":"","ucode":"11911864AE3781","user_header":"","comment_is_top":false,"comment_ctime":1620217112,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1620217112","product_id":100046801,"comment_content":"京东内部不是有蜂巢根据binlog同步数据吗? 什么时候能拿出来开源啊？<br>还有binlake？能否帮忙询问下是否能开源","like_count":0},{"had_liked":false,"id":274465,"user_name":"pretentious","can_delete":false,"product_type":"c1","uid":2036918,"ip_address":"","ucode":"DFEC9F281E33CD","user_header":"https://static001.geekbang.org/account/avatar/00/1f/14/b6/a7bc43d9.jpg","comment_is_top":false,"comment_ctime":1611029528,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1611029528","product_id":100046801,"comment_content":"我们也是在做整表全量缓存，但是需要多个纬度的查询时，redis如何存储？存多份的话有冗余，且要保证一致性；如果是存一份映射，先找到唯一键，再根据唯一键拿数据，那映射和全量数据之间又是强关联关系了；请教老师，这种问题如何解决呢","like_count":0,"discussions":[{"author":{"id":1881778,"avatar":"https://static001.geekbang.org/account/avatar/00/1c/b6/b2/ebb59efe.jpg","nickname":"广播风暴","note":"","ucode":"0EEC713EADA303","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":392279,"discussion_content":"总要取舍，关心的放到重要的位置就好","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1630932396,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":250105,"user_name":"lidashuang","can_delete":false,"product_type":"c1","uid":1104850,"ip_address":"","ucode":"560ABE8032760E","user_header":"https://static001.geekbang.org/account/avatar/00/10/db/d2/e29f8834.jpg","comment_is_top":false,"comment_ctime":1600937141,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1600937141","product_id":100046801,"comment_content":"然后来配置 MySQL，我们需要在 MySQL 的配置文件中开启 Binlog，并设置 Binlog 的格式为 ROW 格式。<br><br>必须设置row 格式吗？<br>","like_count":0,"discussions":[{"author":{"id":1971966,"avatar":"https://static001.geekbang.org/account/avatar/00/1e/16/fe/323b81c2.jpg","nickname":"霖","note":"","ucode":"9A985C64D3836C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":365296,"discussion_content":"row方式记录的是mysql物理变更的结果，比如说id=1的数据，字段A改为B\nStatement方式记录的是sql，也就是执行批量更新或者删除时没办法马上解析到具体更改的数据","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1617764740,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":249089,"user_name":"djfhchdh","can_delete":false,"product_type":"c1","uid":1484184,"ip_address":"","ucode":"E71D75328CE398","user_header":"https://static001.geekbang.org/account/avatar/00/16/a5/98/a65ff31a.jpg","comment_is_top":false,"comment_ctime":1600425371,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1600425371","product_id":100046801,"comment_content":"全部读缓存全量，其实是一种缓存策略吧，refresh ahead？","like_count":0},{"had_liked":false,"id":233300,"user_name":"風逸飛²º¹⁷","can_delete":false,"product_type":"c1","uid":1016159,"ip_address":"","ucode":"CA951BF5289531","user_header":"https://static001.geekbang.org/account/avatar/00/0f/81/5f/4bbdc290.jpg","comment_is_top":false,"comment_ctime":1594282895,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1594282895","product_id":100046801,"comment_content":"老师，你说的这种用Binlog | MQ + 更新redis 的操作，在并发量很大的情况下，刷新缓存仍然会有延迟，binlog会有延迟，消息多的时候还可能造成CPU飙升","like_count":0,"discussions":[{"author":{"id":2734978,"avatar":"https://static001.geekbang.org/account/avatar/00/29/bb/82/1f2df018.jpg","nickname":"努力向前","note":"","ucode":"7921FFCC91FBD8","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":388717,"discussion_content":"这种延迟没啥好的解决办法，除非读写都走MySQL主库。如果设置MySQL主从架构，写都走主库，读都走从库，那么主从同步也是有延迟的。当刚刚写入一条数据后，接着去从库查询。若是这个数据还没复制到从库的话，那么去从库查询，会查不到数据。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1628925578,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":227634,"user_name":"西门吹牛","can_delete":false,"product_type":"c1","uid":1508990,"ip_address":"","ucode":"E5D3624DDE1E83","user_header":"https://static001.geekbang.org/account/avatar/00/17/06/7e/735968e2.jpg","comment_is_top":false,"comment_ctime":1592446865,"is_pvip":false,"replies":[{"id":"84537","content":"请继续学习《19 | 跨系统实时同步数据，分布式事务是唯一的解决方案吗？》，里面会讲到如何尽量降低同步时延。","user_name":"作者回复","user_name_real":"李玥","uid":"1501046","ctime":1592918172,"ip_address":"","comment_id":227634,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1592446865","product_id":100046801,"comment_content":"老师好，我在工作中，用过canal，对一些库中表，进行监听， 然后发消息，这个canal，能监听多张库？如果监听多张库，canal的性能会不会下降，会不会出现读取binlog日志较慢，导致数据同步延迟？","like_count":0,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":498727,"discussion_content":"请继续学习《19 | 跨系统实时同步数据，分布式事务是唯一的解决方案吗？》，里面会讲到如何尽量降低同步时延。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1592918172,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1508990,"avatar":"https://static001.geekbang.org/account/avatar/00/17/06/7e/735968e2.jpg","nickname":"西门吹牛","note":"","ucode":"E5D3624DDE1E83","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":285726,"discussion_content":"感谢老师回复，之前没看到第19节内容，后来看到之后，这个问题已经明白了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1592921364,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}