{"id":792682,"title":"结束语｜再谈大模型应用开发","content":"<p>“你好，我是黄佳。” —— 随着我第24次输入这个句子，我们的这门课程也进入了尾声。其实，每一个课程，都是我对当下这个节点的学习过程的一次真实记录和总结。感谢朋友你，又陪着我走完了一次不长不短的旅程。</p><p>在开篇词中，我引用了李彦宏的观点，“大模型应用开发时代，人人都是程序员”。那么在结束语中，让我再次引用他在一年一度的世界人工智能大会（WAIC）的最新演讲金句做开场——<strong>没有应用，光有基础模型，不管是开源还是闭源都一文不值</strong>。</p><p>他说，只要对应用场景能产生大的增益，那么，大模型应用开发的整体价值，就比移动互联网要大得多了。</p><p>话虽如此，我们的实际感受是，要让大模型应用呈现出互联网和移动互连网时代中App风起云涌的那种状态，还尚待时日。大模型应用开发整体的情况是雷声大，雨点小。</p><p><img src=\"https://static001.geekbang.org/resource/image/db/92/dbdf3458bd67fedcf0f2922441303592.png?wh=2015x1079\" alt=\"图片\" title=\"优秀的 LLM 应用还非常稀少\"></p><p>对此，我的看法是，历史的车轮将滚滚向前，已经不会由人类的意志为转移，大模型时代已经到了，而且必定会改变我们工作和生活的方方面面。当前的雨点越小，作为先行者的我们未来收获可能就越多。</p><p>李建忠老师在最近的一次演讲中，对大模型在软件开发领域的应用提出了深刻而全面的见解。他认为大模型在处理<strong>直觉性任务</strong>（也就是思考快与慢一书中提到的系统1思维）方面表现出色，但在<strong>需要深度思考的编程任务</strong>（也就是思考快与慢一书中系统2思维）中仍有不足。这一观察为理解大模型在严肃编程领域效果不如预期提供了重要线索。</p><!-- [[[read_end]]] --><p>业界对大模型应用于软件开发的一个常见误区是，过于追求一步到位的智能，以及过度期望全能型智能。面对软件系统的复杂性、动态性、协作性和混沌性，一种平衡的思路是，大模型时代并非要抛弃传统软件开发的经验，而是应该将其与新技术相结合，实现经验的压缩和加速。我们既要充分认识到大模型的潜力，又要清醒地看到其局限性。在利用AI技术增强软件开发的同时，我们要保持对传统软件工程智慧的尊重，通过创新方法来应对未来软件开发的挑战。</p><p>那么，针对大模型应用开发的落地现状，我最近对大模型落地难也总结了三点肤浅的思考，以及三点值得尝试的探索方向。</p><p><img src=\"https://static001.geekbang.org/resource/image/51/f0/5100c52ac3f9a1ba5dyycb31d2e9fbf0.png?wh=2068x1034\" alt=\"图片\"></p><p>第一个难点在于，虽然LLM在通用知识和语言理解方面表现出色，但在处理特定的复杂业务场景时往往力不从心。主要原因是缺乏特定领域知识：LLM 通常是基于通用数据训练的，缺乏对特定行业或业务流程的深入理解。而且，每个企业都有其独特的业务流程和规则，LLM 无法自动掌握这些细节，也无法准确把握业务需求的微妙之处，导致生成的内容或建议可能偏离实际需求。</p><p><img src=\"https://static001.geekbang.org/resource/image/yy/26/yyc10e2d26582a6881a09d3801b06526.png?wh=2049x1058\" alt=\"图片\"></p><p>第二个难点在于，尽管 LLM 在很多任务上表现优异，但它并非完全可靠。LLM 有时会生成看似合理但实际上并不准确的信息；LLM 有时候并不清楚自己知识的边界，可能会自信地给出错误答案。相同的输入可能会得到不同的输出，缺乏稳定性。而且，LLM 的知识往往有时间截止点，无法实时更新。</p><p><img src=\"https://static001.geekbang.org/resource/image/51/8e/5182b5dec1c269902eb0400c75a3d08e.png?wh=2050x1049\" alt=\"图片\"></p><p>最后，LLM 作为一个独立的系统，与现有的业务系统和工具集成存在挑战。LLM 的实际能力取决于它能够访问和调用的外部工具和 API，它无法直接操作或理解企业的特定软件系统；由于隐私和安全考虑，企业的核心数据也可能无法传给云端的LLM，因此LLM 可能也无法实时获取或处理业务系统的最新数据。</p><p>上面的这些问题，都是真真实实存在的拦路之虎。但是，如果一个新技术在实际落地过程中，没有任何拦路虎，不需要任何深度的思考就轻松实现，那么，这个新技术未免也太没有含金量了。</p><p>因此，针对这些问题，我也提出三个探索方向。</p><ol>\n<li>精准寻找合适的业务场景，通过更精准的业务场景定位，让LLM的能力能够得到充分发挥和落地。</li>\n<li>优化而不是重塑，关注优化现有业务流程，而不是彻底重构整个系统。</li>\n<li>形成流程闭环，将LLM的能力与本地原生工具相结合，形成完整的业务流程闭环。</li>\n</ol><p>比如说，我的一位朋友就分享了一个不错的落地案例。他所在的企业，通过LLM开发的Agent + RPA + 企业微信，解决了一系列内部重复性的工作。这个例子，就很符合我上面所说的三个探索方向，其实就是<strong>在对大模型能力的深度理解基础上，抓住实际场景，把它的能力用起来</strong>。</p><p><img src=\"https://static001.geekbang.org/resource/image/96/be/9685625bd202f3068fe993ff7dedb1be.png?wh=787x920\" alt=\"图片\" title=\"不错的 LLM 应用落地案例\"></p><p>最后的最后，从以人为本的角度出发，我其实真正想说的是：在探讨大型语言模型落地难点和解决方案的同时，最最最关键因素仍然是“<strong>人才储备和个人能力提升</strong>”。</p><p>目前，几乎全部的算力都集中在了大模型的训练端。单只是这样，英伟达的股价就已经上天了，但是，让我们每个人扪心自问，我们每天对大模型的使用量够吗？我们有没有把越来越便宜的大模型羊毛撸到极致？</p><p>想象一下，当我们在生活和工作中遇到每一个问题，首先都应该想到，这个事儿是不是应该来由大模型来做，至少也是我们人类和大模型一起来做。只有当这样的想法成为了我们的思维定势，我们的AI用量才能够真正上去，工作的含人量才能逐步下降。</p><p><strong>当人人都习惯了大模型，当大模型的算力逐渐从训练端过渡到推理端，那才是真正的 AI时代的降临。</strong>（温馨提示：英伟达股价可能还会进一步飙升，因为目前推理侧算力远未饱和。免责声明：利益无关，不承担风险。）</p><p>回过头来，对于企业来说，复合型人才的培养和储备至关重要。这些人才不仅要深谙业务流程，还要具备扎实的AI技术知识。他们是连接AI技术与实际业务需求的桥梁，能够准确识别适合AI应用的场景，设计出切实可行的解决方案，并有效管理实施过程中的各种挑战。目前，已经有很多企业意识到了这一点，因为我自己就收到了非常多的企业内训邀请，各企业都如饥似渴的为自己的员工补充大模型的养分。</p><p>而对于我们个人来说，就努力学习并实践吧，<strong>让我们用大模型的能力来武装自己的头脑，不负时代</strong>！</p><p>最后，这里有一份<a href=\"https://jsj.top/f/vEgT0K\">调研问卷</a>，期待你能谈谈对这门课程的学习体验，建议或意见都欢迎指出。我们会根据你的反馈持续迭代课程，让知识长久传递，内容常看常新！</p><p><a href=\"https://jsj.top/f/vEgT0K\"><img src=\"https://static001.geekbang.org/resource/image/6a/1f/6a20578e0b8e345ff85a5036b50afc1f.jpg?wh=1142x801\" alt=\"图片\"></a></p>","neighbors":{"left":{"article_title":"22｜如何在与LLM交互过程中省钱及控制Rate Limits？","id":791499},"right":{"article_title":"结课测试｜来赴一场满分之约","id":793056}},"comments":[{"had_liked":false,"id":392324,"user_name":"qinsi","can_delete":false,"product_type":"c1","uid":1667175,"ip_address":"上海","ucode":"090D9C4068FF12","user_header":"https://static001.geekbang.org/account/avatar/00/19/70/67/0c1359c2.jpg","comment_is_top":false,"comment_ctime":1720597113,"is_pvip":true,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100764201,"comment_content":"推理端也可能asic或fpga甚至cpu更有性价比","like_count":0}]}