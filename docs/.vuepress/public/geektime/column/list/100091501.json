[{"article_id":420765,"article_title":"开篇词｜如何设计一个高并发、高可用的秒杀系统？","article_content":"<p>你好，我是志东，欢迎和我一起从零打造秒杀系统。</p><p>说起秒杀系统啊，我相信你一定听过，甚至亲身参与过秒杀活动。作为技术人，你应该也好奇和思考过秒杀系统背后的实现方案，或者你在面试的时候被问到过，毕竟说它是高频考点一点不夸张。</p><p>因此，可能你已经搜索过秒杀系统的实现，对其有了一定的了解。但我们常说理论和实践是有距离的，知道一些基本的设计理念，其实远不能完成体系化学习的目标。“纸上得来终觉浅，绝知此事要躬行”，我相信头部电商百万用户同时秒杀的实战经验，会是个不错的加持，可以帮助你深刻理解技术难点。</p><p>所以，我来了！作为曾经的头部电商平台的秒杀系统负责人，我经常会和同事、朋友们讨论秒杀系统，当然在设计过程中，我们也确实遇到了很多问题。那么作为整个专栏的开篇，我想先就学习秒杀系统的<strong>共性问题</strong>做一个解答，期望和你对齐目标，然后我们一起向终点发起挑战！欢迎加入思考。</p><h2>三个问题</h2><p><strong>问题一：为什么需要秒杀系统？秒杀系统最大的优势是什么？</strong></p><p>通俗点讲，电商平台的本质是在线上撮合买卖双方的购销需求，达成交易。虽然是线上交易，但也遵守朴素的经济学原理，供求关系决定了商品的经济活动。当<strong>供求平衡</strong>时，买方和卖方处于对等关系，双方是相对稳定、和谐的；当<strong>供大于求</strong>时，这时候市场成了买方市场，买方处于主动地位；当<strong>供不应求</strong>时，这时候市场是卖方市场，卖方处于有利的主导地位。</p><!-- [[[read_end]]] --><p>买卖双方的关系不同，决定了电商平台会采用哪种营销方式。当供大于求，一般会采用各种促销让利的方式，吸引消费者购买，常见的促销方式有单品满减、总价优惠、赠品、会员优惠等；当供不应求，就需要有计划地设置营销活动、用户参与门槛以及限购规则，尽可能的让商家利益最大化，同时惠及更广泛的消费者。</p><p><img src=\"https://static001.geekbang.org/resource/image/dc/79/dcbf846eb29232268a3ae01a8776b479.png?wh=1346x686\" alt=\"\"></p><p>当供需出现极度不平衡时，不管是线下还是线上，都会出现抢购的情况。上面这张照片，是1992年深圳市首次发行股票时群众抢购的情况，“利”字驱动，抢到即是赚到，万人空巷。同样，在线上，当1499元平价茅台上架时，当抢到口罩意味着守护更多一份健康时，流量激增，更是盛况空前。因此，回答为什么需要秒杀系统，其实很简单，那就是<strong>商品的极度供不应求</strong>。</p><p>那么秒杀系统又有哪些优势呢？对于这些极度供不应求的爆品，合理地设置活动，适时地释放库存，可以持续为电商平台带来稳定的热度和流量，可观的VIP会员费，以及技术口碑的认同。当然，通过秒杀系统，电商平台也可以对参与用户进行筛选，杜绝黄牛和刷子，让爆品惠及更广，更公平。</p><p><strong>问题二：京东、阿里巴巴等头部电商平台都把建设秒杀系统放在了什么地位？</strong></p><p>在头部电商平台，除了售卖我们前面讨论的爆品外，更多售卖的是普通商品，这两类商品特点鲜明，爆品具有流量激增的特点，而普通商品流量则比较均衡。</p><p>这里我想请你思考一下：如果这两类商品不加区别，直接在电商平台上一块进行交易，会有什么问题？</p><p>没错，灾难性的后果，容易引发平台P0级重大事故。究其原因，主要就在于秒杀流量是突发式的，而且流量规模很难提前准确预估，如果混合在一起，势必会对普通商品的交易造成比较大的冲击。</p><p>因此，对京东、阿里而言，即使需要投入新的资源，也是需要单独搭建一套秒杀系统的，它将作为<strong>交易体系非常重要的一个核心系统</strong>。</p><p>可见，秒杀在京东、阿里具有非常重要的地位，它是非常重要的营销手段之一。每年的618和双11两次大促，京东都会投入大量的人力资源和机器资源来进行备战，在备战过程中，都会将其作为一个独立专项进行推进，从专项架构梳理、流量预估、全链路压测，到专项预案演练等，再到集团技术VP的专项汇报，都体现了秒杀在大厂中不可或缺的地位。</p><p>而在平常，由于爆品运营的日常化，秒杀系统每天都在承担着重要的使命，同理对技术团队来说，每天都需要像大促那样做好秒杀的稳定保障工作。</p><p><strong>问题三：秒杀系统对于电商技术从业者意味着什么？为什么要学习秒杀系统？</strong></p><p>秒杀系统是电商技术从业者绕不开的一个话题，大到京东、阿里这样的头部电商，小到新兴的社区团购公司，都需要通过秒杀促销活动进行拉新留存，或持续引流保持热度。因此对于从事电商行业的同学来说，设计和开发秒杀系统就是一门必修课。</p><p>退一步说，即便是电商领域范围广、内容多、分工细，当前你的工作范围并不涉及秒杀系统，你也可以花些时间来系统学习一下。</p><p>一方面，这门课程里介绍的一些高可用、高性能、高并发的设计思路遵循普适的原则，在设计其他电商系统时你可以举一反三；另一方面，据我了解，大部分的电商面试场景都会考核秒杀系统的设计能力，而从我自身这么多年作为面试官的经验来看，很多候选人或多或少能描述出一些秒杀的设计思路，比如有些同学知道怎么进行库存控制，有些知道隔离，有些知道限流等等，但是能够系统地讲出怎么设计一个秒杀系统，这样的候选人少之又少。</p><p>讨论完这几个问题，你是不是已经开始好奇这门秒杀课会有什么不一样的地方？毕竟电商发展到今天，秒杀系统已经不是个新鲜的话题了。那么闲话少叙，我们一起看看课程设计。</p><h2>课程设计</h2><p>首先，我们说说课程亮点。为了让你对秒杀系统有一个全面的认知，这门课程我会手把手带你搭建一个秒杀系统，从基础的设计原则讲起，到高阶的设计技巧实战都会涉及，你看到的、学到的将是<strong>一个可扛百万流量的秒杀实战项目</strong>。</p><p>这里我十分鼓励你跟着课程一步步验证，就像我开始说的，没有什么是比你亲手实践一遍收获更大的。这里附上GitHub地址：<a href=\"https://github.com/sanyecao-seckill\">https://github.com/sanyecao-seckill</a>，以及所使用的编程语言：Nignx服务有Lua语言，后端服务都是Java。</p><p>所以说，这门课的受众目标也会较为广泛，它既适用于没有太多经验的初级工程师学习和参考，也可以让相对经验丰富的高级电商从业者查漏补缺，完善学习体系。</p><p>接下来，我们看看具体内容，共分为六个部分。</p><p><strong>前期准备：</strong>这部分我会从秒杀的业务挑战开始讲起，带你看看电商平台的秒杀玩法，总结设计原则；接着我会带着你做秒杀的技术选型，安装基础环境。</p><p><strong>系统动工：</strong>这部分的内容比较基础，我会对秒杀系统进行业务解构，开始着手搭建秒杀的项目工程，梳理秒杀的业务流程，分析系统提供的接口，填充秒杀的业务实现，最终完成一个最简秒杀系统。</p><p><strong>稳定压倒一切：</strong>这部分聚焦在“稳”上，在最简秒杀系统的基础上，我将带着你进行高可用建设，重点讲解秒杀的隔离、流控、削峰、限流、降级、热点和容灾。</p><p><strong>准确无误：</strong>这部分聚焦在“准”上，我们将通过防刷和风控，学习如何保证商品不卖给黄牛和刷子，以确保秒杀的公平性；接着会介绍秒杀的库存和限购设计，以确保商品不超卖，符合限购规则。</p><p><strong>雷令风行：</strong>这部分聚焦在“快”上，我将带着你一起进行系统优化，从而让我们的秒杀系统响应更快，用户体验更好。</p><p><strong>尾声：</strong>最后就是总结部分，梳理整个实战项目的关键点；另外我将结合自身经验，带给你在头部电商的秒杀玩法中，除了上述技术内容外的业务协同思考。</p><p><img src=\"https://static001.geekbang.org/resource/image/85/f1/85eee31f737518f3d26f82ed705399f1.jpg?wh=1896x814\" alt=\"\"></p><p>值得一提的是，每节课我都会布置一道思考题，你要做好准备哦，我们可以一起互动解决。</p><h2>自我介绍</h2><p>那么分享到这里，你可能还不认识我，这里做个自我介绍。</p><p>我叫佘志东，本科和硕士均毕业于华中科技大学。参加工作后，到目前为止，我的职业生涯可以分为两个阶段。第一个阶段是通讯行业，主要服务于朗讯、思科、华为等头部通讯公司，从Java工程师成长为软件架构师，是早期思科视频云平台的设计者和核心开发者。</p><p>从2015年开始，我进入了互联网行业，先后服务过唯品会、京东等知名互联网公司，任职资深架构师，擅长高并发分布式软件架构与开发，也是京东交易平台上海团队负责人，曾负责过京豆、预售、秒杀等核心系统。</p><p>每年的618和双11，京东大促看交易，交易大促看预售开门红，历经了三年内预售流量和订单增长十几倍的系统稳定性的巨大挑战。2020年初，在疫情背景下，我带领团队日夜奋战，为全民抢购口罩项目保驾护航，所负责的秒杀系统成功扛住了三百万人同时秒杀的巨大压力。</p><p>作为一个常年奋战在一线的架构师，我为我参与过的项目感到自豪，也希望能在这里将这份收获与沉淀传递给你！</p><p>随着技术变革，秒杀系统、电商行业乃至整个互联网还会迎来诸多挑战，时代会对技术人提出更高的要求。所以，在当下，我们更应该时刻保持好奇心，保持求知欲，保持激情。“学海无涯苦作舟”，让我们一起苦中作乐，通过学习持续武装自己！</p><p>最后，希望这门课能让你在动手实践中，对秒杀系统有一个新的感悟。更多疑惑与思考，或是在实践中遇到了哪些困难，都欢迎你在留言区中提出，我们共同探讨。</p>","neighbors":{"left":[],"right":{"article_title":"01｜直面痛点：秒杀系统的挑战和设计原则","id":420777}}},{"article_id":420777,"article_title":"01｜直面痛点：秒杀系统的挑战和设计原则","article_content":"<p>你好，我是志东，欢迎和我一起从零打造秒杀系统。</p><p>每年的618、双11都是电商平台的狂欢日，各种营销活动、营销方式层出不穷，而秒杀就是其中最重要的手段之一。飞天茅台、华为手机、高端显卡等热门商品的抢购活动，即使你没有抢过，也或许听过，这就是秒杀带来的影响力。用具有价格优势的稀缺商品，来增加电商平台的关注度，带来空前的流量，进而可以为平台的拉新带来新助力，如果再辅以其他营销手段，比如抢购资格限制VIP等，那么这又是一笔可观的创收。</p><p>所以在当下这个流量为王的网络时代，能够提供秒杀的营销手段，就显得异常重要，这也是我们为什么需要做秒杀系统。</p><p>当然，实现一个秒杀系统也并不是那么容易的事，要考虑的点有很多。比如，我们首先要知道秒杀活动的业务特点，其次是要清楚秒杀系统的请求链路，这样才能根据其特点，针对请求链路中可能存在的瓶颈点做优化与设计。除此之外还有很多其他问题，我会在之后的课程中一一详解。</p><p>那么作为专栏的第一课，为了让你对秒杀系统有一个整体的认知，接下来我们就综合看一下当下秒杀系统都存在哪些挑战，以及所要遵循的设计原则，这些可以为我们后面的实战打下一个很好的基础。</p><h2>秒杀怎么玩</h2><p>我先简单介绍下秒杀业务具体是怎么玩的。</p><!-- [[[read_end]]] --><p>通常情况下，平台商家会拿出稀缺商品，事先在秒杀的运营系统中设置好活动的开始、结束时间，以及投入的库存（简单的玩法，只要这几个主要元素即可）。在活动开始之后，用户可以通过活动抢购入口（一个商品详情页，或是一个广告链接），进入到活动的结算页，然后点击下单，完成商品的抢购操作，整个过程如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/38/73/380d9ea5bbaeb991d2fcdf87bd1bd773.jpg?wh=2000x1100\" alt=\"\"></p><p>这种方式通用性很强，可以适配大部分的平台。当然如果想对流量有个预期上限，方便做备战工作，那么你可以加上预约功能，即在活动开始前，先开放一段时间的预约，让用户先去进行预约，然后才能获得参加抢购活动的资格。</p><p>如果面对的业务场景复杂些，你还可以联合风控，在参加活动时校验用户资质，踢掉黄牛以及有过不良行为的人，尽量将资源给到优质用户。</p><p>那么如果业务再复杂些呢？可以搭配限购开展活动，控制个人维度下一段时间内的购买数，让抢购成功的快乐触达更多的人。</p><p>以上列举的各种组合使用场景，你都可以根据自己的实际情况灵活变通，或者开拓思维创造属于自己独特的秒杀玩法。其实在电商大行其道的今天，大部分玩法已经比较通用了，相信这些方式你也都参与过。</p><p>秒杀系统还是很美好的，可怎么样才能实现它呢？</p><h2>秒杀系统的挑战</h2><p>首先，我们得直面以下的这些挑战。</p><h3>巨大的瞬时流量</h3><p>秒杀活动的特点，就是将用户全部集中到同一个时刻，然后一起开抢某个热门商品，而热门商品的库存往往又非常少，所以持续的时间也比较短，快的话可能一两秒内就结束了。</p><p>这种场景下，高并发产生的巨大瞬时流量，首先会击垮你服务的“大门”，当“大门”被击垮后，外面的进不来，里面的出不去，进而造成了整个服务的瘫痪；退一步说，即便你保住了大门，进来的流量如果不加以管控，任凭其横冲直撞，也会对依赖的基础设施服务造成毁灭性打击；再退一步说，即使我们的系统没有被摧毁，在机器资源的高负载下，整个请求链路的响应时间也会跟着拉长，这样就会大大降低用户的抢购体验，紧接着就会是蜂拥而来的客诉。本想通过秒杀活动带来正面影响，但结果可能恰恰相反。</p><p>我记得京东最开始用秒杀系统售卖口罩时，就出现过类似的问题。技术团队内部事前没有沟通充分，导致准备不足，大家谁也没有预料到活动商品会成为爆品，以致最终的用户抢购体验很差。当然了这也不限于京东，相信每逢大促把瞬时流量测试列为重中之重的平台还是非常多的。</p><h3>热点数据问题</h3><p>高并发下一个无法避开的问题，就是热点数据问题。</p><p>特别是对于秒杀活动，大家抢购的都是同一个商品，所以这个商品直接就被推到了热点的位置，不管你是用的数据库，还是分布式缓存，都无法支持几十万、上百万对同一个key的读写，以Redis的写为例，最高仅可支持几万的TPS。像商品库存的控制，就会有这个问题。</p><h3>刷子流量</h3><p>当你的系统被刷子盯上，那说明你的秒杀系统已经有了很大的影响力了。一般我们提供的秒杀对外服务，都是HTTP的服务。不管你是用H5实现的页面，还是通过安卓或是iOS实现的原生页面，特别是H5，都可以直接通过浏览器或是抓包工具拿到请求数据，这样刷子便可以自己通过程序实现接口的直接调用，并可以设置请求的频率。</p><p>这样高频次的请求，会挤占正常用户的抢购通道，同时，刷子也获得了更高的秒杀成功率。这不仅破坏了公平的抢购环境，也给系统服务带来了巨大的额外负担。</p><p>其实总结来说，瞬时的大流量就是最大的挑战，当业务系统流量成几何增长时，有些业务接口加机器便可以支持。但考虑到成本与收益，在有限的资源下，如何通过合理的系统设计来达到预期的业务目标，就显得格外重要了。</p><h2>秒杀系统如何设计</h2><p>清楚了秒杀系统所面临的挑战，接下来我们就可以考虑如何应对了。所谓知己知彼，百战不殆。在设计系统之前，我们不妨先来看下，一次HTTP请求所经过的链路路径：</p><p><img src=\"https://static001.geekbang.org/resource/image/b0/1b/b00056b2589a86dc6523e248f607f11b.jpg?wh=1918x934\" alt=\"\"></p><p>这是一个比较宏观的图谱，如果我们提供的是一个HTTP服务，那么每个客户端请求进来都要经过这些链路，而每个链路节点的作用又是什么呢？我们逐一看下。</p><p><strong>DNS</strong>：负责域名解析，会将你的域名请求指定一个实际的IP来处理（事先配置好处理请求的IP，DNS按顺序指定），并且一般客户端浏览器会缓存这个IP一段时间，当下次再请求时就直接用这个IP来建立连接，当然如果指定的IP挂了，DNS并不会自动剔除，下次依然会使用它。</p><p><strong>Nginx</strong>：也就是上面的被DNS指定来处理请求的IP，一般都会被用来当做反向代理和负载均衡器使用，因为它具有良好的吞吐性能，所以一般也可以用来做静态资源服务器。当Nginx接收到客户端请求后，根据负载均衡算法（默认是轮询）将请求分发给下游的Web服务。</p><p><strong>Web服务</strong>：这个就是我们都比较熟知的领域了，一般我们写业务接口的地方就是这了，还有我们的H5页面，也都可以放到这里，这里是我们做业务聚合的地方，提供页面需要的数据以及元素。</p><p><strong>RPC服务</strong>：一般提供支撑业务的基础服务，服务功能相对单一，可灵活、快速部署，复用性高。RPC服务一般都是公司内部服务，仅供内部服务间调用，不对外开放，安全性高。</p><p>在了解了一次请求所经过的链路节点后，接下来我们再看下，在用户的一次抢购过程中，每次和系统的交互都要做什么事情。</p><p><img src=\"https://static001.geekbang.org/resource/image/0b/68/0bbe71ceab7c344cyydfc81bb32e8968.jpg?wh=1973x1502\" alt=\"\"></p><p>结合上图来看，商详页部分和支付页部分，对于一般平台来说，都是通用板块，而从“点击抢购”开始到“下单成功待支付”，这一段是属于秒杀系统的业务范畴，在这里我们梳理下，有哪几件事情是需要秒杀系统来做的。</p><p><strong>1.提供活动数据</strong>：提供参加秒杀活动的商品信息，主要用于商详页判断活动的倒计时、开始、结束等页面展示和抢购入口校验。</p><p><strong>2.提供结算页</strong>：如果把秒杀做成一个单独业务模块，可跨平台（安卓、PC、iOS）嵌入，那么就需要提供一整套服务，包括H5页面，主要用于展示商品的抢购信息，包括商品名称、价格、抢购数量、地址、支付方式、虚拟资产等等。</p><p><strong>3.提供结算页页面渲染所需数据</strong>：包括用户维度的地址、虚拟资产等数据，活动维度的名称、价格等数据。</p><p><strong>4.提供下单</strong>：用户结算页下单，提供订单生成或是将下单数据透传给下游（如果平台有通用的订单接入接口）。</p><p>当然在这中间，还有个隐形的，但却是非常重要的核心能力，那就是做<strong>流量的精细化筛选</strong>，尽量确保传给下游接口的流量，都是优质请求。</p><p>以上，我们了解了HTTP请求所经过的链路，也总结了秒杀系统所需要提供的能力，那么接下来，我们就可以着手做秒杀系统的设计了。</p><p>对于系统的设计，有一些基本的原则，比如校验前置、分层过滤，再结合我们上面的链路路径图，效果如下所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/5f/50/5fd7d23c72f02459c9e17yy50d0e2850.jpg?wh=2000x1100\" alt=\"\" title=\"流量漏斗图\"></p><p>一般我们会在<strong>DNS层</strong>做一些和网络相关的防攻击措施，公司的网络安全部门有统一的一些配置措施，这层我们无法写业务，但是可以拦截一些攻击请求。</p><p>接下来到<strong>Nginx层。</strong>Nginx不仅可以作为反向代理和负载均衡器，也可以做大流量的Web服务器，同时也是一款非常优秀的静态资源服务器。如果把业务校验也放到这里来，就可以实现校验前置的原则了吗？</p><p>Nginx+Lua说，没问题。这时候可能你会有顾虑，Nginx担负了那么多任务，会被拖垮吗？不会，因为Nginx很强大，能力越大，责任越大。那么Nginx为什么比Apache服务更强大呢？第1课我们留个悬念，后面会讲。</p><p>接下来就到了<strong>Web服务</strong>了。我们在这里做业务的聚合，提供结算页页面渲染所需要的数据以及下单数据透传，同时也负责流量的筛选与控制，保证下游系统的安全。</p><p>最后就是<strong>RPC服务。</strong>它提供基础服务，一般经过上面3层的严格把关，到这里的请求，量已经小很多了，我们写业务逻辑，在技术上也有更多的发挥空间。</p><h2>小结</h2><p>想要设计秒杀系统，首先得了解秒杀，包括业务和技术层面。从业务上来说，我们了解到秒杀一般适用于稀缺商品的售卖，能够聚集人气，可以给平台带来关注度和流量。同时配合秒杀的营销手段也有很多种，可以结合预约、限购、风控等功能模块开展活动，以应对不同的业务场景。此外，我们也归纳了秒杀需要提供的能力，即活动数据、活动结算页、活动提单等能力。</p><p>从技术层面上来说，我们需要了解HTTP服务的请求链路路径，即请求从DNS到Nginx，Nginx处理后分发给Web服务，Web服务再聚合调用下游的RPC服务。每个链路节点都有它擅长做的事情。只有清楚了这些，我们才能够将秒杀系统提供的业务功能，按不同阶段、不同响应，合理地拆分到不同的链路层级来实现，以符合我们校验前置、分层过滤、缩短链路的设计原则，并能够从容应对秒杀系统所面临的瞬时大流量、热点数据、黄牛刷子等各种挑战。</p><p>当然，这只是第一步，在接下来课程中，我们将实际开发一个秒杀系统，并将我以往在实际生产中遇到的问题以及积累的各环节优化技术，一一分享。</p><h2>思考题</h2><p>这节课我们介绍了秒杀系统面临的挑战，除了重点介绍的瞬时流量以外，你觉得对秒杀系统而言，还有哪些方面也是比较重要的呢？我们又该通过怎样的设计来解决呢？</p><p>以上就是这节课的全部内容，欢迎你在评论区和我讨论问题，交流经验！</p>","neighbors":{"left":{"article_title":"开篇词｜如何设计一个高并发、高可用的秒杀系统？","id":420765},"right":{"article_title":"02｜蓄势待发：秒杀系统架构设计和环境准备","id":422016}}},{"article_id":422016,"article_title":"02｜蓄势待发：秒杀系统架构设计和环境准备","article_content":"<p>你好，我是志东，欢迎和我一起从零打造秒杀系统。</p><p>我们知道，系统的设计是个由巨入细的过程，想去设计好它，那你首先得去了解清楚它。就像上节课我们对HTTP请求所走链路的介绍，学完后你就会明白，做秒杀系统设计时，会用到哪些层级系统，并且每个层级系统可以做什么事情。</p><p>今天我们要做的就是给每个层级系统做最合适的<strong>技术选型和职能边界划分</strong>，最终实现让各系统、技术做它们所擅长的事情，并在最后搭建起我们的开发依赖环境。</p><p>那如何给层级系统做技术选型和职能边界划分呢？我们通常都说，没有最好的技术，只有最契合当下业务场景的技术，所以我们得先了解一下，如果使用我们传统的架构系统来支持秒杀业务，可能会出现哪些问题。只有清楚了要面对的问题，我们才能做针对性的思考和优化。</p><p>所以这节课我们将重点分析传统架构设计的特点，接着介绍最新的秒杀系统架构，并做好技术选型和环境准备。</p><h2>传统秒杀系统架构</h2><p>下面先看一个大家常用的系统功能架构图：</p><p><img src=\"https://static001.geekbang.org/resource/image/75/10/75c66bf2cb65bdbb125b06765d148c10.jpg?wh=1800x1575\" alt=\"\"></p><p></p><p>这种功能结构以及系统架构，是我们非常熟悉的。在这种方式下，Nginx只做反向代理和负载均衡，甚至这层对我们做业务开发的研发人员来说，都是无感知的，一般运维同事在做生产环境搭建时，都会帮我们配好。研发人员更多的是在开发Web服务和RPC服务，我们把页面以及页面所依赖的静态资源都放到Web服务中，同时Web服务还提供业务接口，RPC服务提供一些支撑服务。</p><!-- [[[read_end]]] --><p>如果这是个ToB的运营管理系统，这样没有什么问题，因为请求量非常低，系统基本不会有太大的负载。但是对于ToC，且瞬时流量非常大的情况，问题就会暴露出来，那它究竟会有哪些问题呢？</p><p></p><h3>域名与带宽问题</h3><p>我们从最基础的讲起。如果Web服务既提供H5页面、静态资源，同时也提供业务接口，这就意味着所有的请求使用的都是同一个域名，在活动刚开始时，大家都点击抢购按钮进结算页，而结算页页面拉取静态资源，会占用很多带宽资源。</p><p>这在活动开始的瞬间，带宽资源很稀缺的情况下，可能会出现用户进不了结算页，或者进了结算页却不能正常渲染页面的问题，导致抢购体验大幅下降。</p><p></p><h3>Web服务器性能问题</h3><p>接着，讲一个关键问题。我们一般部署Web服务，都是使用Apache的Tomcat来部署的，Tomcat在处理请求的时候，是通过线程去处理的。</p><p>这样的问题就是如果瞬时的大量请求过来，线程池中的线程不够用，Tomcat就会瞬间新建很多线程，直至达到配置的最大线程数，如果线程数设置的过大，这个过程可能会直接将机器的CPU打满，导致机器死掉。即使没有挂掉，在高负载下，当设置的等待队列也满了之后，后面的请求都会被拒绝连接，直到有空出的资源去处理新请求。这时候你可能会想，我加机器分摊流量不就行了？可以是可以，但由此增加的活动成本不知道你的老板会不会买单？</p><p></p><p>当然了，这个过程中，还会伴有热点数据读写、库存超卖等问题，这些细节也非常重要，我会在后面的课程中一一给你展开说明。</p><p></p><h2><strong>新的秒杀系统架构</strong></h2><p>上面我们谈到了传统系统架构的局限性，那么我们新的系统该如何设计才能避免出现以上问题呢？结合上节课对于各链路层级的介绍，我画了一张新的功能结构与系统架构图：</p><p><img src=\"https://static001.geekbang.org/resource/image/6e/8e/6eaca4f202c11ca5fc4954512cda858e.jpg?wh=1800x1671\" alt=\"\"></p><p>首先新系统我们依然保留了HTTP服务常用的层级调用关系，即 <strong>Nginx-&gt;Web服务-&gt;RPC服务</strong>，这也是绝大部分公司都会使用的一种系统结构。</p><p>其次将原先由Web服务提供的静态资源放到了CDN（CDN是全国都有的服务器，客户端可以根据所处位置自动就近从CDN上拉取静态资源，速度更快），来大大减轻抢购瞬时秒杀域名的负担。</p><p>最后，同时也是我们所做的最大改变，就是<strong>将Nginx的职责放大</strong>，前置用来做Web网关，承担部分业务逻辑校验，并且增加黑白名单、限流和流控的功能，这其实也是考虑到我们的秒杀业务特点所做的调整。这种在Nginx里写业务的做法在很多大公司里都是很常见的，像京东是用来做商详、秒杀的业务网关，美团用来做负载均衡接入层，12306用来做车票查询等等，他们的共同特点都是要面对高并发的业务场景，这也说明在这种业务场景下，我们的设计是得到了真实实践和广泛认可的。</p><p>而这么做的目的，就是要充分利用Nginx的高并发、高吞吐能力，并且非常契合我们秒杀业务的特点，即入口流量大。但流量组成却非常的混杂，这些请求中，一部分是刷子请求，一部分是无效请求（传参等异常），剩下的才是正常请求，这个的比例可能是6：1：3，所以需要我们在网关层尽可能多地接收流量进来，并做精确地筛选，将真正有效的3成请求分发到下游，剩余的7成拦截在网关层。不然把这些流量都打到Web服务层，Web服务再新起线程来处理刷子和无效请求，这是种资源的浪费。</p><p>所以网关层对秒杀系统而言，至关重要，而Nginx刚好可以胜任此项任务。由此可见，Nginx在我们的系统设计中，扮演着非常重要的角色，但你对Nginx也许没那么了解，别急，接下来我就给你简单介绍一下Nginx，并带你解开Nginx在高并发下仍具有高性能的秘密。</p><p></p><h3><strong>Nginx介绍</strong></h3><p>Nginx最早被发明出来，就是来应对互联网高速发展下，出现的并发几十万、上百万的网络请求连接场景的，传统Apache服务器无法有效地解决这种问题，而Nginx却具有并发能力强、资源消耗低的特性。</p><p>总的来说，Nginx有5大优点，即<strong>模块化、事件驱动、异步、非阻塞、多进程单线程</strong>。以下是Nginx的架构原理图：</p><p><img src=\"https://static001.geekbang.org/resource/image/3a/9b/3a811fe3cec72e5487e48a5f236f739b.jpg?wh=2406x1084\" alt=\"\"></p><p>Nginx是由一个master进程和多个worker进程（可配置）来配合完成工作的。其中master进程负责Nginx配置文件的加载和worker进程的管理工作，而worker进程负责请求的处理与转发，进程之间相互隔离，互不干扰。同时每个进程中只有一个线程，这就省去了并发情况下的加锁以及线程的切换带来的性能损耗。</p><p><strong>但一个线程能支持高并发的业务场景吗？</strong></p><p>这就要说到Nginx的工作模型。以Linux为例，其采用的是epoll模型（即事件驱动模型），该模型是IO多路复用思想的一种实现方式，是异步非阻塞的，什么意思呢？就是一个请求进来后，会由一个worker进程去处理，当程序代码执行到IO时，比如调用外部服务或是通过upstream分发请求到后端Web服务时，IO是阻塞的，但是worker进程不会一直在这等着，而是等IO有结果了再处理，在这期间它会去处理别的请求，这样就可以充分利用CPU资源去处理多个请求了。</p><p>这里你还可以思考这样一个问题：Linux支持的以IO多路复用思想来实现的模型还有select和poll，为什么选择了epoll呢？<strong>因为epoll的效率更高。</strong></p><p>举个例子，刚刚我们上面说到worker在处理请求到IO时，不会阻塞等待，而是去干其他事情，等IO有结果了再回头处理，那worker进程怎么知道刚刚的IO处理完毕了呢？</p><p>假设一个work&nbsp;process处理了1000个连接，但其中只有10个IO完成了，并可以继续往下执行，select/poll的做法是遍历这1000个FD（File Description，可以理解成每个建立了连接的一个标识），找到那10个就绪状态的，并把没做完的事情继续做完，这样检索的效率明显很低。所以epoll的做法是当这10个IO准备就绪时，通过系统的回调函数将FD放到一个专门的就绪列表中，这样系统只需要去找这个就绪列表就可以了，这大大提高了系统的响应效率。当然这只是epoll的其中一个优点，具体三种模型的对比，你可以自行去了解一下，网上相关的资料有很多，或者我们在留言区讨论也是可以的。</p><p>正是<strong>多进程+事件驱动</strong>的工作原理，才使得Nginx具有非常良好的性能表现，同时Nginx的模块化，也能够支撑强大的第三方自定义工具模块，让你的开发更加灵活自由。</p><p></p><h3><strong>OpenResty介绍</strong></h3><p>我们知道，Nginx的底层模块一般都是用C语言写的，如果我们想在Nginx的基础之上写业务逻辑，还得借助OpenResty，它是Nginx的一个社区分支。这里我也简单介绍一下它。</p><p>OpenResty是一个基于 Nginx 与 Lua 的高性能 Web 平台，它使我们具备在Nginx上使用Lua语言来开发业务逻辑的能力，并充分利用 Nginx 的非阻塞 IO 模型，来帮助我们非常方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。</p><p>这里插一句，<strong>为什么要用Lua语言来做Nginx开发呢？</strong>这就要说到Lua语言的特点了，Lua的线程模型是单线程多协程的模式，而Nginx刚好是单进程单线程，天生的完美搭档。同时Lua是一种小巧的脚本语言，语法非常的简单，很容易学习掌握，所以对于新语言你先不要有排斥心理，我会在后面的课程中慢慢向你展示讲解。</p><h2><strong>Web/RPC服务技术选型</strong></h2><p>以上我介绍完了Nginx服务层的技术选型，同时也讲解了为什么这么选的原因，下面就轮到Web服务和RPC服务了。</p><p>这里大的框架选择，其实就没有太多要求了，只要能提供我们需要的能力即可，比如基础框架是使用SpringMVC还是SpringBoot，持久层是喜欢用MyBatis还是JPA，数据库是用MySQL还是Oracle，这些都可以根据你的个人使用习惯或者所在公司的技术栈做灵活变通。</p><p>同时对于已经有秒杀系统，但是想要做优化的情况，也完全不用担心，跟着我学习之后，你只需将旧系统中的部分轻业务逻辑迁移到Nginx层来，体量最大的业务逻辑代码基本都不用动的，并且旧系统中的一些优化点，也都有单独的技术来实现，而这些都不需要太多的学习成本和迁移成本。</p><p>那么为了更好的本地开发教学，这里介绍一下<strong>我所使用的技术栈</strong>：Web服务和RPC服务的基础框架都是使用SpringMVC，RPC框架使用的是Dubbo，数据库使用免费开源的MySQL，分布式缓存数据库使用Redis，这应该也是大多数公司会使用的技术栈。</p><p>在技术选型和层级系统职能划分都确定了之后，接下来就让我们动起手来，先把开发的依赖环境准备好。</p><h3><strong>环境准备</strong></h3><p>以下是我在本地Mac上的安装方式，如果你是其他系统，可以找对应的安装方法，对于程序员来说应该是没难度的。如果Mac上没有安装过Homebrew，可以安装一下，这是一个Mac软件的工具包，很好用。以下操作都是在Mac的终端里输入相关命令来完成操作的。</p><p></p><h3><strong> Homebrew安装</strong></h3><p>ruby -e “$(curl -fsSL <a href=\"https://raw.githubusercontent.com/Homebrew/install/master/install\">https://raw.githubusercontent.com/Homebrew/install/master/install)</a>)”</p><p></p><h3><strong>OpenResty安装</strong></h3><ol>\n<li>brew install openresty/brew/openresty</li>\n</ol><p>从Homebrew安装OpenResty。</p><ol start=\"2\">\n<li>export PATH=/usr/local/Cellar/openresty/1.19.3.2_1/nginx/sbin:$PATH</li>\n</ol><p>安装完成之后，默认的安装位置在 /usr/local/Cellar/openresty/1.19.3.2_1，这时我们设置下环境变量（即告诉终端输入的命令去哪里找）。</p><ol start=\"3\">\n<li>Nginx&nbsp;-V</li>\n</ol><p>然后就可以查看OpenResty是否安装成功。如下图，执行红框内的命令，出现绿框的输出内容，即表示安装成功了。</p><p><img src=\"https://static001.geekbang.org/resource/image/2a/d8/2a9d383d17932088c11281ac8d4605d8.png?wh=1920x668\" alt=\"图片\"></p><ol start=\"4\">\n<li>然后我们就可以测试下Nginx是否好用，所以我们在本地新建了个nginx.conf配置文件，就放在/Users/～/Documents/seckillproject/nginx/conf下，并且在nginx文件夹下新建logs文件夹，用于log日志的输出，新建后的文件目录结构如下：</li>\n</ol><p><img src=\"https://static001.geekbang.org/resource/image/93/69/934cb93ab4c052081a921ffb84966169.png?wh=1920x515\" alt=\"图片\"></p><p>nginx.conf的内容就用官方的模板，输出个hello&nbsp;world：</p><pre><code class=\"language-plain\">worker_processes &nbsp;1;\nerror_log logs/error.log;\nevents {\n&nbsp;&nbsp;&nbsp;&nbsp;worker_connections 1024;\n}\nhttp {\n&nbsp;&nbsp;&nbsp;&nbsp;server {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;listen 8080;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;location / {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;default_type text/html;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;content_by_lua_block {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ngx.say(\"&lt;p&gt;hello, world&lt;/p&gt;\")\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;}\n}\n</code></pre><p>5. cd /Users/wangzhangfei5/Documents/seckillproject/nginx</p><p>进入到我们新建的nginx文件夹下。</p><ol start=\"6\">\n<li>nginx -p `pwd`/ -c conf/nginx.conf</li>\n</ol><p>启动Nginx服务，这时输入 `ps&nbsp;-ef|grep nginx` 可以查看起来Nginx进程，有两个，一个master&nbsp;，一个worker。</p><p><img src=\"https://static001.geekbang.org/resource/image/6c/27/6c25ac6529f8afe884a2yyce84326427.png?wh=1920x182\" alt=\"图片\"></p><p>7.&nbsp;curl <a href=\"http://localhost:8080\">http://localhost:8080</a></p><p>访问本地8080端口，可以看到，输出了\"&lt;p&gt;hello, world&lt;/p&gt;\"，也可以在浏览器输入 <a href=\"http://localhost:8080\">http://localhost:8080</a>，看到 hello,world 的返回。</p><p><img src=\"https://static001.geekbang.org/resource/image/af/25/afbf1ed0c3fyyb8bd759eb9d21d7c925.png?wh=1920x287\" alt=\"图片\"></p><p>8.&nbsp;nginx -p `pwd` -s stop</p><p>停止Nginx服务。</p><p></p><h3><strong>MySQL安装</strong></h3><p>brew install <a href=\"mailto:mysql@5.7\">mysql@5.7</a></p><p>也可以通过<a href=\"https://downloads.mysql.com/archives/community/\">官网</a>下载，根据系统版本，下载好对应包之后直接安装，完成安装之后可以测试下。</p><p>1.&nbsp;export PATH=<a href=\"mailto:/usr/local/opt/mysql@5.7/bin:$PATH\">/usr/local/opt/mysql@5.7/bin:$PATH</a></p><p>默认的安装位置在 <a href=\"mailto:/usr/local/opt/mysql@5.7\">/usr/local/opt/mysql@5.7</a>&nbsp;这时我们设置下环境变量（即告诉终端输入的命令去哪里找）。</p><p>2.&nbsp;mysql.server start</p><p>启动MySQL。</p><p>3.&nbsp;mysql_secure_installation</p><p>设置数据库密码，按照对应的提示，让选择Y/N时，输入Y，然后会让选择密码等级，一共三个级别 0,1,2&nbsp;强度由低到强，选择后设置密码，并记住刚设的密码。</p><p>4.&nbsp;mysql -uroot -p</p><p>登录数据库，这时会提示你输入密码，输入刚设置的密码即可进入。</p><p>5.&nbsp;show databases;</p><p>查看下当前的所有库，到这里也说明我们的MySQL准备好了，可以建库建表了。</p><p><img src=\"https://static001.geekbang.org/resource/image/03/a5/034609767df8ecbe23bc6a74f1c4f6a5.png?wh=1920x979\" alt=\"图片\"></p><p>6.&nbsp;mysql.server stop</p><p>control+z退出MySQL后，执行该命令，关闭MySQL。</p><p></p><h3><strong>Redis安装</strong></h3><p>brew install redis</p><p>安装完成之后 ，依次执行以下命令进行测试。</p><p></p><ol>\n<li>/usr/local/opt/redis/bin/redis-server /usr/local/etc/redis.conf</li>\n</ol><p>启动Redis服务端，如下图绿框，在安装好后提示我们如何启动Redis，按照提示输入命令，便可以看到启动成功等待连接。</p><p><img src=\"https://static001.geekbang.org/resource/image/d3/3d/d3c99f1a374cd99635567c7c91a2083d.png?wh=1920x1223\" alt=\"图片\"></p><ol start=\"2\">\n<li>redis-cli -h 127.0.0.1 -p 6379</li>\n</ol><p>这时新建一个终端窗口，模拟客户端连接Redis服务，如下图所示，可以set一个值，并get查询出来，说明Redis也正常安装成功并可以使用。</p><p><img src=\"https://static001.geekbang.org/resource/image/11/51/117820fcf5f023d46312dae5530da851.png?wh=1920x502\" alt=\"图片\"></p><ol start=\"3\">\n<li>服务端停止，可以直接control+z退出，也可以 sudo pkill redis-server 客户端断开连接 redis-cli shutdown。</li>\n</ol><p></p><p>到这我们主要的依赖环境都已经搭好了，而项目的搭建与开发，我会在下节课为你讲解。</p><p></p><h2><strong>小结</strong></h2><p>在这节课里，针对秒杀系统，我们将传统的架构设计与我们新的架构设计做了一个对比，可以看出传统架构设计的局限性，其中仅列举了域名带宽问题和Tomcat服务器性能问题，这也是我们从宏观上做技术选型时，就需要去认真思考的问题。</p><p>而针对这两点，我们也给出了我们的答案，即利用Nginx在高并发下仍具有高性能的特性，将Web网关职能前置，尽量在流量入口处拦截掉风险流量以及缩短请求链路，保护下游系统，并提高服务的响应速度。</p><p>有了大的方向指导，我们便可以针对一些更细的技术点去做优化和设计，比如哪种限流算法更好，怎么能在高并发下保证库存不超卖等等这些。</p><p>同时在做技术选型时，我也尽可能地使用了多数公司都在使用的技术栈，以降低你的学习成本。但是用Lua语言来做Nginx业务开发，或许还有不少同学是第一次用，不过不着急，后面跟着我慢慢学，相信你自己一定可以，或许这还将成为你比别人厉害的法宝！</p><h2>思考题</h2><p>关于Tomcat的思考，为什么Tomcat也支持NIO，但性能却比Nginx差那么多呢？</p><p>以上就是这节课的全部内容，欢迎你在评论区和我讨论问题，交流想法！</p>","neighbors":{"left":{"article_title":"01｜直面痛点：秒杀系统的挑战和设计原则","id":420777},"right":{"article_title":"03 | 指日可待：一步一步搭建秒杀系统（上）","id":423075}}},{"article_id":423075,"article_title":"03 | 指日可待：一步一步搭建秒杀系统（上）","article_content":"<p>你好，我是志东，欢迎和我一起从零打造秒杀系统。</p><p>在上一节课中我们搭建了本地的依赖环境，这节课我们将依据前篇中做的技术选型，继续搭建我们的开发项目，并在我们搭建好的项目上，<strong>开发一个最简的秒杀系统</strong>。</p><p>这个系统模拟通过商详页，进入到结算页，可以展示商品图片、名称、价格等；其次支持输入地址、选择支付方式、修改购买数量等操作行为；然后提交订单；最后在下单成功后模拟跳转到支付页。</p><p>麻雀虽小，五脏俱全，这些基本上涵盖了秒杀的整个流程，只不过大平台的结算元素更丰富，也有更多的分支操作，但这些都可以在我们的基础上，按照专栏中介绍的一些原则，进行增减。</p><p>整个项目的搭建和秒杀业务系统的具体实现还是比较复杂的，所以我们将分成两节课来完成。这节课我们主要是搭建项目，那么话不多说，我们直接开始吧。</p><p></p><h2>职能划分</h2><p>根据前面我们对秒杀业务做的分析可知，要实现秒杀业务，我们最少需要3个系统服务：</p><ul>\n<li>一个是Nginx服务，我们命名为demo-nginx；</li>\n<li>再一个是Web服务，我们称其为demo-web；</li>\n<li>最后一个是RPC服务，我们就叫它demo-support。</li>\n</ul><p>3个项目的关系如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/f6/3c/f627a52ea373f6d4cf3a1613fd9cdb3c.jpg?wh=1508x1108\" alt=\"\"></p><p>3个项目的目标职能划分这里我也详细介绍一下。</p><p><strong>首先是demo-nginx，主要负责：</strong></p><!-- [[[read_end]]] --><ul>\n<li>流量筛选：根据黑白名单、登录态和参数有效性等来筛选流量。</li>\n<li>流量分发：通过设置的负载均衡算法进行流量分发，也可以自定义算法，比如根据IP做hash，或者根据用户ID做hash等。</li>\n<li>简单业务以及校验：提供活动数据、活动有效性校验、库存数量校验和其他业务相关的简单校验等。</li>\n<li>限流：根据IP或者自定义关键入参做限流。</li>\n<li>异常提示页面：主要是进结算页失败的提示页，可能是被限流，被业务校验拦截或者是后端服务异常等。</li>\n</ul><p><strong>其次是demo-web，主要负责：</strong></p><ul>\n<li>提供结算页H5。</li>\n</ul><p>提供结算页的HTML，或者是重定向到CDN上的结算页H5地址。这里你肯定要问，为什么不把这个功能前置到Nginx服务，那样不是可以更快地返回吗？</p><p>这里主要考虑到一个上线灰度发布的问题。你有没有想过，如果秒杀上线后，在后续的需求版本迭代中，我们页面新增了一个功能，该功能需要调用一个新的接口，我们该如何制定发布计划，来确保上线的安全以及不影响线上用户的使用体验呢？</p><p>我们可以选择全量上线，但这么做的后果就是一旦出现我们测试未覆盖到的业务场景而引发了线上事故，那么就会影响到全部的用户，这对我们来说是不可接受的，所以上线还得采取灰度发布的方式。</p><p><strong>那什么是灰度发布呢？</strong></p><p>大多数同学应该有所了解，这里我只简单讲一下灰度发布的做法与目的。一般我们新功能上线，都不是一下子全量上线，而是有计划地逐步灰度上线，即先上1台或几台服务线上观察，如果有问题，马上回滚。这样做的好处是，如果真的出现问题，那么受影响的流量也只有灰度的那些机器。也就是说，如果你线上有1000台服务，你上一台灰度，那么受影响的流量也只有千分之一。这个做法最大限度地降低了事故的影响面。</p><p>但采用灰度发布的方式又会带来新的问题，即用户点击抢购进入到了新页面，新页面调用新接口，但如果这个请求打到了旧的服务器上，没有新的接口，那岂不是就报错了？</p><p>这里你不妨主动思考下：怎么确保灰度上线情况下，使同一个用户进入到新页面所发出的请求也能够打到新的接口服务上。</p><p><img src=\"https://static001.geekbang.org/resource/image/cb/13/cbb1666d0c36ab235bbyy7ee8fb09413.jpg?wh=1870x926\" alt=\"\"></p><ul>\n<li>业务聚合接口：提供结算页H5渲染页面所需数据，以及提供用户行为操作所需接口，比如下单等。</li>\n<li>其他功能：部分关键接口的限流，以保证下游接口的安全。</li>\n</ul><p><strong>最后是demo-support，主要负责：</strong></p><p>提供基础服务、数据的支持，包括活动数据、商品数据、用户维度数据、提单等，主要模拟基础服务，正常情况下，应该是按业务模块做细致划分的，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/c0/1c/c0ac84c48a59c9a8dd25b2d5yy50971c.jpg?wh=1628x590\" alt=\"\"></p><p>这里我们为了开发方便，就全部集成到一个demo-support服务里了。</p><h2>项目搭建</h2><p></p><p>现在，我们确定了项目服务职能范围，也做了相关的命名，下面就可以做项目的搭建了。</p><p>但在开始之前我要简单说明下：在后面的项目搭建以及后续的开发中，对涉及到demo-nginx项目的配置或Lua语法等我会多讲一些，这部分可能大家都比较陌生，而对于demo-web、demo-support项目的一些常用配置，则会稍加精简，因为大家会比较熟悉，特别的地方会再重点说明。</p><p>以下除了demo-nginx项目外，你在搭建项目时都可以通过自己熟悉的技术栈来实现，只需要让目标系统达到我们所希望它具备的能力即可，技术不限。</p><p></p><h3><strong>demo-nginx项目搭建</strong></h3><p>这个项目主要是用Lua语言开发，在上节课中我们安装了OpenResty，本地创建的nginx.conf文件的路径在 ~/Documents/seckillproject/nginx/conf/nginx.conf，这个是Nginx服务配置的核心文件，Nginx启动就是根据这个配置来做一些初始化工作的。</p><p>一个nginx.conf文件的正常配置结构如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/24/b5/2418515a40bba14bcef425a35a5cbab5.jpg?wh=1726x1656\" alt=\"\"></p><p>这里的“全局模块配置”“events模块配置”，以及HTTP模块配置中的“HTTP全局模块配置”，都是直接配置在nginx.conf中，属于核心配置。而“server模块配置”以及下面的“location块”配置都是我们写业务逻辑的地方，比较灵活，所以写到我们的demo-nginx项目中，并通过Nginx的include关键字将对应的路径在nginx.conf中的“HTTP模块配置”里引用进来。</p><p>这里先粗略地介绍一下各个模块的作用：</p><ul>\n<li><strong>全局模块配置</strong>：这里一般配置Nginx的进程数、日志目录与级别、CPU绑核等。</li>\n<li><strong>events模块配置</strong>：主要配置Nginx使用的工作模型，进程连接数限制等；</li>\n<li><strong>HTTP模块配置</strong>：这里就是处理HTTP请求的相关配置，包括监控的域名、端口、URL以及业务代码的配置引用等。</li>\n</ul><p></p><p>那么在了解了项目的基本结构之后，我们就开始动手搭建吧。</p><p></p><p><strong>第一步：</strong>我们先在本地创建一个demo-nginx项目，这里我用的开发工具是IDEA，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/55/c4/55eaee8109975755b2dc6453d92d9fc4.png?wh=2594x936\" alt=\"\"></p><p>这里我创建了三个文件夹，依次是config、domain、lua。其中，config文件夹是用来存放一些常用配置的，像一些常量配置和负载均衡配置等；domain文件夹主要是用来存放“HTTP配置”中的server模块配置文件；lua文件夹则主要用来存放用Lua语言编写的业务逻辑代码文件。</p><p><strong>第二步：</strong>在domain文件下，新增domain.com文件，用来配置server和location。</p><p><strong>第三步：</strong>修改我们的nginx.conf文件，引入刚刚新建的domain.com文件以及lua文件夹下即将要写的.lua文件。nginx.conf内容修改如下：</p><pre><code class=\"language-plain\">worker_processes 1; #工作进程数\nerror_log logs/error.log error;#日志路径 &nbsp;日志级别\nevents {\n\tworker_connections 256;#单进程最大连接数\n}\nhttp {\n\tlua_package_path \"~/Documents/seckillproject/demo-nginx/lua/?.lua;;\";\n\tinclude ~/Documents/seckillproject/demo-nginx/domain/domain.com;\n}\n</code></pre><p>这里lua_package_path 的功能是导入项目中的 .lua文件。Include 是导入一些server模块配置文件，就像在HTML里引用JavaScript一样。</p><p><strong>第四步：</strong>配置server和location，这里先只简单配置一个监控端口，以及一个请求的匹配URL，简单输出“hello&nbsp;world”，配置内容如下：</p><pre><code class=\"language-plain\">server {\n&nbsp; &nbsp; listen 7081;\n&nbsp; &nbsp; location /sayhello {\n&nbsp; &nbsp; &nbsp; &nbsp; default_type text/plain;\n&nbsp; &nbsp; &nbsp; &nbsp; content_by_lua_block {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ngx.say(\"hello world!!!\")\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; }\n}\n</code></pre><p><strong>第五步：</strong>启动Nginx。还记得Nginx的命令吗？不记得可以回头看看我们之前搭建OpenResty时教的。启动Nginx之后，在终端或者浏览器输入请求地址，就可以看到输出结果了，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/cd/76/cd850cda3dea612bf19c0f605b402076.png?wh=866x245\" alt=\"图片\"></p><p>这样我们的demo-nginx项目就搭建完成了，剩下的就是填充配置与业务逻辑的开发了。</p><p></p><p>现在让我们马不停蹄，继续下一个项目的搭建。</p><p></p><h3><strong>demo-web项目搭建</strong></h3><p>因为demo-web项目提供的是HTTP接口，所以我们的基础框架使用的是SpringMVC，新建了一个maven项目，命名为demo-web，并且新建了3个子module，分别是demo-gateway，demo-common，demo-service。</p><p>其中demo-gateway主要负责对外HTTP接口定义，以及SpringMVC相关文件配置，并且也是要打包部署的module；demo-service主要用来做业务逻辑处理；demo-common用来放一些公用方法或者工具类等。</p><p>整体项目结构如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/ac/71/acdd356c114659c3a8bf2b05e4500b71.png?wh=2139x1500\" alt=\"\"></p><p>之后进行SpringMVC相关配置，配置完成后，可以自己写个controller，测试一下是否搭建成功，这里因为都是大家比较熟悉的领域，所以就不做过多赘述了。</p><p></p><p>当demo-web项目搭建完成后，就可以和我们之前搭建的demo-nginx项目联动一下了，即请求先到Nginx，被其配置的location拦截，经过处理后将其分发给demo-web。所以接下来我们需要对demo-nginx做一些修改。</p><p><strong>第一步：</strong>在config文件夹，新建upstream.conf的配置文件，用来配置打到后端Web服务器的IP和端口号。如果是线上，这里可以配置服务器集群，内容如下：</p><pre><code class=\"language-plain\">upstream backend {\n\t&nbsp;server 127.0.0.1:8080;\n}\n</code></pre><p>其中upstream是Nginx关键字，backend是自定义名称。我们了解的Nginx的负载均衡功能，就是在这里配置的。修改后的项目结构如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/71/e5/71557d5a71295654dbb02b29fca5a2e5.png?wh=2600x972\" alt=\"\"></p><p><strong>第二步：</strong>修改domain.com的server配置文件，新增proxy_pass配置项。意在将请求分发给后端服务器，其中backend就是我们在第一步中自定义的名字，如代码第5行所标：</p><pre><code class=\"language-plain\">server {\n\tlisten 7081;\n\tlocation /sayhello{\n\t&nbsp;&nbsp;&nbsp;&nbsp;default_type text/plain;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;proxy_pass http://backend;\n\t}\n}\n</code></pre><p><strong>第三步：</strong>在nginx.conf中，将upstream.conf文件加载进去。</p><pre><code class=\"language-plain\">\tworker_processes 1;\n\terror_log logs/error.log error;\n\tevents {\n\t&nbsp;&nbsp;&nbsp;&nbsp;worker_connections 256;\n\t}\n\thttp {\n\t&nbsp;&nbsp;&nbsp;&nbsp;lua_package_path \"~/Documents/seckillproject/demo-nginx/lua/?.lua;;\";\n\t&nbsp;&nbsp;&nbsp;&nbsp;include ~/Documents/seckillproject/demo-nginx/domain/domain.com;\n\t&nbsp;&nbsp;&nbsp;&nbsp;include ~/Documents/seckillproject/demo-nginx/config/upstream.conf;\n    }\n</code></pre><p><strong>第四步：</strong>demo-nginx修改完成后，我们在demo-web新建一个controller，并启动。这里就要重点说明一下了，Nginx配置的location&nbsp;URL需要和demo-web中定义的controller下对应的方法mapping保持一致，不然两者是串不起来的。</p><p>准备完成后，我们来启动一下Nginx，在浏览器输入请求URL：<a href=\"http://localhost:7081/sayhello\">http://localhost:7081/sayhello</a>，你就会看到预期结果，这里就不展示截图了。</p><p></p><p>到这里，我们的demo-nginx与demo-web两个项目就可以串联起来工作了。现在就只剩下一个demo-support项目了，我们马上着手搭建它。</p><p></p><h3><strong>demo-support搭建</strong></h3><p>可以参考刚刚的步骤与配置。首先新建demo-support项目，然后新建5个子module，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/00/b1/008ddda95316ecd1ba38e5ae2342f3b1.png?wh=2133x1498\" alt=\"\"></p><ul>\n<li>demo-support-common：存放一些基本的工具方法或者常量等。</li>\n<li>demo-support-dao：持久层，主要存放数据库相关的SQL文件、实体、操作方法。</li>\n<li>demo-support-export：对外接口定义层，主要定义提供的RPC接口方法以及实体等。</li>\n<li>demo-support-service：业务逻辑层。</li>\n<li>demo-support-launcher：项目文件配置、监控、拦截器等，同时也是打包部署module。</li>\n</ul><p></p><p>这里也同样不做过多的讲解，你最终搭建起来项目，使其能够操作数据库，并能够提供RPC服务即可。这里特别说明一下，就是在集成RPC框架Dubbo时，因为是本地服务间调用，所以不需要注册中心，像下面这样配置即可，线上再正常配置。</p><p><img src=\"https://static001.geekbang.org/resource/image/db/50/db3234a5607018589946f04e9b9dd050.png?wh=2602x1118\" alt=\"\"><br>\n<img src=\"https://static001.geekbang.org/resource/image/31/95/31496dfb4df279ca07459a77098de095.png?wh=2603x1107\" alt=\"\"></p><p></p><h2>小结</h2><p>在这节课中我们为了开发一个最简的秒杀系统，设计了3个系统项目：一个是demo-nginx，用来做真正的网关入口；另一个是demo-web，用来做业务的聚合；最后一个是web-support，用来做基础数据和服务的支撑。</p><p>同时我们给每个项目做了比较明确的职能划分，然后按照顺序依次搭建起了3个项目。</p><p>在这3个项目中，我们着重介绍了demo-nginx项目的搭建，其他两个因为是大家比较熟悉的内容，所以就没有做太多着墨。</p><p>由于在上节课的OpenResty搭建和这节课的demo-nginx搭建教学里，一共出现了好几个和Nginx相关的文件，在这里我们做个归纳总结，以防你混淆。</p><p><img src=\"https://static001.geekbang.org/resource/image/31/ee/31266d58627f134248ceebef3175daee.png?wh=1422x868\" alt=\"图片\"></p><p>通过表格，我们可以更清楚明了地看到这些文件的作用。同时到这里，我们的所有依赖环境和项目都已经准备就绪了，那么下节课我们将正式开始秒杀业务代码的编写，来实现我们课程开头设定的小目标。</p><p></p><h2><strong>思考题</strong></h2><p>课程中布置过的一道思考题：H5在做灰度上线时，如何让新版本的页面请求始终打到新的灰度机器，而老页面的请求始终打到旧版本的服务上，两者不出现交叉呢？</p><p><img src=\"https://static001.geekbang.org/resource/image/cb/13/cbb1666d0c36ab235bbyy7ee8fb09413.jpg?wh=1870x926\" alt=\"\"></p><p>以上就是这节课的全部内容，欢迎你在评论区和我讨论问题，交流经验！</p>","neighbors":{"left":{"article_title":"02｜蓄势待发：秒杀系统架构设计和环境准备","id":422016},"right":{"article_title":"04 | 指日可待：一步一步搭建秒杀系统（下）","id":423966}}},{"article_id":423966,"article_title":"04 | 指日可待：一步一步搭建秒杀系统（下）","article_content":"<p>你好，我是志东，欢迎和我一起从零打造秒杀系统。</p><p>在上节课中，我们完成了3个项目的搭建，并给项目做了大致的最终目标职能划分。那么接下来我们就可以对秒杀业务的流程做一个详细的梳理了，给出要实现的交互逻辑，然后按照交互需求，提炼出各个项目具体要提供的接口，之后按照各个接口要实现的功能，去具体<strong>开发我们的业务代码</strong>，最终实现秒杀活动开展的全闭环。话不多说，现在就开始吧。</p><p></p><h2><strong>秒杀业务流程梳理</strong></h2><p>根据我们之前对秒杀业务的介绍，一场完整的秒杀活动的大概流程是这样的，我们一起梳理一下。</p><p>1.&nbsp;运营人员在秒杀系统的运营后台，根据指定商品，创建秒杀活动，指定活动的开始时间、结束时间、活动库存等。</p><p>2.&nbsp;活动开始之前，由秒杀系统运营后台worker，将活动商品的标识更改为秒杀标识。</p><p>3.&nbsp;用户进入到商详页面时，系统会判断当前商品标识，如果是秒杀标识，则去查询当前商品的秒杀活动数据，判断是否正式开始，即通过商品标识+活动时间来判断活动是否真正开始。如果活动时间还没有到，页面可以是禁售展示，也可以是倒计时展示，或者是按正常价格售卖，这个可以按实际业务需求来定。</p><p>4.&nbsp;当活动已经开始，用户进入商详页，可以看到立即抢购的按钮，这里我们可以通过增加一些逻辑判断来限制按钮是否可以点击，比如是否设置了抢购用户等级限制，是否还有活动库存，是否设置了预约等等。如果都没限制，用户可以点击抢购按钮，进入到秒杀结算页。</p><!-- [[[read_end]]] --><p>5.&nbsp;在结算页，用户可更改购买数量，切换地址、支付方式等，这里的结算元素也需要按实际业务来定，更复杂的场景还可以支持积分、优惠券、红包、配送时效等，并且这些都会影响最终价格的计算。</p><p>6.&nbsp;确认无误后，用户提交订单，在这里后端服务可以调用风控、限购等接口，来完善校验，都通过之后，完成库存的扣减和订单的生成。如果结算页支持了第5步中提到的一些虚拟资产，则还需要做对应的抵扣。</p><p>7.&nbsp;订单完成后，根据用户选择的支付方式跳转到对应的页面，比如在线支付就跳转到收银台，货到付款的话，就跳到下单成功提示页。</p><p></p><p><strong>整个时序图如下：</strong></p><p><img src=\"https://static001.geekbang.org/resource/image/2d/72/2d40cc6f38298361411f6f0fda810572.jpg?wh=1758x1568\" alt=\"图片\"></p><p>这样一来，秒杀业务从开始到用户抢购，到最后的活动结束关闭，整个流程就形成<strong>闭环</strong>了。当然上面列举的也只是主要的流程，实际业务可以在不同节点依据实际需求添加不同的业务功能，这个你可以灵活调整。</p><p></p><h2><strong>系统提供接口梳理</strong></h2><p>从上面的时序图中，我们可以非常清楚地归纳出秒杀系统需要提供的<strong><span class=\"orange\">主要接口</span></strong>：</p><p>1.&nbsp;活动数据查询接口：查询活动相关信息，包括开始、结束时间等。</p><p>2.&nbsp;进结算页页面（H5）接口：结算页H5，并通过Ajax异步加载结算页数据。</p><p>3.&nbsp;结算页页面初始化渲染所需数据的接口：大体包括活动信息、商品信息、结算信息（用户的地址、虚拟资产、价格等等）。</p><p>4.&nbsp;结算页页面用户行为操作接口：支持地址列表查看和选择，虚拟资产的查看和使用等等，并在操作后更新页面价格相关信息。</p><p>5.&nbsp;结算页提交订单接口：支持秒杀活动商品下单。</p><p></p><p>当然这是秒杀网关系统所需要提供的接口，但是要完整地实现整个秒杀功能，我们还得需要以下功能。而这些个功能点，不需要做到秒杀的主流程系统里，一般都有秒杀的运营系统来提供<strong>相应能力</strong>，简列如下：</p><p>1.&nbsp;秒杀活动的创建：创建秒杀活动，主要要素包括活动名称、参加活动的商品、活动库存、活动单次限购数量、活动开始时间、活动结束时间。</p><p>2.&nbsp;秒杀活动的查看：查看活动信息、活动状态等。</p><p>3.&nbsp;秒杀活动的开始：一般活动都是提前创建，并在活动即将开始之前几分钟，自动更改活动商品标识，这样商详页就能区分出当前商品是普通商品还是秒杀商品了，然后执行不同的业务分支逻辑。</p><p>4.&nbsp;秒杀活动的结束：活动时间到期或者运营人员手动关闭，并将活动商品的秒杀标识去掉。</p><p></p><p>同时为了我们整个秒杀功能的展示，我们还需要有模拟商品信息的查询（后台查看），客户端商品的详情页面（秒杀入口）以及下单成功后的收银台页面，这3个一般情况下不属于秒杀整个系统的功能范畴了，这里仅仅是为了更好地展示秒杀的整个链路所做的模拟。</p><p></p><p>我们需要将所有网关入口都封闭在demo-nginx（本地为了模拟一些业务功能，会将部分入口放在demo-web，方便访问）。而所有操作数据库的入口都放在demo-support，并且为了模拟整个秒杀的流程业务，我们需要以下3张表来支撑：</p><p><img src=\"https://static001.geekbang.org/resource/image/23/aa/235361620fe038f528986d95abdd28aa.png?wh=1360x494\" alt=\"图片\"></p><p>一切就绪，接下来，我们就根据上面的设计，开始投入到实际的开发中去吧。</p><p></p><h2><strong>秒杀业务的实现</strong></h2><p>这里，详细的开发细节就不说了，因为上面已经理清了所有的接口和对应的能力，实际的代码开发并不复杂，相信对你来说也不是难事。</p><p>这里我主要说一下demo-nginx的配置，因为我们前面说过，初版先用比较传统的结构来实现秒杀，这样一来主要功能的开发都放在了demo-web和demo-support，所以我们的demo-nginx现在还不会有太多的配置更改。只需要将对应的接口URL匹配，配置到domain.com里即可，实现对应接口请求的接收和分发，修改后文件内容如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/a0/3a/a05006cb11f22922dcc15aff5086a73a.png?wh=1920x1340\" alt=\"图片\"></p><p>这里结算页用户行为操作的接口，可能是一个或是多个，如果没有特别的处理，可以配置一个模糊匹配，并直接打到后端服务，不需要做额外处理。（其中 ~* 表示启用正则匹配，同时忽略字母大小写，如果遇到请求静态资源不到的情况，也可以参照此方式配置）</p><p></p><p>省略掉中间的开发过程，我们先来看下最终要实现的效果吧，同时你也可以根据下面的交互，去理解一下我们为什么会要求提供上面的那些接口，<strong><span class=\"orange\">其中各个阶段要调用的接口，我都用橘色特别标识出了。</span></strong></p><p></p><h3><strong>第一步</strong></h3><p>我们先在数据库商品表中初始化一条商品信息，用来模拟参加秒杀活动。然后再通过<span class=\"orange\">商品信息查询接口</span>，在浏览器页面查看商品的信息（根据商品编号查询），这是个后台功能，主要是看下商品的基本信息，比如名称、价格、商品标识，特别是商品标识在参加秒杀活动前后的一个变化。</p><p>这里为了方便，我把入口放在了demo-web服务，我们通过demo-web的端口号，访问对应的URL即可，如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/07/ae/07b628c8cba3f7ddc132fe62ff9d4cae.png?wh=1920x702\" alt=\"图片\"></p><h3><strong>第二步</strong></h3><p>用第一步的商品，创建一个秒杀活动。这个功能正常是放在运营系统里的，通过页面来进行秒杀活动的管理，这里为了方便教学，就直接调用<span class=\"orange\">秒杀活动创建接口</span>，来完成秒杀活动的创建，效果如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/5e/cb/5e833346968a6024974bf3cea03131cb.png?wh=1920x294\" alt=\"图片\"></p><p>创建完成后，我们调用<span class=\"orange\">活动信息查询接口</span>，来查看刚刚创建的活动，页面只是简单地列举了一下活动的主要元素，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/79/ae/79766a407df9d1b9f23fc64746cc82ae.png?wh=1920x553\" alt=\"图片\"></p><p>这里我们将参加秒杀活动的商品价格设为了998，原价是1298，并且设置了4件库存，活动的开始时间是当前时间，结束时间是两天后。正常情况下活动是已经开始了，需要通过worker来启动活动，并完成商品标识的修改，但我本地模拟是没有加定时worker功能的，想通过HTTP接口的方式来触发，所以这里还是显示活动未开始。</p><h3><strong>第三步</strong></h3><p>我们先不触发活动开始，我们先模拟客户端进商详页看看现在活动入口页面的样式，同样是通过URL方式，直接访问demo-web，效果如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/0d/0b/0db0fa8ed2e1290a2ae399798566800b.png?wh=1629x1634\" alt=\"图片\"></p><p></p><p>可以看到，活动虽然创建了，但还没有开始，所以这里展示的还是普通商品的名称和价格。下面我们就来手动触发一下，让活动开始，直接调用demo-web的<span class=\"orange\">活动开始接口</span>：</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/ea/d9/ea02da1e2f1060da58c693123b7c63d9.png?wh=1920x254\" alt=\"图片\"></p><p>这样活动就触发成功了，这个时候，我们再分别看下活动信息和商品信息，看看都有什么变化：</p><p><img src=\"https://static001.geekbang.org/resource/image/af/db/afe9a2273b8c356286e9e12f260df5db.png?wh=1920x527\" alt=\"图片\"></p><p><img src=\"https://static001.geekbang.org/resource/image/14/f5/1458086b58abfa425f25cf1ed6e53af5.png?wh=1920x413\" alt=\"图片\"></p><p></p><p>正如我们所期望的，活动的状态变成了进行中，同时商品标识也变成了秒杀标识。</p><h3><strong>第四步</strong></h3><p>秒杀活动开始后，我们再次进入到商详页。</p><p><img src=\"https://static001.geekbang.org/resource/image/2c/a4/2c8074edfb7aa59a52b66745e8ebf5a4.png?wh=1611x1675\" alt=\"图片\"></p><p>对比之前的商详页，我们可以看到商品的图片、名称、价格展示，都已经变成了活动配置的，同时按钮也变成了立即抢购，并可以点击，说明到这里我们一切都进展的很顺利！</p><p></p><h3><strong>第五步</strong></h3><p>这时，我们点击立即抢购按钮，去进入到秒杀结算页。这里点击按钮，调用的是进<span class=\"orange\">结算页页面（H5）接口</span>，在加载了HTML后，JavaScript通过Ajax调用<span class=\"orange\">结算页页面初始化渲染所需数据的接口</span>，去渲染页面展示，效果如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/9b/55/9b470cac45f0bb1ed04afb738b822455.png?wh=1642x1707\" alt=\"图片\"></p><p>页面的结算元素，这里只简单地展示了几个，当然你可以根据实际需要去灵活填充。展示中的结算页支持修改购买数量，修改后总金额会随之变化，而且有单次够买数量的限制，同时也允许用户切换支付方式、修改地址等操作，这里做的用户操作，会调用<span class=\"orange\">结算页页面用户行为操作接口</span>。</p><h3><strong>第六步</strong></h3><p>操作结算元素完成后，我们就可以提交订单了，调用的是<span class=\"orange\">结算页提交订单接口</span>。在经过一系列的校验之后，完成库存的预占和订单的生成，并返回收银台的URL，完成下单成功后的跳转动作，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/e7/e6/e7d9d60920619cf83989acd498af92e6.png?wh=1491x1512\" alt=\"图片\"></p><p>这里是跳转到了收银台的模拟页面，这时我们再回头看看我们的活动库存：</p><p><img src=\"https://static001.geekbang.org/resource/image/21/f6/21414cc311c4db1c64fe98919173caf6.png?wh=1920x552\" alt=\"图片\"></p><p>由4件变成了3件，说明成功做了库存扣减。后续用户可以继续完成支付相关操作，那么用户的一次抢购行为也就结束了，当然如果用户放弃了支付或是取消了订单，那么需要将预占的库存再恢复回去。</p><p>我们这里可以模拟多次抢购，当我们把商品买完时：</p><p><img src=\"https://static001.geekbang.org/resource/image/79/b9/790f1ayybea6e532717f4c0a6d64cab9.png?wh=1920x514\" alt=\"图片\"></p><p>再去商详页看一下：</p><p><img src=\"https://static001.geekbang.org/resource/image/fd/09/fde6c5146e3fcd835be8e0bd3e04df09.png?wh=1726x1706\" alt=\"图片\"></p><p></p><p>可以发现，展示的虽然还是活动相关数据，但是按钮变成灰色的了，因为没有活动库存了。</p><h3><strong>第七步</strong></h3><p>正常情况下，当商品售完时，活动也应该关闭掉了。因为我们没有worker，所以我们就来手动关闭一下，和触发活动开始一样，调用<span class=\"orange\">活动关闭的接口</span>，去关闭活动并将商品的标识恢复成普通商品，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/bb/61/bbc0cd6cf4a72ec774c3222b642e4961.png?wh=1920x282\" alt=\"图片\"></p><p>成功后，我们再看下刷新下商详页：</p><p><img src=\"https://static001.geekbang.org/resource/image/46/06/46248c7bcc93f888abdd4d2800b18906.png?wh=1610x1697\" alt=\"图片\"></p><p>可以看到页面已经恢复到最初的状态了，同时查看下活动信息与商品信息：</p><p><img src=\"https://static001.geekbang.org/resource/image/f0/6a/f0178715f9024597e58047462fbb6d6a.png?wh=1920x551\" alt=\"图片\"></p><p><img src=\"https://static001.geekbang.org/resource/image/7d/75/7d8f7a46d73d74e727ced50c74439575.png?wh=1920x391\" alt=\"图片\"></p><p>活动显示已经结束，商品标识也变回了普通商品，一切都符合预期。</p><p></p><p>到此，我们就完整地支持了一场秒杀活动的开展，秒杀系统中的一些关键链路也得以完美复现，并顺利地实现了我们设定的那个小目标——实现一个最简的秒杀系统。</p><p></p><h2>小结</h2><p>在这节课中，我们为了开发一个最简的秒杀系统，针对秒杀流程做了详细的梳理，画出了系统间的交互过程，同时明确列出了整个秒杀系统所需要提供的主要接口和能力，并且为了整个秒杀业务场景的再现，还加入了一些辅助接口，总体归纳如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/54/6b/5408aa838c6b05b8e732de0847c7ed6b.png?wh=1354x1258\" alt=\"图片\"></p><p>有了这些详细设计的指引，我们可以很快速地开发出一个最简的秒杀系统，并能在本地实现“秒杀活动的创建-&gt;活动开始的打标-&gt;从商详页进秒杀结算页-&gt;提交订单-&gt;活动的关闭与去标”的完整交互。一方面可以帮助我们熟悉和理解秒杀的整个流程，另一方面也可以让我们以“摸的着”的方式去近距离地接触秒杀系统，并感受秒杀系统的设计之美。</p><p></p><h2>思考题</h2><p>现在我们已经自己动手实现了整个秒杀业务，也让我们有了去优化秒杀系统的基石。现在你是时候该去认真思考一下，以上提供的每个接口的瓶颈点在哪里，会出现什么问题，以及如何有效应对了。</p><p>以上就是这节课的全部内容，欢迎你在评论区和我讨论问题，交流经验！</p>","neighbors":{"left":{"article_title":"03 | 指日可待：一步一步搭建秒杀系统（上）","id":423075},"right":{"article_title":"05｜勇于担当：秒杀的隔离策略","id":424175}}},{"article_id":424175,"article_title":"05｜勇于担当：秒杀的隔离策略","article_content":"<p>你好，我是志东，欢迎和我一起从零打造秒杀系统。</p><p>通过前面几节课的学习，相信你对秒杀系统已经有了一个初步的认识，也已经能够按照第二课、第三课和第四课的指引一步一步搭建出一个极简的秒杀系统了。</p><p>那么，当前的秒杀系统是否已经足够强大去应对我们所说的最大的挑战了呢？当面对巨大的瞬时流量冲击的时候，当前的秒杀系统是否能够像三峡大坝一样扛住洪峰，坚不可摧呢？显然，还有距离。</p><p>为了让系统更加的坚固，屹立不倒，我们还需要做哪些工作对秒杀系统进行加固呢？</p><p>从这节课开始，我们将深入到秒杀系统的优化细节，从<strong>高可用、高性能、高并发</strong>等维度出发，一步一步打造一个满足真实业务需求的能够应对百万级用户参与的超大流量冲击的秒杀系统。</p><h2><strong>为流量而生</strong></h2><p>这里我想先请你思考一个问题，非常简单。你觉得普通商品和秒杀商品最本质的区别是什么？</p><p>显而易见的是流量不同。针对普通商品，销量当然是越多越好，所以商家备货一般都会很充足，这样用户去购买的时间就会分散开，流量也会比较均衡。而秒杀商品，说白了，就是稀缺爆品，特点就是库存少，因此用户会去抢购，刷子也会热情高涨，以致瞬时流量巨大。</p><p>另外，普通商品和秒杀商品的数量级也是完全不同的。在头部电商平台，几十亿的商品都是普通商品，只有少数（百个以下）的商品具备秒杀商品的特点。</p><!-- [[[read_end]]] --><p>面对这样的区别，这两类商品其实很难在电商平台上一块进行交易。因为秒杀流量是突发式的，而且流量规模很难提前准确预估，如果混合在一起，势必会对普通商品的交易造成比较大的冲击。所以就像我们开篇词讲的，需要单独搭建秒杀系统，它天然为流量而生。</p><h2><strong>秒杀的隔离</strong></h2><p>很自然，为了不让0.001%的爆品影响99.999%普通商品的交易，我们很快就想到了隔离。隔离是控制危险范围的最直接的手段，正如当下新冠病毒肆虐，采取严格隔离和松散管控不同方式的不同国家，取得的效果也是完全不同的。</p><p>而面对超预期的瞬时流量，我们也要采取很多措施进行流量的隔离，防止秒杀流量串访到普通商品交易流程上，带来不可预估的灾难性后果。</p><p><img src=\"https://static001.geekbang.org/resource/image/d6/0b/d6d8e2e1f96c6e037c0b9bf6568d0c0b.jpg?wh=2351x1148\" alt=\"\"></p><p>上图是几个比较重要的隔离策略，接下来我们详细展开讨论。</p><h3><strong>业务隔离</strong></h3><p>秒杀商品的稀缺性，决定了业务不会像普通商品那样进行投放售卖。一般会有计划地进行营销策划，制订详细的方案，以达到预期的目标。</p><p>因此，从业务上看，它是和普通商品完全不一样的售卖流程，它需要一个提报过程。大部分的电商平台，会有一个专门的提报系统（提报系统的建设不是秒杀的核心部分，这里不再赘述），商家或者业务可以根据自己的运营计划在提报系统里进行活动提报，提供参与秒杀的商品编号、活动起止时间、库存量、限购规则、风控规则以及参与活动群体的地域分布、预计人数、会员级别等基本信息。</p><p>你别小看这个提报过程和这些基本信息，有了这些信息作为输入，我们就能预估出大致的流量、并发数等，并结合系统当前能支撑的容量情况，评估是否需要扩容，是否需要降级或者调整限流策略等，因此业务隔离的重要性可见一斑。</p><h3><strong>系统隔离</strong></h3><p>接下来我们看下系统隔离。前面已经介绍过商品交易流程大概会用到哪些系统，理论上讲，需要把交易链路上涉及到的系统都单独复制部署一套，隔离干净，但这样做成本比较高，一般大点的电商平台都采用分布式微服务的部署架构，服务数量少则几十个，多则几百个，全部复制一套进行隔离不现实。</p><p>所以比较常见的实践是对会被流量冲击比较大的核心系统进行<strong>物理隔离</strong>，而相对链路末端的一些系统，经过前面的削峰之后，流量比较可控了，这些系统就可以不做物理隔离。</p><p><img src=\"https://static001.geekbang.org/resource/image/cd/d5/cd62700f46e2a5yye40637594df388d5.jpg?wh=1250x1208\" alt=\"\"></p><p>我们知道，用户的秒杀习惯，一般是打开商品详情页进行倒计时等待，时间到了点击秒杀按钮进行抢购。因此第一个需要关注的系统就是商品详情页，我们需要申请独立的秒杀详情页域名，独立的Nginx负载均衡器，以及独立的详情页后端服务，并采用Dubbo独立分组的方式单独提供秒杀服务。</p><p>详情页的独立部署完成之后，你可能会有疑问，流量怎么会自己跑到独立的部署集群去呢？这个问题我们先放一放，在后面数据隔离的部分再为你解答。</p><p>我们先来看下如何通过Dubbo的分组来提供独立的微服务集群。</p><p>服务端代码：</p><pre><code class=\"language-java\">package com.ecommerce.product.service;\npublic interface IProductService {&nbsp;&nbsp;\n&nbsp; &nbsp; public SkuInfo getSkuInfo(String skuId);&nbsp;&nbsp;\n}\n</code></pre><pre><code class=\"language-java\">package com.ecommerce.product.service.impl;\nimport com.ecommerce.product.service.IProductService;\n@Autowired\nCacheManager cacheManager;\npublic class ProductServiceImpl implements IProductService {\n&nbsp; &nbsp; \n    //根据商品编号获取商品详细信息\n&nbsp; &nbsp; @Override\n    public SkuInfo getSkuInfo(String skuId) {&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; return cacheManager.getSkuInfo(skuId);\n&nbsp; &nbsp; }\n}\n</code></pre><p>服务端applicationContext配置：</p><pre><code class=\"language-plain\">&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;beans xmlns=\"http://www.springframework.org/schema/beans\"\n&nbsp; &nbsp; xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n&nbsp; &nbsp; xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\"\n&nbsp; &nbsp; xsi:schemaLocation=\"http://www.springframework.org/schema/beans&nbsp; &nbsp; &nbsp; &nbsp; http://www.springframework.org/schema/beans/spring-beans.xsd&nbsp; &nbsp; &nbsp; &nbsp; http://code.alibabatech.com/schema/dubbo&nbsp; &nbsp; &nbsp; &nbsp; http://code.alibabatech.com/schema/dubbo/dubbo.xsd\"&gt;\n\n&nbsp; &nbsp; &lt;!-- 配置Bean --&gt;\n&nbsp; &nbsp; &lt;bean id=\"productService\" class=\"com.ecommerce.product.service.impl.ProductServiceImpl\"/&gt;\n&nbsp; &nbsp; &lt;!-- 引入配置文件 --&gt;\n&nbsp; &nbsp; &lt;import resource=\"classpath:dubbo.xml\"/&gt;\n&nbsp;&lt;/beans&gt;\n</code></pre><p>服务端dubbo.xml配置：</p><pre><code class=\"language-plain\">&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;beans xmlns=\"http://www.springframework.org/schema/beans\"\n&nbsp; &nbsp; xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n&nbsp; &nbsp; xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\"\n&nbsp; &nbsp; xsi:schemaLocation=\"http://www.springframework.org/schema/beans&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; http://www.springframework.org/schema/beans/spring-beans.xsd&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; http://code.alibabatech.com/schema/dubbo&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; http://code.alibabatech.com/schema/dubbo/dubbo.xsd\"&gt;&nbsp;\n&nbsp; &nbsp; &lt;!-- 指定web服务名字 --&gt;\n&nbsp; &nbsp; &lt;dubbo:application name=\"ProductGroup\"/&gt;\n&nbsp; &nbsp; &lt;!-- 声明服务注册中心 --&gt;\n&nbsp; &nbsp; &lt;dubbo:registry&nbsp; protocol=\"zookeeper\" address=\"127.0.0.1:2181\"/&gt;\n&nbsp; &nbsp; &lt;!-- 指定传输层通信协议 --&gt;\n&nbsp; &nbsp; &lt;dubbo:protocol name=\"dubbo\" port=\"20880\"/&gt;\n&nbsp; &nbsp; &lt;!-- 暴露你的服务地址 --&gt;\n&nbsp; &nbsp; &lt;dubbo:service&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; ref=\"productService\"&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; interface=\"com.ecommerce.product.service.IProductService\"\n&nbsp; &nbsp; &nbsp; &nbsp; protocol=\"dubbo\"\n        &lt;!-- 普通交易流程，商品后端微服务的逻辑分组 --&gt;\n&nbsp; &nbsp; &nbsp; &nbsp; group=\"product-cloud\"\n&nbsp; &nbsp; /&gt;\n&nbsp;&lt;/beans&gt;\n</code></pre><p>以上是商品后端服务的一些基础代码和配置，不知道你有没有注意到第21行的逻辑分组定义，这里表明当前Dubbo提供了一个分组名为 <strong>product-cloud</strong> 的微服务，给普通商品交易流程使用。</p><p>那为了隔离出专门给秒杀通道的服务，我们只需要申请相应的容器资源，复制以上配置，并对分组名进行修改就完成了。</p><pre><code class=\"language-plain\">&nbsp; &nbsp; &lt;!-- 暴露你的服务地址 --&gt;\n&nbsp; &nbsp; &lt;dubbo:service&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; ref=\"productService\"&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; interface=\"com.ecommerce.product.service.IProductService\"\n&nbsp; &nbsp; &nbsp; &nbsp; protocol=\"dubbo\"\n        &lt;!-- 秒杀流程，商品后端微服务的逻辑分组 --&gt;\n&nbsp; &nbsp; &nbsp; &nbsp; group=\"seckill\"\n&nbsp; &nbsp; /&gt;\n</code></pre><p>这样我们商品后端微服务的隔离就完成了。接着我们看下调用端如何实现隔离。</p><p>调用端dubbo.xml配置：</p><pre><code class=\"language-plain\">&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;beans xmlns=\"http://www.springframework.org/schema/beans\"\n&nbsp; &nbsp; xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n&nbsp; &nbsp; xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\"\n&nbsp; &nbsp; xsi:schemaLocation=\"http://www.springframework.org/schema/beans&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; http://www.springframework.org/schema/beans/spring-beans.xsd&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; http://code.alibabatech.com/schema/dubbo&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; http://code.alibabatech.com/schema/dubbo/dubbo.xsd\"&gt;\n\n&nbsp; &nbsp; &lt;!-- 指定web服务名字 --&gt;\n&nbsp; &nbsp; &lt;dubbo:application name=\"ProductGroup\"/&gt;\n&nbsp; &nbsp; &lt;!-- 声明服务注册中心 --&gt;\n&nbsp; &nbsp; &lt;dubbo:registry protocol=\"zookeeper\" address=\"127.0.0.1:2181\"/&gt;\n\n&nbsp; &nbsp; &lt;!-- 指定传输层通信协议 --&gt;\n&nbsp; &nbsp; &lt;dubbo:protocol name=\"dubbo\" port=\"20881\"/&gt;\n\n&nbsp; &nbsp; &lt;!-- 引用你的服务地址 --&gt;\n&nbsp; &nbsp; &lt;dubbo:reference&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; id=\"productService\"&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; interface=\"com.ecommerce.product.service.IProductService\"\n&nbsp; &nbsp; &nbsp; &nbsp; protocol=\"dubbo\"\n        &lt;!-- 这里引用的分组名，选择了秒杀流程的逻辑分组 --&gt;\n&nbsp; &nbsp; &nbsp; &nbsp; group=\"seckill\"\n&nbsp; &nbsp; /&gt;\n&nbsp;&lt;/beans&gt;\n</code></pre><p>根据以上第24行代码可知，调用方在使用时，根据场景选择相应的分组名进行调用，那么流量就会走到不同的微服务集群里，从而达到微服务流量隔离的目的。</p><p>前面我们介绍了微服务集群的隔离方法，接下来我们看下负载均衡器的隔离。为了能水平扩展服务的能力，一般我们在流量入口都会通过负载均衡器来进行流量分配，常用的有硬件负载均衡，比如F5，其功能和性能优于软件方式，但一般比较昂贵。</p><p>大厂里比较常用的负载均衡器都是软件方式，有LVS、HAProxy、Nginx等，一方面是出于成本考虑，毕竟大厂的网络规模非常大，单个F5的硬件成本能承受，但是大规模的硬件成本就很高了；另一方面开源的软件也更加灵活和可定制。</p><p>但不管采用的是硬件还是软件，为了不让流量互相影响，我们都有必要对负载均衡进行隔离，需要单独部署一套。隔离的方式也比较简单，部署之后，把相应的IP地址挂载到不同的DNS域名下就好了。</p><p>紧接着我们仍需要对域名进行隔离，我们可以向运维部门申请一个独立的域名，专门用来承接秒杀流量，流量从专有域名进来之后，分配到专有的负载均衡器，再路由到专门的微服务分组，这样就做到了应用服务层面从入口到微服务的流量隔离。</p><p><img src=\"https://static001.geekbang.org/resource/image/d9/6f/d9d69c7decae541883f55a030476bf6f.jpg?wh=5540x2840\" alt=\"\"></p><p>以上就是商品详情页的系统隔离方法，交易流程的其他系统，比如结算页、价格中心、订单中心等也可以参照类似的方式进行隔离，这里就不重复讲解了。</p><p>在我看来，这里流量冲击比较大的核心系统就是秒杀详情页、秒杀结算页，是需要我们重点关注的对象，而相对链路末端的一些系统，经过前面的削峰之后，流量比较可控了，如接单系统、收银台、支付系统，物理隔离的意义就不大，反而会增加成本。你自己设计秒杀系统的时候，可以格外注意一下。</p><h3>数据隔离</h3><p>现在，我们已经完成了应用层的隔离。接下来，在数据层面，我们也应该进行相应的隔离，否则如果共用缓存或者共用数据库，一旦瞬时流量把它们冲垮，照样会影响无辜商品的交易。</p><p>数据层的专有部署，需要结合秒杀的场景来设计部署拓扑结构，比如Redis缓存，一般的场景一主一从就够了，但是在秒杀场景，需要<strong>一主多从</strong>来扛读热点数据。关于热点数据的处理在后面的课程中我们会详细进行介绍，这里先留个悬念。</p><p>到这里为止，我们基本学习完了秒杀隔离策略。现在，我们回过头来思考系统隔离中遗留的问题：<strong>怎么让秒杀流量正确地路由到我们隔离出来的专有环境里来呢？</strong></p><p>答案就是对商品进行打标，在商品的主数据上有了秒杀标，那么我们在任何一个环节都可以把这个染色过的流量进行正确地路由了。</p><p>那么既然提到了商品打标，这里我再简单介绍一下商品打标的设计思路。当然，电商平台的商品系统设计远远比这复杂。</p><p>打标就是一个标记，我们可以使用一个long型字段skuTags来保存，long是64位，每一位代表一种类型的活动，0代表否，1代表是，通过对skuTags进行二进制操作即可完成商品的打标和去标。假设秒杀的标识我们定义在skuTags的第11位，那么要给一个sku打上秒杀标，我们就可以对这个标实际进行“或”操作：skuTags=skuTags|1024，这样skuTags字段的第11位就变成了1，对其它bit位没影响。去标过程相反，同样进行位操作，skuTags=skuTags&amp;~1024，把第11位置为0。</p><p>好了，<strong>最后我们把整个隔离流程再串一下</strong>。</p><p>首先业务通过提报系统对秒杀sku进行提报，系统对秒杀sku进行打标，从活动页、列表页或者搜索页点击商品的时候，系统就能识别出秒杀标，路由到秒杀的商品详情页域名，进而进入到专有Nginx。</p><p>然后就是到专有的微服务分组，以及专有的Redis缓存了。这里提一下，上面介绍的流量分流实际上是从活动页就开始的，为了节约成本，我们也可以设计在商品详情页进行分流，这样做的好处是商品详情页是通用的实现，也是通用的部署，当用户在详情页点击购买的时候，才根据是否有秒杀标识进行流量分流。劣势就是进行秒杀的时候，商品详情页的流量压力会比较大。</p><h2>小结</h2><p>秒杀系统的特点倒逼我们不得不做流量隔离。如果不做隔离，任由流量互相横冲直撞，将会对电商平台造成很大的影响。隔离的措施概括下来有三种：业务隔离、系统隔离和数据隔离。</p><p>其中我们需要重点关注系统和数据的隔离，从ROI的角度看，我们需要找出电商交易平台最核心的几个系统进行隔离，从头部电商平台的实践来看，一般会单独设计和部署秒杀的商详页和结算页系统，以及结算页系统链路下游的购物车和订单系统。</p><p>在这个过程中，一般购物车和订单不需要做特殊定制，只需要根据流量情况进行专门部署即可。而挑战比较大的就是秒杀的结算页系统，它是秒杀流量的主要入口，承担着把瞬时流量承接下来并进行优质流量筛选的重任，因此如何搭建秒杀结算页的高可用、高性能和高并发至关重要。</p><p>这节课我们介绍了秒杀隔离，它是秒杀系统高可用体系非常重要的一个环节，接下来我们将从其他方面继续探讨秒杀系统的高可用，敬请期待下一节课流量管控的内容！</p><h2>思考题</h2><p>如果采用通用的商品详情页，当用户点击购买按钮的时候才进行流量分流，那么商品详情页的流量压力就比较大，这种设计有什么办法可以避免秒杀流量对普通商品的详情页造成冲击吗？</p><p>以上就是这节课的全部内容，欢迎你在评论区和我讨论问题，交流经验！</p>","neighbors":{"left":{"article_title":"04 | 指日可待：一步一步搭建秒杀系统（下）","id":423966},"right":{"article_title":"06｜谋定后动：秒杀的流量管控","id":424215}}},{"article_id":424215,"article_title":"06｜谋定后动：秒杀的流量管控","article_content":"<p>你好，我是志东，欢迎和我一起从零打造秒杀系统。</p><p>上节课我们详细探讨了秒杀的隔离策略，简单回顾一下，为了让秒杀商品不影响其他商品的正常销售，我们从多个角度详细介绍了隔离，特别是系统隔离层面，我们从流量的起始链路入手，介绍了各个链路不同的隔离方法。从这节课开始，我们将重点介绍流量的管控。</p><h2>如何有效地管控流量？</h2><p>通过对秒杀流量的隔离，我们已经能够把巨大瞬时流量的影响范围控制在隔离的秒杀环境里了。接下来，我们开始考虑隔离环境的高可用问题，通俗点说，普通商品交易流程保住了，现在就要看怎么把秒杀系统搞稳定，来应对流量冲击，让秒杀系统也不出问题。方法很多，有<strong>流量控制、削峰、限流、缓存热点处理、扩容、熔断</strong>等一系列措施。</p><p>这些措施都是我们在第二模块要重点讲解的技术手段，内容比较多，而且会有一些交叉，我会用三节课来分享。</p><p>这节课我们先来看流量控制。在库存有限的情况下，过多的用户参与实际上对电商平台的价值是边际递减的。举个例子，1万的茅台库存，100万用户进来秒杀和1000万用户进来秒杀，对电商平台而言，所带来的经济效益、社会影响不会有10倍的差距。相反，用户越多，一方面消耗机器资源越多；另一方面，越多的人抢不到商品，平台的客诉和舆情压力也就越大。当然如果为了满足用户，让所有用户都能参与，秒杀系统也可以通过堆机器扩容来实现，但是成本太高，ROI不划算，所以我们需要提前对流量进行管控。</p><!-- [[[read_end]]] --><p><img src=\"https://static001.geekbang.org/resource/image/30/a3/300be2283197b07yyaa538e20f175aa3.jpg?wh=2209x1079\" alt=\"\"></p><p>如果你关注过电商平台的双11或618大促，你肯定能感受到“预约+秒杀”在大促时的主流营销玩法。上图是预约+秒杀营销模式的示意图，主要分为预约期和秒杀期。</p><p>预约期内，开放用户预约，获取秒杀抢购资格；秒杀期内，具备抢购资格的用户真正开始秒杀。在预约期内，关键是<strong>锁定用户</strong>，这也是我们能够用来做流量管控的核心。在展开通过预约进行流量管控的细节之前，我们先看下如何来设计一个简单的预约系统。</p><h2>预约系统设计</h2><p>在进行系统设计之前，我们先分析预约的业务情况。</p><p>先从角色看，参与的有运营方，提供商品，进行预约活动的计划安排；C端用户，进行预约和秒杀行为；以及支撑预约活动的交易链路系统。</p><p>因此我们需要一个<strong>预约管理后台</strong>，进行活动的设置和关闭；需要一个<strong>预约worker系统</strong>，根据时间调用商品系统进行预约打标和去标，向预约过的用户发短信或消息提醒；还需要一个面向C端的<strong>预约核心微服务</strong>，提供给用户预约和取消预约能力，商详在展示时获取预约信息的能力，秒杀下单时检查预约资格的能力，以及获取用户的预约列表能力。</p><p>这样预约的架构就出来了，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/b3/90/b33b7faf17887dc8ac4c534bcf92d690.jpg?wh=1584x1430\" alt=\"\"></p><p>预约管理后台和预约worker的功能比较简单，这里就不展开介绍了。我们重点看下预约核心微服务系统的设计，包括接口、数据库和缓存。</p><p>以下是核心微服务需要提供的<strong>Dubbo接口</strong>：</p><pre><code class=\"language-java\">package com.ecommerce.reservation.service;\n\npublic interface IReservationService { \n    //添加预约资格接口 \n    public Boolean addReservation(String skuId, String userName); \n    //取消预约资格接口\n    public Boolean cancelReservation(String skuId, String userName);  \n    //获取预约信息接口\n    public List&lt;ReservationInfo&gt; getReservationInfoList(List&lt;String&gt; skuIds);\n    //校验预约资格接口\n    public Boolean validateReservation(String skuId, String userName);\n    //获取用户预约列表接口\n    public List&lt;MyReservation&gt; getMyReservationList(String userName);\n}\n</code></pre><p>接口的具体实现这里就不展开了，代码逻辑还是比较简单的。拿添加预约资格接口来说，这个接口的实现就是先做一些参数校验，接着把预约关系写入数据库，再写入Redis缓存，最后更新商品的总预约人数。当然，这里面数据库和缓存的一致性问题是需要仔细考虑的。</p><p>再看下<strong>数据库层</strong>的设计，对预约来讲，核心就是两个维度：预约活动和用户预约关系。因此实际上数据库层面只需要两张表就够了，一张是预约活动信息表，另一张是用户预约关系表。</p><pre><code class=\"language-sql\">CREATE TABLE `t_reserve_info` (\n&nbsp; `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT '预约活动id',\n&nbsp; `sku_id` bigint(20) unsigned DEFAULT NULL COMMENT '商品编号',\n&nbsp; `reserve_start_time` datetime DEFAULT NULL COMMENT '预约开始时间',\n&nbsp; `reserve_end_time` datetime DEFAULT NULL COMMENT '预约结束时间',\n&nbsp; `seckill_start_time` datetime DEFAULT NULL COMMENT '秒杀开始时间',\n&nbsp; `seckill_end_time` datetime DEFAULT NULL COMMENT '秒杀结束时间',\n&nbsp; `creator` varchar(255) DEFAULT NULL COMMENT '活动创建人',\n&nbsp; `update_time` datetime DEFAULT NULL COMMENT '更新时间',\n&nbsp; `yn` tinyint(255) unsigned DEFAULT NULL COMMENT '是否删除',\n&nbsp; PRIMARY KEY (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n\nCREATE TABLE `t_reserve_user` (\n&nbsp; `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT '关系id',\n&nbsp; `reserve_info_id` bigint(20) unsigned DEFAULT NULL COMMENT '预约活动id',\n&nbsp; `sku_id` bigint(20) unsigned DEFAULT NULL COMMENT '商品编号',\n&nbsp; `user_name` varchar(255) DEFAULT NULL COMMENT '用户名称',\n&nbsp; `reserve_time` datetime DEFAULT NULL COMMENT '预约时间',\n&nbsp; `yn` tinyint(255) unsigned DEFAULT NULL COMMENT '是否删除',\n&nbsp; PRIMARY KEY (`id`),\n&nbsp; KEY `reserve_id_ref` (`reserve_info_id`),\n&nbsp; CONSTRAINT `reserve_id_ref` FOREIGN KEY (`reserve_info_id`) REFERENCES `t_reserve_info` (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n</code></pre><p>以下是这两张核心数据库表的ER图：</p><p><img src=\"https://static001.geekbang.org/resource/image/f1/6a/f1215e6a5dd4e9dd8cefc36a880de96a.jpg?wh=1202x558\" alt=\"\"></p><p>当数据量小的时候，我们用以上这两张表就能满足业务需求。但是在头部电商平台，每次大促时预约人数都是几千万量级的，因此为了更好的性能，我们需要对数据库分库分表。对t_reserve_user这个用户预约关系表来说，就需要按照user_name的哈希值进行分库和分表。另外，对于历史数据，也需要有个定时任务进行结转归档，以减轻数据库的压力。</p><p>接下来我们再看下<strong>缓存设计</strong>。对高并发系统来说，要扛住大流量，我们知道肯定不能让流量击穿到数据库，所以需要设计缓存来抵挡。</p><p>先看t_reserve_info这个对象，首先我们需要在Redis缓存里存储它，那么Redis key可以这样设计：reserve_info_{skuid}，value可以用JSON string存储，当然也可以采用其他序列化方式，取决于你自己。</p><p>因为这个对象是sku维度的，在爆品的场景下，可能会有热点问题，针对热点问题的解决方案，可以设计Redis分片的一主多从来扛流量，也可以通过微服务层的本地缓存来解决。具体细节这里先留个悬念，我们在后面的热点缓存板块再来深入讨论。</p><p>另外，用户和商品的预约关系，可以存储成Redis的hash表，key为reserve_user_{userName}，value就是用户的预约sku列表，field为skuid。用户的预约关系和预约信息表不同，它是用户维度的，不会存在热点问题，所以我们可以不用考虑本地缓存。</p><p>假设skuid=10001的商品正常进行预约，用户szd预约了该商品，那么缓存内容大致如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/2b/35/2b624d0070224a124fd8105ee569e635.jpg?wh=1496x1474\" alt=\"\"></p><h2>预约系统优化</h2><p>现在我们已经把预约系统设计出来了，接下来要做的就是优化它。</p><p>传统的预约模式，预约期是固定的时间段，用户在这个阶段内都可以预约；但在秒杀场景下，为了能够准确把控流量，控制预约人数上限，我们需要拓展预约期的定义，除了时间维度外，还要加入预约人数上限的维度，一旦达到上限，预约期就即时结束。</p><p>这实际上是给预约活动添加了一个自动熔断的功能，一旦活动太火爆，到达上限后系统自动关闭预约入口，提前进入等待秒杀状态。这样就可以准确把控人数，从而为秒杀期护航。</p><p><img src=\"https://static001.geekbang.org/resource/image/3d/a4/3d12611a9166fd13bb112038f916e8a4.jpg?wh=1202x1538\" alt=\"\"></p><p>以上是预约熔断的流程图，白色部分流程是原有的用户预约过程，蓝色部分是添加了熔断机制的流程。技术方案还是比较简单的，这里更多的是给你思路上的启发，这也是我多次踩坑之后的经验总结。</p><p>这里，你可以拓展想一想，我们现在已经能够通过预约熔断来把控秒杀资格的上限，那么随着用户对流程的熟悉，<strong>预约系统会怎么演变呢？</strong></p><p>是的，你没有猜错，当用户都知道必须预约才能在秒杀阶段有参与资格时，用户就会在预约期疯狂地挤进来，那么此时的预约系统也具备秒杀系统的特点了。好在预约人数的把控不需要那么精确，我们只需要即时熔断就达到目的了。</p><p>当然了，不是所有的爆品都有这样的号召力，我刚说的属于特殊情况。要知道即使是飞天茅台，都不会触发预约熔断。而2020年2月初口罩紧缺的时候，线下都是居委会分配票证购买（我印象中听父母提起他们那一辈计划经济时代才需要粮票肉票），线上一开放预约，一分钟就预约了几百万用户触发熔断了。这应该是互联网历史上流量最大的秒杀活动了吧。</p><p>另外，一般预约系统在业务设计上，需要在商详页展示当前预约人数给用户看，以营造商品火爆的气氛。我们自然就想到了可以在Redis里记录一个预约人数的key，比如reserve_amount_{skuid}，value就是预约人数。商详页展示氛围的时候，会从Redis里获取到这个value进行提示，而用户点击“立即预约”按钮进行预约时，会往这个key进行++操作。这个设计在预约流量没那么聚集时没什么问题，因为一般Redis单片也能扛个七八万的OPS。而当预约期一分钟内几百万人都来预约时，显然这个Redis key就是典型的热key问题了。这个热key问题的解决我们会在热点处理章节重点介绍。</p><h2>小结</h2><p>上一节课我们介绍了秒杀的隔离，我们需要进一步思考的就是控制流量。通常的做法是事前引入预约环节，进行秒杀参与人数的把控，“预约+秒杀”是主流电商平台通用的营销方式。</p><p>这个方案有两点好处，人气不足时，可以通过预约聚集人气，在同一时间点放闸开始秒杀，起到烘托大促气氛的作用；而人气过于旺盛时，则可以通过预约控制参与人数上限，只有预约过的会员才有秒杀资格，就可以防止过多人数对秒杀抢购造成冲击。</p><p>为了准确地控制能够参与秒杀的用户量级，预约系统需要增加基于用户数量级设定的自动熔断的功能。有了预约自动熔断，我们就可以结合秒杀商品的库存，业务计划引流的PV多少，提前规划好预约阶段开放的抢购资格数量，进行流量规划，准确管控秒杀期的流量。</p><p>除此之外，这节课我们还重点学习了预约系统的设计思路，根据这个思路，你可以很快速地搭建出一个比较简单的预约系统。</p><p>通过预约来控制流量属于事前管控，其实在事中，还有很多的手段来管控流量。比如通过答题或验证码，让流量平缓；通过排队机制，让流量有序地进入秒杀系统；抑或通过限流，对流量进行过滤。这些流量管控的具体措施我将在下一讲为你一一道来。</p><h2>思考题</h2><p>预约业务还有一个功能，就是给预约过的用户发消息提醒，引导用户进行秒杀。一般的做法是根据skuid从t_reserve_user表取出预约过的用户，然后进行push推送。</p><pre><code class=\"language-sql\">select user_name from t_reserve_user where sku_id=#{skuId} limit #{page.beginIndex},#{page.step}\n</code></pre><p>那么，当一个sku预约了几百万用户之后，这个查询会遇到深度分页的问题，越到后面查询越慢。现在请你想一下，有没有其他替代方案可以解决深度分页难题？</p><p>以上就是这节课的全部内容，欢迎你在评论区和我讨论问题，交流经验！</p>","neighbors":{"left":{"article_title":"05｜勇于担当：秒杀的隔离策略","id":424175},"right":{"article_title":"07｜乾坤大挪移：秒杀的削峰和限流","id":424503}}},{"article_id":424503,"article_title":"07｜乾坤大挪移：秒杀的削峰和限流","article_content":"<p>你好，我是志东，欢迎和我一起从零打造秒杀系统。</p><p>前面两节课我们讲了秒杀的隔离策略和流量控制，其目的是降低流量的相互耦合和量级，减少对系统的冲击。这节课我们将继续从<strong>技术角度</strong>来讨论秒杀系统的其他高可用手段——削峰和限流，通过削峰，让系统更加稳健。</p><p>削峰填谷概念一开始出现在电力行业，是调整用电负荷的一种措施，在互联网分布式高可用架构的演进过程中，也经常会采用类似的削峰填谷手段来构建稳定的系统。</p><p>削峰的方法有很多，可以通过业务手段来削峰，比如秒杀流程中设置验证码或者问答题环节；也可以通过技术手段削峰，比如采用消息队列异步化用户请求，或者采用限流漏斗对流量进行层层过滤。削峰又分为无损和有损削峰。本质上，<strong>限流是一种有损技术削峰；而引入验证码、问答题以及异步化消息队列可以归为无损削峰。</strong></p><p>我们先来看一下电商平台线上真实场景下的秒杀流量图，因为数据保密的需要，这里我隐去了具体的流量数字。但是，你可以看到这个图有个非常明显的特点，就是毛刺特别大，流量几秒内爬升到峰值，然后马上掉下来。不管是口罩、茅台，还是春运的火车票，都符合这样的流量特点。</p><p><img src=\"https://static001.geekbang.org/resource/image/35/64/35dc492a82da8e4bbc0188918dcc7964.png?wh=2464x1740\" alt=\"\"></p><p>我们现在需要做的就是通过削峰和限流，把这超大的瞬时流量平稳地承接下来，落到秒杀系统里。这就犹如武侠小说里，众人从高塔纵身跳下，张无忌运用乾坤大挪移，把对众人伤害极大的垂直自由落体运动改变为水平运动，使之安然脱险。</p><!-- [[[read_end]]] --><h2>流量削峰</h2><p>前面的章节中，我介绍过秒杀的业务特点是库存少，最终能够抢到商品的人数取决于库存数量，而参与秒杀的人越多，并发数就越高，随之无效请求也就越多。但从业务方的角度来说，肯定是希望有更多的人参与进来，点击“立即秒杀”按钮体验秒杀的乐趣。</p><p>从上面的流量监控图可以看到，在秒杀开始的时刻，会出现巨大的瞬时流量，这个流量对资源的消耗也是巨大且瞬时的。</p><p>一般来说，我们支撑秒杀系统的硬件资源是有限的，它的处理能力是恒定的，当有秒杀活动的时候，很容易繁忙导致请求处理不过来，而没有活动的时候，机器又是低负载运转。但是为了保证用户的秒杀体验，一般情况下我们的处理资源只能按照忙的时候来预估，这会导致资源的一个浪费。这就好比交通存在早高峰和晚高峰的问题，所以有了外牌限行、尾号限行等多种错峰解决方案。</p><p>因此我们需要设计一些<strong>规则</strong>，延缓并发请求，甚至过滤掉无效的请求，让真正可以下单的请求越少越好。总结来说，削峰的本质，一是让服务端处理变得更加平稳，二是节省服务器的机器成本。</p><p>接下来，我们就重点学习几个常用的削峰手段：验证码、问答题、消息队列、分层过滤和限流。顺便看看互联网大厂里都会采用什么样的手段，以及背后的思考逻辑。</p><h3>验证码和问答题</h3><p>在秒杀交易流程中，引入验证码和问答题，有两个目的：一是快速拦截掉部分刷子流量，防止机器作弊，起到防刷的作用；二是平滑秒杀的毛刺请求，延缓并发，对流量进行削峰。</p><p>让用户在秒杀前输入验证码或者做问答题，不同用户的手速有快有慢，这就起到了让1s的瞬时流量平均到30s甚至1分钟的平滑流量中，这样就不需要堆积过多的机器应对1s的瞬时流量了。</p><p>以下是流程图，我来解释一下。</p><p><img src=\"https://static001.geekbang.org/resource/image/a7/6d/a7e4c6a0af9c9c22db57d24e8910676d.jpg?wh=2036x1130\" alt=\"\"></p><p>设计验证码流程，一般是在用户进入详情页时，先判别秒杀活动是否已经开始，如果已经开始，同时秒杀活动也配置了需要校验验证码标识，那么就需要从秒杀系统获取图片验证码，并进行渲染；用户手工输入验证码后，提交给秒杀系统进行验证码校验，如果通过就跳转至秒杀结算页。</p><p>上图增加的红线部分就是引入了验证码的秒杀流程。当然，我这里介绍的，是把验证码功能作为秒杀系统的一个模块了，而大公司一般都会有单独的验证码服务，我们不用自己造轮子，只要进行系统对接就行了。</p><p>下面我简单介绍一下验证码的实现，通过上图得知，验证码服务需提供两个基本的功能：生成验证码和校验验证码。</p><p><strong>生成验证码</strong><strong>，</strong>先看接口设计如下：</p><pre><code class=\"language-sql\">POST /seckill/captchas.jpg?skuId=10001\n</code></pre><p>对应的后端代码实现：</p><pre><code class=\"language-sql\">    /**\n\t * 生成图片验证码\n\t */\n\t@RequestMapping(value=\"/seckill/captchas.jpg\", method=RequestMethod.POST})\n\t@ResponseBody\n\tpublic SeckillResponse&lt;String&gt; genCaptchas(String skuId, HttpServletRequest request, HttpServletResponse response) {\n        //从cookie中取出user\n        String user = getUserFromCookie(request);\n        //根据skuId和user生成图片\n        BufferedImage img=createCaptchas(user, skuId);\n\t\ttry {\n\t\t\tOutputStream out=response.getOutputStream();\n\t\t\tImageIO.write(img, \"JPEG\", out);\n\t\t\tout.flush();\n\t\t\tout.close();\n\t\t\treturn null;&nbsp;\n\t\t} catch (IOException e) {\n\t\t\te.printStackTrace();\n\t\t\treturn SeckillResponse.error(ErrorMsg.SECKILL_FAIL);\n\t\t}\n\t}\n\n    /**\n     * 生成验证码图片方法\n     */\n    public BufferedImage createCaptchas(String user, String skuId) {\n\t\tint width=90;\n\t\tint height=40;\n\t\tBufferedImage img=new BufferedImage(width,height,BufferedImage.TYPE_INT_RGB);\n\t\tGraphics graph=img.getGraphics();\n\t\tgraph.setColor(new Color(0xDCDCDC));\n\t\tgraph.fillRect(0, 0, width, height);\n\t\tRandom random=new Random();\n\t\t//生成验证码\n\t\tString formula=createFormula(random);\n\t\tgraph.setColor(new Color(0,100,0));\n\t\tgraph.setFont(new Font(\"Candara\",Font.BOLD,24));\n\t\t//将验证码写在图片上\n\t\tgraph.drawString(formula, 8, 24);\n\t\tgraph.dispose();\n\t\t//计算验证码的值\n\t\tint vCode=calc(formula);\n\t\t//将计算结果保存到redis上面去，过期时间1分钟\n\t\tcacheMgr.set(\"CAPTCHA_\"+user+\"_\"+skuId, vCode, 60000);\n\t\treturn img;\n\t}\n\n\tprivate String createFormula(Random random) {\n\t\tprivate static char[]ops=new char[] {'+','-','*'};\n        //生成10以内的随机数\n\t\tint num1=random.nextInt(10);\n\t\tint num2=random.nextInt(10);\n\t\tint num3=random.nextInt(10);\n\t\tchar oper1=ops[random.nextInt(3)];\n\t\tchar oper2=ops[random.nextInt(3)];\n\t\tString exp=\"\"+num1+oper1+num2+oper2+num3;\n\t\treturn exp;\n\t}\n\n    private static int calc(String formula) {\n\t\ttry {\n\t\t\tScriptEngineManager manager=new ScriptEngineManager();\n\t\t\tScriptEngine engine=manager.getEngineByName(\"JavaScript\");\n\t\t\treturn (Integer) engine.eval(formula);\n\t\t}catch(Exception e){\n\t\t\te.printStackTrace();\n\t\t\treturn 0;\n\t\t}\n\t}\n</code></pre><p>以上是自己生成图片验证码的方式，方便起见，你也可以用Google提供的Kaptcha包生成图片验证码。</p><p>同时，为了让交互更加安全，避免被篡改，我们还可以加入签名机制，后端在返回给前端图片验证码的时候，同时返回一个签名，前端在点击“抢购”按钮的时候，把用户输入的验证码以及签名提交给后端服务进行验证。这个签名可以设计如下：</p><pre><code class=\"language-plain\">signature=base64(timestamp,md5(timestamp,vCode,skuId,user,randomSalt)\n</code></pre><p>这里timestamp取生成验证码vCode时的时间戳，randomSalt可以理解为后端的一个私钥。那么在前面代码的第44行，我们存入Redis的值就要换成这个signature了。</p><p>当前端点击“抢购”按钮时，调用后端服务如下：</p><pre><code class=\"language-plain\">POST /seckill/settlement.html?skuId=10001&amp;signature=ad6543audhhw13dg&amp;timestamp=1345611143&amp;newCode=54\n</code></pre><p>接下来我们看<strong>校验验证码</strong><strong>。</strong>校验的逻辑比较简单，从前端的HTTP请求里，取得skuId、user、signature、timestamp和newCode，首先验证timestamp是否已经过期，然后根据用户输入的验证码内容newCode重新计算签名newSignature，并和Redis里的signature进行比对，比对一致表示验证码校验通过。然后我们需要删掉Redis的内容，避免被重复验证，这样的话一个验证码就只会被验证一次了。</p><h3>消息队列</h3><p>除了验证码和问答题，另一种削峰方式是<strong>异步消息队列</strong>。</p><p>当服务A依赖服务B时，正常情况下服务A会直接通过RPC调用服务B的接口，当服务A调用的流量可控，且服务B的TP99和QPS能满足调用时，这是最简单直接的调用方式，没什么问题，目前大部分的微服务间调用也都是这样做的。</p><p>但是，试想一下，如果服务A的流量非常高（假设10万QPS），远远大于服务B所能支持的能力（假设1万QPS），那么服务B的CPU很快就会升高，TP99也随之变高，最终服务B被服务A的流量冲垮。</p><p>这个时候，消息队列就派上用场了，我们把一步调用的直接紧耦合方式，通过消息队列改造成两步异步调用，让超过服务B范围的流量，暂存在消息队列里，由B根据自己的服务能力来决定处理快慢，这就是通过消息队列进行调用解耦的常见手段。</p><p><img src=\"https://static001.geekbang.org/resource/image/b8/6c/b8f142e7926cd954935497917711ae6c.jpg?wh=1530x807\" alt=\"\"></p><p>常见的开源消息队列有Kafka、RocketMQ和RabbitMQ等，大厂的基础中间件部门一般也会根据自己公司的业务特点，自研适合自己的MQ系统。对一般的场景来说，我推荐你用RocketMQ，应该能解决你大部分的问题。</p><p>以上是通过MQ进行调用解耦的基本思路，现在我们回到秒杀的场景，看看应该怎么设计呢？请看下图：</p><p><img src=\"https://static001.geekbang.org/resource/image/94/df/944yy258d21de2f70b2acc1f0e217edf.jpg?wh=2230x1026\" alt=\"\"></p><p>以上红色和蓝色的部分，就是通过消息队列解耦后，详情页系统和秒杀系统各自处理的部分。因为解耦了，所以在第6步下单之后，其实是不知道秒杀结果的，因此在第11步，需要前端定期去查询秒杀结果反馈给用户。而在秒杀系统拉取消息队列进行处理的时候，也有个小技巧，那就是当前面的请求已经把库存消耗光之后，在缓存里设置占位符，让后续的请求快速失败，从而最快地进行响应。</p><h2>限流</h2><p>削峰的方式，前面介绍了验证码/问答题以及消息队列，这些方式使流量峰值变得更加平滑，但也在一定程度上降低了抢购体验，容易引发用户咨询和投诉。那有没有更好的解决方式呢？接下来我们学习下限流，看看如何通过限流实现削峰。</p><p>限流是系统自我保护的最直接手段，再厉害的系统，总有所能承载的能力上限，一旦流量突破这个上限，就会引起实例宕机，进而发生系统雪崩，带来灾难性后果。</p><p>在<a href=\"https://time.geekbang.org/column/article/420777\">第一讲</a>的时候，我有和你提到过流量漏斗的概念，对于秒杀流程来说，从用户开始参与秒杀，到秒杀成功支付完成，实际上经历了很多的系统链路调用，中间有非常庞杂的系统在支撑，比如有商详、风控、登录、限购、购物车以及订单等很多交易系统。</p><p>那么对于秒杀的瞬时流量，如果不加筛选，不做限制，直接把流量传递给下游各个系统，对整个交易系统都是非常大的挑战，也是很大的资源浪费，所以主流的做法是从上游开始，对流量进行逐级限流，分层过滤，优质的有效的流量最终才能参与下单。</p><p><img src=\"https://static001.geekbang.org/resource/image/e8/cd/e8e9d01c9e384c8eb7ee6bc908901dcd.jpg?wh=4247x2227\" alt=\"\"></p><p>这是系统的<strong>流量漏斗示意图</strong>，通过风控和防刷筛选刷子流量，通过限购和预约校验过滤无效流量，通过限流丢弃多余流量，最终秒杀系统给到下游的流量就是非常优质且少量的了。</p><p>限流常用的算法有令牌桶和漏桶，有关这两个算法的专业介绍，你可以参考：<a href=\"https://hansliu.com/posts/2020/11/what-is-token-bucket-and-leaky-bucket-algorithms.html\">https://hansliu.com/posts/2020/11/what-is-token-bucket-and-leaky-bucket-algorithms.html</a></p><p><img src=\"https://static001.geekbang.org/resource/image/fb/69/fb564594bb1bb523dde77b678822c269.jpg?wh=2028x844\" alt=\"\"></p><p>下面我们针对demo-nginx和demo-web两个应用，介绍一下具体的限流方法。</p><h3><strong>demo-nginx网关限流</strong></h3><p>先开始<strong>准备工作</strong>，俗话说，工欲善其事必先利其器，在开发之前，我们先把Nginx的日志给配置起来，方便我们后续开发的调试与验证。</p><p></p><p>Nginx日志配置：Nginx主要有两种类型的日志文件。</p><p>一个是error_log，用来记录我们的系统日志，以及主动打印的业务日志，配置语法为：</p><pre><code class=\"language-sql\">\terror_log &lt;日志文件路径&gt; &lt;日志级别&gt;;\n</code></pre><p>另一个是access_log，这个日志主要用来记录我们的请求和返回相关的信息，配置语法为：</p><pre><code class=\"language-sql\">\taccess_log &lt;日志文件路径&gt; &lt;日志格式定义的名称&gt;;\n</code></pre><p>如果想自定义输出日志格式，需要使用log_format来实现，下面我们就来配置一下这两种日志。</p><p>首先我们在nginx.conf中定义一个名为access的日志格式，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/75/b3/75a292b5508576f439fa7888c2c3e9b3.png?wh=1920x750\" alt=\"图片\"></p><p></p><p>然后在domain.com中配置error_log和access_log，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/12/39/12f71dfa20538527c923591ff6595639.jpg?wh=1920x509\" alt=\"图片\"></p><p></p><p>这里我使用了内置变量以及自定义变量$user_id（通过set_by_lua_block定义并赋值）。现在我们已经把日志配置好了，接下来就开始今天的重头戏吧，就从Nginx限流开始讲起。</p><p>这里的Nginx限流，主要是依赖Nginx自带的限流功能，针对请求的来源IP或者自定义的一个关键参数来做限流，比如用户ID。其配置限流规则的语法为：</p><pre><code class=\"language-sql\">limit_req_zone &lt;变量名&gt; zone=&lt;限流规则名称&gt;:&lt;内存大小&gt; rate=&lt;速率阈值&gt;r/s;\n</code></pre><p>解释一下：</p><ul>\n<li>以上limit_req_zone是关键字，&lt;变量名&gt;是指定根据什么来限流；</li>\n<li>zone是关键字，&lt;限流规则名称&gt;是定义规则名称，后续代码中可以指定使用哪个规则；</li>\n<li>&lt;内存大小&gt;是指声明多大内存来支撑限流的功能；</li>\n<li>rate是关键字，可以指定限流的阈值，单位r/s意为每秒允许通过的请求，这个算法是使用令牌漏桶的思想来实现的。</li>\n</ul><p>那么明白了语法之后，下面我们就<strong>动手定义一个限流规则</strong>，看看实际效果。</p><pre><code class=\"language-plain\">http {\n    limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s; \n    server {\n        location /search/ {\n            limit_req zone=one burst=2 nodelay;\n        }\n    }\n}  \n</code></pre><p>以上是基于IP地址进行限流的例子，你可以根据实际的情况调整rate和burst的值，在秒杀的场景下，一般我们会把rate和burst设置的很低，可以都为1，即要求1个IP1秒内只能访问1次。</p><p>但根据IP地址设置限流时要慎重，会存在误杀的情况，特别像公司内用户，他们的出口IP就那么几个，很容易就触发了限流，所以我一般在参与阿里、苏宁或京东的秒杀活动时，都会切换到4G网络，避免用公司网络。</p><p>除了基于IP限流外，我们还可以设计基于用户的userId进行限流。</p><pre><code class=\"language-plain\">limit_req_zone $user_id zone=limit_by_user:10m rate=1r/s; \n</code></pre><h3><strong>demo-web应用层限流</strong></h3><p>以上是Nginx网关层的限流，接下来我们进入应用层的限流。应用层的限流手段也是比较多的，这里我们重点介绍通过线程池和API限流的方法。</p><p><strong>线程池限流</strong></p><p>Java原生的线程池原理相信你非常清楚，我们可以通过自定义线程池，配置最大连接数，以请求处理队列长度以及拒绝策略等参数来达到限流的目的。当处理队列满，而且最大线程都在处理时，多余的请求就会被拒绝策略丢弃，也就是被限流了。</p><p><img src=\"https://static001.geekbang.org/resource/image/7f/56/7f30154bdbc6d9f085dc92bde0216856.jpg?wh=1385x786\" alt=\"\"></p><p><strong>API限流</strong></p><p>上面介绍的线程池限流可以看做是一种并发数限流，对于并发数限流来说，实际上服务提供的QPS能力是和后端处理的响应时长有关系的，在并发数恒定的情况下，TP99越低，QPS就越高。</p><p>然而大部分情况是，我们希望根据QPS多少来进行限流，这时就不能用线程池策略了。不过，我们可以用Google提供的RateLimiter开源包，自己手写一个基于令牌桶的限流注解和实现，在业务API代码里使用。当然了，大厂中都会有通用的限流机制，你直接用就行了。</p><pre><code class=\"language-plain\">/**\t\n * 自定义注解 &nbsp;限流\t\n */\t\n\n@Target({ElementType.PARAMETER, ElementType.METHOD})\t\n@Retention(RetentionPolicy.RUNTIME)\t\n@Documented\t\npublic @interface MyRateLimit {\t\n &nbsp; &nbsp; String description()&nbsp;default \"\";\t\n}\n</code></pre><p>我们自定义一个切面：</p><pre><code class=\"language-plain\">\n/**\t\n * 限流 AOP\t\n */\t\n\n@Component\t\n@Scope\t\n@Aspect\t\npublic class LimitAspect {\t\n &nbsp; &nbsp;//引用RateLimiter，内部是基于令牌桶实现的\t\n &nbsp; &nbsp;private static RateLimiter rateLimiter = RateLimiter.create(100.0);\t\n\n &nbsp; &nbsp;//定义限流注解的pointcut\t\n &nbsp; &nbsp;@Pointcut(\"@annotation(com.ecommerce.seckill.aop.MyRateLimit)\") &nbsp;\t\n &nbsp; &nbsp;public void MyRateLimitAspect() {\t\n &nbsp; &nbsp;}\t\n\n &nbsp; &nbsp;@Around(\"MyRateLimitAspect()\")\t\n &nbsp; &nbsp;public &nbsp;Object around(ProceedingJoinPoint joinPoint) { \t\n &nbsp; &nbsp; &nbsp; &nbsp;Boolean flag = rateLimiter.tryAcquire();\t\n &nbsp; &nbsp; &nbsp; &nbsp;Object obj = null;\t\n &nbsp; &nbsp; &nbsp; &nbsp;try {\t\n &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;if(flag){\t\n &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;obj = joinPoint.proceed();\t\n &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}\t\n &nbsp; &nbsp; &nbsp; &nbsp;} catch (Throwable e) {\t\n &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;e.printStackTrace();\t\n &nbsp; &nbsp; &nbsp; &nbsp;}\t\n &nbsp; &nbsp; &nbsp; &nbsp;return obj;\t\n &nbsp; &nbsp;}\t\n}\n</code></pre><p>业务层代码实现：</p><pre><code class=\"language-plain\">@Override\t\n@MyRateLimit\t\n@Transactional\t\npublic SeckillResponse initData(String skuId, String userName) {\t\n &nbsp; &nbsp;//此次为业务代码实现\t\n}\n</code></pre><h2>小结</h2><p>这节课我们介绍了削峰的多种手段，有验证码、问答题、消息队列以及限流等。实际上，这些削峰的方式都可以达到控制流量的目的，你可以根据自己的情况进行选择。</p><p>验证码是一种非常常见的防刷手段，大多数网站的登录模块中，为避免被机器人刷，都会加入图片验证码。而在秒杀系统中，我们除了用验证码来防刷外，还有一个目的就是通过验证码进行削峰，达到流量整形的目的。除了图片验证码，你一定也见过短信和语音验证码，那为什么在秒杀系统的削峰中，我们通常会选择图片验证码呢？主要还是出于成本和用户体验的考虑。</p><p>消息队列是常用的应用解耦方式，通过把同步调用改造成异步消息，消费方可以根据自己的能力来处理请求，而不用担心被瞬时流量打垮。当然了，如果库存已经卖完，那么消费方在处理请求的时候，可以快速失败，这样也不用担心消息的长期积压。</p><p>最后，我介绍了几种限流的方式，和其他削峰方式相比，限流是有损的。限流实际上是根据服务自身的容量，无差别地丢弃多余流量，对于被丢弃的流量来说，这块的体验是受损的。另外，因为秒杀流量会经历很多交易系统，所以我们在设计时需要从起始流量开始，分层过滤，逐级限流，这样流量在最后的下单环节就是少量而可控的了。</p><p>另外，在这一节课开始的时候，我有留下一个小伏笔，就是在介绍了各种削峰手段后，互联网大厂在实践中一般都是怎么选择的呢？其实，如果你去体验下像天猫、京东的秒杀，就会发现他们总体是比较类似的，基本不会使用验证码或答题这两种方式，因为对于头部电商平台来说，体验可能不是那么友好。他们比较偏向采用非公平的抢购策略，也就是有损的逐级限流和分层过滤，背后最重要的考虑其实就是兼顾了体验与系统资源。</p><h2>思考题</h2><p>我们在介绍削峰手段的时候，有提到过问答题也是一种削峰方式，但是在这一讲中，因为不常用的关系，我略去了问答题的设计。这里我想请你思考一下，如果让你来设计秒杀的问答题系统，将其作为一种削峰方式，你会怎么设计呢？</p><p>以上就是这节课的全部内容，欢迎你在评论区和我讨论问题，交流经验！</p>","neighbors":{"left":{"article_title":"06｜谋定后动：秒杀的流量管控","id":424215},"right":{"article_title":"加餐｜高并发场景：如何提升对突发事件的应急处理能力？","id":425333}}},{"article_id":425333,"article_title":"加餐｜高并发场景：如何提升对突发事件的应急处理能力？","article_content":"<p>你好，我是胡丽麟，新浪微博的高级架构师，很开心受邀来到志东老师的专栏做一期加餐分享，今天我们来聊一聊高可用高并发服务。</p><p>最开始选择话题的时候，我其实有点迟疑，高可用高并发服务应该当属互联网技术分享的头把交椅了，各家技术争相斗艳层出不穷，包括我们这门课也会有相关设计思路的讲解，所以一番思想斗争之后，我决定和你谈谈自己一路过来的感想，包括我的成长经历以及一些阶段性的思考和沉淀，相信能给你带来启发。</p><p>说起高可用、高并发，我们很容易就联想起分布式、云服务、弹性扩缩容、微服务、缓存架构、业务解耦、异步队列等等，一系列的技术和规范，优秀的架构师往往能设计出一套容易部署、容易扩展、可维护性较好的架构。</p><p>在微博发展的几个阶段里，架构也进行过多次升级，都是为了更好地应对高并发流量，提高服务的稳定性。但即便如此，突发热点还是会让整个系统及技术人员措手不及，那么为什么宣称能支持N个并发热点事件的系统在面对突增流量的时候还是会出现不可用情况呢？</p><p>有很多原因，比如通用架构面临某个单一事件的集中爆发：明星单个人的热点引发资源单点问题；再比如千里之堤上被人忽视的蚁穴：一个已经出问题的服务在热点事件中扩大了影响倍数。这也都是诸多互联网产品所会面临的一些挑战，想要攻克，解决方案一定是多方考量的，比较复杂。所以这节课我们不妨本着收获最大化的原则，从技术人个人层面出发聊聊<strong>如何应对高并发场景中的突发事件</strong>，我想这也是更具普适性的收获。</p><!-- [[[read_end]]] --><h3>高并发的挑战</h3><p>我刚加入微博的时候，恰逢微博快速发展初期，我们时常会遇到各种各样的问题，流量高了、服务不可用了，往往这个时候办公区里就特别沸腾，指点江山、排兵布阵、奋勇杀敌。</p><p>当时作为新生的我很是羡慕，一直觉得很威风。可时间长一点我就发现，这些光环总是在小部分人身上，尽管我们都在同一套高可用高并发的架构体系中进行几乎同样的业务需求开发，但遇到突发状况时能站在前面的都是那一部分人。此后我就开始思考<strong>为什么他们能站在前面，我什么时候也能站到前面？</strong></p><p>所以我就开始观察、取经，慢慢地就发现这些人其实存在共性，他们都拥有良好的应急处理能力，而具备这种能力的人一般都具备这些素质：</p><ul>\n<li><strong>过硬的心理素质。</strong>首先你得能做到不自乱阵脚，从容面对。</li>\n<li><strong>良好的分析问题、解决问题的能力。</strong>除了对本身系统有足够的了解外，他们一般对整个服务的链路、依赖关系、底层原理也都有一定的了解，能敏锐地捕捉到异常信息，抽丝剥茧找出问题根因。</li>\n<li><strong>决策能力。</strong>能对突发问题快速作出决策，降低故障时长、减少影响范围。</li>\n</ul><h3>提升应急处理能力</h3><p>当然了，这些描述更侧重表象，不妨再往深层想一想。评估架构设计能力，我通常会看他们的设计思路和实现技巧，看他们是怎么把复杂的问题梳理清楚，并按照逻辑关系组织编码的。</p><p>总结来看，要想从容应对突发问题，并在更短的时间内做出判断、决策和执行，提高个人的应急处理能力，我认为还得从<strong>细节</strong>和<strong>习惯</strong>做起。</p><ol>\n<li><strong>打破自己的视野局限</strong></li>\n</ol><p>在一些复杂庞大的项目中，同时参与的部门、人数很多，大家协同完成了一件事，身在其中的程序员绝大多数只是负责某一块具体的业务，但我们的视野不应该只停留在自己的代码中，还要把整个调用流程梳理清楚。这里我建议你常去画画调用流程图，我个人比较喜欢画一些泳道图，可以直观地体现各个参与方。</p><p>关注上下游调用的好处就是知道流量从哪里产生，以及上游和下游的服务稳定性情况对整个链路的影响，这都是突发事件时可快速作出判断的必要条件，这里我列举几个比较重要的上下游关注点：</p><ul>\n<li><strong>产品形态。</strong>直接面向用户的产品形态，通过直接的体验知道服务出问题时产品的报错形态。</li>\n<li><strong>调用策略。</strong>上游调用服务时的策略，是否有缓存，超时时间是多少，用户流量传递的比例。</li>\n<li><strong>网络环境。</strong>上游业务的的网络部署结构，是否跟自己的服务有跨机房、跨运营商的网络调用。</li>\n<li><strong>下游服务。</strong>下游业务的响应时间、最大抗压能力等情况，同时需要了解网络部署结构，是否有跨机房、跨运营商网络调用的情况。</li>\n</ul><ol start=\"2\">\n<li><strong>避免浅尝辄止</strong></li>\n</ol><p>我通过简历或者项目接触过不少同学，他们都做过高并发应用，大多数同学都能描述一些缓存系统的设计思路，整体架构大同小异，但当问到比如缓存系统占据了多少内存，命中率剔除率是多少，是怎么去规划端口数量和容量大小时，很多候选人给的回复却是我们有DBA，他帮我们维护，提供了一个API只需要进行服务调用就行。</p><p>但是遇到突发热点事件时，往往会因为连接数过高、带宽跑满、命中率低等问题导致整个系统负载高性能下降，如果平时不怎么关注这些，那么出现问题时我们就很难去想到应对策略，所以要想从容地应对突发事件，我们就需要调整思路、关注细节，比如缓存系统：</p><ul>\n<li><strong>关注缓存需求大小。</strong>使用缓存时知道如何去计算需要多少内存空间，通过存储Value的大小、缓存的时间、活跃用户等计算出缓存的预计大小，避免存储内容增加导致缓存效率降低。</li>\n<li><strong>参与缓存结构部署。</strong>使用新缓存时学会根据存储大小、用户请求QPS、存储时间评估出缓存部署结构，评估出需要几个实例，每个实例多少容量。通过这种方式了解缓存实例的承载上限。</li>\n<li><strong>关注缓存实例运行指标。</strong>容量、剔除率、命中率、链接数、CMD数都是我们日常运行需要关注的指标，提前了解运行指标，可以避免突发性服务崩溃。</li>\n</ul><p>另外，现在很多框架、类库都对行为做了非常好的封装，在日常编码时我们只需要关注接口名和接口参数，这就导致了很多事离开了框架就无法去解释清楚。</p><p>比如我们曾经调用第三方的接口服务报错了，实现调用的代码是使用HttpClient封装好的库，当想快速复现一次HTTP请求时，我们的同学就开始为难了，一方面他没办法在线上跑起来测试程序，另一方面他的测试环境没办法快速运行起整套代码，一个简单的HTTP请求curl命令无法快速构建出来，问题就在于他不知道HttpClient是如何将请求发出去的，也就不知道实际调用API的HTTP请求参数是怎样的，这样遇到突发问题时就没办法从容应对。</p><p>所以平时建议你做到以下两点：</p><ul>\n<li><strong>了解底层封装逻辑。</strong>了解相关类库底层封装逻辑，尤其是底层有许多默认参数配置，最好都去弄懂。</li>\n<li><strong>抛开代码封装的实现</strong>。时刻准备如果没有封装好的代码如何去完成同样的事情，该怎么做，可以借助什么工具。</li>\n</ul><p>以上这是两个很典型的例子，我们在封装精美的框架中进行开发时，美其名曰大家只需要关注自己的代码，写好自己的业务逻辑，无需操心其他，但这给大家带来的问题就是很多事情只知其一不知其二，在突发事件来临时没有足够的信息来辅助分析问题。</p><ol start=\"3\">\n<li><strong>平日积累</strong></li>\n</ol><p>遇到突发事件时所表现出来的从容它不是一朝一夕达成的，它来自对系统、对服务的长期跟踪，来自于了如指掌的自信。</p><p>绝大多数程序员都知道写程序应该记日志加监控，但是又有多少人会定期去看监控，在没有出现问题的时候也保持去观察监控，敏锐地察觉到监控上的一点点异常呢？所以平常的积累很重要，我们可以养成一些好的习惯：</p><ul>\n<li><strong>经常看监控。</strong>并且学会分析趋势，2日线、7日线是比较常关注的点，除了通过监控发现异常外，还要思考监控发现不了什么，然后做进一步的完善。</li>\n<li><strong>熟悉日志。</strong>熟悉记录的每一份日志的作用，了解日志中记录的内容，发现不合理的日志、不完善的日志，让日志真正辅助我们定位问题。</li>\n<li><strong>分析日志。</strong>线上服务尤其是高访问量的服务，日志通常会记录很多，平日查看日志的时候就不能只看单条日志，要学会基于大量的日志去分析问题。从几万条，甚至几十万条的日志中找出规律。</li>\n</ul><p>有了一些好习惯的积累，遇到突发事件时我们才能有条不紊地找到着手点，不至于慌慌张张不知道从哪里入手。</p><ol start=\"4\">\n<li><strong>一套称手的工具</strong></li>\n</ol><p>对突发事件的处理讲究的就是效率，越早定位、越早解决，影响就越小，快速解决除了前面提到的积累、习惯外，还要有一套称手的工具。</p><ul>\n<li><strong>日志分析工具</strong>。通过分析日志来定位原因是最常用到的方法，查找某一条具体的日志是最简单的，但如果需要通过日志来分析异常流量、归纳错误就涉及到大量日志的分析了。如何在面对上万条、几十万条甚至更多日志的时候不慌，那就需要考虑日志分析方法了，常用的有awk、sed、sort、uniq等工具，熟练使用会事半功倍。</li>\n<li><strong>抓包分析工具</strong>。网络抓包也是一个很常用的手段，分析流量从哪里来的、请求去了哪里，这时类似Wireshark、tcpdump等工具就派上用场了，能帮助你快速找到源头。</li>\n<li><strong>系统工具。</strong>在Linux系统里，有很多关于系统层面的命令，查看系统负载、网络带宽、磁盘IO等等，这种对于找到单机系统瓶颈很关键。</li>\n<li><strong>业务工具。</strong>业务工具有点像测试用例，一段独立的代码能帮助你快速判断代码运行结果，不少同学一定经历过遇到一个问题时需要临时去写一个脚本的状况。这种工具一般遇到问题写一个，时间长了对于快速验证是非常有帮助的。</li>\n</ul><h3>成长平台</h3><p>以上就是我从个人层面出发，总结出的可以快速提升应急处理能力的法门。那么从长远角度来看，我们还可以做哪些事情助力自身进阶呢？</p><ol>\n<li><strong>认清平台局限性</strong></li>\n</ol><p>有些同学一毕业就去了大厂，有经验丰富的leader带，有平台的大规模用户，有高并发的流量，在这种背景下会有更多机会去进行技术验证，对于个人技术成长确实有很大的帮助。但是大厂我们也经常说面试的时候造火箭，实际干的是拧螺丝的活。大厂的项目很大，人员很多，所以职能划分就很细，每个人只需要关注自己的业务就能让大厂这艘船跑的很好，但如果突破不了自己，可能真就只是干拧螺丝的活。</p><p>也有同学毕业去了小厂，然后就会面临身兼数职，练就了八般武艺，但这往往就会陷入多数技术浅尝辄止、学而不精的情况，这种时候就更需要沉下心来深入学习。</p><p>可无论身在大厂还是小厂，都不要忽视习惯的养成，关心细节的习惯、关心全局的习惯、深入了解的习惯。</p><ol start=\"2\">\n<li><strong>清楚架构局限性</strong></li>\n</ol><p>架构不是万能的，有些架构适合做业务扩展，有些架构适合高并发流量，日常开发的时候要根据业务的特性去选择架构，同时需要分析了解每一种架构的优缺点。</p><p>举个例子，我在微博参与的其中一个业务，初期的架构可以简单地称之为同步架构，遇到热点事件的时候会出现接口性能急剧下降的问题，它的瓶颈点在于同步处理耗时太多，开发的时候就需要注意服务调用策略，比如设置超时时间、自动降级等等。突发应急的时候需要快速找出同步中出问题的点，及时摘掉。</p><p>后来流量不断创新高，这个架构就有点力不从心了，所以就改成了异步架构。新架构上线后抗住了流量新高，但流量继续涨的时候还是出了问题，因为异步处理导致很多资源重复读写，无形中增加了资源的压力，资源就成为了系统瓶颈，这个时候开发的关注点就变成了如何复用资源、如何提高资源的抗压能力，应急突发时就变成了资源扩容、替换等。</p><p>这里我想告诉你的就是，不要迷恋架构，每一个架构都有其适用性，在平日要多了解架构的优缺点，遇到突发情况时才能迅速找出痛点、作出决策、解决问题。</p><h3>结语</h3><p>在我们的工作乃至面试中，聊的最多的可能就是算法、数据结构、设计模式了，然后也会聊一些架构设计思路，比如如何保证高并发，如何保证低处理时间，如何满足很好的扩展性等等。但我在这节课里避开了这些问题，因为在服务流量一直很稳定的情况下，大概率是不会出问题的，这个只是考验系统的架构设计。</p><p>但通常在高并发服务里最常见的或者最怕见到的就是突发热点、突增流量，像微博这种系统就是经受着一次又一次的热点冲击，那么这个时候考验的就是人，快速应对、快速处理。在这一轮又一轮的冲击中，成长的除了你的架构设计能力，还有应急处理能力，从容地应对突发问题来自于脚踏实地的积累。只有夯实了自己的基础，拥有清晰的思路去分析问题，我们才能更容易地抓住问题的重点，作出相应的决策，不慌不忙从容应对。</p><p>期待你也能在诸多的问题中找到自己的应对之法！</p>","neighbors":{"left":{"article_title":"07｜乾坤大挪移：秒杀的削峰和限流","id":424503},"right":{"article_title":"08｜化骨绵掌：降级、热点和容灾处理","id":426067}}},{"article_id":426067,"article_title":"08｜化骨绵掌：降级、热点和容灾处理","article_content":"<p>你好，我是志东，欢迎和我一起从零打造秒杀系统。</p><p>上节课我们介绍了秒杀的削峰，你在手写秒杀系统的时候，可以采用验证码/问答题、异步消息队列或者限流的方式进行削峰，以此平滑流量峰值，减轻单位时间分片内的系统压力。这节课我们将把重点放在其他高可用的方面——降级、热点数据和容灾，<strong>持续打造秒杀系统的高可用</strong>。</p><p>当秒杀活动开启，流量洪峰来临时，交易系统压力陡增，具体表现一般会包括CPU升高，IO等待变长，请求响应时间TP99指标变差，整个系统变得越来越不稳定。为了力保核心交易流程，我们需要对非核心的一些服务进行降级，减轻系统负担，这种降级一般是有损的，属于“弃卒保帅”。</p><p>而秒杀的核心问题，是要解决单个商品的高并发读和高并发写的问题，这是典型的热点数据问题，我们需要有相应的机制，避免热点数据打垮系统。</p><p><strong>机房容灾其实不仅仅是秒杀系统需要思考的</strong>，重要的软件系统，不管是互联网应用，还是传统应用，比如银行系统等，都需要考虑机房容灾的问题。不同的场景，容灾的设计也不尽相同，这节课我们将从常见的互联网公司的角度，看看他们一般会怎么搭建交易系统的容灾。</p><h2>降级</h2><p>我们先说说“降级”，其实和削峰一样，降级解决的也是有限的机器资源和超大的流量需求之间的矛盾。如果你的资源够多，或者你的流量不够大，就不需要对系统进行降级了；只有当资源和流量的矛盾突出时，我们才需要考虑系统的降级。</p><!-- [[[read_end]]] --><p>前面已经介绍了，降级一般是有损的，那么必然要有所牺牲，下面介绍几种常见的降级：</p><ul>\n<li>写服务降级，牺牲数据一致性获取更高的性能；</li>\n<li>读服务降级，故障场景下紧急降级快速止损；</li>\n<li>简化系统功能，干掉一些不必要的流程，舍弃非核心功能。</li>\n</ul><p>下面我们逐一分析下。</p><p><strong>1. 写服务降级，牺牲数据一致性获取更高的性能</strong></p><p>我们知道，在多数据源（MySQL和Redis）的场景下，数据一致性一般是很难保证的。除非你引入分布式事务，但分布式事务也会带来一些缺点，比如实现复杂、性能问题、可靠性问题等。因此一般在涉及金融资产类对一致性要求高的场景时，我们才会考虑分布式事务。</p><p>在流量不高的时候，我们的写请求可以直接先落入MySQL数据库，再通过监听数据库的Binlog变化，把数据更新进Redis缓存，如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/b7/f2/b7551fa007c9bd02cba5fe63c665a7f2.jpg?wh=1200x600\" alt=\"\"></p><p>这种设计，缓存和数据库是最终一致的。通过缓存，我们可以扛更高流量的读操作，但是写操作仍然受制于数据库的磁盘IOPS，一般考虑一个数据库也就能支持 3000～5000&nbsp;TPS的写操作。</p><p>当流量激增的时候，我们就需要对以上的写路径进行降级，由同步写数据库降级成同步写缓存、异步写数据库，利用Redis强大的OPS来扛流量，一般单个Redis分片可达8～10万的OPS，Redis集群的OPS就更高了。</p><p>如下图所示，写请求首先直接写入Redis缓存，写入成功之后，同时再启动一个线程，发出写操作MQ，就可以返回客户端了。其他应用消费MQ，通过MQ异步化写数据库。</p><p><img src=\"https://static001.geekbang.org/resource/image/8a/49/8a036583d50024606372f1c1d5930c49.jpg?wh=1200x600\" alt=\"\"></p><p>这里，我们通过Redis的高并发写能力，提升了系统性能，带来的牺牲就是缓存数据和数据库数据的一致性问题。为了追求高性能，牺牲一致性在大厂的设计中比较常见，对于异步造成的数据丢失等一致性问题，一般会有定时任务一直在比对，以便最快发现问题，进行修复。</p><p><strong>2.读服务降级，故障场景下紧急降级快速止损</strong></p><p>在做高可用系统设计时，我们都会有个共识，就是微服务自身所依赖的外部中间件服务或者其他RPC服务，随时都可能发生故障，因此我们需要建设多级缓存，以便故障时能及时降级止损。</p><p>如下图所示，我们给Redis缓存之外，又增加了ES缓存。当然了，你可以建立多个缓存副本，比如主Redis缓存外，再建立副Redis缓存，或者再增加ES缓存，这些都可以的，不过相应会增加你的资源成本和代码编写的复杂度。</p><p><img src=\"https://static001.geekbang.org/resource/image/bc/5f/bc636e43feaf3d44c0364b4b4878455f.jpg?wh=1200x600\" alt=\"\"></p><p>如上图，假设当秒杀的Redis缓存出现故障时，我们就可以通过降级开关，快速将读请求降级到ES上。或者当Redis和ES同时出现故障时（现实中很少出现同时故障的场景），我们还是可以通过降级开关将流量切换到数据库上，让数据库暂时承压来完成读请求服务。</p><p>由此可见，在做高可用系统设计时，降级路径是多么的重要，它会是你关键时候的保命开关，让你在突发故障时有路可退。</p><p><strong>3. 简化系统功能，干掉一些不必要的流程，舍弃非核心功能</strong></p><p>当你打开京东或淘宝的商品详情页时，你会发现，除了商品的基本信息外，还有很多附加的信息，比如你是否收藏过该商品、商品的收藏总数量、商品的排行榜、评价和推荐等楼层。同样，对于秒杀结算页，还会有礼品卡、优惠券等虚拟支付路径。</p><p>如果是普通商品，这些附加信息当然是越多越好，一方面体现了系统的完整性，另一方面也可以多渠道引流促进转化。但是在秒杀场景下，这些信息是否有必要就需要视情况而定了，秒杀系统要求尽量简单，交互越少，数据越小，链路越短，离用户越近，响应就越快，因此非核心的功能在秒杀场景下都是可以降级的，如下图红框所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/23/ee/23acce5a60a381c535d93d1d5a489aee.png?wh=1562x754\" alt=\"图片\"></p><p>这种非核心功能的有损降级，要视具体的SKU而定，一般为了降低影响范围，我们只对流量非常高的SKU进行降级。比如，如果是手机秒杀，一般是不需要降级的，但是像茅台、口罩这样的爆品，就需要针对SKU维度进行非核心功能的降级了。</p><p>以上就是几个典型的降级场景了，简单总结一下。这3种降级场景在秒杀系统建设中都会用到。首先，非核心链路的降级在爆品的SKU上经常用到，你可以收藏一下京东的平价茅台商品，然后进入商详页看下是否有收藏功能，就会发现一直是处于降级的状态；非核心链路的降级在大促时也经常用，一般在快接近0点前的5分钟，全系统就会启动很多非核心功能的降级，以确保有限的机器资源用在更核心的场景。故障场景的读服务降级也是常用的高可用手段，通过一键降级开关我们可以灵活的在不同链路间进行切换，提供灵活的服务能力，应对可能突发的故障。为了追求高性能，秒杀也会牺牲一致性对写服务进行降级。</p><p>这里我们顺便也看下<strong>降级开关的设计</strong>，比较简单，核心思路就是通过配置中心，对降级开关进行变更，然后推送到各个微服务实例上。</p><p><img src=\"https://static001.geekbang.org/resource/image/c3/33/c3efa7e5f5c4a90791dfe492yyc0b433.jpg?wh=1200x600\" alt=\"\"></p><h2>热点数据</h2><p>讲完了降级，接下来我们来聊聊热点数据。进入正题前，我们先看看高并发的常规解决思路。</p><p>分布式系统设计，解决高并发问题，可能你很快会想到，如果是数据库，可以通过分库分表来应对，如果是Redis，可以增加Redis集群的分片来解决，而应用层一般是无状态的设计。所以从数据库、Redis缓存到应用服务，都是可以通过增加机器来水平扩展服务能力，解决高并发的问题。</p><p>然而，这样就能应对秒杀的挑战了吗？其实还不够，前面我有提到，秒杀的核心问题是要<strong>解决单个商品的高并发读和高并发写问题，也就是要处理好热点数据问题。</strong></p><p>所谓热点数据，是从单个数据被访问的频次角度去看的。单位时间（1s）内，一个数据非常频繁的被访问，就可以称之为热点数据，反之可以归为一般数据或冷数据。那么单位时间内究竟多高的频次才能称为热点数据呢？实际上并没有一个明确的定义，可以根据你自己的系统吞吐能力而定。</p><p>平价茅台在进行秒杀时，只有这个SKU是热点，所以再怎么进行分库分表，或者增加Redis集群的分片数，茅台SKU落在的那个分片的能力实际并没有提升，总会触达上限，把Redis打挂，最后可能引发缓存击穿、系统雪崩。那我们应该怎么解决这个棘手的热点问题呢？别担心，难不倒我们，请跟我继续往下学习。</p><p><strong>我们把这个问题分为两类：读热点问题和写热点问题。</strong>下面我们分别展开讨论。</p><p>先看下<strong>读热点</strong>如何解决，我先抛出解决该问题的思路：</p><ol>\n<li>增加热点数据的副本数；</li>\n<li>让热点数据离用户越近越好。</li>\n</ol><p><img src=\"https://static001.geekbang.org/resource/image/0f/f7/0fdee3bf8ecf1706cd5d51a4033c27f7.jpg?wh=1261x1441\" alt=\"\"></p><p>以上是秒杀系统的部署结构图，参照解决思路，我们的第一个解决方案，就是<strong>增加Redis从的副本数</strong>，然后业务层（Tomcat集群）轮询查询不同的副本，提高同一数据的QPS。一般情况下，单个Redis从，可提供8~10万的查询，所以如果我们增加12个副本，就可以提供百万QPS的热点查询。</p><p><img src=\"https://static001.geekbang.org/resource/image/d6/a3/d6952799be5641c2212108f82263e3a3.jpg?wh=1001x678\" alt=\"\"></p><p>这个方法能解决热点问题，但成本比较高，如果你的集群分片数比较多，那分片数*副本数就是一笔不小的开销。</p><p>第二个解决方案，我们<strong>把热点数据再上移</strong>，在Tomcat集群做热点数据的本地缓存，也就是让业务层的每个实例里都有份数据副本，读请求数据的时候，无需去Redis获取，直接从本地缓存里取。这时候，数据的副本数和Tomcat实例一样多，另外请求链路减少了一层，而且也减少了对Redis单片QPS上限的依赖，具有更高的可靠性和更高的性能。</p><p><img src=\"https://static001.geekbang.org/resource/image/5a/e4/5a4bcd3ab9dcaaa8d3f13b07aed369e4.jpg?wh=1001x678\" alt=\"\"></p><p>这种方式热点数据的副本数随实例的增加而增加，非常容易扩展，扛高流量。不过你要思考一个问题，本地缓存的数据延迟业务是否能够接受？</p><p>如果能接受，本地缓存的时候可以设置几分钟？如果对延迟要求比较高，可以设置1s，这样对Redis而言，OPS的压力直接降低到实例数/每秒，就不需要那么多副本了。</p><p>本地缓存的实现比较简单，可以用HashMap、Ehcache，或者Google提供的Guava组件。</p><p>读热点还有一个比较简单粗暴的方法，那就是直接短路返回。这么说可能比较抽象，我举个例子，茅台秒杀的时候，这个SKU是不支持使用优惠券的，那么优惠券系统在处理的时候，可以根据配置中心的茅台SKU编码，直接返回空的券列表，这样基本上不怎么耗资源，效率非常高。当然了，这种方式和具体商品的活动方式有关，不具有通用性，但是在几百万的流量面前，简单有效。</p><p>介绍完读热点，接下来我们看<strong>写热点</strong>问题。我们先回忆一下，在<a href=\"https://time.geekbang.org/column/article/424215\">第6讲</a>流量管控里，我们介绍到用户点击“立即预约”的时候，会往“预约人数”这个Redis key上进行++操作，当几百万人同时预约的时候，这个key就是热点写操作了。</p><p>这个预约总人数有个特点，只是在前端给用户展示用，除此之外，没有其他用途，因此在高并发的场景下，这个人数可以不用那么及时和精确。知道了问题所在，解决方案就在眼前了，我们的思路就是先在JVM内存里++，延迟提交到Redis，这样就可以把Redis的OPS降低几十倍。以下是示意图：</p><p><img src=\"https://static001.geekbang.org/resource/image/a5/ba/a52768c760c1880dc5240660e37013ba.jpg?wh=1024x1140\" alt=\"\"></p><p>写热点还有一个场景就是库存的扣减，这里讲一下基本思路，<strong>可以通过把一个热key拆解成多个key的方式，避免热点问题</strong>。这种设计涉及到对库存进行再细分，以及子库存挪动，非常复杂，而且边界问题比较多，容易出现少卖或者超卖问题，一般不推荐这种方法。</p><p>另一个思路就是对单SKU的库存直接在Redis单分片上进行扣减，实际上，库存系统在秒杀链路的末端，通过我们之前介绍的削峰和限流，真正到库存的流量是有限的，单片的Redis OPS能承受得了。然后，我们可以针对单SKU的库存扣减进行限流，保证库存单片Redis的压力。这样双管齐下，单SKU的库存Redis扣减压力就是可控的了。</p><h2>容灾</h2><p>最后我们一起看下容灾，容灾不仅仅是秒杀系统需要考虑的，但凡重要的系统，都要在方案设计时考虑容灾问题。容灾，一般是指搭建多套（两套或以上）相同的系统，当其中一个系统出现故障时，其他系统能快速进行接管，从而持续提供7*24不间断业务。</p><p>在讨论容灾的时候，你可能听说过“同城双活”“异地多活”等术语，它们都是不同的容灾方案，不同的方案，其技术要求、建设成本、运维成本都不一样。在多活架构下，对两套系统之间通信线路质量、时延要求很高，业内主流IT厂家比较认可的是单向时延2ms以内，超过这个时延，对“多活”的跨机房请求和数据同步的性能影响就会比较大。</p><p>因此，涉及跨城市的多活，当城市距离较大时，比如上海和北京，那么这种物理上的时延很难克服。为了保证数据库的一致性，就需要付出很高的时间成本，往返几个来回时延叠加，RT就受不了了。所以，如果是异地多活的情况，一般是需要把数据划分成不同单元，让流量在单元内闭环。异地多活单元化的设计其实非常复杂，成本高昂，即便是大厂也不一定能搭建好异地多活。</p><p><strong>因此，这节课我们的重点还是放在“同城双活”的设计上。</strong></p><p>同城双活是在同城或相近区域内建立两个机房。同城双机房距离比较近，通信线路质量较好，比较容易实现数据的同步复制，保证高度的数据完整性和数据零丢失。</p><p>同城两个机房各承担一部分流量，一般入口流量完全随机，内部RPC调用尽量通过就近路由闭环在同机房，相当于两个机房镜像部署了两个独立集群，数据仍然是单点写到主机房数据库，然后实时同步到另外一个机房。</p><p><img src=\"https://static001.geekbang.org/resource/image/7b/c2/7b31b36b54824fefb9457b8b93b152c2.jpg?wh=2024x1156\" alt=\"\"></p><p>如上图所示，就是秒杀系统的“同城双活”方案。从Nginx层、Tomcat层，到Redis、MySQL层，我们都做了双中心部署，不管哪一层出现故障，都可以灵活切换。</p><p>同城双活因为物理距离短，机房间的时延是有保证的，我们可以让写流量最后落库的时候都写到主机房，而读流量则完全可以做到机房内闭环。当然了，我们在做系统设计的时候，也是要尽量避免C端流量直接打到数据库，因此，这种跨机房的写流量都是比较可控的。</p><p>简单提示一下，双机房间的物理专线也必须是高可用的设计，至少需要两根以上进行互备，这样在专线故障时才有机会绕行避免不可用，这些在大厂里一般是运维团队在保障，业务团队了解实现原理就可以。</p><h2>小结</h2><p>这节课我们主要讨论了秒杀的降级策略，热点数据的处理方式以及“同城双活”的容灾方案。</p><p>降级是系统故障发生时你的逃生路径，你一定要有这个认知。系统故障不可避免，随时都可能发生，所以在做系统设计时一定要给自己预留逃生通道，不能在系统故障时让用户只能干等着故障恢复。</p><p>所以降级的设计非常重要，这一节课里，我们介绍了几种常见的降级场景和解决方法，有同步写库降级为异步写库，其实也可以反过来，从异步写库降级为同步写库，取决于你追求的是性能还是一致性；我们还介绍了通过搭建多级缓存，在一级缓存故障时就可以降级到二级缓存；最后我们还介绍了业务功能降级，舍弃非核心功能，力保主流程功能正常运转。</p><p>当我们有了降级手段后，日常就要经常演练了，避免线上真的发生故障时茫然失措。</p><p>接着我们还介绍了秒杀的热点数据处理，热点数据是秒杀系统的基本属性，必须面对。读热点问题的解决遵循朴素的思路，通过增加数据副本数来扛流量，同时尽量让数据靠近用户。这节课我们更多着墨在动态热点数据上，通过搭建Redis多从副本以及JVM本地缓存，能解决大部分的读热点问题；而对于静态数据的处理，可以通过CDN缓存、浏览器缓存来应对，我将在系统优化章节详细介绍CDN缓存。</p><p>写热点的思路就比较简单了，我们共介绍了3种方法。一是本地缓存，延迟提交；二是将写热点数据进行分片，我们在处理大key时也经常用分片的思路；三是单SKU限流，保护单分片的Redis操作。</p><p>最后一部分我们介绍了系统容灾，容灾是解决系统级故障的手段，这是个比较大的话题，一般在互联网大厂中会有运维和架构组织统一设计方案，而不同公司选择的方案和路径不同，要结合你所在公司的具体情况而定。</p><p>需要特别注意的是，机房物理距离的问题，对你的方案设计至关重要，本质上难点就是数据的复制和一致性问题。这节课我们重点学习了“同城双活”的设计思路，通过秒杀系统的同城双活设计，你可以看到，不管是Nginx集群、Tomcat集群、Redis集群，还是MySQL集群，我们都可以灵活进行机房间切换，在故障时快速恢复。</p><h2>思考题</h2><p>这节课我们探讨了热点数据以及热点数据的几种处理方法，这里请你思考下，我们怎么能主动发现热点数据并进行预警呢？该如何设计？</p><p>以上就是这节课的全部内容，欢迎你在评论区和我讨论问题，交流经验！</p>","neighbors":{"left":{"article_title":"加餐｜高并发场景：如何提升对突发事件的应急处理能力？","id":425333},"right":{"article_title":"09｜御敌国门外：黑产对抗——防刷和风控","id":426696}}},{"article_id":426696,"article_title":"09｜御敌国门外：黑产对抗——防刷和风控","article_content":"<p>你好，我是志东，欢迎和我一起从零打造秒杀系统。</p><p>经过前面对秒杀业务的介绍，你现在应该清楚，秒杀系统之所以流量高，主要是因为一般使用秒杀系统做活动的商品，基本都是稀缺商品。稀缺商品意味着在市场上具有较高的流通价值，那么它的这一特点，必定会引来一群“聪明”的用户，为了利益最大化，通过非正常手段来抢购商品，这种行为群体我们称之为黑产用户。</p><p></p><p>他们确实是聪明的，因为他们总能想出五花八门的抢购方式，有借助物理工具，像“金手指”这种帮忙点击手机抢购按钮的；有通过第三方软件，按时准点帮忙触发App内的抢购按钮的；还有的是通过抓取并分析抢购的相关接口，然后自己通过程序来模拟抢购过程的。</p><p>可不管是哪种方式，其实都在做一件事，那就是<strong>先你一步</strong>。因为秒杀的抢购原则无外乎两种，要么是绝对公平的，即先到的请求先处理，暂时处理不了的，会把你放入到一个等待队列，然后慢慢处理。要么是非公平的，暂时处理不完的请求会立即拒绝，让你回到开始的地方，和大家一起再比谁先到，如此往复，直至商品售完。</p><p>因此黑产的方法也很简单，就是想法设法比别人快，发出的请求比别人多，就像在一个赛道上，给自己制造很多的分身，不仅保证自己比别人快，同时还要把别人挤出赛道，确保自己能够到达终点。</p><!-- [[[read_end]]] --><p>所以黑产对秒杀业务的威胁是巨大的，它不仅破坏了公平的抢购环境，而且给秒杀系统带来了庞大的性能开销，所以我们不能放任黑产流量对系统的肆意冲击，我们必须对抗它。既然黑产流量的特点是比正常流量快且频率高，那么我们也就可以从这两个方面来着手思考对策。</p><p>只针对第一个快的特点，其实在活动开始后，进来的流量我们都无法将其定义为非法流量，这个只能借助像风控这种多维度校验，才能将其识别出来，除非它跳步骤。而第二个高频率的特点，同时也是对秒杀系统造成危害最大的一种，我们还是有很多种手段来应对的。所以这节课我就给你介绍几种比较有效且经过实践的防刷方案，它们<strong>专门针对高频率以及跳步奏的非法手段</strong>。</p><h2>防刷：Nginx有条件限流</h2><p>在上节课中我已经介绍过Nginx限流的语法了，现在咱们就直接来实践。这里呢，我们是根据用户ID来做限流防刷的。</p><p></p><p>首先我们新建一个通用配置文件common.conf，用来定义限流规则以及后续一些其他的通用配置，所在位置如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/de/79/de62316555d371852a5b3dd6899c4c79.png?wh=1722x1512\" alt=\"图片\"></p><p>同时，不要忘记在nginx.conf文件中将该配置文件引入进去，和引入upstream.conf一样，如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/28/65/28d8044ef9bd4d5bdf155774824b5e65.png?wh=1920x799\" alt=\"图片\"></p><p>然后，我们在common.conf中定义限流规则如下：</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/a0/99/a09ec76448014de730b6c26c9e776a99.png?wh=1920x337\" alt=\"图片\"></p><p>意为定义了一个名为 limit_by_user的限流规则，根据用户ID来做限流，限流的速率为同一个用户1秒内只允许1个请求通过，且为该规则申请的内存大小为10M。</p><p>这里的10M大概是什么概念呢？可以简单粗略地算下，假如一个user_id占用的内存大小为16字节，那么10M的内存大概可以处理单机 10*1024*1024/16=655360个请求。</p><p>规则配置完毕后，接下来就在我们需要限流的接口引用该规则，这里依然以活动查询接口为例，配置如下：</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/c5/fa/c5fb44759735fe82a9691b7f7ee830fa.png?wh=1920x984\" alt=\"图片\"></p><p>其中nodelay是被限流后的策略，意为不等待，直接返回。</p><p>配置好之后，我们启动Nginx，通过URL进入到商详页（要在活动进行中时）。</p><p><img src=\"https://static001.geekbang.org/resource/image/0c/34/0ca228e08dce27d3ba9654410fd46134.png?wh=1920x1655\" alt=\"图片\"></p><p>这时，我们通过鼠标快速地刷新两次页面（点击浏览器中的刷新图标，在1秒内完成），来模拟外部的请求，然后看下对应的access和error日志，结果如下：</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/a5/a7/a59a1f7160c60ccc00aaac45523790a7.png?wh=1920x307\" alt=\"图片\"></p><p><img src=\"https://static001.geekbang.org/resource/image/eb/da/eb25a30c92d99d295b1a7232a14cfdda.png?wh=1920x302\" alt=\"图片\"></p><p>通过domain-access.log日志可以看到，两次请求，第一次正常返回，第二次返回给客户端503的状态码，原因通过domain-error.log可以看到，是触发了根据用户ID的限流规则，这样我们的限流防刷功能就实现了。</p><p></p><p>以上通过限流的方式来防刷，是非常简单且直接的一种方式，<strong>这种方式可以有效解决黑产流量对单个接口的高频请求</strong>，但要想防止刷子不经过前置流程直接提单，还需要引入一个流程编排的Token机制。</p><p></p><h2>防刷：Token机制</h2><p>Token我想你是知道的，一般都是用来做鉴权的。放到秒杀的业务场景就是，对于有先后顺序的接口调用，我们要求进入下个接口之前，要在上个接口获得令牌，不然就认定为非法请求。同时这种方式也可以防止多端操作对数据的篡改，如果我们在Nginx层做Token的生成与校验，可以做到对业务流程主数据的无侵入。</p><p>在Token机制下，前端与demo-nginx中的接口交互时序图如下所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/a6/4d/a6b84a677fe6d411319becd71a5d6e4d.jpg?wh=1710x1083\" alt=\"图片\"></p><p>现在我们就按照对应的时序，依次给4个接口增加上Token相关的生成与校验功能。</p><p>在这之前，我们为了更真实地获取用户ID，需要在demo-web中新增加个登录功能，模拟将user_id放到cookie，这样之后的每次请求，我们就直接从cookie中获取user_id即可。</p><p>同时根据我们的设计，有几个主要参数是每次接口请求都必须要校验的，那就是用户ID、产品编号，还有新的Token，所以我们就定义了一个统一的解析方法，其中用户ID从cookie中解析，产品编号和st从请求的URL中解析，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/7f/9f/7f90b174bf698a7c9561a4eb9bfc059f.png?wh=1920x652\" alt=\"图片\"></p><p>set_common_var.lua主要就是负责参数的解析，并给对应的变量做赋值，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/fa/81/fa2dedd40b8c881ebfe0e5ddaff04781.png?wh=1920x907\" alt=\"图片\"></p><p></p><p>做完之后，我们开始改造活动数据查询接口，改造后如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/be/bd/bef17a652c670eacfe5e53940bee08bd.png?wh=1920x1170\" alt=\"图片\"></p><p>这里通过header_filter_by_lua_block指令，在返回的header里增加流程Token。这里st的生成只是简单地将用户ID+步骤编号做了MD5，生产上需要更严格一些，需要加入商品编号、活动开始时间、自定义加密key等，这样前端通过解析请求响应header，就可以拿到st了，然后将其拼在请求结算页H5的URL后即可。</p><p>然后再对结算页H5的location做改造，改造后如下图所示（当然这里可以将rewrite_by_lua的内容放到file，看起来会更整洁一些）：</p><p><img src=\"https://static001.geekbang.org/resource/image/af/c0/af04f483483a6a5d1d93ed4810c052c0.png?wh=1920x1225\" alt=\"图片\"></p><p>结算页H5的改造点，就是将之前的一个location拆成了2个了，增加了/settlement/prePage，这样点击立即抢购时就可以直接调用这个接口。</p><p>这里你可能会有疑问，<strong>这里为什么没有选择将st放在header中返回呢？</strong>因为和活动数据查询接口不同的是，这个接口返回的是HTML，上个接口返回的是JSON，所以选择了重定向的方式，这样浏览器就可以获得到新的st了，具体代码如上，在rewrite_by_lua_block配置中使用ngx.redirect()方法来实现重定向。</p><p></p><p>同时这里再给你介绍下，如果业务校验不通过，想终止整个请求流程，可以通过ngx.exit（状态码）来实现，这样就可以将对应状态码返回给前端了。但如果想要做得更友好些，当系统内部异常或者是后端服务器异常时，我们可以指定返回的内容。这就需要通过error_page指令来实现，意为出现不同的错误码，我们会转到不同的location去做处理。如果是H5请求，那就返回对应的错误提示页，如果是JSON请求，也可以返回自定义的JSON数据，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/5b/12/5b355812fda489dddd72c8d79206f612.png?wh=1920x614\" alt=\"图片\"></p><p>上图就是配置了两个异常处理location，其中html_fail.html的位置和内容如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/aa/52/aaab5c80b3eb5a8ac0dc4e1404860752.png?wh=1920x661\" alt=\"图片\"></p><p></p><p>那么做完了上面那么多工作，现在我们就来验证下针对活动数据查询接口和结算页H5接口的顺序编排是否生效。</p><p>我们启动Nginx，并且进入到商详页，点击立即抢购，正常流程是可以进入到结算页的，这里就不展示了，那如果我们不经过商详页，直接通过URL访问结算页H5接口（不带st或者带错误的st），效果会如何呢？看下图：</p><p><img src=\"https://static001.geekbang.org/resource/image/b0/7a/b07e6bc5c350c28bf7d81ba44e59e97a.png?wh=1519x1487\" alt=\"图片\"></p><p>出现了我们配置的错误提示页，同时日志中出现了st校验不通过的提示：</p><p><img src=\"https://static001.geekbang.org/resource/image/b8/78/b85b9ba8b675fb63bc64e51d27148578.png?wh=1920x394\" alt=\"图片\"></p><p>那么使用同样的机制，我们可以把剩下的接口功能给补上，因为做法一样，这里就不多说了，直接上最终改造后的代码，如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/2f/60/2fe31a8064e6ba9ab3702cfaab9e6860.png?wh=1824x1483\" alt=\"图片\"></p><p>到这，防刷的Token机制就介绍完了，<strong>这种机制可以有效防止黑产流量跳过中间接口，直接调用下单接口</strong>。通过该机制+Nginx有条件限流机制，可以有效拦截大部分场景下的刷子流量。但如果我们还想再严格一些，对于黑产不仅仅是想拦截过多的非法请求，而是想全部拦截，那有没有什么办法呢？有，咱们继续学习下黑名单机制。</p><p></p><h2>防刷：黑名单机制</h2><p>黑名单机制分为本地黑名单和集群黑名单两种，接下来我们会重点介绍本地黑名单。该机制顾名思义，就是通过黑名单的方式来拦截非法请求的，但我们的核心问题是黑名单从哪里来呢？</p><p>总体来说，有两个来源：一个是从外部导入，可以是风控，也可以是别的渠道；而另一个就是自力更生，自己生成自己用。</p><p>前面介绍了Nginx有条件限流会过滤掉超过阈值的流量，但不能完全拦截，所以索性就不限流，直接全部放进来。然后我们自己实现一套“逮捕机制”，即利用Lua的共享缓存功能，去统计1秒内这个用户或者IP的请求频率，如果达到了我们设定的阈值，我们就认定其为黑产，然后将其放入到本地缓存黑名单。黑名单可以被所有接口共享，这样用户一旦被认定为黑产，其针对所有接口的请求，都将直接被全部拦截，实现刷子流量的0通过。</p><p><strong>这里以提单做逮捕入口示例，大致流程如下：</strong></p><p><img src=\"https://static001.geekbang.org/resource/image/cc/e5/cc6f4yy4b5d3bdda647013ef5c1373e5.jpg?wh=1756x1224\" alt=\"图片\"></p><p>其中红线表示黑名单的校验与生成路径，蓝线表示普通接口的黑名单校验路径。那么下面我们就根据这个设计思路，去具体实现它。</p><p>首先新建两个Lua文件，一个叫submit_access.lua，另一个叫black_user_cache.lua。然后修改提单接口的access_by_lua_*指令，将其替换成access_by_lua_file，并引用submit_access.lua，如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/3a/ef/3aaf11580b694beaf485363f7ce3ecef.png?wh=1920x488\" alt=\"图片\"></p><p>其中black_user_cache.lua主要用来写和黑名单相关的本地缓存逻辑，包括黑名单的检查以及黑名单的过滤生成。其中黑名单的过滤方法是核心逻辑，这里主要是根据传入的key，利用Lua缓存的自动失效机制，来统计一段时间内的请求数，在达到了我们设定的阈值后，便将其放到本地缓存中，并提供针对key的查询功能，如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/4e/68/4eba9144f2e22e040eab4e42a7e81f68.png?wh=1616x1483\" alt=\"图片\"></p><p>这里引入了Lua本地缓存的概念，所以在使用前我们需要先申请一个内存块。我们将申请的地方放在了common.conf中，其中black_hole就是我们申请的内存名称，大小为50M，如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/c3/90/c3147fb3e977898e69b28fff7633b490.png?wh=1920x717\" alt=\"图片\"></p><p>底层方法写好后，我们在submit_access.lua中引入black_user_cache.lua，实现黑名单的判断、过滤以及前面的st校验功能：</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/0a/c5/0a72e5454803f3ea0cecb6571e9ef4c5.png?wh=1590x1483\" alt=\"图片\"></p><p>一切完成后，我们来测试一下，看是否生效。我们可以直接在浏览器访问提单功能，然后模拟1秒内请求提单接口超过两次的场景，但在看效果前，我们可以根据上面的逻辑实现，先设想下可能会出现的场景。</p><p>首先肯定是每次请求都会返回错误提示，第一次错误是因为我们没有st；第二次错误是因为我们触发了黑名单规则，然后被加进了黑名单；第三次及以后的请求，错误都是因为已经在黑名单，被直接拦截了。</p><p>好的，那么下面就让我们看下页面效果以及access和error日志是否达到了预期：</p><p><img src=\"https://static001.geekbang.org/resource/image/41/80/41bf19530eebb76d100f8f0bfc306780.png?wh=1920x379\" alt=\"图片\"><img src=\"https://static001.geekbang.org/resource/image/13/6e/1368cb64779554b36bf1aeffddd7fd6e.png?wh=1920x341\" alt=\"图片\"><img src=\"https://static001.geekbang.org/resource/image/99/13/9954e2fc526141bf98f968b56bdb5613.png?wh=1920x437\" alt=\"图片\"></p><p>可以看到，1秒内有4次请求进来，且响应结果都与我们预期的一样。上面的逻辑中，比如统计的频率，统计的key，黑产被加入黑名单的有效期等，都可以根据实际业务灵活变化。</p><p></p><p>本地黑名单机制的优点就是简单、高效。但也正因为基于单机，如果黑产将请求频率控制在1*Nginx机器数以内，按请求理想散落的情况下，那么就不会被我们抓到，所以真要想通过频率来严格限制刷子请求，是可以借助Redis来实现集群黑名单的。</p><p>实现思路和单机的基本一致，就是使用的内存由本地变为了Redis，当然这也必然会影响接口的响应性能，所以这里我只给出了一个进一步收紧校验的思路，就不做具体教学了，感兴趣的话可以自己尝试下。</p><p></p><h2>风控</h2><p>以上我们介绍了如何通过防刷的手段与黑产用户对抗。而想要更全面地对抗黑产，我们还需要引入另一个重要的机制，那就是风控。</p><p>风控在秒杀业务流程中非常重要，但风控的建立却是非常困难的。成熟的风控体系需要建立在大量的数据之上，并且要通过复杂的实际业务场景考验，不断地做智能修正，才能逐步提高风险识别的准确率。</p><p>像腾讯的风控，其依赖于庞大的微信、手Q生态体系的客户数据，日均调用量达2000亿次；京东的风控体系，涵盖零售、数科、物流、健康等线上线下多业务场景，跨多个领域且闭环；还有就是阿里的风控，相比京东，不仅有零售、数科、物流等，还有大文娱之类，场景更丰富。</p><p>那么为什么场景越丰富，相对来说风控的准确率越高呢？</p><p>这是因为风控的建设过程，其实就是一个不断完善用户画像的过程，而用户画像是建立风控的基础。一个用户画像的基础要素包括手机号、设备号、身份、IP、地址等，一些延展的信息还包括信贷记录、购物记录、履信记录、工作信息、社保信息等等。这些数据的收集，仅仅依靠单平台是无法做到的，这也是为什么风控的建立需要多平台、广业务、深覆盖，因为只有这样，才能够尽可能多地拿到用户数据。</p><p>有了这些数据，所谓的风控，其实就是针对某个用户，在不同的业务场景下，检查用户画像中的某些数据，是否触碰了红线，或者是某几项综合数据，是否触碰了红线。而有了完善的用户画像，那些黑产用户，在风控的照妖镜下，自然也就无处遁形了。</p><p></p><h2>小结</h2><p>这节课我们主要介绍了如何对抗黑产。黑产用户因为利益的引诱，通过外部工具、第三方软件甚至模拟请求的方式参与抢购活动，因为其速度更快、发出请求的频率更高，使得黑产用户获得了比普通用户更大的抢购成功率，这种行为不仅严重破坏了公平的抢购环境，同时也给秒杀系统带来了巨大的额外负担。</p><p>所以针对这种情形，我们也给出了几种应对的方案。像Nginx有条件限流机制，它可以直接有效地拦截针对接口的高频刷子请求；Token机制确保了刷子流量无法跳过中间步骤直接下单；还有黑名单机制，配置合理的情况下，可以彻底拦截刷子流量。最后我们还简单地介绍了风控机制，即使黑产藏得很深，依然能将其揪出。</p><p>当然每个机制虽有其优点，但也都有其不足。像Nginx有条件限流，无法完全拦截刷子；黑名单机制不能抓到隐形的黑产用户；风控虽然可以抓到隐形黑产，但体系的搭建非常困难。所以我们往往需要将各种机制做灵活的组合使用，从多维度为秒杀活动的进行保驾护航！</p><p></p><h2>思考题</h2><p>如果我既想做到严格针对用户ID的防刷，又不想使用Redis，该如何实现呢？</p><p>以上就是这节课的全部内容，期待你的思考和答案，我们评论区见！</p>","neighbors":{"left":{"article_title":"08｜化骨绵掌：降级、热点和容灾处理","id":426067},"right":{"article_title":"10｜不差毫厘：秒杀的库存与限购","id":427445}}},{"article_id":427445,"article_title":"10｜不差毫厘：秒杀的库存与限购","article_content":"<p>你好，我是志东，欢迎和我一起从零打造秒杀系统。</p><p>你应该还记得，在介绍秒杀系统所面临的挑战时，我们就有提到库存超卖的问题，它是秒杀系统面临的几大挑战之一。而库存系统一般是商城平台的公共基础模块，负责所有商品可售卖数量的管理，对于库存系统来说，如果我只卖100件商品，那理想状态下，我希望外部系统就放过来100个下单请求就好了（以每单购买1件来说），因为再多的请求过来，库存不足，也会返回失败。</p><p>并且对于像秒杀这种大流量、高并发的业务场景，更不适合直接将全部流量打到库存系统，所以这个时候就需要有个系统能够承接大流量，并且只放和商品库存相匹配的请求量到库存系统，而限购就承担这样的角色。<strong>限购之于库存，就像秒杀之于下单，前者都是后者的过滤网和保护伞。</strong></p><p>所以在有了限购系统之后，库存扣减的难题其实就转移到限购了。当然从纯技术的角度来说，不管是哪个系统来做库存的限制，高并发下库存扣减都是绕不开的难题。所以在今天这节课里，首先我们会了解限购的能力，然后会详细地讲解如何从技术角度解决库存超卖的问题。这样只要你学会了这类问题的解决方案和思路，不管是否做活动库存与真实库存的区分，都能从容应对。</p><h2><strong>限购</strong></h2><p>顾名思义，限购的主要功能就是做商品的限制性购买。因为参加秒杀活动的商品都是爆品、稀缺品，所以为了让更多的用户参与进来，并让有限的投放量惠及到更多的人，所以往往会对商品的售卖做限制，一般限制的维度主要包括两方面。</p><!-- [[[read_end]]] --><p></p><p><strong>商品维度限制：</strong>最基本的限制就是商品活动库存的限制，即每次参加秒杀活动的商品投放量。如果再细分，还可以支持针对不同地区做投放的场景，比如我只想在北京、上海、广州、深圳这些一线城市投放，那么就只有收货地址是这些城市的用户才能参与抢购，而且各地区库存量是隔离的，互不影响。</p><p></p><p><strong>个人维度限制：</strong>就是以个人维度来做限制，这里不单单指同一用户ID，还会从同一手机号、同一收货地址、同一设备IP等维度来做限制。比如限制同一手机号每天只能下1单，每单只能购买1件，并且一个月内只能购买2件等。个人维度的限购，体现了秒杀的公平性。</p><p></p><p>有了这些功能支持之后，再做一个热门秒杀活动时，首先会在限购系统中配置活动库存以及各种个人维度的限购策略；然后在用户提单时，走下限购系统，通过限购的请求，再去做真实库存的扣减，这个时候到库存系统的量已经是非常小了。</p><p>该限购流程如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/a7/b1/a755edd995f37468850dc23338bd53b1.jpg?wh=1234x732\" alt=\"\"></p><p>那么在介绍完限购之后，下面我再来详细说一下上图中活动库存扣减的实现方案。</p><p></p><h2><strong>活动库存扣减方案</strong></h2><p>我们都知道，用户成功购买一个商品，对应的库存就要完成相应的扣减。而库存的扣减主要涉及到两个核心操作，一个是查询商品库存，另一个是在活动库存充足的情况下，做对应数量的扣减。两个操作拆分开来，都是非常简单的操作，但是在高并发场景下，不好的事情就发生了。</p><p></p><p>举个简单的例子，比如现在活动商品有2件库存，此时有两个并发请求过来，其中请求A要抢购1件，请求B要抢购2件，然后大家都去调用活动查询接口，发现库存都够，紧接着就都去调用对应的库存扣减接口，这个时候，两个都会扣减成功，但库存却变成了-1，也就是超卖了。</p><p>整个过程如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/34/65/3432cfe3769def280f570ab27a550365.jpg?wh=1178x622\" alt=\"\"></p><p>从图中我们可以看到，库存超卖的问题主要是由两个原因引起的，一个是查询和扣减不是原子操作，另一个是并发引起的请求无序。</p><p>所以要解决这个问题，我们就得<strong>做到库存扣减的原子性和有序性</strong>。理想过程应该如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/1e/31/1e42d6e7e2bb5efc95d789b71278c331.jpg?wh=1508x1060\" alt=\"\"></p><p>当然理想很美好，那我们该怎么去实现它呢？</p><p>你首先可能会想到利用数据库的行锁机制。这种方式的优点是简单安全，但是其性能比较差，无法适用于我们秒杀业务场景，在请求量比较小的业务场景下，是可以考虑的。</p><p>既然数据库不行，那能使用分布式锁吗？即通过Redis或者ZooKeeper来实现一个分布式锁，以商品维度来加锁，在获取到锁的线程中，按顺序去执行商品库存的查询和扣减，这样就同时实现了顺序性和原子性。</p><p>其实这个思路是可以的，只是不管通过哪种方式实现的分布式锁，都是有弊端的。以Redis的实现来说，仅仅在设置锁的有效期问题上，就让人头大。如果时间太短，那么业务程序还没有执行完，锁就自动释放了，这就失去了锁的作用；而如果时间偏长，一旦在释放锁的过程中出现异常，没能及时地释放，那么所有的业务线程都得阻塞等待直到锁自动失效，这与我们要实现高性能的秒杀系统是相悖的。所以<strong>通过分布式锁的方式可以实现，但不建议使用。</strong></p><p>那还有其他方式吗？有！我们都知道Redis本身就是单线程的，天生就可以支持操作的顺序性，如果我们能在一次Redis的执行中，同时包含查询和扣减两个命令不就好了吗？庆幸的是，Redis确实能够支持。</p><p>Redis有个功能，是可以执行Lua脚本的（我们Nginx服务也有用到Lua语言，看来Lua语言的适用场景还真不少），并且可以保证脚本中的所有逻辑会在一次执行中按顺序完成。而在Lua脚本中，又可以调用Redis的原生API，这样就能同时满足顺序性和原子性的要求了。</p><p>当然这里的原子性说法可能不是很准确，因为Lua脚本并不会自动帮你完成回滚操作，所以如果你的脚本逻辑中包含两步写操作，需要自己去做回滚。好在我们库存扣减的逻辑针对Redis的命令就两种，一个读一个写，并且写命令在最后，这样就不存在需要回滚的问题了。</p><p></p><p>这里能帮我们实现Redis执行Lua脚本的命令有两个，一个是EVAL，另一个是EVALSHA。</p><p>原生EVAL方法的使用语法如下：</p><pre><code class=\"language-plain\">EVAL script numkeys key [key ...] arg [arg ...]\n</code></pre><p>其中EVAL是命令，script是我们Lua脚本的字符串形式，numkeys是我们要传入的参数数量，key 是我们的入参，可以传入多个，arg 是额外的入参。</p><p>但这种方式需要每次都传入Lua脚本字符串，不仅浪费网络开销，同时Redis需要每次重新编译Lua脚本，对于我们追求性能极限的系统来说，不是很完美。</p><p>所以这里就要说到另一个命令EVALSHA了，原生语法如下：</p><pre><code class=\"language-plain\">EVALSHA sha1 numkeys key [key ...] arg [arg ...]\n</code></pre><p>可以看到其语法与EVAL类似，不同的是这里传入的不是脚本字符串，而是一个加密串sha1。这个sha1是从哪来的呢？它是通过另一个命令SCRIPT LOAD 返回的，该命令是预加载脚本用的，语法为：</p><pre><code class=\"language-plain\">SCRIPT LOAD script\n</code></pre><p>这样的话，我们通过预加载命令，将Lua脚本先存储在Redis中，并返回一个sha1，下次要执行对应脚本时，只需要传入sha1即可执行对应的脚本。这完美地解决了EVAL命令存在的弊端，所以我们这里也是基于EVALSHA方式来实现的。</p><p></p><p>既然有了思路，也有了方案，那我们开始用代码实现它吧。</p><p></p><p>首先我们根据以上介绍的库存扣减核心操作，完成核心Lua脚本的编写。其主要实现的功能就是查询库存并判断库存是否充足，如果充足，则做相应的扣减操作，脚本内容如下：</p><pre><code class=\"language-plain\">-- 调用Redis的get指令，查询活动库存，其中KEYS[1]为传入的参数1，即库存key\nlocal c_s = redis.call('get', KEYS[1])\n-- 判断活动库存是否充足，其中KEYS[2]为传入的参数2，即当前抢购数量\nif not c_s or tonumber(c_s) &lt; tonumber(KEYS[2]) then\n   return 0\nend\n-- 如果活动库存充足，则进行扣减操作。其中KEYS[2]为传入的参数2，即当前抢购数量\nredis.call('decrby',KEYS[1], KEYS[2])\n</code></pre><p>然后我们将Lua脚本转成字符串，并添加脚本预加载机制。</p><p>预加载可以有多种实现方式，一个是外部预加载好，生成了sha1然后配置到配置中心，这样Java代码从配置中心拉取最新sha1即可。另一种方式是在服务启动时，来完成脚本的预加载，并生成单机全局变量sha1。我们这里先采取第二种方式，代码结构如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/47/7d/47c9b70d3ee184f6f822cf93a7dd997d.png?wh=849x624\" alt=\"图片\"></p><p>以上是将Lua脚本转成字符串形式，并通过@PostConstruct完成脚本的预加载。然后新增EVALSHA方法，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/1a/62/1a1371b717a91yy229c6bfe09afbe762.png?wh=891x522\" alt=\"图片\"></p><p>方法入参为活动商品库存key以及单次抢购数量，并在内部调用Lua脚本执行库存扣减操作。看起来是不是很简单？在写完底层核心方法之后，我们只需要在下单之前，调用该方法即可，具体如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/20/76/20a3cd59468619a6b2f55732458f2276.png?wh=879x309\" alt=\"图片\"></p><p>一切完成后，接下来就让我们来验证一下，是否会出现超卖的情况吧。</p><h2>模拟场景</h2><p></p><p>我们模拟的场景是这样的：</p><ul>\n<li>首先，通过前文中提到的活动创建接口，完成活动的创建；</li>\n<li>然后，调用活动开始接口，并将商品活动信息同步到Redis里，包括商品活动库存；</li>\n<li>接着，我们通过并发测试工具，直接模拟请求下单操作；</li>\n<li>最后，请求在经过限购（代码中直接调用EVALSHA核心方法模拟）时，判断是否通过，如果通过就继续下单，并完成数据库中库存的扣减，如果售空，则返回失败。</li>\n</ul><p></p><p>我们按照模拟思路，先创建一个活动，数据库库存为4，然后调用活动开始接口，活动信息如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/3b/df/3b0072f152aacb4d9096df46d6f93bdf.png?wh=832x314\" alt=\"图片\"></p><p>再查看一下该活动对应的Redis活动库存，也是4件，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/57/65/57239bdc7c8ed19c9759094f432aa965.png?wh=832x134\" alt=\"图片\"></p><p>然后我们开始模拟1秒内发出多个并发请求，每个请求抢购2件商品。我这里使用的是wrk工具做的测试，测试命令如下：</p><pre><code class=\"language-plain\">wrk -t3 -c3 -d1s http://localhost:8080//settlement/submitData?productId=20002001\n</code></pre><p>以上命令的大概意思是使用3个线程来做压测，持续时间1秒。执行后的测试结果如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/c4/d0/c4a65e2b027d025af53152c5ec13cfd0.png?wh=832x206\" alt=\"图片\"></p><p>从上图可以看到，在1秒内发出了15个请求。现在我们看下限购的结果，1代表通过，0代表不通过，具体如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/fc/62/fc2835653c7412c22dc5b73b043f9862.png?wh=845x193\" alt=\"图片\"></p><p>确实只有2个请求通过限购，其他的全部被拦截了。这个时候，我们再分别查看下Redis活动库存和数据库库存，如下图所示：<img src=\"https://static001.geekbang.org/resource/image/4c/4d/4c86e82e0a4dba7880b8d3ca3abb9d4d.png?wh=758x202\" alt=\"图片\"></p><p><img src=\"https://static001.geekbang.org/resource/image/49/d7/49dd3bbd73be597622432859da5a72d7.png?wh=851x334\" alt=\"图片\"></p><p>库存数量都变成了0，没有出现超卖的情况！一切都完美符合我们的预期。</p><h2><strong>总结</strong></h2><p>这节课我们分析了库存系统的业务边界，由于是电商平台的基础系统，并且基于秒杀业务隔离的原则，使得库存系统不太适合直接承接秒杀的高并发流量，需要有个过滤层。而限购系统刚好可以胜任这样的角色，限购可以从商品和个人的维度来做商品的限制性购买，从而可以帮库存系统抵挡住无效的流量，只放过和商品库存相匹配的请求数量。</p><p>当然不管是哪个系统来做库存的控制，都要面临的问题就是库存的精确控制，所以我们从纯技术的角度分析了库存超卖发生的两个原因。一个是库存扣减涉及到的两个核心操作，查询和扣减不是原子操作；另一个是高并发引起的请求无序。</p><p>所以我们的应对方案是利用Redis的单线程原理，以及提供的原生EVALSHA和SCRIPT LOAD 命令来实现库存扣减的原子性和顺序性，并且经过实测也确实能达到我们的预期，且性能良好，从而有效地解决了秒杀系统所面临的库存超卖挑战。以后再遇到类似的问题，你也可以用同样的解决思路来应对。</p><p></p><h2>思考题</h2><p>请你思考一下，根据我们校验前置的原则，是否可以仅仅将库存的校验前置到demo-nginx或demo-web中，像下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/4c/c6/4c6ef532c64c3ddc2a54a6e05deee4c6.jpg?wh=1814x858\" alt=\"\"></p><p>如果可以，该如何具体实现它？</p><p>期待你的思考和方案，也欢迎你在留言区中与我交流，我们下节课再见！</p>","neighbors":{"left":{"article_title":"09｜御敌国门外：黑产对抗——防刷和风控","id":426696},"right":{"article_title":"11｜高性能优化：物理机极致优化","id":428142}}},{"article_id":428142,"article_title":"11｜高性能优化：物理机极致优化","article_content":"<p>你好，我是志东，欢迎和我一起从零打造秒杀系统。</p><p>经过前面章节的学习，咱们逻辑代码层面的优化，基本都已经差不多了。这个时候，再制约系统性能的，往往是些逻辑代码之外的因素了，这些我们可能很少接触，但却非常重要。</p><p>所以今天我们将学习一下物理机相关的优化思路，以及部署在物理机上的Nginx的配置优化。同时说明一下，以下的优化都是在Linux平台下的优化方式，在其他平台的话，部分优化可能不支持。</p><p></p><h2><strong>物理机优化</strong></h2><p>以下优化，在搭建生产环境时，你可以协同运维部门的同事一起完成，你可以将优化的思路告诉他们，由他们来完成操作会更加合适。</p><p></p><h3>CPU模式的优化</h3><p>所谓CPU模式的调整，就是调整CPU的工作频率，使其呈现出不同的性能表现，以满足特定的业务使用场景。我们一般使用的Linux系统，也都有多种模式可供选择，像PowerSave、OnDemand、Interactive、Performance等，每个模式的调频方式都不同。</p><p>因为考虑到秒杀业务的特殊性，并且有时候活动非常的火热，但过段时间可能就降温了些，所以我们采用的模式也不相同。</p><p>像大促期间或者某段时间部分商品持续大力度营销，这时的活动非常火热，流量也高，所以我们需要将CPU模式调整成Performance，即高性能模式。这时CPU一直处于超频状态，当然这种状态也是比较耗电的，但是为了更好地开展活动，还是需要打开的。</p><!-- [[[read_end]]] --><p>而当活动处于日常化时，此时流量较大促有很大差异，并且每天的流量相对稳定，这时候我们就可以将CPU模式切回成PowerSave模式，即节能模式，或者是切回系统的默认模式OnDemand。这样的话，可以兼顾性能与资源开销，高性价比地支持秒杀活动。</p><h3>网卡中断优化</h3><p>那调完了CPU，另一个需要优化的点就是网卡中断了。</p><p>“中断”是机器硬件与CPU交互的一种方式，即硬件告诉CPU有事情要处理了。而网卡中断，就是机器网卡告诉CPU要处理网络数据了。</p><p>前面我们就有说过秒杀的瞬时流量非常高，带来的问题就是一下子会有非常多的网络请求进来。网卡在收到网络信号后，会通知CPU来处理，这时如果我们没有调整过相关配置，那么很有可能处理网卡中断的CPU都集中在一个核上。</p><p>如果这个时候该CPU也在承担处理应用进程的任务，那么就有可能出现单核CPU飙升的问题，同时网络数据的处理也会受到影响，导致大量TCP重传现象的发生。所以这个时候，我们要做的就是合理分配多核CPU资源，专门拿出一个核来处理网卡中断。</p><p><strong>操作的过程大致可以分成3步：</strong></p><ol>\n<li>查看在流量高峰时，是否处理网卡中断的工作都集中在同一个核上；</li>\n<li>找到网卡中断的IRQ（硬件设备的一个编号，让CPU知道是哪个硬件的中断信号）；</li>\n<li>将网卡的IRQ与一个特定的CPU核进行绑定。</li>\n</ol><p></p><p>我们这么做的目的，其实就是在多核CPU下，让一个进程在某个给定的CPU上尽量长时间地运行而不被迁移到其他处理器。这样做的好处就是：一方面可以减少CPU调度产生的开销；另一方面可以提高每个CPU核的缓存命中率。</p><p>同样地，如果我们的Nginx服务和我们的Redis也安装在同一台物理机上，那么我们也可以将Redis进程以及Nginx进程分别绑定到不同的核上。比如我们有16核，那这个时候，我们可以将其中的10核绑定Nginx进程，2核用来绑定Redis实例，1核用来绑定处理网卡中断，剩下的可以选择再开Nginx实例或者给其他进程使用，这样每个核都可以专注处理自己的进程任务，不用切换拷贝内存等，从而大大提高了整体的服务响应性能。</p><p></p><p>以上Redis的绑核操作可以通过taskset来完成，而Nginx的绑核则可以通过Nginx的配置来直接绑定。那么接下来我们就一起看下Nginx配置方面的优化点。</p><p></p><h2><strong>Nginx配置优化</strong></h2><p>前面在介绍Nginx的时候，我有给你展示过这张Nginx配置的模块结构图，每个模块都可以做相应的配置。</p><p><img src=\"https://static001.geekbang.org/resource/image/af/e8/af0a2cd9ab08af631c5ab95ae91141e8.png?wh=1726x1656\" alt=\"图片\"></p><p>下面我们就按照顺序，依次介绍下各模块中重要配置的优化方式，并在最后附上一个最终建议优化配置。</p><h3>全局模块配置</h3><p></p><p>首先是全局模块配置 worker_processes，即用来处理网络请求的工作进程数。这个配置参数的设置非常关键，它直接会影响到整个Nginx服务的吞吐量，设置小了，发挥不了服务器的硬件水平，设置过大，还会起到反效果。</p><p>那设置多少合适呢？这个就要看我们机器的硬件配置了，我们建议工作进程数和CPU核数保持一致，这是种比较理想的状态。但就像上面提到的，如果机器上还部署了其他应用，像Redis实例等，那这个时候就要考虑到其他应用对CPU资源的占用，并且需要结合绑核操作，尽量让一个CPU核能专门处理一个工作进程。所以我们下面结合绑核配置一起看下。</p><p><strong>worker_cpu_affinity：</strong>绑核的目的，上面也已经介绍过了。当我们了解了机器的配置，以及部署在机器的应用以后，我们就可以合理地分配CPU资源，以4核CPU绑核为例，其绑定语法如下：</p><pre><code class=\"language-plain\">worker_cpu_affinity &nbsp;&nbsp;0001 0010 0100 1000;\n</code></pre><p>针对语法的说明可参考下图：</p><p><img src=\"https://static001.geekbang.org/resource/image/25/d7/25yy8caa109ebfc1f9b21d8af7164ed7.jpg?wh=1566x726\" alt=\"\"></p><p>通过合理地设置工作进程，并将工作进程与CPU一一绑定，可以有效利用机器资源，提高服务的吐吞量与整体响应性能。</p><p>那说到吞吐量呢，还得介绍一个关键的配置参数，即工作进程可以打开的最大文件描述符数量，其配置指令为worker_rlimit_nofile。</p><p><strong>worker_rlimit_nofile：</strong>我们都知道网络通信的底层是通过socket来建立连接的，而每一个socket又会打开一个文件描述符，所以文件描述符的数量设置会影响服务器处理网络连接的上限。如果设置过小，那么超过文件描述符数量的连接都会被直接返回。而该配置又和单个工作进程可以建立的最大连接数量息息相关，所以我们和下面的worker_ connections一起说下。</p><h3>events模块配置</h3><p>worker_ connections指令是在events模块配置中使用的。</p><p></p><p><strong>worker_connections：</strong>刚上面提到，单个工作进程可以建立的最大连接数量是受worker_rlimit_nofile配置限制的，理论上该值的设置应等于最大文件描述符数量除以工作进程数，但因为工作进程处理请求并不是均匀的，所以将该值的设置只要小于等于最大文件描述符数量即可。一般在线上使用时，我们会将这两个的配置值都设置为65535。</p><p></p><p>那既然说到event模块的配置，那我们就再说几个其他的常用配置。</p><p></p><p><strong>accept_mutex：</strong>这个指令是用来配置工作进程接受新连接的方式。如果开启，那么工作进程会轮流接受新的连接，即采用互斥锁的方式。否则的话，当有新连接进来之后，所有的工作进程都会被唤醒，但只有一个可以接受新连接并处理。其他进程如果没有连接处理，则过段时间会继续进入等待状态，而这个时间段内对CPU资源是有消耗的。由此可见，如果我们流量较小时，建议打开，相反，则建议关闭。如果该配置启用，那么最好也设置一下以下配置。</p><p></p><p><strong>accept_mutex_delay：</strong>该指令是配合accept_mutex来使用，是设置工作进程取得互斥锁后接受新连接的超时时间。超过设置时间，其他进程将可以获得互斥锁，这样可以防止上个进程拿到锁后一直不释放，导致处理请求受阻。</p><h3>HTTP模块配置</h3><p>那events配置模块差不多就这些了，下面我们开始介绍HTTP模块的配置。这块都是关于HTTP请求处理相关的设置，比较多，我们这里会总结出一些针对秒杀场景的常用优化项。</p><p></p><p><strong>sendfile：这个是操作系统用来优化文件传输提供的一个函数。</strong></p><p>正常的文件传输，读时需要将数据文件从硬盘拷到内核空间，再从内核空间拷贝到用户空间，写时再依次拷贝出，同时也伴随着上下文的切换。</p><p>而sendfile的做法是省略掉了内核空间和用户空间的拷贝以及上下文切换操作，这也叫做零拷贝，节省资源的同时提高了效率，具体如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/fa/48/fafd20fe607cbab6e021cecc9e865b48.jpg?wh=1956x672\" alt=\"\"></p><p>因为秒杀有文件传输的场景，所以建议打开这个配置（通过upstream的文件传输，是不受该配置影响的）。打开该配置后，就可以继续使用另一个指令tcp_nopush了。</p><p></p><p><strong>tcp_nopush：该配置只有在打开sendfile配置的情况下才能生效。</strong></p><p>简单来说，该配置是关于TCP传输的配置。如果打开了nopush，那么在Nginx响应客户端请求时，会优化响应数据包的发送模式，即将多个较小的数据包合并发送，就像响应头和响应体。这样做的好处是可以减少网络拥堵，优化网络传输，当然也会牺牲稍许实时性的体验。</p><p>那么说到这，就不得不说下另一个关于TCP传输的配置了。</p><p></p><p><strong>tcp_nodelay：顾名思义，如果开启，就是用来降低网络延时的。</strong></p><p>其做法和上面的tcp_nopush相反，追求数据包的实时传输，对于秒杀这种网络负载较高的场景，一般不推荐打开，并且该配置只在长连接条件下才能生效，而秒杀结算页的HTTP请求一般都使用短连接（这里以及下文提到的长、短连接，都是指TCP层面的）。那在Nginx上也可以通过指令来配置客户端的连接处理方式，即keepalive_timeout。</p><p></p><p><strong>keepalive_timeout：一般HTTP请求是要使用长连接还是短连接，需要客户端和服务端都支持。</strong></p><p>客户端在使用HTTP1.1之后的协议版本，默认都是长连接，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/ea/d9/ea7bc78ffbd0293d9f60babbd63515d9.jpg?wh=879x477\" alt=\"\"></p><p>协议版本是HTTP2.0的话，如果没有特殊配置，请求头里会有keep-alive的设置。但我们可以在Nginx通过配置空闲连接的存活时间为0，来关闭长连接，使其变成短连接。效果如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/a2/cc/a2514a8292e2d42b06f6d25668b3b3cc.png?wh=764x696\" alt=\"\"></p><p></p><p>我们知道Nginx要连接的不仅有客户端，还有下游的Web服务。那针对上游客户端以及下游服务端，采用的连接方式会有什么不同呢？我们看下这张图：</p><p><img src=\"https://static001.geekbang.org/resource/image/78/ff/78c7683c0c937d35934fd1d6abbb47ff.jpg?wh=1508x818\" alt=\"\"></p><p>Nginx之所以针对客户端采用短连接，是因为客户端数量太多了，且交互不频繁。如果都用长连接，那么很快服务端连接将会被占完。</p><p>但对于下游，Nginx相对就成了客户端了，其数量只有几台到几十台之间不等，且与后端Tomcat交互是十分频繁的，如果不停地创建连接，将会造成非常大的性能损耗，所以最好采用长连接的方式。长连接配置的方式，就放到最后的汇总配置里了。</p><p></p><p><strong>最后再说几个与下游Web服务相关的超时配置。</strong></p><p>它们分别是proxy_connect_timeout、proxy_send_timeout、proxy_read_timeout，即连接建立超时时间、发送请求超时时间、读取响应超时时间。</p><p>如果不合理设置这些超时时间，就会因为各种网络状况导致Nginx与Web服务之间数据传输受阻，客户端将会一直等待，体验极差。所以我们需要根据接口的正常响应时间，设置一个合理的超时时间，等待超过超时配置，再将返回提示给到用户。具体的设置我也放到汇总配置里了。</p><p></p><h2><strong>总结</strong></h2><p>这节课我们介绍了物理机与Nginx相关配置的优化，优化的方向无非是对内存、CPU、IO（磁盘IO和网络IO）的优化。</p><p>所以对于物理机，我们主要从调整CPU的工作模式来入手，根据不同的秒杀业务场景，我们切换不同的工作模式。像大促期间或者活动非常火热时，我们将CPU模式切换成高性能模式，以得到更好的响应性能，当然代价就是耗电增加；如果活动比较平稳，我们可以考虑切换成省电模式，这样可以节约成本。</p><p>另外在秒杀高峰期间，网络负载重，TCP重传现象频发，我们也做了针对性的措施，即通过绑定专门CPU来处理网卡中断。当然绑核的操作不只可以针对网卡中断，还可以绑定Nginx进程以及部署的其他应用服务。这么做的目的，一方面是为了减少CPU调度产生的开销，另一方面也可以提高每个CPU核的缓存命中率。</p><p>之后我们又讲到了Nginx的优化，分别针对客户端以及下游服务端，从网络的连接、传输、超时等方面做了不同的配置讲解。具体的Nginx优化配置你可以参考以下示例。</p><p>nginx.conf配置如下：</p><pre><code class=\"language-plain\">#工作进程：根据CPU核数以及机器实际部署项目来定，建议小于等于实际可使用CPU核数\nworker_processes 2;\n\n#绑核：MacOS不支持。\n#worker_cpu_affinity&nbsp; &nbsp;01 10;\n\n#工作进程可打开的最大文件描述符数量，建议65535\nworker_rlimit_nofile 65535;\n\n#日志：路径与打印级别\nerror_log logs/error.log error;\n\n\n\nevents {\n&nbsp; &nbsp; #指定处理连接的方法，可以不设置，默认会根据平台选最高效的方法，比如Linux是epoll\n&nbsp; &nbsp; #use epoll;\n&nbsp; &nbsp; #一个工作进程的最大连接数：默认512，建议小于等于worker_rlimit_nofile\n&nbsp; &nbsp; worker_connections 65535;\n&nbsp; &nbsp; #工作进程接受请求互斥，默认值off,如果流量较低，可以设置为on\n&nbsp; &nbsp; #accept_mutex off;\n&nbsp; &nbsp; #accept_mutex_delay 50ms;\n}\n\nhttp {\n&nbsp; &nbsp; &nbsp; &nbsp; #关闭非延时设置\n&nbsp; &nbsp; &nbsp; &nbsp; tcp_nodelay&nbsp; off;\n&nbsp; &nbsp; &nbsp; &nbsp; #优化文件传输效率\n&nbsp; &nbsp; &nbsp; &nbsp; sendfile&nbsp; &nbsp; &nbsp;on;\n&nbsp; &nbsp; &nbsp; &nbsp; #降低网络堵塞\n&nbsp; &nbsp; &nbsp; &nbsp; tcp_nopush&nbsp; &nbsp;on;\n\n&nbsp; &nbsp; &nbsp; &nbsp; #与客户端使用短连接\n&nbsp; &nbsp; &nbsp; &nbsp; keepalive_timeout&nbsp; 0;\n&nbsp; &nbsp; &nbsp; &nbsp; #与下游服务使用长连接,指定HTTP协议版本，并清除header中的Connection，默认是close\n&nbsp; &nbsp; &nbsp; &nbsp; proxy_http_version 1.1;\n&nbsp; &nbsp; &nbsp; &nbsp; proxy_set_header Connection \"\";\n\n&nbsp; &nbsp; &nbsp; &nbsp; #将客户端IP放在header里传给下游，不然下游获取不到客户端真实IP\n&nbsp; &nbsp; &nbsp; &nbsp; proxy_set_header X-Real-IP $remote_addr;\n\n&nbsp; &nbsp; &nbsp; &nbsp; #与下游服务的连接建立超时时间\n&nbsp; &nbsp; &nbsp; &nbsp; proxy_connect_timeout 500ms;\n&nbsp; &nbsp; &nbsp; &nbsp; #向下游服务发送数据超时时间\n&nbsp; &nbsp; &nbsp; &nbsp; proxy_send_timeout 500ms;\n&nbsp; &nbsp; &nbsp; &nbsp; #从下游服务拿到响应结果的超时时间（可以简单理解成Nginx多长时间内，拿不到响应结果，就算超时），\n        #这个根据每个接口的响应性能不同，可以在每个location单独设置\n&nbsp; &nbsp; &nbsp; &nbsp; proxy_read_timeout 3000ms;\n&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; #开启响应结果的压缩\n&nbsp; &nbsp; &nbsp; &nbsp; gzip on;\n&nbsp; &nbsp; &nbsp; &nbsp; #压缩的最小长度，小于该配置的不压缩\n&nbsp; &nbsp; &nbsp; &nbsp; gzip_min_length&nbsp; 1k;\n&nbsp; &nbsp; &nbsp; &nbsp; #执行压缩的缓存区数量以及大小，可以使用默认配置，根据平台自动变化\n&nbsp; &nbsp; &nbsp; &nbsp; #gzip_buffers&nbsp; &nbsp; &nbsp;4 8k;\n&nbsp; &nbsp; &nbsp; &nbsp; #执行压缩的HTTP请求的最低协议版本，可以不设置，默认就是1.1\n&nbsp; &nbsp; &nbsp; &nbsp; #gzip_http_version 1.1;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; #哪些响应类型，会执行压缩，如果静态资源放到CDN了，那这里只要配置文本和html即可\n&nbsp; &nbsp; &nbsp; &nbsp; gzip_types&nbsp; &nbsp; &nbsp; text/plain;\n\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; #acccess_log的日志格式\n&nbsp; &nbsp; &nbsp; &nbsp; log_format&nbsp; access&nbsp; '$remote_addr - $remote_user [$time_local] \"$request\" $status '\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; '\"$upstream_addr\" \"$upstream_status\" \"$upstream_response_time\" userId:\"$user_id\"';\n\n&nbsp; &nbsp; &nbsp; &nbsp; #加载lua文件\n&nbsp; &nbsp; &nbsp; &nbsp; lua_package_path \"/Users/~/Documents/seckillproject/demo-nginx/lua/?.lua;;\";\n&nbsp; &nbsp; &nbsp; &nbsp; #导入其他文件\n&nbsp; &nbsp; &nbsp; &nbsp; include /Users/~/Documents/seckillproject/demo-nginx/domain/domain.com;\n&nbsp; &nbsp; &nbsp; &nbsp; include /Users/~/Documents/seckillproject/demo-nginx/domain/internal.com;\n&nbsp; &nbsp; &nbsp; &nbsp; include /Users/~/Documents/seckillproject/demo-nginx/config/upstream.conf;\n&nbsp; &nbsp; &nbsp; &nbsp; include /Users/~/Documents/seckillproject/demo-nginx/config/common.conf;\n}\n</code></pre><p>当然，今天说到的这些优化方向和优化点，考虑到机器配置、网络环境、业务功能等因素的差异，我们还需要依据实际压测效果来做灵活的调整，但总体优化思路是不变的。</p><h2><strong>思考题</strong></h2><p>以上针对Nginx的优化配置有很多的指令，这些指令可以在不同的模块进行配置，比如像proxy_set_header这种，既可以在HTTP全局模块配置，也可以在server模块进行配置，那类似这样的指令设置，都会考虑哪些因素呢？</p><p>期待你的思考，欢迎在评论区中和我讨论问题，交流经验！我们下节课再见。</p>","neighbors":{"left":{"article_title":"10｜不差毫厘：秒杀的库存与限购","id":427445},"right":{"article_title":"12｜高性能优化：单机Java极致优化","id":429098}}},{"article_id":429098,"article_title":"12｜高性能优化：单机Java极致优化","article_content":"<p>你好，我是志东，欢迎和我一起从零打造秒杀系统。</p><p>今天这节课我们主要是聊一聊和Java相关的一些技术点的优化方向，包括Tomcat、RPC框架、JVM以及CDN等。但在开始之前呢，我们先来说个基本知识点，那就是关于程序代码的两种运行模式，即 <strong>CPU密集型与IO密集型</strong>。</p><p>CPU密集型操作，顾名思义就是需要持续依赖CPU资源来执行的操作，比如各种逻辑计算、解析、判断等等。在这种情况下，我们的优化方向是尽可能地利用多核CPU资源，并且避免让CPU做无效的切换，因为CPU已经在不停地工作了，谁来干都一样，同时切换CPU还浪费资源。所以这个时候，我们最好让任务线程数和CPU核数保持一致，从而最大限度地利用CPU资源。</p><p>和CPU密集型操作相对的，就是IO密集型操作了，比如磁盘IO或者网络IO，这个过程操作系统会挂起任务线程，让出CPU资源。此时如果任务线程较少，同时IO时间相对较长，那可能会出现所有线程都被挂起，然后CPU资源都在闲着的情况，所以此时我们需要适当地增加任务线程数量，来提高吞吐量，同时将CPU资源利用起来。</p><p>那为什么要说这个呢？因为这是做程序优化的基本原则。通过前面课程的学习，我们知道，秒杀系统里有提供两种类型的服务，一个是Web服务，一个是RPC服务，前者一般提供HTTP接口，后者提供RPC接口。当然这两种服务我们一般都是通过Tomcat来启动发布，但它们两者之间还是有些不同的。Web服务接受和处理请求走的是Tomcat那套线程模型，而RPC服务则是根据选择的RPC框架的不同而有所变化，所以这节课我们首先来了解一下Tomcat相关的知识。</p><!-- [[[read_end]]] --><p></p><h2><strong>Tomcat</strong></h2><p>根据我们以往“知己知彼”的学习方式，先看下 <strong>Tomcat在NIO线程模型下是怎么工作的</strong>，简图如下所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/09/9c/09f73f9dabbyyabe8c78dcbc0abfc79c.jpg?wh=1378x1190\" alt=\"\"></p><p>简单来说就是：</p><ul>\n<li>Tomcat启动时，会创建一个Server端的Socket，来监控我们配置的端口号；</li>\n<li>之后使用一个Acceptor来接受请求，然后将请求放到一个Poller下的事件队列中；</li>\n<li>Poller会轮询取出事件队列中的Channel，并将其注册到自身下的Selector；</li>\n<li>而Selector也会不停轮询检查就绪的Channel，然后将其交给Tomcat线程池；</li>\n<li>Tomcat线程池会拿出一个线程来进行处理，包括解析请求头、请求体等，并将其封装进HttpServletRequest；</li>\n<li>最后执行自定义的Servlet业务逻辑，执行完毕将响应结果返回。</li>\n</ul><p>所以从上图可以看出，所谓的非阻塞，其实就是相对以前的BIO，Tomcat不再是用一个线程将一个请求从头处理到尾，而是分阶段来执行了。<strong>好处显然易见，那就是提高了系统吞吐量。</strong></p><p>在了解了Tomcat基本原理之后，我们再回过头来看下有什么地方是我们可以入手优化的。先看下Tomcat给我们开放了哪些可配置项：</p><pre><code class=\"language-plain\">&lt;Connector port=\"8080\" protocol=\"HTTP/1.1\" connectionTimeout=\"20000\" redirectPort=\"8443\" /&gt;\n</code></pre><p>上面是Tomcat的Connector默认配置，首先是端口号，其次是protocol，也就是上面说到的线程模型。Tomcat 8之后默认使用的都是NIO模式，这个也可以通过我们服务的启动来查看：</p><p><img src=\"https://static001.geekbang.org/resource/image/0c/76/0cdfc74546cdaa36b5003acef59fac76.jpg?wh=852x127\" alt=\"图片\"></p><p>如上图所示，就代表分别使用的是NIO模式和NIO2(AIO)模式，当然还可以选择BIO模式以及APR模式。具体对比可参考下表：</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/89/42/8966cb8e33788bdded84f325d19ed942.png?wh=1260x508\" alt=\"图片\"></p><p>那说完线程模型的选择，从上图中我们可以看到有个Tomcat线程池的概念，它是通过哪些配置来控制的呢？这里我们只摘几个重要的配置说一下，详细信息如下表所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/ac/db/ac0fddbddeb80f53565debe35de5e4db.png?wh=1254x794\" alt=\"图片\"></p><p>说完了Tomcat的配置，这里再简单说说&nbsp;Servlet 的部分知识。我们都知道Servlet从3.0开始加入了异步，从3.1开始又新增了对IO非阻塞的支持，那么这个和Tomcat线程模型中提到的异步非阻塞是一个概念吗？这里我们就来捋一捋。</p><p></p><p>首先从上面的Tomcat线程模型图中，我们可以清晰地看到，NIO或AIO的概念是针对请求的接收来说，而Servlet的异步非阻塞主要是针对请求的处理，已经是到了Tomcat线程池那里了。</p><p>我们先来看下Servlet3.0前后的变化对比，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/76/f8/7614fe72f3cff040947c1e5yy9c119f8.jpg?wh=1824x1190\" alt=\"\"></p><p>概述一下就是，Servlet3.0之前，Tomcat线程在执行自定义Servlet时，如果过程中发生了IO，那么Tomcat线程只能在那等着结果，这时线程是被挂起的，如果被挂起的多了，自然会影响对其他请求的处理。</p><p>所以在Servlet3.0之后，支持在这种情况下将这种等待的任务交给一个自定义的业务线程池去做，这样Tomcat线程可以很快地回到线程池，处理其他请求。而业务线程在执行完业务逻辑以后，通过调用指定的方法，告诉Tomcat线程池接下来可以将业务线程执行的结果返回给调用方，这样就实现了同步转异步的效果。</p><p></p><p>这样做的好处，可能对提高系统的吞吐量有一定帮助，但从JVM层面来说，并没有减少工作量。业务线程在执行任务遇到IO时，依然会阻塞，现在只是由业务线程池代替了Tomcat线程池做了最耗时的那部分工作，这样也许可以将原来的200个Tomcat线程，拆分成20个Tomcat线程、180个业务线程来配合工作。这里原生Servlet以及SpringMVC对异步功能支持的测试代码，你可以看GitHub代码库中的AsyncServlet类和TestAsyncController类，相信你一看就明白了。</p><p></p><p>接着我们再聊一下Servlet3.1的非阻塞，这块简单来说，就是针对请求消息体的读取，这是个IO过程，以前是阻塞式读取，现在支持非阻塞读取了。实现的大致原理就是在读取数据时，新增一个监听事件，在读取完成后由Tomcat线程执行回调。</p><p></p><p>在了解了Tomcat线程模型之后，我们接着再说下RPC框架相关的知识。</p><p></p><h2><strong>RPC框架</strong></h2><p>虽然RPC服务处理请求的过程，会依据选用的RPC框架而有所不同，但绝大部分RPC框架底层使用的都是Netty，而Netty则是基于NIO开发的一种网络通信框架，支持多种通信协议，其服务端线程模型简略图如下所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/0c/64/0ca1cd1d776fdb9c272f63b23c657d64.jpg?wh=1570x1118\" alt=\"\"></p><p>简单描述就是：</p><ul>\n<li>在服务启动时，会创建一个Server端Socket，监控我们配置的端口号；</li>\n<li>然后将NioServerSocketChannel注册到Boss Pool中的一个Selector上；</li>\n<li>再之后对Selector做轮询，将就绪状态的连接封装成NioSocketChannel并注册到Worker Pool下的一个Selector上；</li>\n<li>而Worker Pool下的Selector也是同样轮询，找出可读和可写状态的分别执行不同操作。</li>\n<li>同时两个Pool中都有任务队列，是不同场景下用户自定义或外部通过特定方式提交过去的任务，都会被依次执行。</li>\n</ul><p>所以当我们的应用只提供RPC服务时，我们可以将Tomcat的核心线程池配置，也就是minSpareThreads配置成1，因为用不到。而我们主要需要调整的是RPC框架的相关配置，以Dubbo为例，我们看下 &lt;dubbo:protocol&gt; 的主要配置项：</p><p><img src=\"https://static001.geekbang.org/resource/image/23/41/2340f6d3b57a6310fda38622d93cab41.png?wh=1258x584\" alt=\"图片\"></p><p>在Netty中，虽然只有一个Worker Pool，但会做两种类型的事情，一个是做IO处理，包括请求消息的读写，另一个是做业务逻辑处理。</p><p>而Dubbo将其分成了两个线程池，也就是上面表格中的两个线程池配置。这两个线程池做的事情，会根据Dispatcher的配置而有所不同。Netty是以事件驱动的形式来工作的，像请求、响应、连接、断开、异常等操作都是事件；而Dubbo中的Dispatcher就是将不同的事件类型分给不同的线程池来处理，如果你感兴趣的话可以去看下Dubbo中WrappedChannelHandler类的5个实现类，分别对应Dispatcher的5个选项。</p><p>最后一个配置项Queues，这个默认值是0，也就是不接受等待，如果没有空闲线程处理任务，将会直接返回。这个得和客户端配置配合使用，如果这里配置了0，那客户端最好配置重试。</p><p></p><p>讲完了两种服务的底层线程模型之后，我们再来介绍一下静态资源相关的优化。</p><p></p><h2><strong>静态资源</strong></h2><p>我们知道在秒杀系统中，客户端与服务端既有动态数据交互，也有静态数据交互，而我们做系统优化有个基本的原则，即<strong>前后端交互越少，数据越小，链路越短，数据离用户越近，响应就越快。</strong></p><p><img src=\"https://static001.geekbang.org/resource/image/ce/76/ce46453e685ed16f58ae3f365a1cd376.jpg?wh=1456x325\" alt=\"\"></p><p>基于这个原则，针对以上的静态数据，我们就可以把静态文件CDN化，资源前移到全国各地的CDN节点上，用户秒杀的时候就近进行下载，就不需要都挤到中心的Tomcat服务器上了。</p><p>静态资源前移，大家平常也会做，感受比较深的是不是就是客户端的页面加载更快了，但除了性能的提升外，其实它对系统稳定也至关重要。</p><p></p><p>试想一下，当几百万人同时来拉取这些较大的资源文件时，对中心的Tomcat服务器以及公司的网络带宽都是巨大的压力。京东当初在进行口罩抢购的时候，这些静态资源就差点把公司的出口带宽打满，影响交易大盘，后来紧急扩容才避免了危机。</p><p>另外，这些静态资源对Tomcat所在物理机的网卡挑战也很大，京东在资源CDN化前，物理机的万兆网卡曾被打满，后来经过优化之后，网卡的流量只有原来的10%了。</p><p><img src=\"https://static001.geekbang.org/resource/image/a4/13/a48171f5a6a8fc510d18c19aa0f29c13.jpg?wh=1110x414\" alt=\"\"></p><p>在最后，我们再说下Java运行的基础环境，JVM相关的知识以及优化。</p><p></p><h2><strong>JVM</strong></h2><p>这里如果你对一些基本概念，比如JVM内存结构、GC原理、垃圾收集器类型等还不了解，那建议你先了解一下，会有事半功倍的效果。这块的内容比较多，又比较重要，但我们没办法一一展开，只说最核心的优化点。</p><p>先看个JVM内存模型以及常用配置，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/2a/81/2afaeb5e409a78b968812f6363fb0881.jpg?wh=1668x1313\" alt=\"\"></p><p>其实针对JVM的优化，我们最关心的无非就两个问题，一个是垃圾回收器怎么选择，另一个就是对选择的垃圾回收器如何做优化。这里我们分别讲一下。</p><p></p><p>对于垃圾回收器的选择，是需要分业务场景的。如果我们提供的服务对响应时间敏感，并且堆内存能够给到8G以上的，那建议选择G1；堆内存较小或JDK版本较低的，可以选择CMS。相反如果对响应时间不敏感，追求一定的吞吐量的，则建议选择ParallelGC，同时这也是JDK8的默认垃圾回收器。</p><p></p><p><strong>选择完垃圾回收器之后，接下来就针对不同的垃圾回收器，分别做不同的参数优化。</strong></p><p>首先是ParallelGC，其主要配置参数如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/50/10/50387966e16a2c74266f815f6872ea10.png?wh=1258x376\" alt=\"图片\"></p><p>然后是CMS，在ParallelGC配置参数的基础上增加以下配置：</p><p><img src=\"https://static001.geekbang.org/resource/image/e7/ea/e7df72c932f39fb02b3566ab388f83ea.png?wh=1256x556\" alt=\"图片\"></p><p>再说下G1的优化配置（在使用了G1的情况下，就不要设置 -Xmn 和 XX:NewRatio了），同样是在ParallelGC配置参数的基础上增加以下配置：</p><p><img src=\"https://static001.geekbang.org/resource/image/37/6b/37351b2260ffff7384ea30cb43bbb76b.png?wh=1252x196\" alt=\"图片\"></p><p>因为我们秒杀的业务场景更适合选择G1来做垃圾回收器，那这里也给一个在8核16G容器下的JVM配置，具体如下：</p><pre><code class=\"language-plain\">-Xms8192m -Xmx8192m -XX:MaxMetaspaceSize=512m -XX:+UseG1GC -XX:ParallelGCThreads=8 -XX:ConcGCThreads=4 -XX:G1HeapRegionSize=8m\n</code></pre><h2><strong>总结</strong></h2><p></p><p>今天主要围绕着Java，对与其息息相关的Tomcat、JVM、RPC框架以及静态资源的优化，做了分析和讲解。</p><p>对于Tomcat的优化，在秒杀的特定业务场景下针对线程模型的选择，从理论和实际压测上看，NIO2比NIO是有吐吞量的提升，但不是很大，如果为了省事，选择默认的NIO即可。而APR的话，因为我们静态资源都上到CDN了，并且Web服务并不直接对外（请求由Nginx转发过来），也不要求是HTTPS方式，所以这里也不考虑了，和线程池相关的配置，最好按照这节课中的建议做适当的调整。</p><p>同时我们也提到了Servlet在3.0和3.1版本提供的异步非阻塞功能，由于秒杀的接口入参不涉及文件之类的较大消息体，所以IO非阻塞可以不用。而异步功能这块，其实可以有更好的选择，那就是Vertx技术，这也是我们在下节课中，将会单独介绍的一种异步化编程思想技术。</p><p>而对于RPC框架，我们主要介绍了基于NIO开发的一种网络通信框架Netty，了解了Netty主要使用两个池子，即使用Boss Pool和Worker Pool来实现Reactor模式。同时选择了一个具体的RPC框架Dubbo，来做了详细的配置优化讲解。</p><p>在聊完了两种服务的底层线程模型与优化后，我们介绍了静态资源的优化方案，即将静态资源上到CDN，以减轻对秒杀域名流量的压力，同时可以依靠CDN的全国部署，快速加载到对应的静态资源。</p><p></p><p>另外，我们还提到了Java运行的环境JVM，包括垃圾回收器的选择与优化，即如果我们提供的服务对响应时间敏感，并且堆内存能够给到8G以上的，那就选择G1；而堆内存较小或JDK版本较低的，可以选择CMS。相反如果对响应时间不敏感，追求一定的吞吐量的，则建议选择ParallelGC。同时针对不同的垃圾回收器，也给出了对应的优化配置。</p><p></p><p>当然以上所有的优化建议，在调整后都需要做实际业务场景下的压测，毕竟实践才是检测真理的唯一标准！</p><p></p><h2><strong>思考题</strong></h2><p>这节课我们介绍了通过Tomcat发布的Web服务和RPC服务，两者走的底层线程模型是不同的，如果我们的服务既提供HTTP接口，也提供RPC接口，我们该通过何种方式才能将二者的相互影响降至最低呢？</p><p>期待你的思考，也欢迎在留言区中分享讨论。我们下节课再见！</p>","neighbors":{"left":{"article_title":"11｜高性能优化：物理机极致优化","id":428142},"right":{"article_title":"13｜优化番外篇：Vertx介绍及快速入门","id":429877}}},{"article_id":429877,"article_title":"13｜优化番外篇：Vertx介绍及快速入门","article_content":"<p>你好，我是志东，欢迎和我一起从零打造秒杀系统。</p><p>经过前面课程的学习，我们知道Nginx和Tomcat都可以做网关服务，并且从理论出发做了分析比对，也从实践上做了相应服务的开发，那么今天我们将学习一款优秀的、可开发网关服务的技术，即Vertx。该技术的总体性能要优于Tomcat，但弱于Nginx。其在国内的普及度相对国外来说还是比较低的，但已经有些公司开始尝试使用了，比如京东的PC商详页服务、秒杀Web服务都是用它来开发的，并且线上实际效果也很不错。</p><p></p><p>接下来我们将对Vertx做个简单的介绍，并实际搭建一个Vertx项目，来替换demo-web的角色，重新构造秒杀Web系统的一环。</p><p></p><h2><strong>Vertx简介</strong></h2><p>我们先了解一下Vertx可以用来干什么，这样我们才能在已知的技术栈中找出一个和其相对应的技术来帮助理解。</p><p>首先它可以开发Web服务，这点Nginx、Tomcat也能做。</p><p>其次它也有点像Spring，它提供了完整的生态，包括Vertx Web、Vertx Core、Vertx Unit等模块，但它和Spring也不是互斥关系，我们待会搭建的项目中就会使用Vertx+Spring，它们可以配合使用。</p><p>然后它还提供了很多其他的能力，比如EventBus的消息机制，实现服务间通信，同时它还可以支持多种语言的开发。</p><!-- [[[read_end]]] --><p><strong>所以我们很难直接给它做一个精确的定义，但其总体的设计思路就是异步非阻塞。</strong>这里不仅仅是针对我们熟悉的一些请求消息的读写，还包括下游服务的调用，甚至是数据库的读写都可以实现异步，支持你去编写全链路的非阻塞代码。这样可以使用有限的线程，来充分利用机器的CPU资源，当然这并不能缩短业务接口的执行时间，这点你得清楚。</p><p></p><p>那么从以上这几个方面来看的话，我们其实很难用一节课把Vertx技术介绍全面，所以这里我们定个更加好实现的小目标，那就是用Vertx+Spring来开发一个Web服务。你可以在这个过程中，和Nginx还有Tomcat做个简单的对比。</p><p></p><h2><strong>Vertx对比Nginx<strong><strong>和</strong></strong>Tomcat</strong></h2><p>首先，Nginx由于多进程、单线程、多协程的模式，其占用资源更少，并发处理能力更强，再加上其事件驱动、异步非阻塞等特性，总体性能也是三者中最好的，并且比Vertx和Tomcat要强出很多。</p><p>Nginx还可以支持使用Lua、C等语言做业务开发，但大部分以Java为主的公司能够支持的SDK、中间件等相对较少，所以一般都是用它来做反向代理和负载均衡器。因为秒杀的特殊业务场景，故而我们启用了Nginx来做前置网关。</p><p></p><p>Tomcat的话，大部分公司都用它来部署服务，不管是HTTP服务还是RPC服务。虽然底层线程模型一直在迭代更新，新的NIO模式也大大提高了并发处理能力，但由于其历史更久、内部结构更重，所以整体性能也是三者中最差的，但好在普及度高，绝大部分的公司技术栈里都有它。所以在秒杀系统中我们暂时只用其来启动RPC服务，不再用它来部署Web服务了。</p><p></p><p>最后是Vertx，就像上面介绍的那样，其在诞生之初，就是以纯异步化的思想来设计的。其内部提供的几乎所有接口都支持异步，并且所有的操作都是基于事件来实现程序的非阻塞运行。再加上它的网络通信框架集成了Netty，其内部的零拷贝机制、基于内存池的缓冲区重用机制，还有高性能的序列化框架，以及它本身的Multi-Reactor模式，总结来看它的性能是要优于Tomcat的。但由于它仍使用线程池来处理业务请求，所以整体性能是弱于Nginx的。</p><p><strong>它的底层线程模型，大概是这样的，如下图所示：</strong></p><p><img src=\"https://static001.geekbang.org/resource/image/a5/8f/a525b96dd2cfd7cdc0e59f464fef988f.jpg?wh=1091x753\" alt=\"图片\"></p><p>简单来说，Vertx在启动时，可以部署多个Verticle实例，每个Verticle实例都是Actor模型的一种具体实现（其内部定义好了整个流程的处理顺序，当然我们可以针对可扩展项做自定义开发）。</p><p>它接受请求，然后将其封装成事件，并交给EventLoop线程来处理。当然在EventLoop线程中，我们也可以决定是否将后续事件交给Worker线程来处理，比如像调用外部RPC接口等IO操作。</p><p>这里有个黄金原则，即在EventLoop线程里运行的程序一定不能阻塞该线程，否则这将直接影响其处理后续请求的效率。正是因为其有着不错的性能表现，所以在秒杀系统中，我们使用它代替了demo-web，来开发新的Web服务。</p><p></p><p>那在了解了Vertx的一些基本概念之后，咱们来实际搭建一个Vertx Web项目，使其具备demo-web的能力，同时上下游系统demo-nginx和demo-support不用做任何的改动。下面咱们就正式开始吧！</p><p></p><h2><strong>Vertx项目搭建</strong></h2><p><strong>第一步：</strong>新建一个项目demo-vertx-web，并包含两个module，整体项目结构和demo-web类似，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/3c/cc/3cfbc9eaa68e8b8c0bc5be5acc85c9cc.png?wh=764x598\" alt=\"图片\"></p><p>其中demo-vertx-gateway模块用来做一些文件的配置，并且也是用来打包部署的，demo-vertx-service主要用来做业务聚合，这块的代码到时候可以直接将demo-web中的service模块代码拷过来即可。所以我们主要的改动点也都是在demo-vertx-gateway这一块。</p><p></p><p><strong>第二步</strong>：由于没了Tomcat来启动服务，所以我们需要自己写个main方法，来加载对应的配置，完成项目的启动，由于我们仍然使用Spring来管理类，所以这里也通过Spring提供的机制来完成对应配置的加载。如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/42/16/4254467264d63ebc102187208d884e16.png?wh=1920x823\" alt=\"图片\"></p><p>那我们继续看下InitialModule类都配置了些什么：</p><p><img src=\"https://static001.geekbang.org/resource/image/5f/b9/5f4c6a996b938b90a5de67eacd6f70b9.png?wh=1920x1064\" alt=\"图片\"></p><p>这里首先是导入Spring的配置文件spring-config，同时配置Spring的包扫描路径，其次是初始化Vertx，然后开始部署Verticle实例，这里Vertx的初始化配置和部署实例的配置如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/c6/8a/c63a5950d369238b7bc8c11148b8568a.png?wh=1920x893\" alt=\"图片\"></p><p>vertxOptions主要配置了两个属性，即EventLoop线程池大小和Worker线程池大小，而deploymentOptions主要配置了部署的实例数。</p><p>这里要注意一下，一个Verticle实例会被指定到一个EventLoop线程处理，一个EventLoop线程可以处理多个Verticle实例，所以这里的EventLoop线程数最好和CPU核数相等，而部署的实例数，最好小于等于EventLoop线程数，这样可以确保一个线程只对应处理一个Verticle实例。比如你是8核机器，那就配置8个EventLoop线程和8个Verticle实例。</p><p></p><p><strong>第三步：</strong>从上面可以看到，我们部署的实例是MainVerticle，在这里我们可以编排请求的处理流程，先看下代码，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/52/39/5220cb6cdff8c2f0a7d3fc38fd59ca39.png?wh=1740x1668\" alt=\"图片\"></p><p>这里我们首先是创建了一个Router，即路由，这个类主要是用来设置请求的处理逻辑，包括哪个URL请求由哪个类的方法来处理，是让EventLoop线程来执行，还是让Worker线程来执行，处理的过程是什么样的等等。</p><p>其次我们就按上面说的对Router进行配置了。这里分了两种情况，一种是处理动态请求的，一种是处理静态资源请求的。动态请求的配置咱们先放一下，等会细说，这里先说下配置静态资源请求的情况。</p><p>这里统一都是由StaticHandler来处理，同时设置了启用静态资源的缓存，这样就不用每次都读文件了，大大地提高了响应的速度。</p><p>StaticHandler处理静态资源的逻辑是直接根据你请求的URL，然后加上配置的WebRoot，来读取文件。所以比如我们想获取结算页H5，我们的请求URL是/settlement/page，这个时候需要我们reroute一下，重新路由到对应要返回的HTML文件路径，这块也会在下面说到。</p><p></p><p>设置好路由Router之后，我们就可以配置HTTP服务的启动配置了，包括各种HTTP相关的设置，如连接超时配置、端口号设置等。</p><p></p><p><strong>第四步：</strong>这块再详细说下动态路由的配置，我们是通过RouterHelper来做相应配置的。这块的主要功能是将请求URL与对应的处理方法做绑定，并注册到Router，这样请求进来后，就知道该执行哪段业务逻辑了。</p><p><img src=\"https://static001.geekbang.org/resource/image/d0/0d/d0fd1ab2byy795abccd9035710531b0d.png?wh=1920x968\" alt=\"图片\"></p><p>这里首先是从Spring管理的Bean中，找出添加了我们自定义注解RequestMapping的类，然后遍历，将请求URL与对应的类和方法注册到Router中，具体的注册方法如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/c1/69/c151ef7027ac0e2ebb1fd427fc3eb369.png?wh=1920x1204\" alt=\"图片\"></p><p>这里我们指定了业务逻辑由Worker线程来执行，那是怎么指定的呢？</p><p>我们是通过Router的blockingHandler()方法来指定的。如果想在EventLoop线程里执行，则使用route.handler()方法。关于如何合理分配任务，我们有个简单的基本原则，比如你想每秒处理1000个请求，那么理论上每个请求的处理时间不能超过1ms，如果超过了1ms，那就不应该放到EventLoop线程里执行，否则会影响后续请求的处理，所以一般为了简单起见，我们都是将业务逻辑直接分配给Worker线程来处理。</p><p>另外在blockingHandler中，我们可以在执行目标方法之前，增加像监控、限流之类的公共逻辑，有点像拦截器的概念。然后执行目标方法的的调用，这里是通过Java的反射来做的。</p><p><img src=\"https://static001.geekbang.org/resource/image/ca/c7/ca76e89abd8aaee1df8f7c9b07f7cfc7.png?wh=1920x787\" alt=\"图片\"></p><p>这里目标方法的入参，暂时只适配了2种，一个是RoutingContext，另一个是HttpServerRequest。</p><p>这是Vertx的一个弊端，它没有提供直接的功能，无法像SpringMVC一样方便，能够支持在Controller的方法入参里直接定义我们想要的变量来接受入参的值，得需要我们自己去扩展。所以这里为了简便，我们直接先将原始的RoutingContext或HttpServerRequest往下传，其中RoutingContext是一次请求的上下文，HttpServerRequest是将HTTP请求的相关信息都封装进去了，包括入参、Header等。</p><p>另外这里要重点关注一下，blockingHandler()方法的第二个入参，可以设置Hander是顺序执行还是并发执行。这个是指同一个Verticle实例下，同一个适配URL，默认是true，但在高并发场景下，需要设置成false，否则吞吐量上不去。</p><p></p><p>最后，在执行完目标方法之后，需要将响应结果返回。我们根据响应类型，也做了区分处理，目前支持两种，一个是JSON返回，另一个是HTML返回。对于HTML的返回，我们reroute到了真实的静态文件路径，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/35/53/359807dyyb6a64d6136179592cff5153.png?wh=1920x986\" alt=\"图片\"></p><p>并且在异常时，也做同样的区分处理。</p><p></p><p><strong>第五步：</strong>到这里，一些核心逻辑的编写就完成了。下面再看一个业务Handler的示例，为了让你适应SpringMVC的使用习惯，所以这里的写法风格上也是类似的：</p><p><img src=\"https://static001.geekbang.org/resource/image/b4/38/b41d3e40600ec4409451c772bc9af038.png?wh=1920x732\" alt=\"图片\"></p><p>这里要记得加上Spring的@Component注解，这样Spring才能将其管理起来。同时也要加上自定义的@RequestMapping注解，这样才能被我们自己的逻辑扫到。</p><p>那下面再展示下两种响应类型的写法，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/2c/00/2c1f6e5bb3e45a6f8b40444ff64e9100.png?wh=1920x943\" alt=\"图片\"></p><p>一个是默认返回JSON，另一个是返回HTML（真实的HTML文件路径），HTML的返回需要指定RT的类型。</p><p></p><p>其他的如Dubbo相关配置，都是和demo-web一样的，剩下的我们只需要将demo-web中的业务代码拷过来即可。唯一有个变动的点，就是在活动查询接口有个请求跨域问题，需要在Nginx中设置响应结果的Header，其他的都没有变化。</p><p>那这样，咱们的demo-vertx-web项目就算搭建完成了，之后可以按照以前的测试方式，从商详页进入到结算页然后完成下单，测试整个秒杀流程，这里就不再复述了。</p><p></p><h2>总结</h2><p>这节课我们初步认识了Vertx，这是一种以异步化思想来设计的技术。其内部提供的几乎所有接口都是异步的，并且像传统的RPC调用、数据库读写等阻塞操作，Vertx也都提供了异步化、非阻塞的解决方案。</p><p>这和我们传统的开发方式有所不同，你可以借助Vertx习惯这种新的开发思想。当然异步化编程势必会增加代码的复杂度，这也是其弊端。而对于开发Web服务这块，我们横向对比分析了Vertx与Nginx、Tomcat的优劣势，其性能介于Tomcat与Nginx之间，而这三种技术都有其自身的优缺点，并且我们在秒杀系统中都有使用到。</p><p>像Nginx，性能最优，我们用其来做前置网关，直面大流量的冲击；Vertx性能次之，所以我们用其来开发业务Web服务；Tomcat使用起来最方便也最普及，可以用来发布RPC服务，或者是像ERP这种小流量的Web服务。</p><p>同时在今天这节课中，我们也用了较多的篇幅，来讲解Vertx开发Web服务的详细过程，帮助你更直观地学习Vertx，并投入到实际的使用中。</p><p>虽然如此，但今天介绍的也仅仅是Vertx的冰山一角，这里只是起到抛砖引玉的作用，Vertx所具备的能力绝对不止这些。如果你感兴趣，可以自己做进一步的学习，当然更多的相关开发使用，也可以关注我的GitHub，我们一起交流学习。</p><p></p><h2><strong>思考题</strong></h2><p>这节课我们实际开发的Vertx项目，处理业务逻辑这块，仍然使用的是Worker线程池，这块和Tomcat没有太大区别。如果我们使用Vertx提供的异步化API，该如何改造现有代码呢？又会带来怎样的影响？</p><p>期待你的思考，欢迎你来评论区和我讨论问题，交流经验！我们下节课再见。</p>","neighbors":{"left":{"article_title":"12｜高性能优化：单机Java极致优化","id":429098},"right":{"article_title":"14｜百万级流量秒杀系统的关键总结","id":431399}}},{"article_id":431399,"article_title":"14｜百万级流量秒杀系统的关键总结","article_content":"<p>你好，我是志东，欢迎和我一起从零打造秒杀系统。</p><p>经过前面课程的介绍，相信你已经能够对秒杀系统的设计和实施有了比较深入的理解，也能够在自己的项目中去应用这些设计原则和方法了。那么我们的课程也差不多到尾声了，这一节课我们主要做一下总结，和你一块回顾之前的学习内容。</p><p>正如<a href=\"https://time.geekbang.org/column/article/420765\">开篇词</a>所讲，我们主要是从系统准备、着手搭建、系统高可用、一致性以及性能优化等维度进行秒杀系统的学习。为了便于你总结，我把每节课的重点整理成了下面这张思维导图，带你系统复习一下秒杀系统的全部内容。</p><p><img src=\"https://static001.geekbang.org/resource/image/e3/5e/e3d3c41e084278a5b8c7d820c1b68c5e.jpg?wh=1920x1422\" alt=\"图片\"></p><h2><strong><a href=\"https://time.geekbang.org/column/article/420777\">01 秒杀系统的业务挑战和设计原则</a></strong></h2><p>第一节，我首先介绍了秒杀的业务特点和挑战。秒杀是电商平台大促狂欢时非常重要的手段之一，用具有价格优势的稀缺商品，来增加电商平台的关注度，带来空前的流量。<strong>因此，秒杀的主要挑战在于：</strong></p><ul>\n<li>高并发产生的巨大瞬时流量。秒杀活动的特点，就是将用户全部集中到同一个时刻，然后一起开抢某个热门商品，而热门商品的库存往往又非常少，因此聚集效应产生了巨大的瞬时流量。</li>\n<li>高并发无法避开的热点数据问题。秒杀活动大家抢购的都是同一个商品，所以这个商品直接就被推到了热点的位置。</li>\n<li>来自黑产的刷子流量。刷子高频次的请求，会挤占正常用户的抢购通道，也获得了更高的秒杀成功率。这不仅破坏了公平的抢购环境，也给系统服务带来了巨大的额外负担。</li>\n</ul><!-- [[[read_end]]] --><p>接着，我们从技术层面介绍了HTTP服务的请求链路路径。我们讨论了将秒杀系统提供的业务功能，按不同阶段、不同响应，合理地拆分到不同的链路层级来实现，以符合我们校验前置、分层过滤、缩短链路的设计原则，并能够从容应对秒杀系统所面临的瞬时大流量、热点数据、黄牛刷子等各种挑战。</p><h2><strong><a href=\"https://time.geekbang.org/column/article/422016\">02 秒杀系统架构设计和环境准备</a></strong></h2><p>在这一节里，针对秒杀系统，我们将传统的架构设计与我们新的架构设计做了一个对比，可以看出传统架构设计的局限性。其中列举了域名带宽问题和Tomcat服务器性能问题，新的架构设计将Web网关职能前置，尽量在流量入口处拦截掉风险流量，缩短请求链路，保护下游系统，并提高服务的响应速度。</p><p>技术选型时，我们采用的是<strong>主流的技术栈</strong>，Web服务和RPC服务的基础框架都是使用SpringMVC，RPC框架使用的是Dubbo，数据库使用免费开源的MySQL，分布式缓存数据库使用Redis。</p><h2><strong><a href=\"https://time.geekbang.org/column/article/423075\">03 一步一步搭建秒杀系统（上）</a></strong></h2><p>在这节课中我们开始开发一个最简的秒杀系统，共设计了 <strong>3个系统项目</strong>：一个是demo-nginx，用来做真正的网关入口；另一个是demo-web，用来做业务的聚合；最后一个是web-support，用来做基础数据和服务的支撑。</p><h2><strong><a href=\"https://time.geekbang.org/column/article/423966\">04 一步一步搭建秒杀系统（下）</a></strong></h2><p>在第03课的基础上，这节课我们梳理了秒杀的业务流程和系统的关键接口，接着通过<strong>七个步骤</strong>实现了秒杀的关键业务，在本地实现了“秒杀活动的创建-&gt;活动开始的打标-&gt;从商详页进秒杀结算页-&gt;提交订单-&gt;活动的关闭与去标”的完整交互，让我们以“摸得着”的方式去近距离地接触秒杀系统。</p><h2><strong><a href=\"https://time.geekbang.org/column/article/424175\">05 秒杀的隔离策略</a></strong></h2><p>这节课开始我们进入了秒杀的高可用专题，我们介绍了秒杀隔离，它是秒杀系统高可用体系非常重要的一个环节。如果不做隔离，任由流量互相横冲直撞，将会对电商平台的普通商品售卖造成很大的影响。隔离的措施概括下来有三种：<strong>业务隔离、系统隔离和数据隔离</strong>。</p><p>在隔离过程中，一般购物车和订单不需要做特殊定制，只需要根据流量情况进行专门部署即可。而挑战比较大的就是秒杀的结算页系统，它是秒杀流量的主要入口，承担着把瞬时流量承接下来并进行优质流量筛选的重任，因此如何搭建秒杀结算页的高可用、高性能和高并发至关重要。</p><p>为了对秒杀的结算页系统进行隔离，核心思路是对商品进行打标，当用户在详情页点击秒杀操作的时候，我们就能根据商品是否秒杀的标识，跳转到普通商品结算页流程，或是隔离出来的专用秒杀结算页系统。</p><h2><strong><a href=\"https://time.geekbang.org/column/article/424215\">06 秒杀的流量管控</a></strong></h2><p>这节课我们介绍了主流电商平台通用的营销方式：<strong>预约+秒杀</strong>。通过事前引入预约环节，进行秒杀参与人数的把控，起到秒杀流量管控的目的。通过预约控制参与人数上限，只有预约过的会员才有秒杀资格，就可以防止过多人数对秒杀抢购造成冲击。</p><p>除此之外，这节课我们还重点学习了预约系统的设计思路，介绍了预约系统的推荐架构设计，关键的两张数据库表，以及预约系统需要提供的接口。根据这些思路，你可以很快速地搭建出一个比较简单的预约系统。</p><h2><strong><a href=\"https://time.geekbang.org/column/article/424503\">07 秒杀的削峰和限流</a></strong></h2><p>这节课我们介绍了事中控制流量的方式，有验证码、问答题、消息队列以及限流等，这些削峰的方式都可以达到控制流量的目的。</p><p>我们重点学习了验证码的设计和实现，通过代码了解了验证码的生成和校验两个过程。在验证码设计时，为了交互更加安全，我们需要<strong>加入签名机制</strong>，同时验证通过后，需要<strong>加入后端黑名单</strong>，避免多次验证。验证码是一种非常常见的防刷手段，大多数网站的登录模块中，为避免被机器人刷，都会加入图片验证码。而在秒杀系统中，我们除了用验证码来防刷外，还有一个目的就是通过验证码进行削峰，以达到流量整形的目的。</p><p>接着我们重点介绍了秒杀的几种限流方式，和其他削峰方式相比，限流是有损的。限流是根据服务自身的容量，无差别地丢弃多余流量，对于被丢弃的流量来说，这块的体验是受损的。另外，因为秒杀流量会经历很多交易系统，所以我们在设计时需要从起始流量开始，分层过滤，逐级限流，这样流量在最后的下单环节就是少量而可控的了。</p><p>在demo-nginx层，我们主要采用的是Nginx自带模块进行网关限流，而在demo-web层主要采用的是线程池限流来控制并发数和基于令牌桶的API限流方法。</p><h2><strong><a href=\"https://time.geekbang.org/column/article/426067\">08&nbsp;降级、热点和容灾处理</a></strong></h2><p>这节课我们主要讨论了秒杀的降级策略，热点数据的处理方式以及“同城双活”的容灾方案。</p><p>降级的设计非常重要，它是系统故障发生时你的逃生路径。这一节课里，我们学习了几种常见的降级场景和解决方法。这些方法都可以结合你的业务场景进行应用。</p><ul>\n<li><strong>写服务降级：</strong>牺牲数据一致性获取更高的性能，在大厂的设计中比较常见，对于异步造成的数据丢失等一致性问题，一般会有定时任务一直在比对，以便最快发现问题，进行修复。</li>\n<li><strong>读服务降级：</strong>在做高可用系统设计时，我们认为微服务自身所依赖的外部中间件服务或者其他RPC服务，随时都可能发生故障，因此我们需要建设多级缓存，以便故障时能及时降级止损。</li>\n<li><strong>简化系统功能：</strong>在秒杀场景下，并不是页面信息越丰富越好，要视情况而定。秒杀系统要求尽量简单，交互越少，数据越小，链路越短，离用户越近，响应就越快，因此非核心的功能，比如商品的收藏总数量、商品的排行榜、评价和推荐等楼层在秒杀场景下都是可以降级的。</li>\n</ul><p>接着我们还学习了秒杀的热点数据处理，热点数据是秒杀系统的基本属性，读热点问题的解决遵循朴素的思路，通过增加数据副本数来扛流量，同时尽量让数据靠近用户。</p><p>这里也介绍了 <strong>3种写热点解决方法：</strong>一是本地缓存，延迟提交；二是将写热点数据进行分片；三是单SKU限流。实际上，Redis的单片写能力可以达到几万QPS，所以即便是秒杀扣库存这样的写热点操作，通过单SKU限流也能应对。</p><p>最后，我重点介绍了“同城双活”的容灾方案，本质上多活的难点就是数据的复制和一致性问题，因此比较主流的做法是同城单写。通过秒杀系统的同城双活设计，你可以看到，不管是Nginx集群、Tomcat集群、Redis集群，还是MySQL集群，我们都可以灵活进行机房间切换，在故障时快速恢复。</p><h2><strong><a href=\"https://time.geekbang.org/column/article/426696\">09 黑产对抗——防刷和风控</a></strong></h2><p>这节课我们主要介绍了如何对抗黑产以及应对方案。</p><ul>\n<li><strong>Nginx有条件限流机制：</strong>直接有效拦截针对接口的高频刷子请求，可以有效解决黑产流量对单个接口的高频请求。</li>\n<li><strong>Token机制：</strong>可以有效防止黑产流量跳过中间接口，直接调用下单接口。</li>\n<li><strong>黑名单机制：</strong>简单、高效，配置合理可以拦截大部分刷子。</li>\n<li><strong>风控：</strong>风控体系需要建立在大量的数据之上，并且要通过复杂的实际业务场景考验，不断地做智能修正，逐步提高风险识别的准确率。</li>\n</ul><h2><strong><a href=\"https://time.geekbang.org/column/article/427445\">10 秒杀的库存与限购</a></strong></h2><p>这节课我们重点探讨了限购和库存。限购的作用有两个，一个是限制用户在确定时间内的购买单数和商品件数，比如限制同一手机号每天只能下1单，每单只能购买1件，并且一个月内只能购买2件，确保秒杀的公平性，让爆品惠及更广泛的用户；另一个作用是充当活动库存的用途，通过限购控制每天的投放总量，或者整个活动的投放总量。</p><p>所以我们的重点就放在了活动库存的扣减方案设计上，讨论了出现超卖的场景以及如何规避。我们从纯技术的角度分析了<strong>库存超卖发生的两个原因</strong><strong>：</strong>一个是库存扣减涉及到的两个核心操作，查询和扣减不是原子操作；另一个是高并发引起的请求无序。</p><p>我们的应对方案是利用Redis的单线程原理，通过Lua来实现库存扣减的原子性和顺序性，并且经过实测也确实能达到我们的预期，且性能良好，从而有效地解决了秒杀系统所面临的库存超卖挑战。</p><h2><strong><a href=\"https://time.geekbang.org/column/article/428142\">11 高性能优化：物理机极致优化</a></strong></h2><p>从这节课开始我们进入高性能优化专题，我们介绍了物理机与Nginx相关配置的优化，优化的方向是对内存、CPU、IO（磁盘IO和网络IO）的优化。</p><p>对于物理机，我们主要<strong>从调整CPU的工作模式入手</strong>，将CPU模式切换成高性能模式，以得到更好的响应性能。另外在秒杀高峰期间，我们也做了针对性的措施，即通过绑定专门CPU来处理网卡中断。</p><p>当然绑核的操作不只可以针对网卡中断，还可以绑定Nginx进程以及部署的其他应用服务。这么做的目的，一方面是为了减少CPU调度产生的开销，另一方面也可以提高每个CPU核的缓存命中率。</p><p>接着我们又讨论了Nginx的优化，分别针对客户端以及下游服务端，从网络的连接、传输、超时等方面做了不同的配置讲解。具体的Nginx优化配置你可以参考以下示例：</p><pre><code class=\"language-plain\">#工作进程：根据CPU核数以及机器实际部署项目来定，建议小于等于实际可使用CPU核数\nworker_processes 2;\n\n#绑核：MacOS不支持。\n#worker_cpu_affinity&nbsp; &nbsp;01 10;\n\n#工作进程可打开的最大文件描述符数量，建议65535\nworker_rlimit_nofile 65535;\n\n#日志：路径与打印级别\nerror_log logs/error.log error;\n\n\n\nevents {\n&nbsp; &nbsp; #指定处理连接的方法，可以不设置，默认会根据平台选最高效的方法，比如Linux是epoll\n&nbsp; &nbsp; #use epoll;\n&nbsp; &nbsp; #一个工作进程的最大连接数：默认512，建议小于等于worker_rlimit_nofile\n&nbsp; &nbsp; worker_connections 65535;\n&nbsp; &nbsp; #工作进程接受请求互斥，默认值off,如果流量较低，可以设置为on\n&nbsp; &nbsp; #accept_mutex off;\n&nbsp; &nbsp; #accept_mutex_delay 50ms;\n}\n\nhttp {\n&nbsp; &nbsp; &nbsp; &nbsp; #关闭非延时设置\n&nbsp; &nbsp; &nbsp; &nbsp; tcp_nodelay&nbsp; off;\n&nbsp; &nbsp; &nbsp; &nbsp; #优化文件传输效率\n&nbsp; &nbsp; &nbsp; &nbsp; sendfile&nbsp; &nbsp; &nbsp;on;\n&nbsp; &nbsp; &nbsp; &nbsp; #降低网络堵塞\n&nbsp; &nbsp; &nbsp; &nbsp; tcp_nopush&nbsp; &nbsp;on;\n\n&nbsp; &nbsp; &nbsp; &nbsp; #与客户端使用短连接\n&nbsp; &nbsp; &nbsp; &nbsp; keepalive_timeout&nbsp; 0;\n&nbsp; &nbsp; &nbsp; &nbsp; #与下游服务使用长连接,指定HTTP协议版本，并清除header中的Connection，默认是close\n&nbsp; &nbsp; &nbsp; &nbsp; proxy_http_version 1.1;\n&nbsp; &nbsp; &nbsp; &nbsp; proxy_set_header Connection \"\";\n\n&nbsp; &nbsp; &nbsp; &nbsp; #将客户端IP放在header里传给下游，不然下游获取不到客户端真实IP\n&nbsp; &nbsp; &nbsp; &nbsp; proxy_set_header X-Real-IP $remote_addr;\n\n&nbsp; &nbsp; &nbsp; &nbsp; #与下游服务的连接建立超时时间\n&nbsp; &nbsp; &nbsp; &nbsp; proxy_connect_timeout 500ms;\n&nbsp; &nbsp; &nbsp; &nbsp; #向下游服务发送数据超时时间\n&nbsp; &nbsp; &nbsp; &nbsp; proxy_send_timeout 500ms;\n&nbsp; &nbsp; &nbsp; &nbsp; #从下游服务拿到响应结果的超时时间（可以简单理解成Nginx多长时间内，拿不到响应结果，就算超时），\n        #这个根据每个接口的响应性能不同，可以在每个location单独设置\n&nbsp; &nbsp; &nbsp; &nbsp; proxy_read_timeout 3000ms;\n&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; #开启响应结果的压缩\n&nbsp; &nbsp; &nbsp; &nbsp; gzip on;\n&nbsp; &nbsp; &nbsp; &nbsp; #压缩的最小长度，小于该配置的不压缩\n&nbsp; &nbsp; &nbsp; &nbsp; gzip_min_length&nbsp; 1k;\n&nbsp; &nbsp; &nbsp; &nbsp; #执行压缩的缓存区数量以及大小，可以使用默认配置，根据平台自动变化\n&nbsp; &nbsp; &nbsp; &nbsp; #gzip_buffers&nbsp; &nbsp; &nbsp;4 8k;\n&nbsp; &nbsp; &nbsp; &nbsp; #执行压缩的HTTP请求的最低协议版本，可以不设置，默认就是1.1\n&nbsp; &nbsp; &nbsp; &nbsp; #gzip_http_version 1.1;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; #哪些响应类型，会执行压缩，如果静态资源放到CDN了，那这里只要配置文本和html即可\n&nbsp; &nbsp; &nbsp; &nbsp; gzip_types&nbsp; &nbsp; &nbsp; text/plain;\n\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; #acccess_log的日志格式\n&nbsp; &nbsp; &nbsp; &nbsp; log_format&nbsp; access&nbsp; '$remote_addr - $remote_user [$time_local] \"$request\" $status '\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; '\"$upstream_addr\" \"$upstream_status\" \"$upstream_response_time\" userId:\"$user_id\"';\n\n&nbsp; &nbsp; &nbsp; &nbsp; #加载lua文件\n&nbsp; &nbsp; &nbsp; &nbsp; lua_package_path \"/Users/~/Documents/seckillproject/demo-nginx/lua/?.lua;;\";\n&nbsp; &nbsp; &nbsp; &nbsp; #导入其他文件\n&nbsp; &nbsp; &nbsp; &nbsp; include /Users/~/Documents/seckillproject/demo-nginx/domain/domain.com;\n&nbsp; &nbsp; &nbsp; &nbsp; include /Users/~/Documents/seckillproject/demo-nginx/domain/internal.com;\n&nbsp; &nbsp; &nbsp; &nbsp; include /Users/~/Documents/seckillproject/demo-nginx/config/upstream.conf;\n&nbsp; &nbsp; &nbsp; &nbsp; include /Users/~/Documents/seckillproject/demo-nginx/config/common.conf;\n}\n</code></pre><h2><strong><a href=\"https://time.geekbang.org/column/article/429098\">12 高性能优化：单机Java极致优化</a></strong></h2><p>这一节课主要围绕着Java，分析和讲解了与其息息相关的Tomcat、JVM、RPC框架以及静态资源的优化。</p><p>对于Tomcat的优化，在秒杀的特定业务场景下针对线程模型的选择，NIO2从理论和实际压测上看，比NIO是有吐吞量的提升，但不是很大，如果为了省事，选择默认的NIO即可。对于RPC框架，我们主要介绍了Netty的Boss Pool和Worker Pool来实现Reactor模式。</p><p>接着，我们介绍了静态资源的优化方案，即<strong>将静态资源上到CDN</strong>，以减少对秒杀域名流量的压力，同时可以依靠CDN的全国部署，快速加载到对应的静态资源。</p><p></p><h2><strong><a href=\"https://time.geekbang.org/column/article/429877\">13 优化番外篇：Vertx介绍及快速入门</a></strong></h2><p>这一节初步介绍了Vertx，<strong>Vertx提供了异步化、非阻塞的解决方案</strong>。和我们传统的开发方式有所不同，异步化提升了性能，当然异步化编程势必会增加代码的复杂度，这也是其弊端。</p><p>接着我们横向对比分析了Vertx与Nginx、Tomcat的优劣势，其性能介于Tomcat与Nginx之间。像Nginx，性能最优，我们用其来做前置网关，直面大流量的冲击；Vertx性能次之，所以我们用其来开发业务Web服务，但Vertx受众小，有一定的门槛，开发者难寻；Tomcat使用起来最方便也最普及，可以用来发布RPC服务，或者是像ERP这种小流量的Web服务。</p><h2>思考题</h2><p>到这节课为止，我们已经把秒杀课程的核心内容介绍完了，相信经过体系化的学习，你已经掌握了秒杀的基本设计思路，以及能够着手自己进行高可用、高性能、高并发的系统搭建。</p><p>那么除了以上介绍的这些内容，你觉得还有哪些方面也是需要我们考虑的呢？例如，系统的压测、监控和应急？或者还有么？请你先思考，我们下一节课再来讨论！</p>","neighbors":{"left":{"article_title":"13｜优化番外篇：Vertx介绍及快速入门","id":429877},"right":{"article_title":"结束语｜秒杀系统之上的业务协同思考","id":432014}}},{"article_id":432014,"article_title":"结束语｜秒杀系统之上的业务协同思考","article_content":"<p>你好，我是志东，这是专栏的最后一节课。很高兴在这里遇见你，这说明你选择了坚持！</p><p>本专栏虽然较短，但我们已经从技术的角度对秒杀系统的高可用、高性能、一致性等方面进行了深入的讨论和学习，相信你已经有了不少的收获。</p><p>那在正式结课之前，我想我还有一些压箱底的东西是可以和你分享的，关于秒杀系统之上的其他思考，这些都是比较宝贵的经验总结。也许未来，当你真正有机会参与大厂的百万级流量的秒杀系统建设时，这些思考可以帮助你少走弯路，从容应对挑战。</p><h2>如何预估秒杀活动的流量？</h2><p>如果你身处电商大厂核心系统的开发团队，你一定知道，这些电商平台在每年大促前，都会有几个月的备战期。而在备战期，最重要的一个事情，就是对核心业务链路进行系统压测，找到系统最大承压能力，再评估最大承压能力是否能满足业务预估的备战目标，如果不满足就需要进行相应的优化和扩容。</p><p>这里提到的业务流量预估，对于电商大盘来说，相对比较容易一些。业务结合自己的销售目标可以预估个大致的GMV涨幅和订单涨幅，在业务的基础上适当增加点buffer，就可以作为技术侧的同比备战目标，这样压测目标也就出来了。</p><p>举个例子，假如业务今年双11预期销售同比增长30%，那技术侧可以按照同比1.4倍或1.5倍来进行备战。比如下单接口去年双11的QPS为10000/s，那么今年我们就要准备15000/s的下单能力。除了下单接口，核心交易流程的各个链路都可以参照这个逻辑，比如进购物车接口，去年的QPS为10w/s，那么今年就准备15w/s，促销接口、优惠券接口、商品详情接口等都以此类推。</p><!-- [[[read_end]]] --><p><strong>在流量比较均衡增长且没有突发瞬时流量的场景下，以上的预估逻辑没有问题，但是在秒杀场景下，这种按照同比倍数的预估逻辑就不一定能奏效了。</strong></p><p>试想一下，在2020年疫情最严重的时候，全国口罩紧缺的情况下，那时候上线口罩秒杀活动，确实很难对流量进行准确预估。我记得当时第一场口罩秒杀活动开始前，技术团队虽然预估到流量会很大，但是究竟有多大没有人能给出相对准确的数据。虽然我们紧急进行了3倍容量的系统扩容，但其实面对未知的流量，我们的扩容能不能撑住流量，心里真没有底。</p><p>事实也证明，京东在前几场的口罩秒杀活动时，因为流量过大、评估不足，出现过部分用户商详页白屏、结算页白屏的情况。面对这些问题，技术团队日夜奋战，经过几个通宵的紧急优化，系统才调整到最佳状态，最终能够承接300万人同时秒杀。</p><p>毫不夸张地说，口罩SKU的秒杀活动，是互联网秒杀历史上流量最高的单个SKU，没有之一。在当时大厂纷纷采用抽签方式进行口罩派发时，只有京东采用预约+秒杀的方式，这体现了京东技术团队强大的技术能力和自信。</p><p>瞬时流量的预估确实是个难题，不仅仅是秒杀系统，大家熟知的微博突发热点事件，也有类似的问题。流量明星突然宣布结婚离婚，都会对系统造成直接冲击，所以坊间有个说法，明星火不火，够不够TOP，就看能不能搞挂微博。虽然是有点戏谑的说法，但也确实反映了突发瞬时流量背后巨大的技术挑战。</p><p><strong>那面对秒杀的突发瞬时流量，我们是不是就束手无策，坐以待毙呢？</strong></p><p>那倒也不是，前面的课程已经介绍过了，通过对流量的提前管控，我们可以有个初步预估，再结合前面介绍的削峰、限流、降级等高可用手段，我们是能够应对秒杀的挑战的。</p><p>另一方面，任何一次的失败都是宝贵的财富。我们当时通过对一开始几次口罩活动出现问题的复盘总结，就摸清楚了流量的大致范围以及流量的大致组成，多少用户流量，多少刷子流量，再结合库存情况和用户体验考量，就可以有针对性地进行扩容，调整限流阈值。</p><p>最后，通过前几场活动信息的收集，我们找到了少量库存下（库存&lt; 5w），秒杀系统能承载的普遍模式。在这种模式下，参与用户最多，系统资源利用最大化，用户抢购体验最佳。这种模式，在经过验证后，可以非常快速地适用到其他秒杀场景，具备通用性。</p><p>因此，面对不可控的秒杀瞬时流量预估问题，我们要化被动为主动，转化成为在一定库存下，结合系统资源和抢购体验，秒杀系统需要服务多少流量的问题。</p><h2>如何做好跨团队的业务协同？</h2><p>参与秒杀活动的都是稀缺爆品，非常火爆，一旦活动处理不当，可能出现大规模群诉事件。更夸张的，可能演变成为一个公共危机事件，占据热搜头条，给公司和商家的声誉造成负面影响。</p><p>因此，秒杀活动除了本专栏提到的技术挑战外，业务的挑战同样巨大。所以，秒杀活动的顺利完成，不仅仅需要技术团队的努力，更需要公司内跨部门的紧密配合、高度协同，才能共同完成业务目标。涉及的团队包括运营团队、产品团队、技术团队、客服团队、法务团队、公关团队等。</p><p>运营团队负责采购和销售，连接供应商和用户，制定商品秒杀活动的销售计划；产品和技术团队落地业务诉求，保障秒杀系统平稳运行，确保活动正常开展；客服团队处在第一线，需及时安抚用户和反馈用户心声；法务和公关团队要对活动中可能出现的法律和公关问题进行评估，给出指导建议。</p><p>大的电商平台在做爆品秒杀活动计划的时候，比如茅台，需要提前联动各团队，进行各种风险点评估，只有准备充分之后，才会上线秒杀活动。</p><p><strong>因此，项目之初，我们就需要成立一个各个团队核心成员组成的虚拟项目小组，主要工作内容包括事前、事中和事后几个部分。</strong></p><p>事前，针对秒杀活动的各个环节，进行全流程串联以及风险评估，提前将可能的技术问题和业务问题识别出来，进行补漏和改进。事中，针对活动过程中出现的问题，快速响应，及时灭火，将损失和影响最小化。事后，全团队进行总结复盘，为流程和系统提供优化建议。</p><p>上面提到的业务协同内容还是比较抽象的，我们可以结合几个案例再看看，具象化业务协同会涉及到的内容，感受其重要性。</p><p><strong>第一个案例：</strong>我们知道秒杀活动具有非常强的引流作用，因为参与秒杀的都是高价值的爆品，比如1499元平价茅台，抢到一瓶马上转手能赚1000元，这些商品天生具备高流量特质，这个特点也很容易被商家盯上加以利用。在2020年618大促前夕，就有一个酒商，看到京东自营的茅台秒杀模式后，就拿出一瓶茅台库存，来进行1499元预约秒杀活动，主要目的是给自己的店铺增加曝光度和用户关注度。当技术侧监控到这个问题后，立即召集虚拟协同团队开会商讨解决方案。</p><p>你可能会问，为啥平台要介入商家的营销活动？正常一般不会，但是像这种没有提前规划和报备的活动，会给平台带来不少的危害。</p><p>一是平台需要消耗大量的硬件资源来应对这个秒杀；二是任何一场秒杀背后，都需要技术人员的全力保障，为了一个库存，耗费这么多的人力物力资源，投入产出太低。另一方面，当几十万甚至上百万人来秒杀一个库存时，意味着几乎所有人都抢不到，一旦宣传出去，处理不好就会上升到“平台虚假宣传”的舆情高度上来，对平台的伤害很大。</p><p>因此这就需要运营、商家、客服、公关、法务等一块讨论，协商善后方案，避免大规模群诉和舆情。</p><p><strong>第二个案例：</strong>是正常上架商品时导致的投诉事件。你可能会问，上架商品不是正常的操作吗？怎么还会有投诉？听我慢慢和你说，当平价茅台已经按照固定时间点进行预约秒杀活动后，用户已经习惯了这种售卖方式，这种情况下，用户没有买到，会怪自己运气和手速，而不会推责给平台。</p><p>在去年年底的时候，业务有非常少量的库存需要在12月30日前清掉，想着快速卖掉完事，就没有通过预约秒杀营销方式，而是直接上架了商品当做普通商品售卖。库存卖完没几分钟，没想到紧接着就是大量的客诉进来，给一线客服带来了巨大的压力。为什么会投诉？理由也很容易理解，黄牛们会投诉平台没有按照原有规划投放库存，突然进行售卖，质疑平台内部有猫腻，投放给自己员工。</p><p>可见，对于这种千万只眼睛盯着的爆品，卖与不卖，如何售卖，都是压力巨大，需要业务、客服、法务等协同一致，按照既定计划进行，任何的计划变更，需要团队一起进行流程串联和推演。</p><p>另外，当平台上线了风控和限购后，黄牛被拦截在外，他们的利益受到损害，他们就会制造各种谣言和舆论来给平台压力。比如会在各种媒体曝光所谓的平台漏洞、技术漏洞，试图混肴视听，希望平台在各种压力之下变更售卖规则，从中谋利。这时候，就需要技术、客服、公关和法务部门通力合作，从技术角度消除谣言，客服要顶住黄牛压力，公关部门要联动媒体进行投诉删文，避免事件扩大化。</p><p><strong>第三个案例：</strong>运营、产品、技术、客服、法务等需要对秒杀全场景下出现的所有面向用户侧的文案通盘评审，对不合理的文案，需要客服和法务的专业意见进行优化。</p><p>比如，如果用户是因为已经买到了上限被限购拦住了，那我们可以直接文案提示“您本月已经购买过2瓶，达到上限”，这个文案对用户比较直观也能接受，因为规则就是这样定的。</p><p>如果用户被风控识别为黄牛，被风控拦截不能下单，那我们能不能直接提示“您是风险用户，不能购买”？显然不能，这样的文案会招来黄牛的投诉。因此，这种情况应该展示何种文案以及后续如何处理，需要客服和法务的专业意见，一般这种黄牛用户，我们的文案可以直接提示“很抱歉没有抢到，下次再来”。</p><p>再来，系统在运行过程中，也会出现抖动、接口超时以及流量过大被限流的情况，那我们要怎样友好地提示用户呢？</p><p>在普通售卖场景，我们这样提示“系统开了小差，请你稍后重试”，“当前参与人数多，系统繁忙，请你稍后重试”，一般也不会有太大问题。但是在秒杀场景，就可能招来大量客诉，因为商品非常昂贵，一旦出现系统异常文案，用户就会怪罪于平台的问题而导致他没有抢到，要求赔偿。</p><p>因此秒杀的文案，还是需要结合法务和客服的意见，修改为“很抱歉没有抢到，下次再接再厉”。你可能会觉得这样修改文案，对用户不公平，实际上你仔细想想，如果用户被限流，本身就表示他的手速还是慢了，提示“没有抢到”也合理。</p><p>综上几个案例，可见秒杀活动的开展不仅仅是运营和技术的事情，需要公司内各个部门协同联动，共同保障业务顺利开展。</p><h2>如何快速发现爆品？</h2><p>有了各部门的业务协同联动机制，还有一个事情需要技术侧提供，那就是快速地发现爆品，及时进行预警，联动各部门协同处理。因此，如何快速发现爆品就很关键了。</p><p>对于热点爆品的发现，技术上可以归结为Redis热点数据的发现。方法也比较简单，首先会在一个周期内对key进行请求统计，在达到请求量级后会对热点key进行收集和预警，反馈给虚拟联动小组决策处理。</p><h2>如何建设监控应急体系？</h2><p>在搭建秒杀系统高可用时，需要有一套监控应急体系的支撑，各个大厂都会花大把的精力来重点建设。这里我也整理了监控应急体系建设的思维导图，供你参考，涉及以下几个重要的方面：目标、发现问题、监控维度、问题原因、问题解决、问题复盘、演练/值班/报备制度等。</p><p>下面我就几个重要的方面详细展开讨论。</p><p><strong>发现问题</strong>：当系统出现异常的时候，我们要能第一时间感知问题、发现问题。而发现问题的途径一般又分为被动和主动，被动的有舆情事件被关注、被用户投诉、订单或资损被业务投诉、兄弟研发部门群里通知；主动的主要是指研发能够根据报警感知系统变化。对监控体系的建设来说，我们希望能做到，系统的异常都是主动通过报警感知到的。</p><p><strong>监控维度</strong>：哪些内容需要监控也很重要。我们从架构底层往上看，首先需要感知基础设施的故障，包括物理机、网络、Docker、域名等指标；接着我们需要对中间件的各种故障进行监控，包括MySQL、Redis、ES、Dubbo等；微服务应用方面的监控，需要监控线程数、FullGC次数等；然后我们还需要对接口的流量以及性能进行监控；对核心业务流程中的重要节点也需要进行监控。</p><p><strong>报警方式</strong>：一般是微信告警，但是需要研发第一时间进行介入处理的，需要配置成电话告警，比如数据库宕机。</p><p><strong>问题原因</strong>：线上出现故障，无外乎这几个方面的原因。系统层面的故障（基础设施和中间件），需要快速进行降级或切换；业务系统变更导致的，比如上线新功能，更改配置，压测引起线上故障，这时候需要第一时间进行回滚操作；依赖的下游接口变更导致的，需要快速定位问题通知下游。</p><p><img src=\"https://static001.geekbang.org/resource/image/e5/a7/e56218077cacf2bab3f955361b9a85a7.jpg?wh=1920x2127\" alt=\"图片\"></p><p>好了，以上就是我做秒杀业务近几年的沉淀和思考。</p><ol>\n<li>关于预估秒杀流量，和大促备战不同，在很难预估的前提下，我们要做的就是化被动为主动，提前规划秒杀商品的流量上限，提前进行扩容和限流。</li>\n<li>关于跨团队的业务协同，对于秒杀而言，公司内客服、法务、公关、产品、运营等团队缺一不可，我们要做的就是提前成立由核心成员组成的虚拟项目小组，共同应对各类突发问题。</li>\n<li>关于爆品的快速发现方法，以及高可用系统搭建过程中必不可少的监控应急体系，它们不仅仅是秒杀系统需要的，也是任何一个互联网应用必须考虑的内容，我们应予以重视。</li>\n</ol><p>希望这个专栏能帮助你在这条技术之路上越走越远。那么任何一段旅程都有终点，感谢你的陪伴。我是志东，我们后会有期！</p><p>最后，文末有一份结课问卷，希望你可以花两分钟的时间填写一下。我会认真倾听你对这个专栏的意见或建议，期待你的反馈。</p><p><a href=\"https://jinshuju.net/f/AvlIbF\"><img src=\"https://static001.geekbang.org/resource/image/dd/4d/dd6b2862d9e42e68cb5c4ca1f6bb3f4d.jpg?wh=1142x801\" alt=\"\"></a></p>","neighbors":{"left":{"article_title":"14｜百万级流量秒杀系统的关键总结","id":431399},"right":[]}}]