{"id":783310,"title":"07｜大模型API封装：自建大模型如何对外服务？","content":"<p>你好，我是独行。</p><p>上一节课我们详细讲解了基于ChatGLM3-6B + LangChain + 向量数据库的企业内部知识系统，在这个演示项目中，其实已经用到了API的封装，我们从WebUI界面提问，通过接口将数据传到后端服务，从而获得响应。大模型是没有Web API的，所以需要我们进行一次封装，将大模型的核心接口封装成Web API来为用户提供服务，这是企业自建大模型的必经之路。</p><p>在这里我们需要引入一个类似于SpringBoot的框架，用来做接口服务化，在Python技术体系里，有一个框架叫 <strong>FastAPI</strong>，可以很方便地实现接口注册，所以我们这节课会基于FastAPI对大模型的接口进行封装。实际上光写一个Demo不算难，但是如果要完整地用于工程化项目，还是有不少事情要注意，所以这节课我会把各种各样和API相关的细节梳理出来，学完这节课的内容，再结合前面学习的大模型部署，你本地搭建的大模型基本可以对外提供服务了。</p><h2>接口封装</h2><p>提供Web API服务需要两个技术组件：Uvicorn和FastAPI。</p><p>Uvicorn作为Web服务器，类似Tomcat，但是比Tomcat轻很多。允许异步处理 HTTP 请求，所以非常适合处理并发请求。基于uvloop和httptools，所以具备非常高的性能，适合高并发请求的现代Web应用。</p><!-- [[[read_end]]] --><p>FastAPI作为API框架，和SpringBoot差不多，同样比SpringBoot轻很多，只是形式上类似于SpringBoot的角色。结合使用Uvicorn和FastAPI，你可以构建一个高性能、易于扩展的异步Web应用程序或API。Uvicorn作为服务器运行你的FastAPI应用，可以提供优异的并发处理能力，而FastAPI则让你的应用开发得更快、更简单、更安全。</p><p>接下来我们一步一步讲解。首先，安装所需要的依赖包。</p><h4>安装依赖</h4><pre><code class=\"language-plain\">pip install fastapi\npip install uvicorn\n</code></pre><h4>代码分层</h4><p>简单来看，创建api.py，写入以下代码，就可以定义一个接口。</p><pre><code class=\"language-python\">import uvicorn\nfrom fastapi import FastAPI\n\n# 创建API应用\napp = FastAPI()\n\n@app.get(\"/\")\nasync def root():\n  return {\"message\": \"Hello World\"}\n\nif __name__ == '__main__':\n  uvicorn.run(app, host='0.0.0.0', port=6006, log_level=\"info\", workers=1)\n</code></pre><pre><code class=\"language-python\">python api.py\n</code></pre><p><img src=\"https://static001.geekbang.org/resource/image/0e/bb/0e2ee439501432e968dc8fe827747ebb.png?wh=1042x370\" alt=\"图片\"></p><p>实际开发过程中，接口输入可能是多个字段，和Java接口一样，需要定义一个Request实体类来承接HTTP请求参数，Python里使用Pydantic模型来定义数据结构，Pydantic是一个数据验证和设置管理的库，它利用Python类型提示来进行数据验证。类似Java里的Validation，下面这段代码你应该并不陌生。</p><pre><code class=\"language-java\">import javax.validation.constraints.Min;\nimport javax.validation.constraints.NotNull;\nimport javax.validation.constraints.Size;\n\npublic class Product {\n\n&nbsp; &nbsp; @NotNull\n&nbsp; &nbsp; @Size(min = 2, max = 30)\n&nbsp; &nbsp; private String name;\n\n&nbsp; &nbsp; @NotNull\n&nbsp; &nbsp; @Min(0)\n&nbsp; &nbsp; private Float price;\n\n&nbsp; &nbsp; // 构造器、getter 和 setter 省略\n}\n</code></pre><p>对应的Python实现就是这样的：</p><pre><code class=\"language-python\">from fastapi import FastAPI\nfrom pydantic import BaseModel, Field\nfrom typing import Optional, List\n\napp = FastAPI()\n\nclass Message(BaseModel):\n    role: str\n    content: str\n\nclass ChatMessage(BaseModel):\n    history: List[Message]\n    prompt: str\n    max_tokens: int\n    temperature: float\n    top_p: float = Field(default=1.0)\n\n@app.post(\"/v1/chat/completions\")\nasync def create_chat_response(message: ChatMessage):\n    return {\"message\": \"Hello World\"}\n\nif __name__ == '__main__':\n  uvicorn.run(app, host='0.0.0.0', port=6006, log_level=\"info\", workers=1)\n\n</code></pre><p>这里引入了一个BaseModel类，类似于Java里的Object类，但是又不完全是Object，Object是所有Java类的基类，Java中所有类会默认集成Object类的公共方法，比如toString()、equals()、hashcode()等，而BaseModel 是为了数据验证和管理而设计的。当你创建一个继承自BaseModel的类时，比如上面的ChatSession和Message类，将自动获得数据验证、序列化和反序列化的功能。</p><p>另外，我们实际开发过程中，也不可能把所有API的定义和Pydantic类放在最外层，按照Java工程化的最佳实践，Web应用我们一般会进行分层，比如controller、service、model、tool等，Python工程化的时候，为了方便管理代码，也会进行分层，一个典型的代码结构如下：</p><pre><code class=\"language-python\">project_name/\n│\n├── app/&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# 主应用目录\n│&nbsp; &nbsp;├── main.py&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # FastAPI 应用入口\n│&nbsp; &nbsp;└── controller/&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # API 特定逻辑\n│&nbsp; &nbsp; &nbsp;  └── chat.py\n│&nbsp;  └── common/&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;     # 通用API组件\n│&nbsp; &nbsp; &nbsp; &nbsp;└── errors.py&nbsp; &nbsp; &nbsp; &nbsp;     # 错误处理和自定义异常\n│\n├── services/&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # 服务层目录\n│&nbsp; &nbsp;├── chat_service.py&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # 聊天服务相关逻辑\n│\n├── schemas/&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# Pydantic 模型（请求和响应模式）\n│&nbsp; &nbsp;├── chat_schema.py&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# 聊天数据模式\n│\n├── database/&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # 数据库连接和会话管理\n│&nbsp; &nbsp;├── session.py&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# 数据库会话配置\n│&nbsp; &nbsp;└── engine.py&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # 数据库引擎配置\n│\n├── tools/&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# 工具和实用程序目录\n│&nbsp; &nbsp;├── data_migration.py&nbsp; &nbsp; &nbsp; &nbsp; # 数据迁移工具\n│\n├── tests/&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# 测试目录\n│&nbsp; &nbsp;├── conftest.py&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # 测试配置和夹具\n│&nbsp; &nbsp;├── test_services/&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# 服务层测试\n│&nbsp; &nbsp;│&nbsp; &nbsp;├── test_chat_service.py\n│&nbsp; &nbsp;└── test_controller/&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \n│&nbsp; &nbsp; &nbsp; &nbsp;├── test_chat_controller.py\n│\n├── requirements.txt&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# 项目依赖文件\n└── setup.py&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# 安装、打包、分发配置文件\n\n</code></pre><p>FastAPI的include_router方法就是用来将不同的路由集成到主应用中的，有助于组织和分离代码，特别是在构建大型工程化应用时，非常好用。你可以看一下修改后的代码。</p><p>应用入口main.py</p><pre><code class=\"language-python\">import uvicorn as uvicorn\nfrom fastapi import FastAPI\nfrom controller.chat_controller import chat_router as chat_router\napp = FastAPI()\napp.include_router(chat_router, prefix=\"/chat\", tags=[\"chat\"])\nif __name__ == '__main__':\n    uvicorn.run(app, host='0.0.0.0', port=6006, log_level=\"info\", workers=1)\n\n</code></pre><p>chat_controller.py</p><pre><code class=\"language-python\">from fastapi import APIRouter\nfrom service.chat_service import ChatService\nfrom schema.chat_schema import ChatMessage, MessageDisplay\nchat_router = APIRouter()\nchat_service = ChatService()\n\n@chat_router.post(\"/new/message/\")\ndef post_message(message: ChatMessage):\n    return chat_service.post_message(message)\n\n@chat_router.get(\"/get/messages/\")\ndef get_messages():\n    return chat_service.get_messages()\n\n</code></pre><p>chat_service.py</p><pre><code class=\"language-python\">from schema.chat_schema import ChatMessage\n\nclass ChatService:\n    def post_message(self, message: ChatMessage) :\n        print(message.prompt)\n        return {\"message\": \"post message\"}\n    def get_messages(self):\n        return {\"message\": \"get message\"}\n\n</code></pre><p>参数类定义如下：</p><pre><code class=\"language-python\">from pydantic import BaseModel, Field\n\nclass Message(BaseModel):\n    role: str\n    content: str\n\nclass ChatMessage(BaseModel):\n    prompt: str\n    max_tokens: int\n    temperature: float = Field(default=1.0)\n    top_p: float = Field(default=1.0)\n    \n</code></pre><p>我们可以在chat_service里进行详细地业务逻辑处理，到这里基本就和Java里一样了。下面是一段简单的测试代码：</p><pre><code class=\"language-python\">import json\nimport requests\n\nurl = 'http://localhost:6006/chat/new/message/'\ndata = {\n    'prompt': 'hello',\n    'max_tokens': 1000\n}\n\nresponse = requests.post(url, data=json.dumps(data))\nprint(response.text)\n\nurl2 = 'http://localhost:6006/chat/get/messages/'\nresponse = requests.get(url2)\nprint(response.text)\n\n</code></pre><pre><code class=\"language-python\">{\"message\":\"post message\"}\n{\"message\":\"get message\"}\n</code></pre><p>关于FastAPI的使用，你可以参考这个<a href=\"https://fastapi.tiangolo.com/zh/tutorial/\">教程</a>。工程化代码结构搞定，我们就可以封装大模型的接口了。</p><h4>大模型接口封装</h4><p>不同的大模型对应的对话接口不一样，下面的示例代码基于ChatGLM3-6B。我们在service层进行模型对话的封装。你可以看一下示例代码。</p><pre><code class=\"language-python\">from datetime import datetime\nimport model_manager\nfrom schema.chat_schema import ChatMessage\n\nclass ChatService:\n    def post_message(self, message: ChatMessage):\n        print(message.prompt)\n        model = model_manager.ModelManager.get_model()\n        tokenizer = model_manager.ModelManager.get_tokenizer()\n        response, history = model.chat(\n            tokenizer,\n            message.prompt,\n            history=message.histroy,\n            max_length=message.max_tokens,\n            top_p=message.top_p,\n            temperature=message.temperature\n        )\n        now = datetime.datetime.now()  # 获取当前时间\n        time = now.strftime(\"%Y-%m-%d %H:%M:%S\")  # 格式化时间为字符串\n        answer = {\n            \"response\": response,\n            \"history\": history,\n            \"status\": 200,\n            \"time\": time\n        }\n        log = \"[\" + time + \"] \" + '\", prompt:\"' + message.prompt + '\", response:\"' + repr(response) + '\"'\n        print(log)\n        return answer\n    def get_messages(self):\n        return {\"message\": \"get message\"}\n</code></pre><p>定义一个ModelManager类进行大模型的懒加载。</p><pre><code class=\"language-python\">from transformers import AutoTokenizer, AutoModelForCausalLM\n\nclass ModelManager:\n    _model = None\n    _tokenizer = None\n    \n    @classmethod\n    def get_model(cls):\n        if cls._model is None:\n            _model = AutoModelForCausalLM.from_pretrained(\"chatglm3-6b\", trust_remote_code=True).half().cuda().eval()\n        return _model\n\n        @classmethod\n    def get_tokenizer(cls):\n        if cls._tokenizer is None:\n            _tokenizer = AutoTokenizer.from_pretrained(\"chatglm3-6b\", trust_remote_code=True)\n        return _tokenizer\n</code></pre><p>model.chat()是6B暴露的对话接口，通过对model.chat()的封装就可以实现基本的对话接口了，这个接口一次性输出大模型返回的内容，而我们在使用大模型产品的时候，比如ChatGPT或者文心一言，会发现大模型是一个字一个字返回的，那是什么原因呢？那种模式叫<strong>流式输出</strong>。</p><h2>流式输出</h2><p>流式输出使用另一个接口：model.stream_chat，有几种模式，像一个字一个字输出，比如：</p><pre><code class=\"language-plain\">我\n是\n中\n国\n人\n</code></pre><p>或者每次输出当前已经输出的全部，比如：</p><pre><code class=\"language-plain\">我\n我是\n我是中\n我是中国\n我是中国人\n</code></pre><p>当然也有每次吐出2个字的，实际生产过程中可以根据产品交互设计自行修改逻辑。我们看一个简单的代码片段，通过stream变量来控制是否是流式输出。</p><pre><code class=\"language-python\">if stream:\n    async for token in callback.aiter():\n        # Use server-sent-events to stream the response\n        yield json.dumps(\n            {\"text\": token, \"message_id\": message_id},\n            ensure_ascii=False)\nelse:\n    answer = \"\"\n    async for token in callback.aiter():\n        answer += token\n    yield json.dumps(\n        {\"text\": answer, \"message_id\": message_id},\n        ensure_ascii=False)\nawait task\n</code></pre><p>我们输入“你好”，当stream=true时，接口输出是这样的：</p><pre><code class=\"language-python\">data: {\"text\": \"你\", \"message_id\": \"80b2af55c5b7440eaca6b9d510677a75\"}\ndata: {\"text\": \"好\", \"message_id\": \"80b2af55c5b7440eaca6b9d510677a75\"}\ndata: {\"text\": \"👋\", \"message_id\": \"80b2af55c5b7440eaca6b9d510677a75\"}\ndata: {\"text\": \"！\", \"message_id\": \"80b2af55c5b7440eaca6b9d510677a75\"}\ndata: {\"text\": \"我是\", \"message_id\": \"80b2af55c5b7440eaca6b9d510677a75\"}\ndata: {\"text\": \"人工智能\", \"message_id\": \"80b2af55c5b7440eaca6b9d510677a75\"}\ndata: {\"text\": \"助手\", \"message_id\": \"80b2af55c5b7440eaca6b9d510677a75\"}\ndata: {\"text\": \" Chat\", \"message_id\": \"80b2af55c5b7440eaca6b9d510677a75\"}\ndata: {\"text\": \"GL\", \"message_id\": \"80b2af55c5b7440eaca6b9d510677a75\"}\ndata: {\"text\": \"M\", \"message_id\": \"80b2af55c5b7440eaca6b9d510677a75\"}\ndata: {\"text\": \"3\", \"message_id\": \"80b2af55c5b7440eaca6b9d510677a75\"}\ndata: {\"text\": \"-\", \"message_id\": \"80b2af55c5b7440eaca6b9d510677a75\"}\ndata: {\"text\": \"6\", \"message_id\": \"80b2af55c5b7440eaca6b9d510677a75\"}\ndata: {\"text\": \"B\", \"message_id\": \"80b2af55c5b7440eaca6b9d510677a75\"}\ndata: {\"text\": \"，\", \"message_id\": \"80b2af55c5b7440eaca6b9d510677a75\"}\ndata: {\"text\": \"很高兴\", \"message_id\": \"80b2af55c5b7440eaca6b9d510677a75\"}\ndata: {\"text\": \"见到\", \"message_id\": \"80b2af55c5b7440eaca6b9d510677a75\"}\ndata: {\"text\": \"你\", \"message_id\": \"80b2af55c5b7440eaca6b9d510677a75\"}\ndata: {\"text\": \"，\", \"message_id\": \"80b2af55c5b7440eaca6b9d510677a75\"}\ndata: {\"text\": \"欢迎\", \"message_id\": \"80b2af55c5b7440eaca6b9d510677a75\"}\ndata: {\"text\": \"问我\", \"message_id\": \"80b2af55c5b7440eaca6b9d510677a75\"}\ndata: {\"text\": \"任何\", \"message_id\": \"80b2af55c5b7440eaca6b9d510677a75\"}\ndata: {\"text\": \"问题\", \"message_id\": \"80b2af55c5b7440eaca6b9d510677a75\"}\ndata: {\"text\": \"。\", \"message_id\": \"80b2af55c5b7440eaca6b9d510677a75\"}\n</code></pre><p>当stream=false时，接口返回如下：</p><pre><code class=\"language-python\">data: {\"text\": \"你好！我是人工智能助手，很高兴为您服务。请问有什么问题我可以帮您解答吗？\", \"message_id\": \"741a630ac3d64fd5b1832cc0bae6bb68\"}\n</code></pre><p>到这里，大模型的API基本就封装好了，接下来我们看下如何调用。</p><h2>接口调用</h2><p>在实际工程化过程中，我们一般会把AI相关的逻辑，包括大模型API的封装放在Python应用中，上层应用一般通过其他语言实现，比如Java、C#、Go等，这里我简单举一个Java版本的调用例子。非流式输出就是普通的HTTP请求，我们就不展示了，重点看下流式输出怎么进行调用，主要分两步，都是流式的。</p><ol>\n<li><strong>Java调用Python接口：</strong>主要用到了okhttp3框架，需要组装参数、发起流式请求，事件监听处理三步。</li>\n</ol><pre><code class=\"language-java\">\n@ApiOperation(value = \"流式发送对话消息\")\n@PostMapping(value = \"sendMessage\")\npublic void sendMessage(@RequestBody ChatRequest request, HttpServletResponse response) {\n\ttry {\n\t\tJSONObject body = new JSONObject();\n\t\tbody.put(\"model\", request.getModel());\n\t\tbody.put(\"stream\", true);\n\t\tJSONArray messages = new JSONArray();\n\t\tJSONObject query = new JSONObject();\n\t\tquery.put(\"role\", \"user\");\n\t\tquery.put(\"content\", request.getQuery());\n\t\tmessages.add(query);\n\t\tbody.put(\"messages\", messages);\n\t\tEsListener eventSourceListener = new EsListener(request, response);\n\n\n\n\t\tRequestBody formBody = RequestBody.create(body, MediaType.parse(\"application/json\"));\n\t\tRequest.Builder requestBuilder = new Request.Builder();\n\n\t\tRequest request2 = requestBuilder.url(URL).post(formBody).build();\n\t\tEventSource.Factory factory = EventSources.createFactory(OkHttpUtil.getInstance());\n\n\t\tfactory.newEventSource(request2, eventSourceListener);\n\t\teventSourceListener.getCountDownLatch().await();\n\t} catch (Exception e) {\n\t\tlog.error(\"流式调用异常\", e);\n\t}\n}\n</code></pre><p>EsListener继承自EventSourceListener，在Request请求的过程中不断触发EsListener的onEvent方法，然后将数据写回前端。</p><pre><code class=\"language-java\">@Override\npublic void onEvent(EventSource eventSource, String id, String type, String data) {\n\ttry {\n\t\toutput.append(data);\n\t\tif (\"finish\".equals(type)) {\n\t\t}\n\t\tif (\"error\".equals(type)) {\n\t\t}\n\n\t\t// 开始处理data，此处只展示基本操作\n\t\t// 开发过程中具体逻辑可自行扩展\n\t\tif (response != null) {\n\t\t\tresponse.getWriter().write(data);\n\t\t\tresponse.getWriter().flush();\n\t\t}\n\t} catch (Exception e) {\n\t\tlog.error(\"事件处理异常\", e);\n\t}\n}\n</code></pre><ol start=\"2\">\n<li><strong>前端调用Java接口：</strong>使用JS原生EventSource的API就可以。</li>\n</ol><pre><code class=\"language-java\">&lt;script&gt;\n&nbsp; &nbsp; let eventData = '';\n&nbsp; &nbsp; const eventSource = new EventSource('http://localhost:8888/sendMessage');\n&nbsp; &nbsp; eventSource.onmessage = function(event) {\n&nbsp; &nbsp; &nbsp; &nbsp; // 累加接收到的事件数据\n&nbsp; &nbsp; &nbsp; &nbsp; eventData += event.data;\n&nbsp; &nbsp; };\n&lt;/script&gt;\n</code></pre><p>到这一步，大模型API从封装到调用就基本完成了，你可以把整个链路都串起来跑一跑，体验下效果。实际工程化的过程中，还会遇到其他问题，比如API的鉴权（指Java-&gt;Python）、跨域问题、API限流问题（大模型的吞吐量有限），我们会在后面的课程中讲解。</p><h2>小结</h2><p>我们这节课学的内容是自建大模型服务不可缺少的一步，整体来说不算难，唯一可能难一点的就是要使用Python语言，因为在使用FastAPI的过程中，会有大量的异步操作，和Java的处理方式有点差异，需要注意下。</p><p>这节课学完，我们基本上把企业内部构建大模型的过程全部讲完了，你自己构建的大模型基本可以对外提供服务了。如果在生产环境使用，一定要注意做好降级准备，因为有很多不确定性，比如模型的吞吐量（TPS）评估是否准确，模型会不会出现意想不到的输出等等，一旦出现问题随时降级。</p><h2>思考题</h2><p>前面我们提到，大模型相关的API封装在Python应用中，对用户提供服务的时候，会再套一层Java应用，你可以想一下为什么要这么设计，欢迎你把你的想法分享到评论区，我们一起讨论，如果你觉得这节课的内容对你有帮助的话，也欢迎你分享给其他朋友，我们下节课再见！</p>","neighbors":{"left":{"article_title":"06｜RAG实战：基于ChatGLM3-6B+LangChain+Faiss搭建企业内部知识库","id":782736},"right":{"article_title":"08｜关于机器学习，你需要了解的基本概念（一）","id":783348}},"comments":[{"had_liked":false,"id":391579,"user_name":"张申傲","can_delete":false,"product_type":"c1","uid":1182372,"ip_address":"北京","ucode":"22D46BC529BA8A","user_header":"https://static001.geekbang.org/account/avatar/00/12/0a/a4/828a431f.jpg","comment_is_top":false,"comment_ctime":1718594070,"is_pvip":false,"replies":[{"id":142390,"content":"没错👍","user_name":"作者回复","user_name_real":"编辑","uid":2083554,"ctime":1718609550,"ip_address":"浙江","comment_id":391579,"utype":1}],"discussion_count":3,"race_medal":2,"score":2,"product_id":100770601,"comment_content":"第7讲打卡~\n思考题：这里应该主要考虑的是不同语言的优势和适用场景。使用Python实现大模型的核心API，应该是因为Python是机器学习领域最主流的语言，包括了像pytorch、TensorFlow等主流的框架，而且一些主流的大模型像ChatGPT也提供了完善的Python SDK，使用起来比较方便。而在外面又套了一层Java应用，应该是考虑这么多年来Java在Web服务端领域积累下来的完善的生态，针对用户端的应用，可以快速构建起服务鉴权、路由、熔断、降级、限流、可观测等等能力。","like_count":11,"discussions":[{"author":{"id":2083554,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erZP8e2vqiaACFaDxruOzUTPbPv2uRUTp9UuEg98Ib9aYddjZK2kastqf0B14Ec7uXx7CCSXr0fhAA/132","nickname":"Geek_cf2545","note":"","ucode":"B69DF1E734FBA2","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":646722,"discussion_content":"没错👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1718609550,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1181055,"avatar":"https://static001.geekbang.org/account/avatar/00/12/05/7f/a7df049a.jpg","nickname":"Standly","note":"","ucode":"805CC5784D3F76","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":647350,"discussion_content":"但是大模型不是也有http接口么，直接用Java封装一下不也行么","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1719909481,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"江苏","group_id":0},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1182372,"avatar":"https://static001.geekbang.org/account/avatar/00/12/0a/a4/828a431f.jpg","nickname":"张申傲","note":"","ucode":"22D46BC529BA8A","race_medal":2,"user_type":1,"is_pvip":false},"reply_author":{"id":1181055,"avatar":"https://static001.geekbang.org/account/avatar/00/12/05/7f/a7df049a.jpg","nickname":"Standly","note":"","ucode":"805CC5784D3F76","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":647355,"discussion_content":"理论上是的，但是LLM应用的很多扩展功能，例如多模型切换、流式输出、记忆、RAG等等这些，直接用Java封装的话工作量会很大，而用LangChain这种框架开发就会简化很多","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1719915393,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":647350,"ip_address":"北京","group_id":0},"score":647355,"extra":""}]}]},{"had_liked":false,"id":391575,"user_name":"Lee","can_delete":false,"product_type":"c1","uid":1060230,"ip_address":"福建","ucode":"357C3D2F33B325","user_header":"https://static001.geekbang.org/account/avatar/00/10/2d/86/07a10be2.jpg","comment_is_top":false,"comment_ctime":1718587301,"is_pvip":false,"replies":[{"id":142386,"content":"马上啦","user_name":"作者回复","user_name_real":"编辑","uid":2083554,"ctime":1718595462,"ip_address":"浙江","comment_id":391575,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100770601,"comment_content":"老师 我等不及了  上瘾了  催更催更","like_count":3,"discussions":[{"author":{"id":2083554,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erZP8e2vqiaACFaDxruOzUTPbPv2uRUTp9UuEg98Ib9aYddjZK2kastqf0B14Ec7uXx7CCSXr0fhAA/132","nickname":"Geek_cf2545","note":"","ucode":"B69DF1E734FBA2","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":646714,"discussion_content":"马上啦","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1718595462,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":396111,"user_name":"狒狒","can_delete":false,"product_type":"c1","uid":1242295,"ip_address":"广东","ucode":"10A320ECEBF074","user_header":"https://static001.geekbang.org/account/avatar/00/12/f4/b7/5c775af5.jpg","comment_is_top":false,"comment_ctime":1733146874,"is_pvip":false,"replies":[{"id":143833,"content":"稍微调一下，正好练一下python功底，否则后面也没法深入，搞ai主要是python呀","user_name":"作者回复","user_name_real":"编辑","uid":2083554,"ctime":1733536926,"ip_address":"浙江","comment_id":396111,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100770601,"comment_content":"python基础不是太好，有可用的完整代码吗，文中的代码似乎不能直接使用，比如结构版本与实际案例不一致，在controller中引入serveice时无法直接引入","like_count":0,"discussions":[{"author":{"id":2083554,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erZP8e2vqiaACFaDxruOzUTPbPv2uRUTp9UuEg98Ib9aYddjZK2kastqf0B14Ec7uXx7CCSXr0fhAA/132","nickname":"Geek_cf2545","note":"","ucode":"B69DF1E734FBA2","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":654815,"discussion_content":"稍微调一下，正好练一下python功底，否则后面也没法深入，搞ai主要是python呀","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1733536926,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":395435,"user_name":"神经蛙","can_delete":false,"product_type":"c1","uid":3963624,"ip_address":"上海","ucode":"A2D470E345195D","user_header":"https://static001.geekbang.org/account/avatar/00/3c/7a/e8/c86468e8.jpg","comment_is_top":false,"comment_ctime":1730793960,"is_pvip":false,"replies":[{"id":143646,"content":"首先，模型要充分测试；其次，要有一些前置、后置的内容检测机制，有问题直接屏蔽；机器负载达上限就限流，大家都是这么做的，包括ChatGPT","user_name":"作者回复","user_name_real":"编辑","uid":2083554,"ctime":1731470401,"ip_address":"浙江","comment_id":395435,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100770601,"comment_content":"大模型的输出降级方案有哪些考虑方案？比如如果被引导输出不当言论，如何快速封掉这个漏洞？机器负载达到上限后又该如何处理？","like_count":0,"discussions":[{"author":{"id":2083554,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erZP8e2vqiaACFaDxruOzUTPbPv2uRUTp9UuEg98Ib9aYddjZK2kastqf0B14Ec7uXx7CCSXr0fhAA/132","nickname":"Geek_cf2545","note":"","ucode":"B69DF1E734FBA2","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":653811,"discussion_content":"首先，模型要充分测试；其次，要有一些前置、后置的内容检测机制，有问题直接屏蔽；机器负载达上限就限流，大家都是这么做的，包括ChatGPT","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1731470401,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":393394,"user_name":"cricket1981","can_delete":false,"product_type":"c1","uid":1001715,"ip_address":"上海","ucode":"758262F5958DA4","user_header":"https://static001.geekbang.org/account/avatar/00/0f/48/f3/65c7e3ef.jpg","comment_is_top":false,"comment_ctime":1723684849,"is_pvip":false,"replies":[{"id":142936,"content":"翻墙或者使用替代产品魔搭","user_name":"作者回复","user_name_real":"编辑","uid":2083554,"ctime":1724424722,"ip_address":"浙江","comment_id":393394,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100770601,"comment_content":"请问国内如何使用huggingface? 很多国外大模型网站被墙了，有什么替代方案或work around方法吗？","like_count":0,"discussions":[{"author":{"id":2083554,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erZP8e2vqiaACFaDxruOzUTPbPv2uRUTp9UuEg98Ib9aYddjZK2kastqf0B14Ec7uXx7CCSXr0fhAA/132","nickname":"Geek_cf2545","note":"","ucode":"B69DF1E734FBA2","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":650138,"discussion_content":"翻墙或者使用替代产品魔搭","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1724424723,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":392421,"user_name":"大宽","can_delete":false,"product_type":"c1","uid":1071011,"ip_address":"北京","ucode":"12970A21E939EA","user_header":"https://static001.geekbang.org/account/avatar/00/10/57/a3/4bcf1b59.jpg","comment_is_top":false,"comment_ctime":1720875350,"is_pvip":false,"replies":[{"id":142654,"content":"示例用的是pytorch，其他框架你可以自己试一试","user_name":"作者回复","user_name_real":"编辑","uid":2083554,"ctime":1721109997,"ip_address":"浙江","comment_id":392421,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100770601,"comment_content":"老师 ，示例示例中的大模型推理框架用的是哪个呢，可否引入 VLLM","like_count":0,"discussions":[{"author":{"id":2083554,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erZP8e2vqiaACFaDxruOzUTPbPv2uRUTp9UuEg98Ib9aYddjZK2kastqf0B14Ec7uXx7CCSXr0fhAA/132","nickname":"Geek_cf2545","note":"","ucode":"B69DF1E734FBA2","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":648121,"discussion_content":"示例用的是pytorch，其他框架你可以自己试一试","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1721109997,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":392307,"user_name":"Geek_frank","can_delete":false,"product_type":"c1","uid":1685433,"ip_address":"上海","ucode":"534D46C2D1EFF5","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erG6I79WlHDjs51JOff9GBibD4Fh2PhITQMvmh2aTUVzH2BKia1tFLLoQr7VFeZddywwRoZlVUyhDDQ/132","comment_is_top":false,"comment_ctime":1720572665,"is_pvip":false,"replies":[{"id":142592,"content":"没错","user_name":"作者回复","user_name_real":"编辑","uid":2083554,"ctime":1720604376,"ip_address":"浙江","comment_id":392307,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100770601,"comment_content":"打卡第六课：python封装大模型借口提供AI服务有天然的优势，基本上大模型都是用python开发的，开源的也都有python的lib。使用python进行API封装或者模型微调都特别方便。 在AI服务之上的一些政增值服务可能java来提供更好一些，因为java适合业务的封装。但也不是非java不可，python也可以实现不做的业务服务。我现在做的一个运维一体化平台很多业务实现都是python来做的。比如认证鉴权，配置仓库，在线作业管理等等","like_count":0,"discussions":[{"author":{"id":2083554,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erZP8e2vqiaACFaDxruOzUTPbPv2uRUTp9UuEg98Ib9aYddjZK2kastqf0B14Ec7uXx7CCSXr0fhAA/132","nickname":"Geek_cf2545","note":"","ucode":"B69DF1E734FBA2","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":647782,"discussion_content":"没错","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1720604376,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":391774,"user_name":"season","can_delete":false,"product_type":"c1","uid":2894734,"ip_address":"新加坡","ucode":"1CBBFCC58A245E","user_header":"https://static001.geekbang.org/account/avatar/00/2c/2b/8e/4d24c872.jpg","comment_is_top":false,"comment_ctime":1719054337,"is_pvip":false,"replies":[{"id":142452,"content":"没有放在仓库上","user_name":"作者回复","user_name_real":"编辑","uid":2083554,"ctime":1719195524,"ip_address":"浙江","comment_id":391774,"utype":1}],"discussion_count":3,"race_medal":0,"score":2,"product_id":100770601,"comment_content":"课程里面的代码，有代码仓库吗？","like_count":0,"discussions":[{"author":{"id":2083554,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erZP8e2vqiaACFaDxruOzUTPbPv2uRUTp9UuEg98Ib9aYddjZK2kastqf0B14Ec7uXx7CCSXr0fhAA/132","nickname":"Geek_cf2545","note":"","ucode":"B69DF1E734FBA2","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":646971,"discussion_content":"没有放在仓库上","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1719195525,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3199773,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/EC0Xp12qA9thF8IIeVu6lJFttDxrocOe40HYSSFjzLJnEacGlBs0kTanvPfchOj3t2RR29gBnBWjGAvMH3JH7w/132","nickname":"Geek_f7b82c","note":"","ucode":"FF2C8610B7BDDB","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":653267,"discussion_content":"如何获取示例代码","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1730536607,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"陕西","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1253161,"avatar":"https://static001.geekbang.org/account/avatar/00/13/1f/29/8c55ccaf.jpg","nickname":"朱凌峰","note":"","ucode":"96C33BE610B060","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":647704,"discussion_content":"有计划放到git仓库吗","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1720484259,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":391676,"user_name":"风轻扬","can_delete":false,"product_type":"c1","uid":1542987,"ip_address":"北京","ucode":"DB972F2DF059C4","user_header":"https://static001.geekbang.org/account/avatar/00/17/8b/4b/15ab499a.jpg","comment_is_top":false,"comment_ctime":1718798555,"is_pvip":false,"replies":[{"id":142424,"content":"点赞，感谢！","user_name":"作者回复","user_name_real":"编辑","uid":2083554,"ctime":1718856730,"ip_address":"浙江","comment_id":391676,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100770601,"comment_content":"如果大家在跑demo的时候遇到这个错误。TypeError: ChatGLMForConditionalGeneration.chat() missing 1 required positional argument: &#39;query&#39;，可以尝试将chat_service.py文件中，model.chat方法的第二个入参去掉&quot;prompt=&quot;，只保留message.prompt即可","like_count":0,"discussions":[{"author":{"id":2083554,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erZP8e2vqiaACFaDxruOzUTPbPv2uRUTp9UuEg98Ib9aYddjZK2kastqf0B14Ec7uXx7CCSXr0fhAA/132","nickname":"Geek_cf2545","note":"","ucode":"B69DF1E734FBA2","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":646847,"discussion_content":"点赞，感谢！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1718856730,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":391669,"user_name":"0.0","can_delete":false,"product_type":"c1","uid":2246077,"ip_address":"广东","ucode":"9080F7DD748B29","user_header":"https://static001.geekbang.org/account/avatar/00/22/45/bd/df16cf9d.jpg","comment_is_top":false,"comment_ctime":1718781005,"is_pvip":false,"replies":[{"id":142416,"content":"只能说dify界面更加友好，各有优势，国内使用，优先推荐dify","user_name":"作者回复","user_name_real":"编辑","uid":2083554,"ctime":1718796115,"ip_address":"浙江","comment_id":391669,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100770601,"comment_content":"dify 是否更优雅","like_count":0,"discussions":[{"author":{"id":2083554,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erZP8e2vqiaACFaDxruOzUTPbPv2uRUTp9UuEg98Ib9aYddjZK2kastqf0B14Ec7uXx7CCSXr0fhAA/132","nickname":"Geek_cf2545","note":"","ucode":"B69DF1E734FBA2","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":646822,"discussion_content":"只能说dify界面更加友好，各有优势，国内使用，优先推荐dify","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1718796115,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2944137,"avatar":"","nickname":"Geek_162656","note":"","ucode":"71AC5B3AA640D8","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":651031,"discussion_content":"dify 是啥？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1726098976,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"江苏","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":391666,"user_name":"风轻扬","can_delete":false,"product_type":"c1","uid":1542987,"ip_address":"北京","ucode":"DB972F2DF059C4","user_header":"https://static001.geekbang.org/account/avatar/00/17/8b/4b/15ab499a.jpg","comment_is_top":false,"comment_ctime":1718778063,"is_pvip":false,"replies":[{"id":142417,"content":"参考微信群的解答，调整下model.chat()的入参，我怀疑官方入参更新了","user_name":"作者回复","user_name_real":"编辑","uid":2083554,"ctime":1718796223,"ip_address":"浙江","comment_id":391666,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100770601,"comment_content":"老师，ModelManager类中，两个from_pretrained方法的第一个入参都是模型的路径吧？我按照文中的代码实现了一下，在一张3090 gpu上跑，python版本3.11，一直报：TypeError: ChatGLMForConditionalGeneration.chat() missing 1 required positional argument: &#39;query&#39;，查了查ChatGLMForConditionalGeneration，并没有chat方法，不知道咋排查了。。。。","like_count":0,"discussions":[{"author":{"id":2083554,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erZP8e2vqiaACFaDxruOzUTPbPv2uRUTp9UuEg98Ib9aYddjZK2kastqf0B14Ec7uXx7CCSXr0fhAA/132","nickname":"Geek_cf2545","note":"","ucode":"B69DF1E734FBA2","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":646824,"discussion_content":"参考微信群的解答，调整下model.chat()的入参，我怀疑官方入参更新了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1718796223,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":391640,"user_name":"风轻扬","can_delete":false,"product_type":"c1","uid":1542987,"ip_address":"北京","ucode":"DB972F2DF059C4","user_header":"https://static001.geekbang.org/account/avatar/00/17/8b/4b/15ab499a.jpg","comment_is_top":false,"comment_ctime":1718711408,"is_pvip":false,"replies":[{"id":142408,"content":"这是一方面，主要还是考虑业务应用与大模型分开，起到保护的作用","user_name":"作者回复","user_name_real":"编辑","uid":2083554,"ctime":1718716592,"ip_address":"浙江","comment_id":391640,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100770601,"comment_content":"思考题，是为了解耦？工程类的代码修改，不太应该让模型跟着一起发布。","like_count":0,"discussions":[{"author":{"id":2083554,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erZP8e2vqiaACFaDxruOzUTPbPv2uRUTp9UuEg98Ib9aYddjZK2kastqf0B14Ec7uXx7CCSXr0fhAA/132","nickname":"Geek_cf2545","note":"","ucode":"B69DF1E734FBA2","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":646782,"discussion_content":"这是一方面，主要还是考虑业务应用与大模型分开，起到保护的作用","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1718716592,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":391606,"user_name":"Eleven","can_delete":false,"product_type":"c1","uid":1168452,"ip_address":"湖南","ucode":"FB4A0C8CA732BE","user_header":"https://static001.geekbang.org/account/avatar/00/11/d4/44/0ec958f4.jpg","comment_is_top":false,"comment_ctime":1718630659,"is_pvip":false,"replies":[{"id":142400,"content":"多试一下，改变一下训练素材和训练配置，比如轮数等","user_name":"作者回复","user_name_real":"编辑","uid":2083554,"ctime":1718690900,"ip_address":"浙江","comment_id":391606,"utype":1}],"discussion_count":2,"race_medal":0,"score":3,"product_id":100770601,"comment_content":"我微调完成后再去composite_demo启动，对话好像没有效果呀\n","like_count":0,"discussions":[{"author":{"id":2083554,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erZP8e2vqiaACFaDxruOzUTPbPv2uRUTp9UuEg98Ib9aYddjZK2kastqf0B14Ec7uXx7CCSXr0fhAA/132","nickname":"Geek_cf2545","note":"","ucode":"B69DF1E734FBA2","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":646759,"discussion_content":"多试一下，改变一下训练素材和训练配置，比如轮数等","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1718690900,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2083554,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erZP8e2vqiaACFaDxruOzUTPbPv2uRUTp9UuEg98Ib9aYddjZK2kastqf0B14Ec7uXx7CCSXr0fhAA/132","nickname":"Geek_cf2545","note":"","ucode":"B69DF1E734FBA2","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":646758,"discussion_content":"多试一下，改变一下训练素材和训练配置，比如轮数等","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1718690738,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":391587,"user_name":"徐石头","can_delete":false,"product_type":"c1","uid":1035885,"ip_address":"湖南","ucode":"D8FA8A64FB7E33","user_header":"https://static001.geekbang.org/account/avatar/00/0f/ce/6d/530df0dd.jpg","comment_is_top":false,"comment_ctime":1718601218,"is_pvip":true,"replies":[{"id":142389,"content":"没错👍","user_name":"作者回复","user_name_real":"编辑","uid":2083554,"ctime":1718609461,"ip_address":"浙江","comment_id":391587,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100770601,"comment_content":"为什么这么设计？\n高内聚，低耦合。把大模型 API 封装在 python 中作为一个微服务从整个架构中独立出来，它只处理和大模型相关的，不和其他业务接口放一起。它就可以单独部署，扩容，隔离，而且由单独的人维护，也是微服务的优势。\n如果我来做，我还会增加 rpc接口，注册到注册中心。","like_count":0,"discussions":[{"author":{"id":2083554,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erZP8e2vqiaACFaDxruOzUTPbPv2uRUTp9UuEg98Ib9aYddjZK2kastqf0B14Ec7uXx7CCSXr0fhAA/132","nickname":"Geek_cf2545","note":"","ucode":"B69DF1E734FBA2","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":646721,"discussion_content":"没错👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1718609461,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":391583,"user_name":"roman","can_delete":false,"product_type":"c1","uid":1017679,"ip_address":"北京","ucode":"6E147F09D6EC32","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJZO3Xkicd9Cy8tAian8JnxqVianHNggKcMtdx6sKrQygxnCUKib3ERXIxiaFqkFyhPibkCGzpbdTOiaGvSA/132","comment_is_top":false,"comment_ctime":1718597534,"is_pvip":false,"replies":[{"id":142387,"content":"说的很好👍 大模型是工具，上层ai应用可能是多个工具的集合","user_name":"作者回复","user_name_real":"编辑","uid":2083554,"ctime":1718609401,"ip_address":"浙江","comment_id":391583,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100770601,"comment_content":"老师 好，再套一层应用我的想法是这样的，不知道是否正确 \n1.保护底层大模型应用：套一层类似Java应用层的应用可以做到将大模型的底层服务和客户端的访问进行隔离，避免一些客户端注入攻击类型的场景\n2.给应用层提供更多可扩展的场景，底层大模型只是一个工具，但是如何让工具更好的满足不同的业务场景，可能就需要在应用层做一些扩展，比如应用层可以针对同一个问题调用多个大模型（避免出现大模型单点故障问题）等场景的扩展","like_count":0,"discussions":[{"author":{"id":2083554,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erZP8e2vqiaACFaDxruOzUTPbPv2uRUTp9UuEg98Ib9aYddjZK2kastqf0B14Ec7uXx7CCSXr0fhAA/132","nickname":"Geek_cf2545","note":"","ucode":"B69DF1E734FBA2","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":646719,"discussion_content":"说的很好👍 大模型是工具，上层ai应用可能是多个工具的集合","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1718609401,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]}]}