{"id":687062,"title":"26｜消息不丢失：生产者收到写入成功响应后消息一定不会丢失吗？","content":"<p>你好，我是大明。今天我们来学习消息队列中的新主题——消息丢失。</p><p>和消息丢失相对应的概念叫做可靠消息，这两者基本上指的就是同一件事。在实践中，一旦遇到消息丢失的问题，是很难定位的。从理论上来说，要想理解消息丢失，就需要对生产者到消费者整个环节都有深刻地理解。</p><p>今天我就带你看看从生产者发出，到消费者完成消费，每一个环节都需要考虑什么才可以确保自己的消息不会丢失。到最后，我会再给你一个在 Kafka 的基础上支持消息回查的方案，帮助你在面试的时候赢得竞争优势。让我们先从基础知识开始。</p><h2>Kafka 主从同步与 ISR</h2><p>在 Kafka 中，消息被存储在分区中。为了避免分区所在的消息服务器宕机，分区本身也是一个主从结构。换一句话来说，不同的分区之间是一个对等的结构，而每一个分区其实是由一个主分区和若干个从分区组成的。</p><p>不管是主分区还是从分区，都放在 broker 上。但是在放某个 topic 分区的时候，尽量做到一个 broker 上只放一个主分区，但是可以放别的主分区的从分区。</p><p><img src=\"https://static001.geekbang.org/resource/image/f8/yb/f8b5a1f5a32849a155283dea50d60yyb.png?wh=1920x1076\" alt=\"图片\"></p><p>这种思路也很容易理解，它有点像是隔离，也就是通过将主分区分布在不同的 broker 上，避免 broker 本身崩溃影响多个主分区。</p><h3>写入语义</h3><p>结合我们在 MySQL 部分对写入语义的讨论，你就可以想到，当我们说写入消息的时候，既可以是写入主分区，也可以是写入了主分区之后再写入一部分从分区。</p><!-- [[[read_end]]] --><p>这方面 Kafka 做得比较灵活，它让生产者来决定写入语义。这个控制参数叫做 acks，它的取值有三个。</p><ul>\n<li>0：就是所谓的 “fire and forget”，意思就是发送之后就不管了，也就是说 broker 是否收到，收到之后是否持久化，是否进行了主从同步，全都不管。</li>\n</ul><p><img src=\"https://static001.geekbang.org/resource/image/ac/83/ac3146bb0e35a512ebbd0c51477d4583.png?wh=1920x836\" alt=\"图片\"></p><ul>\n<li>1：当主分区写入成功的时候，就认为已经发送成功了。</li>\n</ul><p><img src=\"https://static001.geekbang.org/resource/image/13/77/1353ae8a02b273f87ae59ccae30e7f77.png?wh=1920x786\" alt=\"图片\"></p><ul>\n<li>all：不仅写入了主分区，还同步给了所有 ISR 成员。<br>\n<img src=\"https://static001.geekbang.org/resource/image/eb/84/ebbb36b5b50yy462ecba039152359b84.png?wh=1920x802\" alt=\"图片\"></li>\n</ul><p>这时候，你就接触到了 Kafka 中另外一个核心概念 ISR。</p><h3>ISR</h3><p>ISR（In-Sync Replicas）是指和主分区保持了主从同步的所有从分区。比如说，一个主分区本身有 3 个从分区，但是因为网络之类的问题，导致其中一个从分区和主分区失去了联系，没办法同步数据，那么对于这个主分区来说，它的 ISR 就是剩下的 2 个分区。</p><p><img src=\"https://static001.geekbang.org/resource/image/12/3f/12a8a6a8c0db302e2459bab8ca594b3f.png?wh=1920x853\" alt=\"图片\"></p><p>Kafka 对 ISR 里面的分区数量有没有限制呢？比如说，我有一个主分区，有 11 个从分区，那我的 ISR 可以只有一个从分区吗？</p><p>是可以的，我们能够通过min.insync.replicas这个参数来配置。比如说当你设置 min.insync.replicas = 2 的时候，就意味着 ISR 里面至少要有两个从分区。如果分区数量不足，那么生产者在配置 acks = all 的时候，发送消息会失败。与它对应的一个概念是 OSR，也就是不在 ISR 里面的分区集合。</p><h2>消息丢失的各种场景</h2><p>为了让你理解后面我们提到的各种措施，现在我要先带你分析一下消息从生产者发送到消费者完成消费这个过程中，究竟哪些环节可能导致消息丢失。</p><h3>生产者发送</h3><p>了解了 acks 参数之后，我们首先能够想到一个消息丢失的场景就是生产者把 acks 设置成 0，然后发送消息。这个时候虽然生产者能够拿到消息客户端返回的成功响应，但是事实上 broker 可能根本没收到，或者收到了但是处理新消息的时候遇到 Bug 了。</p><p><img src=\"https://static001.geekbang.org/resource/image/by/e6/byy09273953344093825845yy28e8fe6.png?wh=1920x749\" alt=\"图片\"></p><p>如果你启用了批量发送功能，而且批次比较大的话，那么还可能发生的情况就是，Kafka 客户端连请求都没有发送出去，服务就整个崩溃了，这种情况也会引起消息丢失。</p><p>那么是不是主分区真的写入了就万无一失了呢？也不是，因为你还要考虑主从同步的问题。</p><h3>主从同步</h3><p>我们注意到在 acks=1 的时候，只要求写入主分区就可以。所以假设在写入主分区之后，主分区所在 broker 立刻就崩溃了。这个时候发起新的主分区选举，不管是哪个从分区被选上，它都缺了这条消息。</p><p><img src=\"https://static001.geekbang.org/resource/image/3b/30/3be0fc0783a37ba7a72a031dd896da30.png?wh=1920x752\" alt=\"图片\"></p><p>这么看起来，只要使用 acks=all 就肯定不会有问题了，对不对？实际上也不是，因为 Kafka 里面还有一种 unclean 选举。在允许 unclean 选举的情况下，如果 ISR 里面没有任何分区，那么 Kafka 就会选择第一个从分区来作为主分区。</p><p><img src=\"https://static001.geekbang.org/resource/image/ef/83/efa51a426a5243408dbc58faeb786183.png?wh=1920x1006\" alt=\"图片\"></p><p>这种 unclean 选举机制本身主要是为了解决你希望尽可能保证 Kafka 依旧可用，并且等待从分区重新进入 ISR 的问题。类似地，unclean 选出来的新的主分区也可能少了部分数据。那么如果我设置 acks=all 并且禁用 unclean 选举，是不是就万无一失了？</p><p>实际上也不是，因为你还有一个问题没有考虑到，就是刷盘。</p><h3>刷盘</h3><p>之前我们在数据库部分讨论过写入语义，提到了 redo log 和 binlog 的刷盘问题。在 Kafka 这里还是会有这个问题。</p><p>当 acks=1 的时候，主分区返回写入成功的消息，但是这个时候消息可能还在操作系统的 page cache 里面。</p><p>而当 acks=all 的时候，主分区返回写入成功的消息，不管是主分区还是 ISR 中的从分区，这条消息都可能还在 page cache 里面。</p><p><img src=\"https://static001.geekbang.org/resource/image/d8/89/d8229a87f6e364e8703yybcfc66e1089.png?wh=1920x945\" alt=\"图片\"></p><p>而在 Kafka 中，控制刷盘的参数有三个。</p><ul>\n<li>log.flush.interval.messages：控制消息到多少条就要强制刷新磁盘。Kafka 会在写入 page cache 的时候顺便检测一下。</li>\n<li>log.flush.interval.ms：间隔多少毫秒就刷新数据到磁盘上。</li>\n<li>log.flush.scheduler.interval.ms：间隔多少毫秒，就检测数据是否需要刷新到磁盘上。</li>\n</ul><p>后面两个是要配合在一起的。举个例子，假如说 log.flush.internval.ms 设置为 500，而 log.flush.schduler.interval.ms 设置为 200。也就是说，Kafka 每隔 200 毫秒检查一下，如果上次刷新到现在已经过了 500 毫秒，那么就刷新一次磁盘。</p><p>而 log.flush.interval.messages 和 log.flush.interval.ms 都设置了的话，那么就是它们俩之间任何一个条件满足了，都会刷新磁盘。</p><p>这里我教你一个简单的记忆方法：Kafka 要么是<strong>定量刷</strong>，要么是<strong>定时刷</strong>。</p><p>不过，Kafka 的维护者之前是不建议调整这些参数的，而是强调依赖于副本（从分区）来保证数据不丢失。</p><h3>消费者提交</h3><p>消费者提交是指消费者提交了偏移量，但是最终却没有消费的情况。比如说线程池形态的异步消费，消费者线程拿到消息就直接提交，然后再转交给工作线程。在转交之前，或者工作线程正在处理的时候，消费者都有可能宕机。于是一个消息本来并没有被消费，但是却被提交了，这也叫做消息丢失。</p><h2>面试准备</h2><p>在面试前，你要在公司内部收集一些和消息丢失相关的素材。</p><ul>\n<li>你或者你的同事有没有因为消息丢失而出现线上故障？如果出现过，那么是因为什么原因引起的故障？后来又是怎么解决的？或者说你用什么措施来防止再次出现这种问题？</li>\n<li>核心业务的 topic 的分区数量是多少，每一个主分区有多少个从分区？</li>\n<li>你的业务发送消息的时候是不是异步发送？acks 的设置是多少？</li>\n<li>你使用的 Kafka 里面那三个刷盘参数的值分别是多少？如果和默认值不一样，为什么修改？</li>\n<li>你有没有遇到一些场景是必须要发送消息成功的？在这些场景下是如何保证业务方一定把消息发送出来的？</li>\n</ul><p>你在平时学习类似 Kafka 这种框架的时候，要注意一下它们的写入语义。这个之前我在 MySQL 部分已经提过了。你多看几个框架，你就会发现在写入语义上，不同框架之间的区别很小。</p><p>应该说，大部分框架的设计理念都是接近的，你在平时学习的时候注意总结。这些总结出来的内容能体现你对问题思考的深度和广度，你就可以用在面试中。</p><p>如果面试官问到了下面这些问题，你就可以考虑把话题引导到消息丢失这个话题上。</p><ul>\n<li>面试官问到了延迟消息，那么你可以在介绍了如何在 Kafka 上支持延迟消息之后，提及你采用类似的手段支持了消息回查。</li>\n<li>面试官问到了有关刷盘的问题，比如说 MySQL 里的 redo log，那么你可以提起在 Kafka 里面也有类似的参数。</li>\n<li>面试官问到了分区表、分库分表等问题，你可以说你用这些技术解决过延迟消息和消息回查的问题。</li>\n<li>面试官问到了有关主从模式的问题，那么你可以介绍一下在主从模式下的写入语义。</li>\n</ul><p>面试官也可能直接问你和消息丢失有关的问题。比如说：</p><ul>\n<li>你的业务有没有遇到过消息丢失的问题？最后是怎么解决的？</li>\n<li>你的业务发送消息的时候，acks 是怎么设置的？你为什么设置成这个值？</li>\n<li>在使用异步消费的时候，怎么做避免消息已提交，但是最终却没有消费的情况？</li>\n<li>什么是 ISR？什么样的场景可能会导致一个分区被挪出 ISR？</li>\n</ul><h2>基本思路</h2><p>这一次的面试方案强调的是成体系。这种面试思路你以前已经见过了，它能够全方面体现你对某一个主题的理解。首先你需要从整体上介绍一下你的方案。</p><blockquote>\n<p>在我的核心业务里面，关键点是消息是不能丢失的。也就是说，发送者在完成业务之后，一定要把消息发送出去，而消费者也一定要消费这个消息。所以，我在发送方、消息队列本身以及消费者三个方面，都做了很多事情来保证消息绝对不丢失。</p>\n</blockquote><h3>发送方一定发了消息</h3><p>这实际上和本地事务有点关系。你可以把类似场景都抽象成执行业务操作和发送消息这两个步骤。</p><p>站在业务的角度，我们需要确保这两个步骤要么都不执行，要么都执行。这本身是一个分布式事务的问题，大体上有两种方案：本地消息表和消息回查。这里我们先看本地消息表方案，消息回查方案会作为亮点方案在后面系统分析。</p><p>本地消息表这个方案整体来说并不复杂，在实践中被广泛使用。你可以先讲述这个方案的基本思路。</p><blockquote>\n<p>在发送方，我采用的是本地消息表解决方案。简单来说，就是在业务操作的过程中，在本地消息表里面记录一条待发消息，做成一个本地数据库事务。然后尝试立刻发送消息，如果发送成功，那么就把本地消息表里对应的数据删除，或者把状态标记成已发送。<br>\n&nbsp;<br>\n如果这个时候失败了，就可以立刻尝试重试。同时，还要有一个异步的补发机制，扫描本地消息表，找出已经过了一段时间，比如说三分钟，但是还没有发送成功的待发消息，然后补发。</p>\n</blockquote><p>最后提到的异步补发机制，你可以简单理解成有一个线程定时扫描数据库，找到需要发送但是又没有发送的消息发送出去。更直观的来说，就是这个线程会执行一个类似这样的 SQL。</p><pre><code class=\"language-plain\">SELECT * FROM msg_tab WHERE create_time &lt; now() - 3min AND status = '未发送'\n#找出三分钟前还没发送出去的消息，然后补发。\n</code></pre><p>整个过程如下图。</p><p><img src=\"https://static001.geekbang.org/resource/image/d8/86/d8d681ff7bc0469aa703d80bc2481f86.png?wh=1844x1414\" alt=\"图片\"></p><p>我在图里标注了三个易出错点，面试官大概率会追问这三个点，也就是你要刷亮点的地方。</p><blockquote>\n<ol>\n<li>如果已经提交事务了，那么即便服务器立刻宕机了也没关系。因为我们的异步补发机制会找出这条消息，进行补发。<br>\n&nbsp;</li>\n<li>如果消息发送成功了，但是还没把数据库里的消息状态更新成已发送，也没关系，异步补发机制还是会找出这条消息，再发一次。也就是说，在这种情况下会发送两次。<br>\n&nbsp;</li>\n<li>如果在重试的过程中，重发成功了但是还没把消息状态更新成已发送，和第 2 点一样，也是依赖于异步补发机制。</li>\n</ol>\n</blockquote><p>我们注意到，这三点都依赖于异步补发机制。但是，就像我前面多次提到的，你重试也要控制住重试间隔和重试次数。所以在你的本地消息表里，还可以用额外的字段来控制重试间隔和重试次数。</p><blockquote>\n<p>我在本地消息表里面额外增加了一个新的列，用来控制重试的间隔和重试的次数。如果最终补发都失败了就会告警。这个时候就需要人手工介入了。</p>\n</blockquote><p>那么这时候本地消息表至少有两个关键列：一个是消息体列，里面存储了消息的数据；另一个是重试机制列，里面可以只存储重试次数，也可以存储重试间隔、已重试次数、最大重试次数。剩余的列，你就根据自己的需要随便加，不关键。</p><p>最后你注意总结升华一下，体现出你对分布式事务的深刻理解。</p><blockquote>\n<p>这种解决方案其实就是把一个分布式事务转变成本地事务 + 补偿机制。在这里案例里面，我们的分布式事务是要求执行业务操作并且发消息，那么就转化成一个本地事务，这个本地事务包含了业务操作，以及下一步做什么。然后，补偿机制会查看本地事务提交的数据，找出需要执行但是又没有执行成功的下一步，执行。这里的下一步，就是发送消息。</p>\n</blockquote><p>在实践中，很多分布式事务都可以转化成本地事务 + 补偿机制，你可以看看自己公司有没有类似的场景。这部分面试可能会把话题转向分布式事务，需要把这两部分知识串联起来记忆。</p><h3>消息队列不丢失</h3><p>发送者一定发了消息就意味着它拿到了消息队列的响应，那么根据前面的基础知识，要想让消息队列一定不会丢失消息，那么 acks 就需要设置成 all。而且，也不能允许 Kafka 使用 unclean 选举。</p><p>进一步考虑刷盘的问题，那么就需要调整 log.flush.interval.messages、log.flush.interval.ms 和 log.flush.scheduler.interval.ms 的值。</p><p>这一点，你可以结合自己公司的实际取值来回答。</p><blockquote>\n<p>在关键业务上，我一般都是把 acks 设置成 all 并且禁用 unclean 选举，来确保消息发送到了消息队列上，而且不会丢失。同时 log.flush.interval.messages、log.flush.interval.ms 和 log.flush.scheduler.interval.ms 三个参数会影响刷盘，这三个值我们公司设置的是 10000、2000、3000。<br>\n&nbsp;<br>\n理论上来说，这种配置确实还是有一点消息丢失的可能，但是概率已经非常低了。只有一种可能，就是消息队列完成主从同步之后，主分区和 ISR 的从分区都没来得及刷盘就崩溃了，才会丢失消息。这个时候真丢失了消息，就只能人手工补发了。</p>\n</blockquote><p>你也可以从优化的角度来描述。</p><blockquote>\n<p>早期我们就遇到过一个消息丢失的案例。我们有一个业务在发送消息的时候把 acks 设置成了 0，后来有一天消息队列真的崩了，等再恢复过来的时候，已经找不到消息了。而这个业务其实是一个很核心的业务，所以我们把 acks 的设置改成了 all。之后消息队列再崩溃，也确实没再出现过丢失的问题。</p>\n</blockquote><p>当消息队列确保消息不会丢失之后，你需要做的就是确保消费者肯定消费了。</p><h3>消费者肯定消费</h3><p>消费者肯定消费这个几乎不需要你额外做什么，除非你使用了异步消费机制，这部分你可以参考消息积压那一节课提到的异步消费方案。</p><p>这里你只需要简单介绍一下。</p><blockquote>\n<p>要确保消费者肯定消费消息，大多数时候都不需要额外做什么，但是如果业务上有使用异步消费机制就要小心一些。比如说我的 A 业务里面就采用了异步消费来提高消费速率，我利用批量消费、批量提交来保证异步消费的同时，也不会出现未消费的问题。</p>\n</blockquote><p>这里就可以把话题引导到异步消费上，你也就可以顺便提起消息积压的问题，这样整个面试节奏就在你的掌控之中了。</p><h2>亮点方案：在 Kafka 上支持消息回查机制</h2><p>所谓的消息回查机制是指消息队列允许你在发送消息的时候，先发一个准备请求，里面带着你的消息。这个时候消息队列并不会把消息转交给消费者，而是当业务完成之后，你需要再发一个确认请求，这时候消息中间件才会把消息转交给消费者。</p><p><img src=\"https://static001.geekbang.org/resource/image/8d/d6/8d9d674df16be9850b2a1d67c5dc2cd6.png?wh=1920x1080\" alt=\"图片\"></p><p>显然，这就是之前我们讨论的两阶段提交的一个简单应用，所以这个也被叫做事务消息。</p><p>你仔细看一下事务消息这张图，你就会发现一个问题：如果我的业务成功了，但是我的确认请求没发怎么办？所以这时候就有了消息回查，也就是消息在没收到确认请求的时候，会反过来问一下你，这个消息要不要交给消费者。</p><p><img src=\"https://static001.geekbang.org/resource/image/ff/40/ff789860cf433f3e91517cacd11d9540.png?wh=1920x1080\" alt=\"图片\"></p><p>消息回查机制依赖于消息队列的支持。RocketMQ 是支持的，但是不幸的是 Kafka 和 RabbitMQ 都不支持。所以这里就有一个问题了，就是怎么在 Kafka 的基础上支持消息回查。</p><p><img src=\"https://static001.geekbang.org/resource/image/c8/c7/c83e031e7c8895710bfc1f1ddddf77c7.png?wh=1920x1120\" alt=\"图片\"></p><p>你可以结合图片简要回答整个流程。</p><blockquote>\n<p>我们公司用的是 Kafka，它并不支持消息回查机制，所以我在公司里面设计过一个系统来支持回查功能。<br>\n&nbsp;<br>\n它的基本步骤是这样的：</p>\n<ol>\n<li>应用代码把准备消息发送到 topic=look_back_msg 上。里面包含业务 topic、消息体、业务类型、业务 ID、准备状态、回查接口。</li>\n<li>回查中间件消费这个 look_back_msg，把消息内容存储到数据库里。</li>\n<li>应用代码执行完业务操作之后，再发送一个消息到 look_back_msg 上，带上业务类型、业务 ID 和提交状态这些信息。如果应用代码执行业务出错了，那么就使用回滚状态。</li>\n<li>回查中间件查询消息内容，转发到业务 topic 上。</li>\n</ol>\n</blockquote><p>整个过程到处都是亮点，我们一个一个看。</p><h3>亮点一：回查实现</h3><p>你应该注意到了，如果在业务操作完成之后，没有发提交消息，这时候就需要回查中间件来回查。一般来说，回查中间件会异步地扫描长时间未提交的消息，然后回查业务方。</p><p><img src=\"https://static001.geekbang.org/resource/image/90/c0/90b4f9762f283c80b0a34f5504fe3ac0.png?wh=1920x1076\" alt=\"图片\"></p><p>这里的关键点就是<strong>回查中间件得知道怎么回查你的应用代码</strong>。正常来说，你这里应该要设计成可扩展的，也就是说可以回查 HTTP 接口，也可以回查 RPC 接口。</p><p>所以你接着补充。</p><blockquote>\n<p>如果业务方最终没有发送提交消息，那么回查中间件会找出这些长时间没提交的消息，执行回查。回查中间件执行回查的关键点是利用准备消息中带着的回查接口配置来发起调用。我设计了一个通用的机制，支持 HTTP 调用或者 RPC 调用。<br>\n&nbsp;<br>\n对于 HTTP 调用来说，业务方需要提供回查 URL。而对于 RPC 调用来说，业务方需要实现我提供的回查接口，然后提供对应的服务名。我在回查的时候会带上业务类型和业务 ID，业务方需要告诉我这个消息能不能提交，也就是要不要发给业务 topic。</p>\n</blockquote><p>上面的回答你肯定摸不着头脑，尤其是这个回查接口究竟是怎么一回事。我给你举个例子，你就明白了。如果是回查一个订单业务的 HTTP 接口，那么业务方需要告诉我回查 URL，那么回查中间件发出的请求就类似于下面这样。</p><pre><code class=\"language-plain\">method: POST\nURL: https://abc.com:8080/order/lookback\nBody: {\n  \"biz_type\": \"order\",\n  \"biz_id\": \"oid-123\"\n}\n</code></pre><p>业务方返回的响应：</p><pre><code class=\"language-plain\">Body: {\n  \"biz_type\": \"order\",\n  \"biz_id\": \"oid-123\",\n  \"status\": \"提交\" //如果业务没成功，那么可以是回滚\n}\n</code></pre><p>而如果是 RPC 接口，回查中间件就可以定义一个接口，要求所有的业务方都实现这个接口。</p><pre><code class=\"language-plain\">type MsgLookBack interface{\n    LookBack(bizType string, bizID int) Status\n}\n</code></pre><p>然后业务方需要提供服务名字，比如说 abc.com.order.msg_look_back，回查中间件会利用 RPC 的泛化调用功能，发起调用。如果你不理解泛化调用，那么你可以说你暂时只支持了 HTTP 回查接口，但是将来可以轻易扩展到 RPC 调用上。</p><p>这是一个非常能够体现你设计能力的一个点，你要是答好了，就足以证明你具备设计复杂系统来解决业务问题的能力。</p><h3>亮点二：数据存储</h3><p>这部分和你在延迟队列里看到的差不多。在延迟队列中，我介绍过你可以考虑使用分区表、交替表或者分库分表来存储延迟消息。这里你同样可以用分区表、交替表和分库分表来存储回查消息。</p><p>具体细节我就不重复了，你可以参考延迟队列的内容。你在回答的时候注意引导就可以，我用分区表作为例子给你演示一下。</p><blockquote>\n<p>为了保证我这个回查机制的高性能和高可靠，我使用了分区表。我按照时间进行分区，并且历史分区是可以快速归档的，毕竟这个回查机制使用的数据库只是临时存储一下消息数据而已。当然，后续随着业务扩展，我觉得这个地方是可以考虑使用分库分表的，比如说按照业务 topic 来分库分表。</p>\n</blockquote><h3>亮点三：有序消息</h3><p>你有没有想过这样一种可能：我的中间件回查机制，有没有可能先收到某个业务的提交消息？</p><p>答案是有可能的。但是回查机制要求的是一定要先收到准备消息，再收到提交消息。所以你可以尝试讲清楚这个点。</p><blockquote>\n<p>这个方案是要求准备消息和提交消息是有序的，也就是说，同一个业务的准备消息一定要先于提交消息。解决方案也很简单，在发送的时候要求业务方按照业务 ID 计算一个哈希值，然后除以分区数量的余数，就是目标分区。</p>\n</blockquote><p>显然，你也可以在这里趁机把话题引导到有序消息上。</p><h2>面试思路总结</h2><p>最后我们来总结一下这节课的主要内容。为了理解消息丢失这个问题，我给你介绍了 Kafka 主从同步与 ISR 的基本概念，然后系统地分析了各个环节消息丢失的场景。在面试的时候，你要沿着生产者、消息队列、消费者这条线来说明每一个环节怎么做到消息不丢失。</p><ul>\n<li>在生产者这一边要保证消息一定被发出来，可以考虑本地消息表和消息回查机制。</li>\n<li>在消息队列上要注意设置 acks 参数，同时也要注意三个刷盘参数：log.flush.interval.messages、log.flush.interval.ms 和 log.flush.scheduler.interval.ms。</li>\n<li>在消费者这边，只需要小心异步消费的问题就可以了。</li>\n</ul><p>而 Kafka 本身并不支持消息回查机制，所以你可以考虑利用 MySQL 来支持。核心就是借鉴两阶段提交协议，要求业务方先发准备消息，再发提交消息。如果没有发送提交消息，你就可以回查业务方。对应的三个关键点就是回查怎么实现、数据怎么存储、准备消息和提交消息怎么保持有序？</p><p>这里我再强调一点，我几次提到重试的时候你就应该能够想到，这必然会导致重复消费，也因此要求消费者必须是幂等的。</p><p>同时，结合延迟消息，我给了你两个增强 Kafka 功能的方案。你如果有时间，可以尝试自己把它们两者融合在一起，做成一个开源框架。</p><p>一方面，这两个方案都要求支持高并发、高性能、大数据，对你来说很能锻炼自己设计和实现一个系统的能力。另外一方面，如果你真的能够按照开源标准做出来，那么你只要不是面什么高级架构师之类的岗位，就都能赢得竞争优势。</p><p><img src=\"https://static001.geekbang.org/resource/image/a3/0d/a3b33a0dc84166b8ebaa35fea709920d.jpg?wh=2290x3237\" alt=\"\"></p><h2>思考题</h2><p>最后请你来思考两个问题。</p><ul>\n<li>在支持 Kafka 回查机制中，要是回查中间件把消息转发到业务 topic 了，但是标记成已发送失败，会发生什么？</li>\n<li>在支持 Kafka 回查机制中，你可以考虑把关系型数据库换成 Redis，这样换的话有什么优缺点？</li>\n</ul><p>欢迎你把你的答案分享在评论区，也欢迎你把这节课的内容分享给需要的朋友，我们下节课再见！</p>","comments":[{"had_liked":false,"id":386068,"user_name":"Qualifor","can_delete":false,"product_type":"c1","uid":1658706,"ip_address":"河北","ucode":"8F42453286719C","user_header":"https://static001.geekbang.org/account/avatar/00/19/4f/52/791d0f5e.jpg","comment_is_top":false,"comment_ctime":1703950901,"is_pvip":false,"replies":[{"id":140736,"content":"使用 kafka 的核心是为了解耦、削峰和限流。从这个角度来说，因为本息消息表的性能限制，所以削峰和限流基本没啥效果，也就是说，mysql 该崩还是崩。因此这种形态下，只能说是为了解耦了。直接使用 mysql 的话，其实你就是将 mysql 当成了消息队列，那么这个时候你就要自己手动解决消费者组、偏移量之类的问题了。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1704187881,"ip_address":"广东","comment_id":386068,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"本地事务表加补偿机制这种方式真的有必要吗，感觉如果那么麻烦来保证持久性，kafka的优势完全没有了呀，直接用mysql得了呗","like_count":6,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":634895,"discussion_content":"使用 kafka 的核心是为了解耦、削峰和限流。从这个角度来说，因为本息消息表的性能限制，所以削峰和限流基本没啥效果，也就是说，mysql 该崩还是崩。因此这种形态下，只能说是为了解耦了。直接使用 mysql 的话，其实你就是将 mysql 当成了消息队列，那么这个时候你就要自己手动解决消费者组、偏移量之类的问题了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1704187881,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":379582,"user_name":"进击的和和","can_delete":false,"product_type":"c1","uid":2986043,"ip_address":"四川","ucode":"8978AF077FA6AD","user_header":"https://static001.geekbang.org/account/avatar/00/2d/90/3b/791d0f5e.jpg","comment_is_top":false,"comment_ctime":1692150927,"is_pvip":false,"replies":[{"id":138316,"content":"同学你好，26、27课的图片已经替换，现在是清晰版本，感谢反馈🌹","user_name":"编辑回复","user_name_real":"编辑","uid":2843479,"ctime":1692343229,"ip_address":"北京","comment_id":379582,"utype":2}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"作者你好 \n结尾今日课程总结的图好考验视力呀","like_count":6,"discussions":[{"author":{"id":2843479,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/63/57/cba4c68b.jpg","nickname":"小虎子🐯","note":"","ucode":"4C9530B3FB407B","race_medal":0,"user_type":8,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":625940,"discussion_content":"同学你好，26、27课的图片已经替换，现在是清晰版本，感谢反馈🌹","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1692343229,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":8}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":385948,"user_name":"sheep","can_delete":false,"product_type":"c1","uid":2770150,"ip_address":"广东","ucode":"DAC2036F08CE27","user_header":"https://static001.geekbang.org/account/avatar/00/2a/44/e6/2c97171c.jpg","comment_is_top":false,"comment_ctime":1703727268,"is_pvip":false,"replies":[{"id":140748,"content":"数据库崩了。你刚发出去，然后数据库崩了，或者网络抖动。又或者你刚发出去，结果应用自己崩了。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1704188862,"ip_address":"广东","comment_id":385948,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"问一个小问题，课后问题中，“要是回查中间件把消息转发到业务 topic 了，但是标记成已发送失败”，这样子的情况下会产生重复的消息，消费者要做好幂等性。但是什么情况下会出现已经发送过去了，但被标记为已发送失败这种情况呢，一般是网络问题？","like_count":3,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":634907,"discussion_content":"数据库崩了。你刚发出去，然后数据库崩了，或者网络抖动。又或者你刚发出去，结果应用自己崩了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1704188862,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":380381,"user_name":"Geek8004","can_delete":false,"product_type":"c1","uid":2328971,"ip_address":"中国香港","ucode":"B3828F6414BDB0","user_header":"","comment_is_top":false,"comment_ctime":1693464341,"is_pvip":false,"replies":[{"id":138530,"content":"赞！第一个问题，在落地的时候，要注意异步检查这种异常情况。\n第二个问题也对，正常如果 Redis 用了 Cluster，可用性很高的话，直接用 Redis 就可以。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1693487725,"ip_address":"广东","comment_id":380381,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"尝试回答下上面的题目:\n1.在支持 Kafka 回查机制中，要是回查中间件把消息转发到业务 topic 了，但是标记成已发送失败，会发生什么？\n\n答:会产生重复的消息\n\n在支持 Kafka 回查机制中，你可以考虑把关系型数据库换成 Redis，这样换的话有什么优缺点？\n答:优点:性能高,毕竟redis比mysql耐打;缺点:1.扫key的时候容易阻塞redis?2.掉电之后如果持久化机制如果不是每条数据都落盘的话,掉电之后可能造成消息丢失?\n请老师帮忙check下","like_count":1,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":626910,"discussion_content":"赞！第一个问题，在落地的时候，要注意异步检查这种异常情况。\n第二个问题也对，正常如果 Redis 用了 Cluster，可用性很高的话，直接用 Redis 就可以。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1693487726,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":390246,"user_name":"哆啦a喵","can_delete":false,"product_type":"c1","uid":3601364,"ip_address":"北京","ucode":"AE5E51BB43753D","user_header":"https://static001.geekbang.org/account/avatar/00/36/f3/d4/86a99ae0.jpg","comment_is_top":false,"comment_ctime":1714896859,"is_pvip":false,"replies":[{"id":141964,"content":"就是确保在业务层面上，消息一定发出去了。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1715229946,"ip_address":"广东","comment_id":390246,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"老师好，想问一下，这一讲的回查机制其实就是一个分布式事务的应用，也就是事务消息吗？\n\n为啥感觉好像不是和消息不丢失这个章节直接关联，更像是确认消息后执行业务逻辑的这个动作和中间件发送消息到业务mq这个动作，这两个动作的一个事务？","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":644384,"discussion_content":"就是确保在业务层面上，消息一定发出去了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1715229946,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":380452,"user_name":"浩仔是程序员","can_delete":false,"product_type":"c1","uid":1104601,"ip_address":"广东","ucode":"A7E5CF9E1571A2","user_header":"https://static001.geekbang.org/account/avatar/00/10/da/d9/f051962f.jpg","comment_is_top":false,"comment_ctime":1693626301,"is_pvip":false,"replies":[{"id":138601,"content":"这个纯纯就是面试用的，我个人也不怎么喜欢用回查。之前某些 MQ 提供消息回查的时候我还吐槽过这就是中间件研发者闲着没事给自己刷 KPI。\n\n你说的那种，是业务比对。就是要保证生产者的消息一定被消费了。但是也不是好的实践，因为生产者理论上来说，是不应该知道有消费者，有哪些消费者的，毕竟你们都通过 QM 解耦了。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1693896142,"ip_address":"广东","comment_id":380452,"utype":1}],"discussion_count":3,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"老师你好，这个消息回查是为了解决什么问题，如果是为了解决生产者发送成功，那本地消息表也可以，感觉消息回查增加了复杂度。我一开始以为的消息回查是业务方生产者写kafka，消费者消费完会回写一个结果给生产者，但是如果生产者一直没有收到消费者的回写，那生产者就会回查消费者提供的接口，更换对应的状态","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":627209,"discussion_content":"这个纯纯就是面试用的，我个人也不怎么喜欢用回查。之前某些 MQ 提供消息回查的时候我还吐槽过这就是中间件研发者闲着没事给自己刷 KPI。\n\n你说的那种，是业务比对。就是要保证生产者的消息一定被消费了。但是也不是好的实践，因为生产者理论上来说，是不应该知道有消费者，有哪些消费者的，毕竟你们都通过 QM 解耦了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1693896142,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":2,"child_discussions":[{"author":{"id":2770150,"avatar":"https://static001.geekbang.org/account/avatar/00/2a/44/e6/2c97171c.jpg","nickname":"sheep","note":"","ucode":"DAC2036F08CE27","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":634599,"discussion_content":"那如果面试官问，为什么不用本地信息表，而用这种复杂的回查方案，该怎么样回复呢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1703726896,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":627209,"ip_address":"广东","group_id":0},"score":634599,"extra":""},{"author":{"id":3794407,"avatar":"","nickname":"Geek_3d0fe8","note":"","ucode":"E75EACDA00E7A6","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":639398,"discussion_content":"为什么生产者要感知消费者呢，只要通过本地消息表确保一定能把消息发到mq里面就好了吧，消费没消费那是他的事情了，最多生产者这边提供一个接口给消费者来查信息","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1710590650,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":627209,"ip_address":"广东","group_id":0},"score":639398,"extra":""}]}]},{"had_liked":false,"id":379741,"user_name":"Feng","can_delete":false,"product_type":"c1","uid":1015205,"ip_address":"广东","ucode":"42DB60B7BF69D0","user_header":"https://static001.geekbang.org/account/avatar/00/0f/7d/a5/930c9103.jpg","comment_is_top":false,"comment_ctime":1692364028,"is_pvip":false,"replies":[{"id":138338,"content":"我没懂，你的意思是不是你还没订阅，生产者就生产消息了？这种情况不是指定偏移量就可以吗？或者说从 Oldest 开始消费。还是你这里有啥特殊的问题？","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1692528803,"ip_address":"广东","comment_id":379741,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"最近遇到个kafka消费者重新订阅某个主题，但是生产者的消息来的太快导致没有消费到的问题；\npython client可以consumer循环poll直到partition_EOF再通知生产消息，但是Java好像没有这个机制。","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":626091,"discussion_content":"我没懂，你的意思是不是你还没订阅，生产者就生产消息了？这种情况不是指定偏移量就可以吗？或者说从 Oldest 开始消费。还是你这里有啥特殊的问题？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1692528804,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":379607,"user_name":"peter","can_delete":false,"product_type":"c1","uid":1058183,"ip_address":"北京","ucode":"261C3FC001DE2D","user_header":"https://static001.geekbang.org/account/avatar/00/10/25/87/f3a69d1b.jpg","comment_is_top":false,"comment_ctime":1692188121,"is_pvip":false,"replies":[{"id":138352,"content":"1. 你可以认为，一个 broker 就是一个进程，一般是建议独立部署的\n2. 不不不，你的数据库存储部分，和回查部分是，是通用的。只有真的和 Kafka 打交道的部分，才用不上。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1692542546,"ip_address":"广东","comment_id":379607,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"请教老师两个问题：\nQ1：一个broker需要部署在一台机器上吗？\nQ2：回看中间件，相当于基于MQ进行二次开发了，需要针对选择的MQ，不具有通用性，是吗？","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":626109,"discussion_content":"1. 你可以认为，一个 broker 就是一个进程，一般是建议独立部署的\n2. 不不不，你的数据库存储部分，和回查部分是，是通用的。只有真的和 Kafka 打交道的部分，才用不上。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1692542546,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":392009,"user_name":"一颗星的夜","can_delete":false,"product_type":"c1","uid":1597035,"ip_address":"北京","ucode":"7AAD2AD9691C5D","user_header":"https://static001.geekbang.org/account/avatar/00/18/5e/6b/b8fce3a1.jpg","comment_is_top":false,"comment_ctime":1719676604,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"消息回查的可靠性是不是又依赖于消息回查中间件的可靠性？另外本地消息表这里是否可以靠redis来实现类似的功能，比如生产端写入一个带ttl的key和value（比如0）表示一个消息已发送，消费端消费完以后又更改对应key的value（比如1）代表消息消费已确认。排查消息丢失的时候看看redis的记录来判断整个链路哪个环节有丢数据的可能。","like_count":1,"discussions":[{"author":{"id":2323413,"avatar":"https://static001.geekbang.org/account/avatar/00/23/73/d5/b5da0102.jpg","nickname":"Sanford","note":"","ucode":"205AD3F0F301C0","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":648961,"discussion_content":"本地消息表, 感觉作者更多应该是想利用 本地消息表 和 业务表 在一个库上, 具有事务的一致性. 如果业务表回滚了, 本地消息表也会回滚. \n如果改用redis记录, 在流量比较大的场景下, 一些重试操作是很正常的, 例如“消费-处理-再生产”的场景, 我消费一条消息, 处理完之后再写入一条新消息, 要求整体具有最终的一致性, 那么当事务回滚时, redis的数据不会回滚, 就需要频繁的人工介入.","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1722442302,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":395277,"user_name":"彭俊","can_delete":false,"product_type":"c1","uid":1054541,"ip_address":"广东","ucode":"FBEDBCCF22F1D0","user_header":"https://static001.geekbang.org/account/avatar/00/10/17/4d/7e13ec93.jpg","comment_is_top":false,"comment_ctime":1730042239,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"生产者自己起一组消费者组去消费，并负责流转状态到发送成功。这个方案会不会简单很多","like_count":0},{"had_liked":false,"id":394921,"user_name":"Emmcd","can_delete":false,"product_type":"c1","uid":2004534,"ip_address":"广东","ucode":"8B8BFDD26CB89A","user_header":"https://static001.geekbang.org/account/avatar/00/1e/96/36/25938cd1.jpg","comment_is_top":false,"comment_ctime":1728812959,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":3,"product_id":100551601,"comment_content":"生产者不是可以通过配置retries参数实现异常重试吗，为啥要设计一套这么复杂的呢","like_count":0,"discussions":[{"author":{"id":1434114,"avatar":"https://static001.geekbang.org/account/avatar/00/15/e2/02/488aec70.jpg","nickname":"超级费事儿","note":"","ucode":"FD873FF4ADAA5F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":652753,"discussion_content":"retry也会失败，严格不丢是消息，需要考虑这样的极端情况。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1729582035,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"四川","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}