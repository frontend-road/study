{"id":79975,"title":"22丨SVM（上）：如何用一根棍子将蓝红两色球分开？","content":"<p>今天我来带你进行SVM的学习，SVM的英文叫Support Vector Machine，中文名为支持向量机。它是常见的一种分类方法，在机器学习中，SVM是有监督的学习模型。</p><p>什么是有监督的学习模型呢？它指的是我们需要事先对数据打上分类标签，这样机器就知道这个数据属于哪个分类。同样无监督学习，就是数据没有被打上分类标签，这可能是因为我们不具备先验的知识，或者打标签的成本很高。所以我们需要机器代我们部分完成这个工作，比如将数据进行聚类，方便后续人工对每个类进行分析。SVM作为有监督的学习模型，通常可以帮我们模式识别、分类以及回归分析。</p><p>听起来，是不是很高大上。我先带你做个小练习。</p><p>练习1：桌子上我放了红色和蓝色两种球，请你用一根棍子将这两种颜色的球分开。</p><p><img src=\"https://static001.geekbang.org/resource/image/21/88/210bc20b5963d474d425ad1ca9ac6888.jpg?wh=1726*1063\" alt=\"\"><br>\n你可以很快想到解决方案，在红色和蓝色球之间画条直线就好了，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/ec/bb/ec657a6d274b5afb4d8169df9c248abb.jpg?wh=1846*1389\" alt=\"\"><br>\n练习2：这次难度升级，桌子上依然放着红色、蓝色两种球，但是它们的摆放不规律，如下图所示。如何用一根棍子把这两种颜色分开呢？</p><p><img src=\"https://static001.geekbang.org/resource/image/b4/a3/b4b9793cdec47d0ea1528ff1922973a3.jpg?wh=1790*1085\" alt=\"\"><br>\n你可能想了想，认为一根棍子是分不开的。除非把棍子弯曲，像下面这样：</p><p><img src=\"https://static001.geekbang.org/resource/image/14/eb/144d72013a808e955e78718f6df3d2eb.jpg?wh=1710*1050\" alt=\"\"><br>\n所以这里直线变成了曲线。如果在同一个平面上来看，红蓝两种颜色的球是很难分开的。那么有没有一种方式，可以让它们自然地分开呢？</p><!-- [[[read_end]]] --><p>这里你可能会灵机一动，猛拍一下桌子，这些小球瞬间腾空而起，如下图所示。在腾起的那一刹那，出现了一个水平切面，恰好把红、蓝两种颜色的球分开。</p><p><img src=\"https://static001.geekbang.org/resource/image/9e/dc/9e07b78932456cd8a6f46d7ea65bdadc.png?wh=1358*577\" alt=\"\"></p><p><img src=\"https://static001.geekbang.org/resource/image/f3/34/f3497cd97c8bb06e952efcdae6059434.jpg?wh=1210*1020\" alt=\"\"><br>\n在这里，二维平面变成了三维空间。原来的曲线变成了一个平面。这个平面，我们就叫做超平面。</p><h2>SVM的工作原理</h2><p>用SVM计算的过程就是帮我们找到那个超平面的过程，这个超平面就是我们的SVM分类器。</p><p>我们再过头来看最简单的练习1，其实我们可以有多种直线的划分，比如下图所示的直线A、直线B和直线C，究竟哪种才是更好的划分呢？</p><p><img src=\"https://static001.geekbang.org/resource/image/74/e7/7459de7fbe99af85cbfdacf2333f84e7.jpg?wh=1444*1464\" alt=\"\"><br>\n很明显图中的直线B更靠近蓝色球，但是在真实环境下，球再多一些的话，蓝色球可能就被划分到了直线B的右侧，被认为是红色球。同样直线A更靠近红色球，在真实环境下，如果红色球再多一些，也可能会被误认为是蓝色球。所以相比于直线A和直线B，直线C的划分更优，因为它的鲁棒性更强。</p><p>那怎样才能寻找到直线C这个更优的答案呢？这里，我们引入一个SVM特有的概念：<strong>分类间隔</strong>。</p><p>实际上，我们的分类环境不是在二维平面中的，而是在多维空间中，这样直线C就变成了决策面C。</p><p>在保证决策面不变，且分类不产生错误的情况下，我们可以移动决策面C，直到产生两个极限的位置：如图中的决策面A和决策面B。极限的位置是指，如果越过了这个位置，就会产生分类错误。这样的话，两个极限位置A和B之间的分界线C就是最优决策面。极限位置到最优决策面C之间的距离，就是“分类间隔”，英文叫做margin。</p><p>如果我们转动这个最优决策面，你会发现可能存在多个最优决策面，它们都能把数据集正确分开，这些最优决策面的分类间隔可能是不同的，而那个拥有“最大间隔”（max margin）的决策面就是SVM要找的最优解。</p><p><img src=\"https://static001.geekbang.org/resource/image/50/ea/506cc4b85a9206cca12048b29919a7ea.jpg?wh=1524*1502\" alt=\"\"><br>\n<strong>点到超平面的距离公式</strong></p><p>在上面这个例子中，如果我们把红蓝两种颜色的球放到一个三维空间里，你发现决策面就变成了一个平面。这里我们可以用线性函数来表示，如果在一维空间里就表示一个点，在二维空间里表示一条直线，在三维空间中代表一个平面，当然空间维数还可以更多，这样我们给这个线性函数起个名称叫做“超平面”。超平面的数学表达可以写成：</p><p><img src=\"https://static001.geekbang.org/resource/image/76/28/765e87a2d9d6358f1274478dacbbce28.png?wh=536*72\" alt=\"\"><br>\n在这个公式里，w、x是n维空间里的向量，其中x是函数变量；w是法向量。法向量这里指的是垂直于平面的直线所表示的向量，它决定了超平面的方向。</p><p><strong>SVM就是帮我们找到一个超平面</strong>，这个超平面能将不同的样本划分开，同时使得样本集中的点到这个分类超平面的最小距离（即分类间隔）最大化。</p><p>在这个过程中，<strong>支持向量</strong>就是离<strong>分类超平面</strong>最近的样本点，实际上如果确定了支持向量也就确定了这个超平面。所以支持向量决定了分类间隔到底是多少，而在最大间隔以外的样本点，其实对分类都没有意义。</p><p>所以说， SVM就是求解最大分类间隔的过程，我们还需要对分类间隔的大小进行定义。</p><p>首先，我们定义某类样本集到超平面的距离是这个样本集合内的样本到超平面的最短距离。我们用di代表点xi到超平面wxi+b=0的欧氏距离。因此我们要求di的最小值，用它来代表这个样本到超平面的最短距离。di可以用公式计算得出：</p><p><img src=\"https://static001.geekbang.org/resource/image/83/76/8342b5253cb4c294c72cef6802814176.png?wh=279*163\" alt=\"\"><br>\n其中||w||为超平面的范数，di的公式可以用解析几何知识进行推导，这里不做解释。</p><p><strong>最大间隔的优化模型</strong></p><p>我们的目标就是找出所有分类间隔中最大的那个值对应的超平面。在数学上，这是一个凸优化问题（凸优化就是关于求凸集中的凸函数最小化的问题，这里不具体展开）。通过凸优化问题，最后可以求出最优的w和b，也就是我们想要找的最优超平面。中间求解的过程会用到拉格朗日乘子，和KKT（Karush-Kuhn-Tucker）条件。数学公式比较多，这里不进行展开。</p><h2>硬间隔、软间隔和非线性SVM</h2><p>假如数据是完全的线性可分的，那么学习到的模型可以称为硬间隔支持向量机。<strong>换个说法，硬间隔指的就是完全分类准确，不能存在分类错误的情况。软间隔，就是允许一定量的样本分类错误</strong>。</p><p>我们知道，实际工作中的数据没有那么“干净”，或多或少都会存在一些噪点。所以线性可分是个理想情况。这时，我们需要使用到软间隔SVM（近似线性可分），比如下面这种情况：</p><p><img src=\"https://static001.geekbang.org/resource/image/7c/a6/7c913ee92cdcf4d461f0ebc1314123a6.jpg?wh=1490*1447\" alt=\"\"><br>\n另外还存在一种情况，就是非线性支持向量机。</p><p>比如下面的样本集就是个非线性的数据。图中的两类数据，分别分布为两个圆圈的形状。那么这种情况下，不论是多高级的分类器，只要映射函数是线性的，就没法处理，SVM 也处理不了。这时，我们需要引入一个新的概念：<strong>核函数。它可以将样本从原始空间映射到一个更高维的特质空间中，使得样本在新的空间中线性可分</strong>。这样我们就可以使用原来的推导来进行计算，只是所有的推导是在新的空间，而不是在原来的空间中进行。</p><p><img src=\"https://static001.geekbang.org/resource/image/55/23/5530b0e61085a213ef1d0dfe02b70223.jpg?wh=1501*1163\" alt=\"\"><br>\n所以在非线性SVM中，核函数的选择就是影响SVM最大的变量。最常用的核函数有线性核、多项式核、高斯核、拉普拉斯核、sigmoid核，或者是这些核函数的组合。这些函数的区别在于映射方式的不同。通过这些核函数，我们就可以把样本空间投射到新的高维空间中。</p><p>当然软间隔和核函数的提出，都是为了方便我们对上面超平面公式中的w*和b*进行求解，从而得到最大分类间隔的超平面。</p><h2>用SVM如何解决多分类问题</h2><p>SVM本身是一个二值分类器，最初是为二分类问题设计的，也就是回答Yes或者是No。而实际上我们要解决的问题，可能是多分类的情况，比如对文本进行分类，或者对图像进行识别。</p><p>针对这种情况，我们可以将多个二分类器组合起来形成一个多分类器，常见的方法有“一对多法”和“一对一法”两种。</p><p>1.一对多法</p><p>假设我们要把物体分成A、B、C、D四种分类，那么我们可以先把其中的一类作为分类1，其他类统一归为分类2。这样我们可以构造4种SVM，分别为以下的情况：</p><p>（1）样本A作为正集，B，C，D作为负集；</p><p>（2）样本B作为正集，A，C，D作为负集；</p><p>（3）样本C作为正集，A，B，D作为负集；</p><p>（4）样本D作为正集，A，B，C作为负集。</p><p>这种方法，针对K个分类，需要训练K个分类器，分类速度较快，但训练速度较慢，因为每个分类器都需要对全部样本进行训练，而且负样本数量远大于正样本数量，会造成样本不对称的情况，而且当增加新的分类，比如第K+1类时，需要重新对分类器进行构造。</p><p>2.一对一法</p><p>一对一法的初衷是想在训练的时候更加灵活。我们可以在任意两类样本之间构造一个SVM，这样针对K类的样本，就会有C(k,2)类分类器。</p><p>比如我们想要划分A、B、C三个类，可以构造3个分类器：</p><p>（1）分类器1：A、B；</p><p>（2）分类器2：A、C；</p><p>（3）分类器3：B、C。</p><p>当对一个未知样本进行分类时，每一个分类器都会有一个分类结果，即为1票，最终得票最多的类别就是整个未知样本的类别。</p><p>这样做的好处是，如果新增一类，不需要重新训练所有的SVM，只需要训练和新增这一类样本的分类器。而且这种方式在训练单个SVM模型的时候，训练速度快。</p><p>但这种方法的不足在于，分类器的个数与K的平方成正比，所以当K较大时，训练和测试的时间会比较慢。</p><h2>总结</h2><p>今天我给你讲了SVM分类器，它在文本分类尤其是针对二分类任务性能卓越。同样，针对多分类的情况，我们可以采用一对多，或者一对一的方法，多个二值分类器组合成一个多分类器。</p><p>另外关于SVM分类器的概念，我希望你能掌握以下的三个程度：</p><ol>\n<li>\n<p>完全线性可分情况下的线性分类器，也就是线性可分的情况，是最原始的SVM，它最核心的思想就是找到最大的分类间隔；</p>\n</li>\n<li>\n<p>大部分线性可分情况下的线性分类器，引入了软间隔的概念。软间隔，就是允许一定量的样本分类错误；</p>\n</li>\n<li>\n<p>线性不可分情况下的非线性分类器，引入了核函数。它让原有的样本空间通过核函数投射到了一个高维的空间中，从而变得线性可分。</p>\n</li>\n</ol><p>在SVM的推导过程中，有大量的数学公式，这里不进行推导演绎，因为除了写论文，你大部分时候不会用到这些公式推导。</p><p>所以最重要的还是理解我上面讲的这些概念，能在实际工作中使用SVM才是最重要的。下一节我会和你讲如何用sklearn工具包进行SVM分类，带你做一个实际的案例。</p><p>最后，你能说一下你对有监督学习和无监督学习的理解吗？以及，SVM最主要的思想就是硬间隔、软间隔和核函数。你是如何理解它们的？</p><p>欢迎你在评论区进行留言，与我分享你的答案。也欢迎点击“请朋友读”，把这篇文章分享给你的朋友或者同事。</p><p></p>","comments":[{"had_liked":false,"id":65065,"user_name":"captain","can_delete":false,"product_type":"c1","uid":1352640,"ip_address":"","ucode":"645767DA0960C7","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/2DyBmGYZYz2rgfdR3OMAletl16fZ9VZ9znkaJQSDny4bpcKLsmKMEUdbP4hDBm1f8jIOAfS1NZoYeYGMfgH7WQ/132","comment_is_top":false,"comment_ctime":1549016998,"is_pvip":false,"replies":[{"id":39999,"content":"关于书籍：\n《Python数据挖掘与机器学习实战》 因为我在代码中用到sklearn比较多，可以结合这个来看，里面有一些关于sklearn数据集的练习，我在专栏中也用到过，你可以对应起来看\n《白话大数据与机器学习》这本书主要讲算法原理，没有太多实战。想要对原理更深入了解的话可以看看\n《利用Python进行数据分析》 这本相对基础，没有太多算法部分，主要是关于Python的使用：数据结构，NumPy，Pandas，数据加载、存储、清洗、规整、可视化等。\n《精益数据分析》 这本书是将业务场景的，里面没有算法的部分，所以如果你想对业务场景有更深刻的理解，可以看下这本\n\n关于项目实战\n可以配合 https:&#47;&#47;www.kaggle.com&#47;\n比如你想做和SVM相关的，可以在kernels中搜索SVM\nhttps:&#47;&#47;www.kaggle.com&#47;kernels?sortBy=relevance&amp;group=everyone&amp;search=SVM&amp;page=1&amp;pageSize=20","user_name":"编辑回复","user_name_real":"何昌梅","uid":1165037,"ctime":1562221928,"ip_address":"","comment_id":65065,"utype":2}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"老师好，最近几期的算法课内容量比较大，麻烦推荐一些相关的理论或案例的书籍，谢谢","like_count":60},{"had_liked":false,"id":68235,"user_name":"third","can_delete":false,"product_type":"c1","uid":1025114,"ip_address":"","ucode":"9A37408A834F0B","user_header":"https://static001.geekbang.org/account/avatar/00/0f/a4/5a/e708e423.jpg","comment_is_top":false,"comment_ctime":1550463509,"is_pvip":false,"replies":[{"id":40003,"content":"这个解释比较通俗易懂，大家都可以看看。","user_name":"编辑回复","user_name_real":"何昌梅","uid":1165037,"ctime":1562222089,"ip_address":"","comment_id":68235,"utype":2}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"有监督学习，就是告诉他这个是红的那个是蓝的。你给我分出红蓝\n无监督，自己学会认识红色和蓝色，然后再分类\n\n硬间接，就是完美数据下的完美情况，分出完美类\n软间隔，就是中间总有杂质，情况总是复杂，分类总是有一点错误\n核函数，高纬度打低纬度，","like_count":45,"discussions":[{"author":{"id":1165037,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c6/ed/89a2dc13.jpg","nickname":"丢了个丢丢丢","note":"","ucode":"BDD7E97E0E5E96","race_medal":0,"user_type":4,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438306,"discussion_content":"关于书籍：\n《Python数据挖掘与机器学习实战》 因为我在代码中用到sklearn比较多，可以结合这个来看，里面有一些关于sklearn数据集的练习，我在专栏中也用到过，你可以对应起来看\n《白话大数据与机器学习》这本书主要讲算法原理，没有太多实战。想要对原理更深入了解的话可以看看\n《利用Python进行数据分析》 这本相对基础，没有太多算法部分，主要是关于Python的使用：数据结构，NumPy，Pandas，数据加载、存储、清洗、规整、可视化等。\n《精益数据分析》 这本书是将业务场景的，里面没有算法的部分，所以如果你想对业务场景有更深刻的理解，可以看下这本\n\n关于项目实战\n可以配合 https://www.kaggle.com/\n比如你想做和SVM相关的，可以在kernels中搜索SVM\nhttps://www.kaggle.com/kernels?sortBy=relevance&amp;amp;group=everyone&amp;amp;search=SVM&amp;amp;page=1&amp;amp;pageSize=20","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562221928,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":4}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":65855,"user_name":"李沛欣","can_delete":false,"product_type":"c1","uid":1362695,"ip_address":"","ucode":"98874954230D95","user_header":"https://static001.geekbang.org/account/avatar/00/14/cb/07/e34220d6.jpg","comment_is_top":false,"comment_ctime":1549702245,"is_pvip":false,"replies":[{"id":40001,"content":"对的，核函数就是从低维到高维的映射关系。如果从高维到低维进行维度压缩的话，可能就会变得混沌不可分。但是从低维到高维，属性维度增加了，可以在另一个空间中变得线性可分。","user_name":"编辑回复","user_name_real":"何昌梅","uid":1165037,"ctime":1562222004,"ip_address":"","comment_id":65855,"utype":2}],"discussion_count":3,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"核函数，是一种格局更高的分类模式。通过它我们可以把原本混沌的一堆数据映射到高维，从上帝视角来对这些数据进行线性分类。\n\n来，扔个二向箔🤣","like_count":18,"discussions":[{"author":{"id":1165037,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c6/ed/89a2dc13.jpg","nickname":"丢了个丢丢丢","note":"","ucode":"BDD7E97E0E5E96","race_medal":0,"user_type":4,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":439582,"discussion_content":"这个解释比较通俗易懂，大家都可以看看。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562222089,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":4}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":71132,"user_name":"fancy","can_delete":false,"product_type":"c1","uid":1243166,"ip_address":"","ucode":"0C51F80B9C35B1","user_header":"https://static001.geekbang.org/account/avatar/00/12/f8/1e/0d5f8336.jpg","comment_is_top":false,"comment_ctime":1551270807,"is_pvip":false,"replies":[{"id":40004,"content":"解释的很清晰，大家可以看下。","user_name":"编辑回复","user_name_real":"何昌梅","uid":1165037,"ctime":1562222143,"ip_address":"","comment_id":71132,"utype":2}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"1. 有监督学习and无监督学习\n有监督学习，即在已有类别标签的情况下，将样本数据进行分类。\n无监督学习，即在无类别标签的情况下，样本数据根据一定的方法进行分类，即聚类，分类好的类别需要进一步分析后，从而得知每个类别的特点。\n2. 硬间隔、软间隔、核函数\n使用SVM算法，是基于数据是线性分布的情况，这时使用硬间隔的方法分类数据即可。但实际情况下，大部分数据都不属于线性分布，即通过软间隔、核函数处理后，使得数据可以利用SVM算法进行分类。软间隔是通过允许数据有误差，不是绝对的线性分布；核函数是通过将非线性分布的数据映射为线性分布的数据。","like_count":10,"discussions":[{"author":{"id":1165037,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c6/ed/89a2dc13.jpg","nickname":"丢了个丢丢丢","note":"","ucode":"BDD7E97E0E5E96","race_medal":0,"user_type":4,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438613,"discussion_content":"对的，核函数就是从低维到高维的映射关系。如果从高维到低维进行维度压缩的话，可能就会变得混沌不可分。但是从低维到高维，属性维度增加了，可以在另一个空间中变得线性可分。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562222004,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":4}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1526391,"avatar":"https://static001.geekbang.org/account/avatar/00/17/4a/77/754a127b.jpg","nickname":"王张","note":"","ucode":"8153B5532B2C62","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":13888,"discussion_content":"三体么？🤣","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1568711949,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1362695,"avatar":"https://static001.geekbang.org/account/avatar/00/14/cb/07/e34220d6.jpg","nickname":"李沛欣","note":"","ucode":"98874954230D95","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1526391,"avatar":"https://static001.geekbang.org/account/avatar/00/17/4a/77/754a127b.jpg","nickname":"王张","note":"","ucode":"8153B5532B2C62","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":289453,"discussion_content":"哈哈哈","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1594105378,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":13888,"ip_address":"","group_id":0},"score":289453,"extra":""}]}]},{"had_liked":false,"id":203797,"user_name":"霸蛮人","can_delete":false,"product_type":"c1","uid":1929137,"ip_address":"","ucode":"EAB5F275D69490","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/73JN7HxoDAxjPmSWlaGydX6Cpico0aWNIP6mHYibB5BsYcLRt3f7Lm3ZgvtLYWTnBKm9D8bicZI7Q02UTicTiaXycLA/132","comment_is_top":false,"comment_ctime":1586268044,"is_pvip":false,"replies":[{"id":104326,"content":"总结的不错！！！","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1617901317,"ip_address":"","comment_id":203797,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"核函数，是使用变换思维，当数据从一个角度无法进行分类，就变换一个角度来分。就比如，两个人的声音混在一起，要区分开来的话，从时域的角度去看，互相叠加，根本就无法区分，但通过傅里叶变换到频域之后，通过频率的不同就能轻松地区分开来了。在这里，傅里叶变换就相当于核函数的作用。面对不同的数据常见，需要使用不同的变换角度，也就是不同的核函数。","like_count":6,"discussions":[{"author":{"id":1165037,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c6/ed/89a2dc13.jpg","nickname":"丢了个丢丢丢","note":"","ucode":"BDD7E97E0E5E96","race_medal":0,"user_type":4,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":441006,"discussion_content":"解释的很清晰，大家可以看下。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562222143,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":4}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":65243,"user_name":"Python","can_delete":false,"product_type":"c1","uid":1276314,"ip_address":"","ucode":"969500D2A88AE6","user_header":"https://static001.geekbang.org/account/avatar/00/13/79/9a/4f907ad6.jpg","comment_is_top":false,"comment_ctime":1549159124,"is_pvip":false,"replies":[{"id":40000,"content":"是的，可以这么理解。核函数与硬间隔、软间隔 不是在同一个维度，是从低维到高维空间的映射，因为在同一个维度上已经无法线性可分。而硬间隔、软间隔主要对线性可分的容错率。硬间隔可以完美切分样本，但是软间隔就需要允许有一定的样本分类错误。","user_name":"编辑回复","user_name_real":"何昌梅","uid":1165037,"ctime":1562221958,"ip_address":"","comment_id":65243,"utype":2}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"硬间隔，我认为就像线性回归一样，一条直线粗暴的画出边界，然后回答YES OR NO。\n软间隔，我认为类似逻辑回归，会绕一下弯子，最后给出的答案是一个概率。\n以上两种方式都是处理线性可分的数据，但碰到线性完全分布开的非线性数据的时候，就需要用到核函数，核函数主要是通过把低维的数据映射到高纬，产生一个落差，并给出一个超平面来划分。\n\n不知道我理解的对不对，希望老师回答YES OR NO","like_count":5,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":490962,"discussion_content":"总结的不错！！！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617901317,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2037505,"avatar":"https://static001.geekbang.org/account/avatar/00/1f/17/01/1c5309a3.jpg","nickname":"McKee Chen","note":"","ucode":"F74B76542FAB65","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":335149,"discussion_content":"举的例子真好","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1608106509,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":67897,"user_name":"林","can_delete":false,"product_type":"c1","uid":1256841,"ip_address":"","ucode":"A33AB4C8DE5646","user_header":"https://static001.geekbang.org/account/avatar/00/13/2d/89/a01375a1.jpg","comment_is_top":false,"comment_ctime":1550316636,"is_pvip":false,"replies":[{"id":40002,"content":"这一块适当屏蔽了一些数学原理，关于拉格朗日对偶和kkt的推导就省略了，感兴趣的同学可以看下SVM原理中的这部分。","user_name":"编辑回复","user_name_real":"何昌梅","uid":1165037,"ctime":1562222056,"ip_address":"","comment_id":67897,"utype":2}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"老师好，这一块的数学原理讲的有点少了吧，能不能讲讲拉格朗日对偶和kkt","like_count":3,"discussions":[{"author":{"id":1165037,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c6/ed/89a2dc13.jpg","nickname":"丢了个丢丢丢","note":"","ucode":"BDD7E97E0E5E96","race_medal":0,"user_type":4,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":439418,"discussion_content":"这一块适当屏蔽了一些数学原理，关于拉格朗日对偶和kkt的推导就省略了，感兴趣的同学可以看下SVM原理中的这部分。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562222056,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":4}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":67575,"user_name":"深白浅黑","can_delete":false,"product_type":"c1","uid":1123923,"ip_address":"","ucode":"DCCAA31DE8B127","user_header":"https://static001.geekbang.org/account/avatar/00/11/26/53/60fe31fb.jpg","comment_is_top":false,"comment_ctime":1550199212,"is_pvip":false,"replies":[{"id":64563,"content":"对的","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577621775,"ip_address":"","comment_id":67575,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"核心在于数据是否线性可分，以及容错能力强弱。\n硬间隔和软间隔都是处理线性可分的情况，区别在于容错能力。\n核函数用于处理线性不可分情况，将现有数据进行升维，达到线性可分，再进行类别划分处理。","like_count":3,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":439255,"discussion_content":"对的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577621775,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":150939,"user_name":"一纸书","can_delete":false,"product_type":"c1","uid":1659590,"ip_address":"","ucode":"C58A22B54521CA","user_header":"https://static001.geekbang.org/account/avatar/00/19/52/c6/8eb48963.jpg","comment_is_top":false,"comment_ctime":1573631971,"is_pvip":false,"replies":[{"id":59734,"content":"哈哈 确实 很形象","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1574738590,"ip_address":"","comment_id":150939,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"那句&quot;灵机一动,猛拍一下桌子&quot;真的是神来一笔,哈哈哈哈哈哈\n","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":439255,"discussion_content":"对的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577621775,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":87287,"user_name":"滢","can_delete":false,"product_type":"c1","uid":1221511,"ip_address":"","ucode":"971A6F20AF3F9A","user_header":"https://static001.geekbang.org/account/avatar/00/12/a3/87/c415e370.jpg","comment_is_top":false,"comment_ctime":1555559798,"is_pvip":false,"replies":[{"id":64249,"content":"对的 整理的不错 滢","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577615314,"ip_address":"","comment_id":87287,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"告诉机器，给它一些数据，这部分数据一些是数据集合A，一部分是属于集合B，然后让机器去把数据往集合A和集合B里去划分，这是有监督学习；同样的数据给机器，只是告诉它去做划分和归类，这是无监督学习，类似于孩子的放养。   \n硬间隔：表示得到的分类间隔即超平面 能完美的划分数据，不存在划分错误的情况，即零误差\n软间隔：表示得到的分类间隔，没有达到完美的程度，对数据划分存在一定的误差\n核函数：在数据分布无法用线性函数来表示的时候，需要对数据进行划分的标准变成来非线性的，这个时候就需要用到一种函数名叫核函数，核函数要做的工作是将原来的映射关系在更高维度的空间重新映射，使得新的映射关系变得线性可分。","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":474318,"discussion_content":"哈哈 确实 很形象","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1574738590,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":65065,"user_name":"captain","can_delete":false,"product_type":"c1","uid":1352640,"ip_address":"","ucode":"645767DA0960C7","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/2DyBmGYZYz2rgfdR3OMAletl16fZ9VZ9znkaJQSDny4bpcKLsmKMEUdbP4hDBm1f8jIOAfS1NZoYeYGMfgH7WQ/132","comment_is_top":false,"comment_ctime":1549016998,"is_pvip":false,"replies":[{"id":39999,"content":"关于书籍：\n《Python数据挖掘与机器学习实战》 因为我在代码中用到sklearn比较多，可以结合这个来看，里面有一些关于sklearn数据集的练习，我在专栏中也用到过，你可以对应起来看\n《白话大数据与机器学习》这本书主要讲算法原理，没有太多实战。想要对原理更深入了解的话可以看看\n《利用Python进行数据分析》 这本相对基础，没有太多算法部分，主要是关于Python的使用：数据结构，NumPy，Pandas，数据加载、存储、清洗、规整、可视化等。\n《精益数据分析》 这本书是将业务场景的，里面没有算法的部分，所以如果你想对业务场景有更深刻的理解，可以看下这本\n\n关于项目实战\n可以配合 https:&#47;&#47;www.kaggle.com&#47;\n比如你想做和SVM相关的，可以在kernels中搜索SVM\nhttps:&#47;&#47;www.kaggle.com&#47;kernels?sortBy=relevance&amp;group=everyone&amp;search=SVM&amp;page=1&amp;pageSize=20","user_name":"编辑回复","user_name_real":"何昌梅","uid":1165037,"ctime":1562221928,"ip_address":"","comment_id":65065,"utype":2}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"老师好，最近几期的算法课内容量比较大，麻烦推荐一些相关的理论或案例的书籍，谢谢","like_count":60,"discussions":[{"author":{"id":1165037,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c6/ed/89a2dc13.jpg","nickname":"丢了个丢丢丢","note":"","ucode":"BDD7E97E0E5E96","race_medal":0,"user_type":4,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438306,"discussion_content":"关于书籍：\n《Python数据挖掘与机器学习实战》 因为我在代码中用到sklearn比较多，可以结合这个来看，里面有一些关于sklearn数据集的练习，我在专栏中也用到过，你可以对应起来看\n《白话大数据与机器学习》这本书主要讲算法原理，没有太多实战。想要对原理更深入了解的话可以看看\n《利用Python进行数据分析》 这本相对基础，没有太多算法部分，主要是关于Python的使用：数据结构，NumPy，Pandas，数据加载、存储、清洗、规整、可视化等。\n《精益数据分析》 这本书是将业务场景的，里面没有算法的部分，所以如果你想对业务场景有更深刻的理解，可以看下这本\n\n关于项目实战\n可以配合 https://www.kaggle.com/\n比如你想做和SVM相关的，可以在kernels中搜索SVM\nhttps://www.kaggle.com/kernels?sortBy=relevance&amp;amp;group=everyone&amp;amp;search=SVM&amp;amp;page=1&amp;amp;pageSize=20","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562221928,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":4}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":68235,"user_name":"third","can_delete":false,"product_type":"c1","uid":1025114,"ip_address":"","ucode":"9A37408A834F0B","user_header":"https://static001.geekbang.org/account/avatar/00/0f/a4/5a/e708e423.jpg","comment_is_top":false,"comment_ctime":1550463509,"is_pvip":false,"replies":[{"id":40003,"content":"这个解释比较通俗易懂，大家都可以看看。","user_name":"编辑回复","user_name_real":"何昌梅","uid":1165037,"ctime":1562222089,"ip_address":"","comment_id":68235,"utype":2}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"有监督学习，就是告诉他这个是红的那个是蓝的。你给我分出红蓝\n无监督，自己学会认识红色和蓝色，然后再分类\n\n硬间接，就是完美数据下的完美情况，分出完美类\n软间隔，就是中间总有杂质，情况总是复杂，分类总是有一点错误\n核函数，高纬度打低纬度，","like_count":45,"discussions":[{"author":{"id":1165037,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c6/ed/89a2dc13.jpg","nickname":"丢了个丢丢丢","note":"","ucode":"BDD7E97E0E5E96","race_medal":0,"user_type":4,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":439582,"discussion_content":"这个解释比较通俗易懂，大家都可以看看。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562222089,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":4}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":65855,"user_name":"李沛欣","can_delete":false,"product_type":"c1","uid":1362695,"ip_address":"","ucode":"98874954230D95","user_header":"https://static001.geekbang.org/account/avatar/00/14/cb/07/e34220d6.jpg","comment_is_top":false,"comment_ctime":1549702245,"is_pvip":false,"replies":[{"id":40001,"content":"对的，核函数就是从低维到高维的映射关系。如果从高维到低维进行维度压缩的话，可能就会变得混沌不可分。但是从低维到高维，属性维度增加了，可以在另一个空间中变得线性可分。","user_name":"编辑回复","user_name_real":"何昌梅","uid":1165037,"ctime":1562222004,"ip_address":"","comment_id":65855,"utype":2}],"discussion_count":3,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"核函数，是一种格局更高的分类模式。通过它我们可以把原本混沌的一堆数据映射到高维，从上帝视角来对这些数据进行线性分类。\n\n来，扔个二向箔🤣","like_count":18,"discussions":[{"author":{"id":1165037,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c6/ed/89a2dc13.jpg","nickname":"丢了个丢丢丢","note":"","ucode":"BDD7E97E0E5E96","race_medal":0,"user_type":4,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438613,"discussion_content":"对的，核函数就是从低维到高维的映射关系。如果从高维到低维进行维度压缩的话，可能就会变得混沌不可分。但是从低维到高维，属性维度增加了，可以在另一个空间中变得线性可分。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562222004,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":4}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1526391,"avatar":"https://static001.geekbang.org/account/avatar/00/17/4a/77/754a127b.jpg","nickname":"王张","note":"","ucode":"8153B5532B2C62","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":13888,"discussion_content":"三体么？🤣","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1568711949,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1362695,"avatar":"https://static001.geekbang.org/account/avatar/00/14/cb/07/e34220d6.jpg","nickname":"李沛欣","note":"","ucode":"98874954230D95","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1526391,"avatar":"https://static001.geekbang.org/account/avatar/00/17/4a/77/754a127b.jpg","nickname":"王张","note":"","ucode":"8153B5532B2C62","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":289453,"discussion_content":"哈哈哈","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1594105378,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":13888,"ip_address":"","group_id":0},"score":289453,"extra":""}]}]},{"had_liked":false,"id":71132,"user_name":"fancy","can_delete":false,"product_type":"c1","uid":1243166,"ip_address":"","ucode":"0C51F80B9C35B1","user_header":"https://static001.geekbang.org/account/avatar/00/12/f8/1e/0d5f8336.jpg","comment_is_top":false,"comment_ctime":1551270807,"is_pvip":false,"replies":[{"id":40004,"content":"解释的很清晰，大家可以看下。","user_name":"编辑回复","user_name_real":"何昌梅","uid":1165037,"ctime":1562222143,"ip_address":"","comment_id":71132,"utype":2}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"1. 有监督学习and无监督学习\n有监督学习，即在已有类别标签的情况下，将样本数据进行分类。\n无监督学习，即在无类别标签的情况下，样本数据根据一定的方法进行分类，即聚类，分类好的类别需要进一步分析后，从而得知每个类别的特点。\n2. 硬间隔、软间隔、核函数\n使用SVM算法，是基于数据是线性分布的情况，这时使用硬间隔的方法分类数据即可。但实际情况下，大部分数据都不属于线性分布，即通过软间隔、核函数处理后，使得数据可以利用SVM算法进行分类。软间隔是通过允许数据有误差，不是绝对的线性分布；核函数是通过将非线性分布的数据映射为线性分布的数据。","like_count":10,"discussions":[{"author":{"id":1165037,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c6/ed/89a2dc13.jpg","nickname":"丢了个丢丢丢","note":"","ucode":"BDD7E97E0E5E96","race_medal":0,"user_type":4,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":441006,"discussion_content":"解释的很清晰，大家可以看下。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562222143,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":4}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":203797,"user_name":"霸蛮人","can_delete":false,"product_type":"c1","uid":1929137,"ip_address":"","ucode":"EAB5F275D69490","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/73JN7HxoDAxjPmSWlaGydX6Cpico0aWNIP6mHYibB5BsYcLRt3f7Lm3ZgvtLYWTnBKm9D8bicZI7Q02UTicTiaXycLA/132","comment_is_top":false,"comment_ctime":1586268044,"is_pvip":false,"replies":[{"id":104326,"content":"总结的不错！！！","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1617901317,"ip_address":"","comment_id":203797,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"核函数，是使用变换思维，当数据从一个角度无法进行分类，就变换一个角度来分。就比如，两个人的声音混在一起，要区分开来的话，从时域的角度去看，互相叠加，根本就无法区分，但通过傅里叶变换到频域之后，通过频率的不同就能轻松地区分开来了。在这里，傅里叶变换就相当于核函数的作用。面对不同的数据常见，需要使用不同的变换角度，也就是不同的核函数。","like_count":6,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":490962,"discussion_content":"总结的不错！！！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617901317,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2037505,"avatar":"https://static001.geekbang.org/account/avatar/00/1f/17/01/1c5309a3.jpg","nickname":"McKee Chen","note":"","ucode":"F74B76542FAB65","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":335149,"discussion_content":"举的例子真好","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1608106509,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":65243,"user_name":"Python","can_delete":false,"product_type":"c1","uid":1276314,"ip_address":"","ucode":"969500D2A88AE6","user_header":"https://static001.geekbang.org/account/avatar/00/13/79/9a/4f907ad6.jpg","comment_is_top":false,"comment_ctime":1549159124,"is_pvip":false,"replies":[{"id":40000,"content":"是的，可以这么理解。核函数与硬间隔、软间隔 不是在同一个维度，是从低维到高维空间的映射，因为在同一个维度上已经无法线性可分。而硬间隔、软间隔主要对线性可分的容错率。硬间隔可以完美切分样本，但是软间隔就需要允许有一定的样本分类错误。","user_name":"编辑回复","user_name_real":"何昌梅","uid":1165037,"ctime":1562221958,"ip_address":"","comment_id":65243,"utype":2}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"硬间隔，我认为就像线性回归一样，一条直线粗暴的画出边界，然后回答YES OR NO。\n软间隔，我认为类似逻辑回归，会绕一下弯子，最后给出的答案是一个概率。\n以上两种方式都是处理线性可分的数据，但碰到线性完全分布开的非线性数据的时候，就需要用到核函数，核函数主要是通过把低维的数据映射到高纬，产生一个落差，并给出一个超平面来划分。\n\n不知道我理解的对不对，希望老师回答YES OR NO","like_count":5,"discussions":[{"author":{"id":1165037,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c6/ed/89a2dc13.jpg","nickname":"丢了个丢丢丢","note":"","ucode":"BDD7E97E0E5E96","race_medal":0,"user_type":4,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438369,"discussion_content":"是的，可以这么理解。核函数与硬间隔、软间隔 不是在同一个维度，是从低维到高维空间的映射，因为在同一个维度上已经无法线性可分。而硬间隔、软间隔主要对线性可分的容错率。硬间隔可以完美切分样本，但是软间隔就需要允许有一定的样本分类错误。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562221958,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":4}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":67897,"user_name":"林","can_delete":false,"product_type":"c1","uid":1256841,"ip_address":"","ucode":"A33AB4C8DE5646","user_header":"https://static001.geekbang.org/account/avatar/00/13/2d/89/a01375a1.jpg","comment_is_top":false,"comment_ctime":1550316636,"is_pvip":false,"replies":[{"id":40002,"content":"这一块适当屏蔽了一些数学原理，关于拉格朗日对偶和kkt的推导就省略了，感兴趣的同学可以看下SVM原理中的这部分。","user_name":"编辑回复","user_name_real":"何昌梅","uid":1165037,"ctime":1562222056,"ip_address":"","comment_id":67897,"utype":2}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"老师好，这一块的数学原理讲的有点少了吧，能不能讲讲拉格朗日对偶和kkt","like_count":3,"discussions":[{"author":{"id":1165037,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c6/ed/89a2dc13.jpg","nickname":"丢了个丢丢丢","note":"","ucode":"BDD7E97E0E5E96","race_medal":0,"user_type":4,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438369,"discussion_content":"是的，可以这么理解。核函数与硬间隔、软间隔 不是在同一个维度，是从低维到高维空间的映射，因为在同一个维度上已经无法线性可分。而硬间隔、软间隔主要对线性可分的容错率。硬间隔可以完美切分样本，但是软间隔就需要允许有一定的样本分类错误。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562221958,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":4}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":67575,"user_name":"深白浅黑","can_delete":false,"product_type":"c1","uid":1123923,"ip_address":"","ucode":"DCCAA31DE8B127","user_header":"https://static001.geekbang.org/account/avatar/00/11/26/53/60fe31fb.jpg","comment_is_top":false,"comment_ctime":1550199212,"is_pvip":false,"replies":[{"id":64563,"content":"对的","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577621775,"ip_address":"","comment_id":67575,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"核心在于数据是否线性可分，以及容错能力强弱。\n硬间隔和软间隔都是处理线性可分的情况，区别在于容错能力。\n核函数用于处理线性不可分情况，将现有数据进行升维，达到线性可分，再进行类别划分处理。","like_count":3,"discussions":[{"author":{"id":1165037,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c6/ed/89a2dc13.jpg","nickname":"丢了个丢丢丢","note":"","ucode":"BDD7E97E0E5E96","race_medal":0,"user_type":4,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":439418,"discussion_content":"这一块适当屏蔽了一些数学原理，关于拉格朗日对偶和kkt的推导就省略了，感兴趣的同学可以看下SVM原理中的这部分。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562222056,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":4}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":150939,"user_name":"一纸书","can_delete":false,"product_type":"c1","uid":1659590,"ip_address":"","ucode":"C58A22B54521CA","user_header":"https://static001.geekbang.org/account/avatar/00/19/52/c6/8eb48963.jpg","comment_is_top":false,"comment_ctime":1573631971,"is_pvip":false,"replies":[{"id":59734,"content":"哈哈 确实 很形象","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1574738590,"ip_address":"","comment_id":150939,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"那句&quot;灵机一动,猛拍一下桌子&quot;真的是神来一笔,哈哈哈哈哈哈\n","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":474318,"discussion_content":"哈哈 确实 很形象","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1574738590,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":87287,"user_name":"滢","can_delete":false,"product_type":"c1","uid":1221511,"ip_address":"","ucode":"971A6F20AF3F9A","user_header":"https://static001.geekbang.org/account/avatar/00/12/a3/87/c415e370.jpg","comment_is_top":false,"comment_ctime":1555559798,"is_pvip":false,"replies":[{"id":64249,"content":"对的 整理的不错 滢","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577615314,"ip_address":"","comment_id":87287,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"告诉机器，给它一些数据，这部分数据一些是数据集合A，一部分是属于集合B，然后让机器去把数据往集合A和集合B里去划分，这是有监督学习；同样的数据给机器，只是告诉它去做划分和归类，这是无监督学习，类似于孩子的放养。   \n硬间隔：表示得到的分类间隔即超平面 能完美的划分数据，不存在划分错误的情况，即零误差\n软间隔：表示得到的分类间隔，没有达到完美的程度，对数据划分存在一定的误差\n核函数：在数据分布无法用线性函数来表示的时候，需要对数据进行划分的标准变成来非线性的，这个时候就需要用到一种函数名叫核函数，核函数要做的工作是将原来的映射关系在更高维度的空间重新映射，使得新的映射关系变得线性可分。","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":447382,"discussion_content":"对的 整理的不错 滢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577615314,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":81339,"user_name":"滨滨","can_delete":false,"product_type":"c1","uid":1334567,"ip_address":"","ucode":"881EFA798BEE34","user_header":"https://static001.geekbang.org/account/avatar/00/14/5d/27/74e152d3.jpg","comment_is_top":false,"comment_ctime":1553866352,"is_pvip":false,"replies":[{"id":64334,"content":"总结的不错","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577616998,"ip_address":"","comment_id":81339,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"有监督学习和无监督学习的根本区别，就是训练数据中是否有标签。监督学习的数据既有特征又有标签，而非监督学习的数据中只有特征而没有标签。\n监督学习是通过训练让机器自己找到特征和标签之间的联系，在以后面对只有特征而没有标签的数据时可以自己判别出标签。\n非监督学习由于训练数据中只有特征没有标签，所以就需要自己对数据进行聚类分析，然后就可以通过聚类的方式从数据中提取一个特殊的结构。\n2、硬间隔、软间隔和核函数\n硬间隔指的就是完全分类准确，不能存在分类错误的情况。软间隔，就是允许一定量的样本分类错误。\n线性不可分的情况下，可以使用核函数将样本从原始空间映射到一个更高维的特质空间中，使得样本在新的空间中线性可分。","like_count":2},{"had_liked":false,"id":69354,"user_name":"Geek_hve78z","can_delete":false,"product_type":"c1","uid":1015045,"ip_address":"","ucode":"386803B8FC2DD5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg","comment_is_top":false,"comment_ctime":1550723784,"is_pvip":false,"replies":[{"id":64519,"content":"很好的总结","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577621180,"ip_address":"","comment_id":69354,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"1、有监督学习和无监督学习的理解\n有监督学习和无监督学习的根本区别，就是训练数据中是否有标签。监督学习的数据既有特征又有标签，而非监督学习的数据中只有特征而没有标签。\n监督学习是通过训练让机器自己找到特征和标签之间的联系，在以后面对只有特征而没有标签的数据时可以自己判别出标签。\n非监督学习由于训练数据中只有特征没有标签，所以就需要自己对数据进行聚类分析，然后就可以通过聚类的方式从数据中提取一个特殊的结构。\n2、硬间隔、软间隔和核函数\n硬间隔指的就是完全分类准确，不能存在分类错误的情况。软间隔，就是允许一定量的样本分类错误。\n它可以将样本从原始空间映射到一个更高维的特质空间中，使得样本在新的空间中线性可分。","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":440078,"discussion_content":"很好的总结","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577621180,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":268193,"user_name":"McKee Chen","can_delete":false,"product_type":"c1","uid":2037505,"ip_address":"","ucode":"F74B76542FAB65","user_header":"https://static001.geekbang.org/account/avatar/00/1f/17/01/1c5309a3.jpg","comment_is_top":false,"comment_ctime":1608098480,"is_pvip":false,"replies":[{"id":100875,"content":"总结的不错，继续努力","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1612705934,"ip_address":"","comment_id":268193,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"1.有监督的学习模型和无监督的学习模型\n  有监督的学习模型：事先对数据打上分类标签，机器知道数据的分类\n  无监督的学习模型：没有对数据打上分类标签，机器不知道数据的分类\n\n2.硬间隔、软间隔、核函数\n  硬间隔：对数据进行分类，不存在分类错误的情况\n  软间隔：允许存在一定数据分类错误的情况\n  核函数：对于非线性数据，通过核函数让原始的样本空间投射到一个高位的空间，使数据变得线性可分","like_count":1,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":440078,"discussion_content":"很好的总结","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577621180,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":212827,"user_name":"Prometheus","can_delete":false,"product_type":"c1","uid":1694431,"ip_address":"","ucode":"3FCD34CE08BAC1","user_header":"https://static001.geekbang.org/account/avatar/00/19/da/df/4ea7b148.jpg","comment_is_top":false,"comment_ctime":1588217090,"is_pvip":false,"replies":[{"id":103959,"content":"同学没有想歪，聚类分析事先没有类别，而判别分析事先已经有类别。","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1617288108,"ip_address":"","comment_id":212827,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"有监督学习和无监督学习的根本区别，由这个知识点，我想起了统计学基础中，K聚类与判别聚类的知识点。不知道是否想歪了？求教老师，与各位同学。谢谢。","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":511874,"discussion_content":"总结的不错，继续努力","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1612705934,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":85411,"user_name":"Daniel的爹","can_delete":false,"product_type":"c1","uid":1241306,"ip_address":"","ucode":"1B450BF830E84E","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEJGXItsGm9EEgVzURZ5iae2T0SLyic5LPzuhsjgu9nvbgne7qIINWkNd1LIVuav1GschBVGj1guLCYg/132","comment_is_top":false,"comment_ctime":1555055097,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"有监督学习就是在训练组中已知数据的结果，可以对模型的训练进行Supervise监督。无监督就是拿到手的训练集并不知道分类情况，要根据算法来区分并生成对应的结果。\n硬间隔是理想化的世界，非红即白，不允许出错。软间隔有容错率更现实点，包容性强，更有普适性。核函数可以在原本训练集中多加一维，让分类更容易。","like_count":1},{"had_liked":false,"id":65110,"user_name":"Python","can_delete":false,"product_type":"c1","uid":1276314,"ip_address":"","ucode":"969500D2A88AE6","user_header":"https://static001.geekbang.org/account/avatar/00/13/79/9a/4f907ad6.jpg","comment_is_top":false,"comment_ctime":1549065562,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"老师，多分类器用的是集成法吗？","like_count":1},{"had_liked":false,"id":340670,"user_name":"忙了你个狗","can_delete":false,"product_type":"c1","uid":2628906,"ip_address":"","ucode":"DB46648E82495C","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Lop0uAwiawHbqgRFYqIZv2YbFMJSeDePB0fia3j6joQQ3sddhvgpic6ibXLkva572O6dWS3QzicOibJGjr4QjrNXEgwg/132","comment_is_top":false,"comment_ctime":1649037586,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"核函数的作用我可以理解就是一拍桌子球弹了起来这个时候可以找到一个平面把球分开的过程吗","like_count":0},{"had_liked":false,"id":248176,"user_name":"小强","can_delete":false,"product_type":"c1","uid":1149004,"ip_address":"","ucode":"CC3D3A9E5D9A42","user_header":"https://static001.geekbang.org/account/avatar/00/11/88/4c/2c3d2c7d.jpg","comment_is_top":false,"comment_ctime":1600051187,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"其中||w||为超平面的范数，di 的公式可以用解析几何知识进行推导，这里不做解释。这是能否学下去的精神支柱，被老师放弃讲解了","like_count":0},{"had_liked":false,"id":202536,"user_name":"timeng27","can_delete":false,"product_type":"c1","uid":1914163,"ip_address":"","ucode":"C92D7484F7FF35","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJAl7V1ibk8gX62W5I4SER2zbQAj3gy5icJlavGhnAmxENCia7QFm8lE3YBc5HOHvlyNVFz7rQKFQ7dA/132","comment_is_top":false,"comment_ctime":1586004103,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"svm “超平面”将样本分为两份。它是二分类器，最大化最小距离。硬间隔，将两个完全分开；软间隔，可以存在误差；非线性可分的，就需要使用到核函数，可以理解为将坐标转换，比如直角坐标转成极坐标，或者理解为投影到某个平面。\n如果要多分类，可以1对多，过1对1。","like_count":0},{"had_liked":false,"id":185608,"user_name":"William～Zhang","can_delete":false,"product_type":"c1","uid":1527138,"ip_address":"","ucode":"8659B589428F11","user_header":"https://static001.geekbang.org/account/avatar/00/17/4d/62/0fe9cbb3.jpg","comment_is_top":false,"comment_ctime":1583644629,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"老师 有个问题 关于文中最大间隔 指的其中分界线c 距离左侧点的最大距离还是右侧点？","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493622,"discussion_content":"同学没有想歪，聚类分析事先没有类别，而判别分析事先已经有类别。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617288108,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":81339,"user_name":"滨滨","can_delete":false,"product_type":"c1","uid":1334567,"ip_address":"","ucode":"881EFA798BEE34","user_header":"https://static001.geekbang.org/account/avatar/00/14/5d/27/74e152d3.jpg","comment_is_top":false,"comment_ctime":1553866352,"is_pvip":false,"replies":[{"id":64334,"content":"总结的不错","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577616998,"ip_address":"","comment_id":81339,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"有监督学习和无监督学习的根本区别，就是训练数据中是否有标签。监督学习的数据既有特征又有标签，而非监督学习的数据中只有特征而没有标签。\n监督学习是通过训练让机器自己找到特征和标签之间的联系，在以后面对只有特征而没有标签的数据时可以自己判别出标签。\n非监督学习由于训练数据中只有特征没有标签，所以就需要自己对数据进行聚类分析，然后就可以通过聚类的方式从数据中提取一个特殊的结构。\n2、硬间隔、软间隔和核函数\n硬间隔指的就是完全分类准确，不能存在分类错误的情况。软间隔，就是允许一定量的样本分类错误。\n线性不可分的情况下，可以使用核函数将样本从原始空间映射到一个更高维的特质空间中，使得样本在新的空间中线性可分。","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":445160,"discussion_content":"总结的不错","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577616998,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":69354,"user_name":"Geek_hve78z","can_delete":false,"product_type":"c1","uid":1015045,"ip_address":"","ucode":"386803B8FC2DD5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg","comment_is_top":false,"comment_ctime":1550723784,"is_pvip":false,"replies":[{"id":64519,"content":"很好的总结","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577621180,"ip_address":"","comment_id":69354,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"1、有监督学习和无监督学习的理解\n有监督学习和无监督学习的根本区别，就是训练数据中是否有标签。监督学习的数据既有特征又有标签，而非监督学习的数据中只有特征而没有标签。\n监督学习是通过训练让机器自己找到特征和标签之间的联系，在以后面对只有特征而没有标签的数据时可以自己判别出标签。\n非监督学习由于训练数据中只有特征没有标签，所以就需要自己对数据进行聚类分析，然后就可以通过聚类的方式从数据中提取一个特殊的结构。\n2、硬间隔、软间隔和核函数\n硬间隔指的就是完全分类准确，不能存在分类错误的情况。软间隔，就是允许一定量的样本分类错误。\n它可以将样本从原始空间映射到一个更高维的特质空间中，使得样本在新的空间中线性可分。","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":445160,"discussion_content":"总结的不错","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577616998,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":268193,"user_name":"McKee Chen","can_delete":false,"product_type":"c1","uid":2037505,"ip_address":"","ucode":"F74B76542FAB65","user_header":"https://static001.geekbang.org/account/avatar/00/1f/17/01/1c5309a3.jpg","comment_is_top":false,"comment_ctime":1608098480,"is_pvip":false,"replies":[{"id":100875,"content":"总结的不错，继续努力","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1612705934,"ip_address":"","comment_id":268193,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"1.有监督的学习模型和无监督的学习模型\n  有监督的学习模型：事先对数据打上分类标签，机器知道数据的分类\n  无监督的学习模型：没有对数据打上分类标签，机器不知道数据的分类\n\n2.硬间隔、软间隔、核函数\n  硬间隔：对数据进行分类，不存在分类错误的情况\n  软间隔：允许存在一定数据分类错误的情况\n  核函数：对于非线性数据，通过核函数让原始的样本空间投射到一个高位的空间，使数据变得线性可分","like_count":1,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":511874,"discussion_content":"总结的不错，继续努力","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1612705934,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":212827,"user_name":"Prometheus","can_delete":false,"product_type":"c1","uid":1694431,"ip_address":"","ucode":"3FCD34CE08BAC1","user_header":"https://static001.geekbang.org/account/avatar/00/19/da/df/4ea7b148.jpg","comment_is_top":false,"comment_ctime":1588217090,"is_pvip":false,"replies":[{"id":103959,"content":"同学没有想歪，聚类分析事先没有类别，而判别分析事先已经有类别。","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1617288108,"ip_address":"","comment_id":212827,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"有监督学习和无监督学习的根本区别，由这个知识点，我想起了统计学基础中，K聚类与判别聚类的知识点。不知道是否想歪了？求教老师，与各位同学。谢谢。","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493622,"discussion_content":"同学没有想歪，聚类分析事先没有类别，而判别分析事先已经有类别。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617288108,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":85411,"user_name":"Daniel的爹","can_delete":false,"product_type":"c1","uid":1241306,"ip_address":"","ucode":"1B450BF830E84E","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEJGXItsGm9EEgVzURZ5iae2T0SLyic5LPzuhsjgu9nvbgne7qIINWkNd1LIVuav1GschBVGj1guLCYg/132","comment_is_top":false,"comment_ctime":1555055097,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"有监督学习就是在训练组中已知数据的结果，可以对模型的训练进行Supervise监督。无监督就是拿到手的训练集并不知道分类情况，要根据算法来区分并生成对应的结果。\n硬间隔是理想化的世界，非红即白，不允许出错。软间隔有容错率更现实点，包容性强，更有普适性。核函数可以在原本训练集中多加一维，让分类更容易。","like_count":1},{"had_liked":false,"id":65110,"user_name":"Python","can_delete":false,"product_type":"c1","uid":1276314,"ip_address":"","ucode":"969500D2A88AE6","user_header":"https://static001.geekbang.org/account/avatar/00/13/79/9a/4f907ad6.jpg","comment_is_top":false,"comment_ctime":1549065562,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"老师，多分类器用的是集成法吗？","like_count":1},{"had_liked":false,"id":340670,"user_name":"忙了你个狗","can_delete":false,"product_type":"c1","uid":2628906,"ip_address":"","ucode":"DB46648E82495C","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Lop0uAwiawHbqgRFYqIZv2YbFMJSeDePB0fia3j6joQQ3sddhvgpic6ibXLkva572O6dWS3QzicOibJGjr4QjrNXEgwg/132","comment_is_top":false,"comment_ctime":1649037586,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"核函数的作用我可以理解就是一拍桌子球弹了起来这个时候可以找到一个平面把球分开的过程吗","like_count":0},{"had_liked":false,"id":248176,"user_name":"小强","can_delete":false,"product_type":"c1","uid":1149004,"ip_address":"","ucode":"CC3D3A9E5D9A42","user_header":"https://static001.geekbang.org/account/avatar/00/11/88/4c/2c3d2c7d.jpg","comment_is_top":false,"comment_ctime":1600051187,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"其中||w||为超平面的范数，di 的公式可以用解析几何知识进行推导，这里不做解释。这是能否学下去的精神支柱，被老师放弃讲解了","like_count":0},{"had_liked":false,"id":202536,"user_name":"timeng27","can_delete":false,"product_type":"c1","uid":1914163,"ip_address":"","ucode":"C92D7484F7FF35","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJAl7V1ibk8gX62W5I4SER2zbQAj3gy5icJlavGhnAmxENCia7QFm8lE3YBc5HOHvlyNVFz7rQKFQ7dA/132","comment_is_top":false,"comment_ctime":1586004103,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"svm “超平面”将样本分为两份。它是二分类器，最大化最小距离。硬间隔，将两个完全分开；软间隔，可以存在误差；非线性可分的，就需要使用到核函数，可以理解为将坐标转换，比如直角坐标转成极坐标，或者理解为投影到某个平面。\n如果要多分类，可以1对多，过1对1。","like_count":0},{"had_liked":false,"id":185608,"user_name":"William～Zhang","can_delete":false,"product_type":"c1","uid":1527138,"ip_address":"","ucode":"8659B589428F11","user_header":"https://static001.geekbang.org/account/avatar/00/17/4d/62/0fe9cbb3.jpg","comment_is_top":false,"comment_ctime":1583644629,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"老师 有个问题 关于文中最大间隔 指的其中分界线c 距离左侧点的最大距离还是右侧点？","like_count":0,"discussions":[{"author":{"id":1914504,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/36/88/20b6a6ee.jpg","nickname":"Simon","note":"","ucode":"A8A2E3E57BD029","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":223641,"discussion_content":"分界线C距离两侧都要最大","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586242779,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":150922,"user_name":"Ronnyz","can_delete":false,"product_type":"c1","uid":1488280,"ip_address":"","ucode":"9F34527B1D343D","user_header":"https://static001.geekbang.org/account/avatar/00/16/b5/98/ffaf2aca.jpg","comment_is_top":false,"comment_ctime":1573628681,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"硬间隔：需要完全分开\n软间隔：允许有个别点分类错误\n核函数：转换到更高维度来达到分类效果\n还有想问下为什么说落在超平面上的点就是支持向量？","like_count":0},{"had_liked":false,"id":149339,"user_name":"明翼","can_delete":false,"product_type":"c1","uid":1068361,"ip_address":"","ucode":"E77F86BEB3D5C1","user_header":"https://static001.geekbang.org/account/avatar/00/10/4d/49/28e73b9c.jpg","comment_is_top":false,"comment_ctime":1573197154,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"老师，这里面用二分类算法实现多分类怎么用，比如一对多分类，一个测试样本分别用这几个训练模型去匹配，的到的结果难道是百分比吗？哪个大属于哪个分类？","like_count":0,"discussions":[{"author":{"id":1914504,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/36/88/20b6a6ee.jpg","nickname":"Simon","note":"","ucode":"A8A2E3E57BD029","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":223649,"discussion_content":"看《机器学习》多分类学习","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586243418,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":101404,"user_name":"姜泮昌","can_delete":false,"product_type":"c1","uid":1107213,"ip_address":"","ucode":"89B63270BAE099","user_header":"https://static001.geekbang.org/account/avatar/00/10/e5/0d/b4258141.jpg","comment_is_top":false,"comment_ctime":1559802405,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"老师，能不能讲讲这些分类算法的区别？尤其是二分类算法，在使用时怎样进行选择呢？谢谢","like_count":0},{"had_liked":false,"id":95380,"user_name":"张晓辉","can_delete":false,"product_type":"c1","uid":1085046,"ip_address":"","ucode":"1CD9717DE399C5","user_header":"https://static001.geekbang.org/account/avatar/00/10/8e/76/6d55e26f.jpg","comment_is_top":false,"comment_ctime":1558050398,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"监督学习适用于打标签的数据。无监督学习适于用没有标签的数据。\nSVM的硬间隔是指线性分类器完全线性可分，软间隔是指允许线性分类器有一定的分类错误。核函数是针对非线性可分的情况提出来的，可以利用核函数把样本空间投射到高维空间，然后再利用线性分类器进行分类。","like_count":0},{"had_liked":false,"id":79752,"user_name":"小高","can_delete":false,"product_type":"c1","uid":1283052,"ip_address":"","ucode":"FCD422249F7355","user_header":"https://static001.geekbang.org/account/avatar/00/13/93/ec/985675c8.jpg","comment_is_top":false,"comment_ctime":1553532311,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"有点烧脑了，慢慢消化，感觉一篇文章要花几个小时才能消化。","like_count":0},{"had_liked":false,"id":76834,"user_name":"Geek_dancer","can_delete":false,"product_type":"c1","uid":1440561,"ip_address":"","ucode":"F66D454E58E35E","user_header":"https://static001.geekbang.org/account/avatar/00/15/fb/31/f0a884a3.jpg","comment_is_top":false,"comment_ctime":1552722368,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"SVM如何与回归应用联系起来？","like_count":0},{"had_liked":false,"id":71403,"user_name":"Wei_强","can_delete":false,"product_type":"c1","uid":1152887,"ip_address":"","ucode":"B0E40FB6636F9D","user_header":"https://static001.geekbang.org/account/avatar/00/11/97/77/a01ebefc.jpg","comment_is_top":false,"comment_ctime":1551334091,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"能讲解一下什么叫做“线性不可分”么？对这个知识点不是很了解，结果导致文章后面的知识点没有怎么理解","like_count":0},{"had_liked":false,"id":66428,"user_name":"JingZ","can_delete":false,"product_type":"c1","uid":1023464,"ip_address":"","ucode":"6F97895B2CC375","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/wJphZ3HcvhjVUyTWCIsCugzfQY5NAy6VJ0XoPLibDlcHWMswFmFe678zd0lUjFETia80NQhyQcVnGDlKgKPcRGyw/132","comment_is_top":false,"comment_ctime":1549938012,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"监督学习和无监督学习根本区别在于是否有标签，核心分别是分类和聚类、同维和降维等~\n\n硬间隔、软间隔、核函数是适用于线性可分、不完全可分、不可分等不同情况下的分类思想","like_count":0},{"had_liked":false,"id":150922,"user_name":"Ronnyz","can_delete":false,"product_type":"c1","uid":1488280,"ip_address":"","ucode":"9F34527B1D343D","user_header":"https://static001.geekbang.org/account/avatar/00/16/b5/98/ffaf2aca.jpg","comment_is_top":false,"comment_ctime":1573628681,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"硬间隔：需要完全分开\n软间隔：允许有个别点分类错误\n核函数：转换到更高维度来达到分类效果\n还有想问下为什么说落在超平面上的点就是支持向量？","like_count":0,"discussions":[{"author":{"id":1914504,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/36/88/20b6a6ee.jpg","nickname":"Simon","note":"","ucode":"A8A2E3E57BD029","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":223642,"discussion_content":"不是落在超平面上，是距离超平面最近的点是支持向量。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586242880,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":149339,"user_name":"明翼","can_delete":false,"product_type":"c1","uid":1068361,"ip_address":"","ucode":"E77F86BEB3D5C1","user_header":"https://static001.geekbang.org/account/avatar/00/10/4d/49/28e73b9c.jpg","comment_is_top":false,"comment_ctime":1573197154,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"老师，这里面用二分类算法实现多分类怎么用，比如一对多分类，一个测试样本分别用这几个训练模型去匹配，的到的结果难道是百分比吗？哪个大属于哪个分类？","like_count":0,"discussions":[{"author":{"id":1914504,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/36/88/20b6a6ee.jpg","nickname":"Simon","note":"","ucode":"A8A2E3E57BD029","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":223642,"discussion_content":"不是落在超平面上，是距离超平面最近的点是支持向量。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586242880,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":101404,"user_name":"姜泮昌","can_delete":false,"product_type":"c1","uid":1107213,"ip_address":"","ucode":"89B63270BAE099","user_header":"https://static001.geekbang.org/account/avatar/00/10/e5/0d/b4258141.jpg","comment_is_top":false,"comment_ctime":1559802405,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"老师，能不能讲讲这些分类算法的区别？尤其是二分类算法，在使用时怎样进行选择呢？谢谢","like_count":0},{"had_liked":false,"id":95380,"user_name":"张晓辉","can_delete":false,"product_type":"c1","uid":1085046,"ip_address":"","ucode":"1CD9717DE399C5","user_header":"https://static001.geekbang.org/account/avatar/00/10/8e/76/6d55e26f.jpg","comment_is_top":false,"comment_ctime":1558050398,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"监督学习适用于打标签的数据。无监督学习适于用没有标签的数据。\nSVM的硬间隔是指线性分类器完全线性可分，软间隔是指允许线性分类器有一定的分类错误。核函数是针对非线性可分的情况提出来的，可以利用核函数把样本空间投射到高维空间，然后再利用线性分类器进行分类。","like_count":0},{"had_liked":false,"id":79752,"user_name":"小高","can_delete":false,"product_type":"c1","uid":1283052,"ip_address":"","ucode":"FCD422249F7355","user_header":"https://static001.geekbang.org/account/avatar/00/13/93/ec/985675c8.jpg","comment_is_top":false,"comment_ctime":1553532311,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"有点烧脑了，慢慢消化，感觉一篇文章要花几个小时才能消化。","like_count":0},{"had_liked":false,"id":76834,"user_name":"Geek_dancer","can_delete":false,"product_type":"c1","uid":1440561,"ip_address":"","ucode":"F66D454E58E35E","user_header":"https://static001.geekbang.org/account/avatar/00/15/fb/31/f0a884a3.jpg","comment_is_top":false,"comment_ctime":1552722368,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"SVM如何与回归应用联系起来？","like_count":0},{"had_liked":false,"id":71403,"user_name":"Wei_强","can_delete":false,"product_type":"c1","uid":1152887,"ip_address":"","ucode":"B0E40FB6636F9D","user_header":"https://static001.geekbang.org/account/avatar/00/11/97/77/a01ebefc.jpg","comment_is_top":false,"comment_ctime":1551334091,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"能讲解一下什么叫做“线性不可分”么？对这个知识点不是很了解，结果导致文章后面的知识点没有怎么理解","like_count":0},{"had_liked":false,"id":66428,"user_name":"JingZ","can_delete":false,"product_type":"c1","uid":1023464,"ip_address":"","ucode":"6F97895B2CC375","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/wJphZ3HcvhjVUyTWCIsCugzfQY5NAy6VJ0XoPLibDlcHWMswFmFe678zd0lUjFETia80NQhyQcVnGDlKgKPcRGyw/132","comment_is_top":false,"comment_ctime":1549938012,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"监督学习和无监督学习根本区别在于是否有标签，核心分别是分类和聚类、同维和降维等~\n\n硬间隔、软间隔、核函数是适用于线性可分、不完全可分、不可分等不同情况下的分类思想","like_count":0,"discussions":[{"author":{"id":1914504,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/36/88/20b6a6ee.jpg","nickname":"Simon","note":"","ucode":"A8A2E3E57BD029","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":223649,"discussion_content":"看《机器学习》多分类学习","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586243418,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}