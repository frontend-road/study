{"id":484447,"title":"23 | 调用链追踪：如何通过 ELK 实现日志检索？","content":"<p>你好，我是姚秋辰。</p><p>在上节课中，我们借助Sleuth和Zikpin的合力，搭建了一套调用链追踪系统，它可以帮助我们串联调用链中的上下游访问单元，快速定位线上异常出现在哪个环节。不过呢，光有Tracing能力似乎还不够，如果我们想要更深一步调查异常背后的原因，那必须完整还原这个异常问题的案发现场。</p><p>在线上环境中，我们无法像操作本地开发环境一样去打断点一步步调试问题，服务器的Remote Debug端口通常也是被禁用的，我们唯一能重现案发现场的途径就是<strong>日志信息</strong>。因此，我们还要去构建一套<strong>日志检索系统</strong>，作为线上异常排查的辅助工具。</p><p>今天，我就来带你通过ELK组件来搭建日志检索系统，完成整个调用链追踪方案的最后一块拼图。在这个过程中，你会知道如何使用Docker搭建ELK镜像，以及如何把应用程序对接到Logstash日志收集器，当然了，还有如何在UI界面查询日志。</p><p>在开始之前，我们先来看看什么是ELK吧。</p><h2>什么是ELK？</h2><p>ELK并不是一个技术框架的名称，它其实是一个三位一体的技术名词，ELK的每个字母都来自一个技术组件，它们分别是Elasticsearch（简称ES）、Logstash和Kibana。取这三个组件各自的首字母，就组成了所谓的ELK。</p><!-- [[[read_end]]] --><p>那么这三个技术组件在日志检索平台中分别起到了什么作用呢？我用一幅图来表达一下它们之间的关系。</p><p><img src=\"https://static001.geekbang.org/resource/image/ac/3d/acb9f72fa960914b1c7b0bd17c511b3d.jpg?wh=1920x769\" alt=\"图片\"></p><p>在Elastic解决方案中，<strong>Logstash</strong>扮演了一个<strong>日志收集器</strong>的角色。它可以从多个数据源对数据进行采集，也可以对数据做初步过滤和清洗，比如将数据转换成通用格式、隐匿敏感数据等。</p><p>而<strong>Elasticsearch</strong>呢，它是一个<strong>分布式的搜索和数据分析引擎</strong>。它在整套方案中扮演了日志存储和分词器的角色。Elasticsearch会收到来自Logstash的日志信息，并将这些日志信息集中存储起来。同时，Elasticserch还对外提供了多种RESTful风格的接口，上层应用可以通过这些接口完成数据查找和分析的任务。</p><p><strong>Kibana</strong>在整个Elastic方案中扮演了一个“<strong>花瓶</strong>”的角色。它提供了一套UI界面，让我们可以对Elasticsearch中存储的数据进行查找。同时，它还提供了各种统计报表的功能，如柱状图、饼图、时序统计分析、图谱关联分析等等。当然了，报表数据都来自于Elasticsearch。</p><p>现在，你已经了解了Elasticsearch、Logstash和Kibana的用途和三者间的关系。接下来，我们就来动手搭建ELK环境吧。</p><h2>搭建ELK环境</h2><p>我们有两种搭建ELK环境的方法，一种是分别搭建Elasticsearch、Logstash和Kibana的集群，并将这些组件相互集成起来。就算我们可以通过Docker技术分别搭建三者的镜像环境，环境配置和启动异常排查还是有些麻烦的，很容易劝退初学者。</p><p>因此，我这里推荐你使用一种更简单的搭建方式，那就是<strong>直接下载sebp/elk镜像</strong>。因为sebp/elk镜像已经为我们集成了完整的ELK环境，只需要稍加配置就能迅速构建ELK环境，而且异常排查也比较方便。</p><p>为了安装sebp/elk镜像，你要先确保本地电脑上已经安装了Docker环境。如果你对Docker已经比较熟悉，那么可以直接使用Docker的命令行程序来操作镜像；如果你之前没有使用过Docker，那么可以下载Docker桌面版简化操作流程。我在课程里将使用命令行程序来操作Docker容器和镜像。</p><h4>下载ELK镜像</h4><p>搭建ELK环境的第一步，就是下载sebp/elk镜像。你可以在命令行运行以下命令，来下载7.16.1标签的镜像文件。因为镜像文件相当庞大，所以这个下载过程是非常漫长的，请你拿出对待初恋女友的耐心独自等待。</p><pre><code class=\"language-bash\">docker pull sebp/elk:7.16.1\n</code></pre><p>为什么需要你选择7.16.1标签呢？因为默认情况下，docker会尝试获取LASTEST标签也就是最新版本的镜像文件，而Elastic的版本一直处于不断更新发布的过程中。为了保证你能获得和本节课一致的集成体验，我推荐你和我使用同样的镜像版本。</p><p><strong>在这里我要重点提醒你两个点。</strong></p><p><strong>第一，一定要记得尽可能多给Docker容器分配一些内存。</strong>否则，Elasticsearch很容易启动失败，要知道ES可是一个非常吃内存的组件。我本地为Docker分配的运行期内存是10G（顶配Mac就是豪横），我推荐你为Docker分配不低于5G的内存。</p><p><strong>第二，低配电脑可以降低ELK镜像版本。</strong>如果你的电脑配置比较吃紧，无法分配高内存，那么你可以尝试获取更低版本的ELK组件，因为版本越高对系统的资源要求越高。你可以在<a href=\"https://hub.docker.com/r/sebp/elk\">Docker Hub</a>网站上查看sebp/elk镜像的版本信息，再选择适合自己电脑配置的进行下载。</p><p>镜像下载完成之后，就可以创建一个ELK容器了。</p><h4>创建ELK容器</h4><p>你可以在命令行使用如下命令创建并启动一个ELK容器，在这段命令中，我为Elasticsearch、Logstash和Kibana指定的启动端口分别为9200、5044和5601。命令中的–name elk参数指定了新创建的Container的名称为“elk”，当然了，这里你可以更换成自己喜欢的名称。</p><pre><code class=\"language-xml\">sudo docker run -p 5601:5601 -p 9200:9200 -p 5044:5044 -it --name elk sebp/elk\n</code></pre><p>这里要注意的是，以上命令只用在容器创建的时候执行一次即可。一旦容器被创建完成，后续你就可以使用docker的标准命令来启动、关闭和重启容器了。</p><p>上面这行命令不光会创建容器，还会尝试启动ELK的组件，这个过程可能会花费几分钟。</p><p>你可以在浏览器中访问“localhost:9200”来验证ES是否成功被启动，正常情况下，你应该能在浏览器中看到ES集群的版本号等信息，这就说明ES启动成功了。</p><p>而Kibana的启动时间会更长一些，你可以在浏览器中访问“localhost:5601”来访问Kibana的网页。</p><p>如果启动过程中出现异常，你可以从启动日志中找到异常原因。首先你需要执行下面的命令，进入到Container内部。然后，使用cd命令进入到/var/log文件夹，在这里你可以找到ES、Logstash和Kibana的启动日志，查看具体的报错。</p><pre><code class=\"language-xml\">docker exec -it elk /bin/bash\n</code></pre><p>接下来，我们需要对Logstash配置项做一些修改，定义数据传输方式。</p><h4>配置Logstash</h4><p>我们使用docker exec命令进入到elk容器之后，需要使用编辑器打开/etc/logstash/conf.d/02-beats-input.conf文件，它是用来配置Logstash的输入输出源的文件。你可以使用vi命令或者vim命令进入文件编辑模式，接下来你需要将文件中的内容替换为以下配置项。</p><pre><code class=\"language-plain\">input {\n&nbsp; &nbsp; tcp {\n&nbsp; &nbsp; &nbsp; &nbsp; port =&gt; 5044\n&nbsp; &nbsp; &nbsp; &nbsp; codec =&gt; json_lines\n&nbsp; &nbsp; }\n}\n\noutput {\n&nbsp; &nbsp; elasticsearch {\n&nbsp; &nbsp; &nbsp; &nbsp; hosts =&gt; [\"localhost:9200\"]\n&nbsp; &nbsp; &nbsp; &nbsp; index =&gt; \"geekbang\"\n&nbsp; &nbsp; }\n}\n</code></pre><p>在上面的文件中，我指定Logstash使用TCP插件作为数据输入源，并从5044端口收集数据，格式为JSON，你可以通过这个<a href=\"https://www.elastic.co/guide/en/logstash/current/plugins-inputs-tcp.html\">链接</a>访问TCP插件的完整参数列表。</p><p>同时，我还通过output参数将处理过后的日志数据输出到了ES组件中，这里我配置了ES的地址和数据索引，你可以点击这里的<a href=\"https://www.elastic.co/guide/en/logstash/current/plugins-outputs-elasticsearch.html\">链接</a>获取ES插件的详细信息。<strong>修改完成之后记得一定要保存文件</strong>。</p><p>Logstash支持多种类型的输入和输出源，你可以结合自己的项目架构，选择适合的数据源。如果你对这部分内容感兴趣，可以分别参考以下的两个配置文档：</p><ul>\n<li><a href=\"https://www.elastic.co/guide/en/logstash/current/input-plugins.html\">Logstash Input插件列表</a></li>\n<li><a href=\"https://www.elastic.co/guide/en/logstash/current/output-plugins.html\">Logstash Output插件列表</a></li>\n</ul><p>接下来，你还需要在容器外部执行下面这行命令，通过重启ELK容器，让Logstash重新加载最新的配置项。</p><pre><code class=\"language-plain\">docker restart elk\n</code></pre><p>到这里，ELK容器就配置完成了，接下来我们需要将微服务生成的日志发送到ELK容器中。</p><h2>对接ELK容器</h2><p>应用程序对接ELK的过程很简单，只有两处改动，一处是添加依赖项，另一处是添加logback配置文件。</p><p>首先，你需要为三个微服务项目添加logstash-logback-encoder依赖项，它提供了对接Logstash的日志输出组件，这里我使用了7.0.1的稳定版本。</p><pre><code class=\"language-xml\">&lt;dependency&gt;\n    &lt;groupId&gt;net.logstash.logback&lt;/groupId&gt;\n    &lt;artifactId&gt;logstash-logback-encoder&lt;/artifactId&gt;\n    &lt;version&gt;7.0.1&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre><p>接下来，你需要在每个项目的src/main/resources路径下创建logback-spring.xml组件，在这个文件中，我们定义了两个Appender用来输出日志信息。</p><p>第一个是<strong>ConsoleAppender</strong>，<strong>它可以将日志信息打印到控制台上</strong>。这里我使用了Spring Boot默认的日志格式。</p><pre><code class=\"language-plain\">&lt;appender name=\"console\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt;\n    &lt;filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\"&gt;\n        &lt;level&gt;DEBUG&lt;/level&gt;\n    &lt;/filter&gt;\n    &lt;!-- 日志输出编码 --&gt;\n    &lt;encoder&gt;\n        &lt;pattern&gt;${CONSOLE_LOG_PATTERN}&lt;/pattern&gt;\n        &lt;charset&gt;utf8&lt;/charset&gt;\n    &lt;/encoder&gt;\n&lt;/appender&gt;\n</code></pre><p>第二个是<strong>LogstashTcpSocketAppender</strong>，由于我们在ELK容器中指定了使用TCP的方式接收日志信息，所以这个Appender对象专门用来<strong>构建JSON格式化数据发送到Logstash</strong>。在下面的代码中，你可以看到我将日志的主体信息，以及Span、Trace等链路追踪信息作为了JSON数据的一部分。</p><pre><code class=\"language-plain\">&lt;appender name=\"logstash\"\n          class=\"net.logstash.logback.appender.LogstashTcpSocketAppender\"&gt;\n    &lt;!-- 这是Logstash的连接方式 --&gt;\n    &lt;destination&gt;127.0.0.1:5044&lt;/destination&gt;\n    &lt;!-- 日志输出的JSON格式 --&gt;\n    &lt;encoder class=\"net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder\"&gt;\n        &lt;providers&gt;\n            &lt;timestamp&gt;\n                &lt;timeZone&gt;UTC&lt;/timeZone&gt;\n            &lt;/timestamp&gt;\n            &lt;pattern&gt;\n                &lt;pattern&gt;\n                    {\n                    \"severity\": \"%level\",\n                    \"service\": \"${applicationName:-}\",\n                    \"trace\": \"%X{traceId:-}\",\n                    \"span\": \"%X{spanId:-}\",\n                    \"pid\": \"${PID:-}\",\n                    \"thread\": \"%thread\",\n                    \"class\": \"%logger{40}\",\n                    \"rest\": \"%message\"\n                    }\n                &lt;/pattern&gt;\n            &lt;/pattern&gt;\n        &lt;/providers&gt;\n    &lt;/encoder&gt;\n&lt;/appender&gt;\n</code></pre><p>我这里贴出的只是logback-spring.xml文件的一部分，你可以到代码仓库查看完整的代码。</p><p>到这里，我们就完成了所有的对接工作。接下来，你只要在本地启动微服务项目，然后发起几个服务调用，生成一些Log文件，我们就能够在Kibana中查看到日志信息了。</p><h2>查看Kibana日志信息</h2><p>当ELK容器处于运行状态时，你可以在浏览器中打开“localhost:5601”地址访问Kibana系统。不过，在使用Kibana做日志查询之前，你还需要添加一个Index。这里所说的Index其实是ES中的一个查询参数。</p><p>在这节课前半部分，我在ELK容器的Logstash配置项中指定了Index=geekbang，这个值会作为Index参数，Logstash向ES传输日志信息的时候，会将“geekbang”写入ES。</p><p>为了简化配置，我将所有的日志信息都归在了geekbang这个索引之下，当然了，你也可以在Logstash配置文件中通过表达式动态生成Index的值。</p><p>我录了一段Video来演示如何在Kibana中创建Index，并查询日志内容，你可以参考一下。</p><p><video poster=\"https://media001.geekbang.org/6c9e5b6957f44150918d424a9b2a6819/snapshots/87475ab5f0dc4d33a151f6c8888d041b-00003.jpg\" preload=\"none\" controls=\"\"><source src=\"https://media001.geekbang.org/customerTrans/7e27d07d27d407ebcc195a0e78395f55/61972c25-17ebf4d09e0-0000-0000-01d-dbacd.mp4\" type=\"video/mp4\"><source src=\" https://media001.geekbang.org/e072b972a7414632b67e4c004a056143/dfed6981ab7c4a76bcdb4e6189e3067f-74a18b1e3aba4566da760d95566be19e-sd.m3u8\" type=\"application/x-mpegURL\"></video></p><p>如果你有了一个Trace ID或者Span ID，那么你可以直接在Kibana的Discover页面查询这个ID对应的所有详细日志信息。当然了，根据ES对日志的分词结果，你还可以借助Kibana的KQL表达式构造复杂查询条件，你可以访问Kibana的<a href=\"https://www.elastic.co/guide/en/kibana/current/kuery-query.html\">Kuery-query页面</a>学习如何使用KQL查询。</p><p><img src=\"https://static001.geekbang.org/resource/image/39/a5/3977e79a24e556ef4b5438710ced59a5.png?wh=1568x1000\" alt=\"图片\"></p><p>到这里，我们就完成了线上日志查询系统的搭建，现在让我们来回顾一下这节课的重点内容吧。</p><h2>总结</h2><p>今天我们通过ELK镜像搭建了一套完整的日志查询系统，这个过程中的重点是<strong>配置Logstash的输入输出数据源</strong>。出于简化课程难度的目的，我并没有使用filebeat或者kafka之类的输入源，而是使用了TCP Socket方式，让业务系统直接把日志信息传输到Logstash。</p><p>从高可用的角度出发，我们通常并不会将业务系统与Logstash直连，取而代之的是将日志写入本地文件，然后通过Filebeat之类的工具收集本地log文件，并传输给Logstash。</p><p>这样做的好处是，无论Logstash和应用服务器之间的连接通路是否顺畅，日志文件都会落盘保存，并不会因网络异常而丢失。另一方面，Filebeat使用了一种“背压敏感协议”技术，用来应对海量数据访问的压力，它会根据Logstash的处理速率调整文件读取速度，如果Logstash正忙，Filebeat就会降低读取文件的速度。</p><h2>思考题</h2><p>结合这节课的内容，请你想一想，如果要将Filebeat添加到ELK体系中，实现日志归集的功能，你打算怎么做？这个作业稍微有一点挑战性，先别搜索网上现成的方案，你可以尝试通过阅读官方文档来搞定这个问题。</p><p>好啦，这节课就结束啦。欢迎你把这节课分享给更多对Spring Cloud感兴趣的朋友。我是姚秋辰，我们下节课再见！</p>","comments":[{"had_liked":false,"id":333016,"user_name":"黄叶","can_delete":false,"product_type":"c1","uid":2332411,"ip_address":"","ucode":"8D8C566F7772A6","user_header":"https://static001.geekbang.org/account/avatar/00/23/96/fb/af39abb1.jpg","comment_is_top":true,"comment_ctime":1643959906,"is_pvip":true,"replies":[{"id":"121835","content":"满分满分，帮了没有windows电脑的我的大忙，windows的同学可以看过来","user_name":"作者回复","comment_id":333016,"uid":"2819998","ip_address":"","utype":1,"ctime":1644326908,"user_name_real":"编辑"}],"discussion_count":1,"race_medal":0,"score":"9.2233720900383007e+18","product_id":100101301,"comment_content":"window版本搭建<br>3个软件都可以前往该中心下载，注意es和kibana版本要一样，链接：https:&#47;&#47;elasticsearch.cn&#47;download&#47;<br>1.安装es<br>下载后，进入bin目录，elasticsearch.bat <br>测试：localhost:9200<br>2.安装kibana<br>下载后，进入bin目录，kibana.bat<br>测试：localhost:5601<br>3.安装logstash<br>需要修改配置，如下<br>input {<br>  tcp {<br>    #模式选择为server<br>    mode =&gt; &quot;server&quot;<br>    #ip和端口根据自己情况填写，端口默认4560,对应下文logback.xml里appender中的destination<br>    host =&gt; &quot;localhost&quot;<br>    port =&gt; 4560<br>    #格式json<br>    codec =&gt; json_lines<br>  }<br>}<br>output {<br>  elasticsearch {<br>    action =&gt; &quot;index&quot;<br>    #这里是es的地址，多个es要写成数组的形式<br>    hosts  =&gt; &quot;localhost:9200&quot;<br>    #用于kibana过滤，可以填项目名称<br>    index  =&gt; &quot;applog&quot;<br>  }<br>}<br>启动：进入bin，cmd输入logstash -f logstash.conf<br>测试：localhost：9600","like_count":12,"discussions":[{"author":{"id":2819998,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/07/9e/d2de2832.jpg","nickname":"姚半仙","note":"","ucode":"4C86AA5D6D8C39","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":550003,"discussion_content":"满分满分，帮了没有windows电脑的我的大忙，windows的同学可以看过来","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1644326908,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":338690,"user_name":"威威威小哥","can_delete":false,"product_type":"c1","uid":1794075,"ip_address":"","ucode":"D1833693BB1957","user_header":"https://static001.geekbang.org/account/avatar/00/1b/60/1b/37a1eb91.jpg","comment_is_top":false,"comment_ctime":1647663580,"is_pvip":false,"replies":[{"id":"123909","content":"两者的用途不同，zipkin的主要目的是根据global trace id查询当前请求的调用链路。比如说我通过某个请求的header拿到trace id，接下来我用这个id搜索这次请求都调用了哪些服务，然后发生error的是哪个调用span。初步定位异常之后，再到kibana里搜索更细粒度的日志信息","user_name":"作者回复","comment_id":338690,"uid":"2819998","ip_address":"","utype":1,"ctime":1647870382,"user_name_real":"编辑"}],"discussion_count":1,"race_medal":0,"score":"31712434652","product_id":100101301,"comment_content":"老师，请问有了elk还需要集成zipkin吗？ Sleuth打的日志都可以被收集到elk，那zipkin还有意义吗","like_count":7,"discussions":[{"author":{"id":2819998,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/07/9e/d2de2832.jpg","nickname":"姚半仙","note":"","ucode":"4C86AA5D6D8C39","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":557580,"discussion_content":"两者的用途不同，zipkin的主要目的是根据global trace id查询当前请求的调用链路。比如说我通过某个请求的header拿到trace id，接下来我用这个id搜索这次请求都调用了哪些服务，然后发生error的是哪个调用span。初步定位异常之后，再到kibana里搜索更细粒度的日志信息","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1647870382,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":333015,"user_name":"peter","can_delete":false,"product_type":"c1","uid":1058183,"ip_address":"","ucode":"261C3FC001DE2D","user_header":"https://static001.geekbang.org/account/avatar/00/10/25/87/f3a69d1b.jpg","comment_is_top":false,"comment_ctime":1643959654,"is_pvip":true,"replies":[{"id":"121840","content":"还真是的，呼叫编辑大大！看这里看这里，有个笔误","user_name":"作者回复","comment_id":333015,"uid":"2819998","ip_address":"","utype":1,"ctime":1644327516,"user_name_real":"编辑"}],"discussion_count":3,"race_medal":0,"score":"10233894246","product_id":100101301,"comment_content":"老师请教一个问题啊：<br>Q1：docker restart geekbang<br>这里“geekbang”是笔误吗？前面ELK的名字是“elk”啊。","like_count":2,"discussions":[{"author":{"id":2819998,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/07/9e/d2de2832.jpg","nickname":"姚半仙","note":"","ucode":"4C86AA5D6D8C39","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":550009,"discussion_content":"还真是的，呼叫编辑大大！看这里看这里，有个笔误","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1644327516,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2843182,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/62/2e/6cd7e076.jpg","nickname":"Angela","note":"","ucode":"0C144DE7ECB865","race_medal":0,"user_type":8,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":550287,"discussion_content":"对不起来晚啦！已修改，感谢peter同学、~同学！！！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1644473430,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2495621,"avatar":"https://static001.geekbang.org/account/avatar/00/26/14/85/73e55be5.jpg","nickname":"~","note":"","ucode":"BE5E3BD6EE3665","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":549746,"discussion_content":"应该是笔误","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1644224692,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":343497,"user_name":"牛年榴莲","can_delete":false,"product_type":"c1","uid":1183703,"ip_address":"","ucode":"230C076193C6C0","user_header":"https://static001.geekbang.org/account/avatar/00/12/0f/d7/31d07471.jpg","comment_is_top":false,"comment_ctime":1650877629,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5945844925","product_id":100101301,"comment_content":"也是给了docker10个G内存才起来，给到8个G都不行","like_count":1},{"had_liked":false,"id":336273,"user_name":"zx","can_delete":false,"product_type":"c1","uid":1021839,"ip_address":"","ucode":"D1AA03A0A629B1","user_header":"https://static001.geekbang.org/account/avatar/00/0f/97/8f/aa0c2471.jpg","comment_is_top":false,"comment_ctime":1646044490,"is_pvip":true,"replies":[{"id":"123083","content":"动态做索引其实就是用类似“参数引用”的方式，把log里的参数配置到这里，就像你在本地log文件中配置动态参数一样，一般做index的话application name肯定是要做进去的，除此之外，server name或者cluster(集群封闭模式)也可以考虑加入index","user_name":"作者回复","comment_id":336273,"uid":"2819998","ip_address":"","utype":1,"ctime":1646404177,"user_name_real":"编辑"}],"discussion_count":1,"race_medal":0,"score":"5941011786","product_id":100101301,"comment_content":"请问老师，生产环境  一般创建日志索引有什么规范没 像您文章中说的 通过配置文件表达式动态生成索引 可以大概讲一下这块思路吗","like_count":1,"discussions":[{"author":{"id":2819998,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/07/9e/d2de2832.jpg","nickname":"姚半仙","note":"","ucode":"4C86AA5D6D8C39","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":554489,"discussion_content":"动态做索引其实就是用类似“参数引用”的方式，把log里的参数配置到这里，就像你在本地log文件中配置动态参数一样，一般做index的话application name肯定是要做进去的，除此之外，server name或者cluster(集群封闭模式)也可以考虑加入index","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1646404177,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":335282,"user_name":"张逃逃","can_delete":false,"product_type":"c1","uid":1435550,"ip_address":"","ucode":"DBF3A573CDF7DB","user_header":"https://static001.geekbang.org/account/avatar/00/15/e7/9e/5853da22.jpg","comment_is_top":false,"comment_ctime":1645438724,"is_pvip":true,"replies":[{"id":"122644","content":"有个简单的方法，直接用lombok的@Data或者@ToString注解加到Request的对应类头上，里面会自动覆盖toString打印漂亮的输出，只要在log里直接输出这个对象就好了","user_name":"作者回复","comment_id":335282,"uid":"2819998","ip_address":"","utype":1,"ctime":1645631242,"user_name_real":"编辑"}],"discussion_count":1,"race_medal":0,"score":"5940406020","product_id":100101301,"comment_content":"请问老师，我想log request的参数应该怎么写？","like_count":1,"discussions":[{"author":{"id":2819998,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/07/9e/d2de2832.jpg","nickname":"姚半仙","note":"","ucode":"4C86AA5D6D8C39","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":552908,"discussion_content":"有个简单的方法，直接用lombok的@Data或者@ToString注解加到Request的对应类头上，里面会自动覆盖toString打印漂亮的输出，只要在log里直接输出这个对象就好了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1645631242,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":356339,"user_name":"qwfys200","can_delete":false,"product_type":"c1","uid":1359108,"ip_address":"浙江","ucode":"DFE438CA2F77A2","user_header":"https://static001.geekbang.org/account/avatar/00/14/bd/04/fc82a7f1.jpg","comment_is_top":false,"comment_ctime":1662177213,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1662177213","product_id":100101301,"comment_content":"可以配置docker的阿里云镜像环境(mirror)，这样，下载就快了。","like_count":0},{"had_liked":false,"id":347648,"user_name":"Geek_0b93c0","can_delete":false,"product_type":"c1","uid":2971019,"ip_address":"","ucode":"ACAA7817AD2C61","user_header":"","comment_is_top":false,"comment_ctime":1654248620,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1654248620","product_id":100101301,"comment_content":"mac m1 启动 不了","like_count":1,"discussions":[{"author":{"id":2028955,"avatar":"","nickname":"勿更改任何信息","note":"","ucode":"B4949BEB8B2AFD","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":578678,"discussion_content":"同上","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1656940192,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":342397,"user_name":"牛年榴莲","can_delete":false,"product_type":"c1","uid":1183703,"ip_address":"","ucode":"230C076193C6C0","user_header":"https://static001.geekbang.org/account/avatar/00/12/0f/d7/31d07471.jpg","comment_is_top":false,"comment_ctime":1650247496,"is_pvip":false,"replies":[{"id":"125198","content":"就像平时console打印log的方式输出就可以，ELK和splunk之类的系统都可以设置分词策略，根据设置的分词策略打印规范日志（比如重要参数为ab=xx这种格式打印）可以方便问题排查","user_name":"作者回复","comment_id":342397,"uid":"2819998","ip_address":"","utype":1,"ctime":1650419866,"user_name_real":"编辑"}],"discussion_count":1,"race_medal":0,"score":"1650247496","product_id":100101301,"comment_content":"打本地日志的时候，推荐使用JSON格式还是像本节console那样的日志格式","like_count":0,"discussions":[{"author":{"id":2819998,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/07/9e/d2de2832.jpg","nickname":"姚半仙","note":"","ucode":"4C86AA5D6D8C39","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":565245,"discussion_content":"就像平时console打印log的方式输出就可以，ELK和splunk之类的系统都可以设置分词策略，根据设置的分词策略打印规范日志（比如重要参数为ab=xx这种格式打印）可以方便问题排查","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1650419866,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":337578,"user_name":"罗逸","can_delete":false,"product_type":"c1","uid":2869911,"ip_address":"","ucode":"828C36255274C0","user_header":"https://static001.geekbang.org/account/avatar/00/2b/ca/97/87f1f07c.jpg","comment_is_top":false,"comment_ctime":1646901244,"is_pvip":false,"replies":[{"id":"123556","content":"文章中的elk镜像很吃内存，尤其是ES这部分，内存不足会导致ES启动失败。建议同学给docker分配5G以上的内存然后再试一下，或者指定一个老版本的elk镜像（占用内存少）","user_name":"作者回复","comment_id":337578,"uid":"2819998","ip_address":"","utype":1,"ctime":1647181182,"user_name_real":"编辑"}],"discussion_count":1,"race_medal":0,"score":"1646901244","product_id":100101301,"comment_content":"docker 运行elk Elasticsearch启动，容器也进不去<br><br>starting elasticsearch server [fail]，<br>Couldn&#39;t start Elasticsearch. Exiting.<br>Elasticsearch log follows below.<br>cat: &#47;var&#47;log&#47;elasticsearch&#47;elasticsearch.log: No such file or directory","like_count":0,"discussions":[{"author":{"id":2819998,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/07/9e/d2de2832.jpg","nickname":"姚半仙","note":"","ucode":"4C86AA5D6D8C39","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":556052,"discussion_content":"文章中的elk镜像很吃内存，尤其是ES这部分，内存不足会导致ES启动失败。建议同学给docker分配5G以上的内存然后再试一下，或者指定一个老版本的elk镜像（占用内存少）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1647181182,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":334892,"user_name":"ziky","can_delete":false,"product_type":"c1","uid":2837547,"ip_address":"","ucode":"C769959727FCAA","user_header":"https://static001.geekbang.org/account/avatar/00/2b/4c/2b/8df2453e.jpg","comment_is_top":false,"comment_ctime":1645172865,"is_pvip":false,"replies":[{"id":"122391","content":"logstash和ES放在了同一个容器中，它们之间的连接相当于本地连接，网络环境相同","user_name":"作者回复","comment_id":334892,"uid":"2819998","ip_address":"","utype":1,"ctime":1645369142,"user_name_real":"编辑"}],"discussion_count":1,"race_medal":0,"score":"1645172865","product_id":100101301,"comment_content":"请问一下老师：docker不是部署在虚拟机上吗，那么这个ip地址就会发生改变，为什么ip还是localhost ","like_count":0,"discussions":[{"author":{"id":2819998,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/07/9e/d2de2832.jpg","nickname":"姚半仙","note":"","ucode":"4C86AA5D6D8C39","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":552250,"discussion_content":"logstash和ES放在了同一个容器中，它们之间的连接相当于本地连接，网络环境相同","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1645369142,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":333005,"user_name":"kimoti","can_delete":false,"product_type":"c1","uid":1897671,"ip_address":"","ucode":"0A78077408C2B1","user_header":"https://static001.geekbang.org/account/avatar/00/1c/f4/c7/037235c9.jpg","comment_is_top":false,"comment_ctime":1643951582,"is_pvip":false,"replies":[{"id":"121839","content":"可以，在检索出来的日志信息里有具体的日志打印。在logback-spring.xml中，只要在pattern格式中把message和error信息传递给logstash就能够在elk里查到，你可以本地试一下","user_name":"作者回复","comment_id":333005,"uid":"2819998","ip_address":"","utype":1,"ctime":1644327441,"user_name_real":"编辑"}],"discussion_count":3,"race_medal":0,"score":"1643951582","product_id":100101301,"comment_content":"用ELK的目的是为了看日志排错,这样配置可以看到错误信息吗？毕竟仅有TraceID和Span ID还是不知道发生了什么错误？","like_count":0,"discussions":[{"author":{"id":2819998,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/07/9e/d2de2832.jpg","nickname":"姚半仙","note":"","ucode":"4C86AA5D6D8C39","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":550008,"discussion_content":"可以，在检索出来的日志信息里有具体的日志打印。在logback-spring.xml中，只要在pattern格式中把message和error信息传递给logstash就能够在elk里查到，你可以本地试一下","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1644327441,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":1897671,"avatar":"https://static001.geekbang.org/account/avatar/00/1c/f4/c7/037235c9.jpg","nickname":"kimoti","note":"","ucode":"0A78077408C2B1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2819998,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/07/9e/d2de2832.jpg","nickname":"姚半仙","note":"","ucode":"4C86AA5D6D8C39","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":550064,"discussion_content":"谢谢老师","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1644373331,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":550008,"ip_address":""},"score":550064,"extra":""}]},{"author":{"id":1408553,"avatar":"https://static001.geekbang.org/account/avatar/00/15/7e/29/2fc94ee7.jpg","nickname":"金灶沐","note":"","ucode":"997DE6CD343179","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":549677,"discussion_content":"你的系统日志会往elk里面写呀，就和你看控制台输出类似，可以看到错误信息啊","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1644201952,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}