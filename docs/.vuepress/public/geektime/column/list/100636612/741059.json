{"id":741059,"title":"第 7 章 分布式资源管理和调度(1)","content":"<p>第 5 章和第 6 章都讲到了对计算任务以及存储单元做拆分，目的是高效处理并发请求和海量数据。无论是计算任务还是数据存储都免不了分配资源这一步，其中的资源指硬件资源，包括 CPU、内存、硬盘、网口。在单机环境中，资源管理相对简单，而分布式环境中，资源分布相对分散，如何协调资源应对计算任务和数据存储就是亟待解决的问题。这一章讲的内容解决的就是如何匹配资源与计算任务，并对资源进行有效管理。本章首先会介绍分布式资源管理和调度的概念，包括分布式资源调度的由来、要素和内容。然后聚焦资源的划分和调度，介绍任务队列与资源池以及三大资源调度策略。之后引出分布式资源调度的三类架构，即中心化调度器、两级调度器和共享状态调度器。分布式资源调度除了应用于计算任务，在微服务部署领域也起到了重要作用，本章也会通过一个应用部署的例子，介绍 Kubernetes 的各个组件以及实现原理。总结起来，本章会讲解以下内容。</p>\n<ul>\n<li>分布式资源调度的由来与过程</li>\n<li>资源划分和调度策略</li>\n<li>分布式调度架构</li>\n<li>Kubernetes——资源调度的实践</li>\n</ul>\n<h2 id=\"nav_point_136\">7.1　分布式资源调度的由来与过程</h2>\n<p>相较于分布式系统的资源调度，操作系统的工作可以视为一种微观的资源调度。操作系统将要处理的计算任务抽象成一个个进程，在最初只有单个 CPU 的情况下，同一时间只能处理一个进程，也就是一个计算任务。如果需要同时处理多个计算任务，就需要用到操作系统的进程调度算法，例如时间片轮转调度算法，这种算法中 CPU 会在多个计算任务之间快速切换，使计算任务交替执行，这也是最早处理计算任务并发执行的方式。对于并发的计算任务而言，好像自身独占 CPU 一样。随着业务的发展，需要在同一时刻支持更多计算任务，于是诞生了多核 CPU。和单核 CPU 一样，多核 CPU 也需要用到调度算法。推而广之，分布式系统为了处理更高并发的计算任务，对硬件资源进行了水平扩展。就像 CPU 从单核扩展到多核一样，服务器被扩展成多台并且分布在不同的网络节点上，每个节点都包含 CPU、内存、硬盘、网口等系统资源。如何管理好这些资源，并且将计算任务分配给它们就是我们要解决的问题。</p><!-- [[[read_end]]] -->\n<h3 id=\"nav_point_137\">7.1.1　资源调度可以解决什么问题</h3>\n<p>从前面的分析可以得出，资源管理和调度是将计算任务分配到资源的过程，为了处理并发的计算任务，系统会通过集群的方式组织资源。集群中的资源可以按照服务器或者虚拟机的方式划分。在资源管理和分配初期，会将对应的计算任务分配给对应的资源执行。如图 7-1 所示，有 3 个计算任务，分别是 Spark、MapReduce 和 Storm，系统将它们分配到资源节点 1~9 上，分别把每个计算任务分配给 3 个资源节点，这里的资源节点指的是服务器或者虚拟机，也就是 CPU、内存、硬盘、网口等资源。这些资源节点负责运行计算任务，并且输出计算结果，我们称这种资源分配方式为静态资源分配。通俗点说就是一个萝卜一个坑，资源节点只处理指定的计算任务，例如资源节点 1~3 专门处理 Spark 计算任务。</p>\n<p class=\"pic\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00498.jpeg\" alt=\"\" width=\"90%\" style=\"width: 90%\" /></p>\n<p class=\"ebook-image-title\"><strong>图 7-1　静态资源分配</strong></p>\n<p>顺着这个思路继续推理，静态资源分配其实没什么不好的，每种计算任务都有对应的资源节点可利用。可如果遇到资源不可用的状况，该如何处理？如图 7-2 所示，Storm 计算任务对应的资源节点 8 和资源节点 9 由于某种原因不可用了，因此它只能运行在资源节点 7 上面，如果此时并发执行更多的 Storm 任务，是没有资源节点可以使用的，即使 Spark 和 MapReduce 计算任务并没有占用全部的资源节点 1~6，这些资源也无法共享给 Storm 计算任务使用，这就是静态资源分配存在的弊端。</p>\n<p class=\"pic\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00499.jpeg\" alt=\"\" width=\"90%\" style=\"width: 90%\" /></p>\n<p class=\"ebook-image-title\"><strong>图 7-2　资源节点不可用的情况</strong></p>\n<p>除了资源节点不可用引发的弊端，在进行资源扩容的时候也会产生问题，即有些资源节点会因为没有被分配计算任务，从而造成浪费，同时还可能存在一些计算任务需要资源，却得不到资源的支持。我们换个角度来分析这个问题，静态资源分配是对计算任务和资源做匹配，那如果加入一层资源调度器，是不是会让任务和资源的匹配变得更加灵活呢？如图 7-3 所示，Spark、MapReduce 和 Storm 计算任务分别对资源调度器发起执行任务的申请。资源调度器根据各资源的使用情况，将这 3 个计算任务分配给资源节点 1~9。这个资源分配的过程遵循一定的分配策略，从结果来看，任务和资源不再具有固定的匹配关系，这是根据资源使用情况进行的动态资源分配。例如 Spark 计算任务被分配给了资源节点 1 和 7，MapReduce 计算任务被分配给了资源节点 2，Storm 计算任务对应的是资源节点 5。当这些计算任务全部执行完毕后，资源调度器会释放相应的资源，从而让其他计算任务有机会获取资源。同时，如果有部分资源节点不可用了，也不会影响整个集群的正常使用，所有资源节点都会在资源调度器的安排下完成计算任务。即便是对整个集群进行扩容，也只需把注意力放到资源节点的扩充上即可，任务与资源的动态匹配过程由资源调度器完成，实现了计算任务和资源的解耦。</p>\n<p class=\"pic\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00500.jpeg\" alt=\"\" width=\"83%\" style=\"width: 83%\" /></p>\n<p class=\"ebook-image-title\"><strong>图 7-3　动态资源分配</strong></p>\n<p>在介绍完静态资源分配和动态资源分配之后，动态资源分配明显具有如下优势。</p>\n<ul>\n<li>动态资源分配会根据计算任务实时分配资源，通常不会出现资源闲置的情况，只要没有达到资源的使用上限，是不会出现任务匹配不到资源的情况的。总体来说，资源利用率较高，硬件成本较低，有良好的扩展性。</li>\n<li>由于动态资源分配需要收集资源的整体信息，形成资源池以便调配，因此增加了数据共享功能，所有计算任务的请求都可以共享资源。</li>\n<li>最重要的一点是在多类型计算框架盛行的今天，动态资源分配方式同时支持如 Spark、Storm、MapReduce 等计算框架。让计算框架和资源利用得以完全解耦，使资源管理和调度平台实现平滑切换。</li>\n</ul>\n<h3 id=\"nav_point_138\">7.1.2　资源调度过程</h3>\n<p>本节介绍资源调度器的内容和要素。资源调度指的是根据调度策略对资源和计算任务做匹配。从参与者的角度讲，涉及资源、资源调度器和计算任务三部分。如图 7-4 所示，先看最上面的“任务的组织和管理”，任何请求调度资源的计算任务在申请调度之前都需要服从统一组织和管理，例如构建任务队列、按照一定顺序对计算任务进行资源匹配。再看最下面的“资源的组织和管理”，分布在网络中的资源节点上一般都会安装一个节点管理器，其会不断收集节点的资源使用情况，然后向资源收集器汇报，从而实现对资源的组织和管理。最后看中间的“调度策略”，在获得计算任务和资源的情况以后，会通过一些策略对它们进行匹配，例如 FIFO 策略、公平策略、能力策略、延迟策略等。</p>\n<p class=\"pic\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00501.jpeg\" alt=\"\" width=\"80%\" style=\"width: 80%\" /></p>\n<p class=\"ebook-image-title\"><strong>图 7-4　计算任务、调度策略和资源</strong></p>\n<p>实际上，计算任务、调度策略和资源的关系就是根据调度策略对计算任务和资源进行“配对”。这整个过程中，资源调度器起到了“红娘”的作用，通过动态分配的方式对计算任务和资源做匹配，下面就详细描述这一调度过程。资源调度流程图如图 7-5 所示，从上到下分别是计算任务、资源调度器和资源节点三大部分。资源调度器中包含工作队列、调度策略、资源池和资源收集器。工作队列既是用来存放计算任务的容器，也是资源调度器组织和管理计算任务的一种形式。调度策略包含所需的任务调度策略，也就是对资源和计算任务进行匹配的算法。资源池是对收集起来的硬件资源进行存储和管理的地方。资源收集器，顾名思义就是对资源节点上报的资源进行收集和汇总。</p>\n<p class=\"pic\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00502.jpeg\" alt=\"\" width=\"60%\" style=\"width: 60%\" /></p>\n<p class=\"ebook-image-title\"><strong>图 7-5　资源调度流程图</strong></p>\n<p>下面就来看看资源调度的整个过程，我们顺着序号从下往上看，虽然一些操作有可能是同时进行的，但为了方便理解，我通过顺序的方式来讲解。</p>\n<p>① 硬件资源（CPU、内存、硬盘、网口）分布在不同的网络节点上，为了让资源调度器能够更好地组织和管理它们，在每个资源节点上都安装了节点管理器。节点管理器主要负责不断地向资源收集器汇报资源节点上的资源情况。管理资源的时候，需要按照规则对资源进行分割，这里暂且将这些分割后的资源称为容器。设置容器的目的是将资源隔离，每个容器中都会运行指定的计算任务，隔离的做法使得计算任务的执行互不影响。节点管理器负责管理这些容器，并且将容器的运行情况和资源使用情况汇报给资源收集器。</p>\n<p>② 资源收集器接收到节点管理器上报的资源使用情况以后，将这些资源放入资源池中实施管理。这里的资源池是一个逻辑概念，其实际存放的是目前可用的资源信息。这些信息会提供给调度策略使用，当有计算任务到来时，通过调度策略在资源池中选择资源分配给它。</p>\n<p>③ 同理，资源池的信息也会上报到调度策略中。调度策略中维护着 FIFO、公平调度、能力调度、延迟调度等分配算法。在实际的调度场景中，可以选择其中的 1 种或者多种策略。</p>\n<p>④ 调度策略会不断监控工作队列中的计算任务，并依次处理这些任务——使用调度策略对计算任务与资源做匹配，让计算任务在具体的容器中执行。当计算任务执行完毕以后，资源调度器会回收资源，并通过节点管理器将空闲资源上报给资源收集器，使其重新回到资源池中等待被分配。</p>\n<p>⑤ 当有计算任务请求资源调度器的时候，会将这些任务放到工作队列中以便管理。资源调度器在这里起到承上启下的作用。承上是对接计算任务框架并对其进行组织；启下是获取资源信息并对其进行抽象；最后，对计算任务和资源按照策略进行匹配。同时这也是一个动态资源分配的过程，这种方式可用支持不同的计算框架，例如 MapReduce、Spark、Storm 等。真正做到了计算任务和资源的解耦。</p>\n<h2 id=\"nav_point_139\">7.2　资源划分和调度策略</h2>\n<p>从 7.1.2 节中介绍的资源分配过程可以看出，为了匹配资源与计算任务，需要针对资源进行划分，并且按照调度策略将其分配给计算任务。因此本节以资源划分和资源调度作为切入点，进行进一步讲述。</p>\n<h3 id=\"nav_point_140\">7.2.1　Linux Container 资源是如何划分的</h3>\n<p>正如在第 5 章中提到的，MapReduce 模式会对计算资源按照 Slot 的方式进行分割。在分布式资源调度中，为了完成计算任务，也会对资源进行分割，7.1.2 节中我们把分割后的资源称为容器（container）。目前，最常见的资源分割方式是 Linux Container（LXC），这是一种内核虚拟化技术，可以提供轻量级的虚拟化，以便隔离进程和资源。YARN、Mesos 等资源调度系统都是利用这种方式进行的资源分割。LXC 将物理节点上的资源（例如 CPU、内存等）分割成若干个相互隔离的容器，每个容器分别完成资源调度器分配给自己的计算任务。这种方式保证计算任务的进程之间互不干扰，每个计算任务都有固定的资源空间，其运行范围也被限制这个空间内。</p>\n<p>如图 7-6 所示，左边是基于操作系统的传统应用模式，APP1~APP3 基于操作系统的 Kernel（核心），会同时使用操作系统中的所有资源。顺着箭头向右过渡到容器应用，这种模式在操作系统的 Kernel 之上建立了一层容器引擎（Container Engine），用来对操作系统的资源进行划分，让 APP1~APP3 的应用基于容器引擎而非操作系统，每个容器分配的资源服务于独立的应用程序，这里的容器引擎也就是 LXC。</p>\n<p class=\"pic\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00503.jpeg\" alt=\"{%}\" /></p>\n<p class=\"ebook-image-title\"><strong>图 7-6　从传统应用到容器应用</strong></p>\n<p>这种用容器划分操作系统资源的方式具有以下几个优点。</p>\n<ul>\n<li><strong>隔离性</strong>。显而易见，容器的部署方式允许在一台物理机器上部署多个应用。每个应用被分配到单独的容器中，以独占的方式获取容器中的资源。</li>\n<li><strong>安全性</strong>。可以针对各个容器，设置对应的安全级别，这种做法能够弥补安全漏洞以及由安全问题造成的损害。即便是容器中遭到黑客攻击，其危害范围也只在本容器之内，不会危及到其他容器以及操作系统内核。</li>\n<li><strong>透明性</strong>。容器机制只是对操作系统的资源进行抽象，将这些资源以虚拟化的方式重新组织在一起。对于应用程序而言，不需要了解更多的操作系统以及硬件级别的信息，只是使用分配给自己的虚拟化资源就好。</li>\n<li><strong>扩展性</strong>。正是良好的隔离性和透明性，让容器本身具有良好的扩展性，容器可以根据操作系统的资源情况以及整个集群的资源情况进行扩展。特别是在高并发、大流量的应用场景中，容器的扩展性会发挥特有的作用。</li>\n</ul>\n<p>除了具有以上优点，采取这种资源划分的模式也会引发新问题，就是如何进行资源的隔离和限制。资源的隔离解决的是如何划分资源，资源的限制解决的是如何对资源进行限制。简单来说，前者负责隔离资源，后者负责管理资源，即容器如何划分是科学的，以及如何合理地管理容器。这两部分功能在 LXC 中分别由 Namespace 和 Cgroup 实现，下面就分别讲述两部分的功能。</p>\n<ol>\n<li><p><strong>LXC 的 Namespace 机制</strong></p>\n<p>Linux Namespace，即命名空间机制，是一种资源隔离方案，它按照特定的命名空间对系统资源进行划分。每个命名空间中的资源对其他命名空间都是透明的。</p>\n<p>命名空间给容器化提供了轻量级形式，也就是图 7-6 中提到的操作系统级别的容器化。一般来说，Linux 系统中的每个进程都有一个唯一的 PID 作为标识，操作系统内核会维护一个 PID 列表。每个 Linux 用户都有唯一的 UID 作为标识，操作系统内核同样会维护一个 UID 列表。全局唯一 ID 的模式能够帮助内核管理整个系统中的资源。这种分配方式虽然可以对 PID 和 UID 进行匹配，可以设置用户对应的执行进程，可以针对用户执行的进程设置权限。但是用户之间还是可以感知对方的存在，例如用户 A 知道用户 B 执行进程的状态，对于对隐私性要求较高的服务而言，这显然是不够的。</p>\n<p>为了解决上述类似的问题，在系统内核之上提供了隔离的用户空间，这种隔离面向目标就是用户运行的进程。目的是使在隔离空间中运行的进程不受其他空间中进程的干扰，每个进程只能看到自己用户空间内的信息，而无法感知其他空间中进程的状态。简单来说，这么做不只是为了运行进程，更是为了隔离。如图 7-7 所示，父命名空间中管理着进程 1~4，同时父命名空间可以分别查看两个子命名空间，其中子命名空间 1 中运行着进程 1 和 2，子命名空间 2 中运行着进程 3 和 4。但是，站在两个子命名空间的角度，它们都只能看到在自己空间中运行的进程，无法感知对方的存在，更无法改变对方的运行状态。</p>\n<p class=\"p-img\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00504.jpeg\" alt=\"\" width=\"95%\" style=\"width: 95%\" /></p>\n<p class=\"ebook-image-title\"><strong>图 7-7　命名空间实现资源隔离</strong></p>\n<p>上面提到了 LXC Namespace 内核级别隔离的机制，接下来介绍几种常见的隔离模式。这里分别从主机名、磁盘、进程以及进程通信、用户和网络的角度讲解。</p>\n<ul>\n<li><p><strong>UTS Namespace</strong></p>\n<p>UTS Namespace（UNIX Time-sharing System Namespace，主机名隔离），提供了主机名和域名的隔离，使进程能够独立运行于主机名和域名。可以想象，有多个容器运行在同一主机上，从资源隔离的角度来看，这若干个容器就好像多台独立运行的主机。既然是可以独立运行的主机，就必须拥有自己的主机名。UTS Namespace 就提供了对主机名和域名的隔离，它会给每个容器设置默认的 ID 作为主机名。当然这个 ID 也可以在容器启动的时候进行设置。</p>\n<p>&nbsp;</p>\n</li>\n<li><p><strong>Mount Namespace</strong></p>\n<p>Mount 是 Linux 系统中的挂载命令，因此 Mount Namespace（文件系统隔离）是为进程提供独立的文件系统，也就是从文件系统层面实现隔离。Mount Namespace 会为容器分配指定的文件系统，使其拥有 /、/bin、/sbin、/etc 等目录，换言之就是隔离文件系统的挂载点，使运行在容器中的进程只能看到自己的文件系统挂载点。同理，在容器中对文件系统进行操作，也不会影响到主机内核以及其他容器中的文件系统。</p>\n<p>&nbsp;</p>\n</li>\n<li><p><strong>IPC Namespace</strong></p>\n<p>IPC（Inter-Process Communication，进程间通信）是 Linux 系统中进程间通信的一种方式，其中包含共享内存、信号量、消息队列等方法。系统中的每个 Namespace 都拥有自己的 IPC，设置 IPC 的目的是保证处在同一用户空间的进程之间可以通信，跨用户空间的进程之间则无法通信，这就是 IPC 隔离。另外，每个用户空间都会维护一个全局的 ID，这个 ID 对除自己外的其他用户空间隔离。</p>\n<p>&nbsp;</p>\n</li>\n<li><p><strong>PID Namespace</strong></p>\n<p>PID 是 Process ID 的缩写，即进程 ID。Linux 系统中会一直维护进程树和文件系统树，init 进程作为初始进程，就是进程树的根节点。在系统中运行的进程都需要由对应的父进程创建，除非这个进程本身就是 init 进程，这是 Linux 系统管理进程的方式。在进行 PID 资源隔离的时候，一个独立的用户空间，就相当于一片小天地，这片小天地里面同样需要有自己的 init 进程。但是整个系统中的 init 进程只能有一个（真的），因此每个用户空间都会创建一个假的 init 进程，可以将之理解为系统指派的用来管理这个容器的 init 进程。这个特殊进程只针对用户空间而言，它如果消失就意味着用户空间的消失，但是并不会影响其他用户空间以及 Linux 系统的真 init 进程。这也是为什么需要对 PID 进行隔离的原因。</p>\n<p>&nbsp;</p>\n</li>\n<li><p><strong>User Namespace</strong></p>\n<p>和 PID Namespace 的原理相似，Linux 系统会维护一个用户树，在系统内核中只能有一个 root 用户，也就是用户树的根节点，所有用户都要基于这个节点进行挂接。对于隔离的用户空间而言，也需要一个 root 用户节点，于是如法炮制，给用户空间生成一个假的 root 用户。这个 root 用户下面可以挂接其他用户，并且只作为这个空间的 root 用户存在，对于整个 Linux 系统而言，它是真正 root 用户下面的一个普通用户。通过这种方式实现了用户隔离。</p>\n<p>&nbsp;</p>\n</li>\n<li><p><strong>Network Namespace</strong></p>\n<p>顾名思义，Network Namespace（网络隔离）是让容器拥有独立的网卡、IP、路由等资源，同时实现容器之间的网络通信。由于资源隔离的原因，每个用户空间都认为自己是唯一存在的空间，拥有独立的 IP 以及端口、TCP/IP 协议栈。这里完全可以将两个容器想象为两个独立的计算机，它们之间可以通过网络协议完成通信。</p>\n</li>\n</ul>\n<p>&nbsp;</p>\n</li>\n<li><p><strong>LXC 的 CGroup 机制</strong></p>\n<p>通过对 LXC 中命名空间机制的介绍，我们了解到该机制的主要工作就是对操作系统管理的资源进行划分，使运行在不同用户空间（容器）中的进程互相隔离。那么有了对资源的划分后，又该如何管理运行在划分的资源中的进程呢？这就是 CGroup 需要解决的问题。CGroup 即 Control Groups，是 Linux 内核提供的一种资源管理机制，包括资源限制、记录等。Namespace 是负责资源隔离的，CGroup 是负责管理运行在隔离资源中的进程的。CGroup 先对进程进行分组，然后针对分组后的进程进行 CPU、内存、磁盘等资源的限制和管理。它会将具有相同资源限制要求的进程放到一个组里，通过设置 CGroup 子系统的方式对进程组进行资源限制。下面来介绍 CGroup 中的几个概念。</p>\n<ul>\n<li><strong>任务（Task）</strong>。这里可以理解为计算任务，也可以理解为进程，说白了就是执行计算的基本单元。每个用户空间中都存在多个任务，CGroup 就是对任务占用的资源进行限制和管理。</li>\n<li><strong>控制族群（Control Group）</strong>。就是进程的集合，多个进程会被划分到同一个控制族群中。也可以将控制族群理解为进程组，即若干个进程的集合。一个进程可以加入到任意一个控制族群中，也可以从一个控制族群移动到另一个控制族群。</li>\n<li><strong>层级（Hierarchy）</strong>。它是由多个控制族群组成的，表现为一个树形结构。层级结构通常有一个根节点，根节点本身就是一个控制族群，可以根据这个根节点生成子节点，同样子节点也是一个控制族群，最终形成一个树状结构。子节点会继承父节点的属性。</li>\n<li><strong>子系统（subsystem）</strong>。它的作用是针对控制族群进行资源限制。例如：配置某一控制族群中的进程 CPU 利用率不得超过 20%，最多可以使用 64KB 内存。子系统必须附加（attach）到一个层级上才能起作用，也就是针对这个层级进行资源限制。当子系统附加到某个层级后，这个层级上的所有控制族群都会受到这个子系统的控制。下面我们将利用子系统进行资源限制的细节通过表 7-1 展示出来。</li>\n</ul>\n<p><strong>表 7-1　CGroup 子系统功能列表</strong></p>\n<table class=\"table table-bordered table-striped table-condensed\" width=\"90%\" border=\"1\"><tr><th>子系统名称</th><th>描述</th></tr><tr><td>cpu 子系统</td><td>限制进程的 CPU 使用率</td></tr><tr><td>cpuacct 子系统</td><td>统计 CGroup 中进程的 CPU 使用报告</td></tr><tr><td>cpuset 子系统</td><td>为 CGroup 中的进程分配单独的 CPU 节点</td></tr><tr><td>memory 子系统</td><td>限制进程的内存使用量</td></tr><tr><td>blkio 子系统</td><td>限制进程的块设备 IO 访问量</td></tr><tr><td>devices 子系统</td><td>限制进程能够访问的设备</td></tr><tr><td>net_cls 子系统</td><td>标记 CGroup 中进程的网络数据包，并使用 traffic control 模块对数据包进行限制</td></tr><tr><td>net_prio 子系统</td><td>设置网络流量的优先级</td></tr><tr><td>freezer 子系统</td><td>挂起或者恢复 CGroup 中的进程</td></tr><tr><td>ns 子系统</td><td>针对不同 CGroup 中的进程，使用不同的命名空间</td></tr></table>\n\n<p>上面介绍了 CGroup 的概念，接下来对其工作方式做进一步的了解。我们通过一个小例子来了解 CGroup 的运行原理，原理图如图 7-8 所示。</p>\n<p class=\"p-img\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00505.jpeg\" alt=\"{%}\" /></p>\n<p class=\"ebook-image-title\"><strong>图 7-8　CGroup 运行原理图</strong></p>\n<p>从左往右看图 7-8。假设用户空间中有四个计算任务，分别是 P1~P4，正在等待执行。CGroup 会将它们分配到右边的层级中去，这里假设需要对计算任务的 CPU 和内存做限制，于是相应建立了两个层级，分别是 CPU 层级和 Memory 层级。每个层级都对应一个或者多个子系统，这个例子里的两个层级分别对应 cpu 子系统和 memory 子系统，这一点可以从图中右侧看出。回到两个层级，CPU 层级中有一个根节点叫作 CPU CGroup，这个根节点下面有两个子节点，一个叫作 CPU 20% CGroup，这是一个控制族群，其中存放着 P1 和 P2 两个进程。这些配置的含义是通过 cpu 子系统对 CPU 层级中的进程进行资源限制，而对 CPU 层级中的 CPU 20% CGroup 节点的限制条件是 CPU 的使用率不超过 20%。同理，另外一个节点 CPU 80% CGroup 也是一个控制族群，它包含进程 P3 和 P4，对这两个进程做出的资源限制是 CPU 使用率不超过 80%。一个进程可以同时属于多个层级和控制族群，在看 Memory 层级的时候会发现，针对这个层级使用了 memory 子系统，也就是限制进程的内存资源。Memory 层级中，同样出现了 P1~P4 四个进程的身影，Memory 64K（进程的运行内存不超过 64KB）控制族群中包括 P1 和 P3，Memory 128K（进程的运行内存不超过 128KB）控制族群中包括 P2 和 P4。很明显，P1 进程在资源限制方面存在于 CPU 20% 和 Memory 64K 两个族群，其他三个进程的情况也是类似。</p>\n<p>上面这个例子描述了 CGroup 是如何进行资源限制的。在特定的用户空间中，由于每个进程都具有特殊性，因此对它们的资源限制要求是不一样的，这便需要对用户空间中的进程进行分类，然后使用子系统实现资源限制。这里提到的进程分类方式就是层级，一个层级中包含具有同一类型的资源限制要求的进程。针对每个层级，可以附着一个或者多个子系统，用来执行资源限制。层级中维护着一个树形结构，其每个节点称作控制族群，控制族群包含一个或者多个进程，针对具体的控制族群还会进行更加具体的资源限制，例如限制 CPU 的使用率为 20%，限制内存的使用量不超过 64KB 等。</p>\n<p>至此，LXC 中的 Namespace 和 CGroup 的概念就介绍完了，最后稍加总结。LXC 是用来进行资源划分的机制，其主要功能包括 Namespace，即资源的隔离，和 CGroup，即对隔离的资源做限制。可以通过一个通俗的例子加以记忆，假设学校对学生进行分班，给每个班级分别分配了教室、桌椅板凳、黑板和粉笔等，这个分配的过程就可以理解为资源隔离。每个班上都有各式各样的学生，针对这些学生可以设置不同的兴趣小组，例如画画小组、篮球小组、舞蹈小组，每个小组都可以有一个或者多个学生参加。可以把学生理解为一个个进程，设置的小组就可以理解为层级结构。每个兴趣小组根据具体情况，可以把自己组内的学生划分为高中低三个档次，学校会为每个兴趣小组分配指定用品供其活动，例如为画画小组提供彩笔、颜料棒等；为篮球小组提供篮球和场地；为舞蹈小组提供服装和音响等。这个过程就可以理解为子系统对层级中的控制族群限制资源。另外，根据小组内部学生的不同档次，还可以进行用品的精确分配，例如分配 10 只画笔、2 个篮球、3 套服装等。LXC 做的事情实际上就是面向进程进行合理的资源分配和限制，为分布式资源调度提供坚实的基础。例如流行的容器系统 Docker，就是基于 LXC 进行的封装，本书主要介绍分布式技术的原理和实践，故不针对 Docker 展开描述。可以通过了解 Docker 与 LXC 的区别来获知 LXC 都为容器技术提供了哪些基础服务，以及 Docker 又是如何在这个基础上将容器思想发扬光大的。</p>\n</li>\n</ol>\n<h3 id=\"nav_point_141\">7.2.2　任务与资源如何匹配</h3>\n<p>上一节讲到了如何划分资源。对系统资源按照一定规律进行划分的目的是分配给计算任务使用，这一节就来介绍计算任务与资源是如何相匹配的，主要从计算任务与资源的组织形态和资源调度策略两方面展开。</p>\n<ol>\n<li><p><strong>任务队列与资源池</strong></p>\n<p>资源的划分就好像对资源进行切割，通常来说，被切割的资源会被放到资源池中等待调度器分配计算任务。这里的资源池是逻辑上的概念，可以根据计算任务、用户、场景以及需求的不同进行相应调整。</p>\n<p>试想一个公司有两个部门，分别是开发部门和数据分析部门，如图 7-9 所示。两个部门虽然从事的业务各不相同，但是都需要使用公司提供的资源才能进行应用的开发。公司为了满足它们应用的需要，在服务器集群中动态划分出了两个资源池，也就是图 7-9 中显示的开发部门资源池和数据分析部门资源池。当开发部门有计算任务的时候，调度系统会用这些任务组成一个任务队列，就像图 7-9 中的 P1~P6 计算任务形成的队列一样，并将其分配到对应的资源池中进行计算。同样，数据分析部门的资源池中也有 P7~P12 计算任务组成的任务队列。</p>\n<p class=\"p-img\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00506.jpeg\" alt=\"\" width=\"82%\" style=\"width: 82%\" /></p>\n<p class=\"ebook-image-title\"><strong>图 7-9　平级队列的组织方式</strong></p>\n<p>上述这种资源分配的方式被称为平级队列的组织方式，在资源分配的初期，业务场景比较简单时可以采取这种方式。但是，随着业务变复杂，分配方式也产生了变化，例如开发部门需要分别针对 Storm 和 MapReduce 两类应用进行计算处理，数据分析部门则需要分析业务数据和日志数据。此时就需要采用多层级队列来组织计算任务，如图 7-10 所示，针对开发部门和数据分析部门处理的业务情况，分别在 Root 资源节点下面建立了两个资源节点：开发部门和数据分析部门。假设 Root 资源节点占有整个系统 100%的资源，并按照 60%和 40%的比例将资源分配给了两个部门对应的资源池，这里的资源池可以理解为资源划分中的用户空间或者资源容器。在开发部门的资源池下面，又建立了 Storm 计算（50%）和 MapReduce 计算（50%）两个资源池，从资源分配的比例来看，这两类计算任务平分了开发部门从 Root 节点获取的资源。开发部门的计算任务则会根据计算类型的不同，生成 Storm 计算的队列（P1~P3）和 MapReduce 计算的队列（P4~P6），这两个队列分别使用相应资源池里的资源。再来看数据分析部门，它获取了 Root 节点（整个系统）的 40%的资源，业务数据分析和日志数据分析分别获得了 60% 和 40% 的数据分析部门的资源。同样，数据分析部门的计算任务会生成业务数据分析的计算队列（P7~P10）和日志数据分析的计算队列（P11 和 P12）。</p>\n<p class=\"p-img\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00507.jpeg\" alt=\"\" width=\"85%\" style=\"width: 85%\" /></p>\n<p class=\"ebook-image-title\"><strong>图 7-10　多层级队列的组织方式</strong></p>\n<p>多层级队列的组织方式具有以下特点。</p>\n<ul>\n<li><strong>子队列</strong>。资源节点可以嵌套，每个节点下面还可以拥有子节点。用户会将计算任务（应用程序）形成队列，并提交给叶子节点。</li>\n<li><strong>容量限制</strong>。每个层级的资源节点都有容量限制，表现为一个比例，这个比例表示该资源节点可以使用父节点的多少资源，该节点的计算任务不能超过这个资源的使用限制。需要注意的是，当资源节点上的计算任务没有使用到节点的最少容量时，系统会将剩余没有使用的容量分配给同级的其他节点使用。当该节点需要更多资源的时候，会去回收这部分借出去的资源容量，再为己所用。</li>\n<li><strong>用户权限</strong>。根据图 7-10 例子中的描述，不同部门参与资源的分配时，一定会针对部门不同的用户。这些用户权限也需要和资源节点相映射。例如，开发部门只有负责 Storm 运算小组的成员才能使用 Storm 计算对应的资源，运行对应的应用程序。这里系统允许用户和用户组对应一个或者多个计算任务队列。</li>\n</ul>\n<p>&nbsp;</p>\n</li>\n<li><p><strong>三大资源调度策略</strong></p>\n<p>至此，就说完了计算任务和资源是如何匹配的，需要注意的是，计算任务是以队列的形式存在，分布式调度系统会为这个队列划分一块资源以便使用。但是无论怎样分配，资源都不可能同时满足队列中的所有任务，换句话说就是队列中的计算任务需要按照一定的规则获取硬件资源，这种规则被理解为资源的调度策略。接下来就介绍三种调度策略器，分别是 FIFO 调度器、Capacity 调度器和 Fair 调度器。</p>\n<ul>\n<li><p><strong>FIFO 调度器（先进先出）</strong></p>\n<p>对于队列，会把先提交的任务放在前面，因此先提交的任务理所当然会被优先执行。在分配资源的时候，会先给排在队列前面的任务分配，当满足前面任务的资源需求以后，才能轮到后面的计算任务。如图 7-11 所示，在一个平面坐标轴上，横轴表示时间，纵轴表示任务对资源的占用量。假设在一个 FIFO 队列中，任务 1 首先提交到队列，队列会将所有资源都分配给任务 1，保证其运行。从虚线的部分可以看出，过一段时间后任务 2 也提交了，但是此时任务 1 仍然在运行中，因此任务 2 还不能运行。直到任务 1 运行完毕并且释放资源后，任务 2 才能接着运行。FIFO 调度器执行起来比较简单，不需要额外的配置，所有的调度策略都按照任务的提交次序来决定，这就可能出现排在后面的小任务一直等待前面的大任务，从而被大任务阻塞这种情况。</p>\n<p class=\"p-img\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00508.jpeg\" alt=\"\" width=\"90%\" style=\"width: 90%\" /></p>\n<p class=\"ebook-image-title\"><strong>图 7-11　FIFO 调度器</strong></p>\n<p>&nbsp;</p>\n</li>\n<li><p><strong>Capacity 调度器（能力）</strong></p>\n<p>Capacity 调度器是 Yahoo 为 Hadoop 开发的多用户调度器，适合用户较多的应用场景。这种调度器允许用户和任务共享整个集群资源，会为每个用户和队列分配专门的队列，为每个队列设置资源使用的最低保障和使用上限。在队列内部，资源的调度是采用的是 FIFO 策略。</p>\n<p>当队列资源有剩余时，可以将这部分资源分配给其他队列中的任务使用。在进行调度的时候，调度器会优先将资源分配给资源使用率最低的队列，也就是队列已经使用的资源量占分配给队列的资源量之比最小的队列。正常情况下，Capacity 调度器不会强制释放资源，当一个队列资源不够用时，可以获得其他队列释放的资源。这里需要给队列设置最大资源使用量，以免队列占用过多的空闲资源，导致其他队列无法使用这些空闲资源。在 Capacity 调度器的应用中，可以设置一个专门的队列用来运行小任务，这种设置不像在 FIFO 调度器中提到的，小任务必须等待大任务运行完毕以后才能执行。如图 7-12 所示，Capacity 调度器根据每个任务队列的能力，为它们设置了不同的资源限制。其中位于下方的大任务队列占有更大的资源量，位于上方的小任务队列则占用较小的资源量。在时间轴的开始位置，任务 1 提交了，调度器将其分配到了大任务队列中执行。此时任务 1 并没有占用小任务队列中的资源，过一会儿任务 2 提交了，调度器将其分配到了小任务队列中，此时任务 2 进入运行状态。执行了一段时间以后，任务 2 完成。这整个过程中，小任务队列和大任务对列都维持着各自的资源空间。</p>\n<p class=\"p-img\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00509.jpeg\" alt=\"\" width=\"95%\" style=\"width: 95%\" /></p>\n<p class=\"ebook-image-title\"><strong>图 7-12　Capacity 调度器</strong></p>\n<p>假设小任务队列一直占用一定的资源，但是又没有小任务被执行，那么这部分资源也不能被大任务利用，就会导致大任务的执行时间远多于 FIFO 策略下大任务的执行时间。为了解决这个问题，引入了 Fair 调度器。</p>\n<p>&nbsp;</p>\n</li>\n<li><p><strong>Fair 调度器（公平）</strong></p>\n<p>Fair 调度器是 Facebook 为 Hadoop 开发的多用户多作业调度器，可以将用户需要执行的任务分配到资源池中。每个资源池中都会维护用户的任务队列，并且为任务队列设置资源分配的上限和下限。Fair 调度器还可以设置资源池的优先级。优先级高的资源池会获得更多的资源，倘若一个资源池中有剩余资源，是可以临时共享给其他资源池的。</p>\n<p>如图 7-13 所示，假设在单用户单资源池（队列）的场景下，在时间轴的开始位置，任务 1 首先提交。此时，任务队列中并没有其他任务在运行，预算任务 1 获得全部的队列资源。过了一会，任务 2 提交了，系统会分配一半资源给任务 2 以使其运行，从而任务 1 让出了一半的运行资源。当任务 2 运行完毕并释放使用的资源后，任务 1 重新获取全部的资源，继续执行。</p>\n<p class=\"p-img\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00510.jpeg\" alt=\"\" width=\"95%\" style=\"width: 95%\" /></p>\n<p class=\"ebook-image-title\"><strong>图 7-13　Fair 调度器（单用户单资源池）</strong></p>\n<p>如图 7-14 所示，是多用户多资源池（队列）的场景。假设有两个用户分别将计算任务分配到了队列 A 和队列 B 上，在时间轴的开始位置，队列 A 中的任务 1 提交并且运行了，队列 B 中并没有任务运行，因此任务 1 暂时占用着队列 A 和队列 B 中的资源。过了一会儿，队列 B 中的任务 2 提交了，于是任务 2 获取队列 B 中的资源，同时任务 1 让出队列 B 中的资源且仅使用队列 A 中的资源。又过了一会儿，队列 B 中的任务 3 提交了，此时任务 2 还在运行中并没有完成，所以任务 3 和任务 2 平分了队列 B 里的资源。当任务 2 运行完成后，任务 3 获取了队列 B 里全部的资源，继续执行。任务 2 和任务 3 的交替执行在图中形成了两个 L 型（一正一倒）的资源占用。</p>\n<p class=\"p-img\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00511.jpeg\" alt=\"\" width=\"90%\" style=\"width: 90%\" /></p>\n<p class=\"ebook-image-title\"><strong>图 7-14　 Fair 调度器（多用户多资源池）</strong></p>\n</li>\n</ul>\n</li>\n</ol>\n","comments":[]}