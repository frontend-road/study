{"id":109121,"title":"21 | Java 消费者是如何管理TCP连接的?","content":"<p>你好，我是胡夕。今天我要和你分享的主题是：Kafka的Java消费者是如何管理TCP连接的。</p><p>在专栏<a href=\"https://time.geekbang.org/column/article/103844\">第13讲</a>中，我们专门聊过“Java<strong>生产者</strong>是如何管理TCP连接资源的”这个话题，你应该还有印象吧？今天算是它的姊妹篇，我们一起来研究下Kafka的Java<strong>消费者</strong>管理TCP或Socket资源的机制。只有完成了今天的讨论，我们才算是对Kafka客户端的TCP连接管理机制有了全面的了解。</p><p>和之前一样，我今天会无差别地混用TCP和Socket两个术语。毕竟，在Kafka的世界中，无论是ServerSocket，还是SocketChannel，它们实现的都是TCP协议。或者这么说，Kafka的网络传输是基于TCP协议的，而不是基于UDP协议，因此，当我今天说到TCP连接或Socket资源时，我指的是同一个东西。</p><h2>何时创建TCP连接？</h2><p>我们先从消费者创建TCP连接开始讨论。消费者端主要的程序入口是KafkaConsumer类。<strong>和生产者不同的是，构建KafkaConsumer实例时是不会创建任何TCP连接的</strong>，也就是说，当你执行完new KafkaConsumer(properties)语句后，你会发现，没有Socket连接被创建出来。这一点和Java生产者是有区别的，主要原因就是生产者入口类KafkaProducer在构建实例的时候，会在后台默默地启动一个Sender线程，这个Sender线程负责Socket连接的创建。</p><!-- [[[read_end]]] --><p>从这一点上来看，我个人认为KafkaConsumer的设计比KafkaProducer要好。就像我在第13讲中所说的，在Java构造函数中启动线程，会造成this指针的逃逸，这始终是一个隐患。</p><p>如果Socket不是在构造函数中创建的，那么是在KafkaConsumer.subscribe或KafkaConsumer.assign方法中创建的吗？严格来说也不是。我还是直接给出答案吧：<strong>TCP连接是在调用KafkaConsumer.poll方法时被创建的</strong>。再细粒度地说，在poll方法内部有3个时机可以创建TCP连接。</p><p>1.<strong>发起FindCoordinator请求时</strong>。</p><p>还记得消费者端有个组件叫协调者（Coordinator）吗？它驻留在Broker端的内存中，负责消费者组的组成员管理和各个消费者的位移提交管理。当消费者程序首次启动调用poll方法时，它需要向Kafka集群发送一个名为FindCoordinator的请求，希望Kafka集群告诉它哪个Broker是管理它的协调者。</p><p>不过，消费者应该向哪个Broker发送这类请求呢？理论上任何一个Broker都能回答这个问题，也就是说消费者可以发送FindCoordinator请求给集群中的任意服务器。在这个问题上，社区做了一点点优化：消费者程序会向集群中当前负载最小的那台Broker发送请求。负载是如何评估的呢？其实很简单，就是看消费者连接的所有Broker中，谁的待发送请求最少。当然了，这种评估显然是消费者端的单向评估，并非是站在全局角度，因此有的时候也不一定是最优解。不过这不并影响我们的讨论。总之，在这一步，消费者会创建一个Socket连接。</p><p>2.<strong>连接协调者时。</strong></p><p>Broker处理完上一步发送的FindCoordinator请求之后，会返还对应的响应结果（Response），显式地告诉消费者哪个Broker是真正的协调者，因此在这一步，消费者知晓了真正的协调者后，会创建连向该Broker的Socket连接。只有成功连入协调者，协调者才能开启正常的组协调操作，比如加入组、等待组分配方案、心跳请求处理、位移获取、位移提交等。</p><p>3.<strong>消费数据时。</strong></p><p>消费者会为每个要消费的分区创建与该分区领导者副本所在Broker连接的TCP。举个例子，假设消费者要消费5个分区的数据，这5个分区各自的领导者副本分布在4台Broker上，那么该消费者在消费时会创建与这4台Broker的Socket连接。</p><h2>创建多少个TCP连接？</h2><p>下面我们来说说消费者创建TCP连接的数量。你可以先思考一下大致需要的连接数量，然后我们结合具体的Kafka日志，来验证下结果是否和你想的一致。</p><p>我们来看看这段日志。</p><blockquote>\n<p><em>[2019-05-27 10:00:54,142] DEBUG [Consumer clientId=consumer-1, groupId=test] Initiating connection to node <span class=\"orange\">localhost:9092</span> (id: -1 rack: null) using address localhost/127.0.0.1 (org.apache.kafka.clients.NetworkClient:944)</em></p>\n</blockquote><blockquote>\n<p><em>......</em></p>\n</blockquote><blockquote>\n<p><em>[2019-05-27 10:00:54,188] DEBUG [Consumer clientId=consumer-1, groupId=test] <span class=\"orange\">Sending metadata request</span>  MetadataRequestData(topics=[MetadataRequestTopic(name='t4')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node <span class=\"orange\">localhost:9092</span> (id: -1 rack: null) (org.apache.kafka.clients.NetworkClient:1097)</em></p>\n</blockquote><blockquote>\n<p><em>......</em></p>\n</blockquote><blockquote>\n<p><em>[2019-05-27 10:00:54,188] TRACE [Consumer clientId=consumer-1, groupId=test] <span class=\"orange\">Sending FIND_COORDINATOR</span> {key=test,key_type=0} with correlation id 0 to node -1 (org.apache.kafka.clients.NetworkClient:496)</em></p>\n</blockquote><blockquote>\n<p><em>[2019-05-27 10:00:54,203] TRACE [Consumer clientId=consumer-1, groupId=test] Completed receive from node -1 for FIND_COORDINATOR with correlation id 0, received {throttle_time_ms=0,error_code=0,error_message=null, <span class=\"orange\">node_id=2,host=localhost,port=9094</span>} (org.apache.kafka.clients.NetworkClient:837)</em></p>\n</blockquote><blockquote>\n<p><em>......</em></p>\n</blockquote><blockquote>\n<p><em>[2019-05-27 10:00:54,204] DEBUG [Consumer clientId=consumer-1, groupId=test] Initiating connection to node <span class=\"orange\">localhost:9094</span> (id: 2147483645 rack: null) using address localhost/127.0.0.1 (org.apache.kafka.clients.NetworkClient:944)</em></p>\n</blockquote><blockquote>\n<p><em>......</em></p>\n</blockquote><blockquote>\n<p><em>[2019-05-27 10:00:54,237] DEBUG [Consumer clientId=consumer-1, groupId=test] Initiating connection to node <span class=\"orange\">localhost:9094</span> (id: 2 rack: null) using address localhost/127.0.0.1 (org.apache.kafka.clients.NetworkClient:944)</em></p>\n</blockquote><blockquote>\n<p><em>[2019-05-27 10:00:54,237] DEBUG [Consumer clientId=consumer-1, groupId=test] Initiating connection to node<span class=\"orange\"> localhost:9092</span> (id: 0 rack: null) using address localhost/127.0.0.1 (org.apache.kafka.clients.NetworkClient:944)</em></p>\n</blockquote><blockquote>\n<p><em>[2019-05-27 10:00:54,238] DEBUG [Consumer clientId=consumer-1, groupId=test] Initiating connection to node <span class=\"orange\">localhost:9093</span> (id: 1 rack: null) using address localhost/127.0.0.1 (org.apache.kafka.clients.NetworkClient:944)</em></p>\n</blockquote><p>这里我稍微解释一下，日志的第一行是消费者程序创建的第一个TCP连接，就像我们前面说的，这个Socket用于发送FindCoordinator请求。由于这是消费者程序创建的第一个连接，此时消费者对于要连接的Kafka集群一无所知，因此它连接的Broker节点的ID是-1，表示消费者根本不知道要连接的Kafka Broker的任何信息。</p><p>值得注意的是日志的第二行，消费者复用了刚才创建的那个Socket连接，向Kafka集群发送元数据请求以获取整个集群的信息。</p><p>日志的第三行表明，消费者程序开始发送FindCoordinator请求给第一步中连接的Broker，即localhost:9092，也就是nodeId等于-1的那个。在十几毫秒之后，消费者程序成功地获悉协调者所在的Broker信息，也就是第四行标为橙色的“node_id = 2”。</p><p>完成这些之后，消费者就已经知道协调者Broker的连接信息了，因此在日志的第五行发起了第二个Socket连接，创建了连向localhost:9094的TCP。只有连接了协调者，消费者进程才能正常地开启消费者组的各种功能以及后续的消息消费。</p><p>在日志的最后三行中，消费者又分别创建了新的TCP连接，主要用于实际的消息获取。还记得我刚才说的吗？要消费的分区的领导者副本在哪台Broker上，消费者就要创建连向哪台Broker的TCP。在我举的这个例子中，localhost:9092，localhost:9093和localhost:9094这3台Broker上都有要消费的分区，因此消费者创建了3个TCP连接。</p><p>看完这段日志，你应该会发现日志中的这些Broker节点的ID在不断变化。有时候是-1，有时候是2147483645，只有在最后的时候才回归正常值0、1和2。这又是怎么回事呢？</p><p>前面我们说过了-1的来由，即消费者程序（其实也不光是消费者，生产者也是这样的机制）首次启动时，对Kafka集群一无所知，因此用-1来表示尚未获取到Broker数据。</p><p>那么2147483645是怎么来的呢？它是<strong>由Integer.MAX_VALUE减去协调者所在Broker的真实ID计算得来的</strong>。看第四行标为橙色的内容，我们可以知道协调者ID是2，因此这个Socket连接的节点ID就是Integer.MAX_VALUE减去2，即2147483647减去2，也就是2147483645。这种节点ID的标记方式是Kafka社区特意为之的结果，目的就是要让组协调请求和真正的数据获取请求使用不同的Socket连接。</p><p>至于后面的0、1、2，那就很好解释了。它们表征了真实的Broker ID，也就是我们在server.properties中配置的broker.id值。</p><p>我们来简单总结一下上面的内容。通常来说，消费者程序会创建3类TCP连接：</p><ol>\n<li>确定协调者和获取集群元数据。</li>\n<li>连接协调者，令其执行组成员管理操作。</li>\n<li>执行实际的消息获取。</li>\n</ol><p>那么，这三类TCP请求的生命周期都是相同的吗？换句话说，这些TCP连接是何时被关闭的呢？</p><h2>何时关闭TCP连接？</h2><p>和生产者类似，消费者关闭Socket也分为主动关闭和Kafka自动关闭。主动关闭是指你显式地调用消费者API的方法去关闭消费者，具体方式就是<strong>手动调用KafkaConsumer.close()方法，或者是执行Kill命令</strong>，不论是Kill -2还是Kill -9；而Kafka自动关闭是由<strong>消费者端参数connection.max.idle.ms</strong>控制的，该参数现在的默认值是9分钟，即如果某个Socket连接上连续9分钟都没有任何请求“过境”的话，那么消费者会强行“杀掉”这个Socket连接。</p><p>不过，和生产者有些不同的是，如果在编写消费者程序时，你使用了循环的方式来调用poll方法消费消息，那么上面提到的所有请求都会被定期发送到Broker，因此这些Socket连接上总是能保证有请求在发送，从而也就实现了“长连接”的效果。</p><p>针对上面提到的三类TCP连接，你需要注意的是，<strong>当第三类TCP连接成功创建后，消费者程序就会废弃第一类TCP连接</strong>，之后在定期请求元数据时，它会改为使用第三类TCP连接。也就是说，最终你会发现，第一类TCP连接会在后台被默默地关闭掉。对一个运行了一段时间的消费者程序来说，只会有后面两类TCP连接存在。</p><h2>可能的问题</h2><p>从理论上说，Kafka Java消费者管理TCP资源的机制我已经说清楚了，但如果仔细推敲这里面的设计原理，还是会发现一些问题。</p><p>我们刚刚讲过，第一类TCP连接仅仅是为了首次获取元数据而创建的，后面就会被废弃掉。最根本的原因是，消费者在启动时还不知道Kafka集群的信息，只能使用一个“假”的ID去注册，即使消费者获取了真实的Broker ID，它依旧无法区分这个“假”ID对应的是哪台Broker，因此也就无法重用这个Socket连接，只能再重新创建一个新的连接。</p><p>为什么会出现这种情况呢？主要是因为目前Kafka仅仅使用ID这一个维度的数据来表征Socket连接信息。这点信息明显不足以确定连接的是哪台Broker，也许在未来，社区应该考虑使用<strong>&lt;主机名、端口、ID&gt;</strong>三元组的方式来定位Socket资源，这样或许能够让消费者程序少创建一些TCP连接。</p><p>也许你会问，反正Kafka有定时关闭机制，这算多大点事呢？其实，在实际场景中，我见过很多将connection.max.idle.ms设置成-1，即禁用定时关闭的案例，如果是这样的话，这些TCP连接将不会被定期清除，只会成为永久的“僵尸”连接。基于这个原因，社区应该考虑更好的解决方案。</p><h2>小结</h2><p>好了，今天我们补齐了Kafka Java客户端管理TCP连接的“拼图”。我们不仅详细描述了Java消费者是怎么创建和关闭TCP连接的，还对目前的设计方案提出了一些自己的思考。希望今后你能将这些知识应用到自己的业务场景中，并对实际生产环境中的Socket管理做到心中有数。</p><p><img src=\"https://static001.geekbang.org/resource/image/f1/04/f13d7008d7b251df0e6e6a89077d7604.jpg?wh=2069*2535\" alt=\"\"></p><h2>开放讨论</h2><p>假设有个Kafka集群由2台Broker组成，有个主题有5个分区，当一个消费该主题的消费者程序启动时，你认为该程序会创建多少个Socket连接？为什么？</p><p>欢迎写下你的思考和答案，我们一起讨论。如果你觉得有所收获，也欢迎把文章分享给你的朋友。</p>","neighbors":{"left":{"article_title":"20 | 多线程开发消费者实例","id":108512},"right":{"article_title":"22 | 消费者组消费进度监控都怎么实现？","id":109238}},"comments":[{"had_liked":false,"id":115400,"user_name":"常超","can_delete":false,"product_type":"c1","uid":1138665,"ip_address":"","ucode":"4AE7743B4ADF20","user_header":"https://static001.geekbang.org/account/avatar/00/11/5f/e9/95ef44f3.jpg","comment_is_top":false,"comment_ctime":1563576131,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"177657235267","product_id":100029201,"comment_content":"整个生命周期里会建立4个连接，进入稳定的消费过程后，同时保持3个连接，以下是详细。<br>第一类连接：确定协调者和获取集群元数据。 <br> 一个，初期的时候建立，当第三类连接建立起来之后，这个连接会被关闭。<br><br>第二类连接：连接协调者，令其执行组成员管理操作。<br> 一个<br><br>第三类连接：执行实际的消息获取。<br>两个分别会跟两台broker机器建立一个连接，总共两个TCP连接，同一个broker机器的不同分区可以复用一个socket。","like_count":42,"discussions":[{"author":{"id":1522220,"avatar":"https://static001.geekbang.org/account/avatar/00/17/3a/2c/683ae4af.jpg","nickname":"豆花羹","note":"","ucode":"57D8F64988C305","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":7261,"discussion_content":"整个生命周期也有可能是建立3个连接。\n当领导者副本都位于同一个broker上时，第三类连接只会建立一个。","likes_number":6,"is_delete":false,"is_hidden":false,"ctime":1567437682,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1096984,"avatar":"https://static001.geekbang.org/account/avatar/00/10/bd/18/2af6bf4b.jpg","nickname":"兔2🐰🍃","note":"","ucode":"1FEDA044BB6CBD","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":8601,"discussion_content":"只有2个 Broker，5个分区的领导者副本，由zookeeper分配Leader，所以默认是均匀的，故有4个TCP连接。","likes_number":5,"is_delete":false,"is_hidden":false,"ctime":1568023920,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":148378,"user_name":"注定非凡","can_delete":false,"product_type":"c1","uid":1113597,"ip_address":"","ucode":"80673056E131B7","user_header":"https://static001.geekbang.org/account/avatar/00/10/fd/fd/326be9bb.jpg","comment_is_top":false,"comment_ctime":1573000411,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"96062280923","product_id":100029201,"comment_content":"1，何时创建<br>\tA ：消费者和生产者不同，在创建KafkaConsumer实例时不会创建任何TCP连接。<br>\t\t原因：是因为生产者入口类KafkaProducer在构建实例时，会在后台启动一个Sender线程，这个线程是负责Socket连接创建的。<br><br>\tB ：TCP连接是在调用KafkaConsumer.poll方法时被创建。在poll方法内部有3个时机创建TCP连接<br>\t（1）发起findCoordinator请求时创建<br>\t\tCoordinator（协调者）消费者端主键，驻留在Broker端的内存中，负责消费者组的组成员管理和各个消费者的位移提交管理。<br>\t\t当消费者程序首次启动调用poll方法时，它需要向Kafka集群发送一个名为FindCoordinator的请求，确认哪个Broker是管理它的协调者。<br><br>\t（2）连接协调者时<br>\t\tBroker处理了消费者发来的FindCoordinator请求后，返回响应显式的告诉消费者哪个Broker是真正的协调者。<br>\t\t当消费者知晓真正的协调者后，会创建连向该Broker的socket连接。<br>\t\t只有成功连入协调者，协调者才能开启正常的组协调操作。<br><br>\t（3）消费数据时<br>\t\t消费者会为每个要消费的分区创建与该分区领导者副本所在的Broker连接的TCP.<br><br>2 创建多少<br>\t消费者程序会创建3类TCP连接：<br>\t（1） ：确定协调者和获取集群元数据<br>\t（2）：连接协调者，令其执行组成员管理操作<br>\t（3） ：执行实际的消息获取<br><br>3 何时关闭TCP连接<br>\tA ：和生产者相似，消费者关闭Socket也分为主动关闭和Kafka自动关闭。<br>\tB ：主动关闭指通过KafkaConsumer.close()方法，或者执行kill命令，显示地调用消费者API的方法去关闭消费者。<br>\tC ：自动关闭指消费者端参数connection.max.idle.ms控制的，默认为9分钟，即如果某个socket连接上连续9分钟都没有任何请求通过，那么消费者会强行杀死这个连接。<br>\tD ：若消费者程序中使用了循环的方式来调用poll方法消息消息，以上的请求都会被定期的发送到Broker，所以这些socket连接上总是能保证有请求在发送，从而实现“长连接”的效果。<br>\tE ：当第三类TCP连接成功创建后，消费者程序就会废弃第一类TCP连接，之后在定期请求元数据时，会改为使用第三类TCP连接。对于一个运行了一段时间的消费者程序来讲，只会有后面两种的TCP连接。<br>","like_count":22},{"had_liked":false,"id":163005,"user_name":"AAA_叶子","can_delete":false,"product_type":"c1","uid":1325994,"ip_address":"","ucode":"1E93617D308EE0","user_header":"https://static001.geekbang.org/account/avatar/00/14/3b/aa/e8dfcd7e.jpg","comment_is_top":false,"comment_ctime":1576639203,"is_pvip":false,"replies":[{"id":"62105","content":"嗯，如果就是要长时间的消费，维持一个长连接是不错的选择","user_name":"作者回复","comment_id":163005,"uid":"1288090","ip_address":"","utype":1,"ctime":1576717360,"user_name_real":"huxi_2b"}],"discussion_count":3,"race_medal":0,"score":"91770952419","product_id":100029201,"comment_content":"消费者tcp连接一旦断开，就会导致rebalance，实际开发过程中，是不是需要尽量保证长连接的模式？","like_count":21,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":478211,"discussion_content":"嗯，如果就是要长时间的消费，维持一个长连接是不错的选择","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1576717360,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1339409,"avatar":"https://static001.geekbang.org/account/avatar/00/14/70/11/42cf8f9d.jpg","nickname":"chenjia","note":"","ucode":"61983C29FF4987","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":367245,"discussion_content":"维持2个，并交替使用，岂不美哉？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618305030,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1339409,"avatar":"https://static001.geekbang.org/account/avatar/00/14/70/11/42cf8f9d.jpg","nickname":"chenjia","note":"","ucode":"61983C29FF4987","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":367244,"discussion_content":"维持多个岂不是更加安全？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618305008,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":116200,"user_name":"taj3991","can_delete":false,"product_type":"c1","uid":1161307,"ip_address":"","ucode":"0CC37B928EB49E","user_header":"https://static001.geekbang.org/account/avatar/00/11/b8/5b/dbe74486.jpg","comment_is_top":false,"comment_ctime":1563801238,"is_pvip":false,"replies":[{"id":"42576","content":"是的。每个group都有一个与之对应的coordinator","user_name":"作者回复","comment_id":116200,"uid":"1288090","ip_address":"","utype":1,"ctime":1563849643,"user_name_real":"huxi_2b"}],"discussion_count":1,"race_medal":0,"score":"70283277974","product_id":100029201,"comment_content":"老师同一个消费组的客户端都只会连接到一个协调者吗？","like_count":16,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":459430,"discussion_content":"是的。每个group都有一个与之对应的coordinator","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563849643,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":115849,"user_name":"Williamzhang","can_delete":false,"product_type":"c1","uid":1148759,"ip_address":"","ucode":"C016AE5DE39F4E","user_header":"https://static001.geekbang.org/account/avatar/00/11/87/57/e28ba87b.jpg","comment_is_top":false,"comment_ctime":1563757543,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"48808397799","product_id":100029201,"comment_content":"我觉得作者可以跟学员的留言互动，然后每期课后思考可以在下期中贴出答案及分析，其实留言讨论也是一个非常让人有收获的地方","like_count":12,"discussions":[{"author":{"id":1339409,"avatar":"https://static001.geekbang.org/account/avatar/00/14/70/11/42cf8f9d.jpg","nickname":"chenjia","note":"","ucode":"61983C29FF4987","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":367246,"discussion_content":"留言更多的是沟通，沟通是最有效的学习方式，可以查漏补缺","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1618305106,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1488243,"avatar":"https://static001.geekbang.org/account/avatar/00/16/b5/73/15a8006a.jpg","nickname":"goxdev","note":"","ucode":"7374587CD08BEE","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":393962,"discussion_content":"留言区更像是宝藏区 学到更多😄","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631672586,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":188802,"user_name":"Geek_ab3d9a","can_delete":false,"product_type":"c1","uid":1550553,"ip_address":"","ucode":"1AFEE5FA59D470","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eol8MiawYVfCtkaFL9DFGoWpuajsKicwyt7IWm07JfrLMDuksEZJqia4Rbicw0biayokhgvSK0rUXIAngQ/132","comment_is_top":false,"comment_ctime":1584417843,"is_pvip":false,"replies":[{"id":"72974","content":"每个客户端至少主机名和端口是不一样的，我是指在TCP连接这个层面。另外对于producer而言，其实Kafka也不用区分它们，反正知道它们都再向集群发送消息就行了。对于consumer而言，主要还是看group.id的设置以确定它们是否在同一个group。最后如果是你想区分客户端，那么可以设置不同的client.id","user_name":"作者回复","comment_id":188802,"uid":"1288090","ip_address":"","utype":1,"ctime":1584491610,"user_name_real":"huxi_2b"}],"discussion_count":1,"race_medal":0,"score":"31649188915","product_id":100029201,"comment_content":"老师您好，请问k8s这样的容器平台，适合部署kafka的消费者吗？如果容器平台起了二个一模一样的消费者，对kafka来说会不会不知道自己通信的哪一个消费者?  kafka通过什么来判断不同的客户端?","like_count":7,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":487532,"discussion_content":"每个客户端至少主机名和端口是不一样的，我是指在TCP连接这个层面。另外对于producer而言，其实Kafka也不用区分它们，反正知道它们都再向集群发送消息就行了。对于consumer而言，主要还是看group.id的设置以确定它们是否在同一个group。最后如果是你想区分客户端，那么可以设置不同的client.id","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1584491610,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":134501,"user_name":"天天向上","can_delete":false,"product_type":"c1","uid":1031113,"ip_address":"","ucode":"5948D359734193","user_header":"https://static001.geekbang.org/account/avatar/00/0f/bb/c9/37924ad4.jpg","comment_is_top":false,"comment_ctime":1568856390,"is_pvip":false,"replies":[{"id":"51670","content":"不包括，因为你请求元数据的broker可能不是Coordinator，没有Coordinator的信息","user_name":"作者回复","comment_id":134501,"uid":"1288090","ip_address":"","utype":1,"ctime":1568901429,"user_name_real":"huxi_2b"}],"discussion_count":1,"race_medal":0,"score":"27338660166","product_id":100029201,"comment_content":"元数据不包含协调者信息吗？为啥还要再请求一次协调者信息 什么设计思路？","like_count":6,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":467776,"discussion_content":"不包括，因为你请求元数据的broker可能不是Coordinator，没有Coordinator的信息","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1568901429,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":116746,"user_name":"信信","can_delete":false,"product_type":"c1","uid":1303865,"ip_address":"","ucode":"8DF0EC045579FD","user_header":"https://static001.geekbang.org/account/avatar/00/13/e5/39/951f89c8.jpg","comment_is_top":false,"comment_ctime":1563900443,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"27333704219","product_id":100029201,"comment_content":"一共建过四次连接。若connection.max.idle.ms 不为-1，最终会断开第一次连的ID为-1的连接。","like_count":6},{"had_liked":false,"id":115626,"user_name":"October","can_delete":false,"product_type":"c1","uid":1137879,"ip_address":"","ucode":"CEDA78F4A5F8B1","user_header":"https://static001.geekbang.org/account/avatar/00/11/5c/d7/e4673fde.jpg","comment_is_top":false,"comment_ctime":1563677848,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"27333481624","product_id":100029201,"comment_content":"总共创建4个连接，最终保持3个连接：<br>        确定消费者所属的消费组对应的GroupCoordinator和获取集群的metadata时创建一个TCP连接，由于此时的node id = -1，所以该连接无法重用。<br>        连接GroupCoordinator时，创建第二个TCP连接，node id值为Integer.MAX_VALUE-id<br>        消费者会与每个分区的leader创建一个TCP连接来消费数据，node id为broker.id，由于kafka只是用id这一维度来表征Socket连接信息，因此如果多个分区的leader在同一个broker上时，会共用一个TCP连接，由于分区数大于broker的数量，所以会创建两个TCP连接消费数据。","like_count":6},{"had_liked":false,"id":210791,"user_name":"真锅","can_delete":false,"product_type":"c1","uid":1141547,"ip_address":"","ucode":"D36634359B0BD6","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eqxnw92EOgZbyHDGMZ1d1OFDjjJKnBdmpiac8J7kBEN5h3AvvzU85mo5Chj8pkIHQc390dL1mu0neQ/132","comment_is_top":false,"comment_ctime":1587825812,"is_pvip":false,"replies":[{"id":"78457","content":"这个数字不是固定的，而是用MAX - broker ID算出来的。对Coordinator的连接来说，是的！ 它的ID就是这个算法","user_name":"作者回复","comment_id":210791,"uid":"1288090","ip_address":"","utype":1,"ctime":1587865652,"user_name_real":"胡夕"}],"discussion_count":1,"race_medal":0,"score":"18767694996","product_id":100029201,"comment_content":"意思是即便知道了协调者在node 2上，还是会依然用2147483645这个id的TCP连接去跟协调者通信吗。","like_count":4,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493109,"discussion_content":"这个数字不是固定的，而是用MAX - broker ID算出来的。对Coordinator的连接来说，是的！ 它的ID就是这个算法","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587865652,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":173179,"user_name":"Eco","can_delete":false,"product_type":"c1","uid":1373230,"ip_address":"","ucode":"5459B494753183","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/x86UN2kFbJGGwiaw7yeVtyaf05y5eZmdOciaAF09WEBRVicbPGsej1b62UAH3icjeJqvibVc6aqB0EuFwDicicKKcF47w/132","comment_is_top":false,"comment_ctime":1579448135,"is_pvip":false,"replies":[{"id":"67156","content":"目前与Coordinator和普通数据交互的TCP连接的确是分开的，你要说是否能复用，我觉得当然可以复用，只不过现在没有这么设计：）","user_name":"作者回复","comment_id":173179,"uid":"1288090","ip_address":"","utype":1,"ctime":1579481854,"user_name_real":"huxi_2b"}],"discussion_count":2,"race_medal":0,"score":"18759317319","product_id":100029201,"comment_content":"应该是3个tcp连接，第一个id=-1的没什么争议，然后是连接协调者的，但是broker，5个分区的leader肯定会分布到这两台broker上，那么第三类tcp就是2个tcp连接，但是这2个中完全可以有一个是直接使用连接协调者的那个tcp连接吧，但老师好像说过连接协调者的连接会和传输数据的分开，id的计算都不相同，好吧，那就4个tcp连接吧。可这里真的不能复用吗？我觉得可以。","like_count":4,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":481990,"discussion_content":"目前与Coordinator和普通数据交互的TCP连接的确是分开的，你要说是否能复用，我觉得当然可以复用，只不过现在没有这么设计：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1579481854,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1373230,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/x86UN2kFbJGGwiaw7yeVtyaf05y5eZmdOciaAF09WEBRVicbPGsej1b62UAH3icjeJqvibVc6aqB0EuFwDicicKKcF47w/132","nickname":"Eco","note":"","ucode":"5459B494753183","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":142709,"discussion_content":"好吧~_~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1579481994,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":115805,"user_name":"小木匠","can_delete":false,"product_type":"c1","uid":1055610,"ip_address":"","ucode":"222F861CF9129C","user_header":"https://static001.geekbang.org/account/avatar/00/10/1b/7a/390a8530.jpg","comment_is_top":false,"comment_ctime":1563752631,"is_pvip":false,"replies":[{"id":"42575","content":"刚开始的时候当然就类似于随机选broker了，但后面慢慢积累了一些数据之后这个小优化还是会起一些作用的","user_name":"作者回复","comment_id":115805,"uid":"1288090","ip_address":"","utype":1,"ctime":1563849596,"user_name_real":"huxi_2b"}],"discussion_count":1,"race_medal":0,"score":"18743621815","product_id":100029201,"comment_content":"“负载是如何评估的呢？其实很简单，就是看消费者连接的所有 Broker 中，谁的待发送请求最少。”  <br>老师这个没太明白，这时候消费者不是还没连接么？那这部分信息是从哪获取到的呢？消费者本地吗？","like_count":4,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":459295,"discussion_content":"刚开始的时候当然就类似于随机选broker了，但后面慢慢积累了一些数据之后这个小优化还是会起一些作用的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563849596,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":228361,"user_name":"yes","can_delete":false,"product_type":"c1","uid":1386201,"ip_address":"","ucode":"612BF6884ED6CC","user_header":"https://static001.geekbang.org/account/avatar/00/15/26/d9/f7e96590.jpg","comment_is_top":false,"comment_ctime":1592648167,"is_pvip":false,"replies":[{"id":"84194","content":"它首先倾向于使用已建立连接的节点。如果已建立连接的节点都在使用中，可能会创建新的TCP连接","user_name":"作者回复","comment_id":228361,"uid":"1288090","ip_address":"","utype":1,"ctime":1592662804,"user_name_real":"胡夕"}],"discussion_count":2,"race_medal":0,"score":"14477550055","product_id":100029201,"comment_content":"老师我有个疑问，consumer在FindCoordinator的时候会选择负载最小的broker进行连接，文章说看消费者连接的所有 Broker 中，谁的待发送请求最少。请问consumer如何得知这个消息？如果它想知道这个消息，不就得先和“某个东西”建立连接了？","like_count":3,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":499008,"discussion_content":"它首先倾向于使用已建立连接的节点。如果已建立连接的节点都在使用中，可能会创建新的TCP连接","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1592662804,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1141254,"avatar":"https://static001.geekbang.org/account/avatar/00/11/6a/06/66831563.jpg","nickname":"阡陌","note":"","ucode":"58634836C8E03F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":295307,"discussion_content":"难道说已建立的连接中存在未使用的连接的话，首先选择的是未使用的连接中负载最小的？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1596161432,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":218792,"user_name":"Treagzhao","can_delete":false,"product_type":"c1","uid":1109643,"ip_address":"","ucode":"906C3A7F33040C","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eqKurYDna034zK0ibDIWicybibQhiaM6afgla2zVFqBrAemLgCh3WoibjACnic5ibiaYMd29tMB26cjaGaPoA/132","comment_is_top":false,"comment_ctime":1589876107,"is_pvip":false,"replies":[{"id":"80947","content":"是这样判断的，就是看消费者与broker的TCP连接上的待处理请求的个数","user_name":"作者回复","comment_id":218792,"uid":"1288090","ip_address":"","utype":1,"ctime":1589942860,"user_name_real":"胡夕"}],"discussion_count":1,"race_medal":0,"score":"10179810699","product_id":100029201,"comment_content":"老师，“消费者程序会向集群中当前负载最小的那台 Broker 发送请求”，消费者怎么单方面知道服务器待发送的消息数量呢？而且应该只有leader才会实际发送消息吧，follower待发送的都是0,消费者怎么在建立连接之前就知道服务器的角色呢？","like_count":2,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":495575,"discussion_content":"是这样判断的，就是看消费者与broker的TCP连接上的待处理请求的个数","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589942860,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":129265,"user_name":"臧萌","can_delete":false,"product_type":"c1","uid":1008692,"ip_address":"","ucode":"5505C1516EDFD5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/64/34/03335c4a.jpg","comment_is_top":false,"comment_ctime":1567073830,"is_pvip":false,"replies":[{"id":"48162","content":"和它要订阅的topic分区数以及这些分区在broker上的散列情况有关。比如你订阅了100个分区，但这个100个分区的leader副本都在一个broker上，那么长期来看consumer也就只和这1个broker建立连接；相反如果这100分区散列在100个broker上，那么长期来看consumer会和100个broker维持长连接","user_name":"作者回复","comment_id":129265,"uid":"1288090","ip_address":"","utype":1,"ctime":1567125672,"user_name_real":"huxi_2b"}],"discussion_count":2,"race_medal":0,"score":"10157008422","product_id":100029201,"comment_content":"我们要设计一个消息系统。有两个选择，更好的一种是每种不同schema的消息发一个topic。但是有一种担心是consumer会为每个topic建立一个连接，造成连接数太多。请问胡老师，kafka client的consumer是每个集群固定数目的tcp连接，还是和topic数目相关？","like_count":2,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":465370,"discussion_content":"和它要订阅的topic分区数以及这些分区在broker上的散列情况有关。比如你订阅了100个分区，但这个100个分区的leader副本都在一个broker上，那么长期来看consumer也就只和这1个broker建立连接；相反如果这100分区散列在100个broker上，那么长期来看consumer会和100个broker维持长连接","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567125672,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1008692,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/64/34/03335c4a.jpg","nickname":"臧萌","note":"","ucode":"5505C1516EDFD5","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":6804,"discussion_content":"相同的partition分布，tcp连接数会和这些partition属于多少个topic有关吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567127076,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":115696,"user_name":"rm -rf 😊ི","can_delete":false,"product_type":"c1","uid":1070908,"ip_address":"","ucode":"BC448EC4206D95","user_header":"https://static001.geekbang.org/account/avatar/00/10/57/3c/081b89ec.jpg","comment_is_top":false,"comment_ctime":1563700099,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10153634691","product_id":100029201,"comment_content":"我认为也是3个连接，第一个是查找Coordinator的，这个会在后面断开。然后5个partition会分布在2个broker上，那么客户端最多也就连接2次就能消费所有partition了，因此是连接3个，最后保持2个。","like_count":2},{"had_liked":false,"id":237867,"user_name":"艺超(鲁鸣)","can_delete":false,"product_type":"c1","uid":1029436,"ip_address":"","ucode":"7F749FA543E0F1","user_header":"https://static001.geekbang.org/account/avatar/00/0f/b5/3c/967d7291.jpg","comment_is_top":false,"comment_ctime":1595989429,"is_pvip":false,"replies":[{"id":"87879","content":"其实也没什么管理。如果一定要说管理，通过KafkaChannel对象来管理。","user_name":"作者回复","comment_id":237867,"uid":"1288090","ip_address":"","utype":1,"ctime":1596005105,"user_name_real":"胡夕"}],"discussion_count":2,"race_medal":0,"score":"5890956725","product_id":100029201,"comment_content":"老师好，请教一个问题，现在对于producer和consumer都介绍了维持tcp连接的情况，那么对于kafka集群 broker来说，这么多的tcp连接，是如何管理的呢？","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":502571,"discussion_content":"其实也没什么管理。如果一定要说管理，通过KafkaChannel对象来管理。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1596005105,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1029436,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b5/3c/967d7291.jpg","nickname":"艺超(鲁鸣)","note":"","ucode":"7F749FA543E0F1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":294956,"discussion_content":"谢谢老师，那么单和节点管理那么多的链接，会有性能的问题吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1596036777,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":138063,"user_name":"举个荔枝","can_delete":false,"product_type":"c1","uid":1168195,"ip_address":"","ucode":"7F6B8EC3A3E0E1","user_header":"https://static001.geekbang.org/account/avatar/00/11/d3/43/f22b39c3.jpg","comment_is_top":false,"comment_ctime":1570004896,"is_pvip":false,"replies":[{"id":"53468","content":"嗯嗯，其实这里的消费者端指的是广义的消费者，我是想说在Kafka消费者的概念中有Coordinator。当然如你所说Coordinator是Broker端的组件没错。这里的确有不严谨的地方，多谢指出：）","user_name":"作者回复","comment_id":138063,"uid":"1288090","ip_address":"","utype":1,"ctime":1570495568,"user_name_real":"huxi_2b"}],"discussion_count":1,"race_medal":0,"score":"5864972192","product_id":100029201,"comment_content":"老师，想问下这里是不是笔误。<br>还记得消费者端有个组件叫Coordinator吗？协调者应该是位于Broker端的吧？","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":469369,"discussion_content":"嗯嗯，其实这里的消费者端指的是广义的消费者，我是想说在Kafka消费者的概念中有Coordinator。当然如你所说Coordinator是Broker端的组件没错。这里的确有不严谨的地方，多谢指出：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570495568,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":115888,"user_name":"吴宇晨","can_delete":false,"product_type":"c1","uid":1199968,"ip_address":"","ucode":"F8F45B7067DF6D","user_header":"https://static001.geekbang.org/account/avatar/00/12/4f/60/049a20e9.jpg","comment_is_top":false,"comment_ctime":1563762187,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5858729483","product_id":100029201,"comment_content":"一个获取元数据的连接（之后会断开）+两个连接分区leader的连接+一个连接协调者的连接","like_count":1},{"had_liked":false,"id":115421,"user_name":"明翼","can_delete":false,"product_type":"c1","uid":1068361,"ip_address":"","ucode":"E77F86BEB3D5C1","user_header":"https://static001.geekbang.org/account/avatar/00/10/4d/49/28e73b9c.jpg","comment_is_top":false,"comment_ctime":1563586144,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5858553440","product_id":100029201,"comment_content":"连接有三个阶段：首先获取协调者连接同时也获取元数据信息，这个连接后面会关闭；连接协调者执行，等待分配分区，组协调等，这需要一个连接；后面真正消费五个分区两个broker最多就两个连接，分区大于broker所以一定是两个，因为第一类连接没有id，所以无法重用，会在第三类开启连接后关闭，所以开始四个连接最终保持三个连接","like_count":1},{"had_liked":false,"id":115393,"user_name":"nightmare","can_delete":false,"product_type":"c1","uid":1056314,"ip_address":"","ucode":"EF2E51C2122A86","user_header":"https://static001.geekbang.org/account/avatar/00/10/1e/3a/5b21c01c.jpg","comment_is_top":false,"comment_ctime":1563555218,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5858522514","product_id":100029201,"comment_content":"3个tcp连接  一个查询协调着和获取元数据的tcp连接    一个连接协调写 管理组成员的tcp连接    主题5个分区只有连接leader副本的broker需要创建连接","like_count":1},{"had_liked":false,"id":351162,"user_name":"ppd0705","can_delete":false,"product_type":"c1","uid":1155646,"ip_address":"","ucode":"EB63D4E3FD1E9A","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKotsBr2icbYNYlRSlicGUD1H7lulSTQUAiclsEz9gnG5kCW9qeDwdYtlRMXic3V6sj9UrfKLPJnQojag/132","comment_is_top":false,"comment_ctime":1657584985,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1657584985","product_id":100029201,"comment_content":"请问一下如果消费多个主题，那么同一个Broker不同主题的分区消息是共用连接还是单独的？简而言之，第三类连接是broker级别还是主题级别的？","like_count":0},{"had_liked":false,"id":330032,"user_name":"爱学习的小学生","can_delete":false,"product_type":"c1","uid":1413556,"ip_address":"","ucode":"040AB71F0394F2","user_header":"https://static001.geekbang.org/account/avatar/00/15/91/b4/d5d9e4fb.jpg","comment_is_top":false,"comment_ctime":1641740467,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1641740467","product_id":100029201,"comment_content":"kafka的close wait过多导致broker超时这个有啥优化么","like_count":0},{"had_liked":false,"id":314071,"user_name":"凯文小猪","can_delete":false,"product_type":"c1","uid":1980201,"ip_address":"","ucode":"36D8AD0229547F","user_header":"https://static001.geekbang.org/account/avatar/00/1e/37/29/b3af57a7.jpg","comment_is_top":false,"comment_ctime":1632824140,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1632824140","product_id":100029201,"comment_content":"consumer的poll其实就是个long polling这样理解我感觉就清楚了","like_count":0},{"had_liked":false,"id":285565,"user_name":"Allan","can_delete":false,"product_type":"c1","uid":1310388,"ip_address":"","ucode":"8DA4DBECC2C45C","user_header":"https://static001.geekbang.org/account/avatar/00/13/fe/b4/295338e7.jpg","comment_is_top":false,"comment_ctime":1616900561,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1616900561","product_id":100029201,"comment_content":"第一个链接寻找协调器，第二个链接链接协调器进行管理，因为有两台broker索引需要创建两个实际消费数据用的链接。总共四个链接。","like_count":0},{"had_liked":false,"id":268257,"user_name":"hpfish","can_delete":false,"product_type":"c1","uid":1217377,"ip_address":"","ucode":"86DB066E5B6D89","user_header":"https://static001.geekbang.org/account/avatar/00/12/93/61/3e4607c7.jpg","comment_is_top":false,"comment_ctime":1608115106,"is_pvip":false,"replies":[{"id":"97588","content":"有办法通过域名访问吗?","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1608516445,"ip_address":"","comment_id":268257,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1608115106","product_id":100029201,"comment_content":"老师，我的kafka部在k8s上，版本是2.1.1，消费者通过serviceName+port的方式去访问，但是kafka重启后Pod的IP变了，消费者连得还是原来的IP有什么办法吗","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":511888,"discussion_content":"有办法通过域名访问吗?","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1608516445,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":261795,"user_name":"crud~boy","can_delete":false,"product_type":"c1","uid":2083659,"ip_address":"","ucode":"4DD62B9BA480D3","user_header":"","comment_is_top":false,"comment_ctime":1605526866,"is_pvip":false,"replies":[{"id":"95344","content":"通过监测进程和端口号也可以判断吧。","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1605838655,"ip_address":"","comment_id":261795,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1605526866","product_id":100029201,"comment_content":"老师我们有这样一个场景，我们需要监测kafka是否存活，然后有一个程序没隔1s就通过tcp连接kafka，然后断开！这样会不会把kakfa连接资源耗尽了啊","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509612,"discussion_content":"通过监测进程和端口号也可以判断吧。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605838655,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2083659,"avatar":"","nickname":"crud~boy","note":"","ucode":"4DD62B9BA480D3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":326140,"discussion_content":"现在看日志报错，open too many files，每隔几天kafka就报错了！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605530770,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":214184,"user_name":"石栖","can_delete":false,"product_type":"c1","uid":1496443,"ip_address":"","ucode":"35600F645A479F","user_header":"https://static001.geekbang.org/account/avatar/00/16/d5/7b/c512da6a.jpg","comment_is_top":false,"comment_ctime":1588672051,"is_pvip":false,"replies":[{"id":"79343","content":"看着很眼熟，应该是2.3已经修复的bug。你的客户端也升级到2.3版本了吗？","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1588725462,"ip_address":"","comment_id":214184,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1588672051","product_id":100029201,"comment_content":"胡老师，您好。我这边用的kafka 2.3 。Consumer一直出现这个错误信息在日志里面：2020-05-05 07:31:06.428  INFO 6 --- [ntainer#1-0-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-4, groupId=test-collections] Node 1 was unable to process the fetch request with (sessionId=2065156504, epoch=1204): FETCH_SESSION_ID_NOT_FOUND. 但是我看log是INFO级别的，请问是不是可以忽略掉？网上说需要修改broker的max.incremental.fetch.session.cache.slots，有其他办法吗？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493977,"discussion_content":"看着很眼熟，应该是2.3已经修复的bug。你的客户端也升级到2.3版本了吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588725462,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1496443,"avatar":"https://static001.geekbang.org/account/avatar/00/16/d5/7b/c512da6a.jpg","nickname":"石栖","note":"","ucode":"35600F645A479F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":258991,"discussion_content":"我用的是Spring-kafka 2.2.3，然后kafka-clients 2.3.1","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588748863,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":172952,"user_name":"成立-Charlie","can_delete":false,"product_type":"c1","uid":1091556,"ip_address":"","ucode":"2970BB5446B70A","user_header":"https://static001.geekbang.org/account/avatar/00/10/a7/e4/5a4515e9.jpg","comment_is_top":false,"comment_ctime":1579391914,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1579391914","product_id":100029201,"comment_content":"4个","like_count":0},{"had_liked":false,"id":159902,"user_name":"大鸡腿","can_delete":false,"product_type":"c1","uid":1502174,"ip_address":"","ucode":"A93E0598D68252","user_header":"https://static001.geekbang.org/account/avatar/00/16/eb/de/087611a3.jpg","comment_is_top":false,"comment_ctime":1575821680,"is_pvip":false,"replies":[{"id":"61047","content":"会有的，只是暂时还不知道ID","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1575851820,"ip_address":"","comment_id":159902,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1575821680","product_id":100029201,"comment_content":"胡大佬，问下 &quot;它连接的 Broker 节点的 ID 是 -1，表示消费者根本不知道要连接的 Kafka Broker 的任何信息。&quot; 这边会有真实的broker机器与之对应嘛？ ","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":477204,"discussion_content":"会有的，只是暂时还不知道ID","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1575851820,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":132109,"user_name":"兔2🐰🍃","can_delete":false,"product_type":"c1","uid":1096984,"ip_address":"","ucode":"1FEDA044BB6CBD","user_header":"https://static001.geekbang.org/account/avatar/00/10/bd/18/2af6bf4b.jpg","comment_is_top":false,"comment_ctime":1568023986,"is_pvip":false,"replies":[{"id":"50563","content":"如果是不考虑机架信息，你基本上可以认为是round robin策略","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1568077774,"ip_address":"","comment_id":132109,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1568023986","product_id":100029201,"comment_content":"有2个 Broker，5个分区的领导者副本，由zookeeper分配Leader，所以默认是均匀的，第三类会创建2个TCP连接，故共有4个TCP连接。<br>请问胡老师 Leader副本 分配策略是什么？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":466771,"discussion_content":"如果是不考虑机架信息，你基本上可以认为是round robin策略","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1568077774,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":119894,"user_name":"落霞与孤鹜","can_delete":false,"product_type":"c1","uid":1111004,"ip_address":"","ucode":"1F06EB86DD2E6B","user_header":"https://static001.geekbang.org/account/avatar/00/10/f3/dc/e7e5c159.jpg","comment_is_top":false,"comment_ctime":1564721961,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1564721961","product_id":100029201,"comment_content":"最终会保留三个吧，协调者链接需要与其他链接特地分开。","like_count":0},{"had_liked":false,"id":116523,"user_name":"Hello world","can_delete":false,"product_type":"c1","uid":1333607,"ip_address":"","ucode":"4D2EF3034571B7","user_header":"https://static001.geekbang.org/account/avatar/00/14/59/67/f4ba1da4.jpg","comment_is_top":false,"comment_ctime":1563863469,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1563863469","product_id":100029201,"comment_content":"老师，如果是调用consumer.createMessageStreams()这个方法，那这样也是建立min(broker数，分区leader数)+1个tcp连接吗？还有建立一个连接会启动一个线程的吧，我看了我的java进程下有几十个线程,但是好像也远远大于broker的数量。","like_count":0,"discussions":[{"author":{"id":1956764,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/db/9c/f4116338.jpg","nickname":"CG","note":"","ucode":"4A2121D219DC14","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":293578,"discussion_content":"老师您好，在poll数据阶段，如果10个分区，分布在10个broker上，consumer会建立10个socket连接，想问下consumer是并发的从这10个socket中取数据吗，还是串行的去取","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1595586142,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":115830,"user_name":"30斤的大番薯","can_delete":false,"product_type":"c1","uid":1564545,"ip_address":"","ucode":"1C85FEE30B1CF2","user_header":"https://static001.geekbang.org/account/avatar/00/17/df/81/756f7a87.jpg","comment_is_top":false,"comment_ctime":1563755652,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1563755652","product_id":100029201,"comment_content":"老师您好。我之前搭建了一个单机kafka，能正常收发消息。最近我按网上的介绍，把kafka改成集群，出现一个问题：使用kafka自带的命令行生产者工具可以成功发送消息。但是用命令行消费者工具总是接收不到数据（启动消费者一直不输出数据，仿佛没收到消息一样）。我用strace跟踪发现消费者进程一在循环进行epoll（超时）调用，kafka服务器日志无异常。请问这种情况要怎么检查问题。","like_count":0,"discussions":[{"author":{"id":1246493,"avatar":"https://static001.geekbang.org/account/avatar/00/13/05/1d/018804ad.jpg","nickname":"抛物线","note":"","ucode":"46BD27D7BA8CE3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":3189,"discussion_content":"我之前好像遇到了和你一样的问题，最后是因为我启动消费者的时候，配的broken server有问题，需要主机名加ip，你可以启动一个Java消费者程序，debug一下，看能不能获取到集群元数据，我上次解决就是这样发现问题的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1564286483,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":115533,"user_name":"杨陆伟","can_delete":false,"product_type":"c1","uid":1108457,"ip_address":"","ucode":"3BC968447406EB","user_header":"https://static001.geekbang.org/account/avatar/00/10/e9/e9/1f95e422.jpg","comment_is_top":false,"comment_ctime":1563613650,"is_pvip":true,"discussion_count":1,"race_medal":0,"score":"1563613650","product_id":100029201,"comment_content":"我觉得是3个TCP连接，查找协调者1个连接，连接两个Broker2个连接，且查找协调者的连接慢慢会关闭","like_count":0,"discussions":[{"author":{"id":1034204,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/c7/dc/9408c8c2.jpg","nickname":"ban","note":"","ucode":"E523CE97E48266","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":2445,"discussion_content":"连接协调者的连接也算一个吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563628602,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":115381,"user_name":"空知","can_delete":false,"product_type":"c1","uid":1013283,"ip_address":"","ucode":"C448E98238DD36","user_header":"https://static001.geekbang.org/account/avatar/00/0f/76/23/31e5e984.jpg","comment_is_top":false,"comment_ctime":1563548161,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1563548161","product_id":100029201,"comment_content":"同一个broker 一个topic下的分区可以复用一个连接 但是topic的不同分区的 leader 不一定都在一个broker上 也就是消费时候 只有一个broker上的tcp连接起作用","like_count":0}]}