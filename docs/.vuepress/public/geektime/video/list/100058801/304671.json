{"id":304671,"title":"55｜Querying Dynamic  Tables","content":"<p><strong>课件和Demo地址</strong><br>\n<a href=\"https://gitee.com/geektime-geekbang/geektime-Flink\">https://gitee.com/geektime-geekbang/geektime-Flink</a></p>","comments":[{"had_liked":false,"id":259369,"user_name":"鬼谷阳明","can_delete":false,"product_type":"c3","uid":1183950,"ip_address":"","ucode":"DBAB611CEB9C75","user_header":"https://static001.geekbang.org/account/avatar/00/12/10/ce/fd941b1a.jpg","comment_is_top":false,"comment_ctime":1604714457,"is_pvip":false,"replies":[{"id":94933,"content":"效果能达到就行","user_name":"作者回复","user_name_real":"张利兵","uid":1119779,"ctime":1605457107,"ip_address":"","comment_id":259369,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100058801,"comment_content":"插图真的非常萌","like_count":2,"discussions":[{"author":{"id":1119779,"avatar":"https://static001.geekbang.org/account/avatar/00/11/16/23/99c7ede5.jpg","nickname":"张利兵","note":"","ucode":"DBAE17970AB143","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":508917,"discussion_content":"效果能达到就行","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605457107,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":327738,"user_name":"hujihu33","can_delete":false,"product_type":"c3","uid":1078729,"ip_address":"","ucode":"686860FE2DFABB","user_header":"https://static001.geekbang.org/account/avatar/00/10/75/c9/fb23007c.jpg","comment_is_top":false,"comment_ctime":1640259263,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100058801,"comment_content":"视频主要内容：\n\n1,基于Stream上实现关系查询\n   1),流是一个无限元组序列\n   2),流式查询在启动时不能访问所有数据，必须&#39;等待&#39;数据流入\n   3),流处理不断的根据接收到的记录更新其结果，并且始终不会结束\n2，物化视图\n   有点像\n3，动态表 &amp; 连续查询\n   概念：相对于静态表来说，动态表时随着时间变化的\n   基于动态查询\n      1)，查询动态表将生成一个连续查询\n\t  2)，一个连续查询永远不会终止，结果会生成一个动态表\n\t  3), 查询不断更新其结果表，以反映其输入表上的更改\n\t  4), 动态表上的连续查询非常类似与查询物化视图\n\t  5), 连续查询的语义上总是等价于以批处理模式在输入表快照上执行的相同查询的结果\n   DataStream 和 dynamic table 支持相互转化\n    stream -&gt; dynamic table -&gt; continuous query -&gt; dynamic table -&gt; stream\n4，基于stream 上定义 dynamic table\n5，dynamic table 是否支持任何查询\n   1)，状态结果不会无限制的增长，容易引发系统内存资源不足，因此必须定义State Clean-up timeout\n   2)，输入数据只能触发结果表的部分计算逻辑\n6，状态大小查询限制\n   1，需要划定一下时间范围。\n7，Update Results 查询限制\n   有些查询需要重新计算和更新大量已输出的结果行\n8，dynamic table 和 datastream的转换 \n   a stream is the changelog of a dynamic table\n   different changelog interpretations\n    1), append-only change messages\n    2), upsert change messages\n    3), add&#47;retract change messages\n9, \tdynamic table-&gt; stream  : insert\n     append-only 流：仅通过insert 操作修改的动态表可以通过输出插入的行转换为流\n\t  insert 的 sink  可以是 mysql, hdfs, es , s3, kafka\n10 ,\tdynamic table-&gt; stream  : insert+delete\n     retract流：retract流包含两种类型的message: add messages 和 retract messages\n     retract 的sink 有  mysql es ， gp \t \n11 ,\tdynamic table-&gt; stream  : upsert+delete","like_count":3},{"had_liked":false,"id":312094,"user_name":"小乙哥","can_delete":false,"product_type":"c3","uid":1063308,"ip_address":"","ucode":"C77E79BEA0C325","user_header":"https://static001.geekbang.org/account/avatar/00/10/39/8c/ff48ece3.jpg","comment_is_top":false,"comment_ctime":1631620530,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100058801,"comment_content":"upsert流为什么还需要配合delete，我理解只有upsert就可以了，没有插入，有更新。什么情况下会触发delete操作了？望老师解答一下","like_count":0},{"had_liked":false,"id":265063,"user_name":"Ki","can_delete":false,"product_type":"c3","uid":1470477,"ip_address":"","ucode":"5B675CC101FFC0","user_header":"https://static001.geekbang.org/account/avatar/00/16/70/0d/f4c7a01f.jpg","comment_is_top":false,"comment_ctime":1606748032,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100058801,"comment_content":"我们生产刚好有rank计算，取最新一条订单数据做聚合计算，如何只保留近三天的状态呢，现在我们状态很大","like_count":0},{"had_liked":false,"id":265062,"user_name":"Ki","can_delete":false,"product_type":"c3","uid":1470477,"ip_address":"","ucode":"5B675CC101FFC0","user_header":"https://static001.geekbang.org/account/avatar/00/16/70/0d/f4c7a01f.jpg","comment_is_top":false,"comment_ctime":1606747964,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100058801,"comment_content":"我们生产刚好就有rank这种计算，取当天最新一条订单做聚合。这种场景怎么处理状态呢","like_count":0},{"had_liked":false,"id":264029,"user_name":"geek","can_delete":false,"product_type":"c3","uid":1234974,"ip_address":"","ucode":"BF9406F6ABDB7B","user_header":"https://static001.geekbang.org/account/avatar/00/12/d8/1e/985d5363.jpg","comment_is_top":false,"comment_ctime":1606315223,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100058801,"comment_content":"老师好，请问下，连续查询然后直接将结果写入mysql，可能大部分数据都需要先delete再insert，数据量多的话会造成数据库压力过大，实践中有什么优化方法吗？","like_count":0}]}