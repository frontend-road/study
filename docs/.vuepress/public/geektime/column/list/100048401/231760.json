{"id":231760,"title":"16 | 最近邻检索（下）：如何用乘积量化实现“拍照识花”功能？","content":"<p>你好，我是陈东。</p><p>随着AI技术的快速发展，以图搜图、拍图识物已经是许多平台上的常见功能了。比如说，在搜索引擎中，我们可以直接上传图片进行反向搜索。在购物平台中，我们可以直接拍照进行商品搜索。包括在一些其他的应用中，我们还能拍照识别植物品种等等。这些功能都依赖于高效的图片检索技术，那它究竟是怎么实现的呢？今天，我们就来聊一聊这个问题。</p><h2>聚类算法和局部敏感哈希的区别？</h2><p>检索图片和检索文章一样，我们首先需要用向量空间模型将图片表示出来，也就是将一个图片对象转化为高维空间中的一个点。这样图片检索问题就又变成了我们熟悉的高维空间的相似检索问题。</p><p>如果我们把每个图片中的像素点看作一个维度，把像素点的RGB值作为该维度上的值，那一张图片的维度会是百万级别的。这么高的维度，检索起来会非常复杂，我们该怎么处理呢？我们可以像提取文章关键词一样，对图片进行特征提取来压缩维度。</p><p>要想实现图片特征提取，我们有很多种深度学习的方法可以选择。比如，使用卷积神经网络（CNN）提取图片特征。这样，用一个512到1024维度的向量空间模型，我们就可以很好地描述图像了，但这依然是一个非常高的维度空间。因此，我们仍然需要使用一些近似最邻近检索技术来加速检索过程。</p><!-- [[[read_end]]] --><p>一种常用的近似最邻近检索方法，是使用局部敏感哈希对高维数据进行降维处理，将高维空间的点划到有限的区域中。这样，通过判断要查询的点所在的区域，我们就能快速取出这个区域的所有候选集了。</p><p>不过，在上一讲中我们也提到，局部敏感哈希由于哈希函数构造相对比较简单，往往更适合计算字面上的相似性（表面特征的相似性），而不是语义上的相似性（本质上的相似性）。这怎么理解呢？举个例子，即便是面对同一种花，不同的人在不同的地点拍出来的照片，在角度、背景、花的形状上也会有比较大的差异。也就是说，这两张图片的表面特征其实差异很大，这让我们没办法利用局部敏感哈希，来合理评估它们的相似度。</p><p>而且，局部敏感哈希其实是一种粒度很粗的非精准检索方案。以SimHash为例，它能将上百万的高维空间压缩到64位的比特位中，这自然也会损失不少的精确性。<br>\n<img src=\"https://static001.geekbang.org/resource/image/3d/c6/3d30166fba8d4af8917e53fa4a4d3ac6.jpg?wh=814*375\" alt=\"\" title=\"表面特征差异很大的同一种花的对比示意图\"></p><p>因此，更常见的一种方案，是使用聚类算法来划分空间。和简单的局部敏感哈希算法相比，聚类算法能将空间中的点更灵活地划分成多个类，并且保留了向量的高维度，使得我们可以更准确地计算向量间的距离。好的聚类算法要保证类内的点足够接近，不同类之间的距离足够大。一种常见的聚类算法是K-means算法（K-平均算法）。<br>\n<img src=\"https://static001.geekbang.org/resource/image/0c/b5/0c9793222bb1a062d7135a88914ae2b5.jpg?wh=1920*824\" alt=\"\" title=\"局部敏感哈希空间划分 VS 聚类空间划分\"></p><p>K-means聚类算法的思想其实很“朴素”，它将所有的点划分为k个类，每个类都有一个<strong>类中心向量</strong>。在构建聚类的时候，我们希望每个类内的点都是紧密靠近类中心的。用严谨的数学语言来说，K-means聚类算法的优化目标是，<strong>类内的点到类中心的距离均值总和最短</strong>。因此，K-means聚类算法具体的计算步骤如下:</p><ol>\n<li>随机选择k个节点，作为初始的k个聚类的中心；</li>\n<li>针对所有的节点，计算它们和k个聚类中心的距离，将节点归入离它最近的类中；</li>\n<li>针对k个类，统计每个类内节点的向量均值，作为每个类的新的中心向量；</li>\n<li>重复第2步和第3步，<strong>重新计算每个节点和新的类中心的距离，将节点再次划分到最近的类中，然后再更新类的中心节点向量</strong>。经过多次迭代，直到节点分类不再变化，或者迭代次数达到上限，我们停止算法。<br>\n<img src=\"https://static001.geekbang.org/resource/image/81/4f/8115bc2286b78f9e65f2a2fdb4faef4f.jpeg?wh=1920*1080\" alt=\"\" title=\"K-means 算法计算流程图\"></li>\n</ol><p>以上，就是K-means聚类算法的计算过程了，那使用聚类算法代替了局部敏感哈希以后，我们该怎么进行相似检索呢？</p><h2>如何使用聚类算法进行相似检索？</h2><p>首先，对于所有的数据，我们先用聚类算法将它们划分到不同的类中。在具体操作之前，我们会给聚类的个数设定一个目标。假设聚类的个数是1024个，那所有的点就会被分到这1024个类中。这样，我们就可以用每个聚类的ID作为Key，来建立倒排索引了。</p><p>建立好索引之后，当要查询一个点邻近的点时，我们直接计算该点和所有聚类中心的距离，将离查询点最近的聚类作为该点所属的聚类。因此，以该聚类的ID为Key去倒排索引中查询，我们就可以取出所有该聚类中的节点列表了。然后，我们遍历整个节点列表，计算每个点和查询点的距离，取出Top K个结果进行返回。</p><p>这个过程中会有两种常见情况出现。第一种，最近的聚类中的节点数非常多。这个时候，我们就计算该聚类中的所有节点和查询点的距离，这个代价会很大。这该怎么优化呢？这时，我们可以参考二分查找算法不断划分子空间划分的思路，使用层次聚类将一个聚类中的节点，再次划分成多个聚类。这样，在该聚类中查找相近的点时，我们通过继续判断查询点和哪个子聚类更相近，就能快速减少检索空间，从而提升检索效率了。<br>\n<img src=\"https://static001.geekbang.org/resource/image/b6/15/b69ff3fcaa5a8f1ad192f1714ae43215.jpg?wh=1920*836\" alt=\"\" title=\"层次聚类检索过程示意图\"></p><p>第二种，该聚类中的候选集不足Top K个，或者我们担心聚类算法的相似判断不够精准，导致最近的聚类中的结果不够好。那我们还可以再去查询次邻近的聚类，将这些聚类中的候选集取出，计算每个点和查询点的距离，补全最近的Top K个点。</p><h2>如何使用乘积量化压缩向量？</h2><p>对于向量的相似检索，除了检索算法本身以外，如何优化存储空间也是我们必须要关注的一个技术问题。以1024维的向量为例，因为每个向量维度值是一个浮点数（浮点数就是小数，一个浮点数有4个字节），所以一个向量就有4K个字节。如果是上亿级别的数据，光是存储向量就需要几百G的内存，这会导致向量检索难以在内存中完成检索。</p><p>因此，为了能更好地将向量加载到内存中，我们需要压缩向量的表示。比如说，我们可以用聚类中心的向量代替聚类中的每个向量。这样，一个类内的点都可以用这个类的ID来代替和存储，我们也就节省了存储每个向量的空间开销。那计算查询向量和原始样本向量距离的过程，也就可以改为计算查询向量和对应聚类中心向量的距离了。<br>\n<img src=\"https://static001.geekbang.org/resource/image/e3/5a/e364eb5c372b58192b88b029842de05a.jpg?wh=1920*861\" alt=\"\" title=\"用聚类中心代替样本点\"></p><p>想要压缩向量，我们往往会使用<strong>向量量化</strong>（Vector Quantization）技术。其中，我们最常用的是<strong>乘积量化</strong>（Product Quantization）技术。</p><p>乍一看，你会觉得乘积量化是个非常晦涩难懂的概念，但它其实并没有那么复杂。接下来，我就把它拆分成乘积和量化这两个概念，来为你详细解释一下。</p><p><strong>量化指的就是将一个空间划分为多个区域，然后为每个区域编码标识</strong>。比如说，一个二维空间&lt;x,y&gt;可以被划为两块，那我们只需要1个比特位就能分别为这两个区域编码了，它们的空间编码分别是0和1。那对二维空间中的任意一个点来说，它要么属于区域0，要么属于区域1。</p><p>这样，我们就可以用1个比特位的0或1编码，来代替任意一个点的二维空间坐标&lt;x,y&gt;了 。假设x和y是两个浮点数，各4个字节，那它们一共是8个字节。如果我们将8个字节的坐标用1个比特位来表示，就能达到压缩存储空间的目的了。前面我们说的用聚类ID代替具体的向量来进行压缩，也是同样的原理。</p><p>而<strong>乘积指的是高维空间可以看作是由多个低维空间相乘得到的</strong>。我们还是以二维空间&lt;x,y&gt;为例，它就是由两个一维空间<x>和<y>相乘得到。类似的还有，三维空间&lt;x,y,z&gt;是由一个二维空间&lt;x,y&gt;和一个一维空间<z>相乘得到，依此类推。</z></y></x></p><p>那将高维空间分解成多个低维空间的乘积有什么好处呢？它能降低数据的存储量。比如说，二维空间是由一维的x轴和y轴相乘得到。x轴上有4个点x1到x4，y轴上有4个点y1到y4，这四个点的交叉乘积，会在二维空间形成16个点。但是，如果我们仅存储一维空间中，x轴和y轴的各4个点，一共只需要存储8个一维的点，这会比存储16个二维的点更节省空间。</p><p>总结来说，对向量进行乘积量化，其实就是将向量的高维空间看成是多个子空间的乘积，然后针对每个子空间，再用聚类技术分成多个区域。最后，给每个区域生成一个唯一编码，也就是聚类ID。</p><p>好了，乘积量化压缩向量的原理我们已经知道了。接下来，我们就通过一个例子来说说，乘积量化压缩样本向量的具体操作过程。</p><p>如果我们的样本向量都是1024维的浮点数向量，那我们可以将它分为4段，这样每一段就都是一个256维的浮点向量。然后，在每一段的256维的空间里，我们用聚类算法将这256维空间再划分为256个聚类。接着，我们可以用1至256作为ID，来为这256个聚类中心编号。这样，我们就得到了256 * 4 共1024个聚类中心，每个聚类中心都是一个256维的浮点数向量（256 * 4字节 = 1024字节）。最后，我们将这1024个聚类中心向量都存储下来。<br>\n<img src=\"https://static001.geekbang.org/resource/image/20/c6/204ab74bf747ee1308454fb1ff91f3c6.jpg?wh=1920*1027\" alt=\"\" title=\"记录256*4个聚类向量中心示意图\"></p><p>这样，对于这个空间中的每个向量，我们就不需要再精确记录它在每一维上的权重了。我们只需要将每个向量都分为四段，让<strong>每段子向量都根据聚类算法找到所属的聚类，然后用它所属聚类的ID来表示这段子向量</strong>就可以了。</p><p>因为聚类ID是从1到256的，所以我们只需要8个比特位就可以表示这个聚类ID了。由于完整的样本向量有四段，因此我们用4个聚类ID就可以表示一个完整的样本向量了，也就一共只需要32个比特位。因此，一个1024维的原始浮点数向量（共1024 * 4 字节）使用乘积量化压缩后，存储空间变为了32个比特位，空间使用只有原来的1/1024。存储空间被大幅降低之后，所有的样本向量就有可能都被加载到内存中了。<br>\n<img src=\"https://static001.geekbang.org/resource/image/f1/12/f1e2e8a56fb4ca40de8bc0cfeb514c12.jpg?wh=1954*755\" alt=\"\" title=\"压缩前后向量的存储空间对比图\"></p><h2>如何计算查询向量和压缩样本向量的距离（相似性）？</h2><p>这样，我们就得到了一个压缩后的样本向量，它是一个32个比特位的向量。这个时候，如果要我们查询一个新向量和样本向量之间的距离，也就是它们之间的相似性，我们该怎么做呢？这里我要强调一下，一般来说，要查询的新向量都是一个未被压缩过的向量。也就是说在我们的例子中，它是一个1024维的浮点向量。</p><p>好了，明确了这一点之后，我们接着来说一下计算过程。这整个计算过程会涉及3个主要向量，分别是<strong>样本向量</strong>、<strong>查询向量</strong>以及<strong>聚类中心向量</strong>。你在理解这个过程的时候，要注意分清楚它们。</p><p>那接下来，我们一起来看一下具体的计算过程。</p><p>首先，我们在对所有样本点生成聚类时，需要记录下<strong>聚类中心向量</strong>的向量值，作为后面计算距离的依据。由于1024维向量会分成4段，每段有256个聚类。因此，我们共需要存储1024个聚类中所有中心向量的数据。</p><p>然后，对于<strong>查询向量</strong>，我们也将它分为4段，每段也是一个256维的向量。对于查询向量的每一段子向量，我们要分别计算它和之前存储的对应的256个聚类中心向量的距离，并用一张距离表存下来。由于有4段，因此一共有4个距离表。<br>\n<img src=\"https://static001.geekbang.org/resource/image/e6/dd/e67d8f8adc92486a250b5781b9e015dd.jpg?wh=1920*879\" alt=\"\" title=\"计算查询向量和聚类中心向量的距离表过程示意图\"></p><p>当计算查询向量和样本向量的距离时，我们将查询向量和样本向量都分为4段子空间。然后分别计算出每段子空间中，查询子向量和样本子向量的距离。这时，我们可以用聚类中心向量代替样本子向量。这样，求查询子向量和样本子向量的距离，就转换为求查询子向量和对应的聚类中心向量的距离。那我们只需要将样本子向量的聚类ID作为key去查距离表，就能在O(1)的时间代价内知道这个距离了。<br>\n<img src=\"https://static001.geekbang.org/resource/image/74/d9/749af0780fdd1d7ac8f3641095ed70d9.jpg?wh=1920*979\" alt=\"\" title=\"获得全部查询子向量和样本子向量近似距离的过程示意图\"></p><p>最后，我们将得到的四段距离按欧氏距离的方式计算，合并起来，即可得到查询向量和样本向量的距离，距离计算公式：<br>\n<img src=\"https://static001.geekbang.org/resource/image/64/1a/644e03d03748728edff3332f39e82a1a.jpg?wh=1920*467\" alt=\"\"></p><p>以上，就是计算查询向量和样本向量之间距离的过程了。你会看到，原本两个高维向量的复杂的距离计算，被4次O(1)时间代价的查表操作代替之后，就变成了常数级的时间代价。因此，在对压缩后的样本向量进行相似查找的时候，我们即便是使用遍历的方式进行计算，时间代价也会减少许多。</p><p>而计算查询向量到每个聚类中心的距离，我们也只需要在查询开始的时候计算一次，就可以生成1024个距离表，在后面对比每个样本向量时，这个对比表就可以反复使用了。</p><h2>如何对乘积量化进行倒排索引？</h2><p>尽管使用乘积量化的方案，我们已经可以用很低的代价来遍历所有的样本向量，计算每个样本向量和查询向量的距离了。但是我们依然希望能用更高效的检索技术代替遍历，来提高检索效率。因此，结合前面的知识，我们可以将聚类、乘积量化和倒排索引综合使用，让整体检索更高效。下面，我就来具体说说，在建立索引和查询这两个过程中，它们是怎么综合使用的。</p><p>首先，我们来说建立索引的过程，我把它总结为3步。</p><ol>\n<li>使用K-means聚类，将所有的样本向量分为1024个聚类，以聚类ID为Key建立倒排索引。</li>\n<li>对于每个聚类中的样本向量，计算它们和聚类中心的差值，得到新的向量。你也可以认为这是以聚类中心作为原点重新建立向量空间，然后更新该聚类中的每个样本向量。</li>\n<li>使用乘积量化的方式，压缩存储每个聚类中新的样本向量。<br>\n<img src=\"https://static001.geekbang.org/resource/image/ba/d3/ba2da0119e3e53448e31c5824433d0d3.jpg?wh=1920*995\" alt=\"\" title=\"一个样本向量加入倒排索引的过程示意图\"></li>\n</ol><p>建好索引之后，我们再来说说查询的过程，它也可以总结为3步。</p><ol>\n<li>当查询向量到来时，先计算它离哪个聚类中心最近，然后查找倒排表，取出该聚类中所有的向量。</li>\n<li>计算查询向量和聚类中心的差值，得到新的查询向量。</li>\n<li>对新的查询向量，使用乘积量化的距离计算法，来遍历该聚类中的所有压缩样本向量，取出最近的k个结果返回。<br>\n<img src=\"https://static001.geekbang.org/resource/image/75/b2/75fbb780bbbc5d412f660bb76fc717b2.jpg?wh=1920*983\" alt=\"\" title=\"查询向量查询倒排索引的过程示意图\"></li>\n</ol><p>这样，我们就同时结合了聚类、乘积量化和倒排索引的检索技术，使得我们能在压缩向量节省存储空间的同时，也通过快速减少检索空间的方式，提高了检索效率。通过这样的组合技术，我们能解决大量的图片检索问题。比如说，以图搜图、拍照识物，人脸识别等等。</p><p>实际上，除了图像检索领域，在文章推荐、商品推荐等推荐领域中，我们也都可以用类似的检索技术，来快速返回大量的结果。尤其是随着AI技术的发展，越来越多的对象需要用特征向量来表示。所以，针对这些对象的检索问题，其实都会转换为高维空间的近似检索问题，那我们今天讲的内容就完全可以派上用场了。</p><h2>重点回顾</h2><p>今天，我们学习了在高维向量空间中实现近似最邻近检索的方法。相对于局部敏感哈希，使用聚类技术能实现更灵活的分类能力，并且聚类技术还支持层次聚类，它能更快速地划分检索空间。</p><p>此外，对于高维的向量检索，如何优化存储空间也是我们需要考虑的一个问题。这个时候，可以使用乘积量化的方法来压缩样本向量，让我们能在内存中运行向量检索的算法。</p><p>那为了进一步提高检索率和优化存储空间，我们还能将聚类技术、乘积量化和倒排索引技术结合使用。这也是目前图像检索和文章推荐等领域中，非常重要的设计思想和实现方案。<br>\n<img src=\"https://static001.geekbang.org/resource/image/0b/c3/0bc88d22a8ae6ac44e4a7e5180c7ebc3.jpg?wh=2391*2038\" alt=\"\" title=\"知识总结\"></p><h2>课堂讨论</h2><p>1.为什么使用聚类中心向量来代替聚类中的样本向量，我们就可以达到节省存储空间的目的？</p><p>2.如果二维空间中有16个点，它们是由x轴的1、2、3、4四个点，以及y轴的1、2、3、4四个点两两相乘组合成的。那么，对于二维空间中的这16个样本点，如果使用乘积量化的思路，你会怎么进行压缩存储？当我们新增了一个点(17,17)时，它的查询过程又是怎么样的？</p><p>欢迎在留言区畅所欲言，说出你的思考过程和最终答案。如果有收获，也欢迎把这一讲分享给你的朋友。</p>","neighbors":{"left":{"article_title":"15 | 最近邻检索（上）：如何用局部敏感哈希快速过滤相似文章？","id":230686},"right":{"article_title":"特别加餐 | 高性能检索系统中的设计漫谈","id":232420}},"comments":[{"had_liked":false,"id":213507,"user_name":"wcf","can_delete":false,"product_type":"c1","uid":1829111,"ip_address":"","ucode":"6E3B0A47B963E7","user_header":"https://static001.geekbang.org/account/avatar/00/1b/e8/f7/1b45fa46.jpg","comment_is_top":false,"comment_ctime":1588436495,"is_pvip":false,"replies":[{"id":79169,"content":"首先，你举的这个例子不叫“乘积”，而只是将16个(x，y)分别存成16个(x)和16个(y)，这样的确是没有省空间的。\n然后，我文中的点，其实代表的是“聚类中心向量”，而不是“样本向量”。接下来我来和你一起分析一下。\n如果二维空间按格子划分区域，一共有16个区域，那么我们就需要16个编号(相当于生成16个聚类，每个聚类要记录自己的中心向量，有16个二维的中心向量)。但如果我们把二维空间分解为x轴和y轴，那么x轴只需要4个编号，y轴只需要4个编号。这样我们只需要4+4个编号既可以表示完整的二维空间了(相当于将向量分为两个子空间，每个子空间生成4个聚类，每个聚类需要记录自己的中心向量，这样就有8个一维的中心向量)\n那么，记录8个一维的中心向量比记录16个二维的中心向量省空间。空间是省在了这里，而不是省在样本向量上。\n对于每个样本向量，之前的二维空间编号是1－16，需要4个比特位，分解后的两个一维空间编号是(1－4)*(1－4)，也是需要4个比特位。因此，样本向量的存储，无论是个数，还是压缩后需要用到比特位，都是无法节省的。\n总结一下，乘积的好处，其实是可以降低我们要存储的中心向量的个数和维度，而不是降低样本向量的个数。如果样本向量原来有n个，那么乘积量化后依然有n个。我文中举的“点”的例子，结合后面的内容看，你就会发现它代表的是聚类中心向量，而不是样本向量。我想这可能就是让你觉得疑惑的地方，希望这个分析可以解答你的疑惑。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1588479164,"ip_address":"","comment_id":213507,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"对于乘积法省空间的说法有点疑问.老师在文章里的说法确实能看出节省了空间,但是这里面临的问题是:给定16个二维空间的点,使用(x,y)的存储方法,会比分别存储x和y的方法更省空间吗?假如这16个点的x值分布在16个值上,y值也分布在16个值上,那两种方法都需要32个浮点数表示啊?怎么就能省空间呢?","like_count":9},{"had_liked":false,"id":213053,"user_name":"每天晒白牙","can_delete":false,"product_type":"c1","uid":1004698,"ip_address":"","ucode":"A1B102CD933DEA","user_header":"https://static001.geekbang.org/account/avatar/00/0f/54/9a/76c0af70.jpg","comment_is_top":false,"comment_ctime":1588290186,"is_pvip":false,"replies":[{"id":79090,"content":"实话实说，这一讲的内容的确很难。即使是我自己当年学这些内容的时候，也琢磨了好久。而且这一部分的内容和AI结合较紧密，也是随着这几年AI的大面积铺开才开始变得重要起来的，之前大部分工程师可能并不熟悉。因此，多看几遍，有不懂的地方一起讨论分析，相信你会有收获的。\n为什么进阶篇最后一篇讲了这样一个内容呢，你会发现，我们的应用场景都在进化，现在搜索引擎已经支持图片搜索了，电商平台也支持拍照购物，还有人脸识别等应用，对应起来，我们的检索技术，已经需要从文本关键词检索，升级到图片检索，视频检索等更复杂的空间中了。\n包括现在的广告系统，其实各种智能匹配，都可以看着是向量匹配，而不仅仅是传统的关键词倒排检索。\n我希望我们都能跟着时代的潮流，提升自己的认知和竞争力。\n由于专栏篇幅有限，因此多少会有一些知识没有展开介绍。不过，你可以把这个专栏的内容当做一个索引，然后对于自己感兴趣的部分去深入学习了解。有不清楚的地方，也欢迎讨论和交流。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1588299318,"ip_address":"","comment_id":213053,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"老师讲的是真好，只是学生我底子差，越到后面的文章越看不太懂了，很吃力\n\n也许这就是因为门槛高了，才使得做算法和 AI 的同学工资高\n\n想想从小学开始一直到大学(甚至有些读到了研究生和博士)，也都是从简单开始学起，最开始的 1+1=2，看不出学生有多大差别，但后面四则混合运算，再到各种三角函数，大学的微积分等等吧\n\n越到后面学习门槛越高，大家的差距也逐渐拉开","like_count":5,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493800,"discussion_content":"首先，你举的这个例子不叫“乘积”，而只是将16个(x，y)分别存成16个(x)和16个(y)，这样的确是没有省空间的。\n然后，我文中的点，其实代表的是“聚类中心向量”，而不是“样本向量”。接下来我来和你一起分析一下。\n如果二维空间按格子划分区域，一共有16个区域，那么我们就需要16个编号(相当于生成16个聚类，每个聚类要记录自己的中心向量，有16个二维的中心向量)。但如果我们把二维空间分解为x轴和y轴，那么x轴只需要4个编号，y轴只需要4个编号。这样我们只需要4+4个编号既可以表示完整的二维空间了(相当于将向量分为两个子空间，每个子空间生成4个聚类，每个聚类需要记录自己的中心向量，这样就有8个一维的中心向量)\n那么，记录8个一维的中心向量比记录16个二维的中心向量省空间。空间是省在了这里，而不是省在样本向量上。\n对于每个样本向量，之前的二维空间编号是1－16，需要4个比特位，分解后的两个一维空间编号是(1－4)*(1－4)，也是需要4个比特位。因此，样本向量的存储，无论是个数，还是压缩后需要用到比特位，都是无法节省的。\n总结一下，乘积的好处，其实是可以降低我们要存储的中心向量的个数和维度，而不是降低样本向量的个数。如果样本向量原来有n个，那么乘积量化后依然有n个。我文中举的“点”的例子，结合后面的内容看，你就会发现它代表的是聚类中心向量，而不是样本向量。我想这可能就是让你觉得疑惑的地方，希望这个分析可以解答你的疑惑。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1588479164,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":213124,"user_name":"范闲","can_delete":false,"product_type":"c1","uid":1073125,"ip_address":"","ucode":"F21FD7DF6BA53C","user_header":"https://static001.geekbang.org/account/avatar/00/10/5f/e5/54325854.jpg","comment_is_top":false,"comment_ctime":1588307453,"is_pvip":false,"replies":[{"id":79094,"content":"你去看了乘积量化的论文，这一点非常好。原始的论文肯定会描述得更详细，有更多的内容，当然，也会更难懂。不过从你的描述来看，你很好地提炼出了乘积量化算法的核心，相信你对它已经理解得很清楚了。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1588310967,"ip_address":"","comment_id":213124,"utype":1}],"discussion_count":6,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"今天上午刚刚看了乘积量化的论文。乘积量化实际上是建立在一个D维向量由M个子向量组成的假设上。子向量的维度就是K=D&#47;M. 而M代表着码本的数量，码本实际上就是对子向量进行kmeans运算得到的聚类中心。另外在乘积量化过程中，还有个PQcode，实际上存储的子向量属于哪一个码本。\n\n在向量搜索过程中，向量直接和码本运算得到距离表，然后再同PQcode求和就能得到距离了。\n\n但是如果你的向量的数据集的数目N是亿级别的，就会导致你的向量搜索的速度下降。\n\n而倒排向量实际是为了解决这个问题而产生的。先对N个向量聚类，产生1024（这部分可以改变的）个中心，然后会得到N个向量和聚类中心的残差，再对残差进行乘积量化的步骤即可。\n","like_count":4,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493678,"discussion_content":"实话实说，这一讲的内容的确很难。即使是我自己当年学这些内容的时候，也琢磨了好久。而且这一部分的内容和AI结合较紧密，也是随着这几年AI的大面积铺开才开始变得重要起来的，之前大部分工程师可能并不熟悉。因此，多看几遍，有不懂的地方一起讨论分析，相信你会有收获的。\n为什么进阶篇最后一篇讲了这样一个内容呢，你会发现，我们的应用场景都在进化，现在搜索引擎已经支持图片搜索了，电商平台也支持拍照购物，还有人脸识别等应用，对应起来，我们的检索技术，已经需要从文本关键词检索，升级到图片检索，视频检索等更复杂的空间中了。\n包括现在的广告系统，其实各种智能匹配，都可以看着是向量匹配，而不仅仅是传统的关键词倒排检索。\n我希望我们都能跟着时代的潮流，提升自己的认知和竞争力。\n由于专栏篇幅有限，因此多少会有一些知识没有展开介绍。不过，你可以把这个专栏的内容当做一个索引，然后对于自己感兴趣的部分去深入学习了解。有不清楚的地方，也欢迎讨论和交流。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588299318,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":249965,"user_name":"piboye","can_delete":false,"product_type":"c1","uid":1066752,"ip_address":"","ucode":"7CFD8712857A85","user_header":"https://static001.geekbang.org/account/avatar/00/10/47/00/3202bdf0.jpg","comment_is_top":false,"comment_ctime":1600868450,"is_pvip":true,"replies":[{"id":91847,"content":"这可以说是最难的一章了。但是如果理解好了，你就能吃透向量检索的核心。而向量检索是近期结合深度学习浪潮的热门检索技术，在许多大公司中都开始采用了。建议可以耐心点慢慢多看几遍，相信会理解越来越深刻的。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1601391171,"ip_address":"","comment_id":249965,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"好难啊","like_count":1,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493687,"discussion_content":"你去看了乘积量化的论文，这一点非常好。原始的论文肯定会描述得更详细，有更多的内容，当然，也会更难懂。不过从你的描述来看，你很好地提炼出了乘积量化算法的核心，相信你对它已经理解得很清楚了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588310967,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1159442,"avatar":"https://static001.geekbang.org/account/avatar/00/11/b1/12/46e601ba.jpg","nickname":"Kevin2468","note":"","ucode":"6A138CCD3BF280","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":313212,"discussion_content":"为什么要对残差乘积量化？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1603002836,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":4,"child_discussions":[{"author":{"id":1073125,"avatar":"https://static001.geekbang.org/account/avatar/00/10/5f/e5/54325854.jpg","nickname":"范闲","note":"","ucode":"F21FD7DF6BA53C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1159442,"avatar":"https://static001.geekbang.org/account/avatar/00/11/b1/12/46e601ba.jpg","nickname":"Kevin2468","note":"","ucode":"6A138CCD3BF280","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":314374,"discussion_content":"对残差量化实际上就是重新做一次乘积量化。\n在没有倒排的时候，只有乘积量化。\n在有倒排的时候，只需要根据向量和聚类中心点的差做量化就可以。因为倒排的时候你是根据聚类中心找到哪些向量集可能和搜索向量最近。和聚类中心比较完以后，搜索向量-聚类中心就是剩余的残差部分。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1603153870,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":313212,"ip_address":"","group_id":0},"score":314374,"extra":""},{"author":{"id":1311128,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJ5WmAmuxTzKoln814dKIAia1KTUcgSSYzYgDIphlbv5dQpCuxrfRqodtXGMh7QtVUexCZE3CfYAgg/132","nickname":"尹小白","note":"","ucode":"AA726C8FB04454","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1073125,"avatar":"https://static001.geekbang.org/account/avatar/00/10/5f/e5/54325854.jpg","nickname":"范闲","note":"","ucode":"F21FD7DF6BA53C","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":533970,"discussion_content":"似乎还是没说清楚为什么要对残差做乘积量化，不太理解为什么要计算残差重建向量空间呢（原始向量转换），这一步是必须的么？我理解不计算残差只用原始向量应该也是可以的？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1638042431,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":314374,"ip_address":"","group_id":0},"score":533970,"extra":""},{"author":{"id":1311128,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJ5WmAmuxTzKoln814dKIAia1KTUcgSSYzYgDIphlbv5dQpCuxrfRqodtXGMh7QtVUexCZE3CfYAgg/132","nickname":"尹小白","note":"","ucode":"AA726C8FB04454","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1159442,"avatar":"https://static001.geekbang.org/account/avatar/00/11/b1/12/46e601ba.jpg","nickname":"Kevin2468","note":"","ucode":"6A138CCD3BF280","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":533971,"discussion_content":"大佬解了这个问题了么","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1638042461,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":313212,"ip_address":"","group_id":0},"score":533971,"extra":""}]}]},{"had_liked":false,"id":213233,"user_name":"那时刻","can_delete":false,"product_type":"c1","uid":1150927,"ip_address":"","ucode":"B0D150856C3A4A","user_header":"https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg","comment_is_top":false,"comment_ctime":1588338029,"is_pvip":false,"replies":[{"id":79114,"content":"今天的内容的确会比较难，知识点也比较多，所以总结部分有一个思维导图，希望能帮你更好地吸收。\n关于思考题:\n1. 压缩的根源，是在于我们可以用1个类的中心向量来代替类内所有的n个样本向量。用你熟悉的数据库分表来做例子，分析如下:\n原来的向量存储是这样的:\n样本向量表结构:[样本向量ID | 向量数据]\n每个向量数据都是一个高维向量，会很占空间。\n但用聚类中心向量代替样本向量以后，我们会有两张表:\n聚类中心表结构:[聚类ID | 聚类中心向量数据]\n样本向量表结构:[样本向量ID | 聚类ID]\n你会发现，和原先的相比，我们加了一个聚类中心表，由于聚类不多，因此这个表不会太大。而原来的样本向量表，它存的数据从“向量数据”变成了“聚类ID”，从而不用存储具体的向量(可以用聚类ID关联到聚类中心表)，因此表空间得到压缩。\n2.是的，这题是希望你能更好地理解乘积量化的思想，并不一定要求要严格按照每个流程做。我们可以分为xy轴两个维度(这样就是乘积了)。不过由于数据太少，所以也不需要用聚类，比如你把x轴等分2段也可以。然后每段编上号(这样就是量化了)。\n然后查询时，你分别和x轴和y轴比，找到对应的区域就好。\n","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1588348622,"ip_address":"","comment_id":213233,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"非常感谢老师这一节内容，收获不少。对于高维度的向量进行乘积量化，颇类似于数据库里对于数据分表操作，分散存储和提高查询速度。\n\n尝试回答一下讨论问题\n1. 使用聚类中心向量来代替聚类中的样本向量，其一，这样不需要存储每个聚类里样本向量，只需要存储他们和中心向量的差值，乘积量化后减少存储，其二，查询时候，只需要比较这个中心向量，减少比较次数，提高查询效率。\n2.二维空间的点，可以按照x，y轴两个维度分别进行聚类，然后乘积量化来压缩存储。查询过程可以按照老师文章讲述的过程来查询。","like_count":1,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":506078,"discussion_content":"这可以说是最难的一章了。但是如果理解好了，你就能吃透向量检索的核心。而向量检索是近期结合深度学习浪潮的热门检索技术，在许多大公司中都开始采用了。建议可以耐心点慢慢多看几遍，相信会理解越来越深刻的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1601391171,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":275886,"user_name":"易企秀-郭彦超","can_delete":false,"product_type":"c1","uid":2343516,"ip_address":"","ucode":"2E25574FAB1B3B","user_header":"https://static001.geekbang.org/account/avatar/00/23/c2/5c/791d0f5e.jpg","comment_is_top":false,"comment_ctime":1611712382,"is_pvip":false,"replies":[{"id":102770,"content":"在本文的例子中，样本向量指的就是图片向量，分为1024个聚类，指的是将每个图片分到1024个聚类中的某一个。(图片向量维度可以很高，大于1024)","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1615713110,"ip_address":"","comment_id":275886,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"老师 倒排乘机量化中，使用k-means将样本向量分为1024个聚类 ，这里的样本向量指的是图片向量吗，意思是将高维图片向量压缩为1024维图片向量吗，还是每张图片被划分到1024个聚类中的某一个","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493718,"discussion_content":"今天的内容的确会比较难，知识点也比较多，所以总结部分有一个思维导图，希望能帮你更好地吸收。\n关于思考题:\n1. 压缩的根源，是在于我们可以用1个类的中心向量来代替类内所有的n个样本向量。用你熟悉的数据库分表来做例子，分析如下:\n原来的向量存储是这样的:\n样本向量表结构:[样本向量ID | 向量数据]\n每个向量数据都是一个高维向量，会很占空间。\n但用聚类中心向量代替样本向量以后，我们会有两张表:\n聚类中心表结构:[聚类ID | 聚类中心向量数据]\n样本向量表结构:[样本向量ID | 聚类ID]\n你会发现，和原先的相比，我们加了一个聚类中心表，由于聚类不多，因此这个表不会太大。而原来的样本向量表，它存的数据从“向量数据”变成了“聚类ID”，从而不用存储具体的向量(可以用聚类ID关联到聚类中心表)，因此表空间得到压缩。\n2.是的，这题是希望你能更好地理解乘积量化的思想，并不一定要求要严格按照每个流程做。我们可以分为xy轴两个维度(这样就是乘积了)。不过由于数据太少，所以也不需要用聚类，比如你把x轴等分2段也可以。然后每段编上号(这样就是量化了)。\n然后查询时，你分别和x轴和y轴比，找到对应的区域就好。\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588348622,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":224403,"user_name":"范闲","can_delete":false,"product_type":"c1","uid":1073125,"ip_address":"","ucode":"F21FD7DF6BA53C","user_header":"https://static001.geekbang.org/account/avatar/00/10/5f/e5/54325854.jpg","comment_is_top":false,"comment_ctime":1591369911,"is_pvip":false,"replies":[{"id":82595,"content":"对的。你可以将checksum的值汇总到zookeeper，或者Redis中，进行所有节点的数据一致性判断。当然，如果进行scp的数据源机器只有一台的话，汇总到这台机器进行判断和处理也是OK的。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1591401723,"ip_address":"","comment_id":224403,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"CheckSum的值还需要多个节点同步一下，来确认节点内的数据最终是一致的对吧。","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":497462,"discussion_content":"对的。你可以将checksum的值汇总到zookeeper，或者Redis中，进行所有节点的数据一致性判断。当然，如果进行scp的数据源机器只有一台的话，汇总到这台机器进行判断和处理也是OK的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1591401723,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":224154,"user_name":"范闲","can_delete":false,"product_type":"c1","uid":1073125,"ip_address":"","ucode":"F21FD7DF6BA53C","user_header":"https://static001.geekbang.org/account/avatar/00/10/5f/e5/54325854.jpg","comment_is_top":false,"comment_ctime":1591286297,"is_pvip":false,"replies":[{"id":82582,"content":"关于使用scp拷贝数据的问题，如果你需要保证数据的一致性，可以做一下checksum的检查，要checksum一致才算是传输成功，否则就是同步失败。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1591342938,"ip_address":"","comment_id":224154,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"最近遇到一个问题想请教下老师。\n情况是这样的\n我有一个在线召回模块和离线数据模块。\n利用词向量生成句向量，然后利用Annoy搜索。\n主线程负责在线召回的搜索，副线程负责监控有没有新的词向量模型和索引模型。\n\n\n离线数据模块主要是从数据库和接口拉取用户问句，训练词向量模型，生成句向量和构建索引。当向量模型和索引构建完毕后，利用scp分别拷贝到多台在线召回的机器上，来完成数据同步。\n\n1.当请求量上去以后，在线召回词向量模型的查性能不行而且随着数据量增大，词向量的内存占用也越来越大。\n2.利用scp拷贝到多机的时候，没法确认是不是真的拷贝过去了，真的数据同步了，然后这就会导致不同在线模块的结果可能不一致。\n\n\n针对问题1的话，我想在离线数据生成词向量的时候。直接写入redis集群，在线召回去redis读取即可。\n\n针对问题2的话，目前没有考虑到太好的办法，只能还是按照scp的方式把索引文件同步过去。\n关于问题2您有什么好的想法么？","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":497377,"discussion_content":"关于使用scp拷贝数据的问题，如果你需要保证数据的一致性，可以做一下checksum的检查，要checksum一致才算是传输成功，否则就是同步失败。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1591342938,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":223888,"user_name":"鲁滨逊","can_delete":false,"product_type":"c1","uid":1191378,"ip_address":"","ucode":"54AA764E65ADEE","user_header":"https://static001.geekbang.org/account/avatar/00/12/2d/d2/9ef1e70d.jpg","comment_is_top":false,"comment_ctime":1591226021,"is_pvip":false,"replies":[{"id":82476,"content":"对于第一个问题，属性过滤如何做?你可以参考一下后面广告系统，以及进阶篇的测试题“如何寻找附近的相同兴趣的人”。\n你会看到，我们可以先用有明确过滤条件的属性(比如地点)，将所有数据进行分片，然后在分片里进行向量检索，然后最后可以再进行属性过滤。\n第二个问题，索引肯定是需要定期重建的，至于聚类的数量是否需要修改，主要还是看业务形态是否有变化和聚类结果是否依然理想。只要能保证类的边界清晰，类内元素紧密，那么聚类数量多一些少一些都可以的。\n","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1591254318,"ip_address":"","comment_id":223888,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"老师，对于向量搜索我有两个实际问题。1.对于特征向量携带多个属性的情境下，属性过滤该怎么做呢？比如我们现在在给公安做的交通路口，人脸卡扣抓拍搜索，时间范围和地点这两个基本属性是一定会进行过滤的。我的考虑是，如果放在距离计算之前进行过滤，确实能减少搜索范围，但向量存储一定依照一定的组织方式，这种组织方式该怎样设计，或者其他数据库能解决？如果全量搜索完之后再做过滤，那可能得不到topk个结果，极端情形甚至一个都没有（都被过滤掉了）2.对于数据量不断增多，一段时间后倒排索引是不是得重新建立，聚类中心数量还如何选择呢？麻烦老师解惑。","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":497284,"discussion_content":"对于第一个问题，属性过滤如何做?你可以参考一下后面广告系统，以及进阶篇的测试题“如何寻找附近的相同兴趣的人”。\n你会看到，我们可以先用有明确过滤条件的属性(比如地点)，将所有数据进行分片，然后在分片里进行向量检索，然后最后可以再进行属性过滤。\n第二个问题，索引肯定是需要定期重建的，至于聚类的数量是否需要修改，主要还是看业务形态是否有变化和聚类结果是否依然理想。只要能保证类的边界清晰，类内元素紧密，那么聚类数量多一些少一些都可以的。\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1591254318,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":215665,"user_name":"峰","can_delete":false,"product_type":"c1","uid":1056019,"ip_address":"","ucode":"C53CB64E8E7D19","user_header":"https://static001.geekbang.org/account/avatar/00/10/1d/13/31ea1b0b.jpg","comment_is_top":false,"comment_ctime":1589071875,"is_pvip":false,"replies":[{"id":79828,"content":"哈哈，的确是这样的，聚类，乘积，量化，倒排索引，其实每个词单独看都不算很复杂，但这些技术组合起来以后，却能发挥很好的效果。\n包括为什么它们可以组合在一起串起来，怎么起到互补的作用，的确可以好好消化一下。\n至于问题2，可能例子不算很好，不过大家看了评论以后，能理解怎么使用乘积量化，那么我觉得目的就达到了。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1589091542,"ip_address":"","comment_id":215665,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"问题1， 假设只有一个子空间就是本身，这就当于用聚类中心ID表示原始的数据点，当然还需要记录下聚类中心的原始特征向量，而多个就是扩展的问题，对每个子空间都采用这种方式对数据进行编码，但是如何选择有效的子空间无疑是这个算法的问题所在。\n问题2，我理解17，17 是一个异常点，作为一个聚类中心，单独考虑记录好了。 额看了下评论，原来理解错了意思。。。。。\n这节课真的是厉害了，思想其实都明白，串在一起还真是得好好看看看看看看。。。。。。","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":497284,"discussion_content":"对于第一个问题，属性过滤如何做?你可以参考一下后面广告系统，以及进阶篇的测试题“如何寻找附近的相同兴趣的人”。\n你会看到，我们可以先用有明确过滤条件的属性(比如地点)，将所有数据进行分片，然后在分片里进行向量检索，然后最后可以再进行属性过滤。\n第二个问题，索引肯定是需要定期重建的，至于聚类的数量是否需要修改，主要还是看业务形态是否有变化和聚类结果是否依然理想。只要能保证类的边界清晰，类内元素紧密，那么聚类数量多一些少一些都可以的。\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1591254318,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":213507,"user_name":"wcf","can_delete":false,"product_type":"c1","uid":1829111,"ip_address":"","ucode":"6E3B0A47B963E7","user_header":"https://static001.geekbang.org/account/avatar/00/1b/e8/f7/1b45fa46.jpg","comment_is_top":false,"comment_ctime":1588436495,"is_pvip":false,"replies":[{"id":79169,"content":"首先，你举的这个例子不叫“乘积”，而只是将16个(x，y)分别存成16个(x)和16个(y)，这样的确是没有省空间的。\n然后，我文中的点，其实代表的是“聚类中心向量”，而不是“样本向量”。接下来我来和你一起分析一下。\n如果二维空间按格子划分区域，一共有16个区域，那么我们就需要16个编号(相当于生成16个聚类，每个聚类要记录自己的中心向量，有16个二维的中心向量)。但如果我们把二维空间分解为x轴和y轴，那么x轴只需要4个编号，y轴只需要4个编号。这样我们只需要4+4个编号既可以表示完整的二维空间了(相当于将向量分为两个子空间，每个子空间生成4个聚类，每个聚类需要记录自己的中心向量，这样就有8个一维的中心向量)\n那么，记录8个一维的中心向量比记录16个二维的中心向量省空间。空间是省在了这里，而不是省在样本向量上。\n对于每个样本向量，之前的二维空间编号是1－16，需要4个比特位，分解后的两个一维空间编号是(1－4)*(1－4)，也是需要4个比特位。因此，样本向量的存储，无论是个数，还是压缩后需要用到比特位，都是无法节省的。\n总结一下，乘积的好处，其实是可以降低我们要存储的中心向量的个数和维度，而不是降低样本向量的个数。如果样本向量原来有n个，那么乘积量化后依然有n个。我文中举的“点”的例子，结合后面的内容看，你就会发现它代表的是聚类中心向量，而不是样本向量。我想这可能就是让你觉得疑惑的地方，希望这个分析可以解答你的疑惑。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1588479164,"ip_address":"","comment_id":213507,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"对于乘积法省空间的说法有点疑问.老师在文章里的说法确实能看出节省了空间,但是这里面临的问题是:给定16个二维空间的点,使用(x,y)的存储方法,会比分别存储x和y的方法更省空间吗?假如这16个点的x值分布在16个值上,y值也分布在16个值上,那两种方法都需要32个浮点数表示啊?怎么就能省空间呢?","like_count":9,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493800,"discussion_content":"首先，你举的这个例子不叫“乘积”，而只是将16个(x，y)分别存成16个(x)和16个(y)，这样的确是没有省空间的。\n然后，我文中的点，其实代表的是“聚类中心向量”，而不是“样本向量”。接下来我来和你一起分析一下。\n如果二维空间按格子划分区域，一共有16个区域，那么我们就需要16个编号(相当于生成16个聚类，每个聚类要记录自己的中心向量，有16个二维的中心向量)。但如果我们把二维空间分解为x轴和y轴，那么x轴只需要4个编号，y轴只需要4个编号。这样我们只需要4+4个编号既可以表示完整的二维空间了(相当于将向量分为两个子空间，每个子空间生成4个聚类，每个聚类需要记录自己的中心向量，这样就有8个一维的中心向量)\n那么，记录8个一维的中心向量比记录16个二维的中心向量省空间。空间是省在了这里，而不是省在样本向量上。\n对于每个样本向量，之前的二维空间编号是1－16，需要4个比特位，分解后的两个一维空间编号是(1－4)*(1－4)，也是需要4个比特位。因此，样本向量的存储，无论是个数，还是压缩后需要用到比特位，都是无法节省的。\n总结一下，乘积的好处，其实是可以降低我们要存储的中心向量的个数和维度，而不是降低样本向量的个数。如果样本向量原来有n个，那么乘积量化后依然有n个。我文中举的“点”的例子，结合后面的内容看，你就会发现它代表的是聚类中心向量，而不是样本向量。我想这可能就是让你觉得疑惑的地方，希望这个分析可以解答你的疑惑。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1588479164,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":213053,"user_name":"每天晒白牙","can_delete":false,"product_type":"c1","uid":1004698,"ip_address":"","ucode":"A1B102CD933DEA","user_header":"https://static001.geekbang.org/account/avatar/00/0f/54/9a/76c0af70.jpg","comment_is_top":false,"comment_ctime":1588290186,"is_pvip":false,"replies":[{"id":79090,"content":"实话实说，这一讲的内容的确很难。即使是我自己当年学这些内容的时候，也琢磨了好久。而且这一部分的内容和AI结合较紧密，也是随着这几年AI的大面积铺开才开始变得重要起来的，之前大部分工程师可能并不熟悉。因此，多看几遍，有不懂的地方一起讨论分析，相信你会有收获的。\n为什么进阶篇最后一篇讲了这样一个内容呢，你会发现，我们的应用场景都在进化，现在搜索引擎已经支持图片搜索了，电商平台也支持拍照购物，还有人脸识别等应用，对应起来，我们的检索技术，已经需要从文本关键词检索，升级到图片检索，视频检索等更复杂的空间中了。\n包括现在的广告系统，其实各种智能匹配，都可以看着是向量匹配，而不仅仅是传统的关键词倒排检索。\n我希望我们都能跟着时代的潮流，提升自己的认知和竞争力。\n由于专栏篇幅有限，因此多少会有一些知识没有展开介绍。不过，你可以把这个专栏的内容当做一个索引，然后对于自己感兴趣的部分去深入学习了解。有不清楚的地方，也欢迎讨论和交流。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1588299318,"ip_address":"","comment_id":213053,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"老师讲的是真好，只是学生我底子差，越到后面的文章越看不太懂了，很吃力\n\n也许这就是因为门槛高了，才使得做算法和 AI 的同学工资高\n\n想想从小学开始一直到大学(甚至有些读到了研究生和博士)，也都是从简单开始学起，最开始的 1+1=2，看不出学生有多大差别，但后面四则混合运算，再到各种三角函数，大学的微积分等等吧\n\n越到后面学习门槛越高，大家的差距也逐渐拉开","like_count":5,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493678,"discussion_content":"实话实说，这一讲的内容的确很难。即使是我自己当年学这些内容的时候，也琢磨了好久。而且这一部分的内容和AI结合较紧密，也是随着这几年AI的大面积铺开才开始变得重要起来的，之前大部分工程师可能并不熟悉。因此，多看几遍，有不懂的地方一起讨论分析，相信你会有收获的。\n为什么进阶篇最后一篇讲了这样一个内容呢，你会发现，我们的应用场景都在进化，现在搜索引擎已经支持图片搜索了，电商平台也支持拍照购物，还有人脸识别等应用，对应起来，我们的检索技术，已经需要从文本关键词检索，升级到图片检索，视频检索等更复杂的空间中了。\n包括现在的广告系统，其实各种智能匹配，都可以看着是向量匹配，而不仅仅是传统的关键词倒排检索。\n我希望我们都能跟着时代的潮流，提升自己的认知和竞争力。\n由于专栏篇幅有限，因此多少会有一些知识没有展开介绍。不过，你可以把这个专栏的内容当做一个索引，然后对于自己感兴趣的部分去深入学习了解。有不清楚的地方，也欢迎讨论和交流。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588299318,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":213124,"user_name":"范闲","can_delete":false,"product_type":"c1","uid":1073125,"ip_address":"","ucode":"F21FD7DF6BA53C","user_header":"https://static001.geekbang.org/account/avatar/00/10/5f/e5/54325854.jpg","comment_is_top":false,"comment_ctime":1588307453,"is_pvip":false,"replies":[{"id":79094,"content":"你去看了乘积量化的论文，这一点非常好。原始的论文肯定会描述得更详细，有更多的内容，当然，也会更难懂。不过从你的描述来看，你很好地提炼出了乘积量化算法的核心，相信你对它已经理解得很清楚了。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1588310967,"ip_address":"","comment_id":213124,"utype":1}],"discussion_count":6,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"今天上午刚刚看了乘积量化的论文。乘积量化实际上是建立在一个D维向量由M个子向量组成的假设上。子向量的维度就是K=D&#47;M. 而M代表着码本的数量，码本实际上就是对子向量进行kmeans运算得到的聚类中心。另外在乘积量化过程中，还有个PQcode，实际上存储的子向量属于哪一个码本。\n\n在向量搜索过程中，向量直接和码本运算得到距离表，然后再同PQcode求和就能得到距离了。\n\n但是如果你的向量的数据集的数目N是亿级别的，就会导致你的向量搜索的速度下降。\n\n而倒排向量实际是为了解决这个问题而产生的。先对N个向量聚类，产生1024（这部分可以改变的）个中心，然后会得到N个向量和聚类中心的残差，再对残差进行乘积量化的步骤即可。\n","like_count":4,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493687,"discussion_content":"你去看了乘积量化的论文，这一点非常好。原始的论文肯定会描述得更详细，有更多的内容，当然，也会更难懂。不过从你的描述来看，你很好地提炼出了乘积量化算法的核心，相信你对它已经理解得很清楚了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588310967,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1159442,"avatar":"https://static001.geekbang.org/account/avatar/00/11/b1/12/46e601ba.jpg","nickname":"Kevin2468","note":"","ucode":"6A138CCD3BF280","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":313212,"discussion_content":"为什么要对残差乘积量化？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1603002836,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":4,"child_discussions":[{"author":{"id":1073125,"avatar":"https://static001.geekbang.org/account/avatar/00/10/5f/e5/54325854.jpg","nickname":"范闲","note":"","ucode":"F21FD7DF6BA53C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1159442,"avatar":"https://static001.geekbang.org/account/avatar/00/11/b1/12/46e601ba.jpg","nickname":"Kevin2468","note":"","ucode":"6A138CCD3BF280","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":314374,"discussion_content":"对残差量化实际上就是重新做一次乘积量化。\n在没有倒排的时候，只有乘积量化。\n在有倒排的时候，只需要根据向量和聚类中心点的差做量化就可以。因为倒排的时候你是根据聚类中心找到哪些向量集可能和搜索向量最近。和聚类中心比较完以后，搜索向量-聚类中心就是剩余的残差部分。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1603153870,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":313212,"ip_address":"","group_id":0},"score":314374,"extra":""},{"author":{"id":1311128,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJ5WmAmuxTzKoln814dKIAia1KTUcgSSYzYgDIphlbv5dQpCuxrfRqodtXGMh7QtVUexCZE3CfYAgg/132","nickname":"尹小白","note":"","ucode":"AA726C8FB04454","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1073125,"avatar":"https://static001.geekbang.org/account/avatar/00/10/5f/e5/54325854.jpg","nickname":"范闲","note":"","ucode":"F21FD7DF6BA53C","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":533970,"discussion_content":"似乎还是没说清楚为什么要对残差做乘积量化，不太理解为什么要计算残差重建向量空间呢（原始向量转换），这一步是必须的么？我理解不计算残差只用原始向量应该也是可以的？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1638042431,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":314374,"ip_address":"","group_id":0},"score":533970,"extra":""},{"author":{"id":1311128,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJ5WmAmuxTzKoln814dKIAia1KTUcgSSYzYgDIphlbv5dQpCuxrfRqodtXGMh7QtVUexCZE3CfYAgg/132","nickname":"尹小白","note":"","ucode":"AA726C8FB04454","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1159442,"avatar":"https://static001.geekbang.org/account/avatar/00/11/b1/12/46e601ba.jpg","nickname":"Kevin2468","note":"","ucode":"6A138CCD3BF280","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":533971,"discussion_content":"大佬解了这个问题了么","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1638042461,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":313212,"ip_address":"","group_id":0},"score":533971,"extra":""}]}]},{"had_liked":false,"id":249965,"user_name":"piboye","can_delete":false,"product_type":"c1","uid":1066752,"ip_address":"","ucode":"7CFD8712857A85","user_header":"https://static001.geekbang.org/account/avatar/00/10/47/00/3202bdf0.jpg","comment_is_top":false,"comment_ctime":1600868450,"is_pvip":true,"replies":[{"id":91847,"content":"这可以说是最难的一章了。但是如果理解好了，你就能吃透向量检索的核心。而向量检索是近期结合深度学习浪潮的热门检索技术，在许多大公司中都开始采用了。建议可以耐心点慢慢多看几遍，相信会理解越来越深刻的。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1601391171,"ip_address":"","comment_id":249965,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"好难啊","like_count":1,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":506078,"discussion_content":"这可以说是最难的一章了。但是如果理解好了，你就能吃透向量检索的核心。而向量检索是近期结合深度学习浪潮的热门检索技术，在许多大公司中都开始采用了。建议可以耐心点慢慢多看几遍，相信会理解越来越深刻的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1601391171,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":213233,"user_name":"那时刻","can_delete":false,"product_type":"c1","uid":1150927,"ip_address":"","ucode":"B0D150856C3A4A","user_header":"https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg","comment_is_top":false,"comment_ctime":1588338029,"is_pvip":false,"replies":[{"id":79114,"content":"今天的内容的确会比较难，知识点也比较多，所以总结部分有一个思维导图，希望能帮你更好地吸收。\n关于思考题:\n1. 压缩的根源，是在于我们可以用1个类的中心向量来代替类内所有的n个样本向量。用你熟悉的数据库分表来做例子，分析如下:\n原来的向量存储是这样的:\n样本向量表结构:[样本向量ID | 向量数据]\n每个向量数据都是一个高维向量，会很占空间。\n但用聚类中心向量代替样本向量以后，我们会有两张表:\n聚类中心表结构:[聚类ID | 聚类中心向量数据]\n样本向量表结构:[样本向量ID | 聚类ID]\n你会发现，和原先的相比，我们加了一个聚类中心表，由于聚类不多，因此这个表不会太大。而原来的样本向量表，它存的数据从“向量数据”变成了“聚类ID”，从而不用存储具体的向量(可以用聚类ID关联到聚类中心表)，因此表空间得到压缩。\n2.是的，这题是希望你能更好地理解乘积量化的思想，并不一定要求要严格按照每个流程做。我们可以分为xy轴两个维度(这样就是乘积了)。不过由于数据太少，所以也不需要用聚类，比如你把x轴等分2段也可以。然后每段编上号(这样就是量化了)。\n然后查询时，你分别和x轴和y轴比，找到对应的区域就好。\n","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1588348622,"ip_address":"","comment_id":213233,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"非常感谢老师这一节内容，收获不少。对于高维度的向量进行乘积量化，颇类似于数据库里对于数据分表操作，分散存储和提高查询速度。\n\n尝试回答一下讨论问题\n1. 使用聚类中心向量来代替聚类中的样本向量，其一，这样不需要存储每个聚类里样本向量，只需要存储他们和中心向量的差值，乘积量化后减少存储，其二，查询时候，只需要比较这个中心向量，减少比较次数，提高查询效率。\n2.二维空间的点，可以按照x，y轴两个维度分别进行聚类，然后乘积量化来压缩存储。查询过程可以按照老师文章讲述的过程来查询。","like_count":1,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493718,"discussion_content":"今天的内容的确会比较难，知识点也比较多，所以总结部分有一个思维导图，希望能帮你更好地吸收。\n关于思考题:\n1. 压缩的根源，是在于我们可以用1个类的中心向量来代替类内所有的n个样本向量。用你熟悉的数据库分表来做例子，分析如下:\n原来的向量存储是这样的:\n样本向量表结构:[样本向量ID | 向量数据]\n每个向量数据都是一个高维向量，会很占空间。\n但用聚类中心向量代替样本向量以后，我们会有两张表:\n聚类中心表结构:[聚类ID | 聚类中心向量数据]\n样本向量表结构:[样本向量ID | 聚类ID]\n你会发现，和原先的相比，我们加了一个聚类中心表，由于聚类不多，因此这个表不会太大。而原来的样本向量表，它存的数据从“向量数据”变成了“聚类ID”，从而不用存储具体的向量(可以用聚类ID关联到聚类中心表)，因此表空间得到压缩。\n2.是的，这题是希望你能更好地理解乘积量化的思想，并不一定要求要严格按照每个流程做。我们可以分为xy轴两个维度(这样就是乘积了)。不过由于数据太少，所以也不需要用聚类，比如你把x轴等分2段也可以。然后每段编上号(这样就是量化了)。\n然后查询时，你分别和x轴和y轴比，找到对应的区域就好。\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588348622,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":275886,"user_name":"易企秀-郭彦超","can_delete":false,"product_type":"c1","uid":2343516,"ip_address":"","ucode":"2E25574FAB1B3B","user_header":"https://static001.geekbang.org/account/avatar/00/23/c2/5c/791d0f5e.jpg","comment_is_top":false,"comment_ctime":1611712382,"is_pvip":false,"replies":[{"id":102770,"content":"在本文的例子中，样本向量指的就是图片向量，分为1024个聚类，指的是将每个图片分到1024个聚类中的某一个。(图片向量维度可以很高，大于1024)","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1615713110,"ip_address":"","comment_id":275886,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"老师 倒排乘机量化中，使用k-means将样本向量分为1024个聚类 ，这里的样本向量指的是图片向量吗，意思是将高维图片向量压缩为1024维图片向量吗，还是每张图片被划分到1024个聚类中的某一个","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":514519,"discussion_content":"在本文的例子中，样本向量指的就是图片向量，分为1024个聚类，指的是将每个图片分到1024个聚类中的某一个。(图片向量维度可以很高，大于1024)","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1615713110,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":224403,"user_name":"范闲","can_delete":false,"product_type":"c1","uid":1073125,"ip_address":"","ucode":"F21FD7DF6BA53C","user_header":"https://static001.geekbang.org/account/avatar/00/10/5f/e5/54325854.jpg","comment_is_top":false,"comment_ctime":1591369911,"is_pvip":false,"replies":[{"id":82595,"content":"对的。你可以将checksum的值汇总到zookeeper，或者Redis中，进行所有节点的数据一致性判断。当然，如果进行scp的数据源机器只有一台的话，汇总到这台机器进行判断和处理也是OK的。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1591401723,"ip_address":"","comment_id":224403,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"CheckSum的值还需要多个节点同步一下，来确认节点内的数据最终是一致的对吧。","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":514519,"discussion_content":"在本文的例子中，样本向量指的就是图片向量，分为1024个聚类，指的是将每个图片分到1024个聚类中的某一个。(图片向量维度可以很高，大于1024)","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1615713110,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":224154,"user_name":"范闲","can_delete":false,"product_type":"c1","uid":1073125,"ip_address":"","ucode":"F21FD7DF6BA53C","user_header":"https://static001.geekbang.org/account/avatar/00/10/5f/e5/54325854.jpg","comment_is_top":false,"comment_ctime":1591286297,"is_pvip":false,"replies":[{"id":82582,"content":"关于使用scp拷贝数据的问题，如果你需要保证数据的一致性，可以做一下checksum的检查，要checksum一致才算是传输成功，否则就是同步失败。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1591342938,"ip_address":"","comment_id":224154,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"最近遇到一个问题想请教下老师。\n情况是这样的\n我有一个在线召回模块和离线数据模块。\n利用词向量生成句向量，然后利用Annoy搜索。\n主线程负责在线召回的搜索，副线程负责监控有没有新的词向量模型和索引模型。\n\n\n离线数据模块主要是从数据库和接口拉取用户问句，训练词向量模型，生成句向量和构建索引。当向量模型和索引构建完毕后，利用scp分别拷贝到多台在线召回的机器上，来完成数据同步。\n\n1.当请求量上去以后，在线召回词向量模型的查性能不行而且随着数据量增大，词向量的内存占用也越来越大。\n2.利用scp拷贝到多机的时候，没法确认是不是真的拷贝过去了，真的数据同步了，然后这就会导致不同在线模块的结果可能不一致。\n\n\n针对问题1的话，我想在离线数据生成词向量的时候。直接写入redis集群，在线召回去redis读取即可。\n\n针对问题2的话，目前没有考虑到太好的办法，只能还是按照scp的方式把索引文件同步过去。\n关于问题2您有什么好的想法么？","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":497462,"discussion_content":"对的。你可以将checksum的值汇总到zookeeper，或者Redis中，进行所有节点的数据一致性判断。当然，如果进行scp的数据源机器只有一台的话，汇总到这台机器进行判断和处理也是OK的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1591401723,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":223888,"user_name":"鲁滨逊","can_delete":false,"product_type":"c1","uid":1191378,"ip_address":"","ucode":"54AA764E65ADEE","user_header":"https://static001.geekbang.org/account/avatar/00/12/2d/d2/9ef1e70d.jpg","comment_is_top":false,"comment_ctime":1591226021,"is_pvip":false,"replies":[{"id":82476,"content":"对于第一个问题，属性过滤如何做?你可以参考一下后面广告系统，以及进阶篇的测试题“如何寻找附近的相同兴趣的人”。\n你会看到，我们可以先用有明确过滤条件的属性(比如地点)，将所有数据进行分片，然后在分片里进行向量检索，然后最后可以再进行属性过滤。\n第二个问题，索引肯定是需要定期重建的，至于聚类的数量是否需要修改，主要还是看业务形态是否有变化和聚类结果是否依然理想。只要能保证类的边界清晰，类内元素紧密，那么聚类数量多一些少一些都可以的。\n","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1591254318,"ip_address":"","comment_id":223888,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"老师，对于向量搜索我有两个实际问题。1.对于特征向量携带多个属性的情境下，属性过滤该怎么做呢？比如我们现在在给公安做的交通路口，人脸卡扣抓拍搜索，时间范围和地点这两个基本属性是一定会进行过滤的。我的考虑是，如果放在距离计算之前进行过滤，确实能减少搜索范围，但向量存储一定依照一定的组织方式，这种组织方式该怎样设计，或者其他数据库能解决？如果全量搜索完之后再做过滤，那可能得不到topk个结果，极端情形甚至一个都没有（都被过滤掉了）2.对于数据量不断增多，一段时间后倒排索引是不是得重新建立，聚类中心数量还如何选择呢？麻烦老师解惑。","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":497377,"discussion_content":"关于使用scp拷贝数据的问题，如果你需要保证数据的一致性，可以做一下checksum的检查，要checksum一致才算是传输成功，否则就是同步失败。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1591342938,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":215665,"user_name":"峰","can_delete":false,"product_type":"c1","uid":1056019,"ip_address":"","ucode":"C53CB64E8E7D19","user_header":"https://static001.geekbang.org/account/avatar/00/10/1d/13/31ea1b0b.jpg","comment_is_top":false,"comment_ctime":1589071875,"is_pvip":false,"replies":[{"id":79828,"content":"哈哈，的确是这样的，聚类，乘积，量化，倒排索引，其实每个词单独看都不算很复杂，但这些技术组合起来以后，却能发挥很好的效果。\n包括为什么它们可以组合在一起串起来，怎么起到互补的作用，的确可以好好消化一下。\n至于问题2，可能例子不算很好，不过大家看了评论以后，能理解怎么使用乘积量化，那么我觉得目的就达到了。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1589091542,"ip_address":"","comment_id":215665,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"问题1， 假设只有一个子空间就是本身，这就当于用聚类中心ID表示原始的数据点，当然还需要记录下聚类中心的原始特征向量，而多个就是扩展的问题，对每个子空间都采用这种方式对数据进行编码，但是如何选择有效的子空间无疑是这个算法的问题所在。\n问题2，我理解17，17 是一个异常点，作为一个聚类中心，单独考虑记录好了。 额看了下评论，原来理解错了意思。。。。。\n这节课真的是厉害了，思想其实都明白，串在一起还真是得好好看看看看看看。。。。。。","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":494517,"discussion_content":"哈哈，的确是这样的，聚类，乘积，量化，倒排索引，其实每个词单独看都不算很复杂，但这些技术组合起来以后，却能发挥很好的效果。\n包括为什么它们可以组合在一起串起来，怎么起到互补的作用，的确可以好好消化一下。\n至于问题2，可能例子不算很好，不过大家看了评论以后，能理解怎么使用乘积量化，那么我觉得目的就达到了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589091542,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":214574,"user_name":"paulhaoyi","can_delete":false,"product_type":"c1","uid":1105619,"ip_address":"","ucode":"C972F4B459E7D6","user_header":"https://static001.geekbang.org/account/avatar/00/10/de/d3/2aa0177f.jpg","comment_is_top":false,"comment_ctime":1588767268,"is_pvip":false,"replies":[{"id":79455,"content":"你说得很对，可以多分，也可以少分，取决于你的应用需求，以及对成本和效果的权衡。\n其实上一讲的simhash检索就是一个例子，如果我们将海明距离从3调为4，那么切分就需要从4段改为五段以上。可见，我们最主要还是要理解原理，这样在需要优化的时候，才会有思路和方向。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1588778992,"ip_address":"","comment_id":214574,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"那么分组切分的数目有什么通用规则么？就是为什么1024通常分四组，每组256聚类，如果我多分，多聚类，或者少，会有那些影响？感觉应该是一个效果和成本的权衡？","like_count":0},{"had_liked":false,"id":214359,"user_name":"paulhaoyi","can_delete":false,"product_type":"c1","uid":1105619,"ip_address":"","ucode":"C972F4B459E7D6","user_header":"https://static001.geekbang.org/account/avatar/00/10/de/d3/2aa0177f.jpg","comment_is_top":false,"comment_ctime":1588730223,"is_pvip":false,"replies":[{"id":79377,"content":"如果是把二维空间分成8个聚类中心的话，那么划分粒度自然是比划分成16个聚类中心更粗，因此会损失精度。(你可以参考Geohash那一课的区域划分，你会看到，肯定是划分得越细粒度越精准)。\n并且，如果整个二维空间被划分为8个聚类中心的话，那我也可以将它看做是2*4两个子空间的乘积。因此我可以仅记录2+4个一维的聚类中心，这样还是比记录8个二维的聚类中心更省空间。\n你可以尝试拿一张纸，试着根据上面的例子，在纸上画一下区域划分的例子，这样应该会有所帮助。\n","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1588747471,"ip_address":"","comment_id":214359,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"关于向量乘积的例子，请教下老师，两个纬度各四个分区，共8个中心。如果我把2纬空间就分成8个聚类中心（不用16个），保持总分类数一样。也就是占用存储空间一样，那么两种方式的精度损失应该是不一样的吧？这个损失差别怎么理解？感觉不管怎么分，都是把整个空间或者说样本分成了8组或16组？那么直接二维分8组，为什么比两个一纬各分4组的效果差？这个地方感觉没理解清楚。","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":494121,"discussion_content":"你说得很对，可以多分，也可以少分，取决于你的应用需求，以及对成本和效果的权衡。\n其实上一讲的simhash检索就是一个例子，如果我们将海明距离从3调为4，那么切分就需要从4段改为五段以上。可见，我们最主要还是要理解原理，这样在需要优化的时候，才会有思路和方向。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588778992,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":214256,"user_name":"奕","can_delete":false,"product_type":"c1","uid":1005391,"ip_address":"","ucode":"73CEA468CE70C3","user_header":"https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg","comment_is_top":false,"comment_ctime":1588685528,"is_pvip":false,"replies":[{"id":79333,"content":"如果只将一个空间分为两部分，那的确可能太粗糙了，这个例子更多是让你直观感受一下量化的压缩原理。如果觉得太粗糙，你可以多划分几次，比如说用2个比特位，就可以将空间划分为4份，这样精度就提高。\n后面的例子中，你会看到，我们对于一段子空间，将它生成256个聚类，这样是一个常用的方案。当然，你也可以根据自己的需求去调整粒度，比如生成512个聚类，或者128个聚类都可以。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1588696796,"ip_address":"","comment_id":214256,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"我们就可以用 1 个比特位的 0 或 1 编码，来代替任意一个点的二维空间坐标 &lt;x,y&gt; 了 。假设 x 和 y 是两个浮点数，各 4 个字节，那它们一共是 8 个字节。如果我们将 8 个字节的坐标用 1 个比特位来表示\n------------------------------\n像文章说的二维空间量化，一个具体的坐标&lt;x,y&gt; 转换为一个 0 和 1，只知道大致的方向了，这样的话信息不是丢的很严重，这样的量化有意义吗？","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":494032,"discussion_content":"如果是把二维空间分成8个聚类中心的话，那么划分粒度自然是比划分成16个聚类中心更粗，因此会损失精度。(你可以参考Geohash那一课的区域划分，你会看到，肯定是划分得越细粒度越精准)。\n并且，如果整个二维空间被划分为8个聚类中心的话，那我也可以将它看做是2*4两个子空间的乘积。因此我可以仅记录2+4个一维的聚类中心，这样还是比记录8个二维的聚类中心更省空间。\n你可以尝试拿一张纸，试着根据上面的例子，在纸上画一下区域划分的例子，这样应该会有所帮助。\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588747471,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":214251,"user_name":"奕","can_delete":false,"product_type":"c1","uid":1005391,"ip_address":"","ucode":"73CEA468CE70C3","user_header":"https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg","comment_is_top":false,"comment_ctime":1588684891,"is_pvip":false,"replies":[{"id":79332,"content":"不需要的。中心向量并不是已有节点。\n第一步之所以随机选择已有节点作为中心向量，只是一个初始化步骤而已。你也可以随机生成k个中心向量作为第一步的代替方案。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1588696444,"ip_address":"","comment_id":214251,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"K-means 算法的第三步：\n计算每个类内节点的向量均值，作为每个类的新的中心向量。\n\n有个问题是：如果计算出来的新的中心向量的值 不在 所有的节点中会怎么进行处理的？ 还有这一步要不要判断 新的中心向量的值 在不在所有的节点中？","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":494002,"discussion_content":"如果只将一个空间分为两部分，那的确可能太粗糙了，这个例子更多是让你直观感受一下量化的压缩原理。如果觉得太粗糙，你可以多划分几次，比如说用2个比特位，就可以将空间划分为4份，这样精度就提高。\n后面的例子中，你会看到，我们对于一段子空间，将它生成256个聚类，这样是一个常用的方案。当然，你也可以根据自己的需求去调整粒度，比如生成512个聚类，或者128个聚类都可以。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588696796,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":213237,"user_name":"那时刻","can_delete":false,"product_type":"c1","uid":1150927,"ip_address":"","ucode":"B0D150856C3A4A","user_header":"https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg","comment_is_top":false,"comment_ctime":1588338599,"is_pvip":false,"replies":[{"id":79115,"content":"是这样的，在k-means算法中，我们会生成k个聚类，每个聚类都有自己的聚类中心向量。这些中心向量会存储好。\n然后，当查询向量到来的时候，我们会和这k个聚类中心向量比较，这样就能得到查询向量到每个聚类的距离。最近的那个聚类，就是目标聚类。如果这个目标聚类中的候选集不足，那么距离第二近的聚类，就是次临近的聚类。同理，如果次邻近的这个聚类中候选集还是不足，那么我们可以再去找距离第三近的聚类。依此类推。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1588349511,"ip_address":"","comment_id":213237,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"请问在聚类算法进行相似检索中，对于聚类中的候选集不足 Top K 个，我们还可以再去查询次邻近的聚类，这个临近聚类怎么来寻找呢？是重新计算当前聚类中心点和其它中心点距离么？还是需要额外存储聚类中心点之间的距离？","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":494000,"discussion_content":"不需要的。中心向量并不是已有节点。\n第一步之所以随机选择已有节点作为中心向量，只是一个初始化步骤而已。你也可以随机生成k个中心向量作为第一步的代替方案。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588696444,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":372790,"user_name":"ifelse","can_delete":false,"product_type":"c1","uid":2550743,"ip_address":"浙江","ucode":"D0565908C99695","user_header":"https://static001.geekbang.org/account/avatar/00/26/eb/d7/90391376.jpg","comment_is_top":false,"comment_ctime":1681625787,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":3,"score":3,"product_id":100048401,"comment_content":"学习打卡，干货满满","like_count":0},{"had_liked":false,"id":371397,"user_name":"吴怀炜","can_delete":false,"product_type":"c1","uid":3533040,"ip_address":"广东","ucode":"EFB8E2472A898E","user_header":"","comment_is_top":false,"comment_ctime":1679901332,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"老师可以请教个问题吗，就是乘积量化中，原向量需要被拆分的段数，还有子向量聚类的数量，有什么好的方法可以确定吗？使得效果更好一点。","like_count":0},{"had_liked":false,"id":340049,"user_name":"姚文轩","can_delete":false,"product_type":"c1","uid":2866391,"ip_address":"","ucode":"3DDA79FD8C4D62","user_header":"","comment_is_top":false,"comment_ctime":1648555371,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"“这样，求查询子向量和样本子向量的距离，就转换为求查询子向量和对应的聚类中心向量的距离。那我们只需要将样本子向量的聚类 ID 作为 key 去查距离表，就能在 O(1) 的时间代价内知道这个距离了。“\n\nteacher， 这块我可不可以认为是为了压缩存储节约内存而做的精度损失呢？，损失了所有样本向量的具体信息，只保留了样本向量所对应4个聚类中心向量的信息\n\n","like_count":0},{"had_liked":false,"id":323637,"user_name":"尹小白","can_delete":false,"product_type":"c1","uid":1311128,"ip_address":"","ucode":"AA726C8FB04454","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJ5WmAmuxTzKoln814dKIAia1KTUcgSSYzYgDIphlbv5dQpCuxrfRqodtXGMh7QtVUexCZE3CfYAgg/132","comment_is_top":false,"comment_ctime":1638041261,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"或者说没太理解为什么要以聚类中心向量为原点，重新建立向量空间","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493719,"discussion_content":"是这样的，在k-means算法中，我们会生成k个聚类，每个聚类都有自己的聚类中心向量。这些中心向量会存储好。\n然后，当查询向量到来的时候，我们会和这k个聚类中心向量比较，这样就能得到查询向量到每个聚类的距离。最近的那个聚类，就是目标聚类。如果这个目标聚类中的候选集不足，那么距离第二近的聚类，就是次临近的聚类。同理，如果次邻近的这个聚类中候选集还是不足，那么我们可以再去找距离第三近的聚类。依此类推。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588349511,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":323635,"user_name":"尹小白","can_delete":false,"product_type":"c1","uid":1311128,"ip_address":"","ucode":"AA726C8FB04454","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJ5WmAmuxTzKoln814dKIAia1KTUcgSSYzYgDIphlbv5dQpCuxrfRqodtXGMh7QtVUexCZE3CfYAgg/132","comment_is_top":false,"comment_ctime":1638039786,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"老师，请问聚类乘积量化加倒排索引中，向量变换的目的是什么呢？","like_count":0,"discussions":[{"author":{"id":2285106,"avatar":"https://static001.geekbang.org/account/avatar/00/22/de/32/f04d6fbb.jpg","nickname":"gaoyang","note":"","ucode":"8EE36F1C5D4BFE","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":584708,"discussion_content":"+1","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1661055370,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":214574,"user_name":"paulhaoyi","can_delete":false,"product_type":"c1","uid":1105619,"ip_address":"","ucode":"C972F4B459E7D6","user_header":"https://static001.geekbang.org/account/avatar/00/10/de/d3/2aa0177f.jpg","comment_is_top":false,"comment_ctime":1588767268,"is_pvip":false,"replies":[{"id":79455,"content":"你说得很对，可以多分，也可以少分，取决于你的应用需求，以及对成本和效果的权衡。\n其实上一讲的simhash检索就是一个例子，如果我们将海明距离从3调为4，那么切分就需要从4段改为五段以上。可见，我们最主要还是要理解原理，这样在需要优化的时候，才会有思路和方向。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1588778992,"ip_address":"","comment_id":214574,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"那么分组切分的数目有什么通用规则么？就是为什么1024通常分四组，每组256聚类，如果我多分，多聚类，或者少，会有那些影响？感觉应该是一个效果和成本的权衡？","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":494121,"discussion_content":"你说得很对，可以多分，也可以少分，取决于你的应用需求，以及对成本和效果的权衡。\n其实上一讲的simhash检索就是一个例子，如果我们将海明距离从3调为4，那么切分就需要从4段改为五段以上。可见，我们最主要还是要理解原理，这样在需要优化的时候，才会有思路和方向。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588778992,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":214359,"user_name":"paulhaoyi","can_delete":false,"product_type":"c1","uid":1105619,"ip_address":"","ucode":"C972F4B459E7D6","user_header":"https://static001.geekbang.org/account/avatar/00/10/de/d3/2aa0177f.jpg","comment_is_top":false,"comment_ctime":1588730223,"is_pvip":false,"replies":[{"id":79377,"content":"如果是把二维空间分成8个聚类中心的话，那么划分粒度自然是比划分成16个聚类中心更粗，因此会损失精度。(你可以参考Geohash那一课的区域划分，你会看到，肯定是划分得越细粒度越精准)。\n并且，如果整个二维空间被划分为8个聚类中心的话，那我也可以将它看做是2*4两个子空间的乘积。因此我可以仅记录2+4个一维的聚类中心，这样还是比记录8个二维的聚类中心更省空间。\n你可以尝试拿一张纸，试着根据上面的例子，在纸上画一下区域划分的例子，这样应该会有所帮助。\n","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1588747471,"ip_address":"","comment_id":214359,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"关于向量乘积的例子，请教下老师，两个纬度各四个分区，共8个中心。如果我把2纬空间就分成8个聚类中心（不用16个），保持总分类数一样。也就是占用存储空间一样，那么两种方式的精度损失应该是不一样的吧？这个损失差别怎么理解？感觉不管怎么分，都是把整个空间或者说样本分成了8组或16组？那么直接二维分8组，为什么比两个一纬各分4组的效果差？这个地方感觉没理解清楚。","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":494032,"discussion_content":"如果是把二维空间分成8个聚类中心的话，那么划分粒度自然是比划分成16个聚类中心更粗，因此会损失精度。(你可以参考Geohash那一课的区域划分，你会看到，肯定是划分得越细粒度越精准)。\n并且，如果整个二维空间被划分为8个聚类中心的话，那我也可以将它看做是2*4两个子空间的乘积。因此我可以仅记录2+4个一维的聚类中心，这样还是比记录8个二维的聚类中心更省空间。\n你可以尝试拿一张纸，试着根据上面的例子，在纸上画一下区域划分的例子，这样应该会有所帮助。\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588747471,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":214256,"user_name":"奕","can_delete":false,"product_type":"c1","uid":1005391,"ip_address":"","ucode":"73CEA468CE70C3","user_header":"https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg","comment_is_top":false,"comment_ctime":1588685528,"is_pvip":false,"replies":[{"id":79333,"content":"如果只将一个空间分为两部分，那的确可能太粗糙了，这个例子更多是让你直观感受一下量化的压缩原理。如果觉得太粗糙，你可以多划分几次，比如说用2个比特位，就可以将空间划分为4份，这样精度就提高。\n后面的例子中，你会看到，我们对于一段子空间，将它生成256个聚类，这样是一个常用的方案。当然，你也可以根据自己的需求去调整粒度，比如生成512个聚类，或者128个聚类都可以。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1588696796,"ip_address":"","comment_id":214256,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"我们就可以用 1 个比特位的 0 或 1 编码，来代替任意一个点的二维空间坐标 &lt;x,y&gt; 了 。假设 x 和 y 是两个浮点数，各 4 个字节，那它们一共是 8 个字节。如果我们将 8 个字节的坐标用 1 个比特位来表示\n------------------------------\n像文章说的二维空间量化，一个具体的坐标&lt;x,y&gt; 转换为一个 0 和 1，只知道大致的方向了，这样的话信息不是丢的很严重，这样的量化有意义吗？","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":494002,"discussion_content":"如果只将一个空间分为两部分，那的确可能太粗糙了，这个例子更多是让你直观感受一下量化的压缩原理。如果觉得太粗糙，你可以多划分几次，比如说用2个比特位，就可以将空间划分为4份，这样精度就提高。\n后面的例子中，你会看到，我们对于一段子空间，将它生成256个聚类，这样是一个常用的方案。当然，你也可以根据自己的需求去调整粒度，比如生成512个聚类，或者128个聚类都可以。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588696796,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":214251,"user_name":"奕","can_delete":false,"product_type":"c1","uid":1005391,"ip_address":"","ucode":"73CEA468CE70C3","user_header":"https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg","comment_is_top":false,"comment_ctime":1588684891,"is_pvip":false,"replies":[{"id":79332,"content":"不需要的。中心向量并不是已有节点。\n第一步之所以随机选择已有节点作为中心向量，只是一个初始化步骤而已。你也可以随机生成k个中心向量作为第一步的代替方案。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1588696444,"ip_address":"","comment_id":214251,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"K-means 算法的第三步：\n计算每个类内节点的向量均值，作为每个类的新的中心向量。\n\n有个问题是：如果计算出来的新的中心向量的值 不在 所有的节点中会怎么进行处理的？ 还有这一步要不要判断 新的中心向量的值 在不在所有的节点中？","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":494000,"discussion_content":"不需要的。中心向量并不是已有节点。\n第一步之所以随机选择已有节点作为中心向量，只是一个初始化步骤而已。你也可以随机生成k个中心向量作为第一步的代替方案。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588696444,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":213237,"user_name":"那时刻","can_delete":false,"product_type":"c1","uid":1150927,"ip_address":"","ucode":"B0D150856C3A4A","user_header":"https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg","comment_is_top":false,"comment_ctime":1588338599,"is_pvip":false,"replies":[{"id":79115,"content":"是这样的，在k-means算法中，我们会生成k个聚类，每个聚类都有自己的聚类中心向量。这些中心向量会存储好。\n然后，当查询向量到来的时候，我们会和这k个聚类中心向量比较，这样就能得到查询向量到每个聚类的距离。最近的那个聚类，就是目标聚类。如果这个目标聚类中的候选集不足，那么距离第二近的聚类，就是次临近的聚类。同理，如果次邻近的这个聚类中候选集还是不足，那么我们可以再去找距离第三近的聚类。依此类推。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1588349511,"ip_address":"","comment_id":213237,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"请问在聚类算法进行相似检索中，对于聚类中的候选集不足 Top K 个，我们还可以再去查询次邻近的聚类，这个临近聚类怎么来寻找呢？是重新计算当前聚类中心点和其它中心点距离么？还是需要额外存储聚类中心点之间的距离？","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493719,"discussion_content":"是这样的，在k-means算法中，我们会生成k个聚类，每个聚类都有自己的聚类中心向量。这些中心向量会存储好。\n然后，当查询向量到来的时候，我们会和这k个聚类中心向量比较，这样就能得到查询向量到每个聚类的距离。最近的那个聚类，就是目标聚类。如果这个目标聚类中的候选集不足，那么距离第二近的聚类，就是次临近的聚类。同理，如果次邻近的这个聚类中候选集还是不足，那么我们可以再去找距离第三近的聚类。依此类推。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588349511,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":372790,"user_name":"ifelse","can_delete":false,"product_type":"c1","uid":2550743,"ip_address":"浙江","ucode":"D0565908C99695","user_header":"https://static001.geekbang.org/account/avatar/00/26/eb/d7/90391376.jpg","comment_is_top":false,"comment_ctime":1681625787,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":3,"score":3,"product_id":100048401,"comment_content":"学习打卡，干货满满","like_count":0},{"had_liked":false,"id":371397,"user_name":"吴怀炜","can_delete":false,"product_type":"c1","uid":3533040,"ip_address":"广东","ucode":"EFB8E2472A898E","user_header":"","comment_is_top":false,"comment_ctime":1679901332,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"老师可以请教个问题吗，就是乘积量化中，原向量需要被拆分的段数，还有子向量聚类的数量，有什么好的方法可以确定吗？使得效果更好一点。","like_count":0},{"had_liked":false,"id":340049,"user_name":"姚文轩","can_delete":false,"product_type":"c1","uid":2866391,"ip_address":"","ucode":"3DDA79FD8C4D62","user_header":"","comment_is_top":false,"comment_ctime":1648555371,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"“这样，求查询子向量和样本子向量的距离，就转换为求查询子向量和对应的聚类中心向量的距离。那我们只需要将样本子向量的聚类 ID 作为 key 去查距离表，就能在 O(1) 的时间代价内知道这个距离了。“\n\nteacher， 这块我可不可以认为是为了压缩存储节约内存而做的精度损失呢？，损失了所有样本向量的具体信息，只保留了样本向量所对应4个聚类中心向量的信息\n\n","like_count":0},{"had_liked":false,"id":323637,"user_name":"尹小白","can_delete":false,"product_type":"c1","uid":1311128,"ip_address":"","ucode":"AA726C8FB04454","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJ5WmAmuxTzKoln814dKIAia1KTUcgSSYzYgDIphlbv5dQpCuxrfRqodtXGMh7QtVUexCZE3CfYAgg/132","comment_is_top":false,"comment_ctime":1638041261,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"或者说没太理解为什么要以聚类中心向量为原点，重新建立向量空间","like_count":0,"discussions":[{"author":{"id":2285106,"avatar":"https://static001.geekbang.org/account/avatar/00/22/de/32/f04d6fbb.jpg","nickname":"gaoyang","note":"","ucode":"8EE36F1C5D4BFE","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":584708,"discussion_content":"+1","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1661055370,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":323635,"user_name":"尹小白","can_delete":false,"product_type":"c1","uid":1311128,"ip_address":"","ucode":"AA726C8FB04454","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJ5WmAmuxTzKoln814dKIAia1KTUcgSSYzYgDIphlbv5dQpCuxrfRqodtXGMh7QtVUexCZE3CfYAgg/132","comment_is_top":false,"comment_ctime":1638039786,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"老师，请问聚类乘积量化加倒排索引中，向量变换的目的是什么呢？","like_count":0}]}