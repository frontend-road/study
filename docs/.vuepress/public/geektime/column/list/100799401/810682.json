{"id":810682,"title":"20｜单表查询：如何评估单表访问成本？","content":"<p>你好，我是俊达。</p><p>上一讲中我们介绍了优化器的工作原理，并介绍了全表扫描和索引范围扫描的成本评估方法。在这一讲中，我们继续来学习单表查询的其他几种访问路径：REF、覆盖索引、MRR、Index Merge。最后，我们还将通过一个真实的业务场景，来讨论怎么给业务创建一个合适的索引。</p><h2>测试表</h2><p>这一讲中，我们依然会使用18讲开头创建的那个测试表，这个表的表结构和统计信息情况如下：</p><pre><code class=\"language-plain\">mysql&gt; show create table tab\\G\n*************************** 1. row ***************************\n       Table: tab\nCreate Table: CREATE TABLE `tab` (\n  `id` int NOT NULL,\n  `a` int NOT NULL,\n  `b` int NOT NULL,\n  `c` int NOT NULL,\n  `padding` varchar(7000) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `idx_abc` (`a`,`b`,`c`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci\n\n\nmysql&gt; select * from mysql.innodb_table_stats where table_name = 'tab'\\G\n*************************** 1. row ***************************\n           database_name: rep\n              table_name: tab\n             last_update: 2024-02-26 17:37:12\n                  n_rows: 9913\n    clustered_index_size: 161\nsum_of_other_index_sizes: 17\n</code></pre><!-- [[[read_end]]] --><h2>Index Dive是怎么工作的？</h2><p>上一讲中提到了，InnoDB使用了Index Dive机制，来评估一个索引区间内有多少行记录。那么Index Dive是如何估算一个索引区间内的记录数呢？大致的步骤是这样的。</p><ol>\n<li>根据where条件，确定range访问的上下边界。range的上下边界，决定了需要在索引中扫描多少记录。</li>\n<li>根据上下边界的值，到索引中查找，并记录每一层边界记录的所在位置。</li>\n<li>从下边界记录开始扫描数据，一直扫描到上边界记录，或者直到扫描的页面数超出限制（8个页面）。</li>\n</ol><p>如果区间内的记录数不多，则可以精确地统计出记录数。如果区间内记录数很多，超过了8个页面，那么InnoDB会估算出记录数。首先，根据已经扫描的索引页面，可以算出平均每个页面有多少行记录。然后，再估算出区间内有多少个页面，两个数字相乘，就得到了记录数的一个估算值。</p><p>InnoDB怎么估算一个区间内有多少页面呢？从索引结构可以看出，上一层页面中，每一个索引条目都指向了下一层的一个页面，那么统计上一层中索引条目的数量，就知道了下一层中区间内的页面数。</p><p><img src=\"https://static001.geekbang.org/resource/image/ee/ae/ee39d06eee95c8d45d2a87e3c73c9aae.jpg?wh=1500x825\" alt=\"图片\"></p><p>Index Dive通常都能获得范围内记录数据比较准确的估计。但是有一个特殊情况。range内的页面数较多时，得到的不是精确的记录数，这需要将行数乘以2，如果乘以2之后的行数超过了表统计信息中记录数的一半，则将记录数设置为总记录数的一半。通过以下几个例子我们可以观察到这种情况。</p><pre><code class=\"language-plain\">-- rows为精确值\nmysql&gt; explain select * from tab where id &gt;=1 and id &lt;= 790;\n+----+-------------+-------+-------+---------------+---------+---------+------+\n| id | select_type | table | type  | possible_keys | key     | key_len | rows |\n+----+-------------+-------+-------+---------------+---------+---------+------+\n|  1 | SIMPLE      | tab   | range | PRIMARY       | PRIMARY | 4       |  790 |\n+----+-------------+-------+-------+---------------+---------+---------+------+\n\n-- rows不精确，按预估行数的2倍返回\nmysql&gt; explain select * from tab where id &gt;=1 and id &lt;= 791;\n+----+-------------+-------+-------+---------------+---------+---------+------+\n| id | select_type | table | type  | possible_keys | key     | key_len | rows |\n+----+-------------+-------+-------+---------------+---------+---------+------+\n|  1 | SIMPLE      | tab   | range | PRIMARY       | PRIMARY | 4       | 1422 |\n+----+-------------+-------+-------+---------------+---------+---------+------+\n\n-- rows不精确，按预估行数的2倍返回\nmysql&gt; explain select * from tab where id &gt;=1 and id &lt;= 2396;\n+----+-------------+-------+-------+---------------+---------+---------+------+\n| id | select_type | table | type  | possible_keys | key     | key_len | rows |\n+----+-------------+-------+-------+---------------+---------+---------+------+\n|  1 | SIMPLE      | tab   | range | PRIMARY       | PRIMARY | 4       | 4952 |\n+----+-------------+-------+-------+---------------+---------+---------+------+\n\n-- rows不精确，预估行数的2倍超过表记录数的一半，按表记录数的一半返回\nmysql&gt; explain select * from tab where id &gt;=1 and id &lt;= 6000;\n+----+-------------+-------+-------+---------------+---------+---------+------+\n| id | select_type | table | type  | possible_keys | key     | key_len | rows |\n+----+-------------+-------+-------+---------------+---------+---------+------+\n|  1 | SIMPLE      | tab   | range | PRIMARY       | PRIMARY | 4       | 4956 |\n+----+-------------+-------+-------+---------------+---------+---------+------+\n</code></pre><h2>REF访问路径</h2><p>REF是MySQL中比较特别的一种访问路径。和RANGE一样，REF访问路径也使用索引来查找数据，但只有当索引字段的匹配条件是等值匹配，并且索引字段上没有使用IN多个值或使用OR条件，类型才是REF。</p><p><img src=\"https://static001.geekbang.org/resource/image/86/bf/86bb45c86b5388e64a30b9c8cd2fe0bf.jpg?wh=916x523\" alt=\"图片\"></p><p>REF执行可以看作是索引范围扫描的一种特殊情况，使用REF访问路径查找数据的步骤大致如下：</p><ol>\n<li>先在索引中定位到第1条满足索引查找条件的记录。</li>\n<li>如果语句没有使用覆盖索引，还需要回表获取整条记录。</li>\n<li>判断记录是否满足查询语句中的其它条件。如果满足条件，则返回记录。</li>\n<li>在索引中获取下一行记录。</li>\n</ol><p>下面是REF访问路径的一个例子：</p><pre><code class=\"language-plain\">mysql&gt; explain select * from tab where a=1;\n\n+----+-------------+-------+------+---------------+---------+---------+-------+------+----------+-------+\n| id | select_type | table | type | possible_keys | key     | key_len | ref   | rows | filtered | Extra |\n+----+-------------+-------+------+---------------+---------+---------+-------+------+----------+-------+\n|  1 | SIMPLE      | tab   | ref  | idx_abc       | idx_abc | 4       | const | 3333 |   100.00 | NULL  |\n+----+-------------+-------+------+---------------+---------+---------+-------+------+----------+-------+\n</code></pre><p>上述执行计划中，type列显示ref，rows列显示3333，表示ref执行计划需要在索引中查找的记录数。</p><p>从optimizer_trace中，查看ref访问的成本为454.05。</p><pre><code class=\"language-plain\">mysql&gt; select * from information_schema.optimizer_trace\\G\n...\n\n\"best_access_path\": {\n  \"considered_access_paths\": [\n    {\n      \"access_type\": \"ref\",\n      \"index\": \"idx_abc\",\n      \"rows\": 3333,\n      \"cost\": 454.05,\n      \"chosen\": true\n    },\n    {\n      \"rows_to_scan\": 9913,\n      \"filtering_effect\": [\n      ],\n      \"final_filtering_effect\": 0.336225,\n      \"access_type\": \"scan\",\n      \"resulting_rows\": 3333,\n      \"cost\": 1031.55,\n      \"chosen\": false\n    }\n  ]\n</code></pre><p>REF访问路径的成本由IO成本和行评估成本组成。</p><p>我们上面这个测试中，使用了非覆盖索引，这种情况下，优化器认为每读取1行记录都需要访问1次IO。同时MySQL对REF访问的成本设置了一个上限worst_seeks，worst_seeks从下面两种情况中取较小值：</p><ul>\n<li>表扫描的IO成本的3倍。</li>\n<li>读取表（聚簇索引）中10%的记录数的成本。优化器将读取1行记录的成本记为1次IO访问的成本。</li>\n</ul><p>同时优化器还设置了worst_seeks的下限min_worst_seek，min_worst_seek设置为读取2条主键记录的成本，也就是2次IO的成本。</p><p>非覆盖索引的情况下，ref访问的成本使用python代码表示：</p><pre><code class=\"language-plain\">def worst_seeks(rows, n_rows, clustered_index_size):\n    worst_seek1 = 3 * clustered_index_size\n    worst_seek2 = 0.1 * n_rows\n    min_worst_seek = 2\n    worst_seek = min(worst_seek1, worst_seek2)\n    if worst_seek &lt; min_worst_seek:\n        worst_seek = min_worst_seek\n    return worst_seek\n\ndef ref_cost_normal_index(rows, n_rows, clustered_index_size, in_mem_pct):\n    worst_seek = worst_seeks(rows, n_rows, clustered_index_size)\n    if rows &gt; worst_seek:\n        result = worst_seek\n    else:\n        result = rows\n    return result * page_read_cost(in_mem_pct)\n\ndef ref_cost_normal(rows, n_rows, clustered_index_size, in_mem_pct=1.0):\n    io_cost = ref_cost_normal_index(rows, n_rows, clustered_index_size, in_mem_pct)\n    cpu_cost = row_evaluate_cost(rows)\n    return io_cost + cpu_cost\n</code></pre><p>上面的代码中，参数total_rows和clustered_index_size的值从表统计信息中获取，分别为表的总行数和聚簇索引的大小。</p><p>在我们的测试案例中，表统计信息中可知，总行数为9913，聚簇索引的大小为161。</p><pre><code class=\"language-plain\">mysql&gt; select * from mysql.innodb_table_stats where table_name = 'tab'\\G\n*************************** 1. row ***************************\n           database_name: rep\n              table_name: tab\n             last_update: 2024-08-22 14:18:26\n                  n_rows: 9913\n    clustered_index_size: 161\nsum_of_other_index_sizes: 17\n</code></pre><p>扫描的行数为3333，因此得到ref访问的总成本为454.05。</p><pre><code class=\"language-plain\">&gt;&gt;&gt; ref_cost_normal(rows=3333, n_rows=9913, clustered_index_size=161)\n454.05\n</code></pre><h3>一个特殊的例子</h3><p>我们给前面的测试SQL增加一个过滤条件，发现这种情况下，MySQL直接使用了全表扫描。</p><pre><code class=\"language-plain\">mysql&gt; explain select * from tab where a=1 and b &lt;= 9000;\n+----+-------------+-------+------+---------------+------+---------+------+------+----------+-------------+\n| id | select_type | table | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra       |\n+----+-------------+-------+------+---------------+------+---------+------+------+----------+-------------+\n|  1 | SIMPLE      | tab   | ALL  | idx_abc       | NULL | NULL    | NULL | 9913 |    30.26 | Using where |\n+----+-------------+-------+------+---------------+------+---------+------+------+----------+-------------+\n</code></pre><p>但是根据测试表tab的索引idx_abc(a,b,c)的结构看，增添一个过滤条件，理论上是能提高效率的，为什么优化器反而放弃了使用这个索引呢？</p><p>我们来看一下优化器跟踪。全表扫描的成本是1033.65。</p><pre><code class=\"language-plain\">\"table_scan\": {\n  \"rows\": 9913,\n  \"cost\": 1033.65\n}\n</code></pre><p>索引range访问的成本是1050.26，超过了全表扫描的成本，因此没有采用。</p><pre><code class=\"language-plain\">\"range_scan_alternatives\": [\n  {\n    \"index\": \"idx_abc\",\n    \"ranges\": [\n      \"a = 1 AND b &lt;= 9000\"\n    ],\n    \"index_dives_for_eq_ranges\": true,\n    \"rowid_ordered\": false,\n    \"using_mrr\": false,\n    \"index_only\": false,\n    \"in_memory\": 0.357143,\n    \"rows\": 3000,\n    \"cost\": 1050.26,\n    \"chosen\": false,\n    \"cause\": \"cost\"\n  }\n]\n</code></pre><p>为什么连ref访问路径也没有被采用呢？这里优化器使用了一条规则：<strong>因为range访问路径和ref使用了同一个索引，但是range使用了更多的索引字段，因此优先选择使用range。</strong>注意优化器跟踪里显示的原因“range_uses_more_keyparts”。</p><pre><code class=\"language-plain\">\"best_access_path\": {\n  \"considered_access_paths\": [\n    {\n      \"access_type\": \"ref\",\n      \"index\": \"idx_abc\",\n      \"chosen\": false,\n      \"cause\": \"range_uses_more_keyparts\"\n    },\n    {\n      \"rows_to_scan\": 9913,\n      \"filtering_effect\": [\n      ],\n      \"final_filtering_effect\": 0.302633,\n      \"access_type\": \"scan\",\n      \"resulting_rows\": 3000,\n      \"cost\": 1031.55,\n      \"chosen\": true\n    }\n  ]\n}\n</code></pre><p>实际上在5.7版本中，这种情况下优化器还是使用了REF。</p><pre><code class=\"language-plain\">-- 5.7.38-log\nmysql&gt; explain select * from tab where a=1 and b &lt;= 9000;\n+----+-------------+-------+------+---------------+---------+---------+-------+------+----------+-----------------------+\n| id | select_type | table | type | possible_keys | key     | key_len | ref   | rows | filtered | Extra                 |\n+----+-------------+-------+------+---------------+---------+---------+-------+------+----------+-----------------------+\n|  1 | SIMPLE      | tab   | ref  | idx_abc       | idx_abc | 4       | const | 3336 |    33.33 | Using index condition |\n+----+-------------+-------+------+---------------+---------+---------+-------+------+----------+-----------------------+\n</code></pre><p>我们再来对比下下面这2个SQL的执行计划，这2个SQL基本一样，只是limit相差了1，但是一个SQL使用了索引range访问，另一个SQL使用了全表扫描。</p><pre><code class=\"language-plain\">mysql&gt; explain select * from tab where a=1 and b &lt;= 9000 order by b limit 885;\n+----+-------------+-------+-------+---------------+---------+---------+------+------+----------+-----------------------+\n| id | select_type | table | type  | possible_keys | key     | key_len | ref  | rows | filtered | Extra                 |\n+----+-------------+-------+-------+---------------+---------+---------+------+------+----------+-----------------------+\n|  1 | SIMPLE      | tab   | range | idx_abc       | idx_abc | 8       | NULL | 3000 |   100.00 | Using index condition |\n+----+-------------+-------+-------+---------------+---------+---------+------+------+----------+-----------------------+\n\n\nmysql&gt; explain select * from tab where a=1 and b &lt;= 9000 order by b limit 886;\n+----+-------------+-------+------+---------------+------+---------+------+------+----------+-----------------------------+\n| id | select_type | table | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra                       |\n+----+-------------+-------+------+---------------+------+---------+------+------+----------+-----------------------------+\n|  1 | SIMPLE      | tab   | ALL  | idx_abc       | NULL | NULL    | NULL | 9913 |    30.26 | Using where; Using filesort |\n+----+-------------+-------+------+---------------+------+---------+------+------+----------+-----------------------------+\n</code></pre><p>这主要是在8.0的优化器中，对于order by limit的情况，做了一些额外的考虑。当可以使用某个索引的有序性来避免排序，并且limit的数量比较少，少到扫描索引区间的成本比表扫描更低时，优化器会选择使用这个索引。</p><p>在5.7中测试，并没有出现这种情况。这也提醒我们，大版本升级后，可能会由于优化器内部实现的变化，导致SQL的执行计划发生变化。这也是升级前需要使用真实业务场景做好测试的一个重要原因。</p><h2>覆盖索引</h2><p>如果查询使用了覆盖索引，那么执行过程中不需要回表，这种情况下，成本的计算方式有一些变化。REF和Range访问路径都有可能使用覆盖索引。</p><h3>REF使用覆盖索引</h3><p>下面这个例子中，REF访问路径使用了覆盖索引，注意到Extra中的“using index”。</p><pre><code class=\"language-plain\">mysql&gt; explain select a,b,c from tab where a = 1;\n+----+-------------+-------+------+---------------+---------+---------+-------+------+----------+-------------+\n| id | select_type | table | type | possible_keys | key     | key_len | ref   | rows | filtered | Extra       |\n+----+-------------+-------+------+---------------+---------+---------+-------+------+----------+-------------+\n|  1 | SIMPLE      | tab   | ref  | idx_abc       | idx_abc | 4       | const | 3333 |   100.00 | Using index |\n+----+-------------+-------+------+---------------+---------+---------+-------+------+----------+-------------+\n</code></pre><p>使用覆盖索引后，执行计划的成本更低。</p><pre><code class=\"language-plain\">\"analyzing_range_alternatives\": {\n  \"range_scan_alternatives\": [\n    {\n      \"index\": \"idx_abc\",\n      \"ranges\": [\n        \"a = 1\"\n      ],\n      \"index_dives_for_eq_ranges\": true,\n      \"rowid_ordered\": false,\n      \"using_mrr\": false,\n      \"index_only\": true,\n      \"in_memory\": 1,\n      \"rows\": 3333,\n      \"cost\": 335.184,\n      \"chosen\": true\n    }\n  ]\n</code></pre><p>由于使用了覆盖索引，不需要回表，因此需要访问的数据页数就是索引占用的页面数。</p><p>索引页面数的计算方法，我使用下面这段Python代码来表示。</p><pre><code class=\"language-plain\">BLOCK_SIZE = 16384\nMEMORY_BLOCK_READ_COST = 0.25\nIO_BLOCK_READ_COST = 1\nROW_EVALUATE_COST = 0.1\n    \ndef index_scan_pages(rows, key_len, ref_len):\n    keys_per_block = BLOCK_SIZE / 2 / (key_len + ref_len) + 1\n    index_blocks = 1.0* (rows + keys_per_block - 1) / keys_per_block\n    return index_blocks\n    \ndef page_read_cost(in_mem_pct):\n    result = MEMORY_BLOCK_READ_COST * in_mem_pct + IO_BLOCK_READ_COST * (1-in_mem_pct)\n    return result\n\ndef index_scan_io_cost(rows, key_len, ref_len, in_mem_pct):\n    pages = index_scan_pages(rows, key_len, ref_len)\n    read_cost = page_read_cost(in_mem_pct)\n    return pages * read_cost\n\ndef covering_index_cost(rows, key_len, ref_len, in_mem_pct):\n    result = index_scan_io_cost(rows, key_len, ref_len, in_mem_pct) + row_eval_cost(rows)\n    return result + 0.01\n    \n</code></pre><p>在我们的测试例子中，key_len为12，ref_len为4，ref访问的记录数为3333，因此REF总成本为：</p><pre><code class=\"language-plain\">&gt;&gt;&gt; covering_index_cost(rows=3333, key_len=12, ref_len=4, in_mem_pct=1)\n335.1837816764133\n</code></pre><h3>Range使用覆盖索引</h3><p>下面是Range查询使用覆盖索引的一个例子，注意到行数为4944，Extra中有“Using index”。</p><pre><code class=\"language-plain\">mysql&gt; explain select a,b,c from tab where a &gt;=0 and a &lt;= 2;\n+----+-------------+-------+-------+---------------+---------+---------+------+------+----------+--------------------------+\n| id | select_type | table | type  | possible_keys | key     | key_len | ref  | rows | filtered | Extra                    |\n+----+-------------+-------+-------+---------------+---------+---------+------+------+----------+--------------------------+\n|  1 | SIMPLE      | tab   | range | idx_abc       | idx_abc | 4       | NULL | 4944 |   100.00 | Using where; Using index |\n+----+-------------+-------+-------+---------------+---------+---------+------+------+----------+--------------------------+\n</code></pre><pre><code class=\"language-plain\">\"range_scan_alternatives\": [\n  {\n    \"index\": \"idx_abc\",\n    \"ranges\": [\n      \"0 &lt;= a &lt;= 2\"\n    ],\n    \"index_dives_for_eq_ranges\": true,\n    \"rowid_ordered\": false,\n    \"using_mrr\": false,\n    \"index_only\": true,\n    \"in_memory\": 1,\n    \"rows\": 4944,\n    \"cost\": 497.069,\n    \"chosen\": true\n  }\n</code></pre><pre><code class=\"language-plain\">&gt;&gt;&gt; covering_index_cost(rows=4944, key_len=12, ref_len=4, in_mem_pct=1)\n497.06886939571154\n</code></pre><h3>使用主键访问</h3><p>直接使用主键来进行REF或Range访问，可以看作是覆盖索引的一种特殊情况。下面的查询使用主键进行range访问，区间内的记录数为4944。</p><pre><code class=\"language-plain\">mysql&gt;  explain select * from tab where id between 1000 and 4000;\n+----+-------------+-------+-------+---------------+---------+---------+------+------+----------+-------------+\n| id | select_type | table | type  | possible_keys | key     | key_len | ref  | rows | filtered | Extra       |\n+----+-------------+-------+-------+---------------+---------+---------+------+------+----------+-------------+\n|  1 | SIMPLE      | tab   | range | PRIMARY       | PRIMARY | 4       | NULL | 4944 |   100.00 | Using where |\n+----+-------------+-------+-------+---------------+---------+---------+------+------+----------+-------------+\n</code></pre><p>从optimizer trace中可以看到执行计划的成本为496.415。</p><pre><code class=\"language-plain\">\"range_scan_alternatives\": [\n  {\n    \"index\": \"PRIMARY\",\n    \"ranges\": [\n      \"1000 &lt;= id &lt;= 4000\"\n    ],\n    \"index_dives_for_eq_ranges\": true,\n    \"rowid_ordered\": true,\n    \"using_mrr\": false,\n    \"index_only\": false,\n    \"in_memory\": 1,\n    \"rows\": 4944,\n    \"cost\": 496.415,\n    \"chosen\": true\n  }\n</code></pre><p>使用主键进行range查询时，查询的成本和需要扫描的聚簇索引页面数相关。聚簇索引页面数的计算方式大致是这样的。</p><ol>\n<li>先评估表中记录数的一个上限upper_bound_rows。</li>\n</ol><p>这里优化器没有使用统计信息中的表记录行数，而是使用了以下公式来估算记录数：upper_bound_rows = 2 * stat_n_leaf_pages * block_size / min_record_length</p><p>上面的公式中，block_size为InnoDB页面大小，默认16K。stat_n_leaf_pages为索引叶子节点页面数的一个预估值。InnoDB将索引的叶子节点存放到一个单独的段，所以可以从段的空间管理信息中获取到页面数。min_record_length为一行记录至少需要占用的空间，根据行记录格式计算得到。InnoDB一行记录由记录头部信息、用户字段、InnoDB隐藏字段等信息组成，具体记录格式后续会在InnoDB存储引擎篇中介绍。</p><ol start=\"2\">\n<li>根据需要访问的记录数来计算页面数。</li>\n</ol><p>页面数由以下公式计算得出：页面数 = 1 + rows / upper_bound_rows * stat_clustered_index_size</p><p>上面公式中，stat_clustered_index_size为统计信息中主键的页面数。优化器根据待访问的记录数占整个表记录数的比例来估算IO成本。</p><p>使用主键进行ref访问的成本计算由以下代码表示：</p><pre><code class=\"language-plain\">BLOCK_SIZE = 16384\ndef primary_key_scan_pages(rows, leaf_pages, min_record_len, clustered_index_size):\n    upper_bound_rows = 2 * leaf_pages * BLOCK_SIZE / min_record_len\n    if rows &gt; upper_bound_rows:\n        pages = clustered_index_size\n    else:\n        pages = 1 + 1.0 * rows / upper_bound_rows * clustered_index_size\n    return pages\n    \ndef primary_key_scan_cost(rows, leaf_pages, min_record_len, clustered_index_size, in_mem_pct):\n    scan_pages = primary_key_scan_pages(rows, leaf_pages, min_record_len, clustered_index_size)\n    return scan_pages * page_read_cost(in_mem_pct)\n\ndef range_clustered_cost(rows, leaf_pages, min_record_len,\n    clustered_index_size, in_mem_pct):\n    io_cost = primary_key_scan_cost(rows, leaf_pages, min_record_len,\n        clustered_index_size, in_mem_pct)\n    result = io_cost + row_eval_cost(rows) + 0.01\n    return result\n\ndef range_clustered_cost_total(rows, leaf_pages, min_record_len,\n    clustered_index_size, in_mem_pct):\n    range_cost = range_clustered_cost(rows, leaf_pages, min_record_len,\n    clustered_index_size, in_mem_pct)\n    return range_cost + row_eval_cost(rows)\n</code></pre><p>在我们的测试案例中，rows为4944，leaf_pages为128，min_record_len为37，clustered_index_size为161，表在内存中缓存的比例为100%，因此使用主键进行RANGE访问的成本为：</p><pre><code class=\"language-plain\">&gt;&gt;&gt; range_clustered_cost(rows=4944, leaf_pages=128, min_record_len=37, clustered_index_size=161, in_mem_pct=1.0)\n496.4154495011424\n</code></pre><p>上面的leaf_pages、min_record_len实际上是我从GDB调试器中取到的。min_record_len大概是这么计算的：表里有4个非空固定长度的int字段，占用16字节，InnoDB内部字段db_trx_id和db_roll_ptr共占用13字节，行首有5字节的固定长度，varchar字段需要2字节记录长度，以及1个字节来记录字段数据是否为null，因此总共需要16 + 13 + 5 + 2 + 1 = 37字节。</p><pre><code class=\"language-plain\">CREATE TABLE `tab` (\n  `id` int NOT NULL,\n  `a` int NOT NULL,\n  `b` int NOT NULL,\n  `c` int NOT NULL,\n  `padding` varchar(7000) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `idx_abc` (`a`,`b`,`c`)\n) ENGINE=InnoDB\n</code></pre><h2>关于MRR</h2><p>MRR是DISK SWEEP Multi-Range Read的简称。在常规的range访问路径下，通过索引获取到的ROWID是无序的，根据这些ROWID回表获取数据时，对表来说，就是随机访问，而随机访问可能带来更多的IO操作。MRR访问路径对这种场景进行了优化。从索引中获取到一批ROWID时，先对ROWID进行排序，然后按顺序回表获取数据，以此来达到减少随机IO的目的。</p><p><img src=\"https://static001.geekbang.org/resource/image/02/87/022ba695a2d5c208d52b5fbe6939f587.jpg?wh=1648x437\" alt=\"图片\"></p><p>MRR访问路径会先在MRR buffer中对ROWID进行排序。MRR buffer的大小由参数read_rnd_buffer_size控制。MRR访问路径的成本计算中，加入了对ROWID进行排序的成本。按ROWID顺序回表时，IO成本的计算方式也有一些调整。不过这里我们就不展开讨论MRR成本的计算细节了。</p><p>优化器使用MRR有一些额外的条件。</p><ol>\n<li>表的大小超过InnoDB Buffer Pool的大小。</li>\n<li>访问的行数超过50。</li>\n<li>optimizer_switch中开启mrr_cost_based选项，MRR成本比普通的Range成本低时，才会使用MRR。</li>\n<li>optimizer_switch中开启mrr选项。</li>\n</ol><p>如果查询使用了MRR或BKA提示，则不需要满足以上几点，也可以使用MRR访问路径。下面的例子中，我们使用MRR了提示，执行计划Extra列中有Using MRR字样，说明使用了MRR访问路径。</p><pre><code class=\"language-plain\">mysql&gt; explain select /*+ MRR(tab) */ * from tab where a between 0.9 and 1.1;\n+----+-------------+-------+-------+---------------+---------+---------+------+----------------------------------+\n| id | select_type | table | type  | possible_keys | key     | key_len | rows | Extra                            |\n+----+-------------+-------+-------+---------------+---------+---------+------+----------------------------------+\n|  1 | SIMPLE      | tab   | range | idx_abc       | idx_abc | 4       | 3333 | Using index condition; Using MRR |\n+----+-------------+-------+-------+---------------+---------+---------+------+----------------------------------+\t\n</code></pre><h2>索引合并（index_merge）</h2><p>在第18讲中，我们提到了索引合并的几种情况。一般在真实业务中，如果遇到了索引合并，通常说明查询的性能不是很好，我们需要先考虑是否能通过一些方法来避免索引合并，比如根据查询条件创建合适的联合索引，或者将where语句的OR条件拆分成多个SQL，或者使用union all。这里我们使用t_merge表，对索引合并进行一些基本的介绍，生成这个表和数据的SQL可以在第18讲开头找到，这里我就不重复了。</p><p>这个表的统计信息如下：</p><pre><code class=\"language-plain\">mysql&gt; select * from mysql.innodb_table_stats where table_name = 't_merge'\\G\n*************************** 1. row ***************************\n           database_name: rep\n              table_name: t_merge\n             last_update: 2024-04-07 14:43:57\n                  n_rows: 9737\n    clustered_index_size: 97\nsum_of_other_index_sizes: 51\n\nmysql&gt; show indexes from t_merge;\n+---------+------------+----------+--------------+-------------+-------------+\n| Table   | Non_unique | Key_name | Seq_in_index | Column_name | Cardinality |\n+---------+------------+----------+--------------+-------------+-------------+\n| t_merge |          0 | PRIMARY  |            1 | id          |        9737 |\n| t_merge |          1 | idx_ad   |            1 | a           |           3 |\n| t_merge |          1 | idx_ad   |            2 | d           |          30 |\n| t_merge |          1 | idx_bd   |            1 | b           |          17 |\n| t_merge |          1 | idx_bd   |            2 | d           |         170 |\n| t_merge |          1 | idx_cd   |            1 | c           |          19 |\n| t_merge |          1 | idx_cd   |            2 | d           |         190 |\n+---------+------------+----------+--------------+-------------+-------------+\n</code></pre><p>索引合并访问路径会使用多个索引来获取ROWID，对ROWID取交集或并集操作后，再回表获取数据。index_merge分三种情况：</p><ul>\n<li>intersect：多个索引的条件使用AND相连</li>\n<li>union：多个索引的条件使用OR相连</li>\n<li>sort_union：多个索引的条件使用OR相连</li>\n</ul><h3>Index intersect</h3><p>Index intersect大致按以下步骤执行：</p><ol>\n<li>从index 1读取满足索引条件的记录。</li>\n<li>从index 2读取满足索引条件的记录。</li>\n<li>将步骤1、步骤2获取到的记录求交集。</li>\n<li>根据步骤3得到的ROWID回表获取数据。</li>\n<li>判断记录是否满足其它额外的条件。</li>\n</ol><p><img src=\"https://static001.geekbang.org/resource/image/77/5e/774d965672fe63cbd27a483cb2500a5e.jpg?wh=1210x665\" alt=\"图片\"></p><p>使用Index Intersection有一个前提条件，就是参与到intersection的索引，其索引字段的条件都要传入。下面的这个测试SQL中，使用了索引 idx_bd, idx_ad 进行intersect操作，注意这2个索引的key_len都是8。如果查询中去掉d=1这个条件，就无法使用index intersection。</p><pre><code class=\"language-plain\">mysql&gt; explain select * from t_merge where a=1 and b=1  and d=1\\G\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: t_merge\n   partitions: NULL\n         type: index_merge\npossible_keys: idx_ad,idx_bd\n          key: idx_bd,idx_ad\n      key_len: 8,8\n          ref: NULL\n         rows: 18\n     filtered: 95.20\n        Extra: Using intersect(idx_bd,idx_ad); Using where\n</code></pre><p>Index Intersect的成本由索引扫描成本、回表成本、行评估成本组成，可以由以下公式表示：<br>\nIndex Intersect成本 = 索引扫描成本 + 回表成本 + 行评估成本</p><p>具体的计算方式这里就不再展开讨论了。</p><h3>Index union</h3><p>Index Union大致按如下步骤执行：</p><ol>\n<li>按索引条件读取索引记录</li>\n<li>对多个索引的记录合并，去重。</li>\n<li>回表查询数据</li>\n</ol><p><img src=\"https://static001.geekbang.org/resource/image/9c/93/9cb0844c611b80d207bc97d256600193.jpg?wh=1222x658\" alt=\"图片\"></p><p>如果第一步从索引中取到记录已经按ROWID顺序排列，则可以直接进行合并去重，这种情况下执行计划Extra显示“Using union”。如果第一步取到的记录没有按ROWID顺序排列，则需要先进行排序，然后再进行合并去重，这种情况下执行计划Extra中会显示“Using sort_union”。</p><p>使用Index Union的一个例子：</p><pre><code class=\"language-plain\">mysql&gt;  explain select * from t_merge where (c=1 and d=1) or (b=1 and d=1) \\G\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: t_merge\n   partitions: NULL\n         type: index_merge\npossible_keys: idx_bd,idx_cd\n          key: idx_cd,idx_bd\n      key_len: 8,8\n          ref: NULL\n         rows: 108\n     filtered: 100.00\n        Extra: Using union(idx_cd,idx_bd); Using where\n</code></pre><p>和Index Intersect成本计算方式类似，Index Union的成本可以由以下公式来表示：<br>\n$$Index Union成本 = 索引扫描成本 + 求并集成本 + 回表成本 + 行评估成本$$</p><p>这个公式中多了一项集合求并集的成本，具体的计算公式这里也不展开讨论了。</p><h3>Index sort_union</h3><p>Index sort_union的执行方式和Index union类似，但是使用sort_union时，从各个索引获取到的ROWID需要先排序，增加了排序的成本。下面是使用index sort_union的一个例子：</p><pre><code class=\"language-plain\">mysql&gt; explain select * from t_merge where (c=1 and d between 1 and 5) or (b=1 and d=1)\\G\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: t_merge\n   partitions: NULL\n         type: index_merge\npossible_keys: idx_bd,idx_cd\n          key: idx_cd,idx_bd\n      key_len: 8,8\n          ref: NULL\n         rows: 312\n     filtered: 100.00\n        Extra: Using sort_union(idx_cd,idx_bd); Using where\n1 row in set, 1 warning (2.88 sec)\n</code></pre><p>注意上述执行计划中Extra列显示的“Using sort_union”。<br>\n$$Index Sort Union 成本 = 索引扫描成本 + ROWID排序去重成本 + 回表成本 + 行评估成本$$</p><p>和Index Union相比，这里多了ROWID排序去重的成本。排序的成本，还和参数sort_buffer_size的设置有关，具体的计算方式也不展开讨论了。</p><h2>如何创建高效的索引？</h2><p>关于MySQL索引的内容，到这里基本上都介绍完了。那么，在面对一个具体的业务场景时，我们应该怎么来创建合适、高效的索引呢？接下来我们以电商系统中一个很典型的业务场景，订单列表为例，来讨论创建索引的一些关键点。</p><p>下面就是一个订单列表页面的一个工具栏，商家和买家都需要查看订单列表。</p><p><img src=\"https://static001.geekbang.org/resource/image/10/03/101f3388d07488ee06baf31ed8bee003.jpg?wh=1120x305\" alt=\"图片\"></p><p>订单列表使用最多的几个场景包括：</p><ul>\n<li>查看所有订单</li>\n<li>查看某个状态的订单（待付款、待发货、待收货、待评价、退款）</li>\n<li>搜索某个商品相关的订单</li>\n</ul><p>一般都会按订单的创建时间来展示订单信息，最新创建的订单排在最前面。</p><p>下面是一个假想的订单表。</p><pre><code class=\"language-plain\">create table t_order_detail(\n  id bigint unsigned not null,\n  seller_id bigint not null,\n  buyer_id bigint not null,\n  create_time datetime not null,\n  modify_time datetime not null,\n  order_status tinyint not null comment '订单状态: 未付款、已付款、已发货、已确认收货、订单关闭',\n  refund_status tinyint not null comment '退款状态：未退款、退款中、退款完成',\n  goods_id bigint comment '商品ID',\n  goods_title varchar(255) comment '商品名称',\n  buy_num int comment '购买数量',\n  goods_price decimal(20,4) comment '商品单价',\n  features varchar(256) comment '商品规格',\n  discount decimal(20,4) comment '优惠金额',\n  logis_id bigint comment '物流订单编号',\n  is_deleted tinyint not null comment '是否删除',\n  descrition varchar(512) comment '描述信息',\n  primary key(id),\n  key idx_sellerid_createtime_sta(seller_id, create_time, order_status, refund_status),\n  key idx_buyerid_createtime_sta(buyer_id, create_time, order_status, refund_status)\n) engine=innodb;\n</code></pre><p>订单列表有这么几类SQL：</p><pre><code class=\"language-plain\">select count(*) from t_order_detail where buyer_id = ? and create_time &gt;= date_sub(now(), interval 90 day)  and order_status in (?) and refund_status in (?);\nselect * from t_order_detail where buyer_id = ? and create_time &gt;= date_sub(now(), interval 90 day) and order_status in (?) and refund_status in (?) order by create_time desc limit M, N;\nselect count(*) from t_order_detail where seller_id = ? and create_time &gt;= date_sub(now(), interval 90 day)  and order_status in (?) and refund_status in (?);\nselect * from t_order_detail where seller_id = ? and create_time &gt;= date_sub(now(), interval 90 day) and order_status in (?) and refund_status in (?) order by create_time desc limit M, N;\n</code></pre><p>上面的SQL中，order_status和refund_status可能传，也可能不传，主要看用户在前端选择了哪些条件。</p><p>有一些大商家，订单的数量可能非常多，达到百万甚至千万级别。有一些大买家也可能会有大量的订单，可能有上万单。</p><p>我们需要考虑几个问题：</p><ul>\n<li>如何降低count(*)的代价？</li>\n<li>如何降低order by的代价？</li>\n<li>翻页到很后面时，如何降低查询的代价？</li>\n</ul><p>基于索引访问的特征，我们可以这么来设计：</p><ol>\n<li>对于count(<em>)查询，我们利用覆盖索引、索引条件下推等特性，减少大量的回表操作。假设某个用户下有一万条订单数据，索引条目长度控制在五十字节内，那么保存这些数据大约需要三十多个索引页面。如果要回表，那么执行一次count(</em>)需要访问一万多个数据页，不回表，则只需要访问三十多个数据页。</li>\n<li>对于order by，利用索引的有序性来避免排序。考虑到order_status、refund_status可能不传，也可能传多个，需要将create_time放在索引的第二个字段，否则就无法避免排序了。这里也请你思考一下，如果无法避免排序，对查询的性能会有什么影响？</li>\n<li>对于翻页查询，一个常用的技巧是先在索引上获取记录主键ID的分页数据，然后再关联原表获取数据。</li>\n</ol><p>查询改成下面这个形式。你可以思考一下，查询改写前后，在执行时会有什么区别。</p><pre><code class=\"language-plain\">select t2.* from (\n    select id from t_order_detail \n\twhere  seller_id = ? \n\tand create_time &gt;= date_sub(now(), interval 90 day) \n\tand order_status in (?) \n\tand refund_status in (?) \n\torder by create_time desc limit M, N)\n) t1 straight_join t_order_detail t2\nwhere t1.id = t2.id\n</code></pre><p>下面是使用索引进行分页操作的一个示意图，可以减少回表的次数。</p><p><img src=\"https://static001.geekbang.org/resource/image/27/5c/27a1bb7529c127c5cbca8f08ce70635c.jpg?wh=1196x566\" alt=\"图片\"></p><p>最后还需要提一点，虽然使用覆盖索引可以减少回表的次数，但是由于InnoDB MVCC实现机制的原因，即使用了覆盖索引，也是有可能要回表的，因为构建记录的一致性版本时，需要用到聚簇索引中的隐藏字段db_roll_ptr、db_trx_id，这一部分的内容我们会在InnoDB存储引擎篇里再做详细介绍。</p><h2>总结</h2><p>结合上一讲的内容，我们已经把单个表的访问做了比较全面地介绍。索引在SQL优化中有非常重要的作用。平时在建索引时，有几个问题需要考虑，一是应该把哪些字段加到索引中，二是索引中字段的顺序如何排列。</p><p>我们需要考虑索引的过滤性，这里是指索引前缀字段组合的过滤性。还要根据业务的数据分布情况和访问需求，综合考虑。每新增一个索引都会带来额外的维护成本，因此我们要避免创建重复的索引。尽量使用一些精炼的索引来满足业务的查询需求。</p><h2>思考题</h2><p>回到我们前面那个订单列表的场景，有一天，产品决定要做一个订单删除的功能，方便用户将一些不想让人看到订单隐藏起来。相应地，业务SQL需要做一些相应的调整，where条件中需要增加is_deleted的条件。</p><pre><code class=\"language-plain\">select count(*)\nfrom t_order_detail\nwhere seller_id = ? \nand order_status in (?) \nand refund_status in(?) \nand is_deleted=0;\n\n\nselect t2.* from (\n  select id\n  from t_order_detail\n  where seller_id = ? \n  and order_status in (?) \n  and refund_status in(?) \n  and is_deleted=0\n  order by create_time\nlimit M, N) t1 straight_join t_order_detail t2\nwhere t1.id = t2.id;\n</code></pre><p>作为一名研发人员，或者是一名DBA，接到这个需求后，在数据库这一层，有哪些需要考虑的地方？为了实现这个功能，你会怎样做？</p><p>期待你的思考，欢迎在留言区中与我交流。如果今天的课程让你有所收获，也欢迎转发给有需要的朋友。我们下节课再见！</p>","neighbors":{"left":{"article_title":"19｜优化器成本模型：优化器为什么选择这个执行计划？","id":810671},"right":{"article_title":"21｜表连接如何执行？","id":813345}},"comments":[{"had_liked":false,"id":396110,"user_name":"笙 鸢","can_delete":false,"product_type":"c1","uid":3951358,"ip_address":"上海","ucode":"477AF524212C6D","user_header":"https://static001.geekbang.org/account/avatar/00/3c/4a/fe/7b6bd101.jpg","comment_is_top":false,"comment_ctime":1733143447,"is_pvip":false,"replies":[{"id":143816,"content":"是的，这里和演示例子不一致了。这就修改过来。\n\n参与到intersect的索引，可以从Extra中看出来，\nExtra: Using intersect(idx_bd,idx_ad); ","user_name":"作者回复","user_name_real":"编辑","uid":3898827,"ctime":1733217964,"ip_address":"浙江","comment_id":396110,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100799401,"comment_content":"老师，index intersect这块“使用了索引 idx_b, idx_c”，好像有点问题吧","like_count":0,"discussions":[{"author":{"id":3898827,"avatar":"https://static001.geekbang.org/account/avatar/00/3b/7d/cb/fa3dae58.jpg","nickname":"俊达","note":"","ucode":"F79BF9651AD086","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":654666,"discussion_content":"是的，这里和演示例子不一致了。这就修改过来。\n\n参与到intersect的索引，可以从Extra中看出来，\nExtra: Using intersect(idx_bd,idx_ad); ","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1733217964,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":396107,"user_name":"笙 鸢","can_delete":false,"product_type":"c1","uid":3951358,"ip_address":"上海","ucode":"477AF524212C6D","user_header":"https://static001.geekbang.org/account/avatar/00/3c/4a/fe/7b6bd101.jpg","comment_is_top":false,"comment_ctime":1733132590,"is_pvip":false,"replies":[{"id":143817,"content":"第二个函数也是有用的。可以看一下执行计划最终的cost，实际上就是range成本加上行评估成本。\n\n比如这个例子：\nmysql&gt;  explain  format=json select * from tab where id between 1000 and 4000;\n{\n  &quot;query_block&quot;: {\n    &quot;select_id&quot;: 1,\n    &quot;cost_info&quot;: {\n      &quot;query_cost&quot;: &quot;986.68&quot;\n    },\n    &quot;table&quot;: {\n      &quot;table_name&quot;: &quot;tab&quot;,\n      &quot;access_type&quot;: &quot;range&quot;,\n      &quot;possible_keys&quot;: [\n        &quot;PRIMARY&quot;\n      ],\n      &quot;key&quot;: &quot;PRIMARY&quot;,\n      &quot;used_key_parts&quot;: [\n        &quot;id&quot;\n      ],\n      &quot;key_length&quot;: &quot;4&quot;,\n      &quot;rows_examined_per_scan&quot;: 4902,\n      &quot;rows_produced_per_join&quot;: 4902,\n      &quot;filtered&quot;: &quot;100.00&quot;,\n      &quot;cost_info&quot;: {\n        &quot;read_cost&quot;: &quot;496.48&quot;,\n        &quot;eval_cost&quot;: &quot;490.20&quot;,\n        &quot;prefix_cost&quot;: &quot;986.68&quot;,\n        &quot;data_read_per_join&quot;: &quot;131M&quot;\n      },\n      &quot;used_columns&quot;: [\n        &quot;id&quot;,\n        &quot;a&quot;,\n        &quot;b&quot;,\n        &quot;c&quot;,\n        &quot;padding&quot;\n      ],\n      &quot;attached_condition&quot;: &quot;(`rep`.`tab`.`id` between 1000 and 4000)&quot;\n    }\n  }\n}\n\n从代码看，计算执行最终的cost时，row_eval_cost确实是加了2遍。","user_name":"作者回复","user_name_real":"编辑","uid":3898827,"ctime":1733219424,"ip_address":"浙江","comment_id":396107,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100799401,"comment_content":"def range_clustered_cost(rows, leaf_pages, min_record_len, clustered_index_size, in_mem_pct): io_cost = primary_key_scan_cost(rows, leaf_pages, min_record_len, clustered_index_size, in_mem_pct) result = io_cost + row_eval_cost(rows) + 0.01 return result\ndef range_clustered_cost_total(rows, leaf_pages, min_record_len, clustered_index_size, in_mem_pct): range_cost = range_clustered_cost(rows, leaf_pages, min_record_len, clustered_index_size, in_mem_pct) return range_cost + row_eval_cost(rows)\n这个第二个函数是不是没用啊，或者有其他算法这里没具体讲？？我看这个又加了一遍row_eval(rows)，有点迷惑性啊。。。。。","like_count":0,"discussions":[{"author":{"id":3898827,"avatar":"https://static001.geekbang.org/account/avatar/00/3b/7d/cb/fa3dae58.jpg","nickname":"俊达","note":"","ucode":"F79BF9651AD086","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":654667,"discussion_content":"第二个函数也是有用的。可以看一下执行计划最终的cost，实际上就是range成本加上行评估成本。\n\n比如这个例子：\nmysql&gt;  explain  format=json select * from tab where id between 1000 and 4000;\n{\n  &#34;query_block&#34;: {\n    &#34;select_id&#34;: 1,\n    &#34;cost_info&#34;: {\n      &#34;query_cost&#34;: &#34;986.68&#34;\n    },\n    &#34;table&#34;: {\n      &#34;table_name&#34;: &#34;tab&#34;,\n      &#34;access_type&#34;: &#34;range&#34;,\n      &#34;possible_keys&#34;: [\n        &#34;PRIMARY&#34;\n      ],\n      &#34;key&#34;: &#34;PRIMARY&#34;,\n      &#34;used_key_parts&#34;: [\n        &#34;id&#34;\n      ],\n      &#34;key_length&#34;: &#34;4&#34;,\n      &#34;rows_examined_per_scan&#34;: 4902,\n      &#34;rows_produced_per_join&#34;: 4902,\n      &#34;filtered&#34;: &#34;100.00&#34;,\n      &#34;cost_info&#34;: {\n        &#34;read_cost&#34;: &#34;496.48&#34;,\n        &#34;eval_cost&#34;: &#34;490.20&#34;,\n        &#34;prefix_cost&#34;: &#34;986.68&#34;,\n        &#34;data_read_per_join&#34;: &#34;131M&#34;\n      },\n      &#34;used_columns&#34;: [\n        &#34;id&#34;,\n        &#34;a&#34;,\n        &#34;b&#34;,\n        &#34;c&#34;,\n        &#34;padding&#34;\n      ],\n      &#34;attached_condition&#34;: &#34;(`rep`.`tab`.`id` between 1000 and 4000)&#34;\n    }\n  }\n}\n\n从代码看，计算执行最终的cost时，row_eval_cost确实是加了2遍。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1733219424,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":395246,"user_name":"mw","can_delete":false,"product_type":"c1","uid":1672042,"ip_address":"上海","ucode":"0F8DC29949CDAE","user_header":"https://static001.geekbang.org/account/avatar/00/19/83/6a/6f04edbd.jpg","comment_is_top":false,"comment_ctime":1729844213,"is_pvip":false,"replies":[{"id":143510,"content":"这个例子中MySQL是哪个版本的？\n\n从SQL语句的where条件看，使用索引 idx_posts_entle_posts_id_like_count 效率应该是最高的，也不需要排序，使用索引逆袭扫描10行记录就可以了。\n\n如果执行计划不对，就这个SQL，可以加上force index(idx_posts_entle_posts_id_like_count) 。\n\n这里type=range也比较奇怪，可以到optimizer_trace里看看。\n\n另外，能提供一下MySQL版本和建表语句吗？我测试一下看看。","user_name":"作者回复","user_name_real":"编辑","uid":3898827,"ctime":1730103901,"ip_address":"浙江","comment_id":395246,"utype":1}],"discussion_count":3,"race_medal":0,"score":2,"product_id":100799401,"comment_content":"老师 请教个问题 有个下面的查询，\n1、为啥所有前缀条件都是等于，这里的type是range，这里底层查找数据是怎样的呢\n2、神奇的现象是ignore index（posts_entle_root_parent_IDX）之后 type 又变成了ref，还是使用idx_posts_entle_posts_id_like_count索引。\n3、测试走的range，线上走的ref，线上环境查询慢，目前想到的办法是optimize table，怀疑是索引和表信息的影响，还有其他方法吗\n执行计划：\nmysql&gt; desc select * from posts_entle where posts_id=16700 and root_parent=0 and status=1 order by like_count desc limit 0,10\\G\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: posts_entle\n   partitions: NULL\n         type: range\npossible_keys: posts_entle_root_parent_IDX,idx_posts_entle_posts_id_like_count,idx_posts_entle_posts_id_create_at\n          key: idx_posts_entle_posts_id_like_count\n      key_len: 20\n          ref: NULL\n         rows: 756733\n     filtered: 100.00\n        Extra: Using index condition\n索引是： `idx_posts_entle_posts_id_like_count` (`posts_id`,`root_parent`,`status`,`like_count`)\n              `posts_entle_root_parent_IDX` (`root_parent`)","like_count":0,"discussions":[{"author":{"id":3898827,"avatar":"https://static001.geekbang.org/account/avatar/00/3b/7d/cb/fa3dae58.jpg","nickname":"俊达","note":"","ucode":"F79BF9651AD086","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":653035,"discussion_content":"这个例子中MySQL是哪个版本的？\n\n从SQL语句的where条件看，使用索引 idx_posts_entle_posts_id_like_count 效率应该是最高的，也不需要排序，使用索引逆袭扫描10行记录就可以了。\n\n如果执行计划不对，就这个SQL，可以加上force index(idx_posts_entle_posts_id_like_count) 。\n\n这里type=range也比较奇怪，可以到optimizer_trace里看看。\n\n另外，能提供一下MySQL版本和建表语句吗？我测试一下看看。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1730103901,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1672042,"avatar":"https://static001.geekbang.org/account/avatar/00/19/83/6a/6f04edbd.jpg","nickname":"mw","note":"","ucode":"0F8DC29949CDAE","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":653066,"discussion_content":"MySQL版本：5.7.33-log Source distribution\n建表sql：\nCREATE TABLE `posts_entle` (\n  `id` bigint(40) unsigned NOT NULL AUTO_INCREMENT,\n  `posts_id` bigint(40) DEFAULT NULL,\n  `content` text,\n  `mask_content` text,\n  `entle_pic` varchar(255) DEFAULT NULL ,\n  `uuid` bigint(40) DEFAULT NULL,\n  `sndaId` bigint(20) DEFAULT NULL,\n  `character_id` bigint(40) DEFAULT NULL,\n  `character_name` varchar(255) DEFAULT NULL,\n  `area_name` varchar(255) DEFAULT NULL,\n  `area_id` int(11) DEFAULT NULL,\n  `group_name` varchar(255) DEFAULT NULL,\n  `group_id` int(11) DEFAULT NULL,\n  `root_parent` bigint(40) DEFAULT &#39;0&#39; ,\n  `parent_id` bigint(40) DEFAULT &#39;0&#39; ,\n  `to_cid` bigint(40) DEFAULT NULL ,\n  `to_sndaId` bigint(20) DEFAULT NULL,\n  `to_uuid` bigint(40) DEFAULT NULL,\n  `to_cname` varchar(255) DEFAULT NULL,\n  `to_area_name` varchar(255) DEFAULT NULL,\n  `to_group_name` varchar(255) DEFAULT NULL,\n  `ip` varchar(255) DEFAULT NULL,\n  `ip_location` varchar(255) DEFAULT NULL,\n  `like_count` bigint(20) DEFAULT NULL ,\n  `mask_time` datetime DEFAULT NULL ,\n  `created_at` datetime DEFAULT NULL,\n  `updated_at` varchar(128) DEFAULT NULL,\n  `deleted_at` datetime DEFAULT NULL,\n  `updated_by` varchar(128) DEFAULT NULL,\n  `status` tinyint(2) DEFAULT &#39;1&#39; ,\n  `platform` tinyint(2) NOT NULL ,\n  `deleted_by` varchar(255) DEFAULT NULL,\n  `is_read` tinyint(1) DEFAULT &#39;0&#39; ,\n  PRIMARY KEY (`id`) USING BTREE,\n  KEY `character_id` (`character_id`) USING BTREE,\n  KEY `to_cid` (`to_cid`),\n  KEY `to_uuid` (`to_uuid`),\n  KEY `posts_entle_root_parent_IDX` (`root_parent`) USING BTREE,\n  KEY `uuid` (`uuid`) USING BTREE,\n  KEY `idx_posts_entle_posts_id_like_count` (`posts_id`,`root_parent`,`status`,`like_count`),\n  KEY `idx_posts_entle_posts_id_create_at` (`posts_id`,`root_parent`,`status`,`created_at`)\n) ENGINE=InnoDB AUTO_INCREMENT=1679608 DEFAULT CHARSET=utf8mb4 ;","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1730187834,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1672042,"avatar":"https://static001.geekbang.org/account/avatar/00/19/83/6a/6f04edbd.jpg","nickname":"mw","note":"","ucode":"0F8DC29949CDAE","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":653065,"discussion_content":"MySQL版本：5.7.33-log Source distribution\nforce index 和 不指定任何索引的情况下都选择了idx_posts_entle_posts_id_like_count 索引，不过一个range，一个ref。（和数据分布还有关系，posts_id 传入的值不同 也影响range 和 ref 选择）\n还有个问题想请教下老师：\n1、像这种联合索引的查询，都是等于条件，那 ref 和 range 方式通过索引找数据有啥区别吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1730187770,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":394824,"user_name":"叶明","can_delete":false,"product_type":"c1","uid":1412429,"ip_address":"江苏","ucode":"D0B4B7660DA766","user_header":"https://static001.geekbang.org/account/avatar/00/15/8d/4d/992070e8.jpg","comment_is_top":false,"comment_ctime":1728486874,"is_pvip":false,"replies":[{"id":143368,"content":"对的，增加is_deleted的查询条件，会带来回表，因此建议把is_deleted也冗余到索引中。\n\n由于is_deleted总是会传进来，而且是固定的，放在create_time前也是比较合理的。","user_name":"作者回复","user_name_real":"编辑","uid":3898827,"ctime":1728552139,"ip_address":"浙江","comment_id":394824,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100799401,"comment_content":"首先，查询中多了 is_deleted=0 的条件，那么原来的索引 idx_sellerid_createtime_sta 和 idx_buyerid_createtime_sta 应该加上 is_deleted 这一列，因为如果不加上，那么无论是\n统计查询还是明细查询都必须要回表，这个代价有点高。\n\n既然要将字段 is_deleted 加入到索引中，那么接下来就要考虑将该字段放到索引中哪个位置上，is_deleted 字段具有两个特征，一是等值查询，二是其值绝大多数为 0，区分度不高，\n考虑到 order_status、refund_status 可能不传，也可能传多个，而 create_time 是范围查询，如果放在 create_time 后面，index push down 是能利用上 is_deleted 字段，但这就得额外的排序操作了。\n因此应该放在 create_time 前，seller_id&#47;buyer_id 后。\n\nkey idx_sellerid_createtime_sta(seller_id, create_time, order_status, refund_status), \nkey idx_buyerid_createtime_sta(buyer_id, create_time, order_status, refund_status)\n\n老师怎么不解答留言了？另外思考题也没解答了，希望老师有空时可以讲解下，有的文章太深，读起来挺吃力。","like_count":0,"discussions":[{"author":{"id":3898827,"avatar":"https://static001.geekbang.org/account/avatar/00/3b/7d/cb/fa3dae58.jpg","nickname":"俊达","note":"","ucode":"F79BF9651AD086","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":652256,"discussion_content":"对的，增加is_deleted的查询条件，会带来回表，因此建议把is_deleted也冗余到索引中。\n\n由于is_deleted总是会传进来，而且是固定的，放在create_time前也是比较合理的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1728552139,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":394800,"user_name":"binzhang","can_delete":false,"product_type":"c1","uid":1647189,"ip_address":"美国","ucode":"F2670F2EA24FAD","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q3auHgzwzM59PTNiaDASVicbVaeWBU1WKmOgyHcqVtl85nDwAqDicib1EUKE2RRoU0x0vZctZO4kbPDUTTke8qKfAw/132","comment_is_top":false,"comment_ctime":1728447519,"is_pvip":false,"replies":[{"id":143375,"content":"这也是一种办法，在一个字段中存放更多的信息。\n有些场景下，确实会这么处理，比如使用bigint来存储64个bit，每个bit可以有不同的业务含义。应用代码中要定义好每个bit的用途。\n👍👍\n","user_name":"作者回复","user_name_real":"编辑","uid":3898827,"ctime":1728553847,"ip_address":"浙江","comment_id":394800,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100799401,"comment_content":"可以让order status支持这个需求。避免加列和重建索引等工作。比方说order status &gt; 100 的就 表示被逻辑删除。order status in （1，101）表示新order 等等。通常使用位运算 bitand 这样一个列可以表达多个逻辑。","like_count":0,"discussions":[{"author":{"id":3898827,"avatar":"https://static001.geekbang.org/account/avatar/00/3b/7d/cb/fa3dae58.jpg","nickname":"俊达","note":"","ucode":"F79BF9651AD086","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":652263,"discussion_content":"这也是一种办法，在一个字段中存放更多的信息。\n有些场景下，确实会这么处理，比如使用bigint来存储64个bit，每个bit可以有不同的业务含义。应用代码中要定义好每个bit的用途。\n👍👍\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1728553847,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":394789,"user_name":"123","can_delete":false,"product_type":"c1","uid":2662872,"ip_address":"浙江","ucode":"5A343B568B9524","user_header":"https://static001.geekbang.org/account/avatar/00/28/a1/d8/42252c48.jpg","comment_is_top":false,"comment_ctime":1728376159,"is_pvip":false,"replies":[{"id":143369,"content":"对的。\n查询中新增is_deleted的条件后，最好在索引中冗余这个字段，不然会带来大量回表，对性能的影响比较大。\n\nis_deleted放在排序字段后也可以，因为这个条件过滤性不高，主要是为了避免回表。","user_name":"作者回复","user_name_real":"编辑","uid":3898827,"ctime":1728552322,"ip_address":"浙江","comment_id":394789,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100799401,"comment_content":"思考题：\n对于逻辑删除，可以在需要使用到的联合索引中加入字段，注意添加的位置，需要在排序的字段之后，然后通过索引条件下推，可以在内存中进行筛选，对性能的影响不大；但是还是注意加字段的情况，由于MySQL8.0支持在线DDL，所以应该也可以快速完成；","like_count":0,"discussions":[{"author":{"id":3898827,"avatar":"https://static001.geekbang.org/account/avatar/00/3b/7d/cb/fa3dae58.jpg","nickname":"俊达","note":"","ucode":"F79BF9651AD086","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":652257,"discussion_content":"对的。\n查询中新增is_deleted的条件后，最好在索引中冗余这个字段，不然会带来大量回表，对性能的影响比较大。\n\nis_deleted放在排序字段后也可以，因为这个条件过滤性不高，主要是为了避免回表。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1728552322,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":394784,"user_name":"一本书","can_delete":false,"product_type":"c1","uid":2767251,"ip_address":"湖北","ucode":"4C07047F052BB4","user_header":"https://static001.geekbang.org/account/avatar/00/2a/39/93/f0247cf8.jpg","comment_is_top":false,"comment_ctime":1728359829,"is_pvip":true,"replies":[{"id":143370,"content":"这么理解也没错，如果区间内的数据很多，index dive获取的不是精确值。\n\n这里的准确是一个相对的概念。不使用index dive的情况下，如果是用索引的统计信息来估算，在数据倾斜的情况下，可能会存在很大的偏差。\n如果使用条件过滤，没有分析字段直方图时，估算可能更不准。\n跟这几种情况相比，index dive的估算可能会相对更准确一些。\n","user_name":"作者回复","user_name_real":"编辑","uid":3898827,"ctime":1728552664,"ip_address":"浙江","comment_id":394784,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100799401,"comment_content":"“Index Dive 是怎么工作的”这一节中，&quot;Index Dive 通常都能获得范围内记录数据比较准确的估计。&quot;这句话指的是记录数小于等于 8 个页面的场景下吗？如果区间内记录数超过 8 个页面，记录数就是估算值，返回的结果大概是实际行数的2倍，这已经不能称得上是准确了吧？","like_count":0,"discussions":[{"author":{"id":3898827,"avatar":"https://static001.geekbang.org/account/avatar/00/3b/7d/cb/fa3dae58.jpg","nickname":"俊达","note":"","ucode":"F79BF9651AD086","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":652258,"discussion_content":"这么理解也没错，如果区间内的数据很多，index dive获取的不是精确值。\n\n这里的准确是一个相对的概念。不使用index dive的情况下，如果是用索引的统计信息来估算，在数据倾斜的情况下，可能会存在很大的偏差。\n如果使用条件过滤，没有分析字段直方图时，估算可能更不准。\n跟这几种情况相比，index dive的估算可能会相对更准确一些。\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1728552664,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]}]}