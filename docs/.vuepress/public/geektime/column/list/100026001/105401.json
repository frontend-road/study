{"id":105401,"title":"31 | GPU（下）：为什么深度学习需要使用GPU？","content":"<p>上一讲，我带你一起看了三维图形在计算机里的渲染过程。这个渲染过程，分成了顶点处理、图元处理、 栅格化、片段处理，以及最后的像素操作。这一连串的过程，也被称之为图形流水线或者渲染管线。</p><p>因为要实时计算渲染的像素特别地多，图形加速卡登上了历史的舞台。通过3dFx的Voodoo或者NVidia的TNT这样的图形加速卡，CPU就不需要再去处理一个个像素点的图元处理、栅格化和片段处理这些操作。而3D游戏也是从这个时代发展起来的。</p><p>你可以看这张图，这是“古墓丽影”游戏的多边形建模的变化。这个变化，则是从1996年到2016年，这20年来显卡的进步带来的。</p><p><img src=\"https://static001.geekbang.org/resource/image/1d/c3/1d098ce5b2c779392c8d3a33636673c3.png?wh=1200*520\" alt=\"\"></p><center><a href=\"http://www.gamesgrabr.com/blog/2016/01/07/the-evolution-of-lara-croft/\">图片来源</a></center><h2>Shader的诞生和可编程图形处理器</h2><p>不知道你有没有发现，在Voodoo和TNT显卡的渲染管线里面，没有“顶点处理“这个步骤。在当时，把多边形的顶点进行线性变化，转化到我们的屏幕的坐标系的工作还是由CPU完成的。所以，CPU的性能越好，能够支持的多边形也就越多，对应的多边形建模的效果自然也就越像真人。而3D游戏的多边形性能也受限于我们CPU的性能。无论你的显卡有多快，如果CPU不行，3D画面一样还是不行。</p><p>所以，1999年NVidia推出的GeForce 256显卡，就把顶点处理的计算能力，也从CPU里挪到了显卡里。不过，这对于想要做好3D游戏的程序员们还不够，即使到了GeForce 256。整个图形渲染过程都是在硬件里面固定的管线来完成的。程序员们在加速卡上能做的事情呢，只有改配置来实现不同的图形渲染效果。如果通过改配置做不到，我们就没有什么办法了。</p><!-- [[[read_end]]] --><p>这个时候，程序员希望我们的GPU也能有一定的可编程能力。这个编程能力不是像CPU那样，有非常通用的指令，可以进行任何你希望的操作，而是在整个的<strong>渲染管线</strong>（Graphics Pipeline）的一些特别步骤，能够自己去定义处理数据的算法或者操作。于是，从2001年的Direct3D 8.0开始，微软第一次引入了<strong>可编程管线</strong>（Programable Function Pipeline）的概念。</p><p><img src=\"https://static001.geekbang.org/resource/image/27/6d/2724f76ffa4222eae01521cd2dffd16d.jpeg?wh=2506*1876\" alt=\"\"></p><center><span class=\"reference\">早期的可编程管线的GPU，提供了单独的顶点处理和片段处理（像素处理）的着色器</span></center><p>一开始的可编程管线呢，仅限于顶点处理（Vertex Processing）和片段处理（Fragment Processing）部分。比起原来只能通过显卡和Direct3D这样的图形接口提供的固定配置，程序员们终于也可以开始在图形效果上开始大显身手了。</p><p>这些可以编程的接口，我们称之为<strong>Shader</strong>，中文名称就是<strong>着色器</strong>。之所以叫“着色器”，是因为一开始这些“可编程”的接口，只能修改顶点处理和片段处理部分的程序逻辑。我们用这些接口来做的，也主要是光照、亮度、颜色等等的处理，所以叫着色器。</p><p>这个时候的GPU，有两类Shader，也就是Vertex Shader和Fragment Shader。我们在上一讲看到，在进行顶点处理的时候，我们操作的是多边形的顶点；在片段操作的时候，我们操作的是屏幕上的像素点。对于顶点的操作，通常比片段要复杂一些。所以一开始，这两类Shader都是独立的硬件电路，也各自有独立的编程接口。因为这么做，硬件设计起来更加简单，一块GPU上也能容纳下更多的Shader。</p><p>不过呢，大家很快发现，虽然我们在顶点处理和片段处理上的具体逻辑不太一样，但是里面用到的指令集可以用同一套。而且，虽然把Vertex Shader和Fragment Shader分开，可以减少硬件设计的复杂程度，但是也带来了一种浪费，有一半Shader始终没有被使用。在整个渲染管线里，Vertext Shader运行的时候，Fragment Shader停在那里什么也没干。Fragment Shader在运行的时候，Vertext Shader也停在那里发呆。</p><p>本来GPU就不便宜，结果设计的电路有一半时间是闲着的。喜欢精打细算抠出每一分性能的硬件工程师当然受不了了。于是，<strong>统一着色器架构</strong>（Unified Shader Architecture）就应运而生了。</p><p>既然大家用的指令集是一样的，那不如就在GPU里面放很多个一样的Shader硬件电路，然后通过统一调度，把顶点处理、图元处理、片段处理这些任务，都交给这些Shader去处理，让整个GPU尽可能地忙起来。这样的设计，就是我们现代GPU的设计，就是统一着色器架构。</p><p>有意思的是，这样的GPU并不是先在PC里面出现的，而是来自于一台游戏机，就是微软的XBox 360。后来，这个架构才被用到ATI和NVidia的显卡里。这个时候的“着色器”的作用，其实已经和它的名字关系不大了，而是变成了一个通用的抽象计算模块的名字。</p><p>正是因为Shader变成一个“通用”的模块，才有了把GPU拿来做各种通用计算的用法，也就是<strong>GPGPU</strong>（General-Purpose Computing on Graphics Processing Units，通用图形处理器）。而正是因为GPU可以拿来做各种通用的计算，才有了过去10年深度学习的火热。</p><p><img src=\"https://static001.geekbang.org/resource/image/da/93/dab4ed01f50995d82e6e5d970b54c693.jpeg?wh=2926*1876\" alt=\"\"></p><h2>现代GPU的三个核心创意</h2><p>讲完了现代GPU的进化史，那么接下来，我们就来看看，为什么现代的GPU在图形渲染、深度学习上能那么快。</p><h3>芯片瘦身</h3><p>我们先来回顾一下，之前花了很多讲仔细讲解的现代CPU。现代CPU里的晶体管变得越来越多，越来越复杂，其实已经不是用来实现“计算”这个核心功能，而是拿来实现处理乱序执行、进行分支预测，以及我们之后要在存储器讲的高速缓存部分。</p><p>而在GPU里，这些电路就显得有点多余了，GPU的整个处理过程是一个<a href=\"https://en.wikipedia.org/wiki/Stream_processing\">流式处理</a>（Stream Processing）的过程。因为没有那么多分支条件，或者复杂的依赖关系，我们可以把GPU里这些对应的电路都可以去掉，做一次小小的瘦身，只留下取指令、指令译码、ALU以及执行这些计算需要的寄存器和缓存就好了。一般来说，我们会把这些电路抽象成三个部分，就是下面图里的取指令和指令译码、ALU和执行上下文。</p><p><img src=\"https://static001.geekbang.org/resource/image/4c/9d/4c153ac45915fbf3985d24b092894b9d.jpeg?wh=2356*1333\" alt=\"\"></p><h3>多核并行和SIMT</h3><p>这样一来，我们的GPU电路就比CPU简单很多了。于是，我们就可以在一个GPU里面，塞很多个这样并行的GPU电路来实现计算，就好像CPU里面的多核CPU一样。和CPU不同的是，我们不需要单独去实现什么多线程的计算。因为GPU的运算是天然并行的。</p><p><img src=\"https://static001.geekbang.org/resource/image/3d/ac/3d0859652adf9e3c0305e8e8517b47ac.jpeg?wh=1936*2041\" alt=\"\"></p><p>我们在上一讲里面其实已经看到，无论是对多边形里的顶点进行处理，还是屏幕里面的每一个像素进行处理，每个点的计算都是独立的。所以，简单地添加多核的GPU，就能做到并行加速。不过光这样加速还是不够，工程师们觉得，性能还有进一步被压榨的空间。</p><p>我们在<a href=\"https://time.geekbang.org/column/article/103433\">第27讲</a>里面讲过，CPU里有一种叫作SIMD的处理技术。这个技术是说，在做向量计算的时候，我们要执行的指令是一样的，只是同一个指令的数据有所不同而已。在GPU的渲染管线里，这个技术可就大有用处了。</p><p>无论是顶点去进行线性变换，还是屏幕上临近像素点的光照和上色，都是在用相同的指令流程进行计算。所以，GPU就借鉴了CPU里面的SIMD，用了一种叫作<a href=\"https://en.wikipedia.org/wiki/Single_instruction,_multiple_threads\">SIMT</a>（Single Instruction，Multiple Threads）的技术。SIMT呢，比SIMD更加灵活。在SIMD里面，CPU一次性取出了固定长度的多个数据，放到寄存器里面，用一个指令去执行。而SIMT，可以把多条数据，交给不同的线程去处理。</p><p>各个线程里面执行的指令流程是一样的，但是可能根据数据的不同，走到不同的条件分支。这样，相同的代码和相同的流程，可能执行不同的具体的指令。这个线程走到的是if的条件分支，另外一个线程走到的就是else的条件分支了。</p><p>于是，我们的GPU设计就可以进一步进化，也就是在取指令和指令译码的阶段，取出的指令可以给到后面多个不同的ALU并行进行运算。这样，我们的一个GPU的核里，就可以放下更多的ALU，同时进行更多的并行运算了。</p><p><img src=\"https://static001.geekbang.org/resource/image/3d/28/3d7ce9c053815f6a32a6fbf6f7fb9628.jpeg?wh=1936*1363\" alt=\"\"></p><h3>GPU里的“超线程”</h3><p>虽然GPU里面的主要以数值计算为主。不过既然已经是一个“通用计算”的架构了，GPU里面也避免不了会有if…else这样的条件分支。但是，在GPU里我们可没有CPU这样的分支预测的电路。这些电路在上面“芯片瘦身”的时候，就已经被我们砍掉了。</p><p>所以，GPU里的指令，可能会遇到和CPU类似的“流水线停顿”问题。想到流水线停顿，你应该就能记起，我们之前在CPU里面讲过超线程技术。在GPU上，我们一样可以做类似的事情，也就是遇到停顿的时候，调度一些别的计算任务给当前的ALU。</p><p>和超线程一样，既然要调度一个不同的任务过来，我们就需要针对这个任务，提供更多的<strong>执行上下文</strong>。所以，一个Core里面的<strong>执行上下文</strong>的数量，需要比ALU多。</p><p><img src=\"https://static001.geekbang.org/resource/image/c9/b8/c971c34e0456dea9e4a87857880bb5b8.jpeg?wh=3046*1246\" alt=\"\"></p><h2>GPU在深度学习上的性能差异</h2><p>在通过芯片瘦身、SIMT以及更多的执行上下文，我们就有了一个更擅长并行进行暴力运算的GPU。这样的芯片，也正适合我们今天的深度学习的使用场景。</p><p>一方面，GPU是一个可以进行“通用计算”的框架，我们可以通过编程，在GPU上实现不同的算法。另一方面，现在的深度学习计算，都是超大的向量和矩阵，海量的训练样本的计算。整个计算过程中，没有复杂的逻辑和分支，非常适合GPU这样并行、计算能力强的架构。</p><p>我们去看NVidia 2080显卡的<a href=\"https://www.techpowerup.com/gpu-specs/geforce-rtx-2080.c3224\">技术规格</a>，就可以算出，它到底有多大的计算能力。</p><p>2080一共有46个SM（Streaming Multiprocessor，流式处理器），这个SM相当于GPU里面的GPU Core，所以你可以认为这是一个46核的GPU，有46个取指令指令译码的渲染管线。每个SM里面有64个Cuda Core。你可以认为，这里的Cuda Core就是我们上面说的ALU的数量或者Pixel Shader的数量，46x64呢一共就有2944个Shader。然后，还有184个TMU，TMU就是Texture Mapping Unit，也就是用来做纹理映射的计算单元，它也可以认为是另一种类型的Shader。</p><p><img src=\"https://static001.geekbang.org/resource/image/14/e2/14d05a43f559cecff2b0813e8d5bdde2.png?wh=2226*2500\" alt=\"\"></p><center><a href=\"https://www.anandtech.com/show/13282/nvidia-turing-architecture-deep-dive/7\">图片来源</a></center><center><span class=\"reference\">2080 Super显卡有48个SM，比普通版的2080多2个。每个SM（SM也就是GPU Core）里有64个Cuda Core，也就是Shader</span></center><p>2080的主频是1515MHz，如果自动超频（Boost）的话，可以到1700MHz。而NVidia的显卡，根据硬件架构的设计，每个时钟周期可以执行两条指令。所以，能做的浮点数运算的能力，就是：</p><center>（2944 + 184）× 1700 MHz × 2  = 10.06  TFLOPS</center><p>对照一下官方的技术规格，正好就是10.07TFLOPS。</p><p>那么，最新的Intel i9 9900K的性能是多少呢？不到1TFLOPS。而2080显卡和9900K的价格却是差不多的。所以，在实际进行深度学习的过程中，用GPU所花费的时间，往往能减少一到两个数量级。而大型的深度学习模型计算，往往又是多卡并行，要花上几天乃至几个月。这个时候，用CPU显然就不合适了。</p><p>今天，随着GPGPU的推出，GPU已经不只是一个图形计算设备，更是一个用来做数值计算的好工具了。同样，也是因为GPU的快速发展，带来了过去10年深度学习的繁荣。</p><h2>总结延伸</h2><p>这一讲里面，我们讲了，GPU一开始是没有“可编程”能力的，程序员们只能够通过配置来设计需要用到的图形渲染效果。随着“可编程管线”的出现，程序员们可以在顶点处理和片段处理去实现自己的算法。为了进一步去提升GPU硬件里面的芯片利用率，微软在XBox 360里面，第一次引入了“统一着色器架构”，使得GPU变成了一个有“通用计算”能力的架构。</p><p>接着，我们从一个CPU的硬件电路出发，去掉了对GPU没有什么用的分支预测和乱序执行电路，来进行瘦身。之后，基于渲染管线里面顶点处理和片段处理就是天然可以并行的了。我们在GPU里面可以加上很多个核。</p><p>又因为我们的渲染管线里面，整个指令流程是相同的，我们又引入了和CPU里的SIMD类似的SIMT架构。这个改动，进一步增加了GPU里面的ALU的数量。最后，为了能够让GPU不要遭遇流水线停顿，我们又在同一个GPU的计算核里面，加上了更多的执行上下文，让GPU始终保持繁忙。</p><p>GPU里面的多核、多ALU，加上多Context，使得它的并行能力极强。同样架构的GPU，如果光是做数值计算的话，算力在同样价格的CPU的十倍以上。而这个强大计算能力，以及“统一着色器架构”，使得GPU非常适合进行深度学习的计算模式，也就是海量计算，容易并行，并且没有太多的控制分支逻辑。</p><p>使用GPU进行深度学习，往往能够把深度学习算法的训练时间，缩短一个，乃至两个数量级。而GPU现在也越来越多地用在各种科学计算和机器学习上，而不仅仅是用在图形渲染上了。</p><h2>推荐阅读</h2><p>关于现代GPU的工作原理，你可以仔细阅读一下 haifux.org 上的这个<a href=\"http://haifux.org/lectures/267/Introduction-to-GPUs.pdf\">PPT</a>，里面图文并茂地解释了现代GPU的架构设计的思路。</p><h2>课后思考</h2><p>上面我给你算了NVidia 2080显卡的FLOPS，你可以尝试算一下9900K CPU的FLOPS。</p><p>欢迎在留言区写下你的答案，你也可以把今天的内容分享给你的朋友，和他一起学习和进步。</p><p></p>","neighbors":{"left":{"article_title":"30 | GPU（上）：为什么玩游戏需要使用GPU？","id":104747},"right":{"article_title":"32 | FPGA和ASIC：计算机体系结构的黄金时代","id":105974}},"comments":[{"had_liked":false,"id":164147,"user_name":"王加武","can_delete":false,"product_type":"c1","uid":1665471,"ip_address":"","ucode":"DDCFE578C6C428","user_header":"https://static001.geekbang.org/account/avatar/00/19/69/bf/50a824a4.jpg","comment_is_top":false,"comment_ctime":1576895672,"is_pvip":false,"discussion_count":4,"race_medal":0,"score":"237800096952","product_id":100026001,"comment_content":"CPU：在电脑里面起着控制运算的作用，是电脑的中央处理器<br>GPU:  主要是处理计算机中图形的有关计算，是一个附属形的处理器<br>只有CPU和GPU配合，才能充分的发挥计算机的性能！<br><br>学到了31讲，个人觉得，其实真的记不住什么东西，也不可能记得住，但是对某些知识的理解更加深刻了，不要放弃，先统一的学完一遍，对有的知识点有个映象，学习是一辈子的事情，后面再一遍一遍的把它当做读物来学习，一点点的弄！不慌！<br><br>专科大二，朝着自己的目标继续努力！","like_count":56,"discussions":[{"author":{"id":2427925,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epP0aHseGFYtPYbWf4mHl9JQoLAFZ5yXJwLUWibXuhoydibY5wIjL13QQzcibNIp69o37clnuicw8M1tg/132","nickname":"琴魂醉","note":"","ucode":"F63C235F6ED148","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":359642,"discussion_content":"加油！~我原先也是专科，现在硕士毕业了。这个老师讲的很好，但是很多知识是汇总起来的，需要结合很多书籍搭配一起看，思考并理解。如果能有模电和数电的基础，会更优帮助的！","likes_number":6,"is_delete":false,"is_hidden":false,"ctime":1616246476,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1348823,"avatar":"https://static001.geekbang.org/account/avatar/00/14/94/d7/bd4ffe8c.jpg","nickname":"么么直播","note":"","ucode":"1D4C3EDBCCD2F9","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":318591,"discussion_content":"小伙子，来么么直播，和我一起玩吧","likes_number":5,"is_delete":false,"is_hidden":false,"ctime":1603788530,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":2806043,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLBFkSq1oiaEMRjtyyv4ZpCI0OuaSsqs04ODm0OkZF6QhsAh3SvqhxibS2n7PLAVZE3QRSn5Hic0DyXg/132","nickname":"ddh","note":"","ucode":"8E852375365F16","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1348823,"avatar":"https://static001.geekbang.org/account/avatar/00/14/94/d7/bd4ffe8c.jpg","nickname":"么么直播","note":"","ucode":"1D4C3EDBCCD2F9","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":540148,"discussion_content":"好","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1639971594,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":318591,"ip_address":""},"score":540148,"extra":""}]},{"author":{"id":1655940,"avatar":"https://static001.geekbang.org/account/avatar/00/19/44/84/4da14994.jpg","nickname":"呆瓜","note":"","ucode":"C98C7B224D0640","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":292666,"discussion_content":"有前途","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1595301002,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":122424,"user_name":"笑若海","can_delete":false,"product_type":"c1","uid":1283537,"ip_address":"","ucode":"A10EF247EE4B5B","user_header":"https://static001.geekbang.org/account/avatar/00/13/95/d1/7d3834ef.jpg","comment_is_top":false,"comment_ctime":1565363156,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"44515036116","product_id":100026001,"comment_content":"由此看出，CPU适合做逻辑复杂、小量数据、IO密集这三类运算。<br>只要数据量大，即使逻辑复杂，还是值得研究可编程的专门硬件来提高效率，正如GPU的出现。<br>IO密集型的场景，由于内存、网卡、硬盘与CPU之间的速率差异，更适合借助中断机制用异步方式实现，提高总体的吞吐率。并借助高速缓存和超线程，进一步提升吞吐率，Web服务就是这种场景。","like_count":11},{"had_liked":false,"id":110640,"user_name":"许童童","can_delete":false,"product_type":"c1","uid":1003005,"ip_address":"","ucode":"4B799C0C6BC678","user_header":"https://static001.geekbang.org/account/avatar/00/0f/4d/fd/0aa0e39f.jpg","comment_is_top":false,"comment_ctime":1562308971,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"40217014635","product_id":100026001,"comment_content":"算了一下，大概是 16 * 5G = 0.8TFLOPS<br>","like_count":9,"discussions":[{"author":{"id":1735740,"avatar":"","nickname":"Geek_bb8d16","note":"","ucode":"964BD4DB3D9653","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":294667,"discussion_content":"https://en.wikipedia.org/wiki/Instructions_per_second\nIPC 是 10,  那么 8 core * 5 GHz * 10 = 400 \n\nhttps://www.notebookcheck.net/Intel-UHD-Graphics-630-GPU-Benchmarks-and-Specs.257928.0.html\n加上显卡 24 core * 1.0GHz * （假设为5）= 100\n\n那么 0.5TFLOPS，不知对不","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1595952169,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":130201,"user_name":"活的潇洒","can_delete":false,"product_type":"c1","uid":1238830,"ip_address":"","ucode":"666C30CA894754","user_header":"https://static001.geekbang.org/account/avatar/00/12/e7/2e/1522a7d6.jpg","comment_is_top":false,"comment_ctime":1567402255,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"27337206031","product_id":100026001,"comment_content":"1、以前只知道深度学习、大数据需要GPU但是底层的原理并不知道？<br>2、也不知道GPU的硬件组成和CPU有什么不同？<br>听完来时的讲解一下感觉都明白了<br><br>day31天笔记: https:&#47;&#47;www.cnblogs.com&#47;luoahong&#47;p&#47;11417549.html","like_count":6,"discussions":[{"author":{"id":1328500,"avatar":"https://static001.geekbang.org/account/avatar/00/14/45/74/7a82eebb.jpg","nickname":"Ins","note":"","ucode":"A2509BAD9CB72C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":381285,"discussion_content":"话说直接把内容转载出去，不用经过极客授权么","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1624981117,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":232989,"user_name":"A君","can_delete":false,"product_type":"c1","uid":1940105,"ip_address":"","ucode":"FE96F089C2312C","user_header":"https://static001.geekbang.org/account/avatar/00/1d/9a/89/babe8b52.jpg","comment_is_top":false,"comment_ctime":1594183092,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"5889150388","product_id":100026001,"comment_content":"原来着色器，ALU和cuda core其实是同一个东西。那个ppt很给力，谢谢","like_count":1},{"had_liked":false,"id":348955,"user_name":"jorin@zou","can_delete":false,"product_type":"c1","uid":1564869,"ip_address":"","ucode":"A8CEF7CCF33570","user_header":"https://static001.geekbang.org/account/avatar/00/17/e0/c5/c324a7de.jpg","comment_is_top":false,"comment_ctime":1655608139,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1655608139","product_id":100026001,"comment_content":"cpu和GPU是怎么协同工作的，就是两者的pipeline过程。","like_count":0},{"had_liked":false,"id":336199,"user_name":"GEEK_jahen","can_delete":false,"product_type":"c1","uid":1119448,"ip_address":"","ucode":"44A92200A392F8","user_header":"https://static001.geekbang.org/account/avatar/00/11/14/d8/2bacd9bb.jpg","comment_is_top":false,"comment_ctime":1646008184,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1646008184","product_id":100026001,"comment_content":"这章真好，通俗地讲出了GPU硬件发展以及为什么适合深度学习应用。对体系结构只有一些概念性理解的软件工程师，也能很好地接收Get到。","like_count":0},{"had_liked":false,"id":309553,"user_name":"种花家","can_delete":false,"product_type":"c1","uid":1486568,"ip_address":"","ucode":"1BBBF4E10255E9","user_header":"https://static001.geekbang.org/account/avatar/00/16/ae/e8/d01b90c3.jpg","comment_is_top":false,"comment_ctime":1630228917,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1630228917","product_id":100026001,"comment_content":"（2944 + 184）× 1700 MHz × 2  = 10.06  TFLOPS<br>为什么乘以2呢？","like_count":0,"discussions":[{"author":{"id":2756819,"avatar":"","nickname":"Geek_f4fb8b","note":"","ucode":"32114B90BF7060","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":392904,"discussion_content":"每个时钟周期可以执行2条指令","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631174725,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":299790,"user_name":"Yongtao","can_delete":false,"product_type":"c1","uid":2324603,"ip_address":"","ucode":"248BE5661D6532","user_header":"https://static001.geekbang.org/account/avatar/00/23/78/7b/09defb8d.jpg","comment_is_top":false,"comment_ctime":1624862288,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1624862288","product_id":100026001,"comment_content":"Intel i9 9900k<br>售价：500美元<br>最高主频：5GHz<br>核心数：8核16线程<br>浮点数运算能力：16*5GHz=0.08TFLOPS","like_count":0},{"had_liked":false,"id":265732,"user_name":"黄奇就💤","can_delete":false,"product_type":"c1","uid":2275907,"ip_address":"","ucode":"36EC8A98E48E0F","user_header":"https://static001.geekbang.org/account/avatar/00/22/ba/43/ab9bca4b.jpg","comment_is_top":false,"comment_ctime":1606996515,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"1606996515","product_id":100026001,"comment_content":"GPU挖矿","like_count":0,"discussions":[{"author":{"id":1904497,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJKkThulMFj6MiaY8qlsmHWrlIzo1SEhwDjwpgLP2bhLYETx1f0DepRDsBdssd5dFKN35zzFUYnia1Q/132","nickname":"luck_tou","note":"","ucode":"E6BACBB08C504E","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":339837,"discussion_content":"其实光挖矿我感觉还能少掉很多的电路，搞专门的挖矿芯片，电费省一个数量级","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1609818016,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1934606,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/85/0e/ad39a252.jpg","nickname":"西塞尔","note":"","ucode":"F1AA53B3B405E3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1904497,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJKkThulMFj6MiaY8qlsmHWrlIzo1SEhwDjwpgLP2bhLYETx1f0DepRDsBdssd5dFKN35zzFUYnia1Q/132","nickname":"luck_tou","note":"","ucode":"E6BACBB08C504E","race_medal":0,"user_type":1,"is_pvip":true},"discussion":{"id":339893,"discussion_content":"早就有专门设计的矿机了","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1609834088,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":339837,"ip_address":""},"score":339893,"extra":""}]}]},{"had_liked":false,"id":255931,"user_name":"风","can_delete":false,"product_type":"c1","uid":1077538,"ip_address":"","ucode":"104638BF19B048","user_header":"https://static001.geekbang.org/account/avatar/00/10/71/22/b8c596b6.jpg","comment_is_top":false,"comment_ctime":1603459212,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1603459212","product_id":100026001,"comment_content":"GPU 一开始是没有“可编程”能力的，程序员们只能够通过配置来设计需要用到的图形渲染效果。随着“可编程管线”的出现，程序员们可以在顶点处理和片段处理去实现自己的算法。为了进一步去提升 GPU 硬件里面的芯片利用率，微软在 XBox 360 里面，第一次引入了“统一着色器架构”，使得 GPU 变成了一个有“通用计算”能力的架构。","like_count":0},{"had_liked":false,"id":181062,"user_name":"深水蓝","can_delete":false,"product_type":"c1","uid":1637933,"ip_address":"","ucode":"3E3B195DE54DE1","user_header":"https://static001.geekbang.org/account/avatar/00/18/fe/2d/e23fc6ee.jpg","comment_is_top":false,"comment_ctime":1582468450,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1582468450","product_id":100026001,"comment_content":"同样时代的AMD显卡，内核的数量好像比NVIDIA的要多不少，但为什么AMD在通用计算领域没有什么影响力呢？","like_count":0},{"had_liked":false,"id":139899,"user_name":"拓山","can_delete":false,"product_type":"c1","uid":1545647,"ip_address":"","ucode":"11FE9CF3821898","user_header":"https://static001.geekbang.org/account/avatar/00/17/95/af/b7f8dc43.jpg","comment_is_top":false,"comment_ctime":1570762809,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1570762809","product_id":100026001,"comment_content":"徐老师，我理解GPU【执行上下文】的组件多是由于GPU的超线程的数量比CPU多而造成的<br>那么你的这句话【最后，为了能够让 GPU 不要遭遇流水线停顿，我们又在同一个 GPU 的计算核里面，加上了更多的执行上下文】是不是指的就是GPU超线程多，可以避免流水线的停顿？","like_count":0,"discussions":[{"author":{"id":1795371,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/65/2b/446ef7b6.jpg","nickname":"许先森","note":"","ucode":"1F42D4A6B5C6AF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":135176,"discussion_content":"超线程的目的就是让线程A指令在流水线停顿的时候，另一个线程B去执行指令，不是没有流水线停顿，而是流水线停顿的时钟周期被利用起来了。","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1579075759,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":110750,"user_name":"coder","can_delete":false,"product_type":"c1","uid":1399673,"ip_address":"","ucode":"929E3FFD14EFC8","user_header":"https://static001.geekbang.org/account/avatar/00/15/5b/79/d55044ac.jpg","comment_is_top":false,"comment_ctime":1562324259,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1562324259","product_id":100026001,"comment_content":"最新版的GPU Turing架构，加入了Tensor Core，面向深度学习，直接支持矩阵乘法这种相对复杂的运算🌝🌝🌝","like_count":0},{"had_liked":false,"id":110620,"user_name":"清秋（翟浩）","can_delete":false,"product_type":"c1","uid":1302569,"ip_address":"","ucode":"92A50ED18AA7D2","user_header":"https://static001.geekbang.org/account/avatar/00/13/e0/29/60a814e0.jpg","comment_is_top":false,"comment_ctime":1562303637,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1562303637","product_id":100026001,"comment_content":"这份讲义都是2011年的了，近8年的GPU发展如何呢，这八年没有任何变化么？","like_count":0},{"had_liked":false,"id":110527,"user_name":"拉欧","can_delete":false,"product_type":"c1","uid":1206605,"ip_address":"","ucode":"40996A8093A95F","user_header":"https://static001.geekbang.org/account/avatar/00/12/69/4d/81c44f45.jpg","comment_is_top":false,"comment_ctime":1562290032,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1562290032","product_id":100026001,"comment_content":"技术都是螺旋式发展的，正如 :游戏的发展<br>—&gt; GPU技术升级—&gt;深度学习发展","like_count":0},{"had_liked":false,"id":110500,"user_name":"coder","can_delete":false,"product_type":"c1","uid":1399673,"ip_address":"","ucode":"929E3FFD14EFC8","user_header":"https://static001.geekbang.org/account/avatar/00/15/5b/79/d55044ac.jpg","comment_is_top":false,"comment_ctime":1562288203,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1562288203","product_id":100026001,"comment_content":"徐老师能把haifux.org中的ppt链接贴出来吗，客户端上加载不出来:D","like_count":0,"discussions":[{"author":{"id":1302569,"avatar":"https://static001.geekbang.org/account/avatar/00/13/e0/29/60a814e0.jpg","nickname":"清秋（翟浩）","note":"","ucode":"92A50ED18AA7D2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":1051,"discussion_content":"http://haifux.org/lectures/267/Introduction-to-GPUs.pdf","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1562296031,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}