{"id":253403,"title":"大咖助场1 | 李玥：高并发场景下如何优化微服务的性能?","content":"<p>你好，我是李玥。相信这里有部分同学对我是比较熟悉的，我在极客时间开了两门课，分别是<a href=\"https://time.geekbang.org/column/intro/212?utm_term=zeusEX4MV&amp;utm_source=geektime&amp;utm_medium=xiangqingye\">《消息队列高手课》</a>和<a href=\"https://time.geekbang.org/column/intro/100046801\">《后端存储实战课》</a>。今天很荣幸受邀来到陶辉老师的专栏做一期分享。</p><p>陶辉老师的这门课程，其中的知识点都是非常“硬核”，因为涉及到计算机操作系统底层的这些运行机制，确实非常抽象。我也看到有些同学在留言区提到，希望能通过一些例子来帮助大家更好地消化一下这些知识。那么这期分享呢，我就来帮陶辉老师做一次科普，帮助同学们把“基础设施优化”这一部分中讲到的一些抽象的概念和方法，用举例子的方式来梳理一遍。总结下的话，就是帮你理清这些问题：</p><ul>\n<li>线程到底是如何在CPU中执行的？</li>\n<li>线程上下文切换为什么会影响性能？</li>\n<li>为什么说异步比同步的性能好？</li>\n<li>BIO、NIO、AIO到底有什么区别？</li>\n</ul><h2>为什么线程数越多反而性能越差？</h2><p>今天的课程，从一个选择题开始。假设我们有一个服务，服务的业务逻辑和我们每天在做的业务都差不多，根据传入的参数去数据库查询数据，然后执行一些简单的业务逻辑后返回。我们的服务需要能支撑10,000TPS的请求数量，那么数据库的连接池设置成多大合适呢？</p><p>我给你二个选项：</p><ul>\n<li>A. 32</li>\n<li>B. 2048</li>\n</ul><p>我们直接公布答案，选项A是性能更好的选择。连接池的大小直接影响的是，同时请求到数据库服务器的并发数量。那我们直觉的第一印象可能是，并发越多总体性能应该越好才对，事实真的是这样吗？下面我们通过一个例子来探究一下这个问题的答案。</p><!-- [[[read_end]]] --><p>说有一个工厂，要新上一个车间，车间里面设置了8条流水生产线，每个流水线设置1个工位，那需要安排多少个工人才能达到最佳的效率呢？显然是需要8个工人是吧？工人少了生产线闲置，工人多了也没有工位让他们去工作，工人闲置，8个工人对8条流水线是效率最优解。这里面的车间，就可以类比为一台计算机，工位就是线程，工人就是CPU的核心。通过这个类比，我们就可以得出这样一个结论：<strong>一个8核的CPU，8个线程的情况下效率是最高的。</strong> 这时，每个CPU核心正好对应一个线程。</p><p>这是一个非常理想的情况，它有一个前提就是，流水线上的工人（CPU核心）一直有事情做，没有任何等待。而现实情况下，我们绝大部分的计算程序都做不到像工厂流水线那么高效。我们开发的程序几乎是<strong>请求/响应</strong>的模型，对应到车间的例子，生产模式不太像流水线，更像是来料加工。工人在工位上等着，来了一件原料，工人开始加工，加工完成后，成品被送走，然后再等待下一件，周而复始。对应到计算机程序中，原料就是请求，工人在工位上加工原料的过程，相当于CPU在线程上执行业务逻辑的过程，成品就是响应，或者说是请求的返回值。你可以对照下面这个图来理解上面我们讲的这个例子，以及对应到计算机程序中的概念。</p><p><img src=\"https://static001.geekbang.org/resource/image/yy/8c/yy53149254ae8cc325b1bc24e5a6428c.png?wh=749*311\" alt=\"\"></p><p>来料加工这种情况下，只有8个工位并不能保证8个工人一直满负荷的工作。因为，工人每加工完成一件产品之后，需要等待成品被送出去，下一件原料被送进来，才能开始继续工作。在同一个工位上加工每件产品之间的等待是不可避免的，那怎么才能最大化工人的效率，尽量减少工人等待呢？很简单，增加一些工位就可以了。工人在A工位加工完成一件产品之后，不在A工位等着，马上去另外一个原料已经就绪的B工位继续工作，这样只要工位设置得足够多，就可以保证8个工人一直满负荷工作。</p><p>那同样是8个工人满负荷工作，多工位来料加工这种方式，和上面提到的8条流水线作业的方式，哪种效率更高呢？还是流水线的效率高，是不是？原因是，虽然在这两种方式下，工人们都在满负荷工作，但是，来料加工这种方式下，工人在不同的工位之间切换，也是需要一点点时间的，相比于流水线作业，这部分工时相当于被浪费掉了。</p><p>工人在工位间切换，对应到计算机执行程序的过程，就是CPU在不同的线程之间切换，称为<strong>线程上下文切换</strong>。一次线程上下文切换的时间耗时非常短，大约只有几百个纳秒（ns）。一般来说我们并不需要太关注这个短到不可感知的切换时间，但是，在多线程高并发的场景下，如果没有很好的优化，就有可能出现，CPU在大量线程间频繁地发生切换，累积下来，这个切换时间就很可观了，严重的话就会拖慢服务的总体性能。</p><p>我们再来思考另外一个问题：设置多少个工位最合适呢？工位数量不足时，工人不能满负荷工作，工位数量太多了也不行，工人需要频繁地切换工位，浪费时间。这里面一定存在一个最优工位数，可以让所有工人正好不需要等待且满负荷工作。最优工位数取决于工人的加工速度、等待原料的时长等因素。如果这些参数是确定的，那我们确定这个最佳工位数就不太难了。一般来说，工位的数量设置成工人数量的两三倍就差不多了，如果等待的时间比较长，可能需要五六倍，大致是这样一个数量级。把这个结论对应到计算机系统中就是，<strong>对于一个请求/响应模型的服务，并发线程数设置为CPU核数N倍时性能最佳</strong>，N的大致的经验值范围是[2, 10]。</p><p>有了这个结论，再回过头来看我们课程开始提到的那个数据库连接池问题。数据库服务符合“请求/响应模型”，所以它的并发数量并不是越多越好，根据我们上面得出的结论，大约是CPU核数的几倍时达到最佳性能。这个问题来自于数据库连接池HikariCP的一篇Wiki: <a href=\"https://github.com/brettwooldridge/HikariCP/wiki/About-Pool-Sizing\">About Pool Sizing</a>，里面有详细的性能测试数据和计算最佳连接池数量的公式，强烈推荐你课后去看一下。</p><h2>为什么说异步比同步的性能好？</h2><p>然后我们再来思考这样一个问题。我们开发的很多业务服务实际的情况是，并发线程数越多总体性能越好，几百甚至上千个线程才达到最佳性能。这并不符合我们上面说的那个结论啊？什么原因？</p><p>原因是这样的，我们上面这个结论它有一个适用范围，它的适用范围是，像数据库服务这样，只依赖于本地计算资源的服务。</p><p>如果说，我们的业务服务，它在处理请求过程中，还需要去调用其他服务，这种情况就不适用于我们上面所说的结论。这里面的其它服务包括数据库服务或者是下游的业务服务等等。不适用的原因是，我们线程在执行业务逻辑过程中，很大一部分时间都花在等待外部服务上了，在这个等待的过程中，几乎不需要CPU参与。换句话说，每个线程需要的CPU时间是非常少的，这样的情况下，一个CPU核心需要非常多的线程才能把它“喂饱”，这就是为什么这些业务服务需要非常多的线程数，才能达到最佳性能的原因。</p><p>我们刚刚讲过，线程数过多很容易导致CPU频繁的在这些线程之间切换，虽然CPU看起来已经在满负荷运行了，但CPU并没有把所有的时间都用在执行我们的业务逻辑上，其中一部分CPU时间浪费在线程上下文切换上了。怎么来优化这种情况呢？要想让CPU高效地执行业务逻辑，最佳方式就是我们开头提到的流水线，用和CPU核数相同的线程数，通过源源不断地供给请求，让CPU一直不停地执行业务逻辑。<strong>所以优化的关键点是，减少线程的数量</strong>，把线程数量控制在和CPU核数相同的数量级这样一个范围。</p><p>要减少线程数量，有这样两个问题需要解决。</p><p>第一个问题是，如何用少量的线程来处理大量并发请求呢？我们可以用一个请求队列，和一组数量固定的执行线程，来解决这个问题。线程的数量就等于CPU的核数。接收到的请求先放入请求队列，然后分配给执行线程去处理。这样基本上能达到，让每个CPU的核心相对固定到一个线程上，不停地执行业务逻辑这样一个效果。</p><p>第二个问题是，执行线程在需要调用外部服务的时候，如何避免线程等待外部服务，同时还要保证及时处理返回的响应呢？我们希望的情况是，执行线程需要调用外部服务的时候，把请求发送出去之后，不要去等待响应，而是去继续处理下一个请求。等外部请求的响应回来之后，能有一个通知，来触发执行线程再执行后续的业务逻辑，直到给客户端返回响应。这其实就是我们通常所说的<strong>异步IO模型（AIO，Asynchronous I/O）</strong>，这个模型的关键就是，线程不去等待Socket通道上的数据，而是待数据到达时，由操作系统来发起一个通知，触发业务线程来处理。Linux内核从2.6开始才加入了AIO的支持，到目前为止AIO还没有被广泛使用。</p><p>使用更广泛的是<strong>IO多路复用模型（IO Multiplexing）</strong>，IO多路复用本质上还是一种同步IO模型。但是，它允许一个线程同时等待多个Socket通道，任意一个通道上有数据到来，就解除等待去处理。IO多路复用没有AIO那么理想化，但也只是多了一个线程用于等待响应，相比AIO来说，效果也差不了多少，在内核AIO支持还不完善的时代，是一个非常务实且高效的网络IO模型。</p><p>很多编程语言中，都有一些网络IO框架，封装了这些IO模型，来帮我们解决这个问题，比如Java语言中的BIO、NIO、AIO分别对应了同步IO模型、IO多路复用模型和异步IO模型。</p><p>解决了上面这两个问题之后，我们用很少量的线程就可以处理大量的并发请求。这种情况下，负责返回响应的线程和接收请求的线程，不再是同一个线程，这其实就是我们所说的<strong>异步模型</strong>。你可以看到，<strong>异步模型并不会让程序的业务逻辑执行得更快，但是它可以非常有效地避免线程等待，大幅减少CPU在线程上下文切换上浪费的时间。</strong>这样，在同样的计算机配置下，异步模型相比同步模型，可以更高效地利用计算机资源，从而拥有更好的总体的吞吐能力。</p><h2>小结</h2><p>以上就是本节课的全部内容了，我们来简单地做个小结。</p><p>理论上，线程数量设置为CPU核数，并且线程没有等待的情况下，CPU几乎不会发生线程上下文切换，这个时候程序的执行效率是最高的。实际情况下，对于一个请求/响应模型的服务，并发线程数设置为CPU核数N倍时性能最佳。这个N取决于业务逻辑的执行时间、线程等待时间等因素，N的大致的经验值范围是[2, 10]。</p><p>使用异步模型编写微服务，配合异步IO或者IO多路复用，可以有效地避免线程等待，用少量的线程处理大量并发请求，大幅减少线程上下文切换的开销，从而达到提升服务总体性能的效果。</p><h2>思考题</h2><p>最后留给你一道思考题。IO多路复用，它只是一种IO模型，实际上有多种实现。在Linux中，有select、poll、epoll三种实现方式，课后请你去查阅一下资料，看看这三种实现方式有什么区别？</p><p>感谢阅读，如果今天的内容让你有所收获，欢迎把它分享给你的朋友。</p>","comments":[{"had_liked":false,"id":238156,"user_name":"west","can_delete":false,"product_type":"c1","uid":2080899,"ip_address":"","ucode":"B42BF349E55900","user_header":"https://static001.geekbang.org/account/avatar/00/1f/c0/83/ca1c44d5.jpg","comment_is_top":false,"comment_ctime":1596082273,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"40250787937","product_id":100051201,"comment_content":"线程数量需要根据业务特征io密集，计算密集型<br>计算密集型线程数量 CPU核数+1<br>IO密集型 线程数量=(CPU空闲时间+CPU工作时间)&#47;CPU工作时间 + 1","like_count":10,"discussions":[{"author":{"id":1628501,"avatar":"https://static001.geekbang.org/account/avatar/00/18/d9/55/bd65c4df.jpg","nickname":"王木杉","note":"","ucode":"712288EE2A3F4B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":380318,"discussion_content":"为什么要+1呢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1624436187,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":229709,"user_name":"點點點，点顛","can_delete":false,"product_type":"c1","uid":1790368,"ip_address":"","ucode":"1BC77F6E044650","user_header":"https://static001.geekbang.org/account/avatar/00/1b/51/a0/5db02ac2.jpg","comment_is_top":false,"comment_ctime":1593109057,"is_pvip":false,"replies":[{"id":"90883","content":"^_^","user_name":"作者回复","user_name_real":"陶辉","uid":"1283912","ctime":1599708365,"ip_address":"","comment_id":229709,"utype":1}],"discussion_count":3,"race_medal":0,"score":"14478010945","product_id":100051201,"comment_content":"先回答一下思考题：<br>    首先是poll和 select 函数对比， poll 函数和 select 不一样的地方就是，在 select 里面，文件描述符的个数已经随着 fd_set 的实现而固定，没有办法对此进行配置；而在 poll 函数里，我们可以控制 pollfd 结构的数组大小，这意味着我们可以突破原来 select 函数最大描述符的限制，在这种情况下，应用程序调用者需要分配 pollfd 数组并通知 poll 函数该数组的大小。<br>    epoll 与poll相对比，epoll不同于 poll 的是，epoll 不仅提供了默认的 level-triggered（条件触发）机制，还提供了性能更为强劲的 edge-triggered（边缘触发）机制。条件触发的意思是只要满足事件的条件，比如有数据需要读，就一直不断地把这个事件传递给用户；而边缘触发的意思是只有第一次满足条件的时候才触发，之后就不会再传递同样的事件了。一般我们认为，边缘触发的效率比条件触发的效率要高，这一点也是 epoll 的杀手锏之一。<br>    答案来源主要是极客专栏盛延敏老师的《网络编程实战》。<br><br>    非常的喜欢李玥老师，老师的两门课都收获很多。比如《消息队列高手课》里面实现一个简单的RPC框架，真的是意外之喜，买一送一。还有《后端存储实战课》，意外之喜就是结束语了，感觉又是买一送一了，让我学到了很多技术之外的东西，感谢李玥老师。（也许秋招我可以投京东试一试😄）","like_count":3,"discussions":[{"author":{"id":1283912,"avatar":"https://static001.geekbang.org/account/avatar/00/13/97/48/550271b0.jpg","nickname":"陶辉","note":"","ucode":"F81A9087435953","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":499602,"discussion_content":"^_^","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1599708365,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":287213,"discussion_content":"谢谢你喜欢我的课程，希望你能有所收获！\n\n那我也相信，如果你能把极客时间中，和你技术栈相关的课程都学透，收获一个大厂的offer也是水到渠成的事儿。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1593401124,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1790368,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/51/a0/5db02ac2.jpg","nickname":"點點點，点顛","note":"","ucode":"1BC77F6E044650","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":287427,"discussion_content":"谢谢李老师😁","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1593439206,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":287213,"ip_address":""},"score":287427,"extra":""}]}]},{"had_liked":false,"id":230457,"user_name":"战斗机二虎🐯","can_delete":false,"product_type":"c1","uid":1157201,"ip_address":"","ucode":"8AB69AD2D76784","user_header":"https://static001.geekbang.org/account/avatar/00/11/a8/51/46a788b1.jpg","comment_is_top":false,"comment_ctime":1593393458,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"10183328050","product_id":100051201,"comment_content":"感觉说得太绝对了，现网DB链接池配置32不现实，业务侧mysql访问组件一个进程就会建立几个链接，多起几个进程mysql就受不了了","like_count":2,"discussions":[{"author":{"id":1419723,"avatar":"https://static001.geekbang.org/account/avatar/00/15/a9/cb/a431bde5.jpg","nickname":"木头发芽","note":"","ucode":"657B381C5DA963","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":305664,"discussion_content":"&#34;业务侧mysql访问组件一个进程就会建立几个链接，多起几个进程mysql就受不了了&#34;\n我的理解是你业务侧的连接只是连接,跟mysql建立连接后不是时时都有请求在里面,mysql端2000个连接里的请求放到请求队列,交给32个线程去处理","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1600051163,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1984116,"avatar":"https://static001.geekbang.org/account/avatar/00/1e/46/74/a7ffa090.jpg","nickname":"浪浪","note":"","ucode":"C576FA979959AA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":288312,"discussion_content":"可以在数据库上再加一层网关","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1593705442,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":299643,"user_name":"程序员老王","can_delete":false,"product_type":"c1","uid":1025340,"ip_address":"","ucode":"28577A15F064CF","user_header":"https://static001.geekbang.org/account/avatar/00/0f/a5/3c/7c0d2e57.jpg","comment_is_top":false,"comment_ctime":1624776849,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1624776849","product_id":100051201,"comment_content":"select、poll、epoll 不是aio 模型。","like_count":0},{"had_liked":false,"id":235715,"user_name":"🎧重返归途","can_delete":false,"product_type":"c1","uid":1991518,"ip_address":"","ucode":"33F748AE188B07","user_header":"https://static001.geekbang.org/account/avatar/00/1e/63/5e/799cd6dc.jpg","comment_is_top":false,"comment_ctime":1595161100,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1595161100","product_id":100051201,"comment_content":"对于独立应用socket 的网关服务和处理服务的线程数实际上是很低的，多数只能达到应用瓶颈而不会出现服务器CPU或IO瓶颈。Linux内核的select方式在处理socket似乎优于后面两个，曾经在一个项目中遇到了这个问题，选择select 在超过线程数的并发下服务器不会出现拒绝连接的响应。","like_count":0},{"had_liked":false,"id":230257,"user_name":"。。。","can_delete":false,"product_type":"c1","uid":1803113,"ip_address":"","ucode":"F97D05D81A5803","user_header":"https://static001.geekbang.org/account/avatar/00/1b/83/69/a9201594.jpg","comment_is_top":false,"comment_ctime":1593329107,"is_pvip":false,"discussion_count":3,"race_medal":0,"score":"1593329107","product_id":100051201,"comment_content":"如果是应用服务器有20多台，数据库是一台master3台salve的话，这样的数据库连接池怎么设置呢？希望老师能回答","like_count":0,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":287206,"discussion_content":"这个分布式系统计算就有点儿复杂了，首先你需要确定数据库服务器的CPU核数，然后根据《About Pool Sizing》这篇WiKi上给出的公式，综合下面几个因素来计算：\n\n1. 数据库服务的CPU核心数量；\n2. 数据库请求的读写比；\n3. 主库和从库的实例数（假设你已经做了读写分离）\n4. 应用服务器的数量；\n5. 请求的并发数（QPS）；\n\n另外，考虑到业务的复杂性，并不是说按照公式算出来的数量一定是最优的，如果你要是追求极致性能的话，还是需要在你的业务场景下进行压测，找到最优值。\n\n如果你的要求没有那么苛刻的话，文中也已经给出了更傻瓜化的建议：如果你有10000个并发用户，设置一个10000的连接池就是脑子进水了。1000仍然很恐怖，即使100也太多了。你需要一个10来个连接的小连接池，然后让剩下的业务线程都在队列里等待。连接池中的连接数量应该等于你的数据库能够有效同时进行的查询任务数（通常不会高于2*CPU核心数）。\n","likes_number":4,"is_delete":false,"is_hidden":false,"ctime":1593400145,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1803113,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/83/69/a9201594.jpg","nickname":"。。。","note":"","ucode":"F97D05D81A5803","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":291535,"discussion_content":"感谢老师解答、因为对这个连接池数设置多少都没有达到最优、我们领导就直接设置2万（tps要求确实有点高）感觉不合理、但是又不晓得怎样设置","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1594864824,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1073027,"avatar":"https://static001.geekbang.org/account/avatar/00/10/5f/83/bb728e53.jpg","nickname":"Douglas","note":"","ucode":"CFDE3D76B9DAE6","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":287790,"discussion_content":"这篇文章我也看了，实测下来，不准确，实际生产环境需要的连接数远大于理论值","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1593537924,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":229805,"user_name":"凉人。","can_delete":false,"product_type":"c1","uid":1659177,"ip_address":"","ucode":"4DB16004A62015","user_header":"https://static001.geekbang.org/account/avatar/00/19/51/29/24739c58.jpg","comment_is_top":false,"comment_ctime":1593151055,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"1593151055","product_id":100051201,"comment_content":"老师你好，我有两个问题想请教一下。<br>1 多工位解决等待问题，这部分应该解决的是io读写的时间吧？<br>2 异步io，在发送信号之前是在做下一个请求么？如果是在处理下个请求，那么信号唤醒，这里会涉及线程的切换么？ ","like_count":0,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":287210,"discussion_content":"同学你好，简单说下我对这两个问题的理解：\n\n1. 是的，这里的等待主要是等待网络IO；\n\n2. 这个问题没有明确的答案，因为CPU的调度是操作系统决定的，理论上任何时刻都有可能发生线程切换。\n\n但是，这里面还是有一些规律的。假设A线程处理完一个客户端请求，再继续处理下一个请求，大概率是不会发生线程切换，因为A线程获得了一个CPU核心后，一直处于RUNNING状态，这个CPU核心被调度走的可能性就比较小。\n\n但如果线程在等待（BLOCKED）状态，比如EPOLL中等待网络IO的数据包，处于等待状态的线程是不需要CPU的，如果等到了数据，需要继续执行来处理数据的时候，必然要转换成RUNNING状态，这个时候一定会有一次线程上下文切换。\n\n","likes_number":4,"is_delete":false,"is_hidden":false,"ctime":1593400911,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1659177,"avatar":"https://static001.geekbang.org/account/avatar/00/19/51/29/24739c58.jpg","nickname":"凉人。","note":"","ucode":"4DB16004A62015","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":287251,"discussion_content":"好的，谢谢老师解惑。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1593407381,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}