{"id":198947,"title":"24丨Kafka：性能监控工具之队列级监控及常用计数器解析","content":"<p>在我看来队列服务器是最简单的一种组件了。因为队列给我们下手的机会实在是并不多。我们只是用它，如果想改变它就只能去改代码，其他的都只是配置问题。</p><p>在当前的市场中，Kafka算是用得非常火的一个队列服务器了，所以今天，我选择它来做一些解读。</p><p>虽然我在前面一直在强调分析的思路，但在这一篇中，我打算换个思路，不是像以前那样，直接给你一个结论型的思维导图，而是一起来分析一个组件，让我们看看从哪里下手，来观察一个被分析对象的相关配置。</p><h2>了解Kafka的基本知识</h2><p>我们先看一下这张图，以便更好地了解一个队列服务器。</p><p><img src=\"https://static001.geekbang.org/resource/image/65/87/659043d7a680bd0cb5df070e0ecec687.jpg?wh=1069*899\" alt=\"\"></p><p>这是Kafka官网上的一个图。从这个图中可以看到，对Kafka来说，这就像一个典型的集线器。那它里面的结构是什么样子的呢？根据我的理解，我画了一个如下的示意图：</p><p><img src=\"https://static001.geekbang.org/resource/image/d5/30/d59231449717009067723332de568130.png?wh=978*648\" alt=\"\"></p><p>在这个图中，有三个Broker，也就是三个集群节点。每个消息有一个leader partition，还有两个follower partition。我没有画更多的Producer和Consumer、Consumer Group，是觉得线太多了容易乱。</p><p>因为Producer和Consumer肯定会从leader partition中读写数据，而Kafka也保证了leader在不同broker上的均衡，所以Kafka的集群能力很好。</p><!-- [[[read_end]]] --><p>我们再看一下消息是如何在Kafka中被存储的。</p><p><img src=\"https://static001.geekbang.org/resource/image/20/72/2047c0b11c63407a8ebfb696398b0272.png?wh=1131*346\" alt=\"\"></p><p>上图是Kafka数据的存储方式，也就是每个分区都是一直往后面加的。</p><p>我们再来看一下它的数据存储方式。</p><p>首先是目录：</p><pre><code>drwxr-xr-x 2 root root 4096 Feb  7 23:39 test-0\ndrwxr-xr-x 2 root root 4096 Feb  7 01:34 test_perf-1\ndrwxr-xr-x 2 root root 4096 Feb  7 01:34 test_perf-4\n</code></pre><p>Kafka的目录是根据topic创建的，每个目录名中也包括一个partition。比如上面名字中的test_perf-1就是topic名是test_perf，partition就是1。</p><p>接着再来看下文件：</p><pre><code>[root@node-2 test-2]# ll\ntotal 10850656\n-rw-r--r-- 1 root root     493128 Feb  9 14:14 00000000000000000000.index\n-rw-r--r-- 1 root root 1073739646 Feb  9 14:14 00000000000000000000.log\n-rw-r--r-- 1 root root     630504 Feb  9 14:14 00000000000000000000.timeindex\n-rw-r--r-- 1 root root     443520 Feb  9 14:16 00000000000000240212.index\n-rw-r--r-- 1 root root 1073727327 Feb  9 14:16 00000000000000240212.log\n-rw-r--r-- 1 root root     551052 Feb  9 14:16 00000000000000240212.timeindex\n-rw-r--r-- 1 root root     448840 Feb  9 14:18 00000000000000453584.index\n-rw-r--r-- 1 root root 1073729759 Feb  9 14:18 00000000000000453584.log\n-rw-r--r-- 1 root root     556920 Feb  9 14:18 00000000000000453584.timeindex\n.........................\n-rw-r--r-- 1 root root         12 Feb  9 13:14 leader-epoch-checkpoint\n[root@node-2 test-2]#\n</code></pre><p>有索引文件，有数据文件，也有时间索引文件，非常明显的三个后缀名。索引文件显然就是指向message在数据文件中的什么位置，而这些数据文件就是一个个的Segment，也就是一段一段的。这些文件的大小受server.properties文件中的log.segment.bytes参数限制，默认为1G。</p><p>要查到相应的message就要先查索引文件，找到message的位置；然后从log文件中找到具体的message。</p><p>在这个逻辑中，Segment的大小就很有讲究了，太细就会导致索引文件过大，查找索引费时间；太粗了就会导致查找得不够精准。那么该如何配置呢？也要通过性能测试才能知道。</p><p>有了这些信息之后，我们再看下Kafka高效的原因：</p><ol>\n<li>Kafka直接使用Linux文件系统的Cache来高效缓存数据。</li>\n<li>Kafka采用Linux Zero-Copy技术提高发送性能（不懂Linux Zero-copy的请自行补课）。</li>\n<li>Kafka服务端采用的是selector多线程模式（从逻辑上理解，它和Tomcat的NIO类似，我就不单独画图了，以免占篇幅）。</li>\n<li>Kafka采用二分法找数据。</li>\n</ol><p>总体来说，就是一个Java的应用，直接使用文件系统和操作系统的特性实现了队列的高效应用场景。</p><h2>配置文件</h2><p>我们先来查看一下Kafka的配置文件中都有什么，为了简洁，在这里，我把一些注释以及和性能无关的配置删除了。当然如果你有兴趣的话，可以到Kafka的config目录中找到server.properties中，以查看这些内容。</p><pre><code>############################# Socket Server Settings #############################\nnum.network.threads=3\nnum.io.threads=8\nsocket.send.buffer.bytes=102400\nsocket.receive.buffer.bytes=102400\nsocket.request.max.bytes=104857600\n\n\n############################# Log Basics #############################\nnum.partitions=10\nnum.recovery.threads.per.data.dir=1\n\n\n############################# Internal Topic Settings  #############################\noffsets.topic.replication.factor=1\ntransaction.state.log.replication.factor=1\ntransaction.state.log.min.isr=1\n\n\n############################# Log Flush Policy #############################\nlog.flush.interval.messages=10000\nlog.flush.interval.ms=1000\n\n\n############################# Log Retention Policy #############################\nlog.retention.check.interval.ms=300000\n\n\n############################# Zookeeper #############################\nzookeeper.connection.timeout.ms=6000\n\n\n############################# Group Coordinator Settings #############################\ngroup.initial.rebalance.delay\n\n</code></pre><p>其实配置文件并不多，对不对？从配置名称上也很容易知道它们和什么相关。这里比较重要的参数就是Socket Server相关的，以及和log相关的。</p><p>我觉得到了这里，这个逻辑就基本清楚了，对Kafka的性能优化也就有了大体的判断。</p><h2>构建Kafka的性能优化思维导图</h2><p>我们可以根据以上的知识画出如下所示的，Kafka的基本优化点：</p><p><img src=\"https://static001.geekbang.org/resource/image/b2/db/b2b0ad6f744035d26d5efab25d4ec9db.png?wh=1299*592\" alt=\"\"></p><p>同样的，我把操作系统和JDK方面的优化当成独立的部分，在上图中只把Kafka相关的内容列出来。</p><p>有了上面的知识，也有了这个思维逻辑，那么就可以理出针对一个Kafka应用要干的事情：</p><ol>\n<li>先分析一下具体的应用场景，关键是topic、partition数量、message大小。</li>\n<li>确定要支撑的业务容量和时间长度。</li>\n<li>分析架构中需要的broker量级、partition、Segment等配置。这些配置应该是架构师给出的准确预估，如果不能给出，那只能靠我们，也就是做性能测试的人给出具体的结论了。</li>\n</ol><h2>对组件的性能分析思路</h2><p>我想告诉你的是对一个组件的性能分析思路。如果你有了下面这张图所示的思路，那至少可以覆盖大部分的性能问题了。这个思路就是：</p><p><img src=\"https://static001.geekbang.org/resource/image/62/ab/625d1ec2717f84cb2dc9119d8c7e43ab.jpg?wh=1947*1431\" alt=\"\"></p><p>对于Kafka这样的队列服务器来说，状态计数器是啥子呢？让我们看一下Kafka的一个Grafana Dashboard。</p><p><img src=\"https://static001.geekbang.org/resource/image/f0/d7/f0025246911a11e34d0608e607669ad7.png?wh=1279*396\" alt=\"\"></p><p><img src=\"https://static001.geekbang.org/resource/image/f9/1d/f9cefe3ff768fe06662a3ab26aca6c1d.png?wh=1280*400\" alt=\"\"></p><p><img src=\"https://static001.geekbang.org/resource/image/35/37/35319958007c7fbcb2332cc920af7837.png?wh=1282*314\" alt=\"\"></p><p>从这几个图就能看得出来，最重要的是每秒产生了多少message，以及消费时间间隔。这两个对我们来说是最重要的队列计数器了。</p><p>但是它们能不能告诉我们现在的队列服务器有没有瓶颈呢？显然是不能的。</p><p>对于队列来说，消息都是异步被消费者取走的。所以队列中要有保存消息的能力，但是保存多久呢？永远保存吗？显然不现实。但是如果保存得太短了，正常的业务都可能做不下去，所以，我们要制定策略，哪些topic是实时处理的，处理不完怎么办？内存多大，能保存多少消息，积压了怎么办？</p><p>所以对于队列服务器，只看上面的那几个计数器，我觉得过于片面。</p><p>我们前面提到的grafana+prometheus监控操作系统、MySQL的DashBoard都有非常完整的数据，但是Kafka的DashBoard显然信息不够，不能判断它自己有没有问题。</p><p>操作系统的监控指标对Kafka来说，也是异常的重要。就像之前我说过的那样，操作系统是不可绕过的分析节点。所以所有要做性能测试和性能分析的人，首先要学的就是操作系统方面的知识。</p><h2>示例</h2><p>下面我们来看一个简单测试示例。</p><h3>生产10W消息</h3><p>在这个示例中，共生产10W的消息，每个消息大小是2000字节，每秒产生5000个消息。</p><pre><code>[root@node-1 Kafka_2.13-2.4.0]# /home/zee/Kafka/Kafka_2.13-2.4.0/bin/Kafka-producer-perf-test.sh --topic test --num-records 100000 --record-size 2000 --throughput 5000 --producer-props bootstrap.servers=172.18.0.2:9092,172.19.0.14:9092,172.20.0.7:9092\n24997 records sent, 4999.4 records/sec (9.54 MB/sec), 15.8 ms avg latency, 398.0 ms max latency.\n25010 records sent, 5001.0 records/sec (9.54 MB/sec), 26.0 ms avg latency, 514.0 ms max latency.\n25000 records sent, 5000.0 records/sec (9.54 MB/sec), 1.1 ms avg latency, 24.0 ms max latency.\n100000 records sent, 4998.000800 records/sec (9.53 MB/sec), 11.03 ms avg latency, 514.00 ms max latency, 1 ms 50th, 52 ms 95th, 305 ms 99th, 501 ms 99.9th.\n</code></pre><p>可以看到每秒有9.53MB的消息产生，平均响应时延是11.03ms，最大时延是514ms。</p><h3>生产100W消息</h3><p>在这个示例中，共生产100W的消息，每个消息大小是2000字节，每秒产生5000个消息。</p><pre><code>[root@node-4 bin]# /home/zee/Kafka/Kafka_2.13-2.4.0/bin/Kafka-producer-perf-test.sh --topic test_perf --num-records 1000000 --record-size 2000 --throughput 5000 --producer-props bootstrap.servers=172.17.0.11:9092,172.19.0.14:9092,172.20.0.7:9092\n24992 records sent, 4996.4 records/sec (9.53 MB/sec), 21.7 ms avg latency, 482.0 ms max latency.\n25025 records sent, 5004.0 records/sec (9.54 MB/sec), 0.9 ms avg latency, 16.0 ms max latency.\n........\n25000 records sent, 5000.0 records/sec (9.54 MB/sec), 0.6 ms avg latency, 9.0 ms max latency.\n25005 records sent, 5001.0 records/sec (9.54 MB/sec), 0.7 ms avg latency, 30.0 ms max latency.\n1000000 records sent, 4999.625028 records/sec (9.54 MB/sec), 2.05 ms avg latency, 482.00 ms max latency, 1 ms 50th, 1 ms 95th, 16 ms 99th, 267 ms 99.9th.\n</code></pre><p>可以看到每秒有9.54MB的消息产生，平均响应时延是2.05ms，最大时延是482ms。</p><h3>生产1000W消息</h3><p>在这个示例中，生产1000W消息，其他参数不变：</p><pre><code>[root@node-4 bin]# /home/zee/Kafka/Kafka_2.13-2.4.0/bin/Kafka-producer-perf-test.sh --topic test_perf --num-records 10000000 --record-size 2000 --throughput 5000 --producer-props bootstrap.servers=172.17.0.11:9092,172.19.0.14:9092,172.20.0.7:9092\n24992 records sent, 4998.4 records/sec (9.53 MB/sec), 22.7 ms avg latency, 480.0 ms max latency.\n25015 records sent, 5002.0 records/sec (9.54 MB/sec), 0.8 ms avg latency, 13.0 ms max latency.\n25005 records sent, 5000.0 records/sec (9.54 MB/sec), 0.7 ms avg latency, 21.0 ms max latency.\n..........\n25000 records sent, 5000.0 records/sec (9.54 MB/sec), 0.7 ms avg latency, 26.0 ms max latency.\n25010 records sent, 5001.0 records/sec (9.54 MB/sec), 0.7 ms avg latency, 24.0 ms max latency.\n10000000 records sent, 4999.900002 records/sec (9.54 MB/sec), 0.83 ms avg latency, 532.00 ms max latency, 1 ms 50th, 1 ms 95th, 4 ms 99th, 65 ms 99.9th.\n</code></pre><p>从结果可以看到，每秒还是9.54MB大小的消息，平均时延0.83ms，最大时延是532ms。</p><p>来做一个图比对一下：</p><p><img src=\"https://static001.geekbang.org/resource/image/e4/8f/e4f416d4dc41898ad5dd264d9e022f8f.jpg?wh=557*338\" alt=\"\"></p><p>从这个图就明显看出生产的消息越少，平均响应时间越长。可见顺序写得越多，那每次写的平均时间就会越小，所以Kafka在大数据量的读写中会表现得非常好。</p><h2>总结</h2><p>严格来说，这一篇文章是为了告诉你一个逻辑，那就是对一个组件不了解的时候，如何用你的基础技术知识把对组件的性能优化方向整理出来，以及如何通过自己的基础知识来做一个非常合理的分析。</p><p>这个逻辑就是：</p><ol>\n<li>先了解这个组件的基本知识：包括架构、实现原理等信息。</li>\n<li>再整理出这个组件的配置参数。</li>\n<li>找到合适的全局监控工具。</li>\n<li>做压力测试时给出明显的判断。</li>\n</ol><p>这是个大体的逻辑，当然这个逻辑还有一个前提，那就是你得有相应的基础知识，在Kafka的这个分析中，要有操作系统和Java的基础知识，在实操中还需要多找几个不懂的组件做些练习才能理解这个逻辑的真谛。</p><p>就我自己来说，我会找一个完全没有接触过的组件，从安装部署开始直到性能测试、瓶颈判断、优化分析，看看需要多长时间，我才能理解得了这个组件。</p><p>这种思维方式，给了我很多的安全感，就是遇到了没接触过的内容，也不至心慌气短。</p><h2>思考题</h2><p>最后给你留两道思考题吧，你觉得如何分析一个未知组件呢？Kafka的分析逻辑又是什么？</p><p>欢迎你用自己的理解思考一下这两个问题，也欢迎把这篇文章分享给你的朋友或者同事，一起交流一下。</p>","neighbors":{"left":{"article_title":"23丨MySQL：数据库级监控及常用计数器解析（下）","id":197432},"right":{"article_title":"25丨SkyWalking：性能监控工具之链路级监控及常用计数器解析","id":199703}},"comments":[{"had_liked":false,"id":178966,"user_name":"夜空中最亮的星","can_delete":false,"product_type":"c1","uid":1267566,"ip_address":"","ucode":"ADC3E7B6789955","user_header":"https://static001.geekbang.org/account/avatar/00/13/57/6e/b6795c44.jpg","comment_is_top":false,"comment_ctime":1581864549,"is_pvip":false,"replies":[{"id":"69493","content":"多谢支持。能理顺思路就是最重要的。","user_name":"作者回复","user_name_real":"高楼(Zee)","uid":"1785562","ctime":1581911013,"ip_address":"","comment_id":178966,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10171799141","product_id":100042501,"comment_content":"听了这节课 思路清晰了","like_count":3,"discussions":[{"author":{"id":1785562,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/3e/da/e686a72b.jpg","nickname":"高楼(Zee)","note":"","ucode":"149202404A5ABC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":484042,"discussion_content":"多谢支持。能理顺思路就是最重要的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1581911013,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":178948,"user_name":"董飞","can_delete":false,"product_type":"c1","uid":1693828,"ip_address":"","ucode":"4A4A13C4A971E3","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/6Be8vjNk03LEXMl52vONOQvdKTL1MWPR6OsAGEDsHIZXw9FibW8c4YtNL6HAmB8wRkDNIEx15xawJ9PWLW4y1UA/132","comment_is_top":false,"comment_ctime":1581862463,"is_pvip":false,"replies":[{"id":"69494","content":"默认情况下，http的标准错误就会统计进去。","user_name":"作者回复","user_name_real":"高楼(Zee)","uid":"1785562","ctime":1581911042,"ip_address":"","comment_id":178948,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5876829759","product_id":100042501,"comment_content":"老师，请教下jmeter测性能时，聚合报告中有一个错误率，具体怎样的请求会被统计成错误？","like_count":1,"discussions":[{"author":{"id":1785562,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/3e/da/e686a72b.jpg","nickname":"高楼(Zee)","note":"","ucode":"149202404A5ABC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":484033,"discussion_content":"默认情况下，http的标准错误就会统计进去。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1581911042,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1744834,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/9f/c2/3d1c2f88.jpg","nickname":"京都念慈菴","note":"","ucode":"2A310A91069A5E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":212986,"discussion_content":"你可以生成html报告，上面就会详细列出你的错误统计，错误类型，还有前五个错误这些东西","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1585040169,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":289486,"user_name":"Geek_7869f6","can_delete":false,"product_type":"c1","uid":2558826,"ip_address":"","ucode":"C4090A8C49E657","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erVRFkhqd8tb8Hq0oFYHd5wfGxROKjg2dOC5KPJicpaSib6BF1cJeR7c7kibvMhdkiazSIygNxTFlaokQ/132","comment_is_top":false,"comment_ctime":1619051616,"is_pvip":false,"replies":[{"id":"105041","content":"持久化开不开，取决于业务需求。这个不是技术能决定的。<br>这个专栏已更新完，不会再出新内容。redis可优化的不多，查查资料应该也可以搞定。 ","user_name":"作者回复","user_name_real":"高楼(Zee)","uid":"1785562","ctime":1619077621,"ip_address":"","comment_id":289486,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1619051616","product_id":100042501,"comment_content":"老师，消息中间件性能测试过程中建议开持久化不？<br>另外，可以出一期redis性能优化不。","like_count":0,"discussions":[{"author":{"id":1785562,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/3e/da/e686a72b.jpg","nickname":"高楼(Zee)","note":"","ucode":"149202404A5ABC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":518928,"discussion_content":"持久化开不开，取决于业务需求。这个不是技术能决定的。\n这个专栏已更新完，不会再出新内容。redis可优化的不多，查查资料应该也可以搞定。 ","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1619077621,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":271040,"user_name":"修继伟","can_delete":false,"product_type":"c1","uid":1929596,"ip_address":"","ucode":"C438C858D039D0","user_header":"https://static001.geekbang.org/account/avatar/00/1d/71/7c/29f2d5ed.jpg","comment_is_top":false,"comment_ctime":1609379600,"is_pvip":false,"replies":[{"id":"98310","content":"那就得把栈发给我看看了。这样描述过于平面了。","user_name":"作者回复","user_name_real":"高楼(Zee)","uid":"1785562","ctime":1609417500,"ip_address":"","comment_id":271040,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1609379600","product_id":100042501,"comment_content":"老师 线程日志里出现大量的 waiting on condition  这个程序会有问题吗","like_count":0,"discussions":[{"author":{"id":1785562,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/3e/da/e686a72b.jpg","nickname":"高楼(Zee)","note":"","ucode":"149202404A5ABC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":512825,"discussion_content":"那就得把栈发给我看看了。这样描述过于平面了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1609417500,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":257005,"user_name":"雄鹰","can_delete":false,"product_type":"c1","uid":1786819,"ip_address":"","ucode":"67E0C4BDE7F6F2","user_header":"https://static001.geekbang.org/account/avatar/00/1b/43/c3/2c53acd7.jpg","comment_is_top":false,"comment_ctime":1603810382,"is_pvip":true,"replies":[{"id":"93927","content":"感谢支持。","user_name":"作者回复","user_name_real":"高楼(Zee)","uid":"1785562","ctime":1604280951,"ip_address":"","comment_id":257005,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1603810382","product_id":100042501,"comment_content":"正好项目组要测试kafka的基准测试，派上用场了，感谢老师o(^o^)o","like_count":0,"discussions":[{"author":{"id":1785562,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/3e/da/e686a72b.jpg","nickname":"高楼(Zee)","note":"","ucode":"149202404A5ABC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":508183,"discussion_content":"感谢支持。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1604280951,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":231153,"user_name":"GeekS","can_delete":false,"product_type":"c1","uid":1976460,"ip_address":"","ucode":"CB29620EC93F62","user_header":"https://static001.geekbang.org/account/avatar/00/1e/28/8c/c4d33971.jpg","comment_is_top":false,"comment_ctime":1593594436,"is_pvip":false,"replies":[{"id":"87983","content":"也可以用jmeter做呀。有插件。","user_name":"作者回复","user_name_real":"高楼(Zee)","uid":"1785562","ctime":1596077032,"ip_address":"","comment_id":231153,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1593594436","product_id":100042501,"comment_content":"老师，请教下，对于kafka队列这种客户端sdk与服务器对接的应用，用kafka自带性能脚本kafka-producer-perf-test.sh只能做基准性能测试，但是对于多种业务混合场景下的性能测试，有推荐的性能工具吗","like_count":0,"discussions":[{"author":{"id":1785562,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/3e/da/e686a72b.jpg","nickname":"高楼(Zee)","note":"","ucode":"149202404A5ABC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":500179,"discussion_content":"也可以用jmeter做呀。有插件。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1596077032,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":213487,"user_name":"t6666","can_delete":false,"product_type":"c1","uid":1953608,"ip_address":"","ucode":"9B3FC6BF459CFE","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/EjMVAocAC3kwH9zWkicAsJ3rFpTwUZFJdPvSs5jYHoOJXktk4AHnlpYgt1arm2gYTmvJqQaQ73MK4QzATNuFFsw/132","comment_is_top":false,"comment_ctime":1588431238,"is_pvip":false,"replies":[{"id":"81983","content":"未知组件，肯定是要先学习它的架构原理和使用，然后再分析的。","user_name":"作者回复","user_name_real":"高楼(Zee)","uid":"1785562","ctime":1590749092,"ip_address":"","comment_id":213487,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1588431238","product_id":100042501,"comment_content":"感觉自己还有很多需要学习，如果是我拿到未知组件应该先去看他的文档然后理清楚运行逻辑然后再分析吧，后面那个，我觉得我还是滚去看书了","like_count":0,"discussions":[{"author":{"id":1785562,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/3e/da/e686a72b.jpg","nickname":"高楼(Zee)","note":"","ucode":"149202404A5ABC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493795,"discussion_content":"未知组件，肯定是要先学习它的架构原理和使用，然后再分析的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1590749092,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":210492,"user_name":"月亮和六便士","can_delete":false,"product_type":"c1","uid":1080894,"ip_address":"","ucode":"EFFCB9171D4B4E","user_header":"https://static001.geekbang.org/account/avatar/00/10/7e/3e/82202cc8.jpg","comment_is_top":false,"comment_ctime":1587777633,"is_pvip":false,"replies":[{"id":"82003","content":"没有重要不重要。取决于问题在哪。","user_name":"作者回复","user_name_real":"高楼(Zee)","uid":"1785562","ctime":1590754116,"ip_address":"","comment_id":210492,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1587777633","product_id":100042501,"comment_content":"老师打开kafka-exporter 一堆的计数器，怎么确定哪个重要，哪个不重要","like_count":0,"discussions":[{"author":{"id":1785562,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/3e/da/e686a72b.jpg","nickname":"高楼(Zee)","note":"","ucode":"149202404A5ABC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493033,"discussion_content":"没有重要不重要。取决于问题在哪。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1590754116,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":182944,"user_name":"Duke","can_delete":false,"product_type":"c1","uid":1786107,"ip_address":"","ucode":"2EE45277C37484","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83er3G5DWFp5PEklibQPYE1m8OxtYqTcryibkcUHpP4ibBicf8OUYHB6V1iaSRaNiaFV8cuNFb0xbOUF7mZhQ/132","comment_is_top":false,"comment_ctime":1582894012,"is_pvip":false,"replies":[{"id":"70747","content":"多谢支持。","user_name":"作者回复","user_name_real":"高楼(Zee)","uid":"1785562","ctime":1582904077,"ip_address":"","comment_id":182944,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1582894012","product_id":100042501,"comment_content":"授人以鱼不如授人以渔！感谢老师，真的受益匪浅","like_count":1,"discussions":[{"author":{"id":1785562,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/3e/da/e686a72b.jpg","nickname":"高楼(Zee)","note":"","ucode":"149202404A5ABC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":485509,"discussion_content":"多谢支持。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1582904077,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]}]}