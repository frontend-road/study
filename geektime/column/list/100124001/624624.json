{"id":624624,"title":"46｜Master任务调度：服务发现与资源管理","content":"<p>你好，我是郑建勋。</p><p>在上一节课程中，我们实现了Master的选主，这一节课，我们继续深入Master的开发，实现一下Master的服务发现与资源的管理。</p><h2>Master服务发现</h2><p>首先我们来实现一下Master对Worker的服务发现。</p><p>Master需要监听Worker节点的信息，感知到Worker节点的注册与销毁。和服务的注册一样，我们的服务发现也使用micro提供的registry功能，代码如下所示。</p><p>m.WatchWorker方法调用registry.Watch监听Worker节点的变化，watch.Next()会堵塞等待节点的下一个事件，当Master收到节点变化事件时，将事件发送到workerNodeChange通道。m.Campaign方法接收到变化事件后，会用日志打印出变化的信息。</p><pre><code class=\"language-plain\">\nfunc (m *Master) Campaign() {\n\t...\n\tworkerNodeChange := m.WatchWorker()\n\n\tfor {\n\t\tselect {\n\t\t...\n\t\tcase resp := &lt;-workerNodeChange:\n\t\t\tm.logger.Info(\"watch worker change\", zap.Any(\"worker:\", resp))\n\t\t}\n\t}\n}\n\nfunc (m *Master) WatchWorker() chan *registry.Result {\n\twatch, err := m.registry.Watch(registry.WatchService(worker.ServiceName))\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tch := make(chan *registry.Result)\n\tgo func() {\n\t\tfor {\n\t\t\tres, err := watch.Next()\n\t\t\tif err != nil {\n\t\t\t\tm.logger.Info(\"watch worker service failed\", zap.Error(err))\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tch &lt;- res\n\t\t}\n\t}()\n\treturn ch\n\n}\n</code></pre><!-- [[[read_end]]] --><p>Master中的etcd registry对象是我们在初始化时注册到go-micro中的。</p><pre><code class=\"language-plain\">// cmd/master/master.go\nreg := etcd.NewRegistry(registry.Addrs(sconfig.RegistryAddress))\nmaster.New(\n\tmasterID,\n\tmaster.WithLogger(logger.Named(\"master\")),\n\tmaster.WithGRPCAddress(GRPCListenAddress),\n\tmaster.WithregistryURL(sconfig.RegistryAddress),\n\tmaster.WithRegistry(reg),\n\tmaster.WithSeeds(seeds),\n)\n</code></pre><h3>深入go-micro registry接口</h3><p>go-micro提供的registry接口提供了诸多API，其结构如下所示。</p><pre><code class=\"language-plain\">type Registry interface {\n\tInit(...Option) error\n\tOptions() Options\n\tRegister(*Service, ...RegisterOption) error\n\tDeregister(*Service, ...DeregisterOption) error\n\tGetService(string, ...GetOption) ([]*Service, error)\n\tListServices(...ListOption) ([]*Service, error)\n\tWatch(...WatchOption) (Watcher, error)\n\tString() string\n}\n</code></pre><p>对于Master的服务发现，我们借助了registry.Watch方法。Watch方法借助client.Watch实现了对特定Key的监听，并封装了client.Watch返回的结果。</p><pre><code class=\"language-plain\">func (e *etcdRegistry) Watch(opts ...registry.WatchOption) (registry.Watcher, error) {\n   return newEtcdWatcher(e, e.options.Timeout, opts...)\n}\n\nfunc newEtcdWatcher(r *etcdRegistry, timeout time.Duration, opts ...registry.WatchOption) (registry.Watcher, error) {\n   var wo registry.WatchOptions\n   for _, o := range opts {\n      o(&amp;wo)\n   }\n   watchPath := prefix\n   if len(wo.Service) &gt; 0 {\n      watchPath = servicePath(wo.Service) + \"/\"\n   }\n   return &amp;etcdWatcher{\n      stop:    stop,\n      w:       r.client.Watch(ctx, watchPath, clientv3.WithPrefix(), clientv3.WithPrevKV()),\n      client:  r.client,\n      timeout: timeout,\n   }, nil\n}\n</code></pre><p>registry.Watch方法返回了Watcher接口，Watcher接口中有Next方法用于完成事件的迭代。</p><pre><code class=\"language-plain\">type Watcher interface {\n   // Next 堵塞调用\n   Next() (*Result, error)\n   Stop()\n}\n</code></pre><p>go-micro 的 etcd 插件库实现的 Next 方法也比较简单，只要监听client.Watch返回的通道，并将事件信息封装后返回即可。</p><pre><code class=\"language-plain\">func (ew *etcdWatcher) Next() (*registry.Result, error) {\n   for wresp := range ew.w {\n      if wresp.Err() != nil {\n         return nil, wresp.Err()\n      }\n      if wresp.Canceled {\n         return nil, errors.New(\"could not get next\")\n      }\n      for _, ev := range wresp.Events {\n         service := decode(ev.Kv.Value)\n         var action string\n         switch ev.Type {\n         case clientv3.EventTypePut:\n            if ev.IsCreate() {\n               action = \"create\"\n            } else if ev.IsModify() {\n               action = \"update\"\n            }\n         case clientv3.EventTypeDelete:\n            action = \"delete\"\n            // get service from prevKv\n            service = decode(ev.PrevKv.Value)\n         }\n         if service == nil {\n            continue\n         }\n         return &amp;registry.Result{\n            Action:  action,\n            Service: service,\n         }, nil\n      }\n   }\n   return nil, errors.New(\"could not get next\")\n}\n</code></pre><p>另外，Worker节点也利用了registry接口的Register方法实现了服务的注册。如下所示，Register方法最终调用了clientv3的Put方法，将包含节点信息的键值对写入了etcd中。</p><pre><code class=\"language-plain\">func (e *etcdRegistry) Register(s *registry.Service, opts ...registry.RegisterOption) error {\n\t// register each node individually\n\tfor _, node := range s.Nodes {\n\t\terr := e.registerNode(s, node, opts...)\n\t\tif err != nil {\n\t\t\tgerr = err\n\t\t}\n\t}\n\treturn gerr\n}\n\nfunc (e *etcdRegistry) registerNode(s *registry.Service, node *registry.Node, opts ...registry.RegisterOption) error {\n\tservice := &amp;registry.Service{\n\t\tName:      s.Name,\n\t\tVersion:   s.Version,\n\t\tMetadata:  s.Metadata,\n\t\tEndpoints: s.Endpoints,\n\t\tNodes:     []*registry.Node{node},\n\t}\n\t...\n\t// create an entry for the node\n\tif lgr != nil {\n\t\t_, err = e.client.Put(ctx, nodePath(service.Name, node.Id), encode(service), clientv3.WithLease(lgr.ID))\n\t} else {\n\t\t_, err = e.client.Put(ctx, nodePath(service.Name, node.Id), encode(service))\n\t}\n\tif err != nil {\n\t\treturn err\n\t}\n}\n</code></pre><p>现在让我们来看一看服务发现的效果。首先，启动Master服务。</p><pre><code class=\"language-plain\">» go run main.go master --id=2 --http=:8081  --grpc=:9091\n</code></pre><p>接着启动Worker服务。</p><pre><code class=\"language-plain\">» go run main.go worker --id=2 --http=:8079  --grpc=:9089\n</code></pre><p>Worker启动后，在Master的日志中会看到变化的事件。其中，<code>\"Action\":\"create\"</code> 表明当前的事件为节点的注册。</p><pre><code class=\"language-plain\">{\"level\":\"INFO\",\"ts\":\"2022-12-12T16:55:42.798+0800\",\"logger\":\"master\",\"caller\":\"master/master.go:117\",\"msg\":\"watch worker change\",\"worker:\":{\"Action\":\"create\",\"Service\":{\"name\":\"go.micro.server.worker\",\"version\":\"latest\",\"metadata\":null,\"endpoints\":[{\"name\":\"Greeter.Hello\",\"request\":{\"name\":\"Request\",\"type\":\"Request\",\"values\":[{\"name\":\"name\",\"type\":\"string\",\"values\":null}]},\"response\":{\"name\":\"Response\",\"type\":\"Response\",\"values\":[{\"name\":\"greeting\",\"type\":\"string\",\"values\":null}]},\"metadata\":{\"endpoint\":\"Greeter.Hello\",\"handler\":\"rpc\",\"method\":\"POST\",\"path\":\"/greeter/hello\"}}],\"nodes\":[{\"id\":\"go.micro.server.worker-2\",\"address\":\"192.168.0.107:9089\",\"metadata\":{\"broker\":\"http\",\"protocol\":\"grpc\",\"registry\":\"etcd\",\"server\":\"grpc\",\"transport\":\"grpc\"}}]}}}\n</code></pre><p>中止Worker节点后，我们还会看到Master的信息。其中，<code>\"Action\":\"delete\"</code> 表明当前的事件为节点的删除。</p><pre><code class=\"language-plain\">{\"level\":\"INFO\",\"ts\":\"2022-12-12T16:58:31.985+0800\",\"logger\":\"master\",\"caller\":\"master/master.go:117\",\"msg\":\"watch worker change\",\"worker:\":{\"Action\":\"delete\",\"Service\":{\"name\":\"go.micro.server.worker\",\"version\":\"latest\",\"metadata\":null,\"endpoints\":[{\"name\":\"Greeter.Hello\",\"request\":{\"name\":\"Request\",\"type\":\"Request\",\"values\":[{\"name\":\"name\",\"type\":\"string\",\"values\":null}]},\"response\":{\"name\":\"Response\",\"type\":\"Response\",\"values\":[{\"name\":\"greeting\",\"type\":\"string\",\"values\":null}]},\"metadata\":{\"endpoint\":\"Greeter.Hello\",\"handler\":\"rpc\",\"method\":\"POST\",\"path\":\"/greeter/hello\"}}],\"nodes\":[{\"id\":\"go.micro.server.worker-2\",\"address\":\"192.168.0.107:9089\",\"metadata\":{\"broker\":\"http\",\"protocol\":\"grpc\",\"registry\":\"etcd\",\"server\":\"grpc\",\"transport\":\"grpc\"}}]}}}\n</code></pre><h3>维护Worker节点信息</h3><p>完成服务发现之后，让我们更进一步，维护Worker节点的信息。在updateWorkNodes函数中，我们利用registry.GetService方法获取当前集群中全量的Worker节点，并将它最新的状态保存起来。</p><pre><code class=\"language-plain\">func (m *Master) Campaign() {\n\t...\n\tworkerNodeChange := m.WatchWorker()\n\n\tfor {\n\t\tselect {\n\t\t...\n\t\tcase resp := &lt;-workerNodeChange:\n\t\t\tm.logger.Info(\"watch worker change\", zap.Any(\"worker:\", resp))\n\t\t}\n\t}\n}\n\ntype Master struct {\n\t...\n\tworkNodes map[string]*registry.Node\n}\n\nfunc (m *Master) updateWorkNodes() {\n\tservices, err := m.registry.GetService(worker.ServiceName)\n\tif err != nil {\n\t\tm.logger.Error(\"get service\", zap.Error(err))\n\t}\n\n\tnodes := make(map[string]*registry.Node)\n\tif len(services) &gt; 0 {\n\t\tfor _, spec := range services[0].Nodes {\n\t\t\tnodes[spec.Id] = spec\n\t\t}\n\t}\n\n\tadded, deleted, changed := workNodeDiff(m.workNodes, nodes)\n\tm.logger.Sugar().Info(\"worker joined: \", added, \", leaved: \", deleted, \", changed: \", changed)\n\n\tm.workNodes = nodes\n\n}\n</code></pre><p>我们还可以使用 workNodeDiff 函数比较集群中新旧节点的变化。</p><pre><code class=\"language-plain\">func workNodeDiff(old map[string]*registry.Node, new map[string]*registry.Node) ([]string, []string, []string) {\n\tadded := make([]string, 0)\n\tdeleted := make([]string, 0)\n\tchanged := make([]string, 0)\n\tfor k, v := range new {\n\t\tif ov, ok := old[k]; ok {\n\t\t\tif !reflect.DeepEqual(v, ov) {\n\t\t\t\tchanged = append(changed, k)\n\t\t\t}\n\t\t} else {\n\t\t\tadded = append(added, k)\n\t\t}\n\t}\n\tfor k := range old {\n\t\tif _, ok := new[k]; !ok {\n\t\t\tdeleted = append(deleted, k)\n\t\t}\n\t}\n\treturn added, deleted, changed\n}\n</code></pre><p>当节点发生变化时，可以打印出日志。</p><pre><code class=\"language-plain\">{\"level\":\"INFO\",\"ts\":\"2022-12-12T16:55:42.810+0800\",\"logger\":\"master\",\"caller\":\"master/master.go:187\",\"msg\":\"worker joined: [go.micro.server.worker-2], leaved: [], changed: []\"}\n{\"level\":\"INFO\",\"ts\":\"2022-12-12T16:58:32.026+0800\",\"logger\":\"master\",\"caller\":\"master/master.go:187\",\"msg\":\"worker joined: [], leaved: [go.micro.server.worker-2], changed: []\"}\n</code></pre><h2>Master资源管理</h2><p>下一步，让我们来看看对爬虫任务的管理。</p><p>爬虫任务也可以理解为一种资源。和Worker一样，Master中可以有一些初始化的爬虫任务存储在配置文件中。初始化时，程序通过读取配置文件将爬虫任务注入到Master中。这节课我们先将任务放置到配置文件中，下节课我们还会构建Master的API来完成任务的增删查改。</p><pre><code class=\"language-plain\">seeds := worker.ParseTaskConfig(logger, nil, nil, tcfg)\n\tmaster.New(\n\t\tmasterID,\n\t\tmaster.WithLogger(logger.Named(\"master\")),\n\t\tmaster.WithGRPCAddress(GRPCListenAddress),\n\t\tmaster.WithregistryURL(sconfig.RegistryAddress),\n\t\tmaster.WithRegistry(reg),\n\t\tmaster.WithSeeds(seeds),\n\t)\n</code></pre><p>在初始化Master时，调用m.AddSeed函数完成资源的添加。m.AddSeed会首先调用etcdCli.Get方法，查看当前任务是否已经写入到了etcd中。如果没有，则调用m.AddResource将任务存储到etcd，存储在etcd中的任务的Key为 <code>/resources/xxxx</code>。</p><pre><code class=\"language-plain\">func (m *Master) AddSeed() {\n\trs := make([]*ResourceSpec, 0, len(m.Seeds))\n\tfor _, seed := range m.Seeds {\n\t\tresp, err := m.etcdCli.Get(context.Background(), getResourcePath(seed.Name), clientv3.WithSerializable())\n\t\tif err != nil {\n\t\t\tm.logger.Error(\"etcd get faiiled\", zap.Error(err))\n\t\t\tcontinue\n\t\t}\n\t\tif len(resp.Kvs) == 0 {\n\t\t\tr := &amp;ResourceSpec{\n\t\t\t\tName: seed.Name,\n\t\t\t}\n\t\t\trs = append(rs, r)\n\t\t}\n\t}\n\n\tm.AddResource(rs)\n}\n\nconst (\n\tRESOURCEPATH = \"/resources\"\n)\n\nfunc getResourcePath(name string) string {\n\treturn fmt.Sprintf(\"%s/%s\", RESOURCEPATH, name)\n}\n</code></pre><p>在添加资源的时候，我们可以设置资源的ID、创建时间等。在这里我借助了第三方库 <a href=\"https://github.com/bwmarrin/snowflake\">Snowflake</a> ，使用雪花算法来为资源生成了一个单调递增的分布式ID。</p><pre><code class=\"language-plain\">func (m *Master) AddResource(rs []*ResourceSpec) {\n\tfor _, r := range rs {\n\t\tr.ID = m.IDGen.Generate().String()\n\t\tns, err := m.Assign(r)\n\t\tif err != nil {\n\t\t\tm.logger.Error(\"assign failed\", zap.Error(err))\n\t\t\tcontinue\n\t\t}\n\t\tr.AssignedNode = ns.Id + \"|\" + ns.Address\n\t\tr.CreationTime = time.Now().UnixNano()\n\t\tm.logger.Debug(\"add resource\", zap.Any(\"specs\", r))\n\n\t\t_, err = m.etcdCli.Put(context.Background(), getResourcePath(r.Name), encode(r))\n\t\tif err != nil {\n\t\t\tm.logger.Error(\"put etcd failed\", zap.Error(err))\n\t\t\tcontinue\n\t\t}\n\t\tm.resources[r.Name] = r\n\t}\n}\n</code></pre><p>Snowflake&nbsp;利用雪花算法生成了一个64位的唯一ID，其结构如下。</p><pre><code class=\"language-plain\">\n+--------------------------------------------------------------------------+\n| 1 Bit Unused | 41 Bit Timestamp |  10 Bit NodeID  |   12 Bit Sequence ID |\n+--------------------------------------------------------------------------+\n</code></pre><p>其中，41位用于存储时间戳；10位用于存储NodeID，在这里就是我们的Master ID；最后12位为序列号。如果我们的程序打算在同一个毫秒内生成多个ID，那么每生成一个新的ID，序列号会递增1，这意味着每个节点每毫秒最多能够产生4096个不同的ID，这已经能满足我们当前的场景了。雪花算法确保了我们生成的资源ID是全局唯一的。</p><p>添加资源时，还有一步很重要，那就是调用m.Assign计算出当前的资源应该被分配到哪一个节点上。在这里，我们先用随机的方式选择一个节点，后面还会再优化调度逻辑。</p><pre><code class=\"language-plain\">func (m *Master) Assign(r *ResourceSpec) (*registry.Node, error) {\n\tfor _, n := range m.workNodes {\n\t\treturn n, nil\n\t}\n\treturn nil, errors.New(\"no worker nodes\")\n}\n</code></pre><p>设置好资源的ID信息、分配信息之后，调用etcdCli.Put，将资源的KV信息存储到etcd中。其中，存储到etcd中的Value需要是string类型，所以我们书写了JSON的序列化与反序列化函数，用于存储信息的序列化和反序列化。</p><pre><code class=\"language-plain\">func encode(s *ResourceSpec) string {\n\tb, _ := json.Marshal(s)\n\treturn string(b)\n}\n\nfunc decode(ds []byte) (*ResourceSpec, error) {\n\tvar s *ResourceSpec\n\terr := json.Unmarshal(ds, &amp;s)\n\treturn s, err\n}\n</code></pre><p>最后一步，当Master成为新的Leader后，我们还要全量地获取一次etcd中当前最新的资源信息，并把它保存到内存中，核心逻辑位于loadResource函数中。</p><pre><code class=\"language-plain\">\nfunc (m *Master) BecomeLeader() error {\n\tif err := m.loadResource(); err != nil {\n\t\treturn fmt.Errorf(\"loadResource failed:%w\", err)\n\t}\n\tatomic.StoreInt32(&amp;m.ready, 1)\n\treturn nil\n}\n\nfunc (m *Master) loadResource() error {\n\tresp, err := m.etcdCli.Get(context.Background(), RESOURCEPATH, clientv3.WithSerializable())\n\tif err != nil {\n\t\treturn fmt.Errorf(\"etcd get failed\")\n\t}\n\n\tresources := make(map[string]*ResourceSpec)\n\tfor _, kv := range resp.Kvs {\n\t\tr, err := decode(kv.Value)\n\t\tif err == nil &amp;&amp; r != nil {\n\t\t\tresources[r.Name] = r\n\t\t}\n\t}\n\tm.logger.Info(\"leader init load resource\", zap.Int(\"lenth\", len(m.resources)))\n\tm.resources = resources\n\treturn nil\n}\n</code></pre><h3>验证Master资源分配结果</h3><p>最后让我们实战验证一下 Master的资源分配结果。</p><p>首先我们需要启动Worker。要注意的是，如果先启动了Master，初始的任务将会由于没有对应的Worker节点而添加失败。</p><pre><code class=\"language-plain\">» go run main.go worker --id=2 --http=:8079&nbsp; --grpc=:9089\n</code></pre><p>接着启动Master服务。</p><pre><code class=\"language-plain\">» go run main.go master --id=2 --http=:8081  --grpc=:9091\n</code></pre><p>现在查看etcd的信息会发现，当前两个爬虫任务都已经设置到etcd中，并且Master为他们分配的Worker节点为\"go.micro.server.worker-2|192.168.0.107:9089\"，说明Master的资源分配成功了。</p><pre><code class=\"language-plain\">» docker exec etcd-gcr-v3.5.6 /bin/sh -c \"/usr/local/bin/etcdctl get --prefix /\"                                                                           jackson@bogon\n/micro/registry/go.micro.server.master/go.micro.server.master-2\n{\"name\":\"go.micro.server.master\",\"version\":\"latest\",\"metadata\":null,\"endpoints\":[{\"name\":\"Greeter.Hello\",\"request\":{\"name\":\"Request\",\"type\":\"Request\",\"values\":[{\"name\":\"name\",\"type\":\"string\",\"values\":null}]},\"response\":{\"name\":\"Response\",\"type\":\"Response\",\"values\":[{\"name\":\"greeting\",\"type\":\"string\",\"values\":null}]},\"metadata\":{\"endpoint\":\"Greeter.Hello\",\"handler\":\"rpc\",\"method\":\"POST\",\"path\":\"/greeter/hello\"}}],\"nodes\":[{\"id\":\"go.micro.server.master-2\",\"address\":\"192.168.0.107:9091\",\"metadata\":{\"broker\":\"http\",\"protocol\":\"grpc\",\"registry\":\"etcd\",\"server\":\"grpc\",\"transport\":\"grpc\"}}]}\n\n/micro/registry/go.micro.server.worker/go.micro.server.worker-2\n{\"name\":\"go.micro.server.worker\",\"version\":\"latest\",\"metadata\":null,\"endpoints\":[{\"name\":\"Greeter.Hello\",\"request\":{\"name\":\"Request\",\"type\":\"Request\",\"values\":[{\"name\":\"name\",\"type\":\"string\",\"values\":null}]},\"response\":{\"name\":\"Response\",\"type\":\"Response\",\"values\":[{\"name\":\"greeting\",\"type\":\"string\",\"values\":null}]},\"metadata\":{\"endpoint\":\"Greeter.Hello\",\"handler\":\"rpc\",\"method\":\"POST\",\"path\":\"/greeter/hello\"}}],\"nodes\":[{\"id\":\"go.micro.server.worker-2\",\"address\":\"192.168.0.107:9089\",\"metadata\":{\"broker\":\"http\",\"protocol\":\"grpc\",\"registry\":\"etcd\",\"server\":\"grpc\",\"transport\":\"grpc\"}}]}\n\n/resources/douban_book_list\n{\"ID\":\"1602250527540776960\",\"Name\":\"douban_book_list\",\"AssignedNode\":\"go.micro.server.worker-2|192.168.0.107:9089\",\"CreationTime\":1670841268798763000}\n\n/resources/election/3f3584fc571ae9d0\nmaster2-192.168.0.107:9091\n\n/resources/xxx\n{\"ID\":\"1602250527570137088\",\"Name\":\"xxx\",\"AssignedNode\":\"go.micro.server.worker-2|192.168.0.107:9089\",\"CreationTime\":1670841268805921000}\n</code></pre><h2>总结</h2><p>这节课。我们实现了Master的两个重要功能：服务发现与资源管理。</p><p>对于服务发现，我们借助了micro registry提供的接口，实现了节点的注册、发现和状态获取。micro的registry接口是一个插件，这意味着我们可以轻松使用不同插件与不同的注册中心交互。在这里我们使用的仍然是go-micro的etcd插件，借助etcd clientv3的API实现了服务发现与注册的相关功能。</p><p>而对于资源管理，这节课我们为资源加上了必要的ID信息，我们使用了分布式的雪花算法来保证生成ID全局唯一。同时，我们用随机的方式为资源分配了其所属的Worker节点并验证了分配的效果。在下一节课程中，我们还会继续实现负载均衡的资源分配。</p><h2>课后题</h2><p>学完这节课，给你留两道思考题。</p><ol>\n<li>我们什么时候需要全量拉取资源？什么时候需要使用事件监听机制？你认为监听机制是可靠的吗？</li>\n<li>我们前面提到的 Snowflake 雪花算法生成的分布式ID，在什么场景下是不适用的？</li>\n</ol><p>欢迎你在留言区与我交流讨论，我们下节课见。</p>","comments":[{"had_liked":false,"id":367494,"user_name":"Realm","can_delete":false,"product_type":"c1","uid":1081299,"ip_address":"浙江","ucode":"30CBEBE619D1A2","user_header":"https://static001.geekbang.org/account/avatar/00/10/7f/d3/b5896293.jpg","comment_is_top":false,"comment_ctime":1675262559,"is_pvip":true,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100124001,"comment_content":"1 “当 Master 成为新的 Leader 后，我们还要全量地获取一次 etcd 中当前最新的资源信息，并把它保存到内存中”，\n当添加单个task任务时，使用事件监听；\n事件监听机制在服务异常时可能丢信息？\n望勋哥指点.\n\n2 雪花算法生成的id有可能会出现重复。\n如一个节点时，把服务器时钟回拨的情况；\n多个节点时候，假如服务器的标志位一样，同一毫秒不同的节点可能产生的id相同；","like_count":1},{"had_liked":false,"id":367514,"user_name":"胡军","can_delete":false,"product_type":"c1","uid":1719006,"ip_address":"浙江","ucode":"4DA22C603EE773","user_header":"https://static001.geekbang.org/account/avatar/00/1a/3a/de/ed40f1bb.jpg","comment_is_top":false,"comment_ctime":1675299303,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100124001,"comment_content":"老师语速好快，都来不及思考和看文档😅","like_count":0}]}