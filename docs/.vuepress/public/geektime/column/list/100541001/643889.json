{"id":643889,"title":"05｜善用Embedding，我们来给文本分分类","content":"<p>你好，我是徐文浩。</p><p>上一讲里我们看到大模型的确有效。在进行情感分析的时候，我们通过OpenAI的API拿到的Embedding，比T5-base这样单机可以运行的小模型，效果还是好很多的。</p><p>不过，我们之前选用的问题的确有点太简单了。我们把5个不同的分数分成了正面、负面和中性，还去掉了相对难以判断的“中性”评价，这样我们判断的准确率高的确是比较好实现的。但如果我们想要准确地预测出具体的分数呢？</p><h2>利用Embedding，训练机器学习模型</h2><p>最简单的办法就是利用我们拿到的文本Embedding的向量。这一次，我们不直接用向量之间的距离，而是使用传统的机器学习的方法来进行分类。毕竟，如果只是用向量之间的距离作为衡量标准，就没办法最大化地利用已经标注好的分数信息了。</p><p>事实上，OpenAI在自己的官方教程里也直接给出了这样一个例子。我在这里也放上了相应的GitHub的代码<a href=\"https://github.com/openai/openai-cookbook/blob/main/examples/Classification_using_embeddings.ipynb\">链接</a>，你可以去看一下。不过，为了避免OpenAI王婆卖瓜自卖自夸，我们也希望能和其他人用传统的机器学习方式得到的结果做个比较。</p><p>因此我重新找了一个中文的数据集来试一试。这个数据集是在中文互联网上比较容易找到的一份今日头条的新闻标题和新闻关键词，在GitHub上可以直接找到数据，我把<a href=\"https://github.com/aceimnorstuvwxz/toutiao-text-classfication-dataset\">链接</a>也放在这里。用这个数据集的好处是，有人同步放出了预测的实验效果。我们可以拿自己训练的结果和他做个对比。</p><!-- [[[read_end]]] --><h2>数据处理，小坑也不少</h2><p>在训练模型之前，我们要先获取每一个新闻标题的Embedding。我们通过Pandas这个Python数据处理库，把对应的文本加载到内存里。接着去调用之前我们使用过的OpenAI的Embedding接口，然后把返回结果一并存下来就好了。这个听起来非常简单直接，我也把对应的代码先放在下面，不过你先别着急运行。</p><p><span class=\"reference\">注：因为后面的代码可能会耗费比较多的Token数量，如果你使用的是免费的5美元额度的话，可以直接去拿我放在Github里的<a href=\"https://github.com/xuwenhao/geektime-ai-course\">数据文件</a>，用我已经处理好的数据。</span></p><pre><code class=\"language-python\">import pandas as pd\nimport tiktoken\nimport openai\nimport os\n\nfrom openai.embeddings_utils import get_embedding, get_embeddings\n\nopenai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n\n# embedding model parameters\nembedding_model = \"text-embedding-ada-002\"\nembedding_encoding = \"cl100k_base\"  # this the encoding for text-embedding-ada-002\nmax_tokens = 8000  # the maximum for text-embedding-ada-002 is 8191\n\n# import data/toutiao_cat_data.txt as a pandas dataframe\ndf = pd.read_csv('data/toutiao_cat_data.txt', sep='_!_', names=['id', 'code', 'category', 'title', 'keywords'])\ndf = df.fillna(\"\")\ndf[\"combined\"] = (\n    \"标题: \" + df.title.str.strip() + \"; 关键字: \" + df.keywords.str.strip()\n)\n\nprint(\"Lines of text before filtering: \", len(df))\n\nencoding = tiktoken.get_encoding(embedding_encoding)\n# omit reviews that are too long to embed\ndf[\"n_tokens\"] = df.combined.apply(lambda x: len(encoding.encode(x)))\ndf = df[df.n_tokens &lt;= max_tokens]\n\nprint(\"Lines of text after filtering: \", len(df))\n</code></pre><p><span class=\"reference\">注：这个是加载数据并做一些简单预处理的代码，你可以直接运行。</span></p><p>此外，我们也需要和前几讲的代码一样，定义一个 get_embedding 的函数，方便后面调用。这个函数原本在早期的openai库里是直接提供的，但是随着API的不断更新，这个库已经被移除了，不过代码非常简单，我们自己来定义一下就好。</p><pre><code>from openai import OpenAI\nimport os\n\nclient = OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n\nEMBEDDING_MODEL = &quot;text-embedding-ada-002&quot;\n\ndef get_embedding(text, model=EMBEDDING_MODEL):\n   text = text.replace(&quot;\\n&quot;, &quot; &quot;)\n   return client.embeddings.create(input = [text], model=model).data[0].embedding\n</code></pre><pre><code class=\"language-python\"># randomly sample 1k rows\ndf_1k = df.sample(1000, random_state=42)\n\ndf_1k[\"embedding\"] = df_1k.combined.apply(lambda x : get_embedding(x, engine=embedding_model))\ndf_1k.to_csv(\"data/toutiao_cat_data_10k_with_embeddings.csv\", index=False)\n</code></pre><p><span class=\"reference\">注：这个是一条条数据请求OpenAI的API获取Embedding的代码，但是你在运行中会遇到报错。</span></p><p>直接运行这个代码，你多半会遇到一个报错，因为在这个数据处理过程中也是有几个坑的。</p><p>第一个坑是<strong> OpenAI提供的接口限制了每条数据的长度</strong>。我们这里使用的 text-embedding-ada-002 的模型，支持的长度是每条记录8191个Token。所以我们在实际发送请求前，需要计算一下每条记录有多少Token，超过8000个的需要过滤掉。不过，在我们这个数据集里，只有新闻的标题，所以不会超过这个长度。但是你在使用其他数据集的时候，可能就需要过滤下数据，或者采用截断的方法，只用文本最后8000个Token。</p><p>我们在这里，调用了Tiktoken这个库，使用了 cl100k_base 这种编码方式，这种编码方式和 text-embedding-ada-002 模型是一致的。如果选错了编码方式，你计算出来的Token数量可能和OpenAI的不一样。</p><p>第二个坑是，如果你直接一条条调用OpenAI的API，很快就会遇到报错。这是因为<strong> OpenAI对API的调用进行了限速</strong>（Rate Limit）。如果你过于频繁地调用，就会遇到限速的报错。而如果你在报错之后继续持续调用，限速的时间还会被延长。那怎么解决这个问题呢？我习惯选用 backoff 这个Python库，在调用的时候如果遇到报错了，就等待一段时间，如果连续报错，就拉长等待时间。通过backoff改造的代码我放在了下面，不过这还没有彻底解决问题。</p><pre><code class=\"language-python\">conda install backoff\n</code></pre><p>你需要先安装一下backoff库。</p><pre><code class=\"language-python\">import backoff\n\n@backoff.on_exception(backoff.expo, openai.error.RateLimitError)\ndef get_embedding_with_backoff(**kwargs):\n    return get_embedding(**kwargs)\n\n# randomly sample 10k rows\ndf_10k = df.sample(10000, random_state=42)\n\ndf_10k[\"embedding\"] = df_10k.combined.apply(lambda x : get_embedding_with_backoff(text=x, engine=embedding_model))\ndf_10k.to_csv(\"data/toutiao_cat_data_10k_with_embeddings.csv\", index=False)\n</code></pre><p>通过backoff库，我们指定了在遇到RateLimitError的时候，按照指数级别增加等待时间。</p><p>如果你直接运行上面那个代码，大约需要2个小时才能处理完1万条数据。我们的数据集里有38万条数据，真要这么干，需要3天3夜才能把训练数据处理完，这样显然不怎么实用。这么慢的原因有两个，一个是限速，backoff只是让我们的调用不会因为失败而终止，但是我还是受到了每分钟API调用次数的限制。第二个是延时，因为我们是按照顺序一个个调用Embedding接口，每一次调用都要等前一次调用结束后才会发起请求，而不是多条数据并行请求，这更进一步<strong>拖长了处理数据所需要的时间</strong>。</p><p><img src=\"https://static001.geekbang.org/resource/image/07/a5/07e5bf0bdfce40a3f1b5a89cb43010a5.png?wh=1589x666\" alt=\"图片\"></p><p><span class=\"reference\">注：你可以点开这个<a href=\"https://platform.openai.com/docs/guides/rate-limits/overview\">链接</a>，看看目前OpenAI对不同模型的限速。</span></p><p>要解决这个问题也不困难，OpenAI是支持batch调用接口的，也就是说，你可以在一个请求里一次批量处理很多个请求。我们把1000条记录打包在一起处理，速度就会快很多。我把对应的代码放在下面，你可以试着执行一下，处理这38万多条的数据，也就个把小时。不过，你也不能一次性打包太多条记录，因为OpenAI的限速不仅仅是针对请求数的，也<strong>限制你每分钟可以处理的 Token 数量</strong>，具体一次打包几条，你可以根据每条数据包含的Token数自己测算一下。</p><pre><code class=\"language-python\">import backoff\nfrom openai.embeddings_utils import get_embeddings\n\nbatch_size = 1000\n\n@backoff.on_exception(backoff.expo, openai.error.RateLimitError)\ndef get_embeddings_with_backoff(prompts, engine):\n    embeddings = []\n    for i in range(0, len(prompts), batch_size):\n        batch = prompts[i:i+batch_size]\n        embeddings += get_embeddings(list_of_text=batch, engine=engine)\n    return embeddings\n\n# randomly sample 10k rows\ndf_all = df\n# group prompts into batches of 100\nprompts = df_all.combined.tolist()\nprompt_batches = [prompts[i:i+batch_size] for i in range(0, len(prompts), batch_size)]\n\nembeddings = []\nfor batch in prompt_batches:\n    batch_embeddings = get_embeddings_with_backoff(prompts=batch, engine=embedding_model)\n    embeddings += batch_embeddings\n\ndf_all[\"embedding\"] = embeddings\ndf_all.to_parquet(\"data/toutiao_cat_data_all_with_embeddings.parquet\", index=True)\n</code></pre><p>最后一个你需要注意的点是，对于这样的大数据集，<strong>不要存储成CSV格式</strong>。特别是我们获取到的Embedding数据，是很多浮点数，存储成CSV格式会把本来只需要4个字节的浮点数，都用字符串的形式存储下来，会浪费好几倍的空间，写入的速度也很慢。我在这里<strong>采用了parquet这个序列化的格式</strong>，整个存储的过程只需要1分钟。</p><h2>训练模型，看看效果怎么样</h2><p>数据处理完了，我们就不妨试一试模型训练。如果你担心浪费太多的API调用，我把我处理好的数据集，放在了我的 <a href=\"https://github.com/xuwenhao/geektime-ai-course\">GitHub</a> 上，我把链接也放在了这里，你可以直接下载、使用这个数据集。</p><pre><code class=\"language-python\">from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score\n\ntraining_data = pd.read_parquet(\"data/toutiao_cat_data_all_with_embeddings.parquet\")\ntraining_data.head()\n\ndf =  training_data.sample(50000, random_state=42)\n\nX_train, X_test, y_train, y_test = train_test_split(\n    list(df.embedding.values), df.category, test_size=0.2, random_state=42\n)\n\nclf = RandomForestClassifier(n_estimators=300)\nclf.fit(X_train, y_train)\npreds = clf.predict(X_test)\nprobas = clf.predict_proba(X_test)\n\nreport = classification_report(y_test, preds)\nprint(report)\n</code></pre><p>模型训练的代码也非常简单，考虑到运行时间的因素，我这里直接随机选取了里面的5万条数据，4万条作为训练集，1万条作为测试集。然后通过最常用的scikit-learn这个机器学习工具包里面的随机森林（RandomForest）算法，做了一次训练和测试。在我的电脑上，大概10分钟可以跑完，整体的准确率可以达到84%。</p><pre><code class=\"language-python\">                    precision    recall  f1-score   support\n  news_agriculture       0.83      0.85      0.84       495\n          news_car       0.88      0.94      0.91       895\n      news_culture       0.86      0.76      0.81       741\n          news_edu       0.86      0.89      0.87       708\nnews_entertainment       0.71      0.92      0.80      1051\n      news_finance       0.81      0.76      0.78       735\n         news_game       0.91      0.82      0.86       742\n        news_house       0.91      0.86      0.89       450\n     news_military       0.89      0.82      0.85       688\n       news_sports       0.90      0.92      0.91       968\n        news_story       0.95      0.46      0.62       197\n         news_tech       0.82      0.86      0.84      1052\n       news_travel       0.80      0.77      0.78       599\n        news_world       0.83      0.73      0.78       671\n             stock       0.00      0.00      0.00         8\n          accuracy                           0.84     10000\n         macro avg       0.80      0.76      0.77     10000\n      weighted avg       0.84      0.84      0.84     10000\n</code></pre><p>随机森林这个算法，虽然效果不错，但是跑起来有些慢。我们接下来用个更简单的逻辑回归（LogisticRegression）算法，但我们这次要跑在整个数据集上。一样的，我们拿80%作为训练，20%作为测试。这一次，虽然数据量是刚才4万条数据的好几倍，但是时间上却只要3～4分钟，而最终的准确率也能达到86%。</p><pre><code class=\"language-python\">from sklearn.linear_model import LogisticRegression\n\ndf =  training_data\n\nX_train, X_test, y_train, y_test = train_test_split(\n    list(df.embedding.values), df.category, test_size=0.2, random_state=42\n)\n\nclf = LogisticRegression()\nclf.fit(X_train, y_train)\npreds = clf.predict(X_test)\nprobas = clf.predict_proba(X_test)\n\nreport = classification_report(y_test, preds)\nprint(report)\n</code></pre><p>输出结果：</p><pre><code class=\"language-python\">                    precision    recall  f1-score   support\n  news_agriculture       0.86      0.88      0.87      3908\n          news_car       0.92      0.92      0.92      7101\n      news_culture       0.83      0.85      0.84      5719\n          news_edu       0.89      0.89      0.89      5376\nnews_entertainment       0.86      0.88      0.87      7908\n      news_finance       0.81      0.79      0.80      5409\n         news_game       0.91      0.88      0.89      5899\n        news_house       0.91      0.91      0.91      3463\n     news_military       0.86      0.82      0.84      4976\n       news_sports       0.93      0.93      0.93      7611\n        news_story       0.83      0.82      0.83      1308\n         news_tech       0.84      0.86      0.85      8168\n       news_travel       0.80      0.80      0.80      4252\n        news_world       0.79      0.81      0.80      5370\n             stock       0.00      0.00      0.00        70\n          accuracy                           0.86     76538\n         macro avg       0.80      0.80      0.80     76538\n      weighted avg       0.86      0.86      0.86     76538\n</code></pre><p><span class=\"reference\">注：下载的数据集所在的测试结果可以看<a href=\"https://github.com/aceimnorstuvwxz/toutiao-text-classfication-dataset\">这里</a>。</span></p><p>这个结果已经比我们下载数据集的GitHub页面里看到的效果好了，那个的准确率只有85%。</p><p>可以看到，通过OpenAI的API获取到Embedding，然后通过一些简单的线性模型，我们就能获得很好的分类效果。我们既不需要提前储备很多自然语言处理的知识，对数据进行大量的分析和清理；也不需要搞一块昂贵的显卡，去使用什么深度学习模型。只要1～2个小时，我们就能在一个几十万条文本的数据集上训练出一个非常不错的分类模型。</p><h2>理解指标，学一点机器学习小知识</h2><p>刚刚我说了，就算你没有机器学习的相关知识，也没有关系，这里我来给你补补课。理解一下上面模型输出的报告是什么意思。报告的每一行都有四个指标，分别是准确率（Precision）、召回率（Recall）、F1分数，以及支持样本量（Support）。我还是用今日头条的新闻标题这个数据集来解释这些概念。</p><ol>\n<li><strong>准确率</strong>，代表模型判定属于这个分类的标题里面判断正确的有多少，有多少真的是属于这个分类的。比如，模型判断里面有 100个都是农业新闻，但是这100个里面其实只有83个是农业新闻，那么准确率就是0.83。准确率自然是越高越好，但是并不是准确率达到100%就代表模型全对了。因为模型可能会漏，所以我们还要考虑召回率。</li>\n<li><strong>召回率</strong>，代表模型判定属于这个分类的标题占实际这个分类下所有标题的比例，也就是没有漏掉的比例。比如，模型判断100个都是农业新闻，这100个的确都是农业新闻。准确率已经100%了。但是，实际我们一共有200条农业新闻。那么有100条其实被放到别的类目里面去了。那么在农业新闻这个类目，我们的召回率，就只有 100/200 = 50%。</li>\n<li>所以模型效果的好坏，既要考虑准确率，又要考虑召回率，综合考虑这两项得出的结果，就是 <strong>F1</strong> <strong>分数</strong>（F1 Score）。F1分数，是准确率和召回率的调和平均数，也就是 F1 Score = 2/ (1/Precision + 1/Recall)。当准确率和召回率都是100%的时候，F1分数也是1。如果准确率是100%，召回率是80%，那么算下来F1分数就是0.88。F1分数也是越高越好。</li>\n<li><strong>支持的样本量</strong>，是指数据里面，实际是这个分类的数据条数有多少。一般来说，数据条数越多，这个分类的训练就会越准确。</li>\n</ol><p>分类报告里一个类目占一行，每一行都包含对应的这四个指标，而最下面还有三行数据。这三行数据，是整个拿来测试的数据集，所以对应的支持样本量都是1万个。</p><p>第一行的accuracy，只有一个指标，虽然它在F1 Score这个列里，但是并不是F1分数的意思。而是说，模型总共判断对的分类/模型测试的样本数，也就是模型的整体准确率。</p><p>第二行的macro average，中文名叫做宏平均，宏平均的三个指标，就是把上面每一个分类算出来的指标加在一起平均一下。它主要是在数据分类不太平衡的时候，帮助我们衡量模型效果怎么样。</p><p>比如，我们做情感分析，可能90%都是正面情感，10%是负面情感。这个时候，我们预测正面情感效果很好，比如有90%的准确率，但是负面情感预测很差，只有50%的准确率。如果看整体数据，其实准确率还是非常高的，毕竟负面情感的例子很少。</p><p>但是我们的目标可能就是找到有负面情绪的客户和他们沟通、赔偿。那么整体准确率对我们就没有什么用了。而宏平均，会把整体的准确率变成 (90%+50%)/2 = 70%。这就不是一个很好的预测结果了，我们需要进一步优化。宏平均对于数据样本不太平衡，有些类目样本特别少，有些特别多的场景特别有用。</p><p>第三行的weighted average，就是加权平均，也就是我们把每一个指标，按照分类里面支持的样本量加权，算出来的一个值。无论是 Precision、Recall 还是 F1 Score都要这么按照各个分类加权平均一下。</p><h2>小结</h2><p><img src=\"https://static001.geekbang.org/resource/image/94/c3/947d63ba603abfc137b904b7db1cf3c3.jpg?wh=2872x1940\" alt=\"\"></p><p>好了，今天的这一讲到这里就结束了，最后我们来回顾一下。这一讲我们学会了两件事情。</p><p>第一件，是怎么利用OpenAI的API来获取文本的Embedding。虽然接口不复杂，但是我们也要考虑模型能够接受的最大文本长度，API本身的限速，以及网络延时带来的问题。</p><p>我们分别给出了解决方案，使用Tiktoken计算样本的Token数量，并进行过滤；在遇到限速问题时通过backoff进行指数级别的时间等待；通过一次性批量请求一批数据，最大化我们的吞吐量来解决问题；对于返回的结果，我们可以通过parquet这样序列化的方式保存数据，来减少数据尺寸。</p><p>第二件，是如何直接利用拿到的Embedding，简单调用一下scikit-learn，通过机器学习的方法，进行更准确的分类。我们最终把Embedding放到一个简单的逻辑回归模型里，就取得了很不错的分类效果。你学会了吗？</p><h2>课后练习</h2><p>这一讲里我们学会了利用OpenAI来获取文本的Embedding，然后通过传统的机器学习方式来进行训练，并评估训练的结果。</p><p>我们之前用过Amazon1000条食物评论的情感分析数据，在那个数据集里，我们其实已经使用过获取到并保存下来的Embedding数据了。那么，你能不能试着在完整的数据集上，训练一个能把从1分到5分的每一个级别都区分出来的机器学习模型，看看效果怎么样？</p><p>整个原始数据集的下载链接我放在<a href=\"https://www.kaggle.com/snap/amazon-fine-food-reviews\">这里</a>了，欢迎你把你测试出来的结果分享出来，看看和其他人比起来怎么样。另外如果你觉得有收获的话，也欢迎你把这节课分享出去，让更多的人了解用Embedding给文本分类的方法。</p>","neighbors":{"left":{"article_title":"04｜新时代模型性能大比拼，GPT-3到底胜在哪里？","id":642224},"right":{"article_title":"06｜ChatGPT来了，让我们快速做个AI应用","id":643915}},"comments":[{"had_liked":false,"id":373871,"user_name":"麦耀锋","can_delete":false,"product_type":"c1","uid":1401327,"ip_address":"广东","ucode":"077DA831185C01","user_header":"https://static001.geekbang.org/account/avatar/00/15/61/ef/ac5e914d.jpg","comment_is_top":false,"comment_ctime":1683276840,"is_pvip":false,"replies":[{"id":136870,"content":"👍","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1684753131,"ip_address":"上海","comment_id":373871,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"应该这么去理解embedding的使用。以前我们做机器学习的时候（或者相对于深度学习之前的“浅层学习”），不管是有监督还是无监督，一般我们需要做feature engineering，也就是需要data scientist，根据业务、专家领域，对数据提取有用的feature；而在NLP领域，那么就是通过word2vec等各种方式来提取feature。通过openai的embedding接口，实际上就是openai帮我们做了feature engineering这一步，将文本映射到一个合适的vector space，得到的embedding其实就是文本的feature，所以可以基于这个embedding即feature X来做传统的机器学习","like_count":31,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":619059,"discussion_content":"👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684753131,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3565051,"avatar":"","nickname":"Geek_44df74","note":"","ucode":"CD6D47CE1A0BBB","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":617174,"discussion_content":"假使上面例子的准备和召回符合业务目标了，具体要咋应用呢？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683362142,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":371454,"user_name":"浩仔是程序员","can_delete":false,"product_type":"c1","uid":1104601,"ip_address":"广东","ucode":"A7E5CF9E1571A2","user_header":"https://static001.geekbang.org/account/avatar/00/10/da/d9/f051962f.jpg","comment_is_top":false,"comment_ctime":1679966594,"is_pvip":false,"replies":[{"id":135720,"content":"可以的啊，但是要考虑\n1. 成本\n2. 效果\n\n在有标注数据的情况下，机器学习的效果通常比让ChatGPT只用先验知识效果还是要好不少的。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1680581747,"ip_address":"上海","comment_id":371454,"utype":1}],"discussion_count":9,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"老师，你好！既然都调用open ai的接口，为什么不直接让chatgpt直接返回分类结果呢","like_count":17,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612219,"discussion_content":"可以的啊，但是要考虑\n1. 成本\n2. 效果\n\n在有标注数据的情况下，机器学习的效果通常比让ChatGPT只用先验知识效果还是要好不少的。","likes_number":4,"is_delete":false,"is_hidden":false,"ctime":1680581747,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3582440,"avatar":"https://static001.geekbang.org/account/avatar/00/36/a9/e8/beca7b42.jpg","nickname":"狐狸的帽子","note":"","ucode":"0BBD5868274536","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612008,"discussion_content":"这是大模型另一种使用方式，用来预训练，储备先验知识，然后再用常用的机器学习模型做二次训练和微调，可能会取得更佳的效果。","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1680486916,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"美国","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2161554,"avatar":"https://static001.geekbang.org/account/avatar/00/20/fb/92/0537ea08.jpg","nickname":"漫游者","note":"","ucode":"23DD0146F43C7D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":637517,"discussion_content":"我倒感觉4万条的训练，准确度是否会超过让chatgpt直接进行分类~老师显然认为有了准确标签的后续训练会比让gpt自己分类效果好，这点我保留意见。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1708585286,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1786915,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/44/23/ebe7bd0f.jpg","nickname":"啊啊啊啊","note":"","ucode":"090E3983DD41A6","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":619493,"discussion_content":"但这个过程也引入了openAI 的接口，即使这个模型训练好了，以后每给用户的数据做分类，不也要调用 openAI的接口计算embedding么","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1685178660,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3568860,"avatar":"","nickname":"Geek_0b2332","note":"","ucode":"B64FA0D7BA6BA6","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":611780,"discussion_content":"哥们，看看本讲的标题哈。直接给出分类结果当然可以，不过老师是给出了另一种技术路径（使用embedding+后端classifier）来做分类。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680315414,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"江苏","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1899996,"avatar":"https://static001.geekbang.org/account/avatar/00/1c/fd/dc/8c394a51.jpg","nickname":"刘蕾","note":"","ucode":"984D2C7E286DA1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":611557,"discussion_content":"使用的语言模型有差别，chatgpt是gpt-3.5-turbo，分类是text-embedding-ada-002","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680168223,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"斯洛伐克","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1186273,"avatar":"https://static001.geekbang.org/account/avatar/00/12/19/e1/a7fbc963.jpg","nickname":"Warren","note":"","ucode":"7518ED2E07AAF7","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":611533,"discussion_content":"评价的评分(1分到5分)的分类chatGPT直接给不出来吧？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680158467,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2081124,"avatar":"https://static001.geekbang.org/account/avatar/00/1f/c1/64/3b994bd5.jpg","nickname":"卖烧烤夫斯基","note":"","ucode":"EC9DB8C4A3C21A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":611362,"discussion_content":"同问","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680056879,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1922378,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/55/4a/8a841200.jpg","nickname":"ACK","note":"","ucode":"C5D09B18DEF151","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":611342,"discussion_content":"这也是我的疑问，但想一下也有合理的地方，就是 open ai 可以通过编程提供的输入调用，形成自动化能力。\nchatGPT 主要是与人的自然语言对话，在对话窗口来输入，人工手动操作，局限性很大。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680051138,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"中国香港","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":372211,"user_name":"良辰美景","can_delete":false,"product_type":"c1","uid":1074803,"ip_address":"上海","ucode":"B36E6955A2872D","user_header":"https://static001.geekbang.org/account/avatar/00/10/66/73/fd1e37a2.jpg","comment_is_top":false,"comment_ctime":1680850347,"is_pvip":false,"replies":[{"id":135874,"content":"读一遍API文档，读一遍OpenAI Cookbook。这是看起来最笨，其实最节约时间的办法。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1680973554,"ip_address":"日本","comment_id":372211,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"“调用了 Tiktoken 这个库，使用了 cl100k_base 这种编码方式，这种编码方式和 text-embedding-ada-002 模型是一致的。如果选错了编码方式，你计算出来的 Token 数量可能和 OpenAI 的不一样。” 老师， 问你一个学习上的问题， 像这种API 文档里这么细节的东西，你是如何获取这些信息的","like_count":10,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612869,"discussion_content":"读一遍API文档，读一遍OpenAI Cookbook。这是看起来最笨，其实最节约时间的办法。","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1680973554,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"日本","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":371683,"user_name":"Toni","can_delete":false,"product_type":"c1","uid":3206957,"ip_address":"瑞士","ucode":"E6B2FACCC1E000","user_header":"https://static001.geekbang.org/account/avatar/00/30/ef/2d/757bb0d3.jpg","comment_is_top":false,"comment_ctime":1680178508,"is_pvip":false,"replies":[{"id":135729,"content":"👍 我本机是默认会退回到用python引擎来分割，感谢。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1680582401,"ip_address":"上海","comment_id":371683,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"在执行这段代码时会报ParserWarning\ndf = pd.read_csv(&#39;data&#47;toutiao_cat&#47;toutiao_cat_data.txt&#39;, sep=&#39;_!_&#39;, names=[&#39;id&#39;, &#39;code&#39;, &#39;category&#39;, &#39;title&#39;, &#39;keywords&#39;])\n\nParserWarning: Falling back to the &#39;python&#39; engine because the &#39;c&#39; engine does not support regex separators (separators &gt; 1 char and different from &#39;\\s+&#39; are interpreted as regex); you can avoid this warning by specifying engine=&#39;python&#39;.\n\n原因是 &#39;c&#39; 引擎不支持分隔符sep=&#39;_!_&#39;表达式，可指定 engine=&#39;python&#39; 来避免此警告。\n代码如下\ndf = pd.read_csv(&#39;data&#47;toutiao_cat&#47;toutiao_cat_data.txt&#39;, engine= &#39;python&#39;， sep=&#39;_!_&#39;, names=[&#39;id&#39;, &#39;code&#39;, &#39;category&#39;, &#39;title&#39;, &#39;keywords&#39;])","like_count":5,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612228,"discussion_content":"👍 我本机是默认会退回到用python引擎来分割，感谢。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680582401,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":371478,"user_name":"怡仔","can_delete":false,"product_type":"c1","uid":2201689,"ip_address":"上海","ucode":"FD17CA43292456","user_header":"https://static001.geekbang.org/account/avatar/00/21/98/59/c2ce609d.jpg","comment_is_top":false,"comment_ctime":1679981704,"is_pvip":false,"replies":[{"id":135766,"content":"看一下github的README里给了一个百度网盘的下载方式\n对应的数据文件比较大，GitHub里直接放也不太方便下载","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1680587423,"ip_address":"上海","comment_id":371478,"utype":1}],"discussion_count":4,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"github中的找不到途中列举的数据文件","like_count":5,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612273,"discussion_content":"看一下github的README里给了一个百度网盘的下载方式\n对应的数据文件比较大，GitHub里直接放也不太方便下载","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680587423,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1085809,"avatar":"https://static001.geekbang.org/account/avatar/00/10/91/71/d7471004.jpg","nickname":"luis小麦","note":"","ucode":"6AE70B61C713A2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":611448,"discussion_content":"404，打不开","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1680090848,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1452167,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJcwXucibksEYRSYg6icjibzGa7efcMrCsGec2UwibjTd57icqDz0zzkEEOM2pXVju60dibzcnQKPfRkN9g/132","nickname":"Geek_93970d","note":"","ucode":"52AC308BEC7737","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":618788,"discussion_content":"好嘞","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684556569,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1795369,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/65/29/a76c69d9.jpg","nickname":"张发 Fain","note":"","ucode":"A3745E544066F9","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612117,"discussion_content":"在data文件夹里","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680517849,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":371877,"user_name":"lala","can_delete":false,"product_type":"c1","uid":3582410,"ip_address":"北京","ucode":"D6B9DD7A6E899F","user_header":"https://static001.geekbang.org/account/avatar/00/36/a9/ca/f216bece.jpg","comment_is_top":false,"comment_ctime":1680483828,"is_pvip":false,"replies":[{"id":135752,"content":"看最新上线的10，11讲，以及后面会上线的14-17讲","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1680586366,"ip_address":"上海","comment_id":371877,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"现在chatGPT是通用的问答应用。请问如何根据ChatGPT结合公司业务的知识库和商品信息，如何打造服务客户和内部顾问的机器人？比如根据用户问题，推荐对应产品给用户。根据内部知识库，回答内部同事关于产品使用，运营信息相关的问题呢。谢谢","like_count":4,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612258,"discussion_content":"看最新上线的10，11讲，以及后面会上线的14-17讲","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680586366,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":371746,"user_name":"Toni","can_delete":false,"product_type":"c1","uid":3206957,"ip_address":"瑞士","ucode":"E6B2FACCC1E000","user_header":"https://static001.geekbang.org/account/avatar/00/30/ef/2d/757bb0d3.jpg","comment_is_top":false,"comment_ctime":1680254620,"is_pvip":false,"replies":[{"id":135726,"content":"👍","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1680582186,"ip_address":"上海","comment_id":371746,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"训练一个能把从 1 分到 5 分的每一个级别都区分出来的机器学习模型.\n使用下载的数据 fine_food_reviews_with_embeddings_1k.csv\n\n随机森林模型，超参数 n_estimators=100 下跑的结果\n\n              precision    recall  f1-score   support\n\n           1       0.86      0.30      0.44        20\n           2       1.00      0.38      0.55         8\n           3       1.00      0.18      0.31        11\n           4       1.00      0.26      0.41        27\n           5       0.74      1.00      0.85       134\n\n       accuracy                               0.76       200\n    macro avg       0.92      0.42      0.51       200\nweighted avg       0.81      0.76      0.71       200\n\n极端随机森林模型 ExtraTreesClassifier() 下跑的结果\n\n              precision    recall  f1-score   support\n\n           1       1.00      0.20      0.33        20\n           2       1.00      0.38      0.55         8\n           3       1.00      0.18      0.31        11\n           4       1.00      0.26      0.41        27\n           5       0.73      1.00      0.84       134\n\n      accuracy                                0.75       200\n    macro avg       0.95      0.40      0.49       200\nweighted avg       0.82      0.75      0.69       200\n","like_count":4,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612225,"discussion_content":"👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680582186,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1081299,"avatar":"https://static001.geekbang.org/account/avatar/00/10/7f/d3/b5896293.jpg","nickname":"Realm","note":"","ucode":"30CBEBE619D1A2","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":614036,"discussion_content":"我在线性回归下跑的结果，比随机森林要差很多，会是什么原因？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1681641971,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"日本","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":371528,"user_name":"Geek_513b7c","can_delete":false,"product_type":"c1","uid":3579076,"ip_address":"吉林","ucode":"8F252A56BFA03F","user_header":"","comment_is_top":false,"comment_ctime":1680017129,"is_pvip":false,"replies":[{"id":135782,"content":"可以认为，就是把文本，用一组数字来表示，这组数字表示了这段文本在高维空间里面的坐标。两段文本相似，就是他们坐标之间比较近。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1680590051,"ip_address":"上海","comment_id":371528,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"老师，你能解释一下在ai中向量是什么意思吗？这几节看的云里雾里的","like_count":4,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612299,"discussion_content":"可以认为，就是把文本，用一组数字来表示，这组数字表示了这段文本在高维空间里面的坐标。两段文本相似，就是他们坐标之间比较近。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680590052,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3579742,"avatar":"https://static001.geekbang.org/account/avatar/00/36/9f/5e/791d0f5e.jpg","nickname":"自然卷的Neil","note":"","ucode":"44ECCBE5B7F6CA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":611423,"discussion_content":"NLP里的基础知识，B站有好多，很快就学懂了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680080241,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":372052,"user_name":"四月.  🕊","can_delete":false,"product_type":"c1","uid":1796939,"ip_address":"北京","ucode":"C8B8C3605AB67A","user_header":"https://static001.geekbang.org/account/avatar/00/1b/6b/4b/4a622bdf.jpg","comment_is_top":false,"comment_ctime":1680664138,"is_pvip":false,"replies":[{"id":135904,"content":"看了一下的确是可以不用的。原来是想做成两层batch_size的，就是1000个batch扔给get_embeddings_with_backoff，然后里面再100个一个batch这样，不过后来发现没有必要。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1680975719,"ip_address":"日本","comment_id":372052,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"请问一下老师，既然已经按照batch_size划分出来了prompt_batches，为什么在get_embeddings_with_backoff函数中还要划分一次batch呢？是不是重复了？","like_count":2,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612901,"discussion_content":"看了一下的确是可以不用的。原来是想做成两层batch_size的，就是1000个batch扔给get_embeddings_with_backoff，然后里面再100个一个batch这样，不过后来发现没有必要。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680975719,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"日本","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":371881,"user_name":"王平","can_delete":false,"product_type":"c1","uid":1487529,"ip_address":"上海","ucode":"CF1ABC5F962EC8","user_header":"https://static001.geekbang.org/account/avatar/00/16/b2/a9/791d0f5e.jpg","comment_is_top":false,"comment_ctime":1680485431,"is_pvip":false,"replies":[{"id":135712,"content":"我没有试过，你可以试一下，如果有结果欢迎分享。我猜如果一般人能判断出来，它就能判断出来。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1680581376,"ip_address":"上海","comment_id":371881,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"老师请问如果把时序数据，比如用户行为序列作为输入给openAI 的 embedding, 根据行为判断用户情感的效果会好吗？","like_count":2,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612211,"discussion_content":"我没有试过，你可以试一下，如果有结果欢迎分享。我猜如果一般人能判断出来，它就能判断出来。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680581376,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":374341,"user_name":"高捷","can_delete":false,"product_type":"c1","uid":3618463,"ip_address":"日本","ucode":"2FF75E8918E6C2","user_header":"","comment_is_top":false,"comment_ctime":1683951491,"is_pvip":false,"replies":[{"id":136851,"content":"text-ada-embedding-002 这样的模型并不会更新，所以不存在需要“同步一次embedding模型”\n\nOpenAI的模型，有不更新的（带日期快照的 gpt-3.5-turbo-0314 这种），也有更新的（gpt-3.5-turbo）\n\n如果说模型本身OpenAI怎么更新的话，我推测是伴随着用户反馈的数据作为输入继续微调模型权重的一个流程，可以看看18讲的fine-tune","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1684749244,"ip_address":"上海","comment_id":374341,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"老师您好，想知道大概多久需要去同步一次embedding模型，大模型自己怎么更新迭代呢？","like_count":1,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":619030,"discussion_content":"text-ada-embedding-002 这样的模型并不会更新，所以不存在需要“同步一次embedding模型”\n\nOpenAI的模型，有不更新的（带日期快照的 gpt-3.5-turbo-0314 这种），也有更新的（gpt-3.5-turbo）\n\n如果说模型本身OpenAI怎么更新的话，我推测是伴随着用户反馈的数据作为输入继续微调模型权重的一个流程，可以看看18讲的fine-tune","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684749244,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":374039,"user_name":"楚翔style","can_delete":false,"product_type":"c1","uid":1174846,"ip_address":"内蒙古","ucode":"E715F82C34A9AA","user_header":"https://static001.geekbang.org/account/avatar/00/11/ed/3e/c1725237.jpg","comment_is_top":false,"comment_ctime":1683530765,"is_pvip":false,"replies":[{"id":136832,"content":"英文单词基本上大约3个单词4个Token，中文基本上1个字2-3个Token。\n后面的课程里有具体介绍如何计算token的例子。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1684744358,"ip_address":"上海","comment_id":374039,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"花费多少token怎么算呢 \n一个问题一个token吗","like_count":1,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":619001,"discussion_content":"英文单词基本上大约3个单词4个Token，中文基本上1个字2-3个Token。\n后面的课程里有具体介绍如何计算token的例子。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684744359,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":373683,"user_name":"R9Go","can_delete":false,"product_type":"c1","uid":1070171,"ip_address":"韩国","ucode":"D15816C721FB80","user_header":"https://static001.geekbang.org/account/avatar/00/10/54/5b/fe7ebc2e.jpg","comment_is_top":false,"comment_ctime":1683010973,"is_pvip":false,"replies":[{"id":136444,"content":"应该是全的，或者可以去README里面列出来的百度网盘下载\n链接: https:&#47;&#47;pan.baidu.com&#47;s&#47;1Cl0eFNLOkQqquf9ls0trEw 提取码: jvr4\n","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1683082455,"ip_address":"上海","comment_id":373683,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"https:&#47;&#47;github.com&#47;xuwenhao&#47;geektime-ai-course&#47;blob&#47;main&#47;data&#47;20_newsgroup_with_embedding.parquet\n这个数据是不是不全？","like_count":1,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":616666,"discussion_content":"应该是全的，或者可以去README里面列出来的百度网盘下载\n链接: https://pan.baidu.com/s/1Cl0eFNLOkQqquf9ls0trEw 提取码: jvr4\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683082455,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":372821,"user_name":"Geek_512735","can_delete":false,"product_type":"c1","uid":3588303,"ip_address":"北京","ucode":"D45BF63D413316","user_header":"","comment_is_top":false,"comment_ctime":1681693744,"is_pvip":false,"replies":[{"id":136255,"content":"效果好，语义表达能力强，成本也不高。主要缺点是需要把数据发送给OpenAI。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1681794225,"ip_address":"上海","comment_id":372821,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"老师，请利用ChatGPT embedding的优势在什么地方？","like_count":1,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":614457,"discussion_content":"效果好，语义表达能力强，成本也不高。主要缺点是需要把数据发送给OpenAI。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1681794225,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":372307,"user_name":"Bank","can_delete":false,"product_type":"c1","uid":3580859,"ip_address":"北京","ucode":"8EAA7C63DF9297","user_header":"https://static001.geekbang.org/account/avatar/00/36/a3/bb/5cde4385.jpg","comment_is_top":false,"comment_ctime":1680954783,"is_pvip":false,"replies":[{"id":135859,"content":"134217728 是128MB内存空间，看起来应该会不会是环境哪里做了限制？\n\n即使在Windows下，我也推荐使用WSL2的Linux子系统来运行这些代码。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1680972295,"ip_address":"中国香港","comment_id":372307,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"在读数据的时候报了这个错，请问如何解决呢？内存应该是足够的\n---------------------------------------------------------------------------\nArrowMemoryError                          Traceback (most recent call last)\nCell In[6], line 6\n      3 from sklearn.model_selection import train_test_split\n      4 from sklearn.metrics import classification_report, accuracy_score\n----&gt; 6 training_data = pd.read_parquet(&quot;D:&#47;work&#47;data&#47;toutiao_cat_data_all_with_embeddings.parquet&quot;)\n      7 training_data.head()\n      9 df =  training_data.sample(50000, random_state=42)\n\n。。。。。。\n-&gt; 2517 table = self._dataset.to_table(\n   2518     columns=columns, filter=self._filter_expression,\n   2519     use_threads=use_threads\n   2520 )\n   2522 # if use_pandas_metadata, restore the pandas metadata (which gets\n   2523 # lost if doing a specific `columns` selection in to_table)\n   2524 if use_pandas_metadata:\n\nFile D:\\anaconda3\\lib\\site-packages\\pyarrow\\_dataset.pyx:332, in pyarrow._dataset.Dataset.to_table()\n\nFile D:\\anaconda3\\lib\\site-packages\\pyarrow\\_dataset.pyx:2661, in pyarrow._dataset.Scanner.to_table()\n\nFile D:\\anaconda3\\lib\\site-packages\\pyarrow\\error.pxi:144, in pyarrow.lib.pyarrow_internal_check_status()\n\nFile D:\\anaconda3\\lib\\site-packages\\pyarrow\\error.pxi:117, in pyarrow.lib.check_status()\n\nArrowMemoryError: malloc of size 134217728 failed","like_count":1,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612854,"discussion_content":"134217728 是128MB内存空间，看起来应该会不会是环境哪里做了限制？\n\n即使在Windows下，我也推荐使用WSL2的Linux子系统来运行这些代码。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680972295,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"中国香港","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":371527,"user_name":"xbc","can_delete":false,"product_type":"c1","uid":2187437,"ip_address":"海南","ucode":"03F1FD7B8CA32F","user_header":"https://static001.geekbang.org/account/avatar/00/21/60/ad/03351e6e.jpg","comment_is_top":false,"comment_ctime":1680016017,"is_pvip":false,"replies":[{"id":135722,"content":"默认embedding是 text-similarity-davinci-001\n第8讲，会列举模型差别\n\n text-similarity-davinci-001 效果比  text-embedding-ada-002 在相似度比较上其实更好，但是太贵了。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1680581988,"ip_address":"上海","comment_id":371527,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"from openai.embeddings_utils import get_embeddings 用的是 text-similarity-davinci-001 吧.\n\nopenai.Embedding.create 可以选择用 text-embedding-ada-002","like_count":1,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612221,"discussion_content":"默认embedding是 text-similarity-davinci-001\n第8讲，会列举模型差别\n\n text-similarity-davinci-001 效果比  text-embedding-ada-002 在相似度比较上其实更好，但是太贵了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680581988,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":374920,"user_name":"Geek_378f83","can_delete":false,"product_type":"c1","uid":3196784,"ip_address":"美国","ucode":"AD2B400EED436A","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/z3nIITkhzRj9WApibhic524lQSJmqUCerpuqpntEe06LE3lRGKr6rGwPpPJtZ5Xj0NBPyvTatKtIk0hfyAnl9Hsg/132","comment_is_top":false,"comment_ctime":1684657728,"is_pvip":false,"replies":[{"id":136800,"content":"其实ChatGPT回答不了的问题，还是可以Google或者Stackoverflow搜索一下，参看\n\nhttps:&#47;&#47;stackoverflow.com&#47;questions&#47;67720198&#47;how-to-upgrade-libstdc-so-on-colab-runtime\n\nColab的确环境搭建不统一，会给大家造成点困扰","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1684723299,"ip_address":"新加坡","comment_id":374920,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"老师，同学们好，请教一下：\ncolab 中运行时报错：  &#47;lib&#47;x86_64-linux-gnu&#47;libstdc++.so.6: version `GLIBCXX_3.4.29&#39; not found (required by &#47;usr&#47;local&#47;lib&#47;python3.10&#47;site-packages&#47;sentencepiece&#47;_sentencepiece.cpython-310-x86_64-linux-gnu.so)；需要在colab中怎么解决？\n询问gpt后目前仍未解决，求助","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":618936,"discussion_content":"其实ChatGPT回答不了的问题，还是可以Google或者Stackoverflow搜索一下，参看\n\nhttps://stackoverflow.com/questions/67720198/how-to-upgrade-libstdc-so-on-colab-runtime\n\nColab的确环境搭建不统一，会给大家造成点困扰","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684723299,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"新加坡","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":374878,"user_name":"Geek_93970d","can_delete":false,"product_type":"c1","uid":1452167,"ip_address":"北京","ucode":"52AC308BEC7737","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJcwXucibksEYRSYg6icjibzGa7efcMrCsGec2UwibjTd57icqDz0zzkEEOM2pXVju60dibzcnQKPfRkN9g/132","comment_is_top":false,"comment_ctime":1684556519,"is_pvip":false,"replies":[{"id":136791,"content":"👍","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1684720609,"ip_address":"新加坡","comment_id":374878,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score\n# 换成正确的路径\ndf_all = pd.read_csv(&quot;..&#47;data&#47;fine_food_reviews_with_embeddings_1k.csv&quot;)\ndf_all[&quot;embedding&quot;] = df_all.embedding.apply(eval).apply(np.array)\n\n# 其实没必要转换成 parquet\ndf_all.to_parquet(&quot;fine_food_reviews_with_embeddings.parquet&quot;, index=True)\ntraining_data = pd.read_parquet(&quot;fine_food_reviews_with_embeddings.parquet&quot;)\ntraining_data.head()\n\n#df =  training_data.sample(50000, random_state=42)\n#df = df_all\ndf = training_data\n\nX_train, X_test, y_train, y_test = train_test_split(\n    list(df.embedding.values), df.Score, test_size=0.2, random_state=42\n)\n\nclf = RandomForestClassifier(n_estimators=300)\nclf.fit(X_train, y_train)\npreds = clf.predict(X_test)\nprobas = clf.predict_proba(X_test)\n\nreport = classification_report(y_test, preds)\nprint(report)\n\n------------结果如下-----------\n              precision    recall  f1-score   support\n\n           1       0.89      0.40      0.55        20\n           2       1.00      0.38      0.55         8\n           3       1.00      0.18      0.31        11\n           4       1.00      0.26      0.41        27\n           5       0.75      1.00      0.86       134\n\n    accuracy                           0.77       200\n   macro avg       0.93      0.44      0.53       200\nweighted avg       0.82      0.77      0.72       200","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":618923,"discussion_content":"👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684720609,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"新加坡","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":374862,"user_name":"Geek_93970d","can_delete":false,"product_type":"c1","uid":1452167,"ip_address":"北京","ucode":"52AC308BEC7737","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJcwXucibksEYRSYg6icjibzGa7efcMrCsGec2UwibjTd57icqDz0zzkEEOM2pXVju60dibzcnQKPfRkN9g/132","comment_is_top":false,"comment_ctime":1684503041,"is_pvip":false,"replies":[{"id":136787,"content":"https:&#47;&#47;github.com&#47;xuwenhao&#47;geektime-ai-course 去README里面找一下百度网盘，下载对应数据文件\n\n链接: https:&#47;&#47;pan.baidu.com&#47;s&#47;1Cl0eFNLOkQqquf9ls0trEw 提取码: jvr4","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1684720396,"ip_address":"新加坡","comment_id":374862,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"data&#47;toutiao_cat_data_all_with_embeddings.parquet\n这个文件找不到","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":618919,"discussion_content":"https://github.com/xuwenhao/geektime-ai-course 去README里面找一下百度网盘，下载对应数据文件\n\n链接: https://pan.baidu.com/s/1Cl0eFNLOkQqquf9ls0trEw 提取码: jvr4","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684720396,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"新加坡","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":374688,"user_name":"地平线","can_delete":false,"product_type":"c1","uid":1482026,"ip_address":"上海","ucode":"F50717D6244867","user_header":"https://static001.geekbang.org/account/avatar/00/16/9d/2a/3e57b54a.jpg","comment_is_top":false,"comment_ctime":1684313272,"is_pvip":false,"replies":[{"id":136802,"content":"👍","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1684723807,"ip_address":"新加坡","comment_id":374688,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"训练一个能把从 1 分到 5 分的每一个级别都区分出来的机器学习模型.\n使用老师的数据 fine_food_reviews_with_embeddings_1k.csv\n\n随机森林模型，参数 n_estimators=300下跑的结果\n\n              precision    recall  f1-score   support\n\n           1       1.00      0.30      0.46        20\n           2       1.00      0.38      0.55         8\n           3       1.00      0.18      0.31        11\n           4       1.00      0.26      0.41        27\n           5       0.74      1.00      0.85       134\n\n    accuracy                           0.76       200\n   macro avg       0.95      0.42      0.51       200\nweighted avg       0.82      0.76      0.71       200","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":618942,"discussion_content":"👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684723808,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"新加坡","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":373936,"user_name":"Geek_44df74","can_delete":false,"product_type":"c1","uid":3565051,"ip_address":"上海","ucode":"CD6D47CE1A0BBB","user_header":"","comment_is_top":false,"comment_ctime":1683362061,"is_pvip":false,"replies":[{"id":136869,"content":"通过代码里面的predict函数预测就好了呀。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1684753118,"ip_address":"上海","comment_id":373936,"utype":1}],"discussion_count":2,"race_medal":0,"score":4,"product_id":100541001,"comment_content":"老师，有个问题，上面只是用一些算法校验了准确和召回率，假使现在准确和召回率符合业务目标了，具体要如何应用啊，基于上面的文章分类的例子，给一个标题的embedding如何返回具体的分类？","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":619058,"discussion_content":"通过代码里面的predict函数预测就好了呀。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684753118,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1222233,"avatar":"https://static001.geekbang.org/account/avatar/00/12/a6/59/1689ea0c.jpg","nickname":"金hb.Ryan 冷空氣駕到","note":"","ucode":"CAD363576696E4","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":618671,"discussion_content":"业务场景驱动，否则就是伪需求😄","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684418592,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":373682,"user_name":"R9Go","can_delete":false,"product_type":"c1","uid":1070171,"ip_address":"韩国","ucode":"D15816C721FB80","user_header":"https://static001.geekbang.org/account/avatar/00/10/54/5b/fe7ebc2e.jpg","comment_is_top":false,"comment_ctime":1683010920,"is_pvip":false,"replies":[{"id":136450,"content":"看一下是否有哪行前面的代码没有执行，整个Notebook可以在\nhttps:&#47;&#47;github.com&#47;xuwenhao&#47;geektime-ai-course\n找到","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1683082723,"ip_address":"上海","comment_id":373682,"utype":1}],"discussion_count":2,"race_medal":0,"score":4,"product_id":100541001,"comment_content":"&#39;DataFrame&#39; object has no attribute &#39;category&#39;","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":616672,"discussion_content":"看一下是否有哪行前面的代码没有执行，整个Notebook可以在\nhttps://github.com/xuwenhao/geektime-ai-course\n找到","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683082723,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1452167,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJcwXucibksEYRSYg6icjibzGa7efcMrCsGec2UwibjTd57icqDz0zzkEEOM2pXVju60dibzcnQKPfRkN9g/132","nickname":"Geek_93970d","note":"","ucode":"52AC308BEC7737","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":618805,"discussion_content":"指的是思考题吗？改成 Score 试试","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684567402,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":373369,"user_name":"Adoph","can_delete":false,"product_type":"c1","uid":1400489,"ip_address":"四川","ucode":"DE85FA2638BAE4","user_header":"https://static001.geekbang.org/account/avatar/00/15/5e/a9/cc943f81.jpg","comment_is_top":false,"comment_ctime":1682430314,"is_pvip":false,"replies":[{"id":136480,"content":"https:&#47;&#47;github.com&#47;aceimnorstuvwxz&#47;toutiao-text-classfication-dataset\n\n或者\n链接: https:&#47;&#47;pan.baidu.com&#47;s&#47;1Cl0eFNLOkQqquf9ls0trEw 提取码: jvr4","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1683086311,"ip_address":"上海","comment_id":373369,"utype":1}],"discussion_count":1,"race_medal":0,"score":4,"product_id":100541001,"comment_content":"data&#47;toutiao_cat_data.txt 这个文件在哪里呢","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":616716,"discussion_content":"https://github.com/aceimnorstuvwxz/toutiao-text-classfication-dataset\n\n或者\n链接: https://pan.baidu.com/s/1Cl0eFNLOkQqquf9ls0trEw 提取码: jvr4","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683086311,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":371895,"user_name":"Rukit","can_delete":false,"product_type":"c1","uid":2199570,"ip_address":"广东","ucode":"03C30EB7F7415B","user_header":"https://static001.geekbang.org/account/avatar/00/21/90/12/29148117.jpg","comment_is_top":false,"comment_ctime":1680499549,"is_pvip":false,"replies":[{"id":135710,"content":"不通过backoff，是否能够执行成功？看上去像是网络问题导致的超时。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1680581095,"ip_address":"上海","comment_id":371895,"utype":1}],"discussion_count":4,"race_medal":0,"score":4,"product_id":100541001,"comment_content":"运行batch_embeddings = get_embeddings_with_backoff(prompts=batch, engine=embedding_model)这句代码一直显示这个错误RetryError[&lt;Future at 0x1e3a1819900 state=finished raised Timeout&gt;]\n","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612209,"discussion_content":"不通过backoff，是否能够执行成功？看上去像是网络问题导致的超时。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680581095,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":2199570,"avatar":"https://static001.geekbang.org/account/avatar/00/21/90/12/29148117.jpg","nickname":"Rukit","note":"","ucode":"03C30EB7F7415B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":614427,"discussion_content":"不行还是报同样的错误，InvalidRequestError ，说是请求无效造成的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1681788338,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":612209,"ip_address":"广东","group_id":0},"score":614427,"extra":""}]},{"author":{"id":3017168,"avatar":"https://static001.geekbang.org/account/avatar/00/2e/09/d0/8609bddc.jpg","nickname":"戒贪嗔痴","note":"","ucode":"D53EA3525DBD71","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612122,"discussion_content":"网络问题","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680521859,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":2199570,"avatar":"https://static001.geekbang.org/account/avatar/00/21/90/12/29148117.jpg","nickname":"Rukit","note":"","ucode":"03C30EB7F7415B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":3017168,"avatar":"https://static001.geekbang.org/account/avatar/00/2e/09/d0/8609bddc.jpg","nickname":"戒贪嗔痴","note":"","ucode":"D53EA3525DBD71","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":614428,"discussion_content":"我用了梯子，选择美国节点，还是不行","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1681788363,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":612122,"ip_address":"广东","group_id":0},"score":614428,"extra":""}]}]},{"had_liked":false,"id":371875,"user_name":"lala","can_delete":false,"product_type":"c1","uid":3582410,"ip_address":"北京","ucode":"D6B9DD7A6E899F","user_header":"https://static001.geekbang.org/account/avatar/00/36/a9/ca/f216bece.jpg","comment_is_top":false,"comment_ctime":1680483638,"is_pvip":false,"replies":[{"id":135751,"content":"往后看到 11 和 14-17 讲","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1680586344,"ip_address":"上海","comment_id":371875,"utype":1}],"discussion_count":2,"race_medal":0,"score":4,"product_id":100541001,"comment_content":"请问我想利用chatGPT来结合公司的自己业务，打造公司自己的机器人，回答外部客户问题和内部同事问题。比如根据用户问题，直接推荐对应产品，","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612257,"discussion_content":"往后看到 11 和 14-17 讲","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680586344,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2161554,"avatar":"https://static001.geekbang.org/account/avatar/00/20/fb/92/0537ea08.jpg","nickname":"漫游者","note":"","ucode":"23DD0146F43C7D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":617157,"discussion_content":"账号被封两个了，所以要做产品的话，还是得确保账号得安全性，不然三天两头用不了就麻烦了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683355159,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":371856,"user_name":"疯狂的大石榴","can_delete":false,"product_type":"c1","uid":3582370,"ip_address":"中国台湾","ucode":"3D6D582CD65C0E","user_header":"https://static001.geekbang.org/account/avatar/00/36/a9/a2/3b44d3ca.jpg","comment_is_top":false,"comment_ctime":1680431395,"is_pvip":false,"replies":[{"id":135713,"content":"这个文件太大了，看 https:&#47;&#47;github.com&#47;xuwenhao&#47;geektime-ai-course Readme里面写了如何通过百度网盘获取。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1680581415,"ip_address":"上海","comment_id":371856,"utype":1}],"discussion_count":2,"race_medal":0,"score":4,"product_id":100541001,"comment_content":"请问处理之后的数据github链接是正常的么，我点进去显示404呢（toutiao_cat_data_all_with_embeddings.parquet这个文件没办法获取）","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612212,"discussion_content":"这个文件太大了，看 https://github.com/xuwenhao/geektime-ai-course Readme里面写了如何通过百度网盘获取。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680581415,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3579410,"avatar":"https://static001.geekbang.org/account/avatar/00/36/9e/12/969cce3b.jpg","nickname":"没事溜达","note":"","ucode":"367F2C51B40EF6","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612158,"discussion_content":"这个是老师发的网盘链接:  https://pan.baidu.com/s/1Cl0eFNLOkQqquf9ls0trEw 提取码: jvr4","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680535639,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":371799,"user_name":"yanyu-xin","can_delete":false,"product_type":"c1","uid":1899757,"ip_address":"广东","ucode":"3AA389F9E4C236","user_header":"","comment_is_top":false,"comment_ctime":1680341662,"is_pvip":false,"replies":[{"id":135727,"content":" 看 https:&#47;&#47;github.com&#47;xuwenhao&#47;geektime-ai-course 里的README里的百度网盘说明\n\n我请编辑帮忙修正一下","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1680582282,"ip_address":"上海","comment_id":371799,"utype":1}],"discussion_count":1,"race_medal":0,"score":4,"product_id":100541001,"comment_content":"标题”训练模型，看看效果怎么样“下的 GitHub 链接是404错误","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612226,"discussion_content":" 看 https://github.com/xuwenhao/geektime-ai-course 里的README里的百度网盘说明\n\n我请编辑帮忙修正一下","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680582282,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":371773,"user_name":"John","can_delete":false,"product_type":"c1","uid":1020861,"ip_address":"加拿大","ucode":"E4ADF8488953FB","user_header":"https://static001.geekbang.org/account/avatar/00/0f/93/bd/f3977ebb.jpg","comment_is_top":false,"comment_ctime":1680311646,"is_pvip":false,"replies":[{"id":135734,"content":"不设市模型参数，模式使用的是 text-similarity-davinci-001\n一般推荐使用 text-embedding-ada-002\n\nllama-index 默认embedding和query使用的model是可以指定的","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1680583186,"ip_address":"上海","comment_id":371773,"utype":1}],"discussion_count":1,"race_medal":0,"score":4,"product_id":100541001,"comment_content":"想问个问题 OpenAI embedding的时候 是不是跟ChatGPT的model没有关系 默认只会用embedding的ada002? 最近看llama index有点困惑 不知道他的API为什么在构建embedding的service context之前先确定model是3或者4","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612234,"discussion_content":"不设市模型参数，模式使用的是 text-similarity-davinci-001\n一般推荐使用 text-embedding-ada-002\n\nllama-index 默认embedding和query使用的model是可以指定的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680583186,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":371651,"user_name":"无形","can_delete":false,"product_type":"c1","uid":1016889,"ip_address":"北京","ucode":"B740E2A68A17A5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/84/39/c8772466.jpg","comment_is_top":false,"comment_ctime":1680149682,"is_pvip":true,"replies":[{"id":135757,"content":"当然不是，可以用在一起需要使用向量的场景，比如聚类也可以啊，后面做更复杂的深度学习也可以啊。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1680586643,"ip_address":"上海","comment_id":371651,"utype":1}],"discussion_count":1,"race_medal":0,"score":4,"product_id":100541001,"comment_content":"embedding只能解决分类问题吗","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612263,"discussion_content":"当然不是，可以用在一起需要使用向量的场景，比如聚类也可以啊，后面做更复杂的深度学习也可以啊。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680586643,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":371711,"user_name":"Oli张帆","can_delete":false,"product_type":"c1","uid":1338098,"ip_address":"新加坡","ucode":"6E60A370C3C14A","user_header":"https://static001.geekbang.org/account/avatar/00/14/6a/f2/db90fa96.jpg","comment_is_top":false,"comment_ctime":1680226424,"is_pvip":false,"replies":null,"discussion_count":3,"race_medal":0,"score":4,"product_id":100541001,"comment_content":"我对embedding的一些理解，就是在与用户交互时，它可以帮助你在不消耗token的情况下，把你当前需要的最相关的context信息从你的知识库提取出来。我个人觉得这个是目前，把自己的专有知识库和人工智能结合起来的最高效性价比最高的一个办法。不知道我这个看法有没有有一定道理，请老师和大家来指正。","like_count":1,"discussions":[{"author":{"id":3023902,"avatar":"https://static001.geekbang.org/account/avatar/00/2e/24/1e/7a10b411.jpg","nickname":"巧克力张张包","note":"","ucode":"AECA996C607648","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":617511,"discussion_content":"也消耗token吧，你的用户问题也需要embedding才能去搜索知识库里相关context","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683625503,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3588303,"avatar":"","nickname":"Geek_512735","note":"","ucode":"D45BF63D413316","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":614090,"discussion_content":"请问一下这种方法有什么优势呢？比如比其他方法embedding效果更好？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1681693283,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2311670,"avatar":"https://static001.geekbang.org/account/avatar/00/23/45/f6/09aa6e38.jpg","nickname":"Even","note":"","ucode":"A9CDFB3621B603","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612007,"discussion_content":"embedding主要是将你输入的一些字符串转换为浮点数向量，用于各类模型计算","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680486239,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":394033,"user_name":"Mamba","can_delete":false,"product_type":"c1","uid":1475049,"ip_address":"湖北","ucode":"8B3EC90736B8EB","user_header":"https://static001.geekbang.org/account/avatar/00/16/81/e9/d131dd81.jpg","comment_is_top":false,"comment_ctime":1725593927,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100541001,"comment_content":"在美食评论的完整的数据集上，一共299276条，使用text-embedding-3-small模型，花了0.66美刀，得到所有的评论的embedding，然后二八分测试训练集，训练一个能把从 1 分到 5 分的每一个级别都区分出来的随机森林模型，参数n_estimators=500，得到五分类效果：\n              precision    recall  f1-score   support\n\n           1       0.74      0.84      0.79      5577\n           2       0.94      0.35      0.51      3107\n           3       0.81      0.44      0.57      4622\n           4       0.94      0.33      0.49      8633\n           5       0.81      1.00      0.89     37917\n\n    accuracy                           0.81     59856\n   macro avg       0.85      0.59      0.65     59856\nweighted avg       0.83      0.81      0.78     59856","like_count":0},{"had_liked":false,"id":391660,"user_name":"Geek_d54869","can_delete":false,"product_type":"c1","uid":1953765,"ip_address":"北京","ucode":"CF55462EF65B9E","user_header":"","comment_is_top":false,"comment_ctime":1718770664,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100541001,"comment_content":"有一个小小的疑问，使用embending的结果也并没有比传统ML高多少，仅仅1%，实际项目中是不是直接用ML的分类算法了？","like_count":0},{"had_liked":false,"id":391622,"user_name":"cocozhang","can_delete":false,"product_type":"c1","uid":3582519,"ip_address":"美国","ucode":"0157318A652E63","user_header":"https://static001.geekbang.org/account/avatar/00/36/aa/37/7f1b3fbc.jpg","comment_is_top":false,"comment_ctime":1718684049,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100541001,"comment_content":"def get_embeddings_with_backoff(prompts, engine): \n    for i in range(0, len(prompts), batch_size): \n        batch = prompts[i:i+batch_size] \n        embeddings += get_embeddings(list_of_text=batch, engine=engine) \n    return embeddings\n\nprompts = df_all.combined.tolist()\nprompt_batches = [prompts[i:i+batch_size] for i in range(0, len(prompts), batch_size)]\n\nfor batch in prompt_batches: \n    batch_embeddings = get_embeddings_with_backoff(prompts=batch, engine=embedding_model) \n    embeddings += batch_embeddings\n\n老师您好，我对这段代码有点疑惑，想请教一下。我看函数内外均遍历了一遍所有的batch，按说函数的入参就已经是其中之一的batch了，函数应该针对这个batch直接获取embeding就可以了，为什么还要再遍历一遍每个batch呢？是不是重复了呀？","like_count":0},{"had_liked":false,"id":391075,"user_name":"xin","can_delete":false,"product_type":"c1","uid":1609258,"ip_address":"四川","ucode":"B311A30BFE66E0","user_header":"https://static001.geekbang.org/account/avatar/00/18/8e/2a/448b2177.jpg","comment_is_top":false,"comment_ctime":1717233479,"is_pvip":true,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100541001,"comment_content":"1到5分的情感分类结果，使用随机森林\n              precision    recall  f1-score   support\n\n           1       1.00      0.40      0.57        20\n           2       1.00      0.38      0.55         8\n           3       1.00      0.18      0.31        11\n           4       1.00      0.26      0.41        27\n           5       0.74      1.00      0.85       134\n\n    accuracy                           0.77       200\n   macro avg       0.95      0.44      0.54       200\nweighted avg       0.83      0.77      0.72       200","like_count":0},{"had_liked":false,"id":389327,"user_name":"李晓琳_Xiaolin","can_delete":false,"product_type":"c1","uid":1498441,"ip_address":"北京","ucode":"11D2FA6CF9F07F","user_header":"https://static001.geekbang.org/account/avatar/00/16/dd/49/eda13d48.jpg","comment_is_top":false,"comment_ctime":1712127040,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100541001,"comment_content":"一共就五块的额度，十万条数据是0.5， 三十万条数据就得15","like_count":0},{"had_liked":false,"id":389267,"user_name":"李晓琳_Xiaolin","can_delete":false,"product_type":"c1","uid":1498441,"ip_address":"北京","ucode":"11D2FA6CF9F07F","user_header":"https://static001.geekbang.org/account/avatar/00/16/dd/49/eda13d48.jpg","comment_is_top":false,"comment_ctime":1711985747,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100541001,"comment_content":"getembeddings 已经不在embedding_utils 里面了","like_count":0},{"had_liked":false,"id":381171,"user_name":"咖喱棒","can_delete":false,"product_type":"c1","uid":3675984,"ip_address":"新疆","ucode":"E20EFBE019D964","user_header":"https://static001.geekbang.org/account/avatar/00/38/17/50/500c8dd4.jpg","comment_is_top":false,"comment_ctime":1694751113,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100541001,"comment_content":"老师，https:&#47;&#47;raw.githubusercontent.com&#47;aceimnorstuvwxz&#47;toutiao-text-classfication-dataset&#47;master&#47;toutiao_cat_data.txt.zip这个文件貌似失效了，下载不下来，提示Read error (No such file or directory) in headers","like_count":0},{"had_liked":false,"id":380470,"user_name":"飘雨","can_delete":false,"product_type":"c1","uid":1177874,"ip_address":"江苏","ucode":"30AB52C77B2B7B","user_header":"https://static001.geekbang.org/account/avatar/00/11/f9/12/6dcd08eb.jpg","comment_is_top":false,"comment_ctime":1693642087,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100541001,"comment_content":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score\n\ntraining_data = pd.read_parquet(&quot;data&#47;toutiao_cat_data_all_with_embeddings.parquet&quot;)\ntraining_data.head()\n\ndf =  training_data.sample(50000, random_state=42)\n\nX_train, X_test, y_train, y_test = train_test_split(\n    list(df.embedding.values), df.category, test_size=0.2, random_state=42\n)\n\nclf = RandomForestClassifier(n_estimators=300)\nclf.fit(X_train, y_train)\npreds = clf.predict(X_test)\nprobas = clf.predict_proba(X_test)\n\nreport = classification_report(y_test, preds)\nprint(report)\n\n老师帮忙看下，在conda环境下的notebook运行上述代码报如下错误：\nImportError: Unable to find a usable engine; tried using: &#39;pyarrow&#39;, &#39;fastparquet&#39;.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency &#39;pyarrow&#39;. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency &#39;fastparquet&#39;. fastparquet is required for parquet support. Use pip or conda to install fastparquet.","like_count":0},{"had_liked":false,"id":379328,"user_name":"jeff","can_delete":false,"product_type":"c1","uid":1026894,"ip_address":"河北","ucode":"68456DD035BDF4","user_header":"https://static001.geekbang.org/account/avatar/00/0f/ab/4e/82e9657c.jpg","comment_is_top":false,"comment_ctime":1691732508,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100541001,"comment_content":"toutiao_cat_data_all_with_embeddings 数据集不存在了？？？","like_count":0},{"had_liked":false,"id":375480,"user_name":"Geek_d7a1f9","can_delete":false,"product_type":"c1","uid":3632907,"ip_address":"北京","ucode":"6F608EA3CADE57","user_header":"","comment_is_top":false,"comment_ctime":1685523960,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":5,"product_id":100541001,"comment_content":"老师，为什么 chatgpt 的 embedding 需要通过 api 调用，如果我们知道具体算法，实现一个库本地计算不是更好吗","like_count":0,"discussions":[{"author":{"id":2161554,"avatar":"https://static001.geekbang.org/account/avatar/00/20/fb/92/0537ea08.jpg","nickname":"漫游者","note":"","ucode":"23DD0146F43C7D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":620455,"discussion_content":"效果，效果，还是tmd效果~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1686191120,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":375043,"user_name":"石云升","can_delete":false,"product_type":"c1","uid":1024195,"ip_address":"广东","ucode":"78F1DD33EFD000","user_header":"https://static001.geekbang.org/account/avatar/00/0f/a0/c3/c5db35df.jpg","comment_is_top":false,"comment_ctime":1684831329,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":1,"score":6,"product_id":100541001,"comment_content":"琢磨了一下才理解召回率的意思。举个例子，如果我预测了200个邮件，其中80个我预测为垃圾邮件，其他120个为正常邮件。但实际上我预测的这80个里，有70个是真的垃圾邮件。那么预测垃圾邮件准确率就是70&#47;80，另外120个正常邮件里，还有10个垃圾邮件，那么垃圾邮件的召回率就是70&#47;80（总的垃圾邮件数量）","like_count":0},{"had_liked":false,"id":372371,"user_name":"aoe","can_delete":false,"product_type":"c1","uid":1121758,"ip_address":"浙江","ucode":"1C6201EDB4E954","user_header":"https://static001.geekbang.org/account/avatar/00/11/1d/de/62bfa83f.jpg","comment_is_top":false,"comment_ctime":1681047496,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":6,"product_id":100541001,"comment_content":"原来 API 有这么强大的功能！","like_count":0},{"had_liked":false,"id":372072,"user_name":"Viola","can_delete":false,"product_type":"c1","uid":3581980,"ip_address":"摩尔多瓦","ucode":"0F43DBBE822AB6","user_header":"https://static001.geekbang.org/account/avatar/00/36/a8/1c/d231cbfb.jpg","comment_is_top":false,"comment_ctime":1680683890,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":6,"product_id":100541001,"comment_content":"交作业，老师讲得真好，大大启发了我\n---------------------------------\n随机森林300棵树，fine_food_reviews_with_embeddings_1k.csv\n      precision    recall  f1-score   support\n\n           1       1.00      0.35      0.52        20\n           2       1.00      0.38      0.55         8\n           3       1.00      0.18      0.31        11\n           4       1.00      0.26      0.41        27\n           5       0.74      1.00      0.85       134\n\n    accuracy                           0.77       200\n   macro avg       0.95      0.43      0.53       200\nweighted avg       0.83      0.77      0.72       200","like_count":0},{"had_liked":false,"id":371467,"user_name":"Ethan New","can_delete":false,"product_type":"c1","uid":2063962,"ip_address":"浙江","ucode":"9CA2EF39E58030","user_header":"https://static001.geekbang.org/account/avatar/00/1f/7e/5a/da39f489.jpg","comment_is_top":false,"comment_ctime":1679975006,"is_pvip":true,"replies":null,"discussion_count":0,"race_medal":4,"score":6,"product_id":100541001,"comment_content":"学习打卡","like_count":0}]}