{"id":99797,"title":"03 | Kafka只是消息引擎系统吗？","content":"<p>你好，我是胡夕。今天我们来聊一个老生常谈的话题：Kafka只是消息引擎系统吗？</p><p>要搞清楚这个问题，我们不可避免地要了解一下Apache Kafka的发展历程。有的时候我们会觉得说了解一个系统或框架的前世今生似乎没什么必要，直接开始学具体的技术不是更快更好吗？其实，不论是学习哪种技术，直接扎到具体的细节中，亦或是从一个很小的点开始学习，你很快就会感到厌烦。为什么呢？因为你虽然快速地搞定了某个技术细节，但无法建立全局的认知观，这会导致你只是在单个的点上有所进展，却没法将其串联成一条线进而扩展成一个面，从而实现系统地学习。</p><p>我这么说是有依据的，因为这就是我当初学习Kafka的方式。你可能不会相信，我阅读Kafka源码就是从utils包开始的。显然，我们不用看源码也知道这玩意是干什么用的，对吧？就是个工具类包嘛，而且这种阅读源码的方式是极其低效的。就像我说的，我是在一个点一个点地学习，但全部学完之后压根没有任何感觉，依然不了解Kafka，因为不知道这些包中的代码组合在一起能达成什么效果。所以我说它是很低效的学习方法。</p><p>后来我修改了学习的方法，转而从自上而下的角度去理解Kafka，竟然发现了很多之前学习过程中忽略掉的东西。更特别的是，我发现这种学习方法能够帮助我维持较长时间的学习兴趣，不会阶段性地产生厌烦情绪。特别是在了解Apache Kafka整个发展历史的过程中我愉快地学到了很多运营大型开源软件社区的知识和经验，可谓是技术之外的一大收获。</p><!-- [[[read_end]]] --><p>纵观Kafka的发展脉络，它的确是从消息引擎起家的，但正如文章标题所问，<strong>Apache Kafka真的只是消息引擎吗</strong>？通常，在回答这个问题之前很多文章可能就要这样展开了：那我们先来讨论下什么是消息引擎以及消息引擎能做什么事情。算了，我还是直给吧，就不从“唐尧虞舜”说起了。这个问题的答案是，<strong>Apache Kafka是消息引擎系统，也是一个分布式流处理平台</strong>（Distributed Streaming Platform）。如果你通读全篇文字但只能记住一句话，我希望你记住的就是这句。再强调一遍，Kafka是消息引擎系统，也是分布式流处理平台。</p><p>众所周知，Kafka是LinkedIn公司内部孵化的项目。根据我和Kafka创始团队成员的交流以及查阅到的公开信息显示，LinkedIn最开始有强烈的数据强实时处理方面的需求，其内部的诸多子系统要执行多种类型的数据处理与分析，主要包括业务系统和应用程序性能监控，以及用户行为数据处理等。</p><p>当时他们碰到的主要问题包括：</p><ul>\n<li>数据正确性不足。因为数据的收集主要采用轮询（Polling）的方式，如何确定轮询的间隔时间就变成了一个高度经验化的事情。虽然可以采用一些类似于启发式算法（Heuristic）来帮助评估间隔时间值，但一旦指定不当，必然会造成较大的数据偏差。</li>\n<li>系统高度定制化，维护成本高。各个业务子系统都需要对接数据收集模块，引入了大量的定制开销和人工成本。</li>\n</ul><p>为了解决这些问题，LinkedIn工程师尝试过使用ActiveMQ来解决这些问题，但效果并不理想。显然需要有一个“大一统”的系统来取代现有的工作方式，而这个系统就是Kafka。</p><p>Kafka自诞生伊始是以消息引擎系统的面目出现在大众视野中的。如果翻看0.10.0.0之前的官网说明，你会发现Kafka社区将其清晰地定位为一个分布式、分区化且带备份功能的提交日志（Commit Log）服务。</p><p>这里引出一个题外话，你可能好奇Kafka这个名字的由来，实际上Kafka作者之一Jay Kreps曾经谈及过命名的原因。</p><blockquote>\n<p>因为Kafka系统的写性能很强，所以找了个作家的名字来命名似乎是一个好主意。大学期间我上了很多文学课，非常喜欢Franz Kafka这个作家，另外为开源软件起这个名字听上去很酷。</p>\n</blockquote><p>言归正传，Kafka在设计之初就旨在提供三个方面的特性：</p><ul>\n<li>提供一套API实现生产者和消费者；</li>\n<li>降低网络传输和磁盘存储开销；</li>\n<li>实现高伸缩性架构。</li>\n</ul><p>在专栏后面的课程中，我们将陆续探讨Kafka是如何做到以上三点的。总之随着Kafka的不断完善，Jay等大神们终于意识到将其开源惠及更多的人是一个非常棒的主意，因此在2011年Kafka正式进入到Apache基金会孵化并于次年10月顺利毕业成为Apache顶级项目。</p><p>开源之后的Kafka被越来越多的公司应用到它们企业内部的数据管道中，特别是在大数据工程领域，Kafka在承接上下游、串联数据流管道方面发挥了重要的作用：所有的数据几乎都要从一个系统流入Kafka然后再流向下游的另一个系统中。这样的使用方式屡见不鲜以至于引发了Kafka社区的思考：与其我把数据从一个系统传递到下一个系统中做处理，我为何不自己实现一套流处理框架呢？基于这个考量，Kafka社区于0.10.0.0版本正式推出了流处理组件Kafka Streams，也正是从这个版本开始，Kafka正式“变身”为分布式的流处理平台，而不仅仅是消息引擎系统了。今天Apache Kafka是和Apache Storm、Apache Spark和Apache Flink同等级的实时流处理平台。</p><p>诚然，目前国内对Kafka是流处理平台的认知还尚不普及，其核心的流处理组件Kafka Streams更是少有大厂在使用。但我们也欣喜地看到，随着在Kafka峰会上各路大神们的鼎力宣传，如今利用Kafka构建流处理平台的案例层出不穷，而了解并有意愿使用Kafka Streams的厂商也是越来越多，因此我个人对于Kafka流处理平台的前景也是非常乐观的。</p><p>你可能会有这样的疑问：作为流处理平台，Kafka与其他主流大数据流式计算框架相比，优势在哪里呢？我能想到的有两点。</p><p><strong>第一点是更容易实现端到端的正确性（Correctness）</strong>。Google大神Tyler曾经说过，流处理要最终替代它的“兄弟”批处理需要具备两点核心优势：<strong>要实现正确性和提供能够推导时间的工具。实现正确性是流处理能够匹敌批处理的基石</strong>。正确性一直是批处理的强项，而实现正确性的基石则是要求框架能提供精确一次处理语义，即处理一条消息有且只有一次机会能够影响系统状态。目前主流的大数据流处理框架都宣称实现了精确一次处理语义，但这是有限定条件的，即它们只能实现框架内的精确一次处理语义，无法实现端到端的。</p><p>这是为什么呢？因为当这些框架与外部消息引擎系统结合使用时，它们无法影响到外部系统的处理语义，所以如果你搭建了一套环境使得Spark或Flink从Kafka读取消息之后进行有状态的数据计算，最后再写回Kafka，那么你只能保证在Spark或Flink内部，这条消息对于状态的影响只有一次。但是计算结果有可能多次写入到Kafka，因为它们不能控制Kafka的语义处理。相反地，Kafka则不是这样，因为所有的数据流转和计算都在Kafka内部完成，故Kafka可以实现端到端的精确一次处理语义。</p><p><strong>可能助力Kafka胜出的第二点是它自己对于流式计算的定位</strong>。官网上明确标识Kafka Streams是一个用于搭建实时流处理的客户端库而非是一个完整的功能系统。这就是说，你不能期望着Kafka提供类似于集群调度、弹性部署等开箱即用的运维特性，你需要自己选择适合的工具或系统来帮助Kafka流处理应用实现这些功能。</p><p>读到这你可能会说这怎么算是优点呢？坦率来说，这的确是一个“双刃剑”的设计，也是Kafka社区“剑走偏锋”不正面PK其他流计算框架的特意考量。大型公司的流处理平台一定是大规模部署的，因此具备集群调度功能以及灵活的部署方案是不可或缺的要素。但毕竟这世界上还存在着很多中小企业，它们的流处理数据量并不巨大，逻辑也并不复杂，部署几台或十几台机器足以应付。在这样的需求之下，搭建重量级的完整性平台实在是“杀鸡焉用牛刀”，而这正是Kafka流处理组件的用武之地。因此从这个角度来说，未来在流处理框架中，Kafka应该是有一席之地的。</p><p>除了消息引擎和流处理平台，Kafka还有别的用途吗？当然有！你能想象吗，Kafka能够被用作分布式存储系统。Kafka作者之一Jay Kreps曾经专门写过一篇文章阐述为什么能把<a href=\"https://www.confluent.io/blog/okay-store-data-apache-kafka/\">Kafka用作分布式存储</a>。不过我觉得你姑且了解下就好了，我从没有见过在实际生产环境中，有人把Kafka当作持久化存储来用 。</p><p>说了这么多，我只想阐述这样的一个观点：Apache Kafka从一个优秀的消息引擎系统起家，逐渐演变成现在分布式的流处理平台。你不仅要熟练掌握它作为消息引擎系统的非凡特性及使用技巧，最好还要多了解下其流处理组件的设计与案例应用。</p><p><img src=\"https://static001.geekbang.org/resource/image/ea/59/eafc2d9315a8ba858649c1ecd4201459.jpg?wh=2069*2560\" alt=\"\"></p><h2>开放讨论</h2><p>你觉得Kafka未来的演进路线是怎么样的？如果你是Kafka社区的“掌舵人”，你准备带领整个社区奔向什么方向呢？（提示下，你可以把自己想象成Linus再去思考）</p><p>欢迎写下你的思考和答案，我们一起讨论。如果你觉得有所收获，也欢迎把文章分享给你的朋友。</p>","comments":[{"had_liked":false,"id":101757,"user_name":"Michael 🛡YZY","can_delete":false,"product_type":"c1","uid":1186115,"ip_address":"","ucode":"F1D2BF8489A7D2","user_header":"https://static001.geekbang.org/account/avatar/00/12/19/43/226ca347.jpg","comment_is_top":false,"comment_ctime":1559962119,"is_pvip":false,"replies":[{"id":"36809","content":"举个例子，如果我们使用Kafka计算某网页的PV——我们将每次网页访问都作为一个消息发送的Kafka。PV的计算就是我们统计Kafka总共接收了多少条这样的消息即可。精确一次处理语义表示每次网页访问都会产生且只会产生一条消息，否则有可能产生多条消息或压根不产生消息。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1560135852,"ip_address":"","comment_id":101757,"utype":1}],"discussion_count":3,"race_medal":0,"score":"310797607431","product_id":100029201,"comment_content":"学到了。刚接触， 对一次性处理语义的概念和背后的含义不太明确， 能否结合实例讲解比较一下…","like_count":73,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":453104,"discussion_content":"举个例子，如果我们使用Kafka计算某网页的PV——我们将每次网页访问都作为一个消息发送的Kafka。PV的计算就是我们统计Kafka总共接收了多少条这样的消息即可。精确一次处理语义表示每次网页访问都会产生且只会产生一条消息，否则有可能产生多条消息或压根不产生消息。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1560135852,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1221705,"avatar":"https://static001.geekbang.org/account/avatar/00/12/a4/49/1c8598d1.jpg","nickname":"军舰","note":"","ucode":"C7E97415F5196A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":192766,"discussion_content":"Kafka的数据传输给其它流处理系统，不是一样可以保证一次性处理语义？","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1583080260,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":2550743,"avatar":"https://static001.geekbang.org/account/avatar/00/26/eb/d7/90391376.jpg","nickname":"if...else...","note":"","ucode":"D0565908C99695","race_medal":4,"user_type":1,"is_pvip":false},"reply_author":{"id":1221705,"avatar":"https://static001.geekbang.org/account/avatar/00/12/a4/49/1c8598d1.jpg","nickname":"军舰","note":"","ucode":"C7E97415F5196A","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":385544,"discussion_content":"是的，所以让你消息引擎和流处理平台都用kafka","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627120591,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":192766,"ip_address":""},"score":385544,"extra":""}]}]},{"had_liked":false,"id":104577,"user_name":"October","can_delete":false,"product_type":"c1","uid":1137879,"ip_address":"","ucode":"CEDA78F4A5F8B1","user_header":"https://static001.geekbang.org/account/avatar/00/11/5c/d7/e4673fde.jpg","comment_is_top":false,"comment_ctime":1560778655,"is_pvip":false,"replies":[{"id":"37846","content":"不用拿Flink或Spark举例。我们就说一个普通的producer程序：producer需要接收到broker发送的response才能认为发送成功，如果response在传输过程中因为网络抖动丢失了或超时了（这种情况非常常见）而broker实际上已经写入了该消息，那么producer就会认为发送失败从而尝试重新发送，这就可能造成同一条消息被发送了多次。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1560819155,"ip_address":"","comment_id":104577,"utype":1}],"discussion_count":11,"race_medal":0,"score":"259258816415","product_id":100029201,"comment_content":"对于kafka streams相对于其他大数据流式计算框架的优势的第一点不是特别理解。spark或者flink读取消息之后再写回kafka，可能会导致多次写入kafka，老师能不能解释一下什么情况下会多次写入kafka？","like_count":61,"discussions":[{"author":{"id":1846785,"avatar":"https://static001.geekbang.org/account/avatar/00/1c/2e/01/8ef7493c.jpg","nickname":"Lyl","note":"","ucode":"8BA71F2C8789F9","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":174567,"discussion_content":"这个是不是是就是幂等性","likes_number":5,"is_delete":false,"is_hidden":false,"ctime":1581927381,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454326,"discussion_content":"不用拿Flink或Spark举例。我们就说一个普通的producer程序：producer需要接收到broker发送的response才能认为发送成功，如果response在传输过程中因为网络抖动丢失了或超时了（这种情况非常常见）而broker实际上已经写入了该消息，那么producer就会认为发送失败从而尝试重新发送，这就可能造成同一条消息被发送了多次。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1560819155,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1547667,"avatar":"https://static001.geekbang.org/account/avatar/00/17/9d/93/4159edaa.jpg","nickname":"朴素柠檬c","note":"","ucode":"2D4CBB70D801B1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":327209,"discussion_content":"这不就是幂等性问题吗","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1605768044,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1151003,"avatar":"https://static001.geekbang.org/account/avatar/00/11/90/1b/d1bb3edf.jpg","nickname":"谢文杰","note":"","ucode":"DEC1486BA7D985","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":319369,"discussion_content":"Kafka 本身这个问题就存在，Kafka streams是如何做到的.","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1604018245,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3021157,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/rw5mLNEdt1Pk3EYiazjhghykgffMBXd6ib7oQ6lIemQFwd3mXnoj00L4WVWQk1wKHwodLXd9J8sN4pnFVW49qKvQ/132","nickname":"Geek_122e16","note":"","ucode":"632FF9E091B2ED","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":579574,"discussion_content":"kafka streams如何解决这个问题呢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1657532611,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1652895,"avatar":"https://static001.geekbang.org/account/avatar/00/19/38/9f/895353ab.jpg","nickname":"黄卫江","note":"","ucode":"0366942B81E7FC","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":573127,"discussion_content":"换言之，卡夫卡无法提供消息幂等性保证","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1653212452,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1358609,"avatar":"https://static001.geekbang.org/account/avatar/00/14/bb/11/7069b8eb.jpg","nickname":"炫炫","note":"","ucode":"FDC7A0C6E08B02","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":558064,"discussion_content":"怎么解决着幂等呢？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1648083162,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1249652,"avatar":"https://static001.geekbang.org/account/avatar/00/13/11/74/72ffa6d6.jpg","nickname":"StayLet","note":"","ucode":"6B748CA3AF3C5B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":379752,"discussion_content":"是不是有点 事务 的味道？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1624107607,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1066752,"avatar":"https://static001.geekbang.org/account/avatar/00/10/47/00/3202bdf0.jpg","nickname":"piboye","note":"","ucode":"7CFD8712857A85","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":315622,"discussion_content":"而且源头和也没办法保障不重复啊","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1603294219,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1066752,"avatar":"https://static001.geekbang.org/account/avatar/00/10/47/00/3202bdf0.jpg","nickname":"piboye","note":"","ucode":"7CFD8712857A85","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":315621,"discussion_content":"kafka怎么就可以避免呢？ ","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1603294168,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1466447,"avatar":"https://static001.geekbang.org/account/avatar/00/16/60/4f/db0e62b3.jpg","nickname":"Daiver","note":"","ucode":"9B1A03AFBC79BC","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":164066,"discussion_content":"Kafka没有去重功能吗","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1581145102,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":3,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":101844,"user_name":"梁亮","can_delete":false,"product_type":"c1","uid":1376120,"ip_address":"","ucode":"7733F15EBA9D60","user_header":"https://static001.geekbang.org/account/avatar/00/14/ff/78/c05eed06.jpg","comment_is_top":false,"comment_ctime":1559991828,"is_pvip":false,"discussion_count":3,"race_medal":0,"score":"220603323924","product_id":100029201,"comment_content":"推荐大家去搜索一个Confluence的演讲，题目是ETL is dead，其中讲到了Kafka在流处理平台的来龙去脉","like_count":52,"discussions":[{"author":{"id":1118650,"avatar":"https://static001.geekbang.org/account/avatar/00/11/11/ba/2175bc50.jpg","nickname":"Mr.Brooks","note":"","ucode":"D47A6B0236A79F","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":3272,"discussion_content":"https://www.infoq.com/presentations/etl-streams/","likes_number":6,"is_delete":false,"is_hidden":false,"ctime":1564369360,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1063916,"avatar":"https://static001.geekbang.org/account/avatar/00/10/3b/ec/9717448c.jpg","nickname":"刘付强🇨🇳","note":"","ucode":"271094461AD0FC","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":753,"discussion_content":"https://www.youtube.com/watch?v=I32hmY4diFY","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1562040022,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1011453,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/6e/fd/6d0109c0.jpg","nickname":"走小調的凡世林","note":"","ucode":"EF3E5195D56188","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":35179,"discussion_content":"听不懂怎么办哈哈","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1571239201,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":102777,"user_name":"清晨吼于林","can_delete":false,"product_type":"c1","uid":1112920,"ip_address":"","ucode":"6ADCB9B9FB8330","user_header":"https://static001.geekbang.org/account/avatar/00/10/fb/58/6c422e70.jpg","comment_is_top":false,"comment_ctime":1560304276,"is_pvip":false,"replies":[{"id":"37174","content":"同一个组下有多少消费者实例不是看进程数或线程数，而是看创建的KafkaConsumer实例数。所以在你的场景中，B消费者不是一个，而是多个，因为B进程启动了多个线程，而每个线程都维护了单独的KafkaConsumer实例。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1560307578,"ip_address":"","comment_id":102777,"utype":1}],"discussion_count":2,"race_medal":0,"score":"100344552084","product_id":100029201,"comment_content":"老师您好~~~<br>我了解的：一个partition在一个group内，只能被一个消息者进程消费（一个jvm，启动了一个java进程）。  <br>问题前提：经过分区算法的匹配，A partition 被 B 消费者 消费。<br>我的问题：在这个B的消费者里面，假如我用多线程消费（多个线程，每个线程维护了一个KafkaConsumer实例。 而不是一个KafkaConsumer然后多个worker线程消费的模式），那这多个线程都能从这个A partition里面取到消息嘛？","like_count":23,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":453574,"discussion_content":"同一个组下有多少消费者实例不是看进程数或线程数，而是看创建的KafkaConsumer实例数。所以在你的场景中，B消费者不是一个，而是多个，因为B进程启动了多个线程，而每个线程都维护了单独的KafkaConsumer实例。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1560307578,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1270262,"avatar":"https://static001.geekbang.org/account/avatar/00/13/61/f6/1d6b548a.jpg","nickname":"wang","note":"","ucode":"C1A3BCACCB188E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":257389,"discussion_content":"所以回答提问者的问题，是B 进程中只会有一个KafkaConsumer 实例也即是一个线程能消费A partition ， B 消费者更应该称之为一个group, 是吧😁","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1588564664,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":107910,"user_name":"DarKnight","can_delete":false,"product_type":"c1","uid":1435845,"ip_address":"","ucode":"B04AFD03768827","user_header":"https://static001.geekbang.org/account/avatar/00/15/e8/c5/8bdb0bba.jpg","comment_is_top":false,"comment_ctime":1561632471,"is_pvip":false,"replies":[{"id":"39124","content":"嗯嗯，在Spark看来，写入Kafka是一种side effect，它无法控制。所以它无法实现端到端的EOS。Flink 1.4借助了Kafka提供的事务机制来保证E2E EOS，但是没听说Spark也做了这样的改进。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561680531,"ip_address":"","comment_id":107910,"utype":1}],"discussion_count":2,"race_medal":0,"score":"78871043799","product_id":100029201,"comment_content":"胡老师您好！我对于第一点优势那个例子不是很懂，但又很感兴趣。我能否用一个这样的情形去理解呢：<br><br>我在spark内部consume了一条数据并要进行有状态的计算，我可以通过roll back确保做到exactly once，当状态计算过程中可以通过捕捉exception从而roll back到初始状态，但状态计算过程中我可能已经将某些结果发送到kafka了（这些结果我并不想重复发送），虽然我可以roll back所有处于spark内部的数据状态，但发送到kafka的所有数据就已经收不回了。<br><br>不知道这个例子算不算一种解读呢？谢谢！","like_count":18,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":455741,"discussion_content":"嗯嗯，在Spark看来，写入Kafka是一种side effect，它无法控制。所以它无法实现端到端的EOS。Flink 1.4借助了Kafka提供的事务机制来保证E2E EOS，但是没听说Spark也做了这样的改进。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1561680531,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1546425,"avatar":"https://wx.qlogo.cn/mmopen/vi_32/NicGuX4PVAEF0OZGtzxEIHfMMnu58YjXsSS3ubm6q7jPlxZx6iaOMzpFHJQ4UcBA6bXQzAyVI5WD6R1wpnBkbSlw/132","nickname":"shine88","note":"","ucode":"C19CB397E490E6","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":396666,"discussion_content":"不就类似是分布式事务的问题嘛。。用kafka自己的流处理，是不是就不存在类似分布式事务的问题了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1632473600,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":122783,"user_name":"钱","can_delete":false,"product_type":"c1","uid":1009652,"ip_address":"","ucode":"2C92A243A463D4","user_header":"https://static001.geekbang.org/account/avatar/00/0f/67/f4/9a1feb59.jpg","comment_is_top":false,"comment_ctime":1565521312,"is_pvip":false,"replies":[{"id":"45064","content":"嗯嗯，记下了您的建议","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1565571284,"ip_address":"","comment_id":122783,"utype":1}],"discussion_count":1,"race_medal":0,"score":"61695063456","product_id":100029201,"comment_content":"课前思考<br>kafka除了可以作为一个消息引擎系统，还能用来干什么？这个还真不太清楚，它的核心功能不就是，将消息倒一道手嘛？<br>课后思考<br>1：kafka可以作为什么来使用？<br>1-1：一个分布式消息引擎系统——广泛使用<br>1-2：一个分布式流处理平台，可以和Storm&#47;Spark&#47;Flink相媲美——越来越多这么玩，根据老师的评论回复，感觉kafka更是一个分布式流处理库。<br>1-3：一个分布式存储系统——很少使用，关键增删改查的效率好不？如果挺好，也可以这么玩吧！<br><br>如果我是kafka的掌舵人，我会逐渐丰富kafka的生态圈，把kafka弄得和Spring全家桶类似，以后的ABC把kafka家族的程员作为标配。<br><br>2：啥是流处理？<br>是指实时处理无限数据集的数据的一种处理方式嘛？<br>3：啥是批处理？<br>是指一次处理一批数据，且此数据的集合是有限的？<br>4：流处理和批处理，没理解，kafka作为分布式流处理平台的优势也没理解？看评论，流处理的数据集是无限数据集，那岂不是永远处理不完，直到天荒地老？<br>5：数据正确性不足是什么意思？会丢数据？没明白和数据收集的方式的逻辑是什么？<br><br>计算机我的理解，就是处理数据的，处理数据无非是针对数据的存储转发增删改查存分析统计，然后就是挖空心思加快速度。<br>感觉不该如此难以理解😊，一图胜千言，希望后面看到老师有图有真相。","like_count":15,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":462403,"discussion_content":"嗯嗯，记下了您的建议","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1565571284,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":102980,"user_name":"你好旅行者","can_delete":false,"product_type":"c1","uid":1154101,"ip_address":"","ucode":"5C72A428DC28F3","user_header":"https://static001.geekbang.org/account/avatar/00/11/9c/35/9dc79371.jpg","comment_is_top":false,"comment_ctime":1560341520,"is_pvip":false,"replies":[{"id":"37297","content":"嗯嗯，这说的就是0.11之前的故事。事实上，Apache Flink从1.4开始推出了支持E2E Exactly-Once语义的两阶段SinkFunction。它用的就是Kafka 0.11的事务","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1560385636,"ip_address":"","comment_id":102980,"utype":1}],"discussion_count":1,"race_medal":0,"score":"31625112592","product_id":100029201,"comment_content":"关于【但是计算结果有可能多次写入到 Kafka，因为它们不能控制 Kafka的语义处理】。我想问老师，Kafka不是在0.11版本实现了exactly once，保证一条消息只会被消费一次吗，为什么说计算结果还有可能会被多次写入到Kafka呢？","like_count":7,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":453674,"discussion_content":"嗯嗯，这说的就是0.11之前的故事。事实上，Apache Flink从1.4开始推出了支持E2E Exactly-Once语义的两阶段SinkFunction。它用的就是Kafka 0.11的事务","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1560385636,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":135285,"user_name":"平叔叔","can_delete":false,"product_type":"c1","uid":1477999,"ip_address":"","ucode":"E521DFF752C89B","user_header":"https://static001.geekbang.org/account/avatar/00/16/8d/6f/c21eff20.jpg","comment_is_top":false,"comment_ctime":1569118236,"is_pvip":false,"replies":[{"id":"51951","content":"你不要搭建多套这样重量级的系统，只需要一套Kafka集群就可以。并不是说Kafka集群不需要运维管理","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1569200716,"ip_address":"","comment_id":135285,"utype":1}],"discussion_count":1,"race_medal":0,"score":"27338922012","product_id":100029201,"comment_content":"在这样的需求之下，搭建重量级的完整性平台实在是“杀鸡焉用牛刀，的意思中小企业使用Kafka 不用配套提供集群调度、弹性部署？<br><br>","like_count":7,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":468126,"discussion_content":"你不要搭建多套这样重量级的系统，只需要一套Kafka集群就可以。并不是说Kafka集群不需要运维管理","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1569200716,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":104003,"user_name":"Shane","can_delete":false,"product_type":"c1","uid":1291344,"ip_address":"","ucode":"322D0A883BAF16","user_header":"https://static001.geekbang.org/account/avatar/00/13/b4/50/c5dad2dc.jpg","comment_is_top":false,"comment_ctime":1560587560,"is_pvip":false,"replies":[{"id":"37733","content":"流处理和批处理的区别是前者主要用于处理无限数据集（unbound data set）","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1560687150,"ip_address":"","comment_id":104003,"utype":1}],"discussion_count":2,"race_medal":0,"score":"27330391336","product_id":100029201,"comment_content":"老师，能举个例子说明下流出来和批处理的区别吗？<br>目前我的理解就是批处理是一次请求中包含多条消息？然后消费者取出这一整个请求内容进行处理消费。流处理就是每个请求每次只发送一条消息，所以消费者也只能每次消费一条？<br><br>感觉自己理解的应该不怎么正确呢？网络上的解释也是非常虚，想看看老师有啥指导的吗？","like_count":6,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454087,"discussion_content":"流处理和批处理的区别是前者主要用于处理无限数据集（unbound data set）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1560687150,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1039886,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/de/0e/af8dd241.jpg","nickname":"GeekZd","note":"","ucode":"D2AA3305A6AFE8","race_medal":1,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":543356,"discussion_content":"所以楼主理解的流处理和批处理是否正确呢？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1641104831,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":112070,"user_name":"赵鹏举","can_delete":false,"product_type":"c1","uid":1260182,"ip_address":"","ucode":"B3785788D6176C","user_header":"https://static001.geekbang.org/account/avatar/00/13/3a/96/9fddfb4a.jpg","comment_is_top":false,"comment_ctime":1562664172,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"23037500652","product_id":100029201,"comment_content":"夕哥的英文非常标准，听着语音很舒服","like_count":5},{"had_liked":false,"id":106036,"user_name":"EricJones","can_delete":false,"product_type":"c1","uid":1207580,"ip_address":"","ucode":"0A80B609400D6B","user_header":"https://static001.geekbang.org/account/avatar/00/12/6d/1c/d9746372.jpg","comment_is_top":false,"comment_ctime":1561134670,"is_pvip":false,"replies":[{"id":"38474","content":"假设我们统计单词计数。如果不出现问题，对于相同的有限输入（bounded dataset）批处理是不是总是能够得到相同的输出？","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561337380,"ip_address":"","comment_id":106036,"utype":1}],"discussion_count":1,"race_medal":0,"score":"23035971150","product_id":100029201,"comment_content":"我又仔细意会了一下，流处理大概已经懂了，但是批处理的正确性到底体现在哪里。还是不知道。","like_count":5,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454928,"discussion_content":"假设我们统计单词计数。如果不出现问题，对于相同的有限输入（bounded dataset）批处理是不是总是能够得到相同的输出？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561337380,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":104188,"user_name":"东方奇骥","can_delete":false,"product_type":"c1","uid":1354850,"ip_address":"","ucode":"DEE7085F7E55A4","user_header":"https://static001.geekbang.org/account/avatar/00/14/ac/62/37912d51.jpg","comment_is_top":false,"comment_ctime":1560677285,"is_pvip":true,"replies":[{"id":"37743","content":"如果和rabbitmq和activemq相比，Kafka还是以消息引擎的角色。目前Kafka消息引擎单方面只能提供at least once处理语义，无法实现精确一次的消息交付语义。<br><br>另外，正确性一般用在数据计算领域。在消息引擎中我们更多的是谈它的消息交付语义（message delivery semantics）","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1560687861,"ip_address":"","comment_id":104188,"utype":1}],"discussion_count":3,"race_medal":0,"score":"23035513765","product_id":100029201,"comment_content":"老师，请问一下，kafka相比于rabbitmq和activemq作为消息引擎系统的优势是什么呢。就是文中所说的消息正确性吗？","like_count":5,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454164,"discussion_content":"如果和rabbitmq和activemq相比，Kafka还是以消息引擎的角色。目前Kafka消息引擎单方面只能提供at least once处理语义，无法实现精确一次的消息交付语义。\n\n另外，正确性一般用在数据计算领域。在消息引擎中我们更多的是谈它的消息交付语义（message delivery semantics）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1560687861,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1789481,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/4e/29/adcb78e7.jpg","nickname":"静心","note":"","ucode":"B80DE4B5C923D3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":394858,"discussion_content":"对啊，不是有幂等生产者吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1632104126,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1067981,"avatar":"https://static001.geekbang.org/account/avatar/00/10/4b/cd/185e5378.jpg","nickname":"泊浮目","note":"","ucode":"182A7CC2F6BDAB","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":193847,"discussion_content":"不是有幂等生产者吗？为什么无法实现精确一次的消息交付语义？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1583162786,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":102171,"user_name":"永光","can_delete":false,"product_type":"c1","uid":1102702,"ip_address":"","ucode":"0C54531ABED1B0","user_header":"https://static001.geekbang.org/account/avatar/00/10/d3/6e/281b85aa.jpg","comment_is_top":false,"comment_ctime":1560155993,"is_pvip":false,"replies":[{"id":"36843","content":"1. E2E你可以近似地认为是从生产者端到消费者端或者是跨上下游系统。这种场景下如何确保消息或事件对最终状态的影响有且只有一次是极有挑战的课题。 <br>2. 可以这么理解。Kafka Streams目前定位是流处理库（library），而不是平台（platform）。这也说明了它和其他流处理框架的差异化。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1560158735,"ip_address":"","comment_id":102171,"utype":1}],"discussion_count":1,"race_medal":0,"score":"23034992473","product_id":100029201,"comment_content":"老师好，<br>对于流处理不是很了解，然后你说的Kafka流处理的两个优点都没有get到，呜呜呜。<br>1、第一点是更容易实现端到端的正确性。<br>目前主流的大数据流处理框架都宣称实现了精确一次处理语义，但这是有限定条件的，即它们只能实现框架内的精确一次处理语义，无法实现端到端的。<br><br>主流的大数据流处理框架为什么不能实现端到端的精确一次处理语义，什么是端到端的精确一次处理语义呀？<br><br>2、它自己对于流式计算的定位。这是在说Kafka流处理相比于其他的更轻量级？<br>","like_count":5,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":453286,"discussion_content":"1. E2E你可以近似地认为是从生产者端到消费者端或者是跨上下游系统。这种场景下如何确保消息或事件对最终状态的影响有且只有一次是极有挑战的课题。 \n2. 可以这么理解。Kafka Streams目前定位是流处理库（library），而不是平台（platform）。这也说明了它和其他流处理框架的差异化。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1560158735,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":206767,"user_name":"小晏子","can_delete":false,"product_type":"c1","uid":1132337,"ip_address":"","ucode":"3AAA6FB5ACB6AE","user_header":"https://static001.geekbang.org/account/avatar/00/11/47/31/f35367c8.jpg","comment_is_top":false,"comment_ctime":1586931286,"is_pvip":false,"replies":[{"id":"77324","content":"非常棒的建议！<br>","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1587003475,"ip_address":"","comment_id":206767,"utype":1}],"discussion_count":2,"race_medal":1,"score":"18766800470","product_id":100029201,"comment_content":"课后思考：我不是特别清楚kafka未来发展方向，不过在老师的提示下我感觉可以让kafka提供扩展接口，用户可以自定义plugin去扩展kafka的功能，kafka只提供核心的消息服务和流处理服务。","like_count":4,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491895,"discussion_content":"非常棒的建议！\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587003475,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1601052,"avatar":"","nickname":"nextforevershit","note":"","ucode":"606F238E0F189B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":343770,"discussion_content":"然后Kafka就成为了消息界的Spring，光想想就很牛逼！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1611153463,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":104593,"user_name":"October","can_delete":false,"product_type":"c1","uid":1137879,"ip_address":"","ucode":"CEDA78F4A5F8B1","user_header":"https://static001.geekbang.org/account/avatar/00/11/5c/d7/e4673fde.jpg","comment_is_top":false,"comment_ctime":1560780697,"is_pvip":false,"replies":[{"id":"37849","content":"hmm...... 社区的确是宣称Kafka Streams可以做到EOS。但我个人的看法是：目前市面宣称做到EOS这件事更多的还是marketing，即营销的一种手段。我不觉得有哪个流处理框架100%地实现了EOS，否则如果流处理真的实现了正确性，同时还提供低延时，批处理为什么还活着呢？当然这是我一家之言了哈。至少从技术的角度探讨，Kafka Streams是能做到EOS的。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1560819339,"ip_address":"","comment_id":104593,"utype":1}],"discussion_count":2,"race_medal":0,"score":"18740649881","product_id":100029201,"comment_content":"看到老师评论区的回复有个问题，kafka目前到底能否实现exactly once的处理语义？","like_count":4,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454334,"discussion_content":"hmm...... 社区的确是宣称Kafka Streams可以做到EOS。但我个人的看法是：目前市面宣称做到EOS这件事更多的还是marketing，即营销的一种手段。我不觉得有哪个流处理框架100%地实现了EOS，否则如果流处理真的实现了正确性，同时还提供低延时，批处理为什么还活着呢？当然这是我一家之言了哈。至少从技术的角度探讨，Kafka Streams是能做到EOS的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1560819339,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1412220,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEIaTvOKvUt4WnuSjkBp0tjd6O6vvVyw5fcib3UgZibE8tz2ICbTfkwbzs8MHNMJjV6W2mLjywLsvBibg/132","nickname":"火力全开","note":"","ucode":"8CE1733A2F618C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":165334,"discussion_content":"批处理还有其他用途， 也就是在需要使用历史数据的时候","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1581263746,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":104946,"user_name":"JoeyLi666","can_delete":false,"product_type":"c1","uid":1564463,"ip_address":"","ucode":"734864661E4BE0","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJZCkGPSOcvucpfLqRP3aqp3qRpwJKyzjNms4jMwibIkxpjiaszqiazSItCeo3IxqQSFvMDh66XaJ2zw/132","comment_is_top":false,"comment_ctime":1560876696,"is_pvip":false,"replies":[{"id":"38033","content":"最近Flink Kafka Connector正式移除了Beta标签【Flink-12806】，应该会更加稳定了吧：）","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1560906086,"ip_address":"","comment_id":104946,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14445778584","product_id":100029201,"comment_content":"flink支持kafka的端到端 exactly once,不过有一定局限性","like_count":3,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454494,"discussion_content":"最近Flink Kafka Connector正式移除了Beta标签【Flink-12806】，应该会更加稳定了吧：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1560906086,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":106035,"user_name":"EricJones","can_delete":false,"product_type":"c1","uid":1207580,"ip_address":"","ucode":"0A80B609400D6B","user_header":"https://static001.geekbang.org/account/avatar/00/12/6d/1c/d9746372.jpg","comment_is_top":false,"comment_ctime":1561134347,"is_pvip":false,"replies":[{"id":"38473","content":"每次执行批处理都能保证得到相同的值，但是流处理无法做到这一点。批处理一般采用fail-fast来保证即使中间出现错误也能实现正确性 ","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561337316,"ip_address":"","comment_id":106035,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10151068939","product_id":100029201,"comment_content":"学到了，消息引擎系统、分布式流处理平台。<br>kafka 流处理平台具有的优势：正确性，精确一次处理语义。对流式计算的定位。<br>理解了精确一次处理语义，但是没get到这其中的点。为什么说正确性是批处理的强项。一批消息传给服务器A，A进行处理然后B服务器从A获取这批消息。这个过程不也是有可能出现消息获取失败，需要第二次去获取吗？该怎么理解框架内流处理与端与端？有大佬可以解释下吗？ 谢谢","like_count":2,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454927,"discussion_content":"每次执行批处理都能保证得到相同的值，但是流处理无法做到这一点。批处理一般采用fail-fast来保证即使中间出现错误也能实现正确性 ","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561337316,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":102518,"user_name":"霄嵩","can_delete":false,"product_type":"c1","uid":1241047,"ip_address":"","ucode":"13F41F87B812C4","user_header":"https://static001.geekbang.org/account/avatar/00/12/ef/d7/049cc631.jpg","comment_is_top":false,"comment_ctime":1560242001,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10150176593","product_id":100029201,"comment_content":"老师写的很用心，加油！","like_count":2},{"had_liked":false,"id":102304,"user_name":"文竹","can_delete":false,"product_type":"c1","uid":1103167,"ip_address":"","ucode":"74413B1975976B","user_header":"https://static001.geekbang.org/account/avatar/00/10/d5/3f/80bf4841.jpg","comment_is_top":false,"comment_ctime":1560183677,"is_pvip":false,"replies":[{"id":"36913","content":"Confluent公司的Confluent Kafka做到了这一点。社区版的Kafka没有这样的功能~","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1560214897,"ip_address":"","comment_id":102304,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10150118269","product_id":100029201,"comment_content":"目前kafka相关组件太分散以及通过命令行运维，希望有一个平台产品集成所有组件（基础运维，ksql，AI等）","like_count":2,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":453350,"discussion_content":"Confluent公司的Confluent Kafka做到了这一点。社区版的Kafka没有这样的功能~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1560214897,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":101957,"user_name":"燕子上","can_delete":false,"product_type":"c1","uid":1102811,"ip_address":"","ucode":"E82C78BE7D312A","user_header":"https://static001.geekbang.org/account/avatar/00/10/d3/db/5ce5bb26.jpg","comment_is_top":false,"comment_ctime":1560072124,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10150006716","product_id":100029201,"comment_content":"还是那句话：Apache Kafka 是消息引擎系统，也是一个分布式流处理平台！主：消息引擎，辅：流处理","like_count":2},{"had_liked":false,"id":101941,"user_name":"言希","can_delete":false,"product_type":"c1","uid":1154218,"ip_address":"","ucode":"D7F80B86BCAF2E","user_header":"https://static001.geekbang.org/account/avatar/00/11/9c/aa/6f780187.jpg","comment_is_top":false,"comment_ctime":1560063668,"is_pvip":false,"replies":[{"id":"36815","content":"看看是否存在消息corrupted导致的hang住——可能的原因是网络传输中的某些瞬时故障，不过应该极为罕见。可以启动一个Console consumer去消费下试试","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1560136325,"ip_address":"","comment_id":101941,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10149998260","product_id":100029201,"comment_content":"胡大神，最近生产环境上遇到问题，数据在kafka中积压了一段时间，重新启动消费者后显示加入消费组成功但是一直不消费数据，current-offset一直没变。能帮忙提供排查思路嘛|","like_count":2,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":453181,"discussion_content":"看看是否存在消息corrupted导致的hang住——可能的原因是网络传输中的某些瞬时故障，不过应该极为罕见。可以启动一个Console consumer去消费下试试","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1560136325,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":101912,"user_name":"臧萌","can_delete":false,"product_type":"c1","uid":1008692,"ip_address":"","ucode":"5505C1516EDFD5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/64/34/03335c4a.jpg","comment_is_top":false,"comment_ctime":1560050702,"is_pvip":false,"replies":[{"id":"36814","content":"这个没有通用的范围值，但我像毫秒到几十毫秒级的消息传输应该是能够达到的吧。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1560136169,"ip_address":"","comment_id":101912,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10149985294","product_id":100029201,"comment_content":"虽然Kafka的优势是吞吐量，但是我想请教一下latency的问题。对于生产级的硬件（ssd，Linux系统优化，最新cpu，0.1以下的ping），一个Kafka的消息从发出到被收到，合理的latency应该是多少范围内？","like_count":2,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":453169,"discussion_content":"这个没有通用的范围值，但我像毫秒到几十毫秒级的消息传输应该是能够达到的吧。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1560136169,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":101744,"user_name":"aof","can_delete":false,"product_type":"c1","uid":1062864,"ip_address":"","ucode":"5815D63C4926BC","user_header":"https://static001.geekbang.org/account/avatar/00/10/37/d0/26975fba.jpg","comment_is_top":false,"comment_ctime":1559955940,"is_pvip":false,"replies":[{"id":"36808","content":"就我目前得到的消息，Kafka创业团队正在发力KSQL，尚无KML之类计划：）","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1560135624,"ip_address":"","comment_id":101744,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10149890532","product_id":100029201,"comment_content":"作为对比，Spark生态比较完善，flink也在完善批处理，而且两者都对机器学习支持的也比较好，在以后人工智能技术和应用场景越来越成熟的情况下，如果kafka要想持续获得竞争力，是不是也要发力机器学习？","like_count":2,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":453098,"discussion_content":"就我目前得到的消息，Kafka创业团队正在发力KSQL，尚无KML之类计划：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1560135624,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":255287,"user_name":"piboye","can_delete":false,"product_type":"c1","uid":1066752,"ip_address":"","ucode":"7CFD8712857A85","user_header":"https://static001.geekbang.org/account/avatar/00/10/47/00/3202bdf0.jpg","comment_is_top":false,"comment_ctime":1603294039,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"5898261335","product_id":100029201,"comment_content":"不认同kafka作为流处理简单的优势，云平台本身提供了便利性，这种运维优势，以后越来越不重要了。基于k8s云原生理念，未来的大量技术的假设都要发生改变。 new sql，已经云上的分布式文件系统。","like_count":1},{"had_liked":false,"id":251029,"user_name":"TrumanDu","can_delete":false,"product_type":"c1","uid":1297721,"ip_address":"","ucode":"7749D655E6BFD2","user_header":"https://static001.geekbang.org/account/avatar/00/13/cd/39/abe23300.jpg","comment_is_top":false,"comment_ctime":1601338577,"is_pvip":false,"replies":[{"id":"92157","content":"������","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1602208286,"ip_address":"","comment_id":251029,"utype":1}],"discussion_count":3,"race_medal":0,"score":"5896305873","product_id":100029201,"comment_content":"推荐一个kafka监控及管理的平台开源产品 https:&#47;&#47;github.com&#47;xaecbd&#47;KafkaCenter<br><br>国人开源，国货之光","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":506369,"discussion_content":"������","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1602208286,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2103320,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/YQBwClu5f6pibYCNxoEgKkM2uvgytevWp1FBVnec3ialmFDsftEvjvRShYKn2cTicmK8M9az6ribcz65zPpGq3X3QA/132","nickname":"Geek_a68e6d","note":"","ucode":"F7AD54784E79A6","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":583792,"discussion_content":"mark","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1660385984,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"北京"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1297721,"avatar":"https://static001.geekbang.org/account/avatar/00/13/cd/39/abe23300.jpg","nickname":"TrumanDu","note":"","ucode":"7749D655E6BFD2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":311096,"discussion_content":"乱码了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1602219551,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":209870,"user_name":"shi.yunlai","can_delete":false,"product_type":"c1","uid":1210248,"ip_address":"","ucode":"9E7124F22F182A","user_header":"https://static001.geekbang.org/account/avatar/00/12/77/88/965e9951.jpg","comment_is_top":false,"comment_ctime":1587629469,"is_pvip":false,"replies":[{"id":"78370","content":"对于producer而言，实现同步使用producer.send().get()；<br>对于consumer而言，目前默认就是同步消费的效果，即consumer等待消息返回然后在同一个线程内消费数据，然后再继续消费。不知道这是否是你说的意思：）","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1587712786,"ip_address":"","comment_id":209870,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5882596765","product_id":100029201,"comment_content":"请教一个问题：基于kafka如何实现同步的请求&#47;响应？（我的第一反应是需要请求和处理双方预先约定好一来一回两个topic）请教夕哥、同时也请各位大牛指点。","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492888,"discussion_content":"对于producer而言，实现同步使用producer.send().get()；\n对于consumer而言，目前默认就是同步消费的效果，即consumer等待消息返回然后在同一个线程内消费数据，然后再继续消费。不知道这是否是你说的意思：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587712786,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1789481,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/4e/29/adcb78e7.jpg","nickname":"静心","note":"","ucode":"B80DE4B5C923D3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":394861,"discussion_content":"应该说的是producer和consumer之间如何实现同步的请求和响应吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1632105562,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":106828,"user_name":"武塘","can_delete":false,"product_type":"c1","uid":1507813,"ip_address":"","ucode":"4F898F7615C39E","user_header":"","comment_is_top":false,"comment_ctime":1561391323,"is_pvip":false,"replies":[{"id":"38672","content":"对Camel不是特别熟悉，但我不认为这两者构成竞争关系。Camel有一些独到之处是Kafka没有的，至少它能汇聚各个中间件的消息，另外它也支持复杂的消息路由。就像Camel宣称的那样，它是一款企业级的数据整合方案。在设计立意上， 我感觉要比Kafka的层次要高。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561423630,"ip_address":"","comment_id":106828,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5856358619","product_id":100029201,"comment_content":"请教下kafka和camel在流处理上的实际区别。理论上来说，kafka是一个有着一定流处理能力的消息引擎，camel是一个ETL的framework，但实际应用在结合一个消息引擎比如ActiveMQ也可以实现流处理，当然这里也可以采用Kafka做消息引擎。我的迷惑是有了kafka，在工程应用中是否可以完全取代camel，还是它们还是有自己适用的不同场景呢？","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":455240,"discussion_content":"对Camel不是特别熟悉，但我不认为这两者构成竞争关系。Camel有一些独到之处是Kafka没有的，至少它能汇聚各个中间件的消息，另外它也支持复杂的消息路由。就像Camel宣称的那样，它是一款企业级的数据整合方案。在设计立意上， 我感觉要比Kafka的层次要高。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561423630,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":104115,"user_name":"Bitson","can_delete":false,"product_type":"c1","uid":1565077,"ip_address":"","ucode":"9C8EF990D47F07","user_header":"https://static001.geekbang.org/account/avatar/00/17/e1/95/29a5cb97.jpg","comment_is_top":false,"comment_ctime":1560656104,"is_pvip":false,"replies":[{"id":"37736","content":"有。Confluent Kafka目前也分社区版和商业版本，前者是免费的","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1560687383,"ip_address":"","comment_id":104115,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5855623400","product_id":100029201,"comment_content":"请问confluence kafka要收费的吗，有没有免费版的？","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454132,"discussion_content":"有。Confluent Kafka目前也分社区版和商业版本，前者是免费的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1560687383,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":103301,"user_name":"demmm","can_delete":false,"product_type":"c1","uid":1564662,"ip_address":"","ucode":"59AFF2F0AE8975","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Dj5vm74aAUm94vSrpRlCx2YOHhcufubUA6yJHzcdNw3X7TYwKjpl0kAxfTs9Xcmt0YuIHZu7fHI4mt1mzKs4sw/132","comment_is_top":false,"comment_ctime":1560410704,"is_pvip":false,"replies":[{"id":"37387","content":"严格来说这两个是完全不同领域内的东西。各自都有响当当的理论、框架。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1560425094,"ip_address":"","comment_id":103301,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5855378000","product_id":100029201,"comment_content":"消息引擎系统，也是一个分布式流处理平台<br><br>想问下这两个概念到底有什么区别呢","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":453822,"discussion_content":"严格来说这两个是完全不同领域内的东西。各自都有响当当的理论、框架。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1560425094,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":101909,"user_name":"南辕北辙","can_delete":false,"product_type":"c1","uid":1214502,"ip_address":"","ucode":"03EC406AE0D591","user_header":"https://static001.geekbang.org/account/avatar/00/12/88/26/b8c53cee.jpg","comment_is_top":false,"comment_ctime":1560048841,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5855016137","product_id":100029201,"comment_content":"目前团队还是在用flink做实时流计算，希望好好跟着老师学一下kafka的流处理，再来好好对比一下","like_count":1},{"had_liked":false,"id":356533,"user_name":"码小呆","can_delete":false,"product_type":"c1","uid":2055809,"ip_address":"广东","ucode":"44532D6ABF9340","user_header":"https://static001.geekbang.org/account/avatar/00/1f/5e/81/82709d6e.jpg","comment_is_top":false,"comment_ctime":1662385204,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1662385204","product_id":100029201,"comment_content":"说实话,在工作中没有实际的用到kafka,跟着专栏 学习","like_count":0},{"had_liked":false,"id":323116,"user_name":"追风筝的人","can_delete":false,"product_type":"c1","uid":1488020,"ip_address":"","ucode":"2993D60F94C396","user_header":"https://static001.geekbang.org/account/avatar/00/16/b4/94/2796de72.jpg","comment_is_top":false,"comment_ctime":1637734630,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1637734630","product_id":100029201,"comment_content":"Apache Kafka 从一个优秀的消息引擎系统起家，逐渐演变成现在分布式的流处理平台。","like_count":0},{"had_liked":false,"id":277944,"user_name":"Geek8819","can_delete":false,"product_type":"c1","uid":2028950,"ip_address":"","ucode":"521AEDAB2EED81","user_header":"https://static001.geekbang.org/account/avatar/00/1e/f5/96/e963b41b.jpg","comment_is_top":false,"comment_ctime":1612679084,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1612679084","product_id":100029201,"comment_content":"flink的kafka connector通过kafka事务可以做到end to end exactly once的","like_count":0},{"had_liked":false,"id":269905,"user_name":"懒懒想睡觉","can_delete":false,"product_type":"c1","uid":1461520,"ip_address":"","ucode":"3979C31A90B504","user_header":"https://static001.geekbang.org/account/avatar/00/16/4d/10/5c9bc771.jpg","comment_is_top":false,"comment_ctime":1608853966,"is_pvip":false,"replies":[{"id":"98147","content":"呃。。。。。当个技术储备也是好的","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1609205141,"ip_address":"","comment_id":269905,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1608853966","product_id":100029201,"comment_content":"我面对的客户往往都不是互联网企业，一台服务器是标配，两台服务器基本没有，多数只有局域网，少部分移动信号都没有，不知道Kafka有何用武之地。","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":512433,"discussion_content":"呃。。。。。当个技术储备也是好的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1609205141,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":262555,"user_name":"朴素柠檬c","can_delete":false,"product_type":"c1","uid":1547667,"ip_address":"","ucode":"2D4CBB70D801B1","user_header":"https://static001.geekbang.org/account/avatar/00/17/9d/93/4159edaa.jpg","comment_is_top":false,"comment_ctime":1605767921,"is_pvip":false,"replies":[{"id":"95338","content":"嗯嗯，毕竟我们担心的事情99%都不会发生：）","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1605838131,"ip_address":"","comment_id":262555,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1605767921","product_id":100029201,"comment_content":"作为应用开发，真心吧kafka作为存储系统，异步定时从Kafka中获取数据","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509883,"discussion_content":"嗯嗯，毕竟我们担心的事情99%都不会发生：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605838131,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":223244,"user_name":"弱水穿云天","can_delete":false,"product_type":"c1","uid":1190060,"ip_address":"","ucode":"80DC528A23ED7E","user_header":"https://static001.geekbang.org/account/avatar/00/12/28/ac/37a2a265.jpg","comment_is_top":false,"comment_ctime":1591026689,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1591026689","product_id":100029201,"comment_content":"打卡","like_count":0},{"had_liked":false,"id":216962,"user_name":"Geek_fanfan","can_delete":false,"product_type":"c1","uid":1878084,"ip_address":"","ucode":"A2E50A38037DE7","user_header":"","comment_is_top":false,"comment_ctime":1589377974,"is_pvip":false,"replies":[{"id":"80241","content":"Kafka Streams也提供了时间窗口，有3种：Tumbling&#47;Sliding&#47;Session","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1589382402,"ip_address":"","comment_id":216962,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1589377974","product_id":100029201,"comment_content":"胡老，kafka流处理是像spark一样window机制？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":494994,"discussion_content":"Kafka Streams也提供了时间窗口，有3种：Tumbling/Sliding/Session","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589382402,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":192383,"user_name":"sipom","can_delete":false,"product_type":"c1","uid":1074197,"ip_address":"","ucode":"80411DC49CFA57","user_header":"https://static001.geekbang.org/account/avatar/00/10/64/15/9c9ca35c.jpg","comment_is_top":false,"comment_ctime":1584848287,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1584848287","product_id":100029201,"comment_content":"正设计一个系统，使用kafka作为临时性数据存储来使用。","like_count":0},{"had_liked":false,"id":185386,"user_name":"技术修行者","can_delete":false,"product_type":"c1","uid":1013147,"ip_address":"","ucode":"28CA41A1214D6B","user_header":"https://static001.geekbang.org/account/avatar/00/0f/75/9b/611e74ab.jpg","comment_is_top":false,"comment_ctime":1583571956,"is_pvip":true,"discussion_count":0,"race_medal":5,"score":"1583571956","product_id":100029201,"comment_content":"Kafka不仅是一个消息引擎，还是一个分布式流处理系统和分布式存储系统。","like_count":0},{"had_liked":false,"id":103164,"user_name":"Joypan","can_delete":false,"product_type":"c1","uid":1044182,"ip_address":"","ucode":"B7298241E7AAAF","user_header":"https://static001.geekbang.org/account/avatar/00/0f/ee/d6/a9b34bd3.jpg","comment_is_top":false,"comment_ctime":1560389274,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1560389274","product_id":100029201,"comment_content":"基本的运维kafka-manager","like_count":0},{"had_liked":false,"id":102514,"user_name":"风中花","can_delete":false,"product_type":"c1","uid":1085237,"ip_address":"","ucode":"067E0A1E116844","user_header":"https://static001.geekbang.org/account/avatar/00/10/8f/35/f1839bb2.jpg","comment_is_top":false,"comment_ctime":1560241553,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1560241553","product_id":100029201,"comment_content":"其实要学会是什么，最终得选择交给自己，掌握得知识广度和厚度来，做出更好的选择。 百花齐放 啊，，，，","like_count":0},{"had_liked":false,"id":102345,"user_name":"pepezzzz","can_delete":false,"product_type":"c1","uid":1143169,"ip_address":"","ucode":"414AD2DFD4BA1A","user_header":"https://static001.geekbang.org/account/avatar/00/11/71/81/4e47560f.jpg","comment_is_top":false,"comment_ctime":1560211144,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1560211144","product_id":100029201,"comment_content":"题外话 “唐尧虞舜”","like_count":0},{"had_liked":false,"id":101958,"user_name":"南山","can_delete":false,"product_type":"c1","uid":1119593,"ip_address":"","ucode":"94656FE4A6C378","user_header":"https://static001.geekbang.org/account/avatar/00/11/15/69/187b9968.jpg","comment_is_top":false,"comment_ctime":1560073538,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1560073538","product_id":100029201,"comment_content":"为中小型公司提供开箱即用的流处理平台，低成本，低学习曲线，支持与其他框架集成~~","like_count":0},{"had_liked":false,"id":101939,"user_name":"然行","can_delete":false,"product_type":"c1","uid":1103274,"ip_address":"","ucode":"3DF253F89B0B4A","user_header":"https://static001.geekbang.org/account/avatar/00/10/d5/aa/09581405.jpg","comment_is_top":false,"comment_ctime":1560063519,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1560063519","product_id":100029201,"comment_content":"我觉得kafka还有很多点需要优化，excatly once 的传输保障，消息的延迟问题，不确定问题，不稳定问题，都是金融级应用所不承受的问题，在高可用和性能之间的取舍和平衡","like_count":0},{"had_liked":false,"id":101868,"user_name":"明翼","can_delete":false,"product_type":"c1","uid":1068361,"ip_address":"","ucode":"E77F86BEB3D5C1","user_header":"https://static001.geekbang.org/account/avatar/00/10/4d/49/28e73b9c.jpg","comment_is_top":false,"comment_ctime":1560004450,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1560004450","product_id":100029201,"comment_content":"希望胡大神多讲点kafka的流计算的方面内容，我还是比较敢兴趣，像这种只有API实时流客户端的系统，整个处理流程如何，虽然以前看了些不完备，谢谢。","like_count":0},{"had_liked":false,"id":101817,"user_name":"jeffery","can_delete":false,"product_type":"c1","uid":1219972,"ip_address":"","ucode":"35E2DAA386FB86","user_header":"https://static001.geekbang.org/account/avatar/00/12/9d/84/171b2221.jpg","comment_is_top":false,"comment_ctime":1559982169,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1559982169","product_id":100029201,"comment_content":"整章介绍Kafka 是消息引擎系统，也是一个分布式流处理平台 是不是有点太奢华了！阿里的收购flink 必hot","like_count":0}]}