{"id":816765,"title":"04｜LLaMA 3的思考之道：思维链的源流与应用","content":"<p>你好，我是Tyler。</p><p>在上节课中，我们讨论了如何将大模型从传统的“对话框”应用场景中解放出来，通过指令和工具的使用，扩展其在实际应用中的能力。然而，即便如此，大模型在处理复杂任务时，仍然会出现力不从心的情况。面对长篇复杂的任务描述，模型往往会抓不住重点，甚至可能产生一些奇怪的错误，这在实际应用中显然是不可接受的。</p><p>那么，如何让大模型在处理复杂问题时更加得心应手？研究人员通过不断的探索，提出了一种名为<strong>思维链</strong>（Chain of Thought, CoT）的技术。它不仅能帮助模型更好地理解复杂问题，还能逐步推理出准确的答案。今天我将带你深入探讨思维链的概念、应用场景、技术实现及其在未来智能体应用中的潜力。</p><h2>什么是思维链？</h2><p>思维链，顾名思义，就是引导模型进行逐步推理的链条。通过分步骤思考，模型能够在复杂的任务中逐渐接近正确答案，避免因直接跳到结论而产生的错误。这种方法最初是由一句简单的提示语“Let’s think step by step”衍生出来的。这句提示语告诉模型：“我们一步一步来，别急。”这句话可以显著提高模型在处理复杂问题时的准确性。</p><p><img src=\"https://static001.geekbang.org/resource/image/14/52/14955c841ace33370ebfa0bc9241eb52.png?wh=940x473\" alt=\"图片\" title=\"图片来源于 https://arxiv.org/abs/2201.11903\"></p><p>在探讨思维链的过程中，我们需要思考一个重要的问题：所有的思维链是否都是链？实际上，思维链的灵活性和复杂性远不止于此。尽管“链”暗示了一个线性结构，但实际上，思维链可以表现为更加复杂的多步骤推理路径。这些路径有时可能是树状结构，有时则可能需要在多个平行的推理分支中进行选择和组合。因此，思维链的设计并非总是线性的，而是根据具体任务的复杂性和需求进行灵活调整。</p><!-- [[[read_end]]] --><p>思维链的核心在于逐步引导模型进行推理，而不是让它一次性得出结论。通过这一策略，模型在每个推理步骤中都需要认真思考，确保每一步都是逻辑严谨且正确的。这种方法不仅可以减少错误，还能帮助模型更好地理解问题的整体框架。</p><p>为了更直观地理解思维链，我们可以通过一个简单的例子来说明。假设我们让模型解决一个数学问题，直接问它“5 + 3 + 7等于多少？”模型通常可以直接给出正确答案。但是，如果问题更复杂，比如涉及多个步骤的推理，模型可能会出错。这时，如果我们在问题前加上“Let’s think step by step”，模型就会逐步进行解题，并最终得出正确答案。</p><h3>数学问题中的思维链</h3><pre><code class=\"language-python\">import ollama\n\ndef cot(problem):\n&nbsp; &nbsp; # 提示模型逐步思考\n&nbsp; &nbsp; prompt = f\"{problem} Let's think step by step.\"\n&nbsp; &nbsp; response = ollama.chat(model='llama3', messages=[\n&nbsp; &nbsp; &nbsp; &nbsp; {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 'role': 'user',\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 'content': prompt,\n&nbsp; &nbsp; &nbsp; &nbsp; },\n&nbsp; &nbsp; ])\n&nbsp; &nbsp; return response['content']\n\ndef solve_math_problem():\n&nbsp; &nbsp; problem = \"What is 5 + 3 + 7?\"\n&nbsp; &nbsp; result = cot(problem)\n&nbsp; &nbsp; return result\n\nresult = solve_math_problem()\nprint(result)\n</code></pre><p>在这个例子中，模型通过逐步计算，最终得出了正确的答案。这样的方式不仅能够让模型更好地理解问题，还能避免因为直接推理导致的错误。</p><h3>逻辑推理与任务规划中的应用</h3><p>思维链不仅适用于数学问题，还可以广泛应用于逻辑推理、复杂问答、任务规划等场景中。例如，在任务规划中，我们可以引导模型逐步拆解任务，并按照逻辑顺序完成每一步，从而保证任务的正确性和完整性。</p><p><img src=\"https://static001.geekbang.org/resource/image/ec/e4/ec02d4e08157ddfb07aa9142a49516e4.png?wh=1575x885\" alt=\"图片\" title=\"Introducing OpenAI o1-preview\"></p><p>比如我们看到的 GPT-4o1 中强大的推理能力，就是来自于思维链的赋能。它甚至已经能在信息学竞赛中超过人类的表现。</p><h3>复杂思维链的实际应用</h3><p>随着研究的深入，思维链技术已经从最初的提示语工程，逐渐发展成了一种广泛的多步骤推理方法。在更复杂的应用场景中，思维链不仅仅是一个提示语，而是一种多步骤推理的全新方法论。例如，在跨会话的多步骤推理中，模型需要在多个对话中逐步积累信息，并在最终的会话中得出综合性的结论。</p><p>以下是一个示例代码，其中设计了一系列精巧的问题，引导模型逐步推理并整合信息：</p><pre><code class=\"language-python\">import ollama\n\ndef cross_session_reasoning(session_data):\n&nbsp; &nbsp; accumulated_info = \"\"\n&nbsp; &nbsp; for session in session_data:\n&nbsp; &nbsp; &nbsp; &nbsp; prompt = f\"Based on our previous discussions: {accumulated_info} {session['question']}\"\n&nbsp; &nbsp; &nbsp; &nbsp; response = ollama.chat(model='llama3', messages=[\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {'role': 'user', 'content': prompt},\n&nbsp; &nbsp; &nbsp; &nbsp; ])\n&nbsp; &nbsp; &nbsp; &nbsp; accumulated_info += response['content'] + \" \"\n\n&nbsp; &nbsp; final_prompt = f\"Now, let's summarize the conclusion based on all the steps we've discussed: {accumulated_info.strip()}\"\n&nbsp; &nbsp; final_response = ollama.chat(model='llama3', messages=[\n&nbsp; &nbsp; &nbsp; &nbsp; {'role': 'user', 'content': final_prompt},\n&nbsp; &nbsp; ])\n&nbsp; &nbsp; return final_response['content']\n\nsession_data = [\n&nbsp; &nbsp; {\"question\": \"What foundational concepts should we consider when addressing problem X?\"},\n&nbsp; &nbsp; {\"question\": \"Based on those concepts, what is the initial action we should take to approach problem X?\"},\n&nbsp; &nbsp; {\"question\": \"What factors should we evaluate after the initial action to determine its effectiveness?\"},\n&nbsp; &nbsp; {\"question\": \"Considering the evaluation results, what would be the next logical step?\"},\n&nbsp; &nbsp; {\"question\": \"What potential challenges might arise from this next step, and how can we mitigate them?\"},\n&nbsp; &nbsp; {\"question\": \"Finally, how can we integrate all these steps to formulate a comprehensive solution to problem X?\"}\n]\n\nresult = cross_session_reasoning(session_data)\nprint(result)\n</code></pre><p>在这个例子中，模型在多个会话中逐步积累信息，最终得出一个全面的结论。这种方法能够确保复杂任务处理的连贯性和准确性。</p><h2>灵活性与安全性的平衡</h2><p>在处理复杂任务时，如何平衡模型的灵活性与推理过程的安全性，是一个不可忽视的重要问题。随着任务描述的复杂化，如果没有合适的推理策略，模型可能会忽略重要信息，导致出现幻觉，最终影响任务的处理质量。</p><h3>单一职责原则：分解任务，确保可控性</h3><p>为了应对这一挑战，我们引入了“单一职责原则”，这一原则要求将复杂任务分解为多个独立的步骤，每个步骤只负责解决特定的子问题。通过明确每个步骤的职责，模型能够更加专注，减少错误的发生，并提高整体任务的处理质量。</p><pre><code class=\"language-python\">import ollama\n\ndef decompose_task(task_description):\n&nbsp; &nbsp; # 假设这里有一个逻辑来分解任务\n&nbsp; &nbsp; return [\n&nbsp; &nbsp; &nbsp; &nbsp; {\"role\": \"analyst\", \"description\": \"analyze the data\"},\n&nbsp; &nbsp; &nbsp; &nbsp; {\"role\": \"developer\", \"description\": \"write the code\"},\n&nbsp; &nbsp; &nbsp; &nbsp; # 添加更多步骤...\n&nbsp; &nbsp; ]\n\ndef combine_results(results):\n&nbsp; &nbsp; # 假设这里有逻辑来组合结果\n&nbsp; &nbsp; return \" \".join(results)\n\ndef task_decomposition(task_description):\n&nbsp; &nbsp; steps = decompose_task(task_description)\n&nbsp; &nbsp; results = []\n&nbsp; &nbsp; for step in steps:\n&nbsp; &nbsp; &nbsp; &nbsp; # 每个步骤都有明确的职责和约束\n&nbsp; &nbsp; &nbsp; &nbsp; prompt = f\"As a {step['role']}, let's solve the specific part: {step['description']}\"\n&nbsp; &nbsp; &nbsp; &nbsp; response = ollama.chat(model='llama3', messages=[\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {'role': 'user', 'content': prompt},\n&nbsp; &nbsp; &nbsp; &nbsp; ])\n&nbsp; &nbsp; &nbsp; &nbsp; results.append(response['content'])\n\n&nbsp; &nbsp; # 综合所有步骤的结果，得出最终结论\n&nbsp; &nbsp; final_result = combine_results(results)\n&nbsp; &nbsp; return final_result\n\ntask_description = \"Complex task involving multiple roles and responsibilities.\"\nresult = task_decomposition(task_description)\nprint(result)\n</code></pre><p>在这个示例中，不同的角色设定帮助模型专注于特定任务，从而提高任务处理的质量和安全性。</p><h3>安全策略：引入检查机制</h3><p>为了进一步确保任务处理的安全性，我们还引入了<strong>检查机制</strong>。通过在每一个推理步骤后添加检查机制，可以验证模型的输出是否符合预期。这不仅能够及时发现并纠正错误，还能提高模型的整体推理质量。</p><pre><code class=\"language-python\">import ollama\n\ndef decompose_task(task_description):\n&nbsp; &nbsp; \"\"\"将任务描述分解为可操作的步骤\"\"\"\n&nbsp; &nbsp; prompt = f\"请将以下任务分解为具体的可操作步骤，并以编号的形式列出每个步骤：{task_description}\"\n&nbsp; &nbsp; response = ollama.chat(model='llama3', messages=[\n&nbsp; &nbsp; &nbsp; &nbsp; {'role': 'user', 'content': prompt},\n&nbsp; &nbsp; ])\n&nbsp; &nbsp; steps = response['content'].strip().split('\\n') if response['content'] else []\n&nbsp; &nbsp; return steps\n\ndef check_result(response):\n&nbsp; &nbsp; \"\"\"验证模型输出的合理性\"\"\"\n&nbsp; &nbsp; prompt = f\"以下响应是否存在安全隐患？{response} 请回答“是”或“否”。\"\n&nbsp; &nbsp; validation_response = ollama.chat(model='llama3', messages=[\n&nbsp; &nbsp; &nbsp; &nbsp; {'role': 'user', 'content': prompt},\n&nbsp; &nbsp; ])\n&nbsp; &nbsp; return \"是\" in validation_response['content']\n\ndef combine_results(results):\n&nbsp; &nbsp; \"\"\"综合所有有效结果\"\"\"\n&nbsp; &nbsp; if not results:\n&nbsp; &nbsp; &nbsp; &nbsp; return \"没有有效结果可供总结。\"\n&nbsp; &nbsp; prompt = \"请总结以下结果，并以段落形式呈现：\" + \"; \".join(results)&nbsp; # 使用分号分隔\n&nbsp; &nbsp; summary_response = ollama.chat(model='llama3', messages=[\n&nbsp; &nbsp; &nbsp; &nbsp; {'role': 'user', 'content': prompt},\n&nbsp; &nbsp; ])\n&nbsp; &nbsp; return summary_response['content']\n\ndef handle_error(step, response):\n&nbsp; &nbsp; \"\"\"处理错误情况\"\"\"\n&nbsp; &nbsp; print(f\"处理步骤时出错：{step}。响应：{response}\")&nbsp; # 可以增加更详细的错误处理\n\ndef reasoning_with_checkpoints(task_description):\n&nbsp; &nbsp; \"\"\"多步骤推理中的检查机制\"\"\"\n&nbsp; &nbsp; steps = decompose_task(task_description)&nbsp; # 将任务分解为多个步骤\n&nbsp; &nbsp; results = []\n&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; for step in steps:\n&nbsp; &nbsp; &nbsp; &nbsp; prompt = f\"让我们解决这个问题：{step.strip()} 请以清晰的步骤形式回答。\"\n&nbsp; &nbsp; &nbsp; &nbsp; response = ollama.chat(model='llama3', messages=[\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {'role': 'user', 'content': prompt},\n&nbsp; &nbsp; &nbsp; &nbsp; ])['content']&nbsp; # 生成模型响应\n\n&nbsp; &nbsp; &nbsp; &nbsp; # 检查输出有效性\n&nbsp; &nbsp; &nbsp; &nbsp; if check_result(response):\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; results.append(response)\n&nbsp; &nbsp; &nbsp; &nbsp; else:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; handle_error(step, response)&nbsp; # 处理错误情况\n\n&nbsp; &nbsp; return combine_results(results)&nbsp; # 返回综合结果\n\ntask_description = \"\"\"\n把大象放入冰箱\n\"\"\"\nresult = reasoning_with_checkpoints(task_description)\nprint(result)\n</code></pre><p>在这个例子中，检查机制确保每个推理步骤都符合预期，从而提高整体任务的安全性。</p><p><img src=\"https://static001.geekbang.org/resource/image/e8/55/e84e2ea7c021bcc69c8d043c45fcff55.png?wh=1887x1060\" alt=\"图片\"></p><p>进一步来说，如上图所示的一致性检测算法是一种更为高级的检测方法。它通过整合多条推理链的返回结果，综合评估后选出最优策略，从而提高检测的准确性和可靠性。</p><h2>为什么LLaMA模型适合做思维链？</h2><p>LLaMA模型在思维链推理中的出色表现，主要得益于其在指令微调和模型涌现能力方面的优化。</p><p>指令微调的优势：LLaMA 3模型通过大量的指令微调数据进行了训练。这些数据不仅包含传统的问答和对话任务，还包括复杂推理任务。在这些任务中，模型不仅要给出正确答案，还需要解释每一个推理步骤。这种训练方式让LLaMA 3在处理多步推理任务时表现得尤为出色。</p><p>模型的涌现能力：涌现能力是指随着模型规模和数据量的增加，模型自发产生的一些新能力。这些能力并没有被明确编码或设计出来，而是在模型训练过程中自然涌现的。对于思维链来说，LLaMA 3能够自发地进行更复杂的逻辑推理和任务规划，甚至在没有明确提示的情况下，也能展现出良好的推理能力。</p><p>代码数据的贡献：LLaMA 3在训练数据中包含了大量的代码数据。这使得模型在推理和规划任务中具有更强的结构化思维能力。代码数据的逻辑性和严格的语法规则，让模型在推理时能够更好地遵循逻辑步骤，避免无序推理。</p><h2>小结</h2><p>在上节课中，我们探讨了智能体工具使用的本质，即指令跟随能力。本节课的重点则是深入讨论智能体的“思考”能力，尤其是跨会话的多步推理。通过对思维链的深入探讨，我们了解到，这项技术不仅提升了模型的推理能力，还帮助模型更好地理解和处理复杂任务。</p><p>在本节课中，我们梳理了从思维链到多步推理，再到跨会话推理及智能体发展的技术脉络，这是专栏对智能体技术“祛魅”的第二步。我们通过逐步剖析，明确了实现智能体高效、准确任务执行的关键——跨会话的多步推理能力。</p><p>未来，随着技术的进一步发展，思维链将成为智能体不可或缺的一部分，为解决更复杂的任务提供强有力的支持。这节课的内容也将成为智能体状态机设计的重要前序知识。在接下来的课程中，我将详细讲解思维链在智能体架构设计中的实际应用，带你了解如何将这项技术集成到智能体中，从而增强其逻辑推理能力。</p><h2>思考题</h2><p>GPT-4o1 的能力和思维链之间的关系是什么？欢迎你把思考后的结果分享到留言区，和我一起讨论，如果你觉得这节课的内容对你有帮助的话，欢迎你分享给其他朋友，我们下节课再见！</p>","neighbors":{"left":{"article_title":"03｜LLaMA 3的应用探索：指令跟随的最佳实践","id":816759},"right":{"article_title":"05｜LLaMA 3如何通过提示词获得上下文学习能力？","id":818359}},"comments":[{"had_liked":false,"id":395935,"user_name":"小虎子🐯","can_delete":false,"product_type":"c1","uid":2843479,"ip_address":"北京","ucode":"4C9530B3FB407B","user_header":"https://static001.geekbang.org/account/avatar/00/2b/63/57/cba4c68b.jpg","comment_is_top":true,"comment_ctime":1732500636,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100828301,"comment_content":"课程代码地址：https:&#47;&#47;github.com&#47;tylerelyt&#47;LLaMa-in-Action","like_count":0},{"had_liked":false,"id":395177,"user_name":"兵戈","can_delete":false,"product_type":"c1","uid":1017595,"ip_address":"北京","ucode":"0F1723EBCE1BC0","user_header":"https://static001.geekbang.org/account/avatar/00/0f/86/fb/4add1a52.jpg","comment_is_top":false,"comment_ctime":1729664537,"is_pvip":false,"replies":[{"id":143536,"content":"你好，兵戈！代码已 merge，感谢你的贡献！也欢迎更多同学共建 GitHub repo 在练习中学习。","user_name":"作者回复","user_name_real":"编辑","uid":1002568,"ctime":1730470034,"ip_address":"北京","comment_id":395177,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100828301,"comment_content":"Tyler老师，学完了您《LLaMA 3 前沿模型实战课》的第4课，并跑通了其中的相关案例代码。\n\n但我看当前工程中还一直没有第4课的工程代码，于是我提交PR：https:&#47;&#47;github.com&#47;tylerelyt&#47;llama&#47;pull&#47;2\n\n您看看是否需要，可以Merge进来，或者直接上传您那边的工程代码：\n\n对应课程代码，有些地方稍作修改，使得能运行成功或者更顺畅：\n\n# 1、修改所有example中 response 的获取方式\nresponse[&#39;content&#39;] -&gt; response[&#39;message&#39;][&#39;content&#39;]\n\n# 2、example4 中添加step判断，减少循环次数\nif step == &#39;&#39;:\n    continue","like_count":3,"discussions":[{"author":{"id":1002568,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/4c/48/99de2a2b.jpg","nickname":"Tyler","note":"","ucode":"A657DD2FBAF31D","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":653245,"discussion_content":"你好，兵戈！代码已 merge，感谢你的贡献！也欢迎更多同学共建 GitHub repo 在练习中学习。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1730470034,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]}]}