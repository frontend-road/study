{"id":184042,"title":"30 | 备份与恢复操作","content":"<p><strong>课件和Demo地址</strong><br>\n<a href=\"https://gitee.com/geektime-geekbang/geektime-mongodb-course\">https://gitee.com/geektime-geekbang/geektime-mongodb-course</a></p>","comments":[{"had_liked":false,"id":173609,"user_name":"dream","can_delete":false,"product_type":"c3","uid":1117793,"ip_address":"","ucode":"65B33D32FA8BE9","user_header":"https://static001.geekbang.org/account/avatar/00/11/0e/61/ae68f8eb.jpg","comment_is_top":false,"comment_ctime":1579616014,"is_pvip":false,"replies":[{"id":67808,"content":"如果是一次性迁移，直接导出到CSV文件然后使用mongoimport命令。100MB或者几个T都是这样。\n\n如果是持续迁移，那需要一些专门的工具，比如说我们公司的tapdata产品。","user_name":"作者回复","user_name_real":"远航的TJ 唐建法","uid":1260017,"ctime":1580254939,"ip_address":"","comment_id":173609,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"老师，请问mysql中的数据怎么迁移到mongodb呢？对于少量数据(100m内) 和 大量数据(几个T) 的处理方式分别是什么呢？\n","like_count":3,"discussions":[{"author":{"id":1260017,"avatar":"https://static001.geekbang.org/account/avatar/00/13/39/f1/6d18a4d1.jpg","nickname":"远航的TJ 唐建法","note":"","ucode":"0719807390250A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":482134,"discussion_content":"如果是一次性迁移，直接导出到CSV文件然后使用mongoimport命令。100MB或者几个T都是这样。\n\n如果是持续迁移，那需要一些专门的工具，比如说我们公司的tapdata产品。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1580254939,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":167988,"user_name":"撑伞也是雨中人。","can_delete":false,"product_type":"c3","uid":1610634,"ip_address":"","ucode":"743F23626ACF53","user_header":"https://static001.geekbang.org/account/avatar/00/18/93/8a/2b78f44d.jpg","comment_is_top":false,"comment_ctime":1577972725,"is_pvip":false,"replies":[{"id":65262,"content":"停掉均衡以后，备份可以保证每个节点各自是准确的。但是各个节点之间时间点很难保证在同一点上，所以每个节点恢复以后那个状态不是完全同步的。这个没有致命风险，但是确实有数据不一致的可能性。如果要做到完全一致，需要使用MongoDB 企业版 Ops Manager的分片备份功能。","user_name":"作者回复","user_name_real":"远航的TJ 唐建法","uid":1260017,"ctime":1578010016,"ip_address":"","comment_id":167988,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"老师 分片集群具体如何实施备份？  停掉均衡器之后，各个节点通过定时任务备份（各个机器启动备份时间点是否能够绝对一致，如果备份时间点存在几秒的差别，是否有致命风险？）","like_count":2,"discussions":[{"author":{"id":1260017,"avatar":"https://static001.geekbang.org/account/avatar/00/13/39/f1/6d18a4d1.jpg","nickname":"远航的TJ 唐建法","note":"","ucode":"0719807390250A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":480088,"discussion_content":"停掉均衡以后，备份可以保证每个节点各自是准确的。但是各个节点之间时间点很难保证在同一点上，所以每个节点恢复以后那个状态不是完全同步的。这个没有致命风险，但是确实有数据不一致的可能性。如果要做到完全一致，需要使用MongoDB 企业版 Ops Manager的分片备份功能。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1578010016,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":248059,"user_name":"Mr.zhou","can_delete":false,"product_type":"c3","uid":1461488,"ip_address":"","ucode":"F7B2365D183788","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83ep0Cb1HGLBTD57I53ZLsIBnvN3YkJOTkibWyibPoCUM5cbnhqDicm1aKWTUFeI7SEd8REnibfZVWeM3BQ/132","comment_is_top":false,"comment_ctime":1599996253,"is_pvip":false,"replies":[{"id":91324,"content":"这个方法可以做备份，但是不是最严格的。严格的备份能够提供指定时间点的恢复。比如说，如果你发现13：01分的时候有个误删操作，使用好的分片备份机制，可以恢复到13：00的准确状态。而通过mongodump是没有这种保障机制的。","user_name":"作者回复","user_name_real":"远航的TJ 唐建法","uid":1260017,"ctime":1600309400,"ip_address":"","comment_id":248059,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"老师，有一个问题不明白。为什么需要分片集备份？通过 mongodump 连接到mongos上不就能对集群进行备份吗？比如这命令：.&#47;mongodump --host IP地址:27017 --username=用户名 --password=密码 --authenticationDatabase=admin --db=bim --collection=processTask --out=&#47;data&#47;20200901\n不就能对bim数据库下的processTask进行全量备份嘛？我们的集群是有两个shard，每一个shard有3个复制集的集群","like_count":0,"discussions":[{"author":{"id":1260017,"avatar":"https://static001.geekbang.org/account/avatar/00/13/39/f1/6d18a4d1.jpg","nickname":"远航的TJ 唐建法","note":"","ucode":"0719807390250A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":505558,"discussion_content":"这个方法可以做备份，但是不是最严格的。严格的备份能够提供指定时间点的恢复。比如说，如果你发现13：01分的时候有个误删操作，使用好的分片备份机制，可以恢复到13：00的准确状态。而通过mongodump是没有这种保障机制的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1600309400,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":247282,"user_name":"book尾汁","can_delete":false,"product_type":"c3","uid":1446375,"ip_address":"","ucode":"AE2B8DFC643ACC","user_header":"https://static001.geekbang.org/account/avatar/00/16/11/e7/044a9a6c.jpg","comment_is_top":false,"comment_ctime":1599647040,"is_pvip":false,"replies":[{"id":91326,"content":"可以通过历史数据备份+oplog 重放来恢复，抱歉回复完了。","user_name":"作者回复","user_name_real":"远航的TJ 唐建法","uid":1260017,"ctime":1600309751,"ip_address":"","comment_id":247282,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"老师请教下，我们的生产环境近几日有些数据删掉了，看还在oplog的覆盖范围内，但是我们之前没做过全量备份，这个有什么办法可以恢复吗","like_count":0,"discussions":[{"author":{"id":1260017,"avatar":"https://static001.geekbang.org/account/avatar/00/13/39/f1/6d18a4d1.jpg","nickname":"远航的TJ 唐建法","note":"","ucode":"0719807390250A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":505364,"discussion_content":"可以通过历史数据备份+oplog 重放来恢复，抱歉回复完了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1600309751,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1446375,"avatar":"https://static001.geekbang.org/account/avatar/00/16/11/e7/044a9a6c.jpg","nickname":"book尾汁","note":"","ucode":"AE2B8DFC643ACC","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":306693,"discussion_content":"已经恢复了，通过之前掉线的一个节点 的全量数据大概到今年6月份，又通过oplog重放了几天的日志，还是缺了几个月的数据，还可以接受，\n另外再问老师两个问题，有密码认证的情况下怎么将新的机器加入进来，目前我是先关闭认证然后加入集群的。\n还有就是今天我在做复制集群的时候，就是用add的方式一台台加入的，当我加入成功了一台新机器以后，我在新机器上执行rs.init初始化集群这个命令，原来的主的机器变成从了，而新加入的机器变成主了，但是因为原来的主服务器是有密码的，所以新的主连不上原来的服务器，这种情况该怎么做，目前打算先把原来有数据的主库变成单实例的，然后删除local库重新初始化，以非认证模式启动，重新配置集群，老师有什么更好的方法吗","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1600350117,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":186939,"user_name":"阿丽","can_delete":false,"product_type":"c3","uid":1170970,"ip_address":"","ucode":"C01D32E7165302","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erJFlHhylrbLANtehiaX50wgVa2Z1ibQAdLpgyW4gCpEyOKEI9bPNZZBiabrP2oCleZWc2KKyKADz8tg/132","comment_is_top":false,"comment_ctime":1583977007,"is_pvip":false,"replies":[{"id":72142,"content":"dump的话单独备份是不需要的。除非你另有别的用途","user_name":"作者回复","user_name_real":"远航的TJ 唐建法","uid":1260017,"ctime":1584001736,"ip_address":"","comment_id":186939,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"老师，除了dump时指定oplog，是不是oplog也要单独备份呢？","like_count":0,"discussions":[{"author":{"id":1260017,"avatar":"https://static001.geekbang.org/account/avatar/00/13/39/f1/6d18a4d1.jpg","nickname":"远航的TJ 唐建法","note":"","ucode":"0719807390250A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":486927,"discussion_content":"dump的话单独备份是不需要的。除非你另有别的用途","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1584001736,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1170970,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erJFlHhylrbLANtehiaX50wgVa2Z1ibQAdLpgyW4gCpEyOKEI9bPNZZBiabrP2oCleZWc2KKyKADz8tg/132","nickname":"阿丽","note":"","ucode":"C01D32E7165302","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":203125,"discussion_content":"因为oplog会被覆盖，而我们有可能恢复到一天的任意时间点","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1584001959,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":173327,"user_name":"Geek_f7ecaa","can_delete":false,"product_type":"c3","uid":1476575,"ip_address":"","ucode":"0D5375FA7537D1","user_header":"","comment_is_top":false,"comment_ctime":1579505352,"is_pvip":false,"replies":[{"id":67874,"content":"你是如何在查询和分析，可以稍微明确一些吗？","user_name":"作者回复","user_name_real":"远航的TJ 唐建法","uid":1260017,"ctime":1580285104,"ip_address":"","comment_id":173327,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"在遇到误删除数据需要恢复的到删除时间点的数据时，需要通过OPLOG先找到误操作的时间点，但往往遇到因为oplog往往比较大（生产环境几十、上百G），导致查询和分析OPLOG很慢，恢复效率较低，有没有更高效一些的恢复方法？","like_count":0,"discussions":[{"author":{"id":1260017,"avatar":"https://static001.geekbang.org/account/avatar/00/13/39/f1/6d18a4d1.jpg","nickname":"远航的TJ 唐建法","note":"","ucode":"0719807390250A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":482039,"discussion_content":"你是如何在查询和分析，可以稍微明确一些吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1580285104,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":170845,"user_name":"齐宝金","can_delete":false,"product_type":"c3","uid":1305074,"ip_address":"","ucode":"F783442C82FCC2","user_header":"https://static001.geekbang.org/account/avatar/00/13/e9/f2/9067371a.jpg","comment_is_top":false,"comment_ctime":1578738330,"is_pvip":false,"replies":[{"id":66767,"content":"可以的，大致步骤是：\n\n1）用snapshot或者关机复制文件方式进行全量备份\n\n2）使用mongodump 备份 oplog 库\n\n3）恢复全量备份\n\n4） 使用 mongorestore 的 --oplogFile --oplogLimit 参数来恢复指定的oplog 时间点\n\n可以参考下面这个英文博客\nhttps:&#47;&#47;alexmarquardt.com&#47;2017&#47;01&#47;25&#47;mongodb-point-in-time-restore&#47;\n","user_name":"作者回复","user_name_real":"远航的TJ 唐建法","uid":1260017,"ctime":1579131918,"ip_address":"","comment_id":170845,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"请问下老师，副本集集群有通过物理备份+oplog实现任意点的恢复吗，就是类似mysql的innobackupex+binlog的方式，有可参照的案例吗","like_count":0,"discussions":[{"author":{"id":1260017,"avatar":"https://static001.geekbang.org/account/avatar/00/13/39/f1/6d18a4d1.jpg","nickname":"远航的TJ 唐建法","note":"","ucode":"0719807390250A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":481134,"discussion_content":"可以的，大致步骤是：\n\n1）用snapshot或者关机复制文件方式进行全量备份\n\n2）使用mongodump 备份 oplog 库\n\n3）恢复全量备份\n\n4） 使用 mongorestore 的 --oplogFile --oplogLimit 参数来恢复指定的oplog 时间点\n\n可以参考下面这个英文博客\nhttps://alexmarquardt.com/2017/01/25/mongodb-point-in-time-restore/\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1579131918,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3031770,"avatar":"","nickname":"Geek_b357a7","note":"","ucode":"41C61850FC98E5","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":580488,"discussion_content":"老师，我想请教一下，我全量恢复完毕，恢复oplog的部分，他总是报错E11000 duplicate key error collection 说和之前的数据id重复怎么办么~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1658212290,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":170312,"user_name":"癫狂的小兵","can_delete":false,"product_type":"c3","uid":1018069,"ip_address":"","ucode":"77AB0E7A21CEF9","user_header":"https://static001.geekbang.org/account/avatar/00/0f/88/d5/1e8fccab.jpg","comment_is_top":false,"comment_ctime":1578565796,"is_pvip":false,"replies":[{"id":66105,"content":"如果两个情况下，你的请求量是完全一样的，比如说，同样的请求，查的是同一个集合，一样的并发，那么影响不大，因为其他集合的数据只是在硬盘上，不会被调用到内存里。如果你对其他9个集合也有访问，那性能自然就不相同了。","user_name":"作者回复","user_name_real":"远航的TJ 唐建法","uid":1260017,"ctime":1578638173,"ip_address":"","comment_id":170312,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"唐老师你好，想问一个问题。对于单个实例的mongodb, 假设条件1：数据库有10个集合，每个集合的文档数是1亿条记录和假设条件2：数据库只有1个集合,同样拥有1亿条记录，那么对于同样数量级的访问请求 这两个假设条件下性能是否会有不同，影响有多大呢？  问题主要是想知道，同一实例下，大集合之间会不会有互相影响(不存在聚合查询, 各查各的)  ","like_count":0,"discussions":[{"author":{"id":1260017,"avatar":"https://static001.geekbang.org/account/avatar/00/13/39/f1/6d18a4d1.jpg","nickname":"远航的TJ 唐建法","note":"","ucode":"0719807390250A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":480934,"discussion_content":"如果两个情况下，你的请求量是完全一样的，比如说，同样的请求，查的是同一个集合，一样的并发，那么影响不大，因为其他集合的数据只是在硬盘上，不会被调用到内存里。如果你对其他9个集合也有访问，那性能自然就不相同了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1578638173,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":169909,"user_name":"鲨无赦","can_delete":false,"product_type":"c3","uid":1266727,"ip_address":"","ucode":"3072D8198C9CDD","user_header":"https://static001.geekbang.org/account/avatar/00/13/54/27/05df800c.jpg","comment_is_top":false,"comment_ctime":1578470806,"is_pvip":false,"replies":[{"id":66206,"content":"1） 应该先修复副本集再做删除动作，可以删掉坏掉的那个节点的数据，让它自动恢复数据。\n\n2） 这个要看mongoshake团队，有个钉钉群，你可以搜一下加群问。","user_name":"作者回复","user_name_real":"远航的TJ 唐建法","uid":1260017,"ctime":1578746593,"ip_address":"","comment_id":169909,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"唐老师好，问2个问题：\n1、分片集群下的副本集只有2台机器，一次意外断电导致其中一台系统启动不了，这个副本集也就坏了，如果强制把它从分片集群理彻底删除，现在一直处理【&quot;draining&quot; : true】。\n\n2、用MongoShake从A副本集同步数据到B副本集报错【Size must be between 0 and 16793600(16MB) First element】，2个副本集配置和参数都一样，那报错的这个文档为什么在A副本集写入是成功？","like_count":0,"discussions":[{"author":{"id":1260017,"avatar":"https://static001.geekbang.org/account/avatar/00/13/39/f1/6d18a4d1.jpg","nickname":"远航的TJ 唐建法","note":"","ucode":"0719807390250A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":480768,"discussion_content":"1） 应该先修复副本集再做删除动作，可以删掉坏掉的那个节点的数据，让它自动恢复数据。\n\n2） 这个要看mongoshake团队，有个钉钉群，你可以搜一下加群问。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1578746593,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":168950,"user_name":"qbit","can_delete":false,"product_type":"c3","uid":1262927,"ip_address":"","ucode":"96C70A1E47B93D","user_header":"https://static001.geekbang.org/account/avatar/00/13/45/4f/f94caf47.jpg","comment_is_top":false,"comment_ctime":1578223819,"is_pvip":false,"replies":[{"id":66771,"content":"这两种方式比较简单，一个是复制文件，一个是操作系统命令，就没有特别讲了。","user_name":"作者回复","user_name_real":"远航的TJ 唐建法","uid":1260017,"ctime":1579132416,"ip_address":"","comment_id":168950,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"另外两种全量备份方式（文件复制、文件快照）后面会讲到吗？","like_count":0,"discussions":[{"author":{"id":1260017,"avatar":"https://static001.geekbang.org/account/avatar/00/13/39/f1/6d18a4d1.jpg","nickname":"远航的TJ 唐建法","note":"","ucode":"0719807390250A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":480384,"discussion_content":"这两种方式比较简单，一个是复制文件，一个是操作系统命令，就没有特别讲了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1579132416,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":362297,"user_name":"wljs","can_delete":false,"product_type":"c3","uid":1306543,"ip_address":"广东","ucode":"6B88A664972AD2","user_header":"https://static001.geekbang.org/account/avatar/00/13/ef/af/adce8c49.jpg","comment_is_top":false,"comment_ctime":1668397859,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100040001,"comment_content":"唐建法老师，请问一下，有关于mongoDB的开发 规范吗？","like_count":0},{"had_liked":false,"id":324467,"user_name":"Leo","can_delete":false,"product_type":"c3","uid":1313963,"ip_address":"","ucode":"E0E655D048824A","user_header":"https://static001.geekbang.org/account/avatar/00/14/0c/ab/cfbf16e4.jpg","comment_is_top":false,"comment_ctime":1638447144,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100040001,"comment_content":"请问mongodb的数据同步，如果是删除操作，oplog中的记录是只有objectid信息么，有什么办法可以从oplog的删除记录中获知具体删除的数据信息，即除了objectid外，还可以获取对应记录的其它key信息，以便用于更新被同步侧服务的缓存么，谢谢！","like_count":0},{"had_liked":false,"id":284560,"user_name":"Geek_fa2d08","can_delete":false,"product_type":"c3","uid":2417280,"ip_address":"","ucode":"CFFB39182B1079","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epAKicFAuQALxybmuUuK0FiczXObJvwVXCfmqScRNAk3RD4Vp9MLlOvkSgRzn3qhicA6JpmSvIHAzA4w/132","comment_is_top":false,"comment_ctime":1616336984,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100040001,"comment_content":"老师，您好，如果备份的数据很大的话，在使用mongorestore时，会超出内存大小而导致恢复中断，有好的解决办法吗？我没看到有相关的参数可以配置","like_count":0},{"had_liked":false,"id":231134,"user_name":"GeekLi","can_delete":false,"product_type":"c3","uid":2049635,"ip_address":"","ucode":"1D9E9F3439B87A","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/yib4NPWzs5g36icOuVviaUtOYEXo5iaDicsCPpILyvRaoBj7FwibPu43aKNQBXZh7qK4Dv0jZSvsC8F9ibrZ7a5LKNhjg/132","comment_is_top":false,"comment_ctime":1593591047,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100040001,"comment_content":"老师，我有一个困惑mongodump数据备份了以后下一次在同样的目录下加上--oplog参数备份是增量备份吗？我想要的备份效果是这样的：首次全量数据备份，然后每次在固定时间增量将这段时间多出来的数据备份到第一次备份的目录中（备份过程中的oplog每次备份时候都是增量增加的吗？），等到需要的时候将其恢复（热备份，数据一直在增加）","like_count":0},{"had_liked":false,"id":225880,"user_name":"扬一场远远的风","can_delete":false,"product_type":"c3","uid":1357801,"ip_address":"","ucode":"AB47E3D2EAB8A8","user_header":"https://static001.geekbang.org/account/avatar/00/14/b7/e9/5400cdf3.jpg","comment_is_top":false,"comment_ctime":1591882086,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100040001,"comment_content":"如果对分片集群中某个库做快照（相当于备份成另一个库），请问有什么好的办法吗？","like_count":0},{"had_liked":false,"id":168302,"user_name":"cheriston","can_delete":false,"product_type":"c3","uid":1309984,"ip_address":"","ucode":"617CBFCE0925C4","user_header":"https://static001.geekbang.org/account/avatar/00/13/fd/20/2761ef0e.jpg","comment_is_top":false,"comment_ctime":1578044008,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":3,"product_id":100040001,"comment_content":"[root@server22 ~]# mongorestore --host 192.168.127.22:27017 --oplogReplay\n2020-01-03T17:31:36.817+0800\tusing default &#39;dump&#39; directory\n2020-01-03T17:31:36.817+0800\tpreparing collections to restore from\n2020-01-03T17:31:36.818+0800\treading metadata for test.random from dump&#47;test&#47;random.metadata.json\n2020-01-03T17:31:36.819+0800\trestoring to existing collection config.cache.chunks.test.random without dropping\n2020-01-03T17:31:36.819+0800\treading metadata for config.cache.chunks.test.random from dump&#47;config&#47;cache.chunks.test.random.metadata.json\n2020-01-03T17:31:36.819+0800\trestoring config.cache.chunks.test.random from dump&#47;config&#47;cache.chunks.test.random.bson\n2020-01-03T17:31:36.819+0800\trestoring to existing collection config.cache.databases without dropping\n2020-01-03T17:31:36.819+0800\treading metadata for config.cache.databases from dump&#47;config&#47;cache.databases.metadata.json\n2020-01-03T17:31:36.819+0800\trestoring to existing collection config.cache.collections without dropping\n2020-01-03T17:31:36.819+0800\treading metadata for config.cache.collections from dump&#47;config&#47;cache.collections.metadata.json\n2020-01-03T17:31:36.820+0800\trestoring config.cache.databases from dump&#47;config&#47;cache.databases.bson\n2020-01-03T17:31:36.821+0800\tfinished restoring test.random (0 documents, 0 failures)\n2020-01-03T17:31:36.821+0800\trestoring config.cache.collections from dump&#47;config&#47;cache.collections.bson\n2020-01-03T17:31:36.821+0800\tfinished restoring config.cache.chunks.test.random (0 documents, 0 failures)\n2020-01-03T17:31:36.822+0800\tterminating read on config.cache.databases\n2020-01-03T17:31:36.822+0800\tfinished restoring config.cache.databases (0 documents, 0 failures)\n2020-01-03T17:31:36.822+0800\tterminating read on config.cache.collections\npanic: close of closed channel","like_count":0,"discussions":[{"author":{"id":1309984,"avatar":"https://static001.geekbang.org/account/avatar/00/13/fd/20/2761ef0e.jpg","nickname":"cheriston","note":"","ucode":"617CBFCE0925C4","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":116842,"discussion_content":"老师这是什么错误","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1578066160,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}