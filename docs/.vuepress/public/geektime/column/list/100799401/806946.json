{"id":806946,"title":"12｜表太大了，修改表结构太慢怎么解决？（下）","content":"<p>你好，我是俊达。</p><p>在上一讲中，我们介绍了几种执行很快的DDL操作，这些DDL操作只需要修改元数据，因此即使表很大，也不影响执行速度。但是还有很多DDL操作，在执行的过程中需要读取全表的数据，或者是重建整个表，因此表的大小会直接影响执行的速度。这一讲中，我们就来看看这些DDL的执行策略。</p><h2>InnoDB在线DDL</h2><p>添加字段、删除字段可以使用Instant DDL，但是还有其他很多DDL并不能仅仅修改元数据。比如创建索引时，需要读取全表的数据，对索引字段进行排序，生成新的索引。优化表（optimize table）时，需要重建整个表的数据。MySQL从5.6开始支持在线DDL。在线DDL的主要含义，是指在DDL执行的期间，应用程序可以正常地读写表中的数据。对于只需要修改元数据的DDL，前面已经做了比较多的介绍了，这里我们只讨论创建索引和需要重建表的在线DDL。</p><h3>创建二级索引</h3><p>创建二级索引可以使用INPLACE的方式执行。这里只讨论普通的B+树索引，不讨论全文索引、空间索引。下面的这个例子中，我们使用ALTER TABLE命令新建了一个索引。</p><pre><code class=\"language-go\">mysql&gt; alter table employees \n    add key idx_firstname_lastname(first_name, last_name), \n    algorithm=inplace, \n    lock=none;\n\nQuery OK, 0 rows affected (0.73 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\n</code></pre><!-- [[[read_end]]] --><p>创建二级索引主要分为几个步骤。</p><p><strong>1.  扫描整个表，读取新建索引需要的字段。</strong></p><p>InnoDB可以使用多个线程并发读取聚簇索引，参数innodb_parallel_read_threads用来设置并发读取的线程数，默认值是4。如果表比较大，服务器的配置比较好，可以将这个参数设置得大一些，来提升读取的速度。读取到的数据会先写到一块临时的内存中，参数innodb_ddl_buffer_size用来控制这块临时内存的大小，最终临时内存中的数据会写到临时排序文件中。如果你的表比较大，临时文件也可能占用比较大的空间。</p><p><strong>2. 合并排序步骤1生成的多个临时文件中的数据。</strong></p><p>如果步骤1使用了多个线程，那么每个线程都会生成临时排序文件。步骤2需要将所有临时文件中的数据合并到一起。合并排序时，InnoDB也使用了多个线程，线程的数量由参数innodb_ddl_threads控制。</p><p><strong>3. 将步骤2得到的数据加载到新建的索引中。</strong></p><p>步骤2得到的数据已经按索引字段排序好了，这里需要将这些数据插入到新的索引中。</p><p>前面这3个步骤在执行的过程中，其他会话还可以正常读取和修改表里面的数据。InnoDB需要将这期间修改过的数据记录下来，数据会先写入到一块临时的内存中，这块临时内存的大小由参数innodb_sort_buffer_size控制。最终这些数据会写到一个临时文件中，我们把这个临时文件称为在线变更日志。如果在创建索引的过程中，表中的数据变更特别频繁，那么在线变更日志中就要记录很多数据，参数innodb_online_alter_log_max_size限制了在线变更日志的大小，如果期间产生的变更日志超过了这个限制，DDL最终会失败。</p><p><strong>4. 将在线变更日志中的数据更新到索引中。</strong></p><p>为了保障索引数据和表中数据的一致性，步骤3执行完成后，InnoDB需要将在线变更日志中的数据更新到索引结构中。这个过程中，需要锁定新创建的这个索引，因此，其他会话插入新的数据，或者更新这个新创建的索引中包含的字段时，都会被阻塞。</p><p>处理在线变更日志中的数据时，可能会遇到几个问题。</p><p>如果创建索引的过程中发生变化的数据太多，超过了innodb_online_alter_log_max_size的限制，那么DDL最后会报DB_ONLINE_LOG_TOO_BIG的错误。如果新创建的是唯一索引，那么如果在线变更日志中如果有数据违反了唯一性约束，DDL也会失败。</p><p>下面我通过一个例子来说明这种情况。</p><p>我们在会话1中创建一个唯一索引。此时表中这几个字段的数据是唯一的。</p><pre><code class=\"language-go\">alter table employees add unique key \n    uk_x(first_name, last_name, birth_date, hire_date);\n</code></pre><p>在索引创建的过程中，我们在另外一个会话中执行下面这几个SQL。因为新的唯一索引还没有创建好，所以这些INSERT语句可以正常执行。</p><pre><code class=\"language-go\">mysql&gt; insert into employees values\n    (10, '2013-10-10', 'AAAA', 'BBBB', 'M', '2020-10-01');\n\nQuery OK, 1 row affected (5.05 sec)\n\nmysql&gt; insert into employees values\n    (20, '2013-10-10', 'AAAA', 'BBBB', 'M', '2020-10-01');\n\nQuery OK, 1 row affected (5.45 sec)\n\nmysql&gt; insert into employees values\n    (30, '2013-10-10', 'AAAA', 'BBBB', 'M', '2020-10-01');\n\nQuery OK, 1 row affected (2.10 sec)\n\nmysql&gt; delete from employees where emp_no in (10,30);\nQuery OK, 2 rows affected (0.90 sec)\n</code></pre><p>当会话1完成新索引的创建，在处理在线变更日志中的数据时，发生了数据冲突，因此DDL最终失败了。</p><pre><code class=\"language-go\">mysql&gt; alter table employees add unique key uk_x(first_name, last_name, birth_date, hire_date);\n\nERROR 1062 (23000): Duplicate entry 'AAAA-BBBB-2013-10-10-2020-10-01' for key 'employees.uk_x'\n</code></pre><h3>需要重建表的在线DDL</h3><p>还有一些DDL操作，虽然能以INPLACE的方式执行，但是在执行过程中需要重建表，因此开销也是比较大的。</p><p>创建主键、修改主键这几个操作都需要重建表。这一点很容易理解，因为InnoDB表以聚簇索引的方式组织数据，主键变了，数据的物理格式就会发生变化。下面是一个修改主键的例子。</p><pre><code class=\"language-go\">mysql&gt; alter table employees_bak \n    drop primary key, \n    add primary key(emp_no, last_name, first_name), \n    algorithm=inplace;\n\nQuery OK, 0 rows affected (46.97 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\n</code></pre><p>修改字段的顺序和NOT NULL属性也需要重建表。这几个操作会改变行的存储格式，因此也需要重建表。下面这个例子中，将字段first_name移到了第1列。当然，我们一般应该不太会特意去修改表的字段顺序。</p><pre><code class=\"language-go\">mysql&gt; desc employees_bak;\n+------------+---------------+------+-----+---------+-------+\n| Field      | Type          | Null | Key | Default | Extra |\n+------------+---------------+------+-----+---------+-------+\n| first_name | varchar(14)   | NO   | PRI | NULL    |       |\n| emp_no     | int           | NO   | PRI | NULL    |       |\n| birth_date | date          | NO   |     | NULL    |       |\n| last_name  | varchar(16)   | NO   | PRI | NULL    |       |\n| gender     | enum('M','F') | NO   |     | NULL    |       |\n| hire_date  | date          | YES  |     | NULL    |       |\n+------------+---------------+------+-----+---------+-------+\n\nmysql&gt; alter table employees_bak \n    modify first_name varchar(14) not null first, \n    algorithm=inplace;\n\nQuery OK, 0 rows affected (41.22 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\n</code></pre><p>另外，优化表、修改表的行格式或key_block_size属性也都需要重建表。</p><p>使用optimize table命令优化表。</p><pre><code class=\"language-go\">mysql&gt; optimize table employees_bak;\n+-------------------------+----------+----------+-------------------------------------------------------------------+\n| Table                   | Op       | Msg_type | Msg_text                                                          |\n+-------------------------+----------+----------+-------------------------------------------------------------------+\n| employees.employees_bak | optimize | note     | Table does not support optimize, doing recreate + analyze instead |\n| employees.employees_bak | optimize | status   | OK                                                                |\n+-------------------------+----------+----------+-------------------------------------------------------------------+\n2 rows in set (42.58 sec)\n</code></pre><p>optimize table命令的语法中，不支持algorithm关键字，但是实际上优化表是做了一次在线的表重建。和下面这个命令的效果类似。</p><pre><code class=\"language-go\">mysql&gt; alter table employees_bak engine=innodb, algorithm=inplace, lock=none;\nQuery OK, 0 rows affected (45.60 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\n</code></pre><p>InnoDB重建表的时候，需要将整个表的数据写到一个临时的ibd文件中，这个临时文件和表的ibd文件放在同一个目录下，文件名以 “#sql-ib” 开头，在重建表的过程中，你可以在数据目录中看到这个文件。</p><pre><code class=\"language-go\"># ls -lrt /data/mysql01/data/employees\n......\n-rw-r----- 1 mysql mysql  37748736 8月   3 16:08 employees.ibd\n-rw-r----- 1 mysql mysql   7340032 8月   3 16:28 #sql-ib1396-1337919602.ibd\n</code></pre><p>表中的二级索引，也需要加载到新生成的这个ibd文件中。</p><p>和在线创建二级索引类似，重建表的过程中，其他会话可以正常读写表中的数据。这个过程中，如果表中的记录被修改了，需要将修改的数据记录到在线变更日志中。</p><p>当聚簇索引和二级索引的数据全部都写到新的ibd文件中后，需要将在线变更日志中的数据更新到新的ibd文件中，这个过程中，会先锁定老的聚簇索引。因此，在应用在线变更日志时，应用程序无法读写表的数据，注意，这个过程中连查询都会被阻塞。</p><p>如果在重建表的过程中，修改的数据超过了innodb_online_alter_log_max_size的限制，DDL最终会失败。你可以增加innodb_online_alter_log_max_size，但是，这同时也可能会导致应用在线变更日志的时间变长，因此会增加锁表的时间。</p><p>在线变更日志应用完成之后，InnoDB删除老的ibd文件，修改新创建的ibd文件，并在元数据中记录这些操作。</p><h3>在线DDL小结</h3><p>在线DDL是MySQL为了增加数据库可维护性引入的一个很有用的特性。你可以适当地调大innodb_parallel_read_threads、innodb_ddl_threads、innodb_ddl_buffer_size、innodb_sort_buffer_size等参数，以加快DDL的执行效率，当然前提是服务器的性能要跟得上。</p><p>在线DDL的执行过程中，需要占用一些额外的空间，包括临时排序文件，在线变更日志文件，以及临时的ibd文件。临时排序文件默认存放在tmpdir下，如果tmpdir空间紧张，你也可以设置参数innodb_tmpdir，将这些文件放到一个空间足够大的目录下。你可以根据表ibd文件当前的大小来估算临时排序文件和临时ibd文件需要的空间。</p><p>虽然在线DDL极大地减少了锁表的时间，但是在应用在线变更日志时，还是会将表或二级索引锁住，因此应用程序还是会有影响的，锁的时间取决于表的大小以及和DDL期间发生变化的数据量有关。</p><p>InnoDB在线变更日志按innodb_sort_buffer_size的设置，分为多个块。在应用在线变更日志时，如果是在应用最后一个日志块中的记录，需要获取主键或索引的锁。</p><p><img src=\"https://static001.geekbang.org/resource/image/a1/0d/a14d78989f67a7117c0f7f506e41yy0d.png?wh=1406x408\" alt=\"\"></p><p>如果你的表特别大，并且表中数据的修改非常频繁，InnoDB原生的在线DDL并不一定能满足你的需求。</p><h2>不支持在线执行的DDL</h2><p>虽然MySQL增加了在线DDL的能力，但还是存在一些情况无法使用在线DDL，执行这些DDL时，需要使用MySQL最原始的COPY方式，先创建一个临时表，再锁住源表，将源表的记录插入到临时表，最后，当数据复制完成后，将临时表改为正式表。</p><p>下面这些操作都不支持在线DDL。</p><ul>\n<li>删除表的主键。</li>\n</ul><pre><code class=\"language-go\">mysql&gt; alter table salaries drop primary key, algorithm=inplace;\nERROR 1846 (0A000): ALGORITHM=INPLACE is not supported. Reason: Dropping a primary key is not allowed without also adding a new primary key. Try ALGORITHM=COPY.\n</code></pre><ul>\n<li>修改字符集。</li>\n</ul><p>注意，使用alter table table_name convert to character set才会修改表中已有数据的编码。alter table table_name character set只是修改了表的默认字符集，不会修改现有数据的编码方式。</p><pre><code class=\"language-go\">mysql&gt; alter table employees_bak CONVERT TO CHARACTER SET GBK, algorithm=inplace;\nERROR 1846 (0A000): ALGORITHM=INPLACE is not supported. Reason: Cannot change column type INPLACE. Try ALGORITHM=COPY.\n</code></pre><ul>\n<li>修改字段的数据类型。</li>\n</ul><pre><code class=\"language-go\">mysql&gt; desc salaries;\n+-----------+------+------+-----+---------+-------+\n| Field     | Type | Null | Key | Default | Extra |\n+-----------+------+------+-----+---------+-------+\n| emp_no    | int  | NO   | PRI | NULL    |       |\n| salary    | int  | NO   |     | NULL    |       |\n| from_date | date | NO   | PRI | NULL    |       |\n| to_date   | date | YES  |     | NULL    |       |\n+-----------+------+------+-----+---------+-------+\n4 rows in set (0.01 sec)\n\nmysql&gt; alter table salaries modify salary bigint, algorithm=inplace;\nERROR 1846 (0A000): ALGORITHM=INPLACE is not supported. Reason: Cannot change column type INPLACE. Try ALGORITHM=COPY.\n</code></pre><ul>\n<li>缩减VARCHAR字段的长度，或者将VARCHAR字段的长度从不到255字节修改为超过255字节。这一点对CHAR类型其实也一样。</li>\n</ul><pre><code class=\"language-go\">mysql&gt; desc departments;\n+-----------+-------------+------+-----+---------+-------+\n| Field     | Type        | Null | Key | Default | Extra |\n+-----------+-------------+------+-----+---------+-------+\n| dept_no   | char(4)     | NO   | PRI | NULL    |       |\n| dept_name | varchar(40) | NO   | UNI | NULL    |       |\n+-----------+-------------+------+-----+---------+-------+\n2 rows in set (0.01 sec)\n\n\nmysql&gt; alter table departments modify dept_name varchar(30), algorithm=inplace;\nERROR 1846 (0A000): ALGORITHM=INPLACE is not supported. Reason: Cannot change column type INPLACE. Try ALGORITHM=COPY.\n\nmysql&gt; alter table departments modify dept_name varchar(64), algorithm=inplace;\nERROR 1846 (0A000): ALGORITHM=INPLACE is not supported. Reason: Cannot change column type INPLACE. Try ALGORITHM=COPY.\n\nmysql&gt; alter table departments modify dept_no char(64), algorithm=inplace;\nERROR 1846 (0A000): ALGORITHM=INPLACE is not supported. Reason: Cannot change column type INPLACE. Try ALGORITHM=COPY.\n\nmysql&gt; alter table departments modify dept_no char(2), algorithm=inplace;\nERROR 1846 (0A000): ALGORITHM=INPLACE is not supported. Reason: Cannot change column type INPLACE. Try ALGORITHM=COPY.\n</code></pre><p>虽然有些INPLACE操作也需要重建表，需要复制整个表的数据，但是和COPY方式相比，还是存在比较大的区别的。首先，以COPY的方式执行DDL时，整个过程中都会锁表。其次COPY是在MySQL的Server层执行的，需要先从存储引擎获取一行数据，再调用存储引擎的接口写入一行数据，直到处理完所有的记录。而INPLACE DDL是在InnoDB存储引擎的内部复制数据，这个过程中不需要记录UNDO日志和REDO日志，而且二级索引的条目会预先排好序，因此理论上写入的速度会更快。</p><h2>第三方在线DDL工具</h2><p>如果你要执行的DDL不支持以INSTANT和INPLACE的方式执行，或者你的表非常大，数据变更也很频繁，使用MySQL原生的在线DDL也无法满足业务的可用性要求，那么你可以考虑使用一些第三方的在线DDL工具，业界比较知名的有percona出品的pt-online-schema-change工具，以及Github出品的gh-ost工具。当然，可能还存在其他类似的第三方工具，实际上你自己也可以写一个类似的工具。</p><p>接下来我们来一起探讨下，怎么实现一个在线DDL工具。假设我们要对一个表SRC_TAB执行一个开销很大的DDL，我们可以将DDL拆分成几个步骤。</p><ol>\n<li>创建一个表结构一样的空表。</li>\n</ol><pre><code class=\"language-go\">create table __SRC_TAB_TMP like SRC_TAB;\n</code></pre><ol start=\"2\">\n<li>在新建的临时表上执行DDL。由于新表中没有任何数据，因此DDL很快就能执行完。</li>\n<li>分批读取源表的数据，插入到新建的临时表中。</li>\n</ol><pre><code class=\"language-go\">insert ignore into __SRC_TAB_TMP(...) select ... from SRC_TAB where ...\n</code></pre><p>当然，在复制数据的过程中，源表的数据会不断地发生变化，因此我们需要想办法同步这些发生了变化的数据，否则两个表的数据就不一致了。</p><ol start=\"4\">\n<li>我们可以给源表建几个触发器，将源表发生过变化的记录都捕捉下来。</li>\n</ol><p>实际上，要在复制数据前，先把触发器建好，因此这一步要在步骤3之前执行。触发器的实现上，有几种不同的策略可以选择。一种是在触发器中，将整条记录直接写到目标临时表中。</p><p>还有一种方式是先将发生过变化的数据写到一个日志表中，日志表中只保存主键字段和数据的变更类型。</p><p>日志表的结构类似于下面建的__SRC_TAB_DML_LOG表。PK字段是源表的主键字段，当然数据类型要和源表保持一致，用来标识发生过变化的记录的主键。DML_TYPE字段用了标识发生的DML类型。DML类型分为INSERT、UPDATE、DELETE。如果是更新了主键，那么需要记录两条日志，一条是删除操作，一条是插入操作。</p><pre><code class=\"language-go\">create table __SRC_TAB_DML_LOG(\n    id bigint not null auto_increment,\n    pk bigint not null,\n    dml_type tinyint not null comment '0: insert, 1: update, 2: delete',\n    ts timestamp,\n    applied tinyint not null comment '0: not applied, 1: applied',\n    primary key(id)\n) engine=innodb;\n</code></pre><ol start=\"5\">\n<li>按顺序处理增量日志表中的数据。</li>\n</ol><p>根据增量日志表中记录的主键ID，依次将数据从源表复制到目标表。</p><pre><code class=\"language-go\">replace into __SRC_TAB_TMP(...) select ... from SRC_TAB where pk in (...)\n</code></pre><p>如果是DELETE操作，则需要到目标表中删除对应的记录。</p><pre><code class=\"language-go\">delete from __SRC_TAB_TMP where pk in (...)\n</code></pre><p>处理增量日志表中的数据时，你可以想办法做并行处理。还可以将主键相同的多条变更记录合并到一起执行。比如源表中有一行记录被更新了100次，你只要将该记录最新的数据同步到目标表就可以了。</p><ol start=\"6\">\n<li>锁定源表，处理增量日志表中剩余的数据。</li>\n</ol><p>当增量日志表中的数据基本处理完之后，锁定源表。源表锁定后，就不会再发生数据变化了，然后你再将增量日志表中所剩不多的数据处理完。</p><pre><code class=\"language-go\">lock tables SRC_TAB write, __SRC_TAB_TMP write;\n</code></pre><ol start=\"7\">\n<li>交换源表和目标表。</li>\n</ol><p>此时源表和目标表的数据已经完全同步了，执行rename操作，交换两个表的表名。</p><pre><code class=\"language-go\">rename table SRC_TAB to __SRC_TAB_TOBE_DROPPED, __SRC_TAB_TMP to SRC_TAB_;\n</code></pre><p>这样，你就完成了SRC_TAB表的DDL操作。当然，在实现上，还有很多细节问题需要处理。比如，如果源表使用了联合主键，你应该如何分批复制数据。如果有其他表对源表有外键依赖，这样做也会有问题。更重要的是，如何保证源表和目标表的数据是完全一致的。</p><h2>总结</h2><p>这一讲中，我们讨论MySQL中执行DDL的几种不同的方式。</p><p>DDL，特别是对大表进行DDL，最好是安排在业务访问的低峰期进行。如果你的数据库非常繁忙，即使是DROP TABLE这样看似简单的操作，都有可能对业务造成明显的影响。</p><p>还有，即使你执行的DDL只需要修改元数据，在DDL执行开始和执行结束的时候，也是需要短暂地获取元数据锁的，如果数据库中有别的长事务提前获取了元数据锁，那么DDL就会被阻塞，而DDL被阻塞后，后续其他会话访问同一个表时，也会被阻塞。因此在DDL执行的过程中，需要注意观察数据库的整体状况，特别是要注意有没有会话在等待元数据锁。</p><p>MySQL的在线DDL并不是完全无锁的。还有一些DDL并不支持在线执行。你可以考虑使用第三方的在线DDL工具，但是在使用前一定要在你自己的环境中做好充分的测试，这些工具可能会有一些额外的限制。你需要重点验证下这些工具是否能保证数据的一致性。</p><h2>思考题</h2><p>gh-ost是比较知名的一款在线DDL工具，在实现上也非常有特色。gt-ost在执行DDL变更时，不需要给源表建触发器，而是通过BINLOG来捕捉DDL变更期间发生过变化的数据。我尝试在测试环境做了一个实验。</p><pre><code class=\"language-go\">gh-ost -alter \"alter table employees_bak modify hire_date date\" \\\n  -user user_01 \\\n  -host 127.0.0.1 \\\n  -password somepass \\\n  -database employees \\\n  --allow-on-master \\\n  --execute \\\n  -heartbeat-interval-millis 1000\n</code></pre><p>在执行gh-ost前，我先开启了general_log，最终在general log中发现有以下这几类SQL。</p><ul>\n<li>create table like</li>\n</ul><pre><code class=\"language-go\">create /* gh-ost */ table `employees`.`_employees_bak_gho` \n  like `employees`.`employees_bak`\n</code></pre><ul>\n<li>alter table</li>\n</ul><pre><code class=\"language-go\">alter /* gh-ost */ table `employees`.`_employees_bak_gho` modify hire_date date\n</code></pre><ul>\n<li>select</li>\n</ul><pre><code class=\"language-go\">select  /* gh-ost `employees`.`employees_bak` iteration:0 */\n    `emp_no`\nfrom `employees`.`employees_bak`\nwhere ((`emp_no` &gt; _binary'10001') or ((`emp_no` = _binary'10001'))) \nand ((`emp_no` &lt; _binary'20000') or ((`emp_no` = _binary'20000')))\norder by `emp_no` asc\nlimit 1\noffset 999\n</code></pre><ul>\n<li>insert ignore into</li>\n</ul><pre><code class=\"language-go\">insert /* gh-ost `employees`.`employees_bak` */ \nignore into `employees`.`_employees_bak_gho` \n(`emp_no`, `birth_date`, `first_name`, `last_name`, `gender`, `hire_date`)\n( \n  select `emp_no`, `birth_date`, `first_name`, `last_name`, `gender`, `hire_date` \n  from `employees`.`employees_bak` force index (`PRIMARY`)\n  where (((`emp_no` &gt; _binary'10001') or ((`emp_no` = _binary'10001')))\n  and ((`emp_no` &lt; _binary'11000') or ((`emp_no` = _binary'11000')))) \n  lock in share mode\n)\n</code></pre><ul>\n<li>replace into</li>\n</ul><pre><code class=\"language-go\">replace /* gh-ost `employees`.`_employees_bak_gho` */ into\n    `employees`.`_employees_bak_gho`(`emp_no`, `birth_date`, `first_name`, `last_name`, `gender`, `hire_date`)\nvalues (20001, '1962-05-16', _binary'Atreye', _binary'Eppinger', ELT(1, 'M','F'), '1990-04-18')\n</code></pre><ul>\n<li>rename table</li>\n</ul><pre><code class=\"language-go\">rename /* gh-ost */ table `employees`.`employees_bak` to `employees`.`_employees_bak_del`, `employees`.`_employees_bak_gho` to `employees`.`employees_bak`\n</code></pre><p>上面的这几类SQL，分别起到了什么作用？insert ignore into和replace into的执行顺序，对最终数据的一致性有影响吗？执行insert ignore into … select from … 的时候，为什么要加上lock in share mode？</p><p>期待你的思考，欢迎在留言区中与我交流。如果今天的课程让你有所收获，也欢迎转发给有需要的朋友。我们下节课再见！</p>","neighbors":{"left":{"article_title":"11｜表太大了，修改表结构太慢怎么解决？（上）","id":806938},"right":{"article_title":"13｜定位MySQL问题的思路：数据库为什么慢了？","id":806951}},"comments":[{"had_liked":false,"id":394534,"user_name":"叶明","can_delete":false,"product_type":"c1","uid":1412429,"ip_address":"江苏","ucode":"D0B4B7660DA766","user_header":"https://static001.geekbang.org/account/avatar/00/15/8d/4d/992070e8.jpg","comment_is_top":false,"comment_ctime":1727082531,"is_pvip":false,"replies":[{"id":143231,"content":"对的。\n\n我再测试了一下，Binlog中，Insert事件解析为replace into语句，Update事件解析为update语句，Delete事件解析为delete语句。\n\nBinlog可见和事务可见之间存在的时间差，由两阶段提交引起。👍👍\n","user_name":"作者回复","user_name_real":"编辑","uid":3898827,"ctime":1727331881,"ip_address":"浙江","comment_id":394534,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100799401,"comment_content":"insert ignore into用来同步全量数据，replace into是从binlog中解析出来的insert和update事件。binlog中的delete事件应该会解析成delete语句。我测试的结果是 update 语句并没有转为 replace into，仍旧是 update。全量日志如下\n\n2024-09-20T03:59:21.024359Z\t 1451 Query\tupdate employees_bak set first_name = &#39;2024-09-20&#39; where emp_no = 10001\n\n2024-09-20T03:59:21.044251Z\t 1467 Query\tSTART TRANSACTION\n2024-09-20T03:59:21.044461Z\t 1467 Query\tSET SESSION time_zone = &#39;+00:00&#39;, sql_mode = CONCAT(@@session.sql_mode, &#39;,NO_AUTO_VALUE_ON_ZERO,STRICT_ALL_TABLES&#39;)\n2024-09-20T03:59:21.044739Z\t 1467 Query\tupdate &#47;* gh-ost `employees`.`_employees_bak_gho` *&#47;\n\t\t\t\t\t`employees`.`_employees_bak_gho`\n\t\t\t\tset\n\t\t\t\t\t`emp_no`=10001, `birth_date`=&#39;1953-09-02&#39;, `first_name`=_binary&#39;2024-09-20&#39;, `last_name`=_binary&#39;Facello&#39;, `gender`=ELT(1, &#39;M&#39;,&#39;F&#39;), `hire_date`=&#39;1986-06-26&#39;\n\t\t\t\twhere\n\t\t\t\t\t((`emp_no` = 10001))\n2024-09-20T03:59:21.051821Z\t 1467 Query\tCOMMIT\n\n我理解的转化规则，不知道对否\n1、insert -&gt; replace into\n2、update -&gt; update，如果记录已经拷贝到影子表中，那么直接 update 影子表，影子表中记录达到最新；如果记录尚未拷贝到影子表，直接更新影子表，但此时影子表中没有这条记录，因此更新 0 行，待后面 insert ignore into 插入新的记录，影子表中对应的行仍旧为最新的记录\n3、delete -&gt; delete\n\nBinlog可见和事务可见之间存在一个时间差，这是两阶段提交导致的吧，innodb prepare -&gt; binlog write -&gt; innodb commit，binlog 比 innodb commit 提前完成，所以说 binlog 比事务可见早一点。","like_count":1,"discussions":[{"author":{"id":3898827,"avatar":"https://static001.geekbang.org/account/avatar/00/3b/7d/cb/fa3dae58.jpg","nickname":"俊达","note":"","ucode":"F79BF9651AD086","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":651720,"discussion_content":"对的。\n\n我再测试了一下，Binlog中，Insert事件解析为replace into语句，Update事件解析为update语句，Delete事件解析为delete语句。\n\nBinlog可见和事务可见之间存在的时间差，由两阶段提交引起。👍👍\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1727331881,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":394283,"user_name":"Shelly","can_delete":false,"product_type":"c1","uid":2422713,"ip_address":"广东","ucode":"75BA35C2737EA6","user_header":"https://static001.geekbang.org/account/avatar/00/24/f7/b9/f2eec64e.jpg","comment_is_top":false,"comment_ctime":1726317907,"is_pvip":false,"replies":[{"id":143137,"content":"和我的理解基本一致。\n\nlock in shared mode是为了保证数据的一致性，你举的例子是其中一种情况。\n\n没有使用半同步时，也会存在类似的情况。Binlog可见和事物可见之间存在一个时间差，虽然一般这个时间差很短，但如果不加lock in shared mode，理论上有可能会读取到DELETE之前的数据，这样影子表可能会多数据。","user_name":"作者回复","user_name_real":"编辑","uid":3898827,"ctime":1726557916,"ip_address":"浙江","comment_id":394283,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100799401,"comment_content":"思考题：\n\ngh-ost做DDL变更期间，有三种操作：(1). 对原表的copy到影子表  (2). 应用binlog到影子表 (3). 业务对原表的DML操作  \n由于copy原表操作和应用binlog到影子表是交替进行的，所以：\n1. insert ingore into ...操作，如果业务先对原表进行了一些插入操作（注意此时对应的行还没有被copy到影子表），然后应用binlog到影子表，这时copy对应的行到影子表，如果不加ingore就会导致主键冲突错误 \n2. replace into 操作，如果业务对表进行了一些插入操作，对原表相应记录copy到影子表（此时对应的binlog还未被应用），后续在应用binlog时影子表已经有了相应记录，所以要加inplace into 覆盖掉copy操作的相应记录，否则会导致主键冲突错误\n3. insert ingore into ...操作和replace into 操作的顺序不会对最终的数据一致性有影响\n4. 个人理解查询时加lock in shared mode原因：假设一个场景主从半同步（after_sync），有个用户在主库对表进行了几行删除操作，此时从库由于某些原因没有回复ack，如果binlog已经被捕获，应用binlog到影子表时操作会被忽略（此时相应的记录还没有被copy到影子表），然后再copy相应原表记录到影子表（由于主库没有收到从库的ack，所以主库是可以查询到这些被删除的表），于是实际上已经被删除的数据却被拷贝到了影子表，导致原表和影子表的数据不一致。  如果在copy数据时，查询加上lock in shard mode共享锁，就会等待删除的事务提交后才能获取数据相应行的数据，防止了DDL变更前后数据不一致的情况发生。","like_count":1,"discussions":[{"author":{"id":3898827,"avatar":"https://static001.geekbang.org/account/avatar/00/3b/7d/cb/fa3dae58.jpg","nickname":"俊达","note":"","ucode":"F79BF9651AD086","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":651218,"discussion_content":"和我的理解基本一致。\n\nlock in shared mode是为了保证数据的一致性，你举的例子是其中一种情况。\n\n没有使用半同步时，也会存在类似的情况。Binlog可见和事物可见之间存在一个时间差，虽然一般这个时间差很短，但如果不加lock in shared mode，理论上有可能会读取到DELETE之前的数据，这样影子表可能会多数据。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1726557917,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":394279,"user_name":"123","can_delete":false,"product_type":"c1","uid":2662872,"ip_address":"新加坡","ucode":"5A343B568B9524","user_header":"https://static001.geekbang.org/account/avatar/00/28/a1/d8/42252c48.jpg","comment_is_top":false,"comment_ctime":1726307713,"is_pvip":false,"replies":[{"id":143138,"content":"replace into 和 insert ignore into的顺序应该不影响最终的结果。\ninsert ignore into用来同步全量数据，replace into是从binlog中解析出来的insert和update事件。binlog中的delete事件应该会解析成delete语句，这一点我文章里没提到。\n\nlock in share mode是为了保证影子表数据和原表一致。\n\nBinlog可见和事物可见之间存在一个时间差，虽然一般这个时间差很短，但如果不加lock in shared mode，源库执行delete语句时，binlog中读到了delete语句，但select可能会读取到DELETE之前的数据。这样，如果先对影子表执行了delete，然后再insert ignore into时，会把本来应该已经delete掉的数据，插入到影子表，就多数据了。\n\n","user_name":"作者回复","user_name_real":"编辑","uid":3898827,"ctime":1726558367,"ip_address":"浙江","comment_id":394279,"utype":1}],"discussion_count":7,"race_medal":0,"score":2,"product_id":100799401,"comment_content":"思考题：\n1 - create table like：创建临时表，复制表结构；\n2 - alter table：根据命令更改表表结构；\n3 - select：并发读取数据（看到了偏移量，应该是多线程）写入临时文件，使用_binary应该是可以忽略字符集，直接比较二进制文本，减少开销提升性能；\n4 - insert ignore into：将数据插入到临时表中，忽略唯一键报错；\n5 - replace into：将增量数据更新至临时表中；\n6 - rename table：将临时表变更为生产表；\n\ninsert into  应该是原表的数据，replace into 的是增量的数据，改变执行顺序，会导致数据不一致，特别是涉及删除操作的内容，如果仅仅是数据的插入和更新，更新本身就带有全量数据，插入后就代表了该行的最新数据，后续的insert into ignore也会忽略，觉得仅仅是replace into 和 insert into的替换感觉也不会出问题，望老师指正\n\n执行insert时需要lock in share mode加上共享锁，应该是防止进行数据更新，仅供查询。","like_count":1,"discussions":[{"author":{"id":3898827,"avatar":"https://static001.geekbang.org/account/avatar/00/3b/7d/cb/fa3dae58.jpg","nickname":"俊达","note":"","ucode":"F79BF9651AD086","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":651220,"discussion_content":"replace into 和 insert ignore into的顺序应该不影响最终的结果。\ninsert ignore into用来同步全量数据，replace into是从binlog中解析出来的insert和update事件。binlog中的delete事件应该会解析成delete语句，这一点我文章里没提到。\n\nlock in share mode是为了保证影子表数据和原表一致。\n\nBinlog可见和事物可见之间存在一个时间差，虽然一般这个时间差很短，但如果不加lock in shared mode，源库执行delete语句时，binlog中读到了delete语句，但select可能会读取到DELETE之前的数据。这样，如果先对影子表执行了delete，然后再insert ignore into时，会把本来应该已经delete掉的数据，插入到影子表，就多数据了。\n\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1726558367,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":6,"child_discussions":[{"author":{"id":2662872,"avatar":"https://static001.geekbang.org/account/avatar/00/28/a1/d8/42252c48.jpg","nickname":"123","note":"","ucode":"5A343B568B9524","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":3898827,"avatar":"https://static001.geekbang.org/account/avatar/00/3b/7d/cb/fa3dae58.jpg","nickname":"俊达","note":"","ucode":"F79BF9651AD086","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":651254,"discussion_content":"老师，增量数据的执行难道不是后于源表复制的吗？如果是select先行，那么后续提交事务的binlog都会被记录下来的，然后待源表复制完成后再执行增量binlog数据","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1726630723,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":651220,"ip_address":"浙江","group_id":0},"score":651254,"extra":""},{"author":{"id":1582134,"avatar":"https://static001.geekbang.org/account/avatar/00/18/24/36/0829cbdc.jpg","nickname":"TheOne","note":"","ucode":"2A359780156A8B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":3898827,"avatar":"https://static001.geekbang.org/account/avatar/00/3b/7d/cb/fa3dae58.jpg","nickname":"俊达","note":"","ucode":"F79BF9651AD086","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":651277,"discussion_content":"老师，binlog可见和事务可见有时间差是什么意思，没太理解，binlog写完，不就约等于事务结束了吗","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1726668451,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":651220,"ip_address":"北京","group_id":0},"score":651277,"extra":""},{"author":{"id":3951358,"avatar":"https://static001.geekbang.org/account/avatar/00/3c/4a/fe/7b6bd101.jpg","nickname":"笙 鸢","note":"","ucode":"477AF524212C6D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":3898827,"avatar":"https://static001.geekbang.org/account/avatar/00/3b/7d/cb/fa3dae58.jpg","nickname":"俊达","note":"","ucode":"F79BF9651AD086","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":651412,"discussion_content":"老师，这个时间差能详讲下吗？现在对于一个事务的提交——写到redolog——bufferpool和binlog日志的写入这块不知道哪个先后（顺序问题）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1726826106,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":651220,"ip_address":"上海","group_id":0},"score":651412,"extra":""}]}]},{"had_liked":false,"id":396473,"user_name":"木几丶","can_delete":false,"product_type":"c1","uid":2420294,"ip_address":"福建","ucode":"FFDB958DA64F8C","user_header":"https://static001.geekbang.org/account/avatar/00/24/ee/46/7d65ae37.jpg","comment_is_top":false,"comment_ctime":1734602368,"is_pvip":true,"replies":[{"id":143932,"content":"是的。至少到8.0版本为止，修改字段的数据类型，都不支持Online DDL。","user_name":"作者回复","user_name_real":"编辑","uid":3898827,"ctime":1734660945,"ip_address":"浙江","comment_id":396473,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100799401,"comment_content":"老师，请问下修改字段数据类型这些操作不能用OnlineDDL?","like_count":0,"discussions":[{"author":{"id":3898827,"avatar":"https://static001.geekbang.org/account/avatar/00/3b/7d/cb/fa3dae58.jpg","nickname":"俊达","note":"","ucode":"F79BF9651AD086","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":655348,"discussion_content":"是的。至少到8.0版本为止，修改字段的数据类型，都不支持Online DDL。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1734660946,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":1,"child_discussions":[{"author":{"id":2420294,"avatar":"https://static001.geekbang.org/account/avatar/00/24/ee/46/7d65ae37.jpg","nickname":"木几丶","note":"","ucode":"FFDB958DA64F8C","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":3898827,"avatar":"https://static001.geekbang.org/account/avatar/00/3b/7d/cb/fa3dae58.jpg","nickname":"俊达","note":"","ucode":"F79BF9651AD086","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":655366,"discussion_content":"老师不好意思，漏字了，我想问的是为什么修改字段类型不能用Online DDL？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1734689977,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":655348,"ip_address":"福建","group_id":0},"score":655366,"extra":""}]}]},{"had_liked":false,"id":394603,"user_name":"陈星宇(2.11)","can_delete":false,"product_type":"c1","uid":1450562,"ip_address":"四川","ucode":"970E48260B7924","user_header":"https://static001.geekbang.org/account/avatar/00/16/22/42/11674804.jpg","comment_is_top":false,"comment_ctime":1727276469,"is_pvip":false,"replies":[{"id":143232,"content":"Online DDL MySQL 5.6就有的，包括参数innodb_online_alter_log_max_size。\n\nmysql&gt; select @@version, @@innodb_online_alter_log_max_size\\G\n*************************** 1. row ***************************\n                         @@version: 5.6.51-log\n@@innodb_online_alter_log_max_size: 134217728","user_name":"作者回复","user_name_real":"编辑","uid":3898827,"ctime":1727332251,"ip_address":"浙江","comment_id":394603,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100799401,"comment_content":"老师，这些都是8.0才有的吧？innodb_online_alter_log_max_size","like_count":0,"discussions":[{"author":{"id":3898827,"avatar":"https://static001.geekbang.org/account/avatar/00/3b/7d/cb/fa3dae58.jpg","nickname":"俊达","note":"","ucode":"F79BF9651AD086","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":651721,"discussion_content":"Online DDL MySQL 5.6就有的，包括参数innodb_online_alter_log_max_size。\n\nmysql&gt; select @@version, @@innodb_online_alter_log_max_size\\G\n*************************** 1. row ***************************\n                         @@version: 5.6.51-log\n@@innodb_online_alter_log_max_size: 134217728","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1727332251,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":394232,"user_name":"binzhang","can_delete":false,"product_type":"c1","uid":1647189,"ip_address":"美国","ucode":"F2670F2EA24FAD","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q3auHgzwzM59PTNiaDASVicbVaeWBU1WKmOgyHcqVtl85nDwAqDicib1EUKE2RRoU0x0vZctZO4kbPDUTTke8qKfAw/132","comment_is_top":false,"comment_ctime":1726191735,"is_pvip":false,"replies":[{"id":143098,"content":"是的，inplace DDL即使要重建表，也是在存储引擎内部完成的，因此rows affected总是0。\n\nCOPY模式是在Server层复制数据的，相当于select + insert，rows affected会显示为实际处理的记录数，也就是表里的记录数。","user_name":"作者回复","user_name_real":"编辑","uid":3898827,"ctime":1726208364,"ip_address":"浙江","comment_id":394232,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100799401,"comment_content":"为啥有些inplace的ddl也显示rows affected是0？ 只有copy模式会显示非0 的rows affected吗？","like_count":0,"discussions":[{"author":{"id":3898827,"avatar":"https://static001.geekbang.org/account/avatar/00/3b/7d/cb/fa3dae58.jpg","nickname":"俊达","note":"","ucode":"F79BF9651AD086","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":651088,"discussion_content":"是的，inplace DDL即使要重建表，也是在存储引擎内部完成的，因此rows affected总是0。\n\nCOPY模式是在Server层复制数据的，相当于select + insert，rows affected会显示为实际处理的记录数，也就是表里的记录数。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1726208364,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]}]}