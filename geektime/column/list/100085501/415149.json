{"id":415149,"title":"04｜ 实战5步（下）：怎么建立估计10万+软文点击率的模型？","content":"<p>你好，我是黄佳。欢迎来到零基础实战机器学习。</p><p>上一讲，我们通过一个项目讲解了“实战5步”的前两步。在第一步“定义问题”中，我们定义了要处理的问题，也就是根据点赞数和转发数等指标，估计一篇文章能实现多大的浏览量。同时我们还将它归类为回归问题；在第二步“收集数据和预处理”中，我们做好了数据的预处理工作，还把数据集拆分成了这四个数据集：</p><ul>\n<li>特征训练集（X_train）</li>\n<li>特征测试集（X_test）</li>\n<li>标签训练集（y_train）</li>\n<li>标签测试集（y_test）</li>\n</ul><p>有了这些数据集后，我们就可以开始考虑选什么算法，然后建立模型了。所以，今天这节课我们继续完成“实战5步”中的后三步：选择算法并建立模型、训练拟合模型和评估并优化模型性能，来把这个项目做完。下面，我们先看看怎么选择算法并建立模型。</p><h1>第3步 选择算法并建立模型</h1><p>在这一步中，我们需要先根据特征和标签之间的关系，选出一个合适的算法，并找到与之对应的合适的算法包，然后通过调用这个算法包来建立模型。</p><p>选算法的过程很考验数据科学家们的经验，不过，你也无需担心自己没有经验，在这个课程中，我会给你讲清楚每一个实战中所用的算法的原理，帮助你建立起选算法的直觉。</p><p>具体到我们这个项目里，在上一讲中我说过，我们这个数据集里的某些特征和标签之间，存在着近似线性的关系。而且，这个数据集的标签是连续变量，因此，适合用回归分析来寻找从特征到标签的预测函数。</p><!-- [[[read_end]]] --><p>所谓回归分析(regression analysis)，就是确定两种或两种以上变量间相互依赖的定量关系的一种统计分析，说白了就是当自变量变化的时候，研究一下因变量是怎么跟着变化的，它可以用来预测客流量、降雨量、销售量等。</p><p>不过，回归分析的算法有很多种，比如说线性回归，多项式回归，贝叶斯回归等等，那具体该选哪个呢？其实，这是根据特征和标签之间的关系来决定的。我们在上一讲的可视化过程中，推测特征和标签可能存在线性关系，并且用下面这个散点图简单做了验证。</p><p><img src=\"https://static001.geekbang.org/resource/image/24/7d/24e97d5a919c0e03b924270233a3b67d.png?wh=399x260\" alt=\"\"></p><p>所以这里，我们就选择用线性回归算法来建模。</p><p>线性回归算法是最简单、最基础的机器学习算法，它其实就是给每一个特征变量找参数的过程。我想你一定熟悉一元线性回归的公式：</p><p>$$ y = a*x + b $$</p><p>对于一元线性回归来说，它的内部参数就是未知的斜率和截距。只不过在机器学习中，我们把斜率a叫做权重（weight），用英文字母w代表，把截距b叫做偏置（bias），用英文字母b代表。所以机器学习中一元线性回归的公式也写成：</p><p>$$ y = w*x + b $$</p><p>而在我们这个项目中，数据集中有4个特征，所以就是：</p><p>$$ y = w_{1}x_{1} + w_{2}x_{2} + w_{3}x_{3} + w_{4}x_{4} + b $$</p><p>因此，我们的模型就会有5个内部参数，也就是4个特征的权重和一个偏置（截距）需要确定。不过这些公式的具体代码实现，都不用我们自己完成，它们全部封装在工具包里了。你只要对算法的原理有个印象就行了。</p><p>确定好算法后，我们接着来看一下调用什么样的算法包建立模型比较合适。</p><p>对于机器学习来说，最常用的算法工具包是scikit-learn，简称sklearn，它是使用最广泛的开源Python机器学习库，堪称机器学习神器。sklearn提供了大量用于数据挖掘的机器学习工具，覆盖数据预处理、可视化、交叉验证和多种机器学习算法。</p><p>虽然我们已经选定使用线性回归算法，但是在sklearn中又有很多线性回归算法包，比如说基本的线性回归算法LinearRegression，以及在它的基础上衍生出来的Lasso回归和Ridge回归等。</p><p>那哪一个才是适合我们这个项目的算法包呢？其实，我们一般选算法包的方法是从能够解决该问题的最简单的算法开始尝试，直到得到满意的结果为止。对于这个项目，我们选择LinearRegression，它也是机器学习中最常见、最基础的回归算法包。其它回归算法包，未来我会慢慢给你介绍。</p><p>调用LinearRegression建立模型非常简单，两行代码就可以搞定：</p><pre><code class=\"language-plain\">from sklearn.linear_model import LinearRegression # 导入线性回归算法模型\nlinereg_model = LinearRegression() # 使用线性回归算法创建模型\n</code></pre><p>可以看到，我把这个线性回归模型命名为了“linereg_model”。那到这里，我们算不算是建立好模型了呢？是的，模型已经创建出来了，我们可以开始训练它了。不过，有一点需要指出，建立模型时，你通常还需要了解它有哪些外部参数，同时指定好它的外部参数的值。</p><p>模型的参数有两种：内部参数和外部参数。内部参数是属于算法本身的一部分，不用我们人工来确定，刚才提到的权重w和截距b，都是线性回归模型的内部参数；而外部参数也叫做超参数，它们的值是在创建模型时由我们自己设定的。</p><p>对于LinearRegression模型来讲，它的外部参数主要包括两个布尔值：</p><ul>\n<li>fit_intercept&nbsp;，默认值为True，代表是否计算模型的截距。</li>\n<li>normalize，默认值为 False，代表是否对特征X在回归之前做规范化。</li>\n</ul><p>不过呢，对于比较简单的模型来说，默认的外部参数设置也都是不错的选择，所以，我们不显式指定外部参数而直接调用模型，也是可以的。在上面的代码中，我就是在创建模型时直接使用了外部参数的默认值。</p><p>还有一点需要说明的是，我们课程中不会去详细介绍每一个参数的意义，因为这不是我们的重点。但是对于一些特殊情况下需要调整外部参数的，在后面的课程里我会告诉你调参的重要技巧。</p><p>好，现在我们已经创建好线性回归模型linereg_model，接下来我们就可以进入机器学习的核心环节“训练拟合机器学习模型”了。</p><h1>第4步 训练模型</h1><p>训练模型就是用训练集中的特征变量和已知标签，根据当前样本的损失大小来<strong>逐渐拟合函数，确定最优的内部参数，最后完成模型</strong>。虽然看起来挺复杂，但这些步骤，我们都通过调用fit方法来完成。</p><p>fit方法是机器学习的核心环节，里面封装了很多具体的机器学习核心算法，我们只需要把特征训练数据集和标签训练数据集，同时作为参数传进fit方法就行了。</p><pre><code class=\"language-plain\">linereg_model.fit(X_train, y_train) # 用训练集数据，训练机器，拟合函数，确定内部参数\n</code></pre><p>运行该语句后的输出如下：</p><pre><code class=\"language-plain\">LinearRegression()\n</code></pre><p>这样，我们就完成了对模型的训练。你可能会觉得很奇怪，既然训练模型是机器学习的核心环节，怎么只有一句代码？其实这就是我反复强调过的，由于优秀的机器学习库的存在，我们可以用一两行语句实现很强大的功能。所以，不要小看上面那个简单的fit语句，这是模型进行自我学习的关键过程。</p><p>在这个过程里，<strong>fit的核心就是减少损失，使函数对特征到标签的模拟越来越贴切</strong>。那么它具体是怎么减少损失呢？这里我画了一张图片展示模型从很不靠谱到比较靠谱的过程。</p><p><img src=\"https://static001.geekbang.org/resource/image/d7/08/d711fe6c1ace614dfe4ef1268498d608.jpg?wh=2284x1032\" alt=\"\"></p><p>这个拟合的过程，同时也是机器学习算法优化其内部参数的过程。而优化参数的关键就是减小损失。</p><p>那什么是损失呢？它其实是<strong>对糟糕预测的惩罚</strong>，同时也是对模型好坏的度量。损失也就是模型的误差，也称为成本或代价。名字虽多，但都是一个意思，就是当前预测值和真实值之间的差距的体现。它是一个数值，表示对于单个样本而言模型预测的准确程度。如果模型的预测完全准确，则损失为0；如果不准确，就有损失。</p><p>在机器学习中，我们追求的当然是比较小的损失。不过，模型好不好，还不能仅看单个样本，还要针对所有数据样本，找到一组平均损失“较小”的函数模型。样本的损失大小，从几何意义上基本可以理解为预测值和真值之间的几何距离。平均距离越大，说明误差越大，模型越离谱。在下面这个图中，左边是平均损失较大的模型，右边是平均损失较小的模型，模型所有数据点的平均损失很明显大过右边模型。</p><p><img src=\"https://static001.geekbang.org/resource/image/1e/1f/1e07d5c3fe9a82b4f2c1d83c6fcd591f.jpg?wh=2284x868\" alt=\"\"></p><p>因此，针对每一组不同的参数，机器都会基于样本数据集，用损失函数算一次平均损失。而机器学习的最优化过程，就是逐步减小训练集上损失的过程。具体到我们今天这个回归模型的拟合，它的关键环节就是<strong>通过梯度下降，逐步优化模型的参数，使训练集误差值达到最小</strong>。这也就是我们刚才讲的那个fit语句所要实现的最优化过程。</p><p>在这里面，线性回归中计算误差的方法很好理解，就是数据集中真值与预测值之间的残差平方和。那梯度下降又是怎么一回事呢？为了让你直观地理解，我用一张图来展示一下，梯度下降是怎么一步一步地走到损失曲线中的最小损失点的。</p><p><img src=\"https://static001.geekbang.org/resource/image/12/1a/128eec906305b3be97989f28cec1961a.jpg?wh=2284x1285\" alt=\"\"></p><p>就像图里这样，梯度下降其实就和下山一样。你可以想象一下，当你站在高处，你的目标就是找到一系列的参数，让训练数据集上的损失值最小。那么你该往哪走才能保证损失值最小呢？关键就是通过求导的方法，找到每一步的方向，确保总是往更小的损失方向前进。</p><p>所以，你可以看出方向是有多么的重要。机器学习最优化之所以能够拟合出最佳的模型，就是因为能够找到前进方向，你看，<strong>不仅我们人需要方向，连AI也需要正确的方向</strong>。</p><p>关于梯度下降，你理解这些就已经差不多了。至于具体的细节，我们在这个课程中并不会通过公式和代码实现，这也是基于不重复造轮子的原则。那到这里为止，我们已经完成了模型的建立和训练，接下来，我们一起看看怎么对这个训练好的模型进行评估和优化，让它尽可能精准地估计出我们的文章浏览量。</p><h1>第5步 模型的评估和优化</h1><p>我们刚才说，梯度下降是在用训练集拟合模型时最小化误差，这时候算法调整的是模型的内部参数。而<strong>在验证集或者测试集进行模型效果评估的过程中，我们则是通过最小化误差来实现超参数（模型外部参数）的优化</strong>。</p><p>对此，机器学习工具包（如scikit-learn）中都会提供常用的工具和指标，对验证集和测试集进行评估，进而计算当前的误差。比如$R^{2}$或者MSE均方误差指标，就可以用于评估回归分析模型的优劣。</p><p>不过呢，在开始评估模型之前，我想请你思考一下：在我们这5个实战步骤里面，并没有“使用模型预测浏览量”这个环节，这是为什么呢？其实这个环节已经包含在第5步“模型性能的评估和优化”之中了，并且是我们在第5步中首先要去实现的。</p><p>具体来说，在“模型的评估和优化”这一步中，当我们预测完测试集的浏览量后，我们要再拿这个预测结果去和测试集已有的真值去比较，这样才能够求出模型的性能。而这整个过程也同样是一个循环迭代的过程，我把这个循环过程总结成了下面的图，你可以看看：</p><p><img src=\"https://static001.geekbang.org/resource/image/69/67/691da4be2681f183f396bfb0e5b74867.jpg?wh=2284x1285\" alt=\"\"></p><p>对于我们这个项目来说，预测测试集的浏览量，只需要用训练好的模型linereg_model中的predict方法，在X_test（特征测试集）上进行预测，这个方法就会返回对测试集的预测结果。</p><pre><code class=\"language-typescript\">y_pred = linereg_model.predict(X_test) #预测测试集的Y值\n</code></pre><p>在几乎所有的机器学习项目中，你都可以用predict方法来进行预测，它就是用模型在任意的同类型数据集上去预测真值的，可以应用于验证集、测试集，当然也可以应用于训练集本身。</p><p>这里我要说明一下，为了简化流程，我们并没有真正进行验证和测试的多重循环。因此，在这个项目中，X_test既充当了测试集，也充当了验证集。</p><p>拿到预测结果后，我们再通过下面的代码，把测试数据集的原始特征数据、原始标签真值，以及模型对标签的预测值组合在一起进行显示、比较。</p><pre><code class=\"language-typescript\">df_ads_pred = X_test.copy() # 测试集特征数据\ndf_ads_pred['浏览量真值'] = y_test # 测试集标签真值\ndf_ads_pred['浏览量预测值'] = y_pred # 测试集标签预测值\ndf_ads_pred #显示数据\n</code></pre><p>输出结果如下:</p><p><img src=\"https://static001.geekbang.org/resource/image/6f/66/6fa715a600aab30ddefb792409ed5366.png?wh=432x346\" alt=\"\"></p><p>可以看出，浏览量预测值是比较接近于真值的。而且对于一些文章，这个模型的预测得非常准确，比如编号第1387号数据，其实际浏览量为213501，预测浏览量为216491。这就是一个很棒的结果。</p><p>如果你想看看现在的模型长得什么样？你可以通过LinearRegression的coef_和intercept_属性打印出各个特征的权重和模型的偏置来。它们也就是模型的内部参数。</p><pre><code>print('当前模型的4个特征的权重分别是: ', model.coef_)\nprint('当前模型的截距（偏置）是: ', model.intercept_)\n</code></pre><p>输出如下：</p><pre><code>当前模型的4个特征的权重分别是:  [   48.08395224    34.73062229 29730.13312489  2949.62196343]\n当前模型的截距（偏置）是:  -127493.90606857178\n</code></pre><p>这也就是说，我们现在的模型的线性回归公式是：</p><p>$$ yy=48.08x_{1}（点赞）+34.73x_{2}（转发）+29730.13x_{3}（热度）+2949.62x_{4}（评级）-127493.91 $$</p><p>不过到这里，整个机器学习项目并没有结束，我们最后还要给出当前这个模型的评估分数：</p><pre><code class=\"language-typescript\">print(\"线性回归预测评分：\", linereg_model.score(X_test, y_test)) # 评估模型\n</code></pre><p>在机器学习中，常用于评估回归分析模型的指标有两种：$R^{2}$分数和MSE指标，并且大多数机器学习工具包中都会提供相关的工具。对此，你无需做过多了解，只需要知道我们这里的score这个API中，选用的是$R^{2}$分数来评估模型的就可以了。</p><p>最后我们得到这样的结果：</p><pre><code class=\"language-plain\">线性回归预测评分： 0.7085754407718876\n</code></pre><p>可以看到，$R^{2}$值约为0.708。那这意味着什么呢？</p><p>一般来说，$R^{2}$的取值在0到1之间，$R^{2}$越大，说明所拟合的回归模型越优。现在我们得到的$R^{2}$值约为0.708，在没有与其它模型进行比较之前，我们实际上也没法确定它是否能令人满意。</p><p>因为分数的高低，与数据集预测的难易程度、模型的类型和参数都有关系。而且，$R^{2}$分数也不是线性回归模型唯一的评估标准。关于模型的评估和优化，我们就先讲到这里，更多内容，我们还会在以后逐步深入讲解。</p><p>不过你需要知道的是，如果模型的评估分数不理想，我们就需要回到第3步，调整模型的外部参数，重新训练模型。要是得到的结果依旧不理想，那我们就要考虑选择其他算法，创建全新的模型了。如果很不幸，新模型的效果还是不好的话，我们就得回到第2步，看看是不是数据出了问题。</p><p><img src=\"https://static001.geekbang.org/resource/image/ba/0c/ba6f2b4e7fb781ecb238af3325c1b40c.jpg?wh=2284x2341\" alt=\"\"></p><p>这也是为什么，我<strong>一直强调机器学习项目是一个循环迭代的过程，优秀的模型都是一次次迭代的产物</strong>。</p><p>当模型通过了评估，就可以去解决实际问题了，机器学习项目也算是基本结束。你或许会问，为什么“实战5步”中没有模型的上线和部署？这是因为在通常的机器学习项目中，机器学习工程师并不负责这一块，而且，各个公司把机器学习部署到生产环境的方法也大不相同。所以，我们没有把部署模型放在我们的实战5步里。不过，具体怎么部署模型，我在后面会讲到。</p><h1>总结一下</h1><p>这一讲的内容到此就全部结束了，现在你已经拥有了一次完整的机器学习实战经历。怎么样，并没有你想象得那么难吧？</p><p>在这一讲和上一讲中，我们通过一个预测软文浏览量的实战项目，了解了机器学习项目要经历5个步骤。第一步就是通过定义问题来明确我们的项目目标；第二步是数据的收集和预处理，这一步的重点是把数据转换成机器学习可处理的格式，这样我们就可以在第三步中针对问题选定适宜的算法，来建立模型了。</p><p>有了模型后，我们要在接下来的第四步中训练模型、拟合函数。最后，再对训练好的模型进行评估和优化。对于这最后一步，也就是第5步，我们的重点是反复测评，找到最优的超参数，确定最终模型。</p><p><img src=\"https://static001.geekbang.org/resource/image/e8/02/e8b5a33fa7b0576f95f97f627f600402.jpg?wh=2284x1245\" alt=\"\"></p><p>在这“实战5步”中，我们每一步做了些什么、机器学习模型做了些什么，都需要你好好地理解和体会。从下一讲开始，我们就要进入更接近实际业务场景的项目实战了，我会引导着你进一步加深对数据和机器学习概念的理解，挖掘出数据之中的价值。</p><p>准备好了吗？让我们继续上路，开始正式闯关，在动手实践中把机器学习知识用起来！</p><h1>思考题</h1><p>这节课讲完了，我给你留的思考题是这样的：</p><p>在我们这个项目中，使用的是线性回归模型LinearRegression的默认外部参数。此时，两个参数的默认值分别是，fit_intercept&nbsp;= True，normalize = False。尽管解释算法中每一个参数的具体意义并非我们的课程重点，但是阅读算法和参数的说明文档，然后调整参数，优化模型，却是机器学习项目的日常工作。</p><p>因此，请你用fit_intercept&nbsp;和normalize这两个参数练练手，自己调整它们的值，形成各种组合，重新训练出其它外部参数组合的模型。我们可以大概算一下，两个布尔类型参数最多就形成4种组合，而且我们的默认参数已经训练出了其中的一种，所以你可以尝试其它三种。</p><p>另外，你也可以看一看，对于这个数据集来说，取哪组fit_intercept和normalize值，你的模型测试结果更优？</p><p>最后，给你一个小提示，如果你希望对变量X做“规范化”，在建立模型的同时就要指定外部参数normalize的值：</p><pre><code class=\"language-plain\">from sklearn.linear_model import LinearRegression # 导入线性回归算法模型\nlinereg_model = LinearRegression(normalize&nbsp;=&nbsp;True) # 使用线性回归算法创建模型,并指定外部参数normalize\n</code></pre><p>欢迎你在留言区分享你的想法和收获，我在留言区等你。如果这节课帮到了你，也欢迎你把这节课分享给自己的朋友。</p><p><img src=\"https://static001.geekbang.org/resource/image/56/81/5647a4e7bc72e040d8654df556f72081.jpg?wh=2284x1136\" alt=\"\"></p>","comments":[{"had_liked":false,"id":310772,"user_name":"在路上","can_delete":false,"product_type":"c1","uid":1402511,"ip_address":"","ucode":"6E31908EFE1107","user_header":"https://static001.geekbang.org/account/avatar/00/15/66/8f/02be926d.jpg","comment_is_top":true,"comment_ctime":1630899768,"is_pvip":false,"replies":[{"id":"112609","content":"置顶！","user_name":"作者回复","user_name_real":"黄佳","uid":"1809833","ctime":1630909425,"ip_address":"","comment_id":310772,"utype":1}],"discussion_count":2,"race_medal":0,"score":"9.2233720857302999e+18","product_id":100085501,"comment_content":"佳哥好，这节课的示例在我的电脑上运行会报错：Glyph 28909 missing from current font. font.set_text(s, 0.0, flags=flags)，原因是中文字体乱码，解决方法是设置一个本地有的中文字体，可以先打印下本地支持的字体，方法如下，在`import matplotlib.pyplot as plt`这条语句所在的单元格插入代码：<br>```<br>from matplotlib import font_manager<br>for font in font_manager.fontManager.ttflist:<br>    # 查看字体名以及对应的字体文件名<br>    print(font.name, &#39;-&#39;, font.fname)<br># 我使用了微软雅黑<br>plt.rcParams[&#39;font.sans-serif&#39;]=&#39;Microsoft YaHei&#39;   <br>```<br><br>调整参数后的测试结果是：<br>LinearRegression(normalize = True, fit_intercept= False)<br>线性回归预测集评分： 0.689427235535854<br>线性回归训练集评分： 0.6947857687516026<br><br>LinearRegression(normalize = False, fit_intercept= False)<br>线性回归预测集评分： 0.689427235535854<br>线性回归训练集评分： 0.6947857687516026<br><br>LinearRegression(normalize = True, fit_intercept= True)<br>线性回归预测集评分： 0.740552064611524<br>线性回归训练集评分： 0.7422107889561247<br><br>LinearRegression(normalize = True, fit_intercept= True)<br>线性回归预测集评分： 0.740552064611524<br>线性回归训练集评分： 0.7422107889561247","like_count":12,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526345,"discussion_content":"置顶！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1630909425,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2750760,"avatar":"https://static001.geekbang.org/account/avatar/00/29/f9/28/dc7d0b76.jpg","nickname":"zzzzzlj","note":"","ucode":"C09537664B4DBC","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":392517,"discussion_content":"我也遇到了一样的问题！！感谢！！！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631025572,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":310807,"user_name":"茜茜","can_delete":false,"product_type":"c1","uid":2652053,"ip_address":"","ucode":"8861DD63536EEF","user_header":"https://static001.geekbang.org/account/avatar/00/28/77/95/0d10d4b2.jpg","comment_is_top":true,"comment_ctime":1630918514,"is_pvip":false,"replies":[{"id":"112632","content":"十分认真！","user_name":"作者回复","user_name_real":"黄佳","uid":"1809833","ctime":1630932270,"ip_address":"","comment_id":310807,"utype":1}],"discussion_count":4,"race_medal":0,"score":"9.2233720728454001e+18","product_id":100085501,"comment_content":"在方法2我使用了网格搜索自动调参，可以获得更好的预测评分。<br># 思考题;<br>from sklearn.model_selection import train_test_split<br>from sklearn.linear_model import LinearRegression <br>from sklearn.model_selection import GridSearchCV<br>import pandas as pd<br>import chardet<br>import itertools<br>#查询编码格式<br>with open(&#39;易速鲜花微信软文.csv&#39;, &#39;rb&#39;) as f:<br>    enc = chardet.detect(f.read())  # or readline if the file is large <br>#读取数据<br>df_ads = pd.read_csv(&#39;易速鲜花微信软文.csv&#39;, encoding = enc[&#39;encoding&#39;])<br># 判断空值<br>df_ads.isna().sum()<br># 删掉含空值的行<br>df_ads = df_ads.dropna()<br># 构建特征集和标签集<br>x = df_ads.drop([&#39;浏览量&#39;], axis = 1)<br>y = df_ads[&#39;浏览量&#39;]<br># 拆分训练集(80%)和测试集(20%)<br>xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = 0.2, random_state = 0)<br><br># 调参：方法一<br>fit_intercept_list = [True, False]<br>normalize_list = [True, False]<br>print(&#39;方法1&#39;)<br>for item in itertools.product(fit_intercept_list, fit_intercept_list):<br>    fit_intercept = item[0]<br>    normalize = item[1]<br>    # 训练模型<br>    linereg_model = LinearRegression(fit_intercept = fit_intercept, normalize = normalize)<br>    linereg_model.fit(xtrain, ytrain)<br>    # 预测测试集对的y值<br>    y_pred  = linereg_model.predict(xtest)<br>    # 给出模型评分(使用验证集)<br>    print(f&#39;参数组合; fit_intercept = {fit_intercept},normalize = {normalize}&#39;,&#39;线性回归预测评分:&#39;, linereg_model.score(xtest, ytest))  <br><br># 调参：方法2<br>model =  LinearRegression()<br># 建立需要搜索的参数的范围<br>param ={&#39;fit_intercept&#39;:[True, False],&#39;normalize&#39;: [True, False]}<br># 初始化网格搜索的方法<br>grid = GridSearchCV(model,param)<br>#用网格搜索方法进行拟合数据<br>grid.fit(x, y)<br># 输出最优的参数组合<br>print(&#39;方法2&#39;)<br>print(&#39;最佳模型的参数组合：&#39;, grid.best_params_)<br>print(&#39;样本得分平均值:&#39;,grid.best_score_)<br>print(&#39;最佳模型测预测评分：&#39;,grid.score(xtest, ytest))<br><br>#结论：<br>#1. 最佳参数组合是：{&#39;fit_intercept&#39;: True, &#39;normalize&#39;: True} 或 {&#39;fit_intercept&#39;: True, &#39;normalize&#39;: False}<br>#2. 方法2 的预测评分：0.75 高于方法1的预测评分：0.74","like_count":9,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526362,"discussion_content":"十分认真！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1630932270,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1037367,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/d4/37/bb19dbcd.jpg","nickname":"楼梯口倒立","note":"","ucode":"BE53FDB3A3F085","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":582721,"discussion_content":"{&#39;fit_intercept&#39;: True, &#39;normalize&#39;: False} 这不是默认值？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1659604894,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"美国"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2813087,"avatar":"https://static001.geekbang.org/account/avatar/00/2a/ec/9f/7fa3bf00.jpg","nickname":"Elaine","note":"","ucode":"BC35964F85B55B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":411026,"discussion_content":"小姐姐好强，但有个typo 应该是for item in itertools.product(fit_intercept_list, normalize_list): ","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1635833082,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1087879,"avatar":"https://static001.geekbang.org/account/avatar/00/10/99/87/98ebb20e.jpg","nickname":"dao","note":"","ucode":"4181FB270462CF","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":402408,"discussion_content":"为什么是 print(&#39;最佳模型测预测评分：&#39;,grid.score(xtest, ytest))，\n而不是 print(&#39;最佳模型测预测评分：&#39;,grid.score(x, y)) ？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633875817,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":310819,"user_name":"茜茜","can_delete":false,"product_type":"c1","uid":2652053,"ip_address":"","ucode":"8861DD63536EEF","user_header":"https://static001.geekbang.org/account/avatar/00/28/77/95/0d10d4b2.jpg","comment_is_top":true,"comment_ctime":1630922233,"is_pvip":false,"replies":[{"id":"112631","content":"看到你的答案里面已经用了GridSearchCV。很好，GridSearchCV，默认已经使用了5折交叉验证，就是其中的CV参数。那么我们原来不是说3个集吗，训练集，验证集，测试集。因为GridSearchCV有已经自带交叉验证的存在。就不再需要验证集了。<br>而测试集，还需要，目的是把GridSearchCV的交叉验证结果拿到测试集做最后测试。<br>好问题。谢谢。","user_name":"作者回复","user_name_real":"黄佳","uid":"1809833","ctime":1630932251,"ip_address":"","comment_id":310819,"utype":1}],"discussion_count":4,"race_medal":0,"score":"9.2233720599605002e+18","product_id":100085501,"comment_content":"黄老师，我有一个问题，在使用GridSearchCV前，需要划分训练集和测试集吗？按照什么比例划分呢？谢谢","like_count":6,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526367,"discussion_content":"看到你的答案里面已经用了GridSearchCV。很好，GridSearchCV，默认已经使用了5折交叉验证，就是其中的CV参数。那么我们原来不是说3个集吗，训练集，验证集，测试集。因为GridSearchCV有已经自带交叉验证的存在。就不再需要验证集了。\n而测试集，还需要，目的是把GridSearchCV的交叉验证结果拿到测试集做最后测试。\n好问题。谢谢。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1630932251,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1178201,"avatar":"https://static001.geekbang.org/account/avatar/00/11/fa/59/52a504f6.jpg","nickname":"u","note":"","ucode":"6FDCEA63AE67C3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":392423,"discussion_content":"同学，你为何如此优秀 👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631002002,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":2652053,"avatar":"https://static001.geekbang.org/account/avatar/00/28/77/95/0d10d4b2.jpg","nickname":"茜茜","note":"","ucode":"8861DD63536EEF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1178201,"avatar":"https://static001.geekbang.org/account/avatar/00/11/fa/59/52a504f6.jpg","nickname":"u","note":"","ucode":"6FDCEA63AE67C3","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":392466,"discussion_content":"你也很优秀^*^","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631013606,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":392423,"ip_address":""},"score":392466,"extra":""}]},{"author":{"id":2652053,"avatar":"https://static001.geekbang.org/account/avatar/00/28/77/95/0d10d4b2.jpg","nickname":"茜茜","note":"","ucode":"8861DD63536EEF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":392283,"discussion_content":"谢谢黄老师的指点，我明白了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1630933335,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":310973,"user_name":"u","can_delete":false,"product_type":"c1","uid":1178201,"ip_address":"","ucode":"6FDCEA63AE67C3","user_header":"https://static001.geekbang.org/account/avatar/00/11/fa/59/52a504f6.jpg","comment_is_top":false,"comment_ctime":1631006139,"is_pvip":false,"replies":[{"id":"112687","content":"👍","user_name":"作者回复","user_name_real":"黄佳","uid":"1809833","ctime":1631021844,"ip_address":"","comment_id":310973,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18810875323","product_id":100085501,"comment_content":"代码：<br><br>@pytest.mark.parametrize(&quot;fit_intercept&quot;, [True, False])<br>@pytest.mark.parametrize(&quot;normalize&quot;, [True, False])<br>def test_train_model(fit_intercept, normalize):<br>    df_cleaned = df_data.dropna()<br>    feature_set = df_cleaned.drop([&#39;浏览量&#39;], axis=1)<br>    label_set = df_cleaned[&#39;浏览量&#39;]<br>    x_train, x_test, y_train, y_test = train_test_split(feature_set, label_set,<br>                                                        train_size=0.8, test_size=0.2, random_state=0)<br>    line_reg_model = LR(fit_intercept=fit_intercept, normalize=normalize)<br>    line_reg_model.fit(x_train, y_train)<br>    y_pred = line_reg_model.predict(x_test)<br>    features = x_test.copy()<br>    features[&#39;真浏览量&#39;] = y_test<br>    features[&#39;预测浏览量&#39;] = y_pred<br>    print()<br>    print(&quot;===============fit_intercept=&quot;, fit_intercept, &quot;,normalize=&quot;, normalize, &quot;====================&quot;)<br>    print(&quot;模型的权重分别是：&quot;, line_reg_model.coef_)<br>    print(&quot;模型的截距是：&quot;, line_reg_model.intercept_)<br>    print(&quot;线性回归预测分数是：&quot;, line_reg_model.score(x_test, y_test))<br>    print(&quot;========================================&quot;)<br><br>","like_count":4,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526415,"discussion_content":"👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631021844,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":320904,"user_name":"🇱 、🇲","can_delete":false,"product_type":"c1","uid":2840148,"ip_address":"","ucode":"F709EA85196768","user_header":"https://static001.geekbang.org/account/avatar/00/2b/56/54/f8d9e6e0.jpg","comment_is_top":false,"comment_ctime":1636551190,"is_pvip":false,"replies":[{"id":"116877","content":"明佬群中解决了对吧，用inplace = True让删除语句直接修改原有df对象。","user_name":"作者回复","user_name_real":"编辑","uid":"1809833","ctime":1637075454,"ip_address":"","comment_id":320904,"utype":1}],"discussion_count":2,"race_medal":0,"score":"10226485782","product_id":100085501,"comment_content":"佳哥，我在删除nan的行之后，再统计NAN出现的次数，还是有nan。这就导致后面建模型，报错<br>ValueError: Input contains NaN, infinity or a value too large for dtype(&#39;float64&#39;).","like_count":2,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":530459,"discussion_content":"明佬群中解决了对吧，用inplace = True让删除语句直接修改原有df对象。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1637075454,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2840148,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/56/54/f8d9e6e0.jpg","nickname":"🇱 、🇲","note":"","ucode":"F709EA85196768","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":530701,"discussion_content":"嗯嗯，解决了，哈哈哈","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1637130317,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"user_type\":1}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":310759,"user_name":"GAC·DU","can_delete":false,"product_type":"c1","uid":1385403,"ip_address":"","ucode":"7847FBE1C13740","user_header":"https://static001.geekbang.org/account/avatar/00/15/23/bb/a1a61f7c.jpg","comment_is_top":false,"comment_ctime":1630895797,"is_pvip":true,"replies":[{"id":"112584","content":"课代表！","user_name":"作者回复","user_name_real":"黄佳","uid":"1809833","ctime":1630897874,"ip_address":"","comment_id":310759,"utype":1}],"discussion_count":3,"race_medal":0,"score":"10220830389","product_id":100085501,"comment_content":"对fit_intercept和normalize这两个参数做了一下测试，发现normalize的值是True还是False对模型评估的值几乎没有影响，但是fit_intercept的值如果为False对模型评估值影响较大，我用google colab进行的测试。","like_count":2,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526341,"discussion_content":"课代表！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1630897874,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1917715,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/43/13/649ccaa9.jpg","nickname":"海林Lin","note":"","ucode":"26333AE3DFAF9D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":392244,"discussion_content":"请教使用google colab需要梯子吗。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1630919988,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":1917715,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/43/13/649ccaa9.jpg","nickname":"海林Lin","note":"","ucode":"26333AE3DFAF9D","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":392277,"discussion_content":"估计需要科学上网 希望大家分享一下方法\nhttps://colab.research.google.com/","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1630931919,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":392244,"ip_address":""},"score":392277,"extra":""}]}]},{"had_liked":false,"id":310722,"user_name":"年轻","can_delete":false,"product_type":"c1","uid":1900044,"ip_address":"","ucode":"0EE1C7B82DD960","user_header":"https://static001.geekbang.org/account/avatar/00/1c/fe/0c/f5267835.jpg","comment_is_top":false,"comment_ctime":1630859762,"is_pvip":true,"replies":[{"id":"112558","content":"给力！后续内容更精彩，敬请期待。","user_name":"作者回复","user_name_real":"黄佳","uid":"1809833","ctime":1630861471,"ip_address":"","comment_id":310722,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10220794354","product_id":100085501,"comment_content":"👍👍👍👍👍👍👍👍👍👍👍👍👍👍👍👍👍👍👍👍👍👍👍👍","like_count":2,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526323,"discussion_content":"给力！后续内容更精彩，敬请期待。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1630861471,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":314615,"user_name":"河宣潮广","can_delete":false,"product_type":"c1","uid":2778064,"ip_address":"","ucode":"CD5B4AA2EF263D","user_header":"https://static001.geekbang.org/account/avatar/00/2a/63/d0/a0cc950d.jpg","comment_is_top":false,"comment_ctime":1633259083,"is_pvip":false,"replies":[{"id":"116868","content":"这里只是一个极简化了的示例，因此并没有明确计算公式。在具体的业务模型中，不同场景的业务指标都会有对应的计算方法，不过这并非这个示例的关注点。","user_name":"作者回复","user_name_real":"编辑","uid":"1809833","ctime":1637074001,"ip_address":"","comment_id":314615,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5928226379","product_id":100085501,"comment_content":"有个问题，请教老师，热度指数和其他几个变量是不是有明确的计算公式。","like_count":1,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":530434,"discussion_content":"这里只是一个极简化了的示例，因此并没有明确计算公式。在具体的业务模型中，不同场景的业务指标都会有对应的计算方法，不过这并非这个示例的关注点。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1637074001,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":311941,"user_name":"蝶舞清风寒","can_delete":false,"product_type":"c1","uid":2753090,"ip_address":"","ucode":"2818B4BE7DCC16","user_header":"https://static001.geekbang.org/account/avatar/00/2a/02/42/e8ef9639.jpg","comment_is_top":false,"comment_ctime":1631539831,"is_pvip":false,"replies":[{"id":"113041","content":"1、fit_intercept=True， bool型，默认为True，对训练数据进行中心化，false的话，说明数据已经进行中心化；------ 总结的很好哦！<br><br>2. normalize布尔型，默认为false，说明：是否对数据进行标准化处理；---- 我对文档的理解应该是对数据进行某种归一化缩放，（If True, the regressors X will be normalized before regression by subtracting the mean and dividing by the l2-norm. ），如果需要标准化，实现数据的正态分布，应该使用StandardScaler。 ---- 所以这个normalize和标准化（standardize）还是有区别的，这是我的理解。😁","user_name":"作者回复","user_name_real":"黄佳","uid":"1809833","ctime":1631551415,"ip_address":"","comment_id":311941,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5926507127","product_id":100085501,"comment_content":"线性回归函数：LinearRegression<br>1、fit_intercept=True， bool型，默认为True，对训练数据进行中心化，false的话，说明数据已经进行中心化；<br>2、 normalize布尔型，默认为false，说明：是否对数据进行标准化处理；<br>步骤：数据清洗、数据集成、数据变化、数据分析。<br>我理解这主要是为了数据变化，实现数据正态分布。<br>","like_count":2,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526809,"discussion_content":"1、fit_intercept=True， bool型，默认为True，对训练数据进行中心化，false的话，说明数据已经进行中心化；------ 总结的很好哦！\n\n2. normalize布尔型，默认为false，说明：是否对数据进行标准化处理；---- 我对文档的理解应该是对数据进行某种归一化缩放，（If True, the regressors X will be normalized before regression by subtracting the mean and dividing by the l2-norm. ），如果需要标准化，实现数据的正态分布，应该使用StandardScaler。 ---- 所以这个normalize和标准化（standardize）还是有区别的，这是我的理解。😁","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631551415,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2753090,"avatar":"https://static001.geekbang.org/account/avatar/00/2a/02/42/e8ef9639.jpg","nickname":"蝶舞清风寒","note":"","ucode":"2818B4BE7DCC16","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":394027,"discussion_content":"我是这样理解的，因为案例数据其实相关度很高，所以归一化看着没什么差别。每一列数据的范围不同，若是不归一化，对于数值范围很小的特征，其计算的w，权重就会偏小。\n这一块主要是根据您推荐的陈阳的数据课，第13部分分析的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631692502,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":311059,"user_name":"李冀","can_delete":false,"product_type":"c1","uid":1212032,"ip_address":"","ucode":"F393FA203B834C","user_header":"https://static001.geekbang.org/account/avatar/00/12/7e/80/be05419a.jpg","comment_is_top":false,"comment_ctime":1631058777,"is_pvip":false,"replies":[{"id":"112728","content":"好问题。其实很简单，通过Pred函数预测全体的Y&amp;#39;值，然后绘制标签X和全体预测值Y&amp;#39;（注意不是真值，是预测值Y帽）的散点图。不过你只能选择一个特征绘图，不可能绘制超过三维的图。","user_name":"作者回复","user_name_real":"黄佳","uid":"1809833","ctime":1631063677,"ip_address":"","comment_id":311059,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5926026073","product_id":100085501,"comment_content":"怎么可以可视化得到的模型呢","like_count":1,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526452,"discussion_content":"好问题。其实很简单，通过Pred函数预测全体的Y&amp;amp;#39;值，然后绘制标签X和全体预测值Y&amp;amp;#39;（注意不是真值，是预测值Y帽）的散点图。不过你只能选择一个特征绘图，不可能绘制超过三维的图。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631063677,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":344743,"user_name":"沙隆巴斯","can_delete":false,"product_type":"c1","uid":2992390,"ip_address":"","ucode":"0659DB32D27A23","user_header":"https://static001.geekbang.org/account/avatar/00/2d/a9/06/2527d639.jpg","comment_is_top":false,"comment_ctime":1651744850,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1651744850","product_id":100085501,"comment_content":"请问，范例的文章特征数据点赞量、转发量是在文章发布以后一段时间内收集得到，如果一篇新文章发布，此时是没有点赞数和转发数等数据的，这时该如何确定特征值？是否需要对文章内容进行识别，提取出特征值才能计算出结果呢？","like_count":0},{"had_liked":false,"id":342320,"user_name":"ZzzL","can_delete":false,"product_type":"c1","uid":2529532,"ip_address":"","ucode":"01B09ACD8BEF4E","user_header":"https://static001.geekbang.org/account/avatar/00/26/98/fc/df6a9ed7.jpg","comment_is_top":false,"comment_ctime":1650188337,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1650188337","product_id":100085501,"comment_content":"老师代码有点小错误。<br>在输出“当前模型的4个特征的权重”那里应该修改为（是linereg_model不是model）：<br>print(&#39;当前模型的4个特征的权重分别是: &#39;, linereg_model.coef_)<br>print(&#39;当前模型的截距（偏置）是: &#39;, linereg_model.intercept_)","like_count":1},{"had_liked":false,"id":323793,"user_name":"夏日🍉情缘","can_delete":false,"product_type":"c1","uid":2755497,"ip_address":"","ucode":"0BD258E390E537","user_header":"https://static001.geekbang.org/account/avatar/00/2a/0b/a9/ccacdd57.jpg","comment_is_top":false,"comment_ctime":1638164575,"is_pvip":false,"replies":[{"id":"118523","content":"具体的话请参考Github上的完整代码哈，反正前面定义的model变量名是啥，这里输出的时候就用啥就对了。","user_name":"作者回复","user_name_real":"编辑","uid":"1809833","ctime":1639498993,"ip_address":"","comment_id":323793,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1638164575","product_id":100085501,"comment_content":"老师，当运行如下这段代码的的时候：<br>print(&#39;当前模型的4个特征的权重分别是: &#39;, model.coef_)<br>print(&#39;当前模型的截距（偏置）是: &#39;, model.intercept_)<br><br>我这边并没有输出结果，而是报错了，说model没有定义，但是我也没看见你代码中有任何定义的地方<br><br>NameError: name &#39;model&#39; is not defined<br><br>请问下老师是怎么回事","like_count":0,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":538771,"discussion_content":"具体的话请参考Github上的完整代码哈，反正前面定义的model变量名是啥，这里输出的时候就用啥就对了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1639498993,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":311921,"user_name":"Jove","can_delete":false,"product_type":"c1","uid":1234583,"ip_address":"","ucode":"82CEFDC5F66073","user_header":"https://static001.geekbang.org/account/avatar/00/12/d6/97/035a237b.jpg","comment_is_top":false,"comment_ctime":1631531039,"is_pvip":true,"replies":[{"id":"113039","content":"🤟","user_name":"作者回复","user_name_real":"黄佳","uid":"1809833","ctime":1631550945,"ip_address":"","comment_id":311921,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1631531039","product_id":100085501,"comment_content":"预测值和实际值的绘图表示<br><br>plt.scatter(df_ads_pred.点赞数, df_ads_pred.浏览量真值, c=&#39;r&#39;, marker=&#39;o&#39;, label=&quot;true&quot;)<br>plt.scatter(df_ads_pred.点赞数, df_ads_pred.浏览量预测值, c=&#39;b&#39;, marker=&quot;x&quot;, label=&quot;pre&quot;)<br>plt.grid(True)  #网格<br>plt.xlabel(&quot;点赞数&quot;)<br>plt.ylabel(&quot;浏览量&quot;)<br>plt.legend(loc=&#39;upper right&#39;)  #图例的位置<br>plt.title(&quot;scatter view&quot;)","like_count":0,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526799,"discussion_content":"🤟","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631550945,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":310976,"user_name":"u","can_delete":false,"product_type":"c1","uid":1178201,"ip_address":"","ucode":"6FDCEA63AE67C3","user_header":"https://static001.geekbang.org/account/avatar/00/11/fa/59/52a504f6.jpg","comment_is_top":false,"comment_ctime":1631007123,"is_pvip":false,"replies":[{"id":"112686","content":"谢谢你的调研。非常好。<br>1. 的确，fit_intercept=False时，会忽略normalize参数。是这样的。<br>2. fit_intercept很简单啦，就是截距。<br>而normalize参数是什么意思呢？它翻译为规范化，属于特征缩放的一种，但是并不常见。文档中的解释是它将变量 X 将在回归之前通过减去均值并除以 l2 范数进行缩放。而这种缩放，可能对于特殊类型的数据集有用（文本分类的特征集），对我们这个数据集，意义不大。","user_name":"作者回复","user_name_real":"黄佳","uid":"1809833","ctime":1631021169,"ip_address":"","comment_id":310976,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1631007123","product_id":100085501,"comment_content":"输出结果：<br>MLTest.py::test_train_model[True-True] PASSED                            [ 25%]<br>===============fit_intercept= True ,normalize= True ====================<br>模型的权重分别是： [   48.08395224    34.73062229 29730.13312489  2949.62196343]<br>模型的截距是： -127493.90606857173<br>线性回归预测分数是： 0.740552064611524<br>========================================<br><br>MLTest.py::test_train_model[True-False] PASSED                           [ 50%]<br>===============fit_intercept= False ,normalize= True ====================<br>模型的权重分别是： [   49.22775653    24.7593051  22106.78160819 -9416.98488967]<br>模型的截距是： 0.0<br>线性回归预测分数是： 0.6894272355358542<br>========================================<br><br>MLTest.py::test_train_model[False-True] PASSED                           [ 75%]<br>===============fit_intercept= True ,normalize= False ====================<br>模型的权重分别是： [   48.08395224    34.73062229 29730.13312489  2949.62196343]<br>模型的截距是： -127493.90606857178<br>线性回归预测分数是： 0.740552064611524<br>========================================<br><br>MLTest.py::test_train_model[False-False] PASSED                          [100%]<br>===============fit_intercept= False ,normalize= False ====================<br>模型的权重分别是： [   49.22775653    24.7593051  22106.78160819 -9416.98488967]<br>模型的截距是： 0.0<br>线性回归预测分数是： 0.6894272355358542<br>========================================<br><br><br>说明：<br>看了LinearRegression的文档，fit_intercept=False时，会忽略normalize参数，所以结果只有三种；<br>而且fit_intercept=True时，normalize的值除了对截距有轻微影响，好像对其它内部参数并没有影响；<br><br><br>问题：<br>这两个参数是什么意思呢？老师给讲一下吧","like_count":0,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526418,"discussion_content":"谢谢你的调研。非常好。\n1. 的确，fit_intercept=False时，会忽略normalize参数。是这样的。\n2. fit_intercept很简单啦，就是截距。\n而normalize参数是什么意思呢？它翻译为规范化，属于特征缩放的一种，但是并不常见。文档中的解释是它将变量 X 将在回归之前通过减去均值并除以 l2 范数进行缩放。而这种缩放，可能对于特殊类型的数据集有用（文本分类的特征集），对我们这个数据集，意义不大。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631021169,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]}]}