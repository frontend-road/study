{"id":87071,"title":"43丨深度学习（下）：如何用Keras搭建深度学习网络做手写数字识别？","content":"<p>通过上节课的讲解，我们已经对神经网络和深度学习有了基本的了解。这节课我就用Keras这个深度学习框架做一个识别手写数字的练习。</p><p>你也许还有印象，在KNN算法那节中，我讲到过Mnist手写数字识别这个数据集，当时我们采用的是mini版的手写数字数据集。实际上完整版的Mnist一共有60000个训练样本和10000个测试样本，这么庞大的数据量更适合用深度学习框架完成训练。</p><p>今天的学习目标主要有以下的几个方面：</p><ol>\n<li>\n<p>进一步了解CNN网络。CNN网络在深度学习网络中应用很广，很多网络都是基于CNN网络构建的，你有必要进一步了解CNN的网络层次，尤其是关于卷积的原理。</p>\n</li>\n<li>\n<p>初步了解LeNet和AlexNet。它们都是经典的CNN网络，我们今天的任务就是认识这些经典的CNN网络，这样在接触更深度的CNN网络的时候，比如VGG、GoogleNet和ResNet这些网络的时候，就会更容易理解和使用。</p>\n</li>\n<li>\n<p>对常用的深度学习框架进行对比，包括Tensorflow、Keras、Caffe、PyTorch、 MXnet和Theano。当选择深度学习框架的时候到底该选择哪个？</p>\n</li>\n<li>\n<p>使用Keras这个深度学习框架编写代码，完成第一个深度学习任务，也就是Mnist手写数字识别。</p>\n</li>\n</ol><!-- [[[read_end]]] --><h2>如何理解CNN网络中的卷积作用</h2><p>CNN的网络结构由三种层组成，它们分别是卷积层、池化层和全连接层。</p><p>在上篇文章中，我讲到卷积层相当于滤镜的作用，它可以把图像分块，对每一块的图像进行卷积操作。</p><p>卷积本身是一种矩阵运算，那什么是卷积呢？</p><p>假设我有一个二维的图像X，和卷积K，把二维矩阵X进行卷积K操作之后，可以得到矩阵Z，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/9d/cf/9d1bb65b30517775b632c10c1cb1c0cf.jpg?wh=2697*1495\" alt=\"\"><br>\n我简单说下计算的原理。</p><p>第一步，我们需要将卷积核翻转180度（只有翻转之后才能做矩阵运算），也就是变成：</p><p><img src=\"https://static001.geekbang.org/resource/image/cb/33/cb755c0cf5868c39d71e0392146c4833.jpg?wh=704*692\" alt=\"\"><br>\n第二步，将卷积核的第一个元素，对准矩阵X左上角的第一个元素，对应元素相乘，然后再相加可以就可以得到10*1+10*1+10*0+10*1+5*0+5*-1+10*0+5*-1+5*-1=15。</p><p><img src=\"https://static001.geekbang.org/resource/image/90/11/90a3bbabba732a2a7ad97a24f3587411.jpg?wh=1454*908\" alt=\"\"><br>\n第三步，每个元素都重复第二步的计算过程，可以得到如下的矩阵结果Z：</p><p><img src=\"https://static001.geekbang.org/resource/image/b8/6c/b824778383e3a898fe2399fb2eb8846c.jpg?wh=647*686\" alt=\"\"><br>\n这样我们就完成了一个卷积的操作。如果编写代码的话，你可以这样写：</p><pre><code>import pylab\nimport numpy as np\nfrom scipy import signal\n# 设置原图像\nimg = np.array([[10, 10, 10, 10, 10],\n                     [10, 5, 5, 5, 10],\n                     [10, 5, 5, 5, 10],\n                     [10, 5, 5, 5, 10],\n                     [10, 10, 10, 10, 10]])\n# 设置卷积核\nfil = np.array([[ -1,-1, 0],\n                [ -1, 0, 1],\n                [  0, 1, 1]])\n# 对原图像进行卷积操作\nres = signal.convolve2d(img, fil, mode='valid')\n# 输出卷积后的结果\nprint(res)\n</code></pre><p>运行结果：</p><pre><code>[[ 15  10   0]\n [ 10   0 -10]\n [  0 -10 -15]]\n</code></pre><p>这里我用到了convolve2d函数对图像img和卷积核fil做卷积运算，最后输出结果res。你可能还是会问，为什么我们要对图像进行卷积操作呢？你可以看看下面一段代码：</p><pre><code>import matplotlib.pyplot as plt\nimport pylab\nimport cv2\nimport numpy as np\nfrom scipy import signal\n# 读取灰度图像\nimg = cv2.imread(&quot;haibao.jpg&quot;, 0)\n# 显示灰度图像\nplt.imshow(img,cmap=&quot;gray&quot;)\npylab.show()\n# 设置卷积核\nfil = np.array([[ -1,-1, 0],\n                [ -1, 0, 1],\n                [  0, 1, 1]])\n# 卷积操作\nres = signal.convolve2d(img, fil, mode='valid')\nprint(res)\n#显示卷积后的图片\nplt.imshow(res,cmap=&quot;gray&quot;)\npylab.show()\n</code></pre><p>运行结果：</p><p><img src=\"https://static001.geekbang.org/resource/image/56/1d/562a68ac064736a6c00fab3808578b1d.png?wh=813*1259\" alt=\"\"></p><p><img src=\"https://static001.geekbang.org/resource/image/ec/2c/ecac01b4b72f0b5132294e3cfb9d562c.png?wh=828*1288\" alt=\"\"></p><p>这里我对专栏的海报做了卷积的操作，你能看到卷积操作是对图像进行了特征的提取。实际上每个卷积核都是一种滤波器，它们把图像中符合条件的部分筛选出来，也就相当于做了某种特征提取。</p><p>在CNN的卷积层中可以有多个卷积核，以LeNet为例，它的第一层卷积核有6个，因此可以帮我们提取出图像的6个特征，从而得到6个特征图（feature maps）。</p><h3>激活函数的作用</h3><p>做完卷积操作之后，通常还需要使用激活函数对图像进一步处理。在逻辑回归中，我提到过Sigmoid函数，它在深度学习中有广泛的应用，除了Sigmoid函数作为激活函数以外，tanh、ReLU都是常用的激活函数。</p><p>这些激活函数通常都是非线性的函数，使用它们的目的是把线性数值映射到非线性空间中。卷积操作实际上是两个矩阵之间的乘法，得到的结果也是线性的。只有经过非线性的激活函数运算之后，才能映射到非线性空间中，这样也可以让神经网络的表达能力更强大。</p><h3>池化层的作用</h3><p>池化层通常在两个卷积层之间，它的作用相当于对神经元的数据做降维处理，这样就能降低整体计算量。</p><p>假设池化的窗大小是2x2，就相当于用一个2x2的窗口对输出数据进行计算，将原图中2x2矩阵的4个点变成一个点。常用的池化操作是平均池化和最大池化。平均池化是对特征点求平均值，也就是用4个点的平均值来做代表。最大池化则是对特征点求最大值，也就是用4个点的最大值来做代表。</p><p>在神经网络中，我们可以叠加多个卷积层和池化层来提取更抽象的特征。经过几次卷积和池化之后，通常会有一个或多个全连接层。</p><h3>全连接层的作用</h3><p>全连接层将前面一层的输出结果与当前层的每个神经元都进行了连接。</p><p>这样就可以把前面计算出来的所有特征，通过全连接层将输出值输送给分类器，比如Softmax分类器。在深度学习中，Softmax是个很有用的分类器，通过它可以把输入值映射到0-1之间，而且所有输出结果相加等于1。其实你可以换种方式理解这个概念，假设我们想要识别一个数字，从0到9都有可能。那么通过Softmax层，对应输出10种分类结果，每个结果都有一个概率值，这些概率相加为1，我们就可以知道这个数字是0的概率是多少，是1的概率是多少……是9的概率又是多少，从而也就帮我们完成了数字识别的任务。</p><h2>LeNet和AlexNet网络</h2><p>你能看出CNN网络结构中每一层的作用：它通过卷积层提取特征，通过激活函数让结果映射到非线性空间，增强了结果的表达能力，再通过池化层压缩特征图，降低了网络复杂度，最后通过全连接层归一化，然后连接Softmax分类器进行计算每个类别的概率。</p><p>通常我们可以使用多个卷积层和池化层，最后再连接一个或者多个全连接层，这样也就产生了不同的网络结构，比如LeNet和AlexNet。</p><p>我将LeNet和AlexNet的参数特征整理如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/dd/d1/dd0dbbcd6797bf9560c306025ee6fbd1.png?wh=580*105\" alt=\"\"><br>\nLeNet提出于1986年，是最早用于数字识别的CNN网络，输入尺寸是32*32。它输入的是灰度的图像，整个的网络结构是：输入层→C1卷积层→S2池化层→C3卷积层→S4池化层→C5卷积层→F6全连接层→Output全连接层，对应的Output输出类别数为10。</p><p>AlexNet在LeNet的基础上做了改进，提出了更深的CNN网络模型，输入尺寸是227*227*3，可以输入RGB三通道的图像，整个网络的结构是：输入层→(C1卷积层→池化层)→(C2卷积层→池化层)→C3卷积层→C4卷积层→(C5池化层→池化层)→全连接层→全连接层→Output全连接层。</p><p>实际上后面提出来的深度模型，比如VGG、GoogleNet和ResNet都是基于下面的这种结构方式改进的：输出层→（卷积层+ -&gt; 池化层？）+ → 全连接层+→Output全连接层。</p><p>其中“+”代表1个或多个，“？”代表0个或1个。</p><p>你能看出卷积层后面可以有一个池化层，也可以没有池化层，“卷积层+ → 池化层？”这样的结构算是一组卷积层，在多组卷积层之后，可以连接多个全连接层，最后再接Output全连接层。</p><h2>常用的深度学习框架对比</h2><p>了解了CNN的网络结构之后，我们来看下常用的深度学习框架都有哪些。</p><p>下面这张图是常用框架的简单对比。</p><p><img src=\"https://static001.geekbang.org/resource/image/ea/67/ea523df67c73d19732df1d172b30fd67.png?wh=493*227\" alt=\"\"><br>\n从GitHub上的热门程序排序来看，Tensorflow、Keras和Caffe是三个排名最高的深度学习框架，其中Tensorflow是Google出品，也是深度学习最常用的库。关于Keras，你可以理解成是把Tensorflow或Theano作为后端，基于它们提供的封装接口，这样更方便我们操作使用。Caffe、PyTorch、MXNet和Theano也是常用的深度学习库，你在接触深度学习的时候可能也会遇到，这里不做介绍。</p><p>如果你刚进入深度学习这个领域，我更建议你直接使用Keras，因为它使用方便，更加友好，可以方便我们快速构建网络模型，不需要过多关注底层细节。</p><h2>用Keras做Mnist手写数字识别</h2><p>Keras也是基于Python语言的。在使用Keras之前，我们需要安装相应的工具包：</p><pre><code>pip install keras\npip install tensorflow\n</code></pre><p>这里需要注明的是Keras需要用tensorflow或者theano作为后端，因此我们也需要引入相关的工具。同时你还需要注意NumPy版本是否为最新的版本，我们需要采用最新的NumPy版本才能正常运行keras，更新NumPy工具的方法：</p><pre><code>pip install -U numpy\n</code></pre><p>安装好Keras工具包之后，就可以创建一个Sequential序贯模型，它的作用是将多个网络层线性堆叠起来，使用方法：</p><pre><code>from keras.models import Sequential\nmodel = Sequential()\n</code></pre><p>然后就可以在网络中添加各种层了。</p><h3>创建二维卷积层</h3><p>使用Conv2D(filters, kernel_size, activation=None)进行创建,其中filters代表卷积核的数量，kernel_size代表卷积核的宽度和长度，activation代表激活函数。如果创建的二维卷积层是第一个卷积层，我们还需要提供input_shape参数，比如：input_shape=(28, 28, 1)代表的就是28*28的灰度图像。</p><h3>对2D信号做最大池化层</h3><p>使用MaxPooling2D(pool_size=(2, 2))进行创建，其中pool_size代表下采样因子，比如pool_size=(2,2)的时候相当于将原来2<em>2的矩阵变成一个点，即用2</em>2矩阵中的最大值代替，输出的图像在长度和宽度上均为原图的一半。</p><h3>创建Flatten层</h3><p>使用Flatten()创建，常用于将多维的输入扁平化，也就是展开为一维的向量。一般用在卷积层与全连接层之间，方便后面进行全连接层的操作。</p><h3>创建全连接层</h3><p>使用Dense(units, activation=None)进行创建，其中units代表的是输出的空间维度，activation代表的激活函数。</p><p>我这里只列举了部分常用的层，这些层在今天手写数字识别的项目中会用到。当我们把层创建好之后，可以加入到模型中，使用model.add()函数即可。</p><p>添加好网络模型中的层之后，我们可以使用model.compile(loss, optimizer=‘adam’, metrics=[‘accuracy’])来完成损失函数和优化器的配置，其中loss代表损失函数的配置，optimizer代表优化器，metrics代表评估模型所采用的指标。</p><p>然后我们可以使用fit函数进行训练，使用predict函数进行预测，使用evaluate函数对模型评估。</p><p>针对Mnist手写数字识别，用keras的实现代码如下：</p><pre><code># 使用LeNet模型对Mnist手写数字进行识别\nimport keras\nfrom keras.datasets import mnist\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Dense, Flatten\nfrom keras.models import Sequential\n# 数据加载\n(train_x, train_y), (test_x, test_y) = mnist.load_data()\n# 输入数据为 mnist 数据集\ntrain_x = train_x.reshape(train_x.shape[0], 28, 28, 1)\ntest_x = test_x.reshape(test_x.shape[0], 28, 28, 1)\ntrain_x = train_x / 255\ntest_x = test_x / 255\ntrain_y = keras.utils.to_categorical(train_y, 10)\ntest_y = keras.utils.to_categorical(test_y, 10)\n# 创建序贯模型\nmodel = Sequential()\n# 第一层卷积层：6个卷积核，大小为5∗5, relu激活函数\nmodel.add(Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1)))\n# 第二层池化层：最大池化\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n# 第三层卷积层：16个卷积核，大小为5*5，relu激活函数\nmodel.add(Conv2D(16, kernel_size=(5, 5), activation='relu'))\n# 第二层池化层：最大池化\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n# 将参数进行扁平化，在LeNet5中称之为卷积层，实际上这一层是一维向量，和全连接层一样\nmodel.add(Flatten())\nmodel.add(Dense(120, activation='relu'))\n# 全连接层，输出节点个数为84个\nmodel.add(Dense(84, activation='relu'))\n# 输出层 用softmax 激活函数计算分类概率\nmodel.add(Dense(10, activation='softmax'))\n# 设置损失函数和优化器配置\nmodel.compile(loss=keras.metrics.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n# 传入训练数据进行训练\nmodel.fit(train_x, train_y, batch_size=128, epochs=2, verbose=1, validation_data=(test_x, test_y))\n# 对结果进行评估\nscore = model.evaluate(test_x, test_y)\nprint('误差:%0.4lf' %score[0])\nprint('准确率:', score[1])\n</code></pre><p>运行结果：</p><pre><code>……（省略中间迭代的结算结果，即显示每次迭代的误差loss和准确率acc）\n误差:0.0699\n准确率: 0.9776\n</code></pre><p>我用epochs控制了训练的次数，当训练2遍的时候，准确率达到97.76%，还是很高的。</p><h2>总结</h2><p>今天我们用keras对手写数字进行了识别，具体的代码部分讲解的不多，其中涉及到API，你可以参考下Keras中文手册。</p><p>在这个过程里，我们只是使用了LeNet的网络模型，实际上AlexNet、VGG、GoogleNet和ResNet都是基于CNN的网络结构。在CNN网络中包括了卷积层、池化层和全连接层。一个基于CNN的深度学习网络通常是几组卷积层之后，再连接多个全连接层，最后再接Output全连接层，而每组的卷积层都是“卷积层+ →池化层？”的结构。</p><p>另外，通过今天的学习你应该能体会到卷积在图像领域中的应用。今天我对专栏的海报进行了一个3*3的卷积核操作，可以看到卷积之后得到的图像是原图像某种特征的提取。在实际的卷积层中，会包括多个卷积核，对原图像在不同特征上进行提取。通过多个卷积层的操作，可以在更高的维度上对图像特征进一步提取，这样可以让机器在不同层次、不同维度理解图像特征。</p><p>另外在Keras使用中，你能看到与sklearn中的机器学习算法使用不同。我们需要对网络模型中的层进行配置，将创建好的层添加到模型中，然后对模型中使用的损失函数和优化器进行配置，最后就可以对它进行训练和预测了。</p><p><img src=\"https://static001.geekbang.org/resource/image/43/39/431ccdf001d421b3810e03c9c598b539.png?wh=1728*1495\" alt=\"\"><br>\n今天讲的知识点比较多，其中我讲到了卷积、卷积核和卷积层，你能说一下对这三者的理解吗？你之前有使用Keras或Tensorflow的经验么，你能否谈谈你的使用感受？</p><p>欢迎你在评论区与我分享你的答案，也欢迎点击“请朋友读”，把这篇文章分享给你的朋友或者同事。</p><p></p>","neighbors":{"left":{"article_title":"42丨当我们谈深度学习的时候，我们都在谈什么？","id":86582},"right":{"article_title":"44丨如何培养你的数据分析思维？","id":87240}},"comments":[{"had_liked":false,"id":78738,"user_name":"third","can_delete":false,"product_type":"c1","uid":1025114,"ip_address":"","ucode":"9A37408A834F0B","user_header":"https://static001.geekbang.org/account/avatar/00/0f/a4/5a/e708e423.jpg","comment_is_top":false,"comment_ctime":1553226704,"is_pvip":false,"replies":[{"id":64386,"content":"对的","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577618130,"ip_address":"","comment_id":78738,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"卷积是一种操作，就像是过滤这个动作。\n卷积核是卷积的一层滤网，\n多个卷积核形成一个卷积层\n卷积层像一个过滤层，过滤掉不需要的杂质","like_count":12},{"had_liked":false,"id":210449,"user_name":"JustDoDT","can_delete":false,"product_type":"c1","uid":1127175,"ip_address":"","ucode":"6AF0B80F00EAEF","user_header":"https://static001.geekbang.org/account/avatar/00/11/33/07/8f351609.jpg","comment_is_top":false,"comment_ctime":1587746126,"is_pvip":false,"replies":[{"id":103971,"content":"是的，在Python第三方库的仓库https:&#47;&#47;pypi.org&#47;中，OpenCV的安装包名称为opencv-python，调用时，名称是cv2","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1617289018,"ip_address":"","comment_id":210449,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"在python中，要使用OpenCV，要安装cv的package。在python代码中，看到import cv2。但pip install 的名称不是cv2、或者Opencv，而是opencv-python.\n\n执行：\n\npip install opencv-python","like_count":10,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":444217,"discussion_content":"对的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577618130,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":91015,"user_name":"滨滨","can_delete":false,"product_type":"c1","uid":1334567,"ip_address":"","ucode":"881EFA798BEE34","user_header":"https://static001.geekbang.org/account/avatar/00/14/5d/27/74e152d3.jpg","comment_is_top":false,"comment_ctime":1556788118,"is_pvip":false,"replies":[{"id":64204,"content":"整理总结不错","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577614210,"ip_address":"","comment_id":91015,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"1、卷积是矩阵运算。图像中不同数据窗口的数据和卷积核（一个滤波矩阵）作内积的操作叫做卷积。\n2、卷积核就是图像处理时，给定输入图像，在输出图像中每一个像素是输入图像中一个小区域中像素的加权平均，其中权值由一个函数定义，这个函数称为卷积核。\n3、卷积层：多个滤波器叠加便成了卷积层。","like_count":5,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493022,"discussion_content":"是的，在Python第三方库的仓库https://pypi.org/中，OpenCV的安装包名称为opencv-python，调用时，名称是cv2","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617289018,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":82091,"user_name":"林","can_delete":false,"product_type":"c1","uid":1256841,"ip_address":"","ucode":"A33AB4C8DE5646","user_header":"https://static001.geekbang.org/account/avatar/00/13/2d/89/a01375a1.jpg","comment_is_top":false,"comment_ctime":1554117475,"is_pvip":false,"replies":[{"id":64323,"content":"谢谢林，深度这个变化太快了","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577616886,"ip_address":"","comment_id":82091,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"讲的真好，希望老师也能出深度学习的课程","like_count":5,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":445464,"discussion_content":"谢谢林，深度这个变化太快了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577616886,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":87708,"user_name":"浩然","can_delete":false,"product_type":"c1","uid":1295043,"ip_address":"","ucode":"D1FB4E3E7ADE5F","user_header":"https://static001.geekbang.org/account/avatar/00/13/c2/c3/da31c9c2.jpg","comment_is_top":false,"comment_ctime":1555665576,"is_pvip":false,"replies":[{"id":64238,"content":"对的","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577615049,"ip_address":"","comment_id":87708,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"至于为什么要翻转，举个例子，假如图像是这样： 0 0 0 1 0 ；卷积核是这样： 1 2 3，如果不翻转，结果就是 0 3 2 1 0，发现结果是反的。如果卷积核翻转成 3 2 1 ，那么结果就是 0 1 2 3 0 ，是正的。","like_count":4,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":445464,"discussion_content":"谢谢林，深度这个变化太快了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577616886,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":262250,"user_name":"厚积薄发","can_delete":false,"product_type":"c1","uid":1206674,"ip_address":"","ucode":"8640C07176C249","user_header":"https://static001.geekbang.org/account/avatar/00/12/69/92/69c2c135.jpg","comment_is_top":false,"comment_ctime":1605673697,"is_pvip":false,"replies":[{"id":100892,"content":"总结的不错，继续坚持","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1612706491,"ip_address":"","comment_id":262250,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"深度学习手写体数字识别\n1.卷积，卷积核，卷积层的理解\n卷积：是一种特殊的内积操作，先对卷积核进行180度的旋转，然后从第一个像素点依次与卷积核做内积操作。\n卷积核：对图像做卷积操作的权重参数\n卷积层：一个或多个卷积组成的过滤网\n\n卷积的作用：提取特征，内积操作，把数据映射到线性空间。\n激活函数的作用：把线性空间映射到非线性空间，让神经网络具有更强的表达能力\n池化层的作用：对神经元的数据进行降维，降低的计算量\n全连接层的作用：前一层的输出结果与当前神经元全部进行相连，做最后一层的分类任务，比如softmax","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":447571,"discussion_content":"对的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577615049,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":131487,"user_name":"Lisa","can_delete":false,"product_type":"c1","uid":1622750,"ip_address":"","ucode":"9879032355DC55","user_header":"https://static001.geekbang.org/account/avatar/00/18/c2/de/98cd7728.jpg","comment_is_top":false,"comment_ctime":1567764887,"is_pvip":false,"replies":[{"id":53380,"content":"这个是LeNet-5的模型，3个全连接层的输出维度分别是120，84，10。都是确定好的，直接使用就好了","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1570431157,"ip_address":"","comment_id":131487,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"老师，配置每个层的时候填的数字有什么一般规律或范围吗？比如全连接层为什么填120呢？为什么填84呢？\n\nmodel.add(Dense(120, activation=&#39;relu&#39;))\nmodel.add(Dense(84, activation=&#39;relu&#39;))","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509749,"discussion_content":"总结的不错，继续坚持","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1612706491,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":91011,"user_name":"滨滨","can_delete":false,"product_type":"c1","uid":1334567,"ip_address":"","ucode":"881EFA798BEE34","user_header":"https://static001.geekbang.org/account/avatar/00/14/5d/27/74e152d3.jpg","comment_is_top":false,"comment_ctime":1556786865,"is_pvip":false,"replies":[{"id":64205,"content":"Good Sharing","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577614218,"ip_address":"","comment_id":91011,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"CNN 网络结构中每一层的作用：它通过卷积层提取特征，通过激活函数让结果映射到非线性空间，增强了结果的表达能力，再通过池化层压缩特征图，降低了网络复杂度，最后通过全连接层归一化，然后连接 Softmax 分类器进行计算每个类别的概率。","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":466479,"discussion_content":"这个是LeNet-5的模型，3个全连接层的输出维度分别是120，84，10。都是确定好的，直接使用就好了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570431157,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1914504,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/36/88/20b6a6ee.jpg","nickname":"Simon","note":"","ucode":"A8A2E3E57BD029","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":233723,"discussion_content":"全连接层神经元个数可以改动。具体到LeNet，由于是10分类，最后一个全连接层必须是10。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586941365,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":90037,"user_name":"滢","can_delete":false,"product_type":"c1","uid":1221511,"ip_address":"","ucode":"971A6F20AF3F9A","user_header":"https://static001.geekbang.org/account/avatar/00/12/a3/87/c415e370.jpg","comment_is_top":false,"comment_ctime":1556376371,"is_pvip":false,"replies":[{"id":64212,"content":"对的 理解的很好","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577614365,"ip_address":"","comment_id":90037,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"个人对于卷积、卷积核、卷积层的理解是：\n卷积是一种做内积运算的操作；\n卷积核就是要做内积运算的规则；\n卷积层是融合了一个或多个卷积核（即多个运算规则）的过滤网络","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":448365,"discussion_content":"对的 理解的很好","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577614365,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":78731,"user_name":"Geek_hve78z","can_delete":false,"product_type":"c1","uid":1015045,"ip_address":"","ucode":"386803B8FC2DD5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg","comment_is_top":false,"comment_ctime":1553225525,"is_pvip":false,"replies":[{"id":64378,"content":"多谢分享","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577618034,"ip_address":"","comment_id":78731,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"参考链接：https:&#47;&#47;www.cnblogs.com&#47;readingintheway&#47;p&#47;4977669.html\n卷积核为何要翻转才能计算的原因：\n所谓的翻转只是因为你站立的现在是过去的未来，而因为h(t)始终不变，故h(1)其实是前一秒的h(1)，而前一秒的h(1)就是现在，所以从当前x(4)的角度往左看，你看到的是过去的作用。h(t)未翻转前，当从h(0)往右看，你看到的是现在对于未来的影响，当翻转h(t)之后，从h(0)往左看，你依次看到的越来越远的过去对现在的影响，而这个影响，与从x=4向左看的作用影响相对应（都是越来越远的过去），作用与作用的响应就对应起来了，这一切的本质，是因为你站立的时间观察点和方向在变。","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":448365,"discussion_content":"对的 理解的很好","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577614365,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":78738,"user_name":"third","can_delete":false,"product_type":"c1","uid":1025114,"ip_address":"","ucode":"9A37408A834F0B","user_header":"https://static001.geekbang.org/account/avatar/00/0f/a4/5a/e708e423.jpg","comment_is_top":false,"comment_ctime":1553226704,"is_pvip":false,"replies":[{"id":64386,"content":"对的","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577618130,"ip_address":"","comment_id":78738,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"卷积是一种操作，就像是过滤这个动作。\n卷积核是卷积的一层滤网，\n多个卷积核形成一个卷积层\n卷积层像一个过滤层，过滤掉不需要的杂质","like_count":12,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":444217,"discussion_content":"对的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577618130,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":210449,"user_name":"JustDoDT","can_delete":false,"product_type":"c1","uid":1127175,"ip_address":"","ucode":"6AF0B80F00EAEF","user_header":"https://static001.geekbang.org/account/avatar/00/11/33/07/8f351609.jpg","comment_is_top":false,"comment_ctime":1587746126,"is_pvip":false,"replies":[{"id":103971,"content":"是的，在Python第三方库的仓库https:&#47;&#47;pypi.org&#47;中，OpenCV的安装包名称为opencv-python，调用时，名称是cv2","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1617289018,"ip_address":"","comment_id":210449,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"在python中，要使用OpenCV，要安装cv的package。在python代码中，看到import cv2。但pip install 的名称不是cv2、或者Opencv，而是opencv-python.\n\n执行：\n\npip install opencv-python","like_count":10,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493022,"discussion_content":"是的，在Python第三方库的仓库https://pypi.org/中，OpenCV的安装包名称为opencv-python，调用时，名称是cv2","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617289018,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":91015,"user_name":"滨滨","can_delete":false,"product_type":"c1","uid":1334567,"ip_address":"","ucode":"881EFA798BEE34","user_header":"https://static001.geekbang.org/account/avatar/00/14/5d/27/74e152d3.jpg","comment_is_top":false,"comment_ctime":1556788118,"is_pvip":false,"replies":[{"id":64204,"content":"整理总结不错","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577614210,"ip_address":"","comment_id":91015,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"1、卷积是矩阵运算。图像中不同数据窗口的数据和卷积核（一个滤波矩阵）作内积的操作叫做卷积。\n2、卷积核就是图像处理时，给定输入图像，在输出图像中每一个像素是输入图像中一个小区域中像素的加权平均，其中权值由一个函数定义，这个函数称为卷积核。\n3、卷积层：多个滤波器叠加便成了卷积层。","like_count":5,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":448764,"discussion_content":"整理总结不错","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577614210,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":82091,"user_name":"林","can_delete":false,"product_type":"c1","uid":1256841,"ip_address":"","ucode":"A33AB4C8DE5646","user_header":"https://static001.geekbang.org/account/avatar/00/13/2d/89/a01375a1.jpg","comment_is_top":false,"comment_ctime":1554117475,"is_pvip":false,"replies":[{"id":64323,"content":"谢谢林，深度这个变化太快了","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577616886,"ip_address":"","comment_id":82091,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"讲的真好，希望老师也能出深度学习的课程","like_count":5,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":448764,"discussion_content":"整理总结不错","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577614210,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":87708,"user_name":"浩然","can_delete":false,"product_type":"c1","uid":1295043,"ip_address":"","ucode":"D1FB4E3E7ADE5F","user_header":"https://static001.geekbang.org/account/avatar/00/13/c2/c3/da31c9c2.jpg","comment_is_top":false,"comment_ctime":1555665576,"is_pvip":false,"replies":[{"id":64238,"content":"对的","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577615049,"ip_address":"","comment_id":87708,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"至于为什么要翻转，举个例子，假如图像是这样： 0 0 0 1 0 ；卷积核是这样： 1 2 3，如果不翻转，结果就是 0 3 2 1 0，发现结果是反的。如果卷积核翻转成 3 2 1 ，那么结果就是 0 1 2 3 0 ，是正的。","like_count":4,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":447571,"discussion_content":"对的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577615049,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":262250,"user_name":"厚积薄发","can_delete":false,"product_type":"c1","uid":1206674,"ip_address":"","ucode":"8640C07176C249","user_header":"https://static001.geekbang.org/account/avatar/00/12/69/92/69c2c135.jpg","comment_is_top":false,"comment_ctime":1605673697,"is_pvip":false,"replies":[{"id":100892,"content":"总结的不错，继续坚持","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1612706491,"ip_address":"","comment_id":262250,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"深度学习手写体数字识别\n1.卷积，卷积核，卷积层的理解\n卷积：是一种特殊的内积操作，先对卷积核进行180度的旋转，然后从第一个像素点依次与卷积核做内积操作。\n卷积核：对图像做卷积操作的权重参数\n卷积层：一个或多个卷积组成的过滤网\n\n卷积的作用：提取特征，内积操作，把数据映射到线性空间。\n激活函数的作用：把线性空间映射到非线性空间，让神经网络具有更强的表达能力\n池化层的作用：对神经元的数据进行降维，降低的计算量\n全连接层的作用：前一层的输出结果与当前神经元全部进行相连，做最后一层的分类任务，比如softmax","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509749,"discussion_content":"总结的不错，继续坚持","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1612706491,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":131487,"user_name":"Lisa","can_delete":false,"product_type":"c1","uid":1622750,"ip_address":"","ucode":"9879032355DC55","user_header":"https://static001.geekbang.org/account/avatar/00/18/c2/de/98cd7728.jpg","comment_is_top":false,"comment_ctime":1567764887,"is_pvip":false,"replies":[{"id":53380,"content":"这个是LeNet-5的模型，3个全连接层的输出维度分别是120，84，10。都是确定好的，直接使用就好了","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1570431157,"ip_address":"","comment_id":131487,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"老师，配置每个层的时候填的数字有什么一般规律或范围吗？比如全连接层为什么填120呢？为什么填84呢？\n\nmodel.add(Dense(120, activation=&#39;relu&#39;))\nmodel.add(Dense(84, activation=&#39;relu&#39;))","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":466479,"discussion_content":"这个是LeNet-5的模型，3个全连接层的输出维度分别是120，84，10。都是确定好的，直接使用就好了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570431157,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1914504,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/36/88/20b6a6ee.jpg","nickname":"Simon","note":"","ucode":"A8A2E3E57BD029","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":233723,"discussion_content":"全连接层神经元个数可以改动。具体到LeNet，由于是10分类，最后一个全连接层必须是10。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586941365,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":91011,"user_name":"滨滨","can_delete":false,"product_type":"c1","uid":1334567,"ip_address":"","ucode":"881EFA798BEE34","user_header":"https://static001.geekbang.org/account/avatar/00/14/5d/27/74e152d3.jpg","comment_is_top":false,"comment_ctime":1556786865,"is_pvip":false,"replies":[{"id":64205,"content":"Good Sharing","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577614218,"ip_address":"","comment_id":91011,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"CNN 网络结构中每一层的作用：它通过卷积层提取特征，通过激活函数让结果映射到非线性空间，增强了结果的表达能力，再通过池化层压缩特征图，降低了网络复杂度，最后通过全连接层归一化，然后连接 Softmax 分类器进行计算每个类别的概率。","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":448763,"discussion_content":"Good Sharing","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577614218,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":90037,"user_name":"滢","can_delete":false,"product_type":"c1","uid":1221511,"ip_address":"","ucode":"971A6F20AF3F9A","user_header":"https://static001.geekbang.org/account/avatar/00/12/a3/87/c415e370.jpg","comment_is_top":false,"comment_ctime":1556376371,"is_pvip":false,"replies":[{"id":64212,"content":"对的 理解的很好","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577614365,"ip_address":"","comment_id":90037,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"个人对于卷积、卷积核、卷积层的理解是：\n卷积是一种做内积运算的操作；\n卷积核就是要做内积运算的规则；\n卷积层是融合了一个或多个卷积核（即多个运算规则）的过滤网络","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":448763,"discussion_content":"Good Sharing","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577614218,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":78731,"user_name":"Geek_hve78z","can_delete":false,"product_type":"c1","uid":1015045,"ip_address":"","ucode":"386803B8FC2DD5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg","comment_is_top":false,"comment_ctime":1553225525,"is_pvip":false,"replies":[{"id":64378,"content":"多谢分享","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577618034,"ip_address":"","comment_id":78731,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"参考链接：https:&#47;&#47;www.cnblogs.com&#47;readingintheway&#47;p&#47;4977669.html\n卷积核为何要翻转才能计算的原因：\n所谓的翻转只是因为你站立的现在是过去的未来，而因为h(t)始终不变，故h(1)其实是前一秒的h(1)，而前一秒的h(1)就是现在，所以从当前x(4)的角度往左看，你看到的是过去的作用。h(t)未翻转前，当从h(0)往右看，你看到的是现在对于未来的影响，当翻转h(t)之后，从h(0)往左看，你依次看到的越来越远的过去对现在的影响，而这个影响，与从x=4向左看的作用影响相对应（都是越来越远的过去），作用与作用的响应就对应起来了，这一切的本质，是因为你站立的时间观察点和方向在变。","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":444214,"discussion_content":"多谢分享","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577618034,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":85603,"user_name":"Switch","can_delete":false,"product_type":"c1","uid":1250758,"ip_address":"","ucode":"EB9FFA94D2F24B","user_header":"https://static001.geekbang.org/account/avatar/00/13/15/c6/f5c543ef.jpg","comment_is_top":false,"comment_ctime":1555138694,"is_pvip":false,"replies":[{"id":64265,"content":"可以Model Serving","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577615675,"ip_address":"","comment_id":85603,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"老师，训练出来的模型，怎么用于实际使用呢？","like_count":1},{"had_liked":false,"id":78721,"user_name":"zy","can_delete":false,"product_type":"c1","uid":1353192,"ip_address":"","ucode":"63055CBE8804F8","user_header":"https://static001.geekbang.org/account/avatar/00/14/a5/e8/ca96d759.jpg","comment_is_top":false,"comment_ctime":1553224058,"is_pvip":false,"replies":[{"id":64379,"content":"哈哈 不错zy","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577618043,"ip_address":"","comment_id":78721,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"我是用pytorch，这几天的内容好熟悉呀","like_count":1,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":444207,"discussion_content":"哈哈 不错zy","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577618043,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":78720,"user_name":"Geek_hve78z","can_delete":false,"product_type":"c1","uid":1015045,"ip_address":"","ucode":"386803B8FC2DD5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg","comment_is_top":false,"comment_ctime":1553224052,"is_pvip":false,"replies":[{"id":64380,"content":"多谢分享","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577618048,"ip_address":"","comment_id":78720,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"参考链接：https:&#47;&#47;blog.csdn.net&#47;cheneykl&#47;article&#47;details&#47;79740810\n\n1、卷积是矩阵运算。图像中不同数据窗口的数据和卷积核（一个滤波矩阵）作内积的操作叫做卷积。\n2、卷积核就是图像处理时，给定输入图像，在输出图像中每一个像素是输入图像中一个小区域中像素的加权平均，其中权值由一个函数定义，这个函数称为卷积核。\n3、卷积层：多个滤波器叠加便成了卷积层。","like_count":1,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":444206,"discussion_content":"多谢分享","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577618048,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":214141,"user_name":"开心哥","can_delete":false,"product_type":"c1","uid":1705468,"ip_address":"","ucode":"D44C1F03B23C5A","user_header":"https://static001.geekbang.org/account/avatar/00/1a/05/fc/bceb3f2b.jpg","comment_is_top":false,"comment_ctime":1588665471,"is_pvip":false,"replies":[{"id":103762,"content":"图像数据中元素值为0-255之间，所以通过&#47;255进行归一化。","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1617041446,"ip_address":"","comment_id":214141,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"train_x = train_x &#47; 255   &#47;&#47; 这个是要干啥？","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493966,"discussion_content":"图像数据中元素值为0-255之间，所以通过/255进行归一化。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617041446,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":85344,"user_name":"mickey","can_delete":false,"product_type":"c1","uid":1051663,"ip_address":"","ucode":"8B490C2DDE4010","user_header":"https://static001.geekbang.org/account/avatar/00/10/0c/0f/93d1c8eb.jpg","comment_is_top":false,"comment_ctime":1555040855,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"请教以下几个问题：\n1、卷积核是怎么来的？\n2、为什么卷积核要翻转180度？为什么不一开始就设置为已经转好的？\n3、为什么要做这样乘？其背后的数学理论、思想和原理是什么？","like_count":15},{"had_liked":false,"id":87705,"user_name":"浩然","can_delete":false,"product_type":"c1","uid":1295043,"ip_address":"","ucode":"D1FB4E3E7ADE5F","user_header":"https://static001.geekbang.org/account/avatar/00/13/c2/c3/da31c9c2.jpg","comment_is_top":false,"comment_ctime":1555665160,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"1、不同的卷积核应该对应不用的图像操作，比如可以通过改变卷积核实现图像锐化等操作\n2、不旋转180的操作是滤波器，旋转后是卷积\n","like_count":5},{"had_liked":false,"id":198736,"user_name":"张贺","can_delete":false,"product_type":"c1","uid":1283181,"ip_address":"","ucode":"0254E40FB3EB5F","user_header":"https://static001.geekbang.org/account/avatar/00/13/94/6d/5cd6e8c7.jpg","comment_is_top":false,"comment_ctime":1585466147,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"keras大概就是对tensorflow的再封装","like_count":2},{"had_liked":false,"id":302276,"user_name":"wanghao","can_delete":false,"product_type":"c1","uid":1639349,"ip_address":"","ucode":"A0EABFBEFC28B4","user_header":"https://static001.geekbang.org/account/avatar/00/19/03/b5/61258e9b.jpg","comment_is_top":false,"comment_ctime":1626153643,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"文章可以系列了解一下各个知识点内容，但确实授人以渔的内容","like_count":1},{"had_liked":false,"id":89939,"user_name":"滢","can_delete":false,"product_type":"c1","uid":1221511,"ip_address":"","ucode":"971A6F20AF3F9A","user_header":"https://static001.geekbang.org/account/avatar/00/12/a3/87/c415e370.jpg","comment_is_top":false,"comment_ctime":1556338556,"is_pvip":false,"replies":null,"discussion_count":2,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"有个疑问，卷积核翻转180度后，应该是\n1     1     0\n1     0    -1\n0    -1   -1\n但是在做运算的时候 ，为何成了\n10*1   10*1  10*1\n10*1   5*0   5*-1\n10*0   5*-1 5 *-1\n第一行第三个数不应该是10*0 吗 ？ 想问下这里是在怎么回事嘛？刚接触神经网络，对卷积还不太了解","like_count":0,"discussions":[{"author":{"id":1018685,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/8b/3d/0c3a2fd4.jpg","nickname":"偶尔复活下","note":"","ucode":"18B1D525CD50D3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":294141,"discussion_content":"在图像中应该是写错了 不过结果是对的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1595808378,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1488280,"avatar":"https://static001.geekbang.org/account/avatar/00/16/b5/98/ffaf2aca.jpg","nickname":"Ronnyz","note":"","ucode":"9F34527B1D343D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":70398,"discussion_content":"根据求和结果可以算出，第三个数确实是0，应该是图片出了点小错误","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1575352898,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":82851,"user_name":"我不造⊙_⊙","can_delete":false,"product_type":"c1","uid":1451221,"ip_address":"","ucode":"B3D66DF36DBB31","user_header":"https://static001.geekbang.org/account/avatar/00/16/24/d5/04d68bc0.jpg","comment_is_top":false,"comment_ctime":1554339529,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"老师，对于多列文字的数据，想要分析出字段之间的关联关系应该怎么做啊？","like_count":0,"discussions":[{"author":{"id":1914504,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/36/88/20b6a6ee.jpg","nickname":"Simon","note":"","ucode":"A8A2E3E57BD029","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":233379,"discussion_content":"先word embedding，再计算相似度？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586922008,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":85603,"user_name":"Switch","can_delete":false,"product_type":"c1","uid":1250758,"ip_address":"","ucode":"EB9FFA94D2F24B","user_header":"https://static001.geekbang.org/account/avatar/00/13/15/c6/f5c543ef.jpg","comment_is_top":false,"comment_ctime":1555138694,"is_pvip":false,"replies":[{"id":64265,"content":"可以Model Serving","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577615675,"ip_address":"","comment_id":85603,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"老师，训练出来的模型，怎么用于实际使用呢？","like_count":1,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":446730,"discussion_content":"可以Model Serving","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577615675,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":78721,"user_name":"zy","can_delete":false,"product_type":"c1","uid":1353192,"ip_address":"","ucode":"63055CBE8804F8","user_header":"https://static001.geekbang.org/account/avatar/00/14/a5/e8/ca96d759.jpg","comment_is_top":false,"comment_ctime":1553224058,"is_pvip":false,"replies":[{"id":64379,"content":"哈哈 不错zy","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577618043,"ip_address":"","comment_id":78721,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"我是用pytorch，这几天的内容好熟悉呀","like_count":1,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":446730,"discussion_content":"可以Model Serving","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577615675,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":78720,"user_name":"Geek_hve78z","can_delete":false,"product_type":"c1","uid":1015045,"ip_address":"","ucode":"386803B8FC2DD5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg","comment_is_top":false,"comment_ctime":1553224052,"is_pvip":false,"replies":[{"id":64380,"content":"多谢分享","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577618048,"ip_address":"","comment_id":78720,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"参考链接：https:&#47;&#47;blog.csdn.net&#47;cheneykl&#47;article&#47;details&#47;79740810\n\n1、卷积是矩阵运算。图像中不同数据窗口的数据和卷积核（一个滤波矩阵）作内积的操作叫做卷积。\n2、卷积核就是图像处理时，给定输入图像，在输出图像中每一个像素是输入图像中一个小区域中像素的加权平均，其中权值由一个函数定义，这个函数称为卷积核。\n3、卷积层：多个滤波器叠加便成了卷积层。","like_count":1,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":444207,"discussion_content":"哈哈 不错zy","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577618043,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":214141,"user_name":"开心哥","can_delete":false,"product_type":"c1","uid":1705468,"ip_address":"","ucode":"D44C1F03B23C5A","user_header":"https://static001.geekbang.org/account/avatar/00/1a/05/fc/bceb3f2b.jpg","comment_is_top":false,"comment_ctime":1588665471,"is_pvip":false,"replies":[{"id":103762,"content":"图像数据中元素值为0-255之间，所以通过&#47;255进行归一化。","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1617041446,"ip_address":"","comment_id":214141,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"train_x = train_x &#47; 255   &#47;&#47; 这个是要干啥？","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":444206,"discussion_content":"多谢分享","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577618048,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":85344,"user_name":"mickey","can_delete":false,"product_type":"c1","uid":1051663,"ip_address":"","ucode":"8B490C2DDE4010","user_header":"https://static001.geekbang.org/account/avatar/00/10/0c/0f/93d1c8eb.jpg","comment_is_top":false,"comment_ctime":1555040855,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"请教以下几个问题：\n1、卷积核是怎么来的？\n2、为什么卷积核要翻转180度？为什么不一开始就设置为已经转好的？\n3、为什么要做这样乘？其背后的数学理论、思想和原理是什么？","like_count":15},{"had_liked":false,"id":87705,"user_name":"浩然","can_delete":false,"product_type":"c1","uid":1295043,"ip_address":"","ucode":"D1FB4E3E7ADE5F","user_header":"https://static001.geekbang.org/account/avatar/00/13/c2/c3/da31c9c2.jpg","comment_is_top":false,"comment_ctime":1555665160,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"1、不同的卷积核应该对应不用的图像操作，比如可以通过改变卷积核实现图像锐化等操作\n2、不旋转180的操作是滤波器，旋转后是卷积\n","like_count":5},{"had_liked":false,"id":198736,"user_name":"张贺","can_delete":false,"product_type":"c1","uid":1283181,"ip_address":"","ucode":"0254E40FB3EB5F","user_header":"https://static001.geekbang.org/account/avatar/00/13/94/6d/5cd6e8c7.jpg","comment_is_top":false,"comment_ctime":1585466147,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"keras大概就是对tensorflow的再封装","like_count":2},{"had_liked":false,"id":302276,"user_name":"wanghao","can_delete":false,"product_type":"c1","uid":1639349,"ip_address":"","ucode":"A0EABFBEFC28B4","user_header":"https://static001.geekbang.org/account/avatar/00/19/03/b5/61258e9b.jpg","comment_is_top":false,"comment_ctime":1626153643,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"文章可以系列了解一下各个知识点内容，但确实授人以渔的内容","like_count":1},{"had_liked":false,"id":89939,"user_name":"滢","can_delete":false,"product_type":"c1","uid":1221511,"ip_address":"","ucode":"971A6F20AF3F9A","user_header":"https://static001.geekbang.org/account/avatar/00/12/a3/87/c415e370.jpg","comment_is_top":false,"comment_ctime":1556338556,"is_pvip":false,"replies":null,"discussion_count":2,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"有个疑问，卷积核翻转180度后，应该是\n1     1     0\n1     0    -1\n0    -1   -1\n但是在做运算的时候 ，为何成了\n10*1   10*1  10*1\n10*1   5*0   5*-1\n10*0   5*-1 5 *-1\n第一行第三个数不应该是10*0 吗 ？ 想问下这里是在怎么回事嘛？刚接触神经网络，对卷积还不太了解","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493966,"discussion_content":"图像数据中元素值为0-255之间，所以通过/255进行归一化。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617041446,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":82851,"user_name":"我不造⊙_⊙","can_delete":false,"product_type":"c1","uid":1451221,"ip_address":"","ucode":"B3D66DF36DBB31","user_header":"https://static001.geekbang.org/account/avatar/00/16/24/d5/04d68bc0.jpg","comment_is_top":false,"comment_ctime":1554339529,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"老师，对于多列文字的数据，想要分析出字段之间的关联关系应该怎么做啊？","like_count":0,"discussions":[{"author":{"id":1018685,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/8b/3d/0c3a2fd4.jpg","nickname":"偶尔复活下","note":"","ucode":"18B1D525CD50D3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":294141,"discussion_content":"在图像中应该是写错了 不过结果是对的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1595808378,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1488280,"avatar":"https://static001.geekbang.org/account/avatar/00/16/b5/98/ffaf2aca.jpg","nickname":"Ronnyz","note":"","ucode":"9F34527B1D343D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":70398,"discussion_content":"根据求和结果可以算出，第三个数确实是0，应该是图片出了点小错误","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1575352898,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":78748,"user_name":"深白浅黑","can_delete":false,"product_type":"c1","uid":1123923,"ip_address":"","ucode":"DCCAA31DE8B127","user_header":"https://static001.geekbang.org/account/avatar/00/11/26/53/60fe31fb.jpg","comment_is_top":false,"comment_ctime":1553229227,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"CNN卷积网络神经结构\nCNN卷积网络由三种层次构成，分别是卷积层、池化层和全连接层。\n卷积\n卷积是一种举证运算，在深度学习中，以图像识别为例，个人理解可以把卷积操作理解为，提取矩阵数据特征的一种手段。\n卷积核\n在进行卷积操作时，会用到卷积核，在图像识别中，个人理解可以将卷积核理解为一种滤波器，可以将图像中符合卷积核特性的特征进行提取。\n卷积层\n卷积层的作用是提取数据多维特征，方法是：使用卷积核，运用矩阵相乘的方式对二维数据进行卷积运算，提取数据的特征。通常卷积层使用多个卷积核，提取数据中的多种数据特征。\n\n问题：\n1、在卷积层与池化层之间，需要使用激活函数对数据体征进行非线性变换，对于激活函数的选取，有没有详细的说明，或者说，哪些激活函数适用于哪些非线性变化的情况？\n2、有没有其他的实际项目经验，可以分享o(∩_∩)o ","like_count":0},{"had_liked":false,"id":78748,"user_name":"深白浅黑","can_delete":false,"product_type":"c1","uid":1123923,"ip_address":"","ucode":"DCCAA31DE8B127","user_header":"https://static001.geekbang.org/account/avatar/00/11/26/53/60fe31fb.jpg","comment_is_top":false,"comment_ctime":1553229227,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"CNN卷积网络神经结构\nCNN卷积网络由三种层次构成，分别是卷积层、池化层和全连接层。\n卷积\n卷积是一种举证运算，在深度学习中，以图像识别为例，个人理解可以把卷积操作理解为，提取矩阵数据特征的一种手段。\n卷积核\n在进行卷积操作时，会用到卷积核，在图像识别中，个人理解可以将卷积核理解为一种滤波器，可以将图像中符合卷积核特性的特征进行提取。\n卷积层\n卷积层的作用是提取数据多维特征，方法是：使用卷积核，运用矩阵相乘的方式对二维数据进行卷积运算，提取数据的特征。通常卷积层使用多个卷积核，提取数据中的多种数据特征。\n\n问题：\n1、在卷积层与池化层之间，需要使用激活函数对数据体征进行非线性变换，对于激活函数的选取，有没有详细的说明，或者说，哪些激活函数适用于哪些非线性变化的情况？\n2、有没有其他的实际项目经验，可以分享o(∩_∩)o ","like_count":0,"discussions":[{"author":{"id":1914504,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/36/88/20b6a6ee.jpg","nickname":"Simon","note":"","ucode":"A8A2E3E57BD029","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":233384,"discussion_content":"通常，relu。不易梯度消失和梯度膨胀即可。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586922079,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}