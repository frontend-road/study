{"id":80983,"title":"24丨KNN（上）：如何根据打斗和接吻次数来划分电影类型？","content":"<p>今天我来带你进行KNN的学习，KNN的英文叫K-Nearest Neighbor，应该算是数据挖掘算法中最简单的一种。</p><p>我们先用一个例子体会下。</p><p>假设，我们想对电影的类型进行分类，统计了电影中打斗次数、接吻次数，当然还有其他的指标也可以被统计到，如下表所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/6d/87/6dac3a9961e69aa86d80de32bdc00987.png?wh=1134*440\" alt=\"\"><br>\n我们很容易理解《战狼》《红海行动》《碟中谍6》是动作片，《前任3》《春娇救志明》《泰坦尼克号》是爱情片，但是有没有一种方法让机器也可以掌握这个分类的规则，当有一部新电影的时候，也可以对它的类型自动分类呢？</p><p>我们可以把打斗次数看成X轴，接吻次数看成Y轴，然后在二维的坐标轴上，对这几部电影进行标记，如下图所示。对于未知的电影A，坐标为(x,y)，我们需要看下离电影A最近的都有哪些电影，这些电影中的大多数属于哪个分类，那么电影A就属于哪个分类。实际操作中，我们还需要确定一个K值，也就是我们要观察离电影A最近的电影有多少个。</p><p><img src=\"https://static001.geekbang.org/resource/image/fa/cc/fa0aa02dae219b21de5984371950c3cc.png?wh=674*388\" alt=\"\"></p><h2>KNN的工作原理</h2><p>“近朱者赤，近墨者黑”可以说是KNN的工作原理。整个计算过程分为三步：</p><ol>\n<li>\n<p>计算待分类物体与其他物体之间的距离；</p>\n</li>\n<li>\n<p>统计距离最近的K个邻居；</p>\n</li>\n<li>\n<p>对于K个最近的邻居，它们属于哪个分类最多，待分类物体就属于哪一类。</p>\n</li>\n</ol><p><strong>K值如何选择</strong></p><p>你能看出整个KNN的分类过程，K值的选择还是很重要的。那么问题来了，K值选择多少是适合的呢？</p><!-- [[[read_end]]] --><p>如果 K 值比较小，就相当于未分类物体与它的邻居非常接近才行。这样产生的一个问题就是，如果邻居点是个噪声点，那么未分类物体的分类也会产生误差，这样KNN分类就会产生过拟合。</p><p>如果K值比较大，相当于距离过远的点也会对未知物体的分类产生影响，虽然这种情况的好处是鲁棒性强，但是不足也很明显，会产生欠拟合情况，也就是没有把未分类物体真正分类出来。</p><p>所以K值应该是个实践出来的结果，并不是我们事先而定的。在工程上，我们一般采用交叉验证的方式选取 K 值。</p><p>交叉验证的思路就是，把样本集中的大部分样本作为训练集，剩余的小部分样本用于预测，来验证分类模型的准确性。所以在KNN算法中，我们一般会把K值选取在较小的范围内，同时在验证集上准确率最高的那一个最终确定作为K值。</p><p><strong>距离如何计算</strong></p><p>在KNN算法中，还有一个重要的计算就是关于距离的度量。两个样本点之间的距离代表了这两个样本之间的相似度。距离越大，差异性越大；距离越小，相似度越大。</p><p>关于距离的计算方式有下面五种方式：</p><ol>\n<li>\n<p>欧氏距离；</p>\n</li>\n<li>\n<p>曼哈顿距离；</p>\n</li>\n<li>\n<p>闵可夫斯基距离；</p>\n</li>\n<li>\n<p>切比雪夫距离；</p>\n</li>\n<li>\n<p>余弦距离。</p>\n</li>\n</ol><p>其中前三种距离是KNN中最常用的距离，我给你分别讲解下。</p><p><strong>欧氏距离</strong>是我们最常用的距离公式，也叫做欧几里得距离。在二维空间中，两点的欧式距离就是：</p><p><img src=\"https://static001.geekbang.org/resource/image/f8/80/f8d4fe58ec9580a4ffad5cee263b1b80.png?wh=748*162\" alt=\"\"><br>\n同理，我们也可以求得两点在n维空间中的距离：</p><p><img src=\"https://static001.geekbang.org/resource/image/40/6a/40efe7cb4a2571e55438b55f8d37366a.png?wh=1262*190\" alt=\"\"><br>\n<strong>曼哈顿距离</strong>在几何空间中用的比较多。以下图为例，绿色的直线代表两点之间的欧式距离，而红色和黄色的线为两点的曼哈顿距离。所以曼哈顿距离等于两个点在坐标系上绝对轴距总和。用公式表示就是：</p><p><img src=\"https://static001.geekbang.org/resource/image/bd/aa/bda520e8ee34ea19df8dbad3da85faaa.png?wh=582*112\" alt=\"\"></p><p><img src=\"https://static001.geekbang.org/resource/image/dd/43/dd19ca4f0be3f60b526e9ea0b7d13543.jpg?wh=1467*1500\" alt=\"\"><br>\n<strong>闵可夫斯基距离</strong>不是一个距离，而是一组距离的定义。对于n维空间中的两个点 x(x1,x2,…,xn) 和 y(y1,y2,…,yn) ， x 和 y 两点之间的闵可夫斯基距离为：</p><p><img src=\"https://static001.geekbang.org/resource/image/4d/c5/4d614c3d6722c02e4ea03cb1e6653dc5.png?wh=516*238\" alt=\"\"><br>\n其中p代表空间的维数，当p=1时，就是曼哈顿距离；当p=2时，就是欧氏距离；当p→∞时，就是切比雪夫距离。</p><p><strong>那么切比雪夫距离</strong>怎么计算呢？二个点之间的切比雪夫距离就是这两个点坐标数值差的绝对值的最大值，用数学表示就是：max(|x1-y1|,|x2-y2|)。</p><p><strong>余弦距离</strong>实际上计算的是两个向量的夹角，是在方向上计算两者之间的差异，对绝对数值不敏感。在兴趣相关性比较上，角度关系比距离的绝对值更重要，因此余弦距离可以用于衡量用户对内容兴趣的区分度。比如我们用搜索引擎搜索某个关键词，它还会给你推荐其他的相关搜索，这些推荐的关键词就是采用余弦距离计算得出的。</p><h2>KD树</h2><p>其实从上文你也能看出来，KNN的计算过程是大量计算样本点之间的距离。为了减少计算距离次数，提升KNN的搜索效率，人们提出了KD树（K-Dimensional的缩写）。KD树是对数据点在K维空间中划分的一种数据结构。在KD树的构造中，每个节点都是k维数值点的二叉树。既然是二叉树，就可以采用二叉树的增删改查操作，这样就大大提升了搜索效率。</p><p>在这里，我们不需要对KD树的数学原理了解太多，你只需要知道它是一个二叉树的数据结构，方便存储K维空间的数据就可以了。而且在sklearn中，我们直接可以调用KD树，很方便。</p><h2>用KNN做回归</h2><p>KNN不仅可以做分类，还可以做回归。首先讲下什么是回归。在开头电影这个案例中，如果想要对未知电影进行类型划分，这是一个分类问题。首先看一下要分类的未知电影，离它最近的K部电影大多数属于哪个分类，这部电影就属于哪个分类。</p><p>如果是一部新电影，已知它是爱情片，想要知道它的打斗次数、接吻次数可能是多少，这就是一个回归问题。</p><p>那么KNN如何做回归呢？</p><p>对于一个新电影X，我们要预测它的某个属性值，比如打斗次数，具体特征属性和数值如下所示。此时，我们会先计算待测点（新电影X）到已知点的距离，选择距离最近的K个点。假设K=3，此时最近的3个点（电影）分别是《战狼》，《红海行动》和《碟中谍6》，那么它的打斗次数就是这3个点的该属性值的平均值，即(100+95+105)/3=100次。</p><p><img src=\"https://static001.geekbang.org/resource/image/35/16/35dc8cc7d781c94b0fbaa0b53c01f716.png?wh=890*396\" alt=\"\"></p><h2>总结</h2><p>今天我给你讲了KNN的原理，以及KNN中的几个关键因素。比如针对K值的选择，我们一般采用交叉验证的方式得出。针对样本点之间的距离的定义，常用的有5种表达方式，你也可以自己来定义两个样本之间的距离公式。不同的定义，适用的场景不同。比如在搜索关键词推荐中，余弦距离是更为常用的。</p><p>另外你也可以用KNN进行回归，通过K个邻居对新的点的属性进行值的预测。</p><p>KNN的理论简单直接，针对KNN中的搜索也有相应的KD树这个数据结构。KNN的理论成熟，可以应用到线性和非线性的分类问题中，也可以用于回归分析。</p><p>不过KNN需要计算测试点与样本点之间的距离，当数据量大的时候，计算量是非常庞大的，需要大量的存储空间和计算时间。另外如果样本分类不均衡，比如有些分类的样本非常少，那么该类别的分类准确率就会低很多。</p><p>当然在实际工作中，我们需要考虑到各种可能存在的情况，比如针对某类样本少的情况，可以增加该类别的权重。</p><p>同样KNN也可以用于推荐算法，虽然现在很多推荐系统的算法会使用TD-IDF、协同过滤、Apriori算法，不过针对数据量不大的情况下，采用KNN作为推荐算法也是可行的。</p><p><img src=\"https://static001.geekbang.org/resource/image/d6/0f/d67073bef9247e1ca7a58ae7869f390f.png?wh=1172*1017\" alt=\"\"><br>\n最后我给你留几道思考题吧，KNN的算法原理和工作流程是怎么样的？KNN中的K值又是如何选择的？</p><h2>上一篇文章思考题的代码</h2><p>我在上篇文章里留了一道思考题，你可以在<a href=\"http://github.com/cystanford/breast_cancer_data\">GitHub</a>上看到我写的关于这道题的代码（完整代码和文章案例代码差别不大），供你借鉴。</p><p><img src=\"https://static001.geekbang.org/resource/image/fa/44/fa09558150152cdb250e715ae9047544.png?wh=618*286\" alt=\"\"></p><p>欢迎你在评论区与我分享你的答案，也欢迎点击“请朋友读”，把这篇文章分享给你的朋友或者同事。</p><p></p>","neighbors":{"left":{"article_title":"23丨SVM（下）：如何进行乳腺癌检测？","id":80712},"right":{"article_title":"25丨KNN（下）：如何对手写数字进行识别？","id":81018}},"comments":[{"had_liked":false,"id":67292,"user_name":"白夜","can_delete":false,"product_type":"c1","uid":1354449,"ip_address":"","ucode":"7AABFA7C04EA34","user_header":"https://static001.geekbang.org/account/avatar/00/14/aa/d1/076482f3.jpg","comment_is_top":true,"comment_ctime":1550125208,"is_pvip":false,"replies":[{"id":23807,"content":"我之前在微信群里说过这个问题，这个主要是因为后面有个n维空间，所以我定义的两个点分别是(x1,x2,...,xn)和(y1,y2,...,yn)。所以你看到的公式是用|x1-y1|+|x2-y2|，看起来会和我们之前学到的不一样，关键还是在于对点的定义上。你能理解公式的含义即可，另外这里主要是考虑到不光是2维的空间，如果是2维，3维我可以用字母来表示，比如用x,y,z，但是更多的维度，我在文章里是会用x1,x2,...,xn来表示一个点的定义。","user_name":"编辑回复","user_name_real":"何昌梅","uid":1165037,"ctime":1550134947,"ip_address":"","comment_id":67292,"utype":2}],"discussion_count":4,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"曼哈顿距离写错了吧？ 应该d=|X1-X2|+|Y1-Y2|吧","like_count":18},{"had_liked":false,"id":65489,"user_name":"Python","can_delete":false,"product_type":"c1","uid":1276314,"ip_address":"","ucode":"969500D2A88AE6","user_header":"https://static001.geekbang.org/account/avatar/00/13/79/9a/4f907ad6.jpg","comment_is_top":false,"comment_ctime":1549414745,"is_pvip":false,"replies":[{"id":40572,"content":"Kaggle上有些项目还是不错的\n信用卡欺诈交易分类预测 https:&#47;&#47;www.kaggle.com&#47;mlg-ulb&#47;creditcardfraud\n比特币趋势分析\nhttps:&#47;&#47;www.kaggle.com&#47;mczielinski&#47;bitcoin-historical-data\n宇宙中的脉冲星预测 https:&#47;&#47;www.kaggle.com&#47;pavanraj159&#47;predicting-a-pulsar-star\n西班牙高铁票价 https:&#47;&#47;www.kaggle.com&#47;thegurus&#47;spanish-high-speed-rail-system-ticket-pricing\n我列举了几个，Kaggle上有不少项目值得练习和研究，基本上你可以从Datasets和Kernels里面按照Hotness排序，找一下热门的项目，同时如果是初学者，有一些标签也可以参考，比如beginner, tutorial这种的。另外你也可以根据算法来检索比如：SVM, decision tree等","user_name":"编辑回复","user_name_real":"何昌梅","uid":1165037,"ctime":1562555699,"ip_address":"","comment_id":65489,"utype":2}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"老师，能不能推荐一下kaggle上谁的项目能让我们学习。","like_count":28,"discussions":[{"author":{"id":1165037,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c6/ed/89a2dc13.jpg","nickname":"丢了个丢丢丢","note":"","ucode":"BDD7E97E0E5E96","race_medal":0,"user_type":4,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438469,"discussion_content":"Kaggle上有些项目还是不错的\n信用卡欺诈交易分类预测 https://www.kaggle.com/mlg-ulb/creditcardfraud\n比特币趋势分析\nhttps://www.kaggle.com/mczielinski/bitcoin-historical-data\n宇宙中的脉冲星预测 https://www.kaggle.com/pavanraj159/predicting-a-pulsar-star\n西班牙高铁票价 https://www.kaggle.com/thegurus/spanish-high-speed-rail-system-ticket-pricing\n我列举了几个，Kaggle上有不少项目值得练习和研究，基本上你可以从Datasets和Kernels里面按照Hotness排序，找一下热门的项目，同时如果是初学者，有一些标签也可以参考，比如beginner, tutorial这种的。另外你也可以根据算法来检索比如：SVM, decision tree等","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1562555699,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":4}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":65483,"user_name":"Python","can_delete":false,"product_type":"c1","uid":1276314,"ip_address":"","ucode":"969500D2A88AE6","user_header":"https://static001.geekbang.org/account/avatar/00/13/79/9a/4f907ad6.jpg","comment_is_top":false,"comment_ctime":1549411527,"is_pvip":false,"replies":[{"id":40573,"content":"对的，K值是个实践出来的结果，不是事先而定的","user_name":"编辑回复","user_name_real":"何昌梅","uid":1165037,"ctime":1562555736,"ip_address":"","comment_id":65483,"utype":2}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"k越少就会越拟合，越多则越不拟合。最后就是为了寻找k的数值","like_count":9,"discussions":[{"author":{"id":1165037,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c6/ed/89a2dc13.jpg","nickname":"丢了个丢丢丢","note":"","ucode":"BDD7E97E0E5E96","race_medal":0,"user_type":4,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438469,"discussion_content":"Kaggle上有些项目还是不错的\n信用卡欺诈交易分类预测 https://www.kaggle.com/mlg-ulb/creditcardfraud\n比特币趋势分析\nhttps://www.kaggle.com/mczielinski/bitcoin-historical-data\n宇宙中的脉冲星预测 https://www.kaggle.com/pavanraj159/predicting-a-pulsar-star\n西班牙高铁票价 https://www.kaggle.com/thegurus/spanish-high-speed-rail-system-ticket-pricing\n我列举了几个，Kaggle上有不少项目值得练习和研究，基本上你可以从Datasets和Kernels里面按照Hotness排序，找一下热门的项目，同时如果是初学者，有一些标签也可以参考，比如beginner, tutorial这种的。另外你也可以根据算法来检索比如：SVM, decision tree等","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1562555699,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":4}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":67540,"user_name":"FORWARD―MOUNT","can_delete":false,"product_type":"c1","uid":1357857,"ip_address":"","ucode":"CD8E9ECF882980","user_header":"https://static001.geekbang.org/account/avatar/00/14/b8/21/c03839f1.jpg","comment_is_top":false,"comment_ctime":1550194780,"is_pvip":false,"replies":[{"id":40577,"content":"一个很好的问题，回归一般是预测某个属性值，这个属性值是连续型的，而不是离散型的。如果是离散型的就变成了分类问题。比如\n对于这个待测点的已知属性值，我们先计算这个待测点与已知点的距离，然后选择最近的K个点。这样也就是知道了这个待测点和哪K个已知点最接近。那么这个待测点的未知属性值就等于这K个点的该属性值的平均值","user_name":"编辑回复","user_name_real":"何昌梅","uid":1165037,"ctime":1562555892,"ip_address":"","comment_id":67540,"utype":2}],"discussion_count":3,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"KNN回归，既然已经知道某部电影的位置了，也就知道接吻次数和打斗次数。还用相邻的电影做回归求接吻次数和打斗次数？\n这个表示没懂。","like_count":8,"discussions":[{"author":{"id":1165037,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c6/ed/89a2dc13.jpg","nickname":"丢了个丢丢丢","note":"","ucode":"BDD7E97E0E5E96","race_medal":0,"user_type":4,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438466,"discussion_content":"对的，K值是个实践出来的结果，不是事先而定的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562555736,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":4}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":69672,"user_name":"Geek_hve78z","can_delete":false,"product_type":"c1","uid":1015045,"ip_address":"","ucode":"386803B8FC2DD5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg","comment_is_top":false,"comment_ctime":1550805837,"is_pvip":false,"replies":[{"id":64515,"content":"总结整理的不错","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577621142,"ip_address":"","comment_id":69672,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"KNN 的算法原理和工作流程是怎么样的？KNN 中的 K 值又是如何选择的？\n1、kNN算法的核心思想是如果一个样本在特征空间中的k个最相邻的样本中的大多数属于某一个类别，则该样本也属于这个类别，并具有这个类别上样本的特性。\n2、整个计算过程分为三步：\n1）计算待分类物体与其他物体之间的距离；\n2）统计距离最近的 K 个邻居；\n3）对于 K 个最近的邻居，它们属于哪个分类最多，待分类物体就属于哪一类。\n3、我们一般采用交叉验证的方式选取 K 值。\n交叉验证的思路就是，把样本集中的大部分样本作为训练集，剩余的小部分样本用于预测，来验证分类模型的准确性，准确率最高的那一个最终确定作为 K 值。\n","like_count":5,"discussions":[{"author":{"id":1165037,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c6/ed/89a2dc13.jpg","nickname":"丢了个丢丢丢","note":"","ucode":"BDD7E97E0E5E96","race_medal":0,"user_type":4,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":439238,"discussion_content":"一个很好的问题，回归一般是预测某个属性值，这个属性值是连续型的，而不是离散型的。如果是离散型的就变成了分类问题。比如\n对于这个待测点的已知属性值，我们先计算这个待测点与已知点的距离，然后选择最近的K个点。这样也就是知道了这个待测点和哪K个已知点最接近。那么这个待测点的未知属性值就等于这K个点的该属性值的平均值","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562555892,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":4}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2657294,"avatar":"https://static001.geekbang.org/account/avatar/00/28/8c/0e/14221860.jpg","nickname":"一个报复社会的坏蛋","note":"","ucode":"D74B2702BAE8B5","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":381778,"discussion_content":"编辑说了啥啊，还是没解答你的问题","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1625207410,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1869447,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/dv2p9vTZcdqaV4ibBsej1kibNldoLI7NoNz1UtfowQs9aNcdzZuyFgjKhkYQoy5LibWYzT92ozW3wYw9jPRIlYqSA/132","nickname":"甘坤","note":"","ucode":"45E43D93823773","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2657294,"avatar":"https://static001.geekbang.org/account/avatar/00/28/8c/0e/14221860.jpg","nickname":"一个报复社会的坏蛋","note":"","ucode":"D74B2702BAE8B5","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":392642,"discussion_content":"他的意思是，这个待测点的位置是不知道的，只知道它的某个属性，比如接吻次数，然后只根据接吻次数计算距离，找到与待测点最近的k个点，把这k个点的打斗次数平均一下，作为待测点的打斗次数。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631084405,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":381778,"ip_address":"","group_id":0},"score":392642,"extra":""}]}]},{"had_liked":false,"id":65490,"user_name":"文晟","can_delete":false,"product_type":"c1","uid":1098714,"ip_address":"","ucode":"2CD9A626CB354C","user_header":"https://static001.geekbang.org/account/avatar/00/10/c3/da/44b9273b.jpg","comment_is_top":false,"comment_ctime":1549414992,"is_pvip":false,"replies":[{"id":40574,"content":"这个主要是因为后面有个n维空间，所以我定义的两个点分别是(x1,x2,...,xn)和(y1,y2,...,yn)。对应的公式是用|x1-y1|+|x2-y2|。看起来会和我们之前学到的不一样，关键还是在于对点的定义上。","user_name":"编辑回复","user_name_real":"何昌梅","uid":1165037,"ctime":1562555760,"ip_address":"","comment_id":65490,"utype":2}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"老师，那几个距离公式怎么跟别处的不一样，记得课本上是x1-x2而不是x1-y1这种形式","like_count":5,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":440220,"discussion_content":"总结整理的不错","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577621142,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":68311,"user_name":"third","can_delete":false,"product_type":"c1","uid":1025114,"ip_address":"","ucode":"9A37408A834F0B","user_header":"https://static001.geekbang.org/account/avatar/00/0f/a4/5a/e708e423.jpg","comment_is_top":false,"comment_ctime":1550481579,"is_pvip":false,"replies":[{"id":64540,"content":"对的","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577621461,"ip_address":"","comment_id":68311,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"跟谁像，就是谁\n\n计算距离\n通过交叉验证的方法，找到较小K，准确还较高的\n计算K个近邻，\n跟谁多","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":439623,"discussion_content":"对的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577621461,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":65482,"user_name":"Python","can_delete":false,"product_type":"c1","uid":1276314,"ip_address":"","ucode":"969500D2A88AE6","user_header":"https://static001.geekbang.org/account/avatar/00/13/79/9a/4f907ad6.jpg","comment_is_top":false,"comment_ctime":1549411080,"is_pvip":false,"replies":[{"id":64605,"content":"有时候需要调超参数的，所以你可以使用GridSearchCV来帮你寻找最优的超参数","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577622289,"ip_address":"","comment_id":65482,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"老师，在实际工作中，我们直接调库和调参就行了吗？","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438465,"discussion_content":"有时候需要调超参数的，所以你可以使用GridSearchCV来帮你寻找最优的超参数","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577622289,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":234161,"user_name":"贺中堃","can_delete":false,"product_type":"c1","uid":1434183,"ip_address":"","ucode":"BE5A738DABE805","user_header":"https://static001.geekbang.org/account/avatar/00/15/e2/47/1914418a.jpg","comment_is_top":false,"comment_ctime":1594607373,"is_pvip":false,"replies":[{"id":103511,"content":"k值的确定方法常使用手肘法或者轮廓系数，k值一般会先取2并循环增加，直到找到手肘法拐点处的k或者使轮廓系数最大的k。","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1616693184,"ip_address":"","comment_id":234161,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"1.找K个最近邻。KNN分类算法的核心就是找最近的K个点，选定度量距离的方法之后，以待分类样本点为中心，分别测量它到其他点的距离，找出其中的距离最近的“TOP K”，这就是K个最近邻。\n2.统计最近邻的类别占比。确定了最近邻之后，统计出每种类别在最近邻中的占比。\n3.选取占比最多的类别作为待分类样本的类别。\n\nk值一般取一个比较小的数值，通常采用交叉验证法来选取最优的k值。","like_count":1,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438465,"discussion_content":"有时候需要调超参数的，所以你可以使用GridSearchCV来帮你寻找最优的超参数","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577622289,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":227688,"user_name":"§mc²ompleXWr","can_delete":false,"product_type":"c1","uid":1932586,"ip_address":"","ucode":"8D2527DE0F760B","user_header":"https://static001.geekbang.org/account/avatar/00/1d/7d/2a/4c7e2e2f.jpg","comment_is_top":false,"comment_ctime":1592454376,"is_pvip":false,"replies":[{"id":103726,"content":"如果这个特征的属性未知值较多，那这一列可以考虑剔除。","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1617037756,"ip_address":"","comment_id":227688,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"KNN回归：如果某个特征属性未知，我怎么算距离？","like_count":1,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":501303,"discussion_content":"k值的确定方法常使用手肘法或者轮廓系数，k值一般会先取2并循环增加，直到找到手肘法拐点处的k或者使轮廓系数最大的k。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616693184,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":67292,"user_name":"白夜","can_delete":false,"product_type":"c1","uid":1354449,"ip_address":"","ucode":"7AABFA7C04EA34","user_header":"https://static001.geekbang.org/account/avatar/00/14/aa/d1/076482f3.jpg","comment_is_top":true,"comment_ctime":1550125208,"is_pvip":false,"replies":[{"id":23807,"content":"我之前在微信群里说过这个问题，这个主要是因为后面有个n维空间，所以我定义的两个点分别是(x1,x2,...,xn)和(y1,y2,...,yn)。所以你看到的公式是用|x1-y1|+|x2-y2|，看起来会和我们之前学到的不一样，关键还是在于对点的定义上。你能理解公式的含义即可，另外这里主要是考虑到不光是2维的空间，如果是2维，3维我可以用字母来表示，比如用x,y,z，但是更多的维度，我在文章里是会用x1,x2,...,xn来表示一个点的定义。","user_name":"编辑回复","user_name_real":"何昌梅","uid":1165037,"ctime":1550134947,"ip_address":"","comment_id":67292,"utype":2}],"discussion_count":4,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"曼哈顿距离写错了吧？ 应该d=|X1-X2|+|Y1-Y2|吧","like_count":18,"discussions":[{"author":{"id":1165037,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c6/ed/89a2dc13.jpg","nickname":"丢了个丢丢丢","note":"","ucode":"BDD7E97E0E5E96","race_medal":0,"user_type":4,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":439134,"discussion_content":"我之前在微信群里说过这个问题，这个主要是因为后面有个n维空间，所以我定义的两个点分别是(x1,x2,...,xn)和(y1,y2,...,yn)。所以你看到的公式是用|x1-y1|+|x2-y2|，看起来会和我们之前学到的不一样，关键还是在于对点的定义上。你能理解公式的含义即可，另外这里主要是考虑到不光是2维的空间，如果是2维，3维我可以用字母来表示，比如用x,y,z，但是更多的维度，我在文章里是会用x1,x2,...,xn来表示一个点的定义。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1550134947,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":4}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2037505,"avatar":"https://static001.geekbang.org/account/avatar/00/1f/17/01/1c5309a3.jpg","nickname":"McKee Chen","note":"","ucode":"F74B76542FAB65","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":336482,"discussion_content":"编辑讲的很好","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1608606230,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1940971,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/9d/eb/2c7f3d3b.jpg","nickname":"Ricky","note":"","ucode":"0BC8F8DB52F01D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":233282,"discussion_content":"请问如何加群？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586916011,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1149405,"avatar":"https://static001.geekbang.org/account/avatar/00/11/89/dd/802dacd4.jpg","nickname":"Aggi","note":"","ucode":"71F21996F46FD8","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":66904,"discussion_content":"欧式距离也是这个道理吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1575115248,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":65489,"user_name":"Python","can_delete":false,"product_type":"c1","uid":1276314,"ip_address":"","ucode":"969500D2A88AE6","user_header":"https://static001.geekbang.org/account/avatar/00/13/79/9a/4f907ad6.jpg","comment_is_top":false,"comment_ctime":1549414745,"is_pvip":false,"replies":[{"id":40572,"content":"Kaggle上有些项目还是不错的\n信用卡欺诈交易分类预测 https:&#47;&#47;www.kaggle.com&#47;mlg-ulb&#47;creditcardfraud\n比特币趋势分析\nhttps:&#47;&#47;www.kaggle.com&#47;mczielinski&#47;bitcoin-historical-data\n宇宙中的脉冲星预测 https:&#47;&#47;www.kaggle.com&#47;pavanraj159&#47;predicting-a-pulsar-star\n西班牙高铁票价 https:&#47;&#47;www.kaggle.com&#47;thegurus&#47;spanish-high-speed-rail-system-ticket-pricing\n我列举了几个，Kaggle上有不少项目值得练习和研究，基本上你可以从Datasets和Kernels里面按照Hotness排序，找一下热门的项目，同时如果是初学者，有一些标签也可以参考，比如beginner, tutorial这种的。另外你也可以根据算法来检索比如：SVM, decision tree等","user_name":"编辑回复","user_name_real":"何昌梅","uid":1165037,"ctime":1562555699,"ip_address":"","comment_id":65489,"utype":2}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"老师，能不能推荐一下kaggle上谁的项目能让我们学习。","like_count":28,"discussions":[{"author":{"id":1165037,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c6/ed/89a2dc13.jpg","nickname":"丢了个丢丢丢","note":"","ucode":"BDD7E97E0E5E96","race_medal":0,"user_type":4,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":439134,"discussion_content":"我之前在微信群里说过这个问题，这个主要是因为后面有个n维空间，所以我定义的两个点分别是(x1,x2,...,xn)和(y1,y2,...,yn)。所以你看到的公式是用|x1-y1|+|x2-y2|，看起来会和我们之前学到的不一样，关键还是在于对点的定义上。你能理解公式的含义即可，另外这里主要是考虑到不光是2维的空间，如果是2维，3维我可以用字母来表示，比如用x,y,z，但是更多的维度，我在文章里是会用x1,x2,...,xn来表示一个点的定义。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1550134947,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":4}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2037505,"avatar":"https://static001.geekbang.org/account/avatar/00/1f/17/01/1c5309a3.jpg","nickname":"McKee Chen","note":"","ucode":"F74B76542FAB65","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":336482,"discussion_content":"编辑讲的很好","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1608606230,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1940971,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/9d/eb/2c7f3d3b.jpg","nickname":"Ricky","note":"","ucode":"0BC8F8DB52F01D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":233282,"discussion_content":"请问如何加群？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586916011,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1149405,"avatar":"https://static001.geekbang.org/account/avatar/00/11/89/dd/802dacd4.jpg","nickname":"Aggi","note":"","ucode":"71F21996F46FD8","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":66904,"discussion_content":"欧式距离也是这个道理吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1575115248,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":65483,"user_name":"Python","can_delete":false,"product_type":"c1","uid":1276314,"ip_address":"","ucode":"969500D2A88AE6","user_header":"https://static001.geekbang.org/account/avatar/00/13/79/9a/4f907ad6.jpg","comment_is_top":false,"comment_ctime":1549411527,"is_pvip":false,"replies":[{"id":40573,"content":"对的，K值是个实践出来的结果，不是事先而定的","user_name":"编辑回复","user_name_real":"何昌梅","uid":1165037,"ctime":1562555736,"ip_address":"","comment_id":65483,"utype":2}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"k越少就会越拟合，越多则越不拟合。最后就是为了寻找k的数值","like_count":9,"discussions":[{"author":{"id":1165037,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c6/ed/89a2dc13.jpg","nickname":"丢了个丢丢丢","note":"","ucode":"BDD7E97E0E5E96","race_medal":0,"user_type":4,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438466,"discussion_content":"对的，K值是个实践出来的结果，不是事先而定的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562555736,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":4}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":67540,"user_name":"FORWARD―MOUNT","can_delete":false,"product_type":"c1","uid":1357857,"ip_address":"","ucode":"CD8E9ECF882980","user_header":"https://static001.geekbang.org/account/avatar/00/14/b8/21/c03839f1.jpg","comment_is_top":false,"comment_ctime":1550194780,"is_pvip":false,"replies":[{"id":40577,"content":"一个很好的问题，回归一般是预测某个属性值，这个属性值是连续型的，而不是离散型的。如果是离散型的就变成了分类问题。比如\n对于这个待测点的已知属性值，我们先计算这个待测点与已知点的距离，然后选择最近的K个点。这样也就是知道了这个待测点和哪K个已知点最接近。那么这个待测点的未知属性值就等于这K个点的该属性值的平均值","user_name":"编辑回复","user_name_real":"何昌梅","uid":1165037,"ctime":1562555892,"ip_address":"","comment_id":67540,"utype":2}],"discussion_count":3,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"KNN回归，既然已经知道某部电影的位置了，也就知道接吻次数和打斗次数。还用相邻的电影做回归求接吻次数和打斗次数？\n这个表示没懂。","like_count":8,"discussions":[{"author":{"id":1165037,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c6/ed/89a2dc13.jpg","nickname":"丢了个丢丢丢","note":"","ucode":"BDD7E97E0E5E96","race_medal":0,"user_type":4,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":439238,"discussion_content":"一个很好的问题，回归一般是预测某个属性值，这个属性值是连续型的，而不是离散型的。如果是离散型的就变成了分类问题。比如\n对于这个待测点的已知属性值，我们先计算这个待测点与已知点的距离，然后选择最近的K个点。这样也就是知道了这个待测点和哪K个已知点最接近。那么这个待测点的未知属性值就等于这K个点的该属性值的平均值","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562555892,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":4}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2657294,"avatar":"https://static001.geekbang.org/account/avatar/00/28/8c/0e/14221860.jpg","nickname":"一个报复社会的坏蛋","note":"","ucode":"D74B2702BAE8B5","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":381778,"discussion_content":"编辑说了啥啊，还是没解答你的问题","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1625207410,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1869447,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/dv2p9vTZcdqaV4ibBsej1kibNldoLI7NoNz1UtfowQs9aNcdzZuyFgjKhkYQoy5LibWYzT92ozW3wYw9jPRIlYqSA/132","nickname":"甘坤","note":"","ucode":"45E43D93823773","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2657294,"avatar":"https://static001.geekbang.org/account/avatar/00/28/8c/0e/14221860.jpg","nickname":"一个报复社会的坏蛋","note":"","ucode":"D74B2702BAE8B5","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":392642,"discussion_content":"他的意思是，这个待测点的位置是不知道的，只知道它的某个属性，比如接吻次数，然后只根据接吻次数计算距离，找到与待测点最近的k个点，把这k个点的打斗次数平均一下，作为待测点的打斗次数。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631084405,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":381778,"ip_address":"","group_id":0},"score":392642,"extra":""}]}]},{"had_liked":false,"id":69672,"user_name":"Geek_hve78z","can_delete":false,"product_type":"c1","uid":1015045,"ip_address":"","ucode":"386803B8FC2DD5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg","comment_is_top":false,"comment_ctime":1550805837,"is_pvip":false,"replies":[{"id":64515,"content":"总结整理的不错","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577621142,"ip_address":"","comment_id":69672,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"KNN 的算法原理和工作流程是怎么样的？KNN 中的 K 值又是如何选择的？\n1、kNN算法的核心思想是如果一个样本在特征空间中的k个最相邻的样本中的大多数属于某一个类别，则该样本也属于这个类别，并具有这个类别上样本的特性。\n2、整个计算过程分为三步：\n1）计算待分类物体与其他物体之间的距离；\n2）统计距离最近的 K 个邻居；\n3）对于 K 个最近的邻居，它们属于哪个分类最多，待分类物体就属于哪一类。\n3、我们一般采用交叉验证的方式选取 K 值。\n交叉验证的思路就是，把样本集中的大部分样本作为训练集，剩余的小部分样本用于预测，来验证分类模型的准确性，准确率最高的那一个最终确定作为 K 值。\n","like_count":5,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":440220,"discussion_content":"总结整理的不错","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577621142,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":65490,"user_name":"文晟","can_delete":false,"product_type":"c1","uid":1098714,"ip_address":"","ucode":"2CD9A626CB354C","user_header":"https://static001.geekbang.org/account/avatar/00/10/c3/da/44b9273b.jpg","comment_is_top":false,"comment_ctime":1549414992,"is_pvip":false,"replies":[{"id":40574,"content":"这个主要是因为后面有个n维空间，所以我定义的两个点分别是(x1,x2,...,xn)和(y1,y2,...,yn)。对应的公式是用|x1-y1|+|x2-y2|。看起来会和我们之前学到的不一样，关键还是在于对点的定义上。","user_name":"编辑回复","user_name_real":"何昌梅","uid":1165037,"ctime":1562555760,"ip_address":"","comment_id":65490,"utype":2}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"老师，那几个距离公式怎么跟别处的不一样，记得课本上是x1-x2而不是x1-y1这种形式","like_count":5,"discussions":[{"author":{"id":1165037,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c6/ed/89a2dc13.jpg","nickname":"丢了个丢丢丢","note":"","ucode":"BDD7E97E0E5E96","race_medal":0,"user_type":4,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438470,"discussion_content":"这个主要是因为后面有个n维空间，所以我定义的两个点分别是(x1,x2,...,xn)和(y1,y2,...,yn)。对应的公式是用|x1-y1|+|x2-y2|。看起来会和我们之前学到的不一样，关键还是在于对点的定义上。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562555760,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":4}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1104690,"avatar":"https://static001.geekbang.org/account/avatar/00/10/db/32/aeb274d8.jpg","nickname":"数据社","note":"","ucode":"2A41B848035D75","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":41804,"discussion_content":"这个让很多人搞混了……","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1572508892,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":68311,"user_name":"third","can_delete":false,"product_type":"c1","uid":1025114,"ip_address":"","ucode":"9A37408A834F0B","user_header":"https://static001.geekbang.org/account/avatar/00/0f/a4/5a/e708e423.jpg","comment_is_top":false,"comment_ctime":1550481579,"is_pvip":false,"replies":[{"id":64540,"content":"对的","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577621461,"ip_address":"","comment_id":68311,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"跟谁像，就是谁\n\n计算距离\n通过交叉验证的方法，找到较小K，准确还较高的\n计算K个近邻，\n跟谁多","like_count":2,"discussions":[{"author":{"id":1165037,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c6/ed/89a2dc13.jpg","nickname":"丢了个丢丢丢","note":"","ucode":"BDD7E97E0E5E96","race_medal":0,"user_type":4,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438470,"discussion_content":"这个主要是因为后面有个n维空间，所以我定义的两个点分别是(x1,x2,...,xn)和(y1,y2,...,yn)。对应的公式是用|x1-y1|+|x2-y2|。看起来会和我们之前学到的不一样，关键还是在于对点的定义上。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562555760,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":4}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1104690,"avatar":"https://static001.geekbang.org/account/avatar/00/10/db/32/aeb274d8.jpg","nickname":"数据社","note":"","ucode":"2A41B848035D75","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":41804,"discussion_content":"这个让很多人搞混了……","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1572508892,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":65482,"user_name":"Python","can_delete":false,"product_type":"c1","uid":1276314,"ip_address":"","ucode":"969500D2A88AE6","user_header":"https://static001.geekbang.org/account/avatar/00/13/79/9a/4f907ad6.jpg","comment_is_top":false,"comment_ctime":1549411080,"is_pvip":false,"replies":[{"id":64605,"content":"有时候需要调超参数的，所以你可以使用GridSearchCV来帮你寻找最优的超参数","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577622289,"ip_address":"","comment_id":65482,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"老师，在实际工作中，我们直接调库和调参就行了吗？","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":439623,"discussion_content":"对的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577621461,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":234161,"user_name":"贺中堃","can_delete":false,"product_type":"c1","uid":1434183,"ip_address":"","ucode":"BE5A738DABE805","user_header":"https://static001.geekbang.org/account/avatar/00/15/e2/47/1914418a.jpg","comment_is_top":false,"comment_ctime":1594607373,"is_pvip":false,"replies":[{"id":103511,"content":"k值的确定方法常使用手肘法或者轮廓系数，k值一般会先取2并循环增加，直到找到手肘法拐点处的k或者使轮廓系数最大的k。","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1616693184,"ip_address":"","comment_id":234161,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"1.找K个最近邻。KNN分类算法的核心就是找最近的K个点，选定度量距离的方法之后，以待分类样本点为中心，分别测量它到其他点的距离，找出其中的距离最近的“TOP K”，这就是K个最近邻。\n2.统计最近邻的类别占比。确定了最近邻之后，统计出每种类别在最近邻中的占比。\n3.选取占比最多的类别作为待分类样本的类别。\n\nk值一般取一个比较小的数值，通常采用交叉验证法来选取最优的k值。","like_count":1,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":501303,"discussion_content":"k值的确定方法常使用手肘法或者轮廓系数，k值一般会先取2并循环增加，直到找到手肘法拐点处的k或者使轮廓系数最大的k。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616693184,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":227688,"user_name":"§mc²ompleXWr","can_delete":false,"product_type":"c1","uid":1932586,"ip_address":"","ucode":"8D2527DE0F760B","user_header":"https://static001.geekbang.org/account/avatar/00/1d/7d/2a/4c7e2e2f.jpg","comment_is_top":false,"comment_ctime":1592454376,"is_pvip":false,"replies":[{"id":103726,"content":"如果这个特征的属性未知值较多，那这一列可以考虑剔除。","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1617037756,"ip_address":"","comment_id":227688,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"KNN回归：如果某个特征属性未知，我怎么算距离？","like_count":1,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":498748,"discussion_content":"如果这个特征的属性未知值较多，那这一列可以考虑剔除。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617037756,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":81494,"user_name":"滨滨","can_delete":false,"product_type":"c1","uid":1334567,"ip_address":"","ucode":"881EFA798BEE34","user_header":"https://static001.geekbang.org/account/avatar/00/14/5d/27/74e152d3.jpg","comment_is_top":false,"comment_ctime":1553926922,"is_pvip":false,"replies":[{"id":64329,"content":"多谢分享","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577616958,"ip_address":"","comment_id":81494,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"kd树的简单解释https:&#47;&#47;blog.csdn.net&#47;App_12062011&#47;article&#47;details&#47;51986805","like_count":1},{"had_liked":false,"id":81463,"user_name":"滨滨","can_delete":false,"product_type":"c1","uid":1334567,"ip_address":"","ucode":"881EFA798BEE34","user_header":"https://static001.geekbang.org/account/avatar/00/14/5d/27/74e152d3.jpg","comment_is_top":false,"comment_ctime":1553918161,"is_pvip":false,"replies":[{"id":64343,"content":"总结的不错","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577617093,"ip_address":"","comment_id":81463,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"1. KNN的算法原理\n离哪个邻居越近，属性与那个邻居越相似，和那个邻居的类别越一致。\n2. KNN的工作流程\n首先，根据场景，选取距离的计算方式\n然后，统计与所需分类对象距离最近的K个邻居\n最后，K个邻居中，所占数量最多的类别，即预测其为该分类对象的类别\n3. K值的选取\n交叉验证的方式，即设置多个测试集，用这些测试集测试多个K值，那个测试集所预测准确率越高的，即选取其相应的K值。","like_count":1,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":445228,"discussion_content":"多谢分享","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577616958,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":71893,"user_name":"fancy","can_delete":false,"product_type":"c1","uid":1243166,"ip_address":"","ucode":"0C51F80B9C35B1","user_header":"https://static001.geekbang.org/account/avatar/00/12/f8/1e/0d5f8336.jpg","comment_is_top":false,"comment_ctime":1551475272,"is_pvip":false,"replies":[{"id":64482,"content":"很好的总结","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577619903,"ip_address":"","comment_id":71893,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"1. KNN的算法原理\n离哪个邻居越近，属性与那个邻居越相似，和那个邻居的类别越一致。\n2. KNN的工作流程\n首先，根据场景，选取距离的计算方式\n然后，统计与所需分类对象距离最近的K个邻居\n最后，K个邻居中，所占数量最多的类别，即预测其为该分类对象的类别\n3. K值的选取\n交叉验证的方式，即设置多个测试集，用这些测试集测试多个K值，那个测试集所预测准确率越高的，即选取其相应的K值。","like_count":1,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":445210,"discussion_content":"总结的不错","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577617093,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":65477,"user_name":"顾仲贤","can_delete":false,"product_type":"c1","uid":1107515,"ip_address":"","ucode":"2E2516A8916716","user_header":"https://static001.geekbang.org/account/avatar/00/10/e6/3b/2d14b5e1.jpg","comment_is_top":false,"comment_ctime":1549392475,"is_pvip":false,"replies":[{"id":64607,"content":"一开始都是随机的，经过多次迭代之后，分类状态就会稳定下来，我们求的是最终稳定的状态，一开始的随机状态，即使是不正确的，也没有关系","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577622353,"ip_address":"","comment_id":65477,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"老师，您在KNN做回归时举例说已知分类求属性。问题是，在没有属性只知道分类的情况下，怎么求出k个近邻呢？","like_count":1,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":441382,"discussion_content":"很好的总结","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577619903,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":151510,"user_name":"Ronnyz","can_delete":false,"product_type":"c1","uid":1488280,"ip_address":"","ucode":"9F34527B1D343D","user_header":"https://static001.geekbang.org/account/avatar/00/16/b5/98/ffaf2aca.jpg","comment_is_top":false,"comment_ctime":1573733029,"is_pvip":false,"replies":[{"id":59808,"content":"你可以采用手肘法来确定K值，也就是肘部对应的数值作为K的取值","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1574756195,"ip_address":"","comment_id":151510,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"老师，KNN中的K值选取还是得不断的尝试是吗，只是最终确定K值的选取是以K折交叉验证得出的准确度的高低来确定","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":474508,"discussion_content":"你可以采用手肘法来确定K值，也就是肘部对应的数值作为K的取值","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1574756195,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":150375,"user_name":"William～Zhang","can_delete":false,"product_type":"c1","uid":1527138,"ip_address":"","ucode":"8659B589428F11","user_header":"https://static001.geekbang.org/account/avatar/00/17/4d/62/0fe9cbb3.jpg","comment_is_top":false,"comment_ctime":1573524113,"is_pvip":false,"replies":[{"id":59739,"content":"随机选一个，不用纠结，这种情况下算哪个都是正确的","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1574738761,"ip_address":"","comment_id":150375,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"老师，请问选取k个最近的领居，看分类最多的那一类，待分类物体就属于哪一类，那请问如果，刚好k个最近领居各一半，分属于不同类，怎么办","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":474140,"discussion_content":"随机选一个，不用纠结，这种情况下算哪个都是正确的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1574738761,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":116702,"user_name":"FeiFei","can_delete":false,"product_type":"c1","uid":1045586,"ip_address":"","ucode":"01CD655DD4E56C","user_header":"https://static001.geekbang.org/account/avatar/00/0f/f4/52/10c4d863.jpg","comment_is_top":false,"comment_ctime":1563892281,"is_pvip":false,"replies":[{"id":63639,"content":"对的","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577526131,"ip_address":"","comment_id":116702,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"1，计算待分类物和其他物体之间的距离；\n2，统计距离最近的K的物体；\n3，K个邻居最多的分类=待分类物的分类。\n\n分割线\n\n1，太小会过于拟合\n2，太大会欠拟合","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":459645,"discussion_content":"对的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577526131,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":96740,"user_name":"闫伟","can_delete":false,"product_type":"c1","uid":1233666,"ip_address":"","ucode":"6BFCDB82478C73","user_header":"https://static001.geekbang.org/account/avatar/00/12/d3/02/ff2e1881.jpg","comment_is_top":false,"comment_ctime":1558495576,"is_pvip":false,"replies":[{"id":64165,"content":"可以联系运营同学，把你拉到微信群里","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577610845,"ip_address":"","comment_id":96740,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"老师，微信群是多少呀，想进群一起学习，麻烦老师加 下，vx：yw903167000","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":450998,"discussion_content":"可以联系运营同学，把你拉到微信群里","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577610845,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":87408,"user_name":"滢","can_delete":false,"product_type":"c1","uid":1221511,"ip_address":"","ucode":"971A6F20AF3F9A","user_header":"https://static001.geekbang.org/account/avatar/00/12/a3/87/c415e370.jpg","comment_is_top":false,"comment_ctime":1555586409,"is_pvip":false,"replies":[{"id":64241,"content":"对的","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577615124,"ip_address":"","comment_id":87408,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"KNN工作原理：计算分类物体与其它物体的距离，选取k值，获得k个邻居的属性，哪种属性最多，该类就归属于这种属性。\nK值选择：交叉验证选择","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":447433,"discussion_content":"对的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577615124,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":362293,"user_name":"AI悦创","can_delete":false,"product_type":"c1","uid":1525309,"ip_address":"福建","ucode":"D1007711CB0A79","user_header":"https://static001.geekbang.org/account/avatar/00/17/46/3d/55653953.jpg","comment_is_top":false,"comment_ctime":1668396113,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"很不错，讲了等于没讲，所以K怎么找？具体教学都没有，怎么实战？","like_count":1},{"had_liked":false,"id":81494,"user_name":"滨滨","can_delete":false,"product_type":"c1","uid":1334567,"ip_address":"","ucode":"881EFA798BEE34","user_header":"https://static001.geekbang.org/account/avatar/00/14/5d/27/74e152d3.jpg","comment_is_top":false,"comment_ctime":1553926922,"is_pvip":false,"replies":[{"id":64329,"content":"多谢分享","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577616958,"ip_address":"","comment_id":81494,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"kd树的简单解释https:&#47;&#47;blog.csdn.net&#47;App_12062011&#47;article&#47;details&#47;51986805","like_count":1,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":445228,"discussion_content":"多谢分享","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577616958,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":81463,"user_name":"滨滨","can_delete":false,"product_type":"c1","uid":1334567,"ip_address":"","ucode":"881EFA798BEE34","user_header":"https://static001.geekbang.org/account/avatar/00/14/5d/27/74e152d3.jpg","comment_is_top":false,"comment_ctime":1553918161,"is_pvip":false,"replies":[{"id":64343,"content":"总结的不错","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577617093,"ip_address":"","comment_id":81463,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"1. KNN的算法原理\n离哪个邻居越近，属性与那个邻居越相似，和那个邻居的类别越一致。\n2. KNN的工作流程\n首先，根据场景，选取距离的计算方式\n然后，统计与所需分类对象距离最近的K个邻居\n最后，K个邻居中，所占数量最多的类别，即预测其为该分类对象的类别\n3. K值的选取\n交叉验证的方式，即设置多个测试集，用这些测试集测试多个K值，那个测试集所预测准确率越高的，即选取其相应的K值。","like_count":1,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":445210,"discussion_content":"总结的不错","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577617093,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":71893,"user_name":"fancy","can_delete":false,"product_type":"c1","uid":1243166,"ip_address":"","ucode":"0C51F80B9C35B1","user_header":"https://static001.geekbang.org/account/avatar/00/12/f8/1e/0d5f8336.jpg","comment_is_top":false,"comment_ctime":1551475272,"is_pvip":false,"replies":[{"id":64482,"content":"很好的总结","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577619903,"ip_address":"","comment_id":71893,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"1. KNN的算法原理\n离哪个邻居越近，属性与那个邻居越相似，和那个邻居的类别越一致。\n2. KNN的工作流程\n首先，根据场景，选取距离的计算方式\n然后，统计与所需分类对象距离最近的K个邻居\n最后，K个邻居中，所占数量最多的类别，即预测其为该分类对象的类别\n3. K值的选取\n交叉验证的方式，即设置多个测试集，用这些测试集测试多个K值，那个测试集所预测准确率越高的，即选取其相应的K值。","like_count":1,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":441382,"discussion_content":"很好的总结","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577619903,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":65477,"user_name":"顾仲贤","can_delete":false,"product_type":"c1","uid":1107515,"ip_address":"","ucode":"2E2516A8916716","user_header":"https://static001.geekbang.org/account/avatar/00/10/e6/3b/2d14b5e1.jpg","comment_is_top":false,"comment_ctime":1549392475,"is_pvip":false,"replies":[{"id":64607,"content":"一开始都是随机的，经过多次迭代之后，分类状态就会稳定下来，我们求的是最终稳定的状态，一开始的随机状态，即使是不正确的，也没有关系","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577622353,"ip_address":"","comment_id":65477,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"老师，您在KNN做回归时举例说已知分类求属性。问题是，在没有属性只知道分类的情况下，怎么求出k个近邻呢？","like_count":1,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438462,"discussion_content":"一开始都是随机的，经过多次迭代之后，分类状态就会稳定下来，我们求的是最终稳定的状态，一开始的随机状态，即使是不正确的，也没有关系","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577622353,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":151510,"user_name":"Ronnyz","can_delete":false,"product_type":"c1","uid":1488280,"ip_address":"","ucode":"9F34527B1D343D","user_header":"https://static001.geekbang.org/account/avatar/00/16/b5/98/ffaf2aca.jpg","comment_is_top":false,"comment_ctime":1573733029,"is_pvip":false,"replies":[{"id":59808,"content":"你可以采用手肘法来确定K值，也就是肘部对应的数值作为K的取值","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1574756195,"ip_address":"","comment_id":151510,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"老师，KNN中的K值选取还是得不断的尝试是吗，只是最终确定K值的选取是以K折交叉验证得出的准确度的高低来确定","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438462,"discussion_content":"一开始都是随机的，经过多次迭代之后，分类状态就会稳定下来，我们求的是最终稳定的状态，一开始的随机状态，即使是不正确的，也没有关系","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577622353,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":150375,"user_name":"William～Zhang","can_delete":false,"product_type":"c1","uid":1527138,"ip_address":"","ucode":"8659B589428F11","user_header":"https://static001.geekbang.org/account/avatar/00/17/4d/62/0fe9cbb3.jpg","comment_is_top":false,"comment_ctime":1573524113,"is_pvip":false,"replies":[{"id":59739,"content":"随机选一个，不用纠结，这种情况下算哪个都是正确的","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1574738761,"ip_address":"","comment_id":150375,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"老师，请问选取k个最近的领居，看分类最多的那一类，待分类物体就属于哪一类，那请问如果，刚好k个最近领居各一半，分属于不同类，怎么办","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":474508,"discussion_content":"你可以采用手肘法来确定K值，也就是肘部对应的数值作为K的取值","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1574756195,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":116702,"user_name":"FeiFei","can_delete":false,"product_type":"c1","uid":1045586,"ip_address":"","ucode":"01CD655DD4E56C","user_header":"https://static001.geekbang.org/account/avatar/00/0f/f4/52/10c4d863.jpg","comment_is_top":false,"comment_ctime":1563892281,"is_pvip":false,"replies":[{"id":63639,"content":"对的","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577526131,"ip_address":"","comment_id":116702,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"1，计算待分类物和其他物体之间的距离；\n2，统计距离最近的K的物体；\n3，K个邻居最多的分类=待分类物的分类。\n\n分割线\n\n1，太小会过于拟合\n2，太大会欠拟合","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":474140,"discussion_content":"随机选一个，不用纠结，这种情况下算哪个都是正确的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1574738761,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":96740,"user_name":"闫伟","can_delete":false,"product_type":"c1","uid":1233666,"ip_address":"","ucode":"6BFCDB82478C73","user_header":"https://static001.geekbang.org/account/avatar/00/12/d3/02/ff2e1881.jpg","comment_is_top":false,"comment_ctime":1558495576,"is_pvip":false,"replies":[{"id":64165,"content":"可以联系运营同学，把你拉到微信群里","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577610845,"ip_address":"","comment_id":96740,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"老师，微信群是多少呀，想进群一起学习，麻烦老师加 下，vx：yw903167000","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":459645,"discussion_content":"对的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577526131,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":87408,"user_name":"滢","can_delete":false,"product_type":"c1","uid":1221511,"ip_address":"","ucode":"971A6F20AF3F9A","user_header":"https://static001.geekbang.org/account/avatar/00/12/a3/87/c415e370.jpg","comment_is_top":false,"comment_ctime":1555586409,"is_pvip":false,"replies":[{"id":64241,"content":"对的","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577615124,"ip_address":"","comment_id":87408,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"KNN工作原理：计算分类物体与其它物体的距离，选取k值，获得k个邻居的属性，哪种属性最多，该类就归属于这种属性。\nK值选择：交叉验证选择","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":450998,"discussion_content":"可以联系运营同学，把你拉到微信群里","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577610845,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":362293,"user_name":"AI悦创","can_delete":false,"product_type":"c1","uid":1525309,"ip_address":"福建","ucode":"D1007711CB0A79","user_header":"https://static001.geekbang.org/account/avatar/00/17/46/3d/55653953.jpg","comment_is_top":false,"comment_ctime":1668396113,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"很不错，讲了等于没讲，所以K怎么找？具体教学都没有，怎么实战？","like_count":1,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":447433,"discussion_content":"对的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577615124,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":202937,"user_name":"timeng27","can_delete":false,"product_type":"c1","uid":1914163,"ip_address":"","ucode":"C92D7484F7FF35","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJAl7V1ibk8gX62W5I4SER2zbQAj3gy5icJlavGhnAmxENCia7QFm8lE3YBc5HOHvlyNVFz7rQKFQ7dA/132","comment_is_top":false,"comment_ctime":1586089092,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"k值的选取是否可以参考样本中的分类比例和个数？比如样本中最少的一个分类是10个，那么k肯定不能取10。回不会有类似的方法取k值？","like_count":1},{"had_liked":false,"id":297920,"user_name":"彭涛","can_delete":false,"product_type":"c1","uid":1890860,"ip_address":"","ucode":"86EACC03B46A37","user_header":"https://static001.geekbang.org/account/avatar/00/1c/da/2c/783413de.jpg","comment_is_top":false,"comment_ctime":1623844160,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"同样 KNN 也可以用于推荐算法，虽然现在很多推荐系统的算法会使用 TD-IDF、协同过滤、Apriori 算法，不过针对数据量不大的情况下，采用 KNN 作为推荐算法也是可行的。\n请问：总结中的 TD-IDF 是否应该为：TF-IDF ？","like_count":0},{"had_liked":false,"id":269337,"user_name":"McKee Chen","can_delete":false,"product_type":"c1","uid":2037505,"ip_address":"","ucode":"F74B76542FAB65","user_header":"https://static001.geekbang.org/account/avatar/00/1f/17/01/1c5309a3.jpg","comment_is_top":false,"comment_ctime":1608616933,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"KNN算法原理:\n1.根据业务场景，选择合适的距离计算公式，计算待分类点与其他样本点之间的距离\n2.统计与待分类点距离最近的K个邻居\n3.观察K个邻居的分类占比，分类占比最高的即为待分类点所属的类别\n\nK值的选择:\n交叉验证法: 选取样本集中的大部分样本为训练集，剩下的样本为测试集，不断训练模型，得到不同的模型准确率，直至得到最高的准确率，此时的K值为最优值\n\nKD树: 待学习","like_count":0},{"had_liked":false,"id":184369,"user_name":"鱼非子","can_delete":false,"product_type":"c1","uid":1818595,"ip_address":"","ucode":"BB76AE2CB4D680","user_header":"https://static001.geekbang.org/account/avatar/00/1b/bf/e3/2aa8ec84.jpg","comment_is_top":false,"comment_ctime":1583300721,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"KNN算法原理：物以类聚\n工作流程：计算一个样本与其它样本的距离，选择最近的k个样本，k个样本中哪种类别最多，这个样本就属于哪种类别\nk值选择：利用交叉验证的方法\n","like_count":0},{"had_liked":false,"id":184019,"user_name":"学技术攒钱开宠物店","can_delete":false,"product_type":"c1","uid":1849036,"ip_address":"","ucode":"3EA297FD4C9635","user_header":"https://static001.geekbang.org/account/avatar/00/1c/36/cc/499625d3.jpg","comment_is_top":false,"comment_ctime":1583206134,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"回归已经知道值了呀，为什么还计算距离平均","like_count":0},{"had_liked":false,"id":84113,"user_name":"大鱼","can_delete":false,"product_type":"c1","uid":1020811,"ip_address":"","ucode":"1144A0E7EE3B8B","user_header":"https://static001.geekbang.org/account/avatar/00/0f/93/8b/35fa42aa.jpg","comment_is_top":false,"comment_ctime":1554787091,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"如果回归的话，怎么找到那k个相邻的点呢？除了类别，是不是还需要其他的特征来辅助，比如我是爱情电影，除了这个分类，还得有我是几级的爱情电影？","like_count":0},{"had_liked":false,"id":70701,"user_name":"上善若水","can_delete":false,"product_type":"c1","uid":1432353,"ip_address":"","ucode":"FEECBBA65AC0CD","user_header":"https://static001.geekbang.org/account/avatar/00/15/db/21/26ff0240.jpg","comment_is_top":false,"comment_ctime":1551167221,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"请问TD-IDF是什么，为啥我搜的是tf-idf,是不同的命名吗？\n\n","like_count":0},{"had_liked":false,"id":68781,"user_name":"开心","can_delete":false,"product_type":"c1","uid":1273224,"ip_address":"","ucode":"9ECFB8642D42A3","user_header":"https://static001.geekbang.org/account/avatar/00/13/6d/88/d6e6ddcf.jpg","comment_is_top":false,"comment_ctime":1550617005,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"预估值就是历史的平均值，这样理解对吗？上一讲的乳腺癌的发病率是不是这样算的","like_count":0},{"had_liked":false,"id":68675,"user_name":"Chen","can_delete":false,"product_type":"c1","uid":1359478,"ip_address":"","ucode":"DBCC6C2A5D513E","user_header":"https://static001.geekbang.org/account/avatar/00/14/be/76/55e5e326.jpg","comment_is_top":false,"comment_ctime":1550570587,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"1、K值太小的时候，模型变得复杂，容易发生过拟合，这点怎么理解呢？难道不是K太小，看的邻居太少，学习能力不足，会欠拟合吗，这儿没有理解。\n2、当数据量非常大的时候，KNN会面临庞大的存储空间和计算时间问题，我们可以用kd树解决。\n当样本类别非常地不均衡的时候，KNN会面临分类准确率很低的问题，我们该怎么解决呢？","like_count":0},{"had_liked":false,"id":66595,"user_name":"从未在此","can_delete":false,"product_type":"c1","uid":1354589,"ip_address":"","ucode":"5A4AA275D8EE9A","user_header":"https://static001.geekbang.org/account/avatar/00/14/ab/5d/430ed3b6.jpg","comment_is_top":false,"comment_ctime":1549964102,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"欧式距离应该是同坐标轴数字相减吧？跨坐标轴不好计算","like_count":0},{"had_liked":false,"id":202937,"user_name":"timeng27","can_delete":false,"product_type":"c1","uid":1914163,"ip_address":"","ucode":"C92D7484F7FF35","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJAl7V1ibk8gX62W5I4SER2zbQAj3gy5icJlavGhnAmxENCia7QFm8lE3YBc5HOHvlyNVFz7rQKFQ7dA/132","comment_is_top":false,"comment_ctime":1586089092,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"k值的选取是否可以参考样本中的分类比例和个数？比如样本中最少的一个分类是10个，那么k肯定不能取10。回不会有类似的方法取k值？","like_count":1},{"had_liked":false,"id":297920,"user_name":"彭涛","can_delete":false,"product_type":"c1","uid":1890860,"ip_address":"","ucode":"86EACC03B46A37","user_header":"https://static001.geekbang.org/account/avatar/00/1c/da/2c/783413de.jpg","comment_is_top":false,"comment_ctime":1623844160,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"同样 KNN 也可以用于推荐算法，虽然现在很多推荐系统的算法会使用 TD-IDF、协同过滤、Apriori 算法，不过针对数据量不大的情况下，采用 KNN 作为推荐算法也是可行的。\n请问：总结中的 TD-IDF 是否应该为：TF-IDF ？","like_count":0},{"had_liked":false,"id":269337,"user_name":"McKee Chen","can_delete":false,"product_type":"c1","uid":2037505,"ip_address":"","ucode":"F74B76542FAB65","user_header":"https://static001.geekbang.org/account/avatar/00/1f/17/01/1c5309a3.jpg","comment_is_top":false,"comment_ctime":1608616933,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"KNN算法原理:\n1.根据业务场景，选择合适的距离计算公式，计算待分类点与其他样本点之间的距离\n2.统计与待分类点距离最近的K个邻居\n3.观察K个邻居的分类占比，分类占比最高的即为待分类点所属的类别\n\nK值的选择:\n交叉验证法: 选取样本集中的大部分样本为训练集，剩下的样本为测试集，不断训练模型，得到不同的模型准确率，直至得到最高的准确率，此时的K值为最优值\n\nKD树: 待学习","like_count":0},{"had_liked":false,"id":184369,"user_name":"鱼非子","can_delete":false,"product_type":"c1","uid":1818595,"ip_address":"","ucode":"BB76AE2CB4D680","user_header":"https://static001.geekbang.org/account/avatar/00/1b/bf/e3/2aa8ec84.jpg","comment_is_top":false,"comment_ctime":1583300721,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"KNN算法原理：物以类聚\n工作流程：计算一个样本与其它样本的距离，选择最近的k个样本，k个样本中哪种类别最多，这个样本就属于哪种类别\nk值选择：利用交叉验证的方法\n","like_count":0},{"had_liked":false,"id":184019,"user_name":"学技术攒钱开宠物店","can_delete":false,"product_type":"c1","uid":1849036,"ip_address":"","ucode":"3EA297FD4C9635","user_header":"https://static001.geekbang.org/account/avatar/00/1c/36/cc/499625d3.jpg","comment_is_top":false,"comment_ctime":1583206134,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"回归已经知道值了呀，为什么还计算距离平均","like_count":0},{"had_liked":false,"id":84113,"user_name":"大鱼","can_delete":false,"product_type":"c1","uid":1020811,"ip_address":"","ucode":"1144A0E7EE3B8B","user_header":"https://static001.geekbang.org/account/avatar/00/0f/93/8b/35fa42aa.jpg","comment_is_top":false,"comment_ctime":1554787091,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"如果回归的话，怎么找到那k个相邻的点呢？除了类别，是不是还需要其他的特征来辅助，比如我是爱情电影，除了这个分类，还得有我是几级的爱情电影？","like_count":0},{"had_liked":false,"id":70701,"user_name":"上善若水","can_delete":false,"product_type":"c1","uid":1432353,"ip_address":"","ucode":"FEECBBA65AC0CD","user_header":"https://static001.geekbang.org/account/avatar/00/15/db/21/26ff0240.jpg","comment_is_top":false,"comment_ctime":1551167221,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"请问TD-IDF是什么，为啥我搜的是tf-idf,是不同的命名吗？\n\n","like_count":0},{"had_liked":false,"id":68781,"user_name":"开心","can_delete":false,"product_type":"c1","uid":1273224,"ip_address":"","ucode":"9ECFB8642D42A3","user_header":"https://static001.geekbang.org/account/avatar/00/13/6d/88/d6e6ddcf.jpg","comment_is_top":false,"comment_ctime":1550617005,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"预估值就是历史的平均值，这样理解对吗？上一讲的乳腺癌的发病率是不是这样算的","like_count":0},{"had_liked":false,"id":68675,"user_name":"Chen","can_delete":false,"product_type":"c1","uid":1359478,"ip_address":"","ucode":"DBCC6C2A5D513E","user_header":"https://static001.geekbang.org/account/avatar/00/14/be/76/55e5e326.jpg","comment_is_top":false,"comment_ctime":1550570587,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"1、K值太小的时候，模型变得复杂，容易发生过拟合，这点怎么理解呢？难道不是K太小，看的邻居太少，学习能力不足，会欠拟合吗，这儿没有理解。\n2、当数据量非常大的时候，KNN会面临庞大的存储空间和计算时间问题，我们可以用kd树解决。\n当样本类别非常地不均衡的时候，KNN会面临分类准确率很低的问题，我们该怎么解决呢？","like_count":0},{"had_liked":false,"id":66595,"user_name":"从未在此","can_delete":false,"product_type":"c1","uid":1354589,"ip_address":"","ucode":"5A4AA275D8EE9A","user_header":"https://static001.geekbang.org/account/avatar/00/14/ab/5d/430ed3b6.jpg","comment_is_top":false,"comment_ctime":1549964102,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"欧式距离应该是同坐标轴数字相减吧？跨坐标轴不好计算","like_count":0}]}