{"id":671725,"title":"05｜存储：消息数据和元数据的存储是如何设计的？","content":"<p>你好，我是文强。今天我们讲消息队列的存储模块。</p><p>存储模块作为消息队列高吞吐、低延时、高可靠特性的基础保证，可以说是最核心的模块。从技术架构的角度来看，存储模块包含<strong>功能实现和性能优化</strong>两个方面，我们今天先聊存储模块的功能设计和实现。</p><p>上节课我们讲过，存储模块的主流程是数据的写入、存储、读取、过期。读写、持久化存储是基本功能，但因为消息队列独有的产品特性，主要被用来当缓冲分发，它的数据存储是临时的，数据持久化存储后，在一定的时间或操作后，需要能自动过期删除。</p><p>那对于消息队列这样有特殊需求的存储模块，我们在实现功能的时候要注意哪些事情呢？带着这个问题，我们开始今天的学习。</p><p>首先，一个前置信息你要清楚，消息队列中的数据一般分为<strong>元数据和消息数据</strong>。元数据是指Topic、Group、User、ACL、Config等集群维度的资源数据信息，消息数据指客户端写入的用户的业务数据。下面我们先来看元数据信息的存储。</p><h2>元数据信息的存储</h2><p>元数据信息的特点是数据量比较小，不会经常读写，但是需要保证数据的强一致和高可靠，不允许出现数据的丢失。同时，元数据信息一般需要通知到所有的Broker节点，Broker会根据元数据信息执行具体的逻辑。比如创建Topic并生成元数据后，就需要通知对应的Broker执行创建分区、创建目录等操作。</p><!-- [[[read_end]]] --><p>所以元数据信息的存储，一般有两个思路。</p><ul>\n<li>基于第三方组件来实现元数据的存储。</li>\n<li>在集群内部实现元数据的存储。</li>\n</ul><p><strong>基于第三方组件来实现元数据的存储是目前业界的主流选择。</strong>比如Kafka ZooKeeper版本、Pulsar、RocketMQ 用的就是这个思路，其中Kakfa和Pulsar的元数据存储在ZooKeeper中，RocketMQ存储在NameServer中（准确说是存储在Broker+NameServer中，后面会详细说明）。</p><p><img src=\"https://static001.geekbang.org/resource/image/3d/93/3d1f0787356054efb7fcc7806a5c7a93.jpg?wh=3228x1488\" alt=\"\"></p><p>这个方案最大的优点是集成方便，开发成本低，能满足消息队列功能层面的基本要求，因为我们可以直接复用第三方组件已经实现的一致性存储、高性能的读写和存储、Hook机制等能力，而且在后续集群构建中也可以复用这个组件，能极大降低开发难度和工作成本。</p><p>但也有缺点。引入第三方组件会增加系统部署和运维的复杂度，而且第三方组件自身的稳定性问题会增加系统风险，第三方组件和多台Broker之间可能会出现数据信息不一致的情况，导致读写异常。</p><p><strong>另一种思路，</strong><strong>集群内部实现元数据的存储是指在集群内部完成元数据的存储和分发。</strong>也就是在集群内部实现类似第三方组件一样的元数据服务，比如基于Raft协议实现内部的元数据存储模块或依赖一些内置的数据库。目前Kafka 去ZooKeeper的版本、RabbitMQ的Mnesia、Kafka的C++版本RedPanda用的就是这个思路。</p><p><img src=\"https://static001.geekbang.org/resource/image/34/b6/3411d5e9b57efebf403edc06cd2488b6.jpg?wh=3228x1488\" alt=\"\"></p><p>这个方案的优缺点跟第一个正好相反。优点是部署和运维成本低，不会因为依赖第三方服务导致稳定性问题，也不会有数据不一致的问题。但缺点是开发成本高，前期要投入大量的开发人力。</p><p>总的来说，当前主流选择第一种方案，主要是出于开发成本考虑。</p><p>用第三方组件导致的稳定性问题，大部分可以通过后期的运维、运营、编码技巧来解决规避或降低发生频率，但如果前期开发成本太大、架构太复杂，会影响项目的成型和业务的使用。所以在项目前期，大部分都会选择这个方案。</p><p>如果消息队列核心架构已成熟或者前期允许有较大投入，我才会建议你选择第二种方案。因为第一种方案虽然开发成本较低，但其使用成本、机器资源成本、运维成本还是偏高，另外，一些稳定性问题，比如元数据不一致，因为第三方组件的存在是无法根治的，会有长久的隐患。</p><h2>消息数据的存储</h2><p>了解了元数据，接下来我们讲消息数据的存储。一般情况下，消息队列的存储主要是指消息数据的存储，分为存储结构、数据分段、数据存储格式、数据清理四个部分。</p><h3>数据存储结构设计</h3><p>我们先看数据存储目录结构设计。在消息队列中，跟存储有关的主要是Topic和分区两个维度。用户可以将数据写入Topic或直接写入到分区。</p><p>不过如果写入Topic，数据也是分发到多个分区去存储的。所以从实际数据存储的角度来看，<strong>Topic和Group不承担数据存储功能，承担的是逻辑组织的功能，实际的数据存储是在<strong><strong>在</strong></strong>分区维度完成的</strong>。</p><p><img src=\"https://static001.geekbang.org/resource/image/9b/a1/9b91e1ab61c5c2c92a0e12d4ea0438a1.jpg?wh=3998x1615\" alt=\"\"></p><p>从技术架构的角度，数据的落盘存储也有两个思路。</p><ul>\n<li>每个分区单独一个存储“文件”。</li>\n<li>每个节点上所有分区的数据都存储在同一个“文件”。</li>\n</ul><p>特别说明下，这里的“文件”是一个虚指，即表示所有分区的数据是存储在一起，还是每个分区的数据分开存储的意思。在实际的存储中，这个“文件”通常以目录的形式存在，目录中会有多个分段文件。接下来讲到的文件都是表示这个意思。</p><p>第一个思路，每个分区对应一个文件的形式去存储数据。具体实现时，每个分区上的数据顺序写到同一个磁盘文件中，数据的存储是连续的。因为消息队列在大部分情况下的读写是有序的，所以<strong>这种机制在读写性能上的表现是最高的</strong>。</p><p>但如果分区太多，会占用太多的系统FD资源，极端情况下有可能把节点的FD资源耗完，并且硬盘层面会出现大量的随机写情况，导致写入的性能下降很多，另外管理起来也相对复杂。Kafka在存储数据的组织上用的就是这个思路。</p><p><img src=\"https://static001.geekbang.org/resource/image/b6/71/b6yyc4b63b2794e877995c756000d371.jpg?wh=4977x1699\" alt=\"\"></p><p>具体的磁盘的组织结构一般有“目录+分区二级结构”和“目录+分区一级结构”两种形式。不过从技术上来看，没有太大的优劣区别。</p><pre><code class=\"language-plain\">目录+分区二级结构：\n├── topic1\n│&nbsp; &nbsp;├── partrt0\n│&nbsp; &nbsp;├── 1\n│&nbsp; &nbsp;└── 2\n└── topic2\n&nbsp; &nbsp; ├── 0\n&nbsp; &nbsp; ├── 1\n\n目录+分区一级结构：\n├── topic1-0\n├── topic1-1\n├── topic1-2\n├── topic2-0\n├── topic2-1\n└── topic2-2\n</code></pre><p>第二种思路，每个节点上所有分区的数据都存储在同一个文件中，这种方案需要为每个分区维护一个对应的索引文件，索引文件里会记录每条消息在File里面的位置信息，以便快速定位到具体的消息内容。</p><p><img src=\"https://static001.geekbang.org/resource/image/4e/0a/4e0ebbf928847bf60b3fd642ae654e0a.jpg?wh=5528x1581\" alt=\"\"></p><p>因为<strong>所有文件都在一份文件上，管理简单，也不会占用过多的系统FD资源，单机上的数据写入都是顺序的，写入的性能会很高</strong>。缺点是同一个分区的数据一般会在文件中的不同位置，或者不同的文件段中，无法利用到顺序读的优势，读取的性能会受到影响，但是随着SSD技术的发展，随机读写的性能也越来越高。如果使用SSD或高性能SSD，一定程度上可以缓解随机读写的性能损耗，但SSD的成本比机械硬盘高很多。</p><p>目前RocketMQ、RabbitMQ和Pulsar的底层存储BookKeeper用的就是这个方案。</p><p>这种方案的数据组织形式一般是这样的。假设这个统一的文件叫commitlog，则commitlog就是用来存储数据的文件，.index是每个分区的索引信息。</p><pre><code class=\"language-plain\">.\n├── commitlog\n├── topic-0.index\n├── topic-1.index\n└── topic-2.index\n</code></pre><p>那怎么选择呢？<strong>核心考虑是你对读和写的性能要求。</strong></p><ul>\n<li>第一种方案，单个文件读和写都是顺序的，性能最高。但是当文件很多且都有读写的场景下，硬盘层面就会退化为随机读写，性能会严重下降。</li>\n<li>第二种方案，因为只有一个文件，不存在文件过多的情况，写入层面一直都会是顺序的，性能一直很高。但是在消费的时候，因为多个分区数据存储在同一个文件中，同一个分区的数据在底层存储上是不连续的，硬盘层面会出现随机读的情况，导致读取的性能降低。</li>\n</ul><p>不过随机读带来的性能问题，可以通过给底层配备高性能的硬件来缓解。所以当前比较多的消息队列选用的是第二种方案，但是 Kafka 为了保证更高的吞吐性能，选用的是第一种方案。</p><blockquote>\n<p><span class=\"reference\">关于FD的占用问题。Linux上的FD数是可以配置的，比如配置几十万个FD没问题，所以我们一般不会用完系统的FD限制，这一点在实际的落地中不需要太担心。</span></p>\n</blockquote><p>但是不管是方案一还是方案二，在数据存储的过程中，如果单个文件过大，在文件加载、写入和检索的时候，性能就会有问题，并且消息队列有自动过期机制，如果单个文件过大，数据清理时会很麻烦，效率很低。所以，我们的消息数据都会分段存储。</p><h3>消息数据的分段实现</h3><p>数据分段的规则一般是根据大小来进行的，比如默认1G一个文件，同时会支持配置项调整分段数据的大小。看数据目录中的文件分段示意图。</p><p><img src=\"https://static001.geekbang.org/resource/image/1c/13/1cb88018d4yy166ecd477c766ce66a13.jpg?wh=3228x1488\" alt=\"\"></p><p>从技术上来看，当数据段到达了规定的大小后，就会新创建一个新文件来保存数据。</p><p>如果进行了分段，消息数据可能分布在不同的文件中。所以我们在读取数据的时候，就需要先定位消息数据在哪个文件中。为了满足这个需求，技术上一般有<strong>根据<strong><strong>偏移量</strong></strong>定位或根据<strong><strong>索引</strong></strong>定位</strong>两种思路。</p><p>根据偏移量（Offset）来定位消息在哪个分段文件中，是指通过记录每个数据段文件的起始偏移量、中止偏移量、消息的偏移量信息，来快速定位消息在哪个文件。</p><p>当消息数据存储时，通常会用一个自增的数值型数据（比如Long）来表示这条数据在分区或commitlog中的位置，这个值就是消息的偏移量。</p><p><img src=\"https://static001.geekbang.org/resource/image/17/c5/17ecbd8a23fc6d5ba185e21f78bb00c5.jpg?wh=3228x1488\" alt=\"\"></p><p>在实际的编码过程中，记录文件的起始偏移量一般有两种思路：单独记录每个数据段的起始和结束偏移量，在文件名称中携带起始偏移量信息。因为数据是顺序存储的，每个文件记录了本文件的起始偏移量，那么下一个文件的起始偏移量就是上一个文件的结束偏移量。</p><p><img src=\"https://static001.geekbang.org/resource/image/1e/d0/1e87141d2f9e052d5b4a68cdff738cd0.jpg?wh=3228x1488\" alt=\"\"></p><p>如果用索引定位，会直接存储消息对应的文件信息，而不是通过偏移量来定位到具体文件。</p><p>具体是通过维护一个单独的索引文件，记录消息在哪个文件和文件的哪个位置。读取消息的时候，先根据消息ID找到存储的信息，然后找到对应的文件和位置，读取数据。RabbitMQ和RocketMQ用的就是这个思路。</p><p><img src=\"https://static001.geekbang.org/resource/image/24/2d/24ebd2bc36905901fdd95eac868a062d.jpg?wh=4125x2260\" alt=\"\"></p><p><strong>这两种方案所面临的场景不一样。</strong>根据偏移量定位数据，通常用在每个分区各自存储一份文件的场景；根据索引定位数据，通常用在所有分区的数据存储在同一份文件的场景。因为在前一种场景，每一份数据都属于同一个分区，那么通过位点来二分查找数据的效率是最高的。第二种场景，这一份数据属于多个不同分区，则通过二分查找来查找数据效率很低，用哈希查找效率是最高的。</p><p>接下来，我们继续看消息数据的存储格式，看看每行记录长什么样子，都存储了哪些信息。</p><h3>消息数据存储格式</h3><p>消息数据存储格式一般包含消息写入文件的格式和消息内容的格式两个方面。</p><p><strong>消息写入文件的格式指消息是以什么格式写入到文件中的</strong>，比如JSON字符串或二进制。从性能和空间冗余的角度来看，消息队列中的数据基本都是以二进制的格式写入到文件的。这部分二进制数据，我们不能直接用vim/cat等命令查看，需要用专门的工具读取，并解析对应的格式。</p><p>比如，我们想查看Kafka消息数据存储文件中的数据，如果用cat命令查看是乱码，用日志解析工具kafka.tools.DumpLogSegments查看，才是格式化的数据。</p><pre><code class=\"language-plain\"># cat 00000000000000000000.log&nbsp;\n&gt;f0z�sl{]�sl{���������������xlobo\n\n# kafka-run-class.sh&nbsp; kafka.tools.DumpLogSegments --files 00000000000000000000.log --print-data-log\n\nbaseOffset: 0 lastOffset: 0 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 LogAppendTime: 1681268702091 size: 74 magic: 2 compresscodec: NONE crc: 1714453217 isvalid: true\n| offset: 0 LogAppendTime: 1681268702091 keysize: 2 valuesize: 4 sequence: -1 headerKeys: [] key: xu payload: lobo\n</code></pre><p><strong>消息内容的格式是指写入到文件中的数据都包含哪些信息。</strong>对于一个成熟的消息队列来说，消息内容格式不仅关系功能维度的扩展，还牵涉性能维度的优化。</p><p>如果消息格式设计得不够精简，功能和性能都会大打折扣。比如冗余字段会增加分区的磁盘占用空间，使存储和网络开销变大，性能也会下降。如果缺少字段，则可能无法满足一些功能上的需要，导致无法实现某些功能，又或者是实现某些功能的成本较高。</p><p>所以，在数据的存储格式设计方面，内容的格式需要尽量完整且不要有太多冗余。</p><p>听起来有点抽象，我们分析一下Kafka和RocketMQ的消息内容格式设计，让你对具体的数据存储格式有更直观的感受。</p><p>以一个具体的消息内容截图为例，我们看Kakfa的V2版本存储格式的内容。</p><p><img src=\"https://static001.geekbang.org/resource/image/2e/c9/2ed471618360416bb4ba331eb5e092c9.png?wh=2912x186\" alt=\"\"></p><p>看每个字段的含义。<img src=\"https://static001.geekbang.org/resource/image/33/04/33d8678yy6b75b7663d6abcaf6d00404.jpg?wh=4000x2202\" alt=\"\">可以看到，Kafka的消息内容包含了业务会感知到的消息的Header、Key、Value，还包含了时间戳、偏移量、协议版本、数据长度和大小、校验码等基础信息，最后还包含了压缩、事务、幂等Kafka业务相关的信息。</p><p>特别说明，因为Kafka支持Batch特性，所以消息格式中还包含base和last等Batch相关信息。</p><p>再看RocketMQ的存储格式的内容。</p><p><img src=\"https://static001.geekbang.org/resource/image/a7/87/a797510810aeb878c11de7ab70e5d787.png?wh=856x926\" alt=\"\" title=\"图片来源：https://github.com/rmq-plus-plus/rocketmq-decoder\"></p><p>看每个字段的含义。<img src=\"https://static001.geekbang.org/resource/image/4c/y3/4ccc5bfbbab55cd7486de0a87eca9yy3.jpg?wh=4000x2080\" alt=\"\">RocketMQ的存储格式中也包含基础的Properties（相当于Kafka中的Header）、Value、时间戳、偏移量、协议版本、数据长度和大小、校验码等信息，还包含了系统标记、事务等RocketMQ特有的信息，另外还包含了数据来源和数据目标的节点信息。</p><p>对比看，消息数据的存储格式虽然没有统一的规范，但是一般包含通用信息和业务信息两部分。通用信息主要包括时间戳、CRC、消息头、消息体、偏移量、长度、大小等信息，业务信息主要跟业务相关，包含事务、幂等、系统标记、数据来源、数据目标等信息。<img src=\"https://static001.geekbang.org/resource/image/a8/67/a8ea54c1c6f1585ebab42b4a326a2767.jpg?wh=3228x1488\" alt=\"\">前面讲过，消息队列的数据在持久化存储后，需要在一定策略后自动过期删除。那消息队列的数据过期机制如何实现呢？</p><h3>消息数据清理机制</h3><p>消息队列中的数据最终都会删除，时间周期短的话几小时、甚至几分钟，正常情况一天、三天、七天，长的话可能一个月，基本很少有场景需要在消息队列中存储一年的数据。</p><p>消息队列的数据过期机制一般有手动删除和自动删除两种形式，从实现上看主要有三种思路。</p><ul>\n<li>消费完成执行ACK删除数据</li>\n<li>根据时间和保留大小删除</li>\n<li>ACK机制和过期机制相结合</li>\n</ul><p><strong>消费完成执行ACK删除数据，技术上的实现思路一般是</strong><strong>：</strong>当客户端成功消费数据后，回调服务端的ACK接口，告诉服务端数据已经消费成功，服务端就会标记删除该行数据，以确保消息不会被重复消费。ACK的请求一般会有单条消息ACK和批量消息ACK两种形式。</p><p><img src=\"https://static001.geekbang.org/resource/image/1a/10/1ab659d29a236b11yy55a834yy663410.jpg?wh=3228x1488\" alt=\"\"></p><p>因为消息队列的ACK一般是顺序的，如果前一条消息无法被正确处理并ACK，就无法消费下一条数据，导致消费卡住。此时就需要死信队列的功能，把这条数据先写入到死信队列，等待后续的处理。然后ACK这条消息，确保消费正确进行。</p><p>这个方案，优点是不会出现重复消费，一条消息只会被消费一次。缺点是ACK成功后消息被删除，无法满足需要消息重放的场景。</p><p><strong>根据时间和保留大小删除指消息在被消费后不会被删除，只会通过提交消费位点的形式标记消费进度。</strong></p><p>实现思路一般是服务端提供偏移量提交的接口，当客户端消费成功数据后，客户端会回调偏移量提交接口，告诉服务端这个偏移量的数据已经消费成功了，让服务端把偏移量记录起来。然后服务端会根据消息保留的策略，比如保留时间或保留大小来清理数据。一般通过一个常驻的异步线程来清理数据。</p><p><img src=\"https://static001.geekbang.org/resource/image/77/c8/772a4735742ec4e89bb031fe84d08fc8.jpg?wh=3228x1488\" alt=\"\"></p><p>这个方案，一条消息可以重复消费多次。不管有没有被成功消费，消息都会根据配置的时间规则或大小规则进行删除。优点是消息可以多次重放，适用于需要多次进行重放的场景。缺点是在某些情况下（比如客户端使用不当）会出现大量的重复消费。</p><p>我们结合前两个方案，就有了 <strong>ACK机制和过期机制相结合的方案</strong>。实现核心逻辑跟方案二很像，但保留了ACK的概念，不过ACK是相对于Group概念的。</p><p>当消息完成后，在Group维度ACK消息，此时消息不会被删除，只是这个Group也不会再重复消费到这个消息，而新的Group可以重新消费订阅这些数据。所以在Group维度避免了重复消费的情况，也可以允许重复订阅。</p><p><img src=\"https://static001.geekbang.org/resource/image/17/35/17d26f435043399134305b93f3fe1835.jpg?wh=3228x1488\" alt=\"\"></p><p>纵观业界主流消息队列，三种方案都有在使用，RabbitMQ选择的是第一个方案，Kafka和RocketMQ选择的是第二种方案，Pulsar选择的是第三种方案。不同消息队列的方案选择，主要都是考虑架构设计和组件开发时业务场景的影响。我个人觉得第三种比较合理。</p><p>前面我们虽然反复提到“删除”，但数据实际怎么删除也有讲究。</p><p>我们知道消息数据是顺序存储在文件中的，会有很多分段数据，一个文件可能会有很多行数据。那么在ACK或者数据删除的时候，一个文件中可能既存在可删除数据，也存在不可删除数据。如果我们每次都立即删除数据，需要不断执行“读取文件、找到记录、删除记录、写入文件”的过程，即使批量操作，降低频率，还是得不断地重复这个过程，会导致性能明显下降。</p><p>当前主流的思路都是<strong>延时删除，以段数据为单位清理</strong>，降低频繁修改文件内容和频繁随机读写文件的操作。</p><p><img src=\"https://static001.geekbang.org/resource/image/98/bd/9884d62373887596b694227ef242cfbd.jpg?wh=3228x1488\" alt=\"\"></p><p>只有该段里面的数据都允许删除后，才会把数据删除。而删除该段数据中的某条数据时，会先对数据进行标记删除，比如在内存或 Backlog 文件中记录待删除数据，然后在消费的时候感知这个标记，这样就不会重复消费这些数据。</p><h2>总结</h2><p>消息队列的存储分为元数据存储和消息数据存储两方面。</p><p>元数据的存储主要依赖第三方组件实现，比如ZooKeeper、etcd或者自研的简单元数据存储服务等等。在成熟的消息队列架构中，基于简化架构和提升稳定性的考虑，都会考虑在集群内部完成元数据的存储和管理。</p><p>消息数据的存储在功能层面包含数据存储结构设计、数据分段存储、数据存储格式、数据清理机制四个方面。</p><p>消息数据的存储主要包含Topic和分区两个维度。Topic起逻辑组织作用，实际的数据存储是在分区维度完成的。所以在数据存储目录结构上，我们都以分区为最小粒度去设计，至于选择每个分区单独一个存储文件，还是将每个节点上所有分区的数据都存储在同一个文件，方案各有优劣，你可以根据实际情况去选择。</p><p>因为大文件存在性能和资源占用、数据清理成本等问题，一般情况下，我们都需要对数据文件进行分段处理，分段的策略一般都是按照文件大小进行的。</p><p>数据存储格式可以分为基础信息和业务信息两个维度，数据格式需要遵循极简原则，以达到性能和成本的最优。</p><p>数据的过期策略一般有三种，ACK删除、根据时间和保留大小删除数据、两者结合。目前业界的实现比较多样，从选择上来看，两者结合的方案更合理。</p><h2>思考题</h2><p>如果让你从头实现一个消息队列的存储模块，你的思考路径是什么？</p><p>欢迎分享你的方案，如果觉得有收获，欢迎你把这节课分享给身边的朋友。我们下节课再见。</p><h2><span class=\"orange\">上节课思考闭环</span></h2><p><span class=\"orange\">假如你的团队需要开发一款新的消息队列，你需要完成网络模块的选型开发设计，你的思考路径是什么？</span></p><p><span class=\"reference\">1. 你要了解这款消息队列需要满足什么场景，比如消息、流、IOT等。</span></p><p><span class=\"reference\">2. 理解目标场景的业务形态，比如IOT就需要管理大量连接，消息就需要尽量保证低延时，流的话就需要考虑吞吐问题等等。</span></p><p><span class=\"reference\">3. 根据业务特点分析出技术架构的瓶颈和难点。</span></p><p><span class=\"reference\">4. 考虑技术语言的选型问题，用哪种语言合适，比如Java、Go、Rust、C++等。这点应该结合技术需要和团队本身的技术栈来思考选择哪种语言。</span></p><p><span class=\"reference\">5. 理解这个语言当前网络编程的相关库，网络库、网络库框架，并且调研该语言主流网络编程技巧。</span></p><p><span class=\"reference\">6. 基于理解的网络模块编程思想，结合网络库去实现网络模块。</span></p><p><span class=\"reference\">7. 在最后需要设计压测场景，利用自研或开源的压测工具，最后完成性能和稳定性验证。</span></p>","neighbors":{"left":{"article_title":"04｜网络：如何设计高性能的网络模块？","id":670965},"right":{"article_title":"06｜存储：如何提升存储模块的性能和可靠性？","id":672152}},"comments":[{"had_liked":false,"id":377534,"user_name":"贝氏倭狐猴","can_delete":false,"product_type":"c1","uid":1100690,"ip_address":"江苏","ucode":"0A89A70C48629C","user_header":"https://static001.geekbang.org/account/avatar/00/10/cb/92/cfc1cfd3.jpg","comment_is_top":false,"comment_ctime":1688654224,"is_pvip":false,"replies":[{"id":137623,"content":"你好啊，在我看来这里是有一种细微的差别的。以kafka为例：\n1. 第二种方案，提交了offset后，还可以通过重置offset，来消费到之前消费过的数据。此时就有一种可能，就是客户端错误的重置了offset，此时就会出现重复消费消息的情况。这种场景在kafka里面经常会遇到，这也是kafka无法保证消费不重复的原因所在。\n2. 如果第三种，当ack掉这个消息后，这个消费分组就无法再通过重置offset等操作来消费到已经消费过的数据。只要消息被ack，此时消息就永远(除非提供unack的功能)无法在这个消费分组被重复消费到。此时就避免了同一个消费分组的消息被重复消费的情况。从而提供了不重复消费的语义。\n\n以上，就是我认为kafka是第二种方案的原因","user_name":"作者回复","user_name_real":"编辑","uid":1299071,"ctime":1688950962,"ip_address":"广东","comment_id":377534,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100552001,"comment_content":"老师您好，咨询一个问题：原文“纵观业界主流消息队列，三种方案都有在使用，RabbitMQ 选择的是第一个方案，Kafka 和 RocketMQ 选择的是第二种方案，Pulsar 选择的是第三种方案。不同消息队列的方案选择，主要都是考虑架构设计和组件开发时业务场景的影响。我个人觉得第三种比较合理。”问题是kafka里新group不是也可以消费其他group已经ackknowledged的消息么？那是不是也是第三种方案呢？","like_count":7,"discussions":[{"author":{"id":1299071,"avatar":"https://static001.geekbang.org/account/avatar/00/13/d2/7f/a3d193ea.jpg","nickname":"许文强(LoboXu)","note":"","ucode":"8D6AB35808A88C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":623015,"discussion_content":"你好啊，在我看来这里是有一种细微的差别的。以kafka为例：\n1. 第二种方案，提交了offset后，还可以通过重置offset，来消费到之前消费过的数据。此时就有一种可能，就是客户端错误的重置了offset，此时就会出现重复消费消息的情况。这种场景在kafka里面经常会遇到，这也是kafka无法保证消费不重复的原因所在。\n2. 如果第三种，当ack掉这个消息后，这个消费分组就无法再通过重置offset等操作来消费到已经消费过的数据。只要消息被ack，此时消息就永远(除非提供unack的功能)无法在这个消费分组被重复消费到。此时就避免了同一个消费分组的消息被重复消费的情况。从而提供了不重复消费的语义。\n\n以上，就是我认为kafka是第二种方案的原因","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1688950962,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":377450,"user_name":"勋","can_delete":false,"product_type":"c1","uid":3072985,"ip_address":"浙江","ucode":"390EAAB86257A5","user_header":"https://static001.geekbang.org/account/avatar/00/2e/e3/d9/a8b50c2d.jpg","comment_is_top":false,"comment_ctime":1688525841,"is_pvip":false,"replies":[{"id":137638,"content":"从技术上来看，Dubbo肯定也能做，而且还有facebook的thrift等rpc框架也能做。技术上的差异，我们可以写出很多，比如你说的多语言，协议、性能等等，就先不展开。\n\n但是我理解这个问题可以跳出技术的角度来看。 我会认为主要是社区影响力、技术生态丰富度、研发人员的认知接受度的差异。我认为主要是前两点。\n\nGRPC当前可以说得业界RPC框架的代表了，业界接受度最高。此时带来的结果是，各个社区开源组件对GRPC的支持就很友好，比如Service Mesh，比如多个语言的SDK支持等等。 此时如果选择用GRPC 就会天然和社区的组件联通，减少了很多重复开发，对接的成本。有强强联合的效果。而如果用其他的组件，就会多很多对接、重复开发、客户适配的问题。\n\n","user_name":"作者回复","user_name_real":"编辑","uid":1299071,"ctime":1689045546,"ip_address":"广东","comment_id":377450,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100552001,"comment_content":"老师您好，我问问，不理解dubbo和gRpc的区别，为什么不选dubbo，而是选gRpc作为RPC框架。\n\n按我的理解\n\n1. 序列化\n      1. dubbo默认采用java原生序列化框架、json序列化框架。\n      2. gRpc默认采用protoBuf框架，提高传输效率。\n2. 语言支持\n      1. dubbo跨语言支持较弱。\n      2. gRpc支持多种语言。\n3. 协议\n      1. dubbo支持多种协议，http协议、dubbo协议等\n      2. gRpc 默认为http2协议。http2协议支持NIO模式\n\n问题：\n为啥选gRPC而不是dubbo，dubbo也是基于NIO的多路复用的Reactor模型，也不差，是因为协议不高效、语言支持不够？还是其他原因，麻烦老师解答下。\n\n \n","like_count":6,"discussions":[{"author":{"id":1299071,"avatar":"https://static001.geekbang.org/account/avatar/00/13/d2/7f/a3d193ea.jpg","nickname":"许文强(LoboXu)","note":"","ucode":"8D6AB35808A88C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":623104,"discussion_content":"从技术上来看，Dubbo肯定也能做，而且还有facebook的thrift等rpc框架也能做。技术上的差异，我们可以写出很多，比如你说的多语言，协议、性能等等，就先不展开。\n\n但是我理解这个问题可以跳出技术的角度来看。 我会认为主要是社区影响力、技术生态丰富度、研发人员的认知接受度的差异。我认为主要是前两点。\n\nGRPC当前可以说得业界RPC框架的代表了，业界接受度最高。此时带来的结果是，各个社区开源组件对GRPC的支持就很友好，比如Service Mesh，比如多个语言的SDK支持等等。 此时如果选择用GRPC 就会天然和社区的组件联通，减少了很多重复开发，对接的成本。有强强联合的效果。而如果用其他的组件，就会多很多对接、重复开发、客户适配的问题。\n\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1689045546,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":378244,"user_name":"张洋","can_delete":false,"product_type":"c1","uid":1182914,"ip_address":"北京","ucode":"549BE5DEEF8417","user_header":"https://static001.geekbang.org/account/avatar/00/12/0c/c2/bad34a50.jpg","comment_is_top":false,"comment_ctime":1689932910,"is_pvip":false,"replies":[{"id":138020,"content":"你好啊~\n\n如果仅仅从文件数量的角度来看，就会认为可能有这个问题。但是生产环境中却很少会出现因为索引文件导致硬盘的压力多大的情况。原因是顺序写退化到随机写其实需要满足两个条件：\n1. 文件数量很多。\n2. 这些文件同时都有较大量的读写。\n\n所以核心点在于文件的读写频率和读写数据量的差别。从技术上来看，索引文件不会产生这个问题主要有下面三个原因：\n1. 索引文件的读写频率相对数据文件低很多，一般不会存在大量同时的读写。\n2. 索引文件的数据量很小，即使大量读写，在短时间内就完成了，不会造成持续的压力。\n2. 索引的数据因为数据量较小，一般会缓存到内存中，所以读写对硬盘的压力不大。\n\n所以在大部分情况下，索引文件不会导致顺序写退化到随机写。但是从理论上看，非常极端的场景下是有这个可能的。","user_name":"作者回复","user_name_real":"编辑","uid":1299071,"ctime":1690789754,"ip_address":"广东","comment_id":378244,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100552001,"comment_content":"关于顺序写和随机写有一些问题？Kafka在分区特别多的时候，如果同时写的操作特别多的时候就有可能退化到随机写，但是RocketMq 在写数据的时候（如果Topic queue特别多的情况下）也要写索引文件（ConsumerQueue，IndexFile等等）,虽然是定时刷新的，如果与数据文件同时写的情况下，也有肯能存在退化到随机写的可能，不过这种概率要比Kafka低的多不知道这样理解对吗？","like_count":5,"discussions":[{"author":{"id":1299071,"avatar":"https://static001.geekbang.org/account/avatar/00/13/d2/7f/a3d193ea.jpg","nickname":"许文强(LoboXu)","note":"","ucode":"8D6AB35808A88C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":624630,"discussion_content":"你好啊~\n\n如果仅仅从文件数量的角度来看，就会认为可能有这个问题。但是生产环境中却很少会出现因为索引文件导致硬盘的压力多大的情况。原因是顺序写退化到随机写其实需要满足两个条件：\n1. 文件数量很多。\n2. 这些文件同时都有较大量的读写。\n\n所以核心点在于文件的读写频率和读写数据量的差别。从技术上来看，索引文件不会产生这个问题主要有下面三个原因：\n1. 索引文件的读写频率相对数据文件低很多，一般不会存在大量同时的读写。\n2. 索引文件的数据量很小，即使大量读写，在短时间内就完成了，不会造成持续的压力。\n2. 索引的数据因为数据量较小，一般会缓存到内存中，所以读写对硬盘的压力不大。\n\n所以在大部分情况下，索引文件不会导致顺序写退化到随机写。但是从理论上看，非常极端的场景下是有这个可能的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1690789754,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":377687,"user_name":"Geek_8562b2","can_delete":false,"product_type":"c1","uid":2793035,"ip_address":"江苏","ucode":"48273A7E64A3AC","user_header":"","comment_is_top":false,"comment_ctime":1689039744,"is_pvip":false,"replies":[{"id":137634,"content":"因为数据是写入到硬盘的。 如果同时有很多个文件在同时往硬盘去读写的话。从硬盘的角度来看的话，就是同时在硬盘的不同位置去读写，此时硬盘就得去调度不同位置的读写。即使是SSD和NVME的盘，这种在频繁的在硬盘不同位置的读写就是会降低性能。从硬盘角度来看，就是在不同位置的随机读写。","user_name":"作者回复","user_name_real":"编辑","uid":1299071,"ctime":1689044017,"ip_address":"广东","comment_id":377687,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100552001,"comment_content":"老师，为什么Kafka分区过多会导致顺序读写变为随机读写","like_count":3,"discussions":[{"author":{"id":1299071,"avatar":"https://static001.geekbang.org/account/avatar/00/13/d2/7f/a3d193ea.jpg","nickname":"许文强(LoboXu)","note":"","ucode":"8D6AB35808A88C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":623100,"discussion_content":"因为数据是写入到硬盘的。 如果同时有很多个文件在同时往硬盘去读写的话。从硬盘的角度来看的话，就是同时在硬盘的不同位置去读写，此时硬盘就得去调度不同位置的读写。即使是SSD和NVME的盘，这种在频繁的在硬盘不同位置的读写就是会降低性能。从硬盘角度来看，就是在不同位置的随机读写。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1689044018,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":2793035,"avatar":"","nickname":"Geek_8562b2","note":"","ucode":"48273A7E64A3AC","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1299071,"avatar":"https://static001.geekbang.org/account/avatar/00/13/d2/7f/a3d193ea.jpg","nickname":"许文强(LoboXu)","note":"","ucode":"8D6AB35808A88C","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":623487,"discussion_content":"好的，谢谢老师","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1689563986,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":623100,"ip_address":"江苏","group_id":0},"score":623487,"extra":""}]}]},{"had_liked":false,"id":377212,"user_name":"张申傲","can_delete":false,"product_type":"c1","uid":1182372,"ip_address":"北京","ucode":"22D46BC529BA8A","user_header":"https://static001.geekbang.org/account/avatar/00/12/0a/a4/828a431f.jpg","comment_is_top":false,"comment_ctime":1688095080,"is_pvip":false,"replies":[{"id":137456,"content":"是的，技术上确实是这个原理，但是大部分情况下其实还好。\n因为只有在很极端的情况，比如分区很多，并且都存在读写的场景才会触发。\n在现网，做好运营的话，控制好单机的分区数，触发的概率不大。 - - ","user_name":"作者回复","user_name_real":"编辑","uid":1299071,"ctime":1688104501,"ip_address":"广东","comment_id":377212,"utype":1}],"discussion_count":2,"race_medal":2,"score":2,"product_id":100552001,"comment_content":"每个分区独立一个文件存储，在分区数量较多时会退化成全局磁盘随机I&#47;O，这也是Kafka在多Partition时吞吐量大幅下降的原因~","like_count":3,"discussions":[{"author":{"id":1182372,"avatar":"https://static001.geekbang.org/account/avatar/00/12/0a/a4/828a431f.jpg","nickname":"张申傲","note":"","ucode":"22D46BC529BA8A","race_medal":2,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":622354,"discussion_content":"是的，正常情况下问题不大，我们之前是对Kafka压测出来的这个问题，创建了1k+个Partition且都有读写，发现吞吐量下降确实比较明显。当时还困惑为啥RocketMQ就好很多，今天看到这里豁然开朗😁","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1688120801,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1299071,"avatar":"https://static001.geekbang.org/account/avatar/00/13/d2/7f/a3d193ea.jpg","nickname":"许文强(LoboXu)","note":"","ucode":"8D6AB35808A88C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":622309,"discussion_content":"是的，技术上确实是这个原理，但是大部分情况下其实还好。\n因为只有在很极端的情况，比如分区很多，并且都存在读写的场景才会触发。\n在现网，做好运营的话，控制好单机的分区数，触发的概率不大。 - - ","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1688104501,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":377206,"user_name":"翡翠虎","can_delete":false,"product_type":"c1","uid":1448015,"ip_address":"广西","ucode":"2572E93C4C57A5","user_header":"https://static001.geekbang.org/account/avatar/00/16/18/4f/9e4d5591.jpg","comment_is_top":false,"comment_ctime":1688086373,"is_pvip":false,"replies":[{"id":137457,"content":"从工程的角度来看，消息队列是一个分布式存储系统。而分布式存储系统，底层的技术选型和设计要点其实是差不多的，有很多共性。只是形态和需求不一样，导致实现有差别。","user_name":"作者回复","user_name_real":"编辑","uid":1299071,"ctime":1688104598,"ip_address":"广东","comment_id":377206,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100552001,"comment_content":"存储部分，嗅到了一点 bitcask 的味道，感觉很接近","like_count":1,"discussions":[{"author":{"id":1299071,"avatar":"https://static001.geekbang.org/account/avatar/00/13/d2/7f/a3d193ea.jpg","nickname":"许文强(LoboXu)","note":"","ucode":"8D6AB35808A88C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":622310,"discussion_content":"从工程的角度来看，消息队列是一个分布式存储系统。而分布式存储系统，底层的技术选型和设计要点其实是差不多的，有很多共性。只是形态和需求不一样，导致实现有差别。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1688104598,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":377349,"user_name":"文敦复","can_delete":false,"product_type":"c1","uid":1195258,"ip_address":"四川","ucode":"B8F4A6BD5D7805","user_header":"https://static001.geekbang.org/account/avatar/00/12/3c/fa/e2990931.jpg","comment_is_top":false,"comment_ctime":1688373836,"is_pvip":false,"replies":[{"id":137592,"content":"是的，这里的表达有点问题。我想表达的意思是”缺点是同一个分区的数据一般会在文件中的不同位置，或者不同的文件段中“。我修改一下，谢谢提醒~ 感谢感谢","user_name":"作者回复","user_name_real":"编辑","uid":1299071,"ctime":1688795658,"ip_address":"广东","comment_id":377349,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100552001,"comment_content":"文中提到：（对所有分区公用1个单文件的情况下）缺点是同一个分区的数据一般会在文件中的不同目录。 这个“目录”是不是指文件不同位置的意思？","like_count":0,"discussions":[{"author":{"id":1299071,"avatar":"https://static001.geekbang.org/account/avatar/00/13/d2/7f/a3d193ea.jpg","nickname":"许文强(LoboXu)","note":"","ucode":"8D6AB35808A88C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":622903,"discussion_content":"是的，这里的表达有点问题。我想表达的意思是”缺点是同一个分区的数据一般会在文件中的不同位置，或者不同的文件段中“。我修改一下，谢谢提醒~ 感谢感谢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1688795658,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":377289,"user_name":"阳阳","can_delete":false,"product_type":"c1","uid":2716386,"ip_address":"中国香港","ucode":"5E61EF18F08DF2","user_header":"https://static001.geekbang.org/account/avatar/00/29/72/e2/9a19b202.jpg","comment_is_top":false,"comment_ctime":1688271263,"is_pvip":false,"replies":[{"id":137499,"content":"有这个规划的。我们先把理论讲完，理论扎实了，再一起来实战，效率会更高，效果也更好","user_name":"作者回复","user_name_real":"编辑","uid":1299071,"ctime":1688361419,"ip_address":"广东","comment_id":377289,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100552001,"comment_content":"如果能添加实战的内容就更好了。","like_count":0,"discussions":[{"author":{"id":1299071,"avatar":"https://static001.geekbang.org/account/avatar/00/13/d2/7f/a3d193ea.jpg","nickname":"许文强(LoboXu)","note":"","ucode":"8D6AB35808A88C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":622496,"discussion_content":"有这个规划的。我们先把理论讲完，理论扎实了，再一起来实战，效率会更高，效果也更好","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1688361419,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":377231,"user_name":"aoe","can_delete":false,"product_type":"c1","uid":1121758,"ip_address":"浙江","ucode":"1C6201EDB4E954","user_header":"https://static001.geekbang.org/account/avatar/00/11/1d/de/62bfa83f.jpg","comment_is_top":false,"comment_ctime":1688107816,"is_pvip":false,"replies":[{"id":137479,"content":"区别还是蛮大的，你可以先想想区别是什么。提示一下，可以从功能层面分析底层存储结构的区别","user_name":"作者回复","user_name_real":"编辑","uid":1299071,"ctime":1688201223,"ip_address":"广东","comment_id":377231,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100552001,"comment_content":"MQ 的 Topic、Partition 和 MySQL 的服务层、存储引擎层有点像","like_count":0,"discussions":[{"author":{"id":1299071,"avatar":"https://static001.geekbang.org/account/avatar/00/13/d2/7f/a3d193ea.jpg","nickname":"许文强(LoboXu)","note":"","ucode":"8D6AB35808A88C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":622391,"discussion_content":"区别还是蛮大的，你可以先想想区别是什么。提示一下，可以从功能层面分析底层存储结构的区别","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1688201223,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1121758,"avatar":"https://static001.geekbang.org/account/avatar/00/11/1d/de/62bfa83f.jpg","nickname":"aoe","note":"","ucode":"1C6201EDB4E954","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":622399,"discussion_content":"感谢老师指点错误：\n应该是这段我理解错了「所以从实际数据存储的角度来看，Topic 和 Group 不承担数据存储功能，承担的是逻辑组织的功能，实际的数据存储是在在分区维度完成的。」\n误以为 Topic 和 Group 类似 MySQL Server 层的功能。\n这个疑问我等学了后续内容之后再来看看。\n\nMySQL Server 层：连接器、分析器、优化器、执行器（操作引擎，返回结果）\nMySQL 存储引擎：InnoDB、MyISAM、Memory\n—— 来源：极客时间《MySQL 实战 45 讲》01 | 基础架构：一条SQL查询语句是如何执行的？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1688213319,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":381185,"user_name":"shan","can_delete":false,"product_type":"c1","uid":1321027,"ip_address":"河南","ucode":"DD7C79B1211E68","user_header":"https://static001.geekbang.org/account/avatar/00/14/28/43/5062a59b.jpg","comment_is_top":false,"comment_ctime":1694765279,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100552001,"comment_content":"总结\n\n元数据的存储一般有两种方式：\n1. 基于第三方组件存储，一般会选用此种方式，比如Kafka Zookeeper版本。RocektMQ早期使用Zookeeper，后来选择自己实现注册中心NameServer的方式来替代来替代ZooKeeper；\n优点：集成方便，降低开发难度和工作成本。\n缺点：增加部署和运维的难度，而且第三方组件自身稳定性会增加系统风险。\n2. 在集群内部存储，在集群内部实现类似第三方组件一样的元数据服务，比如Kafka去ZooKeeper的版本。\n优点是运维部署成本低，缺点是开发成本高，与方式一的优缺点刚好相反。\n\n消息数据的存储\n\n存储结构\n一般会消息指定一个Topic，每个Topic下面又划分为多个分区（kafka叫partition，RocketMQ叫MessageQueue），一般有以下两种存储方式：\n1. 每个分区对应一个文件，存储每个分区上的消息，Kafka采用的这种方式实现；\n优点：同一个分区的消息顺序写入同一个文件中，数据存储连续，读写性能都较好。\n缺点：分区太多占用太多的系统FD资源，硬盘层面会出现大量随机写的情况，导致写入性能下降，并且管理复杂；\n2. 每个节点上所有分区的消息都存储在同一个文件，不过需要创建索引文件，记录每条消息在文件中的偏移量，以便快速定位到消息的内容，RocketMQ采用的此种方式；\n缺点：同一个分区的消息被打乱，在读取的时候，无法利用顺序读的优势，影响读取性能。\n优点：管理简单，不会占用太多FD资源，并且写入是顺序写，性能比较高。\n\n数据分段\n数据分段指的是文件的大小，比如默认1G一个文件，超出1G的时候会新建一个文件，分为了多个文件的时候，读取数据需要先定位文件，定位方式有两种：\n1. 根据偏移量定位，通过记录每个文件的起始偏移量、中止偏移量等信息来定位；\n2. 根据索引定位，维护一个单独的索引文件，记录消息在文件的哪个位置，RocketMQ和RabbitMQ采用的是这种方式；\n\n消息数据存储格式\n消息数据存储格式指消息是以什么格式写入到文件中的，里面都包含什么信息。一般会包含通用信息（时间戳、CRC、长度等）和业务信息（事务、系统标记等）两部分。\n\n数据清理机制\n数据清理一般有以下三种实现方式：\n1. 消费完成执行ACK删除：当客户端成功消费数据后，服务端标记删除；\n2. 根据时间和保留大小删除：消息被消费后不会被立刻删除，服务端根据消息的保留策略，开启异步线程进行清理；\n3. ACK机制和过期机制相结的方式；\nRabbitMQ 选择的是第一个方案，Kafka 和 RocketMQ 选择的是第二种方案，Pulsar 选择的是第三种方案。","like_count":2},{"had_liked":false,"id":377210,"user_name":"张申傲","can_delete":false,"product_type":"c1","uid":1182372,"ip_address":"北京","ucode":"22D46BC529BA8A","user_header":"https://static001.geekbang.org/account/avatar/00/12/0a/a4/828a431f.jpg","comment_is_top":false,"comment_ctime":1688091801,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":2,"score":3,"product_id":100552001,"comment_content":"强哥讲的真好~","like_count":2},{"had_liked":false,"id":389199,"user_name":"Spoon","can_delete":false,"product_type":"c1","uid":1959822,"ip_address":"江苏","ucode":"2FF9193AD482C2","user_header":"https://static001.geekbang.org/account/avatar/00/1d/e7/8e/318cfde0.jpg","comment_is_top":false,"comment_ctime":1711808702,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100552001,"comment_content":"根据偏移量定位，当一个分区的消息A被拆分到不同的两个文件中时，这个案例可以详细说一下吗？","like_count":0},{"had_liked":false,"id":389135,"user_name":"柯察金","can_delete":false,"product_type":"c1","uid":1115149,"ip_address":"美国","ucode":"F722BF8FCD2C47","user_header":"https://static001.geekbang.org/account/avatar/00/11/04/0d/3dc5683a.jpg","comment_is_top":false,"comment_ctime":1711639888,"is_pvip":false,"replies":null,"discussion_count":2,"race_medal":0,"score":3,"product_id":100552001,"comment_content":"有一点很不解：\nkafka 分区太多，读写的时候导致随机 io 严重。但是 rocket mq，分区都是写到一个文件，写的随机 io 不严重，但是每个分区的数据交织在一个文件的不同位置，那读的时候不是很严重的随机 io 嘛\n\n很难说哪个更好呢","like_count":0,"discussions":[{"author":{"id":1338136,"avatar":"https://static001.geekbang.org/account/avatar/00/14/6b/18/cebd9dbc.jpg","nickname":"Stark","note":"","ucode":"C0B81192DA1326","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":654073,"discussion_content":"Rocketmq有索引文件的，不会有严重的随机io","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1731840142,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1115149,"avatar":"https://static001.geekbang.org/account/avatar/00/11/04/0d/3dc5683a.jpg","nickname":"柯察金","note":"","ucode":"F722BF8FCD2C47","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1338136,"avatar":"https://static001.geekbang.org/account/avatar/00/14/6b/18/cebd9dbc.jpg","nickname":"Stark","note":"","ucode":"C0B81192DA1326","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":654821,"discussion_content":"不是也要 seek 定位吗，这不就是随机 io 吗","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1733542983,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":654073,"ip_address":"上海","group_id":0},"score":654821,"extra":""}]}]},{"had_liked":false,"id":389119,"user_name":"Faddei","can_delete":false,"product_type":"c1","uid":1990585,"ip_address":"浙江","ucode":"0D31C24E4878B2","user_header":"https://static001.geekbang.org/account/avatar/00/1e/5f/b9/6dbac933.jpg","comment_is_top":false,"comment_ctime":1711615857,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100552001,"comment_content":"老师你好，这节课提到两张存储方案，每个 Partition&#47;Queue 单独一个存储文件，每台节点上所有 Partition&#47;Queue 的数据都存储在同一个文件。","like_count":0}]}