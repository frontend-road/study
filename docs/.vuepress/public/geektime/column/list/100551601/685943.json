{"id":685943,"title":"25｜消息积压：业务突然增长，导致消息消费不过来怎么办？","content":"<p>你好，我是大明。今天我们来学习消息队列中消息积压问题的解决办法。</p><p>我们说的消息积压是指消息生产速率大于消费速率，所以消息会在broker上存放着。消息积压可能会导致消息要等很久才会被消费，这对于一些业务来说损害很大。特别是一些对消息消费时效性有要求的业务，几乎不能容忍任何程度的消息积压。</p><p>消息积压在实践中是一个很容易遇到的问题，尤其是如果你所在的公司处在快速扩张期。因为在实践中很常见，所以在面试中消息积压也是一个热点题目。而大部分人面试的时候，只会说增加分区，又或者说异步消费，但是很难深入讨论。</p><p>其实消息积压的解决方案有很多，一会儿我就带你一个一个看。</p><h2>消费者和分区的关系</h2><p>在 Kafka 里面，一个分区只能有一个消费者，但是一个消费者可以同时消费多个分区。也就是说，如果你有 N 个分区，那么最多只有 N 个消费者，这个时候再增加消费者已经不能提高消费速率了。如果不足 N 个消费者，那么就会有一些消费者同时从多个分区里面拉取数据。</p><p><img src=\"https://static001.geekbang.org/resource/image/c9/41/c9172f4079d1f90eb45d2a99dbab9a41.png?wh=1920x811\" alt=\"图片\"></p><p>这种设计导致我们不能无限制地增加消费者来解决消息积压问题。反过来说，但凡没这种限制，也就没有消息积压这回事了。</p><h2>确定分区数量</h2><p>消息积压也可以看作是分区数量不足引发的问题，毕竟如果分区数量多，就意味着消费者多，消费者足够就肯定不会产生消息积压的问题。所以为了避免消息积压，就要求你在使用消息队列的时候想清楚你需要几个分区。</p><!-- [[[read_end]]] --><p>最正确的做法就是，直接用 Kafka 的性能测试脚本，控制消息的平均大小、吞吐量、分区数量和消费者线程数，执行压测，得出结论。不过实践中还是很少用的，因为在测试环境测了也不一定准，而且你也不敢去生产环境测试。当然，如果你们公司的消息队列团队非常专业，你直接告诉他你预期中的生产者速率、消息大小和消费者速率就可以了，他们会帮你创建好分区数量合适的 topic。</p><p>除此以外，确定分区数量目前并没有什么权威说法或者统一标准，我这里给出一个我个人的标准，你可以作为参考。</p><p>首先，预估生产者的发送速率，这里我们假设 QPS 是 1000。然后估算单独一个分区能撑住多大的写流量，假如说这里 QPS 是 100，那么你至少需要 10 个分区。</p><p>其次，预估消费者的消费速率，这个时候不要考虑异步消费之类的改进措施，假设消费速率是 50，那么你就需要至少 20 个分区。</p><p>通过这两条标准得出的这两个值里取比较大的那个，也就是用 20 个分区，或者你再多加一两个分区作为余量。当然这是一种简单粗暴、方便你理解的算法，但是核心是分区数量要<strong>确保生产者不会阻塞，<strong>同时</strong>确保消费者来得及消费消息</strong>。</p><p>那么单一一个分区能撑住多少写流量该怎么确定呢？你可以通过前面的压测来确定，也可以通过观测消息集群的性能来确定，当然最简单的办法就是问消息队列运维团队。</p><h2>面试准备</h2><p>在面试前，你需要在公司内部收集一些信息。</p><ul>\n<li>你们公司消息队列的监控有哪些？可以利用哪些监控指标来确定消息是否积压？</li>\n<li>在发现消息积压的时候，能不能利用监控的消费速率和生产速率，来推断多久以后积压的消息会被处理完毕？</li>\n<li>你们公司消息积压的真实案例，包括故障原因、发现和定位过程、最终解决方案。</li>\n<li>你负责的业务使用的 topic 还有对应的分区数量。</li>\n<li>如果有可能，你去问问你们消息队列团队的人是怎么计算分区数量的。</li>\n</ul><p>你可以考虑将消息积压纳入你的高性能面试方案中，也就是说解决消息积压问题也是你优化系统性能的一环。你可以在简历中、项目介绍中提及自己解决过消息积压的问题，那么面试官就可能会问你相关的问题。</p><p>此外，还有一些和消息积压有关的问题。</p><ul>\n<li>你的业务 topic 里面用了几个分区？你是怎么确定分区数量的？如果分区数量不够会发生什么？</li>\n<li>什么情况下会发生消息积压？怎么解决消息积压的问题？</li>\n<li>在异步消费的时候，如果你拉取了一批消息，还没来得及提交就宕机了会发生什么？</li>\n</ul><h2>解决方案</h2><p>我这里给出了几个可行的解决方案，每一个方案都有各自的亮点，你在面试的时候根据自己的实际情况挑选其中的两三个来回答就可以了。</p><p>解决消息积压的问题，我们首先要区分清楚是临时性积压还是永久性积压。</p><p>所谓的临时性积压是指消费能力是够的，但是因为突如其来的流量，导致消费者一时半会跟不上速度而引起的积压。而永久性积压是指你的消费者处理能力就是跟不上，所以积压的消息只会越来越多。</p><p>临时性积压基本上都不需要处理，因为随着时间流逝，消费者会慢慢把所有消息都消费完。但是有一种情况例外，那就是你等不及了。而等不及则有多种可能，比如说你的业务要求消费延迟不能超过一分钟，这时候你就要时刻关注消息积压的问题；又或者说你发现这一次突如其来的流量太多了，积攒的消息要好几天才能消费完，这种情况下你多半也无法接受。</p><p>所以你可以先点出这个问题。</p><blockquote>\n<p>消息积压首先要看是临时性积压还是永久性积压。临时性积压是指突如其来的流量，导致消费者一时半会跟不上。而永久性积压则是指消费者的消费速率本身就跟不上生产速率。<br>\n&nbsp;<br>\n如果是临时性积压，并且评估最终消费者处理完积压消息的时间是自己能够接受的，那么就不需要解决。比如说偶发性的消息积压，需要半个小时才能处理完毕，而我完全等得起半小时，就不需要处理。<br>\n&nbsp;<br>\n但要是接受不了，又或者是永久性积压。就要尝试解决了。最简单的办法就是增加消费者，增加到和分区数量一样。不过我想大部分人在遇到消息积压问题的时候，消费者数量都已经和分区数量一样了。</p>\n</blockquote><p>注意这里假设的都是你的消费者数量已经和分区数量一样了，也就是说，你即便再增加消费者也已经没办法提高消费速率了。</p><p><img src=\"https://static001.geekbang.org/resource/image/dd/4f/ddcded8c18b54633ac4df38ee63e774f.png?wh=1920x913\" alt=\"图片\"></p><h3>增加分区</h3><p>最简单的做法就是增加分区，你可以稍微提一下。</p><blockquote>\n<p>另外一种做法就是增加分区，比如说直接增加好几个分区。</p>\n</blockquote><p><img src=\"https://static001.geekbang.org/resource/image/1c/81/1c5b1ecb43740ab4a3ea422e93f61681.png?wh=1920x930\" alt=\"图片\"></p><p>有些时候，公司或者说消息队列的运维是不准你加分区的，那你可以考虑下面这个方案：创建新的 topic。</p><h4>创建新 topic</h4><p>采用这个方案意味着你需要准备一个新的 topic，这个 topic 会有更多的分区。前期消费老的 topic，同时也消费新的 topic。等老的 topic 上的数据都消费完毕之后，就可以完全切换到新的 topic了。</p><p><img src=\"https://static001.geekbang.org/resource/image/0d/46/0ddd8449bc80a92d108b071112fe8846.png?wh=1920x1147\" alt=\"图片\"></p><p>这种做法还有一个变种，就是当你创建了新 topic 之后，把老 topic 上已有的消息转发到这个新的 topic 里面。这样你只需要启动消费者消费新 topic 就可以了。</p><p><img src=\"https://static001.geekbang.org/resource/image/ce/9e/cedb185d31defb9bc07f826ee9a65a9e.png?wh=1920x1173\" alt=\"图片\"></p><p>这个变种的优点就是代码比较容易维护，但是它也会降低消费积压数据的速度。不过你面试的时候还是可以稍微提一下这个方案。</p><blockquote>\n<p>如果公司不允许增加分区的话，那么可以考虑直接创建一个新的 topic。这时候有两种做法，一种是直接启动足够数量的消费者去消费新老 topic 上的消息，在老 topic 上的消息消费完毕之后就可以停掉老的 topic上的消费者了。另外一种做法是启动几个消费者，这些消费者会把老的 topic 上的消息转发到新的 topic 里面。同时启动消费者消费新的 topic。</p>\n</blockquote><blockquote>\n<p>相比之下，第一种做法会更加高效，但是需要多启动几个消费者。</p>\n</blockquote><p>这里，你可以顺势引出另外一个话题。</p><blockquote>\n<p>不过这里的难点都是要计算清楚究竟需要几个分区。比如说，原本八个分区不够，要增加新分区，那么增加几个？如果是创建新 topic，需要几个分区？它本质上是一个分区数量预估的问题。</p>\n</blockquote><p>你一提这一句，大概率面试官就会追问你怎么计算需要的新分区的数量。记住要先强调理论上的最佳做法肯定是通过压测来确定的。</p><h3>新的分区数量</h3><p>这里和一般的分区预估有点不太一样，因为消息积压场景下的瓶颈在于消费者，也就是说，你不需要考虑生产者速率，也不需要考虑broker的速率，你只需要考虑消费者。</p><p>所以最简单的做法就是，用平均生产者速率除以单一消费者的消费速率。在涉及数学计算的时候，你要记得使用一个简单例子来帮助面试官理解计算方式。</p><blockquote>\n<p>要确定新的分区数量的最简单的做法就是用平均生产者速率除以单一消费者的消费速率。<br>\n&nbsp;<br>\n比如说所有的生产者合并在一起，QPS 是 3000。而一个消费者处理的 QPS 是 200，那么 $3000 \\div 200 = 15$。也就是说你需要 15 个分区。进一步考虑业务增长或者突发流量，可以使用 18 个或者 20 个。</p>\n</blockquote><p>这里面试官可能会进一步追问，为什么用平均生产者速率而不是峰值速率？这是因为本身消息队列就承担着削峰的功能，所以在业务巅峰可能会有少量的消息积压，但是这是正常现象，所以可以不考虑。当然，如果有钱有资源，那么就可以按照生产峰值速率来算。</p><h3>优化消费者性能</h3><p>在不能增加消费者数量也不能增加分区数量的时候，还可以考虑提高消费者的消费速率，也就是优化消费者性能。</p><p>优化的思路大体上有两种。</p><ol>\n<li>把消费者部署在更好的实例上，这属于花钱买性能。</li>\n<li>优化消费者的消费逻辑，这跟业务密切相关，本质上是一个性能优化的问题。</li>\n</ol><p>我们能够回答的就是第二点，毕竟第一点是钞能力，不是你的能力。可惜的是，它毕竟是一个和业务密切相关的话题，所以我只能给你一个案例来参考。你也可以自己看看公司内部所有的消费者代码，找找看有没有可以优化的，作为你面试的真实案例。</p><blockquote>\n<p>还有一个思路是优化消费者的性能。早期我在公司的时候就优化过消费者的性能。我们的业务逻辑也不是特别复杂，但是因为考虑同一个业务的消息可能被不同的消费者消费，所以在消费消息的时候引入了一个分布式锁。<br>\n&nbsp;<br>\n但是，实际上我们可以通过主动选择目标分区使相同的业务总是把消息发到同一个分区上，确保同一时间只有一个消费者处理一个业务的消息，这样就可以把分布式锁去掉。它带来的好处就是，当没有分布式锁的时候，也不会有消费者因为等待分布式锁而导致消费速率下降了。</p>\n</blockquote><p><img src=\"https://static001.geekbang.org/resource/image/af/f8/af9dcfab76f8dac7141f335c721157f8.png?wh=1920x864\" alt=\"图片\"></p><p>这个案例非常精巧，它充分结合了消息队列、分布式锁，还借鉴了解决有序消息的思路。所以这个案例不光这里可以用，在聊起性能优化和分布式锁的时候也可以用。</p><h3>消费者降级</h3><p>这一次你又接触到了降级。不过这个降级不是为了保护消费者，而是为了提高消费速率。使用这个方案的前提是你的业务能接受有损消费消息。这里你可以参考微服务降级部分的内容，比如说如果你的业务有快慢路径之分，那么可以考虑在消息积压的情况下只执行快路径。</p><p>这里我就不再重复降级有关的内容，直接给你一个案例更能说明问题，同样的，你也可以在公司内部找找有没有消费者的逻辑是可以用上这种降级策略的。</p><blockquote>\n<p>我也尝试过利用微服务中的降级思路来解决消息积压的问题。但是这个降级本身并不是为了保护系统，而是为了加快消费速率。在之前出现消息积压的场景里面，消费者的处理逻辑总体上可以认为就是调用几个接口，计算一个值，然后放到缓存里面，缓存过期时间就是 15 分钟。这些提前计算出来的结果就是给查询接口使用的，查询接口如果都自己算的话，性能会比较差。<br>\n&nbsp;<br>\n在不触发降级的时候，也就是没有消息积压的时候，就正常算。但是在消息积压的时候，如果缓存里面有对应的数据，那就不算，否则就重新计算一下。这种降级逻辑是基于这样一个底层逻辑，就是如果这个数据本身过期时间是十五分钟，那么我即便不更新，用户拿到的无非就是十五分钟以内的一个不准确的数据。这在我们业务上是可以接受的。<br>\n&nbsp;<br>\n而如果缓存不存在了，那么就确实需要重新计算一遍，避免查询接口自己实时计算。<br>\n&nbsp;<br>\n在引入了这种降级策略之后，大概有 1/3 的消息处理逻辑是被降级的。</p>\n</blockquote><p>这个案例最大的优点就是，降级并不仅仅是局限在了微服务中，而是被你用在了消息消费上，它能够体现你对服务治理的深刻理解，还有灵活敏锐的思维。</p><h3>聚合消息与批量操作</h3><p>假如说你现在有一个业务，是要从数据库里筛选出一批数据，然后针对每一条数据进行处理。处理之后，会发送一条消息到消息队列，消费者再一条条取出来处理。</p><p>这里我们假设消息的关键字段就是带上业务 ID，例如 <code>msg1(biz_id = 1)</code>。但是，消费者这边也是有批量接口的。也就是说，如果发送消息的时候在一条消息里面直接带上批量数据，消费者这边也可以借助批量接口一次性处理完。</p><p>也就是说，发送者发送的数据是 <code>msg2(biz_ids=1,2,3,4)</code>，消费者可以一次性处理完毕。</p><p><img src=\"https://static001.geekbang.org/resource/image/22/30/22491b5766cfe928576771af9de69d30.png?wh=1920x661\" alt=\"图片\"></p><p>这种调整带来了两方面的好处。一方面自然是消费者借助批量接口处理，速度有数量级的提升；另外一个则是消息所需的存储空间大大降低，broker的负载也会降低不少。</p><p>这里我直接整理成对应的话术，供你参考，如果你有类似的场景，也可以使用自己的案例来替换。</p><blockquote>\n<p>还有一种思路是聚合消息和批量操作来优化性能。之前我有一个业务，生产者那边是按照用户输入的参数来查找符合条件的数据，然后一条条处理的。每条数据处理完毕之后就发送一条消息到消息队列里面。简单来说，就是消息里会带上业务 ID。同时消费者消费消息，根据业务 ID 进一步处理。<br>\n&nbsp;<br>\n后来随着业务增长就出现了消息积压的问题，我负责解决这个问题。在经过排查之后，我发现其实消费者这边是可以批量处理的。所以我就先研发了批量接口，通过性能测试发现批量接口有了一个数量级性能的提升。然后我又开始改造生产者，让生产者不再是一条数据发一条消息，而是一批数据发一条消息。消费者这边也改造成了使用批量接口。<br>\n&nbsp;<br>\n上线之后积压的消息很快就被处理完了，并且到现在都没再出现消息积压的问题。而且因为消费速率非常高，所以反而削减了两个消费者，节省了一点资源。<br>\n&nbsp;<br>\n这个方案 最大的优点就是业务改造的成本不高。尤其是在消费者端，对于历史积压的消息，还是调用批量接口，只不过传入的业务 ID 只有一个而已。</p>\n</blockquote><p>接下来你要进一步总结出一般的规律，刷一个亮点。</p><blockquote>\n<p>这种方式一般适用于消费者可以改造成批量接口的场景，而且可以考虑不改造生产者，只改造消费者。把消费者改造成批量消费、批量提交偏移量。比如说消费者一次性拉取 100 条消息，构造批量处理请求。在处理成功之后，再提交偏移量。这种批量消费，再批量提交的做法也可以用于异步消费中。</p>\n</blockquote><p>显然，最后提到异步消费，就是为了引出下一个解决方案，也是我们的核心解决方案——异步消费。</p><h3>异步消费</h3><p>你可以先看一下最简单的异步消费架构图。</p><p><img src=\"https://static001.geekbang.org/resource/image/5d/01/5d0d5ed1503d23bb128d3a6a81da5301.png?wh=1920x839\" alt=\"图片\"></p><p>结合图片，你可以简单介绍一下这个方案。</p><blockquote>\n<p>也可以考虑用异步消费来解决消息积压的问题。所谓的异步消费就是指在消费者这边有一个消费者线程，负责从消息队列里面拉取消息。同时拉到的消息会立刻转发给一个线程池，线程池里面会有一些工作线程负责处理消息。这个方案对生产者毫无影响，但是消费者这边要小心消息丢失的问题。</p>\n</blockquote><p>在这个回答里面，因为聊到了线程池，那么面试官也可能问你线程池相关的问题。同时，你提到了消息丢失的问题，面试官有极大概率会追问你消息丢失该怎么处理。</p><h4>消息丢失</h4><p>所谓的消息丢失是指你的消费者线程取出消息之后，要想继续消费下一条就得先提交当前这一条。这种情况下，就可能会出现一个问题：消费者线程提交了，但是工作者线程还没处理就宕机了。这个时候，因为你已经提交了，所以就算重启，你也是从下一条开始消费。</p><p>就算你不主动提消息丢失的问题，面试官也会主动问你怎么解决，那么你就可以抓住关键词<strong>批量提交</strong>来回答。</p><blockquote>\n<p>要解决消息丢失，那么就可以考虑使用批量提交的方法。也就是说，消费者线程一次拉取一批消息，比如说 10 条。然后，并不是说立刻提交这 10 条消息，而是直接开启十个线程，并行处理这 10 条消息。等到 10 条消息都处理完毕，再批量提交。</p>\n</blockquote><p><img src=\"https://static001.geekbang.org/resource/image/91/06/91275e07c2f6cb591cb5dc7be2e77b06.png?wh=1920x907\" alt=\"图片\"></p><p>在批量提交这个方案里面，还是有破绽的，你可以进一步引导。</p><blockquote>\n<p>批量提交的效果是很好的，可以做到数量级性能提升。但是它的缺陷也很明显，就是重复消费和部分失败的问题。</p>\n</blockquote><h4>重复消费</h4><p>批量提交很容易出现重复消费的问题。在消费者线程拉取了一批消息之后，如果过了一段时间还没提交就宕机了，那么会发生什么？</p><ol>\n<li>可能所有的消息都还没被处理或者正在处理。</li>\n<li>部分消息被处理了，可能成功可能失败。</li>\n<li>全部消息都被处理了，可能成功可能失败，还来不及提交。</li>\n</ol><p>可以预见的是，因为没有提交，所以当消费者从宕机中恢复过来的时候，就会拉取同一批继续消费。怎么办？</p><p>很简单，保证处理消息的逻辑是幂等的就可以。也就是同一条消息，你反复处理多少次，最终结果都是一样的。所以抓住关键词<strong>幂等</strong>来回答。</p><blockquote>\n<p>对于重复消费来说，解决方案也很简单，就是让消费逻辑保证是幂等的。这样，即便宕机导致消息被消费了但是来不及提交，也可以保证在下一次恢复过来的时候，重复处理不会引起什么业务问题。</p>\n</blockquote><h4>部分失败</h4><p>在批量提交里面，还有一个非常棘手的问题就是一批消息里面部分消息处理失败了怎么办？</p><p>实际上，如果考虑到要继续消费，你肯定可以得出一个结论：要继续提交，然后继续消费下一批。不过，在提交之前你可以做很多事情。最简单的做法就是，当某个工作线程失败的时候，直接重试。但是要注意，当工作线程重试的时候，其他工作线程也在等它，所以你要控制住重试的次数和重试的整体时间。</p><p><img src=\"https://static001.geekbang.org/resource/image/4a/ed/4a121b11e2dcc617c28a44056287b9ed.png?wh=1920x955\" alt=\"图片\"></p><p>当然你也可以考虑异步重试。</p><p><img src=\"https://static001.geekbang.org/resource/image/7f/f7/7f9bd57c3fe4823281f4b4c09cfbabf7.png?wh=1920x1008\" alt=\"图片\"></p><p>但是，你还有一个更加优雅的动作，就是失败之后，这个工作线程把这个消息再次丢回消息队列。这个丢回去的动作实际上是产生了一个全新的消息，只不过消息内容一模一样而已。</p><p><img src=\"https://static001.geekbang.org/resource/image/6f/43/6ffd9fbc1b838d0c3ae991358ca79e43.png?wh=1920x973\" alt=\"图片\"></p><p>这里你要注意，你可能需要在消息里面记录一下你已经处理过几次了。比如说你限制只能重试三次，那么三次重试都失败了，你就不要再丢回去了。</p><p>你可以把这三个方案放在一起回答。</p><blockquote>\n<p>在部分失败的情况下，第一种做法是要求工作线程立刻重试，比如说重试三次，也可以用一个全新的异步线程来重试。当然，也可以考虑把消费失败的消息丢回消息队列里，后面再轮到它的时候又会被处理，这就相当于重试了。这些方案的核心都是确保部分失败不会影响继续向前消费。</p>\n</blockquote><p>到这里，整个异步消费方案就非常完整了，而且讨论得也足够深入了。</p><h2>面试思路总结</h2><p>今天这节课我们讨论了消息积压的问题。为了让你更好地理解消息积压，我在前置知识里面先介绍了消费者和分区的关系，还有怎么确定分区数量。确定分区数量在面试中比较常见，你要记牢。</p><p>为了解决消息积压问题，我还准备了五个案例，分别是<strong>增加分区、优化消费者性能、消费者降级、聚合消息与批量操作、异步消费</strong>。你可以根据自己的经历来选择方案用于面试，但是我也建议你在面试的时候尽量用上异步消费，并且深入讨论里面的<strong>消息丢失、重复消费和部分失败</strong>三个问题。</p><p><img src=\"https://static001.geekbang.org/resource/image/1f/02/1f73f07effd8ea0dcb2e8706deb68802.jpg?wh=2082x1488\" alt=\"\"></p><h2>思考题</h2><p>最后也请你来思考两个问题。</p><ul>\n<li>有些人认为，优化生产者性能也能解决消息积压，你觉得能还是不能？为什么？</li>\n<li>在出现消息积压的时候，能不能在生产者发送的时候加个限流？毕竟，限制住了发送消息的速率，自然就解决了消息积压。</li>\n</ul><p>欢迎你把你的答案分享在评论区，也欢迎你把这节课的内容分享给需要的朋友，我们下节课再见！</p>","neighbors":{"left":{"article_title":"24｜消息顺序：保证消息有序，一个 topic 只能有一个 partition 吗？","id":685914},"right":{"article_title":"26｜消息不丢失：生产者收到写入成功响应后消息一定不会丢失吗？","id":687062}},"comments":[{"had_liked":false,"id":379773,"user_name":"TimJuly","can_delete":false,"product_type":"c1","uid":1065064,"ip_address":"北京","ucode":"56FE7BF7447DEA","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eooNCNEO0vhRiagdrCnNW2LWzzV4g5tXJ9KkTu9hegCTx6lBrA06AZ3Uylb2wdKjvtrmZUWkKKHTGA/132","comment_is_top":false,"comment_ctime":1692456601,"is_pvip":false,"replies":[{"id":138412,"content":"好思路，防止生产者自己有坑！好思路！","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1692893382,"ip_address":"广东","comment_id":379773,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"在出现消息积压的时候，能不能在生产者发送的时候加个限流？\n---\n这个要看是什么原因导致的积压\n如果是消费方能力不足导致的那就不应该给生产者加限流\n如果是生产者出 bug 了，写了个死循环拼命生产消息，那么该加限流还是要加的，毕竟 MQ 它性能再高也是需要进行保护的，更别说下游系统了。","like_count":6,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":626427,"discussion_content":"好思路，防止生产者自己有坑！好思路！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1692893382,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":379433,"user_name":"陈斌","can_delete":false,"product_type":"c1","uid":1367048,"ip_address":"广东","ucode":"B639AB5F6AA03D","user_header":"https://static001.geekbang.org/account/avatar/00/14/dc/08/64f5ab52.jpg","comment_is_top":false,"comment_ctime":1691947204,"is_pvip":false,"replies":[{"id":138258,"content":"赞！\n生产者这边限流的问题就在于，违背了引入消息队列的本意。不过如果说被限流的请求，是转储到本地，后续再转发到 Kafka，那还可以接受。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1692078508,"ip_address":"广东","comment_id":379433,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"有些人认为，优化生产者性能也能解决消息积压，你觉得能还是不能？为什么？\n我认为这是一个没有标准答案的问题，主要看对消息积压这个名词的理解；例如整个流程是生产者拿到消息（从前端、其他上游组件甚至说另一个消息队列中）之后处理的很慢，导致写入消息队列速度很慢，而消费者都是实时消费生产者产生的消息。从整体流程上来看好像消息积压确实是在生产者这里，但是如果你把消息积压理解的更狭隘一点，消息积压中的消息你认为是消息队列中的消息，只看最后一段流程，生产者都没有生产消息，何来消息积压之说。\n\n在出现消息积压的时候，能不能在生产者发送的时候加个限流？毕竟，限制住了发送消息的速率，自然就解决了消息积压。\n看具体业务，如果业务流程中在流量高峰期确实可以做限流操作，那确实可以限制住最高的流量生产速度，如果所有消费者的消费速度确实可以cover住所有生产者的生产速度，自然就可以解决消息积压问题。此时的消息积压一般是瞬时流量徒增导致的。","like_count":5,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":625694,"discussion_content":"赞！\n生产者这边限流的问题就在于，违背了引入消息队列的本意。不过如果说被限流的请求，是转储到本地，后续再转发到 Kafka，那还可以接受。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1692078509,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":3601364,"avatar":"https://static001.geekbang.org/account/avatar/00/36/f3/d4/86a99ae0.jpg","nickname":"哆啦a喵","note":"","ucode":"AE5E51BB43753D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":644009,"discussion_content":"我之前这么说过，然后面试官问我，如果流量太大，本地不够存怎么办 = = ","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1714891602,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":625694,"ip_address":"北京","group_id":0},"score":644009,"extra":""}]}]},{"had_liked":false,"id":379541,"user_name":"子休","can_delete":false,"product_type":"c1","uid":1131592,"ip_address":"上海","ucode":"EDB61FB012C195","user_header":"https://static001.geekbang.org/account/avatar/00/11/44/48/fae317c1.jpg","comment_is_top":false,"comment_ctime":1692084529,"is_pvip":false,"replies":[{"id":138353,"content":"赞！第一个问题的角度很刁钻，受教了。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1692542597,"ip_address":"广东","comment_id":379541,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"有些人认为，优化生产者性能也能解决消息积压，你觉得能还是不能？为什么？\n优化生产者性能可以从一定程度上缓解消息积压，比如kafak的批量读写和压缩的特性，就是提升了高吞吐，以及本文中提到的聚合消息和批量消费也是优化了生产者发送。\n\n\n在出现消息积压的时候，能不能在生产者发送的时候加个限流？毕竟，限制住了发送消息的速率，自然就解决了消息积压。\n如果在生产者上面加限流，那么消息中间件的削峰作用也就丧失了。虽然这样限制了发送消息的速率，看似解决了消息积压，但是消息中间件本身的削峰特性就大大丧失了，有点得不偿失。\n另外，如果生产者自己做限流的话，很可能会对生产者本身造成巨大的资源负担，因为这样会导致生产者被限流限制，要持续不断地运行逻辑发消息。","like_count":2,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":626110,"discussion_content":"赞！第一个问题的角度很刁钻，受教了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1692542597,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":385098,"user_name":"程序员花卷","can_delete":false,"product_type":"c1","uid":1665471,"ip_address":"云南","ucode":"DDCFE578C6C428","user_header":"https://static001.geekbang.org/account/avatar/00/19/69/bf/58f70a2a.jpg","comment_is_top":false,"comment_ctime":1702040097,"is_pvip":false,"replies":[{"id":140766,"content":"就是你自己再额外开线程，然后自己控制线程数量。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1704190195,"ip_address":"广东","comment_id":385098,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"异步消费这个没太理解，比如RocketMQ默认就是使用线程池消费消息的，那这个异步消费还要怎么加，老师是否能给点具体的思路？一堆消息取出来之后再塞入某个本地队列然后进行异步的消费吗？","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":634927,"discussion_content":"就是你自己再额外开线程，然后自己控制线程数量。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1704190195,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":382415,"user_name":"kai","can_delete":false,"product_type":"c1","uid":1018452,"ip_address":"美国","ucode":"443ED92B59AB8C","user_header":"","comment_is_top":false,"comment_ctime":1697267763,"is_pvip":true,"replies":[{"id":139357,"content":"1. 首先如果怀疑是网络传输的问题，有没有办法在深圳那边也部署同样地消费者，比如说部署个一台两台，看看性能，这样就能排除是否是网络传输的问题。\n2. 除了排查 CPU，还要看看磁盘 IO，网络带宽这些。\n\n我看你的说法是大半年了代码都没变过，但是消费量下降了一半。我个人是觉得这有点奇诡，你确定一下消息消费逻辑，以及消息大小有没有变过。\n\n比如说你这边可能没变过，但是你依赖的上下游变了，也有可能导致你消费速率变慢。\n\n如果你并不想深究问题根源，只是单纯想要提高性能，那就可以直接考虑增加分区（或者创建新 topic），或者引入异步消费。\n\n还是得先确认问题根源。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1697725352,"ip_address":"广东","comment_id":382415,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"请问老师，有个问题一直没有解决，想咨询一下您。问题是这样的：\n\n我们有一个消费者应用（同一个消费组下有 16 个消费者），部署在上海，消费深圳的 Kafka 集群的一个 Topic（16 个分区），消费之后在内存中，取出部分字段，通过 16 个生产者将数据异步发送到上海 Kafka 集群。\n\n去年同期，消费的性能大概在 6300 QPS，但是今年大概只有 3000QPS，深圳和上海 Kafka 集群没有变化，消费应用没有变化，消费应用所在的服务器也没有变化，CPU 内存使用率大概在 50% 左右。\n\n比较奇怪的一点是消费带宽一直没有上去。\n\n消费应用的消费者参数：\nfetch.min.bytes：100000\n\n生产者参数：\nbatch.size：200000\nlinger.ms：100\ncompress.type：lz4\n\n客户端做了各种尝试也没有提高性能，怀疑是上海到深圳之间基础网络层面有问题，但是又无法证明，因为这条路上没办法抓包。\n\n请问一下，这种情形下如何提升消费 QPS 呢？","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":629860,"discussion_content":"1. 首先如果怀疑是网络传输的问题，有没有办法在深圳那边也部署同样地消费者，比如说部署个一台两台，看看性能，这样就能排除是否是网络传输的问题。\n2. 除了排查 CPU，还要看看磁盘 IO，网络带宽这些。\n\n我看你的说法是大半年了代码都没变过，但是消费量下降了一半。我个人是觉得这有点奇诡，你确定一下消息消费逻辑，以及消息大小有没有变过。\n\n比如说你这边可能没变过，但是你依赖的上下游变了，也有可能导致你消费速率变慢。\n\n如果你并不想深究问题根源，只是单纯想要提高性能，那就可以直接考虑增加分区（或者创建新 topic），或者引入异步消费。\n\n还是得先确认问题根源。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1697725352,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":382344,"user_name":"chooseTime","can_delete":false,"product_type":"c1","uid":1229743,"ip_address":"内蒙古","ucode":"D3F836DC016AF7","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/eAXOa0O1reSCoMRUK9V4NgVlRsiaRZicvRLczuzxsKq82jUscVuwgF8WVPEQI1wL3fruo3icnPv8fmv9q2ab1jRrw/132","comment_is_top":false,"comment_ctime":1697097158,"is_pvip":false,"replies":[{"id":139354,"content":"有一部分我倒是在我的训练营里面写过，不过都是比较简单的微服务部分和缓存部分，这边 MQ 部分的做起来代码量比较大，所以我就没有搞开源版本。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1697724883,"ip_address":"广东","comment_id":382344,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"有代码实例实战吗","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":629857,"discussion_content":"有一部分我倒是在我的训练营里面写过，不过都是比较简单的微服务部分和缓存部分，这边 MQ 部分的做起来代码量比较大，所以我就没有搞开源版本。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1697724884,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":381818,"user_name":"锅菌鱼","can_delete":false,"product_type":"c1","uid":1131961,"ip_address":"广东","ucode":"82EC0452ED0E38","user_header":"https://static001.geekbang.org/account/avatar/00/11/45/b9/3db96ade.jpg","comment_is_top":false,"comment_ctime":1695893946,"is_pvip":false,"replies":[{"id":139232,"content":"异步和重试并不冲突的。比如说在批量异步里面。你完全可以在某一条消息失败之后，重新丢回去消息队列，而后再批量提交。\n\n不过确实要比非异步，用起来麻烦很多，要做一些额外的工作。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1696923340,"ip_address":"广东","comment_id":381818,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"异步消费不是一个好的方案，MQ提供重试就没用了，少了一层业务保证","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":629300,"discussion_content":"异步和重试并不冲突的。比如说在批量异步里面。你完全可以在某一条消息失败之后，重新丢回去消息队列，而后再批量提交。\n\n不过确实要比非异步，用起来麻烦很多，要做一些额外的工作。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1696923340,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":380450,"user_name":"浩仔是程序员","can_delete":false,"product_type":"c1","uid":1104601,"ip_address":"广东","ucode":"A7E5CF9E1571A2","user_header":"https://static001.geekbang.org/account/avatar/00/10/da/d9/f051962f.jpg","comment_is_top":false,"comment_ctime":1693622467,"is_pvip":false,"replies":[{"id":138571,"content":"感谢提醒，我们更新一下🌹","user_name":"编辑回复","user_name_real":"编辑","uid":2843479,"ctime":1693627537,"ip_address":"河北","comment_id":380450,"utype":2}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"最后总结的思维导图，增加分区那里有两个点重复了，都是根据消费者速率计算新的分区数量","like_count":0,"discussions":[{"author":{"id":2843479,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/63/57/cba4c68b.jpg","nickname":"小虎子🐯","note":"","ucode":"4C9530B3FB407B","race_medal":0,"user_type":8,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":627023,"discussion_content":"感谢提醒，我们更新一下🌹","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1693627537,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"河北","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":8}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":380348,"user_name":"Geek8004","can_delete":false,"product_type":"c1","uid":2328971,"ip_address":"中国香港","ucode":"B3828F6414BDB0","user_header":"","comment_is_top":false,"comment_ctime":1693404147,"is_pvip":false,"replies":[{"id":138533,"content":"好问题。\n这也是你架构要考虑的问题。第一个是其它 9 条都不提交，停下来等重试。如果重试都失败了就告警，这个时候也会提交。\n\n第二种做法是，只要执行一次就提交，你失败了的话，后面自己再异步重试。这种做法是首先要保证能够持续向后消费。\n\n幂等方案，你是指啥分享？","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1693487953,"ip_address":"广东","comment_id":380348,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"假如批量消费10条数据,第9条数据消费失败,采用异步重新执行的方案,那成功执行的剩下9条数据会提前先提交吗?假如异步这个线程充实了好多次都没成功咋办,这会不会造成了消息丢失了呀~\n第二个问题,老师您能分享一节幂等方案的课程吗?","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":626913,"discussion_content":"好问题。\n这也是你架构要考虑的问题。第一个是其它 9 条都不提交，停下来等重试。如果重试都失败了就告警，这个时候也会提交。\n\n第二种做法是，只要执行一次就提交，你失败了的话，后面自己再异步重试。这种做法是首先要保证能够持续向后消费。\n\n幂等方案，你是指啥分享？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1693487953,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":379492,"user_name":"peter","can_delete":false,"product_type":"c1","uid":1058183,"ip_address":"北京","ucode":"261C3FC001DE2D","user_header":"https://static001.geekbang.org/account/avatar/00/10/25/87/f3a69d1b.jpg","comment_is_top":false,"comment_ctime":1692013938,"is_pvip":false,"replies":[{"id":138255,"content":"业务不是幂等的话，坦白来说你只能考虑将消息 ID 做成唯一索引，然后封装和业务一样的本地事务里面。\n\n而且，我个人经验表名大部分业务都是可以改造成幂等的。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1692078304,"ip_address":"广东","comment_id":379492,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"对于消息重复消费，业务有不是幂等的情况吗？ 如果不是幂等，该怎么处理？","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":625691,"discussion_content":"业务不是幂等的话，坦白来说你只能考虑将消息 ID 做成唯一索引，然后封装和业务一样的本地事务里面。\n\n而且，我个人经验表名大部分业务都是可以改造成幂等的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1692078304,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":379449,"user_name":"shuff1e","can_delete":false,"product_type":"c1","uid":1756280,"ip_address":"北京","ucode":"85601271951B5A","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83ep075ibtmxMf3eOYlBJ96CE9TEelLUwePaLqp8M75gWHEcM3za0voylA0oe9y3NiaboPB891rypRt7w/132","comment_is_top":false,"comment_ctime":1691983672,"is_pvip":false,"replies":[{"id":138256,"content":"对！！！也就是生产者那边限制，连治标都算不上。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1692078333,"ip_address":"广东","comment_id":379449,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100551601,"comment_content":"在出现消息积压的时候，能不能在生产者发送的时候加个限流？\n------\n感觉还是要回到系统的本质，而不是为了解决问题而解决问题。\n消息队列本来就是削峰填谷，如果不让消息队列积压，那就会积压在生产者那里。","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":625692,"discussion_content":"对！！！也就是生产者那边限制，连治标都算不上。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1692078334,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":390935,"user_name":"黄堃健","can_delete":false,"product_type":"c1","uid":2037522,"ip_address":"广东","ucode":"B4AD5250A41B3A","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/YbUxEV3741vKZAiasOXggWucQbmicJwIjg3HDE58oyibYXbSop9QQFqZ7X6OhynDoo6rDHwzK8njSeJjN9hx3pJXg/132","comment_is_top":false,"comment_ctime":1716797470,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100551601,"comment_content":"候有两种做法，一种是直接启动足够数量的消费者去消费新老 topic 上的消息，在老 topic 上的消息消费完毕之后就可以停掉老的 topic 上的消费者了。另外一种做法是启动几个消费者，这些消费者会把老的 topic 上的消息转发到新的 topic 里面。同时启动消费者消费新的 topic。 ---  老师，采用新的topic不怕有消费失序的问题吗？","like_count":0}]}