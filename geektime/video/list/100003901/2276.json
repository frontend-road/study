{"id":2276,"title":"16 | 微服务监控系统分层和监控架构","content":"<p>无</p>\n","comments":[{"had_liked":false,"id":2385,"user_name":"LMD","can_delete":false,"product_type":"c3","uid":1013443,"ip_address":"","ucode":"7626FBB7A4E771","user_header":"","comment_is_top":true,"comment_ctime":1516964861,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100003901,"comment_content":"关于《微服务架构核心20讲》课程讲义（PDF 文件），学员可复制下面链接到浏览器下载获取。 http:&#47;&#47;t.cn&#47;RQs9iTw","like_count":5},{"had_liked":false,"id":8972,"user_name":"LEON","can_delete":false,"product_type":"c3","uid":1109922,"ip_address":"","ucode":"58F7AF5302FCAD","user_header":"https://static001.geekbang.org/account/avatar/00/10/ef/a2/6ea5bb9e.jpg","comment_is_top":false,"comment_ctime":1526549472,"is_pvip":false,"replies":[{"id":2788,"content":"log是文本日志。metrics一般是数据点，也称时间序列（time series），格式如(value, timestamp)，比方说CPU的使用率，某个API的单位时间调用次数，都是可以数字化的，并且可以定时记录起来，就形成了一串的时间序列数据，这些时间序列可以存起来，而且可以在像grafana这样的工具中进行分析展示。metrics可以认为是一种特殊的日志，使用特殊的方式存储。当前log一般存elasticsearch分布式搜索引擎，metrics一般存时间序列数据库（例如opentsdb, influxDB等）。log一般是用在调试和Trouble Shooting等场景，metrics一般用在系统和应用性能监控场景，或者是业务数据分析等场景。log数据可以进一步分析产生出metrics来。","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1526740303,"ip_address":"","comment_id":8972,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100003901,"comment_content":"老师您好，metrics具体指的是什么？一般收集有什么用？我理解有log吐向elk就够了。log里面也有时间戳。他和metrics的具体区别是什么？谢谢","like_count":12,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":417927,"discussion_content":"log是文本日志。metrics一般是数据点，也称时间序列（time series），格式如(value, timestamp)，比方说CPU的使用率，某个API的单位时间调用次数，都是可以数字化的，并且可以定时记录起来，就形成了一串的时间序列数据，这些时间序列可以存起来，而且可以在像grafana这样的工具中进行分析展示。metrics可以认为是一种特殊的日志，使用特殊的方式存储。当前log一般存elasticsearch分布式搜索引擎，metrics一般存时间序列数据库（例如opentsdb, influxDB等）。log一般是用在调试和Trouble Shooting等场景，metrics一般用在系统和应用性能监控场景，或者是业务数据分析等场景。log数据可以进一步分析产生出metrics来。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1526740303,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":30390,"user_name":"怪盗キッド","can_delete":false,"product_type":"c3","uid":1048065,"ip_address":"","ucode":"D96BC268F5FB6C","user_header":"https://static001.geekbang.org/account/avatar/00/0f/fe/01/3f3ae95e.jpg","comment_is_top":false,"comment_ctime":1538822773,"is_pvip":false,"replies":[{"id":11735,"content":"不错很强👍","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1539517135,"ip_address":"","comment_id":30390,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100003901,"comment_content":"Hi，我利用ASM写了一个高性能、低消耗且无侵入的 Java 性能监控工具 MyPerf4J，通过 JavaAgent 方式对 Java 方法进行字节码注入，可以统计出方法的执行性能指标，包括 RPS、Avg、Min、Max、StdDev、 TP50、TP90、TP99、TP999 等；同时也支持 JVM 监控，包括 Thread、GC、Memory 和 ClassLoad。\nGitHub 地址：https:&#47;&#47;github.com&#47;ThinkpadNC5&#47;MyPerf4J","like_count":5,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":425975,"discussion_content":"不错很强👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1539517135,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":7768,"user_name":"张鑫","can_delete":false,"product_type":"c3","uid":1030197,"ip_address":"","ucode":"9A0AE1DD952B59","user_header":"https://static001.geekbang.org/account/avatar/00/0f/b8/35/86e333b9.jpg","comment_is_top":false,"comment_ctime":1525706208,"is_pvip":false,"replies":[{"id":2285,"content":"日志监控一定要有，用ELK收集应用日志，方便排查错误和性能问题，其它监控可暂缓","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1525792954,"ip_address":"","comment_id":7768,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100003901,"comment_content":"请问杨老师，对于公司规模不大的时候，是否可以先简单的搭个监控系统先满足当前需求呢？您觉得如果要搭这个监控系统，哪个层面的监控体系是必不可少的呢","like_count":5,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":417474,"discussion_content":"日志监控一定要有，用ELK收集应用日志，方便排查错误和性能问题，其它监控可暂缓","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1525792954,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":134604,"user_name":"静水流深","can_delete":false,"product_type":"c3","uid":1339724,"ip_address":"","ucode":"644F05EFBD2E7B","user_header":"https://static001.geekbang.org/account/avatar/00/14/71/4c/2cefec07.jpg","comment_is_top":false,"comment_ctime":1568877010,"is_pvip":false,"replies":[{"id":51646,"content":"不能脱离场景，单纯讲某个监控产品的好坏。zabbix是老牌的监控产品，目前还是业界运维监控的一个主流产品，这个产品主要偏运维层的监控，但对大规模应用层和业务层的监控的能力比较欠缺，所以一般需要和ELK&#47;Prometheus&#47;CAT等监控产品配合互补，才能构成完整的监控体系。","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1568894818,"ip_address":"","comment_id":134604,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100003901,"comment_content":"老师您好，zabbix监控应该好一点吧？","like_count":3,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":467826,"discussion_content":"不能脱离场景，单纯讲某个监控产品的好坏。zabbix是老牌的监控产品，目前还是业界运维监控的一个主流产品，这个产品主要偏运维层的监控，但对大规模应用层和业务层的监控的能力比较欠缺，所以一般需要和ELK/Prometheus/CAT等监控产品配合互补，才能构成完整的监控体系。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1568894818,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":138269,"user_name":"stg609","can_delete":false,"product_type":"c3","uid":1073025,"ip_address":"","ucode":"FB70A75A891BB8","user_header":"https://static001.geekbang.org/account/avatar/00/10/5f/81/1c614f4a.jpg","comment_is_top":false,"comment_ctime":1570143564,"is_pvip":false,"replies":[{"id":74643,"content":"考虑维护成本，能共享尽量共享。但是共享也有问题，一个是量大性能会有问题，另外团队之间需求不同可能会打架，所以视情况各个团队也可以搞两套以上，但是尽量避免每个团队都搞一套就太浪费了。","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1585405545,"ip_address":"","comment_id":138269,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100003901,"comment_content":"老师，一般一个公司都有多个系统。可不可以多个不同的系统共享一套elk，promethus? 会不会有什么问题","like_count":2,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":469460,"discussion_content":"考虑维护成本，能共享尽量共享。但是共享也有问题，一个是量大性能会有问题，另外团队之间需求不同可能会打架，所以视情况各个团队也可以搞两套以上，但是尽量避免每个团队都搞一套就太浪费了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1585405545,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":112961,"user_name":"天草二十六","can_delete":false,"product_type":"c3","uid":1360712,"ip_address":"","ucode":"3165EE3007527B","user_header":"https://static001.geekbang.org/account/avatar/00/14/c3/48/3a739da6.jpg","comment_is_top":false,"comment_ctime":1562855053,"is_pvip":false,"replies":[{"id":41221,"content":"我在网上简单搜了一下，貌似pinpoint&#47;skywalking的架构都没有直接支持kafka这样的mq做中转。zipkin应该是支持的，但是zipkin的报表能力不行。如果这是你们企业的强需求，建议研究下pinpoint的通讯协议，然后做一下定制扩展，支持mq中转，我想这个工作量不会很大。","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1562936182,"ip_address":"","comment_id":112961,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100003901,"comment_content":"我使用pinpoint,在跨局域网环境下行不通。有像文中讲的那样把采集数据推送到mq的apm吗？","like_count":2,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":457979,"discussion_content":"我在网上简单搜了一下，貌似pinpoint/skywalking的架构都没有直接支持kafka这样的mq做中转。zipkin应该是支持的，但是zipkin的报表能力不行。如果这是你们企业的强需求，建议研究下pinpoint的通讯协议，然后做一下定制扩展，支持mq中转，我想这个工作量不会很大。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562936182,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":36251,"user_name":"wmg","can_delete":false,"product_type":"c3","uid":1070036,"ip_address":"","ucode":"BA4CED171B59E9","user_header":"https://static001.geekbang.org/account/avatar/00/10/53/d4/2ed767ea.jpg","comment_is_top":false,"comment_ctime":1540995904,"is_pvip":false,"replies":[{"id":13048,"content":"当然可以扛住，只是集群容量规模问题。HBase&#47;ELK这些大数据产品就是为应对海量数据而生，集群容量可大可大，大公司一天几T甚至几十T数据都很正常。","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1541339930,"ip_address":"","comment_id":36251,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100003901,"comment_content":"老师你好，我有个疑惑，对于终端用户体验的监控，采集到的数据应该是海量的，这些数据也是存入时间序列数据库吗，能扛得住吗？","like_count":2,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":427798,"discussion_content":"当然可以扛住，只是集群容量规模问题。HBase/ELK这些大数据产品就是为应对海量数据而生，集群容量可大可大，大公司一天几T甚至几十T数据都很正常。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1541339930,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":3395,"user_name":"self-discipline","can_delete":false,"product_type":"c3","uid":1024457,"ip_address":"","ucode":"A5AEDCA9ACC68A","user_header":"https://static001.geekbang.org/account/avatar/00/0f/a1/c9/501a1d02.jpg","comment_is_top":false,"comment_ctime":1519336510,"is_pvip":false,"replies":[{"id":1363,"content":"日志监控一般要有，然后是metrics和告警逐步完善，到一定规模上调用链","user_name":"作者回复","user_name_real":"晨晖","uid":1000463,"ctime":1522812093,"ip_address":"","comment_id":3395,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100003901,"comment_content":"我们可能可能不能一次搭建好所有的监控,比如创业公司,那么哪些优先搭建,哪些后面搭建呢","like_count":2,"discussions":[{"author":{"id":1000463,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/44/0f/abb7bfe3.jpg","nickname":"Geek_4zi01v","note":"","ucode":"6A485218B87E38","race_medal":0,"user_type":4,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":415888,"discussion_content":"日志监控一般要有，然后是metrics和告警逐步完善，到一定规模上调用链","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1522812093,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":4}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":201030,"user_name":"郭新鹏","can_delete":false,"product_type":"c3","uid":1154281,"ip_address":"","ucode":"F9D76691B335FC","user_header":"https://static001.geekbang.org/account/avatar/00/11/9c/e9/5ba8b1a3.jpg","comment_is_top":false,"comment_ctime":1585708116,"is_pvip":false,"replies":[{"id":75440,"content":"监控数据处理中延迟和吞吐(throughput)是一对矛盾，要快速低延迟就会牺牲吞吐量，要高吞吐就要适当做batch导致高延迟，没有完美解决办法，需要权衡，一般在可接受延迟下尽量提高吞吐量(单位时间内发送的数据量)，而不是追求单条监控数据的低延迟。","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1585839696,"ip_address":"","comment_id":201030,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100003901,"comment_content":"业务把数据达到agent，agent然后定时往kafka写数据吧。\n向美团的监控做的是分钟级别，饿了么做的是10s级别，峰值会被分摊到一段时间区间内，怎么解决的？","like_count":1,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":490217,"discussion_content":"监控数据处理中延迟和吞吐(throughput)是一对矛盾，要快速低延迟就会牺牲吞吐量，要高吞吐就要适当做batch导致高延迟，没有完美解决办法，需要权衡，一般在可接受延迟下尽量提高吞吐量(单位时间内发送的数据量)，而不是追求单条监控数据的低延迟。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1585839696,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":181633,"user_name":"钱","can_delete":false,"product_type":"c3","uid":1009652,"ip_address":"","ucode":"2C92A243A463D4","user_header":"https://static001.geekbang.org/account/avatar/00/0f/67/f4/9a1feb59.jpg","comment_is_top":false,"comment_ctime":1582600913,"is_pvip":false,"replies":[{"id":74950,"content":"建议日志写文件先落地，这样一般不会丢，然后用LogStash&#47;Fluentd之类的采集器集中送到kafka消息队列。这样日志要么在本地文件，要么在kafka队列，一般不会丢，而且本地文件和kafka都可以重复消费。","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1585570892,"ip_address":"","comment_id":181633,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100003901,"comment_content":"老师在实际工作中遇到过日志采集，丢日志数据的情况吗？由于日志生产速度快体量大，我们的日志采集系统存在丢业务日志的情况，对于线上业务排查问题有很大影响，不知有什么解决思路？\n我们曾经尝试和日志采集部门一起排查这个问题，发现写日志的速度大于采集的速度会导致一部分业务日志丢失，另外，就是日志采集的agent设定的CPU和内存有重启阈值，设置的小会导致频繁重启，过大又会担心影响业务应用的性能，最后就一点点调大然后监控，找到一个平衡点。\n针对类似问题，老师的解决思路是什么？","like_count":1,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":485059,"discussion_content":"建议日志写文件先落地，这样一般不会丢，然后用LogStash/Fluentd之类的采集器集中送到kafka消息队列。这样日志要么在本地文件，要么在kafka队列，一般不会丢，而且本地文件和kafka都可以重复消费。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1585570892,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":145587,"user_name":"Geek_433972","can_delete":false,"product_type":"c3","uid":1702813,"ip_address":"","ucode":"7EB9503666360E","user_header":"","comment_is_top":false,"comment_ctime":1572320986,"is_pvip":false,"replies":[{"id":74648,"content":"请参考sentinel的官方文档：https:&#47;&#47;github.com&#47;alibaba&#47;Sentinel&#47;wiki&#47;%E5%90%AF%E5%8A%A8%E9%85%8D%E7%BD%AE%E9%A1%B9\n\nSentinel 提供如下的配置方式：\n1. JVM -D 参数方式\n2. properties 文件方式（1.7.0 版本开始支持）","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1585406389,"ip_address":"","comment_id":145587,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100003901,"comment_content":"老师，您好，想请教一个事情，csp.sentinel.api.port这个参数可以通过配置文件配置吗？而不是通过jvm参数的形式","like_count":1,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":472482,"discussion_content":"请参考sentinel的官方文档：https://github.com/alibaba/Sentinel/wiki/%E5%90%AF%E5%8A%A8%E9%85%8D%E7%BD%AE%E9%A1%B9\n\nSentinel 提供如下的配置方式：\n1. JVM -D 参数方式\n2. properties 文件方式（1.7.0 版本开始支持）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1585406389,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":93622,"user_name":"杨杰","can_delete":false,"product_type":"c3","uid":1131823,"ip_address":"","ucode":"74817EA9499843","user_header":"https://static001.geekbang.org/account/avatar/00/11/45/2f/b0b0dd74.jpg","comment_is_top":false,"comment_ctime":1557536952,"is_pvip":false,"replies":[{"id":33642,"content":"已回复，见08节","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1557747709,"ip_address":"","comment_id":93622,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100003901,"comment_content":"老师，为什么网关层需要区分内部gw，h5网关，无线网关等? 网关不是应该重点关注跨横切面的功能而不应该涉及具体业务么？","like_count":1,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":449704,"discussion_content":"已回复，见08节","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1557747709,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":74310,"user_name":"fomy","can_delete":false,"product_type":"c3","uid":1125834,"ip_address":"","ucode":"CD87EA03B1F327","user_header":"https://static001.geekbang.org/account/avatar/00/11/2d/ca/02b0e397.jpg","comment_is_top":false,"comment_ctime":1552186962,"is_pvip":false,"replies":[{"id":27282,"content":"你指得是微服务监控agent吗？简单的监控agent可以直接往消息系统（例如kafka）丢消息即可，生产级的监控agent要考虑很多方面，如性能，cpu内存消耗，消息可靠性和及时性等，有很多参考，例如influxdb有golang写的agent，prometheus有golang写的很多exportor，cat有cat client，还有ELK有logstash，等等，这些可以参考。","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1552309587,"ip_address":"","comment_id":74310,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100003901,"comment_content":"杨老师，微服务的agent层具体怎么实现的？要是我来做的会直接使用一个抛消息的工具类。","like_count":1,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":442521,"discussion_content":"你指得是微服务监控agent吗？简单的监控agent可以直接往消息系统（例如kafka）丢消息即可，生产级的监控agent要考虑很多方面，如性能，cpu内存消耗，消息可靠性和及时性等，有很多参考，例如influxdb有golang写的agent，prometheus有golang写的很多exportor，cat有cat client，还有ELK有logstash，等等，这些可以参考。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1552309587,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":68049,"user_name":"Apple","can_delete":false,"product_type":"c3","uid":1039810,"ip_address":"","ucode":"904D70CF7A6148","user_header":"https://static001.geekbang.org/account/avatar/00/0f/dd/c2/0d58f08b.jpg","comment_is_top":false,"comment_ctime":1550396515,"is_pvip":false,"replies":[{"id":24394,"content":"1. consul是一种通用服务发现产品，不管go&#47;python都可以用，有相应的客户端。\n2. 如果使用的是grpc&#47;thrift这样的rpc框架，那么它们支持跨语言调用，go可以调用python服务，可以通过契约直接生成调用客户端。如果是restful的服务，则更加松散，一般http client就可以调用，每个语言一般都有http client，然后自己解析一下json之类的payload就可以了。","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1550576271,"ip_address":"","comment_id":68049,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100003901,"comment_content":"老师你好, 比如我现在 有两个团队 一个是Go 一个Python,\nGo与Python分别部署在两台服务器上面.\n请问, \n1.可以用同一个consul进行服务发现嘛?\n2. 如果可以的话, 我知道如果代码在同一个服务器上面我直接引用就可以调用RPC, 那么代码部署在不同的服务器上面 Go 怎么调用Python的RPC服务呢? \n谢谢!\n","like_count":1,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":439490,"discussion_content":"1. consul是一种通用服务发现产品，不管go/python都可以用，有相应的客户端。\n2. 如果使用的是grpc/thrift这样的rpc框架，那么它们支持跨语言调用，go可以调用python服务，可以通过契约直接生成调用客户端。如果是restful的服务，则更加松散，一般http client就可以调用，每个语言一般都有http client，然后自己解析一下json之类的payload就可以了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1550576271,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":36933,"user_name":"RocWay","can_delete":false,"product_type":"c3","uid":1088024,"ip_address":"","ucode":"377CD114BABBF7","user_header":"https://static001.geekbang.org/account/avatar/00/10/9a/18/3596069c.jpg","comment_is_top":false,"comment_ctime":1541394587,"is_pvip":false,"replies":[{"id":13187,"content":"你的问题太宽泛了，能否具一点？后台服务一般是一些原子基础服务，根据企业业务领域划分，集成一般是供前台聚合服务消费调用，有同步和异步消息等方式。","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1541423852,"ip_address":"","comment_id":36933,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100003901,"comment_content":"老师，能讲讲后台服务集成的一些实践吗？\n","like_count":1,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":428089,"discussion_content":"你的问题太宽泛了，能否具一点？后台服务一般是一些原子基础服务，根据企业业务领域划分，集成一般是供前台聚合服务消费调用，有同步和异步消息等方式。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1541423852,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]}]}