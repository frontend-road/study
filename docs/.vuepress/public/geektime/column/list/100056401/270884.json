{"id":270884,"title":"06 | 线性无关：如何理解向量在N维空间的几何意义？","content":"<p>你好，我是朱维刚。欢迎你继续跟我学习线性代数，今天我们要讲的内容是“线性无关”。</p><p>上一节课中，我讲的是线性空间的基本概念，是立足于宏观角度来讲的。那么今天，我们就要深入线性空间，从微观角度，再来看看线性空间中元素之间的关系，也就是<strong>线性组合</strong>。</p><p>线性组合有<strong>线性相关</strong>和<strong>线性无关</strong>，而线性无关是线性代数中最重要的概念之一，为什么这么说呢？因为线性相关的向量组中存在多余的向量，去掉它们不影响我们所考虑的问题。而线性无关向量集合是没有任何冗余的，也就是说，失去集合中任意一个向量，我们都会失去一些东西。接下来我们就开始把这个“直观上的理解”固化成实实在在的知识体系。</p><p>在正式开始讲解前，我还是一样，先通过一个例子，让你对线性组合有个大致的了解。</p><p>假设，有一家物流运输公司$Y$，$Y$主要靠车辆的货物运输来赚钱，而且$Y$拥有很多直营的运输车辆，设共有$n$辆车，$｛x_{1}, x_{2}, \\ldots, x_{n}｝$，那么，$Y$公司的收入可以表示成：$Y_{i}=a_{0}+a_{1} x_{1}+a_{2} x_{2}+\\cdots+a_{n} x_{n}$。</p><!-- [[[read_end]]] --><p>这是个线性方程，它的系数$a$表示了各辆车对收入的贡献率，$a_{0}$表示企业的日常总支出。这时企业内，任何一辆车对收入的贡献大小和这个企业其他的车都没有关系，所以各车之间就是<strong>线性无关</strong>的。如果这时，我们再聚焦到每辆车本身的利润上，比如我们都知道的这个公式：利润=收入-成本，那每辆车的利润、成本和收入之间就是<strong>线性相关</strong>的。</p><h2>线性组合</h2><p>在例子中，我们已经知道了线性组合中的线性相关、线性无关的意思。那么接下来，我们来看线性组合的确切定义：一个向量空间$V$和属于这个向量空间的有限数量的向量$｛x_{1}, x_{2}, \\ldots, x_{k}｝$，对于属于向量空间$V$的每个向量$v$，都有这样的表达形式：$v=\\lambda_{1} x_{1}+\\lambda_{2} x_{2}+\\cdots+\\lambda_{k} x_{k}=\\sum_{i=1}^{k} \\lambda_{i} x_{i}$。</p><p>那么，$v$就是向量$｛x_{1}, x_{2}, \\ldots, x_{k}｝$的线性组合。</p><p>我们继续看线性相关和线性无关的定义，一个向量空间$V$和属于这个向量空间的有限数量的向量$｛x_{1}, x_{2}, \\ldots, x_{k}｝$，有一个非平凡线性组合：$0=\\lambda_{1} x_{1}+\\lambda_{2} x_{2}+\\cdots+\\lambda_{k} x_{k}=\\sum_{i=1}^{k} \\lambda_{i} x_{i}$。如果其中至少有一个$λ$不等于0，这时，向量$｛x_{1}, x_{2}, \\ldots, x_{k}｝$是<strong>线性相关</strong>的。而如果有平凡解存在，例如：$λ_{1}= \\ldots=λ_{k}=0$，则向量$｛x_{1}, x_{2}, \\ldots, x_{k}｝$是<strong>线性无关</strong>的。</p><blockquote>\n<p>注意：这里有个数学用语“平凡解”，术语“平凡”经常用于结构非常简单的对象，一般来说，$Ax=0$中的零解，即$x=0$，就叫做平凡解。</p>\n</blockquote><p>现在，我们通过一个实际的例子来加深一下理解。</p><p>假如你想从上海去杭州，有两条路线可以供你选择：一条是从上海出发，行驶$84.9$公里后到苏州，再从苏州出发行驶$120.14$公里后到达杭州；另一条是从上海出发行驶$164.7$公里后直接到达杭州。</p><p><img src=\"https://static001.geekbang.org/resource/image/1d/3b/1dc1a7aa6c762519eff1c6d9cb00343b.png?wh=1390*1138\" alt=\"\"></p><p>我们可以把地理位置坐标系看成是一个二维的向量空间，上海到苏州可以表示成向量$v1$，苏州到杭州可以表示成向量$v2$，上海到杭州可以表示成向量$v3$，这样很明显可以看出，向量$v1$和$v2$是线性无关的，而上海到杭州$v3$却可以被另两个向量$v1$和$v2$表达，于是我们可以说$v1$，$v2$和$v3$之间是线性相关的。</p><h2>线性无关的判断方式</h2><p>线性无关的判断，对于实践中数据冗余的判断非常有用，那有没有一些方法来判断向量之间是线性无关的呢？我们来看一些有用的方法吧：</p><ol>\n<li>k向量要么线性无关，要么线性相关，没有第三个选择。</li>\n<li>已知向量集合 $｛x_{1}, x_{2}, \\ldots, x_{k}｝$ 中至少有一个是$0$向量，则它们是线性相关的。</li>\n<li>已知有向量集合 $｛x_{1}, x_{2}, \\ldots, x_{k}｝$ ，其中$x_{k}≠0$ ，如果一个向量等于另一向量和一个标量的乘，$x_{i}=λx_{j}$ ，那么，向量集合 $｛x_{1}, x_{2}, \\ldots, x_{k}｝$ 是线性相关的。</li>\n</ol><p>之前的方式方法都是偏理论的，而更加实践的方法，就是用高斯消元法来判断向量集合$｛x_{1}, x_{2}, \\ldots, x_{k}｝$是否是线性无关的。将所有向量组合成矩阵的列，做高斯消元，一直到形成行阶梯型矩阵为止。如果所有的列都是主元列，那矩阵所有列向量是线性无关的，反之，如果有至少一个非主元列，那矩阵所有列向量是线性相关的。</p><p>现在我们来做个小练习，就用高斯消元法来看一下这3个向量是否是线性无关的。</p><p>$$x_{1}=\\left[\\begin{array}{c}<br>\n1 \\\\\\<br>\n2 \\\\\\<br>\n-3 \\\\\\<br>\n4<br>\n\\end{array}\\right], x_{2}=\\left[\\begin{array}{l}<br>\n1 \\\\\\<br>\n1 \\\\\\<br>\n0 \\\\\\<br>\n2<br>\n\\end{array}\\right], x_{3}=\\left[\\begin{array}{c}<br>\n-1 \\\\\\<br>\n-2 \\\\\\<br>\n1 \\\\\\<br>\n1<br>\n\\end{array}\\right]$$</p><p>首先，我们把它表示成一般线性方程形式，或者一个非平凡线性组合。</p><p>$$\\lambda_{1} x_{1}+\\lambda_{2} x_{2}+\\lambda_{3} x_{3}=\\lambda_{1}\\left[\\begin{array}{c}<br>\n1 \\\\\\<br>\n2 \\\\\\<br>\n-3 \\\\\\<br>\n4<br>\n\\end{array}\\right]+\\lambda_{2}\\left[\\begin{array}{c}<br>\n1 \\\\\\<br>\n1 \\\\\\<br>\n0 \\\\\\<br>\n2<br>\n\\end{array}\\right]+\\lambda_{3}\\left[\\begin{array}{c}<br>\n-1 \\\\\\<br>\n-2 \\\\\\<br>\n1 \\\\\\<br>\n1<br>\n\\end{array}\\right]=0$$</p><p>接着，把向量组合成矩阵的列，运用行运算，一直到能够识别出主元列为止。</p><p>$$\\left[\\begin{array}{ccc}<br>\n1 &amp; 1 &amp; -1 \\\\\\<br>\n2 &amp; 1 &amp; -2 \\\\\\<br>\n-3 &amp; 0 &amp; 1 \\\\\\<br>\n4 &amp; 2 &amp; 1<br>\n\\end{array}\\right] \\cdots\\left[\\begin{array}{ccc}<br>\n1 &amp; 1 &amp; -1 \\\\\\<br>\n0 &amp; 1 &amp; 0 \\\\\\<br>\n0 &amp; 0 &amp; 1 \\\\\\<br>\n0 &amp; 0 &amp; 0<br>\n\\end{array}\\right]$$</p><p>这里，矩阵每一列都是主元列，所以，它没有非平凡解，只有在$λ_{1}=0$，$λ_{2}=0$，$λ_{3}=0$的情况下，方程才有解。因此，我们能说向量$｛x_{1}, x_{2}, x_{k}｝$ 是线性无关的。</p><h2>更普遍和复杂的线性无关判断</h2><p>理论是这样的，接下来我们再扩展一下学到的知识，把它用到更普遍和复杂的情况中，也就是有$k$个线性无关的向量$｛b_{1}, b_{2}, \\ldots, b_{k}｝$，以及$m$个线性组合的情况：</p><p>$$<br>\n\\begin{aligned}<br>\nx_{1} &amp;=\\sum_{i=1}^{k} \\lambda_{i 1} b_{i} \\\\\\<br>\nx_{2} &amp;=\\sum_{i=1}^{k} \\lambda_{i 2} b_{i} \\\\\\<br>\n\\cdot &amp; \\\\\\<br>\n\\cdot &amp; \\\\\\<br>\n\\cdot &amp; \\\\\\<br>\nx_{m} &amp;=\\sum_{i=1}^{k} \\lambda_{i m} b_{i}<br>\n\\end{aligned}<br>\n$$</p><p>如果把这$k$个线性无关的向量组合成矩阵$B$，$B=\\left[\\begin{array}{lll}b_{1} &amp; \\ldots &amp; b_{k}\\end{array}\\right]$ ，我们就能用更紧凑的形式来表达：</p><p>$$x_{j}=B \\lambda_{i}, \\lambda_{j}=\\left[\\begin{array}{c}<br>\n\\lambda_{1 j} \\\\\\<br>\n\\cdot \\\\\\<br>\n\\cdot \\\\\\<br>\n\\cdot \\\\\\<br>\n\\lambda_{kj}<br>\n\\end{array}\\right],  j=1, \\ldots, m$$</p><p>这时，如何判断$｛x_{1}, x_{2}, \\ldots, x_{m}｝$ 是否是线性无关的呢？首先，我们用一个非平凡线性组合来测试，就和之前的方法一样，把它表示成这样的形式：$\\sum_{i=1}^{m} \\varphi_{j} x_{j}=\\sum_{i=1}^{m} \\varphi_{j} B \\lambda_{j}=B \\sum_{i=1}^{m} \\varphi_{j} \\lambda_{j}=0$。</p><p>接着，从这样的等式可以很容易看出，只有向量$｛λ_{1}, λ_{2}, \\ldots, λ_{m}｝$线性无关，$｛x_{1}, x_{2}, \\ldots, x_{m}｝$ 才是线性无关的。</p><p>还是老样子，我们通过一个例子来看下。假设，有一组线性无关的向量 $｛b_{1}, b_{2},  b_{3}, b_{4}｝$，和4个线性组合。</p><p>$$\\left\\{\\begin{aligned}<br>\nx_{1} &amp;=b_{1}-2 b_{2}+b_{3}-b_{4} \\\\\\<br>\nx_{2} &amp;=-4 b_{1}-2 b_{2}+4 b_{4} \\\\\\<br>\nx_{3} &amp;=2 b_{1}+3 b_{2}-b_{3}-3 b_{4} \\\\\\<br>\nx_{4} &amp;=17 b_{1}-10 b_{2}+11 b_{3}+b_{4}<br>\n\\end{aligned}\\right.$$</p><p>接下来我们该怎么判断$｛x_{1}, x_{2},  x_{3}, x_{4}｝$是否是线性无关的呢？按刚才说的方法，我们需要首先找到$λ$向量，通过$λ$向量组合成这样的矩阵：</p><p>$$\\left[\\begin{array}{cccc}<br>\n1 &amp; -4 &amp; 2 &amp; 17 \\\\\\<br>\n-2 &amp; -2 &amp; 3 &amp; -10 \\\\\\<br>\n1 &amp; 0 &amp; -1 &amp; 11 \\\\\\<br>\n-1 &amp; 4 &amp; -3 &amp; 1<br>\n\\end{array}\\right]$$</p><p>接着，使用高斯消元法，一直到形成行阶梯型矩阵为止。高斯消元法的用法已经在<a href=\"https://time.geekbang.org/column/article/269448\">第四节课</a>中详细说了，如果你有些记不清，可以回去复习一下。这里我们直接得到了行阶梯型矩阵：</p><p>$$<br>\n\\left[\\begin{array}{cccc}<br>\n1 &amp; 0 &amp; 0 &amp; -7 \\\\\\<br>\n0 &amp; 1 &amp; 0 &amp; -15 \\\\\\<br>\n0 &amp; 0 &amp; 1 &amp; -18 \\\\\\<br>\n0 &amp; 0 &amp; 0 &amp; 0<br>\n\\end{array}\\right]<br>\n$$</p><p>矩阵的最后一列不是主元列，而且你可以很直观地发现 $x_{4}=-7 x_{1}-15 x_{2}-18 x_{3}$，所以，我们可以判断 $｛x_{1}, x_{2},  x_{3}, x_{4}｝$是线性相关的，$x_{4}$ 能由 $｛x_{1}, x_{2},  x_{3}｝$ 的线性组合来表达。</p><p>友情提醒：已知在一个向量空间$V$中，有$k$个向量 $｛x_{1}, x_{2}, \\ldots, x_{k}｝$和$m$个线性组合，如果$m&gt;k$，那么我们可以说，这$k$个向量 $｛x_{1}, x_{2}, \\ldots, x_{k}｝$ 的$m$个线性组合是线性相关的。所以，在这样的情况下，就为你省去了计算的时间。</p><h2>线性组合在机器学习中的应用</h2><p>在了解了线性组合的概念，以及线性组合中的线性相关，特别是线性无关的判断后，我们来看一个机器学习中的实践例子，来了解一下线性组合是怎么体现在机器学习中的。</p><p>机器学习中，最经典，也是最简单的线性组合应用莫过于<strong>线性回归</strong>了。线性回归是比较常见，也是简单实用的机器学习算法，它是利用数理统计中的回归分析，来确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法。</p><p>线性回归假设目标值与特征之间线性相关，也就是说满足一个多元一次方程。它可以通过构建“损失（loss）”函数，来求解损失函数最小时的参数$w$和$b$，也就是说，整个机器学习的过程就是通过样本数据，得到最后的参数$w$和$b$。</p><p>我们通过一个例子来看看线性回归。</p><p><img src=\"https://static001.geekbang.org/resource/image/c2/00/c2a1d35f4175d0ff599eeedd5df2e200.png?wh=1542*1044\" alt=\"\"></p><p>这是一个典型的一元线性回归模型。图中的空心圆点是真实数据点，而红线是一元线性回归模型，是用来做数据预测的，也就是$y=\\omega^{T} x+b$。我们可以根据给定的$x$值通过方程式来计算$y$值。从分布在红色线周围的真实数据点来看，其实我们可以直观的得出结论：这个一元线性回归模型可以被用来很好的做预测。</p><p>线性回归在现实生活中的一个典型的应用场景是健身卡路里的燃烧预测，比如输入数据是年龄、性别、身高、体重、健身心跳、健身持久时间，而输出则是燃烧掉的卡路里。</p><p>怎么样？机器学习是不是很简单？</p><p>其实，机器学习的本质就是用数学来解决现实的问题。而很多看起来简单的数学公式可以解决很多问题，比如这里说的线性组合应用——线性回归。</p><p>我最近发现，有不少同学遇到问题，都想着怎么用复杂的机器学习算法去解决问题，特别是高大上的深度学习、神经网络之类的。但其实对于机器学习来说，算法不是越复杂越好，而是越适用越好。你可以先从简单的算法模型入手，先验证效果后，再做进一步的判断，是否需要用更复杂的算法模型。</p><h2>本节小结</h2><p>好了，到这里线性无关这一讲就结束了，最后我再总结一下前面讲解的内容。</p><p>向量空间是实践的基本单位，之前都是从宏观角度出发的，而今天的知识的重点在于，我从微观角度，深入讲解了线性空间中元素之间的关系，也就是线性组合，线性组合有线性相关和线性无关，而线性无关是线性代数中最重要的概念之一。所以，你一定要掌握线性组合的概念，以及它包含的线性相关，特别是线性无关的判断方式，希望你能多练习线性组合中的线性无关的判断，为实践打好坚实的基础。</p><h2>线性代数练习场</h2><p>练习时刻到了，今天的练习题简单一些，和之前举过的例子相似，假设我们有一组线性无关的向量$｛b_{1}, b_{2}, b_{3}, b_{4}｝$，和4个线性组合。</p><p>$$\\left\\{\\begin{aligned}<br>\nx_{1} &amp;=b_{1}+b_{2}-2 b_{3}-b_{4} \\\\\\<br>\nx_{2} &amp;=b_{1}+5 b_{2}-3 b_{3}-2 b_{4} \\\\\\<br>\nx_{3} &amp;=3 b_{1}-b_{2}+b_{3}+4 b_{4} \\\\\\<br>\nx_{4} &amp;=-2 b_{1}+2 b_{2}+b_{3}-b_{4}<br>\n\\end{aligned}\\right.$$</p><p>请你判断$｛x_{1}, x_{2}, x_{3}, x_{4}｝$是线性无关的吗？</p><blockquote>\n<p>友情提示：通过高斯消元法，我们能得到行阶梯型矩阵，通过行阶梯型矩阵，就可以判断$｛x_{1}, x_{2}, x_{3}, x_{4}｝$是否是线性无关的。</p>\n</blockquote><p>欢迎你在留言区或<a href=\"https://horde.geekbang.org/channel/list/39\">部落</a>里晒出你的运算过程和结果。如果有收获，也欢迎你把这篇文章分享给你的朋友。</p>","neighbors":{"left":{"article_title":"05 | 线性空间：如何通过向量的结构化空间在机器学习中做降维处理？","id":270329},"right":{"article_title":"07 | 基和秩：为什么说它表达了向量空间中“有用”的向量个数？","id":271943}},"comments":[{"had_liked":false,"id":292756,"user_name":"田埂","can_delete":false,"product_type":"c1","uid":2617093,"ip_address":"","ucode":"0B0C7F37A63826","user_header":"https://static001.geekbang.org/account/avatar/00/27/ef/05/94addfd0.jpg","comment_is_top":false,"comment_ctime":1620962888,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1620962888","product_id":100056401,"comment_content":"y=w^x+b 定义是一个超平面， 机器学习的目标是使得这个超平面离各个数据点的平均欧氏距离&#47;距离平方根最短。问题是这个和线性相关有关系吗？ 我暂时无法理解，线性相关一般用于相关性分析中。例如客流量与收入，相关度越高，客流量这个特征就重要。<br>【老师能解析下回归与相关的关系吗？】","like_count":0},{"had_liked":false,"id":265186,"user_name":"果然爸爸","can_delete":false,"product_type":"c1","uid":1467300,"ip_address":"","ucode":"0E5F031A0E6A69","user_header":"https://static001.geekbang.org/account/avatar/00/16/63/a4/e663c4d4.jpg","comment_is_top":false,"comment_ctime":1606809323,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1606809323","product_id":100056401,"comment_content":"[1 1 -2 -1<br>0 4 -1 -1<br>0 0 6 6 <br>0 0 -2 -2] 初等变换两次 看到这个结果，最后两行，看得出是线性相关的","like_count":0},{"had_liked":false,"id":251040,"user_name":"A君","can_delete":false,"product_type":"c1","uid":1940105,"ip_address":"","ucode":"FE96F089C2312C","user_header":"https://static001.geekbang.org/account/avatar/00/1d/9a/89/babe8b52.jpg","comment_is_top":false,"comment_ctime":1601342234,"is_pvip":true,"discussion_count":1,"race_medal":0,"score":"1601342234","product_id":100056401,"comment_content":"不明白线性相关&#47;无关跟线性回归有什么关系，能再解释下么。另外，线性无关和线性相关数学计算上我明白，但它们又表示什么呢？线性相关表示还有多余变量要丢掉，线性无关表示两个矩阵或向量已经正交了？","like_count":0,"discussions":[{"author":{"id":1420624,"avatar":"https://static001.geekbang.org/account/avatar/00/15/ad/50/3cb818e8.jpg","nickname":"灰太狼","note":"","ucode":"4FB0501E6AFADB","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":314445,"discussion_content":"线性回归假设目标值与特征之间线性相关，也就是说满足一个多元一次方程。它可以通过构建“损失（loss）”函数，来求解损失函数最小时的参数 w 和 b，也就是说，整个机器学习的过程就是通过样本数据，得到最后的参数 w 和 b。\n\n如果特征和目标值线性无关，我觉得模型要么欠拟合，要么无法泛化即过拟合，如有错误，请指正","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1603157599,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":245232,"user_name":"流殇忘情","can_delete":false,"product_type":"c1","uid":1119767,"ip_address":"","ucode":"7B6CF2F2B11C75","user_header":"https://static001.geekbang.org/account/avatar/00/11/16/17/1d6ec0df.jpg","comment_is_top":false,"comment_ctime":1598870260,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1598870260","product_id":100056401,"comment_content":"首先通过矩阵的初等行变换把第一列的2，3，4行化成0，然后直接按照第一列展开直接计算行列式的值为0，由线性相关和行列式等于0等价得出结果是线性相关。","like_count":0},{"had_liked":false,"id":244836,"user_name":"思致精研_益达","can_delete":false,"product_type":"c1","uid":1586709,"ip_address":"","ucode":"9886B8F58E7635","user_header":"https://static001.geekbang.org/account/avatar/00/18/36/15/937dee0a.jpg","comment_is_top":false,"comment_ctime":1598693995,"is_pvip":false,"replies":[{"id":"90106","content":"是的，只要能够识别出主元列就行。","user_name":"作者回复","user_name_real":"朱维刚","uid":"1512030","ctime":1598752210,"ip_address":"","comment_id":244836,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1598693995","product_id":100056401,"comment_content":"老师，我有个疑问。<br>老师我留言评论上面提到的<br>[1 0 0 -3<br> 0 1 0 5&#47;8<br> 0 0 1 -1&#47;5<br> 0 0 0 0] <br>上面的矩阵我是从下面这个矩阵进一步计算的，计算结束的标准是不是：&quot;每一行的第一个数出现是1&quot;，就可以不用进行下一步计算了呢(所以说，我计算到下面这个公式就可以得出结果，就不用继续往下计算了对吗【大学学的线代有些有点忘了】)。<br>[1 0 0 -3<br> 0 1 3 1<br> 0 0 1 -1&#47;5<br> 0 0 0 0]","like_count":0,"discussions":[{"author":{"id":1512030,"avatar":"https://static001.geekbang.org/account/avatar/00/17/12/5e/f85fcfb2.jpg","nickname":"朱维刚","note":"","ucode":"3032B6AAB578F3","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":504714,"discussion_content":"是的，只要能够识别出主元列就行。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1598752210,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":243885,"user_name":"思致精研_益达","can_delete":false,"product_type":"c1","uid":1586709,"ip_address":"","ucode":"9886B8F58E7635","user_header":"https://static001.geekbang.org/account/avatar/00/18/36/15/937dee0a.jpg","comment_is_top":false,"comment_ctime":1598319630,"is_pvip":false,"replies":[{"id":"89861","content":"你好，思致精研_益达<br>最后一列有些出入，我的是-5&#47;3，0，-1&#47;3，0，且最后一列不是主元列，所以它们线性相关。","user_name":"作者回复","user_name_real":"朱维刚","uid":"1512030","ctime":1598399902,"ip_address":"","comment_id":243885,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1598319630","product_id":100056401,"comment_content":"[1 0 0 -3<br> 0 1 0 5&#47;8<br> 0 0 1 -1&#47;5<br> 0 0 0 0]   在练习场经过计算的结果，老师看下我算出来的最终结果对吗","like_count":0,"discussions":[{"author":{"id":1512030,"avatar":"https://static001.geekbang.org/account/avatar/00/17/12/5e/f85fcfb2.jpg","nickname":"朱维刚","note":"","ucode":"3032B6AAB578F3","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":504424,"discussion_content":"你好，思致精研_益达\n最后一列有些出入，我的是-5/3，0，-1/3，0，且最后一列不是主元列，所以它们线性相关。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1598399902,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1586709,"avatar":"https://static001.geekbang.org/account/avatar/00/18/36/15/937dee0a.jpg","nickname":"思致精研_益达","note":"","ucode":"9886B8F58E7635","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":300938,"discussion_content":"老师，我有个疑问。\n老师我留言评论上面提到的\n[1 0 0 -3\n 0 1 0 5/8\n 0 0 1 -1/5\n 0 0 0 0] \n上面的矩阵我是从下面这个矩阵进一步计算的，计算结束的标准是不是：&#34;每一行的第一个数出现是1&#34;，就可以不用进行下一步计算了呢(所以说，我计算到下面这个公式就可以得出结果，就不用继续往下计算了对吗【大学学的线代有些有点忘了】)。\n[1 0 0 -3\n 0 1 3 1\n 0 0 1 -1/5\n 0 0 0 0]","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1598328314,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":242073,"user_name":"王震","can_delete":false,"product_type":"c1","uid":1194568,"ip_address":"","ucode":"691C40D45510B3","user_header":"https://static001.geekbang.org/account/avatar/00/12/3a/48/fbacc564.jpg","comment_is_top":false,"comment_ctime":1597584611,"is_pvip":false,"replies":[{"id":"89356","content":"你好，王震，是的，因为这只有在lambda都是零的情况下。","user_name":"作者回复","user_name_real":"朱维刚","uid":"1512030","ctime":1597622538,"ip_address":"","comment_id":242073,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1597584611","product_id":100056401,"comment_content":"而如果“有”平凡解存在，例如：λ_{1}= \\ldots=λ_{k}=0，则向量 ｛x_{1}, x_{2}, \\ldots, x_{k}｝ 是线性无关的。<br><br>这里应该是说 “仅有”平凡解存在，则是线性无关的吧？","like_count":0,"discussions":[{"author":{"id":1512030,"avatar":"https://static001.geekbang.org/account/avatar/00/17/12/5e/f85fcfb2.jpg","nickname":"朱维刚","note":"","ucode":"3032B6AAB578F3","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":503914,"discussion_content":"你好，王震，是的，因为这只有在lambda都是零的情况下。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1597622538,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":240689,"user_name":"三件事","can_delete":false,"product_type":"c1","uid":1055819,"ip_address":"","ucode":"BCC867C8961A24","user_header":"https://static001.geekbang.org/account/avatar/00/10/1c/4b/2e5df06f.jpg","comment_is_top":false,"comment_ctime":1597034714,"is_pvip":false,"replies":[{"id":"88913","content":"答案正确 :-)<br>继续加油！","user_name":"作者回复","user_name_real":"朱维刚","uid":"1512030","ctime":1597053572,"ip_address":"","comment_id":240689,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1597034714","product_id":100056401,"comment_content":"练习场 ｛x1, x2, x3, x4} 线性相关 最后一列不是主元列","like_count":0,"discussions":[{"author":{"id":1512030,"avatar":"https://static001.geekbang.org/account/avatar/00/17/12/5e/f85fcfb2.jpg","nickname":"朱维刚","note":"","ucode":"3032B6AAB578F3","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":503528,"discussion_content":"答案正确 :-)\n继续加油！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1597053572,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":240651,"user_name":"那时刻","can_delete":false,"product_type":"c1","uid":1150927,"ip_address":"","ucode":"B0D150856C3A4A","user_header":"https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg","comment_is_top":false,"comment_ctime":1597026896,"is_pvip":false,"replies":[{"id":"88847","content":"可以的，从损失函数的角度来解释，一切都是为了找到 y=wx+b的w和b服务。特征和目标之间的线性关系，体现到向量空间中，就是构建最合适的线性组合，找到使损失函数最小的参数w和b。","user_name":"作者回复","user_name_real":"朱维刚","uid":"1512030","ctime":1597040901,"ip_address":"","comment_id":240651,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1597026896","product_id":100056401,"comment_content":"请问老师，线性回归假设目标值与特征之间线性相关，这句话可以从公式推导的方式证明么？<br><br>我粗略想了下，貌似可以用老师提到的这个来着解释：已知在一个向量空间 V 中，有 k 个向量 ｛x_{1}, x_{2}, \\ldots, x_{k}｝ 和 m 个线性组合，如果 m&gt;k，那么我们可以说，这 k 个向量 ｛x_{1}, x_{2}, \\ldots, x_{k}｝ 的 m 个线性组合是线性相关的。<br><br>我直接copy的原文，格式有偏差了...","like_count":0,"discussions":[{"author":{"id":1512030,"avatar":"https://static001.geekbang.org/account/avatar/00/17/12/5e/f85fcfb2.jpg","nickname":"朱维刚","note":"","ucode":"3032B6AAB578F3","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":503512,"discussion_content":"可以的，从损失函数的角度来解释，一切都是为了找到 y=wx+b的w和b服务。特征和目标之间的线性关系，体现到向量空间中，就是构建最合适的线性组合，找到使损失函数最小的参数w和b。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1597040901,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]}]}