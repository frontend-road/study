{"id":709523,"title":"14｜工具和工具箱：LangChain中的Tool和Toolkits一览","content":"<p>你好，我是黄佳，欢迎来到LangChain实战课！</p><p>这节课我们来一起看一看LangChain中各种强大的工具（Tool），以及如何使用它们。</p><p>在之前的几节课中，我们深入讲解了LangChain中的代理。未来的AI Agent，应该就是以LLM为核心控制器的代理系统。而<strong>工具，则是代理身上延展出的三头六臂，是代理的武器，代理通过工具来与世界进行交互，控制并改造世界</strong>。</p><h2>工具是代理的武器</h2><p>LangChain之所以强大，第一是大模型的推理能力强大，第二则是工具的执行能力强大！孙猴子法力再强，没有金箍棒，也降伏不了妖怪。大模型再能思考，没有工具也不行。</p><p>工具是代理可以用来与世界交互的功能。这些工具可以是通用实用程序（例如搜索），也可以是其他链，甚至其他的代理。</p><p>那么到底什么是工具？在LangChain中，工具是如何发挥作用的？</p><p>LangChain通过提供一个统一的框架来集成功能的具体实现。在这个框架中，每个功能都被封装成一个工具。每个工具都有自己的输入和输出，以及处理这些输入和生成输出的方法。</p><p>当代理接收到一个任务时，它会根据任务的类型和需求，通过大模型的推理，来选择合适的工具处理这个任务。这个选择过程可以基于各种策略，例如基于工具的性能，或者基于工具处理特定类型任务的能力。</p><!-- [[[read_end]]] --><p>一旦选择了合适的工具，LangChain就会将任务的输入传递给这个工具，然后工具会处理这些输入并生成输出。这个输出又经过大模型的推理，可以被用作其他工具的输入，或者作为最终结果，被返回给用户。</p><p><img src=\"https://static001.geekbang.org/resource/image/eb/b6/ebcyyaccd79133c03f417c45c225d1b6.png?wh=1456x636\" alt=\"\" title=\"LLM 和工具之间相互依存\"></p><p>通过这种方式，LangChain 大大延展了大模型的功能。大模型的推理，加上工具的调用，都集成在一个系统中，而这个系统可以处理多种类型的任务。这提高了系统的灵活性和可扩展性，也大大简化了开发者的工作。</p><h2>如何加载工具</h2><p>在程序中，可以使用以下代码片段加载工具。</p><pre><code class=\"language-plain\">from langchain.agents import load_tools\ntool_names = [...]\ntools = load_tools(tool_names)\n</code></pre><p>某些工具（例如链、代理）可能需要 LLM 来初始化它们。</p><pre><code class=\"language-plain\">from langchain.agents import load_tools\ntool_names = [...]\nllm = ...\ntools = load_tools(tool_names, llm=llm)\n</code></pre><h2>LangChain 支持的工具一览</h2><p>下面，我给你列出目前LangChain中所支持的工具。</p><p><img src=\"https://static001.geekbang.org/resource/image/e2/5b/e2f8a0318b4f1da7f0e756e87761d95b.jpg?wh=1459x2148\" alt=\"\"></p><p>当然这个列表随着时间的推移会越来越长，也就意味着LangChain的功能会越来越强大。</p><h2>使用 arXiv 工具开发科研助理</h2><p>其中有一些工具，比如SerpAPI，你已经用过了，这里我们再来用一下arXiv工具。arXiv本身就是一个论文研究的利器，里面的论文数量比AI顶会还早、还多、还全。那么把它以工具的形式集成到LangChain中，能让你在研究学术最新进展时如虎添翼。</p><blockquote>\n<p><span class=\"reference\">arXiv是一个提供免费访问的预印本库，供研究者在正式出版前上传和分享其研究工作。它成立于1991年，最初是作为物理学预印本数据库开始的，但后来扩展到了数学、计算机科学、生物学、经济学等多个领域。</span><br>\n&nbsp;<br>\n<span class=\"reference\">预印本是研究者完成的、但尚未经过同行评议或正式出版的论文。Arxiv允许研究者上传这些预印本，使其他研究者可以在正式出版之前查看、评论和使用这些工作。这样，研究的发现可以更快地传播和分享，促进学术交流。</span></p>\n</blockquote><pre><code class=\"language-plain\"># 设置OpenAI API的密钥\nimport os \nos.environ[\"OPENAI_API_KEY\"] = 'Your Key' \n\n# 导入库\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.agents import load_tools, initialize_agent, AgentType\n\n# 初始化模型和工具\nllm = ChatOpenAI(temperature=0.0)\ntools = load_tools(\n&nbsp; &nbsp; [\"arxiv\"],\n)\n\n# 初始化链\nagent_chain = initialize_agent(\n&nbsp; &nbsp; tools,\n&nbsp; &nbsp; llm,\n&nbsp; &nbsp; agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n&nbsp; &nbsp; verbose=True,\n)\n\n# 运行链\nagent_chain.run(\"介绍一下2005.14165这篇论文的创新点?\")\n</code></pre><p>首先，我们还是来研究一下ZERO_SHOT_REACT_DESCRIPTION这个Agent是怎么通过提示来引导模型调用工具的。</p><blockquote>\n<p>“prompts”: [<br>\n&nbsp; &nbsp; \"Answer the following questions as best you can. You have access to the following tools:\\n\\n</p>\n</blockquote><p><span class=\"orange\">首先告诉模型，要尽力回答问题，但是可以访问下面的工具。</span></p><blockquote>\n<p><strong>arxiv:</strong> A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.\\n\\n</p>\n</blockquote><p><span class=\"orange\">arxiv工具：一个围绕Arxiv.org的封装工具。当你需要回答关于物理学、数学、计算机科学、定量生物学、定量金融、统计学、电气工程和经济学的问题时，来自arxiv.org上的科学文章非常有用。同时还告诉模型：输入这个工具的内容应该是搜索查询。</span></p><blockquote>\n<p>Use the following format:\\n\\n</p>\n</blockquote><p><span class=\"orange\">指导模型输出下面的内容。</span></p><blockquote>\n<p>Question: the input question you must answer\\n <span class=\"reference\">（问题：需要回答的问题）</span><br>\nThought: you should always think about what to do\\n <span class=\"reference\">（思考：应该总是思考下一步做什么）</span><br>\nAction: the action to take, should be one of [arxiv]\\n <span class=\"reference\">（行动：从具体工具列表中选择行动——这里只有arxiv一个工具）</span><br>\nAction Input: the input to the action\\n <span class=\"reference\">（行动的输入：输入工具的内容）</span><br>\nObservation: the result of the action\\n…  <span class=\"reference\">（观察：工具返回的结果）</span><br>\n(this Thought/Action/Action Input/Observation can repeat N times)\\n <span class=\"reference\">（上面 Thought/Action/Action Input/Observation 的过程将重复N次）</span><br>\nThought: I now know the final answer\\n <span class=\"reference\">（现在我知道最终答案了）</span><br>\nFinal Answer: the final answer to the original input question\\n\\n <span class=\"reference\">（原始问题的最终答案）</span></p>\n</blockquote><blockquote>\n<p><strong>Begin!</strong>\\n\\n</p>\n</blockquote><p><span class=\"orange\">现在开始！</span></p><blockquote>\n<p><strong>Question</strong>: 'Chain-of-Thought Prompting Elicits Reasoning in Large Language Models’这篇论文的创新点\\n</p>\n</blockquote><p><span class=\"orange\">真正的问题在此。</span></p><blockquote>\n<p>Thought:\"</p>\n</blockquote><p><span class=\"orange\">开始思考吧！</span></p><p>然后，我们来看看Chain的运行过程。</p><p><img src=\"https://static001.geekbang.org/resource/image/6e/57/6e1195d608d47fbe5b67131c1fe32357.jpg?wh=1041x1519\" alt=\"\"></p><p>其中，代理的思考过程中的第一个返回结果如下：</p><blockquote>\n<p>“text”: \" I need to read the paper to understand the innovation\\n <span class=\"reference\">（思考：我需要阅读文章才能理解创新点）</span><br>\nAction: arxiv\\n <span class=\"reference\">（行动：arxiv工具）</span><br>\nAction Input: ‘Chain-of-Thought Prompting Elicits Reasoning in Large Language Models’\", <span class=\"reference\">（行动的输入：论文的标题）</span></p>\n</blockquote><p>因为在之前的提示中，LangChain告诉大模型，对于Arxiv工具的输入总是以搜索的形式出现，因此尽管我指明了论文的ID，Arxiv还是根据这篇论文的关键词搜索到了3篇相关论文的信息。</p><p>模型对这些信息进行了总结，认为信息已经完善，并给出了最终答案。</p><blockquote>\n<p>Thought: I now know the final answer</p>\n</blockquote><p><span class=\"orange\">想法：我现在知道了最终答案。</span></p><blockquote>\n<p>Final Answer: The innovation of the paper ‘Chain-of-Thought Prompting Elicits Reasoning in Large Language Models’ is the introduction of a simple method called chain of thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting, which significantly improves the ability of large language models to perform complex reasoning.\"</p>\n</blockquote><p><span class=\"orange\">最终答案：这篇名为《链式思考提示促使大型语言模型进行推理》的论文的创新之处在于，引入了一种简单的方法，即链式思考提示，在提示中提供了一些链式思考的示例，这大大提高了大型语言模型执行复杂推理的能力。</span></p><h2>LangChain 中的工具箱一览</h2><p>下面，我给你列出了目前LangChain中所支持的工具箱。每个工具箱中都有一系列工具。</p><p><img src=\"https://static001.geekbang.org/resource/image/c8/27/c87be0638409b278c2657a66f45aa927.jpg?wh=1223x1314\" alt=\"\"></p><h2>使用 Gmail 工具箱开发个人助理</h2><p>刚才，你使用了arXiv工具帮助你做了一些科研工作。你当然还希望你的AI Agent能够成为你的全能自动助理，你开发出的智能应用应该能帮你检查邮件、写草稿，甚至发邮件、写文档，对吧？</p><p>上面这一切的一切，LangChain当然能够安排上！</p><ul>\n<li>通过Gmail工具箱，你可以通过LangChain应用检查邮件、删除垃圾邮件，甚至让它帮你撰写邮件草稿。</li>\n<li>通过Office365工具箱，你可以让LangChain应用帮你读写文档、总结文档，甚至做PPT。</li>\n<li>通过GitHub工具箱，你可以指示LangChain应用来检查最新的代码，Commit Changes、Merge Branches，甚至尝试让大模型自动回答 Issues 中的问题——反正大模型解决代码问题的能力本来就更强。</li>\n</ul><p>这些都不再是梦想。</p><p>下面咱们从一个最简单的应用开始。</p><p><strong>目标：我要让AI应用来访问我的Gmail邮件，让他每天早晨检查一次我的邮箱，看看“易速鲜花”的客服有没有给我发信息。</strong>（因为我可能正在焦急地等待他们的退款😁）</p><p>现在开始。</p><h3>第一步：在 Google Cloud 中设置你的应用程序接口</h3><p>这个步骤你要跟着Gmail API的官方配置<a href=\"https://developers.google.com/gmail/api/quickstart/python?hl=zh-cn#authorize_credentials_for_a_desktop_application\">链接</a>完成，这个和LangChain无关。蛮复杂的，你需要有点耐心。跟着流程一步步配置就好了。</p><p>下面是我在这个设置过程中截取的一部分图片，只是供你参考。详细配置你要follow Google的官方说明。</p><p><img src=\"https://static001.geekbang.org/resource/image/8a/21/8a3c72f48c231bd2d886b4d99e9f3321.jpg?wh=1170x854\" alt=\"\" title=\"创建你的 Project（每人有 12 个免费的 Project）\"></p><p><img src=\"https://static001.geekbang.org/resource/image/38/ab/3822d1effb90c855c133acdecea2eaab.jpg?wh=1930x711\" alt=\"\" title=\"Gmail API\"></p><p><img src=\"https://static001.geekbang.org/resource/image/96/f3/96a788e8a1f7d4f32e3d23eb94cce8f3.jpg?wh=1688x1172\" alt=\"\" title=\"Enable 它\"></p><p><img src=\"https://static001.geekbang.org/resource/image/0f/29/0f746cfa48ba60c0fe98e657cb3yyb29.jpg?wh=1925x810\" alt=\"\" title=\"Create Credentials\"></p><p>下面这个OAuth同意屏幕里面的配置非常重要，你的智能代理能做什么，不能做什么，就看你怎么给权限了！</p><p><img src=\"https://static001.geekbang.org/resource/image/19/2f/195ec3590bb075ecff42911f13d2f22f.jpg?wh=823x1214\" alt=\"\"></p><p>所有设置都完成之后，在OAuth客户段已创建这个页面，你拥有了开发密钥。</p><p><img src=\"https://static001.geekbang.org/resource/image/f6/b0/f6829a70c320161a1002ee3380c5b1b0.jpg?wh=506x509\" alt=\"\" title=\"可以下载的开发密钥\"></p><h3>第二步：根据密钥生成开发 Token</h3><p>在这一步之前，你可能需要安装一些相关的包。</p><pre><code class=\"language-plain\">pip install --upgrade google-api-python-client&nbsp;\npip install --upgrade google-auth-oauthlib\npip install --upgrade google-auth-httplib2\n</code></pre><p>然后，把密钥下载下来，保存为credentials.json。</p><p>运行下面的代码，生成token.json。</p><pre><code class=\"language-plain\">from __future__ import print_function\n\nimport os.path\n\nfrom google.auth.transport.requests import Request\nfrom google.oauth2.credentials import Credentials\nfrom google_auth_oauthlib.flow import InstalledAppFlow\nfrom googleapiclient.discovery import build\nfrom googleapiclient.errors import HttpError\n\n# If modifying these scopes, delete the file token.json.\nSCOPES = ['https://www.googleapis.com/auth/gmail.readonly']\n\n\n\ndef main():\n&nbsp; &nbsp; \"\"\"Shows basic usage of the Gmail API.\n&nbsp; &nbsp; Lists the user's Gmail labels.\n&nbsp; &nbsp; \"\"\"\n&nbsp; &nbsp; creds = None\n&nbsp; &nbsp; # The file token.json stores the user's access and refresh tokens, and is\n&nbsp; &nbsp; # created automatically when the authorization flow completes for the first\n&nbsp; &nbsp; # time.\n&nbsp; &nbsp; if os.path.exists('token.json'):\n&nbsp; &nbsp; &nbsp; &nbsp; creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n&nbsp; &nbsp; # If there are no (valid) credentials available, let the user log in.\n&nbsp; &nbsp; if not creds or not creds.valid:\n&nbsp; &nbsp; &nbsp; &nbsp; if creds and creds.expired and creds.refresh_token:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; creds.refresh(Request())\n&nbsp; &nbsp; &nbsp; &nbsp; else:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; flow = InstalledAppFlow.from_client_secrets_file(\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 'credentials.json', SCOPES)\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; creds = flow.run_local_server(port=8088)\n&nbsp; &nbsp; &nbsp; &nbsp; # Save the credentials for the next run\n&nbsp; &nbsp; &nbsp; &nbsp; with open('token.json', 'w') as token:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; token.write(creds.to_json())\n\n&nbsp; &nbsp; try:\n&nbsp; &nbsp; &nbsp; &nbsp; # Call the Gmail API\n&nbsp; &nbsp; &nbsp; &nbsp; service = build('gmail', 'v1', credentials=creds)\n&nbsp; &nbsp; &nbsp; &nbsp; results = service.users().labels().list(userId='me').execute()\n&nbsp; &nbsp; &nbsp; &nbsp; labels = results.get('labels', [])\n\n&nbsp; &nbsp; &nbsp; &nbsp; if not labels:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print('No labels found.')\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; return\n&nbsp; &nbsp; &nbsp; &nbsp; print('Labels:')\n&nbsp; &nbsp; &nbsp; &nbsp; for label in labels:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(label['name'])\n\n&nbsp; &nbsp; except HttpError as error:\n&nbsp; &nbsp; &nbsp; &nbsp; # TODO(developer) - Handle errors from gmail API.\n&nbsp; &nbsp; &nbsp; &nbsp; print(f'An error occurred: {error}')\n\n\n\nif __name__ == '__main__':\n&nbsp; &nbsp; main()\n</code></pre><p>这是Google API网站提供的标准示例代码，里面给了读取权限（gmail.readonly）的Token，如果你要编写邮件，甚至发送邮件，需要根据需求来调整权限。更多细节可以参阅Google API的<a href=\"https://cloud.google.com/compute/docs/apis?hl=zh-cn\">文档</a>。</p><p>这个程序会生成一个token.json文件，是有相关权限的开发令牌。这个文件在LangChain应用中需要和密钥一起使用。</p><p><img src=\"https://static001.geekbang.org/resource/image/54/78/541c541b377063b49d74ddc53f41d578.jpg?wh=304x55\" alt=\"\"></p><p>把密钥和Token文件都放在程序的同一个目录中，你就可以开始开发应用程序了。</p><p><img src=\"https://static001.geekbang.org/resource/image/f2/b4/f23144b35b44fef8d900d0d50c9da6b4.jpg?wh=147x52\" alt=\"\"></p><h3>第三步：用 LangChain 框架开发 Gmail App</h3><p>这段代码的核心目的是连接到Gmail API，查询用户的邮件，并通过LangChain的Agent框架智能化地调用API（用语言而不是具体API），与邮件进行互动。</p><pre><code class=\"language-plain\"># 设置OpenAI API的密钥\nimport os \nos.environ[\"OPENAI_API_KEY\"] = 'Your Key'&nbsp;\n\n# 导入与Gmail交互所需的工具包\nfrom langchain.agents.agent_toolkits import GmailToolkit\n\n# 初始化Gmail工具包\ntoolkit = GmailToolkit()\n\n# 从gmail工具中导入一些有用的功能\nfrom langchain.tools.gmail.utils import build_resource_service, get_gmail_credentials\n\n# 获取Gmail API的凭证，并指定相关的权限范围\ncredentials = get_gmail_credentials(\n&nbsp; &nbsp; token_file=\"token.json\",&nbsp; # Token文件路径\n&nbsp; &nbsp; scopes=[\"https://mail.google.com/\"],&nbsp; # 具有完全的邮件访问权限\n&nbsp; &nbsp; client_secrets_file=\"credentials.json\",&nbsp; # 客户端的秘密文件路径\n)\n# 使用凭证构建API资源服务\napi_resource = build_resource_service(credentials=credentials)\ntoolkit = GmailToolkit(api_resource=api_resource)\n\n# 获取工具\ntools = toolkit.get_tools()\nprint(tools)\n\n# 导入与聊天模型相关的包\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.agents import initialize_agent, AgentType\n\n# 初始化聊天模型\nllm = ChatOpenAI(temperature=0, model='gpt-4')\n\n# 通过指定的工具和聊天模型初始化agent\nagent = initialize_agent(\n&nbsp; &nbsp; tools=toolkit.get_tools(),\n&nbsp; &nbsp; llm=llm,\n&nbsp; &nbsp; agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n)\n\n# 使用agent运行一些查询或指令\nresult = agent.run(\n&nbsp; &nbsp; \"今天易速鲜花客服给我发邮件了么？最新的邮件是谁发给我的？\"\n)\n\n# 打印结果\nprint(result)&nbsp; \n</code></pre><p>代码的核心部分主要是连接到Gmail API，获取用户的邮件数据，并通过特定的 Agent 查询这些数据。</p><p>你的请求是查询今天是否收到了来自“易速鲜花客服”的邮件，以及最新邮件的发送者是谁。<strong>这个请求是模糊的，是自然语言格式，具体调用什么API，由Agent、Tool也就是Gmail API它俩商量着来。</strong>这与我们之前所进行的清晰的、具体API调用式的应用开发迥然不同。</p><p>第一次运行程序，会进行一些确认，并让我Login我的Gmail。</p><p><img src=\"https://static001.geekbang.org/resource/image/0e/37/0e2a7df295caa50512552e05ea3def37.jpg?wh=562x146\" alt=\"\"></p><p><img src=\"https://static001.geekbang.org/resource/image/32/51/3208ff117674ebf3f08eac6118393e51.jpg?wh=488x664\" alt=\"\"></p><p><img src=\"https://static001.geekbang.org/resource/image/0c/30/0cc81560c4bc412104b5144a474c5530.jpg?wh=546x119\" alt=\"\"></p><p>之后，我就得到了智能助手的回答！</p><p><img src=\"https://static001.geekbang.org/resource/image/45/cf/455f8cb0138cd3860869e5eee74f8ecf.jpg?wh=1296x605\" alt=\"\"></p><p>她说：<strong>主人，看起来你没有收到“易速鲜花”的邮件耶，还需要我帮你做些什么吗？</strong>真的很贴心，这样的话，我每天早晨就不需要自己去检查邮件啦！</p><p>后来，我又问她，那么谁给我发来了新邮件呢？</p><p><img src=\"https://static001.geekbang.org/resource/image/c9/e4/c95a8e75cdc78a7da4960c8f2yyf8be4.jpg?wh=1291x159\" alt=\"\"></p><p>她告诉我说，Medium - Programing 给我发了一篇 VS code 的 10 个 tips 的文章，还有Kubernetes的点子啥的。</p><p>嗯，这是我订阅的内容。下一步，我还可以让她针对这些内容给我总结总结！这也是她的强项！</p><h2>总结时刻</h2><p>学到现在，你应该对LangChain 的核心价值有了更深的感悟吧。它的价值，在于它将模型运行和交互的复杂性进行了封装和抽象化，为开发者提供了一个更简单、更直观的接口来利用大模型。</p><ul>\n<li><strong>集成多模型和多策略：</strong>LangChain 提供了一种方法，使得多个模型或策略能够在一个统一的框架下工作。例如，arXiv 是一个单独的工具，它负责处理特定的任务。这种工具可以与其他工具（例如用于处理自然语言查询或者数据库查询的工具）一起作为一个集成的系统存在。这样，你可以轻松地创建一个系统，该系统可以处理多种类型的输入并执行多种任务，而不必为每个任务单独写代码。<br>\n&nbsp;</li>\n<li><strong>更易于交互和维护：</strong>通过 LangChain，你可以更方便地管理和维护你的工具和模型。LangChain 提供的工具和代理（Agent）抽象使得开发者可以将关注点从底层实现细节转向实现应用的高层逻辑。而且，LangChain封装了像模型的加载、输入输出的处理、工具的调度等底层任务，使得开发者能够更专注于如何组合这些工具以解决实际问题。<br>\n&nbsp;</li>\n<li><strong>适应性：</strong>LangChain 提供的架构允许你轻松地添加新的工具或模型，或者替换现有的工具或模型。这种灵活性使得你的系统可以很容易地适应新的需求或改变。<br>\n&nbsp;</li>\n<li><strong>可解释性：</strong>LangChain 还提供了对模型决策的可解释性。在你的示例中，LangChain 提供的对话历史和工具选择的记录可以帮助理解系统做出某些决策的原因。</li>\n</ul><p>总的来说，尽管直接调用模型可能对于单一任务或简单应用来说足够了，但是当你需要处理更复杂的场景，例如需要协调多个模型或工具，或者需要处理多种类型的输入时，使用像 LangChain 这样的框架可以大大简化你的工作。</p><h2>思考题</h2><ol>\n<li>上面Gmail的示例中我只是展示了邮件读取功能，你能否让你的AI助理帮你写邮件的草稿甚至发送邮件？<br>\n&nbsp;</li>\n<li>你可否尝试使用GitHub工具开发一些App来自动完成一部分GitHub任务，比如查看Issues、Merge Branches之类的事儿。</li>\n</ol><p>提示：参考此<a href=\"https://docs.github.com/en/apps/creating-github-apps/registering-a-github-app/registering-a-github-app\">链接</a>创建 GitHub App，以及LangChain的<a href=\"https://python.langchain.com/docs/integrations/toolkits/github\">参考文档</a>。</p><p><img src=\"https://static001.geekbang.org/resource/image/1b/2e/1bc0dcd6e05133f934ed926cdcc9eb2e.jpg?wh=1898x851\" alt=\"\"><br>\n<img src=\"https://static001.geekbang.org/resource/image/e0/ea/e037cf6460826e189811ea2af4bb96ea.jpg?wh=1281x747\" alt=\"\"></p><p>期待在留言区看到你的分享，如果你觉得内容对你有帮助，也欢迎分享给有需要的朋友！最后如果你学有余力，可以进一步学习下面的延伸阅读。</p><h2>延伸阅读</h2><ol>\n<li>文档：LangChain中集成的所有<a href=\"https://python.langchain.com/docs/integrations/tools/\">工具</a></li>\n<li>文档：LangChain中集成的所有<a href=\"https://python.langchain.com/docs/integrations/toolkits/\">工具箱</a></li>\n<li>文档：Google Cloud <a href=\"https://cloud.google.com/compute/docs/apis?hl=zh-cn\">API</a></li>\n<li>文档：Github REST <a href=\"https://support.github.com/features/rest-api\">API</a></li>\n</ol>","comments":[{"had_liked":false,"id":383239,"user_name":"Geek_995b81","can_delete":false,"product_type":"c1","uid":3733604,"ip_address":"广东","ucode":"D99E0838B97C0B","user_header":"","comment_is_top":false,"comment_ctime":1698738621,"is_pvip":false,"replies":[{"id":139600,"content":"当然可以。参考实战篇第20，21课内容。","user_name":"作者回复","user_name_real":"编辑","uid":1809833,"ctime":1698770322,"ip_address":"瑞士","comment_id":383239,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100617601,"comment_content":"老师好，那我们可以自定义工具吗？比如某个实际场景，我需要调用到某个内部系统的API，通过API返回的信息我再做提取，然后将提取到的信息重新给LLM推理","like_count":3,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":630670,"discussion_content":"当然可以。参考实战篇第20，21课内容。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1698770322,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"瑞士","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":382230,"user_name":"抽象派","can_delete":false,"product_type":"c1","uid":2599971,"ip_address":"广东","ucode":"6879F90CB702FC","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/YflLdCdbUAkfr9LPzF50EibDrMxBibPicQ5NNAETaPP0ytTmuR3h6QNichDMhDbR2XelSIXpOrPwbiaHgBkMJYOeULA/132","comment_is_top":false,"comment_ctime":1696923006,"is_pvip":false,"replies":[{"id":139258,"content":"是的，为了让模型更好地理解代码，LLM在编程领域已经受到了良好的培训。例如，OpenAI的Codex就是专门为代码编写和编程任务而训练的模型。ChatGPT和GPT4也一样。\n当向模型提问时，应该明确并详细。例如：“请分析以下的REST API接口代码，并为我列出它的调用和依赖关系。”\n确保为模型提供足够的上下文信息，如相关的代码片段、库、框架等。一个高层次的概览，然后继续追问更具体的细节。","user_name":"作者回复","user_name_real":"编辑","uid":1809833,"ctime":1697019000,"ip_address":"新加坡","comment_id":382230,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100617601,"comment_content":"老师，文中“甚至尝试让大模型自动回答 Issues 中的问题——反正大模型解决代码问题的能力本来就更强。”是怎样实现让大模型理解项目系统代码的？例如：一个web项目，我给出一个接口，大模型能从给定的接口出发自顶向下，分析出每一层的调用关系和依赖关系。","like_count":2,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":629407,"discussion_content":"是的，为了让模型更好地理解代码，LLM在编程领域已经受到了良好的培训。例如，OpenAI的Codex就是专门为代码编写和编程任务而训练的模型。ChatGPT和GPT4也一样。\n当向模型提问时，应该明确并详细。例如：“请分析以下的REST API接口代码，并为我列出它的调用和依赖关系。”\n确保为模型提供足够的上下文信息，如相关的代码片段、库、框架等。一个高层次的概览，然后继续追问更具体的细节。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1697019000,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"新加坡","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":382182,"user_name":"阿斯蒂芬","can_delete":false,"product_type":"c1","uid":1024164,"ip_address":"广东","ucode":"61D5E3BDA4EBC5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/a0/a4/b060c723.jpg","comment_is_top":false,"comment_ctime":1696842560,"is_pvip":false,"replies":[{"id":139250,"content":"Tool是单一工具，Toolkits里面装了一系列的工具，LLM需要在每一步中思考，然后选择，用一系列工具中的哪一个。","user_name":"作者回复","user_name_real":"编辑","uid":1809833,"ctime":1696989000,"ip_address":"瑞士","comment_id":382182,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100617601,"comment_content":"怎么理解Tool和Toolkits 的异同呢？","like_count":2,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":629368,"discussion_content":"Tool是单一工具，Toolkits里面装了一系列的工具，LLM需要在每一步中思考，然后选择，用一系列工具中的哪一个。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1696989001,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"瑞士","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":390453,"user_name":"liyinda0000","can_delete":false,"product_type":"c1","uid":1198421,"ip_address":"北京","ucode":"12D5C62716DAB6","user_header":"https://static001.geekbang.org/account/avatar/00/12/49/55/b6c9c0f4.jpg","comment_is_top":false,"comment_ctime":1715391154,"is_pvip":false,"replies":[{"id":142267,"content":"我还没有尝试，挺其它的同学说，LangChain Agent的封装，OpenAI做的好，其它国内的模型好像封装的不好，还不能调用工具吧。","user_name":"作者回复","user_name_real":"编辑","uid":1809833,"ctime":1717648136,"ip_address":"新加坡","comment_id":390453,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100617601,"comment_content":"老师，你有遇到过这个问题吗？\n不使用openai封装agent，使用的是私有模型比如qwen-1.8b时封装的agent不能调用tools，不知道什么原因？","like_count":0,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":646254,"discussion_content":"我还没有尝试，挺其它的同学说，LangChain Agent的封装，OpenAI做的好，其它国内的模型好像封装的不好，还不能调用工具吧。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1717648136,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"新加坡","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1899757,"avatar":"","nickname":"yanyu-xin","note":"","ucode":"3AA389F9E4C236","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":649401,"discussion_content":"用通义模型可以调用工具。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1723297596,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"美国","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":382252,"user_name":"enbool","can_delete":false,"product_type":"c1","uid":2851308,"ip_address":"四川","ucode":"BB460DCCA87099","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epEexjZIhNpYNiaAibdLD0Jsl797U6hianjrDs2QT4Q4HOicIEeILxjOcEF7gXGyQeJRJHaeenibb3N9QQ/132","comment_is_top":false,"comment_ctime":1696935704,"is_pvip":false,"replies":[{"id":139245,"content":"如果首页上找不到入群的信息，加我微信jackyhuang79吧","user_name":"作者回复","user_name_real":"编辑","uid":1809833,"ctime":1696988394,"ip_address":"瑞士","comment_id":382252,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100617601,"comment_content":"老师，怎么进群啊？","like_count":0,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":629363,"discussion_content":"如果首页上找不到入群的信息，加我微信jackyhuang79吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1696988394,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"瑞士","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":393261,"user_name":"yanyu-xin","can_delete":false,"product_type":"c1","uid":1899757,"ip_address":"广东","ucode":"3AA389F9E4C236","user_header":"","comment_is_top":false,"comment_ctime":1723297870,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100617601,"comment_content":"不使用openai封装agent，使用的是私有模型比如qwen-1.8b时封装的agent是可以很好调用tools。\n将“使用 arXiv 工具开发科研助理”到代码修改、输出如下：\n\n旧代码：\nllm = ChatOpenAI(temperature=0.0)\n新代码：\nllm = ChatOpenAI(\n    api_key= &quot;DASHSCOPE_API_KEY&quot;,  #换为你的 key\n    base_url=&quot;https:&#47;&#47;dashscope.aliyuncs.com&#47;compatible-mode&#47;v1&quot;,  # 填写 DashScope base_url\n    model=&quot;qwen-1.8b-chat&quot;     # 其他通义模型也可以 &quot;qwen-long&quot; 、&quot;qwen-max&quot; \n)\n\n####  运行结果\n&gt;&gt; from langchain.agents import load_tools\nwith new imports of:\n&gt;&gt; from langchain_community.agent_toolkits.load_tools import load_tools\n（略）\n&gt; Entering new AgentExecutor chain...\n 我应该使用arxiv来查找相关信息。\nAction: arxiv\nAction Input: &quot;2005.14165&quot;\nObservation: Published: 2020-07-22\nTitle: Language Models are Few-Shot Learners\nAuthors: （略）\nThought: 我现在可以作答了。\nFinal Answer: 2005年发表的一项研究《语言模型是少样本学习者》对语言模型进行了创新性的研究。研究发现，通过预训练在大量文本数据上进行，以及针对特定任务进行微调的方 法，这些方法通常具有跨任务通用性，但在架构上仍然需要特定的任务强化学习数据集。相比之下，人类可以从少量或简单的指示中完成新的语言任务，而目前的自然语言处理系统在 这方面仍做得不好。研究人员展示了，在少样本情况下，可以极大地提高任务通用性和少样本性能，并有时甚至可以达到与先前的细粒度微调方法相当的竞争力。具体来说，他们训练 了GPT-3，这是一款拥有175亿参数、比以前任何非稀疏语言模型都要多的自注意力语言模型，然后测试其在少数样本设置下的表现。在所有任务上，GPT-3都无需梯度更新或微调即可应用，而是在文本交互的情况下对模型进行指定的任务和少数样本演示。GPT-3在许多NLP任务（包括翻译、问答、缺失填入等）中表现出色，还包括一些需要实时推理或领域适应的任务 ，如解开单词、将一个新词放入句子中或执行三进制算术。同时，研究人员还识别了一些大型Web语料库上的任务，其中GPT-3的少数样本学习仍然存在挑战，以及一些任务中的方法问 题，这些问题与在大型Web语料库上训练算法有关。最后，研究人员发现GPT-3可以在人工评估者难以区分的人类文章中生成样本来。他们讨论了这项发现及其广泛的社会影响，以及GPT-3的一般性影响。\n&gt; Finished chain. ","like_count":1},{"had_liked":false,"id":392558,"user_name":"张申傲","can_delete":false,"product_type":"c1","uid":1182372,"ip_address":"北京","ucode":"22D46BC529BA8A","user_header":"https://static001.geekbang.org/account/avatar/00/12/0a/a4/828a431f.jpg","comment_is_top":false,"comment_ctime":1721219761,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":2,"score":2,"product_id":100617601,"comment_content":"第14讲打卡~\n通过合理地编排多种Tools，一个多功能的智能助手就出来了~","like_count":0},{"had_liked":false,"id":392072,"user_name":"rs勿忘初心","can_delete":false,"product_type":"c1","uid":1519200,"ip_address":"北京","ucode":"557D1ECD757195","user_header":"https://static001.geekbang.org/account/avatar/00/17/2e/60/4fa1f3bd.jpg","comment_is_top":false,"comment_ctime":1719887392,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100617601,"comment_content":"比较好奇自然语言-&gt;参数抽取是哪个环节做的？如果的业务自己开发的API，涉及的参数较多（比如4-5个），能很好的处理么？","like_count":0},{"had_liked":false,"id":388845,"user_name":"左可","can_delete":false,"product_type":"c1","uid":1863064,"ip_address":"广东","ucode":"F7CC3D3B1036BC","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eqt6kWhJMrTD7lMTVYiaRe2ru9ibvScXgxaGgoRKOkmB5kNkQpmhfPYT8yoHG9icM542ttxtKYca39kA/132","comment_is_top":false,"comment_ctime":1711002205,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100617601,"comment_content":"(this Thought&#47;Action&#47;Action Input&#47;Observation can repeat N times)\\n——老师，这个可以让模型自主决定回溯多少次，如果稍微复杂的问题，是否有可能模型找不到最终答案？这种情况是如何跳出的？使用者是如何控制这个异常场景处理的？","like_count":0},{"had_liked":false,"id":388591,"user_name":"Longerian","can_delete":false,"product_type":"c1","uid":1032464,"ip_address":"浙江","ucode":"0B74EE70D09A2A","user_header":"https://static001.geekbang.org/account/avatar/00/0f/c1/10/28d5a686.jpg","comment_is_top":false,"comment_ctime":1710427748,"is_pvip":false,"replies":null,"discussion_count":2,"race_medal":0,"score":2,"product_id":100617601,"comment_content":"I should search for the paper with the identifier &quot;2005.14165&quot; on arxiv to find out its innovative points.\nAction: arxiv\nAction Input: 2005.14165\nObservation: Published: 2020-07-22\nTitle: Language Models are Few-Shot Learners\nAuthors: Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, Dario Amodei\nSummary: Recent work has demonstrated substantial gains on many NLP tasks and\nbenchmarks by pre-training on a large corpus of text followed by fine-tuning on\na specific task. While typically task-agnostic in architecture, this method\nstill requires task-specific fine-tuning datasets of thousands or tens \n\n为何我执行了搜到的论文和文中的不一样，开始胡说八道了。","like_count":0,"discussions":[{"author":{"id":3864625,"avatar":"","nickname":"Geek_e74222","note":"","ucode":"61626A4620E761","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":639788,"discussion_content":"同学，你用的是什么模型？\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1710921101,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"湖北","group_id":0},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1032464,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/c1/10/28d5a686.jpg","nickname":"Longerian","note":"","ucode":"0B74EE70D09A2A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":3864625,"avatar":"","nickname":"Geek_e74222","note":"","ucode":"61626A4620E761","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":640087,"discussion_content":"就是文中的代码","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1711121228,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":639788,"ip_address":"浙江","group_id":0},"score":640087,"extra":""}]}]}]}