{"id":740894,"title":"第 16 章 服务集成(2)","content":"<h2 id=\"nav_point_245\">16.2　使用消息中间件进行异步通信</h2>\n<p>在本书前面的所有章节中，我们的交互几乎是同步的，而且服务的消费者明确地知道自己要调用的服务到底是谁，以及它们在哪里。然而，在日常工作中，除了同步通信，还经常会用到基于消息中间件的异步通信方式。在这一节里，就让我们来了解下如何在 Spring 工程中进行异步消息通信。</p>\n<h3 id=\"nav_point_246\">16.2.1　为什么要使用基于消息的异步通信</h3>\n<p>基于消息的异步通信有三个明显的优势。第一个优势是<strong>提供了服务解耦的能力</strong>。在同步调用中，上下游是紧密关联在一起的，系统 B 需要系统 A 的一个通知，那就必须在系统 A 的代码里进行硬编码，对系统 B 发起一个调用。如果日后系统 B 不再需要这个通知，那系统 A 还要进行代码变更，万一系统 B 出问题，系统 A 的执行就会失败，这就是耦合。如果两者不直接交互，而是系统 A 将通知发给消息中间件，系统 B 从消息中间件消费，那它们的关系就没那么紧密了。不管系统 B 能不能正常工作，系统 A 只是和消息中间件打交道，并不会感知系统 B 的状态。即使系统 B 不再需要这个通知，系统 A 依然可以继续向消息中间件发消息，系统 B 不接收就好了。更重要的是，如果来了个系统 C 也需要一样的通知，同样从消息中间件获取即可，就不用再修改系统 A 了，就像图 16-3 那样。</p><!-- [[[read_end]]] -->\n<p class=\"pic\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100008/image00800.jpeg\" alt=\"{%}\" /></p>\n<p class=\"ebook-image-title\"><strong>图 16-3　通过消息中间件实现服务解耦</strong></p>\n<p>第二个优势是能够<strong>提供异步处理的能力</strong>，提升系统响应性能。假设一个业务流程，一共有 10 个步骤，每个步骤耗时 100 毫秒，整个流程执行下来就需要 1000 毫秒。如果能把其中 3 个非必需的步骤从主干中剥离，改为异步执行，那么结果会怎样呢？假设与消息中间件通信一次需要 5 毫秒，交互 3 次就会耗时 15 毫秒，对于这 3 个动作，同步应答的时间能减少 285 毫秒。此外，如果这 3 个动作能接受失败重试，就进一步提升了操作的成功率（本来在主流程里，它们的失败会造成整个流程的失败，现在消息中间件能帮忙进行重试，相当于间接提升了主流程的成功率）。</p>\n<p>第三个优势是能够<strong>提供削峰填谷的能力</strong>。在面临流量高峰时，如果任由流量涌入，那系统迟早会被压垮。而要是用限流的手段，势必要牺牲一部分请求，让这部分请求直接失败。借助上面的异步处理能力，我们可以将一部分不需要及时处理的步骤暂时积压到消息中间件里，系统在有能力消费这些消息时，会逐步从里面取出消息来进行处理。这个“有能力消费”，就是在高峰时全力应对必须要处理的同步任务，在低峰时就有资源能处理积压在消息中间件里的异步任务了。</p>\n<p>在组合叠加这三个优势的助推下，基于消息的异步通信方式在各种规模的系统中得到了广泛的应用，也诞生了很多知名的消息中间件，例如开源世界的 ActiveMQ、Kafka、RabbitMQ 和 RocketMQ 等——稍后我们就会看到如何在 Spring 项目里使用这些设施。</p>\n<blockquote>\n<p><strong>茶歇时间：常见的消息模型</strong></p>\n<p>想知道消息是如何在不同的系统间流转的，又是谁能收到系统中的消息呢？先让我们弄清消息的“推模型”（Push Model）与“拉模型”（Pull Model）。所谓“推”，是指消息的消费者被动等待消息中间件的通知，消息会由中间件推送给消费者，这时，消费者无须关心生产者和中间件的情况。而“拉”则正好相反，消费者会主动前往中间件获取消息。无论是“推”还是“拉”，都可以是批量的形式，每次处理一批消息。消息的生产者将消息投递给到中间件，Kafka 中的消费者使用的是“拉”的方式（从 Broker 获取消息），RabbitMQ 中的消费者则用的是“推”模型。</p>\n<p>在日常的使用过程中，大家接触比较多的消息传递模型有两种，一种是队列（Queue）模型，另一种是发布订阅（Publish/Subscribe，或者简称为 Pub/Sub）模型。在队列模型下，一个队列可以有多个生产者和消费者，生产者投递到队列里的消息只能被一个消费者消费，所以这种模型下的消息也可以算是“点对点”消费的。而在发布订阅模型下，消费者其实是订阅了某个主题的消息，一条消息在被生产者发布后可以被多个消费者消费。两种模型的一大区别就是消息是否可以被不同的消费者多次消费。<span class=\"comment-number\">7</span></p>\n</blockquote>\n\n<h3 id=\"nav_point_247\">16.2.2　通过 Spring AMQP 使用 RabbitMQ</h3>\n<p>RabbitMQ 是一款技术领先的开源消息队列中间件，由 Erlang 语言开发，遵循<strong>高级消息列队协议</strong>（Advanced Message Queuing Protocol，AMQP）。2010 年，SpringSource 收购了 RabbitMQ，所以说起来现在 RabbitMQ 和 Spring 还是“一家人”。Spring AMQP 项目为遵循 AMQP 的消息中间件提供了比较好的支持，通过 Spring AMQP 可以方便地使用 RabbitMQ 来进行消息通信。</p>\n<p>在讨论使用前，先要了解一些 AMQP 的核心概念，方便后面编写代码。</p>\n<ul>\n<li>Queue，消息队列的载体，消息会被投入一个或多个队列。</li>\n<li>Broker，接收和发送消息的代理，RabbitMQ 的服务端就是一个 Broker。</li>\n<li>Exchange，消息交换机，也是消息到达 Broker 后的第一站，它会根据路由分发规则，将消息分发到不同的队列。</li>\n<li>Binding，将 Exchange 与 Queue 按照路由规则绑定到一起。</li>\n<li>Routing Key，路由关键字，Exchange 会根据它来进行消息投递。</li>\n</ul>\n<p>在 RabbitMQ 中，Exchange 分为四种，分别是直接（Direct）交换机、主题（Topic）交换机、扇出（Fanout）交换机和消息头（Header）交换机，前三种用得会多一些。直接交换机绑定了明确的路由关键字，完全匹配才会投递；主题交换机会对关键字进行模式匹配，<code>#</code> 匹配一个或多个词，<code>*</code> 匹配有且仅有一个词；扇出交换机则完全不需要关键字。上一章的例子里我们提到有些场景使用 HTTP 调用并不是理想的方式，使用消息通信会更好一些，接下来就来看看应该如何在两者之间调整。</p>\n<blockquote>\n<p><strong>需求描述</strong>　以前顾客在支付订单后，系统会隔段时间通知调茶师，然后等待他完成制作。但其实这个步骤完全是没有必要的，通知调茶师订单消息之后，让他自己去制作就好了，等待的动作是多余的。待订单制作完毕后，调茶师再通知系统即可。这里就可以通过消息通信的方式对两者进行解耦。</p>\n</blockquote>\n<p>在开始前，还是和之前一样，引入对应的 <code>spring-boot-starter-amqp</code> 起步依赖，它的版本由 Spring Boot 统一管理：</p>\n<pre class=\"code-rows\"><code>&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;\n&lt;/dependency&gt;</code></pre>\n<p>Spring Boot 的 <code>RabbitAutoConfiguration</code> 自动配置类为我们准备好了 <code>CachingConnectionFactory</code>、<code>RabbitTemplate</code> 和 <code>AmqpAdmin</code>。与此同时，配置类 <code>RabbitAnnotationDrivenConfiguration.EnableRabbitConfiguration</code> 上加了 <code>@EnableRabbit</code> 注解，告诉 Spring 开启 RabbitMQ 相关的注解支持，所以我们也无须自己动手了。</p>\n<ol>\n<li><p><strong>发送消息</strong></p>\n<p>与 Spring 中的其他抽象类似，在收发 AMQP 的消息时，Spring AMQP 提供了一个 <code>AmqpTemplate</code> 接口及其实现类 <code>RabbitTemplate</code>，其中包含了收发消息所需的各种模板方法，表 16-3 罗列了其中的一些主要方法，表中省略了很多参数，通过这个表格可以看到 <code>AmqpTemplate</code> 既提供了原子的操作，也提供了多种操作的组合。</p>\n<p><strong>表 16-3　<code>AmqpTemplate</code> 中的一些主要方法</strong></p>\n<table class=\"table table-bordered table-striped table-condensed\" width=\"90%\" border=\"1\"><tr><th>方法</th><th>说明</th></tr><tr><td><code>send()</code></td><td>发送消息，消息体已经是需要的 <code>Message</code> 类型了，发送时可以选择性地指定 Exchange 和 Routing Key</td></tr><tr><td><code>convertAndSend()</code></td><td>发送消息，传入的消息内容会被转换为 <code>Message</code> 类型</td></tr><tr><td><code>receive()</code></td><td>接收消息，返回 <code>Message</code> 类型的消息内容，可以选择性地传入队列名和等待时间</td></tr><tr><td><code>receiveAndConvert()</code></td><td>接收消息，消息体会被转换为 <code>Object</code>，或者通过 <code>ParameterizedTypeReference&lt;T&gt;</code> 明确类型</td></tr><tr><td><code>receiveAndReply()</code></td><td>接收消息并发送一个应答</td></tr><tr><td><code>sendAndReceive()</code></td><td>发送消息并等待接收应答</td></tr><tr><td><code>convertSendAndReceive()</code></td><td>发送转换类型后的内容，并等待接收应答</td></tr><tr><td><code>convertSendAndReceiveAsType()</code></td><td>发送转换类型后的内容，等待接收应答，并将应答转换为指定类型</td></tr></table>\n\n<p>在之前的例子里，我们单独启动了一个定时任务，加载状态为 <code>PAID</code> 的订单，通过 HTTP 将请求发送到 TeaMaker 并取回结果。定时任务有一个弊端，本来相对平滑的曲线，会由于调度在每个执行时间出现尖刺。我们可以将与 TeaMaker 的交互改为消息，在订单支付后立即发送一个消息，通知调茶师开始制作订单。为此，可以像代码示例 16-6<span class=\"comment-number\">8</span> 那样彻底重写 <code>TeaMakerClient</code> 类，将 HTTP 交互改为使用 <code>AmqpTemplate</code> 向 <code>notify.order.paid</code> 发送消息，消息体是 <code>OrderMessage</code> 类型的对象。</p>\n<blockquote>\n<p><strong>代码示例 16-6</strong>　发送消息的代码片段</p>\n</blockquote>\n<pre class=\"code-rows\"><code>@Component\n@Slf4j\npublic class TeaMakerClient {\n    @Autowired\n    private AmqpTemplate amqpTemplate;\n\n    public void notifyPaidOrder(Long id) {\n        log.info(\"将消息发送给TeaMaker，通知订单{}\", id);\n        amqpTemplate.convertAndSend(\"notify.order.paid\",\n            OrderMessage.builder().orderId(id).build());\n    }\n}\n\n@Getter\n@Setter\n@Builder\npublic class OrderMessage {\n    private Long orderId;\n    private Long teaMakerId;\n    private String state;\n}</code></pre>\n<p>上面的代码中的 <code>convertAndSend()</code> 方法有两个地方需要特别说明。首先是它可以传入 Exchange 和 Routing Key，消息先到 Exchange，随后根据 Routing Key 进行一轮计算，最后决定要投递的队列。而在例子中，我们省略了 Exchange 直接传入 Routing Key，这里使用默认的空白 Exchange，这样消息会直接投递到 <code>notify.order.paid</code> 队列。如果代码中注入的是 <code>RabbitTemplate</code>，则还可以通过 <code>setExchange()</code> 方法来设置默认使用的 Exchange。</p>\n<p>其次是消息体，Spring Boot 的自动配置的默认转换器是 <code>SimpleMessageConverter</code>，它只支持可序列化对象 <code>byte[]</code> 和 <code>String</code> 类型，为了支持其他的类型，我们需要自己配置一个消息转换器。好在 Spring AMQP 自带的那些 Jackson2 的转换器就够用了，只需在 Spring 上下文中配置一个 <code>MessageConverter</code> 类型的 Bean，<code>RabbitAnnotationDrivenConfiguration</code> 配置类就会把它注入进来。像代码示例 16-7 那样，在 <code>BinaryTeaApplication</code> 里配置一个 <code>Jackson2JsonMessageConverter</code>。</p>\n<blockquote>\n<p><strong>代码示例 16-7</strong>　配置 <code>Jackson2JsonMessageConverter</code></p>\n</blockquote>\n<pre class=\"code-rows\"><code>@SpringBootApplication\n@EnableCaching\n@EnableScheduling\npublic class BinaryTeaApplication implements WebMvcConfigurer {\n    @Bean\n    public Jackson2JsonMessageConverter jackson2JsonMessageConverter(ObjectMapper jsonObjectMapper) {\n        return new Jackson2JsonMessageConverter(jsonObjectMapper);\n    }\n}</code></pre>\n<p>上述步骤完成后，删除不再需要的定时任务 <code>TeaMakerNotifier</code> 类，调整一下 <code>OrderService.modifyOrderStatus()</code>，在订单状态被改为 <code>PAID</code> 时调用 <code>TeaMakerClient.notifyPaidOrder()</code> 方法发送消息，具体如代码示例 16-8 所示。但这个改动并不是最优的方法，毕竟它在一个相对通用的 <code>modifyOrderStatus()</code> 方法里嵌入了一段特殊的逻辑，这不是一种值得鼓励的方法，后文中介绍的事件方式会更优雅些。</p>\n<blockquote>\n<p><strong>代码示例 16-8</strong>　订单改为支付状态后触发发送消息</p>\n</blockquote>\n<pre class=\"code-rows\"><code>@Service\n@Transactional\n@Slf4j\npublic class OrderService {\n    @Autowired\n    private TeaMakerClient teaMakerClient;\n\n    public Order modifyOrderStatus(Long id, OrderStatus status) {\n        // 省略部分代码\n        if (OrderStatus.PAID == status) {\n            teaMakerClient.notifyPaidOrder(id);\n            order.get().setStatus(OrderStatus.MAKING);\n        }\n        return orderRepository.save(order.get());\n    }\n    // 省略其他代码\n}</code></pre>\n<p>&nbsp;</p>\n</li>\n<li><p><strong>消费消息</strong></p>\n<p>写完了消息的生产者，后面自然就到了消费者。<code>AmqpTemplate</code> 里虽然提供了 <code>receive()</code> 等方法，但用起来总不太方便，于是就该 <code>@RabbtListener</code> 注解闪亮登场了。在 TeaMaker 项目中创建一个 <code>BinaryteaClient</code>，用来消费 <code>notify.order.paid</code> 队列中的消息，消费的逻辑是从消息中取出订单号，调用之前用的 <code>OrderService.make()</code> 方法，处理完毕后再给 <code>notify.order.finished</code> 队列发个消息，通知 BinaryTea，具体如代码示例 16-9 所示。</p>\n<blockquote>\n<p><strong>代码示例 16-9</strong>　调茶师通过消息接收订单的逻辑</p>\n</blockquote>\n<pre class=\"code-rows\"><code>@Component\n@Slf4j\npublic class BinaryteaClient {\n    @Autowired\n    private OrderService orderService;\n    @Autowired\n    private AmqpTemplate amqpTemplate;\n\n    @RabbitListener(queues = \"notify.order.paid\")\n    public void processOrder(OrderMessage message) {\n        Long id = message.getOrderId();\n        log.info(\"开始制作订单{}\", id);\n        ProcessResult result = orderService.make(id);\n        OrderMessage finished = OrderMessage.builder().orderId(id)\n            .teaMakerId(result.getTeaMakerId())\n            .state(\"FINISHED\").build();\n        log.info(\"订单{}制作完毕\", id);\n        amqpTemplate.convertAndSend(\"notify.order.finished\", finished);\n    }\n}</code></pre>\n<p>因为消息中传递的内容是 <code>OrderMessage</code> 类型的，所以需要和之前一样在 <code>TeaMakerApplication</code> 中配置 <code>Jackson2JsonMessageConverter</code> Bean。在带有 <code>@RabbitListener</code> 注解的方法参数里，还可以增加 <code>@Payload</code> 注解来标注这个参数是消息体，用 <code>@Header</code> 注解标注的参数则是特定的消息头。同时，在 <code>application.yml</code> 中添加 RabbitMQ 服务端的信息：</p>\n<pre class=\"code-rows\"><code>spring:\n  rabbitmq:\n    addresses: \"amqp://spring:spring@localhost\"</code></pre>\n<p>为了能够正确记录已完成订单的信息，BinaryTea 要去消费刚才生产的 <code>notify.order.finished</code> 并做进一步的处理。我们在 <code>TeaMakerClient</code> 里增加一个 <code>receiveFinishedOrder()</code> 方法，如果收到消息中的订单状态是 <code>FINISHED</code>，通过 2.3 节中介绍的 Spring 事件机制发送一个 <code>OrderFinishedEvent</code> 事件。因为这个类位于 <code>learning.spring.binarytea.integration</code> 包中，这层的主要工作是处理各种服务集成的相关事宜，在里面直接调用 <code>OrderService</code> 就与它的定位有些格格不入，所以用事件机制广播一个事件，关心的人自己处理即可。具体如代码示例 16-10 所示。</p>\n<blockquote>\n<p><strong>代码示例 16-10</strong>　<code>notify.order.finished</code> 消息处理逻辑</p>\n</blockquote>\n<pre class=\"code-rows\"><code>@Component\n@Slf4j\npublic class TeaMakerClient {\n    @Autowired\n    private ApplicationEventPublisher applicationEventPublisher;\n\n    @RabbitListener(queues = \"notify.order.finished\")\n    public void receiveFinishedOrder(OrderMessage message) {\n        if (OrderStatus.FINISHED.name().equals(message.getState())) {\n            log.info(\"收到订单[{}]的完成通知\", message.getOrderId());\n            applicationEventPublisher.publishEvent(new OrderFinishedEvent(message));\n        } else {\n            log.warn(\"被通知到的订单[{}]状态不正确\", message.getOrderId());\n        }\n    }\n    // 省略其他代码\n}\n\npublic class OrderFinishedEvent extends ApplicationEvent {\n    public OrderFinishedEvent(OrderMessage source) {\n        super(source);\n    }\n}</code></pre>\n<p>我们将 <code>OrderFinishedEvent</code> 的监听逻辑放在 <code>OrderService</code> 里，这样一来订单相关的处理逻辑还是都集中在 <code>OrderService</code> 里，代码示例 16-11 里的 <code>finishOrder()</code> 通过 <code>modifyOrderStatus()</code> 来推进订单状态的变化，这里并没有对数据库操作做过多优化，变更调茶师 ID 的动作还会更新一次数据，所以在生产中可以酌情考虑优化这段逻辑。</p>\n<blockquote>\n<p><strong>代码示例 16-11</strong>　<code>OrderFinishedEvent</code> 的事件监听逻辑</p>\n</blockquote>\n<pre class=\"code-rows\"><code>@Service\n@Transactional\n@Slf4j\npublic class OrderService {\n    // 省略其他代码\n    @EventListener\n    public void finishOrder(OrderFinishedEvent event) {\n        OrderMessage message = (OrderMessage) event.getSource();\n        // 没考虑性能等问题\n        Order order = modifyOrderStatus(message.getOrderId(), OrderStatus.FINISHED);\n        if (order != null) {\n            teaMakerRepository.findById(message.getTeaMakerId()).ifPresent(order::setMaker);\n            orderRepository.save(order);\n        }\n    }\n}</code></pre>\n<p>最后，在运行这些程序前，需要在 <code>localhost:5672</code> 启动一个 RabbitMQ，建议从 DockerHub 上寻找官方镜像来运行。为了方便配置，可以选择带 <code>-management</code> 的版本，例如 <code>3.7-management</code>，通过将 DockerHub 镜像介绍页面上的命令稍作修改来启动，下面的命令就做了端口映射还调整了默认的用户名和密码，控制台登录的用户名和密码都是 <code>spring</code><span class=\"comment-number\">9</span>：</p>\n<pre class=\"code-rows\"><code>▸ docker pull rabbitmq:3.7-management\n▸ docker run --name rabbitmq -d -p 5672:5672 -p 15672:15672 \\\n  -e RABBITMQ_DEFAULT_USER=spring -e RABBITMQ_DEFAULT_PASS=spring \\\n  rabbitmq:3.7-management</code></pre>\n<p>访问 <code>http://localhost:15672</code> 登录到控制台后，手动在队列的页面里创建 <code>notify.order.paid</code> 和 <code>notify.order.finished</code> 消息队列。虽然 Spring AMQP 提供了 <code>AmqpAdmin</code>，允许我们在代码里创建 Exchange 和 Queue，但在生产中还是建议事先通过一定的流程来创建这些队列，同时在创建的流程里还要明确生产者、消费者、预估消息量、作用等信息，方便后期的运维。</p>\n<p>&nbsp;</p>\n</li>\n<li><p><strong>常用配置</strong></p>\n<p>Spring Boot 针对 Spring AMQP（其实就是 RabbitMQ）做了对应的自动配置，相关的配置属性都在 <code>RabbitProperties</code> 中，表 16-4 罗列了其中的一些常用配置。</p>\n<p><strong>表 16-4　Spring Boot 中关于 RabbitMQ 的部分配置</strong></p>\n<table class=\"table table-bordered table-striped table-condensed\" width=\"90%\" border=\"1\"><tr><th>配置项</th><th>默认值</th><th>说明</th></tr><tr><td><code>spring.rabbitmq.addresses</code></td><td></td><td>逗号分隔的服务端地址列表，如果设置了会忽略主机和端口的配置</td></tr><tr><td><code>spring.rabbitmq.host</code></td><td><code>localhost</code></td><td>要连接的主机名</td></tr><tr><td><code>spring.rabbitmq.port</code></td><td><code>5672</code> 或 <code>5671</code></td><td>要连接的端口，默认是 <code>5672</code>，如果开启了 SSL 则默认是 <code>5671</code></td></tr><tr><td><code>spring.rabbitmq.username</code></td><td><code>guest</code></td><td>连接 RabbitMQ 时用的用户名</td></tr><tr><td><code>spring.rabbitmq.password</code></td><td><code>guest</code></td><td>连接 RabbitMQ 时用的密码</td></tr><tr><td><code>spring.rabbitmq.virtual-host</code></td><td></td><td>连接 RabbitMQ 时用的虚拟主机</td></tr><tr><td><code>spring.rabbitmq.ssl.enabled</code></td><td><code>false</code></td><td>是否开启 SSL<sup><b>10</b></sup>，如果用 <code>spring.rabbitmq.addresses</code> 设置的地址，这个参数可以通过 <code>amqp://</code> 或 <code>amqps://</code> 前缀来自动判断</td></tr><tr><td><code>spring.rabbitmq.connection-timeout</code></td><td></td><td>连接超时，<code>0</code> 代表永不超时</td></tr><tr><td><code>spring.rabbitmq.channel-rpc-timeout</code></td><td><code>10m</code></td><td>在通信频道中进行 RPC 调用时的超时，<code>0</code> 代表永不超时</td></tr><tr><td><code>spring.rabbitmq.template.retry.enabled</code></td><td><code>false</code></td><td>模板方法发送消息是否开启重试</td></tr><tr><td><code>spring.rabbitmq.template.retry.initial-interval</code></td><td><code>1000ms</code></td><td>模板方法中的首次重试间隔时间</td></tr><tr><td><code>spring.rabbitmq.template.retry.max-attempts</code></td><td><code>3</code></td><td>模板方法中的最大重试次数</td></tr><tr><td><code>spring.rabbitmq.template.reply-timeout</code></td><td></td><td>模板的 <code>sendAndReceive()</code>方法的超时时间</td></tr><tr><td><code>spring.rabbitmq.template.receive-timeout</code></td><td></td><td>模板的 <code>receive()</code> 方法的超时时间</td></tr><tr><td><code>spring.rabbitmq.listener.type</code></td><td><code>simple</code></td><td>监听器类型，<code>SIMPLE</code> 是将消息分发给调用线程来消费，<code>DIRECT</code> 则是直接在 RabbitMQ 消费线程上消费</td></tr></table>\n\n<blockquote>\n<p><sup><b>10</b></sup>如需开启还需要设置相关的 SSL 证书等信息，具体的配置都用 <code>spring.rabbitmq.ssl</code> 开头，可以参考官方手册。</p>\n</blockquote>\n</li>\n</ol>\n\n\n<h3 id=\"nav_point_248\">16.2.3　通过 Spring Cloud Stream 使用 Kafka</h3>\n<p>与上一章的 Spring Cloud CircuitBreaker 类似，如果可以替换组件来实现在 Spring 项目中收发消息，那必然在其之上可以做一层抽象，屏蔽不同底层实现之间的差异，用更统一的方式来编写代码。虽然 Spring 为我们提供了 Spring AMQP 和 Spring for Apache Kafka 这样的框架，用 <code>AmqpTemplate</code> 和 <code>KafkaTemplate</code> 来收发消息，用 <code>@RabbitListener</code> 和 <code>@KafkaListener</code> 这两个注解来标识接收消息的方法，不同的消息中间件的用法已经很接近了。但在 Spring 团队看来，接近还是不够的，Spring 可以做得更好，于是就有了这节的主角——Spring Cloud Stream。</p>\n<ol>\n<li><p><strong>概念模型</strong></p>\n<p>既然是对众多优秀消息中间件的抽象，自然就少不了要了解一下 Spring Cloud Stream 抽象后的模型是什么样的。图 16-4 是其官方文档中给出的应用模型，其中有如下几个重要概念。</p>\n<ul>\n<li>Binder，这是连接应用核心（Application Core）与中间件（Middleware）的桥梁，不同的消息中间件会有对应的 Binder 实现。</li>\n<li>输入（inputs），这是消息流入的渠道，将消息队列绑定到应用中的消费者。</li>\n<li>输出（outputs），这是消息流出的渠道，将生产者产生的消息投递到中间件。</li>\n</ul>\n<p class=\"p-img\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100008/image00801.jpeg\" alt=\"{%}\" /></p>\n<p class=\"ebook-image-title\"><strong>图 16-4　Spring Cloud Stream 模型</strong></p>\n<p>除了图 16-4 中展现出来的几个概念，为了兼容 Kafka 和 RabbitMQ，Spring Cloud Stream 还提供了消费者分组（Consumer Group）和主题分区（Partition）的支持，Kafka 原生就支持这些概念，RabbitMQ 并不支持，但在 Spring Cloud Stream 的帮助下，我们可以用一样的方式来进行思考，编写代码。</p>\n<p>对一个消息主题而言：一个消费者分组中的不同消费者实例是竞争关系，一条消息只能被一个消费者实例消费；不同的分组则是合作的关系，消息的不同副本会被分别投递到每个分组，每个分组都能消费这条消息。试想这样一个场景，系统 A 和 B 都希望消费主题 T 的消息，在没有分组的情况下，两者一起订阅主题 T，一条消息只能被 A 或 B 中的一个实例消费。这显然不符合我们的需求，无奈之下只能把 T 拆成 T1 和 T2，A 和 B 分别订阅 T1 和 T2，原来发一条消息必须变成发两次。支持分组的情况就不一样了，A 和 B 可以一起订阅主题 T，但使用不同的分组，例如组 1 和组 2，这样就能实现两个系统订阅同一个主题，两个系统都能消费所有消息。</p>\n<p>分区的概念同样也借鉴自 Kafka，RabbitMQ 原生并不支持。通常情况下，我们认为消息的投递是无序的，并不能保证先生产的消息一定先被消费。但这种需求是一直存在的，于是就有了分区这种解决方案——在同一分区中能保证消息是有序的，只要生产者指定向一个分区投递消息，那这个分区的消费者就一定能按消息的生产顺序消费。</p>\n<p>&nbsp;</p>\n</li>\n<li><p><strong>定义生产者与消费者</strong></p>\n<p>在 Spring Cloud Stream<span class=\"comment-number\">11</span> 中：消息的生产者和消费者可以对应到 Java 的函数类型 <code>Supplier</code> 和 <code>Consumer</code>；此外，还有一种特殊的情况，由一个消息触发，结果作为消息再投递出去，这对应了 <code>Function</code> 类型。只要在 Spring 上下文中声明对应类型的 Bean，Spring Cloud Stream 就能让它按照消息生产者和消费者的方式运作起来。</p>\n<p>仍旧以 BinaryTea 向 TeaMaker 发送制作订单通知为例。我们需要在 TeaMaker 一端监听通知，这在 RabbitMQ 的例子中是通过 <code>BinaryteaClient.processOrder()</code> 方法带上 <code>@RabbitListener</code> 注解来实现的。在 Spring Cloud Stream 下，我们不用注解来声明要监听的对象，直接定义一个 Bean，就像代码示例 16-12<span class=\"comment-number\">12</span> 那样。这段代码定义的 Bean 是 <code>Function&lt;OrderMessage, OrderMessage&gt;</code> 类型的，消费 <code>OrderMessage</code>，产生一个 <code>OrderMessage</code> 的消息再投递出去。</p>\n<blockquote>\n<p><strong>代码示例 16-12</strong>　消息监听后再生产的逻辑</p>\n</blockquote>\n<pre class=\"code-rows\"><code>@SpringBootApplication\npublic class TeaMakerApplication {\n    @Bean\n    public Function&lt;OrderMessage, OrderMessage&gt; notifyOrderPaid(BinaryteaClient client) {\n        return message -&gt; client.processOrder(message);\n    }\n    // 省略其他代码\n}</code></pre>\n<p>之前的投递逻辑是写在 <code>BinaryteaClient.processOrder()</code> 方法里的，现在这个方法不需要再关心怎么投递了，因此简化成了代码示例 16-13 的样子。</p>\n<blockquote>\n<p><strong>代码示例 16-13</strong>　简化后的订单制作代码</p>\n</blockquote>\n<pre class=\"code-rows\"><code>@Component\n@Slf4j\npublic class BinaryteaClient {\n    @Autowired\n    private OrderService orderService;\n\n    public OrderMessage processOrder(OrderMessage message) {\n        Long id = message.getOrderId();\n        log.info(\"开始制作订单{}\", id);\n        ProcessResult result = orderService.make(id);\n        OrderMessage finished = OrderMessage.builder().orderId(id)\n            .teaMakerId(result.getTeaMakerId())\n            .state(\"FINISHED\").build();\n        log.info(\"订单{}制作完毕\", id);\n        return finished;\n    }\n}</code></pre>\n<p>上面的两段代码都没有指出消息从哪里来、到哪里去，Spring Cloud Stream 是通过约定的方式来实现输入、输出与消息队列或主题的绑定的。用 <code>spring.cloud.stream.bindings.&lt;标识符&gt;.destination</code> 来指定要绑定的目标，以代码示例 16-12 的定义为例，标识符可以是 <code>notifyOrderPaid-in-0</code>（“-”分隔的三部分分别是：<code>方法名</code>，其实是 Bean 的 ID；表示消费或生产的 <code>in</code> 或 <code>out</code>；函数的参数或返回位置，因为通常是单个参数或返回值，所以大部分情况下是 <code>0</code>）。具体配置如代码示例 16-14 所示。</p>\n<blockquote>\n<p><strong>代码示例 16-14</strong>　增加了 Spring Cloud Stream 配置的 YAML 文件片段</p>\n</blockquote>\n<pre class=\"code-rows\"><code>spring:\n  cloud:\n    stream:\n      bindings:\n        notifyOrderPaid-in-0:\n          destination: notify.order.paid\n          group: teamaker\n        notifyOrderPaid-out-0:\n          destination: notify.order.finished</code></pre>\n<p><code>notifyOrderPaid-in-0</code> 这个标识符不是特别容易理解，所以可以给它起个别名，就像下面这样，随后就能用 <code>input</code> 来代替它了。</p>\n<pre class=\"code-rows\"><code>spring.cloud.stream.function.bindings.notifyOrderPaid-in-0=input\nspring.cloud.stream.bindings.input.destination=notify.order.paid\nspring.cloud.stream.bindings.input.group=teamaker</code></pre>\n<p>从代码示例 16-14 中我们已经看到了 <code>notifyOrderPaid()</code> 生产的消息会被投递到 <code>notify.order.finished</code> 中，在 RabbitMQ 里这就是个 Exchange，而在 Kafka 里这代表了一个消息主题，BinaryTea 中就要有相应的监听代码。对于仅是消费消息的情况，可以直接定义一个 <code>Consumer</code> 类型的 Bean，如代码示例 16-15 所示。其中的 <code>TeaMakerClient.receiveFinishedOrder()</code> 方法和之前 RabbitMQ 的例子是完全一样的，只是去掉了方法上的 <code>@RabbitListener</code> 注解。</p>\n<blockquote>\n<p><strong>代码示例 16-15</strong>　<code>notify.order.finished</code> 的消费者定义</p>\n</blockquote>\n<pre class=\"code-rows\"><code>@SpringBootApplication\n@EnableCaching\n@EnableScheduling\npublic class BinaryTeaApplication implements WebMvcConfigurer {\n    // 省略其他代码\n    @Bean\n    public Consumer&lt;OrderMessage&gt; notifyFinishedOrder(TeaMakerClient client) {\n        return message -&gt; client.receiveFinishedOrder(message);\n    }\n}</code></pre>\n<p>对应的，还需要和上面一样定义消费者的绑定关系，让 <code>notifyOrderFinished</code> 消费 <code>notify.order.finished</code>，同时声明自己的分组是 <code>binarytea</code>：</p>\n<pre class=\"code-rows\"><code>spring.cloud.stream.bindings.notifyFinishedOrder-in-0.destination=notify.order.finished\nspring.cloud.stream.bindings.notifyFinishedOrder-in-0.group=binarytea</code></pre>\n<p>最后，再让我们来看看如何向 <code>notify.order.paid</code> 发消息，也就是 BinaryTea 在收到订单支付的请求后如何通知 TeaMaker。这是一个单纯的消息生产者，按照之前的说法似乎应该定义一个 <code>Supplier</code> 类型的 Bean，就像下面这样，每次从 <code>OrderRepository</code> 里查询 <code>PAID</code> 状态的订单，将它变为 <code>OrderMessage</code> 发出去。</p>\n<pre class=\"code-rows\"><code>@Bean\npublic Supplier&lt;OrderMessage&gt; notifyPaidOrders(OrderRepository orderRepository) {...}</code></pre>\n<p>然而一切并没有那么简单，一系列的问题接踵而至。例如，谁负责调用 <code>notifyPaidOrders()</code>？什么时候调用？<code>Supplier&lt;OrderMessage&gt;</code> 是每次只产生一条消息吗？</p>\n<p>Spring Cloud Stream 内部有一个轮询机制，每隔 1 秒会调用 <code>Supplier</code> 的 <code>get()</code> 方法来获取要发送的消息内容。轮询相关的配置都在 <code>DefaultPollerProperties</code> 类里，用的是 <code>spring.cloud.stream.poller</code> 前缀，例如 <code>spring.cloud.stream.poller.fixed-delay=10000</code> 可以把调用间隔调整为 10 秒。</p>\n<p>如果一个时间段里只能生产一个通知，未免也太低效了。在 11.4 节里我们学习过 Project Reactor，其中 <code>Mono</code> 代表单个对象，<code>Flux</code> 代表多个对象。Spring Cloud Stream 同样支持 Reactor 模式，将方法的返回值类型调整为 <code>Supplier&lt;Flux&lt;OrderMessage&gt;&gt;</code> 就能返回多个消息了。伴随着编程模型的变化，框架的逻辑也有些不同，<code>Supplier&lt;Flux&lt;OrderMessage&gt;&gt;</code> 返回的是一个 <code>OrderMessage</code> 的流，框架认为调用一次 <code>notifyPaidOrders()</code> 就能拿到源源不断的流，所以如果在方法里是通过查询数据库的方式获取当前状态为已支付的订单，可能并不能满足要求。于是又有了 <code>@PollableBean</code> 注解，用它来代替 <code>@Bean</code>，告诉 Spring Cloud Stream，这个方法还是得轮询。<code>@PollableBean</code> 的 <code>splittable</code> 属性表示方法的结果是否要被拆分成多个消息，默认为 <code>true</code>。所以 <code>notifyPaidOrders()</code> 方法最后可能是像代码示例 16-16 这样的。</p>\n<blockquote>\n<p><strong>代码示例 16-16</strong>　<code>notify.order.paid</code> 消息的生产者</p>\n</blockquote>\n<pre class=\"code-rows\"><code>@PollableBean\npublic Supplier&lt;Flux&lt;OrderMessage&gt;&gt; notifyPaidOrders(OrderRepository orderRepository) {\n    return () -&gt; Flux.fromStream(orderRepository.findByStatusOrderById(OrderStatus.PAID)\n        .stream().map(o -&gt; {\n            o.setStatus(OrderStatus.MAKING);\n            orderRepository.save(o);\n        return OrderMessage.builder().orderId(o.getId()).build();\n    }));\n}</code></pre>\n<p>为了让 Spring Cloud Stream 能正确定时调用这个方法，并将输出的对象投递出去，还需要进行如下的配置。<code>spring.cloud.stream.function.definition</code> 将告诉 Spring Cloud Stream 哪些函数要被处理为绑定关系，用分号分隔：</p>\n<pre class=\"code-rows\"><code>spring.cloud.stream.function.definition=notifyPaidOrders;notifyFinishedOrder\nspring.cloud.stream.bindings.notifyPaidOrders-out-0.destination=notify.order.paid</code></pre>\n<p>上面这一连串的操作虽然符合函数设计的标准，但总觉得理解起来不太顺畅，Spring Cloud Stream 还提供了一种更“传统”的方式。通过 <code>StreamBridge</code> 可以向任意目标投递消息，<code>StreamBridge.send()</code> 可以传入绑定的标识符，或者直接传入目标，像代码示例 16-17 那样，我们就直接传入了 <code>notify.order.paid</code>。<code>TeaMakerClient.notifyPaidOrder()</code> 的触发则沿用之前的代码示例 16-8。</p>\n<blockquote>\n<p><strong>代码示例 16-17</strong>　通过 <code>StreamBridge</code> 来生产消息</p>\n</blockquote>\n<pre class=\"code-rows\"><code>@Component\n@Slf4j\npublic class TeaMakerClient {\n    @Autowired\n    private StreamBridge streamBridge;\n\n    public void notifyPaidOrder(Long id) {\n        log.info(\"将消息发送给TeaMaker，通知订单{}\", id);\n        streamBridge.send(\"notify.order.paid\",\n        OrderMessage.builder().orderId(id).build());\n    }\n    // 省略其他代码\n}</code></pre>\n<p>如果不希望把主题写死在代码里，也可以把绑定关系挪到配置中，把上面的代码调整为下面这样：</p>\n<pre class=\"code-rows\"><code>streamBridge.send(\"notifyPaidOrder-out-0\", OrderMessage.builder().orderId(id).build());</code></pre>\n<p><code>notifyPaidOrder-out-0</code> 的形式看起来是不是特别眼熟，我们虽然没有在代码中创建 <code>notifyPaidOrder</code> 这个生产者 Bean，但可以用 <code>spring.cloud.stream.source</code> 配置告诉 Spring Cloud Stream<span class=\"comment-number\">13</span>，这个名字代表了一个绑定关系：</p>\n<pre class=\"code-rows\"><code>spring.cloud.stream.source=notifyPaidOrder\nspring.cloud.stream.bindings.notifyPaidOrder-out-0.destination=notify.order.paid</code></pre>\n<p>相信大家也都注意到了，这里我们生产和消费的消息都是 <code>OrderMessage</code> 类型的，那在整个过程中一定有类型转换的机制将对象转换为可以投递的类型。完成这个转换的同样是 <code>MessageConverter</code>，<code>ContentTypeConfiguration</code> 配置类会创建一个包含了 Spring 上下文中所有 <code>MessageConverter</code> 的 <code>CompositeMessageConverter</code>。<code>BinderFactoryAutoConfiguration</code> 在构造 <code>MessageHandlerMethodFactory</code> 时会注入之前创建的 <code>CompositeMessageConverter</code>。</p>\n<p>消息的类型是由 <code>contentType</code> 来决定的，默认的类型是 <code>application/json</code>，<code>Message</code> 头里的 <code>contentType</code> 会将这个信息传递下去。每个生产者和消费者都可以单独设置自己的消息类型，就像下面这样：</p>\n<pre class=\"code-rows\"><code>spring.cloud.stream.bindings.notifyPaidOrder-out-0.content-type=application/json</code></pre>\n<p>&nbsp;</p>\n</li>\n<li><p><strong>Kafka 相关配置</strong></p>\n<p>到目前为止，我们都还没有提到 Kafka，那是因为在 Spring Cloud Stream 的抽象下，是 Kafka 还是 RabbitMQ 在代码层面几乎就没有差别。我们要做的就只有两件事，首先，引入 <code>spring-cloud-starter-stream-kafka</code> 的依赖：</p>\n<pre class=\"code-rows\"><code>&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-cloud-starter-stream-kafka&lt;/artifactId&gt;\n&lt;/dependency&gt;</code></pre>\n<p>然后，在 <code>application.properties</code> 中设置 Kafka 的信息，例如，下面这段配置用来设置 Kafka Bootstrap 服务器列表，其中用逗号分隔多个地址（两种方式可以任选其一）。</p>\n<pre class=\"code-rows\"><code># Spring Kafka配置方式\nspring.kafka.bootstrap-servers=localhost:9092\n# Spring Cloud Stream Kafka配置方式\nspring.cloud.stream.kafka.binder.brokers=localhost:9092</code></pre>\n<p>与 Kafka Binder 相关的配置，都用 <code>spring.cloud.stream.kafka.binder</code> 这个前缀，对应的配置类是 <code>KafkaBinderConfigurationProperties</code>，常见的配置项见表 16-5。</p>\n<p><strong>表 16-5　Spring Cloud Stream Kafka 中的常用配置</strong></p>\n<table class=\"table table-bordered table-striped table-condensed\" width=\"90%\" border=\"1\"><tr><th>配置项</th><th>默认值</th><th>说明</th></tr><tr><td><code>spring.cloud.stream.kafka.binder.brokers</code></td><td><code>localhost</code></td><td>逗号分隔的 Bootstrap 服务器列表</td></tr><tr><td><code>spring.cloud.stream.kafka.binder.default-broker-port</code></td><td><code>9092</code></td><td>默认的 Bootstrap 服务器端口</td></tr><tr><td><code>spring.cloud.stream.kafka.binder.configuration</code></td><td></td><td>同时适用于生产者和消费者的 KV 配置项</td></tr><tr><td><code>spring.cloud.stream.kafka.binder.health-timeout</code></td><td><code>60</code></td><td>分区健康检查的超时时间，单位是秒</td></tr><tr><td><code>spring.cloud.stream.kafka.binder.required-acks</code></td><td><code>1</code></td><td>对于 Broker 所要求的应答数</td></tr><tr><td><code>spring.cloud.stream.kafka.binder.auto-create-topics</code></td><td><code>true</code></td><td>是否自动创建主题</td></tr><tr><td><code>spring.cloud.stream.kafka.binder.replication-factor</code></td><td><code>-1</code></td><td>自动创建主题的复制因子，<code>-1</code> 会使用 Broker 配置的 <code>default.replication.factor</code>，Kafka 2.4 之前的版本至少要是 <code>1</code></td></tr></table>\n\n<p>其他与具体生产者和消费者有关的配置，可以有针对性地配置在绑定关系里，前缀是 <code>spring.cloud.stream.kafka</code>，格式为 <code>spring.cloud.stream.kafka.&lt;标识符&gt;.&lt;配置项&gt;</code>，其中默认配置的标识符用 <code>default</code>，配置项对应的属性类是 <code>KafkaBindingProperties</code>，其中又分成了 <code>producer</code> 生产者对应的 <code>KafkaProducerProperties</code> 和 <code>consumer</code> 消费者对应的 <code>KafkaConsumerProperties</code>，具体配置项形如 <code>producer.xxx</code> 或 <code>consumer.xxx</code>，例如，<code>spring.cloud.stream.kafka.notifyFinishedOrder-in-0.consumer.auto-rebalance-enabled=true</code>。关于各种配置，在官方文档中有较为详细的说明，此处就不再展开了。</p>\n<blockquote>\n<p><strong>茶歇时间：用 Docker Compose 在本地启动一套 Kafka</strong></p>\n<p>本书之前的章节中，在需要某些基础设施时，基本都是使用 <code>docker pull</code> 命令来拉取 Docker 镜像，然后用一句 <code>docker run</code> 命令来运行。但并非所有设施的本地运行都能如此简单，它们可能需要一些依赖，这里的 Kafka 就是一个例子。</p>\n<p>正常情况下，运行 Kafka 需要先部署一个 Zookeeper（单机测试可以简化为单节点的 Zookeeper），然后再启动一个 Kafka 的 Broker，让它连上之前启动的 Zookeeper。用几句命令来运行当然可以，但其实 Docker 为我们提供了容器编排的能力，也就是 Docker Compose 工具，具体来说就是 <code>docker-compose</code> 命令。</p>\n<p>在运行命令前，我们先要准备一个 <code>docker-compose.yml</code> 文件，以便告诉 Docker Compose 如何按照要求编排容器，单节点 Kafka 的 <code>docker-compose.yml</code> 大概会是这样的：</p>\n<pre class=\"code-rows\"><code>---\nversion: '2'\nservices:\n    zookeeper:\n       image: confluentinc/cp-zookeeper:latest\n       environment:\n         ZOOKEEPER_CLIENT_PORT: 2181\n\n    kafka:\n       image: confluentinc/cp-kafka:latest\n       depends_on:\n      - zookeeper\n    ports:\n      - 9092:9092\n    environment:\n      KAFKA_BROKER_ID: 1\n      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181\n      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092\n      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT\n      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT\n      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1</code></pre>\n<p>解释一下这个文件。<code>services</code> 是要启动的服务（或者说容器），<code>zookeeper</code> 和 <code>kafka</code> 是服务的名称。<code>zookeeper</code> 这一段是描述 Zookeeper 服务的配置，用的镜像是 <code>confluentinc/cp-zookeeper:latest</code>，通过环境变量设置了 Zookeeper 的监听端口 <code>2181</code>。<code>kafka</code> 这一段是 Kafka 的配置，镜像是 <code>confluentinc/cp-kafka:latest</code>，这个服务依赖上面的 <code>zookeeper</code> 服务，通过 <code>ports</code> 把容器的 <code>9092</code> 端口绑定到宿主机的 <code>9092</code> 端口，这样就能在容器外通过 <code>9092</code> 端口访问 Kafka 了，最后再添加一些环境变量，告诉 Kafka 怎么连接 Zookeeper 以及一些其他配置。具体能用哪些环境变量，有些什么作用，可以查看镜像的文档。</p>\n<p>准备好 <code>docker-compose.yml</code> 文件后，在文件同级目录里运行下面的命令就能在本地拉起一个单机 Kafka 实例了：</p>\n<pre class=\"code-rows\"><code>▸ docker-compose up -d</code></pre>\n<p>在复杂的服务场景下，用 Docker Compose 可以简化环境的启动，降低维护成本，总之这是个有用的工具。</p>\n</blockquote>\n</li>\n</ol>\n\n\n\n<h2 id=\"nav_point_249\">16.3　服务链路追踪</h2>\n<p>经过了一系列的升级改造，我们的二进制奶茶店早已不是当初那个简单的“小系统”了，不仅由多个不同的模块组成，模块间还运用了多种不同的通信方式，再加上可集群化部署的服务……这还只是我们在书中做的一个示例，真实世界中系统的复杂度就更可见一斑了。为了让我们能更清楚地理解系统具体是怎么运作的，一个请求是怎么被处理的，传统人工分析的方法在大规模的复杂环境下可能就不再适用了，这时就需要通过技术手段进行一定的分析，链路追踪就是其中的一种常用技术。</p>\n<h3 id=\"nav_point_250\">16.3.1　链路追踪概述</h3>\n<p>提到链路追踪，不得不提的就是 Google Dapper，这是 Google 内部使用的一套分布式追踪系统，它可以称得上是现在服务链路追踪领域的“鼻祖”。链路追踪的概念未必是 Google 提出的，但 Google Dapper 的那篇经典论文“Dapper, a Large-Scale Distributed Systems Tracing Infrastructure”将它的设计思路与实践传递给了大家。后续出现的很多监控系统都深受这篇论文的影响，比方说 OpenZipkin 和 Jaeger。</p>\n<p>图 16-5<span class=\"comment-number\">14</span> 是 Dapper 论文中对一个由用户（user）发起的请求 X（RequestX）的描述，这是一个复杂分布式系统中的常见请求链路，处理过程从前端（Frontend）经过中间层（Middle Tier）到达后端（Backend），一共经过了 5 个系统，系统间是 RPC 调用。</p>\n\n<p class=\"pic\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100008/image00802.jpeg\" alt=\"{%}\" /></p>\n<p class=\"ebook-image-title\"><strong>图 16-5　请求 X 的处理链路</strong></p>\n<p>为了描述这个请求链路，需要为它添加一个全局的标识符，也就是 Trace ID，它会贯穿整个请求的处理过程，随着调用被一路传递下去。拥有同样的 Trace ID 意味着都是同一个业务请求，但又该怎么表示各步骤之间的关系呢？从图 16-5 可以看出这是一个树型结构，请求链路中的每个系统都是一个节点，而请求和响应则是边，这样一来问题就简化为如何来表述这棵树。如图 16-6 所示，我们可以用 Span 来表述请求的每一个步骤，每个 Span 都有自己的 ID，还有它的父 Span ID。前端系统 Frontend 刚收到请求时，创建第一个 Span，它还没有父 Span，自己的 ID 是 1，此时还会生成一个贯穿始终的 Trace ID；随后往下发起了两个调用，这时会创建两个新的 Span，父 Span 的 ID 是 1，自己的 ID 分别是 2 和 3，Trace ID 也会传递下来，再往后的调用情况也以此类推。</p>\n<p class=\"pic\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100008/image00803.jpeg\" alt=\"{%}\" /></p>\n<p class=\"ebook-image-title\"><strong>图 16-6　链路中各节点的关系</strong></p>\n<p>除了两个 ID，在 Span 里还需要记录下不少操作的时间信息，表 16-6 中就罗列了具体的细节。</p>\n<p><strong>表 16-6　Span 中的一些具体的时间信息</strong></p>\n<table width=\"90%\" border=\"1\">\n<thead>\n<tr>\n<th><p>步骤</p></th>\n<th><p>简写</p></th>\n<th><p>说明</p></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><p>Client Send</p></td>\n<td><p>cs</p></td>\n<td><p>客户端向服务端发起请求</p></td>\n</tr>\n<tr>\n<td><p>Server Recv</p></td>\n<td><p>sr</p></td>\n<td><p>服务端接收到了客户端的请求</p></td>\n</tr>\n<tr>\n<td><p>Server Send</p></td>\n<td><p>ss</p></td>\n<td><p>服务端向客户端发送应答</p></td>\n</tr>\n<tr>\n<td><p>Client Recv</p></td>\n<td><p>cr</p></td>\n<td><p>客户端收到了服务端返回的应答</p></td>\n</tr>\n</tbody>\n</table>\n<p>Google 希望 Dapper 能够无处不在，持续不断地监控系统的每个角落，为此提出了三个具体的目标。</p>\n<ul>\n<li><strong>低消耗</strong>（low overhead），被监控系统引入的开销要小，不能有明显的性能损耗，在生产环境中通常还会做采样，并不会详细地记录下每个请求。</li>\n<li><strong>应用级透明</strong>（application-level transparency），如果链路追踪需要侵入业务代码，那接入的成本无疑是巨大的，而且应用开发者也未必会积极配合，能不用业务系统开发者介入是非常重要的。</li>\n<li><strong>大范围部署</strong>（ubiquitous deployment），在 Google 或类似的系统规模下，整套解决方案必须完全可控。</li>\n</ul>\n<p>现在，我们已经不用羡慕 Google 的这套 Dapper 系统了，因为基于论文已经诞生了好多不同的开源系统，而且 Spring Cloud 还提供了一套抽象。在接下来，我们将看到如何使用 Spring Cloud Sleuth 和 OpenZipkin 来实现无侵入的服务链路追踪功能。</p>\n<h3 id=\"nav_point_251\">16.3.2　基于 Spring Cloud Sleuth 实现链路追踪</h3>\n<p>sleuth 一词的意思是侦探，顾名思义，Spring Cloud Sleuth 也想成为一名分布式系统中的“侦探”。它为我们的工程提供了一套分布式服务链路追踪的 API，底层集成了 OpenZipkin Brave，支持各种与 OpenZipkin 兼容的分布式链路追踪系统。即使我们不打算将数据发送到 OpenZipkin，自动添加到日志里的 Trace ID 和 Span ID 信息，也足够我们分析整条请求链路了。Spring Cloud Sleuth 为各种常用的组件提供了可自动配置的探针，只需添加依赖即可完成接入。</p>\n<ol>\n<li><p><strong>日志中的链路信息</strong></p>\n<p>因此我们要做的第一件事，就是引入 Sleuth 的依赖，在 pom.xml 中添加如下内容 <span class=\"comment-number\">15</span>：</p>\n<pre class=\"code-rows\"><code>&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt;\n&lt;/dependency&gt;</code></pre>\n<p>在 BinaryTea 和 TeaMaker 工程里添加完依赖后，自动配置就已经完成了绝大部分的配置，这时运行 Customer 工程发起请求后，就可以看到 BinaryTea 的日志发生了一些变化，在下面的日志里我们可以发现多了 <code>[binarytea,ae0175cc49602df5,e9bb3788c191ad61]</code>，它们分别是应用名（也就是 <code>spring.application.name</code>）、Trace ID 和 Span ID：</p>\n<pre class=\"code-rows\"><code>2021-11-21 14:30:06.824 INFO [binarytea,ae0175cc49602df5,e9bb3788c191ad61] 81962 --- [io-8080-exec-10]\nl.s.b.integration.TeaMakerClient : 发送消息给TeaMaker，通知订单2\n2021-11-21 14:30:06.841 INFO [binarytea,ae0175cc49602df5,e9bb3788c191ad61] 81962 --- [io-8080-exec-10]\nl.s.b.support.log.LogHandlerInterceptor : 192.168.3.86,PUT,/order,OrderController.modifyOrderStatus(),\n200,-,LiLei,31ms</code></pre>\n<p>根据 <code>ae0175cc49602df5</code> 这个 Trace ID，到 TeaMaker 的日志中就能找到对应的日志，它们拥有同样的 Trace ID，但 Span ID 有所不同。</p>\n<pre class=\"code-rows\"><code>2021-11-21 14:30:06.947 INFO [tea-maker,ae0175cc49602df5,b73f00db446a541c] 81947 --- [ntContainer#0-1]\nl.s.t.integration.BinaryteaClient : 开始制作订单2\n2021-11-21 14:30:07.984 INFO [tea-maker,ae0175cc49602df5,b73f00db446a541c] 81947 --- [ntContainer#0-1]\nl.s.t.integration.BinaryteaClient : 订单2制作完毕</code></pre>\n<p>日志内容的变化其实比较容易实现，Spring Cloud Sleuth 只是将这些信息放到了 SLF4J 的 MDC 中，这是一个保存上下文信息的地方，底层用的是 <code>ThreadLocal</code>，在日志的 Pattern 中再增加这些信息的输出即可。大概的 Pattern 部分如下所示，框架默认会调整成这样的。</p>\n<pre class=\"code-rows\"><code>%5p [$},%X,%X]</code></pre>\n<p>至于 Spring Cloud Sleuth 是如何将 Trace 和 Span 的信息“自动”传递给下游的，这就只能归功于 Spring 团队为多种常用的基础组件开发了大量的探针，并通过自动配置（根据 CLASSPATH 里各种类的信息）做了相应的配置。这些自动配置都在 <code>org.springframework.cloud.sleuth.autoconfig.instrument</code> 里。在上面的例子中生效的就是 <code>TraceSpringMessagingAutoConfiguration</code>，它为 Spring Message 提供了向消息头里设置信息的 <code>Propagator.Setter&lt;MessageHeaderAccessor&gt;</code>，还有从消息头里取出信息的 <code>Propagator.Getter&lt;MessageHeaderAccessor&gt;</code>。而像 <code>RestTemplate</code>、OpenFeign、定时任务、异步任务、断路器等组件也都有对应的探针。正是有了这些繁琐的基础工作的铺垫，才让开发者轻松了下来。</p>\n<p>&nbsp;</p>\n</li>\n<li><p><strong>将信息发送到 OpenZipkin</strong></p>\n<p>如果只有日志，所有的信息都要到 ELK 里去找，那在实际操作上着实不太方便，为了追踪请求链路做深入的分析和治理，我们要有更强大的工具。OpenZipkin 是参考 Google Dapper 设计的一套分布式追踪系统，通过它可以收集并直观地展示分析后的链路信息，帮助我们更好地理解链路情况。</p>\n<p>Spring Cloud Sleuth 对 OpenZipkin 的支持非常到位，只需在 pom.xml 中引入下面的依赖 <span class=\"comment-number\">16</span>，稍加配置即可以 HTTP 的方式向 Zipkin 发送信息。</p>\n<pre class=\"code-rows\"><code>&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-cloud-sleuth-zipkin&lt;/artifactId&gt;\n&lt;/dependency&gt;</code></pre>\n<p>默认情况下，Spring Cloud Sleuth 会向 <code>http://localhost:9411/</code> 发送信息。关于 Zipkin 服务端的信息可以通过表 16-7 中的配置来对框架的一些行为进行微调，<code>spring.zipkin.*</code> 的大部分配置都在 <code>ZipkinProperties</code> 配置类中。</p>\n<p><strong>表 16-7　Spring Cloud Sleuth 向 Zipkin 发送信息时的一些配置项</strong></p>\n<table class=\"table table-bordered table-striped table-condensed\" width=\"90%\" border=\"1\"><tr><th>配置项</th><th>默认值</th><th>说明</th></tr><tr><td><code>spring.zipkin.enabled</code></td><td><code>true</code></td><td>是否开启 Zipkin 支持</td></tr><tr><td><code>spring.zipkin.base-url</code></td><td><code>http://localhost:9411/</code></td><td>Zipkin 服务的 URL</td></tr><tr><td><code>spring.zipkin.api-path</code></td><td><code>v2/path2</code></td><td>Zipkin 的 API 路径</td></tr><tr><td><code>spring.zipkin.discovery-client-enabled</code></td><td><code>false</code></td><td><code>base-url</code> 是否包含服务发现的服务名</td></tr><tr><td><code>spring.zipkin.message-timeout</code></td><td><code>1</code></td><td>Span 批量发送的等待时间，单位是秒</td></tr><tr><td><code>spring.zipkin.compression.enabled</code></td><td><code>false</code></td><td>是否开启压缩功能</td></tr><tr><td><code>spring.sleuth.sampler.probability</code></td><td></td><td>采样比例，1.0 就是 100%，最小精度为 1%</td></tr><tr><td><code>spring.sleuth.sampler.rate</code></td><td><code>10</code></td><td>每秒速率，在大流量情况下按比例采样后样本很多，可以控制发送的上限</td></tr></table>\n\n<p>在 BinaryTea、TeaMaker 和 Customer 工程中，简单地引入前面提到的依赖。为了演示方便，在 <code>application.properties</code> 中将采样比例调整为 100%，也就是 <code>1.0</code>，在生产中不建议用这个比例。大概就是下面这样的（<code>application.yml</code> 的配置类似）：</p>\n<pre class=\"code-rows\"><code>spring.sleuth.sampler.probability=1.0</code></pre>\n<p>随后，用下面的命令在本地启动一个 OpenZipkin 服务，它会监听 9411 端口，并将所有数据存储在内存里。</p>\n<pre class=\"code-rows\"><code>▸ docker pull openzipkin/zipkin\n▸ docker run --name zipkin -d -p 9411:9411 openzipkin/zipkin</code></pre>\n<p>程序运行后，就能在 http://localhost:9411/zipkin 中找到之前各种请求的链路信息以及依赖关系了。链路信息大致会是图 16-7 这样的。</p>\n<p class=\"p-img\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100008/image00804.jpeg\" alt=\"{%}\" /></p>\n<p class=\"ebook-image-title\"><strong>图 16-7　<code>PUT</code> 请求的链路</strong></p>\n<p>除了 HTTP，Zipkin 还可以通过消息的方式来上报链路追踪信息，支持的消息中间件有 Kafka、ActiveMQ 和 RabbitMQ。发送方式可以通过 <code>spring.zipkin.sender.type</code> 参数进行调整，默认是 <code>web</code>，还可以选择 <code>activemq</code>、<code>rabbit</code> 和 <code>kafka</code>，后三个选项需要在 CLASSPATH 中有对应的依赖。例如，可以在 BinaryTea 的 <code>application.properties</code> 中增加如下两个配置，通过 RabbitMQ 来发送信息，使用的队列是 <code>zipkin</code>。</p>\n<pre class=\"code-rows\"><code>spring.zipkin.sender.type=rabbit\nspring.zipkin.rabbitmq.queue=zipkin</code></pre>\n<p>随后，重新调整一下 Zipkin Docker 容器 <span class=\"comment-number\">17</span> 的启动命令，通过环境变量 <code>RABBIT_ADDRESSES</code>、<code>RABBIT_USER</code> 和 <code>RABBIT_PASSWORD</code> 告诉 Zipkin 如何连接 RabbitMQ，<code>--link rabbitmq</code> 用来链接之前已经启动的 RabbitMQ 容器，使用哪个队列来接收消息由 <code>RABBIT_QUEUE</code> 环境变量来控制，默认就是 <code>zipkin</code>。</p>\n<pre class=\"code-rows\"><code>docker run --name rabbit-zipkin -d -p 9411:9411 --link rabbitmq \\\n    -e RABBIT_ADDRESSES=rabbitmq:5672 -e RABBIT_USER=spring -e RABBIT_PASSWORD=spring \\\n    openzipkin/zipkin</code></pre>\n<p>&nbsp;</p>\n</li>\n<li><p><strong>增加附加信息</strong></p>\n<p>大部分情况下，Spring Cloud Sleuth 自动拦截并生成的 Span 信息就已经够用了。但如果你希望对一些具体的步骤再做细分，更精确地掌握执行的情况，也可以自己创建 Span。此外，除了默认的信息，还可以在 Span 中添加标签（Tag），附带一些额外的信息。Spring Cloud Sleuth 提供了 <code>@NewSpan</code>、<code>@ContinueSpan</code> 和 <code>@SpanTag</code> 注解，可以方便地实现上述功能，相比直接用底层的 Zipkin Brave 要容易不少。链路分析多数是用在非功能性需求中的，下面让我们用二进制奶茶店请求链路追踪的例子来做个说明。</p>\n<blockquote>\n<p><strong>需求描述</strong>　链路追踪的信息有比较清楚的调用关系，但缺少一些业务属性，尤其是没有订单号会导致研发排查问题不方便。最好能在链路的信息中添加明确的订单号，方便分析具体订单的情况。</p>\n</blockquote>\n<p><code>@NewSpan</code> 顾名思义是用来创建新 Span 的，我们稍微修改一下 BinaryTea 的 <code>OrderService.modifyOrderStatus()</code> 方法，具体如代码示例 16-18 所示。<code>@NewSpan</code> 注解创建了一个名为 <code>modify-order-status</code> 的新 Span，在这个 Span 中添加了一个 <code>order-id</code> 标签，它的值是方法的 <code>id</code> 参数。</p>\n<blockquote>\n<p><strong>代码示例 16-18</strong>　增加了 <code>@NewSpan</code> 和 <code>@SpanTag</code> 注解的 <code>modifyOrderStatus()</code> 方法</p>\n</blockquote>\n<pre class=\"code-rows\"><code>@Service\n@Transactional\n@Slf4j\npublic class OrderService {\n    @NewSpan(\"modify-order-status\")\n    public Order modifyOrderStatus(@SpanTag(\"order-id\") Long id, OrderStatus status) {...}\n    // 省略其他代码\n}</code></pre>\n<p>在 TeaMaker 中，我们演示一下 <code>@ContinueSpan</code> 的用法，为 <code>BinaryteaClient.processOrder()</code> 加上注解，具体如代码示例 16-19 所示。<code>@ContinueSpan</code> 并不会新建 Span，而是继续当前的 Span。<code>@SpanTag</code> 也可以通过 <code>expression</code> 传入 SpEL 表达式，出于安全原因，此处的表达式不能调用对象的方法，只能做些简单的运算符操作。为了标签中的信息更直观，可以为 <code>OrderMessage</code> 加上 Lombok 的 <code>@ToString</code> 注解，优化一下 <code>toString()</code> 方法的输出，避免直接变为散列值。</p>\n<blockquote>\n<p><strong>代码示例 16-19</strong>　增加了 <code>@ContinueSpan</code> 和 <code>@SpanTag</code> 的 <code>processOrder()</code> 方法</p>\n</blockquote>\n<pre class=\"code-rows\"><code>@Component\n@Slf4j\npublic class BinaryteaClient {\n    @RabbitListener(queues = \"notify.order.paid\")\n    @ContinueSpan\n    public void processOrder(@SpanTag(\"msg\") OrderMessage message) {...}\n    // 省略其他代码\n}</code></pre>\n<p>做了这样的一些调整后，我们在 OpenZipkin 中看到的 <code>PUT</code> 操作效果大概会如图 16-8 所示。可以看到，相比图 16-7，这里多了一个 <code>modify-order-status</code>Span，TeaMaker 的 <code>on-message</code>Span 里多了 <code>msg</code> 标签。</p>\n<p class=\"p-img\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100008/image00805.jpeg\" alt=\"{%}\" /></p>\n<p class=\"ebook-image-title\"><strong>图 16-8　带有自定义 Span 和标签的链路信息</strong></p>\n<blockquote>\n<p><strong>茶歇时间：OpenTelemetry 概述</strong></p>\n<p>在云原生环境下，可观测性的问题变得尤为突出，毕竟多语言与分布式是新的常态，想要快速定位并解决可用性和性能的问题，就要有一套完整的技术方案。但凡是个常见的需求，就一定会有很多人尝试给出解决方案，既有开源的方案也有商业的方案，但不同方案之间的数据缺乏可移植性，不同设施之间的联动也有一定的壁垒。</p>\n<p>OpenTelemetry 是 CNCF 下的一个可观测性项目，提供了一套标准化且厂商独立的遥测（telemetry）数据解决方案。这里的遥测数据主要是指链路追踪、度量和日志。OpenTelemetry 只是套规范、API 和 SDK，本身并不提供类似 Jaeger、Prometheus、OpenZipkin 这样的后端服务。OpenTelemetry 规定了数据模型，以及如何采集、处理并导出数据，可以向前面提到的后端服务导出自己的遥测数据。</p>\n<p>目前，OpenTelemetry 中的链路追踪相比度量和日志的成熟度要高一些，已经发布了 1.0 规范，整套规范与我们在 16.3 节中介绍的内容相近，本质上也是基于 Dapper 论文的那套方法。各大厂商也在跟进 OpenTelemetry，尤其是提供自己的 Exporter，以便能够让 OpenTelemetry 的数据无缝地导出到自己的服务中，例如阿里云的 SLS。</p>\n</blockquote>\n</li>\n</ol>\n\n\n\n","neighbors":{"left":{"article_title":"第 16 章 服务集成(1)","id":740893},"right":{"article_title":"第 16 章 服务集成(3)","id":740895}},"comments":[]}