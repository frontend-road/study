{"id":200157,"title":"47 | MongoDB + Spark实时大数据","content":"<p><strong>课件和Demo地址</strong><br>\n<a href=\"https://gitee.com/geektime-geekbang/geektime-mongodb-course\">https://gitee.com/geektime-geekbang/geektime-mongodb-course</a></p>","comments":[{"had_liked":false,"id":179768,"user_name":"rayallen335","can_delete":false,"product_type":"c3","uid":1045724,"ip_address":"","ucode":"C39AD40AEAA60C","user_header":"https://static001.geekbang.org/account/avatar/00/0f/f4/dc/2bd409a5.jpg","comment_is_top":false,"comment_ctime":1582094501,"is_pvip":false,"replies":[{"id":70074,"content":"HBase 和 MongoDB在这种和Spark场景下是比较类似的，可以互换。如果数据仅仅是用来做spark 分析计算，HBase可能还有一些性能上的优势。\n\nMongoDB的好处是，你很可能已经用MongoDB在存储业务产生的数据，当你需要再做分析的时候不需要再把数据导到大数据平台（HDFS&#47;Hbase）一份。你可以直接加上spark计算框架就可以完成分析了。节省存储，节省人力。\n\n","user_name":"作者回复","user_name_real":"远航的TJ 唐建法","uid":1260017,"ctime":1582343898,"ip_address":"","comment_id":179768,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"老师您好，请问一下Spark+MongoDB比Spark+HBase的架构有哪些优点","like_count":8,"discussions":[{"author":{"id":1260017,"avatar":"https://static001.geekbang.org/account/avatar/00/13/39/f1/6d18a4d1.jpg","nickname":"远航的TJ 唐建法","note":"","ucode":"0719807390250A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":484388,"discussion_content":"HBase 和 MongoDB在这种和Spark场景下是比较类似的，可以互换。如果数据仅仅是用来做spark 分析计算，HBase可能还有一些性能上的优势。\n\nMongoDB的好处是，你很可能已经用MongoDB在存储业务产生的数据，当你需要再做分析的时候不需要再把数据导到大数据平台（HDFS/Hbase）一份。你可以直接加上spark计算框架就可以完成分析了。节省存储，节省人力。\n\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1582343898,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1045724,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/f4/dc/2bd409a5.jpg","nickname":"rayallen335","note":"","ucode":"C39AD40AEAA60C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":220427,"discussion_content":"谢谢老师","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1585876693,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":179812,"user_name":"qbit","can_delete":false,"product_type":"c3","uid":1262927,"ip_address":"","ucode":"96C70A1E47B93D","user_header":"https://static001.geekbang.org/account/avatar/00/13/45/4f/f94caf47.jpg","comment_is_top":false,"comment_ctime":1582103851,"is_pvip":false,"replies":[{"id":70070,"content":"flink 是一个专门的流处理计算软件，关注对“现在产生的数据”。\nspark 除了能做流处理，更多的是批处理能力，对“现在和以前的数据”做回顾式计算和分析。\n\nflink 和 spark 的一个模块，spark stream更有可比性。\n\nflink的实时能力更强一些，颗粒度是一条数据。spark stream是基于微批，所以颗粒度粗一点。\n\n","user_name":"作者回复","user_name_real":"远航的TJ 唐建法","uid":1260017,"ctime":1582341463,"ip_address":"","comment_id":179812,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"老师能直观简要的说一下对 spark 和 flink 的感受吗？","like_count":3,"discussions":[{"author":{"id":1260017,"avatar":"https://static001.geekbang.org/account/avatar/00/13/39/f1/6d18a4d1.jpg","nickname":"远航的TJ 唐建法","note":"","ucode":"0719807390250A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":484410,"discussion_content":"flink 是一个专门的流处理计算软件，关注对“现在产生的数据”。\nspark 除了能做流处理，更多的是批处理能力，对“现在和以前的数据”做回顾式计算和分析。\n\nflink 和 spark 的一个模块，spark stream更有可比性。\n\nflink的实时能力更强一些，颗粒度是一条数据。spark stream是基于微批，所以颗粒度粗一点。\n\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1582341463,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1262927,"avatar":"https://static001.geekbang.org/account/avatar/00/13/45/4f/f94caf47.jpg","nickname":"qbit","note":"","ucode":"96C70A1E47B93D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":181979,"discussion_content":"好的，谢谢。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1582384893,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":199020,"user_name":"Robin.Ku","can_delete":false,"product_type":"c3","uid":1066180,"ip_address":"","ucode":"78E9211C5D76A6","user_header":"https://static001.geekbang.org/account/avatar/00/10/44/c4/10a95b2d.jpg","comment_is_top":false,"comment_ctime":1585476226,"is_pvip":false,"replies":[{"id":75816,"content":"在这个场景下是两者都是okay的，因为是批量计算完了存储结果的场景，然后只是用来读。\n\nES和mongo相比有一个比较关键的点就是实时更新能力。ES一般不建议做实时更新，因为索引更新耗时很长。所以如果你需要实时更新某些数据并且马上查询，ES会有索引不及时更新的情况导致数据不够一致。","user_name":"作者回复","user_name_real":"远航的TJ 唐建法","uid":1260017,"ctime":1586082332,"ip_address":"","comment_id":199020,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"唐老师你好，这节讲的课程提到的CASE：\n1、请问Spark + MongoDB 选型改成 Spark + Elasticsearch 架构如何？\n2、MongoDB 和 Elasticsearch 对比的主要应用场景和对比如何？","like_count":2,"discussions":[{"author":{"id":1260017,"avatar":"https://static001.geekbang.org/account/avatar/00/13/39/f1/6d18a4d1.jpg","nickname":"远航的TJ 唐建法","note":"","ucode":"0719807390250A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":489778,"discussion_content":"在这个场景下是两者都是okay的，因为是批量计算完了存储结果的场景，然后只是用来读。\n\nES和mongo相比有一个比较关键的点就是实时更新能力。ES一般不建议做实时更新，因为索引更新耗时很长。所以如果你需要实时更新某些数据并且马上查询，ES会有索引不及时更新的情况导致数据不够一致。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586082332,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":238050,"user_name":"楚翔style","can_delete":false,"product_type":"c3","uid":1174846,"ip_address":"","ucode":"E715F82C34A9AA","user_header":"https://static001.geekbang.org/account/avatar/00/11/ed/3e/c1725237.jpg","comment_is_top":false,"comment_ctime":1596036701,"is_pvip":false,"replies":[{"id":88156,"content":"是的，那个示例用的是local 模式。","user_name":"作者回复","user_name_real":"远航的TJ 唐建法","uid":1260017,"ctime":1596276735,"ip_address":"","comment_id":238050,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"spark－local模式吗？运价计算那个例子。  ","like_count":0,"discussions":[{"author":{"id":1260017,"avatar":"https://static001.geekbang.org/account/avatar/00/13/39/f1/6d18a4d1.jpg","nickname":"远航的TJ 唐建法","note":"","ucode":"0719807390250A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":502629,"discussion_content":"是的，那个示例用的是local 模式。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1596276735,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":370020,"user_name":"Geek_97446b","can_delete":false,"product_type":"c3","uid":3563327,"ip_address":"广东","ucode":"A5535FDAE72DB4","user_header":"","comment_is_top":false,"comment_ctime":1678266789,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"请问下，这样的 mongodb 集群有多少个节点，是什么样的一个集群模式？","like_count":0},{"had_liked":false,"id":262851,"user_name":"龙行天下","can_delete":false,"product_type":"c3","uid":1669292,"ip_address":"","ucode":"23551F422A02EF","user_header":"https://static001.geekbang.org/account/avatar/00/19/78/ac/a34a15fb.jpg","comment_is_top":false,"comment_ctime":1605858575,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"spark + mongodb 如果要像hdfs将大量的数据读过来，是否会更浪费时间，毕竟hdfs是将任务下沉到各个节点，处理完了收集上来，统一处理，而mongodb要么在mongo服务端就做过滤，如果需求需要将1GB左右数据读过来，那有何好办法","like_count":0}]}