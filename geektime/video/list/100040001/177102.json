{"id":177102,"title":"26 | 分片集群设计","content":"<p><strong>课件和Demo地址</strong><br>\n<a href=\"https://gitee.com/geektime-geekbang/geektime-mongodb-course\">https://gitee.com/geektime-geekbang/geektime-mongodb-course</a></p>","comments":[{"had_liked":false,"id":203747,"user_name":"lostsky","can_delete":false,"product_type":"c3","uid":1131326,"ip_address":"","ucode":"FD65474995FFD3","user_header":"https://static001.geekbang.org/account/avatar/00/11/43/3e/2724d823.jpg","comment_is_top":false,"comment_ctime":1586262228,"is_pvip":false,"replies":[{"id":77498,"content":"不会，因为根据user_id的值，你可以从config里面获得准确的shard#。只有少数几个（取决分片数）user_id 才需要跨分片。其他的都是指定分片","user_name":"作者回复","user_name_real":"远航的TJ 唐建法","uid":1260017,"ctime":1587097805,"ip_address":"","comment_id":203747,"utype":1}],"discussion_count":4,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"老师，请问email的例子里，user_id &amp; time做片键，就是说一个user_id下的邮件还是会因为time的不同落到不同分片上。\n如果只按user_id查询，就意味着查询请求会发向所有分片？","like_count":6,"discussions":[{"author":{"id":1260017,"avatar":"https://static001.geekbang.org/account/avatar/00/13/39/f1/6d18a4d1.jpg","nickname":"远航的TJ 唐建法","note":"","ucode":"0719807390250A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":490949,"discussion_content":"不会，因为根据user_id的值，你可以从config里面获得准确的shard#。只有少数几个（取决分片数）user_id 才需要跨分片。其他的都是指定分片","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587097805,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":2596556,"avatar":"https://static001.geekbang.org/account/avatar/00/27/9e/cc/1d57f923.jpg","nickname":"NotFoundMoneyException:¥0","note":"","ucode":"D454002955D09C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1260017,"avatar":"https://static001.geekbang.org/account/avatar/00/13/39/f1/6d18a4d1.jpg","nickname":"远航的TJ 唐建法","note":"","ucode":"0719807390250A","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":578481,"discussion_content":"老师的意思是不是这样：同一个user_id的数据会落到一个分片上，如果同一个user_id产生超级块，那么分裂出来的chunk就会拷贝到其他分片，并且在config中记录下来，这个user_id的数据会在多个分片上存在","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1656815399,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":490949,"ip_address":"","group_id":0},"score":578481,"extra":""}]},{"author":{"id":3008825,"avatar":"","nickname":"Geek_64ac91","note":"","ucode":"66E87F31364059","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":650573,"discussion_content":"这是不是再说 大概率的情况下 同一个 user 是在一块的，也不排除 同一个 user 在不同地方，只能说是 分片数越大  同一个 user 在不同地方的概率越大？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1725270179,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"山东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2034681,"avatar":"https://static001.geekbang.org/account/avatar/00/1f/0b/f9/253826a3.jpg","nickname":"覃SIR","note":"","ucode":"E99D4916C0FF63","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":596390,"discussion_content":"之前也在想这个问题；理解应该是同个userid不同time的数据，会分布到不同的chunk不同分片上；因为复合索引中userid在前面，所以根据userid查询的时候，也会知道这个userid下的数据在哪些分片上，然后到这些分片查询把结果汇总起来","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1670934514,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":246866,"user_name":"Mr.zhou","can_delete":false,"product_type":"c3","uid":1461488,"ip_address":"","ucode":"F7B2365D183788","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83ep0Cb1HGLBTD57I53ZLsIBnvN3YkJOTkibWyibPoCUM5cbnhqDicm1aKWTUFeI7SEd8REnibfZVWeM3BQ/132","comment_is_top":false,"comment_ctime":1599495143,"is_pvip":false,"replies":[{"id":91323,"content":"chunk的是以片键值的upper bound 和 lower bound范围决定的。如果user_id是片键，那么对于user_id:1000，在他的email数量达到一定程度，不断分块后最后的就是：\n \n   user_id  &gt;= 1000(包含1000）\n   user_id  &lt; 1001( 不包含）\n\n到了这一步，这一块里面只有他自己一个人的数据了。如果继续增长，你已经无法只用user_id这一个字段作为范围键来定义多余一个的chunk了。这时候就会早场超级块\n\n\n\n\n","user_name":"作者回复","user_name_real":"远航的TJ 唐建法","uid":1260017,"ctime":1600308982,"ip_address":"","comment_id":246866,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"email系统以user_id作为片键，为什么会造成超级快？难道chunk达到一定的大小后，不会分裂吗？不会生成新的chunk？","like_count":4,"discussions":[{"author":{"id":1260017,"avatar":"https://static001.geekbang.org/account/avatar/00/13/39/f1/6d18a4d1.jpg","nickname":"远航的TJ 唐建法","note":"","ucode":"0719807390250A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":505248,"discussion_content":"chunk的是以片键值的upper bound 和 lower bound范围决定的。如果user_id是片键，那么对于user_id:1000，在他的email数量达到一定程度，不断分块后最后的就是：\n \n   user_id  &amp;gt;= 1000(包含1000）\n   user_id  &amp;lt; 1001( 不包含）\n\n到了这一步，这一块里面只有他自己一个人的数据了。如果继续增长，你已经无法只用user_id这一个字段作为范围键来定义多余一个的chunk了。这时候就会早场超级块\n\n\n\n\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1600308982,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":237564,"user_name":"polk","can_delete":false,"product_type":"c3","uid":1165455,"ip_address":"","ucode":"1B6E948BA4DFAF","user_header":"https://static001.geekbang.org/account/avatar/00/11/c8/8f/e13a6552.jpg","comment_is_top":false,"comment_ctime":1595864537,"is_pvip":false,"replies":[{"id":88157,"content":"你的理解正确。如果同一个userid下面的行数很多的时候，使用time可以将数据分布到多个块上。","user_name":"作者回复","user_name_real":"远航的TJ 唐建法","uid":1260017,"ctime":1596276796,"ip_address":"","comment_id":237564,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"是否可以理解为，userId + time, 同一个userId都在同一个分片，time使其在同一个分片分散在不同的块上。","like_count":4,"discussions":[{"author":{"id":1260017,"avatar":"https://static001.geekbang.org/account/avatar/00/13/39/f1/6d18a4d1.jpg","nickname":"远航的TJ 唐建法","note":"","ucode":"0719807390250A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":502459,"discussion_content":"你的理解正确。如果同一个userid下面的行数很多的时候，使用time可以将数据分布到多个块上。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1596276796,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":173975,"user_name":"月迷津渡","can_delete":false,"product_type":"c3","uid":1264111,"ip_address":"","ucode":"2B18B2FE3DAC3B","user_header":"https://static001.geekbang.org/account/avatar/00/13/49/ef/02401473.jpg","comment_is_top":false,"comment_ctime":1579845265,"is_pvip":false,"replies":[{"id":67802,"content":"mongodb使用LRU算法对缓存数据进行管理。热数据和索引数据，他们本身的特性就决定了会经常被访问。你只要提供足够大小的缓存空间，他们自然就会被mongo留在缓存里，因为被经常访问缘故。\n\n应用程序不用自己维护缓存数据。","user_name":"作者回复","user_name_real":"远航的TJ 唐建法","uid":1260017,"ctime":1580254028,"ip_address":"","comment_id":173975,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"这里有个问题没理解，工作集大小是热数据加索引数据，隐含的意思就是索引数据和热数据都是全量在内存里的？如果是的话，索引数据是mongodb自己维护在内存的？热数据是自己应用程序维护在内存里的?","like_count":4,"discussions":[{"author":{"id":1260017,"avatar":"https://static001.geekbang.org/account/avatar/00/13/39/f1/6d18a4d1.jpg","nickname":"远航的TJ 唐建法","note":"","ucode":"0719807390250A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":482261,"discussion_content":"mongodb使用LRU算法对缓存数据进行管理。热数据和索引数据，他们本身的特性就决定了会经常被访问。你只要提供足够大小的缓存空间，他们自然就会被mongo留在缓存里，因为被经常访问缘故。\n\n应用程序不用自己维护缓存数据。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1580254028,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":225718,"user_name":"乖，摸摸头","can_delete":false,"product_type":"c3","uid":1611745,"ip_address":"","ucode":"BD92741A11D3CD","user_header":"https://static001.geekbang.org/account/avatar/00/18/97/e1/0f4d90ff.jpg","comment_is_top":false,"comment_ctime":1591838998,"is_pvip":false,"replies":[{"id":88234,"content":"开始的时候你都是写入到同一个chunk，只有到了一定的量以后，超过chunk的阈值，chunk 会拆分变成2个或者更多，然后chunk会迁移到另一个分片。这个时候你的写入就会分布了。","user_name":"作者回复","user_name_real":"远航的TJ 唐建法","uid":1260017,"ctime":1596358099,"ip_address":"","comment_id":225718,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"我的分片集群有 2个shard, 集合shard key 使用 _id:&quot;hashed&quot; ,写入数据能正常分布到2个shard 上去，当使用 shard key 使用{user_id:1,time:1} 时，数据始终分布在一个 分片上面，无论我怎么调整插入  user_id 和 time 的值，请教老师，这是为什么？","like_count":3,"discussions":[{"author":{"id":1260017,"avatar":"https://static001.geekbang.org/account/avatar/00/13/39/f1/6d18a4d1.jpg","nickname":"远航的TJ 唐建法","note":"","ucode":"0719807390250A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":497962,"discussion_content":"开始的时候你都是写入到同一个chunk，只有到了一定的量以后，超过chunk的阈值，chunk 会拆分变成2个或者更多，然后chunk会迁移到另一个分片。这个时候你的写入就会分布了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1596358099,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":182447,"user_name":"沈洪彬","can_delete":false,"product_type":"c3","uid":1458200,"ip_address":"","ucode":"F9911236D0BA1C","user_header":"https://static001.geekbang.org/account/avatar/00/16/40/18/cc3804e2.jpg","comment_is_top":false,"comment_ctime":1582789143,"is_pvip":false,"replies":[{"id":70946,"content":"在某一个shard的主节点上进行合并排序。\n\n“mongos 是无状态的“ - 合并排序操作不需要记状态。但是确实不是在mongos做的。\n\n和mysql&#47;mycat架构上类似，但是对应用基本是全透明，使用上几乎和未分片的复制集没有区别。对程序员的使用体验更好","user_name":"作者回复","user_name_real":"远航的TJ 唐建法","uid":1260017,"ctime":1583028442,"ip_address":"","comment_id":182447,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"关于分片这个感觉和 mysql+mycat这种差不多。这里有个疑问：\n  如果查询没有使用分表键，那么理论上查询会分发到多有的具体集群执行。那么这个结果的汇总(可能存在排序／分组) 在那里做呢？   是在mongos的内存上，还是config的内存上？        mycat那种实在mycat中间件机器上，但是我看前面说mongos是无状态的","like_count":3,"discussions":[{"author":{"id":1260017,"avatar":"https://static001.geekbang.org/account/avatar/00/13/39/f1/6d18a4d1.jpg","nickname":"远航的TJ 唐建法","note":"","ucode":"0719807390250A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":485341,"discussion_content":"在某一个shard的主节点上进行合并排序。\n\n“mongos 是无状态的“ - 合并排序操作不需要记状态。但是确实不是在mongos做的。\n\n和mysql/mycat架构上类似，但是对应用基本是全透明，使用上几乎和未分片的复制集没有区别。对程序员的使用体验更好","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1583028442,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":200985,"user_name":"李英权","can_delete":false,"product_type":"c3","uid":1076081,"ip_address":"","ucode":"FECAC14A9C414B","user_header":"https://static001.geekbang.org/account/avatar/00/10/6b/71/e833b14a.jpg","comment_is_top":false,"comment_ctime":1585703057,"is_pvip":false,"replies":[{"id":75807,"content":"分片是基于单表的。\n不分片的集合默认留在主分片上。你也可以通过movePrimary 命令调整主分片所在位置。","user_name":"作者回复","user_name_real":"远航的TJ 唐建法","uid":1260017,"ctime":1586081104,"ip_address":"","comment_id":200985,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"老师，是整个数据库超过2T还是单个集合超过2T的时候需要分片？ 我设想 如果我的项目需要分片的时候，大概率是某一个集合太大了，这时是不是只需要对这个集合设置分片键？其它小集合怎么处理呢 不做任何设置 它们会被mongodb怎么安排？","like_count":2,"discussions":[{"author":{"id":1260017,"avatar":"https://static001.geekbang.org/account/avatar/00/13/39/f1/6d18a4d1.jpg","nickname":"远航的TJ 唐建法","note":"","ucode":"0719807390250A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":490200,"discussion_content":"分片是基于单表的。\n不分片的集合默认留在主分片上。你也可以通过movePrimary 命令调整主分片所在位置。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586081104,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":184390,"user_name":"Hoboson!","can_delete":false,"product_type":"c3","uid":1341692,"ip_address":"","ucode":"D593C3EB90E136","user_header":"https://static001.geekbang.org/account/avatar/00/14/78/fc/f7d59501.jpg","comment_is_top":false,"comment_ctime":1583305143,"is_pvip":false,"replies":[{"id":72154,"content":"1）可以，直接用shardCollection就可以\n2）不会。\n\n数据均衡可能会花很长时间（数天），这是正常的。\n","user_name":"作者回复","user_name_real":"远航的TJ 唐建法","uid":1260017,"ctime":1584004220,"ip_address":"","comment_id":184390,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"老师好：我们生产使用的是分片模式，但是有一个集合没有建片键，这个集合现在太大了占了7.4TB，\n1：现在怎么建片键，可以建吗？\n2：建了片键之后会不会影响之前的数据查询","like_count":1,"discussions":[{"author":{"id":1260017,"avatar":"https://static001.geekbang.org/account/avatar/00/13/39/f1/6d18a4d1.jpg","nickname":"远航的TJ 唐建法","note":"","ucode":"0719807390250A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":485999,"discussion_content":"1）可以，直接用shardCollection就可以\n2）不会。\n\n数据均衡可能会花很长时间（数天），这是正常的。\n","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1584004220,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1341692,"avatar":"https://static001.geekbang.org/account/avatar/00/14/78/fc/f7d59501.jpg","nickname":"Hoboson!","note":"","ucode":"D593C3EB90E136","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":198191,"discussion_content":"我们有一个集合每天增长量为40G左右 ，这样下去存储肯定够用了，麻烦老师指导下，该如何进行分片缓解这种问题，再有历史数据的情况下如何分片 ？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1583486200,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":172958,"user_name":"t86","can_delete":false,"product_type":"c3","uid":1261927,"ip_address":"","ucode":"B336666DC5FFFA","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIo6P1BKTjzM5QagaoM99aFmiaTIzpJ7hMG81Hhx9PwCsNjkrpmDPxVHAbQ2MWIKJEYSf5cES9dA7Q/132","comment_is_top":false,"comment_ctime":1579394849,"is_pvip":false,"replies":[{"id":67152,"content":"如果你的查询条件里有userid，就不会用到多个分片。\n如果你的查询条件里没有userid，就会发散到多个片","user_name":"作者回复","user_name_real":"远航的TJ 唐建法","uid":1260017,"ctime":1579479453,"ip_address":"","comment_id":172958,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"老师，用userid加time做片键，在查询时会有需要等待多个分片的结果一起返回的问题吗？","like_count":1,"discussions":[{"author":{"id":1260017,"avatar":"https://static001.geekbang.org/account/avatar/00/13/39/f1/6d18a4d1.jpg","nickname":"远航的TJ 唐建法","note":"","ucode":"0719807390250A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":481916,"discussion_content":"如果你的查询条件里有userid，就不会用到多个分片。\n如果你的查询条件里没有userid，就会发散到多个片","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1579479453,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":170716,"user_name":"Jason","can_delete":false,"product_type":"c3","uid":1131778,"ip_address":"","ucode":"1FD1A9D9F6341A","user_header":"https://static001.geekbang.org/account/avatar/00/11/45/02/795ce950.jpg","comment_is_top":false,"comment_ctime":1578672860,"is_pvip":false,"replies":[{"id":66201,"content":"官方没有标准算法 - 根据workload的不同，硬件配置可以差别很大。你可以参考MongoDB Atlas上面有个机器大小可以支持的Connections，所以从应用要支持的连接数，可以做一个反推。但是并不考虑你的数据量，所以只是个概括估计。\n\nhttps:&#47;&#47;docs.atlas.mongodb.com&#47;connection-limits&#47;index.html\n\n","user_name":"作者回复","user_name_real":"远航的TJ 唐建法","uid":1260017,"ctime":1578741902,"ip_address":"","comment_id":170716,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"老师，请教一个问题，数据大小与机器配置有没有经验换算方式，比如1TB数据，1主2从复制集，单台服务器需要多大的配置，CPU、内存，还是需要模拟压测","like_count":1,"discussions":[{"author":{"id":1260017,"avatar":"https://static001.geekbang.org/account/avatar/00/13/39/f1/6d18a4d1.jpg","nickname":"远航的TJ 唐建法","note":"","ucode":"0719807390250A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":481081,"discussion_content":"官方没有标准算法 - 根据workload的不同，硬件配置可以差别很大。你可以参考MongoDB Atlas上面有个机器大小可以支持的Connections，所以从应用要支持的连接数，可以做一个反推。但是并不考虑你的数据量，所以只是个概括估计。\n\nhttps://docs.atlas.mongodb.com/connection-limits/index.html\n\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1578741902,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":201880,"user_name":"xibuhaohao","can_delete":false,"product_type":"c3","uid":1935390,"ip_address":"","ucode":"7C47D0B29AE978","user_header":"","comment_is_top":false,"comment_ctime":1585872344,"is_pvip":false,"replies":[{"id":78483,"content":"分片的读写分离和复制集的是一样机制。可以查阅一下MongoDB read preference。参数可以直接给到mongos连接串。\n\n视频课程相关内容在这里\nhttps:&#47;&#47;time.geekbang.org&#47;course&#47;detail&#47;100040001-176897\n","user_name":"作者回复","user_name_real":"远航的TJ 唐建法","uid":1260017,"ctime":1587878731,"ip_address":"","comment_id":201880,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100040001,"comment_content":"老师，mongo分片集群如何实现读写分离？需要配置哪些？可以提供一些资料查看吗？","like_count":0,"discussions":[{"author":{"id":1260017,"avatar":"https://static001.geekbang.org/account/avatar/00/13/39/f1/6d18a4d1.jpg","nickname":"远航的TJ 唐建法","note":"","ucode":"0719807390250A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":490446,"discussion_content":"分片的读写分离和复制集的是一样机制。可以查阅一下MongoDB read preference。参数可以直接给到mongos连接串。\n\n视频课程相关内容在这里\nhttps://time.geekbang.org/course/detail/100040001-176897\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587878731,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":199433,"user_name":"hellojd_gk","can_delete":false,"product_type":"c3","uid":1679543,"ip_address":"","ucode":"319AF4C1AD568D","user_header":"https://static001.geekbang.org/account/avatar/00/19/a0/b7/1327ae60.jpg","comment_is_top":false,"comment_ctime":1585489006,"is_pvip":false,"replies":[{"id":75814,"content":"哈希分配最开始的时候你就不需要做分配，只是指定哈希这种方式。4个到8个，方式没变，就不需要做任何事情。mongo会处理。","user_name":"作者回复","user_name_real":"远航的TJ 唐建法","uid":1260017,"ctime":1586082147,"ip_address":"","comment_id":199433,"utype":1}],"discussion_count":2,"race_medal":0,"score":3,"product_id":100040001,"comment_content":"哈希分配方式，如果刚开始是4个shard， 如果变成8个shard，是不是还需要再分配。老师没有讲到。","like_count":0,"discussions":[{"author":{"id":1260017,"avatar":"https://static001.geekbang.org/account/avatar/00/13/39/f1/6d18a4d1.jpg","nickname":"远航的TJ 唐建法","note":"","ucode":"0719807390250A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":489833,"discussion_content":"哈希分配最开始的时候你就不需要做分配，只是指定哈希这种方式。4个到8个，方式没变，就不需要做任何事情。mongo会处理。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586082147,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1041865,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/e5/c9/1061582b.jpg","nickname":"skying","note":"","ucode":"E7CFF50AB64BB1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":240986,"discussion_content":"老师你好，如果增加 分片，mongo 会自动进行 auto sharding 的过程吗","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587392634,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":172913,"user_name":"t86","can_delete":false,"product_type":"c3","uid":1261927,"ip_address":"","ucode":"B336666DC5FFFA","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIo6P1BKTjzM5QagaoM99aFmiaTIzpJ7hMG81Hhx9PwCsNjkrpmDPxVHAbQ2MWIKJEYSf5cES9dA7Q/132","comment_is_top":false,"comment_ctime":1579357664,"is_pvip":false,"replies":[{"id":67153,"content":"是的，分片不仅仅是数据量（我想你指的是行数），也和存储&#47;IOPS有关系，还有内存&#47;客户端连接数都有关系。 在课程内这一点我有明确说明。","user_name":"作者回复","user_name_real":"远航的TJ 唐建法","uid":1260017,"ctime":1579479607,"ip_address":"","comment_id":172913,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100040001,"comment_content":"老师，分片除了基于数据量是不是也要考虑集合内部的数据数量大小考虑？之前好像您有说上亿条还是多少以后读写性能也会显著变差，这种情况是不是也要考虑分片？","like_count":0,"discussions":[{"author":{"id":1260017,"avatar":"https://static001.geekbang.org/account/avatar/00/13/39/f1/6d18a4d1.jpg","nickname":"远航的TJ 唐建法","note":"","ucode":"0719807390250A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":481901,"discussion_content":"是的，分片不仅仅是数据量（我想你指的是行数），也和存储/IOPS有关系，还有内存/客户端连接数都有关系。 在课程内这一点我有明确说明。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1579479607,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":391841,"user_name":"Geek_9b19ad","can_delete":false,"product_type":"c3","uid":1811531,"ip_address":"广东","ucode":"109E631E085B8C","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/O9jhHevKia7Axa7dAiaFCmLIFZT3uaE47R09Mkxk54Fw7dcv7yS4yFFW8JlvxEzLJY3AUcKdsyeViap8xIDJzdj1w/132","comment_is_top":false,"comment_ctime":1719240415,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100040001,"comment_content":"在选择基数大的键进行分片,块会一直增大,影响数据均衡， 前面不是说一个块64M？那应该怎么理解？","like_count":0},{"had_liked":false,"id":375713,"user_name":"lixin","can_delete":false,"product_type":"c3","uid":1512599,"ip_address":"广东","ucode":"94D99DAFB6C929","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/88nXicqmkJWm3IXVfPfGQSk8SKIBVKjuC4qhzaCkf5Ud88uvKgS4Vf5AzCJ1uaFO0gpPnxdh4CowfhpxV1kSbXw/132","comment_is_top":false,"comment_ctime":1685894055,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100040001,"comment_content":"有个疑问想请教下老师，在sharding中，具体通过chunk来聚合存储doc,如果某个sharding中的chunck数过大，mongodb会自动将一些chunck 迁移到其他分片上去，但是这些迁出的chunck中的doc 因为sharding key 已经算好落在 原来的sharding中，比如hash 算法。那迁出到其他sharding的数据怎么通过这个路由来查找？有点想不明白，是不是哪个知识没理解清楚。还请老师帮忙指定。","like_count":0},{"had_liked":false,"id":370091,"user_name":"Geek_97446b","can_delete":false,"product_type":"c3","uid":3563327,"ip_address":"广东","ucode":"A5535FDAE72DB4","user_header":"","comment_is_top":false,"comment_ctime":1678360442,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100040001,"comment_content":"这里有个含糊的地方，是单分片是 2T，还是整个节点是 2T","like_count":0},{"had_liked":false,"id":355590,"user_name":"zhoubo_eric","can_delete":false,"product_type":"c3","uid":1584208,"ip_address":"北京","ucode":"34725AA3A9D59C","user_header":"https://static001.geekbang.org/account/avatar/00/18/2c/50/64365ef7.jpg","comment_is_top":false,"comment_ctime":1661515148,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100040001,"comment_content":"1.cardinality\n2.写分散\n3.定向读\n硬件","like_count":0},{"had_liked":false,"id":355584,"user_name":"zhoubo_eric","can_delete":false,"product_type":"c3","uid":1584208,"ip_address":"北京","ucode":"34725AA3A9D59C","user_header":"https://static001.geekbang.org/account/avatar/00/18/2c/50/64365ef7.jpg","comment_is_top":false,"comment_ctime":1661512927,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100040001,"comment_content":"chunk包含某一范围的shard key, 极端情况 chunk_nums == count(distinct shard_key),所以 shard_key的区分度越高，chunk数量越多，那么单个chunk存储数据量越少 。反过来同理，可能出现大chunk","like_count":0},{"had_liked":false,"id":347066,"user_name":"颜海航","can_delete":false,"product_type":"c3","uid":1308159,"ip_address":"","ucode":"5644F6328BF901","user_header":"https://static001.geekbang.org/account/avatar/00/13/f5/ff/523fb378.jpg","comment_is_top":false,"comment_ctime":1653660562,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100040001,"comment_content":"老师 您好 课程里有讲wiredtiger的部分吗 ","like_count":0},{"had_liked":false,"id":346358,"user_name":"Ken mo","can_delete":false,"product_type":"c3","uid":1761063,"ip_address":"","ucode":"2530EDD2F80BB0","user_header":"https://static001.geekbang.org/account/avatar/00/1a/df/27/0abab1e9.jpg","comment_is_top":false,"comment_ctime":1653043671,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":3,"product_id":100040001,"comment_content":"我们有的生产 就两个分片但每个接近50T了 老是有连通性告警","like_count":0,"discussions":[{"author":{"id":1308159,"avatar":"https://static001.geekbang.org/account/avatar/00/13/f5/ff/523fb378.jpg","nickname":"颜海航","note":"","ucode":"5644F6328BF901","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":573813,"discussion_content":"你们单机磁盘多大？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1653660780,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":335889,"user_name":"鞠振泰","can_delete":false,"product_type":"c3","uid":1258930,"ip_address":"","ucode":"E7E698250DD436","user_header":"https://static001.geekbang.org/account/avatar/00/13/35/b2/a64546fb.jpg","comment_is_top":false,"comment_ctime":1645757752,"is_pvip":true,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100040001,"comment_content":"老师，目前遇到一个mongodb分片集群出现的问题。官网购物车项目使用java开发，已经出现过3次应用程序在运行正常的情况下突然连接mongos无响应，登录mongos服务器，直接连接mongos也无响应。日志中有报错2022-02-16T16:41:48.404+0800 I  -        [conn117686] operation was interrupted because a client disconnected\n2022-02-16T16:41:48.404+0800 I  NETWORK  [conn117686] DBException handling request, closing client connection: ClientDisconnect: operation was interrupted，其他无相关信息，重启之后恢复正常。mongo版本4.2.9，数据量才几十M","like_count":0},{"had_liked":false,"id":280138,"user_name":"cocos","can_delete":false,"product_type":"c3","uid":1016599,"ip_address":"","ucode":"6DCA74033FFBEA","user_header":"https://static001.geekbang.org/account/avatar/00/0f/83/17/74c6e081.jpg","comment_is_top":false,"comment_ctime":1614090881,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":4,"product_id":100040001,"comment_content":"老师好，请教两个问题，如果分片键用userId + time\n1.同一个userId是否在同一个分片（可能会在同一个分片的不同块里）？\n2.如果同一个userId的数据在同一个分片里，那均衡器就不能把一个分片里的块，迁移到其他分片上了吧？","like_count":0,"discussions":[{"author":{"id":2215928,"avatar":"https://static001.geekbang.org/account/avatar/00/21/cf/f8/86076de4.jpg","nickname":"宏彬","note":"","ucode":"8EFDD45EA62342","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":382611,"discussion_content":"1：同一个userid只在一个分片里，根据不同的time，分布在不同的块里。\n2：在新添加机器扩容的时候，如果这个userid需要迁移，mongodb应该是把这个userid所有的块都会迁移到新的机器。\n3：以上回答是我学习的理解，不对之处，请轻拍。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1625646082,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":186663,"user_name":"Hoboson!","can_delete":false,"product_type":"c3","uid":1341692,"ip_address":"","ucode":"D593C3EB90E136","user_header":"https://static001.geekbang.org/account/avatar/00/14/78/fc/f7d59501.jpg","comment_is_top":false,"comment_ctime":1583897533,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100040001,"comment_content":"问题现象：\n{&quot;errInfo&quot;:{&quot;code&quot;:&quot;500&quot;,&quot;msg&quot;:&quot;Command failed with error 13: &#39;not authorized on user1 to execute command { $eval: \\&quot;db.getCollection(\\&quot;CCDataVO\\&quot;).insert\n处理方法：\ndb.createRole( { role: &quot;executeFunctions&quot;, privileges: [ { resource: { anyResource: true }, actions: [ &quot;anyAction&quot; ] } ], roles: [] } )\ndb.grantRolesToUser(&quot;user1&quot;, [ { role: &quot;executeFunctions&quot;, db: &quot;user1&quot; } ])\n但是授权只能给admin下面的用户授权， 不能给user1库下面的用户授权，授权失败\n","like_count":0}]}