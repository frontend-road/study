{"id":227161,"title":"12 | 非精准Top K检索：如何给检索结果的排序过程装上“加速器”？","content":"<p>你好，我是陈东。</p><p>上一讲，我们详细讲解了Top K检索的打分排序过程，并且还提到可以使用堆排序代替全排序，来大幅降低排序的时间代价。然而，对于这整个检索过程来说，精准复杂的打分开销要比排序大得多。因此，如果我们想更大幅度地提升检索性能，优化打分过程是一个重要的研究方向。那打分过程具体该怎么优化呢？今天，我们就来聊聊这个问题。</p><h2>什么是非精准的Top K检索？</h2><p>想要优化打分过程，一个很自然的思路就是通过简化打分机制，来降低打分开销。但是简化之后，我们的排序结果就不精准了。这该怎么办呢？这个问题先不着急解决，我们先来看看不精准的排序结果对用户会有什么影响。</p><p>其实，在搜索引擎中，排在第一页的结果并不一定是分数最高的。但由于用户在搜索时，本来就没有明确的目标网页，所以只要第一页的网页内容能满足用户的需求，那这就是高质量的检索结果了。</p><p>不仅如此，在推荐引擎中也是一样。推荐系统会根据用户的历史行为进行推荐，可推荐的物品非常多。比如说，如果用户曾经购买过《C++程序设计》这本书，那接下来我们既可以推荐《C++编程实战》，也可以推荐《C++编程宝典》。无论我们推荐哪一本，可能对用户来说差别都不大。</p><p>我们发现，其实在很多实际的应用场景中，<strong>高质量的检索结果并不一定要非常精准，我们只需要保证质量足够高的结果，被包含在最终的Top K个结果中就够了</strong>。这就是<strong>非精准Top K检索的思路</strong>。</p><!-- [[[read_end]]] --><p>实际上，在工业界中，我们会使用非精准Top K检索结合精准Top K检索的方案，来保证高效地检索出高质量的 结果。具体来说，就是把检索排序过程分为两个阶段：第一阶段，我们会进行非精准的Top K检索，将所有的检索结果进行简单的初步筛选，留下k1个结果，这样处理代价会小很多（这个阶段也被称为召回阶段）；第二个阶段，就是使用精准Top K检索，也就是使用复杂的打分机制，来对这k1个结果进行打分和排序，最终选出k2个最精准的结果返回（这个阶段也被称为排序阶段）。</p><p>其实，这个流程你应该很熟悉。这就像我们在招聘时，会先根据简历筛选，再根据面试结果进行筛选。简历筛选的效率很高，但是不精准；面试比较耗时，但能更好地判断候选人的能力，这就属于精准挑选了。</p><p>再说回到工业界的检索方案，非精准Top K检索到底是怎么使用简单的机制，来“加速”检索过程的呢？加速的效果如何呢？我们一起来看看。</p><h2>非精准Top K检索如何实现？</h2><p>在非精准Top K检索中，一个降低打分计算复杂度的重要思路是：<strong>尽可能地将计算放到离线环节，而不是在线环节</strong>。这样，在线环节我们就只需要进行简单的计算，然后快速截断就可以了。一个极端的方案就是根据检索结果的静态质量得分进行打分和截断。具体该怎么做呢？我们一起来看。</p><h3>1.  根据静态质量得分排序截断</h3><p>所谓静态质量得分，指的是不考虑检索结果和实时检索词的相关性，打分计算仅和结果自身的质量有关。这样，所有的打分计算就都可以在离线环节完成了。也就是说，我们只需要根据离线算好的静态质量得分直接截断，就可以加速检索的过程了。这么说可能比较抽象，我们通过一个例子来解释一下。</p><p>以搜索引擎为例，我们可以不考虑搜索词和网页之间复杂的相关性计算，只根据网站自身的质量打分排序。比如说，使用Page Rank算法（<a href=\"http://ilpubs.stanford.edu:8090/422/1/1999-66.pdf\">Google的核心算法，通过分析网页链接的引用关系来判断网页的质量</a>）离线计算好每个网站的质量分，当一个搜索词要返回多个网站时，我们只需要根据网站质量分排序，将质量最好的Top K个网站返回即可。</p><p>不过，为了能快速返回Top K个结果，我们需要改造一下倒排索引中的posting list的组织方式。我们讲过，倒排索引的posting list都是按文档ID进行排序的。如果希望根据静态质量得分快速截断的话，那我们就应该将posting list按照静态质量得分，由高到低排序。对于分数相同的文档，再以文档ID二次排序。<br>\n<img src=\"https://static001.geekbang.org/resource/image/03/16/03d377079560c983d70c853d51f5cf16.jpeg?wh=1920*1080\" alt=\"\" title=\"按静态质量得分排序\"></p><p>这样一来，在检索的时候，如果只有一个关键词，那我们只需要查出该关键词对应的posting list，截取前k个结果即可。但是如果我们要同时查询两个关键词，截断的过程就会复杂一些。尽管比较复杂，我们可以总结为两步：第一步，我们取出这两个关键词的posting list，但不直接截断；第二步，我们对这两个posting list归并排序。留下分数和文档ID都相同的条目作为结果集合，当结果集合中的条目达到k个时，我们就直接结束归并。如果是查询多个关键词，步骤也一样。</p><p>那在这个过程中，我们为什么可以对这两个posting list进行归并排序呢？这是因为文档是严格按照静态质量得分排列的。如果文档1的分数大于文档2，那在这两个posting list中文档1都会排在文档2前面。而且，对于分数相同的文档，它们也会按照ID进行二次排序。所以，任意的两个文档在不同的posting list中，是会具有相同的排序次序的。也因此，我们可以使用归并的方式来处理这两个posting list。</p><p>总结来说，在使用静态质量得分选取非精准Top K个结果的过程中，因为没有实时的复杂运算，仅有简单的截断操作，所以它和复杂的精准检索打分相比，开销几乎可以忽略不计。因此，在对相关性要求不高的场景下，如果使用静态质量得分可以满足系统需求，这会是一个非常合适的方案。但如果应用场景对相关性的要求比较高，那我们还得采用其他考虑相关性的非精准检索方案。</p><h3>2.  根据词频得分排序截断</h3><p>既然说到了相关性，就必须要提到词频了。我们在上一讲说过，词频记录了一个关键词在文档中出现的次数，可以代表关键词在文档中的重要性。而且，词频的计算是在索引构建的时候，也就是在离线环节完成的，并且它还可以直接存储在posting list中。</p><p>这就给了我们一个启发，我们可以考虑使用词频来对posting list中的文档进行截断。具体该怎么做呢？我们可以像使用静态质量得分一样，直接使用词频的值降序排序posting list吗？你可以先自己想一想，然后和我一起分析。</p><p>假设，搜索词中只有一个关键词，那我们只需要查出该关键词对应的posting list，截取前k个结果就可以了。这时候，这个方法是可以正常工作的。</p><p>但是如果搜索词中有两个关键词A和B，就可能出现这么一种情况：文档1中出现了2次关键词A，1次关键词B；文档2中出现了1次关键词A，2次关键词B。那么，在关键词A的posting list中，文档1的分数是2，文档2的分数是1，文档1排在文档2前面。但是在关键词B的posting list中，文档2的分数是2，文档1的分数是1，文档2排在文档1前面。</p><p>这个时候，文档1和文档2在不同的posting list中的排序是不同的，因此，我们无法使用归并排序的方法将它们快速合并和截断。</p><p><img src=\"https://static001.geekbang.org/resource/image/63/62/636562a949ae9db36f09583723990862.jpeg?wh=1920*1080\" alt=\"\" title=\"以词频数值排序导致无法归并\"></p><p>既然问题出在排序上，那我们能否既用上词频的分值，又保持ID有序呢？有这么一个解决思路，就是对posting list，我们先根据词频大小选出远多于k的前r个结果，然后将这r个结果按文档ID排序，这样就兼顾了相关性和快速归并截断的问题。这种根据某种权重将posting list中的元素进行排序，并提前截取r个最优结果的方案，就叫作<strong>胜者表</strong>。</p><p>胜者表的优点在于，它的排序方案更加灵活。比如说，我可以同时结合词频和静态质量得分进行排序（比如说权重 = 词频 + 静态质量得分），这样就同时考虑了相关性和结果质量两个维度。然后，我们对于每个posting list提前截断r个结果，再按文档ID排序即可。</p><p>但是有一点需要注意，胜者表的提前截断是有风险的，它可能会造成归并后的结果不满k个。比如说，文档1同时包含关键词A和B，但它既不在关键词A的前r个结果中，也不在关键词B的前r个结果中，那它就不会被选出来。在极端情况下，比如，关键词A的前r个结果都是仅包含A的文档，而关键词B的前r个结果都是仅包含B的文档，那关键词A和B的前r个结果的归并结果就是空的！这就会造成检索结果的丢失。</p><h3>3.  使用分层索引</h3><p>对于胜者表可能丢失检索结果的问题，我们有一种更通用的解决方案：<strong>分层索引</strong>。我们可以同时考虑相关性和结果质量，用离线计算的方式先给所有文档完成打分，然后将得分最高的m个文档作为高分文档，单独建立一个高质量索引，其他的文档则作为低质量索引。高质量索引和低质量索引的posting list都可以根据静态质量得分来排序，以方便检索的时候能快速截断。那具体是怎么检索的呢？我们一起来看看。<br>\n<img src=\"https://static001.geekbang.org/resource/image/27/f1/27389ea8c3865c59e625d5ba01e422f1.jpg?wh=1920*1080\" alt=\"\" title=\"分层索引的Top K检索\"></p><p>在实际检索的时候，我们会先去高质量索引中查询，如果高质量索引中可以返回的结果大于k个，我们直接截取Top K个结果返回即可；如果高质量索引中的检索结果不足k个，那我们再去低质量索引中查询，补全到k个结果，然后终止查询。通过这样的分层索引，我们就能快速地完成Top K的检索了。</p><p>相比于前面两种优化方案，分层索引是最通用的一种。而且，分层索引还可以看作是一种特殊的索引拆分，它可以和我们前面学过的索引拆分技术并存。比如说，对于高质量索引和低质量索引，我们还可以通过文档拆分的方式，将它们分为多个索引分片，使用分布式技术来进一步加速检索。</p><p>到这里，非精准Top K检索的三种实现方法我们都讲完了。总结来说，这些方法都是把非精准Top K检索应用在了离线环节，实际上，非精准Top K检索的思想还可以拓展应用到在线环节。也就是说，<strong>我们还能在倒排检索结束后，精准打分排序前，插入一个“非精准打分”环节</strong>，让我们能以较低的代价，快速过滤掉大部分的低质量结果，从而降低最终进行精准打分的性能开销。</p><p>除此之外，我还想补充一点。我们说的“非精准打分”和“精准打分”其实是相对的。这怎么理解呢？</p><p>举个例子，如果我们的“精准打分”环节采用的是传统的机器学习打分方式，如逻辑回归、梯度下降树等。那“非精准打分”环节就可以采用相对轻量级的打分方案，比如说采用TF-IDF方案，甚至是BM25方案等。而如果“精准打分”环节采用的是更复杂的深度学习的打分方式，比如使用了DNN模型，那么相对来说，“非精准打分”环节就可以采用逻辑回归这些方案了。</p><p>所以说，无论非精准打分的方案是什么，只要和精准打分相比，“能使用更小的代价，快速减少检索范围”，这就足够了。而这也是在前面多次出现过的检索加速的核心思想。</p><h2>重点回顾</h2><p>今天，我们主要学习了利用非精准Top K检索为检索过程“加速”。</p><p>非精准Top K检索实现加速的方法主要有三种，分别是根据静态质量得分排序截断，以及使用胜者表，利用词频进行相关性判断进行截断，还有使用分层索引，对一次查询请求进行两层检索。</p><p>这三种方法的核心思路都是，尽可能地将计算从在线环节转移到离线环节，让我们在在线环节中，也就是在倒排检索的时候，只需要进行少量的判断，就能快速截断Top K个结果，从而大幅提升检索引擎的检索效率。</p><p>此外，我们还能将非精准Top K检索拓展到线上环节，通过引入“非精准打分”的环节，来进一步减少参与“精准打分”的检索结果数量。</p><p>最后，在工业界中，完整的Top K检索是由非精准Top K检索和精准Top K共同完成的。这种设计的核心思想，是希望用更小的代价快速减少检索排序范围，从而提升整体在线检索的效率。我把它的实现过程总结成了一张示意图，你可以参考它来梳理、巩固今天的内容。<br>\n<img src=\"https://static001.geekbang.org/resource/image/81/56/81620b228164d406870a6136731d2e56.jpg?wh=1920*1080\" alt=\"\" title=\"完整Top K检索的过程示意图\"></p><h2>课堂讨论</h2><ol>\n<li>在分层索引中，posting list中的文档为什么还要根据静态质量得分排序？排序应该是升序还是降序？</li>\n<li>对于非精准Top K检索，你有没有相关的方法或者应用场景可以分享呢？</li>\n</ol><p>欢迎在留言区畅所欲言，说出你的思考过程和最终答案。如果有收获，也欢迎把这一讲分享给你的朋友。</p>","comments":[{"had_liked":false,"id":209434,"user_name":"奕","can_delete":false,"product_type":"c1","uid":1005391,"ip_address":"","ucode":"73CEA468CE70C3","user_header":"https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg","comment_is_top":false,"comment_ctime":1587548882,"is_pvip":false,"replies":[{"id":78200,"content":"是的。静态质量得分不考虑相关性，因此只需要对文档自身进行打分就好。写成函数形式就是f(d)，d代表文档。\n而精确打分要考虑查询词和文档的相关性。如果文档是d，查询词是q，那么打分函数就是f(q，d)。由于查询词是动态的，因此只能在实时环节进行打分，无法在离线环节打分。(注意:查询词可能有多个词项，比如同时有“极客”和“时间”两个词项，因此只能实时计算相加。否则如果查询词只有一个词项，那么是可以用胜者表的方法离线计算相关性的)。\n","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1587553794,"ip_address":"","comment_id":209434,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"看完这篇文章和上一篇文章：我的理解是 \n静态质量得分的非精确打分和精确打分的打分对象是不同的\n静态质量得分非精确打分因为是离线打分，针对的是文档进行打分，该文档的所有关键词的分都一样\n精确打分：针对的某个关键词和文档的相关性进行打分","like_count":15},{"had_liked":false,"id":215419,"user_name":"牛牛","can_delete":false,"product_type":"c1","uid":1194626,"ip_address":"","ucode":"CFCE68B4F92209","user_header":"https://static001.geekbang.org/account/avatar/00/12/3a/82/1ff83a38.jpg","comment_is_top":false,"comment_ctime":1588988766,"is_pvip":false,"replies":[{"id":79765,"content":"从某种角度角度来说，计算机世界和我们的生活的确都是蛮相似的，其实都是在针对目标，做各种优化和平衡，我们的学习，其实也是应该触类旁通，不仅仅是学习技术本身，也在学习做事的方式。\n问题1: posting list的确是用链表或数组降序排序好的。而不是用堆。因为用堆的话，取出堆顶元素，就需要调整堆，代价是log n。但posting list只要是只读的就好，我们没必要要读第二大的元素的时候还要实时调整，这样效率反而会低。包括posting list如果插入新元素，其实我们可以使用第九讲索引更新的技术实现，而不是实时插入。因此，posting list目前的实现还是跳表或数组。\n2.你举的这些例子都很好，都是先初步筛选，再精确筛选的。如果我们要实现人工智能的话，其实也是可以按照这个思路来设计实现的。\n","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1589009875,"ip_address":"","comment_id":215419,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"感觉计算机的世界和人类的世界是惊人的相似, 总是在做各种权衡(时间和空间, 资源消耗与效率提升、耗时与准确度...) 总是在追求较小成本的最大收益(也正因为如此、才推动社会的进步和发展、不断的创新、尝试), 而这种关系、总在趋于平缓(某种资源达到一定程度之后、对整体的提升就不再明显), 所以就需要不断的突破(计算机的发展和自我成长都是如此)~~~~\n\n---------------\n尝试回答下今天的问题:\n1. 应该是为了在同层次索引中最快速的得到相关度最高的top N 结果\n  至于是升序还是降序, 若[posting list]是链表的话、应该是降序; 但我有一个疑问, 就是 [posting list]是目前一般都这么实现的吗? 为什么不是使用小顶堆呢 ?这样topk的取值效率应该是 O(1) ？堆插入的效率会低于链表、就搜索来说、应该是插入频次远小于查询频次的\n\n2. a. 每次购物时、同类型的商品我们会加入多个(非精准topK)、然后再对比价格、评论等信息, 再决定买哪一个或哪些(精准筛选)\n   b. 找相关文章时、一般会先打开多个链接、然后再从中挑选一下, 看哪个文章更适合自己(有时候top1、2、3的推荐不一定是适合的, eg. 理论性太强、全英文等)\n  c. 在微信读书选书时、一般我会调同一题材的多本书籍、然后再根据感兴趣的程度继续挑选最喜欢的一到两个放到书架\n暂时能想到这几个场景、不知道算不算~~~ ","like_count":7,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492797,"discussion_content":"是的。静态质量得分不考虑相关性，因此只需要对文档自身进行打分就好。写成函数形式就是f(d)，d代表文档。\n而精确打分要考虑查询词和文档的相关性。如果文档是d，查询词是q，那么打分函数就是f(q，d)。由于查询词是动态的，因此只能在实时环节进行打分，无法在离线环节打分。(注意:查询词可能有多个词项，比如同时有“极客”和“时间”两个词项，因此只能实时计算相加。否则如果查询词只有一个词项，那么是可以用胜者表的方法离线计算相关性的)。\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587553794,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":209398,"user_name":"峰","can_delete":false,"product_type":"c1","uid":1056019,"ip_address":"","ucode":"C53CB64E8E7D19","user_header":"https://static001.geekbang.org/account/avatar/00/10/1d/13/31ea1b0b.jpg","comment_is_top":false,"comment_ctime":1587545638,"is_pvip":false,"replies":[{"id":78198,"content":"1.你提了很好的一个问题，静态质量分不好的是否会被活活饿死?其实，不管是静态质量得分还是动态的相关性打分，既然是排序，肯定会有优胜劣汰，只是在大数据的场景下，所谓的劣汰不是完全封杀，而是降低出现的概率。\n首先，如果快速截断采取的是静态质量分，那么粗排的时候肯定就是换一种打分机制了，比如说采用bm25进行粗排，或者使用简化版的机器学习(为了保证效率，用在粗排阶段的机器学习模型会比较简单，而不是和用在精排阶段的机器学习模型完全一样)。\n另一方面，为了保证结果的多样性，我们应该加入exploit &amp;explore机制，就是保证有小比例的流量可以采用随机的方式选择检索结果，而不是靠打分排序，从而给一些初始打分不高的检索结果证明自己的机会。但如果数据依然不好，那么接下来这些低质量的结果被选出来的概率就会越来越低。\n2.在搜索引擎和推荐引擎中，使用tf-idf，bm25，甚至是简化的逻辑回归模型来做非精准top k检索，都是常见的使用方案。此外，就像你说的一样，可以用一些简单算法算一遍，快速排除掉一些数据项。这方面其实也有许多研究和论文，比如说雅虎有一篇wand(weak and)算法的论文，就是讲如何根据相似度的上限来快速截断。\n其实，使用非精准检索思路的场景非常多，我文中的简历筛选的过程就是一个例子。下一篇你也会看到另一个例子。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1587551517,"ip_address":"","comment_id":209398,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"问题1 降序是必然的，毕竟升序没有意义，但根据静态分降序，然后根据静态分去做粗排，这样不会饿死静态分不高的文档吗，或者它活该饿死。。。。\n问题2，没想到什么场景，但思路就是比如可以用一些近似计算的方式算一遍，排除掉一些数据项，再做精确运算。\n\n","like_count":4,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":494427,"discussion_content":"从某种角度角度来说，计算机世界和我们的生活的确都是蛮相似的，其实都是在针对目标，做各种优化和平衡，我们的学习，其实也是应该触类旁通，不仅仅是学习技术本身，也在学习做事的方式。\n问题1: posting list的确是用链表或数组降序排序好的。而不是用堆。因为用堆的话，取出堆顶元素，就需要调整堆，代价是log n。但posting list只要是只读的就好，我们没必要要读第二大的元素的时候还要实时调整，这样效率反而会低。包括posting list如果插入新元素，其实我们可以使用第九讲索引更新的技术实现，而不是实时插入。因此，posting list目前的实现还是跳表或数组。\n2.你举的这些例子都很好，都是先初步筛选，再精确筛选的。如果我们要实现人工智能的话，其实也是可以按照这个思路来设计实现的。\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589009875,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":230877,"user_name":"流浪在寂寞古城","can_delete":false,"product_type":"c1","uid":1105678,"ip_address":"","ucode":"FE90DCD5DC3A20","user_header":"https://static001.geekbang.org/account/avatar/00/10/df/0e/4e2b06d5.jpg","comment_is_top":false,"comment_ctime":1593511162,"is_pvip":false,"replies":[{"id":85360,"content":"你思考了一些细节和案例，这个习惯很好。你也会发现:高质量索引的“极客”和低质量索引的“时间”求交集，这个方法感觉不太对是不是? 分层索引的确不是这么实现的。\n分层索引不是根据词频类似的打分方式来对文档进行分层，它更多的还是根据静态质量分来区分。\n比如说，来自门户网站的文章会被打上更高的质量分，而个人站点的类似文章会被打上较低的质量分。它们分别被划分到了高质量文档集合a，以及普通文档集合b中。\n我们在建立倒排索引时，会针对a建立一个倒排索引，针对b建立一个倒排索引。\n在检索时，先检索a索引，得到x个文档。如果不满足k个结果，那么再去索引b中，以“极客”和“时间”为key，单独在索引b中找到符合条件的y个文档，然后将x个文档和y个文档合并，再取top k。\n那为什么不是在索引a中用“极客”检索posting list，再在索引b中用“时间”检索出posting list然后合并呢？因为这两个posting list的文档集合是空。(索引a和索引b中的文档是无交集的)。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1593605930,"ip_address":"","comment_id":230877,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"分层索引有一些不明白，高质量的索引离线计算的方式得到分数，我理解这个离线计算应该是利用词频类似的方法吧（因为高质量内部排序用的静态分）。以“极客”和“时间”为例，这时候如果高质量的召回不够k，那么很可能“极客”的高质量索引与“时间”低质量索引有交集，反之毅然。这时候我们为例凑够k个，一般工业上是如何操作的呢？拿彼此的高质量和低质量进行匹配？因为高质量的索引一定文档不是很多，有可能还是不够k个。还是直接低质量和低质量召回呢？","like_count":3,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492790,"discussion_content":"1.你提了很好的一个问题，静态质量分不好的是否会被活活饿死?其实，不管是静态质量得分还是动态的相关性打分，既然是排序，肯定会有优胜劣汰，只是在大数据的场景下，所谓的劣汰不是完全封杀，而是降低出现的概率。\n首先，如果快速截断采取的是静态质量分，那么粗排的时候肯定就是换一种打分机制了，比如说采用bm25进行粗排，或者使用简化版的机器学习(为了保证效率，用在粗排阶段的机器学习模型会比较简单，而不是和用在精排阶段的机器学习模型完全一样)。\n另一方面，为了保证结果的多样性，我们应该加入exploit &amp;amp;explore机制，就是保证有小比例的流量可以采用随机的方式选择检索结果，而不是靠打分排序，从而给一些初始打分不高的检索结果证明自己的机会。但如果数据依然不好，那么接下来这些低质量的结果被选出来的概率就会越来越低。\n2.在搜索引擎和推荐引擎中，使用tf-idf，bm25，甚至是简化的逻辑回归模型来做非精准top k检索，都是常见的使用方案。此外，就像你说的一样，可以用一些简单算法算一遍，快速排除掉一些数据项。这方面其实也有许多研究和论文，比如说雅虎有一篇wand(weak and)算法的论文，就是讲如何根据相似度的上限来快速截断。\n其实，使用非精准检索思路的场景非常多，我文中的简历筛选的过程就是一个例子。下一篇你也会看到另一个例子。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587551517,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1123043,"avatar":"https://static001.geekbang.org/account/avatar/00/11/22/e3/510b69f9.jpg","nickname":"benny","note":"","ucode":"E2F30AF0C808D9","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":281327,"discussion_content":"exploit &amp;explore 应该是explore &amp; exploit吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1591712498,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":320510,"user_name":"zj","can_delete":false,"product_type":"c1","uid":1100064,"ip_address":"","ucode":"E3329CCF694AC2","user_header":"https://static001.geekbang.org/account/avatar/00/10/c9/20/e4f1b17c.jpg","comment_is_top":false,"comment_ctime":1636359324,"is_pvip":false,"replies":[{"id":116701,"content":"你说的没错，如果分层索引不考虑相关性，仅采用静态质量分，那么和第一种方法差不多（仅是在高质量层查不到的时候才有区别）","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1636816067,"ip_address":"","comment_id":320510,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"第一种静态质量分 和 第三种分层索引方法，如果第三种分层索引也采用静态分层索引，那我觉得跟第一种静态质量分的效率是差不多的","like_count":1,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":500059,"discussion_content":"你思考了一些细节和案例，这个习惯很好。你也会发现:高质量索引的“极客”和低质量索引的“时间”求交集，这个方法感觉不太对是不是? 分层索引的确不是这么实现的。\n分层索引不是根据词频类似的打分方式来对文档进行分层，它更多的还是根据静态质量分来区分。\n比如说，来自门户网站的文章会被打上更高的质量分，而个人站点的类似文章会被打上较低的质量分。它们分别被划分到了高质量文档集合a，以及普通文档集合b中。\n我们在建立倒排索引时，会针对a建立一个倒排索引，针对b建立一个倒排索引。\n在检索时，先检索a索引，得到x个文档。如果不满足k个结果，那么再去索引b中，以“极客”和“时间”为key，单独在索引b中找到符合条件的y个文档，然后将x个文档和y个文档合并，再取top k。\n那为什么不是在索引a中用“极客”检索posting list，再在索引b中用“时间”检索出posting list然后合并呢？因为这两个posting list的文档集合是空。(索引a和索引b中的文档是无交集的)。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1593605930,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":209237,"user_name":"那时刻","can_delete":false,"product_type":"c1","uid":1150927,"ip_address":"","ucode":"B0D150856C3A4A","user_header":"https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg","comment_is_top":false,"comment_ctime":1587522320,"is_pvip":false,"replies":[{"id":78170,"content":"就如你说的，分层索引大概率只扫描第一层就能得到top k。因此，在第一层索引候选集充足的情况下，采用静态质量分降序，能更快进行top k截断，而不需要完整检索完第一层索引，从而达到检索加速的目的。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1587530787,"ip_address":"","comment_id":209237,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"1.分层索引采用静态质量得分是大概率只扫描第一层索引就可以得到topk。而采用词频相关性的话，为保证文档齐全大概率需要搜索多层索引。效率比较低。分层索引采用降序排序。","like_count":1,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":530021,"discussion_content":"你说的没错，如果分层索引不考虑相关性，仅采用静态质量分，那么和第一种方法差不多（仅是在高质量层查不到的时候才有区别）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1636816067,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":209253,"user_name":"那时刻","can_delete":false,"product_type":"c1","uid":1150927,"ip_address":"","ucode":"B0D150856C3A4A","user_header":"https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg","comment_is_top":false,"comment_ctime":1587524660,"is_pvip":false,"replies":[{"id":78171,"content":"实际中是有的。其实就是一个加权的表达式:\nw1*tf + w2*静态质量分。\n具体w1和w2的权重，可以看你的应用诉求，手动调整。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1587530931,"ip_address":"","comment_id":209253,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"老师，您在胜者表提到静态质量得分和词频两个维度综合考虑来计算文档权重，请问在实际操作中有这样的应用么？","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492744,"discussion_content":"就如你说的，分层索引大概率只扫描第一层就能得到top k。因此，在第一层索引候选集充足的情况下，采用静态质量分降序，能更快进行top k截断，而不需要完整检索完第一层索引，从而达到检索加速的目的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587530787,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":209187,"user_name":"pedro","can_delete":false,"product_type":"c1","uid":1200704,"ip_address":"","ucode":"F40C839DDFD599","user_header":"https://static001.geekbang.org/account/avatar/00/12/52/40/e57a736e.jpg","comment_is_top":false,"comment_ctime":1587517906,"is_pvip":false,"replies":[{"id":78167,"content":"1.是的。还是为了快速截断。如果在高质量文档的索引中也有足够的候选集，那么其实我们也不需要检索完全部文档，因此对于高质量索引，依然采用根据静态质量降序，是能有加速效果的。\n2.的确是这样的，现在的召回环节中，就有用逻辑回归进行截断的，当然，这个环节也有人叫做“粗排”环节。不过历史是相似的，在机器学习出来之前，bm25就是精排；在机器学习出来后，bm25就变成粗排了；同理，在深度学习出来以后，机器学习就可以变成粗排了。说不定未来哪天，深度学习也会变成粗排。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1587530629,"ip_address":"","comment_id":209187,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"问题1，根据静态质量得分来排序可以有效的筛选出高质量的内容，排序应该是降序，将高质量文档放在前面从而更快的打分。\n问题2，没想到深度学习的降维打击，让传统经典的打分算法都沦为到非精准打分的环节了，哎，英雄迟暮。","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492751,"discussion_content":"实际中是有的。其实就是一个加权的表达式:\nw1*tf + w2*静态质量分。\n具体w1和w2的权重，可以看你的应用诉求，手动调整。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587530931,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":387253,"user_name":"庄墨寒","can_delete":false,"product_type":"c1","uid":1063970,"ip_address":"浙江","ucode":"BBD9EFA891BF06","user_header":"https://static001.geekbang.org/account/avatar/00/10/3c/22/9024c062.jpg","comment_is_top":false,"comment_ctime":1706779305,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"很好的课程，回答了我对搜索引擎诸多忙点。点赞。","like_count":0},{"had_liked":false,"id":375065,"user_name":"Trent","can_delete":false,"product_type":"c1","uid":1113467,"ip_address":"上海","ucode":"779CF5EA0991E1","user_header":"https://static001.geekbang.org/account/avatar/00/10/fd/7b/89bc309e.jpg","comment_is_top":false,"comment_ctime":1684854998,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"非精确排序以静态得分作为截断依据会降低多样性和新鲜度以及相关心。如何才能够平衡性能和上述指标。","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492732,"discussion_content":"1.是的。还是为了快速截断。如果在高质量文档的索引中也有足够的候选集，那么其实我们也不需要检索完全部文档，因此对于高质量索引，依然采用根据静态质量降序，是能有加速效果的。\n2.的确是这样的，现在的召回环节中，就有用逻辑回归进行截断的，当然，这个环节也有人叫做“粗排”环节。不过历史是相似的，在机器学习出来之前，bm25就是精排；在机器学习出来后，bm25就变成粗排了；同理，在深度学习出来以后，机器学习就可以变成粗排了。说不定未来哪天，深度学习也会变成粗排。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587530629,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":209434,"user_name":"奕","can_delete":false,"product_type":"c1","uid":1005391,"ip_address":"","ucode":"73CEA468CE70C3","user_header":"https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg","comment_is_top":false,"comment_ctime":1587548882,"is_pvip":false,"replies":[{"id":78200,"content":"是的。静态质量得分不考虑相关性，因此只需要对文档自身进行打分就好。写成函数形式就是f(d)，d代表文档。\n而精确打分要考虑查询词和文档的相关性。如果文档是d，查询词是q，那么打分函数就是f(q，d)。由于查询词是动态的，因此只能在实时环节进行打分，无法在离线环节打分。(注意:查询词可能有多个词项，比如同时有“极客”和“时间”两个词项，因此只能实时计算相加。否则如果查询词只有一个词项，那么是可以用胜者表的方法离线计算相关性的)。\n","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1587553794,"ip_address":"","comment_id":209434,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"看完这篇文章和上一篇文章：我的理解是 \n静态质量得分的非精确打分和精确打分的打分对象是不同的\n静态质量得分非精确打分因为是离线打分，针对的是文档进行打分，该文档的所有关键词的分都一样\n精确打分：针对的某个关键词和文档的相关性进行打分","like_count":15,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492797,"discussion_content":"是的。静态质量得分不考虑相关性，因此只需要对文档自身进行打分就好。写成函数形式就是f(d)，d代表文档。\n而精确打分要考虑查询词和文档的相关性。如果文档是d，查询词是q，那么打分函数就是f(q，d)。由于查询词是动态的，因此只能在实时环节进行打分，无法在离线环节打分。(注意:查询词可能有多个词项，比如同时有“极客”和“时间”两个词项，因此只能实时计算相加。否则如果查询词只有一个词项，那么是可以用胜者表的方法离线计算相关性的)。\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587553794,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":215419,"user_name":"牛牛","can_delete":false,"product_type":"c1","uid":1194626,"ip_address":"","ucode":"CFCE68B4F92209","user_header":"https://static001.geekbang.org/account/avatar/00/12/3a/82/1ff83a38.jpg","comment_is_top":false,"comment_ctime":1588988766,"is_pvip":false,"replies":[{"id":79765,"content":"从某种角度角度来说，计算机世界和我们的生活的确都是蛮相似的，其实都是在针对目标，做各种优化和平衡，我们的学习，其实也是应该触类旁通，不仅仅是学习技术本身，也在学习做事的方式。\n问题1: posting list的确是用链表或数组降序排序好的。而不是用堆。因为用堆的话，取出堆顶元素，就需要调整堆，代价是log n。但posting list只要是只读的就好，我们没必要要读第二大的元素的时候还要实时调整，这样效率反而会低。包括posting list如果插入新元素，其实我们可以使用第九讲索引更新的技术实现，而不是实时插入。因此，posting list目前的实现还是跳表或数组。\n2.你举的这些例子都很好，都是先初步筛选，再精确筛选的。如果我们要实现人工智能的话，其实也是可以按照这个思路来设计实现的。\n","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1589009875,"ip_address":"","comment_id":215419,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"感觉计算机的世界和人类的世界是惊人的相似, 总是在做各种权衡(时间和空间, 资源消耗与效率提升、耗时与准确度...) 总是在追求较小成本的最大收益(也正因为如此、才推动社会的进步和发展、不断的创新、尝试), 而这种关系、总在趋于平缓(某种资源达到一定程度之后、对整体的提升就不再明显), 所以就需要不断的突破(计算机的发展和自我成长都是如此)~~~~\n\n---------------\n尝试回答下今天的问题:\n1. 应该是为了在同层次索引中最快速的得到相关度最高的top N 结果\n  至于是升序还是降序, 若[posting list]是链表的话、应该是降序; 但我有一个疑问, 就是 [posting list]是目前一般都这么实现的吗? 为什么不是使用小顶堆呢 ?这样topk的取值效率应该是 O(1) ？堆插入的效率会低于链表、就搜索来说、应该是插入频次远小于查询频次的\n\n2. a. 每次购物时、同类型的商品我们会加入多个(非精准topK)、然后再对比价格、评论等信息, 再决定买哪一个或哪些(精准筛选)\n   b. 找相关文章时、一般会先打开多个链接、然后再从中挑选一下, 看哪个文章更适合自己(有时候top1、2、3的推荐不一定是适合的, eg. 理论性太强、全英文等)\n  c. 在微信读书选书时、一般我会调同一题材的多本书籍、然后再根据感兴趣的程度继续挑选最喜欢的一到两个放到书架\n暂时能想到这几个场景、不知道算不算~~~ ","like_count":7,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":494427,"discussion_content":"从某种角度角度来说，计算机世界和我们的生活的确都是蛮相似的，其实都是在针对目标，做各种优化和平衡，我们的学习，其实也是应该触类旁通，不仅仅是学习技术本身，也在学习做事的方式。\n问题1: posting list的确是用链表或数组降序排序好的。而不是用堆。因为用堆的话，取出堆顶元素，就需要调整堆，代价是log n。但posting list只要是只读的就好，我们没必要要读第二大的元素的时候还要实时调整，这样效率反而会低。包括posting list如果插入新元素，其实我们可以使用第九讲索引更新的技术实现，而不是实时插入。因此，posting list目前的实现还是跳表或数组。\n2.你举的这些例子都很好，都是先初步筛选，再精确筛选的。如果我们要实现人工智能的话，其实也是可以按照这个思路来设计实现的。\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589009875,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":209398,"user_name":"峰","can_delete":false,"product_type":"c1","uid":1056019,"ip_address":"","ucode":"C53CB64E8E7D19","user_header":"https://static001.geekbang.org/account/avatar/00/10/1d/13/31ea1b0b.jpg","comment_is_top":false,"comment_ctime":1587545638,"is_pvip":false,"replies":[{"id":78198,"content":"1.你提了很好的一个问题，静态质量分不好的是否会被活活饿死?其实，不管是静态质量得分还是动态的相关性打分，既然是排序，肯定会有优胜劣汰，只是在大数据的场景下，所谓的劣汰不是完全封杀，而是降低出现的概率。\n首先，如果快速截断采取的是静态质量分，那么粗排的时候肯定就是换一种打分机制了，比如说采用bm25进行粗排，或者使用简化版的机器学习(为了保证效率，用在粗排阶段的机器学习模型会比较简单，而不是和用在精排阶段的机器学习模型完全一样)。\n另一方面，为了保证结果的多样性，我们应该加入exploit &amp;explore机制，就是保证有小比例的流量可以采用随机的方式选择检索结果，而不是靠打分排序，从而给一些初始打分不高的检索结果证明自己的机会。但如果数据依然不好，那么接下来这些低质量的结果被选出来的概率就会越来越低。\n2.在搜索引擎和推荐引擎中，使用tf-idf，bm25，甚至是简化的逻辑回归模型来做非精准top k检索，都是常见的使用方案。此外，就像你说的一样，可以用一些简单算法算一遍，快速排除掉一些数据项。这方面其实也有许多研究和论文，比如说雅虎有一篇wand(weak and)算法的论文，就是讲如何根据相似度的上限来快速截断。\n其实，使用非精准检索思路的场景非常多，我文中的简历筛选的过程就是一个例子。下一篇你也会看到另一个例子。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1587551517,"ip_address":"","comment_id":209398,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"问题1 降序是必然的，毕竟升序没有意义，但根据静态分降序，然后根据静态分去做粗排，这样不会饿死静态分不高的文档吗，或者它活该饿死。。。。\n问题2，没想到什么场景，但思路就是比如可以用一些近似计算的方式算一遍，排除掉一些数据项，再做精确运算。\n\n","like_count":4,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492790,"discussion_content":"1.你提了很好的一个问题，静态质量分不好的是否会被活活饿死?其实，不管是静态质量得分还是动态的相关性打分，既然是排序，肯定会有优胜劣汰，只是在大数据的场景下，所谓的劣汰不是完全封杀，而是降低出现的概率。\n首先，如果快速截断采取的是静态质量分，那么粗排的时候肯定就是换一种打分机制了，比如说采用bm25进行粗排，或者使用简化版的机器学习(为了保证效率，用在粗排阶段的机器学习模型会比较简单，而不是和用在精排阶段的机器学习模型完全一样)。\n另一方面，为了保证结果的多样性，我们应该加入exploit &amp;amp;explore机制，就是保证有小比例的流量可以采用随机的方式选择检索结果，而不是靠打分排序，从而给一些初始打分不高的检索结果证明自己的机会。但如果数据依然不好，那么接下来这些低质量的结果被选出来的概率就会越来越低。\n2.在搜索引擎和推荐引擎中，使用tf-idf，bm25，甚至是简化的逻辑回归模型来做非精准top k检索，都是常见的使用方案。此外，就像你说的一样，可以用一些简单算法算一遍，快速排除掉一些数据项。这方面其实也有许多研究和论文，比如说雅虎有一篇wand(weak and)算法的论文，就是讲如何根据相似度的上限来快速截断。\n其实，使用非精准检索思路的场景非常多，我文中的简历筛选的过程就是一个例子。下一篇你也会看到另一个例子。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587551517,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1123043,"avatar":"https://static001.geekbang.org/account/avatar/00/11/22/e3/510b69f9.jpg","nickname":"benny","note":"","ucode":"E2F30AF0C808D9","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":281327,"discussion_content":"exploit &amp;explore 应该是explore &amp; exploit吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1591712498,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":230877,"user_name":"流浪在寂寞古城","can_delete":false,"product_type":"c1","uid":1105678,"ip_address":"","ucode":"FE90DCD5DC3A20","user_header":"https://static001.geekbang.org/account/avatar/00/10/df/0e/4e2b06d5.jpg","comment_is_top":false,"comment_ctime":1593511162,"is_pvip":false,"replies":[{"id":85360,"content":"你思考了一些细节和案例，这个习惯很好。你也会发现:高质量索引的“极客”和低质量索引的“时间”求交集，这个方法感觉不太对是不是? 分层索引的确不是这么实现的。\n分层索引不是根据词频类似的打分方式来对文档进行分层，它更多的还是根据静态质量分来区分。\n比如说，来自门户网站的文章会被打上更高的质量分，而个人站点的类似文章会被打上较低的质量分。它们分别被划分到了高质量文档集合a，以及普通文档集合b中。\n我们在建立倒排索引时，会针对a建立一个倒排索引，针对b建立一个倒排索引。\n在检索时，先检索a索引，得到x个文档。如果不满足k个结果，那么再去索引b中，以“极客”和“时间”为key，单独在索引b中找到符合条件的y个文档，然后将x个文档和y个文档合并，再取top k。\n那为什么不是在索引a中用“极客”检索posting list，再在索引b中用“时间”检索出posting list然后合并呢？因为这两个posting list的文档集合是空。(索引a和索引b中的文档是无交集的)。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1593605930,"ip_address":"","comment_id":230877,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"分层索引有一些不明白，高质量的索引离线计算的方式得到分数，我理解这个离线计算应该是利用词频类似的方法吧（因为高质量内部排序用的静态分）。以“极客”和“时间”为例，这时候如果高质量的召回不够k，那么很可能“极客”的高质量索引与“时间”低质量索引有交集，反之毅然。这时候我们为例凑够k个，一般工业上是如何操作的呢？拿彼此的高质量和低质量进行匹配？因为高质量的索引一定文档不是很多，有可能还是不够k个。还是直接低质量和低质量召回呢？","like_count":3,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":500059,"discussion_content":"你思考了一些细节和案例，这个习惯很好。你也会发现:高质量索引的“极客”和低质量索引的“时间”求交集，这个方法感觉不太对是不是? 分层索引的确不是这么实现的。\n分层索引不是根据词频类似的打分方式来对文档进行分层，它更多的还是根据静态质量分来区分。\n比如说，来自门户网站的文章会被打上更高的质量分，而个人站点的类似文章会被打上较低的质量分。它们分别被划分到了高质量文档集合a，以及普通文档集合b中。\n我们在建立倒排索引时，会针对a建立一个倒排索引，针对b建立一个倒排索引。\n在检索时，先检索a索引，得到x个文档。如果不满足k个结果，那么再去索引b中，以“极客”和“时间”为key，单独在索引b中找到符合条件的y个文档，然后将x个文档和y个文档合并，再取top k。\n那为什么不是在索引a中用“极客”检索posting list，再在索引b中用“时间”检索出posting list然后合并呢？因为这两个posting list的文档集合是空。(索引a和索引b中的文档是无交集的)。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1593605930,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":320510,"user_name":"zj","can_delete":false,"product_type":"c1","uid":1100064,"ip_address":"","ucode":"E3329CCF694AC2","user_header":"https://static001.geekbang.org/account/avatar/00/10/c9/20/e4f1b17c.jpg","comment_is_top":false,"comment_ctime":1636359324,"is_pvip":false,"replies":[{"id":116701,"content":"你说的没错，如果分层索引不考虑相关性，仅采用静态质量分，那么和第一种方法差不多（仅是在高质量层查不到的时候才有区别）","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1636816067,"ip_address":"","comment_id":320510,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"第一种静态质量分 和 第三种分层索引方法，如果第三种分层索引也采用静态分层索引，那我觉得跟第一种静态质量分的效率是差不多的","like_count":1,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":530021,"discussion_content":"你说的没错，如果分层索引不考虑相关性，仅采用静态质量分，那么和第一种方法差不多（仅是在高质量层查不到的时候才有区别）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1636816067,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":209237,"user_name":"那时刻","can_delete":false,"product_type":"c1","uid":1150927,"ip_address":"","ucode":"B0D150856C3A4A","user_header":"https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg","comment_is_top":false,"comment_ctime":1587522320,"is_pvip":false,"replies":[{"id":78170,"content":"就如你说的，分层索引大概率只扫描第一层就能得到top k。因此，在第一层索引候选集充足的情况下，采用静态质量分降序，能更快进行top k截断，而不需要完整检索完第一层索引，从而达到检索加速的目的。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1587530787,"ip_address":"","comment_id":209237,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"1.分层索引采用静态质量得分是大概率只扫描第一层索引就可以得到topk。而采用词频相关性的话，为保证文档齐全大概率需要搜索多层索引。效率比较低。分层索引采用降序排序。","like_count":1,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492744,"discussion_content":"就如你说的，分层索引大概率只扫描第一层就能得到top k。因此，在第一层索引候选集充足的情况下，采用静态质量分降序，能更快进行top k截断，而不需要完整检索完第一层索引，从而达到检索加速的目的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587530787,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":209253,"user_name":"那时刻","can_delete":false,"product_type":"c1","uid":1150927,"ip_address":"","ucode":"B0D150856C3A4A","user_header":"https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg","comment_is_top":false,"comment_ctime":1587524660,"is_pvip":false,"replies":[{"id":78171,"content":"实际中是有的。其实就是一个加权的表达式:\nw1*tf + w2*静态质量分。\n具体w1和w2的权重，可以看你的应用诉求，手动调整。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1587530931,"ip_address":"","comment_id":209253,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"老师，您在胜者表提到静态质量得分和词频两个维度综合考虑来计算文档权重，请问在实际操作中有这样的应用么？","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492751,"discussion_content":"实际中是有的。其实就是一个加权的表达式:\nw1*tf + w2*静态质量分。\n具体w1和w2的权重，可以看你的应用诉求，手动调整。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587530931,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":209187,"user_name":"pedro","can_delete":false,"product_type":"c1","uid":1200704,"ip_address":"","ucode":"F40C839DDFD599","user_header":"https://static001.geekbang.org/account/avatar/00/12/52/40/e57a736e.jpg","comment_is_top":false,"comment_ctime":1587517906,"is_pvip":false,"replies":[{"id":78167,"content":"1.是的。还是为了快速截断。如果在高质量文档的索引中也有足够的候选集，那么其实我们也不需要检索完全部文档，因此对于高质量索引，依然采用根据静态质量降序，是能有加速效果的。\n2.的确是这样的，现在的召回环节中，就有用逻辑回归进行截断的，当然，这个环节也有人叫做“粗排”环节。不过历史是相似的，在机器学习出来之前，bm25就是精排；在机器学习出来后，bm25就变成粗排了；同理，在深度学习出来以后，机器学习就可以变成粗排了。说不定未来哪天，深度学习也会变成粗排。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1587530629,"ip_address":"","comment_id":209187,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"问题1，根据静态质量得分来排序可以有效的筛选出高质量的内容，排序应该是降序，将高质量文档放在前面从而更快的打分。\n问题2，没想到深度学习的降维打击，让传统经典的打分算法都沦为到非精准打分的环节了，哎，英雄迟暮。","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492732,"discussion_content":"1.是的。还是为了快速截断。如果在高质量文档的索引中也有足够的候选集，那么其实我们也不需要检索完全部文档，因此对于高质量索引，依然采用根据静态质量降序，是能有加速效果的。\n2.的确是这样的，现在的召回环节中，就有用逻辑回归进行截断的，当然，这个环节也有人叫做“粗排”环节。不过历史是相似的，在机器学习出来之前，bm25就是精排；在机器学习出来后，bm25就变成粗排了；同理，在深度学习出来以后，机器学习就可以变成粗排了。说不定未来哪天，深度学习也会变成粗排。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587530629,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":387253,"user_name":"庄墨寒","can_delete":false,"product_type":"c1","uid":1063970,"ip_address":"浙江","ucode":"BBD9EFA891BF06","user_header":"https://static001.geekbang.org/account/avatar/00/10/3c/22/9024c062.jpg","comment_is_top":false,"comment_ctime":1706779305,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"很好的课程，回答了我对搜索引擎诸多忙点。点赞。","like_count":0},{"had_liked":false,"id":375065,"user_name":"Trent","can_delete":false,"product_type":"c1","uid":1113467,"ip_address":"上海","ucode":"779CF5EA0991E1","user_header":"https://static001.geekbang.org/account/avatar/00/10/fd/7b/89bc309e.jpg","comment_is_top":false,"comment_ctime":1684854998,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"非精确排序以静态得分作为截断依据会降低多样性和新鲜度以及相关心。如何才能够平衡性能和上述指标。","like_count":0},{"had_liked":false,"id":372628,"user_name":"ifelse","can_delete":false,"product_type":"c1","uid":2550743,"ip_address":"浙江","ucode":"D0565908C99695","user_header":"https://static001.geekbang.org/account/avatar/00/26/eb/d7/90391376.jpg","comment_is_top":false,"comment_ctime":1681360311,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":3,"score":3,"product_id":100048401,"comment_content":"学习打卡","like_count":0},{"had_liked":false,"id":349967,"user_name":"阿甘","can_delete":false,"product_type":"c1","uid":1057843,"ip_address":"","ucode":"BC93175B70E05D","user_header":"https://static001.geekbang.org/account/avatar/00/10/24/33/bcf37f50.jpg","comment_is_top":false,"comment_ctime":1656474114,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"是不是可以理解召回阶段一般是静态打分，也可以简单的动态打分，而精排阶段一般是动态打分。","like_count":0},{"had_liked":false,"id":334520,"user_name":"阿甘","can_delete":false,"product_type":"c1","uid":1057843,"ip_address":"","ucode":"BC93175B70E05D","user_header":"https://static001.geekbang.org/account/avatar/00/10/24/33/bcf37f50.jpg","comment_is_top":false,"comment_ctime":1644983337,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"在上一篇文章的时候就有这个疑问：为什么不把topK过程离线处理，直接在posting list就按照scope排好序，到时候直接截断就可以了。这样看起来topK是一个离线排序的召回过程，性能会比在线打分排序截断好很多，不过缺点也确实就在他是离线处理的，没法跟用户查询时候的上下文（query词，用户画像，context如地理位置啥的）联合打分排序，不过这个过程可以放在后面的精排过程（一般是模型）处理。","like_count":0},{"had_liked":false,"id":209407,"user_name":"奕","can_delete":false,"product_type":"c1","uid":1005391,"ip_address":"","ucode":"73CEA468CE70C3","user_header":"https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg","comment_is_top":false,"comment_ctime":1587546111,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"第一步，我们取出这两个关键词的 posting list，但不直接截断；第二步，我们对这两个 posting list 归并排序。留下分数和文档 ID 都相同的条目作为结果集合，当结果集合中的条目达到 k 个时，\n--------------------------------------------------\n这里面为什么也要要求分数也相当呢？ \n如果一个文档对于 关键词 A 的分是4，对于B的是5，那不就是把这个文档过滤掉了？\n归并的时候找到前 k 个文档 ID 相同的不就可以了吗？","like_count":0},{"had_liked":false,"id":372628,"user_name":"ifelse","can_delete":false,"product_type":"c1","uid":2550743,"ip_address":"浙江","ucode":"D0565908C99695","user_header":"https://static001.geekbang.org/account/avatar/00/26/eb/d7/90391376.jpg","comment_is_top":false,"comment_ctime":1681360311,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":3,"score":3,"product_id":100048401,"comment_content":"学习打卡","like_count":0},{"had_liked":false,"id":349967,"user_name":"阿甘","can_delete":false,"product_type":"c1","uid":1057843,"ip_address":"","ucode":"BC93175B70E05D","user_header":"https://static001.geekbang.org/account/avatar/00/10/24/33/bcf37f50.jpg","comment_is_top":false,"comment_ctime":1656474114,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"是不是可以理解召回阶段一般是静态打分，也可以简单的动态打分，而精排阶段一般是动态打分。","like_count":0},{"had_liked":false,"id":334520,"user_name":"阿甘","can_delete":false,"product_type":"c1","uid":1057843,"ip_address":"","ucode":"BC93175B70E05D","user_header":"https://static001.geekbang.org/account/avatar/00/10/24/33/bcf37f50.jpg","comment_is_top":false,"comment_ctime":1644983337,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"在上一篇文章的时候就有这个疑问：为什么不把topK过程离线处理，直接在posting list就按照scope排好序，到时候直接截断就可以了。这样看起来topK是一个离线排序的召回过程，性能会比在线打分排序截断好很多，不过缺点也确实就在他是离线处理的，没法跟用户查询时候的上下文（query词，用户画像，context如地理位置啥的）联合打分排序，不过这个过程可以放在后面的精排过程（一般是模型）处理。","like_count":0},{"had_liked":false,"id":209407,"user_name":"奕","can_delete":false,"product_type":"c1","uid":1005391,"ip_address":"","ucode":"73CEA468CE70C3","user_header":"https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg","comment_is_top":false,"comment_ctime":1587546111,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"第一步，我们取出这两个关键词的 posting list，但不直接截断；第二步，我们对这两个 posting list 归并排序。留下分数和文档 ID 都相同的条目作为结果集合，当结果集合中的条目达到 k 个时，\n--------------------------------------------------\n这里面为什么也要要求分数也相当呢？ \n如果一个文档对于 关键词 A 的分是4，对于B的是5，那不就是把这个文档过滤掉了？\n归并的时候找到前 k 个文档 ID 相同的不就可以了吗？","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":243664,"discussion_content":"是这样的，在静态质量得分的场景中，一个文档的得分确定了以后，那么它在A和B的posting list中的得分一定是一样的。\n而且，我们先按得分排序，再按ID排序，你可以想象成相同得分的文档是一个整体元素，分数是key，这样我们可以先查询到相同的整体元素，在里面再查找相同的文档，这样检索效率更高。\n至于你说的是否分数可以不同，但ID相同就可以了，这其实是胜者表，我们要保证的是元素要有序可查。否则检索效率会很低。你看可以用我文中的例子看看，如果不用score做主key，那么文档1，2，3是乱序的，只能两两对比了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587555730,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}