{"id":418480,"title":"01 | 什么是大数据：从GFS到Dataflow，12年大数据生态演化图","content":"<p>你好，我是徐文浩。</p><p>在正式开始解读一篇篇论文之前，我想先让你来回答一个问题，那就是<strong>“大数据”技术到底是什么呢？</strong>处理100GB数据算是大数据技术吗？如果不算的话，那么处理1TB数据算是大数据吗？</p><p>“大数据”这个名字流行起来到现在，差不多已经有十年时间了。在这十年里，不同的人都按照自己的需要给大数据编出了自己的解释。有些解释很具体，来自于一线写Java代码的工程师，说用Hadoop处理数据就是大数据；有些解释很高大上，来自于市场上靠发明大词儿为生的演说家，说我们能采集和处理全量的数据就是大数据，如果只能采集到部分数据，或者处理的时候要对数据进行采样，那就不是大数据。</p><p>其实，要想学好大数据，我们需要先<strong>正本清源</strong>，弄清楚大数据在技术上到底涵盖了些什么。所以今天这节课，我就从大数据技术的核心理念和历史脉络这两个角度，来带你理解下什么是大数据技术。</p><p>通过理解这两点，你就会对大数据技术有一个全面的认识。而这个认识，一方面呢，能让你始终围绕着大数据技术的核心理念，去做好技术开发工作，不至于跑偏；而另一方面呢，它能帮你在学习后面每一个知识点的时候，都能和其他部分建立联系，帮你加深对大数据技术的理解。</p><p>好了，那么下面，我们就先来一起看看，大数据的核心理念是什么。</p><!-- [[[read_end]]] --><h2>大数据技术的核心理念</h2><p>首先，让我们来看看Wikipedia里是怎么定义它的。“<a href=\"https://zh.wikipedia.org/wiki/%E5%A4%A7%E6%95%B8%E6%93%9A\">大数据</a>”是指传统数据处理应用软件时，不足以处理的大的或者复杂的数据集的术语。换句话说，就是技术上的老办法行不通了，必须使用新办法才能处理的数据就叫大数据。不过，这个定义似乎也是一个很模糊的描述性的定义，并没有告诉我们到底哪些技术算是“大数据”技术的范畴。</p><p>那么，在我看来，其实“大数据”技术的核心理念是非常清晰的，基本上可以被三个核心技术理念概括。</p><p><strong>第一个，是能够伸缩到一千台服务器以上的分布式数据处理集群的技术。</strong></p><p>在“大数据”这个理念出现之前，传统的并行数据库技术就已经在尝试处理海量的数据了。比如成立于1979年的Teradata公司，就是专门做数据仓库的。从公司名字上，你也能看出来那个时候他们就想要处理TB级别的数据。但是，这些并行数据库的单个集群往往也就是几十个服务器。</p><p>而在2003年Google发表了GFS的论文之后，我们才第一次看到了单个集群里就可以有上千个节点。集群规模有了数量级上的变化，也就把数据处理能力拉上了一个新的台阶。因为集群可以伸缩到上千，乃至上万个节点，让我们今天可以处理PB级别的数据，所以微信、Facebook这样十亿级别日活的应用，也能不慌不忙地处理好每天的数据。</p><p>当然，这个数量级上的变化，也给我们带来了大量新的技术挑战。而解决了这些挑战的种种技术方案，就是我们的“大数据”技术。</p><p><strong>第二个，是这个上千个节点的集群，是采用廉价的PC架构搭建起来的。</strong></p><p>事实上，今天跑在数据中心里的各个大数据集群，用的硬件设备和我拿来写这节课的笔记本电脑本质上是一样的。可能数据中心里的CPU强一点、内存大一点、硬盘多一些，但是我完全可以用几台家里的电脑组一个一样的集群出来。</p><p>在“大数据”技术里，不需要使用“神威·太湖之光”这样的超算，也不用IBM的大型机或者Sun公司的SPARC这样的小型机，同样也不需要EMC的专用存储设备。“大数据”技术在硬件层面，是完全架设在开放的PC架构下的，这就让任何一个新创的公司，都能够很容易地搭建起自己的集群。</p><p>而且，由于不需要购买昂贵的专属硬件或者存储设备，所以大数据技术很容易地在大大小小的公司之间散播开来，任何一个有兴趣的程序员都可以用自己的PC开发、测试贡献代码，使得整个技术的生态异常繁荣。</p><p><strong>最后一个，则是“把数据中心当作是一台计算机”（Datacenter as a Computer）。</strong></p><p>要知道，“大数据”技术的目标，是希望对于开发者来说，TA意识不到自己面对的是一个一千台服务器的集群，而是一台虚拟的“计算机”。使用了部署好的大数据的各种框架之后，开发者能够像面对单台计算机编程一样去写自己的代码，而不需要操心系统的可用性、数据的一致性之类的问题。</p><p>所有的“大数据”框架，都希望就算没有“大数据”底层技术知识的工程师，也能很容易地处理海量数据。</p><p><img src=\"https://static001.geekbang.org/resource/image/65/42/65571219d50694883a216ebd4e1d4b42.jpg?wh=2000x864\" alt=\"\"></p><p>大型集群让处理海量数据变得“可能”；基于开放的PC架构，让处理海量数据变得“便宜”；而优秀的封装和抽象，则是让处理海量数据变得“容易”。这也是现在谁都能用上大数据技术的基础。可以说，这三个核心技术理念，真正引爆了整个“大数据”技术，让整个技术生态异常繁荣。</p><h2>大数据技术的来龙与去脉</h2><p>看到这里，你可能要问了，这三个核心技术理念是从哪里来的呢？这些理念当然不是“机械降神”，凭空出现的。</p><p>事实上，可以说整个“大数据”领域的蓬勃发展，都来自于Google这家公司遇到的真实需求。我们今天看到的“大数据”技术，十有八九，都来自于Google公开发表的论文，然后再演变成一个个开源系统，让整个行业受益。可以说，Google是“大数据”领域的普罗米修斯。</p><p>而在这个过程中，整个技术的发展也并不是一个直线上升的状态：</p><ul>\n<li><strong>有争论</strong>，比如MapReduce的论文发表之后，数据库领域知名的科学家大卫·德维特（David DeWitt）就发表过一篇论文<a href=\"https://www.dcs.bbk.ac.uk/~dell/teaching/cc/paper/dbc08/dewitt_mr_db.pdf\">“MapReduce：A major step backwards”</a>，抨击MapReduce相比于并行数据库是一种倒退；</li>\n<li><strong>有妥协</strong>，比如，Bigtable不支持跨行事务也不支持SQL，就是一个明证。直到5年后发表的Megastore，他们才开始着手解决这两个问题；</li>\n<li><strong>更有不成功的尝试</strong>，典型的就是Sawzall和Pig，Google在发表MapReduce论文之前，就发表了Sawzall这个用来撰写MapReduce任务的DSL，Yahoo也很早就完成了对应的开源实现Apache Pig。但是10年后的今天，我们的主流选择是用SQL或者DataFrame，Pig的用户已经不多了，而Sawzall也没有再听Google提起过。</li>\n</ul><p>所以可以说，<strong>大数据技术的发展是一个非常典型的技术工程的发展过程</strong>，跟随这个脉络，我们可以看到工程师们对于技术的探索、选择过程，以及最终历史告诉我们什么是正确的选择。</p><p>那么接下来，我们就一起来看看整个“大数据技术”的历史脉络，一起来看看这一篇篇论文、一个个开源系统都是为什么会出现。</p><h3>需求起源</h3><p>我认为，Google能成为散播大数据火种的人，是有着历史的必然性的。</p><p>作为一个搜索引擎，Google在数据层面，面临着比任何一个互联网公司都更大的挑战。无论是Amazon这样的电商公司，还是Yahoo这样的门户网站，都只需要存储自己网站相关的数据。而Google，则是需要抓取所有网站的网页数据并存下来。</p><p>而且光存下来还不够，早在1999年，两个创始人就发表了PageRank的论文，也就是说，Google不只是简单地根据网页里面的关键字来排序搜索结果，而是要通过网页之间的反向链接关系，进行很多轮的迭代计算，才能最终确认排序。而不断增长的搜索请求量，让Google还需要有响应迅速的在线服务。</p><h3>三驾马车和基础设施</h3><p>由此一来，面对存储、计算和在线服务这三个需求，Google就在2003、2004以及2006年，分别抛出了三篇重磅论文。也就是我们常说的“大数据”的三驾马车：GFS、MapReduce和Bigtable。</p><p><strong>GFS</strong>的论文发表于2003年，它主要是解决了数据的<strong>存储</strong>问题。作为一个上千节点的分布式文件系统，Google可以把所有需要的数据都能很容易地存储下来。</p><p>然后，光存下来还不够，我们还要基于这些数据进行各种<strong>计算</strong>。这个时候，就轮到2004年发表的<strong>MapReduce</strong>出场了。通过借鉴Lisp，Google利用简单的Map和Reduce两个函数，对于海量数据计算做了一次抽象，这就让“处理”数据的人，不再需要深入掌握分布式系统的开发了。而且他们推出的PageRank算法，也可以通过多轮的MapReduce的迭代来实现。</p><p>这样，无论是GFS存储数据，还是MapReduce处理数据，系统的吞吐量都没有问题了，因为所有的数据都是<strong>顺序读写</strong>。但是这两个，其实都没有办法解决好数据的高性能<strong>随机读写</strong>问题。</p><p>因此，面对这个问题，2006年发表的<strong>Bigtable</strong>就站上了历史舞台了。它是直接使用GFS作为底层存储，来做好集群的分片调度，以及利用MemTable+SSTable的底层存储格式，来解决大集群、机械硬盘下的高性能的随机读写问题。</p><p>下图就展示了Google的三驾马车针对这三类问题的技术优缺点，你可以参考下。</p><h2><img src=\"https://static001.geekbang.org/resource/image/e0/32/e069a97c337d583yyddb87fe51992232.jpg?wh=1920x1279\" alt=\"图片\"></h2><p>到这里，GFS、MapReduce和Bigtable这三驾马车的论文，就完成了“存储”“计算”“实时服务”这三个核心架构的设计。不过你还要知道，这三篇论文其实还依赖了两个基础设施。</p><p>第一个是为了保障数据一致性的分布式锁。对于这个问题，Google在发表Bigtable的同一年，就发表了实现了Paxos算法的<strong>Chubby锁服务</strong>的论文（我会在基础知识篇“分布式锁Chubby”这一讲中为你详细解读这篇论文）。</p><p>第二个是数据怎么序列化以及分布式系统之间怎么通信。Google在前面的论文里都没有提到这一点，所以在基础知识篇的“通过Thrift序列化：我们要预知未来才能向后兼容吗？”我们会一起来看看Facebook在2007年发表的<strong>Thrift</strong>的相关论文。</p><blockquote>\n<p>小知识：实际上，Bigtable的开源实现HBase，就用了Thrift作为和外部多语言进行通信的协议。Twitter也开源了elephant-bird，使得Hadoop上的MapReduce可以方便地使用Thrift来进行数据的序列化。</p>\n</blockquote><p><img src=\"https://static001.geekbang.org/resource/image/da/28/daa602b79dacbd377f7242a3cf345728.jpg?wh=1920x734\" alt=\"图片\"></p><h3>OLAP和OLTP数据库</h3><p>可以说，GFS、MapReduce和Bigtable这三驾马车是为整个业界带来了火种，但是整个大数据领域的进化才刚刚开始。事实上，不管是GFS也好，MapReduce也好，还是Bigtable也好，在那个时候，它们都还是很糙的系统设计。</p><p>这里，我们先来看下MapReduce，作为一个“计算”引擎，它开始朝着以下方式进化。</p><blockquote>\n<p>补充：作为存储的GFS，Google并没有公开后续的Colossus系统的论文，而且GFS要优化的一致性问题，其实在从BigTable到Spanner的进化过程中，就已经被彻底讲清楚了，所以在课程里我们就先按下不表了。</p>\n</blockquote><p>首先是<strong>编程模型</strong>。MapReduce的编程模型还是需要工程师去写程序的，所以它进化的方向就是通过一门DSL，进一步降低写MapReduce的门槛。</p><p>虽然Google发表了Sawzall，Yahoo实现了Pig，但是在这个领域的第一阶段最终胜出的，是Facebook在2009年发表的<strong>Hive</strong>。Hive通过一门基本上和SQL差不多的HQL，大大降低了数据处理的门槛，从而成为了大数据数据仓库的事实标准。</p><p>其次是<strong>执行引擎</strong>。Hive虽然披上了一个SQL的皮，但是它的底层仍然是一个个MapReduce的任务，所以延时很高，没法当成一个交互式系统来给数据分析师使用。于是Google又在2010年，发表了<strong>Dremel</strong>这个交互式查询引擎的论文，采用数据列存储+并行数据库的方式。这样一来，Dremel不仅有了一个SQL的皮，还进一步把MapReduce这个执行引擎给替换掉了。</p><p>最后是<strong>多轮迭代问题</strong>。在MapReduce这个模型里，一个MapReduce就要读写一次硬盘，而且Map和Reduce之间的数据通信，也是先要落到硬盘上的。这样，无论是复杂一点的Hive SQL，还是需要进行上百轮迭代的机器学习算法，都会浪费非常多的硬盘读写。</p><p>于是和Dremel论文发表的同一年，来自Berkeley的博士生马泰·扎哈里亚（Matei Zaharia），就发表了<strong>Spark</strong>的论文，通过把数据放在内存而不是硬盘里，大大提升了分布式数据计算性能。</p><p>所以到这里，你可以看到，围绕MapReduce，整个技术圈都在不断优化和迭代计算性能，Hive、Dremel和Spark分别从<strong>“更容易写程序”“查询响应更快”“更快的单轮和多轮迭代”</strong>的角度，完成了对MapReduce的彻底进化。</p><p>好了，花开两朵，各表一枝。看完了MapReduce这头，我们再来看看Bigtable那一头。</p><p>作为一个“在线服务”的数据库，Bigtable的进化是这样的：</p><ul>\n<li>首先是<strong>事务问题和Schema问题</strong>。Google先是在2011年发表了<strong>Megastore</strong>的论文，在Bigtable之上，实现了类SQL的接口，提供了Schema，以及简单的跨行事务。如果说Bigtable为了伸缩性，放弃了关系型数据库的种种特性。那么Megastore就是开始在Bigtable上逐步弥补关系型数据库的特性。</li>\n<li>其次是<strong>异地多活和跨数据中心问题</strong>。Google在2012年发表的<strong>Spanner</strong>，能够做到“全局一致性”。这样，就算是基本解决了这两个问题，第一次让我们有一个“全球数据库”。</li>\n</ul><p><img src=\"https://static001.geekbang.org/resource/image/cc/d5/ccc40c7c9770f7e82594cb9d5dd399d5.jpg?wh=2000x1780\" alt=\"\" title=\"一个新系统的设计当然不能用一句话概括[br]但是任何一个新系统都是为了解决前一个系统的不足之处\"></p><p>我在这里放了一张图，你可以看到在大数据领域里，MapReduce和Bigtable是怎么通过前面说的节点一步步进化下去的。实际上，如果说MapReduce对应的迭代进行，是在不断优化OLAP类型的数据处理性能，那么Bigtable对应的进化，则是在保障伸缩性的前提下，获得了更多的关系型数据库的能力。</p><h3>实时数据处理的抽象进化</h3><p>这样，从MapReduce到Dremel，我们查询数据的响应时间就大大缩短了。但是计算的数据仍然是固定的、预先确定的数据，这样系统往往有着大到数小时、小到几分钟的数据延时。</p><p>所以，为了解决好这个问题，流式数据处理就走上了舞台。</p><p>首先是Yahoo在2010年发表了<strong>S4</strong>的论文，并在2011年开源了S4。而几乎是在同一时间，Twitter工程师南森·马茨（Nathan Marz）以一己之力开源了<strong>Storm</strong>，并且在很长一段时间成为了工业界的事实标准。和GFS一样，Storm还支持“至少一次”（At-Least-Once）的数据处理。另外，基于Storm和MapReduce，南森更是提出了<strong>Lambda架构</strong>，它可以称之为是第一个“流批协同”的大数据处理架构。</p><p>接着在2011年，Kafka的论文也发表了。最早的Kafka其实只是一个“消息队列”，看起来它更像是Scribe这样进行数据传输组件的替代品。但是由于Kafka里发送的消息可以做到“正好一次”（Exactly-Once），所以大家就动起了在上面直接解决Storm解决不好的消息重复问题的念头。于是，Kafka逐步进化出了Kafka Streams这样的实时数据处理方案。而后在2014年，Kafka的作者Jay Krepson提出了<strong>Kappa架构</strong>，这个可以被称之为第一代“流批一体”的大数据处理架构。</p><p>看到这里，你会发现大数据的流式处理似乎没有Google什么事儿。的确，在流式数据处理领域，Google发表的FlumeJava和MillWheel的论文，并没有像前面的三驾马车或者Spanner的影响力那么大。</p><p>但是在2015年，Google发表的<strong>Dataflow的模型</strong>，可以说是对于流式数据处理模型做出了最好的总结和抽象。一直到现在，Dataflow就成为了真正的“流批一体”的大数据处理架构。而后来开源的Flink和Apache Beam，则是完全按照Dataflow的模型实现的了。</p><p><img src=\"https://static001.geekbang.org/resource/image/0f/b9/0f55142af70b3f40fa5b9b8a3f24c9b9.jpg?wh=1920x1709\" alt=\"图片\"></p><p>这里，我把这些论文的前后之间的脉络联系专门做了一张图，放在了下面。当你对某一篇论文感到困惑的时候，就可以去翻看它前后对应的论文，找到对应问题的来龙去脉。</p><p><img src=\"https://static001.geekbang.org/resource/image/a8/1f/a898bc57b976a8a6e10b84507c4ce81f.jpg?wh=2000x1780\" alt=\"\" title=\"简化过的大数据论文脉络关系，实际的整个大数据领域中会更深入、细致和复杂\"></p><h3>将所有服务器放在一起的资源调度</h3><p>到了现在，随着“大数据领域”本身的高速发展，数据中心里面的服务器越来越多，我们对于数据一致性的要求也越来越高。</p><p>那么，为了解决一致性问题，我们就有了<strong>基于Paxos协议的分布式锁</strong>。但是Paxos协议的性能很差，于是有了进一步的<strong>Multi-Paxos协议</strong>。</p><p>而接下来的问题就是，Paxos协议并不容易理解，于是就有了<strong>Raft</strong>这个更容易理解的算法的出现。Kubernetes依赖的etcd就是用Raft协议实现的，我们在后面的资源调度篇里，会一起来看一下Raft协议到底是怎么实现的，以及现代分布式系统依赖的基础设施是什么样子的。</p><p>然后，也正是因为数据中心里面的服务器越来越多，我们会发现原有的系统部署方式越来越浪费。</p><p>原先我们一般是一个计算集群独占一系列服务器，而往往很多时候，我们的服务器资源都是闲置的。这在服务器数量很少的时候确实不太要紧，但是，当我们有数百乃至数千台服务器的时候，浪费的硬件和电力成本就成为不能承受之重了。</p><p>于是，尽可能用满硬件资源成为了刚需。由此一来，我们对于整个分布式系统的视角，也从虚拟机转向了<strong>容器</strong>，这也是Kubernetes这个系统的由来。在后面的资源调度篇中，我们就会一起来深入看看，Kubernetes这个更加抽象、全面的资源管理和调度系统。</p><h2>小结</h2><p>最后，我把在这个课程中会解读到的论文清单列在了下面，供你作为一个索引。</p><p><img src=\"https://static001.geekbang.org/resource/image/fd/e0/fdc694d707095e8d73dc18521676c0e0.jpg?wh=2000x1725\" alt=\"\"></p><p>我在这节课里提到的这十几篇论文，其实只是2003到2015年这12年的大数据发展的冰山一角。</p><p>还有许许多多值得一读的论文，比如针对Bigtable，你就可以还去读一下Cassandra和Dynamo，这样思路略有不同的分布式数据的论文；针对Borg和Kubernetes，你可以去看看Mesos这个调度系统的论文又是什么样的。网上更有“开源大数据架构的100篇论文”这样的文章，如果你想深耕大数据领域，也可以有选择地多读一些其中的论文。</p><h2>推荐阅读</h2><p>如果你觉得今天的这一讲学完后还不够过瘾，我推荐你可以读一下<a href=\"http://www.cs.unibo.it/~danilo.montesi/CBD/Articoli/SurveyBigData.pdf\">“Big Data: A Survey”</a>这篇综述文章，可以让你更加深入“大数据”技术的全貌。另外，学完了这门课程之后，如果你还想更加深入地了解更多的大数据技术，你可以对着“Big Data: A Survey”这篇论文按图索骥，研读更多里面引用到的论文。</p><h2>课后思考</h2><p>除了这些论文之外，你觉得还有哪些论文和开源框架，对于大数据领域的发展是有重要贡献的呢？你觉得它们主要是解决了什么样的重要问题？</p><p>欢迎留言和我分享你的思考和疑惑，你也可以把今天的内容分享给你的朋友，和他一起学习进步。</p>","comments":[{"had_liked":false,"id":312244,"user_name":"Ball","can_delete":false,"product_type":"c1","uid":1521451,"ip_address":"","ucode":"1EE949E68D84CA","user_header":"https://static001.geekbang.org/account/avatar/00/17/37/2b/b32f1d66.jpg","comment_is_top":false,"comment_ctime":1631701780,"is_pvip":false,"replies":[{"id":"113181","content":"Ball同学，<br><br>你好，收到这个留言很高兴，也希望后续的内容能对你有帮助。","user_name":"作者回复","comment_id":312244,"uid":"1053568","ip_address":"","utype":1,"ctime":1631771392,"user_name_real":"徐文浩"}],"discussion_count":1,"race_medal":0,"score":"78941113108","product_id":100091101,"comment_content":"这篇文章很赞！通读整篇文章最大的收获是从全局视角了解了大数据经典论文、关键数据系统和重要事件之间的关系。感谢作者如此详细的列举了大数据相关的论文、数据系统和历史事件，还仔细梳理了他们之间的逻辑关系。<br>之前对大数据的认知就是零散的几篇论文以及对少数大数据组件的深入了解，对整个大数据生态的全貌还是一无所知。这篇文章让我从纵向的时间轴和横向的各个数据系统的发展竞争两个角度，对整个大数据生态有了新的认识，值回票价了！","like_count":19,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526909,"discussion_content":"Ball同学，\n\n你好，收到这个留言很高兴，也希望后续的内容能对你有帮助。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631771392,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":312602,"user_name":"pedro","can_delete":false,"product_type":"c1","uid":1200704,"ip_address":"","ucode":"F40C839DDFD599","user_header":"https://static001.geekbang.org/account/avatar/00/12/52/40/e57a736e.jpg","comment_is_top":false,"comment_ctime":1631886522,"is_pvip":false,"replies":[{"id":"113290","content":"感谢支持，欢迎和我一起坚持完整个专栏","user_name":"作者回复","comment_id":312602,"uid":"1053568","ip_address":"","utype":1,"ctime":1631940611,"user_name_real":"徐文浩"}],"discussion_count":1,"race_medal":0,"score":"61761428666","product_id":100091101,"comment_content":"这讲的实在是太好了，很多大数据领域的教授都未必能写出如此提纲挈领的综述！<br><br>追追追！！！","like_count":15,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527042,"discussion_content":"感谢支持，欢迎和我一起坚持完整个专栏","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631940611,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":312246,"user_name":"Condor Hero","can_delete":false,"product_type":"c1","uid":1528334,"ip_address":"","ucode":"BD850FE812D22F","user_header":"https://static001.geekbang.org/account/avatar/00/17/52/0e/c5ff46d2.jpg","comment_is_top":false,"comment_ctime":1631702997,"is_pvip":true,"replies":[{"id":"113177","content":"Condor Hero同学，<br><br>你好，的确作为科普文看是不错。我会尽量减少对于各类知识的“前置依赖”，有需要依赖特定知识的时候也会尽量给出推荐可以补充阅读的基础知识。不过对于学习大数据来说，的确对于后端开发有一些基本认识会更有效率一些。","user_name":"作者回复","comment_id":312246,"uid":"1053568","ip_address":"","utype":1,"ctime":1631770923,"user_name_real":"徐文浩"}],"discussion_count":1,"race_medal":1,"score":"40286408661","product_id":100091101,"comment_content":"对于前端来讲发现当做科普文来读不错哎，不知道后面内容会不会很难。","like_count":10,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526910,"discussion_content":"Condor Hero同学，\n\n你好，的确作为科普文看是不错。我会尽量减少对于各类知识的“前置依赖”，有需要依赖特定知识的时候也会尽量给出推荐可以补充阅读的基础知识。不过对于学习大数据来说，的确对于后端开发有一些基本认识会更有效率一些。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631770923,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":314039,"user_name":"Jeffpan","can_delete":false,"product_type":"c1","uid":1025607,"ip_address":"","ucode":"C476849A845B3D","user_header":"https://static001.geekbang.org/account/avatar/00/0f/a6/47/73a5aa22.jpg","comment_is_top":false,"comment_ctime":1632815236,"is_pvip":false,"replies":[{"id":"113913","content":"👍","user_name":"作者回复","comment_id":314039,"uid":"1053568","ip_address":"","utype":1,"ctime":1633162964,"user_name_real":"徐文浩"}],"discussion_count":1,"race_medal":0,"score":"23107651716","product_id":100091101,"comment_content":"围绕着批处理，流式处理，分布式协议以及资源调度系统来把握整个文章发展，这些技术的发展无外乎想用更少的资源去做更多的事情，同时可以更加优快好省地去发展业务，节约开发人员和企业的时间与成本。","like_count":5,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527553,"discussion_content":"👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633162964,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":312886,"user_name":"冯磊","can_delete":false,"product_type":"c1","uid":1855112,"ip_address":"","ucode":"4FFB8B984269FB","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIYj6Zv3ibicLebxo7lsPMEwpBynHkYp8pLc3FcltUfmOBSRxpmicEwIAgP9OvSKnGGdaxwsZ7yiciaSsQ/132","comment_is_top":false,"comment_ctime":1632104225,"is_pvip":false,"replies":[{"id":"113940","content":"👍 一起加油呀。","user_name":"作者回复","comment_id":312886,"uid":"1053568","ip_address":"","utype":1,"ctime":1633167082,"user_name_real":"徐文浩"}],"discussion_count":1,"race_medal":0,"score":"18811973409","product_id":100091101,"comment_content":"从大数据开发到数仓到再用户画像，中间接触了十多个框架了。比较常用的是spark,kafka,presto,kudu了，从调用API到分析源码，这条路很艰难。<br>不过最终也终于把spark和kafka的源码分析完了，但也只能到What这一步。老师说得很对，只有研究明白论文才会懂得Why，希望能跟上老师脚步让自己再上一个台阶。<br>同时，自己近期也在研究分布式理论，也学了极客的很多优质课程。我组建了一个优质分享群，感兴趣可以加我VX: aacc6688521","like_count":5,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527147,"discussion_content":"👍 一起加油呀。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633167082,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":312569,"user_name":"zhanyd","can_delete":false,"product_type":"c1","uid":1073845,"ip_address":"","ucode":"4C994EE512A3C4","user_header":"https://static001.geekbang.org/account/avatar/00/10/62/b5/4159fa05.jpg","comment_is_top":false,"comment_ctime":1631867796,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"18811736980","product_id":100091101,"comment_content":"如果说使用各种系统是学习“招式”，那么读这些基础的论文就练“内功”，“招式”容易过时，但是“内功”却不会，这是一种可以迁移的能力，有了“内功”以后学习新的“招式”就会快很多。","like_count":4},{"had_liked":false,"id":313372,"user_name":"vkingnew","can_delete":false,"product_type":"c1","uid":1124637,"ip_address":"","ucode":"16E37A23BFE579","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJoiar0OoeEdc1l1UiaKKLjKblibqda3fxzibXibiahMqsvAanS3Gzu1CF4xupc6wPzmbpQqr2MMWkGeXeA/132","comment_is_top":false,"comment_ctime":1632400067,"is_pvip":false,"replies":[{"id":"113821","content":"vkingnew同学，你好，<br><br>过去20年实际互联网工程届主流的解决方案还是 OLAP和OLTP分开，两边数据通过ETL或者其他各种方式同步。并且不断优化的是能够缩短两边同步的Latency。现在所谓的很多HTAP方案其实也是这样一个工程方案，而不是在数据库的存储引擎上有什么新发明。<br><br>我自己个人观点也是 HTAP 太理想化了，不过这个事情很难说，大部分工程师也没有想到Spanner的出现。","user_name":"作者回复","comment_id":313372,"uid":"1053568","ip_address":"","utype":1,"ctime":1632917809,"user_name_real":"徐文浩"}],"discussion_count":2,"race_medal":0,"score":"14517301955","product_id":100091101,"comment_content":"可以补充讲讲HTAP的往事","like_count":3,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527330,"discussion_content":"vkingnew同学，你好，\n\n过去20年实际互联网工程届主流的解决方案还是 OLAP和OLTP分开，两边数据通过ETL或者其他各种方式同步。并且不断优化的是能够缩短两边同步的Latency。现在所谓的很多HTAP方案其实也是这样一个工程方案，而不是在数据库的存储引擎上有什么新发明。\n\n我自己个人观点也是 HTAP 太理想化了，不过这个事情很难说，大部分工程师也没有想到Spanner的出现。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1632917809,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":1113571,"avatar":"https://static001.geekbang.org/account/avatar/00/10/fd/e3/a9d21a3b.jpg","nickname":"Kuqi","note":"","ucode":"42143DAB548FCE","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":536915,"discussion_content":"将一个工程方案取了一个名字，当然名字出来后以后方案内在也会变","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1638891229,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":527330,"ip_address":""},"score":536915,"extra":""}]}]},{"had_liked":false,"id":312926,"user_name":"Renaissance","can_delete":false,"product_type":"c1","uid":1367198,"ip_address":"","ucode":"26BD4336E4B677","user_header":"https://static001.geekbang.org/account/avatar/00/14/dc/9e/3092d6a7.jpg","comment_is_top":false,"comment_ctime":1632125575,"is_pvip":false,"replies":[{"id":"113938","content":"Dataflow是Google发表的对于实时数据处理或者说通用数据处理相对总结性的论文。<br><br>但是和Google的很多系统一样，Dataflow只有论文，Google并没有把代码开源出来。只开源了一个类似于标准接口层的Apache Beam。<br><br>Flink可能是现在最接近Dataflow论文原始实现的一个系统了。<br><br>对于AWS，抱歉一方面大部分大数据论文都来自于Google，另一方面我们也重度使用GCP而不是AWS，所以AWS的产品我并不熟悉。","user_name":"作者回复","comment_id":312926,"uid":"1053568","ip_address":"","utype":1,"ctime":1633166990,"user_name_real":"徐文浩"}],"discussion_count":1,"race_medal":0,"score":"14517027463","product_id":100091101,"comment_content":"老师的那张图里面，dataflow和flink两个分支具体有什么区别呢？另外一个问题，对应的AWS产品有哪些呢？我看图里面只画出来了Google cloud的一些产品，不知道老师能否告知一二。","like_count":3,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527164,"discussion_content":"Dataflow是Google发表的对于实时数据处理或者说通用数据处理相对总结性的论文。\n\n但是和Google的很多系统一样，Dataflow只有论文，Google并没有把代码开源出来。只开源了一个类似于标准接口层的Apache Beam。\n\nFlink可能是现在最接近Dataflow论文原始实现的一个系统了。\n\n对于AWS，抱歉一方面大部分大数据论文都来自于Google，另一方面我们也重度使用GCP而不是AWS，所以AWS的产品我并不熟悉。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633166990,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":312430,"user_name":"Geek_40bb5c","can_delete":false,"product_type":"c1","uid":1535926,"ip_address":"","ucode":"BE55312BD7D21E","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJ6Qpib06NaI4cIf8VFMFYfa8bVve4uxab1qytsXZoRbCBWgK1cyRt7PZRQHicC9X8PPLy1kibwLZ35Q/132","comment_is_top":false,"comment_ctime":1631796959,"is_pvip":false,"replies":[{"id":"113292","content":"那就趁着这个机会多读几篇吧，读论文是一种很有意思的思维实验","user_name":"作者回复","comment_id":312430,"uid":"1053568","ip_address":"","utype":1,"ctime":1631940803,"user_name_real":"徐文浩"}],"discussion_count":4,"race_medal":0,"score":"10221731551","product_id":100091101,"comment_content":"本科研究生都是大数据专业，却一篇大数据论文都没看过，惭愧惭愧。","like_count":2,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526965,"discussion_content":"那就趁着这个机会多读几篇吧，读论文是一种很有意思的思维实验","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631940803,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1310798,"avatar":"https://static001.geekbang.org/account/avatar/00/14/00/4e/be2b206b.jpg","nickname":"吴小智","note":"","ucode":"C7C9F58B5C9F7B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":395962,"discussion_content":"老哥，请问是如何毕业的？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1632369013,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1535926,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJ6Qpib06NaI4cIf8VFMFYfa8bVve4uxab1qytsXZoRbCBWgK1cyRt7PZRQHicC9X8PPLy1kibwLZ35Q/132","nickname":"Geek_40bb5c","note":"","ucode":"BE55312BD7D21E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1310798,"avatar":"https://static001.geekbang.org/account/avatar/00/14/00/4e/be2b206b.jpg","nickname":"吴小智","note":"","ucode":"C7C9F58B5C9F7B","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":556086,"discussion_content":"大学中学习方向和研究方向没有多大关系，老师干啥就干啥。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1647196077,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":395962,"ip_address":""},"score":556086,"extra":""}]},{"author":{"id":1200704,"avatar":"https://static001.geekbang.org/account/avatar/00/12/52/40/e57a736e.jpg","nickname":"pedro","note":"","ucode":"F40C839DDFD599","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":394449,"discussion_content":"铁子，那你是怎么毕业的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631885491,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":324865,"user_name":"可加","can_delete":false,"product_type":"c1","uid":1219553,"ip_address":"","ucode":"C0DB61661144DA","user_header":"https://static001.geekbang.org/account/avatar/00/12/9b/e1/aa0af424.jpg","comment_is_top":false,"comment_ctime":1638694268,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5933661564","product_id":100091101,"comment_content":"总结的非常好，感谢老师整理的图<br>想问问Google 的 F1 query 为什么没有加进去呀，F1 query 是 dremel 的升级版吧","like_count":1},{"had_liked":false,"id":314721,"user_name":"1.5-4-4-3-72","can_delete":false,"product_type":"c1","uid":2617245,"ip_address":"","ucode":"D1BB7DB52A5386","user_header":"https://static001.geekbang.org/account/avatar/00/27/ef/9d/9180a6ed.jpg","comment_is_top":false,"comment_ctime":1633351581,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5928318877","product_id":100091101,"comment_content":"总结大数据的发展历程是:<br>1. 用更多的资源完成单机不可能的事<br>2. 更好，更快的完成<br>3. 提高资源利用率","like_count":2},{"had_liked":false,"id":312786,"user_name":"一步","can_delete":false,"product_type":"c1","uid":1005391,"ip_address":"","ucode":"73CEA468CE70C3","user_header":"https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg","comment_is_top":false,"comment_ctime":1632018501,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"5926985797","product_id":100091101,"comment_content":"核心理念：是一个集群，这个集群可以利用廉价的 PC 机扩展到上千个节点，做为一个整体对外提供服务","like_count":1},{"had_liked":false,"id":312747,"user_name":"巴普洛夫的","can_delete":false,"product_type":"c1","uid":1787466,"ip_address":"","ucode":"0FE795ECA04B1D","user_header":"https://static001.geekbang.org/account/avatar/00/1b/46/4a/b0cd391e.jpg","comment_is_top":false,"comment_ctime":1631964461,"is_pvip":false,"replies":[{"id":"113332","content":"实战是需要的，如果完全没有实际体验过大数据的开发，可能很多概念理解起来会更难。<br><br>一个办法是现在很多云服务都有免费的额度，比如Google Cloud就可以有免费300美元的额度，你可以直接在上面试着跑一些示例程序找找感觉。","user_name":"作者回复","comment_id":312747,"uid":"1053568","ip_address":"","utype":1,"ctime":1632038314,"user_name_real":"徐文浩"}],"discussion_count":1,"race_medal":0,"score":"5926931757","product_id":100091101,"comment_content":"没有做过大数据的人，是不是要实战一些项目了解一下概念","like_count":1,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527098,"discussion_content":"实战是需要的，如果完全没有实际体验过大数据的开发，可能很多概念理解起来会更难。\n\n一个办法是现在很多云服务都有免费的额度，比如Google Cloud就可以有免费300美元的额度，你可以直接在上面试着跑一些示例程序找找感觉。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1632038314,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":312327,"user_name":"bearlu","can_delete":false,"product_type":"c1","uid":1030862,"ip_address":"","ucode":"14F260C8B24E27","user_header":"https://static001.geekbang.org/account/avatar/00/0f/ba/ce/fd45714f.jpg","comment_is_top":false,"comment_ctime":1631752250,"is_pvip":true,"replies":[{"id":"113174","content":"bearlu同学，<br><br>你好，很好的建议，我在基础部分之后，写篇如何读论文的加餐","user_name":"作者回复","comment_id":312327,"uid":"1053568","ip_address":"","utype":1,"ctime":1631770345,"user_name_real":"徐文浩"}],"discussion_count":2,"race_medal":0,"score":"5926719546","product_id":100091101,"comment_content":"老师，希望能加上如何阅读论文的技巧。","like_count":1,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526938,"discussion_content":"bearlu同学，\n\n你好，很好的建议，我在基础部分之后，写篇如何读论文的加餐","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631770345,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1111985,"avatar":"https://static001.geekbang.org/account/avatar/00/10/f7/b1/982ea185.jpg","nickname":"Frank","note":"","ucode":"9DADD72C193296","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":397394,"discussion_content":"期待","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1632617722,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":347439,"user_name":"Chloe","can_delete":false,"product_type":"c1","uid":1004953,"ip_address":"","ucode":"C4848ED5B35752","user_header":"https://static001.geekbang.org/account/avatar/00/0f/55/99/4bdadfd3.jpg","comment_is_top":false,"comment_ctime":1654043364,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1654043364","product_id":100091101,"comment_content":"文章很赞，描述了整个冰山的轮廓，让我忍不住要继续读下去，一探究竟 ：D","like_count":0},{"had_liked":false,"id":338878,"user_name":"小安","can_delete":false,"product_type":"c1","uid":2785570,"ip_address":"","ucode":"B40D4D34A46AB3","user_header":"https://static001.geekbang.org/account/avatar/00/2a/81/22/4b3ec312.jpg","comment_is_top":false,"comment_ctime":1647769131,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1647769131","product_id":100091101,"comment_content":"以前对大数据只是一知半解，工作也只是应用了一部分的大数据组件，这次听了以后有了全面的了解，会继续听下去，谢谢作者的解读","like_count":0},{"had_liked":false,"id":331916,"user_name":"长脖子树","can_delete":false,"product_type":"c1","uid":1182802,"ip_address":"","ucode":"D9090EF67EEB1B","user_header":"https://static001.geekbang.org/account/avatar/00/12/0c/52/f25c3636.jpg","comment_is_top":false,"comment_ctime":1642870301,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1642870301","product_id":100091101,"comment_content":"非常棒的文章，了解了大数据技术的来龙去脉，很赞！","like_count":0},{"had_liked":false,"id":326742,"user_name":"zixuan","can_delete":false,"product_type":"c1","uid":1131300,"ip_address":"","ucode":"C72920DD05B074","user_header":"https://static001.geekbang.org/account/avatar/00/11/43/24/3f9f7c70.jpg","comment_is_top":false,"comment_ctime":1639651350,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1639651350","product_id":100091101,"comment_content":"很棒！不知道 Facebook的presto是在体系里的什么角色和位置？","like_count":0},{"had_liked":false,"id":325055,"user_name":"Leon","can_delete":false,"product_type":"c1","uid":2524788,"ip_address":"","ucode":"8849E1E2AA8E9E","user_header":"https://static001.geekbang.org/account/avatar/00/26/86/74/3903b3a6.jpg","comment_is_top":false,"comment_ctime":1638789498,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1638789498","product_id":100091101,"comment_content":"这一篇大数据历史读起来让人热血沸腾，世界上顶尖的公司、顶尖的工程师，共同发展起蓬勃的大数据技术，而很多人只是停留在应用阶段，有时间确实应该好好研读这些技术背后的论文。期待后面的内容！","like_count":0},{"had_liked":false,"id":323306,"user_name":"漫画火起","can_delete":false,"product_type":"c1","uid":2853921,"ip_address":"","ucode":"3335C963B6510E","user_header":"https://static001.geekbang.org/account/avatar/00/2b/8c/21/8947eab1.jpg","comment_is_top":false,"comment_ctime":1637828013,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1637828013","product_id":100091101,"comment_content":"对于初学者来说，能看到这样一篇好文章，详细地讲述了大数据的来龙去脉以及各个技术的进化方向，无疑对大数据领域有了大方向的把握，点赞！","like_count":0},{"had_liked":false,"id":320588,"user_name":"Jackey","can_delete":false,"product_type":"c1","uid":1063751,"ip_address":"","ucode":"125DE81993FEDD","user_header":"https://static001.geekbang.org/account/avatar/00/10/3b/47/f6c772a1.jpg","comment_is_top":false,"comment_ctime":1636388001,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1636388001","product_id":100091101,"comment_content":"刚刚转型大数据，这门课真是雪中送炭","like_count":1},{"had_liked":false,"id":318451,"user_name":"燕行","can_delete":false,"product_type":"c1","uid":1048380,"ip_address":"","ucode":"AE2BEFD3C5F31F","user_header":"https://static001.geekbang.org/account/avatar/00/0f/ff/3c/215aecca.jpg","comment_is_top":false,"comment_ctime":1635301491,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1635301491","product_id":100091101,"comment_content":"老师，您好：<br>我想请问一下，是能够扩展到一千台以上的分布式数据处理集群的技术。<br>其中一千台的量级是有什么实际的数据支持或参考文献吗？","like_count":0},{"had_liked":false,"id":316954,"user_name":"小豹哥","can_delete":false,"product_type":"c1","uid":1613919,"ip_address":"","ucode":"115FF45CAA6FAD","user_header":"https://static001.geekbang.org/account/avatar/00/18/a0/5f/cf72d453.jpg","comment_is_top":false,"comment_ctime":1634627392,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1634627392","product_id":100091101,"comment_content":"老师好，GFS处理并发写入和顺序写入是怎么实现的？对应hadoop的hdfs，客户端和namenode通信了数据存储的节点后，对数据进行分packet就直接开io流，依次在几个节点写入数据了，并没有体现并发写数据？还是说hdfs就没有实现并发写入，希望得到老师的解答","like_count":0},{"had_liked":false,"id":316953,"user_name":"haha橙子","can_delete":false,"product_type":"c1","uid":1547273,"ip_address":"","ucode":"36E805538FF716","user_header":"","comment_is_top":false,"comment_ctime":1634627134,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1634627134","product_id":100091101,"comment_content":"非技术野生产品表示买课的直接原因是想看看大佬们是怎么读论文、研究论文的，因为正在准备论文。虽已身处大数据为背景的公司几年，但是并没有人如此专业、系统、全面的为我们梳理过大数据及相关技术、工具的发展史、关联关系。收获颇丰，这么多年，看来要入门了【微笑】。技术小白表示老师您真的很厉害【点赞】~","like_count":0},{"had_liked":false,"id":314591,"user_name":"leon","can_delete":false,"product_type":"c1","uid":1217955,"ip_address":"","ucode":"97610F35D2543A","user_header":"https://static001.geekbang.org/account/avatar/00/12/95/a3/0a3cde60.jpg","comment_is_top":false,"comment_ctime":1633246735,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1633246735","product_id":100091101,"comment_content":"太棒了，提纲挈领，把大数据相关技术的来龙去脉梳理的一清二楚，光只一篇就值回票价","like_count":0},{"had_liked":false,"id":314245,"user_name":"leslie","can_delete":false,"product_type":"c1","uid":1324255,"ip_address":"","ucode":"798E7C1CC98CC2","user_header":"https://static001.geekbang.org/account/avatar/00/14/34/df/64e3d533.jpg","comment_is_top":false,"comment_ctime":1632911685,"is_pvip":false,"replies":[{"id":"113897","content":"感谢一直以来的支持，我会尽我所能保障出品质量的。","user_name":"作者回复","user_name_real":"徐文浩","uid":"1053568","ctime":1633159437,"ip_address":"","comment_id":314245,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1632911685","product_id":100091101,"comment_content":"整体底层过程和关键技术解决梳理了一遍，质量还是和之前的一样。","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527621,"discussion_content":"感谢一直以来的支持，我会尽我所能保障出品质量的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633159437,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":314021,"user_name":"曾轼麟","can_delete":false,"product_type":"c1","uid":1451391,"ip_address":"","ucode":"D418371AC11270","user_header":"https://static001.geekbang.org/account/avatar/00/16/25/7f/473d5a77.jpg","comment_is_top":false,"comment_ctime":1632806387,"is_pvip":false,"replies":[{"id":"113922","content":"我说说我的个人观点，不一定对。<br><br>Hive其实本身就是HQL以及怎么将HQL变成下面的计算引擎的执行计划，Hive on Spark说实话从整个技术演变的角度，相对来说还是不够重要，特点也不够多。","user_name":"作者回复","user_name_real":"徐文浩","uid":"1053568","ctime":1633165191,"ip_address":"","comment_id":314021,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1632806387","product_id":100091101,"comment_content":"老师第四张图有个点，后期其实演化出了Hive on spark之类的技术，使用Hive的语法转换，使用spark的计算引擎。","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527548,"discussion_content":"我说说我的个人观点，不一定对。\n\nHive其实本身就是HQL以及怎么将HQL变成下面的计算引擎的执行计划，Hive on Spark说实话从整个技术演变的角度，相对来说还是不够重要，特点也不够多。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633165191,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":313996,"user_name":"全有","can_delete":false,"product_type":"c1","uid":1488139,"ip_address":"","ucode":"D16B42B1F71E4E","user_header":"https://static001.geekbang.org/account/avatar/00/16/b5/0b/df89c357.jpg","comment_is_top":false,"comment_ctime":1632794502,"is_pvip":false,"replies":[{"id":"113930","content":"lambda架构需要有一个batch layer，定期利用batch layer重算数据，所以实时部分 at-least-once 带来的问题只需要容忍一段时间。<br><br>具体我会在Storm和Kafka部分讲解。","user_name":"作者回复","user_name_real":"徐文浩","uid":"1053568","ctime":1633166192,"ip_address":"","comment_id":313996,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1632794502","product_id":100091101,"comment_content":"至少一次和精准一次消息模型，为什么会成为lamda 架构和Kapa 架构的核心区分点","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527540,"discussion_content":"lambda架构需要有一个batch layer，定期利用batch layer重算数据，所以实时部分 at-least-once 带来的问题只需要容忍一段时间。\n\n具体我会在Storm和Kafka部分讲解。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633166192,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":313734,"user_name":"吴小智","can_delete":false,"product_type":"c1","uid":1310798,"ip_address":"","ucode":"C7C9F58B5C9F7B","user_header":"https://static001.geekbang.org/account/avatar/00/14/00/4e/be2b206b.jpg","comment_is_top":false,"comment_ctime":1632640738,"is_pvip":false,"replies":[{"id":"113826","content":"Percolator 这个系统高度和搜索引擎的索引更新相关，考虑到整个专栏的通用性，以及篇幅的限制，所以没有选择讲解这篇论文。","user_name":"作者回复","user_name_real":"徐文浩","uid":"1053568","ctime":1632918420,"ip_address":"","comment_id":313734,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1632640738","product_id":100091101,"comment_content":"没有 《Large-scale Incremental Processing Using Distributed Transactions and Notiﬁcations》 这个论文吗？","like_count":1,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527454,"discussion_content":"Percolator 这个系统高度和搜索引擎的索引更新相关，考虑到整个专栏的通用性，以及篇幅的限制，所以没有选择讲解这篇论文。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1632918420,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":313017,"user_name":"葛尧","can_delete":false,"product_type":"c1","uid":2766673,"ip_address":"","ucode":"6B2B9D3F969246","user_header":"https://static001.geekbang.org/account/avatar/00/2a/37/51/914db89c.jpg","comment_is_top":false,"comment_ctime":1632208650,"is_pvip":false,"replies":[{"id":"113928","content":"DEC可是小型机之王……<br>我觉得是需求驱动的，最早计算机是国防需求，这个是为什么IBM是那个时代的王者。<br>到了PC驱动就变成大量的中小商业公司和个人了，所以IBM就慢慢淡出了。<br>Google是因为要做搜索引擎，索引全网的所有数据的，而且因为早期没有融太多钱，也没有找到商业化的办法，所以通过技术上使用PC来解决大量问题，诞生了现在的大数据技术。","user_name":"作者回复","user_name_real":"徐文浩","uid":"1053568","ctime":1633165790,"ip_address":"","comment_id":313017,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1632208650","product_id":100091101,"comment_content":"单纯好奇，GFS作者Sanjay和Jeff在进去google之前也都在dec等商业机构工作过，但是不管是他们俩还是更多的在NASA、联合国等大数据需求旺盛的机构中工作的工程师，都没有开发出GFS、Mapreduce类似的系统，所以，why google？","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527199,"discussion_content":"DEC可是小型机之王……\n我觉得是需求驱动的，最早计算机是国防需求，这个是为什么IBM是那个时代的王者。\n到了PC驱动就变成大量的中小商业公司和个人了，所以IBM就慢慢淡出了。\nGoogle是因为要做搜索引擎，索引全网的所有数据的，而且因为早期没有融太多钱，也没有找到商业化的办法，所以通过技术上使用PC来解决大量问题，诞生了现在的大数据技术。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633165790,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":312875,"user_name":"Ryan Fu","can_delete":false,"product_type":"c1","uid":2733136,"ip_address":"","ucode":"805706B2161FDC","user_header":"https://static001.geekbang.org/account/avatar/00/29/b4/50/bac17db5.jpg","comment_is_top":false,"comment_ctime":1632086125,"is_pvip":false,"replies":[{"id":"113934","content":"一般叫做 cross-row transactions 或者 multi-row transactions。<br><br>当然还有更进一步的叫做 general-purpose transactions","user_name":"作者回复","user_name_real":"徐文浩","uid":"1053568","ctime":1633166659,"ip_address":"","comment_id":312875,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1632086125","product_id":100091101,"comment_content":"你好<br><br>請問”跨行事務操作”的原英文名詞是什麼<br>謝謝～","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527142,"discussion_content":"一般叫做 cross-row transactions 或者 multi-row transactions。\n\n当然还有更进一步的叫做 general-purpose transactions","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633166659,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":312820,"user_name":"Scott","can_delete":false,"product_type":"c1","uid":1014800,"ip_address":"","ucode":"7E57FDCB5E5D49","user_header":"https://static001.geekbang.org/account/avatar/00/0f/7c/10/165cb374.jpg","comment_is_top":false,"comment_ctime":1632039645,"is_pvip":false,"replies":[{"id":"113935","content":"我曾经也是pig的重度用户，团队里也是更多用pig。但是10年之后回头看，的确SQL作为业界标准才是正确的选择。跑去Apache看了一眼release notes，pig早就不更新了，最新版本也就是 0.18.0","user_name":"作者回复","user_name_real":"徐文浩","uid":"1053568","ctime":1633166746,"ip_address":"","comment_id":312820,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1632039645","product_id":100091101,"comment_content":"pig挺可惜的，我现在还是觉得这个最方便","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527123,"discussion_content":"我曾经也是pig的重度用户，团队里也是更多用pig。但是10年之后回头看，的确SQL作为业界标准才是正确的选择。跑去Apache看了一眼release notes，pig早就不更新了，最新版本也就是 0.18.0","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633166746,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1014800,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/7c/10/165cb374.jpg","nickname":"Scott","note":"","ucode":"7E57FDCB5E5D49","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":400132,"discussion_content":"我那会就是你team的呀，不过SQL还是要求数据比较结构化，pig啥数据都可以处理。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633177978,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":312692,"user_name":"那时刻","can_delete":false,"product_type":"c1","uid":1150927,"ip_address":"","ucode":"B0D150856C3A4A","user_header":"https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg","comment_is_top":false,"comment_ctime":1631944857,"is_pvip":false,"replies":[{"id":"113331","content":"你可以认为BigTable的单个Tablet的存储，就是一个LSM，其实也就是LevelDB","user_name":"作者回复","user_name_real":"徐文浩","uid":"1053568","ctime":1632038221,"ip_address":"","comment_id":312692,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1631944857","product_id":100091101,"comment_content":"请问老师，Bigtable 利用 MemTable+SSTable 的底层存储格式。这与LSM使用的Memtable与sstable是否一致呢？","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527082,"discussion_content":"你可以认为BigTable的单个Tablet的存储，就是一个LSM，其实也就是LevelDB","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1632038221,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":312630,"user_name":"Geek_143f57","can_delete":false,"product_type":"c1","uid":2030445,"ip_address":"","ucode":"868DA0E5529EAA","user_header":"https://static001.geekbang.org/account/avatar/00/1e/fb/6d/cfdf6156.jpg","comment_is_top":false,"comment_ctime":1631901033,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1631901033","product_id":100091101,"comment_content":"加大力度","like_count":0},{"had_liked":false,"id":312537,"user_name":"在路上","can_delete":false,"product_type":"c1","uid":1402511,"ip_address":"","ucode":"6E31908EFE1107","user_header":"https://static001.geekbang.org/account/avatar/00/15/66/8f/02be926d.jpg","comment_is_top":false,"comment_ctime":1631852773,"is_pvip":false,"replies":[{"id":"113297","content":"在路上：<br><br>你好，这些论文都是可以免费下载到。论文我不建议用Google Translate翻译。因为大部分都是很经典的论文，所以网上也有不少人把他们都已经翻译成中文了，搜索一下可以找到。不过有些翻译版本的很多内容不够准确，我建议如果英语不太好，可以中英文对照着读。","user_name":"作者回复","user_name_real":"徐文浩","uid":"1053568","ctime":1631941707,"ip_address":"","comment_id":312537,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1631852773","product_id":100091101,"comment_content":"徐老师好，这些论文都是免费的吗？我英文很不好，我把pdf下载下来用google translate翻译之后有影响吗？需要读原文吗？","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527008,"discussion_content":"在路上：\n\n你好，这些论文都是可以免费下载到。论文我不建议用Google Translate翻译。因为大部分都是很经典的论文，所以网上也有不少人把他们都已经翻译成中文了，搜索一下可以找到。不过有些翻译版本的很多内容不够准确，我建议如果英语不太好，可以中英文对照着读。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631941707,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":312395,"user_name":"子月十七","can_delete":false,"product_type":"c1","uid":2047274,"ip_address":"","ucode":"FDCF1ABF9F2D74","user_header":"https://static001.geekbang.org/account/avatar/00/1f/3d/2a/5c90358c.jpg","comment_is_top":false,"comment_ctime":1631784089,"is_pvip":false,"replies":[{"id":"113291","content":"其实Spark，Kafka已经是今天数据处理的标配了。基于Dremel模型的OLAP分析和Dataflow模型也已经是主流的解决方案了，相信在未来几年里也会成为处理数据的标准工具库。<br><br>所以一起来学习吧！","user_name":"作者回复","user_name_real":"徐文浩","uid":"1053568","ctime":1631940757,"ip_address":"","comment_id":312395,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1631784089","product_id":100091101,"comment_content":"开头的三驾马车是大概听过，之后的很多就都没听说过了","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526961,"discussion_content":"其实Spark，Kafka已经是今天数据处理的标配了。基于Dremel模型的OLAP分析和Dataflow模型也已经是主流的解决方案了，相信在未来几年里也会成为处理数据的标准工具库。\n\n所以一起来学习吧！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631940757,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":312267,"user_name":"yeyuliunian","can_delete":false,"product_type":"c1","uid":1002074,"ip_address":"","ucode":"ACBCD834BDE602","user_header":"https://static001.geekbang.org/account/avatar/00/0f/4a/5a/c9e70aec.jpg","comment_is_top":false,"comment_ctime":1631709929,"is_pvip":true,"replies":[{"id":"113175","content":"BigTable不支持跨行事务，但是Megastore已经在EntityGroup层面支持了<br>到Spanner就已经完全支持了<br><br>后两者本质上是BigTable的进化。","user_name":"作者回复","user_name_real":"徐文浩","uid":"1053568","ctime":1631770672,"ip_address":"","comment_id":312267,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1631709929","product_id":100091101,"comment_content":"有妥协，比如，Bigtable 不支持单行事务也不支持 SQL，就是一个明证。直到 5 年后发表的 MegaStore，他们才开始着手解决这两个问题。 --bigtable是不支持跨行事务吧","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526919,"discussion_content":"BigTable不支持跨行事务，但是Megastore已经在EntityGroup层面支持了\n到Spanner就已经完全支持了\n\n后两者本质上是BigTable的进化。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631770672,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":312252,"user_name":"夜空中最亮的星","can_delete":false,"product_type":"c1","uid":1267566,"ip_address":"","ucode":"ADC3E7B6789955","user_header":"https://static001.geekbang.org/account/avatar/00/13/57/6e/b6795c44.jpg","comment_is_top":false,"comment_ctime":1631705507,"is_pvip":false,"replies":[{"id":"113178","content":"哈哈哈，欢迎订阅","user_name":"作者回复","user_name_real":"徐文浩","uid":"1053568","ctime":1631770933,"ip_address":"","comment_id":312252,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1631705507","product_id":100091101,"comment_content":"老师您讲的这么有意思，我是订阅呢，订阅呢，还是订阅呢？","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526913,"discussion_content":"哈哈哈，欢迎订阅","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631770933,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1360830,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIhuVHHiapLgIicW5U7OiaENaWtwNaBbYaWFWvPibia4BzZjaPIYdoHDUSeib4LJS8ptFjBdXQiaBzM6P6GA/132","nickname":"杨","note":"","ucode":"FE06154101E2B1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":572496,"discussion_content":"双开订阅","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1652803150,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}