{"id":296576,"title":"43 | Checkpoint实现原理","content":"<p><strong>课件和Demo地址</strong><br>\n<a href=\"https://gitee.com/geektime-geekbang/geektime-Flink\">https://gitee.com/geektime-geekbang/geektime-Flink</a></p>","comments":[{"had_liked":false,"id":253668,"user_name":"Geek_qsftko","can_delete":false,"product_type":"c3","uid":1526892,"ip_address":"","ucode":"EE3316C188EC3C","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKerOHGs8VAMWj0ysxZpTPcARHEITiaH8YDJR7aoDNYhRpbLsZ0pJdJXIfzvR7u06iaKPBUoWfic5Zww/132","comment_is_top":false,"comment_ctime":1602824154,"is_pvip":false,"replies":[{"id":93254,"content":"这个好像不太好操作","user_name":"作者回复","user_name_real":"张利兵","uid":1119779,"ctime":1603529630,"ip_address":"","comment_id":253668,"utype":1}],"discussion_count":3,"race_medal":0,"score":2,"product_id":100058801,"comment_content":"老师您好，有个问题想请教您，Flink Stream中，将同一条stream的计算结果，同时分别写入ES和HBase，怎么来保证这两个sink，都可以同时成功写入呢？","like_count":0,"discussions":[{"author":{"id":1119779,"avatar":"https://static001.geekbang.org/account/avatar/00/11/16/23/99c7ede5.jpg","nickname":"张利兵","note":"","ucode":"DBAE17970AB143","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":507141,"discussion_content":"这个好像不太好操作","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1603529630,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1065272,"avatar":"https://static001.geekbang.org/account/avatar/00/10/41/38/4f89095b.jpg","nickname":"写点啥呢","note":"","ucode":"C19032CF1C41BA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":313220,"discussion_content":"我想了两种方案，一种自定义sink function来做双写但是会有一侧sink失败导致阻塞，一种先sink到消息队列然后各种output单独消费来做到最终一致。也请老师指点一下","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1603005460,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2760246,"avatar":"","nickname":"Geek_74dea9","note":"","ucode":"14092EEBC08171","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":408004,"discussion_content":"写入到kafka里面，然后消费数据，分别写入到不同的地方。虽然不能保证同时都成功，但是可以在失败的时候， 及时处理就可以","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1635166184,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":376260,"user_name":"Geek_3360b0","can_delete":false,"product_type":"c3","uid":3553421,"ip_address":"福建","ucode":"8E16877BCD71EC","user_header":"","comment_is_top":false,"comment_ctime":1686620527,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100058801,"comment_content":"state checkpoint 可以设置并发度，这个最好是能说下这些状态数据是如何分割数据集的，如何拆分成并发的小任务。\n\n类似的，Flink SQL 是如何对数据库（比如 PG）全表数据进行并发度查询，这个课程这些都没有点到，这个是一个很明显的缺憾。\n\n谢谢。","like_count":0},{"had_liked":false,"id":302369,"user_name":"Allan","can_delete":false,"product_type":"c3","uid":1310388,"ip_address":"","ucode":"8DA4DBECC2C45C","user_header":"https://static001.geekbang.org/account/avatar/00/13/fe/b4/295338e7.jpg","comment_is_top":false,"comment_ctime":1626180976,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100058801,"comment_content":"flink checkpoint 算子之间如何进行，还是没看到地方，我进行了搜索明白了算子之间也就是需要注册barrie事件发送到下个算，从source开始发送给下一个算子节点，直到最后一个算子sink最后结束提交给coornator完成最后的快照。但是我自己找源码却不知道如何找？","like_count":0},{"had_liked":false,"id":271244,"user_name":"最烦起名字","can_delete":false,"product_type":"c3","uid":2153662,"ip_address":"","ucode":"405A886940AD46","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIXbxuhFpUq10M3H87WiaE4bbqI5gTtmxfQCZDPUad4KrCJn8NiaPxhask5YSzRyQiaRaEJqaGoax35A/132","comment_is_top":false,"comment_ctime":1609488838,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":2,"product_id":100058801,"comment_content":"老师，flink消费kafka数据时，开启了checkpoint，每次做checkpoint持久化操作的时候，会自动保存到外部存储么","like_count":0,"discussions":[{"author":{"id":2760246,"avatar":"","nickname":"Geek_74dea9","note":"","ucode":"14092EEBC08171","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":408001,"discussion_content":"会的吧， checkpoint本身就是做这件事情的。所以开启ck的话，就会进行状态数据的持久化","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1635166055,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}