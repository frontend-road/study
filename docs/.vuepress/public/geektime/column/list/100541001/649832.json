{"id":649832,"title":"19｜Whisper+ChatGPT：请AI代你听播客","content":"<p>你好，我是徐文浩。</p><p>今天，我们的课程开始进入一个新的主题了，那就是语音识别。过去几周我们介绍的ChatGPT虽然很强大，但是只能接受文本的输入。而在现实生活中，很多时候我们并不方便停下来打字。很多内容比如像播客也没有文字版，所以这个时候，我们就需要一个能够将语音内容转换成文本的能力。</p><p>作为目前AI界的领导者，OpenAI自然也不会放过这个需求。他们不仅发表了一个通用的语音识别模型 Whisper，还把对应的代码开源了。在今年的1月份，他们也在API里提供了对应的语音识别服务。那么今天，我们就一起来看看Whisper这个语音识别的模型可以怎么用。</p><h2>Whisper API 101</h2><p>我自己经常会在差旅的过程中听播客。不过，筛选听什么播客的时候，有一个问题，就是光看标题和简介其实不是特别好判断里面的内容我是不是真的感兴趣。所以，在看到Whisper和ChatGPT这两个产品之后，我自然就想到了可以通过组合这两个API，让AI来代我听播客。<strong>我想通过Whisper把想要听的播客转录成文字稿，再通过ChatGPT做个小结，看看AI总结的小结内容是不是我想要听的。</strong></p><p>我前一阵刚听过一个<a href=\"https://www.listennotes.com/podcasts/onboard/ep-26-10pmK95wovN/\">关于 ChatGPT 的播客</a>，我们不妨就从这个开始。我们可以通过 <a href=\"https://www.listennotes.com/\">listennotes</a> 这个网站来搜索播客，还能够下载到播客的源文件。而且，这个网站还有一个很有用的功能，就是可以直接切出播客中的一段内容，创建出一个切片（clip）。</p><!-- [[[read_end]]] --><p>我们先拿一个小的切片来试试Whisper的API，对应的切片的<a href=\"https://www.listennotes.com/podcast-clips/ep-26-chatgpt%E4%B8%8E%E7%94%9F%E6%88%90%E5%BC%8Fai%E7%9A%84%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E4%B8%8E%E5%95%86%E4%B8%9A%E6%9C%AA%E6%9D%A5%E5%AF%B9%E8%AF%9Dgoogle-P9dfstDKIV6/\">链接</a>我也放在这里了。课程Github的data目录里也有已经下载好的MP3文件。</p><p>OpenAI提供的Whisper的API非常简单，你只要调用一下transcribe函数，就能将音频文件转录成文字。</p><pre><code class=\"language-python\">import openai, os\n\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")\n\naudio_file= open(\"./data/podcast_clip.mp3\", \"rb\")\ntranscript = openai.Audio.transcribe(\"whisper-1\", audio_file)\nprint(transcript['text'])\n</code></pre><p>输出结果：</p><pre><code class=\"language-python\">欢迎来到 Onboard 真实的一线经验 走新的投资思考 我是 Monica 我是高宁 我们一起聊聊软件如何改变世界 大家好 欢迎来到 Onboard 我是 Monica 自从OpenAI发布的ChatGBT 掀起了席卷世界的AI热潮 不到三个月就积累了 超过一亿的越货用户 超过1300万的日货用户 真的是展现了AI让人惊讶的 也让很多人直呼 这就是下一个互联网的未来 有不少观众都说 希望我们再做一期AI的讨论 于是这次硬核讨论就来了 这次我们请来了 Google Brain的研究员雪芝 她是Google大语言模型PALM Pathway Language Model的作者之一 要知道这个模型的参数量 是GPT-3的三倍还多 另外还有两位AI产品大牛 一位来自著名的StableDM 背后的商业公司Stability AI 另一位来自某硅谷科技大厂 也曾在吴恩达教授的Landing AI中 担任产品负责人 此外 莫妮凯还邀请到一位 一直关注AI的投资人朋友Bill 当做我的特邀共同主持嘉宾 我们主要讨论几个话题 一方面从研究的视角 最前沿的研究者在关注什么 现在技术的天花板 和未来大的变量可能会在哪里 第二个问题是 未来大的变量可能会在哪里 从产品和商业的角度 什么是一个好的AI产品 整个生态可能随着技术 有怎样的演变 更重要的 我们又能从上一波 AI的创业热潮中学到什么 最后 莫妮凯和Bill还会从投资人的视角 做一个回顾 总结和畅想 这里还有一个小的update 在本集发布的时候 Google也对爆发式增长的 Chad GPT做出了回应 正在测试一个基于Lambda 模型的聊天机器人 ApprenticeBot 正式发布后会有怎样的惊喜 我们都拭目以待 AI无疑是未来几年 最令人兴奋的变量之一 莫妮凯也希望未来能邀请到更多 一线从业者 从不同角度讨论这个话题 不论是想要做创业 研究 产品 还是投资的同学 希望这些对话 对于大家了解这些技术演进 商业的可能 甚至未来对于我们每个人 每个社会意味着什么 都能引发一些思考 提供一些启发 这次的讨论有些技术硬核 需要各位对生成式AI 大模型都有一些基础了解 讨论中涉及到的论文和重要概念 也会总结在本集的简介中 供大家复习参考 几位嘉宾在北美工作生活多年 夹杂英文在所难免 也请大家体谅了 欢迎来到未来 希望大家enjoy\n</code></pre><p>从转录的结果来看，有一个好消息和一个坏消息。好消息是，语音识别的转录效果非常好。我们看到尽管播客里面混杂着中英文，但是Whisper还是很好地识别出来了。坏消息是，转录出来的内容只有空格的分隔符，没有标点符号。</p><p>不过，这个问题也并不难解决。我们只要在前面的代码里面，增加一个Prompt参数就好了。</p><pre><code class=\"language-python\">audio_file= open(\"./data/podcast_clip.mp3\", \"rb\")\ntranscript = openai.Audio.transcribe(\"whisper-1\", audio_file, \n                                     prompt=\"这是一段中文播客内容。\")\nprint(transcript['text'])\n</code></pre><p>输出结果：</p><pre><code class=\"language-python\">欢迎来到 Onboard,真实的一线经验,走新的投资思考。 我是 Monica。 我是高宁。我们一起聊聊软件如何改变世界。 大家好,欢迎来到 Onboard,我是 Monica。 自从 OpenAI 发布的 ChatGBT 掀起了席卷世界的 AI 热潮, 不到三个月就积累了超过一亿的越活用户,超过一千三百万的日活用户。 真的是展现了 AI 让人惊叹的能力, 也让很多人直呼这就是下一个互联网的未来。 有不少观众都说希望我们再做一期 AI 的讨论, 于是这次硬核讨论就来了。 这次我们请来了 Google Brain 的研究员雪芝, 她是 Google 大语言模型 PAMP,Pathway Language Model 的作者之一。 要知道,这个模型的参数量是 GPT-3 的三倍还多。 另外还有两位 AI 产品大牛,一位来自著名的 Stable Diffusion 背后的商业公司 Stability AI, 另一位来自某硅谷科技大厂,也曾在吴恩达教授的 Landing AI 中担任产品负责人。 此外,Monica 还邀请到一位一直关注 AI 的投资人朋友 Bill 当作我的特邀共同主持嘉宾。 我们主要讨论几个话题,一方面从研究的视角,最前沿的研究者在关注什么? 现在技术的天花板和未来大的变量可能会在哪里? 从产品和商业的角度,什么是一个好的 AI 产品? 整个生态可能随着技术有怎样的演变? 更重要的,我们又能从上一波 AI 的创业热潮中学到什么? 最后,Monica 和 Bill 还会从投资人的视角做一个回顾、总结和畅想。 这里还有一个小的 update,在本集发布的时候, Google 也对爆发式增长的ChatGPT 做出了回应, 正在测试一个基于 Lambda 模型的聊天机器人 ApprenticeBot。 正式发布后会有怎样的惊喜?我们都拭目以待。 AI 无疑是未来几年最令人兴奋的变量之一, Monica 也希望未来能邀请到更多一线从业者从不同角度讨论这个话题。 不论是想要做创业、研究、产品还是投资的同学, 希望这些对话对于大家了解这些技术演进、商业的可能, 甚至未来对于我们每个人、每个社会意味着什么, 都能引发一些思考,提供一些启发。 这次的讨论有些技术硬核,需要各位对生成式 AI 大模型都有一些基础了解。 讨论中涉及到的论文和重要概念,也会总结在本集的简介中,供大家复习参考。 几位嘉宾在北美工作生活多年,夹杂英文在所难免,也请大家体谅了。 欢迎来到未来,大家 enjoy!\n</code></pre><p>我们在transcribe函数被调用的时候，传入了一个Prompt参数。里面是一句引导Whisper模型的提示语。在这里，我们的Prompt里用了一句中文介绍，并且带上了标点符号。你就会发现，transcribe函数转录出来的内容也就带上了正确的标点符号。</p><p>不过，转录出来的内容还有一点小小的瑕疵。那就是中英文混排的内容里面，英文前后会多出一些空格。那我们就再修改一下Prompt，在提示语里面也使用中英文混排并且不留空格。</p><pre><code class=\"language-python\">audio_file= open(\"./data/podcast_clip.mp3\", \"rb\")\ntranscript = openai.Audio.transcribe(\"whisper-1\", audio_file, \n                                     prompt=\"这是一段Onboard播客的内容。\")\nprint(transcript['text'])\n</code></pre><p>输出结果：</p><pre><code class=\"language-python\">欢迎来到Onboard,真实的一线经验,走新的投资思考。 我是Monica,我是高宁,我们一起聊聊软件如何改变世界。 大家好,欢迎来到Onboard,我是Monica。 自从OpenAI发布的ChatGBT掀起了席卷世界的AI热潮, 不到三个月就积累了超过一亿的越活用户,超过1300万的日活用户。 真的是展现了AI让人惊叹的能力,也让很多人直呼这就是下一个互联网的未来。 有不少观众都说希望我们再做一期AI的讨论,于是这次硬核讨论就来了。 这次我们请来了Google Brain的研究员雪芝, 她是Google大语言模型POM,Pathway Language Model的作者之一。 要知道这个模型的参数量是GPT-3的三倍还多。 另外还有两位AI产品大牛,一位来自著名的Stable Diffusion背后的商业公司Stability AI, 另一位来自某硅谷科技大厂,也曾在吴恩达教授的Landing AI中担任产品负责人。 此外,Monica还邀请到一位一直关注AI的投资人朋友Bill,当做我的特邀共同主持嘉宾。 我们主要讨论几个话题,一方面从研究的视角,最前沿的研究者在关注什么? 现在的技术的天花板和未来大的变量可能会在哪里? 从产品和商业的角度,什么是一个好的AI产品? 整个生态可能随着技术有怎样的演变? 更重要的,我们又能从上一波AI的创业热潮中学到什么? 最后,Monica和Bill还会从投资人的视角做一个回顾、总结和畅想。 这里还有一个小的update,在本集发布的时候, Google也对爆发式增长的ChatGPT做出了回应, 正在测试一个基于Lambda模型的聊天机器人ApprenticeBot。 正式发布后会有怎样的惊喜?我们都拭目以待。 AI无疑是未来几年最令人兴奋的变量之一, Monica也希望未来能邀请到更多一线从业者从不同角度讨论这个话题。 不论是想要做创业、研究、产品还是投资的同学, 希望这些对话对于大家了解这些技术演进、商业的可能, 甚至未来对于我们每个人、每个社会意味着什么, 都能引发一些思考,提供一些启发。 这次的讨论有些技术硬核,需要各位对生成式AI、大模型都有一些基础了解。 讨论中涉及到的论文和重要概念,也会总结在本集的简介中,供大家复习参考。 几位嘉宾在北美工作生活多年,夹杂英文在所难免,也请大家体谅了。 欢迎来到未来,大家enjoy!\n</code></pre><p>可以看到，输出结果的英文前后也就没有空格了。<strong>能够在音频内容的转录之前提供一段Prompt，来引导模型更好地做语音识别，是Whisper模型的一大亮点。</strong>如果你觉得音频里面会有很多专有名词，模型容易识别错，你就可以在Prompt里加上对应的专有名词。比如，在上面的内容转录里面，模型就把ChatGPT也听错了，变成了ChatGBT。Google的PALM模型也给听错了，听成了POM。对应的全称Pathways Language Model也少了一个s。而针对这些错漏，我们只要再修改一下Prompt，它就能够转录正确了。</p><pre><code class=\"language-python\">audio_file= open(\"./data/podcast_clip.mp3\", \"rb\")\ntranscript = openai.Audio.transcribe(\"whisper-1\", audio_file, \n                                     prompt=\"这是一段Onboard播客，里面会聊到ChatGPT以及PALM这个大语言模型。这个模型也叫做Pathways Language Model。\")\nprint(transcript['text'])\n</code></pre><p>输出结果：</p><pre><code class=\"language-python\">欢迎来到Onboard,真实的一线经验,走新的投资思考。我是Monica。 我是高宁。我们一起聊聊软件如何改变世界。 大家好,欢迎来到Onboard,我是Monica。 自从OpenAI发布的ChatGPT掀起了席卷世界的AI热潮,不到三个月就积累了超过一亿的越活用户,超过1300万的日活用户。 真的是展现了AI让人惊叹的能力,也让很多人直呼这就是下一个互联网的未来。 有不少观众都说希望我们再做一期AI的讨论,于是这次硬核讨论就来了。 这次我们请来了Google Brain的研究员雪芝,她是Google大语言模型PALM Pathways Language Model的作者之一。 要知道,这个模型的参数量是GPT-3的三倍还多。 另外还有两位AI产品大牛,一位来自著名的Stable Diffusion背后的商业公司Stability AI, 另一位来自某硅谷科技大厂,也曾在吴恩达教授的Landing AI中担任产品负责人。 此外,Monica还邀请到一位一直关注AI的投资人朋友Bill当作我的特邀共同主持嘉宾。 我们主要讨论几个话题,一方面从研究的视角,最前沿的研究者在关注什么? 现在的技术的天花板和未来大的变量可能会在哪里? 从产品和商业的角度,什么是一个好的AI产品? 整个生态可能随着技术有怎样的演变? 更重要的,我们又能从上一波AI的创业热潮中学到什么? 最后,Monica和Bill还会从投资人的视角做一个回顾、总结和畅想。 这里还有一个小的update,在本集发布的时候,Google也对爆发式增长的Chat GPT做出了回应。 正在测试一个基于Lambda模型的聊天机器人ApprenticeBot。 证实发布后会有怎样的惊喜,我们都拭目以待。 AI无疑是未来几年最令人兴奋的变量之一。 Monica也希望未来能邀请到更多一线从业者从不同角度讨论这个话题。 不论是想要做创业、研究、产品还是投资的同学, 希望这些对话对于大家了解这些技术演进、商业的可能,甚至未来对于我们每个人、每个社会意味着什么都能引发一些思考,提供一些启发。 这次的讨论有些技术硬核,需要各位对生成式AI大模型都有一些基础了解。 讨论中涉及到的论文和重要概念也会总结在本集的简介中,供大家复习参考。 几位嘉宾在北美工作生活多年,夹杂英文在所难免,也请大家体谅了。 欢迎来到未来,大家enjoy!\n</code></pre><p>出现这个现象的原因，主要和Whisper的模型原理相关，它也是一个和GPT类似的模型，会用前面转录出来的文本去预测下一帧音频的内容。通过在最前面加上文本Prompt，就会影响后面识别出来的内容的概率，也就是能够起到给专有名词“纠错”的作用。</p><p>除了模型名称、音频文件和Prompt之外，transcribe接口还支持这样三个参数。</p><ol>\n<li>response_format，也就是返回的文件格式，我们这里是默认值，也就是JSON。实际你还可以选择TEXT这样的纯文本，或者SRT和VTT这样的音频字幕格式。这两个格式里面，除了文本内容，还会有对应的时间信息，方便你给视频和音频做字幕。你可以直接试着运行一下看看效果。</li>\n<li>temperature，这个和我们之前在ChatGPT类型模型里的参数含义类似，就是采样下一帧的时候，如何调整概率分布。这里的参数范围是0-1之间。</li>\n<li>language，就是音频的语言。提前给模型指定音频的语言，有助于提升模型识别的准确率和速度。</li>\n</ol><p>这些参数你都可以自己试着改一下，看看效果。</p><pre><code class=\"language-python\">audio_file= open(\"./data/podcast_clip.mp3\", \"rb\")\ntranscript = openai.Audio.transcribe(\"whisper-1\", audio_file, response_format=\"srt\",\n                                     prompt=\"这是一段Onboard播客，里面会聊到PALM这个大语言模型。这个模型也叫做Pathways Language Model。\")\nprint(transcript)\n</code></pre><p>输出结果：</p><pre><code class=\"language-python\">1\n00:00:01,000 --&gt; 00:00:07,000\n欢迎来到Onboard,真实的一线经验,走新的投资思考。我是Monica。\n2\n00:00:07,000 --&gt; 00:00:11,000\n我是高宁。我们一起聊聊软件如何改变世界。\n3\n00:00:15,000 --&gt; 00:00:17,000\n大家好,欢迎来到Onboard,我是Monica。\n4\n00:00:17,000 --&gt; 00:00:28,000\n自从OpenAI发布的ChatGBT掀起了席卷世界的AI热潮,不到三个月就积累了超过一亿的越活用户,超过1300万的日活用户。\n5\n00:00:28,000 --&gt; 00:00:34,000\n真的是展现了AI让人惊叹的能力,也让很多人直呼这就是下一个互联网的未来。\n6\n00:00:34,000 --&gt; 00:00:41,000\n有不少观众都说希望我们再做一期AI的讨论,于是这次硬核讨论就来了。\n7\n...\n欢迎来到未来,大家enjoy!\n</code></pre><h2>转录的时候顺便翻译一下</h2><p>除了基本的音频转录功能，Whisper的API还额外提供了一个叫做translation的接口。这个接口可以在转录音频的时候直接把语音翻译成英文，我们不妨来试一下。</p><pre><code class=\"language-python\">audio_file= open(\"./data/podcast_clip.mp3\", \"rb\")\ntranslated_prompt=\"\"\"This is a podcast discussing ChatGPT and PaLM model. \nThe full name of PaLM is Pathways Language Model.\"\"\"\ntranscript = openai.Audio.translate(\"whisper-1\", audio_file, \n                                    prompt=translated_prompt)\nprint(transcript['text'])\n</code></pre><p>输出结果：</p><pre><code class=\"language-python\">Welcome to Onboard. Real first-line experience. New investment thinking. I am Monica. I am Gao Ning. Let's talk about how software can change the world. Hello everyone, welcome to Onboard. I am Monica. Since the release of ChatGPT by OpenAI, the world's AI has been in a frenzy. In less than three months, it has accumulated more than 100 million active users, and more than 13 million active users. It really shows the amazing ability of AI. It also makes many people say that this is the future of the next Internet. Many viewers said that they wanted us to do another AI discussion. So this discussion came. This time we invited a researcher from Google Brain, Xue Zhi. He is one of the authors of Google's large-scale model PaLM, Pathways Language Model. You should know that the number of parameters of this model is three times more than ChatGPT-3. In addition, there are two AI product big cows. One is from the famous company behind Stable Diffusion, Stability AI. The other is from a Silicon Valley technology factory. He was also the product manager in Professor Wu Wenda's Landing AI. In addition, Monica also invited a friend of AI who has been paying attention to AI, Bill, as my special guest host. We mainly discuss several topics. On the one hand, from the perspective of research, what are the most cutting-edge researchers paying attention to? Where are the cutting-edge technologies and the large variables of the future? From the perspective of products and business, what is a good AI product? What kind of evolution may the whole state follow? More importantly, what can we learn from the previous wave of AI entrepreneurship? Finally, Monica and Bill will also make a review, summary and reflection from the perspective of investors. Here is a small update. When this issue was released, Google also responded to the explosive growth of ChatGPT. We are testing an Apprentice Bot based on Lambda model. What kind of surprises will be released? We are looking forward to it. AI is undoubtedly one of the most exciting variables in the coming years. Monica also hopes to invite more first-line entrepreneurs to discuss this topic from different angles. Whether you want to do entrepreneurship, research, product or investment, I hope these conversations will help you understand the possibilities of these technical horizons and business. Even in the future, it can cause some thoughts and inspire us to think about what it means to each person and each society. This discussion is a bit technical, and requires you to have some basic understanding of the biometric AI model. The papers and important concepts involved in the discussion will also be summarized in this episode's summary, which is for your reference. You have worked in North America for many years, and you may have some English mistakes. Please understand. Welcome to the future. Enjoy. Let me give you a brief introduction. Some of your past experiences. A fun fact. Using an AI to represent the world is now palped.\n</code></pre><p>这个接口只能把内容翻译成英文，不能变成其他语言。所以对应的，Prompt也必须换成英文。只能翻译成英文对我们来说稍微有些可惜了。如果能够指定翻译的语言，很多英文播客，我们就可以直接转录成中文来读了。现在我们要做到这一点，就不得不再花一份钱，让ChatGPT来帮我们翻译。</p><h2>通过分割音频来处理大文件</h2><p>刚才我们只是尝试转录了一个3分钟的音频片段，那接下来我们就来转录一下整个音频。不过，我们没法把整个150分钟的播客一次性转录出来，因为OpenAI限制Whisper一次只能转录25MB大小的文件。所以我们要先把大的播客文件分割成一个个小的片段，转录完之后再把它们拼起来。我们可以选用OpenAI在官方文档里面提供的 <a href=\"https://platform.openai.com/docs/guides/speech-to-text/longer-inputs\">PyDub 的库</a>来分割文件。</p><p>不过，在分割之前，我们先要通过FFmpeg把从listennotes下载的MP4文件转换成MP3格式。你不了解FFmpeg或者没有安装也没有关系，对应的命令我是让ChatGPT写的。转换后的文件我也放到了<a href=\"https://github.com/xuwenhao/geektime-ai-course\">课程 Github 库</a>里的网盘地址了。</p><pre><code class=\"language-python\">ffmpeg -i ./data/podcast_long.mp4 -vn -c:a libmp3lame -q:a 4 ./data/podcast_long.mp3\n</code></pre><p>分割MP3文件的代码也很简单，我们按照15分钟一个片段的方式，把音频切分一下就好了。通过PyDub的AudioSegment包，我们可以把整个长的MP3文件加载到内存里面来变成一个数组。里面每1毫秒的音频数据就是数组里的一个元素，我们可以很容易地将数组按照时间切分成每15分钟一个片段的新的MP3文件。</p><p>先确保我们安装了PyDub包。</p><pre><code class=\"language-python\">%pip install -U pydub\n</code></pre><p>代码：</p><pre><code class=\"language-python\">from pydub import AudioSegment\n\npodcast = AudioSegment.from_mp3(\"./data/podcast_long.mp3\")\n\n# PyDub handles time in milliseconds\nten_minutes = 15 * 60 * 1000\n\ntotal_length = len(podcast)\n\nstart = 0\nindex = 0\nwhile start &lt; total_length:\n    end = start + ten_minutes\n    if end &lt; total_length:\n        chunk = podcast[start:end]\n    else:\n        chunk = podcast[start:]\n    with open(f\"./data/podcast_clip_{index}.mp3\", \"wb\") as f:\n        chunk.export(f, format=\"mp3\")\n    start = end\n    index += 1\n</code></pre><p>在切分完成之后，我们就一个个地来转录对应的音频文件，对应的代码就在下面。</p><pre><code class=\"language-python\">prompt = \"这是一段Onboard播客，里面会聊到ChatGPT以及PALM这个大语言模型。这个模型也叫做Pathways Language Model。\"\nfor i in range(index):\n    clip = f\"./data/podcast_clip_{i}.mp3\"\n    audio_file= open(clip, \"rb\")\n    transcript = openai.Audio.transcribe(\"whisper-1\", audio_file, \n                                     prompt=prompt)\n    # mkdir ./data/transcripts if not exists\n    if not os.path.exists(\"./data/transcripts\"):\n        os.makedirs(\"./data/transcripts\")\n    # write to file\n    with open(f\"./data/transcripts/podcast_clip_{i}.txt\", \"w\") as f:\n        f.write(transcript['text'])\n    # get last sentence of the transcript\n    sentences = transcript['text'].split(\"。\")\n    prompt = sentences[-1]\n</code></pre><p>在这里，我们对每次进行转录的Prompt做了一个小小的特殊处理。我们把前一个片段转录结果的最后一句话，变成了下一个转录片段的提示语。这样，我们可以让后面的片段在进行语音识别的时候，知道前面最后说了什么。这样做，可以减少错别字的出现。</p><h2>通过开源模型直接在本地转录</h2><p>通过OpenAI的Whisper API来转录音频是有成本的，目前的定价是 0.006 美元/分钟。比如我们上面的150分钟的音频文件，只需要不到1美元，其实已经很便宜了。不过，如果你不想把对应的数据发送给OpenAI，避免任何数据泄露的风险，你还有另外一个选择，那就是直接使用OpenAI开源出来的模型就好了。</p><p>不过使用开源模型你还是需要一块GPU，如果没有的话，你仍然可以使用免费的Colab的Notebook环境。</p><p>先安装openai-whisper的相关的依赖包。</p><pre><code class=\"language-python\">%pip install openai-whisper\n%pip install setuptools-rust\n</code></pre><p>代码本身很简单，我们只是把原先调用OpenAI的API的地方，换成了加载Whisper的模型，然后在transcribe的参数上，有一些小小的差异。其他部分的代码和前面我们调用OpenAI的Whisper API的代码基本上是一致的。</p><pre><code class=\"language-python\">import whisper\n\nmodel = whisper.load_model(\"large\")\nindex = 11 # number of fi\n  \ndef transcript(clip, prompt, output):\n    result = model.transcribe(clip, initial_prompt=prompt)\n    with open(output, \"w\") as f:\n        f.write(result['text'])\n    print(\"Transcripted: \", clip)\n\noriginal_prompt = \"这是一段Onboard播客，里面会聊到ChatGPT以及PALM这个大语言模型。这个模型也叫做Pathways Language Model。\\n\\n\"\nprompt = original_prompt\nfor i in range(index):\n    clip = f\"./drive/MyDrive/colab_data/podcast/podcast_clip_{i}.mp3\"\n    output = f\"./drive/MyDrive/colab_data/podcast/transcripts/local_podcast_clip_{i}.txt\"\n    transcript(clip, prompt, output)\n    # get last sentence of the transcript\n    with open(output, \"r\") as f:\n        transcript = f.read()\n    sentences = transcript.split(\"。\")\n    prompt = original_prompt + sentences[-1]\n</code></pre><p>有一个点你可以注意一下，Whisper的模型和我们之前看过的其他开源模型一样，有好几种不同尺寸。你可以通过 load_model 里面的参数来决定加载什么模型。这里我们选用的是最大的 large 模型，它大约需要10GB的显存。因为Colab提供的GPU是英伟达的T4，有16G显存，所以是完全够用的。</p><p>如果你是使用自己电脑上的显卡，显存没有那么大，你可以选用小一些的模型，比如small或者base。如果你要转录的内容都是英语的，还可以直接使用small.en这样仅限于英语的模型。这种小的或者限制语言的模型，速度还更快。不过，如果是像我们这样转录中文为主，混杂了英文的内容，那么尽可能选取大一些的模型，转录的准确率才会比较高。</p><p><img src=\"https://static001.geekbang.org/resource/image/7a/3d/7a36faf9bb3f023714dea7e24a86653d.png?wh=1928x1076\" alt=\"\" title=\"Whisper项目的模型参数和尺寸说明\"></p><p>Whisper项目：<a href=\"https://github.com/openai/whisper\">https://github.com/openai/whisper</a></p><h2>结合ChatGPT做内容小结</h2><p>无论是使用API还是通过本地的GPU进行文本转录，我们都会获得转录之后的文本。要给这些文本做个小结，其实我们在<a href=\"https://time.geekbang.org/column/article/645305\">第 10 讲</a>讲解llama-index的时候就给过示例了。我们把那个代码稍微改写一下，就能得到对应播客的小结。</p><pre><code class=\"language-python\">from langchain.chat_models import ChatOpenAI\nfrom langchain.text_splitter import SpacyTextSplitter\nfrom llama_index import GPTListIndex, LLMPredictor, ServiceContext, SimpleDirectoryReader\nfrom llama_index.node_parser import SimpleNodeParser\n\n# define LLM\nllm_predictor = LLMPredictor(llm=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\", max_tokens=1024))\n\ntext_splitter = SpacyTextSplitter(pipeline=\"zh_core_web_sm\", chunk_size = 2048)\nparser = SimpleNodeParser(text_splitter=text_splitter)\ndocuments = SimpleDirectoryReader('./data/transcripts').load_data()\nnodes = parser.get_nodes_from_documents(documents)\n\nservice_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)\n\nlist_index = GPTListIndex(nodes=nodes, service_context=service_context)\nresponse = list_index.query(\"请你用中文总结一下我们的播客内容:\", response_mode=\"tree_summarize\")\nprint(response)\n</code></pre><p>输出结果：</p><pre><code class=\"language-python\">这个播客讨论了人工智能和深度学习领域的高级技术和最新发展，包括稳定性人工智能、语言模型的预训练方法、图像生成模型的训练和优化，以及各种机器学习模型的比较和应用场景。同时，我们探讨了开源社区的作用和趋势，以及开源商业化的优缺点及如何应对。我们还讨论了人工智能在各个领域的应用和未来发展趋势，并强调了找到实际应用场景和解决实际问题的重要性。最后，我们提醒说，未来值得期待的AI应用将是能够真正跟人交互的产品，对于创业公司来说，需要从用户实际的痛点出发去考虑如何更好地应用AI技术。\n</code></pre><p>基于这里的代码，你完全可以开发一个自动抓取并小结你订阅的播客内容的小应用。一般的播客也就是40-50分钟一期，转录并小结一期的成本也就在5块人民币上下。</p><h2>小结</h2><p>好了，这一讲到这里也就结束了。</p><p>OpenAI的Whisper模型，使用起来非常简单方便。无论是通过API还是使用开源的模型，只要一行代码调用一个transcribe函数，就能把一个音频文件转录成对应的文本。而且即使对于多语言混杂的内容，它也能转录得很好。而通过传入一个Prompt，它不仅能够在整个文本里，加上合适的标点符号，还能够根据Prompt里面的专有名词，减少转录中这些内容的错漏。虽然OpenAI的API接口限制了单个转录文件的大小，但是我们可以很方便地通过PyDub这样的Python包，把音频文件切分成多个小的片段来解决问题。</p><p>对于转录后的结果，我们可以很容易地使用之前学习过的ChatGPT和llama-index来进行相应的文本小结。通过组合Whisper和ChatGPT，我们就可以快速地让机器自动帮助我们将播客、Youtube访谈，变成一段文本小结，能够让我们快速浏览并判定是否有必要深入去听一下原始的内容。</p><h2>思考题</h2><p>我们在将长音频分片进行转录的过程里，是完全按照精确的时间去切割音频文件的。但是实际上音频的断句其实并不在那一毫秒。所以转录的时候，效果也不一定好，特别是在录音的开头和结尾部分，很有可能不是一个完整的句子，也容易出现一些错漏的情况。你能想想有什么好办法可以解决这个问题吗？我们是否可以利用SRT或VTT文件里面文本对应的时间标注信息？</p><p>欢迎你把你思考的结果分享到留言区，也欢迎你把这一讲分享给需要的朋友，我们下一讲再见！</p><h2>推荐阅读</h2><p>李沐老师在他的论文精读系列视频里面，有专门讲解过 <a href=\"https://www.bilibili.com/video/BV1VG4y1t74x/\">OpenAI Whisper 的相关论文</a>。他还专门基于Whisper的开源代码做了一个用来剪辑视频的小工具 <a href=\"https://www.bilibili.com/video/BV1Pe4y1t7de/?spm_id_from=333.788.recommend_more_video.2&vd_source=dd7dfb298255b22a34220853aab4f816\">AutoCut</a>。你有兴趣的话，可以去看一看。</p>","neighbors":{"left":{"article_title":"18｜流式生成与模型微调，打造极致的对话体验","id":648466},"right":{"article_title":"20｜TTS与语音合成：让你的机器人拥有声音","id":650449}},"comments":[{"had_liked":false,"id":373020,"user_name":"Toni","can_delete":false,"product_type":"c1","uid":3206957,"ip_address":"瑞士","ucode":"E6B2FACCC1E000","user_header":"https://static001.geekbang.org/account/avatar/00/30/ef/2d/757bb0d3.jpg","comment_is_top":false,"comment_ctime":1681923880,"is_pvip":false,"replies":[{"id":136499,"content":"👍","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1683088301,"ip_address":"上海","comment_id":373020,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"将长音频分片转录时，如果完全按照精确的时间去切割音频文件，很有可能在结尾处裁出一个不完整的句子，而下一段的开头也可能会是半句话。如何解决，思考题很实用。\n\n下面是一种思路:\n\n1.  从计划切割的位置上取出一小片。比如音频文件长约2小时，初步计划分成四个文件，每份约长30分钟，将30分到30分10秒的音频切出来。实现方法\nextract = audio_long[StartTime:EndTime]\nextract.export(&quot;cutat30mins.mp3&quot;, format=&quot;mp3&quot;)\n\n2. 找出这个10秒切片中的断句位置，实现方法\nfrom pydub.silence import detect_silence\npiece = AudioSegment.from_mp3(&quot;cutat30mins.mp3&quot;)\nsilent_ranges = detect_silence(piece, min_silence_len=500, silence_thresh=-40)\n参数代表静音时长和分贝\n\n3. 选上面断句位置中的第一个的起点作为第一段半小时音频文件的结尾。这样就得到 1. 中的EndTime 准确值，而不是在一句话的中间。\n\n测试: 选 podcast_clip.mp3 作为测试文件，时长3分钟。初选2分钟处分割。\n\n取 2 分钟到 2 分钟10秒 的一个小片段，得出静音数列 [[793, 1803], [4991, 5813]]\n\nfile =  = AudioSegment.from_mp3(&quot;podcast_clip.mp3&quot;)\nEndTime = 2*60*1000 + 793 = 120793\npart_1 = file[:EndTime]\nStartTime = 2*60*1000 + 1803 = 121803\npart_2 = file[StartTime:]\n\n结果:\npart_1 结束句 &#39;证实发布后会有怎样的惊喜,我们都拭目以待。&#39;\npart_2 开始句 &#39;AI无疑是未来几年最令人兴奋的变量之一。&#39;\n\n还会有其它的解决方法。","like_count":31,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":616736,"discussion_content":"👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683088301,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":373227,"user_name":"Toni","can_delete":false,"product_type":"c1","uid":3206957,"ip_address":"瑞士","ucode":"E6B2FACCC1E000","user_header":"https://static001.geekbang.org/account/avatar/00/30/ef/2d/757bb0d3.jpg","comment_is_top":false,"comment_ctime":1682262234,"is_pvip":false,"replies":[{"id":136457,"content":"👍","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1683082917,"ip_address":"上海","comment_id":373227,"utype":1}],"discussion_count":3,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"尝试着将李沐老师视频 &#39;AutoCut--如何用 Whisper 来剪辑视频&#39; 的内容进行了概要信息提取。分三步，1 视频读取和语音识别，2 将大块文件裁成小块，使得输入的 Token 数能满足 OpenAI 的要求，3 分块总结。\n\n1. 从 B 站读取视频 (Bilibili Video)，实现代码如下:\n\n!pip install bilibili-api\nfrom langchain.document_loaders.bilibili import BiliBiliLoader\nloader_bi = BiliBiliLoader([&quot;https:&#47;&#47;www.bilibili.com&#47;video&#47;BV1Pe4y1t7de&#47;&quot;])\nresult_bi = loader_bi.load()\n\n2. 数据分割，实现代码如下:\n\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\ntext_splitter_bi = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=20)\ntexts_bi = text_splitter_bi.split_documents(result_bi)\n\n调整参数 chunk_size 决定切割的大小，在本例中，裁成了6段，查看代码如下:\n\nlen(texts_bi)\n6\n\n3. 给出视频内容提要，实现代码如下:\n\nfrom langchain.prompts import PromptTemplate\nllm = OpenAI(temperature=0)\nprompt_template = &quot;&quot;&quot;Answer in Chinese. Summarize this conversation {text}. Do NOT write sentences that has no sense.&quot;&quot;&quot;\nprompt_template2 = &quot;&quot;&quot;Answer in Chinese. Choose the more relevant phrases of the following text and summarize them {text}.&quot;&quot;&quot;\nPROMPT = PromptTemplate(\n    template=prompt_template,\n    input_variables=[&quot;text&quot;]       \n)\nPROMPT2 = PromptTemplate(\n    template=prompt_template2,\n    input_variables=[&quot;text&quot;]       \n)\noverall_bi = load_summarize_chain(llm, chain_type=&quot;map_reduce&quot;, map_prompt=PROMPT, combine_prompt=PROMPT2, return_intermediate_steps=True, verbose=True)\n\nsummarize_bi = overall_bi( {&quot;input_documents&quot;: texts_bi},return_only_outputs=True)\n\n输出结果如下:\n\n这段视频介绍了一个叫OpenAI Whisper的剪视频小工具，并附上了一个GitHub链接，...\n我们演示了如何使用OpenAI的Whisper模型来识别视频中的字幕，并且可以选择不同的模型，从tiny到large ... 以提高识别精度。\n选择Small模型可以满足大部分需求，...可以节省时间。\n...\n这次讨论的主要内容是Whisper这个模型的使用，它在中文语谅上的表现不是很好，但是在带有英文词汇的视频中，它的识别能力还是很强的， ...\n\n---\n上面提供了一种提取视频核心思想的方法，还会有更好的。","like_count":12,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":616679,"discussion_content":"👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683082917,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3174831,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJyOmDVPSA0xVAkS991LDPUWfiaUZgYcCNtEIdM8gw8pb4AWwOyAmmiauYMI3m7gbvXaMGshVPYuWdQ/132","nickname":"TylorWu","note":"","ucode":"93C21CC33ABD54","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":620223,"discussion_content":"666","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1685959836,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1253652,"avatar":"https://static001.geekbang.org/account/avatar/00/13/21/14/423a821f.jpg","nickname":"Steven","note":"","ucode":"3FE64459842015","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":615496,"discussion_content":"强，学习了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1682306204,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"辽宁","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":373070,"user_name":"Geek_00eb03","can_delete":false,"product_type":"c1","uid":1300603,"ip_address":"湖北","ucode":"35D123F2A0FD43","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJiaPZjokKDOAicIIOtJB0Omkw5tXZem8icbDBpxqhqE5iaMicHbEgEicESiaGDZ7icSwqmYfqXc4r8uhKHwQ/132","comment_is_top":false,"comment_ctime":1681985698,"is_pvip":false,"replies":[{"id":136521,"content":"1. 换一下 splitter，用SpacyTextSplitter以及对应中文的模型\n2. 设置一下 chunk_size （大一点），chunk_overlap（小一点）","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1683093709,"ip_address":"上海","comment_id":373070,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"老师，运行代码报错， 能帮忙看看什么原因吗？\n--&gt; 157     raise ValueError(\n    158         &quot;A single term is larger than the allowed chunk size.\\n&quot;\n    159         f&quot;Term size: {num_cur_tokens}\\n&quot;\n    160         f&quot;Chunk size: {self._chunk_size}&quot;\n    161         f&quot;Effective chunk size: {effective_chunk_size}&quot;\n    162     )\n    163 # If adding token to current_doc would exceed the chunk size:\n    164 # 1. First verify with tokenizer that current_doc\n    165 # 1. Update the docs list\n    166 if cur_total + num_cur_tokens &gt; effective_chunk_size:\n    167     # NOTE: since we use a proxy for counting tokens, we want to\n    168     # run tokenizer across all of current_doc first. If\n    169     # the chunk is too big, then we will reduce text in pieces\n\nValueError: A single term is larger than the allowed chunk size.\nTerm size: 414\nChunk size: 357Effective chunk size: 357","like_count":1,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":616762,"discussion_content":"1. 换一下 splitter，用SpacyTextSplitter以及对应中文的模型\n2. 设置一下 chunk_size （大一点），chunk_overlap（小一点）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683093709,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1681607,"avatar":"https://static001.geekbang.org/account/avatar/00/19/a8/c7/f57dadb9.jpg","nickname":"张弛","note":"","ucode":"77E0BC5D0667A8","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":615502,"discussion_content":"遇到了同样的问题，辛苦老师帮忙解答，谢谢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1682307268,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":372959,"user_name":"胡萝卜","can_delete":false,"product_type":"c1","uid":2456594,"ip_address":"上海","ucode":"54DF5159C1704C","user_header":"https://static001.geekbang.org/account/avatar/00/25/7c/12/7b9a2efb.jpg","comment_is_top":false,"comment_ctime":1681867879,"is_pvip":false,"replies":[{"id":136469,"content":"已经有人做了，可以去看 https:&#47;&#47;github.com&#47;openai&#47;whisper&#47;discussions&#47;2","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1683084778,"ip_address":"上海","comment_id":372959,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"能做成流式的音转文吗？","like_count":1,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":616696,"discussion_content":"已经有人做了，可以去看 https://github.com/openai/whisper/discussions/2","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683084778,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":373485,"user_name":"子辰","can_delete":false,"product_type":"c1","uid":1626032,"ip_address":"上海","ucode":"4435EC483C7361","user_header":"https://static001.geekbang.org/account/avatar/00/18/cf/b0/5ff252b6.jpg","comment_is_top":false,"comment_ctime":1682563835,"is_pvip":false,"replies":[{"id":136460,"content":"Mac下不是NVidia的显卡，是跑在CPU上的，可以看看 Whisper cpp之类的项目，有人移植了可以用M1&#47;M2的GPU","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1683083069,"ip_address":"上海","comment_id":373485,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"默认就是跑GPU的吗？我用 mac 看活动监视器好像是跑在 CPU 上的。。。","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":616684,"discussion_content":"Mac下不是NVidia的显卡，是跑在CPU上的，可以看看 Whisper cpp之类的项目，有人移植了可以用M1/M2的GPU","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683083070,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3682659,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Wiba6ReQVp446vhcibQYiah5tdWPiaYAwsr6dty9ZTcZS1yXW1x9OQqPpkQbz2qyWMLPIl1T89rep1tXXEC9TefdKCjt51Crvrh2KmSO5cbeZFk/132","nickname":"Geek_e3264b","note":"","ucode":"D6388103876BD8","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":625151,"discussion_content":"环境没装好","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1691409806,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":373324,"user_name":"詹杰","can_delete":false,"product_type":"c1","uid":3586914,"ip_address":"四川","ucode":"3744C62FD8C388","user_header":"https://static001.geekbang.org/account/avatar/00/36/bb/62/f87ee12f.jpg","comment_is_top":false,"comment_ctime":1682391226,"is_pvip":false,"replies":[{"id":136484,"content":"看一下 whisper cpp 或者 whisper accelerated 或者 faster-whisper 这些项目。\n\n应该有挺多人在做Whisper的加速方案的，应该可以做到5分钟以内转录60分钟的音频的。\n\n","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1683086816,"ip_address":"上海","comment_id":373324,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"老师，whisper开源模型本地部署支持批量推理不？怎么批量推理呢？目前就是需要完成很多很多的语言识别任务，效率跟不上，想请教老师怎么解决呢","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":616720,"discussion_content":"看一下 whisper cpp 或者 whisper accelerated 或者 faster-whisper 这些项目。\n\n应该有挺多人在做Whisper的加速方案的，应该可以做到5分钟以内转录60分钟的音频的。\n\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683086816,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":373318,"user_name":"詹杰","can_delete":false,"product_type":"c1","uid":3586914,"ip_address":"四川","ucode":"3744C62FD8C388","user_header":"https://static001.geekbang.org/account/avatar/00/36/bb/62/f87ee12f.jpg","comment_is_top":false,"comment_ctime":1682390465,"is_pvip":false,"replies":[{"id":136487,"content":"有 Whisper-Accelerated，通过CPU多线程\n多GPU也可以啊，指定每个任务使用的device就好了。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1683086926,"ip_address":"上海","comment_id":373318,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"徐老师，我想问一个提高开源whisper模型计算效率的问题，我用多线程去调度解析会报错，请问如何提高效率呢，我只能再买显卡，多部署几台服务嘛？","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":616723,"discussion_content":"有 Whisper-Accelerated，通过CPU多线程\n多GPU也可以啊，指定每个任务使用的device就好了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683086926,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":373039,"user_name":"Geek_00eb03","can_delete":false,"product_type":"c1","uid":1300603,"ip_address":"湖北","ucode":"35D123F2A0FD43","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJiaPZjokKDOAicIIOtJB0Omkw5tXZem8icbDBpxqhqE5iaMicHbEgEicESiaGDZ7icSwqmYfqXc4r8uhKHwQ/132","comment_is_top":false,"comment_ctime":1681960922,"is_pvip":false,"replies":[{"id":136495,"content":"whisper用CPU也能跑，就是比起GPU还是慢一些。可以看看 whisper cpp或者 whisper accelerated 之类的项目","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1683087377,"ip_address":"上海","comment_id":373039,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"普通服务器的CPU 能不能跑起来whisper 开源模型？","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":616732,"discussion_content":"whisper用CPU也能跑，就是比起GPU还是慢一些。可以看看 whisper cpp或者 whisper accelerated 之类的项目","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683087377,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":373028,"user_name":"安菲尔德","can_delete":false,"product_type":"c1","uid":1660533,"ip_address":"北京","ucode":"A7B310463C15F1","user_header":"https://static001.geekbang.org/account/avatar/00/19/56/75/28a29e7c.jpg","comment_is_top":false,"comment_ctime":1681953346,"is_pvip":false,"replies":[{"id":136516,"content":"有付费订阅，付费订阅才能无限使用 GPT-4 和 Claude+。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1683091868,"ip_address":"上海","comment_id":373028,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"老师，请教一个非技术问题，peo.com这个网站是收费的么，如果不收费的话，他们里面chatgpt功能调用的是openai的接口实现的么，如果是的话，那岂不是很费钱，他们怎么赚钱呢？","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":616757,"discussion_content":"有付费订阅，付费订阅才能无限使用 GPT-4 和 Claude+。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683091868,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":373022,"user_name":"张弛","can_delete":false,"product_type":"c1","uid":1681607,"ip_address":"美国","ucode":"77E0BC5D0667A8","user_header":"https://static001.geekbang.org/account/avatar/00/19/a8/c7/f57dadb9.jpg","comment_is_top":false,"comment_ctime":1681927449,"is_pvip":false,"replies":[{"id":136497,"content":"看报错应该是文本切分的时候，单个 term太大了。一个是建议用 SpacySplitter 第二个是设置一下 chunk_size（设大），以及 chunk_overlap（设小）","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1683088236,"ip_address":"上海","comment_id":373022,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"自己尝试转录了一个播客，成功用Colab进行了语音转文字，一共生成了4个12kb的文本文件，建索引也没问题，但是到最后调模型总结就会出错。用GPT和google查了半天，也尝试自己对比转录的文本和您之前的案例中使用的朝花夕拾的文本，确实没看出差别，最终也没能解决，只好来求助老师了，谢谢！\n\n&#47;usr&#47;local&#47;lib&#47;python3.9&#47;dist-packages&#47;llama_index&#47;langchain_helpers&#47;text_splitter.py in split_text_with_overlaps(self, text, extra_info_str)\n    155             num_cur_tokens = max(len(self.tokenizer(cur_token)), 1)\n    156             if num_cur_tokens &gt; effective_chunk_size:\n--&gt; 157                 raise ValueError(\n    158                     &quot;A single term is larger than the allowed chunk size.\\n&quot;\n    159                     f&quot;Term size: {num_cur_tokens}\\n&quot;\n\nValueError: A single term is larger than the allowed chunk size.\nTerm size: 683\nChunk size: 358Effective chunk size: 358","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":616734,"discussion_content":"看报错应该是文本切分的时候，单个 term太大了。一个是建议用 SpacySplitter 第二个是设置一下 chunk_size（设大），以及 chunk_overlap（设小）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683088236,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1300603,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJiaPZjokKDOAicIIOtJB0Omkw5tXZem8icbDBpxqhqE5iaMicHbEgEicESiaGDZ7icSwqmYfqXc4r8uhKHwQ/132","nickname":"Geek_00eb03","note":"","ucode":"35D123F2A0FD43","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":614969,"discussion_content":"同样的错误， 求助老师了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1681986766,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"湖北","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":395910,"user_name":"极客用户","can_delete":false,"product_type":"c1","uid":3868560,"ip_address":"广东","ucode":"86936B48F68998","user_header":"","comment_is_top":false,"comment_ctime":1732437246,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"vad模型可以做分割","like_count":0},{"had_liked":false,"id":387645,"user_name":"方梁","can_delete":false,"product_type":"c1","uid":1899249,"ip_address":"北京","ucode":"80FA42955D250E","user_header":"https://static001.geekbang.org/account/avatar/00/1c/fa/f1/7d21b2b0.jpg","comment_is_top":false,"comment_ctime":1708322057,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"很好","like_count":0},{"had_liked":false,"id":385121,"user_name":"小雨青青","can_delete":false,"product_type":"c1","uid":1017008,"ip_address":"四川","ucode":"EF521E12CEB3BF","user_header":"https://static001.geekbang.org/account/avatar/00/0f/84/b0/abb7bfe3.jpg","comment_is_top":false,"comment_ctime":1702118019,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"老师，我的请求被拒绝了，这种怎么办呢？ openai.RateLimitError: Error code: 429 - {&#39;error&#39;: {&#39;message&#39;: &#39;Your access was terminated due to violation of our policies, please check your email for more information. If you believe this is in error and would like to appeal, please contact us through our help center at help.openai.com.&#39;, &#39;type&#39;: &#39;access_terminated&#39;, &#39;param&#39;: None, &#39;code&#39;: &#39;access_terminated&#39;}}","like_count":0,"discussions":[{"author":{"id":2403622,"avatar":"https://static001.geekbang.org/account/avatar/00/24/ad/26/767527f6.jpg","nickname":"Owen","note":"","ucode":"FDE0D574B8ED5A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":639491,"discussion_content":"你做了什么事情 怎么被openai封号了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1710727686,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":377395,"user_name":"Mr.wu","can_delete":false,"product_type":"c1","uid":3170416,"ip_address":"广东","ucode":"1860258E8E33BC","user_header":"https://static001.geekbang.org/account/avatar/00/30/60/70/6e816acc.jpg","comment_is_top":false,"comment_ctime":1688441266,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"请教一下whisper能读取流式文本输出语音么，接gpt要等待输出完毕后再转文本延迟太久了，实时交互体验不好","like_count":0},{"had_liked":false,"id":376980,"user_name":"神毓逍遥","can_delete":false,"product_type":"c1","uid":2147220,"ip_address":"安徽","ucode":"83351CB18B190E","user_header":"https://static001.geekbang.org/account/avatar/00/20/c3/94/e89ebc50.jpg","comment_is_top":false,"comment_ctime":1687788725,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"语音转文本，然后本地转录的开源模型有推荐吗","like_count":0,"discussions":[{"author":{"id":1029016,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b3/98/2ad8b465.jpg","nickname":"Hugh","note":"","ucode":"126A56632CB09A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":622120,"discussion_content":"文章里不是说了 Whisper 是开源的吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1687930714,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":375724,"user_name":"Geek_083973","can_delete":false,"product_type":"c1","uid":1791945,"ip_address":"美国","ucode":"DA24A06C6B7451","user_header":"","comment_is_top":false,"comment_ctime":1685926383,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"老师，chatgpt是不是不支持根据文本生成语音\n","like_count":0},{"had_liked":false,"id":372952,"user_name":"树静风止","can_delete":false,"product_type":"c1","uid":1929509,"ip_address":"北京","ucode":"66089F1ECE811E","user_header":"https://static001.geekbang.org/account/avatar/00/1d/71/25/e9bad0b3.jpg","comment_is_top":false,"comment_ctime":1681862265,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"显存大小限制生产力😂","like_count":0}]}