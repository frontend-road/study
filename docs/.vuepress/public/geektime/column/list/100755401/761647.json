{"id":761647,"title":"08｜使用LLM辅助业务理解","content":"<p>你好，我是徐昊，今天我们来继续学习AI时代的软件工程。</p><p>在上一节课，我们介绍了如何使用业务模型通过模型展开的方式，帮助我们理解业务。我们也谈到了，在使用模型展开的时候，我们处在庞杂的认知模式下。因此，提效的关键在于构造思维链，让LLM帮助我们更好地应用不可言说知识。</p><p>那么今天，我们就围绕之前的例子，看看如何通过LLM辅助我们理解不同的业务场景。</p><h2>通过半结构化自然语言表示模型</h2><p>当我们想让大语言模型（Large Language Model，LLM）帮助我们通过模型解释业务知识时，首先就会碰到一个问题，如何将我们的模型表达为大语言模型能够理解的形式。</p><p>其实这比想象中要容易得多，因为LLM不仅仅懂得自然语言，它还懂得各种编程语言或结构化描述语言。我们可以使用 <strong>Mermaid</strong> 描述我们的领域模型：</p><pre><code class=\"language-plain\">classDiagram\n  Department \"1\" -- \"*\" Program \n  Department \"1\" -- \"*\" Offer \n  Offer  \"1\" -- \"1\" Program\n  Program \"1\" -- \"1\" Curriculum \n  Curriculum \"1\" -- \"*\" Course \n  Student \"1\" -- \"1\" ProgramEnrollment\n  ProgramEnrollment \"1\" -- \"*\" CourseEnrollment\n  Student \"1\" -- \"1\" Offer\n  ProgramEnrollment \"1\" -- \"1\" Program\n  CourseEnrollment \"1\" -- \"1\" Course \n  \n  class Department {\n  }\n  class Program {\n  }\n  class Curriculum {\n  }\n  class Course {\n  }\n  class Student {\n  }\n  class Offer {\n  }\n  class ProgramEnrollment {\n  }\n  class CourseEnrollment {\n  }\n</code></pre><!-- [[[read_end]]] --><p>当我们把这段Mermaid录入LLM，它会为我们提供它的理解：</p><p><img src=\"https://static001.geekbang.org/resource/image/1c/27/1ce601ebb1a7d874fe13a6928ed26d27.jpg?wh=1412x1651\" alt=\"\"></p><p>其中大部分的内容都是正确的，只是不够准确。比如领域概念的名字，在LLM中的解读部分就是错误的。再比如，关联所代表的含义，也不甚准确。图里Department、Program、Offer三个对象间的意思就不对。</p><p>这时候，我们可以使用一个我发明的技巧，叫<strong>半结构化自然语言</strong>。所谓半结构化自然语言，就是在结构化的描述中混入自然语言去补充对应的上下文。说人话就是<strong>写注释</strong>。</p><p>那为什么要叫半结构化自然语言呢？因为在LLM的视角来看，结构化的信息和<strong>非结构化的自然语言一样重要</strong>。半结构化自然语言既<strong>可以看作以自然语言给予结构化数据补充，也可以看作结构化数据赋予自然语言结构</strong>。而从赋予自然语言结构的角度，就能够解锁更多对于LLM应用的巧思。</p><p>首先我们来解决一下命名的问题。在Mermaid中增加注释，并给出解释和例子：</p><pre><code class=\"language-plain\">classDiagram\n  ...\n  %% 学院\n  class Department {\n  }\n  %% 教学计划\n  %% 比如，计算机科学与技术学士学位教学计划，或是计算机科学与技术硕士学位教学计划\n  class Program {\n  }\n  %% 教学大纲\n  class Curriculum {\n  }\n  %% 教学课程\n  class Course {\n  }\n  %% 学生\n  class Student {\n  }\n  %% 录取通知\n  %% 通知学生被那个教学计划录取，比如张三录取为学士学位学生\n  class Offer {\n  }\n  %% 学籍\n  %% 根据录取通知将学籍注册到指定的教学计划，比如，张三根据录取通知注册为2023年入学的计算机科学与技术学士学位教学计划学生\n  class ProgramEnrollment {\n  }\n  %% 选课\n  %% 在学籍有效期内，需要根据教学大纲选课\n  class CourseEnrollment {\n  }\n</code></pre><p><img src=\"https://static001.geekbang.org/resource/image/e2/a1/e27d4c728f5b90f128e39190db74bea1.jpg?wh=1419x1744\" alt=\"\"></p><p>这就是半结构化自然语言为什么会被称作半结构化自然语言。我们通过注释，实际上使用了<strong>少样本迁移学习（Few Shots Example）</strong>，在一个小范围的上下文中，给LLM提供了更为具体的迁移指引。</p><p>接下来我们用同样的方法来处理关联关系。通过Mermaid的语法，标注关系之间方向和含义，并提供注释：</p><pre><code class=\"language-plain\">classDiagram\n  Department \"1\" *-- \"*\" Program: 提供不同学位的教学计划 &gt;\n  Department \"1\" *-- \"*\" Offer: 为学生发出录取通知 &gt;\n  Offer \"1\" --&gt; \"1\" Program: 录取通知针对某个学位 &gt;\n  Program \"1\" --&gt; \"1\" Curriculum: 教学计划对应的教学大纲 &gt;\n  Curriculum \"1\" *--&gt; \"*\" Course: 组成教学大纲的课程 &gt;\n  Student \"1\" --&gt; \"1\" ProgramEnrollment: 学生登录的学籍 &gt;\n  ProgramEnrollment \"1\" *-- \"*\" CourseEnrollment: 在学籍有效期内，需要根据教学大纲选课 &gt;\n  Student \"1\" --&gt; \"1\" Offer : 学生拿到的入学通知 &gt;\n  ProgramEnrollment \"1\" --&gt; \"1\" Program: 录取通知中指定的教学计划 &gt;\n  CourseEnrollment \"1\" --&gt; \"1\" Course: 选定的课程 &gt;\n  %% ProgramEnrollment根据Offer生成，表示学生已经到校注册\n  \n  ...\n</code></pre><p><img src=\"https://static001.geekbang.org/resource/image/ef/88/ef67a430c500aa994de452f2da1bbc88.jpg?wh=1386x1899\" alt=\"\"></p><p>至此，我们可以看到LLM已经可以理解我们包含在模型中的业务知识了。</p><h2>围绕业务上下文进行模型的展开</h2><p>让我们再看一下上节课中模型展开之后的结果：</p><p><img src=\"https://static001.geekbang.org/resource/image/20/fd/20b68a1fc9c93eaa62fa2c6e23d5f5fd.jpg?wh=1920x978\" alt=\"\"></p><p>可以明显看到，我们的模型展开了两次。第一次是根据<strong>Given</strong>描述的场景，寻找样例数据，然后再用模型实例化解释这个数据。第二次是根据<strong>When</strong>的描述，引入了数据改变，然后再用模型实例化解释这个数据。</p><p>这是一个典型的<strong>知识生成（Generated Knowledge）</strong>场景。下面我来展示一下这个知识提取的过程。让我们先做一个提示词模板，然后先给出第一个任务，让LLM根据验收条件生成样例数据。</p><pre><code class=\"language-plain\">领域模型\n======\n```mermaid\n{model}\n```\n\n用户故事\n======\n{user_story}\n\n验收场景\n======\n{ac}\n\n任务\n===\n数据都以yaml格式给出。\n首先，请根据领域模型理解用户故事中的场景，并针对验收场景中Given的部分，给出样例数据。\n</code></pre><p><img src=\"https://static001.geekbang.org/resource/image/bd/9f/bde911aa4795b0c4f0165c4a80440a9f.jpg?wh=1357x2350\" alt=\"\"></p><p>我们看到此处的模型展开与图中得到的结果是一样的，并且LLM按照模型的指引，在当前的上下文中给出了为什么如此展开的解释。最后LLM按照要求以YAML的格式给出数据，便于我们进行数据处理与准备。我们可以改进任务，让LLM帮助我们生成后续的结果。</p><pre><code class=\"language-plain\">任务\n===\n数据都以yaml格式给出。\n首先，请根据领域模型理解用户故事中的场景，并针对验收场景中Given的部分，给出样例数据。\n然后，参看验收场景中When的部分，给出样例数据会产生怎样的改变。\n</code></pre><p><img src=\"https://static001.geekbang.org/resource/image/75/5b/757b842b58007097aaee54531aa9ed5b.jpg?wh=1367x2508\" alt=\"\"></p><p>这个结果基本是正确的，但是在注册的时候，LLM认为应该连同课程一起注册了。这并不是我们希望的结果。</p><p>那么我们可以继续在半结构化自然语言中，包含一部分<strong>思维链的内容（Chain of Thought，CoT）</strong>，也就是解释一下为什么注册和选课应该是分开的环节，并不应该合并<strong>。</strong></p><pre><code class=\"language-plain\">classDiagram\n  Department \"1\" *-- \"*\" Program: 提供不同学位的教学计划 &gt;\n  Department \"1\" *-- \"*\" Offer: 为学生发出录取通知 &gt;\n  Offer \"1\" --&gt; \"1\" Program: 录取通知针对某个学位 &gt;\n  Program \"1\" --&gt; \"1\" Curriculum: 教学计划对应的教学大纲 &gt;\n  Curriculum \"1\" --&gt; \"*\" Course: 组成教学大纲的课程 &gt;\n  Student \"1\" --&gt; \"1\" ProgramEnrollment: 学生登录的学籍 &gt;\n  ProgramEnrollment \"1\" --&gt; \"*\" CourseEnrollment: 在学籍有效期内，需要根据教学大纲选课 &gt;\n  Student \"1\" --&gt; \"1\" Offer : 学生拿到的入学通知 &gt;\n  ProgramEnrollment \"1\" --&gt; \"1\" Program: 录取通知中指定的教学计划 &gt;\n  CourseEnrollment \"1\" --&gt; \"1\" Course: 选定的课程 &gt;\n  %% ProgramEnrollment根据Offer生成，表示学生已经到校注册\n  %% 向ProgramEnrollment中添加CourseEnrollment，表示学生选课。选课与注册是不同的流程。\n</code></pre><p><img src=\"https://static001.geekbang.org/resource/image/b0/cd/b0540c68068ac41d35e6d46d6b3af5cd.jpg?wh=1425x1676\" alt=\"\"></p><p>通过在模型描述的注释中，引入部分<strong>思维链的内容</strong>，我们成功地指导了LLM按照模型与我们的期待，完成了模型展开的部分。</p><h2>小结</h2><p>到此为止，我们通过将模型转化为Mermaid格式，并将其转化为半结构化自然语言，指导LLM帮助我们完成了模型展开。这里有几个问题需要注意。</p><p>第一，<strong>通过Mermaid描述的类图，极大地简化了我们构造CoT的难度</strong>。这是因为Mermaid描述的类图，本身就是对于抽象概念的表述。而LLM可以理解Mermaid中的内容，这样LLM会自然而然地使用Mermaid中的概念，做下一步分解映射的指引。这也是目前为止（2023年12月），我们构造思维链最简单的方法。</p><p>第二，<strong>在LLM通过Mermaid构造的原始思维链中，LLM会更多地将它映射到方案域</strong>。所以需要我们通过半结构化自然语言的方式，以问题域的角度，对思维链进行标注。也就是，通过注释给予更多的上下文信息，并且在Mermaid允许提供额外信息的地方，提供自然语言的说明。</p><p>第三，由于我们使用的是类图，一些隐含的关系需要通过额外的方式补充。当然，如果我们愿意，还可以逐步引入关键逻辑的时序图，进一步帮助LLM理解业务上下文。但是，以我的经验，大部分时候，一些简单的补充就已经足够了。</p><p>最后，如果你不会写Mermaid或是别的结果描述，可以使用ChatGPT-4的识图功能，让它生成最初始的版本，再在其上修改。</p><p><img src=\"https://static001.geekbang.org/resource/image/00/8e/000781a4fb00cccde317d200778b3e8e.jpg?wh=1578x4962\" alt=\"\"></p><h2>思考题</h2><p>请使用这节课介绍的技术，在其他场景中展开模型。</p><p>欢迎你在留言区分享自己的思考或疑惑，我们会把精彩内容置顶供大家学习讨论。</p>","neighbors":{"left":{"article_title":"07｜通过业务建模应用业务知识","id":761096},"right":{"article_title":"09｜LLM辅助建模（一）：构造反馈循环","id":762250}},"comments":[{"had_liked":false,"id":389028,"user_name":"李威","can_delete":false,"product_type":"c1","uid":1460961,"ip_address":"湖南","ucode":"3409A9390BD1FD","user_header":"https://static001.geekbang.org/account/avatar/00/16/4a/e1/2a498473.jpg","comment_is_top":true,"comment_ctime":1711418741,"is_pvip":false,"replies":[{"id":141565,"content":"以目前chtgpt的context window 很难超过 而如果超过 你可以看一下 领域模型是不是抽程度不够","user_name":"作者回复","user_name_real":"编辑","uid":2537798,"ctime":1711422791,"ip_address":"浙江","comment_id":389028,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100755401,"comment_content":"请教老师：对于一个复杂的软件系统有大量的领域模型，所有的领域模型及其他们之间的关系我都用mermaid格式编写好，并添加相应的注释，但是最终生成的文本超过了LLM可接受最大字数限制，我譔怎么办呢？\n\n当然我可以根据限界上下文或者功能模块将领域模型进行拆分，每次只为LLM提供部分领域模型的半结构化自然语言描述文本，这样可以让LLM针对部分业务需求为我提供相关的辅助。\n\n还有一种办法是每次为LLM提供部分领域模型的半结构化自然语言描述文本，然后让其先总结一把，之后再输入另一部分的领域模型，继续让其总结以压缩文本内容。但是我试了一下发现，针对这种领域模型的半结构化自然语言的描述文本，LLM一总结就把重要的领域概念直接给总结没了，下次直接使用LLM总结后的文本重新发起一轮新的聊天对话，他就完全不知道自己在说什么了。\n\n所以，请教老师，如何突破LLM对字数的限制，将大量的领域知识一把喂给LLM？","like_count":2,"discussions":[{"author":{"id":2537798,"avatar":"https://static001.geekbang.org/account/avatar/00/26/b9/46/758ecf4a.jpg","nickname":"徐八叉","note":"","ucode":"DA6D1EB08A7396","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":640339,"discussion_content":"以目前chtgpt的context window 很难超过 而如果超过 你可以看一下 领域模型是不是抽程度不够","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1711422791,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":388995,"user_name":"一只豆","can_delete":false,"product_type":"c1","uid":1003886,"ip_address":"广东","ucode":"73953B25ADC953","user_header":"https://static001.geekbang.org/account/avatar/00/0f/51/6e/efb76357.jpg","comment_is_top":true,"comment_ctime":1711354261,"is_pvip":false,"replies":[{"id":141560,"content":"不是显式知识 是不可言说 因为任何概念模型的使用 至少都是complicated。这就好像 不能说因为有书教游泳 游泳就是显式知识","user_name":"作者回复","user_name_real":"编辑","uid":2537798,"ctime":1711415008,"ip_address":"北京","comment_id":388995,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100755401,"comment_content":"有个很模糊的直觉性感触：这两讲中的业务模型好像是比较 E-R 样子的，好像偏重于显性知识的核心脉络全写出来。看了编辑推荐的 《创造知识的企业》后，特别是SECI 模型，我在想 未来的模型是不是 不一定停留在显性知识范畴，而是从人类直接提取不可言说知识后形成的模型。所以我的问题是：我的推论是否合理？哪里偏差了？如果存在这种新模型，LLM 如何辅助我们展开，并增强业务理解？","like_count":0,"discussions":[{"author":{"id":2537798,"avatar":"https://static001.geekbang.org/account/avatar/00/26/b9/46/758ecf4a.jpg","nickname":"徐八叉","note":"","ucode":"DA6D1EB08A7396","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":640321,"discussion_content":"不是显式知识 是不可言说 因为任何概念模型的使用 至少都是complicated。这就好像 不能说因为有书教游泳 游泳就是显式知识","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1711415008,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":1,"child_discussions":[{"author":{"id":1003886,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/51/6e/efb76357.jpg","nickname":"一只豆","note":"","ucode":"73953B25ADC953","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2537798,"avatar":"https://static001.geekbang.org/account/avatar/00/26/b9/46/758ecf4a.jpg","nickname":"徐八叉","note":"","ucode":"DA6D1EB08A7396","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":640391,"discussion_content":"明白了～ 有用的模型都是直达本质的真经。媒介上的稀松平常不能掩盖真经的本质，更不妨碍 在无数具体业务场景下展开时，传递业务知识的的巨大威力～ （拱手礼）","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1711453559,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":640321,"ip_address":"广东","group_id":0},"score":640391,"extra":""}]}]},{"had_liked":false,"id":389021,"user_name":"术子米德","can_delete":false,"product_type":"c1","uid":1898023,"ip_address":"浙江","ucode":"382EA7E2AF0B56","user_header":"https://static001.geekbang.org/account/avatar/00/1c/f6/27/c27599ae.jpg","comment_is_top":false,"comment_ctime":1711407312,"is_pvip":true,"replies":[{"id":141566,"content":"使用模型 目的是理解业务 并不是要从模型直接去写代码","user_name":"作者回复","user_name_real":"编辑","uid":2537798,"ctime":1711422831,"ip_address":"浙江","comment_id":389021,"utype":1}],"discussion_count":4,"race_medal":0,"score":2,"product_id":100755401,"comment_content":"08 | 使用LLM辅助业务理解\n🤔☕️🤔☕️🤔\n【R】Mermaid（🧜🏻‍♀️），用它来描述业务模型，能绘制成示意图，人瞄一眼就懂，LLM也能读懂，这样就双赢。\n半结构化自然语言（即：写注释），一方面，作为自然语言的结构化补充，另一方面，作为结构化语言的自然补充，这样就双边补充、双边互通。\n【.I.】之前，我敲代码，敲的时候，我Clear，跑一下发现不对，那就转到调试，调的时候，我到处打断点，待程序跑到那里，我停下来看看，我大概率是Complex、小概率是Chaotic。无论怎样，我总能一点点来，喝点水、走走路、熬个夜、睡一觉、问一问，总能搞定。\n【Q】如今，自然语言的描述、加上半结构化的注释、再加上增强半结构化的Mermaid，输出的内容有个三长两短，除了一遍又一遍尝试，我咋个“逐行调试”法？\n—  by 术子米德@2024年3月25日","like_count":0,"discussions":[{"author":{"id":2537798,"avatar":"https://static001.geekbang.org/account/avatar/00/26/b9/46/758ecf4a.jpg","nickname":"徐八叉","note":"","ucode":"DA6D1EB08A7396","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":640342,"discussion_content":"使用模型 目的是理解业务 并不是要从模型直接去写代码","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1711422831,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":1,"child_discussions":[{"author":{"id":1898023,"avatar":"https://static001.geekbang.org/account/avatar/00/1c/f6/27/c27599ae.jpg","nickname":"术子米德","note":"","ucode":"382EA7E2AF0B56","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":2537798,"avatar":"https://static001.geekbang.org/account/avatar/00/26/b9/46/758ecf4a.jpg","nickname":"徐八叉","note":"","ucode":"DA6D1EB08A7396","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":640344,"discussion_content":"用LLM来协助理解业务模型，是这个意思嘛？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1711423258,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":640342,"ip_address":"浙江","group_id":0},"score":640344,"extra":""}]},{"author":{"id":1154294,"avatar":"https://static001.geekbang.org/account/avatar/00/11/9c/f6/eca921d9.jpg","nickname":"赫伯伯","note":"","ucode":"85722DBCB88E9C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":640875,"discussion_content":"模型生产代码，很多年前热过一阵，但快速归于平淡","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1711958834,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"河北","group_id":0},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1898023,"avatar":"https://static001.geekbang.org/account/avatar/00/1c/f6/27/c27599ae.jpg","nickname":"术子米德","note":"","ucode":"382EA7E2AF0B56","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1154294,"avatar":"https://static001.geekbang.org/account/avatar/00/11/9c/f6/eca921d9.jpg","nickname":"赫伯伯","note":"","ucode":"85722DBCB88E9C","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":640885,"discussion_content":"代码补全，这个效果，不改变喜欢，比不过IDE的自动补全，不过，改进喜欢，会有收益，难在体系越大，越改得呆滞。代码生成，绝对是趋势，加上老师的方法论，以及最领先的工具，已经试验成功，顶多3年就会产生断崖式的软件工程实践效率👀","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1711966625,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":640875,"ip_address":"浙江","group_id":0},"score":640885,"extra":""}]}]},{"had_liked":false,"id":388980,"user_name":"范飞扬","can_delete":false,"product_type":"c1","uid":2721761,"ip_address":"广东","ucode":"A665DF46833A81","user_header":"https://static001.geekbang.org/account/avatar/00/29/87/e1/b3edcc09.jpg","comment_is_top":false,"comment_ctime":1711329865,"is_pvip":false,"replies":[{"id":141545,"content":"whatever works for you","user_name":"作者回复","user_name_real":"编辑","uid":2537798,"ctime":1711334051,"ip_address":"浙江","comment_id":388980,"utype":1}],"discussion_count":4,"race_medal":0,"score":2,"product_id":100755401,"comment_content":"神操作！\n\n问个细微的问题，请教一下老师和各位同学的经验：\n\n对于比较庞大的领域模型，画图的方式和顺序有什么经验嘛？比如，应该采用以下哪种方式呢？\n\n1、先用draw.io等类似工具画图，再让gpt生成 mermaid.  (可能gpt看不懂？）\n\n2、一开始就用mermaid来画图（可能有些没法用mermaid表达？或者不太灵活？）\n\n3、迭代交织使用1和2。\n\n4、还有更好的方式？","like_count":0,"discussions":[{"author":{"id":2721761,"avatar":"https://static001.geekbang.org/account/avatar/00/29/87/e1/b3edcc09.jpg","nickname":"范飞扬","note":"","ucode":"A665DF46833A81","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":642211,"discussion_content":"后面直接让LLM建了，所以答案比较明显：直接从mermaid开始","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1713413893,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2537798,"avatar":"https://static001.geekbang.org/account/avatar/00/26/b9/46/758ecf4a.jpg","nickname":"徐八叉","note":"","ucode":"DA6D1EB08A7396","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":640236,"discussion_content":"whatever works for you","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1711334052,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":2,"child_discussions":[{"author":{"id":2895829,"avatar":"https://static001.geekbang.org/account/avatar/00/2c/2f/d5/7499d3f1.jpg","nickname":"预测师啊","note":"","ucode":"5F4B815182EC30","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":2537798,"avatar":"https://static001.geekbang.org/account/avatar/00/26/b9/46/758ecf4a.jpg","nickname":"徐八叉","note":"","ucode":"DA6D1EB08A7396","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":640250,"discussion_content":"这题我熟，关键是找到合适的粒度 至于什么是合适的，以及如何找到，那可得加钱了","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1711340932,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":640236,"ip_address":"上海","group_id":0},"score":640250,"extra":""},{"author":{"id":2721761,"avatar":"https://static001.geekbang.org/account/avatar/00/29/87/e1/b3edcc09.jpg","nickname":"范飞扬","note":"","ucode":"A665DF46833A81","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2537798,"avatar":"https://static001.geekbang.org/account/avatar/00/26/b9/46/758ecf4a.jpg","nickname":"徐八叉","note":"","ucode":"DA6D1EB08A7396","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":640341,"discussion_content":"😂I just wonder what works for you","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1711422807,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":640236,"ip_address":"广东","group_id":0},"score":640341,"extra":""}]}]},{"had_liked":false,"id":389196,"user_name":"aoe","can_delete":false,"product_type":"c1","uid":1121758,"ip_address":"浙江","ucode":"1C6201EDB4E954","user_header":"https://static001.geekbang.org/account/avatar/00/11/1d/de/62bfa83f.jpg","comment_is_top":false,"comment_ctime":1711802149,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100755401,"comment_content":"第二次学习，把示例中变量 {user_story}、{ac} 从 07 课中补充完整后询问 AI 获得了正常的答案\n第一次学习时，直接粘贴了模板，AI 和我都懵了","like_count":2},{"had_liked":false,"id":389246,"user_name":"范飞扬","can_delete":false,"product_type":"c1","uid":2721761,"ip_address":"广东","ucode":"A665DF46833A81","user_header":"https://static001.geekbang.org/account/avatar/00/29/87/e1/b3edcc09.jpg","comment_is_top":false,"comment_ctime":1711954500,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100755401,"comment_content":"趁还没讲到测试驱动AI开发，我盲猜一下：生成 yaml 数据后，就可以用于编写 TDD的测试了，有了测试，“功能良好”的软件 就不是啥问题了。不过仅靠这些yaml，应该还没法保证“架构良好”？架构良好得靠CoT？ 那CoT从哪来呢？直接复制粘贴架构的描述？（比如六边形架构的描述？）","like_count":1},{"had_liked":false,"id":389491,"user_name":"赫伯伯","can_delete":false,"product_type":"c1","uid":1154294,"ip_address":"河北","ucode":"85722DBCB88E9C","user_header":"https://static001.geekbang.org/account/avatar/00/11/9c/f6/eca921d9.jpg","comment_is_top":false,"comment_ctime":1712732281,"is_pvip":false,"replies":null,"discussion_count":4,"race_medal":0,"score":2,"product_id":100755401,"comment_content":"所以，模型展开的用途是什么？？？","like_count":0,"discussions":[{"author":{"id":1004357,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/45/8c0eb589.jpg","nickname":"D调的暖冬","note":"","ucode":"A7DE4F80470970","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":644505,"discussion_content":"如果模型无法cover 验收条件，那么说明还有业务知识没有被很好的捕获和抽象。模型的验证可以基于展开方式进行梳理","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1715270903,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1703256,"avatar":"https://static001.geekbang.org/account/avatar/00/19/fd/58/1af629c7.jpg","nickname":"6点无痛早起学习的和尚","note":"","ucode":"33A8A1CDA103F9","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":643865,"discussion_content":"我也一直很好奇，模型展开的作用是啥，以为是辅助编码，但是作者答复说“使用模型 目的是理解业务 并不是要从模型直接去写代码”","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1714706533,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2721761,"avatar":"https://static001.geekbang.org/account/avatar/00/29/87/e1/b3edcc09.jpg","nickname":"范飞扬","note":"","ucode":"A665DF46833A81","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":642210,"discussion_content":"模型是LLM帮你建的，展开了才能说明你的模型能解释业务。无法解释业务的模型，就不是个好模型","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1713413846,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1116630,"avatar":"https://static001.geekbang.org/account/avatar/00/11/09/d6/5f366427.jpg","nickname":"码农Kevin亮","note":"","ucode":"D34562461CA0A1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":641911,"discussion_content":"个人理解：展开是聚焦特定场景的描述，展开两次是方便描述动态关系变化","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1713141498,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":389350,"user_name":"范飞扬","can_delete":false,"product_type":"c1","uid":2721761,"ip_address":"浙江","ucode":"A665DF46833A81","user_header":"https://static001.geekbang.org/account/avatar/00/29/87/e1/b3edcc09.jpg","comment_is_top":false,"comment_ctime":1712206907,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100755401,"comment_content":"和 chatGPT 的聊天：https:&#47;&#47;chat.openai.com&#47;share&#47;587f2e0f-53be-4fa0-8458-7f5658b30714","like_count":0}]}