{"id":107845,"title":"19 | CommitFailedException异常怎么处理？","content":"<p>你好，我是胡夕。今天我来跟你聊聊CommitFailedException异常的处理。</p><p>说起这个异常，我相信用过Kafka Java Consumer客户端API的你一定不会感到陌生。<strong>所谓CommitFailedException，顾名思义就是Consumer客户端在提交位移时出现了错误或异常，而且还是那种不可恢复的严重异常</strong>。如果异常是可恢复的瞬时错误，提交位移的API自己就能规避它们了，因为很多提交位移的API方法是支持自动错误重试的，比如我们在上一期中提到的<strong>commitSync方法</strong>。</p><p>每次和CommitFailedException一起出现的，还有一段非常著名的注释。为什么说它很“著名”呢？第一，我想不出在近50万行的Kafka源代码中，还有哪个异常类能有这种待遇，可以享有这么大段的注释，来阐述其异常的含义；第二，纵然有这么长的文字解释，却依然有很多人对该异常想表达的含义感到困惑。</p><p>现在，我们一起领略下这段文字的风采，看看社区对这个异常的最新解释：</p><blockquote>\n<p>Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. <span class=\"orange\">You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.</span></p>\n</blockquote><!-- [[[read_end]]] --><p>这段话前半部分的意思是，本次提交位移失败了，原因是消费者组已经开启了Rebalance过程，并且将要提交位移的分区分配给了另一个消费者实例。出现这个情况的原因是，你的消费者实例连续两次调用poll方法的时间间隔超过了期望的max.poll.interval.ms参数值。这通常表明，你的消费者实例花费了太长的时间进行消息处理，耽误了调用poll方法。</p><p>在后半部分，社区给出了两个相应的解决办法（即橙色字部分）：</p><ol>\n<li>增加期望的时间间隔max.poll.interval.ms参数值。</li>\n<li>减少poll方法一次性返回的消息数量，即减少max.poll.records参数值。</li>\n</ol><p>在详细讨论这段文字之前，我还想提一句，实际上这段文字总共有3个版本，除了上面的这个最新版本，还有2个版本，它们分别是：</p><blockquote>\n<p>Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member.<span class=\"orange\"> This means that the time between subsequent calls to poll() was longer than the configured session.timeout.ms</span>, which typically implies that the poll loop is spending too much time message processing. You can address this either by <span class=\"orange\">increasing the session timeout</span> or by reducing the maximum size of batches returned in poll() with max.poll.records.</p>\n</blockquote><blockquote>\n<p>Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. <span class=\"orange\">This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms</span>, which typically implies that the poll loop is spending too much time message processing. You can address this either by <span class=\"orange\">increasing the session timeout</span> or by reducing the maximum size of batches returned in poll() with max.poll.records.</p>\n</blockquote><p>这两个较早的版本和最新版相差不大，我就不详细解释了，具体的差异我用橙色标注了。我之所以列出这些版本，就是想让你在日后看到它们时能做到心中有数，知道它们说的是一个事情。</p><p>其实不论是哪段文字，它们都表征位移提交出现了异常。下面我们就来讨论下该异常是什么时候被抛出的。从源代码方面来说，CommitFailedException异常通常发生在手动提交位移时，即用户显式调用KafkaConsumer.commitSync()方法时。从使用场景来说，有两种典型的场景可能遭遇该异常。</p><p><strong>场景一</strong></p><p>我们先说说最常见的场景。当消息处理的总时间超过预设的max.poll.interval.ms参数值时，Kafka Consumer端会抛出CommitFailedException异常。这是该异常最“正宗”的登场方式。你只需要写一个Consumer程序，使用KafkaConsumer.subscribe方法随意订阅一个主题，之后设置Consumer端参数max.poll.interval.ms=5秒，最后在循环调用KafkaConsumer.poll方法之间，插入Thread.sleep(6000)和手动提交位移，就可以成功复现这个异常了。在这里，我展示一下主要的代码逻辑。</p><pre><code>…\nProperties props = new Properties();\n…\nprops.put(&quot;max.poll.interval.ms&quot;, 5000);\nconsumer.subscribe(Arrays.asList(&quot;test-topic&quot;));\n \nwhile (true) {\n    ConsumerRecords&lt;String, String&gt; records = \n\t\tconsumer.poll(Duration.ofSeconds(1));\n    // 使用Thread.sleep模拟真实的消息处理逻辑\n    Thread.sleep(6000L);\n    consumer.commitSync();\n}\n</code></pre><p>如果要防止这种场景下抛出异常，你需要简化你的消息处理逻辑。具体来说有4种方法。</p><ol>\n<li>\n<p><strong>缩短单条消息处理的时间</strong>。比如，之前下游系统消费一条消息的时间是100毫秒，优化之后成功地下降到50毫秒，那么此时Consumer端的TPS就提升了一倍。</p>\n</li>\n<li>\n<p><strong>增加Consumer端允许下游系统消费一批消息的最大时长</strong>。这取决于Consumer端参数max.poll.interval.ms的值。在最新版的Kafka中，该参数的默认值是5分钟。如果你的消费逻辑不能简化，那么提高该参数值是一个不错的办法。值得一提的是，Kafka 0.10.1.0之前的版本是没有这个参数的，因此如果你依然在使用0.10.1.0之前的客户端API，那么你需要增加session.timeout.ms参数的值。不幸的是，session.timeout.ms参数还有其他的含义，因此增加该参数的值可能会有其他方面的“不良影响”，这也是社区在0.10.1.0版本引入max.poll.interval.ms参数，将这部分含义从session.timeout.ms中剥离出来的原因之一。</p>\n</li>\n<li>\n<p><strong>减少下游系统一次性消费的消息总数</strong>。这取决于Consumer端参数max.poll.records的值。当前该参数的默认值是500条，表明调用一次KafkaConsumer.poll方法，最多返回500条消息。可以说，该参数规定了单次poll方法能够返回的消息总数的上限。如果前两种方法对你都不适用的话，降低此参数值是避免CommitFailedException异常最简单的手段。</p>\n</li>\n<li>\n<p><strong>下游系统使用多线程来加速消费</strong>。这应该算是“最高级”同时也是最难实现的解决办法了。具体的思路就是，让下游系统手动创建多个消费线程处理poll方法返回的一批消息。之前你使用Kafka  Consumer消费数据更多是单线程的，所以当消费速度无法匹及Kafka Consumer消息返回的速度时，它就会抛出CommitFailedException异常。如果是多线程，你就可以灵活地控制线程数量，随时调整消费承载能力，再配以目前多核的硬件条件，该方法可谓是防止CommitFailedException最高档的解决之道。事实上，很多主流的大数据流处理框架使用的都是这个方法，比如Apache Flink在集成Kafka时，就是创建了多个KafkaConsumerThread线程，自行处理多线程间的数据消费。不过，凡事有利就有弊，这个方法实现起来并不容易，特别是在多个线程间如何处理位移提交这个问题上，更是极容易出错。在专栏后面的内容中，我将着重和你讨论一下多线程消费的实现方案。</p>\n</li>\n</ol><p>综合以上这4个处理方法，我个人推荐你首先尝试采用方法1来预防此异常的发生。优化下游系统的消费逻辑是百利而无一害的法子，不像方法2、3那样涉及到Kafka Consumer端TPS与消费延时（Latency）的权衡。如果方法1实现起来有难度，那么你可以按照下面的法则来实践方法2、3。</p><p>首先，你需要弄清楚你的下游系统消费每条消息的平均延时是多少。比如你的消费逻辑是从Kafka获取到消息后写入到下游的MongoDB中，假设访问MongoDB的平均延时不超过2秒，那么你可以认为消息处理需要花费2秒的时间。如果按照max.poll.records等于500来计算，一批消息的总消费时长大约是1000秒，因此你的Consumer端的max.poll.interval.ms参数值就不能低于1000秒。如果你使用默认配置，那默认值5分钟显然是不够的，你将有很大概率遭遇CommitFailedException异常。将max.poll.interval.ms增加到1000秒以上的做法就属于上面的第2种方法。</p><p>除了调整max.poll.interval.ms之外，你还可以选择调整max.poll.records值，减少每次poll方法返回的消息数。还拿刚才的例子来说，你可以设置max.poll.records值为150，甚至更少，这样每批消息的总消费时长不会超过300秒（150*2=300），即max.poll.interval.ms的默认值5分钟。这种减少max.poll.records值的做法就属于上面提到的方法3。</p><p><strong>场景二</strong></p><p>Okay，现在我们已经说完了关于CommitFailedException异常的经典发生场景以及应对办法。从理论上讲，关于该异常你了解到这个程度，已经足以帮助你应对应用开发过程中由该异常带来的“坑”了 。但其实，该异常还有一个不太为人所知的出现场景。了解这个冷门场景，可以帮助你拓宽Kafka Consumer的知识面，也能提前预防一些古怪的问题。下面我们就来说说这个场景。</p><p>之前我们花了很多时间学习Kafka的消费者，不过大都集中在消费者组上，即所谓的Consumer Group。其实，Kafka Java Consumer端还提供了一个名为Standalone Consumer的独立消费者。它没有消费者组的概念，每个消费者实例都是独立工作的，彼此之间毫无联系。不过，你需要注意的是，独立消费者的位移提交机制和消费者组是一样的，因此独立消费者的位移提交也必须遵守之前说的那些规定，比如独立消费者也要指定group.id参数才能提交位移。你可能会觉得奇怪，既然是独立消费者，为什么还要指定group.id呢？没办法，谁让社区就是这么设计的呢？总之，消费者组和独立消费者在使用之前都要指定group.id。</p><p>现在问题来了，如果你的应用中同时出现了设置相同group.id值的消费者组程序和独立消费者程序，那么当独立消费者程序手动提交位移时，Kafka就会立即抛出CommitFailedException异常，因为Kafka无法识别这个具有相同group.id的消费者实例，于是就向它返回一个错误，表明它不是消费者组内合法的成员。</p><p>虽然说这个场景很冷门，但也并非完全不会遇到。在一个大型公司中，特别是那些将Kafka作为全公司级消息引擎系统的公司中，每个部门或团队都可能有自己的消费者应用，谁能保证各自的Consumer程序配置的group.id没有重复呢？一旦出现不凑巧的重复，发生了上面提到的这种场景，你使用之前提到的哪种方法都不能规避该异常。令人沮丧的是，无论是刚才哪个版本的异常说明，都完全没有提及这个场景，因此，如果是这个原因引发的CommitFailedException异常，前面的4种方法全部都是无效的。</p><p>更为尴尬的是，无论是社区官网，还是网上的文章，都没有提到过这种使用场景。我个人认为，这应该算是Kafka的一个bug。比起返回CommitFailedException异常只是表明提交位移失败，更好的做法应该是，在Consumer端应用程序的某个地方，能够以日志或其他方式友善地提示你错误的原因，这样你才能正确处理甚至是预防该异常。</p><h2>小结</h2><p>总结一下，今天我们详细讨论了Kafka Consumer端经常碰到的CommitFailedException异常。我们从它的含义说起，再到它出现的时机和场景，以及每种场景下的应对之道。当然，我也留了个悬念，在专栏后面的内容中，我会详细说说多线程消费的实现方式。希望通过今天的分享，你能清晰地掌握CommitFailedException异常发生的方方面面，从而能在今后更有效地应对此异常。</p><p><img src=\"https://static001.geekbang.org/resource/image/df/88/df3691cee68c7878efd21e79719bec88.jpg?wh=2069*2569\" alt=\"\"></p><h2>开放讨论</h2><p>请比较一下今天我们提到的预防该异常的4种方法，并说说你对它们的理解。</p><p>欢迎写下你的思考和答案，我们一起讨论。如果你觉得有所收获，也欢迎把文章分享给你的朋友。</p><p></p>","neighbors":{"left":{"article_title":"18 | Kafka中位移提交那些事儿","id":106904},"right":{"article_title":"20 | 多线程开发消费者实例","id":108512}},"comments":[{"had_liked":false,"id":114620,"user_name":"小生向北","can_delete":false,"product_type":"c1","uid":1068933,"ip_address":"","ucode":"47DC72775B9A53","user_header":"https://static001.geekbang.org/account/avatar/00/10/4f/85/c92bcc6b.jpg","comment_is_top":false,"comment_ctime":1563351828,"is_pvip":false,"discussion_count":6,"race_medal":0,"score":"181951978260","product_id":100029201,"comment_content":"max.poll.interval.ms是指两次poll()的最大间隔时间，kafka消费者以轮询的方式来拉取消息，并且一次拉取批量的消息（默认500条），而批量的大小是通过max.poll.records来控制的。两次poll()的实际时间取决于 单条消息的处理时间*一次拉取的消息量（500），当超过max.poll.interval.ms配置的时间Kafka server认为kafka consumer掉线了，于是就执行分区再均衡将这个consumer踢出消费者组。但是consumer又不知道服务端把自己给踢出了，下次在执行poll()拉取消息的时候（在poll()拉取消息之前有个自动提交offset的操作），就会触发该问题。 可见第2,3种方案是通过调整Kafka consumer的配置参数来缩短业务总的处理时间或者增加服务端判断时长，比较容易实现；第1种就跟业务有关了，比较难搞，有些业务可能就是要这么长的时间，很难再缩短；第4种方案就更复杂了，要把同步消息转换成异步，交给其它线程来处理，这时需要把auto.commit.enable=false，手动提交offset，并且consumer是线程不安全的，异步线程何时处理完，何时该提交，在哪提交，也是应用需要考虑的问题！希望胡老师针对第4种方案重点探讨一下！","like_count":43,"discussions":[{"author":{"id":1795511,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/65/b7/058276dc.jpg","nickname":"i_chase","note":"","ucode":"09C41C863F4EA3","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":559159,"discussion_content":"max.poll.interval.ms这个是客户端参数。kafka broker判断client掉线应该是session.timeout之类的参数吧？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1648630411,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1473167,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/et0qH6zf5icoo6YJoH2WDyia7MTtdQiasicFecfMupzT5VD18aOjzoiaym1OP9RGUEUvLsPRUmCZVSTbrmydpNicVAPA/132","nickname":"GeekJohn","note":"","ucode":"C00462E2195C81","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1795511,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/65/b7/058276dc.jpg","nickname":"i_chase","note":"","ucode":"09C41C863F4EA3","race_medal":0,"user_type":1,"is_pvip":true},"discussion":{"id":576623,"discussion_content":"官网有解释：For consumers using a non-null group.instance.id which reach this timeout, partitions will not be immediately reassigned. Instead, the consumer will stop sending heartbeats and partitions will be reassigned after expiration of session.timeout.ms. ","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1655707463,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":559159,"ip_address":""},"score":576623,"extra":""}]},{"author":{"id":1736462,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/7f/0e/e3a8dbd9.jpg","nickname":"Liujun","note":"","ucode":"3DB1F3CA57B5B3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":390213,"discussion_content":"采用多线程滑动窗口方式消费。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1629715188,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1103208,"avatar":"https://static001.geekbang.org/account/avatar/00/10/d5/68/2201b6b9.jpg","nickname":"归零","note":"","ucode":"C99B8E93009A46","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":339705,"discussion_content":"是要看处理时间的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1609759978,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1095049,"avatar":"https://static001.geekbang.org/account/avatar/00/10/b5/89/9a1b4dee.jpg","nickname":"蛋炒番茄","note":"","ucode":"3F963347C4A97C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":7998,"discussion_content":"这个值默认是max.poll.interval.ms，如果max.poll.records数据量不大的话，很难达到这个时间吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567751409,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1134861,"avatar":"https://static001.geekbang.org/account/avatar/00/11/51/0d/fc1652fe.jpg","nickname":"James","note":"","ucode":"48B0F2A334D1C1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1095049,"avatar":"https://static001.geekbang.org/account/avatar/00/10/b5/89/9a1b4dee.jpg","nickname":"蛋炒番茄","note":"","ucode":"3F963347C4A97C","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":52611,"discussion_content":"不是还得看处理的时间吗。\n","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1574072229,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":7998,"ip_address":""},"score":52611,"extra":""}]}]},{"had_liked":false,"id":114393,"user_name":"ban","can_delete":false,"product_type":"c1","uid":1034204,"ip_address":"","ucode":"E523CE97E48266","user_header":"https://static001.geekbang.org/account/avatar/00/0f/c7/dc/9408c8c2.jpg","comment_is_top":false,"comment_ctime":1563289264,"is_pvip":false,"replies":[{"id":"41762","content":"1. 很多流处理框架的Kafka connector都没有使用consumer group，而是直接使用standalone consumer，因为group机制不好把控<br>2. standalone consumer没有rebalance，也没有group提供的负载均衡，你需要自己实现。其他方面（比如位移提交）和group没有太大的不同","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563323985,"ip_address":"","comment_id":114393,"utype":1}],"discussion_count":1,"race_medal":0,"score":"156182111920","product_id":100029201,"comment_content":"老师，1、请问Standalone Consumer 的独立消费者一般什么情况会用到<br>2、Standalone Consumer 的独立消费者 使用跟普通消费者组有什么区别的。","like_count":37,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":458641,"discussion_content":"1. 很多流处理框架的Kafka connector都没有使用consumer group，而是直接使用standalone consumer，因为group机制不好把控\n2. standalone consumer没有rebalance，也没有group提供的负载均衡，你需要自己实现。其他方面（比如位移提交）和group没有太大的不同","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563323985,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":215903,"user_name":"胡小禾","can_delete":false,"product_type":"c1","uid":1132315,"ip_address":"","ucode":"1C23B7492C0C9E","user_header":"https://static001.geekbang.org/account/avatar/00/11/47/1b/64262861.jpg","comment_is_top":false,"comment_ctime":1589128736,"is_pvip":false,"replies":[{"id":"80066","content":"嗯，差不多是这个道理：）","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1589248984,"ip_address":"","comment_id":215903,"utype":1}],"discussion_count":2,"race_medal":0,"score":"108963311136","product_id":100029201,"comment_content":"“当消息处理的总时间超过预设的 max.poll.interval.ms 参数值时，Kafka Consumer 端会抛出 CommitFailedException 异常”。<br><br><br>其实逻辑是这样：消息处理的总时间超过预设的 max.poll.interval.ms 参数值  导致了 Rebalance‘；<br>rebalance导致了 partition assgined 的consumer member变了；<br>导致原来的consumer 想要commit都没法commit 。（因为元信息,比如连的broker都变了）.<br><br>请老师指正下","like_count":26,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":494604,"discussion_content":"嗯，差不多是这个道理：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589248984,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2071279,"avatar":"https://static001.geekbang.org/account/avatar/00/1f/9a/ef/6162b0e0.jpg","nickname":"Rangarok","note":"","ucode":"D13AF6E247EFCF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":577689,"discussion_content":"Mark","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1656298903,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":216272,"user_name":"胡小禾","can_delete":false,"product_type":"c1","uid":1132315,"ip_address":"","ucode":"1C23B7492C0C9E","user_header":"https://static001.geekbang.org/account/avatar/00/11/47/1b/64262861.jpg","comment_is_top":false,"comment_ctime":1589212606,"is_pvip":false,"replies":[{"id":"80060","content":"自动commit失败由Kafka内部消化处理","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1589248557,"ip_address":"","comment_id":216272,"utype":1}],"discussion_count":1,"race_medal":0,"score":"74603656638","product_id":100029201,"comment_content":"为啥自动commit 不会抛 CommitFailedException？","like_count":18,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":494742,"discussion_content":"自动commit失败由Kafka内部消化处理","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589248557,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":114093,"user_name":"德惠先生","can_delete":false,"product_type":"c1","uid":1178969,"ip_address":"","ucode":"FD8AEBEC32085F","user_header":"https://static001.geekbang.org/account/avatar/00/11/fd/59/4416b40f.jpg","comment_is_top":false,"comment_ctime":1563237791,"is_pvip":false,"replies":[{"id":"41693","content":"假设full gc导致所有线程STW，从而心跳中断，导致被踢出group，Coordinator向其他存活consumer发送心跳response，通知它们开启新一轮rebalance。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563274767,"ip_address":"","comment_id":114093,"utype":1}],"discussion_count":3,"race_medal":0,"score":"65987747231","product_id":100029201,"comment_content":"希望老师可以更加具体的说说，rebalance的细节，比如某个consumer发生full gc的场景，它的partition是怎么被分配走的，重连之后提交会发生什么","like_count":16,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":458512,"discussion_content":"假设full gc导致所有线程STW，从而心跳中断，导致被踢出group，Coordinator向其他存活consumer发送心跳response，通知它们开启新一轮rebalance。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563274767,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1736462,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/7f/0e/e3a8dbd9.jpg","nickname":"Liujun","note":"","ucode":"3DB1F3CA57B5B3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":390214,"discussion_content":"STW 是得有多长才能导致心跳中断啊，这也太可怕了吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1629715526,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1222803,"avatar":"https://static001.geekbang.org/account/avatar/00/12/a8/93/5912bd84.jpg","nickname":"恒","note":"","ucode":"1A0AC6664085A6","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1736462,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/7f/0e/e3a8dbd9.jpg","nickname":"Liujun","note":"","ucode":"3DB1F3CA57B5B3","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":582056,"discussion_content":"有些大内存譬如两三百G堆的的Java发生fgc会很久的 十几分钟都正常","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1659170482,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":390214,"ip_address":"陕西"},"score":582056,"extra":""}]}]},{"had_liked":false,"id":114382,"user_name":"ban","can_delete":false,"product_type":"c1","uid":1034204,"ip_address":"","ucode":"E523CE97E48266","user_header":"https://static001.geekbang.org/account/avatar/00/0f/c7/dc/9408c8c2.jpg","comment_is_top":false,"comment_ctime":1563287855,"is_pvip":false,"replies":[{"id":"41764","content":"嗯，我更愿意说是max.poll.interval.ms承担了session.timeout.ms的部分功能。在没有max.poll.interval.ms和单独的心跳线程之前，如果session.timeout.ms = 5s，消息处理超过了5s，那么consumer就算是超时","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563324196,"ip_address":"","comment_id":114382,"utype":1}],"discussion_count":2,"race_medal":0,"score":"40217993519","product_id":100029201,"comment_content":"老师，我想问下max.poll.interval.ms两者session.timeout.ms有什么联系，可以说0.10.1.0 之前的客户端 API，相当于session.timeout.ms代替了max.poll.interval.ms吗？<br>比如说session.timeout.ms是5秒，如果消息处理超过5秒，也算是超时吗？","like_count":10,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":458634,"discussion_content":"嗯，我更愿意说是max.poll.interval.ms承担了session.timeout.ms的部分功能。在没有max.poll.interval.ms和单独的心跳线程之前，如果session.timeout.ms = 5s，消息处理超过了5s，那么consumer就算是超时","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563324196,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1034204,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/c7/dc/9408c8c2.jpg","nickname":"ban","note":"","ucode":"E523CE97E48266","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":2165,"discussion_content":"赞","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563326182,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":119117,"user_name":"windcaller","can_delete":false,"product_type":"c1","uid":1514157,"ip_address":"","ucode":"1CA3E849805770","user_header":"https://static001.geekbang.org/account/avatar/00/17/1a/ad/faf1bf19.jpg","comment_is_top":false,"comment_ctime":1564524522,"is_pvip":false,"replies":[{"id":"43693","content":"是的。使用assign的consumer就是standalone consumer","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1564536146,"ip_address":"","comment_id":119117,"utype":1}],"discussion_count":1,"race_medal":0,"score":"35924262890","product_id":100029201,"comment_content":"To use this mode, instead of subscribing to the topic using subscribe, you just call assign(Collection) with the full list of partitions that you want to consume.<br><br>     String topic = &quot;foo&quot;;<br>     TopicPartition partition0 = new TopicPartition(topic, 0);<br>     TopicPartition partition1 = new TopicPartition(topic, 1);<br>     consumer.assign(Arrays.asList(partition0, partition1));<br> <br>Once assigned, you can call poll in a loop, just as in the preceding examples to consume records. The group that the consumer specifies is still used for committing offsets, but now the set of partitions will only change with another call to assign. Manual partition assignment does not use group coordination, so consumer failures will not cause assigned partitions to be rebalanced. Each consumer acts independently even if it shares a groupId with another consumer. To avoid offset commit conflicts, you should usually ensure that the groupId is unique for each consumer instance.<br><br>老师 standalone mode 是上面这段内容吗？","like_count":8,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":460750,"discussion_content":"是的。使用assign的consumer就是standalone consumer","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1564536146,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":114311,"user_name":"Li Shunduo","can_delete":false,"product_type":"c1","uid":1222882,"ip_address":"","ucode":"6C5AB4129E9780","user_header":"https://static001.geekbang.org/account/avatar/00/12/a8/e2/f8e51df2.jpg","comment_is_top":false,"comment_ctime":1563269996,"is_pvip":false,"replies":[{"id":"41682","content":"consumer有重连机制","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563274217,"ip_address":"","comment_id":114311,"utype":1}],"discussion_count":1,"race_medal":0,"score":"35923008364","product_id":100029201,"comment_content":"假如broker集群整个挂掉了，过段时间集群恢复后，consumer group会自动恢复消费吗？还是需要手动重启consumer机器？","like_count":8,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":458603,"discussion_content":"consumer有重连机制","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563274217,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":148109,"user_name":"注定非凡","can_delete":false,"product_type":"c1","uid":1113597,"ip_address":"","ucode":"80673056E131B7","user_header":"https://static001.geekbang.org/account/avatar/00/10/fd/fd/326be9bb.jpg","comment_is_top":false,"comment_ctime":1572942524,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"27342746300","product_id":100029201,"comment_content":"A ：定义：所谓CommitFailedException，是指Consumer客户端在提交位移时出现了错误或异常，并且并不可恢复的严重异常。<br><br>B ：导致原因：<br>\t（1）消费者端处理的总时间超过预设的max.poll.interval.ms参数值<br>\t（2）出现一个Standalone Consumerd的独立消费者，配置的group.id重名冲突。<br><br>C ：解决方案：<br>\t（1）减少单条消息处理的时间<br>\t（2）增加Consumer端允许下游系统消费一批消息的最大时长<br>\t（3）减少下游系统一次性消费的消息总数。<br>\t（4）下游使用多线程加速消费<br>","like_count":7},{"had_liked":false,"id":114110,"user_name":"cricket1981","can_delete":false,"product_type":"c1","uid":1001715,"ip_address":"","ucode":"758262F5958DA4","user_header":"https://static001.geekbang.org/account/avatar/00/0f/48/f3/f1034ffd.jpg","comment_is_top":false,"comment_ctime":1563239011,"is_pvip":false,"replies":[{"id":"41690","content":"之前版本中session.timeout.ms有多重含义，session过期时间、消息处理逻辑最大时间等","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563274602,"ip_address":"","comment_id":114110,"utype":1}],"discussion_count":1,"race_medal":0,"score":"27333042787","product_id":100029201,"comment_content":"&quot;不幸的是，session.timeout.ms 参数还有其他的含义，因此增加该参数的值可能会有其他方面的“不良影响”，这也是社区在 0.10.1.0 版本引入 max.poll.interval.ms 参数，将这部分含义从 session.timeout.ms 中剥离出来的原因之一。&quot;---&gt;能细述一下不良影响吗？","like_count":5,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":458523,"discussion_content":"之前版本中session.timeout.ms有多重含义，session过期时间、消息处理逻辑最大时间等","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563274602,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":149192,"user_name":"柯察金","can_delete":false,"product_type":"c1","uid":1115149,"ip_address":"","ucode":"F722BF8FCD2C47","user_header":"https://static001.geekbang.org/account/avatar/00/11/04/0d/3dc5683a.jpg","comment_is_top":false,"comment_ctime":1573174588,"is_pvip":false,"replies":[{"id":"57345","content":"group.id是必须要设置的，否则会抛InvalidGroupIdException异常","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1573175937,"ip_address":"","comment_id":149192,"utype":1}],"discussion_count":1,"race_medal":0,"score":"23048011068","product_id":100029201,"comment_content":"老师，没有设置 group.id 话，会怎么样，系统会自动生成唯一的一个值吗","like_count":5,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":473769,"discussion_content":"group.id是必须要设置的，否则会抛InvalidGroupIdException异常","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1573175937,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":118885,"user_name":"有时也，命也，运也，如之奈何？","can_delete":false,"product_type":"c1","uid":1181147,"ip_address":"","ucode":"792624AA1B2D9C","user_header":"https://static001.geekbang.org/account/avatar/00/12/05/db/1bd78419.jpg","comment_is_top":false,"comment_ctime":1564457788,"is_pvip":false,"replies":[{"id":"43614","content":"还不够，你需要使用Kafka Connect组件才能实现。见：https:&#47;&#47;www.confluent.io&#47;blog&#47;kafka-connect-deep-dive-error-handling-dead-letter-queues","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1564479948,"ip_address":"","comment_id":118885,"utype":1}],"discussion_count":1,"race_medal":0,"score":"23039294268","product_id":100029201,"comment_content":"老师kafka死信该怎么去实现的？<br>2.0之后增加了如下配置：<br>errors.tolerance = all<br>errors.deadletterqueue.topic.name = &quot;&quot;？","like_count":6,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":460638,"discussion_content":"还不够，你需要使用Kafka Connect组件才能实现。见：https://www.confluent.io/blog/kafka-connect-deep-dive-error-handling-dead-letter-queues","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1564479948,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":180671,"user_name":"极极","can_delete":false,"product_type":"c1","uid":1250773,"ip_address":"","ucode":"365F7446ABCC49","user_header":"https://static001.geekbang.org/account/avatar/00/13/15/d5/6d66288b.jpg","comment_is_top":false,"comment_ctime":1582361428,"is_pvip":false,"replies":[{"id":"70213","content":"两个consumer都是使用subscribe方法订阅的topic吗？<br><br>另外，rebalance发生时Coordinator会通过心跳response通知消费者。如果消费者此时正在处理消息，肯定是不会响应的，毕竟还没有强行中断的机制","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1582455598,"ip_address":"","comment_id":180671,"utype":1}],"discussion_count":3,"race_medal":0,"score":"18762230612","product_id":100029201,"comment_content":"老师您好，这边遇到个很奇怪的问题<br><br>开启第一个消费者的时候，正常消费<br><br>但是开启另一个后，触发了 rebalanced<br><br>这时候第一个消费者会报出如下错误：<br>The provided member is not known in the current generation<br><br>是因为第一个消费者被踢出了 generation，但是它不知道，还在继续消费提交位移，或者做着其他事情？这个其他事情可能是什么？<br><br>还有就是 rebalance发生的时候，消费者是立即暂停，还是会消费完整个poll？这时候coordinator会等他吗？还是直接踢出去？<br>","like_count":4,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":484752,"discussion_content":"两个consumer都是使用subscribe方法订阅的topic吗？\n\n另外，rebalance发生时Coordinator会通过心跳response通知消费者。如果消费者此时正在处理消息，肯定是不会响应的，毕竟还没有强行中断的机制","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1582455598,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1250773,"avatar":"https://static001.geekbang.org/account/avatar/00/13/15/d5/6d66288b.jpg","nickname":"极极","note":"","ucode":"365F7446ABCC49","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":182200,"discussion_content":"暂时猜测大概是这个原因\n\nhttps://issues.apache.org/jira/browse/KAFKA-8653\n\n官方在2.3.1提到了有个bug导致rebalance timeout变为0，一开始 rebalance就立马踢出成员，\n\n程序中打印到心跳监测之类的需要用到member id的请求就会报这个错。\n\n","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1582388328,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1250773,"avatar":"https://static001.geekbang.org/account/avatar/00/13/15/d5/6d66288b.jpg","nickname":"极极","note":"","ucode":"365F7446ABCC49","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":182212,"discussion_content":"升级为2.4.0之后的确就没这个问题\n\n不过还有一个问题。\n\n就是上面提到的 rebalance 过程中，是不是有的客户端的实现逻辑是先消费完 本次poll的数据，然后再执行joingroup？\n\n还是说joingroup的过程中还能继续消费，因为poll的数据已经缓存到内存，互不影响？\n\n重新joingroup的memberid和上次一不一样呢？这个membrtid又是哪一端，在什么时候生成的呢？\n\n可能我的问题比较奇怪，希望老师能看到并解答，非常感谢！！\n\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1582389669,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":118715,"user_name":"windcaller","can_delete":false,"product_type":"c1","uid":1514157,"ip_address":"","ucode":"1CA3E849805770","user_header":"https://static001.geekbang.org/account/avatar/00/17/1a/ad/faf1bf19.jpg","comment_is_top":false,"comment_ctime":1564429893,"is_pvip":false,"replies":[{"id":"43514","content":"Standalone consumer的提法并未出现在官方文档中，你可以在javadoc中看到一些：https:&#47;&#47;kafka.apache.org&#47;23&#47;javadoc&#47;org&#47;apache&#47;kafka&#47;clients&#47;consumer&#47;KafkaConsumer.html#manualassignment","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1564447174,"ip_address":"","comment_id":118715,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18744299077","product_id":100029201,"comment_content":"我没在kafka官网、stackoverflow 、google 找到任何关于 standalone kafka consumer的 例子，还望老师给个链接学习学习","like_count":5,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":460543,"discussion_content":"Standalone consumer的提法并未出现在官方文档中，你可以在javadoc中看到一些：https://kafka.apache.org/23/javadoc/org/apache/kafka/clients/consumer/KafkaConsumer.html#manualassignment","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1564447174,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":242874,"user_name":"crud~boy","can_delete":false,"product_type":"c1","uid":2083659,"ip_address":"","ucode":"4DD62B9BA480D3","user_header":"","comment_is_top":false,"comment_ctime":1597882027,"is_pvip":false,"replies":[{"id":"89540","content":"如果是多线程提交位移，的确有可能出现这种情况。影响就是可能出现重复消费","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1597885122,"ip_address":"","comment_id":242874,"utype":1}],"discussion_count":2,"race_medal":0,"score":"14482783915","product_id":100029201,"comment_content":"老师poll一批消息，多线程处理并且是手动处理，会不会每个线程速度不一致，会导致提交位移时，offset小得后提交，会有什么影响吗","like_count":3,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":504119,"discussion_content":"如果是多线程提交位移，的确有可能出现这种情况。影响就是可能出现重复消费","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1597885122,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1736462,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/7f/0e/e3a8dbd9.jpg","nickname":"Liujun","note":"","ucode":"3DB1F3CA57B5B3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":390215,"discussion_content":"采用多线程滑动窗口的方式，实现并发消费","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1629716144,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":214185,"user_name":"石栖","can_delete":false,"product_type":"c1","uid":1496443,"ip_address":"","ucode":"35600F645A479F","user_header":"https://static001.geekbang.org/account/avatar/00/16/d5/7b/c512da6a.jpg","comment_is_top":false,"comment_ctime":1588672607,"is_pvip":false,"replies":[{"id":"79342","content":"能告知一下Kafka版本吗？目前社区对这部分代码改动很多，需要确认下是哪个版本碰到的问题","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1588725315,"ip_address":"","comment_id":214185,"utype":1}],"discussion_count":3,"race_medal":0,"score":"14473574495","product_id":100029201,"comment_content":"关于这个错误，我这边很奇怪，consumer用的是自动提交的配置，但是也出现了这个错误。看错误应该是broker-2挂掉了，然后rediscovery。但是后面日志又说The coordinator is not aware of this member.再后面就是Commit cannot be completed 的错误了。我这里是有多个broker，然后采用的域名的方式，ip可能会变。老师通过这些日志，能给点建议吗？<br>错误日志：<br>2020-05-04 18:49:56.592  INFO 6 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=test-group] Discovered group coordinator broker-2-lhfm0slmx1v4nyfz.kafka.svc01.local:9093 (id: 2147483645 rack: null)<br>2020-05-04 18:49:56.592  INFO 6 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=test-group] Group coordinator broker-2-lhfm0slmx1v4nyfz.kafka.svc01.local:9093 (id: 2147483645 rack: null) is unavailable or invalid, will attempt rediscovery<br>2020-05-04 18:49:56.694  INFO 6 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=test-group] Discovered group coordinator broker-2-lhfm0slmx1v4nyfz.kafka.svc01.local:9093 (id: 2147483645 rack: null)<br>2020-05-04 18:49:56.735 ERROR 6 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-2, groupId=test-group] Offset commit failed on partition test.topic-0 at offset 0: The coordinator is not aware of this member.<br>2020-05-04 18:49:56.735  WARN 6 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-2, groupId=test-group] Asynchronous auto-commit of offsets {test.topic-0=OffsetAndMetadata{offset=0, metadata=&#39;&#39;}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.","like_count":3,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493978,"discussion_content":"能告知一下Kafka版本吗？目前社区对这部分代码改动很多，需要确认下是哪个版本碰到的问题","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588725315,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1580021,"avatar":"https://static001.geekbang.org/account/avatar/00/18/1b/f5/aa777789.jpg","nickname":"洎野","note":"","ucode":"3993CF5559F4F2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":287078,"discussion_content":"我在生产环境遇到了一样的问题  mark一下","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1593357716,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1496443,"avatar":"https://static001.geekbang.org/account/avatar/00/16/d5/7b/c512da6a.jpg","nickname":"石栖","note":"","ucode":"35600F645A479F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":258986,"discussion_content":"kafka是2.3版本","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588748543,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":153740,"user_name":"张洋","can_delete":false,"product_type":"c1","uid":1182914,"ip_address":"","ucode":"549BE5DEEF8417","user_header":"https://static001.geekbang.org/account/avatar/00/12/0c/c2/bad34a50.jpg","comment_is_top":false,"comment_ctime":1574301314,"is_pvip":true,"replies":[{"id":"59160","content":"1. 设置相同group.id的consumer就是属于同一个group，你说的是对的：）<br>2. 会出现位移提交失败的问题。严格来说这其实是一个问题，但是如果反馈到社区，社区会认为这不是标准用法","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1574383781,"ip_address":"","comment_id":153740,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10164235906","product_id":100029201,"comment_content":"老师有两个疑问：<br><br>1.相同的GroupId的Consumer 不应该就是同一个Consumer Group 组下的吗，或者有其他的区分条件，比如订阅的Topic不同？<br><br>2.如果这个standalone Consumer 再给他添加一个同组的standalone Conusmer，会发生什么？","like_count":2,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":475253,"discussion_content":"1. 设置相同group.id的consumer就是属于同一个group，你说的是对的：）\n2. 会出现位移提交失败的问题。严格来说这其实是一个问题，但是如果反馈到社区，社区会认为这不是标准用法","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1574383781,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":305062,"user_name":"if...else...","can_delete":false,"product_type":"c1","uid":2550743,"ip_address":"","ucode":"D0565908C99695","user_header":"https://static001.geekbang.org/account/avatar/00/26/eb/d7/90391376.jpg","comment_is_top":false,"comment_ctime":1627796754,"is_pvip":false,"replies":[{"id":"112540","content":"不会回滚。消费出了任何问题都表现为consumer无法继续处理，然后人工需要介入，然后可能出现重复消费","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1630810928,"ip_address":"","comment_id":305062,"utype":1}],"discussion_count":2,"race_medal":4,"score":"5922764050","product_id":100029201,"comment_content":"好像只说了如何避免出现异常，但是异常出现了怎么处理呢，有类似回滚什么的吗？会重复消费吗？","like_count":2,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":524263,"discussion_content":"不会回滚。消费出了任何问题都表现为consumer无法继续处理，然后人工需要介入，然后可能出现重复消费","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1630810928,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1736462,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/7f/0e/e3a8dbd9.jpg","nickname":"Liujun","note":"","ucode":"3DB1F3CA57B5B3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":390217,"discussion_content":"回滚消息，用到 seek 方法","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1629716535,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":304891,"user_name":"绿箭侠","can_delete":false,"product_type":"c1","uid":1528536,"ip_address":"","ucode":"B994F558A98E29","user_header":"https://static001.geekbang.org/account/avatar/00/17/52/d8/123a4981.jpg","comment_is_top":false,"comment_ctime":1627660295,"is_pvip":false,"replies":[{"id":"110340","content":"group之间相同？那么就会认为是同一个group","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1627784703,"ip_address":"","comment_id":304891,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5922627591","product_id":100029201,"comment_content":"场景二，为什么只强调standalone 和 group之间可能会发生groupid相同，那group之间相同怎么样呢？ 是不是会在coordinator注册group时就能发现组之间重复了groupid ?!!!","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":524203,"discussion_content":"group之间相同？那么就会认为是同一个group","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627784703,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":230049,"user_name":"松鼠鱼","can_delete":false,"product_type":"c1","uid":1815185,"ip_address":"","ucode":"C0E87CCF71DB44","user_header":"","comment_is_top":false,"comment_ctime":1593247458,"is_pvip":true,"replies":[{"id":"85033","content":"这可能是因为broker端的问题而引起的，比如Coordinator变更了，或开启了新的Rebalance。如果是偶发的，你不用太过担心~","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1593388742,"ip_address":"","comment_id":230049,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5888214754","product_id":100029201,"comment_content":"老师，我的程序使用的是自动提交offset，其他interval等相关参数（max poll, session timeout等）都是默认的。消息消费的速度也算快，500条应该就是一秒的事儿。可是这样也还是偶尔会发生Offset commit failed异常，通常是在程序跑了一阵之后，请问您有没有遇到过类似的情况？这是不是和单一一个consumer同时消费多个partition有关？","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":499747,"discussion_content":"这可能是因为broker端的问题而引起的，比如Coordinator变更了，或开启了新的Rebalance。如果是偶发的，你不用太过担心~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1593388742,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1155275,"avatar":"https://static001.geekbang.org/account/avatar/00/11/a0/cb/aab3b3e7.jpg","nickname":"张三丰","note":"","ucode":"3A6215A40B3B21","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":382634,"discussion_content":"我看老师回复，自动提交不是不会出现这种异常么？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1625649430,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":219334,"user_name":"行则将至","can_delete":false,"product_type":"c1","uid":1542987,"ip_address":"","ucode":"DB972F2DF059C4","user_header":"https://static001.geekbang.org/account/avatar/00/17/8b/4b/fa52d222.jpg","comment_is_top":false,"comment_ctime":1589990406,"is_pvip":false,"replies":[{"id":"81036","content":"你的环境中是否存在这种情况：同时有同名的consumer group和standalone group。这种情况下会抛出这个异常。据我所知，自动提交应该不会碰到这个异常，但你的环境是0.10，非常古老，不确定那时候是否是这个设计。<br><br>出现这个问题的原因在于你提交的时候Group在reblance。这种情况特别正常，所以后来社区修改了代码，在自动提交时自行处理这个情况。但手动提交依然无法避免。","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1590022629,"ip_address":"","comment_id":219334,"utype":1}],"discussion_count":1,"race_medal":1,"score":"5884957702","product_id":100029201,"comment_content":"<br>老师。在学习这一章的时候。今天正好碰到一个commitFailedException的问题。kafka是windows版本，0.10.0.0。kafka的持久化目录用的就是默认的&#47;tmp目录。用Idea开发项目时，会经常启停该kafka。今天我启动了一个消费者，生产者发送消息，消费者立马就报出了commitFailedException异常。提示的就是poll loop的处理时间过长，提示我修改session.timeout.ms的值。<br>我的疑问点：我停止了消费者程序，此时就会发生reblance。然后，我又启动消费者。此时再次发生reblance。应该是重新进行分区分配，不应该报出这个错误啊。我这个场景下，这个错误发生的根本原因是什么？望老师解惑 (我最后的解决方案是：把tmp目录全部删除，然后再启动消费者就可以了。)<br><br>极客没有追评的功能。只能再重复一遍问题。老师，我是自动提交，什么原因会出现以上的场景呢？忘了补充一句，我用的是：springboot，引入的是springboot整合kafka 的依赖","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":495770,"discussion_content":"你的环境中是否存在这种情况：同时有同名的consumer group和standalone group。这种情况下会抛出这个异常。据我所知，自动提交应该不会碰到这个异常，但你的环境是0.10，非常古老，不确定那时候是否是这个设计。\n\n出现这个问题的原因在于你提交的时候Group在reblance。这种情况特别正常，所以后来社区修改了代码，在自动提交时自行处理这个情况。但手动提交依然无法避免。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1590022629,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":131431,"user_name":"蛋炒番茄","can_delete":false,"product_type":"c1","uid":1095049,"ip_address":"","ucode":"3F963347C4A97C","user_header":"https://static001.geekbang.org/account/avatar/00/10/b5/89/9a1b4dee.jpg","comment_is_top":false,"comment_ctime":1567751131,"is_pvip":false,"replies":[{"id":"49850","content":"还是要研究下你的环境中Rebalance多吗？","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1567763175,"ip_address":"","comment_id":131431,"utype":1}],"discussion_count":4,"race_medal":0,"score":"5862718427","product_id":100029201,"comment_content":" Synchronous auto-commit of offsets {=OffsetAndMetadata{offset=6236, leaderEpoch=null, metadata=&#39;&#39;}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.<br>我们这边有几个项目，当用原生的kafka客户端经常出现这个报错，max.poll.interval.ms是默认值300000，max.poll.records.是2000，但是实际上数据很少，每条数据处理的时间也很短。heartbeat.interval.ms是2000，session.timeout.ms是12000。为什么经常出现这个错误。<br>重点是，另外几个项目用的是spring-kafka却重来没有出现过这样的报错，相关配置差不多，业务场景差不多。求指点？怎么样避免这样的问题","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":466448,"discussion_content":"还是要研究下你的环境中Rebalance多吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567763175,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1225555,"avatar":"https://static001.geekbang.org/account/avatar/00/12/b3/53/25a4ae4b.jpg","nickname":"DK","note":"","ucode":"F0D330CF0C64BE","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":373461,"discussion_content":"兄弟解决了么，我们也遇到过，莫名其妙的Rebalance，导致提交失败，但consumer端处理的又不慢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1620735601,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1095049,"avatar":"https://static001.geekbang.org/account/avatar/00/10/b5/89/9a1b4dee.jpg","nickname":"蛋炒番茄","note":"","ucode":"3F963347C4A97C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":8094,"discussion_content":"我看了你介绍Rebalance这一章，我把很多参数都调大了，你文章中列举了那些，发现还是会有一些莫名其妙的Rebalance。至少我现在还发现当服务器负载高的时候发生Rebalance的概率大很多","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567776405,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1621119,"avatar":"https://static001.geekbang.org/account/avatar/00/18/bc/7f/3b75677e.jpg","nickname":"洪东楗","note":"","ucode":"D161432152E967","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1095049,"avatar":"https://static001.geekbang.org/account/avatar/00/10/b5/89/9a1b4dee.jpg","nickname":"蛋炒番茄","note":"","ucode":"3F963347C4A97C","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":48170,"discussion_content":"负载高，看看是不是FULL GC引起的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1573456460,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":8094,"ip_address":""},"score":48170,"extra":""}]}]},{"had_liked":false,"id":117797,"user_name":"老鱼","can_delete":false,"product_type":"c1","uid":1221974,"ip_address":"","ucode":"2C873D9E34CB00","user_header":"https://static001.geekbang.org/account/avatar/00/12/a5/56/d1f70c0d.jpg","comment_is_top":false,"comment_ctime":1564132678,"is_pvip":false,"replies":[{"id":"43217","content":"不会","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1564216279,"ip_address":"","comment_id":117797,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5859099974","product_id":100029201,"comment_content":"胡老师，手动提交时，当前后两次poll时间超过期望的max.poll.interval.ms时，会触发Rebalance。 那么假如是自动提交时，会触发Rebalance吗？<br>假如，手动提交场景，consumer消费端处理业务时间过长（特殊case导致的），发生了Rebalance，那么该consumer实例被踢出了，那么它永远‘死掉’了吗，还是会再次通过heartbeat检测让它复活？","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":460120,"discussion_content":"不会","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1564216279,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":114366,"user_name":"Dovelol","can_delete":false,"product_type":"c1","uid":1253384,"ip_address":"","ucode":"9B5DDF7720F307","user_header":"https://static001.geekbang.org/account/avatar/00/13/20/08/bc06bc69.jpg","comment_is_top":false,"comment_ctime":1563283741,"is_pvip":false,"replies":[{"id":"41765","content":"嗯，是的。这个异常只是在手动提交时抛出的。 ","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563324260,"ip_address":"","comment_id":114366,"utype":1}],"discussion_count":4,"race_medal":0,"score":"5858251037","product_id":100029201,"comment_content":"老师好，我上一个问题的具体描述是这样的，今天讲CommitFailedException的例子是调用consumer.commitSync();手动提交offset，确实当消息处理的总时间超过预设的max.poll.interval.ms时会报这个异常，但是如果是自动提交offset的情况下，也就是把enable.auto.commit=true，然后删除consumer.commitSync();代码，其它代码不变，也是max.poll.interval.ms=5s，然后循环中sleep(6s)，发现不会报异常并且会一直重复消费，想问下这是什么原因呢？","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":458627,"discussion_content":"嗯，是的。这个异常只是在手动提交时抛出的。 ","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563324260,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1222882,"avatar":"https://static001.geekbang.org/account/avatar/00/12/a8/e2/f8e51df2.jpg","nickname":"Li Shunduo","note":"","ucode":"6C5AB4129E9780","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":3732,"discussion_content":"同样的疑惑，自动提交的时机是下次调用poll，可是调用的时候已经超过5s了，为什么不会抛出异常？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1564738001,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":2,"child_discussions":[{"author":{"id":1736462,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/7f/0e/e3a8dbd9.jpg","nickname":"Liujun","note":"","ucode":"3DB1F3CA57B5B3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1222882,"avatar":"https://static001.geekbang.org/account/avatar/00/12/a8/e2/f8e51df2.jpg","nickname":"Li Shunduo","note":"","ucode":"6C5AB4129E9780","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":390216,"discussion_content":"内部处理掉了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1629716479,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":3732,"ip_address":""},"score":390216,"extra":""},{"author":{"id":2557592,"avatar":"","nickname":"毛🍢卷卷","note":"","ucode":"6612296E751379","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1736462,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/7f/0e/e3a8dbd9.jpg","nickname":"Liujun","note":"","ucode":"3DB1F3CA57B5B3","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":563031,"discussion_content":"怎么处理的呢\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1649926393,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":390216,"ip_address":""},"score":563031,"extra":""}]}]},{"had_liked":false,"id":340153,"user_name":"i_chase","can_delete":false,"product_type":"c1","uid":1795511,"ip_address":"","ucode":"09C41C863F4EA3","user_header":"https://static001.geekbang.org/account/avatar/00/1b/65/b7/058276dc.jpg","comment_is_top":false,"comment_ctime":1648630555,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1648630555","product_id":100029201,"comment_content":"超过max.poll.interval.ms时间后，应该是consumer主动停止消费了吧？[毕竟这只是个客户端参数，broker又不知道] consumer停止消费，超过一定时间后，进行了rebalance。 另外就是，无论是自动提交或者手动提交，超过max.poll.interval.ms时间都应该会有CommittedFailedException吧","like_count":0},{"had_liked":false,"id":333699,"user_name":"追风筝的人","can_delete":false,"product_type":"c1","uid":1488020,"ip_address":"","ucode":"2993D60F94C396","user_header":"https://static001.geekbang.org/account/avatar/00/16/b4/94/2796de72.jpg","comment_is_top":false,"comment_ctime":1644477636,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1644477636","product_id":100029201,"comment_content":"Consumer 程序配置的 group.id  重复 会导致CommitFailedException 异常","like_count":0},{"had_liked":false,"id":326029,"user_name":"Geek_f9d469","can_delete":false,"product_type":"c1","uid":2842794,"ip_address":"","ucode":"0A14D20CB927F6","user_header":"","comment_is_top":false,"comment_ctime":1639319511,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1639319511","product_id":100029201,"comment_content":"老师，我在近期就遇到过这样的错误<br>背景：一个topic有7个分区，客户端开了3个消费者线程去消费，某一天下午，topic中突然有3个分区的出现消息积压，而另外4个分区则没问题，持续了半个小时后消息积压的分区就恢复正常了，通过日志排查，发现日志中有大量的CommitFailedException。<br>在这半个小时里，频繁出现reblance ，初步排查时由于提交offset太慢导致的","like_count":0},{"had_liked":false,"id":312741,"user_name":"shuifa","can_delete":false,"product_type":"c1","uid":1040063,"ip_address":"","ucode":"636733F5C88A7B","user_header":"https://static001.geekbang.org/account/avatar/00/0f/de/bf/4df4224d.jpg","comment_is_top":false,"comment_ctime":1631958741,"is_pvip":false,"discussion_count":0,"race_medal":1,"score":"1631958741","product_id":100029201,"comment_content":"使用多线程处理是对第一种方法的补充，在单线程处理时间已经无法再优化的时候，就使用多线程","like_count":0},{"had_liked":false,"id":310121,"user_name":"倪大人","can_delete":false,"product_type":"c1","uid":1193052,"ip_address":"","ucode":"4798D69F3E86FB","user_header":"https://static001.geekbang.org/account/avatar/00/12/34/5c/6b4757a0.jpg","comment_is_top":false,"comment_ctime":1630490439,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1630490439","product_id":100029201,"comment_content":"看文的时候很不理解max.poll.interval.ms session.timeout.ms两个参数的区别<br><br>搜了一下，在这儿找到了比较清晰的答案<br>https:&#47;&#47;stackoverflow.com&#47;questions&#47;39730126&#47;difference-between-session-timeout-ms-and-max-poll-interval-ms-for-kafka-0-10<br><br>简单来说，kafka 0.10.0及之前的版本只有session.timeout.ms，consumer只有一个线程，每次poll之前会执行DelayedTask（比如心跳、自动提交）。<br><br>旧版只有session.timeout.ms一个参数有一个巨大的问题：没法及时发现consumer挂了。<br>试想一个场景，假设consumer每poll一次任务需要处理5分钟，那session.timeout.ms就必须大于5分钟，也就是至少需要五分钟才能检测到consumer挂了。<br><br>新版本（0.10.1）为了解决这个问题，把heartbeat和poll解耦，用一个新线程处理heartbeat，引入max.poll.interval.ms控制poll（参加：http:&#47;&#47;kafka.apache.org&#47;0101&#47;documentation.html#newconsumerconfigs）。这样session.timeout.ms可以设置得更小一些，使consumer故障能更快被发现。<br><br><br>也正是由于版本不同，所以老师的文章开头会有多个版本的CommitFailedException注释（文中旧版本解决方案调整session.timeout.ms参数，新版本解决方案调整max.poll.interval.ms）。","like_count":0},{"had_liked":false,"id":290704,"user_name":"西门吹牛","can_delete":false,"product_type":"c1","uid":1508990,"ip_address":"","ucode":"E5D3624DDE1E83","user_header":"https://static001.geekbang.org/account/avatar/00/17/06/7e/735968e2.jpg","comment_is_top":false,"comment_ctime":1619693797,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1619693797","product_id":100029201,"comment_content":"无论哪种提交，最终的解决办法都是保守的，都是宁愿重复消费，也不让消息丢失，如果因为位移提交导致消息丢失，那只能出现在手动提交的过程中，自己处理逻辑问题，没有处理完消息，却提前提交了位移","like_count":0},{"had_liked":false,"id":285516,"user_name":"Allan","can_delete":false,"product_type":"c1","uid":1310388,"ip_address":"","ucode":"8DA4DBECC2C45C","user_header":"https://static001.geekbang.org/account/avatar/00/13/fe/b4/295338e7.jpg","comment_is_top":false,"comment_ctime":1616854156,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1616854156","product_id":100029201,"comment_content":"对于今天说的预防异常的四个种方法：总的来说，就是提高处理速度就可以解决问题，而如何提高速度呢？要不是max.poll.record一次的量级别少，然后处理逻辑快就可以避免；如果处理逻辑慢了，且没办法优化，那么我们max.poll.interval.ms可以设置大一些，从而可以等待我们的处理可以在有限时间内完成逻辑。同时我们采用多线程方式提高我们处理速度也是一种比较复杂的方式。三种方式都可以尽量的去避免异常，但是如果我们的consumer standalone模式groupid名字跟我们的group consumer模式的groupid一样，这种情况就需要我们改名字了。大体的三种优化方案，一种是模式方案。","like_count":0},{"had_liked":false,"id":271584,"user_name":"归零","can_delete":false,"product_type":"c1","uid":1103208,"ip_address":"","ucode":"C99B8E93009A46","user_header":"https://static001.geekbang.org/account/avatar/00/10/d5/68/2201b6b9.jpg","comment_is_top":false,"comment_ctime":1609724719,"is_pvip":true,"replies":[{"id":"99935","content":"只要设置了就会出现","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1611539665,"ip_address":"","comment_id":271584,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1609724719","product_id":100029201,"comment_content":"老师，场景二出现的原因是如果你的应用中同时出现了设置相同 group.id 值的【消费者组程序】和【独立消费者程序】，还是说只要出现了设置相同的group.id就会出现呢？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":512969,"discussion_content":"只要设置了就会出现","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1611539665,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":236283,"user_name":"徐宁","can_delete":false,"product_type":"c1","uid":1208822,"ip_address":"","ucode":"5B38BF576B1749","user_header":"https://static001.geekbang.org/account/avatar/00/12/71/f6/ad0ad3df.jpg","comment_is_top":false,"comment_ctime":1595384451,"is_pvip":false,"replies":[{"id":"87680","content":"不太了解spark中的实现。代码中也没有出现kafkaDataSource？","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1595811176,"ip_address":"","comment_id":236283,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1595384451","product_id":100029201,"comment_content":"我在 spark-sql-kafka-0-10_2.11-2.4.0-cdh6.2.0 看到如下代码：<br>  private def strategy(caseInsensitiveParams: Map[String, String]) =<br>      caseInsensitiveParams.find(x =&gt; STRATEGY_OPTION_KEYS.contains(x._1)).get match {<br>    case (&quot;assign&quot;, value) =&gt;<br>      AssignStrategy(JsonUtils.partitions(value))<br>    case (&quot;subscribe&quot;, value) =&gt;<br>      SubscribeStrategy(value.split(&quot;,&quot;).map(_.trim()).filter(_.nonEmpty))<br>    case (&quot;subscribepattern&quot;, value) =&gt;<br>      SubscribePatternStrategy(value.trim())<br>    case _ =&gt;<br>      &#47;&#47; Should never reach here as we are already matching on<br>      &#47;&#47; matched strategy names<br>      throw new IllegalArgumentException(&quot;Unknown option&quot;)<br>  }<br>是不是说，Spark 中的kafkaDataSource 实现是来自于调用的 option 参数呢？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":502014,"discussion_content":"不太了解spark中的实现。代码中也没有出现kafkaDataSource？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1595811176,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":227204,"user_name":"弱水穿云天","can_delete":false,"product_type":"c1","uid":1190060,"ip_address":"","ucode":"80DC528A23ED7E","user_header":"https://static001.geekbang.org/account/avatar/00/12/28/ac/37a2a265.jpg","comment_is_top":false,"comment_ctime":1592313243,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1592313243","product_id":100029201,"comment_content":"打卡","like_count":0},{"had_liked":false,"id":219108,"user_name":"行则将至","can_delete":false,"product_type":"c1","uid":1542987,"ip_address":"","ucode":"DB972F2DF059C4","user_header":"https://static001.geekbang.org/account/avatar/00/17/8b/4b/fa52d222.jpg","comment_is_top":false,"comment_ctime":1589946136,"is_pvip":false,"replies":[{"id":"80979","content":"你是自动提交还是手动提交？应该是手动提交吧","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1589974378,"ip_address":"","comment_id":219108,"utype":1}],"discussion_count":1,"race_medal":1,"score":"1589946136","product_id":100029201,"comment_content":"老师。在学习这一章的时候。今天正好碰到一个commitFailedException的问题。kafka是windows版本，0.10.0.0。kafka的持久化目录用的就是默认的&#47;tmp目录。用Idea开发项目时，会经常启停该kafka。今天我启动了一个消费者，生产者发送消息，消费者立马就报出了commitFailedException异常。提示的就是poll loop的处理时间过长，提示我修改session.timeout.ms的值。<br>我的疑问点：我停止了消费者程序，此时就会发生reblance。然后，我又启动消费者。此时再次发生reblance。应该是重新进行分区分配，不应该报出这个错误啊。我这个场景下，这个错误发生的根本原因是什么？望老师解惑    (我最后的解决方案是：把tmp目录全部删除，然后再启动消费者就可以了。)","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":495686,"discussion_content":"你是自动提交还是手动提交？应该是手动提交吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589974378,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":186197,"user_name":"成立-Charlie","can_delete":false,"product_type":"c1","uid":1091556,"ip_address":"","ucode":"2970BB5446B70A","user_header":"https://static001.geekbang.org/account/avatar/00/10/a7/e4/5a4515e9.jpg","comment_is_top":false,"comment_ctime":1583795654,"is_pvip":false,"replies":[{"id":"71935","content":"通常无法保证，这也不属于典型的Kafka应用场景——Kafka追求高吞吐量。有诸多限制的话会降低使用Kafka的收益：）","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1583810162,"ip_address":"","comment_id":186197,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1583795654","product_id":100029201,"comment_content":"老师对于多线程消费的场景，如何保证消息的顺序呢。","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":486669,"discussion_content":"通常无法保证，这也不属于典型的Kafka应用场景——Kafka追求高吞吐量。有诸多限制的话会降低使用Kafka的收益：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1583810162,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1736462,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/7f/0e/e3a8dbd9.jpg","nickname":"Liujun","note":"","ucode":"3DB1F3CA57B5B3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":390218,"discussion_content":"采用特殊主题和特殊分区，生产者服务需要把允许等待未应答消息个数置为1，同步发送，同时消费端单线程顺序处理，另外还要考虑幂等性等，重试也要关闭。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1629716782,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":179476,"user_name":"Ryoma","can_delete":false,"product_type":"c1","uid":1130590,"ip_address":"","ucode":"7F692369239692","user_header":"https://static001.geekbang.org/account/avatar/00/11/40/5e/b8fada94.jpg","comment_is_top":false,"comment_ctime":1582011944,"is_pvip":true,"replies":[{"id":"69757","content":"1. 是的<br>2. 这是可能的。不同客户端设计机制不同。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1582072273,"ip_address":"","comment_id":179476,"utype":1}],"discussion_count":1,"race_medal":2,"score":"1582011944","product_id":100029201,"comment_content":"有两个问题：<br>1：请问消费者是不是只有：Consumer Group 及 Standalone Consumer 两类？<br>2：我在 Node 中，使用独立消费者配置相同的 groupId，启动了两个实例。使用生产者发布消息时，两个消费者实例都可以正常处理，跟老师上面说的有点不太一样呀？这个是由于客户端的不同导致的么？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":484275,"discussion_content":"1. 是的\n2. 这是可能的。不同客户端设计机制不同。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1582072273,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":176415,"user_name":"快跑","can_delete":false,"product_type":"c1","uid":1564645,"ip_address":"","ucode":"90ED7E6D40C58E","user_header":"https://static001.geekbang.org/account/avatar/00/17/df/e5/65e37812.jpg","comment_is_top":false,"comment_ctime":1581054209,"is_pvip":false,"replies":[{"id":"68703","content":"从日志只能看到请求超时，具体原因看不出来，还是要结合其他因素进行分析。如果你能确定是消费时间过长，那么优化这个点就可以了：）","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1581295957,"ip_address":"","comment_id":176415,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1581054209","product_id":100029201,"comment_content":"老师你好，我在使用spark streaming消费kafka消息会遇到某个batch消费耗时长。请老师帮忙分析一下这个是什么原因，应该怎么去优化。谢谢老师。日志大体如下：<br>20&#47;02&#47;06 21:13:18 INFO KafkaRDD: Computing topic test_topic, partition 0 offsets 470985316 -&gt; 470988502<br>20&#47;02&#47;06 21:13:18 DEBUG NetworkClient: Disconnecting from node 1 due to request timeout.<br>20&#47;02&#47;06 21:13:18 DEBUG ConsumerNetworkClient: Cancelled FETCH request ClientRequest(expectResponse=true, callback=org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler@bf99562, request=RequestSend(header={api_key=1,api_version=2,correlation_id=32,client_id=consumer-2}, body={replica_id=-1,max_wait_time=3000,min_bytes=1,topics=[{topic=test_topic,partitions=[{partition=0,fetch_offset=470986525,max_bytes=10485760}]}]}), createdTimeMs=1580994741183, sendTimeMs=1580994741183) with correlation id 32 due to node 1 being disconnected<br>20&#47;02&#47;06 21:13:18 DEBUG Fetcher: Fetch failed<br>org.apache.kafka.common.errors.DisconnectException<br>20&#47;02&#47;06 21:13:18 DEBUG NetworkClient: Initialize connection to node 2 for sending metadata request<br>20&#47;02&#47;06 21:13:18 DEBUG NetworkClient: Initiating connection to node 2 at host1:9092.","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":483096,"discussion_content":"从日志只能看到请求超时，具体原因看不出来，还是要结合其他因素进行分析。如果你能确定是消费时间过长，那么优化这个点就可以了：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1581295957,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":165405,"user_name":"Hale","can_delete":false,"product_type":"c1","uid":1129731,"ip_address":"","ucode":"1925955343FE94","user_header":"https://static001.geekbang.org/account/avatar/00/11/3d/03/b2d9a084.jpg","comment_is_top":false,"comment_ctime":1577234353,"is_pvip":true,"replies":[{"id":"63031","content":"看着像网络连接失败导致的问题。网络没问题吗？是持续性地报警吗？","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1577235420,"ip_address":"","comment_id":165405,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1577234353","product_id":100029201,"comment_content":"2019-12-23 16:43:56,367 consumer.py[line:792] WARNING Auto offset commit failed for group aff74e1e254e11ea9f47b827eb16d0ae: NodeNotReadyError: coordinator-1<br>2019-12-23 16:43:56,471 client_async.py[line:695] WARNING &lt;BrokerConnection node_id=coordinator-1 host=39.104.137.50:9093 &lt;connected&gt; [IPv4 (&#39;39.104.137.50&#39;, 9093)]&gt; timed out after 305000 ms. Closing connection.<br>2019-12-23 16:43:56,473 client_async.py[line:327] WARNING Node coordinator-1 connection failed -- refreshing metadata<br>2019-12-23 16:43:56,478 base.py[line:493] ERROR Error sending HeartbeatRequest_v1 to node coordinator-1 [[Error 7] RequestTimedOutError: Request timed out after 305000 ms]<br>2019-12-23 16:43:56,479 base.py[line:714] WARNING Marking the coordinator dead (node coordinator-1) for group aff74e1e254e11ea9f47b827eb16d0ae: [Error 7] RequestTimedOutError: Request timed out after 305000 ms.<br>出现上面的报错consumer就卡主了，不能接收数据了，是提交失败吧","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":479148,"discussion_content":"看着像网络连接失败导致的问题。网络没问题吗？是持续性地报警吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577235420,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":124967,"user_name":"钱","can_delete":false,"product_type":"c1","uid":1009652,"ip_address":"","ucode":"2C92A243A463D4","user_header":"https://static001.geekbang.org/account/avatar/00/0f/67/f4/9a1feb59.jpg","comment_is_top":false,"comment_ctime":1566030205,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1566030205","product_id":100029201,"comment_content":" CommitFailedException 表示，Consumer 客户端在提交位移时出现了错误或异常，而且还是那种不可恢复的严重异常。<br>如果框架在设计的时候，针对异常情况不但抛出异常信息，还给出相应的解决方案，那就更人性化啦！<br>多谢分享。","like_count":0},{"had_liked":false,"id":115130,"user_name":"曹伟雄","can_delete":false,"product_type":"c1","uid":1400754,"ip_address":"","ucode":"9740E426C0742C","user_header":"https://static001.geekbang.org/account/avatar/00/15/5f/b2/c4780c10.jpg","comment_is_top":false,"comment_ctime":1563498324,"is_pvip":false,"replies":[{"id":"42088","content":"用于侦测会话超时。standalone consumer和group的区分体现在API上","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563517231,"ip_address":"","comment_id":115130,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1563498324","product_id":100029201,"comment_content":"老师，请教2个问题，谢谢!<br>我想问下0.10.1.0之后的session.timeout.ms还有什么作用呢？<br>standalone consumer和group consumer在配置上如何区分?","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":458980,"discussion_content":"用于侦测会话超时。standalone consumer和group的区分体现在API上","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563517231,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":114675,"user_name":"郭刚","can_delete":false,"product_type":"c1","uid":1292032,"ip_address":"","ucode":"22CB8ECE8E3DCA","user_header":"https://static001.geekbang.org/account/avatar/00/13/b7/00/12149f4e.jpg","comment_is_top":false,"comment_ctime":1563360926,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1563360926","product_id":100029201,"comment_content":"[2019-07-17 18:53:36,230] ERROR [ReplicaManager broker=2] Error processing append operation on partition __consumer_offsets-49 (kafka.server.ReplicaManager)<br>org.apache.kafka.common.errors.NotEnoughReplicasException: The size of the current ISR Set(2) is insufficient to satisfy the min.isr requirement of 2 for partition __consumer_offsets-49<br>把min.insync.replicas = 2改成1，消费者就可以运行了，这种flower失效的情况怎么处理呢？","like_count":0,"discussions":[{"author":{"id":1292032,"avatar":"https://static001.geekbang.org/account/avatar/00/13/b7/00/12149f4e.jpg","nickname":"郭刚","note":"","ucode":"22CB8ECE8E3DCA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":2381,"discussion_content":"问题总算解决了，要增加__consumer_offsets副本的数量","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563527864,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":114664,"user_name":"郭刚","can_delete":false,"product_type":"c1","uid":1292032,"ip_address":"","ucode":"22CB8ECE8E3DCA","user_header":"https://static001.geekbang.org/account/avatar/00/13/b7/00/12149f4e.jpg","comment_is_top":false,"comment_ctime":1563359413,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1563359413","product_id":100029201,"comment_content":"老师，kafka报错，哪个论坛比较火？","like_count":0},{"had_liked":false,"id":114434,"user_name":"juan","can_delete":false,"product_type":"c1","uid":1503525,"ip_address":"","ucode":"2799013456F532","user_header":"https://static001.geekbang.org/account/avatar/00/16/f1/25/6908f80a.jpg","comment_is_top":false,"comment_ctime":1563302056,"is_pvip":false,"replies":[{"id":"41761","content":"这取决于你对如何才算处理完一条消息的定义。另外从Kafka中拿到消息后剩下的事情就完全由你负责了，因此如何计算处理时间应该是你说了算的：）","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563323895,"ip_address":"","comment_id":114434,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1563302056","product_id":100029201,"comment_content":"请问如何计算单条消息处理的时间， 比如收到一条消息之后要调用A,B,C,D,E 五个方法处理，其中处理完B,E之后将结果发给别的kafka，处理时间是处理完A,B时间还是处理完A,B,C,D,E 的总时间？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":458662,"discussion_content":"这取决于你对如何才算处理完一条消息的定义。另外从Kafka中拿到消息后剩下的事情就完全由你负责了，因此如何计算处理时间应该是你说了算的：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563323895,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":114389,"user_name":"电光火石","can_delete":false,"product_type":"c1","uid":1013160,"ip_address":"","ucode":"3AD33BB4AA940F","user_header":"https://static001.geekbang.org/account/avatar/00/0f/75/a8/dfe4cade.jpg","comment_is_top":false,"comment_ctime":1563288674,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1563288674","product_id":100029201,"comment_content":"我在线上也遇到这个问题，想问一下老师：在新的consumer加入，发生repartition的时候，是否也会抱这个错，谢谢了！","like_count":0},{"had_liked":false,"id":114383,"user_name":"曾轼麟","can_delete":false,"product_type":"c1","uid":1451391,"ip_address":"","ucode":"D418371AC11270","user_header":"https://static001.geekbang.org/account/avatar/00/16/25/7f/473d5a77.jpg","comment_is_top":false,"comment_ctime":1563288177,"is_pvip":false,"replies":[{"id":"41763","content":"这都是info级别的log，没有看出有什么问题。最好确认去leader副本所在的broker去看日志","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563324092,"ip_address":"","comment_id":114383,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1563288177","product_id":100029201,"comment_content":"老师我这边遇到了一个奇怪的情况，kafka生成者发送消息能创建topic,但是消息怎么都发不上去broker。并且在kafka-logs底下有一个和刚刚那条消息key值一样的文件夹,<br><br>并且打印出如下的日志：<br>[2019-07-16 22:34:16,380] INFO [Log partition=23bb7ffd-4aa5-42e2-9d84-c90f4566c15b-2, dir=&#47;tmp&#47;kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)<br>[2019-07-16 22:34:16,381] INFO [Log partition=23bb7ffd-4aa5-42e2-9d84-c90f4566c15b-2, dir=&#47;tmp&#47;kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)<br>[2019-07-16 22:34:16,383] INFO Created log for partition 23bb7ffd-4aa5-42e2-9d84-c90f4566c15b-2 in &#47;tmp&#47;kafka-logs with properties {compression.type -&gt; producer, message.format.version -&gt; 2.0-IV1, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, message.downconversion.enable -&gt; true, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 40","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":458635,"discussion_content":"这都是info级别的log，没有看出有什么问题。最好确认去leader副本所在的broker去看日志","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563324092,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":114270,"user_name":"Dovelol","can_delete":false,"product_type":"c1","uid":1253384,"ip_address":"","ucode":"9B5DDF7720F307","user_header":"https://static001.geekbang.org/account/avatar/00/13/20/08/bc06bc69.jpg","comment_is_top":false,"comment_ctime":1563264045,"is_pvip":false,"replies":[{"id":"41684","content":"不知道你的代码是怎么写的。你是说循环调用poll然后返回相同的方法，是吗","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563274349,"ip_address":"","comment_id":114270,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1563264045","product_id":100029201,"comment_content":"老师好，今天讲CommitFailedException的例子是调用consumer.commitSync();手动提交offset，确实当消息处理的总时间超过预设的max.poll.interval.ms时会报这个异常，但是如果是自动提交offset的情况下，不会报异常并且会一直重复消费，想问下这是什么原因呢？<br>","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":458588,"discussion_content":"不知道你的代码是怎么写的。你是说循环调用poll然后返回相同的方法，是吗","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563274349,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1253384,"avatar":"https://static001.geekbang.org/account/avatar/00/13/20/08/bc06bc69.jpg","nickname":"Dovelol","note":"","ucode":"9B5DDF7720F307","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":2149,"discussion_content":"设置enable.auto.commit=true，删除consumer.commitSync(); 也就是改为自动提交offset，其它代码不变，就不会报这个异常了，并且会一直重复消费，这是什么原因呢？代码是这样的…\nProperties props = new Properties();\n…\nprops.put(&#34;max.poll.interval.ms&#34;, 5000);\nprops.put(&#34;enable.auto.commit&#34;, &#34;false&#34;);//改为自动提交offset\nconsumer.subscribe(Arrays.asList(&#34;test-topic&#34;));\n \nwhile (true) {\n    ConsumerRecords<String, String> records = \n\t\tconsumer.poll(Duration.ofSeconds(1));\n    // 使用 Thread.sleep 模拟真实的消息处理逻辑\n    Thread.sleep(6000L);\n}\n","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1563284309,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":114116,"user_name":"cricket1981","can_delete":false,"product_type":"c1","uid":1001715,"ip_address":"","ucode":"758262F5958DA4","user_header":"https://static001.geekbang.org/account/avatar/00/0f/48/f3/f1034ffd.jpg","comment_is_top":false,"comment_ctime":1563239383,"is_pvip":false,"replies":[{"id":"41689","content":"没有。你可以自己试试。其实用法与consumer group差不多","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563274575,"ip_address":"","comment_id":114116,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1563239383","product_id":100029201,"comment_content":"想进一步了解学习standalone consumer有什么资料推荐吗？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":458525,"discussion_content":"没有。你可以自己试试。其实用法与consumer group差不多","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563274575,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":114104,"user_name":"Dovelol","can_delete":false,"product_type":"c1","uid":1253384,"ip_address":"","ucode":"9B5DDF7720F307","user_header":"https://static001.geekbang.org/account/avatar/00/13/20/08/bc06bc69.jpg","comment_is_top":false,"comment_ctime":1563238513,"is_pvip":false,"replies":[{"id":"41692","content":"所以这段注释是有歧义或不准确的地方啊。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563274693,"ip_address":"","comment_id":114104,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1563238513","product_id":100029201,"comment_content":"老师好，看你解释注释那段的时候提到消费者组已经开启了Rebalance过程，但是看后面的介绍，出现异常好像并不一定有Rebalance，是这样吗？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":458517,"discussion_content":"所以这段注释是有歧义或不准确的地方啊。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563274693,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1035562,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/cd/2a/bdbed6ed.jpg","nickname":"无菇朋友","note":"","ucode":"80482C5F0464A3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":2498,"discussion_content":"所以老师，出现这个错误一定是发生了rebalance是么，因为consumer不是已经从组中被踢出去了么","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563723985,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":114055,"user_name":"玉剑冰锋","can_delete":false,"product_type":"c1","uid":1214202,"ip_address":"","ucode":"8EA56A71BA5B22","user_header":"https://static001.geekbang.org/account/avatar/00/12/86/fa/4bcd7365.jpg","comment_is_top":false,"comment_ctime":1563234383,"is_pvip":false,"replies":[{"id":"41581","content":"你可以自己加一些打点代码来计算","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563237541,"ip_address":"","comment_id":114055,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1563234383","product_id":100029201,"comment_content":"通过什么方法计算单条消息处理时间呢？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":458497,"discussion_content":"你可以自己加一些打点代码来计算","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563237541,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1133918,"avatar":"https://static001.geekbang.org/account/avatar/00/11/4d/5e/c5c62933.jpg","nickname":"lmtoo","note":"","ucode":"FCD5B9C941D448","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":2068,"discussion_content":"StopWatch，spring内置有这个类，Apache Commons好像也有","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563241030,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}