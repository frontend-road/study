{"id":292803,"title":"期中测试题答案 | 这些问题，你都答对了吗？","content":"<p>你好，我是蒋德钧。今天，我来公布一下主观题的答案。</p><h3>第一题</h3><p>Redis在接收多个网络客户端发送的请求操作时，如果有一个客户端和Redis的网络连接断开了，Redis会一直等待该客户端恢复连接吗？为什么？</p><p><span class=\"orange\">答案：</span></p><p>Redis不会等待客户端恢复连接。<br>\n原因是，Redis的网络连接是由操作系统进行处理的，操作系统内核负责监听网络连接套接字上的连接请求或数据请求，而Redis采用了IO多路复用机制epoll，不会阻塞在某一个特定的套接字上。epoll机制监测到套接字上有请求到达时，就会触发相应的事件，并把事件放到一个队列中，Redis就会对这个事件队列中的事件进行处理。这样一来，Redis只用查看和处理事件队列，就可以了。当客户端网络连接断开或恢复时，操作系统会进行处理，并且在客户端能再次发送请求时，把接收到的请求以事件形式通知Redis。</p><h3>第二题</h3><p>Redis的主从集群可以提升数据可靠性，主节点在和从节点进行数据同步时，会使用两个缓冲区：复制缓冲区和复制积压缓冲区。这两个缓冲区的作用各是什么？会对Redis主从同步产生什么影响吗？</p><p><span class=\"orange\">答案：</span></p><p>首先来说一下复制缓冲区。</p><p><strong>作用：</strong>主节点开始和一个从节点进行全量同步时，会为从节点创建一个输出缓冲区，这个缓冲区就是复制缓冲区。当主节点向从节点发送RDB文件时，如果又接收到了写命令操作，就会把它们暂存在复制缓冲区中。等RDB文件传输完成，并且在从节点加载完成后，主节点再把复制缓冲区中的写命令发给从节点，进行同步。</p><!-- [[[read_end]]] --><p><strong>对主从同步的影响：</strong>如果主库传输RDB文件以及从库加载RDB文件耗时长，同时主库接收的写命令操作较多，就会导致复制缓冲区被写满而溢出。一旦溢出，主库就会关闭和从库的网络连接，重新开始全量同步。所以，我们可以通过调整client-output-buffer-limit slave这个配置项，来增加复制缓冲区的大小，以免复制缓冲区溢出。</p><p>再来看看复制积压缓冲区。</p><p><strong>作用：</strong>主节点和从节点进行常规同步时，会把写命令也暂存在复制积压缓冲区中。如果从节点和主节点间发生了网络断连，等从节点再次连接后，可以从复制积压缓冲区中同步尚未复制的命令操作。</p><p><strong>对主从同步的影响：</strong>如果从节点和主节点间的网络断连时间过长，复制积压缓冲区可能被新写入的命令覆盖。此时，从节点就没有办法和主节点进行增量复制了，而是只能进行全量复制。针对这个问题，应对的方法是调大复制积压缓冲区的大小（可以参考<a href=\"https://time.geekbang.org/column/article/272852\">第6讲</a>中对repl_backlog_size的设置）。</p><h3>第三题</h3><p>假设在业务场景中，我们有20GB的短视频属性信息（包括短视频ID、短视频基本信息，例如短视频作者、创建时间等）要持久化保存，并且线上负载以读为主，需要能快速查询到这些短视频信息。</p><p>现在，针对这个需求，我们想使用Redis来解决，请你来设计一个解决方案。我来提几个问题，你可以思考下。</p><p>首先，你会用Redis的什么数据类型来保存数据？如果我们只用单个实例来运行的话，你会采用什么样的持久化方案来保证数据的可靠性？</p><p>另外，如果不使用单实例运行，我们有两个备选方案：一个是用两台32GB内存的云主机来运行主从两个Redis实例；另一个是用10台8GB的云主机来运行Redis Cluster，每两台云主机分别运行一个Redis实例主库和从库，分别保存4GB数据，你会用哪种方案呢？请聊一聊你的想法。</p><p><span class=\"orange\">答案：</span></p><p>Redis的Hash类型属于典型的集合类型，可以保存key-value形式的数据。而且，当Hash类型中保存较多数据时，它的底层是由哈希表实现的。哈希表的存取复杂度是O(1)，所以可以实现快速访问。在这道题中，短视频属性信息属于典型key-value形式，所以，我们可以使用Hash类型保存短视频信息。具体来说，就是将一个短视频ID作为Hash集合的key，将短视频的其他属性信息作为Hash集合内部的键值对，例如“作者”:“实际姓名”，“创建时间”:“实际时间”。这样既满足了保存数据的需求，也可以利用Hash快速查询的特点，快速查到相应的信息。</p><p>Redis的AOF日志会记录客户端发送给实例的每一次写操作命令，在Redis实例恢复时，可以通过重新运行AOF文件中的命令，实现恢复数据的目的。在这道题的业务场景中，负载以读为主，因此，写命令不会太多，AOF日志文件的体量不会太大，即使实例故障了，也可以快速完成恢复。所以，当使用单实例运行时，我们可以使用AOF日志来做持久化方案。</p><p>关于使用多实例的运行方案：两种方案各有优势，我们来分析一下。</p><h4>方案一</h4><p>优势：可以节省云主机数量和成本。虽然主从节点进行第一次全量同步时，RDB文件较大，耗时会长些，但是因为写请求少，所以复制缓冲区的压力不大。<br>\n不足：如果网络环境不好，需要频繁地进行全量同步的话，这种方案的优势就小了，每次全量同步时的RDB生成和传输压力都很大。</p><h4>方案二</h4><p>优势：每个实例只用保存4GB数据，和从库同步时的压力较小。而且，这种方案的可扩展性更好，如果有新增数据，可以更好地应对。<br>\n不足：需要较多的云主机，运维和资源成本较高。</p><p>好了，这节课就到这里。假期很快就要结束了，希望你抓住最后的几天时间，好好地巩固一下所学的内容。我们下节课见。</p>","neighbors":{"left":{"article_title":"期中测试题 | 一套习题，测出你的掌握程度","id":292800},"right":{"article_title":"39 | Redis 6.0的新特性：多线程、客户端缓存与安全","id":310838}},"comments":[{"had_liked":false,"id":252265,"user_name":"yeek","can_delete":false,"product_type":"c1","uid":1020629,"ip_address":"","ucode":"A1C71023113CB9","user_header":"https://static001.geekbang.org/account/avatar/00/0f/92/d5/699384a0.jpg","comment_is_top":false,"comment_ctime":1602218263,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"44551891223","product_id":100056701,"comment_content":"客户端连接断开的补充猜测：<br><br>1. epoll只是负责帮我们维护连接，当客户端断连之后，epoll不会自己帮我们删除无效的连接，redis服务端有个空闲链接检测机制，需手动开启，用于定期检查释放无效的连接，删除epoll中的fd<br><br>2. 一般客户端会采用池化技术，定期检测客户端连接池的可用性，以保障不会一直创建链接和销毁连接","like_count":11},{"had_liked":false,"id":252269,"user_name":"徐小熊","can_delete":false,"product_type":"c1","uid":2120879,"ip_address":"","ucode":"673D3C055AE5B5","user_header":"https://static001.geekbang.org/account/avatar/00/20/5c/af/2215f3b6.jpg","comment_is_top":false,"comment_ctime":1602218952,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"10192153544","product_id":100056701,"comment_content":"老师，我想问一下，如果我们使用主从库模式，读写分离，会出现高并发情况下主库的写命令还未同步到从库的情况，这个时候又有读命令发送到从库，是不是就会读不到本来应该写入的数据呢？<br>","like_count":3,"discussions":[{"author":{"id":1388092,"avatar":"https://static001.geekbang.org/account/avatar/00/15/2e/3c/eae43616.jpg","nickname":"sid","note":"","ucode":"3D1F9169A19D29","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":311343,"discussion_content":"是的","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1602313085,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":286305,"user_name":"escray","can_delete":false,"product_type":"c1","uid":1020525,"ip_address":"","ucode":"1F4204930E47C4","user_header":"https://static001.geekbang.org/account/avatar/00/0f/92/6d/becd841a.jpg","comment_is_top":false,"comment_ctime":1617246024,"is_pvip":true,"discussion_count":0,"race_medal":2,"score":"1617246024","product_id":100056701,"comment_content":"以前是比较厌恶考试的，现在则比较喜欢，因为是给自己看的。<br><br>选择题第一次做 65 分，第二次 80 分，第三次 95……<br><br>第一题要点：Redis 不会等待客户端恢复连接。Redis 的网络连接由操作系统负责处理……采用 IO 多路复用机制 epoll<br><br>第二题我搞错了复制缓冲区和复制积压缓冲区的概念。<br><br>复制缓冲区就是主从同步时，主节点为从节点创建的输出缓冲区，暂存主节点发送 RDB 文件时收到的写命令操作。RDB 文件传输完成并且在从节点加载完成后，主节点将复制缓冲区中的写命令发给从节点。<br><br>如果复制缓冲区溢出，那么主库关闭和从库的网络连接，重新开始全量同步。可以调整 client-output-buffer-limit slave 配置项，增加复制缓冲区大小。<br><br>复制积压缓冲区，是在主从节点常规同步时，写命令暂存在复制积压缓冲区中，如果主从网络断连，那么从节点再次连接后，可以从复制积压缓冲区同步尚未复制的命令。<br><br>复制积压缓冲区是环形的，如果主从网络断连时间太长，复制积压缓冲区可能被新写入命令覆盖，无法增量复制，只能全量复制。可以调整 repl_backlog_size 的设置，修改复制积压缓冲区大小。<br><br>第三题可以使用 AOF 日志来做持久化方案，主要是因为负载以读为主，写命令不会太多，AOF 日志文件不会太大。<br><br>另外在选择方案的时候也要考虑经济成本。","like_count":0},{"had_liked":false,"id":269248,"user_name":"旅途","can_delete":false,"product_type":"c1","uid":1212902,"ip_address":"","ucode":"5022477E8E9441","user_header":"https://static001.geekbang.org/account/avatar/00/12/81/e6/6cafed37.jpg","comment_is_top":false,"comment_ctime":1608573135,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1608573135","product_id":100056701,"comment_content":"根据方案一中的描述,持久化方案还是用了rdb不是吗","like_count":0,"discussions":[{"author":{"id":2308075,"avatar":"","nickname":"Geek_89e362","note":"","ucode":"E596C2CFE1CFAF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":350274,"discussion_content":"主从复制跟持久化是没有关系的，无论你的持久化方式是采用 AOF还是RDB，主从的全量复制都是采用 RDB 文件","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1613792226,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":262871,"user_name":"KayeArt","can_delete":false,"product_type":"c1","uid":1136073,"ip_address":"","ucode":"61181F41BFAE04","user_header":"https://static001.geekbang.org/account/avatar/00/11/55/c9/3df70927.jpg","comment_is_top":false,"comment_ctime":1605864751,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1605864751","product_id":100056701,"comment_content":"nice","like_count":0},{"had_liked":false,"id":252213,"user_name":"漫步oo0云端","can_delete":false,"product_type":"c1","uid":1427152,"ip_address":"","ucode":"4906095751D7B0","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eppZl39m2knwLH6PIia5YQTOWSOTGhy8ZZAutUIrxKOYFCtLLLYb1OZvIVVLzL7Y8eglKFe4Sib9D7g/132","comment_is_top":false,"comment_ctime":1602200077,"is_pvip":false,"discussion_count":4,"race_medal":0,"score":"1602200077","product_id":100056701,"comment_content":"请问第三题的视频为什么首选不是保存在string上？string也是保存在全局哈希表中，也很快啊？","like_count":0,"discussions":[{"author":{"id":1020629,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/92/d5/699384a0.jpg","nickname":"yeek","note":"","ucode":"A1C71023113CB9","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":311049,"discussion_content":"全局hash有redisobject对象，占用空间较多。\n但如果需求更复杂点，比如按照时间范围，作者id进行筛选和查询的话，设计就更复杂点了","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1602202766,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":3,"child_discussions":[{"author":{"id":1427152,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eppZl39m2knwLH6PIia5YQTOWSOTGhy8ZZAutUIrxKOYFCtLLLYb1OZvIVVLzL7Y8eglKFe4Sib9D7g/132","nickname":"漫步oo0云端","note":"","ucode":"4906095751D7B0","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1020629,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/92/d5/699384a0.jpg","nickname":"yeek","note":"","ucode":"A1C71023113CB9","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":311199,"discussion_content":"如果是这样，string适用于什么场景呢？感觉弊端太明显了，不知道什么场景使用用string了呢。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1602251774,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":311049,"ip_address":""},"score":311199,"extra":""},{"author":{"id":1020629,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/92/d5/699384a0.jpg","nickname":"yeek","note":"","ucode":"A1C71023113CB9","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1427152,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eppZl39m2knwLH6PIia5YQTOWSOTGhy8ZZAutUIrxKOYFCtLLLYb1OZvIVVLzL7Y8eglKFe4Sib9D7g/132","nickname":"漫步oo0云端","note":"","ucode":"4906095751D7B0","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":311240,"discussion_content":"数据量不是特别大，场景简单，内存充沛，就用string，其次value较大时，string性价比也还可以","likes_number":6,"is_delete":false,"is_hidden":false,"ctime":1602288331,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":311199,"ip_address":""},"score":311240,"extra":""},{"author":{"id":1427152,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eppZl39m2knwLH6PIia5YQTOWSOTGhy8ZZAutUIrxKOYFCtLLLYb1OZvIVVLzL7Y8eglKFe4Sib9D7g/132","nickname":"漫步oo0云端","note":"","ucode":"4906095751D7B0","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1020629,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/92/d5/699384a0.jpg","nickname":"yeek","note":"","ucode":"A1C71023113CB9","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":311720,"discussion_content":"哦哦，感谢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1602472134,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":311240,"ip_address":""},"score":311720,"extra":""}]}]},{"had_liked":false,"id":252032,"user_name":"我不用网名","can_delete":false,"product_type":"c1","uid":1066411,"ip_address":"","ucode":"B1C921455BF44F","user_header":"https://static001.geekbang.org/account/avatar/00/10/45/ab/7dec2448.jpg","comment_is_top":false,"comment_ctime":1602068845,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1602068845","product_id":100056701,"comment_content":"哈哈，国庆终于把进度补上来了","like_count":0}]}