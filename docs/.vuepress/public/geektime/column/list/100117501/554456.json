{"id":554456,"title":"13 | FFmpeg 有哪些常见的应用场景？","content":"<p>你好，我是刘歧。</p><p>FFmpeg API 应用部分的前两节课，我们了解了AVFormat、AVCodec以及常用的操作接口，但是现在这些知识还是“各忙各的”的状态，好像没有真正地把图像与封装格式、传输协议给串起来，形成一个完整的音视频图形图像处理的链条，可能你都没空看FFmpeg源代码目录里面提供的例子。</p><p>别急，这节课我们就一起来看一看FFmpeg源代码里面的例子，主要是不转码只转封装、转码转封装和直播推流三个场景，通过分析这三个场景案例，加深一下你对API使用的理解。</p><h2>Remuxing</h2><p>在使用FFmpeg的API做开发之前，我们先来梳理一下想要做Remuxing的话都需要用到哪些结构体与模块，看一下基本的流程。</p><p><img src=\"https://static001.geekbang.org/resource/image/d7/a4/d7bac673dcbfc6949d9abae5ac6bc9a4.png?wh=1310x906\" alt=\"图片\"></p><ol>\n<li>打开输入文件和打开输出文件，我们可以理解为初始化操作。</li>\n<li>从输入文件中读取音视频数据包，将音视频数据包写入输出文件，我们可以把它理解为一个循环操作，直到遇到结束相关的操作信息才停止。</li>\n<li>关闭输出文件和输入文件，我们可以理解为收尾操作。</li>\n</ol><p>下面，我们逐步剖析一下。</p><p>初始化操作部分的代码大概会使用这些函数。</p><p>使用avformat_open_input、avformat_find_stream_info来打开输入文件，并根据输入文件中的音视频流信息建立音视频流，也就是AVStreams。</p><!-- [[[read_end]]] --><p>使用avformat_alloc_output_context2、avformat_new_stream和avformat_write_header 来打开输出文件，并建立音视频流，输出文件会用到AVOutputFormat，并建立封装格式操作的AVFormatContext，作为操作上下文的结构体，并且会尝试写入输出文件的封装格式头部信息。</p><p>从输入文件中读取音视频数据包，将音视频数据包写入输出文件会使用av_read_frame 函数，从输入文件中读取AVPacket音视频数据包，还会使用av_interleaved_write_frame函数，将读取到的音视频数据包写入输出文件。</p><p>然后是关闭输出文件和输入文件，使用av_write_trailer函数，在关闭输出文件之前做写封装收尾工作。使用avformat_free_context函数关闭输出文件，并释放因操作输出文件封装格式申请的资源。最后使用avformat_close_input关闭输入文件并释放相关的资源。</p><p>当然，除了以上这些操作之外，还有一些API是我们可以根据自己的需要使用的。详细的内容你可以看一下<a href=\"https://ffmpeg.org/doxygen/trunk/remuxing_8c-example.html\">示例代码</a>。其实在日常操作时，<strong>做remux主要还是用于收录一些音视频内容的场景中，用得更多的还是编码或者转码的操作。</strong>因为音视频的编码数据格式比较多，需要统一转成相同的编码，换句话说，就是将输入的音视频内容转成统一规格输出的场景，比收录场景更常见，下面我们来看一下转码场景的代码用例。</p><h2>Transcoding</h2><p>转码操作与转封装操作类似，就是多了解码和编码步骤，并且大多数情况下需要自己制定输出的编码参数与编码规格。和之前一样，我们先梳理一下转码的流程。</p><p><img src=\"https://static001.geekbang.org/resource/image/a1/46/a1051608199e8a3e8fc860b884f1c146.png?wh=1808x1234\" alt=\"图片\"></p><p>打开文件的操作，可以定义为open_input_file，这样将输入文件操作相关的代码放在一个函数里面比较清晰。</p><pre><code class=\"language-plain\">static int open_input_file(const char *filename)\n{\n    int ret;\n    unsigned int i;\n\n    ifmt_ctx = NULL;\n    if ((ret = avformat_open_input(&amp;ifmt_ctx, filename, NULL, NULL)) &lt; 0) {\n        av_log(NULL, AV_LOG_ERROR, \"Cannot open input file\\n\");\n        return ret;\n    }\n\n    if ((ret = avformat_find_stream_info(ifmt_ctx, NULL)) &lt; 0) {\n        av_log(NULL, AV_LOG_ERROR, \"Cannot find stream information\\n\");\n        return ret;\n    }\n\n    stream_ctx = av_calloc(ifmt_ctx-&gt;nb_streams, sizeof(*stream_ctx));\n    if (!stream_ctx)\n        return AVERROR(ENOMEM);\n\n    for (i = 0; i &lt; ifmt_ctx-&gt;nb_streams; i++) {\n        AVStream *stream = ifmt_ctx-&gt;streams[i];\n        const AVCodec *dec = avcodec_find_decoder(stream-&gt;codecpar-&gt;codec_id);\n        AVCodecContext *codec_ctx;\n        if (!dec) {\n            av_log(NULL, AV_LOG_ERROR, \"Failed to find decoder for stream #%u\\n\", i);\n            return AVERROR_DECODER_NOT_FOUND;\n        }\n        codec_ctx = avcodec_alloc_context3(dec);\n        if (!codec_ctx) {\n            av_log(NULL, AV_LOG_ERROR, \"Failed to allocate the decoder context for stream #%u\\n\", i);\n            return AVERROR(ENOMEM);\n        }\n        ret = avcodec_parameters_to_context(codec_ctx, stream-&gt;codecpar);\n        if (ret &lt; 0) {\n            av_log(NULL, AV_LOG_ERROR, \"Failed to copy decoder parameters to input decoder context \"\n                   \"for stream #%u\\n\", i);\n            return ret;\n        }\n        /* Reencode video &amp; audio and remux subtitles etc. */\n        if (codec_ctx-&gt;codec_type == AVMEDIA_TYPE_VIDEO\n                || codec_ctx-&gt;codec_type == AVMEDIA_TYPE_AUDIO) {\n            if (codec_ctx-&gt;codec_type == AVMEDIA_TYPE_VIDEO)\n                codec_ctx-&gt;framerate = av_guess_frame_rate(ifmt_ctx, stream, NULL);\n            /* Open decoder */\n            ret = avcodec_open2(codec_ctx, dec, NULL);\n            if (ret &lt; 0) {\n                av_log(NULL, AV_LOG_ERROR, \"Failed to open decoder for stream #%u\\n\", i);\n                return ret;\n            }\n        }\n        stream_ctx[i].dec_ctx = codec_ctx;\n\n        stream_ctx[i].dec_frame = av_frame_alloc();\n        if (!stream_ctx[i].dec_frame)\n            return AVERROR(ENOMEM);\n    }\n\n    av_dump_format(ifmt_ctx, 0, filename, 0);\n    return 0;\n}\n</code></pre><p>从代码中可以看到，除了在Remuxing中见过的函数之外，这里还使用了avcodec_find_decoder，通过CODECID查找要使用的解码器，当然，这里如果自己已经确定好音视频流是什么编码的话，也可以通过avcodec_find_decoder_by_name来指定解码器的名字。</p><p>然后用avcodec_alloc_context3申请AVCodecContext上下文，用avcodec_parameters_to_context将解析到的AVStream流信息中的AVCodecParameter复制到AVCodecContext对应字段中，方便后面解码的时候用。</p><p>使用avcodec_open2打开解码器，因为没有需要传的option，所以这里的avcodec_open2的option字段设置的是NULL，然后申请一个AVFrame，用来存储解码后的AVFrame数据。</p><p>然后是打开输出文件，这部分的代码也可以封装到一个函数里面，整体看上去会清晰很多。</p><pre><code class=\"language-plain\">static int open_output_file(const char *filename)\n{\n    AVStream *out_stream;\n    AVStream *in_stream;\n    AVCodecContext *dec_ctx, *enc_ctx;\n    const AVCodec *encoder;\n    int ret;\n    unsigned int i;\n\n    ofmt_ctx = NULL;\n    avformat_alloc_output_context2(&amp;ofmt_ctx, NULL, NULL, filename);\n    if (!ofmt_ctx) {\n        av_log(NULL, AV_LOG_ERROR, \"Could not create output context\\n\");\n        return AVERROR_UNKNOWN;\n    }\n\n\n\n    for (i = 0; i &lt; ifmt_ctx-&gt;nb_streams; i++) {\n        out_stream = avformat_new_stream(ofmt_ctx, NULL);\n        if (!out_stream) {\n            av_log(NULL, AV_LOG_ERROR, \"Failed allocating output stream\\n\");\n            return AVERROR_UNKNOWN;\n        }\n\n        in_stream = ifmt_ctx-&gt;streams[i];\n        dec_ctx = stream_ctx[i].dec_ctx;\n\n        if (dec_ctx-&gt;codec_type == AVMEDIA_TYPE_VIDEO\n                || dec_ctx-&gt;codec_type == AVMEDIA_TYPE_AUDIO) {\n            /* in this example, we choose transcoding to same codec */\n            encoder = avcodec_find_encoder(dec_ctx-&gt;codec_id);\n            if (!encoder) {\n                av_log(NULL, AV_LOG_FATAL, \"Necessary encoder not found\\n\");\n                return AVERROR_INVALIDDATA;\n            }\n            enc_ctx = avcodec_alloc_context3(encoder);\n            if (!enc_ctx) {\n                av_log(NULL, AV_LOG_FATAL, \"Failed to allocate the encoder context\\n\");\n                return AVERROR(ENOMEM);\n            }\n\n            /* In this example, we transcode to same properties (picture size,\n             * sample rate etc.). These properties can be changed for output\n             * streams easily using filters */\n            if (dec_ctx-&gt;codec_type == AVMEDIA_TYPE_VIDEO) {\n                enc_ctx-&gt;height = dec_ctx-&gt;height;\n                enc_ctx-&gt;width = dec_ctx-&gt;width;\n                enc_ctx-&gt;sample_aspect_ratio = dec_ctx-&gt;sample_aspect_ratio;\n                /* take first format from list of supported formats */\n                if (encoder-&gt;pix_fmts)\n                    enc_ctx-&gt;pix_fmt = encoder-&gt;pix_fmts[0];\n                else\n                    enc_ctx-&gt;pix_fmt = dec_ctx-&gt;pix_fmt;\n                /* video time_base can be set to whatever is handy and supported by encoder */\n                enc_ctx-&gt;time_base = av_inv_q(dec_ctx-&gt;framerate);\n            } else {\n                enc_ctx-&gt;sample_rate = dec_ctx-&gt;sample_rate;\n                ret = av_channel_layout_copy(&amp;enc_ctx-&gt;ch_layout, &amp;dec_ctx-&gt;ch_layout);\n                if (ret &lt; 0)\n                    return ret;\n                /* take first format from list of supported formats */\n                enc_ctx-&gt;sample_fmt = encoder-&gt;sample_fmts[0];\n                enc_ctx-&gt;time_base = (AVRational){1, enc_ctx-&gt;sample_rate};\n            }\n\n            if (ofmt_ctx-&gt;oformat-&gt;flags &amp; AVFMT_GLOBALHEADER)\n                enc_ctx-&gt;flags |= AV_CODEC_FLAG_GLOBAL_HEADER;\n\n            /* Third parameter can be used to pass settings to encoder */\n            ret = avcodec_open2(enc_ctx, encoder, NULL);\n            if (ret &lt; 0) {\n                av_log(NULL, AV_LOG_ERROR, \"Cannot open video encoder for stream #%u\\n\", i);\n                return ret;\n            }\n            ret = avcodec_parameters_from_context(out_stream-&gt;codecpar, enc_ctx);\n            if (ret &lt; 0) {\n                av_log(NULL, AV_LOG_ERROR, \"Failed to copy encoder parameters to output stream #%u\\n\", i);\n                return ret;\n            }\n\n            out_stream-&gt;time_base = enc_ctx-&gt;time_base;\n            stream_ctx[i].enc_ctx = enc_ctx;\n        } else if (dec_ctx-&gt;codec_type == AVMEDIA_TYPE_UNKNOWN) {\n            av_log(NULL, AV_LOG_FATAL, \"Elementary stream #%d is of unknown type, cannot proceed\\n\", i);\n            return AVERROR_INVALIDDATA;\n        } else {\n            /* if this stream must be remuxed */\n            ret = avcodec_parameters_copy(out_stream-&gt;codecpar, in_stream-&gt;codecpar);\n            if (ret &lt; 0) {\n                av_log(NULL, AV_LOG_ERROR, \"Copying parameters for stream #%u failed\\n\", i);\n                return ret;\n            }\n            out_stream-&gt;time_base = in_stream-&gt;time_base;\n        }\n\n    }\n    av_dump_format(ofmt_ctx, 0, filename, 1);\n\n    if (!(ofmt_ctx-&gt;oformat-&gt;flags &amp; AVFMT_NOFILE)) {\n        ret = avio_open(&amp;ofmt_ctx-&gt;pb, filename, AVIO_FLAG_WRITE);\n        if (ret &lt; 0) {\n            av_log(NULL, AV_LOG_ERROR, \"Could not open output file '%s'\", filename);\n            return ret;\n        }\n    }\n\n    /* init muxer, write output file header */\n    ret = avformat_write_header(ofmt_ctx, NULL);\n    if (ret &lt; 0) {\n        av_log(NULL, AV_LOG_ERROR, \"Error occurred when opening output file\\n\");\n        return ret;\n    }\n\n    return 0;\n}\n</code></pre><p>输出部分的话，需要设置的不是解码器，而是编码器，所以调用的是avcodec_find_encoder，然后设置编码器的AVCodecContext上下文，打开编码器。</p><p>因为是例子，所以这里大多数参数是从输入的AVStream的AVCodecParameter和AVCodecContext里面拿到的，相当于复制到输出的AVStream里面了。然后通过avio_open打开输出的AVFormatContext的pb句柄，也就是AVIOContext。然后在初始化操作的时候，写一下输出文件的文件头。</p><p>接着，设置原始数据操作相关的滤镜初始化，例如调色、调音色、放大、缩小等操作，这些操作可以在自己拿到解码后的数据后，用OpenGL等强大的库来完成，这里就不展开介绍了。</p><p>接下来就是循环操作：拿到AVPacket、解码、取原始数据、编码，再拿到AVPacket、再解码、再取原始数据、再编码，直到遇到退出相关的条件为止。</p><pre><code class=\"language-plain\">static int encode_write_frame(unsigned int stream_index, int flush)\n{\n    StreamContext *stream = &amp;stream_ctx[stream_index];\n    FilteringContext *filter = &amp;filter_ctx[stream_index];\n    AVFrame *filt_frame = flush ? NULL : filter-&gt;filtered_frame;\n    AVPacket *enc_pkt = filter-&gt;enc_pkt;\n    int ret;\n\n    av_log(NULL, AV_LOG_INFO, \"Encoding frame\\n\");\n    /* encode filtered frame */\n    av_packet_unref(enc_pkt);\n\n    ret = avcodec_send_frame(stream-&gt;enc_ctx, filt_frame);\n\n    if (ret &lt; 0)\n        return ret;\n\n    while (ret &gt;= 0) {\n        ret = avcodec_receive_packet(stream-&gt;enc_ctx, enc_pkt);\n\n        if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF)\n            return 0;\n\n        /* prepare packet for muxing */\n        enc_pkt-&gt;stream_index = stream_index;\n        av_packet_rescale_ts(enc_pkt,\n                             stream-&gt;enc_ctx-&gt;time_base,\n                             ofmt_ctx-&gt;streams[stream_index]-&gt;time_base);\n\n        av_log(NULL, AV_LOG_DEBUG, \"Muxing frame\\n\");\n        /* mux encoded frame */\n        ret = av_interleaved_write_frame(ofmt_ctx, enc_pkt);\n    }\n\n    return ret;\n}\n\n\n\nwhile (1) {\n        if ((ret = av_read_frame(ifmt_ctx, packet)) &lt; 0)\n            break;\n        stream_index = packet-&gt;stream_index;\n        av_log(NULL, AV_LOG_DEBUG, \"Demuxer gave frame of stream_index %u\\n\",\n                stream_index);\n\n        if (filter_ctx[stream_index].filter_graph) {\n            StreamContext *stream = &amp;stream_ctx[stream_index];\n\n            av_packet_rescale_ts(packet,\n                                 ifmt_ctx-&gt;streams[stream_index]-&gt;time_base,\n                                 stream-&gt;dec_ctx-&gt;time_base);\n            ret = avcodec_send_packet(stream-&gt;dec_ctx, packet);\n            if (ret &lt; 0) {\n                av_log(NULL, AV_LOG_ERROR, \"Decoding failed\\n\");\n                break;\n            }\n\n            while (ret &gt;= 0) {\n                ret = avcodec_receive_frame(stream-&gt;dec_ctx, stream-&gt;dec_frame);\n                if (ret == AVERROR_EOF || ret == AVERROR(EAGAIN))\n                    break;\n                else if (ret &lt; 0)\n                    goto end;\n\n                stream-&gt;dec_frame-&gt;pts = stream-&gt;dec_frame-&gt;best_effort_timestamp;\n                ret = encode_write_frame(stream-&gt;dec_frame, stream_index);\n                if (ret &lt; 0)\n                    goto end;\n            }\n        }\n        av_packet_unref(packet);\n    }\n</code></pre><p>从代码里可以看到，通过av_read_frame循环读取AVPacket，然后调用avcodec_send_packet将AVPacket发送给解码器做解码，通过avcodec_receive_frame拿到解码后的AVFrame数据，然后通过编码器给AVFrame的数据编码，再写到输出文件里。这时候，写编码后的AVPacket数据用的是交错的方式。最后千万别忘了收尾工作，不然内存就泄露了。</p><p>关于转码相关的操作也有代码示例，通过访问<a href=\"https://ffmpeg.org/doxygen/trunk/transcoding_8c-example.html\">官方文档转码示例</a>就可以看到对应代码的完整版。到这里，Remuxing、Transcoding都介绍完了，如果想试试RTMP推流的话，我们可以继续看一下Muxing的例子，自己造一个数据，编码之后推流。</p><h2>推流</h2><p>因为前面两个例子涵盖了API的大部分接口了，其实做推流的话也比较简单，可以任选Remuxing或者Transcoding里的任何一个例子。</p><p>设置输出文件的时候，有一个avformat_alloc_output_context2操作，从我们Remuxing例子中可以看到，最后一个字段是输出文件名，这里可以改成RTMP的URL地址，关于URL的地址，我们<a href=\"https://time.geekbang.org/column/article/546485\">第5节课</a>讲过，这里就不再介绍了。</p><p>有一点需要注意，因为是推RTMP的直播流，所以输出格式要设置成FLV，否则会报错，报错内容是这样的：</p><pre><code class=\"language-plain\">[NULL @ 0x3dc1900] Unable to find a suitable output format for 'rtmp://127.0.0.1/live/stream'\n</code></pre><p>它提示找不到适合这个URL的输出格式，也就是说，我们需要指定输出格式，RTMP对应的输出格式是FLV，所以最后avformat_alloc_output_context2的第一个参数是输出的AVFormatContext，第二个参数可以设置成NULL交给FFmpeg自动查找，第三个参数设置为\"flv\"字符串，第四个参数就是我们输出的URL地址。</p><p>为了控制节奏，我们可以在循环av_read_frame操作的时候，在av_read_frame的下一句加上usleep(40000)来控制节奏，也就是sleep 40毫秒。最后，别忘了在头文件声明部分加上#include &lt;unistd.h&gt;，不然编译会报错。</p><h2>小结</h2><p>最后，我们来复习一下这节课的主要内容。</p><p>这节课，我们通过不转码只转封装、转码转封装和直播推流三个场景案例，详细地了解了FFmpeg中API的使用方法。现在我们可以在视频内容收录的场景中，使用API来自己独立实现收录音视频内容。如果需要将音视频文件或者直播流转一下码再输出的话，也可以通过转码的例子来完成。</p><p>灵活运用今天学到的这三个例子，基本上就可以满足大部分的场景了。当然，这些还是远远不够的，就像上节课说的，还是要从FFmpeg源代码的doc/examples目录下提供的例子入手，多改、多看、多学习，必要的话，以examples代码为入口跟踪代码进行学习，你会对FFmpeg的API有更深刻的理解的。</p><h2>思考题</h2><p>讲了这么多，你可以思考这么一个问题，如果想通过Remuxing将一个视频编码是H.264，音频编码是AAC编码的直播流，收录为MP4文件，并且MP4文件是moov在mdat的前面的话，该怎么改Remuxing这段代码呢？</p>","neighbors":{"left":{"article_title":"12 | FFmpeg基础模块（三）：AVCodec","id":553087},"right":{"article_title":"14｜如何在FFmpeg中定制一个自己专属的模块？","id":556024}},"comments":[{"had_liked":false,"id":355259,"user_name":"peter","can_delete":false,"product_type":"c1","uid":1058183,"ip_address":"北京","ucode":"261C3FC001DE2D","user_header":"https://static001.geekbang.org/account/avatar/00/10/25/87/f3a69d1b.jpg","comment_is_top":false,"comment_ctime":1661235089,"is_pvip":true,"replies":[{"id":"129280","content":"1. 和声道布局有关系，ffmpeg -layouts<br><br>2. 下载ffmpeg源代码后可以先编译ffmpeg，.&#47;configure ;make然后make examples可以编译examples代码","user_name":"作者回复","comment_id":355259,"uid":"1287929","ip_address":"北京","utype":1,"ctime":1661306724,"user_name_real":"编辑"}],"discussion_count":1,"race_medal":0,"score":"1661235089","product_id":100117501,"comment_content":"请教老师两个问题：<br>Q1：双声道合并单声道，还能听到两个声道，有什么意义？<br>用这个命令：ffmpeg -i input.aac -ac 1 output.aac，可以把双声道合并为单声道，但是，合并后的文件，还是能听到两个声道的声音，怎么能算是“单声道”呢？<br>用命令“ffmpeg -i jixiaolan_aac.aac -map_channel 0.0.0 left.aac -map_channel 0.0.1 right.aac”生成的两个文件，无论是left.aac还是right.aac ,两个耳机都能听到，为什么？<br><br>这个问题是看书《FFmpeg从入门到精通》遇到的。<br>Q2：文中的代码，应该是C代码。这些代码可以下载并执行吗？ （比如：从github上下载，然后编译、执行，能看到结果）。如果有一个完整的步骤，能操作成功并看到结果就更好了。","like_count":0,"discussions":[{"author":{"id":1287929,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a6/f9/79cad962.jpg","nickname":"悟空@OnVideo","note":"","ucode":"C320167A9A17B8","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":585045,"discussion_content":"1. 和声道布局有关系，ffmpeg -layouts\n\n2. 下载ffmpeg源代码后可以先编译ffmpeg，./configure ;make然后make examples可以编译examples代码","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1661306724,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京"},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]}]}