{"id":200158,"title":"48 | MongoDB + Spark连接实战","content":"<p><strong>课件和Demo地址</strong><br>\n<a href=\"https://gitee.com/geektime-geekbang/geektime-mongodb-course\">https://gitee.com/geektime-geekbang/geektime-mongodb-course</a></p>","comments":[{"had_liked":false,"id":238056,"user_name":"楚翔style","can_delete":false,"product_type":"c3","uid":1174846,"ip_address":"","ucode":"E715F82C34A9AA","user_header":"https://static001.geekbang.org/account/avatar/00/11/ed/3e/c1725237.jpg","comment_is_top":false,"comment_ctime":1596037921,"is_pvip":false,"replies":[{"id":88155,"content":"MongoDB 会在内存里操作数据，用异步刷盘方式。所以你内存足够大的话，可以近似的认为它有内存数据库的性能。 事实上它有一种存储引擎InMemory就是完全的内存数据库了。","user_name":"作者回复","user_name_real":"远航的TJ 唐建法","uid":1260017,"ctime":1596276716,"ip_address":"","comment_id":238056,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"mongo是内存数据库吗？ 它的数据应该在保存到硬盘吧","like_count":0,"discussions":[{"author":{"id":1260017,"avatar":"https://static001.geekbang.org/account/avatar/00/13/39/f1/6d18a4d1.jpg","nickname":"远航的TJ 唐建法","note":"","ucode":"0719807390250A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":502633,"discussion_content":"MongoDB 会在内存里操作数据，用异步刷盘方式。所以你内存足够大的话，可以近似的认为它有内存数据库的性能。 事实上它有一种存储引擎InMemory就是完全的内存数据库了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1596276716,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1360712,"avatar":"https://static001.geekbang.org/account/avatar/00/14/c3/48/3a739da6.jpg","nickname":"天草二十六","note":"","ucode":"3165EE3007527B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":374431,"discussion_content":"现在没有哪个数据库不利用内存，而直接和磁盘打交道。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1621175237,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":230377,"user_name":"大江","can_delete":false,"product_type":"c3","uid":1047741,"ip_address":"","ucode":"6A0E92C1C1211D","user_header":"http://thirdwx.qlogo.cn/mmopen/h0KAdRFKjCOSLRjzictvlaFZ3EbHnmXKgIu71XpEng5XSUicAnmOXBWkkpuibFGibG9anibwM9Q1E1Q0hFNybYY8azQUkfo8NEBSia/132","comment_is_top":false,"comment_ctime":1593357196,"is_pvip":false,"replies":[{"id":88172,"content":"可以 - mongodb + spark 就是用来做数据分析。因为mongodb本身的分析能力（特别是多表关联）不是太足够","user_name":"作者回复","user_name_real":"远航的TJ 唐建法","uid":1260017,"ctime":1596278876,"ip_address":"","comment_id":230377,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"请问老师，mongodb+spark能做OLAP吗？spark的实时计算能力，能满足多维度的数据统计和查询功能吗？谢谢！","like_count":0,"discussions":[{"author":{"id":1260017,"avatar":"https://static001.geekbang.org/account/avatar/00/13/39/f1/6d18a4d1.jpg","nickname":"远航的TJ 唐建法","note":"","ucode":"0719807390250A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":499858,"discussion_content":"可以 - mongodb + spark 就是用来做数据分析。因为mongodb本身的分析能力（特别是多表关联）不是太足够","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1596278876,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":180090,"user_name":"qbit","can_delete":false,"product_type":"c3","uid":1262927,"ip_address":"","ucode":"96C70A1E47B93D","user_header":"https://static001.geekbang.org/account/avatar/00/13/45/4f/f94caf47.jpg","comment_is_top":false,"comment_ctime":1582185646,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"希望老师开一个 spark 实战的课程！","like_count":4},{"had_liked":false,"id":262886,"user_name":"龙行天下","can_delete":false,"product_type":"c3","uid":1669292,"ip_address":"","ucode":"23551F422A02EF","user_header":"https://static001.geekbang.org/account/avatar/00/19/78/ac/a34a15fb.jpg","comment_is_top":false,"comment_ctime":1605868820,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"hadoop 有yarn统一分配资源，在各节点上拉取数据，拉取大数据时，基本没有网络传输，spark 与 mongodb有什么好的方式，计算节点Co-Lo 部署是什么意思，就是简单的将在每一个有mongodb的节点上都部署上spark节点?有文章推荐嘛，网上基本上没有找到类似的内容","like_count":0},{"had_liked":false,"id":230375,"user_name":"大江","can_delete":false,"product_type":"c3","uid":1047741,"ip_address":"","ucode":"6A0E92C1C1211D","user_header":"http://thirdwx.qlogo.cn/mmopen/h0KAdRFKjCOSLRjzictvlaFZ3EbHnmXKgIu71XpEng5XSUicAnmOXBWkkpuibFGibG9anibwM9Q1E1Q0hFNybYY8azQUkfo8NEBSia/132","comment_is_top":false,"comment_ctime":1593357029,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"请问老师，mongodb + spark能做OLAP吗？用spark做多维度的实时数据统计，可以满足需求吗？谢谢！","like_count":0},{"had_liked":false,"id":228158,"user_name":"lcken","can_delete":false,"product_type":"c3","uid":1298018,"ip_address":"","ucode":"9F7CD55370D94B","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/3Mf5ickZ4gwXXM0kO04EtWY6icTswVNSg1H8bhy72b5ErNjbmKkawcneovickGfmK1OkfhfIZ2Fib77e2uLIsiaH4aw/132","comment_is_top":false,"comment_ctime":1592569719,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100040001,"comment_content":"不知道golang技术栈能否完成相同功能？","like_count":0}]}