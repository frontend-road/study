{"id":740873,"title":"第 8 章 数据访问进阶(1)","content":"<blockquote>\n<p><strong>本章内容</strong></p>\n<ul>\n<li>适用于生产环境的连接池配置技巧</li>\n<li>在 Spring 工程中使用 Redis 的方法</li>\n<li>通过 Spring 的缓存抽象简化缓存的使用</li>\n</ul>\n</blockquote>\n<p>前两章我们都在讨论如何实现基本的数据库操作：直接使用 JDBC，或者通过 ORM 框架。但在实际的生产环境中，仅仅实现基本的操作是不够的，甚至只用关系型数据库也是不够的，我们还需要 NoSQL 的帮助，遇到热点数据，还要增加缓存为数据库减负。所以，在这一章里，我们就要来聊聊这些进阶的内容。</p>\n<h2 id=\"nav_point_120\">8.1　连接池的实用配置</h2>\n<p>在之前的章节里，我们基本都是在使用 Spring Boot 提供的默认数据库连接池配置，它能满足基本的需求。但在生产环境中会遇到很多实际的问题，光靠基本配置就有点捉襟见肘了，例如，连接数据库用的密码属于需要保护的敏感信息，不能直接放在配置文件里该怎么办？为了方便排查问题，希望能记录执行的所有 SQL 该怎么办？</p>\n<h3 id=\"nav_point_121\">8.1.1　保护敏感的连接配置</h3>\n<p>连接数据库所需的信息包括三个要素——JDBC URL、用户名和密码。数据库密码是需要重点保护的信息，所以像第 6 章的代码示例那样以明文方式将密码写在 <code>application.properties</code> 里显然是不合适的。也许你会说：“为配置文件设置一个普通用户不可读的权限，只有运维人员能查看其中的内容行不行？”负责安全的工作人员会告诉你：“不行！”</p>\n<p>在本节中，我们先来了解一下如何为 HikariCP 和 Druid 实现密码加密功能，而在后续的第 14 章，我们还会聊到 Spring Cloud Config 的配置项加密功能。如果你正在使用 Spring Cloud Config，集中式地管理加密密码会是一个相对更好的选择。</p><!-- [[[read_end]]] -->\n<ol>\n<li><p><strong>结合 HikariCP 与 Jasypt 实现密码加密</strong></p>\n<p>HikariCP 的作者一心想做好高性能连接池，把所有其他工作都“外包”了出去，所以配置项加密这个差事显然就需要其他工具来帮忙了。Jasypt 的全称是 Java Simplified Encryption，一看这个名字就知道它是在 Java 环境里处理加解密的，Jasypt 可以很方便地与 Spring 项目集成到一起，究竟有多方便呢？它直接提供了一个 <code>EncryptablePropertiesPropertySource</code>，可以直接解密属性值中用 <code>ENC()</code> 括起来的密文。而且它还有一个 Spring Boot Starter，几乎就是“开箱即用”。</p>\n<p>第一步，在 pom.xml 中添加 <code>jasypt-spring-boot-starter</code> 依赖：</p>\n<pre class=\"code-rows\"><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.github.ulisesbocchio&lt;/groupId&gt;\n    &lt;artifactId&gt;jasypt-spring-boot-starter&lt;/artifactId&gt;\n    &lt;version&gt;3.0.3&lt;/version&gt;\n&lt;/dependency&gt;</code></pre>\n<p>因为我们都会开启自动配置，所以这个起步依赖会自己完成剩下的配置。如果没有开启自动配置，则需要在配置类上增加 <code>@EnableEncryptableProperties</code> 注解。</p>\n<p>第二步，修改配置文件，增加 Jasypt 的配置，并将明文密码改为密文。主要是配置加解密使用的算法和密钥，两者分别是 <code>jasypt.encryptor.algorithm</code> 和 <code>jasypt.encryptor.password</code>，默认的算法是 <code>PBEWITHHMACSHA512ANDAES_256</code>。其主要的配置如表 8-1 所示。</p>\n<p><strong>表 8-1　<code>jasypt-spring-boot-starter</code> 的一些默认配置</strong></p>\n<table class=\"table table-bordered table-striped table-condensed\" width=\"90%\" border=\"1\"><tr><th>配置项</th><th>默认值</th><th>说明</th></tr><tr><td><code>jasypt.encryptor.algorithm</code></td><td><code>PBEWITHHMACSHA512ANDAES_256</code></td><td>加解密算法</td></tr><tr><td><code>jasypt.encryptor.provider-name</code></td><td><code>SunJCE</code></td><td>加密提供者</td></tr><tr><td><code>jasypt.encryptor.salt-generator-classname</code></td><td><code>org.jasypt.salt.RandomSaltGenerator</code></td><td>盐生成器</td></tr><tr><td><code>jasypt.encryptor.iv-generator-classname</code></td><td><code>org.jasypt.iv.RandomIvGenerator</code></td><td>初始化向量生成器</td></tr></table>\n\n<p>要进行加密，可以直接用 Jasypt 的 Jar 包，调用 CLI 的类。在 macOS 中，可以在 ~/.m2/repository 的 Maven 本地仓库里找到 jasypt-1.9.3.jar，执行如下命令：</p>\n<pre class=\"code-rows\"><code>▸ java -cp ./jasypt-1.9.3.jar org.jasypt.intf.cli.JasyptPBEStringEncryptionCLI input=明文 password=密钥\nalgorithm=PBEWITHHMACSHA512ANDAES_256 ivGeneratorClassName=org.jasypt.iv.RandomIvGenerator\nsaltGeneratorClassName=org.jasypt.salt.RandomSaltGenerator</code></pre>\n<p>假设给的明文和密钥都是 <code>binary-tea</code>，那执行的输出应该会是下面这样的（<code>OUTPUT</code> 部分就是加密后的密文）：</p>\n<pre class=\"code-rows\"><code>----ARGUMENTS-------------------\n\ninput: binary-tea\npassword: binary-tea\nsaltGeneratorClassName: org.jasypt.salt.RandomSaltGenerator\nivGeneratorClassName: org.jasypt.iv.RandomIvGenerator\nalgorithm: PBEWITHHMACSHA512ANDAES_256\n----OUTPUT----------------------\n\nX401LMpOiBz7+4gOXybK9cQdDOYlqX7mWXmmj6aGZPGWwjqcbf/80hj0vQWqhaqa</code></pre>\n<p>在 <code>application.properties</code> 中，将 <code>spring.datasource.password</code> 修改为 <code>ENC(X401LMpOiBz7+4gOXybK9cQdDOYlqX7mWXmmj6aGZPGWwjqcbf/80hj0vQWqhaqa)</code> 就完成了配置的修改。</p>\n<p>第三步，在运行时提供解密的密钥。如果把密钥也写在 <code>application.properties</code> 里，那等于把保险箱钥匙和保险箱放在了一起，所以，至少密钥应该放在另一个单独的文件里。借助 Spring Boot 的能力，可以将 <code>jasypt.encryptor.password</code> 放在命令行参数或者环境变量里。由于命令行参数可以通过命令行直接观察到，所以环境变量 <code>JASYPT_ENCRYPTOR_PASSWORD</code> 会是个更好的选择。</p>\n<p>&nbsp;</p>\n</li>\n<li><p><strong>使用 Druid 内置功能实现密码加密</strong></p>\n<p>Druid 的思路与 HikariCP 截然相反，连接池可能会用到的各种相关功能，它都自己实现了，可谓“Druid 在手，连接无忧”。Druid 内置了数据库密码的加密功能，使用 RSA 非对称算法来进行加解密，我们无须操心各种加解密的细节，它能够自己全部封装好，例如，具体操作时内部使用 <code>RSA/ECB/PKCS1Padding</code>。只要用它的工具生成公私钥对，并加密好明文就可以了。</p>\n<p>使用 Druid 提供的命令行工具来生成密钥和密文，和 Jasypt 一样，在本机的 Maven 仓库里找到 Druid 的 Jar 包。例如，在我的 Mac 上，1.2.8 版本 Jar 包的位置是 ~/.m2/repository/com/alibaba/druid/1.2.8，在这个目录里执行下面的命令：</p>\n<pre class=\"code-rows\"><code>▸ java -cp druid-1.2.8.jar com.alibaba.druid.filter.config.ConfigTools 密码明文</code></pre>\n<p>假设密码明文是 <code>binary-tea</code>，则输出会类似下面这样，公私钥和密文会有所不同：</p>\n<pre class=\"code-rows\"><code>privateKey:MIIBUwIBADANBgkqhkiG9w0BAQEFAASCAT0wggE5AgEAAkEAggg3wZKK1/bzA4M4JQ8CtoX48+5poBLFUvMJwxBtnss1o\nUEKacWbw2C0vym+WMMSMgm6R+kCrliJqZ6r8MbYuwIDAQABAkAwntQCTEIgOJVrVdBTgwZXq0aIJzhVg09HEdsvld/3RKnQa5WYBbHnw\n8zEpptF7VCckVEzQDsOY2zzTmCJO0bRAiEAwUqm7RxrVlyKJ2DEoPIzpXbL+g/aW+FO4KA4pVkDq8MCIQCsN7TeYokq8gugiLNngUbz\nBuCL59ovLZUcmkBIbtVnqQIgYTjvZWxaAQJi6xOdU2b/20Y5qvm2V2ioiAuO8nwngIkCIAquleBpWjq4srHtaLtV0HHIjmr/IZBlkm\ncoxi33+fKpAiAyiVc+QJCtRAZrf8Q5KKi8K2wP5TzxopIWAi7l15MSow==\npublicKey:MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAIIIN8GSitf28wODOCUPAraF+PPuaaASxVLzCcMQbZ7LNaFBCmnFm8NgtL8pvl\njDEjIJukfpAq5Yiameq/DG2LsCAwEAAQ==\npassword:gTCrgZfRos9fKw3OOyhkWKaKeiwDrUCTkwIskdB+MdxMQF9CGwVY4wIiIm131Aivt4nEXEHLwavWKMOJTRqjIQ==</code></pre>\n<p>接下来，要在 <code>application.properties</code> 中开启密码加密功能，需要让 Druid 加载 <code>ConfigFilter</code> 这个过滤器，并配置解密用的密钥，就像下面这样 <span class=\"comment-number\">1</span>：</p>\n<pre class=\"code-rows\"><code>spring.datasource.password=gTCrgZfRos9fKw3OOyhkWKaKeiwDrUCTkwIskdB+MdxMQF9CGwVY4wIiIm131Aivt4nEXEHLwavWKMOJTRqjIQ==\n\nspring.datasource.druid.filters=config\nspring.datasource.druid.connection-properties=config.decrypt=true;config.decrypt.key=$\n\npublicKey=MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAIIIN8GSitf28wODOCUPAraF+PPuaaASxVLzCcMQbZ7LNaFBCmnFm8NgtL8pvljDEjIJukfpAq5Yiameq/DG2LsCAwEAAQ==\n\n# 省略其他配置</code></pre>\n<p>同样的，把解密的密钥和密文放在一起也不太安全，有两种方式可供选择。</p>\n<ul>\n<li>在命令行上设置系统属性 <code>-Ddruid.config.decrypt.key=</code> 密钥。</li>\n<li>在 Druid 专属的配置文件里设置解密密钥 <code>config.decrypt.key=</code> 密钥和 <code>password=</code> 密码密文，同时要修改 <code>application.properties</code> 中的连接属性，就像下面这样：</li>\n</ul>\n<pre class=\"code-rows\"><code>spring.datasource.druid.connection-properties=config.decrypt=true;config.file=外部 Druid 配置文件路径</code></pre>\n<p>Druid 配置加密的逻辑基本都在 <code>ConfigFilter</code> 里，它的大致逻辑是这样的：</p>\n<p>(1) 在 Druid 加载 <code>Filter</code> 时，会调用其中的 <code>init()</code> 初始化方法；</p>\n<p>(2) <code>init()</code> 会从 <code>DruidDataSource</code> 的 <code>connectProperties</code> 属性，以及指定的配置文件中获取配置；</p>\n<p>(3) 判断是否需要解密密码；</p>\n<p>(4) 如果需要解密，再从第 (2) 步的两个位置获取解密的密钥；</p>\n<p>(5) 解密获得密码明文并进行设置。</p>\n</li>\n</ol>\n\n<h3 id=\"nav_point_122\">8.1.2　记录 SQL 语句执行情况</h3>\n<p>通常在遇到请求处理缓慢的情况时，我们会对执行的每一步进行分析，看看究竟慢在哪里。如果是执行 SQL 语句，那就要找到较慢的 SQL 进行优化，这时需要记录慢 SQL 日志，DBA 一般也会监控数据库端的慢 SQL。还有另一种场景，数据库里的记录内容与预期的不符，这种时候，如果能记录下每条执行的 SQL 语句，再回过头来分析问题就能方便很多。因此，不管什么情况，如果能够详细地记录程序执行的 SQL 语句，在后续各种性能优化和问题分析时都会非常有用。<span class=\"comment-number\">2</span></p>\n\n<ol>\n<li><p><strong>结合 HikariCP 与 P6SPY 实现 SQL 记录</strong></p>\n<p>HikariCP 本身并没有提供 SQL 日志的功能，因此需要借助 P6SPY<span class=\"comment-number\">3</span> 来记录执行的 SQL。P6SPY 是一套可以无缝拦截并记录 SQL 执行情况的框架，它工作在 JDBC 层面，所以无论我们使用什么连接池，是否使用 ORM 框架，都能通过 P6SPY 来进行拦截。</p>\n<p>首先，在 pom.xml 中引入 P6SPY 的依赖：</p>\n<pre class=\"code-rows\"><code>&lt;dependency&gt;\n    &lt;groupId&gt;p6spy&lt;/groupId&gt;\n    &lt;artifactId&gt;p6spy&lt;/artifactId&gt;\n    &lt;version&gt;3.9.1&lt;/version&gt;\n&lt;/dependency&gt;</code></pre>\n<p>接下来，调整连接池的配置，将 JDBC 驱动类名指定为 <code>com.p6spy.engine.spy.P6SpyDriver</code>，并修改 URL：</p>\n<pre class=\"code-rows\"><code>spring.datasource.driver-class-name=com.p6spy.engine.spy.P6SpyDriver\nspring.datasource.url=jdbc:p6spy:h2:mem:testdb</code></pre>\n<p>P6SPY 的 URL 形式基本可以归纳为在原先的 JDBC URL 的基础上，在 <code>jdbc:</code> 后插入一段 <code>p6spy:</code>，其他与使用数据库原生 JDBC 驱动一致。如果是 MySQL，则 URL 类似 <code>jdbc:p6spy:mysql://localhost:3306/test?useUnicode=true&amp;characterEncoding=UTF-8</code>。</p>\n<p>最后，我们还需要一个 P6SPY 的配置文件。在 CLASSPATH 里放一个 <code>spy.properties</code>，其中是 P6SPY 的相关配置 a。表 8-2 列举了一些基本的配置。</p>\n<p><strong>表 8-2　P6SPY 配置文件中的基本配置项</strong><span class=\"comment-number\">4</span></p>\n<table class=\"table table-bordered table-striped table-condensed\" width=\"90%\" border=\"1\"><tr><th>配置项</th><th>默认值</th><th>说明 <sup><b>5</b></sup></th></tr><tr><td><code>dateformat</code></td><td>默认使用时间戳的形式</td><td>日期格式，使用 <code>SimpleDateFormat</code> 的格式进行配置</td></tr><tr><td><code>logMessageFormat</code></td><td><code>com.p6spy.engine.spy.appender.SingleLineFormat</code></td><td>日志格式化类，可以在 <code>SingleLineFormat</code> 和 <code>CustomLineFormat</code> 之间选择</td></tr><tr><td><code>customLogMessageFormat</code></td><td><code>%(currentTime)|%(executionTime)|%(category)|connection%(connectionId)|%(sqlSingleLine)</code></td><td><code>CustomLineFormat</code> 使用的输出格式</td></tr><tr><td><code>appender</code></td><td><code>com.p6spy.engine.spy.appender.FileLogger</code></td><td>打印日志使用的 <code>Appender</code>，可以在 <code>FileLogger</code>、<code>SthoutLogger</code> 和 <code>Slf4JLogger</code> 之间选择</td></tr><tr><td><code>logfile</code></td><td>spy.log</td><td><code>FileLogger</code> 输出的日志文件</td></tr><tr><td><code>outagedetection</code></td><td><code>false</code></td><td>是否开启慢 SQL 检测，当这个开关开启时，除了慢的 SQL 语句其他语句都不会再输出了</td></tr><tr><td><code>outagedetectioninterval</code></td><td><code>60</code></td><td>慢 SQL 执行检测的间隔时间，单位是秒</td></tr><tr><td><code>realdatasourceclass</code></td><td></td><td>真实的数据源类名，一般都能自动检测出实际需要的驱动类名</td></tr><tr><td><code>realdatasourceproperties</code></td><td></td><td>真实的数据源配置属性，配置项用键值对形式表示，键与值用分号分隔，不同的键值对之间用逗号分隔</td></tr></table>\n\n<blockquote>\n<p><sup><b>5</b></sup>为了方便排版，这一列的类只写了类名，而在实际配置时需要使用全限定类名。</p>\n</blockquote>\n<p>假设我们的 <code>spy.properties</code> 是下面这样的：</p>\n<pre class=\"code-rows\"><code>appender=com.p6spy.engine.spy.appender.Slf4JLogger\ndateformat=yyyyMMdd'T'HH:mm:ss</code></pre>\n<p>在之前的 binarytea-jpa 中完成上述所有的修改，关闭 Hibernate 的 SQL 输出，运行程序，就能在日志中看到类似下面的输出，其中包含了 SQL 执行时间、耗时和 SQL 等内容，一般建议把 P6SPY 的日志单独配置到一个日志里去，方便查看：<span class=\"comment-number\">6</span></p>\n<pre class=\"code-rows\"><code>2022-02-26 14:27:29.922 INFO 67257 --- [main] p6spy : 20220226T14:27:29|0|statement|connection 0|\nurl jdbc:p6spy:h2:mem:testdb|select count(*) as col_0_0_ from t_menu menuitem0_|select count(*) as\ncol_0_0_ from t_menu menuitem0_</code></pre>\n<p>&nbsp;</p>\n</li>\n<li><p><strong>使用 Druid 内置功能实现 SQL 记录</strong></p>\n<p>Druid 就不需要什么额外的库支持了，它自己就内置了详尽的日志与统计功能，与密码加密功能一样，这些功能也是通过 <code>Filter</code> 来实现的。</p>\n<p>先是日志过滤器 <code>LogFilter</code>，Druid 一共内置了四个针对不同日志框架的 <code>LogFilter</code> 子类，在配置时可以使用它们的别名。</p>\n<ul>\n<li>对应 Log4j 1.<em>x</em> 的 <code>Log4jFilter</code>，别名 <code>log4j</code>。</li>\n<li>对应 Log4j 2.<em>x</em> 的 <code>Log4j2Filter</code>，别名 <code>log4j2</code>。</li>\n<li>对应 Commongs Logging 的 <code>CommonsLogFilter</code>，别名 <code>commonlogging</code>。</li>\n<li>对应 SLF4J 的 <code>Slf4jLogFilter</code>，别名 <code>slf4j</code>。</li>\n</ul>\n<p>Druid 的日志过滤器打印的信息很多，它们分别使用了不同的 <code>Logger</code>。我们可以针对不同的 <code>Logger</code> 做不同的日志配置，在实际使用时建议挑选其中的一些打印就可以了。例如，根据不同的日志级别，将日志输出到不同的文件，具体的日志框架配置可以参考它们的文档。表 8-3 罗列了一些与 <code>LogFilter</code> 相关的配置。</p>\n<p><strong>表 8-3　<code>LogFilter</code> 中用到的 <code>Logger</code> 名称和配置</strong></p>\n<table class=\"table table-bordered table-striped table-condensed\" width=\"90%\" border=\"1\"><tr><th><code>Logger</code> 名称</th><th>配置项</th><th>说明</th></tr><tr><td><code>druid.sql.DataSource</code></td><td></td><td>打印关于 <code>DataSource</code> 的日志</td></tr><tr><td><code>druid.sql.Connection</code></td><td><code>druid.log.conn=true</code></td><td>打印关于 <code>Connection</code> 的日志</td></tr><tr><td><code>druid.sql.Statement</code></td><td><code>druid.log.stmt=true</code></td><td>打印关于 <code>Statement</code> 的日志</td></tr><tr><td><code>druid.sql.Statement</code></td><td><code>druid.log.stmt.executableSql=false</code></td><td>在开启了 <code>Statement</code> 的日志时，是否打印执行的 SQL</td></tr><tr><td><code>druid.sql.ResultSet</code></td><td><code>druid.log.rs=true</code></td><td>打印关于 <code>ResultSet</code> 的日志</td></tr></table>\n\n<p>子类，在配置时可以使用它们的别名：查看。要在打印的一大堆 SQL 里找到慢 SQL，还是需要一点时间的。为此，Druid 还贴心地提供了一个慢 SQL 统计的过滤器 <code>StatFilter</code>，别名是 <code>stat</code>。它有三个参数：</p>\n<ul>\n<li><code>druid.stat.logSlowSql</code>，是否打印慢 SQL，默认值为 <code>false</code>；</li>\n<li><code>druid.stat.slowSqlMillis</code>，用来定义多慢的 SQL 属于慢 SQL，默认值为 <code>3000</code>，单位毫秒；</li>\n<li><code>druid.stat.mergeSql</code>，在统计时是否合并 SQL，默认值为 <code>false</code>。</li>\n</ul>\n<p>在 <code>application.properties</code> 中，可以配置多个过滤器，就像下面示例的第二行代码这样，用逗号分隔，随后再配置一些属性。由于 Druid 中正常的 SQL 输出使用的是 <code>DEBUG</code> 级别，所以我们还要调整一下相关 <code>Logger</code> 的日志级别才能输出日志。下面是直接在 <code>application.properties</code> 里修改日志级别的代码，但实践中更建议在日志框架的配置文件里修改，和其他日志配置放一起：</p>\n<pre class=\"code-rows\"><code>logging.level.druid.sql.*=debug\n\nspring.datasource.druid.filters=config,slf4j,stat\nspring.datasource.druid.connection-properties=druid.log.stmt.executableSql=true;druid.stat.\nlogSlowSql=true;druid.stat.mergeSql=true</code></pre>\n<p>执行程序时，我们可以在日志里找到大量与数据库操作相关的日志，其中会有类似下面这样的日志，打印出了 <code>PreparedStatement</code> 的 SQL、参数值的类型，以及执行耗时：</p>\n<pre class=\"code-rows\"><code>2020-10-07 23:16:43.174 DEBUG 68289 --- [main] druid.sql.Statement : \ncreated. select * from t_menu where id = ?\n2020-10-07 23:16:43.174 DEBUG 68289 --- [main] druid.sql.Statement : \nParameters : [1]\n2020-10-07 23:16:43.174 DEBUG 68289 --- [main] druid.sql.Statement : \nTypes : [BIGINT]\n2020-10-07 23:16:43.175 DEBUG 68289 --- [main] druid.sql.Statement : \nquery executed. 0.293573 millis. select * from t_menu where id = ?</code></pre>\n</li>\n</ol>\n\n\n\n<h3 id=\"nav_point_123\">8.1.3　Druid 的 <code>Filter</code> 扩展</h3>\n<p>Druid 的 <code>Filter</code> 是个非常有用的机制，可以拦截 <code>DruidDataSource</code>、<code>Connection</code>、<code>Statement</code>、<code>PreparedStatement</code>、<code>CallableStatement</code>、<code>ResultSet</code>、<code>ResultSetMetaData</code>、<code>Wrapper</code> 和 <code>Clob</code> 上方法的执行。这其中使用了责任链模式，也就是将不同的过滤器串联在一起，以实现不同的功能。</p>\n<p>前文提到的数据库密码加密、数据库执行日志都是 <code>Filter</code> 的例子，在 Druid 里还有一个非常有用的 <code>Filter</code>，那就是 SQL 注入防火墙，即 <code>WallFilter</code>，别名是 <code>wall</code>。它能够有效地控制通过 Druid 执行的 SQL，避免恶意行为。通常情况下，自动识别的配置就已经够用了。在 Spring Boot 中，<code>Filter</code> 除了像 8.1.1 节和 8.1.2 节中那样配置之外，还可以借助 Druid Spring Boot Starter 的帮助，直接在 <code>application.properties</code> 里像下面这样来配置，具体的配置实现可以参考 <code>DruidFilterConfiguration</code> 类：</p>\n<pre class=\"code-rows\"><code>spring.datasource.druid.filter.wall.enabled=true\nspring.datasource.druid.filter.wall.db-type=h2\nspring.datasource.druid.filter.wall.config.delete-allow=false\nspring.datasource.druid.filter.wall.config.drop-table-allow=false\nspring.datasource.druid.filter.wall.config.create-table-allow=false\nspring.datasource.druid.filter.wall.config.alter-table-allow=false</code></pre>\n<p>不光很多内置功能是通过 <code>Filter</code> 实现的，我们自己也可以通过它做出很多扩展。要开发自己的 <code>Filter</code>，可以直接实现 <code>Filter</code> 接口。但这么做太麻烦，有太多的方法需要我们提供空实现，而我们往往只关心其中的几个，所以继承 <code>FilterAdapter</code> 或者 <code>FilterEventAdapter</code> 会是更好的选择。</p>\n<p><code>FilterAdapter</code> 为每个方法都提供了默认实现，可以直接调用方法参数中传入的 <code>FilterChain</code> 的对应方法，继续执行责任链中的其他过滤器方法。例如，<code>preparedStatement_executeUpdate()</code> 方法的实现是下面这样的：</p>\n<pre class=\"code-rows\"><code>public int preparedStatement_executeUpdate(FilterChain chain, PreparedStatementProxy statement)\nthrows SQLException {\n    return chain.preparedStatement_executeUpdate(statement);\n}</code></pre>\n<p><code>FilterEventAdapter</code> 是 <code>FilterAdapter</code> 的子类，它在执行责任链的基础之上，又增加了执行前后的动作，以 <code>statement_execute()</code> 为例，它的实现是下面这样的：</p>\n<pre class=\"code-rows\"><code>public boolean statement_execute(FilterChain chain, StatementProxy statement, String sql,\nString columnNames[]) throws SQLException {\n    statementExecuteBefore(statement, sql);\n    try {\n        boolean firstResult = super.statement_execute(chain, statement, sql, columnNames);\n        this.statementExecuteAfter(statement, sql, firstResult);\n        return firstResult;\n    } catch (SQLException error) {\n        statement_executeErrorAfter(statement, sql, error);\n        throw error;\n    } catch (RuntimeException error) {\n        statement_executeErrorAfter(statement, sql, error);\n        throw error;\n    } catch (Error error) {\n        statement_executeErrorAfter(statement, sql, error);\n        throw error;\n    }\n}</code></pre>\n<p>我们可以根据自己的需要，选择性覆盖 <code>statementExecuteBefore()</code>、<code>statementExecuteAfter()</code> 或 <code>statement_executeErrorAfter()</code> 方法，达到在 SQL 语句执行前、执行后、抛异常时运行自定义逻辑的目的。</p>\n<p>现在，假设我们希望在执行 <code>Connection</code> 的连接动作前后打印一些日志，可以像代码示例 8-1<span class=\"comment-number\">7</span> 那样，继承 <code>FilterEventAdapter</code>，覆盖 <code>connection_connectBefore()</code> 和 <code>connection_connectAfter</code>，并在里面添加自己的逻辑就可以了。</p>\n\n<blockquote>\n<p><strong>代码示例 8-1</strong>　<code>ConnectionConnectFilter</code> 类代码片段</p>\n</blockquote>\n<pre class=\"code-rows\"><code>@Slf4j\n@AutoLoad // 这个注解稍后解释\npublic class ConnectionConnectFilter extends FilterEventAdapter {\n    @Override\n    public void connection_connectBefore(FilterChain chain, Properties info) {\n        log.info(\"Trying to create a new Connection.\");\n        super.connection_connectBefore(chain, info);\n    }\n\n    @Override\n    public void connection_connectAfter(ConnectionProxy connection) {\n        super.connection_connectAfter(connection);\n        log.info(\"We have a new connected Connection.\");\n    }\n}</code></pre>\n<p>在加载 <code>Filter</code> 时有三种方式，第一种是在配置文件中通过别名来选择要加载的 <code>Filter</code>。别名与具体类的对应关系配置在 META-INF/druid-filter.properties 里，内置的文件内容如下所示：</p>\n<pre class=\"code-rows\"><code>druid.filters.default=com.alibaba.druid.filter.stat.StatFilter\ndruid.filters.stat=com.alibaba.druid.filter.stat.StatFilter\ndruid.filters.mergeStat=com.alibaba.druid.filter.stat.MergeStatFilter\ndruid.filters.counter=com.alibaba.druid.filter.stat.StatFilter\ndruid.filters.encoding=com.alibaba.druid.filter.encoding.EncodingConvertFilter\ndruid.filters.log4j=com.alibaba.druid.filter.logging.Log4jFilter\ndruid.filters.log4j2=com.alibaba.druid.filter.logging.Log4j2Filter\ndruid.filters.slf4j=com.alibaba.druid.filter.logging.Slf4jLogFilter\ndruid.filters.commonlogging=com.alibaba.druid.filter.logging.CommonsLogFilter\ndruid.filters.commonLogging=com.alibaba.druid.filter.logging.CommonsLogFilter\ndruid.filters.wall=com.alibaba.druid.wall.WallFilter\ndruid.filters.config=com.alibaba.druid.filter.config.ConfigFilter</code></pre>\n<p>可以看到，键是 <code>druid.filters.</code> 别名，值是具体的全限定类名，所以前面可以用 <code>config</code>、<code>stat</code> 和 <code>slf4j</code> 这样的别名来加载 <code>Filter</code>。</p>\n<p>我们可以在自己的工程里也创建一个 META-INF/druid-filter.properties 文件，内容是之前 <code>ConnectionConnectFilter</code> 的映射：</p>\n<pre class=\"code-rows\"><code>druid.filters.connectLog=learning.spring.binarytea.support.ConnectionConnectFilter</code></pre>\n<p>第二种方式是让 Druid 自动加载 <code>Filter</code>。<code>DruidDataSource</code> 在通过 <code>init()</code> 初始化时，会调用 <code>initFromSPIServiceLoader()</code> 方法，使用 Java 的 <code>ServiceLoader</code> 来加载 <code>Filter</code> 的实现类。如果类上加了 <code>@AutoLoad</code> 注解，则自动加载该 <code>Filter</code>。<code>ServiceLoader</code> 会查找 META-INF/services/com.alibaba.druid.filter.Filter 文件，并从文件中获取具体的全限定类名，因此我们需要把扩展的类写在这个文件里。在工程中创建这个文件，内容如下：</p>\n<pre class=\"code-rows\"><code>learning.spring.binarytea.support.ConnectionConnectFilter</code></pre>\n<p>第三种方式，就是直接在 Spring 上下文中配置 <code>Filter</code> 对应的 Bean，随后将它赋值给 <code>DruidDataSource</code> 的 <code>proxyFilters</code> 属性。这种方式最为灵活，可以根据情况对 Bean 做各种调整，但配置时相对麻烦一些。</p>\n<h2 id=\"nav_point_124\">8.2　在 Spring 工程中访问 Redis</h2>\n<p>如果对系统的性能有所要求，通常都会在系统中引入分布式缓存，在一些极端的情况下甚至会抛弃传统的关系型数据库，将大量数据直接持久化在类似 Redis 这样的 NoSQL<span class=\"comment-number\">8</span> 中。Redis<span class=\"comment-number\">9</span> 是一款优秀的开源 KV 存储方案，与 Memcached 仅支持简单的 KV 类型和操作不同，Redis 支持很多不同的数据结构，例如列表、集合、散列等，还支持不少复杂的操作，因此 Redis 在实践中得到了广泛的应用。本节我们就来了解一下如何在 Spring 工程中方便地使用 Redis。</p>\n\n\n<h3 id=\"nav_point_125\">8.2.1　配置 Redis 连接</h3>\n<p>要使用 Redis，自然少不了 Java 的 Redis 客户端。表 8-4 中展示了目前比较主流的三个 Redis 客户端，这三个也是 Redis 官方推荐的。</p>\n<p><strong>表 8-4　主流的 Redis 客户端</strong></p>\n<table width=\"90%\" border=\"1\">\n<thead>\n<tr>\n<th><p>&nbsp;</p></th>\n<th><p>IO 方式</p></th>\n<th><p>线程安全</p></th>\n<th><p>API</p></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><p>Jedis</p></td>\n<td><p>阻塞</p></td>\n<td><p>否</p></td>\n<td><p>较底层，与 Redis 命令对应</p></td>\n</tr>\n<tr>\n<td><p>Lettuce</p></td>\n<td><p>非阻塞</p></td>\n<td><p>是</p></td>\n<td><p>有较高抽象</p></td>\n</tr>\n<tr>\n<td><p>Redission</p></td>\n<td><p>非阻塞</p></td>\n<td><p>是</p></td>\n<td><p>有较高抽象</p></td>\n</tr>\n</tbody>\n</table>\n<p>在项目中，我们可以直接使用 Redis 客户端来进行操作，只需将其配置为容器中的 Bean，然后注入需要使用它的对象中即可。以 Jedis 为例，在 Spring 容器中配置好 <code>JedisPool</code> Bean，将它注入需要的 Bean 中，操作时从 <code>JedisPool</code> 里取出一个 <code>Jedis</code> 实例就可以了。如果只有这种方式，那我们也不用在这里讨论了。和之前的 ORM 框架一样，Spring 为我们提供了一套对应的抽象——Spring Data Redis，它屏蔽了不同客户端之间的差异，让我们能用相似的方式来配置并操作 Redis。</p>\n<p>Spring Data Redis 支持 Redis 2.6 及以上版本，在客户端方面，支持 Jedis 和 Lettuce，后者是默认客户端。工程的 pom.xml 会通过如下方式引入相关依赖，具体的版本由 Spring Boot 来控制，它会传递引入 <code>spring-data-redis</code> 和 <code>lettuce-core</code> 这两个依赖：</p>\n<pre class=\"code-rows\"><code>&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;\n&lt;/dependency&gt;</code></pre>\n<ol>\n<li><p><strong>Spring Data Redis 的模型抽象</strong></p>\n<p>Spring Data Redis 通过几层抽象来为开发者提供统一的使用体验，屏蔽底层差异，下面列出的这些接口还有一些扩展，就不在此一一列举了。</p>\n<ul>\n<li><code>RedisCommands</code>，针对命令的抽象。</li>\n<li><code>RedisConnection</code>，针对连接的抽象。</li>\n<li><code>RedisConnectionFactory</code>，针对连接创建工厂的抽象。</li>\n</ul>\n<p>从 <code>RedisConnectionFactory</code> 这个名字就能看出，此处使用了工厂模式来构造 Redis 连接，该接口有两个实现类——<code>LettuceConnectionFactory</code> 和 <code>JedisConnectionFactory</code>，分别对应了 Lettuce 和 Jedis 两个不同的客户端。<code>RedisCommands</code> 和 <code>RedisConnection</code> 的情况也是类似的，最终都会提供针对这两种客户端的实现。</p>\n<p>既然 Lettuce 是默认的客户端，那就让我们先来看看它的配置。Spring Boot 在 spring-boot-autoconfigure 中提供了 Redis 相关的自动配置，Lettuce 的配置类是 <code>LettuceConnectionConfiguration</code>，如果 CLASSPATH 中存在 Lettuce 的 <code>RedisClient</code>，则说明用的是 Lettuce 客户端，否则该配置不生效。这个配置类最终会创建两个 Bean，一个是提供构建客户端所需配置及资源的 <code>lettuceClientResources</code>，另一个就是对应 Lettuce 的 <code>redisConnectionFactory</code>：</p>\n<pre class=\"code-rows\"><code>@Configuration(proxyBeanMethods = false)\n@ConditionalOnClass(RedisClient.class)\nclass LettuceConnectionConfiguration extends RedisConnectionConfiguration {\n    @Bean(destroyMethod = \"shutdown\")\n    @ConditionalOnMissingBean(ClientResources.class)\n    DefaultClientResources lettuceClientResources() {...}\n\n    @Bean\n    @ConditionalOnMissingBean(RedisConnectionFactory.class)\n    LettuceConnectionFactory redisConnectionFactory(\n            ObjectProvider&lt;LettuceClientConfigurationBuilderCustomizer&gt; builderCustomizers,\n            ClientResources clientResources)\n        throws UnknownHostException {...}\n\n    // 省略其他方法\n}</code></pre>\n<p><code>LettuceClientConfigurationBuilderCustomizer</code> 是用来定制 <code>LettuceClientConfigurationBuilder</code> 的，我们可以调整其中的一些属性，例如，让 Lettuce 优先读取从节点的数据。</p>\n<p>根据配置的不同，自动配置可以为单机模式、哨兵模式和集群模式的 Redis 创建合适的 <code>RedisConnectionFactory</code>，具体的配置由 <code>RedisProperties</code> 类实现，配置的前缀为 <code>spring.redis</code>。主要的配置项如表 8-5 所示。</p>\n<p><strong>表 8-5　Spring Data Redis 的主要配置项</strong></p>\n<table class=\"table table-bordered table-striped table-condensed\" width=\"90%\" border=\"1\"><tr><th>配置项</th><th>默认值</th><th>说明</th></tr><tr><td><code>spring.redis.host</code></td><td><code>localhost</code></td><td>Redis 服务器主机名</td></tr><tr><td><code>spring.redis.port</code></td><td><code>6379</code></td><td>Redis 服务器端口</td></tr><tr><td><code>spring.redis.password</code></td><td></td><td>Redis 服务器密码</td></tr><tr><td><code>spring.redis.timeout</code></td><td><code>60s</code></td><td>连接超时时间</td></tr><tr><td><code>spring.redis.sentinel.master</code></td><td></td><td>Redis 服务器名称</td></tr><tr><td><code>spring.redis.sentinel.nodes</code></td><td></td><td>哨兵节点列表，节点用“<code>主机名 : 端口</code>”表示，主机之间用逗号分割</td></tr><tr><td><code>spring.redis.sentinel.password</code></td><td></td><td>哨兵节点密码</td></tr><tr><td><code>spring.redis.cluster.nodes</code></td><td></td><td>集群节点列表，节点可以自发现，但至少要配置一个节点</td></tr><tr><td><code>spring.redis.cluster.maxRedirects</code></td><td><code>5</code></td><td>在集群中执行命令时的最大重定向次数</td></tr><tr><td><code>spring.redis.jedis.pool.\\*</code></td><td></td><td>Jedis 连接池配置</td></tr><tr><td><code>spring.redis.lettuce.\\*</code></td><td></td><td>Lettuce 特定的配置</td></tr></table>\n\n<blockquote>\n<p><strong>茶歇时间：Redis 的几种部署模式</strong></p>\n<p>单机版本的 Redis 仅能用于开发和测试，在生产环境中还是需要做很多高可用的保障的。Redis 官方为我们提供了两种高可用方案—哨兵模式（redis sentinel）和集群模式（redis cluster）。</p>\n<p><strong>哨兵模式</strong>，即在原有的 Redis 主从节点之外，再搭建一组哨兵节点，通过哨兵来实现对 Redis 节点的监控，在发生问题时进行通知并自动执行故障迁移。新版本的哨兵模式中客户端也可以通过哨兵来获取当前的主节点。出于可用性方面的考虑，搭建高可用的哨兵模式至少需要三个节点，具体如图 8-1 所示。</p>\n<p class=\"p-img\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100008/image00767.jpeg\" alt=\"{%}\" /></p>\n<p class=\"ebook-image-title\"><strong>图 8-1　Redis 哨兵模式</strong></p>\n<p><strong>集群模式</strong>，比哨兵模式更为强大。在哨兵模式中，Redis 数据过大后需要由开发者来负责数据分片，而集群模式则会自动进行分片。通过建立 16 384 个虚拟槽，每个槽映射一部分分片范围，再将这些槽分布到节点上就实现了数据分片。集群模式下，所有节点之间都会相互通信，连上一个节点就能找到整个集群。为了保证高可用性，其中也加入了主从模式，某个主节点出问题后，集群会把对应的从节点提升为主节点。一种可能的 Redis 集群模式如图 8-2 所示。</p>\n<p class=\"p-img\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100008/image00768.jpeg\" alt=\"{%}\" /></p>\n<p class=\"ebook-image-title\"><strong>图 8-2　Redis 集群模式</strong></p>\n<p>如果集群节点的数量发生变化，那么槽也会进行迁移，这时原先缓存在客户端的槽分布信息就有可能不准确，收到命令的节点会让客户端重定向到正确的节点，这就是<strong>不建议把最大重定向次数设置为</strong> 0 的原因。</p>\n<p>为了最大化地利用集群资源，我们可以将部分读请求发送给从节点。Jedis 对 Redis 集群的读写分离支持得很不好，建议有这方面需求的开发者可以使用 Lettuce。在 Spring Data Redis 里可以配置一个 <code>LettuceClientConfigurationBuilderCustomizer</code>，设置优先通过从节点读取数据：</p>\n<pre class=\"code-rows\"><code>@Bean\npublic LettuceClientConfigurationBuilderCustomizer customizer() {\n    return builder -&gt; builder.readFrom(ReadFrom.SLAVE_PREFERRED);\n}</code></pre>\n<p>另外，因为 Redis 用的是异步复制，所以如果有数据写到主节点，但还来不及同步到从节点上，这时主节点的故障就会导致部分数据丢失。如果数据非常重要，不能丢失，那建议还是不要仅存放在 Redis 里，至少应该再备一份到其他存储上。</p>\n</blockquote>\n<p>&nbsp;</p>\n</li>\n<li><p><strong>将 Lettuce 替换为 Jedis</strong></p>\n<p>如果希望使用 Jedis 而非 Lettuce，只需简单调整 pom.xml 文件中的依赖，就能完成替换。比如像下面这样，先排除 spring-boot-starter-data-redis 里的 Lettuce 依赖，随后添加 Jedis 的依赖，所有的版本都交由 Spring Boot 的依赖负责管理：</p>\n<pre class=\"code-rows\"><code>&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;\n    &lt;exclusions&gt;\n        &lt;exclusion&gt;\n            &lt;groupId&gt;io.lettuce&lt;/groupId&gt;\n            &lt;artifactId&gt;lettuce-core&lt;/artifactId&gt;\n        &lt;/exclusion&gt;\n    &lt;/exclusions&gt;\n&lt;/dependency&gt;\n\n&lt;dependency&gt;\n    &lt;groupId&gt;redis.clients&lt;/groupId&gt;\n    &lt;artifactId&gt;jedis&lt;/artifactId&gt;\n&lt;/dependency&gt;</code></pre>\n<p>Jedis 的自动配置是由 <code>JedisConnectionConfiguration</code> 实现的，它的生效条件是 CLASSPATH 中同时存在 Apache 的 Commons Pool2、Spring Boot Data Redis 和 Jedis 相关类（Commons Pool2 是由 Jedis 传递依赖进来的）。这个自动配置类会根据情况注册一个 <code>redisConnectionFactory</code> Bean：</p>\n<pre class=\"code-rows\"><code>@Configuration(proxyBeanMethods = false)\n@ConditionalOnClass({ GenericObjectPool.class, JedisConnection.class, Jedis.class })\nclass JedisConnectionConfiguration extends RedisConnectionConfiguration {\n    @Bean\n    @ConditionalOnMissingBean(RedisConnectionFactory.class)\n    JedisConnectionFactory redisConnectionFactory(ObjectProvider&lt;JedisClientConfigurationBuilderCustomizer&gt;\nbuilderCustomizers) throws UnknownHostException {...}\n    // 省略其他方法\n}</code></pre>\n<p>通过这个自动配置类，后续我们就能使用 Jedis 作为底层客户端来进行操作了。其中 <code>JedisClientConfigurationBuilderCustomizer</code> 的作用与之前提到的 <code>LettuceClientConfigurationBuilderCustomizer</code> 类似。</p>\n</li>\n</ol>\n<h3 id=\"nav_point_126\">8.2.2　Redis 的基本操作</h3>\n<p>前面在介绍数据库操作时，我们接触到了 <code>TransactionTemplate</code>、<code>JdbcTemplate</code> 等模板类，Spring 把各类可以固化的代码都封装成了模板。其实，Redis 的操作也很符合这个特征，并且 Redis 的操作“界面”也很符合模板模式，常用操作都被封装进了 <code>RedisTemplate</code> 类中，直接操作这个类就能完成 Redis 的操作了。</p>\n<p>Spring Boot 的 <code>RedisAutoConfiguration</code> 为我们自动配置好了两个 <code>RedisTemplate</code>，其中有一个专门用于字符串类型的 Redis 操作。而创建这些 <code>RedisTemplate</code> 所需的 <code>RedisConnectionFactory</code>，就是由上文提到的部分所提供的：</p>\n<pre class=\"code-rows\"><code>@Configuration(proxyBeanMethods = false)\n@ConditionalOnClass(RedisOperations.class)\n@EnableConfigurationProperties(RedisProperties.class)\n@Import({ LettuceConnectionConfiguration.class, JedisConnectionConfiguration.class })\npublic class RedisAutoConfiguration {\n    @Bean\n    @ConditionalOnMissingBean(name = \"redisTemplate\")\n    public RedisTemplate&lt;Object, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory)\n            throws UnknownHostException {\n        RedisTemplate&lt;Object, Object&gt; template = new RedisTemplate&lt;&gt;();\n        template.setConnectionFactory(redisConnectionFactory);\n        return template;\n    }\n\n    @Bean\n    @ConditionalOnMissingBean\n    public StringRedisTemplate stringRedisTemplate(RedisConnectionFactory redisConnectionFactory)\n            throws UnknownHostException {\n        StringRedisTemplate template = new StringRedisTemplate();\n        template.setConnectionFactory(redisConnectionFactory);\n        return template;\n    }\n}</code></pre>\n<p>其中，<code>RedisConnection</code> 提供了与 Redis 交互的底层能力，<code>RedisTemplate</code> 则在前者的基础上提供了序列化与连接管理能力。根据数据结构的不同，具体的操作上也做了一定的抽象，详情如表 8-6 所示。</p>\n<p><strong>表 8-6　<code>RedisTemplate</code> 中封装的操作类型</strong></p>\n<table width=\"90%\" border=\"1\">\n<thead>\n<tr>\n<th><p>操作</p></th>\n<th><p>绑定键名操作</p></th>\n<th><p>描述</p></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><p><code>ClusterOperations</code></p></td>\n<td><p>无</p></td>\n<td><p>Redis 集群的相关操作</p></td>\n</tr>\n<tr>\n<td><p><code>GeoOperations</code></p></td>\n<td><p><code>BoundGeoOperations</code></p></td>\n<td><p>Redis 地理位置的相关操作</p></td>\n</tr>\n<tr>\n<td><p><code>HashOperations</code></p></td>\n<td><p><code>BoundHashOperations</code></p></td>\n<td><p>Redis Hash 类型的相关操作</p></td>\n</tr>\n<tr>\n<td><p><code>HyperLogLogOperations</code></p></td>\n<td><p>无</p></td>\n<td><p>Redis HyperLogLog 类型 <span class=\"comment-number\">10</span> 的相关操作</p></td>\n</tr>\n<tr>\n<td><p><code>ListOperations</code></p></td>\n<td><p><code>BoundListOperations</code></p></td>\n<td><p>Redis 列表类型的相关操作</p></td>\n</tr>\n<tr>\n<td><p><code>SetOperations</code></p></td>\n<td><p><code>BoundSetOperations</code></p></td>\n<td><p>Redis 集合类型的相关操作</p></td>\n</tr>\n<tr>\n<td><p><code>StreamOperations</code></p></td>\n<td><p><code>BoundStreamOperations</code></p></td>\n<td><p>Redis 流 <span class=\"comment-number\">11</span> 的相关操作</p></td>\n</tr>\n<tr>\n<td><p><code>ValueOperations</code></p></td>\n<td><p><code>BoundValueOperations</code></p></td>\n<td><p>Redis 值类型的相关操作</p></td>\n</tr>\n<tr>\n<td><p><code>ZSetOperations</code></p></td>\n<td><p><code>BoundZSetOperations</code></p></td>\n<td><p>Redis 有序结合类型的相关操作</p></td>\n</tr>\n</tbody>\n</table>\n\n\n<p>当我们要进行某种数据结构的操作时，调用 <code>RedisTemplate</code> 的 <code>opsForXxx()</code> 方法获得对应的操作对象，然后就能进行操作了。例如，要对 <code>foo</code> 集合做操作，可以调用 <code>opsForSet()</code> 方法，随后就能使用其中的 <code>add()</code>、<code>remove()</code> 和 <code>pop()</code> 等方法了。如果要对同一个键名的数据做多次操作，则可以使用 <code>boundXxxOps()</code> 来获取 <code>BoundKeyOperations</code> 对象，再执行后续操作。</p>\n<p>此外，<code>RedisTemplate</code> 中还直接提供了一些操作，大多是用于那些和数据结构无关的情况，例如删除、设置过期时间和判断数据是否存在等，这些操作会直接调用 <code>delete()</code>、<code>expire()</code> 和 <code>hasKey()</code> 方法，无须再获取操作对象了。</p>\n<p>回到二进制奶茶店的例子，我们来看看 Redis 作为一种缓存是如何在工程中发挥作用的。</p>\n<blockquote>\n<p><strong>需求描述</strong>　奶茶店里的菜单虽然会有更新，但频率不高，通常一个月甚至一个季度才会根据情况对品类和价格做些调整。如果进店的顾客比较多，大家一起查看菜单，对菜单的请求量就会直线上升，类似情况下数据库迟早会成为瓶颈，这时，我们就需要引入新的解决方案了。</p>\n</blockquote>\n<p>通常对于那些不太会变的东西，我们不会每次访问都去查询数据库，而是将它们缓存起来，从而实现在提升性能的同时降低数据库的压力。在这个例子 <span class=\"comment-number\">12</span> 中，我们完全可以将整个菜单缓存到 Redis 里。</p>\n\n<p>第一步，让我们使用 Docker 在本地启动一个 Redis<span class=\"comment-number\">13</span>，监听 <code>6379</code> 端口，后续就会将该 Redis 作为缓存：</p>\n\n<pre class=\"code-rows\"><code>▸ docker pull redis\n▸ docker run --name redis -d -p 6379:6379 redis</code></pre>\n<p>第二步，修改 <code>MenuItem</code> 的代码，因为 <code>RedisTemplate</code> 会将该对象序列化后存储到 Redis 里，所以它<strong>必须实现 <code>Serializable</code> 接口</strong>：</p>\n<pre class=\"code-rows\"><code>public class MenuItem implements Serializable {\n    private static final long serialVersionUID = 8585684450527309518L;\n    // 其他代码省略\n}</code></pre>\n<p>第三步，在启动时增加一个“加载菜单并存储到 Redis”的动作，这里我们同样使用 <code>ApplicationRunner</code>，具体如代码示例 8-2 所示。它从数据库中获得所有的菜单项，再将其序列化存入 Redis 的集合中，并将过期时间设置为 300 秒。这里演示了 <code>opsForList()</code> 和 <code>expire()</code> 的用法。</p>\n<blockquote>\n<p><strong>代码示例 8-2</strong>　<code>MenuCacheRunner</code> 代码片段</p>\n</blockquote>\n<pre class=\"code-rows\"><code>@Component\n@Slf4j\n@Order(1)\npublic class MenuCacheRunner implements ApplicationRunner {\n    @Autowired\n    private RedisTemplate redisTemplate;\n    @Autowired\n    private MenuRepository menuRepository;\n\n    @Override\n    public void run(ApplicationArguments args) throws Exception {\n        List&lt;MenuItem&gt; itemList = menuRepository.findAll();\n        log.info(\"Load {} MenuItems from DB, ready to cache.\", itemList.size());\n        redisTemplate.opsForList().leftPushAll(\"binarytea-menu\", itemList);\n        redisTemplate.expire(\"binarytea-menu\", 300, TimeUnit.SECONDS);\n    }\n}</code></pre>\n<p>第四步，修改之前的 <code>MenuPrinterRunner</code>。原本它只能从数据库中取得信息并输出，而新的版本会优先从 Redis 中获取数据，如果没有的话再从数据库加载。具体如代码示例 8-3 所示。为了保证 <code>MenuCacheRunner</code> 在 <code>MenuPrinterRunner</code> 之前运行，两个类上都增加了 <code>@Order</code> 注解，并配置了执行顺序。</p>\n<blockquote>\n<p><strong>代码示例 8-3</strong>　修改后的 <code>MenuPrinterRunner</code> 代码片段</p>\n</blockquote>\n<pre class=\"code-rows\"><code>@Component\n@Slf4j\n@Order(2)\npublic class MenuPrinterRunner implements ApplicationRunner {\n    @Autowired\n    private MenuRepository menuRepository;\n    @Autowired\n    private RedisTemplate redisTemplate;\n\n    @Override\n    public void run(ApplicationArguments args) throws Exception {\n        long size = 0;\n        List&lt;MenuItem&gt; menuItemList = null;\n        if (redisTemplate.hasKey(\"binarytea-menu\")) {\n            BoundListOperations&lt;String, MenuItem&gt; operations = redisTemplate.boundListOps(\"binarytea-menu\");\n            size = operations.size();\n            menuItemList = operations.range(0, -1);\n            log.info(\"Loading menu from Redis.\");\n        } else {\n            size = menuRepository.count();\n            menuItemList = menuRepository.findAll();\n            log.info(\"Loading menu from DB.\");\n        }\n        log.info(\"共有{}个饮品可选。\", size);\n        menuItemList.forEach(i -&gt; log.info(\"饮品：{}\", i));\n    }\n}</code></pre>\n<p>Spring Boot 的自动配置默认就会连接 <code>localhost:6379</code> 的 Redis，因此我们无须在 <code>application.properties</code> 中做额外配置。如果不是用这个地址，也可以自己设置，例如：</p>\n<pre class=\"code-rows\"><code>spring.redis.host=127.0.0.1\nspring.redis.port=6379</code></pre>\n<p>程序执行的输出大致会是这样的：</p>\n<pre class=\"code-rows\"><code>2022-02-26 22:11:31.498 INFO 97964 --- [main] l.s.binarytea.runner.MenuCacheRunner : Load 2 MenuItems\nfrom DB, ready to cache.\n2022-02-26 22:11:31.701 INFO 97964 --- [main] l.s.binarytea.runner.MenuPrinterRunner : Loading menu\nfrom Redis.\n2022-02-26 22:11:31.701 INFO 97964 --- [main] l.s.binarytea.runner.MenuPrinterRunner : 共有2个饮品可选。\n2022-02-26 22:11:31.701 INFO 97964 --- [main] l.s.binarytea.runner.MenuPrinterRunner : 饮品：\nMenuItem(id=2, name=Java咖啡, size=LARGE, price=CNY 15.00, createTime=2022-02-26 22:11:30.570549,\nupdateTime=2022-02-26 22:11:30.570549)\n2022-02-26 22:11:31.705 INFO 97964 --- [main] l.s.binarytea.runner.MenuPrinterRunner : 饮品：\nMenuItem(id=1, name=Java咖啡, size=MEDIUM, price=CNY 12.00, createTime=2022-02-26 22:11:30.567212,\nupdateTime=2022-02-26 22:11:30.567212)</code></pre>\n<p>如果这时用客户端连上 Redis，查看我们保存进去的数据，会看到下面这样的一大串内容。如果不做特殊配置，Spring Data Redis 默认会使用 JDK 自带的序列化机制进行序列化和反序列化。如果有不同语言的系统共用这些缓存数据，那会在很大程度上影响缓存的使用，所以可以考虑改用 JSON 来进行序列化：</p>\n<pre class=\"code-rows\"><code>\\xac\\xed\\x00\\x05sr\\x00(learning.spring.binarytea.model.MenuItemw&amp;z\\x84\\xd3Fn\\xce\\x02\\x00\\x06L\\x00\\\nncreateTimet\\x00\\x10L......</code></pre>\n<p><code>RedisTemplate</code> 默认使用 <code>JdkSerializationRedisSerializer</code>，如果要改变这个方式，就要自己来创建 <code>RedisTemplate</code>，调整序列化方式。Spring Data Redis 内置了几种实现了 <code>RedisSerializer</code> 接口的序列化器，具体如表 8-7 所示，其中两个 JSON 的序列化器都是基于 Jackson2 来实现的。</p>\n<p><strong>表 8-7　Spring Data Redis 内置的序列化器</strong></p>\n<table width=\"90%\" border=\"1\">\n<thead>\n<tr>\n<th><p>序列化器</p></th>\n<th><p>快捷方式</p></th>\n<th><p>说明</p></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><p><code>JdkSerializationRedisSerializer</code></p></td>\n<td><p><code>RedisSerializer.java()</code></p></td>\n<td><p>使用 JDK 的序列化方式</p></td>\n</tr>\n<tr>\n<td><p><code>ByteArrayRedisSerializer</code></p></td>\n<td><p><code>RedisSerializer.byteArray()</code></p></td>\n<td><p>直接透传 <code>byte[]</code>，不做任何处理</p></td>\n</tr>\n<tr>\n<td><p><code>StringRedisSerializer</code></p></td>\n<td><p><code>RedisSerializer.string()</code></p></td>\n<td><p>根据字符集将字符串序列化为字节</p></td>\n</tr>\n<tr>\n<td><p><code>GenericToStringSerializer&lt;T&gt;</code></p></td>\n<td><p>&nbsp;</p></td>\n<td><p>依赖 Spring 的 <code>ConversionService</code> 来序列化字符串</p></td>\n</tr>\n<tr>\n<td><p><code>GenericJackson2JsonRedisSerializer</code></p></td>\n<td><p><code>RedisSerializer.json()</code></p></td>\n<td><p>按照 <code>Object</code> 来序列化对象</p></td>\n</tr>\n<tr>\n<td><p><code>Jackson2JsonRedisSerializer&lt;T&gt;</code></p></td>\n<td><p>&nbsp;</p></td>\n<td><p>根据给定的泛型类型序列化对象</p></td>\n</tr>\n<tr>\n<td><p><code>OxmSerializer</code></p></td>\n<td><p>&nbsp;</p></td>\n<td><p>依赖 Spring 的 OXM（Object/XML Mapper，O/M 映射器）来序列化对象</p></td>\n</tr>\n</tbody>\n</table>\n<p>假设我们针对键和值使用不同的序列化方式，可以像下面这段代码一样来配置自己的 <code>RedisTemplate</code>：</p>\n<pre class=\"code-rows\"><code>@Bean\npublic RedisTemplate redisTemplate(RedisConnectionFactory connectionFactory) {\n    RedisTemplate redisTemplate = new RedisTemplate();\n    redisTemplate.setConnectionFactory(connectionFactory);\n    redisTemplate.setKeySerializer(RedisSerializer.string());\n    redisTemplate.setValueSerializer(RedisSerializer.json());\n    return redisTemplate;\n}</code></pre>\n<p>但往往只这么做是不够的，因为总有些 Jackson2 的 <code>ObjectMapper</code> 无法直接序列化的类型，比如 <code>Money</code> 类型就需要做些特别的处理。Jackson2 提供了标准的序列化和反序列化接口，我们只需实现这些接口就能实现特定类型的转换，而在 Spring Boot 提供的 <code>@JsonComponent</code> 注解的支持下，带了这个注解的类会直接被注册为 Bean，并注入 Spring Boot 维护的 <code>ObjectMapper</code> 中，省去了我们自己配置的麻烦。</p>\n<p>其实，在整个序列化和反序列化的过程中，最重要的就是有一个合适的 <code>ObjectMapper</code>，如果我们希望把控其中的细节，还可以注册自己的 <code>Jackson2ObjectMapperBuilderCustomizer</code>，通过它来进行个性化配置。代码示例 8-4 提供了一套简单的处理 <code>Money</code> 类型的代码。<span class=\"comment-number\">14</span></p>\n\n<blockquote>\n<p><strong>代码示例 8-4</strong>　简单的 <code>Money</code> 类型处理代码</p>\n</blockquote>\n<pre class=\"code-rows\"><code>@JsonComponent\npublic class MoneySerializer extends StdSerializer&lt;Money&gt; {\n    protected MoneySerializer() {\n        super(Money.class);\n    }\n\n    @Override\n    public void serialize(Money money, JsonGenerator jsonGenerator,\n                          SerializerProvider serializerProvider) throws IOException {\n        jsonGenerator.writeNumber(money.getAmount());\n    }\n}\n\n@JsonComponent\npublic class MoneyDeserializer extends StdDeserializer&lt;Money&gt; {\n    protected MoneyDeserializer() {\n        super(Money.class);\n    }\n\n    @Override\n    public Money deserialize(JsonParser jsonParser,\n                          DeserializationContext deserializationContext)\n            throws IOException, JsonProcessingException {\n        return Money.of(CurrencyUnit.of(\"CNY\"), jsonParser.getDecimalValue());\n    }\n}</code></pre>\n<p>实际上，考虑到 Joda Money 的使用很广泛，Jackson JSON 官方提供了一个针对 <code>Money</code> 类的序列化类型，无须我们自己来实现序列化与反序列化器，只需添加如下依赖就能引入 jackson-datatype-joda-money：<span class=\"comment-number\">15</span></p>\n\n<pre class=\"code-rows\"><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.fasterxml.jackson.datatype&lt;/groupId&gt;\n    &lt;artifactId&gt;jackson-datatype-joda-money&lt;/artifactId&gt;\n    &lt;version&gt;2.13.1&lt;/version&gt;\n&lt;/dependency&gt;</code></pre>\n<p>随后在 Spring 配置类中注册这个 JSON 模块，让 Spring Boot 在自动配置 <code>ObjectMapper</code> 时自动注册它，也可以手动在自己的 <code>ObjectMapper</code> 中注册这个模块：</p>\n<pre class=\"code-rows\"><code>@Bean\npublic JodaMoneyModule jodaMoneyModule() {\n    return new JodaMoneyModule();\n}</code></pre>\n<p>接下来，再调整一下 <code>redisTemplate()</code>，指定我们要处理的泛型类型，让它专门来处理键为 <code>String</code> 值为 <code>MenuItem</code> 的类型，序列化与反序列化都是用 Spring Boot 自动配置的 <code>ObjectMapper</code>。具体如代码示例 8-5 所示。</p>\n<blockquote>\n<p><strong>代码示例 8-5</strong>　为 <code>MenuItem</code> 提供个性化的 <code>RedisTempalte</code></p>\n</blockquote>\n<pre class=\"code-rows\"><code>@Bean\npublic RedisTemplate&lt;String, MenuItem&gt; redisTemplate(RedisConnectionFactory connectionFactory,\n                                                     ObjectMapper objectMapper) {\n    Jackson2JsonRedisSerializer&lt;MenuItem&gt; serializer = new Jackson2JsonRedisSerializer&lt;&gt;(MenuItem.class);\n    serializer.setObjectMapper(objectMapper);\n\n    RedisTemplate&lt;String, MenuItem&gt; redisTemplate = new RedisTemplate&lt;&gt;();\n    redisTemplate.setConnectionFactory(connectionFactory);\n    redisTemplate.setKeySerializer(RedisSerializer.string());\n    redisTemplate.setValueSerializer(serializer);\n    return redisTemplate;\n}</code></pre>\n<p>程序执行后，再到 Redis 里用 <code>LRANGE \"binarytea-menu\" 0 0</code> 查看数据，看到的 JSON 输出大概是类似下面这样的：</p>\n<pre class=\"code-rows\"><code>{\\\"id\\\":2,\\\"name\\\":\\\"Java\\xe5\\x92\\x96\\xe5\\x95\\xa1\\\",\\\"size\\\":\\\"LARGE\\\",\\\"price\\\":15.00,\\\"createTime\\\":\n\\\"2020-10-15T16:59:26.037+00:00\\\",\\\"updateTime\\\":\\\"2020-10-15T16:59:26.037+00:00\\\"}</code></pre>\n<blockquote>\n<p><strong>茶歇时间：本地缓存 vs. 分布式缓存</strong></p>\n<p>读多写少的情况下就可以用缓存，比如读写比为 10:1 的情况就很合适。本节聊到的 Redis 很适合做缓存，这其实是把 Redis 集群当做分布式缓存集群在用。一个应用集群访问同一个缓存，一般不会出现缓存数据不一致的情况（如果要较真一些，还是有概率会出现数据不一致的情况，例如 Redis 主从同步有延时，从不同节点读取数据时就可能会有问题）。但分布式缓存也是有代价的，例如，网络交互的开销和序列化的开销，如果缓存的对象很大，或者访问量很高，也不排除会有打满带宽的情况。总之，没有哪种方案是包治百病还零成本的。</p>\n<p>与其相对应的是本地缓存，即将数据缓存在应用本地。以 Java 应用为例，可以将数据缓存在 JVM 的堆内存里。这样做的好处是可以不用经过网络，无须序列化，直接就能获取需要的数据。但这样做的弊端也很明显，假设应用集群有 10 台服务器，每台服务器的缓存可能存在差异，何时更新缓存就是一门学问了。因此如果使用本地缓存，就必须考虑不同服务器缓存不一致的情况，要能够容忍这样的差异。</p>\n<p>不过，这两种方式并非水火不容，不妨考虑适当结合两者。例如，我们可以接受缓存数据在更新后 15 秒内的不一致，假设应用集群有 100 台服务器，如果每台机器都每隔 10 秒查询一下数据库，那么这个压力也不小。怎么解决呢？可以在本地做 10 秒的缓存，然后每隔 10 秒查询分布式缓存，并在更新数据库时将分布式缓存的值直接写到缓存里。</p>\n</blockquote>\n<h3 id=\"nav_point_127\">8.2.3　通过 <code>Repository</code> 操作 Redis</h3>\n<p>在介绍 JPA 时，Spring Data JPA 的 <code>Repository</code> 十分惊艳，让人印象深刻，只需定义接口和方法就能实现各种常用操作。其实，这并非 JPA 所独有的，Spring Data Redis 也有类似的机制，只要 Redis 服务器的版本在 2.8.0 以上，不用事务，就可以通过 <code>Repository</code> 实现各种常用操作了。</p>\n<ol>\n<li><p><strong>定义实体</strong></p>\n<p>既然是个仓库，就有对应要操作的领域对象，所以我们需要先定义这些对象。表 8-8 罗列了定义 Redis 领域对象时会用到的一些注解。</p>\n<p><strong>表 8-8　定义 Redis 领域对象常用的注解</strong></p>\n<table class=\"table table-bordered table-striped table-condensed\" width=\"90%\" border=\"1\"><tr><th>注解</th><th>说明</th></tr><tr><td><code>@RedisHash</code></td><td>与 <code>@Entity</code> 类似，用来定义 Redis 的 <code>Repository</code> 操作的领域对象，其中的 <code>value</code> 定义了不同类型对象存储时使用的前缀，也叫做键空间（keyspace），默认是全限定类名，<code>timeToLive</code> 用来定义缓存的秒数</td></tr><tr><td><code>@Id</code></td><td>定义对象的标识符</td></tr><tr><td><code>@Indexed</code></td><td>定义二级索引，加在属性上可以将该属性定义为查询用的索引</td></tr><tr><td><code>@Reference</code></td><td>缓存对象引用，一般引用的对象也会被展开存储在当前对象中，添加了该注解后会直接存储该对象在 Redis 中的引用</td></tr></table>\n\n<p>假设我们希望通过 <code>Repository</code> 来缓存菜单，可以像代码示例 8-6 那样定义一个用于 Redis 的菜单对象，其中我们指定了存储时的前缀是 <code>menu</code>，缓存 60 秒，<code>id</code> 为标识符，还有一个二级索引是 <code>name</code>。<span class=\"comment-number\">16</span></p>\n<blockquote>\n<p><strong>代码示例 8-6</strong>　用于 Redis 的 <code>RedisMenuItem</code> 类代码片段</p>\n</blockquote>\n<pre class=\"code-rows\"><code>@RedisHash(value = \"menu\", timeToLive = 60)\n@Getter\n@Setter\npublic class RedisMenuItem implements Serializable {\n    private static final long serialVersionUID = 4442333144469925590L;\n\n    @Id\n    private Long id;\n    @Indexed\n    private String name;\n    private Size size;\n    private Money price;\n}</code></pre>\n<p>这里有一个地方需要注意，如果不是用的 Java 序列化，而是 Jackson JSON，则无法自动处理 <code>Money</code> 类型，我们必须定义两个 <code>Converter</code> 处理 <code>Money</code> 与 <code>byte[]</code> 的互相转换。就像代码示例 8-7 那样，通过上下文里的 <code>ObjectMapper</code> 和 <code>Jackson2JsonRedisSerializer</code> 来进行序列化与反序列化，<code>@ReadingConverter</code> 标注的 <code>BytesToMoneyConverter</code> 负责在读取时将字节转换为 <code>Money</code>，写进 Redis 时则使用 <code>@WritingConverter</code> 标注的 <code>MoneyToBytesConverter</code>。</p>\n<blockquote>\n<p><strong>代码示例 8-7</strong>　用于处理 <code>Money</code> 类型的 <code>Converter</code> 代码片段</p>\n</blockquote>\n<pre class=\"code-rows\"><code>@ReadingConverter\npublic class BytesToMoneyConverter implements Converter&lt;byte[], Money&gt; {\n    private Jackson2JsonRedisSerializer&lt;Money&gt; serializer;\n\n    public BytesToMoneyConverter(ObjectMapper objectMapper) {\n        serializer = new Jackson2JsonRedisSerializer&lt;Money&gt;(Money.class);\n        serializer.setObjectMapper(objectMapper);\n    }\n\n    @Override\n    public Money convert(byte[] source) {\n        return serializer.deserialize(source);\n    }\n}\n\n@WritingConverter\npublic class MoneyToBytesConverter implements Converter&lt;Money, byte[]&gt;{\n    private Jackson2JsonRedisSerializer&lt;Money&gt; serializer;\n\n    public MoneyToBytesConverter(ObjectMapper objectMapper) {\n        serializer = new Jackson2JsonRedisSerializer&lt;Money&gt;(Money.class);\n        serializer.setObjectMapper(objectMapper);\n    }\n\n    @Override\n    public byte[] convert(Money source) {\n        return serializer.serialize(source);\n    }\n}</code></pre>\n<p>这两个类需要做个简单的注册，即需要在上下文中配置一个 <code>RedisCustomConversions</code>，将它们添加进去，如代码示例 8-8 所示。</p>\n<blockquote>\n<p><strong>代码示例 8-8</strong>　配置 <code>RedisCustomConversions</code> Bean</p>\n</blockquote>\n<pre class=\"code-rows\"><code>@Bean\npublic RedisCustomConversions redisCustomConversions(ObjectMapper objectMapper) {\n    return new RedisCustomConversions( Arrays.asList(new MoneyToBytesConverter(objectMapper),\nnew BytesToMoneyConverter(objectMapper)));\n}</code></pre>\n<p>这时使用的 <code>RedisTemplate</code> 可以不用指定泛型类型，用 <code>GenericJackson2JsonRedisSerializer</code> 就够了。我们还是把键序列化成字符串，值序列化成 JSON，如代码示例 8-9 所示。</p>\n<blockquote>\n<p><strong>代码示例 8-9</strong>　定制 <code>RedisTemplate</code> Bean</p>\n</blockquote>\n<pre class=\"code-rows\"><code>@Bean\npublic RedisTemplate redisTemplate(RedisConnectionFactory connectionFactory,ObjectMapper objectMapper) {\n    GenericJackson2JsonRedisSerializer serializer = new GenericJackson2JsonRedisSerializer(objectMapper);\n    RedisTemplate redisTemplate = new RedisTemplate();\n    redisTemplate.setConnectionFactory(connectionFactory);\n    redisTemplate.setKeySerializer(RedisSerializer.string());\n    redisTemplate.setValueSerializer(serializer);\n    return redisTemplate;\n}</code></pre>\n<p>&nbsp;</p>\n</li>\n<li><p><strong>定义接口</strong></p>\n<p>用于 Redis 的 <code>Repository</code> 接口的定义与 JPA 的如出一辙，基本就是一个模子里刻出来的，继承一样的父接口，用一样的规则来定义接口，如果你不太记得的话，可以回顾一下 7.1.4 节。代码示例 8-10 定义了一个针对 <code>RedisMenuItem</code> 的 <code>Repository</code> 接口。</p>\n<blockquote>\n<p><strong>代码示例 8-10</strong>　针对 Redis 修改过的 <code>Repository</code> 接口定义</p>\n</blockquote>\n<pre class=\"code-rows\"><code>public interface RedisMenuRepository extends CrudRepository&lt;RedisMenuItem, Long&gt; {\n    List&lt;RedisMenuItem&gt; findByName(String name);\n}</code></pre>\n<p>要激活针对 Redis 的 <code>Repository</code> 接口支持，需要在配置类上添加 <code>@EnableRedisRepositories</code> 注解。与 JPA 一样，Spring Boot 的自动配置类 <code>RedisRepositoriesAutoConfiguration</code>（确切地说是它导入的 <code>RedisRepositoriesRegistrar</code>）已经自动添加了这个注解，只要满足条件，就不用我们自己动手了。</p>\n<p>接下来，我们来改造一下之前的 <code>MenuCacheRunner</code> 和 <code>MenuPrinterRunner</code>，从直接使用 <code>RedisTemplate</code> 改为使用 <code>RedisMenuRepository</code> 来操作 Redis。代码示例 8-11 是 <code>MenuCacheRunner</code> 类，它从 <code>MenuRepository</code> 中获取全部的菜单项，转换为 <code>RedisMenuItem</code> 后保存进 Redis。</p>\n<blockquote>\n<p><strong>代码示例 8-11</strong>　改造后的 <code>MenuCacheRunner</code> 类</p>\n</blockquote>\n<pre class=\"code-rows\"><code>@Component\n@Slf4j\n@Order(1)\npublic class MenuCacheRunner implements ApplicationRunner {\n    @Autowired\n    private MenuRepository menuRepository;\n    @Autowired\n    private RedisMenuRepository redisMenuRepository;\n\n    @Override\n    public void run(ApplicationArguments args) throws Exception {\n        List&lt;MenuItem&gt; itemList = menuRepository.findAll();\n        log.info(\"Load {} MenuItems from DB, ready to cache.\", itemList.size());\n\n        itemList.forEach(i -&gt; {\n            RedisMenuItem rmi = new RedisMenuItem();\n            BeanUtils.copyProperties(i, rmi);\n            redisMenuRepository.save(rmi);\n        });\n    }\n}</code></pre>\n<p>代码示例 8-12 是 <code>MenuPrinterRunner</code> 类：<code>redisMenuRepository</code> 中如果存储了内容，则 <code>count()</code> 会返回存储的对象数量，大于 <code>0</code> 就走缓存，否则就走数据库。</p>\n<blockquote>\n<p><strong>代码示例 8-12</strong>　改造后的 <code>MenuPrinterRunner</code> 类</p>\n</blockquote>\n<pre class=\"code-rows\"><code>@Component\n@Slf4j\n@Order(2)\npublic class MenuPrinterRunner implements ApplicationRunner {\n    @Autowired\n    private MenuRepository menuRepository;\n    @Autowired\n    private RedisMenuRepository redisMenuRepository;\n\n    @Override\n    public void run(ApplicationArguments args) throws Exception {\n        long size = 0;\n        Iterable&lt;?&gt; menuList;\n        if (redisMenuRepository.count() &gt; 0) {\n            log.info(\"Loading menu from Redis.\");\n            size = redisMenuRepository.count();\n            menuList = redisMenuRepository.findAll();\n            log.info(\"Java咖啡缓存了{}条\", redisMenuRepository.findByName(\"Java咖啡\").size());\n        } else {\n            log.info(\"Loading menu from DB.\");\n            size = menuRepository.count();\n            menuList = menuRepository.findAll();\n        }\n        log.info(\"共有{}个饮品可选。\", size);\n        menuList.forEach(i -&gt; log.info(\"饮品：{}\", i));\n    }\n}</code></pre>\n<p>程序运行后，在 Redis 里查询到的内容会是类似下面这样的：</p>\n<pre class=\"code-rows\"><code>▸ redis-cli\n127.0.0.1:6379&gt; keys *\n1) \"menu:1:phantom\"\n2) \"menu:2\"\n3) \"menu:1:idx\"\n4) \"menu:2:idx\"\n5) \"menu\"\n6) \"menu:2:phantom\"\n7) \"menu:1\"\n8) \"menu:name:Java\\xe5\\x92\\x96\\xe5\\x95\\xa1\"\n\n127.0.0.1:6379&gt; hgetall menu:1\n 1) \"_class\"\n 2) \"learning.spring.binarytea.model.RedisMenuItem\"\n 3) \"id\"\n 4) \"1\"\n 5) \"name\"\n 6) \"Java\\xe5\\x92\\x96\\xe5\\x95\\xa1\"\n 7) \"size\"\n 8) \"MEDIUM\"\n 9) \"price\"\n10) \"{\\\"amount\\\":12.00,\\\"currency\\\":\\\"CNY\\\"}\"\n127.0.0.1:6379&gt;</code></pre>\n<blockquote>\n<p><strong>茶歇时间：多种不同的 <code>Repository</code> 如何共存</strong></p>\n<p>不知道大家有没有这样的疑问：工程里同时存在 JPA 和 Redis 两种类型的 <code>Repository</code> 接口，Spring Data 怎么知道它们分别适用于什么类型的存储，又该如何实例化呢？</p>\n<p>Spring Data 中定义了如下一些规则，来帮助我们区分。</p>\n<p>(1) 领域对象上添加的注解。通过这条基本就已经可以充分区分了，JPA 的领域对象用 <code>@Entity</code>，Redis 的领域对象用 <code>@RedisHash</code>，还有 MongoDB 的领域对象用 <code>@Document</code>。</p>\n<p>(2) 接口继承的父接口。Spring Data 中有一些针对特定底层技术的接口，例如针对 JPA 的 <code>JpaRepository</code> 或者针对 MongoDB 的 <code>MongoRepository</code>。都用了这些接口了，那一定是适配这些技术的。</p>\n<p>(3) 包路径。<code>@EnableJpaRepositories</code> 和 <code>@EnableRedisRepositories</code> 注解里都有 <code>basePackage</code> 属性用于配置扫描的包路径，通过它可以明确地区分不同的接口。</p>\n<p>如果可以的话，建议使用第(1)条规则，因为它最为清晰明了。</p>\n</blockquote>\n</li>\n</ol>\n\n","neighbors":{"left":{"article_title":"第 7 章 对象关系映射(2)","id":740872},"right":{"article_title":"第 8 章 数据访问进阶(2)","id":740874}},"comments":[]}