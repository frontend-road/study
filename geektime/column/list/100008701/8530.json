{"id":8530,"title":"01 | 频率视角下的机器学习","content":"<p>在“人工智能基础课”中我曾提到，“概率”（probability）这个基本概念存在着两种解读方式，它们分别对应着<strong>概率的频率学派</strong>（Frequentist）和<strong>贝叶斯学派</strong>（Bayesian）。而解读方式上的差异也延伸到了以概率为基础的其他学科，尤其是机器学习之中。 </p>\n<p>根据机器学习领域的元老汤姆·米切尔（Tom M. Mitchell）的定义，机器学习（machine learning）是一门研究通过计算的手段利用经验来改善系统自身性能的学科。</p>\n<p>现如今，几乎所有的经验都以数据的形式出现，因而机器学习的任务也就变成了基于已知数据构造概率模型，反过来再运用概率模型对未知数据进行预测与分析。如此一来，关于概率的不同认识无疑会影响到对模型的构建与解释。</p>\n<p>可在概率的应用上，频率学派和贝叶斯学派的思路呈现出天壤之别，这种思维上的差异也让两派的拥护者势同水火，都视另一方为异端邪说。正因如此，在这个专栏的前两篇文章中，我将首先和你理清频率学派与贝叶斯学派对概率的不同观点，为接下来<strong>从不同的角度理解机器学习的各种算法</strong>打下扎实的基础。</p>\n<p>下面这个流传已久的笑话，不经意间对频率学派和贝叶斯学派的区别给出了形象的解释：有个病人找医生看病，医生检查之后对他说：“你这病说得上是九死一生，但多亏到我这里来看了。不瞒你说，在你之前我已经看了九个得一同样病的患者，结果他们都死了，那你这第十个就一定能看得好啦，妥妥的！”</p>\n<p>如果病人脑子没事，肯定就从这个糊涂医生那里跑了。显然，医生在看待概率时秉持的是频率主义的观点，但却是个蹩脚的频率主义者。之所以说他是频率主义者，是因为他对九死一生的理解就是十次手术九次失败一次成功；说他蹩脚则是因为他不懂频率学派的基础，区区九个病人就让他自以为掌握了生死的密码。</p>\n<p>归根到底，<strong>频率学派口中的概率表示的是事件发生频率的极限值</strong>，它只有在无限次的独立重复试验之下才有绝对的精确意义。在上面的例子中，如果非要从频率的角度解释“九死一生”的话，这个10%的概率只有在样本容量为无穷大时才有意义。因此即使“九死一生”的概率的确存在，它也不能确保第十个病人的康复。</p>\n<p><strong>在频率学派眼中，当重复试验的次数趋近于无穷大时，事件发生的频率会收敛到真实的概率之上。这种观点背后暗含了一个前提，那就是概率是一个确定的值，并不会受单次观察结果的影响。</strong></p>\n<p>将一枚均匀的硬币抛掷10次，结果可能是10次都是正面，也可能10次都是反面，写成频率的话就对应着0%和100%这两个极端，代表着最大范围的波动。可如果将抛掷次数增加到100次，出现正面的次数依然会发生变化，但波动的范围更可能会收缩到40%到60%之间。再将抛掷次数增加到1000，10000的话，频率波动的现象不会消失，但波动的范围会进一步收缩到越来越小的区间之内。</p>\n<p>基于以上的逻辑，把根据频率计算概率的过程反转过来，就是频率统计估计参数的过程。<strong>频率统计理论的核心在于认定待估计的参数是固定不变的常量，讨论参数的概率分布是没有意义的；而用来估计参数的数据是随机的变量，每个数据都是参数支配下一次独立重复试验的结果。由于参数本身是确定的，那频率的波动就并非来源于参数本身的不确定性，而是由有限次观察造成的干扰而导致</strong>。</p>\n<p>这可以从两个角度来解释：一方面，根据这些不精确的数据就可以对未知参数的精确取值做出有效的推断；另一方面，数据中包含的只是关于参数不完全的信息，所以从样本估计整体就必然会产生误差。</p>\n<!-- [[[read_end]]] -->\n<p>统计学的核⼼任务之一是根据从总体中抽取出的样本，也就是数据来估计未知的总体参数。参数的最优估计可以通过样本数据的分布，也就是<strong>采样分布</strong>（sampling distribution）来求解，由于频率统计将数据看作随机变量，所以计算采样分布是没有问题的。确定采样分布之后，参数估计可以等效成一个最优化的问题，而频率统计最常使用的最优化方法，就是<strong>最大似然估计</strong>（maximum likelihood estimation）。</p>\n<p><strong>回忆一下最大似然估计，它的目标是让似然概率最大化，也就是固定参数的前提之下，数据出现的条件概率最大化</strong>。这是频率学派估计参数的基本出发点：一组数据之所以能够在单次试验中出现，是因为它出现的可能性最大。而参数估计的过程就是赋予观测数据最大似然概率的过程。这可以通过下面这个简单的例子来说明：</p>\n<p>“如果观测到的数据$\\theta_i$是真实值$\\theta$和方差为$\\sigma ^ 2$，但形式未知的噪声$e_i$的叠加，那么如何得出$\\theta$的最优估计值？”</p>\n<p>要用最大似然估计解决这个问题，首先就要对似然概率进行建模，建模中的一个重要假设是假定未知形式的噪声满足高斯分布。这不仅在统计学中，在其他学科里也是一个常用的假设。</p>\n<p>从理论上说，在功率有限的条件下，高斯噪声的信源熵最大，因而带来的不确定性也就越大，换句话说，这是最恶劣的噪声；从实践上说，真实的噪声通常来源于多个独立的物理过程，都具有不同的概率分布，中心极限定理告诉我们，当噪声源的数目越来越多时，它们的叠加就趋近于高斯分布，因而高斯噪声就是对真实情况的一个合理的模拟。</p>\n<p>在高斯噪声的假设下，每个观测数据$\\theta_i$所满足的概率分布就可以写成</p>\n<p>$$ p(\\theta_i | \\theta) = \\dfrac{1}{\\sqrt{2\\pi \\sigma ^ 2}} \\exp [-\\dfrac{(\\theta_i - \\theta) ^ 2}{2\\sigma ^ 2}]$$</p>\n<p>这实际上就是采样分布。计算所有数据的概率分布的乘积，得到的就是似然函数（likelihood function）</p>\n<p>$$ L(\\boldsymbol{\\theta} | \\theta) = \\prod\\limits_{i = 1}^N p(\\theta_i | \\theta)$$ </p>\n<p>求解似然函数的对数，就可以将乘法运算转换为加法运算</p>\n<p>$$ \\log L = -\\dfrac{1}{2} \\sum\\limits_{i = 1}^N [\\log (2\\pi \\sigma ^ 2) + \\dfrac{(\\theta_i - \\theta) ^ 2}{2\\sigma ^ 2}]$$</p>\n<p>令对数似然函数的导数为0，就求出了使似然概率最大的最优估计</p>\n<p>$$ \\hat \\theta = \\dfrac{1}{N} \\sum\\limits_{i = 1}^N \\theta_i $$</p>\n<p>不知道你有没有在上面的公式中发现一个问题：虽然真实值$\\theta$是个固定值，但估计值$\\hat \\theta$却是数据的函数，因而也是个随机变量。</p>\n<p>这一点其实很好理解，因为估计值本质上是利用数据构造出来的函数，既然数据是随机分布的，估计值肯定也是随机的。这意味着如果每次估计使用的数据不同，得到的估计值也不会相同。那么如何来度量作为随机变量的估计值和作为客观常量的真实值之间的偏差呢？<strong>置信区间</strong>（confidence interval）就是频率学派给出的答案。</p>\n<p>置信区间的意义在于划定了真值的取值范围，真实的参数会以一定的概率$\\alpha$落入根据样本计算出的置信区间之内。当然，这里的概率还是要从频率的角度来解读：从同一个总体中进行100次采样可以得到100个不同的样本，根据这100个不同的样本又可以计算出100个不同的置信区间。在这么多个置信区间之中，包含真值的有多少个呢？$100 \\times \\alpha$个，剩下的$100 \\times (1 - \\alpha)$个置信区间就把真值漏掉了。这有点像乱枪打鸟：每一枪都乱打一梭子，打了100枪之后统计战果，发现打下来$100 \\times \\alpha$只鸟。如果把参数的真实值比喻成鸟，那么每一枪轰出的一梭子子弹就是置信区间。显然，置信区间的上下界和估计值一样，也是随机变量。</p>\n<p>总结起来，<strong>频率主义解决统计问题的基本思路如下：参数是确定的，数据是随机的，利用随机的数据推断确定的参数，得到的结果也是随机的。</strong></p>\n<p>这种思路直接把可能的参数空间压缩成为一个点：参数本身可能满足这样或者那样的概率分布，但一旦试验的条件确定，参数表现出来的就是一个固定的取值，让所有的概率分布都失去了意义。这就像说即使上帝真的掷骰子，但从骰子脱手那一刻起，它的点数就不再受上帝的控制，也就变成了确定不变的取值。频率主义者关注的就是这个真实存在的唯一参数，通过计算它对数据的影响来实现估计。</p>\n<p><strong>将频率主义“参数确定，数据随机”的思路应用在机器学习当中，得到的就是统计机器学习</strong>（statistical learning）。统计机器学习的做法是通过对给定的指标（比如似然函数或者均方误差）进行最优化，来估计模型中参数的取值，估计时并不考虑参数的不确定性，也就是不考虑未知参数的先验分布。<strong>和参数相关的信息全部来源于数据，输出的则是未知参数唯一的估计结果，这是统计机器学习的核心特征</strong>。</p>\n<p>受噪声和干扰的影响，观测数据并不是未知参数的准确反映，因此如何衡量估计结果的精确程度就成为统计机器学习中的一个关键问题。<strong>损失函数</strong>（loss function）直接定义了模型性能的度量方式，其数学期望被称为<strong>风险</strong>（risk），风险最小化就是参数估计的依据和准则。但风险的计算并不能一蹴而就：估计最优参数需要计算风险，计算风险时需要在数据的概率分布上对损失函数进行积分，可表示数据的分布又需要依赖未知参数的精确取值。这就给频率主义出了一个无解的问题：风险函数是没有办法精确求解的。</p>\n<p>为了解决这个问题，统计机器学习引入了<strong>经验风险</strong>（empirical risk），<strong>用训练数据的经验分布替换掉原始表达式中数据的真实分布</strong>，借此将风险函数转化成了可计算的数值。在真实的学习算法中，无论是分类问题中的误分类率，还是回归问题的中的均方误差，都是经验风险的实例，而所谓的最优模型也就是使经验风险最小化（empirical risk minimization）的那个模型。</p>\n<p>今天我和你分享了频率学派对概率、统计学和机器学习的认识方式，其要点如下：</p>\n<ul>\n<li><p><span class=\"orange\">频率学派认为概率是随机事件发生频率的极限值；</span></p>\n</li>\n<li><p><span class=\"orange\"> 频率学派执行参数估计时，视参数为确定取值，视数据为随机变量；</span></p>\n</li>\n<li><p><span class=\"orange\">频率学派主要使用最大似然估计法，让数据在给定参数下的似然概率最大化；</span></p>\n</li>\n<li><p><span class=\"orange\">频率学派对应机器学习中的统计学习，以经验风险最小化作为模型选择的准则。</span></p>\n</li>\n</ul>\n<p>有了这些理论之后，如何在实际问题中应用频率主义的统计学呢？这里有一个非常好的例子，来源于Nature Biotechnology第22卷第9期上的论文《什么是贝叶斯统计学》（What is Bayesian statistics）。</p>\n<p>在这个例子中，Alice和Bob在进行一场赌局，先得到6分者获胜。判断得分的方式有一些特别：在赌局开始之前，荷官在赌桌上扔一个小球，在这个球停止的位置做个标记。显然，这个标记的位置是随机的。赌局开始后，荷官继续扔球，如果球停到标记的左侧，则Alice得分；反之停到标记右侧，则Bob得分，这就是赌局的计分规则。那么问题来了：在这样的规则下，Alice现在以5:3领先Bob，那么Bob反败为胜的概率是多大呢？</p>\n<p>要计算Bob获胜的概率，必须要借助一个参数，那就是Alice得分的概率，不妨将它设为$p$，那么Bob得分的概率就是$1 - p$。概率$p$取决于标记在赌桌上的位置，由于位置本身是随机的，$p$也就在[0, 1]上满足均匀分布。按照频率主义的观点，在这一场赌局中，$p$有固定的取值，并可以通过已有的得分结果来估计。估计出$p$后就可以进一步计算Bob获胜的概率。这个问题就作为今天的思考题目，你可以计算一下。</p>\n<p>但是，这个问题并没有到此为止。如果跳出频率主义的限制，把$p$的概率分布引入到计算之中，又会得到什么样的结果呢？</p>\n<p>请加以思考并发表你的观点。</p>\n<p><img src=\"https://static001.geekbang.org/resource/image/a7/58/a7a64ab55c83c7a1c2519a6dc777cb58.jpg?wh=2379*2408\" alt=\"\"></p>\n<p></p>\n","comments":[{"had_liked":false,"id":11565,"user_name":"Float","can_delete":false,"product_type":"c1","uid":1148876,"ip_address":"","ucode":"6600DD70400D1A","user_header":"https://static001.geekbang.org/account/avatar/00/11/87/cc/580c8fe4.jpg","comment_is_top":false,"comment_ctime":1528204356,"is_pvip":false,"replies":[{"id":"3826","content":"Bingo！","user_name":"作者回复","user_name_real":"王天一","uid":"1027523","ctime":1528373885,"ip_address":"","comment_id":11565,"utype":1}],"discussion_count":1,"race_medal":0,"score":"302175915076","product_id":100008701,"comment_content":"按照频率学派，由最大似然估计写出似然函数L=p^5(1-p)^3,令一阶导=0得出p=5&#47;8，Bob要连赢三局才能反败为胜，则Bob获胜的概率为（3&#47;8）^3。<br>","like_count":70,"discussions":[{"author":{"id":1027523,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ad/c3/a9a0450b.jpg","nickname":"王天一","note":"","ucode":"142761D44C4C64","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":418902,"discussion_content":"Bingo！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1528373885,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":57706,"user_name":"Tiger","can_delete":false,"product_type":"c1","uid":1266982,"ip_address":"","ucode":"84E1E4F17B0F87","user_header":"https://static001.geekbang.org/account/avatar/00/13/55/26/c77853e0.jpg","comment_is_top":false,"comment_ctime":1546872385,"is_pvip":false,"replies":[{"id":"42408","content":"总结得很到位！","user_name":"作者回复","user_name_real":"王天一","uid":"1027523","ctime":1563778593,"ip_address":"","comment_id":57706,"utype":1}],"discussion_count":2,"race_medal":0,"score":"160460662337","product_id":100008701,"comment_content":"分享个人的学习总结，不对的地方请老师指正：<br>    频率主义认为参数本身是固定的，只是我们不知道，而数据是关于参数的不完全的信息，这就需要我们通过某种手段（比如极大似然法）利用数据找到最优参数。又由于数据是随机的，所以每使用一组不同的数据，找到的参数都不同，但这与参数本身是固定的并不矛盾。这是因为受噪声等因素的影响，数据并非参数的真实反映（否则就可以把固定的参数找到），存在风险，而要计算风险，需要已知数据的真实分布，而数据的真实分布又依赖于参数，这似乎就陷入了一个“先有鸡还是先有蛋”的悖论，为了解决这个悖论，引入经验风险，用训练数据的分布替代真实分布，使得风险可以被计算（这时的风险就称为经验风险），那么通过最小化经验风险就可以找出最优的参数。","like_count":37,"discussions":[{"author":{"id":1027523,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ad/c3/a9a0450b.jpg","nickname":"王天一","note":"","ucode":"142761D44C4C64","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435714,"discussion_content":"总结得很到位！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563778593,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1187210,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epc6ic3WuwDyZGjz1sy6bKIbhgucQfA4WdicickOuiadJmOH5ibHdlTibpibevvCxyc2gptARQuUjthOV8WQ/132","nickname":"学习使我快乐","note":"","ucode":"51FA2F21AE3F4A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":50971,"discussion_content":"牛逼","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1573795091,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":11622,"user_name":"快乐的小傻子","can_delete":false,"product_type":"c1","uid":1109721,"ip_address":"","ucode":"F6C5AB7C08C16F","user_header":"https://static001.geekbang.org/account/avatar/00/10/ee/d9/84d44bc8.jpg","comment_is_top":false,"comment_ctime":1528250339,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"40182956003","product_id":100008701,"comment_content":"数学是基础，概率论和统计学要补补咯","like_count":9},{"had_liked":false,"id":99788,"user_name":"游戏人生","can_delete":false,"product_type":"c1","uid":1553741,"ip_address":"","ucode":"5CEEF55D2B3C56","user_header":"https://static001.geekbang.org/account/avatar/00/17/b5/4d/dd5cb7a0.jpg","comment_is_top":false,"comment_ctime":1559301073,"is_pvip":false,"replies":[{"id":"42380","content":"1&#47;2那里感谢指正，log和ln只是差一个底数，其实底数是多少都不影响。","user_name":"作者回复","user_name_real":"王天一","uid":"1027523","ctime":1563765765,"ip_address":"","comment_id":99788,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18739170257","product_id":100008701,"comment_content":"求解似然函数的对数，就可以将乘法运算转换为加法运算，中(θ_i-θ)^2&#47;2σ^2 多了一个1&#47;2吧，应该是<br><br>(θ_i-θ)^2&#47;σ^2，不是log⁡L  是ln⁡L吧。<br><br>","like_count":4,"discussions":[{"author":{"id":1027523,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ad/c3/a9a0450b.jpg","nickname":"王天一","note":"","ucode":"142761D44C4C64","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":452272,"discussion_content":"1/2那里感谢指正，log和ln只是差一个底数，其实底数是多少都不影响。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563765765,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":47619,"user_name":"Ares","can_delete":false,"product_type":"c1","uid":1323178,"ip_address":"","ucode":"290D252FABCB1D","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEL2wE4k0RxhvTOFu179WngoHIOQvIyoltqZlA1MHMlv7ALDWKyx4dOOLc9zcMuzdRbIAiahvcSQ0aA/132","comment_is_top":false,"comment_ctime":1544166150,"is_pvip":false,"replies":[{"id":"18866","content":"求对数其实就是把乘除变成加减，因为对数不影响单调性。一阶导等于0求出的就是函数的极大值或者极小值。","user_name":"作者回复","user_name_real":"王天一","uid":"1027523","ctime":1545310014,"ip_address":"","comment_id":47619,"utype":1}],"discussion_count":3,"race_medal":0,"score":"18724035334","product_id":100008701,"comment_content":"老师，先对L求对数，再对对数求一阶导的过程有么？另外为什么令一阶导=0什么意义？","like_count":4,"discussions":[{"author":{"id":1027523,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ad/c3/a9a0450b.jpg","nickname":"王天一","note":"","ucode":"142761D44C4C64","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":431836,"discussion_content":"求对数其实就是把乘除变成加减，因为对数不影响单调性。一阶导等于0求出的就是函数的极大值或者极小值。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1545310014,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1480657,"avatar":"http://thirdwx.qlogo.cn/mmopen/KFgDEHIEpnT0EXnh02VHqLt7Qib9q3IEicCEwKb6OVjS5jqpj7tv2FLUTkiaIU7F5kAZlK1psH7b72Z0NpcUWuk7Gc3upajSGF1/132","nickname":"feego","note":"","ucode":"89789531F66222","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":573341,"discussion_content":"p^5(1-p)^3一阶导为0 5p^4(1-p)^3-p^5*3(1-p)^2=0=5p^4(1-p)^2((1-p)-3/5p)=5p^4(1-p^2)(1-8/5p)         p=0|1|-1|5/8","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1653364463,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2060580,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJ4icZuUxdMBSttwThbiazAXrLF4sWOkMMQSWIentO1IobXVAXoxA990Hb8icm0PPxhIbpkrYffJBOCw/132","nickname":"浦骥聃","note":"","ucode":"FDB0CF89F4AAC9","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":400013,"discussion_content":"可以参考 https://zhuanlan.zhihu.com/p/26614750 有最大似然法的讲解","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633141402,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":41245,"user_name":"小高","can_delete":false,"product_type":"c1","uid":1283052,"ip_address":"","ucode":"FCD422249F7355","user_header":"https://static001.geekbang.org/account/avatar/00/13/93/ec/985675c8.jpg","comment_is_top":false,"comment_ctime":1542762151,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"14427664039","product_id":100008701,"comment_content":"看来真的得好好补补数学了、看到数学公式一脸懵","like_count":3},{"had_liked":false,"id":32515,"user_name":"晴子","can_delete":false,"product_type":"c1","uid":1266337,"ip_address":"","ucode":"B29DB75465E780","user_header":"https://static001.geekbang.org/account/avatar/00/13/52/a1/56622f4e.jpg","comment_is_top":false,"comment_ctime":1539597072,"is_pvip":false,"replies":[{"id":"11967","content":"先对L求对数，再对对数求一阶导，就容易得出了。","user_name":"作者回复","user_name_real":"王天一","uid":"1027523","ctime":1539739726,"ip_address":"","comment_id":32515,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14424498960","product_id":100008701,"comment_content":"L=p^5(1-p)^3, 对L求一阶导，怎么求出P=3&#47;8","like_count":3,"discussions":[{"author":{"id":1027523,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ad/c3/a9a0450b.jpg","nickname":"王天一","note":"","ucode":"142761D44C4C64","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":426802,"discussion_content":"先对L求对数，再对对数求一阶导，就容易得出了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1539739726,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":28850,"user_name":"velly","can_delete":false,"product_type":"c1","uid":1106855,"ip_address":"","ucode":"3F77668774E2F6","user_header":"https://static001.geekbang.org/account/avatar/00/10/e3/a7/c1d476ba.jpg","comment_is_top":false,"comment_ctime":1538181293,"is_pvip":false,"replies":[{"id":"10398","content":"参数就是决定模型特性的系数，一般是未知的，需要利用数据来估计。像直线y=ax+b，a和b就是参数。","user_name":"作者回复","user_name_real":"王天一","uid":"1027523","ctime":1538187398,"ip_address":"","comment_id":28850,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14423083181","product_id":100008701,"comment_content":"参数定义是什么，不怎么理解。","like_count":3,"discussions":[{"author":{"id":1027523,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ad/c3/a9a0450b.jpg","nickname":"王天一","note":"","ucode":"142761D44C4C64","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":425396,"discussion_content":"参数就是决定模型特性的系数，一般是未知的，需要利用数据来估计。像直线y=ax+b，a和b就是参数。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1538187398,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":134963,"user_name":"JustDoDT","can_delete":false,"product_type":"c1","uid":1127175,"ip_address":"","ucode":"6AF0B80F00EAEF","user_header":"https://static001.geekbang.org/account/avatar/00/11/33/07/8f351609.jpg","comment_is_top":false,"comment_ctime":1568963368,"is_pvip":false,"replies":[{"id":"58240","content":"这是最大似然的解法","user_name":"作者回复","user_name_real":"王天一","uid":"1027523","ctime":1573719956,"ip_address":"","comment_id":134963,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10158897960","product_id":100008701,"comment_content":"上代码：python3 安装sympy包，pip install sympy<br>from sympy import *<br># 定义符号p<br>p = Symbol(&#39;p&#39;)<br>L = p**5 * (1-p)**3<br># 求导<br>d_L = diff(L, p)<br># 解方程<br>res = solve(d_L, p)<br># res = [0, 5&#47;8, 1]","like_count":2,"discussions":[{"author":{"id":1027523,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ad/c3/a9a0450b.jpg","nickname":"王天一","note":"","ucode":"142761D44C4C64","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":467980,"discussion_content":"这是最大似然的解法","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1573719956,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":32027,"user_name":"明臻","can_delete":false,"product_type":"c1","uid":1105545,"ip_address":"","ucode":"4AD5CA43ABBE03","user_header":"https://static001.geekbang.org/account/avatar/00/10/de/89/b25759e5.jpg","comment_is_top":false,"comment_ctime":1539392790,"is_pvip":false,"replies":[{"id":"11813","content":"感谢细致的阅读👍对置信区间的数学定义定然是1-\\alpha，但文章里写的并非严格定义，而是对概念的直观理解，相当于对置信区间的意义做个解释。这时说有100*(1-\\alpha)枪打中看着就有些别扭了。当然，这里的\\alpha有一些误导性，换一个符号会更恰当。","user_name":"作者回复","user_name_real":"王天一","uid":"1027523","ctime":1539571347,"ip_address":"","comment_id":32027,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10129327382","product_id":100008701,"comment_content":"置信区间的概率是不是写错了，应该是1-阿尔法。","like_count":2,"discussions":[{"author":{"id":1027523,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ad/c3/a9a0450b.jpg","nickname":"王天一","note":"","ucode":"142761D44C4C64","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":426616,"discussion_content":"感谢细致的阅读👍对置信区间的数学定义定然是1-\\alpha，但文章里写的并非严格定义，而是对概念的直观理解，相当于对置信区间的意义做个解释。这时说有100*(1-\\alpha)枪打中看着就有些别扭了。当然，这里的\\alpha有一些误导性，换一个符号会更恰当。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1539571347,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":11734,"user_name":"jeff","can_delete":false,"product_type":"c1","uid":1026894,"ip_address":"","ucode":"68456DD035BDF4","user_header":"https://static001.geekbang.org/account/avatar/00/0f/ab/4e/82e9657c.jpg","comment_is_top":false,"comment_ctime":1528332592,"is_pvip":false,"replies":[{"id":"3926","content":"多治几个病人，成功率可能就提高了","user_name":"作者回复","user_name_real":"王天一","uid":"1027523","ctime":1528460330,"ip_address":"","comment_id":11734,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10118267184","product_id":100008701,"comment_content":"九死一生 ，我看到的是医生治疗成功率是0<br>","like_count":2,"discussions":[{"author":{"id":1027523,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ad/c3/a9a0450b.jpg","nickname":"王天一","note":"","ucode":"142761D44C4C64","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":418974,"discussion_content":"多治几个病人，成功率可能就提高了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1528460330,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":11553,"user_name":"艿艿","can_delete":false,"product_type":"c1","uid":1044546,"ip_address":"","ucode":"8F727AB7A7F6B2","user_header":"https://static001.geekbang.org/account/avatar/00/0f/f0/42/7728d4f5.jpg","comment_is_top":false,"comment_ctime":1528198456,"is_pvip":true,"replies":[{"id":"3833","content":"具体问题是？","user_name":"作者回复","user_name_real":"王天一","uid":"1027523","ctime":1528375825,"ip_address":"","comment_id":11553,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10118133048","product_id":100008701,"comment_content":"第二小节有点难……","like_count":2,"discussions":[{"author":{"id":1027523,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ad/c3/a9a0450b.jpg","nickname":"王天一","note":"","ucode":"142761D44C4C64","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":418896,"discussion_content":"具体问题是？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1528375825,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":232762,"user_name":"stonyliu","can_delete":false,"product_type":"c1","uid":1062631,"ip_address":"","ucode":"E276B9FE907515","user_header":"https://static001.geekbang.org/account/avatar/00/10/36/e7/c9eda4e7.jpg","comment_is_top":false,"comment_ctime":1594112108,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5889079404","product_id":100008701,"comment_content":"看了下有不少人说跟不上或者要去补课，感觉是每一句话都对，但前后逻辑衔接并不强。比如说医生的例子是两个学派区别的形象说明。但看完例子，道理我都懂，频率和概率的区别也懂了，但两个学派的区别到底是什么？就是频率和概率的区别吗，继续懵逼中。。","like_count":1},{"had_liked":false,"id":174188,"user_name":"杨家荣","can_delete":false,"product_type":"c1","uid":1259241,"ip_address":"","ucode":"3DA65396C7F002","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/g1icQRbcv1QvJ5U8Cqk0ZqMH5PcMTXcZ8TpS5utE4SUzHcnJA3FYGelHykpzTfDh55ehE8JO9Zg9VGSJW7Wxibxw/132","comment_is_top":false,"comment_ctime":1580052870,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5875020166","product_id":100008701,"comment_content":"极客时间<br>21天打卡行动 39&#47;21<br>&lt;&lt;机器学习40讲&#47;01&gt;&gt;频率视角下的机器学习<br>今日所学:<br>1,“概率”（probability）这个基本概念存在着两种解读方式，它们分别对应着概率的频率学派（Frequentist）和贝叶斯学派（Bayesian）;<br>2,机器学习（machine learning）是一门研究通过计算的手段利用经验来改善系统自身性能的学科;<br>3,频率学派口中的概率表示的是事件发生频率的极限值，它只有在无限次的独立重复试验之下才有绝对的精确意义;<br>4,概率是一个确定的值，并不会受单次观察结果的影响。<br>5,频率统计理论的核心在于认定待估计的参数是固定不变的常量，讨论参数的概率分布是没有意义的；而用来估计参数的数据是随机的变量，每个数据都是参数支配下一次独立重复试验的结果;<br>6,解释：一方面，根据这些不精确的数据就可以对未知参数的精确取值做出有效的推断；另一方面，数据中包含的只是关于参数不完全的信息，所以从样本估计整体就必然会产生误差。<br>7,统计学的核⼼任务之一是根据从总体中抽取出的样本，也就是数据来估计未知的总体参数。参数的最优估计可以通过样本数据的分布，也就是采样分布;<br>8,频率统计最常使用的最优化方法，就是最大似然估计（maximum likelihood estimation）。<br>9,如何来度量作为随机变量的估计值和作为客观常量的真实值之间的偏差呢？置信区间（confidence interval）就是频率学派给出的答案。<br>10,置信区间的意义在于划定了真值的取值范围，真实的参数会以一定的概率 α 落入根据样本计算出的置信区间之内;<br>11,频率主义解决统计问题的基本思路如下：参数是确定的，数据是随机的，利用随机的数据推断确定的参数，得到的结果也是随机的;<br>12,将频率主义“参数确定，数据随机”的思路应用在机器学习当中，得到的就是统计机器学习;<br>13,和参数相关的信息全部来源于数据，输出的则是未知参数唯一的估计结果，这是统计机器学习的核心特征。<br>14,经验风险（empirical risk），用训练数据的经验分布替换掉原始表达式中数据的真实分布;<br>重点:<br>1,频率学派认为概率是随机事件发生频率的极限值；<br>2, 频率学派执行参数估计时，视参数为确定取值，视数据为随机变量；<br>3,频率学派主要使用最大似然估计法，让数据在给定参数下的似然概率最大化；<br>4,频率学派对应机器学习中的统计学习，以经验风险最小化作为模型选择的准则。","like_count":1},{"had_liked":false,"id":13453,"user_name":"朱沛","can_delete":false,"product_type":"c1","uid":1154196,"ip_address":"","ucode":"B9312C952F264B","user_header":"https://static001.geekbang.org/account/avatar/00/11/9c/94/341f55a4.jpg","comment_is_top":false,"comment_ctime":1529638735,"is_pvip":false,"replies":[{"id":"4534","content":"是的，理解原理需要线代和概率，做算法需要最优化。","user_name":"作者回复","user_name_real":"王天一","uid":"1027523","ctime":1529721639,"ip_address":"","comment_id":13453,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5824606031","product_id":100008701,"comment_content":"大学数学没学好的是不是应该先补数学？","like_count":1,"discussions":[{"author":{"id":1027523,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ad/c3/a9a0450b.jpg","nickname":"王天一","note":"","ucode":"142761D44C4C64","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":419653,"discussion_content":"是的，理解原理需要线代和概率，做算法需要最优化。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1529721639,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":12128,"user_name":"never_giveup","can_delete":false,"product_type":"c1","uid":1150593,"ip_address":"","ucode":"20711DF785095C","user_header":"","comment_is_top":false,"comment_ctime":1528603478,"is_pvip":false,"replies":[{"id":"3990","content":"没毛病！","user_name":"作者回复","user_name_real":"王天一","uid":"1027523","ctime":1528624708,"ip_address":"","comment_id":12128,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5823570774","product_id":100008701,"comment_content":"说下个人的对最后问题理解，p是待估计的参数 ，5:3是给出的数据。最大似然使在p条件下产生数据的可能性最大，进而求极值算出p。","like_count":1,"discussions":[{"author":{"id":1027523,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ad/c3/a9a0450b.jpg","nickname":"王天一","note":"","ucode":"142761D44C4C64","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":419130,"discussion_content":"没毛病！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1528624708,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":11974,"user_name":"洪漫楷","can_delete":false,"product_type":"c1","uid":1150096,"ip_address":"","ucode":"A895CCD6636B6C","user_header":"https://static001.geekbang.org/account/avatar/00/11/8c/90/2c16f7aa.jpg","comment_is_top":false,"comment_ctime":1528473503,"is_pvip":false,"replies":[{"id":"3954","content":"这一篇没有，后面会有的","user_name":"作者回复","user_name_real":"王天一","uid":"1027523","ctime":1528594887,"ip_address":"","comment_id":11974,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5823440799","product_id":100008701,"comment_content":"没有图帮助理解的吗","like_count":1,"discussions":[{"author":{"id":1027523,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ad/c3/a9a0450b.jpg","nickname":"王天一","note":"","ucode":"142761D44C4C64","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":419064,"discussion_content":"这一篇没有，后面会有的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1528594887,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":11555,"user_name":".Yang","can_delete":false,"product_type":"c1","uid":1149154,"ip_address":"","ucode":"68E917693D97A6","user_header":"https://static001.geekbang.org/account/avatar/00/11/88/e2/002b04c6.jpg","comment_is_top":false,"comment_ctime":1528199514,"is_pvip":true,"replies":[{"id":"3834","content":"具体问题是？","user_name":"作者回复","user_name_real":"王天一","uid":"1027523","ctime":1528375832,"ip_address":"","comment_id":11555,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5823166810","product_id":100008701,"comment_content":"我勒个去，看到一半跟不上了","like_count":1,"discussions":[{"author":{"id":1027523,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ad/c3/a9a0450b.jpg","nickname":"王天一","note":"","ucode":"142761D44C4C64","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":418898,"discussion_content":"具体问题是？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1528375832,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":359781,"user_name":"感恩的心","can_delete":false,"product_type":"c1","uid":2975307,"ip_address":"美国","ucode":"6D9E2BB010CE92","user_header":"https://static001.geekbang.org/account/avatar/00/2d/66/4b/79126e5d.jpg","comment_is_top":false,"comment_ctime":1665890819,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1665890819","product_id":100008701,"comment_content":"讲得太好了 建议老师出本书！读了豁然开朗 受益匪浅","like_count":0},{"had_liked":false,"id":341932,"user_name":"Geek_dong","can_delete":false,"product_type":"c1","uid":2976140,"ip_address":"","ucode":"6A2753BF18E66B","user_header":"https://static001.geekbang.org/account/avatar/00/2d/69/8c/a82a3cdc.jpg","comment_is_top":false,"comment_ctime":1649923583,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1649923583","product_id":100008701,"comment_content":"p=5&#47;8","like_count":0},{"had_liked":false,"id":330768,"user_name":"烟雨平生","can_delete":false,"product_type":"c1","uid":2087212,"ip_address":"","ucode":"C34CD9E1D990E3","user_header":"https://static001.geekbang.org/account/avatar/00/1f/d9/2c/296b02b0.jpg","comment_is_top":false,"comment_ctime":1642149654,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1642149654","product_id":100008701,"comment_content":"关于频率派我不是很明白，就以思考题为例，按照频率派的观点，概率的参数固有的属性，那么是球出现的位置是均匀分布，胜利的概率是球的横坐标x1除以总长度x，然后对这些概率做积分，那么甲乙胜利的概率各是1&#47;2才对，赢三局是1&#47;8？","like_count":0,"discussions":[{"author":{"id":2976140,"avatar":"https://static001.geekbang.org/account/avatar/00/2d/69/8c/a82a3cdc.jpg","nickname":"Geek_dong","note":"","ucode":"6A2753BF18E66B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":563032,"discussion_content":"个人理解，你说的1/2更像是对所有样本特征分析出来的结果，但是实际上我们只能根据现有的样本去判断，就比如说，当前已经出现了5：3的情况，那么我们现在要考虑的就是基于这个5:3已经确定的事实，去推断怎么样的概率p才会让这个事实出现的概率最大，所以就构造最大似然函数求导了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1649926639,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":284153,"user_name":"思致精研_益达","can_delete":false,"product_type":"c1","uid":1586709,"ip_address":"","ucode":"9886B8F58E7635","user_header":"https://static001.geekbang.org/account/avatar/00/18/36/15/937dee0a.jpg","comment_is_top":false,"comment_ctime":1616083143,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1616083143","product_id":100008701,"comment_content":"学习第二天打卡，第一遍看得有点懵，遇到不会的，网上百度，补些基础知识，继续加油","like_count":0},{"had_liked":false,"id":246566,"user_name":"建强","can_delete":false,"product_type":"c1","uid":1397126,"ip_address":"","ucode":"62B03D0E0C64EC","user_header":"https://static001.geekbang.org/account/avatar/00/15/51/86/b5fd8dd8.jpg","comment_is_top":false,"comment_ctime":1599405183,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1599405183","product_id":100008701,"comment_content":"思考题：<br>根据现有的比分，可知Alice得分的概率P = 5&#47;8，Bob得分的概率为3&#47;8，而Bop想要反败为胜必须连得三分，而连得三分的概率为3&#47;8 * 3&#47;8 * 3&#47;8 = 27&#47;512 = 0.053","like_count":0},{"had_liked":false,"id":223587,"user_name":"zhenzixiong","can_delete":false,"product_type":"c1","uid":1983955,"ip_address":"","ucode":"C67B802661BFA8","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/KeyzjXhJ4wMLiasxxry0L3RqAMv2GpicoR4dlZGzuUhWDmXIYIwShX6TVSBLyaWQm2LmyUG7xSBxiaNquhqMjbUvA/132","comment_is_top":false,"comment_ctime":1591139380,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1591139380","product_id":100008701,"comment_content":"概率的理论学习和它的实际应用之间还是有差距的，从会计算概率到会运用概率解决问题还需要多多训练。","like_count":0},{"had_liked":false,"id":175508,"user_name":"Ronnyz","can_delete":false,"product_type":"c1","uid":1488280,"ip_address":"","ucode":"9F34527B1D343D","user_header":"https://static001.geekbang.org/account/avatar/00/16/b5/98/ffaf2aca.jpg","comment_is_top":false,"comment_ctime":1580736179,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1580736179","product_id":100008701,"comment_content":"Bob单局获胜的概率为：3&#47;8 ，接下来需要三局连胜：(3&#47;8)^3","like_count":0},{"had_liked":false,"id":140997,"user_name":"何妨","can_delete":false,"product_type":"c1","uid":1385377,"ip_address":"","ucode":"EC3983BFF7992A","user_header":"https://static001.geekbang.org/account/avatar/00/15/23/a1/b08f3ee7.jpg","comment_is_top":false,"comment_ctime":1571101746,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1571101746","product_id":100008701,"comment_content":"我，一脸懵逼……","like_count":0},{"had_liked":false,"id":95810,"user_name":"WS","can_delete":false,"product_type":"c1","uid":1369162,"ip_address":"","ucode":"717D9670BA6A99","user_header":"https://static001.geekbang.org/account/avatar/00/14/e4/4a/63e46022.jpg","comment_is_top":false,"comment_ctime":1558184855,"is_pvip":false,"replies":[{"id":"42381","content":"\\theta指固定的真实值，\\theta_i是在真实值的基础上加了个高斯噪声，所以条件概率就是高斯分布的形式。","user_name":"作者回复","user_name_real":"王天一","uid":"1027523","ctime":1563765859,"ip_address":"","comment_id":95810,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1558184855","product_id":100008701,"comment_content":"观测数据sita的概率分布式子，看不懂，能解释一下吗？","like_count":0,"discussions":[{"author":{"id":1027523,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ad/c3/a9a0450b.jpg","nickname":"王天一","note":"","ucode":"142761D44C4C64","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":450605,"discussion_content":"\\theta指固定的真实值，\\theta_i是在真实值的基础上加了个高斯噪声，所以条件概率就是高斯分布的形式。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563765859,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":88748,"user_name":"浓眉和叶孤橙","can_delete":false,"product_type":"c1","uid":1260073,"ip_address":"","ucode":"40626D652F5056","user_header":"https://static001.geekbang.org/account/avatar/00/13/3a/29/b12c0f7c.jpg","comment_is_top":false,"comment_ctime":1555991183,"is_pvip":false,"replies":[{"id":"42383","content":"吃力恐怕不是你自己的问题，而是这个方向本身难度就很大，参考资料也不多。比较好的就是koller那本大书，但不适合自学，其他值得推荐的恐怕也没什么了……","user_name":"作者回复","user_name_real":"王天一","uid":"1027523","ctime":1563766172,"ip_address":"","comment_id":88748,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1555991183","product_id":100008701,"comment_content":"王老师，您好，我想问下，我现在学习概率图模型很吃力，有没有比较好的学习资料推荐，适合初学者？谢谢王老师","like_count":0,"discussions":[{"author":{"id":1027523,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ad/c3/a9a0450b.jpg","nickname":"王天一","note":"","ucode":"142761D44C4C64","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":447889,"discussion_content":"吃力恐怕不是你自己的问题，而是这个方向本身难度就很大，参考资料也不多。比较好的就是koller那本大书，但不适合自学，其他值得推荐的恐怕也没什么了……","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563766172,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1739288,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/8a/18/4a847af3.jpg","nickname":"赵森","note":"","ucode":"8F69AAD8A12949","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":260799,"discussion_content":"斯坦福在coursera上概率图模型的课程很值得学","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1588902907,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":79922,"user_name":"方得","can_delete":false,"product_type":"c1","uid":1434253,"ip_address":"","ucode":"EECB80EB75829E","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJSZcno3GEdDMUcwqzOOOLibrvvuquBf2qmib6QR8rctSpGibme8WWYIheUjzQ1q9nzNiat0XzHtSSwPA/132","comment_is_top":false,"comment_ctime":1553574404,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1553574404","product_id":100008701,"comment_content":"还是是统计学专业，感觉有点蒙，但是大概还是了解的。","like_count":0},{"had_liked":false,"id":78539,"user_name":"李小文","can_delete":false,"product_type":"c1","uid":1453272,"ip_address":"","ucode":"DA2DDAFA17D005","user_header":"https://static001.geekbang.org/account/avatar/00/16/2c/d8/442c13dc.jpg","comment_is_top":false,"comment_ctime":1553171172,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1553171172","product_id":100008701,"comment_content":"log(L)运算怎么算的？后面的指数函数部分怎么提出的-1&#47;2的呀！","like_count":0},{"had_liked":false,"id":78450,"user_name":"李小文","can_delete":false,"product_type":"c1","uid":1453272,"ip_address":"","ucode":"DA2DDAFA17D005","user_header":"https://static001.geekbang.org/account/avatar/00/16/2c/d8/442c13dc.jpg","comment_is_top":false,"comment_ctime":1553151227,"is_pvip":true,"replies":[{"id":"42388","content":"这个说来话长了，就把它当个现成的结论吧。","user_name":"作者回复","user_name_real":"王天一","uid":"1027523","ctime":1563766861,"ip_address":"","comment_id":78450,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1553151227","product_id":100008701,"comment_content":"从理论上说，在功率有限的条件下，高斯噪声的信源熵最大，因而带来的不确定性也就越大，换句话说，这是最恶劣的噪声；<br>(为什么功率有限，就是高斯噪声的信源熵最大呢？)","like_count":0,"discussions":[{"author":{"id":1027523,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ad/c3/a9a0450b.jpg","nickname":"王天一","note":"","ucode":"142761D44C4C64","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":444099,"discussion_content":"这个说来话长了，就把它当个现成的结论吧。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563766861,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":59565,"user_name":"土土","can_delete":false,"product_type":"c1","uid":1369459,"ip_address":"","ucode":"660118DB8E748A","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/qsmAdOC3R3twep9xwiboiaNGlZ9dtY5NQZibVTKSpkwd6l63kicv3v5vSW3oO0erfxACL679azGTwEBkxfKNxs0VkQ/132","comment_is_top":false,"comment_ctime":1547386706,"is_pvip":false,"replies":[{"id":"42406","content":"确实需要一些概率论的基础","user_name":"作者回复","user_name_real":"王天一","uid":"1027523","ctime":1563778490,"ip_address":"","comment_id":59565,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1547386706","product_id":100008701,"comment_content":"感觉有点听不懂，好多名词不会，不知道是不是概率论没学的原因，不知道是不是概率论没学的原因","like_count":0,"discussions":[{"author":{"id":1027523,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ad/c3/a9a0450b.jpg","nickname":"王天一","note":"","ucode":"142761D44C4C64","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":436356,"discussion_content":"确实需要一些概率论的基础","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563778490,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":58484,"user_name":"秦龙君","can_delete":false,"product_type":"c1","uid":1004181,"ip_address":"","ucode":"2085706DBABD5C","user_header":"https://static001.geekbang.org/account/avatar/00/0f/52/95/abb7bfe3.jpg","comment_is_top":false,"comment_ctime":1547089679,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1547089679","product_id":100008701,"comment_content":"^_^","like_count":0},{"had_liked":false,"id":51528,"user_name":"多襄丸","can_delete":false,"product_type":"c1","uid":1074310,"ip_address":"","ucode":"1AA1497C5A293C","user_header":"https://static001.geekbang.org/account/avatar/00/10/64/86/f5a9403a.jpg","comment_is_top":false,"comment_ctime":1545194383,"is_pvip":false,"replies":[{"id":"18887","content":"考是肯定没问题的，但要想清楚自己要得到什么（除了文凭），还有毕业的出路在哪里。","user_name":"作者回复","user_name_real":"王天一","uid":"1027523","ctime":1545313155,"ip_address":"","comment_id":51528,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1545194383","product_id":100008701,"comment_content":"老师，我非科班毕业两年，现在从事Java开发，可以考机器学习或者AI的研究生吗？ 求回复，谢谢🙏！","like_count":0,"discussions":[{"author":{"id":1027523,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ad/c3/a9a0450b.jpg","nickname":"王天一","note":"","ucode":"142761D44C4C64","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":433500,"discussion_content":"考是肯定没问题的，但要想清楚自己要得到什么（除了文凭），还有毕业的出路在哪里。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1545313155,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":16752,"user_name":"我心飞扬","can_delete":false,"product_type":"c1","uid":1149164,"ip_address":"","ucode":"E41155122C9A1F","user_header":"https://static001.geekbang.org/account/avatar/00/11/88/ec/1460179b.jpg","comment_is_top":false,"comment_ctime":1532155325,"is_pvip":false,"replies":[{"id":"5888","content":"要衡量因变量的分布，需要在相同自变量的条件下做多次测量。确定因变量的分布不能用f(x1), f(x2),  f(x3)这些数据，而是要重复测量f(x1)多次，观察结果是不是正态。这样的多次重复测量在实际中未必可以实现。","user_name":"作者回复","user_name_real":"王天一","uid":"1027523","ctime":1532356694,"ip_address":"","comment_id":16752,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1532155325","product_id":100008701,"comment_content":"既然噪声的概率分布就是因变量的概率分布，那直接检查一下因变量是不是服从正态分布是不是就可以了，为什么还要对噪声做假设呢","like_count":0,"discussions":[{"author":{"id":1027523,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ad/c3/a9a0450b.jpg","nickname":"王天一","note":"","ucode":"142761D44C4C64","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":420917,"discussion_content":"要衡量因变量的分布，需要在相同自变量的条件下做多次测量。确定因变量的分布不能用f(x1), f(x2),  f(x3)这些数据，而是要重复测量f(x1)多次，观察结果是不是正态。这样的多次重复测量在实际中未必可以实现。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1532356694,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":16124,"user_name":"向阳","can_delete":false,"product_type":"c1","uid":1179030,"ip_address":"","ucode":"DBBE3042938CEE","user_header":"https://static001.geekbang.org/account/avatar/00/11/fd/96/44641d9e.jpg","comment_is_top":false,"comment_ctime":1531791085,"is_pvip":false,"replies":[{"id":"5806","content":"没错","user_name":"作者回复","user_name_real":"王天一","uid":"1027523","ctime":1532149663,"ip_address":"","comment_id":16124,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1531791085","product_id":100008701,"comment_content":"3*3*3&#47;（8*8*8）","like_count":0,"discussions":[{"author":{"id":1027523,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ad/c3/a9a0450b.jpg","nickname":"王天一","note":"","ucode":"142761D44C4C64","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":420679,"discussion_content":"没错","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1532149663,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":14182,"user_name":"我心飞扬","can_delete":false,"product_type":"c1","uid":1149164,"ip_address":"","ucode":"E41155122C9A1F","user_header":"https://static001.geekbang.org/account/avatar/00/11/88/ec/1460179b.jpg","comment_is_top":false,"comment_ctime":1530230340,"is_pvip":false,"replies":[{"id":"4878","content":"可以。使用高斯噪声文章里给出了理由，一是符合实际，二是容易计算。","user_name":"作者回复","user_name_real":"王天一","uid":"1027523","ctime":1530498695,"ip_address":"","comment_id":14182,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1530230340","product_id":100008701,"comment_content":"请问假设噪声是高斯，问什么发生概率要写成正态，假设噪声高斯，发生概率其他不行吗","like_count":0,"discussions":[{"author":{"id":1027523,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ad/c3/a9a0450b.jpg","nickname":"王天一","note":"","ucode":"142761D44C4C64","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":419902,"discussion_content":"可以。使用高斯噪声文章里给出了理由，一是符合实际，二是容易计算。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1530498695,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":11778,"user_name":"李奇科","can_delete":false,"product_type":"c1","uid":1032572,"ip_address":"","ucode":"D84778A2DAAA8D","user_header":"https://static001.geekbang.org/account/avatar/00/0f/c1/7c/0d041f20.jpg","comment_is_top":false,"comment_ctime":1528349901,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1528349901","product_id":100008701,"comment_content":"王老师对frequentist有偏见啊。 拋骰子时，出现6的概率难道不是一个常数吗？另外Bayes也是统计的一个分支吧。","like_count":0}]}