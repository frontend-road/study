{"id":4635,"title":"05 | 从文本到用户画像有多远","content":"<p>前面，我和你聊过了不要把用户画像当成银弹，也不要觉得一无是处。对于一个早期的推荐系统来说，基于内容推荐离不开为用户构建一个初级的画像，这种初级的画像一般叫做用户画像（User Profile），一些大厂内部还习惯叫做UP，今天我就来讲一讲从大量文本数据中挖掘用户画像常常用到的一些算法。</p>\n<h2>从文本开始</h2>\n<p>用户这一端比如说有：</p>\n<ol>\n<li>注册资料中的姓名、个人签名；</li>\n<li>发表的评论、动态、日记等；</li>\n<li>聊天记录（不要慌，我举个例子而已，你在微信上说的话还是安全的）。</li>\n</ol>\n<p>物品这一端也有大量文本信息，可以用于构建物品画像（ Item Profile ），并最终帮助丰富 用户画像（User Profile），这些数据举例来说有：</p>\n<ol>\n<li>物品的标题、描述；</li>\n<li>物品本身的内容（一般指新闻资讯类）；</li>\n<li>物品的其他基本属性的文本。</li>\n</ol>\n<p>文本数据是互联网产品中最常见的信息表达形式，数量多、处理快、存储小，因为文本数据的特殊地位，所以今天我专门介绍一些建立用户画像过程中用到的文本挖掘算法。</p>\n<h2>构建用户画像</h2>\n<p>要用物品和用户的文本信息构建出一个基础版本的用户画像，大致需要做这些事：</p>\n<p><strong>1. 把所有非结构化的文本结构化，去粗取精，保留关键信息；</strong><br />\n<br><br />\n<strong>2. 根据用户行为数据把物品的结构化结果传递给用户，与用户自己的结构化信息合并。</strong></p>\n<p>第一步最关键也最基础，其准确性、粒度、覆盖面都决定了用户画像的质量。仿佛如果真的要绘制一个用户的模样，要提前给他拍照，这个拍照技术决定了后面的描绘情况，无论是采用素描、油画、工笔还是写意。这一步要用到很多文本挖掘算法，稍后会详细介绍。</p>\n<p>第二步会把物品的文本分析结果，按照用户历史行为把物品画像（ Item Profile ）传递给用户。你也许会问：传递是什么意思？没关系，这个稍后我会介绍。</p>\n<h3>一、结构化文本</h3>\n<p>我们拿到的文本，常常是自然语言描述的，用行话说，就是“非结构化”的，但是计算机在处理时，只能使用结构化的数据索引，检索，然后向量化后再计算；所以分析文本，就是为了将非结构化的数据结构化，好比是将模拟信号数字化一样，只有这样才能送入计算机，继续计算。这个很好理解，不多解释。</p>\n<p>从物品端的文本信息，我们可以利用成熟的NLP算法分析得到的信息有下面几种。</p>\n<ol>\n<li>关键词提取：最基础的标签来源，也为其他文本分析提供基础数据，常用TF-IDF和TextRank。</li>\n<li>实体识别：人物、位置和地点、著作、影视剧、历史事件和热点事件等，常用基于词典的方法结合CRF模型。</li>\n<li>内容分类：将文本按照分类体系分类，用分类来表达较粗粒度的结构化信息。</li>\n<li>文本 ：在无人制定分类体系的前提下，无监督地将文本划分成多个类簇也很常见，别看不是标签，类簇编号也是用户画像的常见构成。</li>\n<li>主题模型：从大量已有文本中学习主题向量，然后再预测新的文本在各个主题上的概率分布情况，也很实用，其实这也是一种聚类思想，主题向量也不是标签形式，也是用户画像的常用构成。</li>\n<li>嵌入：“嵌入”也叫作Embedding，从词到篇章，无不可以学习这种嵌入表达。嵌入表达是为了挖掘出字面意思之下的语义信息，并且用有限的维度表达出来。</li>\n</ol>\n<p>下面我来介绍几种常用的文本结构化算法。</p>\n<p><strong>1 TF-IDF</strong></p>\n<p>TF全称就是Term Frequency，是词频的意思，IDF就是 Inverse Document Frequency 是逆文档频率的意思。TF-IDF提取关键词的思想来自信息检索领域，其实思想很朴素，包括了两点：在一篇文字中反复出现的词会更重要，在所有文本中都出现的词更不重要。非常符合我们的直觉，这两点就分别量化成TF和IDF两个指标：</p>\n<ol>\n<li>TF，就是词频，在要提取关键词的文本中出现的次数；</li>\n<li>IDF，是提前统计好的，在已有的所有文本中，统计每一个词出现在了多少文本中，记为n，也就是文档频率，一共有多少文本，记为N。</li>\n</ol>\n<p>IDF就是这样计算：<br />\n<img src=\"https://static001.geekbang.org/resource/image/a9/63/a90ba5c08a6ea42773633b278ceca863.png?wh=292*144\" alt=\"\" /><br />\n计算过程为：词出现的文档数加1，再除总文档数，最后结果再取对数。</p>\n<p>IDF的计算公式有这么几个特点：</p>\n<ol>\n<li>所有词的N都是一样的，因此出现文本数越少(n)的词，它的IDF值越大；</li>\n<li>如果一个词的文档频率为0，为防止计算出无穷大的IDF，所以分母中有一个1；</li>\n<li>对于新词，本身应该n是0，但也可以默认赋值为所有词的平均文档频率。</li>\n</ol>\n<p>计算出TF和IDF后，将两个值相乘，就得到每一个词的权重。根据该权重筛选关键词的方式有：</p>\n<ol>\n<li>给定一个K，取Top K个词，这样做简单直接，但也有一点，如果总共得到的词个数少于K，那么所有词都是关键词了，显然这样做不合理；</li>\n<li>计算所有词权重的平均值，取在权重在平均值之上的词作为关键词；</li>\n</ol>\n<p>另外，在某些场景下，还会加入以下其他的过滤措施，如：只提取动词和名词作为关键词。</p>\n<!-- [[[read_end]]] -->\n<p><strong>2 TextRank</strong></p>\n<p>TextRank这个名字看上去是不是和著名的PageRank有点亲戚关系？是的，TextRank是PageRank的私生子之一，著名的PageRank算法是Google用来衡量网页重要性的算法，TextRank算法的思想也与之类似，可以概括为：</p>\n<ol>\n<li>文本中，设定一个窗口宽度，比如K个词，统计窗口内的词和词的共现关系，将其看成无向图。图就是网络，由存在连接关系的节点构成，所谓无向图，就是节点之间的连接关系不考虑从谁出发，有关系就对了；</li>\n<li>所有词初始化的重要性都是1；</li>\n<li>每个节点把自己的权重平均分配给“和自己有连接“的其他节点；</li>\n<li>每个节点将所有其他节点分给自己的权重求和，作为自己的新权重；</li>\n<li>如此反复迭代第3、4两步，直到所有的节点权重收敛为止。</li>\n</ol>\n<p>通过TextRank计算后的词语权重，呈现出这样的特点：那些有共现关系的会互相支持对方成为关键词。</p>\n<p><strong>3 内容分类</strong></p>\n<p>在门户网站时代，每个门户网站都有自己的频道体系，这个频道体系就是一个非常大的内容分类体系，这一做法也延伸到了移动互联网UGC时代，图文信息流 App 的资讯内容也需要被自动分类到不同的频道中，从而能够得到最粗粒度的结构化信息，也被很多推荐系统用来在用户冷启动时探索用户兴趣。</p>\n<p>在门户时代的内容分类，相对来说更容易，因为那时候的内容都是长文本，长文本的内容分类可以提取很多信息，而如今 UGC 当道的时代，短文本的内容分类则更困难一些。短文本分类方面经典的算法是 SVM ，在工具上现在最常用的是Facebook开源的FastText。</p>\n<p><strong>4 实体识别</strong></p>\n<p>命名实体识别（也常常被简称为NER，Named-Entity Recognition）在NLP技术中常常被认为是序列标注问题，和分词、词性标注属于同一类问题。</p>\n<p>所谓序列标注问题，就是给你一个字符序列，从左往右遍历每个字符，一边遍历一边对每一个字符分类，分类的体系因序列标注问题不同而不同：</p>\n<ol>\n<li>分词问题：对每一个字符分类为“词开始”“词中间”“词结束”三类之一；</li>\n<li>词性标注：对每一个分好的词，分类为定义的词性集合的之一；</li>\n<li>实体识别：对每一个分好的词，识别为定义的命名实体集合之一。</li>\n</ol>\n<p>对于序列标注问题，通常的算法就是隐马尔科夫模型（HMM）或者条件随机场（CRF），我们在推荐系统中主要是挖掘出想要的结构化结果，对其中原理有兴趣再去深入了解。</p>\n<p>实体识别还有比较实用化的非模型做法：词典法。提前准备好各种实体的词典，使用trie-tree数据结构存储，拿着分好的词去词典里找，找到了某个词就认为是提前定义好的实体了。</p>\n<p>以实体识别为代表的序列标注问题上，工业级别的工具上spaCy比NLTK在效率上优秀一些。</p>\n<p><strong>5 聚类</strong></p>\n<p>传统聚类方法在文本中的应用，今天逐渐被主题模型取代，同样是无监督模型，以LDA为代表的主题模型能够更准确地抓住主题，并且能够得到软聚类的效果，也就是说可以让一条文本属于多个类簇。</p>\n<p>作为初创公司或初创产品，我知道你的时间宝贵，也知道你的公司处处节俭，以至于没有业务专家为你的应用制定分类体系，这时候如果能在文本数据上跑一个LDA模型，那世界就显得非常美好了。</p>\n<p>LDA模型需要设定主题个数，如果你有时间，那么这个K可以通过一些实验来对比挑选，方法是：每次计算K个主题两两之间的平均相似度，选择一个较低的K值；如果你赶时间，在推荐系统领域，只要计算资源够用，主题数可以尽量多一些。</p>\n<p>另外，需要注意的是，得到文本在各个主题上的分布，可以保留概率最大的前几个主题作为文本的主题。LDA工程上较难的是并行化，如果文本数量没到海量程度，提高单机配置也是可以的，开源的LDA训练工具有Gensim，PLDA等可供选择。</p>\n<p><strong>6 词嵌入</strong></p>\n<p>关于嵌入，是一个数学概念。以词嵌入为例来说吧。</p>\n<p>词嵌入，也叫作Word Embedding。前面讲到的结构化方案，除了LDA，其他都是得到一些标签，而这些标签无一例外都是稀疏的，而词嵌入则能够为每一个词学习得到一个稠密的向量。</p>\n<p>这样说可能很抽象，换个说法，一个词可能隐藏很多语义信息，比如北京，可能包含“首都、中国、北方、直辖市、大城市”等等，这些语义在所有文本上是有限的，比如128个，于是每个词就用一个128维的向量表达，向量中各个维度上的值大小代表了词包含各个语义的多少。</p>\n<p>拿着这些向量可以做以下的事情：</p>\n<ol>\n<li>计算词和词之间的相似度，扩充结构化标签；</li>\n<li>累加得到一个文本的稠密向量；</li>\n<li>用于聚类，会得到比使用词向量聚类更好的语义聚类效果。</li>\n</ol>\n<p>这方面当然就属大名鼎鼎的Word2Vec了。Word2Vec是用浅层神经网络学习得到每个词的向量表达，Word2Vec最大的贡献在于一些工程技巧上的优化，使得百万词的规模在单机上可以几分钟轻松跑出来，得到这些词向量后可以聚类或者进一步合成句子向量再使用。</p>\n<h3>二、标签选择</h3>\n<p>前面说到，用户端的文本，物品端的文本如何结构化，得到了诸如标签（关键词、分类等）、主题、词嵌入向量。接下来就是第二步：如何把物品的结构化信息给用户呢？</p>\n<p>我们想一想，用户在产品上看到了很多我们用各种逻辑和理由展示给他的物品，他只从中消费了一部分物品。现在问题就是，到底是那些特性吸引了他消费呢？</p>\n<p>一种简单粗暴的办法是直接把用户产生过行为的物品标签累积在一起，但是这里要说的是另一种思路。</p>\n<p>我们把用户对物品的行为，消费或者没有消费看成是一个分类问题。用户用实际行动帮我们标注了若干数据，那么挑选出他实际感兴趣的特性就变成了特征选择问题。</p>\n<p>最常用的是两个方法：卡方检验（CHI）和信息增益（IG）。基本思想是：</p>\n<ol>\n<li>把物品的结构化内容看成文档；</li>\n<li>把用户对物品的行为看成是类别；</li>\n<li>每个用户看见过的物品就是一个文本集合；</li>\n<li>在这个文本集合上使用特征选择算法选出每个用户关心的东西。</li>\n</ol>\n<h3>1 卡方检验</h3>\n<p>CHI就是卡方检验，本身是一种特征选择方法。</p>\n<p>前面的TF-IDF和TextRank都是无监督关键词提取算法，而卡方检验（CHI）则是有监督的，需要提供分类标注信息。</p>\n<p>为什么需要呢？在文本分类任务中，挑选关键词就得为了分类任务服务，而不仅仅是挑选出一种直观上看着重要的词。</p>\n<p>卡方检验本质上在检验“词和某个类别C相互独立”这个假设是否成立，和这个假设偏离越大，就越说明这个词和类别C暗中有一腿，那当然这个词就是关键词了。</p>\n<p>计算一个词Wi和一个类别Cj的卡方值，需要统计四个值：</p>\n<ol>\n<li>类别为 Cj 的文本中出现词Wi 的文本数 A；</li>\n<li>词 Wi 在非 Cj 的文本中出现的文本数 B ；</li>\n<li>类别为Cj的文本中没有出现 Wi的文本数 C ；</li>\n<li>词Wi 在非Cj 的文本中没有出现的文本数 D 。</li>\n</ol>\n<p>听起来有点绕，我把它画成一个表格更加一目了然。<br />\n<img src=\"https://static001.geekbang.org/resource/image/fa/87/fa389dccac533dccfe9ebc028a37d987.png?wh=1006*338\" alt=\"\" /></p>\n<p>然后按照如下公式计算每一个词和每一个类别的卡方值：<br />\n<img src=\"https://static001.geekbang.org/resource/image/f4/c5/f49825884771fb06ab9f1a88bae0d2c5.png?wh=806*142\" alt=\"\" /></p>\n<p>关于这个卡方值计算，我在这里说明几点：</p>\n<ol>\n<li>每个词和每个类别都要计算，只要对其中一个类别有帮助的词都应该留下；</li>\n<li>由于是比较卡方值的大小，所以公式中的N可以不参与计算，因为它对每个词都一样，就是总的文本数；</li>\n<li>卡方值越大，意味着偏离“词和类别相互独立”的假设越远，靠“词和类别互相不独立”这个备择假设越近。</li>\n</ol>\n<h3>2 信息增益</h3>\n<p>IG 即 Information Gain，信息增益，也是一种有监督的关键词选择方法，也需要有标注信息。要理解信息增益，理解了信息熵就差不多了。</p>\n<p>信息熵，一批文本被标注了类别，那么任意挑出一条文本问你，“猜猜这是什么类别？”如果原来每个类别的文本数量都一样，那你肯定最不好猜，如果其中一个类别的文本C数远远多于其他类别，那么你猜这条文本属于类别C就很可能猜对。这两个情况区别就在于信息熵不同：</p>\n<ol>\n<li>各个类别的文本数量差不多时，信息熵就比较大。</li>\n<li>其中少数类别的文本数量明显较多时，信息熵就较小。</li>\n</ol>\n<p>进一步再想一件事，如果从这一堆文本中再挑出包含有词W的文本数，再来猜任意一条文本的类别时，仍然会有上面两种情况。这时候考虑一个情况：如果在整个文本上的情况是1，但挑出包含词W后的情况变成2了，那么你想，这个词W是不是非常有用？因为有了它，我们就能以较高的成功率猜对任意一条文本的类别了。</p>\n<p>对，上面这个思考过程就是信息增益的思想，信息增益计算也是分成三步：</p>\n<ol>\n<li>统计全局文本的信息熵；</li>\n<li>统计每个词的条件熵，就是知道了一个词后再统计文本的信息熵，只不过这里要分别计算包含词和不包含词两部分的信息熵，再按照各自文本比例加权平均；</li>\n<li>两者相减就是每个词的信息增益。</li>\n</ol>\n<p>信息增益应用最广就是数据挖掘中的决策树分类算法，经典的决策树分类算法挑选分裂节点时就是计算各个属性的信息增益，始终挑选信息增益最大的节点作为分裂节点。</p>\n<p>卡方检验和信息增益不同之处在于：前者是针对每一个行为单独筛选一套标签出来，后者是全局统一筛选。</p>\n<p>这些方法都是在离线阶段批量完成的，把用户的画像生成配置成离线任务，每天更新一遍，次日就可以使用新的用户画像。</p>\n<p>那么对于一个新用户，能不能在他刚刚进入产品时就能够快速生成一个简单的画像呢？答案是：当然可以。这在后面的专栏中会讲到的 MAB 问题。</p>\n<h2>总结</h2>\n<p>用户画像对于推荐系统还是非常必要的，而产品中属文本数据最多，那如何用文本数据构建出用户的画像内容呢？</p>\n<p>本文按照如下步骤梳理了这一过程：</p>\n<ol>\n<li>分析用户的文本和物品的文本，使其结构化；</li>\n<li>为用户挑选有信息量的结构化数据，作为其画像内容。</li>\n</ol>\n<p>其中，我们提出了把为用户挑选画像标签看成是特征选择问题，除了卡方检验和信息增益，你还知道有哪些特征选择方法呢？欢迎留言一起讨论。</p>\n<p>感谢你的收听，我们下次再见。</p>\n<p><img src=\"https://static001.geekbang.org/resource/image/87/b0/873b086966136189db14874181823fb0.jpg?wh=1110*549\" alt=\"\" /></p>\n","neighbors":{"left":{"article_title":"04 | 画鬼容易画人难：用户画像的“能”和“不能”","id":4574},"right":{"article_title":"06 | 超越标签的内容推荐系统","id":4674}},"comments":[{"had_liked":false,"id":3925,"user_name":"张哲","can_delete":false,"product_type":"c1","uid":1057798,"ip_address":"","ucode":"52B65BE09849FC","user_header":"https://static001.geekbang.org/account/avatar/00/10/24/06/f0fe5cb5.jpg","comment_is_top":false,"comment_ctime":1520989945,"is_pvip":false,"replies":[{"id":"829","content":"慢慢享用，嚼碎了再吞。","user_name":"作者回复","user_name_real":"刑无刀","uid":"1005376","ctime":1521039874,"ip_address":"","comment_id":3925,"utype":1}],"discussion_count":1,"race_medal":0,"score":"126075041529","product_id":100005101,"comment_content":"这一期信息量好大……","like_count":30,"discussions":[{"author":{"id":1005376,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/57/40/777bfe30.jpg","nickname":"刑无刀","note":"","ucode":"496201BF63D49D","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":416115,"discussion_content":"慢慢享用，嚼碎了再吞。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1521039874,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":3948,"user_name":"林彦","can_delete":false,"product_type":"c1","uid":1032615,"ip_address":"","ucode":"5094CC6ED7B40C","user_header":"https://static001.geekbang.org/account/avatar/00/0f/c1/a7/5e66d331.jpg","comment_is_top":false,"comment_ctime":1521039292,"is_pvip":false,"replies":[{"id":"876","content":"你一定是个学霸，向你致敬。<br><br>1. 这里的聚类是指的传统数据挖掘中的聚类。基于距离或者密度等。如kmeans。<br>2. 停用词要去掉。lda在预测阶段也要迭代的，而不是计算相似度。<br>3. 你若理解了，就是晴天。","user_name":"作者回复","user_name_real":"刑无刀","uid":"1005376","ctime":1521119072,"ip_address":"","comment_id":3948,"utype":1}],"discussion_count":1,"race_medal":0,"score":"44470712252","product_id":100005101,"comment_content":"谢谢刑无刀老师的分享。建议各种步骤和场景的工业化工具及其性能和便利，对我们读者提供了不小的价值。<br><br>1. 词嵌入里面提到学习到的包含更多语义信息的(新)词向量可以“用于聚类，会得到比使用词向量聚类更好的语义聚类效果”。这里的聚类是指文中之前提到的LDA等聚类模型来找出文章的主题吗？<br><br>2. “主题模型：从大量已有文本中学习主题向量，然后再预测新的文本在各个主题上的概率分布情况，也很实用，其实这也是一种聚类思想，主题向量也不是标签形式，也是用户画像的常用构成。”请问这里已有文中的主题向量中的主题词如果是通过LDA提取是不是需要有个停用词表排除那些所有文档中词频都很高的词？它不像TF-IDF会自动排除所有文档中词频高的词。 这种场景的聚类就是判别新的文本和哪些主题的文本比较相似（”距离“接近或主题”概率“较大），然后判别新的文本的主题？<br><br>3. ”向量中各个维度上的值大小代表了词包含各个语义的多少“ 有这句说明挺好的。我第一次阅读不太理解，后来查了一些文章，有一个解释我觉得比较直观，Word2Vec生成的向量值可以看成是N维语义空间(N个语义词)中的坐标值(每个坐标轴对应一个语义)。当2个词在同一个N维语义空间中的距离接近时，说明2个词的含义接近。","like_count":10,"discussions":[{"author":{"id":1005376,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/57/40/777bfe30.jpg","nickname":"刑无刀","note":"","ucode":"496201BF63D49D","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":416130,"discussion_content":"你一定是个学霸，向你致敬。\n\n1. 这里的聚类是指的传统数据挖掘中的聚类。基于距离或者密度等。如kmeans。\n2. 停用词要去掉。lda在预测阶段也要迭代的，而不是计算相似度。\n3. 你若理解了，就是晴天。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1521119072,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":3961,"user_name":"Drxan","can_delete":false,"product_type":"c1","uid":1057325,"ip_address":"","ucode":"96FB51264DBD21","user_header":"","comment_is_top":false,"comment_ctime":1521076387,"is_pvip":false,"replies":[{"id":"871","content":"知识星球(原来叫小密圈)搜ResysChina。","user_name":"作者回复","user_name_real":"刑无刀","uid":"1005376","ctime":1521117994,"ip_address":"","comment_id":3961,"utype":1}],"discussion_count":1,"race_medal":0,"score":"40175782051","product_id":100005101,"comment_content":"无刀老师，能否建立个微信群啊，大家可以对您每期的课程内容一起学习讨论","like_count":9,"discussions":[{"author":{"id":1005376,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/57/40/777bfe30.jpg","nickname":"刑无刀","note":"","ucode":"496201BF63D49D","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":416137,"discussion_content":"知识星球(原来叫小密圈)搜ResysChina。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1521117994,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":3926,"user_name":"jt120","can_delete":false,"product_type":"c1","uid":1058471,"ip_address":"","ucode":"245268E9108D54","user_header":"https://static001.geekbang.org/account/avatar/00/10/26/a7/177581b8.jpg","comment_is_top":false,"comment_ctime":1520990276,"is_pvip":false,"replies":[{"id":"828","content":"用Word2vec跑出一个结果你就明白了，设定k维的话，你会得到一个k维向量，每个维度上都有值的。","user_name":"作者回复","user_name_real":"刑无刀","uid":"1005376","ctime":1521039825,"ip_address":"","comment_id":3926,"utype":1}],"discussion_count":2,"race_medal":0,"score":"22995826756","product_id":100005101,"comment_content":"针对embedding，我不太理解，之前理解就是一种映射关系，但文里为什么说结果是稠密的，这是怎么保证的","like_count":5,"discussions":[{"author":{"id":1005376,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/57/40/777bfe30.jpg","nickname":"刑无刀","note":"","ucode":"496201BF63D49D","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":416116,"discussion_content":"用Word2vec跑出一个结果你就明白了，设定k维的话，你会得到一个k维向量，每个维度上都有值的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1521039825,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1266620,"avatar":"https://static001.geekbang.org/account/avatar/00/13/53/bc/72baeee8.jpg","nickname":"林黛玉","note":"","ucode":"F8507366012881","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":2387,"discussion_content":"映射也有稀疏和稀疏。如果通过one-hot编码直接将句子变成向量，可能就几万维；而用word2vec，可能仅需要300维，且捕捉到的信息更多。前者是将信息「句子」从低维打向高维，而后者是将信息「句子」从高维打向低维。前者是稀疏的，后者是稠密的。","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1563531441,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":4672,"user_name":"三竹先生","can_delete":false,"product_type":"c1","uid":1058845,"ip_address":"","ucode":"50E567B1F6CBA9","user_header":"https://static001.geekbang.org/account/avatar/00/10/28/1d/b7cf921d.jpg","comment_is_top":false,"comment_ctime":1522326318,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"14407228206","product_id":100005101,"comment_content":"真的好难啊，邢老师能多结合一下例子吗？方便理解😂😂😂","like_count":3},{"had_liked":false,"id":4258,"user_name":"行行行","can_delete":false,"product_type":"c1","uid":1066121,"ip_address":"","ucode":"2A8481C263FBD2","user_header":"","comment_is_top":false,"comment_ctime":1521793291,"is_pvip":false,"replies":[{"id":"993","content":"1.是<br>2.是<br>3.用你文本中出现的词，去查询通过word2vec计算得到的相似词，从而实现了“扩展”，原来只有两个词，现在增加了几个相似词，变成了4个词。","user_name":"作者回复","user_name_real":"刑无刀","uid":"1005376","ctime":1521804785,"ip_address":"","comment_id":4258,"utype":1}],"discussion_count":2,"race_medal":0,"score":"14406695179","product_id":100005101,"comment_content":"老师，关于word2vec，有几个疑问<br>1  工业上如果通过word2vec得到文档的向量呢，是用累加一个文档中各个词的词向量得到的稠密向量表示吗<br>2 用于聚类，是用上面得到的文档向量来做吗<br>3 到底是如何通过计算词和词之间的相似度，扩充标签的呢","like_count":3,"discussions":[{"author":{"id":1005376,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/57/40/777bfe30.jpg","nickname":"刑无刀","note":"","ucode":"496201BF63D49D","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":416269,"discussion_content":"1.是\n2.是\n3.用你文本中出现的词，去查询通过word2vec计算得到的相似词，从而实现了“扩展”，原来只有两个词，现在增加了几个相似词，变成了4个词。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1521804785,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1266620,"avatar":"https://static001.geekbang.org/account/avatar/00/13/53/bc/72baeee8.jpg","nickname":"林黛玉","note":"","ucode":"F8507366012881","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":2388,"discussion_content":"词向量生成的词空间，可以看到各个词之间的位置关系，从而表征词与词的相似度，那么就可以认为某些词是一类、同义的、近似的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563531591,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":3924,"user_name":"jt120","can_delete":false,"product_type":"c1","uid":1058471,"ip_address":"","ucode":"245268E9108D54","user_header":"https://static001.geekbang.org/account/avatar/00/10/26/a7/177581b8.jpg","comment_is_top":false,"comment_ctime":1520989912,"is_pvip":false,"replies":[{"id":"830","content":"这种场景下，用户也更有耐心一些，可以多向用户询问他的诉求，更像一个辅助决策系统，而不是一个纯粹的推荐系统。","user_name":"作者回复","user_name_real":"刑无刀","uid":"1005376","ctime":1521039969,"ip_address":"","comment_id":3924,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14405891800","product_id":100005101,"comment_content":"上面提到的都是主流的推荐系统方法，例如电影，图书，新闻这些经典场景。<br>但对于特殊商品，例如房子，明显和上面不同，低频，高价，并且房子的特征基本都是分类特征，针对这种场景，如何选择特征，如何推荐了？","like_count":3,"discussions":[{"author":{"id":1005376,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/57/40/777bfe30.jpg","nickname":"刑无刀","note":"","ucode":"496201BF63D49D","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":416114,"discussion_content":"这种场景下，用户也更有耐心一些，可以多向用户询问他的诉求，更像一个辅助决策系统，而不是一个纯粹的推荐系统。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1521039969,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":147060,"user_name":"🐱无限大人🐱","can_delete":false,"product_type":"c1","uid":1728006,"ip_address":"","ucode":"AB9947A9BECA71","user_header":"https://static001.geekbang.org/account/avatar/00/1a/5e/06/8de84ec3.jpg","comment_is_top":false,"comment_ctime":1572782146,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10162716738","product_id":100005101,"comment_content":"这篇好干，得好好啃一下","like_count":2},{"had_liked":false,"id":114483,"user_name":"张苗","can_delete":false,"product_type":"c1","uid":1282008,"ip_address":"","ucode":"60743B9279FED5","user_header":"https://static001.geekbang.org/account/avatar/00/13/8f/d8/47c24ec8.jpg","comment_is_top":false,"comment_ctime":1563323981,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10153258573","product_id":100005101,"comment_content":"这一节都是自然语言处理的基本知识，幸好毕业是做的这块，不然够我喝一壶~😂","like_count":2},{"had_liked":false,"id":109087,"user_name":"漂泊的小飘","can_delete":false,"product_type":"c1","uid":1222578,"ip_address":"","ucode":"25C0CA4887D8AD","user_header":"https://static001.geekbang.org/account/avatar/00/12/a7/b2/274a4192.jpg","comment_is_top":false,"comment_ctime":1561959375,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10151893967","product_id":100005101,"comment_content":"幸亏学过人工智能，不然这一章够我喝一壶了","like_count":2},{"had_liked":false,"id":27137,"user_name":"涛","can_delete":false,"product_type":"c1","uid":1202964,"ip_address":"","ucode":"E2DE6CF556C2B6","user_header":"https://static001.geekbang.org/account/avatar/00/12/5b/14/a1567454.jpg","comment_is_top":false,"comment_ctime":1537838380,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"10127772972","product_id":100005101,"comment_content":"我有一个比较困扰我的问题就是信息增益和WOE、IV之间的区别，我不明白为什么金融欺诈中选取重要性特征都用WOE和IV 方法，而其它领域很少看见用这两个方法进行筛选特征的，谢谢！","like_count":2,"discussions":[{"author":{"id":1364730,"avatar":"https://static001.geekbang.org/account/avatar/00/14/d2/fa/ff691ae0.jpg","nickname":"KongTzeSing","note":"","ucode":"13FCCB30ADDD06","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":351576,"discussion_content":"同问","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1614332477,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":198916,"user_name":"晨晓","can_delete":false,"product_type":"c1","uid":1811062,"ip_address":"","ucode":"8AC664799E5CDD","user_header":"https://static001.geekbang.org/account/avatar/00/1b/a2/76/bdea7aa1.jpg","comment_is_top":false,"comment_ctime":1585473408,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5880440704","product_id":100005101,"comment_content":"可以给一些表设计的案例","like_count":1},{"had_liked":false,"id":99746,"user_name":"wjj","can_delete":false,"product_type":"c1","uid":1516095,"ip_address":"","ucode":"752C7AE3E3FC57","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/pIic2qhfe5ZpmQmSdxjrwVoGaZ7xLxwLSSdeZjicqtTV1E2Kl7sFGutCOW71N5ulRAXSgItuZN9I7Xkeg4icgdFSA/132","comment_is_top":false,"comment_ctime":1559290352,"is_pvip":false,"replies":[{"id":"36013","content":"看情况。","user_name":"作者回复","user_name_real":"刑无刀","uid":"1005376","ctime":1559490034,"ip_address":"","comment_id":99746,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5854257648","product_id":100005101,"comment_content":"老师，TF—IDF中的Top K 排序，实际工作中超参数K值一般取多少？","like_count":1,"discussions":[{"author":{"id":1005376,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/57/40/777bfe30.jpg","nickname":"刑无刀","note":"","ucode":"496201BF63D49D","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":452251,"discussion_content":"看情况。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1559490034,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":66161,"user_name":"Kendal","can_delete":false,"product_type":"c1","uid":1400355,"ip_address":"","ucode":"93E518D5DFFF9A","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIFDmC78F2ciaDVn24E36emK6mE43ZsRxeLeGHVM9IqeVn0uQabzO2Kdc9JNTOKBUeghJbOBpww2EA/132","comment_is_top":false,"comment_ctime":1549887428,"is_pvip":false,"replies":[{"id":"27308","content":"文中有详细介绍。后续图书中有例子。","user_name":"作者回复","user_name_real":"刑无刀","uid":"1005376","ctime":1552322358,"ip_address":"","comment_id":66161,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5844854724","product_id":100005101,"comment_content":"邢老师你好，我是初学者，第二部分把物品的结构化信息传递给用户这里，您把他看成是一个特征选取的问题。这里没太看懂，还望能够详细解释下。<br>假设用户A和我们给他展现的100个物品有了2类操作（消费10，没消费90）。我的理解是这边每个被消费的物品（10个）都有自己的特征向量（假设n维），我们的任务是找到这n维里面到底哪m维是用户真正关心的。这个理解对吗？然后如何选取到这m维，并把它们融合到用户自己原来的向量中又是如何具体实现的？<br>谢谢指点！","like_count":1,"discussions":[{"author":{"id":1005376,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/57/40/777bfe30.jpg","nickname":"刑无刀","note":"","ucode":"496201BF63D49D","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438733,"discussion_content":"文中有详细介绍。后续图书中有例子。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1552322358,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":45552,"user_name":"预见","can_delete":false,"product_type":"c1","uid":1200455,"ip_address":"","ucode":"39DEAEDE1BDB96","user_header":"https://static001.geekbang.org/account/avatar/00/12/51/47/6875debd.jpg","comment_is_top":false,"comment_ctime":1543671162,"is_pvip":false,"replies":[{"id":"17028","content":"谢谢你的建议，采纳到图书中。","user_name":"作者回复","user_name_real":"刑无刀","uid":"1005376","ctime":1544209143,"ip_address":"","comment_id":45552,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5838638458","product_id":100005101,"comment_content":"我来补充林彦同学的第三点，”向量中各个维度上的值大小代表了词包含各个语义的多少“ 。第一遍看到这句话的时候我没有看懂，查阅资料后才明白。比如使用word embedding，一个单词“北京”，用5维向量“首都，中国，大城市，南方，没雾霾”来表示的话，他的向量形式就是[1, 1, 1, 0, 0]，各个维度的值的大小代表了词包含各个语义的多少。老师要是讲的再细致一点，给出示例就更好了","like_count":1,"discussions":[{"author":{"id":1005376,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/57/40/777bfe30.jpg","nickname":"刑无刀","note":"","ucode":"496201BF63D49D","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":431090,"discussion_content":"谢谢你的建议，采纳到图书中。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1544209143,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":5854,"user_name":"top savor","can_delete":false,"product_type":"c1","uid":1086903,"ip_address":"","ucode":"44D02E980C10D0","user_header":"https://static001.geekbang.org/account/avatar/00/10/95/b7/665eb321.jpg","comment_is_top":false,"comment_ctime":1524048624,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5819015920","product_id":100005101,"comment_content":"老师您好，我是初学者，感觉学到很多，但还是有些疑问：请问用户画像如果是用户本身的特征（比如个性签名的文本向量化）+物品端的特征，那在做匹配计算相似度的时候，两者的向量维度岂不是不一样？ ","like_count":1},{"had_liked":false,"id":304710,"user_name":"冯广","can_delete":false,"product_type":"c1","uid":1402435,"ip_address":"","ucode":"B8B780C2AE34E7","user_header":"https://static001.geekbang.org/account/avatar/00/15/66/43/c48c0c0e.jpg","comment_is_top":false,"comment_ctime":1627560493,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1627560493","product_id":100005101,"comment_content":"“通过 TextRank 计算后的词语权重，呈现出这样的特点：那些有共现关系的会互相支持对方成为关键词。”老师可以帮忙推演一下么，对于非技术人员理解这个逻辑还是有点难","like_count":0},{"had_liked":false,"id":288296,"user_name":"小青菜","can_delete":false,"product_type":"c1","uid":2245884,"ip_address":"","ucode":"AB8F9606B4D15C","user_header":"https://static001.geekbang.org/account/avatar/00/22/44/fc/378d2dec.jpg","comment_is_top":false,"comment_ctime":1618398221,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1618398221","product_id":100005101,"comment_content":"有了基本的机器学习常识,发现大佬的牛掰之处","like_count":0},{"had_liked":false,"id":275751,"user_name":"Mew151","can_delete":false,"product_type":"c1","uid":1002201,"ip_address":"","ucode":"D4793F5874F345","user_header":"https://static001.geekbang.org/account/avatar/00/0f/4a/d9/75dd7cf9.jpg","comment_is_top":false,"comment_ctime":1611658914,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1611658914","product_id":100005101,"comment_content":"建议把文中提及的每块内容举个小例子会更好的帮助读者理解，比如这块：<br><br>1. 把物品的结构化内容看成文档；<br>2. 把用户对物品的行为看成是类别；<br>3. 每个用户看见过的物品就是一个文本集合；<br>4. 在这个文本集合上使用特征选择算法选出每个用户关心的东西。<br>————————————————<br>第一点，假设一个物品是“耐克运动鞋”，那么它结构化后的内容可能是“服装”、“时尚”、“运动”等等，那么它对应的文档就是[“服装”、“时尚”、“运动”]么？这里的文档具体含义是指什么呢？<br>第二点，用户对物品的行为举例子可能有：“浏览过”、“下单未支付”、“购买过”等等，这样么？<br>第三点，是用户看见过的物品作为文本集合，还是物品的文档放在一起作为文本集合呢？","like_count":0},{"had_liked":false,"id":202647,"user_name":"Hansee","can_delete":false,"product_type":"c1","uid":1688145,"ip_address":"","ucode":"71B1D8B03B3668","user_header":"https://static001.geekbang.org/account/avatar/00/19/c2/51/fc8841dd.jpg","comment_is_top":false,"comment_ctime":1586042008,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1586042008","product_id":100005101,"comment_content":"好扎实的一章！","like_count":0},{"had_liked":false,"id":161168,"user_name":"雨幕下的稻田","can_delete":false,"product_type":"c1","uid":1388799,"ip_address":"","ucode":"1FBFF3187AE9C4","user_header":"https://static001.geekbang.org/account/avatar/00/15/30/ff/b3e54147.jpg","comment_is_top":false,"comment_ctime":1576136286,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1576136286","product_id":100005101,"comment_content":"老师问一下，我本身是做新闻的<br>1、类别Cj是不是可以理解为点击和未点击<br>2、词Wi就是doc的特征或者关键词<br>3、点击中包含关键词的，属于正例，点击不包含关键词的是反例<br>     没点击中不包含关键词的，属于正例，没点击包含关键词的是反例<br>4、整个过程是基于doc已有特征的有监督学习","like_count":0},{"had_liked":false,"id":153459,"user_name":"夜雨声烦","can_delete":false,"product_type":"c1","uid":1349749,"ip_address":"","ucode":"87D8DB1E32522A","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK6mh3xlaMoGtWjmVJh2LutdLcQcPbKNjRlVru3bx8ynPhgwuGhhdzTkwEMoXbvBtgkcDSfom1kZg/132","comment_is_top":false,"comment_ctime":1574238783,"is_pvip":false,"replies":[{"id":"59187","content":"谢谢。","user_name":"作者回复","user_name_real":"刑无刀","uid":"1005376","ctime":1574394415,"ip_address":"","comment_id":153459,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1574238783","product_id":100005101,"comment_content":"挺好的  了解了好多","like_count":0,"discussions":[{"author":{"id":1005376,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/57/40/777bfe30.jpg","nickname":"刑无刀","note":"","ucode":"496201BF63D49D","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":475174,"discussion_content":"谢谢。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1574394415,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":136363,"user_name":"赖春苹","can_delete":false,"product_type":"c1","uid":1343949,"ip_address":"","ucode":"1B637D46549A21","user_header":"","comment_is_top":false,"comment_ctime":1569416198,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1569416198","product_id":100005101,"comment_content":"感觉还是有一些地方理解不了，看了两三遍还是理解不了：<br>1. 上一节提到的用户画像，是这样用的：&lt;i1,i2,i3...&gt; 点积&lt;u1,u2,u3...&gt;，即用户向量和物品向量做点积，得分高的话说明适合推荐；<br>2. 这一节讲的，先分别对用户内容和物品内容做文本挖掘，得到物品向量后再对物品向量进行特征选择？（特征选择时需要用到用户的行为标签），我理解的特征选择，就是从物品向量里选择一部分和用户行为结果关联度高的特征，可是，这些特征怎么反映到用户侧呢？这里一直搞不懂，因为从物品里挖出来的重要特征，在用户侧向量里不一定有对应的那一项啊，没有对应的项就没办法进行第1步里的点积计算呀……还请明白人帮忙解答下，真的困扰好久啊~","like_count":0,"discussions":[{"author":{"id":1096512,"avatar":"https://static001.geekbang.org/account/avatar/00/10/bb/40/b1412e85.jpg","nickname":"Gnix","note":"","ucode":"F45A2DCCE3C6DE","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":296643,"discussion_content":"我的理解是：\n1. 正确\n2. 做特征选择时，物品和用户是独立的。最终的点积不是物品和用户的点积，而是物品和用户画像的点积","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1596612131,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":130923,"user_name":"Yiliu","can_delete":false,"product_type":"c1","uid":1068884,"ip_address":"","ucode":"2CF20B138244B7","user_header":"https://static001.geekbang.org/account/avatar/00/10/4f/54/552bde40.jpg","comment_is_top":false,"comment_ctime":1567577588,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1567577588","product_id":100005101,"comment_content":"看完这期课程第一遍的感觉就是😵，只能多刷几遍了","like_count":0},{"had_liked":false,"id":114267,"user_name":"nananana","can_delete":false,"product_type":"c1","uid":1604861,"ip_address":"","ucode":"DA391823D07FE6","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epJAgQdLmzu82k7bl8tOyzCRaLvYNIb7p6icNYnrQLOqLvg3flS10vEe90HlUjc6ia5Pv1ib11XfI8ibQ/132","comment_is_top":false,"comment_ctime":1563263537,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1563263537","product_id":100005101,"comment_content":"老师您好，我想问一下，用户挑选画像标签看成是特征选择问题，选择的时候，比如使用卡方验证选择，对每一个用户的数据量有什么要求吗？","like_count":0},{"had_liked":false,"id":102172,"user_name":"对白","can_delete":false,"product_type":"c1","uid":1268797,"ip_address":"","ucode":"3183E5ADBC794B","user_header":"https://static001.geekbang.org/account/avatar/00/13/5c/3d/e8325811.jpg","comment_is_top":false,"comment_ctime":1560156097,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1560156097","product_id":100005101,"comment_content":"刑老师您好，看完这一篇文章收获很多。首先我来谈谈自己的理解，以往我们知道某一个用户喜欢女装或球类物品其实就是从这个用户看过的物品组成的文档集合中使用比如信息增益的特征选择算法选出用户关心的东西，那么为什么说信息增益可以寻找到用户关心的东西呢？信息增益等于由于特征A而使得训练数据的分类不确定性减少的程度，在推荐系统中特征就是关键词，训练数据就是物品文档，那么信息增益在这里就是由于关键词A而使得物品消费不确定性减少的程度，自然这个关键词A就是用户关心的东西了，还有我觉得把标签选择这个标题改成物品画像标签选择更清楚一点。","like_count":0},{"had_liked":false,"id":89855,"user_name":"shangqiu86","can_delete":false,"product_type":"c1","uid":1514817,"ip_address":"","ucode":"07D376EEC21BE4","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/qRjoqWIGC6tpmKZBGTxjQKC9cbz9XLhw2nF1c74R4icFOYOdVO4iaeQEQDqEvmbicxn6HEc4SU8kpkwVaO5nABMug/132","comment_is_top":false,"comment_ctime":1556284174,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1556284174","product_id":100005101,"comment_content":"老师，你好，讲信息熵的时候“这时候考虑一个情况：如果在整个文本上的情况是 1，但挑含包含词 W 后的情况变成 2了” 这里从1变到2的是什么呢？是信息熵吗？我理解如果词W是类别重要特征的话，信息熵应该是变小了啊，可能我蒙住了，望解答，或者其他同学也可以留言帮我解答，我会看课程下面的每个留言！<br><br>极客时间版权所有: https:&#47;&#47;time.geekbang.org&#47;column&#47;article&#47;4635”","like_count":0},{"had_liked":false,"id":81238,"user_name":"lone","can_delete":false,"product_type":"c1","uid":1399722,"ip_address":"","ucode":"5B804EBA0F79C8","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eoPFGq8pz3Bn1pjepWJHS9bunSvpRRUauVSTFf7awMN71PciaBfIgqhOEl3ib8bubXAPmgN46Fkic76A/132","comment_is_top":false,"comment_ctime":1553840038,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"1553840038","product_id":100005101,"comment_content":"在一篇文字中反复出现的词会更重要，在所有文本中都出现的词更不重要   这个更不重要是为什么啊？","like_count":0,"discussions":[{"author":{"id":1758279,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/d4/47/6d9f2da6.jpg","nickname":"Miracle","note":"","ucode":"74116B4D0C0760","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":375380,"discussion_content":"tf-idf的思想是确定文章的关键词，而一篇文章的关键词，就是希望在该文章中多次出现， 但是在其他文章中尽量的少出现，这样才能代表具体的某篇文章呀","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1621597428,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1649685,"avatar":"https://static001.geekbang.org/account/avatar/00/19/2c/15/5f30a666.jpg","nickname":"看那雨","note":"","ucode":"652641FCAFFB17","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":7563,"discussion_content":"就是比如一些 好的，没问题，这，怎么--- 这些词在所有文本中几乎都会出现，但是对于文本分类或者实体识别没啥用","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567565621,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":72351,"user_name":"Ann","can_delete":false,"product_type":"c1","uid":1402306,"ip_address":"","ucode":"D7E9CDF6236324","user_header":"https://static001.geekbang.org/account/avatar/00/15/65/c2/8ade8f57.jpg","comment_is_top":false,"comment_ctime":1551594821,"is_pvip":false,"replies":[{"id":"27310","content":"知识星球APP中搜resyschina。","user_name":"作者回复","user_name_real":"刑无刀","uid":"1005376","ctime":1552322432,"ip_address":"","comment_id":72351,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1551594821","product_id":100005101,"comment_content":"老师，求微信交流群 进入组织","like_count":0,"discussions":[{"author":{"id":1005376,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/57/40/777bfe30.jpg","nickname":"刑无刀","note":"","ucode":"496201BF63D49D","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":441553,"discussion_content":"知识星球APP中搜resyschina。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1552322432,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":53058,"user_name":"Saralu","can_delete":false,"product_type":"c1","uid":1058033,"ip_address":"","ucode":"D6175A74791C12","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eqibWhwgaicVClk15fcHmOhV1okgUC6bBN2c137ItzvAOsOO9Rmic9t0roicky1r96IHrKFQlvk5dVCuQ/132","comment_is_top":false,"comment_ctime":1545576826,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1545576826","product_id":100005101,"comment_content":"词向量的稠密是针对于tfidf, bool等模型说的，这些属于稀疏模型，特征向量的维度等于词典中单词的个数，一个向量中大部分维度上为零，词向量维度较小，每个维度上都有值","like_count":0},{"had_liked":false,"id":48488,"user_name":"无法言喻.","can_delete":false,"product_type":"c1","uid":1322328,"ip_address":"","ucode":"7F375BE388D4FC","user_header":"https://static001.geekbang.org/account/avatar/00/14/2d/58/aa35c402.jpg","comment_is_top":false,"comment_ctime":1544451695,"is_pvip":false,"replies":[{"id":"17985","content":"聚类不需要人标注，分类则需要。","user_name":"作者回复","user_name_real":"刑无刀","uid":"1005376","ctime":1544798400,"ip_address":"","comment_id":48488,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1544451695","product_id":100005101,"comment_content":"老师，主题模型和文本都是通过分类或者聚类算法得到， 有什么区别呢？","like_count":0,"discussions":[{"author":{"id":1005376,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/57/40/777bfe30.jpg","nickname":"刑无刀","note":"","ucode":"496201BF63D49D","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":432204,"discussion_content":"聚类不需要人标注，分类则需要。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1544798400,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":33265,"user_name":"Virgil 阿城","can_delete":false,"product_type":"c1","uid":1172778,"ip_address":"","ucode":"308AA431057EC7","user_header":"https://static001.geekbang.org/account/avatar/00/11/e5/2a/738f90d7.jpg","comment_is_top":false,"comment_ctime":1539768119,"is_pvip":false,"replies":[{"id":"13837","content":"这是个推导出来的公式。推导过程省略了。","user_name":"作者回复","user_name_real":"刑无刀","uid":"1005376","ctime":1542092365,"ip_address":"","comment_id":33265,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1539768119","product_id":100005101,"comment_content":"老师，依据《概率与统计》教材中，卡方分布的卡方值= 累加（(观察值 - 期望值)&#47;期望值））和您公式里的结果对不上。<br>我猜如果可以应该也是能相互推导，请问能否解释下具体原因？","like_count":0,"discussions":[{"author":{"id":1005376,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/57/40/777bfe30.jpg","nickname":"刑无刀","note":"","ucode":"496201BF63D49D","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":426958,"discussion_content":"这是个推导出来的公式。推导过程省略了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1542092365,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":28263,"user_name":"蘑菇酱","can_delete":false,"product_type":"c1","uid":1251943,"ip_address":"","ucode":"9BED7325DC6550","user_header":"https://static001.geekbang.org/account/avatar/00/13/1a/67/4008d168.jpg","comment_is_top":false,"comment_ctime":1538036207,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1538036207","product_id":100005101,"comment_content":"老师你好，在新闻推荐中，上文提到的卡方检验，类别是否可以看成对某篇文章点击或者对某篇文章不点击？词就是看成新闻的类别，关键词等","like_count":0},{"had_liked":false,"id":21820,"user_name":"江枫","can_delete":false,"product_type":"c1","uid":1058771,"ip_address":"","ucode":"4E70420DC5EEDB","user_header":"https://static001.geekbang.org/account/avatar/00/10/27/d3/1a98a899.jpg","comment_is_top":false,"comment_ctime":1535363099,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1535363099","product_id":100005101,"comment_content":"老师好，卡方检测，如果类别是正负反馈两类，那么AD-BC越大，说明越喜欢，反之越小甚至负数，说明不喜欢，那公式里的平方是否需要去掉？我理解做特征选择，正负两级都要保留，但是用来做用户偏好分析，还是要做极性判断。","like_count":0},{"had_liked":false,"id":7338,"user_name":"那年岁月","can_delete":false,"product_type":"c1","uid":1059923,"ip_address":"","ucode":"57E717ADD0FA73","user_header":"https://static001.geekbang.org/account/avatar/00/10/2c/53/8c2f976a.jpg","comment_is_top":false,"comment_ctime":1525404202,"is_pvip":false,"replies":[{"id":"2356","content":"可以求平均。","user_name":"作者回复","user_name_real":"刑无刀","uid":"1005376","ctime":1525914094,"ip_address":"","comment_id":7338,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1525404202","product_id":100005101,"comment_content":"问一下老师，w2v算法把文章中没一个词都做向量化，是把文章所有词向量累加还是等长关键词累加，如果把所有词累加，那么对篇幅小的文章不公平。","like_count":0,"discussions":[{"author":{"id":1005376,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/57/40/777bfe30.jpg","nickname":"刑无刀","note":"","ucode":"496201BF63D49D","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":417313,"discussion_content":"可以求平均。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1525914094,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":7003,"user_name":"mgxs","can_delete":false,"product_type":"c1","uid":1089417,"ip_address":"","ucode":"0D64B7684BAE58","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJwq0QDibn3ibtOYWoA2Z29D3PjWKbTbQsb0m2UHIuv9FqYKHBRjwIGicDwD81nCDDVDttek6AGUibAXg/132","comment_is_top":false,"comment_ctime":1525224350,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1525224350","product_id":100005101,"comment_content":"老师您好，我有一个疑问。最后特征选择后得到的特征直接作为用户画像，每个特征在用户画像里头的有具体的取值吗？还是都认为是1？ 后面推荐的时候如果对物品同样的结构化完，得到所有特征的结构化表示，物品的维度数和特征选择后的用户画像维度数不一样，那么如何基于相似度匹配来推荐呢？  ","like_count":0},{"had_liked":false,"id":5227,"user_name":"Lisa Li","can_delete":false,"product_type":"c1","uid":1046663,"ip_address":"","ucode":"4F7CF929FF4C6B","user_header":"https://static001.geekbang.org/account/avatar/00/0f/f8/87/0491e9e5.jpg","comment_is_top":false,"comment_ctime":1522900846,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1522900846","product_id":100005101,"comment_content":"“每次计算 K 个主题两两之间的平均相似度，选择一个较低的 K 值”<br>可以举个例子吗？","like_count":0},{"had_liked":false,"id":4822,"user_name":"尹士","can_delete":false,"product_type":"c1","uid":1074351,"ip_address":"","ucode":"5F7CE26E5845F3","user_header":"https://static001.geekbang.org/account/avatar/00/10/64/af/8ec3f465.jpg","comment_is_top":false,"comment_ctime":1522514856,"is_pvip":false,"replies":[{"id":"1286","content":"我似乎觉得工程中fasttext用得多些，尤其中小企业。","user_name":"作者回复","user_name_real":"刑无刀","uid":"1005376","ctime":1522596892,"ip_address":"","comment_id":4822,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1522514856","product_id":100005101,"comment_content":"Fasttext准确率跟cnn比，有差距，我的实验结果，不知邢老师参数如何设置的，可以工程中使用fasttext","like_count":0,"discussions":[{"author":{"id":1005376,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/57/40/777bfe30.jpg","nickname":"刑无刀","note":"","ucode":"496201BF63D49D","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":416550,"discussion_content":"我似乎觉得工程中fasttext用得多些，尤其中小企业。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1522596892,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":4670,"user_name":"吴文敏","can_delete":false,"product_type":"c1","uid":1003150,"ip_address":"","ucode":"A4303003E547D1","user_header":"https://static001.geekbang.org/account/avatar/00/0f/4e/8e/f4297447.jpg","comment_is_top":false,"comment_ctime":1522323488,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1522323488","product_id":100005101,"comment_content":"根据用户点击过的商品来做用户画像，假如采用信息增益的方法。可否理解成对每个用户计算 商品集的每个标签对用户点击因为的贡献率，然后选取贡献率超过某个阈值的标签作为用户标签。这种做法是不是只对点击过足够多商品的用户比较有效？","like_count":0},{"had_liked":false,"id":4465,"user_name":"大猫星球","can_delete":false,"product_type":"c1","uid":1020167,"ip_address":"","ucode":"7AB650AA9FECF8","user_header":"https://static001.geekbang.org/account/avatar/00/0f/91/07/17f9fe80.jpg","comment_is_top":false,"comment_ctime":1522119732,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1522119732","product_id":100005101,"comment_content":"这期涉及好几个算法，要消化消化","like_count":0},{"had_liked":false,"id":4255,"user_name":"行行行","can_delete":false,"product_type":"c1","uid":1066121,"ip_address":"","ucode":"2A8481C263FBD2","user_header":"","comment_is_top":false,"comment_ctime":1521791021,"is_pvip":false,"replies":[{"id":"994","content":"信息增益就是用来计算特征出现在正例和负例中的。先计算整体上正例负例的熵，再计算在已知特征的条件下正负例的熵，两者差值就是信息增益。","user_name":"作者回复","user_name_real":"刑无刀","uid":"1005376","ctime":1521804945,"ip_address":"","comment_id":4255,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1521791021","product_id":100005101,"comment_content":"老师我的理解是新增益越大特征越有区分度，如果这个特征在正例中，用户和这个特征越相关，但如果这个特征正例和负例中都有呢，该怎么算","like_count":0,"discussions":[{"author":{"id":1005376,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/57/40/777bfe30.jpg","nickname":"刑无刀","note":"","ucode":"496201BF63D49D","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":416267,"discussion_content":"信息增益就是用来计算特征出现在正例和负例中的。先计算整体上正例负例的熵，再计算在已知特征的条件下正负例的熵，两者差值就是信息增益。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1521804945,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":3981,"user_name":"清风六十五","can_delete":false,"product_type":"c1","uid":1057635,"ip_address":"","ucode":"0B69616A9D7AF9","user_header":"https://static001.geekbang.org/account/avatar/00/10/23/63/36cf68ef.jpg","comment_is_top":false,"comment_ctime":1521109284,"is_pvip":false,"replies":[{"id":"878","content":"欢迎传阅。","user_name":"作者回复","user_name_real":"刑无刀","uid":"1005376","ctime":1521162790,"ip_address":"","comment_id":3981,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1521109284","product_id":100005101,"comment_content":"简洁扼要，很不错","like_count":0,"discussions":[{"author":{"id":1005376,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/57/40/777bfe30.jpg","nickname":"刑无刀","note":"","ucode":"496201BF63D49D","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":416146,"discussion_content":"欢迎传阅。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1521162790,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":3949,"user_name":"ヾ(◍°∇°◍)ﾉﾞ","can_delete":false,"product_type":"c1","uid":1044175,"ip_address":"","ucode":"89545632BDA56E","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJOBwR7MCVqwZbPA5RQ2mjUjd571jUXUcBCE7lY5vSMibWn8D5S4PzDZMaAhRPdnRBqYbVOBTJibhJg/132","comment_is_top":false,"comment_ctime":1521042237,"is_pvip":false,"replies":[{"id":"874","content":"不用管知识点，先一把梭干起来。","user_name":"作者回复","user_name_real":"刑无刀","uid":"1005376","ctime":1521118166,"ip_address":"","comment_id":3949,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1521042237","product_id":100005101,"comment_content":"一到实际内容的时候，就会在听说过的和没听说过的，懂了的还有不知道是什么的知识点里无法理顺思路了","like_count":0,"discussions":[{"author":{"id":1005376,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/57/40/777bfe30.jpg","nickname":"刑无刀","note":"","ucode":"496201BF63D49D","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":416131,"discussion_content":"不用管知识点，先一把梭干起来。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1521118166,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":3945,"user_name":"Drxan","can_delete":false,"product_type":"c1","uid":1057325,"ip_address":"","ucode":"96FB51264DBD21","user_header":"","comment_is_top":false,"comment_ctime":1521037825,"is_pvip":false,"replies":[{"id":"875","content":"我貌似已经回复过你了。","user_name":"作者回复","user_name_real":"刑无刀","uid":"1005376","ctime":1521118721,"ip_address":"","comment_id":3945,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1521037825","product_id":100005101,"comment_content":"无刀老师，不好意思早晨地铁上把字打错了，请见谅！文中提到利用每个用户所见过的物品的文档集合来生成用户画像特征，一般是如何确定哪些物品是用户见过的呢？如果我只有用户的购买记录，而没有浏览、收藏等记录，那是否可以从用户没有购买过的商品中随机抽取部份商品作为负样本呢","like_count":0,"discussions":[{"author":{"id":1005376,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/57/40/777bfe30.jpg","nickname":"刑无刀","note":"","ucode":"496201BF63D49D","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":416129,"discussion_content":"我貌似已经回复过你了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1521118721,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":3939,"user_name":"莘哥（cheung！）","can_delete":false,"product_type":"c1","uid":1016341,"ip_address":"","ucode":"88AC75B3FB3D5C","user_header":"https://static001.geekbang.org/account/avatar/00/0f/82/15/abb7bfe3.jpg","comment_is_top":false,"comment_ctime":1521008938,"is_pvip":false,"replies":[{"id":"822","content":"这个貌似没有，但相关工具都有开源的。","user_name":"作者回复","user_name_real":"刑无刀","uid":"1005376","ctime":1521039515,"ip_address":"","comment_id":3939,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1521008938","product_id":100005101,"comment_content":"都有哪些成熟的用户画像开发框架呢？","like_count":0,"discussions":[{"author":{"id":1005376,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/57/40/777bfe30.jpg","nickname":"刑无刀","note":"","ucode":"496201BF63D49D","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":416126,"discussion_content":"这个貌似没有，但相关工具都有开源的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1521039515,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":3938,"user_name":"叶晓锋","can_delete":false,"product_type":"c1","uid":1059032,"ip_address":"","ucode":"7A84CE1DB4AA88","user_header":"https://static001.geekbang.org/account/avatar/00/10/28/d8/356428c2.jpg","comment_is_top":false,"comment_ctime":1521006943,"is_pvip":false,"replies":[{"id":"823","content":"对。特征化。","user_name":"作者回复","user_name_real":"刑无刀","uid":"1005376","ctime":1521039534,"ip_address":"","comment_id":3938,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1521006943","product_id":100005101,"comment_content":"重要的应该是把文本数据转换成机器能处理的量化数据","like_count":0,"discussions":[{"author":{"id":1005376,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/57/40/777bfe30.jpg","nickname":"刑无刀","note":"","ucode":"496201BF63D49D","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":416125,"discussion_content":"对。特征化。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1521039534,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":3937,"user_name":"叶晓锋","can_delete":false,"product_type":"c1","uid":1059032,"ip_address":"","ucode":"7A84CE1DB4AA88","user_header":"https://static001.geekbang.org/account/avatar/00/10/28/d8/356428c2.jpg","comment_is_top":false,"comment_ctime":1521006839,"is_pvip":false,"replies":[{"id":"827","content":"你得到了。","user_name":"作者回复","user_name_real":"刑无刀","uid":"1005376","ctime":1521039727,"ip_address":"","comment_id":3937,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1521006839","product_id":100005101,"comment_content":"文本来是非常重要的数据源，一般来说物品端的数据比较好控制，包括标题，描述，说明等，用户端的数据会少一些。","like_count":0,"discussions":[{"author":{"id":1005376,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/57/40/777bfe30.jpg","nickname":"刑无刀","note":"","ucode":"496201BF63D49D","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":416124,"discussion_content":"你得到了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1521039727,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":3931,"user_name":"微微一笑","can_delete":false,"product_type":"c1","uid":1057385,"ip_address":"","ucode":"0BC081CA190D44","user_header":"https://static001.geekbang.org/account/avatar/00/10/22/69/c85fdb98.jpg","comment_is_top":false,"comment_ctime":1520993644,"is_pvip":false,"replies":[{"id":"825","content":"LDA可以先试试，也不见得，不太短的话也挺好的。","user_name":"作者回复","user_name_real":"刑无刀","uid":"1005376","ctime":1521039608,"ip_address":"","comment_id":3931,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1520993644","product_id":100005101,"comment_content":"内容很精彩，很受启发。咨询一个问题：在短文本领域，不适合使用LDA吧？如果不适合,有什么替代方法吗？谢谢","like_count":0,"discussions":[{"author":{"id":1005376,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/57/40/777bfe30.jpg","nickname":"刑无刀","note":"","ucode":"496201BF63D49D","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":416119,"discussion_content":"LDA可以先试试，也不见得，不太短的话也挺好的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1521039608,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":3930,"user_name":"Drxan","can_delete":false,"product_type":"c1","uid":1057325,"ip_address":"","ucode":"96FB51264DBD21","user_header":"","comment_is_top":false,"comment_ctime":1520991965,"is_pvip":false,"replies":[{"id":"826","content":"那你首先需要的数据采集系统而不是推荐系统。可以从热门商品里面抽样作为负样本试试。","user_name":"作者回复","user_name_real":"刑无刀","uid":"1005376","ctime":1521039701,"ip_address":"","comment_id":3930,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1520991965","product_id":100005101,"comment_content":"无天老师，文中提到利用每个用户所见过的物品的文档集合来生成用户画像特征，一般是如何确定哪些物品是用户见过的呢？如果我只有用户的购买记录，而没有浏览、收藏等记录，那是否可以从用户没有购买过的商品中随机抽取部份商品作为负样本呢","like_count":0,"discussions":[{"author":{"id":1005376,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/57/40/777bfe30.jpg","nickname":"刑无刀","note":"","ucode":"496201BF63D49D","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":416118,"discussion_content":"那你首先需要的数据采集系统而不是推荐系统。可以从热门商品里面抽样作为负样本试试。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1521039701,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":3929,"user_name":"关羽","can_delete":false,"product_type":"c1","uid":1057179,"ip_address":"","ucode":"6FC2CDA20191DB","user_header":"https://static001.geekbang.org/account/avatar/00/10/21/9b/347301f6.jpg","comment_is_top":false,"comment_ctime":1520991016,"is_pvip":false,"replies":[{"id":"817","content":"一般是自然对数。这个不重要。","user_name":"作者回复","user_name_real":"刑无刀","uid":"1005376","ctime":1520996722,"ip_address":"","comment_id":3929,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1520991016","product_id":100005101,"comment_content":"老师，请问下IDF算法，log的底是什么？10？","like_count":0,"discussions":[{"author":{"id":1005376,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/57/40/777bfe30.jpg","nickname":"刑无刀","note":"","ucode":"496201BF63D49D","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":416117,"discussion_content":"一般是自然对数。这个不重要。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1520996722,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]}]}