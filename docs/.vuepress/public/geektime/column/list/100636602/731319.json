{"id":731319,"title":"再举几个例子","content":"<p>ChatGPT 和 Wolfram|Alpha 的工作方式截然不同，各有优势。为了理解 ChatGPT 可以如何利用 Wolfram|Alpha 的优势，让我们讨论 ChatGPT 本身并不能完全回答正确的一些情况。ChatGPT 像人类一样，经常在数学领域遇到困难。</p><p class=\"pic\"><img img=\"\" src=\"https://static001.geekbang.org/files/resource/ebook/100002/Images/image00170.jpeg\" alt=\"{%}\"></p><p>很有趣的文章式回答，但实际结果是错误的。</p><p class=\"pic\"><img img=\"\" src=\"https://static001.geekbang.org/files/resource/ebook/100002/Images/image00171.jpeg\" alt=\"{%}\"></p><p>如果让 ChatGPT“咨询”Wolfram|Alpha，它当然可以得到正确的答案。</p><p>让我们尝试一些稍微复杂的问题。</p><p class=\"pic\"><img img=\"\" src=\"https://static001.geekbang.org/files/resource/ebook/100002/Images/image00172.jpeg\" alt=\"{%}\"></p><p>乍一看，这个结果似乎很棒，我很容易相信它。然而，事实证明它是错误的，因为 Wolfram|Alpha 可以告诉我们如下答案。</p><p class=\"pic\"><img img=\"\" src=\"https://static001.geekbang.org/files/resource/ebook/100002/Images/image00173.jpeg\" alt=\"{%}\"></p><p>因此，使用（不能咨询 Wolfram|Alpha 的）ChatGPT 做数学作业可能不是一个好主意。它可以给你一个看似非常可信的答案。</p><p class=\"pic\"><img img=\"\" src=\"https://static001.geekbang.org/files/resource/ebook/100002/Images/image00174.jpeg\" alt=\"{%}\"></p><p>但是如果 ChatGPT 没有“真正理解数学”，就基本上不可能可靠地得出正确答案。所以，答案又是错误的。</p><p class=\"pic\"><img img=\"\" src=\"https://static001.geekbang.org/files/resource/ebook/100002/Images/image00175.jpeg\" alt=\"{%}\"></p><p>ChatGPT 甚至可以为“它得出答案的方式”（尽管并不是它所“做”的真正方式）编造一个非常像样的解释。此外，迷人（和有趣）的是，它给出的解释里存在不理解数学的人类可能会犯的错误。</p><p class=\"pic\"><img img=\"\" src=\"https://static001.geekbang.org/files/resource/ebook/100002/Images/image00176.jpeg\" alt=\"{%}\"></p><p>在各种各样的情况下，“不理解事物的含义”都可能会引起麻烦。</p><p class=\"pic\"><img img=\"\" src=\"https://static001.geekbang.org/files/resource/ebook/100002/Images/image00177.jpeg\" alt=\"{%}\"></p><p>听起来颇有说服力，但不正确。</p><!-- [[[read_end]]] --><p class=\"pic\"><img img=\"\" src=\"https://static001.geekbang.org/files/resource/ebook/100002/Images/image00178.jpeg\" alt=\"{%}\"></p><p>ChatGPT 似乎在某处正确地学习了这些基础数据，但它并没有充分“理解数据的含义”以正确地排列这些数字。</p><p class=\"pic\"><img img=\"\" src=\"https://static001.geekbang.org/files/resource/ebook/100002/Images/image00179.jpeg\" alt=\"{%}\"></p><p>是的，可以找到一种方法来“修复这个特定的 bug”。但问题在于，像 ChatGPT 这样基于生成语言的 AI 系统的基本思想并不适用于需要执行结构化计算任务的情况。换句话说，需要“修复”几乎无穷多的“bug”，才能追赶上 Wolfram|Alpha 以其结构化方式所能实现的几乎无穷小的成就。</p><p>“计算链”越复杂，就越有可能需要调用 Wolfram|Alpha 来正确处理。对于下面的问题，ChatGPT 给出了一个相当混乱的答案。</p><p class=\"pic\"><img img=\"\" src=\"https://static001.geekbang.org/files/resource/ebook/100002/Images/image00180.jpeg\" alt=\"{%}\"></p><p>正如 Wolfram|Alpha 告诉我们的那样，ChatGPT 的结论并不正确（就像它自己在某种程度上“已经知道”的）。</p><p class=\"pic\"><img img=\"\" src=\"https://static001.geekbang.org/files/resource/ebook/100002/Images/image00181.jpeg\" alt=\"{%}\"></p><p>每当涉及特定的（例如数量）数据时，即使是相当原始的形式，也往往更适合用 Wolfram|Alpha 处理。以下这个例子受到了长期以来最受喜爱的 Wolfram|Alpha 测试查询“How many turkeys are there in Turkey?”（土耳其有多少只火鸡）的启发。</p><p class=\"pic\"><img img=\"\" src=\"https://static001.geekbang.org/files/resource/ebook/100002/Images/image00182.jpeg\" alt=\"{%}\"></p><p>这（一开始）看起来完全有道理，甚至引用了相关的来源。然而事实证明，这些数据基本上只是“捏造”的。</p><p class=\"pic\"><img img=\"\" src=\"https://static001.geekbang.org/files/resource/ebook/100002/Images/image00183.jpeg\" alt=\"{%}\"></p><p>不过，非常好的一点是，ChatGPT 可以轻松地“请求事实来做检查”。</p><p class=\"pic\"><img img=\"\" src=\"https://static001.geekbang.org/files/resource/ebook/100002/Images/image00184.jpeg\" alt=\"{%}\"></p><p>现在将这些请求通过 Wolfram|Alpha API 进行馈送。</p><p class=\"pic\"><img img=\"\" src=\"https://static001.geekbang.org/files/resource/ebook/100002/Images/image00185.jpeg\" alt=\"{%}\"></p><p>现在我们可以注入这些数据，要求 ChatGPT 修正其原始回答（甚至以粗体显示它所做的修正）。</p><p class=\"pic\"><img img=\"\" src=\"https://static001.geekbang.org/files/resource/ebook/100002/Images/image00186.jpeg\" alt=\"{%}\"></p><p>当涉及实时（或依赖位置等的）数据或计算时，“注入事实”的能力特别好。ChatGPT 不会立即回答下面这个问题。</p><p class=\"pic\"><img img=\"\" src=\"https://static001.geekbang.org/files/resource/ebook/100002/Images/image00187.jpeg\" alt=\"{%}\"></p><p>下面是一些相关的 Wolfram|Alpha API 输出。</p><p class=\"pic\"><img img=\"\" src=\"https://static001.geekbang.org/files/resource/ebook/100002/Images/image00188.jpeg\" alt=\"{%}\"></p><p>如果将其输入 ChatGPT，它会生成漂亮的文章式结果。</p><p class=\"pic\"><img img=\"\" src=\"https://static001.geekbang.org/files/resource/ebook/100002/Images/image00189.jpeg\" alt=\"{%}\"></p><p>有时，计算系统和类人系统之间会有有趣的相互作用。下面是一个向 Wolfram|Alpha 提出的相当异想天开的问题，而它甚至会询问你是否想要“soft-serve ice cream”（软冰激凌）。</p><p class=\"pic\"><img img=\"\" src=\"https://static001.geekbang.org/files/resource/ebook/100002/Images/image00190.jpeg\" alt=\"{%}\"></p><p>ChatGPT 最开始对于“volume”（体积）的概念有些困惑。</p><p class=\"pic\"><img img=\"\" src=\"https://static001.geekbang.org/files/resource/ebook/100002/Images/image00191.jpeg\" alt=\"{%}\"></p><p>但后来它似乎“意识到”那么多冰激凌是相当愚蠢的。</p><p class=\"pic\"><img img=\"\" src=\"https://static001.geekbang.org/files/resource/ebook/100002/Images/image00192.jpeg\" alt=\"{%}\"></p><br style=\"page-break-after:always\">","neighbors":{"left":{"article_title":"一个简单的例子","id":731318},"right":{"article_title":"前方的路","id":731320}},"comments":[]}