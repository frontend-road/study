{"id":224784,"title":"17 | 别以为“自动挡”就不可能出现OOM","content":"<p>你好，我是朱晔。今天，我要和你分享的主题是，别以为“自动挡”就不可能出现OOM。</p><p>这里的“自动挡”，是我对Java自动垃圾收集器的戏称。的确，经过这么多年的发展，Java的垃圾收集器已经非常成熟了。有了自动垃圾收集器，绝大多数情况下我们写程序时可以专注于业务逻辑，无需过多考虑对象的分配和释放，一般也不会出现OOM。</p><p>但，内存空间始终是有限的，Java的几大内存区域始终都有OOM的可能。相应地，Java程序的常见OOM类型，可以分为堆内存的OOM、栈OOM、元空间OOM、直接内存OOM等。几乎每一种OOM都可以使用几行代码模拟，市面上也有很多资料在堆、元空间、直接内存中分配超大对象或是无限分配对象，尝试创建无限个线程或是进行方法无限递归调用来模拟。</p><p>但值得注意的是，我们的业务代码并不会这么干。所以今天，我会从内存分配意识的角度通过一些案例，展示业务代码中可能导致OOM的一些坑。这些坑，或是因为我们意识不到对象的分配，或是因为不合理的资源使用，或是没有控制缓存的数据量等。</p><p>在<a href=\"https://time.geekbang.org/column/article/210337\">第3讲</a>介绍线程时，我们已经看到了两种OOM的情况，一是因为使用无界队列导致的堆OOM，二是因为使用没有最大线程数量限制的线程池导致无限创建线程的OOM。接下来，我们再一起看看，在写业务代码的过程中，还有哪些意识上的疏忽可能会导致OOM。</p><!-- [[[read_end]]] --><h2>太多份相同的对象导致OOM</h2><p>我要分享的第一个案例是这样的。有一个项目在内存中缓存了全量用户数据，在搜索用户时可以直接从缓存中返回用户信息。现在为了改善用户体验，需要实现输入部分用户名自动在下拉框提示补全用户名的功能（也就是所谓的自动完成功能）。</p><p>在<a href=\"https://time.geekbang.org/column/article/216778\">第10讲</a>介绍集合时，我提到对于这种快速检索的需求，最好使用Map来实现，会比直接从List搜索快得多。</p><p>为实现这个功能，我们需要一个HashMap来存放这些用户数据，Key是用户姓名索引，Value是索引下对应的用户列表。举一个例子，如果有两个用户aa和ab，那么Key就有三个，分别是a、aa和ab。用户输入字母a时，就能从Value这个List中拿到所有字母a开头的用户，即aa和ab。</p><p>在代码中，在数据库中存入1万个测试用户，用户名由a~j这6个字母随机构成，然后把每一个用户名的前1个字母、前2个字母以此类推直到完整用户名作为Key存入缓存中，缓存的Value是一个UserDTO的List，存放的是所有相同的用户名索引，以及对应的用户信息：</p><pre><code>//自动完成的索引，Key是用户输入的部分用户名，Value是对应的用户数据\nprivate ConcurrentHashMap&lt;String, List&lt;UserDTO&gt;&gt; autoCompleteIndex = new ConcurrentHashMap&lt;&gt;();\n\n@Autowired\nprivate UserRepository userRepository;\n\n@PostConstruct\npublic void wrong() {\n    //先保存10000个用户名随机的用户到数据库中\n    userRepository.saveAll(LongStream.rangeClosed(1, 10000).mapToObj(i -&gt; new UserEntity(i, randomName())).collect(Collectors.toList()));\n\n    //从数据库加载所有用户\n    userRepository.findAll().forEach(userEntity -&gt; {\n        int len = userEntity.getName().length();\n        //对于每一个用户，对其用户名的前N位进行索引，N可能是1~6六种长度类型\n        for (int i = 0; i &lt; len; i++) {\n            String key = userEntity.getName().substring(0, i + 1);\n            autoCompleteIndex.computeIfAbsent(key, s -&gt; new ArrayList&lt;&gt;())\n                    .add(new UserDTO(userEntity.getName()));\n        }\n    });\n    log.info(&quot;autoCompleteIndex size:{} count:{}&quot;, autoCompleteIndex.size(),\n            autoCompleteIndex.entrySet().stream().map(item -&gt; item.getValue().size()).reduce(0, Integer::sum));\n}\n</code></pre><p>对于每一个用户对象UserDTO，除了有用户名，我们还加入了10K左右的数据模拟其用户信息：</p><pre><code>@Data\npublic class UserDTO {\n    private String name;\n    @EqualsAndHashCode.Exclude\n    private String payload;\n\n    public UserDTO(String name) {\n        this.name = name;\n        this.payload = IntStream.rangeClosed(1, 10_000)\n                .mapToObj(__ -&gt; &quot;a&quot;)\n                .collect(Collectors.joining(&quot;&quot;));\n    }\n}\n</code></pre><p>运行程序后，日志输出如下：</p><pre><code>[11:11:22.982] [main] [INFO ] [.t.c.o.d.UsernameAutoCompleteService:37  ] - autoCompleteIndex size:26838 count:60000\n</code></pre><p>可以看到，一共有26838个索引（也就是所有用户名的1位、2位一直到6位有26838个组合），HashMap的Value，也就是List<userdto>一共有1万个用户*6=6万个UserDTO对象。</userdto></p><p>使用内存分析工具MAT打开堆dump发现，6万个UserDTO占用了约1.2GB的内存：</p><p><img src=\"https://static001.geekbang.org/resource/image/d1/d2/d17fdb7d5123566312f7d3888ef82bd2.png?wh=1058*296\" alt=\"\"></p><p>看到这里发现，<strong>虽然真正的用户只有1万个，但因为使用部分用户名作为索引的Key，导致缓存的Key有26838个，缓存的用户信息多达6万个</strong>。如果我们的用户名不是6位而是10位、20位，那么缓存的用户信息可能就是10万、20万个，必然会产生堆OOM。</p><p>尝试调大用户名的最大长度，重启程序可以看到类似如下的错误：</p><pre><code>[17:30:29.858] [main] [ERROR] [ringframework.boot.SpringApplication:826 ] - Application run failed\norg.springframework.beans.factory.BeanCreationException: Error creating bean with name 'usernameAutoCompleteService': Invocation of init method failed; nested exception is java.lang.OutOfMemoryError: Java heap space\n</code></pre><p>我们可能会想当然地认为，数据库中有1万个用户，内存中也应该只有1万个UserDTO对象，但实现的时候每次都会new出来UserDTO加入缓存，当然在内存中都是新对象。在实际的项目中，用户信息的缓存可能是随着用户输入增量缓存的，而不是像这个案例一样在程序初始化的时候全量缓存，所以问题暴露得不会这么早。</p><p>知道原因后，解决起来就比较简单了。把所有UserDTO先加入HashSet中，因为UserDTO以name来标识唯一性，所以重复用户名会被过滤掉，最终加入HashSet的UserDTO就不足1万个。</p><p>有了HashSet来缓存所有可能的UserDTO信息，我们再构建自动完成索引autoCompleteIndex这个HashMap时，就可以直接从HashSet获取所有用户信息来构建了。这样一来，同一个用户名前缀的不同组合（比如用户名为abc的用户，a、ab和abc三个Key）关联到UserDTO是同一份：</p><pre><code>@PostConstruct\npublic void right() {\n    ...\n\n    HashSet&lt;UserDTO&gt; cache = userRepository.findAll().stream()\n            .map(item -&gt; new UserDTO(item.getName()))\n            .collect(Collectors.toCollection(HashSet::new));\n\n\n    cache.stream().forEach(userDTO -&gt; {\n        int len = userDTO.getName().length();\n        for (int i = 0; i &lt; len; i++) {\n            String key = userDTO.getName().substring(0, i + 1);\n            autoCompleteIndex.computeIfAbsent(key, s -&gt; new ArrayList&lt;&gt;())\n                    .add(userDTO);\n        }\n    });\n    ...\n}\n</code></pre><p>再次分析堆内存，可以看到UserDTO只有9945份，总共占用的内存不到200M。这才是我们真正想要的结果。</p><p><img src=\"https://static001.geekbang.org/resource/image/34/52/34a0fc90ac8be7a20cb295c14f06d752.png?wh=1096*280\" alt=\"\"></p><p>修复后的程序，不仅相同的UserDTO只有一份，总副本数变为了原来的六分之一；而且因为HashSet的去重特性，双重节约了内存。</p><p>值得注意的是，我们虽然清楚数据总量，但却忽略了每一份数据在内存中可能有多份。我之前还遇到一个案例，一个后台程序需要从数据库加载大量信息用于数据导出，这些数据在数据库中占用100M内存，但是1GB的JVM堆却无法完成导出操作。</p><p>我来和你分析下原因吧。100M的数据加载到程序内存中，变为Java的数据结构就已经占用了200M堆内存；这些数据经过JDBC、MyBatis等框架其实是加载了2份，然后领域模型、DTO再进行转换可能又加载了2次；最终，占用的内存达到了200M*4=800M。</p><p>所以，<strong>在进行容量评估时，我们不能认为一份数据在程序内存中也是一份</strong>。</p><h2>使用WeakHashMap不等于不会OOM</h2><p>对于上一节实现快速检索的案例，为了防止缓存中堆积大量数据导致OOM，一些同学可能会想到使用WeakHashMap作为缓存容器。</p><p>WeakHashMap的特点是Key在哈希表内部是弱引用的，当没有强引用指向这个Key之后，Entry会被GC，即使我们无限往WeakHashMap加入数据，只要Key不再使用，也就不会OOM。</p><p>说到了强引用和弱引用，我先和你回顾下Java中引用类型和垃圾回收的关系：</p><ul>\n<li>垃圾回收器不会回收有强引用的对象；</li>\n<li>在内存充足时，垃圾回收器不会回收具有软引用的对象；</li>\n<li>垃圾回收器只要扫描到了具有弱引用的对象就会回收，WeakHashMap就是利用了这个特点。</li>\n</ul><p>不过，我要和你分享的第二个案例，恰巧就是不久前我遇到的一个使用WeakHashMap却最终OOM的案例。我们暂且不论使用WeakHashMap作为缓存是否合适，先分析一下这个OOM问题。</p><p>声明一个Key是User类型、Value是UserProfile类型的WeakHashMap，作为用户数据缓存，往其中添加200万个Entry，然后使用ScheduledThreadPoolExecutor发起一个定时任务，每隔1秒输出缓存中的Entry个数：</p><pre><code>private Map&lt;User, UserProfile&gt; cache = new WeakHashMap&lt;&gt;();\n\n@GetMapping(&quot;wrong&quot;)\npublic void wrong() {\n    String userName = &quot;zhuye&quot;;\n    //间隔1秒定时输出缓存中的条目数\n    Executors.newSingleThreadScheduledExecutor().scheduleAtFixedRate(\n            () -&gt; log.info(&quot;cache size:{}&quot;, cache.size()), 1, 1, TimeUnit.SECONDS);\n    LongStream.rangeClosed(1, 2000000).forEach(i -&gt; {\n        User user = new User(userName + i);\n        cache.put(user, new UserProfile(user, &quot;location&quot; + i));\n    });\n}\n</code></pre><p>执行程序后日志如下：</p><pre><code>[10:30:28.509] [pool-3-thread-1] [INFO ] [t.c.o.demo3.WeakHashMapOOMController:29  ] - cache size:2000000\n[10:30:29.507] [pool-3-thread-1] [INFO ] [t.c.o.demo3.WeakHashMapOOMController:29  ] - cache size:2000000\n[10:30:30.509] [pool-3-thread-1] [INFO ] [t.c.o.demo3.WeakHashMapOOMController:29  ] - cache size:2000000\n</code></pre><p>可以看到，输出的cache size始终是200万，即使我们通过jvisualvm进行手动GC还是这样。这就说明，这些Entry无法通过GC回收。如果你把200万改为1000万，就可以在日志中看到如下的OOM错误：</p><pre><code>Exception in thread &quot;http-nio-45678-exec-1&quot; java.lang.OutOfMemoryError: GC overhead limit exceeded\nException in thread &quot;Catalina-utility-2&quot; java.lang.OutOfMemoryError: GC overhead limit exceeded\n</code></pre><p>我们来分析一下这个问题。进行堆转储后可以看到，堆内存中有200万个UserProfie和User：</p><p><img src=\"https://static001.geekbang.org/resource/image/b9/e9/b9bb8ef163a07a8da92e6e66a6dd55e9.png?wh=2386*572\" alt=\"\"></p><p>如下是User和UserProfile类的定义，需要注意的是，WeakHashMap的Key是User对象，而其Value是UserProfile对象，持有了User的引用：</p><pre><code>@Data\n@AllArgsConstructor\n@NoArgsConstructor\nclass User {\n    private String name;\n}\n\n\n@Data\n@AllArgsConstructor\n@NoArgsConstructor\npublic class UserProfile {\n    private User user;\n    private String location;\n}\n</code></pre><p>没错，这就是问题的所在。分析一下WeakHashMap的源码，你会发现WeakHashMap和HashMap的最大区别，是Entry对象的实现。接下来，我们暂且忽略HashMap的实现，来看下Entry对象：</p><pre><code>private static class Entry&lt;K,V&gt; extends WeakReference&lt;Object&gt; ...\n/**\n * Creates new entry.\n */\nEntry(Object key, V value,\n      ReferenceQueue&lt;Object&gt; queue,\n      int hash, Entry&lt;K,V&gt; next) {\n    super(key, queue);\n    this.value = value;\n    this.hash  = hash;\n    this.next  = next;\n}\n</code></pre><p>Entry对象继承了WeakReference，Entry的构造函数调用了super (key,queue)，这是父类的构造函数。其中，key是我们执行put方法时的key；queue是一个ReferenceQueue。如果你了解Java的引用就会知道，被GC的对象会被丢进这个queue里面。</p><p>再来看看对象被丢进queue后是如何被销毁的：</p><pre><code>public V get(Object key) {\n    Object k = maskNull(key);\n    int h = hash(k);\n    Entry&lt;K,V&gt;[] tab = getTable();\n    int index = indexFor(h, tab.length);\n    Entry&lt;K,V&gt; e = tab[index];\n    while (e != null) {\n        if (e.hash == h &amp;&amp; eq(k, e.get()))\n            return e.value;\n        e = e.next;\n    }\n    return null;\n}\n\nprivate Entry&lt;K,V&gt;[] getTable() {\n    expungeStaleEntries();\n    return table;\n}\n\n/**\n * Expunges stale entries from the table.\n */\nprivate void expungeStaleEntries() {\n    for (Object x; (x = queue.poll()) != null; ) {\n        synchronized (queue) {\n            @SuppressWarnings(&quot;unchecked&quot;)\n                Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;) x;\n            int i = indexFor(e.hash, table.length);\n\n            Entry&lt;K,V&gt; prev = table[i];\n            Entry&lt;K,V&gt; p = prev;\n            while (p != null) {\n                Entry&lt;K,V&gt; next = p.next;\n                if (p == e) {\n                    if (prev == e)\n                        table[i] = next;\n                    else\n                        prev.next = next;\n                    // Must not null out e.next;\n                    // stale entries may be in use by a HashIterator\n                    e.value = null; // Help GC\n                    size--;\n                    break;\n                }\n                prev = p;\n    ``            p = next;\n            }\n        }\n    }\n}\n</code></pre><p>从源码中可以看到，每次调用get、put、size等方法时，都会从queue里拿出所有已经被GC掉的key并删除对应的Entry对象。我们再来回顾下这个逻辑：</p><ul>\n<li>put一个对象进Map时，它的key会被封装成弱引用对象；</li>\n<li>发生GC时，弱引用的key被发现并放入queue；</li>\n<li>调用get等方法时，扫描queue删除key，以及包含key和value的Entry对象。</li>\n</ul><p><strong>WeakHashMap的Key虽然是弱引用，但是其Value却持有Key中对象的强引用，Value被Entry引用，Entry被WeakHashMap引用，最终导致Key无法回收</strong>。解决方案就是让Value变为弱引用，使用WeakReference来包装UserProfile即可：</p><pre><code>private Map&lt;User, WeakReference&lt;UserProfile&gt;&gt; cache2 = new WeakHashMap&lt;&gt;();\n\n@GetMapping(&quot;right&quot;)\npublic void right() {\n    String userName = &quot;zhuye&quot;;\n    //间隔1秒定时输出缓存中的条目数\n    Executors.newSingleThreadScheduledExecutor().scheduleAtFixedRate(\n            () -&gt; log.info(&quot;cache size:{}&quot;, cache2.size()), 1, 1, TimeUnit.SECONDS);\n    LongStream.rangeClosed(1, 2000000).forEach(i -&gt; {\n        User user = new User(userName + i);\n        //这次，我们使用弱引用来包装UserProfile\n        cache2.put(user, new WeakReference(new UserProfile(user, &quot;location&quot; + i)));\n    });\n}\n</code></pre><p>重新运行程序，从日志中观察到cache size不再是固定的200万，而是在不断减少，甚至在手动GC后所有的Entry都被回收了：</p><pre><code>[10:40:05.792] [pool-3-thread-1] [INFO ] [t.c.o.demo3.WeakHashMapOOMController:40  ] - cache size:1367402\n[10:40:05.795] [pool-3-thread-1] [INFO ] [t.c.o.demo3.WeakHashMapOOMController:40  ] - cache size:1367846\n[10:40:06.773] [pool-3-thread-1] [INFO ] [t.c.o.demo3.WeakHashMapOOMController:40  ] - cache size:549551\n...\n[10:40:20.742] [pool-3-thread-1] [INFO ] [t.c.o.demo3.WeakHashMapOOMController:40  ] - cache size:549551\n[10:40:22.862] [pool-3-thread-1] [INFO ] [t.c.o.demo3.WeakHashMapOOMController:40  ] - cache size:547937\n[10:40:22.865] [pool-3-thread-1] [INFO ] [t.c.o.demo3.WeakHashMapOOMController:40  ] - cache size:542134\n[10:40:23.779] [pool-3-thread-1] [INFO ] \n//手动进行GC\n[t.c.o.demo3.WeakHashMapOOMController:40  ] - cache size:0\n</code></pre><p>当然，还有一种办法就是，让Value也就是UserProfile不再引用Key，而是重新new出一个新的User对象赋值给UserProfile：</p><pre><code>@GetMapping(&quot;right2&quot;)\npublic void right2() {\n    String userName = &quot;zhuye&quot;;\n    ...\n        User user = new User(userName + i);\n        cache.put(user, new UserProfile(new User(user.getName()), &quot;location&quot; + i));\n    });\n}\n</code></pre><p>此外，Spring提供的<a href=\"https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/util/ConcurrentReferenceHashMap.html\">ConcurrentReferenceHashMap</a>类可以使用弱引用、软引用做缓存，Key和Value同时被软引用或弱引用包装，也能解决相互引用导致的数据不能释放问题。与WeakHashMap相比，ConcurrentReferenceHashMap不但性能更好，还可以确保线程安全。你可以自己做实验测试下。</p><h2>Tomcat参数配置不合理导致OOM</h2><p>我们再来看看第三个案例。有一次运维同学反馈，有个应用在业务量大的情况下会出现假死，日志中也有大量OOM异常：</p><pre><code>[13:18:17.597] [http-nio-45678-exec-70] [ERROR] [ache.coyote.http11.Http11NioProtocol:175 ] - Failed to complete processing of a request\njava.lang.OutOfMemoryError: Java heap space\n</code></pre><p>于是，我让运维同学进行生产堆Dump。通过MAT打开dump文件后，我们一眼就看到OOM的原因是，有接近1.7GB的byte数组分配，而JVM进程的最大堆内存我们只配置了2GB：</p><p><img src=\"https://static001.geekbang.org/resource/image/0b/ee/0b310e7da83f272afdf51b345d8057ee.png?wh=1738*194\" alt=\"\"></p><p>通过查看引用可以发现，大量引用都是Tomcat的工作线程。大部分工作线程都分配了两个10M左右的数组，100个左右工作线程吃满了内存。第一个红框是Http11InputBuffer，其buffer大小是10008192字节；而第二个红框的Http11OutputBuffer的buffer，正好占用10000000字节：</p><p><img src=\"https://static001.geekbang.org/resource/image/53/12/53546299958a4fecef5fd473a0579012.png?wh=2186*1056\" alt=\"\"></p><p>我们先来看看第一个Http11InputBuffer为什么会占用这么多内存。查看Http11InputBuffer类的init方法注意到，其中一个初始化方法会分配headerBufferSize+readBuffer大小的内存：</p><pre><code>void init(SocketWrapperBase&lt;?&gt; socketWrapper) {\n\n    wrapper = socketWrapper;\n    wrapper.setAppReadBufHandler(this);\n\n    int bufLength = headerBufferSize +\n            wrapper.getSocketBufferHandler().getReadBuffer().capacity();\n    if (byteBuffer == null || byteBuffer.capacity() &lt; bufLength) {\n        byteBuffer = ByteBuffer.allocate(bufLength);\n        byteBuffer.position(0).limit(0);\n    }\n}\n</code></pre><p>在<a href=\"https://tomcat.apache.org/tomcat-8.0-doc/config/http.html\">Tomcat文档</a>中有提到，这个Socket的读缓冲，也就是readBuffer默认是8192字节。显然，问题出在了headerBufferSize上：</p><p><img src=\"https://static001.geekbang.org/resource/image/0c/68/0c14d6aff749d74b3ee0e159e4552168.png?wh=2650*246\" alt=\"\"></p><p>向上追溯初始化Http11InputBuffer的Http11Processor类，可以看到，传入的headerBufferSize配置的是MaxHttpHeaderSize：</p><pre><code>inputBuffer = new Http11InputBuffer(request, protocol.getMaxHttpHeaderSize(),\n        protocol.getRejectIllegalHeaderName(), httpParser);\n</code></pre><p>Http11OutputBuffer中的buffer正好占用了10000000字节，这又是为什么？通过Http11OutputBuffer的构造方法，可以看到它是直接根据headerBufferSize分配了固定大小的headerBuffer：</p><pre><code>protected Http11OutputBuffer(Response response, int headerBufferSize){\n...\n \theaderBuffer = ByteBuffer.allocate(headerBufferSize);\n}\n</code></pre><p>那么我们就可以想到，一定是应用把Tomcat头相关的参数配置为10000000了，使得每一个请求对于Request和Response都占用了20M内存，最终在并发较多的情况下引起了OOM。</p><p>果不其然，查看项目代码发现配置文件中有这样的配置项：</p><pre><code>server.max-http-header-size=10000000\n</code></pre><p>翻看源码提交记录可以看到，当时开发同学遇到了这样的异常：</p><pre><code>java.lang.IllegalArgumentException: Request header is too large\n</code></pre><p>于是他就到网上搜索了一下解决方案，随意将server.max-http-header-size修改为了一个超大值，期望永远不会再出现类似问题。但，没想到这个修改却引起了这么大的问题。把这个参数改为比较合适的20000再进行压测，我们就可以发现应用的各项指标都比较稳定。</p><p>这个案例告诉我们，<strong>一定要根据实际需求来修改参数配置，可以考虑预留2到5倍的量。容量类的参数背后往往代表了资源，设置超大的参数就有可能占用不必要的资源，在并发量大的时候因为资源大量分配导致OOM</strong>。</p><h2>重点回顾</h2><p>今天，我从内存分配意识的角度和你分享了OOM的问题。通常而言，Java程序的OOM有如下几种可能。</p><p>一是，我们的程序确实需要超出JVM配置的内存上限的内存。不管是程序实现的不合理，还是因为各种框架对数据的重复处理、加工和转换，相同的数据在内存中不一定只占用一份空间。针对内存量使用超大的业务逻辑，比如缓存逻辑、文件上传下载和导出逻辑，我们在做容量评估时，可能还需要实际做一下Dump，而不是进行简单的假设。</p><p>二是，出现内存泄露，其实就是我们认为没有用的对象最终会被GC，但却没有。GC并不会回收强引用对象，我们可能经常在程序中定义一些容器作为缓存，但如果容器中的数据无限增长，要特别小心最终会导致OOM。使用WeakHashMap是解决这个问题的好办法，但值得注意的是，如果强引用的Value有引用Key，也无法回收Entry。</p><p>三是，不合理的资源需求配置，在业务量小的时候可能不会出现问题，但业务量一大可能很快就会撑爆内存。比如，随意配置Tomcat的max-http-header-size参数，会导致一个请求使用过多的内存，请求量大的时候出现OOM。在进行参数配置的时候，我们要认识到，很多限制类参数限制的是背后资源的使用，资源始终是有限的，需要根据实际需求来合理设置参数。</p><p>最后我想说的是，在出现OOM之后，也不用过于紧张。我们可以根据错误日志中的异常信息，再结合jstat等命令行工具观察内存使用情况，以及程序的GC日志，来大致定位出现OOM的内存区块和类型。其实，我们遇到的90%的OOM都是堆OOM，对JVM进程进行堆内存Dump，或使用jmap命令分析对象内存占用排行，一般都可以很容易定位到问题。</p><p>这里，<strong>我建议你为生产系统的程序配置JVM参数启用详细的GC日志，方便观察垃圾收集器的行为，并开启HeapDumpOnOutOfMemoryError，以便在出现OOM时能自动Dump留下第一问题现场</strong>。对于JDK8，你可以这么设置：</p><pre><code>XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=. -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc.log -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=100M\n</code></pre><p>今天用到的代码，我都放在了GitHub上，你可以点击<a href=\"https://github.com/JosephZhu1983/java-common-mistakes\">这个链接</a>查看。</p><h2>思考与讨论</h2><ol>\n<li>Spring的ConcurrentReferenceHashMap，针对Key和Value支持软引用和弱引用两种方式。你觉得哪种方式更适合做缓存呢？</li>\n<li>当我们需要动态执行一些表达式时，可以使用Groovy动态语言实现：new出一个GroovyShell类，然后调用evaluate方法动态执行脚本。这种方式的问题是，会重复产生大量的类，增加Metaspace区的GC负担，有可能会引起OOM。你知道如何避免这个问题吗？</li>\n</ol><p>针对OOM或内存泄露，你还遇到过什么案例吗？我是朱晔，欢迎在评论区与我留言分享，也欢迎你把今天的内容分享给你的朋友或同事，一起交流。</p>","neighbors":{"left":{"article_title":"16 | 用好Java 8的日期时间类，少踩一些“老三样”的坑","id":224240},"right":{"article_title":"18 | 当反射、注解和泛型遇到OOP时，会有哪些坑？","id":225596}},"comments":[{"had_liked":false,"id":207699,"user_name":"一个汉子~","can_delete":false,"product_type":"c1","uid":1635211,"ip_address":"","ucode":"9E1419704FDEBB","user_header":"https://static001.geekbang.org/account/avatar/00/18/f3/8b/a629f9d4.jpg","comment_is_top":false,"comment_ctime":1587140053,"is_pvip":false,"replies":[{"id":"77566","content":"👍🏻","user_name":"作者回复","comment_id":207699,"uid":"1001470","ip_address":"","utype":1,"ctime":1587167419,"user_name_real":"朱晔"}],"discussion_count":3,"race_medal":0,"score":"96076420565","product_id":100047701,"comment_content":"针对第二点，可以先compile，然后在内存中保存，脚本内容的hash作为key，compile结果作为value，用ConcurrentReferenceHashMap保存<br>同样的风险还出现在表达式框架aviator中","like_count":23,"discussions":[{"author":{"id":1001470,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/47/fe/d0e25d57.jpg","nickname":"朱晔","note":"","ucode":"0B7F0BADE6AAB8","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492212,"discussion_content":"👍🏻","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587167419,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1139413,"avatar":"https://static001.geekbang.org/account/avatar/00/11/62/d5/1f5c5ab6.jpg","nickname":"大大大熊myeh","note":"","ucode":"4832C2E7CEB151","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":237452,"discussion_content":"Aviator 开了cache会极大降低OOM的风险","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1587142258,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1102228,"avatar":"https://static001.geekbang.org/account/avatar/00/10/d1/94/6c73ab00.jpg","nickname":"叶落","note":"","ucode":"F836A8144518BA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":307971,"discussion_content":"有没有可能hash值重复","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1600819587,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":208640,"user_name":"Darren","can_delete":false,"product_type":"c1","uid":1254968,"ip_address":"","ucode":"CCD2B2C492BE9A","user_header":"https://static001.geekbang.org/account/avatar/00/13/26/38/ef063dc2.jpg","comment_is_top":false,"comment_ctime":1587395151,"is_pvip":true,"replies":[{"id":"77980","content":"源码里我也有一个例子，思路是不要每次都evaluate脚本而是把脚本转变为一个方法parse后缓存起来这个Script，以后直接invokeMethod来使用","user_name":"作者回复","comment_id":208640,"uid":"1001470","ip_address":"","utype":1,"ctime":1587435641,"user_name_real":"朱晔"}],"discussion_count":3,"race_medal":0,"score":"40242100815","product_id":100047701,"comment_content":"试着回到下问题：<br>第一个：<br>肯定是软引用，因为弱引用是只要GC执行，扫描到就被回收，缓存的作用是为了提高速度，要有一定的存在周期；如果是弱引用，每次GC执行，缓存被回收，缓存命中率超低，完全达不到缓存的作用，而又要维护缓存和DB的数据一致性问题，得不偿失。<br>第二个：<br>第一种不完美的方案：GroovyShell不要设置成全局的，每次运行时，都创建一个GroovyShell，然后限制元数据区大小，当元数据回收时，GroovyShell和该GroovyShell加载的类一起被回收；<br>第二种方法：GroovyShell设置为全局的，然后使用缓存，每次都是先从缓存中获取，获取不到了，在加载，然后更新缓存。","like_count":10,"discussions":[{"author":{"id":1001470,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/47/fe/d0e25d57.jpg","nickname":"朱晔","note":"","ucode":"0B7F0BADE6AAB8","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492557,"discussion_content":"源码里我也有一个例子，思路是不要每次都evaluate脚本而是把脚本转变为一个方法parse后缓存起来这个Script，以后直接invokeMethod来使用","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587435641,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1002939,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/4d/bb/abb7bfe3.jpg","nickname":"csyangchsh","note":"","ucode":"8604F5C839710B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":251050,"discussion_content":"软引用也是坑，它自己本身是一个强引用，如果不小心被GC Root引用，就是内存泄露了。软引用的问题是它没有足够的信息提供给GC是否应该回收，-XX:SoftRefLRUPolicyMSPerMB 很难设置一个合适的值。过多使用软引用和弱引用可能会导致GC停顿时间变长。","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1588061267,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1254968,"avatar":"https://static001.geekbang.org/account/avatar/00/13/26/38/ef063dc2.jpg","nickname":"Darren","note":"","ucode":"CCD2B2C492BE9A","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":243316,"discussion_content":"谢谢老师","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587533569,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":208439,"user_name":"汝林外史","can_delete":false,"product_type":"c1","uid":1188906,"ip_address":"","ucode":"3C66C0F0537A99","user_header":"https://static001.geekbang.org/account/avatar/00/12/24/2a/33441e2b.jpg","comment_is_top":false,"comment_ctime":1587358454,"is_pvip":false,"replies":[{"id":"77871","content":"1. 👍 是的，这种场景字典树更合适，不过我这边都是拿着实际的案例整理成文的，主要是希望告知大家我们认为的一份数据在程序中不一定是一份这个误区","user_name":"作者回复","comment_id":208439,"uid":"1001470","ip_address":"","utype":1,"ctime":1587363121,"user_name_real":"朱晔"}],"discussion_count":1,"race_medal":0,"score":"31652129526","product_id":100047701,"comment_content":"1. 对于老师说的autoComplete的场景是不是Trie树更适合一些？<br>2. 这个WeakReference可能导致内存溢出的典型就是ThreadLocal，虽然ThreadLocalMap的entry的key是weakReference，但是value是强引用，当用线程池的时候，就会内存溢出，还是要自己remove才行。<br>3. 对于问题1，应该是用软引用更好一些，用弱引用总是被gc回收就失去了缓存的意义。对于问题2不是很了解。","like_count":8,"discussions":[{"author":{"id":1001470,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/47/fe/d0e25d57.jpg","nickname":"朱晔","note":"","ucode":"0B7F0BADE6AAB8","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492456,"discussion_content":"1. 👍 是的，这种场景字典树更合适，不过我这边都是拿着实际的案例整理成文的，主要是希望告知大家我们认为的一份数据在程序中不一定是一份这个误区","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587363121,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":207896,"user_name":"👽","can_delete":false,"product_type":"c1","uid":1274117,"ip_address":"","ucode":"D313AF941B412D","user_header":"https://static001.geekbang.org/account/avatar/00/13/71/05/db554eba.jpg","comment_is_top":false,"comment_ctime":1587210234,"is_pvip":false,"replies":[{"id":"77587","content":"不错","user_name":"作者回复","comment_id":207896,"uid":"1001470","ip_address":"","utype":1,"ctime":1587215260,"user_name_real":"朱晔"}],"discussion_count":2,"race_medal":0,"score":"31651981306","product_id":100047701,"comment_content":"应该用哪种引用，首先考虑的肯定是四大引用的区别。<br>1.强引用：最常见的一种，只要该引用存在，就不会被GC。<br>2.软引用：内存空间不足时，进行回收。<br>3.弱引用：当JVM进行GC时，则进行回收，无论内存是否充足。<br>4.虚引用：这个不提了，因为我也完全不懂。<br><br>软引用和弱引用，这两个，让我选，肯定是选软引用。因为弱引用，被回收的频率更高。缓存，如果经常被回收的话，就达不到最大利用率。<br><br>但是这里又要说点额外的，单说缓存设计，还要涉及其他的因素。包括缓存大小，缓存的过期时间等。让我来说的话，我可能会考虑使用现有的缓存实现，或者是redis。自己实现一套缓存，成本略高。","like_count":8,"discussions":[{"author":{"id":1001470,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/47/fe/d0e25d57.jpg","nickname":"朱晔","note":"","ucode":"0B7F0BADE6AAB8","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492273,"discussion_content":"不错","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587215260,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2014573,"avatar":"https://static001.geekbang.org/account/avatar/00/1e/bd/6d/7010f98e.jpg","nickname":"SharpBB","note":"","ucode":"D30C5B798B8E8C","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":559653,"discussion_content":"笑死 因为我也不懂 哈哈","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1648865808,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":207701,"user_name":"一个汉子~","can_delete":false,"product_type":"c1","uid":1635211,"ip_address":"","ucode":"9E1419704FDEBB","user_header":"https://static001.geekbang.org/account/avatar/00/18/f3/8b/a629f9d4.jpg","comment_is_top":false,"comment_ctime":1587140559,"is_pvip":false,"replies":[{"id":"77565","content":"很常见的问题，还有包括参数未传导致mybatis条件没有拼接上去，导致全表查询的oom","user_name":"作者回复","comment_id":207701,"uid":"1001470","ip_address":"","utype":1,"ctime":1587167410,"user_name_real":"朱晔"}],"discussion_count":3,"race_medal":0,"score":"31651911631","product_id":100047701,"comment_content":"之前还遇到一个，一个导出功能，拥有管理员权限的人几乎没有限制，造成了全表查，再加上框架禁止join，所以又把外键拉出来做了一次in查询，也是全表扫，大量的Bo对象和超长sql，直接把系统oom了","like_count":7,"discussions":[{"author":{"id":1001470,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/47/fe/d0e25d57.jpg","nickname":"朱晔","note":"","ucode":"0B7F0BADE6AAB8","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492213,"discussion_content":"很常见的问题，还有包括参数未传导致mybatis条件没有拼接上去，导致全表查询的oom","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587167410,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":1253978,"avatar":"https://static001.geekbang.org/account/avatar/00/13/22/5a/450ba91e.jpg","nickname":"卖火柴的男人","note":"","ucode":"F12AE47D039883","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1001470,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/47/fe/d0e25d57.jpg","nickname":"朱晔","note":"","ucode":"0B7F0BADE6AAB8","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":549424,"discussion_content":"刚解决了一个参数未传入，每次7万条数据导致oom","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1643968395,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":492213,"ip_address":""},"score":549424,"extra":""}]},{"author":{"id":1274117,"avatar":"https://static001.geekbang.org/account/avatar/00/13/71/05/db554eba.jpg","nickname":"👽","note":"","ucode":"D313AF941B412D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":238087,"discussion_content":"这种业务，可以不可以考虑，强制分页，并且设定最大分页长度。\n类似于MybatisPlus就有设定最大单页数据长度的。例如设置个1000，保证查询出来的数量无论如何都不会太夸张。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587210353,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":210298,"user_name":"不能忍的地精","can_delete":false,"product_type":"c1","uid":1754913,"ip_address":"","ucode":"66A921C0BC8102","user_header":"","comment_is_top":false,"comment_ctime":1587716502,"is_pvip":false,"replies":[{"id":"78380","content":"😥","user_name":"作者回复","comment_id":210298,"uid":"1001470","ip_address":"","utype":1,"ctime":1587725965,"user_name_real":"朱晔"}],"discussion_count":1,"race_medal":0,"score":"14472618390","product_id":100047701,"comment_content":"我遇到一个OOM,是这样的<br>1. 首先有一个线程池,线程数量是20个,但是线程队列容器的数量是Integer的最大值,所以拒绝策略几乎无效,大概没过3秒往线程池提交3个任务<br>2. 任务里面有一个Restemplate,没有设置超时时间,超时时间为-1,并且里面维护的连接池是5个,小于线程池数量<br>3. 出现5个连接都超时,任务卡住了,但是还是不断的往任务队列里面添加任务,最终导致OOM","like_count":4,"discussions":[{"author":{"id":1001470,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/47/fe/d0e25d57.jpg","nickname":"朱晔","note":"","ucode":"0B7F0BADE6AAB8","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492996,"discussion_content":"😥","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587725965,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":208353,"user_name":"ddosyang","can_delete":false,"product_type":"c1","uid":1903226,"ip_address":"","ucode":"DE0FBAB888AA7F","user_header":"","comment_is_top":false,"comment_ctime":1587344091,"is_pvip":false,"replies":[{"id":"77813","content":"是，不过这就改了设计了","user_name":"作者回复","comment_id":208353,"uid":"1001470","ip_address":"","utype":1,"ctime":1587346124,"user_name_real":"朱晔"}],"discussion_count":1,"race_medal":0,"score":"10177278683","product_id":100047701,"comment_content":"老师想问一下，在WeakHashMap的那个例子里，可不可以直接用String name当作Key，而不是用User做Key。这样是不是也可以解决问题？","like_count":2,"discussions":[{"author":{"id":1001470,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/47/fe/d0e25d57.jpg","nickname":"朱晔","note":"","ucode":"0B7F0BADE6AAB8","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492431,"discussion_content":"是，不过这就改了设计了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587346124,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":207744,"user_name":"自由港","can_delete":false,"product_type":"c1","uid":1086779,"ip_address":"","ucode":"EA1AFDB9123747","user_header":"https://static001.geekbang.org/account/avatar/00/10/95/3b/a7c94a53.jpg","comment_is_top":false,"comment_ctime":1587172122,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10177106714","product_id":100047701,"comment_content":"关于第二个向题限制了metadata的堆大小，发现就可自动回收了","like_count":2},{"had_liked":false,"id":224230,"user_name":"Carisy","can_delete":false,"product_type":"c1","uid":1657429,"ip_address":"","ucode":"67E887967347BA","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLwTZdUafC5YM7bCASt8icUnoyYfV4hUHulexibDI7B4eaokTxYXHFtoic97DBlCAU9j5Jw4QUuGhyZQ/132","comment_is_top":false,"comment_ctime":1591320050,"is_pvip":false,"replies":[{"id":"82556","content":"buffers是指什么buffer？这个和CompletableFuture没有关系，上传下载都会用到缓冲区，如果并发大的话可能是会OOM","user_name":"作者回复","comment_id":224230,"uid":"1001470","ip_address":"","utype":1,"ctime":1591324507,"user_name_real":"朱晔"}],"discussion_count":1,"race_medal":0,"score":"5886287346","product_id":100047701,"comment_content":"老师请教一个问题，在使用CompletableFuture的时候出现了很奇怪的场景，就是buffers飙升出现oom，应用程序使用内存并不多，处理逻辑也相对简单就是调用接口通过http上传下载文件","like_count":1,"discussions":[{"author":{"id":1001470,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/47/fe/d0e25d57.jpg","nickname":"朱晔","note":"","ucode":"0B7F0BADE6AAB8","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":497408,"discussion_content":"buffers是指什么buffer？这个和CompletableFuture没有关系，上传下载都会用到缓冲区，如果并发大的话可能是会OOM","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1591324507,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":207719,"user_name":"pedro","can_delete":false,"product_type":"c1","uid":1200704,"ip_address":"","ucode":"F40C839DDFD599","user_header":"https://static001.geekbang.org/account/avatar/00/12/52/40/e57a736e.jpg","comment_is_top":false,"comment_ctime":1587166161,"is_pvip":false,"replies":[{"id":"77570","content":"不太对，可以再查一些资料或做一些实验看下软和弱的区别","user_name":"作者回复","comment_id":207719,"uid":"1001470","ip_address":"","utype":1,"ctime":1587173889,"user_name_real":"朱晔"}],"discussion_count":3,"race_medal":0,"score":"5882133457","product_id":100047701,"comment_content":"问题一，弱引用是在内存不足时被 gc 掉，而软引用是只要 gc 就回收掉，自然就不能用来做缓存，否则动不动就缓存失效，数据库怕是要被玩坏哦，因为适合做缓存的是弱引用。<br>问题二，没用过 groovy，希望看到别人的解答。😄","like_count":1,"discussions":[{"author":{"id":1001470,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/47/fe/d0e25d57.jpg","nickname":"朱晔","note":"","ucode":"0B7F0BADE6AAB8","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492222,"discussion_content":"不太对，可以再查一些资料或做一些实验看下软和弱的区别","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587173889,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1200704,"avatar":"https://static001.geekbang.org/account/avatar/00/12/52/40/e57a736e.jpg","nickname":"pedro","note":"","ucode":"F40C839DDFD599","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":237693,"discussion_content":"各位不好意思，软引用和弱引用我确实搞反了，年纪大了，大家担待一下😓","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1587178145,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1211223,"avatar":"https://static001.geekbang.org/account/avatar/00/12/7b/57/a9b04544.jpg","nickname":"QQ怪","note":"","ucode":"1A39B8433D9208","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":237671,"discussion_content":"老哥第一个说反了","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1587177234,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":211800,"user_name":"旅途","can_delete":false,"product_type":"c1","uid":1212902,"ip_address":"","ucode":"5022477E8E9441","user_header":"https://static001.geekbang.org/account/avatar/00/12/81/e6/6cafed37.jpg","comment_is_top":false,"comment_ctime":1588012034,"is_pvip":false,"replies":[{"id":"78689","content":"这个异常原因是请求头数据过大超过了限制 不是指tomcat请求头参数配置过大","user_name":"作者回复","comment_id":211800,"uid":"1001470","ip_address":"","utype":1,"ctime":1588031405,"user_name_real":"朱晔"}],"discussion_count":2,"race_medal":0,"score":"1588012034","product_id":100047701,"comment_content":"有点没懂 java.lang.IllegalArgumentException: Request header is too large 的意思不就是request header过大了么 为什么开发人员还设置的那么大？","like_count":1,"discussions":[{"author":{"id":1001470,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/47/fe/d0e25d57.jpg","nickname":"朱晔","note":"","ucode":"0B7F0BADE6AAB8","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493371,"discussion_content":"这个异常原因是请求头数据过大超过了限制 不是指tomcat请求头参数配置过大","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588031405,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1212902,"avatar":"https://static001.geekbang.org/account/avatar/00/12/81/e6/6cafed37.jpg","nickname":"旅途","note":"","ucode":"5022477E8E9441","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":250913,"discussion_content":"明白了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588049850,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":208365,"user_name":"yang","can_delete":false,"product_type":"c1","uid":1227722,"ip_address":"","ucode":"45C1BE2D4AD72B","user_header":"https://static001.geekbang.org/account/avatar/00/12/bb/ca/86d58e40.jpg","comment_is_top":false,"comment_ctime":1587345480,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1587345480","product_id":100047701,"comment_content":"技术方案也够奇葩的------------怎么设计出来的-----~-~----","like_count":0},{"had_liked":false,"id":207781,"user_name":"Geek_3b1096","can_delete":false,"product_type":"c1","uid":1549364,"ip_address":"","ucode":"A6BD92B79B3632","user_header":"","comment_is_top":false,"comment_ctime":1587178668,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1587178668","product_id":100047701,"comment_content":"周六第一件事跟上老师进度","like_count":1,"discussions":[{"author":{"id":1161368,"avatar":"https://static001.geekbang.org/account/avatar/00/11/b8/98/ce254cef.jpg","nickname":"涟漪","note":"","ucode":"2D643A25097FF5","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":251480,"discussion_content":"比较频繁的http请求也遇到过。至今没有找到问题出在哪里","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588086036,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}