{"id":85987,"title":"40丨数据挖掘实战（2）：信用卡诈骗分析","content":"<p>上一篇文章中，我们用随机森林以及之前讲过的SVM、决策树和KNN分类器对信用卡违约数据进行了分析，这节课我们来研究下信用卡欺诈。</p><p>相比于信用卡违约的比例，信用卡欺诈的比例更小，但是危害极大。如何通过以往的交易数据分析出每笔交易是否正常，是否存在盗刷风险是我们这次项目的目标。</p><p>通过今天的学习，你需要掌握以下几个方面：</p><ol>\n<li>\n<p>了解逻辑回归分类，以及如何在sklearn中使用它；</p>\n</li>\n<li>\n<p>信用卡欺诈属于二分类问题，欺诈交易在所有交易中的比例很小，对于这种数据不平衡的情况，到底采用什么样的模型评估标准会更准确；</p>\n</li>\n<li>\n<p>完成信用卡欺诈分析的实战项目，并通过数据可视化对数据探索和模型结果评估进一步加强了解。</p>\n</li>\n</ol><h2>构建逻辑回归分类器</h2><p>逻辑回归虽然不在我们讲解的十大经典数据挖掘算法里面，但也是常用的数据挖掘算法。</p><p>逻辑回归，也叫作logistic回归。虽然名字中带有“回归”，但它实际上是分类方法，主要解决的是二分类问题，当然它也可以解决多分类问题，只是二分类更常见一些。</p><p>在逻辑回归中使用了Logistic函数，也称为Sigmoid函数。Sigmoid函数是在深度学习中经常用到的函数之一，函数公式为：</p><p><img src=\"https://static001.geekbang.org/resource/image/3e/18/3e7c7cb4d26d1a71f958610f26d20818.png?wh=444*204\" alt=\"\"><br>\n函数的图形如下所示，类似S状：</p><p><img src=\"https://static001.geekbang.org/resource/image/b7/3b/b7a5d39d91fda02b21669137a489743b.png?wh=477*206\" alt=\"\"><br>\n你能看出g(z)的结果在0-1之间，当z越大的时候，g(z)越大，当z趋近于无穷大的时候，g(z)趋近于1。同样当z趋近于无穷小的时候，g(z)趋近于0。同时，函数值以0.5为中心。</p><!-- [[[read_end]]] --><p>为什么逻辑回归算法是基于Sigmoid函数实现的呢？你可以这样理解：我们要实现一个二分类任务，0即为不发生，1即为发生。我们给定一些历史数据X和y。其中X代表样本的n个特征，y代表正例和负例，也就是0或1的取值。通过历史样本的学习，我们可以得到一个模型，当给定新的X的时候，可以预测出y。这里我们得到的y是一个预测的概率，通常不是0%和100%，而是中间的取值，那么我们就可以认为概率大于50%的时候，即为发生（正例），概率小于50%的时候，即为不发生（负例）。这样就完成了二分类的预测。</p><p>逻辑回归模型的求解这里不做介绍，我们来看下如何使用sklearn中的逻辑回归工具。在sklearn中，我们使用LogisticRegression()函数构建逻辑回归分类器，函数里有一些常用的构造参数：</p><ol>\n<li>\n<p>penalty：惩罚项，取值为l1或l2，默认为l2。当模型参数满足高斯分布的时候，使用l2，当模型参数满足拉普拉斯分布的时候，使用l1；</p>\n</li>\n<li>\n<p>solver：代表的是逻辑回归损失函数的优化方法。有5个参数可选，分别为liblinear、lbfgs、newton-cg、sag和saga。默认为liblinear，适用于数据量小的数据集，当数据量大的时候可以选用sag或saga方法。</p>\n</li>\n<li>\n<p>max_iter：算法收敛的最大迭代次数，默认为10。</p>\n</li>\n<li>\n<p>n_jobs：拟合和预测的时候CPU的核数，默认是1，也可以是整数，如果是-1则代表CPU的核数。</p>\n</li>\n</ol><p>当我们创建好之后，就可以使用fit函数拟合，使用predict函数预测。</p><h2>模型评估指标</h2><p>我们之前对模型做评估时，通常采用的是准确率(accuracy)，它指的是分类器正确分类的样本数与总体样本数之间的比例。这个指标对大部分的分类情况是有效的，不过当分类结果严重不平衡的时候，准确率很难反应模型的好坏。</p><p>举个例子，对于机场安检中恐怖分子的判断，就不能采用准确率对模型进行评估。我们知道恐怖分子的比例是极低的，因此当我们用准确率做判断时，如果准确率高达99.999%，就说明这个模型一定好么？</p><p>其实正因为现实生活中恐怖分子的比例极低，就算我们不能识别出一个恐怖分子，也会得到非常高的准确率。因为准确率的评判标准是正确分类的样本个数与总样本数之间的比例。因此非恐怖分子的比例会很高，就算我们识别不出来恐怖分子，正确分类的个数占总样本的比例也会很高，也就是准确率高。</p><p>实际上我们应该更关注恐怖分子的识别，这里先介绍下数据预测的四种情况：TP、FP、TN、FN。我们用第二个字母P或N代表预测为正例还是负例，P为正，N为负。第一个字母T或F代表的是预测结果是否正确，T为正确，F为错误。</p><p>所以四种情况分别为：</p><ol>\n<li>\n<p>TP：预测为正，判断正确；</p>\n</li>\n<li>\n<p>FP：预测为正，判断错误；</p>\n</li>\n<li>\n<p>TN：预测为负，判断正确；</p>\n</li>\n<li>\n<p>FN：预测为负，判断错误。</p>\n</li>\n</ol><p>我们知道样本总数=TP+FP+TN+FN，预测正确的样本数为TP+TN，因此准确率Accuracy = (TP+TN)/(TP+TN+FN+FP)。</p><p>实际上，对于分类不平衡的情况，有两个指标非常重要，它们分别是精确度和召回率。</p><p>精确率 P = TP/ (TP+FP)，对应上面恐怖分子这个例子，在所有判断为恐怖分子的人数中，真正是恐怖分子的比例。</p><p>召回率 R = TP/ (TP+FN)，也称为查全率。代表的是恐怖分子被正确识别出来的个数与恐怖分子总数的比例。</p><p>为什么要统计召回率和精确率这两个指标呢？假设我们只统计召回率，当召回率等于100%的时候，模型是否真的好呢？</p><p>举个例子，假设我们把机场所有的人都认为是恐怖分子，恐怖分子都会被正确识别，这个数字与恐怖分子的总数比例等于100%，但是这个结果是没有意义的。如果我们认为机场里所有人都是恐怖分子的话，那么非恐怖分子（极高比例）都会认为是恐怖分子，误判率太高了，所以我们还需要统计精确率作为召回率的补充。</p><p>实际上有一个指标综合了精确率和召回率，可以更好地评估模型的好坏。这个指标叫做F1，用公式表示为：</p><p><img src=\"https://static001.geekbang.org/resource/image/b1/ce/b122244eae9a74eded619d14c0bc12ce.png?wh=398*182\" alt=\"\"><br>\nF1作为精确率P和召回率R的调和平均，数值越大代表模型的结果越好。</p><h2>对信用卡违约率进行分析</h2><p>我们来看一个信用卡欺诈分析的项目，这个数据集你可以从百度网盘（因为数据集大于100M，所以采用了网盘）中下载：</p><blockquote>\n<p>链接：<a href=\"https://pan.baidu.com/s/14F8WuX0ZJntdB_r1EC08HA\">https://pan.baidu.com/s/14F8WuX0ZJntdB_r1EC08HA</a> 提取码：58gp</p>\n</blockquote><p>数据集包括了2013年9月份两天时间内的信用卡交易数据，284807笔交易中，一共有492笔是欺诈行为。输入数据一共包括了28个特征V1，V2，……V28对应的取值，以及交易时间Time和交易金额Amount。为了保护数据隐私，我们不知道V1到V28这些特征代表的具体含义，只知道这28个特征值是通过PCA变换得到的结果。另外字段Class代表该笔交易的分类，Class=0为正常（非欺诈），Class=1代表欺诈。</p><p>我们的目标是针对这个数据集构建一个信用卡欺诈分析的分类器，采用的是逻辑回归。从数据中你能看到欺诈行为只占到了492/284807=0.172%，数据分类结果的分布是非常不平衡的，因此我们不能使用准确率评估模型的好坏，而是需要统计F1值（综合精确率和召回率）。我们先梳理下整个项目的流程：</p><p><img src=\"https://static001.geekbang.org/resource/image/92/a5/929c96584cbc25972f63ef39101c96a5.jpg?wh=2350*1079\" alt=\"\"></p><ol>\n<li>\n<p>加载数据；</p>\n</li>\n<li>\n<p>准备阶段：我们需要探索数据，用数据可视化的方式查看分类结果的情况，以及随着时间的变化，欺诈交易和正常交易的分布情况。上面已经提到过，V1-V28的特征值都经过PCA的变换，但是其余的两个字段，Time和Amount还需要进行规范化。Time字段和交易本身是否为欺诈交易无关，因此我们不作为特征选择，只需要对Amount做数据规范化就行了。同时数据集没有专门的测试集，使用train_test_split对数据集进行划分；</p>\n</li>\n<li>\n<p>分类阶段：我们需要创建逻辑回归分类器，然后传入训练集数据进行训练，并传入测试集预测结果，将预测结果与测试集的结果进行比对。这里的模型评估指标用到了精确率、召回率和F1值。同时我们将精确率-召回率进行了可视化呈现。</p>\n</li>\n</ol><p>基于上面的流程，具体代码如下：</p><pre><code># -*- coding:utf-8 -*-\n# 使用逻辑回归对信用卡欺诈进行分类\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport itertools\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, precision_recall_curve\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\nwarnings.filterwarnings('ignore')\n \n# 混淆矩阵可视化\ndef plot_confusion_matrix(cm, classes, normalize = False, title = 'Confusion matrix&quot;', cmap = plt.cm.Blues) :\n    plt.figure()\n    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation = 0)\n    plt.yticks(tick_marks, classes)\n \n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])) :\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment = 'center',\n                 color = 'white' if cm[i, j] &gt; thresh else 'black')\n \n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()\n \n# 显示模型评估结果\ndef show_metrics():\n    tp = cm[1,1]\n    fn = cm[1,0]\n    fp = cm[0,1]\n    tn = cm[0,0]\n    print('精确率: {:.3f}'.format(tp/(tp+fp)))\n    print('召回率: {:.3f}'.format(tp/(tp+fn)))\n    print('F1值: {:.3f}'.format(2*(((tp/(tp+fp))*(tp/(tp+fn)))/((tp/(tp+fp))+(tp/(tp+fn))))))\n# 绘制精确率-召回率曲线\ndef plot_precision_recall():\n    plt.step(recall, precision, color = 'b', alpha = 0.2, where = 'post')\n    plt.fill_between(recall, precision, step ='post', alpha = 0.2, color = 'b')\n    plt.plot(recall, precision, linewidth=2)\n    plt.xlim([0.0,1])\n    plt.ylim([0.0,1.05])\n    plt.xlabel('召回率')\n    plt.ylabel('精确率')\n    plt.title('精确率-召回率 曲线')\n    plt.show();\n \n# 数据加载\ndata = pd.read_csv('./creditcard.csv')\n# 数据探索\nprint(data.describe())\n# 设置plt正确显示中文\nplt.rcParams['font.sans-serif'] = ['SimHei']\n# 绘制类别分布\nplt.figure()\nax = sns.countplot(x = 'Class', data = data)\nplt.title('类别分布')\nplt.show()\n# 显示交易笔数，欺诈交易笔数\nnum = len(data)\nnum_fraud = len(data[data['Class']==1]) \nprint('总交易笔数: ', num)\nprint('诈骗交易笔数：', num_fraud)\nprint('诈骗交易比例：{:.6f}'.format(num_fraud/num))\n# 欺诈和正常交易可视化\nf, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(15,8))\nbins = 50\nax1.hist(data.Time[data.Class == 1], bins = bins, color = 'deeppink')\nax1.set_title('诈骗交易')\nax2.hist(data.Time[data.Class == 0], bins = bins, color = 'deepskyblue')\nax2.set_title('正常交易')\nplt.xlabel('时间')\nplt.ylabel('交易次数')\nplt.show()\n# 对Amount进行数据规范化\ndata['Amount_Norm'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1,1))\n# 特征选择\ny = np.array(data.Class.tolist())\ndata = data.drop(['Time','Amount','Class'],axis=1)\nX = np.array(data.as_matrix())\n# 准备训练集和测试集\ntrain_x, test_x, train_y, test_y = train_test_split (X, y, test_size = 0.1, random_state = 33)\n \n# 逻辑回归分类\nclf = LogisticRegression()\nclf.fit(train_x, train_y)\npredict_y = clf.predict(test_x)\n# 预测样本的置信分数\nscore_y = clf.decision_function(test_x)  \n# 计算混淆矩阵，并显示\ncm = confusion_matrix(test_y, predict_y)\nclass_names = [0,1]\n# 显示混淆矩阵\nplot_confusion_matrix(cm, classes = class_names, title = '逻辑回归 混淆矩阵')\n# 显示模型评估分数\nshow_metrics()\n# 计算精确率，召回率，阈值用于可视化\nprecision, recall, thresholds = precision_recall_curve(test_y, score_y)\nplot_precision_recall()\n\n</code></pre><p>运行结果：</p><pre><code>                Time            V1      ...               Amount          Class\ncount  284807.000000  2.848070e+05      ...        284807.000000  284807.000000\nmean    94813.859575  1.165980e-15      ...            88.349619       0.001727\nstd     47488.145955  1.958696e+00      ...           250.120109       0.041527\nmin         0.000000 -5.640751e+01      ...             0.000000       0.000000\n25%     54201.500000 -9.203734e-01      ...             5.600000       0.000000\n50%     84692.000000  1.810880e-02      ...            22.000000       0.000000\n75%    139320.500000  1.315642e+00      ...            77.165000       0.000000\nmax    172792.000000  2.454930e+00      ...         25691.160000       1.000000\n\n[8 rows x 31 columns]\n\n</code></pre><p><img src=\"https://static001.geekbang.org/resource/image/5e/61/5e98974d6c2e87168b40e5f751d00f61.png?wh=1728*1363\" alt=\"\"></p><pre><code>总交易笔数:  284807\n诈骗交易笔数： 492\n诈骗交易比例：0.001727\n</code></pre><p><img src=\"https://static001.geekbang.org/resource/image/c8/d2/c8a59cb4f3d94c91eb6648be1b0429d2.png?wh=1726*1022\" alt=\"\"></p><p><img src=\"https://static001.geekbang.org/resource/image/bf/39/bfe65c34b74de661477d9b59d4db6a39.png?wh=1729*1458\" alt=\"\"></p><pre><code>精确率: 0.841\n召回率: 0.617\nF1值: 0.712\n</code></pre><p><img src=\"https://static001.geekbang.org/resource/image/28/69/28ccd0f8d609046b2bafb27fb1195269.png?wh=567*446\" alt=\"\"><br>\n你能看出来欺诈交易的笔数为492笔，占所有交易的比例是很低的，即0.001727，我们可以通过数据可视化的方式对欺诈交易和正常交易的分布进行呈现。另外通过可视化，我们也能看出精确率和召回率之间的关系，当精确率高的时候，召回率往往很低，召回率高的时候，精确率会比较低。</p><p>代码有一些模块需要说明下。</p><p>我定义了plot_confusion_matrix函数对混淆矩阵进行可视化。什么是混淆矩阵呢？混淆矩阵也叫误差矩阵，实际上它就是TP、FP、TN、FN这四个数值的矩阵表示，帮助我们判断预测值和实际值相比，对了多少。从这个例子中，你能看出TP=37，FP=7，FN=23。所以精确率P=TP/(TP+FP)=37/(37+7)=0.841，召回率R=TP/(TP+FN)=37/(37+23)=0.617。</p><p>然后使用了sklearn中的precision_recall_curve函数，通过预测值和真实值来计算精确率-召回率曲线。precision_recall_curve函数会计算在不同概率阈值情况下的精确率和召回率。最后定义plot_precision_recall函数，绘制曲线。</p><h2>总结</h2><p>今天我给你讲了逻辑回归的概念和相关工具的使用，另外学习了在数据样本不平衡的情况下，如何评估模型。这里你需要了解精确率，召回率和F1的概念和计算方式。最后在信用卡欺诈分析的项目中，我们使用了逻辑回归工具，并对混淆矩阵进行了计算，同时在模型结果评估中，使用了精确率、召回率和F1值，最后得到精确率-召回率曲线的可视化结果。</p><p>从这个项目中你能看出来，不是所有的分类都是样本平衡的情况，针对正例比例极低的情况，比如信用卡欺诈、某些疾病的识别，或者是恐怖分子的判断等，都需要采用精确率-召回率来进行统计。</p><p><img src=\"https://static001.geekbang.org/resource/image/ab/50/abee1a58b99814f1e0218778b98a6950.png?wh=1729*824\" alt=\"\"><br>\n最后留两道思考题吧，今天我们对信用卡欺诈数据集进行了分析，它是一个不平衡数据集，你知道还有哪些数据属于不平衡数据么？另外，请你使用线性SVM（对应sklearn中的LinearSVC）对信用卡欺诈数据集进行分类，并计算精确率、召回率和F1值。</p><p>欢迎你在评论区与我分享你的答案，也欢迎点击“请朋友读”，把这篇文章分享给你的朋友或者同事。</p><p></p>","neighbors":{"left":{"article_title":"39丨数据挖掘实战（1）：信用卡违约率分析","id":85577},"right":{"article_title":"41丨数据挖掘实战（3）：如何对比特币走势进行预测？","id":86237}},"comments":[{"had_liked":false,"id":133233,"user_name":"西湖晨曦","can_delete":false,"product_type":"c1","uid":1582253,"ip_address":"","ucode":"38FA2603461C5E","user_header":"https://static001.geekbang.org/account/avatar/00/18/24/ad/54571ab3.jpg","comment_is_top":false,"comment_ctime":1568455495,"is_pvip":false,"replies":[{"id":53401,"content":"很好的问题，你可以进行分类之后，查看下分类器中特征向量的重要程度，然后进行可视化的呈现，比如我们的分类器是clf，使用matplotlib进行可视化，具体代码如下：\n# 显示特征向量的重要程度\ncoeffs = clf.feature_importances_\ndf_co = pd.DataFrame(coeffs, columns=[&quot;importance_&quot;])\n# 下标设置为Feature Name\ndf_co.index = train_features.columns\ndf_co.sort_values(&quot;importance_&quot;, ascending=True, inplace=True)\ndf_co.importance_.plot(kind=&quot;barh&quot;)\nplt.title(&quot;Feature Importance&quot;)\nplt.show()\n","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1570433906,"ip_address":"","comment_id":133233,"utype":1}],"discussion_count":7,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"继续上面的问题。就是，我就是银行信用卡部的工作人员。假设我通过fit()方法得到了信用卡诈骗分析的逻辑回归。假设特征是：性别、收入、是否有房子、是否有车子、是否有助学贷款、是否有公积金这几个特征。我通过fit()方法得到了这个有这些特征的逻辑回归曲线。我如何找到每一个特征前面的系数呢？-----说得直白点，我作为银行信用控制部门工作人员，希望知道上面的特征，哪一个是最重要的，哪一个次重要？哪一个不重要？这样我才能对我的信控工作作出调整。比如我假如知道了是否有助学贷款这个特征不重要，那么我就可以在未来工作中，在银行客户是否允许开信用卡的条件中，取消这个是否有助学贷款的条件，从而给银行信用卡开卡工作带来业务效益。","like_count":22},{"had_liked":false,"id":233206,"user_name":"泷泱汰","can_delete":false,"product_type":"c1","uid":1903845,"ip_address":"","ucode":"4C403F84E06EC2","user_header":"https://static001.geekbang.org/account/avatar/00/1d/0c/e5/d8ba6ba0.jpg","comment_is_top":false,"comment_ctime":1594260536,"is_pvip":false,"replies":[{"id":103080,"content":"感谢泷泱汰同学的分享！as_matrix()确实已经废弃。可以通过data.values或者data.to_numpy()得到DataFrame的数组。","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1616087104,"ip_address":"","comment_id":233206,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"X = np.array(data.as_matrix()) 这个方法现在在pandas里面移除了，改成X = np.array(data.values)","like_count":11,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":467310,"discussion_content":"很好的问题，你可以进行分类之后，查看下分类器中特征向量的重要程度，然后进行可视化的呈现，比如我们的分类器是clf，使用matplotlib进行可视化，具体代码如下：\n# 显示特征向量的重要程度\ncoeffs = clf.feature_importances_\ndf_co = pd.DataFrame(coeffs, columns=[&amp;quot;importance_&amp;quot;])\n# 下标设置为Feature Name\ndf_co.index = train_features.columns\ndf_co.sort_values(&amp;quot;importance_&amp;quot;, ascending=True, inplace=True)\ndf_co.importance_.plot(kind=&amp;quot;barh&amp;quot;)\nplt.title(&amp;quot;Feature Importance&amp;quot;)\nplt.show()\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570433906,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1474214,"avatar":"https://static001.geekbang.org/account/avatar/00/16/7e/a6/4e331ef4.jpg","nickname":"骑行的掌柜J","note":"","ucode":"3163102651C653","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":15150,"discussion_content":"个人思考哈 我觉得你可以尝试分别去掉一个特征看看对最后的精确率-召回率曲线的波动有多大，比如去了性别，看看结果是怎样；下次去掉收入再看看。目前暂时想到这个办法。","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1568807752,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1127175,"avatar":"https://static001.geekbang.org/account/avatar/00/11/33/07/8f351609.jpg","nickname":"JustDoDT","note":"","ucode":"6AF0B80F00EAEF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":242859,"discussion_content":"Python3代码要更改：要不然会报错\nplt.rcParams[&#39;axes.unicode_minus&#39;] = False  # 用来正常显示负号\n# 显示特征向量的重要程度\ncoeffs = clf.coef_\ndf_co = pd.DataFrame(coeffs.T, columns=[&#34;importance_&#34;])\n# 下标设置为Feature Name\ndf_co.index = X.columns\ndf_co.sort_values(&#34;importance_&#34;, ascending=True, inplace=True)\ndf_co.importance_.plot(kind=&#34;barh&#34;)\nplt.title(&#34;Feature Importance&#34;)\nplt.show()","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1587486131,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":2369413,"avatar":"https://static001.geekbang.org/account/avatar/00/24/27/85/ddeeaf30.jpg","nickname":"dived","note":"","ucode":"141916A3BAF5A1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1127175,"avatar":"https://static001.geekbang.org/account/avatar/00/11/33/07/8f351609.jpg","nickname":"JustDoDT","note":"","ucode":"6AF0B80F00EAEF","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":342787,"discussion_content":"这里好像是data.columns吧 X没有columnes属性","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1610810350,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":242859,"ip_address":"","group_id":0},"score":342787,"extra":""}]},{"author":{"id":2864924,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/b7/1c/b5c9456b.jpg","nickname":"Jeff","note":"","ucode":"F9230D1FA48AE1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":566114,"discussion_content":"用特征重要性作为筛选高业务价值的特征是一种不错的方法，但是特征重要性有一个很大的问题就是业务解释性差。比如我有一个CART树模型，现在输出“是否有助学贷款”这个变量的特征重要性是0.3，那业务人员肯定关心0.3代表了什么业务含义呢？这个时候我们给业务讲特征重要性是根据基尼系数算出来的，基尼系数的含义又是balabala，是很难讲清楚的。最好解释的模型就是线性回归模型，回归系数就代表了“在其他条件不变的情况下，如果这个人的助学贷款每提高xxx元，他还款的可能性就会降低百分之xxx”，这样的解释会相对直观一点。但是线性回归模型的问题是模型过于简单，无法有效挖掘特征间非线性的关系。关于模型复杂度与业务的可解释性的平衡，是一个值得研究的问题，不知道老师有没有什么心得。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1650605275,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1127175,"avatar":"https://static001.geekbang.org/account/avatar/00/11/33/07/8f351609.jpg","nickname":"JustDoDT","note":"","ucode":"6AF0B80F00EAEF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":236107,"discussion_content":"很好的问题，给你点赞","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587054001,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1582253,"avatar":"https://static001.geekbang.org/account/avatar/00/18/24/ad/54571ab3.jpg","nickname":"西湖晨曦","note":"","ucode":"38FA2603461C5E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":56583,"discussion_content":"非常好的建议。谢谢老师\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1574499971,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":76650,"user_name":"白夜","can_delete":false,"product_type":"c1","uid":1354449,"ip_address":"","ucode":"7AABFA7C04EA34","user_header":"https://static001.geekbang.org/account/avatar/00/14/aa/d1/076482f3.jpg","comment_is_top":false,"comment_ctime":1552656034,"is_pvip":false,"replies":[{"id":64416,"content":"Good Job","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577618888,"ip_address":"","comment_id":76650,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"试了下SVM\n精确率: 0.843\n召回率: 0.717\nF1值: 0.775\n\n可以通过人的行为（反动言论，购物情况，日常行为）分析预测人群的标签，比如反社会人格，小众爱好者\n也可以，反过来通过人的标签（爱喝酒程度，注意力集中度，运动量等）分析人的行为（车祸，罕见疾病的发生）","like_count":7,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":443389,"discussion_content":"Good Job","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577618888,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":76591,"user_name":"Geek_hve78z","can_delete":false,"product_type":"c1","uid":1015045,"ip_address":"","ucode":"386803B8FC2DD5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg","comment_is_top":false,"comment_ctime":1552636256,"is_pvip":false,"replies":[{"id":64417,"content":"Good Job","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577618895,"ip_address":"","comment_id":76591,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"1、使用LinearSVC输出的结果：\n精确率:0.846\n召回率:0.733\nF1值:0.786\n2、结果代码，把\n\n# 逻辑回归分类\nclf=LogisticRegression()\nclf.fit(train_x,train_y)\npredict_y=clf.predict(test_x)\n\n更换为：\n#线性SVM分类\nfrom sklearn import svm\nmodel=svm.LinearSVC()\nmodel.fit(train_x,train_y)\npredict_y=model.predict(test_x)","like_count":6,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":443366,"discussion_content":"Good Job","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577618895,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":77692,"user_name":"一语中的","can_delete":false,"product_type":"c1","uid":1320112,"ip_address":"","ucode":"E1A0EFCEAD83B4","user_header":"https://static001.geekbang.org/account/avatar/00/14/24/b0/a6e0b03a.jpg","comment_is_top":false,"comment_ctime":1552982169,"is_pvip":false,"replies":[{"id":64400,"content":"Good Job","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577618359,"ip_address":"","comment_id":77692,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"用SVM的LinearSVC算法进行分类\n精确率:0.846\n召回率:0.733\nF1  值:0.786\n如果F1值越大，代表的模型的结果越好，那么SVM应该是优于逻辑回归，但是，从计算时间上来看，用逻辑回归算法比用SVM要节约50多秒（在我本地环境，其他条件不变的情况下）","like_count":4,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":443366,"discussion_content":"Good Job","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577618895,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":133232,"user_name":"西湖晨曦","can_delete":false,"product_type":"c1","uid":1582253,"ip_address":"","ucode":"38FA2603461C5E","user_header":"https://static001.geekbang.org/account/avatar/00/18/24/ad/54571ab3.jpg","comment_is_top":false,"comment_ctime":1568455060,"is_pvip":false,"replies":[{"id":63781,"content":"0.5是个阈值，一般做二分类的时候，大于0.5可以认为是1，小于0.5认为是0，=0.5的时候 可以是0或者1，概率都是一样的","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577541357,"ip_address":"","comment_id":133232,"utype":1}],"discussion_count":4,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"对本期的信用卡诈骗分析中，涉及逻辑回归（LogisticRegression）有几点问题，我在网上找了大量资料都找不到答案。特地求助~ \n1. 逻辑回归数学公式中，求出的值，是介于（0,1）之间。LogisticRegreesion的predict()方法，会设定一个阈值，比如是0.5，把大于0.5的逻辑回归值，设为1，相反小于0.5的，设置为0。那么我的问题是，为什么要设置0.5？是固定的吗？如果我希望把阈值(threshold)提高到0.6，如何设置？---我看了无数遍API，就是找不到如何设置这个阈值。\n 2. 如何看逻辑回归的各个参数。假设我通过fit()这个方法对训练集进行训练，得到了逻辑回归的各个target的值，即我已经得到了这个逻辑回归的各个参数了。假设有10个特征。我如何知道每一个特征前面的变量呢？\n","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":443814,"discussion_content":"Good Job","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577618359,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":118954,"user_name":"陈锦榕","can_delete":false,"product_type":"c1","uid":1352950,"ip_address":"","ucode":"0395281D2B5D54","user_header":"https://static001.geekbang.org/account/avatar/00/14/a4/f6/f2b74c42.jpg","comment_is_top":false,"comment_ctime":1564473651,"is_pvip":false,"replies":[{"id":63611,"content":"Good Job 认真做练习的同学","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577521106,"ip_address":"","comment_id":118954,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"\n***********The evaluation of split test data.*************\nAccuracy-Test data: 0.9601\n************************************************************************************************************************\nKappa: 0.07924493469331251\n************************************************************************************************************************\nConfusion matrix,↓real laebl, →predict label”\n      0    1\n0  9583  397\n1     2   18\n************************************************************************************************************************\n              precision    recall  f1-score   support\n\n           0       1.00      0.96      0.98      9980\n           1       0.04      0.90      0.08        20\n\n    accuracy                           0.96     10000\n   macro avg       0.52      0.93      0.53     10000\nweighted avg       1.00      0.96      0.98     10000","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":467309,"discussion_content":"0.5是个阈值，一般做二分类的时候，大于0.5可以认为是1，小于0.5认为是0，=0.5的时候 可以是0或者1，概率都是一样的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577541357,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1270958,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erBkHFLUBpftqQlK5brd3EDaQFaEfYLfc9iaQrDNJv4eHeSRnSgE5vKnSibJvjUb5hJx5r5nOwa2bRw/132","nickname":"w1sl1y","note":"","ucode":"915073A14B17AB","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":12997,"discussion_content":"Sigmoid函数是仿生函数，如果一个事情我们没有任何信息辅助判断，那么我们判断的概率正确就是50%，也就是0.5。所以如果做二分分类的话，超过0.5就是1，小于0.5就是0","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1568626980,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1869322,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIlAgcic5KYLEly9NXiaYh5IMH94MAxx2QD2zgC1zBEHicV010FpNySPicmjELEn6fUicnEOPmpw5SE1kg/132","nickname":"王英权","note":"","ucode":"DDC1B4DD91CE84","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":290094,"discussion_content":"不一定是设置为0.5，可以调整阈值的，随着阈值的升高，准确率会上升，召回率会下降，然后你看在哪个阈值下，模型的准召数据你可以接受，就用那个阈值","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1594343919,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1988825,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJbuxpls8cAmtDic0lbXjqiblKictEmVZkxHH8iaRq5dRLpoBc0pHZlybY6ERkuCkaQImuNbxj68HpKWQ/132","nickname":"Geek_41d96a","note":"","ucode":"BA85C5BF198399","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":289475,"discussion_content":"1、 你可以试试predict_proba这个函数，对应的是可能性，就是0~1之间的数值，然后你可以自己选择阈值，去判断预测出的可能性与阈值的关系；\n2、模型的coef_和intercept_，是模型的n个特征的权重参数，模型的截距","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1594114242,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":78484,"user_name":"third","can_delete":false,"product_type":"c1","uid":1025114,"ip_address":"","ucode":"9A37408A834F0B","user_header":"https://static001.geekbang.org/account/avatar/00/0f/a4/5a/e708e423.jpg","comment_is_top":false,"comment_ctime":1553157120,"is_pvip":false,"replies":[{"id":64395,"content":"Good Job","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577618259,"ip_address":"","comment_id":78484,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"0、所有的小概率事件都属于不平衡数集，比如得某种病，出现车祸或者意外\n\n1、LinearSVC结果：\n精确率:0.845\n召回率:0.732\nF1值:0.778\n2、结果代码，把\n\n# 逻辑回归分类\nclf=LogisticRegression()\nclf.fit(train_x,train_y)\npredict_y=clf.predict(test_x)\n\n更换为：\n#线性SVM分类\nfrom sklearn import svm\nmodel=svm.LinearSVC()\nmodel.fit(train_x,train_y)\npredict_y=model.predict(test_x)","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":460684,"discussion_content":"Good Job 认真做练习的同学","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577521106,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":76553,"user_name":"Geek_hve78z","can_delete":false,"product_type":"c1","uid":1015045,"ip_address":"","ucode":"386803B8FC2DD5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg","comment_is_top":false,"comment_ctime":1552631687,"is_pvip":false,"replies":[{"id":64421,"content":"总结的不错","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577618935,"ip_address":"","comment_id":76553,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"逻辑回归混淆矩阵对应的TP、FP、TN、FN的位置，以输出的混淆矩阵图为例，\n1）首先这四个概念的定义\n1. TP：预测为正，判断正确；\n2. FP：预测为正，判断错误；\n3. TN：预测为负，判断正确；\n4. FN：预测为负，判断错误。\n2）回归原图\n1、predicted=1，True=1，代表预测为正，判断正确，所以TP=37\n2、predicted=1，true=0，代表预测为正，判断错误，所以FP=7\n3、predicted=0，true=1，代表预测为负，判断错误，所以FN=23\n\n","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":444114,"discussion_content":"Good Job","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577618259,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":269601,"user_name":"拾光","can_delete":false,"product_type":"c1","uid":2087581,"ip_address":"","ucode":"3F88BAB08EF775","user_header":"https://static001.geekbang.org/account/avatar/00/1f/da/9d/1f825568.jpg","comment_is_top":false,"comment_ctime":1608711798,"is_pvip":false,"replies":[{"id":100871,"content":"可以把f1当成对Precision和Recall进行整体评价","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1612705809,"ip_address":"","comment_id":269601,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"F1值表示什么呢，没搞明白，模型判断出一笔交易有可能涉嫌欺诈，准确率只有84.1%，不是也很低吗？","like_count":1,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":443351,"discussion_content":"总结的不错","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577618935,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":133233,"user_name":"西湖晨曦","can_delete":false,"product_type":"c1","uid":1582253,"ip_address":"","ucode":"38FA2603461C5E","user_header":"https://static001.geekbang.org/account/avatar/00/18/24/ad/54571ab3.jpg","comment_is_top":false,"comment_ctime":1568455495,"is_pvip":false,"replies":[{"id":53401,"content":"很好的问题，你可以进行分类之后，查看下分类器中特征向量的重要程度，然后进行可视化的呈现，比如我们的分类器是clf，使用matplotlib进行可视化，具体代码如下：\n# 显示特征向量的重要程度\ncoeffs = clf.feature_importances_\ndf_co = pd.DataFrame(coeffs, columns=[&quot;importance_&quot;])\n# 下标设置为Feature Name\ndf_co.index = train_features.columns\ndf_co.sort_values(&quot;importance_&quot;, ascending=True, inplace=True)\ndf_co.importance_.plot(kind=&quot;barh&quot;)\nplt.title(&quot;Feature Importance&quot;)\nplt.show()\n","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1570433906,"ip_address":"","comment_id":133233,"utype":1}],"discussion_count":7,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"继续上面的问题。就是，我就是银行信用卡部的工作人员。假设我通过fit()方法得到了信用卡诈骗分析的逻辑回归。假设特征是：性别、收入、是否有房子、是否有车子、是否有助学贷款、是否有公积金这几个特征。我通过fit()方法得到了这个有这些特征的逻辑回归曲线。我如何找到每一个特征前面的系数呢？-----说得直白点，我作为银行信用控制部门工作人员，希望知道上面的特征，哪一个是最重要的，哪一个次重要？哪一个不重要？这样我才能对我的信控工作作出调整。比如我假如知道了是否有助学贷款这个特征不重要，那么我就可以在未来工作中，在银行客户是否允许开信用卡的条件中，取消这个是否有助学贷款的条件，从而给银行信用卡开卡工作带来业务效益。","like_count":22,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":467310,"discussion_content":"很好的问题，你可以进行分类之后，查看下分类器中特征向量的重要程度，然后进行可视化的呈现，比如我们的分类器是clf，使用matplotlib进行可视化，具体代码如下：\n# 显示特征向量的重要程度\ncoeffs = clf.feature_importances_\ndf_co = pd.DataFrame(coeffs, columns=[&amp;quot;importance_&amp;quot;])\n# 下标设置为Feature Name\ndf_co.index = train_features.columns\ndf_co.sort_values(&amp;quot;importance_&amp;quot;, ascending=True, inplace=True)\ndf_co.importance_.plot(kind=&amp;quot;barh&amp;quot;)\nplt.title(&amp;quot;Feature Importance&amp;quot;)\nplt.show()\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570433906,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1474214,"avatar":"https://static001.geekbang.org/account/avatar/00/16/7e/a6/4e331ef4.jpg","nickname":"骑行的掌柜J","note":"","ucode":"3163102651C653","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":15150,"discussion_content":"个人思考哈 我觉得你可以尝试分别去掉一个特征看看对最后的精确率-召回率曲线的波动有多大，比如去了性别，看看结果是怎样；下次去掉收入再看看。目前暂时想到这个办法。","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1568807752,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1127175,"avatar":"https://static001.geekbang.org/account/avatar/00/11/33/07/8f351609.jpg","nickname":"JustDoDT","note":"","ucode":"6AF0B80F00EAEF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":242859,"discussion_content":"Python3代码要更改：要不然会报错\nplt.rcParams[&#39;axes.unicode_minus&#39;] = False  # 用来正常显示负号\n# 显示特征向量的重要程度\ncoeffs = clf.coef_\ndf_co = pd.DataFrame(coeffs.T, columns=[&#34;importance_&#34;])\n# 下标设置为Feature Name\ndf_co.index = X.columns\ndf_co.sort_values(&#34;importance_&#34;, ascending=True, inplace=True)\ndf_co.importance_.plot(kind=&#34;barh&#34;)\nplt.title(&#34;Feature Importance&#34;)\nplt.show()","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1587486131,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":2369413,"avatar":"https://static001.geekbang.org/account/avatar/00/24/27/85/ddeeaf30.jpg","nickname":"dived","note":"","ucode":"141916A3BAF5A1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1127175,"avatar":"https://static001.geekbang.org/account/avatar/00/11/33/07/8f351609.jpg","nickname":"JustDoDT","note":"","ucode":"6AF0B80F00EAEF","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":342787,"discussion_content":"这里好像是data.columns吧 X没有columnes属性","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1610810350,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":242859,"ip_address":"","group_id":0},"score":342787,"extra":""}]},{"author":{"id":2864924,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/b7/1c/b5c9456b.jpg","nickname":"Jeff","note":"","ucode":"F9230D1FA48AE1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":566114,"discussion_content":"用特征重要性作为筛选高业务价值的特征是一种不错的方法，但是特征重要性有一个很大的问题就是业务解释性差。比如我有一个CART树模型，现在输出“是否有助学贷款”这个变量的特征重要性是0.3，那业务人员肯定关心0.3代表了什么业务含义呢？这个时候我们给业务讲特征重要性是根据基尼系数算出来的，基尼系数的含义又是balabala，是很难讲清楚的。最好解释的模型就是线性回归模型，回归系数就代表了“在其他条件不变的情况下，如果这个人的助学贷款每提高xxx元，他还款的可能性就会降低百分之xxx”，这样的解释会相对直观一点。但是线性回归模型的问题是模型过于简单，无法有效挖掘特征间非线性的关系。关于模型复杂度与业务的可解释性的平衡，是一个值得研究的问题，不知道老师有没有什么心得。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1650605275,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1127175,"avatar":"https://static001.geekbang.org/account/avatar/00/11/33/07/8f351609.jpg","nickname":"JustDoDT","note":"","ucode":"6AF0B80F00EAEF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":236107,"discussion_content":"很好的问题，给你点赞","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587054001,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1582253,"avatar":"https://static001.geekbang.org/account/avatar/00/18/24/ad/54571ab3.jpg","nickname":"西湖晨曦","note":"","ucode":"38FA2603461C5E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":56583,"discussion_content":"非常好的建议。谢谢老师\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1574499971,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":233206,"user_name":"泷泱汰","can_delete":false,"product_type":"c1","uid":1903845,"ip_address":"","ucode":"4C403F84E06EC2","user_header":"https://static001.geekbang.org/account/avatar/00/1d/0c/e5/d8ba6ba0.jpg","comment_is_top":false,"comment_ctime":1594260536,"is_pvip":false,"replies":[{"id":103080,"content":"感谢泷泱汰同学的分享！as_matrix()确实已经废弃。可以通过data.values或者data.to_numpy()得到DataFrame的数组。","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1616087104,"ip_address":"","comment_id":233206,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"X = np.array(data.as_matrix()) 这个方法现在在pandas里面移除了，改成X = np.array(data.values)","like_count":11,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":500942,"discussion_content":"感谢泷泱汰同学的分享！as_matrix()确实已经废弃。可以通过data.values或者data.to_numpy()得到DataFrame的数组。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616087104,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":76650,"user_name":"白夜","can_delete":false,"product_type":"c1","uid":1354449,"ip_address":"","ucode":"7AABFA7C04EA34","user_header":"https://static001.geekbang.org/account/avatar/00/14/aa/d1/076482f3.jpg","comment_is_top":false,"comment_ctime":1552656034,"is_pvip":false,"replies":[{"id":64416,"content":"Good Job","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577618888,"ip_address":"","comment_id":76650,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"试了下SVM\n精确率: 0.843\n召回率: 0.717\nF1值: 0.775\n\n可以通过人的行为（反动言论，购物情况，日常行为）分析预测人群的标签，比如反社会人格，小众爱好者\n也可以，反过来通过人的标签（爱喝酒程度，注意力集中度，运动量等）分析人的行为（车祸，罕见疾病的发生）","like_count":7,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":500942,"discussion_content":"感谢泷泱汰同学的分享！as_matrix()确实已经废弃。可以通过data.values或者data.to_numpy()得到DataFrame的数组。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616087104,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":76591,"user_name":"Geek_hve78z","can_delete":false,"product_type":"c1","uid":1015045,"ip_address":"","ucode":"386803B8FC2DD5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg","comment_is_top":false,"comment_ctime":1552636256,"is_pvip":false,"replies":[{"id":64417,"content":"Good Job","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577618895,"ip_address":"","comment_id":76591,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"1、使用LinearSVC输出的结果：\n精确率:0.846\n召回率:0.733\nF1值:0.786\n2、结果代码，把\n\n# 逻辑回归分类\nclf=LogisticRegression()\nclf.fit(train_x,train_y)\npredict_y=clf.predict(test_x)\n\n更换为：\n#线性SVM分类\nfrom sklearn import svm\nmodel=svm.LinearSVC()\nmodel.fit(train_x,train_y)\npredict_y=model.predict(test_x)","like_count":6,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":443389,"discussion_content":"Good Job","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577618888,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":77692,"user_name":"一语中的","can_delete":false,"product_type":"c1","uid":1320112,"ip_address":"","ucode":"E1A0EFCEAD83B4","user_header":"https://static001.geekbang.org/account/avatar/00/14/24/b0/a6e0b03a.jpg","comment_is_top":false,"comment_ctime":1552982169,"is_pvip":false,"replies":[{"id":64400,"content":"Good Job","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577618359,"ip_address":"","comment_id":77692,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"用SVM的LinearSVC算法进行分类\n精确率:0.846\n召回率:0.733\nF1  值:0.786\n如果F1值越大，代表的模型的结果越好，那么SVM应该是优于逻辑回归，但是，从计算时间上来看，用逻辑回归算法比用SVM要节约50多秒（在我本地环境，其他条件不变的情况下）","like_count":4,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":443814,"discussion_content":"Good Job","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577618359,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":133232,"user_name":"西湖晨曦","can_delete":false,"product_type":"c1","uid":1582253,"ip_address":"","ucode":"38FA2603461C5E","user_header":"https://static001.geekbang.org/account/avatar/00/18/24/ad/54571ab3.jpg","comment_is_top":false,"comment_ctime":1568455060,"is_pvip":false,"replies":[{"id":63781,"content":"0.5是个阈值，一般做二分类的时候，大于0.5可以认为是1，小于0.5认为是0，=0.5的时候 可以是0或者1，概率都是一样的","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577541357,"ip_address":"","comment_id":133232,"utype":1}],"discussion_count":4,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"对本期的信用卡诈骗分析中，涉及逻辑回归（LogisticRegression）有几点问题，我在网上找了大量资料都找不到答案。特地求助~ \n1. 逻辑回归数学公式中，求出的值，是介于（0,1）之间。LogisticRegreesion的predict()方法，会设定一个阈值，比如是0.5，把大于0.5的逻辑回归值，设为1，相反小于0.5的，设置为0。那么我的问题是，为什么要设置0.5？是固定的吗？如果我希望把阈值(threshold)提高到0.6，如何设置？---我看了无数遍API，就是找不到如何设置这个阈值。\n 2. 如何看逻辑回归的各个参数。假设我通过fit()这个方法对训练集进行训练，得到了逻辑回归的各个target的值，即我已经得到了这个逻辑回归的各个参数了。假设有10个特征。我如何知道每一个特征前面的变量呢？\n","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":467309,"discussion_content":"0.5是个阈值，一般做二分类的时候，大于0.5可以认为是1，小于0.5认为是0，=0.5的时候 可以是0或者1，概率都是一样的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577541357,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1270958,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erBkHFLUBpftqQlK5brd3EDaQFaEfYLfc9iaQrDNJv4eHeSRnSgE5vKnSibJvjUb5hJx5r5nOwa2bRw/132","nickname":"w1sl1y","note":"","ucode":"915073A14B17AB","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":12997,"discussion_content":"Sigmoid函数是仿生函数，如果一个事情我们没有任何信息辅助判断，那么我们判断的概率正确就是50%，也就是0.5。所以如果做二分分类的话，超过0.5就是1，小于0.5就是0","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1568626980,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1869322,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIlAgcic5KYLEly9NXiaYh5IMH94MAxx2QD2zgC1zBEHicV010FpNySPicmjELEn6fUicnEOPmpw5SE1kg/132","nickname":"王英权","note":"","ucode":"DDC1B4DD91CE84","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":290094,"discussion_content":"不一定是设置为0.5，可以调整阈值的，随着阈值的升高，准确率会上升，召回率会下降，然后你看在哪个阈值下，模型的准召数据你可以接受，就用那个阈值","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1594343919,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1988825,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJbuxpls8cAmtDic0lbXjqiblKictEmVZkxHH8iaRq5dRLpoBc0pHZlybY6ERkuCkaQImuNbxj68HpKWQ/132","nickname":"Geek_41d96a","note":"","ucode":"BA85C5BF198399","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":289475,"discussion_content":"1、 你可以试试predict_proba这个函数，对应的是可能性，就是0~1之间的数值，然后你可以自己选择阈值，去判断预测出的可能性与阈值的关系；\n2、模型的coef_和intercept_，是模型的n个特征的权重参数，模型的截距","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1594114242,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":118954,"user_name":"陈锦榕","can_delete":false,"product_type":"c1","uid":1352950,"ip_address":"","ucode":"0395281D2B5D54","user_header":"https://static001.geekbang.org/account/avatar/00/14/a4/f6/f2b74c42.jpg","comment_is_top":false,"comment_ctime":1564473651,"is_pvip":false,"replies":[{"id":63611,"content":"Good Job 认真做练习的同学","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577521106,"ip_address":"","comment_id":118954,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"\n***********The evaluation of split test data.*************\nAccuracy-Test data: 0.9601\n************************************************************************************************************************\nKappa: 0.07924493469331251\n************************************************************************************************************************\nConfusion matrix,↓real laebl, →predict label”\n      0    1\n0  9583  397\n1     2   18\n************************************************************************************************************************\n              precision    recall  f1-score   support\n\n           0       1.00      0.96      0.98      9980\n           1       0.04      0.90      0.08        20\n\n    accuracy                           0.96     10000\n   macro avg       0.52      0.93      0.53     10000\nweighted avg       1.00      0.96      0.98     10000","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":460684,"discussion_content":"Good Job 认真做练习的同学","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577521106,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":78484,"user_name":"third","can_delete":false,"product_type":"c1","uid":1025114,"ip_address":"","ucode":"9A37408A834F0B","user_header":"https://static001.geekbang.org/account/avatar/00/0f/a4/5a/e708e423.jpg","comment_is_top":false,"comment_ctime":1553157120,"is_pvip":false,"replies":[{"id":64395,"content":"Good Job","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577618259,"ip_address":"","comment_id":78484,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"0、所有的小概率事件都属于不平衡数集，比如得某种病，出现车祸或者意外\n\n1、LinearSVC结果：\n精确率:0.845\n召回率:0.732\nF1值:0.778\n2、结果代码，把\n\n# 逻辑回归分类\nclf=LogisticRegression()\nclf.fit(train_x,train_y)\npredict_y=clf.predict(test_x)\n\n更换为：\n#线性SVM分类\nfrom sklearn import svm\nmodel=svm.LinearSVC()\nmodel.fit(train_x,train_y)\npredict_y=model.predict(test_x)","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":444114,"discussion_content":"Good Job","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577618259,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":76553,"user_name":"Geek_hve78z","can_delete":false,"product_type":"c1","uid":1015045,"ip_address":"","ucode":"386803B8FC2DD5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg","comment_is_top":false,"comment_ctime":1552631687,"is_pvip":false,"replies":[{"id":64421,"content":"总结的不错","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577618935,"ip_address":"","comment_id":76553,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"逻辑回归混淆矩阵对应的TP、FP、TN、FN的位置，以输出的混淆矩阵图为例，\n1）首先这四个概念的定义\n1. TP：预测为正，判断正确；\n2. FP：预测为正，判断错误；\n3. TN：预测为负，判断正确；\n4. FN：预测为负，判断错误。\n2）回归原图\n1、predicted=1，True=1，代表预测为正，判断正确，所以TP=37\n2、predicted=1，true=0，代表预测为正，判断错误，所以FP=7\n3、predicted=0，true=1，代表预测为负，判断错误，所以FN=23\n\n","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":443351,"discussion_content":"总结的不错","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577618935,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":269601,"user_name":"拾光","can_delete":false,"product_type":"c1","uid":2087581,"ip_address":"","ucode":"3F88BAB08EF775","user_header":"https://static001.geekbang.org/account/avatar/00/1f/da/9d/1f825568.jpg","comment_is_top":false,"comment_ctime":1608711798,"is_pvip":false,"replies":[{"id":100871,"content":"可以把f1当成对Precision和Recall进行整体评价","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1612705809,"ip_address":"","comment_id":269601,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100021701,"comment_content":"F1值表示什么呢，没搞明白，模型判断出一笔交易有可能涉嫌欺诈，准确率只有84.1%，不是也很低吗？","like_count":1,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":512332,"discussion_content":"可以把f1当成对Precision和Recall进行整体评价","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1612705809,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":206416,"user_name":"Simon","can_delete":false,"product_type":"c1","uid":1914504,"ip_address":"","ucode":"A8A2E3E57BD029","user_header":"https://static001.geekbang.org/account/avatar/00/1d/36/88/20b6a6ee.jpg","comment_is_top":false,"comment_ctime":1586857858,"is_pvip":false,"replies":[{"id":103982,"content":"演示的时候没有使用分层采样。你也可以尝试分层，实际应用中是否需要分层，根据在测试集上的表现选择即可","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1617291662,"ip_address":"","comment_id":206416,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"正负样本极不均衡，为什么在train_test_split时，没有分层采样：stratify=y？","like_count":1},{"had_liked":false,"id":202506,"user_name":"建强","can_delete":false,"product_type":"c1","uid":1397126,"ip_address":"","ucode":"62B03D0E0C64EC","user_header":"https://static001.geekbang.org/account/avatar/00/15/51/86/b5fd8dd8.jpg","comment_is_top":false,"comment_ctime":1585997630,"is_pvip":false,"replies":[{"id":104334,"content":"Good Job","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1617903489,"ip_address":"","comment_id":202506,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"思考题：\n1.不平衡的数据：历年飞机空难和正常飞行的数据，历年发生重大事故的企业和正常生产的企业\n2.使用SVM模型对信用卡数据集分类，计算效率比逻辑回归模型低很多，精确率要低于逻辑回归、但召回率和F1都要高于逻辑回归模型，这三个指标分别为\n精确率: 0.793\n召回率: 0.767\nF1值: 0.780","like_count":1,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491781,"discussion_content":"演示的时候没有使用分层采样。你也可以尝试分层，实际应用中是否需要分层，根据在测试集上的表现选择即可","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617291662,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":206411,"user_name":"Simon","can_delete":false,"product_type":"c1","uid":1914504,"ip_address":"","ucode":"A8A2E3E57BD029","user_header":"https://static001.geekbang.org/account/avatar/00/1d/36/88/20b6a6ee.jpg","comment_is_top":false,"comment_ctime":1586856693,"is_pvip":false,"replies":[{"id":103983,"content":"是的。Amount量级太大，不利于模型收敛，所以进行了标准化。","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1617291920,"ip_address":"","comment_id":206411,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"为什么v1~v28没有做归一化？只是&quot;Amount&quot;做了。因为v1~v28量纲差不多？","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":490602,"discussion_content":"Good Job","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617903489,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":196965,"user_name":"张贺","can_delete":false,"product_type":"c1","uid":1283181,"ip_address":"","ucode":"0254E40FB3EB5F","user_header":"https://static001.geekbang.org/account/avatar/00/13/94/6d/5cd6e8c7.jpg","comment_is_top":false,"comment_ctime":1585325357,"is_pvip":false,"replies":[{"id":104342,"content":"很棒！","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1617904143,"ip_address":"","comment_id":196965,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"精确率: 0.846\n召回率: 0.733\nF1值: 0.786","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491780,"discussion_content":"是的。Amount量级太大，不利于模型收敛，所以进行了标准化。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617291920,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":195798,"user_name":"桔子","can_delete":false,"product_type":"c1","uid":1245080,"ip_address":"","ucode":"635DB29C04FD47","user_header":"https://static001.geekbang.org/account/avatar/00/12/ff/98/6e17646a.jpg","comment_is_top":false,"comment_ctime":1585215711,"is_pvip":false,"replies":[{"id":104348,"content":"可以的。确实需要考虑去除多重共线性特征的问题","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1617904262,"ip_address":"","comment_id":195798,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"前提是进行了pca处理，不然还要考虑多重共线性","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":489158,"discussion_content":"可以的。确实需要考虑去除多重共线性特征的问题","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617904262,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":191446,"user_name":"Since一九八三","can_delete":false,"product_type":"c1","uid":1793018,"ip_address":"","ucode":"0D968260C59ED8","user_header":"https://static001.geekbang.org/account/avatar/00/1b/5b/fa/b796d9f0.jpg","comment_is_top":false,"comment_ctime":1584774175,"is_pvip":false,"replies":[{"id":104357,"content":"看特征代表的含义，如果没有特殊说明，按照常理无法判断出有序逻辑时，按照无序进行处理。有序的类别特征如：中高低；无序的类别特征，如：男女，苹果、橘子、香蕉。\n一般有序的类别特征常使用的one-hot方式。","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1617904768,"ip_address":"","comment_id":191446,"utype":1}],"discussion_count":2,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"老师您好，我想请问一下V1，V2，……V28这28个特征是如何判定他是有序的数值特征还是无序的类别特征呢？如果这是无序类别特征是不是需要做独热编码处理呢？但是这类别数量太大要怎么做独热？","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":488174,"discussion_content":"看特征代表的含义，如果没有特殊说明，按照常理无法判断出有序逻辑时，按照无序进行处理。有序的类别特征如：中高低；无序的类别特征，如：男女，苹果、橘子、香蕉。\n一般有序的类别特征常使用的one-hot方式。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617904768,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":2864924,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/b7/1c/b5c9456b.jpg","nickname":"Jeff","note":"","ucode":"F9230D1FA48AE1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":566120,"discussion_content":"老师是不是说反了，one-hot编码一般用于无序的类别特征吧，用于有序类别特征是不是会丢失排序信息？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1650606303,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":488174,"ip_address":"","group_id":0},"score":566120,"extra":""}]}]},{"had_liked":false,"id":122296,"user_name":"Sam.张朝","can_delete":false,"product_type":"c1","uid":1132448,"ip_address":"","ucode":"FB20554D94B250","user_header":"https://static001.geekbang.org/account/avatar/00/11/47/a0/f12115b7.jpg","comment_is_top":false,"comment_ctime":1565333523,"is_pvip":true,"replies":[{"id":63562,"content":"这个是可以判断的","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577518298,"ip_address":"","comment_id":122296,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"我以为程序是判断一笔交易，是否是不正常的。","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":462193,"discussion_content":"这个是可以判断的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577518298,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":114926,"user_name":"东东哥","can_delete":false,"product_type":"c1","uid":1460044,"ip_address":"","ucode":"99F28A9A36E376","user_header":"https://static001.geekbang.org/account/avatar/00/16/47/4c/65404d1e.jpg","comment_is_top":false,"comment_ctime":1563434561,"is_pvip":false,"replies":[{"id":63683,"content":"解释正确","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577528168,"ip_address":"","comment_id":114926,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"(0, 0)格子真实值和预测值都为0，称为预测Negative正确，记作True Negative，简写为TN。\n(0, 1)格子真实值为0，但预测值为1，称为预测Positive错误，记作False Positive，简写为FP。\n(1, 0)格子真实值为1， 但预测值为0，称为预测Negative错误，记作False Negative，简写为FN。\n(1, 1)格子真实值和预测值都为1，称为预测Positive正确，记作True Positive，简写为TP。","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":458890,"discussion_content":"解释正确","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577528168,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":79203,"user_name":"digitarts","can_delete":false,"product_type":"c1","uid":1032996,"ip_address":"","ucode":"3EDED45A6F2E54","user_header":"https://static001.geekbang.org/account/avatar/00/0f/c3/24/4731d31d.jpg","comment_is_top":false,"comment_ctime":1553400307,"is_pvip":false,"replies":[{"id":64368,"content":"不太可能完全吻合","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577617867,"ip_address":"","comment_id":79203,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"老师，我看到，在预测比特币走势的最后一张图表上，实际值与预测值尽管趋势类似，但是在发生的时间上，测试值比实际值晚了一段时间，请问有什么方法尽量缩短这个时间序列的间隙么？多谢🙏","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":444395,"discussion_content":"不太可能完全吻合","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577617867,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":77729,"user_name":"TKbook","can_delete":false,"product_type":"c1","uid":1073829,"ip_address":"","ucode":"F6E0E99CC79059","user_header":"https://static001.geekbang.org/account/avatar/00/10/62/a5/43aa0c27.jpg","comment_is_top":false,"comment_ctime":1552987512,"is_pvip":false,"replies":[{"id":64398,"content":"Good Job","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577618338,"ip_address":"","comment_id":77729,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"model = svm.SVC()\nmodel.fit(train_x, train_y)\npredict_y = model.predict(test_x)\ncm = confusion_matrix(test_y, predict_y)\nshow_metrics()\n\n精确率：0.953\n召回率：0.683\nF1值：0.796","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":443827,"discussion_content":"Good Job","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577618338,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":206416,"user_name":"Simon","can_delete":false,"product_type":"c1","uid":1914504,"ip_address":"","ucode":"A8A2E3E57BD029","user_header":"https://static001.geekbang.org/account/avatar/00/1d/36/88/20b6a6ee.jpg","comment_is_top":false,"comment_ctime":1586857858,"is_pvip":false,"replies":[{"id":103982,"content":"演示的时候没有使用分层采样。你也可以尝试分层，实际应用中是否需要分层，根据在测试集上的表现选择即可","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1617291662,"ip_address":"","comment_id":206416,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"正负样本极不均衡，为什么在train_test_split时，没有分层采样：stratify=y？","like_count":1,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491781,"discussion_content":"演示的时候没有使用分层采样。你也可以尝试分层，实际应用中是否需要分层，根据在测试集上的表现选择即可","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617291662,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":202506,"user_name":"建强","can_delete":false,"product_type":"c1","uid":1397126,"ip_address":"","ucode":"62B03D0E0C64EC","user_header":"https://static001.geekbang.org/account/avatar/00/15/51/86/b5fd8dd8.jpg","comment_is_top":false,"comment_ctime":1585997630,"is_pvip":false,"replies":[{"id":104334,"content":"Good Job","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1617903489,"ip_address":"","comment_id":202506,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"思考题：\n1.不平衡的数据：历年飞机空难和正常飞行的数据，历年发生重大事故的企业和正常生产的企业\n2.使用SVM模型对信用卡数据集分类，计算效率比逻辑回归模型低很多，精确率要低于逻辑回归、但召回率和F1都要高于逻辑回归模型，这三个指标分别为\n精确率: 0.793\n召回率: 0.767\nF1值: 0.780","like_count":1,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":490602,"discussion_content":"Good Job","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617903489,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":206411,"user_name":"Simon","can_delete":false,"product_type":"c1","uid":1914504,"ip_address":"","ucode":"A8A2E3E57BD029","user_header":"https://static001.geekbang.org/account/avatar/00/1d/36/88/20b6a6ee.jpg","comment_is_top":false,"comment_ctime":1586856693,"is_pvip":false,"replies":[{"id":103983,"content":"是的。Amount量级太大，不利于模型收敛，所以进行了标准化。","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1617291920,"ip_address":"","comment_id":206411,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"为什么v1~v28没有做归一化？只是&quot;Amount&quot;做了。因为v1~v28量纲差不多？","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491780,"discussion_content":"是的。Amount量级太大，不利于模型收敛，所以进行了标准化。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617291920,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":196965,"user_name":"张贺","can_delete":false,"product_type":"c1","uid":1283181,"ip_address":"","ucode":"0254E40FB3EB5F","user_header":"https://static001.geekbang.org/account/avatar/00/13/94/6d/5cd6e8c7.jpg","comment_is_top":false,"comment_ctime":1585325357,"is_pvip":false,"replies":[{"id":104342,"content":"很棒！","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1617904143,"ip_address":"","comment_id":196965,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"精确率: 0.846\n召回率: 0.733\nF1值: 0.786","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":489424,"discussion_content":"很棒！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617904143,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":195798,"user_name":"桔子","can_delete":false,"product_type":"c1","uid":1245080,"ip_address":"","ucode":"635DB29C04FD47","user_header":"https://static001.geekbang.org/account/avatar/00/12/ff/98/6e17646a.jpg","comment_is_top":false,"comment_ctime":1585215711,"is_pvip":false,"replies":[{"id":104348,"content":"可以的。确实需要考虑去除多重共线性特征的问题","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1617904262,"ip_address":"","comment_id":195798,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"前提是进行了pca处理，不然还要考虑多重共线性","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":489424,"discussion_content":"很棒！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617904143,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":191446,"user_name":"Since一九八三","can_delete":false,"product_type":"c1","uid":1793018,"ip_address":"","ucode":"0D968260C59ED8","user_header":"https://static001.geekbang.org/account/avatar/00/1b/5b/fa/b796d9f0.jpg","comment_is_top":false,"comment_ctime":1584774175,"is_pvip":false,"replies":[{"id":104357,"content":"看特征代表的含义，如果没有特殊说明，按照常理无法判断出有序逻辑时，按照无序进行处理。有序的类别特征如：中高低；无序的类别特征，如：男女，苹果、橘子、香蕉。\n一般有序的类别特征常使用的one-hot方式。","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1617904768,"ip_address":"","comment_id":191446,"utype":1}],"discussion_count":2,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"老师您好，我想请问一下V1，V2，……V28这28个特征是如何判定他是有序的数值特征还是无序的类别特征呢？如果这是无序类别特征是不是需要做独热编码处理呢？但是这类别数量太大要怎么做独热？","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":489158,"discussion_content":"可以的。确实需要考虑去除多重共线性特征的问题","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617904262,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":122296,"user_name":"Sam.张朝","can_delete":false,"product_type":"c1","uid":1132448,"ip_address":"","ucode":"FB20554D94B250","user_header":"https://static001.geekbang.org/account/avatar/00/11/47/a0/f12115b7.jpg","comment_is_top":false,"comment_ctime":1565333523,"is_pvip":true,"replies":[{"id":63562,"content":"这个是可以判断的","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577518298,"ip_address":"","comment_id":122296,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"我以为程序是判断一笔交易，是否是不正常的。","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":488174,"discussion_content":"看特征代表的含义，如果没有特殊说明，按照常理无法判断出有序逻辑时，按照无序进行处理。有序的类别特征如：中高低；无序的类别特征，如：男女，苹果、橘子、香蕉。\n一般有序的类别特征常使用的one-hot方式。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617904768,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":2864924,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/b7/1c/b5c9456b.jpg","nickname":"Jeff","note":"","ucode":"F9230D1FA48AE1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":566120,"discussion_content":"老师是不是说反了，one-hot编码一般用于无序的类别特征吧，用于有序类别特征是不是会丢失排序信息？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1650606303,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":488174,"ip_address":"","group_id":0},"score":566120,"extra":""}]}]},{"had_liked":false,"id":114926,"user_name":"东东哥","can_delete":false,"product_type":"c1","uid":1460044,"ip_address":"","ucode":"99F28A9A36E376","user_header":"https://static001.geekbang.org/account/avatar/00/16/47/4c/65404d1e.jpg","comment_is_top":false,"comment_ctime":1563434561,"is_pvip":false,"replies":[{"id":63683,"content":"解释正确","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577528168,"ip_address":"","comment_id":114926,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"(0, 0)格子真实值和预测值都为0，称为预测Negative正确，记作True Negative，简写为TN。\n(0, 1)格子真实值为0，但预测值为1，称为预测Positive错误，记作False Positive，简写为FP。\n(1, 0)格子真实值为1， 但预测值为0，称为预测Negative错误，记作False Negative，简写为FN。\n(1, 1)格子真实值和预测值都为1，称为预测Positive正确，记作True Positive，简写为TP。","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":462193,"discussion_content":"这个是可以判断的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577518298,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":79203,"user_name":"digitarts","can_delete":false,"product_type":"c1","uid":1032996,"ip_address":"","ucode":"3EDED45A6F2E54","user_header":"https://static001.geekbang.org/account/avatar/00/0f/c3/24/4731d31d.jpg","comment_is_top":false,"comment_ctime":1553400307,"is_pvip":false,"replies":[{"id":64368,"content":"不太可能完全吻合","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577617867,"ip_address":"","comment_id":79203,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"老师，我看到，在预测比特币走势的最后一张图表上，实际值与预测值尽管趋势类似，但是在发生的时间上，测试值比实际值晚了一段时间，请问有什么方法尽量缩短这个时间序列的间隙么？多谢🙏","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":458890,"discussion_content":"解释正确","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577528168,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":77729,"user_name":"TKbook","can_delete":false,"product_type":"c1","uid":1073829,"ip_address":"","ucode":"F6E0E99CC79059","user_header":"https://static001.geekbang.org/account/avatar/00/10/62/a5/43aa0c27.jpg","comment_is_top":false,"comment_ctime":1552987512,"is_pvip":false,"replies":[{"id":64398,"content":"Good Job","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577618338,"ip_address":"","comment_id":77729,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100021701,"comment_content":"model = svm.SVC()\nmodel.fit(train_x, train_y)\npredict_y = model.predict(test_x)\ncm = confusion_matrix(test_y, predict_y)\nshow_metrics()\n\n精确率：0.953\n召回率：0.683\nF1值：0.796","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":444395,"discussion_content":"不太可能完全吻合","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577617867,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":76579,"user_name":"一语中的","can_delete":false,"product_type":"c1","uid":1320112,"ip_address":"","ucode":"E1A0EFCEAD83B4","user_header":"https://static001.geekbang.org/account/avatar/00/14/24/b0/a6e0b03a.jpg","comment_is_top":false,"comment_ctime":1552634887,"is_pvip":false,"replies":[{"id":64418,"content":"很好的分享，不过彩票这个很难预测","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577618908,"ip_address":"","comment_id":76579,"utype":1}],"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"不平衡数据：\n1.欺诈预测（欺诈的数量远远小于真实交易的数量）\n比如，本节内容的信用卡欺诈交易\n2.自然灾害预测（不好的事情远远小于好的事情）\n3.买彩票中奖（小概率）\n4.在图像分类中识别恶性肿瘤（训练样本中含有肿瘤的图像远比没有肿瘤的图像少）","like_count":0},{"had_liked":false,"id":76563,"user_name":"Geek_hve78z","can_delete":false,"product_type":"c1","uid":1015045,"ip_address":"","ucode":"386803B8FC2DD5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg","comment_is_top":false,"comment_ctime":1552633015,"is_pvip":false,"replies":[{"id":64420,"content":"总结的不错","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577618928,"ip_address":"","comment_id":76563,"utype":1}],"discussion_count":1,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"不均衡数据集是指，数据集中每个类别下的样本数目相差很大。\n比如，在客户流失的数据集中，绝大部分的客户是会继续享受其服务的（非流失对象），只有极少数部分的客户不会再继续享受其服务（流失对象）\n又如，检查出厂冰箱的合格率，本来合格率就高达了96%。如果对样本进行检测，准确率也是很高的，那么将会无法判断次品。\n再如，检查邮件中的垃圾邮件，因为垃圾邮件占全部邮件极少的部分，所以也是属于不平衡数据集\n","like_count":0},{"had_liked":false,"id":188944,"user_name":"换个调调","can_delete":false,"product_type":"c1","uid":1674204,"ip_address":"","ucode":"F781C8EBB6D529","user_header":"https://static001.geekbang.org/account/avatar/00/19/8b/dc/925e0f8a.jpg","comment_is_top":false,"comment_ctime":1584437222,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"1.置信分数是一个什么概念呢？\n2.为什么计算PR值取 score_y 而不是 pred_y?\n3.像SVC、LogisticRegression没有 feature_importances 如何判断各个特征的重要性呢？","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":443356,"discussion_content":"总结的不错","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577618928,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":355487,"user_name":"feng","can_delete":false,"product_type":"c1","uid":1126994,"ip_address":"湖南","ucode":"A9C47271F1E710","user_header":"https://static001.geekbang.org/account/avatar/00/11/32/52/c843fc53.jpg","comment_is_top":false,"comment_ctime":1661422037,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"逻辑回归模型的求解这里不做介绍，我们来看下如何使用 sklearn 中的逻辑回归工具。在 sklearn 中，我们使用 LogisticRegression() 函数构建逻辑回归分类器，函数里有一些常用的构造参数：penalty：惩罚项，取值为 l1 或 l2，默认为 l2。当模型参数满足高斯分布的时候，使用 l2，当模型参数满足拉普拉斯分布的时候，使用 l1；\n请问老师这个模型的参数是满足高斯分布还是拉普拉斯分布，为什么？","like_count":1},{"had_liked":false,"id":334231,"user_name":"杨博","can_delete":false,"product_type":"c1","uid":1194024,"ip_address":"","ucode":"6949F3A2DD529F","user_header":"","comment_is_top":false,"comment_ctime":1644823764,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"问题一：本文中PCA如何判断降维到28是较适合？维度不同对结果的影响很大。\n问题二：在其他的场景进行回归预测，1954条数据，20个特征变量，但是在sklearn中的几个典型的回归模型中R2分值差别很大，集成类的模型打分0.93+，有的0.7+，有的0.8+，请教是数据存在一定问题？还是模型不合适的问题？","like_count":1},{"had_liked":false,"id":265026,"user_name":"非同凡想","can_delete":false,"product_type":"c1","uid":1934969,"ip_address":"","ucode":"713FD449A49D5A","user_header":"https://static001.geekbang.org/account/avatar/00/1d/86/79/066a062a.jpg","comment_is_top":false,"comment_ctime":1606738450,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"reg = LinearSVC()\nreg.fit(train_x, train_y)\npred_y = reg.predict(test_x)\ncm = confusion_matrix(test_y, pred_y)\nclass_names = [0,1]\nplot_confusion_matrix(cm, classes=class_names, title=&#39;混淆矩阵&#39; )\nshow_metrics(cm)\n\nprecision:0.830\nrecall:0.650\nf1:0.729","like_count":0},{"had_liked":false,"id":261748,"user_name":"Geek_00acb1","can_delete":false,"product_type":"c1","uid":2204908,"ip_address":"","ucode":"B00B73D265C6D0","user_header":"","comment_is_top":false,"comment_ctime":1605511668,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"请问：1、如果现实中不能等到正常交易和异常交易样本的数据都收集完后，才进行模型训练。比如目前只收集了正常样本的数据。是否可以利用正常数据的进行学习，得到正常样本的模型。然后每次交易都和这个模型进行比较。比如利用，高斯混合模型求出正常交易的样本分布情况，每次交易都和正常模型分布进行比较，这种模型训练的方式是否可行？2、文中提到用linearsvm进行模型训练，是否可以用oneclasssvm进行模型训练，oneclasssvm是否适用该数据不均衡的分类问题？","like_count":0},{"had_liked":false,"id":209065,"user_name":"JustDoDT","can_delete":false,"product_type":"c1","uid":1127175,"ip_address":"","ucode":"6AF0B80F00EAEF","user_header":"https://static001.geekbang.org/account/avatar/00/11/33/07/8f351609.jpg","comment_is_top":false,"comment_ctime":1587484369,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"交作业：\nhttps:&#47;&#47;github.com&#47;LearningChanging&#47;Data-analysis-in-action&#47;tree&#47;master&#47;40-%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AE%9E%E6%88%98%EF%BC%882%EF%BC%89%EF%BC%9A%E4%BF%A1%E7%94%A8%E5%8D%A1%E8%AF%88%E9%AA%97%E5%88%86%E6%9E%90","like_count":0},{"had_liked":false,"id":169597,"user_name":"李翔","can_delete":false,"product_type":"c1","uid":1785495,"ip_address":"","ucode":"98E933B109922E","user_header":"https://static001.geekbang.org/account/avatar/00/1b/3e/97/b5da2693.jpg","comment_is_top":false,"comment_ctime":1578385783,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"特征选择中为什么要drop掉amount这个特征呀？上一步amount不是刚标准化嘛？","like_count":0},{"had_liked":false,"id":101076,"user_name":"挠头侠","can_delete":false,"product_type":"c1","uid":1150474,"ip_address":"","ucode":"F96966832E2252","user_header":"https://static001.geekbang.org/account/avatar/00/11/8e/0a/31ec5392.jpg","comment_is_top":false,"comment_ctime":1559710333,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"老师 为什么只依靠查准率无法判断模型的好坏呢？我试过很多情况，让我感觉是基本上都可以通过查准率判断模型好坏","like_count":0,"discussions":[{"author":{"id":2344228,"avatar":"https://static001.geekbang.org/account/avatar/00/23/c5/24/182c710f.jpg","nickname":"lin","note":"","ucode":"356B5A4152B02D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":350693,"discussion_content":"置信分score_y 实际上是实例出现在每个类中的置信分数，因此，每个实例的分类结果实际上取决于此置信分数以及一个称为阈值的值，所有score_y大于阈值的实例都归为一类，较小的归为另一类，因此改变阈值可以得到不同的预测结果\nprecision_recall_curve这个函数的目的是通过模拟不同threshold（阈值）下，precision和recall的变动曲线，在其他分类器中，该函数可用于寻找提高分类效果的最佳阈值。","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1613981397,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":76579,"user_name":"一语中的","can_delete":false,"product_type":"c1","uid":1320112,"ip_address":"","ucode":"E1A0EFCEAD83B4","user_header":"https://static001.geekbang.org/account/avatar/00/14/24/b0/a6e0b03a.jpg","comment_is_top":false,"comment_ctime":1552634887,"is_pvip":false,"replies":[{"id":64418,"content":"很好的分享，不过彩票这个很难预测","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577618908,"ip_address":"","comment_id":76579,"utype":1}],"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"不平衡数据：\n1.欺诈预测（欺诈的数量远远小于真实交易的数量）\n比如，本节内容的信用卡欺诈交易\n2.自然灾害预测（不好的事情远远小于好的事情）\n3.买彩票中奖（小概率）\n4.在图像分类中识别恶性肿瘤（训练样本中含有肿瘤的图像远比没有肿瘤的图像少）","like_count":0},{"had_liked":false,"id":76563,"user_name":"Geek_hve78z","can_delete":false,"product_type":"c1","uid":1015045,"ip_address":"","ucode":"386803B8FC2DD5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg","comment_is_top":false,"comment_ctime":1552633015,"is_pvip":false,"replies":[{"id":64420,"content":"总结的不错","user_name":"作者回复","user_name_real":"cy","uid":1306094,"ctime":1577618928,"ip_address":"","comment_id":76563,"utype":1}],"discussion_count":1,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"不均衡数据集是指，数据集中每个类别下的样本数目相差很大。\n比如，在客户流失的数据集中，绝大部分的客户是会继续享受其服务的（非流失对象），只有极少数部分的客户不会再继续享受其服务（流失对象）\n又如，检查出厂冰箱的合格率，本来合格率就高达了96%。如果对样本进行检测，准确率也是很高的，那么将会无法判断次品。\n再如，检查邮件中的垃圾邮件，因为垃圾邮件占全部邮件极少的部分，所以也是属于不平衡数据集\n","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":443356,"discussion_content":"总结的不错","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577618928,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":188944,"user_name":"换个调调","can_delete":false,"product_type":"c1","uid":1674204,"ip_address":"","ucode":"F781C8EBB6D529","user_header":"https://static001.geekbang.org/account/avatar/00/19/8b/dc/925e0f8a.jpg","comment_is_top":false,"comment_ctime":1584437222,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"1.置信分数是一个什么概念呢？\n2.为什么计算PR值取 score_y 而不是 pred_y?\n3.像SVC、LogisticRegression没有 feature_importances 如何判断各个特征的重要性呢？","like_count":2,"discussions":[{"author":{"id":2344228,"avatar":"https://static001.geekbang.org/account/avatar/00/23/c5/24/182c710f.jpg","nickname":"lin","note":"","ucode":"356B5A4152B02D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":350693,"discussion_content":"置信分score_y 实际上是实例出现在每个类中的置信分数，因此，每个实例的分类结果实际上取决于此置信分数以及一个称为阈值的值，所有score_y大于阈值的实例都归为一类，较小的归为另一类，因此改变阈值可以得到不同的预测结果\nprecision_recall_curve这个函数的目的是通过模拟不同threshold（阈值）下，precision和recall的变动曲线，在其他分类器中，该函数可用于寻找提高分类效果的最佳阈值。","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1613981397,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":355487,"user_name":"feng","can_delete":false,"product_type":"c1","uid":1126994,"ip_address":"湖南","ucode":"A9C47271F1E710","user_header":"https://static001.geekbang.org/account/avatar/00/11/32/52/c843fc53.jpg","comment_is_top":false,"comment_ctime":1661422037,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"逻辑回归模型的求解这里不做介绍，我们来看下如何使用 sklearn 中的逻辑回归工具。在 sklearn 中，我们使用 LogisticRegression() 函数构建逻辑回归分类器，函数里有一些常用的构造参数：penalty：惩罚项，取值为 l1 或 l2，默认为 l2。当模型参数满足高斯分布的时候，使用 l2，当模型参数满足拉普拉斯分布的时候，使用 l1；\n请问老师这个模型的参数是满足高斯分布还是拉普拉斯分布，为什么？","like_count":1},{"had_liked":false,"id":334231,"user_name":"杨博","can_delete":false,"product_type":"c1","uid":1194024,"ip_address":"","ucode":"6949F3A2DD529F","user_header":"","comment_is_top":false,"comment_ctime":1644823764,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"问题一：本文中PCA如何判断降维到28是较适合？维度不同对结果的影响很大。\n问题二：在其他的场景进行回归预测，1954条数据，20个特征变量，但是在sklearn中的几个典型的回归模型中R2分值差别很大，集成类的模型打分0.93+，有的0.7+，有的0.8+，请教是数据存在一定问题？还是模型不合适的问题？","like_count":1},{"had_liked":false,"id":265026,"user_name":"非同凡想","can_delete":false,"product_type":"c1","uid":1934969,"ip_address":"","ucode":"713FD449A49D5A","user_header":"https://static001.geekbang.org/account/avatar/00/1d/86/79/066a062a.jpg","comment_is_top":false,"comment_ctime":1606738450,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"reg = LinearSVC()\nreg.fit(train_x, train_y)\npred_y = reg.predict(test_x)\ncm = confusion_matrix(test_y, pred_y)\nclass_names = [0,1]\nplot_confusion_matrix(cm, classes=class_names, title=&#39;混淆矩阵&#39; )\nshow_metrics(cm)\n\nprecision:0.830\nrecall:0.650\nf1:0.729","like_count":0},{"had_liked":false,"id":261748,"user_name":"Geek_00acb1","can_delete":false,"product_type":"c1","uid":2204908,"ip_address":"","ucode":"B00B73D265C6D0","user_header":"","comment_is_top":false,"comment_ctime":1605511668,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"请问：1、如果现实中不能等到正常交易和异常交易样本的数据都收集完后，才进行模型训练。比如目前只收集了正常样本的数据。是否可以利用正常数据的进行学习，得到正常样本的模型。然后每次交易都和这个模型进行比较。比如利用，高斯混合模型求出正常交易的样本分布情况，每次交易都和正常模型分布进行比较，这种模型训练的方式是否可行？2、文中提到用linearsvm进行模型训练，是否可以用oneclasssvm进行模型训练，oneclasssvm是否适用该数据不均衡的分类问题？","like_count":0},{"had_liked":false,"id":209065,"user_name":"JustDoDT","can_delete":false,"product_type":"c1","uid":1127175,"ip_address":"","ucode":"6AF0B80F00EAEF","user_header":"https://static001.geekbang.org/account/avatar/00/11/33/07/8f351609.jpg","comment_is_top":false,"comment_ctime":1587484369,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"交作业：\nhttps:&#47;&#47;github.com&#47;LearningChanging&#47;Data-analysis-in-action&#47;tree&#47;master&#47;40-%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AE%9E%E6%88%98%EF%BC%882%EF%BC%89%EF%BC%9A%E4%BF%A1%E7%94%A8%E5%8D%A1%E8%AF%88%E9%AA%97%E5%88%86%E6%9E%90","like_count":0},{"had_liked":false,"id":169597,"user_name":"李翔","can_delete":false,"product_type":"c1","uid":1785495,"ip_address":"","ucode":"98E933B109922E","user_header":"https://static001.geekbang.org/account/avatar/00/1b/3e/97/b5da2693.jpg","comment_is_top":false,"comment_ctime":1578385783,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"特征选择中为什么要drop掉amount这个特征呀？上一步amount不是刚标准化嘛？","like_count":0},{"had_liked":false,"id":101076,"user_name":"挠头侠","can_delete":false,"product_type":"c1","uid":1150474,"ip_address":"","ucode":"F96966832E2252","user_header":"https://static001.geekbang.org/account/avatar/00/11/8e/0a/31ec5392.jpg","comment_is_top":false,"comment_ctime":1559710333,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100021701,"comment_content":"老师 为什么只依靠查准率无法判断模型的好坏呢？我试过很多情况，让我感觉是基本上都可以通过查准率判断模型好坏","like_count":0},{"had_liked":false,"id":99965,"user_name":"挠头侠","can_delete":false,"product_type":"c1","uid":1150474,"ip_address":"","ucode":"F96966832E2252","user_header":"https://static001.geekbang.org/account/avatar/00/11/8e/0a/31ec5392.jpg","comment_is_top":false,"comment_ctime":1559373526,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":5,"product_id":100021701,"comment_content":"老师 X = np.array(data.as_matrix()) ，将dataframe转化成ndarray格式不是必须步骤吧，转化之后是有什么性能上的提升吗？","like_count":0},{"had_liked":false,"id":85138,"user_name":"华","can_delete":false,"product_type":"c1","uid":1485516,"ip_address":"","ucode":"668B88249A7AEB","user_header":"https://static001.geekbang.org/account/avatar/00/16/aa/cc/8f1b6214.jpg","comment_is_top":false,"comment_ctime":1554987782,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100021701,"comment_content":"老师FN应该是28414吧？","like_count":0},{"had_liked":false,"id":79346,"user_name":"Lee","can_delete":false,"product_type":"c1","uid":1313515,"ip_address":"","ucode":"ED3D7200A948C3","user_header":"https://static001.geekbang.org/account/avatar/00/14/0a/eb/6d6a94d2.jpg","comment_is_top":false,"comment_ctime":1553440594,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100021701,"comment_content":"好神奇，我之前也做过这个kaggle项目，这个是样本不平衡数据集，我当时没做处理的时候误判率好高，后来才有SMOTE处理之后才好点，但是看老师这个也没做处理，和我之前的差距好大，还要继续琢磨比对看看我之前错在哪了，当然也希望陈老师能指点一下","like_count":0},{"had_liked":false,"id":76637,"user_name":"白夜","can_delete":false,"product_type":"c1","uid":1354449,"ip_address":"","ucode":"7AABFA7C04EA34","user_header":"https://static001.geekbang.org/account/avatar/00/14/aa/d1/076482f3.jpg","comment_is_top":false,"comment_ctime":1552652510,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":5,"product_id":100021701,"comment_content":"好奇问一下，老师你制作分析图的这个软件是什么？","like_count":0,"discussions":[{"author":{"id":1474214,"avatar":"https://static001.geekbang.org/account/avatar/00/16/7e/a6/4e331ef4.jpg","nickname":"骑行的掌柜J","note":"","ucode":"3163102651C653","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":15168,"discussion_content":"难道不是python的那两个库吗？seaborn跟matplotlib","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1568808985,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":76560,"user_name":"Geek_hve78z","can_delete":false,"product_type":"c1","uid":1015045,"ip_address":"","ucode":"386803B8FC2DD5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg","comment_is_top":false,"comment_ctime":1552632551,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100021701,"comment_content":"不均衡数据集是指，数据集中每个类别下的样本数目相差很大。\n比如，在客户流失的数据集中，绝大部分的客户是会继续享受其服务的（非流失对象），只有极少数部分的客户不会再继续享受其服务（流失对象）\n又如，检查出厂冰箱的合格率，本来合格率就高达了96%。如果对样本进行检测，准确率也是很高的，那么将会无法判断次品。","like_count":0,"discussions":[{"author":{"id":1474214,"avatar":"https://static001.geekbang.org/account/avatar/00/16/7e/a6/4e331ef4.jpg","nickname":"骑行的掌柜J","note":"","ucode":"3163102651C653","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":15168,"discussion_content":"难道不是python的那两个库吗？seaborn跟matplotlib","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1568808985,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":99965,"user_name":"挠头侠","can_delete":false,"product_type":"c1","uid":1150474,"ip_address":"","ucode":"F96966832E2252","user_header":"https://static001.geekbang.org/account/avatar/00/11/8e/0a/31ec5392.jpg","comment_is_top":false,"comment_ctime":1559373526,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":5,"product_id":100021701,"comment_content":"老师 X = np.array(data.as_matrix()) ，将dataframe转化成ndarray格式不是必须步骤吧，转化之后是有什么性能上的提升吗？","like_count":0,"discussions":[{"author":{"id":1127175,"avatar":"https://static001.geekbang.org/account/avatar/00/11/33/07/8f351609.jpg","nickname":"JustDoDT","note":"","ucode":"6AF0B80F00EAEF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":242862,"discussion_content":"Python3可以不必装换，直接用。看我代码\nhttps://github.com/LearningChanging/Data-analysis-in-action/tree/master/40-%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AE%9E%E6%88%98%EF%BC%882%EF%BC%89%EF%BC%9A%E4%BF%A1%E7%94%A8%E5%8D%A1%E8%AF%88%E9%AA%97%E5%88%86%E6%9E%90","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587486249,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":85138,"user_name":"华","can_delete":false,"product_type":"c1","uid":1485516,"ip_address":"","ucode":"668B88249A7AEB","user_header":"https://static001.geekbang.org/account/avatar/00/16/aa/cc/8f1b6214.jpg","comment_is_top":false,"comment_ctime":1554987782,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100021701,"comment_content":"老师FN应该是28414吧？","like_count":0},{"had_liked":false,"id":79346,"user_name":"Lee","can_delete":false,"product_type":"c1","uid":1313515,"ip_address":"","ucode":"ED3D7200A948C3","user_header":"https://static001.geekbang.org/account/avatar/00/14/0a/eb/6d6a94d2.jpg","comment_is_top":false,"comment_ctime":1553440594,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100021701,"comment_content":"好神奇，我之前也做过这个kaggle项目，这个是样本不平衡数据集，我当时没做处理的时候误判率好高，后来才有SMOTE处理之后才好点，但是看老师这个也没做处理，和我之前的差距好大，还要继续琢磨比对看看我之前错在哪了，当然也希望陈老师能指点一下","like_count":0},{"had_liked":false,"id":76637,"user_name":"白夜","can_delete":false,"product_type":"c1","uid":1354449,"ip_address":"","ucode":"7AABFA7C04EA34","user_header":"https://static001.geekbang.org/account/avatar/00/14/aa/d1/076482f3.jpg","comment_is_top":false,"comment_ctime":1552652510,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":5,"product_id":100021701,"comment_content":"好奇问一下，老师你制作分析图的这个软件是什么？","like_count":0,"discussions":[{"author":{"id":1127175,"avatar":"https://static001.geekbang.org/account/avatar/00/11/33/07/8f351609.jpg","nickname":"JustDoDT","note":"","ucode":"6AF0B80F00EAEF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":242862,"discussion_content":"Python3可以不必装换，直接用。看我代码\nhttps://github.com/LearningChanging/Data-analysis-in-action/tree/master/40-%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AE%9E%E6%88%98%EF%BC%882%EF%BC%89%EF%BC%9A%E4%BF%A1%E7%94%A8%E5%8D%A1%E8%AF%88%E9%AA%97%E5%88%86%E6%9E%90","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587486249,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":76560,"user_name":"Geek_hve78z","can_delete":false,"product_type":"c1","uid":1015045,"ip_address":"","ucode":"386803B8FC2DD5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg","comment_is_top":false,"comment_ctime":1552632551,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100021701,"comment_content":"不均衡数据集是指，数据集中每个类别下的样本数目相差很大。\n比如，在客户流失的数据集中，绝大部分的客户是会继续享受其服务的（非流失对象），只有极少数部分的客户不会再继续享受其服务（流失对象）\n又如，检查出厂冰箱的合格率，本来合格率就高达了96%。如果对样本进行检测，准确率也是很高的，那么将会无法判断次品。","like_count":0}]}