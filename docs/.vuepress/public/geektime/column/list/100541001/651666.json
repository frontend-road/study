{"id":651666,"title":"21｜DID和PaddleGAN：表情生动的数字人播报员","content":"<p>你好，我是徐文浩。</p><p>上一讲里，我们已经学会了通过AI来进行语音合成。有了语音识别、ChatGPT，再加上这个语音合成，我们就可以做一个能和我们语音聊天的机器人了。不过光有声音还不够，我们还希望这个声音可以是某一个特定的人的声音。就好像在电影《Her》里面那样，AI因为用了影星斯嘉丽·约翰逊的配音，也吸引到不少观众。最后，光有声音还不够，我们还希望能够有视觉上的效果，最好能够模拟自己真的在镜头面前侃侃而谈的样子。</p><p>这些需求结合在一起，就是最近市面上很火的“数字人”，也是我们这一讲要学习的内容。当然，在这么短的时间里，我们做出来的数字人的效果肯定比不上商业公司的方案。不过作为概念演示也完全够用了。</p><h2>制作一个语音聊天机器人</h2><h3>从文本ChatBot起步</h3><p>我们先从最简单的文本ChatBot起步，先来做一个和<a href=\"https://time.geekbang.org/column/article/643915\">第 6 讲</a>一样的文本聊天机器人。对应的代码逻辑和第6讲的ChatGPT应用基本一样，整个的UI界面也还是使用Gradio来创建。</p><p>唯一的区别在于，我们把原先自己封装的Conversation类换成了Langchain的ConversationChain来实现，并且使用了SummaryBufferMemory。这样，我们就不需要强行设定只保留过去几轮对话了。</p><!-- [[[read_end]]] --><pre><code class=\"language-python\">import openai, os\nimport gradio as gr\nfrom langchain import OpenAI\nfrom langchain.chains import ConversationChain\nfrom langchain.memory import ConversationSummaryBufferMemory\nfrom langchain.chat_models import ChatOpenAI\n\nopenai.api_key = os.environ[\"OPENAI_API_KEY\"]\n\nmemory = ConversationSummaryBufferMemory(llm=ChatOpenAI(), max_token_limit=2048)\nconversation = ConversationChain(\n    llm=OpenAI(max_tokens=2048, temperature=0.5), \n    memory=memory,\n)\n\ndef predict(input, history=[]):\n    history.append(input)\n    response = conversation.predict(input=input)\n    history.append(response)\n    responses = [(u,b) for u,b in zip(history[::2], history[1::2])]\n    return responses, history\n\nwith gr.Blocks(css=\"#chatbot{height:800px} .overflow-y-auto{height:800px}\") as demo:\n    chatbot = gr.Chatbot(elem_id=\"chatbot\")\n    state = gr.State([])\n\n    with gr.Row():\n        txt = gr.Textbox(show_label=False, placeholder=\"Enter text and press enter\").style(container=False)\n        \n    txt.submit(predict, [txt, state], [chatbot, state])\n\ndemo.launch()\n</code></pre><p>对应界面：</p><p><img src=\"https://static001.geekbang.org/resource/image/f7/00/f7d911de018acd1959efa040c8658d00.png?wh=1019x877\" alt=\"图片\"></p><h3>增加语音输入功能</h3><p>接着，我们来给这个聊天机器人加上语音输入的功能，Gradio自带Audio模块，所以要做到这一点也不难。</p><ol>\n<li>首先，我们在Gradio的界面代码里面增加一个Audio组件。这个组件可以录制你的麦克风的声音。</li>\n</ol><pre><code class=\"language-python\">    with gr.Row():\n        txt = gr.Textbox(show_label=False, placeholder=\"Enter text and press enter\").style(container=False)\n</code></pre><ol start=\"2\">\n<li>然后，我们封装了一个transcribe方法，通过调用OpenAI的Whisper API就能够完成语音识别。这里有一点需要注意，OpenAI的Whisper API有点笨，它是根据文件名的后缀来判断是否是它支持的文件格式的。而Gradio的Audio组件录制出来的WAV文件没有后缀，所以我们要在这里做个文件重命名的工作。</li>\n</ol><pre><code class=\"language-python\">def transcribe(audio):\n    os.rename(audio, audio + '.wav')\n    audio_file = open(audio + '.wav', \"rb\")\n    transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n    return transcript['text']    \n</code></pre><ol start=\"3\">\n<li>接着，我们就要把麦克风录好的声音自动发送给语音识别，然后再提交给原先基于文本聊天的机器人就好了。</li>\n</ol><pre><code class=\"language-python\">    audio.change(process_audio, [audio, state], [chatbot, state])\n</code></pre><p>我们先在Audio的change事件里，定义了触发process_audio的函数。这样，一旦麦克风的声音录制下来，就会直接触发聊天对话，不需要再单独手工提交一次内容。</p><pre><code class=\"language-python\">def process_audio(audio, history=[]):\n    text = transcribe(audio)\n    return predict(text, history)\n</code></pre><p>然后在process_audio函数里，我们先是转录对应的文本，再调用文本聊天机器人的predict函数，触发对话。</p><p>修改后的完整代码在下面，你可以在本地运行，体验一下。</p><pre><code class=\"language-python\">import openai, os\nimport gradio as gr\nimport azure.cognitiveservices.speech as speechsdk\nfrom langchain import OpenAI\nfrom langchain.chains import ConversationChain\nfrom langchain.memory import ConversationSummaryBufferMemory\nfrom langchain.chat_models import ChatOpenAI\n\nopenai.api_key = os.environ[\"OPENAI_API_KEY\"]\n\nmemory = ConversationSummaryBufferMemory(llm=ChatOpenAI(), max_token_limit=2048)\nconversation = ConversationChain(\n    llm=OpenAI(max_tokens=2048, temperature=0.5), \n    memory=memory,\n)\n\ndef predict(input, history=[]):\n    history.append(input)\n    response = conversation.predict(input=input)\n    history.append(response)\n    responses = [(u,b) for u,b in zip(history[::2], history[1::2])]\n    return responses, history\n\ndef transcribe(audio):\n    os.rename(audio, audio + '.wav')\n    audio_file = open(audio + '.wav', \"rb\")\n    transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n    return transcript['text']    \n\ndef process_audio(audio, history=[]):\n    text = transcribe(audio)\n    return predict(text, history)\n\nwith gr.Blocks(css=\"#chatbot{height:350px} .overflow-y-auto{height:500px}\") as demo:\n    chatbot = gr.Chatbot(elem_id=\"chatbot\")\n    state = gr.State([])\n\n    with gr.Row():\n        txt = gr.Textbox(show_label=False, placeholder=\"Enter text and press enter\").style(container=False)\n        \n    with gr.Row():\n        audio = gr.Audio(source=\"microphone\", type=\"filepath\")\n        \n    txt.submit(predict, [txt, state], [chatbot, state])\n    audio.change(process_audio, [audio, state], [chatbot, state])\n\ndemo.launch()\n</code></pre><p>对应界面：</p><p><img src=\"https://static001.geekbang.org/resource/image/95/73/954c7e642beca777016922f180444873.png?wh=1022x992\" alt=\"图片\" title=\"想要录新的一句话，点击红色方框内的X，重新进入录音界面\"></p><h3>增加语音回复功能</h3><p>在能够接收语音输入之后，我们要做的就是让AI也能够用语音来回答我们的问题。而这个功能，通过<a href=\"https://time.geekbang.org/column/article/650449\">上一讲</a>我们介绍过的Azure的语音合成功能就能实现。我们只需要封装一个函数，来实现语音合成与播放的功能，然后在predict函数里面，拿到ChatGPT返回的回答之后调用一下这个函数就好了。</p><ol>\n<li>封装一个函数进行语音合成与播放。</li>\n</ol><pre><code class=\"language-python\">\nspeech_config = speechsdk.SpeechConfig(subscription=os.environ.get('AZURE_SPEECH_KEY'), region=os.environ.get('AZURE_SPEECH_REGION'))\naudio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n\n# The language of the voice that speaks.\nspeech_config.speech_synthesis_language='zh-CN'\nspeech_config.speech_synthesis_voice_name='zh-CN-XiaohanNeural'\n\nspeech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n\ndef play_voice(text):\n    speech_synthesizer.speak_text_async(text)\n\n</code></pre><ol start=\"2\">\n<li>在拿到ChatGPT的返回结果之后调用一下这个函数。</li>\n</ol><pre><code class=\"language-python\">def predict(input, history=[]):\n    history.append(input)\n    response = conversation.predict(input=input)\n    history.append(response)\n    play_voice(response)\n    responses = [(u,b) for u,b in zip(history[::2], history[1::2])]\n    return responses, history\n</code></pre><p>完整的语音对话的Demo代码我一并放在了下面，你可以像<a href=\"https://time.geekbang.org/column/article/643915\">第 6 讲</a>里我们介绍过的那样，直接部署到Gradio里面体验一下分享出去。</p><pre><code class=\"language-python\">import openai, os\nimport gradio as gr\nimport azure.cognitiveservices.speech as speechsdk\nfrom langchain import OpenAI\nfrom langchain.chains import ConversationChain\nfrom langchain.memory import ConversationSummaryBufferMemory\nfrom langchain.chat_models import ChatOpenAI\n\nopenai.api_key = os.environ[\"OPENAI_API_KEY\"]\n\nmemory = ConversationSummaryBufferMemory(llm=ChatOpenAI(), max_token_limit=2048)\nconversation = ConversationChain(\n    llm=OpenAI(max_tokens=2048, temperature=0.5), \n    memory=memory,\n)\n\nspeech_config = speechsdk.SpeechConfig(subscription=os.environ.get('AZURE_SPEECH_KEY'), region=os.environ.get('AZURE_SPEECH_REGION'))\naudio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n\n# The language of the voice that speaks.\nspeech_config.speech_synthesis_language='zh-CN'\nspeech_config.speech_synthesis_voice_name='zh-CN-XiaohanNeural'\n\nspeech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n\ndef play_voice(text):\n    speech_synthesizer.speak_text_async(text)\n\ndef predict(input, history=[]):\n    history.append(input)\n    response = conversation.predict(input=input)\n    history.append(response)\n    play_voice(response)\n    responses = [(u,b) for u,b in zip(history[::2], history[1::2])]\n    return responses, history\n\ndef transcribe(audio):\n    os.rename(audio, audio + '.wav')\n    audio_file = open(audio + '.wav', \"rb\")\n    transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n    return transcript['text']    \n\ndef process_audio(audio, history=[]):\n    text = transcribe(audio)\n    return predict(text, history)\n\nwith gr.Blocks(css=\"#chatbot{height:800px} .overflow-y-auto{height:800px}\") as demo:\n    chatbot = gr.Chatbot(elem_id=\"chatbot\")\n    state = gr.State([])\n\n    with gr.Row():\n        txt = gr.Textbox(show_label=False, placeholder=\"Enter text and press enter\").style(container=False)\n        \n    with gr.Row():\n        audio = gr.Audio(source=\"microphone\", type=\"filepath\")\n        \n    txt.submit(predict, [txt, state], [chatbot, state])\n    audio.change(process_audio, [audio, state], [chatbot, state])\n\ndemo.launch()\n</code></pre><h2>用D-ID给语音对口型</h2><p>这里我们设计的聊天机器人不仅能够完全听懂我们说的话，还能通过语音来对话，这的确是一件很酷的事情。而且这里我们算上空行，也只用了60行代码。不过，我们并不会止步于此。接下来，我们还要为这个聊天机器人配上视频画面和口型。</p><p>现在，国内外已经有一些公司开始提供基于AI生成能对上口型的“数字人”的业务了。这里，我们就来试试目前用户比较多的 <a href=\"https://www.d-id.com/\">D-ID</a> 提供的API，毕竟它直接为所有开发者提供了开放平台，并且还有5分钟的免费额度。</p><h3>通过D-ID生成视频</h3><p>首先，你要去d-id.com注册一个账号。别紧张，d-id.com 有邮箱就能注册账号，不像ChatGPT那么麻烦，并且D-ID送给注册用户20次调用API的机会，我们可以好好利用这些免费额度。</p><p>注册好账号以后，你就可以去访问自己的 <a href=\"https://studio.d-id.com/account-settings\">Account Setting</a> 页面生成一个API_KEY了。</p><p><img src=\"https://static001.geekbang.org/resource/image/40/3a/40219e8ff1ea0fcea51263163b7ded3a.png?wh=1017x541\" alt=\"图片\"></p><p>之后，你可以查看一下D-ID的文档，里面不仅有API的使用说明，还有一个类似Playground的界面，你可以设置参数，并且可以测试调用API。</p><p><img src=\"https://static001.geekbang.org/resource/image/7b/6c/7b5afe6c026e6cffd62824247985ef6c.png?wh=1235x1069\" alt=\"图片\"></p><p>我们设置一下对应的API KEY并且确保安装了requests这个专门用来写HTTP请求的Python包，就可以测试一下这个代码的效果了。</p><p>安装requests包：</p><pre><code class=\"language-python\">pip install requests\n</code></pre><p>设置DID_API_KEY的环境变量：</p><pre><code class=\"language-python\">export DID_API_KEY=YOUR_DID_API_KEY\n</code></pre><p>我们可以先调用D-ID的<strong>Create A Talk</strong>接口，来创建一段小视频。只需要输入两个东西：一个是我们希望这个视频念出来的文本信息input，另一个就是一个清晰的正面头像照片。</p><p>在下面的代码里面可以看到，这其实就是一个简单的HTTP请求，并且文本转换成语音的过程，其实调用的也是Azure的语音合成功能。</p><pre><code class=\"language-python\">import requests\nimport os\n\ndef generate_talk(input, avatar_url, \n                  voice_type = \"microsoft\", \n                  voice_id = \"zh-CN-XiaomoNeural\", \n                  api_key = os.environ.get('DID_API_KEY')):\n    url = \"https://api.d-id.com/talks\"\n    payload = {\n        \"script\": {\n            \"type\": \"text\",\n            \"provider\": {\n                \"type\": voice_type,\n                \"voice_id\": voice_id\n            },\n            \"ssml\": \"false\",\n            \"input\": input\n        },\n        \"config\": {\n            \"fluent\": \"false\",\n            \"pad_audio\": \"0.0\"\n        },\n        \"source_url\": avatar_url\n    }\n    headers = {\n        \"accept\": \"application/json\",\n        \"content-type\": \"application/json\",\n        \"authorization\": \"Basic \" + api_key\n    }\n\n    response = requests.post(url, json=payload, headers=headers)\n    return response.json()\n\navatar_url = \"https://cdn.discordapp.com/attachments/1065596492796153856/1095617463112187984/John_Carmack_Potrait_668a7a8d-1bb0-427d-8655-d32517f6583d.png\"\ntext = \"今天天气真不错呀。\"\n\nresponse = generate_talk(input=text, avatar_url=avatar_url)\nprint(response)\n</code></pre><p>输出结果：</p><pre><code class=\"language-python\">{'id': 'tlk_Nk9OfTGu_ZvLztD3HHC4b', 'created_at': '2023-04-12T03:07:38.593Z', 'created_by': 'google-oauth2|103752135956955592319', 'status': 'created', 'object': 'talk'}\n</code></pre><p>这段代码运行成功之后，返回的结果是一个JSON。JSON里面有一个对应视频的id，我们可以通过这个id用Get A Talk的API拿到我们刚刚生成的口播视频，然后在Notebook里面播放。</p><p>获取生成的Talk视频：</p><pre><code class=\"language-python\">def get_a_talk(id, api_key = os.environ.get('DID_API_KEY')):\n    url = \"https://api.d-id.com/talks/\" + id\n    headers = {\n        \"accept\": \"application/json\",\n        \"authorization\": \"Basic \"+api_key\n    }\n    response = requests.get(url, headers=headers)\n    return response.json()\n\ntalk = get_a_talk(response['id'])\nprint(talk)\n</code></pre><p>输出结果：</p><pre><code class=\"language-python\">{'metadata': {'driver_url': 'bank://lively/driver-03/original', 'mouth_open': False, 'num_faces': 1, 'num_frames': 48, 'processing_fps': 22.996171137505605, 'resolution': [512, 512], 'size_kib': 386.990234375}, 'audio_url': 'https://d-id-talks-prod.s3.us-west-2.amazonaws.com/google-oauth2%7C103752135956955592319/tlk_Nk9OfTGu_ZvLztD3HHC4b/microsoft.wav?AWSAccessKeyId=AKIA5CUMPJBIK65W6FGA&amp;Expires=1681355260&amp;Signature=2RluUIQyg%2FnIz54O2xEIr%2FqjaXA%3D', 'created_at': '2023-04-12T03:07:38.593Z', 'face': {'mask_confidence': -1, 'detection': [205, 115, 504, 552], 'overlap': 'no', 'size': 618, 'top_left': [45, 25], 'face_id': 0, 'detect_confidence': 0.9987131357192993}, 'config': {'stitch': False, 'pad_audio': 0, 'align_driver': True, 'sharpen': True, 'auto_match': True, 'normalization_factor': 1, 'logo': {'url': 'd-id-logo', 'position': [0, 0]}, 'motion_factor': 1, 'result_format': '.mp4', 'fluent': False, 'align_expand_factor': 0.3}, 'source_url': 'https://d-id-talks-prod.s3.us-west-2.amazonaws.com/google-oauth2%7C103752135956955592319/tlk_Nk9OfTGu_ZvLztD3HHC4b/source/noelle.jpeg?AWSAccessKeyId=AKIA5CUMPJBIK65W6FGA&amp;Expires=1681355260&amp;Signature=LNSFBaEUWtPYUo469qzmUGeHzec%3D', 'created_by': 'google-oauth2|103752135956955592319', 'status': 'done', 'driver_url': 'bank://lively/', 'modified_at': '2023-04-12T03:07:42.570Z', 'user_id': 'google-oauth2|103752135956955592319', 'result_url': 'https://d-id-talks-prod.s3.us-west-2.amazonaws.com/google-oauth2%7C103752135956955592319/tlk_Nk9OfTGu_ZvLztD3HHC4b/noelle.mp4?AWSAccessKeyId=AKIA5CUMPJBIK65W6FGA&amp;Expires=1681355262&amp;Signature=slWpvS1eEqcw4N%2FqVWN6K0zewuU%3D', 'id': 'tlk_Nk9OfTGu_ZvLztD3HHC4b', 'duration': 2, 'started_at': '2023-04-12T03:07:40.402'}\n</code></pre><p>将对应的视频展示播放出来：</p><pre><code class=\"language-python\">from IPython.display import display, HTML\ndef play_mp4_video(url):\n    video_tag = f\"\"\"\n    &lt;video width=\"640\" height=\"480\" controls&gt;\n        &lt;source src=\"{url}\" type=\"video/mp4\"&gt;\n    Your browser does not support the video tag.\n    &lt;/video&gt;\n    \"\"\"\n    return HTML(video_tag)\nresult_url = talk['result_url'])\nplay_mp4_video(result_url)\n</code></pre><p>输出展示：</p><p><img src=\"https://static001.geekbang.org/resource/image/75/7b/754e0357c3dd475b3b7f42c7c9beff7b.png?wh=346x259\" alt=\"图片\"></p><p>在这里，我用Midjourney生成了一张ID Software的创始人——大神约翰卡马克的头像。然后让D-ID给这个头像生成对应的对口型的视频，看到心目中的技术偶像开口说话还是非常让人震撼的。</p><h3>将视频嵌入到Gradio应用中</h3><p>有了这样可以对口型播放的视频，我们就可以再改造一下刚才通过Gradio创建的应用，不要光让机器人用语音了，直接用视频来开口说话吧。</p><p>我们在前面语音聊天界面的基础上，又做了几处改造。</p><ol>\n<li>我们在原有的Gradio界面中，又增加了一个HTML组件，显示头像图片，并用来播放对好口型的视频。默认一开始，显示的是一张图片。</li>\n</ol><pre><code class=\"language-python\">……\n    with gr.Row():\n        video = gr.HTML(f'&lt;img src=\"{avatar_url}\" width=\"320\" height=\"240\" alt=\"John Carmack\"&gt;', live=False)\n</code></pre><p><span class=\"reference\">注：这里增加了一个用来播放视频的HTML组件。</span></p><ol start=\"2\">\n<li>在录音转录后触发Predict函数的时候，我们不再通过Azure的语音合成技术来生成语音，而是直接使用 D-ID 的API来生成基于头像的且口型同步的视频动画。并且视频动画在生成之后，将前面HTML组件的内容替换成新生成的视频，并自动播放。</li>\n</ol><pre><code class=\"language-python\">def predict(input, history=[]):\n    if input is not None:\n        history.append(input)\n        response = conversation.predict(input=input)    \n        video_url = get_mp4_video(input=response, avatar_url=avatar_url)\n        video_html = f\"\"\"&lt;video width=\"320\" height=\"240\" controls autoplay&gt;&lt;source src=\"{video_url}\" type=\"video/mp4\"&gt;&lt;/video&gt;\"\"\"\n        history.append(response)\n        responses = [(u,b) for u,b in zip(history[::2], history[1::2])]\n        return responses, video_html, history\n    else:\n        video_html = f'&lt;img src=\"{avatar_url}\" width=\"320\" height=\"240\" alt=\"John Carmack\"&gt;'\n        responses = [(u,b) for u,b in zip(history[::2], history[1::2])]\n        return responses, video_html, history        \n</code></pre><p><span class=\"reference\">注：通过ChatGPT获取回答，然后将回答和头像一起生成一个视频文件自动播放。</span></p><ol start=\"3\">\n<li>在获取视频的时候需要注意一点，就是我们需要等待视频在D-ID的服务器生成完毕，才能拿到对应的result_url。其实更合理的做法是注册一个webhook，等待d-id通过webhook通知我们视频生成完毕了，再播放视频。不过考虑到演示的简便和代码数量，我们就没有再启用一个HTTP服务来接收webhook，而是采用sleep 1秒然后重试的方式，来实现获取视频的效果。</li>\n</ol><pre><code class=\"language-python\">def get_mp4_video(input, avatar_url=avatar_url):\n    response = generate_talk(input=input, avatar_url=avatar_url)\n    talk = get_a_talk(response['id'])\n    video_url = \"\"\n    index = 0\n    while index &lt; 30:\n        index += 1\n        if 'result_url' in talk:    \n            video_url = talk['result_url']\n            return video_url\n        else:\n            time.sleep(1)\n            talk = get_a_talk(response['id'])\n    return video_url\n</code></pre><p><span class=\"reference\">注：result_url字段会在服务器端把整个视频生成完成之后才出现，所以我们需要循环等待。</span></p><p>改造完整体代码如下：</p><pre><code class=\"language-python\">import openai, os, time, requests\nimport gradio as gr\nfrom gradio import HTML\nfrom langchain import OpenAI\nfrom langchain.chains import ConversationChain\nfrom langchain.memory import ConversationSummaryBufferMemory\nfrom langchain.chat_models import ChatOpenAI\n\nopenai.api_key = os.environ[\"OPENAI_API_KEY\"]\n\nmemory = ConversationSummaryBufferMemory(llm=ChatOpenAI(), max_token_limit=2048)\nconversation = ConversationChain(\n&nbsp; &nbsp; llm=OpenAI(max_tokens=2048, temperature=0.5),&nbsp;\n&nbsp; &nbsp; memory=memory,\n)\n\navatar_url = \"https://cdn.discordapp.com/attachments/1065596492796153856/1095617463112187984/John_Carmack_Potrait_668a7a8d-1bb0-427d-8655-d32517f6583d.png\"\n\ndef generate_talk(input, avatar_url,&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; voice_type = \"microsoft\",&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; voice_id = \"zh-CN-YunyeNeural\",&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; api_key = os.environ.get('DID_API_KEY')):\n&nbsp; &nbsp; url = \"https://api.d-id.com/talks\"\n&nbsp; &nbsp; payload = {\n&nbsp; &nbsp; &nbsp; &nbsp; \"script\": {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"type\": \"text\",\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"provider\": {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"type\": voice_type,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"voice_id\": voice_id\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; },\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"ssml\": \"false\",\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"input\": input\n&nbsp; &nbsp; &nbsp; &nbsp; },\n&nbsp; &nbsp; &nbsp; &nbsp; \"config\": {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"fluent\": \"false\",\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"pad_audio\": \"0.0\"\n&nbsp; &nbsp; &nbsp; &nbsp; },\n&nbsp; &nbsp; &nbsp; &nbsp; \"source_url\": avatar_url\n&nbsp; &nbsp; }\n&nbsp; &nbsp; headers = {\n&nbsp; &nbsp; &nbsp; &nbsp; \"accept\": \"application/json\",\n&nbsp; &nbsp; &nbsp; &nbsp; \"content-type\": \"application/json\",\n&nbsp; &nbsp; &nbsp; &nbsp; \"authorization\": \"Basic \" + api_key\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; response = requests.post(url, json=payload, headers=headers)\n&nbsp; &nbsp; return response.json()\n\n\n\ndef get_a_talk(id, api_key = os.environ.get('DID_API_KEY')):\n&nbsp; &nbsp; url = \"https://api.d-id.com/talks/\" + id\n&nbsp; &nbsp; headers = {\n&nbsp; &nbsp; &nbsp; &nbsp; \"accept\": \"application/json\",\n&nbsp; &nbsp; &nbsp; &nbsp; \"authorization\": \"Basic \"+api_key\n&nbsp; &nbsp; }\n&nbsp; &nbsp; response = requests.get(url, headers=headers)\n&nbsp; &nbsp; return response.json()\n\n\n\ndef get_mp4_video(input, avatar_url=avatar_url):\n&nbsp; &nbsp; response = generate_talk(input=input, avatar_url=avatar_url)\n&nbsp; &nbsp; talk = get_a_talk(response['id'])\n&nbsp; &nbsp; video_url = \"\"\n&nbsp; &nbsp; index = 0\n&nbsp; &nbsp; while index &lt; 30:\n&nbsp; &nbsp; &nbsp; &nbsp; index += 1\n&nbsp; &nbsp; &nbsp; &nbsp; if 'result_url' in talk:&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; video_url = talk['result_url']\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; return video_url\n&nbsp; &nbsp; &nbsp; &nbsp; else:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; time.sleep(1)\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; talk = get_a_talk(response['id'])\n&nbsp; &nbsp; return video_url\n\ndef predict(input, history=[]):\n&nbsp; &nbsp; if input is not None:\n&nbsp; &nbsp; &nbsp; &nbsp; history.append(input)\n&nbsp; &nbsp; &nbsp; &nbsp; response = conversation.predict(input=input)&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; video_url = get_mp4_video(input=response, avatar_url=avatar_url)\n&nbsp; &nbsp; &nbsp; &nbsp; video_html = f\"\"\"&lt;video width=\"320\" height=\"240\" controls autoplay&gt;&lt;source src=\"{video_url}\" type=\"video/mp4\"&gt;&lt;/video&gt;\"\"\"\n&nbsp; &nbsp; &nbsp; &nbsp; history.append(response)\n&nbsp; &nbsp; &nbsp; &nbsp; responses = [(u,b) for u,b in zip(history[::2], history[1::2])]\n&nbsp; &nbsp; &nbsp; &nbsp; return responses, video_html, history\n&nbsp; &nbsp; else:\n&nbsp; &nbsp; &nbsp; &nbsp; video_html = f'&lt;img src=\"{avatar_url}\" width=\"320\" height=\"240\" alt=\"John Carmack\"&gt;'\n&nbsp; &nbsp; &nbsp; &nbsp; responses = [(u,b) for u,b in zip(history[::2], history[1::2])]\n&nbsp; &nbsp; &nbsp; &nbsp; return responses, video_html, history&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n\ndef transcribe(audio):\n&nbsp; &nbsp; os.rename(audio, audio + '.wav')\n&nbsp; &nbsp; audio_file = open(audio + '.wav', \"rb\")\n&nbsp; &nbsp; transcript = openai.Audio.transcribe(\"whisper-1\", audio_file, prompt=\"这是一段简体中文的问题。\")\n&nbsp; &nbsp; return transcript['text']&nbsp; &nbsp;&nbsp;\n\ndef process_audio(audio, history=[]):\n&nbsp; &nbsp; if audio is not None:\n&nbsp; &nbsp; &nbsp; &nbsp; text = transcribe(audio)\n&nbsp; &nbsp; &nbsp; &nbsp; return predict(text, history)\n&nbsp; &nbsp; else:\n&nbsp; &nbsp; &nbsp; &nbsp; text = None\n&nbsp; &nbsp; &nbsp; &nbsp; return predict(text, history)\n\nwith gr.Blocks(css=\"#chatbot{height:500px} .overflow-y-auto{height:500px}\") as demo:\n&nbsp; &nbsp; chatbot = gr.Chatbot(elem_id=\"chatbot\")\n&nbsp; &nbsp; state = gr.State([])\n\n&nbsp; &nbsp; with gr.Row():\n&nbsp; &nbsp; &nbsp; &nbsp; txt = gr.Textbox(show_label=False, placeholder=\"Enter text and press enter\").style(container=False)\n&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; with gr.Row():\n&nbsp; &nbsp; &nbsp; &nbsp; audio = gr.Audio(source=\"microphone\", type=\"filepath\")\n\n&nbsp; &nbsp; with gr.Row():\n&nbsp; &nbsp; &nbsp; &nbsp; video = gr.HTML(f'&lt;img src=\"{avatar_url}\" width=\"320\" height=\"240\" alt=\"John Carmack\"&gt;', live=False)\n\n&nbsp; &nbsp; txt.submit(predict, [txt, state], [chatbot, video, state])\n&nbsp; &nbsp; audio.change(process_audio, [audio, state], [chatbot, video, state])\n&nbsp; &nbsp;&nbsp;\ndemo.launch()\n</code></pre><p>输出结果：</p><p><img src=\"https://static001.geekbang.org/resource/image/65/2e/6531d11d7e54114bd4cd43fe8603622e.png?wh=1020x1014\" alt=\"图片\"></p><p>改造完整个应用，你可以试着运行一下。你的问题会由ID大神卡马克“亲口”+“当面”回答，是不是非常酷炫？</p><h2>体验PaddleGAN开源模型下的数字主播</h2><p>不过，使用D-ID的价格也不便宜，而前面的各个模块，我其实都给你看过对应的开源解决方案。比如ChatGPT我们可以用ChatGLM来代替，语音识别我们可以使用本地的Whisper模型，语音合成也可以通过PaddleSpeech里的fastspeech2的开源模型来完成。那么，我们这里也来尝试一下通过开源模型来合成这样的口播视频。</p><p>目前比较容易找到的解决方案，是百度PaddlePaddle下的 <a href=\"https://github.com/JiehangXie/PaddleBoBo\">PaddleBobo</a> 开源项目。它背后使用的是PaddleGAN的对抗生成网络算法，来实现唇形和表情的匹配。不过PaddleGAN很久没有更新了，对于最新的Python3.10的支持和依赖有些问题。我们也只能在这里做一个简单的演示。</p><p>这里的代码你不一定需要运行，因为这个程序对于GPU的显存要求比较高，而且对于Python以及Cuda的版本都有要求。而如果你使用CPU的话，对应的视频合成需要很长时间。你体验一下最后合成的视频效果就好了。</p><p>首先我们需要配置一个Python3.8的环境，并且安装对应的依赖包。</p><pre><code class=\"language-python\">conda create -n py38 python=3.8\nconda activate py38\n\n#pip install paddlepaddle\n#安装使用GPU的PaddlePaddle\npip install paddlepaddle-gpu  \npip install ppgan\npip install isort\npip install typing-extensions\npip install lazy-object-proxy\npip install wrapt\npip install yacs\npip install paddlespeech\npip install \"numpy&lt;1.24.0\"\n\nbrew install ffmpeg\n</code></pre><p>然后，我们将PaddleBobo的代码通过Git下载到本地，并进入对应的目录。</p><pre><code class=\"language-python\">git clone https://github.com/JiehangXie/PaddleBoBo\ncd PaddleBobo\n</code></pre><p>我们将约翰卡马克的头像文件命名成johncarmack.png，复制到PaddleBobo的file/input目录下，然后修改对应的default.yml的配置，让我们的视频都基于约翰卡马克的头像来生成。</p><pre><code class=\"language-python\">GANDRIVING:\n  FOM_INPUT_IMAGE: './file/input/johncarmack.png'\n  FOM_DRIVING_VIDEO: './file/input/zimeng.mp4'\n  FOM_OUTPUT_VIDEO: './file/input/johncarmack.mp4'\n\nTTS:\n  SPEED: 1.0\n  PITCH: 1.0\n  ENERGY: 1.0\n\nSAVEPATH:\n  VIDEO_SAVE_PATH: './file/output/video/'\n  AUDIO_SAVE_PATH: './file/output/audio/'\n</code></pre><p><span class=\"reference\">注：修改GanDriving的相关配置。</span></p><p>接着我们按照PaddleBobo的文档，通过create_virtual_human先生成一个能够动起来的人脸视频。如果你使用的是CPU的话，这个过程会很长，需要一两个小时。</p><pre><code class=\"language-python\">python create_virtual_human.py --config default.yaml\n</code></pre><p>因为PaddleBobo这个项目有一段时间没有维护了，对于最新版本的PaddleSpeech有一些小小的兼容问题，所以你还需要调整一下 PaddleTools 里面的TTS.py文件，修改import MODEL_HOME包的名称。</p><pre><code class=\"language-python\">from paddlespeech.utils.env import MODEL_HOME\n</code></pre><p>然后，我们再通过generate_demo输入我们希望这个视频口播的文字是什么。</p><pre><code class=\"language-python\">python general_demo.py \\\n    --human ./file/input/johncarmack.mp4 \\\n    --output johncarmack_output.mp4 \\\n    --text \"我是约翰卡马克，很高兴认识大家\"\n</code></pre><p>最后生成的视频文件，我也放到我们的<a href=\"https://github.com/xuwenhao/geektime-ai-course/tree/main/data\">代码库的 data 目录</a>里了，你可以下载下来体验一下效果是怎么样的。目前来说，通过GAN生成影像的方式，需要花费的时间还是比较长的，未来的技术发展也可能更偏向于Diffuser类型的算法，因此今天我们更多地是提供一种新的体验，让你感受一下人工智能带来的影像方面的创新。</p><p>这些命令行对应的Python程序其实也很简单，不超过50行代码，你有兴趣的话，可以读一下源代码看看它具体是调用哪些模型来实现的。</p><h2>小结</h2><p>好了，这一节课，到这里就结束了。</p><p>今天我们整合前两讲学习的知识，打造了一个可以通过语音来交互的聊天机器人。进一步地，我们通过D-ID.com这个SaaS，提供了一个能够对上口型、有表情的数字人来回复问题。当然，D-ID.com的价格比较昂贵，尤其是对于API调用的次数和生成视频的数量都有一定的限制。所以我们进一步尝试使用开源的PaddleBobo项目，来根据文本生成带口型的口播视频。而如果我们把语音识别从云换成本地的Whisper模型，把ChatGPT换成之前测试过的开源的ChatGLM，我们就有了一个完全开源的数字人解决方案。</p><p>当然，今天我为你演示的数字人，从效果上来看还很一般。不过，要知道我们并没有使用任何数据对模型进行微调，而是完全使用预训练好的开源模型。我写对应的演示代码也就只用了一两天晚上的时间而已。如果想要进一步优化效果，我们完全可以基于这些开源模型进一步去改造微调。</p><p>今天，大部分开源的深度学习技术已经进入了一个重大的拐点，任何人都可以通过云服务的API和开源模型搭建一个AI产品出来了。希望这一讲能让你拥有充足的知识和足够的创意去做出一个与众不同的产品来。</p><h2>思考题</h2><p>语音相关的AI产品市场上还有很多，但目前很多好的产品还都是闭源收费的。比如 <a href=\"https://beta.elevenlabs.io/speech-synthesis\">elevenlabs</a> 就可以模仿人的语音语调。它也支持中文，而且预设的“老外”语音说出来的中文还真有点儿老外说中文的腔调，你可以试着去体验一下。我们上一讲介绍过的PaddleSpeech，百度官方也给出了对应的<a href=\"https://aistudio.baidu.com/aistudio/projectdetail/4573549?sUid=2470186&shared=1&ts=1663753541400\">小样本合成和小数据微调</a>的示例，你也可以看一下。</p><p>基于这些SaaS或者开源项目，你是否可以尝试一下，把对应的数字人的声音替换成你自己的？欢迎你大胆尝试并且把你的体会分享到留言区，也欢迎你把这一讲的内容分享给感兴趣的朋友，我们下一讲再见。</p><h2>推荐阅读</h2><p>关于数字人，有很多开源方案，比如 <a href=\"https://github.com/zhangchenxu528/FACIAL\">FACIAL</a> 就是由多个院校和三星研究院合作的解决方案。你也可以基于它们提供的代码来训练一个。感兴趣的话，可以去读一读它们的源码和论文。</p>","comments":[{"had_liked":false,"id":373241,"user_name":"勇.Max","can_delete":false,"product_type":"c1","uid":1248128,"ip_address":"澳大利亚","ucode":"AE5DBC10805A9B","user_header":"https://static001.geekbang.org/account/avatar/00/13/0b/80/a0533acb.jpg","comment_is_top":false,"comment_ctime":1682299175,"is_pvip":false,"replies":[{"id":136526,"content":"想要入门可以看一下 吴恩达 老师的 deeplearning.ai 的课程，根据自己的需要从 beginner 级别的看起。但是这些也是需要一定的时间的，以及了解一定程度的原理。公式可以囫囵吞枣，作业都写完就OK了。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1683094101,"ip_address":"上海","comment_id":373241,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"特意赶到最新进度的文章给老师留言咨询个问题：\n背景：首先，这个课程真的是干货满满，物超所值，感谢老师的辛苦、认真付出！但是，作为一个10来年经验的老码农（现在是区块链方面的架构、研发）总觉得跟得有点吃力，原因是缺少AI方面的基础知识，对课程中的一些库、算法的原理缺少基本的概念认知。当然如果只局限于”过一遍代码、熟练使用“基本是够了，但是我觉得还达不到入门级。所以，特地来请教下老师哪些可以作为入门的一手知识，越精简越好。\n问题：能否请老师推荐或者总结归纳下入门AI或者大语言模型的最小基础知识是哪些？（李笑来老师提过的入门一个新领域的MAKE [Minimal Actionable Knowledge and Experience]) \n可能上面的问题有点大，我再缩小下，我的目的不是转行AI领域开发，而是得心应手的使用AI大语言模型开发自己的应用或者提高工作效率，比如使用AI做些财务建议、投研之类的应用。我总觉得只是会调接口，完全不理解基础概念还是无法游刃有余的使用，离开课程，就很难有思路做自主开发了。\n\n说的有点啰嗦了，感谢老师！\n","like_count":13,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":616767,"discussion_content":"想要入门可以看一下 吴恩达 老师的 deeplearning.ai 的课程，根据自己的需要从 beginner 级别的看起。但是这些也是需要一定的时间的，以及了解一定程度的原理。公式可以囫囵吞枣，作业都写完就OK了。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1683094101,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1221705,"avatar":"https://static001.geekbang.org/account/avatar/00/12/a4/49/1c8598d1.jpg","nickname":"军舰","note":"","ucode":"C7E97415F5196A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":615620,"discussion_content":"补补AI基础，课程多看多练。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1682348527,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"山东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":373234,"user_name":"John","can_delete":false,"product_type":"c1","uid":1020861,"ip_address":"加拿大","ucode":"E4ADF8488953FB","user_header":"https://static001.geekbang.org/account/avatar/00/0f/93/bd/f3977ebb.jpg","comment_is_top":false,"comment_ctime":1682286814,"is_pvip":false,"replies":[{"id":136507,"content":"PaddleBobo其实没有几行代码，本质上就是 Deepfake类的GAN的解决方案，开源的GAN的库都可以看看是否适合作为平替。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1683091367,"ip_address":"上海","comment_id":373234,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"这个paddleBoBo都一年没更新啦 还有没有平替或者潜在新产品呢","like_count":3,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":616747,"discussion_content":"PaddleBobo其实没有几行代码，本质上就是 Deepfake类的GAN的解决方案，开源的GAN的库都可以看看是否适合作为平替。","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1683091367,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1013566,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/77/3e/790f4652.jpg","nickname":"马帅","note":"","ucode":"E86712B25007E1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":617668,"discussion_content":"sadtalker","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683765319,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":373366,"user_name":"abc🙂","can_delete":false,"product_type":"c1","uid":1887261,"ip_address":"福建","ucode":"FCF2B9091D161B","user_header":"https://static001.geekbang.org/account/avatar/00/1c/cc/1d/3c0272a1.jpg","comment_is_top":false,"comment_ctime":1682428925,"is_pvip":false,"replies":[{"id":136520,"content":"用18讲fine-tune的方式，输入大量你自己写作的语料\n\n但是fine-tune对于数据量还是有一定要求的，至少有个500篇的文章才有一定效果吧。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1683093633,"ip_address":"上海","comment_id":373366,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"老师，如果想要AI学习我的写作风格，按照我的风格写作，要怎么训练呢？","like_count":2,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":616761,"discussion_content":"用18讲fine-tune的方式，输入大量你自己写作的语料\n\n但是fine-tune对于数据量还是有一定要求的，至少有个500篇的文章才有一定效果吧。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683093633,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":1887261,"avatar":"https://static001.geekbang.org/account/avatar/00/1c/cc/1d/3c0272a1.jpg","nickname":"abc🙂","note":"","ucode":"FCF2B9091D161B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":616938,"discussion_content":"原来如此，明白了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683204577,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":616761,"ip_address":"福建","group_id":0},"score":616938,"extra":""}]}]},{"had_liked":false,"id":373233,"user_name":"John","can_delete":false,"product_type":"c1","uid":1020861,"ip_address":"加拿大","ucode":"E4ADF8488953FB","user_header":"https://static001.geekbang.org/account/avatar/00/0f/93/bd/f3977ebb.jpg","comment_is_top":false,"comment_ctime":1682286199,"is_pvip":false,"replies":[{"id":136458,"content":"嗯，现在数字人类的产品都不便宜","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1683082938,"ip_address":"上海","comment_id":373233,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"现在HeyGen不错 就是收费不低","like_count":1,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":616681,"discussion_content":"嗯，现在数字人类的产品都不便宜","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683082938,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":373534,"user_name":"劉仲仲","can_delete":false,"product_type":"c1","uid":3582548,"ip_address":"广东","ucode":"265814B92CE40E","user_header":"https://static001.geekbang.org/account/avatar/00/36/aa/54/bf64d522.jpg","comment_is_top":false,"comment_ctime":1682612656,"is_pvip":false,"replies":[{"id":136503,"content":"PaddleGAN应该还不支持windows","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1683091129,"ip_address":"上海","comment_id":373534,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"出现error:module &#39;pexpect&#39; has no attribute &#39;spawn&#39;,已经是最新的pexpect","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":616743,"discussion_content":"PaddleGAN应该还不支持windows","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683091129,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3582548,"avatar":"https://static001.geekbang.org/account/avatar/00/36/aa/54/bf64d522.jpg","nickname":"劉仲仲","note":"","ucode":"265814B92CE40E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":616400,"discussion_content":"原来是pexpeut不支持windows","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1682779421,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":373265,"user_name":"粉墨之下","can_delete":false,"product_type":"c1","uid":3581576,"ip_address":"甘肃","ucode":"3DB6A9CA2D34CD","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/RSBuejSw2icwNxLQeW0Xs6ib9pedqEhB7h6kYbOdaxiaUbLz2xSxE2e7e0yHneLicBCkmnhQ4QSuzKx0K5aUaeyaQQ/132","comment_is_top":false,"comment_ctime":1682329196,"is_pvip":false,"replies":[{"id":136486,"content":"大概率是神奇的网络访问问题，这个需要自己想办法解决啦，或者直接通过Colab环境来运行。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1683086893,"ip_address":"上海","comment_id":373265,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"本地运行后，回复时报错：Retrying langchain.llms.openai.completion_with_retry.&lt;locals&gt;._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: HTTPSConnectionPool(host=&#39;api.openai.com&#39;, port=443): Max retries exceeded with url: &#47;v1&#47;completions (Caused by NewConnectionError(&#39;&lt;urllib3.connection.HTTPSConnection object at 0x000001F9C7DAD670&gt;: Failed to establish a new connection: [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。&#39;)).","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":616722,"discussion_content":"大概率是神奇的网络访问问题，这个需要自己想办法解决啦，或者直接通过Colab环境来运行。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683086893,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":373239,"user_name":"一叶","can_delete":false,"product_type":"c1","uid":3577168,"ip_address":"福建","ucode":"21E5455D0814E5","user_header":"https://static001.geekbang.org/account/avatar/00/36/95/50/01199ae9.jpg","comment_is_top":false,"comment_ctime":1682296833,"is_pvip":false,"replies":[{"id":136452,"content":"对，国内的数字人现在报价也比较贵，有数据的话，自己通过GAN来做梗合适一些。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1683082777,"ip_address":"上海","comment_id":373239,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"刚看了下,这个did的价格不是一般的贵....","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":616674,"discussion_content":"对，国内的数字人现在报价也比较贵，有数据的话，自己通过GAN来做梗合适一些。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683082777,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3572315,"avatar":"https://static001.geekbang.org/account/avatar/00/36/82/5b/df97e03c.jpg","nickname":"Santiago","note":"","ucode":"E7301F6A5076DC","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":615936,"discussion_content":"请问DID的接口调用怎么操作，我用老师的代码配置自己的API KEY，发现需要认证，请问怎么认证","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1682505256,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"山西","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":383704,"user_name":"小理想。","can_delete":false,"product_type":"c1","uid":2238528,"ip_address":"北京","ucode":"EDC35A907570DB","user_header":"https://static001.geekbang.org/account/avatar/00/22/28/40/82d748e6.jpg","comment_is_top":false,"comment_ctime":1699497585,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"txt = gr.Textbox(show_label=False, placeholder=&quot;Enter text and press enter&quot;).style(container=False)\n官网文档也都没有.style(container=False)","like_count":0},{"had_liked":false,"id":383703,"user_name":"小理想。","can_delete":false,"product_type":"c1","uid":2238528,"ip_address":"北京","ucode":"EDC35A907570DB","user_header":"https://static001.geekbang.org/account/avatar/00/22/28/40/82d748e6.jpg","comment_is_top":false,"comment_ctime":1699497397,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"audio = gr.Audio(source=&quot;microphone&quot;, type=&quot;filepath&quot;)\n老师这段代码没有source属性，这个属性是sources才可以，可能写错了哈哈哈\naudio=gr.Audio(sources=&quot;microphone&quot;, type=&quot;filepath&quot;)","like_count":0},{"had_liked":false,"id":383593,"user_name":"小理想。","can_delete":false,"product_type":"c1","uid":2238528,"ip_address":"北京","ucode":"EDC35A907570DB","user_header":"https://static001.geekbang.org/account/avatar/00/22/28/40/82d748e6.jpg","comment_is_top":false,"comment_ctime":1699326871,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"https:&#47;&#47;cdn.discordapp.com&#47;attachments&#47;1065596492796153856&#47;1095617463112187984&#47;John_Carmack_Potrait_668a7a8d-1bb0-427d-8655-d32517f6583d.png\n老师这个地址访问不了，是不是我需要把文件下载下来自己映射一下哈","like_count":0},{"had_liked":false,"id":377767,"user_name":"静心","can_delete":false,"product_type":"c1","uid":1335457,"ip_address":"中国香港","ucode":"EB264FA6519FDA","user_header":"https://static001.geekbang.org/account/avatar/00/14/60/a1/45ffdca3.jpg","comment_is_top":false,"comment_ctime":1689161101,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"如果能有一个完整的数字人开源方案就好了","like_count":0}]}