{"id":280925,"title":"11｜隔离性：读写冲突时，快照是最好的办法吗？","content":"<p>你好，我是王磊，你也可以叫我Ivan。我们今天的话题要从多版本并发控制开始。</p><p>多版本并发控制（Multi-Version Concurrency Control，MVCC）就是<strong>通过记录数据项历史版本的方式，来提升系统应对多事务访问的并发处理能力</strong>。今天，几乎所有主流的单体数据库都实现了MVCC，它已经成为一项非常重要也非常普及的技术。</p><p>MVCC为什么这么重要呢？我们通过下面例子来回顾一下MVCC出现前的读写冲突场景。</p><p><img src=\"https://static001.geekbang.org/resource/image/f2/fc/f2dfc3915ed8f39f4eec8d73bf1b80fc.jpg?wh=2700*916\" alt=\"\"></p><p>图中事务T1、T2先后启动，分别对数据库执行写操作和读操作。写操作是一个过程，在过程中任意一点，数据的变更都是不完整的，所以T2必须在数据写入完成后才能读取，也就形成了读写阻塞。反之，如果T2先启动，T1也要等待T2将数据完全读取后，才能执行写入。</p><p>早期数据库的设计和上面的例子一样，读写操作之间是互斥的，具体是通过锁机制来实现的。</p><p>你可能会觉得这个阻塞也没那么严重，磁盘操作应该很快吧?</p><p>别着急下结论，让我们来分析下。如果先执行的是T1写事务，除了磁盘写入数据的时间，由于要保证数据库的高可靠，至少还有一个备库同步复制主库的变更内容。这样，阻塞时间就要再加上一次网络通讯的开销。</p><p>如果先执行的是T2只读事务，情况也好不到哪去，虽然不用考虑复制问题，但是读操作通常会涉及更大范围的数据，这样一来加锁的记录会更多，被阻塞的写操作也就更多。而且，只读事务往往要执行更加复杂的计算，阻塞的时间也就更长。</p><!-- [[[read_end]]] --><p>所以说，用锁解决读写冲突问题，带来的事务阻塞开销还是不小的。相比之下，用MVCC来解决读写冲突，就不存在阻塞问题，要优雅得多了。</p><p><a href=\"https://time.geekbang.org/column/article/274200\">第4讲</a>中我们介绍了PGXC和NewSQL两种架构风格，而且还说到分布式数据库的很多关键设计是和整体架构风格有关的。MVCC的设计就是这样，随架构风格不同而不同。在PGXC架构中，因为数据节点就是单体数据库，所以<strong>PGXC的MVCC实现方式其实就是单体数据库的实现方式。</strong></p><h2>单体数据库的MVCC</h2><p>那么，就让我们先看下单体数据库的MVCC是怎么设计的。开头我们说了实现MVCC要记录数据的历史版本，这就涉及到存储的问题。</p><h3>MVCC的存储方式</h3><p>MVCC有三类存储方式，一类是将历史版本直接存在数据表中的，称为Append-Only，典型代表是PostgreSQL。另外两类都是在独立的表空间存储历史版本，它们区别在于存储的方式是全量还是增量。增量存储就是只存储与版本间变更的部分，这种方式称为Delta，也就是数学中常作为增量符号的那个Delta，典型代表是MySQL和Oracle。全量存储则是将每个版本的数据全部存储下来，这种方式称为Time-Travle，典型代表是HANA。我把这三种方式整理到了下面的表格中，你看起来会更直观些。</p><p><img src=\"https://static001.geekbang.org/resource/image/93/5f/93a030347f0a93c9a97739f0a82b515f.jpg?wh=2700*848\" alt=\"\"></p><p>下面，我们来看看每种方式的优缺点。</p><h4>Append-Only方式</h4><p>优点</p><ol>\n<li>在事务包含大量更新操作时也能保持较高效率。因为更新操作被转换为Delete + Insert，数据并未被迁移，只是有当前版本被标记为历史版本，磁盘操作的开销较小。</li>\n<li>可以追溯更多的历史版本，不必担心回滚段被用完。</li>\n<li>因为执行更新操作时，历史版本仍然留在数据表中，所以如果出现问题，事务能够快速完成回滚操作。</li>\n</ol><p>缺点</p><ol>\n<li>新老数据放在一起，会增加磁盘寻址的开销，随着历史版本增多，会导致查询速度变慢。</li>\n</ol><h4>Delta方式</h4><p>优点</p><ol>\n<li>因为历史版本独立存储，所以不会影响当前读的执行效率。</li>\n<li>因为存储的只是变化的增量部分，所以占用存储空间较小。</li>\n</ol><p>缺点</p><ol>\n<li>历史版本存储在回滚段中，而回滚段由所有事务共享，并且还是循环使用的。如果一个事务执行持续的时间较长，历史版本可能会被其他数据覆盖，无法查询。</li>\n<li>这个模式下读取的历史版本，实际上是基于当前版本和多个增量版本计算追溯回来的，那么计算开销自然就比较大。</li>\n</ol><p>Oracle早期版本中经常会出现的ORA-01555 “快照过旧”（Snapshot Too Old），就是回滚段中的历史版本被覆盖造成的。通常，设置更大的回滚段和缩短事务执行时间可以解决这个问题。随着Oracle后续版本采用自动管理回滚段的设计，这个问题也得到了缓解。</p><h4>Time-Travel方式</h4><p>优点</p><ol>\n<li>同样是将历史版本独立存储，所以不会影响当前读的执行效率。</li>\n<li>相对Delta方式，历史版本是全量独立存储的，直接访问即可，计算开销小。</li>\n</ol><p>缺点</p><ol>\n<li>相对Delta方式，需要占用更大的存储空间。</li>\n</ol><p>当然，无论采用三种存储方式中的哪一种，都需要进行历史版本清理。</p><p>好了，以上就是单体数据库MVCC的三种存储方式，同时也是PGXC的实现方式。而NewSQL底层使用分布式键值系统来存储数据，MVCC的存储方式与PostgreSQL类似，采用Append方式追加新版本。我觉得你应该比较容易理解，就不再啰嗦了。</p><p>为了便于你记忆，我把三种存储方式的优缺点提炼了一下放到下面表格中，其实说到底这些特点就是由“是否独立存储”和“存储全量还是存储增量变更”这两个因素决定的。</p><p><img src=\"https://static001.geekbang.org/resource/image/ae/e3/aec7c3224af50fe8551697c10be430e3.jpg?wh=2700*1052\" alt=\"\"></p><h3>MVCC的工作过程</h3><p>历史版本存储下来后又是如何发挥作用的呢？这个，我们开头时也说过了，是要解决多事务的并发控制问题，也就是保证事务的隔离性。在<a href=\"https://time.geekbang.org/column/article/272999\">第3讲</a>，我们介绍了隔离性的多个级别，其中可接受的最低隔离级别就是“已提交读”（Read Committed，RC）。</p><p>那么，我们先来看RC隔离级别下MVCC的工作过程。</p><p>按照RC隔离级别的要求，事务只能看到的两类数据：</p><ol>\n<li>当前事务的更新所产生的数据。</li>\n<li>当前事务启动前，已经提交事务更新的数据。</li>\n</ol><p>我们用一个例子来说明。</p><p><img src=\"https://static001.geekbang.org/resource/image/bc/01/bc504c1f630657a17734380def013c01.jpg?wh=2700*1018\" alt=\"\"></p><p>T1到T7是七个数据库事务，它们先后运行，分别操作数据库表的记录R1到R7。事务T6要读取R1到R6这六条记录，在T6启动时（T6-1）会向系统申请一个活动事务列表，活动事务就是已经启动但尚未提交的事务，这个列表中会看到T3、T4、T5等三个事务。</p><p>T6查询到R3、R4、R5时，看到它们最新版本的事务ID刚好在活动事务列表里，就会读取它们的上一版本。而R1、R2最新版本的事务ID小于活动事务列表中的最小事务ID（即T3），所以T6可以看到R1、R2的最新版本。</p><p>这个例子中MVCC的收益非常明显，T6不会被正在执行写入操作的三个事务阻塞，而如果按照原来的锁方式，T6要在T3、T4、T5三个事务都结束后，才能执行。</p><h3>快照的工作原理</h3><p>MVCC在RC级别的效果还不错。那么，如果隔离级别是更严格一些的 “可重复读”（RR）呢？我们继续往下看。</p><p><img src=\"https://static001.geekbang.org/resource/image/03/7d/03ecd79c93d3c1cd3a40af813yy7507d.jpg?wh=2700*1001\" alt=\"\"></p><p>还是继续刚才的例子，当T6执行到下一个时间点（T6-2），T1到T4等4个事务都已经提交，此时T6再次向系统申请活动事务列表，列表包含T5和T7。遵循同样的规则，这次T6可以看到R1到R4等四条记录的最新版本，同时看到R5的上一版本。</p><p>很明显，T6刚才和现在这两次查询得到了不同的结果集，这是不符合RR要求的。</p><p>实现RR的办法也很简单，我们只需要记录下T6-1时刻的活动事务列表，在T6-2时再次使用就行了。那么，这个反复使用的活动事务列表就被称为“快照”（Snapshot）。</p><p><img src=\"https://static001.geekbang.org/resource/image/86/ac/86d3436e8ca462202b8d9ebde33fabac.jpg?wh=2700*1010\" alt=\"\"></p><p>快照是基于MVCC实现的一个重要功能，从效果上看， 快照就是快速地给数据库拍照片，数据库会停留在你拍照的那一刻。所以，用“快照”来实现RR是很方便的。</p><p>从上面的例子可以发现，RC与RR的区别在于RC下每个SQL语句会有一个自己的快照，所以看到的数据库是不同的，而RR下，所有SQL语句使用同一个快照，所以会看到同样的数据库。</p><p>为了提升效率，快照不是单纯的事务ID列表，它会统计最小活动事务ID，还有最大已提交事务ID。这样，多数事务ID通过比较边界值就能被快速排除掉，如果事务ID恰好在边界范围内，再进一步查找是否与活跃事务ID匹配。</p><p>快照在MySQL中称为ReadView，在PostgreSQL中称为SnapshotData，组织方式都是类似的。</p><h2>PGXC读写冲突处理</h2><p>在PGXC架构中，实现RC隔离级的处理过程与单体数据库差异并不大。我想和你重点介绍的是，PGXC在实现RR时遇到的两个挑战，也就是实现快照的两个挑战。</p><p>一是如何保证产生单调递增事务ID。每个数据节点自行处理显然不行，这就需要由一个集中点来统一生成。</p><p>二是如何提供全局快照。每个事务要把自己的状态发送给一个集中点，由它维护一个全局事务列表，并向所有事务提供快照。</p><p>所以，PGXC风格的分布式数据库都有这样一个集中点，通常称为全局事务管理器（GTM）。又因为事务ID是单调递增的，用来衡量事务发生的先后顺序，和时间戳作用相近，所以全局事务管理器也被称为“全局时钟”。</p><h2>NewSQL读写冲突处理</h2><p>讲完PGXC的快照，再来看看NewSQL如何处理读写冲突。这里，我要向你介绍TiDB和CockroachDB两种实现方式，因为它们是比较典型的两种情况。至于它们哪里典型呢？我先不说，你可以在阅读过程中仔细体会。</p><h3>TiDB</h3><p>首先来说TiDB，我们看图说话。</p><p><img src=\"https://static001.geekbang.org/resource/image/e9/d9/e991e0cbf84a02aa5c3851fa083f24d9.jpg?wh=2700*888\" alt=\"\"></p><p>TiDB底层是分布式键值系统，我们假设两个事务操作同一个数据项。其中，事务T1执行写操作，由Prewrite和Commit两个阶段构成，对应了我们之前介绍的两阶段提交协议（2PC），如果你还不熟悉可以重新阅读<a href=\"https://time.geekbang.org/column/article/278949\">第9讲</a>复习一下。这里你也可以简单理解为T1的写操作分成了两个阶段，T2在这两个阶段之间试图执行读操作，但是T2会被阻塞，直到T1完成后，T2才能继续执行。</p><p>你肯定会非常惊讶，这不是MVCC出现前的读写阻塞吗？</p><p>TiDB为什么没有使用快照读取历史版本呢？ TiDB官方文档并没有说明背后的思路，我猜问题出在全局事务列表上，因为TiDB根本没有设计全局事务列表。当然这应该不是设计上的疏忽，我更愿意把它理解为一种权衡，是在读写效率和全局事务列表的维护代价之间的选择。</p><p>事实上，PGXC中的全局事务管理器就是一个单点，很容易成为性能的瓶颈，而分布式系统一个普遍的设计思想就是要避免对单点的依赖。当然，TiDB的这个设计付出的代价也是巨大的。虽然，TiDB在3.0版本后增加了悲观锁，设计稍有变化，但大体仍是这样。</p><h3>CockroachDB</h3><p>那么如果有全局事务列表，又会怎么操作呢？说来也巧，CockroachDB真的就设计了这么一张全局事务列表。它是否照搬了单体数据库的“快照”呢？答案也是否定的。</p><p>我们来看看它的处理过程。</p><p><img src=\"https://static001.geekbang.org/resource/image/e6/68/e6c49739eb9b6ayy030698013e685f68.jpg?wh=2700*968\" alt=\"\"></p><p>依旧是T1事务先执行写操作，中途T2事务启动，执行读操作，此时T2会被优先执行。待T2完成后，T1事务被重启。重启的意思是T1获得一个新的时间戳（等同于事务ID）并重新执行。</p><p>又是一个不可思议的过程，还是会产生读写阻塞，这又怎么解释呢？</p><p>CockroachDB没有使用快照，不是因为没有全局事务列表，而是因为它的隔离级别目标不是RR，而是SSI，也就是可串行化。</p><p>你可以回想一下第3讲中黑白球的例子。对于串行化操作来说，没有与读写并行操作等价的处理方式，因为先读后写和先写后读，读操作必然得到两个不同结果。更加学术的解释是，先读后写操作会产生一个<strong>读写反向依赖</strong>，可能影响串行化事务调度。这个概念有些不好理解，你也不用着急，在14讲中我会有更详细的介绍。总之，CockroachDB对于读写冲突、写写冲突采用了几乎同样的处理方式。</p><p>在上面的例子中，为了方便描述，我简化了读写冲突的处理过程。事实上，被重启的事务并不一定是执行写操作的事务。CockroachDB的每个事务都有一个优先级，出现事务冲突时会比较两个事务的优先级，高优先级的事务继续执行，低优先级的事务则被重启。而被重启事务的优先级也会提升，避免总是在竞争中失败，最终被“饿死”。</p><p>TiDB和CockroachDB的实现方式已经讲完了，现在你该明白它们典型在哪里了吧？对，那就是全局事务列表是否存在和实现哪种隔离级别，这两个因素都会影响最终的设计。</p><p><img src=\"https://static001.geekbang.org/resource/image/fa/91/fa07956ea5ddb076eefa32ae7affa191.jpg?wh=2700*2532\" alt=\"\"></p><h2>小结</h2><p>好了，今天的话题就谈到这了，让我们一起回顾下这一讲的内容。</p><ol>\n<li>用锁机制来处理读写冲突会影响并发处理能力，而MVCC的出现很好地解决了这个问题，几乎所有的单体数据库都实现了MVCC。MVCC技术包括数据的历史版本存储、清理机制，存储方式具体包括Append-Only、Delta、Time-Travel三种方式。通过MVCC和快照（基于MVCC），单体数据库可以完美地解决RC和RR级别下的读写冲突问题，不会造成事务阻塞。</li>\n<li>PGXC风格的分布式数据库，用单体数据库作为数据节点存储数据，所以自然延续了其MVCC的实现方式。但PGXC的改变在于增加了全局事务管理器统一管理事务ID的生成和活动事务列表的维护。</li>\n<li>NewSQL风格的分布式数据库，没有普遍采用快照解决读写冲突问题，其中TiDB是由于权衡全局事务列表的代价，CockroachDB则是因为要实现更高的隔离级别。但无论哪种原因，都造成了读写并行能力的下降。</li>\n</ol><p>要特别说明的是，虽然NewSQL架构的分布式数据库没有普遍使用快照处理读写事务，但它们仍然实现了MVCC，在数据存储层保留了历史版本。所以，NewSQL产品往往也会提供一些低数据一致性的只读事务接口，提升读取操作的性能。</p><h2>思考题</h2><p>最后，又到了我们的思考题时间。今天我介绍了两种风格的分布式数据库如何解决读写冲突问题。其实，无论是否使用MVCC实现快照隔离，时间都是一个重要的因素，每个事务都要获得一个事务ID或者时间戳，这直接决定了它能够读取什么版本的数据或者是否被阻塞。</p><p>但是你有没有想过时间误差的问题。我在<a href=\"https://time.geekbang.org/column/article/272104\">第2讲</a>中曾经提到Spanner的全局时钟存在7毫秒的误差，在<a href=\"https://time.geekbang.org/column/article/274908\">第5讲</a>又深入探讨了物理时钟和逻辑时钟如何控制时间误差。那么，你觉得时间误差会影响读写冲突的处理吗？</p><p>如果你想到了答案，又或者是触发了你对相关问题的思考，都可以在评论区和我聊聊，我会在下一讲和你一起探讨。最后，希望这节课能带给你一些收获，也欢迎你把它分享给周围的朋友，一起进步。</p>","comments":[{"had_liked":false,"id":245615,"user_name":"真名不叫黄金","can_delete":false,"product_type":"c1","uid":1174066,"ip_address":"","ucode":"FB611FC98F5BA7","user_header":"https://static001.geekbang.org/account/avatar/00/11/ea/32/1fd102ec.jpg","comment_is_top":false,"comment_ctime":1599009357,"is_pvip":false,"replies":[{"id":"90332","content":"说得很好，基本都正确，点赞。我在第12讲介绍了Spanner的完整处理过程，可以参考。","user_name":"作者回复","user_name_real":"王磊(Ivan)","uid":"1602401","ctime":1599012449,"ip_address":"","comment_id":245615,"utype":1}],"discussion_count":2,"race_medal":0,"score":"74613453389","product_id":100057401,"comment_content":"我认为 Spanner 的时钟误差会影响到事务吞吐量：<br>由于 Spanner 是 External Consistency 的，也就是可线性化（linearizable）的，那么只要两个事务需要读写的数据中有相交的数据，那么它俩的提交时间平均间隔至少是7ms，因为置信区间平均是7ms，那么在这个置信区间内是不能 commint 2 个读写了某个相同数据的事务的，否则就会打破可线性化，因为两个事务不一定分得出先后。因此 Spanner 在单位时间内的事务吞吐量是被时钟误差限制的，时钟误差越小，吞吐量越高，误差越大，吞吐量越低。<br>并且我也猜测，以下两种情况是的事务吞吐量是不被时钟误差影响的：<br>1. 如果两个事务操作的是完全不相交的数据，那么它们的 commit time 是可以重合的，因此时钟误差限制的仅仅是操作相交数据的事务的吞吐量。<br>2. 如果某个事务是只读事务，那么也不受限制，因为只读是基于快照的，其 commit timestamp 并没有意义，因此不需要与读写事务抢时钟。<br><br>受限于既有知识，猜测可能有误，仅仅是交流~","like_count":18,"discussions":[{"author":{"id":1602401,"avatar":"https://static001.geekbang.org/account/avatar/00/18/73/61/3059679f.jpg","nickname":"王磊(Ivan)","note":"","ucode":"CF0B955A06FE2A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":504931,"discussion_content":"说得很好，基本都正确，点赞。我在第12讲介绍了Spanner的完整处理过程，可以参考。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1599012449,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1069127,"avatar":"https://static001.geekbang.org/account/avatar/00/10/50/47/46da4585.jpg","nickname":"Fan()","note":"","ucode":"FED79EC7D78E91","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":302844,"discussion_content":"大神","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1599046059,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":279786,"user_name":"尘封","can_delete":false,"product_type":"c1","uid":1247006,"ip_address":"","ucode":"CEE0C006387A03","user_header":"https://static001.geekbang.org/account/avatar/00/13/07/1e/bdbe93f4.jpg","comment_is_top":false,"comment_ctime":1613962477,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"14498864365","product_id":100057401,"comment_content":"tidb实现了mvcc，但是使用过程中确实存在读写冲突，一直没想明白，看完这一章内容，理解了。<br>老师，想问下，tidb既然存在读写冲突，那么select count一张大表时，这张表应该会阻塞写，但是感觉好像没阻塞，这是为什么？<br>我想表达的意思是：本文描述的读写冲突原因确实有道理，但是使用时又感觉没那么严重","like_count":3},{"had_liked":false,"id":288040,"user_name":"Clement","can_delete":false,"product_type":"c1","uid":1324923,"ip_address":"","ucode":"0A95EA1A484997","user_header":"https://static001.geekbang.org/account/avatar/00/14/37/7b/cb81828e.jpg","comment_is_top":false,"comment_ctime":1618279352,"is_pvip":false,"replies":[{"id":"105031","content":"Raft通常用来做数据一致性，也就是多副本的一致性，而事务一致性，包括分布式事务，还是用2PC的各种优化。","user_name":"作者回复","user_name_real":"王磊(Ivan)","uid":"1602401","ctime":1619066477,"ip_address":"","comment_id":288040,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10208213944","product_id":100057401,"comment_content":"tidb不是用raft实现了全局时钟么，为什么不可以用来作全局事务管理？","like_count":2,"discussions":[{"author":{"id":1602401,"avatar":"https://static001.geekbang.org/account/avatar/00/18/73/61/3059679f.jpg","nickname":"王磊(Ivan)","note":"","ucode":"CF0B955A06FE2A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":518498,"discussion_content":"Raft通常用来做数据一致性，也就是多副本的一致性，而事务一致性，包括分布式事务，还是用2PC的各种优化。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1619066477,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":259675,"user_name":"幼儿编程教学","can_delete":false,"product_type":"c1","uid":1237199,"ip_address":"","ucode":"F13F3150E6CAE9","user_header":"https://static001.geekbang.org/account/avatar/00/12/e0/cf/43f201f2.jpg","comment_is_top":false,"comment_ctime":1604807373,"is_pvip":false,"replies":[{"id":"94384","content":"多个会话要同时修改一个数据项，就必须有一套规则来协同，这就是并发控制机制。锁只是其中一种技术，基于锁也有多种处理方式，我们的专栏中展开介绍了这个问题。最后，这是所有数据库都要处理的问题，并不限于TiDB。","user_name":"作者回复","user_name_real":"王磊(Ivan)","uid":"1602401","ctime":1604831236,"ip_address":"","comment_id":259675,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10194741965","product_id":100057401,"comment_content":"所以，tidb宣称的高并发，是基于不同的数据？修改同一块数据的话，其实是降的？因为有锁。。。","like_count":3,"discussions":[{"author":{"id":1602401,"avatar":"https://static001.geekbang.org/account/avatar/00/18/73/61/3059679f.jpg","nickname":"王磊(Ivan)","note":"","ucode":"CF0B955A06FE2A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":508999,"discussion_content":"多个会话要同时修改一个数据项，就必须有一套规则来协同，这就是并发控制机制。锁只是其中一种技术，基于锁也有多种处理方式，我们的专栏中展开介绍了这个问题。最后，这是所有数据库都要处理的问题，并不限于TiDB。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1604831236,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":334684,"user_name":"陈阳","can_delete":false,"product_type":"c1","uid":2653715,"ip_address":"","ucode":"C8E676C967D23A","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKib3vNM6TPT1umvR3TictnLurJPKuQq4iblH5upgBB3kHL9hoN3Pgh3MaR2rjz6fWgMiaDpicd8R5wsAQ/132","comment_is_top":false,"comment_ctime":1645076620,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"5940043916","product_id":100057401,"comment_content":"按照 RC 隔离级别的要求，事务只能看到的两类数据：<br>1.当前事务的更新所产生的数据。<br>2.当前事务启动前，已经提交事务更新的数据。<br><br>这段描述好像不对吧， 在rc级别下， 当前事务启动后还未提交的过程中， 这时候有个事务开启，然后提交，对当前事务也是可见的","like_count":1},{"had_liked":false,"id":273034,"user_name":"哎嗨，灰灰","can_delete":false,"product_type":"c1","uid":1231709,"ip_address":"","ucode":"000F8C7E1E6F4E","user_header":"https://static001.geekbang.org/account/avatar/00/12/cb/5d/4c27ce86.jpg","comment_is_top":false,"comment_ctime":1610418186,"is_pvip":true,"replies":[{"id":"98957","content":"这个词也不是很严格，算习惯用法吧，理解意思就好，就是表示不修改原有数据而做追加。比如，hbase中的数据修改也是这样。","user_name":"作者回复","user_name_real":"王磊(Ivan)","uid":"1602401","ctime":1610447928,"ip_address":"","comment_id":273034,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5905385482","product_id":100057401,"comment_content":"MVCC 有三类存储方式，一类是将历史版本直接存在数据表中的，称为 Append-Only，典型代表是 PostgreSQL。<br>------<br>请教老师一下，这个词append-only是专业术语吗？因为我觉得postgresql的mvcc不能说成append-only，这有可能是我对这个名词的理解有问题","like_count":1,"discussions":[{"author":{"id":1602401,"avatar":"https://static001.geekbang.org/account/avatar/00/18/73/61/3059679f.jpg","nickname":"王磊(Ivan)","note":"","ucode":"CF0B955A06FE2A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":513467,"discussion_content":"这个词也不是很严格，算习惯用法吧，理解意思就好，就是表示不修改原有数据而做追加。比如，hbase中的数据修改也是这样。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1610447928,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":246690,"user_name":"扩散性百万咸面包","can_delete":false,"product_type":"c1","uid":1905171,"ip_address":"","ucode":"6D703D51553B42","user_header":"https://static001.geekbang.org/account/avatar/00/1d/12/13/e103a6e3.jpg","comment_is_top":false,"comment_ctime":1599454809,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"5894422105","product_id":100057401,"comment_content":"老师是不是可以这么总结：<br>1. Append-Only的话，会把同一行的历史数据保存到一张表中，比如User里有个叫张三的，修改了它的值之后就会产生另一行张三，还是在同一个表中。<br>2. Delta的话，保存增量操作，这些操作存储到一个独立的磁盘空间中，而不是当前的数据表、<br>3. Time-Travel有点像redo&#47;undo log，记录内存页在物理磁盘上修改前和后的变化","like_count":1,"discussions":[{"author":{"id":1215758,"avatar":"https://static001.geekbang.org/account/avatar/00/12/8d/0e/1f49ade9.jpg","nickname":"大汉_客家族_数据工程_曾院士","note":"","ucode":"AD73C36D617CA1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":372511,"discussion_content":"旧数据处理方式\nappend_only 表内存旧数据行，基本是本行所有列。\nDelta 是增量，表示存的是行的被改变的旧字段的值，基本是表外存\nTimeval是 全量，整行所有例的旧值，存在表外。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1620358800,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2250114,"avatar":"https://static001.geekbang.org/account/avatar/00/22/55/82/985411a8.jpg","nickname":"xyx","note":"","ucode":"1AECC9DDAC3D11","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":335261,"discussion_content":"1. delta 对标 mysql 对标 undo log(并没有存历史全量的数据哦)\n2. redo log和 undo log完全不是一个概念. redo log对标wal 用于机器故障恢复.","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1608131642,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":347252,"user_name":"鱼","can_delete":false,"product_type":"c1","uid":1487584,"ip_address":"","ucode":"89EC9CE3AD0281","user_header":"https://static001.geekbang.org/account/avatar/00/16/b2/e0/d856f5a4.jpg","comment_is_top":false,"comment_ctime":1653875375,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1653875375","product_id":100057401,"comment_content":"这个Append-Only的存储方式，和LSM-Tree设计和Redis的AOF思路好像。","like_count":0},{"had_liked":false,"id":336945,"user_name":"张可夫斯基","can_delete":false,"product_type":"c1","uid":1076487,"ip_address":"","ucode":"3B8DF6D98583F2","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIKoEicqUZTJly55qoUXRmK4wia7YbnibsMncJaO6tKgKAQNJRfpMsibvfeiaukIibsCsuaic8QjQ3gOoTGA/132","comment_is_top":false,"comment_ctime":1646484697,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1646484697","product_id":100057401,"comment_content":"老师，有的表述需要描述的更条理一些呀。如：<br>缺点<br><br>* 历史版本存储在回滚段中，而回滚段由所有事务共享，并且还是循环使用的。如果一个事务执行持续的时间较长，历史版本可能会被其他数据覆盖，无法查询。<br><br>应该指出delta模式下，回滚段有固定大小限制，在清理数据时，可能会将一些数据在回滚段里的所有历史版本都清除掉了，这样就导致无法查询。","like_count":0},{"had_liked":false,"id":297483,"user_name":"花晨少年","can_delete":false,"product_type":"c1","uid":1098987,"ip_address":"","ucode":"6AA3537A6BA10E","user_header":"https://static001.geekbang.org/account/avatar/00/10/c4/eb/2285a345.jpg","comment_is_top":false,"comment_ctime":1623574893,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1623574893","product_id":100057401,"comment_content":"不太理解，为什么独立存储方式的磁盘开销大呢，在更新操作频繁的情况下?<br>是因为增量计算问题吗？ 但是独立存储全量的方式也存在磁盘开销大吗。","like_count":0},{"had_liked":false,"id":273356,"user_name":"wy","can_delete":false,"product_type":"c1","uid":1064681,"ip_address":"","ucode":"41C1B304E7F032","user_header":"https://static001.geekbang.org/account/avatar/00/10/3e/e9/116f1dee.jpg","comment_is_top":false,"comment_ctime":1610549103,"is_pvip":false,"replies":[{"id":"99076","content":"是的，这就破坏了全局事务的隔离性。","user_name":"作者回复","user_name_real":"王磊(Ivan)","uid":"1602401","ctime":1610600397,"ip_address":"","comment_id":273356,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1610549103","product_id":100057401,"comment_content":"我理解pgxc没有在每个数据节点去维护一个活跃事务表，是因为会出现当某个全局事务在commit阶段时候，某个节点已经完成commit，但是整体还没完成的情况下，如果下个事务进来，会读取到已经commit完成节点的数据，但是读不到未完成commit节点的数据。这个时候就有问题了。","like_count":0,"discussions":[{"author":{"id":1602401,"avatar":"https://static001.geekbang.org/account/avatar/00/18/73/61/3059679f.jpg","nickname":"王磊(Ivan)","note":"","ucode":"CF0B955A06FE2A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":513574,"discussion_content":"是的，这就破坏了全局事务的隔离性。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1610600397,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1215758,"avatar":"https://static001.geekbang.org/account/avatar/00/12/8d/0e/1f49ade9.jpg","nickname":"大汉_客家族_数据工程_曾院士","note":"","ucode":"AD73C36D617CA1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":372512,"discussion_content":"其实查询语带着时间戳和全局事务列表进入单体数据库，利用单体mvcc功能，当行上事务时间戳小于等于查询的时间戳，并且不在活跃事务列表。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1620359147,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":272144,"user_name":"扩散性百万咸面包","can_delete":false,"product_type":"c1","uid":1905171,"ip_address":"","ucode":"6D703D51553B42","user_header":"https://static001.geekbang.org/account/avatar/00/1d/12/13/e103a6e3.jpg","comment_is_top":false,"comment_ctime":1609946990,"is_pvip":false,"replies":[{"id":"98667","content":"这里的写操作往往是指一个完整的写操作事务，不是事务中某个单独的update或insert语句。事实上，要满足事务ACID也不可能让每个写操作都执行独立的commit，我将这一点作为大家默认的前提了，看来还是要再说明一下。TiDB的2PC处理过程确实是在整个事务执行到commit语句时才会做实质操作，这点没问题。","user_name":"作者回复","user_name_real":"王磊(Ivan)","uid":"1602401","ctime":1609975716,"ip_address":"","comment_id":272144,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1609946990","product_id":100057401,"comment_content":"感觉这一章有点故意混淆写操作和2PC。TiDB的事务应该只有提交的时候才涉及Prewrite&#47;Commit，而不是每次写操作发生的时候","like_count":0,"discussions":[{"author":{"id":1602401,"avatar":"https://static001.geekbang.org/account/avatar/00/18/73/61/3059679f.jpg","nickname":"王磊(Ivan)","note":"","ucode":"CF0B955A06FE2A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":513173,"discussion_content":"这里的写操作往往是指一个完整的写操作事务，不是事务中某个单独的update或insert语句。事实上，要满足事务ACID也不可能让每个写操作都执行独立的commit，我将这一点作为大家默认的前提了，看来还是要再说明一下。TiDB的2PC处理过程确实是在整个事务执行到commit语句时才会做实质操作，这点没问题。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1609975716,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":260275,"user_name":"贺","can_delete":false,"product_type":"c1","uid":1047983,"ip_address":"","ucode":"63FCE592EDABC5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/fd/af/ca57c38b.jpg","comment_is_top":false,"comment_ctime":1604974663,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"1604974663","product_id":100057401,"comment_content":"我看到tidb官方文档有说到它实现了可重复读隔离级别 https:&#47;&#47;www.bookstack.cn&#47;read&#47;pingcap-docs-cn&#47;sql-transaction-isolation.md<br>如果TiDB 没有设计全局事务列表，它是不是用了别的方式来实现了可重复读的隔离级别；比如通过时间戳的比较来判断两个事务的先后关系。","like_count":1,"discussions":[{"author":{"id":2250114,"avatar":"https://static001.geekbang.org/account/avatar/00/22/55/82/985411a8.jpg","nickname":"xyx","note":"","ucode":"1AECC9DDAC3D11","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":335268,"discussion_content":"tidb key都是按rowid(trx_row_id)排序的 所以实现rr 只需要在事务的开始时刻记住当时的事务id 只读取>=该id的key 相当于自带snapshot吧?","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1608132767,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1033945,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/c6/d9/9058e13c.jpg","nickname":"黄蓉 Jessie","note":"","ucode":"F3205D3B9172F0","race_medal":1,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":554769,"discussion_content":"tidb就是通过mvcc实现的可重复读隔离级别，参考官方文档https://docs.pingcap.com/zh/tidb/stable/tidb-storage#mvcc","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1646586134,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":246891,"user_name":"lovedebug","can_delete":false,"product_type":"c1","uid":1004115,"ip_address":"","ucode":"292FB1FD078AE8","user_header":"https://static001.geekbang.org/account/avatar/00/0f/52/53/a9918d0b.jpg","comment_is_top":false,"comment_ctime":1599524824,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1599524824","product_id":100057401,"comment_content":"老师，MVCC三种存储方式的实现可以再细讲一下吗","like_count":0},{"had_liked":false,"id":246654,"user_name":"piboye","can_delete":false,"product_type":"c1","uid":1066752,"ip_address":"","ucode":"7CFD8712857A85","user_header":"https://static001.geekbang.org/account/avatar/00/10/47/00/3202bdf0.jpg","comment_is_top":false,"comment_ctime":1599446816,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1599446816","product_id":100057401,"comment_content":"append time-tiva delta的实现原理没有仔细讲，所以还是有点懵？ ","like_count":0},{"had_liked":false,"id":246652,"user_name":"piboye","can_delete":false,"product_type":"c1","uid":1066752,"ip_address":"","ucode":"7CFD8712857A85","user_header":"https://static001.geekbang.org/account/avatar/00/10/47/00/3202bdf0.jpg","comment_is_top":false,"comment_ctime":1599446659,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1599446659","product_id":100057401,"comment_content":"全局事务管理器，可以认为是单一时间源不？这种情况下没有误差的问题。如果不是统一的事务id生成，那不同机器生成的事务id排序也可以约定一个规则，这样也可以保证一个顺序。时钟误差，会导致误差区间内，现实中先发起的事务去等待后发起的事务的情况。不知道这样理解对不？","like_count":0},{"had_liked":false,"id":246400,"user_name":"OliviaHu","can_delete":false,"product_type":"c1","uid":1505322,"ip_address":"","ucode":"7316E79FBFD5ED","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK0Qwib3PcoRRxTZSoxAdJ1hELibJeoEqSKP6Ksyu0e7MrGickk1COuv6oQ1w9W2kqM8gUg0Oj057UBw/132","comment_is_top":false,"comment_ctime":1599309265,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1599309265","product_id":100057401,"comment_content":"最近在做Oracle抽数到Hive，由于抽数Job会异常挂掉，重抽则会导致数据重复。<br>于是很苦恼。在《Spark实战训练营》中喵到了DeltaLake，才发现，诶，原来已经有人在着手解决事务问题了。<br>通过老师今天的讲述，也学到了Delta的真正含义，对Time Travel也有了更深的理解。<br>未来，无论SQL、NoSQL和NewSQL，都会变得越来越像吧。用户也不用苦恼和纠结于场景和选型。感觉上TiDB的发展方向就是想要集各家之所长。通过“策略”来帮助用户选择合适的引擎。恩恩，未来真得非常值得期待呢。","like_count":0},{"had_liked":false,"id":245859,"user_name":"游弋云端","can_delete":false,"product_type":"c1","uid":1208637,"ip_address":"","ucode":"A960E8F5AA25B9","user_header":"https://static001.geekbang.org/account/avatar/00/12/71/3d/da8dc880.jpg","comment_is_top":false,"comment_ctime":1599096137,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1599096137","product_id":100057401,"comment_content":"非独立存储与独立存储的差异老师能否再明确下？","like_count":0}]}