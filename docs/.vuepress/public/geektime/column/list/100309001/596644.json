{"id":596644,"title":"02｜缓存一致：读多写少时，如何解决数据更新缓存不同步？","content":"<p>你好，我是徐长龙，我们继续来看用户中心性能改造的缓存技巧。</p><p>上节课我们对数据做了归类整理，让系统的数据更容易做缓存。为了降低数据库的压力，接下来我们需要逐步给系统增加缓存。所以这节课，我会结合用户中心的一些业务场景，带你看看如何使用临时缓存或长期缓存应对高并发查询，帮你掌握高并发流量下缓存数据一致性的相关技巧。</p><p>我们之前提到过，互联网大多数业务场景的数据都属于读多写少，在请求的读写比例中，写的比例会达到百分之一，甚至千分之一。</p><p>而对于用户中心的业务来说，这个比例会更大一些，毕竟用户不会频繁地更新自己的信息和密码，所以这种读多写少的场景特别适合做读取缓存。通过缓存可以大大降低系统数据层的查询压力，拥有更好的并发查询性能。但是，使用缓存后往往会碰到更新不同步的问题，下面我们具体看一看。</p><h2>缓存性价比</h2><p>缓存可以滥用吗？在对用户中心优化时，一开始就碰到了这个有趣的问题。</p><p>就像刚才所说，我们认为用户信息放进缓存可以快速提高性能，所以在优化之初，我们第一个想到的就是将用户中心账号信息放到缓存。这个表有2000万条数据，主要用途是在用户登录时，通过用户提交的账号和密码对数据库进行检索，确认用户账号和密码是否正确，同时查看账户是否被封禁，以此来判定用户是否可以登录：</p><!-- [[[read_end]]] --><pre><code class=\"language-sql\"># 表结构\nCREATE TABLE `accounts` (\n  `id` int(10) unsigned NOT NULL AUTO_INCREMENT,\n  `account` varchar(15) NOT NULL DEFAULT '',\n  `password` char(32) NOT NULL,\n  `salt` char(16) NOT NULL,\n  `status` tinyint(3) NOT NULL DEFAULT '0'\n  `update_time` int(10) NOT NULL DEFAULT '0',\n  `create_time` int(10) NOT NULL DEFAULT '0',\n  PRIMARY KEY (`id`),\n) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;\n\n# 登录查询\nselect id, account, update_time from accounts \nwhere account = 'user1'\nand password = '6b9260b1e02041a665d4e4a5117cfe16'\nand status = 1\n</code></pre><p>这是一个很简单的查询，你可能会想：如果我们将2000万的用户数据放到缓存，肯定能提供性能很好的服务。</p><p>这个想法是对的，但不全对，因为它的性价比并不高：这个表查询的场景主要用于账号登录，用户即使频繁登录，也不会造成太大的流量冲击。因此，缓存在大部分时间是闲置状态，我们没必要将并发不高的数据放到缓存当中，浪费我们的预算。</p><p>这就牵扯到了一个很核心的问题，<strong>我们做缓存是要考虑性价比的</strong>。如果我们费时费力地把一些数据放到缓存当中，但并不能提高系统的性能，反倒让我们浪费了大量的时间和金钱，那就是不合适的。我们需要评估缓存是否有效，一般来说，只有热点数据放到缓存才更有价值。</p><h2>临时热缓存</h2><p>推翻将所有账号信息放到缓存这个想法后，我们把目标放到会被高频查询的信息上，也就是用户信息。</p><p>用户信息的使用频率很高，在很多场景下会被频繁查询展示，比如我们在论坛上看到的发帖人头像、昵称、性别等，这些都是需要频繁展示的数据，不过这些数据的总量很大，全部放入缓存很浪费空间。</p><p>对于这种数据，我建议使用临时缓存方式，就是在用户信息第一次被使用的时候，同时将数据放到缓存当中，短期内如果再次有类似的查询就可以快速从缓存中获取。这个方式能有效降低数据库的查询压力。常见方式实现的<strong>临时缓存</strong>的代码如下：</p><pre><code class=\"language-go\">// 尝试从缓存中直接获取用户信息\nuserinfo, err := Redis.Get(\"user_info_9527\")\nif err != nil {\n  return nil, err\n}\n\n//缓存命中找到，直接返回用户信息\nif userinfo != nil {\n  return userinfo, nil\n}\n\n//没有命中缓存，从数据库中获取\nuserinfo, err := userInfoModel.GetUserInfoById(9527)\nif err != nil {\n  return nil, err\n}\n\n//查找到用户信息\nif userinfo != nil {\n  //将用户信息缓存，并设置TTL超时时间让其60秒后失效\n  Redis.Set(\"user_info_9527\", userinfo, 60)\n  return userinfo, nil\n}\n\n// 没有找到，放一个空数据进去，短期内不再问数据库\n// 可选，这个是用来预防缓存穿透查询攻击的\nRedis.Set(\"user_info_9527\", \"\", 30)\nreturn nil, nil\n</code></pre><p>可以看到，我们的数据只是临时放到缓存，等待60秒过期后数据就会被淘汰，如果有同样的数据查询需要，我们的代码会将数据重新填入缓存继续使用。这种临时缓存适合表中数据量大，但热数据少的情况，可以降低热点数据的压力。</p><p>而之所以给缓存设置数据TTL，是为了节省我们的内存空间。当数据在一段时间内不被使用后就会被淘汰，这样我们就不用购买太大的内存了。这种方式相对来说有极高的性价比，并且维护简单，很常用。</p><h2>缓存更新不及时问题</h2><p>临时缓存是有TTL的，如果60秒内修改了用户的昵称，缓存是不会马上更新的。最糟糕的情况是在60秒后才会刷新这个用户的昵称缓存，显然这会给系统带来一些不必要的麻烦。其实对于这种缓存数据刷新，可以分成几种情况，不同情况的刷新方式有所不同，接下来我给你分别讲讲。</p><h3>1.单条实体数据缓存刷新</h3><p>单条实体数据缓存更新是最简单的一个方式，比如我们缓存了9527这个用户的info信息，当我们对这条数据做了修改，我们就可以在数据更新时同步更新对应的数据缓存：</p><pre><code class=\"language-go\">Type UserInfo struct {\n\tId         int    `gorm:\"column:id;type:int(11);primary_key;AUTO_INCREMENT\" json:\"id\"`\n\tUid        int    `gorm:\"column:uid;type:int(4);NOT NULL\" json:\"uid\"`\n\tNickName   string `gorm:\"column:nickname;type:varchar(32) unsigned;NOT NULL\" json:\"nickname\"`\n\tStatus     int16  `gorm:\"column:status;type:tinyint(4);default:1;NOT NULL\" json:\"status\"`\n\tCreateTime int64  `gorm:\"column:create_time;type:bigint(11);NOT NULL\" json:\"create_time\"`\n\tUpdateTime int64  `gorm:\"column:update_time;type:bigint(11);NOT NULL\" json:\"update_time\"`\n}\n\n//更新用户昵称\nfunc (m *UserInfo)UpdateUserNickname(ctx context.Context, name string, uid int) (bool, int64, error) {\n\t//先更新数据库\n  ret, err := m.db.UpdateUserNickNameById(ctx, uid, name)\n\tif ret {\n        //然后清理缓存，让下次读取时刷新缓存，防止并发修改导致临时数据进入缓存\n        //这个方式刷新较快，使用很方便，维护成本低\n\t\tRedis.Del(\"user_info_\" + strconv.Itoa(uid))\n\t}\n\treturn ret, count, err\n}\n\n</code></pre><p>整体来讲就是先识别出被修改数据的ID，然后根据ID删除被修改的数据缓存，等下次请求到来时，再把最新的数据更新到缓存中，这样就会有效减少并发操作把脏数据带入缓存的可能性。</p><p>除此之外，我们也可以给队列发更新消息让子系统更新，还可以开发中间件把数据操作发给子系统，自行决定更新的数据范围。</p><p>不过，通过队列更新消息这一步，我们还会碰到一个问题——条件批量更新的操作无法知道具体有多少个ID可能有修改，常见的做法是：先用同样的条件把所有涉及的ID都取出来，然后update，这时用所有相关ID更新具体缓存即可。</p><h3>2. 关系型和统计型数据缓存刷新</h3><p>关系型或统计型缓存刷新有很多种方法，这里我给你讲一些最常用的。</p><p>首先是<strong>人工维护缓存方式</strong>。我们知道，关系型数据或统计结果缓存刷新存在一定难度，核心在于这些统计是由多条数据计算而成的。当我们对这类数据更新缓存时，很难识别出需要刷新哪些<strong>关联</strong>缓存。对此，我们需要人工在一个地方记录或者定义特殊刷新逻辑来实现相关缓存的更新。</p><p><img src=\"https://static001.geekbang.org/resource/image/0a/cc/0a1ea9f053fa3c3cb8byy041d2070ecc.jpg?wh=1920x1234\" alt=\"图片\" title=\"人工维护缓存\"></p><p>不过这种方式比较精细，<strong>如果刷新缓存很多，那么缓存更新会比较慢，并且存在延迟</strong>。而且人工书写还需要考虑如何查找到新增数据关联的所有ID，因为新增数据没有登记在ID内，人工编码维护会很麻烦。</p><p>除了人工维护缓存外，还有一种方式就是通过<strong>订阅数据库来找到ID数据变化。</strong>如下图，我们可以使用Maxwell或Canal，对MySQL的更新进行监控。</p><p><img src=\"https://static001.geekbang.org/resource/image/48/7f/4833ec768edc882d4f081338e00aee7f.jpg?wh=1920x775\" alt=\"图片\" title=\"通过记录ID关系刷新缓存\"></p><p>这样变更信息会推送到Kafka内，我们可以根据对应的表和具体的SQL确认更新涉及的数据ID，然后根据脚本内设定好的逻辑对相 关key进行更新。例如用户更新了昵称，那么缓存更新服务就能知道需要更新user_info_9527这个缓存，同时根据配置找到并且删除其他所有相关的缓存。</p><p>很显然，这种方式的好处是能及时更新简单的缓存，同时核心系统会给子系统广播同步数据更改，代码也不复杂；缺点是复杂的关联关系刷新，仍旧需要通过人工写逻辑来实现。</p><p>如果我们表内的数据更新很少，那么可以采用<strong>版本号缓存设计</strong>。</p><p>这个方式比较狂放：一旦有任何更新，整个表内所有数据缓存一起过期。比如对user_info表设置一个key，假设是user_info_version，当我们更新这个表数据时，直接对 user_info_version 进行incr +1。而在写入缓存时，同时会在缓存数据中记录user_info_version的当前值。</p><p>当业务要读取user_info某个用户的信息的时候，业务会同时获取当前表的version。如果发现缓存数据内的版本和当前表的版本不一致，那么就会更新这条数据。但如果version更新很频繁，就会严重降低缓存命中率，所以这种方案适合更新很少的表。</p><p>当然，我们还可以对这个表做一个范围拆分，比如按ID范围分块拆分出多个version，通过这样的方式来减少缓存刷新的范围和频率。</p><p><img src=\"https://static001.geekbang.org/resource/image/b9/11/b97a93c01cc98e68a01d73b920115311.jpg?wh=1920x1234\" alt=\"图片\" title=\"版本号方式刷新缓存\"></p><p>此外，关联型数据更新还可以通过识别<strong>主要实体ID</strong>来刷新缓存。这要保证其他缓存保存的key也是主要实体ID，这样当某一条关联数据发生变化时，就可以根据主要实体ID对所有缓存进行刷新。这个方式的缺点是，我们的缓存要能够根据修改的数据反向找到它关联的主体ID才行。</p><p><img src=\"https://static001.geekbang.org/resource/image/3d/c1/3dfccf998db897ea07705621a06323c1.jpg?wh=1920x854\" alt=\"图片\" title=\"通过主要实体ID刷新缓存\"></p><p>最后，我再给你介绍一种方式：<strong>异步脚本遍历数据库刷新所有相关缓存</strong>。这个方式适用于两个系统之间同步数据，能够减少系统间的接口交互；缺点是删除数据后，还需要人工删除对应的缓存，所以更新会有延迟。但如果能配合订阅更新消息广播的话，可以做到准同步。</p><p><img src=\"https://static001.geekbang.org/resource/image/2c/c8/2cd645766ac43cf90aa5ddd5258898c8.jpg?wh=1920x811\" alt=\"图片\" title=\"遍历数据库刷新缓存\"></p><h2>长期热数据缓存</h2><p>到这里，我们再回过头看看之前的临时缓存伪代码，它虽然能解决大部分问题，但是请你想一想，当TTL到期时，<strong>如果大量缓存请求没有命中，透传的流量会不会打沉我们的数据库？</strong>这其实就是行业里常提到的缓存穿透问题，如果缓存出现大规模并发穿透，那么很有可能导致我们服务宕机。</p><p>所以，数据库要是扛不住平时的流量，我们就不能使用<strong>临时缓存</strong>的方式去设计缓存系统，只能用<strong>长期缓存</strong>这种方式来实现<strong>热点缓存</strong>，以此避免缓存穿透打沉数据库的问题。不过，要想实现长期缓存，就需要我们人工做更多的事情来保持缓存和数据表数据的一致性。</p><p>要知道，长期缓存这个方式自NoSQL兴起后才得以普及使用，主要原因在于长期缓存的实现和临时缓存有所不同，它要求我们的业务<strong>几乎完全不走数据库</strong>，并且服务运转期间所需的数据都要能在缓存中找到，同时还要保证使用期间缓存不会丢失。</p><p>由此带来的问题就是，我们需要知道缓存中具体有哪些数据，然后提前对这些数据进行预热。当然，如果数据规模较小，那我们可以考虑把全量数据都缓存起来，这样会相对简单一些。</p><p>为了加深理解，同时展示特殊技巧，下面我们来看一种“临时缓存+长期热缓存”的一个有趣的实现，这种方式会有小规模缓存穿透，并且代码相对复杂，不过总体来说成本是比较低的：</p><pre><code class=\"language-go\">// 尝试从缓存中直接获取用户信息\nuserinfo, err := Redis.Get(\"user_info_9527\")\nif err != nil {\n  return nil, err\n}\n\n//缓存命中找到，直接返回用户信息\nif userinfo != nil {\n  return userinfo, nil\n}\n\n//set 检测当前是否是热数据\n//之所以没有使用Bloom Filter是因为有概率碰撞不准\n//如果key数量超过千个，建议还是用Bloom Filter\n//这个判断也可以放在业务逻辑代码中，用配置同步做\nisHotKey, err := Redis.SISMEMBER(\"hot_key\", \"user_info_9527\")\nif err != nil {\n  return nil, err\n}\n\n//如果是热key\nif isHotKey {\n  //没有找到就认为数据不存在\n  //可能是被删除了\n  return \"\", nil\n}\n\n//没有命中缓存，并且没被标注是热点，被认为是临时缓存，那么从数据库中获取\n//设置更新锁set user_info_9527_lock nx ex 5\n//防止多个线程同时并发查询数据库导致数据库压力过大\nlock, err := Redis.Set(\"user_info_9527_lock\", \"1\", \"nx\", 5)\nif !lock {\n  //没抢到锁的直接等待1秒 然后再拿一次结果，类似singleflight实现\n  //行业常见缓存服务，读并发能力很强，但写并发能力并不好\n  //过高的并行刷新会刷沉缓存\n  time.sleep( time.second)\n  //等1秒后拿数据，这个数据是抢到锁的请求填入的\n  //通过这个方式降低数据库压力\n  userinfo, err := Redis.Get(\"user_info_9527\")\n  if err != nil {\n    return nil, err\n  }\n  return userinfo,nil\n}\n\n//拿到锁的查数据库，然后填入缓存\nuserinfo, err := userInfoModel.GetUserInfoById(9527)\nif err != nil {\n  return nil, err\n}\n\n//查找到用户信息\nif userinfo != nil {\n  //将用户信息缓存，并设置TTL超时时间让其60秒后失效\n  Redis.Set(\"user_info_9527\", userinfo, 60)\n  return userinfo, nil\n}\n\n// 没有找到，放一个空数据进去，短期内不再问数据库\nRedis.Set(\"user_info_9527\", \"\", 30)\nreturn nil, nil\n</code></pre><p>可以看到，这种方式是长期缓存和临时缓存的混用。当我们要查询某个用户信息时，如果缓存中没有数据，长期缓存会直接返回没有找到，临时缓存则直接走更新流程。此外，我们的用户信息如果属于热点key，并且在缓存中找不到的话，就直接返回数据不存在。</p><p>在更新期间，为了防止高并发查询打沉数据库，我们将更新流程做了简单的singleflight（请求合并）优化，只有先抢到缓存更新锁的线程，才能进入后端读取数据库并将结果填写到缓存中。而没有抢到更新锁的线程先 sleep 1秒，然后直接读取缓存返回结果。这样可以保证后端不会有多个线程读取同一条数据，从而冲垮缓存和数据库服务（缓存的写并发没有读性能那么好）。</p><p>另外，hot_key列表（也就是长期缓存的热点key列表）会在多个Redis中复制保存，如果要读取它，随机找一个分片就可以拿到全量配置。</p><p>这些热缓存key，来自于统计一段时间内数据访问流量，计算得出的热点数据。那长期缓存的更新会异步脚本去定期扫描热缓存列表，通过这个方式来主动推送缓存，同时把TTL设置成更长的时间，来保证新的热数据缓存不会过期。当这个key的热度过去后，热缓存key就会从当前set中移除，腾出空间给其他地方使用。</p><p>当然，如果我们拥有一个很大的缓存集群，并且我们的数据都属于热数据，那么我们大可以脱离数据库，将数据都放到缓存当中直接对外服务，这样我们将获得更好的吞吐和并发。</p><p>最后，还有一种方式来缓解热点高并发查询，在每个业务服务器上部署一个小容量的Redis来保存热点缓存数据，通过脚本将热点数据同步到每个服务器的小Redis上，每次查询数据之前都会在本地小Redis查找一下，如果找不到再去大缓存内查询，通过这个方式缓解缓存的读取性能。</p><h2>总结</h2><p>通过这节课，我希望你能明白：不是所有的数据放在缓存就能有很好的收益，我们要从<strong>数据量</strong>、<strong>使用频率</strong>、<strong>缓存命中率</strong>三个角度去分析。读多写少的数据做缓存虽然能降低数据层的压力，但要根据一致性需求对其缓存的数据做更新。其中，单条实体数据最容易实现缓存更新，但是有条件查询的统计结果并不容易做到实时更新。</p><p>除此之外，如果数据库承受不了透传流量压力，我们需要将一些热点数据做成<strong>长期缓存</strong>，来防止大量请求穿透缓存，这样会影响我们的服务稳定。同时通过singleflight方式预防临时缓存被大量请求穿透，以防热点数据在从临时缓存切换成热点之前，击穿缓存，导致数据库崩溃。</p><p>读多写少的缓存技巧我还画了一张导图，如下所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/1f/cc/1f6bfb4a04342fbedc254a817e577dcc.jpg?wh=3330x2141\" alt=\"\"></p><h2>思考题</h2><p>1.使用Bloom Filter识别热点key时，有时会识别失误，进而导致数据没有找到，那么如何避免这种情况呢？</p><p>2.使用Bloom Filter只能添加新key，不能删除某一个key，如果想更好地更新维护，有什么其他方式吗？</p><p>欢迎你在留言区与我交流讨论，我们下节课见！</p>","neighbors":{"left":{"article_title":"01｜结构梳理：大并发下，你的数据库表可能成为性能隐患","id":595679},"right":{"article_title":"03｜Token：如何降低用户身份鉴权的流量压力？","id":597664}},"comments":[{"had_liked":false,"id":360693,"user_name":"peter","can_delete":false,"product_type":"c1","uid":1058183,"ip_address":"北京","ucode":"261C3FC001DE2D","user_header":"https://static001.geekbang.org/account/avatar/00/10/25/87/f3a69d1b.jpg","comment_is_top":true,"comment_ctime":1666764447,"is_pvip":true,"replies":[{"id":"131231","content":"你好，peter，又见面了，感谢你的留言～<br>Q1:由于我们的大多数数据都是有时效性的，我们很少去做永久的内存缓存，毕竟内存还是很贵的，我们需要考虑性价比。长期缓存可以是一天，临时TTL是30秒。同时长期的更新是定期脚本刷新，临时是用到才会放进去一会儿。再来看，长期的访问很频繁，如果放开会导致数据库压力很大，但是临时的由于访问量小所以不用特意防击穿。<br>Q2:如果缓存压力不大可以用一个，如果很大会再做个L1缓存，在每台业务服务器上，这样能缓解核心缓存压力。<br>Q3：这个属于人工写代码，如我更新了用户的昵称，那么我会刷新这个用户的所有帖子的缓存，以及这个用户的所有最近留言缓存，以及这个用户的个人信息缓存。这是一种，还有一种就是你说的界面配置规则，但是这些都是要能快速定位的才可以。你可能会碰到，用户昵称以rick开头的账号有多少个，当我们改昵称为这个的时候，对于这种条件多样的，刷新哪个缓存不好确定，只能临时缓存30秒等他过期后刷新","user_name":"作者回复","user_name_real":"作者","uid":"1004527","ctime":1666781242,"ip_address":"北京","comment_id":360693,"utype":1}],"discussion_count":1,"race_medal":0,"score":"9.2233720514063995e+18","product_id":100309001,"comment_content":"请教老师几个问题：<br>Q1：缓存都是有超时时间的，从这个意义上说，都是“临时”的，为什么本文还要分为“临时”缓存和“长期”缓存？<br>Q2：“临时”缓存和“长期”缓存在实现上可以用同一个软件吗？<br>比如，两者都可以用Redis实现？或者，“临时缓存”是用一个组件实现（非Redis）而“长期缓存”用Redis实现？ 或者，“临时缓存”在代码中实现而“长期缓存”用Redis？<br>Q3：人工维护缓存，怎么操作？<br>缓存数据一般都比较多，人工怎么能够维护一堆数据？具体是怎么操作的？ 有一个界面，通过此界面来操作吗？","like_count":3,"discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":591730,"discussion_content":"你好，peter，又见面了，感谢你的留言～\nQ1:由于我们的大多数数据都是有时效性的，我们很少去做永久的内存缓存，毕竟内存还是很贵的，我们需要考虑性价比。长期缓存可以是一天，临时TTL是30秒。同时长期的更新是定期脚本刷新，临时是用到才会放进去一会儿。再来看，长期的访问很频繁，如果放开会导致数据库压力很大，但是临时的由于访问量小所以不用特意防击穿。\nQ2:如果缓存压力不大可以用一个，如果很大会再做个L1缓存，在每台业务服务器上，这样能缓解核心缓存压力。\nQ3：这个属于人工写代码，如我更新了用户的昵称，那么我会刷新这个用户的所有帖子的缓存，以及这个用户的所有最近留言缓存，以及这个用户的个人信息缓存。这是一种，还有一种就是你说的界面配置规则，但是这些都是要能快速定位的才可以。你可能会碰到，用户昵称以rick开头的账号有多少个，当我们改昵称为这个的时候，对于这种条件多样的，刷新哪个缓存不好确定，只能临时缓存30秒等他过期后刷新","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1666781242,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京"},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":360820,"user_name":"Daniel","can_delete":false,"product_type":"c1","uid":1020529,"ip_address":"北京","ucode":"282E09B3146501","user_header":"https://static001.geekbang.org/account/avatar/00/0f/92/71/9fd7cd7a.jpg","comment_is_top":true,"comment_ctime":1666875528,"is_pvip":true,"replies":[{"id":"131283","content":"你好，Daniel，很高兴收到你的留言<br><br>第一种方法，如果使用集合检测也可以达到同样效果，你提到的方法缺陷在于not_hotkey会很大，这里需要记录所有不是hot key的所有key。目前bloomfilter只是个模糊筛选，用小量数据换更好的性能，但是他确实误判概率多一些。<br><br>第二个问题也是一个办法，但是需要我们能够精准控制这一批数据过期时间，但是我们在这节课用它主要是为了判断本地缓存中是否有这个缓存，由于无法判断所以需要每次询问，会导致系统更加复杂。<br><br>第三个问题 主要是访问量，我们可以将一些key 做一些count统计，数据埋点就足够了，机器学习和深度学习的QPS有些低，我印象里，一个1w元的显卡做发音评分，一秒钟只能处理4个请求，场景不太适合，有点小才大用了。","user_name":"作者回复","user_name_real":"编辑","uid":"1004527","ctime":1666941201,"ip_address":"北京","comment_id":360820,"utype":1}],"discussion_count":3,"race_medal":0,"score":"9.2233720428166001e+18","product_id":100309001,"comment_content":"1. 使用 Bloom Filter 识别热点 key 时，有时会识别失误，进而导致数据没有找到，那么如何避免这种情况呢？<br><br>通过我的 “机器学习的经验”，我觉得是这个布隆过滤器的哈希算法有点过拟合了，也就是说容错率高了，在资金充足的情况下先试着调低“容错率“(超参数)提升容量试试（不知道工业界上布隆过滤器的容错率能设置成 0%吗？但后期可能随着数据量的增长也是一个无限扩容的”吞金兽“呀），但我感觉我这个想法在工业界应该不成立。<br><br>第二种方法，我想到的是，如果这个 key 被误识别为”hotkey”的话，就在内存中记入“not_hotkey”列表，每次数据进来的时候，先用 缓存里的 not_hotkey里的列表来筛，要是不是hotkey就做成临时缓存，要是这个key是hotkey的话，就进行长期缓存来处理。<br><br><br>2. 使用 Bloom Filter 只能添加新 key，不能删除某一个 key，如果想更好地更新维护，有什么其他方式吗？<br><br>对于长时间不用的 key ，我认为可以设置一个“失效时间”，比如 一周内不用，就自动清除掉这个key。<br>之后在新的一周，把失效的key清理出去，再重新整理好一个列表，重新更新一遍这个布隆过滤器的新的哈希算法表。<br>（但感觉这个方法貌似不是最优的，也要在半夜用户量访问少的时间点去做变更处理）<br><br><br>老师想请教一个问题，对于 hotkey （热点数据）这个工业界的评价标准是不是不同行业会不一样呀？<br>比较想知道工业界上是用什么方法（一般统计方法？机器学习聚类？深度学习网络？）和工具（数据埋点？用户操作行为分析？），来做 “热点数据”的 判别的？ ","like_count":1,"discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":591934,"discussion_content":"你好，Daniel，很高兴收到你的留言\n\n第一种方法，如果使用集合检测也可以达到同样效果，你提到的方法缺陷在于not_hotkey会很大，这里需要记录所有不是hot key的所有key。目前bloomfilter只是个模糊筛选，用小量数据换更好的性能，但是他确实误判概率多一些。\n\n第二个问题也是一个办法，但是需要我们能够精准控制这一批数据过期时间，但是我们在这节课用它主要是为了判断本地缓存中是否有这个缓存，由于无法判断所以需要每次询问，会导致系统更加复杂。\n\n第三个问题 主要是访问量，我们可以将一些key 做一些count统计，数据埋点就足够了，机器学习和深度学习的QPS有些低，我印象里，一个1w元的显卡做发音评分，一秒钟只能处理4个请求，场景不太适合，有点小才大用了。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1666941202,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京"},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":2,"child_discussions":[{"author":{"id":1020529,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/92/71/9fd7cd7a.jpg","nickname":"Daniel","note":"","ucode":"282E09B3146501","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":591970,"discussion_content":"看了老师的评论，感觉老师的实战经验是真丰富呀，👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1666960019,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":591934,"ip_address":"海南"},"score":591970,"extra":""},{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":1020529,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/92/71/9fd7cd7a.jpg","nickname":"Daniel","note":"","ucode":"282E09B3146501","race_medal":0,"user_type":1,"is_pvip":true},"discussion":{"id":592262,"discussion_content":"多多交流，拱手","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1667266849,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":591970,"ip_address":"北京"},"score":592262,"extra":""}]}]},{"had_liked":false,"id":360716,"user_name":"Elvis Lee","can_delete":false,"product_type":"c1","uid":2098270,"ip_address":"北京","ucode":"A4B26AFFE817FA","user_header":"https://static001.geekbang.org/account/avatar/00/20/04/5e/5d2e6254.jpg","comment_is_top":false,"comment_ctime":1666777540,"is_pvip":true,"replies":[{"id":"131229","content":"你好，Elvis Lee，很高兴收到你的留言，不建议这样使用bloomfilter，主要原因在于，他的识别和md5计算结果一样，有的时候不同的key返回的结果是一致的，所以这样是拿不到准确结果的。","user_name":"作者回复","user_name_real":"编辑","uid":"1004527","ctime":1666780674,"ip_address":"北京","comment_id":360716,"utype":1}],"discussion_count":4,"race_medal":0,"score":"10256712132","product_id":100309001,"comment_content":"1. 使用 Bloom Filter 识别热点 key 时，有时会识别失误，进而导致数据没有找到，那么如何避免这种情况呢？<br>布隆可以判断一定不存在的数据，那么是否可以认为，只要插入不成功，即为热数据，但在设计布隆的时候需要根据业务来设置好容量和容错率。同时布隆删除操作在生产上不建议，最好是持久化后用版本号去区分。如果是离线链路，更推荐生成布隆文件，推送去客户端。实时的,目前接触是保存在Redis,Redis7的版本好像已经不需要插件","like_count":2,"discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":591726,"discussion_content":"你好，Elvis Lee，很高兴收到你的留言，不建议这样使用bloomfilter，主要原因在于，他的识别和md5计算结果一样，有的时候不同的key返回的结果是一致的，所以这样是拿不到准确结果的。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1666780674,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京"},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2098270,"avatar":"https://static001.geekbang.org/account/avatar/00/20/04/5e/5d2e6254.jpg","nickname":"Elvis Lee","note":"","ucode":"A4B26AFFE817FA","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":591835,"discussion_content":"个人觉得因为布隆是有一定容错性，所以布隆只能做到部分拦截。\n数据量从小到大的解决：数据库&lt;本地缓存&lt;Redis&lt;布隆\n暂时没有想到其他方式，请老师指点","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1666853986,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"上海"},"score":2,"extra":"","child_discussion_number":2,"child_discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":2098270,"avatar":"https://static001.geekbang.org/account/avatar/00/20/04/5e/5d2e6254.jpg","nickname":"Elvis Lee","note":"","ucode":"A4B26AFFE817FA","race_medal":0,"user_type":1,"is_pvip":true},"discussion":{"id":591944,"discussion_content":"cuckoo filter","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1666946377,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":591835,"ip_address":"北京"},"score":591944,"extra":""},{"author":{"id":2098270,"avatar":"https://static001.geekbang.org/account/avatar/00/20/04/5e/5d2e6254.jpg","nickname":"Elvis Lee","note":"","ucode":"A4B26AFFE817FA","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":592440,"discussion_content":"谢谢老师解答","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1667404651,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":591944,"ip_address":"上海"},"score":592440,"extra":""}]}]},{"had_liked":false,"id":360692,"user_name":"传输助手","can_delete":false,"product_type":"c1","uid":1128987,"ip_address":"北京","ucode":"E81A629D2E565E","user_header":"https://static001.geekbang.org/account/avatar/00/11/3a/1b/ca87cde9.jpg","comment_is_top":false,"comment_ctime":1666764059,"is_pvip":false,"replies":[{"id":"131221","content":"你好，传输助手，很高兴收到你的留言，这里有一个前提，就是我们加缓存的服务基本都是读并发高的服务，对于MySQL主库来说，问题就是全局只有一个主库，所以他是单点，同时更脆弱，理论上这种读压力尽量不要压到主库上～","user_name":"作者回复","user_name_real":"编辑","uid":"1004527","ctime":1666771965,"ip_address":"北京","comment_id":360692,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10256698651","product_id":100309001,"comment_content":"读取数据库设置缓存的时候，为了不受数据库主从延迟的影响，是不是需要强制读主库？","like_count":2,"discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":591706,"discussion_content":"你好，传输助手，很高兴收到你的留言，这里有一个前提，就是我们加缓存的服务基本都是读并发高的服务，对于MySQL主库来说，问题就是全局只有一个主库，所以他是单点，同时更脆弱，理论上这种读压力尽量不要压到主库上～","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1666771965,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京"},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":361342,"user_name":"一步","can_delete":false,"product_type":"c1","uid":1005391,"ip_address":"北京","ucode":"73CEA468CE70C3","user_header":"https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg","comment_is_top":false,"comment_ctime":1667441053,"is_pvip":true,"replies":[{"id":"131428","content":"你好，很高兴收到你的回复，没错！确实Cuckoo Filter能够解决所有问题！同时补充提醒：他也有一些缺点使用的时候要注意，性能没有bf高，同时删除存在误删情况～","user_name":"作者回复","user_name_real":"编辑","uid":"1004527","ctime":1667447071,"ip_address":"北京","comment_id":361342,"utype":1}],"discussion_count":1,"race_medal":1,"score":"1667441053","product_id":100309001,"comment_content":"1. Bloom Filter 存在误报，会把不是热点的 key 识别成热点key, 所以需要一个 0误报的算法，数据结构 所以 Cuckoo Filter 布谷鸟过滤器来了<br>2. 可以定期或者其他策略 重新构造 Bloom Filter<br><br>&gt; 其实上面的2个问题，都可以使用 Cuckoo Filter 来解决","like_count":0,"discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":592494,"discussion_content":"你好，很高兴收到你的回复，没错！确实Cuckoo Filter能够解决所有问题！同时补充提醒：他也有一些缺点使用的时候要注意，性能没有bf高，同时删除存在误删情况～","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1667447071,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京"},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":361182,"user_name":"SunshineBoy","can_delete":false,"product_type":"c1","uid":1160644,"ip_address":"北京","ucode":"FC54CD1815CCBA","user_header":"https://static001.geekbang.org/account/avatar/00/11/b5/c4/9148b40d.jpg","comment_is_top":false,"comment_ctime":1667296369,"is_pvip":false,"replies":[{"id":"131364","content":"你好，建议对象存储配合cdn缓存实现","user_name":"作者回复","user_name_real":"编辑","uid":"1004527","ctime":1667304656,"ip_address":"北京","comment_id":361182,"utype":1}],"discussion_count":3,"race_medal":0,"score":"1667296369","product_id":100309001,"comment_content":"哈喽 大佬 redis适合做app中一级、二级页面降级方案的存储吗？如果存储的value比较大，有没有推荐的降级方案？","like_count":0,"discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":592320,"discussion_content":"你好，建议对象存储配合cdn缓存实现","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1667304656,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京"},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":2,"child_discussions":[{"author":{"id":1160644,"avatar":"https://static001.geekbang.org/account/avatar/00/11/b5/c4/9148b40d.jpg","nickname":"SunshineBoy","note":"","ucode":"FC54CD1815CCBA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":592370,"discussion_content":"老师，app每个页面聚合了很多基础服务接口，这些接口性能比较差，经常挂，所以把基础服务数据缓存下来。这些数据有分发策略，不同的用户看到的用户数据是不一样的数据，想做到server基础服务挂了用户无感知，想在server聚合层做降级方案，既想要服务可用性，也想要数据一致性。现在是把整个页面的动态数据做了一个大value，存储到redis，瓶颈是一到高峰期会出现codis链接池打满，即使扩容，后续qps增长还是会出现这种情况。看了老师的文章，也觉得方案不合理。对于这块，老师有什么好的想法？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1667359300,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":592320,"ip_address":"北京"},"score":592370,"extra":""},{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":1160644,"avatar":"https://static001.geekbang.org/account/avatar/00/11/b5/c4/9148b40d.jpg","nickname":"SunshineBoy","note":"","ucode":"FC54CD1815CCBA","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":592539,"discussion_content":"数据拼合可以不在业务接口上做，可以参考下go的BFF设计，通过这个方式将多个接口数据并行聚合起来，然后展示给用户","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1667470506,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":592370,"ip_address":"北京"},"score":592539,"extra":""}]}]},{"had_liked":false,"id":360947,"user_name":"Sky","can_delete":false,"product_type":"c1","uid":1392585,"ip_address":"北京","ucode":"4C5A5AB73E8B90","user_header":"https://static001.geekbang.org/account/avatar/00/15/3f/c9/1ccefb9a.jpg","comment_is_top":false,"comment_ctime":1667022972,"is_pvip":false,"replies":[{"id":"131313","content":"你好，sky，很高兴收到你的留言，这样数据库压力会更大，这时需要特殊做，后续会讲到强一致怎么做","user_name":"作者回复","user_name_real":"编辑","uid":"1004527","ctime":1667043768,"ip_address":"北京","comment_id":360947,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1667022972","product_id":100309001,"comment_content":"在更新期间，为了防止高并发查询打沉数据库，我们将更新流程做了简单的 singleflight（请求合并）优化，只有先抢到缓存更新锁的线程，才能进入后端读取数据库并将结果填写到缓存中。而没有抢到更新锁的线程先 sleep 1 秒，然后直接读取缓存返回结果。这样可以保证后端不会有多个线程读取同一条数据，从而冲垮缓存和数据库服务（缓存的写并发没有读性能那么好）。<br><br>并发更新的时候，为了防止超卖等问题，是不是最好还要在sql中加上乐观锁CAS？","like_count":0,"discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":592043,"discussion_content":"你好，sky，很高兴收到你的留言，这样数据库压力会更大，这时需要特殊做，后续会讲到强一致怎么做","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1667043769,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京"},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":360908,"user_name":"不吃包子","can_delete":false,"product_type":"c1","uid":2269341,"ip_address":"北京","ucode":"5E0661EC355ED9","user_header":"","comment_is_top":false,"comment_ctime":1666964023,"is_pvip":false,"replies":[{"id":"131315","content":"你好，不吃包子，很高兴收到你的留言，布谷鸟过滤器是一个不错的解决方案，另外查找不到缓存空也不错～","user_name":"作者回复","user_name_real":"编辑","uid":"1004527","ctime":1667044793,"ip_address":"北京","comment_id":360908,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1666964023","product_id":100309001,"comment_content":"针对1.2的问题，<br>搜索到了如下解决方案： 调整布隆过滤器参数或者用布谷鸟过滤器。<br>我想说说我自己的看法，针对误判的情况，能不能再加一层缓存？比如说一个数据被误判为有，则去查询数据库了，这个时候为空，记到缓存里面，如果下次再访问该数据的时候，直接从缓存返回。针对问题2 同样也维护一个删除的缓存。","like_count":0,"discussions":[{"author":{"id":1004527,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/53/ef/5cdaa18b.jpg","nickname":"thinkpc","note":"","ucode":"0EBF75B8707584","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":592047,"discussion_content":"你好，不吃包子，很高兴收到你的留言，布谷鸟过滤器是一个不错的解决方案，另外查找不到缓存空也不错～","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1667044793,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京"},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3214843,"avatar":"https://static001.geekbang.org/account/avatar/00/31/0d/fb/a5fef3f7.jpg","nickname":"移横为固","note":"","ucode":"ECA3065E8485B0","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":592527,"discussion_content":"架构领域里有一句几乎是最著名的话：没有什么架构问题是加一层解决不了的，如果不行就再加一层。再加2层布隆过滤器","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1667464794,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"浙江"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":360903,"user_name":"门窗小二","can_delete":false,"product_type":"c1","uid":1006424,"ip_address":"北京","ucode":"0BF3780C247F22","user_header":"","comment_is_top":false,"comment_ctime":1666958282,"is_pvip":true,"replies":[{"id":"131292","content":"建议先自己尝试回答，课后题答案后续看回答情况再公布。","user_name":"编辑回复","user_name_real":"编辑","uid":"1501385","ctime":1667011334,"ip_address":"北京","comment_id":360903,"utype":2}],"discussion_count":1,"race_medal":0,"score":"1666958282","product_id":100309001,"comment_content":"老师！但是课后题有答疑篇吗？","like_count":0,"discussions":[{"author":{"id":1501385,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e8/c9/59bcd490.jpg","nickname":"听水的湖","note":"","ucode":"B1759F90165D81","race_medal":0,"user_type":8,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":591992,"discussion_content":"建议先自己尝试回答，课后题答案后续看回答情况再公布。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1667011335,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京"},"score":2,"extra":"{\"reply\":true,\"user_type\":8}","child_discussion_number":0,"child_discussions":[]}]}]}