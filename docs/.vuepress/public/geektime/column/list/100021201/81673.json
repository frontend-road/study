{"id":81673,"title":"26 | 信息熵：如何通过几个问题，测出你对应的武侠人物？","content":"<p>你好，我是黄申。</p><p>之前和你聊了概率在朴素贝叶斯分类算法中的应用。其实，概率在很多像信息论这样的应用数学领域都有广泛的应用。信息论最初就是运用概率和统计的方法，来研究信息传递的。最近几十年，人们逐步开始使用信息论的概念和思想，来描述机器学习领域中的概率分布，并衡量概率分布之间的相似性。随之而来的是，人们发明了不少相关的机器学习算法。所以接下来的几节，我来介绍一些基于信息论知识的内容。</p><p>信息论的概念比较枯燥，为了让你更轻松地学习，让我从一个生动的案例开始。最近我在朋友圈看到一个小游戏，叫“测一测你是金庸笔下的哪个人物？”。玩这个游戏的步骤是，先做几道题，然后根据你的答案，生成对应的结果。下面是我几位朋友答题之后得到的结果。</p><p><img src=\"https://static001.geekbang.org/resource/image/55/f1/55ea8faffde5fd7450518903b9d3f3f1.jpeg?wh=1920*2349\" alt=\"\"></p><p>这种测试挺好玩的，而且好像有很多类似的，比如测星座啊、测运势啊等等。那你知道这种心理或者性格测试的题目是怎么设计的吗？</p><p>通常，这种心理测试会有一个题库，包含了许多小题目，也就是从不同的方面，来测试人的性格。不过，针对特定的测试目标，我们可能没必要让被测者回答所有的问题。那么，问卷设计者应该如何选择合适的题目，才能在读者回答尽量少的问题的同时，相对准确地测出自己是什么“性格”呢？这里，我们就需要引入基于概率分布的信息熵的概念，来解决这个问题。</p><!-- [[[read_end]]] --><h2>什么是信息熵？</h2><p>我还是拿刚刚那个“测测你是哪个武侠人物”的小游戏举例子。我设计了一个测试题，你可以看看下面这个图表。这个表里一共有10个人物。每个人物都有性别、智商、情商、侠义和个性共5个属性。相应地，我会设计5道题目分别测试这5个属性所占的比例。最后，将测出的5个属性和答案中的武侠人物对照，就可以找到最接近的答案，也就是被测者对应的武侠人物。</p><p><img src=\"https://static001.geekbang.org/resource/image/40/93/40a23d486077a05edd6dd7f308fb1193.png?wh=1266*688\" alt=\"\"></p><p>这个过程非常简单，你应该很容易就能理解。在这个设计过程中，起决定性作用的环节其实就是，如何设计这5道题目。比如，题目的先后顺序会不会直接影响要回答问题的数量？每个问题在人物划分上，是否有着不同的区分能力？这些都是信息熵要解决的问题。</p><p>我们先来看，这里的<strong>区分能力</strong>指的是什么呢？每一个问题都会将被测试者划分为不同的人物分组。如果某个问题将属于不同人物分组的被测者，尽可能地划分到了相应的分组，那么我们认为这个问题的<strong>区分能力较强。<strong>相反，如果某个问题无法将属于不同人物分组的被测者划分开来，那么我们认为这个问题的</strong>区分能力较弱</strong>。为了帮你进一步理解，我们先来比较一下“性别”和“智商”这两个属性。</p><p><img src=\"https://static001.geekbang.org/resource/image/8d/f3/8d79a177252ded1ca2bacc392e3471f3.png?wh=716*428\" alt=\"\"><img src=\"https://static001.geekbang.org/resource/image/ca/0b/caf124bd2df93a642b2e83404562d60b.png?wh=728*428\" alt=\"\"></p><p>首先，性别属性将武侠人物平均地划分为一半一半，也就是说“男”和“女”出现的先验概率是各50%。如果我们假设被测试的人群，其男女性别的概率分布也是50%和50%，那么关于性别的测试题，就能将被测者的群体大致等分。</p><p>我们再来看智商属性。我们也将武侠人物划分为2个小集合，不过“智商高”的先验概率是80%，而“智商中等”的先验概率只有20%。同样，我们假设被测试的人群，其智商的概率分布也是类似地，那么经过关于智商的测试题之后，仍然有80%左右的不同人物还是属于同一个集合，并没有被区分开来。因此，我们可以认为关于“智商”的测试题，在对人物进行分组这个问题上，其能力要弱于“性别”的测试题。</p><p>上述这些是不是都很简单？这些都是我们按照感觉，或者说经验来划分的。现在，我们试着用两个科学的度量指标，<strong>信息熵</strong>（Entropy）和<strong>信息增益</strong>（Information Gain），来衡量每道题目的区分能力。</p><p>首先，怎么来理解信息熵呢？信息熵，我们通常简称为熵，其实就是用来刻画给定集合的<strong>纯净度</strong>的一个指标。你可能要问了，那纯净度是啥呢？我举个例子给你解释一下。比如说，一个集合里的元素全部是属于同一个分组，这个时候就表示最纯净，我们就说熵为0；如果这个集合里的元素是来自不同的分组，那么熵是大于0的值。其具体的计算公式如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/f9/c0/f9da465b8601bb84b97022afd88cbac0.png?wh=568*136\" alt=\"\"></p><p>其中，$n$表示集合中分组的数量，$p_{i}$表示属于第$i$个分组的元素在集合中出现的概率。</p><p>你可能要问了，这个公式是怎么来的呢？想要解释这个，我们还要从<strong>信息量</strong>说起。熵的公式是用来计算某个随机变量的信息量之期望，而信息量是信息论中的一个度量，简单来说就是，当我们观察到某个随机变量的具体值时，接收到了多少信息。而我们接收到的信息量跟发生事件的概率有关。事情发生的概率越大，产生的信息量越小；事情发生的概率越小，产生的信息量越大。</p><p>因此，我们想要设计一个能够描述信息量的函数，就要同时考虑到下面这三个特点：</p><ul>\n<li>\n<p>信息量应该为正数；</p>\n</li>\n<li>\n<p>一个事件的信息量和它发生的概率成反比；</p>\n</li>\n<li>\n<p>$H(x)$与$P(x)$的对数有关。其中$H(x)$表示$x$的信息量，$P(x)$表示$x$出现的概率。假设有两个不相关的事件$x$和$y$，我们观察到这两个事件同时发生时获得的信息量，应该等于这两个事件各自发生时获得的信息量之和，用公式表达出来就是$H(x,y)=H(x)+H(y)$。之前我们说过，如果$x，y$是两个不相关的事件，那么就有$P(x,y)=P(x)*P(y)$。</p>\n</li>\n</ul><p>依照上述这三点，我们可以设计出信息量公式：$H(x)=-log(P(x), 2)$。函数log的使用是体现了$H(x)$和$P(x)$的对数关系（我们可以使用其他大于1的数字作为对数的底，我这里使用2只是约定俗成。而最开始的负号是为了保证信息量为正）。这个公式可以量化随机变量某种取值时，所产生的信息量。最后，加上计算随机变量不同可能性所产生的信息量之期望，我们就得到了熵的公式。</p><p>从集合和分组的角度来说，如果一个集合里的元素趋向于落在同一分组里，那么告诉你某个元素属于哪个分组的信息量就越小，整个集合的熵也越小，换句话说，整个集合就越“纯净”。相反，如果一个集合里的元素趋向于分散在不同分组里，那么告诉你某个元素属于哪个分组的信息量就越大，整个集合的熵也越大，换句话说，整个集合就越“混乱”。</p><p>为了帮你理解运用，这里我再举几个例子帮助你更好地消化这个公式。我们首先来看一个集合，它只包含了来自A组的元素。</p><p><img src=\"https://static001.geekbang.org/resource/image/f4/5e/f44a38aaf3b1685bd8532618dcd0b75e.png?wh=564*518\" alt=\"\"></p><p>那么集合中分组的数量$n$为1，A分组的元素在集合中出现的概率为100%，所以这个集合的熵为-100%*log(100%, 2) = 0。</p><p>我们再来看另一个集合，它只包含了来自A组和B组的元素，其中A、B两组元素数量一样多，各占一半。</p><p><img src=\"https://static001.geekbang.org/resource/image/9f/6d/9f05be8a2b461f376d8e22356c9df06d.png?wh=604*556\" alt=\"\"></p><p>那么集合中分组的数量$n$为2，A和B分组的元素在集合中出现的概率各为50%，所以这个集合的熵为2*(-50%*log(50%, 2)) = 1，高于刚才那个集合。</p><p>从上述两个集合的对比可以看出，一个集合中所包含的分组越多、元素在这些分组里分布得越均匀，熵值也越大。而熵值表示了纯净的程度，或者从相反的角度来说，是混乱的程度。</p><p>好了，你已经知道单个集合的熵是如何计算的了。那么，如果将一个集合划分成多个更小的集合之后，又该如何根据这些小集合，来计算整体的熵呢？之前我们提到了信息量和熵具有加和的性质，所以对于包含多个集合的更大集合，它的信息量期望值是可以通过每个小集合的信息量期望值来推算的。具体来说，我们可以使用如下公式：</p><p><img src=\"https://static001.geekbang.org/resource/image/cd/d3/cd8f5873383759df7782b37f125bb1d3.png?wh=324*110\" alt=\"\"></p><p>其中，$T$表示一种划分，$P_{v}$表示划分后其中某个小集合，$Entropy(P_{v})$表示某个小集合的熵，而$\\frac{|Pv|} {|P|}$ 表示某个小集合出现的概率。所以这个公式其实就表示，<strong>对于多个小集合而言，其整体的熵等于各个小集合之熵的加权平均</strong>。而每个小集合的权重是其在整体中出现的概率。</p><p>我用个例子进一步解释这个公式。假设A、B、C三个集合是一个大的整体，我们现在将C组的元素和A、B组分开。</p><p><img src=\"https://static001.geekbang.org/resource/image/9e/a3/9e2c0629e7ae441eb8b6cb234bb613a3.png?wh=1558*842\" alt=\"\"></p><p>根据之前单个集合的熵计算，A和B组元素所组成的小集合，它的熵是1。而C组没有和其他组混合，所形成的小集合其熵为0。在计算前两个小集合的整体熵时，A组和B组形成的集合出现的概率为$\\frac{2}{3}$，而C组形成的集合出现概率为$\\frac{1}{3}$，所有整体熵$=\\frac{2}{3} * 1 + \\frac{1}{3} * 0 = 0.67$。</p><h2>什么是信息增益？</h2><p>如果我们将划分前后的整体熵做个对比，你会发现划分后的整体熵要小于划分之前的整体熵。这是因为每次划分，都可能将不同分组的元素区分开来，降低划分后每个小集合的混乱程度，也就是降低它们的熵。我们将划分后整体熵的下降，称为<strong>信息增益</strong>（Information Gain）。如果划分后整体熵下降得越多，信息增益就越大。我列出公式以便你理解。</p><p><img src=\"https://static001.geekbang.org/resource/image/72/79/7268dcacc996164ba51a499db45de679.png?wh=471*80\" alt=\"\"></p><p>其中T表示当前选择的特征，$Entropy§$表示选择特征$T$之前的熵，$Entropy(P_{v})$表示特征$T$取值为$v$分组的熵。减号后面的部分表示选择T做决策之后，各种取值加权平均后整体的熵。</p><p>$Gain(P,T)$表示两个熵值之差，越大表示信息增益越多，应该选择这维特征$T$。</p><p>我们把这个概念放到咱们的小游戏里就是，如果一个测试问题能够将来自不同分组的人物尽量的分开，也就是该划分对应的信息增益越高，那么我们就认为其区分能力越高，提供的信息含量也越多。好，说到这里，让我们从游戏的最开始出发，比较一下有关性别和智商的两个测试题。</p><p>在提出任何问题之前，我们无法知道被测者属于哪位武侠人物，因此所有被测者属于同一个集合。假设被测者的概率分布和这10位武侠人物的先验概率分布相同，那么被测者集合的熵为10*(-1 * 0.1 * log(0.1, 2))=3.32。</p><p>通过性别的测试问题对人物进行划分后，我们得到了两个更小的集合，每个小集合都包含5种不同的人物分组，因此每个小集合的熵是(-1 * 5 * 0.2 * log(0.2, 2)) = 2.32，两个小集合的整体熵是0.5 * 2.32 + 0.5 * 2.32 = 2.32。因此使用性别的测试题后，信息增益是3.32 - 2.32 = 1。</p><p>而通过智商的测试问题对人物分组后，我们也得到了两个小集合，一个包含了8种人物，另一个包含了2种人物。包含8种人物的小集合其熵是(-1* 8 * 0.125 * log(0.125, 2)) = 3，包含2种人物的小集合其熵是(-1* 2 * 0.5 * log(0.5, 2)) = 1。两个小集合的整体熵是0.8 * 3 + 0.2 * 1 = 2.6。因此使用智商的测试题后，信息增益是3.32 - 2.6 = 0.72，低于基于性别的测试。所以，我们可以得出结论，有关性别的测试题比有关智商的测试题更具有区分能力。</p><p>信息增益和信息熵是紧密相关的。如果说信息熵衡量了某个状态下，每个分组的纯净程度或者说混乱程度，那么信息增益就是比较了不同状态下，信息熵的差异程度。</p><h2>总结</h2><p>这一讲中，我们从一个有趣的人物性格测试开始，探讨了如何高效率地进行问卷调查。其中主要包含了两个要点：信息熵和信息增益。熵的计算是基于集合内各组元素分布的概率来进行的。而信息增益是集合划分前后整体熵的差值。对某个集合进行划分，都会将其中元素细分到更小的集合，而每个细分的集合纯净度就会提高，整体熵就会下降，其中下降的部分就是信息增益。</p><p>了解信息熵和信息增益的定义之后，我们可以用它们来安排测试问题的先后顺序。其核心的思路是，利用信息增益找出区分力最强的测试题。如果一道测试题可以将来自不同分组的元素分隔开来，那么就说它是有区分力的。如果分隔后，每个细分的集合其熵越趋近于0，那么我们说这个测试题的区分力越强。</p><h2>思考题</h2><p>假设一个集合包含了64个元素，而每个元素的分类都互不相同，那么这个集合的信息熵是多少？仔细观察一下你所计算的结果，和二进制有没有什么联系？</p><p><span class=\"orange\">欢迎留言和我分享，也欢迎你在留言区写下今天的学习笔记。你可以点击“请朋友读”，把今天的内容分享给你的好友，和他一起精进。</span></p>","neighbors":{"left":{"article_title":"25 | 马尔科夫模型：从PageRank到语音识别，背后是什么模型在支撑？","id":81374},"right":{"article_title":"27 | 决策树：信息增益、增益比率和基尼指数的运用","id":81941}},"comments":[{"had_liked":false,"id":68841,"user_name":"蒋宏伟","can_delete":false,"product_type":"c1","uid":1088541,"ip_address":"","ucode":"02226CABD5ECE7","user_header":"https://static001.geekbang.org/account/avatar/00/10/9c/1d/f0f10198.jpg","comment_is_top":false,"comment_ctime":1550623125,"is_pvip":false,"replies":[{"id":"24564","content":"这是个很新颖的角度来理解信息熵","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1550682493,"ip_address":"","comment_id":68841,"utype":1}],"discussion_count":5,"race_medal":0,"score":"104629838229","product_id":100021201,"comment_content":"信息熵是衡量信息简单、纯净或复杂、混乱的标尺。人类必须将事务抽象为信息才能进行理解。事物的信息熵越小越容易理解，越大越难理解。<br>写好代码的本质，就是降低程序信息熵<br>。作用域、模块、组件、微服务、文档、注释是在不同的纬度，降低信息熵的工具。","like_count":25,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":439852,"discussion_content":"这是个很新颖的角度来理解信息熵","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1550682493,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1187478,"avatar":"https://static001.geekbang.org/account/avatar/00/12/1e/96/c735ad6b.jpg","nickname":"滩涂曳尾","note":"","ucode":"40F650F2A419D4","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":312580,"discussion_content":"可以的，老哥","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1602738041,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1058688,"avatar":"https://static001.geekbang.org/account/avatar/00/10/27/80/03c407f6.jpg","nickname":"木子上清","note":"","ucode":"D6C13218CED0A0","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":278834,"discussion_content":"作用域、模块、组件、微服务、文档、注释是在不同的纬度，降低信息熵的工具。本质上是将不同的职责区分开，模块化，降低耦合 之后，各集合之间的增益值越大。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1591239730,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1082785,"avatar":"https://static001.geekbang.org/account/avatar/00/10/85/a1/2442332c.jpg","nickname":"郭俊杰","note":"","ucode":"D328E5738A4413","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":264892,"discussion_content":"以前老大也说过类似的理解，但当时连熵是啥也不知道，哈哈，今天来看，有点道理。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589356496,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1049017,"avatar":"https://static001.geekbang.org/account/avatar/00/10/01/b9/73435279.jpg","nickname":"学习学个屁","note":"","ucode":"DF2D61E6FB2FCE","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":128301,"discussion_content":"其实说白了就就是降耦合，尽量越低越好，但在代码中看情况降低耦合度。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1578627133,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":73458,"user_name":"qinggeouye","can_delete":false,"product_type":"c1","uid":1251536,"ip_address":"","ucode":"5B53EEDD7BEC9C","user_header":"https://static001.geekbang.org/account/avatar/00/13/18/d0/49b06424.jpg","comment_is_top":false,"comment_ctime":1551887397,"is_pvip":false,"replies":[{"id":"26768","content":"理解正确","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1551894014,"ip_address":"","comment_id":73458,"utype":1}],"discussion_count":3,"race_medal":0,"score":"96041167909","product_id":100021201,"comment_content":"1、事件发生的概率 P(x) 越小，包含的信息量 H(x) 越大；<br>2、两个不相关的事件 x 、y，同时发生的信息量 H(x,y) 等于这两个事件分别发生时的信息量 H(x) 、H(y) 之和；<br>3、信息熵 Entropy(x) 是信息量 H(x) 的加权平均，即信息量的期望；<br>4、信息增益等于集合元素划分前的信息熵减去划分后的信息熵；划分后的信息熵等于各个分组的信息熵的加权平均；<br><br>思考题：64*(-1)*(1&#47;64)*log(1&#47;64) = 6 , (对数底数取 2)。","like_count":22,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":442097,"discussion_content":"理解正确","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1551894014,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1181650,"avatar":"https://static001.geekbang.org/account/avatar/00/12/07/d2/0d7ee298.jpg","nickname":"惘 闻","note":"","ucode":"C5909F034BF072","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":308726,"discussion_content":"第三个是写错了嘛？信息熵不应该是小集合信息熵的加权平均吗","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1601045875,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1025119,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/a4/5f/6892585a.jpg","nickname":"LiuHDme","note":"","ucode":"C8A1437DDD487E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1181650,"avatar":"https://static001.geekbang.org/account/avatar/00/12/07/d2/0d7ee298.jpg","nickname":"惘 闻","note":"","ucode":"C5909F034BF072","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":550881,"discussion_content":"如果有小集合，就是小集合的熵的加权求和，每个小集合的熵是该小集合内信息量的期望；如果没有小集合，那整个集合可以看成是一个小集合，熵依然是信息量的期望","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1644770651,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":308726,"ip_address":""},"score":550881,"extra":""}]}]},{"had_liked":false,"id":68988,"user_name":"刘杰","can_delete":false,"product_type":"c1","uid":1340335,"ip_address":"","ucode":"EA2B5DB6B9F2A8","user_header":"https://static001.geekbang.org/account/avatar/00/14/73/af/4bb834c1.jpg","comment_is_top":false,"comment_ctime":1550639674,"is_pvip":false,"replies":[{"id":"24565","content":"感谢支持，后面我会继续努力深入浅出","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1550682531,"ip_address":"","comment_id":68988,"utype":1}],"discussion_count":1,"race_medal":0,"score":"48795279930","product_id":100021201,"comment_content":"这个是我读过最好的信息论概念的解释！","like_count":11,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":439903,"discussion_content":"感谢支持，后面我会继续努力深入浅出","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1550682531,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":124924,"user_name":"哈","can_delete":false,"product_type":"c1","uid":1130578,"ip_address":"","ucode":"36733D24917941","user_header":"https://static001.geekbang.org/account/avatar/00/11/40/52/7266ee09.jpg","comment_is_top":false,"comment_ctime":1566016180,"is_pvip":false,"replies":[{"id":"46162","content":"举个形象的例子，比如说最近本地区天天下雨，如果明天仍然有很高的概率会下雨，我告诉你“明天下雨”，你就觉得这个信息量不大，因为即使我不说，你也知道明天会下雨，也会带雨伞出门。如果本地区几十年以来从未下过雪，我告诉你“明天要下雪”，那么这个对你来说，这是个极低概率的事件，你没有想到它会发生，这句话包含了很大的信息量，它可能会改变你明天出门的行为，比如买一双防滑靴以备出门之用。","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1566236535,"ip_address":"","comment_id":124924,"utype":1}],"discussion_count":2,"race_medal":0,"score":"44515689140","product_id":100021201,"comment_content":"事情发生的概率越大，产生的信息量越小；事情发生的概率越小，产生的信息量越大。<br>这个应该怎么理解呢","like_count":11,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":463361,"discussion_content":"举个形象的例子，比如说最近本地区天天下雨，如果明天仍然有很高的概率会下雨，我告诉你“明天下雨”，你就觉得这个信息量不大，因为即使我不说，你也知道明天会下雨，也会带雨伞出门。如果本地区几十年以来从未下过雪，我告诉你“明天要下雪”，那么这个对你来说，这是个极低概率的事件，你没有想到它会发生，这句话包含了很大的信息量，它可能会改变你明天出门的行为，比如买一双防滑靴以备出门之用。","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1566236535,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1130578,"avatar":"https://static001.geekbang.org/account/avatar/00/11/40/52/7266ee09.jpg","nickname":"哈","note":"","ucode":"36733D24917941","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":5421,"discussion_content":"哦哦，信息量是这个意思呀，谢谢！！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1566259420,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":66907,"user_name":"拉欧","can_delete":false,"product_type":"c1","uid":1206605,"ip_address":"","ucode":"40996A8093A95F","user_header":"https://static001.geekbang.org/account/avatar/00/12/69/4d/81c44f45.jpg","comment_is_top":false,"comment_ctime":1550039759,"is_pvip":false,"replies":[{"id":"23759","content":"正确","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1550081849,"ip_address":"","comment_id":66907,"utype":1}],"discussion_count":1,"race_medal":0,"score":"31614810831","product_id":100021201,"comment_content":"2的6次方是64，所以是6","like_count":7,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438970,"discussion_content":"正确","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1550081849,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":207776,"user_name":"罗耀龙@坐忘","can_delete":false,"product_type":"c1","uid":1917663,"ip_address":"","ucode":"3CEA258DE7F3C7","user_header":"https://static001.geekbang.org/account/avatar/00/1d/42/df/a034455d.jpg","comment_is_top":false,"comment_ctime":1587177959,"is_pvip":true,"discussion_count":2,"race_medal":5,"score":"23062014439","product_id":100021201,"comment_content":"茶艺师学编程<br><br>思考题：计算一个包含了 64 个元素，而每个元素的分类都互不相同的集合的信息熵。仔细观察一下结果，和二进制有没有什么联系？<br><br>假设这个集合就有64种分类，那么它的信息熵就是64*[-1&#47;64*log（1&#47;64,2）]=6<br>假设这个集合就有63种分类，那么它的信息熵就是63*[-1&#47;63*log（1&#47;63,2）]≈5.977<br>假设这个集合就有62种分类，那么它的信息熵就是62*[-1&#47;62*log（1&#47;62,2）]≈5.954<br>假设这个集合就有61种分类，那么它的信息熵就是61*[-1&#47;61*log（1&#47;61,2）]≈5.931<br>假设这个集合就有60种分类，那么它的信息熵就是60*[-1&#47;60*log（1&#47;60,2）]≈5.907<br>······<br>假设这个集合就有4种分类，那么它的信息熵就是4*[-1&#47;4*log（1&#47;4,2）]=2<br>假设这个集合就有3种分类，那么它的信息熵就是3*[-1&#47;3*log（1&#47;3,2）]≈1.585<br>假设这个集合就有2种分类，那么它的信息熵就是2*[-1&#47;2*log（1&#47;2,2）]=1<br>假设这个集合就有1种分类，那么它的信息熵就是1*[-1&#47;1*log（1&#47;1,2）]=0<br><br>因为这里用到的log2，而在信息论中，描述“有0和1两种状态，出现的可能性都是50%，那么是0还是1？”这就是二进制，这样的信息量就是1比特。换句话说在二进制（信息论）的视角里，一个有64个元素的集合分类的信息熵，最多就是6比特的事情。","like_count":6,"discussions":[{"author":{"id":2903822,"avatar":"","nickname":"丁凌","note":"","ucode":"86295C3C29FFA3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":584789,"discussion_content":"你这错得离谱。。。拿2种分类来说，你这个公式成立的前提是每种分类刚好32个元素，也就是均匀分配，然而压根没有这个前提。。。例如，只有一个元素在第1个分类中，剩下63个元素在第2个分类中，这时候的信息熵是-1/64*log(1/64)-63/64*log(63/64)≈0.116","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1661135876,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"四川"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1957907,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/e0/13/b5972df3.jpg","nickname":"蓝天","note":"","ucode":"746BA411D6386A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":338168,"discussion_content":"牛！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1609206622,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":226550,"user_name":"建强","can_delete":false,"product_type":"c1","uid":1397126,"ip_address":"","ucode":"62B03D0E0C64EC","user_header":"https://static001.geekbang.org/account/avatar/00/15/51/86/b5fd8dd8.jpg","comment_is_top":false,"comment_ctime":1592138442,"is_pvip":false,"replies":[{"id":"83423","content":"是的","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1592177001,"ip_address":"","comment_id":226550,"utype":1}],"discussion_count":3,"race_medal":0,"score":"18772007626","product_id":100021201,"comment_content":"思考题：<br>包含64个元素的集合信息熵 Entroy(P) = 64 * (-1 * 1&#47;64 * log(2, 1&#47;64)) = 2^6 * (-1) * (2^(-6)) * (-6) = 6 = log(2,64)<br>我个人理解：信息熵其实就是用二进制来表达某个数时所需要的二进制位数","like_count":3,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":498282,"discussion_content":"是的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1592177001,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1957907,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/e0/13/b5972df3.jpg","nickname":"蓝天","note":"","ucode":"746BA411D6386A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":338166,"discussion_content":"感谢老师和牛人的分享，我作为非计算机专业的好像懂了原理！","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1609206100,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1397126,"avatar":"https://static001.geekbang.org/account/avatar/00/15/51/86/b5fd8dd8.jpg","nickname":"建强","note":"","ucode":"62B03D0E0C64EC","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1957907,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/e0/13/b5972df3.jpg","nickname":"蓝天","note":"","ucode":"746BA411D6386A","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":338441,"discussion_content":"加油","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1609291870,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":338166,"ip_address":""},"score":338441,"extra":""}]}]},{"had_liked":false,"id":169327,"user_name":"F大圣","can_delete":false,"product_type":"c1","uid":1800834,"ip_address":"","ucode":"BD1389C5308588","user_header":"https://static001.geekbang.org/account/avatar/00/1b/7a/82/182cb2ec.jpg","comment_is_top":false,"comment_ctime":1578315413,"is_pvip":false,"replies":[{"id":"65854","content":"感谢支持，如果有好的机会会考虑🙂","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1578421968,"ip_address":"","comment_id":169327,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18758184597","product_id":100021201,"comment_content":"黄老师，您好！您讲的真的好，虽然之前接触过这些概念，但理解的不透彻，从之前的贝叶斯到今天的信息熵，我现在完全搞明白了，相见恨晚啊。（希望您能开个ML和DL的专栏，将来想从事这方面的研究，谢谢）","like_count":4,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":480510,"discussion_content":"感谢支持，如果有好的机会会考虑🙂","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1578421968,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":131616,"user_name":"张九州","can_delete":false,"product_type":"c1","uid":1455679,"ip_address":"","ucode":"414C0CFC741B4F","user_header":"https://static001.geekbang.org/account/avatar/00/16/36/3f/95a9a40a.jpg","comment_is_top":false,"comment_ctime":1567825720,"is_pvip":false,"replies":[{"id":"50354","content":"虽然信息量减少了，但是对分类这个应用而言，增加了分组内的纯净度，算是“增益”（英文Gain，也可以理解为获益）了","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1567914935,"ip_address":"","comment_id":131616,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18747694904","product_id":100021201,"comment_content":"总信息量减少 为什么叫做增益呢？不太理解","like_count":4,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":466540,"discussion_content":"虽然信息量减少了，但是对分类这个应用而言，增加了分组内的纯净度，算是“增益”（英文Gain，也可以理解为获益）了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567914935,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":213275,"user_name":"zhengfan","can_delete":false,"product_type":"c1","uid":1020160,"ip_address":"","ucode":"B3AC0E10BF7A14","user_header":"https://static001.geekbang.org/account/avatar/00/0f/91/00/2007d2f3.jpg","comment_is_top":false,"comment_ctime":1588350205,"is_pvip":false,"replies":[{"id":"79287","content":"对，如果每次划分都有新的切分，就会如此，这样也是为什么过多的决策树分支会导致过拟合。所以人们提出了适度的剪枝，具体你可以参考后面一节","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1588645865,"ip_address":"","comment_id":213275,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10178284797","product_id":100021201,"comment_content":"黄老师：<br>请问对一个几个不断地做划分，信息熵是否是个单调递减过程？<br>我试着推导了一下可以得出，对于一个完全无分类集合，所有有效划分（不会导致空子集产生的划分）都必然带来大于0的信息增益，也就是信息熵必然减小。<br>对于已经存在分类的集合，我直觉上认为是成立的，思考了几个例子也支持。请问能严格证明吗？","like_count":2,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493728,"discussion_content":"对，如果每次划分都有新的切分，就会如此，这样也是为什么过多的决策树分支会导致过拟合。所以人们提出了适度的剪枝，具体你可以参考后面一节","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588645865,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":203933,"user_name":"Geek_80dbb5","can_delete":false,"product_type":"c1","uid":1795360,"ip_address":"","ucode":"826874C19C51DA","user_header":"https://static001.geekbang.org/account/avatar/00/1b/65/20/cf47a9e1.jpg","comment_is_top":false,"comment_ctime":1586308412,"is_pvip":false,"replies":[{"id":"76427","content":"是的，熵最初来自物理学","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1586401873,"ip_address":"","comment_id":203933,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10176243004","product_id":100021201,"comment_content":"其实，古人的“钻木取火”，就是一种能量转换，即机械能向热能转换；并且在这个转换过程中，“熵”便产生了。","like_count":2,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491007,"discussion_content":"是的，熵最初来自物理学","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586401873,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":79001,"user_name":"zhengnachuan","can_delete":false,"product_type":"c1","uid":1018928,"ip_address":"","ucode":"FC6CD65906BE6B","user_header":"https://static001.geekbang.org/account/avatar/00/0f/8c/30/d642e01a.jpg","comment_is_top":false,"comment_ctime":1553316187,"is_pvip":false,"replies":[{"id":"28937","content":"如果决策树是用于分类的，没有必要细分到每一个样本，我们只需要确保划分后，每一组里所有的样本都属于同一个分类，那么就很完美了。如果细分到每个样本，就是过拟合了。","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1553452907,"ip_address":"","comment_id":79001,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10143250779","product_id":100021201,"comment_content":"如果只是为了增加增益，其实可以细分到最小，但是实际上应该是要考虑其他维度的吧，例如分组的次数，即在固定次数下的最大增益。<br>另外，有点疑惑，假设为了获得最大增益，n个元素分为n组，是不是表示就需要有n个条件能一次进行区分。以开始的人物区分为例，这个条件应该怎么给呢，是不是要重新设计独有的特征。","like_count":2,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":444319,"discussion_content":"如果决策树是用于分类的，没有必要细分到每一个样本，我们只需要确保划分后，每一组里所有的样本都属于同一个分类，那么就很完美了。如果细分到每个样本，就是过拟合了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1553452907,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":227161,"user_name":"良知犹存","can_delete":false,"product_type":"c1","uid":2022036,"ip_address":"","ucode":"16250EC15B73E8","user_header":"https://static001.geekbang.org/account/avatar/00/1e/da/94/8acab546.jpg","comment_is_top":false,"comment_ctime":1592301485,"is_pvip":false,"replies":[{"id":"84224","content":"是的👍","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1592669813,"ip_address":"","comment_id":227161,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5887268781","product_id":100021201,"comment_content":"信息熵用来表示每个分组在整体中的混乱情况。熵增意味着更加混乱，熵减意味着分组的独立<br>思考题：<br>由于各自独立，所以最终分为64组，所以每组的出现的概率为1&#47;64<br>整体的熵计算为：64*（-1*1&#47;64 *log （1&#47;64，2 ））= 6","like_count":1,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":498516,"discussion_content":"是的👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1592669813,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":224907,"user_name":"骑行的掌柜J","can_delete":false,"product_type":"c1","uid":1474214,"ip_address":"","ucode":"3163102651C653","user_header":"https://static001.geekbang.org/account/avatar/00/16/7e/a6/4e331ef4.jpg","comment_is_top":false,"comment_ctime":1591589168,"is_pvip":false,"replies":[{"id":"83387","content":"没错，众人拾柴火焰高🔥😆","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1592102124,"ip_address":"","comment_id":224907,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5886556464","product_id":100021201,"comment_content":"之前在学过一点信息熵的知识 但是理解不是很透彻 这里重学了一遍 瞬间把之前的迷糊点弄懂了 谢谢黄老师<br><br>PS 看评论也可以学到很多😁","like_count":1,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":497651,"discussion_content":"没错，众人拾柴火焰高🔥😆","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1592102124,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":131924,"user_name":"Paul Shan","can_delete":false,"product_type":"c1","uid":1593140,"ip_address":"","ucode":"32D99989028284","user_header":"","comment_is_top":false,"comment_ctime":1567982010,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5862949306","product_id":100021201,"comment_content":"熵是事件概率负对数的加权和。如果把负对数看作搜索一个元素的难度，也就是二分查找树对应叶子节点的高度，熵就是这些叶子节点高度的加权和。<br><br>熵可以看作负信息，熵的减少就是信息的增加。信息增益就是熵减少的一种。<br><br>信息增益就是对集合进行划分，计算划分后子集的熵，然后再对子集的熵做加权平均，这个时候的熵会小于原来集合，减少的熵就是对应的信息增益。","like_count":1},{"had_liked":false,"id":105115,"user_name":"大秦岭","can_delete":false,"product_type":"c1","uid":1515916,"ip_address":"","ucode":"3F7591A279AD93","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJman25D8Jlr6P6AIhumWr2CNqZPvXl8JJLc3yOvvTlWFDVuKbYpNXgKib6y1Sa0HApwvz1xM6MBjw/132","comment_is_top":false,"comment_ctime":1560921655,"is_pvip":false,"replies":[{"id":"38399","content":"这可能也是为什么汉语这么难学的原因吧😆","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1561247215,"ip_address":"","comment_id":105115,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5855888951","product_id":100021201,"comment_content":"经过各学者多年的探究和各种语言的统计，得出一个结果，汉语是世界上信息熵最大的语言。那么这个信息熵是 什么？信息熵指的就是可能发生的所有事情中包含的信息期望值，比如鸟不能生活在水中，违背自然常理，那么信息熵为0.<br>","like_count":1,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454564,"discussion_content":"这可能也是为什么汉语这么难学的原因吧😆","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561247215,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":334155,"user_name":"LiuHDme","can_delete":false,"product_type":"c1","uid":1025119,"ip_address":"","ucode":"C8A1437DDD487E","user_header":"https://static001.geekbang.org/account/avatar/00/0f/a4/5f/6892585a.jpg","comment_is_top":false,"comment_ctime":1644770465,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1644770465","product_id":100021201,"comment_content":"这一讲非常不错👍","like_count":0},{"had_liked":false,"id":301944,"user_name":"201201904","can_delete":false,"product_type":"c1","uid":2438773,"ip_address":"","ucode":"6AE2D909382322","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eo9Xajp9qOGPQMwzvGPKXzb1TptIZsAaJavfU6a3n1qDANplTmVAjkickhddL1lrhqNVX1BneOabNQ/132","comment_is_top":false,"comment_ctime":1625991630,"is_pvip":false,"replies":[{"id":"109612","content":"举个通俗的例子，假设一家上市公司的业绩非常好，股价上涨的概率很大，我告诉你买它家的股票，其实没啥信息量，因为即使我不告诉你，你也会买。但是假设另一种情况，这家公司虽然业绩非常好，但是确出人意料的股价大幅下跌了，那么一定是什么不为人知的事情发生了，这个时候有内部的消息传出，原来是公司做假账，那么如果你提前获知这个信息，它的信息量就很大了。","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1626462282,"ip_address":"","comment_id":301944,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1625991630","product_id":100021201,"comment_content":"事情发生的概率越大，产生的信息量越小；事情发生的概率越小，产生的信息量越大。<br>怎么理解？","like_count":0,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":523129,"discussion_content":"举个通俗的例子，假设一家上市公司的业绩非常好，股价上涨的概率很大，我告诉你买它家的股票，其实没啥信息量，因为即使我不告诉你，你也会买。但是假设另一种情况，这家公司虽然业绩非常好，但是确出人意料的股价大幅下跌了，那么一定是什么不为人知的事情发生了，这个时候有内部的消息传出，原来是公司做假账，那么如果你提前获知这个信息，它的信息量就很大了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1626462282,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":279685,"user_name":"Geek_b636f6","can_delete":false,"product_type":"c1","uid":1901404,"ip_address":"","ucode":"622F30C13645F9","user_header":"https://static001.geekbang.org/account/avatar/00/1d/03/5c/8733ec5a.jpg","comment_is_top":false,"comment_ctime":1613905423,"is_pvip":false,"replies":[{"id":"101931","content":"这么说也很有道理啊👍<br>可是，通过学生的努力，每次都可以往更高分数的那一组进发😆","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1614390012,"ip_address":"","comment_id":279685,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1613905423","product_id":100021201,"comment_content":"看来老师对学生的学习情况进行区分，通过考试问卷给学生打分，是一个信息增益的过程。老师的劳动创造了信息。","like_count":0,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":515831,"discussion_content":"这么说也很有道理啊👍\n可是，通过学生的努力，每次都可以往更高分数的那一组进发😆","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1614390012,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":279684,"user_name":"Geek_b636f6","can_delete":false,"product_type":"c1","uid":1901404,"ip_address":"","ucode":"622F30C13645F9","user_header":"https://static001.geekbang.org/account/avatar/00/1d/03/5c/8733ec5a.jpg","comment_is_top":false,"comment_ctime":1613905065,"is_pvip":false,"replies":[{"id":"101932","content":"能否具体一些，从你的理解“大众创业，万众创新”和熵减、熵增有何关系？","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1614390068,"ip_address":"","comment_id":279684,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1613905065","product_id":100021201,"comment_content":"熵增一般被认为是混乱度增加，信息熵增是指系统的不确定性增加，都是人不喜欢的。人的本性是追求秩序的，追求确定性的，所以生命和文明都是熵减过程。<br>老师，请问个体层面有意识的熵减活动过程，是否从宏观层面看还是是熵增，比如“大众创业，万众创新”？","like_count":0,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":515830,"discussion_content":"能否具体一些，从你的理解“大众创业，万众创新”和熵减、熵增有何关系？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1614390068,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":277363,"user_name":"Dale","can_delete":false,"product_type":"c1","uid":1242602,"ip_address":"","ucode":"AD19A33FE5EEDF","user_header":"https://static001.geekbang.org/account/avatar/00/12/f5/ea/5f046856.jpg","comment_is_top":false,"comment_ctime":1612372910,"is_pvip":false,"replies":[{"id":"101391","content":"是的","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1613531067,"ip_address":"","comment_id":277363,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1612372910","product_id":100021201,"comment_content":"6位二进制数刚好可以表示0~63共64个不同的状态，也就是说在概率相同的情况下，熵就等于存储所有状态的比特数(没有取整)","like_count":1,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":515022,"discussion_content":"是的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1613531067,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":251575,"user_name":"吴关俊","can_delete":false,"product_type":"c1","uid":2173036,"ip_address":"","ucode":"6ACA9C31BBCCF8","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eoxfvYvvMkjsjwA6rnpIGY2DSZ6Ww5yxP6brbzkicNdXc6ftPoAC8J94SoicneVDmH1Wdta194oFribQ/132","comment_is_top":false,"comment_ctime":1601697188,"is_pvip":false,"replies":[{"id":"92020","content":"这里假设一个武侠人物就是代表一个分组。当然实际情况比这个更复杂，参考后面的决策树分析，你能发现在现实中，每个分组是由多个样本组成的。","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1601771613,"ip_address":"","comment_id":251575,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1601697188","product_id":100021201,"comment_content":"就是计算总体熵的时候，为啥用单个武侠人物的平均概率计算呢？ 根据公式 不应该是武侠人物每个特征就是一个集合计算熵然后相加得到总体熵嘛，而你直接用1&#47; 10 = 0.1是何道理？","like_count":0,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":506551,"discussion_content":"这里假设一个武侠人物就是代表一个分组。当然实际情况比这个更复杂，参考后面的决策树分析，你能发现在现实中，每个分组是由多个样本组成的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1601771613,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":251570,"user_name":"吴关俊","can_delete":false,"product_type":"c1","uid":2173036,"ip_address":"","ucode":"6ACA9C31BBCCF8","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eoxfvYvvMkjsjwA6rnpIGY2DSZ6Ww5yxP6brbzkicNdXc6ftPoAC8J94SoicneVDmH1Wdta194oFribQ/132","comment_is_top":false,"comment_ctime":1601694078,"is_pvip":false,"replies":[{"id":"92021","content":"这个是针对C本身形成的分组而言的，在这个分组里，只有C类型的元素，所以认为熵是0。","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1601771686,"ip_address":"","comment_id":251570,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1601694078","product_id":100021201,"comment_content":"老师有个位置不懂啊<br>根据之前单个集合的熵计算，A 和 B 组元素所组成的小集合，它的熵是 1。而 C 组没有和其他组混合，所形成的小集合其熵为 0<br>C组熵咋会是0呢？ AB组形成一个集合 是大集合中的小集合 有熵能理解，C 也是大集合中的小集合熵怎么会是0呢？ 很费解","like_count":0,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":506548,"discussion_content":"这个是针对C本身形成的分组而言的，在这个分组里，只有C类型的元素，所以认为熵是0。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1601771686,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":238609,"user_name":"！null","can_delete":false,"product_type":"c1","uid":1242483,"ip_address":"","ucode":"4E5B7922980397","user_header":"https://static001.geekbang.org/account/avatar/00/12/f5/73/f7d3a996.jpg","comment_is_top":false,"comment_ctime":1596212113,"is_pvip":false,"replies":[{"id":"88534","content":"这个项目要解决的最终问题是什么？是一个分类问题吗？","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1596649237,"ip_address":"","comment_id":238609,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1596212113","product_id":100021201,"comment_content":"真实项目中遇到了一个问题。还是类比大侠吧，有个特征是擅长的兵器，杨过的用剑，谢逊用刀，郭靖用手，张无忌会太极拳和太极剑，石破天啥都用，就是有的人有的特征他不关心。因为实际项目中的问题，有的关心A特征，不关心B特征，有的关心B特征，A特征如何取值无所谓，这个熵和增益应该如何计算？P(用刀|石破天）=P（用剑|石破天）=P(用手|石破天)=P(用刀）=P（用剑）=P（用手），那相当于集合中石破天的概率是其他人的3倍？算熵的时候的概率就相当与3倍的其他人？分组后就相当于3个石破天分到三个组中？","like_count":0,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":502800,"discussion_content":"这个项目要解决的最终问题是什么？是一个分类问题吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1596649237,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1242483,"avatar":"https://static001.geekbang.org/account/avatar/00/12/f5/73/f7d3a996.jpg","nickname":"！null","note":"","ucode":"4E5B7922980397","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":296848,"discussion_content":"实际项目是Android中的一段CPP程序，根据几个特征选择配置参数送入算法库。这些特征可能是通过名值对的方式传进来的，所有的特征都会传进来。比如当前是sensorA，id=2的情况下送A配置。如果mode是35那别的条件都不看了，送B配置。如果是SensorB，mode是34就送C配置。id=4，mode=5可能也是送配置A进去。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1596685665,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":235807,"user_name":"！null","can_delete":false,"product_type":"c1","uid":1242483,"ip_address":"","ucode":"4E5B7922980397","user_header":"https://static001.geekbang.org/account/avatar/00/12/f5/73/f7d3a996.jpg","comment_is_top":false,"comment_ctime":1595208349,"is_pvip":false,"replies":[{"id":"87296","content":"举个例子，如果小明每天的午饭都是蛋炒饭，那么信息量就是0，因为我们知道小明一定吃蛋炒饭，所以他妈妈告知我们他今天吃蛋炒饭，并未给我们带来额外的信息量。如果小明有20%概率吃蛋炒饭，30%概率吃三明治，30%概率吃拉面，20%概率吃汉堡，那么他妈妈告诉我们他今天吃拉面，这个信息就很重要。","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1595379399,"ip_address":"","comment_id":235807,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1595208349","product_id":100021201,"comment_content":"当我们观察到某个随机变量的具体值时，接收到了多少信息。接受到的信息指的什么，能不能举个例子？","like_count":0,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":501838,"discussion_content":"举个例子，如果小明每天的午饭都是蛋炒饭，那么信息量就是0，因为我们知道小明一定吃蛋炒饭，所以他妈妈告知我们他今天吃蛋炒饭，并未给我们带来额外的信息量。如果小明有20%概率吃蛋炒饭，30%概率吃三明治，30%概率吃拉面，20%概率吃汉堡，那么他妈妈告诉我们他今天吃拉面，这个信息就很重要。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1595379399,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":233752,"user_name":"A君","can_delete":false,"product_type":"c1","uid":1940105,"ip_address":"","ucode":"FE96F089C2312C","user_header":"https://static001.geekbang.org/account/avatar/00/1d/9a/89/babe8b52.jpg","comment_is_top":false,"comment_ctime":1594437122,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1594437122","product_id":100021201,"comment_content":"信息量跟信息发生的概率成反比，信息熵是随机变量所有具体值的信息量期望，信息增益是指集合划分后信息熵减少的数值。在选取特征来划分集合时，要选信息增益最大的那个，它让集合减少的信息熵就是它增加的信息增益。<br>决策树模型就是根据信息增益理论设计的。","like_count":0},{"had_liked":false,"id":231533,"user_name":"阳仔","can_delete":false,"product_type":"c1","uid":1046920,"ip_address":"","ucode":"79F73D85EDF3E2","user_header":"https://static001.geekbang.org/account/avatar/00/0f/f9/88/cdda9e6f.jpg","comment_is_top":false,"comment_ctime":1593700531,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1593700531","product_id":100021201,"comment_content":"信息是用来消除不确定性的，而熵是可以理解一个系统的不确定性（混乱程度），信息量大说明消除不确定性就越大","like_count":0},{"had_liked":false,"id":196506,"user_name":"我要换个名字","can_delete":false,"product_type":"c1","uid":1606736,"ip_address":"","ucode":"E262F2924D3484","user_header":"https://static001.geekbang.org/account/avatar/00/18/84/50/3a20b40f.jpg","comment_is_top":false,"comment_ctime":1585287556,"is_pvip":true,"replies":[{"id":"74498","content":"很感谢对你有价值","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1585334692,"ip_address":"","comment_id":196506,"utype":1}],"discussion_count":1,"race_medal":1,"score":"1585287556","product_id":100021201,"comment_content":"通俗易懂，很有用","like_count":0,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":489318,"discussion_content":"很感谢对你有价值","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1585334692,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":173532,"user_name":"Eleven","can_delete":false,"product_type":"c1","uid":1168452,"ip_address":"","ucode":"FB4A0C8CA732BE","user_header":"https://static001.geekbang.org/account/avatar/00/11/d4/44/0ec958f4.jpg","comment_is_top":false,"comment_ctime":1579590986,"is_pvip":false,"replies":[{"id":"67301","content":"是不是少写了log？","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1579624591,"ip_address":"","comment_id":173532,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1579590986","product_id":100021201,"comment_content":"按照公式计算为：<br>-1*64*1&#47;64*log(1&#47;64) = -1*1*(log1 - log64) = -1(0 - 6) = 6","like_count":0,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":482103,"discussion_content":"是不是少写了log？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1579624591,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":152144,"user_name":"so敏仪","can_delete":false,"product_type":"c1","uid":1545669,"ip_address":"","ucode":"51FE61DB350D03","user_header":"https://static001.geekbang.org/account/avatar/00/17/95/c5/397b3d01.jpg","comment_is_top":false,"comment_ctime":1573891216,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1573891216","product_id":100021201,"comment_content":"设某集合含n个互不相同的元素，则Entropy(P)=-n * 1&#47;n * log(1&#47;n,2)=log(n,2) ","like_count":0},{"had_liked":false,"id":139935,"user_name":"Ronnyz","can_delete":false,"product_type":"c1","uid":1488280,"ip_address":"","ucode":"9F34527B1D343D","user_header":"https://static001.geekbang.org/account/avatar/00/16/b5/98/ffaf2aca.jpg","comment_is_top":false,"comment_ctime":1570770263,"is_pvip":false,"replies":[{"id":"54510","content":"是的","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1571073906,"ip_address":"","comment_id":139935,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1570770263","product_id":100021201,"comment_content":"64*-1*（1&#47;64）*log(1&#47;64,2)=6 <br>由于是64等分，相当于2^6=64","like_count":0,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":470179,"discussion_content":"是的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1571073906,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":131923,"user_name":"Paul Shan","can_delete":false,"product_type":"c1","uid":1593140,"ip_address":"","ucode":"32D99989028284","user_header":"","comment_is_top":false,"comment_ctime":1567981444,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1567981444","product_id":100021201,"comment_content":"思考题<br>64个等概率出现的事件集合的熵是6,如果把0到63，这六十四个数看作6位二进制能表示的状态个数，熵就是最大数为64-1的二进制位数。","like_count":0},{"had_liked":false,"id":131922,"user_name":"Paul Shan","can_delete":false,"product_type":"c1","uid":1593140,"ip_address":"","ucode":"32D99989028284","user_header":"","comment_is_top":false,"comment_ctime":1567980462,"is_pvip":false,"replies":[{"id":"50547","content":"这篇讲座暂时还没有设计独立事件的熵计算","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1568055001,"ip_address":"","comment_id":131922,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1567980462","product_id":100021201,"comment_content":"老师，我推导了一下独立事件熵的公式和文中不一样，不知道哪一步有问题？多谢！<br>H(x,y) = -P(x,y)lgP(x,y) = -P(x)P(y)lg(P(x)P(y)) =H(x)P(y) + H(y)P(x)","like_count":0,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":466682,"discussion_content":"这篇讲座暂时还没有设计独立事件的熵计算","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1568055001,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":97732,"user_name":"予悠悠","can_delete":false,"product_type":"c1","uid":1211755,"ip_address":"","ucode":"93D785F354E225","user_header":"https://static001.geekbang.org/account/avatar/00/12/7d/6b/648c30bc.jpg","comment_is_top":false,"comment_ctime":1558757936,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1558757936","product_id":100021201,"comment_content":"-1 * 64 * (1&#47;64) * log(64, 2) = 6","like_count":0,"discussions":[{"author":{"id":1172953,"avatar":"https://static001.geekbang.org/account/avatar/00/11/e5/d9/8fd0aef1.jpg","nickname":"于江水","note":"","ucode":"B42EF199DC7F9E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":80733,"discussion_content":"log(64, 2) 应该是 log(1/64, 2) ?","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1576188357,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":69375,"user_name":"mickey","can_delete":false,"product_type":"c1","uid":1051663,"ip_address":"","ucode":"8B490C2DDE4010","user_header":"https://static001.geekbang.org/account/avatar/00/10/0c/0f/93d1c8eb.jpg","comment_is_top":false,"comment_ctime":1550730380,"is_pvip":false,"replies":[{"id":"24685","content":"H(x)=−log(P(x),2)，这里是指单个变量取值时候获得的信息量","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1550769934,"ip_address":"","comment_id":69375,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1550730380","product_id":100021201,"comment_content":"信息熵的公式是H(x)=−log(P(x),2)<br>文中熵为 -100%*log(100%, 2) = 0<br>请问第一个 100% 怎么来的？少了一个 P（x）吧。","like_count":0,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":440087,"discussion_content":"H(x)=−log(P(x),2)，这里是指单个变量取值时候获得的信息量","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1550769934,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1082785,"avatar":"https://static001.geekbang.org/account/avatar/00/10/85/a1/2442332c.jpg","nickname":"郭俊杰","note":"","ucode":"D328E5738A4413","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":264918,"discussion_content":"熵为所有集合的信息量的加权平均，第一个100%就代表，只分了一个组，那他的概率就是100%","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589358374,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":69248,"user_name":"seleven","can_delete":false,"product_type":"c1","uid":1338701,"ip_address":"","ucode":"B4D84E6B930448","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/SsJajvXghPMDicSuOcx54mV6L9zv4KSKM2bKY0gsUdAH3oGCWzfRv9Q9HRljic2IvHzYFpRECp8SXGWhiaqGWFTKg/132","comment_is_top":false,"comment_ctime":1550706364,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1550706364","product_id":100021201,"comment_content":"信息熵的另一个别名：信息的不确定性。","like_count":0},{"had_liked":false,"id":68846,"user_name":"蒋宏伟","can_delete":false,"product_type":"c1","uid":1088541,"ip_address":"","ucode":"02226CABD5ECE7","user_header":"https://static001.geekbang.org/account/avatar/00/10/9c/1d/f0f10198.jpg","comment_is_top":false,"comment_ctime":1550623500,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1550623500","product_id":100021201,"comment_content":"信息熵是衡量信息简单或复杂的标尺。你要想理解什么东西，必须先将其抽象为信息。事物的信息熵越小你越容易理解，越大越难理解。<br>写好代码的本质，就是降低程序的信息熵。作用域、模块、组件、微服务、注释、文档是在不同纬度降低信息熵的工具。","like_count":0,"discussions":[{"author":{"id":1049017,"avatar":"https://static001.geekbang.org/account/avatar/00/10/01/b9/73435279.jpg","nickname":"学习学个屁","note":"","ucode":"DF2D61E6FB2FCE","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":128304,"discussion_content":"微服务就是一个很好地例子","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1578627226,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}