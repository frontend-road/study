{"id":483203,"title":"答疑篇｜思考题答案集锦","content":"<p>你好，我是编辑宇新。春节将至，给你拜个早年。</p><p>距离我们的专栏更新结束，已经过去不少时间啦。方远老师仍然会在工作之余，回到专栏里转一转，看看同学最新的学习动态。大部分的疑问，老师都在留言区里做了回复。</p><p>除了紧跟更新的第一批同学，也很开心看到有更多新朋友加入到这个专栏的学习中。课程的思考题，为了给你留足思考和研究的时间，我们选择用加餐的方式，把所有参考答案一次性发布出来。</p><p>这里要提醒一下，建议你先自己思考和练习后，再来对答案。每节课都有超链接，方便你跳转回顾。</p><h2><a href=\"https://time.geekbang.org/column/article/426126\">第2节课</a></h2><p>题目：在刚才用户对游戏评分的那个问题中，你能计算一下每位用户对三款游戏打分的平均分吗？</p><p>答案：</p><pre><code class=\"language-plain\">&gt;&gt;&gt;interest_score.mean(axis=1)\n</code></pre><h2><a href=\"https://time.geekbang.org/column/article/42680\">第3节课</a></h2><p>题目：给定数组scores，形状为（256，256，2），scores[: , :, 0] 与scores[:, :, 1]对应位置元素的和为1，现在我们要根据scores生产数组mask，要求scores通道0的值如果大于通道1的值，则mask对应的位置为0，否则为1。</p><p>scores如下，你可以试试用代码实现：</p><pre><code class=\"language-plain\">scores = np.random.rand(256, 256, 2)\nscores[:,:,1] = 1 - scores[:,:,0]\n</code></pre><!-- [[[read_end]]] --><p>答案：</p><pre><code class=\"language-plain\">mask = np.argmax(scores, axis=2)\n</code></pre><h2><a href=\"https://time.geekbang.org/column/article/427460\">第4节课</a></h2><p>题目：在PyTorch中，有torch.Tensor()和torch.tensor()两种函数，它们的区别是什么呢？</p><p>答案：torch.Tensor()<strong>是Pytorch中的类</strong>，其实它是torch.FloatTensor()的别名，使用torch.Tensor()会调用Tensor类的构造函数，生成float类型的张量；</p><p>而torch.tensor()<strong>是Pytorch的函数</strong>，函数原型是torch.tensor(data, dtype…)，其中data可以是scalar，list，tuple等不同的数据结构形式。</p><h2><a href=\"https://time.geekbang.org/column/article/428186\">第5节课</a></h2><p>题目：现在有个Tensor，如下。</p><pre><code class=\"language-python\">&gt;&gt;&gt; A=torch.tensor([[4,5,7], [3,9,8],[2,3,4]])\n&gt;&gt;&gt; A\ntensor([[4, 5, 7],\n&nbsp; &nbsp; &nbsp; &nbsp; [3, 9, 8],\n&nbsp; &nbsp; &nbsp; &nbsp; [2, 3, 4]])\n</code></pre><p>我们想提取出其中第一行的第一个，第二行的第一第二个，第三行的最后一个，该怎么做呢？</p><p>答案：</p><pre><code class=\"language-python\">&gt;&gt;&gt; B=torch.Tensor([[1,0,0], [1,1,0],[0,0,1]]).type(torch.ByteTensor)\n&gt;&gt;&gt; B\ntensor([[1, 0, 0],\n&nbsp; &nbsp; &nbsp; &nbsp; [1, 1, 0],\n&nbsp; &nbsp; &nbsp; &nbsp; [0, 0, 1]], dtype=torch.uint8)\n&gt;&gt;&gt; C=torch.masked_select(A,B)\n&gt;&gt;&gt; C\ntensor([4, 3, 9, 4])\n</code></pre><p>我们只需要创建一个形状跟A一样的Tensor，然后将对应位置的数值置为1，然后再把Tensor转换成torch.ByteTensor类型得到B，最后跟之前masked_select一样的操作就OK啦。</p><h2><a href=\"https://time.geekbang.org/column/article/429048\">第6节课</a></h2><p>题目：在PyTorch中，我们要定义一个数据集，应该继承哪一个类呢？</p><p>答案：torch.utils.data.Dataset</p><h2><a href=\"https://time.geekbang.org/column/article/429826\">第7节课</a></h2><p>题目：Torchvision中 transforms 模块的作用是什么？</p><p>答案：常用的图像操作，例如随机切割、旋转、Tensor 与 Numpy 和 PIL Image 的数据类型转换等。</p><h2><a href=\"https://time.geekbang.org/column/article/431420\">第8节课</a></h2><p>题目：请你使用<code>torchvision.models</code>模块实例化一个VGG 16网络。</p><p>答案：</p><pre><code class=\"language-python\">import torchvision.models as models\nvgg16 = models.vgg16(pretrained=True)\n</code></pre><h2><a href=\"https://time.geekbang.org/column/article/432042\">第9节课</a></h2><p>题目：请你想一想，padding为’same’时，stride可以为1以外的数值吗？</p><p>答案：不可以。</p><h2><a href=\"https://time.geekbang.org/column/article/433801\">第10节课</a></h2><p>题目：随机生成一个3通道的128x128的特征图，然后创建一个有10个卷积核且卷积核尺寸为3x3（DW卷积）的深度可分离卷积，对输入数据进行卷积计算。</p><p>答案：</p><pre><code class=\"language-plain\">import torch\nimport torch.nn as nn\n\n# 生成一个三通道的128x128特征图\nx = torch.rand((3, 128, 128)).unsqueeze(0)\n# DW卷积groups参数与输入通道数一样\ndw = nn.Conv2d(x.shape[1], x.shape[1], 3, 1, groups=x.shape[1])\npw = nn.Conv2d(x.shape[1], 10, 1, 1)\nout = pw(dw(x))\nprint(out.shape)\n</code></pre><h2><a href=\"https://time.geekbang.org/column/article/435553\">第11节课</a></h2><p>题目：损失函数的值越小越好么？</p><p>答案：不是的，咱们在这节课中学习的损失函数，实际上是模型在训练数据上的平均损失，这种损失函数我们称作为经验风险。实际上，还有一个方面也是我们在实际工作中需要考虑的，那就是模型的复杂度：一味追求经验风险的最小化，很容易使得模型过拟合（可回顾一下前文内容）。</p><p>所以，还需要对模型的复杂度进行约束，我们称之为结构风险。实际研发场景中<strong>，最终的损失函数是由经验风险和结构风险共同组成的，我们要求的是两者之和的最小化</strong>。</p><h2><a href=\"https://time.geekbang.org/column/article/436564\">第12节课</a></h2><p>题目：深度学习都是基于反向传播的么？</p><p>答案：不是的，主流的深度学习模型是基于反向传播和梯度下降的，但是一些非梯度下降的二阶优化算法也是存在的，比如拟牛顿法等。不过计算代价非常大，用的就比较少了。而且一般而言，工业界基本都采用基于反向传播和梯度下降的方式。</p><h2><a href=\"https://time.geekbang.org/column/article/438639\">第13节课</a></h2><p>题目：batch size越大越好吗？</p><p>答案：不是的。较大的batch_size容易使模型收敛在局部最优点，特别小则容易受噪声影响。</p><h2><a href=\"https://time.geekbang.org/column/article/442442\">第14节课</a></h2><p>题目：请你自己构建一个卷积神经网络，基于CIFAR-10，训练一个图像分类模型。因为还没有学习图像分类原理，所以我先帮你写好了网络的结构，需要你补全数据读取、损失函数(交叉熵损失)与优化方法（SGD）等部分。</p><pre><code class=\"language-python\">class MyCNN(nn.Module):\n&nbsp; &nbsp; def __init__(self):\n&nbsp; &nbsp; &nbsp; &nbsp; super().__init__()\n&nbsp; &nbsp; &nbsp; &nbsp; self.conv1 = nn.Conv2d(3, 16, kernel_size=3)\n&nbsp; &nbsp; &nbsp; &nbsp; # conv1输出的特征图为222x222大小\n&nbsp; &nbsp; &nbsp; &nbsp; self.fc = nn.Linear(16 * 222 * 222, 10)\n\n&nbsp; &nbsp; def forward(self, input):\n&nbsp; &nbsp; &nbsp; &nbsp; x = self.conv1(input)\n&nbsp; &nbsp; &nbsp; &nbsp; # 进去全连接层之前，先将特征图铺平\n&nbsp; &nbsp; &nbsp; &nbsp; x = x.view(x.shape[0], -1)\n&nbsp; &nbsp; &nbsp; &nbsp; x = self.fc(x)\n&nbsp; &nbsp; &nbsp; &nbsp; return x\n</code></pre><p>答案：</p><pre><code class=\"language-python\">import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\n\ntransform = transforms.Compose([\n&nbsp; &nbsp; transforms.RandomResizedCrop((224,224)),\n&nbsp; &nbsp; transforms.ToTensor(),\n&nbsp; &nbsp; transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n&nbsp; &nbsp; ])\ncifar10_dataset = torchvision.datasets.CIFAR10(root='./data',\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;train=False,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;transform=transform,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;target_transform=None,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;download=True)\ndataloader = DataLoader(dataset=cifar10_dataset, # 传入的数据集, 必须参数\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;batch_size=32,&nbsp; &nbsp; &nbsp; &nbsp;# 输出的batch大小\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;shuffle=True,&nbsp; &nbsp; &nbsp; &nbsp;# 数据是否打乱\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;num_workers=2)&nbsp; &nbsp; &nbsp; # 进程数, 0表示只有主进程\n\nclass MyCNN(nn.Module):\n&nbsp; &nbsp; def __init__(self):\n&nbsp; &nbsp; &nbsp; &nbsp; super().__init__()\n&nbsp; &nbsp; &nbsp; &nbsp; self.conv1 = nn.Conv2d(3, 16, kernel_size=3)\n&nbsp; &nbsp; &nbsp; &nbsp; # conv1输出的特征图为222x222大小\n&nbsp; &nbsp; &nbsp; &nbsp; self.fc = nn.Linear(16 * 222 * 222, 10)\n\n&nbsp; &nbsp; def forward(self, input):\n&nbsp; &nbsp; &nbsp; &nbsp; x = self.conv1(input)\n&nbsp; &nbsp; &nbsp; &nbsp; # 进去全连接层之前，先将特征图铺平\n&nbsp; &nbsp; &nbsp; &nbsp; x = x.view(x.shape[0], -1)\n&nbsp; &nbsp; &nbsp; &nbsp; x = self.fc(x)\n&nbsp; &nbsp; &nbsp; &nbsp; return x\n&nbsp; &nbsp;&nbsp;\ncnn = MyCNN()\noptimizer = torch.optim.SGD(cnn.parameters(), lr=1e-5, weight_decay=1e-2, momentum=0.9)\n\n# 训练3个Epoch\nfor epoch in range(3):\n&nbsp; &nbsp; for step, (images, target) in enumerate(dataloader):\n&nbsp; &nbsp; &nbsp; &nbsp; output = cnn(images)\n\n&nbsp; &nbsp; &nbsp; &nbsp; loss = nn.CrossEntropyLoss()(output, target)\n&nbsp; &nbsp; &nbsp; &nbsp; print('Epoch: {} Step: {} Loss: {}'.format(epoch + 1 , step, loss))\n&nbsp; &nbsp; &nbsp; &nbsp; cnn.zero_grad()\n&nbsp; &nbsp; &nbsp; &nbsp; loss.backward()\n&nbsp; &nbsp; &nbsp; &nbsp; optimizer.step()\n</code></pre><h2><a href=\"https://time.geekbang.org/column/article/444252\">第15节课</a></h2><p>题目：参考Visdom快速上手中的例子，现在需要生成两组随机数，分别表示Loss和Accuracy。在迭代的过程中，如何用代码同时绘制出Loss和Accuracy两组数据呢？</p><p>答案：</p><pre><code class=\"language-python\">from visdom import Visdom\nimport numpy as np\nimport time\n\n# 实例化窗口\nviz = Visdom(port=6006)&nbsp;\n# 初始化窗口参数\nviz.line([[0.,0.]], [0.], \n         win='train', \n         opts=dict(title='loss&amp;acc', legend=['loss','acc'])\n         )\n\nfor step in range(10):\n&nbsp; &nbsp; loss = 0.2 * np.random.randn() + 1\n&nbsp; &nbsp; acc = 0.1 * np.random.randn() + 0.5\n&nbsp; &nbsp; # 更新窗口数据\n&nbsp; &nbsp; viz.line([[loss, acc]], [step], win='train', update='append')\n&nbsp; &nbsp; time.sleep(0.5)\n</code></pre><p>运行结果如图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/7e/18/7eecfc47a74d6fa319d45eb6092dec18.jpg?wh=1920x1075\" alt=\"图片\"></p><h2><a href=\"https://time.geekbang.org/column/article/445886\">第16节课</a></h2><p>题目：在torch.distributed.init_process_group(backend=“nccl”)函数中，backend参数可选哪些后端，它们分别有什么区别？</p><p>答案：backend参数指定的通信后端，包括NCCL、MPI、gloo。NCCL是Nvidia提供的官方多卡通信框架，相对比较高效；MPI也是高性能计算常用的通信协议，但是需要自己安装MPI实现框架，例如OpenMPI；gloo是内置通信后端，但不够高效。</p><h2><a href=\"https://time.geekbang.org/column/article/447503\">第18节课</a></h2><p>题目：老板希望你的模型能尽可能的把线上所有极客时间的海报都找到，允许一些误召回。训练模型的时候你应该侧重精确率还是召回率？</p><p>答案：侧重召回率。</p><h2><a href=\"https://time.geekbang.org/column/article/450898\">第19节课</a></h2><p>题目：对于这节课里讲的小猫分割问题，最终只输出1个特征图是否可以？</p><p>答案：可以的，因为小猫分割是一个二分类问题，可以将输出的特征图使用sigmoid函数将输出的数值转换为一个概率，从而进行判断。</p><h2><a href=\"https://time.geekbang.org/column/article/455415\">第20节课</a></h2><p>题目：图像分割的评价指标都有什么？</p><p>答案：mIoU和Dice系数。</p><h2><a href=\"https://time.geekbang.org/column/article/460504\">第21节课</a></h2><p>题目：TF-IDF有哪些缺点呢？你不妨结合它的计算过程做个梳理。</p><p>答案：TF-IDF认为文本频率小的单词就越重要，也就是区分性越强，但是实际上很多情况下，这并不正确。比如一篇财经类文章有一句“股价就跟火箭一样上了天”，这里的“火箭”就会变得非常重要，显然是错误的。怎么办呢？一般我们会对词频做一个条件过滤，比如超过多少次。也会对TF-IDF的公式进行改进，具体改进方法，如果有兴趣的话，你可以借助网络查找相应的文章。</p><h2><a href=\"https://time.geekbang.org/column/article/461691\">第22节课</a></h2><p>题目：词向量的长度多少比较合适呢？越长越好吗？</p><p>答案：不是的，越长的词向量尽管可以更加精细的表示词语的空间位置，但是也会带来计算量的暴涨、数据稀疏等问题，一般来说我们较多的选择64、128、256这样的长度，具体是多少，要靠实验来不断的确定。有的论文给出的建议是n&gt;8.33logN，具体是否可行，还是要结合实际情况来敲定。</p><h2><a href=\"https://time.geekbang.org/column/article/462524\">第23节课</a></h2><p>题目：利用今天训练的模型，编写一个函数predict_sentiment，实现输入一句话，输出这句话的情绪类别与概率。</p><p>例如：</p><pre><code class=\"language-python\">text = \"This film is terrible!\"\npredict_sentiment(text, model, tokenizer, vocab, device)\n'''\n输出：('neg', 0.8874172568321228)\n'''\n</code></pre><p>答案：参考代码如下。</p><pre><code class=\"language-python\"># 预测过程\ndef predict_sentiment(text, model, tokenizer, vocab, device):\n&nbsp; &nbsp; tokens = tokenizer(text)\n&nbsp; &nbsp; ids = [vocab[t] for t in tokens]\n&nbsp; &nbsp; length = torch.LongTensor([len(ids)])\n&nbsp; &nbsp; tensor = torch.LongTensor(ids).unsqueeze(dim=0).to(device)\n&nbsp; &nbsp; prediction = model(tensor, length).squeeze(dim=0)\n&nbsp; &nbsp; probability = torch.softmax(prediction, dim=-1)\n&nbsp; &nbsp; predicted_class = prediction.argmax(dim=-1).item()\n&nbsp; &nbsp; predicted_probability = probability[predicted_class].item()\n&nbsp; &nbsp; predicted_class = 'neg' if predicted_class == 0 else 'pos'\n&nbsp; &nbsp; return predicted_class, predicted_probability\n\n# 加载模型\nmodel.load_state_dict(torch.load('lstm.pt'))\n\ntext = \"This film is terrible!\"\npredict_sentiment(text, model, tokenizer, vocab, device)\n</code></pre><h2><a href=\"https://time.geekbang.org/column/article/464152\">第24节课</a></h2><p>题目：Bert处理文本是有最大长度要求的（512），那么遇到长文本，该怎么办呢？</p><p>答案：这是一个非常开放的问题，设置为最大512主要还是兼顾了效率问题，但还是有非常多的解决办法，比如我们之前提到过的关键词提取。或者分别从开头、中间、结尾选择一定长度的内容做运算。不过这些都是比较简单的办法。你还有更好的办法吗？欢迎留言给我。</p><h2><a href=\"https://time.geekbang.org/column/article/464870?\">第25节课</a></h2><p>题目：自2018年BERT被提出以来，获得了很大的成功，学术界陆续提出了各类相关模型，例如我们今天学习的BART。请你查一查还有哪些BERT系列的模型，并阅读相关论文，自行学习一下它们的原理与特点。</p><p>答案：</p><p><a href=\"https://arxiv.org/abs/1906.08237\">XLNet: Generalized Autoregressive Pretraining for Language Understanding</a></p><p><a href=\"https://arxiv.org/abs/1907.11692\">RoBERTa: A Robustly Optimized BERT Pretraining Approach</a></p><p><a href=\"https://arxiv.org/abs/1909.11942\">ALBERT: A Lite BERT for Self-supervised Learning of Language Representations</a></p><p>最后，再次祝愿你虎年快乐，学习进步，工作顺利！</p>","neighbors":{"left":{"article_title":"用户故事 | Tango：师傅领进门，修行在个人","id":469029},"right":{"article_title":"结束语｜人生充满选择，选择与努力同样重要","id":465858}},"comments":[]}