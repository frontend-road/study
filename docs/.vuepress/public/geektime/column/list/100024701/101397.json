{"id":101397,"title":"35 | 块设备（下）：如何建立代理商销售模式？","content":"<p>在<a href=\"https://time.geekbang.org/column/article/97876\">文件系统</a>那一节，我们讲了文件的写入，到了设备驱动这一层，就没有再往下分析。上一节我们又讲了mount一个块设备，将block_device信息放到了ext4文件系统的super_block里面，有了这些基础，是时候把整个写入的故事串起来了。</p><p>还记得咱们在文件系统那一节分析写入流程的时候，对于ext4文件系统，最后调用的是ext4_file_write_iter，它将I/O的调用分成两种情况：</p><p>第一是<strong>直接I/O</strong>。最终我们调用的是generic_file_direct_write，这里调用的是mapping-&gt;a_ops-&gt;direct_IO，实际调用的是ext4_direct_IO，往设备层写入数据。</p><p>第二种是<strong>缓存I/O</strong>。最终我们会将数据从应用拷贝到内存缓存中，但是这个时候，并不执行真正的I/O操作。它们只将整个页或其中部分标记为脏。写操作由一个timer触发，那个时候，才调用wb_workfn往硬盘写入页面。</p><p>接下来的调用链为：wb_workfn-&gt;wb_do_writeback-&gt;wb_writeback-&gt;writeback_sb_inodes-&gt;__writeback_single_inode-&gt;do_writepages。在do_writepages中，我们要调用mapping-&gt;a_ops-&gt;writepages，但实际调用的是ext4_writepages，往设备层写入数据。</p><!-- [[[read_end]]] --><p>这一节，我们就沿着这两种情况分析下去。</p><h2>直接I/O如何访问块设备？</h2><p>我们先来看第一种情况，直接I/O调用到ext4_direct_IO。</p><pre><code>static ssize_t ext4_direct_IO(struct kiocb *iocb, struct iov_iter *iter)\n{\n\tstruct file *file = iocb-&gt;ki_filp;\n\tstruct inode *inode = file-&gt;f_mapping-&gt;host;\n\tsize_t count = iov_iter_count(iter);\n\tloff_t offset = iocb-&gt;ki_pos;\n\tssize_t ret;\n......\n\tret = ext4_direct_IO_write(iocb, iter);\n......\n}\n\n\nstatic ssize_t ext4_direct_IO_write(struct kiocb *iocb, struct iov_iter *iter)\n{\n\tstruct file *file = iocb-&gt;ki_filp;\n\tstruct inode *inode = file-&gt;f_mapping-&gt;host;\n\tstruct ext4_inode_info *ei = EXT4_I(inode);\n\tssize_t ret;\n\tloff_t offset = iocb-&gt;ki_pos;\n\tsize_t count = iov_iter_count(iter);\n......\n\tret = __blockdev_direct_IO(iocb, inode, inode-&gt;i_sb-&gt;s_bdev, iter,\n\t\t\t\t   get_block_func, ext4_end_io_dio, NULL,\n\t\t\t\t   dio_flags);\n\n\n……\n}\n</code></pre><p>在ext4_direct_IO_write调用__blockdev_direct_IO，有个参数你需要特别注意一下，那就是inode-&gt;i_sb-&gt;s_bdev。通过当前文件的inode，我们可以得到super_block。这个super_block中的s_bdev，就是咱们上一节填进去的那个block_device。</p><p>__blockdev_direct_IO会调用do_blockdev_direct_IO，在这里面我们要准备一个struct dio结构和struct dio_submit结构，用来描述将要发生的写入请求。</p><pre><code>static inline ssize_t\ndo_blockdev_direct_IO(struct kiocb *iocb, struct inode *inode,\n\t\t      struct block_device *bdev, struct iov_iter *iter,\n\t\t      get_block_t get_block, dio_iodone_t end_io,\n\t\t      dio_submit_t submit_io, int flags)\n{\n\tunsigned i_blkbits = ACCESS_ONCE(inode-&gt;i_blkbits);\n\tunsigned blkbits = i_blkbits;\n\tunsigned blocksize_mask = (1 &lt;&lt; blkbits) - 1;\n\tssize_t retval = -EINVAL;\n\tsize_t count = iov_iter_count(iter);\n\tloff_t offset = iocb-&gt;ki_pos;\n\tloff_t end = offset + count;\n\tstruct dio *dio;\n\tstruct dio_submit sdio = { 0, };\n\tstruct buffer_head map_bh = { 0, };\n......\n\tdio = kmem_cache_alloc(dio_cache, GFP_KERNEL);\n\tdio-&gt;flags = flags;\n\tdio-&gt;i_size = i_size_read(inode);\n\tdio-&gt;inode = inode;\n\tif (iov_iter_rw(iter) == WRITE) {\n\t\tdio-&gt;op = REQ_OP_WRITE;\n\t\tdio-&gt;op_flags = REQ_SYNC | REQ_IDLE;\n\t\tif (iocb-&gt;ki_flags &amp; IOCB_NOWAIT)\n\t\t\tdio-&gt;op_flags |= REQ_NOWAIT;\n\t} else {\n\t\tdio-&gt;op = REQ_OP_READ;\n\t}\n\tsdio.blkbits = blkbits;\n\tsdio.blkfactor = i_blkbits - blkbits;\n\tsdio.block_in_file = offset &gt;&gt; blkbits;\n\n\n\tsdio.get_block = get_block;\n\tdio-&gt;end_io = end_io;\n\tsdio.submit_io = submit_io;\n\tsdio.final_block_in_bio = -1;\n\tsdio.next_block_for_io = -1;\n\n\n\tdio-&gt;iocb = iocb;\n\tdio-&gt;refcount = 1;\n\n\n\tsdio.iter = iter;\n\tsdio.final_block_in_request =\n\t\t(offset + iov_iter_count(iter)) &gt;&gt; blkbits;\n......\n\tsdio.pages_in_io += iov_iter_npages(iter, INT_MAX);\n\n\n\tretval = do_direct_IO(dio, &amp;sdio, &amp;map_bh);\n.....\n}\n</code></pre><p>do_direct_IO里面有两层循环，第一层循环是依次处理这次要写入的所有块。对于每一块，取出对应的内存中的页page，在这一块中，有写入的起始地址from和终止地址to，所以，第二层循环就是依次处理from到to的数据，调用submit_page_section，提交到块设备层进行写入。</p><pre><code>static int do_direct_IO(struct dio *dio, struct dio_submit *sdio,\n\t\t\tstruct buffer_head *map_bh)\n{\n\tconst unsigned blkbits = sdio-&gt;blkbits;\n\tconst unsigned i_blkbits = blkbits + sdio-&gt;blkfactor;\n\tint ret = 0;\n\n\n\twhile (sdio-&gt;block_in_file &lt; sdio-&gt;final_block_in_request) {\n\t\tstruct page *page;\n\t\tsize_t from, to;\n\n\n\t\tpage = dio_get_page(dio, sdio);\n        from = sdio-&gt;head ? 0 : sdio-&gt;from;\n\t\tto = (sdio-&gt;head == sdio-&gt;tail - 1) ? sdio-&gt;to : PAGE_SIZE;\n\t\tsdio-&gt;head++;\n\n\n\t\twhile (from &lt; to) {\n\t\t\tunsigned this_chunk_bytes;\t/* # of bytes mapped */\n\t\t\tunsigned this_chunk_blocks;\t/* # of blocks */\n......\n            ret = submit_page_section(dio, sdio, page,\n\t\t\t\t\t\t  from,\n\t\t\t\t\t\t  this_chunk_bytes,\n\t\t\t\t\t\t  sdio-&gt;next_block_for_io,\n\t\t\t\t\t\t  map_bh);\n......\n\t\t\tsdio-&gt;next_block_for_io += this_chunk_blocks;\n\t\t\tsdio-&gt;block_in_file += this_chunk_blocks;\n\t\t\tfrom += this_chunk_bytes;\n\t\t\tdio-&gt;result += this_chunk_bytes;\n\t\t\tsdio-&gt;blocks_available -= this_chunk_blocks;\n\t\t\tif (sdio-&gt;block_in_file == sdio-&gt;final_block_in_request)\n\t\t\t\tbreak;\n......\n        }\n    }\n}\n</code></pre><p>submit_page_section会调用dio_bio_submit，进而调用submit_bio向块设备层提交数据。其中，参数struct bio是将数据传给块设备的通用传输对象。定义如下：</p><pre><code>/**\n * submit_bio - submit a bio to the block device layer for I/O\n * @bio: The &amp;struct bio which describes the I/O\n */\nblk_qc_t submit_bio(struct bio *bio)\n{\n......\n  return generic_make_request(bio);\n}\n</code></pre><h2>缓存I/O如何访问块设备？</h2><p>我们再来看第二种情况，缓存I/O调用到ext4_writepages。这个函数比较长，我们这里只截取最重要的部分来讲解。</p><pre><code>static int ext4_writepages(struct address_space *mapping,\n\t\t\t   struct writeback_control *wbc)\n{\n......\n\tstruct mpage_da_data mpd;\n\tstruct inode *inode = mapping-&gt;host;\n\tstruct ext4_sb_info *sbi = EXT4_SB(mapping-&gt;host-&gt;i_sb);\n......\n\tmpd.do_map = 0;\n\tmpd.io_submit.io_end = ext4_init_io_end(inode, GFP_KERNEL);\n\tret = mpage_prepare_extent_to_map(&amp;mpd);\n\t/* Submit prepared bio */\n\text4_io_submit(&amp;mpd.io_submit);\n......\n}\n</code></pre><p>这里比较重要的一个数据结构是struct mpage_da_data。这里面有文件的inode、要写入的页的偏移量，还有一个重要的struct ext4_io_submit，里面有通用传输对象bio。</p><pre><code>struct mpage_da_data {\n\tstruct inode *inode;\n......\n\tpgoff_t first_page;\t/* The first page to write */\n\tpgoff_t next_page;\t/* Current page to examine */\n\tpgoff_t last_page;\t/* Last page to examine */\n\tstruct ext4_map_blocks map;\n\tstruct ext4_io_submit io_submit;\t/* IO submission data */\n\tunsigned int do_map:1;\n};\n\n\nstruct ext4_io_submit {\n......\n\tstruct bio\t\t*io_bio;\n\text4_io_end_t\t\t*io_end;\n\tsector_t\t\tio_next_block;\n};\n</code></pre><p>在ext4_writepages中，mpage_prepare_extent_to_map用于初始化这个struct mpage_da_data结构。接下来的调用链为：mpage_prepare_extent_to_map-&gt;mpage_process_page_bufs-&gt;mpage_submit_page-&gt;ext4_bio_write_page-&gt;io_submit_add_bh。</p><p>在io_submit_add_bh中，此时的bio还是空的，因而我们要调用io_submit_init_bio，初始化bio。</p><pre><code>static int io_submit_init_bio(struct ext4_io_submit *io,\n\t\t\t      struct buffer_head *bh)\n{\n\tstruct bio *bio;\n\n\n\tbio = bio_alloc(GFP_NOIO, BIO_MAX_PAGES);\n\tif (!bio)\n\t\treturn -ENOMEM;\n\twbc_init_bio(io-&gt;io_wbc, bio);\n\tbio-&gt;bi_iter.bi_sector = bh-&gt;b_blocknr * (bh-&gt;b_size &gt;&gt; 9);\n\tbio-&gt;bi_bdev = bh-&gt;b_bdev;\n\tbio-&gt;bi_end_io = ext4_end_bio;\n\tbio-&gt;bi_private = ext4_get_io_end(io-&gt;io_end);\n\tio-&gt;io_bio = bio;\n\tio-&gt;io_next_block = bh-&gt;b_blocknr;\n\treturn 0;\n}\n\n</code></pre><p>我们再回到ext4_writepages中。在bio初始化完之后，我们要调用ext4_io_submit，提交I/O。在这里我们又是调用submit_bio，向块设备层传输数据。ext4_io_submit的实现如下：</p><pre><code>void ext4_io_submit(struct ext4_io_submit *io)\n{\n\tstruct bio *bio = io-&gt;io_bio;\n\n\n\tif (bio) {\n\t\tint io_op_flags = io-&gt;io_wbc-&gt;sync_mode == WB_SYNC_ALL ?\n\t\t\t\t  REQ_SYNC : 0;\n\t\tio-&gt;io_bio-&gt;bi_write_hint = io-&gt;io_end-&gt;inode-&gt;i_write_hint;\n\t\tbio_set_op_attrs(io-&gt;io_bio, REQ_OP_WRITE, io_op_flags);\n\t\tsubmit_bio(io-&gt;io_bio);\n\t}\n\tio-&gt;io_bio = NULL;\n}\n\n</code></pre><h2>如何向块设备层提交请求？</h2><p>既然不管是直接I/O，还是缓存I/O，最后都到了submit_bio里面，那我们就来重点分析一下它。</p><p>submit_bio会调用generic_make_request。代码如下：</p><pre><code>blk_qc_t generic_make_request(struct bio *bio)\n{\n\t/*\n\t * bio_list_on_stack[0] contains bios submitted by the current\n\t * make_request_fn.\n\t * bio_list_on_stack[1] contains bios that were submitted before\n\t * the current make_request_fn, but that haven't been processed\n\t * yet.\n\t */\n\tstruct bio_list bio_list_on_stack[2];\n\tblk_qc_t ret = BLK_QC_T_NONE;\n......\n\tif (current-&gt;bio_list) {\n\t\tbio_list_add(&amp;current-&gt;bio_list[0], bio);\n\t\tgoto out;\n\t}\n\n\n\tbio_list_init(&amp;bio_list_on_stack[0]);\n\tcurrent-&gt;bio_list = bio_list_on_stack;\n\tdo {\n\t\tstruct request_queue *q = bdev_get_queue(bio-&gt;bi_bdev);\n\n\n\t\tif (likely(blk_queue_enter(q, bio-&gt;bi_opf &amp; REQ_NOWAIT) == 0)) {\n\t\t\tstruct bio_list lower, same;\n\n\n\t\t\t/* Create a fresh bio_list for all subordinate requests */\n\t\t\tbio_list_on_stack[1] = bio_list_on_stack[0];\n\t\t\tbio_list_init(&amp;bio_list_on_stack[0]);\n\t\t\tret = q-&gt;make_request_fn(q, bio);\n\n\n\t\t\tblk_queue_exit(q);\n\n\n\t\t\t/* sort new bios into those for a lower level\n\t\t\t * and those for the same level\n\t\t\t */\n\t\t\tbio_list_init(&amp;lower);\n\t\t\tbio_list_init(&amp;same);\n\t\t\twhile ((bio = bio_list_pop(&amp;bio_list_on_stack[0])) != NULL)\n\t\t\t\tif (q == bdev_get_queue(bio-&gt;bi_bdev))\n\t\t\t\t\tbio_list_add(&amp;same, bio);\n\t\t\t\telse\n\t\t\t\t\tbio_list_add(&amp;lower, bio);\n\t\t\t/* now assemble so we handle the lowest level first */\n\t\t\tbio_list_merge(&amp;bio_list_on_stack[0], &amp;lower);\n\t\t\tbio_list_merge(&amp;bio_list_on_stack[0], &amp;same);\n\t\t\tbio_list_merge(&amp;bio_list_on_stack[0], &amp;bio_list_on_stack[1]);\n\t\t} \n......\n\t\tbio = bio_list_pop(&amp;bio_list_on_stack[0]);\n\t} while (bio);\n\tcurrent-&gt;bio_list = NULL; /* deactivate */\nout:\n\treturn ret;\n}\n</code></pre><p>这里的逻辑有点复杂，我们先来看大的逻辑。在do-while中，我们先是获取一个请求队列request_queue，然后调用这个队列的make_request_fn函数。</p><h3>块设备队列结构</h3><p>如果再来看struct block_device结构和struct gendisk结构，我们会发现，每个块设备都有一个请求队列struct request_queue，用于处理上层发来的请求。</p><p>在每个块设备的驱动程序初始化的时候，会生成一个request_queue。</p><pre><code>struct request_queue {\n\t/*\n\t * Together with queue_head for cacheline sharing\n\t */\n\tstruct list_head\tqueue_head;\n\tstruct request\t\t*last_merge;\n\tstruct elevator_queue\t*elevator;\n......\n\trequest_fn_proc\t\t*request_fn;\n\tmake_request_fn\t\t*make_request_fn;\n......\n}\n</code></pre><p>在请求队列request_queue上，首先是有一个链表list_head，保存请求request。</p><pre><code>struct request {\n\tstruct list_head queuelist;\n......\n\tstruct request_queue *q;\n......\n\tstruct bio *bio;\n\tstruct bio *biotail;\n......\n}\n</code></pre><p>每个request包括一个链表的struct bio，有指针指向一头一尾。</p><pre><code>struct bio {\n\tstruct bio\t\t*bi_next;\t/* request queue link */\n\tstruct block_device\t*bi_bdev;\n\tblk_status_t\t\tbi_status;\n......\n    struct bvec_iter\tbi_iter;\n\tunsigned short\t\tbi_vcnt;\t/* how many bio_vec's */\n\tunsigned short\t\tbi_max_vecs;\t/* max bvl_vecs we can hold */\n\tatomic_t\t\t__bi_cnt;\t/* pin count */\n\tstruct bio_vec\t\t*bi_io_vec;\t/* the actual vec list */\n......\n};\n\n\nstruct bio_vec {\n\tstruct page\t*bv_page;\n\tunsigned int\tbv_len;\n\tunsigned int\tbv_offset;\n}\n</code></pre><p>在bio中，bi_next是链表中的下一项，struct bio_vec指向一组页面。</p><p><img src=\"https://static001.geekbang.org/resource/image/3c/0e/3c473d163b6e90985d7301f115ab660e.jpeg?wh=1289*2930\" alt=\"\"></p><p>在请求队列request_queue上，还有两个重要的函数，一个是make_request_fn函数，用于生成request；另一个是request_fn函数，用于处理request。</p><h3>块设备的初始化</h3><p>我们还是以scsi驱动为例。在初始化设备驱动的时候，我们会调用scsi_alloc_queue，把request_fn设置为scsi_request_fn。我们还会调用blk_init_allocated_queue-&gt;blk_queue_make_request，把make_request_fn设置为blk_queue_bio。</p><pre><code>/**\n * scsi_alloc_sdev - allocate and setup a scsi_Device\n * @starget: which target to allocate a &amp;scsi_device for\n * @lun: which lun\n * @hostdata: usually NULL and set by -&gt;slave_alloc instead\n *\n * Description:\n *     Allocate, initialize for io, and return a pointer to a scsi_Device.\n *     Stores the @shost, @channel, @id, and @lun in the scsi_Device, and\n *     adds scsi_Device to the appropriate list.\n *\n * Return value:\n *     scsi_Device pointer, or NULL on failure.\n **/\nstatic struct scsi_device *scsi_alloc_sdev(struct scsi_target *starget,\n\t\t\t\t\t   u64 lun, void *hostdata)\n{\n\tstruct scsi_device *sdev;\n\tsdev = kzalloc(sizeof(*sdev) + shost-&gt;transportt-&gt;device_size,\n\t\t       GFP_ATOMIC);\n......\n\tsdev-&gt;request_queue = scsi_alloc_queue(sdev);\n......\n}\n\n\nstruct request_queue *scsi_alloc_queue(struct scsi_device *sdev)\n{\n\tstruct Scsi_Host *shost = sdev-&gt;host;\n\tstruct request_queue *q;\n\n\n\tq = blk_alloc_queue_node(GFP_KERNEL, NUMA_NO_NODE);\n\tif (!q)\n\t\treturn NULL;\n\tq-&gt;cmd_size = sizeof(struct scsi_cmnd) + shost-&gt;hostt-&gt;cmd_size;\n\tq-&gt;rq_alloc_data = shost;\n\tq-&gt;request_fn = scsi_request_fn;\n\tq-&gt;init_rq_fn = scsi_init_rq;\n\tq-&gt;exit_rq_fn = scsi_exit_rq;\n\tq-&gt;initialize_rq_fn = scsi_initialize_rq;\n\n\n    //调用blk_queue_make_request(q, blk_queue_bio);\n\tif (blk_init_allocated_queue(q) &lt; 0) {\n\t\tblk_cleanup_queue(q);\n\t\treturn NULL;\n\t}\n\n\n\t__scsi_init_queue(shost, q);\n......\n\treturn q\n}\n</code></pre><p>在blk_init_allocated_queue中，除了初始化make_request_fn函数，我们还要做一件很重要的事情，就是初始化I/O的电梯算法。</p><pre><code>int blk_init_allocated_queue(struct request_queue *q)\n{\n\tq-&gt;fq = blk_alloc_flush_queue(q, NUMA_NO_NODE, q-&gt;cmd_size);\n......\n\tblk_queue_make_request(q, blk_queue_bio);\n......\n\t/* init elevator */\n\tif (elevator_init(q, NULL)) {\n......\n\t}\n......\n}\n</code></pre><p>电梯算法有很多种类型，定义为elevator_type。下面我来逐一说一下。</p><ul>\n<li><strong>struct elevator_type elevator_noop</strong></li>\n</ul><p>Noop调度算法是最简单的IO调度算法，它将IO请求放入到一个FIFO队列中，然后逐个执行这些IO请求。</p><ul>\n<li><strong>struct elevator_type iosched_deadline</strong></li>\n</ul><p>Deadline算法要保证每个IO请求在一定的时间内一定要被服务到，以此来避免某个请求饥饿。为了完成这个目标，算法中引入了两类队列，一类队列用来对请求按起始扇区序号进行排序，通过红黑树来组织，我们称为sort_list，按照此队列传输性能会比较高；另一类队列对请求按它们的生成时间进行排序，由链表来组织，称为fifo_list，并且每一个请求都有一个期限值。</p><ul>\n<li><strong>struct elevator_type iosched_cfq</strong></li>\n</ul><p>又看到了熟悉的CFQ完全公平调度算法。所有的请求会在多个队列中排序。同一个进程的请求，总是在同一队列中处理。时间片会分配到每个队列，通过轮询算法，我们保证了I/O带宽，以公平的方式，在不同队列之间进行共享。</p><p>elevator_init中会根据名称来指定电梯算法，如果没有选择，那就默认使用iosched_cfq。</p><h3>请求提交与调度</h3><p>接下来，我们回到generic_make_request函数中。调用队列的make_request_fn函数，其实就是调用blk_queue_bio。</p><pre><code>static blk_qc_t blk_queue_bio(struct request_queue *q, struct bio *bio)\n{\n\tstruct request *req, *free;\n\tunsigned int request_count = 0;\n......\n\tswitch (elv_merge(q, &amp;req, bio)) {\n\tcase ELEVATOR_BACK_MERGE:\n\t\tif (!bio_attempt_back_merge(q, req, bio))\n\t\t\tbreak;\n\t\telv_bio_merged(q, req, bio);\n\t\tfree = attempt_back_merge(q, req);\n\t\tif (free)\n\t\t\t__blk_put_request(q, free);\n\t\telse\n\t\t\telv_merged_request(q, req, ELEVATOR_BACK_MERGE);\n\t\tgoto out_unlock;\n\tcase ELEVATOR_FRONT_MERGE:\n\t\tif (!bio_attempt_front_merge(q, req, bio))\n\t\t\tbreak;\n\t\telv_bio_merged(q, req, bio);\n\t\tfree = attempt_front_merge(q, req);\n\t\tif (free)\n\t\t\t__blk_put_request(q, free);\n\t\telse\n\t\t\telv_merged_request(q, req, ELEVATOR_FRONT_MERGE);\n\t\tgoto out_unlock;\n\tdefault:\n\t\tbreak;\n\t}\n\n\nget_rq:\n\treq = get_request(q, bio-&gt;bi_opf, bio, GFP_NOIO);\n......\n\tblk_init_request_from_bio(req, bio);\n......\n\tadd_acct_request(q, req, where);\n\t__blk_run_queue(q);\nout_unlock:\n......\n\treturn BLK_QC_T_NONE;\n}\n</code></pre><p>blk_queue_bio首先做的一件事情是调用elv_merge来判断，当前这个bio请求是否能够和目前已有的request合并起来，成为同一批I/O操作，从而提高读取和写入的性能。</p><p>判断标准和struct bio的成员struct bvec_iter有关，它里面有两个变量，一个是起始磁盘簇bi_sector，另一个是大小bi_size。</p><pre><code>enum elv_merge elv_merge(struct request_queue *q, struct request **req,\n\t\tstruct bio *bio)\n{\n\tstruct elevator_queue *e = q-&gt;elevator;\n\tstruct request *__rq;\n......\n\tif (q-&gt;last_merge &amp;&amp; elv_bio_merge_ok(q-&gt;last_merge, bio)) {\n\t\tenum elv_merge ret = blk_try_merge(q-&gt;last_merge, bio);\n\n\n\t\tif (ret != ELEVATOR_NO_MERGE) {\n\t\t\t*req = q-&gt;last_merge;\n\t\t\treturn ret;\n\t\t}\n\t}\n......\n\t__rq = elv_rqhash_find(q, bio-&gt;bi_iter.bi_sector);\n\tif (__rq &amp;&amp; elv_bio_merge_ok(__rq, bio)) {\n\t\t*req = __rq;\n\t\treturn ELEVATOR_BACK_MERGE;\n\t}\n\n\n\tif (e-&gt;uses_mq &amp;&amp; e-&gt;type-&gt;ops.mq.request_merge)\n\t\treturn e-&gt;type-&gt;ops.mq.request_merge(q, req, bio);\n\telse if (!e-&gt;uses_mq &amp;&amp; e-&gt;type-&gt;ops.sq.elevator_merge_fn)\n\t\treturn e-&gt;type-&gt;ops.sq.elevator_merge_fn(q, req, bio);\n\n\n\treturn ELEVATOR_NO_MERGE;\n}\n</code></pre><p>elv_merge尝试了三次合并。</p><p>第一次，它先判断和上一次合并的request能不能再次合并，看看能不能赶上马上要走的这部电梯。在blk_try_merge主要做了这样的判断：如果blk_rq_pos(rq) + blk_rq_sectors(rq) == bio-&gt;bi_iter.bi_sector，也就是说这个request的起始地址加上它的大小（其实是这个request的结束地址），如果和bio的起始地址能接得上，那就把bio放在request的最后，我们称为ELEVATOR_BACK_MERGE。</p><p>如果blk_rq_pos(rq) - bio_sectors(bio) == bio-&gt;bi_iter.bi_sector，也就是说，这个request的起始地址减去bio的大小等于bio的起始地址，这说明bio放在request的最前面能够接得上，那就把bio放在request的最前面，我们称为ELEVATOR_FRONT_MERGE。否则，那就不合并，我们称为ELEVATOR_NO_MERGE。</p><pre><code>enum elv_merge blk_try_merge(struct request *rq, struct bio *bio)\n{\n......\n    if (blk_rq_pos(rq) + blk_rq_sectors(rq) == bio-&gt;bi_iter.bi_sector)\n\t\treturn ELEVATOR_BACK_MERGE;\n\telse if (blk_rq_pos(rq) - bio_sectors(bio) == bio-&gt;bi_iter.bi_sector)\n\t\treturn ELEVATOR_FRONT_MERGE;\n\treturn ELEVATOR_NO_MERGE;\n}\n</code></pre><p>第二次，如果和上一个合并过的request无法合并，那我们就调用elv_rqhash_find。然后按照bio的起始地址查找request，看有没有能够合并的。如果有的话，因为是按照起始地址找的，应该接在人家的后面，所以是ELEVATOR_BACK_MERGE。</p><p>第三次，调用elevator_merge_fn试图合并。对于iosched_cfq，调用的是cfq_merge。在这里面，cfq_find_rq_fmerge会调用elv_rb_find函数，里面的参数是bio的结束地址。我们还是要看，能不能找到可以合并的。如果有的话，因为是按照结束地址找的，应该接在人家前面，所以是ELEVATOR_FRONT_MERGE。</p><pre><code>static enum elv_merge cfq_merge(struct request_queue *q, struct request **req,\n\t\t     struct bio *bio)\n{\n\tstruct cfq_data *cfqd = q-&gt;elevator-&gt;elevator_data;\n\tstruct request *__rq;\n\n\n\t__rq = cfq_find_rq_fmerge(cfqd, bio);\n\tif (__rq &amp;&amp; elv_bio_merge_ok(__rq, bio)) {\n\t\t*req = __rq;\n\t\treturn ELEVATOR_FRONT_MERGE;\n\t}\n\n\n\treturn ELEVATOR_NO_MERGE;\n}\n\n\nstatic struct request *\ncfq_find_rq_fmerge(struct cfq_data *cfqd, struct bio *bio)\n{\n\tstruct task_struct *tsk = current;\n\tstruct cfq_io_cq *cic;\n\tstruct cfq_queue *cfqq;\n\n\n\tcic = cfq_cic_lookup(cfqd, tsk-&gt;io_context);\n\tif (!cic)\n\t\treturn NULL;\n\n\n\tcfqq = cic_to_cfqq(cic, op_is_sync(bio-&gt;bi_opf));\n\tif (cfqq)\n\t\treturn elv_rb_find(&amp;cfqq-&gt;sort_list, bio_end_sector(bio));\n\n\n\treturn NUL\n}\n</code></pre><p>等从elv_merge返回blk_queue_bio的时候，我们就知道，应该做哪种类型的合并，接着就要进行真的合并。如果没有办法合并，那就调用get_request，创建一个新的request，调用blk_init_request_from_bio，将bio放到新的request里面，然后调用add_acct_request，把新的request加到request_queue队列中。</p><p>至此，我们解析完了generic_make_request中最重要的两大逻辑：获取一个请求队列request_queue和调用这个队列的make_request_fn函数。</p><p>其实，generic_make_request其他部分也很令人困惑。感觉里面有特别多的struct bio_list，倒腾过来，倒腾过去的。这是因为，很多块设备是有层次的。</p><p>比如，我们用两块硬盘组成RAID，两个RAID盘组成LVM，然后我们就可以在LVM上创建一个块设备给用户用，我们称接近用户的块设备为<strong>高层次的块设备</strong>，接近底层的块设备为<strong>低层次</strong>（lower）<strong>的块设备</strong>。这样，generic_make_request把I/O请求发送给高层次的块设备的时候，会调用高层块设备的make_request_fn，高层块设备又要调用generic_make_request，将请求发送给低层次的块设备。虽然块设备的层次不会太多，但是对于代码generic_make_request来讲，这可是递归的调用，一不小心，就会递归过深，无法正常退出，而且内核栈的大小又非常有限，所以要比较小心。</p><p>这里你是否理解了struct bio_list bio_list_on_stack[2]的名字为什么叫stack呢？其实，将栈的操作变成对于队列的操作，队列不在栈里面，会大很多。每次generic_make_request被当前任务调用的时候，将current-&gt;bio_list设置为bio_list_on_stack，并在generic_make_request的一开始就判断current-&gt;bio_list是否为空。如果不为空，说明已经在generic_make_request的调用里面了，就不必调用make_request_fn进行递归了，直接把请求加入到bio_list里面就可以了，这就实现了递归的及时退出。</p><p>如果current-&gt;bio_list为空，那我们就将current-&gt;bio_list设置为bio_list_on_stack后，进入do-while循环，做咱们分析过的generic_make_request的两大逻辑。但是，当前的队列调用make_request_fn的时候，在make_request_fn的具体实现中，会生成新的bio。调用更底层的块设备，也会生成新的bio，都会放在bio_list_on_stack的队列中，是一个边处理还边创建的过程。</p><p>bio_list_on_stack[1] = bio_list_on_stack[0]这一句在make_request_fn之前，将之前队列里面遗留没有处理的保存下来，接着bio_list_init将bio_list_on_stack[0]设置为空，然后调用make_request_fn，在make_request_fn里面如果有新的bio生成，都会加到bio_list_on_stack[0]这个队列里面来。</p><p>make_request_fn执行完毕后，可以想象bio_list_on_stack[0]可能又多了一些bio了，接下来的循环中调用bio_list_pop将bio_list_on_stack[0]积攒的bio拿出来，分别放在两个队列lower和same中，顾名思义，lower就是更低层次的块设备的bio，same是同层次的块设备的bio。</p><p>接下来我们能将lower、same以及bio_list_on_stack[1] 都取出来，放在bio_list_on_stack[0]统一进行处理。当然应该lower优先了，因为只有底层的块设备的I/O做完了，上层的块设备的I/O才能做完。</p><p>到这里，generic_make_request的逻辑才算解析完毕。对于写入的数据来讲，其实仅仅是将bio请求放在请求队列上，设备驱动程序还没往设备里面写呢。</p><h3>请求的处理</h3><p>设备驱动程序往设备里面写，调用的是请求队列request_queue的另外一个函数request_fn。对于scsi设备来讲，调用的是scsi_request_fn。</p><pre><code>static void scsi_request_fn(struct request_queue *q)\n\t__releases(q-&gt;queue_lock)\n\t__acquires(q-&gt;queue_lock)\n{\n\tstruct scsi_device *sdev = q-&gt;queuedata;\n\tstruct Scsi_Host *shost;\n\tstruct scsi_cmnd *cmd;\n\tstruct request *req;\n\n\n\t/*\n\t * To start with, we keep looping until the queue is empty, or until\n\t * the host is no longer able to accept any more requests.\n\t */\n\tshost = sdev-&gt;host;\n\tfor (;;) {\n\t\tint rtn;\n\t\t/*\n\t\t * get next queueable request.  We do this early to make sure\n\t\t * that the request is fully prepared even if we cannot\n\t\t * accept it.\n\t\t */\n\t\treq = blk_peek_request(q);\n......\n\t\t/*\n\t\t * Remove the request from the request list.\n\t\t */\n\t\tif (!(blk_queue_tagged(q) &amp;&amp; !blk_queue_start_tag(q, req)))\n\t\t\tblk_start_request(req);\n.....\n\t\tcmd = req-&gt;special;\n......\n\t\t/*\n\t\t * Dispatch the command to the low-level driver.\n\t\t */\n\t\tcmd-&gt;scsi_done = scsi_done;\n\t\trtn = scsi_dispatch_cmd(cmd);\n......\n\t}\n\treturn;\n......\n}\n</code></pre><p>在这里面是一个for无限循环，从request_queue中读取request，然后封装更加底层的指令，给设备控制器下指令，实施真正的I/O操作。</p><h2>总结时刻</h2><p>这一节我们讲了如何将块设备I/O请求送达到外部设备。</p><p>对于块设备的I/O操作分为两种，一种是直接I/O，另一种是缓存I/O。无论是哪种I/O，最终都会调用submit_bio提交块设备I/O请求。</p><p>对于每一种块设备，都有一个gendisk表示这个设备，它有一个请求队列，这个队列是一系列的request对象。每个request对象里面包含多个BIO对象，指向page cache。所谓的写入块设备，I/O就是将page cache里面的数据写入硬盘。</p><p>对于请求队列来讲，还有两个函数，一个函数叫make_request_fn函数，用于将请求放入队列。submit_bio会调用generic_make_request，然后调用这个函数。</p><p>另一个函数往往在设备驱动程序里实现，我们叫request_fn函数，它用于从队列里面取出请求来，写入外部设备。</p><p><img src=\"https://static001.geekbang.org/resource/image/c9/3c/c9f6a08075ba4eae3314523fa258363c.png?wh=2248*2023\" alt=\"\"></p><p>至此，整个写入文件的过程才算完全结束。这真是个复杂的过程，涉及系统调用、内存管理、文件系统和输入输出。这足以说明，操作系统真的是一个非常复杂的体系，环环相扣，需要分层次层层展开来学习。</p><p>到这里，专栏已经过半了，你应该能发现，很多我之前说“后面会细讲”的东西，现在正在一点一点解释清楚，而文中越来越多出现“前面我们讲过”的字眼，你是否当时学习前面知识的时候，没有在意，导致学习后面的知识产生困惑了呢？没关系，及时倒回去复习，再回过头去看，当初学过的很多知识会变得清晰很多。</p><h2>课堂练习</h2><p>你知道如何查看磁盘调度算法、修改磁盘调度算法以及I/O队列的长度吗？</p><p>欢迎留言和我分享你的疑惑和见解 ，也欢迎可以收藏本节内容，反复研读。你也可以把今天的内容分享给你的朋友，和他一起学习和进步。</p><p><img src=\"https://static001.geekbang.org/resource/image/8c/37/8c0a95fa07a8b9a1abfd394479bdd637.jpg?wh=1110*659\" alt=\"\"></p>","neighbors":{"left":{"article_title":"34 | 块设备（上）：如何建立代理商销售模式？","id":100942},"right":{"article_title":"36 | 进程间通信：遇到大项目需要项目组之间的合作才行","id":101719}},"comments":[{"had_liked":false,"id":106068,"user_name":"Leon📷","can_delete":false,"product_type":"c1","uid":1219496,"ip_address":"","ucode":"B9BBD1EFAAE5A2","user_header":"https://static001.geekbang.org/account/avatar/00/12/9b/a8/6a391c66.jpg","comment_is_top":false,"comment_ctime":1561163872,"is_pvip":false,"replies":[{"id":"48873","content":"是的","user_name":"作者回复","comment_id":106068,"uid":"1001590","ip_address":"","utype":1,"ctime":1567502465,"user_name_real":"刘超@网易云"}],"discussion_count":1,"race_medal":0,"score":"70280640608","product_id":100024701,"comment_content":"文件系统中的page_cache对应逻辑上的块的概念，将page_cache打包成bio递交给通用块设备层，通用块设备层将多个bio打包成一个请求request, 尽量把bio对应的sector临近的数据合并，提交给块设备调度层，块设备调度层就是把各个request当成段提交给设备驱动程序，因为设备驱动程序只识别段，也就是说通用块设备层捣腾的其实就是把bio对应的页框和在磁盘中对应的sector进行合并的过程，调度层只负责把合并的request放进队列，用调度算法下发给驱动程序处理，其实所有复杂的合并操作以及内存和磁盘扇区的对应关系都是通过块设备层做了，老师，可以这么理解吧","like_count":17,"discussions":[{"author":{"id":1001590,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/48/76/0c7d4d23.jpg","nickname":"刘超","note":"","ucode":"196BF3F499E8FE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454934,"discussion_content":"是的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567502465,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":136806,"user_name":"hello","can_delete":false,"product_type":"c1","uid":1510495,"ip_address":"","ucode":"C6FC61A90F202B","user_header":"https://static001.geekbang.org/account/avatar/00/17/0c/5f/4cbcbfb9.jpg","comment_is_top":false,"comment_ctime":1569513223,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"31634284295","product_id":100024701,"comment_content":"太爽了，听了三四遍这节课，以前一直担心io在内核内部会发生多次拷贝，听完发现并没有。下一次我一定要边读源码边听。","like_count":7},{"had_liked":false,"id":106452,"user_name":"djfhchdh","can_delete":false,"product_type":"c1","uid":1484184,"ip_address":"","ucode":"E71D75328CE398","user_header":"https://static001.geekbang.org/account/avatar/00/16/a5/98/a65ff31a.jpg","comment_is_top":false,"comment_ctime":1561305640,"is_pvip":false,"replies":[{"id":"38646","content":"赞","user_name":"作者回复","comment_id":106452,"uid":"1001590","ip_address":"","utype":1,"ctime":1561420019,"user_name_real":"刘超@网易云"}],"discussion_count":1,"race_medal":0,"score":"27331109416","product_id":100024701,"comment_content":"&#47;sys&#47;block&#47;xvda&#47;queue&#47;scheduler 磁盘的调度算法，临时修改：echo noop &gt; &#47;sys&#47;block&#47;xvda&#47;queue&#47;scheduler，永久修改就需要修改内核参数，然后重启。<br>iostat -d  -x 中的avgqu-sz是平均I&#47;O队列长度。<br>","like_count":6,"discussions":[{"author":{"id":1001590,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/48/76/0c7d4d23.jpg","nickname":"刘超","note":"","ucode":"196BF3F499E8FE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":455095,"discussion_content":"赞","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561420019,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":104601,"user_name":"Leon📷","can_delete":false,"product_type":"c1","uid":1219496,"ip_address":"","ucode":"B9BBD1EFAAE5A2","user_header":"https://static001.geekbang.org/account/avatar/00/12/9b/a8/6a391c66.jpg","comment_is_top":false,"comment_ctime":1560782012,"is_pvip":false,"replies":[{"id":"49023","content":"是的","user_name":"作者回复","comment_id":104601,"uid":"1001590","ip_address":"","utype":1,"ctime":1567580353,"user_name_real":"刘超@网易云"}],"discussion_count":1,"race_medal":0,"score":"23035618492","product_id":100024701,"comment_content":"那个队列，队头和队尾的合并都是为了所谓的顺序写，减少机械硬盘寻址消耗吧，能赶上就上同一辆车，赶不上自己叫一辆车等满了再走，但是也是有超时等待时间的，可以这么理解吧","like_count":6,"discussions":[{"author":{"id":1001590,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/48/76/0c7d4d23.jpg","nickname":"刘超","note":"","ucode":"196BF3F499E8FE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454338,"discussion_content":"是的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567580353,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":104360,"user_name":"安排","can_delete":false,"product_type":"c1","uid":1260026,"ip_address":"","ucode":"F78CFA9624CAEF","user_header":"https://static001.geekbang.org/account/avatar/00/13/39/fa/a7edbc72.jpg","comment_is_top":false,"comment_ctime":1560736822,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"18740606006","product_id":100024701,"comment_content":"看了一点儿其它的资料，大概了解了一下，有以下几种情况：1、request_fn是在unplug泄流的时候调用（也就是队列里面的请求达到一定的数量）  2、或者是由定时器触发，也就是即使队列里面的请求很少，但是也不能无限期的不执行它们，所以在定时器超时后会调用request_fn 3、或者在添加request进行合并的时候，判断一下是哪种合并方式，如果是后向合并就会立即调用requset_fn。<br>不知道这样理解的对不对？","like_count":4},{"had_liked":false,"id":104747,"user_name":"安排","can_delete":false,"product_type":"c1","uid":1260026,"ip_address":"","ucode":"F78CFA9624CAEF","user_header":"https://static001.geekbang.org/account/avatar/00/13/39/fa/a7edbc72.jpg","comment_is_top":false,"comment_ctime":1560826581,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10150761173","product_id":100024701,"comment_content":"         make_request_fn被初始化成了blk_queue_bio函数。submit_bio会调用到generic_make_request，然后进一步调用到make_request_fn，也就是blk_queue_bio。在blk_queue_bio里面其实是先尝试将bio合并到当前进程的plug_list里面的request，如果可以合并，则合并后直接返回了，如果不能合并，则接着向磁盘设备的request_queue中合并，向request_queue中合并的时候一定会成功（因为即使不能合并也会新生成一个request）。而每个进程的plug_list里面的request也会在适当的时候就行泄流，泄流的时候会调用到磁盘设备的request_queue里面的电梯成员的elevator_add_req_fn，这个函数就是讲plug_list里面的request加入到request_queue里面的电梯队列里，进行更进一步的合并。<br>        设备驱动会调用request_queue的request_fn，平时写块设备驱动也就是申请一个request_queue，然后调用一些内核api初始化这个request_queue，并且实现自己的request_fn函数，request_fn会调用blk_peek_request从request_queue的queue_head成员取出request，并转化为更底层的指令来执行，如果发现queue_head为空，则会调用request_queue的elevator_dispatch_fn分发request。","like_count":3},{"had_liked":false,"id":249719,"user_name":"Yakmoz","can_delete":false,"product_type":"c1","uid":1257502,"ip_address":"","ucode":"1FA18A711457A0","user_header":"https://static001.geekbang.org/account/avatar/00/13/30/1e/0b05530d.jpg","comment_is_top":false,"comment_ctime":1600769201,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5895736497","product_id":100024701,"comment_content":"这里的page_cache和文件系统里的page_cache是不是不一样的? 不太明白,为什么直接IO 提交的时候也会操作page_cache","like_count":1},{"had_liked":false,"id":112411,"user_name":"眭东亮","can_delete":false,"product_type":"c1","uid":1449336,"ip_address":"","ucode":"E9F629828B4E55","user_header":"https://wx.qlogo.cn/mmopen/vi_32/7dSgJbCaoS5CnCI4toP6mPueW1f0eQ0Ua9LxymPqJjH49cNYkJK0s9NcvrapPU4gvZb12j2u3l2A8Rw5onlJMQ/132","comment_is_top":false,"comment_ctime":1562729393,"is_pvip":false,"replies":[{"id":"46718","content":"赞","user_name":"作者回复","comment_id":112411,"uid":"1001590","ip_address":"","utype":1,"ctime":1566386238,"user_name_real":"刘超@网易云"}],"discussion_count":1,"race_medal":0,"score":"5857696689","product_id":100024701,"comment_content":"查看磁盘调度算法<br>cat &#47;sys&#47;block&#47;sda&#47;queue&#47;scheduler<br>","like_count":1,"discussions":[{"author":{"id":1001590,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/48/76/0c7d4d23.jpg","nickname":"刘超","note":"","ucode":"196BF3F499E8FE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":457722,"discussion_content":"赞","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1566386238,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":105114,"user_name":"蚂蚁内推+v","can_delete":false,"product_type":"c1","uid":1050508,"ip_address":"","ucode":"24B10AEE54B3FD","user_header":"https://static001.geekbang.org/account/avatar/00/10/07/8c/0d886dcc.jpg","comment_is_top":false,"comment_ctime":1560921172,"is_pvip":false,"replies":[{"id":"49014","content":"会呀，flush就不会","user_name":"作者回复","comment_id":105114,"uid":"1001590","ip_address":"","utype":1,"ctime":1567579738,"user_name_real":"刘超@网易云"}],"discussion_count":1,"race_medal":0,"score":"5855888468","product_id":100024701,"comment_content":"会不会断电丢失数据呢？","like_count":1,"discussions":[{"author":{"id":1001590,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/48/76/0c7d4d23.jpg","nickname":"刘超","note":"","ucode":"196BF3F499E8FE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454563,"discussion_content":"会呀，flush就不会","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567579738,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":104274,"user_name":"安排","can_delete":false,"product_type":"c1","uid":1260026,"ip_address":"","ucode":"F78CFA9624CAEF","user_header":"https://static001.geekbang.org/account/avatar/00/13/39/fa/a7edbc72.jpg","comment_is_top":false,"comment_ctime":1560704750,"is_pvip":false,"replies":[{"id":"49039","content":"会调用__blk_run_queue，里面调用request_fn","user_name":"作者回复","comment_id":104274,"uid":"1001590","ip_address":"","utype":1,"ctime":1567583986,"user_name_real":"刘超@网易云"}],"discussion_count":1,"race_medal":0,"score":"5855672046","product_id":100024701,"comment_content":"往设备里面写的时候调用的是request_fn，这个函数是谁来调用的呢？触发这个调用的时机是什么呢？还是说请求一旦进入队列就会立即写入？","like_count":1,"discussions":[{"author":{"id":1001590,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/48/76/0c7d4d23.jpg","nickname":"刘超","note":"","ucode":"196BF3F499E8FE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454197,"discussion_content":"会调用__blk_run_queue，里面调用request_fn","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567583986,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":333057,"user_name":"specter","can_delete":false,"product_type":"c1","uid":1293928,"ip_address":"","ucode":"0E7F6A7FD55DB7","user_header":"https://static001.geekbang.org/account/avatar/00/13/be/68/8c0796be.jpg","comment_is_top":false,"comment_ctime":1644033188,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1644033188","product_id":100024701,"comment_content":"刘老师，我是一个老师，您画的图实在是太好了，我能在讲课的时候借用您的图吗？","like_count":0},{"had_liked":false,"id":324457,"user_name":"TableBear","can_delete":false,"product_type":"c1","uid":1673990,"ip_address":"","ucode":"A2C0562EEA2725","user_header":"https://static001.geekbang.org/account/avatar/00/19/8b/06/fb3be14a.jpg","comment_is_top":false,"comment_ctime":1638441097,"is_pvip":true,"discussion_count":0,"race_medal":5,"score":"1638441097","product_id":100024701,"comment_content":"好晕啊","like_count":1},{"had_liked":false,"id":300551,"user_name":"chaoxifuchen","can_delete":false,"product_type":"c1","uid":1292330,"ip_address":"","ucode":"95DCC5C4994F68","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/VX0ib4CV0m7fwxB2xFcIJaYYWXXpfxxYbfBErqBej9395hgZszqS3dz9bThCxOuFfJ8Xibx9HbdNmZJwL5m33wIw/132","comment_is_top":false,"comment_ctime":1625215934,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1625215934","product_id":100024701,"comment_content":"老师，有个疑问，什么情况下会用到直接 I&#47;O，还有假设一个页里只有1个字节改变了，从page_cache往磁盘里刷脏页时也是重新写整个页4k字节吗？","like_count":0},{"had_liked":false,"id":270532,"user_name":"--","can_delete":false,"product_type":"c1","uid":1075167,"ip_address":"","ucode":"A262E3991E69DA","user_header":"https://static001.geekbang.org/account/avatar/00/10/67/df/8b85d0d9.jpg","comment_is_top":false,"comment_ctime":1609152057,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1609152057","product_id":100024701,"comment_content":"补充知识点：块设备多队列架构。内核在5.0之后已经完全从单队列架构迁移到了多队列架构，按照老师的思路去了解多队列架构还是挺有意思的。","like_count":0},{"had_liked":false,"id":167239,"user_name":"Paul Shan","can_delete":false,"product_type":"c1","uid":1593140,"ip_address":"","ucode":"32D99989028284","user_header":"","comment_is_top":false,"comment_ctime":1577743689,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1577743689","product_id":100024701,"comment_content":"请问老师，do_direct_IO 里面每一页(page)可能对应多个块（block），是不是现实中大多数情况页和块相等（4K），也就是每页也就循环一次。是不是从这里也可以看出，页的大小虽然可以配置，也必须是4K的整数倍，块的大小应该是不可配置的（永远4K）。","like_count":0},{"had_liked":false,"id":129943,"user_name":"游弋云端","can_delete":false,"product_type":"c1","uid":1208637,"ip_address":"","ucode":"A960E8F5AA25B9","user_header":"https://static001.geekbang.org/account/avatar/00/12/71/3d/da8dc880.jpg","comment_is_top":false,"comment_ctime":1567331910,"is_pvip":false,"replies":[{"id":"48702","content":"还是需要设备驱动层的","user_name":"作者回复","comment_id":129943,"uid":"1001590","ip_address":"","utype":1,"ctime":1567479566,"user_name_real":"刘超@网易云"}],"discussion_count":1,"race_medal":0,"score":"1567331910","product_id":100024701,"comment_content":"老师，是否可以认为直接 IO执行完成后，数据就是下盘的，还是不一定，还有驱动层以及磁盘缓存等因素。","like_count":0,"discussions":[{"author":{"id":1001590,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/48/76/0c7d4d23.jpg","nickname":"刘超","note":"","ucode":"196BF3F499E8FE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":465726,"discussion_content":"还是需要设备驱动层的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567479566,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":105282,"user_name":"安排","can_delete":false,"product_type":"c1","uid":1260026,"ip_address":"","ucode":"F78CFA9624CAEF","user_header":"https://static001.geekbang.org/account/avatar/00/13/39/fa/a7edbc72.jpg","comment_is_top":false,"comment_ctime":1560954691,"is_pvip":false,"replies":[{"id":"49009","content":"取出来之后，基本就是面向设备的操作了。","user_name":"作者回复","comment_id":105282,"uid":"1001590","ip_address":"","utype":1,"ctime":1567579543,"user_name_real":"刘超@网易云"}],"discussion_count":1,"race_medal":0,"score":"1560954691","product_id":100024701,"comment_content":"老师，希望在答疑篇能讲一讲request_fn取出请求之后的具体执行过程，具体的执行是不是和block_device有关，磁盘的最底层的操作是不是都在block_device中？","like_count":0,"discussions":[{"author":{"id":1001590,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/48/76/0c7d4d23.jpg","nickname":"刘超","note":"","ucode":"196BF3F499E8FE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454620,"discussion_content":"取出来之后，基本就是面向设备的操作了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567579543,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":104757,"user_name":"安排","can_delete":false,"product_type":"c1","uid":1260026,"ip_address":"","ucode":"F78CFA9624CAEF","user_header":"https://static001.geekbang.org/account/avatar/00/13/39/fa/a7edbc72.jpg","comment_is_top":false,"comment_ctime":1560828149,"is_pvip":false,"replies":[{"id":"49022","content":"不会的","user_name":"作者回复","comment_id":104757,"uid":"1001590","ip_address":"","utype":1,"ctime":1567580335,"user_name_real":"刘超@网易云"}],"discussion_count":1,"race_medal":0,"score":"1560828149","product_id":100024701,"comment_content":"直接读写裸设备不会走文件系统，那还会走通用块层吗？","like_count":0,"discussions":[{"author":{"id":1001590,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/48/76/0c7d4d23.jpg","nickname":"刘超","note":"","ucode":"196BF3F499E8FE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454411,"discussion_content":"不会的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567580335,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":104322,"user_name":"石维康","can_delete":false,"product_type":"c1","uid":1067564,"ip_address":"","ucode":"E39ED8416B2C01","user_header":"https://static001.geekbang.org/account/avatar/00/10/4a/2c/f8451d77.jpg","comment_is_top":false,"comment_ctime":1560732978,"is_pvip":false,"replies":[{"id":"49040","content":"后面会加回去的","user_name":"作者回复","comment_id":104322,"uid":"1001590","ip_address":"","utype":1,"ctime":1567584004,"user_name_real":"刘超@网易云"}],"discussion_count":1,"race_medal":0,"score":"1560732978","product_id":100024701,"comment_content":"bio_list_merge(&amp;bio_list_on_stack[0], &amp;lower);<br>bio_list_merge(&amp;bio_list_on_stack[0], &amp;same);<br>bio_list_merge(&amp;bio_list_on_stack[0], &amp;bio_list_on_stack[1]);<br><br>请问这些加到bio_list_on_stack[0]上的bio是在什么时候被处理的？","like_count":0,"discussions":[{"author":{"id":1001590,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/48/76/0c7d4d23.jpg","nickname":"刘超","note":"","ucode":"196BF3F499E8FE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454224,"discussion_content":"后面会加回去的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567584004,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]}]}