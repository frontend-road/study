{"id":713685,"title":"17｜回调函数：在AI应用中引入异步通信机制","content":"<p>你好，我是黄佳，欢迎来到LangChain实战课！</p><p>这节课我们一起来学习一下LangChain中的回调函数。</p><h2>回调函数和异步编程</h2><p>回调函数，你可能并不陌生。它是函数A作为参数传给另一个函数B，然后在函数B内部执行函数A。当函数B完成某些操作后，会调用（即“回调”）函数A。这种编程模式常见于处理异步操作，如事件监听、定时任务或网络请求。</p><blockquote>\n<p><span class=\"reference\">在编程中，异步通常是指代码不必等待某个操作完成（如I/O操作、网络请求、数据库查询等）就可以继续执行的能力。异步机制的实现涉及事件循环、任务队列和其他复杂的底层机制。这与同步编程形成对比，在同步编程中，操作必须按照它们出现的顺序完成。</span></p>\n</blockquote><p>下面是回调函数的一个简单示例。</p><pre><code class=\"language-plain\">def compute(x, y, callback):\n&nbsp; &nbsp; result = x + y\n&nbsp; &nbsp; callback(result)\n\ndef print_result(value):\n&nbsp; &nbsp; print(f\"The result is: {value}\")\n\ndef square_result(value):\n&nbsp; &nbsp; print(f\"The squared result is: {value**2}\")\n\n# 使用print_result作为回调\ncompute(3, 4, print_result) &nbsp;# 输出: The result is: 7\n\n# 使用square_result作为回调\ncompute(3, 4, square_result) &nbsp;# 输出: The squared result is: 49\n</code></pre><!-- [[[read_end]]] --><p>不过，上面这个程序中并没有体现出异步操作。虽然回调函数这种编程模式常见于处理异步操作，但回调函数本身并不代表异步。回调只是一种编程模式，允许你在某个操作完成时（无论是否异步）执行某些代码。</p><p>而下面的例子，就是在异步操作时使用回调函数的示例。</p><pre><code class=\"language-plain\">import asyncio\n\nasync def compute(x, y, callback):\n&nbsp; &nbsp; print(\"Starting compute...\")\n&nbsp; &nbsp; await asyncio.sleep(0.5) &nbsp;# 模拟异步操作\n&nbsp; &nbsp; result = x + y\n&nbsp; &nbsp; # callback(result)\n&nbsp; &nbsp; print(\"Finished compute...\")\n\ndef print_result(value):\n&nbsp; &nbsp; print(f\"The result is: {value}\")\n\nasync def another_task():\n&nbsp; &nbsp; print(\"Starting another task...\")\n&nbsp; &nbsp; await asyncio.sleep(1)\n&nbsp; &nbsp; print(\"Finished another task...\")\n\nasync def main():\n&nbsp; &nbsp; print(\"Main starts...\")\n&nbsp; &nbsp; task1 = asyncio.create_task(compute(3, 4, print_result))\n&nbsp; &nbsp; task2 = asyncio.create_task(another_task())\n&nbsp; &nbsp; \n&nbsp; &nbsp; await task1\n&nbsp; &nbsp; await task2\n&nbsp; &nbsp; print(\"Main ends...\")\n\nasyncio.run(main())\n</code></pre><p>这个示例中，当我们调用 asyncio.create_task(compute(3, 4, print_result))，compute函数开始执行。当它遇到 await asyncio.sleep(2) 时，它会暂停，并将控制权交还给事件循环。这时，事件循环可以选择开始执行another_task，这是另一个异步任务。这样，你可以清晰地看到，尽管compute函数还没有完成，another_task函数也得以开始执行并完成。这就是异步编程，允许你同时执行多个操作，而不需要等待一个完成后再开始另一个。</p><h2>LangChain 中的 Callback 处理器</h2><p>LangChain 的 Callback 机制允许你在应用程序的不同阶段进行自定义操作，如日志记录、监控和数据流处理，这个机制通过 CallbackHandler（回调处理器）来实现。</p><p>回调处理器是LangChain中实现 CallbackHandler 接口的对象，为每类可监控的事件提供一个方法。当该事件被触发时，CallbackManager 会在这些处理器上调用适当的方法。</p><p>BaseCallbackHandler是最基本的回调处理器，你可以继承它来创建自己的回调处理器。它包含了多种方法，如on_llm_start/on_chat（当 LLM 开始运行时调用）和on_llm_error（当 LLM 出现错误时调用）等。</p><p><img src=\"https://static001.geekbang.org/resource/image/f3/91/f393b0aa5b0b4fa795c27b5e04cae491.jpg?wh=698x805\" alt=\"\"></p><p>LangChain 也提供了一些内置的处理器，例如 StdOutCallbackHandler，它会将所有事件记录到标准输出。还有FileCallbackHandler，会将所有的日志记录到一个指定的文件中。</p><h2>在组件中使用回调处理器</h2><p>在 LangChain 的各个组件，如 Chains、Models、Tools、Agents 等，都提供了两种类型的回调设置方法：构造函数回调和请求回调。你可以在初始化 LangChain 时将回调处理器传入，或者在单独的请求中使用回调。例如，当你想要在整个链的所有请求中进行日志记录时，可以在初始化时传入处理器；而当你只想在某个特定请求中使用回调时，可以在请求时传入。</p><p>这两者的区别，我给你整理了一下。</p><p><img src=\"https://static001.geekbang.org/resource/image/a5/5e/a593e19a4c3693365756a5c34a96355e.jpg?wh=1306x461\" alt=\"\"></p><p>下面这段示例代码，使用 LangChain 执行了一个简单的任务，结合使用 LangChain 的回调机制与 loguru 日志库，将相关事件同时输出到标准输出和 <code>\"output.log\"</code> 文件中。</p><pre><code class=\"language-plain\">from loguru import logger\n\nfrom langchain.callbacks import FileCallbackHandler\nfrom langchain.chains import LLMChain\nfrom langchain.llms import OpenAI\nfrom langchain.prompts import PromptTemplate\n\nlogfile = \"output.log\"\n\nlogger.add(logfile, colorize=True, enqueue=True)\nhandler = FileCallbackHandler(logfile)\n\nllm = OpenAI()\nprompt = PromptTemplate.from_template(\"1 + {number} = \")\n\n# this chain will both print to stdout (because verbose=True) and write to 'output.log'\n# if verbose=False, the FileCallbackHandler will still write to 'output.log'\nchain = LLMChain(llm=llm, prompt=prompt, callbacks=[handler], verbose=True)\nanswer = chain.run(number=2)\nlogger.info(answer)\n</code></pre><p>其中，初始化LLMChain时指定的 verbose 参数，就等同于将一个输出到控制台的回调处理器添加到你的对象中。这个在你调试程序时非常有用，因为它会将所有事件的信息输出到控制台。</p><p>简而言之，LangChain 通过回调系统提供了一种灵活的方式，来监控和操作应用程序的不同阶段。</p><h2>自定义回调函数</h2><p>我们也可以通过BaseCallbackHandler和AsyncCallbackHandler来自定义回调函数。下面是一个示例。</p><pre><code class=\"language-plain\">import asyncio\nfrom typing import Any, Dict, List\n\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.schema import LLMResult, HumanMessage\nfrom langchain.callbacks.base import AsyncCallbackHandler, BaseCallbackHandler\n\n# 创建同步回调处理器\nclass MyFlowerShopSyncHandler(BaseCallbackHandler):\n&nbsp; &nbsp; def on_llm_new_token(self, token: str, **kwargs) -&gt; None:\n&nbsp; &nbsp; &nbsp; &nbsp; print(f\"获取花卉数据: token: {token}\")\n\n# 创建异步回调处理器\nclass MyFlowerShopAsyncHandler(AsyncCallbackHandler):\n\n&nbsp; &nbsp; async def on_llm_start(\n&nbsp; &nbsp; &nbsp; &nbsp; self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any\n&nbsp; &nbsp; ) -&gt; None:\n&nbsp; &nbsp; &nbsp; &nbsp; print(\"正在获取花卉数据...\")\n&nbsp; &nbsp; &nbsp; &nbsp; await asyncio.sleep(0.5) &nbsp;# 模拟异步操作\n&nbsp; &nbsp; &nbsp; &nbsp; print(\"花卉数据获取完毕。提供建议...\")\n\n&nbsp; &nbsp; async def on_llm_end(self, response: LLMResult, **kwargs: Any) -&gt; None:\n&nbsp; &nbsp; &nbsp; &nbsp; print(\"整理花卉建议...\")\n&nbsp; &nbsp; &nbsp; &nbsp; await asyncio.sleep(0.5) &nbsp;# 模拟异步操作\n&nbsp; &nbsp; &nbsp; &nbsp; print(\"祝你今天愉快！\")\n\n# 主要的异步函数\nasync def main():\n&nbsp; &nbsp; flower_shop_chat = ChatOpenAI(\n&nbsp; &nbsp; &nbsp; &nbsp; max_tokens=100,\n&nbsp; &nbsp; &nbsp; &nbsp; streaming=True,\n&nbsp; &nbsp; &nbsp; &nbsp; callbacks=[MyFlowerShopSyncHandler(), MyFlowerShopAsyncHandler()],\n&nbsp; &nbsp; )\n\n&nbsp; &nbsp; # 异步生成聊天回复\n&nbsp; &nbsp; await flower_shop_chat.agenerate([[HumanMessage(content=\"哪种花卉最适合生日？只简单说3种，不超过50字\")]])\n\n# 运行主异步函数\nasyncio.run(main())\n</code></pre><p>在这个鲜花店客服的程序中，当客户问及关于鲜花的建议时，我们使用了一个同步和一个异步回调。</p><p>MyFlowerShopSyncHandler 是一个同步回调，每当新的Token生成时，它就简单地打印出正在获取的鲜花数据。</p><p>而 MyFlowerShopAsyncHandler 则是异步的，当客服开始提供鲜花建议时，它会模拟数据的异步获取。在建议完成后，它还会模拟一个结束的操作，如向客户发出感谢。</p><p>这种结合了同步和异步操作的方法，使得程序能够更有效率地处理客户请求，同时提供实时反馈。</p><p><strong>这里的异步体现在这样几个方面。</strong></p><ol>\n<li>模拟延时操作：在MyFlowerShopAsyncHandler中，我们使用了await asyncio.sleep(0.5)来模拟其他请求异步获取花卉信息的过程。当执行到这个await语句时，当前的on_llm_start函数会“暂停”，释放控制权回到事件循环。这意味着，在这个sleep期间，其他异步任务（如其他客户的请求）可以被处理。<br>\n&nbsp;</li>\n<li>回调机制：当ChatOpenAI在处理每个新Token时，它会调用on_llm_new_token方法。因为这是一个同步回调，所以它会立即输出。但是，开始和结束的异步回调on_llm_start和on_llm_end在开始和结束时都有一个小的延时操作，这是通过await asyncio.sleep(0.5)模拟的。<br>\n&nbsp;</li>\n<li>事件循环：Python的syncio库提供了一个事件循环，允许多个异步任务并发运行。在我们的例子中，虽然看起来所有的操作都是按顺序发生的，但由于我们使用了异步操作和回调，如果有其他并发任务，它们可以在await暂停期间运行。</li>\n</ol><p>为了更清晰地展示异步的优势，通常我们会在程序中同时运行多个异步任务，并观察它们如何“并发”执行。但在这个简单的例子中，我们主要是通过模拟延时来展示异步操作的基本机制。</p><p>因此说，回调函数为异步操作提供了一个机制，使你可以定义“当操作完成时要做什么”，而异步机制的真正实现涉及更深层次的底层工作，如事件循环和任务调度。</p><h2>用 get_openai_callback 构造令牌计数器</h2><p>下面，我带着你使用LangChain中的回调函数来构造一个令牌计数器。这个计数功能对于监控大模型的会话消耗以及成本控制十分重要。</p><p>在构造令牌计数器之前，我们来回忆一下<a href=\"https://time.geekbang.org/column/article/704183\">第10课</a>中的记忆机制。我们用下面的代码生成了ConversationBufferMemory。</p><pre><code class=\"language-plain\">from langchain import OpenAI\nfrom langchain.chains import ConversationChain\nfrom langchain.chains.conversation.memory import ConversationBufferMemory\n\n# 初始化大语言模型\nllm = OpenAI(\n&nbsp; &nbsp; temperature=0.5,\n&nbsp; &nbsp; model_name=\"gpt-3.5-turbo-instruct\")\n\n# 初始化对话链\nconversation = ConversationChain(\n&nbsp; &nbsp; llm=llm,\n&nbsp; &nbsp; memory=ConversationBufferMemory()\n)\n\n# 第一天的对话\n# 回合1\nconversation(\"我姐姐明天要过生日，我需要一束生日花束。\")\nprint(\"第一次对话后的记忆:\", conversation.memory.buffer)\n\n# 回合2\nconversation(\"她喜欢粉色玫瑰，颜色是粉色的。\")\nprint(\"第二次对话后的记忆:\", conversation.memory.buffer)\n\n# 回合3 （第二天的对话）\nconversation(\"我又来了，还记得我昨天为什么要来买花吗？\")\nprint(\"/n第三次对话后时提示:/n\",conversation.prompt.template)\nprint(\"/n第三次对话后的记忆:/n\", conversation.memory.buffer)\n</code></pre><p>同时，我们也给出了各种记忆机制对Token的消耗数量的估算示意图。</p><p><img src=\"https://static001.geekbang.org/resource/image/b6/52/b605f14e7c9151c5172fff5860285e52.png?wh=3627x1427\" alt=\"\" title=\"当对话轮次逐渐增加时，各种记忆机制对 Token 的消耗数量估算\"></p><p>不过，这张图毕竟是估算，要真正地衡量出每种记忆机制到底耗费了多少个Token，那就需要回调函数上场了。</p><p>下面，我们通过回调函数机制，重构这段程序。为了做到这一点，我们首先需要确保在与大语言模型进行交互时，使用了get_openai_callback上下文管理器。</p><blockquote>\n<p><span class=\"reference\">在Python中，一个上下文管理器通常用于管理资源，如文件或网络连接，这些资源在使用前需要设置，在使用后需要清理。上下文管理器经常与with语句一起使用，以确保资源正确地设置和清理。</span><br>\n&nbsp;<br>\n<span class=\"reference\">get_openai_callback被设计用来监控与OpenAI交互的Token数量。当你进入该上下文时，它会通过监听器跟踪Token的使用。当你退出上下文时，它会清理监听器并提供一个Token的总数。通过这种方式，它充当了一个回调机制，允许你在特定事件发生时执行特定的操作或收集特定的信息。</span></p>\n</blockquote><p>具体代码如下：</p><pre><code class=\"language-plain\">from langchain import OpenAI\nfrom langchain.chains import ConversationChain\nfrom langchain.chains.conversation.memory import ConversationBufferMemory\nfrom langchain.callbacks import get_openai_callback\n\n# 初始化大语言模型\nllm = OpenAI(temperature=0.5, model_name=\"gpt-3.5-turbo-instruct\")\n\n# 初始化对话链\nconversation = ConversationChain(\n&nbsp; &nbsp; llm=llm,\n&nbsp; &nbsp; memory=ConversationBufferMemory()\n)\n\n# 使用context manager进行token counting\nwith get_openai_callback() as cb:\n&nbsp; &nbsp; # 第一天的对话\n&nbsp; &nbsp; # 回合1\n&nbsp; &nbsp; conversation(\"我姐姐明天要过生日，我需要一束生日花束。\")\n&nbsp; &nbsp; print(\"第一次对话后的记忆:\", conversation.memory.buffer)\n\n&nbsp; &nbsp; # 回合2\n&nbsp; &nbsp; conversation(\"她喜欢粉色玫瑰，颜色是粉色的。\")\n&nbsp; &nbsp; print(\"第二次对话后的记忆:\", conversation.memory.buffer)\n\n&nbsp; &nbsp; # 回合3 （第二天的对话）\n&nbsp; &nbsp; conversation(\"我又来了，还记得我昨天为什么要来买花吗？\")\n&nbsp; &nbsp; print(\"/n第三次对话后时提示:/n\",conversation.prompt.template)\n&nbsp; &nbsp; print(\"/n第三次对话后的记忆:/n\", conversation.memory.buffer)\n\n# 输出使用的tokens\nprint(\"\\n总计使用的tokens:\", cb.total_tokens)\n</code></pre><p>这里，我使用了get_openai_callback上下文管理器来监控与ConversationChain的交互。这允许我们计算在这些交互中使用的总Tokens数。</p><p>输出：</p><pre><code class=\"language-plain\">总计使用的tokens: 966\n</code></pre><p>下面，我再添加了一个additional_interactions异步函数，用于演示如何在多个并发交互中计算Tokens。</p><blockquote>\n<p><span class=\"reference\">当我们讨论异步交互时，指的是我们可以启动多个任务，它们可以并发（而不是并行）地运行，并且不会阻塞主线程。在Python中，这是通过asyncio库实现的，它使用事件循环来管理并发的异步任务。</span></p>\n</blockquote><pre><code class=\"language-plain\">import asyncio\n# 进行更多的异步交互和token计数\nasync def additional_interactions():\n&nbsp; &nbsp; with get_openai_callback() as cb:\n&nbsp; &nbsp; &nbsp; &nbsp; await asyncio.gather(\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; *[llm.agenerate([\"我姐姐喜欢什么颜色的花？\"]) for _ in range(3)]\n&nbsp; &nbsp; &nbsp; &nbsp; )\n&nbsp; &nbsp; print(\"\\n另外的交互中使用的tokens:\", cb.total_tokens)\n\n# 运行异步函数\nasyncio.run(additional_interactions())\n</code></pre><p>简单解释一下。</p><ol>\n<li><code>async def</code>：这表示additional_interactions是一个异步函数。它可以使用await关键字在其中挂起执行，允许其他异步任务继续。</li>\n<li><code>await asyncio.gather(...)</code>：这是asyncio库提供的一个非常有用的方法，用于并发地运行多个异步任务。它会等待所有任务完成，然后继续执行。</li>\n<li><code>*[llm.agenerate([\"我姐姐喜欢什么颜色的花？\"]) for _ in range(3)]</code>：这实际上是一个Python列表解析，它生成了3个 llm.agenerate(…)的异步调用。asyncio.gather将并发地运行这3个调用。</li>\n</ol><p>由于这3个llm.agenerate调用是并发的，所以它们不会按顺序执行，而是几乎同时启动，并在各自完成时返回。这意味着，即使其中一个调用由于某种原因需要更长时间，其他调用也不会被阻塞，它们会继续并完成。</p><h2>总结时刻</h2><p>回调函数是计算机科学中一个重要和广泛应用的概念，它允许我们在特定的时间或条件下执行特定的代码。</p><p>回调函数在开发过程中有很多应用场景。</p><ol>\n<li>异步编程：在JavaScript中，回调函数常常用于异步编程。例如，当你发送一个AJAX请求到服务器时，你可以提供一个回调函数，这个函数将在服务器的响应到达时被调用。</li>\n<li>事件处理：在许多编程语言和框架中，回调函数被用作事件处理器。例如，你可能会写一个回调函数来处理用户的点击事件，当用户点击某个按钮时，这个函数就会被调用。</li>\n<li>定时器：你可以使用回调函数来创建定时器。例如，你可以使用JavaScript的setTimeout或setInterval函数，并提供一个回调函数，这个函数会在指定的时间过后被调用。</li>\n</ol><p>在 LangChain 中，回调机制同样为用户提供了灵活性和自定义能力，以便更好地控制和响应事件。CallbackHandler允许开发者在链的特定阶段或条件下注入自定义的行为，例如异步编程中的响应处理、事件驱动编程中的事件处理等。这为 LangChain 提供了灵活性和扩展性，使其能够适应各种应用场景。</p><h2>思考题</h2><ol>\n<li>我通过get_openai_callback重构了ConversationBufferMemory的程序，你能否把这个令牌计数器实现到其他记忆机制中？<br>\n&nbsp;</li>\n<li>在LangChain开发过程中，可以在构造函数中引入回调机制，我给出了一个示例，你能否尝试在请求过程（run/apply方法）中引入回调机制？</li>\n</ol><p>提示：请求回调常用在流式传输的实现中。在传统的传输中，我们必须等待这个函数生成所有数据后才能开始处理。在流式传输中，我们可以在数据被生成时立即开始处理。如果你想将单个请求的输出流式传输到一个WebSocket，你可以将一个Callback处理器传递给 call() 方法。</p><p>期待在留言区看到你的分享，如果觉得内容对你有帮助，也欢迎分享给有需要的朋友！最后如果你学有余力，可以进一步学习下面的延伸阅读。</p><h2>延伸阅读</h2><ol>\n<li>GitHub 代码：<a href=\"https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/callbacks/base.py\">CallbackHandler</a> 中的可监控事件和方法</li>\n<li>文档：LangChain中的<a href=\"https://python.langchain.com/docs/modules/callbacks/\">回调</a>机制</li>\n<li>文档：什么是<a href=\"https://www.zhihu.com/question/19801131\">回调函数</a>（知乎）</li>\n</ol>","neighbors":{"left":{"article_title":"16｜连接数据库：通过链和代理查询鲜花信息","id":713462},"right":{"article_title":"18｜CAMEL：通过角色扮演脑暴一个鲜花营销方案","id":714249}},"comments":[{"had_liked":false,"id":382673,"user_name":"阿斯蒂芬","can_delete":false,"product_type":"c1","uid":1024164,"ip_address":"广东","ucode":"61D5E3BDA4EBC5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/a0/a4/b060c723.jpg","comment_is_top":true,"comment_ctime":1697784943,"is_pvip":false,"replies":[{"id":139438,"content":"嗯嗯，你是课代表啊。作业做的又细又好。好滴，第一个我们统一成0.5，第2个经验也非常宝贵，值得用代理的童鞋借鉴。值得置顶。","user_name":"作者回复","user_name_real":"编辑","uid":1809833,"ctime":1698138139,"ip_address":"瑞士","comment_id":382673,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100617601,"comment_content":"笔记mark：\n\n\n1.疑似纠错：\n第二个代码示例后写道：【compute 函数开始执行。当它遇到 await asyncio.sleep(2) 时，它会暂停】\n但是代码中是 await asyncio.sleep(0.5)，休眠时长会影响最终程序的打印输出顺序；\n后面花卉部分 【在 MyFlowerShopAsyncHandler 中，我们使用了 await asyncio.sleep(0.3) 】也与代码中的 await asyncio.sleep(0.5) 不一致；\n如果属实，还是建议修改下，否则容易造成困惑\n\n\n2. 自定义回调函数 代码报错问题\n一开始直接使用老师的代码，未能获得流式响应的打印，出现报错：\nRetrying langchain.chat_models.openai.acompletion_with_retry.&lt;locals&gt;._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI.\n但是此时非流式的响应，是能够正常完成的；\n折腾许久，定位到是openai代理的问题，但是流式响应是通过SSE协议，此时vpn似乎被绕过了，将vpn代理显示添加到 OPENAI_PROXY 环境变量后解决\n\n3. 最后的 additional_interactions() 示例中，可以将 asynio.gather 的返回结果打印出来，能够看到每个任务使用的token数量，与最终的总数是一致的","like_count":1,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":630141,"discussion_content":"嗯嗯，你是课代表啊。作业做的又细又好。好滴，第一个我们统一成0.5，第2个经验也非常宝贵，值得用代理的童鞋借鉴。值得置顶。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1698138139,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"瑞士","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":382672,"user_name":"阿斯蒂芬","can_delete":false,"product_type":"c1","uid":1024164,"ip_address":"广东","ucode":"61D5E3BDA4EBC5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/a0/a4/b060c723.jpg","comment_is_top":false,"comment_ctime":1697783713,"is_pvip":false,"replies":[{"id":139463,"content":"🤴🏻","user_name":"作者回复","user_name_real":"编辑","uid":1809833,"ctime":1698155394,"ip_address":"瑞士","comment_id":382672,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100617601,"comment_content":"来交作业了：\n\n思考题1：\n在确保效果相同的三轮交互中，使用了其他记忆机制，并记录令牌使用情况（分别测试三次取范围值）\nConversationBufferMemory: 1000 ~ 1500\nConversationBufferWindowMemory(k=2): 1200 ~ 1600\nConversationSummaryMemory: 2000 ~ 2500\nConversationSummaryBufferMemory(max_token_limt=300): 1000~1500\n\n大致看也符合估算示意图第一阶段 0-5 interacitions 的走势，ConversationSummaryMemory 增长较快，其他几个增长速率较为一致\n\n\n思考题2：\n使用LLMChain的 run 方法也可以传递callback\n\nclass MyCallBackHandler(BaseCallbackHandler):\n    def on_llm_new_token(self, token: str, **kwargs) -&gt; None:\n        print(f&quot;recv token: {token}&quot;)\n\n\nllm = ChatOpenAI(streaming=True)\nprompt = PromptTemplate.from_template(&quot;1 + {number} = &quot;)\n\n\nchain = LLMChain(llm=llm, prompt=prompt)\nchain.run(number=2, callbacks=[MyCallBackHandler()])\n\n其实这个示例就是从老师的延伸阅读中“拿来”的，不知答对没","like_count":1,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":630184,"discussion_content":"🤴🏻","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1698155394,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"瑞士","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":383837,"user_name":"悟尘","can_delete":false,"product_type":"c1","uid":2189310,"ip_address":"北京","ucode":"4E7E854340D3A4","user_header":"https://static001.geekbang.org/account/avatar/00/21/67/fe/5d17661a.jpg","comment_is_top":false,"comment_ctime":1699777494,"is_pvip":false,"replies":[{"id":140181,"content":"同学，具体指的是哪一段代码的输出结果，我回头看看。。。","user_name":"作者回复","user_name_real":"编辑","uid":1809833,"ctime":1700581433,"ip_address":"瑞士","comment_id":383837,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100617601,"comment_content":"老师，这节课少了输出结果的演示~理解起来有点费劲","like_count":0,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":632229,"discussion_content":"同学，具体指的是哪一段代码的输出结果，我回头看看。。。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1700581433,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"瑞士","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":393849,"user_name":"yanyu-xin","can_delete":false,"product_type":"c1","uid":1899757,"ip_address":"广东","ucode":"3AA389F9E4C236","user_header":"","comment_is_top":false,"comment_ctime":1725089614,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100617601,"comment_content":"###3 将课程代码到大模型修订为国产通义千问模型（03_LangChainOpenAICallback.py）\n###“用 get_openai_callback 构造令牌计数器”代码。用 ChatOpenAI和千问模型平替 OpenAI\n# 原代码3\nllm = OpenAI()\n# 新代码3\nfrom langchain_openai import ChatOpenAI\nllm = ChatOpenAI(\n        model_name=&quot;qwen-turbo&quot;,\n        stream_usage=True,\n        api_key= “API_KEY”, #填写你自己的DASHSCOPE_API_KEY\n        base_url=&quot;https:&#47;&#47;dashscope.aliyuncs.com&#47;compatible-mode&#47;v1&quot;, \n    )\n\n###4 修改“additional_interactions 异步函数”代码（03_LangChainOpenAICallback.py），将llm.agenerate中的参数用 langchain_core.messages 修订。\n\n# 旧代码4\nimport asyncio\nasync def additional_interactions():\n    with get_openai_callback() as cb:\n        await asyncio.gather(\n            *[llm.agenerate([&quot;我姐姐喜欢什么颜色的花？&quot;]) for _ in range(3)]\n        )\n    print(&quot;\\n另外的交互中使用的tokens:&quot;, cb.total_tokens)\nasyncio.run(additional_interactions())\n\n# 新代码4\nimport asyncio\nfrom langchain_core.messages import HumanMessage, SystemMessage\nmessages = [[\n            SystemMessage(content=&quot;你是个花店小助手。&quot;),\n            HumanMessage(content=&quot;我姐姐喜欢什么颜色的花？&quot;),\n        ]]\n\n#进行更多的异步交互和token计数\nasync def additional_interactions():\n    print(&quot;\\n开始进行更多的交互...&quot;)\n    with get_openai_callback() as cb:\n        await asyncio.gather(\n\n            *[llm.agenerate(messages) for _ in range(3)]\n        )\n   print(f&quot;交互{i+1}使用的tokens: {cb.total_tokens}&quot;)  \nasyncio.run(additional_interactions())","like_count":1},{"had_liked":false,"id":393848,"user_name":"yanyu-xin","can_delete":false,"product_type":"c1","uid":1899757,"ip_address":"广东","ucode":"3AA389F9E4C236","user_header":"","comment_is_top":false,"comment_ctime":1725089529,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100617601,"comment_content":"将课程代码到大模型修订为国产通义千问模型：\n###1 修改“在组件中使用回调处理器”代码，用 ChatOpenAI和千问模型平替 OpenAI\n\n# 原代码1\nllm = OpenAI()\n# 新代码1\nfrom langchain_openai import ChatOpenAI\nllm = ChatOpenAI(\n        model_name=&quot;qwen-turbo&quot;, #用通义模型\n        api_key=“API_KEY”, #填写你自己的DASHSCOPE_API_KEY\n        base_url=&quot;https:&#47;&#47;dashscope.aliyuncs.com&#47;compatible-mode&#47;v1&quot;\n\t）\n————\n\n###2 修改“自定义回调函数”代码，将通义模型平替OpenAI\n# 原代码2\nflower_shop_chat = ChatOpenAI(\n        max_tokens=100,\n        streaming=True,\n        callbacks=[MyFlowerShopSyncHandler(), MyFlowerShopAsyncHandler()],\n    )\n# 新代码2\n    flower_shop_chat = ChatOpenAI(\n        model_name=&quot;qwen-turbo&quot;,  #用千问模型\n        api_key=“API_KEY”, #填写你自己的DASHSCOPE_API_KEY\n        base_url=&quot;https:&#47;&#47;dashscope.aliyuncs.com&#47;compatible-mode&#47;v1&quot;, \n        max_tokens=100,\n        streaming=True,\n        callbacks=[MyFlowerShopSyncHandler(), MyFlowerShopAsyncHandler()],\n    )","like_count":1},{"had_liked":false,"id":392613,"user_name":"张申傲","can_delete":false,"product_type":"c1","uid":1182372,"ip_address":"北京","ucode":"22D46BC529BA8A","user_header":"https://static001.geekbang.org/account/avatar/00/12/0a/a4/828a431f.jpg","comment_is_top":false,"comment_ctime":1721302901,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":2,"score":2,"product_id":100617601,"comment_content":"第17讲打卡~\n可以通过回调机制，将LLM运行过程中产生的日志异步写入文件或日志服务，后续通过ELK等机制进行日志采集和链路追踪","like_count":0}]}