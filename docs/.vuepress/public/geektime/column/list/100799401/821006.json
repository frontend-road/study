{"id":821006,"title":"35｜MySQL半同步能提高主备数据的一致性吗？","content":"<p>你好，我是俊达。</p><p>上一讲中，我留了一个问题，就是在默认的情况下，MySQL的数据复制是异步的，当主库意外崩溃后，备库是否有可能比主库多执行一些事务？</p><p>回答这个问题，需要对主库事务提交的过程，以及数据复制的细节有更深入的了解。这一讲我们就来看一看事务的提交过程，分析Binlog是什么时候发送给备库的，还有Semi-Sync插件在中间起到的作用。这里我假定只使用了InnoDB存储引擎，开启了GTID，并且使用了ROW格式Binlog，这也是推荐的使用方式。</p><h2>MySQL数据复制回顾</h2><p>下面这张数据复制的架构图，你应该在上一讲中就看到过了。</p><p><img src=\"https://static001.geekbang.org/resource/image/66/6c/66909ff3d10813e114aff69913085d6c.jpg?wh=1790x812\" alt=\"图片\"></p><p>我们回顾一下。</p><ol>\n<li>\n<p>用户线程在执行事务的过程中不断产生Binlog事件。Binlog事件的内容和事务中执行的语句相关，同时也受参数binlog_format影响。产生的Binlog事件会先缓存到Binlog Cache中。每一个用户线程都有各自独立的Binlog Cache。</p>\n</li>\n<li>\n<p>提交事务时，用户线程将Binlog Cache中的数据写入到Binlog文件。一个事务会产生多个Binlog事件，这些事件在Binlog文件中是连续存放的。一个线程在往Binlog文件中写入数据时，其他线程要等待之前的线程写完数据，才能写入Binlog文件。</p>\n</li>\n<li>\n<p>用户线程将Binlog事件写入到文件或将Binlog文件同步到磁盘后，通知Dump线程有新的binlog事件产生，通知的具体时机跟参数sync_binlog的设置有关系。</p>\n</li>\n<li>\n<p>对每一个备库上的IO线程，主库上都会创建一个Dump线程。Dump线程负责将已提交事务的Binlog事件发送给IO线程。</p>\n</li>\n<li>\n<p>IO线程接收到Binlog事件后，将事件写入RelayLog文件。</p>\n</li>\n<li>\n<p>SQL线程从RelayLog文件中解析出Binlog事件，并进行应用。启用了多线程复制时，SQL线程也称为协调线程。备库上参数replica_parallel_workers设置为大于1的值，就能开启多线程复制。参数replica_parallel_type用来控制并行复制的方式，建议设置为LOGICAL_CLOCK。</p>\n</li>\n<li>\n<p>如果启用了多线程复制，SQL线程会将Binlog事件分发给各个Worker线程。</p>\n</li>\n<li>\n<p>SQL线程或Worker线程执行Binlog事件。</p>\n</li>\n</ol><!-- [[[read_end]]] --><p>如果主库完成了事务提交，但是Dump线程由于各种原因没有及时将Binlog发送出去（可能是主备之间的网络有抖动），这个时候如果主库崩溃了，切换到了备库，备库就比主库少执行了一些事务。</p><p>如果主库提交事务时，Binlog在完成持久化之前（可能是IO hang），Dump线程已经将Binlog发送给了备库，这个时候如果主库崩溃了，切换到了备库，备库就会比主库多执行一些事务。</p><p>这两种情况是不是有可能发生呢？我们先来看一下主库上事务提交的过程。</p><h2>主库事务提交过程</h2><h3>Binlog Cache</h3><p>用户线程执行过程中生成的Binlog事件会先缓存到Binlog Cache。Binlog Cache内部分配了一块内存空间，大小由参数binlog_cache_size控制。Binlog事件先写入到内存空间中，如果事务生成的Binlog超过了binlog_cache_size，就会将数据写到临时文件中。临时文件的大小由参数max_binlog_cache_size控制。如果事务生成的Binlog超过了参数max_binlog_cache_size的限制，事务会失败。</p><p><img src=\"https://static001.geekbang.org/resource/image/65/5c/6569a5a4fc1d9023d7970335dd19a45c.jpg?wh=969x539\" alt=\"图片\"></p><h3>二阶段提交</h3><p>如果使用InnoDB存储引擎，并且开启了Binlog，为了保障InnoDB和Binlog中数据的一致性，MySQL会使用两阶段提交协议来提交事务。</p><p><img src=\"https://static001.geekbang.org/resource/image/47/bc/47bb7cd3939e6aa818293f81yy846abc.jpg?wh=1728x624\" alt=\"图片\"></p><p>如上图所示，MySQL事务的提交分为Prepare和Commit两个阶段。在Prepare阶段，依次进行Binlog Prepare和InnoDB Prepare，只有当Binlog和InnoDB都Prepare成功后，事务才能进行后续的提交步骤。</p><ol>\n<li>\n<p>Binlog Prepare：Binlog Prepare时会计算事务的commit_parent。使用多线程复制时，会根据事务的commit_parent来判断该事务是否可以并行执行。</p>\n</li>\n<li>\n<p>InnoDB Prepare：31讲中说过，InnoDB会给每个事务分配Undo段。InnoDB Prepare时，需要将Undo段的状态设置为TRX_UNDO_PREPARED，并且在Undo段中记录事务的XID。MySQL中每个事务都有各自的XID，在一个实例的生命周期中（也就是实例没有重启），XID是唯一的。</p>\n</li>\n</ol><p>InnoDB Prepare完成后，需要刷新REDO日志，这样才能保证TRX_UNDO_PREPARED状态不会丢失。如果数据库在事务完成Prepare后崩溃了，那么在下次启动时，会读取到状态为TRX_UNDO_PREPARED的事务，但是由于事务的Binlog还没来得及持久化，因此也无法在Binlog中找到这些事务的XID事件，MySQL会回滚这些事务。</p><p>Prepare成功后，进入到Commit阶段。在Commit阶段依次执行下面这几个步骤。</p><ol>\n<li>\n<p>生成XID事件，并将XID写入到Binlog Cache中。</p>\n</li>\n<li>\n<p>Flush Binlog：将Binlog Cache中的数据写入到Binlog文件中。如果开启了GTID，这时会先生成GTID事件，并将GTID事件先写入到Binlog文件。如果参数sync_binlog没有设置为1，执行完Binlog Flush后，通知Dump线程读取Binlog。</p>\n</li>\n<li>\n<p>持久化Binlog。这一步是否真正进行Binlog持久化还依赖参数sync_binlog的设置。如果sync_binlog设置为1，则在这一步将binlog持久化到磁盘中，并通知Dump线程读取Binlog。Binlog持久化之后，事务事实上就已经完成提交了，只不过这时其他会话暂时还无法读取到当前事务所做的修改。如果这一步完成后MySQL服务器崩溃了，在实例重启时，会在Undo段中读取到状态为TRX_UNDO_PREPARED的事务。因为Binlog已经完成了持久化，所以会在Binlog中读取到事务的XID事件，因此会将事务状态设置为已经提交。</p>\n</li>\n<li>\n<p>InnoDB Commit：在InnoDB存储引擎层执行Commit操作，包括释放Undo段，将事务从活动事务列表中移除，持久化Redo日志等。这一步完成后，实例中的其他会话就能读取到当前事务所做的修改了。</p>\n</li>\n</ol><p>所以，如果参数sync_binlog没有设置为1时，理论上存在备库比主库执行更多事务的可能性。</p><h3>组提交</h3><p>接下来我们来看一下组提交。MySQL使用了组提交（Group Commit）技术来提交事务。并发提交事务的会话会先进入到一个队列，最先进入队列的线程称为Leader，负责提交操作，其它线程等待Leader线程完成提交操作。提交的过程分为Flush Binlog、Sync Binlog、Commit三个阶段，每个阶段都有相应的队列。</p><h4>Binlog Flush阶段</h4><p>线程完成Prepare后，调用MYSQL_BIN_LOG::commit函数，开始进行提交阶段的工作。</p><p>下面图中，框框里是MySQL源码中的函数名，你可以到源码中查看具体的代码实现。</p><p><img src=\"https://static001.geekbang.org/resource/image/9a/0e/9a627f3f023659ee42c11f551928490e.jpg?wh=1608x1388\" alt=\"图片\"></p><p>Binlog Flush的执行过程大致如下：</p><ol>\n<li>\n<p>提交事务的线程进入Flush队列。第一个进入队列的线程成为Leader往下执行。其他线程成为follower，等待Leader提交完成后再进行后续处理。</p>\n</li>\n<li>\n<p>Leader线程执行Flush操作，主要包括下面这些操作。</p>\n</li>\n</ol><ul>\n<li>\n<p>将队列中的线程提取出来，同时清空队列，以便后续提交事务的线程可以加入队列。</p>\n</li>\n<li>\n<p>持久化REDO日志。REDO日志持久化之后，即使实例发生崩溃重启，事务的Prepared状态也不会丢失。Leader线程持久化REDO日志时，其他线程的REDO日志也自动完成了持久化。</p>\n</li>\n<li>\n<p>依次将队列中所有线程的Binlog Cache都刷到Binlog文件中。</p>\n<ul>\n<li>\n<p>如果开启了GTID_MODE，则给事务分配一个GTID。</p>\n</li>\n<li>\n<p>给事务分配last_committed、sequence_number，生成GTID事件，并将GTID事件写入到binlog文件中。注意这里GTID事件需要直接写入Binlog文件，而不是加入Binlog Cache，因为GTID事件要放在事务的其他事件之前。last_committed值的计算方式跟参数binlog_transaction_dependency_tracking的设置相关。</p>\n</li>\n<li>\n<p>将binlog cache中的事件写入到binlog文件中。这里只是将事件写到Binlog文件，还没有进行fsync操作。</p>\n</li>\n</ul>\n</li>\n</ul><ol start=\"3\">\n<li>如果sync_binlog != 1，唤醒Dump线程发送binlog。</li>\n</ol><h4>Binlog Sync 阶段</h4><p>Binlog Flush阶段的Leader线程完成Binlog Flush后，进入到Binlog Sync阶段。</p><p><img src=\"https://static001.geekbang.org/resource/image/37/f1/37c29cf7f6c0e0c4cda8ecf60694f7f1.jpg?wh=1444x814\" alt=\"图片\"><br>\nBinlog Sync阶段依次执行下面这些步骤。</p><ol>\n<li>\n<p>线程先加入sync队列。第一个加入队列的成为leader，执行sync操作。其他线程成为follower，等待leader线程完成提交操作后再执行。</p>\n</li>\n<li>\n<p>如果设置了参数binlog_group_commit_sync_delay和binlog_group_commit_sync_no_delay_count，等待一定的时间，让更多的线程加入到group中。</p>\n</li>\n<li>\n<p>根据sync_binlog设置来决定是否将binlog刷新到磁盘。如果sync_binlog设置为1，则每次提交时都需要将binlog文件刷新（fsync）到磁盘。如果sync_binlog为0，就不刷新binlog文件。如果sync_binlog的设置值N大于1，那么就每N次执行一次刷新。Binlog文件刷新到磁盘后，事务实际上就已经完成了持久化，但是事务的修改对其它会话暂时还不可见。如果此时数据库发生崩溃重启，从UNDO段中可以获取到处于Prepared状态的事务。因为事务的XID事件已经持久化到了Binlog文件中，MySQL会将事务状态设置为已经提交。</p>\n</li>\n<li>\n<p>如果sync_binlog为1，唤醒dump线程发送binlog</p>\n</li>\n</ol><h4>Commit阶段</h4><p>Binlog Sync阶段的Leader线程完成相关处理后，进入到Commit阶段。</p><p><img src=\"https://static001.geekbang.org/resource/image/4d/ab/4df11f6e84b2da0209d8cc9793347aab.jpg?wh=1450x1374\" alt=\"图片\"></p><ol>\n<li>\n<p>如果参数binlog_order_commits设置为ON，则sync阶段的leader线程加入commit队列。第一个加入队列的线程成为leader，进行后续的提交操作。其他线程作为follower，等待leader完成提交后再继续处理。如果binlog_order_commits设置为OFF，则线程不需要进入commit队列，在调用after_sync钩子函数后，然后直接进入到第5步唤醒其它等待提交的事务，由各个事务各自完成提交动作。</p>\n</li>\n<li>\n<p>如果启用了semi-sync，并且rpl_semi_sync_master_wait_point设置为after_sync，则在这里等待binlog同步到备库。</p>\n</li>\n<li>\n<p>依次执行以下几个步骤。</p>\n</li>\n</ol><ul>\n<li>\n<p>更新max_committed变量。下一个group进行提交的时候，会根据变量max_committed的值来设置last_committed值。</p>\n</li>\n<li>\n<p>在InnoDB存储引擎内提交事务。InnoDB引擎内部的提交需要进行一系列操作。包括：</p>\n<ul>\n<li>\n<p>设置事务回滚段的状态。</p>\n</li>\n<li>\n<p>如果开启了GTID_MODE，在回滚段中记录事务的GTID。</p>\n</li>\n<li>\n<p>将事务从活动事务列表中移除。这一步完成之后，其它会话就能看到这个事务修改的数据了。</p>\n</li>\n</ul>\n</li>\n<li>\n<p>更新gtid相关变量：gtid_executed、gtid_purged，更新gtid_executed表。</p>\n</li>\n</ul><ol start=\"4\">\n<li>\n<p>如果启用了semi-sync，并且rpl_semi_sync_master_wait_point设置为after_commit，则在这里等待binlog同步到备库。</p>\n</li>\n<li>\n<p>唤醒其他等待提交的线程（signal_done）。</p>\n</li>\n<li>\n<p>执行finish_commit，完成commit。</p>\n</li>\n</ol><h2>Binlog同步</h2><p>最后，我们来看一下Binlog是怎么从主库同步到备库的。同步操作由主库的Dump线程和备库的IO线程一起配合完成。</p><p><img src=\"https://static001.geekbang.org/resource/image/ba/ae/ba1d0db1cf346aaa9c0b3e93d644c4ae.jpg?wh=1810x1244\" alt=\"图片\"></p><h3>IO 线程</h3><p>备库上使用START SLAVE或START REPLICA命令启动复制。当参数skip_slave_start、skip_replica_start为OFF时，实例启动时也会自动启动复制。</p><ol>\n<li>\n<p>IO线程基于master_info中的信息，和主库建立连接。如果建立连接失败，还会进行重连。master_info以文件或表的形式存储。我建议你把参数master_info_repository设置为TABLE，将master_info存储在表中。</p>\n</li>\n<li>\n<p>和主库建立连接后，获取主库的一些基础信息，包括下面这些信息。</p>\n</li>\n</ol><ul>\n<li>\n<p>主库的UUID；</p>\n</li>\n<li>\n<p>主库的server id、GTID_MODE；</p>\n</li>\n<li>\n<p>获取主库的当前时间，计算主库和备库之间的时间差clock_diff_with_master，在计算备库延迟时需要用到这个信息。</p>\n</li>\n</ul><ol start=\"3\">\n<li>发送Dump Binlog命令。</li>\n</ol><ul>\n<li>\n<p>如果启用了GTID并且使用了GTID AUTO Position，就发送COM_BINLOG_DUMP_GTID命令，命令的参数中包括备库的GTID_EXECUTED。</p>\n</li>\n<li>\n<p>如果没有使用AUTO Position，就发送COM_BINLOG_DUMP命令，命令参数中包括需要读取的Binlog文件名和位点。</p>\n</li>\n</ul><ol start=\"4\">\n<li>\n<p>接收主库Dump线程发送过来的Binlog事件。</p>\n</li>\n<li>\n<p>将Binlog事件保存到RelayLog文件中，并更新相关binlog位点信息，根据参数设置持久化relaylog文件和master info。</p>\n</li>\n</ol><ul>\n<li>\n<p>更新备库读取Binlog的位点信息（Show slave status输出中的Master_Log_File和Read_Master_Log_Pos）。如果开启GTID，还要更新Retrieved_Gtid_Set。</p>\n</li>\n<li>\n<p>根据参数sync_relay_log的设置决定是否持久化Relay Log文件。</p>\n</li>\n<li>\n<p>根据参数sync_master_info的设置决定是否持久化master info。</p>\n</li>\n</ul><h3>DUMP线程</h3><p>IO线程启动时，会跟主库建立连接，主库上会启动一个Dump线程。Dump线程主要执行下面这几个步骤。</p><ol>\n<li>\n<p>处理备库上IO线程发送过来的读取Binlog的命令。如果备库启用了AUTO_POSITION，则命令中还包括了备库的GTID_EXECUTED信息。如果没有使用AUTO_POSITION，则命令中包括了Binlog的起始文件名和位点。</p>\n</li>\n<li>\n<p>初始化Binlog读取工作。如果备库使用了AUTO_POSITION，则Dump线程需要根据发送过来的GTID_SET_ARG信息来计算Binlog的起始文件名和位点。这里可能会遇到几种情况。</p>\n</li>\n</ol><ul>\n<li>\n<p>如果主库没有开启GTID，就直接返回错误消息：The replication sender thread cannot start in AUTO_POSITION mode。</p>\n</li>\n<li>\n<p>如果备库发送过来的GTID_SET_ARG中包含主库上不存在的GTID（相对于主库的UUID），就返回错误消息：Got fatal error 1236 from master when reading data from binary log: 'Slave has more GTIDs than the master has, using the master’s SERVER_UUID.</p>\n</li>\n<li>\n<p>如果主库的GTID_PURGED不是备库发送过来的GTID_SET_ARG的子集，就说明备库上需要的一些事务已经被清理了，报错：Got fatal error 1236 from master when reading data from binary log: 'Cannot replicate because the master purged required binary logs. Replicate the missing transactions from elsewhere, or provision a new slave from backup.</p>\n</li>\n</ul><p>一般在正常情况下，备库发送过来的GTID_SET_ARG应该是主库GTID_EXECUTED的子集，而主库的GTID_PURGED应该是GTID_SET_ARG的子集。</p><p><img src=\"https://static001.geekbang.org/resource/image/96/2b/9632777cc5b51be1d5787a405yy7f72b.png?wh=1674x860\" alt=\"图片\"></p><p>如果满足了上面这几个条件，Dump线程开始扫描Binlog，定位从哪个BINLOG开始复制数据。</p><ul>\n<li>\n<p>根据Binlog Index文件中的binlog列表逆序扫描。</p>\n</li>\n<li>\n<p>打开Binlog文件，读取Binlog头部的Previous GTIDs事件。如果Previous GTIDs是GTID_SEG_ARG的子集，就从当前Binlog开始复制数据。否则，继续读取上一个Binlog文件。</p>\n</li>\n</ul><ol start=\"3\">\n<li>发送Binlog。如果没有使用AUTO_POSITION，那么Dump Binlog命令的参数中就包含了起始Binlog的文件和位点。如果使用AUTO_POSITION，那么前面的步骤已经定位到了起始Binlog，这时从Binlog文件的头部开始读取数据。Dump线程依次读取Binlog文件中的事件，发送给备库。如果使用了AUTO_POSITION，会在发送前先检查事件的GTID是不是包含在GTID_SET_ARG中，如果GTID_SET_ARG中已经有这个GTID了，就跳过这个事件。</li>\n</ol><p>当所有Binlog内容都已经发送给备库后，Dump线程开始等待新的Binlog事件生成。用户线程提交新的事务时，会通知Dump线程进行处理。</p><h3>半同步（Semi Sync）</h3><p>默认情况下，MySQL主备库之间的数据是异步进行的。主库提交事务时，并不需要等待Binlog复制到备库。这样做的好处是减少了备库对主库性能的影响，坏处是主库如果异常崩溃，可能最新的Binlog还没有同步到备库，如果业务切换到备库，就有可能出现数据丢失。半同步插件（semi-sync）能在一定程度上减少这种情况的出现。</p><h4>开启半同步</h4><p>开启半同步需要在主库和备库安装插件，并设置相关参数。</p><p>主库上安装rpl_semi_sync_source插件。</p><pre><code class=\"language-plain\">INSTALL PLUGIN rpl_semi_sync_source SONAME 'semisync_source.so';\n</code></pre><p>备库上安装rpl_semi_sync_replica插件。</p><pre><code class=\"language-plain\">INSTALL PLUGIN rpl_semi_sync_replica SONAME 'semisync_replica.so';\n</code></pre><p>主库上设置参数。</p><pre><code class=\"language-plain\">set global rpl_semi_sync_source_enabled=ON;\n</code></pre><p>备库上设置参数。</p><pre><code class=\"language-plain\">set global rpl_semi_sync_replica_enabled=ON;\n</code></pre><p>开启半同步后，主库上事务提交时，会等待Binog发送完成。如果由于各种原因，备库没有接收到Binlog，主库会一直等待，状态是“Waiting for semi-sync ACK from replica”，直到超时。超时时间通过参数rpl_semi_sync_source_timeout设置。</p><pre><code class=\"language-plain\">mysql&gt; show processlist \\G\n*************************** 2. row ***************************\n     Id: 11\n   User: root\n   Host: localhost:54932\n     db: db01\nCommand: Query\n   Time: 10\n  State: Waiting for semi-sync ACK from replica\n   Info: insert into ta values(1100)\n</code></pre><p>超时后，半同步会退化成异步复制。可以查看参数Rpl_semi_sync_source_status，判断半同步有没有生效。</p><pre><code class=\"language-plain\">mysql&gt; show global status like '%semi%status%';\n+-----------------------------+-------+\n| Variable_name               | Value |\n+-----------------------------+-------+\n| Rpl_semi_sync_source_status | ON    |\n+-----------------------------+-------+\n</code></pre><p>如果你使用了半同步，建议把Rpl_semi_sync_source_status和半同步的等待耗时监控起来。错误日志中也有半同步状态变化的信息，也可以监控起来。</p><pre><code class=\"language-plain\">[Warning] [MY-011153] [Repl] Timeout waiting for reply of binlog (file: mysql-binlog.000010, pos: 2654), semi-sync up to file mysql-binlog.000010, position 2381.\n[Note] [MY-011155] [Repl] Semi-sync replication switched OFF.\n[Note] [MY-011156] [Repl] Semi-sync replication switched ON at (mysql-binlog.000010, 2927).\n</code></pre><h4>AFTER_SYNC和AFTER_COMMIT</h4><p>半同步是在事务提交的哪个阶段等待Binlog发送呢？这和参数rpl_semi_sync_master_wait_point的设置有关。</p><p><img src=\"https://static001.geekbang.org/resource/image/c3/24/c371195ea62491c15e050c07d1ebfd24.jpg?wh=1304x305\" alt=\"图片\"><br>\nrpl_semi_sync_master_wait_point可以设置为AFTER_SYNC或AFTER_COMMIT。</p><ul>\n<li>AFTER_SYNC</li>\n</ul><p>在AFTER_SYNC的设置下，事务的Binlog Sync到磁盘之后，等待Binlog发送给备库。Binlog Sync之后，事务对其他线程还不可见。如果这个时候主库异常崩溃了，业务切换到备库。由于Binlog还没有同步到备库，所以备库上也看不到事务所做的修改。从业务的角度看，主备库数据是一致的。</p><p>但是原来的主库重新启动时，由于事务的Binlog已经完成了持久化，MySQL会将事务设置为已提交状态。因此相比于备库，主库多执行了一些事务。因此主库启动后，需要将这些事务的修改撤销后才能和新主库保持数据一致。</p><ul>\n<li>AFTER_COMMIT</li>\n</ul><p>在AFTER_COMMIT的设置下，主库在完成InnoDB Commit之后，等待Binlog同步到备库。此时，主库上其他会话已经能看到事务所做的修改了。如果这个时候主库发生异常崩溃，业务切换到备库。由于Binlog还没有同步到备库，因此备库上看不到事务所做的修改。从业务上看，备库比主库少执行了一些事务。</p><p>半同步不能保证主备数据之间完全同步，因为半同步可能会退化成异步复制。半同步在没有退化的状态下，可以提升主备数据的一致性。如果使用半同步，一般会给主库添加多个备库，只要有一个备库接收到Binlog，主库事务就可以完成提交，减少由于单个备库的问题导致主库性能下降。</p><h2>总结</h2><p>好了，这一讲中，我们分析了MySQL事务的二阶段提交。使用默认的异步复制，在极端情况下，主备数据可能会出现不一致。sync_binlog设置为1时，可以保障主库的数据一致性。</p><p>半同步可以部分提升主备之间的数据一致性，开启半同步会有一些性能开销，使用半同步需要做好监控。</p><h2>思考题</h2><p>主备库数据的一致性非常重要。如果数据不一致了，会带来很多问题，备库的复制可能会中断，业务切换到备库后，会取到错误的数据，影响业务。而且一般我们会在备库上备份，避免备份时影响主库性能，但如果备库的数据有问题，那么我们的备份也都是有问题的。</p><p>那么怎么检查主备库之间的数据是不是一致的呢？</p><p>期待你的思考，欢迎在留言区中与我交流。如果今天的课程让你有所收获，也欢迎转发给有需要的朋友。我们下节课再见。</p>","neighbors":{"left":{"article_title":"34｜MySQL数据库高可用架构部署和维护","id":820990},"right":{"article_title":"36｜备库有延迟怎么办？","id":824886}},"comments":[{"had_liked":false,"id":395816,"user_name":"binzhang","can_delete":false,"product_type":"c1","uid":1647189,"ip_address":"美国","ucode":"F2670F2EA24FAD","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q3auHgzwzM59PTNiaDASVicbVaeWBU1WKmOgyHcqVtl85nDwAqDicib1EUKE2RRoU0x0vZctZO4kbPDUTTke8qKfAw/132","comment_is_top":false,"comment_ctime":1732162643,"is_pvip":false,"replies":[{"id":143740,"content":"Good Question👍\n\nTrxID是事务的ID，每个事务有唯一的事务ID，按事务开始的顺序增长。下一个待分配的TrxID保存在变量trx_sys-&gt;next_trx_id_or_no中。\n即使数据库重启了，TrxID也会一直增长。MySQL会定期把当前最大的TrxID写到系统表空间（页面编号TRX_SYS_PAGE_NO，也就是Page No 5，偏移TRX_SYS_TRX_ID_STORE），数据库重启后，从系统表空间获取之前的TrxID最大值，再加上一定的余量，2*TRX_SYS_TRX_ID_WRITE_MARGIN，来初始化trx_sys-&gt;next_trx_id_or_no。\n\n至于XID，MySQL会给每个SQL分配一个query_id，query_id从变量atomic_global_query_id中获取，每次加1。事务的XID，是取事务中第一个执行的SQL的query_id。数据库重启后，XID会重新从0开始分配。XID通常并不连续。在一个Binlog文件中，XID不会重复，因为数据库重启后会创建新的binlog。\n\n一个事务记录在Binlog 中的XID（XID event），和Undo段中的XID，数值上是一样的。崩溃恢复时，Prepared状态的事务，是应该提交还是回滚，依赖Binlog中是不是存在对应的Xid事件。\n\nUndo段中还记录了事务的GTID，Undo段里的GTID的作用，在37讲的“GTID怎么持久化”这一段有一些解释。\nGTID要保存到Update类型的Undo段中，因此即使事务中只有Insert，也要分配一个Undate类型的Undo段，30讲中“Undo表空间”这里有一些描述。\n","user_name":"作者回复","user_name_real":"作者","uid":3898827,"ctime":1732244775,"ip_address":"浙江","comment_id":395816,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100799401,"comment_content":"Question: in chapter &quot;事务怎么回滚（上）&quot;, you mention in undo segment header save TrxID, XA XID, GTID.  what&#39;s difference between TrxID and XA XID and this chapter&#39;s XID?  looks like innodb also write GTID to undo header during two-phase commit?","like_count":2,"discussions":[{"author":{"id":3898827,"avatar":"https://static001.geekbang.org/account/avatar/00/3b/7d/cb/fa3dae58.jpg","nickname":"俊达","note":"","ucode":"F79BF9651AD086","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":654251,"discussion_content":"Good Question👍\n\nTrxID是事务的ID，每个事务有唯一的事务ID，按事务开始的顺序增长。下一个待分配的TrxID保存在变量trx_sys->next_trx_id_or_no中。\n即使数据库重启了，TrxID也会一直增长。MySQL会定期把当前最大的TrxID写到系统表空间（页面编号TRX_SYS_PAGE_NO，也就是Page No 5，偏移TRX_SYS_TRX_ID_STORE），数据库重启后，从系统表空间获取之前的TrxID最大值，再加上一定的余量，2*TRX_SYS_TRX_ID_WRITE_MARGIN，来初始化trx_sys->next_trx_id_or_no。\n\n至于XID，MySQL会给每个SQL分配一个query_id，query_id从变量atomic_global_query_id中获取，每次加1。事务的XID，是取事务中第一个执行的SQL的query_id。数据库重启后，XID会重新从0开始分配。XID通常并不连续。在一个Binlog文件中，XID不会重复，因为数据库重启后会创建新的binlog。\n\n一个事务记录在Binlog 中的XID（XID event），和Undo段中的XID，数值上是一样的。崩溃恢复时，Prepared状态的事务，是应该提交还是回滚，依赖Binlog中是不是存在对应的Xid事件。\n\nUndo段中还记录了事务的GTID，Undo段里的GTID的作用，在37讲的“GTID怎么持久化”这一段有一些解释。\nGTID要保存到Update类型的Undo段中，因此即使事务中只有Insert，也要分配一个Undate类型的Undo段，30讲中“Undo表空间”这里有一些描述。\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1732244775,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":395611,"user_name":"叶明","can_delete":false,"product_type":"c1","uid":1412429,"ip_address":"江苏","ucode":"D0B4B7660DA766","user_header":"https://static001.geekbang.org/account/avatar/00/15/8d/4d/992070e8.jpg","comment_is_top":false,"comment_ctime":1731403692,"is_pvip":false,"replies":[{"id":143685,"content":"👍👍\nPercona出品了很多实用的数据库运维工具。\n\n","user_name":"作者回复","user_name_real":"编辑","uid":3898827,"ctime":1731563630,"ip_address":"浙江","comment_id":395611,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100799401,"comment_content":"可以用 pt-table-checksum 工具来校验主备数据的一致性。主要原理是让主备处于理论上数据一致的视图里，利用事务的可重复读以及函数 WAIT_FOR_EXECUTED_GTID_SET(gtid_set[, timeout]) &#47; MASTER_POS_WAIT(log_name,log_pos[,timeout][,channel]) 来拿到主备理论上的一致性视图，\n然后分别计算主备上表分批的 checksum，不同就代表这段范围的数据不一致，再到行级别比对数据。","like_count":2,"discussions":[{"author":{"id":3898827,"avatar":"https://static001.geekbang.org/account/avatar/00/3b/7d/cb/fa3dae58.jpg","nickname":"俊达","note":"","ucode":"F79BF9651AD086","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":653912,"discussion_content":"👍👍\nPercona出品了很多实用的数据库运维工具。\n\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1731563630,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]}]}