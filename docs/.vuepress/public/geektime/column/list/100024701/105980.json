{"id":105980,"title":"44 | Socket内核数据结构：如何成立特大项目合作部？","content":"<p>上一节我们讲了Socket在TCP和UDP场景下的调用流程。这一节，我们就沿着这个流程到内核里面一探究竟，看看在内核里面，都创建了哪些数据结构，做了哪些事情。</p><h2>解析socket函数</h2><p>我们从Socket系统调用开始。</p><pre><code>SYSCALL_DEFINE3(socket, int, family, int, type, int, protocol)\n{\n\tint retval;\n\tstruct socket *sock;\n\tint flags;\n......\n\tif (SOCK_NONBLOCK != O_NONBLOCK &amp;&amp; (flags &amp; SOCK_NONBLOCK))\n\t\tflags = (flags &amp; ~SOCK_NONBLOCK) | O_NONBLOCK;\n\n\tretval = sock_create(family, type, protocol, &amp;sock);\n......\n\tretval = sock_map_fd(sock, flags &amp; (O_CLOEXEC | O_NONBLOCK));\n......\n\treturn retval;\n}\n</code></pre><p>这里面的代码比较容易看懂，Socket系统调用会调用sock_create创建一个struct socket结构，然后通过sock_map_fd和文件描述符对应起来。</p><p>在创建Socket的时候，有三个参数。</p><p>一个是<strong>family</strong>，表示地址族。不是所有的Socket都要通过IP进行通信，还有其他的通信方式。例如，下面的定义中，domain sockets就是通过本地文件进行通信的，不需要IP地址。只不过，通过IP地址只是最常用的模式，所以我们这里着重分析这种模式。</p><pre><code>#define AF_UNIX 1/* Unix domain sockets */\n#define AF_INET 2/* Internet IP Protocol */\n</code></pre><p>第二个参数是<strong>type</strong>，也即Socket的类型。类型是比较少的。</p><p>第三个参数是<strong>protocol</strong>，是协议。协议数目是比较多的，也就是说，多个协议会属于同一种类型。</p><p>常用的Socket类型有三种，分别是SOCK_STREAM、SOCK_DGRAM和SOCK_RAW。</p><pre><code>enum sock_type {\nSOCK_STREAM = 1,\nSOCK_DGRAM = 2,\nSOCK_RAW = 3,\n......\n}\n</code></pre><p>SOCK_STREAM是面向数据流的，协议IPPROTO_TCP属于这种类型。SOCK_DGRAM是面向数据报的，协议IPPROTO_UDP属于这种类型。如果在内核里面看的话，IPPROTO_ICMP也属于这种类型。SOCK_RAW是原始的IP包，IPPROTO_IP属于这种类型。</p><!-- [[[read_end]]] --><p><strong>这一节，我们重点看SOCK_STREAM类型和IPPROTO_TCP协议。</strong></p><p>为了管理family、type、protocol这三个分类层次，内核会创建对应的数据结构。</p><p>接下来，我们打开sock_create函数看一下。它会调用__sock_create。</p><pre><code>int __sock_create(struct net *net, int family, int type, int protocol,\n\t\t\t struct socket **res, int kern)\n{\n\tint err;\n\tstruct socket *sock;\n\tconst struct net_proto_family *pf;\n......\n\tsock = sock_alloc();\n......\n\tsock-&gt;type = type;\n......\n\tpf = rcu_dereference(net_families[family]);\n......\n\terr = pf-&gt;create(net, sock, protocol, kern);\n......\n\t*res = sock;\n\n\treturn 0;\n}\n</code></pre><p>这里先是分配了一个struct socket结构。接下来我们要用到family参数。这里有一个net_families数组，我们可以以family参数为下标，找到对应的struct net_proto_family。</p><pre><code>/* Supported address families. */\n#define AF_UNSPEC\t0\n#define AF_UNIX\t\t1\t/* Unix domain sockets \t\t*/\n#define AF_LOCAL\t1\t/* POSIX name for AF_UNIX\t*/\n#define AF_INET\t\t2\t/* Internet IP Protocol \t*/\n......\n#define AF_INET6\t10\t/* IP version 6\t\t\t*/\n......\n#define AF_MPLS\t\t28\t/* MPLS */\n......\n#define AF_MAX\t\t44\t/* For now.. */\n#define NPROTO\t\tAF_MAX\n\nstruct net_proto_family __rcu *net_families[NPROTO] __read_mostly;\n</code></pre><p>我们可以找到net_families的定义。每一个地址族在这个数组里面都有一项，里面的内容是net_proto_family。每一种地址族都有自己的net_proto_family，IP地址族的net_proto_family定义如下，里面最重要的就是，create函数指向inet_create。</p><pre><code>//net/ipv4/af_inet.c\nstatic const struct net_proto_family inet_family_ops = {\n\t.family = PF_INET,\n\t.create = inet_create,//这个用于socket系统调用创建\n......\n}\n</code></pre><p>我们回到函数__sock_create。接下来，在这里面，这个inet_create会被调用。</p><pre><code>static int inet_create(struct net *net, struct socket *sock, int protocol, int kern)\n{\n\tstruct sock *sk;\n\tstruct inet_protosw *answer;\n\tstruct inet_sock *inet;\n\tstruct proto *answer_prot;\n\tunsigned char answer_flags;\n\tint try_loading_module = 0;\n\tint err;\n\n\t/* Look for the requested type/protocol pair. */\nlookup_protocol:\n\tlist_for_each_entry_rcu(answer, &amp;inetsw[sock-&gt;type], list) {\n\t\terr = 0;\n\t\t/* Check the non-wild match. */\n\t\tif (protocol == answer-&gt;protocol) {\n\t\t\tif (protocol != IPPROTO_IP)\n\t\t\t\tbreak;\n\t\t} else {\n\t\t\t/* Check for the two wild cases. */\n\t\t\tif (IPPROTO_IP == protocol) {\n\t\t\t\tprotocol = answer-&gt;protocol;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (IPPROTO_IP == answer-&gt;protocol)\n\t\t\t\tbreak;\n\t\t}\n\t\terr = -EPROTONOSUPPORT;\n\t}\n......\n\tsock-&gt;ops = answer-&gt;ops;\n\tanswer_prot = answer-&gt;prot;\n\tanswer_flags = answer-&gt;flags;\n......\n\tsk = sk_alloc(net, PF_INET, GFP_KERNEL, answer_prot, kern);\n......\n\tinet = inet_sk(sk);\n\tinet-&gt;nodefrag = 0;\n\tif (SOCK_RAW == sock-&gt;type) {\n\t\tinet-&gt;inet_num = protocol;\n\t\tif (IPPROTO_RAW == protocol)\n\t\t\tinet-&gt;hdrincl = 1;\n\t}\n\tinet-&gt;inet_id = 0;\n\tsock_init_data(sock, sk);\n\n\tsk-&gt;sk_destruct\t   = inet_sock_destruct;\n\tsk-&gt;sk_protocol\t   = protocol;\n\tsk-&gt;sk_backlog_rcv = sk-&gt;sk_prot-&gt;backlog_rcv;\n\n\tinet-&gt;uc_ttl\t= -1;\n\tinet-&gt;mc_loop\t= 1;\n\tinet-&gt;mc_ttl\t= 1;\n\tinet-&gt;mc_all\t= 1;\n\tinet-&gt;mc_index\t= 0;\n\tinet-&gt;mc_list\t= NULL;\n\tinet-&gt;rcv_tos\t= 0;\n\n\tif (inet-&gt;inet_num) {\n\t\tinet-&gt;inet_sport = htons(inet-&gt;inet_num);\n\t\t/* Add to protocol hash chains. */\n\t\terr = sk-&gt;sk_prot-&gt;hash(sk);\n\t}\n\n\tif (sk-&gt;sk_prot-&gt;init) {\n\t\terr = sk-&gt;sk_prot-&gt;init(sk);\n\t}\n......\n}\n</code></pre><p>在inet_create中，我们先会看到一个循环list_for_each_entry_rcu。在这里，第二个参数type开始起作用。因为循环查看的是inetsw[sock-&gt;type]。</p><p>这里的inetsw也是一个数组，type作为下标，里面的内容是struct inet_protosw，是协议，也即inetsw数组对于每个类型有一项，这一项里面是属于这个类型的协议。</p><pre><code>static struct list_head inetsw[SOCK_MAX];\n\nstatic int __init inet_init(void)\n{\n......\n\t/* Register the socket-side information for inet_create. */\n\tfor (r = &amp;inetsw[0]; r &lt; &amp;inetsw[SOCK_MAX]; ++r)\n\t\tINIT_LIST_HEAD(r);\n\tfor (q = inetsw_array; q &lt; &amp;inetsw_array[INETSW_ARRAY_LEN]; ++q)\n\t\tinet_register_protosw(q);\n......\n}\n</code></pre><p>inetsw数组是在系统初始化的时候初始化的，就像下面代码里面实现的一样。</p><p>首先，一个循环会将inetsw数组的每一项，都初始化为一个链表。咱们前面说了，一个type类型会包含多个protocol，因而我们需要一个链表。接下来一个循环，是将inetsw_array注册到inetsw数组里面去。inetsw_array的定义如下，这个数组里面的内容很重要，后面会用到它们。</p><pre><code>static struct inet_protosw inetsw_array[] =\n{\n\t{\n\t\t.type =       SOCK_STREAM,\n\t\t.protocol =   IPPROTO_TCP,\n\t\t.prot =       &amp;tcp_prot,\n\t\t.ops =        &amp;inet_stream_ops,\n\t\t.flags =      INET_PROTOSW_PERMANENT |\n\t\t\t      INET_PROTOSW_ICSK,\n\t},\n\t{\n\t\t.type =       SOCK_DGRAM,\n\t\t.protocol =   IPPROTO_UDP,\n\t\t.prot =       &amp;udp_prot,\n\t\t.ops =        &amp;inet_dgram_ops,\n\t\t.flags =      INET_PROTOSW_PERMANENT,\n     },\n     {\n\t\t.type =       SOCK_DGRAM,\n\t\t.protocol =   IPPROTO_ICMP,\n\t\t.prot =       &amp;ping_prot,\n\t\t.ops =        &amp;inet_sockraw_ops,\n\t\t.flags =      INET_PROTOSW_REUSE,\n     },\n     {\n        .type =       SOCK_RAW,\n\t    .protocol =   IPPROTO_IP,\t/* wild card */\n\t    .prot =       &amp;raw_prot,\n\t    .ops =        &amp;inet_sockraw_ops,\n\t    .flags =      INET_PROTOSW_REUSE,\n     }\n}\n</code></pre><p>我们回到inet_create的list_for_each_entry_rcu循环中。到这里就好理解了，这是在inetsw数组中，根据type找到属于这个类型的列表，然后依次比较列表中的struct inet_protosw的protocol是不是用户指定的protocol；如果是，就得到了符合用户指定的family-&gt;type-&gt;protocol的struct inet_protosw *answer对象。</p><p>接下来，struct socket *sock的ops成员变量，被赋值为answer的ops。对于TCP来讲，就是inet_stream_ops。后面任何用户对于这个socket的操作，都是通过inet_stream_ops进行的。</p><p>接下来，我们创建一个struct sock *sk对象。这里比较让人困惑。socket和sock看起来几乎一样，容易让人混淆，这里需要说明一下，socket是用于负责对上给用户提供接口，并且和文件系统关联。而sock，负责向下对接内核网络协议栈。</p><p>在sk_alloc函数中，struct inet_protosw *answer结构的tcp_prot赋值给了struct sock *sk的sk_prot成员。tcp_prot的定义如下，里面定义了很多的函数，都是sock之下内核协议栈的动作。</p><pre><code>struct proto tcp_prot = {\n\t.name\t\t\t= &quot;TCP&quot;,\n\t.owner\t\t\t= THIS_MODULE,\n\t.close\t\t\t= tcp_close,\n\t.connect\t\t= tcp_v4_connect,\n\t.disconnect\t\t= tcp_disconnect,\n\t.accept\t\t\t= inet_csk_accept,\n\t.ioctl\t\t\t= tcp_ioctl,\n\t.init\t\t\t= tcp_v4_init_sock,\n\t.destroy\t\t= tcp_v4_destroy_sock,\n\t.shutdown\t\t= tcp_shutdown,\n\t.setsockopt\t\t= tcp_setsockopt,\n\t.getsockopt\t\t= tcp_getsockopt,\n\t.keepalive\t\t= tcp_set_keepalive,\n\t.recvmsg\t\t= tcp_recvmsg,\n\t.sendmsg\t\t= tcp_sendmsg,\n\t.sendpage\t\t= tcp_sendpage,\n\t.backlog_rcv\t\t= tcp_v4_do_rcv,\n\t.release_cb\t\t= tcp_release_cb,\n\t.hash\t\t\t= inet_hash,\n    .get_port\t\t= inet_csk_get_port,\n......\n}\n</code></pre><p>在inet_create函数中，接下来创建一个struct inet_sock结构，这个结构一开始就是struct sock，然后扩展了一些其他的信息，剩下的代码就填充这些信息。这一幕我们会经常看到，将一个结构放在另一个结构的开始位置，然后扩展一些成员，通过对于指针的强制类型转换，来访问这些成员。</p><p>socket的创建至此结束。</p><h2>解析bind函数</h2><p>接下来，我们来看bind。</p><pre><code>SYSCALL_DEFINE3(bind, int, fd, struct sockaddr __user *, umyaddr, int, addrlen)\n{\n\tstruct socket *sock;\n\tstruct sockaddr_storage address;\n\tint err, fput_needed;\n\n\tsock = sockfd_lookup_light(fd, &amp;err, &amp;fput_needed);\n\tif (sock) {\n\t\terr = move_addr_to_kernel(umyaddr, addrlen, &amp;address);\n\t\tif (err &gt;= 0) {\n\t\t\terr = sock-&gt;ops-&gt;bind(sock,\n\t\t\t\t\t\t      (struct sockaddr *)\n\t\t\t\t\t\t      &amp;address, addrlen);\n\t\t}\n\t\tfput_light(sock-&gt;file, fput_needed);\n\t}\n\treturn err;\n}\n</code></pre><p>在bind中，sockfd_lookup_light会根据fd文件描述符，找到struct socket结构。然后将sockaddr从用户态拷贝到内核态，然后调用struct socket结构里面ops的bind函数。根据前面创建socket的时候的设定，调用的是inet_stream_ops的bind函数，也即调用inet_bind。</p><pre><code>int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)\n{\n\tstruct sockaddr_in *addr = (struct sockaddr_in *)uaddr;\n\tstruct sock *sk = sock-&gt;sk;\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct net *net = sock_net(sk);\n\tunsigned short snum;\n......\n\tsnum = ntohs(addr-&gt;sin_port);\n......\n\tinet-&gt;inet_rcv_saddr = inet-&gt;inet_saddr = addr-&gt;sin_addr.s_addr;\n\t/* Make sure we are allowed to bind here. */\n\tif ((snum || !inet-&gt;bind_address_no_port) &amp;&amp;\n\t    sk-&gt;sk_prot-&gt;get_port(sk, snum)) {\n......\n\t}\n\tinet-&gt;inet_sport = htons(inet-&gt;inet_num);\n\tinet-&gt;inet_daddr = 0;\n\tinet-&gt;inet_dport = 0;\n\tsk_dst_reset(sk);\n}\n</code></pre><p>bind里面会调用sk_prot的get_port函数，也即inet_csk_get_port来检查端口是否冲突，是否可以绑定。如果允许，则会设置struct inet_sock的本方的地址inet_saddr和本方的端口inet_sport，对方的地址inet_daddr和对方的端口inet_dport都初始化为0。</p><p>bind的逻辑相对比较简单，就到这里了。</p><h2>解析listen函数</h2><p>接下来我们来看listen。</p><pre><code>SYSCALL_DEFINE2(listen, int, fd, int, backlog)\n{\n\tstruct socket *sock;\n\tint err, fput_needed;\n\tint somaxconn;\n\n\tsock = sockfd_lookup_light(fd, &amp;err, &amp;fput_needed);\n\tif (sock) {\n\t\tsomaxconn = sock_net(sock-&gt;sk)-&gt;core.sysctl_somaxconn;\n\t\tif ((unsigned int)backlog &gt; somaxconn)\n\t\t\tbacklog = somaxconn;\n\t\terr = sock-&gt;ops-&gt;listen(sock, backlog);\n\t\tfput_light(sock-&gt;file, fput_needed);\n\t}\n\treturn err;\n}\n</code></pre><p>在listen中，我们还是通过sockfd_lookup_light，根据fd文件描述符，找到struct socket结构。接着，我们调用struct socket结构里面ops的listen函数。根据前面创建socket的时候的设定，调用的是inet_stream_ops的listen函数，也即调用inet_listen。</p><pre><code>int inet_listen(struct socket *sock, int backlog)\n{\n\tstruct sock *sk = sock-&gt;sk;\n\tunsigned char old_state;\n\tint err;\n\told_state = sk-&gt;sk_state;\n\t/* Really, if the socket is already in listen state\n\t * we can only allow the backlog to be adjusted.\n\t */\n\tif (old_state != TCP_LISTEN) {\n\t\terr = inet_csk_listen_start(sk, backlog);\n\t}\n\tsk-&gt;sk_max_ack_backlog = backlog;\n}\n</code></pre><p>如果这个socket还不在TCP_LISTEN状态，会调用inet_csk_listen_start进入监听状态。</p><pre><code>int inet_csk_listen_start(struct sock *sk, int backlog)\n{\n\tstruct inet_connection_sock *icsk = inet_csk(sk);\n\tstruct inet_sock *inet = inet_sk(sk);\n\tint err = -EADDRINUSE;\n\n\treqsk_queue_alloc(&amp;icsk-&gt;icsk_accept_queue);\n\n\tsk-&gt;sk_max_ack_backlog = backlog;\n\tsk-&gt;sk_ack_backlog = 0;\n\tinet_csk_delack_init(sk);\n\n\tsk_state_store(sk, TCP_LISTEN);\n\tif (!sk-&gt;sk_prot-&gt;get_port(sk, inet-&gt;inet_num)) {\n......\n\t}\n......\n}\n</code></pre><p>这里面建立了一个新的结构inet_connection_sock，这个结构一开始是struct inet_sock，inet_csk其实做了一次强制类型转换，扩大了结构，看到了吧，又是这个套路。</p><p>struct inet_connection_sock结构比较复杂。如果打开它，你能看到处于各种状态的队列，各种超时时间、拥塞控制等字眼。我们说TCP是面向连接的，就是客户端和服务端都是有一个结构维护连接的状态，就是指这个结构。我们这里先不详细分析里面的变量，因为太多了，后面我们遇到一个分析一个。</p><p>首先，我们遇到的是icsk_accept_queue。它是干什么的呢？</p><p>在TCP的状态里面，有一个listen状态，当调用listen函数之后，就会进入这个状态，虽然我们写程序的时候，一般要等待服务端调用accept后，等待在哪里的时候，让客户端就发起连接。其实服务端一旦处于listen状态，不用accept，客户端也能发起连接。其实TCP的状态中，没有一个是否被accept的状态，那accept函数的作用是什么呢？</p><p>在内核中，为每个Socket维护两个队列。一个是已经建立了连接的队列，这时候连接三次握手已经完毕，处于established状态；一个是还没有完全建立连接的队列，这个时候三次握手还没完成，处于syn_rcvd的状态。</p><p>服务端调用accept函数，其实是在第一个队列中拿出一个已经完成的连接进行处理。如果还没有完成就阻塞等待。这里的icsk_accept_queue就是第一个队列。</p><p>初始化完之后，将TCP的状态设置为TCP_LISTEN，再次调用get_port判断端口是否冲突。</p><p>至此，listen的逻辑就结束了。</p><h2>解析accept函数</h2><p>接下来，我们解析服务端调用accept。</p><pre><code>SYSCALL_DEFINE3(accept, int, fd, struct sockaddr __user *, upeer_sockaddr,\n\t\tint __user *, upeer_addrlen)\n{\n\treturn sys_accept4(fd, upeer_sockaddr, upeer_addrlen, 0);\n}\n\nSYSCALL_DEFINE4(accept4, int, fd, struct sockaddr __user *, upeer_sockaddr,\n\t\tint __user *, upeer_addrlen, int, flags)\n{\n\tstruct socket *sock, *newsock;\n\tstruct file *newfile;\n\tint err, len, newfd, fput_needed;\n\tstruct sockaddr_storage address;\n......\n\tsock = sockfd_lookup_light(fd, &amp;err, &amp;fput_needed);\n\tnewsock = sock_alloc();\n\tnewsock-&gt;type = sock-&gt;type;\n\tnewsock-&gt;ops = sock-&gt;ops;\n\tnewfd = get_unused_fd_flags(flags);\n\tnewfile = sock_alloc_file(newsock, flags, sock-&gt;sk-&gt;sk_prot_creator-&gt;name);\n\terr = sock-&gt;ops-&gt;accept(sock, newsock, sock-&gt;file-&gt;f_flags, false);\n\tif (upeer_sockaddr) {\n\t\tif (newsock-&gt;ops-&gt;getname(newsock, (struct sockaddr *)&amp;address, &amp;len, 2) &lt; 0) {\n\t\t}\n\t\terr = move_addr_to_user(&amp;address,\n\t\t\t\t\tlen, upeer_sockaddr, upeer_addrlen);\n\t}\n\tfd_install(newfd, newfile);\n......\n}\n</code></pre><p>accept函数的实现，印证了socket的原理中说的那样，原来的socket是监听socket，这里我们会找到原来的struct socket，并基于它去创建一个新的newsock。这才是连接socket。除此之外，我们还会创建一个新的struct file和fd，并关联到socket。</p><p>这里面还会调用struct socket的sock-&gt;ops-&gt;accept，也即会调用inet_stream_ops的accept函数，也即inet_accept。</p><pre><code>int inet_accept(struct socket *sock, struct socket *newsock, int flags, bool kern)\n{\n\tstruct sock *sk1 = sock-&gt;sk;\n\tint err = -EINVAL;\n\tstruct sock *sk2 = sk1-&gt;sk_prot-&gt;accept(sk1, flags, &amp;err, kern);\n\tsock_rps_record_flow(sk2);\n\tsock_graft(sk2, newsock);\n\tnewsock-&gt;state = SS_CONNECTED;\n}\n</code></pre><p>inet_accept会调用struct sock的sk1-&gt;sk_prot-&gt;accept，也即tcp_prot的accept函数，inet_csk_accept函数。</p><pre><code>/*\n * This will accept the next outstanding connection.\n */\nstruct sock *inet_csk_accept(struct sock *sk, int flags, int *err, bool kern)\n{\n\tstruct inet_connection_sock *icsk = inet_csk(sk);\n\tstruct request_sock_queue *queue = &amp;icsk-&gt;icsk_accept_queue;\n\tstruct request_sock *req;\n\tstruct sock *newsk;\n\tint error;\n\n\tif (sk-&gt;sk_state != TCP_LISTEN)\n\t\tgoto out_err;\n\n\t/* Find already established connection */\n\tif (reqsk_queue_empty(queue)) {\n\t\tlong timeo = sock_rcvtimeo(sk, flags &amp; O_NONBLOCK);\n\t\terror = inet_csk_wait_for_connect(sk, timeo);\n\t}\n\treq = reqsk_queue_remove(queue, sk);\n\tnewsk = req-&gt;sk;\n......\n}\n\n/*\n * Wait for an incoming connection, avoid race conditions. This must be called\n * with the socket locked.\n */\nstatic int inet_csk_wait_for_connect(struct sock *sk, long timeo)\n{\n\tstruct inet_connection_sock *icsk = inet_csk(sk);\n\tDEFINE_WAIT(wait);\n\tint err;\n\tfor (;;) {\n\t\tprepare_to_wait_exclusive(sk_sleep(sk), &amp;wait,\n\t\t\t\t\t  TASK_INTERRUPTIBLE);\n\t\trelease_sock(sk);\n\t\tif (reqsk_queue_empty(&amp;icsk-&gt;icsk_accept_queue))\n\t\t\ttimeo = schedule_timeout(timeo);\n\t\tsched_annotate_sleep();\n\t\tlock_sock(sk);\n\t\terr = 0;\n\t\tif (!reqsk_queue_empty(&amp;icsk-&gt;icsk_accept_queue))\n\t\t\tbreak;\n\t\terr = -EINVAL;\n\t\tif (sk-&gt;sk_state != TCP_LISTEN)\n\t\t\tbreak;\n\t\terr = sock_intr_errno(timeo);\n\t\tif (signal_pending(current))\n\t\t\tbreak;\n\t\terr = -EAGAIN;\n\t\tif (!timeo)\n\t\t\tbreak;\n\t}\n\tfinish_wait(sk_sleep(sk), &amp;wait);\n\treturn err;\n}\n</code></pre><p>inet_csk_accept的实现，印证了上面我们讲的两个队列的逻辑。如果icsk_accept_queue为空，则调用inet_csk_wait_for_connect进行等待；等待的时候，调用schedule_timeout，让出CPU，并且将进程状态设置为TASK_INTERRUPTIBLE。</p><p>如果再次CPU醒来，我们会接着判断icsk_accept_queue是否为空，同时也会调用signal_pending看有没有信号可以处理。一旦icsk_accept_queue不为空，就从inet_csk_wait_for_connect中返回，在队列中取出一个struct sock对象赋值给newsk。</p><h2>解析connect函数</h2><p>什么情况下，icsk_accept_queue才不为空呢？当然是三次握手结束才可以。接下来我们来分析三次握手的过程。</p><p><img src=\"https://static001.geekbang.org/resource/image/ab/df/ab92c2afb4aafb53143c471293ccb2df.png\" alt=\"\"></p><p>三次握手一般是由客户端调用connect发起。</p><pre><code>SYSCALL_DEFINE3(connect, int, fd, struct sockaddr __user *, uservaddr,\n\t\tint, addrlen)\n{\n\tstruct socket *sock;\n\tstruct sockaddr_storage address;\n\tint err, fput_needed;\n\tsock = sockfd_lookup_light(fd, &amp;err, &amp;fput_needed);\n\terr = move_addr_to_kernel(uservaddr, addrlen, &amp;address);\n\terr = sock-&gt;ops-&gt;connect(sock, (struct sockaddr *)&amp;address, addrlen, sock-&gt;file-&gt;f_flags);\n}\n</code></pre><p>connect函数的实现一开始你应该很眼熟，还是通过sockfd_lookup_light，根据fd文件描述符，找到struct socket结构。接着，我们会调用struct socket结构里面ops的connect函数，根据前面创建socket的时候的设定，调用inet_stream_ops的connect函数，也即调用inet_stream_connect。</p><pre><code>/*\n *\tConnect to a remote host. There is regrettably still a little\n *\tTCP 'magic' in here.\n */\nint __inet_stream_connect(struct socket *sock, struct sockaddr *uaddr,\n\t\t\t  int addr_len, int flags, int is_sendmsg)\n{\n\tstruct sock *sk = sock-&gt;sk;\n\tint err;\n\tlong timeo;\n\n\tswitch (sock-&gt;state) {\n......\n\tcase SS_UNCONNECTED:\n\t\terr = -EISCONN;\n\t\tif (sk-&gt;sk_state != TCP_CLOSE)\n\t\t\tgoto out;\n\n\t\terr = sk-&gt;sk_prot-&gt;connect(sk, uaddr, addr_len);\n\t\tsock-&gt;state = SS_CONNECTING;\n\t\tbreak;\n\t}\n\n\ttimeo = sock_sndtimeo(sk, flags &amp; O_NONBLOCK);\n\n\tif ((1 &lt;&lt; sk-&gt;sk_state) &amp; (TCPF_SYN_SENT | TCPF_SYN_RECV)) {\n......\n\t\tif (!timeo || !inet_wait_for_connect(sk, timeo, writebias))\n\t\t\tgoto out;\n\n\t\terr = sock_intr_errno(timeo);\n\t\tif (signal_pending(current))\n\t\t\tgoto out;\n\t}\n\tsock-&gt;state = SS_CONNECTED;\n}\n</code></pre><p>在__inet_stream_connect里面，我们发现，如果socket处于SS_UNCONNECTED状态，那就调用struct sock的sk-&gt;sk_prot-&gt;connect，也即tcp_prot的connect函数——tcp_v4_connect函数。</p><pre><code>int tcp_v4_connect(struct sock *sk, struct sockaddr *uaddr, int addr_len)\n{\n\tstruct sockaddr_in *usin = (struct sockaddr_in *)uaddr;\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\t__be16 orig_sport, orig_dport;\n\t__be32 daddr, nexthop;\n\tstruct flowi4 *fl4;\n\tstruct rtable *rt;\n......\n\torig_sport = inet-&gt;inet_sport;\n\torig_dport = usin-&gt;sin_port;\n\trt = ip_route_connect(fl4, nexthop, inet-&gt;inet_saddr,\n\t\t\t      RT_CONN_FLAGS(sk), sk-&gt;sk_bound_dev_if,\n\t\t\t      IPPROTO_TCP,\n\t\t\t      orig_sport, orig_dport, sk);\n......\n\ttcp_set_state(sk, TCP_SYN_SENT);\n\terr = inet_hash_connect(tcp_death_row, sk);\n\tsk_set_txhash(sk);\n\trt = ip_route_newports(fl4, rt, orig_sport, orig_dport,\n\t\t\t       inet-&gt;inet_sport, inet-&gt;inet_dport, sk);\n\t/* OK, now commit destination to socket.  */\n\tsk-&gt;sk_gso_type = SKB_GSO_TCPV4;\n\tsk_setup_caps(sk, &amp;rt-&gt;dst);\n    if (likely(!tp-&gt;repair)) {\n\t\tif (!tp-&gt;write_seq)\n\t\t\ttp-&gt;write_seq = secure_tcp_seq(inet-&gt;inet_saddr,\n\t\t\t\t\t\t       inet-&gt;inet_daddr,\n\t\t\t\t\t\t       inet-&gt;inet_sport,\n\t\t\t\t\t\t       usin-&gt;sin_port);\n\t\ttp-&gt;tsoffset = secure_tcp_ts_off(sock_net(sk),\n\t\t\t\t\t\t inet-&gt;inet_saddr,\n\t\t\t\t\t\t inet-&gt;inet_daddr);\n\t}\n\trt = NULL;\n......\n\terr = tcp_connect(sk);\n......\n}\n</code></pre><p>在tcp_v4_connect函数中，ip_route_connect其实是做一个路由的选择。为什么呢？因为三次握手马上就要发送一个SYN包了，这就要凑齐源地址、源端口、目标地址、目标端口。目标地址和目标端口是服务端的，已经知道源端口是客户端随机分配的，源地址应该用哪一个呢？这时候要选择一条路由，看从哪个网卡出去，就应该填写哪个网卡的IP地址。</p><p>接下来，在发送SYN之前，我们先将客户端socket的状态设置为TCP_SYN_SENT。然后初始化TCP的seq num，也即write_seq，然后调用tcp_connect进行发送。</p><pre><code>/* Build a SYN and send it off. */\nint tcp_connect(struct sock *sk)\n{\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\tstruct sk_buff *buff;\n\tint err;\n......\n\ttcp_connect_init(sk);\n......\n\tbuff = sk_stream_alloc_skb(sk, 0, sk-&gt;sk_allocation, true);\n......\n\ttcp_init_nondata_skb(buff, tp-&gt;write_seq++, TCPHDR_SYN);\n\ttcp_mstamp_refresh(tp);\n\ttp-&gt;retrans_stamp = tcp_time_stamp(tp);\n\ttcp_connect_queue_skb(sk, buff);\n\ttcp_ecn_send_syn(sk, buff);\n\n\t/* Send off SYN; include data in Fast Open. */\n\terr = tp-&gt;fastopen_req ? tcp_send_syn_data(sk, buff) :\n\t      tcp_transmit_skb(sk, buff, 1, sk-&gt;sk_allocation);\n......\n\ttp-&gt;snd_nxt = tp-&gt;write_seq;\n\ttp-&gt;pushed_seq = tp-&gt;write_seq;\n\tbuff = tcp_send_head(sk);\n\tif (unlikely(buff)) {\n\t\ttp-&gt;snd_nxt\t= TCP_SKB_CB(buff)-&gt;seq;\n\t\ttp-&gt;pushed_seq\t= TCP_SKB_CB(buff)-&gt;seq;\n\t}\n......\n\t/* Timer for repeating the SYN until an answer. */\n\tinet_csk_reset_xmit_timer(sk, ICSK_TIME_RETRANS,\n\t\t\t\t  inet_csk(sk)-&gt;icsk_rto, TCP_RTO_MAX);\n\treturn 0;\n}\n</code></pre><p>在tcp_connect中，有一个新的结构struct tcp_sock，如果打开他，你会发现他是struct inet_connection_sock的一个扩展，struct inet_connection_sock在struct tcp_sock开头的位置，通过强制类型转换访问，故伎重演又一次。</p><p>struct tcp_sock里面维护了更多的TCP的状态，咱们同样是遇到了再分析。</p><p>接下来tcp_init_nondata_skb初始化一个SYN包，tcp_transmit_skb将SYN包发送出去，inet_csk_reset_xmit_timer设置了一个timer，如果SYN发送不成功，则再次发送。</p><p>发送网络包的过程，我们放到下一节讲解。这里我们姑且认为SYN已经发送出去了。</p><p>我们回到__inet_stream_connect函数，在调用sk-&gt;sk_prot-&gt;connect之后，inet_wait_for_connect会一直等待客户端收到服务端的ACK。而我们知道，服务端在accept之后，也是在等待中。</p><p>网络包是如何接收的呢？对于解析的详细过程，我们会在下下节讲解，这里为了解析三次握手，我们简单的看网络包接收到TCP层做的部分事情。</p><pre><code>static struct net_protocol tcp_protocol = {\n\t.early_demux\t=\ttcp_v4_early_demux,\n\t.early_demux_handler =  tcp_v4_early_demux,\n\t.handler\t=\ttcp_v4_rcv,\n\t.err_handler\t=\ttcp_v4_err,\n\t.no_policy\t=\t1,\n\t.netns_ok\t=\t1,\n\t.icmp_strict_tag_validation = 1,\n}\n</code></pre><p>我们通过struct net_protocol结构中的handler进行接收，调用的函数是tcp_v4_rcv。接下来的调用链为tcp_v4_rcv-&gt;tcp_v4_do_rcv-&gt;tcp_rcv_state_process。tcp_rcv_state_process，顾名思义，是用来处理接收一个网络包后引起状态变化的。</p><pre><code>int tcp_rcv_state_process(struct sock *sk, struct sk_buff *skb)\n{\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\tstruct inet_connection_sock *icsk = inet_csk(sk);\n\tconst struct tcphdr *th = tcp_hdr(skb);\n\tstruct request_sock *req;\n\tint queued = 0;\n\tbool acceptable;\n\n\tswitch (sk-&gt;sk_state) {\n......\n\tcase TCP_LISTEN:\n......\n\t\tif (th-&gt;syn) {\n\t\t\tacceptable = icsk-&gt;icsk_af_ops-&gt;conn_request(sk, skb) &gt;= 0;\n\t\t\tif (!acceptable)\n\t\t\t\treturn 1;\n\t\t\tconsume_skb(skb);\n\t\t\treturn 0;\n\t\t}\n......\n}\n</code></pre><p>目前服务端是处于TCP_LISTEN状态的，而且发过来的包是SYN，因而就有了上面的代码，调用icsk-&gt;icsk_af_ops-&gt;conn_request函数。struct inet_connection_sock对应的操作是inet_connection_sock_af_ops，按照下面的定义，其实调用的是tcp_v4_conn_request。</p><pre><code>const struct inet_connection_sock_af_ops ipv4_specific = {\n        .queue_xmit        = ip_queue_xmit,\n        .send_check        = tcp_v4_send_check,\n        .rebuild_header    = inet_sk_rebuild_header,\n        .sk_rx_dst_set     = inet_sk_rx_dst_set,\n        .conn_request      = tcp_v4_conn_request,\n        .syn_recv_sock     = tcp_v4_syn_recv_sock,\n        .net_header_len    = sizeof(struct iphdr),\n        .setsockopt        = ip_setsockopt,\n        .getsockopt        = ip_getsockopt,\n        .addr2sockaddr     = inet_csk_addr2sockaddr,\n        .sockaddr_len      = sizeof(struct sockaddr_in),\n        .mtu_reduced       = tcp_v4_mtu_reduced,\n};\n</code></pre><p>tcp_v4_conn_request会调用tcp_conn_request，这个函数也比较长，里面调用了send_synack，但实际调用的是tcp_v4_send_synack。具体发送的过程我们不去管它，看注释我们能知道，这是收到了SYN后，回复一个SYN-ACK，回复完毕后，服务端处于TCP_SYN_RECV。</p><pre><code>int tcp_conn_request(struct request_sock_ops *rsk_ops,\n\t\t     const struct tcp_request_sock_ops *af_ops,\n\t\t     struct sock *sk, struct sk_buff *skb)\n{\n......\naf_ops-&gt;send_synack(sk, dst, &amp;fl, req, &amp;foc,\n\t\t\t\t    !want_cookie ? TCP_SYNACK_NORMAL :\n\t\t\t\t\t\t   TCP_SYNACK_COOKIE);\n......\n}\n\n/*\n *\tSend a SYN-ACK after having received a SYN.\n */\nstatic int tcp_v4_send_synack(const struct sock *sk, struct dst_entry *dst,\n\t\t\t      struct flowi *fl,\n\t\t\t      struct request_sock *req,\n\t\t\t      struct tcp_fastopen_cookie *foc,\n\t\t\t      enum tcp_synack_type synack_type)\n{......}\n</code></pre><p>这个时候，轮到客户端接收网络包了。都是TCP协议栈，所以过程和服务端没有太多区别，还是会走到tcp_rcv_state_process函数的，只不过由于客户端目前处于TCP_SYN_SENT状态，就进入了下面的代码分支。</p><pre><code>int tcp_rcv_state_process(struct sock *sk, struct sk_buff *skb)\n{\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\tstruct inet_connection_sock *icsk = inet_csk(sk);\n\tconst struct tcphdr *th = tcp_hdr(skb);\n\tstruct request_sock *req;\n\tint queued = 0;\n\tbool acceptable;\n\n\tswitch (sk-&gt;sk_state) {\n......\n\tcase TCP_SYN_SENT:\n\t\ttp-&gt;rx_opt.saw_tstamp = 0;\n\t\ttcp_mstamp_refresh(tp);\n\t\tqueued = tcp_rcv_synsent_state_process(sk, skb, th);\n\t\tif (queued &gt;= 0)\n\t\t\treturn queued;\n\t\t/* Do step6 onward by hand. */\n\t\ttcp_urg(sk, skb, th);\n\t\t__kfree_skb(skb);\n\t\ttcp_data_snd_check(sk);\n\t\treturn 0;\n\t}\n......\n}\n</code></pre><p>tcp_rcv_synsent_state_process会调用tcp_send_ack，发送一个ACK-ACK，发送后客户端处于TCP_ESTABLISHED状态。</p><p>又轮到服务端接收网络包了，我们还是归tcp_rcv_state_process函数处理。由于服务端目前处于状态TCP_SYN_RECV状态，因而又走了另外的分支。当收到这个网络包的时候，服务端也处于TCP_ESTABLISHED状态，三次握手结束。</p><pre><code>int tcp_rcv_state_process(struct sock *sk, struct sk_buff *skb)\n{\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\tstruct inet_connection_sock *icsk = inet_csk(sk);\n\tconst struct tcphdr *th = tcp_hdr(skb);\n\tstruct request_sock *req;\n\tint queued = 0;\n\tbool acceptable;\n......\n\tswitch (sk-&gt;sk_state) {\n\tcase TCP_SYN_RECV:\n\t\tif (req) {\n\t\t\tinet_csk(sk)-&gt;icsk_retransmits = 0;\n\t\t\treqsk_fastopen_remove(sk, req, false);\n\t\t} else {\n\t\t\t/* Make sure socket is routed, for correct metrics. */\n\t\t\ticsk-&gt;icsk_af_ops-&gt;rebuild_header(sk);\n\t\t\ttcp_call_bpf(sk, BPF_SOCK_OPS_PASSIVE_ESTABLISHED_CB);\n\t\t\ttcp_init_congestion_control(sk);\n\n\t\t\ttcp_mtup_init(sk);\n\t\t\ttp-&gt;copied_seq = tp-&gt;rcv_nxt;\n\t\t\ttcp_init_buffer_space(sk);\n\t\t}\n\t\tsmp_mb();\n\t\ttcp_set_state(sk, TCP_ESTABLISHED);\n\t\tsk-&gt;sk_state_change(sk);\n\t\tif (sk-&gt;sk_socket)\n\t\t\tsk_wake_async(sk, SOCK_WAKE_IO, POLL_OUT);\n\t\ttp-&gt;snd_una = TCP_SKB_CB(skb)-&gt;ack_seq;\n\t\ttp-&gt;snd_wnd = ntohs(th-&gt;window) &lt;&lt; tp-&gt;rx_opt.snd_wscale;\n\t\ttcp_init_wl(tp, TCP_SKB_CB(skb)-&gt;seq);\n\t\tbreak;\n......\n}\n</code></pre><h2>总结时刻</h2><p>这一节除了网络包的接收和发送，其他的系统调用我们都分析到了。可以看出来，它们有一个统一的数据结构和流程。具体如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/c0/d8/c028381cf45d65d3f148e57408d26bd8.png\" alt=\"\"></p><p>首先，Socket系统调用会有三级参数family、type、protocal，通过这三级参数，分别在net_proto_family表中找到type链表，在type链表中找到protocal对应的操作。这个操作分为两层，对于TCP协议来讲，第一层是inet_stream_ops层，第二层是tcp_prot层。</p><p>于是，接下来的系统调用规律就都一样了：</p><ul>\n<li>bind第一层调用inet_stream_ops的inet_bind函数，第二层调用tcp_prot的inet_csk_get_port函数；</li>\n<li>listen第一层调用inet_stream_ops的inet_listen函数，第二层调用tcp_prot的inet_csk_get_port函数；</li>\n<li>accept第一层调用inet_stream_ops的inet_accept函数，第二层调用tcp_prot的inet_csk_accept函数；</li>\n<li>connect第一层调用inet_stream_ops的inet_stream_connect函数，第二层调用tcp_prot的tcp_v4_connect函数。</li>\n</ul><h2>课堂练习</h2><p>TCP的三次握手协议非常重要，请你务必跟着代码走读一遍。另外我们这里重点关注了TCP的场景，请走读代码的时候，也看一下UDP是如何实现各层的函数的。</p><p>欢迎留言和我分享你的疑惑和见解 ，也欢迎可以收藏本节内容，反复研读。你也可以把今天的内容分享给你的朋友，和他一起学习和进步。</p><p></p>","neighbors":{"left":{"article_title":"43 | Socket通信：遇上特大项目，要学会和其他公司合作","id":105359},"right":{"article_title":"45 | 发送网络包（上）：如何表达我们想让合作伙伴做什么？","id":106490}},"comments":[]}