{"id":227950,"title":"10 | 数据服务难道就是对外提供个API吗？","content":"<p>你好，我是郭忆。</p><p>在上一讲中，我为你介绍了为什么必须要有数据服务，你可以看到，数据服务在数据建设中发挥着重要的作用。那有的人可能会好奇了，数据服务到底长什么样子呢？ 是不是只对外提供一个API？ 真的有这么简单吗？接下来，我们就带着这些问题，学习今天的内容。</p><p>而我希望你能在学完这部分内容之后，真正掌握数据服务的产品功能设计和系统架构设计。因为这会对你设计一个数据服务，或者选择一个商业化产品，有很大的帮助。</p><h2>数据服务应该具备的八大功能</h2><p>我认为，数据服务应该具备八个功能，只有具备这些功能，才能解决我们在上一讲提到的问题。比如，数据接入方式多样，接入效率低；数据和接口没办法共享；不知道数据被哪些应用访问……</p><p><img src=\"https://static001.geekbang.org/resource/image/d3/29/d3e6a9bf2d88b050250351ac276c8029.jpg?wh=1142*685\" alt=\"\"></p><p>那么为了让你更好地理解数据服务的功能，我来讲个小故事。</p><p>你肯定去过菜鸟驿站取快递吧？假设有一个很大的菜鸟驿站，里面有很多组货架，每个货架前都有一些工作人员帮助我们取快递，同时也有很多队伍排队。</p><p>取快递，要先约定好接口（比如统一使用收货码来取货）。然后，为了保证不同队伍都能取到快递，我们要对每个队伍做一些限流（比如一个队伍一次只能取一个人）。在你取走快递时，驿站会记录是谁取走了哪个快递，方便后续追查。</p><p>这段时间，菜鸟驿站服务开始升级，不仅可以取快递，还提供快递送货上门的服务。除此之外，不同种类的快递对应的货架也变得不同，比如生鲜食品，货架是冷藏冰箱，文件、信封，货架就是文件柜。</p><!-- [[[read_end]]] --><p>对于取快递的人来说，如果他买了生鲜，又买了信封，那他要排好几个队伍，肯定不方便。所以，一般来讲，取快递的人最好只在一个队伍排队，而驿站工作人员帮他一次把多个货架的快递都取过来。</p><p>可驿站的货架实在是太多了，为了方便每个取快递的小伙伴都能快速找到每个货架以及队伍，驿站提供了一个导览。与此同时，为了不让工作人员出错，驿站的工作人员必须经过严格的测试，才能上岗。</p><p>讲完这个故事之后，我们接着回到数据服务的这八大功能上来。在取快递的这个例子中，你可以把数据服务看成是一个菜鸟驿站，工作人员看成是API解耦库，货架可以看作是中间存储，快递则可以认为是数据。</p><p>那么对应到八个功能，就是：</p><ul>\n<li>接口规范化定义，可以看成是取快递约定的收货码，基于统一的收货码取走快递；</li>\n<li>数据网关，可以看成是我们对每个货架前的队伍进行限流，确保每个队伍都能取走快递；</li>\n<li>链路关系的维护，可以看作是驿站会记录谁取走了什么快递；</li>\n<li>数据交付，可以看作驿站同时提供取快递和送货上门服务；</li>\n<li>提供多样中间存储，可以看成有不同类型的货架；</li>\n<li>逻辑模型，可以看成是一个工作人员，可以取多个货架的快递；</li>\n<li>API接口，可以看作是驿站的不同货架的不同队伍导览；</li>\n<li>API测试，可以看作是驿站工作人员上岗前的测试。</li>\n</ul><p>通过这个故事，你是不是已经对数据服务的八个功能有一个形象的感知了？接下来，我们来看看数据服务这八个功能具体包含什么内容。</p><p><strong>第一个是接口规范化定义。</strong></p><p>接口规范化定义就是取快递时我们约定的取件码。数据服务，对各个数据应用屏蔽了不同的中间存储，提供的是统一的API。</p><p><img src=\"https://static001.geekbang.org/resource/image/c6/e5/c65a500e6c72670c36aa96b0fb3e52e5.png?wh=1894*953\" alt=\"\" title=\"网易数据服务EasyDS界面示意图\n\"></p><p>在上图中，我们可以在数据服务上，定义每个API接口的输入和输出参数。</p><p><strong>第二，数据网关。</strong></p><p>作为网关服务，数据服务必须要具备认证、权限、限流、监控四大功能，这是数据和接口复用的前提。这就跟我们在菜鸟驿站前取快递，要对每个队伍的人进行认证、限流一个道理。我详细介绍一下。</p><p>首先是认证，为了解决接口安全的问题，数据服务首先会为每个注册的应用分配一对accesskey和secretkey，应用每次调用API 接口，都必须携带acesskey和secretkey。</p><p>除此之外，对于每个已发布的API，API 负责人可以对应用进行授权，只有有权限的应用才可以调用该接口。同时，API接口的负责人可以对应用进行限流（例如限制每秒QPS 不超过200），如果超过设定的阈值，就会触发熔断，限制接口的访问频率。</p><p>需要你注意的是，对于接口复用来说，限流功能非常必要，否则会造成不同应用之间的相互影响。</p><p><img src=\"https://static001.geekbang.org/resource/image/71/c4/71b7881dc2eba1ab3f91d6682d2ad1c4.png?wh=1885*959\" alt=\"\" title=\"应用对接口授权示意图\"></p><p>当然，数据服务还要提供接口相关的监控，比如接口的90%的请求响应时间、接口调用次数、失败次数等相关的监控，另外，对于长时间没有调用的API ，应该予以下线。这样做的好处是防止没用的接口额外占用资源。</p><p><strong>第三，全链路打通。</strong></p><p><img src=\"https://static001.geekbang.org/resource/image/59/46/59e8853a53e9456da459064b45212d46.jpg?wh=1142*521\" alt=\"\"></p><p>数据服务还必须负责维护数据模型到数据应用的链路关系。</p><p>在上图中，经营分析是一个数据应用，甄美丽是数据应用的开发，当她想要访问数据服务中的某个接口获取表A和B的数据时，她需要向接口的发布者马帅帅申请授予权限。然后经营分析就可以通过接口获取到数据。</p><p>同时，数据服务会把经营分析和表A和B的访问关系，推送给数据中台的元数据中心。接着元数据中心表A、B以及A和B的上游所有的表（图中D和E）上，就会有经营分析数据应用的标签。</p><p>当表D的产出任务异常时，马帅帅可以通过元数据中心，快速判断出该任务影响了经营分析数据产品的数据产出。同时，当马帅帅想要下线表D时，也可以通过这张表是否有标签，快速判断这个表下游是否还有应用访问。当马帅帅取消API 接口授权时，元数据中心同时会清理表的相关标签。</p><p><strong>需要特别提到的是，</strong>一个数据应用往往涉及很多页面，如果我们在影响分析时，只分析到应用，可能粒度还是太粗了，需要到更细级别的页面的粒度，比如一个任务异常，我不光要知道是哪个数据产品，还必须得知道是哪个数据产品的哪个页面。此时，我们在接口授权时，可以标注页面名称。</p><p><strong>第四，推和拉的数据交付方式。</strong></p><p>相信你听到的数据服务，都是以API接口的形式对外提供服务，但是业务实际场景中，光API 还不够的。我把API 方式称为拉的方式，而实际业务中同样还需要推的场景。</p><p>比如在实时直播场景中，商家需要第一时间获得关于活动的销售数据，此时就需要数据服务具备推的能力，我把它称为数据的送货上门服务。数据服务将数据实时写入到一个Kafka中，然后应用通过订阅Kafka的Topic，可以获得实时数据的推送。</p><p><strong>第五，利用中间存储，加速数据查询。</strong></p><p>数据中台中数据以Hive表的形式存在，基于Hive或者是Spark计算引擎，并不能满足数据产品低延迟，高并发的访问要求，</p><p>所以，一般做法是将数据从Hive表导出到一个中间存储，由中间存储提供实时查询的能力。数据服务需要根据应用场景支持多种中间存储，我列举了一些常用的中间存储以及这些存储适用的场景，希望你能根据实际场景选择适合的中间存储。</p><p><img src=\"https://static001.geekbang.org/resource/image/58/31/589e542b326d8666bb192e6079034831.jpg?wh=1142*392\" alt=\"\"></p><p><strong>第六，逻辑模型，实现数据的复用。</strong></p><p>在前面取快递的场景中，每一个货架一拨工作人员，其实对取快递的人并不友好，所以最好的就是一个人帮我们把所有的快递都取了。这就有点儿类似数据服务中逻辑模型的概念了。我们可以在数据服务中定义逻辑模型，然后基于逻辑模型发布API，逻辑模型的背后实际是多个物理表，从用户的视角，一个接口就可以访问多张不同的物理表了。</p><p>逻辑模型可以类比为数据库中视图的概念，相比于物理模型，逻辑模型只定义了表和字段的映射关系，数据是在查询时动态计算的。逻辑模型可以看作是相同主键的物理模型组成的大宽表。逻辑模型的存在，解决了数据复用的问题，相同的物理模型之上，应用可以根据自己的需求，构建出不同的逻辑模型，每个应用看到不同的列。</p><p><img src=\"https://static001.geekbang.org/resource/image/9d/bd/9d04db950b6545ae7fb67e33c127a9bd.jpg?wh=1142*797\" alt=\"\"></p><p>在上面这个例子中，有三个物理模型，但是主键都是商品ID，针对商品运营系统和店铺参谋，我们可以构建两个不同的逻辑模型，分别从不同的视角看数据，逻辑模型并不实际存在，而是在查询的时候，根据逻辑模型映射的物理模型字段，动态的地将请求拆分给多个物理模型，然后对多个查询结果进行聚合，得到逻辑模型查询的结果。</p><p><strong>第七，构建API 集市，实现接口复用。</strong></p><p>为了实现接口的复用，我们需要构建API的集市，应用开发者可以直接在API 集市发现已有的数据接口，直接申请该接口的API 权限，即可访问该数据，不需要重复开发。</p><p>需要特别指出的是，数据服务通过元数据中心，可以获得接口访问的表关联了哪些指标。使用者可以基于指标的组合，筛选接口，这样就可以根据想要的数据，查找可以提供这些数据的接口，形成了一个闭环。</p><p><img src=\"https://static001.geekbang.org/resource/image/bd/b0/bd41b45fd4f18af51c478ac680a378b0.jpg?wh=1142*530\" alt=\"\"></p><p>讲了这么多数据服务应该具备的功能，你可能会问，那数据服务应该如何实现呢？ 我们下面就来讲数据服务的架构设计。</p><h2>数据服务系统架构设计</h2><p>网易在实现数据服务时，主要采用了云原生、逻辑模型和数据自动导出三个关键设计，关于这部分内容，我希望你能通过学习，在实际工作中可以借鉴我们的方式完成数据服务的设计，或者在选择商业化产品时，给你一个架构选型方面的参考。</p><p><strong>云原生</strong></p><p>云原生的核心优势在于每个服务至少有两个副本，实现了服务的高可用，同时根据访问量大小，服务的副本数量可以动态调整，基于服务发现，可以实现对客户端透明的弹性伸缩。服务之间基于容器实现了资源隔离，避免了服务之间的相互影响。这些特性非常适用于提供高并发、低延迟，在线数据查询的数据服务。</p><p><img src=\"https://static001.geekbang.org/resource/image/18/69/1844f8bf8facbba99c46a8b507203369.jpg?wh=1142*876\" alt=\"\"></p><p>上图是网易数据服务的部署架构，在这个图中，每个已经发布上线的API接口都对应了一个Kubernates的Service，每个Service 有多个副本的Pod组成，每个API 接口访问后端存储引擎的代码运行在Pod对应的容器中，随着API接口调用量的变化，Pod 可以动态的创建和销毁。</p><p>Envoy 是服务网关，可以将Http请求负载均衡到Service的多个Pod上。Ingress Controller 可以查看 Kubernates中每个Service的Pod 变化，动态地将Pod IP写回到Envoy，从而实现动态的服务发现。前端的APP，Web或者是业务系统的Server端，通过一个4层的负载均衡LB接入到Envoy。</p><p>基于云原生的设计，解决了数据服务不同接口之间资源隔离的问题，同时可以基于请求量实现动态的水平扩展。同时借助Envoy实现了限流、熔断的功能。你也可以借鉴我们的方案，实现原原生的数据服务设计。</p><p><strong>逻辑模型</strong></p><p>相较于物理模型，逻辑模型并没有保存实际的数据，而只是包括了逻辑模型和物理模型的映射关系，数据在每次查询时动态生成。逻辑模型的设计，解决了不同接口，对于同一份数据，需要只看到自己需要的数据的需求。</p><p>下图是网易数据服务逻辑模型的系统设计图。</p><p><img src=\"https://static001.geekbang.org/resource/image/c3/6d/c3a2793aa44c4da16b60f80bb2ac626d.jpg?wh=1142*632\" alt=\"\"></p><p>接口发布者在数据服务中选择主键相同的多张物理表构建一个逻辑模型，然后基于逻辑模型发布接口。API 服务接到查询请求后，根据逻辑模型和物理模型字段的映射关系，将逻辑执行计划拆解为面向物理模型的物理执行计划，并下发多个物理模型上去执行，最后对执行的结果进行聚合，返回给客户端。</p><p>一个逻辑模型关联的物理模型可以分布在不同的查询引擎上，但是这种情况下，考虑性能因素，只支持基于主键的筛选。</p><p><strong>数据自动导出</strong></p><p>数据服务选择的是数据中台的一张表，然后将数据导出到中间存储中，对外提供API 。那数据什么时候导出到中间存储中呢？ 要等数据产出完成。</p><p>所以在用户选择了一张数据中台的表，定义好表的中间存储后，数据服务会自动生成一个数据导出任务，同时建立到这个数据中台表的产出任务的依赖关系，等到每次调度产出任务结束，就会触发数据导出服务，将数据导出到中间存储中，此时API 接口就可以查询到最新的数据。</p><p><img src=\"https://static001.geekbang.org/resource/image/2a/b5/2a3a546bc5d8d3b51270755282c580b5.jpg?wh=1142*173\" alt=\"\"></p><h2>课堂总结</h2><p>你看，数据服务化不是一个API接口这么简单吧，它的背后是数据标准化交付的整套流程。通过这节课，我为你介绍了数据服务的八大关键功能设计和三大系统架构设计。</p><p>在最后，我还想强调几个点：</p><ul>\n<li>数据服务实现了数据中台模型和数据应用的全链路打通，解决了任务异常影响分析和数据下线不知道影响哪些应用的难题；</li>\n<li>基于相同主键的物理模型，可以构建逻辑模型，逻辑模型解决了数据复用的难题，提高了接口模型的发布效率；</li>\n<li>数据服务宜采用云原生的设计模式，可以解决服务高可用、弹性伸缩和资源隔离的问题。</li>\n</ul><p>数据服务化对于加速数据交付流程，以及数据交付后的运维管理效率有重要作用，也是数据中台关键的组成部分。</p><p><img src=\"https://static001.geekbang.org/resource/image/a8/6c/a83b384e3fd4932f2bf4fcc4babcd86c.jpg?wh=1142*865\" alt=\"\"></p><h2>思考时间</h2><p>数据服务要想解决数据被哪些应用访问的问题，就必须确保所有数据应用都必须通过数据服务获取数据中台的数据，那问题来了，如何确保数据服务是数据中台的唯一出口？欢迎在留言区与我互动。</p><p>最后感谢你的阅读，如果这节课让你有所收获，也欢迎你将它分享给更多的朋友。</p>","neighbors":{"left":{"article_title":"09 | 数据服务到底解决了什么问题？","id":227418},"right":{"article_title":"11 | 怎么一劳永逸地解决数据安全问题？","id":229940}},"comments":[{"had_liked":false,"id":213386,"user_name":"你好","can_delete":false,"product_type":"c1","uid":1945987,"ip_address":"","ucode":"F6ED43EF5FD164","user_header":"https://static001.geekbang.org/account/avatar/00/1d/b1/83/c6dd1322.jpg","comment_is_top":false,"comment_ctime":1588400461,"is_pvip":false,"replies":[{"id":"79782","content":"你好，问的问题挺好的。<br><br>一对多的话，一个逻辑模型对应多个物理模型，有可能存在分散在不同的数据源的情况，比如一个是MySQL的表，一个是HBase的表，这个时候，我们就得实现跨数据源的查询，当然，是有限制的，比如只能基于主键做Join，你在构建逻辑模型的时候。<br><br>数据服务，接受到请求后，会根据逻辑模型和物理模型的映射关系，把逻辑模型拆分成多个物理查询请求，然后对返回结果进行聚合。这里面必须要限制查询的条数。<br><br>","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1589015109,"ip_address":"","comment_id":213386,"utype":1}],"discussion_count":2,"race_medal":0,"score":"35948138829","product_id":100049101,"comment_content":"老师，逻辑模型映射物理模型，对于一对多的情况，会不会这多个物理模型是来源于多个存储（比如gp、mysql、hbase），如果是的话，是怎么实现的？","like_count":9,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493763,"discussion_content":"你好，问的问题挺好的。\n\n一对多的话，一个逻辑模型对应多个物理模型，有可能存在分散在不同的数据源的情况，比如一个是MySQL的表，一个是HBase的表，这个时候，我们就得实现跨数据源的查询，当然，是有限制的，比如只能基于主键做Join，你在构建逻辑模型的时候。\n\n数据服务，接受到请求后，会根据逻辑模型和物理模型的映射关系，把逻辑模型拆分成多个物理查询请求，然后对返回结果进行聚合。这里面必须要限制查询的条数。\n\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589015109,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1031022,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/bb/6e/44c74b05.jpg","nickname":"马儿快跑","note":"","ucode":"58FD8AE933D4F9","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":302191,"discussion_content":"这里限制查询条数就不一定能查到所需要的数据，如果是分批量查询也要把整张表的数据全部查询出来，这样相当于复制一张表数据了，每次这种查询都要复制全表，存储介质需要跟得上，而且需要join计算的场景对内存的考验也很大","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1598836819,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":218275,"user_name":"无语飞涵","can_delete":false,"product_type":"c1","uid":1920108,"ip_address":"","ucode":"9AE330591B1D05","user_header":"https://static001.geekbang.org/account/avatar/00/1d/4c/6c/d16b3d7d.jpg","comment_is_top":false,"comment_ctime":1589770145,"is_pvip":false,"replies":[{"id":"81543","content":"我觉得，有一个点，你说的很好，技术并不能解决所有的问题，很多问题需要管理机制来配合完成，但是技术本身可以降低管理的复杂性，增强管理的可落地性。<br><br>感谢你的留言~","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1590410808,"ip_address":"","comment_id":218275,"utype":1}],"discussion_count":2,"race_medal":0,"score":"23064606625","product_id":100049101,"comment_content":"老师留的问题我觉得是需要上升到整个组织架构和流程管理，如，每个业务部门提出的需求，需要经过组织中负责企业级数据的部门团队或者评审会，确认该需求是否是属于数据应用类，必须通过数据中台来实现。","like_count":5,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":495415,"discussion_content":"我觉得，有一个点，你说的很好，技术并不能解决所有的问题，很多问题需要管理机制来配合完成，但是技术本身可以降低管理的复杂性，增强管理的可落地性。\n\n感谢你的留言~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1590410808,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1369756,"avatar":"https://wx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIopdUJmtgpsr9GibAibcZgS7h23P4FrgBfed3WveI4b4f8Vl2JjibhCzib9Y8Vs2M1PGQr7cwoKADxZQ/132","nickname":"秦道","note":"","ucode":"BE195C09BD14A5","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":309047,"discussion_content":"数据中台不是银弹，不是啥业务，啥数据都要上中台，中台更多的是为了沉淀重复业务，避免烟囱式的业务或数据处理。有的时候上了中太反而是过度设计，增加业务复杂度！我们公司目前就有这样的问题","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1601180706,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":218164,"user_name":"zhuxueyu","can_delete":false,"product_type":"c1","uid":1943187,"ip_address":"","ucode":"D4FA805528C55C","user_header":"","comment_is_top":false,"comment_ctime":1589726304,"is_pvip":false,"replies":[{"id":"81544","content":"总结的不错~","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1590410820,"ip_address":"","comment_id":218164,"utype":1}],"discussion_count":1,"race_medal":0,"score":"23064562784","product_id":100049101,"comment_content":"要让数据服务成为数据中台的唯一出口，个人觉得要从三点收口：<br>1、数据中台的数据能基本覆盖业务的数据需求；<br>2、业务通过数据服务获取数据更便捷<br>3、公司层面统一数据出口 - 数据中台","like_count":6,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":495367,"discussion_content":"总结的不错~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1590410820,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":264434,"user_name":"leed","can_delete":false,"product_type":"c1","uid":1276808,"ip_address":"","ucode":"644AF858B76C45","user_header":"https://static001.geekbang.org/account/avatar/00/13/7b/88/a4c24e9b.jpg","comment_is_top":false,"comment_ctime":1606465805,"is_pvip":false,"discussion_count":4,"race_medal":0,"score":"14491367693","product_id":100049101,"comment_content":"郭老师，看了您的文章受益匪浅，在数据服务这有一点不知道你们是怎么做的，就是填好api信息后，自动生成api接口，这个是有什么开源的框架吗","like_count":4,"discussions":[{"author":{"id":1347707,"avatar":"https://static001.geekbang.org/account/avatar/00/14/90/7b/7cd7bed2.jpg","nickname":"KONY","note":"","ucode":"2E3D33AA3B1E9A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":592099,"discussion_content":"DBApi","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1667110082,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2419502,"avatar":"https://static001.geekbang.org/account/avatar/00/24/eb/2e/90fea784.jpg","nickname":"柒","note":"","ucode":"D41241629321A1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":585068,"discussion_content":"同样想知道","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1661319766,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"上海"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1347609,"avatar":"https://static001.geekbang.org/account/avatar/00/14/90/19/b3403815.jpg","nickname":"Juha","note":"","ucode":"5B9301CC960D84","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":392045,"discussion_content":"同样的问题","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1630802513,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1402034,"avatar":"https://static001.geekbang.org/account/avatar/00/15/64/b2/18005d2a.jpg","nickname":"Leo Zhao","note":"","ucode":"5E4917CCD120B0","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":340284,"discussion_content":"同样想知道网易怎么做的 是java spring 吗","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1609943907,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":251600,"user_name":"Lee大树","can_delete":false,"product_type":"c1","uid":1005574,"ip_address":"","ucode":"3C2012F6D21698","user_header":"https://static001.geekbang.org/account/avatar/00/0f/58/06/6a9c089b.jpg","comment_is_top":false,"comment_ctime":1601713247,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"14486615135","product_id":100049101,"comment_content":"老师，“网易数据服务逻辑模型的系统设计图”中的“查询服务”是全部自己实现的吗？是否可以利用开源的工具比如：presto、calcite 做这个统一的引擎层？","like_count":3,"discussions":[{"author":{"id":1369756,"avatar":"https://wx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIopdUJmtgpsr9GibAibcZgS7h23P4FrgBfed3WveI4b4f8Vl2JjibhCzib9Y8Vs2M1PGQr7cwoKADxZQ/132","nickname":"秦道","note":"","ucode":"BE195C09BD14A5","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":372464,"discussion_content":"看老师的查询服务实现，里面有cordinator，worker，应该是采用或借鉴了presto","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1620347679,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":238077,"user_name":"海军陆战队","can_delete":false,"product_type":"c1","uid":1134101,"ip_address":"","ucode":"EEB5336AE4E980","user_header":"https://static001.geekbang.org/account/avatar/00/11/4e/15/189686da.jpg","comment_is_top":false,"comment_ctime":1596065969,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"14480967857","product_id":100049101,"comment_content":"您好，对于逻辑模型这块没有看明白，文章中展示的API创建页面都是选定一个数据源，一张表来生成的，多张表，甚至是跨数据源的逻辑模型配置是怎么做的，系统功能是怎样实现的？","like_count":4},{"had_liked":false,"id":214760,"user_name":"特种流氓","can_delete":false,"product_type":"c1","uid":1248825,"ip_address":"","ucode":"D9985CBA8B4AAD","user_header":"https://static001.geekbang.org/account/avatar/00/13/0e/39/174741d1.jpg","comment_is_top":false,"comment_ctime":1588814675,"is_pvip":false,"replies":[{"id":"80227","content":"今年之前，网易的离线和实时数据架构，还是采用的Lamda架构，即实时采用kafka+flink的方式，离线采用spark+hdfs的方式，从ods原始数据开始，kafka会归档一份数据到hdfs，然后分别计算，在数据应用场景上，T+1的数据用离线计算的，T+0的数据用实时链路的。历史数据以离线计算为准。<br><br>今年，我们引入的iceburg，正在研发批流一体的实时数据中台架构，iceburg可以实现upsert功能，可以实时更新，避免merge操作。用iceburg统一离线和实时的存储，同时在计算引擎上，主要使用flink，然后辅助用Spark进行校验。目前整套数据湖的方案还在研发中，当然Iceburg也存在一些挑战，比如怎么和现有的impala mpp集成，怎么基于iceburg文件粒度的元数据统计优化计算引擎性能，都是我们目前正在推进的工作。<br><br>感谢你的阅读~祝好~","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1589371721,"ip_address":"","comment_id":214760,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14473716563","product_id":100049101,"comment_content":"实时部分如何融合到数据到数据中台里面来 与离线模型一起统一对外提供服务","like_count":3,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":494195,"discussion_content":"今年之前，网易的离线和实时数据架构，还是采用的Lamda架构，即实时采用kafka+flink的方式，离线采用spark+hdfs的方式，从ods原始数据开始，kafka会归档一份数据到hdfs，然后分别计算，在数据应用场景上，T+1的数据用离线计算的，T+0的数据用实时链路的。历史数据以离线计算为准。\n\n今年，我们引入的iceburg，正在研发批流一体的实时数据中台架构，iceburg可以实现upsert功能，可以实时更新，避免merge操作。用iceburg统一离线和实时的存储，同时在计算引擎上，主要使用flink，然后辅助用Spark进行校验。目前整套数据湖的方案还在研发中，当然Iceburg也存在一些挑战，比如怎么和现有的impala mpp集成，怎么基于iceburg文件粒度的元数据统计优化计算引擎性能，都是我们目前正在推进的工作。\n\n感谢你的阅读~祝好~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589371721,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":210211,"user_name":"Bill","can_delete":false,"product_type":"c1","uid":1001581,"ip_address":"","ucode":"0D9F998FC0359F","user_header":"https://static001.geekbang.org/account/avatar/00/0f/48/6d/b2c56a77.jpg","comment_is_top":false,"comment_ctime":1587698076,"is_pvip":false,"replies":[{"id":"78444","content":"感谢你的认可，看来你对这个问题也有深入的思考。数据服务，最早我们其实只提供了API的方式，但是其实发现很难满足业务的全部要求，比如实时数据推送的这个场景，你靠API就搞不定。所以我们又做了送货上门的推的服务。<br><br>感谢你的阅读，下一次留言区再会~","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1587828099,"ip_address":"","comment_id":210211,"utype":1}],"discussion_count":2,"race_medal":0,"score":"14472599964","product_id":100049101,"comment_content":"👍 到目前为止，几乎和我设想以及实践方式一致。<br>数据服务这块儿其实可以更简单<br> - 被动获取：通过1个API解决所有数据请求，只变响应结构即可<br> - 主动推送：按需按时推送到使用方，做数据增量&#47;全量同步即可。","like_count":4,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492973,"discussion_content":"感谢你的认可，看来你对这个问题也有深入的思考。数据服务，最早我们其实只提供了API的方式，但是其实发现很难满足业务的全部要求，比如实时数据推送的这个场景，你靠API就搞不定。所以我们又做了送货上门的推的服务。\n\n感谢你的阅读，下一次留言区再会~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587828099,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1859053,"avatar":"","nickname":"姜维兴","note":"","ucode":"2A916E71100D55","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":249932,"discussion_content":"还是不明白，和数据仓库有什么区别。你说的这个我们企业内部的数据交换平台基本一致。可能我们的功能上还更强大些","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587977153,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":235502,"user_name":"风轻云淡","can_delete":false,"product_type":"c1","uid":1495190,"ip_address":"","ucode":"95C3FC7D3DACCF","user_header":"https://static001.geekbang.org/account/avatar/00/16/d0/96/c8cb7862.jpg","comment_is_top":false,"comment_ctime":1595066453,"is_pvip":false,"replies":[{"id":"87123","content":"其实，这门课，我并没有涉及到OneID的概念，比如都是一个用户，他在不同的app之间，是否可以唯一的标识，这个就是把不同业务系统的相同实体用唯一的ID打通，可以横向关联分析，这就是连接的内涵。另外一个用户，即使在同一个App内，登录前，登陆后，能不能标识成一个人，也属于OneID的概念。<br><br>连接、服务、共享，是中台思想的核，不仅仅是在数据中台，同样对应于其他中台。<br><br>感谢你的提问，祝好~","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1595247484,"ip_address":"","comment_id":235502,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10185001045","product_id":100049101,"comment_content":"老师，你之前说数据中台的核心是共享、服务和连接，连接怎么理解？","like_count":2,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":501748,"discussion_content":"其实，这门课，我并没有涉及到OneID的概念，比如都是一个用户，他在不同的app之间，是否可以唯一的标识，这个就是把不同业务系统的相同实体用唯一的ID打通，可以横向关联分析，这就是连接的内涵。另外一个用户，即使在同一个App内，登录前，登陆后，能不能标识成一个人，也属于OneID的概念。\n\n连接、服务、共享，是中台思想的核，不仅仅是在数据中台，同样对应于其他中台。\n\n感谢你的提问，祝好~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1595247484,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":217023,"user_name":"你好","can_delete":false,"product_type":"c1","uid":1945987,"ip_address":"","ucode":"F6ED43EF5FD164","user_header":"https://static001.geekbang.org/account/avatar/00/1d/b1/83/c6dd1322.jpg","comment_is_top":false,"comment_ctime":1589387021,"is_pvip":false,"replies":[{"id":"83586","content":"我们是基于数据传输这个工具，把数据从Hive抽取到HBase中的，数据传输工具是基于Spark实现的。","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1592224923,"ip_address":"","comment_id":217023,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10179321613","product_id":100049101,"comment_content":"老师，数仓统计好的表在hive中，然后落地到hbase才能对外提供api，这个场景应该有吧。我想问的是怎么落地到hbase呢？（数据量大的话还得提前预分区hbase）<br>，两个库之间衔接问题。","like_count":2,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":495009,"discussion_content":"我们是基于数据传输这个工具，把数据从Hive抽取到HBase中的，数据传输工具是基于Spark实现的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1592224923,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":213306,"user_name":"你好","can_delete":false,"product_type":"c1","uid":1945987,"ip_address":"","ucode":"F6ED43EF5FD164","user_header":"https://static001.geekbang.org/account/avatar/00/1d/b1/83/c6dd1322.jpg","comment_is_top":false,"comment_ctime":1588382005,"is_pvip":false,"replies":[{"id":"79783","content":"逻辑模型，跟你定义视图其实是一样的，对应的其实就是一条SQL，这个SQL 表明了你的逻辑模型。<br><br>视图也是对应的一条SQL。","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1589015162,"ip_address":"","comment_id":213306,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10178316597","product_id":100049101,"comment_content":"老师，逻辑模型底层是个复杂的多表连接的SQL吗？还是个基于这个SQL创建好的视图？","like_count":2,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493740,"discussion_content":"逻辑模型，跟你定义视图其实是一样的，对应的其实就是一条SQL，这个SQL 表明了你的逻辑模型。\n\n视图也是对应的一条SQL。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589015162,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":237757,"user_name":"Geek_ba5f3b","can_delete":false,"product_type":"c1","uid":1519917,"ip_address":"","ucode":"4D20AE63FCE56B","user_header":"","comment_is_top":false,"comment_ctime":1595944186,"is_pvip":false,"discussion_count":3,"race_medal":0,"score":"5890911482","product_id":100049101,"comment_content":"郭老师好！目前公司没有完整的数据中台服务，所以目前面临一个比较尴尬的问题：就是如何对每日产生打大量数据（千万--亿级）进行快速计算。目前的做法是通过etl将数据从业务库（PG）抽取到我们数据可视化应用本地库（PG），但在这过程中速度慢不说，一旦统计超过一个月数据，数据库会直接撑不住，不知道如何解决现在的问题。求教~~","like_count":1,"discussions":[{"author":{"id":1369756,"avatar":"https://wx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIopdUJmtgpsr9GibAibcZgS7h23P4FrgBfed3WveI4b4f8Vl2JjibhCzib9Y8Vs2M1PGQr7cwoKADxZQ/132","nickname":"秦道","note":"","ucode":"BE195C09BD14A5","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":309042,"discussion_content":"你这类问题竟然没一个人愿意回答������。其实在传统企业很普遍，比如报表业务，同步业务数据产生报表数据，业务数据和报表数据都用rdb存储(比如你们是pg)，我们之前把这个叫归档。有很多方法可以实现，我这里提供一些思路: 报表存储建议与业务系统剥离，报表存储建议hbase/clickhouse/es等列式存储;报表计算简单的直接写程序实现同步，好一点用spark,晚上定时跑批同步到报表库(这样无论增量还是全量计算逻辑一套);查询逻辑不变。希望可以帮到你","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1601180004,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1122359,"avatar":"https://static001.geekbang.org/account/avatar/00/11/20/37/ffa8579c.jpg","nickname":"赵春辉","note":"","ucode":"81BC5BAFDB8781","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":359146,"discussion_content":"如果是为了分析用，存到hive里面可能更合适","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616122191,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1369756,"avatar":"https://wx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIopdUJmtgpsr9GibAibcZgS7h23P4FrgBfed3WveI4b4f8Vl2JjibhCzib9Y8Vs2M1PGQr7cwoKADxZQ/132","nickname":"秦道","note":"","ucode":"BE195C09BD14A5","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":309044,"discussion_content":"忘了说了，数据量大的问题建议根据时间分区，或者rdb的分表","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1601180205,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":231740,"user_name":"菜鸟和谐号","can_delete":false,"product_type":"c1","uid":1632108,"ip_address":"","ucode":"649BD61DC406C2","user_header":"https://static001.geekbang.org/account/avatar/00/18/e7/6c/aa73b7a7.jpg","comment_is_top":false,"comment_ctime":1593762333,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5888729629","product_id":100049101,"comment_content":" 数据服务是基于明细数据还是结果数据，如果在明细数据表上加视图，实现数据api地图我觉的太难了，毕竟大部分的app层的明细表是基于报表开发的，开发人员有时都懵逼，还让业务开发人员去基于app层的视图去求指标，我觉的简直是一个不可能完成的任务。而且维护成本很高。如果基于结果数据去做视图，数据维度太多，难免会丢失统计维度。","like_count":1},{"had_liked":false,"id":222807,"user_name":"ZSW","can_delete":false,"product_type":"c1","uid":1944866,"ip_address":"","ucode":"36269D9DDB3C7B","user_header":"https://static001.geekbang.org/account/avatar/00/1d/ad/22/654e9762.jpg","comment_is_top":false,"comment_ctime":1590916468,"is_pvip":true,"replies":[{"id":"83583","content":"你的问题涉及到批流一体了。批计算和流计算，有两种架构，一种是lamda架构，一种是kappa架构。<br><br>lamda架构目前在实际企业中落地最多。一般当天数据用实时，过往数据用离线。<br><br>kappa架构应该是未来一个趋势，现在数据湖概念比较火热，可以基于iceburg实现批流一体的存储层统一。","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1592224776,"ip_address":"","comment_id":222807,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5885883764","product_id":100049101,"comment_content":"老师，你好，对于实时数据和离线数据怎么结合这一部分有点疑问，现在离线和实时先分别计算，计算之后，数据是合并到一起呢？我大概想到2两种思路：<br>1、从物理存储上就合并在一起，离线数据统计结果写入A表，实时统计结果追加到A表？如果这种方式有什么好的实现方案吗？<br>2、物理存储层面分别存储， 如果分别存储，那如果一个查询查的时间跨度是“从历史数据查到今天的实时数据”，是不是在逻辑层分别取出来之后，再进行合并？","like_count":1,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":496924,"discussion_content":"你的问题涉及到批流一体了。批计算和流计算，有两种架构，一种是lamda架构，一种是kappa架构。\n\nlamda架构目前在实际企业中落地最多。一般当天数据用实时，过往数据用离线。\n\nkappa架构应该是未来一个趋势，现在数据湖概念比较火热，可以基于iceburg实现批流一体的存储层统一。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1592224776,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":220334,"user_name":"Weehua","can_delete":false,"product_type":"c1","uid":1170152,"ip_address":"","ucode":"91C0C2699D4EE4","user_header":"https://static001.geekbang.org/account/avatar/00/11/da/e8/d49dfa94.jpg","comment_is_top":false,"comment_ctime":1590223477,"is_pvip":false,"replies":[{"id":"81521","content":"HI， 你好，WeehuaZheng，<br><br>第一个问题： 实时数据中台一定是数据中台发展的下一站，解决了离线数据的共享和复用，实时数据的复用和共享将会是下一个阶段关注的重点。一般在使用过程中，T+1的统计数据使用离线数据，当天的数据使用实时数据。<br><br>第二个问题： 实时数据中台与离线数据中台，在方法论上也是相似的，实时数据中台同样也需要通过数据服务接口的方式对外暴漏服务。业务中台与数据中台的责任边界，数据中台负责统计分析型数据的展现。在大数据量下，业务系统去做实时数据的分析是非常耗资源的，而且还面临指标统计口径问题，所以统一由数据中台对接。<br><br>感谢你的提问，欢迎你在留言区与我交流~","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1590406911,"ip_address":"","comment_id":220334,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5885190773","product_id":100049101,"comment_content":"感谢郭老师的分享。我提2个问题：<br>1. 数据中台的数据，大部分应该还是离线为主，这些T+1时效性的数据，可以用在核心的业务流程中吗？<br>2. 实时数据，数据中台和业务中台怎么划清责任边界呢？","like_count":1,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":496123,"discussion_content":"HI， 你好，WeehuaZheng，\n\n第一个问题： 实时数据中台一定是数据中台发展的下一站，解决了离线数据的共享和复用，实时数据的复用和共享将会是下一个阶段关注的重点。一般在使用过程中，T+1的统计数据使用离线数据，当天的数据使用实时数据。\n\n第二个问题： 实时数据中台与离线数据中台，在方法论上也是相似的，实时数据中台同样也需要通过数据服务接口的方式对外暴漏服务。业务中台与数据中台的责任边界，数据中台负责统计分析型数据的展现。在大数据量下，业务系统去做实时数据的分析是非常耗资源的，而且还面临指标统计口径问题，所以统一由数据中台对接。\n\n感谢你的提问，欢迎你在留言区与我交流~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1590406911,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1122359,"avatar":"https://static001.geekbang.org/account/avatar/00/11/20/37/ffa8579c.jpg","nickname":"赵春辉","note":"","ucode":"81BC5BAFDB8781","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":359147,"discussion_content":"可以考虑用flink做实时数仓","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616122313,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":213277,"user_name":"Sandflass","can_delete":false,"product_type":"c1","uid":1917246,"ip_address":"","ucode":"7B75396EEC92B5","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/ajNVdqHZLLCVPh0bcCMJAwtxBx0cCLlkqB9NckSp3I0LYSTlRezuRV0gpXGB0BCZbFDpvLbhBbzsk8cHvczZ7g/132","comment_is_top":false,"comment_ctime":1588351384,"is_pvip":false,"replies":[{"id":"80221","content":"你好，数据服务，只负责数据的交付，数据的接入和加工，不是数据服务负责的范畴，是数据集成和数据开发中心负责的范畴。<br><br>实时数据集成，对于关系数据库，可以基于MySQL的二进制日志binlog，实时同步到kafka，然后基于flink对数据进行清洗加工，然后推送给最终的kafka数据，在实时直播场景下，常见的也有写入到redis，然后应用系统通过数据服务，高频率刷新读redis。<br><br>感谢你的提问~","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1589370964,"ip_address":"","comment_id":213277,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5883318680","product_id":100049101,"comment_content":"老师，请问一下对于实时的数据服务，比如您提到的实时直播场景，您只提到了最后的数据服务通过kafka推送，但是中间的数据源实时接入、数据实时加工应该采用何种技术方案呢？应该是有异于离线计算的方案吧？我们公司一些业务对于数据实时服务要求比较高，计算量并不大，这种场景应如何做技术选型呢？","like_count":2,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493729,"discussion_content":"你好，数据服务，只负责数据的交付，数据的接入和加工，不是数据服务负责的范畴，是数据集成和数据开发中心负责的范畴。\n\n实时数据集成，对于关系数据库，可以基于MySQL的二进制日志binlog，实时同步到kafka，然后基于flink对数据进行清洗加工，然后推送给最终的kafka数据，在实时直播场景下，常见的也有写入到redis，然后应用系统通过数据服务，高频率刷新读redis。\n\n感谢你的提问~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589370964,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1917246,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/ajNVdqHZLLCVPh0bcCMJAwtxBx0cCLlkqB9NckSp3I0LYSTlRezuRV0gpXGB0BCZbFDpvLbhBbzsk8cHvczZ7g/132","nickname":"Sandflass","note":"","ucode":"7B75396EEC92B5","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":267168,"discussion_content":"清楚了，谢谢老师","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589610765,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":210902,"user_name":"枕烟客","can_delete":false,"product_type":"c1","uid":1528946,"ip_address":"","ucode":"6F6D3C5CBF70A8","user_header":"https://static001.geekbang.org/account/avatar/00/17/54/72/46a461c3.jpg","comment_is_top":false,"comment_ctime":1587863936,"is_pvip":false,"replies":[{"id":"78986","content":"你说的真的太对了，强扭的瓜不甜。数据服务也必须要满足不同场景下的取数的需求。甚至包括推送的数据方式。数据服务的存在，不是提高数据的接入成本，而是降低数据的接入成本。<br><br>感谢你的阅读~","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1588159337,"ip_address":"","comment_id":210902,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5882831232","product_id":100049101,"comment_content":"要让数据服务成为数据中台的唯一出口，是不是可以换句话说，数据服务能满足数据需求，数据需求能从数据服务中得到需要的数据或服务，这是一个，另外能满足，是不是也要能获得，有这个东西，也得让人家能拿到，不能说，这个东西我们有，就是体验差让人抓狂。","like_count":1,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493143,"discussion_content":"你说的真的太对了，强扭的瓜不甜。数据服务也必须要满足不同场景下的取数的需求。甚至包括推送的数据方式。数据服务的存在，不是提高数据的接入成本，而是降低数据的接入成本。\n\n感谢你的阅读~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588159337,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1080164,"avatar":"https://static001.geekbang.org/account/avatar/00/10/7b/64/9f404dd2.jpg","nickname":"iron","note":"","ucode":"0728CADB78628D","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":572278,"discussion_content":"这个问题说实话 我看了三遍 都没看懂是啥意思 老师竟然能看懂 佩服\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1652689383,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":210663,"user_name":"艾伦","can_delete":false,"product_type":"c1","uid":1018725,"ip_address":"","ucode":"3D8D5265042D9D","user_header":"https://static001.geekbang.org/account/avatar/00/0f/8b/65/e697e54d.jpg","comment_is_top":false,"comment_ctime":1587804800,"is_pvip":false,"replies":[{"id":"79005","content":"你好，说的是对的，数据服务，可以帮助我们建立全链路数据血缘关系，提高数据后续的管理效率。<br><br>感谢你的阅读~","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1588161187,"ip_address":"","comment_id":210663,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5882772096","product_id":100049101,"comment_content":"数据服务，更好地打通了数据到业务系统的流转，统一服务建设好，能够更好地实现数据到业务的良性闭环，数据指导业务，业务反哺数据。","like_count":1,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493077,"discussion_content":"你好，说的是对的，数据服务，可以帮助我们建立全链路数据血缘关系，提高数据后续的管理效率。\n\n感谢你的阅读~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588161187,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":210222,"user_name":"gd","can_delete":false,"product_type":"c1","uid":1267064,"ip_address":"","ucode":"DAF73A8681A474","user_header":"https://static001.geekbang.org/account/avatar/00/13/55/78/1b80a643.jpg","comment_is_top":false,"comment_ctime":1587699685,"is_pvip":false,"replies":[{"id":"79001","content":"你好，不同的数据库，可以在数据服务层拆分成多个SQL，然后在数据服务层整合。<br><br>感谢你的提问。","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1588160813,"ip_address":"","comment_id":210222,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5882666981","product_id":100049101,"comment_content":"hi，你好！第六，逻辑模型，实现数据的复用，一张表出现2个商品名称。另外，这个实现不同的物理表是服务里面生成查询的视图sql么，如果是不同数据库，是否可以整合，如果可以整合在服务层，是否还需要数据集中？请教下！","like_count":1,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492975,"discussion_content":"你好，不同的数据库，可以在数据服务层拆分成多个SQL，然后在数据服务层整合。\n\n感谢你的提问。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588160813,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":210164,"user_name":"阿巍-豆夫","can_delete":false,"product_type":"c1","uid":1005123,"ip_address":"","ucode":"732188848B0A85","user_header":"https://static001.geekbang.org/account/avatar/00/0f/56/43/abb7bfe3.jpg","comment_is_top":false,"comment_ctime":1587693332,"is_pvip":false,"replies":[{"id":"78445","content":"数据服务，确实技术门槛还挺高的，不过只有数据服务做好，整个数据中台的数据出口才能收口，才能从根本上解决指标管理、全链路血缘建立的问题。<br><br>感谢你的阅读，我们下一次留言区再会~","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1587828169,"ip_address":"","comment_id":210164,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5882660628","product_id":100049101,"comment_content":"数据服务太大了。一个数据服务就远比数据治理麻烦的多","like_count":1,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492959,"discussion_content":"数据服务，确实技术门槛还挺高的，不过只有数据服务做好，整个数据中台的数据出口才能收口，才能从根本上解决指标管理、全链路血缘建立的问题。\n\n感谢你的阅读，我们下一次留言区再会~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587828169,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":338978,"user_name":"杨陆伟","can_delete":false,"product_type":"c1","uid":1108457,"ip_address":"","ucode":"3BC968447406EB","user_header":"https://static001.geekbang.org/account/avatar/00/10/e9/e9/1f95e422.jpg","comment_is_top":false,"comment_ctime":1647847177,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1647847177","product_id":100049101,"comment_content":"为什么采取逻辑模型的设计，而不是利用大数据平台的聚合能力，应用取到之前就聚合好","like_count":0},{"had_liked":false,"id":337755,"user_name":"陶赵文","can_delete":false,"product_type":"c1","uid":1300626,"ip_address":"","ucode":"E76FCBF66F85A3","user_header":"https://static001.geekbang.org/account/avatar/00/13/d8/92/e3202c20.jpg","comment_is_top":false,"comment_ctime":1647011417,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1647011417","product_id":100049101,"comment_content":"请问一下需要大量数据返回的，API返回是不是不合适。是不是还可以推到业务库","like_count":0},{"had_liked":false,"id":337618,"user_name":"糖糖是老坛酸菜女王","can_delete":false,"product_type":"c1","uid":1228279,"ip_address":"","ucode":"F534E13A7DD58C","user_header":"https://static001.geekbang.org/account/avatar/00/12/bd/f7/9fd5fca5.jpg","comment_is_top":false,"comment_ctime":1646918624,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1646918624","product_id":100049101,"comment_content":"郭老师，想问下逻辑模型那一块。我之前试用过网易的数据服务平台，我在通过向导式的方式创建api，或者前置条件中都没有发现定义逻辑模型的部分功能。请问这一块是有限制吗，是只有sql模式下支持吗？<br>另外一个问题是想问，api是否可以和需求承担数据行列权限管控的需求。<br>期待您的解答，非常感谢！","like_count":0},{"had_liked":false,"id":335831,"user_name":"杜天敏","can_delete":false,"product_type":"c1","uid":1049377,"ip_address":"","ucode":"88F6EA90B58FE7","user_header":"https://static001.geekbang.org/account/avatar/00/10/03/21/36ab7c75.jpg","comment_is_top":false,"comment_ctime":1645707274,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1645707274","product_id":100049101,"comment_content":"请问数据服务平台里会涉及几种用户角色，其中api的设计，调试，发布，下线维护等谁去做？数据内容的开发者，还是数据内容的消费方？","like_count":0},{"had_liked":false,"id":319713,"user_name":"僊峯","can_delete":false,"product_type":"c1","uid":2039980,"ip_address":"","ucode":"FA140E7653C26D","user_header":"https://static001.geekbang.org/account/avatar/00/1f/20/ac/c609855b.jpg","comment_is_top":false,"comment_ctime":1635920571,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1635920571","product_id":100049101,"comment_content":"老师，关于逻辑模型的查询你们是自己写的还是用的开源查询引擎，比如presto","like_count":1},{"had_liked":false,"id":293161,"user_name":"fish","can_delete":false,"product_type":"c1","uid":1096768,"ip_address":"","ucode":"B5FC04A69E0E64","user_header":"https://static001.geekbang.org/account/avatar/00/10/bc/40/12086a85.jpg","comment_is_top":false,"comment_ctime":1621249725,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1621249725","product_id":100049101,"comment_content":"1. 数据服务足够好用<br>2. 把数据服务作为一个模块集成在平台上，在源头上认为这个是数据闭环的一部份<br>3. 统一的服务标准规范，定期作培训，加强认知","like_count":0},{"had_liked":false,"id":267049,"user_name":"awoeeeeee","can_delete":false,"product_type":"c1","uid":2215316,"ip_address":"","ucode":"D763D0CF26A0C5","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIAe9af50xfBsOlAKZnbDTazLGEcQrQlezibj5omvHichfquZZuQtztnOMqsTc2DuqTqepFbhu2Pjzw/132","comment_is_top":false,"comment_ctime":1607582663,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1607582663","product_id":100049101,"comment_content":"郭老师，你好。在“第二，数据网关”部分“应用每次调用 API 接口，都必须携带 acesskey 和 secretkey。”不太明白，猜测是不是笔误多加了secretkey。我的理解是acesskey用于请求数据的合法性，secretkey用于数据应用方解密数据","like_count":0,"discussions":[{"author":{"id":1402034,"avatar":"https://static001.geekbang.org/account/avatar/00/15/64/b2/18005d2a.jpg","nickname":"Leo Zhao","note":"","ucode":"5E4917CCD120B0","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":340283,"discussion_content":"我觉得是参考了aws的叫法，其实就是username password.","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1609943785,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":265375,"user_name":"大鱼","can_delete":false,"product_type":"c1","uid":1020811,"ip_address":"","ucode":"1144A0E7EE3B8B","user_header":"https://static001.geekbang.org/account/avatar/00/0f/93/8b/35fa42aa.jpg","comment_is_top":false,"comment_ctime":1606880136,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1606880136","product_id":100049101,"comment_content":"逻辑模型可以理解成在api里建立的sql的联合查询吗？或者各个查询得出结果后，在代码里合成一个数据集？","like_count":0},{"had_liked":false,"id":247516,"user_name":"周正品","can_delete":false,"product_type":"c1","uid":2095845,"ip_address":"","ucode":"C084375F580943","user_header":"","comment_is_top":false,"comment_ctime":1599730651,"is_pvip":false,"replies":[{"id":"91837","content":"你好，更多的情况是通过分区的形式存在的。成熟的数据服务的产品，开源的目前还没有，商业化产品，可以关注一下网易的大数据产品。","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1601380613,"ip_address":"","comment_id":247516,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1599730651","product_id":100049101,"comment_content":"老师你好，就是我们刚开始建设基于hadoop 体系建设数据仓库，就是关于业务库有涉及修改以及物理删除的数据，就是业务数据增量到ods后 ，请问下这些数据如何去把控，是分区的形式还是对ods 进行数据合并后再去跑dw层的数据。以及问下目前对外提供api的话，有没有快速的基于sql的形式马上可以供对外完成一个api的产品？","like_count":0,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":505424,"discussion_content":"你好，更多的情况是通过分区的形式存在的。成熟的数据服务的产品，开源的目前还没有，商业化产品，可以关注一下网易的大数据产品。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1601380613,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":241450,"user_name":"追梦","can_delete":false,"product_type":"c1","uid":1183831,"ip_address":"","ucode":"54C6E76E8FE033","user_header":"https://static001.geekbang.org/account/avatar/00/12/10/57/1adfd4f7.jpg","comment_is_top":false,"comment_ctime":1597298467,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1597298467","product_id":100049101,"comment_content":"老师，您数据服务系统页面中，API集市和API列表的功能区别是什么呢？还有一个问题，如果有数据应用部门想取数据明细，api接口对明细数据是怎么限定的呢？有没有什么原则呢","like_count":0},{"had_liked":false,"id":217379,"user_name":"zhuxueyu","can_delete":false,"product_type":"c1","uid":1943187,"ip_address":"","ucode":"D4FA805528C55C","user_header":"","comment_is_top":false,"comment_ctime":1589472318,"is_pvip":false,"replies":[{"id":"81525","content":"你好，感谢你的认可，数据服务化是数据中台最重要的两个核心概念之一，数据服务化可以解决我们在数据共享层面，接口和数据复用的问题，提高数据的管理效率，降低数据接入的成本。<br><br>祝好~","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1590407771,"ip_address":"","comment_id":217379,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1589472318","product_id":100049101,"comment_content":"感谢老师，一直对数据服务这块儿理解不清晰。这篇文章通过生活中的实例来说明，会让人更能深刻理解","like_count":0,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":495127,"discussion_content":"你好，感谢你的认可，数据服务化是数据中台最重要的两个核心概念之一，数据服务化可以解决我们在数据共享层面，接口和数据复用的问题，提高数据的管理效率，降低数据接入的成本。\n\n祝好~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1590407771,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":214815,"user_name":"Geek_f071bc","can_delete":false,"product_type":"c1","uid":1945778,"ip_address":"","ucode":"B98A0BD2B4620A","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/zgnl95XDvXnicWoGibeAdicWrBYj8UgYGAayxcrJcaFLSbENX402AsVCtRibg3G1tuWrpZwymicribdug9PaHMeGK1Xw/132","comment_is_top":false,"comment_ctime":1588823436,"is_pvip":false,"replies":[{"id":"80228","content":"你好，这个是在数据服务中，进行逻辑执行计划到物理执行计划的拆解和生成，发送给不同的查询引擎，查询完成后，在数据服务中进行数据的聚合。<br><br>感谢你的提问~祝好~","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1589371779,"ip_address":"","comment_id":214815,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1588823436","product_id":100049101,"comment_content":"老师，在逻辑模型部门您提到，“一个逻辑模型关联的物理模型可以分布在不同的查询引擎上”，对于在多个查询引擎上的数据，用什么技术实现数据的关联与汇聚？","like_count":0,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":494209,"discussion_content":"你好，这个是在数据服务中，进行逻辑执行计划到物理执行计划的拆解和生成，发送给不同的查询引擎，查询完成后，在数据服务中进行数据的聚合。\n\n感谢你的提问~祝好~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589371779,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1369756,"avatar":"https://wx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIopdUJmtgpsr9GibAibcZgS7h23P4FrgBfed3WveI4b4f8Vl2JjibhCzib9Y8Vs2M1PGQr7cwoKADxZQ/132","nickname":"秦道","note":"","ucode":"BE195C09BD14A5","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":309048,"discussion_content":"其实老师课程中有张图提到coordinator，worker的查询服务落地，我想应该就是presto","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1601181106,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":213387,"user_name":"你好","can_delete":false,"product_type":"c1","uid":1945987,"ip_address":"","ucode":"F6ED43EF5FD164","user_header":"https://static001.geekbang.org/account/avatar/00/1d/b1/83/c6dd1322.jpg","comment_is_top":false,"comment_ctime":1588400764,"is_pvip":false,"replies":[{"id":"80128","content":"Hi，你好，数据服务就我所知，目前没有一个很成熟的开源产品，我们是自研的。 <br><br>数据服务和元数据中心不是一个产品，只是要打通，在数据服务发布接口的时候，可以把哪个应用的哪个接口下沉到元数据中心，这样可以方便在数据地图，任务运维中心，我们可以看到某张表，下游影响哪些接口。","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1589292860,"ip_address":"","comment_id":213387,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1588400764","product_id":100049101,"comment_content":"老师，数据服务涉及api、网关什么的各个方面，听起来很复杂，有现成的开源产品或收费产品吗？还是一般是自己开发，我看在发布服务时还会在元数据产品中写入标签数据，好像也不像个独立的产品，应该和元数据是一个产品好像又得自己开发整套东西。。","like_count":0,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493764,"discussion_content":"Hi，你好，数据服务就我所知，目前没有一个很成熟的开源产品，我们是自研的。 \n\n数据服务和元数据中心不是一个产品，只是要打通，在数据服务发布接口的时候，可以把哪个应用的哪个接口下沉到元数据中心，这样可以方便在数据地图，任务运维中心，我们可以看到某张表，下游影响哪些接口。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589292860,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":210105,"user_name":"绍晖","can_delete":false,"product_type":"c1","uid":1194932,"ip_address":"","ucode":"4196CF795417EC","user_header":"https://static001.geekbang.org/account/avatar/00/12/3b/b4/b8d0f8c8.jpg","comment_is_top":false,"comment_ctime":1587687934,"is_pvip":true,"replies":[{"id":"78446","content":"你好，你这里的不同系统，指的是中间存储对吧？ 如果是中间存储是没有问题的。数据服务，其实你可以理解为是数据中台对外提供数据的统一的出口。<br><br>感谢你的阅读~","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1587828224,"ip_address":"","comment_id":210105,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1587687934","product_id":100049101,"comment_content":"数据服务就是把部分大不同系统中的表和数据聚合起来对外提供数据服务，中间涉及到逻辑模型，数据存储中间件，api发布实现等等... ","like_count":0,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492950,"discussion_content":"你好，你这里的不同系统，指的是中间存储对吧？ 如果是中间存储是没有问题的。数据服务，其实你可以理解为是数据中台对外提供数据的统一的出口。\n\n感谢你的阅读~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587828224,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]}]}