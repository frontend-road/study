{"id":741061,"title":"第 8 章 高性能与可用性(1)","content":"<p>前面 7 章的内容基本囊括了分布式系统的核心技术，如果把这些内容比作分布式技术的大菜，那么本章要讲的就是分布式技术的甜点。众所周知，分布式就是通过技术手段，让廉价的服务器集群提供高性能、稳定的服务，因此这个技术本身就已经实现了高性能和可用性。在大数据、高并发的应用场景中，都会用到分布式技术，为了提高用户体验和增加系统的并发量，还会用到缓存技术。本章我们会以缓存技术作为高性能的切入点，从客户端的 HTTP 缓存，到 CDN 缓存，再到负载均衡缓存以及进程内缓存和分布式缓存，层层递进地给大家讲解缓存的应用。另外在可用性方面，会从故障的检测、处理以及恢复三个方面展开说明分布式架构是如何保证可用性的。沿着上述思路，本章主要会介绍如下内容。</p>\n<ul>\n<li>缓存的应用<ul>\n<li>HTTP 缓存</li>\n<li>CDN 缓存</li>\n<li>负载均衡缓存</li>\n<li>进程内缓存</li>\n<li>分布式进程缓存</li>\n</ul>\n</li>\n<li>可用性</li>\n</ul>\n<h2 id=\"nav_point_154\">8.1　缓存的应用</h2>\n<p>分布式架构就是将应用或者服务分散部署到多个不同的网络节点中，从而可以通过水平扩展的方式使系统承载更多并发请求，也就是说分布式架构本身已经具备了高性能。本节将会介绍整个分布式系统中，应用在各个不同环节的缓存，从 HTTP 缓存、CDN 缓存、负载均衡缓存、进程内缓存一直到分布式进程缓存。这些缓存虽然实现在不同的应用层次，但目的都相同，就是让用户更快地拿到业务数据，从而提高用户体验。讲到的这些缓存既可以在不同场景中选择使用，也可以在整个架构中同时使用。</p><!-- [[[read_end]]] -->\n<h3 id=\"nav_point_155\">8.1.1　处处皆缓存</h3>\n<p>想必每个开发者都对缓存相当熟悉，使用缓存技术是为了提高程序性能和用户体验，那么缓存的具体使用场景和使用方式又是怎样的呢？例如刚构建了一个网站，需要提高性能，此时就可以把缓存放在浏览器、反向代理服务器或者应用程序进程内，还可以放在分布式缓存系统中。如图 8-1 所示，描述了用户请求从浏览器端到数据库的整个请求链。从上往下顺着箭头来看，用户可以在请求的各个层级加入缓存，无论在哪一层级的缓存中找到自己想要的数据，都可以直接返回结果。</p>\n<p class=\"pic\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00532.jpeg\" alt=\"\" width=\"65%\" style=\"width: 65%\" /></p>\n<p class=\"ebook-image-title\"><strong>图 8-1　缓存策略图</strong></p>\n<p>用户请求经过浏览器的配合，从 CDN 缓存中获取一些静态数据，然后通过代理服务器到应用层获取动态数据，应用服务器中包含进程内缓存、进程外缓存，如果这两个都没有命中，就去请求分布式缓存，如果还是没有命中，再去请求数据库。其中提到的各个层次和环节都可以加入缓存技术。</p>\n<p>当所有缓存都没有命中数据时，才会回源到数据库进行查找。请求各缓存的顺序为 HTTP 缓存 → CDN 缓存 → 负载均衡缓存 → 进程内缓存 → 进程外缓存 → 分布式缓存 → 数据库。</p>\n<p>下面分别看看每层缓存的原理及实现。</p>\n<h3 id=\"nav_point_156\">8.1.2　动静分离</h3>\n<p>分布式系统架构需要快速地响应高并发请求，因此快速将响应信息返回给用户就是设计分布式系统的目的。那么如何更快返回响应信息呢？总结下来可以通过两点：使传输的数据尽量小、把数据存放在离用户最近的地方。沿着这两个思路往下想，要想减小传输数据的容量就要对数据做分离，把静态数据和动态数据分离开；要想让数据离用户更近一点，就要将数据存放到离用户最近的服务器中，同时把这部分数据缓存下来，对于没有发生变化的静态数据，就可以直接返回给用户。</p>\n<p>什么是动静分离呢？先来看看传统的客户端请求流程。如图 8-2 所示，客户端发起请求，通过负载均衡找到应用服务器，应用服务器从数据库中拿出数据返回给客户端，这个请求路径相对较长。</p>\n<p class=\"pic\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00533.jpeg\" alt=\"{%}\" /></p>\n<p class=\"ebook-image-title\"><strong>图 8-2　传统的客户端请求流程</strong></p>\n<p>为了减小请求路径的长度，减小用户请求的大小，和让数据更快地返回给客户端。需要对数据进行动静分离，静态数据直接从离客户端近的网络节点返回，需要返回动态数据的时候才请求应用服务器。通过观察发现，图片、CSS、JS 这些数据在短时间内是不会频繁变化的，因此称之为静态数据。另外一些用户信息的校验、业务逻辑等数据则需要和应用服务器进行交互，因此称之为动态数据。如图 8-3 所示，将客户端页面中的静态数据和动态数据分离开。然后在请求通过负载均衡的时候，根据请求资源的不同完成不同操作，让静态数据请求指向 CDN（Content Delivery Network，内容分发网络）缓存，动态数据请求指向应用服务器。</p>\n<p class=\"pic\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00534.jpeg\" alt=\"\" width=\"70%\" style=\"width: 70%\" /></p>\n<p class=\"ebook-image-title\"><strong>图 8-3　动静分离的设计</strong></p>\n<p>动静分离的方式，一方面让静态资源不用经过应用服务器和数据库，直接从 CDN 缓存中就能获取，然后到达客户端，减少了请求的访问路径；另一方面对于整个客户端页面来说，只有一部分动态数据需要从应用服务器获取，也算减小了获取数据的大小。可以说从路径变短和数据减小两个方面对客户端请求进行了优化。</p>\n<ol>\n<li><p><strong>如何识别动态或者静态数据</strong></p>\n<p>既然动静分离能够带来这些好处，那么如何识别动态数据和静态数据呢？下面以电商平台秒杀商品场景为例来具体分析。</p>\n<p>一般而言，我们会为参与秒杀的商品生成专门的商品页面和订单页面。这些页面以静态的 HTML 为主，包含的动态信息能少则少。从业务角度来说，这些商品的信息早就被用户所熟识，在秒杀的时候，他们更关心如何快速下单。既然商品的详情页面和订单页面都是静态生成的，那么就需要定义一个 URL，在即将开始秒杀时，把这个 URL 开放给用户访问。为了防止“程序员或者内部人员”作弊，可以通过时间戳和 Hash 算法生成商品秒杀页面的 URL 地址，也就是说只有系统才知道这个地址，快到秒杀的时候系统再把地址发布出去。有人会问如果浏览器/客户端存放的都是静态页面，那么控制“开始下单”的按钮，以及发送“下单请求”的按钮，也是静态的吗？答案是否定的，下单、验证用户权限和验证秒杀开始的时间都属于动态数据的范畴。静态页面是方便客户端缓存和下单的，对下单时间的控制在服务器端完成。倒计时功能可以通过 JS 方式在客户端实现，这样就不用每次都请求服务器获取时间信息了，只要在用户请求下单的时候再对比本地时间与服务器时间就可以了，这样能够避免“通过修改本地时间提前下单”的作弊行为。倒计时信息在秒杀快开始之前（10 ~ 15 分钟）以 JS 文件的方式发送给客户端，客户端负责把这部分 JS 文件下载下来。倒计时功能包含的业务逻辑很少，基本只有时间、用户信息、商品信息等。所以，其对网络的要求不高。同时在网络设计中，我们也会将 JS 文件和 HTML 文件同时缓存到 CDN 缓存中，让用户从离自己最近的 CDN 服务器上获取这些信息。</p>\n<p>通过上面的分析，这里总结一下秒杀页面的动静分离。</p>\n<ul>\n<li><strong>静态数据</strong>：商品详情和订单页面的 HTML，包括图片、CSS、基本功能和样式的 JS 文件。页面的 URL 需要提前用 Hash 算法生成，并在秒杀前发布。</li>\n<li><strong>动态数据</strong>：验证用户权限、下单、验证秒杀开始的时间。这些动态数据中可能包含一些 JS 异步请求，虽然实现这些功能是需要请求应用服务器的，但是承载这些功能的 JS 文件可以作为静态资源缓存起来。</li>\n</ul>\n<p>如图 8-4 所示，在秒杀之前可以通过应用服务器生成上面提到的信息，例如包含商品信息页面的 HTML 和下单需要的 JS 文件。把这些文件提前放到 CDN 缓存服务器上，在秒杀开始的时候用户就可以从最近的网络节点拿这些资源了。</p>\n<p class=\"p-img\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00535.jpeg\" alt=\"\" width=\"70%\" style=\"width: 70%\" /></p>\n<p class=\"ebook-image-title\"><strong>图 8-4　静态 HTML 和动态 JS 可以事先缓存起来供客户端使用</strong></p>\n<p>&nbsp;</p>\n</li>\n<li><p><strong>Nginx 实现动静分离</strong></p>\n<p>清楚了动静分离的定义，知道了如何识别动静数据，我们来看如何通过负载均衡器实现动静分离。Nginx 是目前使用比较多的负载均衡器，这里就以它为例进行讲解。假设有一个 HTML 页面，其中静态数据和动态数据都有。用户通过修改页面向服务器发送请求后，Nginx 会把请求拦截下来，然后把静态数据和动态数据分别路由到不同的服务器上。在下述代码中，我们假设有一个 JSP 页面，其中动态数据的部分是通过 <code>Random</code> 函数请求服务器，静态数据只是显示一张图片——picture.png：</p>\n<pre class=\"code-rows\"><code>&lt;%@ page language=\"java\" import=\"java.util.*\" pageEncoding=\"utf-8\"%&gt;\n    &lt;html&gt;\n      &lt;head&gt;\n        &lt;title&gt;TestPage&lt;/title&gt;\n      &lt;/head&gt;\n      &lt;body&gt;\n          &lt;%\n            Random rand = new Random();\n            out.println(\"&lt;h2&gt;我是动态数据&lt;/h2&gt;\");\n            out.println(rand.nextInt(99));\n        %&gt;\n        &lt;h2&gt;我是静态数据&lt;/h2&gt;\n        &lt;img src=\"picture.png\" /&gt;\n      &lt;/body&gt;\n    &lt;/html&gt;</code></pre>\n<p>下面是通过修改 Nginx 的配置文件 Nginx.conf 实现分别路由，具体是找到 <code>server</code> 节点，修改其中的 <code>location</code>，代码如下：</p>\n<pre class=\"code-rows\"><code>server {\n    listen 80;\n    server_name ds.com;\n    location / {       ②\n        proxy_pass http://127.0.0.1:8000;\n    }\n    location ~*\\.(png|jpg) {       ①\n        root / staticResource;\n    }\n}</code></pre>\n<p>从 ① 处可以看到，在 <code>location</code> 标签后面配置了正则表达式 <code>~*\\.(png|jpg)</code>，功能是匹配后缀是 .png 和 .jpg 的文件，将匹配到的文件路由到 <code>root</code> / <code>staticResource</code> 地址上（当然也可以配置 <code>proxy_pass</code>，将这个地址指向对应的静态资源服务器）。从 ② 处可以看到，其他动态请求会通过匹配 / 被路由到地址为 http://127.0.0.1:8000 的应用服务器。因此当用户请求静态数据的时候，Nginx 从 root/staticResource 路径获取数据并且返回；当 <code>Random</code> 函数请求的时候，从地址为 http://127.0.0.1:8000 的服务器返回。</p>\n</li>\n</ol>\n<h3 id=\"nav_point_157\">8.1.3　HTTP 缓存</h3>\n<p>动静分离以后，可以从缓存中获取静态数据，减小了数据的请求量和请求路径的长度。顺着这个思路，下面我们来介绍实现静态数据缓存的方式，HTTP 缓存就是其中之一。</p>\n<p>用户借助浏览器请求服务器的时候，会发起 HTTP 请求，如果能把每次的 HTTP 请求都缓存下来，那么应用服务器的压力就可以减少。在用户第一次发出 HTTP 请求的时候，浏览器的本地缓存库中还没有缓存数据，因此会到应用服务器中获取数据，拿到数据后也会往浏览器的本地缓存库中放一份，这样下次再请求同样数据的时候，根据缓存策略来读取本地缓存库中的数据即可。如图 8-5 所示，客户端请求数据时，先看本地缓存中是否有这部分数据，如果有，则由本地缓存提供数据并直接返回客户端使用；如果是第一次请求，那本地还没有想要的数据，于是向应用服务器发起请求，应用服务器接收请求后提供相应的数据给客户端，客户端接收数据，完成数据获取的操作。</p>\n<p class=\"pic\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00536.jpeg\" alt=\"{%}\" /></p>\n<p class=\"ebook-image-title\"><strong>图 8-5　有了 HTTP 缓存后的请求流程图</strong></p>\n<p>信息一般通过 HTTP 请求头来传递。目前比较常见的 HTTP 缓存方式有两种，分别是强制缓存和对比缓存。</p>\n<ol>\n<li><p><strong>强制缓存</strong></p>\n<p>当浏览器的本地缓存库中保存了缓存信息，而缓存数据又未失效时，是可以直接使用缓存数据的。否则就需要重新获取数据。这种缓存机制看上去比较直接，那么如何判断缓存数据是否失效呢？这里需要关注 HTTP 请求头中的两个字段：<code>Expires</code> 和 <code>Cache-Control</code>。<code>Expires</code> 是服务器端返回的过期时间，客户端第一次请求应用服务器时，服务器会返回资源的过期时间。客户端再次请求相同资源的时候，会对请求时间和资源过期时间做比较，如果前者小于后者，说明缓存没有过期，可以直接使用本地缓存库里的数据；反之说明数据已经过期，必须从应用服务器中重新获取信息，获取完毕后把过期时间更新为最新的。这种方式在 HTTP 1.0 用得比较多，HTTP 1.1 开始使用 <code>Cache-Control</code> 来替代它。<code>Cache-Control</code> 中有个 <code>max-age</code> 属性，单位是秒，用来表示缓存内容在客户端的过期时间。例如 <code>max-age</code> 的取值是 <code>60</code> 表示当前的本地缓存库中没有数据，客户端第一次请求完应用服务器后，将数据放入本地缓存，那么客户端如果在 60 秒以内再次发送请求，就不会请求应用服务器了，而是直接从本地缓存中返回；如果客户端两次请求的相隔时间超过了 60 秒，就需要去应用服务器中获取了。</p>\n<p>&nbsp;</p>\n</li>\n<li><p><strong>对比缓存</strong></p>\n<p>这种缓存方式需要对比前后两次的缓存标识，来判断是否使用缓存中的数据。客户端第一次向应用服务器请求数据时，应用服务器会将缓存标识与数据一并返回，之后浏览器将二者备份至本地缓存库中。当客户端再次发出 HTTP 请求时，将备份的缓存标识发送给应用服务器。</p>\n<p>应用服务器根据缓存标识对数据是否发生变化进行判断，如果判断没有发生变化，就把 HTTP 状态码 304（表示判断成功）发送给浏览器。这时浏览器才可以使用缓存中保存的数据。此处应用服务器返回的就只是响应头，不包含响应体。下面介绍两种标识规则。</p>\n<ul>\n<li><p><strong><code>Last-Modified</code> / <code>If-Modified-Since</code> 规则</strong></p>\n<p>如图 8-6 所示，客户端第一次发出请求的时候，应用服务器会返回资源的最后修改时间，记作 <code>Last-Modified</code>。客户端将这个字段连同资源一并缓存下来，在下次请求的时候把保存的 <code>Last-Modified</code> 当作 <code>If-Modified-Since</code> 字段发送。</p>\n<p class=\"p-img\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00537.jpeg\" alt=\"{%}\" /></p>\n<p class=\"ebook-image-title\"><strong>图 8-6　<code>Last-Modified</code>/<code>If-Modified-Since</code> 规则下的第一次请求服务器</strong></p>\n<p>接着来看图 8-7，当客户端再次请求服务器时，会把 <code>Last-Modified</code> 连同请求的资源一起发给服务器，这时的 <code>Last-Modified</code> 会被命名为 <code>If-Modified-Since</code>，两者存放的内容都是一样的。</p>\n<p class=\"p-img\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00538.jpeg\" alt=\"{%}\" /></p>\n<p class=\"ebook-image-title\"><strong>图 8-7　<code>Last-Modified</code>/<code>If-Modified-Since</code> 规则第二次请求服务器</strong></p>\n<p>服务器接收到请求，会对 <code>If-Modified-Since</code> 字段与自身保存的 <code>Last-Modified</code> 字段做比较。若后者的最后修改时间大于前者，则说明资源被修动过，于是服务器会把资源（包括请求头、请求体）重新返回给浏览器，同时返回状态码 200。</p>\n<p>若后者的最后修改时间小于或等于前者，则说明资源没有修动过，因此只会返回 Header，并且返回状态码 304。浏览器接收到这个消息后，就可以使用本地缓存库中存放的数据了。</p>\n<p>注意，<code>Last-Modified</code> 和 <code>If-Modified-Since</code> 指的是同一个值，只是在客户端和服务器端的叫法不同。</p>\n<p>&nbsp;</p>\n</li>\n<li><p><strong><code>ETag</code> / <code>If-None-Match</code> 规则</strong></p>\n<p>客户端第一次向服务器请求资源的时候，服务器会给每个资源分别生成一个 <code>ETag</code> 标记（<code>ETag</code> 是根据每个资源生成的具有唯一性的 Hash 串，资源如果发生变化，<code>ETag</code> 也会随之更改），然后将这个 <code>ETag</code> 返回给客户端，客户端会把请求到的资源和 <code>ETag</code> 一起缓存到本地。客户端在下次请求资源的时候会把保存下来的 <code>ETag</code> 当作 <code>If-None-Match</code> 字段发送出去。如图 8-8 所示，客户端在请求服务器之前先判断客户端缓存是否存在，如果不存在再去请求应用服务器；服务器在获取资源的同时给资源打上 <code>ETag</code>，这个 <code>ETag</code> 连同资源一起返回给客户端，并且客户端将二者一并保存起来。另外，客户端也会缓存资源和 <code>ETag</code> 信息。</p>\n<p class=\"p-img\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00539.jpeg\" alt=\"\" width=\"85%\" style=\"width: 85%\" /></p>\n<p class=\"ebook-image-title\"><strong>图 8-8　<code>ETag</code>/<code>If-None-Match</code> 第一次请求服务器</strong></p>\n<p>客户端在第二次向服务器请求相同的资源时，会把资源对应的 <code>ETag</code> 一并发送给服务器。在请求时，<code>ETag</code> 会转化成 <code>If-None-Match</code>，但内容不变。</p>\n<p>如图 8-9 所示，由于是第二次请求服务器，客户端中已经存在资源的名字和 <code>If-None-Match</code>。客户端请求资源时，把这两个信息一并发给应用服务器，当应用服务器接收到请求后，会对 <code>If-None-Match</code> 与自身保存的资源的 <code>ETag</code> 做比较。比较结果分不一致和一致两种情况，分别如下。</p>\n<p class=\"p-img\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00540.jpeg\" alt=\"{%}\" /></p>\n<p class=\"ebook-image-title\"><strong>图 8-9　<code>ETag</code>/<code>If-None-Match</code> 第二次请求服务器</strong></p>\n<p>如果不一致，则说明资源被修动过，于是返回资源（Header+Body），以及状态码 200。由于资源被修动过，应用服务器还会重新获取资源，将资源和 <code>ETag</code> 信息都返回给客户端，此举动无疑会增加网络传输。</p>\n<p>如果一致，说明资源没有被修改过，于是返回 Header，以及状态码 304。客户端接收到这个消息就可以使用本地缓存库的数据，而不用从应用服务器获取新的数据，从而减少了网络传输这一步。</p>\n<p>注意，<code>ETag</code> 和 <code>If-None-Match</code> 指的是同一个值，只是在客户端和服务器端的叫法不同。</p>\n</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"nav_point_158\">8.1.4　CDN 缓存</h3>\n<p>HTTP 缓存中存放的主要是静态数据，就是把从服务器中拿出的数据缓存到客户端/浏览器。如果在客户端和服务器之间加上一层 CDN（Content Delivery Network，内容分发网络），就可以让 CDN 为应用服务器提供缓存了，有了 CDN 缓存，客户端就不用再请求服务器了。8.1.3 节讲到的两种策略同样可以应用于 CDN 服务器。</p>\n<p>CDN 缓存解决了资源访问的延迟问题，适用于网络应用加速等场景；使得访问网络应用的用户能从离自己最近的网络节点中获取信息；同时解决了网络拥挤问题，并且提高了用户访问网络应用的响应速度和成功率。CDN 缓存通过尽量缩短信息的传输路径，正如前面讲的动静分离那样，把静态数据存放在 CDN 网络中，保证用户能够以最短的网络路径获取资源，而不用回源到更深层次的应用服务器，甚至数据库。为了方便大家理解客户端访问 CDN 网络的整个过程，我们下面从 CDN 请求流程入手，分 5 个步骤给大家展开说明。CDN 工作简图如图 8-10 所示。</p>\n<p class=\"pic\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00541.jpeg\" alt=\"{%}\" /></p>\n<p class=\"ebook-image-title\"><strong>图 8-10　CDN 工作简图</strong></p>\n<p>CDN 节点负责接收客户端的请求，它就是离客户端最近的服务器，后面会连接多个服务器，起到了缓存和负载均衡的作用。</p>\n<p>(1) 客户端发送 URL 地址给 DNS 服务器。这个 URL 中包含所请求资源的信息。</p>\n<p>(2) DNS 服务器通过域名解析，把请求指向 CDN 网络中的 DNS 负载均衡器。</p>\n<p>(3) DNS 负载均衡器将最近的 CDN 节点的 IP 地址告诉 DNS 服务器，DNS 服务器再告知客户端。</p>\n<p>(4) 客户端向最近的 CDN 节点请求资源。</p>\n<p>(5) CDN 节点从应用服务器获取资源返回给客户端，同时将静态信息缓存下来。注意，客户端下次互动的对象就是 CDN 缓存了，CDN 可以和应用服务器同步缓存信息。</p>\n<h3 id=\"nav_point_159\">8.1.5　DNS 结构与访问流程</h3>\n<p>8.1.4 节讲了客户端请求如何通过 CDN 网络访问到静态资源，在请求流程的 5 个步骤中反复出现了 DNS 服务器和 DNS 负载均衡器的身影。为了让大家对这个访问流程有更加深入的理解，这里将对 DNS 结构和访问流程展开说明。要点包括两个方面：DNS 的定义和结构、DNS 解析客户端请求的原理。</p>\n<ol>\n<li><p><strong>DNS 的含义和结构</strong></p>\n<p>互联网使用 IP 地址来唯一标识一个服务器。虽然 IP 地址能代表一台设备，但其记忆起来比较困难，所以人们把它替换成了一个易于理解和识别的名字，这个名字叫作域名，例如 www.ituring.com 就是一个域名。域名后面会定义一个 IP 地址，用来指向网站服务器。那么问题来了，谁来实现这个从域名到 IP 地址的映射关系呢？答案是 DNS。</p>\n<p>DNS（Domain Name System，域名系统）是互联网的一项服务，它维护着一个分布式数据库，数据库中保存着域名和 IP 地址的对照关系，能够让人们更方便地访问互联网。</p>\n<p>DNS 从结构上来说，最顶层是根域名服务器（ROOT DNS Server），里面存储着 260 个顶级域名服务器的 IP 地址。对于 IPv4 来说，全球有 13 个根域名服务器，这些服务器存储了每个域（如.com、.net、.cn）的解析和域名服务器的地址信息。简单点讲，根域名服务器就是用来存放顶级域名服务器地址的。</p>\n<p>根域名服务器的下一级是顶级域名服务器，顶级域名又称一级域名。例如 .com 域名服务器中存储的是一些一级域名（如 ituring.com）的权威 DNS 服务器地址。顶级域名可以分为三类：gTLD、ccTLD 和 New gTLD。</p>\n<ul>\n<li>gTLD：国际顶级域名，例如 .com、.net、.org 等；</li>\n<li>ccTLD：国家和地区顶级域名，例如中国的域名是.cn，日本的域名是.jp；</li>\n<li>New gTLD：新顶级域名，例如 .xyz、.top、.red、.help 等。</li>\n</ul>\n<p>顶级域名服务器就是根据上面三类保存域名或者 IP 地址的对应数据。</p>\n<p>顶级域名服务器的下一级是本地域名服务器（Local DNS Server），一般是运营商的 DNS，主要作用是代理用户进行域名分析。</p>\n<p>如图 8-11 所示，DNS 服务器分为三级，从上到下分别是根域名服务器、顶级域名服务器和本地域名服务器。</p>\n<p class=\"p-img\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00542.jpeg\" alt=\"\" width=\"80%\" style=\"width: 80%\" /></p>\n<p class=\"ebook-image-title\"><strong>图 8-11　DNS 服务器的结构</strong></p>\n<p>&nbsp;</p>\n</li>\n<li><p><strong>DNS 解析客户端请求的原理</strong></p>\n<p>这部分将以客户端访问网页的过程为例，描述 DNS 解析以及从获取 URL 到将之映射为 IP 地址的整个过程。过程比较复杂，存在信息的来回传递。因此画图时，我们会简化信息来回传递的线段，将重点放在信息传递的路径上，如图 8-12 所示。</p>\n<p class=\"p-img\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00543.jpeg\" alt=\"{%}\" /></p>\n<p class=\"ebook-image-title\"><strong>图 8-12　DNS 解析的全过程</strong></p>\n<p>图 8-12 通过 9 步来诠释 DNS 解析的过程。</p>\n<p>(1) 客户端通过浏览器输入要访问网站的地址，例如：www.ituring.com。浏览器会在自己的缓存中查找此 URL 对应的 IP 地址。如果客户端之前访问过这个地址，那么缓存中就会保存这个 URL 对应的 IP 地址，此时客户端可以直接访问 IP 地址。如果没有缓存，则进入第 (2) 步。</p>\n<p>(2) 通过配置计算机本地的 Host 文件，可以设置 URL 和 IP 地址的映射关系。例如 Windows 系统下是配置 C:\\windwos\\system32\\driver\\etc\\hosts 文件，Linux 系统中是配置 /etc/named.confg 文件。这里查找本地的 Host 文件，是看有无 IP 地址的缓存。如果在此文件中依旧没有找到映射关系，就进入第 (3) 步。</p>\n<p>(3) 请求本地域名服务器，通过本地运营商获取 URL 和 IP 地址的映射关系。如果用的是校园网，那么 DNS 服务器就在学校；如果用的是小区网络，则 DNS 服务器是由运营商提供的。总之，本地域名服务器在物理位置上离发起请求的计算机是比较近的。本地域名服务器中缓存了大量的 DNS 解析结果，由于性能较好，在物理上又与发起请求的计算机的距离比较近，因此它通常在很短的时间内就可以返回针对指定域名的解析结果。这一步可以满足 80%的 DNS 解析需求，如果这一步还是没有完成 DNS 解析，则进入第 (4) 步。</p>\n<p>(4) 通过根域名服务器进行解析，根域名服务器会根据请求的 URL，把顶级域名服务器的地址返回给本地域名服务器。例如查询的是 .com 的域名，就查询 gTLD 对应的域名服务器的地址。</p>\n<p>(5) 收到顶级域名服务器的地址以后，本地域名服务器就去访问对应的顶级域名服务器（gTLD、ccTLD、New gTLD），顶级域名服务器会返回 Name Server 的地址。这个 Name Server 就是网站注册的域名服务器，上面包含网站 URL 和 IP 地址的对应信息。你在哪个域名服务提供商那里申请的域名，这个域名就由这个服务商对应的服务器来解析。Name Server 是由域名提供商维护的。</p>\n<p>(6) Name Server 会把指定域名的 A 记录或者 CNAME 返回给本地域名服务器，并且设置一个 TTL。</p>\n<ul>\n<li>A（Address）记录：用来指定主机名（或域名）对应的 IP 地址记录。用户可以将该域名下的网站服务器指向自己的 Web 服务器，同时也可以给自己的域名设置二级域名。</li>\n<li>CNAME：别名记录。这种记录允许将多个名字映射到同一个域名，通常用于同时提供 WWW 和 MAIL 服务的计算机。例如有一台同时提供 WWW 和 MAIL 服务的计算机名为 host.mydomain.com（A 记录）。为了便于用户访问服务，也方便服务商维护，一般建议用户使用 CNAME 别名记录方式。如果主机使用了双线 IP，显然 CNAME 更方便一些。</li>\n<li>TTL（Time To Live）：用于设置 DNS 解析在本地域名服务器上的过期时间。超过这个过期时间后，URL 和 IP 地址的映射关系就会被删除，之后如果需要获取，还要请求 Name Server。</li>\n</ul>\n<p>(7) 如果第 (6) 步获取的是 A 记录，就可以直接访问网站的 IP 地址了。但大型网站通常会返回 CNAME，然后将其传给 GTM 服务器。GTM（Global Traffic Manager）即全局流量管理，基于网宿智能 DNS、分布式监控体系，实现实时故障切换以及全球负载均衡，保障应用服务的持续高可用性。传给 GTM 服务器的目的是希望通过 GTM 的负载均衡机制，帮助用户找到最适合自己的服务器，也就是离自己最近、性能最好、服务器状态最健康的服务器。而且大多数网站会实现 CDN 缓存，此时就更需要让 GTM 帮忙找到网络节点中适合自己的 CDN 缓存服务器了。</p>\n<p>(8) 找到 CDN 缓存服务器以后，可以直接从上面获取一些静态资源，例如 HTML、CSS、JS 和图片。对于动态资源，例如商品信息和订单信息，则需要走第 (9) 步。</p>\n<p>(9) 对于没有缓存下来的动态资源，需要从应用服务器上获取，应用服务器与互联网之间通常有一层负载均衡器负责反向代理，由它将客户端请求路由到应用服务器上。</p>\n</li>\n</ol>\n<h3 id=\"nav_point_160\">8.1.6　负载均衡实现动态缓存</h3>\n<p>动静分离的设计思想是将静态数据放到客户端和 CDN 中缓存起来。那么除了缓存静态数据，动态数据该如何缓存呢？通常而言，动态缓存指的是缓存一些业务数据，也就是和用户使用的业务场景相关的数据。还是以秒杀业务为例，用户请求会把用户 ID、商品 ID 传给服务器，进行验证操作。实际上这个验证操作不需要在服务器中完成，有些数据相对于秒杀而言是固定的。例如秒杀商品在秒杀之前就已经确定好了、系统中的用户信息也早就存在了。这些信息完全可以在秒杀之前就放到缓存服务器（Redis）中。用户请求在进入服务器集群前都会经过代理层，因此验证操作其实可以在代理层完成。换句话说，验证操作可以在经过负载均衡器的时候完成，这样就省去了调用服务器的环节，能够更快地响应用户。如图 8-13 所示，从接入层来的用户请求，通过 Nginx 代理层。</p>\n<p class=\"pic\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00544.jpeg\" alt=\"\" width=\"80%\" style=\"width: 80%\" /></p>\n<p class=\"ebook-image-title\"><strong>图 8-13　动态缓存的调用方案</strong></p>\n<p>下面为图 8-13 中的三个步骤。</p>\n<p>(1) 用户请求应用服务器时，如果请求的数据在 Nginx 本地保存着，就直接返回给用户。</p>\n<p>(2) 如果没有 Nginx 本地缓存，则需要回源到上游的应用服务器。</p>\n<p>(3) 还有一部分不会经常变动的动态数据（用户信息、商品信息），Nginx 可以直接调用缓存服务器（Redis）获取，因此不用回源到应用服务器。需要注意的是这部分动态数据虽然不经常变化，但不等于不发生变化，一旦其发生变化，是需要更新缓存服务器的。</p>\n<p>图 8-13 所示的方案，无非是减少了调用的步骤，因为服务器有可能存在其他的调用，存在数据转换和网络传输成本。同时这个方案还包含一些业务逻辑和访问数据库的操作，影响响应时间。从代理层调用的缓存数据具有如下特点。</p>\n<ul>\n<li>这类数据变化不太频繁，例如用户信息。</li>\n<li>业务逻辑简单，例如验证用户是否有资格参加秒杀活动、验证商品是否在秒杀活动范围内。</li>\n<li>此类缓存数据需要专门的进程对其进行刷新，如果无法命中，还是需要请求服务器。</li>\n</ul>\n<p>实现这种方案一般需要加入少许代码脚本。以 Nginx 为例，需要加入 Lua 脚本协助实现。针对 OpenResty Lua 的具体开发，在这不展开。我会举一个例子帮助大家理解，最重要的目的是打开思路。例子描述的是客户端发送 <code>userId</code>（用户 ID）信息，有些 <code>userId</code> 事先已经放到了缓存服务器（Redis）中，表示对应的用户可以参与秒杀活动。Nginx 对比用户请求的 <code>userId</code> 和缓存的 <code>userId</code> 是否一致，如果一致，就让客户端进行后续的访问，否则拒绝其请求。这只是一个例子，在实际操作中，这个 <code>userId</code> 也可以是商品 ID，对应的操作是验证商品是否参与秒杀活动；或者是客户端的 IP 地址，对应的操作是判断这个请求是否为来自黑名单的恶意请求。这个例子的示意图如图 8-14 所示。</p>\n<p class=\"pic\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00545.jpeg\" alt=\"\" width=\"76%\" style=\"width: 76%\" /></p>\n<p class=\"ebook-image-title\"><strong>图 8-14　Nginx 动态缓存的例子</strong></p>\n<p>(1) 用户请求秒杀服务的时候，会附带 <code>userId</code> 信息。</p>\n<p>(2) 系统需要确认用户的身份和权限。于是先通过 Nginx 上的 Lua 脚本查询缓存服务器（Redis）。缓存服务器事先已经缓存了用户的鉴权信息，因此如果能从中获得 <code>userId</code> 相关的信息，就可直接返回用户拥有的权限，进行后面的操作。</p>\n<p>(3) 如果从缓存服务器中获取不到，再去请求上游的用户鉴权服务器，并进行后面的业务流程。</p>\n<p>上面提到的 Lua 脚本是一种轻量小巧的脚本语言，由标准 C 语言编写，以源代码的形式开放，嵌入到 Nginx 中，为其提供灵活的扩展和定制功能。它负责调用缓存服务器（Redis）和上游服务器。接下来我们看看 Lua 的具体实现和 Nginx 的配置。</p>\n<p>先建立 Lua 脚本，实现如下功能。</p>\n<p>(1) 创建 Redis 连接。以 <code>userId</code> 为键读取缓存服务器中的信息，看 <code>userId</code> 是否存在于缓存服务器中。实现这一功能的函数是 <code>get_redis</code>，输入参数是 <code>userId</code>，返回值是 <code>Reponse</code>，若返回值不为空，则说明 <code>userId</code> 存在于缓存服务器中。</p>\n<p>(2) 关闭 Reids 连接。对应的函数是 <code>close_redis</code>，输入参数是 <code>redis</code> 对象。</p>\n<p>(3) 连接上游的服务器。对应的函数是 <code>get_http</code>，输入参数是 <code>userId</code>，主要是获取 <code>userId</code> 对应的访问权限。</p>\n<p>脚本的执行过程如下。</p>\n<p>初始时，Nginx 获取用户的 URL 请求，截取 <code>userId</code> 参数并传给 Lua 脚本。Lua 脚本建立与 Redis 的连接，查询对应的 <code>userId</code> 是否存在缓存中。如果存在就直接返回结果，完成后续操作。如果不存在，则调用 <code>get_http</code> 函数请求上游的用户鉴权服务器。最后，调用 <code>close_redis</code> 函数关闭与 Redis 的联机。</p>\n<p>限于篇幅，这里只简单介绍函数 <code>get_redis</code> 的主要代码，其部分代码如下：</p>\n<pre class=\"code-rows\"><code>local redis = require(\"resty.redis\")     ①\nlocal cjson = require(\"cjson\")             ②\nlocal ngx_var = ngx.var                     ③\n\nlocal function get_redis(userId)         ④\nlocal localredis = redis:new()      ⑤\nlocalredis:set_timeout(2000)\nlocal ip = \"192.168.1.1\"\nlocal port = 8888\nlocal ok, err = localredis:connect(ip, port)    ⑥\nlocal response, err = localredis:get(userId)  ⑦\nclose_redis(localredis)\nreturn resp\nend\n\nlocal userId = ngx_var.userId         ⑧\nlocal content = get_redis(userId)    ⑨\n\nif not content then                     ⑩\ncontent = get_http(userId)\nend\n    return ngx_exit(404)\nend</code></pre>\n<p>下面简要介绍其中的代码。</p>\n<p>① 引用 Lua 的 <code>redis</code> 模块，此后就可以对其进行操作，例如产生 Redis 实例。</p>\n<p>② 引用 Lua 的 <code>cjson</code> 模块，用来实现 Lua 值与 Json 值之间的相互转换。</p>\n<p>③ 定义 <code>ngx_var</code>，用来获取 Nginx 传入的请求参数，下面的步骤中需要用它接收传入的用户信息。</p>\n<p>④ 定义函数 <code>get_redis</code>，其主要作用是通过用户 ID（<code>userId</code>）从缓存中获取对应的用户信息。如果其返回值不为空，说明缓存中存在用户信息。</p>\n<p>⑤ 利用 Lua 的 <code>redis</code> 模块，新建 <code>redis</code> 对象，从而可以调用缓存信息，并设置缓存的超时时间。</p>\n<p>⑥ 设置 Redis 缓存服务器的 IP 地址和端口号，并打开 Redis 连接。</p>\n<p>⑦ 输入 <code>userId</code> 获取对应的值，并将结果存放到 <code>response</code> 和 <code>err</code> 变量中。在 <code>response</code> 为空的情况下，可以返回 <code>null</code>，并且关闭 Redis 连接。最后返回请求缓存的结果。</p>\n<p>⑧ 描述完 <code>get_redis</code> 函数以后，程序从这里开始执行，首先从请求的参数变量 <code>ngx_var</code> 中获取 <code>userId</code>。</p>\n<p>⑨ 调用 <code>get_redis</code> 函数，传入 <code>userId</code>，把返回的结果放到 <code>content</code> 变量中。</p>\n<p>⑩ 如果缓存中不存在 <code>userId</code>，就去请求上游的用户鉴权服务器。使用 HTTP 请求调用上游的用户鉴权服务器，如果这个服务器里还没有，就返回 404。</p>\n<p>上面的 Lua 脚本主要是通过 <code>get_redis(userId)</code> 传入 <code>userId</code>，再从缓存中获取信息的过程。将这个脚本保存在 /usr/checkuserid.lua 下面。它如何与 Nginx 协同工作呢？配置 Nginx 的代码如下：</p>\n<pre class=\"code-rows\"><code>location ~ ^/userid(\\d+)$ {\n    default_type 'text/html';\n    charset utf-8;\n    lua_code_cache on;\n    set $userId $1;\n    content_by_lua_file /usr/checkuserid.lua;\n}</code></pre>\n<p>假设用户通过 URL（<code>http://192.168.1.1/userid/123</code>）访问秒杀系统。其中传入的用户 ID 为 <code>123</code>，通过 Nginx 中 <code>location</code> 配置的正则表达式 <code>location ~ ^/userid(\\d+)$</code> 与 Lua 命令 <code>content_by_lua_file</code> 绑定到一起，这个命令后面的参数就是 Lua 脚本的地址。传入的参数 <code>userId</code> 是 <code>123</code>，于是 Lua 脚本中的 <code>get_redis(userId)</code> 就会执行后面的查找操作了。这种动态缓存的方式，不仅缓存了用户信息，还起到了过滤的功效，可以过滤一些不满足条件的用户。注意，这里用户信息的过滤和缓存只是一个例子。主要想表达的意思是，可以将一些变化不频繁的数据，提到代理层来缓存，从而提高响应的效率。同时，还可以根据风控系统返回的信息，过滤一些疑似机器人或者恶意请求的信息。例如从固定 IP 地址发送过来的、频率过高的请求。最重要的就是，在代理层可以识别来自秒杀系统的请求。如果请求中带有秒杀系统的参数，就要把该请求路由到秒杀系统的服务器集群，这样才能将秒杀业务和正常业务系统分割开来。</p>\n<h3 id=\"nav_point_161\">8.1.7　进程内缓存</h3>\n<p>先来介绍进程内缓存的定义和原理，应用服务器上部署着一个个应用，这些应用以进程的方式运行着，那么进程内的缓存是怎样的呢？进程内缓存又叫托管堆缓存，以 Java 为例，这部分缓存放在 JVM 的托管堆上，会受托管堆回收算法的影响。</p>\n<p>进程内缓存是受限于内存大小的。由于缓存运行在本地，因此进程内缓存更新后，其他进程内的缓存是无法知道的，例如对订单更新服务进行水平扩展，将之扩展成两个完全一样的服务。假如其中一个服务在本地更新了订单状态，那么另一个服务是无法知道这个更新的，此时若用户向另一个服务请求数据，就无法获取更新状态后的缓存。因此进程内缓存适用于以下场景。</p>\n<p>数据量小，更新频率低。例如订单状态更新场景只需要在付款完成之后，更新一下订单状态即可，而且更新频率也不高；使用 Caffeine 作为本地缓存，将 <code>size</code> 设置为 <code>10000</code>、过期时间设置为 30 分钟，基本能在解决高峰期的问题。如果更新频繁高的场景也想使用进程内缓存，则需要设置较短的过期时间，或者较短的自动刷新时间。</p>\n<p>进程内缓存由于不涉及序列化和反序列化操作，因此缓存速度较快。缺点上面也提到了，就是缓存的空间不能太大，会对垃圾回收器的性能产生影响。目前比较流行的进程内缓存的实现有 ehcache、Caffeine、GuavaCache。这些架构很容易就能把一些热点数据放到进程内缓存中。由于这个缓存的大小有限，因此其中缓存的数据会面临缓存回收的问题。进程内缓存通过回收那些不经常使用的数据，把空间腾出来，给那些使用较多的数据使用。缓存的回收策略根据具体的架构实现会有所不同，这里我们需要关注两个回收策略，大致思路都是一样的。</p>\n<ol>\n<li><p><strong>缓存回收算法</strong></p>\n<p>LRU（Least Recently Used，最近最少使用算法）的思想是移除缓存中最久没有被使用过的数据。这种算法认为最近被访问过的数据将来被访问的几率也会高。其实现方式是把缓存数据保存在一个双向链表中，新加入的缓存数据和被访问次数较多的数据被放到链表的头部。也就是说，链表的头部存放着被高频访问的数据。按照这个方式，那些被访问较少的数据逐渐积累到了链表的尾部。因此一旦缓存被填满，首先从链表的尾部开始淘汰数据。这种算法在遭遇突发流量时表现不俗，流量爆发通常是因为热点数据的访问量激增，使用这种算法一定不会释放这部分热点数据。</p>\n<p>如图 8-15 所示，使用 LRU 算法的缓存在内部维护着一个双向链表，链表中每个节点都有两个指针，分别指向自己上面和下面的节点。可以看出，左边的链表由三个节点组成，从上到下分别是缓存数据 A、B、C，每个节点都向上、下伸出两个黑色箭头，所有节点通过这种方式实现首尾相连。另外，定义缓存数据 A 为链表头部，定义缓存数据 C 为链表尾部，这样一个有头有尾、节点之间互相连接的链表就形成了。顺着添加新缓存的箭头往右看，当新缓存数据 D（虚线框）加入时，会自动被放到链表的头部，同时缓存数据 A 和 D 之间用双向箭头连接到一起，此时新缓存数据 D 代替 A 成为链表头部。</p>\n<p class=\"p-img\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00546.jpeg\" alt=\"{%}\" /></p>\n<p class=\"ebook-image-title\"><strong>图 8-15　双向链表添加新缓存</strong></p>\n<p>如图 8-16 所示，缓存数据 B 由于被访问次数较多，从而成为热点数据，于是被移动到链表的头部。假设此时有新的缓存数据要加入链表中，而链表的容量已满，为了存放新的数据就会将表尾的缓存数据 C 淘汰。</p>\n<p class=\"p-img\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00547.jpeg\" alt=\"\" width=\"55%\" style=\"width: 55%\" /></p>\n<p class=\"ebook-image-title\"><strong>图 8-16　热点数据移动到表头，淘汰表尾数据</strong></p>\n<p>LFU（Least Frequently Used，最不常用算法）算法的思路是移除缓存中一段时间内使用频率最小的数据。该算法会记录缓存数据的被访问次数，并以这个访问次数作为淘汰数据的依据。算法用一个列表保存访问次数，并对次数从大到小进行排列，说白了就是要明确哪些数据的被访问次数比较多，认为被访问次数越多的数据越是重要，越会留在缓存中继续使用。根据这个思想，需要开辟一个存储列表来存每个数据的被访问次数，这会消耗本来就不多的内存资源。而且容易考虑不到一些特殊情况，例如刚刚上架一个秒杀商品，它的访问次数显然没有其他商品多，如果一加入缓存中，就因为被访问次数少被淘汰掉，那这是我们不希望看到的情形。</p>\n<p>如图 8-17 所示，左边的数据列表中存放着数据 A~G，并且每个节点上都标注着数据被访问的次数。可以看出“数据 E”的被访问次数为 17，给它增加 10 次访问之后，它在列表中的位置就会上移。上移之后形成了右边新的队列，如果此时有其他缓存数据加入，导致缓存空间不足需要释放数据，依旧是从列表的尾部释放被访问次数最少的缓存数据。此时数据 G 由于在整个列表中的被访问次数是最少的（1 次），因此会被淘汰。</p>\n<p class=\"p-img\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00548.jpeg\" alt=\"{%}\" /></p>\n<p class=\"ebook-image-title\"><strong>图 8-17　节点在列表中的位置随着被访问次数的改变而改变</strong></p>\n<p>&nbsp;</p>\n</li>\n<li><p><strong>Caffeine 针对进程内缓存的最佳实践</strong></p>\n<p>8.1.7 节开头提到目前比较流行的进程内缓存有 ehcache、GuavaCache、Caffeine 等。这里以最流行的 Caffeine 为例，给大家介绍一下进程内缓存的用法。Caffeine 是基于 JAVA 8 的高性能缓存库，使用其提供的进程内缓存时可参考 Google Guava Cache 的 API。Caffeine 是基于 Google Guava Cache 的设计经验，改进而得的成果。在性能方面，Caffeine 是比较强的，并发性测试的结果明显优于 Guava Cache。下面我们就从缓存加载策略、缓存过期策略和缓存淘汰策略三方面来看看 Caffeine 是如何实现进程内缓存的。</p>\n<ul>\n<li><p><strong>缓存加载策略</strong></p>\n<p>Caffeine 的缓存加载有三种方式，分别是手动加载、同步加载和异步加载。以下面的代码为例，首先通过 Caffeine 中的 <code>newBuilder</code> 对缓存进行初始化，这里可以定义缓存大小、过期方式、过期时间等参数，在后面的例子中会具体讲解这些参数。首先介绍的是手动加载方式：</p>\n<pre class=\"code-rows\"><code>public class CaffeineTestMain {\n    public static void main(String[] args) {\n        Cache&lt;String, Object&gt; caffeineCache = Caffeine.newBuilder().build();   ①\n        String key = \"cacheKey\";   ②\n        caffeineCache.put(key,\"cacheValue\");  ③\n        System.out.print(\"key=\"+key+\";value=\"+ caffeineCache.\n                         getIfPresent(key)); ④\n    }\n}</code></pre>\n<p>下面简要解释一下上述代码。</p>\n<p>① 通过 Caffeine 的 <code>newBuilder</code> 初始化缓存，这里以 <code>build</code> 方法作为入口，初始化一个缓存。</p>\n<p>② 缓存中的数据都是以键值对形式存放的，因此定义一个 <code>key</code> 为 <code>cacheKey</code>，这里的定义需要根据具体业务来确定，如果存放的是订单状态，就定义为 <code>orderStatus</code>。</p>\n<p>③ 定义好 <code>key</code> 以后，通过 <code>caffeineCache.put(key,\"cacheValue</code>\"); 语句将 <code>cacheValue</code> 这个缓存值存放到缓存中，也就是定义的 <code>cacheKey</code> 中。</p>\n<p>④ 最后，通过 <code>caffeineCache</code> 中的 <code>getIfPresent</code> 方法，传入对应的 <code>key</code>，获取 <code>value</code> 的值。这步看上去比较简单。</p>\n<p>通过 <code>key</code> 获取缓存数据的时候，会遇到同步加载情况。同步加载指在第一次获取缓存数据的时候，缓存中没有 <code>key</code> 对应的值，因此需要去数据库或者其他地方获取这个值。相关代码如下：</p>\n<pre class=\"code-rows\"><code>private static void loadingCache(){\n    LoadingCache&lt;String, Object&gt; loadingCache = Caffeine.newBuilder()\n        .build(key -&gt; createObject(key));   ①\n    String key = \"cacheKey\";\n    Object object = loadingCache.get(key);        ③\n    System.out.print(\"key=\"+key+\";value=\"+ object);\n}\n\nprivate static Object createObject(String key) {     ②\n    return \"data for \"+ key;\n}</code></pre>\n<p>下面简要解释一下上述代码。</p>\n<p>① <code>loadingCache</code> 是用来获取同步加载缓存的 <code>Cache</code> 对象，通过对应的 <code>newBuilder</code> 中的 <code>build</code> 方法对同步加载缓存进行初始化，使用 <code>createObject</code> 方法创建缓存数据。</p>\n<p>② <code>createObject</code> 方法的返回值中，在 <code>key</code> 前面加上了 <code>data for</code> 的字样，在实际操作中可以把这里当成获取缓存数据的方式，例如从数据库中获取。</p>\n<p>③ 在初始化缓存以后，没有像手动加载方式那样使用 <code>put</code> 方法将缓存值放入缓存，因此在运行 <code>loadingCache</code> 中的 <code>get</code> 方法获取缓存数据时，发现 <code>key</code> 对应的 <code>value</code> 为 <code>null</code>，此时会通过 <code>createObject</code> 方法获取缓存信息，也就是返回的 <code>data for cacheKey</code> 信息。</p>\n<p>同步加载会通过 <code>key</code> 获取缓存的内容，当 <code>key</code> 对应的 <code>value</code> 为空时通过指定的同步方法获取缓存内容，既然是同步，那么方法这里会一直等待，直到 <code>value</code> 返回以后，程序才往下执行。</p>\n<p>说完了同步加载，异步加载就比较好理解了，示例代码如下：</p>\n<pre class=\"code-rows\"><code>private static void asyncLoadingCache(){\n    AsyncLoadingCache&lt;String, Object&gt; asyncLoadingCache = Caffeine.newBuilder()\n        .buildAsync(key -&gt; createObject(key));\n    String key = \"cacheKey\";\n    Object object = asyncLoadingCache.get(key);\n    System.out.print(\"key=\"+key+\";value=\"+ object);\n}</code></pre>\n<p>它与同步加载的区别在于，这里是通过 <code>AsyncLoadingCache</code> 进行定义，并且使用 <code>buildAsync</code> 方法定义初始化填充方法。其他的使用方法几乎和同步加载一样。异步加载在获取值的同时，程序不会阻塞可以继续往下执行。</p>\n<p>&nbsp;</p>\n</li>\n<li><p><strong>缓存过期策略</strong></p>\n<p>由于缓存空间有大小限制，因此会为每个进入缓存的数据设置一个过期策略。对于 Caffeine 来说，有三类清除缓存的策略，分别是基于容量大小的过期策略、基于使用时长的过期策略和基于引用的过期策略。</p>\n<p>基于容量大小的过期策略，这里有两种定义方式，分别如下面的 ① 和 ② 所示：</p>\n<pre class=\"code-rows\"><code>LoadingCache&lt;String, Object&gt; loadingCache3 = Caffeine.\n    newBuilder().maximumSize(1000).build(key -&gt; createObject(key)); ①\n\nLoadingCache&lt;String, Object&gt; loadingCache4 = Caffeine.newBuilder().\n    maximumWeight(1000).weigher((key,value) -&gt; 5).\n    build(key -&gt; createObject(key));  ②</code></pre>\n<p>这里简要介绍上面的两种方式。</p>\n<p>① 通过 <code>maximumSize</code> 定义缓存能存放数据的最大个数，如果数据量超过了设置的缓存最大个数，会释放最近或者经常未使用的数据。</p>\n<p>② 定义缓存的 <code>maximumWeight</code>，表示释放缓存的最大权重。这里假设缓存数据占用的内存是不同的，可以通过 <code>weigher</code> 函数设置缓存的权重，换句话说占用不同内存大小的数据所持有的权重也不同。如果缓存中累积的权重超过 <code>maximumWeight</code>，就释放最近或者经常未使用的数据。</p>\n<p>下面的代码为了方便，将所有缓存的权重都设置为了 5，具体情况可以根据业务逻辑进行设置。</p>\n<p>基于使用时长的过期策略，使用 <code>newBuilder</code> 对缓存进行初始化：</p>\n<pre class=\"code-rows\"><code>LoadingCache&lt;String, Object&gt; loadingCache1 = Caffeine.newBuilder().\n    expireAfterAccess(10, TimeUnit.MINUTES).build(key -&gt; createObject(key));  ①\n\nLoadingCache&lt;String, Object&gt; loadingCache2 = Caffeine.newBuilder().\n    expireAfterWrite(5, TimeUnit.MINUTES).build(key -&gt; createObject(key));  ②\n\nLoadingCache&lt;String, DataObject&gt; cache = Caffeine.newBuilder().\n    expireAfter(new Expiry&lt;String, DataObject&gt;() {  ③\n      @Override\n      public long expireAfterCreate(String key, DataObject value, long currentTime) {\n          return 1000;\n      }\n      @Override\n      public long expireAfterUpdate(String key, DataObject value, long\n                                    currentTime, long currentDuration) {\n          return currentDuration;\n      }\n      @Override\n      public long expireAfterRead(String key, DataObject value, long currentTime,\n                                  long currentDuration) {\n          return currentDuration;\n      }\n}).build(k -&gt; DataObject.get(\"Data for \" + k));</code></pre>\n<p>这里简要解释上述代码的作用。</p>\n<p>① 第一个初始化使用了 <code>expireAfterAccess</code> 方法，该方法的第一个参数表示时间长度、第二个参数表达时间单位，意思是在访问缓存 10 分钟以后，该缓存过期。</p>\n<p>② 第二个初始化使用了 <code>expireAfterWrite</code> 方法，同样其第一个参数表示时间长度、第二个参数表示时间单位，意思是在写入缓存 5 分钟以后，该缓存过期。</p>\n<p>③ 第三个初始化使用了 <code>expireAfter</code> 方法，需要重写其中的 <code>expireAfterCreate</code>（创建缓存后过期）、<code>expireAfterUpdate</code>（更新缓存后过期）、<code>expireAfterRead</code>（访问缓存后过期）方法，以自定义基于使用时长的过期策略。</p>\n<p>基于引用的过期策略，这类策略是根据数据对象的引用类型来设置缓存过期策略，示例代码如下所示：</p>\n<pre class=\"code-rows\"><code>LoadingCache&lt;Key, DataObject&gt; loadingCache5 = Caffeine.newBuilder().softValues().\n    build(key -&gt; DataObject.get(\"Data for \" + key));  ①\n\nLoadingCache&lt;Key, DataObject&gt; loadingCache6 = Caffeine.newBuilder().weakKeys().\n    weakValues().build(key -&gt; DataObject.get(\"Data for \" + key));  ②</code></pre>\n<p>这里简要解释上述代码的作用。</p>\n<p>① 第一个缓存初始化方法中使用了 <code>softValues</code>，也就是“软引用”过期策略。如果一个数据对象使用了软引用，那么在内存空间足够的情况下，垃圾回收器是不会回收它的；但内存空间不足时，还是会回收该数据对象的内存。</p>\n<p>② 第二个缓存初始化方法中使用了 <code>weakKeys</code> 和 <code>weakValues</code> 方法，分别指 <code>key</code> 的弱引用和 <code>value</code> 的弱引用，也就是定义了“弱引用”过期策略。当垃圾回收器线程扫描内存时，一旦发现了使用弱引用的数据对象，无论内存空间足够与否，都会回收它的内存。</p>\n<p>&nbsp;</p>\n</li>\n<li><p><strong>缓存淘汰策略</strong></p>\n<p>由于进程内缓存占用的内存空间有限，因此会定期清除不需要的缓存。上面讲的缓存过期策略是在初始化缓存时就制定好的策略，暗含主动淘汰缓存数据的意思，那么在缓存数据并未满足过期条件的情况下，整个内存空间又不足时，Caffeine 如何淘汰缓存数据呢？意味着有些数据即便没有满足淘汰条件，也会因为内存不足而被动淘汰。</p>\n<p>实际上，Caffeine 是使用 W-TinyLFU 算法实现的缓存淘汰策略。算法中会设计一个过滤器，新加入的缓存数据只有在访问频率高的时候才能通过这个过滤器，继而被 Caffeine 缓存接纳。为避免刚进入缓存的数据由于还未被使用，因此在没有预热的情况下就被淘汰掉，Caffeine 提供了 Eden 队列（伊甸园队列），刚进入缓存的数据会被放到这里，并不会因为访问次数的问题被淘汰掉。这个队列的容量大约占整个缓存容量的 1%，特别适合秒杀场景使用。另外，还有一个队列叫作 Probation 队列，也就是“缓刑队列”，用于存放访问次数比较少的冷数据，或者说即将被淘汰的数据。除了放到这两个队列的数据，其他数据存放在 Protected 队列中，也就是“保护队列”。这里的数据暂时不会被淘汰，如果队列放满了，也会转移一些数据到 Probation 队列中，面临被淘汰的局面。不过处在 Probation 队列中的数据如果被再次访问了，就又会移回 Protected 队列。这几个队列是由 LFU 实现的，即分段（Segmented）的 LFU，也就是将实现 LFU 算法的缓存分成一段一段的。如果记得 4.2.4 节讲到的分段加锁的概念，那么这里会比较好理解。多个线程访问同一缓存数据的时候会出现锁的情况，这样会造成大量线程处于等待状态。如果将这些缓存数据分成段，那么每个线程来了以后，就可以选择锁住不同的段缓存，从而避免了等待的情况。</p>\n<p>如图 8-18 所示，新数据会被保存到 Eden 队列中，暂时不会被淘汰。这个存放是暂时的，随着 Eden 队列中数据量、访问量的增加，Caffeine 实现的 Hash 过滤器会将访问量高的那些数据升级到 Protected 队列中。这里的数据是不会被淘汰的。Eden 队列中那些依旧没有访问量的数据，会被降级到 Probation 队列中，这里的数据会被淘汰出 Caffeine 缓存。Probation 队列中的数据如果被访问了，使得访问量上升，也会被升级到 Protected 队列中。Protected 队列中的数据虽然永远不会被淘汰，但如果访问量减少，一样会被降级到 Probation 队列中。</p>\n<p class=\"p-img\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00549.jpeg\" alt=\"{%}\" /></p>\n<p class=\"ebook-image-title\"><strong>图 8-18　Caffeine 内部缓存淘汰策略的原理</strong></p>\n</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"nav_point_162\">8.1.8　分布式进程缓存</h3>\n<p>前面提到的是单机状态下的缓存访问，适用于在某个服务内部对缓存进行操作的情形。在分布式架构盛行的今天，如果在多应用特别是微服务中采用进程内缓存，就会存在数据一致性的问题。就拿订单更新服务来说，它会在订单更新完毕以后在本服务的进程内维护订单的更新信息。如果有多个订单更新服务，其中一个服务更新了订单的内容后，只能将数据缓存在本地的缓存中，该如何通知其他订单服务去更新它们本地缓存中的内容呢？</p>\n<p>这里推荐两种方案：消息队列修改方案和 Timer 修改方案。</p>\n<p>先说消息队列修改方案。由于应用程序分别部署在不同的进程或者网络节点上，彼此之间无法同步信息，因此需要通过消息队列的方式实现消息同步。一旦某个应用程序修改了缓存数据，便会通过消息队列通知其他应用程序更新缓存信息。</p>\n<p>如图 8-19 所示，最上面是消息队列，负责同步缓存信息，它下面是三个应用程序以及数据库。</p>\n<p>(1) 由于业务原因，应用程序 1 修改了本地缓存信息。</p>\n<p>(2) 应用程序 1 将此次修改同时保存到数据库中。</p>\n<p>(3) 然后将缓存信息的修改发送给消息队列。</p>\n<p>(4) 由于应用程序 2、应用程序 3 都订阅了消息队列中缓存更新的通知，因此当应用程序 1 修改缓存信息以后，应用程序 2、3 都会接收到这个通知，然后修改本地的缓存数据，从而达到缓存数据同步的目的。</p>\n<p class=\"pic\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00550.jpeg\" alt=\"\" width=\"80%\" style=\"width: 80%\" /></p>\n<p class=\"ebook-image-title\"><strong>图 8-19　消息队列修改方案简图</strong></p>\n<p>再说 Timer 修改方案。此方案适用于对实时一致性不敏感的场景，每个应用程序中都会内置一个 Timer 时钟，定时从数据库同步最新的数据信息，从而完成对缓存信息的刷新。</p>\n<p>如图 8-20 所示，存在三个应用程序，分别是应用程序 1、2、3，每个应用程序中都启动了一个 Timer 时钟，负责定时从数据库拉取最新的数据，并更新缓存。这里需要注意的是，从应用程序更新数据库，到其他节点通过 Timer 时钟获取数据这期间，用户会读到脏数据，因此使用这种方案需要控制好 Timer 的同步频率。这种方案多应用于对实时性要求不高的场景。</p>\n<p class=\"pic\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100014/image00551.jpeg\" alt=\"\" width=\"65%\" style=\"width: 65%\" /></p>\n<p class=\"ebook-image-title\"><strong>图 8-20　Timer 修改方案简图</strong></p>\n<p>缓存在分布式架构中的应用介绍完了，这里我们稍加总结。8.1 节我们按照“HTTP 缓存 → CDN 缓存 → 负载均衡缓存 → 进程内缓存 → 分布式进程缓存 → 数据库”的思路介绍了数据请求的过程。HTTP 缓存和 CDN 缓存存储的是静态数据，负载均衡缓存、进程内缓存、分布式缓存缓存的是动态数据。HTTP 缓存包括强制缓存和对比缓存；CDN 缓存和 HTTP 缓存是好搭档；负载均衡缓存中会存放变化不大的资源（用户信息），需要服务协助缓存的更新；进程内缓存虽然效率高，但受容量限制；分布式进程缓存可以通过队列和时钟的方式进行缓存同步。注意，这里没有对分布式进程缓存进行深入讲解，因为在 6.3 节已经有了详细的介绍，这里不再赘述。</p>\n","neighbors":{"left":{"article_title":"第 7 章 分布式资源管理和调度(2)","id":741060},"right":{"article_title":"第 8 章 高性能与可用性(2)","id":741062}},"comments":[]}