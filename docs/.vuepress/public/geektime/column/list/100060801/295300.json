{"id":295300,"title":"05 | 特征处理：如何利用Spark解决特征处理问题？","content":"<p>你好，我是王喆。</p><p>上节课，我们知道了推荐系统要使用的常用特征有哪些。但这些原始的特征是无法直接提供给推荐模型使用的，因为推荐模型本质上是一个函数，输入输出都是数字或数值型的向量。那么问题来了，<span class=\"orange\">像动作、喜剧、爱情、科幻这些电影风格，是怎么转换成数值供推荐模型使用的呢？用户的行为历史又是怎么转换成数值特征的呢？</span></p><p>而且，类似的特征处理过程在数据量变大之后还会变得更加复杂，因为工业界的数据集往往都是TB甚至PB规模的，这在单机上肯定是没法处理的。<span class=\"orange\">那业界又是怎样进行海量数据的特征处理呢？</span>这节课，我就带你一起来解决这几个问题。</p><h2>业界主流的大数据处理利器：Spark</h2><p>既然要处理海量数据，那选择哪个数据处理平台就是我们首先要解决的问题。如果我们随机采访几位推荐系统领域的程序员，问他们在公司用什么平台处理大数据，我想最少有一半以上会回答是Spark。作为业界主流的大数据处理利器，Spark的地位毋庸置疑。所以，今天我先带你了解一下Spark的特点，再一起来看怎么用Spark处理推荐系统的特征。</p><p>Spark是一个分布式计算平台。所谓分布式，指的是计算节点之间不共享内存，需要通过网络通信的方式交换数据。Spark最典型的应用方式就是建立在大量廉价的计算节点上，这些节点可以是廉价主机，也可以是虚拟的Docker Container（Docker容器）。</p><!-- [[[read_end]]] --><p>理解了Spark的基本概念，我们来看看它的架构。从下面Spark的架构图中我们可以看到，Spark程序由Manager Node（管理节点）进行调度组织，由Worker Node（工作节点）进行具体的计算任务执行，最终将结果返回给Drive Program（驱动程序）。在物理的Worker Node上，数据还会分为不同的partition（数据分片），可以说partition是Spark的基础数据单元。</p><p><img src=\"https://static001.geekbang.org/resource/image/4a/9b/4ae1153e4daee39985c357ed796eca9b.jpeg?wh=796*404\" alt=\"\" title=\"图1 Spark架构图\"></p><p>Spark计算集群能够比传统的单机高性能服务器具备更强大的计算能力，就是由这些成百上千，甚至达到万以上规模的工作节点并行工作带来的。</p><p>那在执行一个具体任务的时候，<strong>Spark是怎么协同这么多的工作节点，通过并行计算得出最终的结果呢？</strong>这里我们用一个任务来解释一下Spark的工作过程。</p><p>这个任务并不复杂，我们需要先从本地硬盘读取文件textFile，再从分布式文件系统HDFS读取文件hadoopFile，然后分别对它们进行处理，再把两个文件按照ID都join起来得到最终的结果。</p><p>这里你没必要执着于任务的细节，只要清楚任务的大致流程就好。在Spark平台上处理这个任务的时候，会将这个任务拆解成一个子任务DAG（Directed Acyclic Graph，有向无环图），再根据DAG决定程序各步骤执行的方法。从图2中我们可以看到，这个Spark程序分别从textFile和hadoopFile读取文件，再经过一系列map、filter等操作后进行join，最终得到了处理结果。</p><p><img src=\"https://static001.geekbang.org/resource/image/01/fd/01524cdf0ff7f64bcf86c656dd5470fd.jpeg?wh=960*316\" alt=\"\" title=\"图2 某Spark程序的任务有向无环图\"></p><p>其中，最关键的过程是我们要理解哪些是可以纯并行处理的部分，哪些是必须shuffle（混洗）和reduce的部分。</p><p>这里的shuffle指的是所有partition的数据必须进行洗牌后才能得到下一步的数据，最典型的操作就是图2中的groupByKey操作和join操作。以join操作为例，我们必须对textFile数据和hadoopFile数据做全量的匹配才可以得到join后的dataframe（Spark保存数据的结构）。而groupByKey操作则需要对数据中所有相同的key进行合并，也需要全局的shuffle才能完成。</p><p>与之相比，map、filter等操作仅需要逐条地进行数据处理和转换，不需要进行数据间的操作，因此各partition之间可以完全并行处理。</p><p>此外，在得到最终的计算结果之前，程序需要进行reduce的操作，从各partition上汇总统计结果，随着partition的数量逐渐减小，reduce操作的并行程度逐渐降低，直到将最终的计算结果汇总到master节点（主节点）上。可以说，shuffle和reduce操作的触发决定了纯并行处理阶段的边界。</p><p><img src=\"https://static001.geekbang.org/resource/image/6e/13/6e50b4010c27fac81acb0b230516e113.jpeg?wh=960*355\" alt=\"\" title=\"图3 被shuffle操作分割的DAG stages\"></p><p>最后，我还想强调的是，shuffle操作需要在不同计算节点之间进行数据交换，非常消耗计算、通信及存储资源，因此shuffle操作是spark程序应该尽量避免的。</p><p>说了这么多，这里我们再用一句话总结Spark的计算过程：<strong>Stage内部数据高效并行计算，Stage边界处进行消耗资源的shuffle操作或者最终的reduce操作</strong>。</p><p>清楚了Spark的原理，相信你已经摩拳擦掌期待将Spark应用在推荐系统的特征处理上了。下面，我们就进入实战阶段，用Spark处理我们的Sparrow Recsys项目的数据集。在开始学习之前，我希望你能带着2个问题，边学边思考：  经典的特征处理方法有什么？Spark是如何实现这些特征处理方法的？</p><h2>如何利用One-hot编码处理类别型特征</h2><p>广义上来讲，所有的特征都可以分为两大类。第一类是<strong>类别、ID型特征（以下简称类别型特征）</strong>。拿电影推荐来说，电影的风格、ID、标签、导演演员等信息，用户看过的电影ID、用户的性别、地理位置信息、当前的季节、时间（上午，下午，晚上）、天气等等，这些无法用数字表示的信息全都可以被看作是类别、ID类特征。第二类是<strong>数值型特征</strong>，能用数字直接表示的特征就是数值型特征，典型的包括用户的年龄、收入、电影的播放时长、点击量、点击率等。</p><p>我们进行特征处理的目的，是把所有的特征全部转换成一个数值型的特征向量，对于数值型特征，这个过程非常简单，直接把这个数值放到特征向量上相应的维度上就可以了。但是对于类别、ID类特征，我们应该怎么处理它们呢？</p><p>这里我们就要用到One-hot编码（也被称为独热编码），它是将类别、ID型特征转换成数值向量的一种最典型的编码方式。它通过把所有其他维度置为0，单独将当前类别或者ID对应的维度置为1的方式生成特征向量。这怎么理解呢？我们举例来说，假设某样本有三个特征，分别是星期、性别和城市，我们用 [Weekday=Tuesday, Gender=Male, City=London] 来表示，用One-hot编码对其进行数值化的结果。</p><p><img src=\"https://static001.geekbang.org/resource/image/94/15/94f78685d98671648638e330a461ab15.jpeg?wh=960*247\" alt=\"\" title=\"图4 One-hot编码特征向量\"></p><p>从图4中我们可以看到，Weekday这个特征域有7个维度，Tuesday对应第2个维度，所以我把对应维度置为1。而Gender分为Male和Female，所以对应的One-hot编码就有两个维度，City特征域同理。</p><p>除了这些类别型特征外，ID型特征也经常使用One-hot编码。比如，在我们的SparrowRecsys中，用户U观看过电影M，这个行为是一个非常重要的用户特征，那我们应该如何向量化这个行为呢？其实也是使用One-hot编码。假设，我们的电影库中一共有1000部电影，电影M的ID是310（编号从0开始），那这个行为就可以用一个1000维的向量来表示，让第310维的元素为1，其他元素都为0。</p><p>下面，我们就看看SparrowRecsys是如何利用Spark完成这一过程的。这里，我们使用Spark的机器学习库MLlib来完成One-hot特征的处理。</p><p>其中，最主要的步骤是，我们先创建一个负责One-hot编码的转换器，OneHotEncoderEstimator，然后通过它的fit函数完成指定特征的预处理，并利用transform函数将原始特征转换成One-hot特征。实现思路大体上就是这样，具体的步骤你可以参考我下面给出的源码：</p><pre><code>def oneHotEncoderExample(samples:DataFrame): Unit ={\n  //samples样本集中的每一条数据代表一部电影的信息，其中movieId为电影id\n  val samplesWithIdNumber = samples.withColumn(&quot;movieIdNumber&quot;, col(&quot;movieId&quot;).cast(sql.types.IntegerType))\n\n\n  //利用Spark的机器学习库Spark MLlib创建One-hot编码器\n  val oneHotEncoder = new OneHotEncoderEstimator()\n    .setInputCols(Array(&quot;movieIdNumber&quot;))\n    .setOutputCols(Array(&quot;movieIdVector&quot;))\n    .setDropLast(false)\n\n\n  //训练One-hot编码器，并完成从id特征到One-hot向量的转换\n  val oneHotEncoderSamples =      oneHotEncoder.fit(samplesWithIdNumber).transform(samplesWithIdNumber)\n  //打印最终样本的数据结构\n  oneHotEncoderSamples.printSchema()\n  //打印10条样本查看结果\n  oneHotEncoderSamples.show(10)\n\n_（参考 com.wzhe.sparrowrecsys.offline.spark.featureeng.FeatureEngineering__中的oneHotEncoderExample函数）_\n</code></pre><p>One-hot编码也可以自然衍生成Multi-hot编码（多热编码）。比如，对于历史行为序列类、标签特征等数据来说，用户往往会与多个物品产生交互行为，或者一个物品被打上多个标签，这时最常用的特征向量生成方式就是把其转换成Multi-hot编码。在SparrowRecsys中，因为每个电影都是有多个Genre（风格）类别的，所以我们就可以用Multi-hot编码完成标签到向量的转换。你可以自己尝试着用Spark实现该过程，也可以参考SparrowRecsys项目中 multiHotEncoderExample的实现，我就不多说啦。</p><h2>数值型特征的处理-归一化和分桶</h2><p>下面，我们再好好聊一聊数值型特征的处理。你可能会问了，数值型特征本身不就是数字吗？直接放入特征向量不就好了，为什么还要处理呢？</p><p>实际上，我们主要讨论两方面问题，一是特征的尺度，二是特征的分布。</p><p>特征的尺度问题不难理解，比如在电影推荐中有两个特征，一个是电影的评价次数fr，一个是电影的平均评分fs。评价次数其实是一个数值无上限的特征，在SparrowRecsys所用MovieLens数据集上，fr 的范围一般在[0,10000]之间。对于电影的平均评分来说，因为我们采用了5分为满分的评分，所以特征fs的取值范围在[0,5]之间。</p><p>由于fr和fs 两个特征的尺度差距太大，如果我们把特征的原始数值直接输入推荐模型，就会导致这两个特征对于模型的影响程度有显著的区别。如果模型中未做特殊处理的话，fr这个特征由于波动范围高出fs几个量级，可能会完全掩盖fs作用，这当然是我们不愿意看到的。为此我们希望把两个特征的尺度拉平到一个区域内，通常是[0,1]范围，这就是所谓<strong>归一化</strong>。</p><p>归一化虽然能够解决特征取值范围不统一的问题，但无法改变特征值的分布。比如图5就显示了Sparrow Recsys中编号在前1000的电影平均评分分布。你可以很明显地看到，由于人们打分有“中庸偏上”的倾向，因此评分大量集中在3.5的附近，而且越靠近3.5的密度越大。这对于模型学习来说也不是一个好的现象，因为特征的区分度并不高。</p><p><img src=\"https://static001.geekbang.org/resource/image/56/4e/5675f0777bd9275b5cdd8aa166cebd4e.jpeg?wh=960*540\" alt=\"\" title=\"图5 电影的平均评分分布\"></p><p>这该怎么办呢？我们经常会用分桶的方式来解决特征值分布极不均匀的问题。所谓“分桶（Bucketing）”，就是将样本按照某特征的值从高到低排序，然后按照桶的数量找到分位数，将样本分到各自的桶中，再用桶ID作为特征值。</p><p>在Spark MLlib中，分别提供了两个转换器MinMaxScaler和QuantileDiscretizer，来进行归一化和分桶的特征处理。它们的使用方法和之前介绍的OneHotEncoderEstimator一样，都是先用fit函数进行数据预处理，再用transform函数完成特征转换。下面的代码就是SparrowRecSys利用这两个转换器完成特征归一化和分桶的过程。</p><pre><code>def ratingFeatures(samples:DataFrame): Unit ={\n  samples.printSchema()\n  samples.show(10)\n\n\n  //利用打分表ratings计算电影的平均分、被打分次数等数值型特征\n  val movieFeatures = samples.groupBy(col(&quot;movieId&quot;))\n    .agg(count(lit(1)).as(&quot;ratingCount&quot;),\n      avg(col(&quot;rating&quot;)).as(&quot;avgRating&quot;),\n      variance(col(&quot;rating&quot;)).as(&quot;ratingVar&quot;))\n      .withColumn(&quot;avgRatingVec&quot;, double2vec(col(&quot;avgRating&quot;)))\n\n\n  movieFeatures.show(10)\n\n\n  //分桶处理，创建QuantileDiscretizer进行分桶，将打分次数这一特征分到100个桶中\n  val ratingCountDiscretizer = new QuantileDiscretizer()\n    .setInputCol(&quot;ratingCount&quot;)\n    .setOutputCol(&quot;ratingCountBucket&quot;)\n    .setNumBuckets(100)\n\n\n  //归一化处理，创建MinMaxScaler进行归一化，将平均得分进行归一化\n  val ratingScaler = new MinMaxScaler()\n    .setInputCol(&quot;avgRatingVec&quot;)\n    .setOutputCol(&quot;scaleAvgRating&quot;)\n\n\n  //创建一个pipeline，依次执行两个特征处理过程\n  val pipelineStage: Array[PipelineStage] = Array(ratingCountDiscretizer, ratingScaler)\n  val featurePipeline = new Pipeline().setStages(pipelineStage)\n\n\n  val movieProcessedFeatures = featurePipeline.fit(movieFeatures).transform(movieFeatures)\n  //打印最终结果\n  movieProcessedFeatures.show(\n\n_（参考 com.wzhe.sparrowrecsys.offline.spark.featureeng.FeatureEngineering中的ratingFeatures函数）_\n</code></pre><p>当然，对于数值型特征的处理方法还远不止于此，在经典的YouTube深度推荐模型中，我们就可以看到一些很有意思的处理方法。比如，在处理观看时间间隔（time since last watch）和视频曝光量（#previous impressions）这两个特征的时，YouTube模型对它们进行归一化后，又将它们各自处理成了三个特征（图6中红框内的部分），分别是原特征值x，特征值的平方<code>x^2</code>，以及特征值的开方，这又是为什么呢？</p><p><img src=\"https://static001.geekbang.org/resource/image/69/ae/69f2abc980b8d8448867b58468729eae.jpeg?wh=960*540\" alt=\"\" title=\"图6 YouTube推荐模型（来源：Deep Neural Networks for YouTube Recommendations）\"></p><p>其实，无论是平方还是开方操作，改变的还是这个特征值的分布，这些操作与分桶操作一样，都是希望通过改变特征的分布，让模型能够更好地学习到特征内包含的有价值信息。但由于我们没法通过人工的经验判断哪种特征处理方式更好，所以索性把它们都输入模型，让模型来做选择。</p><p>这里其实自然而然地引出了我们进行特征处理的一个原则，就是<strong>特征处理并没有标准答案</strong>，不存在一种特征处理方式是一定好于另一种的。在实践中，我们需要多进行一些尝试，找到那个最能够提升模型效果的一种或一组处理方式。</p><h2>小结</h2><p>这节课我们介绍了推荐系统中特征处理的主要方式，并利用Spark实践了类别型特征和数值型特征的主要处理方法，最后我们还总结出了特征处理的原则，“特征处理没有标准答案，需要根据模型效果实践出真知”。</p><p>针对特征处理的方法，深度学习和传统机器学习的区别并不大，TensorFlow、PyTorch等深度学习平台也提供了类似的特征处理函数。在今后的推荐模型章节我们会进一步用到这些方法。</p><p>最后，我把这节课的主要知识点总结成了一张表格，你可以利用它巩固今天的重点知识。</p><p><img src=\"https://static001.geekbang.org/resource/image/b3/7b/b3b8c959df72ce676ae04bd8dd987e7b.jpeg?wh=1609*660\" alt=\"\"></p><p>这节课是我们的第一堂实战课，对于还未进入到工业界的同学，相信通过这节课的实践，也能够一窥业界的大数据处理方法，增强自己的工程经验，让我们一起由此迈入工业级推荐系统的大门吧！</p><h2>课后思考</h2><ol>\n<li>\n<p>请你查阅一下Spark MLlib的编程手册，找出Normalizer、StandardScaler、RobustScaler、MinMaxScaler这个几个特征处理方法有什么不同。</p>\n</li>\n<li>\n<p>你能试着运行一下SparrowRecSys中的FeatureEngineering类，从输出的结果中找出，到底哪一列是我们处理好的One-hot特征和Multi-hot特征吗？以及这两个特征是用Spark中的什么数据结构来表示的呢？</p>\n</li>\n</ol><p>这就是我们这节课的全部内容了，你掌握得怎么样？欢迎你把这节课转发出去。下节课我们将讲解一种更高阶的特征处理方法，它同时也是深度学习知识体系中一个非常重要的部分，我们到时候见！</p>","comments":[{"had_liked":false,"id":252883,"user_name":"JustDoDT","can_delete":false,"product_type":"c1","uid":1127175,"ip_address":"","ucode":"6AF0B80F00EAEF","user_header":"https://static001.geekbang.org/account/avatar/00/11/33/07/8f351609.jpg","comment_is_top":false,"comment_ctime":1602506224,"is_pvip":false,"replies":[{"id":"92474","content":"非常棒，推荐其他同学参考。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1602634059,"ip_address":"","comment_id":252883,"utype":1}],"discussion_count":5,"race_medal":0,"score":"306545184240","product_id":100060801,"comment_content":"Normalizer、StandardScaler、RobustScaler、MinMaxScaler 都是用让数据无量纲化<br>Normalizer:  正则化；（和Python的sklearn一样是按行处理，而不是按列[每一列是一个特征]处理，原因是：Normalization主要思想是对每个样本计算其p-范数，然后对该样本中每个元素除以该范数，这样处理的结果是使得每个处理后样本的p-范数(l1-norm,l2-norm)等于1。）针对每行样本向量：l1: 每个元素&#47;样本中每个元素绝对值的和，l2: 每个元素&#47;样本中每个元素的平方和开根号，lp: 每个元素&#47;每个元素的p次方和的p次根，默认用l2范数。<br><br>StandardScaler：数据标准化；(xi - u) &#47; σ 【u:均值，σ：方差】当数据(x)按均值(μ)中心化后，再按标准差(σ)缩放，数据就会服从为均值为0，方差为1的正态分布（即标准正态分布）。<br><br>RobustScaler: (xi - median) &#47; IQR 【median是样本的中位数，IQR是样本的 四分位距：根据第1个四分位数和第3个四分位数之间的范围来缩放数据】<br><br>MinMaxScaler：数据归一化，(xi - min(x)) &#47; (max(x) - min(x)) ;当数据(x)按照最小值中心化后，再按极差（最大值 - 最小值）缩放，数据移动了最小值个单位，并且会被收敛到 [0,1]之间<br>","like_count":72,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":506906,"discussion_content":"非常棒，推荐其他同学参考。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1602634059,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2146907,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/qLpWmAg6TR6GgXQ3x5345k2eJsOdsJibYYjxbPtcHlfYSdG5qT1qR72BYzxXWvJuxicPG2lH92ynGfpVtdz5IjjA/132","nickname":"InfoQ_ea311a6b3a82","note":"","ucode":"7D63ABB5C708B8","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":318593,"discussion_content":"层主总结的很好！\n不过第一点Normalizer可以按行也可以按列，例如\nfrom sklearn import preprocessing\n# 默认l2标准化，每个数据的特征平方加和为1\nnormalized_X = preprocessing.normalize(X,norm=&#39;l2&#39;,axis=0) \n#0是按行，1是按列","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1603788691,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1127175,"avatar":"https://static001.geekbang.org/account/avatar/00/11/33/07/8f351609.jpg","nickname":"JustDoDT","note":"","ucode":"6AF0B80F00EAEF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2146907,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/qLpWmAg6TR6GgXQ3x5345k2eJsOdsJibYYjxbPtcHlfYSdG5qT1qR72BYzxXWvJuxicPG2lH92ynGfpVtdz5IjjA/132","nickname":"InfoQ_ea311a6b3a82","note":"","ucode":"7D63ABB5C708B8","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":318688,"discussion_content":"思想是处理一个样本，而不是一个特征所有数据。行业惯例一行一个样本。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1603807710,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":318593,"ip_address":""},"score":318688,"extra":""}]},{"author":{"id":1952248,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/c9/f8/72955ef9.jpg","nickname":"浣熊当家","note":"","ucode":"939F06050423E4","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":312773,"discussion_content":"Normalizer是按行处理，这一点提示的太棒了！感谢","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1602812741,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2547252,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/rVPgtbGVJZGIpfvOUjVaMYoo5gMuMxxHouMxbdbgAgqhd5LGmgEqIupOtBjXCpCnM9IsTYzAorupGztgsN9TBg/132","nickname":"Geek_dadc1e","note":"","ucode":"D8ED870453C301","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":545966,"discussion_content":"https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-scaler","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1642112455,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":253705,"user_name":"李@君","can_delete":false,"product_type":"c1","uid":2111369,"ip_address":"","ucode":"B077098687B4F4","user_header":"","comment_is_top":false,"comment_ctime":1602837008,"is_pvip":false,"replies":[{"id":"92701","content":"这是个好问题。但不应该这样理解，本质上是改变了特征的分布，特征的分布和训练数据的分布没有本质的联系。只要你不改变训练数据label的分布，最终预测出的结果都应该是符合数据本身分布的。因为你要预测的是label，并不是特征本身。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1602871666,"ip_address":"","comment_id":253705,"utype":1}],"discussion_count":4,"race_medal":0,"score":"96092117520","product_id":100060801,"comment_content":"对训练数据进行平方或者开方，是为了改变训练数据的分布。训练数据的分布被改变后，训练出来的模型岂不是不能正确拟合训练数据了。","like_count":23,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":507151,"discussion_content":"这是个好问题。但不应该这样理解，本质上是改变了特征的分布，特征的分布和训练数据的分布没有本质的联系。只要你不改变训练数据label的分布，最终预测出的结果都应该是符合数据本身分布的。因为你要预测的是label，并不是特征本身。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1602871666,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3186244,"avatar":"https://static001.geekbang.org/account/avatar/00/30/9e/44/b9d6a4a9.jpg","nickname":"JohnH","note":"","ucode":"E1BADF7024FC2B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":589478,"discussion_content":"这一步应该是basis function expansion (BFE)，在机器学习里面常用为特征扩张的吗？仅仅是对特征的维度进行了增广（或许能从新的扩张特征中学到有用的东西，这一点或许可以用feature selection或者dimensional reduction进行进一步筛选），对标签值是没有影响的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1665032083,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"美国"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2056623,"avatar":"https://static001.geekbang.org/account/avatar/00/1f/61/af/910f3111.jpg","nickname":"tt","note":"","ucode":"64DE06A3862C31","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":409183,"discussion_content":"想问下，对正负样本按比例采样，算不算改变数据集label整体分布~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1635389066,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":2989808,"avatar":"https://static001.geekbang.org/account/avatar/00/2d/9e/f0/67f85991.jpg","nickname":"🍉 静","note":"","ucode":"E3881B06E91CEE","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2056623,"avatar":"https://static001.geekbang.org/account/avatar/00/1f/61/af/910f3111.jpg","nickname":"tt","note":"","ucode":"64DE06A3862C31","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":576165,"discussion_content":"抽样没有改变label的整体分布","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1655316002,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":409183,"ip_address":""},"score":576165,"extra":""}]}]},{"had_liked":false,"id":274250,"user_name":"小强","can_delete":false,"product_type":"c1","uid":2398148,"ip_address":"","ucode":"C3D1215867302D","user_header":"https://static001.geekbang.org/account/avatar/00/24/97/c4/6c92c78a.jpg","comment_is_top":false,"comment_ctime":1610940293,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"91805253509","product_id":100060801,"comment_content":"OneHotEncoderEstimator() 在PySpark 3.0.0及以上版本已经更改为 OneHotEncoder()","like_count":22},{"had_liked":false,"id":252738,"user_name":"JustDoDT","can_delete":false,"product_type":"c1","uid":1127175,"ip_address":"","ucode":"6AF0B80F00EAEF","user_header":"https://static001.geekbang.org/account/avatar/00/11/33/07/8f351609.jpg","comment_is_top":false,"comment_ctime":1602472364,"is_pvip":false,"replies":[{"id":"92309","content":"不错的文章，也推荐大家学习。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1602485659,"ip_address":"","comment_id":252738,"utype":1}],"discussion_count":3,"race_medal":0,"score":"70321949100","product_id":100060801,"comment_content":"Multiple编码<br>顾名思义，Multiple编码特征将多个属性同时编码到一个特征中。在推荐场景中，单个用户对哪些物品感兴趣的特征就是一种Multiple编码特征，如，表示某用户对产品1、产品2、产品3、产品4是否感兴趣，则这个特征可能有多个取值，如用户A对产品1和产品2感兴趣，用户B对产品1和产品4感兴趣，用户C对产品1、产品3和产品4感兴趣，则用户兴趣特征为<br>用户\tUserInterests<br>A\t[1, 2]<br>B\t[1, 4]<br>C\t[1, 3, 4]<br><br>Multiple编码采用类似oneHot编码的形式进行编码，根据物品种类数目，展成物品种类数目大小的向量，当某个用户感兴趣时，对应维度为1，反之为0，如下<br>用户\tUserInterests<br>A\t[1, 1, 0, 0]<br>B\t[1, 0, 0, 1]<br>C\t[1, 0, 1, 1]<br><br>如何使用Multiple编码呢？<br>我们将多个属性同时编码到同一个特征中，目的就是同时利用多个属性的特征。经过Multiple编码后的特征大小为[batch_size, num_items]，记作U，构建物品items的Embedding矩阵，该矩阵维度为[num_items, embedding_size]，记作V，将矩阵U和矩阵V相乘，我们就得到了大小为[batch_size， embedding_size]的多属性表示。<br>参考资料：https:&#47;&#47;www.codeleading.com&#47;article&#47;97252516619&#47;#_OneHot_19","like_count":16,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":506855,"discussion_content":"不错的文章，也推荐大家学习。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1602485659,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2338426,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eqlGaOqz0NBjhk0VfOx1AAG7k5tqyicuw6sJGcWostrOiaf34wPedm8rIIzrNjPHkBJLG7GboLaNurw/132","nickname":"Geek_55eaf9","note":"","ucode":"3409B413A95188","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":333578,"discussion_content":"问下，对于Multiple的emb向量，一般是不是用avg/max之类的操作把多个emb合成一个emb向量呢","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1607568589,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1362648,"avatar":"https://static001.geekbang.org/account/avatar/00/14/ca/d8/767d8e6e.jpg","nickname":"强者自强","note":"","ucode":"391B934CC10342","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":346499,"discussion_content":"你好，对于batch_size和num_items的大小可以详细说一下吗，谢谢~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1611974813,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":260339,"user_name":"twzd","can_delete":false,"product_type":"c1","uid":1008973,"ip_address":"","ucode":"93341A57D39184","user_header":"https://static001.geekbang.org/account/avatar/00/0f/65/4d/06bf7890.jpg","comment_is_top":false,"comment_ctime":1604987633,"is_pvip":false,"replies":[{"id":"94626","content":"这是一个稀疏向量表示，1001维，第1维的值为1.0","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1605078871,"ip_address":"","comment_id":260339,"utype":1}],"discussion_count":1,"race_medal":0,"score":"44554660593","product_id":100060801,"comment_content":"老师请教一下，movieIdVector列输出结果中(1001,[1],[1.0])，每一列表示什么含义啊","like_count":10,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509172,"discussion_content":"这是一个稀疏向量表示，1001维，第1维的值为1.0","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605078871,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":266153,"user_name":"Geek_ddf8b1","can_delete":false,"product_type":"c1","uid":2309043,"ip_address":"","ucode":"70E1BB4C1CC6C4","user_header":"","comment_is_top":false,"comment_ctime":1607218880,"is_pvip":false,"replies":[{"id":"96780","content":"你好，其实你提的不是问题，提的是自己的思考，我觉得都非常好，他们确实都是我们在实际工作中需要解决的问题。<br>这些问题没有什么所谓答案，自己去思考，自己去尝试就好了。<br><br>我自己的经验是存onehot和muilthot的index，存储结构用protobuf。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1607389709,"ip_address":"","comment_id":266153,"utype":1}],"discussion_count":1,"race_medal":0,"score":"35966957248","product_id":100060801,"comment_content":"老师 我看您FeatureEngForRecModel.scala代码中将特征写入redis是以哈希表的格式写入的，而且有些特征直接是类别型的文本数据。 <br>       这种方式线上读取特征再后续处理输入排序模型预估的时候会不会效率很低，预估打分时间较长？比如取出文本特征做onehot 或者multihot变换等等，是否可以将文本特征onehot 或者multihot处理后再写入redis？ <br>     还有特征除了以hash表形式还可以以其它数据结构存到redis，比如以probuf对象、libsvm数据格式的特征索引：特征值的字符串存到redis 您对这几种存储方式怎么看？哪种更好？","like_count":9,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":511164,"discussion_content":"你好，其实你提的不是问题，提的是自己的思考，我觉得都非常好，他们确实都是我们在实际工作中需要解决的问题。\n这些问题没有什么所谓答案，自己去思考，自己去尝试就好了。\n\n我自己的经验是存onehot和muilthot的index，存储结构用protobuf。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1607389709,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":253231,"user_name":"张弛 Conor","can_delete":false,"product_type":"c1","uid":2208459,"ip_address":"","ucode":"193EBA4A64BAB3","user_header":"https://static001.geekbang.org/account/avatar/00/21/b2/cb/9c6c7bf7.jpg","comment_is_top":false,"comment_ctime":1602657808,"is_pvip":false,"replies":[{"id":"92640","content":"其实不建议这种离散数值，取值数量有比较少的特征进行分桶操作。把相同分值强制分到两个桶里，不仅没有意义，而且引入噪声。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1602827189,"ip_address":"","comment_id":253231,"utype":1}],"discussion_count":2,"race_medal":0,"score":"23077494288","product_id":100060801,"comment_content":"请教老师，像在电影评分这样的离散数值(且比较稀疏)例子中，如果需要取得分桶数较多，而导致分位数附近均是同一数值的情况下，如何使用分桶的方法呢？<br>比如按照分桶法首先排序得到评分为5,5,4,4,4,4,4,4,3,3,3,3,2,2,1(共15个)。取桶数为3时，第一个桶内有前两个5，而后面的6个4中应该选择哪3个来分到第一个桶呢？","like_count":6,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":507012,"discussion_content":"其实不建议这种离散数值，取值数量有比较少的特征进行分桶操作。把相同分值强制分到两个桶里，不仅没有意义，而且引入噪声。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1602827189,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2527743,"avatar":"https://static001.geekbang.org/account/avatar/00/26/91/ff/aa5e573a.jpg","nickname":"牛牪犇","note":"","ucode":"007A5E511EA243","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":359230,"discussion_content":"确实，这种稀疏的数值，如果是无尺度（无大小之分），那可以用onehot编码，如果有尺度，还不如直接使用，分桶这种变换还是针对连续型的数值变量","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1616146516,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":289976,"user_name":"Yvonne","can_delete":false,"product_type":"c1","uid":2577469,"ip_address":"","ucode":"85287A0AC7456C","user_header":"https://static001.geekbang.org/account/avatar/00/27/54/3d/366462d0.jpg","comment_is_top":false,"comment_ctime":1619292573,"is_pvip":false,"replies":[{"id":"105185","content":"赞","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1619411726,"ip_address":"","comment_id":289976,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14504194461","product_id":100060801,"comment_content":"谢谢老师！在读youtube论文的时候，当时没有特别理解为什么要将原值，开方，平方都放进去，解释是：In addition to the raw normalized feature ˜x, we also input powers ˜x2 and √x˜, giving the network more expressive power by allowing it to easily form super- and sub-linear functions of the feature. Feeding powers of continuous features was found to improve offline accuracy.…… 当时没能理解为什么。您提到可以用于改变分布特征，突然就理解了XD","like_count":3,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":519079,"discussion_content":"赞","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1619411726,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":275360,"user_name":"Capricornus","can_delete":false,"product_type":"c1","uid":2371321,"ip_address":"","ucode":"B7B15C58653860","user_header":"https://static001.geekbang.org/account/avatar/00/24/2e/f9/c0a6232c.jpg","comment_is_top":false,"comment_ctime":1611488261,"is_pvip":false,"replies":[{"id":"99965","content":"这个可否自己研究一下？","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1611551194,"ip_address":"","comment_id":275360,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14496390149","product_id":100060801,"comment_content":"+-------+-----------+-----------------+<br>|movieId|ratingCount|ratingCountBucket|<br>+-------+-----------+-----------------+<br>|    296|      14616|             13.0|<br>|    356|      14426|             12.0|<br>|    318|      13826|             12.0|<br>|    593|      13692|             12.0|<br>|    480|      13033|             12.0|<br>|    260|      11958|             12.0|<br>|    110|      11637|             12.0|<br>|    589|      11483|             12.0|<br>|    527|      11017|             12.0|<br>|      1|      10759|             12.0|<br>|    457|      10736|             12.0|<br>|    150|      10324|             12.0|<br>|    780|      10271|             12.0|<br>|     50|      10221|             12.0|<br>|    592|      10028|             12.0|<br>|     32|       9694|             12.0|<br>|    608|       9505|             12.0|<br>|    590|       9497|             12.0|<br>|    380|       9364|             12.0|<br>|     47|       9335|             12.0|<br>+-------+-----------+-----------------+<br>老师我设置的分桶数是20，为什么最大的桶标号不是19啊？","like_count":3,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":514323,"discussion_content":"这个可否自己研究一下？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1611551194,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":271900,"user_name":"Capricornus","can_delete":false,"product_type":"c1","uid":2371321,"ip_address":"","ucode":"B7B15C58653860","user_header":"https://static001.geekbang.org/account/avatar/00/24/2e/f9/c0a6232c.jpg","comment_is_top":false,"comment_ctime":1609855715,"is_pvip":false,"replies":[{"id":"98599","content":"赞，使用spark3.0的同学可以参考","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1609870848,"ip_address":"","comment_id":271900,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14494757603","product_id":100060801,"comment_content":"我使用的spark3.0的环境，脱离老师的项目，单独建立的用来学习。<br>1. 下载Scala支持，[下载链接](https:&#47;&#47;www.scala-lang.org&#47;download&#47;2.12.12.html)<br>2. 解压后放在指定的目录<br>    ```bash<br>    vi ~&#47;.bash_profile<br>    export PATH=&quot;$PATH:&#47;Library&#47;Scala&#47;scala-2.12.12&#47;bin&quot;<br>    ```<br>3. 在IDEA的项目中引入，点击“+”号，根据路径添加<br>4. 右键项目的目录，添加框架支持<br>5. 添加IDEA的插件，preferences中<br><br><br>6. porm.xml的环境依赖<br><br>    ```xml<br>    &lt;dependencies&gt;<br>    &lt;dependency&gt;<br>        &lt;groupId&gt;org.apache.spark&lt;&#47;groupId&gt;<br>        &lt;artifactId&gt;spark-core_2.12&lt;&#47;artifactId&gt;<br>        &lt;version&gt;3.0.0&lt;&#47;version&gt;<br>    &lt;&#47;dependency&gt;<br>    &lt;dependency&gt;<br>        &lt;groupId&gt;org.apache.spark&lt;&#47;groupId&gt;<br>        &lt;artifactId&gt;spark-mllib_2.12&lt;&#47;artifactId&gt;<br>        &lt;version&gt;3.0.0&lt;&#47;version&gt;<br>    &lt;&#47;dependency&gt;<br>    &lt;dependency&gt;<br>        &lt;groupId&gt;org.apache.spark&lt;&#47;groupId&gt;<br>        &lt;artifactId&gt;spark-sql_2.12&lt;&#47;artifactId&gt;<br>        &lt;version&gt;3.0.0&lt;&#47;version&gt;<br>    &lt;&#47;dependency&gt;<br>    &lt;&#47;dependencies&gt;<br>    ```<br>    **注意：路径中不要包括中文，否则可能会出现路径不存在的问题。**<br><br>然后有两处需要更改<br>    val oneHotEncoder = new OneHotEncoder()<br>      .setInputCols(Array(&quot;movieIdNumber&quot;))<br>      .setOutputCols(Array(&quot;movieIdVector&quot;))<br>      .setDropLast(false)<br>&#47;&#47; 官网的说法：OneHotEncoder which is deprecated in 2.3,is removed in 3.0 and OneHotEncoderEstimator is now renamed to OneHotEncoder.<br><br>    val movieFeatures = samples.groupBy(col(&quot;movieId&quot;))<br>      .agg(count(lit(1)).as(&quot;ratingCount&quot;),<br>        avg(col(&quot;rating&quot;)).as(&quot;avgRating&quot;),<br>        functions.variance(col(&quot;rating&quot;)).as(&quot;ratingVar&quot;))<br>      .withColumn(&quot;avgRatingVec&quot;, double2vec(col(&quot;avgRating&quot;)))","like_count":4,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":513088,"discussion_content":"赞，使用spark3.0的同学可以参考","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1609870848,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":265758,"user_name":"神经蛙","can_delete":false,"product_type":"c1","uid":2242137,"ip_address":"","ucode":"9375BA98E03A8D","user_header":"https://static001.geekbang.org/account/avatar/00/22/36/59/010b3e60.jpg","comment_is_top":false,"comment_ctime":1607003980,"is_pvip":false,"replies":[{"id":"96580","content":"总结的好，赞","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1607019705,"ip_address":"","comment_id":265758,"utype":1}],"discussion_count":2,"race_medal":0,"score":"14491905868","product_id":100060801,"comment_content":"--- 看了几位同学的留言，受益匪浅啊。希望大家多多交流~<br><br>1.请你查阅一下 Spark MLlib 的编程手册，找出 Normalizer、StandardScaler、RobustScaler、MinMaxScaler 这个几个特征处理方法有什么不同。<br><br>Normalizer<br>是规范化，根据所传的p值，做p范数归一化(默认p=2)。它是作用在每个样本的向量内部的。无需训练。<br>eg:x:[v1,v2,v3],p1=sum(abs(vi)), 经过normalizer, x:[v1&#47;p1,v2&#47;p1,v3&#47;p1]<br><br>StandardScaler<br>标准化，将样本的每个特征的标准差变为1.或者可以设置将均值变换为0(默认setMean是False)。这里计算标准差（计算均值）是样本集的每个维度单独计算。所以需要fit操作。计算后保存每个样本标准差、均值后。对每个样本第i个维度除以第i个维度的标准差（如此计算后,该维度均值也会自动被除以标准差，经过标准差公式，则新的标准差为1）。如果setMean == True, 则在变幻是需要先减去均值之后再除以标准差。<br><br>RobustScaler<br>我看spark3才有,具体没弄出来,看文档大概意思是将数据变换到1&#47;4~3&#47;4分为之间。好像是让数据变得稠密了。<br><br>MinMaxScaler<br>将数据变为到[0,1]之间，也需要训练，得到每个维度的最大最小值。然后变化Y= (X-X_min)&#47;(X_max-X_min)<br><br><br>2.你能试着运行一下 SparrowRecSys 中的 FeatureEngineering 类，从输出的结果中找出，到底哪一列是我们处理好的 One-hot 特征和 Multi-hot 特征吗？以及这两个特征是用 Spark 中的什么数据结构来表示的呢？<br><br>处理好的One-hot特征<br>movieIdVector<br><br>处理好的Multi-hot特征<br>vector<br><br>数据结构：<br>SparseVector<br><br>其中的数据分别是：（类别数量，索引数组，值数组）。索引数组长度必须等于值数组长度。 ","like_count":3,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":511033,"discussion_content":"总结的好，赞","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1607019705,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1461122,"avatar":"https://static001.geekbang.org/account/avatar/00/16/4b/82/5be29abf.jpg","nickname":"老叔叔安森","note":"","ucode":"EF61ACAC9A44FE","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":377271,"discussion_content":"老师，值数组什么作用","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1622565044,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":253717,"user_name":"fsc2016","can_delete":false,"product_type":"c1","uid":1255585,"ip_address":"","ucode":"5480F05703A974","user_header":"https://static001.geekbang.org/account/avatar/00/13/28/a1/fd2bfc25.jpg","comment_is_top":false,"comment_ctime":1602842023,"is_pvip":false,"replies":[{"id":"92702","content":"非常好。比之前的回答更准确一些，推荐大家参考。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1602871688,"ip_address":"","comment_id":253717,"utype":1}],"discussion_count":2,"race_medal":0,"score":"14487743911","product_id":100060801,"comment_content":"第二个问题：<br>One-hot特征是调用OneHotEncoderEstimator对movieId转换，生成了特征movieIdVector<br>Multi-hot 特征是调用Vectors.sparse方法，对处理后的genreIndexes转换，生成vector。<br>这俩个特征都是稀疏向量表示，不是稠密向量<br>","like_count":3,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":507155,"discussion_content":"非常好。比之前的回答更准确一些，推荐大家参考。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1602871688,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1461122,"avatar":"https://static001.geekbang.org/account/avatar/00/16/4b/82/5be29abf.jpg","nickname":"老叔叔安森","note":"","ucode":"EF61ACAC9A44FE","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":377269,"discussion_content":"评分数据才是dense","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1622564741,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":253694,"user_name":"杨佳亦","can_delete":false,"product_type":"c1","uid":2046547,"ip_address":"","ucode":"D2009DAC396F25","user_header":"https://static001.geekbang.org/account/avatar/00/1f/3a/53/ec2c6c55.jpg","comment_is_top":false,"comment_ctime":1602834144,"is_pvip":false,"replies":[{"id":"92700","content":"非常详细了，也推荐在spark中自己进行实践。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1602871553,"ip_address":"","comment_id":253694,"utype":1}],"discussion_count":2,"race_medal":0,"score":"14487736032","product_id":100060801,"comment_content":"MinMaxScaler: <br>记录数据整体的最大&#47;最小值为max&#47;min, 对于Feature E，若Emax!=Emin, 则rescale后值=(Ei - Emin) &#47; (Emax - Emin) * (max - min) + min. 若Emax == Emin, 则rescale后值=0.5*(min + max). <br><br>Normalizer: <br>参考了其他留言才看懂了：这步做的是正则化。正则化将向量的范数缩放到单位1，即可对「样本」也可对「特征」，此处是对样本的正则化，即求样本在所有特征下的取值的P范数(l1, l2). 用通俗的话解释，l1范数计算的是每个元素在同一样本的所有特征取值之和下占的比例，l2范数计算的是每个元素与P维空间中欧氏距离的比值。<br><br>StandardScaler: <br>常用的数据标准化方法，即计算样本在所有特征下的均值和标准差，用数据减均值以中心化，再除以标准差以缩放至单位1. 就是一个把分布未知（通常情况下）的数据拉回到正态分布的函数。<br><br>RobustScaler：<br>新学到的一个方法，之前没用过。和minmaxScaler类似，即使用大、小值进行数据的缩放。具体为(x - median) &#47; (localUpper - localLower). 其中的localLower, median, localUpper分别为数据的第一、二、三分位点。名字中带有robust，是强调用四分位点而非最大最小值等极端值可以加强模型对噪音的抗干扰力。","like_count":3,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":507147,"discussion_content":"非常详细了，也推荐在spark中自己进行实践。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1602871553,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1127918,"avatar":"https://static001.geekbang.org/account/avatar/00/11/35/ee/8ead7a82.jpg","nickname":"176474441","note":"","ucode":"D36BBC03D12EAF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":332673,"discussion_content":"怎么实践呢？是查看哪个sparrow代码的相应模块吗？我不知道如何下手？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1607305385,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":284505,"user_name":"海滨","can_delete":false,"product_type":"c1","uid":1009518,"ip_address":"","ucode":"F1B94D2DB944DC","user_header":"https://static001.geekbang.org/account/avatar/00/0f/67/6e/f5ee46e8.jpg","comment_is_top":false,"comment_ctime":1616310316,"is_pvip":true,"replies":[{"id":"103429","content":"正确，赞。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1616637561,"ip_address":"","comment_id":284505,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10206244908","product_id":100060801,"comment_content":"Normalizer，是范式归一化操作，保证归一化之后范式为1<br>StandardScaler，是标准差归一化操作，保证归一化之后均值为0标准差为1<br>RobustScaler，是使用分位数进行鲁棒归一化操作，可以有效减少异常值的干扰<br>MinMaxScaler，是使用最大值和最小值进行归一化操作","like_count":2,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":517370,"discussion_content":"正确，赞。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616637561,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":258365,"user_name":"清晨","can_delete":false,"product_type":"c1","uid":1323691,"ip_address":"","ucode":"37545CE235F2E8","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/ye1IU6yGTuKULCqUlNoDCqvRwQ3FbLJHuBNw6l0lTicz4h9IUDH4JOSPyH2KsKzAEqznhdO29JB4OsibEdUjxl2Q/132","comment_is_top":false,"comment_ctime":1604398346,"is_pvip":false,"replies":[{"id":"94117","content":"改变的是特征的分布，为了让特征的区分度更高，让模型更好的捕捉特征中包含的有价值信息。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1604464342,"ip_address":"","comment_id":258365,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10194332938","product_id":100060801,"comment_content":"standscalar 不是改变了数据的分布吗 处理后的特征为均值为0，方差为1 为什么说没有呢？","like_count":2,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":508634,"discussion_content":"改变的是特征的分布，为了让特征的区分度更高，让模型更好的捕捉特征中包含的有价值信息。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1604464342,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":252818,"user_name":"smjccj","can_delete":false,"product_type":"c1","uid":1802329,"ip_address":"","ucode":"F1970D00C8E3B1","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/GomQuKMYYNX7aMCNt4Ut8YyBrzVM71fgly5l1jykTFic8iaqCTG5ELnsIqlhwgG7ibCCxpODn6PzfVaSicrDub6t5Q/132","comment_is_top":false,"comment_ctime":1602493696,"is_pvip":false,"replies":[{"id":"92478","content":"赞","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1602634230,"ip_address":"","comment_id":252818,"utype":1}],"discussion_count":2,"race_medal":0,"score":"10192428288","product_id":100060801,"comment_content":"Normalizer： 转化为方差为1，不影响数据分布<br>StandardScaler： 将数据转化为 variance= 1，mean =0(unit variance and&#47;or zero mean)<br>RobustScaler： 中位数或四分位数进行缩放，处理异常值带来的影响<br>MinMaxScaler: 将特征缩放至0-1之间","like_count":2,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":506881,"discussion_content":"赞","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1602634230,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2527743,"avatar":"https://static001.geekbang.org/account/avatar/00/26/91/ff/aa5e573a.jpg","nickname":"牛牪犇","note":"","ucode":"007A5E511EA243","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":359238,"discussion_content":"觉得mormalizer还是改变了特征(纵向)的分布，除非横向向量的模都一样，但实际中每行的除数不完全一样","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1616147722,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":326923,"user_name":"LEIBER","can_delete":false,"product_type":"c1","uid":2836458,"ip_address":"","ucode":"6310F3F6DF3295","user_header":"https://static001.geekbang.org/account/avatar/00/2b/47/ea/d2924633.jpg","comment_is_top":false,"comment_ctime":1639753225,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5934720521","product_id":100060801,"comment_content":"理论部分都懂，看代码就懵了，没学过scala，也不了解环境应该怎么配","like_count":1},{"had_liked":false,"id":291536,"user_name":"liput","can_delete":false,"product_type":"c1","uid":1057683,"ip_address":"","ucode":"CCCF7D7D17C870","user_header":"https://static001.geekbang.org/account/avatar/00/10/23/93/d6cd8897.jpg","comment_is_top":false,"comment_ctime":1620352775,"is_pvip":false,"replies":[{"id":"105682","content":"现在特征更新一般都会放在流平台上，基本保证online和offline一致。<br><br>在离线训练阶段，如果无法复用online计算特征的代码的话，也一定要保证二者的逻辑是一样的。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1620582675,"ip_address":"","comment_id":291536,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5915320071","product_id":100060801,"comment_content":"请问老师，看到课程里面特征构造都是在offline批量计算得到特征，而在online再另外计算特征，这里经常会出现不一致的情况。想问下，在工业实践中，有什么好的方法去保证这两个地方的一致性呢？","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":519500,"discussion_content":"现在特征更新一般都会放在流平台上，基本保证online和offline一致。\n\n在离线训练阶段，如果无法复用online计算特征的代码的话，也一定要保证二者的逻辑是一样的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1620582675,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1206147,"avatar":"https://static001.geekbang.org/account/avatar/00/12/67/83/2150e0e0.jpg","nickname":"longhx","note":"","ucode":"581A3BD20D7A04","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":380920,"discussion_content":"为什么特征更新放在流平台上，基本保证online和offline一致了？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1624795335,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":290424,"user_name":"diu你头发掉屏幕上了","can_delete":false,"product_type":"c1","uid":2131165,"ip_address":"","ucode":"69E2D5EAD8B50C","user_header":"https://static001.geekbang.org/account/avatar/00/20/84/dd/a9265141.jpg","comment_is_top":false,"comment_ctime":1619535834,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"5914503130","product_id":100060801,"comment_content":"为什么运行FeatureEngineering.scala是正常的，运行FeatureEngineering.py从显示MultiHotEncoder的时候就开始报错了，说python worker failed to connect back.","like_count":1,"discussions":[{"author":{"id":2660352,"avatar":"https://static001.geekbang.org/account/avatar/00/28/98/00/dfb9251d.jpg","nickname":"村口王师傅","note":"","ucode":"F9B84DF46C6224","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":386723,"discussion_content":"请问有解决吗","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627743745,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2615846,"avatar":"https://static001.geekbang.org/account/avatar/00/27/ea/26/e9ad3982.jpg","nickname":"zhy","note":"","ucode":"139912B4799EA6","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":373510,"discussion_content":"同问","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1620751008,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":284100,"user_name":"Geek_71fed1","can_delete":false,"product_type":"c1","uid":2527569,"ip_address":"","ucode":"526351F33FADC9","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/5EgbE7BFRtWHIchE5eCoaXFX4RWxg3iblIbC8G9X2cV4sYlW9qCib1sMiaJusda6p3L5UUq8aoUfOPU1QSia7caibqA/132","comment_is_top":false,"comment_ctime":1616063519,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5911030815","product_id":100060801,"comment_content":"pyspark的实现<br>def oneHotEncoderExample(samples):<br>    #使用WithColumn可以为DataFrame增加新列<br>    #cast强制类型转换<br>    samplesWithIdNumber = samples.withColumn(&quot;movieIdNumber&quot;,col(&quot;movieId&quot;).cast(&quot;int&quot;))<br>    #创建onehot编码器<br>    oneHotEncoder1 = OneHotEncoder().setInputCol(&quot;movieIdNumber&quot;).setOutputCol(&quot;movieIdVector&quot;).setDropLast(False)<br>    #训练onehot编码器，，transform转换<br>    oneHotEncoderSamples= oneHotEncoder1.transform(samplesWithIdNumber)<br>    #打印数据结构<br>    oneHotEncoderSamples.printSchema()<br>    oneHotEncoderSamples.show(10)<br><br><br>double2vec= udf(lambda value:Vectors.dense(value),VectorUDT())<br><br>def ratingFeatures(samples):<br>    #samples.printSchema()<br>    #samples.show()<br>    #计算数值特征<br>    movieFeatures = samples.groupBy(col(&quot;movieId&quot;)).\\<br>      agg(count(lit(1)).alias(&quot;ratingCount&quot;),\\<br>        avg(col(&quot;rating&quot;)).alias(&quot;avgRating&quot;),\\<br>        variance(col(&quot;rating&quot;)).alias(&quot;ratingVar&quot;)).\\<br>        withColumn(&quot;avgRatingVec&quot;, double2vec(col(&quot;avgRating&quot;)))<br>    #movieFeatures.show()<br>    <br>    #分桶<br>    ratignCountDiscretizer = QuantileDiscretizer().setNumBuckets(100).setInputCol(&quot;ratingCount&quot;).setOutputCol(&quot;ratingCountBucket&quot;)<br>    #归一化<br>    ratingScaler = MinMaxScaler().setMin(5).setMax(10).setInputCol(&quot;avgRatingVec&quot;).setOutputCol(&quot;scaleAvgRating&quot;)<br>    <br>    piplinestage=[ratignCountDiscretizer,ratingScaler]<br>    featurpipeline = Pipeline().setStages(piplinestage)<br>    movieProcessedFeatures=featurpipeline.fit(movieFeatures).transform(movieFeatures)<br>    movieProcessedFeatures.show(10)","like_count":1},{"had_liked":false,"id":280881,"user_name":"陈威洋","can_delete":false,"product_type":"c1","uid":2264679,"ip_address":"","ucode":"DCF84B4D3A7354","user_header":"https://static001.geekbang.org/account/avatar/00/22/8e/67/afb412fb.jpg","comment_is_top":false,"comment_ctime":1614435929,"is_pvip":false,"replies":[{"id":"102026","content":"这个可以自己去查一查spark的文档或者源码，类似的细节问题比较多，还是自己查一查比较好。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1614563816,"ip_address":"","comment_id":280881,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5909403225","product_id":100060801,"comment_content":"老师，晚上好！~ 请问一个问题哦，我使用multiHotEncoderExample()函数生成的新的表，表中有一个字段：indexSize，这个字段描述是什么数据？怎么来的？期待老师的回答~^^","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":516232,"discussion_content":"这个可以自己去查一查spark的文档或者源码，类似的细节问题比较多，还是自己查一查比较好。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1614563816,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2264679,"avatar":"https://static001.geekbang.org/account/avatar/00/22/8e/67/afb412fb.jpg","nickname":"陈威洋","note":"","ucode":"DCF84B4D3A7354","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":352057,"discussion_content":"好的👌","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1614585269,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":278608,"user_name":"Geek_36ba7d","can_delete":false,"product_type":"c1","uid":2418524,"ip_address":"","ucode":"DBF706B842171E","user_header":"","comment_is_top":false,"comment_ctime":1613127277,"is_pvip":false,"replies":[{"id":"101384","content":"本质上来说只要你能提取出你要的feature，你用什么工具都可以。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1613529015,"ip_address":"","comment_id":278608,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5908094573","product_id":100060801,"comment_content":"用ES来代替spark可以吗？一个特征就是ES里得keyword呗？","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":515445,"discussion_content":"本质上来说只要你能提取出你要的feature，你用什么工具都可以。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1613529015,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1461122,"avatar":"https://static001.geekbang.org/account/avatar/00/16/4b/82/5be29abf.jpg","nickname":"老叔叔安森","note":"","ucode":"EF61ACAC9A44FE","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":377270,"discussion_content":"es能计算？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1622564789,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":277015,"user_name":"cymx66688","can_delete":false,"product_type":"c1","uid":1510592,"ip_address":"","ucode":"8198B851961BC7","user_header":"https://wx.qlogo.cn/mmopen/vi_32/TYeIuNZlibjr0eCvnCCTkYnFEgc8t7BialET3Bnsrbv9micpGIvbhwQrw7Zvt9BicThAEPPXojibVteAvQLb0eTO3DA/132","comment_is_top":false,"comment_ctime":1612233090,"is_pvip":false,"replies":[{"id":"100804","content":"实话说，我还真没研究这么细，可以看一看spark源码到底是怎么做onehotencoding的。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1612594922,"ip_address":"","comment_id":277015,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5907200386","product_id":100060801,"comment_content":"OneHot代码中setDropLast(false)让1000列字段变成了1001列，按理说不应该是删除最后一列为999列吗？新增的一列有什么作用？<br>val oneHotEncoder = new OneHotEncoderEstimator()<br>      .setInputCols(Array(&quot;movieIdNumber&quot;))<br>      .setOutputCols(Array(&quot;movieIdVector&quot;))<br>      .setDropLast(false)","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":514901,"discussion_content":"实话说，我还真没研究这么细，可以看一看spark源码到底是怎么做onehotencoding的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1612594922,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2369593,"avatar":"https://static001.geekbang.org/account/avatar/00/24/28/39/7e184c50.jpg","nickname":"Jimmy","note":"","ucode":"6D245FAF932C24","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":372491,"discussion_content":"这里说一下，这里有两个问题：\n1.为啥是1001\n2.dropLast有啥用\n先回答1，不是因为有1000部电影，所以id才为多少，而是代码中直接读取了movieId作为这个值，你把/webroot/sampledata/movies.csv的id某一个改成1998，你会发现是1999（因为0-1998），，，所以，原始数据是1-1000，直接用id就是0-1000\n再回答drop干啥了，这里没有drop，所以是原始的，我们把列减为2，比如：男女，其实虽然有两类，但他们互斥，所以常规下，这种两类是一列就好。。。扩展一下，对于5分类的互斥变量，4列也够了（因为互斥，我看到前面4列能推断最后一列，，也就是信息包含在前面里面，last没必要了）","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1620354964,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":270816,"user_name":"卓别林先森","can_delete":false,"product_type":"c1","uid":2198724,"ip_address":"","ucode":"253A52EF861BF3","user_header":"https://static001.geekbang.org/account/avatar/00/21/8c/c4/aba3ee31.jpg","comment_is_top":false,"comment_ctime":1609289405,"is_pvip":false,"replies":[{"id":"98282","content":"你说的特征质量，监控我觉得更多的是实践和工程问题。不会有一个方法论去指导，所以我的建议是自己的工作中多思考多总结，多跟同事讨论解决方案。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1609355034,"ip_address":"","comment_id":270816,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5904256701","product_id":100060801,"comment_content":"王老师您好，关于推荐系统 特征的衍生，应用您都讲很细致，特征决定了整个推荐系统的推荐效果的高度，至关重要。所以特征的质量也尤为重要，请问有关于特征质量，监控方面的比较好的资料推荐吗，谢谢了。","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":512762,"discussion_content":"你说的特征质量，监控我觉得更多的是实践和工程问题。不会有一个方法论去指导，所以我的建议是自己的工作中多思考多总结，多跟同事讨论解决方案。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1609355034,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":269304,"user_name":"Geek_99db42","can_delete":false,"product_type":"c1","uid":1628882,"ip_address":"","ucode":"4B02EF0E0B1C58","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/DPAiarROoO4JCGLRjyNefCicAZYepFickI1nOyKb6lz476tlYe1S6n5k7iaeicK0AOGn2AAJCvn7qBO8Zp98tDtM4zQ/132","comment_is_top":false,"comment_ctime":1608607113,"is_pvip":false,"replies":[{"id":"97716","content":"2147483647明显是32位integer的上限，要么是你的id过大，超过了这个上限，要么是哪有一些隐藏的bug。但onehot encoder有可能真的只支持32位integer。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1608665870,"ip_address":"","comment_id":269304,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5903574409","product_id":100060801,"comment_content":"老师你好，我使用了一个其他数据集，这个数据集的ID比较大，在做OneHot时出现了 OneHotEncoder only supports up to 2147483647 的错误，请问对于这种情况该如何处理，通过谷歌没有找到好的解决方法，也许是搜索的方法有错误","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":512227,"discussion_content":"2147483647明显是32位integer的上限，要么是你的id过大，超过了这个上限，要么是哪有一些隐藏的bug。但onehot encoder有可能真的只支持32位integer。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1608665870,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":259402,"user_name":"流年不流梦","can_delete":false,"product_type":"c1","uid":1061242,"ip_address":"","ucode":"980EB734E2A058","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/FnAia4oNWqvspqYZ8LxpUMh3J6oDxZHR6N8hut8HnywonBaP06dQkwFcqzslPTkMpqzlyDJ3vuOvwmUMx07psoQ/132","comment_is_top":false,"comment_ctime":1604718608,"is_pvip":false,"replies":[{"id":"95560","content":"没有必要","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1606115380,"ip_address":"","comment_id":259402,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5899685904","product_id":100060801,"comment_content":"老师好，想问下分桶后的特征还有必要做特征归一化吗？","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":508929,"discussion_content":"没有必要","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606115380,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":252863,"user_name":"Geek_63ee39","can_delete":false,"product_type":"c1","uid":2202096,"ip_address":"","ucode":"A41379ADD76480","user_header":"https://static001.geekbang.org/account/avatar/00/21/99/f0/ba3c0208.jpg","comment_is_top":false,"comment_ctime":1602503732,"is_pvip":false,"replies":[{"id":"92475","content":"是这样，希望大家都能运行程序查看一下数据细节。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1602634105,"ip_address":"","comment_id":252863,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5897471028","product_id":100060801,"comment_content":"思考2：movieIdVector是处理好的One-hot 特征；vector是处理好的Multi-hot 特征；这两个特征是使用Vector表示的","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":506902,"discussion_content":"是这样，希望大家都能运行程序查看一下数据细节。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1602634105,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":252836,"user_name":"吴波","can_delete":false,"product_type":"c1","uid":2112775,"ip_address":"","ucode":"3739A695E1357D","user_header":"https://static001.geekbang.org/account/avatar/00/20/3d/07/e2fffa6a.jpg","comment_is_top":false,"comment_ctime":1602497932,"is_pvip":false,"replies":[{"id":"92477","content":"应该是环境问题造成的个例。建议自己debug一下。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1602634218,"ip_address":"","comment_id":252836,"utype":1}],"discussion_count":8,"race_medal":0,"score":"5897465228","product_id":100060801,"comment_content":"想问下为什么右键运行FeatureEngineering会报错，提示 错误: 找不到或无法加载主类 com.wzhe.sparrowrecsys.offline.spark.featureeng.FeatureEngineering<br>","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":506887,"discussion_content":"应该是环境问题造成的个例。建议自己debug一下。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1602634218,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1308552,"avatar":"https://static001.geekbang.org/account/avatar/00/13/f7/88/da243c77.jpg","nickname":"大魔王","note":"","ucode":"5EB049D18E122F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":311855,"discussion_content":"scala版本问题","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1602507419,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2670260,"avatar":"https://static001.geekbang.org/account/avatar/00/28/be/b4/5091b607.jpg","nickname":"直行格子","note":"","ucode":"D24E6925E34177","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":381929,"discussion_content":"哎我终于解决了。所有的配置都弄好还会报错，需要在 pom 文件的 build 里加入下面这一段才能运行：\n             <plugin>\n                <groupId>org.scala-tools</groupId>\n                <artifactId>maven-scala-plugin</artifactId>\n                <version>2.11</version>\n                <executions>\n                    <execution>\n                        <goals>\n                            <goal>compile</goal>\n                        </goals>\n                    </execution>\n                </executions>\n            </plugin>","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1625301934,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2670260,"avatar":"https://static001.geekbang.org/account/avatar/00/28/be/b4/5091b607.jpg","nickname":"直行格子","note":"","ucode":"D24E6925E34177","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":381889,"discussion_content":"老师能不能出个详细些的教程？不要让人在配置环境上卡这么久？实战课程怎么配置环境一两句话带过，默认大家都是精通 java+scala+python 的嘛？？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1625280170,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1877078,"avatar":"https://static001.geekbang.org/account/avatar/00/1c/a4/56/29a05cb2.jpg","nickname":"Kepler","note":"","ucode":"C69A3248FB1AF6","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":351266,"discussion_content":"应该是项目没有载入scala，可以File -> Project Structure -> Libraries -> ＋ -> 选择scala载入， Apply后重启IntelliJ即可。本人适用，供大家伙参考","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1614220438,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":2670260,"avatar":"https://static001.geekbang.org/account/avatar/00/28/be/b4/5091b607.jpg","nickname":"直行格子","note":"","ucode":"D24E6925E34177","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1877078,"avatar":"https://static001.geekbang.org/account/avatar/00/1c/a4/56/29a05cb2.jpg","nickname":"Kepler","note":"","ucode":"C69A3248FB1AF6","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":381859,"discussion_content":"没解决。。。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1625242353,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":351266,"ip_address":""},"score":381859,"extra":""}]},{"author":{"id":2203465,"avatar":"https://static001.geekbang.org/account/avatar/00/21/9f/49/babad2a9.jpg","nickname":"空","note":"","ucode":"D3CA6DB61E7393","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":314507,"discussion_content":"我也出现这个问题，请问怎么解决的欸","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1603164187,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1952248,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/c9/f8/72955ef9.jpg","nickname":"浣熊当家","note":"","ucode":"939F06050423E4","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":312762,"discussion_content":"请问有什么解决方案吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1602811387,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":348469,"user_name":"金宣","can_delete":false,"product_type":"c1","uid":2448287,"ip_address":"","ucode":"9CDB027E9F7874","user_header":"https://static001.geekbang.org/account/avatar/00/25/5b/9f/c6c20349.jpg","comment_is_top":false,"comment_ctime":1655121553,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1655121553","product_id":100060801,"comment_content":"scala的运行方式（linux）<br>1. 安装scala、spark、hadoop<br>cs install scala:2.11.12 &amp;&amp; cs install scalac:2.11.12<br>wget https:&#47;&#47;archive.apache.org&#47;dist&#47;spark&#47;spark-2.4.3&#47;spark-2.4.3-bin-hadoop2.7.tgz<br>wget https:&#47;&#47;archive.apache.org&#47;dist&#47;hadoop&#47;common&#47;hadoop-2.7.7&#47;hadoop-2.7.7.tar.gz<br>tar xzf spark-2.4.3-bin-hadoop2.7.tgz<br>tar xzf hadoop-2.7.7.tar.gz<br>2. 配置环境变量<br>export SPARK_HOME=$PWD&#47;spark-2.4.3-bin-hadoop2.7<br>export HADOOP_HOME=$PWD&#47;hadoop-2.7.7<br>3. 创建如下目录结构<br>.&#47;build.sbt<br>.&#47;src<br>.&#47;src&#47;main<br>.&#47;src&#47;main&#47;scala<br>.&#47;src&#47;main&#47;scala&#47;FeatureEngineering.scala<br>build.sbt内容为：<br>name := &quot;SparrowRec&quot;<br>version := &quot;1.0&quot;<br>scalaVersion := &quot;2.11.12&quot;<br>libraryDependencies += &quot;org.apache.spark&quot; %% &quot;spark-sql&quot; % &quot;2.4.3&quot;<br>libraryDependencies += &quot;org.apache.spark&quot; %% &quot;spark-mllib&quot; % &quot;2.4.3&quot;<br>4. 编译<br>sbt clean package<br>5. 运行<br>spark-submit --class &quot;FeatureEngineering&quot; --master local[4] target&#47;scala-2.11&#47;sparrowrecspark_2.11-1.0.jar","like_count":1},{"had_liked":false,"id":345837,"user_name":"星晴","can_delete":false,"product_type":"c1","uid":2195455,"ip_address":"","ucode":"F748EC40E922CF","user_header":"https://static001.geekbang.org/account/avatar/00/21/7f/ff/0b2adf91.jpg","comment_is_top":false,"comment_ctime":1652623685,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1652623685","product_id":100060801,"comment_content":"请问老师：<br>Normalizer、StandardScaler、RobustScaler、MinMaxScaler 这个几个特征处理方法分别在什么情况下使用呢？","like_count":0},{"had_liked":false,"id":334354,"user_name":"Calmness","can_delete":false,"product_type":"c1","uid":2885368,"ip_address":"","ucode":"60CC8C3366C3D0","user_header":"https://static001.geekbang.org/account/avatar/00/2c/06/f8/9f6d64bd.jpg","comment_is_top":false,"comment_ctime":1644896334,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1644896334","product_id":100060801,"comment_content":"代码里为什么是对打分次数分桶，平均分归一化啊？是不是写反了？","like_count":0},{"had_liked":false,"id":326300,"user_name":"静心","can_delete":false,"product_type":"c1","uid":1335457,"ip_address":"","ucode":"EB264FA6519FDA","user_header":"https://static001.geekbang.org/account/avatar/00/14/60/a1/8f003697.jpg","comment_is_top":false,"comment_ctime":1639464043,"is_pvip":true,"discussion_count":0,"race_medal":1,"score":"1639464043","product_id":100060801,"comment_content":"如果执行如下命令：<br>python FeatureEngineering.py<br><br>发生如下错误：<br>Traceback (most recent call last):<br>  File &quot;FeatureEngineering.py&quot;, line 3, in &lt;module&gt;<br>    from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, QuantileDiscretizer, MinMaxScaler<br>ImportError: cannot import name OneHotEncoderEstimator<br><br>是因为OneHotEncoderEstimator在新版本pyspark中已经被重命令为了OneHotEncoder。<br>","like_count":0},{"had_liked":false,"id":321518,"user_name":"m-rui","can_delete":false,"product_type":"c1","uid":2829048,"ip_address":"","ucode":"75C9CBB9580C88","user_header":"https://static001.geekbang.org/account/avatar/00/2b/2a/f8/1af3bba6.jpg","comment_is_top":false,"comment_ctime":1636935082,"is_pvip":false,"replies":[{"id":"116815","content":"例子中的分桶方法处理的比较随意，当然保留原评分是最好的做法。可以想一想如何把原评分引入到模型训练中来。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1637025150,"ip_address":"","comment_id":321518,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1636935082","product_id":100060801,"comment_content":"请教下老师，一直对分桶有个疑惑，虽然业界实践是对skewed distribution进行分桶，但是这样从信息论的角度看不会丢掉一部分信息么？而且从您的例子来说，大家评分都集中在3.5是不是本身就代表了一种普遍偏好呢？如何保证分桶增加离散度就能增加模型收益呢？有没有啥理论支撑还是这只是个经验结果？","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":530309,"discussion_content":"例子中的分桶方法处理的比较随意，当然保留原评分是最好的做法。可以想一想如何把原评分引入到模型训练中来。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1637025150,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":315383,"user_name":"Geek_69905b","can_delete":false,"product_type":"c1","uid":1535570,"ip_address":"","ucode":"86073C3D0F4CE4","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/fo79zus88qcdVNuibzPEwKyUuoVx7TozoxgViaYnbYUCFZtdj97Os59EUIBoeiaheuYLib2Suo1YgJCtL4N7XcfzIg/132","comment_is_top":false,"comment_ctime":1633872426,"is_pvip":false,"replies":[{"id":"114468","content":"示例程序里没有用hdfs","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1634080330,"ip_address":"","comment_id":315383,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1633872426","product_id":100060801,"comment_content":"代码里这些处理完的特征好像是保存到csv里边了吧  有HDFS吗","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527948,"discussion_content":"示例程序里没有用hdfs","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1634080330,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":313138,"user_name":"LAKER","can_delete":false,"product_type":"c1","uid":2720513,"ip_address":"","ucode":"B87CDF0A3FB7EC","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eola14nCkjDaWbUoOICNd02xnolbDs1Uzq0Eut3VEQ39KHAGGXTyuzOpS9NcrUtrXIQM0ficEqCcxg/132","comment_is_top":false,"comment_ctime":1632294872,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1632294872","product_id":100060801,"comment_content":"您好，老师，看了您项目代码，您连接的是本地spark吗，如果连接远程spark的话，例如我的windows连接云服务器上的spark，需要改的是master中的参数吧，将local改为spark：&#47;&#47;ip：7077，其他的依赖根据我自己的spark版本进行修改对吗？","like_count":0},{"had_liked":false,"id":310020,"user_name":"คิดถึง ","can_delete":false,"product_type":"c1","uid":2735702,"ip_address":"","ucode":"205BA133D638C6","user_header":"https://static001.geekbang.org/account/avatar/00/29/be/56/6a2998ba.jpg","comment_is_top":false,"comment_ctime":1630459498,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1630459498","product_id":100060801,"comment_content":"老师好，我想问一下FeatureEngForRecModel.scala中的splitAndSaveTrainingTestSamples函数是不是没有生效，为什么我每次运行的时候，没有重新生成文件啊？","like_count":0},{"had_liked":false,"id":305938,"user_name":"Geek_8a732a","can_delete":false,"product_type":"c1","uid":2723806,"ip_address":"","ucode":"97A312D97F7B91","user_header":"","comment_is_top":false,"comment_ctime":1628239001,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1628239001","product_id":100060801,"comment_content":"2、<br>One-hot是调用OneHotEncoder，将movieId转换成movieIdVector向量<br>Multi-hot是将genres，转换成genreIndexes向量","like_count":0},{"had_liked":false,"id":304845,"user_name":"陈威洋","can_delete":false,"product_type":"c1","uid":2264679,"ip_address":"","ucode":"DCF84B4D3A7354","user_header":"https://static001.geekbang.org/account/avatar/00/22/8e/67/afb412fb.jpg","comment_is_top":false,"comment_ctime":1627637795,"is_pvip":false,"replies":[{"id":"110281","content":"这是个经验值，不用死扣，多尝试就可以","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1627692858,"ip_address":"","comment_id":304845,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1627637795","product_id":100060801,"comment_content":"喆哥，您好，为什么要分100个桶，依据是从方差那里得来的吗？如果不是，那么为什么要计算方差？百思不得其解！~~~对不起喆哥，我很死扣....","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":524184,"discussion_content":"这是个经验值，不用死扣，多尝试就可以","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627692858,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2264679,"avatar":"https://static001.geekbang.org/account/avatar/00/22/8e/67/afb412fb.jpg","nickname":"陈威洋","note":"","ucode":"DCF84B4D3A7354","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":386612,"discussion_content":"好的，马上尝试","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627692905,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":304728,"user_name":"陈威洋","can_delete":false,"product_type":"c1","uid":2264679,"ip_address":"","ucode":"DCF84B4D3A7354","user_header":"https://static001.geekbang.org/account/avatar/00/22/8e/67/afb412fb.jpg","comment_is_top":false,"comment_ctime":1627569591,"is_pvip":false,"replies":[{"id":"110272","content":"这个就是excel的图","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1627691717,"ip_address":"","comment_id":304728,"utype":1}],"discussion_count":3,"race_medal":0,"score":"1627569591","product_id":100060801,"comment_content":"喆哥，晚上好！~<br><br>我是正转型推荐算法工程师，请问：<br><br>文章的数据分布图，喆哥是用什么工具计算出来哦？有推荐吗？","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":524136,"discussion_content":"这个就是excel的图","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627691717,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2264679,"avatar":"https://static001.geekbang.org/account/avatar/00/22/8e/67/afb412fb.jpg","nickname":"陈威洋","note":"","ucode":"DCF84B4D3A7354","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":386611,"discussion_content":"Excel直接方便，感谢喆哥点破～","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627692410,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":2340235,"avatar":"https://static001.geekbang.org/account/avatar/00/23/b5/8b/92549066.jpg","nickname":"Geek_8183d5","note":"","ucode":"D06E69FC7737A2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2264679,"avatar":"https://static001.geekbang.org/account/avatar/00/22/8e/67/afb412fb.jpg","nickname":"陈威洋","note":"","ucode":"DCF84B4D3A7354","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":571245,"discussion_content":"使用python 的matplotlib.pyplot 库也可以画出来。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1652154001,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":386611,"ip_address":""},"score":571245,"extra":""}]}]},{"had_liked":false,"id":301813,"user_name":"发财了带带捉狗","can_delete":false,"product_type":"c1","uid":2689315,"ip_address":"","ucode":"A85D9520407289","user_header":"https://static001.geekbang.org/account/avatar/00/29/09/23/615b56d2.jpg","comment_is_top":false,"comment_ctime":1625894961,"is_pvip":false,"replies":[{"id":"109397","content":"单机工作，当作只有一个节点。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1626216197,"ip_address":"","comment_id":301813,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1625894961","product_id":100060801,"comment_content":"小白来请教一下老师，Spark是一个分布式计算的平台，那我git clone下来的项目是在我自己的windows机器上，只有一台机器，那这里scala的代码是怎么工作的呢？","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":523096,"discussion_content":"单机工作，当作只有一个节点。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1626216197,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":291457,"user_name":"苍绮皓","can_delete":false,"product_type":"c1","uid":2474686,"ip_address":"","ucode":"02A772262E1512","user_header":"https://static001.geekbang.org/account/avatar/00/25/c2/be/1a4598e0.jpg","comment_is_top":false,"comment_ctime":1620294377,"is_pvip":false,"replies":[{"id":"105683","content":"没有办法。只能用其他cold start的方法来生成这个新电影的emb。参考 https:&#47;&#47;zhuanlan.zhihu.com&#47;p&#47;351390011","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1620582753,"ip_address":"","comment_id":291457,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1620294377","product_id":100060801,"comment_content":"老师请问，离线时电影库中有1000部电影，如果线上上线了一部新电影，它不在库中，那它做ID的Embedding怎么办？","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":519475,"discussion_content":"没有办法。只能用其他cold start的方法来生成这个新电影的emb。参考 https://zhuanlan.zhihu.com/p/351390011","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1620582753,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":290203,"user_name":"InfoQ_bb5278aeccff","can_delete":false,"product_type":"c1","uid":1367444,"ip_address":"","ucode":"E70D5AFB8011B9","user_header":"","comment_is_top":false,"comment_ctime":1619428270,"is_pvip":false,"replies":[{"id":"105350","content":"1. 一般实时特征需要线上重写一套，非实时特征可以离线处理好存到内存数据库中，线上直接取出来。<br><br>2. 可以这样，如果工程上可行（比如离线和在线都是用java写的），这样是最好的。<br><br>3. 这个问题太复杂，要通过测试来决定。但我倾向于让tf serving只处理模型的部分，所有特征工程放到recsys server内部或者其他feature api来做，这样减轻tf serving的负担。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1619729578,"ip_address":"","comment_id":290203,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1619428270","product_id":100060801,"comment_content":"老师您好,课程中的特征工程是用spark-ml的api进行处理的,这个在离线处理数据和训练模型是高效的.我的疑惑是:<br>1、怎么把上述离线的特征处理部署到线上呢? 还是离线写一套处理逻辑,上线时又重新写一套处理逻辑,这样能保证离线,在线特征的处理是一致的吗,会不会容易出错?<br>2、我看有的公司用c++或者java写一套公用的特征处理算子,离线和在线的特征处理都调用这些算子,以保证特征处理的一致性,这套方法可行吗?<br>3、课程中关于模型部分,直接使用tf的feature_column来处理特征,业界也是这么做的吗,在模型部署的时候,直接把feature_column和模型一起部署,在线服务时,直接传原始特征给模型即可进行处理和预测,这样效率会很慢吗<br><br>关于在线特征处理这块,老师您有什么建议吗","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":519137,"discussion_content":"1. 一般实时特征需要线上重写一套，非实时特征可以离线处理好存到内存数据库中，线上直接取出来。\n\n2. 可以这样，如果工程上可行（比如离线和在线都是用java写的），这样是最好的。\n\n3. 这个问题太复杂，要通过测试来决定。但我倾向于让tf serving只处理模型的部分，所有特征工程放到recsys server内部或者其他feature api来做，这样减轻tf serving的负担。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1619729578,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":289165,"user_name":"如此轻松。","can_delete":false,"product_type":"c1","uid":1500234,"ip_address":"","ucode":"283EE136E09C03","user_header":"https://static001.geekbang.org/account/avatar/00/16/e4/4a/51847213.jpg","comment_is_top":false,"comment_ctime":1618900186,"is_pvip":false,"replies":[{"id":"105065","content":"是的，但毫无疑问这是一个稀疏向量","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1619112465,"ip_address":"","comment_id":289165,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1618900186","product_id":100060801,"comment_content":"如果有十万部电影，One-Hot 就需要一个十万维的向量？？","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":518839,"discussion_content":"是的，但毫无疑问这是一个稀疏向量","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1619112465,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":287186,"user_name":"归零","can_delete":false,"product_type":"c1","uid":1103208,"ip_address":"","ucode":"C99B8E93009A46","user_header":"https://static001.geekbang.org/account/avatar/00/10/d5/68/2201b6b9.jpg","comment_is_top":false,"comment_ctime":1617808443,"is_pvip":true,"replies":[{"id":"104474","content":"是这样，要精确对照项目的依赖版本","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1618113236,"ip_address":"","comment_id":287186,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1617808443","product_id":100060801,"comment_content":"说一个和scala相关的坑，项目中引用的scala版本是2.11，安装的sdk版本如果不符合的话会有一些奇怪的报错，这时候最好检查一下自己的scala的版本。","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":518225,"discussion_content":"是这样，要精确对照项目的依赖版本","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618113236,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":283641,"user_name":"阿甘","can_delete":false,"product_type":"c1","uid":1057843,"ip_address":"","ucode":"BC93175B70E05D","user_header":"https://static001.geekbang.org/account/avatar/00/10/24/33/bcf37f50.jpg","comment_is_top":false,"comment_ctime":1615862666,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1615862666","product_id":100060801,"comment_content":"特征处理似乎是在样本生成的时候做的，特征工程挖掘的是原始特征吧？","like_count":0},{"had_liked":false,"id":283356,"user_name":"武强","can_delete":false,"product_type":"c1","uid":2243266,"ip_address":"","ucode":"E338F83E4BD240","user_header":"https://static001.geekbang.org/account/avatar/00/22/3a/c2/4011ff84.jpg","comment_is_top":false,"comment_ctime":1615725522,"is_pvip":false,"replies":[{"id":"102836","content":"所谓“分桶（Bucketing）”，就是将样本按照某特征的值从高到低排序，然后按照桶的数量找到分位数，将样本分到各自的桶中，再用桶 ID 作为特征值。<br><br>这句话应该描述的非常清楚了。基本是很严谨的定义。如果有不清楚的名词自己再搜索学习一下。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1615794034,"ip_address":"","comment_id":283356,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1615725522","product_id":100060801,"comment_content":"老师好！分桶处理，我还是没太明白，您可以详细解释一下吗？","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":517006,"discussion_content":"所谓“分桶（Bucketing）”，就是将样本按照某特征的值从高到低排序，然后按照桶的数量找到分位数，将样本分到各自的桶中，再用桶 ID 作为特征值。\n\n这句话应该描述的非常清楚了。基本是很严谨的定义。如果有不清楚的名词自己再搜索学习一下。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1615794034,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":283125,"user_name":"White dragon","can_delete":false,"product_type":"c1","uid":2335965,"ip_address":"","ucode":"31C280D9705322","user_header":"https://static001.geekbang.org/account/avatar/00/23/a4/dd/e09636ca.jpg","comment_is_top":false,"comment_ctime":1615559579,"is_pvip":false,"replies":[{"id":"102827","content":"无绝对，连续值特征“可能”会带来过拟合现象。<br>LR模型把特征离散化的主要目的一般来说就是为了避免噪声和一些过拟合现象，一般不会说提升表达能力，我书中有这句话的话，应该是有上下文，或者表达确实不准确。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1615793104,"ip_address":"","comment_id":283125,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1615559579","product_id":100060801,"comment_content":"老师您好，我在看您的书籍时提到，连续值特征会带来过拟合现象。但是LR模型把特征离散化可以提升模型的表达能力。这两个是否矛盾呢","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":516939,"discussion_content":"无绝对，连续值特征“可能”会带来过拟合现象。\nLR模型把特征离散化的主要目的一般来说就是为了避免噪声和一些过拟合现象，一般不会说提升表达能力，我书中有这句话的话，应该是有上下文，或者表达确实不准确。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1615793104,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2747534,"avatar":"https://static001.geekbang.org/account/avatar/00/29/ec/8e/80ecba15.jpg","nickname":"知行","note":"","ucode":"480B1F72A6FD76","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":391012,"discussion_content":"LR属于线性模型，表达能力有限。使用离散的特征，每个特征有了单独的权重，相当于引入了非线性，因此可以提升模型的表达能力。 王老师书中表达的是不是这种意思？","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1630229979,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":280738,"user_name":"小博","can_delete":false,"product_type":"c1","uid":1078829,"ip_address":"","ucode":"4DB860A0D35BA0","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83er6OV33jHia3U6Y6xwm9BryshBqapb8iaQCf3P4RUxIxiakfEdEzDEPy5QR6sjCjqj7CNgz6Lyj8rPYA/132","comment_is_top":false,"comment_ctime":1614333918,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1614333918","product_id":100060801,"comment_content":"想问一下，目前spark包训练word2vec的错误是否修复了呢，每次用来训练都有问题。。","like_count":0},{"had_liked":false,"id":277282,"user_name":"Sanders","can_delete":false,"product_type":"c1","uid":1697075,"ip_address":"","ucode":"3D460FEEDCDF34","user_header":"","comment_is_top":false,"comment_ctime":1612343581,"is_pvip":false,"replies":[{"id":"100810","content":"不知道你这里说的Feature Map指的是什么？","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1612595748,"ip_address":"","comment_id":277282,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1612343581","product_id":100060801,"comment_content":"老师，在特征处理过程中特征的一致性和增量问题是不是用Spark这么来处理的？<br>1. 在fit时输入全量数据，让每个特征的特征值尽可能全地参与特征处理<br>2. 保存fit后的Spark模型，作为Feature Map<br>3. 实时处理作业加载Feature Map模型，如果实时部分有“未知”的特征值出现，那么更新模型(Feature Map)<br>4. 线上部分通过这个模型(Feature Map)进行业务数据和特征编码之间的转换","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":514984,"discussion_content":"不知道你这里说的Feature Map指的是什么？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1612595748,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1697075,"avatar":"","nickname":"Sanders","note":"","ucode":"3D460FEEDCDF34","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":348481,"discussion_content":"Feature Map是原始特征值和特征编码的映射关系，比如城市：北京映射为1，上海映射为2，假如增量数据中多出一个三沙市，我们希望三沙市也能被正确映射到原有关系中，spark特征处理本身也是一个model，save model就会保存这个关系","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1612596931,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":276841,"user_name":"韩木子","can_delete":false,"product_type":"c1","uid":2338335,"ip_address":"","ucode":"EB45F45897C520","user_header":"","comment_is_top":false,"comment_ctime":1612150366,"is_pvip":false,"replies":[{"id":"100802","content":"当然可以，我们的项目不就是吗？","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1612594801,"ip_address":"","comment_id":276841,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1612150366","product_id":100060801,"comment_content":"老师，在一个多编程语言的项目里，有python，scala，java，代码都是在IDEA上编写、调试和运行的吗","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":514834,"discussion_content":"当然可以，我们的项目不就是吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1612594801,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":274620,"user_name":"彭小鑫","can_delete":false,"product_type":"c1","uid":2407410,"ip_address":"","ucode":"9BEFBE52BC124E","user_header":"http://thirdwx.qlogo.cn/mmopen/VdM9K3h96B7usk6dk8Q2KsAJmLDuFBXKEUtcKxS2yhSt4aKgtO9FgC7ZdVztkPAT71c7vJQgafU70hvUgPXJXerJ7LIZ3Bxn/132","comment_is_top":false,"comment_ctime":1611103969,"is_pvip":false,"replies":[{"id":"99710","content":"多一个）应该会编译不通过吧","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1611191457,"ip_address":"","comment_id":274620,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1611103969","product_id":100060801,"comment_content":"归一化和分桶的代码，第10行as后面是不是多了一个‘)’，跑的时候感觉很奇怪，没找到对应的左括号","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":514071,"discussion_content":"多一个）应该会编译不通过吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1611191457,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2407410,"avatar":"http://thirdwx.qlogo.cn/mmopen/VdM9K3h96B7usk6dk8Q2KsAJmLDuFBXKEUtcKxS2yhSt4aKgtO9FgC7ZdVztkPAT71c7vJQgafU70hvUgPXJXerJ7LIZ3Bxn/132","nickname":"彭小鑫","note":"","ucode":"9BEFBE52BC124E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":344745,"discussion_content":"对啊，我把它删了跑起来了，看到了结果","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1611566753,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":273127,"user_name":"zly","can_delete":false,"product_type":"c1","uid":2354702,"ip_address":"","ucode":"193C22A6F29CF1","user_header":"https://static001.geekbang.org/account/avatar/00/23/ee/0e/833a346f.jpg","comment_is_top":false,"comment_ctime":1610447812,"is_pvip":false,"replies":[{"id":"98995","content":"hadoop是一个体系，数据处理可以侧重spark就可以了","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1610503092,"ip_address":"","comment_id":273127,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1610447812","product_id":100060801,"comment_content":"老师您好，请问作为应届毕业生找工作，需要学习hadoop吗，如果需要的话应该侧重于掌握那些部分呢？","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":513503,"discussion_content":"hadoop是一个体系，数据处理可以侧重spark就可以了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1610503092,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":270381,"user_name":"Geek_988cb0","can_delete":false,"product_type":"c1","uid":2388174,"ip_address":"","ucode":"76666A2B0CE1C9","user_header":"","comment_is_top":false,"comment_ctime":1609107928,"is_pvip":false,"replies":[{"id":"98137","content":"sparrow spark里的multi-hot encoding是基于one hot encoding的多tag编码方案。跟这篇文章里的概念不一样。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1609199946,"ip_address":"","comment_id":270381,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1609107928","product_id":100060801,"comment_content":"spark里multi-hot encoding是基于one hot encoing的，和平时说的multi hot encoding不是一样的，是这样么？比如这篇回答：<br>https:&#47;&#47;stats.stackexchange.com&#47;questions&#47;467633&#47;what-exactly-is-multi-hot-encoding-and-how-is-it-different-from-one-hot<br><br>假设有这几个类别：[&#39;cat&#39;, &#39;dog&#39;, &#39;fish&#39;, &#39;bird&#39;, &#39;ant&#39;]<br>multi-hot 编码之后变成<br>&#39;cat&#39;  = [0,0,0]  <br>&#39;dog&#39;  = [0,0,1]  <br>&#39;fish&#39; = [0,1,0]  <br>&#39;bird&#39; = [0,1,1]  <br>&#39;ant&#39;  = [1,0,0]   <br>维度是⌈log25⌉=3，而不是5","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":512601,"discussion_content":"sparrow spark里的multi-hot encoding是基于one hot encoding的多tag编码方案。跟这篇文章里的概念不一样。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1609199946,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":262605,"user_name":"Sebastian","can_delete":false,"product_type":"c1","uid":1797634,"ip_address":"","ucode":"62E6FC13DB00E3","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/55lYKUdcPFgUHibRYmaRiaBdrsmnLGOHdPp4OicjBh197X0vyGa9qAwruEqicAPuUgibXO4Lz5jLudlcbtsqq2p3CpA/132","comment_is_top":false,"comment_ctime":1605778019,"is_pvip":false,"replies":[{"id":"95328","content":"reduceByKey应该是rdd相关的操作，spark dataframe没有reduceByKey操作。当然可以帮我验证一下。<br><br>spark选哪个函数比较高效，这个问题确实比较大了，还是推荐上一门spark课程吧，这边就不展开讲了。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1605833260,"ip_address":"","comment_id":262605,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1605778019","product_id":100060801,"comment_content":"老师好，上面代码中groupByKey如果考虑函数性能的话是不是会考虑换成reduceByKey呢？关于scala语言里选择什么函数性能更好有没有什么实践经验呢？","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509892,"discussion_content":"reduceByKey应该是rdd相关的操作，spark dataframe没有reduceByKey操作。当然可以帮我验证一下。\n\nspark选哪个函数比较高效，这个问题确实比较大了，还是推荐上一门spark课程吧，这边就不展开讲了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605833260,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2747534,"avatar":"https://static001.geekbang.org/account/avatar/00/29/ec/8e/80ecba15.jpg","nickname":"知行","note":"","ucode":"480B1F72A6FD76","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":391013,"discussion_content":"性能最好的应该是aggregatByKey","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1630230154,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":253729,"user_name":"阳光","can_delete":false,"product_type":"c1","uid":1262252,"ip_address":"","ucode":"9EA201D866EFCD","user_header":"https://static001.geekbang.org/account/avatar/00/13/42/ac/022af9f4.jpg","comment_is_top":false,"comment_ctime":1602845347,"is_pvip":false,"replies":[{"id":"92703","content":"按照之前类似的问题，应该是scala版本的问题，请查一下是不是使用了scala2.11的版本。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1602871718,"ip_address":"","comment_id":253729,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1602845347","product_id":100060801,"comment_content":"我运行FeatureEngineering 类出错，显示“错误: 找不到或无法加载主类 com.wzhe.sparrowrecsys.offline.spark.featureeng.FeatureEngineering<br>原因: java.lang.ClassNotFoundException: com.wzhe.sparrowrecsys.offline.spark.featureeng.FeatureEngineering”<br>这是怎么回事？","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":507158,"discussion_content":"按照之前类似的问题，应该是scala版本的问题，请查一下是不是使用了scala2.11的版本。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1602871718,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2288345,"avatar":"","nickname":"孟竹","note":"","ucode":"E98D7BFD30ABD3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":332395,"discussion_content":"搜到了一篇，https://blog.csdn.net/hongzhen91/article/details/81507140","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1607178947,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":253613,"user_name":"浣熊当家","can_delete":false,"product_type":"c1","uid":1952248,"ip_address":"","ucode":"939F06050423E4","user_header":"https://static001.geekbang.org/account/avatar/00/1d/c9/f8/72955ef9.jpg","comment_is_top":false,"comment_ctime":1602812039,"is_pvip":false,"replies":[{"id":"92635","content":"scala和java都可以，pyspark也可以，看自己的喜好。因为spark原生支持scala，属于最官方的语言，所以本门课程使用scala","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1602826786,"ip_address":"","comment_id":253613,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1602812039","product_id":100060801,"comment_content":"老师我们是不是一般用到spark相关的包，就会一定要用scala？可不可以也用java呢？或者比如线上部分的代码现在用的是java，可不可以用scala呢？ 我们有哪些选择语言的标准和规律吗？","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":507123,"discussion_content":"scala和java都可以，pyspark也可以，看自己的喜好。因为spark原生支持scala，属于最官方的语言，所以本门课程使用scala","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1602826786,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]}]}