{"id":267344,"title":"34 | 如何设计一个高性能大容量持久化的ConcurrentHashmap？","content":"<p><strong>课件和Demo地址</strong><br>\n<a href=\"https://gitee.com/geektime-geekbang/geektime-distributed\">https://gitee.com/geektime-geekbang/geektime-distributed</a></p>","comments":[{"had_liked":false,"id":297078,"user_name":"夏至","can_delete":false,"product_type":"c3","uid":1564736,"ip_address":"","ucode":"19420BB56C833B","user_header":"https://static001.geekbang.org/account/avatar/00/17/e0/40/dbec26a7.jpg","comment_is_top":false,"comment_ctime":1623302153,"is_pvip":false,"replies":[{"id":108043,"content":"这个和bigtable还是有本质区别的，bigtable要复杂很多，bigtable可以对标开源的hbase。","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1623685699,"ip_address":"","comment_id":297078,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100053601,"comment_content":"和谷歌的Bigtable有点像","like_count":0,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":521710,"discussion_content":"这个和bigtable还是有本质区别的，bigtable要复杂很多，bigtable可以对标开源的hbase。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1623685699,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1564736,"avatar":"https://static001.geekbang.org/account/avatar/00/17/e0/40/dbec26a7.jpg","nickname":"夏至","note":"","ucode":"19420BB56C833B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":379158,"discussion_content":"哦是，其实是想说和SStable比较像，Bigtable是个数据库不合适比较","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1623731274,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":286717,"user_name":"托尼斯威特","can_delete":false,"product_type":"c3","uid":1729060,"ip_address":"","ucode":"98A1035527292E","user_header":"https://static001.geekbang.org/account/avatar/00/1a/62/24/07e2507c.jpg","comment_is_top":false,"comment_ctime":1617523560,"is_pvip":false,"replies":[{"id":104789,"content":"1. LRUCache发生Eviction时才写入PersistentMap\n2. Write Behind可以简单理解为将对应的insert&#47;update写入一个queue，后台线程定期刷这个queue，写入DB","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1618667904,"ip_address":"","comment_id":286717,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100053601,"comment_content":"波波老师, 问两个问题, 视频中没有提到. \n1. PersistentMap 是要一致和 LRUCache 保持一致, 还是只有 LRUCache发生 Eviction的时候才写入 PersistentMap? \n2. Write Behind 的时候要遍历所有的key, 把所有的key, value 都往 DB 写一遍吗? 还是记录了 dirty bit ? ","like_count":0,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":518072,"discussion_content":"1. LRUCache发生Eviction时才写入PersistentMap\n2. Write Behind可以简单理解为将对应的insert/update写入一个queue，后台线程定期刷这个queue，写入DB","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618667904,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":271484,"user_name":"红糖白糖","can_delete":false,"product_type":"c3","uid":1221664,"ip_address":"","ucode":"C6415C57AD6FF4","user_header":"https://static001.geekbang.org/account/avatar/00/12/a4/20/dd6f568c.jpg","comment_is_top":false,"comment_ctime":1609663552,"is_pvip":false,"replies":[{"id":98962,"content":"采用Redis也可以实现SessionServer，只是需要重新设计另外一套架构。携程当时还没有引入Redis，没有相关的运维团队，所以我们最终考虑自研Cache服务，这样把控粒度也会更好(尤其是监控埋点)。","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1610460284,"ip_address":"","comment_id":271484,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100053601,"comment_content":"我在想如果为了备份，数据备份到了Redis。那为啥不支持基于Reids来做这个分布式的缓存系统，Redis也支持高可用、持久化、扩展等等。想到的不足可能就是节点宕机后，节点上的数据不可用了，因为数据分片是一致性hash来实现的。如果是基于数据库来备份，异步写SQL也不一定100%成功，这个是允许部分数据的丢失得嘛？","like_count":0,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":512939,"discussion_content":"采用Redis也可以实现SessionServer，只是需要重新设计另外一套架构。携程当时还没有引入Redis，没有相关的运维团队，所以我们最终考虑自研Cache服务，这样把控粒度也会更好(尤其是监控埋点)。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1610460284,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":244831,"user_name":"Vincent_","can_delete":false,"product_type":"c3","uid":1313831,"ip_address":"","ucode":"0904F7CE04E788","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/ibbEWWUTH7964UOnwpBPC8Lhb1TS4s7XMEXTPKHPUBlj58GVkdRQRqa6EydIRL2I1uJDzeichLj86gJfTpzcgcCA/132","comment_is_top":false,"comment_ctime":1598693619,"is_pvip":false,"replies":[{"id":90184,"content":"并没有说要取代redis，这边的SessionServer场景，只是需要一种大容量的能够持久化Value的缓存，我们自己定制了一个bigcache，实现并不复杂，功能刚好够用，我们可以把控，而且可以细粒度埋点监控。\n\n当然，整个SessionServer的实现，也可以考虑基于redis来实现，只是总体架构设计会有不同。","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1598880799,"ip_address":"","comment_id":244831,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100053601,"comment_content":"没有理解到这些的应用场景，bigcache也好halodb也好，最后就是想取代redis这类缓存吗？","like_count":0,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":504711,"discussion_content":"并没有说要取代redis，这边的SessionServer场景，只是需要一种大容量的能够持久化Value的缓存，我们自己定制了一个bigcache，实现并不复杂，功能刚好够用，我们可以把控，而且可以细粒度埋点监控。\n\n当然，整个SessionServer的实现，也可以考虑基于redis来实现，只是总体架构设计会有不同。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1598880799,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":243469,"user_name":"Geek_zbvt62","can_delete":false,"product_type":"c3","uid":1046714,"ip_address":"","ucode":"81EA27ADD9EC1A","user_header":"https://static001.geekbang.org/account/avatar/00/0f/f8/ba/d28174a9.jpg","comment_is_top":false,"comment_ctime":1598147789,"is_pvip":false,"replies":[{"id":89736,"content":"属于log structured KV存储结构","user_name":"作者回复","user_name_real":"杨波","uid":1030344,"ctime":1598198264,"ip_address":"","comment_id":243469,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100053601,"comment_content":"HaloDB这种实现方式基本和大数据方案的存储异曲同工，说明它更适合写操作多的场景","like_count":0,"discussions":[{"author":{"id":1030344,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b8/c8/c94d38a7.jpg","nickname":"杨波","note":"","ucode":"FA3418BB703BCA","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":504294,"discussion_content":"属于log structured KV存储结构","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1598198264,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":351249,"user_name":"青阳","can_delete":false,"product_type":"c3","uid":2139807,"ip_address":"","ucode":"3591D366BAB0B9","user_header":"https://static001.geekbang.org/account/avatar/00/20/a6/9f/3c60fffd.jpg","comment_is_top":false,"comment_ctime":1657638297,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100053601,"comment_content":"和etcd挺像的，不过etcd实现了mvcc，并且用B+Tree替换了HashMap","like_count":1},{"had_liked":false,"id":304683,"user_name":"苏云","can_delete":false,"product_type":"c3","uid":1098301,"ip_address":"","ucode":"68A74AFB289CFC","user_header":"https://static001.geekbang.org/account/avatar/00/10/c2/3d/f7a89a27.jpg","comment_is_top":false,"comment_ctime":1627549146,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100053601,"comment_content":"leveldb, rocksdb. 这两个也很不错","like_count":1},{"had_liked":false,"id":340766,"user_name":"冬风向左吹","can_delete":false,"product_type":"c3","uid":1066928,"ip_address":"","ucode":"376C45C5134F93","user_header":"https://static001.geekbang.org/account/avatar/00/10/47/b0/a9b77a1e.jpg","comment_is_top":false,"comment_ctime":1649125049,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100053601,"comment_content":"对于session这个场景来说刚好比较特殊，可以通过session中存储ip定位缓存节点，但如果是其它缓存的场景呢，还是得用一致性hash这类算法吧","like_count":0}]}