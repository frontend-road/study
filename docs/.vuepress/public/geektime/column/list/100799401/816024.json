{"id":816024,"title":"24｜10+ SQL执行性能不佳的真实案例（下）","content":"<p>你好，我是俊达。这节课我们继续看剩下的几个案例。</p><h2>案例七：优化or查询的另一个例子</h2><p>下面是另一个在where中使用了or的例子，这个SQL的性能非常差，需要将3个表的数据全部关联起来。</p><pre><code class=\"language-plain\">SELECT t_msg.msg_id，t_msg.content , ......\nFROM t_msg \n    LEFT JOIN t_user ON t_msg.user_id = t_user.user_id  \n    LEFT JOIN t_group ON t_msg.group_id = t_group.group_id\nWHERE t_msg.gmt_modified &gt;= date_sub('2018-05-20 09:31:45', INTERVAL 30 SECOND)  \nOR t_user.gmt_modified &gt;= date_sub('2018-05-20 09:31:45', INTERVAL 30 SECOND)  \nOR t_group.gmt_modified &gt;= date_sub('2018-05-20 09:31:45', INTERVAL 30 SECOND)\n</code></pre><p>业务的需求，是查询最近半分钟内发生过变化的数据。这个SQL的where条件中，用到了3个表的gmt_modified字段来过滤数据，而且这些条件使用or相连。看一下下面的示意图，业务关心的是新数据，每个表中，最近修改过的数据都只占了整个表数据的一小部分。而且t_user、t_group表的数据很少更新。但由于SQL的写法，每次都需要连接全量的数据，然后再过滤出一小部分数据，因此SQL的效率很低。</p><!-- [[[read_end]]] --><p><img src=\"https://static001.geekbang.org/resource/image/c0/43/c0a2ayy449a7093714ff7102f920b743.jpg?wh=1470x564\" alt=\"图片\"></p><p>我们将SQL拆分成3个部分。</p><ul>\n<li>SQL片段1</li>\n</ul><pre><code class=\"language-plain\">SELECT t_msg.msg_id，t_msg.content , ......\nFROM t_msg \n    LEFT JOIN t_user ON t_msg.user_id = t_user.user_id  \n    LEFT JOIN t_group ON t_msg.group_id = t_group.group_id\nWHERE t_msg.gmt_modified &gt;= date_sub('2018-05-20 09:31:45', INTERVAL 30 SECOND)  \n</code></pre><p>SQL片段1以t_msg表作为驱动表，先过滤出表中gmt_modified在半分钟之内的数据，然后再去连接t_user和t_group表，大大减少了连接的数据。</p><p><img src=\"https://static001.geekbang.org/resource/image/f3/31/f3c4yy06a6a611f2425c718937858a31.jpg?wh=1458x568\" alt=\"图片\"></p><ul>\n<li>SQL片段2</li>\n</ul><pre><code class=\"language-plain\">SELECT t_msg.msg_id，t_msg.content , ......\nFROM t_msg \n    LEFT JOIN t_user ON t_msg.user_id = t_user.user_id  \n    LEFT JOIN t_group ON t_msg.group_id = t_group.group_id\nWHERE t_user.gmt_modified &gt;= date_sub('2018-04-29 09:31:44', INTERVAL 30 SECOND)\n</code></pre><p>SQL片段2中，对t_user表的left join等价于普通join。以t_user表为驱动表，先过滤t_user表最近修改过的数据，再去连接t_msg和t_group表。</p><p><img src=\"https://static001.geekbang.org/resource/image/87/64/87f233fee5a4609802afd00db65aa464.jpg?wh=1486x608\" alt=\"图片\"></p><ul>\n<li>SQL片段3</li>\n</ul><pre><code class=\"language-plain\">SELECT t_msg.msg_id，t_msg.content , ......\nFROM t_msg \n    LEFT JOIN t_user ON t_msg.user_id = t_user.user_id  \n    LEFT JOIN t_group ON t_msg.group_id = t_group.group_id\nWHERE t_group.gmt_modified &gt;= date_sub('2018-04-29 09:31:44', INTERVAL 30 SECOND)\n</code></pre><p>SQL片段3中，对t_group表的left join等价于普通join。以t_group表为驱动表，先过滤t_group表最近修改过的数据，再去连接t_msg和t_user表。</p><p><img src=\"https://static001.geekbang.org/resource/image/ee/68/eee9ae458224de2a85867b0f98236668.jpg?wh=1458x568\" alt=\"图片\"></p><p>将SQL拆分成3个部分后，优化器可以对这3个SQL片段分别优化，选取不同的表关联顺序。在这个业务场景下，由于t_user和t_group表的数据很少有变化，因此SQL片段2和SQL片段3大部分时间没有数据返回。</p><p>SQL的写法灵活，但是在有些场景下，我们需要拆分SQL，使优化器可以选择到更好的执行计划。</p><h2>案例八：exists子查询优化一例</h2><p>下面是一个带了exists子查询的SQL，当时这个SQL执行需要120秒。</p><pre><code class=\"language-plain\">SELECT u.id userId, u.mobile, u.created_date createdDate \nFROM `user` u\n    LEFT JOIN user_cash_detail ucd ON u.id= ucd.user_id\nWHERE 1=1\nAND EXISTS( \n    SELECT 1 \n    FROM borrow b \n    WHERE b.user_id= u.id \n    AND b.borrow_no LIKE '202001011212XXX%') \nORDER BY u.id limit 13;\n</code></pre><p>我们来看一下执行计划，要扫描的记录数好像（rows 13）很少，连接的几个表也都有索引，索引的过滤性也都很好（rows=1）。这个SQL性能应该是比较好的，为什么执行需要120s 的时间呢？</p><p><img src=\"https://static001.geekbang.org/resource/image/a2/dd/a2e99857b7ab7f1648b9ee1784b6d8dd.png?wh=1806x304\" alt=\"图片\"></p><p>我们来分析一下这个SQL的执行过程：先执行主查询，从user表获取一行记录，再执行exists里的子查询，检查是否有匹配的记录。如果匹配了，检查已经获取到的记录数是否已经达到limit的要求。如果没匹配，那么从user表获取下一行记录，继续这个过程。如果主表的记录数比较大，而且在执行exists子查询时一直没有匹配到记录，那么整个查询的执行时间就会比较长。</p><p>上一讲中，我们提到了，从5.6开始，MySQL会自动将子查询转换为半连接。但是为什么这个SQL没有被转化为半连接呢？</p><p>原因是8.0之前的版本，MySQL还不支持转换exists子查询。在上面这个例子中，exists子查询中有一个b.borrow_no的条件，看起来过滤性比较高，因此我们手动改写了SQL。原始SQL中的LEFT JOIN user_cash_detail实际上是多余的，SQL改写为这个样子。</p><pre><code class=\"language-plain\">SELECT distinct u.id userId, u.mobile, u.created_date createdDate  \nFROM borrow b \njoin `user` u on b.user_id= u.id \nwhere b.borrow_no LIKE '202001011212XXX%' \norder by u.id limit 13\n</code></pre><p>改写后，SQL的执行时间从120秒降到了3毫秒。</p><p><img src=\"https://static001.geekbang.org/resource/image/9f/16/9fb4f250c0e0884dab71fce5d15b7616.png?wh=1736x262\" alt=\"图片\"></p><p>将exists子查询改写为常规的表关联，有几个地方要注意。</p><ol>\n<li>\n<p>原始SQL中并没有使用到user_cash_detail表，可以将left join去掉。</p>\n</li>\n<li>\n<p>Exists 改成join后，由于borrow表user_id不唯一，可能会有重复数据出现，需要添加distinct去重。</p>\n</li>\n</ol><p>我们在SQL优化的时候，一个基本思想是<strong>尽早过滤掉尽可能多的数据</strong>。这个例子中，先执行exists中的子查询可以提前过滤掉大量数据。</p><p>对于这个案例中的SQL，如果使用了8.0，就不再需要手动改写了。我们来构造一些测试数据验证一下。先创建SQL中的测试表，写入一些数据。</p><pre><code class=\"language-plain\">create table user (\n\tid int not null auto_increment,\n\tmobile varchar(20),\n\tcreated_date datetime,\n\tpadding varchar(2000),\n\tprimary key(id)\n) engine=innodb;\n\ncreate table user_cash_detail(\n\tid int not null auto_increment,\n\tuser_id int not null,\n\tpadding varchar(2000),\n\tprimary key(id),\n\tkey idx_userid(user_id)\n) engine=innodb;\n\ncreate table borrow(\n\tid int not null auto_increment,\n\tuser_id int not null,\n\tborrow_no varchar(30),\n\tpadding varchar(2000),\n\tprimary key(id),\n\tkey idx_user_id(user_id),\n\tkey idx_borrowno(borrow_no)\n) engine=innodb;\n\n\ninsert into user(id, mobile, created_date, padding)\nselect 1000000 + n, 13500000000 + n, date_add('2024-01-01 00:00:00', interval n hour), rpad('', 1000, 'abcd ')\nfrom numbers;\n\ninsert into user_cash_detail(user_id, padding)\nselect 1000000 + n, rpad('', 1000, 'abcd ')\nfrom numbers;\n\ninsert into borrow(user_id, borrow_no, padding)\nselect 1000000 + n - n % 2,  date_format(date_add('2019-06-01 00:00:00', interval n hour), '%Y%m%d%H%i%s'), rpad('', 1000, 'abcd ')\nfrom numbers;\n</code></pre><p>在8.0中，这个SQL自动转换成了半连接。</p><pre><code class=\"language-plain\">explain&gt; SELECT u.id userId, u.mobile, u.created_date createdDate \nFROM user u\n    LEFT JOIN user_cash_detail ucd ON u.id= ucd.user_id\nWHERE 1= 1\nAND EXISTS( \n    SELECT 1 \n    FROM borrow b \n    WHERE b.user_id= u.id \n    AND b.borrow_no LIKE '202007201%') \nORDER BY u.id limit 13;\n\n+----+--------------+-------------+--------+--------------------------+--------------+---------+---------------------+------+----------+---------------------------------+\n| id | select_type  | table       | type   | possible_keys            | key          | key_len | ref                 | rows | filtered | Extra                           |\n+----+--------------+-------------+--------+--------------------------+--------------+---------+---------------------+------+----------+---------------------------------+\n|  1 | SIMPLE       | &lt;subquery2&gt; | ALL    | NULL                     | NULL         | NULL    | NULL                | NULL |   100.00 | Using temporary; Using filesort |\n|  1 | SIMPLE       | u           | eq_ref | PRIMARY                  | PRIMARY      | 4       | &lt;subquery2&gt;.user_id |    1 |   100.00 | NULL                            |\n|  1 | SIMPLE       | ucd         | ref    | idx_userid               | idx_userid   | 4       | &lt;subquery2&gt;.user_id |    1 |   100.00 | Using where; Using index        |\n|  2 | MATERIALIZED | b           | range  | idx_user_id,idx_borrowno | idx_borrowno | 123     | NULL                |   10 |   100.00 | Using index condition           |\n+----+--------------+-------------+--------+--------------------------+--------------+---------+---------------------+------+----------+---------------------------------+\n</code></pre><h2>案例九：range和ref</h2><p>优化器在计算REF和Range的访问成本时，使用了不同的公式。在有些情况下，使用同一个索引，虽然range使用了更多的索引字段，但是成本比REF高，有时Range的成本比全表扫描还要高，此时优化器会使用REF访问路径，而不是效率更高的Range。</p><p>下面的这个例子就是这种情况。这是在5.6版本中遇到的问题。先创建一个表，写入一些模拟数据。</p><pre><code class=\"language-plain\">mysql&gt; create table mysql_stat(\n    id int not null auto_increment,\n    tenant_id int not null,\n    instance_name varchar(30) not null,\n    check_time datetime not null,\n    padding varchar(200),\n    primary key(id),\n    key idx_tenantid_instname_checktime(tenant_id, instance_name, check_time)\n  ) engine=innodb;\n\n\nmysql&gt; insert into mysql_stat(tenant_id, instance_name, check_time, padding)\nselect 1, 'dtstack-dev1:3306', \n  date_add('2024-01-01 00:00:00', interval n * 10 second) as check_time,\n  rpad('x', 100, 'abcd ')\nfrom numbers_1m\n\nmysql&gt; select min(check_time), max(check_time) from  mysql_stat;\n+---------------------+---------------------+\n| min(check_time)     | max(check_time)     |\n+---------------------+---------------------+\n| 2024-01-01 00:00:00 | 2024-04-25 17:46:30 |\n+---------------------+---------------------+\n</code></pre><p>我们来看一下这个SQL的执行计划，type为ref，只用到了tenant_id和instance_name的索引条件。</p><pre><code class=\"language-plain\">mysql&gt; explain SELECT * \nFROM mysql_stat  \nWHERE tenant_id = 1 \n  and instance_name='dtstack-dev1:3306' \n  and check_time &gt;='2024-02-01' and check_time &lt;= '2024-03-01' \nORDER BY check_time desc limit 1\\G\n\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: mysql_stat\n         type: ref\npossible_keys: idx_tenantid_instname_checktime\n          key: idx_tenantid_instname_checktime\n      key_len: 36\n          ref: const,const\n         rows: 468284\n        Extra: Using where\n</code></pre><p>check_time字段上的条件，本来也可以用来过滤数据，但是优化器却没有使用。在我的测试环境中，这个SQL耗时1秒多。从慢日志中，可以观察到SQL扫描了48万行数据。</p><pre><code class=\"language-plain\"># Query_time: 1.245558  Lock_time: 0.000281 Rows_sent: 1  Rows_examined: 481600\nSET timestamp=1725604597;\nSELECT *\nFROM mysql_stat\nWHERE tenant_id = 1\n  and instance_name='dtstack-dev1:3306'\n  and check_time &gt;='2024-02-01' and check_time &lt;= '2024-03-01'\nORDER BY check_time desc limit 1;\n</code></pre><p>我们给这个SQL加上一个force index提示。</p><pre><code class=\"language-plain\">mysql&gt; explain SELECT * \nFROM mysql_stat  force index(idx_tenantid_instname_checktime)\nWHERE tenant_id = 1 \n  and instance_name='dtstack-dev1:3306' \n  and check_time &gt;='2024-02-01' and check_time &lt;= '2024-03-01'\nORDER BY check_time desc limit 1\\G\n\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: mysql_stat\n         type: range\npossible_keys: idx_tenantid_instname_checktime\n          key: idx_tenantid_instname_checktime\n      key_len: 41\n          ref: NULL\n         rows: 468284\n        Extra: Using index condition\n</code></pre><p>加上force index之后，执行计划type变成了range。观察慢日志，SQL只扫描了1行数据，执行时间不到1毫秒。</p><pre><code class=\"language-plain\"># Query_time: 0.000468  Lock_time: 0.000162 Rows_sent: 1  Rows_examined: 1\nSET timestamp=1725604885;\nSELECT *\nFROM mysql_stat  force index(idx_tenantid_instname_checktime)\nWHERE tenant_id = 1\n  and instance_name='dtstack-dev1:3306'\n  and check_time &gt;='2024-02-01' and check_time &lt;= '2024-03-01'\nORDER BY check_time desc limit 1;\n</code></pre><p>从optimizer trace中可以看到，加了force index后，ref的成本还是比range低。</p><pre><code class=\"language-plain\">\"considered_execution_plans\": [\n  {\n    \"plan_prefix\": [\n    ],\n    \"table\": \"`mysql_stat` FORCE INDEX (`idx_tenantid_instname_checktime`)\",\n    \"best_access_path\": {\n      \"considered_access_paths\": [\n        {\n          \"access_type\": \"ref\",\n          \"index\": \"idx_tenantid_instname_checktime\",\n          \"rows\": 468284,\n          \"cost\": 123354,\n          \"chosen\": true\n        },\n        {\n          \"access_type\": \"range\",\n          \"rows\": 351213,\n          \"cost\": 655599,\n          \"chosen\": false\n        }\n      ]\n    },\n    \"cost_for_plan\": 123354,\n    \"rows_for_plan\": 468284,\n    \"chosen\": true\n  }\n]\n</code></pre><p>但是优化器最终还是选择了range，因为range能用到更多的索引字段。</p><pre><code class=\"language-plain\">\"attached_conditions_computation\": [\n  {\n    \"access_type_changed\": {\n      \"table\": \"`mysql_stat` FORCE INDEX (`idx_tenantid_instname_checktime`)\",\n      \"index\": \"idx_tenantid_instname_checktime\",\n      \"old_type\": \"ref\",\n      \"new_type\": \"range\",\n      \"cause\": \"uses_more_keyparts\"\n    }\n  }\n]\n</code></pre><p>上面的这个SQL，在5.7和8.0的环境中，不需要加force index，也会使用效率更高的range访问路径。有兴趣的话，你可以自己测试一下，使用优化器跟踪对比一下区别。</p><h2>案例十：in参数列表过长导致的全表扫描</h2><p>这是一个在MySQL 5.6中遇到的性能问题。我们来看这个单表查询的SQL。表里有几千万行数据。</p><pre><code class=\"language-plain\">SELECT *\nFROM t_exp t\nWHERE t.link_id in (x,x,x, ......)\nand t.com_id = xx\nand t.expense in (x,x,x)\nand t.link_type= 1 \nand ledger_status= 1 \nAND status = 1\n</code></pre><p>表上有一个唯一索引。where条件中，link_id、com_id、expense, link_type这几个字段是索引的前缀。</p><pre><code class=\"language-plain\">UNIQUE KEY uk (\n  link_id,\n  com_id,\n  expense,\n  link_type,\n  link_com_id,\n  trans_batch_id,\n  status)\n</code></pre><p>理论上这个SQL是可以用上这个索引的，但是SQL却使用了全表扫描。而且即使加上force index提示，还是全表扫描。</p><p>SQL中link_id传入了几万个，我尝试着减少link_id的个数，当数量少于某个临界值时，就可以用上索引了，查询的性能也没有问题。但是为什么当IN列表中的参数多一点时，就使用全表扫描了呢？</p><p>我们来对比下这两种情况下的优化器跟踪信息。</p><ul>\n<li>使用全表扫描时的跟踪信息</li>\n</ul><p>当IN传入的参数超过一定的个数后，优化器只考虑了全表扫描。从considered_execution_plans中可以看出这一点。</p><p><img src=\"https://static001.geekbang.org/resource/image/99/d4/997f695c15fe43546a8c867e6a8ddbd4.png?wh=884x800\" alt=\"图片\"></p><p><img src=\"https://static001.geekbang.org/resource/image/75/4b/756d79ec6de5ac7f25e4e5f585b8004b.png?wh=684x698\" alt=\"图片\"></p><ul>\n<li>使用索引时的跟踪信息</li>\n</ul><p>将IN的参数减少到某个临界值之后，优化器考虑了range访问路径，并且基于成本，选择了range执行计划。</p><p><img src=\"https://static001.geekbang.org/resource/image/80/c4/8001e3be24849ddd22032fcf46f998c4.png?wh=1820x690\" alt=\"图片\"><br>\n<img src=\"https://static001.geekbang.org/resource/image/e3/c5/e33a4bca4d29f4946e1cca5d77dc40c5.png?wh=872x798\" alt=\"图片\"><br>\n<img src=\"https://static001.geekbang.org/resource/image/22/17/220a5545364818d9c76581d10f1d4217.png?wh=692x706\" alt=\"图片\"></p><p>当in条件中的值超过一定数量时，优化器会放弃使用range执行计划。原因是MySQL限制了生成range执行计划时使用的内存，当IN参数列表太长时，消耗的内存太多，超出了限制，因此放弃使用range执行计划，最终使用了全表扫描。MySQL 5.6中，range优化内存的上限是固定的。MySQL 5.7引入了参数range_optimizer_max_mem_size，我们可以调整这个参数来解决in参数列表过长无法使用索引的问题。实际上，在5.7版本中，如果in参数列表过长导致无法使用range优化，会有这样的warning信息。</p><pre><code class=\"language-plain\">Warning    3170    Memory capacity of N bytes for\n                   'range_optimizer_max_mem_size' exceeded. Range\n                   optimization was not done for this query.\n</code></pre><p>根据官方文档的描述，每个OR条件使用230字节，每个AND条件使用125字节，单个字段上的IN条件，会转换成OR。多个字段使用IN，会以组合形式展开，比如 c1 in (a,b) and c2 in (x,y,z)会转换成 (c1 = a and c2 = x) or (c1 = a and c2=y) or ( c1=a and c2=z) or (c1 = b and c2 = x) or (c1 = b and c2=y) or ( c1=b and c2=z) 。</p><p>我们案例中的SQL，有2个in条件会在range优化时展开。</p><pre><code class=\"language-plain\">SELECT *\nFROM t_exp t\nWHERE t.link_id in (x,x,x,…)\nand t.com_id = xx\nand t.expense in (x,x,x)\nand t.link_type= 1 \nand ledger_status= 1 \nAND status = 1\n</code></pre><p>怎么解决这个问题呢？一个方法是减少IN里面传入的参数个数，但这需要修改代码。所以当时我采用另外一种方法，调整索引字段顺序，将expense字段调整到了link_com_id之后。因为SQL缺少link_com_id的条件，调整索引字段顺序后，只需要展开link_id，而不是link_id和expense的组合，这样SQL就用上了索引。</p><pre><code class=\"language-plain\">UNIQUE KEY uk_new (\n  link_id,\n  com_id,\n  link_type,\n  link_com_id,\n  expense, \n  trans_batch_id,\n  status)\n</code></pre><h2>案例十一：数据倾斜引起的性能问题</h2><p>下面这个SQL是在一个系统压测时发现的。</p><pre><code class=\"language-plain\">select *\nFROM trans_001 a LEFT JOIN purchase_001 b \n\nON a.serial_no = b.order_no \nAND a.dist_name = b.inst_id \nAND a.alino = b.alino \n\nWHERE b.order_no IS NULL \nAND a.serial_no &gt;= '201809200000057858291ALI'\nAND a.serial_no &lt;= '201809216100342526601ALI' \nAND a.business_code = 'xx' \nAND a.trans_date = '20180921';\n</code></pre><p>这是一个两表连接的SQL，当时这个SQL执行了两百多秒，从慢日志中看到扫描行数有1.1亿。下面是当时诊断报告的输出。</p><p><img src=\"https://static001.geekbang.org/resource/image/3b/6d/3b66489b25903a17facc101a80c5a16d.png?wh=964x412\" alt=\"图片\"></p><p>这个系统使用了分库分表，这两个表大概有几十万行数据。SQL的执行计划并没有问题，连接条件中的字段上也建立了正确的联合索引。但是为什么扫描行数会这么高呢？你是不是会怀疑慢SQL的输出有问题？</p><p>有经验的同学可能已经想到原因了，这其实是数据倾斜引起的问题。分别查看2个表中连接条件上的数据分布就能发现问题。</p><pre><code class=\"language-plain\">select serial_no, dist_name, alino, count(*)\nfrom trans_001\ngroup by serial_no, dist_name, alino\norder by count(*) desc limit 10;\n\nselect order_no, inst_id, alino, count(*)\nfrom purchase_001\ngroup by order_no, inst_id, alino\norder by count(*) desc limit 10;\n</code></pre><p>只要某个组合条件下的记录数超过1万，连接时扫描的记录数就会超过1亿。找到问题后，需要业务方来分析为什么会有这样的数据，并进行相应的处理。</p><h2>案例十二：Range checked for each record</h2><p>MySQL优化器在评估一个索引的访问效率时，要么使用Index Dive，要么使用索引统计信息。在表连接时，如果连接条件是一个范围，那么对于驱动表中的每一行记录，都需要进行一次Index Dive，来评估被驱动表里满足条件的记录数。这种情况下，执行计划的Extra 列中会显示“Range checked for each record”，很多时候，这也是一个查询性能不好的信号。</p><p>我们来看下面这个例子。</p><pre><code class=\"language-plain\">SELECT t1.ppd , (\n    SELECT sum(amount) AS total_amount        \n    FROM `order`\n    WHERE pay_date &lt;= t1.ppd         \n    AND pay_date &gt;= date_sub(t1.ppd, INTERVAL 7 DAY)\n) AS total_amount\nFROM (\n    select distinct pay_date as ppd \n    from `order`\n    where pay_date is not null\n) t1\n</code></pre><p><img src=\"https://static001.geekbang.org/resource/image/1f/yy/1f3c045f96b313fee457f639caa9b0yy.png?wh=1920x432\" alt=\"图片\"></p><p>这样的SQL还有优化的空间吗？我们来尝试一下。先准备一点测试数据。</p><pre><code class=\"language-plain\">create table t_order(\n\tid int not null auto_increment,\n\tpay_date date not null,\n\tamount int not null,\n\tpadding varchar(2000),\n\tprimary key(id),\n\tkey idx_paydate(pay_date)\n) engine=innodb;\n\ninsert into t_order(pay_date, amount, padding)\nselect date_add('2023-01-01', interval n % 365 day), \n    2000 + n % 1000, \n    rpad('', 1000, 'abcd ')\nfrom numbers;\n</code></pre><p>在我的测试环境中，原始SQL耗时35秒。</p><pre><code class=\"language-plain\"># Query_time: 35.923849  \n# Lock_time: 0.000086 \n# Rows_sent: 365  \n# Rows_examined: 3650365\nSELECT t1.ppd , (SELECT sum(amount) AS total_amount        \n    FROM t_order\n    WHERE pay_date &lt;= t1.ppd         \n    AND pay_date &gt;= date_sub(t1.ppd, INTERVAL 7 DAY) ) AS total_amount\nFROM (\n    select distinct pay_date as ppd \n    from t_order\n    where pay_date is not null\n) t1;\n</code></pre><p>我尝试把SQL改写成表连接，执行时间减少了一些。</p><pre><code class=\"language-plain\"># Query_time: 7.566888  \n# Lock_time: 0.000050 \n# Rows_sent: 365  \n# Rows_examined: 365\nSELECT t1.ppd, sum(amount) AS leiji_amount\nFROM  (select distinct pay_date as ppd \n       from t_order \n       where pay_date is not null) t1\n    , t_order t2 \nWHERE t1.ppd &gt;= t2. pay_date\n    AND t2.pay_date &gt;= date_sub(t1.ppd, INTERVAL 7 DAY)\nGROUP BY t1.ppd;\n</code></pre><p>就这个SQL的逻辑，我们还可以使用MySQL 8.0的窗口函数，这样SQL执行又更快了一些。</p><pre><code class=\"language-plain\"># Query_time: 0.776545  \n# Lock_time: 0.000046 \n# Rows_sent: 365  \n# Rows_examined: 730\nselect pay_date, sum(total_amount) over(\n    order by pay_date \n    range BETWEEN INTERVAL 7 DAY PRECEDING AND CURRENT ROW)\nfrom (\n    select pay_date, sum(amount) as total_amount\n    from t_order\n    where pay_date is not null\n    group by pay_date\n) t;\n</code></pre><p>考虑到SQL中只用到了2个字段，我们给这个SQL建立一个联合索引。</p><pre><code class=\"language-plain\">alter table t_order add key idx_paydate_amount(pay_date, amount);\n</code></pre><p>这样执行的速度又提升了一些。</p><pre><code class=\"language-plain\"># Query_time: 0.090399  \n# Lock_time: 0.000026 \n# Rows_sent: 365  \n# Rows_examined: 730\nselect pay_date, sum(total_amount) over(\n    order by pay_date\n    range BETWEEN INTERVAL 7 DAY PRECEDING AND CURRENT ROW)\nfrom (\n    select pay_date, sum(amount) as total_amount\n    from t_order\n    where pay_date is not null\n    group by pay_date\n) t;\n</code></pre><p>我们的测试表里，只写入了10000行数据，如果你有兴趣，可以尝试写入10万行或100万行数据，对比下这几种情况下几个SQL的耗时。</p><h2>总结</h2><p>SQL优化是一项基本的技能。你需要掌握索引的特点，了解不同表连接算法的特点和适用场景，还需要了解优化器的一些工作原理。有的时候你可能需要改写SQL，或者使用SQL提示，来获得更好的性能。</p><p>这两讲的十几个例子，都是从真实的业务场景中挑选出来的，当时使用的版本包括5.5、5.6、5.7。可以看到，在8.0中，有一些SQL实际上优化器已经能自动优化得更好了。这也是我们要使用新版本的一个重要的原因。</p><h2>思考题</h2><p>下面这类SQL按多个表的字段来排序，请分析下这么排序，对SQL性能的影响是什么？如果只使用一个表的字段来排序，性能上会有什么区别吗？</p><pre><code class=\"language-plain\">select * \nfrom t1, t2, t3\nwhere t1.c1 = t2.c1\nand t2.c2 = t3.c3\norder by t1.s1, t2.s2\nlimit 100;\n</code></pre><p>期待你的思考，欢迎在留言区中与我交流。如果今天的课程让你有所收获，也欢迎转发给有需要的朋友。我们下节课再见！</p>","comments":[{"had_liked":false,"id":394998,"user_name":"叶明","can_delete":false,"product_type":"c1","uid":1412429,"ip_address":"江苏","ucode":"D0B4B7660DA766","user_header":"https://static001.geekbang.org/account/avatar/00/15/8d/4d/992070e8.jpg","comment_is_top":false,"comment_ctime":1729060319,"is_pvip":false,"replies":[{"id":143444,"content":"是的。\n\n我觉得这里比较大的一个区别是，如果用了多个表的字段来排序，那么需要将表连接操作全部执行完成后，才开始排序。\n\n如果只用到一个表的字段排序，就有机会先对这个表的数据进行排序，然后再去连接其他表，到达limit的记录数之后，就可以退出查询了。","user_name":"作者回复","user_name_real":"编辑","uid":3898827,"ctime":1729147204,"ip_address":"浙江","comment_id":394998,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100799401,"comment_content":"\n1、对 SQL 性能的影响，t1.s1 和 t2.s2 这两个字段来源不同表，并且没有关联关系，驱动表只有一个，当其中一个字段有序时，无法保证另一个字段也有序，因此必须使用到临时表和文件排序，另外如果数据量较大，则还会使用到更慢的磁盘临时表来处理。\n2、如果只使用一个表的字段来排序，性能上会有什么区别吗？如果表上这一个用来排序的字段上有索引，那么以这个表作为驱动表，一来不用建立临时表和排序，只需要有序遍历这个索引的前 100条记录就可以返回了，二来只用返回 100 条数据，大大减少了扫描行数","like_count":1,"discussions":[{"author":{"id":3898827,"avatar":"https://static001.geekbang.org/account/avatar/00/3b/7d/cb/fa3dae58.jpg","nickname":"俊达","note":"","ucode":"F79BF9651AD086","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":652557,"discussion_content":"是的。\n\n我觉得这里比较大的一个区别是，如果用了多个表的字段来排序，那么需要将表连接操作全部执行完成后，才开始排序。\n\n如果只用到一个表的字段排序，就有机会先对这个表的数据进行排序，然后再去连接其他表，到达limit的记录数之后，就可以退出查询了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1729147204,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]}]}