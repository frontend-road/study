{"id":466825,"title":"45｜阶段实操（8）：构建一个简单的KV server-配置/测试/监控/CI/CD","content":"<p>你好，我是陈天。</p><p>终于来到了我们这个 KV server 系列的终章。其实原本 KV server 我只计划了 4 讲，但现在 8 讲似乎都还有些意犹未尽。虽然这是一个“简单”的 KV server，它没有复杂的性能优化 —— 我们只用了一句 unsafe；也没有复杂的生命周期处理 —— 只有零星 'static 标注；更没有支持集群的处理。</p><p>然而，如果你能够理解到目前为止的代码，甚至能独立写出这样的代码，那么，你已经具备足够的、能在一线大厂开发的实力了，国内我不是特别清楚，但在北美这边，保守一些地说，300k+ USD 的 package 应该可以轻松拿到。</p><p>今天我们就给KV server项目收个尾，结合之前梳理的实战中 Rust 项目应该考虑的问题，来聊聊和生产环境有关的一些处理，按开发流程，主要讲五个方面：配置、集成测试、性能测试、测量和监控、CI/CD。</p><h2>配置</h2><p>首先在 Cargo.toml 里添加 <a href=\"https://github.com/serde-rs/serde\">serde</a> 和 <a href=\"https://github.com/alexcrichton/toml-rs\">toml</a>。我们计划使用 toml 做配置文件，serde 用来处理配置的序列化和反序列化：</p><pre><code class=\"language-rust\">[dependencies]\n...\nserde = { version = \"1\", features = [\"derive\"] } # 序列化/反序列化\n...\ntoml = \"0.5\" # toml 支持\n...\n</code></pre><!-- [[[read_end]]] --><p>然后来创建一个 src/config.rs，构建 KV server 的配置：</p><pre><code class=\"language-rust\">use crate::KvError;\nuse serde::{Deserialize, Serialize};\nuse std::fs;\n\n#[derive(Clone, Debug, Serialize, Deserialize, PartialEq)]\npub struct ServerConfig {\n    pub general: GeneralConfig,\n    pub storage: StorageConfig,\n    pub tls: ServerTlsConfig,\n}\n\n#[derive(Clone, Debug, Serialize, Deserialize, PartialEq)]\npub struct ClientConfig {\n    pub general: GeneralConfig,\n    pub tls: ClientTlsConfig,\n}\n\n#[derive(Clone, Debug, Serialize, Deserialize, PartialEq)]\npub struct GeneralConfig {\n    pub addr: String,\n}\n\n#[derive(Clone, Debug, Serialize, Deserialize, PartialEq)]\n#[serde(tag = \"type\", content = \"args\")]\npub enum StorageConfig {\n    MemTable,\n    SledDb(String),\n}\n\n#[derive(Clone, Debug, Serialize, Deserialize, PartialEq)]\npub struct ServerTlsConfig {\n    pub cert: String,\n    pub key: String,\n    pub ca: Option&lt;String&gt;,\n}\n\n#[derive(Clone, Debug, Serialize, Deserialize, PartialEq)]\npub struct ClientTlsConfig {\n    pub domain: String,\n    pub identity: Option&lt;(String, String)&gt;,\n    pub ca: Option&lt;String&gt;,\n}\n\nimpl ServerConfig {\n    pub fn load(path: &amp;str) -&gt; Result&lt;Self, KvError&gt; {\n        let config = fs::read_to_string(path)?;\n        let config: Self = toml::from_str(&amp;config)?;\n        Ok(config)\n    }\n}\n\nimpl ClientConfig {\n    pub fn load(path: &amp;str) -&gt; Result&lt;Self, KvError&gt; {\n        let config = fs::read_to_string(path)?;\n        let config: Self = toml::from_str(&amp;config)?;\n        Ok(config)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn server_config_should_be_loaded() {\n        let result: Result&lt;ServerConfig, toml::de::Error&gt; =\n            toml::from_str(include_str!(\"../fixtures/server.conf\"));\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn client_config_should_be_loaded() {\n        let result: Result&lt;ClientConfig, toml::de::Error&gt; =\n            toml::from_str(include_str!(\"../fixtures/client.conf\"));\n        assert!(result.is_ok());\n    }\n}\n</code></pre><p>你可以看到，在 Rust 下，有了 serde 的帮助，处理任何已知格式的配置文件，是多么容易的一件事情。我们<strong>只需要定义数据结构，并为数据结构使用 Serialize/Deserialize 派生宏，就可以处理任何支持 serde 的数据结构</strong>。</p><p>我还写了个 examples/gen_config.rs（你可以自行去查阅它的代码），用来生成配置文件，下面是生成的服务端的配置：</p><pre><code class=\"language-rust\">[general]\naddr = '127.0.0.1:9527'\n\n[storage]\ntype = 'SledDb'\nargs = '/tmp/kv_server'\n\n[tls]\ncert = \"\"\"\n-----BEGIN CERTIFICATE-----\\r\nMIIBdzCCASmgAwIBAgIICpy02U2yuPowBQYDK2VwMDMxCzAJBgNVBAYMAkNOMRIw\\r\nEAYDVQQKDAlBY21lIEluYy4xEDAOBgNVBAMMB0FjbWUgQ0EwHhcNMjEwOTI2MDEy\\r\nNTU5WhcNMjYwOTI1MDEyNTU5WjA6MQswCQYDVQQGDAJDTjESMBAGA1UECgwJQWNt\\r\nZSBJbmMuMRcwFQYDVQQDDA5BY21lIEtWIHNlcnZlcjAqMAUGAytlcAMhAK2Z2AjF\\r\nA0uiltNuCvl6EVFl6tpaS/wJYB5IdWT2IISdo1QwUjAcBgNVHREEFTATghFrdnNl\\r\ncnZlci5hY21lLmluYzATBgNVHSUEDDAKBggrBgEFBQcDATAMBgNVHRMEBTADAQEA\\r\nMA8GA1UdDwEB/wQFAwMH4AAwBQYDK2VwA0EASGOmOWFPjbGhXNOmYNCa3lInbgRy\\r\niTNtB/5kElnbKkhKhRU7yQ8HTHWWkyU5WGWbOOIXEtYp+5ERUJC+mzP9Bw==\\r\n-----END CERTIFICATE-----\\r\n\"\"\"\nkey = \"\"\"\n-----BEGIN PRIVATE KEY-----\\r\nMFMCAQEwBQYDK2VwBCIEIPMyINaewhXwuTPUufFO2mMt/MvQMHrGDGxgdgfy/kUu\\r\noSMDIQCtmdgIxQNLopbTbgr5ehFRZeraWkv8CWAeSHVk9iCEnQ==\\r\n-----END PRIVATE KEY-----\\r\n\"\"\"\n</code></pre><p>有了配置文件的支持，就可以在 <a href=\"http://lib.rs\">lib.rs</a> 下写一些辅助函数，让我们创建服务端和客户端更加简单：</p><pre><code class=\"language-rust\">mod config;\nmod error;\nmod network;\nmod pb;\nmod service;\nmod storage;\n\npub use config::*;\npub use error::KvError;\npub use network::*;\npub use pb::abi::*;\npub use service::*;\npub use storage::*;\n\nuse anyhow::Result;\nuse tokio::net::{TcpListener, TcpStream};\nuse tokio_rustls::client;\nuse tokio_util::compat::FuturesAsyncReadCompatExt;\nuse tracing::info;\n\n/// 通过配置创建 KV 服务器\npub async fn start_server_with_config(config: &amp;ServerConfig) -&gt; Result&lt;()&gt; {\n    let acceptor =\n        TlsServerAcceptor::new(&amp;config.tls.cert, &amp;config.tls.key, config.tls.ca.as_deref())?;\n\n    let addr = &amp;config.general.addr;\n    match &amp;config.storage {\n        StorageConfig::MemTable =&gt; start_tls_server(addr, MemTable::new(), acceptor).await?,\n        StorageConfig::SledDb(path) =&gt; start_tls_server(addr, SledDb::new(path), acceptor).await?,\n    };\n\n    Ok(())\n}\n\n/// 通过配置创建 KV 客户端\npub async fn start_client_with_config(\n    config: &amp;ClientConfig,\n) -&gt; Result&lt;YamuxCtrl&lt;client::TlsStream&lt;TcpStream&gt;&gt;&gt; {\n    let addr = &amp;config.general.addr;\n    let tls = &amp;config.tls;\n\n    let identity = tls.identity.as_ref().map(|(c, k)| (c.as_str(), k.as_str()));\n    let connector = TlsClientConnector::new(&amp;tls.domain, identity, tls.ca.as_deref())?;\n    let stream = TcpStream::connect(addr).await?;\n    let stream = connector.connect(stream).await?;\n\n    // 打开一个 stream\n    Ok(YamuxCtrl::new_client(stream, None))\n}\n\nasync fn start_tls_server&lt;Store: Storage&gt;(\n    addr: &amp;str,\n    store: Store,\n    acceptor: TlsServerAcceptor,\n) -&gt; Result&lt;()&gt; {\n    let service: Service&lt;Store&gt; = ServiceInner::new(store).into();\n    let listener = TcpListener::bind(addr).await?;\n    info!(\"Start listening on {}\", addr);\n    loop {\n        let tls = acceptor.clone();\n        let (stream, addr) = listener.accept().await?;\n        info!(\"Client {:?} connected\", addr);\n\n        let svc = service.clone();\n        tokio::spawn(async move {\n            let stream = tls.accept(stream).await.unwrap();\n            YamuxCtrl::new_server(stream, None, move |stream| {\n                let svc1 = svc.clone();\n                async move {\n                    let stream = ProstServerStream::new(stream.compat(), svc1.clone());\n                    stream.process().await.unwrap();\n                    Ok(())\n                }\n            });\n        });\n    }\n}\n</code></pre><p>有了 start_server_with_config 和 start_client_with_config 这两个辅助函数，我们就可以简化 src/server.rs 和 src/client.rs 了。下面是 src/server.rs 的新代码：</p><pre><code class=\"language-rust\">use anyhow::Result;\nuse kv6::{start_server_with_config, ServerConfig};\n\n#[tokio::main]\nasync fn main() -&gt; Result&lt;()&gt; {\n    tracing_subscriber::fmt::init();\n    let config: ServerConfig = toml::from_str(include_str!(\"../fixtures/server.conf\"))?;\n\n    start_server_with_config(&amp;config).await?;\n\n    Ok(())\n}\n</code></pre><p>可以看到，整个代码简洁了很多。在这个重构的过程中，还有一些其它改动，你可以看 GitHub repo 下 45 讲的 diff_config。</p><h2>集成测试</h2><p>之前我们写了很多单元测试，但还没有写过一行集成测试。今天就来写一个简单的集成测试，确保客户端和服务器完整的交互工作正常。</p><p>之前提到在 Rust 里，集成测试放在 tests 目录下，每个测试编成单独的二进制。所以首先，我们创建和 src 平行的 tests 目录。然后再创建 tests/server.rs，填入以下代码：</p><pre><code class=\"language-rust\">use anyhow::Result;\nuse kv6::{\n    start_client_with_config, start_server_with_config, ClientConfig, CommandRequest,\n    ProstClientStream, ServerConfig, StorageConfig,\n};\nuse std::time::Duration;\nuse tokio::time;\n\n#[tokio::test]\nasync fn yamux_server_client_full_tests() -&gt; Result&lt;()&gt; {\n    let addr = \"127.0.0.1:10086\";\n\n    let mut config: ServerConfig = toml::from_str(include_str!(\"../fixtures/server.conf\"))?;\n    config.general.addr = addr.into();\n    config.storage = StorageConfig::MemTable;\n\n    // 启动服务器\n    tokio::spawn(async move {\n        start_server_with_config(&amp;config).await.unwrap();\n    });\n\n    time::sleep(Duration::from_millis(10)).await;\n    let mut config: ClientConfig = toml::from_str(include_str!(\"../fixtures/client.conf\"))?;\n    config.general.addr = addr.into();\n\n    let mut ctrl = start_client_with_config(&amp;config).await.unwrap();\n    let stream = ctrl.open_stream().await?;\n    let mut client = ProstClientStream::new(stream);\n\n    // 生成一个 HSET 命令\n    let cmd = CommandRequest::new_hset(\"table1\", \"hello\", \"world\".to_string().into());\n    client.execute_unary(&amp;cmd).await?;\n\n    // 生成一个 HGET 命令\n    let cmd = CommandRequest::new_hget(\"table1\", \"hello\");\n    let data = client.execute_unary(&amp;cmd).await?;\n\n    assert_eq!(data.status, 200);\n    assert_eq!(data.values, &amp;[\"world\".into()]);\n\n    Ok(())\n}\n</code></pre><p>可以看到，<strong>集成测试的写法和单元测试其实很类似，只不过我们不需要再使用 #[cfg(test)] 来做条件编译</strong>。</p><p>如果你的集成测试比较复杂，需要比较多的辅助代码，那么你还可以在 tests 下 cargo new 出一个项目，然后在那个项目里撰写辅助代码和测试代码。如果你对此感兴趣，可以看 <a href=\"https://github.com/hyperium/tonic/tree/master/tests\">tonic 的集成测试</a>。不过注意了，集成测试和你的 crate 用同样的条件编译，所以在集成测试里，无法使用单元测试中构建的辅助代码。</p><h2>性能测试</h2><p>在之前不断完善 KV server 的过程中，你一定会好奇：我们的 KV server 性能究竟如何呢？那来写一个关于 Pub/Sub 的性能测试吧。</p><p>基本的想法是我们连上 100 个 subscriber 作为背景，然后看 publisher publish 的速度。</p><p>因为 BROADCAST_CAPACITY 有限，是 128，当 publisher 速度太快，而导致 server 不能及时往 subscriber 发送时，server 接收 client 数据的速度就会降下来，无法接收新的 client，整体的 publish 的速度也会降下来，所以这个测试能够了解 server 处理 publish 的速度。</p><p>为了确认这一点，我们在 start_tls_server() 函数中，在 process() 之前，再加个 100ms 的延时，人为减缓系统的处理速度：</p><pre><code class=\"language-rust\">async move {\n    let stream = ProstServerStream::new(stream.compat(), svc1.clone());\n    // 延迟 100ms 处理\n    time::sleep(Duration::from_millis(100)).await;\n    stream.process().await.unwrap();\n    Ok(())\n}\n</code></pre><p>好，现在可以写性能测试了。</p><p>在 Rust 下，我们可以用 <a href=\"https://github.com/bheisler/criterion.rs\">criterion</a> 库。它可以处理基本的性能测试，并生成漂亮的报告。所以在 Cargo.toml 中加入：</p><pre><code class=\"language-rust\">[dev-dependencies]\n...\ncriterion = { version = \"0.3\", features = [\"async_futures\", \"async_tokio\", \"html_reports\"] } # benchmark\n...\nrand = \"0.8\" # 随机数处理\n...\n\n[[bench]]\nname = \"pubsub\"\nharness = false\n</code></pre><p>最后这个 bench section，描述了性能测试的名字，它对应 benches 目录下的同名文件。</p><p>我们创建和 src 平级的 benches，然后再创建 benches/pubsub.rs，添入如下代码：</p><pre><code class=\"language-rust\">use anyhow::Result;\nuse criterion::{criterion_group, criterion_main, Criterion};\nuse futures::StreamExt;\nuse kv6::{\n    start_client_with_config, start_server_with_config, ClientConfig, CommandRequest, ServerConfig,\n    StorageConfig, YamuxCtrl,\n};\nuse rand::prelude::SliceRandom;\nuse std::time::Duration;\nuse tokio::net::TcpStream;\nuse tokio::runtime::Builder;\nuse tokio::time;\nuse tokio_rustls::client::TlsStream;\nuse tracing::info;\n\nasync fn start_server() -&gt; Result&lt;()&gt; {\n    let addr = \"127.0.0.1:9999\";\n    let mut config: ServerConfig = toml::from_str(include_str!(\"../fixtures/server.conf\"))?;\n    config.general.addr = addr.into();\n    config.storage = StorageConfig::MemTable;\n\n    tokio::spawn(async move {\n        start_server_with_config(&amp;config).await.unwrap();\n    });\n\n    Ok(())\n}\n\nasync fn connect() -&gt; Result&lt;YamuxCtrl&lt;TlsStream&lt;TcpStream&gt;&gt;&gt; {\n    let addr = \"127.0.0.1:9999\";\n    let mut config: ClientConfig = toml::from_str(include_str!(\"../fixtures/client.conf\"))?;\n    config.general.addr = addr.into();\n\n    Ok(start_client_with_config(&amp;config).await?)\n}\n\nasync fn start_subscribers(topic: &amp;'static str) -&gt; Result&lt;()&gt; {\n    let mut ctrl = connect().await?;\n    let stream = ctrl.open_stream().await?;\n    info!(\"C(subscriber): stream opened\");\n    let cmd = CommandRequest::new_subscribe(topic.to_string());\n    tokio::spawn(async move {\n        let mut stream = stream.execute_streaming(&amp;cmd).await.unwrap();\n        while let Some(Ok(data)) = stream.next().await {\n            drop(data);\n        }\n    });\n\n    Ok(())\n}\n\nasync fn start_publishers(topic: &amp;'static str, values: &amp;'static [&amp;'static str]) -&gt; Result&lt;()&gt; {\n    let mut rng = rand::thread_rng();\n    let v = values.choose(&amp;mut rng).unwrap();\n\n    let mut ctrl = connect().await.unwrap();\n    let mut stream = ctrl.open_stream().await.unwrap();\n    info!(\"C(publisher): stream opened\");\n\n    let cmd = CommandRequest::new_publish(topic.to_string(), vec![(*v).into()]);\n    stream.execute_unary(&amp;cmd).await.unwrap();\n\n    Ok(())\n}\n\nfn pubsub(c: &amp;mut Criterion) {\n    // tracing_subscriber::fmt::init();\n    // 创建 Tokio runtime\n    let runtime = Builder::new_multi_thread()\n        .worker_threads(4)\n        .thread_name(\"pubsub\")\n        .enable_all()\n        .build()\n        .unwrap();\n    let values = &amp;[\"Hello\", \"Tyr\", \"Goodbye\", \"World\"];\n    let topic = \"lobby\";\n\n    // 运行服务器和 100 个 subscriber，为测试准备\n    runtime.block_on(async {\n        eprint!(\"preparing server and subscribers\");\n        start_server().await.unwrap();\n        time::sleep(Duration::from_millis(50)).await;\n        for _ in 0..100 {\n            start_subscribers(topic).await.unwrap();\n            eprint!(\".\");\n        }\n        eprintln!(\"Done!\");\n    });\n\n    // 进行 benchmark\n    c.bench_function(\"publishing\", move |b| {\n        b.to_async(&amp;runtime)\n            .iter(|| async { start_publishers(topic, values).await })\n    });\n}\n\ncriterion_group! {\n    name = benches;\n    config = Criterion::default().sample_size(10);\n    targets = pubsub\n}\ncriterion_main!(benches);\n</code></pre><p>大部分的代码都很好理解，就是创建服务器和客户端，为测试做准备。说一下这里面核心的 benchmark 代码：</p><pre><code class=\"language-rust\">c.bench_function(\"publishing\", move |b| {\n    b.to_async(&amp;runtime)\n        .iter(|| async { start_publishers(topic, values).await })\n});\n</code></pre><p>对于要测试的代码，我们可以封装成一个函数进行测试。<strong>这里因为要做 async 函数的测试，需要使用 runtime。普通的函数不需要调用 to_async</strong>。对于更多有关 criterion 的用法，可以参考它的文档。</p><p>运行 <code>cargo bench</code> 后，会见到如下打印（如果你的代码无法通过，可以参考 repo 里的 diff_benchmark，我顺便做了一点小重构）：</p><pre><code class=\"language-bash\">preparing server and subscribers....................................................................................................Done!\npublishing              time:   [419.73 ms 426.84 ms 434.20 ms]                     \n                        change: [-1.6712% +1.0499% +3.6586%] (p = 0.48 &gt; 0.05)\n                        No change in performance detected.\n</code></pre><p>可以看到，单个 publish 的处理速度要 426ms，好慢！我们把之前在 start_tls_server() 里加的延迟去掉，再次测试：</p><pre><code class=\"language-bash\">preparing server and subscribers....................................................................................................Done!\npublishing              time:   [318.61 ms 324.48 ms 329.81 ms]                     \n                        change: [-25.854% -23.980% -22.144%] (p = 0.00 &lt; 0.05)\n                        Performance has improved.\n</code></pre><p>嗯，这下 324ms，正好是减去刚才加的 100ms。可是这个速度依旧不合理，凭直觉我们感觉一下这个速度，是 Python 这样的语言还正常，如果是 Rust 也太慢了吧？</p><h2>测量和监控</h2><p>工业界有句名言：如果你无法测量，那你就无法改进（If you can’t measure it, you can’t improve it）。现在知道了 KV server 性能有问题，但并不知道问题出在哪里。我们需要使用合适的测量方式。</p><p>目前，<strong>比较好的端对端的性能监控和测量工具是 jaeger</strong>，我们可以在 KV server/client 侧收集监控信息，发送给 jaeger 来查看在服务器和客户端的整个处理流程中，时间都花费到哪里去了。</p><p>之前我们在 KV server 里使用的日志工具是 tracing，不过日志只是它的诸多功能之一，它还能做 <a href=\"https://docs.rs/tracing/0.1.28/tracing/attr.instrument.html\">instrument</a>，然后配合 <a href=\"https://github.com/open-telemetry/opentelemetry-rust\">opentelemetry</a> 库，我们就可以把 instrument 的结果发送给 jaeger 了。</p><p>好，在 Cargo.toml 里添加新的依赖：</p><pre><code class=\"language-rust\">[dependencies]\n...\nopentelemetry-jaeger = \"0.15\" # opentelemetry jaeger 支持\n...\ntracing-appender = \"0.1\" # 文件日志\ntracing-opentelemetry = \"0.15\" # opentelemetry 支持\ntracing-subscriber = { version = \"0.2\", features = [\"json\", \"chrono\"] } # 日志处理\n</code></pre><p>有了这些依赖后，在 benches/pubsub.rs 里，我们可以在初始化 tracing_subscriber 时，使用 jaeger 和 opentelemetry tracer：</p><pre><code class=\"language-rust\">fn pubsub(c: &amp;mut Criterion) {\n    let tracer = opentelemetry_jaeger::new_pipeline()\n        .with_service_name(\"kv-bench\")\n        .install_simple()\n        .unwrap();\n    let opentelemetry = tracing_opentelemetry::layer().with_tracer(tracer);\n\n    tracing_subscriber::registry()\n        .with(EnvFilter::from_default_env())\n        .with(opentelemetry)\n        .init();\n\n    let root = span!(tracing::Level::INFO, \"app_start\", work_units = 2);\n    let _enter = root.enter();\n    // 创建 Tokio runtime\n\t\t...\n}\n</code></pre><p>设置好 tracing 后，就在系统的主流程上添加相应的 instrument：<br>\n<img src=\"https://static001.geekbang.org/resource/image/f1/a1/f1680244d5c7901ec26181c01bfea8a1.jpg?wh=2312x1379\" alt=\"\"></p><p>新添加的代码你可以看 repo 中的 diff_telemetry。注意 instrument 可以用不同的名称，比如，对于 TlsConnector::new() 函数，可以用 <code>#[instrument(name = \"tls_connector_new\")]</code>，这样它的名字辨识度高一些。</p><p>为主流程中的函数添加完 instrument 后，你需要先打开一个窗口，运行 jaeger（需要 docker）：</p><pre><code class=\"language-bash\">docker run -d -p6831:6831/udp -p6832:6832/udp -p16686:16686 -p14268:14268 jaegertracing/all-in-one:latest\n</code></pre><p>然后带着 RUST_LOG=info 运行 benchmark：</p><pre><code class=\"language-bash\">RUST_LOG=info cargo bench\n</code></pre><p>由于我的 OS X 上没装 docker（docker 不支持 Mac，需要 Linux VM 中转），我就在一个 Ubuntu 虚拟机里运行这两条命令：</p><pre><code class=\"language-bash\">preparing server and subscribers....................................................................................................Done!\npublishing              time:   [1.7464 ms 1.9556 ms 2.2343 ms]                       \nFound 2 outliers among 10 measurements (20.00%)\n  1 (10.00%) high mild\n  1 (10.00%) high severe\n</code></pre><p>并没有做任何事情，似乎只是换了个系统，性能就提升了很多，这给我们一个 tip：也许问题出在 OS X 和 Linux 系统相关的部分。</p><p>不管怎样，已经发送了不少数据给 jaeger，我们到 jaeger 上看看问题出在哪里。</p><p>打开 <a href=\"http://localhost:16686/\">http://localhost:16686/</a>，service 选 kv-bench，Operation 选 app_start，点击 “Find Traces”，我们可以看到捕获的 trace。因为运行了两次 benchmark，所以有两个 app_start 的查询结果：<br>\n<img src=\"https://static001.geekbang.org/resource/image/ec/77/ecd9b1d06debe7fb3fe507befd803877.png?wh=1920x1048\" alt=\"\"></p><p>可以看到，每次 start_client_with_config 都要花 1.6-2.5ms，其中有差不多一小半时间花在了 TlsClientConnector::new() 上：<br>\n<img src=\"https://static001.geekbang.org/resource/image/fe/b6/fe574ccac09ce5434027fce2afebaeb6.png?wh=1920x1210\" alt=\"\"></p><p>如果说 TlsClientConnector::connect() 花不少时间还情有可原，因为这是整个 TLS 协议的握手过程，涉及到网络调用、包的加解密等。<strong>但 TlsClientConnector::new() 就是加载一些证书、创建 TlsConnector 这个数据结构而已，为何这么慢</strong>？</p><p>仔细阅读 TlsClientConnector::new() 的代码，你可以对照注释看：</p><pre><code class=\"language-rust\">#[instrument(name = \"tls_connector_new\", skip_all)]\npub fn new(\n    domain: impl Into&lt;String&gt; + std::fmt::Debug,\n    identity: Option&lt;(&amp;str, &amp;str)&gt;,\n    server_ca: Option&lt;&amp;str&gt;,\n) -&gt; Result&lt;Self, KvError&gt; {\n    let mut config = ClientConfig::new();\n\n    // 如果有客户端证书，加载之\n    if let Some((cert, key)) = identity {\n        let certs = load_certs(cert)?;\n        let key = load_key(key)?;\n        config.set_single_client_cert(certs, key)?;\n    }\n\n    // 加载本地信任的根证书链\n    config.root_store = match rustls_native_certs::load_native_certs() {\n        Ok(store) | Err((Some(store), _)) =&gt; store,\n        Err((None, error)) =&gt; return Err(error.into()),\n    };\n\n    // 如果有签署服务器的 CA 证书，则加载它，这样服务器证书不在根证书链\n    // 但是这个 CA 证书能验证它，也可以\n    if let Some(cert) = server_ca {\n        let mut buf = Cursor::new(cert);\n        config.root_store.add_pem_file(&amp;mut buf).unwrap();\n    }\n\n    Ok(Self {\n        config: Arc::new(config),\n        domain: Arc::new(domain.into()),\n    })\n}\n</code></pre><p>可以发现，它的代码唯一可能影响性能的就是加载本地信任的根证书链的部分。这个代码会和操作系统交互，获取信任的根证书链。也许，这就是影响性能的原因之一？</p><p><strong>那我们将其简单重构一下</strong>。因为根证书链，只有在客户端没有提供用于验证服务器证书的 CA 证书时，才需要，所以可以在没有 CA 证书时，才加载本地的根证书链：</p><pre><code class=\"language-rust\">#[instrument(name = \"tls_connector_new\", skip_all)]\npub fn new(\n    domain: impl Into&lt;String&gt; + std::fmt::Debug,\n    identity: Option&lt;(&amp;str, &amp;str)&gt;,\n    server_ca: Option&lt;&amp;str&gt;,\n) -&gt; Result&lt;Self, KvError&gt; {\n    let mut config = ClientConfig::new();\n\n    // 如果有客户端证书，加载之\n    if let Some((cert, key)) = identity {\n        let certs = load_certs(cert)?;\n        let key = load_key(key)?;\n        config.set_single_client_cert(certs, key)?;\n    }\n\n    // 如果有签署服务器的 CA 证书，则加载它，这样服务器证书不在根证书链\n    // 但是这个 CA 证书能验证它，也可以\n    if let Some(cert) = server_ca {\n        let mut buf = Cursor::new(cert);\n        config.root_store.add_pem_file(&amp;mut buf).unwrap();\n    } else {\n        // 加载本地信任的根证书链\n        config.root_store = match rustls_native_certs::load_native_certs() {\n            Ok(store) | Err((Some(store), _)) =&gt; store,\n            Err((None, error)) =&gt; return Err(error.into()),\n        };\n    }\n\n    Ok(Self {\n        config: Arc::new(config),\n        domain: Arc::new(domain.into()),\n    })\n}\n</code></pre><p>完成这个修改后，我们再运行 <code>RUST_LOG=info cargo bench</code>，现在的性能达到了 1.64ms，相比之前的 1.95ms，提升了 16%。</p><p>打开 jaeger，看最新的 app_start 结果，发现 TlsClientConnector::new() 所花时间降到了 ~12us 左右。嗯，虽然没有抓到服务器本身的 bug，但客户端的 bug 倒是解决了一个。<br>\n<img src=\"https://static001.geekbang.org/resource/image/3c/0b/3cfde740dbe0d4a897e2d4c3684b530b.png?wh=1920x1164\" alt=\"\"></p><p>至于服务器，如果我们看 Service::execute 的主流程，执行速度在 40-60us，问题不大：<br>\n<img src=\"https://static001.geekbang.org/resource/image/7b/31/7be6139668c82fb8b79fb66f3ed06d31.png?wh=1920x1215\" alt=\"\"></p><p>再看服务器的主流程 server_process：<br>\n<img src=\"https://static001.geekbang.org/resource/image/07/63/076402ac25b507295d022b980378e363.png?wh=1920x1040\" alt=\"\"></p><p>这是我们在 start_tls_server() 里额外添加的 tracing span：</p><pre><code class=\"language-rust\">loop {\n\t\tlet root = span!(tracing::Level::INFO, \"server_process\");\n\t\tlet _enter = root.enter();\n\t\t...\n}\n</code></pre><p>把右上角的 trace timeline 改成 trace graph，然后点右侧的 time：<br>\n<img src=\"https://static001.geekbang.org/resource/image/14/41/1499657924a241e43c9d1be467793041.png?wh=1920x1207\" alt=\"\"></p><p>可以看到，主要的服务器时间都花在了 TLS accept 上，所以，<strong>目前服务器没有太多值得优化的地方</strong>。</p><p>由于 tracing 本身也占用不少 CPU，所以我们直接 <code>cargo bench</code> 看看目前的结果：</p><pre><code class=\"language-bash\">preparing server and subscribers....................................................................................................Done!\npublishing              time:   [1.3986 ms 1.4140 ms 1.4474 ms]                       \n                        change: [-26.647% -19.977% -10.798%] (p = 0.00 &lt; 0.05)\n                        Performance has improved.\nFound 2 outliers among 10 measurements (20.00%)\n  2 (20.00%) high severe\n</code></pre><p>不加 RUST_LOG=info 后，整体性能到了 1.4ms。这是我在 Ubuntu 虚拟机下的结果。</p><p>我们再回到 OS X 下测试，看看 TlsClientConnector::new() 的修改，对OS X 是否有效：</p><pre><code class=\"language-bash\">preparing server and subscribers....................................................................................................Done!\npublishing              time:   [1.4086 ms 1.4229 ms 1.4315 ms]                       \n                        change: [-99.570% -99.563% -99.554%] (p = 0.00 &lt; 0.05)\n                        Performance has improved.\n</code></pre><p>嗯，在我的 OS X下，现在整体性能也到了 1.4ms 的水平。这也意味着，在有 100 个 subscribers 的情况下，我们的 KV server 每秒钟可以处理 714k publish 请求；而在 1000 个 subscribers 的情况下，性能在 11.1ms 的水平，也就是每秒可以处理 90k publish 请求：</p><pre><code class=\"language-bash\">publishing              time:   [11.007 ms 11.095 ms 11.253 ms]                      \n                        change: [-96.618% -96.556% -96.486%] (p = 0.00 &lt; 0.05)\n                        Performance has improved.\n</code></pre><p>你也许会觉得目前 publish 的 value 太小，那换一些更加贴近实际的字符串大小：</p><pre><code class=\"language-rust\">// let values = &amp;[\"Hello\", \"Tyr\", \"Goodbye\", \"World\"];\nlet base_str = include_str!(\"../fixtures/server.conf\"); // 891 bytes\n\nlet values: &amp;'static [&amp;'static str] = Box::leak(\n    vec![\n        &amp;base_str[..64],\n        &amp;base_str[..128],\n        &amp;base_str[..256],\n        &amp;base_str[..512],\n    ]\n    .into_boxed_slice(),\n);\n</code></pre><p>测试结果差不太多：</p><pre><code class=\"language-plain\">publishing              time:   [10.917 ms 11.098 ms 11.428 ms]                      \n                        change: [-0.4822% +2.3311% +4.9631%] (p = 0.12 &gt; 0.05)\n                        No change in performance detected.\n</code></pre><p>criterion 还会生成漂亮的 report，你可以用浏览器打开 ./target/criterion/publishing/report/index.html 查看（名字是publishing ，因为 benchmark ID 是 publishing）：<br>\n<img src=\"https://static001.geekbang.org/resource/image/d3/85/d3cebd8e3c164171febbe34e43916885.png?wh=1860x2308\" alt=\"\"></p><p>好，处理完性能相关的问题，我们来<strong>为 server 添加日志和性能监测的支持</strong>：</p><pre><code class=\"language-rust\">use std::env;\n\nuse anyhow::Result;\nuse kv6::{start_server_with_config, RotationConfig, ServerConfig};\nuse tokio::fs;\nuse tracing::span;\nuse tracing_subscriber::{\n    fmt::{self, format},\n    layer::SubscriberExt,\n    prelude::*,\n    EnvFilter,\n};\n\n#[tokio::main]\nasync fn main() -&gt; Result&lt;()&gt; {\n    // 如果有环境变量，使用环境变量中的 config\n    let config = match env::var(\"KV_SERVER_CONFIG\") {\n        Ok(path) =&gt; fs::read_to_string(&amp;path).await?,\n        Err(_) =&gt; include_str!(\"../fixtures/server.conf\").to_string(),\n    };\n    let config: ServerConfig = toml::from_str(&amp;config)?;\n\n    let tracer = opentelemetry_jaeger::new_pipeline()\n        .with_service_name(\"kv-server\")\n        .install_simple()?;\n    let opentelemetry = tracing_opentelemetry::layer().with_tracer(tracer);\n\n    // 添加\n    let log = &amp;config.log;\n    let file_appender = match log.rotation {\n        RotationConfig::Hourly =&gt; tracing_appender::rolling::hourly(&amp;log.path, \"server.log\"),\n        RotationConfig::Daily =&gt; tracing_appender::rolling::daily(&amp;log.path, \"server.log\"),\n        RotationConfig::Never =&gt; tracing_appender::rolling::never(&amp;log.path, \"server.log\"),\n    };\n\n    let (non_blocking, _guard1) = tracing_appender::non_blocking(file_appender);\n    let fmt_layer = fmt::layer()\n        .event_format(format().compact())\n        .with_writer(non_blocking);\n\n    tracing_subscriber::registry()\n        .with(EnvFilter::from_default_env())\n        .with(fmt_layer)\n        .with(opentelemetry)\n        .init();\n\n    let root = span!(tracing::Level::INFO, \"app_start\", work_units = 2);\n    let _enter = root.enter();\n\n    start_server_with_config(&amp;config).await?;\n\n    Ok(())\n}\n</code></pre><p>为了让日志能在配置文件中配置，需要更新一下 src/config.rs：</p><pre><code class=\"language-rust\">#[derive(Clone, Debug, Serialize, Deserialize, PartialEq)]\npub struct ServerConfig {\n    pub general: GeneralConfig,\n    pub storage: StorageConfig,\n    pub tls: ServerTlsConfig,\n    pub log: LogConfig,\n}\n\n#[derive(Clone, Debug, Serialize, Deserialize, PartialEq)]\npub struct LogConfig {\n    pub path: String,\n    pub rotation: RotationConfig,\n}\n\n#[derive(Clone, Debug, Serialize, Deserialize, PartialEq)]\npub enum RotationConfig {\n    Hourly,\n    Daily,\n    Never,\n}\n</code></pre><p>你还需要更新 examples/gen_config.rs。相关的改变可以看 repo 下的 diff_logging。<br>\ntracing 和 opentelemetry 还支持 <a href=\"https://github.com/prometheus/prometheus\">prometheus</a>，你可以使用 <a href=\"https://docs.rs/opentelemetry-prometheus\">opentelemetry-prometheus</a> 来和 prometheus 交互，如果有兴趣，你可以自己深入研究一下。</p><h2>CI/CD</h2><p>为了讲述方便，我把 CI/CD 放在最后，但 CI/CD 应该是在一开始的时候就妥善设置的。</p><p>先说CI吧。这个课程的 repo <a href=\"https://github.com/tyrchen/geektime-rust\">tyrchen/geektime-rust</a> 在一开始就设置了 github action，每次 commit 都会运行：</p><ul>\n<li>代码格式检查：cargo fmt</li>\n<li>依赖 license 检查：cargo deny</li>\n<li>linting：cargo check 和 cargo clippy</li>\n<li>单元测试和集成测试：cargo test</li>\n<li>生成文档：cargo doc</li>\n</ul><p>github action 配置如下，供你参考：</p><pre><code class=\"language-yaml\">name: build\n\non:\n  push:\n    branches:\n      - master\n  pull_request:\n    branches:\n      - master\n\njobs:\n  build-rust:\n    strategy:\n      matrix:\n        platform: [ubuntu-latest, windows-latest]\n    runs-on: ${{ matrix.platform }}\n    steps:\n      - uses: actions/checkout@v2\n      - name: Cache cargo registry\n        uses: actions/cache@v1\n        with:\n          path: ~/.cargo/registry\n          key: ${{ runner.os }}-cargo-registry\n      - name: Cache cargo index\n        uses: actions/cache@v1\n        with:\n          path: ~/.cargo/git\n          key: ${{ runner.os }}-cargo-index\n      - name: Cache cargo build\n        uses: actions/cache@v1\n        with:\n          path: target\n          key: ${{ runner.os }}-cargo-build-target\n      - name: Install stable\n        uses: actions-rs/toolchain@v1\n        with:\n          profile: minimal\n          toolchain: stable\n          override: true\n      - name: Check code format\n        run: cargo fmt -- --check\n      - name: Check the package for errors\n        run: cargo check --all\n      - name: Lint rust sources\n        run: cargo clippy --all-targets --all-features --tests --benches -- -D warnings\n      - name: Run tests\n        run: cargo test --all-features -- --test-threads=1 --nocapture\n      - name: Generate docs\n        run: cargo doc --all-features --no-deps\n      - name: Deploy docs to gh-page\n        uses: peaceiris/actions-gh-pages@v3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          publish_dir: ./target/doc\n</code></pre><p>除此之外，我们还可以在每次 push tag 时做 release：</p><pre><code class=\"language-yaml\">name: release\n\non:\n  push:\n    tags:\n      - \"v*\" # Push events to matching v*, i.e. v1.0, v20.15.10\n\njobs:\n  build:\n    name: Upload Release Asset\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-latest]\n    steps:\n      - name: Cache cargo registry\n        uses: actions/cache@v1\n        with:\n          path: ~/.cargo/registry\n          key: ${{ runner.os }}-cargo-registry\n      - name: Cache cargo index\n        uses: actions/cache@v1\n        with:\n          path: ~/.cargo/git\n          key: ${{ runner.os }}-cargo-index\n      - name: Cache cargo build\n        uses: actions/cache@v1\n        with:\n          path: target\n          key: ${{ runner.os }}-cargo-build-target\n      - name: Checkout code\n        uses: actions/checkout@v2\n        with:\n          token: ${{ secrets.GH_TOKEN }}\n          submodules: recursive\n      - name: Build project\n        run: |\n          make build-release\n      - name: Create Release\n        id: create_release\n        uses: actions/create-release@v1\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          tag_name: ${{ github.ref }}\n          release_name: Release ${{ github.ref }}\n          draft: false\n          prerelease: false\n      - name: Upload asset\n        id: upload-kv-asset\n        uses: actions/upload-release-asset@v1\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          upload_url: ${{ steps.create_release.outputs.upload_url }}\n          asset_path: ./target/release/kvs\n          asset_name: kvs\n          asset_content_type: application/octet-stream\n      - name: Set env\n        run: echo \"RELEASE_VERSION=${GITHUB_REF#refs/*/}\" &gt;&gt; $GITHUB_ENV\n      - name: Deploy docs to gh-page\n        uses: peaceiris/actions-gh-pages@v3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          publish_dir: ./target/doc/simple_kv\n          destination_dir: ${{ env.RELEASE_VERSION }}\n</code></pre><p>这样，每次 push tag 时，都可以打包出来 Linux 的 kvs 版本：<br>\n<img src=\"https://static001.geekbang.org/resource/image/1c/19/1c61b7f58dd176bd25a565577d75af19.png?wh=2000x853\" alt=\"\"></p><p>如果你不希望直接使用编译出来的二进制，也可以打包成 docker，在 Kubernetes 下使用。</p><p><strong>在做 CI 的过程中，我们也可以触发 CD</strong>，比如：</p><ul>\n<li>PR merge 到 master，在 build 完成后，触发 dev 服务器的部署，团队内部可以尝试；</li>\n<li>如果 release tag 包含 alpha，在 build 完成后，触发 staging 服务器的部署，公司内部可以使用；</li>\n<li>如果 release tag 包含 beta，在 build 完成后，触发 beta 服务器的部署，beta 用户可以使用；</li>\n<li>正式的 release tag 会触发生产环境的滚动升级，升级覆盖到的用户可以使用。</li>\n</ul><p>一般来说，每家企业都有自己的 CI/CD 的工具链，这里为了展示方便，我们演示了如何使用 github action 对 Rust 代码做 CI，你可以按照自己的需要来处理。</p><p>在刚才的 action 代码中，还编译并上传了文档，所以我们可以通过 github pages 很方便地访问文档：<br>\n<img src=\"https://static001.geekbang.org/resource/image/88/a7/885d092273f8cacda1a65867a2489ea7.png?wh=2000x1563\" alt=\"\"></p><h2>小结</h2><p>我们的 KV server 之旅就到此为止了。在整整 7 堂课里，我们一点点从零构造了一个完整的 KV server，包括注释在内，撰写了近三千行代码：</p><pre><code class=\"language-bash\">❯ tokei .\n-------------------------------------------------------------------------------\n Language            Files        Lines         Code     Comments       Blanks\n-------------------------------------------------------------------------------\n Makefile                1           24           16            1            7\n Markdown                1            7            7            0            0\n Protocol Buffers        1          119           79           23           17\n Rust                   25         3366         2730          145          491\n TOML                    2          268          107          142           19\n-------------------------------------------------------------------------------\n Total                  30         3784         2939          311          534\n-------------------------------------------------------------------------------\n</code></pre><p>这是一个非常了不起的成就！我们应该为自己感到自豪！</p><p>在这个系列里，我们大量使用 trait 和泛型，构建了很多复杂的数据结构；还为自己的类型实现了 AsyncRead / AsyncWrite / Stream / Sink 这些比较高阶的 trait。通过良好的设计，我们把网络层和业务层划分地非常清晰，网络层的变化不会影响到业务层，反之亦然：<br>\n<img src=\"https://static001.geekbang.org/resource/image/53/f3/53f5e5cf68b4300c3231885b10c784f3.jpeg?wh=2312x1379\" alt=\"\"></p><p>我们还模拟了比较真实的开发场景，通过大的需求变更，引发了一次不小的代码重构。</p><p>最终，通过性能测试，发现了一个客户端实现的小 bug。在处理这个 bug 的时候，我们欣喜地看到，Rust 有着非常强大的测试工具链，除了我们使用的单元测试、集成测试、性能测试，Rust 还支持模糊测试（fuzzy testing）和基于特性的测试（property testing）。</p><p>对于测试过程中发现的问题，Rust 有着非常完善的 tracing 工具链，可以和整个 opentelemetry 生态系统（包括 jaeger、prometheus 等工具）打通。我们就是通过使用 jaeger 找到并解决了问题。除此之外，Rust tracing 工具链还支持生成 <a href=\"https://github.com/tokio-rs/tracing/tree/master/tracing-flame\">flamegraph</a>，篇幅关系，没有演示，你感兴趣的话可以试试。</p><p>最后，我们完善了 KV server 的配置、日志以及 CI。完整的代码我放在了 <a href=\"http://github.com/tyrchen/simple-kv\">github.com/tyrchen/simple-kv</a> 上，欢迎查看最终的版本。</p><p>希望通过这个系列，你对如何使用 Rust 的特性来构造应用程序有了深度的认识。我相信，如果你能够跟得上这个系列的节奏，另外如果遇到新的库，用<a href=\"https://time.geekbang.org/column/article/424017\">第 20 讲</a>阅读代码的方式快速掌握，那么，大部分 Rust 开发中的挑战，对你而言都不是难事。</p><h3>思考题</h3><p>我们目前并未对日志做任何配置。一般来说，怎么做日志，会有相应的开关以及日志级别，如果希望能通过如下的配置记录日志，该怎么做？试试看：</p><pre><code class=\"language-rust\">[log]\nenable_log_file = true\nenable_jaeger = false\nlog_level = 'info'\npath = '/tmp/kv-log'\nrotation = 'Daily'\n</code></pre><p>欢迎在留言区分享自己做 KV server 系列的想法和感悟。你已经完成了第45次打卡，我们下节课见。</p>","comments":[{"had_liked":false,"id":326056,"user_name":"Rayjun","can_delete":false,"product_type":"c1","uid":1002514,"ip_address":"","ucode":"61A3D1A3D03569","user_header":"https://static001.geekbang.org/account/avatar/00/0f/4c/12/f0c145d4.jpg","comment_is_top":false,"comment_ctime":1639356813,"is_pvip":true,"replies":[{"id":"118809","content":"👍","user_name":"作者回复","user_name_real":"编辑","uid":"1079375","ctime":1639804494,"ip_address":"","comment_id":326056,"utype":1}],"discussion_count":2,"race_medal":0,"score":"44589029773","product_id":100085301,"comment_content":"老师的工程底子是真的厚，我感觉整个课程下来，学 rust 是其次，更重要的是学到了老师做工程的方法，太棒了","like_count":10,"discussions":[{"author":{"id":1079375,"avatar":"https://static001.geekbang.org/account/avatar/00/10/78/4f/e74f870c.jpg","nickname":"Tyr","note":"","ucode":"EAAFC8063202E0","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":539682,"discussion_content":"👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1639804494,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1023085,"avatar":"","nickname":"安迪","note":"","ucode":"BC23EA989E0A4C","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":538248,"discussion_content":"有同感，老师高屋建瓴，介绍了语言和软件架构的各种方法。受益匪浅！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1639381836,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":326180,"user_name":"乌龙猹","can_delete":false,"product_type":"c1","uid":2739949,"ip_address":"","ucode":"43F94A0DEC54BE","user_header":"https://static001.geekbang.org/account/avatar/00/29/ce/ed/3dbe915b.jpg","comment_is_top":false,"comment_ctime":1639406988,"is_pvip":false,"replies":[{"id":"118802","content":"加油！","user_name":"作者回复","user_name_real":"编辑","uid":"1079375","ctime":1639804341,"ip_address":"","comment_id":326180,"utype":1}],"discussion_count":1,"race_medal":0,"score":"23114243468","product_id":100085301,"comment_content":"这确实是 Rust 编程的第一课   但确是每一个务实程序员的必修课  在做一项工程时，老师的思维方式拆解问题的方法都毫无保留的分享出来   值得我们反复去阅读  反复理解    等什么时候能达到融会贯通 举一反三的时候  那时候就离 300k 的 package 不远了 ","like_count":5,"discussions":[{"author":{"id":1079375,"avatar":"https://static001.geekbang.org/account/avatar/00/10/78/4f/e74f870c.jpg","nickname":"Tyr","note":"","ucode":"EAAFC8063202E0","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":539675,"discussion_content":"加油！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1639804341,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":326478,"user_name":"吴云阁","can_delete":false,"product_type":"c1","uid":1224039,"ip_address":"","ucode":"21089FBAFBF61D","user_header":"https://static001.geekbang.org/account/avatar/00/12/ad/67/8563a71f.jpg","comment_is_top":false,"comment_ctime":1639538318,"is_pvip":false,"replies":[{"id":"118793","content":"谢谢！","user_name":"作者回复","user_name_real":"编辑","uid":"1079375","ctime":1639803767,"ip_address":"","comment_id":326478,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18819407502","product_id":100085301,"comment_content":"这节课的内容不仅仅是rust编程，更是毫无保留的分享工程方法。老师不仅仅是一个极其优秀的工程师，也是一个极其优秀的教学者。非常值得学习。","like_count":4,"discussions":[{"author":{"id":1079375,"avatar":"https://static001.geekbang.org/account/avatar/00/10/78/4f/e74f870c.jpg","nickname":"Tyr","note":"","ucode":"EAAFC8063202E0","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":539666,"discussion_content":"谢谢！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1639803767,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":326043,"user_name":"yyxxccc","can_delete":false,"product_type":"c1","uid":2759441,"ip_address":"","ucode":"BEC53F4F4922B8","user_header":"https://static001.geekbang.org/account/avatar/00/2a/1b/11/5e235665.jpg","comment_is_top":false,"comment_ctime":1639326307,"is_pvip":false,"replies":[{"id":"118807","content":"加油！","user_name":"作者回复","user_name_real":"编辑","uid":"1079375","ctime":1639804400,"ip_address":"","comment_id":326043,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18819195491","product_id":100085301,"comment_content":"看到300k的pkg，又增加了持续反复啃的动力😂","like_count":4,"discussions":[{"author":{"id":1079375,"avatar":"https://static001.geekbang.org/account/avatar/00/10/78/4f/e74f870c.jpg","nickname":"Tyr","note":"","ucode":"EAAFC8063202E0","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":539680,"discussion_content":"加油！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1639804400,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":338851,"user_name":"啦啦啦啦啦啦啦","can_delete":false,"product_type":"c1","uid":1470066,"ip_address":"","ucode":"220DC1DF76454F","user_header":"https://static001.geekbang.org/account/avatar/00/16/6e/72/f8e5b97e.jpg","comment_is_top":false,"comment_ctime":1647762870,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"5942730166","product_id":100085301,"comment_content":"想问下老师在跑 性能测试在 mac下 不会抛出 `Too many open files (os error 24)` 错误吗","like_count":1,"discussions":[{"author":{"id":2912722,"avatar":"","nickname":"新新人类","note":"","ucode":"97EACC93996CCB","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":572404,"discussion_content":"我也遇到了..","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1652771946,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":326149,"user_name":"罗杰","can_delete":false,"product_type":"c1","uid":1320487,"ip_address":"","ucode":"96BAFAA147341F","user_header":"https://static001.geekbang.org/account/avatar/00/14/26/27/eba94899.jpg","comment_is_top":false,"comment_ctime":1639394735,"is_pvip":false,"replies":[{"id":"118805","content":"谢谢 :)","user_name":"作者回复","user_name_real":"编辑","uid":"1079375","ctime":1639804380,"ip_address":"","comment_id":326149,"utype":1}],"discussion_count":1,"race_medal":2,"score":"5934362031","product_id":100085301,"comment_content":"实操项目 120 分，我要抽出连续时间好好完成这个项目，该专栏真的值得看十遍。","like_count":1,"discussions":[{"author":{"id":1079375,"avatar":"https://static001.geekbang.org/account/avatar/00/10/78/4f/e74f870c.jpg","nickname":"Tyr","note":"","ucode":"EAAFC8063202E0","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":539678,"discussion_content":"谢谢 :)","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1639804380,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":359607,"user_name":"进击的Lancelot","can_delete":false,"product_type":"c1","uid":2620407,"ip_address":"广东","ucode":"3BCC355801DC61","user_header":"https://static001.geekbang.org/account/avatar/00/27/fb/f7/88ab6f83.jpg","comment_is_top":false,"comment_ctime":1665674351,"is_pvip":true,"discussion_count":0,"race_medal":1,"score":"1665674351","product_id":100085301,"comment_content":"思考题实现：https:&#47;&#47;play.rust-lang.org&#47;?version=stable&amp;mode=debug&amp;edition=2021&amp;gist=d6037374ea479690681fecf425424cbb<br>","like_count":0},{"had_liked":false,"id":326048,"user_name":"楠楠嘻嘻","can_delete":false,"product_type":"c1","uid":1503202,"ip_address":"","ucode":"3B99180DD8501D","user_header":"https://static001.geekbang.org/account/avatar/00/16/ef/e2/df2a1823.jpg","comment_is_top":false,"comment_ctime":1639350631,"is_pvip":false,"replies":[{"id":"118808","content":":)","user_name":"作者回复","user_name_real":"编辑","uid":"1079375","ctime":1639804409,"ip_address":"","comment_id":326048,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1639350631","product_id":100085301,"comment_content":"确实厉害！真的是rust in action！","like_count":0,"discussions":[{"author":{"id":1079375,"avatar":"https://static001.geekbang.org/account/avatar/00/10/78/4f/e74f870c.jpg","nickname":"Tyr","note":"","ucode":"EAAFC8063202E0","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":539681,"discussion_content":":)","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1639804409,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]}]}