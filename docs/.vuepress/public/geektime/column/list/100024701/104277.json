{"id":104277,"title":"41 | IPC（中）：不同项目组之间抢资源，如何协调？","content":"<p>了解了如何使用共享内存和信号量集合之后，今天我们来解析一下，内核里面都做了什么。</p><p>不知道你有没有注意到，咱们讲消息队列、共享内存、信号量的机制的时候，我们其实能够从中看到一些统一的规律：<strong>它们在使用之前都要生成key，然后通过key得到唯一的id，并且都是通过xxxget函数。</strong></p><p>在内核里面，这三种进程间通信机制是使用统一的机制管理起来的，都叫ipcxxx。</p><p>为了维护这三种进程间通信进制，在内核里面，我们声明了一个有三项的数组。</p><p>我们通过这段代码，来具体看一看。</p><pre><code>struct ipc_namespace {\n......\n\tstruct ipc_ids\tids[3];\n......\n}\n\n#define IPC_SEM_IDS\t0\n#define IPC_MSG_IDS\t1\n#define IPC_SHM_IDS\t2\n\n#define sem_ids(ns)\t((ns)-&gt;ids[IPC_SEM_IDS])\n#define msg_ids(ns)\t((ns)-&gt;ids[IPC_MSG_IDS])\n#define shm_ids(ns)\t((ns)-&gt;ids[IPC_SHM_IDS])\n</code></pre><p>根据代码中的定义，第0项用于信号量，第1项用于消息队列，第2项用于共享内存，分别可以通过sem_ids、msg_ids、shm_ids来访问。</p><p>这段代码里面有ns，全称叫namespace。可能不容易理解，你现在可以将它认为是将一台Linux服务器逻辑的隔离为多台Linux服务器的机制，它背后的原理是一个相当大的话题，我们需要在容器那一章详细讲述。现在，你就可以简单的认为没有namespace，整个Linux在一个namespace下面，那这些ids也是整个Linux只有一份。</p><p>接下来，我们再来看struct ipc_ids里面保存了什么。</p><!-- [[[read_end]]] --><p>首先，in_use表示当前有多少个ipc；其次，seq和next_id用于一起生成ipc唯一的id，因为信号量，共享内存，消息队列，它们三个的id也不能重复；ipcs_idr是一棵基数树，我们又碰到它了，一旦涉及从一个整数查找一个对象，它都是最好的选择。</p><pre><code>struct ipc_ids {\n\tint in_use;\n\tunsigned short seq;\n\tstruct rw_semaphore rwsem;\n\tstruct idr ipcs_idr;\n\tint next_id;\n};\n\nstruct idr {\n\tstruct radix_tree_root\tidr_rt;\n\tunsigned int\t\tidr_next;\n};\n</code></pre><p>也就是说，对于sem_ids、msg_ids、shm_ids各有一棵基数树。那这棵树里面究竟存放了什么，能够统一管理这三类ipc对象呢？</p><p>通过下面这个函数ipc_obtain_object_idr，我们可以看出端倪。这个函数根据id，在基数树里面找出来的是struct kern_ipc_perm。</p><pre><code>struct kern_ipc_perm *ipc_obtain_object_idr(struct ipc_ids *ids, int id)\n{\n\tstruct kern_ipc_perm *out;\n\tint lid = ipcid_to_idx(id);\n\tout = idr_find(&amp;ids-&gt;ipcs_idr, lid);\n\treturn out;\n}\n</code></pre><p>如果我们看用于表示信号量、消息队列、共享内存的结构，就会发现，这三个结构的第一项都是struct kern_ipc_perm。</p><pre><code>struct sem_array {\n\tstruct kern_ipc_perm\tsem_perm;\t/* permissions .. see ipc.h */\n\ttime_t\t\t\tsem_ctime;\t/* create/last semctl() time */\n\tstruct list_head\tpending_alter;\t/* pending operations */\n\t\t\t\t\t\t                /* that alter the array */\n\tstruct list_head\tpending_const;\t/* pending complex operations */\n\t\t\t\t\t\t/* that do not alter semvals */\n\tstruct list_head\tlist_id;\t/* undo requests on this array */\n\tint\t\t\tsem_nsems;\t/* no. of semaphores in array */\n\tint\t\t\tcomplex_count;\t/* pending complex operations */\n\tunsigned int\t\tuse_global_lock;/* &gt;0: global lock required */\n\n\tstruct sem\t\tsems[];\n} __randomize_layout;\n\nstruct msg_queue {\n\tstruct kern_ipc_perm q_perm;\n\ttime_t q_stime;\t\t\t/* last msgsnd time */\n\ttime_t q_rtime;\t\t\t/* last msgrcv time */\n\ttime_t q_ctime;\t\t\t/* last change time */\n\tunsigned long q_cbytes;\t\t/* current number of bytes on queue */\n\tunsigned long q_qnum;\t\t/* number of messages in queue */\n\tunsigned long q_qbytes;\t\t/* max number of bytes on queue */\n\tpid_t q_lspid;\t\t\t/* pid of last msgsnd */\n\tpid_t q_lrpid;\t\t\t/* last receive pid */\n\n\tstruct list_head q_messages;\n\tstruct list_head q_receivers;\n\tstruct list_head q_senders;\n} __randomize_layout;\n\nstruct shmid_kernel /* private to the kernel */\n{\t\n\tstruct kern_ipc_perm\tshm_perm;\n\tstruct file\t\t*shm_file;\n\tunsigned long\t\tshm_nattch;\n\tunsigned long\t\tshm_segsz;\n\ttime_t\t\t\tshm_atim;\n\ttime_t\t\t\tshm_dtim;\n\ttime_t\t\t\tshm_ctim;\n\tpid_t\t\t\tshm_cprid;\n\tpid_t\t\t\tshm_lprid;\n\tstruct user_struct\t*mlock_user;\n\n\t/* The task created the shm object.  NULL if the task is dead. */\n\tstruct task_struct\t*shm_creator;\n\tstruct list_head\tshm_clist;\t/* list by creator */\n} __randomize_layout;\n</code></pre><p>也就是说，我们完全可以通过struct kern_ipc_perm的指针，通过进行强制类型转换后，得到整个结构。做这件事情的函数如下：</p><pre><code>static inline struct sem_array *sem_obtain_object(struct ipc_namespace *ns, int id)\n{\n\tstruct kern_ipc_perm *ipcp = ipc_obtain_object_idr(&amp;sem_ids(ns), id);\n\treturn container_of(ipcp, struct sem_array, sem_perm);\n}\n\nstatic inline struct msg_queue *msq_obtain_object(struct ipc_namespace *ns, int id)\n{\n\tstruct kern_ipc_perm *ipcp = ipc_obtain_object_idr(&amp;msg_ids(ns), id);\n\treturn container_of(ipcp, struct msg_queue, q_perm);\n}\n\nstatic inline struct shmid_kernel *shm_obtain_object(struct ipc_namespace *ns, int id)\n{\n\tstruct kern_ipc_perm *ipcp = ipc_obtain_object_idr(&amp;shm_ids(ns), id);\n\treturn container_of(ipcp, struct shmid_kernel, shm_perm);\n}\n</code></pre><p>通过这种机制，我们就可以将信号量、消息队列、共享内存抽象为ipc类型进行统一处理。你有没有觉得，这有点儿面向对象编程中抽象类和实现类的意思？没错，如果你试图去了解C++中类的实现机制，其实也是这么干的。</p><p><img src=\"https://static001.geekbang.org/resource/image/08/af/082b742753d862cfeae520fb02aa41af.png?wh=1813*1771\" alt=\"\"></p><p>有了抽象类，接下来我们来看共享内存和信号量的具体实现。</p><h2>如何创建共享内存？</h2><p>首先，我们来看创建共享内存的的系统调用。</p><pre><code>SYSCALL_DEFINE3(shmget, key_t, key, size_t, size, int, shmflg)\n{\n\tstruct ipc_namespace *ns;\n\tstatic const struct ipc_ops shm_ops = {\n\t\t.getnew = newseg,\n\t\t.associate = shm_security,\n\t\t.more_checks = shm_more_checks,\n\t};\n\tstruct ipc_params shm_params;\n\tns = current-&gt;nsproxy-&gt;ipc_ns;\n\tshm_params.key = key;\n\tshm_params.flg = shmflg;\n\tshm_params.u.size = size;\n\treturn ipcget(ns, &amp;shm_ids(ns), &amp;shm_ops, &amp;shm_params);\n}\n</code></pre><p>这里面调用了抽象的ipcget、参数分别为共享内存对应的shm_ids、对应的操作shm_ops以及对应的参数shm_params。</p><p>如果key设置为IPC_PRIVATE则永远创建新的，如果不是的话，就会调用ipcget_public。ipcget的具体代码如下：</p><pre><code>int ipcget(struct ipc_namespace *ns, struct ipc_ids *ids,\n\t\t\tconst struct ipc_ops *ops, struct ipc_params *params)\n{\n\tif (params-&gt;key == IPC_PRIVATE)\n\t\treturn ipcget_new(ns, ids, ops, params);\n\telse\n\t\treturn ipcget_public(ns, ids, ops, params);\n}\n\nstatic int ipcget_public(struct ipc_namespace *ns, struct ipc_ids *ids, const struct ipc_ops *ops, struct ipc_params *params)\n{\n\tstruct kern_ipc_perm *ipcp;\n\tint flg = params-&gt;flg;\n\tint err;\n\tipcp = ipc_findkey(ids, params-&gt;key);\n\tif (ipcp == NULL) {\n\t\tif (!(flg &amp; IPC_CREAT))\n\t\t\terr = -ENOENT;\n\t\telse\n\t\t\terr = ops-&gt;getnew(ns, params);\n\t} else {\n\t\tif (flg &amp; IPC_CREAT &amp;&amp; flg &amp; IPC_EXCL)\n\t\t\terr = -EEXIST;\n\t\telse {\n\t\t\terr = 0;\n\t\t\tif (ops-&gt;more_checks)\n\t\t\t\terr = ops-&gt;more_checks(ipcp, params);\n......\n\t\t}\n\t}\n\treturn err;\n}\n</code></pre><p>在ipcget_public中，我们会按照key，去查找struct kern_ipc_perm。如果没有找到，那就看是否设置了IPC_CREAT；如果设置了，就创建一个新的。如果找到了，就将对应的id返回。</p><p>我们这里重点看，如何按照参数shm_ops，创建新的共享内存，会调用newseg。</p><pre><code>static int newseg(struct ipc_namespace *ns, struct ipc_params *params)\n{\n\tkey_t key = params-&gt;key;\n\tint shmflg = params-&gt;flg;\n\tsize_t size = params-&gt;u.size;\n\tint error;\n\tstruct shmid_kernel *shp;\n\tsize_t numpages = (size + PAGE_SIZE - 1) &gt;&gt; PAGE_SHIFT;\n\tstruct file *file;\n\tchar name[13];\n\tvm_flags_t acctflag = 0;\n......\n\tshp = kvmalloc(sizeof(*shp), GFP_KERNEL);\n......\n\tshp-&gt;shm_perm.key = key;\n\tshp-&gt;shm_perm.mode = (shmflg &amp; S_IRWXUGO);\n\tshp-&gt;mlock_user = NULL;\n\n\tshp-&gt;shm_perm.security = NULL;\n......\n\tfile = shmem_kernel_file_setup(name, size, acctflag);\n......\n\tshp-&gt;shm_cprid = task_tgid_vnr(current);\n\tshp-&gt;shm_lprid = 0;\n\tshp-&gt;shm_atim = shp-&gt;shm_dtim = 0;\n\tshp-&gt;shm_ctim = get_seconds();\n\tshp-&gt;shm_segsz = size;\n\tshp-&gt;shm_nattch = 0;\n\tshp-&gt;shm_file = file;\n\tshp-&gt;shm_creator = current;\n\n\terror = ipc_addid(&amp;shm_ids(ns), &amp;shp-&gt;shm_perm, ns-&gt;shm_ctlmni);\n......\n\tlist_add(&amp;shp-&gt;shm_clist, &amp;current-&gt;sysvshm.shm_clist);\n......\n\tfile_inode(file)-&gt;i_ino = shp-&gt;shm_perm.id;\n\n\tns-&gt;shm_tot += numpages;\n\terror = shp-&gt;shm_perm.id;\n......\n\treturn error;\n}\n</code></pre><p><strong>newseg函数的第一步，通过kvmalloc在直接映射区分配一个struct shmid_kernel结构。</strong>这个结构就是用来描述共享内存的。这个结构最开始就是上面说的struct kern_ipc_perm结构。接下来就是填充这个struct shmid_kernel结构，例如key、权限等。</p><p><strong>newseg函数的第二步，共享内存需要和文件进行关联</strong>。**为什么要做这个呢？我们在讲内存映射的时候讲过，虚拟地址空间可以和物理内存关联，但是物理内存是某个进程独享的。虚拟地址空间也可以映射到一个文件，文件是可以跨进程共享的。</p><p>咱们这里的共享内存需要跨进程共享，也应该借鉴文件映射的思路。只不过不应该映射一个硬盘上的文件，而是映射到一个内存文件系统上的文件。mm/shmem.c里面就定义了这样一个基于内存的文件系统。这里你一定要注意区分shmem和shm的区别，前者是一个文件系统，后者是进程通信机制。</p><p>在系统初始化的时候，shmem_init注册了shmem文件系统shmem_fs_type，并且挂在到了shm_mnt下面。</p><pre><code>int __init shmem_init(void)\n{\n\tint error;\n\terror = shmem_init_inodecache();\n\terror = register_filesystem(&amp;shmem_fs_type);\n\tshm_mnt = kern_mount(&amp;shmem_fs_type);\n......\n\treturn 0;\n}\n\nstatic struct file_system_type shmem_fs_type = {\n\t.owner\t\t= THIS_MODULE,\n\t.name\t\t= &quot;tmpfs&quot;,\n\t.mount\t\t= shmem_mount,\n\t.kill_sb\t= kill_litter_super,\n\t.fs_flags\t= FS_USERNS_MOUNT,\n};\n</code></pre><p>接下来，newseg函数会调用shmem_kernel_file_setup，其实就是在shmem文件系统里面创建一个文件。</p><pre><code>/**\n * shmem_kernel_file_setup - get an unlinked file living in tmpfs which must be kernel internal.  \n * @name: name for dentry (to be seen in /proc/&lt;pid&gt;/maps\n * @size: size to be set for the file\n * @flags: VM_NORESERVE suppresses pre-accounting of the entire object size */\nstruct file *shmem_kernel_file_setup(const char *name, loff_t size, unsigned long flags)\n{\n\treturn __shmem_file_setup(name, size, flags, S_PRIVATE);\n}\n\nstatic struct file *__shmem_file_setup(const char *name, loff_t size,\n\t\t\t\t       unsigned long flags, unsigned int i_flags)\n{\n\tstruct file *res;\n\tstruct inode *inode;\n\tstruct path path;\n\tstruct super_block *sb;\n\tstruct qstr this;\n......\n\tthis.name = name;\n\tthis.len = strlen(name);\n\tthis.hash = 0; /* will go */\n\tsb = shm_mnt-&gt;mnt_sb;\n\tpath.mnt = mntget(shm_mnt);\n\tpath.dentry = d_alloc_pseudo(sb, &amp;this);\n\td_set_d_op(path.dentry, &amp;anon_ops);\n......\n\tinode = shmem_get_inode(sb, NULL, S_IFREG | S_IRWXUGO, 0, flags);\n\tinode-&gt;i_flags |= i_flags;\n\td_instantiate(path.dentry, inode);\n\tinode-&gt;i_size = size;\n......\n\tres = alloc_file(&amp;path, FMODE_WRITE | FMODE_READ,\n\t\t  &amp;shmem_file_operations);\n\treturn res;\n}\n</code></pre><p>__shmem_file_setup会创建新的shmem文件对应的dentry和inode，并将它们两个关联起来，然后分配一个struct file结构，来表示新的shmem文件，并且指向独特的shmem_file_operations。</p><pre><code>static const struct file_operations shmem_file_operations = {\n\t.mmap\t\t= shmem_mmap,\n\t.get_unmapped_area = shmem_get_unmapped_area,\n#ifdef CONFIG_TMPFS\n\t.llseek\t\t= shmem_file_llseek,\n\t.read_iter\t= shmem_file_read_iter,\n\t.write_iter\t= generic_file_write_iter,\n\t.fsync\t\t= noop_fsync,\n\t.splice_read\t= generic_file_splice_read,\n\t.splice_write\t= iter_file_splice_write,\n\t.fallocate\t= shmem_fallocate,\n#endif\n};\n</code></pre><p><strong>newseg函数的第三步，通过ipc_addid将新创建的struct shmid_kernel结构挂到shm_ids里面的基数树上，并返回相应的id，并且将struct shmid_kernel挂到当前进程的sysvshm队列中。</strong></p><p>至此，共享内存的创建就完成了。</p><h2>如何将共享内存映射到虚拟地址空间？</h2><p>从上面的代码解析中，我们知道，共享内存的数据结构struct shmid_kernel，是通过它的成员struct file *shm_file，来管理内存文件系统shmem上的内存文件的。无论这个共享内存是否被映射，shm_file都是存在的。</p><p>接下来，我们要将共享内存映射到虚拟地址空间中。调用的是shmat，对应的系统调用如下：</p><pre><code>SYSCALL_DEFINE3(shmat, int, shmid, char __user *, shmaddr, int, shmflg)\n{\n    unsigned long ret;\n    long err;\n    err = do_shmat(shmid, shmaddr, shmflg, &amp;ret, SHMLBA);\n    force_successful_syscall_return();\n    return (long)ret;\n}\n\nlong do_shmat(int shmid, char __user *shmaddr, int shmflg,\n\t      ulong *raddr, unsigned long shmlba)\n{\n\tstruct shmid_kernel *shp;\n\tunsigned long addr = (unsigned long)shmaddr;\n\tunsigned long size;\n\tstruct file *file;\n\tint    err;\n\tunsigned long flags = MAP_SHARED;\n\tunsigned long prot;\n\tint acc_mode;\n\tstruct ipc_namespace *ns;\n\tstruct shm_file_data *sfd;\n\tstruct path path;\n\tfmode_t f_mode;\n\tunsigned long populate = 0;\n......\n\tprot = PROT_READ | PROT_WRITE;\n\tacc_mode = S_IRUGO | S_IWUGO;\n\tf_mode = FMODE_READ | FMODE_WRITE;\n......\n\tns = current-&gt;nsproxy-&gt;ipc_ns;\n\tshp = shm_obtain_object_check(ns, shmid);\n......\n\tpath = shp-&gt;shm_file-&gt;f_path;\n\tpath_get(&amp;path);\n\tshp-&gt;shm_nattch++;\n\tsize = i_size_read(d_inode(path.dentry));\n......\n\tsfd = kzalloc(sizeof(*sfd), GFP_KERNEL);\n......\n\tfile = alloc_file(&amp;path, f_mode,\n\t\t\t  is_file_hugepages(shp-&gt;shm_file) ?\n\t\t\t\t&amp;shm_file_operations_huge :\n\t\t\t\t&amp;shm_file_operations);\n......\n\tfile-&gt;private_data = sfd;\n\tfile-&gt;f_mapping = shp-&gt;shm_file-&gt;f_mapping;\n\tsfd-&gt;id = shp-&gt;shm_perm.id;\n\tsfd-&gt;ns = get_ipc_ns(ns);\n\tsfd-&gt;file = shp-&gt;shm_file;\n\tsfd-&gt;vm_ops = NULL;\n......\n\taddr = do_mmap_pgoff(file, addr, size, prot, flags, 0, &amp;populate, NULL);\n\t*raddr = addr;\n\terr = 0;\n......\n\treturn err;\n}\n</code></pre><p>在这个函数里面，shm_obtain_object_check会通过共享内存的id，在基数树中找到对应的struct shmid_kernel结构，通过它找到shmem上的内存文件。</p><p>接下来，我们要分配一个struct shm_file_data，来表示这个内存文件。将shmem中指向内存文件的shm_file赋值给struct shm_file_data中的file成员。</p><p>然后，我们创建了一个struct file，指向的也是shmem中的内存文件。</p><p>为什么要再创建一个呢？这两个的功能不同，shmem中shm_file用于管理内存文件，是一个中立的，独立于任何一个进程的角色。而新创建的struct file是专门用于做内存映射的，就像咱们在讲内存映射那一节讲过的，一个硬盘上的文件要映射到虚拟地址空间中的时候，需要在vm_area_struct里面有一个struct file *vm_file指向硬盘上的文件，现在变成内存文件了，但是这个结构还是不能少。</p><p>新创建的struct file的private_data，指向struct shm_file_data，这样内存映射那部分的数据结构，就能够通过它来访问内存文件了。</p><p>新创建的struct file的file_operations也发生了变化，变成了shm_file_operations。</p><pre><code>static const struct file_operations shm_file_operations = {\n\t.mmap\t\t= shm_mmap,\n\t.fsync\t\t= shm_fsync,\n\t.release\t= shm_release,\n\t.get_unmapped_area\t= shm_get_unmapped_area,\n\t.llseek\t\t= noop_llseek,\n\t.fallocate\t= shm_fallocate,\n};\n</code></pre><p>接下来，do_mmap_pgoff函数我们遇到过，原来映射硬盘上的文件的时候，也是调用它。这里我们不再详细解析了。它会分配一个vm_area_struct指向虚拟地址空间中没有分配的区域，它的vm_file指向这个内存文件，然后它会调用shm_file_operations的mmap函数，也即shm_mmap进行映射。</p><pre><code>static int shm_mmap(struct file *file, struct vm_area_struct *vma)\n{\n\tstruct shm_file_data *sfd = shm_file_data(file);\n\tint ret;\n\tret = __shm_open(vma);\n\tret = call_mmap(sfd-&gt;file, vma);\n\tsfd-&gt;vm_ops = vma-&gt;vm_ops;\n\tvma-&gt;vm_ops = &amp;shm_vm_ops;\n\treturn 0;\n}\n</code></pre><p>shm_mmap中调用了shm_file_data中的file的mmap函数，这次调用的是shmem_file_operations的mmap，也即shmem_mmap。</p><pre><code>static int shmem_mmap(struct file *file, struct vm_area_struct *vma)\n{\n\tfile_accessed(file);\n\tvma-&gt;vm_ops = &amp;shmem_vm_ops;\n\treturn 0;\n}\n</code></pre><p>这里面，vm_area_struct的vm_ops指向shmem_vm_ops。等从call_mmap中返回之后，shm_file_data的vm_ops指向了shmem_vm_ops，而vm_area_struct的vm_ops改为指向shm_vm_ops。</p><p>我们来看一下，shm_vm_ops和shmem_vm_ops的定义。</p><pre><code>static const struct vm_operations_struct shm_vm_ops = {\n\t.open\t= shm_open,\t/* callback for a new vm-area open */\n\t.close\t= shm_close,\t/* callback for when the vm-area is released */\n\t.fault\t= shm_fault,\n};\n\nstatic const struct vm_operations_struct shmem_vm_ops = {\n\t.fault\t\t= shmem_fault,\n\t.map_pages\t= filemap_map_pages,\n};\n</code></pre><p>它们里面最关键的就是fault函数，也即访问虚拟内存的时候，访问不到应该怎么办。</p><p>当访问不到的时候，先调用vm_area_struct的vm_ops，也即shm_vm_ops的fault函数shm_fault。然后它会转而调用shm_file_data的vm_ops，也即shmem_vm_ops的fault函数shmem_fault。</p><pre><code>static int shm_fault(struct vm_fault *vmf)\n{\n\tstruct file *file = vmf-&gt;vma-&gt;vm_file;\n\tstruct shm_file_data *sfd = shm_file_data(file);\n\treturn sfd-&gt;vm_ops-&gt;fault(vmf);\n}\n</code></pre><p>虽然基于内存的文件系统，已经为这个内存文件分配了inode，但是内存也却是一点儿都没分配，只有在发生缺页异常的时候才进行分配。</p><pre><code>static int shmem_fault(struct vm_fault *vmf)\n{\n\tstruct vm_area_struct *vma = vmf-&gt;vma;\n\tstruct inode *inode = file_inode(vma-&gt;vm_file);\n\tgfp_t gfp = mapping_gfp_mask(inode-&gt;i_mapping);\n......\n\terror = shmem_getpage_gfp(inode, vmf-&gt;pgoff, &amp;vmf-&gt;page, sgp,\n\t\t\t\t  gfp, vma, vmf, &amp;ret);\n......\n}\n\n/*\n * shmem_getpage_gfp - find page in cache, or get from swap, or allocate\n *\n * If we allocate a new one we do not mark it dirty. That's up to the\n * vm. If we swap it in we mark it dirty since we also free the swap\n * entry since a page cannot live in both the swap and page cache.\n *\n * fault_mm and fault_type are only supplied by shmem_fault:\n * otherwise they are NULL.\n */\nstatic int shmem_getpage_gfp(struct inode *inode, pgoff_t index,\n\tstruct page **pagep, enum sgp_type sgp, gfp_t gfp,\n\tstruct vm_area_struct *vma, struct vm_fault *vmf, int *fault_type)\n{\n......\n    page = shmem_alloc_and_acct_page(gfp, info, sbinfo,\n\t\t\t\t\tindex, false);\n......\n}\n</code></pre><p>shmem_fault会调用shmem_getpage_gfp在page cache和swap中找一个空闲页，如果找不到就通过shmem_alloc_and_acct_page分配一个新的页，他最终会调用内存管理系统的alloc_page_vma在物理内存中分配一个页。</p><p>至此，共享内存才真的映射到了虚拟地址空间中，进程可以像访问本地内存一样访问共享内存。</p><h2>总结时刻</h2><p>我们来总结一下共享内存的创建和映射过程。</p><ol>\n<li>调用shmget创建共享内存。</li>\n<li>先通过ipc_findkey在基数树中查找key对应的共享内存对象shmid_kernel是否已经被创建过，如果已经被创建，就会被查询出来，例如producer创建过，在consumer中就会查询出来。</li>\n<li>如果共享内存没有被创建过，则调用shm_ops的newseg方法，创建一个共享内存对象shmid_kernel。例如，在producer中就会新建。</li>\n<li>在shmem文件系统里面创建一个文件，共享内存对象shmid_kernel指向这个文件，这个文件用struct file表示，我们姑且称它为file1。</li>\n<li>调用shmat，将共享内存映射到虚拟地址空间。</li>\n<li>shm_obtain_object_check先从基数树里面找到shmid_kernel对象。</li>\n<li>创建用于内存映射到文件的file和shm_file_data，这里的struct file我们姑且称为file2。</li>\n<li>关联内存区域vm_area_struct和用于内存映射到文件的file，也即file2，调用file2的mmap函数。</li>\n<li>file2的mmap函数shm_mmap，会调用file1的mmap函数shmem_mmap，设置shm_file_data和vm_area_struct的vm_ops。</li>\n<li>内存映射完毕之后，其实并没有真的分配物理内存，当访问内存的时候，会触发缺页异常do_page_fault。</li>\n<li>vm_area_struct的vm_ops的shm_fault会调用shm_file_data的vm_ops的shmem_fault。</li>\n<li>在page cache中找一个空闲页，或者创建一个空闲页。</li>\n</ol><p><img src=\"https://static001.geekbang.org/resource/image/20/51/20e8f4e69d47b7469f374bc9fbcf7251.png?wh=4903*3352\" alt=\"\"></p><h2>课堂练习</h2><p>在这里，我们只分析了shm_ids的结构，消息队列的程序我们写过了，但是msg_ids的结构没有解析，你可以试着解析一下。</p><p>欢迎留言和我分享你的疑惑和见解 ，也欢迎可以收藏本节内容，反复研读。你也可以把今天的内容分享给你的朋友，和他一起学习和进步。</p><p></p>","comments":[{"had_liked":false,"id":137097,"user_name":"Spring","can_delete":false,"product_type":"c1","uid":1222211,"ip_address":"","ucode":"8175463FB4705B","user_header":"https://static001.geekbang.org/account/avatar/00/12/a6/43/cb6ab349.jpg","comment_is_top":false,"comment_ctime":1569595903,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"70289072639","product_id":100024701,"comment_content":"文章一遍看不懂但底下总结的图很好，终于明白了为什么需要两个file。file1是shmem内存文件系统里的文件，file2是进程虚拟内存里映射的文件，所以file1是属于共享内存的，file2是属于某个进程的。","like_count":16,"discussions":[{"author":{"id":1576512,"avatar":"https://static001.geekbang.org/account/avatar/00/18/0e/40/49a71ed8.jpg","nickname":"八戒","note":"","ucode":"3F262A99492A65","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":367836,"discussion_content":"那为什么不直接映射到file1？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618479724,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":148439,"user_name":"小橙子","can_delete":false,"product_type":"c1","uid":1244724,"ip_address":"","ucode":"7E3DD87C3DE6F9","user_header":"https://static001.geekbang.org/account/avatar/00/12/fe/34/67c1ed1e.jpg","comment_is_top":false,"comment_ctime":1573007468,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"48817647724","product_id":100024701,"comment_content":"工作了几年 ，业务代码写多了，框架与API调来调去的，遇到很多疑难杂症，还是不明所以。<br>回过头再看下 操作系统真是核心，很多人说操作系统就是功夫里面的易筋经，内功章法。学习了操作系统，再看很多其他的技术，感觉更自然，理解的更深刻了。一直想读内核代码，但是啃起来很费劲，这个专栏一直再看，越看越喜欢，很多篇章都会反复的看。相信看完专栏后，再去看一些深入理解linux内核，会清晰很多。","like_count":11,"discussions":[{"author":{"id":1731543,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/6b/d7/8872624a.jpg","nickname":"xmeng","note":"","ucode":"C0CA2182BA3B4B","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":396544,"discussion_content":"一样的感受，一样的喜欢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1632449566,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":211771,"user_name":"book尾汁","can_delete":false,"product_type":"c1","uid":1446375,"ip_address":"","ucode":"AE2B8DFC643ACC","user_header":"https://static001.geekbang.org/account/avatar/00/16/11/e7/044a9a6c.jpg","comment_is_top":false,"comment_ctime":1588002692,"is_pvip":true,"replies":[{"id":"83783","content":"赞","user_name":"作者回复","comment_id":211771,"uid":"1001590","ip_address":"","utype":1,"ctime":1592359483,"user_name_real":"刘超@网易云"}],"discussion_count":3,"race_medal":0,"score":"23062839172","product_id":100024701,"comment_content":"共享内存:<br>创建共享内存,通过shmget系统调用来创建一个共享内存,主要是通过key来创建一个struct kern_ipc_perm,信号量 队列和共享内存的结构都是一样的,可以通过强制类型转换来转化成任意一个类型.然后接下来去填充这个结构,然后将一个文件与共享内存关联,内存映射有两种方式一种是匿名映射 一种是映射到一个文件,物理内存是不能共享的,文件可以跨进程共享,所以要映射到文件.但这里的文件是一个特殊的文件系统内存文件系统上的文件,这个内存文件系统也会在系统初始化的时候注册 挂载, 该文件也有目录项和inode以及其fs_operation,然后会将新创建的共享内存对象加入到shm_ids基数上,并将其加到当前进程的sysvshm队列中.<br><br>现在共享内存其实还只是内核中的一个结构体,我们只有共享内存的id,要想使用共享内存还要通过id来将其映射到使用者的用户态的进程空间中,通过shmat系统调用可以做到这一点,该系统调用的主要工作如下:<br>1 通过共享内存的ip在 shm_ids基数树上找到该共享内存的结构体,然后取出内存文件系统里file并将其赋值给新创建的struct shm_file_data-&gt;file,这里我们已经有了可以共享的文件&quot;file&quot;,然后在用户进程虚拟空间的mmap映射区分配一个vm_area struct来做文件映射就可以了,将vm_area_struct里的vm_file的private_data指向shm_file_data,为什么不能直接用file呢?private_data貌似只有共享内存才有用,不太理解,可能因为vm_file有其独特的file_operation的问题吧,两个file&#39;虽然可以是同一类结构体,但差异还是很大.在创建vm_file的过程中应该可以找到答案,略过,映射内存时还会将vm_area的vm_ops先指向shmem_vm_ops,然后在指向shm_vm_ops, 将shm_file_data的vm_ops指向shmem_vm_ops即内存文件系统的文件的vm_ops,到这里就完成了.后面进程读或写数据时,如果对应的页表项没有建立会触发缺页异常,跟之前的缺页异常流程差不多,最终会调用内存文件系统的缺页异常函数来分配对应的物理页,并建立页表项.","like_count":5,"discussions":[{"author":{"id":1001590,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/48/76/0c7d4d23.jpg","nickname":"刘超","note":"","ucode":"196BF3F499E8FE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493360,"discussion_content":"赞","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1592359483,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1099199,"avatar":"https://static001.geekbang.org/account/avatar/00/10/c5/bf/a2fa5bf2.jpg","nickname":"侯超","note":"","ucode":"56D6A5471392D1","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":381209,"discussion_content":"两个进程的虚拟内存地址不同，共享内存怎么实现的，怎么映射到相同的物理内存的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1624954252,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1446375,"avatar":"https://static001.geekbang.org/account/avatar/00/16/11/e7/044a9a6c.jpg","nickname":"book尾汁","note":"","ucode":"AE2B8DFC643ACC","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1099199,"avatar":"https://static001.geekbang.org/account/avatar/00/10/c5/bf/a2fa5bf2.jpg","nickname":"侯超","note":"","ucode":"56D6A5471392D1","race_medal":0,"user_type":1,"is_pvip":true},"discussion":{"id":381440,"discussion_content":"这个好久没复习了，忘记了，文件可以共享，共享内存也是特殊的文件","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1625053982,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":381209,"ip_address":""},"score":381440,"extra":""}]}]},{"had_liked":false,"id":185574,"user_name":"珠闪闪","can_delete":false,"product_type":"c1","uid":1300447,"ip_address":"","ucode":"45BE0D586A3839","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eov38ZkwCyNoBdr5drgX0cp2eOGCv7ibkhUIqCvcnFk8FyUIS6K4gHXIXh0fu7TB67jaictdDlic4OwQ/132","comment_is_top":false,"comment_ctime":1583636894,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"23058473374","product_id":100024701,"comment_content":"文章两遍读下来蒙蒙的，最后对着总结图把共享内存的创建和在用户态映射的流程理顺了。关键就是因为共享内存刚开始申请的物理内存无法在进程中共享，所以先要把物理内存的shmid_kernel对应到shmem文件系统的一个文件，这样shmem中的文件可以再进程中共享；然后在shmat函数时，相当于将shm映射到shmem的file2，先映射到shmem文件系统的文件file1，然后再通过file1的mmap函数完成shm_file_data和vm_area_struct的ops设置。这样内存映射完毕后，并没有真的分配物理内存，当访问内存会触发缺页异常。然后vm_area_struct的vm_ops的shm_fault会调用shm_file_data的vm_ops的shmem_fault。最后在page cache中找一个空闲页，或者创建一个空闲页。","like_count":5,"discussions":[{"author":{"id":2365071,"avatar":"https://static001.geekbang.org/account/avatar/00/24/16/8f/c1baee96.jpg","nickname":"muse","note":"","ucode":"43B0C82639E39F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":373621,"discussion_content":"您好，请问为什么刚开始申请的物理内存无法在进程中共享呢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1620801015,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":211781,"user_name":"book尾汁","can_delete":false,"product_type":"c1","uid":1446375,"ip_address":"","ucode":"AE2B8DFC643ACC","user_header":"https://static001.geekbang.org/account/avatar/00/16/11/e7/044a9a6c.jpg","comment_is_top":false,"comment_ctime":1588003863,"is_pvip":true,"replies":[{"id":"83782","content":"对的，","user_name":"作者回复","comment_id":211781,"uid":"1001590","ip_address":"","utype":1,"ctime":1592359459,"user_name_real":"刘超@网易云"}],"discussion_count":1,"race_medal":0,"score":"14472905751","product_id":100024701,"comment_content":"补充下该查了下file是VFS框架的一个基本概念，一切皆文件指的就是这个,f,然后在这个file下面会有各种各样的实现,比如设备是文件 sock是文件 pipe是文件 共享内存也是文件,file结构体里面都是一些通用的属性,而private_data里面是一些各个披着文件外衣的各种结构体的一个独特的东西,因此这里会有两个file,vm_file就是这个外壳,其private_data里就是共享内存的相关数据","like_count":3,"discussions":[{"author":{"id":1001590,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/48/76/0c7d4d23.jpg","nickname":"刘超","note":"","ucode":"196BF3F499E8FE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493364,"discussion_content":"对的，","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1592359459,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":109530,"user_name":"Amark","can_delete":false,"product_type":"c1","uid":1121326,"ip_address":"","ucode":"E5F48633654002","user_header":"https://static001.geekbang.org/account/avatar/00/11/1c/2e/93812642.jpg","comment_is_top":false,"comment_ctime":1562051640,"is_pvip":false,"replies":[{"id":"48811","content":"的确比较硬核，我实在是没办法再比喻了","user_name":"作者回复","comment_id":109530,"uid":"1001590","ip_address":"","utype":1,"ctime":1567498219,"user_name_real":"刘超@网易云"}],"discussion_count":1,"race_medal":0,"score":"10151986232","product_id":100024701,"comment_content":"老师有没有什么通俗易懂的资料，您将的太专业了","like_count":2,"discussions":[{"author":{"id":1001590,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/48/76/0c7d4d23.jpg","nickname":"刘超","note":"","ucode":"196BF3F499E8FE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":456453,"discussion_content":"的确比较硬核，我实在是没办法再比喻了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567498219,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":348380,"user_name":"NeverSeeYouAgainBUG","can_delete":false,"product_type":"c1","uid":2930836,"ip_address":"","ucode":"1B0E8CA284C181","user_header":"https://static001.geekbang.org/account/avatar/00/2c/b8/94/d20583ef.jpg","comment_is_top":false,"comment_ctime":1655035258,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1655035258","product_id":100024701,"comment_content":"哎呀超哥，深入浅出啊深入浅出啊。关键在 浅出，要好好总结，","like_count":0},{"had_liked":false,"id":347528,"user_name":"小鳄鱼","can_delete":false,"product_type":"c1","uid":1178888,"ip_address":"","ucode":"9C30CAFB41A263","user_header":"https://static001.geekbang.org/account/avatar/00/11/fd/08/c039f840.jpg","comment_is_top":false,"comment_ctime":1654130649,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1654130649","product_id":100024701,"comment_content":"为了统一操作入口：一切皆文件。构建了各种各样的“文件系统”。共享内存文件系统，硬盘文件系统（ext4等），设备文件系统，相信还有各种各样的文件系统！虽然感觉复杂了，但是实际的场景本来就不简单。反而统一入口之后，“上层建筑”的开发人员不再需要关系底层的具体实现，从而实现并行开发，独立维护。","like_count":0},{"had_liked":false,"id":345112,"user_name":"Geek_2b44d4","can_delete":false,"product_type":"c1","uid":2925499,"ip_address":"","ucode":"8283C03D322999","user_header":"","comment_is_top":false,"comment_ctime":1652057126,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1652057126","product_id":100024701,"comment_content":"这个page cache 跟swap的选择时机是怎样的？","like_count":0},{"had_liked":false,"id":159511,"user_name":"艾瑞克小霸王","can_delete":false,"product_type":"c1","uid":1674555,"ip_address":"","ucode":"58FCCAC0F675E1","user_header":"https://static001.geekbang.org/account/avatar/00/19/8d/3b/42d9c669.jpg","comment_is_top":false,"comment_ctime":1575642762,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1575642762","product_id":100024701,"comment_content":"对于 sem_ids、msg_ids、shm_ids 各有一棵基数树<br>---------------------------------------------------<br>应该是共享一个树吧？","like_count":0},{"had_liked":false,"id":151352,"user_name":"Leosocy","can_delete":false,"product_type":"c1","uid":1132542,"ip_address":"","ucode":"5E076D6B981F84","user_header":"https://static001.geekbang.org/account/avatar/00/11/47/fe/f2ce12cd.jpg","comment_is_top":false,"comment_ctime":1573704387,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1573704387","product_id":100024701,"comment_content":"seq 和 next_id 用于一起生成 ipc 唯一的 id，因为信号量，共享内存，消息队列，它们三个的 id 也不能重复<br><br>这句话不太明白，不同的ipc_ids不是有不同的idr吗？为什么要保证他们三个id不重复？","like_count":0},{"had_liked":false,"id":137636,"user_name":"奔跑的码仔","can_delete":false,"product_type":"c1","uid":1609871,"ip_address":"","ucode":"AB3B02B07B8B8C","user_header":"https://static001.geekbang.org/account/avatar/00/18/90/8f/9c691a5f.jpg","comment_is_top":false,"comment_ctime":1569810480,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1569810480","product_id":100024701,"comment_content":"将本节所讲的共享内存实现流程与文件内存映那节所讲的流程对比着梳理一下，感觉明朗了好多","like_count":0},{"had_liked":false,"id":123361,"user_name":"嘉木","can_delete":false,"product_type":"c1","uid":1317999,"ip_address":"","ucode":"AF4877693782C0","user_header":"https://static001.geekbang.org/account/avatar/00/14/1c/6f/3ea2a599.jpg","comment_is_top":false,"comment_ctime":1565661505,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1565661505","product_id":100024701,"comment_content":"C的面向对象居然这么巧妙","like_count":0},{"had_liked":false,"id":109066,"user_name":"不一样的烟火","can_delete":false,"product_type":"c1","uid":1473251,"ip_address":"","ucode":"6E305F0EE90E8B","user_header":"https://static001.geekbang.org/account/avatar/00/16/7a/e3/145adba9.jpg","comment_is_top":false,"comment_ctime":1561954739,"is_pvip":false,"replies":[{"id":"39605","content":"牛","user_name":"作者回复","comment_id":109066,"uid":"1001590","ip_address":"","utype":1,"ctime":1562031295,"user_name_real":"刘超@网易云"}],"discussion_count":1,"race_medal":0,"score":"1561954739","product_id":100024701,"comment_content":"听完了 快点更新😁","like_count":0,"discussions":[{"author":{"id":1001590,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/48/76/0c7d4d23.jpg","nickname":"刘超","note":"","ucode":"196BF3F499E8FE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":456232,"discussion_content":"牛","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562031295,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]}]}