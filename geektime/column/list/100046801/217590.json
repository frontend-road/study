{"id":217590,"title":"16 | 用Redis构建缓存集群的最佳实践有哪些？","content":"<p>你好，我是李玥。</p><p>之前连续几节课，我们都在以MySQL为例子，讲如何应对海量数据，如何应对高并发，如何实现高可用，我先带你简单复习一下。</p><ul>\n<li>数据量太大查询慢怎么办？存档历史数据或者分库分表，这是数据分片。</li>\n<li>并发太高扛不住怎么办？读写分离，这是增加实例数。</li>\n<li>数据库宕机怎么办？增加从节点，主节点宕机的时候用从节点顶上，这是主从复制。但是这里面要特别注意数据一致性的问题。</li>\n</ul><p>我在之前课程中，也多次提到过，<strong>这些方法不仅仅是MySQL特有的，对于几乎所有的存储系统，都是适用的。</strong></p><p>今天这节课，我们来聊一聊，如何构建一个生产系统可用的Redis缓存集群。你将会看到，几种集群解决方案用到的思想，基本和我们上面讲的都是一样的。</p><h2>Redis Cluster如何解决数据量大、高可用和高并发问题？</h2><p>Redis从3.0版本开始，提供了官方的集群支持，也就是Redis Cluser。<strong>Redis Cluster相比于单个节点的Redis，能保存更多的数据，支持更多的并发，并且可以做到高可用，在单个节点故障的情况下，继续提供服务。</strong></p><p>为了能够保存更多的数据，和MySQL分库分表的方式类似，Redis Cluster也是通过分片的方式，把数据分布到集群的多个节点上。</p><!-- [[[read_end]]] --><p>Redis Cluster是如何来分片的呢？它引入了一个“槽（Slot）”的概念，这个槽就是哈希表中的哈希槽，槽是Redis分片的基本单位，每个槽里面包含一些Key。每个集群的槽数是固定的16384（16 * 1024）个，每个Key落在哪个槽中也是固定的，计算方法是：</p><pre><code>HASH_SLOT = CRC16(key) mod 16384\n</code></pre><p>这个算法很简单，先计算Key的CRC值，然后把这个CRC之后的Key值直接除以16384，余数就是Key所在的槽。这个算法就是我们上节课讲过的哈希分片算法。</p><p>这些槽又是如何存放到具体的Redis节点上的呢？这个映射关系保存在集群的每个Redis节点上，集群初始化的时候，Redis会自动平均分配这16384个槽，也可以通过命令来调整。这个分槽的方法，也是我们上节课讲到过的分片算法：查表法。</p><p>客户端可以连接集群的任意一个节点来访问集群的数据，当客户端请求一个Key的时候，被请求的那个Redis实例先通过上面的公式，计算出这个Key在哪个槽中，然后再查询槽和节点的映射关系，找到数据所在的真正节点，如果这个节点正好是自己，那就直接执行命令返回结果。如果数据不在当前这个节点上，那就给客户端返回一个重定向的命令，告诉客户端，应该去连哪个节点上请求这个Key的数据。然后客户端会再连接正确的节点来访问。</p><p>解决分片问题之后，Redis Cluster就可以通过水平扩容来增加集群的存储容量，但是，每次往集群增加节点的时候，需要从集群的那些老节点中，搬运一些槽到新节点，你可以手动指定哪些槽迁移到新节点上，也可以利用官方提供的<a href=\"http://download.redis.io/redis-stable/src/redis-trib.rb\">redis-trib.rb</a>脚本来自动重新分配槽，自动迁移。</p><p>分片可以解决Redis保存海量数据的问题，并且客观上提升了Redis的并发能力和查询性能。但是并不能解决高可用的问题，每个节点都保存了整个集群数据的一个子集，任何一个节点宕机，都会导致这个宕机节点上的那部分数据无法访问。</p><p>那Redis Cluster是怎么解决高可用问题的？</p><p>参见上面我们讲到的方法：<strong>增加从节点，做主从复制</strong>。Redis Cluster支持给每个分片增加一个或多个从节点，每个从节点在连接到主节点上之后，会先给主节点发送一个SYNC命令，请求一次全量复制，也就是把主节点上全部的数据都复制到从节点上。全量复制完成之后，进入同步阶段，主节点会把刚刚全量复制期间收到的命令，以及后续收到的命令持续地转发给从节点。</p><p>因为Redis不支持事务，所以它的复制相比MySQL更简单，连Binlog都省了，直接就是转发客户端发来的更新数据命令来实现主从同步。如果某个分片的主节点宕机了，集群中的其他节点会在这个分片的从节点中选出一个新的节点作为主节点继续提供服务。新的主节点选举出来后，集群中的所有节点都会感知到，这样，如果客户端的请求Key落在故障分片上，就会被重定向到新的主节点上。</p><p>最后我们看一下，Redis Cluster是如何应对高并发的。</p><p>一般来说，Redis Cluster进行了分片之后，每个分片都会承接一部分并发的请求，加上Redis本身单节点的性能就非常高，所以大部分情况下不需要再像MySQL那样做读写分离来解决高并发的问题。默认情况下，集群的读写请求都是由主节点负责的，从节点只是起一个热备的作用。当然了，Redis Cluster也支持读写分离，在从节点上读取数据。</p><p>以上就是Redis Cluster的基本原理，你可以对照下图来加深理解。</p><p><img src=\"https://static001.geekbang.org/resource/image/c4/fd/c405e73a4fd797ca0cda82b383e46ffd.png?wh=778*555\" alt=\"\"></p><center>（图片来源：<a href=\"https://rancher.com/blog/2019/deploying-redis-cluster/\">网络</a>）</center><p>你可以看到，Redis Cluster整体的架构完全就是照抄MySQL构建集群的那一套东西（当然，这些设计和方法也不是MySQL发明的），抄作业抄的就差把名字一起也抄上了。</p><p>具体如何搭建Redis Cluster以及相关的操作命令你可以看一下<a href=\"https://redis.io/topics/cluster-tutorial\">Redis官方的这篇教程</a>。</p><h2>为什么Redis Cluster不适合超大规模集群？</h2><p>Redis Cluster的优点是易于使用。分片、主从复制、弹性扩容这些功能都可以做到自动化，通过简单的部署就可以获得一个大容量、高可靠、高可用的Redis集群，并且对于应用来说，近乎于是透明的。</p><p>所以，<strong>Redis Cluster是非常适合构建中小规模Redis集群</strong>，这里的中小规模指的是，大概几个到几十个节点这样规模的Redis集群。</p><p><strong>但是Redis Cluster不太适合构建超大规模集群，主要原因是，它采用了去中心化的设计。</strong>刚刚我们讲了，Redis的每个节点上，都保存了所有槽和节点的映射关系表，客户端可以访问任意一个节点，再通过重定向命令，找到数据所在的那个节点。那你有没有想过一个问题，这个映射关系表，它是如何更新的呢？比如说，集群加入了新节点，或者某个主节点宕机了，新的主节点被选举出来，这些情况下，都需要更新集群每一个节点上的映射关系表。</p><p>Redis Cluster采用了一种去中心化的<a href=\"https://en.wikipedia.org/wiki/Gossip_protocol\">流言(Gossip)协议</a>来传播集群配置的变化。一般涉及到协议都比较复杂，这里我们不去深究具体协议和实现算法，我大概给你讲一下这个协议原理。</p><p>所谓流言，就是八卦，比如说，我们上学的时候，班上谁和谁偷偷好上了，搞对象，那用不了一天，全班同学都知道了。咋知道的？张三看见了，告诉李四，李四和王小二特别好，又告诉了王小二，这样人传人，不久就传遍全班了。这个就是八卦协议的传播原理。</p><p>这个八卦协议它的好处是去中心化，传八卦不需要组织，吃瓜群众自发就传开了。这样部署和维护就更简单，也能避免中心节点的单点故障。八卦协议的缺点就是传播速度慢，并且是集群规模越大，传播的越慢。这个也很好理解，比如说，换成某两个特别出名的明星搞对象，即使是全国人民都很八卦，但要想让全国每一个人都知道这个消息，还是需要很长的时间。在集群规模太大的情况下，数据不同步的问题会被明显放大，还有一定的不确定性，如果出现问题很难排查。</p><h2>如何用Redis构建超大规模集群？</h2><p>Redis Cluster不太适合用于大规模集群，所以很多大厂，都选择自己去搭建Redis集群。这里面，每一家的解决方案都有自己的特色，但其实总体的架构都是大同小异的。</p><p>一种是基于代理的方式，在客户端和Redis节点之间，还需要增加一层代理服务。这个代理服务有三个作用。</p><p>第一个作用是，负责在客户端和Redis节点之间转发请求和响应。客户端只和代理服务打交道，代理收到客户端的请求之后，再转发到对应的Redis节点上，节点返回的响应再经由代理转发返回给客户端。</p><p>第二个作用是，负责监控集群中所有Redis节点状态，如果发现有问题节点，及时进行主从切换。</p><p>第三个作用就是维护集群的元数据，这个元数据主要就是集群所有节点的主从信息，以及槽和节点关系映射表。这个架构和我在《<a href=\"https://time.geekbang.org/column/article/215330\">12 | MySQL如何应对高并发（二）：读写分离</a>》这节课中给你讲过的，用HAProxy+Keepalived来代理MySQL请求的架构是类似的，只是多了一个自动路由分片的功能而已。</p><p><img src=\"https://static001.geekbang.org/resource/image/03/d6/03c2901db83c02cbfe90a8c9b78d04d6.jpg?wh=1142*513\" alt=\"\"></p><p>像开源的Redis集群方案<a href=\"https://github.com/twitter/twemproxy\">twemproxy</a>和<a href=\"https://github.com/CodisLabs/codis\">Codis</a>，都是这种架构的。</p><p>这个架构最大的优点是对客户端透明，在客户端视角来看，整个集群和一个超大容量的单节点Redis是一样的。并且，由于分片算法是代理服务控制的，扩容也比较方便，新节点加入集群后，直接修改代理服务中的元数据就可以完成扩容。</p><p>不过，这个架构的缺点也很突出，增加了一层代理转发，每次数据访问的链路更长了，必然会带来一定的性能损失。而且，代理服务本身又是集群的一个单点，当然，我们可以把代理服务也做成一个集群来解决单点问题，那样集群就更复杂了。</p><p>另外一种方式是，不用这个代理服务，把代理服务的寻址功能前移到客户端中去。客户端在发起请求之前，先去查询元数据，就可以知道要访问的是哪个分片和哪个节点，然后直连对应的Redis节点访问数据。</p><p>当然，客户端不用每次都去查询元数据，因为这个元数据是不怎么变化的，客户端可以自己缓存元数据，这样访问性能基本上和单机版的Redis是一样的。如果某个分片的主节点宕机了，新的主节点被选举出来之后，更新元数据里面的信息。对集群的扩容操作也比较简单，除了迁移数据的工作必须要做以外，更新一下元数据就可以了。</p><p><img src=\"https://static001.geekbang.org/resource/image/dc/da/dcaced0a9ce9842ef688c9626accdcda.jpg?wh=1142*605\" alt=\"\"></p><p>虽然说，这个元数据服务仍然是一个单点，但是它的数据量不大，访问量也不大，相对就比较容易实现。我们可以用ZooKeeper、etcd甚至MySQL都能满足要求。这个方案应该是最适合超大规模Redis集群的方案了，在性能、弹性、高可用几方面表现都非常好，缺点是整个架构比较复杂，客户端不能通用，需要开发定制化的Redis客户端，只有规模足够大的企业才负担得起。</p><h2>小结</h2><p>今天这节课我们讲了从小到大三种构建Redis集群的方式。</p><ul>\n<li>小规模的集群建议使用官方的Redis Cluster，在节点数量不多的情况下，各方面表现都不错。</li>\n<li>再大一些规模的集群，可以考虑使用twemproxy或者Codis这类的基于代理的集群架构，虽然是开源方案，但是已经被很多公司在生产环境中验证过。</li>\n<li>相比于代理方案，使用定制客户端的方案性能更好，很多大厂采用的都是类似的架构。</li>\n</ul><p>还有一个小问题需要注意的是，这几种集群方案对一些类似于“KEYS”这类的多KEY命令，都没法做到百分百支持。原因很简单，数据被分片了之后，这种多KEY的命令很可能需要跨多个分片查询。当你的系统从单个Redis库升级到集群时，可能需要考虑一下这方面的兼容性问题。</p><h2>思考题</h2><p>很多存储系统之间都存在“互相抄作业”的嫌疑，其实这对于我们这些存储系统的使用者来说是好事儿，比如我们把MySQL都学透了，你再去看Redis，知道它抄了哪些作业，这部分我们就可以迅速掌握了，只要再研究一下不一样的那一小部分内容，我们就可以精通Redis了是不？</p><p>课后请你再去看一下HDFS，它在解决分片、复制和高可用这几方面，哪些是“抄作业”，哪些又是自己独创的。欢迎你在留言区与我讨论。</p><p>感谢你的阅读，如果你觉得今天的内容对你有帮助，也欢迎把它分享给你的朋友。</p>","comments":[{"had_liked":false,"id":201934,"user_name":"李玥","can_delete":false,"product_type":"c1","uid":1501046,"ip_address":"","ucode":"B19E91EE248591","user_header":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","comment_is_top":true,"comment_ctime":1585879111,"is_pvip":false,"discussion_count":3,"race_medal":0,"score":"9.2233722274191995e+18","product_id":100046801,"comment_content":"Hi，我是李玥。<br><br>这里回顾一下上节课的思考题：<br><br>课后请你想一下，把订单表拆分之后，那些和订单有外键关联的表，该怎么处理？<br><br>对于这些表，我的建议是，和订单表一起拆分，让相同订单ID的订单和关联表的数据分布到相同的分片上，这样便于查询。","like_count":45,"discussions":[{"author":{"id":1336783,"avatar":"https://static001.geekbang.org/account/avatar/00/14/65/cf/f4305170.jpg","nickname":"ALEX","note":"","ucode":"02031DD9EADFE9","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":541114,"discussion_content":"牵一发，动全身\n","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1640257175,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1886331,"avatar":"https://static001.geekbang.org/account/avatar/00/1c/c8/7b/153181d7.jpg","nickname":"夜辉","note":"","ucode":"9421385F51FF9E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":366379,"discussion_content":"不同的订单可能包含相同的商品，如何使其一起拆分呢？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618045041,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1520538,"avatar":"https://static001.geekbang.org/account/avatar/00/17/33/9a/f295dea5.jpg","nickname":"李正g","note":"","ucode":"A7BEA03BB6537A","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1886331,"avatar":"https://static001.geekbang.org/account/avatar/00/1c/c8/7b/153181d7.jpg","nickname":"夜辉","note":"","ucode":"9421385F51FF9E","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":581358,"discussion_content":"订单强相关的商品信息可能需要冗余到订单库里了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1658738356,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":366379,"ip_address":""},"score":581358,"extra":""}]}]},{"had_liked":false,"id":215890,"user_name":"LVM_23","can_delete":false,"product_type":"c1","uid":1039544,"ip_address":"","ucode":"5E54F9DB582E9F","user_header":"https://static001.geekbang.org/account/avatar/00/0f/dc/b8/31c7e110.jpg","comment_is_top":false,"comment_ctime":1589126061,"is_pvip":false,"replies":[{"id":"79949","content":"<br>建议你在list中的每个元素用单独的kv存储，在kv上设置过期时间。list中只保存元素的key。<br><br>读取list中的元素时，需要先遍历list，然后再根据key去找到元素的值，如果找不到说明过期了。<br><br>list中的key可以用定时任务清理一下，这个定时任务可以不用执行的太频繁，因为即使来不及清理，也不影响key过期。","user_name":"作者回复","user_name_real":"李玥","uid":"1501046","ctime":1589172052,"ip_address":"","comment_id":215890,"utype":1}],"discussion_count":1,"race_medal":0,"score":"177682785197","product_id":100046801,"comment_content":"老师你好，想问个问题。redis的list内元素的单独过期怎么做，而不是整个list过期。 网上都是用时间戳存，然后用定时任务来清除。有其他的方案吗? 写入频繁的，谢谢老师解答了","like_count":42,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":494596,"discussion_content":"\n建议你在list中的每个元素用单独的kv存储，在kv上设置过期时间。list中只保存元素的key。\n\n读取list中的元素时，需要先遍历list，然后再根据key去找到元素的值，如果找不到说明过期了。\n\nlist中的key可以用定时任务清理一下，这个定时任务可以不用执行的太频繁，因为即使来不及清理，也不影响key过期。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1589172052,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":201916,"user_name":"发条橙子 。","can_delete":false,"product_type":"c1","uid":1259218,"ip_address":"","ucode":"ED076F4534FFED","user_header":"https://static001.geekbang.org/account/avatar/00/13/36/d2/c7357723.jpg","comment_is_top":false,"comment_ctime":1585876894,"is_pvip":false,"replies":[{"id":"75537","content":"每个公司的实现方案也都不一样，几种哈希方法没有哪种是绝对的好，所以并不统一。<br><br>哨兵这种方式在逐步的被弃用，更多的使用类似于Paxos和Raft的一致性协议来通过选举和复制实现高可用。","user_name":"作者回复","user_name_real":"李玥","uid":"1501046","ctime":1585908626,"ip_address":"","comment_id":201916,"utype":1}],"discussion_count":3,"race_medal":0,"score":"66010386334","product_id":100046801,"comment_content":"老师 有两个疑问点<br><br>1.  大厂自建集群 是不是就是常说的使用一致性哈希来做槽的映射<br><br>2. 既然自带集群包含了哨兵， 代理也包含 ，是不是哨兵的功能也是在自建中使用 ，还是大厂自建的也不用哨兵 是自己做的高可用","like_count":16,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":490456,"discussion_content":"每个公司的实现方案也都不一样，几种哈希方法没有哪种是绝对的好，所以并不统一。\n\n哨兵这种方式在逐步的被弃用，更多的使用类似于Paxos和Raft的一致性协议来通过选举和复制实现高可用。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1585908626,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1386818,"avatar":"https://static001.geekbang.org/account/avatar/00/15/29/42/43d4b1a8.jpg","nickname":"烫烫烫","note":"","ucode":"C06018670DE76A","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":330910,"discussion_content":"Redis 哨兵用的也是Raft算法吧","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1606729631,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1622022,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJia6zEsh2u119zJicmq7wApvnricZEKiawaZicice1cOzujWdFicFwPtavlHiaVpCNgCpxBtdl7ynd3y0wkQ/132","nickname":"james_xu","note":"","ucode":"12E50291F5BA89","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1386818,"avatar":"https://static001.geekbang.org/account/avatar/00/15/29/42/43d4b1a8.jpg","nickname":"烫烫烫","note":"","ucode":"C06018670DE76A","race_medal":0,"user_type":1,"is_pvip":true},"discussion":{"id":410907,"discussion_content":"raft是强一致性、去中心化、高可用的分布式协议，使用raft算法之后就不需要哨兵的存在了，redis cluster的节点自治。","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1635813596,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":330910,"ip_address":""},"score":410907,"extra":""}]}]},{"had_liked":false,"id":201438,"user_name":"特种流氓","can_delete":false,"product_type":"c1","uid":1248825,"ip_address":"","ucode":"D9985CBA8B4AAD","user_header":"https://static001.geekbang.org/account/avatar/00/13/0e/39/174741d1.jpg","comment_is_top":false,"comment_ctime":1585788907,"is_pvip":false,"replies":[{"id":"75365","content":"是的，redis cluster已经包含哨兵的功能了。","user_name":"作者回复","user_name_real":"李玥","uid":"1501046","ctime":1585792657,"ip_address":"","comment_id":201438,"utype":1}],"discussion_count":1,"race_medal":0,"score":"48830429163","product_id":100046801,"comment_content":"redis cluster集群 是不是就没有哨兵的概念了","like_count":12,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":490334,"discussion_content":"是的，redis cluster已经包含哨兵的功能了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1585792657,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":201516,"user_name":"正在减肥的胖籽。","can_delete":false,"product_type":"c1","uid":1033728,"ip_address":"","ucode":"99E2E4DF599236","user_header":"https://static001.geekbang.org/account/avatar/00/0f/c6/00/683bb4f0.jpg","comment_is_top":false,"comment_ctime":1585797858,"is_pvip":false,"replies":[{"id":"75386","content":"如果用的是官方的Redis Cluster，可以用它提供的redis-trib.rb自动平滑迁移。<br><br>像Codis也提供了平滑迁移的管理工具。如果是自建的集群，相对就比较麻烦了。<br><br>我会在后面的第20节课讲，怎么来平滑的迁移数据库，方法同样适用于迁移Redis。","user_name":"作者回复","user_name_real":"李玥","uid":"1501046","ctime":1585803355,"ip_address":"","comment_id":201516,"utype":1}],"discussion_count":1,"race_medal":0,"score":"31650568930","product_id":100046801,"comment_content":"请教老师一个问题：<br> 1.redis集群新增分片后，线上怎么实现好的平滑迁移？这个一直没有想到好的解决方法","like_count":8,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":490357,"discussion_content":"如果用的是官方的Redis Cluster，可以用它提供的redis-trib.rb自动平滑迁移。\n\n像Codis也提供了平滑迁移的管理工具。如果是自建的集群，相对就比较麻烦了。\n\n我会在后面的第20节课讲，怎么来平滑的迁移数据库，方法同样适用于迁移Redis。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1585803355,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":201471,"user_name":"haijian.yang","can_delete":false,"product_type":"c1","uid":1162081,"ip_address":"","ucode":"E3D13ABA2CA347","user_header":"https://static001.geekbang.org/account/avatar/00/11/bb/61/2c2f5024.jpg","comment_is_top":false,"comment_ctime":1585792466,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"27355596242","product_id":100046801,"comment_content":"阿里云有个 redis 方案，冷数据存磁盘，热数据放在内存。","like_count":7},{"had_liked":false,"id":217650,"user_name":"申学晋","can_delete":false,"product_type":"c1","uid":1748750,"ip_address":"","ucode":"3F329A4DEBEE97","user_header":"https://static001.geekbang.org/account/avatar/00/1a/af/0e/ac955022.jpg","comment_is_top":false,"comment_ctime":1589556725,"is_pvip":false,"replies":[{"id":"80849","content":"redis-cluster-proxy 这个项目目前还处于alpha阶段，官方不建议用于生产环境，可以持续关注它。","user_name":"作者回复","user_name_real":"李玥","uid":"1501046","ctime":1589868837,"ip_address":"","comment_id":217650,"utype":1}],"discussion_count":1,"race_medal":0,"score":"23064393205","product_id":100046801,"comment_content":"redis6.0的官方集群代理和客户端缓存是不是可以把您讲的两种方案结合使用？","like_count":6,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":495206,"discussion_content":"redis-cluster-proxy 这个项目目前还处于alpha阶段，官方不建议用于生产环境，可以持续关注它。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589868837,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":208534,"user_name":"暴君•熊","can_delete":false,"product_type":"c1","uid":1101531,"ip_address":"","ucode":"AD1C6055E1F665","user_header":"https://static001.geekbang.org/account/avatar/00/10/ce/db/9dba29ea.jpg","comment_is_top":false,"comment_ctime":1587376081,"is_pvip":false,"replies":[{"id":"78332","content":"这种一般数据节点上就只用原生的Redis，元数据存储在元数据服务上。扩容也只是变更元数据，不需要Redis服务来参与。","user_name":"作者回复","user_name_real":"李玥","uid":"1501046","ctime":1587694734,"ip_address":"","comment_id":208534,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18767245265","product_id":100046801,"comment_content":"老师，最后介绍的定制客户端模式来保存分片表。那redis的服务端不需要动嘛？当有新增或者删除节点的时候，服务端内部不还是需要使用流言来传播一次嘛？","like_count":5,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492497,"discussion_content":"这种一般数据节点上就只用原生的Redis，元数据存储在元数据服务上。扩容也只是变更元数据，不需要Redis服务来参与。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587694734,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":215282,"user_name":"喜欢地球的阿培同学","can_delete":false,"product_type":"c1","uid":1361746,"ip_address":"","ucode":"5F97037585F857","user_header":"https://static001.geekbang.org/account/avatar/00/14/c7/52/c5adf218.jpg","comment_is_top":false,"comment_ctime":1588947262,"is_pvip":false,"replies":[{"id":"79939","content":"是的，后面二种方法都不会用到流言协议。","user_name":"作者回复","user_name_real":"李玥","uid":"1501046","ctime":1589170820,"ip_address":"","comment_id":215282,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14473849150","product_id":100046801,"comment_content":"老师，您好，问一个问题。最后介绍的定制客户端模式。是不是这些redis是一个一个节点，并没有一起组成一个集群。如果这些redis组成一个集群的话，那岂不是每次新增和删除redis节点时，也会流言传播一次吗？","like_count":3,"discussions":[{"author":{"id":1501046,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg","nickname":"李玥","note":"","ucode":"B19E91EE248591","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":494382,"discussion_content":"是的，后面二种方法都不会用到流言协议。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589170820,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":201493,"user_name":"sami","can_delete":false,"product_type":"c1","uid":1033240,"ip_address":"","ucode":"9A66FCA00D8A37","user_header":"https://wx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJkwbyTYtSCx6Qc7cQPnnRWv38Jybh3etziaPmuP8gHcgS6FMxcdftrKgWiamH6fc2iciaicDKDVEwcEibQ/132","comment_is_top":false,"comment_ctime":1585795505,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"10175730097","product_id":100046801,"comment_content":"cluster命令是受限的，跟mysql的分库分表一样，有一些场景也是无法支持","like_count":2},{"had_liked":false,"id":201398,"user_name":"leslie","can_delete":false,"product_type":"c1","uid":1324255,"ip_address":"","ucode":"798E7C1CC98CC2","user_header":"https://static001.geekbang.org/account/avatar/00/14/34/df/64e3d533.jpg","comment_is_top":false,"comment_ctime":1585763999,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"5880731295","product_id":100046801,"comment_content":"其实这也反向提出了另一个问题mysql cluster的问题：其自身同样有cluster,可是真实环境下很少企业会去用mysql cluster；都是各自运用自己的方案去做集群，方案之前的课程中都有提及就不提了。<br>自身的cluster在实际生产中极少被某些数据库使用这大概算是一大特点，尤其像我们所常见的mysql、redis、以及后面新出来的、、、","like_count":1,"discussions":[{"author":{"id":1886331,"avatar":"https://static001.geekbang.org/account/avatar/00/1c/c8/7b/153181d7.jpg","nickname":"夜辉","note":"","ucode":"9421385F51FF9E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":366408,"discussion_content":"换言之其实集群就是为了解决高性能（分表），高可用（故障转移），高并发（分库）问题，解决得不好（性能不好，使用不便），就会自行研发","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1618054422,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":336651,"user_name":"千锤百炼领悟之极限","can_delete":false,"product_type":"c1","uid":1744257,"ip_address":"","ucode":"224B5CF2101716","user_header":"https://static001.geekbang.org/account/avatar/00/1a/9d/81/d748b7eb.jpg","comment_is_top":false,"comment_ctime":1646276182,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1646276182","product_id":100046801,"comment_content":"小规模集群适合使用Redis Cluster，适合几个到几十个节点的规模。<br><br>为什么不适合大规模的集群? 因为Redis Cluster使用了一种去中心化设计的Gossip（流言）协议，用于节点之间更新映射表。<br><br>如果集群的节点数量多，更新映射表速度较慢，导致数据同步等问题。","like_count":0},{"had_liked":false,"id":282545,"user_name":"锐","can_delete":false,"product_type":"c1","uid":1110915,"ip_address":"","ucode":"A245BA96C9471F","user_header":"https://static001.geekbang.org/account/avatar/00/10/f3/83/e2612d81.jpg","comment_is_top":false,"comment_ctime":1615295571,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1615295571","product_id":100046801,"comment_content":"定制客户端这个方案，客户端缓存元数据，当集群中机器发生变化时，是通过zookeeper通知客户端更新元数据吗","like_count":0},{"had_liked":false,"id":246408,"user_name":"Lynn","can_delete":false,"product_type":"c1","uid":2165368,"ip_address":"","ucode":"D4CB95A1F1D60A","user_header":"https://static001.geekbang.org/account/avatar/00/21/0a/78/5ac3666f.jpg","comment_is_top":false,"comment_ctime":1599313039,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1599313039","product_id":100046801,"comment_content":"老师你好，假如两个key计算出来的槽是同一个，那是以链表的方式保存到槽里面吗？","like_count":0,"discussions":[{"author":{"id":1886331,"avatar":"https://static001.geekbang.org/account/avatar/00/1c/c8/7b/153181d7.jpg","nickname":"夜辉","note":"","ucode":"9421385F51FF9E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":366405,"discussion_content":"redis中hash的底层结构是hash table或者skiplist","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618053422,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":242022,"user_name":"lcf枫","can_delete":false,"product_type":"c1","uid":1144171,"ip_address":"","ucode":"D51E8F68BD41CA","user_header":"https://static001.geekbang.org/account/avatar/00/11/75/6b/fd685164.jpg","comment_is_top":false,"comment_ctime":1597564473,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1597564473","product_id":100046801,"comment_content":"老师 redis cluster 的高可用应该是有两方面来保证的吧？中从库 + 哨兵帮助监控切换","like_count":0},{"had_liked":false,"id":238515,"user_name":"哈德韦","can_delete":false,"product_type":"c1","uid":1637085,"ip_address":"","ucode":"E7C9B3D087D2D9","user_header":"https://static001.geekbang.org/account/avatar/00/18/fa/dd/f640711f.jpg","comment_is_top":false,"comment_ctime":1596186477,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1596186477","product_id":100046801,"comment_content":"请问下老师，跨数据中心的 Redis 数据同步有没有最佳实践？比如用户的登录信息Session数据缓存在Redis，那么国内集群和海外集群怎么同步呢？","like_count":0},{"had_liked":false,"id":231852,"user_name":"远航","can_delete":false,"product_type":"c1","uid":2051135,"ip_address":"","ucode":"A16171F1EAF7A1","user_header":"https://static001.geekbang.org/account/avatar/00/1f/4c/3f/5a343ddd.jpg","comment_is_top":false,"comment_ctime":1593788693,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1593788693","product_id":100046801,"comment_content":"老师您好，如果系统部署在两个机房，1:1部署业务，redis采用何种部署方式？两个机房需要保证redis的数据一致性","like_count":0},{"had_liked":false,"id":231383,"user_name":"Demon.Lee","can_delete":false,"product_type":"c1","uid":1052859,"ip_address":"","ucode":"7F0E5493A8E345","user_header":"https://static001.geekbang.org/account/avatar/00/10/10/bb/f1061601.jpg","comment_is_top":false,"comment_ctime":1593660715,"is_pvip":false,"discussion_count":0,"race_medal":1,"score":"1593660715","product_id":100046801,"comment_content":"老师，请教一下：<br>我们现在做redis小规模的高可用，只有3台机器，部署的就是redis cluster集群，一共部署了6个实例，3个master，3个slave（错开部署，A机器上master1, slave3; B 机器上 master2, slave1; C 机器上master 3, slave2 这样）。<br>我测试时，把A机器上的两个实例停掉，java jedis客户端连接报错一会后，就正常了；然后我把A恢复，再把B机器上的两个实例停掉，java jedis客户端连接报错就无法恢复正常了（错误：throw new JedisClusterMaxRedirectionsException(&quot;Too many Cluster redirections?&quot;)），重启java服务也无效。然后我通过CLUSTER NODES命令看到B机器上的两个实例都是master （fail， disconnectd状态）。<br><br>我理解是第一次停止A机器上实例的时候，master漂到B机器上了，然后停止B机器上实例的时候，master没有漂到其他机器上，不清楚为什么？<br>同事建议换哨兵模式，我自己想了一下，觉得哨兵好像更靠谱些，但我看老师说哨兵已经慢慢过时了，且redis cluster已经有哨兵的功能了，请老师针对我这种场景，给点意见，谢谢。","like_count":0},{"had_liked":false,"id":224364,"user_name":"博","can_delete":false,"product_type":"c1","uid":1798979,"ip_address":"","ucode":"F7CA69FF5D09BA","user_header":"https://static001.geekbang.org/account/avatar/00/1b/73/43/ae139b1f.jpg","comment_is_top":false,"comment_ctime":1591355242,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1591355242","product_id":100046801,"comment_content":"老师，redis的key 有什么统一的设计规范吗，看到好多都是与数据库表相对应的方式","like_count":0},{"had_liked":false,"id":220340,"user_name":"😚 46","can_delete":false,"product_type":"c1","uid":1433535,"ip_address":"","ucode":"EED0EBBBF80A43","user_header":"https://static001.geekbang.org/account/avatar/00/15/df/bf/96b50d1e.jpg","comment_is_top":false,"comment_ctime":1590224522,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1590224522","product_id":100046801,"comment_content":"最后一种集群方案，感觉有点类似于sharding sphere这样的中间件，客户端读取元数据然后路由到具体的redis实例请求","like_count":0},{"had_liked":false,"id":213875,"user_name":"旅途","can_delete":false,"product_type":"c1","uid":1212902,"ip_address":"","ucode":"5022477E8E9441","user_header":"https://static001.geekbang.org/account/avatar/00/12/81/e6/6cafed37.jpg","comment_is_top":false,"comment_ctime":1588581231,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1588581231","product_id":100046801,"comment_content":"老师,为什么redis没有事务同步就不需要binlog了?","like_count":0,"discussions":[{"author":{"id":1886331,"avatar":"https://static001.geekbang.org/account/avatar/00/1c/c8/7b/153181d7.jpg","nickname":"夜辉","note":"","ucode":"9421385F51FF9E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":366407,"discussion_content":"没有事务直接更新数据即可\nbinlog配合redo log，undo log实现原子性","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1618053489,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":208387,"user_name":"mickey","can_delete":false,"product_type":"c1","uid":1051663,"ip_address":"","ucode":"8B490C2DDE4010","user_header":"https://static001.geekbang.org/account/avatar/00/10/0c/0f/93d1c8eb.jpg","comment_is_top":false,"comment_ctime":1587348426,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1587348426","product_id":100046801,"comment_content":"HDFS分片、复制和高可用原理基本一样，机架感知是独创。","like_count":0}]}