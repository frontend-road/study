{"id":98948,"title":"01 |  消息引擎系统ABC","content":"<p>你好，我是胡夕。欢迎你来到“Kafka核心技术与实战”专栏。如果你对Kafka及其背后的消息引擎、流处理感兴趣，很高兴我们可以在此相聚，并在未来的一段日子里一同学习有关Kafka的方方面面。</p><p>毫无疑问，你现在对Apache Kafka一定充满了各种好奇，那么今天就允许我先来尝试回答下Kafka是什么这个问题。对了，先卖个关子，在下一期我还将继续回答这个问题，而且答案是不同的。那么，Kafka是什么呢？用一句话概括一下：<strong>Apache Kafka是一款开源的消息引擎系统</strong>。</p><p>倘若“消息引擎系统”这个词对你来说有点陌生的话，那么“消息队列”“消息中间件”的提法想必你一定是有所耳闻的。不过说实话我更愿意使用消息引擎系统这个称谓，因为消息队列给出了一个很不明确的暗示，仿佛Kafka是利用队列的方式构建的；而消息中间件的提法有过度夸张“中间件”之嫌，让人搞不清楚这个中间件到底是做什么的。</p><p>像Kafka这一类的系统国外有专属的名字叫Messaging System，国内很多文献将其简单翻译成消息系统。我个人认为并不是很恰当，因为它片面强调了消息主体的作用，而忽视了这类系统引以为豪的消息传递属性，就像引擎一样，具备某种能量转换传输的能力，所以我觉得翻译成消息引擎反倒更加贴切。</p><!-- [[[read_end]]] --><p>讲到这里，说点题外话。我觉得目前国内在翻译国外专有技术词汇方面做得不够标准化，各种名字和提法可谓五花八门。我举个例子，比如大名鼎鼎的Raft算法和Paxos算法。了解它的人都知道它们的作用是在分布式系统中让多个节点就某个决定达成共识，都属于Consensus Algorithm一族。如果你在搜索引擎中查找Raft算法，国内多是称呼它们为一致性算法。实际上我倒觉得翻译成共识算法是最准确的。我们使用“一致性”这个字眼太频繁了，国外的Consistency被称为一致性、Consensus也唤作一致性，甚至是Coherence都翻译成一致性。</p><p>还是拉回来继续聊消息引擎系统，那这类系统是做什么用的呢？我先来个官方严肃版本的答案。</p><p>根据维基百科的定义，消息引擎系统是一组规范。企业利用这组规范在不同系统之间传递语义准确的消息，实现松耦合的异步式数据传递。</p><p>果然是官方定义，有板有眼。如果觉得难于理解，那么可以试试我下面这个民间版：</p><p>系统A发送消息给消息引擎系统，系统B从消息引擎系统中读取A发送的消息。</p><p>最基础的消息引擎就是做这点事的！不论是上面哪个版本，它们都提到了两个重要的事实：</p><ul>\n<li>消息引擎传输的对象是消息；</li>\n<li>如何传输消息属于消息引擎设计机制的一部分。</li>\n</ul><p>既然消息引擎是用于在不同系统之间传输消息的，那么如何设计待传输消息的格式从来都是一等一的大事。试问一条消息如何做到信息表达业务语义而无歧义，同时它还要能最大限度地提供可重用性以及通用性？稍微停顿几秒去思考一下，如果是你，你要如何设计你的消息编码格式。</p><p>一个比较容易想到的是使用已有的一些成熟解决方案，比如使用CSV、XML亦或是JSON；又或者你可能熟知国外大厂开源的一些序列化框架，比如Google的Protocol Buffer或Facebook的Thrift。这些都是很酷的办法。那么现在我告诉你Kafka的选择：它使用的是纯二进制的字节序列。当然消息还是结构化的，只是在使用之前都要将其转换成二进制的字节序列。</p><p>消息设计出来之后还不够，消息引擎系统还要设定具体的传输协议，即我用什么方法把消息传输出去。常见的有两种方法：</p><ul>\n<li><strong>点对点模型</strong>：也叫消息队列模型。如果拿上面那个“民间版”的定义来说，那么系统A发送的消息只能被系统B接收，其他任何系统都不能读取A发送的消息。日常生活的例子比如电话客服就属于这种模型：同一个客户呼入电话只能被一位客服人员处理，第二个客服人员不能为该客户服务。</li>\n<li><strong>发布/订阅模型</strong>：与上面不同的是，它有一个主题（Topic）的概念，你可以理解成逻辑语义相近的消息容器。该模型也有发送方和接收方，只不过提法不同。发送方也称为发布者（Publisher），接收方称为订阅者（Subscriber）。和点对点模型不同的是，这个模型可能存在多个发布者向相同的主题发送消息，而订阅者也可能存在多个，它们都能接收到相同主题的消息。生活中的报纸订阅就是一种典型的发布/订阅模型。</li>\n</ul><p>比较酷的是Kafka同时支持这两种消息引擎模型，专栏后面我会分享Kafka是如何做到这一点的。</p><p>提到消息引擎系统，你可能会问JMS和它是什么关系。JMS是Java Message Service，它也是支持上面这两种消息引擎模型的。严格来说它并非传输协议而仅仅是一组API罢了。不过可能是JMS太有名气以至于很多主流消息引擎系统都支持JMS规范，比如ActiveMQ、RabbitMQ、IBM的WebSphere MQ和Apache Kafka。当然Kafka并未完全遵照JMS规范，相反，它另辟蹊径，探索出了一条特有的道路。</p><p>好了，目前我们仅仅是了解了消息引擎系统是做什么的以及怎么做的，但还有个重要的问题是为什么要使用它。</p><p>依旧拿上面“民间版”举例，我们不禁要问，为什么系统A不能直接发送消息给系统B，中间还要隔一个消息引擎呢？</p><p>答案就是“<strong>削峰填谷</strong>”。这四个字简直比消息引擎本身还要有名气。</p><p>我翻了很多文献，最常见的就是这四个字。所谓的“削峰填谷”就是指缓冲上下游瞬时突发流量，使其更平滑。特别是对于那种发送能力很强的上游系统，如果没有消息引擎的保护，“脆弱”的下游系统可能会直接被压垮导致全链路服务“雪崩”。但是，一旦有了消息引擎，它能够有效地对抗上游的流量冲击，真正做到将上游的“峰”填满到“谷”中，避免了流量的震荡。消息引擎系统的另一大好处在于发送方和接收方的松耦合，这也在一定程度上简化了应用的开发，减少了系统间不必要的交互。</p><p>说了这么多，可能你对“削峰填谷”并没有太多直观的感受。我还是举个例子来说明一下Kafka在这中间是怎么去“抗”峰值流量的吧。回想一下你在极客时间是如何购买这个课程的。如果我没记错的话极客时间每门课程都有一个专门的订阅按钮，点击之后进入到付费页面。这个简单的流程中就可能包含多个子服务，比如点击订阅按钮会调用订单系统生成对应的订单，而处理该订单会依次调用下游的多个子系统服务 ，比如调用支付宝和微信支付的接口、查询你的登录信息、验证课程信息等。显然上游的订单操作比较简单，它的TPS要远高于处理订单的下游服务，因此如果上下游系统直接对接，势必会出现下游服务无法及时处理上游订单从而造成订单堆积的情形。特别是当出现类似于秒杀这样的业务时，上游订单流量会瞬时增加，可能出现的结果就是直接压跨下游子系统服务。</p><p>解决此问题的一个常见做法是我们对上游系统进行限速，但这种做法对上游系统而言显然是不合理的，毕竟问题并不出现在它那里。所以更常见的办法是引入像Kafka这样的消息引擎系统来对抗这种上下游系统TPS的错配以及瞬时峰值流量。</p><p>还是这个例子，当引入了Kafka之后。上游订单服务不再直接与下游子服务进行交互。当新订单生成后它仅仅是向Kafka Broker发送一条订单消息即可。类似地，下游的各个子服务订阅Kafka中的对应主题，并实时从该主题的各自分区（Partition）中获取到订单消息进行处理，从而实现了上游订单服务与下游订单处理服务的解耦。这样当出现秒杀业务时，Kafka能够将瞬时增加的订单流量全部以消息形式保存在对应的主题中，既不影响上游服务的TPS，同时也给下游子服务留出了充足的时间去消费它们。这就是Kafka这类消息引擎系统的最大意义所在。</p><p>如果你对Kafka Broker、主题和分区等术语还不甚了解的话也不必担心，我会在专栏后面专门花时间介绍一下Kafka的常见概念和术语。</p><p>在今天结束之前，我还想和你分享一个自己的小故事。在2015年那会儿，我花了将近1年的时间阅读Kafka源代码，期间多次想要放弃。你要知道阅读将近50万行源码是多么痛的领悟。我还记得当初为了手写源代码注释，自己写满了一个厚厚的笔记本。不过幸运的是我坚持了下来，之前的所有努力也没有白费，以至于后面写书、写极客时间专栏就变成了一件件水到渠成的事情。</p><p>最后我想送给你一句话：<strong>聪明人也要下死功夫</strong>。我不记得这是曾国藩说的还是季羡林说的，但这句话对我有很大影响，当我感到浮躁的时候它能帮我静下心来踏踏实实做事情。希望这句话对你也有所启发。切记：聪明人要下死功夫！</p><p><img src=\"https://static001.geekbang.org/resource/image/8b/26/8bc58bf5bb98db09fd6ef343e0f28826.jpg?wh=2069*2560\" alt=\"\"></p><h2>开放讨论</h2><p>请谈谈你对消息引擎系统的理解，或者分享一下你的公司或组织是怎么使用消息引擎来处理实际问题的。</p><p>欢迎写下你的思考和答案，我们一起讨论。如果你觉得有所收获，也欢迎把文章分享给你的朋友。</p><p></p>","neighbors":{"left":{"article_title":"开篇词 | 为什么要学习Kafka？","id":98683},"right":{"article_title":"02 | 一篇文章带你快速搞定Kafka术语","id":99318}},"comments":[{"had_liked":false,"id":100742,"user_name":"huaweichen","can_delete":false,"product_type":"c1","uid":1249907,"ip_address":"","ucode":"974917DE2AE92E","user_header":"https://static001.geekbang.org/account/avatar/00/13/12/73/2183839d.jpg","comment_is_top":false,"comment_ctime":1559630226,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"474006032786","product_id":100029201,"comment_content":"曾国藩：真正聪明人都在下笨功夫！<br><br>https:&#47;&#47;zhuanlan.zhihu.com&#47;p&#47;25100394","like_count":111,"discussions":[{"author":{"id":1051470,"avatar":"https://static001.geekbang.org/account/avatar/00/10/0b/4e/fd946cb2.jpg","nickname":"allean","note":"","ucode":"A0D2DB4F219EAA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":5395,"discussion_content":"优秀！","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1566225489,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2055809,"avatar":"https://static001.geekbang.org/account/avatar/00/1f/5e/81/82709d6e.jpg","nickname":"码小呆","note":"","ucode":"44532D6ABF9340","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":586421,"discussion_content":"这不错","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1662196041,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":100767,"user_name":"孙志强","can_delete":false,"product_type":"c1","uid":1325997,"ip_address":"","ucode":"9C070F1E4EC6FF","user_header":"https://static001.geekbang.org/account/avatar/00/14/3b/ad/31193b83.jpg","comment_is_top":false,"comment_ctime":1559635206,"is_pvip":true,"replies":[{"id":"36328","content":"一行一行啃下来的。如果你也有兴趣，我建议可以先从kafka.log包开始读起，会很有收获的~~","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1559646678,"ip_address":"","comment_id":100767,"utype":1}],"discussion_count":6,"race_medal":0,"score":"276437542150","product_id":100029201,"comment_content":"讲讲怎么把50完行源代码读下来的? 嘿嘿","like_count":65,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":452671,"discussion_content":"一行一行啃下来的。如果你也有兴趣，我建议可以先从kafka.log包开始读起，会很有收获的~~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1559646678,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":2,"child_discussions":[{"author":{"id":1627556,"avatar":"https://static001.geekbang.org/account/avatar/00/18/d5/a4/ee3228a1.jpg","nickname":"Spicks and Specks","note":"","ucode":"5362796A81676C","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":549046,"discussion_content":"我发现这种事我一天都没干过，唯一做到的时候还是高中背文言文的时候","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1643530710,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":452671,"ip_address":""},"score":549046,"extra":""},{"author":{"id":2840141,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/lckPEyWYFBo5MITP4RIWcotQdbJBIoefftZfskUr5IyVpo2cnhASHF4kVCNtNw6cdNwPDSdPrFMhxc8P30f5JQ/132","nickname":"Geek_52688c","note":"","ucode":"1B9D0AC63436C3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":565341,"discussion_content":"如果看不懂怎么办，读源码需要很强的基础吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1650442864,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":452671,"ip_address":""},"score":565341,"extra":""}]},{"author":{"id":2621412,"avatar":"https://static001.geekbang.org/account/avatar/00/27/ff/e4/927547a9.jpg","nickname":"无名无姓","note":"","ucode":"487BD5AA2CD305","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":406964,"discussion_content":"我去，牛逼，致敬","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1634874673,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2066119,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/hlgyFUQVCrhaO46VJkrR3fE9hvOWnnwKsAj9gzK4Yp70BmU1a06YkwS1vNexMqkttorodO2ZMtiajBMXo7seD8g/132","nickname":"Geek_Daniel","note":"","ucode":"9AC8E4D12FBC72","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":319988,"discussion_content":"源码是什么语言写的？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1604222111,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1197455,"avatar":"https://static001.geekbang.org/account/avatar/00/12/45/8f/a56b2214.jpg","nickname":"innocent","note":"","ucode":"368659A0DDE7E4","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2066119,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/hlgyFUQVCrhaO46VJkrR3fE9hvOWnnwKsAj9gzK4Yp70BmU1a06YkwS1vNexMqkttorodO2ZMtiajBMXo7seD8g/132","nickname":"Geek_Daniel","note":"","ucode":"9AC8E4D12FBC72","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":328130,"discussion_content":"core是scala，客户端是Java","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606068034,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":319988,"ip_address":""},"score":328130,"extra":""}]}]},{"had_liked":false,"id":100509,"user_name":"开发无止境，BUG随身行","can_delete":false,"product_type":"c1","uid":1443903,"ip_address":"","ucode":"76AA8C6372E435","user_header":"https://static001.geekbang.org/account/avatar/00/16/08/3f/820ae54e.jpg","comment_is_top":false,"comment_ctime":1559568447,"is_pvip":false,"replies":[{"id":"36278","content":"这个场景使用Kafka Streams比较适合，它就是为read-process-write场景服务的","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1559614381,"ip_address":"","comment_id":100509,"utype":1}],"discussion_count":1,"race_medal":0,"score":"224897867839","product_id":100029201,"comment_content":"有个问题请教下老师:<br>之前也用过kafka，怎么解决实时结果响应问题呢？比如秒杀商品，生产者产生订单，消费者处理订单结果，那这结果如何实时返回给用户呢？","like_count":53,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":452578,"discussion_content":"这个场景使用Kafka Streams比较适合，它就是为read-process-write场景服务的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1559614381,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":100537,"user_name":"Lei Yang","can_delete":false,"product_type":"c1","uid":1100549,"ip_address":"","ucode":"306708B3EA4781","user_header":"https://static001.geekbang.org/account/avatar/00/10/cb/05/64d3b05a.jpg","comment_is_top":false,"comment_ctime":1559573077,"is_pvip":false,"replies":[{"id":"36279","content":"RabbitMQ属于比较传统的消息队列系统，支持标准的消息队列协议（AMQP, STOMP，MQTT等），如果你的应用程序需要支持这些协议，那么还是使用RabbitMQ。另外RabbitMQ支持比较复杂的consumer Routing，这点也是Kafka不提供的。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1559614657,"ip_address":"","comment_id":100537,"utype":1}],"discussion_count":2,"race_medal":0,"score":"212012970581","product_id":100029201,"comment_content":"老师可以讲一讲Kafka和别的mq的区别和最佳选择方法么？例如什么时候选择RabbitMQ什么时候选择Kafka等等","like_count":50,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":452589,"discussion_content":"RabbitMQ属于比较传统的消息队列系统，支持标准的消息队列协议（AMQP, STOMP，MQTT等），如果你的应用程序需要支持这些协议，那么还是使用RabbitMQ。另外RabbitMQ支持比较复杂的consumer Routing，这点也是Kafka不提供的。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1559614657,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1762749,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epfxaVbvxcTgyRGNOgDDusLWxpSBxdF9OUlaEpyy1NBibRXXbduONdQ4f2FP8ibWs5ca1CxhFibkPEXA/132","nickname":"Geek_c397cc","note":"","ucode":"671A84455CC5AE","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":69018,"discussion_content":"在哪看 视频啊","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1575251374,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":100483,"user_name":"Dovelol","can_delete":false,"product_type":"c1","uid":1253384,"ip_address":"","ucode":"9B5DDF7720F307","user_header":"https://static001.geekbang.org/account/avatar/00/13/20/08/bc06bc69.jpg","comment_is_top":false,"comment_ctime":1559564011,"is_pvip":false,"replies":[{"id":"36261","content":"mq和rpc的区别往大了说属于数据流模式（dataflow mode）的问题。我们常见的数据流有三种：1. 通过数据库；2. 通过服务调用（REST&#47;RPC）; 3. 通过异步消息传递（消息引擎，如Kafka）<br>RPC和MQ是有相似之处的，毕竟我们远程调用一个服务也可以看做是一个事件，但不同之处在于：<br>1. MQ有自己的buffer，能够对抗过载（overloaded）和不可用场景<br>2. MQ支持重试<br>3. 允许发布&#47;订阅模式<br>当然它们还有其他区别。应该这样说RPC是介于通过数据库和通过MQ之间的数据流模式。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1559611803,"ip_address":"","comment_id":100483,"utype":1}],"discussion_count":4,"race_medal":0,"score":"186243157739","product_id":100029201,"comment_content":"老师好，想问下有些业务用mq来做异步处理，为了削峰填谷，是不是上游发送消息成功就认为业务成功了，可能下游过很久去消费，那实时性要求很高的业务怎么办呢，比如生成了订单但是一直不处理也不好吧。另外想请教下老师的角度来讲下mq和rpc调用的区别是什么呢？","like_count":44,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":452568,"discussion_content":"mq和rpc的区别往大了说属于数据流模式（dataflow mode）的问题。我们常见的数据流有三种：1. 通过数据库；2. 通过服务调用（REST/RPC）; 3. 通过异步消息传递（消息引擎，如Kafka）\nRPC和MQ是有相似之处的，毕竟我们远程调用一个服务也可以看做是一个事件，但不同之处在于：\n1. MQ有自己的buffer，能够对抗过载（overloaded）和不可用场景\n2. MQ支持重试\n3. 允许发布/订阅模式\n当然它们还有其他区别。应该这样说RPC是介于通过数据库和通过MQ之间的数据流模式。","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1559611803,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2028946,"avatar":"","nickname":"Geek3443","note":"","ucode":"C6351639FD0633","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":288626,"discussion_content":"实时性要求很高的的考虑同步了比如RPC，MQ是异步的，生产者需要保证投递成功，消费者要保障及时消费。","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1593829087,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1436422,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLRKgow8PPLLgCqt6ZWiaylrFG1ButvHRSqOZ8hvFZFHoUGaoYCLlasbRiaaM0pTWKeeLbW4xBM4vjg/132","nickname":"执芳之手","note":"","ucode":"8199F569D6A8F1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":296302,"discussion_content":"RPC也是支持重试的吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1596505507,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1438860,"avatar":"https://static001.geekbang.org/account/avatar/00/15/f4/8c/0866b228.jpg","nickname":"子房","note":"","ucode":"CB05938C248BB3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1436422,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLRKgow8PPLLgCqt6ZWiaylrFG1ButvHRSqOZ8hvFZFHoUGaoYCLlasbRiaaM0pTWKeeLbW4xBM4vjg/132","nickname":"执芳之手","note":"","ucode":"8199F569D6A8F1","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":553510,"discussion_content":"有的\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1645940094,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":296302,"ip_address":""},"score":553510,"extra":""}]}]},{"had_liked":false,"id":103839,"user_name":"Shane","can_delete":false,"product_type":"c1","uid":1291344,"ip_address":"","ucode":"322D0A883BAF16","user_header":"https://static001.geekbang.org/account/avatar/00/13/b4/50/c5dad2dc.jpg","comment_is_top":false,"comment_ctime":1560526849,"is_pvip":false,"replies":[{"id":"37572","content":"http不属于消息传输协议，它是网络通信协议的一种，严格来说这是两个范畴或者说是两个层次上的协议。<br><br>通常来说，两个进程进行数据流交互的方式一般有三种：<br>1. 通过数据库：进程1写入数据库；进程2读取数据库<br>2. 通过服务调用：比如REST或RPC，而HTTP协议通常就作为REST方式的底层通讯协议<br>3. 通过消息传递的方式：进程1发送消息给名为broker的中间件，然后进程2从该broker中读取消息。消息传输协议属于这种模式<br><br>因此我说虽然我们都称它们为协议，但它们不是一个层次上的协议。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1560558647,"ip_address":"","comment_id":103839,"utype":1}],"discussion_count":4,"race_medal":0,"score":"151884382209","product_id":100029201,"comment_content":"老师，今天才学习到这篇文章，还是老师能够在百忙之中抽出时间来解答我的困惑。<br>这篇文章提到了消息的协议，老师这里介绍了两种模式一种是点对点，一种是订阅，发布模式。但是，为什么我一开始想到消息的协议是http之类的传输协议？这两个有什么区别和联系？","like_count":36,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454019,"discussion_content":"http不属于消息传输协议，它是网络通信协议的一种，严格来说这是两个范畴或者说是两个层次上的协议。\n\n通常来说，两个进程进行数据流交互的方式一般有三种：\n1. 通过数据库：进程1写入数据库；进程2读取数据库\n2. 通过服务调用：比如REST或RPC，而HTTP协议通常就作为REST方式的底层通讯协议\n3. 通过消息传递的方式：进程1发送消息给名为broker的中间件，然后进程2从该broker中读取消息。消息传输协议属于这种模式\n\n因此我说虽然我们都称它们为协议，但它们不是一个层次上的协议。","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1560558647,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1083395,"avatar":"https://static001.geekbang.org/account/avatar/00/10/88/03/805c8e0e.jpg","nickname":"追忆似水年华","note":"","ucode":"FB6C3EDC6988B6","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":1880,"discussion_content":"soap的webservice服务的一种实现格式，是在http协议之上的。主要想说的是，老师的分类，分布式系统中进程间通信有同步和异步的方式，异步实现了空间和时间的解耦。同步的方式有RPC、webservice，而进程的异步通信就可以通过消息队列或消息引擎实现。进程间通过数据库、缓存、消息队列（引擎）都可以看做事异步通信。按老师的分类感觉不拖","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1563026859,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1594532,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eqGaJsoQicG7Bo1qTpl3ruFd2zmIS4ECgqOejH2RkvXED8skWicwKzQdyFyhuFaIzk0wxHv0H1mshHg/132","nickname":"杨佳胜","note":"","ucode":"8834DC6E5A701D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":346371,"discussion_content":"我觉得rest和1.3不能并列，rest只是在1，3之上的一种数据读取交换方式","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1611927071,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1358936,"avatar":"https://static001.geekbang.org/account/avatar/00/14/bc/58/c66ef3f4.jpg","nickname":".","note":"","ucode":"96F575CA8C1064","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":336,"discussion_content":"采用soap呢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561454891,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":101700,"user_name":"第一装甲集群司令克莱斯特","can_delete":false,"product_type":"c1","uid":1265707,"ip_address":"","ucode":"4E8FBB23AD860B","user_header":"https://static001.geekbang.org/account/avatar/00/13/50/2b/2344cdaa.jpg","comment_is_top":false,"comment_ctime":1559919260,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"134703905436","product_id":100029201,"comment_content":"我们公司用kafaka通过埋点，日志分析，做链路监控，某个业务接口出现问题，预警系统发送消息给处理人。很及时有效，不用等运维那么慢的反馈了。合作方对比处理效率也很满意。","like_count":32},{"had_liked":false,"id":100476,"user_name":"jeffery","can_delete":false,"product_type":"c1","uid":1219972,"ip_address":"","ucode":"35E2DAA386FB86","user_header":"https://static001.geekbang.org/account/avatar/00/12/9d/84/171b2221.jpg","comment_is_top":false,"comment_ctime":1559561744,"is_pvip":false,"replies":[{"id":"36251","content":"和Pulsar的斯杰、翟佳都相识，不敢妄下结论。Flink + Kafka最近的确有标准套餐的趋势：）","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1559610958,"ip_address":"","comment_id":100476,"utype":1}],"discussion_count":2,"race_medal":0,"score":"113228711440","product_id":100029201,"comment_content":"pulsar高吞吐低延迟和kafka谁会主宰未来？夕哥、能不能拓展下flink+kafka的耦合！谢谢","like_count":27,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":452566,"discussion_content":"和Pulsar的斯杰、翟佳都相识，不敢妄下结论。Flink + Kafka最近的确有标准套餐的趋势：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1559610958,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1344281,"avatar":"https://static001.geekbang.org/account/avatar/00/14/83/19/0a3fe8c1.jpg","nickname":"Evan","note":"","ucode":"B877ABD0CF4661","race_medal":1,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":282450,"discussion_content":"Kafka Stream 对于小型公司来说，非常实用了，不用维护非常沉重的技术平台，另外小平台也不具被维护的技术实力。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1591974082,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":105396,"user_name":"杨鹏程baci","can_delete":false,"product_type":"c1","uid":1205949,"ip_address":"","ucode":"3D22F6B74340A8","user_header":"https://static001.geekbang.org/account/avatar/00/12/66/bd/bd5d503e.jpg","comment_is_top":false,"comment_ctime":1560992551,"is_pvip":false,"replies":[{"id":"38186","content":"嗯嗯，确实不太容易。因为这种通信方式一般是异步且是单向的，如果你需要这种回馈机制，最好使用服务调用 的方式","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561018959,"ip_address":"","comment_id":105396,"utype":1}],"discussion_count":3,"race_medal":0,"score":"87460338471","product_id":100029201,"comment_content":"胡夕老师好，我是第一次在这提问，这门课程我应该是0基础了，有一些疑问希望老师帮忙解答一下，用消息引擎的这种数据流数据方式，上游是不是就无法得知处理结果了，甚至是无法将返回值传回上游了？谢谢！","like_count":21,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454664,"discussion_content":"嗯嗯，确实不太容易。因为这种通信方式一般是异步且是单向的，如果你需要这种回馈机制，最好使用服务调用 的方式","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1561018959,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1173129,"avatar":"https://static001.geekbang.org/account/avatar/00/11/e6/89/d8aec012.jpg","nickname":"Liang","note":"","ucode":"E1A816EE5CE7DC","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":254926,"discussion_content":"如果想要上游应用得到返回结果，我觉得是不是可以借鉴RabbitMQ的做法？每条消息构建一个唯一的ID，消息被下游系统消费时，kafka客户端会把消费的结果发送到另一个topic，由上游去消费这个response的topic？","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1588347333,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1762252,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/e3/cc/0947ff0b.jpg","nickname":"nestle","note":"","ucode":"469800BED81B54","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1173129,"avatar":"https://static001.geekbang.org/account/avatar/00/11/e6/89/d8aec012.jpg","nickname":"Liang","note":"","ucode":"E1A816EE5CE7DC","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":300513,"discussion_content":"你说的是RabbitMQ RPC功能吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1598154615,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":254926,"ip_address":""},"score":300513,"extra":""}]}]},{"had_liked":false,"id":100571,"user_name":"燕子上","can_delete":false,"product_type":"c1","uid":1102811,"ip_address":"","ucode":"E82C78BE7D312A","user_header":"https://static001.geekbang.org/account/avatar/00/10/d3/db/5ce5bb26.jpg","comment_is_top":false,"comment_ctime":1559579182,"is_pvip":false,"replies":[{"id":"36330","content":"赞👍","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1559646749,"ip_address":"","comment_id":100571,"utype":1}],"discussion_count":2,"race_medal":0,"score":"87458925102","product_id":100029201,"comment_content":"我司直接把kafka当mq来使用，高吞吐、低延迟、松耦合。对！我司看上了松耦合，哪哪都要用kafka解耦，真正的面向kafka编程🤣","like_count":21,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":452605,"discussion_content":"赞👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1559646749,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1491357,"avatar":"https://static001.geekbang.org/account/avatar/00/16/c1/9d/7e64ee67.jpg","nickname":"云霄","note":"","ucode":"A4745981132E86","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":237779,"discussion_content":"我们准备重构老系统，计划是用kafka做日志处理，rabbitmq做消息队列，实际上我觉得只用kafka就足够了，不需要再增加rabbitmq。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587184034,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":100541,"user_name":"gnayuh","can_delete":false,"product_type":"c1","uid":1309119,"ip_address":"","ucode":"988909372D5B02","user_header":"https://static001.geekbang.org/account/avatar/00/13/f9/bf/bcf0fdf9.jpg","comment_is_top":false,"comment_ctime":1559573840,"is_pvip":false,"replies":[{"id":"36332","content":"它们的确很类似。特别是发布&#47;订阅与观察者模式。在《Head first Design Pattern》一书中更是有这样的话： Publishers + Subscribers = Observer Pattern<br><br>不过细究起来还是有些许不同，pub与sub之间通常都隔了一层，比如broker或message channel，但是Observer模式中Observer通常都直接对接被观测者，因此Pub&#47;Sub模式中组件的耦合度更低；另外Pub&#47;Sub经常是以异步的方式实现，而Observer模式通常都是同步的","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1559647213,"ip_address":"","comment_id":100541,"utype":1}],"discussion_count":1,"race_medal":0,"score":"87458919760","product_id":100029201,"comment_content":"老师讲的很好，我是之前那种听过kafaka等消息引擎大名的初学者，听完第一节课，联想到这个发布订阅模型跟之前学过java设计模式之观察者，总感觉它们之间有那么点类似，想知道它们之间的某种关系。还有就是学操作系统时候的生产者消费者也很像","like_count":20,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":452591,"discussion_content":"它们的确很类似。特别是发布/订阅与观察者模式。在《Head first Design Pattern》一书中更是有这样的话： Publishers + Subscribers = Observer Pattern\n\n不过细究起来还是有些许不同，pub与sub之间通常都隔了一层，比如broker或message channel，但是Observer模式中Observer通常都直接对接被观测者，因此Pub/Sub模式中组件的耦合度更低；另外Pub/Sub经常是以异步的方式实现，而Observer模式通常都是同步的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1559647213,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":100466,"user_name":"paradox","can_delete":false,"product_type":"c1","uid":1087615,"ip_address":"","ucode":"4ABDAB21D0F7E9","user_header":"https://static001.geekbang.org/account/avatar/00/10/98/7f/9ce24253.jpg","comment_is_top":false,"comment_ctime":1559559870,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"74574003902","product_id":100029201,"comment_content":"1. consesus algorithm，在区块链中多翻译为共识算法，而在其它领域多被翻译为一致性算法，个人觉得共识算法表意更清楚。<br><br>2. 削峰填谷，实际上就是流量整形的形象表达，主要还是为了应对上游瞬时大流量的冲击，避免出现流量毛刺现象，保护下游应用和数据库不被大流量打垮。","like_count":17,"discussions":[{"author":{"id":1116807,"avatar":"https://static001.geekbang.org/account/avatar/00/11/0a/87/56b07589.jpg","nickname":"nearzk","note":"","ucode":"CDEA6841E5F54C","race_medal":1,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":353001,"discussion_content":"小词儿整的挺硬","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1614942660,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":104955,"user_name":"Bin滨","can_delete":false,"product_type":"c1","uid":1298294,"ip_address":"","ucode":"7F113EF3AF81E9","user_header":"https://static001.geekbang.org/account/avatar/00/13/cf/76/9e413c61.jpg","comment_is_top":false,"comment_ctime":1560891764,"is_pvip":true,"replies":[{"id":"38030","content":"嗯嗯，DDIA是一本神书：）<br><br>其实这个定义最早还是Kafka作者Jay Kreps提出的，有兴趣可以看看Kafka的论文：http:&#47;&#47;notes.stephenholiday.com&#47;Kafka.pdf<br>以及Jay Kreps的 《I ❤️ Logs》","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1560905810,"ip_address":"","comment_id":104955,"utype":1}],"discussion_count":1,"race_medal":0,"score":"70280368500","product_id":100029201,"comment_content":"谢谢知识分享。<br>在Martin Kleppmann 的书中把kafka 定义成 log-based message brocker， 这个基本上是对kafka最简单的定义了。append-only， partition， totally ordered 是比较需要理解的概念。 ","like_count":16,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454502,"discussion_content":"嗯嗯，DDIA是一本神书：）\n\n其实这个定义最早还是Kafka作者Jay Kreps提出的，有兴趣可以看看Kafka的论文：http://notes.stephenholiday.com/Kafka.pdf\n以及Jay Kreps的 《I ❤️ Logs》","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1560905810,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":100558,"user_name":"吃饭饭","can_delete":false,"product_type":"c1","uid":1231549,"ip_address":"","ucode":"95CFA07CDA2957","user_header":"https://static001.geekbang.org/account/avatar/00/12/ca/bd/a51ae4b2.jpg","comment_is_top":false,"comment_ctime":1559577077,"is_pvip":false,"replies":[{"id":"36254","content":"指定--zookeeper是老版本的消费者，新版本需要指定--bootstrap-server。新版本消费者API是0.9版本引入的，主要是为了移除消费者API对ZooKeeper的依赖。专栏后面有文章谈到这一点。<br>新版本使用方法：<br>bin&#47;kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1559611210,"ip_address":"","comment_id":100558,"utype":1}],"discussion_count":2,"race_medal":0,"score":"61689119221","product_id":100029201,"comment_content":"胡老师好，我想请教一个学习方法，我在做Kafka测试的时候遇到一个问题，我记得以前老版本的时候使用命令行进行Demo测试时，消费消息到控制台使用：bin&#47;kafka-console-consumer.sh --zookeeper localhost:2181&#47;kafka --topic test 就可以，但是今天我换了高版本发现不对了，以前的 --zookeeper 新版本不支持了。知道这点后我希望能够从官网找到具体是哪个版本开始删除这个指令的以及删除的原因，但是我这种为题我不会查询官网，只能从百度等搜索引擎上看其他人的一些总结，希望老师能给示例一番，感谢。","like_count":14,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":452598,"discussion_content":"指定--zookeeper是老版本的消费者，新版本需要指定--bootstrap-server。新版本消费者API是0.9版本引入的，主要是为了移除消费者API对ZooKeeper的依赖。专栏后面有文章谈到这一点。\n新版本使用方法：\nbin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1559611210,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1670763,"avatar":"https://static001.geekbang.org/account/avatar/00/19/7e/6b/36fc4516.jpg","nickname":"FIRE","note":"","ucode":"85861D990FB3AB","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":296376,"discussion_content":"我的kafka_2.11-0.10.0.1版本只能用-zookeeper,奇怪了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1596527005,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":100421,"user_name":"东风第一枝","can_delete":false,"product_type":"c1","uid":1402697,"ip_address":"","ucode":"0CD0F62E90DAD8","user_header":"https://static001.geekbang.org/account/avatar/00/15/67/49/864dba17.jpg","comment_is_top":false,"comment_ctime":1559554110,"is_pvip":false,"replies":[{"id":"36170","content":"Kafka是以消息引擎起家的，后面转型成流处理平台。没有冒犯的意思，我不认为消息引擎是流处理的一种。事实上，流处理在意的是如何处理无限数据集的问题。它们是不同的领域：）","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1559559452,"ip_address":"","comment_id":100421,"utype":1}],"discussion_count":2,"race_medal":0,"score":"53099161662","product_id":100029201,"comment_content":"Kafka官网的描述是“Apache Kafka® is a distributed streaming platform.”，我觉得这里的重点在于分布式和流式处理，而且我认为消息引擎也可以看做是流式处理的一种，不知道老师怎么看？","like_count":12,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":452540,"discussion_content":"Kafka是以消息引擎起家的，后面转型成流处理平台。没有冒犯的意思，我不认为消息引擎是流处理的一种。事实上，流处理在意的是如何处理无限数据集的问题。它们是不同的领域：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1559559452,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1344281,"avatar":"https://static001.geekbang.org/account/avatar/00/14/83/19/0a3fe8c1.jpg","nickname":"Evan","note":"","ucode":"B877ABD0CF4661","race_medal":1,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":282451,"discussion_content":"学习了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1591974321,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":100613,"user_name":"杨俊","can_delete":false,"product_type":"c1","uid":1158214,"ip_address":"","ucode":"3CAE634618D924","user_header":"https://static001.geekbang.org/account/avatar/00/11/ac/46/7e24bad6.jpg","comment_is_top":false,"comment_ctime":1559606418,"is_pvip":true,"replies":[{"id":"36570","content":"如果是升级Kafka这种主动停机，应该采用rolling upgrade来做，不至于服务中断。如果是大面积突然宕机，快速处理反而是最重要的。如果在乎上游系统的消息delivery语义，增加retries的同时试试幂等producer吧","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1559815269,"ip_address":"","comment_id":100613,"utype":1}],"discussion_count":2,"race_medal":0,"score":"48804246674","product_id":100029201,"comment_content":"希望后面能说下要是kafka突然宕机或者临时停止服务进行更新，上游服务的消息该怎么正确更好处理呢？怎么保证消息的能够在kafka恢复工作的时候正确传递，谢谢","like_count":11,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":452616,"discussion_content":"如果是升级Kafka这种主动停机，应该采用rolling upgrade来做，不至于服务中断。如果是大面积突然宕机，快速处理反而是最重要的。如果在乎上游系统的消息delivery语义，增加retries的同时试试幂等producer吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1559815269,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":1054827,"avatar":"https://static001.geekbang.org/account/avatar/00/10/18/6b/a1448af1.jpg","nickname":"贝影","note":"","ucode":"19545C8DCBF8A2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":543574,"discussion_content":"幂等producer是指业务自己来保证吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1641209238,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":452616,"ip_address":""},"score":543574,"extra":""}]}]},{"had_liked":false,"id":102521,"user_name":"清晨吼于林","can_delete":false,"product_type":"c1","uid":1112920,"ip_address":"","ucode":"6ADCB9B9FB8330","user_header":"https://static001.geekbang.org/account/avatar/00/10/fb/58/6c422e70.jpg","comment_is_top":false,"comment_ctime":1560242268,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"44509915228","product_id":100029201,"comment_content":"1、A系统为什么不能直接把消息发送给B系统？ 这可以出一个面试题，😆<br>2、作者的学习经历确实让人很振奋，可不可以花一个章节，专门讲讲，你当时是怎么读kafka的源码的？🙏","like_count":10},{"had_liked":false,"id":100525,"user_name":"草头","can_delete":false,"product_type":"c1","uid":1004177,"ip_address":"","ucode":"FA5FE436FE7163","user_header":"https://static001.geekbang.org/account/avatar/00/0f/52/91/c0414437.jpg","comment_is_top":false,"comment_ctime":1559570990,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"40214276654","product_id":100029201,"comment_content":"50万行，我的天……大牛都是这样炼成的！向大佬看齐，做不到喊喊口号也好！","like_count":9},{"had_liked":false,"id":100471,"user_name":"安不安生","can_delete":false,"product_type":"c1","uid":1242774,"ip_address":"","ucode":"8F6D16871C46C4","user_header":"https://static001.geekbang.org/account/avatar/00/12/f6/96/cc4d553e.jpg","comment_is_top":false,"comment_ctime":1559561008,"is_pvip":false,"replies":[{"id":"36235","content":"hmmm... 使用Kafka自己把控度会高一些。另外很多公司对数据出公网是有顾虑的，使用云上的服务必然涉及到将 公司数据传给云服务器的问题。如果是敏感数据这也是要考虑的","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1559607322,"ip_address":"","comment_id":100471,"utype":1}],"discussion_count":1,"race_medal":0,"score":"35919299376","product_id":100029201,"comment_content":"我们公司用来传输视频切片，然后使用集群进行视频分析，之前曾经用过kafka ，因为没有人熟悉，不会维护，导致放弃，现在使用aws kinesis 服务，怎么才能说服领导引进kafka 呢？<br>","like_count":8,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":452563,"discussion_content":"hmmm... 使用Kafka自己把控度会高一些。另外很多公司对数据出公网是有顾虑的，使用云上的服务必然涉及到将 公司数据传给云服务器的问题。如果是敏感数据这也是要考虑的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1559607322,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":100444,"user_name":"tracy","can_delete":false,"product_type":"c1","uid":1230864,"ip_address":"","ucode":"24C3A7422BF040","user_header":"https://static001.geekbang.org/account/avatar/00/12/c8/10/36f36b42.jpg","comment_is_top":false,"comment_ctime":1559556825,"is_pvip":false,"replies":[{"id":"36165","content":"如果是以实现高吞吐量为主要目标，Kafka是不错的首选；如果是以实现业务系统为主要目标，特别是金融类业务，可以考虑应用Kafka的流处理组件Kafka Streams。不过坦率说目前将Kafka应用于纯业务系统的并不多，但是前景依然可期：）","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1559559181,"ip_address":"","comment_id":100444,"utype":1}],"discussion_count":1,"race_medal":0,"score":"35919295193","product_id":100029201,"comment_content":"现在消息中间件很多，想要了解kafka和其他消息中间件的优劣点，系统选型时需要考虑什么？","like_count":8,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":452552,"discussion_content":"如果是以实现高吞吐量为主要目标，Kafka是不错的首选；如果是以实现业务系统为主要目标，特别是金融类业务，可以考虑应用Kafka的流处理组件Kafka Streams。不过坦率说目前将Kafka应用于纯业务系统的并不多，但是前景依然可期：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1559559181,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":209406,"user_name":"Nicko","can_delete":false,"product_type":"c1","uid":1690659,"ip_address":"","ucode":"C27CE2846C4BB1","user_header":"https://static001.geekbang.org/account/avatar/00/19/cc/23/6b17fe26.jpg","comment_is_top":false,"comment_ctime":1587545998,"is_pvip":false,"replies":[{"id":"78228","content":"各种可能。内存溢出是最常见的。还可能导致下游磁盘被撑爆，TCP连接被打满，带宽被用完等情形。总之都是因为上下游没有解耦，从而使得上游流量直接冲击到下游","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1587604617,"ip_address":"","comment_id":209406,"utype":1}],"discussion_count":1,"race_medal":0,"score":"31652317070","product_id":100029201,"comment_content":"请教一下流量太高压垮下游系统，是指什么意思，比如是内存溢出吗，为什么会导致下游系统的内存溢出等等。","like_count":7,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492792,"discussion_content":"各种可能。内存溢出是最常见的。还可能导致下游磁盘被撑爆，TCP连接被打满，带宽被用完等情形。总之都是因为上下游没有解耦，从而使得上游流量直接冲击到下游","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587604617,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":104030,"user_name":"@%初%@","can_delete":false,"product_type":"c1","uid":1053509,"ip_address":"","ucode":"2B8A6134675ED7","user_header":"https://static001.geekbang.org/account/avatar/00/10/13/45/16c60da2.jpg","comment_is_top":false,"comment_ctime":1560595725,"is_pvip":true,"replies":[{"id":"37734","content":"延时大可能有很多种因素，producer、broker、consumer任何一端都可能引入较长的延时。最好还是先定位发生延时的组件再进行调优","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1560687274,"ip_address":"","comment_id":104030,"utype":1}],"discussion_count":1,"race_medal":0,"score":"31625366797","product_id":100029201,"comment_content":"现在在做商城业务，我们使用的mysql+es存储数据，开始时，用的双写模式，即先写mysql，在刷es，这样tps上不去，后来改成异步消费，借助大数据，他们监听binlog文件，监听订单的变化，然后放入kafka，我们监听kafka，异步刷新es，但是延迟有点高，最后发展成，自己开发了一套canel，监听mysql主库，刷新es，对于要求实时性比较高的查询，先走数据库搂一把，，，之后再去搂es，我一直没搞清楚，为什么kafka的消息有时候会延迟那么大，期待老师后面的内容有所涉及，，，以便真正理解原理，，，不至于出了问题一脸懵逼。。。。","like_count":7,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454096,"discussion_content":"延时大可能有很多种因素，producer、broker、consumer任何一端都可能引入较长的延时。最好还是先定位发生延时的组件再进行调优","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1560687274,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":101987,"user_name":"诗泽","can_delete":false,"product_type":"c1","uid":1031865,"ip_address":"","ucode":"F28BE01C3FD12F","user_header":"https://static001.geekbang.org/account/avatar/00/0f/be/b9/f2481c2c.jpg","comment_is_top":false,"comment_ctime":1560087569,"is_pvip":false,"replies":[{"id":"36819","content":"特别大的消息传输其实不太适合于Kafka。对于那种特别大的文件，你可以选择将文件的指针或引用作为消息在Kafka中传递。当然如果一定要传输大文件，需要调整很多Kafka端的参数，专栏后面会有介绍~~","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1560136853,"ip_address":"","comment_id":101987,"utype":1}],"discussion_count":1,"race_medal":0,"score":"31624858641","product_id":100029201,"comment_content":"看到有位同学留言说用kafka 传输视频切片做视频分析的。这种场景的msg大小应该比较大吧，想请教一下老师，kafka 是否适用于传输图片或视频切片等大msg场景，如果适用的话应对kafka 做出什么配置调整呢，谢谢！P.S. 极客时间要是支持读者间相互交流就好了🤣","like_count":7,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":453206,"discussion_content":"特别大的消息传输其实不太适合于Kafka。对于那种特别大的文件，你可以选择将文件的指针或引用作为消息在Kafka中传递。当然如果一定要传输大文件，需要调整很多Kafka端的参数，专栏后面会有介绍~~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1560136853,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":101389,"user_name":"QQ怪","can_delete":false,"product_type":"c1","uid":1211223,"ip_address":"","ucode":"1A39B8433D9208","user_header":"https://static001.geekbang.org/account/avatar/00/12/7b/57/a9b04544.jpg","comment_is_top":false,"comment_ctime":1559796755,"is_pvip":false,"replies":[{"id":"36563","content":"Kafka对消息持久性是有一定程度的保障的，当然这种保障是有限度的。其实，任何分布式系统在数据持久性方面的保障都是有条件的。但是你还是可以安全地认为：配置良好的Kafka是不会丢失消息的","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1559813912,"ip_address":"","comment_id":101389,"utype":1}],"discussion_count":2,"race_medal":0,"score":"31624567827","product_id":100029201,"comment_content":"我指的数据不一致可能会容许消息丢失，麻烦老师解惑😂","like_count":7,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":452940,"discussion_content":"Kafka对消息持久性是有一定程度的保障的，当然这种保障是有限度的。其实，任何分布式系统在数据持久性方面的保障都是有条件的。但是你还是可以安全地认为：配置良好的Kafka是不会丢失消息的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1559813912,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2237298,"avatar":"https://static001.geekbang.org/account/avatar/00/22/23/72/8397b85e.jpg","nickname":"hanna","note":"","ucode":"E60EEA9D4BFAC8","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":556764,"discussion_content":"学到了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1647504224,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":200562,"user_name":"周谦","can_delete":false,"product_type":"c1","uid":1054264,"ip_address":"","ucode":"43520078455347","user_header":"https://static001.geekbang.org/account/avatar/00/10/16/38/88eb9377.jpg","comment_is_top":false,"comment_ctime":1585618462,"is_pvip":false,"replies":[{"id":"75166","content":"如果分区过多的确会拉低顺序写的性能，因为要向不同的路径下写入消息","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1585665199,"ip_address":"","comment_id":200562,"utype":1}],"discussion_count":1,"race_medal":0,"score":"27355422238","product_id":100029201,"comment_content":"请教下 kafka说的写磁盘高性能是由于是顺序写，但是多个进程写多个文件时候这种顺序写的高性能还存在不？","like_count":6,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":490068,"discussion_content":"如果分区过多的确会拉低顺序写的性能，因为要向不同的路径下写入消息","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1585665199,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":107796,"user_name":"丁满和彭彭","can_delete":false,"product_type":"c1","uid":1329727,"ip_address":"","ucode":"A6150E4D4D12DE","user_header":"https://static001.geekbang.org/account/avatar/00/14/4a/3f/25db3a2d.jpg","comment_is_top":false,"comment_ctime":1561610747,"is_pvip":false,"replies":[{"id":"39133","content":"不能拒绝。这个是留存策略。一旦超过阈值开启老消息删除，而不是拒绝新消息。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561680917,"ip_address":"","comment_id":107796,"utype":1}],"discussion_count":1,"race_medal":0,"score":"27331414523","product_id":100029201,"comment_content":"老师，卡夫卡的消息超过了log.retention.bytes以后可以拒绝生产者的消息么，现在默认好像直接删除","like_count":6,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":455677,"discussion_content":"不能拒绝。这个是留存策略。一旦超过阈值开启老消息删除，而不是拒绝新消息。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561680917,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":206228,"user_name":"小晏子","can_delete":false,"product_type":"c1","uid":1132337,"ip_address":"","ucode":"3AAA6FB5ACB6AE","user_header":"https://static001.geekbang.org/account/avatar/00/11/47/31/f35367c8.jpg","comment_is_top":false,"comment_ctime":1586826064,"is_pvip":false,"replies":[{"id":"77015","content":"嗯嗯，这是个挺好的应用场景：）","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1586830615,"ip_address":"","comment_id":206228,"utype":1}],"discussion_count":1,"race_medal":1,"score":"23061662544","product_id":100029201,"comment_content":"我们的系统中大量使用消息引擎系统做异步化控制，比如订单状态流转，支付什么的，如果有任何失败都会进入失败队列，然后人工干预。","like_count":5,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491720,"discussion_content":"嗯嗯，这是个挺好的应用场景：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586830615,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":122684,"user_name":"钱","can_delete":false,"product_type":"c1","uid":1009652,"ip_address":"","ucode":"2C92A243A463D4","user_header":"https://static001.geekbang.org/account/avatar/00/0f/67/f4/9a1feb59.jpg","comment_is_top":false,"comment_ctime":1565490492,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"23040326972","product_id":100029201,"comment_content":"课前思考<br>消息引擎系统ABC？这是要讲啥？消息引擎系统的基础？消息引擎系统是啥？kafka是消息引擎系统的一种？kafka这种消息引擎系统的特点？<br>课后思考<br>1：和课前猜的类似吧！只是老师讲解的更多，首先，回答了<br>kafka是什么？——一种消息引擎系统<br>kafka的作用？——系统解藕、流量削峰填谷<br>kafka的特点？——源于大数据，处理大数据问题比较强<br>2：老师为啥这么优秀？<br>老师是聪明人，并且是肯下死功夫的聪明人，50万源码啃下来，消化掉，距离成为大牛就不远了。这么可能是为啥自己出不了专栏的原因吧😄<br>阅读源码和牛逼的人做朋友，自己自然也就差不了。<br>3：明白了kafka是什么？有什么特点？和其他的xxxMQ比有什么异同后，我更好奇他们各自的特点是怎么实现的？为什么这样实现？<br>4：系统解藕容易理解，削峰填谷也容易理解，高吞出、低延迟是怎么做到的？接收消息、存储消息、发送消息的数据结构是啥？消息是有序的嘛？<br><br>我们有自己的MQ中间件，使用简单，性能强悍，不过研发、维护、问题定位和排查都是基础架构部的人来做，怎么实现的，内部结构是啥像个小黑盒，我想弄明白kafka，理解这个也就不难啦！","like_count":5},{"had_liked":false,"id":101256,"user_name":"Savage.M","can_delete":false,"product_type":"c1","uid":1111385,"ip_address":"","ucode":"2AF8D63405E27D","user_header":"https://static001.geekbang.org/account/avatar/00/10/f5/59/f1a04e5e.jpg","comment_is_top":false,"comment_ctime":1559752894,"is_pvip":false,"replies":[{"id":"36487","content":"我和RocketMQ的冯总也相识，说实话不敢妄言两者的优劣，网上也有一些文章比较过两者的区别。就目前公开的资料查看，RocketMQ宣称擅长主打金融业务领域场景，我个人是比较相信的。Kafka更多还是发家于大数据领域。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1559780018,"ip_address":"","comment_id":101256,"utype":1}],"discussion_count":1,"race_medal":0,"score":"23034589374","product_id":100029201,"comment_content":"老师，您好！感觉kafka和rocketmq的设计有很多相似之处，能否列举一下他们之间的区别呢？如果要选型，哪些场景适合用kafka，哪些场景适合用rocketmq呢？谢谢！","like_count":5,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":452875,"discussion_content":"我和RocketMQ的冯总也相识，说实话不敢妄言两者的优劣，网上也有一些文章比较过两者的区别。就目前公开的资料查看，RocketMQ宣称擅长主打金融业务领域场景，我个人是比较相信的。Kafka更多还是发家于大数据领域。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1559780018,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":226107,"user_name":"Fighter","can_delete":false,"product_type":"c1","uid":1282641,"ip_address":"","ucode":"B1925EE400372D","user_header":"https://static001.geekbang.org/account/avatar/00/13/92/51/0505254d.jpg","comment_is_top":false,"comment_ctime":1591952610,"is_pvip":false,"replies":[{"id":"83308","content":"1、下功夫；2、先从broker端源码读起；3、参见第一条：）","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1591973292,"ip_address":"","comment_id":226107,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18771821794","product_id":100029201,"comment_content":"老师能不能读kafka源码的一些心得或是方法分享下 我们后来者能站在巨人肩膀上 少走弯路","like_count":4,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":498108,"discussion_content":"1、下功夫；2、先从broker端源码读起；3、参见第一条：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1591973292,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":106161,"user_name":"dream","can_delete":false,"product_type":"c1","uid":1117793,"ip_address":"","ucode":"65B33D32FA8BE9","user_header":"https://static001.geekbang.org/account/avatar/00/11/0e/61/ae68f8eb.jpg","comment_is_top":false,"comment_ctime":1561192012,"is_pvip":false,"replies":[{"id":"38502","content":"Active MQ属于传统的消息中间件，支持传统的消息传输协议（AMQP, STOMP, MQTT），而且这些传统中间件（比如RabbitMQ）都支持比较复杂的消息路由，这些都是Kafka不具备的。如果你的应用要支持这些协议或者是用于SOA中的应用互联，那么这些传统消息中间件比较合适。<br><br>反观Kafka还是在大数据场景下孕育的框架，如果你的场景都是大数据方面的，可以考虑使用Kafka。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561339199,"ip_address":"","comment_id":106161,"utype":1}],"discussion_count":2,"race_medal":0,"score":"18741061196","product_id":100029201,"comment_content":"老师能不能分享一下，kafka作为消息引擎（不考虑流式处理），对比其他消息引擎的优势，什么时候用kafka，什么时候用Active MQ等消息引擎？","like_count":4,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454983,"discussion_content":"Active MQ属于传统的消息中间件，支持传统的消息传输协议（AMQP, STOMP, MQTT），而且这些传统中间件（比如RabbitMQ）都支持比较复杂的消息路由，这些都是Kafka不具备的。如果你的应用要支持这些协议或者是用于SOA中的应用互联，那么这些传统消息中间件比较合适。\n\n反观Kafka还是在大数据场景下孕育的框架，如果你的场景都是大数据方面的，可以考虑使用Kafka。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561339199,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1134861,"avatar":"https://static001.geekbang.org/account/avatar/00/11/51/0d/fc1652fe.jpg","nickname":"James","note":"","ucode":"48B0F2A334D1C1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":46174,"discussion_content":"留名，\n需要传统消息传输协议，路由的话，就不能使用卡夫卡。\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1573127766,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":101835,"user_name":"ChenJZ","can_delete":false,"product_type":"c1","uid":1123518,"ip_address":"","ucode":"50DF1CFB41C90D","user_header":"https://static001.geekbang.org/account/avatar/00/11/24/be/19c9d3e1.jpg","comment_is_top":false,"comment_ctime":1559989194,"is_pvip":false,"replies":[{"id":"36813","content":"我个人认为是很适合的。至于采用什么方式，我不太确认你这里的解析是什么意思。不过Kafka的确支持自定义的serializer&#47;deserializer","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1560136034,"ip_address":"","comment_id":101835,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18739858378","product_id":100029201,"comment_content":"有个问题想请教一下老师：<br>（1）需要接收一个2000多个站的实时数据流，kafka是否适用于这样的场景？<br>（2）如果适合的使用kafka，采用什么方式进行解析，然后分站存储？谢谢<br>","like_count":4,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":453137,"discussion_content":"我个人认为是很适合的。至于采用什么方式，我不太确认你这里的解析是什么意思。不过Kafka的确支持自定义的serializer/deserializer","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1560136034,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":100745,"user_name":"huaweichen","can_delete":false,"product_type":"c1","uid":1249907,"ip_address":"","ucode":"974917DE2AE92E","user_header":"https://static001.geekbang.org/account/avatar/00/13/12/73/2183839d.jpg","comment_is_top":false,"comment_ctime":1559631113,"is_pvip":false,"replies":[{"id":"36327","content":"1. 传统MQ通常都支持标准的消息队列协议，比如AMQP, STOMP，MQTT等。如果你的应用程序需要支持这些协议，那么还是应该使用传统的MQ。Kafka则是基于提交日志，可能有更大的吞吐量，通常比较适合于大数据领域（比如最经典的日志收集与分析）<br>2. Kafka是适合于应用到Event sourcing场景，毕竟它有比较好的容错性、高伸缩性以及存储特性。唯一令人有些担心的是topic的数量。在Event sourcing中topic数量可能会很多。超多topic分区的Kafka集群在性能上是有隐患的。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1559646610,"ip_address":"","comment_id":100745,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18739500297","product_id":100029201,"comment_content":"请问老师，Kafka对CQRS的架构，有没有什么帮助呢？<br>之前我们公司使用的是RabbitMQ，后来发现ActiveMQ更快，就采用了ActiveMQ。<br>现在又有同事想换Kafka，说Kafka更scalable，更利于CQRS的架构风格（Replay all events history）等等。<br><br>总的来说，想请教一下老师：<br>1. Kafka和其它MQ，各自之间，有什么决定性的优势。<br>2. Kafka对CQRS event sourcing架构有什么强有力的帮助吗？（其它MQ系统呢？）<br><br>谢谢老师。学习了。","like_count":4,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":452663,"discussion_content":"1. 传统MQ通常都支持标准的消息队列协议，比如AMQP, STOMP，MQTT等。如果你的应用程序需要支持这些协议，那么还是应该使用传统的MQ。Kafka则是基于提交日志，可能有更大的吞吐量，通常比较适合于大数据领域（比如最经典的日志收集与分析）\n2. Kafka是适合于应用到Event sourcing场景，毕竟它有比较好的容错性、高伸缩性以及存储特性。唯一令人有些担心的是topic的数量。在Event sourcing中topic数量可能会很多。超多topic分区的Kafka集群在性能上是有隐患的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1559646610,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":100654,"user_name":"木 易","can_delete":false,"product_type":"c1","uid":1033212,"ip_address":"","ucode":"5C3BBB5958A4B5","user_header":"","comment_is_top":false,"comment_ctime":1559611106,"is_pvip":false,"replies":[{"id":"36270","content":"Kafka依赖ZooKeeper实现集群成员管理、领导者选举等。从架构上来说，目前所有Kafka Broker启动时都需要向ZooKeeper注册","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1559612321,"ip_address":"","comment_id":100654,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18739480290","product_id":100029201,"comment_content":"老师，Kafka和ZooKeeper是什么关系。以及整个架构，可以整体介绍一下吗。","like_count":4,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":452626,"discussion_content":"Kafka依赖ZooKeeper实现集群成员管理、领导者选举等。从架构上来说，目前所有Kafka Broker启动时都需要向ZooKeeper注册","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1559612321,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":100477,"user_name":"aof","can_delete":false,"product_type":"c1","uid":1062864,"ip_address":"","ucode":"5815D63C4926BC","user_header":"https://static001.geekbang.org/account/avatar/00/10/37/d0/26975fba.jpg","comment_is_top":false,"comment_ctime":1559561932,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"18739431116","product_id":100029201,"comment_content":"公司主要是将APP埋点数据以json格式推到kafka中，然后我们数据开发这边那structured  streaming去消费解析，另外一个就是保存MySQL的binlog，去跟踪业务库的变化。","like_count":4},{"had_liked":false,"id":206589,"user_name":"shi.yunlai","can_delete":false,"product_type":"c1","uid":1210248,"ip_address":"","ucode":"9E7124F22F182A","user_header":"https://static001.geekbang.org/account/avatar/00/12/77/88/965e9951.jpg","comment_is_top":false,"comment_ctime":1586905003,"is_pvip":false,"replies":[{"id":"77335","content":"嗯嗯，大家有个地方一起交流是最好的努力方式了：）","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1587003926,"ip_address":"","comment_id":206589,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14471806891","product_id":100029201,"comment_content":"除了看课程，最帅气的就是看评论里面大家的各种问题和精彩解答，个个都在下笨功夫","like_count":3,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491835,"discussion_content":"嗯嗯，大家有个地方一起交流是最好的努力方式了：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587003926,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":102132,"user_name":"niemo","can_delete":false,"product_type":"c1","uid":1100142,"ip_address":"","ucode":"71364762238367","user_header":"https://static001.geekbang.org/account/avatar/00/10/c9/6e/1ac1c955.jpg","comment_is_top":false,"comment_ctime":1560146524,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"14445048412","product_id":100029201,"comment_content":"我们公司使用kafka做不同数据库之间的准实时同步","like_count":3,"discussions":[{"author":{"id":1833151,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIHziahkgLzMiaAIRicJUd2n8asMFntzHzmmpIvlw3smg45vx0aGLqYkU446esficyEQ7m5j6AOdHeDBg/132","nickname":"常星星","note":"","ucode":"ABE70EEFB0C0DA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":226613,"discussion_content":"最近才看这个文章，看到了评论，想问下，如果出现消费失败，会不会出现各个数据库数据不一致的情况呢？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586437285,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1132337,"avatar":"https://static001.geekbang.org/account/avatar/00/11/47/31/f35367c8.jpg","nickname":"小晏子","note":"","ucode":"3AAA6FB5ACB6AE","race_medal":1,"user_type":1,"is_pvip":false},"reply_author":{"id":1833151,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIHziahkgLzMiaAIRicJUd2n8asMFntzHzmmpIvlw3smg45vx0aGLqYkU446esficyEQ7m5j6AOdHeDBg/132","nickname":"常星星","note":"","ucode":"ABE70EEFB0C0DA","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":231687,"discussion_content":"应该会有手工干预","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586826427,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":226613,"ip_address":""},"score":231687,"extra":""}]}]},{"had_liked":false,"id":100952,"user_name":"你好旅行者","can_delete":false,"product_type":"c1","uid":1154101,"ip_address":"","ucode":"5C72A428DC28F3","user_header":"https://static001.geekbang.org/account/avatar/00/11/9c/35/9dc79371.jpg","comment_is_top":false,"comment_ctime":1559694854,"is_pvip":false,"replies":[{"id":"36415","content":"并没有说Kafka不能用于实际业务，只是说Kafka的确是从大数据场景里面发源出来的，而且很多业务应用要求支持传统的消息队列协议，这一点Kafka就无法做到了。另外，专栏后面会涉及Kafka提供高吞吐的原因，简单来说就是采用了log-structured的结构加上充分利用了操作系统提供的各种优化","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1559699491,"ip_address":"","comment_id":100952,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14444596742","product_id":100029201,"comment_content":"有个问题想请教老师：<br><br>为什么业务生产上都会用rabbitmq或者rocketmq，但一到日志的问题上kafka就是不二选择？根据老师之前的回答，是因为Kafka相比于其他的mq在吞吐量上更有优势，可以详细解释一下为什么Kafka可以提供高吞吐量吗？","like_count":3,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":452753,"discussion_content":"并没有说Kafka不能用于实际业务，只是说Kafka的确是从大数据场景里面发源出来的，而且很多业务应用要求支持传统的消息队列协议，这一点Kafka就无法做到了。另外，专栏后面会涉及Kafka提供高吞吐的原因，简单来说就是采用了log-structured的结构加上充分利用了操作系统提供的各种优化","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1559699491,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":206239,"user_name":"而立斋","can_delete":false,"product_type":"c1","uid":1087258,"ip_address":"","ucode":"5FED6E9E148195","user_header":"https://static001.geekbang.org/account/avatar/00/10/97/1a/389eab84.jpg","comment_is_top":false,"comment_ctime":1586827674,"is_pvip":false,"replies":[{"id":"77013","content":"厉害！","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1586830593,"ip_address":"","comment_id":206239,"utype":1}],"discussion_count":2,"race_medal":0,"score":"10176762266","product_id":100029201,"comment_content":"1. Apache Kafka是一款开源的消息引擎系统。<br>2. 什么是消息引擎系统呢？一组规范，企业使用这组规范在不同系统之间传递语义明确消息，进而来实现松耦合的异步式数据传输。系统A发送消息给消息引擎系统，系统B从消息引擎系统读取系统A发布的消息。<br>3. 要实现消息的传输，首先要确定的就是从消息格式统一的问题，常见有各种序列化的方法，但Kafka使用的是纯二进制序列的形式<br>4. 明确了消息格式之后，还要定一下消息传输的协议问题。怎么传输呢？有点对点，明确发送方和接收方的方式；还有订阅&#47;发布的方式，这种方式可以有多个发送方，也可以有多个接收方。<br>5. 以上两个点明确之后，就开始讨论消息引擎系统的作用了，换句话来说就是，使用消息引擎系统能带来什么好处呢？根据定义就可以得出一些相应的结论：系统异步化，并且以松散耦合的形式来搭建系统。这是现在搭建系统的趋势，这也是消息引擎系统解决问题的根本吧。另一方面的好处也是显而易见的，可以用来缓解上下游系统速度不匹配的问题（削峰填谷），峰指的是瞬时的流量洪峰，谷指的就是消息引擎系统强大的抗压能力，就是一个巨大的天坑。就等着你来填满它","like_count":2,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491724,"discussion_content":"厉害！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586830593,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1087258,"avatar":"https://static001.geekbang.org/account/avatar/00/10/97/1a/389eab84.jpg","nickname":"而立斋","note":"","ucode":"5FED6E9E148195","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":231846,"discussion_content":"我准备买源码阅读，发现这个还没读完，收到老师结硬寨打呆仗的启发，所以现在打算用心从头开始精读一遍。阅读过程中发现文章的一些问题，后续会一块儿发出来，但是措辞难免会有一些不当，到时候还望老师见谅。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586832149,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":206195,"user_name":"而立斋","can_delete":false,"product_type":"c1","uid":1087258,"ip_address":"","ucode":"5FED6E9E148195","user_header":"https://static001.geekbang.org/account/avatar/00/10/97/1a/389eab84.jpg","comment_is_top":false,"comment_ctime":1586822505,"is_pvip":false,"replies":[{"id":"77005","content":"消息系统这个词仅仅强调了这是一个消息的系统，实际上，对于消息引擎而言，最重要的是如何传输消息的机制，而非消息本身：）","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1586829211,"ip_address":"","comment_id":206195,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10176757097","product_id":100029201,"comment_content":"【像 Kafka 这一类的系统国外有专属的名字叫 Messaging System，国内很多文献将其简单翻译成消息系统。我个人认为并不是很恰当，因为它片面强调了消息主体的作用，而忽视了这类系统引以为豪的消息传递属性，就像引擎一样，具备某种能量转换传输的能力，所以我觉得翻译成消息引擎反倒更加贴切。】<br>这个段落没太看懂，消息系统怎么就片面的强调了消息主体的作用呢？该怎么理解呢？","like_count":2,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491708,"discussion_content":"消息系统这个词仅仅强调了这是一个消息的系统，实际上，对于消息引擎而言，最重要的是如何传输消息的机制，而非消息本身：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586829211,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":156837,"user_name":"洛奇","can_delete":false,"product_type":"c1","uid":1624355,"ip_address":"","ucode":"662B4005721119","user_header":"https://static001.geekbang.org/account/avatar/00/18/c9/23/76511858.jpg","comment_is_top":false,"comment_ctime":1574987295,"is_pvip":false,"replies":[{"id":"60179","content":"我的感觉是别设有什么具体的目标，就是单纯地看源码反而效果比较好","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1574988304,"ip_address":"","comment_id":156837,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10164921887","product_id":100029201,"comment_content":"五十万行代码，老师您是每一行都能看明白吗？看不明白的地方该怎么办，直接绕过吗？阅读源码需要什么基础知识？初级程序员学习技术最好的方式我觉得还是看极客时间的专栏，基础不扎实的人直接看源码效果不好，是吗？","like_count":2,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":476247,"discussion_content":"我的感觉是别设有什么具体的目标，就是单纯地看源码反而效果比较好","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1574988304,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":114892,"user_name":"清风","can_delete":false,"product_type":"c1","uid":1542078,"ip_address":"","ucode":"AB2D169746BC23","user_header":"https://static001.geekbang.org/account/avatar/00/17/87/be/7466bf26.jpg","comment_is_top":false,"comment_ctime":1563425234,"is_pvip":false,"replies":[{"id":"41998","content":"可以业务去重","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563458931,"ip_address":"","comment_id":114892,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10153359826","product_id":100029201,"comment_content":"老师，消息的重复消费问题有什么解决方案吗","like_count":2,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":458869,"discussion_content":"可以业务去重","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563458931,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":106814,"user_name":"Knight²º¹⁸","can_delete":false,"product_type":"c1","uid":1089754,"ip_address":"","ucode":"BDCB830B6A730F","user_header":"https://static001.geekbang.org/account/avatar/00/10/a0/da/4f50f1b2.jpg","comment_is_top":false,"comment_ctime":1561389067,"is_pvip":false,"replies":[{"id":"38666","content":"很多约定俗成的翻译我们就遵守吧：）","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561423170,"ip_address":"","comment_id":106814,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10151323659","product_id":100029201,"comment_content":"说到翻译这个事儿最让我记忆深刻的是random access&#47;read，明明是任意读偏偏被翻译成了随机读，困扰了我好久。","like_count":2,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":455233,"discussion_content":"很多约定俗成的翻译我们就遵守吧：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561423170,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":102244,"user_name":"彰玉","can_delete":false,"product_type":"c1","uid":1225932,"ip_address":"","ucode":"E35220D59D9B27","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/IyrKOr1vBfpdjgKEqRTOMpiciaMZtlVv6WLFt4lENZRtibt0O9EaOuI1DGIyfeiazD8x8Z1hgicVHZhOxIhez6pkQIw/132","comment_is_top":false,"comment_ctime":1560168446,"is_pvip":false,"replies":[{"id":"36909","content":"其实也没什么具体的原因。从我个人的理解，kafka项目开始的时候还没有etcd~","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1560214719,"ip_address":"","comment_id":102244,"utype":1}],"discussion_count":3,"race_medal":0,"score":"10150103038","product_id":100029201,"comment_content":"k8s用ETCD替换了zK   kafka选zk的原因能说说不","like_count":2,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":453310,"discussion_content":"其实也没什么具体的原因。从我个人的理解，kafka项目开始的时候还没有etcd~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1560214719,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1008348,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/62/dc/8876c73b.jpg","nickname":"moooofly","note":"","ucode":"4A20795C281B6F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":54514,"discussion_content":"不知道后续 kafka 是否有使用 etcd 替换 zk 的计划？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1574301501,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1054958,"avatar":"https://static001.geekbang.org/account/avatar/00/10/18/ee/a1ed60d1.jpg","nickname":"ABC","note":"","ucode":"7501AD9C0C4A70","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1008348,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/62/dc/8876c73b.jpg","nickname":"moooofly","note":"","ucode":"4A20795C281B6F","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":555452,"discussion_content":"现在才开始学专栏，最新消息是Kafka3.x计划移除zk了，不依赖外部服务。（在测试中，估计很快到生产阶段）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1646908745,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":54514,"ip_address":""},"score":555452,"extra":""}]}]},{"had_liked":false,"id":100567,"user_name":"skyhackvip","can_delete":false,"product_type":"c1","uid":1083561,"ip_address":"","ucode":"05C7784736C97A","user_header":"https://static001.geekbang.org/account/avatar/00/10/88/a9/789fc9b0.jpg","comment_is_top":false,"comment_ctime":1559578811,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10149513403","product_id":100029201,"comment_content":"我们常用Kafka消息引擎接受日志流，然后倒入bi系统。","like_count":2},{"had_liked":false,"id":320661,"user_name":"追风筝的人","can_delete":false,"product_type":"c1","uid":1488020,"ip_address":"","ucode":"2993D60F94C396","user_header":"https://static001.geekbang.org/account/avatar/00/16/b4/94/2796de72.jpg","comment_is_top":false,"comment_ctime":1636443181,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5931410477","product_id":100029201,"comment_content":"依旧拿上面“民间版”举例，我们不禁要问，为什么系统 A 不能直接发送消息给系统 B，中间还要隔一个消息引擎呢？答案就是“削峰填谷”。这四个字简直比消息引擎本身还要有名气。","like_count":1},{"had_liked":false,"id":185228,"user_name":"技术修行者","can_delete":false,"product_type":"c1","uid":1013147,"ip_address":"","ucode":"28CA41A1214D6B","user_header":"https://static001.geekbang.org/account/avatar/00/0f/75/9b/611e74ab.jpg","comment_is_top":false,"comment_ctime":1583539135,"is_pvip":true,"replies":[{"id":"71720","content":"1. Kafka起源于日志收集，不表示它只能做日志收集。实际上目前Kafka是流处理平台，类似于Flink、Spark Streaming。ELK做日志收集和简单的处理还是很方便的。Kafka则更痛用一些<br>2. 常见的做法是Kafka + ELK，利用ELK收集日志，毕竟Kafka Connect这块还是不太好用。同时利用Kafka的高可靠性、高持久性来保证数据质量","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1583667274,"ip_address":"","comment_id":185228,"utype":1}],"discussion_count":1,"race_medal":5,"score":"5878506431","product_id":100029201,"comment_content":"我们在做的系统是基于微服务的，主要用Kafka做两件事情：<br>1. 不同的微服务之间如果有依赖，会用Kafka来传递消息。<br>2. 和第三方系统交互，避免紧耦合。<br><br>我们现在的系统日志是在用EK收集，我想请教一下，<br>1. 既然Kafka是基于大数据系统开发的，日志收集也是它的开家本领，那么Kafka和ELK各有什么优缺点？<br>2. 一个完善的日志收集和管理系统，怎么能充分发挥Kafka和ELK的优点？","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":486297,"discussion_content":"1. Kafka起源于日志收集，不表示它只能做日志收集。实际上目前Kafka是流处理平台，类似于Flink、Spark Streaming。ELK做日志收集和简单的处理还是很方便的。Kafka则更痛用一些\n2. 常见的做法是Kafka + ELK，利用ELK收集日志，毕竟Kafka Connect这块还是不太好用。同时利用Kafka的高可靠性、高持久性来保证数据质量","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1583667274,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":116907,"user_name":"刘彬","can_delete":false,"product_type":"c1","uid":1053307,"ip_address":"","ucode":"D18611F7FFF2A8","user_header":"https://static001.geekbang.org/account/avatar/00/10/12/7b/456e46f2.jpg","comment_is_top":false,"comment_ctime":1563937236,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"5858904532","product_id":100029201,"comment_content":"现在企业里面kafka的应用场景大多还是流计算多一些吧？<br>“削峰填谷”kafka是挡住了流量冲击，但是这样会不会也影响消费的性能呢？比如消息一致性！<br>期待老师后面的内容讲解！","like_count":1},{"had_liked":false,"id":105919,"user_name":"better","can_delete":false,"product_type":"c1","uid":1257750,"ip_address":"","ucode":"2B9BCCED753D7F","user_header":"https://static001.geekbang.org/account/avatar/00/13/31/16/f2269e73.jpg","comment_is_top":false,"comment_ctime":1561104606,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"5856071902","product_id":100029201,"comment_content":"笔记<br>## 1.消息引擎系统<br><br>### 1.1 Kafka是什么<br><br>Apache Kafka 是一款开源的消息引擎系统。<br><br>### 1.2 消息引擎系统的作用<br>维基百科上的定义：消息引擎系统是一组规范。企业利用这组规范在不同系统之间传递语义准确的消息，实现松耦合的异步式数据传递。<br>简单理解：系统A发送消息给消息引擎系统，系统B从消息引擎系统中读取A发送的消息。也就是说消息引擎是用于在不同系统之间传输消息的。<br>消息引擎传输的对象是消息，而如何传输消息属于消息引擎设计机制的一部分<br><br>### 1.3 常见的两种消息引擎系统传输协议(即我用什么方式把消息传输出去)<br><br>- 点对点模型：也叫消息队列模型。系统A发送的消息只能被系统B接收，其他任何系统都不能读取A发送的消息。<br>- 发布&#47;订阅模型：与点对点模型不用的是，发布&#47;订阅模型有一个主题(Topic)的概念，可以理解为逻辑语义相近的消息容器。发布&#47;订阅模型的发送方成为发布者(Publisher)，接收方(Subscriber)。和点对点模型不同的是，这个模型可能存在多个发布者向相同的主题发送消息，而订阅者也可能存在多个，它们都能接收到相同主题的消息。","like_count":1},{"had_liked":false,"id":101820,"user_name":"浅唱诺","can_delete":false,"product_type":"c1","uid":1042470,"ip_address":"","ucode":"D8E802F439B47D","user_header":"https://static001.geekbang.org/account/avatar/00/0f/e8/26/e2cbfe68.jpg","comment_is_top":false,"comment_ctime":1559983411,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5854950707","product_id":100029201,"comment_content":"老师讲的很不错，我是有点基础了，这次学习希望能有一定的提升。","like_count":1},{"had_liked":false,"id":101244,"user_name":"RogerFederer","can_delete":false,"product_type":"c1","uid":1564110,"ip_address":"","ucode":"27EE3C62EF3493","user_header":"https://static001.geekbang.org/account/avatar/00/17/dd/ce/f676ccdb.jpg","comment_is_top":false,"comment_ctime":1559748646,"is_pvip":false,"replies":[{"id":"36484","content":"这就是学校和工程界不匹配的情形。P2P的提法是标准的学院派称谓，我觉得我们理解了意思就好。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1559779825,"ip_address":"","comment_id":101244,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5854715942","product_id":100029201,"comment_content":"胡老师：上文中讲到消息队列要把消息传输出去有2中模型：点对点模型(消息队列模型)；发布&#47;订阅模型；然后举例点对点模式 系统 A 发送的消息只能被系统 B 接收。<br>一开始我就以为 消息的发送者只能有一个。但当在公司做老系统的队列改造时才明白;选择队列模型,消息的生产者不只是一个。多个系统会往一个队列里面丢消息,消费系统只有一个。<br>那这么一说来,称这个叫点对点模型是不是不合适？<br>","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":452866,"discussion_content":"这就是学校和工程界不匹配的情形。P2P的提法是标准的学院派称谓，我觉得我们理解了意思就好。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1559779825,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":101074,"user_name":"QQ怪","can_delete":false,"product_type":"c1","uid":1211223,"ip_address":"","ucode":"1A39B8433D9208","user_header":"https://static001.geekbang.org/account/avatar/00/12/7b/57/a9b04544.jpg","comment_is_top":false,"comment_ctime":1559710063,"is_pvip":false,"replies":[{"id":"36479","content":"你指的数据不一致具体是什么意思呢？ ？","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1559779571,"ip_address":"","comment_id":101074,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5854677359","product_id":100029201,"comment_content":"我们公司一般用消息引擎用于日志系统，但一般上游业务tps比较多的情况也会像作者一样做削峰填谷处理，但我想问问老师kafka是不是更加适合做日志分发系统？是不是kafka有一定程度上不保证数据一致性?","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":452792,"discussion_content":"你指的数据不一致具体是什么意思呢？ ？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1559779571,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":100958,"user_name":"曾轼麟","can_delete":false,"product_type":"c1","uid":1451391,"ip_address":"","ucode":"D418371AC11270","user_header":"https://static001.geekbang.org/account/avatar/00/16/25/7f/473d5a77.jpg","comment_is_top":false,"comment_ctime":1559695636,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5854662932","product_id":100029201,"comment_content":"我们使用kafka做微服务间的数据下发，例如资金服务接口表数据就是来源上游的kafka消息","like_count":1},{"had_liked":false,"id":356355,"user_name":"码小呆","can_delete":false,"product_type":"c1","uid":2055809,"ip_address":"广东","ucode":"44532D6ABF9340","user_header":"https://static001.geekbang.org/account/avatar/00/1f/5e/81/82709d6e.jpg","comment_is_top":false,"comment_ctime":1662196088,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1662196088","product_id":100029201,"comment_content":"做开发工作有2年多了,还没有在公司项目中使用kafka,或许是我在的都是小公司的!!","like_count":0},{"had_liked":false,"id":352532,"user_name":"余晓杰","can_delete":false,"product_type":"c1","uid":1889760,"ip_address":"","ucode":"97269A045FE190","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEIoRAqV3Yic1wa2gKDq74h1SB5azIpZAOE2uY43CZevju1vd4wxibXq3Y6LJvxJ4tlsJEEmkI64ZJvw/132","comment_is_top":false,"comment_ctime":1658748336,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1658748336","product_id":100029201,"comment_content":"1","like_count":0},{"had_liked":false,"id":350190,"user_name":"摊牌","can_delete":false,"product_type":"c1","uid":1453182,"ip_address":"","ucode":"F142596BFE4594","user_header":"https://static001.geekbang.org/account/avatar/00/16/2c/7e/f1efd18b.jpg","comment_is_top":false,"comment_ctime":1656644126,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1656644126","product_id":100029201,"comment_content":"请教下胡老师，您是如何为源码添加注释的，看文字您是选择手写笔记本记录的方式。","like_count":0},{"had_liked":false,"id":348293,"user_name":"Geek_c89d45","can_delete":false,"product_type":"c1","uid":2900023,"ip_address":"","ucode":"43BDF15D01B1D4","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJnywjwpeXxRz0ibZS0ibmhVytkVnXiaTjPuicicWNcjiaUsiaicTEGQgtR4bj3ddMnUOKUiau2zcb1UG1R99g/132","comment_is_top":false,"comment_ctime":1654942126,"is_pvip":true,"discussion_count":0,"race_medal":1,"score":"1654942126","product_id":100029201,"comment_content":"我们公司使用kafka采集各个节点报上来的日志文件，原始文件是分散在各个子节点的并且是加密的，需要所谓的适配层处理后生成parquet，然后保存到hdfs上，供后续的spark引擎做汇总分析","like_count":0},{"had_liked":false,"id":340008,"user_name":"王布斯","can_delete":false,"product_type":"c1","uid":1141005,"ip_address":"","ucode":"F435E512E4DDC3","user_header":"https://static001.geekbang.org/account/avatar/00/11/69/0d/7ba74474.jpg","comment_is_top":false,"comment_ctime":1648537937,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1648537937","product_id":100029201,"comment_content":"我们的服务使用卡夫卡 就是 Go 然后 订阅了一个主题 之后就是其他服务比如一些绑定关系发送过来 我们接受了之后处理信息都没有发送，都是接收","like_count":0},{"had_liked":false,"id":334979,"user_name":"易飞","can_delete":false,"product_type":"c1","uid":2630424,"ip_address":"","ucode":"32AC28754237F7","user_header":"https://static001.geekbang.org/account/avatar/00/28/23/18/4284361f.jpg","comment_is_top":false,"comment_ctime":1645238339,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1645238339","product_id":100029201,"comment_content":"使用kafka解耦合两个系统，","like_count":0},{"had_liked":false,"id":330605,"user_name":"Cxy","can_delete":false,"product_type":"c1","uid":1222478,"ip_address":"","ucode":"B90B914ABD1164","user_header":"https://static001.geekbang.org/account/avatar/00/12/a7/4e/aa9c0f43.jpg","comment_is_top":false,"comment_ctime":1642065654,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1642065654","product_id":100029201,"comment_content":"最后这句好 很有意义！","like_count":0},{"had_liked":false,"id":327841,"user_name":"syc","can_delete":false,"product_type":"c1","uid":1787922,"ip_address":"","ucode":"C8142823C9C05B","user_header":"https://static001.geekbang.org/account/avatar/00/1b/48/12/3d177d3d.jpg","comment_is_top":false,"comment_ctime":1640324397,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1640324397","product_id":100029201,"comment_content":"结合第一节课，进行学习记录<br>Kafka在业务系统提供的能力：<br>1.削峰填谷：也就是所谓的流量整形，承接上游系统的高并发，将消息存于Kafka中，下游按正常速率处理消息，不至于直接承接高并发请求，导致链路崩掉；<br>2.系统间的松耦合：系统与系统之间减少相互调用，也就减少了相互依赖，让每个系统更关注于本身的业务，比如订单生成后，需要通知库存系统、优惠券系统等，通过Kafka及能做到系统和系统之间的低耦合<br><br>问题点<br>1. 结果的实时性：Kafka更多的只是做一个事件触发的作用，而不能替代系统间的调用，比如获取库存时，还是直接调用系统会比较好，刚刚翻记录，说是用Kafka stream，read-process-write可以比较好的改善实时性的问题","like_count":0},{"had_liked":false,"id":318641,"user_name":"沙","can_delete":false,"product_type":"c1","uid":1377412,"ip_address":"","ucode":"131A5114452DE5","user_header":"https://static001.geekbang.org/account/avatar/00/15/04/84/cb0a009b.jpg","comment_is_top":false,"comment_ctime":1635381917,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1635381917","product_id":100029201,"comment_content":"我们使用Kafka来完成服务的异步操作和削峰限流","like_count":0},{"had_liked":false,"id":317764,"user_name":"哒哒哒","can_delete":false,"product_type":"c1","uid":1061803,"ip_address":"","ucode":"9378AD329F8AE0","user_header":"https://static001.geekbang.org/account/avatar/00/10/33/ab/d8ba4242.jpg","comment_is_top":false,"comment_ctime":1634954415,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1634954415","product_id":100029201,"comment_content":"这节的内容看似只是概述，但是还是有很多给人启发的知识。尤其是用了一段时间的kafka以后。","like_count":0},{"had_liked":false,"id":314651,"user_name":"summer","can_delete":false,"product_type":"c1","uid":1333872,"ip_address":"","ucode":"08C3232561C7D9","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJkKNKezgVwHxn13elAia7xueLnHAguTrbXcnMmDWWpUsnVWj4iapXWSs4tJGZvL6VotbudUaGSLo6w/132","comment_is_top":false,"comment_ctime":1633280405,"is_pvip":true,"replies":[{"id":"114435","content":"producer和consumer的主API大多是单线程的","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1634004369,"ip_address":"","comment_id":314651,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1633280405","product_id":100029201,"comment_content":"老师好，作为初学者有个问题，在一个消费实例的情况下，kafka的基础api是不是单线程的","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527752,"discussion_content":"producer和consumer的主API大多是单线程的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1634004369,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":314507,"user_name":"Sundnd","can_delete":false,"product_type":"c1","uid":1131316,"ip_address":"","ucode":"BA60F74AD42F9A","user_header":"https://static001.geekbang.org/account/avatar/00/11/43/34/5684e180.jpg","comment_is_top":false,"comment_ctime":1633160794,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1633160794","product_id":100029201,"comment_content":"额，我是从业务系统研发的角度看的，并不能苟同削峰的直接作用或者叫目的。<br><br>站在业务开发的角度看，消息的最大价值是为了解决降低业务的复杂度——单一应用的职责解耦，不需要关注太多的业务领域，消息事件是纯粹的技术手段解决业务复杂度问题——分治。<br><br>而保障丢失、重发、削峰...什么 balabala 的东西，是因为引入的消息后要解决的技术问题。因为如果都揉到一起做的话，其实database 事务也可以做到的，只是太复杂了。<br><br>p.s 本来在 ipad 上看，忍不住拿起电脑写下评论。 <br>当然我没做过大数据，只是站在业务开发的角度看消息价值。","like_count":0},{"had_liked":false,"id":305074,"user_name":"日拱一卒","can_delete":false,"product_type":"c1","uid":1056944,"ip_address":"","ucode":"3BDFD6F473862C","user_header":"https://static001.geekbang.org/account/avatar/00/10/20/b0/0a1551c4.jpg","comment_is_top":false,"comment_ctime":1627804559,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1627804559","product_id":100029201,"comment_content":"感谢作者。很受益。","like_count":0},{"had_liked":false,"id":304527,"user_name":"阿文","can_delete":false,"product_type":"c1","uid":1467219,"ip_address":"","ucode":"B53454CA52BD7E","user_header":"https://static001.geekbang.org/account/avatar/00/16/63/53/b4590ccc.jpg","comment_is_top":false,"comment_ctime":1627465607,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1627465607","product_id":100029201,"comment_content":"哈哈，第一次听到 削峰削骨 这个词。精辟","like_count":0},{"had_liked":false,"id":302879,"user_name":"西楼","can_delete":false,"product_type":"c1","uid":2307289,"ip_address":"","ucode":"BEF1FB185B5A0E","user_header":"https://static001.geekbang.org/account/avatar/00/23/34/d9/4c6df0f2.jpg","comment_is_top":false,"comment_ctime":1626420050,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1626420050","product_id":100029201,"comment_content":"传输协议：P2P , Pub&#47;Sub<br>消息引擎系统：削峰填谷","like_count":0},{"had_liked":false,"id":297410,"user_name":"扭高达💨🌪","can_delete":false,"product_type":"c1","uid":1906054,"ip_address":"","ucode":"3737A3DCD58EA3","user_header":"https://static001.geekbang.org/account/avatar/00/1d/15/86/15b942d6.jpg","comment_is_top":false,"comment_ctime":1623506820,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1623506820","product_id":100029201,"comment_content":"聪明人也要下死功夫","like_count":0},{"had_liked":false,"id":296211,"user_name":"一颗小橘子🍊","can_delete":false,"product_type":"c1","uid":2045627,"ip_address":"","ucode":"584557A3E26B33","user_header":"https://static001.geekbang.org/account/avatar/00/1f/36/bb/67d689c5.jpg","comment_is_top":false,"comment_ctime":1622807542,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1622807542","product_id":100029201,"comment_content":"消息队列除了削峰填谷 还有异步通信的作用","like_count":0},{"had_liked":false,"id":289732,"user_name":"wnz27","can_delete":false,"product_type":"c1","uid":1130122,"ip_address":"","ucode":"BC9ACB6B7C6FD9","user_header":"https://static001.geekbang.org/account/avatar/00/11/3e/8a/891b0e58.jpg","comment_is_top":false,"comment_ctime":1619157732,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1619157732","product_id":100029201,"comment_content":"最后两段话值一个亿的小目标","like_count":0},{"had_liked":false,"id":289164,"user_name":"黄福超","can_delete":false,"product_type":"c1","uid":2277769,"ip_address":"","ucode":"BAADC19A45FE05","user_header":"","comment_is_top":false,"comment_ctime":1618900031,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1618900031","product_id":100029201,"comment_content":"在公司内，我开发的功能中有用到kafka和canal结合做数据的同步","like_count":0},{"had_liked":false,"id":280908,"user_name":"xp","can_delete":false,"product_type":"c1","uid":2345297,"ip_address":"","ucode":"2A963D84E9762B","user_header":"https://static001.geekbang.org/account/avatar/00/23/c9/51/dd75af0b.jpg","comment_is_top":false,"comment_ctime":1614479379,"is_pvip":false,"replies":[{"id":"102231","content":"因为是消息队列，在业务峰值时引入队列帮忙平滑尖峰时刻的流量（都先缓存在队列中，不会对下游业务造成急速冲击），反向也是相同道理","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1614821849,"ip_address":"","comment_id":280908,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1614479379","product_id":100029201,"comment_content":"老师，我是这个领域的小白，我就一个问题，为什么kafaka能够削峰填谷？至于松耦合等好处我都能理解。","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":516239,"discussion_content":"因为是消息队列，在业务峰值时引入队列帮忙平滑尖峰时刻的流量（都先缓存在队列中，不会对下游业务造成急速冲击），反向也是相同道理","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1614821849,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":278267,"user_name":"子夜2104","can_delete":false,"product_type":"c1","uid":1070286,"ip_address":"","ucode":"C4FF54AEA6002F","user_header":"https://static001.geekbang.org/account/avatar/00/10/54/ce/92029d2f.jpg","comment_is_top":false,"comment_ctime":1612853180,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1612853180","product_id":100029201,"comment_content":"Kafka作为一个消息引擎，它可以很好的承接上游的巨大能量，然后平稳的输出到下游系统。在系统中可以保护子系统不被流量冲垮，做到削峰填谷。","like_count":0},{"had_liked":false,"id":271036,"user_name":"张洋","can_delete":false,"product_type":"c1","uid":1182914,"ip_address":"","ucode":"549BE5DEEF8417","user_header":"https://static001.geekbang.org/account/avatar/00/12/0c/c2/bad34a50.jpg","comment_is_top":false,"comment_ctime":1609378778,"is_pvip":true,"replies":[{"id":"98423","content":"比较能用到的是队列和基于事件驱动的思路，其他就是一个编程方面的技巧了<br>","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1609721608,"ip_address":"","comment_id":271036,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1609378778","product_id":100029201,"comment_content":"二刷。公司最终选型的是rabbitmq，平时没问题的时候还好，服务端出现问题的时候，确实排查问题很难，看不到错误日志，不能跟源码（erlang没人会）。更不能自己解决，只能社区提交bug，等待社区的解决方案。 希望二刷收获更大吧。 有一个疑问就是 学习了kafka 的设计思路和原理，怎么去应用到我们日常的开发和设计当中去呢？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":512824,"discussion_content":"比较能用到的是队列和基于事件驱动的思路，其他就是一个编程方面的技巧了\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1609721608,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":270562,"user_name":"山海","can_delete":false,"product_type":"c1","uid":1702117,"ip_address":"","ucode":"77FA9967E58FA3","user_header":"https://static001.geekbang.org/account/avatar/00/19/f8/e5/119d5c15.jpg","comment_is_top":false,"comment_ctime":1609159953,"is_pvip":false,"replies":[{"id":"98144","content":"加油加油。目标不用设定得那么宏伟。每天看一点就可以了","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1609205072,"ip_address":"","comment_id":270562,"utype":1}],"discussion_count":1,"race_medal":1,"score":"1609159953","product_id":100029201,"comment_content":"老师真的太厉害了，我每次雄心勃勃的想看一个框架的源码，结果最后都没有坚持下来，这次我要真正去下决心了。 ","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":512670,"discussion_content":"加油加油。目标不用设定得那么宏伟。每天看一点就可以了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1609205072,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":256091,"user_name":"李俊超","can_delete":false,"product_type":"c1","uid":1029549,"ip_address":"","ucode":"C70D72BA6E92F3","user_header":"https://static001.geekbang.org/account/avatar/00/0f/b5/ad/381c57be.jpg","comment_is_top":false,"comment_ctime":1603525476,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1603525476","product_id":100029201,"comment_content":"对消息引擎系统的理解最深的体会是北京上下班高峰期地铁口的排队体验.  由于在上下班高峰期, 上班族乘坐地铁的需求激增,此时地铁的运输能力没办法完成承载高峰期的乘客运输能力,所以在地铁口通过排队的方式来限流进入.来自四面八方小区的上班族进入地铁口的时候,进入了排队的队列中(乘客队列).等待着进站口一列接着一列的地铁来消费排队的上班族.","like_count":0},{"had_liked":false,"id":252999,"user_name":"爱码士","can_delete":false,"product_type":"c1","uid":1516495,"ip_address":"","ucode":"8E31D7E69F2C26","user_header":"https://static001.geekbang.org/account/avatar/00/17/23/cf/7429d6e8.jpg","comment_is_top":false,"comment_ctime":1602558379,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1602558379","product_id":100029201,"comment_content":"消息中间件还有一个作用，打破循环依赖。","like_count":0},{"had_liked":false,"id":246347,"user_name":"Geek_riki","can_delete":false,"product_type":"c1","uid":2165795,"ip_address":"","ucode":"1D2C280C6DEBBF","user_header":"","comment_is_top":false,"comment_ctime":1599290831,"is_pvip":false,"replies":[{"id":"90628","content":"没有绝对的程度之分。只要对Kafka有基本的认知（比如知道是做什么的，能够用console consumer&#47;producer收发消息）加上Java功底，就可以开始阅读了","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1599443586,"ip_address":"","comment_id":246347,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1599290831","product_id":100029201,"comment_content":"老师您好，我想问下，就是学习这些开源组件，达到什么程度可以开始像您这样钻研源码了？希望您能解答下，谢谢。","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":505119,"discussion_content":"没有绝对的程度之分。只要对Kafka有基本的认知（比如知道是做什么的，能够用console consumer/producer收发消息）加上Java功底，就可以开始阅读了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1599443586,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":242924,"user_name":"渠梁","can_delete":false,"product_type":"c1","uid":1488038,"ip_address":"","ucode":"DC86BDEC63C9BC","user_header":"https://static001.geekbang.org/account/avatar/00/16/b4/a6/b6fa2562.jpg","comment_is_top":false,"comment_ctime":1597894710,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1597894710","product_id":100029201,"comment_content":"致敬强者，能坚持啃50万行枯燥源码","like_count":0},{"had_liked":false,"id":239578,"user_name":"FIRE","can_delete":false,"product_type":"c1","uid":1670763,"ip_address":"","ucode":"85861D990FB3AB","user_header":"https://static001.geekbang.org/account/avatar/00/19/7e/6b/36fc4516.jpg","comment_is_top":false,"comment_ctime":1596591240,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1596591240","product_id":100029201,"comment_content":"公司用的Kafka主要用于解耦,核心的是用于收单系统与支付系统解耦,收单系统收到批量订单后,单笔处理扔到Kafka,支付系统根据主题不同选择不通的支付方式","like_count":0},{"had_liked":false,"id":234185,"user_name":"见南山","can_delete":false,"product_type":"c1","uid":1118111,"ip_address":"","ucode":"6A8BB82B7573CA","user_header":"https://static001.geekbang.org/account/avatar/00/11/0f/9f/f4b06bd5.jpg","comment_is_top":false,"comment_ctime":1594612968,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1594612968","product_id":100029201,"comment_content":"kafka是一个异步松耦合的消息引擎。消息引擎定义是需要协议和消息的定义，比如csv xml json还有牛逼的protocol buf。而消息传递协议就是点对点和订阅发布两种模式，kafka两种都支持。","like_count":0},{"had_liked":false,"id":233361,"user_name":"爱雨薇","can_delete":false,"product_type":"c1","uid":1966003,"ip_address":"","ucode":"2F1E8EED8C65AE","user_header":"https://static001.geekbang.org/account/avatar/00/1d/ff/b3/3a949695.jpg","comment_is_top":false,"comment_ctime":1594297259,"is_pvip":false,"replies":[{"id":"86094","content":"消息格式由社区定义和控制，不受其他第三方框架或组件的影响，可以独立演进，这算是一个好处吧。","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1594305867,"ip_address":"","comment_id":233361,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1594297259","product_id":100029201,"comment_content":"老师您好，kafka的消息编码格式选的是纯二进制的字节序列，对比其他的成熟解决方案，有什么好处呢？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":500995,"discussion_content":"消息格式由社区定义和控制，不受其他第三方框架或组件的影响，可以独立演进，这算是一个好处吧。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1594305867,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":231734,"user_name":"袁帅","can_delete":false,"product_type":"c1","uid":1084993,"ip_address":"","ucode":"A71A89B9F1BD69","user_header":"https://static001.geekbang.org/account/avatar/00/10/8e/41/709e9677.jpg","comment_is_top":false,"comment_ctime":1593761468,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1593761468","product_id":100029201,"comment_content":"我理解的消息引擎系统：<br>    是消息存储，发送的中间系统，可以解决业务系统间的联系更加送耦合，业务系统异步处理，另外还是最重要的削峰填谷<br><br>我们公司主要用用它当做mq队列，用户各业务系统之间的连接","like_count":0},{"had_liked":false,"id":229413,"user_name":"杯莫停","can_delete":false,"product_type":"c1","uid":1759325,"ip_address":"","ucode":"4FA1D5CBBEF702","user_header":"https://static001.geekbang.org/account/avatar/00/1a/d8/5d/07dfb3b5.jpg","comment_is_top":false,"comment_ctime":1592988103,"is_pvip":true,"replies":[{"id":"84692","content":"加油！","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1593002608,"ip_address":"","comment_id":229413,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1592988103","product_id":100029201,"comment_content":"坚持，打破舒适区。<br>踏踏实实的做与想。","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":499473,"discussion_content":"加油！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1593002608,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":228853,"user_name":"Peng","can_delete":false,"product_type":"c1","uid":1261957,"ip_address":"","ucode":"8896E7DB280D50","user_header":"https://static001.geekbang.org/account/avatar/00/13/41/85/4cb8a579.jpg","comment_is_top":false,"comment_ctime":1592825901,"is_pvip":false,"replies":[{"id":"84416","content":"嗯嗯，我们一块学习！","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1592874865,"ip_address":"","comment_id":228853,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1592825901","product_id":100029201,"comment_content":"很久之前就订阅了这个专栏，最近实习需要用到才开始看，感觉老师写的很棒，这次要坚持读完！","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":499216,"discussion_content":"嗯嗯，我们一块学习！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1592874865,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":227139,"user_name":"蒋盛飞","can_delete":false,"product_type":"c1","uid":2029954,"ip_address":"","ucode":"FFE1F519AF7DFB","user_header":"","comment_is_top":false,"comment_ctime":1592297583,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1592297583","product_id":100029201,"comment_content":"我们之前用flink处理完往ES写数据时候，因为ES每小时创建索引都是消耗大量内存，就会导致flink报错重启，就把flink处理完的数据往kafka里写再用采集器写到ES。","like_count":0},{"had_liked":false,"id":226186,"user_name":"Evan","can_delete":false,"product_type":"c1","uid":1344281,"ip_address":"","ucode":"B877ABD0CF4661","user_header":"https://static001.geekbang.org/account/avatar/00/14/83/19/0a3fe8c1.jpg","comment_is_top":false,"comment_ctime":1591973939,"is_pvip":false,"replies":[{"id":"83442","content":"可以尝试使用Kafka看看","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1592183681,"ip_address":"","comment_id":226186,"utype":1}],"discussion_count":1,"race_medal":1,"score":"1591973939","product_id":100029201,"comment_content":"目前公司内部主要使用RabbitMQ处理业务消息，也文章讲到“削峰填谷”， 准备切换Kafka平台，目前对Kafka掌握还不够熟练。另外使用类似DataBus产品，使用了Kafka。","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":498139,"discussion_content":"可以尝试使用Kafka看看","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1592183681,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":213126,"user_name":"Joe Black","can_delete":false,"product_type":"c1","uid":1052528,"ip_address":"","ucode":"21FE222A286445","user_header":"https://static001.geekbang.org/account/avatar/00/10/0f/70/c8680841.jpg","comment_is_top":false,"comment_ctime":1588307940,"is_pvip":false,"replies":[{"id":"79130","content":"嗯，这种场景Kafka挺适合的","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1588399598,"ip_address":"","comment_id":213126,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1588307940","product_id":100029201,"comment_content":"目前想用消息系统接收大量传感器信息，可能用的是mqtt协议，我看其它消息系统支持，kafka通过mqtt connector 也能支持（虽然好像是要购买的）。这种情况是不是可以选用kafka呢？是不是吞吐量会更高？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493688,"discussion_content":"嗯，这种场景Kafka挺适合的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588399598,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":212466,"user_name":"若镜O","can_delete":false,"product_type":"c1","uid":1517354,"ip_address":"","ucode":"6C4D7CA063B387","user_header":"https://static001.geekbang.org/account/avatar/00/17/27/2a/a914cd3f.jpg","comment_is_top":false,"comment_ctime":1588128415,"is_pvip":false,"replies":[{"id":"78958","content":"有点形象啊：）","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1588152293,"ip_address":"","comment_id":212466,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1588128415","product_id":100029201,"comment_content":"”削峰填谷”  ^^  现实生活中大领导的秘书  大明星的经纪人  ","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493514,"discussion_content":"有点形象啊：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588152293,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":210733,"user_name":"请叫我小岳同学","can_delete":false,"product_type":"c1","uid":1130999,"ip_address":"","ucode":"E35BBA40FF052A","user_header":"https://static001.geekbang.org/account/avatar/00/11/41/f7/8345488c.jpg","comment_is_top":false,"comment_ctime":1587816641,"is_pvip":false,"replies":[{"id":"78458","content":"第2个做法是可行的。也可以使用kafka-reassign-partitions.sh工具为分区指定不同的路径来实现。具体参见reassignment-json-file参数的用法。","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1587865784,"ip_address":"","comment_id":210733,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1587816641","product_id":100029201,"comment_content":"老师，您好！ 想请教一个关于 kafka 运维方面的问题。<br>一个 kafka 实例，挂载两块数据盘a,b。如何在不停服的情况下，将磁盘a 的分区数据迁移到 磁盘b。<br>之前的做法<br>1. 停服: mv a&#47;data b&#47;data<br>2. 不停服，先把占用磁盘较大的分区迁移到别的实例上。然后再把部分分区再迁移回来","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493096,"discussion_content":"第2个做法是可行的。也可以使用kafka-reassign-partitions.sh工具为分区指定不同的路径来实现。具体参见reassignment-json-file参数的用法。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587865784,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1762252,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/e3/cc/0947ff0b.jpg","nickname":"nestle","note":"","ucode":"469800BED81B54","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":300537,"discussion_content":"试了一下 kafka-reassign-partitions.sh 工具，应该也是需要停服修改 log.dirs 配置的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1598161277,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":207718,"user_name":"卡特","can_delete":false,"product_type":"c1","uid":1060491,"ip_address":"","ucode":"FF63677089E701","user_header":"https://static001.geekbang.org/account/avatar/00/10/2e/8b/32a8c5a0.jpg","comment_is_top":false,"comment_ctime":1587166030,"is_pvip":true,"replies":[{"id":"77600","content":"👍","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1587220515,"ip_address":"","comment_id":207718,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1587166030","product_id":100029201,"comment_content":"适用场景有3<br>1，流量削峰  高并发场景下保护下游服务<br>2，提速，mq作为同步转异步的一种方式，加快响应速度<br>3，广播事件通知","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492221,"discussion_content":"👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587220515,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":206205,"user_name":"而立斋","can_delete":false,"product_type":"c1","uid":1087258,"ip_address":"","ucode":"5FED6E9E148195","user_header":"https://static001.geekbang.org/account/avatar/00/10/97/1a/389eab84.jpg","comment_is_top":false,"comment_ctime":1586823357,"is_pvip":false,"replies":[{"id":"77007","content":"嗯嗯，同意，也行的：）","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1586829239,"ip_address":"","comment_id":206205,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1586823357","product_id":100029201,"comment_content":"【根据维基百科的定义，消息引擎系统是一组规范。企业利用这组规范在不同系统之间传递语义准确的消息，实现松耦合的异步式数据传递。】<br>我觉得这里应该用传输，不应该用传递这个词","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491712,"discussion_content":"嗯嗯，同意，也行的：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586829239,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":194311,"user_name":"顾君","can_delete":false,"product_type":"c1","uid":1934589,"ip_address":"","ucode":"44DC22D1BACED1","user_header":"","comment_is_top":false,"comment_ctime":1585049257,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1585049257","product_id":100029201,"comment_content":"之前了解的是activeMQ、rabbitMQ、乘机会来了解一下kafaka","like_count":0},{"had_liked":false,"id":149013,"user_name":"James","can_delete":false,"product_type":"c1","uid":1134861,"ip_address":"","ucode":"48B0F2A334D1C1","user_header":"https://static001.geekbang.org/account/avatar/00/11/51/0d/fc1652fe.jpg","comment_is_top":false,"comment_ctime":1573127255,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1573127255","product_id":100029201,"comment_content":"我公司使用kafka接收原始数据，使用多线程消费数据并加工成带有业务的数据放进redis…<br><br>","like_count":0},{"had_liked":false,"id":140515,"user_name":"song218888","can_delete":false,"product_type":"c1","uid":1057087,"ip_address":"","ucode":"D6A0559B4709E1","user_header":"https://static001.geekbang.org/account/avatar/00/10/21/3f/7e3e9dc4.jpg","comment_is_top":false,"comment_ctime":1570973636,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1570973636","product_id":100029201,"comment_content":"”聪明的人都在下笨功夫“，受教了","like_count":0},{"had_liked":false,"id":135714,"user_name":"smilence","can_delete":false,"product_type":"c1","uid":1344619,"ip_address":"","ucode":"D512DA378165BD","user_header":"https://static001.geekbang.org/account/avatar/00/14/84/6b/bc0b42f4.jpg","comment_is_top":false,"comment_ctime":1569245318,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1569245318","product_id":100029201,"comment_content":"当聪明人使用本笨方法时，会发生非常可怕的事","like_count":0},{"had_liked":false,"id":134734,"user_name":"丁丁历险记","can_delete":false,"product_type":"c1","uid":1661704,"ip_address":"","ucode":"A43829E454C067","user_header":"https://static001.geekbang.org/account/avatar/00/19/5b/08/b0b0db05.jpg","comment_is_top":false,"comment_ctime":1568905728,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1568905728","product_id":100029201,"comment_content":"聪明人，也要下死功夫，受教了。","like_count":0},{"had_liked":false,"id":134685,"user_name":"jc9090kkk","can_delete":false,"product_type":"c1","uid":1338831,"ip_address":"","ucode":"6C992D07A2E78F","user_header":"https://static001.geekbang.org/account/avatar/00/14/6d/cf/ec335526.jpg","comment_is_top":false,"comment_ctime":1568894483,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1568894483","product_id":100029201,"comment_content":"感谢老师分享，对于我个人的理解来讲，我刚开始理解kafka是觉得kafka可以作为数据管道，能够抵御流量高峰对系统的冲击，这对于实时性要求不是特别高的业务，kafka会比较合适一些，公司的项目刚好用了kafka，版本是1.1.1，貌似跟现在最新的版本有点差距，用kafka主要是做业务端的用户行为数据日志采集提供给大数据部门做统计和数据分析的，为什么使用kafka，主要的原因还是因为kafka作为消息引擎，数据可以存储一段时间，又能保证高性能和高可用，对于用户行为日志的分析来讲，不要求实时性，并且不“污染”业务端代码逻辑，消费者在后期消费的时候，也可以提供给spark进行分析处理，方便又高效，因为刚接手kafka的时候，发现kafka里面的一些broker，topic，partition，还有leader, follower 这样的定义和实现方式很有趣，所以想深入的学习一下，希望通过学习老师的课程，能为以后的开发工作提供更大的帮助。","like_count":0},{"had_liked":false,"id":132439,"user_name":"Christophe","can_delete":false,"product_type":"c1","uid":1066344,"ip_address":"","ucode":"A6E88DB17FD755","user_header":"https://static001.geekbang.org/account/avatar/00/10/45/68/d918758d.jpg","comment_is_top":false,"comment_ctime":1568122801,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1568122801","product_id":100029201,"comment_content":"我是小白新同事，跟着胡老师学习😃","like_count":0},{"had_liked":false,"id":120510,"user_name":"欠债太多","can_delete":false,"product_type":"c1","uid":1099238,"ip_address":"","ucode":"B0CC91FA6F3981","user_header":"https://static001.geekbang.org/account/avatar/00/10/c5/e6/50c5b805.jpg","comment_is_top":false,"comment_ctime":1564919921,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1564919921","product_id":100029201,"comment_content":"你好，再读一遍的时候，看到你阅读源代码的时候，记笔记，请教下，源代码的笔记主要是整理什么内容，感觉自己整理的笔记都很乱....","like_count":0},{"had_liked":false,"id":116472,"user_name":"阡陌","can_delete":false,"product_type":"c1","uid":1141254,"ip_address":"","ucode":"58634836C8E03F","user_header":"https://static001.geekbang.org/account/avatar/00/11/6a/06/66831563.jpg","comment_is_top":false,"comment_ctime":1563854024,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1563854024","product_id":100029201,"comment_content":"现在公司的kafka用于大批量数据的汇集以及两个子系统之间的消息传输（削峰填谷，松耦合，以前用接口传输有耦合和峰值过大时数据丢失的问题）。但是感觉现在用的还比较浅，希望在这里能学到更多知识改进自己的代码。","like_count":0},{"had_liked":false,"id":111717,"user_name":"leslie","can_delete":false,"product_type":"c1","uid":1324255,"ip_address":"","ucode":"798E7C1CC98CC2","user_header":"https://static001.geekbang.org/account/avatar/00/14/34/df/64e3d533.jpg","comment_is_top":false,"comment_ctime":1562589341,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1562589341","product_id":100029201,"comment_content":"其实之前听到这个名词是在一个数据库同行那边：现在的企业虽然没在用，但是Rabbit的使用效果并不好而且使用者并不理解rabbit；我是因为目前公司的rabbit和redis没看到什么效果，故而希望后期用redis+kafka去减轻目前过重的数据库压力。<br>老师的讲述非常通俗易懂，让我觉得作为一个初学者还是能较快时间入手；老师说的国外的作品到国内就翻译的问题，这个事实确实非常典型；国内基本翻译销量很好的数据库书籍其实都有不少解释是错误的，刚好书中部分知识本人阅读时刚好有些地方大量研究过，就发现了问题-甚至其中部分销量还能超过5万册、、、<br>感谢老师在讲课的过程中秉承尽可能遵照原版的说法来传授知识，希望课程结束后能把所学用到生产上-确实解决问题。","like_count":0},{"had_liked":false,"id":102330,"user_name":"Casper","can_delete":false,"product_type":"c1","uid":1022129,"ip_address":"","ucode":"69282EB175B48E","user_header":"https://static001.geekbang.org/account/avatar/00/0f/98/b1/f89a84d0.jpg","comment_is_top":false,"comment_ctime":1560208092,"is_pvip":true,"discussion_count":0,"race_medal":5,"score":"1560208092","product_id":100029201,"comment_content":"之前只是听说过消息系统，没有在工程中使用过，希望通过这次学习，深入了解消息引擎并在合适的项目中使用消息引擎。","like_count":0},{"had_liked":false,"id":102137,"user_name":"可以","can_delete":false,"product_type":"c1","uid":1564517,"ip_address":"","ucode":"3FEE197722C406","user_header":"https://static001.geekbang.org/account/avatar/00/17/df/65/c9dace3e.jpg","comment_is_top":false,"comment_ctime":1560147580,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1560147580","product_id":100029201,"comment_content":"打卡留言。","like_count":0},{"had_liked":false,"id":101504,"user_name":"InfoQ_686548eeb0d8","can_delete":false,"product_type":"c1","uid":1316985,"ip_address":"","ucode":"8222D0A7EE6155","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIsf7oYWKWrCu7LzT4xt2ZvLdNsn2Me8yEcdgVjJTKe68MQicIcO09FLXRYH5R8hCJ9RiatklFkSGtQ/132","comment_is_top":false,"comment_ctime":1559831343,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1559831343","product_id":100029201,"comment_content":"希望在专栏里讲到一些消息引擎系统的特有属性时，可以拿出比如pulsar等于kafka做下对比说明","like_count":0},{"had_liked":false,"id":101142,"user_name":"star","can_delete":false,"product_type":"c1","uid":1024998,"ip_address":"","ucode":"454FBD4EAA52FE","user_header":"https://static001.geekbang.org/account/avatar/00/0f/a3/e6/abb7bfe3.jpg","comment_is_top":false,"comment_ctime":1559726196,"is_pvip":false,"replies":[{"id":"36481","content":"目前Flink社区已经推出了flink-connector-kafka_2.11的connector，支持Kafka 1.0及以后的版本，但仍属于Beta版本，稳定性上不如0.11 connector","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1559779667,"ip_address":"","comment_id":101142,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1559726196","product_id":100029201,"comment_content":"请问下线上使用flink1.6和kafka0.9，现在想升级kafka版本，我看了flink-kafka-connector现在只有kafka0.11的版本，是不是我只能把kafka升级到0.11版本？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":452821,"discussion_content":"目前Flink社区已经推出了flink-connector-kafka_2.11的connector，支持Kafka 1.0及以后的版本，但仍属于Beta版本，稳定性上不如0.11 connector","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1559779667,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":100857,"user_name":"落霞与孤鹜","can_delete":false,"product_type":"c1","uid":1111004,"ip_address":"","ucode":"1F06EB86DD2E6B","user_header":"https://static001.geekbang.org/account/avatar/00/10/f3/dc/e7e5c159.jpg","comment_is_top":false,"comment_ctime":1559656088,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1559656088","product_id":100029201,"comment_content":"我们组用来做客服聊天系统了","like_count":0},{"had_liked":false,"id":100834,"user_name":"然行","can_delete":false,"product_type":"c1","uid":1103274,"ip_address":"","ucode":"3DF253F89B0B4A","user_header":"https://static001.geekbang.org/account/avatar/00/10/d5/aa/09581405.jpg","comment_is_top":false,"comment_ctime":1559649930,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1559649930","product_id":100029201,"comment_content":"最近开始频繁使用kafka在项目中应用，的确遇到了很多问题，如kafka丢消息，kafka把服务器cpu干到100%宕机，发现使用kafka需要优化很多地方，希望跟着老师，neng深入的人学习学习额","like_count":0},{"had_liked":false,"id":100799,"user_name":"道可","can_delete":false,"product_type":"c1","uid":1240858,"ip_address":"","ucode":"4AB4EFDFFF95A0","user_header":"https://static001.geekbang.org/account/avatar/00/12/ef/1a/e7ebdfa8.jpg","comment_is_top":false,"comment_ctime":1559641481,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1559641481","product_id":100029201,"comment_content":"结硬寨，打呆仗 --曾国藩","like_count":0},{"had_liked":false,"id":100674,"user_name":"永光","can_delete":false,"product_type":"c1","uid":1102702,"ip_address":"","ucode":"0C54531ABED1B0","user_header":"https://static001.geekbang.org/account/avatar/00/10/d3/6e/281b85aa.jpg","comment_is_top":false,"comment_ctime":1559614408,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1559614408","product_id":100029201,"comment_content":"同@开发无止境，bug随身行 的问题，怎么解决实时结果响应问题呢?","like_count":0},{"had_liked":false,"id":100643,"user_name":"厉害了我的国","can_delete":false,"product_type":"c1","uid":1052191,"ip_address":"","ucode":"CD0A54A1B998AA","user_header":"https://static001.geekbang.org/account/avatar/00/10/0e/1f/d0472177.jpg","comment_is_top":false,"comment_ctime":1559610054,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1559610054","product_id":100029201,"comment_content":"老师，读源码太累了无从下手啊","like_count":0},{"had_liked":false,"id":100637,"user_name":"伟伟","can_delete":false,"product_type":"c1","uid":1450367,"ip_address":"","ucode":"59BE820B03B97F","user_header":"https://static001.geekbang.org/account/avatar/00/16/21/7f/efda2a64.jpg","comment_is_top":false,"comment_ctime":1559609454,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1559609454","product_id":100029201,"comment_content":"我记得是鲁迅说的","like_count":0},{"had_liked":false,"id":100609,"user_name":"周小桥","can_delete":false,"product_type":"c1","uid":1062408,"ip_address":"","ucode":"80875AE7675695","user_header":"https://static001.geekbang.org/account/avatar/00/10/36/08/e3ed94b8.jpg","comment_is_top":false,"comment_ctime":1559606067,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1559606067","product_id":100029201,"comment_content":"目前我们项目中把他作为数据传输的通道，主要是应用能堆积数据和解耦的特性。","like_count":0},{"had_liked":false,"id":100552,"user_name":"南辕北辙","can_delete":false,"product_type":"c1","uid":1214502,"ip_address":"","ucode":"03EC406AE0D591","user_header":"https://static001.geekbang.org/account/avatar/00/12/88/26/b8c53cee.jpg","comment_is_top":false,"comment_ctime":1559576163,"is_pvip":false,"replies":[{"id":"36331","content":"嗯嗯，我个人是不太喜欢叫消息队列的，不过约定俗成的力量很大，有时候也不得不妥协：）","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1559646777,"ip_address":"","comment_id":100552,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1559576163","product_id":100029201,"comment_content":"哈哈，看书的时候就看到老师说更喜欢叫消息引擎，对比了mq等队列的模式，确实叫引擎更合适","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":452596,"discussion_content":"嗯嗯，我个人是不太喜欢叫消息队列的，不过约定俗成的力量很大，有时候也不得不妥协：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1559646777,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":100533,"user_name":"汉","can_delete":false,"product_type":"c1","uid":1304899,"ip_address":"","ucode":"DE76E3E207F2C4","user_header":"https://static001.geekbang.org/account/avatar/00/13/e9/43/2d34b30b.jpg","comment_is_top":false,"comment_ctime":1559572142,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1559572142","product_id":100029201,"comment_content":"简单的类比一下，我觉得消息引擎就类似于银行，储户存的钱，5毛、10元、100元就相当于各种类型的消息，消息引擎（银行）要控制风险防止恶意挤兑（大流量访问），同时对消息进行处理、整合、分发。如果你是vip贷款人那好，点对点服务，有专员接待您。如果你是普通贷款人（es、hbase、mysql）那好根据你的信用等级（需要的数据各式）进行贷款，并且银行发出贷款消息，贷款人都能知道自己是否有资格贷款（发布订阅）","like_count":0},{"had_liked":false,"id":100464,"user_name":"Alan","can_delete":false,"product_type":"c1","uid":1119761,"ip_address":"","ucode":"F263C5A01A6377","user_header":"https://static001.geekbang.org/account/avatar/00/11/16/11/45e7b64e.jpg","comment_is_top":false,"comment_ctime":1559559184,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1559559184","product_id":100029201,"comment_content":"消息重播是个好机制，从某种意义上讲，卡夫卡相当于时间流上的一个顺序存储件。","like_count":0}]}