{"id":101763,"title":"08 | 最最最重要的集群参数配置（下）","content":"<p>今天我们继续来聊那些重要的Kafka集群配置，下半部分主要是Topic级别参数、JVM参数以及操作系统参数的设置。</p><p>在上一期中，我们讨论了Broker端参数设置的一些法则，但其实Kafka也支持为不同的Topic设置不同的参数值。当前最新的2.2版本总共提供了大约25个Topic级别的参数，当然我们也不必全部了解它们的作用，这里我挑出了一些最关键的参数，你一定要把它们掌握清楚。除了Topic级别的参数，我今天还会给出一些重要的JVM参数和操作系统参数，正确设置这些参数是搭建高性能Kafka集群的关键因素。</p><h2>Topic级别参数</h2><p>说起Topic级别的参数，你可能会有这样的疑问：如果同时设置了Topic级别参数和全局Broker参数，到底听谁的呢？哪个说了算呢？答案就是Topic级别参数会覆盖全局Broker参数的值，而每个Topic都能设置自己的参数值，这就是所谓的Topic级别参数。</p><p>举个例子说明一下，上一期我提到了消息数据的留存时间参数，在实际生产环境中，如果为所有Topic的数据都保存相当长的时间，这样做既不高效也无必要。更适当的做法是允许不同部门的Topic根据自身业务需要，设置自己的留存时间。如果只能设置全局Broker参数，那么势必要提取所有业务留存时间的最大值作为全局参数值，此时设置Topic级别参数把它覆盖，就是一个不错的选择。</p><!-- [[[read_end]]] --><p>下面我们依然按照用途分组的方式引出重要的Topic级别参数。从保存消息方面来考量的话，下面这组参数是非常重要的：</p><ul>\n<li><code>retention.ms</code>：规定了该Topic消息被保存的时长。默认是7天，即该Topic只保存最近7天的消息。一旦设置了这个值，它会覆盖掉Broker端的全局参数值。</li>\n<li><code>retention.bytes</code>：规定了要为该Topic预留多大的磁盘空间。和全局参数作用相似，这个值通常在多租户的Kafka集群中会有用武之地。当前默认值是-1，表示可以无限使用磁盘空间。</li>\n</ul><p>上面这些是从保存消息的维度来说的。如果从能处理的消息大小这个角度来看的话，有一个参数是必须要设置的，即<code>max.message.bytes</code>。它决定了Kafka Broker能够正常接收该Topic的最大消息大小。我知道目前在很多公司都把Kafka作为一个基础架构组件来运行，上面跑了很多的业务数据。如果在全局层面上，我们不好给出一个合适的最大消息值，那么不同业务部门能够自行设定这个Topic级别参数就显得非常必要了。在实际场景中，这种用法也确实是非常常见的。</p><p>好了，你要掌握的Topic级别的参数就这么几个。下面我来说说怎么设置Topic级别参数吧。其实说到这个事情，我是有点个人看法的：我本人不太赞同那种做一件事情开放给你很多种选择的设计方式，看上去好似给用户多种选择，但实际上只会增加用户的学习成本。特别是系统配置，如果你告诉我只能用一种办法来做，我会很努力地把它学会；反之，如果你告诉我说有两种方法甚至是多种方法都可以实现，那么我可能连学习任何一种方法的兴趣都没有了。Topic级别参数的设置就是这种情况，我们有两种方式可以设置：</p><ul>\n<li>创建Topic时进行设置</li>\n<li>修改Topic时设置</li>\n</ul><p>我们先来看看如何在创建Topic时设置这些参数。我用上面提到的<code>retention.ms</code>和<code>max.message.bytes</code>举例。设想你的部门需要将交易数据发送到Kafka进行处理，需要保存最近半年的交易数据，同时这些数据很大，通常都有几MB，但一般不会超过5MB。现在让我们用以下命令来创建Topic：</p><pre><code>bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic transaction --partitions 1 --replication-factor 1 --config retention.ms=15552000000 --config max.message.bytes=5242880\n</code></pre><p>我们只需要知道Kafka开放了<code>kafka-topics</code>命令供我们来创建Topic即可。对于上面这样一条命令，请注意结尾处的<code>--config</code>设置，我们就是在config后面指定了想要设置的Topic级别参数。</p><p>下面看看使用另一个自带的命令<code>kafka-configs</code>来修改Topic级别参数。假设我们现在要发送最大值是10MB的消息，该如何修改呢？命令如下：</p><pre><code>bin/kafka-configs.sh --zookeeper localhost:2181 --entity-type topics --entity-name transaction --alter --add-config max.message.bytes=10485760\n</code></pre><p>总体来说，你只能使用这么两种方式来设置Topic级别参数。我个人的建议是，你最好始终坚持使用第二种方式来设置，并且在未来，Kafka社区很有可能统一使用<code>kafka-configs</code>脚本来调整Topic级别参数。</p><h2>JVM参数</h2><p>我在专栏前面提到过，Kafka服务器端代码是用Scala语言编写的，但终归还是编译成Class文件在JVM上运行，因此JVM参数设置对于Kafka集群的重要性不言而喻。</p><p>首先我先说说Java版本，我个人极其不推荐将Kafka运行在Java 6或7的环境上。Java 6实在是太过陈旧了，没有理由不升级到更新版本。另外Kafka自2.0.0版本开始，已经正式摒弃对Java 7的支持了，所以有条件的话至少使用Java 8吧。</p><p>说到JVM端设置，堆大小这个参数至关重要。虽然在后面我们还会讨论如何调优Kafka性能的问题，但现在我想无脑给出一个通用的建议：将你的JVM堆大小设置成6GB吧，这是目前业界比较公认的一个合理值。我见过很多人就是使用默认的Heap Size来跑Kafka，说实话默认的1GB有点小，毕竟Kafka Broker在与客户端进行交互时会在JVM堆上创建大量的ByteBuffer实例，Heap Size不能太小。</p><p>JVM端配置的另一个重要参数就是垃圾回收器的设置，也就是平时常说的GC设置。如果你依然在使用Java 7，那么可以根据以下法则选择合适的垃圾回收器：</p><ul>\n<li>如果Broker所在机器的CPU资源非常充裕，建议使用CMS收集器。启用方法是指定<code>-XX:+UseCurrentMarkSweepGC</code>。</li>\n<li>否则，使用吞吐量收集器。开启方法是指定<code>-XX:+UseParallelGC</code>。</li>\n</ul><p>当然了，如果你在使用Java 8，那么可以手动设置使用G1收集器。在没有任何调优的情况下，G1表现得要比CMS出色，主要体现在更少的Full GC，需要调整的参数更少等，所以使用G1就好了。</p><p>现在我们确定好了要设置的JVM参数，我们该如何为Kafka进行设置呢？有些奇怪的是，这个问题居然在Kafka官网没有被提及。其实设置的方法也很简单，你只需要设置下面这两个环境变量即可：</p><ul>\n<li><code>KAFKA_HEAP_OPTS</code>：指定堆大小。</li>\n<li><code>KAFKA_JVM_PERFORMANCE_OPTS</code>：指定GC参数。</li>\n</ul><p>比如你可以这样启动Kafka Broker，即在启动Kafka Broker之前，先设置上这两个环境变量：</p><pre><code>$&gt; export KAFKA_HEAP_OPTS=--Xms6g  --Xmx6g\n$&gt; export KAFKA_JVM_PERFORMANCE_OPTS= -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=true\n$&gt; bin/kafka-server-start.sh config/server.properties\n</code></pre><h2>操作系统参数</h2><p>最后我们来聊聊Kafka集群通常都需要设置哪些操作系统参数。通常情况下，Kafka并不需要设置太多的OS参数，但有些因素最好还是关注一下，比如下面这几个：</p><ul>\n<li>文件描述符限制</li>\n<li>文件系统类型</li>\n<li>Swappiness</li>\n<li>提交时间</li>\n</ul><p>首先是<code>ulimit -n</code>。我觉得任何一个Java项目最好都调整下这个值。实际上，文件描述符系统资源并不像我们想象的那样昂贵，你不用太担心调大此值会有什么不利的影响。通常情况下将它设置成一个超大的值是合理的做法，比如<code>ulimit -n 1000000</code>。还记得电影《让子弹飞》里的对话吗：“你和钱，谁对我更重要？都不重要，没有你对我很重要！”。这个参数也有点这么个意思。其实设置这个参数一点都不重要，但不设置的话后果很严重，比如你会经常看到“Too many open files”的错误。</p><p>其次是文件系统类型的选择。这里所说的文件系统指的是如ext3、ext4或XFS这样的日志型文件系统。根据官网的测试报告，XFS的性能要强于ext4，所以生产环境最好还是使用XFS。对了，最近有个Kafka使用ZFS的<a href=\"https://www.confluent.io/kafka-summit-sf18/kafka-on-zfs\">数据报告</a>，貌似性能更加强劲，有条件的话不妨一试。</p><p>第三是swap的调优。网上很多文章都提到设置其为0，将swap完全禁掉以防止Kafka进程使用swap空间。我个人反倒觉得还是不要设置成0比较好，我们可以设置成一个较小的值。为什么呢？因为一旦设置成0，当物理内存耗尽时，操作系统会触发OOM killer这个组件，它会随机挑选一个进程然后kill掉，即根本不给用户任何的预警。但如果设置成一个比较小的值，当开始使用swap空间时，你至少能够观测到Broker性能开始出现急剧下降，从而给你进一步调优和诊断问题的时间。基于这个考虑，我个人建议将swappniess配置成一个接近0但不为0的值，比如1。</p><p>最后是提交时间或者说是Flush落盘时间。向Kafka发送数据并不是真要等数据被写入磁盘才会认为成功，而是只要数据被写入到操作系统的页缓存（Page Cache）上就可以了，随后操作系统根据LRU算法会定期将页缓存上的“脏”数据落盘到物理磁盘上。这个定期就是由提交时间来确定的，默认是5秒。一般情况下我们会认为这个时间太频繁了，可以适当地增加提交间隔来降低物理磁盘的写操作。当然你可能会有这样的疑问：如果在页缓存中的数据在写入到磁盘前机器宕机了，那岂不是数据就丢失了。的确，这种情况数据确实就丢失了，但鉴于Kafka在软件层面已经提供了多副本的冗余机制，因此这里稍微拉大提交间隔去换取性能还是一个合理的做法。</p><h2>小结</h2><p>今天我和你分享了关于Kafka集群设置的各类配置，包括Topic级别参数、JVM参数以及操作系统参数，连同上一篇一起构成了完整的Kafka参数配置列表。我希望这些最佳实践能够在你搭建Kafka集群时助你一臂之力，但切记配置因环境而异，一定要结合自身业务需要以及具体的测试来验证它们的有效性。</p><p><img src=\"https://static001.geekbang.org/resource/image/da/87/da521c645594bcf0e4670a3d20937b87.jpg?wh=2069*2560\" alt=\"\"></p><h2>开放讨论</h2><p>很多人争论Kafka不需要为Broker设置太大的堆内存，而应该尽可能地把内存留给页缓存使用。对此你是怎么看的？在你的实际使用中有哪些好的法则来评估Kafka对内存的使用呢？</p><p>欢迎写下你的思考和答案，我们一起讨论。如果你觉得有所收获，也欢迎把文章分享给你的朋友。</p>","comments":[{"had_liked":false,"id":105357,"user_name":"丰富","can_delete":false,"product_type":"c1","uid":1017611,"ip_address":"","ucode":"8FF798DC1418C3","user_header":"https://static001.geekbang.org/account/avatar/00/0f/87/0b/6a4cf978.jpg","comment_is_top":false,"comment_ctime":1560989762,"is_pvip":false,"replies":[{"id":"38182","content":"嗯嗯，笔误了。多谢纠正 ：）","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561018220,"ip_address":"","comment_id":105357,"utype":1}],"discussion_count":3,"race_medal":0,"score":"370928177218","product_id":100029201,"comment_content":"G1是jdk9中默认的，jdk8还是需要显式指定的","like_count":86,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454646,"discussion_content":"嗯嗯，笔误了。多谢纠正 ：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561018220,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1134861,"avatar":"https://static001.geekbang.org/account/avatar/00/11/51/0d/fc1652fe.jpg","nickname":"James","note":"","ucode":"48B0F2A334D1C1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":46873,"discussion_content":"原来的文章还是没有修改……","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1573221861,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1466953,"avatar":"https://static001.geekbang.org/account/avatar/00/16/62/49/6332c99b.jpg","nickname":"man1s","note":"","ucode":"FFDB6B52F65A1B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":80014,"discussion_content":"kafka中默认使用的就是G1, kafka-run-class.sh 这个启动脚本里","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1576137779,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":105845,"user_name":"saup007","can_delete":false,"product_type":"c1","uid":1003624,"ip_address":"","ucode":"5BE1CA2E482E96","user_header":"https://static001.geekbang.org/account/avatar/00/0f/50/68/7a8aa1e1.jpg","comment_is_top":false,"comment_ctime":1561092943,"is_pvip":false,"replies":[{"id":"38298","content":"是的，您考虑得很全面：）","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561104608,"ip_address":"","comment_id":105845,"utype":1}],"discussion_count":4,"race_medal":0,"score":"302208803663","product_id":100029201,"comment_content":"修改 Topic 级 max.message.bytes，还要考虑以下两个吧？<br>还要修改 Broker的 replica.fetch.max.bytes 保证复制正常<br>消费还要修改配置 fetch.message.max.bytes<br>","like_count":70,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454837,"discussion_content":"是的，您考虑得很全面：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561104608,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1477754,"avatar":"https://static001.geekbang.org/account/avatar/00/16/8c/7a/5ee20222.jpg","nickname":"小晨","note":"","ucode":"C95BC5211A5741","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":568380,"discussion_content":"我感觉没有应该也不会有事吧，竟然Topic都已经限制了，那么replica和consumer就不可能拉到大于限制的消息了","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1651121359,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1181055,"avatar":"https://static001.geekbang.org/account/avatar/00/12/05/7f/d35ab9a1.jpg","nickname":"z.l","note":"","ucode":"805CC5784D3F76","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1477754,"avatar":"https://static001.geekbang.org/account/avatar/00/16/8c/7a/5ee20222.jpg","nickname":"小晨","note":"","ucode":"C95BC5211A5741","race_medal":0,"user_type":1,"is_pvip":true},"discussion":{"id":589817,"discussion_content":"考虑下如果一开始设置为1M，后来改成10M的情况","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1665325524,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":568380,"ip_address":"江苏"},"score":589817,"extra":""}]},{"author":{"id":1054827,"avatar":"https://static001.geekbang.org/account/avatar/00/10/18/6b/a1448af1.jpg","nickname":"贝影","note":"","ucode":"19545C8DCBF8A2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":543763,"discussion_content":"max.partition.fetch.bytes 不用考虑吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1641295274,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":105508,"user_name":"Hello world","can_delete":false,"product_type":"c1","uid":1333607,"ip_address":"","ucode":"4D2EF3034571B7","user_header":"https://static001.geekbang.org/account/avatar/00/14/59/67/f4ba1da4.jpg","comment_is_top":false,"comment_ctime":1561018000,"is_pvip":false,"replies":[{"id":"38201","content":"虽然无脑推荐6GB，但绝不是无脑推荐&gt;6GB。一个16GB的堆Full GC一次要花多长时间啊，所以我觉得6GB可以是一个初始值，你可以实时监控堆上的live data大小，根据这个值调整heap size。只是因为大内存就直接调整到16GB，个人觉得不可取。<br><br>另外堆越小留给页缓存的空间也就越大，这对Kafka是好事啊。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561021309,"ip_address":"","comment_id":105508,"utype":1}],"discussion_count":6,"race_medal":0,"score":"181949644432","product_id":100029201,"comment_content":"老师说的无脑配置给jvm heap 6G大小，这应该也看机器的吧，现在机器的内存也越来越大，我们这的机器都是64G 内存，配了16G的heap，老师觉得可以优化吗","like_count":42,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454709,"discussion_content":"虽然无脑推荐6GB，但绝不是无脑推荐&amp;gt;6GB。一个16GB的堆Full GC一次要花多长时间啊，所以我觉得6GB可以是一个初始值，你可以实时监控堆上的live data大小，根据这个值调整heap size。只是因为大内存就直接调整到16GB，个人觉得不可取。\n\n另外堆越小留给页缓存的空间也就越大，这对Kafka是好事啊。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561021309,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":3,"child_discussions":[{"author":{"id":2912918,"avatar":"","nickname":"Geek_284c06","note":"","ucode":"4BD6D4449D4F1A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":577011,"discussion_content":"这个页缓存指的是啥","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1655883233,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":454709,"ip_address":""},"score":577011,"extra":""},{"author":{"id":1441991,"avatar":"https://static001.geekbang.org/account/avatar/00/16/00/c7/59caefa7.jpg","nickname":"ok绷","note":"","ucode":"7B2303B3319C4D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2912918,"avatar":"","nickname":"Geek_284c06","note":"","ucode":"4BD6D4449D4F1A","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":578528,"discussion_content":"操作系统级的缓存能力吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1656858435,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":577011,"ip_address":""},"score":578528,"extra":""},{"author":{"id":1255794,"avatar":"https://static001.geekbang.org/account/avatar/00/13/29/72/515e8867.jpg","nickname":"王厂长","note":"","ucode":"FF41279DA5A860","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":2912918,"avatar":"","nickname":"Geek_284c06","note":"","ucode":"4BD6D4449D4F1A","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":578690,"discussion_content":"堆是Jvm使用的内存，缓存页，是操作系统使用的内存。比如写文件，一般就先写到操作系统使用的内存（缓存页），一定时间在批量写到磁盘。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1656945905,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":577011,"ip_address":""},"score":578690,"extra":""}]},{"author":{"id":1516600,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/wBjvGCCZmO0Bic0DrnG466y6hwPkibGevAV6E6FPfQEricvw5toL7a2HSgjhI83cCiadrUibIyVibkgbbMOHVxo7HA8Q/132","nickname":"距离30米","note":"","ucode":"5566D9AB9E47DE","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":590038,"discussion_content":"这个我学到了，就是文件系统的page cache吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1665482700,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"四川"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2103320,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/YQBwClu5f6pibYCNxoEgKkM2uvgytevWp1FBVnec3ialmFDsftEvjvRShYKn2cTicmK8M9az6ribcz65zPpGq3X3QA/132","nickname":"Geek_a68e6d","note":"","ucode":"F7AD54784E79A6","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":583864,"discussion_content":"mark","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1660452118,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"北京"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":106546,"user_name":"赌神很低调","can_delete":false,"product_type":"c1","uid":1168545,"ip_address":"","ucode":"1066778E1EDF26","user_header":"https://static001.geekbang.org/account/avatar/00/11/d4/a1/8bc8e7e1.jpg","comment_is_top":false,"comment_ctime":1561341904,"is_pvip":true,"replies":[{"id":"38796","content":"写入到页缓存即认为成功。如果在flush之前机器就宕机了，的确这条数据在broker上就算丢失了。producer端表现如何取决于acks的设定。如果是acks=1而恰恰是leader broker在flush前宕机，那么的确有可能消息就丢失了，而且producer端不会重发——因为它认为是成功了。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561511128,"ip_address":"","comment_id":106546,"utype":1}],"discussion_count":6,"race_medal":0,"score":"134705328080","product_id":100029201,"comment_content":"胡老师，kafka认为写入成功是指写入页缓存成功还是数据刷到磁盘成功算成功呢？还是上次刷盘宕机失败的问题，页缓存的数据如果刷盘失败，是不是就丢了？这个异常会不会响应给生产者让其重发呢？","like_count":31,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":455134,"discussion_content":"写入到页缓存即认为成功。如果在flush之前机器就宕机了，的确这条数据在broker上就算丢失了。producer端表现如何取决于acks的设定。如果是acks=1而恰恰是leader broker在flush前宕机，那么的确有可能消息就丢失了，而且producer端不会重发——因为它认为是成功了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561511128,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1547667,"avatar":"https://static001.geekbang.org/account/avatar/00/17/9d/93/4159edaa.jpg","nickname":"朴素柠檬c","note":"","ucode":"2D4CBB70D801B1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":327504,"discussion_content":"那如何找回这条丢失的消息，需要人工介入吧？","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1605852686,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":2,"child_discussions":[{"author":{"id":2563580,"avatar":"https://static001.geekbang.org/account/avatar/00/27/1d/fc/12dc7a46.jpg","nickname":"Ru","note":"","ucode":"EEF496EC828DD1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1547667,"avatar":"https://static001.geekbang.org/account/avatar/00/17/9d/93/4159edaa.jpg","nickname":"朴素柠檬c","note":"","ucode":"2D4CBB70D801B1","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":377834,"discussion_content":"这里我也好奇会怎么做，其实和redis持久化那里有点像，就是会丢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1622899509,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":327504,"ip_address":""},"score":377834,"extra":""},{"author":{"id":1736462,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/7f/0e/e3a8dbd9.jpg","nickname":"Liujun","note":"","ucode":"3DB1F3CA57B5B3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1547667,"avatar":"https://static001.geekbang.org/account/avatar/00/17/9d/93/4159edaa.jpg","nickname":"朴素柠檬c","note":"","ucode":"2D4CBB70D801B1","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":389350,"discussion_content":"什么工都没用\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1629249515,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":327504,"ip_address":""},"score":389350,"extra":""}]},{"author":{"id":1054827,"avatar":"https://static001.geekbang.org/account/avatar/00/10/18/6b/a1448af1.jpg","nickname":"贝影","note":"","ucode":"19545C8DCBF8A2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":543773,"discussion_content":"这里我才懂了MySQL的2阶段提交的含义","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1641297432,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":2603445,"avatar":"https://static001.geekbang.org/account/avatar/00/27/b9/b5/7975f3a3.jpg","nickname":"⭕️⭕️","note":"","ucode":"999231614A28A3","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1054827,"avatar":"https://static001.geekbang.org/account/avatar/00/10/18/6b/a1448af1.jpg","nickname":"贝影","note":"","ucode":"19545C8DCBF8A2","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":577027,"discussion_content":"mysql两阶段提交只是为了保证binlog和redolog一致，数据不丢失还是靠redolog，并且还得设置redolog一次write就一次fsync，要不然该丢还是丢。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1655889102,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":543773,"ip_address":""},"score":577027,"extra":""}]}]},{"had_liked":false,"id":105323,"user_name":"aoe","can_delete":false,"product_type":"c1","uid":1121758,"ip_address":"","ucode":"1C6201EDB4E954","user_header":"https://static001.geekbang.org/account/avatar/00/11/1d/de/62bfa83f.jpg","comment_is_top":false,"comment_ctime":1560969126,"is_pvip":false,"discussion_count":6,"race_medal":0,"score":"126115020710","product_id":100029201,"comment_content":"ulimit -n这个参数说的太好了！如果不设置，单机在Centos7上几百的并发就报“Too many open files”了。网上搜索后设置成65535，用JMater压测单机也只能支撑到1000左右的并发，原来这个值可以设置到1000000！《Kafka权威指南》上说Kafka单机可以轻松处理300万并发；《响应式架构:消息模式Actor实现与Scala、Akka应用集成》上说Scala用Actor单机可以处理5000万并发。请问胡老师有没有推荐的Linux方面的书籍，可以详细解答ulimit -n参数、如何知道单台Linux机器可以处理的连接数上线？<br>我在mac笔记本上用Go开启了10万个goroutine，压测服务器，结果得到异常“Too many open files”，后来也修改了ulimit -65535，但也只能保证1万左右的请求正常，请问Mac上也是只要设置ulimit -n参数就可以将请求的连接数提升到上限吗？","like_count":29,"discussions":[{"author":{"id":1601052,"avatar":"","nickname":"nextforevershit","note":"","ucode":"606F238E0F189B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":344215,"discussion_content":"首先你的内存够不够，如果够，那么fd几乎没有限制，设置到你想要的值即可","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1611330342,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1121758,"avatar":"https://static001.geekbang.org/account/avatar/00/11/1d/de/62bfa83f.jpg","nickname":"aoe","note":"","ucode":"1C6201EDB4E954","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1601052,"avatar":"","nickname":"nextforevershit","note":"","ucode":"606F238E0F189B","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":344240,"discussion_content":"谢谢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1611367906,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":344215,"ip_address":""},"score":344240,"extra":""}]},{"author":{"id":1149539,"avatar":"https://static001.geekbang.org/account/avatar/00/11/8a/63/a5fda84d.jpg","nickname":"烟火不坠","note":"","ucode":"BEEE3173C66E5F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":196997,"discussion_content":"试一下不就知道了？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1583393226,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":3,"child_discussions":[{"author":{"id":1121758,"avatar":"https://static001.geekbang.org/account/avatar/00/11/1d/de/62bfa83f.jpg","nickname":"aoe","note":"","ucode":"1C6201EDB4E954","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1149539,"avatar":"https://static001.geekbang.org/account/avatar/00/11/8a/63/a5fda84d.jpg","nickname":"烟火不坠","note":"","ucode":"BEEE3173C66E5F","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":197753,"discussion_content":"只改这个参数是不行的，要改一堆参数","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1583426718,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":196997,"ip_address":""},"score":197753,"extra":""},{"author":{"id":1188175,"avatar":"https://static001.geekbang.org/account/avatar/00/12/21/4f/581c85e2.jpg","nickname":"LBruce","note":"","ucode":"55884BE8C58C8B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1121758,"avatar":"https://static001.geekbang.org/account/avatar/00/11/1d/de/62bfa83f.jpg","nickname":"aoe","note":"","ucode":"1C6201EDB4E954","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":326359,"discussion_content":"请问，都要改哪些参数呢？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605583616,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":197753,"ip_address":""},"score":326359,"extra":""},{"author":{"id":1121758,"avatar":"https://static001.geekbang.org/account/avatar/00/11/1d/de/62bfa83f.jpg","nickname":"aoe","note":"","ucode":"1C6201EDB4E954","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1188175,"avatar":"https://static001.geekbang.org/account/avatar/00/12/21/4f/581c85e2.jpg","nickname":"LBruce","note":"","ucode":"55884BE8C58C8B","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":329917,"discussion_content":"搜索一下，每个系统不一样，也许可以解决问题，但不清楚原理。目前正在学习Linux基础","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606481614,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":326359,"ip_address":""},"score":329917,"extra":""}]}]},{"had_liked":false,"id":105940,"user_name":"cricket1981","can_delete":false,"product_type":"c1","uid":1001715,"ip_address":"","ucode":"758262F5958DA4","user_header":"https://static001.geekbang.org/account/avatar/00/0f/48/f3/f1034ffd.jpg","comment_is_top":false,"comment_ctime":1561108453,"is_pvip":false,"replies":[{"id":"38470","content":"Kafka Streams的性能调优建议：https:&#47;&#47;www.confluent.io&#47;blog&#47;optimizing-kafka-streams-applications<br><br>KSQL本专栏不会涉及，目前我也给不出相应的建议，因为我。。。。我也不会😳","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561337176,"ip_address":"","comment_id":105940,"utype":1}],"discussion_count":1,"race_medal":0,"score":"104640323557","product_id":100029201,"comment_content":"kafka streams或者ksql的性能参数调优有什么建议和参考资料吗？","like_count":24,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454880,"discussion_content":"Kafka Streams的性能调优建议：https://www.confluent.io/blog/optimizing-kafka-streams-applications\n\nKSQL本专栏不会涉及，目前我也给不出相应的建议，因为我。。。。我也不会😳","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561337176,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":107560,"user_name":"小头针","can_delete":false,"product_type":"c1","uid":1422920,"ip_address":"","ucode":"21EB7CDE48EC9B","user_header":"https://static001.geekbang.org/account/avatar/00/15/b6/48/1275e0ce.jpg","comment_is_top":false,"comment_ctime":1561557709,"is_pvip":false,"replies":[{"id":"38942","content":"页缓存属于磁盘缓存（Disk cache）的一种，主要是为了改善系统性能。重复访问磁盘上的磁盘块是常见的操作，把它们保存在内存中可以避免昂贵的磁盘IO操作。<br><br>既然叫页缓存，它是根据页（page）来组织的内存结构。每一页包含了很多磁盘上的块数据。Linux使用Radix树实现页缓存，主要是加速特定页的查找速度。另外一般使用LRU策略来淘汰过期页数据。总之它是一个完全由内核来管理的磁盘缓存，用户应用程序通常是无感知的。<br><br>如果要详细了解page cache，可以参见《Understanding the Linux Kernel》一书的第15章","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561596894,"ip_address":"","comment_id":107560,"utype":1}],"discussion_count":5,"race_medal":0,"score":"74576001741","product_id":100029201,"comment_content":"胡老师，在本课程最后留的问题，又成功的引起了我的注意，我曾经因为kafka假死，不知原因为何，而尝试过设置Broker的内存为（32G&#47;256G），然而进程假死更加频繁（后面检测是那个版本存在线程死锁）。后来还是设置为16G了。当然我这真真的是无脑设置。我也看到了评论了胡老师的建议，很值得参考。<br>另外，胡老师在这节课里，讲到了页缓存，我想请问一下这个页缓存它存在的意义和作用，以及它在整个过程中的机制又是怎样的呢？","like_count":17,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":455558,"discussion_content":"页缓存属于磁盘缓存（Disk cache）的一种，主要是为了改善系统性能。重复访问磁盘上的磁盘块是常见的操作，把它们保存在内存中可以避免昂贵的磁盘IO操作。\n\n既然叫页缓存，它是根据页（page）来组织的内存结构。每一页包含了很多磁盘上的块数据。Linux使用Radix树实现页缓存，主要是加速特定页的查找速度。另外一般使用LRU策略来淘汰过期页数据。总之它是一个完全由内核来管理的磁盘缓存，用户应用程序通常是无感知的。\n\n如果要详细了解page cache，可以参见《Understanding the Linux Kernel》一书的第15章","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561596894,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1336475,"avatar":"https://static001.geekbang.org/account/avatar/00/14/64/9b/0b578b08.jpg","nickname":"J.Smile","note":"","ucode":"C4D98DFDBF7584","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":283565,"discussion_content":"其实很多中间件在落盘的时候都需要page cache优化，比如mysql的binlog和redolog","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1592298046,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1547667,"avatar":"https://static001.geekbang.org/account/avatar/00/17/9d/93/4159edaa.jpg","nickname":"朴素柠檬c","note":"","ucode":"2D4CBB70D801B1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":327506,"discussion_content":"无论应用还是数据库 甚至操作系统，为了防止直接操作磁盘，都会有缓存这一层","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605852870,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1231549,"avatar":"https://static001.geekbang.org/account/avatar/00/12/ca/bd/a51ae4b2.jpg","nickname":"吃饭饭","note":"","ucode":"95CFA07CDA2957","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":291906,"discussion_content":"这哥们只管问，从不回复啊","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1594996218,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2049905,"avatar":"","nickname":"爱码哥（Gerry）","note":"","ucode":"17FD4F4A2695DB","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":291506,"discussion_content":"你好，你说的死锁版本是kafka 2.1.0版本嘛？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1594859294,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":105414,"user_name":"theivanxu","can_delete":false,"product_type":"c1","uid":1154400,"ip_address":"","ucode":"7A4794EACA6C97","user_header":"https://static001.geekbang.org/account/avatar/00/11/9d/60/55b9660f.jpg","comment_is_top":false,"comment_ctime":1560995139,"is_pvip":true,"replies":[{"id":"38188","content":"没有通用的标准，只有一个最佳实践值：6GB。最好还是监控一下实时的堆大小，特别是GC之后的live data大小，通常将heapsize设置成其1.5~2倍就足以了","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561020404,"ip_address":"","comment_id":105414,"utype":1}],"discussion_count":1,"race_medal":1,"score":"65985504579","product_id":100029201,"comment_content":"最近环境中有一台3G堆内存的节点在某个topic handle request的时候一直OOM，调整到5G重启后恢复正常，很想知道如何评判堆内存大小设置的标准。","like_count":15,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454673,"discussion_content":"没有通用的标准，只有一个最佳实践值：6GB。最好还是监控一下实时的堆大小，特别是GC之后的live data大小，通常将heapsize设置成其1.5~2倍就足以了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561020404,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":153086,"user_name":"张振宇","can_delete":false,"product_type":"c1","uid":1130691,"ip_address":"","ucode":"7A6FD7294E65FF","user_header":"https://static001.geekbang.org/account/avatar/00/11/40/c3/e545ba80.jpg","comment_is_top":false,"comment_ctime":1574155308,"is_pvip":false,"replies":[{"id":"58853","content":"这是我之前写的，可以参考下：https:&#47;&#47;www.cnblogs.com&#47;huxi2b&#47;p&#47;8609453.html<br>","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1574210907,"ip_address":"","comment_id":153086,"utype":1}],"discussion_count":3,"race_medal":0,"score":"53113762860","product_id":100029201,"comment_content":"老师，怎么能限制消费者的消费速度，或者限制消费带宽啊，","like_count":12,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":475037,"discussion_content":"这是我之前写的，可以参考下：https://www.cnblogs.com/huxi2b/p/8609453.html\n","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1574210907,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1083422,"avatar":"https://static001.geekbang.org/account/avatar/00/10/88/1e/69e84907.jpg","nickname":"罗罗诺亚.恩佐","note":"","ucode":"42D7932946CEBF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":261182,"discussion_content":"什么场景需要限制消费速度啊？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588945156,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1214808,"avatar":"https://static001.geekbang.org/account/avatar/00/12/89/58/ba318314.jpg","nickname":"db","note":"","ucode":"2E21B60B4C0FC8","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1083422,"avatar":"https://static001.geekbang.org/account/avatar/00/10/88/1e/69e84907.jpg","nickname":"罗罗诺亚.恩佐","note":"","ucode":"42D7932946CEBF","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":571815,"discussion_content":"消费者所在机器配置过低，承接不了kafka吐给他的数据量，可能会造成磁盘io过高，或者占用带宽较高吧。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1652420461,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":261182,"ip_address":""},"score":571815,"extra":""}]}]},{"had_liked":false,"id":216073,"user_name":"张洋","can_delete":false,"product_type":"c1","uid":1182914,"ip_address":"","ucode":"549BE5DEEF8417","user_header":"https://static001.geekbang.org/account/avatar/00/12/0c/c2/bad34a50.jpg","comment_is_top":false,"comment_ctime":1589182599,"is_pvip":true,"replies":[{"id":"80065","content":"Kafka其实只是把数据写入到pagecache中，后面的刷盘是由os完成的，什么时候刷，刷那些数据都是由os决定","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1589248798,"ip_address":"","comment_id":216073,"utype":1}],"discussion_count":1,"race_medal":0,"score":"40243888263","product_id":100029201,"comment_content":"老师我想问下，写入到pageCache  根据配置的时间‘脏数据’Flush到磁盘，kafka 把数据同步到磁盘只在这个地方做吗。意思是：只有每次‘判断’的脏数据才入盘吗，其他的数据呢？","like_count":9,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":494660,"discussion_content":"Kafka其实只是把数据写入到pagecache中，后面的刷盘是由os完成的，什么时候刷，刷那些数据都是由os决定","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589248798,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":206102,"user_name":"王晨光","can_delete":false,"product_type":"c1","uid":1914972,"ip_address":"","ucode":"A3EC8815A534C0","user_header":"https://static001.geekbang.org/account/avatar/00/1d/38/5c/2d1de317.jpg","comment_is_top":false,"comment_ctime":1586787272,"is_pvip":false,"replies":[{"id":"76997","content":"OOM的问题首先看下到底是那OOM的问题可以这样排查：<br>1. 到底是哪部分内存。大部分是堆溢出<br>2. 如果是heap溢出，主要看stacktrace，看看到底是哪段代码导致的<br>3. 再看导致的原因，到底是内存泄露还是内存溢出。这两者是有区别的。前者是程序写的有问题，后者是程序确实需要这么多内存，那么只能增加heap size<br><br>不管怎么样，你可以先增加一下heap size试试，如果还是OOM，那么很有可能出现了内存泄露","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1586828765,"ip_address":"","comment_id":206102,"utype":1}],"discussion_count":1,"race_medal":0,"score":"40241492936","product_id":100029201,"comment_content":"老师，kafka消费段，过一段时间jvm内存就会超过设置上线，有什么好的思路调整吗","like_count":9,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491671,"discussion_content":"OOM的问题首先看下到底是那OOM的问题可以这样排查：\n1. 到底是哪部分内存。大部分是堆溢出\n2. 如果是heap溢出，主要看stacktrace，看看到底是哪段代码导致的\n3. 再看导致的原因，到底是内存泄露还是内存溢出。这两者是有区别的。前者是程序写的有问题，后者是程序确实需要这么多内存，那么只能增加heap size\n\n不管怎么样，你可以先增加一下heap size试试，如果还是OOM，那么很有可能出现了内存泄露","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586828765,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":105411,"user_name":"刘朋","can_delete":false,"product_type":"c1","uid":1075141,"ip_address":"","ucode":"7B7B8E4776C22E","user_header":"https://static001.geekbang.org/account/avatar/00/10/67/c5/63b09189.jpg","comment_is_top":false,"comment_ctime":1560994654,"is_pvip":false,"replies":[{"id":"38187","content":"不算内核参数，是文件系统的参数。你可以查询一下文件系统手册。比如ext4就是commit=Nseconds这样设置","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561020342,"ip_address":"","comment_id":105411,"utype":1}],"discussion_count":1,"race_medal":0,"score":"40215700318","product_id":100029201,"comment_content":"系统会根据LRU算法定期将页缓存上的 脏 数据落盘到物理磁盘上. 这个定期就是由提交时间来确定的,默认是5秒.<br><br>这个时间如何设置？ 是内核参数吗？ ","like_count":9,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454672,"discussion_content":"不算内核参数，是文件系统的参数。你可以查询一下文件系统手册。比如ext4就是commit=Nseconds这样设置","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561020342,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":105524,"user_name":"Xiao","can_delete":false,"product_type":"c1","uid":1179212,"ip_address":"","ucode":"71FFCCEEDE09E1","user_header":"https://static001.geekbang.org/account/avatar/00/11/fe/4c/46eb517a.jpg","comment_is_top":false,"comment_ctime":1561021185,"is_pvip":true,"replies":[{"id":"38260","content":"会有的，后面有防止消息丢失和重复消费，到时候一起讨论哈","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561080422,"ip_address":"","comment_id":105524,"utype":1}],"discussion_count":1,"race_medal":0,"score":"31625792257","product_id":100029201,"comment_content":"帅气的胡老师，后边是否会将Kafka数据丢失和消息重复的场景以以及解决思路！","like_count":7,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454713,"discussion_content":"会有的，后面有防止消息丢失和重复消费，到时候一起讨论哈","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561080422,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":206313,"user_name":"露娜","can_delete":false,"product_type":"c1","uid":1289012,"ip_address":"","ucode":"CC3EF71EB30EE1","user_header":"https://static001.geekbang.org/account/avatar/00/13/ab/34/ef002163.jpg","comment_is_top":false,"comment_ctime":1586838126,"is_pvip":false,"replies":[{"id":"77344","content":"这里想表达的意思是，如果swap=0，内存不足时oom killer触发可能直接将broker进程杀死。而如果设置swap为一个比较小的值，在oom killer触发前你至少有一段时间观察到broker性能变差，给你监控和调优都留了一些时间","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1587004932,"ip_address":"","comment_id":206313,"utype":1}],"discussion_count":1,"race_medal":0,"score":"23061674606","product_id":100029201,"comment_content":"swap设置成1，可以观测到Broker 性能开始出现急剧下降，从而进一步调优和诊断问题。这个地方的意思是观测运维指标，发现Kafka性能下降然后被kill。基本可以推断是出发了OOM Killer 是吗？","like_count":5,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491749,"discussion_content":"这里想表达的意思是，如果swap=0，内存不足时oom killer触发可能直接将broker进程杀死。而如果设置swap为一个比较小的值，在oom killer触发前你至少有一段时间观察到broker性能变差，给你监控和调优都留了一些时间","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587004932,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":123238,"user_name":"钱","can_delete":false,"product_type":"c1","uid":1009652,"ip_address":"","ucode":"2C92A243A463D4","user_header":"https://static001.geekbang.org/account/avatar/00/0f/67/f4/9a1feb59.jpg","comment_is_top":false,"comment_ctime":1565651782,"is_pvip":false,"replies":[{"id":"45266","content":"1. Broker是Kafka集群的服务器。启动集群就是指启动若干个Broker进程<br>2. Topic在一个Kafka集群上可能有很多个，Topic数据的确保存在Broker上，但它们之间没有什么关系。1台Broker也可以对外提供服务，只是如你所说：很脆弱。<br>3. 分区下面是副本，副本的存储结构是日志（log）。每条消息写入分区时，其实是写入副本的日志文件中","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1565656948,"ip_address":"","comment_id":123238,"utype":1}],"discussion_count":2,"race_medal":0,"score":"18745520966","product_id":100029201,"comment_content":"胡老师或者其他同学，初学kafka有些概念没完全弄明白，请帮忙解答一下，多谢。<br>1：broker的本质是什么？启动一个kafka应用程序的进程就相当于一个broker在跑了嘛？还是说可以通过设置会存在多个broker在跑？<br>2：broker和topic的关系是怎么样的？目前我确定的是一个kafka集群中topic一定是一个唯一的，但肯定会有多个broker，是不是说启一台kafka服务器就是一个broker在跑，多个一块构成一个集群？还是说一台服务器可以跑多个kafka程序也有多个broker在跑，也能构成一个集群，只是比较脆弱？<br>3：分区的底层数据结构是什么？队列？数组还是列表？还是说分区这一次还不够底层和具体的数据结构关系不大？<br>请老师帮忙解答一下，学到目前还不太明确一个消息从生产出来到消费掉，都经历了那些关键的路程，感觉理解其他的越发困难了，如果方便也请老师大致勾画一下一个消息的生命轨迹，其中那些是关键的转变？<br>多谢啦!","like_count":4,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":462594,"discussion_content":"1. Broker是Kafka集群的服务器。启动集群就是指启动若干个Broker进程\n2. Topic在一个Kafka集群上可能有很多个，Topic数据的确保存在Broker上，但它们之间没有什么关系。1台Broker也可以对外提供服务，只是如你所说：很脆弱。\n3. 分区下面是副本，副本的存储结构是日志（log）。每条消息写入分区时，其实是写入副本的日志文件中","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1565656948,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1009652,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/67/f4/9a1feb59.jpg","nickname":"钱","note":"","ucode":"2C92A243A463D4","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":4679,"discussion_content":"多谢，老师的答疑。\n请问副本就是日志文件对吗？这个日志文件的具体格式是怎么样的呢？怎么表示一条一条的消息？一条条消息之间有逻辑关系嘛？之前kafka的作者说kafka也可以作为分布式存储系统，那查询是极其关键的，使用kafka查询某消息的性能如何呢？\n抱歉，问题有点多，我有点好奇，是否存储消息也存在类数据的索引结构？以及如果有，这个结构如何实现的？如果没有，那查询一条消息岂非要全部遍历，性能怎么保证呢？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1565659557,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":105374,"user_name":"bunny","can_delete":false,"product_type":"c1","uid":1513004,"ip_address":"","ucode":"EB5A8447708CE6","user_header":"https://static001.geekbang.org/account/avatar/00/17/16/2c/243c354a.jpg","comment_is_top":false,"comment_ctime":1560991083,"is_pvip":false,"replies":[{"id":"38183","content":"这是topic级别的参数，控制每个分区能占用的最大磁盘空间。设置它就好了~~<br><br>监控的话，好像没有现成的JMX指标。我之前写过一个方法可以监控磁盘占用，你不妨一试：https:&#47;&#47;www.cnblogs.com&#47;huxi2b&#47;p&#47;7929690.html ","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561018488,"ip_address":"","comment_id":105374,"utype":1}],"discussion_count":2,"race_medal":0,"score":"18740860267","product_id":100029201,"comment_content":"胡老师，这个参数retention.bytes应该是指使用的磁盘空间吧，而且是针对于单个分区的;之前遇到过kafka将磁盘写满的情况，导致broker不可用，请问有什么好的预防措施和监控手段么？","like_count":4,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454652,"discussion_content":"这是topic级别的参数，控制每个分区能占用的最大磁盘空间。设置它就好了~~\n\n监控的话，好像没有现成的JMX指标。我之前写过一个方法可以监控磁盘占用，你不妨一试：https://www.cnblogs.com/huxi2b/p/7929690.html ","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561018488,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1285800,"avatar":"https://static001.geekbang.org/account/avatar/00/13/9e/a8/09106237.jpg","nickname":"吴亚楠","note":"","ucode":"9582C4086FD13E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":4,"discussion_content":"系统级别的监控磁盘","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561002666,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":196436,"user_name":"poettian","can_delete":false,"product_type":"c1","uid":1144021,"ip_address":"","ucode":"26EE408F908D12","user_header":"https://static001.geekbang.org/account/avatar/00/11/74/d5/de9641dc.jpg","comment_is_top":false,"comment_ctime":1585281017,"is_pvip":false,"replies":[{"id":"74832","content":"确实只需要写1个就可以，因为Kafka能够通过这1个找到集群所有的Broker。当然最好还是多写几个","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1585533471,"ip_address":"","comment_id":196436,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14470182905","product_id":100029201,"comment_content":"请教老师一个问题，我在使用 kafka 客户端应用时，有时会需要 broker list 这个参数，在我的集群有三个broker 的情况下，我发现 只填一个 和 三个都填上 都可以用，这个有什么区别吗？网上搜了一圈也没搜着","like_count":3,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":489300,"discussion_content":"确实只需要写1个就可以，因为Kafka能够通过这1个找到集群所有的Broker。当然最好还是多写几个","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1585533471,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":134527,"user_name":"云师兄","can_delete":false,"product_type":"c1","uid":1010459,"ip_address":"","ucode":"4475AF1598FBFD","user_header":"https://static001.geekbang.org/account/avatar/00/0f/6b/1b/4b397b80.jpg","comment_is_top":false,"comment_ctime":1568859131,"is_pvip":false,"replies":[{"id":"51671","content":"zero copy和heap size并无直接的关联。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1568901888,"ip_address":"","comment_id":134527,"utype":1}],"discussion_count":2,"race_medal":0,"score":"14453761019","product_id":100029201,"comment_content":"设置堆大小为6g（较大）时候，文章说是broker提交时候大量bytebuf，kafka如果使用zero copy，也要设置大堆值吗","like_count":3,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":467789,"discussion_content":"zero copy和heap size并无直接的关联。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1568901888,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1030082,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b7/c2/196932c7.jpg","nickname":"南琛一梦","note":"","ucode":"6338D5428DB2B0","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":413332,"discussion_content":"zero copy是直接将数据在内核态完成处理，占用的是机器内存中非堆的部分，也就是常说的堆外内存，二者并不是一个含义。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1636448756,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":133339,"user_name":"miwucc","can_delete":false,"product_type":"c1","uid":1326429,"ip_address":"","ucode":"7935BD907119AE","user_header":"https://static001.geekbang.org/account/avatar/00/14/3d/5d/ac666969.jpg","comment_is_top":false,"comment_ctime":1568520886,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"14453422774","product_id":100029201,"comment_content":"上了6g内存确实g1最好。4g cms，3g以下就pg","like_count":3,"discussions":[{"author":{"id":1786819,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/43/c3/2c53acd7.jpg","nickname":"雄鹰","note":"","ucode":"67E0C4BDE7F6F2","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":318650,"discussion_content":"同问？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1603798627,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1008348,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/62/dc/8876c73b.jpg","nickname":"moooofly","note":"","ucode":"4A20795C281B6F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":58368,"discussion_content":"这个结论是怎么得到的？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1574671743,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":110535,"user_name":"King Yao","can_delete":false,"product_type":"c1","uid":1026946,"ip_address":"","ucode":"B431FD02175B96","user_header":"https://static001.geekbang.org/account/avatar/00/0f/ab/82/b6af9f94.jpg","comment_is_top":false,"comment_ctime":1562291296,"is_pvip":false,"replies":[{"id":"40200","content":"路径下有多个.log文件才有可能删除消息，如果只有一个.log文件是不会开启的，即使满足条件也不行。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1562307246,"ip_address":"","comment_id":110535,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14447193184","product_id":100029201,"comment_content":"多个日志段文件？这个没太理解，老师能详细说下吗，谢谢。","like_count":3,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":456927,"discussion_content":"路径下有多个.log文件才有可能删除消息，如果只有一个.log文件是不会开启的，即使满足条件也不行。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1562307246,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":110191,"user_name":"King Yao","can_delete":false,"product_type":"c1","uid":1026946,"ip_address":"","ucode":"B431FD02175B96","user_header":"https://static001.geekbang.org/account/avatar/00/0f/ab/82/b6af9f94.jpg","comment_is_top":false,"comment_ctime":1562205726,"is_pvip":false,"replies":[{"id":"40147","content":"你要有多个日志段文件消息删除才可能生效。只有一个日志段文件是没用的。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1562286900,"ip_address":"","comment_id":110191,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14447107614","product_id":100029201,"comment_content":"老师请教一个问题，我们设置了过期时间3小时，但是客户端还是会消费到昨天的昨天的消息，这个如何查找原因呢","like_count":3,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":456769,"discussion_content":"你要有多个日志段文件消息删除才可能生效。只有一个日志段文件是没用的。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1562286900,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":108451,"user_name":"黎","can_delete":false,"product_type":"c1","uid":1008946,"ip_address":"","ucode":"B2AB6BB4D7FE9C","user_header":"https://static001.geekbang.org/account/avatar/00/0f/65/32/74e47b74.jpg","comment_is_top":false,"comment_ctime":1561775614,"is_pvip":false,"discussion_count":0,"race_medal":2,"score":"14446677502","product_id":100029201,"comment_content":"老师的美式英语发音真标准","like_count":3},{"had_liked":false,"id":105491,"user_name":"Geek_Sue","can_delete":false,"product_type":"c1","uid":1580774,"ip_address":"","ucode":"B2C9400D72BB1D","user_header":"","comment_is_top":false,"comment_ctime":1561014430,"is_pvip":false,"replies":[{"id":"38200","content":"Kafka 2.0已经不支持Java 7了，2.1版本开始初步支持Java 11，但不建议生产环境用11，所以还是使用Java 8吧。<br><br>性能方面，如果是Linux平台，性能的差异主要还是Java版本升级带来的差异吧，应该说影响不是太大。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561021195,"ip_address":"","comment_id":105491,"utype":1}],"discussion_count":2,"race_medal":0,"score":"14445916318","product_id":100029201,"comment_content":"胡老师，您好，文章中提到的JVM版本问题，是否有比较好的建议呢？Java版本对于Kafka的性能方面影响大吗？","like_count":3,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454703,"discussion_content":"Kafka 2.0已经不支持Java 7了，2.1版本开始初步支持Java 11，但不建议生产环境用11，所以还是使用Java 8吧。\n\n性能方面，如果是Linux平台，性能的差异主要还是Java版本升级带来的差异吧，应该说影响不是太大。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561021195,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1134861,"avatar":"https://static001.geekbang.org/account/avatar/00/11/51/0d/fc1652fe.jpg","nickname":"James","note":"","ucode":"48B0F2A334D1C1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":46876,"discussion_content":"马克","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1573222073,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":216218,"user_name":"James","can_delete":false,"product_type":"c1","uid":1134861,"ip_address":"","ucode":"48B0F2A334D1C1","user_header":"https://static001.geekbang.org/account/avatar/00/11/51/0d/fc1652fe.jpg","comment_is_top":false,"comment_ctime":1589206401,"is_pvip":false,"replies":[{"id":"80061","content":"👍","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1589248562,"ip_address":"","comment_id":216218,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10179140993","product_id":100029201,"comment_content":"随便写一下,方便以后查看<br><br>二.Topic级别参数(以Topic级别参数为主,可覆盖全局Broker参数的值)<br>1.retention.ms<br>(消息被保存的时长)<br>2.retention.bytes<br>(预留多大的磁盘空间)<br>3.max.message.bytes<br>(能够正常接收该Topic的最大消息大小)<br>4.调整参数<br>bin&#47;kafka-configs.sh --zookeeper localhost:2181 --entity-type topics --entity-name transaction --alter --add-config max.message.bytes=10485760<br><br>三.JVM参数(java版本1.8以上,自2.0版本以上仅支持jdk1.8以上)<br>1.Heap Size设置为6GB(默认为1GB)<br>(Broker与客户端交互会在堆上创建大量的ByteBuffer)<br>2.垃圾回收器的设置<br>2.1jdk1.7,在cpu充足下使用CMS收集器<br>否则使用吞吐量收集器。开启方法是指定-XX:+UseParallelGC<br>2.2jdk1.8,使用默认Parallel GC,Java9默认才是G1<br><br>以上参数,在启动Broker前配置<br>$&gt; export KAFKA_HEAP_OPTS=--Xms6g  --Xmx6g<br>$&gt; export KAFKA_JVM_PERFORMANCE_OPTS= -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=true<br>$&gt; bin&#47;kafka-server-start.sh config&#47;server.properties<br><br><br>四.操作系统参数<br>4.1文件描述符<br>(设置ulimit -n 1000000 ,否则Too many open files)<br>4.2限制文件系统类型<br>(ext3,ext4,XFS日志型文件系统;XFS的性能要强于ext4最好还是使用XFS)<br>4.3Swappiness<br>(设置为0,当无物理内存时会随机杀死进程;设置接近0不为0的值,可以观测到Broker性能下降时,给予调优的时间)<br>4.4提交时间(Flush落盘时间)<br>(向Kafka发送数据并不是真正等数据写入磁盘才算成功;而是只要数据被写入到操作系统的页缓存就算成功)<br>默认为5s,应该提高这个时间,降低物理磁盘的写操作.","like_count":2,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":494721,"discussion_content":"👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589248562,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":137010,"user_name":"小可","can_delete":false,"product_type":"c1","uid":1006735,"ip_address":"","ucode":"8834AF621FA67D","user_header":"https://static001.geekbang.org/account/avatar/00/0f/5c/8f/551b5624.jpg","comment_is_top":false,"comment_ctime":1569575302,"is_pvip":false,"replies":[{"id":"52558","content":"最好确认下是否真的修改成功，比如是否是在&#47;etc&#47;security&#47;limits.conf中修改的，这个才是永久生效的配置","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1569579854,"ip_address":"","comment_id":137010,"utype":1}],"discussion_count":2,"race_medal":0,"score":"10159509894","product_id":100029201,"comment_content":"老师好，我这边单机kafka，400个client，出现这个错误<br>ulimit 和 file-max都调大了，还是报错<br><br>ERROR Error while accepting connection (kafka.network.Acceptor)<br>java.io.IOException: No file descriptors available<br>\tat sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)<br>\tat sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)<br>\tat sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)<br>\tat kafka.network.Acceptor.accept(SocketServer.scala:460)<br>\tat kafka.network.Acceptor.run(SocketServer.scala:403)<br>\tat java.lang.Thread.run(Thread.java:748)<br><br>","like_count":2,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":468902,"discussion_content":"最好确认下是否真的修改成功，比如是否是在/etc/security/limits.conf中修改的，这个才是永久生效的配置","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1569579854,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1006735,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5c/8f/551b5624.jpg","nickname":"小可","note":"","ucode":"8834AF621FA67D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":22426,"discussion_content":"改的就是这个，最后确认是别人客户端代码问题，异常时不断创建client连接😥","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1569637737,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":112714,"user_name":"行则将至","can_delete":false,"product_type":"c1","uid":1542987,"ip_address":"","ucode":"DB972F2DF059C4","user_header":"https://static001.geekbang.org/account/avatar/00/17/8b/4b/fa52d222.jpg","comment_is_top":false,"comment_ctime":1562809054,"is_pvip":false,"replies":[{"id":"41130","content":"其实就是：反正也没什么事，就读吧。。。。。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1562892999,"ip_address":"","comment_id":112714,"utype":1}],"discussion_count":3,"race_medal":1,"score":"10152743646","product_id":100029201,"comment_content":"老师，您读kafka源码的时候，肯定碰见过很多困难。是怎么坚持下去的？能简单说几句吗？谢谢","like_count":2,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":457871,"discussion_content":"其实就是：反正也没什么事，就读吧。。。。。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1562892999,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":1282021,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Crr2DudRs9Br7V6WKqKJko3dfOKJygicAIxLCLiaEaLoxgogBAgbXYjCLoFsib1yzOTN1kFf2P589JR0DN9gsde2g/132","nickname":"牛","note":"","ucode":"7AB8A25A3DD0C4","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":587962,"discussion_content":"这个很厉害，没什么事说明把这件事的优先级排的比较靠前","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1663406158,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":457871,"ip_address":"山东"},"score":587962,"extra":""}]},{"author":{"id":1064894,"avatar":"https://static001.geekbang.org/account/avatar/00/10/3f/be/c7141382.jpg","nickname":"是KK呀","note":"","ucode":"5DCEB53A13D049","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":79856,"discussion_content":"哈哈，老师蛮可爱","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1576117985,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":106305,"user_name":"wykkx","can_delete":false,"product_type":"c1","uid":1122358,"ip_address":"","ucode":"ABCDF49E7A95C8","user_header":"https://static001.geekbang.org/account/avatar/00/11/20/36/b3e2f1d5.jpg","comment_is_top":false,"comment_ctime":1561260456,"is_pvip":false,"replies":[{"id":"38512","content":"这些参数都是有默认值的，如果没加就是官网中的默认值。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561339633,"ip_address":"","comment_id":106305,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10151195048","product_id":100029201,"comment_content":"老师我的kafka的配置文件server.properties 里没有 message.max.bytes这个参数，是不是我要手工的加上去","like_count":2,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":455040,"discussion_content":"这些参数都是有默认值的，如果没加就是官网中的默认值。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561339633,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":106151,"user_name":"赌神很低调","can_delete":false,"product_type":"c1","uid":1168545,"ip_address":"","ucode":"1066778E1EDF26","user_header":"https://static001.geekbang.org/account/avatar/00/11/d4/a1/8bc8e7e1.jpg","comment_is_top":false,"comment_ctime":1561190458,"is_pvip":true,"replies":[{"id":"38500","content":"我的意思是至少还有其他正常的副本可以使用。。。这个副本重启回来后会重新加载日志段，获取到当前末端位移，因此也能感知刚才为成功写入的消息并重新拉取之~~","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561339005,"ip_address":"","comment_id":106151,"utype":1}],"discussion_count":3,"race_medal":0,"score":"10151125050","product_id":100029201,"comment_content":"“如果在页缓存中的数据在写入到磁盘前机器宕机了，那岂不是数据就丢失了。的确，这种情况数据确实就丢失了，但鉴于 Kafka 在软件层面已经提供了多副本的冗余机制，因此这里稍微拉大提交间隔去换取性能还是一个合理的做法。“即使提供了副本，这种情况数据也会丢吧？还是说这部分数据会重发？","like_count":2,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454977,"discussion_content":"我的意思是至少还有其他正常的副本可以使用。。。这个副本重启回来后会重新加载日志段，获取到当前末端位移，因此也能感知刚才为成功写入的消息并重新拉取之~~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561339005,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1181787,"avatar":"https://static001.geekbang.org/account/avatar/00/12/08/5b/2a342424.jpg","nickname":"青莲","note":"","ucode":"6BA5D5D47DE38E","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":181,"discussion_content":"kafka 生产者提交数据到broker时有几种机制可以选择，一般是ack等到一半以上follow收到消息返回成功，leader才会返回给生产者ok，这样即使leader挂掉了 但一般是子同步数据较多的follower会去选举成为leader，保证新的leader上还是有最新数据副本的","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1561259225,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1696125,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKMwnuGv3ZYsU2jVdQy9icXWJIbUrUYOazjn6cV3Rtq8knKdzMgWk1o9JaRsIzP6GrdicXEhGeCrSSA/132","nickname":"宠坏你","note":"","ucode":"501ADD1C0E7382","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":49905,"discussion_content":"那没写入磁盘的数据是不是就彻底丢失了呢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1573648617,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":106127,"user_name":"电光火石","can_delete":false,"product_type":"c1","uid":1013160,"ip_address":"","ucode":"3AD33BB4AA940F","user_header":"https://static001.geekbang.org/account/avatar/00/0f/75/a8/dfe4cade.jpg","comment_is_top":false,"comment_ctime":1561183639,"is_pvip":false,"replies":[{"id":"38493","content":"如果你只有8GB，就不要设置6GB了，酌情调小吧。具体设置方法可以监控堆上的live data，然后大约乘以1.5或2即可。比如你可以手动触发Full GC，然后查看一下堆上存活的数据大小，比如说是1500MB，那么你可以设置heap size为2.25GB。<br><br>没有说一定要配置相同，但是如果某些机器拖慢了整个集群，的确是要为它们做一些调整的。有条件的话可以保持配置一样，至少方面运维。<br>","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561338748,"ip_address":"","comment_id":106127,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10151118231","product_id":100029201,"comment_content":"老师，我们开始是用了3台物理机做broker，但是后面因为磁盘空间不够，做了扩容，但是是扩了8台云主机（性能明显不如物理机），按照produce 均匀分发的原则，会不会云主机会拖慢整个集群的处理效率？在我们搭建的时候，尽量机器配置相同？<br>另外，jvm的heap推荐6G，如果我整个机器的只有8G，是否50%-50%的分配比较合适？留一半给OS？<br>谢谢了！","like_count":2,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454966,"discussion_content":"如果你只有8GB，就不要设置6GB了，酌情调小吧。具体设置方法可以监控堆上的live data，然后大约乘以1.5或2即可。比如你可以手动触发Full GC，然后查看一下堆上存活的数据大小，比如说是1500MB，那么你可以设置heap size为2.25GB。\n\n没有说一定要配置相同，但是如果某些机器拖慢了整个集群，的确是要为它们做一些调整的。有条件的话可以保持配置一样，至少方面运维。\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561338748,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":106093,"user_name":"闭门造车","can_delete":false,"product_type":"c1","uid":1125278,"ip_address":"","ucode":"8EBB8083D2A6CB","user_header":"https://static001.geekbang.org/account/avatar/00/11/2b/9e/821c75f9.jpg","comment_is_top":false,"comment_ctime":1561172390,"is_pvip":false,"replies":[{"id":"38477","content":"嗯呢","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561337696,"ip_address":"","comment_id":106093,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10151106982","product_id":100029201,"comment_content":"如果broker设置的是消息留存7天，而topic A设置的是留存10天，那么实际应该是留存10天吧","like_count":2,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454945,"discussion_content":"嗯呢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561337696,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":105453,"user_name":"南山","can_delete":false,"product_type":"c1","uid":1119593,"ip_address":"","ucode":"94656FE4A6C378","user_header":"https://static001.geekbang.org/account/avatar/00/11/15/69/187b9968.jpg","comment_is_top":false,"comment_ctime":1561003533,"is_pvip":true,"replies":[{"id":"38198","content":"有道理。这里给出的6GB一般对那些很多的生产服务器而言的。如果只有8GB的服务器，自然不建议分配这么大的heap size。<br><br>另外监控堆占用也是sizing的一个好办法，特别是监控Full GC之后的live data大小。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561021016,"ip_address":"","comment_id":105453,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10150938125","product_id":100029201,"comment_content":"是不是要根据服务器性能来设置呢？比如机器的总内存是多少，单运行kafka的话，再针对性的按比例设置jvm内存大小呢？无脑设置6g也是在一定规格的服务器配置的情况下吧","like_count":2,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454691,"discussion_content":"有道理。这里给出的6GB一般对那些很多的生产服务器而言的。如果只有8GB的服务器，自然不建议分配这么大的heap size。\n\n另外监控堆占用也是sizing的一个好办法，特别是监控Full GC之后的live data大小。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561021016,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":247411,"user_name":"Geek_03","can_delete":false,"product_type":"c1","uid":1905527,"ip_address":"","ucode":"1502D858542269","user_header":"","comment_is_top":false,"comment_ctime":1599703020,"is_pvip":false,"replies":[{"id":"90905","content":"一批消息","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1599721961,"ip_address":"","comment_id":247411,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5894670316","product_id":100029201,"comment_content":"老师，我想问一下，message.max.bytes这个参数是针对单条消息做大小限制还是针对一批消息做大小限制呢","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":505391,"discussion_content":"一批消息","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1599721961,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":216199,"user_name":"James","can_delete":false,"product_type":"c1","uid":1134861,"ip_address":"","ucode":"48B0F2A334D1C1","user_header":"https://static001.geekbang.org/account/avatar/00/11/51/0d/fc1652fe.jpg","comment_is_top":false,"comment_ctime":1589204325,"is_pvip":false,"replies":[{"id":"80062","content":"不是配置文件里面配置的，是通过命令配置的","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1589248575,"ip_address":"","comment_id":216199,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5884171621","product_id":100029201,"comment_content":"请问老师,topic默认配置是哪个配置文件查看的.","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":494712,"discussion_content":"不是配置文件里面配置的，是通过命令配置的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589248575,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":213067,"user_name":"李奕慧","can_delete":false,"product_type":"c1","uid":1201005,"ip_address":"","ucode":"0D8871ED38859C","user_header":"https://static001.geekbang.org/account/avatar/00/12/53/6d/c3828950.jpg","comment_is_top":false,"comment_ctime":1588295078,"is_pvip":false,"replies":[{"id":"79097","content":"生产者和另外两个不冲突，主题的会覆盖服务器端的","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1588314463,"ip_address":"","comment_id":213067,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5883262374","product_id":100029201,"comment_content":"服务端 message.max.bytes<br>主题 max.message.bytes<br>生产者 max.request.size<br>这如果三个都设置了，且不同以哪个为准啊 生产者 吗","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493681,"discussion_content":"生产者和另外两个不冲突，主题的会覆盖服务器端的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588314463,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":108106,"user_name":"其实我很屌","can_delete":false,"product_type":"c1","uid":1138722,"ip_address":"","ucode":"2B75EAAD748A60","user_header":"https://static001.geekbang.org/account/avatar/00/11/60/22/92284df2.jpg","comment_is_top":false,"comment_ctime":1561683051,"is_pvip":false,"replies":[{"id":"39454","content":"topic级别参数是segment.bytes。应该没有缺陷。主要是它和你想的原理不太一样。看看我写的这篇：https:&#47;&#47;www.cnblogs.com&#47;huxi2b&#47;p&#47;8042099.html","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561948163,"ip_address":"","comment_id":108106,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5856650347","product_id":100029201,"comment_content":"老师，我用的kafka0.11.0，在新建topic的时候，命令上也是支持自定义topic价格参数的，但我发现我设置的log.segment.bytes参数并没有生效，还是用的集群配置，想知道topic的个性化配置，是从哪个版本提供的？是不是一开始还有缺陷？麻烦老师帮忙解答，谢谢","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":455827,"discussion_content":"topic级别参数是segment.bytes。应该没有缺陷。主要是它和你想的原理不太一样。看看我写的这篇：https://www.cnblogs.com/huxi2b/p/8042099.html","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561948163,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":106283,"user_name":"Geek_986289","can_delete":false,"product_type":"c1","uid":1182717,"ip_address":"","ucode":"503FE134FCC109","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKtYGLkKnh186Ynyx3bPvOMI7ViaWia2l8DD8eomDkE6AKNwW7l1a00CiaaiaiapibZY5JlQlxqQEQuSYFg/132","comment_is_top":false,"comment_ctime":1561255141,"is_pvip":false,"replies":[{"id":"38511","content":"满足任何一个就会开始删除消息","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561339603,"ip_address":"","comment_id":106283,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5856222437","product_id":100029201,"comment_content":"老师请问，<br>retention.ms<br>retention.bytes<br>这两个参数是不是只要满足一个，Kafka就会开始清消息了？还是需要两个同时满足才会清消息？","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":455032,"discussion_content":"满足任何一个就会开始删除消息","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561339603,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":105731,"user_name":"明翼","can_delete":false,"product_type":"c1","uid":1068361,"ip_address":"","ucode":"E77F86BEB3D5C1","user_header":"https://static001.geekbang.org/account/avatar/00/10/4d/49/28e73b9c.jpg","comment_is_top":false,"comment_ctime":1561079410,"is_pvip":false,"replies":[{"id":"38269","content":"1. 删除的时候不会顾及consumer的。可能的问题就是位移越界导致的位移重置，比如consumer位移发生跳跃的情形<br>2. 是Coordinator挂掉还是所在broker挂掉？或者说后者挂掉也不一定就是Coordinator组件故障导致的吧。最好还是给出一些详细信息，否则不太好评估。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561082051,"ip_address":"","comment_id":105731,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5856046706","product_id":100029201,"comment_content":"胡老师，有个问题想提前请教下，就是我们生产环境有个kafka的存储周期因为磁盘大小原因没设置多大，所以有存在kafka在删除数据的时候，这些数据可能正在消费，程序挂死问题，日志显示kafka协调者死掉了，或者有的直接一台broker挂了。想请教下两个问题：一是，如果kafka在删除的时候，是不是一定会规避这些正在消费的数据，如果不规避会产生什么问题？二是，我们常遇到协调者死掉的问题，这个有可能有什么原因引起的。我们在用的版本为apache  kafka0.10.1","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454790,"discussion_content":"1. 删除的时候不会顾及consumer的。可能的问题就是位移越界导致的位移重置，比如consumer位移发生跳跃的情形\n2. 是Coordinator挂掉还是所在broker挂掉？或者说后者挂掉也不一定就是Coordinator组件故障导致的吧。最好还是给出一些详细信息，否则不太好评估。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561082051,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1008348,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/62/dc/8876c73b.jpg","nickname":"moooofly","note":"","ucode":"4A20795C281B6F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":58378,"discussion_content":"any updates?","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1574672413,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":105417,"user_name":"莫问流年","can_delete":false,"product_type":"c1","uid":1249663,"ip_address":"","ucode":"23140E031AED4B","user_header":"https://static001.geekbang.org/account/avatar/00/13/11/7f/80d56c1c.jpg","comment_is_top":false,"comment_ctime":1560995287,"is_pvip":false,"replies":[{"id":"38189","content":"同意：）","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561020414,"ip_address":"","comment_id":105417,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5855962583","product_id":100029201,"comment_content":"我觉得 Kafka broker设置堆内存够用的情况下即可，比如老师说的6G，具体也要根据实际kafka使用情况评估调整。一般服务器的内存都比较高，其余的给页缓存够了。","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454675,"discussion_content":"同意：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561020414,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":105387,"user_name":"蒙开强","can_delete":false,"product_type":"c1","uid":1317706,"ip_address":"","ucode":"61B3183781B9F7","user_header":"https://static001.geekbang.org/account/avatar/00/14/1b/4a/f9df2d06.jpg","comment_is_top":false,"comment_ctime":1560991588,"is_pvip":false,"replies":[{"id":"38185","content":"各用个的，不会有影响。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561018917,"ip_address":"","comment_id":105387,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5855958884","product_id":100029201,"comment_content":"老师，你好 你文章中提到topic级的参数优先级高于全局的参数，可以根据topic设置特定的参数，如果有的设置特定参数，有的用全局参数，那特定的覆盖了全局参数，那是不是会对用全局参数的topic造成干扰影响呢。","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454658,"discussion_content":"各用个的，不会有影响。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561018917,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":105372,"user_name":"风中花","can_delete":false,"product_type":"c1","uid":1085237,"ip_address":"","ucode":"067E0A1E116844","user_header":"https://static001.geekbang.org/account/avatar/00/10/8f/35/f1839bb2.jpg","comment_is_top":false,"comment_ctime":1560990888,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5855958184","product_id":100029201,"comment_content":"给老师点个赞！按时发布！辛苦","like_count":1},{"had_liked":false,"id":360480,"user_name":"杜桀","can_delete":false,"product_type":"c1","uid":2935490,"ip_address":"山东","ucode":"68B04A040AA940","user_header":"https://static001.geekbang.org/account/avatar/00/2c/ca/c2/f3ce9c87.jpg","comment_is_top":false,"comment_ctime":1666592743,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1666592743","product_id":100029201,"comment_content":"请教一个关于kafka buffer&#47;Cache 优化的问题。 我们采用容器运行的kafka，运行几个月后free -m 看到大部分内存都被buffer&#47;cache占用了，通过查看cgroups中内存用量发现都是kafka占用的。 不想采用设置cgroups的limits来限制kafka内存用量，担心会应用kafka正常使用。所以想问一下kafka有关于缓存释放的配置吗？","like_count":0},{"had_liked":false,"id":354264,"user_name":"余晓杰","can_delete":false,"product_type":"c1","uid":1889760,"ip_address":"江苏","ucode":"97269A045FE190","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEIoRAqV3Yic1wa2gKDq74h1SB5azIpZAOE2uY43CZevju1vd4wxibXq3Y6LJvxJ4tlsJEEmkI64ZJvw/132","comment_is_top":false,"comment_ctime":1660225720,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1660225720","product_id":100029201,"comment_content":"Jdk7不能设置g1吗","like_count":0},{"had_liked":false,"id":345541,"user_name":"InfoQ_7b1f2555555f","can_delete":false,"product_type":"c1","uid":1962216,"ip_address":"","ucode":"FB718710FD5B12","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erp3Is6ckmsGqtTP8t7xTQkrLUcOcFstAkE565FmYFibawfVIXTtu1vXtXibpHZK5dBL2F42ZpM0iamA/132","comment_is_top":false,"comment_ctime":1652367968,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1652367968","product_id":100029201,"comment_content":"kafka设置手动提交之后，如果提交成功那么提交成功的意思是提交到操作系统页缓存成功了？剩下的也需要靠操作系统定期刷新到硬盘？","like_count":0},{"had_liked":false,"id":334193,"user_name":"晴天","can_delete":false,"product_type":"c1","uid":2911405,"ip_address":"","ucode":"7DD9D1274C1F3E","user_header":"https://static001.geekbang.org/account/avatar/00/2c/6c/ad/8ea2e93e.jpg","comment_is_top":false,"comment_ctime":1644806339,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1644806339","product_id":100029201,"comment_content":"老师请问，日志过期时间设置了7天，是删除7天内已经消费的数据还是未消费的也会被删除？","like_count":0},{"had_liked":false,"id":320988,"user_name":"Pierce","can_delete":false,"product_type":"c1","uid":1128843,"ip_address":"","ucode":"D5401B96AC2E1A","user_header":"https://static001.geekbang.org/account/avatar/00/11/39/8b/d021d285.jpg","comment_is_top":false,"comment_ctime":1636611314,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1636611314","product_id":100029201,"comment_content":"老师您好,请问retention.bytes参数控制的是Topic全部Partition磁盘用量的总和,还是限制单个Partition的磁盘用量呢?","like_count":0},{"had_liked":false,"id":320980,"user_name":"拿笔小星","can_delete":false,"product_type":"c1","uid":1193755,"ip_address":"","ucode":"D3D8F6A959710D","user_header":"https://static001.geekbang.org/account/avatar/00/12/37/1b/82310e20.jpg","comment_is_top":false,"comment_ctime":1636608953,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1636608953","product_id":100029201,"comment_content":"业界推荐jvm设置6GB，这个数字是怎么来的呢？","like_count":0,"discussions":[{"author":{"id":1736462,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/7f/0e/e3a8dbd9.jpg","nickname":"Liujun","note":"","ucode":"3DB1F3CA57B5B3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":559028,"discussion_content":"G1的最佳使用场景是JVM 大于6G的条件，除此之外其他均为瞎编","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1648567889,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":313897,"user_name":"lucas","can_delete":false,"product_type":"c1","uid":1564695,"ip_address":"","ucode":"B2973251F63A15","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTI3lJFX3XBF3C0qriazEcv7rPsdJZCwz0bkmP5M37pa1IJr7G5LNQevXLFBzPpOZLzNZnybN0bNPhg/132","comment_is_top":false,"comment_ctime":1632730514,"is_pvip":false,"replies":[{"id":"114437","content":"可能是消息已经被删除了，或者是有些topic配置成了compact","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1634004517,"ip_address":"","comment_id":313897,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1632730514","product_id":100029201,"comment_content":"老师好，我遇到一个奇怪的问题，flink消费kafka的时候发现同一分区的offset偶尔有不连续的，比如10、11、12、14，13没了，我指定去消费，发现这个offset确实没有，这是什么情况，是不是有问题，丢数据了？我的理解生产者消息写入应该是连续的么","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527510,"discussion_content":"可能是消息已经被删除了，或者是有些topic配置成了compact","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1634004517,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":301052,"user_name":"小源哥","can_delete":false,"product_type":"c1","uid":1730754,"ip_address":"","ucode":"B5130CE20CF31D","user_header":"https://static001.geekbang.org/account/avatar/00/1a/68/c2/b112da90.jpg","comment_is_top":false,"comment_ctime":1625498258,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1625498258","product_id":100029201,"comment_content":"不知道1.8上g1表现怎么样，对此我持谨慎态度","like_count":0},{"had_liked":false,"id":298411,"user_name":"Soul","can_delete":false,"product_type":"c1","uid":1332755,"ip_address":"","ucode":"91D8794DD2FAD2","user_header":"https://static001.geekbang.org/account/avatar/00/14/56/13/b2f3611e.jpg","comment_is_top":false,"comment_ctime":1624088956,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1624088956","product_id":100029201,"comment_content":"unclean.leader.election.enable：是否允许 Unclean Leader 选举。<br>假如按照推荐的设置成false， 由其他存储比较多的副本来参与竞争 竞选Leader， 这时候的副本应该也是数据不全的副本吧， 不还是会丢失数据？<br>和设置成true，用落后更多数据的副本产生的副作用不是一样吗？","like_count":0},{"had_liked":false,"id":296324,"user_name":"Ru","can_delete":false,"product_type":"c1","uid":2563580,"ip_address":"","ucode":"EEF496EC828DD1","user_header":"https://static001.geekbang.org/account/avatar/00/27/1d/fc/12dc7a46.jpg","comment_is_top":false,"comment_ctime":1622899318,"is_pvip":false,"replies":[{"id":"107773","content":"找不回数据了。只能依靠副本机制来保证一致性了","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1623120163,"ip_address":"","comment_id":296324,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1622899318","product_id":100029201,"comment_content":"kafka写入cache丢失这里没太懂：<br>假设OS写丢了，kafka也已经写入cache，确认写成功了，如何找回数据？<br>","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":521396,"discussion_content":"找不回数据了。只能依靠副本机制来保证一致性了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1623120163,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":265543,"user_name":"Coding小先","can_delete":false,"product_type":"c1","uid":1051563,"ip_address":"","ucode":"965B1CC757E026","user_header":"https://static001.geekbang.org/account/avatar/00/10/0b/ab/0e2857e5.jpg","comment_is_top":false,"comment_ctime":1606925466,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1606925466","product_id":100029201,"comment_content":"在 Linux 系统中，一个长连接会占用一个 Socket 句柄（文件描述符），像 Ubuntu 默认是 1024，也就是最多 1024 个 Socket 长连接，Kafka 网络通信中大量使用长连接，这对比较大的 Kafka 集群来说可能是不够的。<br><br>为了避免 Socket 句柄不够用，将这个设置为一个比较大值是合理的。","like_count":0},{"had_liked":false,"id":262787,"user_name":"朴素柠檬c","can_delete":false,"product_type":"c1","uid":1547667,"ip_address":"","ucode":"2D4CBB70D801B1","user_header":"https://static001.geekbang.org/account/avatar/00/17/9d/93/4159edaa.jpg","comment_is_top":false,"comment_ctime":1605842425,"is_pvip":false,"replies":[{"id":"95355","content":"嗯嗯，是的。这点不准确。Java 9才正式将G1切换为默认","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1605855745,"ip_address":"","comment_id":262787,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1605842425","product_id":100029201,"comment_content":"刚才通过命令 java -XX:+PrintFlagsFinal -version 默认的事CMS不是G1，而且不是说G1在jdk10后比较完善吗，文中说的默认G1是怎么得出的.","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509972,"discussion_content":"嗯嗯，是的。这点不准确。Java 9才正式将G1切换为默认","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605855745,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":260920,"user_name":"尚小树","can_delete":false,"product_type":"c1","uid":2165300,"ip_address":"","ucode":"9BCB0DF0F3C8E4","user_header":"https://static001.geekbang.org/account/avatar/00/21/0a/34/3e29eb5a.jpg","comment_is_top":false,"comment_ctime":1605152093,"is_pvip":false,"replies":[{"id":"94906","content":"1. 我倾向于做个试验试试就知道了：）<br>2. heap大小和写入量的关系不好评估，至少没有清晰且固化的关系。。。","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1605423370,"ip_address":"","comment_id":260920,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1605152093","product_id":100029201,"comment_content":"老师，想问一下如果使用默认的1G的 heap size或者更小 当数据量很大的时候会发生什么呢？<br>我的猜测是，数据会很快填满heap空间触发Full GC 导致kafka假死无法写入。我的猜想对么？<br>另外还想问下老师，heap的大小和写入数据量的关系什么呢，也就是ByteBuffer 和写入数据间的关系是什么呢？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509326,"discussion_content":"1. 我倾向于做个试验试试就知道了：）\n2. heap大小和写入量的关系不好评估，至少没有清晰且固化的关系。。。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605423370,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":248250,"user_name":"赵小通","can_delete":false,"product_type":"c1","uid":1047266,"ip_address":"","ucode":"C19D395C2E8BA4","user_header":"https://static001.geekbang.org/account/avatar/00/0f/fa/e2/178bc954.jpg","comment_is_top":false,"comment_ctime":1600080689,"is_pvip":false,"replies":[{"id":"91218","content":"Kafka的写入都是追加写(append-only)，所以是可以保证顺序写入的。删除数据是从文件起始部分开始删除，不影响写入。真正影响顺写写入的因素是同时写入多个分区的数据，此时，确实很难保证顺序写入","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1600131280,"ip_address":"","comment_id":248250,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1600080689","product_id":100029201,"comment_content":"老师，kafka高性能的原因是因为顺序读写，但是一旦删除数据，会不会造成磁盘的碎片化，导致新的写入的数据，就不是顺序读写了？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":505598,"discussion_content":"Kafka的写入都是追加写(append-only)，所以是可以保证顺序写入的。删除数据是从文件起始部分开始删除，不影响写入。真正影响顺写写入的因素是同时写入多个分区的数据，此时，确实很难保证顺序写入","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1600131280,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":247055,"user_name":"Action","can_delete":false,"product_type":"c1","uid":1239234,"ip_address":"","ucode":"FFFD1537C6BB3C","user_header":"https://static001.geekbang.org/account/avatar/00/12/e8/c2/77a413a7.jpg","comment_is_top":false,"comment_ctime":1599572307,"is_pvip":false,"replies":[{"id":"90757","content":"哪两个参数？","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1599617192,"ip_address":"","comment_id":247055,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1599572307","product_id":100029201,"comment_content":"export KAFKA_HEAP_OPTS=--Xms6g --Xmx6g$&gt; export KAFKA_JVM_PERFORMANCE_OPTS= -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=true$&gt; bin&#47;kafka-server-start.sh config&#47;server.properties<br>请问老师这两个参数设置在哪里呀？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":505297,"discussion_content":"哪两个参数？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1599617192,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1488243,"avatar":"https://static001.geekbang.org/account/avatar/00/16/b5/73/15a8006a.jpg","nickname":"goxdev","note":"","ucode":"7374587CD08BEE","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":393736,"discussion_content":"export KAFKA_HEAP_OPTS相当于把这个参数写到环境变量里面了，kafka启动的时候会读","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631581911,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":243996,"user_name":"阡陌","can_delete":false,"product_type":"c1","uid":1141254,"ip_address":"","ucode":"58634836C8E03F","user_header":"https://static001.geekbang.org/account/avatar/00/11/6a/06/66831563.jpg","comment_is_top":false,"comment_ctime":1598347737,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1598347737","product_id":100029201,"comment_content":"max.message.bytes：决定了Kafka Broker能够正常接收该Topic的最大消息大小。<br>replica.fetch.max.bytes：对上面参数的补充，此参数是broker端参数，修改max.message.bytes后需要同时在broker端修改该参数，使该参数大于所有topic的max.message.bytes，以确保数据复制正常。<br>fetch.message.max.bytes：对上面参数的补充，此参数是消费者端参数，修改max.message.bytes后需要在当前topic所属消费者端修改此参数，使消费者端该参数大于当前topic的max.message.bytes，以确保数据消费正常。","like_count":0},{"had_liked":false,"id":242910,"user_name":"单朋荣","can_delete":false,"product_type":"c1","uid":1272662,"ip_address":"","ucode":"8AD121BEDD9675","user_header":"https://static001.geekbang.org/account/avatar/00/13/6b/56/37a4cea7.jpg","comment_is_top":false,"comment_ctime":1597889825,"is_pvip":false,"replies":[{"id":"89607","content":"所以靠软件层面来保证不丢失。比如多个follower + acks=all<br>","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1597971842,"ip_address":"","comment_id":242910,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1597889825","product_id":100029201,"comment_content":"小白有个疑问哈，&quot;小结&quot;前面一段：写入pagecache如果数据丢失了，就真丢失了吧。。冗余机制毕竟只是从leader拿数据，写不到leader的数据不就真丢失了吗😂","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":504130,"discussion_content":"所以靠软件层面来保证不丢失。比如多个follower + acks=all\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1597971842,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":234964,"user_name":".","can_delete":false,"product_type":"c1","uid":1083502,"ip_address":"","ucode":"83F583994F4F72","user_header":"https://static001.geekbang.org/account/avatar/00/10/88/6e/3bd860d3.jpg","comment_is_top":false,"comment_ctime":1594860441,"is_pvip":true,"replies":[{"id":"86839","content":"可以有选择地查询数据","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1594947003,"ip_address":"","comment_id":234964,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1594860441","product_id":100029201,"comment_content":"我想问他们用kafka保存数据后，像保存半年以后怎么利用，难道要用时在全部取出来？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":501562,"discussion_content":"可以有选择地查询数据","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1594947003,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":234792,"user_name":"死后的天空","can_delete":false,"product_type":"c1","uid":1045293,"ip_address":"","ucode":"1652F8C8FE12F5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/f3/2d/4b7f12b6.jpg","comment_is_top":false,"comment_ctime":1594796622,"is_pvip":true,"replies":[{"id":"86715","content":"--zookeeper已经被标记为“不推荐”了，后续可能会被移除。对于用户来说，这两个参数没有太大区别","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1594860421,"ip_address":"","comment_id":234792,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1594796622","product_id":100029201,"comment_content":"在用kafka-topic.sh和group相关的命令时候，我发现可以用--bootstrap-server指定kafka来跑命令，也可以用 --zookeeper 指定zk来跑命令，这两种执行的方式有什么区别吗","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":501507,"discussion_content":"--zookeeper已经被标记为“不推荐”了，后续可能会被移除。对于用户来说，这两个参数没有太大区别","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1594860421,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1045293,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/f3/2d/4b7f12b6.jpg","nickname":"死后的天空","note":"","ucode":"1652F8C8FE12F5","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":291870,"discussion_content":"谢谢老师","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1594980982,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":221342,"user_name":"张洋","can_delete":false,"product_type":"c1","uid":1182914,"ip_address":"","ucode":"549BE5DEEF8417","user_header":"https://static001.geekbang.org/account/avatar/00/12/0c/c2/bad34a50.jpg","comment_is_top":false,"comment_ctime":1590478485,"is_pvip":true,"replies":[{"id":"81708","content":"书里面的文件系统算是广义的提法了。严格来说，页缓存属于磁盘缓存的一类。我们重点掌握这个原理就好；0","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1590547155,"ip_address":"","comment_id":221342,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1590478485","product_id":100029201,"comment_content":"老师关于消息发送成功这点还有点疑问，我在您的《Apach kafka 实战》一书中 1.3.2消息持久化 一章节中有这样一句话“所有数据都会被立即写入文件系统中，之后kafka服务器才会返回结果给客户端通知他们消息已经被成功写入。“ 但是你这篇文章写的是 消息写入 PageCache 中就会通知客户端 消息被成功写入，具体的落盘操作由OS来具体操作。","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":496431,"discussion_content":"书里面的文件系统算是广义的提法了。严格来说，页缓存属于磁盘缓存的一类。我们重点掌握这个原理就好；0","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1590547155,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":216193,"user_name":"James","can_delete":false,"product_type":"c1","uid":1134861,"ip_address":"","ucode":"48B0F2A334D1C1","user_header":"https://static001.geekbang.org/account/avatar/00/11/51/0d/fc1652fe.jpg","comment_is_top":false,"comment_ctime":1589203738,"is_pvip":false,"replies":[{"id":"80063","content":"一个是topic级别配置，一个是topic级别的，都是正确的","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1589248647,"ip_address":"","comment_id":216193,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1589203738","product_id":100029201,"comment_content":"上一章是message.max.bytes<br>这一章是max.message.bytes ,哪个才是正确得<br>server配置文件没有找到,是不是自己得自己写进去.","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":494710,"discussion_content":"一个是topic级别配置，一个是topic级别的，都是正确的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589248647,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1134861,"avatar":"https://static001.geekbang.org/account/avatar/00/11/51/0d/fc1652fe.jpg","nickname":"James","note":"","ucode":"48B0F2A334D1C1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":263429,"discussion_content":"知道了,前者是broker.后者是topic","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589206736,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":184722,"user_name":"SAM(陈嘉奇)","can_delete":false,"product_type":"c1","uid":1430905,"ip_address":"","ucode":"7A7B2767DE22E0","user_header":"https://static001.geekbang.org/account/avatar/00/15/d5/79/3d711fed.jpg","comment_is_top":false,"comment_ctime":1583391355,"is_pvip":false,"replies":[{"id":"71460","content":"如果你需要JVM参数的话还是需要设置这两个参数的。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1583456841,"ip_address":"","comment_id":184722,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1583391355","product_id":100029201,"comment_content":"老师你好，现在kafka安装都要求java的版本是8以上了。那是否就不需要配置这两个参数？谢谢<br>KAFKA_HEAP_OPTS：指定堆大小。KAFKA_JVM_PERFORMANCE_OPTS：指定 GC 参数。","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":486108,"discussion_content":"如果你需要JVM参数的话还是需要设置这两个参数的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1583456841,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":132108,"user_name":"Geek_b809ff","can_delete":false,"product_type":"c1","uid":1288329,"ip_address":"","ucode":"F3F17E99F3AA0B","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eoPY23R9RRSfBeTJUlyc612VlodjAaWWBNiay9tPydkrd6b9NA8GNibdibnFibTsx94ItHE4jvQwprNzA/132","comment_is_top":false,"comment_ctime":1568023935,"is_pvip":false,"replies":[{"id":"50564","content":"以kafka-server-start.sh为准","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1568077793,"ip_address":"","comment_id":132108,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1568023935","product_id":100029201,"comment_content":"KAFKA_HEAP_OPTS 参数在kafka-run-class.sh 是<br># Memory options<br>if [ -z &quot;$KAFKA_HEAP_OPTS&quot; ]; then<br>  KAFKA_HEAP_OPTS=&quot;-Xmx256M&quot;<br>fi <br>但是在kafka-server-start.sh 里面是<br>if [ &quot;x$KAFKA_HEAP_OPTS&quot; = &quot;x&quot; ]; then<br>    export KAFKA_HEAP_OPTS=&quot;-Xmx1G -Xms1G&quot;<br>fi<br>那到底以哪个为准，怎么两个默认的文件还设置的不一样呢。是有什么考虑？（我的版本是2.3.0）","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":466770,"discussion_content":"以kafka-server-start.sh为准","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1568077793,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":122630,"user_name":"天草二十六","can_delete":false,"product_type":"c1","uid":1360712,"ip_address":"","ucode":"3165EE3007527B","user_header":"https://static001.geekbang.org/account/avatar/00/14/c3/48/3a739da6.jpg","comment_is_top":false,"comment_ctime":1565445413,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1565445413","product_id":100029201,"comment_content":"学习kafaka相关的书籍有没有好推荐的","like_count":0,"discussions":[{"author":{"id":1149080,"avatar":"https://static001.geekbang.org/account/avatar/00/11/88/98/7bcd7183.jpg","nickname":"人生几度秋凉","note":"","ucode":"796591E35991BA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":6019,"discussion_content":"apache kafka 实战","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1566614900,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":122437,"user_name":"小鱼","can_delete":false,"product_type":"c1","uid":1588606,"ip_address":"","ucode":"BDAEE77E973C0D","user_header":"","comment_is_top":false,"comment_ctime":1565367874,"is_pvip":false,"replies":[{"id":"45078","content":"1. 要确定是不是bug，目前这个topic占用磁盘空间过多的问题社区有几个bug，最好去搜搜看。另外用jstack查一下log cleaner线程的状态。最后调优的话就是适当增加log.cleaner.threads的值，前提是你的log cleaner线程是正常工作的<br>2. 手动清理可能会造成部分consumer group的位移提交数据丢失","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1565571901,"ip_address":"","comment_id":122437,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1565367874","product_id":100029201,"comment_content":"胡老师，你好，有两个问题请教一下？<br>1、我们生产环境有个__counsumer_offsets-49目录经常会变的很大，把磁盘撑满，要设置什么参数优化一下啊？<br>2、手工清理__counsumer_offsets-49目录下的文件有什么影响吗？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":462251,"discussion_content":"1. 要确定是不是bug，目前这个topic占用磁盘空间过多的问题社区有几个bug，最好去搜搜看。另外用jstack查一下log cleaner线程的状态。最后调优的话就是适当增加log.cleaner.threads的值，前提是你的log cleaner线程是正常工作的\n2. 手动清理可能会造成部分consumer group的位移提交数据丢失","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1565571901,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":119071,"user_name":"不能扮演天使","can_delete":false,"product_type":"c1","uid":1046172,"ip_address":"","ucode":"9922330BFF7FFB","user_header":"https://static001.geekbang.org/account/avatar/00/0f/f6/9c/b457a937.jpg","comment_is_top":false,"comment_ctime":1564497951,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1564497951","product_id":100029201,"comment_content":"老师你是怎么阅读的源码，可以分享下经验么，从哪块看起呢；","like_count":0},{"had_liked":false,"id":115789,"user_name":"黄智荣","can_delete":false,"product_type":"c1","uid":1027823,"ip_address":"","ucode":"3C84C8654CCB11","user_header":"https://static001.geekbang.org/account/avatar/00/0f/ae/ef/cbb8d881.jpg","comment_is_top":false,"comment_ctime":1563733669,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1563733669","product_id":100029201,"comment_content":"batch.size和linger.ms  这两个参数也重要","like_count":0},{"had_liked":false,"id":111390,"user_name":"外星人","can_delete":false,"product_type":"c1","uid":1132861,"ip_address":"","ucode":"D8469B13F2AB37","user_header":"https://static001.geekbang.org/account/avatar/00/11/49/3d/4ac37cc2.jpg","comment_is_top":false,"comment_ctime":1562550654,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1562550654","product_id":100029201,"comment_content":"内存没有用满，free看了，cache和buff占了100g+","like_count":0},{"had_liked":false,"id":111035,"user_name":"外星人","can_delete":false,"product_type":"c1","uid":1132861,"ip_address":"","ucode":"D8469B13F2AB37","user_header":"https://static001.geekbang.org/account/avatar/00/11/49/3d/4ac37cc2.jpg","comment_is_top":false,"comment_ctime":1562426973,"is_pvip":false,"replies":[{"id":"40505","content":"内存用满了吗？","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1562546568,"ip_address":"","comment_id":111035,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1562426973","product_id":100029201,"comment_content":"老师，你好，关于swap有点疑问，我们生产上有128g内存，swsppiness设置为1了，但是，过段时间发现，swap使用了10g+，最后不得不关闭了swap，请问下这是什么原因啊？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":457189,"discussion_content":"内存用满了吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562546568,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1000347,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/43/9b/50927dfc.jpg","nickname":"小飞","note":"","ucode":"4C126548FBA94C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":1911,"discussion_content":"kafka强烈联系关闭swap.   swap 会使用&#34;作为&#34; 内存使用，当磁盘本身比较繁忙时，非常容易完成 io util 飙升，造成 load 飙升 (cpu iowait 高导致)。 最终会影响集群的性能。 \n生产端发送性能会明显下降。集群吞吐下降。\n PS.   现在基本的云服务厂商都是关闭swap的，不限于Kafka. ","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563091621,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":109002,"user_name":"yswang","can_delete":false,"product_type":"c1","uid":1023688,"ip_address":"","ucode":"B9CB98838B215C","user_header":"https://static001.geekbang.org/account/avatar/00/0f/9e/c8/d261f700.jpg","comment_is_top":false,"comment_ctime":1561945869,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1561945869","product_id":100029201,"comment_content":"老师您好，Kafka 下的 topic 有没有数量限制？公司一个使用Kafka的团队说，他们查询网络资料了解到 Kafka topic 超过 64 个时，会影响读写性能。<br><br>请问老师，这是真的吗？","like_count":0,"discussions":[{"author":{"id":1000347,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/43/9b/50927dfc.jpg","nickname":"小飞","note":"","ucode":"4C126548FBA94C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":1913,"discussion_content":"看集群规模，和partition 总数。\n\n规模一定后，partition 总数多到一个范围后，就等同于随机读写了 （log 文件数非常多)。这样就不能充分利用kafka 顺序读写的好吞吐特性了。\nhdd磁盘随机读写的性能，是非常差的，iops只能到 200以下。\n具体的范围值，可以google下，有附带压测结果，有个文章讲的很清楚。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563091996,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":107566,"user_name":"有钱的包子","can_delete":false,"product_type":"c1","uid":1566228,"ip_address":"","ucode":"0C19EC301A47BC","user_header":"https://static001.geekbang.org/account/avatar/00/17/e6/14/c3b18082.jpg","comment_is_top":false,"comment_ctime":1561557893,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1561557893","product_id":100029201,"comment_content":"G1 收集器的开启码","like_count":0},{"had_liked":false,"id":107262,"user_name":"阿丽","can_delete":false,"product_type":"c1","uid":1170970,"ip_address":"","ucode":"C01D32E7165302","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erJFlHhylrbLANtehiaX50wgVa2Z1ibQAdLpgyW4gCpEyOKEI9bPNZZBiabrP2oCleZWc2KKyKADz8tg/132","comment_is_top":false,"comment_ctime":1561509634,"is_pvip":false,"replies":[{"id":"38818","content":"目前没有Kafka + OpenJDK的案例分享。不过大致应该是类似的吧。 ","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561513900,"ip_address":"","comment_id":107262,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1561509634","product_id":100029201,"comment_content":"老师，之前有消息jdk闭源，有可能要使用openjdk，这个版本问题有相关配置吗？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":455443,"discussion_content":"目前没有Kafka + OpenJDK的案例分享。不过大致应该是类似的吧。 ","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561513900,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":105967,"user_name":"文古","can_delete":false,"product_type":"c1","uid":1313934,"ip_address":"","ucode":"9A3991AA033EB4","user_header":"https://static001.geekbang.org/account/avatar/00/14/0c/8e/8a39ee55.jpg","comment_is_top":false,"comment_ctime":1561116649,"is_pvip":true,"replies":[{"id":"38472","content":"有相应的报错信息吗？","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561337256,"ip_address":"","comment_id":105967,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1561116649","product_id":100029201,"comment_content":"老师，您好！外网连接线上服务器集群的参数配置是advertised.listeners配置为外网IP吗?如果这个配置为外网的话，集群启动不起来。","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454893,"discussion_content":"有相应的报错信息吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561337256,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":105588,"user_name":"Alpha","can_delete":false,"product_type":"c1","uid":1001861,"ip_address":"","ucode":"60CA15A25EC796","user_header":"https://static001.geekbang.org/account/avatar/00/0f/49/85/3f161d95.jpg","comment_is_top":false,"comment_ctime":1561036351,"is_pvip":false,"replies":[{"id":"38267","content":"似乎没看到什么问题，能否详细说说？","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561081902,"ip_address":"","comment_id":105588,"utype":1}],"discussion_count":3,"race_medal":0,"score":"1561036351","product_id":100029201,"comment_content":"老师，kafka-topics.sh那条命令格式好像错乱了，空格都不见了","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454731,"discussion_content":"似乎没看到什么问题，能否详细说说？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561081902,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1034204,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/c7/dc/9408c8c2.jpg","nickname":"ban","note":"","ucode":"E523CE97E48266","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":171,"discussion_content":"确实看的时候没有空格隔开，可以多打几个空格试下","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561217532,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1564943,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJUJKviaecwxpAZCAnHWap86kXUichv5JwUoAtrUNy4ugC0kMMmssFDdyayKFgAoA9Z62sqMZaibbvUg/132","nickname":"Geek_edc612","note":"","ucode":"3E01DE3CE4BF3E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":75,"discussion_content":"bin/kafka-topics.sh--bootstrap-serverlocalhost:9092--create--topictransaction--partitions1--replication-factor1--configretention.ms=15552000000--configmax.message.bytes=5242880\n\n这是粘贴出来的，子命令之间没有空格了:)","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561083734,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":105455,"user_name":"Xiao","can_delete":false,"product_type":"c1","uid":1179212,"ip_address":"","ucode":"71FFCCEEDE09E1","user_header":"https://static001.geekbang.org/account/avatar/00/11/fe/4c/46eb517a.jpg","comment_is_top":false,"comment_ctime":1561003728,"is_pvip":true,"replies":[{"id":"38199","content":"嗯嗯，是的：0","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561021034,"ip_address":"","comment_id":105455,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1561003728","product_id":100029201,"comment_content":"全局参数应用于所有的topic，但是topic只应用于当前topic","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454692,"discussion_content":"嗯嗯，是的：0","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561021034,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":105426,"user_name":"燃烧的M豆","can_delete":false,"product_type":"c1","uid":1355000,"ip_address":"","ucode":"BEDA9FC8852F5D","user_header":"https://static001.geekbang.org/account/avatar/00/14/ac/f8/a56b7475.jpg","comment_is_top":false,"comment_ctime":1560996864,"is_pvip":false,"replies":[{"id":"38194","content":"嗯嗯，我只是给出了我认为重要的配置，可能和你想的有出入。有问题的话可以在这里提出来，我们一起讨论：）","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561020779,"ip_address":"","comment_id":105426,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1560996864","product_id":100029201,"comment_content":"在最最最最重要配置的两节。。我居然没看到 topic 冗余部分的参数设置。。。","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454680,"discussion_content":"嗯嗯，我只是给出了我认为重要的配置，可能和你想的有出入。有问题的话可以在这里提出来，我们一起讨论：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561020779,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":105422,"user_name":"诗泽","can_delete":false,"product_type":"c1","uid":1031865,"ip_address":"","ucode":"F28BE01C3FD12F","user_header":"https://static001.geekbang.org/account/avatar/00/0f/be/b9/f2481c2c.jpg","comment_is_top":false,"comment_ctime":1560996599,"is_pvip":false,"replies":[{"id":"38192","content":"后面谈到Kafka调优的时候会讨论下：0","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561020687,"ip_address":"","comment_id":105422,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1560996599","product_id":100029201,"comment_content":"另外就是如何设置合理的分区partition 数量也是比较重要的吧，当然这个不是一个参数能搞定，需要多个参数一起配合。在这个问题上老师有什么建议吗？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454678,"discussion_content":"后面谈到Kafka调优的时候会讨论下：0","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561020687,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":105420,"user_name":"诗泽","can_delete":false,"product_type":"c1","uid":1031865,"ip_address":"","ucode":"F28BE01C3FD12F","user_header":"https://static001.geekbang.org/account/avatar/00/0f/be/b9/f2481c2c.jpg","comment_is_top":false,"comment_ctime":1560995953,"is_pvip":false,"replies":[{"id":"38191","content":"不太好评估。建议还是先按照实际业务需求实现功能目标，然后再优化。毕竟先把事情做对，然后再最好。不用过早为了性能就放弃很多朴素的实现方法：）","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1561020654,"ip_address":"","comment_id":105420,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1560995953","product_id":100029201,"comment_content":"所以一般kafka 消息的大小超过多大就会明显影响性能？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454677,"discussion_content":"不太好评估。建议还是先按照实际业务需求实现功能目标，然后再优化。毕竟先把事情做对，然后再最好。不用过早为了性能就放弃很多朴素的实现方法：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561020654,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1000347,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/43/9b/50927dfc.jpg","nickname":"小飞","note":"","ucode":"4C126548FBA94C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":1914,"discussion_content":"默认server 接受的单条消息最大1MB. 再大,server会拒绝接受。需要重新设置了。\n\n基本可以满足大部分的业务需要了&#39;","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563092344,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}