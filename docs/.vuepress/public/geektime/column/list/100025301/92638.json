{"id":92638,"title":"06 | 如何区分批处理还是流处理？","content":"<p>你好，我是蔡元楠。</p><p>今天，我将会带领你一起学习在进行大规模数据处理时，无论如何也绕不开的两个处理模式：批处理（Batching Processing）和流处理（Streaming Processing）。</p><p>在我看来，大规模的视频流系统、大规模物联网（IoT）数据监控系统等各种现代大规模数据系统的出现，已经成为了一种必然的历史潮流。</p><p>无论你是在从事哪一种开发方向，都不可避免地要与这些海量数据打交道。如何能既满足实际应用场景的需求，又高效地处理好大规模数据，在整个项目开发架构中都是非常重要的一个环节。</p><p>在开始讲解批处理和流处理之前，我想先介绍一下几个必要的背景知识。</p><h3>无边界数据和有边界数据</h3><p>这个世界上的数据可以抽象成为两种，分别是无边界数据（Unbounded Data）和有边界数据（Bounded Data）。</p><p>顾名思义，<strong>无边界数据</strong>是一种不断增长，可以说是无限的数据集。</p><p>这种类型的数据，我们无法判定它们到底什么时候会停止发送。</p><p>例如，从手机或者从传感器发送出来的信号数据，又比如我们所熟知的移动支付领域中的交易数据。因为每时每刻都会有交易产生，所以我们不能判定在某一刻这类数据就会停止发送了。</p><p><img src=\"https://static001.geekbang.org/resource/image/92/f4/923137d938e2f11b52a69d8446df81f4.jpg?wh=1920*1920\" alt=\"\"></p><p>在国外的一些技术文章上，有时候我们会看到“流数据（Streaming Data）”这一说法，其实它和无边界数据表达的是同一个概念。</p><!-- [[[read_end]]] --><p>与此相反，<strong>有边界数据</strong>是一种有限的数据集。</p><p>这种数据更常见于已经保存好了的数据中。例如，数据库中的数据，或者是我们常见的CSV格式文件中的数据。</p><p>当然了，你可能会问，那我们把无边界数据按照时间窗口提取一小份出来，那这样的数据是什么数据呢？</p><p>拿我们之前提到过的移动支付中的交易数据来说吧。移动支付中的交易数据可以看作是无边界数据。那我们按2019年4月29日这个时间窗口提取出来的数据呢？这个当日的交易数据就变成了有边界数据了。</p><p>所以，有边界数据其实可以看作是无边界数据的一个子集。</p><h3>事件时间和处理时间</h3><p>在处理大规模数据的时候，我们通常还会关心<strong>时域</strong>（Time Domain）的问题。</p><p>我们要处理的任意数据都会有两种时域，分别是事件时间（Event Time）和处理时间（Precessing Time）。</p><p><strong>事件时间</strong>指的是一个数据实际产生的时间点，而<strong>处理时间</strong>指的是处理数据的系统架构实际接收到这个数据的时间点。</p><p>下面我来用一个实际的例子进一步说明这两个时间概念。</p><p>现在假设，你正在去往地下停车场的路上，并且打算用手机点一份外卖。选好了外卖后，你就用在线支付功能付款了，这个时候是12点05分。恰好这时，你走进了地下停车库，而这里并没有手机信号。因此外卖的在线支付并没有立刻成功，而支付系统一直在重试（Retry）“支付”这个操作。</p><p>当你找到自己的车并且开出地下停车场的时候，已经是12点15分了。这个时候手机重新有了信号，手机上的支付数据成功发到了外卖在线支付系统，支付完成。</p><p>在上面这个场景中你可以看到，支付数据的事件时间是12点05分，而支付数据的处理时间是12点15分。事件时间和处理时间的概念，你明白了吗？</p><p>在了解完上面的4个基本概念后，我将开始为你揭开批处理和流处理模式的面纱。</p><h3>批处理</h3><p>数据的批处理，可以理解为一系列相关联的任务按顺序（或并行）一个接一个地执行。批处理的输入是在一段时间内已经收集保存好的数据。每次批处理所产生的输出也可以作为下一次批处理的输入。</p><p>绝大部分情况下，批处理的输入数据都是<strong>有边界数据</strong>，同样的，输出结果也一样是<strong>有边界数据</strong>。所以在批处理中，我们所关心的更多会是数据的<strong>事件时间</strong>。</p><p>举个例子，你在每年年初所看到的“支付宝年账单”就是一个数据批处理的典型例子。</p><p><img src=\"https://static001.geekbang.org/resource/image/de/03/deb1cc0e27841807e28e8202a055d503.jpg?wh=1125*852\" alt=\"\"></p><p>支付宝会将我们在过去一年中的消费数据存储起来，并作为批处理输入，提取出过去一年中产生交易的事件时间，然后经过一系列业务逻辑处理，得到各种有趣的信息作为输出。</p><p>在许多情况下，批处理任务会被安排，并以预先定义好的时间间隔来运行，例如一天，一个月或者是一年这样的特定时间。</p><p>在银行系统中，银行信用卡消费账单和最低还款额度也都是由批处理系统以预先定义好的一个月的时间间隔运行，所产生出来的。</p><p>批处理架构通常会被设计在以下这些应用场景中：</p><ul>\n<li>\n<p>日志分析：日志系统是在一定时间段（日，周或年）内收集的，而日志的数据处理分析是在不同的时间内执行，以得出有关系统的一些关键性能指标。</p>\n</li>\n<li>\n<p>计费应用程序：计费应用程序会计算出一段时间内一项服务的使用程度，并生成计费信息，例如银行在每个月末生成的信用卡还款单。</p>\n</li>\n<li>\n<p>数据仓库：数据仓库的主要目标是根据收集好的数据事件时间，将数据信息合并为静态快照 （static snapshot），并将它们聚合为每周、每月、每季度的报告等。</p>\n</li>\n</ul><p>由Google MapReduce衍生出来的开源项目Apache Hadoop或者是Apache Spark等开源架构都是支持这种大数据批处理架构的。</p><p>由于完成批处理任务具有高延迟性，一般可以需要花费几小时，几天甚至是几周的时间。要是在开发业务中有快速响应用户的时间需求，我们则需要考虑使用流处理/实时处理来处理大数据。</p><h3>流处理</h3><p>数据的流处理可以理解为系统需要接收并处理一系列连续不断变化的数据。例如，旅行预订系统，处理社交媒体更新信息的有关系统等等。</p><p>流处理的输入数据基本上都是<strong>无边界数据</strong>。而流处理系统中是关心数据的事件时间还是处理时间，将视具体的应用场景而定。</p><p>例如，像网页监控系统这样的流处理系统要计算网站的QPS，它所关心的更多是<strong>处理时间</strong>，也就是网页请求数据被监控系统接收到的时间，从而计算QPS。</p><p>而在一些医疗护理监控系统的流处理系统中，他们则更关心数据的<strong>事件时间</strong>，这种系统不会因为接收到的数据有网络延时，而忽略数据本来产生的时间。</p><p>流处理的特点应该是要足够快、低延时，以便能够处理来自各种数据源的大规模数据。流处理所需的响应时间更应该以毫秒（或微秒）来进行计算。像我们平时用到的搜索引擎，系统必须在用户输入关键字后以毫秒级的延时返回搜索结果给用户。</p><p>流处理速度如此之快的根本原因是因为它在数据到达磁盘之前就对其进行了分析。</p><p>当流处理架构拥有在一定时间间隔（毫秒）内产生逻辑上正确的结果时，这种架构可以被定义为<strong>实时处理</strong>（Real-time Processing）。</p><p>而如果一个系统架构可以接受以分钟为单位的数据处理时间延时，我们也可以把它定义为<strong>准实时处理</strong>（Near real-time Processing）。</p><p>还记得我们在介绍批处理架构中所说到的不足吗？没错，是高延迟。而流处理架构则恰恰拥有高吞度量和低延迟等特点。</p><p>流处理架构通常都会被设计在以下这些应用场景中：</p><ul>\n<li>实时监控：捕获和分析各种来源发布的数据，如传感器，新闻源，点击网页等。</li>\n<li>实时商业智能：智能汽车，智能家居，智能病人护理等。</li>\n<li>销售终端（POS）系统：像是股票价格的更新，允许用户实时完成付款的系统等。</li>\n</ul><p>在如今的开源架构生态圈中，如Apache Kafka、Apache Flink、Apache Storm、Apache Samza等，都是流行的流处理架构平台。</p><p>在介绍完这两种处理模式后，你会发现，无论是批处理模式还是流处理模式，在现实生活中都有着很广泛的应用。你应该根据自己所面临的实际场景来决定到底采用哪种数据处理模式。</p><h2>小结</h2><p>批处理模式在不需要实时分析结果的情况下是一种很好的选择。尤其当业务逻辑需要处理大量的数据以挖掘更为深层次数据信息的时候。</p><p>而在应用需求需要对数据进行实时分析处理时，或者说当有些数据是永无止境的事件流时（例如传感器发送回来的数据时），我们就可以选择用流处理模式。</p><h2>思考题</h2><p>相信在学习完这一讲后，你会对批处理模式和流处理模式有着清晰的认识。今天的思考题是，在你的日常开发中，所面临的数据处理模式又是哪一种模式呢？</p><p>欢迎你把答案写在留言区，与我和其他同学一起讨论。如果你觉得有所收获，也欢迎把文章分享给你的朋友。</p><p></p>","neighbors":{"left":{"article_title":"05 | 分布式系统（下）：架构师不得不知的三大指标","id":91647},"right":{"article_title":"07 | Workflow设计模式：让你在大规模数据世界中君临天下","id":92928}},"comments":[{"had_liked":false,"id":90393,"user_name":"孙稚昊","can_delete":false,"product_type":"c1","uid":1010660,"ip_address":"","ucode":"44283BA4A577B6","user_header":"https://static001.geekbang.org/account/avatar/00/0f/6b/e4/afacba1c.jpg","comment_is_top":false,"comment_ctime":1556508137,"is_pvip":false,"replies":[{"id":"32544","content":"谢谢你的分享！","user_name":"作者回复","comment_id":90393,"uid":"1503187","ip_address":"","utype":1,"ctime":1556654140,"user_name_real":"Geek_88e0d7"}],"discussion_count":1,"race_medal":0,"score":"57391082985","product_id":100025301,"comment_content":"我们的用户画像本质还是批处理，还不能做到实时更新每个人的 profile，但对用户的每次电机有一个实时的劣化推荐版本，就是根据session中点的几个item的click，找到它们的simiiar item，这个是通过cache 和API实现的，并不是实时数据处理","like_count":13,"discussions":[{"author":{"id":1503187,"avatar":"","nickname":"Geek_88e0d7","note":"","ucode":"3E2596F3EB9165","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":448504,"discussion_content":"谢谢你的分享！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1556654140,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":1}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":90730,"user_name":"hua168","can_delete":false,"product_type":"c1","uid":1065255,"ip_address":"","ucode":"CFF9A7E86EBA48","user_header":"https://static001.geekbang.org/account/avatar/00/10/41/27/3ff1a1d6.jpg","comment_is_top":false,"comment_ctime":1556618146,"is_pvip":false,"replies":[{"id":"32991","content":"谢谢你的提问！数据如果没有保存到磁盘的话，确实整个软件挂了所有数据就丢失了。不过流处理一样可以处理重要数据的。一般即使数据存在内存中，有的软件会定时将数据的snapshot保存到磁盘中，以防软件全部挂掉。而很多软件都会有data replica，而且会有N+1或者N+2的policy，以此来保证如果有其中一台机器上的软件挂了，另外一台机器可以顶替它。<br><br>一般全部机器都挂的情况非常少见，这就如同存在磁盘上的数据被人运行“rm -fR &#47;”一样，所以在采用流处理的时候不必过于担心。","user_name":"作者回复","comment_id":90730,"uid":"1503187","ip_address":"","utype":1,"ctime":1557217286,"user_name_real":"Geek_88e0d7"}],"discussion_count":1,"race_medal":0,"score":"40211323810","product_id":100025301,"comment_content":"老师，上面说流数据是在没到达磁盘之前就处理了，所以速度很快，但是如果那处软件挂了，那部分流数据不是丢失了吗？是不是不能处理重要的数据？<br>    如果我的数据很重要，但是又想像流那样处理的快速怎办？像redis那样，使用持久化，边处理写延迟写及磁盘这种处理思想吗？还是其它？","like_count":9,"discussions":[{"author":{"id":1503187,"avatar":"","nickname":"Geek_88e0d7","note":"","ucode":"3E2596F3EB9165","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":448631,"discussion_content":"谢谢你的提问！数据如果没有保存到磁盘的话，确实整个软件挂了所有数据就丢失了。不过流处理一样可以处理重要数据的。一般即使数据存在内存中，有的软件会定时将数据的snapshot保存到磁盘中，以防软件全部挂掉。而很多软件都会有data replica，而且会有N+1或者N+2的policy，以此来保证如果有其中一台机器上的软件挂了，另外一台机器可以顶替它。\n\n一般全部机器都挂的情况非常少见，这就如同存在磁盘上的数据被人运行“rm -fR /”一样，所以在采用流处理的时候不必过于担心。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1557217286,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":1}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":90599,"user_name":"xzy","can_delete":false,"product_type":"c1","uid":1082132,"ip_address":"","ucode":"483350A630625E","user_header":"https://static001.geekbang.org/account/avatar/00/10/83/14/099742ae.jpg","comment_is_top":false,"comment_ctime":1556586207,"is_pvip":false,"replies":[{"id":"32540","content":"谢谢你的分享！","user_name":"作者回复","comment_id":90599,"uid":"1503187","ip_address":"","utype":1,"ctime":1556653885,"user_name_real":"Geek_88e0d7"}],"discussion_count":3,"race_medal":0,"score":"40211291871","product_id":100025301,"comment_content":"既有批处理也有流处理，生产环境利用elasticsearch来存储监控数据、日志数据等。为了降低成本和查询速度，会按照小时、天粒度对历史数据做预聚合，这应该属于批处理。其次，es作为搜索引擎，用户也有实时查询的需求，这块应该属于流处理。 谢谢","like_count":9,"discussions":[{"author":{"id":1503187,"avatar":"","nickname":"Geek_88e0d7","note":"","ucode":"3E2596F3EB9165","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":448588,"discussion_content":"谢谢你的分享！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1556653885,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":1}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1055034,"avatar":"https://static001.geekbang.org/account/avatar/00/10/19/3a/c1dbffb7.jpg","nickname":"amixyue","note":"","ucode":"97822C9E1F6A72","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":313250,"discussion_content":"es是存算一体的AP系统，面向分析，提前做（实时的）数据预处理。还不能说是流数据处理平台。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1603012597,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1897610,"avatar":"","nickname":"Fiery","note":"","ucode":"CDB000687A6B14","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":200250,"discussion_content":"其实应该说ElasticSearch也是很好的一种实时流处理平台，因为它可以实时导入数据而且对导入的事件提供分钟级延迟的搜索式查询，这种Near Realtime查询依赖于基于LSTM风格的Solr索引。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1583672274,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":90410,"user_name":"mini希","can_delete":false,"product_type":"c1","uid":1043539,"ip_address":"","ucode":"54DFFE0CE0C7EF","user_header":"https://static001.geekbang.org/account/avatar/00/0f/ec/53/dcec6fdc.jpg","comment_is_top":false,"comment_ctime":1556513438,"is_pvip":true,"discussion_count":1,"race_medal":0,"score":"31621284510","product_id":100025301,"comment_content":"数仓有没有准实时的解决方案呢？","like_count":7,"discussions":[{"author":{"id":1261957,"avatar":"https://static001.geekbang.org/account/avatar/00/13/41/85/4cb8a579.jpg","nickname":"Peng","note":"","ucode":"8896E7DB280D50","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":206839,"discussion_content":"spark streaming","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1584449463,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":90384,"user_name":"yangs","can_delete":false,"product_type":"c1","uid":1294897,"ip_address":"","ucode":"25D11BE2505953","user_header":"https://static001.geekbang.org/account/avatar/00/13/c2/31/d381fbd6.jpg","comment_is_top":false,"comment_ctime":1556505262,"is_pvip":false,"replies":[{"id":"33040","content":"可以","user_name":"作者回复","comment_id":90384,"uid":"1257426","ip_address":"","utype":1,"ctime":1557266895,"user_name_real":"Yuannan蔡元楠"}],"discussion_count":3,"race_medal":0,"score":"31621276334","product_id":100025301,"comment_content":"老师您好，之前看到网上说flink实现的流处理和spark streaming不一样，是因为spark使用了微批处理模拟流处理，可是我觉得flink实现的原理也像是用批处理模拟流处理，将一段一段数据包裹在时间窗口里来实现，这个时间窗口的数据处理，可不可以也理解成为是批处理？","like_count":8,"discussions":[{"author":{"id":1257426,"avatar":"https://static001.geekbang.org/account/avatar/00/13/2f/d2/0b6a8945.jpg","nickname":"Yuannan蔡元楠","note":"","ucode":"695E183CE496A8","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":448500,"discussion_content":"可以","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1557266895,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1055034,"avatar":"https://static001.geekbang.org/account/avatar/00/10/19/3a/c1dbffb7.jpg","nickname":"amixyue","note":"","ucode":"97822C9E1F6A72","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":313251,"discussion_content":"《streaming system》有用光的波粒二象性，来解读流批一体的引擎实现。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1603012691,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1131326,"avatar":"https://static001.geekbang.org/account/avatar/00/11/43/3e/2724d823.jpg","nickname":"lostsky","note":"","ucode":"FD65474995FFD3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":276073,"discussion_content":"可以理解为无数离散组成连续吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1590810966,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":90426,"user_name":"邱从贤※klion26","can_delete":false,"product_type":"c1","uid":1027239,"ip_address":"","ucode":"36DF21F2B9E94C","user_header":"https://static001.geekbang.org/account/avatar/00/0f/ac/a7/4d41966a.jpg","comment_is_top":false,"comment_ctime":1556517055,"is_pvip":false,"replies":[{"id":"32997","content":"谢谢你的留言！我很认同你的观点，关于流处理和批处理未来应该会统一起来。数据库作为存储系统的话还是会单独存在的吧。","user_name":"作者回复","comment_id":90426,"uid":"1503187","ip_address":"","utype":1,"ctime":1557218159,"user_name_real":"Geek_88e0d7"}],"discussion_count":3,"race_medal":0,"score":"18736386239","product_id":100025301,"comment_content":"有限流是无限流的一个特例，所以一直在想是不是未来不再需要批处理，所有的都可以流处理，从而达到真正的流批一体。<br><br>从现在的情况看，批处理主要用于分析，用 sql 较多，且会对多个表进行处理，是不是意味着流上的 sql 也是刚需。<br><br>线下批处理能够不停重算的特性，应该可以让流处理不停做 checkpoint 来支持，这样是不是就和 db 的 backup 就有点像了，那是不是最后流处理，批处理，数据库也会统一起来呢？","like_count":4,"discussions":[{"author":{"id":1503187,"avatar":"","nickname":"Geek_88e0d7","note":"","ucode":"3E2596F3EB9165","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":448520,"discussion_content":"谢谢你的留言！我很认同你的观点，关于流处理和批处理未来应该会统一起来。数据库作为存储系统的话还是会单独存在的吧。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1557218159,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":1}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1055034,"avatar":"https://static001.geekbang.org/account/avatar/00/10/19/3a/c1dbffb7.jpg","nickname":"amixyue","note":"","ucode":"97822C9E1F6A72","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":313253,"discussion_content":"但streaming architecture本身，基于流的理念，是可以持续探索的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1603012877,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1055034,"avatar":"https://static001.geekbang.org/account/avatar/00/10/19/3a/c1dbffb7.jpg","nickname":"amixyue","note":"","ucode":"97822C9E1F6A72","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":313252,"discussion_content":"DB本身对TP（修改事务）吞吐的强要求，还做不到。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1603012785,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":185728,"user_name":"Fiery","can_delete":false,"product_type":"c1","uid":1897610,"ip_address":"","ucode":"CDB000687A6B14","user_header":"","comment_is_top":false,"comment_ctime":1583671874,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"14468573762","product_id":100025301,"comment_content":"&quot;流处理架构则恰恰拥有高吞度（吐）量和低延迟等特点&quot;，关于这一句有点疑惑请老师解答，我之前一直把Throughput和Latency当做互斥的一组指标，一般来讲高吞吐的系统都会选择牺牲响应速率（即低延迟），而如果专注提供低延迟响应，那一般吞吐量都到达不了系统的peak capacity。比如同样的一组集群，同样的数据量，如果不考虑其它影响处理效率的问题，那么集群进行批处理作业时的吞吐量应该是一定会超过做流处理作业时的吞吐量的，不是吗？所以我觉得这句话难道不应该是“流处理更专注于低延迟的数据处理，而批处理更专注于高吞吐的数据处理”吗？","like_count":3},{"had_liked":false,"id":90311,"user_name":"涵","can_delete":false,"product_type":"c1","uid":1502742,"ip_address":"","ucode":"BB8575DB13F1E0","user_header":"https://static001.geekbang.org/account/avatar/00/16/ee/16/742956ac.jpg","comment_is_top":false,"comment_ctime":1556489905,"is_pvip":false,"replies":[{"id":"33005","content":"谢谢你的经验分享！赞一个！","user_name":"作者回复","comment_id":90311,"uid":"1503187","ip_address":"","utype":1,"ctime":1557219808,"user_name_real":"Geek_88e0d7"}],"discussion_count":1,"race_medal":0,"score":"14441391793","product_id":100025301,"comment_content":"在实际工作中数据仓库的数据处理使用的是批处理，根据需要大多数据是日处理，个别数据是一天处理几次，但都是批处理。在做核心业务系统时使用的是流数据处理，通常用消息中间件来传递事件，接收到事件时即开始处理。一直想尝试的是通过日志信息抽取业务信息，实现对业务信息的实时分析，例如当日的实时交易笔数，交易额等，无需侵入核心业务系统，通过日志即可以流数据的形式实时传递给数据平台。了解过splunk,elasticsearch都可以做，但是不清楚哪个更好，或者有其他更好的选择。","like_count":3,"discussions":[{"author":{"id":1503187,"avatar":"","nickname":"Geek_88e0d7","note":"","ucode":"3E2596F3EB9165","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":448466,"discussion_content":"谢谢你的经验分享！赞一个！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1557219808,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":1}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":90341,"user_name":"JohnT3e","can_delete":false,"product_type":"c1","uid":1063982,"ip_address":"","ucode":"CF4AAAC933529C","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLdWHFCr66TzHS2CpCkiaRaDIk3tU5sKPry16Q7ic0mZZdy8LOCYc38wOmyv5RZico7icBVeaPX8X2jcw/132","comment_is_top":false,"comment_ctime":1556497902,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10146432494","product_id":100025301,"comment_content":"一般业务中都会涉及到实时处理和批处理的需求，现在采取的类似于Kappa的架构。<br><br>Kappa Architecture: http:&#47;&#47;milinda.pathirage.org&#47;kappa-architecture.com&#47;<br>Samba Architecture: http:&#47;&#47;lambda-architecture.net&#47; ","like_count":2},{"had_liked":false,"id":111802,"user_name":"柳年思水","can_delete":false,"product_type":"c1","uid":1106802,"ip_address":"","ucode":"65589C121B904A","user_header":"https://static001.geekbang.org/account/avatar/00/10/e3/72/afd1eef0.jpg","comment_is_top":false,"comment_ctime":1562602757,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5857570053","product_id":100025301,"comment_content":"我个人也是比较赞同 DataFlow 模型的思想的，认为批是流的一个特例，未来的计算不会再明显区分到底是流还是批，但不能排除除一些特殊情况（毕竟当前的批计算引擎针对批的场景做了大量的优化，通用系统的性能肯定是赶不上专用系统的），但计算不仅仅是批和流两种形态，还有复杂计算场景，比如现在的 TensorFlow（AI 框架的本质也是计算）、RAY 等，计算引擎最后会不会完全融合到一起呢？或者换个思路，一个引擎可以兼容所有的引擎（有点类似 Beam），在一个计算框架里，可以跑多个 runner（这个 runner 可以是不同的引擎），未来会不会是这样的呢？","like_count":1},{"had_liked":false,"id":95808,"user_name":"小凡","can_delete":false,"product_type":"c1","uid":1007802,"ip_address":"","ucode":"4B35A8B81A575B","user_header":"https://static001.geekbang.org/account/avatar/00/0f/60/ba/3717bab6.jpg","comment_is_top":false,"comment_ctime":1558184152,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"5853151448","product_id":100025301,"comment_content":"请问spring-batch和hadoop这类批处理框架有什么不同吗？还有spring data flow","like_count":1,"discussions":[{"author":{"id":1055034,"avatar":"https://static001.geekbang.org/account/avatar/00/10/19/3a/c1dbffb7.jpg","nickname":"amixyue","note":"","ucode":"97822C9E1F6A72","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":313254,"discussion_content":"从扩展性、可靠性、一致性的角度，你可以再论证下。spring batch/dataflow只是更贴近spring生态。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1603012982,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":93131,"user_name":"slowforce","can_delete":false,"product_type":"c1","uid":1507235,"ip_address":"","ucode":"5A50DB726F00EC","user_header":"","comment_is_top":false,"comment_ctime":1557404343,"is_pvip":false,"replies":[{"id":"33225","content":"谢谢你的分享！","user_name":"作者回复","comment_id":93131,"uid":"1503187","ip_address":"","utype":1,"ctime":1557428528,"user_name_real":"Geek_88e0d7"}],"discussion_count":1,"race_medal":0,"score":"5852371639","product_id":100025301,"comment_content":"我们接收现场设备发回来的数据，数据以email或者sftp的形式上传 或者以自定义的格式通过socket直接传。对于前一种情况，我们采取批处理的方式 定时去处理，而对于第二种情况 我认为就是流处理","like_count":1,"discussions":[{"author":{"id":1503187,"avatar":"","nickname":"Geek_88e0d7","note":"","ucode":"3E2596F3EB9165","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":449500,"discussion_content":"谢谢你的分享！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1557428528,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":1}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":92087,"user_name":"越甲非甲","can_delete":false,"product_type":"c1","uid":1502575,"ip_address":"","ucode":"A5C4BD977A02F1","user_header":"https://static001.geekbang.org/account/avatar/00/16/ed/6f/352eb4d4.jpg","comment_is_top":false,"comment_ctime":1557187620,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5852154916","product_id":100025301,"comment_content":"目前我们做的流处理场景下的解决方案，都是控制较小时间窗口的批处理，通过累加类似的方案来实现近似流处理的效果。请问老师，流处理的更一般性的解决思路是什么样子的呢？是这种微批处理的路子吗？谢谢老师！","like_count":1},{"had_liked":false,"id":91192,"user_name":"CoderLean","can_delete":false,"product_type":"c1","uid":1518409,"ip_address":"","ucode":"DC9E25428EDB3F","user_header":"https://static001.geekbang.org/account/avatar/00/17/2b/49/e94b2a35.jpg","comment_is_top":false,"comment_ctime":1556899574,"is_pvip":false,"replies":[{"id":"32971","content":"赞一个大牛的留言啊！","user_name":"作者回复","comment_id":91192,"uid":"1503187","ip_address":"","utype":1,"ctime":1557206886,"user_name_real":"Geek_88e0d7"}],"discussion_count":1,"race_medal":0,"score":"5851866870","product_id":100025301,"comment_content":"Flink的本质就是流处理，而里面的批处理api底层是将时间或者个数设定在某个区域里面，可以认为在这个架构中批处理是流处理的一个特例，我看有的评论说反了。说明还没好好掌握flink","like_count":1,"discussions":[{"author":{"id":1503187,"avatar":"","nickname":"Geek_88e0d7","note":"","ucode":"3E2596F3EB9165","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":448838,"discussion_content":"赞一个大牛的留言啊！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1557206886,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":1}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":90385,"user_name":"每天晒白牙","can_delete":false,"product_type":"c1","uid":1004698,"ip_address":"","ucode":"A1B102CD933DEA","user_header":"https://static001.geekbang.org/account/avatar/00/0f/54/9a/76c0af70.jpg","comment_is_top":false,"comment_ctime":1556505280,"is_pvip":false,"replies":[{"id":"32545","content":"谢谢你的分享！","user_name":"作者回复","comment_id":90385,"uid":"1503187","ip_address":"","utype":1,"ctime":1556654228,"user_name_real":"Geek_88e0d7"}],"discussion_count":1,"race_medal":0,"score":"5851472576","product_id":100025301,"comment_content":"产生特定格式和维度的报表数据一般是批处理，但实时报表是流处理，需要低延迟","like_count":1,"discussions":[{"author":{"id":1503187,"avatar":"","nickname":"Geek_88e0d7","note":"","ucode":"3E2596F3EB9165","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":448501,"discussion_content":"谢谢你的分享！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1556654228,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":1}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":90317,"user_name":"peter","can_delete":false,"product_type":"c1","uid":1058183,"ip_address":"","ucode":"261C3FC001DE2D","user_header":"https://static001.geekbang.org/account/avatar/00/10/25/87/f3a69d1b.jpg","comment_is_top":false,"comment_ctime":1556493430,"is_pvip":true,"replies":[{"id":"33004","content":"谢谢你的留言！没错，Spark也是支持流处理的。现在数据处理的Framework太多了，可能没有面面俱到描述到。","user_name":"作者回复","comment_id":90317,"uid":"1503187","ip_address":"","utype":1,"ctime":1557219758,"user_name_real":"Geek_88e0d7"}],"discussion_count":1,"race_medal":0,"score":"5851460726","product_id":100025301,"comment_content":"老师在谈流处理框架时没有说spark，难道spark不是流处理框架吗？(spark streaming也是流处理呀)","like_count":1,"discussions":[{"author":{"id":1503187,"avatar":"","nickname":"Geek_88e0d7","note":"","ucode":"3E2596F3EB9165","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":448469,"discussion_content":"谢谢你的留言！没错，Spark也是支持流处理的。现在数据处理的Framework太多了，可能没有面面俱到描述到。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1557219758,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":1}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":358830,"user_name":"杨大伟","can_delete":false,"product_type":"c1","uid":3171452,"ip_address":"江苏","ucode":"F451C9A6395300","user_header":"","comment_is_top":false,"comment_ctime":1664865923,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1664865923","product_id":100025301,"comment_content":"我做的国家电网相关的项目，在计算电费，客户支付电费订单时的数据处理使用流处理，而每个月，每个季度的电费统计，使用了批处理","like_count":0},{"had_liked":false,"id":337688,"user_name":"哇哈哈","can_delete":false,"product_type":"c1","uid":1175537,"ip_address":"","ucode":"47453D1C96A1DD","user_header":"https://static001.geekbang.org/account/avatar/00/11/ef/f1/8b06801a.jpg","comment_is_top":false,"comment_ctime":1646975342,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1646975342","product_id":100025301,"comment_content":"event time &amp; process time是流式处理的重要概念，推荐大家一本《streaming system》，虽然没有中文版，但是写的也算比较好理解了","like_count":0},{"had_liked":false,"id":313129,"user_name":"高景洋","can_delete":false,"product_type":"c1","uid":2717072,"ip_address":"","ucode":"532188513579E4","user_header":"","comment_is_top":false,"comment_ctime":1632289068,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1632289068","product_id":100025301,"comment_content":"在我们的业务中，流处理 和 批处理都有使用。<br><br>流处理<br>1、我们将数据，按特定频次调度到kafka中，比如说 2小时一次、6小时一次、1天一次...<br>2、有一个分发程序，将数据按特定频率,从kafka消费出来 （比如说，一共有120条数据，2小时要处理一次，那平均到1分钟的粒度，就是每分钟一条。实际业务中，每2小时要处理的数据量可能到2000W级）<br>3、第二步消费出来的数据，会推到redis 的一个队列中，进行后续的业务逻辑处理（为什么不用kafka，而用redis做队列组件呢？kakfa受分区数限制，而我们的业务逻辑程序，要求高并发1W+线程，kafka的分区数，限制了业务的线程数）<br>4、业务处理后的数据，又会重新推回新的 kafka,会有数据处理程序，对新的kafka 进行消费入库操作<br>5、形成闭环，这是业务中的 一个流处理的流程~<br><br>批处理<br>1、批处理我们用在了数据的汇总统计上<br>2、我们要对库中（hbase）,每天数据的新增量、更新量、各渠道的来源量做汇总统计，形成报表<br>3、我们会在每天凌晨，将hbase中的数据，导入到hive，由hive对各个维度的数据，进行汇总group by统计<br>4、统计结果入mysql，对外生成报表输出<br>5、这是一个批处理的流程","like_count":1},{"had_liked":false,"id":292291,"user_name":"Cullenx","can_delete":false,"product_type":"c1","uid":1081085,"ip_address":"","ucode":"042A1FEEB9BF95","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaELnwfIlKG3CC76QPUmDhZNFqvuK8IDrKObiawYSpibac479Gaq3LYlp6VgIqgmWCIIJlY5GBT7mjgmw/132","comment_is_top":false,"comment_ctime":1620772381,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1620772381","product_id":100025301,"comment_content":"最近在做智能电池项目，收集上报信息，典型的流处理场景，非常感谢作者的分享，有个小问题，要求实时处理，但是逻辑中设计复杂调用和多种取库信息和落库，无法保证毫秒级响应，如何解决？谢谢","like_count":0},{"had_liked":false,"id":259385,"user_name":"技术修行者","can_delete":false,"product_type":"c1","uid":1013147,"ip_address":"","ucode":"28CA41A1214D6B","user_header":"https://static001.geekbang.org/account/avatar/00/0f/75/9b/611e74ab.jpg","comment_is_top":false,"comment_ctime":1604717085,"is_pvip":true,"discussion_count":0,"race_medal":1,"score":"1604717085","product_id":100025301,"comment_content":"我目前项目中的业务数据是批处理，日志数据是流处理。","like_count":0},{"had_liked":false,"id":194483,"user_name":"不记年","can_delete":false,"product_type":"c1","uid":1045945,"ip_address":"","ucode":"287E40C68356DC","user_header":"https://static001.geekbang.org/account/avatar/00/0f/f5/b9/888fe350.jpg","comment_is_top":false,"comment_ctime":1585061838,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1585061838","product_id":100025301,"comment_content":"目前做的数仓主要还是批处理为主，如果未来涉及数据的实时同步还是会上流处理的","like_count":0},{"had_liked":false,"id":187778,"user_name":"Eden2020","can_delete":false,"product_type":"c1","uid":1899158,"ip_address":"","ucode":"0DEE62F2335237","user_header":"https://static001.geekbang.org/account/avatar/00/1c/fa/96/4a7b7505.jpg","comment_is_top":false,"comment_ctime":1584240263,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1584240263","product_id":100025301,"comment_content":"我们遇到的大部分是批处理场景，如日志分析，搜索，统计报表之类的，流处理主要是一些实时流量，实时监控需求，都是一些特定需求，批处理需求会比较易变","like_count":0},{"had_liked":false,"id":185732,"user_name":"Fiery","can_delete":false,"product_type":"c1","uid":1897610,"ip_address":"","ucode":"CDB000687A6B14","user_header":"","comment_is_top":false,"comment_ctime":1583672560,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1583672560","product_id":100025301,"comment_content":"“在如今的开源架构生态圈中，如 Apache Kafka、Apache Flink、Apache Storm、Apache Samza 等，都是流行的流处理架构平台”<br>我在想是不是应该说ElasticSearch也是很好的一种实时流处理平台，因为它可以实时导入数据而且对导入的事件提供分钟级延迟的搜索式查询，这种Near Realtime查询依赖于基于LSTM风格的改进版Solr索引。虽然不如Spark&#47;Flink这种全能式的流处理框架，但是和Kafka一样算是一种专注于为特定场景提供服务的流处理平台","like_count":0},{"had_liked":false,"id":132571,"user_name":"lipi","can_delete":false,"product_type":"c1","uid":1219442,"ip_address":"","ucode":"2BE76BD029C348","user_header":"https://static001.geekbang.org/account/avatar/00/12/9b/72/50c20592.jpg","comment_is_top":false,"comment_ctime":1568167494,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1568167494","product_id":100025301,"comment_content":"实时处理我的理解是session保持，而不是仅仅因为毫秒就是实时处理。例如，voip","like_count":0},{"had_liked":false,"id":107117,"user_name":"风中花","can_delete":false,"product_type":"c1","uid":1085237,"ip_address":"","ucode":"067E0A1E116844","user_header":"https://static001.geekbang.org/account/avatar/00/10/8f/35/f1839bb2.jpg","comment_is_top":false,"comment_ctime":1561462112,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1561462112","product_id":100025301,"comment_content":"看到老师有设专栏讲fink的想法！有点期待哦","like_count":0},{"had_liked":false,"id":105927,"user_name":"Echo💯","can_delete":false,"product_type":"c1","uid":1502473,"ip_address":"","ucode":"1452A5F2B5B298","user_header":"https://static001.geekbang.org/account/avatar/00/16/ed/09/fb41d795.jpg","comment_is_top":false,"comment_ctime":1561105488,"is_pvip":false,"replies":[{"id":"38469","content":"谢谢你的分享！","user_name":"作者回复","user_name_real":"Geek_88e0d7","uid":"1503187","ctime":1561337021,"ip_address":"","comment_id":105927,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1561105488","product_id":100025301,"comment_content":"由spark中的流式表处理 structured-streaming来说，就是针对批处理来对数据进行一段时间一批一批的处理，但是structured-streaming里针对的是连接kafka中的数据，是针对事件时间来处理的，而不是处理时间，所以就是structured-streaming是针对事件时间的批处理计算，谢谢。","like_count":0,"discussions":[{"author":{"id":1503187,"avatar":"","nickname":"Geek_88e0d7","note":"","ucode":"3E2596F3EB9165","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":454874,"discussion_content":"谢谢你的分享！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561337021,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":1}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":103636,"user_name":"西北偏北","can_delete":false,"product_type":"c1","uid":1043160,"ip_address":"","ucode":"64BD69C84EE6A1","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erdpKbFgRLnicjsr6qkrPVKZcFrG3aS2V51HhjFP6Mh2CYcjWric9ud1Qiclo8A49ia3eZ1NhibDib0AOCg/132","comment_is_top":false,"comment_ctime":1560480108,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1560480108","product_id":100025301,"comment_content":"有界数据是无界数据的一个子集<br><br>对实时性要求很高的无界数据处理，需要使用流失处理技术<br><br>对数据进行挖掘深沉挖掘的数据处理，需要使用批处理技术，其时延相对较高","like_count":0},{"had_liked":false,"id":100849,"user_name":"天下行走","can_delete":false,"product_type":"c1","uid":1462449,"ip_address":"","ucode":"73A4CD8BB91235","user_header":"https://wx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLfrbMvhKQYhxP6ziaHaj4KUNRzst8u7BZsWUsazK8oTLXcNH6sDGITl6icy3IiaGFe9Iiae12LuTrF1g/132","comment_is_top":false,"comment_ctime":1559654191,"is_pvip":false,"replies":[{"id":"36983","content":"谢谢你的分享！我觉得你能自己写出一个处理架构出来也是很牛的，继续加油！","user_name":"作者回复","user_name_real":"Geek_88e0d7","uid":"1503187","ctime":1560239088,"ip_address":"","comment_id":100849,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1559654191","product_id":100025301,"comment_content":"很棒，项目中流批处理都用到了，不过没有用成熟的组件，是自己项目写的处理框架，根据lamda架构思想来实现的；<br>当数据是永无止境的事件流时，使用流处理，记下了","like_count":0,"discussions":[{"author":{"id":1503187,"avatar":"","nickname":"Geek_88e0d7","note":"","ucode":"3E2596F3EB9165","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":452706,"discussion_content":"谢谢你的分享！我觉得你能自己写出一个处理架构出来也是很牛的，继续加油！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1560239088,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":1}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":98866,"user_name":"Zoe","can_delete":false,"product_type":"c1","uid":1528912,"ip_address":"","ucode":"A5D671919EE7B1","user_header":"https://static001.geekbang.org/account/avatar/00/17/54/50/8a76a8cc.jpg","comment_is_top":false,"comment_ctime":1559109892,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1559109892","product_id":100025301,"comment_content":"老师，突然想到一个小问题。比如说我有一个系统会源源不断的产生log，我把log按小时写进不同文件里。这个过程我可以理解为是流处理，对吗？但当我需要再对log进行其他分析时，我很有可能需要读取不同时间的log文件，再进行一个可能好几个小时的处理，这个过程就可以视为批处理？虽然数据有可能也是以数据流的形式从文件中读取进来的？","like_count":0},{"had_liked":false,"id":94809,"user_name":"漫漫越","can_delete":false,"product_type":"c1","uid":1249222,"ip_address":"","ucode":"F9F1E3AC4CF692","user_header":"https://static001.geekbang.org/account/avatar/00/13/0f/c6/cf344f74.jpg","comment_is_top":false,"comment_ctime":1557901326,"is_pvip":false,"replies":[{"id":"33965","content":"谢谢你的经验分享！是的，很多时候我们都不知觉在使用一些技术，能够了解背后的本质也是一件好事来的。","user_name":"作者回复","user_name_real":"Geek_88e0d7","uid":"1503187","ctime":1557953121,"ip_address":"","comment_id":94809,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1557901326","product_id":100025301,"comment_content":"我们的消息采用的是RabbitMQ,属于流处理，一些服务定时去统计数据，这个就是批处理了，网页搜索用的也是流处理，其实我们的业务中这两种处理都有涉及，我想任何一个业务，或多或少都会用到这两种处理，只是我们用的时候，还不自知摆了。","like_count":0,"discussions":[{"author":{"id":1503187,"avatar":"","nickname":"Geek_88e0d7","note":"","ucode":"3E2596F3EB9165","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":450218,"discussion_content":"谢谢你的经验分享！是的，很多时候我们都不知觉在使用一些技术，能够了解背后的本质也是一件好事来的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1557953121,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":1}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":93934,"user_name":"shawn","can_delete":false,"product_type":"c1","uid":1516046,"ip_address":"","ucode":"1A52A00A0A6610","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIkkg9icSGleYMAnwlb7A9MMJYOdovl8kOCA0asMkDe6grPNF74ib0prQMicicJTNa1WsdpMJ4p1CWkUQ/132","comment_is_top":false,"comment_ctime":1557671664,"is_pvip":false,"replies":[{"id":"33570","content":"谢谢你的提问！Flink的话如果数据无法全部放内存还是会被split到disk上的。","user_name":"作者回复","user_name_real":"Geek_88e0d7","uid":"1503187","ctime":1557708827,"ip_address":"","comment_id":93934,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1557671664","product_id":100025301,"comment_content":"spark和flink的批处理是一次把数据都放入内存中吗？","like_count":0,"discussions":[{"author":{"id":1503187,"avatar":"","nickname":"Geek_88e0d7","note":"","ucode":"3E2596F3EB9165","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":449834,"discussion_content":"谢谢你的提问！Flink的话如果数据无法全部放内存还是会被split到disk上的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1557708827,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":1}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":90583,"user_name":"歪曲丶","can_delete":false,"product_type":"c1","uid":1182880,"ip_address":"","ucode":"5D3DDAAFFE2C7D","user_header":"https://static001.geekbang.org/account/avatar/00/12/0c/a0/a7a87f96.jpg","comment_is_top":false,"comment_ctime":1556584168,"is_pvip":true,"replies":[{"id":"32541","content":"谢谢你的分享！","user_name":"作者回复","user_name_real":"Geek_88e0d7","uid":"1503187","ctime":1556653925,"ip_address":"","comment_id":90583,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1556584168","product_id":100025301,"comment_content":"我之前在做apm jvm qps rt 系统告警等 storm做了第一版 目前已转向flink","like_count":0,"discussions":[{"author":{"id":1503187,"avatar":"","nickname":"Geek_88e0d7","note":"","ucode":"3E2596F3EB9165","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":448580,"discussion_content":"谢谢你的分享！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1556653925,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":1}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":90526,"user_name":"朱同学","can_delete":false,"product_type":"c1","uid":1514233,"ip_address":"","ucode":"2EF7D5A051712C","user_header":"https://static001.geekbang.org/account/avatar/00/17/1a/f9/180f347a.jpg","comment_is_top":false,"comment_ctime":1556546469,"is_pvip":false,"replies":[{"id":"32543","content":"谢谢你的分享！","user_name":"作者回复","user_name_real":"Geek_88e0d7","uid":"1503187","ctime":1556654037,"ip_address":"","comment_id":90526,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1556546469","product_id":100025301,"comment_content":"实时在线人数，实时订单数用流处理，按天按月出的指标数据用批处理","like_count":0,"discussions":[{"author":{"id":1503187,"avatar":"","nickname":"Geek_88e0d7","note":"","ucode":"3E2596F3EB9165","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":448556,"discussion_content":"谢谢你的分享！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1556654037,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":1}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":90455,"user_name":"Rtree","can_delete":false,"product_type":"c1","uid":1502520,"ip_address":"","ucode":"29E9BF20FBB605","user_header":"https://static001.geekbang.org/account/avatar/00/16/ed/38/1f74babc.jpg","comment_is_top":false,"comment_ctime":1556523714,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1556523714","product_id":100025301,"comment_content":"我们现在在做批处理用的Hadoop&amp;Hbase，客户希望我们下一步支持流处理，我还在思考用什么框架比较好。主要是存储时空数据。","like_count":0},{"had_liked":false,"id":90399,"user_name":"六维","can_delete":false,"product_type":"c1","uid":1022887,"ip_address":"","ucode":"EB1C15AC06A8DF","user_header":"https://static001.geekbang.org/account/avatar/00/0f/9b/a7/440aff07.jpg","comment_is_top":false,"comment_ctime":1556509383,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1556509383","product_id":100025301,"comment_content":"既有批处理，也有流处理。例如数据产生后，需要及时展示在系统上，此为流处理；每天凌晨做汇总分析的处理为批处理。只是数据规模比较小，不构成大数据。但本质上应该是一致的。","like_count":0},{"had_liked":false,"id":90356,"user_name":"君哥聊技术","can_delete":false,"product_type":"c1","uid":1325816,"ip_address":"","ucode":"2C9A22BCE4C79E","user_header":"https://static001.geekbang.org/account/avatar/00/14/3a/f8/c1a939e7.jpg","comment_is_top":false,"comment_ctime":1556499329,"is_pvip":false,"replies":[{"id":"32999","content":"谢谢你的提问！其实Hive和Spark对于批处理和流处理都是支持的，当然本质上，你也可以说它们的流处理是建立在一定的时间窗口上的批处理。","user_name":"作者回复","user_name_real":"Geek_88e0d7","uid":"1503187","ctime":1557218734,"ip_address":"","comment_id":90356,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1556499329","product_id":100025301,"comment_content":"老师，我是数据处理小白，请问hive和spark是批处理还是流处理","like_count":0,"discussions":[{"author":{"id":1503187,"avatar":"","nickname":"Geek_88e0d7","note":"","ucode":"3E2596F3EB9165","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":448487,"discussion_content":"谢谢你的提问！其实Hive和Spark对于批处理和流处理都是支持的，当然本质上，你也可以说它们的流处理是建立在一定的时间窗口上的批处理。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1557218734,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":1}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":90323,"user_name":"lwenbin","can_delete":false,"product_type":"c1","uid":1202109,"ip_address":"","ucode":"05C4CC6BE0B56C","user_header":"https://static001.geekbang.org/account/avatar/00/12/57/bd/acf40fa0.jpg","comment_is_top":false,"comment_ctime":1556495620,"is_pvip":false,"replies":[{"id":"33003","content":"谢谢你的留言与建议！流处理其实也是能够做到高吞吐的。另外我很赞同你的观点，lambda架构确实在实际应用的时候使用得非常多，我也会在第十讲中展开讲述。<br><br>对于讲述原理实现这一点，是我在写专栏的时候很纠结的一点。因为如果要讲到实现的话就必定会具体到某一个framework，这在短短3000字的章节里不一定能够描述清楚。就像之前有读者留言Flink的datastream内容，我觉得可以专门开Flink的专栏去讲述实现原理。而这个专栏的目的我是想让读者，无论是小白还是有经验的工程师都了解到背后的本质思想，所以写作上跟偏向概念加例子。<br><br>最后还是非常感谢你宝贵的意见，我在后面的章节中也会有专门讲述Dataflow Model原理的内容，希望会符合你的要求。","user_name":"作者回复","user_name_real":"Geek_88e0d7","uid":"1503187","ctime":1557219632,"ip_address":"","comment_id":90323,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1556495620","product_id":100025301,"comment_content":"个人愚见。<br>批处理关心的是高吞吐，而流处理关心的是低延迟吧。<br>MPP可否也算一种？是否可归入near realtime?<br>很多时候业务上可能还会批流结合吧，类似lambda架构。比如风控，性能预测等，基于历史数据构建模型，作用于实时数据做预测等，当然本质上还是两个类型。<br>希望老师能更深入一些，除了概念，更多的讲一些原理，实现上的区别。<br>谢谢老师啦","like_count":0,"discussions":[{"author":{"id":1503187,"avatar":"","nickname":"Geek_88e0d7","note":"","ucode":"3E2596F3EB9165","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":448471,"discussion_content":"谢谢你的留言与建议！流处理其实也是能够做到高吞吐的。另外我很赞同你的观点，lambda架构确实在实际应用的时候使用得非常多，我也会在第十讲中展开讲述。\n\n对于讲述原理实现这一点，是我在写专栏的时候很纠结的一点。因为如果要讲到实现的话就必定会具体到某一个framework，这在短短3000字的章节里不一定能够描述清楚。就像之前有读者留言Flink的datastream内容，我觉得可以专门开Flink的专栏去讲述实现原理。而这个专栏的目的我是想让读者，无论是小白还是有经验的工程师都了解到背后的本质思想，所以写作上跟偏向概念加例子。\n\n最后还是非常感谢你宝贵的意见，我在后面的章节中也会有专门讲述Dataflow Model原理的内容，希望会符合你的要求。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1557219632,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":1}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":90316,"user_name":"明翼","can_delete":false,"product_type":"c1","uid":1068361,"ip_address":"","ucode":"E77F86BEB3D5C1","user_header":"https://static001.geekbang.org/account/avatar/00/10/4d/49/28e73b9c.jpg","comment_is_top":false,"comment_ctime":1556492872,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1556492872","product_id":100025301,"comment_content":"我们遇到的是以分钟为单位的准实时处理框架，以spark处理为主","like_count":0}]}