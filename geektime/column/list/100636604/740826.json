{"id":740826,"title":"第 20 章 异步编程(2)","content":"<h2 id=\"nav_point_408\">20.2　异步客户端与服务器</h2>\n<p>现在，我们要把这些已讨论过的关键思想组合成一个真正可用的程序。在很大程度上，异步应用程序和普通的多线程应用程序非常相似，但在某些需要紧凑而且富有表现力的代码的场合，异步编程可以大显身手。</p>\n<p>本节的示例是聊天服务器和客户端。真正的聊天系统是很复杂的，涉及从安全、重新连接到隐私和内部审核的各种问题，但我们已将此系统缩减为一组非常基础的特性，来把注意力聚焦于少数我们感兴趣的要点上。</p>\n<p>特别是，我们希望能好好处理<strong>背压</strong>。也就是说，即使一个客户端的网络连接速度较慢或完全断开连接，也绝不能影响其他客户端按照自己的节奏交换消息。由于“龟速”客户端不应该让服务器花费无限的内存来保存其不断增长的积压消息，因此我们的服务器应该丢弃那些发给掉队客户端的消息，但也有义务提醒他们其信息流不完整。（一个真正的聊天服务器会将消息记录到磁盘并允许客户端检索他们错过的消息，但这里不考虑那样做。）</p>\n<p>使用命令 <code>cargo new --lib async-chat</code> 启动项目，并将以下文本放入 async-chat/Cargo.toml 中：</p>\n<pre class=\"code-rows\"><code>[package]\nname = \"async-chat\"\nversion = \"0.1.0\"\nauthors = [\"You &lt;you@example.com&gt;\"]\nedition = \"2021\"\n\n[dependencies]\nasync-std = { version = \"1.7\", features = [\"unstable\"] }\ntokio = { version = \"1.0\", features = [\"sync\"] }\nserde = { version = \"1.0\", features = [\"derive\", \"rc\"] }\nserde_json = \"1.0\"</code></pre>\n<p>我们依赖于 4 个 crate。</p>\n<ul>\n<li><code>async-std</code> crate 是本章中一直在用的异步 I/O 基础构件和实用工具的集合。</li>\n<li><p><code>tokio</code> crate 是类似于 <code>async-std</code> crate 的另一个异步基础构件集合，它也是最古老且最成熟的 crate 之一。<code>tokio</code> crate 应用广泛，设计和实现的标准都很高，但使用时需要比 <code>async-std</code> crate 更加小心。</p><!-- [[[read_end]]] -->\n<p><code>tokio</code> 是一个大型 crate，但我们只需要其中的一个组件，因此 Cargo.toml 依赖行中的 <code>features = [\"sync\"]</code> 字段将 <code>tokio</code> 缩减为了我们需要的部分，使其成为一种轻型依赖。当异步库生态系统还不太成熟时，人们会避免在同一个程序中同时使用 <code>tokio</code> 和 <code>async-std</code>。不过，只要遵循这两个项目各自 crate 文档中的规则，就可以在同一个程序中使用。</p>\n<p>&nbsp;</p>\n</li>\n<li><p><code>serde</code> 和 <code>serde_json</code> 是第 18 章中介绍过的两个 crate。它们为我们提供了方便且高效的工具来生成和解析 JSON，我们的聊天协议使用 JSON 来表示网络上的数据。我们想使用 <code>serde</code> 的一些可选特性，因此会在提供依赖项时选择它们。</p>\n</li>\n</ul>\n<p>我们的聊天应用程序、客户端和服务器的整体结构如下所示：</p>\n<pre class=\"code-rows\"><code>async-chat\n├── Cargo.toml\n└── src\n    ├── lib.rs\n    ├── utils.rs\n    └── bin\n        ├── client.rs\n        └── server\n            ├── main.rs\n            ├── connection.rs\n            ├── group.rs\n            └── group_table.rs</code></pre>\n<p>这个包的布局使用了 8.4 节中提到的一项 Cargo 特性：除了主库 crate src/lib.rs 及其子模块 src/utils.rs，还包括两个可执行文件。</p>\n<ul>\n<li>src/bin/client.rs 是聊天客户端的单文件可执行文件。</li>\n<li>src/bin/server 是服务端的可执行文件，分布在 4 个文件中：main.rs 包含 <code>main</code> 函数，另外 3 个子模块分别是 connection.rs、group.rs 和 group_table.rs。</li>\n</ul>\n<p>我们将在本章中展示每个源文件的内容，如果它们都就位了，那么一旦在此目录树中键入 <code>cargo build</code>，就会编译库的 crate，然后构建出两个可执行文件。Cargo 会自动包含库的 crate 作为依赖项，使其成为放置客户端和服务器共享定义的约定位置。同样，<code>cargo check</code> 会检查整棵源代码树。要运行任何一个可执行文件，可以使用如下命令：</p>\n<pre class=\"code-rows\"><code>$ cargo run --release --bin server -- localhost:8088\n$ cargo run --release --bin client -- localhost:8088</code></pre>\n<p><code>--bin</code> 选项会指出要运行哪个可执行文件，而 <code>--</code> 选项后面的任何参数都会传给可执行文件本身。我们的客户端和服务器只希望知道服务器的地址和 TCP 端口。</p>\n<h3 id=\"nav_point_409\">20.2.1　<code>Error</code> 类型与 <code>Result</code> 类型</h3>\n<p>库 crate 的 <code>utils</code> 模块定义了要在整个应用程序中使用的 <code>Error</code> 类型与 <code>Result</code> 类型。以下来自 src/utils.rs：</p>\n<pre class=\"code-rows\"><code>use std::error::Error;\n\npub type ChatError = Box&lt;dyn Error + Send + Sync + 'static&gt;;\npub type ChatResult&lt;T&gt; = Result&lt;T, ChatError&gt;;</code></pre>\n<p>这些是我们在 7.2.5 节中建议的泛型错误类型。<code>async_std</code> crate、<code>serde_json</code> crate 和 <code>tokio</code> crate 也分别定义了自己的错误类型，但是 <code>?</code> 运算符可以自动将它们全部转换为 <code>ChatError</code>，这是借助标准库的 <code>From</code> 特型实现的，该特型可以将任何合适的错误类型转换为 <code>Box&lt;dyn Error + Send + Sync + 'static&gt;</code> 类型。类型限界 <code>Send</code> 和 <code>Sync</code> 会确保，如果在另一个线程中启动的任务失败，那么它可以安全地将错误报告给主线程。</p>\n<p>在实际的应用程序中，请考虑使用 <code>anyhow</code> crate，它提供了与这里类似的 <code>Error</code> 类型和 <code>Result</code> 类型。<code>anyhow</code> crate 易于使用，而且提供了一些超越 <code>ChatError</code> 和 <code>ChatResult</code> 的优秀特性。</p>\n<h3 id=\"nav_point_410\">20.2.2　协议</h3>\n<p>库 crate 以下面这两种类型来支持整个聊天协议，这是在 lib.rs 中定义的：</p>\n<pre class=\"code-rows\"><code>use serde::;\nuse std::sync::Arc;\n\npub mod utils;\n\n#[derive(Debug, Deserialize, Serialize, PartialEq)]\npub enum FromClient {\n    Join { group_name: Arc&lt;String&gt; },\n    Post {\n        group_name: Arc&lt;String&gt;,\n        message: Arc&lt;String&gt;,\n    },\n}\n\n#[derive(Debug, Deserialize, Serialize, PartialEq)]\npub enum FromServer {\n    Message {\n        group_name: Arc&lt;String&gt;,\n        message: Arc&lt;String&gt;,\n    },\n    Error(String),\n}\n\n#[test]\nfn test_fromclient_json() {\n    use std::sync::Arc;\n\n    let from_client = FromClient::Post {\n        group_name: Arc::new(\"Dogs\".to_string()),\n        message: Arc::new(\"Samoyeds rock!\".to_string()),\n    };\n\n    let json = serde_json::to_string(&amp;from_client).unwrap();\n    assert_eq!(json,\n               r#\"{\"Post\":{\"group_name\":\"Dogs\",\"message\":\"Samoyeds rock!\"}}\"#);\n\n    assert_eq!(serde_json::from_str::&lt;FromClient&gt;(&amp;json).unwrap(),\n               from_client);\n}</code></pre>\n<p><code>FromClient</code> 枚举表示可以从客户端发送到服务器的数据包：它可以请求加入一个组或向已加入的任何组发布消息。<code>FromServer</code> 表示可以由服务器发回的内容，即发布到某个组的消息或错误消息。可以使用带引用计数的 <code>Arc&lt;String&gt;</code> 而不是普通的 <code>String</code>，这有助于服务器在管理组和分发消息时避免复制字符串。</p>\n<p><code>#[derive]</code> 属性要求 <code>serde</code> crate 为 <code>FromClient</code> 和 <code>FromServer</code> 生成其 <code>Serialize</code> 特型和 <code>Deserialize</code> 特型的实现。这样一来，就可以调用 <code>serde_json::to_string</code> 将它们转换为 JSON 值，通过网络进行发送，最后再调用 <code>serde_json::from_str</code> 转换回它们的 Rust 形式。</p>\n<p><code>test_fromclient_json</code> 这个单元测试演示了它的用法。给定由 <code>serde</code> 派生的 <code>Serialize</code> 实现，可以调用 <code>serde_json::to_string</code> 将给定的 <code>FromClient</code> 值转换为这样的 JSON：</p>\n<pre class=\"code-rows\"><code>{\"Post\":{\"group_name\":\"Dogs\",\"message\":\"Samoyeds rock!\"}}</code></pre>\n<p>然后，派生出的 <code>Deserialize</code> 实现会将其解析回等效的 <code>FromClient</code> 值。请注意，<code>FromClient</code> 中的 <code>Arc</code> 指针对其序列化形式没有任何影响：引用计数字符串会直接显示为 JSON 对象成员的值。</p>\n<h3 id=\"nav_point_411\">20.2.3　获取用户输入：异步流</h3>\n<p>我们的聊天客户端的首要职责是读取用户的命令并将相应的数据包发送到服务器。管理一个合适的用户界面超出了本章的范围，所以我们将做最简单可行的事情：直接从标准输入中读取行。以下代码位于 src/bin/client.rs 中：</p>\n<pre class=\"code-rows\"><code>use async_std::prelude::*;\nuse async_chat::utils::;\nuse async_std::io;\nuse async_std::net;\n\nasync fn send_commands(mut to_server: net::TcpStream) -&gt; ChatResult&lt;()&gt; {\n    println!(\"Commands:\\n\\\n              join GROUP\\n\\\n              post GROUP MESSAGE...\\n\\\n              Type Control-D (on Unix) or Control-Z (on Windows) \\\n              to close the connection.\");\n\n    let mut command_lines = io::BufReader::new(io::stdin()).lines();\n    while let Some(command_result) = command_lines.next().await {\n        let command = command_result?;\n        // 参见GitHub存储库中对`parse_command`的定义\n        let request = match parse_command(&amp;command) {\n            Some(request) =&gt; request,\n            None =&gt; continue,\n        };\n\n        utils::send_as_json(&amp;mut to_server, &amp;request).await?;\n        to_server.flush().await?;\n    }\n\n    Ok(())\n}</code></pre>\n<p>这会调用 <code>async_std::io::stdin</code> 来获取客户端标准输入的异步句柄，并包装在 <code>async_std::io::BufReader</code> 中对其进行缓冲，然后调用 <code>lines</code> 逐行处理用户的输入。它会尝试将每一行解析为与某个 <code>FromClient</code> 值相对应的命令，如果成功，就将该值发送到服务器。如果用户输入了无法识别的命令，那么 <code>parse_command</code> 就会打印一条错误消息并返回 <code>None</code>，以便 <code>send_commands</code> 可以重新开始循环。如果用户键入了文件结束（EOF）指示符，则 <code>lines</code> 流会返回 <code>None</code>，并且 <code>send_commands</code> 也会返回。此代码与你在普通同步程序中编写的代码非常相似，只不过它使用的是 <code>async_std</code> 版本的库特性。</p>\n<p>异步 <code>BufReader</code> 的 <code>lines</code> 方法很有趣。它没有像标准库那样返回一个迭代器：<code>Iterator::next</code> 方法是一个普通的同步函数，因此调用 <code>command_lines.next()</code> 会阻塞线程，直到下一行代码就绪。而这里的 <code>lines</code> 会返回一个 <code>Result&lt;String&gt;</code> 值组成的<strong>流</strong>。流是迭代器的异步模拟，它会用异步友好的方式按需生成一系列值。下面是 <code>async_std::stream</code> 模块中 <code>Stream</code> 特型的定义：</p>\n<pre class=\"code-rows\"><code>trait Stream {\n    type Item;\n\n    // 现在，把`Pin&lt;&amp;mut Self&gt;`读取为`&amp;mut Self`\n    fn poll_next(self: Pin&lt;&amp;mut Self&gt;, cx: &amp;mut Context&lt;'_&gt;)\n        -&gt; Poll&lt;Option&lt;Self::Item&gt;&gt;;\n}</code></pre>\n<p>可以将 <code>Stream</code> 特型视为 <code>Iterator</code> 特型和 <code>Future</code> 特型的混合体。与迭代器一样，<code>Stream</code> 也有关联的 <code>Item</code> 类型，并使用 <code>Option</code> 来指示序列何时结束。同时，与 <code>Future</code> 一样，流必须被轮询：要获取下一个条目（或了解流是否结束），就必须调用 <code>poll_next</code> 直到它返回 <code>Poll::Ready</code>。流的 <code>poll_next</code> 实现应该总是快速返回，不会阻塞。如果流返回了 <code>Poll::Pending</code>，则必须在值得再次轮询时通过 <code>Context</code> 通知调用者。</p>\n<p><code>poll_next</code> 方法很难直接使用，不过通常也不需要直接使用该方法。与迭代器一样，流有很多实用方法，比如 <code>filter</code> 和 <code>map</code>。在这些方法中，有一个 <code>next</code> 方法，它会返回流中下一个 <code>Option&lt;Self::Item&gt;</code> 的 <code>Future</code>。可以调用 <code>next</code> 并等待它返回的 <code>Future</code>，而不必显式轮询流。</p>\n<p>把这些片段结合起来看，<code>send_commands</code> 会利用 <code>while let</code> 和 <code>next</code> 循环遍历输入行组成的流来消耗这个流：</p>\n<pre class=\"code-rows\"><code>while let Some(item) = stream.next().await {\n    ……使用条目……\n}</code></pre>\n<p>（Rust 可能会在未来版本中引入可用来消耗流的异步 <code>for</code> 循环，就像普通 <code>for</code> 循环能消耗 <code>Iterator</code> 值一样。）</p>\n<p>在流结束后（也就是说，在流返回 <code>Poll::Ready(None)</code> 指出流已结束之后）轮询流，就像在迭代器返回 <code>None</code> 之后调用 <code>next</code>，或者在 <code>Future</code> 返回 <code>Poll::Ready</code> 之后轮询 <code>Future</code>：<code>Stream</code> 特型没有规定此时流应该怎么做，某些流可能行为诡异。与 <code>Future</code> 和迭代器一样，流也有一个 <code>fuse</code> 方法来确保此类调用的行为在必要时是可预测的。有关详细信息，请参阅在线文档。</p>\n<p>使用流时，务必记住使用 <code>async_std</code> 预导入：</p>\n<pre class=\"code-rows\"><code>use async_std::prelude::*;</code></pre>\n<p>这是因为 <code>Stream</code> 特型的实用方法（如 <code>next</code>、<code>map</code>、<code>filter</code> 等）实际上并没有定义在自身上，而是单独特型 <code>StreamExt</code> 上的默认方法，该特型会自动为所有 <code>Stream</code> 实现：</p>\n<pre class=\"code-rows\"><code>pub trait StreamExt: Stream {\n    ……把一些实用工具方法定义为默认方法……\n}\n\nimpl&lt;T: Stream&gt; StreamExt for T { }</code></pre>\n<p>这是 11.2.2 节描述的<strong>扩展特型</strong>模式的示例。<code>async_std::prelude</code> 模块会将 <code>StreamExt</code> 方法引入作用域，因此使用预导入可以确保这些方法在你的代码中可见。</p>\n<h3 id=\"nav_point_412\">20.2.4　发送数据包</h3>\n<p>为了在网络套接字上传输数据包，我们的客户端和服务器会使用库 crate 的 <code>utils</code> 模块中的 <code>send_as_json</code> 函数：</p>\n<pre class=\"code-rows\"><code>use async_std::prelude::*;\nuse serde::Serialize;\nuse std::marker::Unpin;\n\npub async fn send_as_json&lt;S, P&gt;(outbound: &amp;mut S, packet: &amp;P) -&gt; ChatResult&lt;()&gt;\nwhere\n    S: async_std::io::Write + Unpin,\n    P: Serialize,\n{\n    let mut json = serde_json::to_string(&amp;packet)?;\n    json.push('\\n');\n    outbound.write_all(json.as_bytes()).await?;\n    Ok(())\n}</code></pre>\n<p>这个函数会将 <code>packet</code> 的 JSON 表示形式构建为 <code>String</code>，在末尾添加换行符，然后将其全部写入 <code>outbound</code>。</p>\n<p>从这个函数的 <code>where</code> 子句可以看出 <code>send_as_json</code> 非常灵活。要发送的数据包类型 <code>P</code> 可以是任何实现了 <code>serde::Serialize</code> 的值。输出流 <code>S</code> 可以是任何实现了 <code>async_std::io::Write</code>（输出流的 <code>std::io::Write</code> 特型的异步版本）的值。这足以让我们在异步 <code>TcpStream</code> 上发送 <code>FromClient</code> 值和 <code>FromServer</code> 值。只要遵守 <code>send_as_json</code> 的泛型定义，就能确保它不会意外依赖于流类型或数据包类型的细节，因为 <code>send_as_json</code> 只能使用来自这些特型的方法。</p>\n<p>使用 <code>write_all</code> 方法需要满足 <code>S</code> 上的 <code>Unpin</code> 约束。本章在后面会介绍 <code>Pin</code> 和 <code>Unpin</code>，但就目前而言，只要在必要时向类型变量中添加 <code>Unpin</code> 约束就足够了，如果忘记了，Rust 编译器会帮你指出这些问题。</p>\n<p><code>send_as_json</code> 没有将数据包直接序列化到 <code>outbound</code> 流，而是将其序列化为临时 <code>String</code>，然后写入 <code>outbound</code> 中。<code>serde_json</code> crate 确实提供了将值直接序列化为输出流的函数，但这些函数只支持同步流。要想写入异步流，就要对 <code>serde_json</code> 和 <code>serde</code> 这两个 crate 中与格式无关的核心代码进行根本性更改，因为围绕它们设计的特型都有一些同步方法。</p>\n<p>与流一样，<code>async_std</code> 的 I/O 特型的许多方法实际上是在其扩展特型上定义的，因此在使用它们时请务必记住 <code>use async_std::prelude::*</code>。</p>\n<h3 id=\"nav_point_413\">20.2.5　接收数据包：更多异步流</h3>\n<p>为了接收数据包，我们的服务器和客户端将使用一个来自 <code>utils</code> 模块的函数从异步缓冲的 TCP 套接字（<code>async_std::io::BufReader&lt;TcpStream&gt;</code>）中接收 <code>FromClient</code> 值和 <code>FromServer</code> 值：</p>\n<pre class=\"code-rows\"><code>use serde::de::DeserializeOwned;\n\npub fn receive_as_json&lt;S, P&gt;(inbound: S) -&gt; impl Stream&lt;Item = ChatResult&lt;P&gt;&gt;\n    where S: async_std::io::BufRead + Unpin,\n          P: DeserializeOwned,\n{\n    inbound.lines()\n        .map(|line_result| -&gt; ChatResult&lt;P&gt; {\n            let line = line_result?;\n            let parsed = serde_json::from_str::&lt;P&gt;(&amp;line)?;\n            Ok(parsed)\n        })\n}</code></pre>\n<p>与 <code>send_as_json</code> 一样，这个函数的输入流类型和数据包类型是泛型的。</p>\n<ul>\n<li>流类型 <code>S</code> 必须实现 <code>async_std::io::BufRead</code>，这是 <code>std::io::BufRead</code> 的异步模拟，表示缓冲输入字节流。</li>\n<li>数据包类型 <code>P</code> 必须实现 <code>DeserializeOwned</code>，这是 <code>serde</code> 的 <code>Deserialize</code> 特型的更严格变体。为了提高效率，<code>Deserialize</code> 可以生成 <code>&amp;str</code> 值和 <code>&amp;[u8]</code> 值，这些值会直接从反序列化的缓冲区中借用它们的内容，以免复制数据。然而，在上面的例子中，这样做可不太好：我们要将反序列化后的值返回给调用者，因此它们的生命周期必须超出被解析的缓冲区。实现了 <code>DeserializeOwned</code> 的类型始终独立于被反序列化的缓冲区。</li>\n</ul>\n<p>调用 <code>inbound.lines()</code> 会为我们提供一个携带 <code>std::io::Result&lt;String&gt;</code> 值的 <code>Stream</code>。然后，使用流的 <code>map</code> 适配器对每个条目应用一个闭包，处理错误并将每一行都解析为 <code>P</code> 类型值的 JSON 形式。这就生成了一个携带 <code>ChatResult&lt;P&gt;</code> 值的流，我们直接将其返回。该函数的返回类型如下所示：</p>\n<pre class=\"code-rows\"><code>impl Stream&lt;Item = ChatResult&lt;P&gt;&gt;</code></pre>\n<p>这表示我们返回了<strong>某种</strong>会异步生成 <code>ChatResult&lt;P&gt;</code> 值序列的类型，但我们的调用者无法准确判断是哪种类型。由于传给 <code>map</code> 的闭包无论如何都是匿名类型，因此这已经是 <code>receive_as_json</code> 可能返回的最具体的类型了。</p>\n<p>请注意，<code>receive_as_json</code> 本身并不是异步函数，它是会返回一个异步值（一个流）的普通函数。现在，比起“只在某些地方添加 <code>async</code> 与 <code>.await</code>”，你更深入地理解了 Rust 的异步支持机制，能够写出清晰、灵活和高效的定义，就像刚才这个充分发挥出语言特性的定义一样。</p>\n<p>要想了解 <code>receive_as_json</code> 的用法，可以看看下面这个来自 src/bin/client.rs 的聊天客户端的 <code>handle_replies</code> 函数，该函数会从网络接收 <code>FromServer</code> 的值流并将它们打印出来供用户查看：</p>\n<pre class=\"code-rows\"><code>use async_chat::FromServer;\n\nasync fn handle_replies(from_server: net::TcpStream) -&gt; ChatResult&lt;()&gt; {\n    let buffered = io::BufReader::new(from_server);\n    let mut reply_stream = utils::receive_as_json(buffered);\n\n    while let Some(reply) = reply_stream.next().await {\n        match reply? {\n            FromServer::Message { group_name, message } =&gt; {\n                println!(\"message posted to {}: {}\", group_name, message);\n            }\n            FromServer::Error(message) =&gt; {\n                println!(\"error from server: {}\", message);\n            }\n        }\n    }\n\n    Ok(())\n}</code></pre>\n<p>这个函数会接受一个从服务器接收数据的套接字，把它包装进 <code>BufReader</code>（请注意，这是 <code>async_std</code> 版本），然后将其传给 <code>receive_as_json</code> 以获取传入的 <code>FromServer</code> 值流。接下来它会用 <code>while let</code> 循环来处理传入的回复，检查错误结果并打印每个服务器的回复以供用户查看。</p>\n<h3 id=\"nav_point_414\">20.2.6　客户端的 <code>main</code> 函数</h3>\n<p>介绍完 <code>send_commands</code> 和 <code>handle_replies</code>，现在可以展示聊天客户端的 <code>main</code> 函数了，该函数来自 src/bin/client.rs：</p>\n<pre class=\"code-rows\"><code>use async_std::task;\n\nfn main() -&gt; ChatResult&lt;()&gt; {\n    let address = std::env::args().nth(1)\n        .expect(\"Usage: client ADDRESS:PORT\");\n\n    task::block_on(async {\n        let socket = net::TcpStream::connect(address).await?;\n        socket.set_nodelay(true)?;\n\n        let to_server = send_commands(socket.clone());\n        let from_server = handle_replies(socket);\n\n        from_server.race(to_server).await?;\n\n        Ok(())\n    })\n}</code></pre>\n<p>从命令行获取服务器地址后，<code>main</code> 要调用一系列异步函数，因此它会将函数的其余部分都包装在一个异步块中，并将该块返回的 <code>Future</code> 传给 <code>async_std::task::block_on</code> 来运行。</p>\n<p>建立连接后，我们希望 <code>send_commands</code> 函数和 <code>handle_replies</code> 函数双线运行，这样就可以在键入的同时看到别人发来的消息。如果遇到了 EOF 指示器或者与服务器的连接断开了，那么程序就应该退出。</p>\n<p>考虑到我们在本章其他地方所做的工作，你可能想要写出这样的代码：</p>\n<pre class=\"code-rows\"><code>let to_server = task::spawn(send_commands(socket.clone()));\nlet from_server = task::spawn(handle_replies(socket));\n\nto_server.await?;\nfrom_server.await?;</code></pre>\n<p>但由于我们在等待两个 <code>JoinHandle</code>，这会让程序在<strong>两个</strong>任务都完成后才能退出。但我们希望只要<strong>任何</strong>一个完成就立即退出。<code>Future</code> 上的 <code>race</code>（赛跑）方法可以满足这一要求。调用 <code>from_server.race(to_server)</code> 会返回一个新的 <code>Future</code>，它会同时轮询 <code>from_server</code> 和 <code>to_server</code>，并在二者之一就绪时返回 <code>Poll::Ready(v)</code>。这两个 <code>Future</code> 必须具有相同的输出类型，其最终值是先完成的那个 <code>Future</code> 的值。未完成的 <code>Future</code> 会被丢弃。</p>\n<p><code>race</code> 方法以及许多其他的便捷工具都是在 <code>async_std::prelude::FutureExt</code> 特型上定义的，<code>async_std::prelude</code> 能让它对我们可见。</p>\n<p>迄今为止，我们唯一没有展示过的客户端代码是 <code>parse_command</code> 函数。这是一目了然的文本处理代码，所以这里就不展示它的定义了。有关详细信息，请参阅 Git 库中的完整代码。</p>\n<h3 id=\"nav_point_415\">20.2.7　服务器的 <code>main</code> 函数</h3>\n<p>以下是服务器主文件 src/bin/server/main.rs 的全部内容：</p>\n<pre class=\"code-rows\"><code>use async_std::prelude::*;\nuse async_chat::utils::ChatResult;\nuse std::sync::Arc;\n\nmod connection;\nmod group;\nmod group_table;\n\nuse connection::serve;\n\nfn main() -&gt; ChatResult&lt;()&gt; {\n    let address = std::env::args().nth(1).expect(\"Usage: server ADDRESS\");\n\n    let chat_group_table = Arc::new(group_table::GroupTable::new());\n\n    async_std::task::block_on(async {\n        // 下面这段代码曾在本章的章节介绍中展示过\n        use async_std::;\n\n        let listener = net::TcpListener::bind(address).await?;\n\n        let mut new_connections = listener.incoming();\n        while let Some(socket_result) = new_connections.next().await {\n            let socket = socket_result?;\n            let groups = chat_group_table.clone();\n            task::spawn(async {\n                log_error(serve(socket, groups).await);\n            });\n        }\n\n        Ok(())\n    })\n}\n\nfn log_error(result: ChatResult&lt;()&gt;) {\n    if let Err(error) = result {\n        eprintln!(\"Error: {}\", error);\n    }\n}</code></pre>\n<p>服务器的 <code>main</code> 函数和客户端的 <code>main</code> 函数类似：它会先进行一些设置，然后调用 <code>block_on</code> 来运行一个异步块以完成真正的工作。为了处理来自客户端的传入连接，它创建了 <code>TcpListener</code> 套接字，其 <code>incoming</code> 方法会返回一个 <code>std::io::Result&lt;TcpStream&gt;</code> 值流。</p>\n<p>对于每个传入的连接，我们都会启动一个运行 <code>connection::serve</code> 函数的异步任务。每个任务还会收到一个 <code>GroupTable</code> 值的引用，该值表示服务器的当前聊天组列表，由所有连接通过 <code>Arc</code> 引用计数指针共享。</p>\n<p>如果 <code>connection::serve</code> 返回错误，我们就会将一条消息记录到标准错误并让任务退出，其他连接则照常运行。</p>\n<h3 id=\"nav_point_416\">20.2.8　处理聊天连接：异步互斥锁</h3>\n<p>下面这些位于 src/bin/server/connection.rs 的 <code>connection</code> 模块中的 <code>serve</code> 函数是服务器的主要工作代码：</p>\n<pre class=\"code-rows\"><code>use async_chat::;\nuse async_chat::utils::;\nuse async_std::prelude::*;\nuse async_std::io::BufReader;\nuse async_std::net::TcpStream;\nuse async_std::sync::Arc;\n\nuse crate::group_table::GroupTable;\n\npub async fn serve(socket: TcpStream, groups: Arc&lt;GroupTable&gt;)\n                   -&gt; ChatResult&lt;()&gt;\n\n{\n    let outbound = Arc::new(Outbound::new(socket.clone()));\n\n    let buffered = BufReader::new(socket);\n    let mut from_client = utils::receive_as_json(buffered);\n    while let Some(request_result) = from_client.next().await {\n        let request = request_result?;\n\n        let result = match request {\n            FromClient::Join { group_name } =&gt; {\n                let group = groups.get_or_create(group_name);\n                group.join(outbound.clone());\n                Ok(())\n            }\n\n            FromClient::Post { group_name, message } =&gt; {\n                match groups.get(&amp;group_name) {\n                    Some(group) =&gt; {\n                        group.post(message);\n                        Ok(())\n                    }\n                    None =&gt; {\n                        Err(format!(\"Group '{}' does not exist\", group_name))\n                    }\n                }\n            }\n        };\n\n        if let Err(message) = result {\n            let report = FromServer::Error(message);\n            outbound.send(report).await?;\n        }\n    }\n\n    Ok(())\n}</code></pre>\n<p>这几乎就是客户端的 <code>handle_replies</code> 函数的镜像：大部分代码是一个循环，用于处理传入的 <code>FromClient</code> 值的流，它是从带有 <code>receive_as_json</code> 的缓冲 TCP 流构建出来的。如果发生错误，就会生成一个 <code>FromServer::Error</code> 数据包，将坏消息传回给客户端。</p>\n<p>除了错误消息，客户端还希望接收来自他们已加入的聊天组的消息，因此需要与每个组共享和客户端的连接。虽然可以简单地为每个人提供一份 <code>TcpStream</code> 的克隆，但是如果其中两个源试图同时将数据包写入套接字，那么他们的输出就可能彼此交叉，并且客户端最终会收到乱码 JSON。我们需要对此连接安排安全的并发访问。</p>\n<p>这是使用 <code>Outbound</code> 类型管理的，在 src/bin/server/connection.rs 中的定义如下所示：</p>\n<pre class=\"code-rows\"><code>use async_std::sync::Mutex;\n\npub struct Outbound(Mutex&lt;TcpStream&gt;);\n\nimpl Outbound {\n    pub fn new(to_client: TcpStream) -&gt; Outbound {\n        Outbound(Mutex::new(to_client))\n    }\n\n    pub async fn send(&amp;self, packet: FromServer) -&gt; ChatResult&lt;()&gt; {\n        let mut guard = self.0.lock().await;\n        utils::send_as_json(&amp;mut *guard, &amp;packet).await?;\n        guard.flush().await?;\n        Ok(())\n    }\n}</code></pre>\n<p><code>Outbound</code> 值在创建时会获得 <code>TcpStream</code> 的所有权并将其包装在 <code>Mutex</code> 中以确保一次只有一个任务可以使用它。<code>serve</code> 函数会将每个 <code>Outbound</code> 包装在一个 <code>Arc</code> 引用计数指针中，以便客户端加入的所有组都可以指向同一个共享的 <code>Outbound</code> 实例。</p>\n<p>调用 <code>Outbound::send</code> 时会首先锁定互斥锁，返回一个可解引用为内部 <code>TcpStream</code> 的守卫值。我们使用 <code>send_as_json</code> 来传输 <code>packet</code>，最后会调用 <code>guard.flush()</code> 来确保它不会在某处缓冲区进行不完整传输。（据我们所知，<code>TcpStream</code> 实际上并不会缓冲数据，但 <code>Write</code> 特型确实允许它的实现这样做，所以不应该冒这个险。）</p>\n<p>表达式 <code>&amp;mut *guard</code> 可以帮我们解决 Rust 不会通过隐式解引用来满足特型限界的问题。我们会显式解引用互斥锁守卫，得到受保护的 <code>TcpStream</code>，然后借用一个可变引用，生成 <code>send_as_json</code> 所需的 <code>&amp;mut TcpStream</code>。</p>\n<p>请注意，<code>Outbound</code> 会使用 <code>async_std::sync::Mutex</code> 类型，而不是标准库的 <code>Mutex</code>。原因有以下 3 点。</p>\n<p>首先，如果任务在持有互斥锁守卫时被挂起，那么标准库的 <code>Mutex</code> 可能会行为诡异。如果一直运行该任务的线程选择了另一个试图锁定同一 <code>Mutex</code> 的任务，那么麻烦就会随之而来：从 <code>Mutex</code> 的角度来看，已经拥有它的线程正试图再次锁定它。标准的 <code>Mutex</code> 不是为处理这种情况而设计的，因此会发生 panic 或死锁。（它永远不会以不恰当的方式授予锁。）Rust 团队正在进行的一项工作就是在编译期检测到这个问题，并当 <code>std::sync::Mutex</code> 守卫运行在 <code>await</code> 表达式中时发出警告。由于 <code>Outbound::send</code> 在等待 <code>send_as_json</code> 和 <code>guard.flush</code> 返回的 <code>Future</code> 时需要持有锁，因此它必须使用 <code>async_std</code> 的 <code>Mutex</code>。</p>\n<p>其次，异步 <code>Mutex</code> 的 <code>lock</code> 方法会返回一个守卫的 <code>Future</code>，因此正在等待互斥锁的任务会将其线程让给别的任务使用，直到互斥锁就绪。（如果互斥锁已然可用，则此 <code>lock</code> 的 <code>Future</code> 会立即就绪，任务根本不会自行挂起。）另外，标准库 <code>Mutex</code> 的 <code>lock</code> 方法在等待获取锁期间会锁定整个线程。由于前面的代码在通过网络传输数据包时持有互斥锁，因此这种等待可能会持续相当长的时间。</p>\n<p>最后，标准库 <code>Mutex</code> 必须由锁定它的同一个线程解锁。为了强制执行此操作，标准库互斥锁的守卫类型没有实现 <code>Send</code>，它不能传输到其他线程。这意味着持有这种守卫的 <code>Future</code> 本身不会实现 <code>Send</code>，并且不能传给 <code>spawn</code> 以在线程池中运行，它只能与 <code>block_on</code> 或 <code>spawn_local</code> 一起使用。而 <code>async_std Mutex</code> 的守卫实现了 <code>Send</code>，因此在已启动的任务中使用它没有问题。</p>\n<h3 id=\"nav_point_417\">20.2.9　群组表：同步互斥锁</h3>\n<p>但前面所讲的那些并不能导向“在异步代码中应该始终使用 <code>async_std::sync::Mutex</code>”这样简单的结论。通常在持有互斥锁时不需要等待任何东西，并且这种锁定不会持续太久。在这种情况下，标准库的 <code>Mutex</code> 效率会更高。聊天服务器的 <code>GroupTable</code> 类型就说明了这种情况。以下是 src/bin/server/group_table.rs 的全部内容：</p>\n<pre class=\"code-rows\"><code>use crate::group::Group;\nuse std::collections::HashMap;\nuse std::sync::;\n\npub struct GroupTable(Mutex&lt;HashMap&lt;Arc&lt;String&gt;, Arc&lt;Group&gt;&gt;&gt;);\n\nimpl GroupTable {\n    pub fn new() -&gt; GroupTable {\n        GroupTable(Mutex::new(HashMap::new()))\n    }\n\n    pub fn get(&amp;self, name: &amp;String) -&gt; Option&lt;Arc&lt;Group&gt;&gt; {\n        self.0.lock()\n            .unwrap()\n            .get(name)\n            .cloned()\n    }\n\n    pub fn get_or_create(&amp;self, name: Arc&lt;String&gt;) -&gt; Arc&lt;Group&gt; {\n        self.0.lock()\n            .unwrap()\n        .entry(name.clone())\n        .or_insert_with(|| Arc::new(Group::new(name)))\n        .clone()\n    }\n}</code></pre>\n<p><code>GroupTable</code> 只是一个受互斥锁保护的哈希表，它会将聊天组名称映射到实际组，两者都使用引用计数指针进行管理。<code>get</code> 方法和 <code>get_or_create</code> 方法会锁定互斥锁，执行一些哈希表操作，可能还会做一些内存分配，然后返回。</p>\n<p>在 <code>GroupTable</code> 中，我们会使用普通的旧式 <code>std::sync::Mutex</code>。此模块中根本没有异步代码，因此无须避免 <code>await</code>。事实上，如果想在这里使用 <code>async_std::sync::Mutex</code>，就要将 <code>get</code> 和 <code>get_or_create</code> 变成异步函数，这会引入 <code>Future</code> 创建、暂停和恢复的开销，但收益甚微：互斥锁只会在一些哈希操作和可能出现的少量内存分配上锁定。</p>\n<p>如果聊天服务器发现自己拥有数百万用户，并且 <code>GroupTable</code> 的互斥锁确实成了瓶颈，那么就算把它变成异步形式也无法解决该问题。使用某种专门用于并发访问的集合类型来代替 <code>HashMap</code> 可能会好一些。例如，<code>dashmap</code> crate 就提供了这样一个类型。</p>\n<h3 id=\"nav_point_418\">20.2.10　聊天组：<code>tokio</code> 的广播通道</h3>\n<p>在我们的服务器中，<code>group::Group</code> 类型代表一个聊天组。该类型只需要支持 <code>connection::serve</code> 调用的两个方法：<code>join</code> 用于添加新成员，<code>post</code> 用于发布消息。发布的每条消息都要分发给所有成员。</p>\n<p>现在我们来解决前面提过的<strong>背压</strong>大挑战。有几项需求相互掣肘。</p>\n<ul>\n<li>如果一个成员无法跟上发布到群组的消息（比如，其网络连接速度较慢），则群组中的其他成员不应受到影响。</li>\n<li>即使某个成员掉线了，也应该有办法重新加入对话并以某种方式继续参与。</li>\n<li>用于缓冲消息的内存不应无限制地增长。</li>\n</ul>\n<p>因为这些挑战在实现多对多通信模式时很常见，所以 <code>tokio</code> crate 提供了一种<strong>广播通道</strong>类型，可以对这些挑战进行合理的权衡。<code>tokio</code> 广播通道是一个值队列（在这个例子中就是聊天消息），它允许任意数量的不同线程或任务发送值和接收值。之所以称为“广播”通道，是因为每个消费者都会获得这里发出的每个值的副本。（这个值的类型必须实现了 <code>Clone</code>。）</p>\n<p>通常，广播通道会在队列中把一条消息保留到每个消费者都获得了它的副本为止。但是，如果队列的长度超过通道的最大容量（在创建通道时指定），那么最旧的消息将被丢弃。任何掉队的消费者在下次尝试获取下一条消息时都会收到错误消息，并且通道会让他们赶上仍然可用的最旧消息。</p>\n<p>例如，图 20-4 展示了一个最大容量为 16 个值的广播通道。</p>\n<p class=\"pic\"><img img src=\"https://static001.geekbang.org/files/resource/ebook/100006/image00890.jpeg\" alt=\"{%}\" /></p>\n<p class=\"ebook-image-title\"><strong>图 20-4：<code>tokio</code> 广播通道</strong></p>\n<p>有 2 个发送方会将消息排入队列，4 个接收方会将消息从队列中取出——或者更准确地说，是将消息从队列中复制出来。接收者 B 还有 14 条消息要接收，接收者 C 还有 7 条，接收者 D 已经完全赶上了。接收者 A 掉队了，有 11 条消息在它看到之前就被丢弃了。它的下一次接收消息的尝试将失败，然后会返回一个错误以说明情况，并快进到队列的当前尾部。</p>\n<p>聊天服务器会将每个聊天组都表示为承载 <code>Arc&lt;String&gt;</code> 值的广播通道：向该组发布消息会将消息广播给所有当前成员。下面是 src/bin/server/group.rs 中的 <code>group::Group</code> 类型的定义：</p>\n<pre class=\"code-rows\"><code>use async_std::task;\nuse crate::connection::Outbound;\nuse std::sync::Arc;\nuse tokio::sync::broadcast;\n\npub struct Group {\n    name: Arc&lt;String&gt;,\n    sender: broadcast::Sender&lt;Arc&lt;String&gt;&gt;\n}\n\nimpl Group {\n    pub fn new(name: Arc&lt;String&gt;) -&gt; Group {\n        let (sender, _receiver) = broadcast::channel(1000);\n        Group { name, sender }\n    }\n\n    pub fn join(&amp;self, outbound: Arc&lt;Outbound&gt;) {\n        let receiver = self.sender.subscribe();\n\n        task::spawn(handle_subscriber(self.name.clone(),\n                                      receiver,\n                                      outbound));\n    }\n\n    pub fn post(&amp;self, message: Arc&lt;String&gt;) {\n        // 这只会在没有订阅者时返回错误。连接的发送端可能会退出，并恰好赶在其\n        // 接收端回复之前丢弃订阅，这可能会最终导致接收端试图向空组回复消息\n        let _ignored = self.sender.send(message);\n    }\n}</code></pre>\n<p><code>Group</code> 结构体中包含聊天组的名称，以及表示组广播通道发送端的 <code>broadcast::Sender</code>。</p>\n<p><code>Group::new</code> 函数会调用 <code>broadcast::channel</code> 创建一个最大容量为 1000 条消息的广播通道。<code>channel</code> 函数会返回发送者和接收者，但此时我们不需要接收者，因为组中还没有任何成员。</p>\n<p>要向组中添加新成员，<code>Group::join</code> 方法会调用发送者的 <code>subscribe</code> 方法来为通道创建新的接收者。然后聊天组会在 <code>handle_subscribe</code> 函数中启动一个新的异步任务来监视消息的接收者并将它们写回客户端。</p>\n<p>有了这些细节，<code>Group::post</code> 方法就很简单了：它只是将消息发送到广播通道。由于通道携带的值是 <code>Arc&lt;String&gt;</code> 型的值，因此为每个接收者提供自己的消息副本只会增加消息的引用计数，不会进行任何复制或堆分配。一旦所有订阅者都传输了这条消息，引用计数就会降为 0，并且此消息会被释放。</p>\n<p>下面是 <code>handle_subscriber</code> 的定义：</p>\n<pre class=\"code-rows\"><code>use async_chat::FromServer;\nuse tokio::sync::broadcast::error::RecvError;\n\nasync fn handle_subscriber(group_name: Arc&lt;String&gt;,\n                           mut receiver: broadcast::Receiver&lt;Arc&lt;String&gt;&gt;,\n                           outbound: Arc&lt;Outbound&gt;)\n{\n    loop {\n        let packet = match receiver.recv().await {\n            Ok(message) =&gt; FromServer::Message {\n                group_name: group_name.clone(),\n                message: message.clone(),\n            },\n\n            Err(RecvError::Lagged(n)) =&gt; FromServer::Error(\n                format!(\"Dropped {} messages from {}.\", n, group_name)\n            ),\n\n            Err(RecvError::Closed) =&gt; break,\n        };\n\n        if outbound.send(packet).await.is_err() {\n            break;\n        }\n    }\n}</code></pre>\n<p>尽管细节略有不同，但此函数的形式我们很熟悉：它是一个循环，从广播通道接收消息并通过共享的 <code>Outbound</code> 值将消息传输回客户端。如果此循环跟不上广播通道，它就会收到一个 <code>Lagged</code> 错误，并会尽职尽责地报告给客户端。</p>\n<p>如果将数据包发送回客户端时完全失败了，那么可能是因为连接已关闭，<code>handle_subscriber</code> 退出其循环并返回，导致异步任务退出。这会丢弃广播通道的 <code>Receiver</code>，并取消订阅该通道。这样，当连接断开时，它的每个组成员身份都会在下次该组试图向它发送消息时被清除。</p>\n<p>这个聊天组永远不会关闭，因为我们不会从群组表中移除一个组。但为完整性考虑，一旦遇到 <code>Closed</code> 错误，<code>handle_subscriber</code> 就会退出该任务。</p>\n<p>请注意，我们正在为每个客户端的每个组成员创建一个新的异步任务。这之所以可行，是因为异步任务使用的内存要比线程少得多，而且在同一个进程中从一个异步任务切换到另一个异步任务效率非常高。</p>\n<p>这就是聊天服务器的完整代码。它有点儿简陋，<code>async_std</code> crate、<code>tokio</code> crate 和 <code>futures</code> crate 中有许多比本书所讲更有价值的特性，但从理论上说，这个扩展示例已经阐明了异步生态系统的一些特性是如何协同工作的：例子中有两种风格的异步任务、流、异步 I/O 特型、通道和互斥锁。</p>\n<h2 id=\"nav_point_419\">20.3　原始 <code>Future</code> 与执行器：<code>Future</code> 什么时候值得再次轮询</h2>\n<p>聊天服务器展示了我们如何使用 <code>TcpListener</code>、<code>broadcast</code> 通道等异步原语来编写代码，并使用 <code>block_on</code>、<code>spawn</code> 等执行器来驱动它们的执行。现在来看看这些操作是如何实现的。关键问题是，当一个 <code>Future</code> 返回 <code>Poll::Pending</code> 时，应该如何与执行器协调，以便在正确的时机再次轮询。</p>\n<p>想想当我们从聊天客户端的 <code>main</code> 函数运行如下代码时会发生什么：</p>\n<pre class=\"code-rows\"><code>task::block_on(async {\n    let socket = net::TcpStream::connect(address).await?;\n    ...\n})</code></pre>\n<p>在 <code>block_on</code> 第一次轮询异步块的 <code>Future</code> 时，几乎可以肯定网络连接没有立即就绪，所以 <code>block_on</code> 进入了睡眠状态。那它应该在什么时候醒来呢？一旦网络连接就绪，<code>TcpStream</code> 就需要以某种方式告诉 <code>block_on</code> 应该再次尝试轮询异步块的 <code>Future</code>，因为它知道这一次 <code>await</code> 将完成，并且异步块的执行可以向前推进。</p>\n<p>当像 <code>block_on</code> 这样的执行器轮询 <code>Future</code> 时，必须传入一个称为<strong>唤醒器</strong>（waker）的回调。如果 <code>Future</code> 还没有就绪，那么 <code>Future</code> 特型的规则就会要求它必须暂时返回 <code>Poll::Pending</code>，并且如果 <code>Future</code> 值得再次轮询，就会安排在那时调用唤醒器。</p>\n<p>所以 <code>Future</code> 的手写实现通常看起来是这样的：</p>\n<pre class=\"code-rows\"><code>use std::task::Waker;\n\nstruct MyPrimitiveFuture {\n    ...\n    waker: Option&lt;Waker&gt;,\n}\n\nimpl Future for MyPrimitiveFuture {\n    type Output = ...;\n\n    fn poll(mut self: Pin&lt;&amp;mut Self&gt;, cx: &amp;mut Context&lt;'_&gt;) -&gt; Poll&lt;...&gt; {\n        ...\n        if ... future is ready ... {\n            return Poll::Ready(final_value);\n        }\n\n        // 保存此唤醒器以备后用\n        self.waker = Some(cx.waker().clone());\n        Poll::Pending\n    }\n}</code></pre>\n<p>换句话说，如果 <code>Future</code> 的值就绪了，就返回它。否则，将 <code>Context</code> 中唤醒器的克隆体存储在某处，并返回 <code>Poll::Pending</code>。</p>\n<p>当 <code>Future</code> 值得再次轮询时，它一定会通过调用其唤醒器的 <code>wake</code> 方法通知最后一个轮询它的执行器：</p>\n<pre class=\"code-rows\"><code>// 如果有一个唤醒器，就调用它，并清除`self.waker`\nif let Some(waker) = self.waker.take() {\n    waker.wake();\n}</code></pre>\n<p>理论上，执行器和 <code>Future</code> 会轮流轮询和唤醒：执行器会轮询 <code>Future</code> 并进入休眠状态，然后 <code>Future</code> 会调用唤醒器，这样，执行器就会醒来并再次轮询 <code>Future</code>。</p>\n<p>异步函数和异步块的 <code>Future</code> 不会处理唤醒器本身，它们只会将自己获得的上下文传给要等待的子 <code>Future</code>，并将保存和调用唤醒器的义务委托给这些子 <code>Future</code>。在我们的聊天客户端中，对异步块返回的 <code>Future</code> 的第一次轮询只会在等待 <code>TcpStream::connect</code> 返回的 <code>Future</code> 时传递上下文（<code>Context</code>）。随后的轮询会同样将自己的上下文传给异步块接下来要等待的任何 <code>Future</code>。</p>\n<p>如前面的示例所示，<code>TcpStream::connect</code> 返回的 <code>Future</code> 会被轮询。也就是说，这些返回的 <code>Future</code> 会将唤醒器转移给一个辅助线程，该线程会等待连接就绪，然后调用唤醒器。</p>\n<p><code>Waker</code> 实现了 <code>Clone</code> 和 <code>Send</code>，因此 <code>Future</code> 总是可以制作自己的唤醒器副本并根据需要将其发送到其他线程。<code>Waker::wake</code> 方法会消耗此唤醒器。还有一个 <code>wake_by_ref</code> 方法，该方法不会消耗唤醒器，但某些执行器可以更高效地实现消耗唤醒器的版本。（但这种差异充其量也只是一次 <code>clone</code> 而已。）</p>\n<p>执行器过度轮询 <code>Future</code> 并无害处，只会影响效率。然而，<code>Future</code> 应该只在轮询会取得实际进展时才小心地调用唤醒器：虚假唤醒和轮询之间的循环调用可能会阻止执行器完全休眠，从而浪费电量并使处理器对其他任务的响应速度降低。</p>\n<p>既然已经展示了执行器和原始 <code>Future</code> 是如何通信的，那么接下来我们就自己实现一个原始 <code>Future</code>，然后看看 <code>block_on</code> 执行器的实现。</p>\n<h3 id=\"nav_point_420\">20.3.1　调用唤醒器：<code>spawn_blocking</code></h3>\n<p>本章在前面介绍过 <code>spawn_blocking</code> 函数，该函数会启动在另一个线程上运行的给定闭包，并返回携带闭包返回值的 <code>Future</code>。现在，我们拥有实现 <code>spawn_blocking</code> 所需的所有“零件”。为简单起见，我们的版本会为每个闭包创建一个新线程，而不是像 <code>async_std</code> 的版本那样使用线程池。</p>\n<p>尽管 <code>spawn_blocking</code> 会返回 <code>Future</code>，但我们并不会将其写成 <code>async fn</code>。相反，它将作为普通的同步函数，返回一个 <code>SpawnBlocking</code> 结构体，我们会利用该结构体实现自己的 <code>Future</code>。</p>\n<p><code>spawn_blocking</code> 的签名如下所示：</p>\n<pre class=\"code-rows\"><code>pub fn spawn_blocking&lt;T, F&gt;(closure: F) -&gt; SpawnBlocking&lt;T&gt;\nwhere F: FnOnce() -&gt; T,\n      F: Send + 'static,\n      T: Send + 'static,</code></pre>\n<p>由于需要将闭包发送到另一个线程并带回返回值，因此闭包 <code>F</code> 及其返回值 <code>T</code> 必须实现 <code>Send</code>。由于不知道线程会运行多长时间，因此它们也必须是 <code>'static</code> 的。这些限界与 <code>std::thread::spawn</code> 自身的强制限界是一样的。</p>\n<p><code>SpawnBlocking&lt;T&gt;</code> 是携带闭包返回值的 <code>Future</code>。下面是它的定义：</p>\n<pre class=\"code-rows\"><code>use std::sync::;\nuse std::task::Waker;\n\npub struct SpawnBlocking&lt;T&gt;(Arc&lt;Mutex&lt;Shared&lt;T&gt;&gt;&gt;);\n\nstruct Shared&lt;T&gt; {\n    value: Option&lt;T&gt;,\n    waker: Option&lt;Waker&gt;,\n}</code></pre>\n<p><code>Shared</code> 结构体必须充当 <code>Future</code> 和运行闭包的线程之间的结合点，因此它由 <code>Arc</code> 拥有并受 <code>Mutex</code> 保护。（同步互斥锁在这里很好用。）轮询此 <code>Future</code> 会检查 <code>value</code> 是否存在，如果不存在则将唤醒器保存在 <code>waker</code> 中。运行闭包的线程会将其返回值保存在 <code>value</code> 中，然后调用 <code>waker</code>（如果存在的话）。</p>\n<p>下面是 <code>spawn_blocking</code> 的完整定义：</p>\n<pre class=\"code-rows\"><code>pub fn spawn_blocking&lt;T, F&gt;(closure: F) -&gt; SpawnBlocking&lt;T&gt;\nwhere F: FnOnce() -&gt; T,\n      F: Send + 'static,\n      T: Send + 'static,\n{\n    let inner = Arc::new(Mutex::new(Shared {\n        value: None,\n        waker: None,\n    }));\n\n    std::thread::spawn({\n        let inner = inner.clone();\n        move || {\n            let value = closure();\n\n            let maybe_waker = {\n                let mut guard = inner.lock().unwrap();\n                guard.value = Some(value);\n                guard.waker.take()\n            };\n\n            if let Some(waker) = maybe_waker {\n                waker.wake();\n            }\n        }\n    });\n\n    SpawnBlocking(inner)\n}</code></pre>\n<p>创建 <code>Shared</code> 值后，就会启动一个线程来运行此闭包，将结果存储在 <code>Shared</code> 的 <code>value</code> 字段中，并调用唤醒器（如果有的话）。</p>\n<p>可以为 <code>SpawnBlocking</code> 实现 <code>Future</code>，如下所示：</p>\n<pre class=\"code-rows\"><code>use std::future::Future;\nuse std::pin::Pin;\nuse std::task::;\n\nimpl&lt;T: Send&gt; Future for SpawnBlocking&lt;T&gt; {\n    type Output = T;\n\n    fn poll(self: Pin&lt;&amp;mut Self&gt;, cx: &amp;mut Context&lt;'_&gt;) -&gt; Poll&lt;T&gt; {\n        let mut guard = self.0.lock().unwrap();\n        if let Some(value) = guard.value.take() {\n            return Poll::Ready(value);\n        }\n\n        guard.waker = Some(cx.waker().clone());\n        Poll::Pending\n    }\n}</code></pre>\n<p>轮询 <code>SpawnBlocking</code> 来检查闭包的值是否就绪，如果已经就绪，就接手这个值的所有权并返回它。否则，<code>Future</code> 仍然处于 <code>Pending</code> 状态，因此它在 <code>Future</code> 的 <code>waker</code> 字段中保存了此上下文中唤醒器的克隆体。</p>\n<p>一旦 <code>Future</code> 返回了 <code>Poll::Ready</code>，就不应该再次对其进行轮询。诸如 <code>await</code> 和 <code>block_on</code> 之类消耗 <code>Future</code> 的常用方式都遵守这条规则。过度轮询 <code>SpawnBlocking</code> 型 <code>Future</code> 并不会发生什么可怕的事情，因此也不必花费精力来处理这种情况。这就是典型的手写型 <code>Future</code>。</p>\n<h3 id=\"nav_point_421\">20.3.2　实现 <code>block_on</code></h3>\n<p>除了能够实现原始 <code>Future</code>，我们还拥有构建简单执行器所需的全部“零件”。在本节中，我们将编写自己的 <code>block_on</code> 版本。它会比 <code>async_std</code> 的版本简单很多，比如，它不支持 <code>spawn_local</code>、任务局部变量或嵌套调用（从异步代码调用 <code>block_on</code>）。但这已足够运行我们的聊天客户端和服务器了。</p>\n<p>代码如下所示：</p>\n<pre class=\"code-rows\"><code>use waker_fn::waker_fn;      // Cargo.toml: waker-fn = \"1.1\"\nuse futures_lite::pin;       // Cargo.toml: futures-lite = \"1.11\"\nuse crossbeam::sync::Parker; // Cargo.toml: crossbeam = \"0.8\"\nuse std::future::Future;\nuse std::task::;\n\nfn block_on&lt;F: Future&gt;(future: F) -&gt; F::Output {\n    let parker = Parker::new();\n    let unparker = parker.unparker().clone();\n    let waker = waker_fn(move || unparker.unpark());\n    let mut context = Context::from_waker(&amp;waker);\n\n    pin!(future);\n\n    loop {\n        match future.as_mut().poll(&amp;mut context) {\n            Poll::Ready(value) =&gt; return value,\n            Poll::Pending =&gt; parker.park(),\n        }\n    }\n}</code></pre>\n<p>上述代码虽然很短，但做了很多事，我们慢慢讲。</p>\n<pre class=\"code-rows\"><code>let parker = Parker::new();\nlet unparker = parker.unparker().clone();</code></pre>\n<p><code>crossbeam</code> crate 的 <code>Parker</code> 类型是一个简单的阻塞原语：调用 <code>parker.park()</code> 阻塞线程，直到其他人在相应的 <code>Unparker</code>（可以通过调用 <code>parker.unparker()</code> 预先获得）上调用 <code>.unpark()</code>。如果要 <code>unpark</code> 一个尚未停泊（<code>park</code>）的线程，那么它的下一次 <code>park</code> 调用将立即返回，而不会阻塞。这里的 <code>block_on</code> 将使用 <code>Parker</code> 在 <code>Future</code> 未就绪时等待，而我们传给 <code>Future</code> 的唤醒器将解除停泊。</p>\n<pre class=\"code-rows\"><code>let waker = waker_fn(move || unparker.unpark());</code></pre>\n<p>来自 <code>waker_fn</code> crate 的 <code>waker_fn</code> 函数会从给定的闭包创建一个 <code>Waker</code>。在这里，我们制作了一个 <code>Waker</code>，当调用它时，它会调用闭包 <code>move || unparker.unpark()</code>。还可以通过实现 <code>std::task::Wake</code> 特型来创建唤醒器，但这里用 <code>waker_fn</code> 更方便一些。</p>\n<pre class=\"code-rows\"><code>pin!(future);</code></pre>\n<p>给定一个携带 <code>F</code> 类型 <code>Future</code> 的变量，<code>pin!</code> 宏<span class=\"comment-number\">4</span>会获取 <code>Future</code> 的所有权并声明一个同名的新变量，其类型为 <code>Pin&lt;&amp;mut F&gt;</code> 并借入了此 <code>Future</code>。这就为我们提供了 <code>poll</code> 方法所需的 <code>Pin&lt;&amp;mut Self&gt;</code>。异步函数和异步块返回的 <code>Future</code> 必须在轮询之前通过 <code>Pin</code> 换成引用，20.4 节会对此进行解释。</p>\n\n<pre class=\"code-rows\"><code>loop {\n    match future.as_mut().poll(&amp;mut context) {\n        Poll::Ready(value) =&gt; return value,\n        Poll::Pending =&gt; parker.park(),\n    }\n}</code></pre>\n<p>最后，轮询循环非常简单。以一个携带唤醒器的上下文为入参，我们会轮询 <code>Future</code> 直到它返回 <code>Poll::Ready</code>。如果返回的是 <code>Poll::Pending</code>，我们会暂停此线程，并阻塞到调用了 <code>waker</code> 为止。放行后就再重试。</p>\n<p><code>as_mut</code> 调用能让我们在不放弃所有权的情况下对 <code>future</code> 进行轮询，20.4 节会对此进行详细解释。</p>\n","comments":[]}