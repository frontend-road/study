{"id":790957,"title":"21｜LLM开发过程中的错误处理和Tracing","content":"<p>你好，我是黄佳。</p><p>今天我们来聊两个实际的问题。第一，在调用OpenAI API时，可能会碰见哪些错误，应该如何处理。第二，如何通过各种日志记录工具，来监控大模型的应用的运行过程。</p><h2>OpenAI API 的错误处理</h2><p>在与OpenAI API交互时，你可能会遇到各种错误。了解如何处理这些错误，对于确保应用程序的稳定性和可靠性至关重要。如果了解可能出现的错误类型，那么就见怪不怪了。</p><p>下面我们总结一下OpenAI API返回的常见错误类型，并提供处理这些错误的实用技巧。</p><p>OpenAI API返回的错误主要分为以下几类：</p><ol>\n<li>请求错误（400）：表示请求格式不正确或缺少必需参数，如Token或输入。常见原因包括参数名称、类型、值或格式与文档不匹配。</li>\n<li>身份验证错误（401）：表示API密钥无效、已过期或已撤销。常见原因包括API密钥有错或已经发生了安全漏洞。</li>\n<li>速率限制错误（429）：表示在给定时间段内发送了太多Token或请求，超过了分配的速率限制。</li>\n<li>服务器错误（500）：表示服务器在处理请求时出现意外错误，可能是由于临时错误、bug或系统中断。</li>\n<li>连接错误：表示请求无法到达服务器或建立安全连接，可能是由于网络问题、代理配置、SSL证书或防火墙规则。</li>\n<li>超时错误：表示请求花费的时间太长而无法完成，服务器关闭了连接。可能是由于网络问题、服务器负载过重或请求过于复杂。</li>\n</ol><!-- [[[read_end]]] --><p>完整的错误信息列表如下。</p><p><img src=\"https://static001.geekbang.org/resource/image/c6/34/c69898b420f1a7ba6b67f353c2117734.jpg?wh=2144x1140\" alt=\"图片\"></p><p>如果遇到错误，见招拆招。先检查API密钥是否正确。如果遇到Connection的问题，很可能需要切换网络或调整代理设置。遇到速率限制错误时，减少请求频率，或等待速率限制重置。遇到服务器错误时，等待几秒钟后重试请求。检查OpenAI系统状态页面，了解是否有正在进行的事件或维护影响服务。也有的时候，ChatGPT会出现宕机，可以去ChatGPT网站看看是否有宕机声明。</p><p>这里我举一个调用OpenAI API时出错的例子。在下面这段代码中，我试图让GPT给我把某一个目录中所有的Markdown文档内容都做个总结，然后生成一个新的文档。</p><pre><code class=\"language-plain\">import os\n\n# 创建OpenAI客户端\nfrom openai import OpenAI \nclient = OpenAI()\n\ninput_directory = '10_Applications/06_VideoCaption/output'\noutput_file = '10_Applications/06_VideoCaption/output/Summary.md'\n\ndef read_md_files(directory):\n&nbsp; &nbsp; md_contents = []\n&nbsp; &nbsp; for filename in os.listdir(directory):\n&nbsp; &nbsp; &nbsp; &nbsp; if filename.endswith('.md'):\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; with open(os.path.join(directory, filename), 'r', encoding='utf-8') as file:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; md_contents.append(file.read())\n&nbsp; &nbsp; return md_contents\n\ndef summarize_contents_with_gpt4o(contents):\n&nbsp; &nbsp; content_str = \"\\n\\n\".join(contents)\n&nbsp; &nbsp; response = client.chat.completions.create(\n&nbsp; &nbsp; &nbsp; &nbsp; model=\"gpt-4o\",\n&nbsp; &nbsp; &nbsp; &nbsp; messages=[\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {\"role\": \"system\", \"content\": \"你正在生成视频的总结。请提供视频的总结，并以Markdown格式回应。\"},\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {\"role\": \"user\", \"content\": [\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"这些是文件的内容：\",\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {\"type\": \"text\", \"text\": \"\\n\\n\".join(contents)}\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ]}\n&nbsp; &nbsp; &nbsp; &nbsp; ],\n&nbsp; &nbsp; &nbsp; &nbsp; temperature=0.5,\n&nbsp; &nbsp; )\n&nbsp; &nbsp; return response.choices[0].message.content\n\ndef write_summary_file(summary, output_file):\n&nbsp; &nbsp; with open(output_file, 'w', encoding='utf-8') as file:\n&nbsp; &nbsp; &nbsp; &nbsp; file.write(summary)\n\ndef main():\n&nbsp; &nbsp; md_contents = read_md_files(input_directory)\n&nbsp; &nbsp; summary = summarize_contents_with_gpt4o(md_contents)\n&nbsp; &nbsp; write_summary_file(summary, output_file)\n&nbsp; &nbsp; print(f\"Summary file created at {output_file}\")\n\nif __name__ == \"__main__\":\n&nbsp; &nbsp; main()\n</code></pre><p>运行程序会出现下面的错误。</p><blockquote>\n<p>openai.BadRequestError: Error code: 400 - {‘error’: {‘message’: “Invalid type for ‘messages[1].content[0]’: expected an object, but got a string instead.”, ‘type’: ‘invalid_request_error’, ‘param’: ‘messages[1].content[0]’, ‘code’: ‘invalid_type’}}</p>\n</blockquote><p>下面调整一下程序，增加 try/except 块处理OpenAI API返回的错误。这虽然没有解决本质问题，但是至少能够让程序正常结束。</p><pre><code class=\"language-plain\">def summarize_contents_with_gpt4o(contents):\n&nbsp; &nbsp; try:\n&nbsp; &nbsp; &nbsp; &nbsp; response = client.chat.completions.create(\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; model=\"gpt-4o\",\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; messages=[\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {\"role\": \"system\", \"content\": \"你正在生成视频的总结。请提供视频的总结，并以Markdown格式回应。\"},\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {\"role\": \"user\", \"content\": [\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"这些是文件的内容：\",\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {\"type\": \"text\", \"text\": \"\\n\\n\".join(contents)}\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ]}\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ],\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; temperature=0.5,\n&nbsp; &nbsp; &nbsp; &nbsp; )\n&nbsp; &nbsp; &nbsp; &nbsp; return response.choices[0].message.content\n&nbsp; &nbsp; except Exception as e:\n&nbsp; &nbsp; &nbsp; &nbsp; print(f\"Error generating summary: {e}\")\n&nbsp; &nbsp; &nbsp; &nbsp; return None\n</code></pre><p>那么，实际上，问题出在构建messages时，试图将一个列表嵌入到content字段中，而这个字段预期的类型是字符串。这导致了BadRequestError错误。为了解决这个问题，我们需要将内容连接成一个单一的字符串，而不是列表。这个修改程序的过程就留给你作为一个额外的思考题来完成。</p><h2>使用 Weights &amp; Biases 跟踪应用开发过程</h2><p>在机器学习和AI等涉及大量数据和模型调试的工作中，经常会用到Weights &amp; Biases  (wandb) 这个工具。这是一个用于机器学习和深度学习项目的实验跟踪和可视化工具，它能够自动记录和跟踪实验参数、超参数、模型架构和训练指标，提供实时监控和可视化图表，支持团队协作，集成超参数优化工具，管理和部署模型，并生成详细的实验报告。</p><p>这些功能可以帮助开发者和研究人员高效地管理、监控和优化模型及其实验过程。</p><p><img src=\"https://static001.geekbang.org/resource/image/c3/bb/c331b4425481eb0399c90bea3a7df3bb.png?wh=1914x894\" alt=\"图片\"></p><p>上图所示为一个典型的机器学习模型训练过程，通过wandb这个工具来可视化训练过程中各个轮次的损失和准确率。</p><p>对于我们的大模型应用开发来说，虽然我们不需要训练模型，但是，我们也可以利用wandb的强大的Logging、Tracing以及可视化的能力，来监控我们的大模型应用运行状态。<strong>比如说，如果我让大模型帮我总结</strong> <strong>100</strong> <strong>个文档，我可以通过日志记录每个文档的大小，我传输过程中</strong> <strong>Token</strong> <strong>的数量，总结完成后的文本长度等等</strong>。这就是wandb这个工具的重要价值所在。</p><p>这里我们先安装好wandb这个包。</p><pre><code class=\"language-plain\">pip install langsmith\n</code></pre><p>好的，那么现在可以去这里<a href=\"https://wandb.ai/\">创建</a>一个账号了。并且，申请到Access Key，等一下跑程序的时候需要用到。</p><p><img src=\"https://static001.geekbang.org/resource/image/36/25/363c441a31669dc8809d9536e971b925.png?wh=984x408\" alt=\"图片\" title=\"Weights & Biases 界面\"></p><p>我把刚才的文档总结程序进行下面的改造，意图就是记录，并且检测每一次文档总结时候的以下细节，比如说文件名、总结的长度等等。</p><pre><code class=\"language-plain\">def read_md_files(directory):\n&nbsp; &nbsp; md_contents = []\n&nbsp; &nbsp; filenames = []\n&nbsp; &nbsp; for filename in os.listdir(directory):\n&nbsp; &nbsp; &nbsp; &nbsp; if filename.endswith('.md'):\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; with open(os.path.join(directory, filename), 'r', encoding='utf-8') as file:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; md_contents.append(file.read())\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; filenames.append(filename)\n&nbsp; &nbsp; return md_contents, filenames\n\ndef main():\n&nbsp; &nbsp; # 初始化wandb\n&nbsp; &nbsp; wandb.init(project=\"video_summary\", name=\"summarize_md_files\")\n\n&nbsp; &nbsp; md_contents, filenames = read_md_files(input_directory)\n&nbsp; &nbsp; all_summaries = []\n\n&nbsp; &nbsp; for content, filename in zip(md_contents, filenames):\n&nbsp; &nbsp; &nbsp; &nbsp; try:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; summary = summarize_contents_with_gpt4o(content)\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; all_summaries.append(f\"# Summary for {filename}\\n\\n{summary}\\n\\n\")\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; wandb.log({\"filename\": filename, \"summary_length\": len(summary)})\n\n&nbsp; &nbsp; &nbsp; &nbsp; except Exception as e:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(f\"Error summarizing {filename}: {e}\")\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; wandb.log({\"filename\": filename, \"error\": str(e)})\n\n&nbsp; &nbsp; final_summary = \"\\n\".join(all_summaries)\n&nbsp; &nbsp; write_summary_file(final_summary, output_file)\n&nbsp; &nbsp; print(f\"Summary file created at {output_file}\")\n&nbsp; &nbsp; wandb.finish()\n</code></pre><p>代码的结构也很清晰。</p><ol>\n<li>在代码中初始化wandb会话，通过 <code>wandb.init(project=\"video_summary\", name=\"summarize_md_files\")</code>。</li>\n<li>在main函数中，逐个处理Markdown文件，调用summarize_contents_with_gpt4o进行总结。</li>\n<li>记录每个文件的总结状态和长度，通过wandb.log将总结的文本长度这个信息发送到wandb服务器。同时，在总结过程中捕获异常，并将错误信息记录到wandb。</li>\n<li>将所有文件的总结合并成一个文件，并写入指定的输出文件。</li>\n</ol><p>通过上述步骤，你可以实现对每个Markdown文件的逐个总结，并使用wandb监控和记录每个总结过程的状态和结果。这不仅有助于跟踪处理进度，还能在出现问题时快速定位并解决。</p><p>运行程序时，wandb会要求我选择是否已经有账号。我选择2，因为我刚刚已经创建了账号。</p><p><img src=\"https://static001.geekbang.org/resource/image/0f/1a/0fec3965efae3ca0cc8fe0194ccae51a.png?wh=310x80\" alt=\"图片\"></p><p>然后找到我的Key，并且输入。</p><p><img src=\"https://static001.geekbang.org/resource/image/2b/cf/2b41f8a4bb8yy4a2a7d54e8d30ddcbcf.png?wh=575x429\" alt=\"图片\"></p><p>这样，wandb就开始在跑程序的时候监控并记录日志了。</p><p><img src=\"https://static001.geekbang.org/resource/image/cb/y2/cbce12ffcf48a97a17a0fd14b011ayy2.png?wh=1021x124\" alt=\"图片\"></p><p>程序运行结束，在本地的wandb目录下，也可以看到日志。</p><p><img src=\"https://static001.geekbang.org/resource/image/ec/a2/ecee459b528d1a08aa91bebb269730a2.png?wh=296x126\" alt=\"图片\"></p><p>当然，更漂亮的是，在网页端，wandb满足了我们的核心需求：记录这些文件的summary的长度。同时还有其他一些信息，包括我跑代码时候GPU的使用情况。</p><p><img src=\"https://static001.geekbang.org/resource/image/df/4b/df8db14c7cfda41abe043bc782104d4b.png?wh=1743x1340\" alt=\"图片\"></p><p>好了，这样，我们就成功的把程序的运行日志，通过Weights &amp; Biases进行了实时的记载和可视化。</p><h2>使用 LangSmith 监控大模型调用</h2><p>不过，对于大模型应用开发来说，Weights &amp; Biases还不够完美，因为有些细节，比如说调用大模型时候的输入输出，调用的细节，调用了多少Token，花费了多少钱，这些东西Weights &amp; Biases没法自动帮我们进行归纳。</p><p>此时，<a href=\"https://xn--LangChain-4y4o934fqyr7p8jil0a\">LangChain</a> 这个大模型开发生态环境中的 <a href=\"https://www.langchain.com/langsmith\">LangSmith</a> 工具就能够帮到我们。LangSmith是一个用于构建生产级LLM应用程序的平台，可以帮你密切监控和评估应用程序，而且使用LangSmith不需要依赖LangChain包，也就是说这个工具可以独立于LangChain而存在。</p><p>首先，安装LangSmith。</p><pre><code class=\"language-plain\">pip install -U langsmith\n</code></pre><p>然后，到设置页面，创建API密钥。</p><p>接下来，设置环境变量。</p><pre><code class=\"language-plain\">export LANGCHAIN_TRACING_V2=true \nexport LANGCHAIN_API_KEY=&lt;your-api-key&gt;\n</code></pre><p>接下来就可以使用LangSmith来记录任意的大模型调用过程了。下面，我们使用 @traceable 装饰器来自动trace LLM调用。这个程序，是我们在前几课中曾经讲解过的给Video做Summary的程序。</p><pre><code class=\"language-plain\">from dotenv import load_dotenv\nload_dotenv()\nimport os\nimport openai\nfrom langsmith.wrappers import wrap_openai\nfrom langsmith import traceable\n\n# 创建OpenAI客户端并使用langsmith进行包装\nclient = wrap_openai(openai.Client())\n\ninput_directory = '10_Applications/06_VideoCaption/output'\noutput_file = '10_Applications/06_VideoCaption/output/Summary.md'\n\ndef read_md_files(directory):\n&nbsp; &nbsp; md_contents = []\n&nbsp; &nbsp; filenames = []\n&nbsp; &nbsp; for filename in os.listdir(directory):\n&nbsp; &nbsp; &nbsp; &nbsp; if filename.endswith('.md'):\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; with open(os.path.join(directory, filename), 'r', encoding='utf-8') as file:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; md_contents.append(file.read())\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; filenames.append(filename)\n&nbsp; &nbsp; return md_contents, filenames\n\n@traceable\ndef summarize_contents_with_gpt4o(content):\n&nbsp; &nbsp; response = client.chat.completions.create(\n&nbsp; &nbsp; &nbsp; &nbsp; model=\"gpt-4o\",\n&nbsp; &nbsp; &nbsp; &nbsp; messages=[\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {\"role\": \"system\", \"content\": \"你正在生成视频的总结。请提供视频的总结，并以Markdown格式回应。\"},\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {\"role\": \"user\", \"content\": \"这些是文件的内容：\\n\\n\" + content}\n&nbsp; &nbsp; &nbsp; &nbsp; ],\n&nbsp; &nbsp; &nbsp; &nbsp; temperature=0.5,\n&nbsp; &nbsp; )\n&nbsp; &nbsp; return response.choices[0].message.content\n\ndef write_summary_file(summary, output_file):\n&nbsp; &nbsp; with open(output_file, 'w', encoding='utf-8') as file:\n&nbsp; &nbsp; &nbsp; &nbsp; file.write(summary)\n\ndef main():\n&nbsp; &nbsp; md_contents, filenames = read_md_files(input_directory)\n&nbsp; &nbsp; all_summaries = []\n\n&nbsp; &nbsp; for content, filename in zip(md_contents, filenames):\n&nbsp; &nbsp; &nbsp; &nbsp; try:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; summary = summarize_contents_with_gpt4o(content)\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; all_summaries.append(f\"# Summary for {filename}\\n\\n{summary}\\n\\n\")\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # 使用langsmith记录日志\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(f\"Summary for {filename} length: {len(summary)}\")\n\n&nbsp; &nbsp; &nbsp; &nbsp; except Exception as e:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(f\"Error summarizing {filename}: {e}\")\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # 使用langsmith记录错误日志\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(f\"Error: {str(e)}\")\n\n&nbsp; &nbsp; final_summary = \"\\n\".join(all_summaries)\n&nbsp; &nbsp; write_summary_file(final_summary, output_file)\n&nbsp; &nbsp; print(f\"Summary file created at {output_file}\")\n\nif __name__ == \"__main__\":\n&nbsp; &nbsp; main()\n</code></pre><p>程序代码中，先使用LangSmith包装OpenAI客户端。其中，wrap_openai函数用于将OpenAI客户端包装为LangSmith兼容的客户端，以便进行追踪和日志记录。之后，添加traceable装饰器。@traceable装饰器用于将函数标记为可追踪的，这样LangSmith可以记录函数调用的输入和输出。</p><p>程序运行之后，再度登录LangSmith，将看到程序与大模型的交互细节都被记录。</p><p><img src=\"https://static001.geekbang.org/resource/image/a5/4e/a5b0bd6ecc3d642606acccbf85e60a4e.png?wh=1479x445\" alt=\"图片\" title=\"调用次数、Token 数、Cost 等\"></p><p><img src=\"https://static001.geekbang.org/resource/image/09/c8/09cde0ayy008e2ae4254114264bb52c8.png?wh=1723x714\" alt=\"图片\" title=\"LLM 调用细节，包括输入、模型、输出等\"></p><h2>总结时刻</h2><p>在调用OpenAI API时，常见的错误类型包括请求错误（400）、身份验证错误（401）、速率限制错误（429）、服务器错误（500）、连接错误和超时错误。针对这些错误，我们可以采取相应的处理措施，如检查API密钥、调整网络设置、减少请求频率、重试请求等。</p><p>为了更好地监控和记录大模型应用的运行过程，可以使用日志记录工具，如Weights &amp; Biases和LangSmith。Weights &amp; Biases适用于记录和可视化训练过程中的各类参数和指标，而LangSmith更适合追踪大模型调用的详细信息，包括输入输出、调用次数、消耗的Token数等。</p><p>除了Weights &amp; Biases之外，TensorBoard也是常用的机器学习可视化工具，尤其是用于监控和记录基于TensorFlow的模型训练过程中的指标、模型结构和数据流图。另一个机器学习开源监控平台是MLflow，用于管理机器学习的生命周期，包括实验跟踪、项目管理、模型管理和部署。这两个工具，你也可以了解一下。</p><h2>思考题</h2><ol>\n<li>你曾遇到过哪些OpenAI API错误，如何解决的？</li>\n<li>Weights &amp; Biases和LangSmith各自的优缺点是什么？在什么场景下你会选择使用Weights &amp; Biases？在什么场景下你会选择使用LangSmith？</li>\n</ol><p>期待你的分享，欢迎与我交流。如果今天的内容让你有所收获，也欢迎你把这节课转发给有需要的朋友！我们下节课再见！</p>","comments":[{"had_liked":false,"id":392178,"user_name":"刘宪涛","can_delete":false,"product_type":"c1","uid":2843286,"ip_address":"北京","ucode":"74D2DDD094DDF0","user_header":"","comment_is_top":false,"comment_ctime":1720168082,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100764201,"comment_content":"wandb安装的代码是不是写错了，写成langsmith了？","like_count":0}]}