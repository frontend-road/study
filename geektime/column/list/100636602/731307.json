{"id":731307,"title":"“嵌入”的概念","content":"<p>神经网络，至少以目前的设置来说，基本上是基于数的。因此，如果要用它来处理像文本这样的东西，我们需要一种用数表示文本的方法。当然，我们可以（本质上和 ChatGPT 一样）从为字典中的每个词分配一个数开始。但有一个重要的思想—也是 ChatGPT 的中心思想—更胜一筹。这就是“嵌入”（embedding）的思想。可以将嵌入视为一种尝试通过数的数组来表示某些东西“本质”的方法，其特性是“相近的事物”由相近的数表示。</p><p>例如，我们可以将词嵌入视为试图在一种“意义空间”中布局词，其中“在意义上相近”的词会出现在相近的位置。实际使用的嵌入（例如在 ChatGPT 中）往往涉及大量数字列表。但如果将其投影到二维平面上，则可以展示嵌入对词的布局方式。</p><p class=\"pic\"><img img=\"\" src=\"https://static001.geekbang.org/files/resource/ebook/100002/Images/image00135.jpeg\" alt=\"{%}\"></p><p>可以看到，这确实非常成功地捕捉了我们典型的日常印象。但是如何才能构建这样的嵌入呢？大致的想法是查看大量的文本（这里查看了来自互联网的 50 亿个词），然后看看各个词出现的“环境”有多“相似”。例如，alligator（短吻鳄）和 crocodile（鳄鱼）在相似的句子中经常几乎可以互换，这意味着它们将在嵌入中被放在相近的位置。但是，turnip（芜菁）和 eagle（鹰）一般不会出现在相似的句子中，因此将在嵌入中相距很远。</p><!-- [[[read_end]]] --><p>如何使用神经网络实际实现这样的机制呢？让我们从讨论图像的嵌入而非词嵌入开始。我们希望找到一种以数字列表来表征图像的方法，以便为“我们认为相似的图像”分配相似的数字列表。</p><p>如何判断我们是否应该“认为图像相似”呢？对于手写数字图像，如果两个图像是同一个数字，我们就可能会认为它们是相似的。前面，我们讨论了一个被训练用于识别手写数字的神经网络。可以将这个神经网络看作被设置成在最终输出中将图像放入 10 个不同的箱（bin）中，每个箱对应一个数字。</p><p>如果在神经网络做出“这是 4”的最终决策之前“拦截”其内部进程，会发生什么呢？我们可能会期望，神经网络内部有一些数值，将图像表征为“大部分类似于 4 但有点类似于 2”。想法是获取这些数值并将其作为嵌入中的元素使用。</p><p>这里的关键概念是，我们不直接尝试表征“哪个图像接近哪个图像”，而是考虑一个定义良好、可以获取明确的训练数据的任务（这里是数字识别），然后利用如下事实：在完成这个任务时，神经网络隐含地必须做出相当于“接近度决策”的决策。因此，我们不需要明确地谈论“图像的接近度”，而是只谈论图像代表什么数字的具体问题，然后“让神经网络”隐含地确定这对于“图像的接近度”意味着什么。</p><p>对于数字识别网络来说，这是如何具体操作的呢？我们可以将该网络想象成由 11 个连续的层组成，并做如下简化（将激活函数显示为单独的层）。</p><p class=\"pic\"><img img=\"\" src=\"https://static001.geekbang.org/files/resource/ebook/100002/Images/image00136.jpeg\" alt=\"{%}\"></p><p>在开始，我们将实际图像输入第一层，这些图像由其像素值的二维数组表示。在最后，我们（从最后一层）得到一个包含 10 个值的数组，可以认为这些值表示网络对图像与数字 0 到 9 的对应关系的确定程度。</p><p>输入图像 <img img=\"\" src=\"https://static001.geekbang.org/files/resource/ebook/100002/Images/image00137.jpeg\" alt=\"\" width=\"4%\" style=\"width: 4%\">，最后一层中神经元的值为</p><p class=\"pic\"><img img=\"\" src=\"https://static001.geekbang.org/files/resource/ebook/100002/Images/image00138.jpeg\" alt=\"{%}\"></p><p>换句话说，神经网络现在“非常确定”这个图像是一个 4—为了得到输出的 4，我们只需要找出具有最大值的神经元的位置。</p><p>如果我们再往前看一步呢？网络中的最后一个操作是所谓的 softmax，它试图“强制推出确定性”。在此之前，神经元的值是</p><p class=\"pic\"><img img=\"\" src=\"https://static001.geekbang.org/files/resource/ebook/100002/Images/image00139.jpeg\" alt=\"{%}\"></p><p>代表数字 4 的神经元仍然具有最大的数值，但是其他神经元的值中也有信息。我们可以期望这个数字列表在某种程度上能用来表征图像的“本质”，从而提供可以用作嵌入的东西。例如，这里的每个 4 都具有略微不同的“签名”（或“特征嵌入”），与 8 完全不同。</p><p class=\"pic\"><img img=\"\" src=\"https://static001.geekbang.org/files/resource/ebook/100002/Images/image00140.jpeg\" alt=\"{%}\"></p><p>这里，我们基本上是用 10 个数来描述图像的。但使用更多的数通常更好。例如，在我们的数字识别网络中，可以通过接入前一层来获取一个包含 500 个数的数组。这可能是一个可以用作“图像嵌入”的合理数组。</p><p>如果想要对手写数字的“图像空间”进行明确的可视化，需要将我们得到的 500 维向量投影到（例如）三维空间中来有效地“降维”。</p><p class=\"pic\"><img img=\"\" src=\"https://static001.geekbang.org/files/resource/ebook/100002/Images/image00141.jpeg\" alt=\"{%}\"></p><p>我们刚刚谈论了为图像创建特征（并嵌入）的方法，它的基础实际上是通过（根据我们的训练集）确定一些图像是否对应于同一个手写数字来识别它们的相似性。如果我们有一个训练集，可以识别每个图像属于 5000 种常见物体（如猫、狗、椅子……）中的哪一种，就可以做更多这样的事情。这样，就能以我们对常见物体的识别为“锚点”创建一个图像嵌入，然后根据神经网络的行为“围绕它进行泛化”。关键是，这种行为只要与我们人类感知和解读图像的方式一致，就将最终成为一种“我们认为正确”且在实践中对执行“类人判断”的任务有用的嵌入。</p><p>那么如何采用相同的方法来找到对词的嵌入呢？关键在于，要从一个我们可以轻松训练的任务开始。一个这样的标准任务是词预测。想象一下，给定问题“the ___ cat”。基于一个大型文本语料库，比如互联网上的文本内容，可能用来“填空”的各个词的概率分别是多少？或者给定“___ black ___”，不同的“两侧词”的概率分别是多少？</p><p>如何为神经网络设置这个问题呢？最终，我们必须用数来表述一切。一种方法是为英语中约 50 000 个常用词分别分配一个唯一的数。例如，分配给 the 的可能是 914，分配给 cat 的可能是 3542。（这些是 GPT-2 实际使用的数。）因此，对于“the ___ cat”的问题，我们的输入可能是 。输出应该是什么样的呢？应该是一个大约包含 50 000 个数的列表，有效地给出了每个可能“填入”的词的概率。为了找到嵌入，我们再次在神经网络“得到结论”之前“拦截”它的“内部”进程，然后获取此时的数字列表，可以认为这是“每个词的表征”。</p><p>这些表征是什么样子的呢？在过去 10 年里，已经出现了一系列不同的系统（word2vec、GloVe、BERT、GPT……），每个系统都基于一种不同的神经网络方法。但最终，所有这些系统都是通过有几百到几千个数的列表对词进行表征的。</p><p>这些“嵌入向量”在其原始形式下是几乎无信息的。例如，下面是 GPT-2 为三个特定的词生成的原始嵌入向量。</p><p class=\"pic\"><img img=\"\" src=\"https://static001.geekbang.org/files/resource/ebook/100002/Images/image00142.jpeg\" alt=\"{%}\"></p><p>如果测量这些向量之间的距离，就可以找到词之间的“相似度”。我们稍后将更详细地讨论这种嵌入的“认知”意义可能是什么，而现在的要点是，我们有一种有用的方法能将词转化为“对神经网络友好”的数字集合。</p><p>实际上，比起用一系列数对词进行表征，我们还可以做得更好—可以对词序列甚至整个文本块进行这样的表征。ChatGPT 内部就是这样进行处理的。它会获取到目前为止的所有文本，并生成一个嵌入向量来表示它。然后，它的目标就是找到下一个可能出现的各个词的概率。它会将答案表示为一个数字列表，这些数基本上给出了大约 50 000 个可能出现的词的概率。</p><p>［严格来说，ChatGPT 并不处理词，而是处理“标记”（token）—这是一种方便的语言单位，既可以是整个词，也可以只是像 pre、ing 或 ized 这样的片段。使用标记使 ChatGPT 更容易处理罕见词、复合词和非英语词，并且会发明新单词（不论结果好坏）。］</p><br style=\"page-break-after:always\">","comments":[]}