{"id":237851,"title":"结课测试 | 这些检索知识，你都掌握了吗？","content":"<p>你好，我是陈东。</p><p>《检索技术核心 20 讲》这门课程就正式完结了，很感谢你一直以来的认真学习和支持！</p><p>那为了帮助你检验自己的学习效果，我特别给你准备了一套结课测试题。这套测试题一共有 20 道题目，包括 10 道单选题和 10 道多选题，满分 100 分，我建议你在30分钟以内完成。</p><p>还等什么，快点击下面的按钮开始测试吧！</p><p><a href=\"http://time.geekbang.org/quiz/intro?act_id=161&exam_id=359\"><img src=\"https://static001.geekbang.org/resource/image/28/a4/28d1be62669b4f3cc01c36466bf811a4.png?wh=1142*201\" alt=\"\"></a></p><!-- [[[read_end]]] -->","neighbors":{"left":{"article_title":"开篇词 | 学会检索，快人一步！","id":215243},"right":[]},"comments":[{"had_liked":false,"id":218254,"user_name":"范闲","can_delete":false,"product_type":"c1","uid":1073125,"ip_address":"","ucode":"F21FD7DF6BA53C","user_header":"https://static001.geekbang.org/account/avatar/00/10/5f/e5/54325854.jpg","comment_is_top":false,"comment_ctime":1589765951,"is_pvip":false,"replies":[{"id":80728,"content":"谢谢你对专栏的支持。专栏的内容毕竟是有限的，而知识是无限的，并且也一直在更新。其实光是系统篇的每一类系统，本身都可以写一个专栏。\n这个专栏，更多的还是关注于检索技术的基础和方向，希望能让你对检索技术有一个更全面的了解和认知，同时也介绍了一些已经沉淀下来的解决方案。你可以认为这个专栏也是对检索技术的一个索引。如果要深入研究的话，其实每一篇提到的内容，都有许多细节和优化空间，都可以继续去深入学习的。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1589774189,"ip_address":"","comment_id":218254,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"结束的好快啊，意犹未尽","like_count":2,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":495406,"discussion_content":"谢谢你对专栏的支持。专栏的内容毕竟是有限的，而知识是无限的，并且也一直在更新。其实光是系统篇的每一类系统，本身都可以写一个专栏。\n这个专栏，更多的还是关注于检索技术的基础和方向，希望能让你对检索技术有一个更全面的了解和认知，同时也介绍了一些已经沉淀下来的解决方案。你可以认为这个专栏也是对检索技术的一个索引。如果要深入研究的话，其实每一篇提到的内容，都有许多细节和优化空间，都可以继续去深入学习的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589774189,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":223671,"user_name":"Geek_2e6a7e","can_delete":false,"product_type":"c1","uid":2027323,"ip_address":"","ucode":"BCDD3367AC16FD","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIyPPFIyvytj0LJrpHicVrTqibuLWLWcR5VqzArSHZicwJYC6gKrIF6GTxx4MakS6xiaxZBCw8icCPB8wQ/132","comment_is_top":false,"comment_ctime":1591153913,"is_pvip":false,"replies":[{"id":82581,"content":"spark是一个通用的分布式计算框架，它和检索倒没有太直接的相关性，不过在一些设计理念上，倒是有一些相似的地方。比如说rdd的设计就是典型的避免磁盘io，读写分离的设计。\n如果你希望使用spark进行高效检索服务，其实有一些spark+es的方案。\n而如果你是想优化spark自己的性能，那么比如避免数据倾斜这些方案可以参考一下。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1591340500,"ip_address":"","comment_id":223671,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"特别想了解，当前spark这种分布式计算引擎有什么好的优化措施","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":497209,"discussion_content":"spark是一个通用的分布式计算框架，它和检索倒没有太直接的相关性，不过在一些设计理念上，倒是有一些相似的地方。比如说rdd的设计就是典型的避免磁盘io，读写分离的设计。\n如果你希望使用spark进行高效检索服务，其实有一些spark+es的方案。\n而如果你是想优化spark自己的性能，那么比如避免数据倾斜这些方案可以参考一下。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1591340500,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2027323,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIyPPFIyvytj0LJrpHicVrTqibuLWLWcR5VqzArSHZicwJYC6gKrIF6GTxx4MakS6xiaxZBCw8icCPB8wQ/132","nickname":"Geek_2e6a7e","note":"","ucode":"BCDD3367AC16FD","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":281199,"discussion_content":"现在的数据湖概念，类似hudi，用spark作为计算引擎，也支持presto，flink这些。当然 hudi作为存储层做了很多优化，那计算引擎有什么更好的调优方向？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1591690740,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":373158,"user_name":"ifelse","can_delete":false,"product_type":"c1","uid":2550743,"ip_address":"浙江","ucode":"D0565908C99695","user_header":"https://static001.geekbang.org/account/avatar/00/26/eb/d7/90391376.jpg","comment_is_top":false,"comment_ctime":1682155365,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":1,"score":2,"product_id":100048401,"comment_content":"学习打卡，60分","like_count":0}]}