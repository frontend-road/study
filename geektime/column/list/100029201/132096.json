{"id":132096,"title":"40 | Kafka Streams与其他流处理平台的差异在哪里？","content":"<p>你好，我是胡夕。今天我要和你分享的主题是：Kafka Streams与其他流处理平台的差异。</p><p>近些年来，开源流处理领域涌现出了很多优秀框架。光是在Apache基金会孵化的项目，关于流处理的大数据框架就有十几个之多，比如早期的Apache Samza、Apache Storm，以及这两年火爆的Spark以及Flink等。</p><p>应该说，每个框架都有自己独特的地方，也都有自己的缺陷。面对这众多的流处理框架，我们应该如何选择呢？今天，我就来梳理几个主流的流处理平台，并重点分析一下Kafka Streams与其他流处理平台的差异。</p><h2>什么是流处理平台？</h2><p>首先，我们有必要了解一下流处理平台的概念。<a href=\"https://www.oreilly.com/library/view/streaming-systems/9781491983867/ch01.html\">“Streaming Systems”</a>一书是这么定义“流处理平台”的：<strong>流处理平台（Streaming System）是处理无限数据集（Unbounded Dataset）的数据处理引擎，而流处理是与批处理（Batch Processing）相对应的。</strong></p><p>所谓的无限数据，是指数据永远没有尽头。流处理平台是专门处理这种数据集的系统或框架。当然，这并不是说批处理系统不能处理这种无限数据集，只是通常情况下，它更擅长处理有限数据集（Bounded Dataset）。</p><!-- [[[read_end]]] --><p>那流处理和批处理究竟该如何区分呢？下面这张图应该能帮助你快速且直观地理解它们的区别。</p><p><img src=\"https://static001.geekbang.org/resource/image/2f/b2/2f8e72ce532cf1d05306cb8b78510bb2.png?wh=1837*1340\" alt=\"\"></p><p>好了，现在我来详细解释一下流处理和批处理的区别。</p><p>长期以来，流处理给人的印象通常是低延时，但是结果不准确。每来一条消息，它就能计算一次结果，但由于它处理的大多是无界数据，可能永远也不会结束，因此在流处理中，我们很难精确描述结果何时是精确的。理论上，流处理的计算结果会不断地逼近精确结果。</p><p>但是，它的竞争对手批处理则正好相反。批处理能提供准确的计算结果，但往往延时很高。</p><p>因此，业界的大神们扬长避短，将两者结合在一起使用。一方面，利用流处理快速地给出不那么精确的结果；另一方面，依托于批处理，最终实现数据一致性。这就是所谓的<strong>Lambda架构</strong>。</p><p>延时低是个很好的特性，但如果计算结果不准确，流处理是无法完全替代批处理的。所谓计算结果准确，在教科书或文献中有个专属的名字，叫正确性（Correctness）。可以这么说，<strong>目前难以实现正确性是流处理取代批处理的最大障碍</strong>，而实现正确性的基石是精确一次处理语义（Exactly Once Semantics，EOS）。</p><p>这里的精确一次是流处理平台能提供的一类一致性保障。常见的一致性保障有三类：</p><ul>\n<li>至多一次（At most once）语义：消息或事件对应用状态的影响最多只有一次。</li>\n<li>至少一次（At least once）语义：消息或事件对应用状态的影响最少一次。</li>\n<li>精确一次（Exactly once）语义：消息或事件对应用状态的影响有且只有一次。</li>\n</ul><p>注意，我这里说的都是<strong>对应用状态的影响</strong>。对于很多有副作用（Side Effect）的操作而言，实现精确一次语义几乎是不可能的。举个例子，假设流处理中的某个步骤是发送邮件操作，当邮件发送出去后，倘若后面出现问题要回滚整个流处理流程，已发送的邮件是没法追回的，这就是所谓的副作用。当你的流处理逻辑中存在包含副作用的操作算子时，该操作算子的执行是无法保证精确一次处理的。因此，我们通常只是保证这类操作对应用状态的影响精确一次罢了。后面我们会重点讨论Kafka Streams是如何实现EOS的。</p><p>我们今天讨论的流处理既包含真正的实时流处理，也包含微批化（Microbatch）的流处理。<strong>所谓的微批化，其实就是重复地执行批处理引擎来实现对无限数据集的处理</strong>。典型的微批化实现平台就是<strong>Spark Streaming</strong>。</p><h2>Kafka Streams的特色</h2><p>相比于其他流处理平台，<strong>Kafka Streams最大的特色就是它不是一个平台</strong>，至少它不是一个具备完整功能（Full-Fledged）的平台，比如其他框架中自带的调度器和资源管理器，就是Kafka Streams不提供的。</p><p>Kafka官网明确定义Kafka Streams是一个<strong>Java客户端库</strong>（Client Library）。<strong>你可以使用这个库来构建高伸缩性、高弹性、高容错性的分布式应用以及微服务</strong>。</p><p>使用Kafka Streams API构建的应用就是一个普通的Java应用程序。你可以选择任何熟悉的技术或框架对其进行编译、打包、部署和上线。</p><p>在我看来，这是Kafka Streams与Storm、Spark Streaming或Flink最大的区别。</p><p>Java客户端库的定位既可以说是特色，也可以说是一个缺陷。目前Kafka Streams在国内推广缓慢的一个重要原因也在于此。毕竟，很多公司希望它是一个功能完备的平台，既能提供流处理应用API，也能提供集群资源管理与调度方面的能力。所以，这个定位到底是特色还是缺陷，仁者见仁、智者见智吧。</p><h2>Kafka Streams与其他框架的差异</h2><p>接下来，我从应用部署、上下游数据源、协调方式和消息语义保障（Semantic Guarantees）4个方面，详细分析一下Kafka Streams与其他框架的差异。</p><h3>应用部署</h3><p>首先，我们从流处理应用部署方式上对Kafka Streams及其他框架进行区分。</p><p>我们刚刚提到过，Kafka Streams应用需要开发人员自行打包和部署，你甚至可以将Kafka Streams应用嵌入到其他Java应用中。因此，作为开发者的你，除了要开发代码之外，还要自行管理Kafka Streams应用的生命周期，要么将其打包成独立的jar包单独运行，要么将流处理逻辑嵌入到微服务中，开放给其他服务调用。</p><p>但不论是哪种部署方式，你需要自己处理，不要指望Kafka Streams帮你做这些事情。</p><p>相反地，其他流处理平台则提供了完整的部署方案。我以Apache Flink为例来解释一下。在Flink中，流处理应用会被建模成单个的流处理计算逻辑，并封装进Flink的作业中。类似地，Spark中也有作业的概念，而在Storm中则叫拓扑（Topology）。作业的生命周期由框架来管理，特别是在Flink中，Flink框架自行负责管理作业，包括作业的部署和更新等。这些都无需应用开发人员干预。</p><p>另外，Flink这类框架都存在<strong>资源管理器</strong>（Resource Manager）的角色。一个作业所需的资源完全由框架层的资源管理器来支持。常见的资源管理器，如YARN、Kubernetes、Mesos等，比较新的流处理框架（如Spark、Flink等）都是支持的。像Spark和Flink这样的框架，也支持Standalone集群的方式，即不借助于任何已有的资源管理器，完全由集群自己来管理资源。这些都是Kafka Streams无法提供的。</p><p>因此，从应用部署方面来看，Kafka Streams更倾向于将部署交给开发人员来做，而不是依赖于框架自己实现。</p><h3>上下游数据源</h3><p>谈完了部署方式的差异，我们来说说连接上下游数据源方面的差异。简单来说，<strong>Kafka Streams目前只支持从Kafka读数据以及向Kafka写数据</strong>。在没有Kafka Connect组件的支持下，Kafka Streams只能读取Kafka集群上的主题数据，在完成流处理逻辑后也只能将结果写回到Kafka主题上。</p><p>反观Spark Streaming和Flink这类框架，它们都集成了丰富的上下游数据源连接器（Connector），比如常见的连接器MySQL、ElasticSearch、HBase、HDFS、Kafka等。如果使用这些框架，你可以很方便地集成这些外部框架，无需二次开发。</p><p>当然，由于开发Connector通常需要同时掌握流处理框架和外部框架，因此在实际使用过程中，Connector的质量参差不齐，在具体使用的时候，你可以多查查对应的<strong>jira官网</strong>，看看有没有明显的“坑”，然后再决定是否使用。</p><p>在这个方面，我是有前车之鉴的。曾经，我使用过一个Connector，我发现它在读取Kafka消息向其他系统写入的时候似乎总是重复消费。费了很多周折之后，我才发现这是一个已知的Bug，而且早就被记录在jira官网上了。因此，我推荐你多逛下jira，也许能提前避开一些“坑”。</p><p><strong>总之，目前Kafka Streams只支持与Kafka集群进行交互，它没有提供开箱即用的外部数据源连接器。</strong></p><h3>协调方式</h3><p>在分布式协调方面，Kafka Streams应用依赖于Kafka集群提供的协调功能，来提供<strong>高容错性和高伸缩性</strong>。</p><p><strong>Kafka Streams应用底层使用了消费者组机制来实现任意的流处理扩缩容</strong>。应用的每个实例或节点，本质上都是相同消费者组下的独立消费者，彼此互不影响。它们之间的协调工作，由Kafka集群Broker上对应的协调者组件来完成。当有实例增加或退出时，协调者自动感知并重新分配负载。</p><p>我画了一张图来展示每个Kafka Streams实例内部的构造，从这张图中，我们可以看出，每个实例都由一个消费者实例、特定的流处理逻辑，以及一个生产者实例组成，而这些实例中的消费者实例，共同构成了一个消费者组。</p><p><img src=\"https://static001.geekbang.org/resource/image/4d/4d/4de6620323d74aa537127c5405bac54d.jpg?wh=2416*2037\" alt=\"\"></p><p>通过这个机制，Kafka Streams应用同时实现了<strong>高伸缩性和高容错性</strong>，而这一切都是自动提供的，不需要你手动实现。</p><p>而像Flink这样的框架，它的容错性和扩展性是通过专属的主节点（Master Node）全局来协调控制的。</p><p>Flink支持通过ZooKeeper实现主节点的高可用性，避免单点失效：<strong>某个节点出现故障会自动触发恢复操作</strong>。<strong>这种全局性协调模型对于流处理中的作业而言非常实用，但不太适配单独的流处理应用程序</strong>。原因就在于它不像Kafka Streams那样轻量级，应用程序必须要实现特定的API来开启检查点机制（checkpointing），同时还需要亲身参与到错误恢复的过程中。</p><p>应该这样说，在不同的场景下，Kafka Streams和Flink这种重量级的协调模型各有优劣。</p><h3>消息语义保障</h3><p>我们刚刚提到过EOS，目前很多流处理框架都宣称它们实现了EOS，也包括Kafka Streams本身。关于精确一次处理语义，有一些地方需要澄清一下。</p><p>实际上，当把Spark、Flink与Kafka结合使用时，如果不使用Kafka在0.11.0.0版本引入的幂等性Producer和事务型Producer，这些框架是无法实现端到端的EOS的。</p><p>因为这些框架与Kafka是相互独立的，彼此之间没有任何语义保障机制。但如果使用了事务机制，情况就不同了。这些外部系统利用Kafka的事务机制，保障了消息从Kafka读取到计算再到写入Kafka的全流程EOS。这就是所谓的端到端精确一次处理语义。</p><p>之前Spark和Flink宣称的EOS都是在各自的框架内实现的，无法实现端到端的EOS。只有使用了Kafka的事务机制，它们对应的Connector才有可能支持端到端精确一次处理语义。</p><p>Spark官网上明确指出了<strong>用户若要实现与Kafka的EOS，必须自己确保幂等输出和位移保存在同一个事务中。如果你不能自己实现这套机制，那么就要依赖于Kafka提供的事务机制来保证</strong>。</p><p>而Flink在Kafka 0.11之前也宣称提供EOS，不过是有前提条件的，即每条消息对<strong>Flink应用状态</strong>的影响有且只有一次。</p><p>举个例子，如果你使用Flink从Kafka读取消息，然后不加任何处理直接写入到MySQL，那么这个操作就是无状态的，此时Flink无法保证端到端的EOS。</p><p>换句话说，Flink最后写入到MySQL的Kafka消息可能有重复的。当然，Flink社区自1.4版本起正式实现了端到端的EOS，其基本设计思想正是基于Kafka 0.11幂等性Producer的两阶段提交机制。</p><p>两阶段提交（2-Phase Commit，2PC）机制是一种分布式事务机制，用于实现分布式系统上跨多个节点事务的原子性提交。下面这张图来自于神书“Designing Data-Intensive Applications”中关于2PC讲解的章节。它清晰地描述了一次成功2PC的过程。在这张图中，两个数据库参与到分布式事务的提交过程中，它们各自做了一些变更，现在需要使用2PC来保证两个数据库的变更被原子性地提交。如图所示，2PC被分为两个阶段：Prepare阶段和Commit阶段。只有完整地执行了这两个阶段，这个分布式事务才算是提交成功。</p><p><img src=\"https://static001.geekbang.org/resource/image/eb/c4/eb979df60ca9a2d2bb811febbe4545c4.png?wh=2880*962\" alt=\"\"></p><p>分布式系统中的2PC常见于数据库内部实现或以XA事务的方式供各种异质系统使用。Kafka也借鉴了2PC的思想，在Kafka内部实现了基于2PC的事务机制。</p><p>但是，对于Kafka Streams而言，情况就不同了。它天然支持端到端的EOS，因为它本来就是和Kafka紧密相连的。</p><p>下图展示了一个典型的Kafka Streams应用的执行逻辑。</p><p><img src=\"https://static001.geekbang.org/resource/image/3a/44/3a0cd5a5b04ea5d7c7c082ecd9d63144.jpg?wh=1857*1811\" alt=\"\"></p><p>通常情况下，一个Kafka Streams需要执行5个步骤：</p><ol>\n<li>读取最新处理的消息位移；</li>\n<li>读取消息数据；</li>\n<li>执行处理逻辑；</li>\n<li>将处理结果写回到Kafka；</li>\n<li>保存位置信息。</li>\n</ol><p>这五步的执行必须是<strong>原子性</strong>的，否则无法实现精确一次处理语义。</p><p>在设计上，Kafka Streams在底层大量使用Kafka事务机制和幂等性Producer来实现多分区的原子性写入，又因为它只能读写Kafka，因此Kafka Streams很容易地就实现了端到端的EOS。</p><p>总之，虽然Flink自1.4版本也提供与Kafka的EOS，但从适配性来考量的话，应该说Kafka Streams与Kafka的适配性是最好的。</p><h2>小结</h2><p>好了，我们来小结一下。今天，我重点分享了Kafka Streams与其他流处理框架或平台的差异。总的来说，Kafka Streams是一个轻量级的客户端库，而其他流处理平台都是功能完备的流处理解决方案。这是Kafka Streams的特色所在，但同时可能也是缺陷。不过，我认为很多情况下我们并不需要重量级的流处理解决方案，采用轻量级的库API帮助我们实现实时计算是很方便的情形，我想，这或许是Kafka Streams未来的破局之路吧。</p><p>在专栏后面的内容中，我会详细介绍如何使用Kafka Streams API实现实时计算，并跟你分享一个实际的案例，希望这些能激发你对Kafka Streams的兴趣，并为你以后的探索奠定基础。</p><p><img src=\"https://static001.geekbang.org/resource/image/d2/0e/d2d0b922414c3776d34523946feeae0e.jpg?wh=2069*2560\" alt=\"\"></p><h2>开放讨论</h2><p>知乎上有个关于Kafka Streams的“灵魂拷问”：<a href=\"https://www.zhihu.com/question/337923430/answer/787298849\">为什么Kafka Streams没什么人用？</a>我推荐你去看一下，并谈谈你对这个问题的理解和答案。</p><p>欢迎写下你的思考和答案，我们一起讨论。如果你觉得有所收获，也欢迎把文章分享给你的朋友。</p>","comments":[{"had_liked":false,"id":208137,"user_name":"沧海一粟","can_delete":false,"product_type":"c1","uid":1482590,"ip_address":"","ucode":"146961635959E7","user_header":"https://static001.geekbang.org/account/avatar/00/16/9f/5e/479f33a6.jpg","comment_is_top":false,"comment_ctime":1587283259,"is_pvip":false,"replies":[{"id":"77763","content":"Kafka Streams是实时流处理组件，默认提供了很多算子，组合在一起可以实现较为复杂的流处理逻辑。Consumer只是单纯的消费者组件，没有这些算子。另外Consumer也不能保证EOS和operator状态管理等常见的流处理框架提供的功能","user_name":"作者回复","comment_id":208137,"uid":"1288090","ip_address":"","utype":1,"ctime":1587307819,"user_name_real":"胡夕"}],"discussion_count":1,"race_medal":0,"score":"61716825403","product_id":100029201,"comment_content":"分不太清streams和直接启动consumer消费有什么区别？都是实时的呀。","like_count":14,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492354,"discussion_content":"Kafka Streams是实时流处理组件，默认提供了很多算子，组合在一起可以实现较为复杂的流处理逻辑。Consumer只是单纯的消费者组件，没有这些算子。另外Consumer也不能保证EOS和operator状态管理等常见的流处理框架提供的功能","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587307819,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":148880,"user_name":"hunterlodge","can_delete":false,"product_type":"c1","uid":1069755,"ip_address":"","ucode":"5B83A79E784161","user_header":"https://static001.geekbang.org/account/avatar/00/10/52/bb/225e70a6.jpg","comment_is_top":false,"comment_ctime":1573098684,"is_pvip":false,"replies":[{"id":"57350","content":"无限数据集也可以按照时间线进行窗口化切分，那么我们就关心每个窗口的实时计算结果是否能够和离线计算这段时间内的结果匹配上","user_name":"作者回复","comment_id":148880,"uid":"1288090","ip_address":"","utype":1,"ctime":1573176243,"user_name_real":"huxi_2b"}],"discussion_count":2,"race_medal":0,"score":"40227804348","product_id":100029201,"comment_content":"老师，我一直没理解流处理的正确性是什么，既然是处理无限的数据，那又怎么可以和批处理来比较呢？好比我们无法比较一个无限整数集合的sum以及一个有限整数集合的sum呢？","like_count":10,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":473649,"discussion_content":"无限数据集也可以按照时间线进行窗口化切分，那么我们就关心每个窗口的实时计算结果是否能够和离线计算这段时间内的结果匹配上","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1573176243,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1069755,"avatar":"https://static001.geekbang.org/account/avatar/00/10/52/bb/225e70a6.jpg","nickname":"hunterlodge","note":"","ucode":"5B83A79E784161","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":47501,"discussion_content":"谢谢老师回复，我最近看到kafka里可以对kstream和ktable作join操作，不是很理解这其中的语义，请问老师，当join操作有一方是kstream时，是不是暗含着一定是某个时间窗口中的数据参与join呢？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1573356209,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":218737,"user_name":"小刀","can_delete":false,"product_type":"c1","uid":1070261,"ip_address":"","ucode":"785923D8F0D46A","user_header":"https://static001.geekbang.org/account/avatar/00/10/54/b5/310dae7b.jpg","comment_is_top":false,"comment_ctime":1589862351,"is_pvip":false,"replies":[{"id":"80948","content":"👍","user_name":"作者回复","comment_id":218737,"uid":"1288090","ip_address":"","utype":1,"ctime":1589942864,"user_name_real":"胡夕"}],"discussion_count":2,"race_medal":0,"score":"23064698831","product_id":100029201,"comment_content":"留言好少，我加一个场景，我在用stream关联应用日志和istio的open tracing调用链日志","like_count":5,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":495560,"discussion_content":"👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589942864,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1030082,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b7/c2/196932c7.jpg","nickname":"南琛一梦","note":"","ucode":"6338D5428DB2B0","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":414700,"discussion_content":"感觉有些意思，可否详细的讲讲。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1636862629,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":192407,"user_name":"sipom","can_delete":false,"product_type":"c1","uid":1074197,"ip_address":"","ucode":"80411DC49CFA57","user_header":"https://static001.geekbang.org/account/avatar/00/10/64/15/9c9ca35c.jpg","comment_is_top":false,"comment_ctime":1584849072,"is_pvip":false,"replies":[{"id":"73574","content":"Thanks, man:)","user_name":"作者回复","comment_id":192407,"uid":"1288090","ip_address":"","utype":1,"ctime":1584877017,"user_name_real":"huxi_2b"}],"discussion_count":1,"race_medal":0,"score":"14469750960","product_id":100029201,"comment_content":"batch、streaming区别的图非常形象👍","like_count":3,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":488390,"discussion_content":"Thanks, man:)","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1584877017,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":236635,"user_name":"轶","can_delete":false,"product_type":"c1","uid":1099881,"ip_address":"","ucode":"FA0483DF79E37D","user_header":"https://static001.geekbang.org/account/avatar/00/10/c8/69/ce605c29.jpg","comment_is_top":false,"comment_ctime":1595486878,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10185421470","product_id":100029201,"comment_content":"单纯从功能角度来看，Flink 等标准的大数据处理框架肯定是胜过 kafka streams 的。但按照 Confluent CTO 的说法，二者之间的最大区别是：“Flink 和 Kafka Streams 程序之间的根本区别在于它们的部署和管理方式。”<br>怎么理解这句话呢？一般来说 Flink 等大数据处理平台都是由公司的大数据团队部署和管理的，如果某个应用项目中的部分处理逻辑需要依赖于这些大数据处理平台的话，那必然涉及团队间的协作问题，很多时候这比技术问题本身还难以解决😅。但是如果相关处理不是很复杂的话，其实完全可以通过 Kafka streams 来解决，因此应用研发团队可以完全掌控相关的代码和部署，从而能够快速响应需求变化。 ","like_count":2},{"had_liked":false,"id":324233,"user_name":"Joey","can_delete":false,"product_type":"c1","uid":2415368,"ip_address":"","ucode":"6856FA3A28B32C","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/DLcTlSKOQlrhRq1hzBNvnWfENsyFrxNnhJ5UPibPMLazy9c2nBlSd1sxHqzHaOTTaZIYkEDAby3HpdianMxt6Dsw/132","comment_is_top":false,"comment_ctime":1638345319,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5933312615","product_id":100029201,"comment_content":"所以相比flink，kafka stream一点也不香","like_count":1},{"had_liked":false,"id":131099,"user_name":"吴宇晨","can_delete":false,"product_type":"c1","uid":1199968,"ip_address":"","ucode":"F8F45B7067DF6D","user_header":"https://static001.geekbang.org/account/avatar/00/12/4f/60/049a20e9.jpg","comment_is_top":false,"comment_ctime":1567644044,"is_pvip":false,"replies":[{"id":"49314","content":"个人感觉市场定位不是很清晰。大数据工程师本身不会用，而对于纯数据分析人员门槛又有点高。","user_name":"作者回复","comment_id":131099,"uid":"1288090","ip_address":"","utype":1,"ctime":1567645080,"user_name_real":"huxi_2b"}],"discussion_count":1,"race_medal":0,"score":"5862611340","product_id":100029201,"comment_content":"想问老师对新出的ksql有什么看法","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":466284,"discussion_content":"个人感觉市场定位不是很清晰。大数据工程师本身不会用，而对于纯数据分析人员门槛又有点高。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567645080,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":131080,"user_name":"jellyabd","can_delete":false,"product_type":"c1","uid":1131186,"ip_address":"","ucode":"5A4B3FE9DE8FC7","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/tVtdATOIDmDt85Xuv5dAHNpk93NVTPiaU2MtPA4DLXQia6VXwycpreNzkQs91bLuMCrYUhdGShOtcR1GKW3cp5xA/132","comment_is_top":false,"comment_ctime":1567640546,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"5862607842","product_id":100029201,"comment_content":" xAcs","like_count":1},{"had_liked":false,"id":356452,"user_name":"夏落de烦恼","can_delete":false,"product_type":"c1","uid":1875724,"ip_address":"广东","ucode":"0CBDC51EF566A6","user_header":"https://static001.geekbang.org/account/avatar/00/1c/9f/0c/8484f8b1.jpg","comment_is_top":false,"comment_ctime":1662339311,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1662339311","product_id":100029201,"comment_content":"flink和kafka stream的算子是一样的么？","like_count":0},{"had_liked":false,"id":351149,"user_name":"余晓杰","can_delete":false,"product_type":"c1","uid":1889760,"ip_address":"","ucode":"97269A045FE190","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEIoRAqV3Yic1wa2gKDq74h1SB5azIpZAOE2uY43CZevju1vd4wxibXq3Y6LJvxJ4tlsJEEmkI64ZJvw/132","comment_is_top":false,"comment_ctime":1657550823,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1657550823","product_id":100029201,"comment_content":"Java8 stream和kafka stream 有可比性吗","like_count":0},{"had_liked":false,"id":306740,"user_name":"if...else...","can_delete":false,"product_type":"c1","uid":2550743,"ip_address":"","ucode":"D0565908C99695","user_header":"https://static001.geekbang.org/account/avatar/00/26/eb/d7/90391376.jpg","comment_is_top":false,"comment_ctime":1628687215,"is_pvip":false,"discussion_count":0,"race_medal":4,"score":"1628687215","product_id":100029201,"comment_content":"中国程序员喜欢开箱即用，都要自己开发很多人可能能力就不足以胜任。","like_count":0},{"had_liked":false,"id":290316,"user_name":"火锅小王子","can_delete":false,"product_type":"c1","uid":1053262,"ip_address":"","ucode":"7D1BF39C437A99","user_header":"https://static001.geekbang.org/account/avatar/00/10/12/4e/ff0702fc.jpg","comment_is_top":false,"comment_ctime":1619494917,"is_pvip":false,"replies":[{"id":"105279","content":"push还pull不影响真正的流处理","user_name":"作者回复","comment_id":290316,"uid":"1288090","ip_address":"","utype":1,"ctime":1619599622,"user_name_real":"胡夕"}],"discussion_count":1,"race_medal":0,"score":"1619494917","product_id":100029201,"comment_content":"老师好，请教下，kafka stream模型底层有应该也是采用拉模型的方式吧，这样的话还是一个轮训的过程，也就是实际上不是属于那种真正的流数据吧 ？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":519170,"discussion_content":"push还pull不影响真正的流处理","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1619599622,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":278677,"user_name":"你为啥那么牛","can_delete":false,"product_type":"c1","uid":1503506,"ip_address":"","ucode":"1ABC604A54A8F6","user_header":"https://static001.geekbang.org/account/avatar/00/16/f1/12/7dac30d6.jpg","comment_is_top":false,"comment_ctime":1613192244,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1613192244","product_id":100029201,"comment_content":"我说一下对于流处理计算不准确的问题，似乎大家对这块不太理解。什么是不准确？没有绝对的准确。即使是批处理也不敢保证准确。<br><br>流处理与批处理最大的区别就是实时性，批处理在一个处理间隔周期内，从业务角度来说，我们可以认为它所依靠的基础数据是可信可靠的，可以保证的。基于此，我们认为批处理上准确的。<br><br>但是流处理就不一样了，它是实时性的，基础数据在最终确认可信前，数据状态是一直在变化的，就比如网上买东西，购物车一直是变化的，只有你下单后，才能确定具体买了哪些。<br>","like_count":0},{"had_liked":false,"id":273192,"user_name":"时彬斌","can_delete":false,"product_type":"c1","uid":1200839,"ip_address":"","ucode":"15F9D5EFBEE3B9","user_header":"https://static001.geekbang.org/account/avatar/00/12/52/c7/f9ad5669.jpg","comment_is_top":false,"comment_ctime":1610489971,"is_pvip":false,"replies":[{"id":"99090","content":"对golang的客户端确实不太了解。。。","user_name":"作者回复","comment_id":273192,"uid":"1288090","ip_address":"","utype":1,"ctime":1610620776,"user_name_real":"胡夕"}],"discussion_count":1,"race_medal":0,"score":"1610489971","product_id":100029201,"comment_content":"老师好，请问有好用的golang版的处理streams的库推荐吗，目前用的kasper","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":513523,"discussion_content":"对golang的客户端确实不太了解。。。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1610620776,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":266087,"user_name":"Cryhard","can_delete":false,"product_type":"c1","uid":1589593,"ip_address":"","ucode":"E0BF4548B502CB","user_header":"https://static001.geekbang.org/account/avatar/00/18/41/59/78042964.jpg","comment_is_top":false,"comment_ctime":1607161449,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1607161449","product_id":100029201,"comment_content":"突然觉得，这节课的文稿封面图片和内容还是很搭的。","like_count":0},{"had_liked":false,"id":227457,"user_name":"长脖子树","can_delete":false,"product_type":"c1","uid":1182802,"ip_address":"","ucode":"D9090EF67EEB1B","user_header":"https://static001.geekbang.org/account/avatar/00/12/0c/52/f25c3636.jpg","comment_is_top":false,"comment_ctime":1592384231,"is_pvip":true,"replies":[{"id":"83829","content":"哈哈哈，谢谢~","user_name":"作者回复","comment_id":227457,"uid":"1288090","ip_address":"","utype":1,"ctime":1592403047,"user_name_real":"胡夕"}],"discussion_count":1,"race_medal":0,"score":"1592384231","product_id":100029201,"comment_content":"配图 好评 哈哈哈","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":498646,"discussion_content":"哈哈哈，谢谢~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1592403047,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":132718,"user_name":"Hello world","can_delete":false,"product_type":"c1","uid":1333607,"ip_address":"","ucode":"4D2EF3034571B7","user_header":"https://static001.geekbang.org/account/avatar/00/14/59/67/f4ba1da4.jpg","comment_is_top":false,"comment_ctime":1568201918,"is_pvip":false,"replies":[{"id":"50880","content":"不是官方的，是个人写的。目前Confluent公司在给各个connector做认证。我使用的时候还是比较久远的年代。。。","user_name":"作者回复","comment_id":132718,"uid":"1288090","ip_address":"","utype":1,"ctime":1568250322,"user_name_real":"huxi_2b"}],"discussion_count":1,"race_medal":0,"score":"1568201918","product_id":100029201,"comment_content":"老师，你使用有bug的connector是官方的还是自己写的呢？kafka stream如果要写入其他数据源，是不是就得开发自己的connector呢？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":467085,"discussion_content":"不是官方的，是个人写的。目前Confluent公司在给各个connector做认证。我使用的时候还是比较久远的年代。。。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1568250322,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":131095,"user_name":"蒙开强","can_delete":false,"product_type":"c1","uid":1317706,"ip_address":"","ucode":"61B3183781B9F7","user_header":"https://static001.geekbang.org/account/avatar/00/14/1b/4a/f9df2d06.jpg","comment_is_top":false,"comment_ctime":1567643532,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1567643532","product_id":100029201,"comment_content":"老师，你好，kafka流处理sink端的自带支持少，但可以自己用第三方包把结果写入mysql，hbase等的","like_count":0}]}