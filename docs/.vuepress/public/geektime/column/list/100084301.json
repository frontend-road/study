[{"article_id":399839,"article_title":"开篇词 | 阅读Redis源码能给你带来什么？","article_content":"<p>你好，我是蒋德钧，目前在中科院计算所任职副研究员。在2015年的时候，我和团队开始设计实现一个高性能键值数据库。为了实现这一目标，我们调研了业界常用的多种键值数据库，并选择Redis作为重点研究对象。在学习Redis的过程中，我就通读了Redis的源码，尤其是Redis的数据结构、主从复制、RDB/AOF等关键功能。</p><p>也正是通过阅读Redis源码，我发现自己对Redis的关键设计原理和机制，有了更加直接和深刻的理解。更重要的是，Redis的代码设计和实现教给了我很多计算机系统的设计思路，让我受益匪浅。</p><p>2020年，我在极客时间上开设了一门《Redis核心技术与实战》课程，来帮助同学们掌握Redis的核心原理和实战应用技术。在课程的更新和学习过程中，也有不少同学说想要了解和学习Redis源码，但是又苦于无从下手。因此时隔一年，我又带来了一个源码课程。</p><p>这门课程会从<strong>Redis源码阅读</strong>的角度出发，一方面会给你介绍Redis关键技术的代码实现，以便你能更加彻底地理解和掌握该项关键技术。另外更重要的一方面就是，我希望通过这门课程，把我当时在阅读Redis源码时，体会和掌握到的计算机单机系统和分布式系统常见的设计思想，分享给你，让你也可以把这些设计思想应用到自身的项目开发中。</p><!-- [[[read_end]]] --><p>好了，那么接下来，我就先和你聊聊阅读Redis源码能给我们带来什么，也就是为什么要学习Redis源码。</p><h2>会用Redis不就行了，为啥要读源码呢？</h2><p>平常我们在基于Redis做应用开发时，可能只是将Redis作为一个缓存系统或是数据库来存取数据，并不会接触到源码层面的东西。比如，我们在做社交应用开发时，会将用户数据、关注信息等缓存在Redis中；在开发存储系统软件时，也会用Redis保存系统元数据。</p><p>不过，我遇到过不少做开发或是运维的团队，他们在使用或运维Redis时，经常会面临Redis性能变差、Redis实例故障等问题，而这些问题都会影响到业务应用的运行。再者，经历过大厂面试的人也知道，很多互联网公司在招聘资深技术岗时，都会问一些跟Redis相关的考点问题。</p><p>也就是说，如果你不了解Redis源码层面的实现原理，那不管你是在实际开发中排查问题故障点，还是在技术面试中快速拆解问题的套路，都可能会受到阻碍。</p><p>我就举个简单的例子。Redis在运行过程中，随着保存数据的增加，会进行rehash操作，而rehash操作会对Redis的性能造成一定影响。如果我们想定位当前性能问题是否由rehash引起，我们就需要了解rehash的具体触发时机，这就包括rehash的触发条件有哪些，以及在哪些操作过程中会对这些触发条件进行判断。</p><p>可是，当我们只是了解rehash的基本原理时，我们就只是知道当哈希表的负载因子大于预设阈值后，就会开始执行rehash。但是，具体到Redis来说，我们还需要进一步了解：</p><ul>\n<li>哈希表的负载因子是怎么算的？知道了这一点，我们可以推算Redis的负载压力。</li>\n<li>除了负载因子这一条件，是否还有其他触发条件？了解这一点，可以帮助我们结合Redis运行情况，推断当前是否发生rehash。</li>\n<li>rehash触发条件的判断会在哪些函数中进行调用？了解这一点很有用，可以让我们知道在哪些操作执行过程中，会判断rehash触发条件，进而执行rehash。</li>\n</ul><p>你看，虽然从原理上说这是一个rehash操作，但一旦落到实际的性能问题排查时，我们却会面临很多的具体问题。</p><p>那么，要想解答这些问题，最好的办法就是阅读和学习Redis源码。通过学习源码，我们能<strong>进一步掌握Redis的实现细节</strong>，这带来的最明显收益就是，能了解Redis运行过程中要判断和处理的各种条件。这些细节正对应了我们在排查Redis性能、故障问题时的排查思路，可以帮助我们有章法、高效地解决问题。</p><p>另外，从我的经验来看，学习源码除了能帮助我们掌握Redis的设计细节，还能带来以下三点收获。</p><p><strong>第一，从原理到源码，学习源码阅读方法，培养源码习惯，掌握学习主动权。</strong></p><p>阅读源码本身是一个辛苦的过程，尤其是面对像Redis这样的系统软件。但是，你一旦掌握了阅读方法，进而养成了阅读习惯后，你就能从源码中掌握Redis的各种实现细节，建立对Redis的全面认识。这样一来，你就能成为一名Redis专家。</p><p>除此之外，一旦我们养成阅读源码的习惯，再遇到问题时，我们就会“条件反射”式地从源码中去寻找答案。而且，Redis的代码一直在不断迭代更新，因此更新代码所对应的工作原理有时也会发生一些变化，但是又没有材料可以及时介绍代码更新带来的变化。此时，如果我们已经习惯从代码层去理解Redis的工作机制的话，那么，我们就能在第一时间掌握Redis的新发展和新变化，并可以将其应用到实际工作中。</p><p>比如，Redis在2020年5月份推出了6.0版本，在该版本中，Redis实现了多IO线程机制。如果我们养成了阅读Redis源码的习惯，就可以尽早地了解Redis 6.0中多IO线程的具体实现，并评估其可用性。</p><p><strong>第二，学习良好的编程规范和技巧，写出高质量的代码。</strong></p><p>学习Redis源码给我们带来的第二个收获，是它提供了一个经典的、使用C语言开发的软件系统示例，可以让我们学习掌握良好的C语言编码规范和技巧。</p><p>Redis的稳定版包括2、3、4、5，以及2020年发布的6.0版本，这些版本在实际业务中都有部署使用，其代码稳定性和健壮性也都经过了考验。因此，Redis的源码是一份优秀的C语言编程学习素材。无论你是C语言的初学者，还是有经验的C语言开发者，通过学习Redis源码，都可以帮助你掌握编码规范和技巧。</p><p>比如，我们可以从Redis源码中学习功能模块单元测试的编程方法，下面的代码就显示了Redis SDS数据类型的单元测试，通过定义测试函数，以及宏定义开关，就可以实现针对SDS类型的各种操作测试。</p><pre><code>int sdsTest() {\n    ...\n}\n\n#ifdef SDS_TEST_MAIN\nint main(void) {\n    return sdsTest();\n}\n#endif\n</code></pre><p><strong>第三，举一反三，学习计算机系统设计思想，实现职业能力进阶。</strong></p><p>最后，学习Redis源码还有一个大收获，就是跟着Redis学习计算机系统的关键设计思想。Redis是一个非常经典的内存数据库，它的设计与实现涉及两类计算机系统的关键技术。</p><p>一是单机键值数据库的关键技术，包括支持高性能访问的数据结构、支持高效空间利用率的数据结构、网络服务器高并发通信、高效线程执行模型、内存管理、日志机制等。这些技术是设计和实现一个单机键值数据库时都需要考虑的问题。</p><p>二是分布式系统的关键技术，包括分布式系统主从库复制机制、可扩展集群数据切片与放置技术、可扩展集群通信机制等。</p><p>Redis在开发时，就针对上述问题进行了合理的设计和优化。因此，你通过阅读Redis源码，就可以充分学习到这些计算机系统的设计思想，并把它们应用到自身的项目开发中，这样进一步也能提升你的职业竞争力。</p><p>我画了下面这张图，显示了通过阅读Redis源码，可以学习和掌握到的计算机系统设计思想，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/d4/8f/d4d4dea857ee82360a0bb5f4cb847f8f.jpg?wh=2000x1125\" alt=\"\"></p><p>好了，到这里，你就可以发现，阅读和学习Redis源码，无论是对掌握Redis细节，成为Redis达人，还是养成源码阅读习惯，主动跟进Redis最新发展，或者是跟着Redis学习编程规范和设计思想，都大有裨益。</p><h2>如何正确学习Redis源码？</h2><p>但是，你在尝试阅读Redis源码的时候，有没有感到无从下手或是无所适从，比如说：</p><ul>\n<li>Redis源码中的功能模块很多，不清楚它们之间的逻辑关系，或是某个模块中的内容很多，很难厘清一条清晰的调用路径；</li>\n<li>花费了很多时间阅读代码，但总是抓不住重点，或者是在阅读一个函数代码时，很容易陷入细节之中，无法快速抓住代码的关键部分。</li>\n</ul><p>其实，你之所以“无从下手”的原因，是缺少了代码结构的全景图，而出现“无所适从”的问题，是缺少阅读目标的牵引和基本原理的支撑。<strong>简单来说，就是没有掌握科学、高效的代码阅读方法。</strong></p><p>根据我阅读Redis这种大型系统源码的经验，下面我就来给你提供三个锦囊妙计。</p><p><strong>高效阅读代码的第一个要点，是要先从整体上掌握源码的结构。</strong></p><p>这是因为，如果一开始就盯着一个代码文件看，这样就很容易陷入到细节中，无法从全局上了解到Redis源码的组成，也不容易分清主次。</p><p>所以，对于阅读Redis源码来说，我们就需要先形成一幅Redis源码的全景图，如下所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/59/35/5975c57d9ac404fe3a774ea28a7ac935.jpg?wh=2238x811\" alt=\"\"></p><p>有了这张图以后，我们就可以根据自己的学习需求，查找到所要学习的代码文件。然后，我们再根据Redis不同的功能特性，分线条学习每个功能特性上涉及的关键技术和设计思想。</p><p><strong>高效阅读代码的第二个要点，是一定要有目标牵引和原理支撑。</strong></p><p>Redis的功能模块很多，每个功能模块的实现也比较复杂，我们在阅读代码前一定要明确想要了解的目标，比如是想了解某个数据结构，还是想要了解主从复制的流程。</p><p>在确定目标后，我们还需要对相应的原理有所了解，然后再开始阅读源码。这是因为源码是原理的体现，如果对Redis功能的基本原理不了解，直接阅读源码，就难于理解代码逻辑，增加了代码阅读的难度。</p><p><strong>高效阅读代码的第三个要点，是要做到先主线逻辑再分支细节。</strong></p><p>虽然说源码是原理的体现，但是和原理相比，源码通常会考虑系统运行时的各种情况和细节。我看到有些开发人员在阅读源码时，一上来就阅读代码中的每个分支，然后在每个分支上又追到每个函数中细看。而不同分支上的函数往往又涉及其他处理细节，这样一来，就会导致自己既不容易理解代码的主要逻辑，又会感到代码不好读，容易气馁。</p><p>其实，我们在阅读代码时一定要先把功能模块的主线逻辑梳理出来，具体来说，就是先把代码执行路径了解清楚，其中的分支做好标记，不用一开始就逐行阅读。等主线逻辑清楚后，我们再学习不同分支的处理。</p><p>比如，我们在阅读Redis事件驱动处理框架代码时，就需要在代码中先把事件处理流程的主要步骤梳理出来，包括创建事件、监听事件、启动事件处理循环。然后，我们再去了解事件创建、监听和处理的各种细节。这样一来，代码阅读就能更加高效了。</p><p>好了，在了解了代码学习方法之后，我们可以开始深入Redis具体的源码模块当中，去学习不同功能特性的设计与实现了。</p><h2>这门课程是怎样设计的？</h2><p>说到Redis的功能特性，Redis提供了String、List、Hash、Set、Sorted Set等丰富的数据类型，同时，Redis的访问性能高，还能构建成主从集群、切片集群来分别提升Redis使用的可靠性和可扩展性。</p><p>因此，针对Redis的上述功能特性，我把这门课程分成五大模块，具体如下。</p><ul>\n<li><strong>数据结构</strong>：你将学习到Redis主要数据结构的设计思想和实现，包括字符串的实现方法、内存紧凑型结构的设计、哈希表性能优化设计，以及ziplist、quicklist、listpack、跳表的设计与实现等。</li>\n<li><strong>网络通信与执行模型</strong>：你将掌握Redis server的启动流程、高性能网络通信设计与实现、事件驱动框架的设计与实现、Redis线程类型的设计和优化等。</li>\n<li><strong>缓存</strong>：你将了解常见缓存替换算法如何从原理转变为代码。</li>\n<li><strong>可靠性保证</strong>：你将掌握RDB、AOF的具体实现，分布式系统中Raft一致性协议的设计实现，故障切换的关键代码实现等。</li>\n<li><strong>切片集群</strong>：你将学习到Redis切片集群中关键机制的设计与实现，包括Gossip通信协议、请求重定向、数据迁移等。</li>\n</ul><p>并且，在学习这五类模块中的关键源码的同时，我还会给你介绍对应的计算机系统设计思想，以便你把这些设计思想应用到自己的系统开发中。最后，我还会向你介绍Redis源码中使用的一些<strong>编程技巧</strong>，以便你学习掌握后，应用到自己的程序开发中。</p><p><img src=\"https://static001.geekbang.org/resource/image/09/24/09677e4a46d5981241821e12988fc924.jpg?wh=1563x8278\" alt=\"\"></p><h3>写在最后</h3><p>万事开头难，对于阅读源码来说，尤其是这样。Redis有上百个源码文件，源码文件中的代码动辄上千行。如果想彻底掌握Redis源码，的确需要花大量的精力和时间。</p><p>但是，掌握一个好方法，是成功做好一件事的关键。所以，在跟随学习Redis源码的过程中，希望你能掌握好我给出的三个学习要点：</p><ol>\n<li>获得代码全景图；</li>\n<li>在阅读代码前确定具体学习目标，并做好原理准备；</li>\n<li>在阅读代码时，先梳理出代码的主线逻辑，再详细学习分支细节。</li>\n</ol><p>最后，我还想正式认识一下你。你可以在留言区做个自我介绍，和我聊聊你目前使用Redis或阅读Redis的源码时，都存在哪些困难，或是都有哪些独特的思考和体验，我们一起交流讨论。</p><p>好了，让我们一起努力，开始Redis代码之旅吧。</p>","neighbors":{"left":[],"right":{"article_title":"01 | 带你快速攻略Redis源码的整体架构","id":399866}}},{"article_id":399866,"article_title":"01 | 带你快速攻略Redis源码的整体架构","article_content":"<p>你好，我是蒋德钧。从今天这节课开始，我们将开启“Redis代码之旅”，一起来掌握Redis的核心设计思想。</p><p>不过，在正式开始我们的旅程之前，还需要先做个“攻略”，也就是要了解和掌握Redis代码的整体架构。</p><p>这是因为，一旦掌握了Redis代码的整体架构，就相当于给Redis代码画了张全景图。有了这张图，我们再去学习Redis不同功能模块的设计与实现时，就可以从图上快速查找和定位这些功能模块对应的代码文件。而且，有了代码的全景图之后，我们还可以对Redis各方面的功能特性有个全面了解，这样也便于更加全面地掌握Redis的功能，而不会遗漏某一特性。</p><p>那么，我们究竟该如何学习Redis的代码架构呢？我的建议是要掌握以下两方面内容：</p><ul>\n<li><strong>代码的目录结构和作用划分</strong>，目的是理解Redis代码的整体架构，以及所包含的代码功能类别；</li>\n<li><strong>系统功能模块与对应代码文件</strong>，目的是了解Redis实例提供的各项功能及其相应的实现文件，以便后续深入学习。</li>\n</ul><p>实际上，当你掌握了以上两方面的内容之后，即使你要去了解和学习其他软件系统的代码架构，你都可以按照“先面后点”的方法来推进。也就是说，先了解目录结构与作用类别，再对应功能模块与实现文件，这样可以帮助你快速地掌握一个软件系统的代码全景。</p><!-- [[[read_end]]] --><p>所以，在后续的学习过程中，你要仔细跟住我的脚步，并且手边最好能备着一台可以方便查看源码的电脑，针对我提到的源码文件、关键模块或是代码运行，一定要实际阅读一遍或是实操一遍，这样你就能对Redis的代码架构建立更深刻的认识。</p><p>好了，话不多说，下面我们就一起来完成Redis代码之旅的攻略吧。</p><h2>Redis目录结构</h2><p>首先，我们来了解下Redis的目录结构。</p><p>为什么要从目录结构开始了解呢？其实，这是我自己<strong>阅读代码的一个小诀窍</strong>：在学习一个大型系统软件的代码时，要想快速地对代码有个初步认知，了解系统源码的整体目录结构就是一个行之有效的方法。这是因为，系统开发者通常会把完成同一或相近功能的代码文件，按目录结构来组织。能划归到同一个目录下的代码文件，一般都是具有相近功能目标的。</p><p>所以，从代码的目录结构开始学习，可以让我们从目录命名和目录层次结构中，直接了解到一个系统的主要组成部分。</p><p>那么对于Redis来说，在它的源码总目录下，一共包含了<a href=\"https://github.com/redis/redis/tree/5.0/deps\">deps</a>、<a href=\"https://github.com/redis/redis/tree/5.0/src\">src</a>、<a href=\"https://github.com/redis/redis/tree/5.0/tests\">tests</a>、<a href=\"https://github.com/redis/redis/tree/5.0/utils\">utils</a>四个子目录，这四个子目录分别对应了Redis中发挥不同作用的代码，下面我们具体来看看。</p><h3>deps目录</h3><p>这个目录主要<strong>包含了Redis依赖的第三方代码库</strong>，包括Redis的C语言版本客户端代码hiredis、jemalloc内存分配器代码、readline功能的替代代码linenoise，以及lua脚本代码。</p><p>这部分代码的一个显著特点，就是<strong>它们可以独立于Redis src目录下的功能源码进行编译</strong>，也就是说，它们可以独立于Redis存在和发展。下面这张图显示了deps目录下的子目录内容。</p><p><img src=\"https://static001.geekbang.org/resource/image/42/c7/4278463fb96f165bf41d6a97ff3216c7.jpg?wh=1945x726\" alt=\"\"></p><p>那么，为什么在Redis源码结构中会有第三方代码库目录呢？其实主要有两方面的原因。</p><p><strong>一方面</strong>，Redis作为一个用C语言写的用户态程序，它的不少功能是依赖于标准的glibc库提供的，比如内存分配、行读写（readline）、文件读写、子进程/线程创建等。但是，glibc库提供的某些功能实现，效率并不高。</p><p>我举个简单的例子，glibc库中实现的内存分配器的性能就不是很高，它的内存碎片化情况也比较严重。因此为了避免对系统性能产生影响，Redis使用了jemalloc库替换了glibc库的内存分配器。可是，jemalloc库本身又不属于Redis系统自身的功能，把它和Redis功能源码放在一个目录下并不合适，所以，Redis使用了专门的deps目录来保存这部分代码。</p><p><strong>另一方面</strong>，有些功能是Redis运行所需要的，但是这部分功能又会独立于Redis进行开发和演进。这种类型最为典型的功能代码，就是Redis的客户端代码。</p><p>Redis作为Client-Server架构的系统，访问Redis离不开客户端的支撑。此外，Redis自身功能中的命令行redis-cli、基准测试程序redis-benchmark以及哨兵，都需要用到客户端来访问Redis实例。</p><p>不过你应该也清楚，针对客户端的开发，只要保证客户端和实例交互的过程满足RESP协议就行，客户端和实例的功能可以各自迭代演进。所以在Redis源码结构中，C语言版本的客户端hiredis，就被放到了deps目录中，以便开发人员自行开发和改进客户端功能。</p><p>好了，总而言之，对于deps目录来说，你只需要记住它主要存放了三类代码：一是Redis依赖的、实现更加高效的功能库，如内存分配；二是独立于Redis开发演进的代码，如客户端；三是lua脚本代码。后续你在学习这些功能的设计实现时，就可以在deps目录找到它们。</p><h3>src目录</h3><p>这个目录里面<strong>包含了Redis所有功能模块的代码文件，也是Redis源码的重要组成部分</strong>。同样，我们先来看下src目录下的子目录结构。</p><p><img src=\"https://static001.geekbang.org/resource/image/d7/26/d7ac6b01af49047409db5d9e16b6e826.jpg?wh=2187x487\" alt=\"\"></p><p>我们会发现，src目录下只有一个modules子目录，其中包含了一个实现Redis module的示例代码。剩余的源码文件都是在src目录下，没有再分下一级子目录。</p><p>因为Redis的功能模块实现是典型的C语言风格，不同功能模块之间不再设置目录分隔，而是通过头文件包含来相互调用。这样的代码风格在基于C语言开发的系统软件中，也比较常见，比如Memcached的源码文件也是在同一级目录下。</p><p>所以，当你使用C语言来开发软件系统时，就可以参考Redis的功能源码结构，用一个扁平的目录组织所有的源码文件，这样模块相互间的引用也会很方便。</p><h3>tests目录</h3><p>在软件产品的开发过程中，除了第三方依赖库和功能模块源码以外，我们通常还需要在系统源码中，添加用于功能模块测试和单元测试的代码。而在Redis的代码目录中，就将这部分代码用一个tests目录统一管理了起来。</p><p>Redis实现的测试代码可以分成四部分，分别是<strong>单元测试</strong>（对应unit子目录），<strong>Redis Cluster功能测试</strong>（对应cluster子目录）、<strong>哨兵功能测试</strong>（对应sentinel子目录）、<strong>主从复制功能测试</strong>（对应integration子目录）。这些子目录中的测试代码使用了Tcl语言（通用的脚本语言）进行编写，主要目的就是方便进行测试。</p><p>另外，每一部分的测试都是一个测试集合，覆盖了相应功能模块中的多项子功能测试。比如，在单元测试的目录中，我们可以看到有针对过期key的测试（expire.tcl）、惰性删除的测试（lazyfree.tcl），以及不同数据类型操作的测试（type子目录）等。而在Redis Cluster功能测试的目录中，我们可以看到有针对故障切换的测试（failover.tcl）、副本迁移的测试（replica-migration.tcl）等。</p><p>不过在tests目录中，除了有针对特定功能模块的测试代码外，还有一些代码是<strong>用来支撑测试功能</strong>的，这些代码在assets、helpers、modules、support四个目录中。这里我画了这张图，展示了tests目录下的代码结构和层次，你可以参考下。</p><p><img src=\"https://static001.geekbang.org/resource/image/cc/5e/ccb2feae193e4911cc68a0ccb755ac5e.jpg?wh=2250x1111\" alt=\"\"></p><h3>utils目录</h3><p>在Redis开发过程中，还有一些功能属于辅助性功能，包括用于创建Redis Cluster的脚本、用于测试LRU算法效果的程序，以及可视化rehash过程的程序。在Redis代码结构中，这些功能代码都被归类到了utils目录中统一管理。下图展示了utils目录下的主要子目录，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/3b/b2/3b7933e5f1740ccdc3870ee554faf4b2.jpg?wh=2250x1039\" alt=\"\"></p><p>所以，当我们在开发系统时，就可以学习Redis的代码结构，也把和系统相关的辅助性功能划归到utils目录中统一管理。</p><p>好，除了deps、src、tests、utils四个子目录以外，Redis源码总目录下其实还包含了两个重要的配置文件，一个是<strong>Redis实例的配置文件redis.conf</strong>，另一个是<strong>哨兵的配置文件sentinel.conf</strong>。当你需要查找或修改Redis实例或哨兵的配置时，就可以直接定位到源码总目录下。</p><p>最后呢，你也可以再次整体回顾下Redis源码的总体结构层次，如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/59/35/5975c57d9ac404fe3a774ea28a7ac935.jpg?wh=2238x811\" alt=\"\"></p><p>好，在了解了Redis的代码目录和层次以后，接下来，我们还需要重点学习下功能模块的源码文件（即src目录下的文件内容），这有助于我们在后续课程中学习Redis的相关设计思想时，能够快速找到对应的源码文件。</p><h2>Redis功能模块与源码对应</h2><p>Redis代码结构中的src目录，包含了实现功能模块的123个代码文件。在这123个代码文件中，对于某个功能来说，一般包括了实现该功能的 <strong>C语言文件（.c文件）</strong> 和对应的<strong>头文件（.h文件）</strong>。比如，dict.c和dict.h就是用于实现哈希表的C文件和头文件。</p><blockquote>\n<p>注意：在课程中，如果没有特殊说明，我介绍的源码都是基于Redis 5.0.8版本的。</p>\n</blockquote><p>那么，我们该如何将这123个文件和Redis的主要功能对应上呢？</p><p>其实，<strong>Redis代码文件的命名非常规范，文件名中就体现了该文件实现的主要功能。</strong>比如，对于rdb.h和rdb.c这两个代码文件来说，从文件名上，你就可以看出来它们是实现内存快照RDB的对应代码。</p><p>所以这里，为了让你能快速定位源码，我分别按照Redis的服务器实例、数据库操作、可靠性和可扩展性保证、辅助功能四个维度，把Redis功能源码梳理成了四条代码路径。你可以根据自己想要了解的功能维度，对应地学习相关代码。</p><h3>服务器实例</h3><p>首先我们知道，Redis在运行时是一个网络服务器实例，因此相应地就需要有代码实现服务器实例的初始化和主体控制流程，而这是由server.h/server.c实现的，Redis整个代码的main入口函数也是在server.c中。<strong>如果你想了解Redis是如何开始运行的，那么就可以从server.c的main函数开始看起。</strong></p><p>当然，对于一个网络服务器来说，它还需要提供网络通信功能。Redis使用了<strong>基于事件驱动机制的网络通信框架</strong>，涉及的代码文件包括ae.h/ae.c，ae_epoll.c，ae_evport.c，ae_kqueue.c，ae_select.c。关于事件驱动框架的具体设计思路与实现方法，我会在第10讲中给你详细介绍。</p><p>而除了事件驱动网络框架以外，与网络通信相关的功能还包括<strong>底层TCP网络通信</strong>和<strong>客户端实现</strong>。</p><p>Redis对TCP网络通信的Socket连接、设置等操作进行了封装，这些封装后的函数实现在anet.h/anet.c中。这些函数在Redis Cluster创建和主从复制的过程中，会被调用并用于建立TCP连接。</p><p>除此之外，客户端在Redis的运行过程中也会被广泛使用，比如实例返回读取的数据、主从复制时在主从库间传输数据、Redis Cluster的切片实例通信等，都会用到客户端。Redis将客户端的创建、消息回复等功能，实现在了networking.c文件中，如果你想了解客户端的设计与实现，可以重点看下这个代码文件。</p><p>这里我也给你总结了与服务器实例相关的功能模块及对应的代码文件，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/51/df/514e63ce6947d382fe7a3152c1c989df.jpg?wh=2250x882\" alt=\"\"></p><p>那么，在了解了Redis服务器实例的主要功能代码之后，我们再从Redis内存数据库这一特性维度，来梳理下与它相关的代码文件。</p><h3>数据库数据类型与操作</h3><p>Redis数据库提供了丰富的键值对类型，其中包括了String、List、Hash、Set和Sorted Set这五种基本键值类型。此外，Redis还支持位图、HyperLogLog、Geo等扩展数据类型。</p><p>而为了支持这些数据类型，Redis就使用了多种数据结构来作为这些类型的底层结构。比如，String类型的底层数据结构是SDS，而Hash类型的底层数据结构包括哈希表和压缩列表。</p><p>不过，因为Redis实现的底层数据结构非常多，所以这里我把这些底层结构和它们对应的键值对类型，以及相应的代码文件列在了下表中，你可以用这张表来快速定位代码文件。</p><p><img src=\"https://static001.geekbang.org/resource/image/0b/57/0be4769a748a22dae5760220d9c05057.jpg?wh=2000x1125\" alt=\"\"></p><p>除了实现了诸多的数据类型以外，Redis作为数据库，还实现了对键值对的新增、查询、修改和删除等操作接口，这部分功能是在<strong>db.c文件</strong>实现的。</p><p>当然，Redis作为内存数据库，其保存的数据量受限于内存大小。因此，内存的高效使用对于Redis来说就非常重要。</p><p>那么你可能就要问了：<strong>Redis是如何优化内存使用的呢？</strong></p><p>实际上，Redis是从三个方面来优化内存使用的，分别是内存分配、内存回收，以及数据替换。</p><p>首先，在<strong>内存分配</strong>方面，Redis支持使用不同的内存分配器，包括glibc库提供的默认分配器tcmalloc、第三方库提供的jemalloc。Redis把对内存分配器的封装实现在了zmalloc.h/zmalloc.c。</p><p>其次，在<strong>内存回收</strong>上，Redis支持设置过期key，并针对过期key可以使用不同删除策略，这部分代码实现在expire.c文件中。同时，为了避免大量key删除回收内存，会对系统性能产生影响，Redis在lazyfree.c中实现了异步删除的功能，所以这样，我们就可以使用后台IO线程来完成删除，以避免对Redis主线程的影响。</p><p>最后，针对<strong>数据替换</strong>，如果内存满了，Redis还会按照一定规则清除不需要的数据，这也是Redis可以作为缓存使用的原因。Redis实现的<a href=\"https://time.geekbang.org/column/article/294640\">数据替换策略</a>有很多种，包括LRU、LFU等经典算法。这部分的代码实现在了evict.c中。</p><p>同样，这里我也把和Redis数据库数据类型与操作相关的功能模块及代码文件，总结成了一张图，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/15/f0/158fa224d6a49c7d4702ce3f07dbeff0.jpg?wh=1938x768\" alt=\"\"></p><h3>高可靠性和高可扩展性</h3><p>首先，虽然Redis一般是作为内存数据库来使用的，但是它也提供了可靠性保证，这主要体现在Redis可以对数据做持久化保存，并且它还实现了主从复制机制，从而可以提供故障恢复的功能。</p><p>这部分的代码实现比较集中，主要包括以下两个部分。</p><ul>\n<li><strong>数据持久化实现</strong></li>\n</ul><p>Redis的数据持久化实现有两种方式：<strong>内存快照RDB</strong> 和 <strong>AOF日志</strong>，分别实现在了 <strong>rdb.h/rdb.c</strong> 和 <strong>aof.c</strong> 中。</p><p>注意，在使用RDB或AOF对数据库进行恢复时，RDB和AOF文件可能会因为Redis实例所在服务器宕机，而未能完整保存，进而会影响到数据库恢复。因此针对这一问题，Redis还实现了<strong>对这两类文件的检查功能</strong>，对应的代码文件分别是redis-check-rdb.c和redis-check-aof.c。</p><ul>\n<li><strong>主从复制功能实现</strong></li>\n</ul><p>Redis把主从复制功能实现在了<strong>replication.c文件</strong>中。另外你还需要知道的是，Redis的主从集群在进行恢复时，主要是依赖于哨兵机制，而这部分功能则直接实现在了sentinel.c文件中。</p><p>其次，与Redis实现高可靠性保证的功能类似，Redis高可扩展性保证的功能，是通过<strong>Redis Cluster</strong>来实现的，这部分代码也非常集中，就是在<strong>cluster.h/cluster.c代码文件</strong>中。所以这样，我们在学习Redis Cluster的设计与实现时，就会非常方便，不用在不同的文件之间来回跳转了。</p><h3>辅助功能</h3><p>Redis还实现了一些用于支持系统运维的辅助功能。比如，为了便于运维人员查看分析不同操作的延迟产生来源，Redis在latency.h/latency.c中实现了操作延迟监控的功能；为了便于运维人员查找运行过慢的操作命令，Redis在slowlog.h/slowlog.c中实现了慢命令的记录功能，等等。</p><p>此外，运维人员有时还需要了解Redis的性能表现，为了支持这一目标，Redis实现了对系统进行性能评测的功能，这部分代码在redis-benchmark.c中。如果你想要了解如何对Redis开展性能测试，这个代码文件也值得一读。</p><h2>小结</h2><p>今天是我们了解Redis源码架构和设计思想的“热身课”，这里我们需要先明确一点，就是理解代码结构，可以为我们提供Redis功能模块的全景图，并方便我们快速查找和定位某个具体功能模块的实现源码，这样也有助于提升代码阅读的效率。</p><p>我在一开始，先给你介绍了一个<strong>小诀窍</strong>：通过目录命名和层次，来快速掌握一个系统软件的代码结构。而通过学习Redis的目录结构，我们也学到了一个<strong>重要的编程规范</strong>：在开发系统软件时，使用不同的目录对代码进行划分。</p><p>常见的目录包括保存第三方库的deps目录、保存测试用例的tests目录，以及辅助功能和工具的常用目录utils目录。按照这个规范来组织你的代码，就可以提升代码的可读性和可维护性。</p><p>另外，在学习Redis功能模块的代码结构时，面对123个代码文件，我也给你分享了一种我一直比较推崇的方法：<strong>分门别类</strong>。也就是说，按照一定的维度将所要学习的内容进行分类描述或总结。</p><p>在课程中，我是按照服务器实例、数据库数据类型与操作、高可靠与高可扩展保证，以及辅助功能四个维度，给你梳理了四条代码路径。这四条代码路径也基本涵盖了Redis的主要功能代码，可以方便你去有逻辑、有章法地学习掌握Redis源码，不至于遗漏重要代码。</p><p>那么在最后，我还想说一点，就是在你学习了Redis源码结构的同时，也希望你能把这个方法应用到其他的代码学习中，提高学习效率。</p><h2>每课一问</h2><p>Redis从4.0版本开始，能够支持后台异步执行任务，比如异步删除数据，你能在Redis功能源码中，找到实现后台任务的代码文件么？</p><p>欢迎在留言区分享你的思考和操作过程，我们一起交流讨论。如果觉得有收获的话，也欢迎你把今天的内容分享给更多的朋友。</p>","neighbors":{"left":{"article_title":"开篇词 | 阅读Redis源码能给你带来什么？","id":399839},"right":{"article_title":"02 | 键值对中字符串的实现，用char*还是结构体？","id":400314}}},{"article_id":400314,"article_title":"02 | 键值对中字符串的实现，用char*还是结构体？","article_content":"<p>你好，我是蒋德钧。</p><p>字符串在我们平时的应用开发中十分常见，比如我们要记录用户信息、商品信息、状态信息等等，这些都会用到字符串。</p><p>而对于Redis来说，键值对中的键是字符串，值有时也是字符串。我们在Redis中写入一条用户信息，记录了用户姓名、性别、所在城市等，这些都是字符串，如下所示：</p><pre><code>SET user:id:100 {“name”: “zhangsan”, “gender”: “M”,“city”:&quot;beijing&quot;}\n</code></pre><p>此外，Redis实例和客户端交互的命令和数据，也都是用字符串表示的。</p><p>那么，既然字符串的使用如此广泛和关键，就使得我们在实现字符串时，需要尽量满足以下三个要求：</p><ul>\n<li>能支持丰富且高效的字符串操作，比如字符串追加、拷贝、比较、获取长度等；</li>\n<li>能保存任意的二进制数据，比如图片等；</li>\n<li>能尽可能地节省内存开销。</li>\n</ul><p>其实，如果你开发过C语言程序，你应该就知道，在C语言中可以使用<strong>char*字符数组</strong>来实现字符串。同时，C语言标准库string.h中也定义了多种字符串的操作函数，比如字符串比较函数strcmp、字符串长度计算函数strlen、字符串追加函数strcat等，这样就便于开发者直接调用这些函数来完成字符串操作。</p><p>所以这样看起来，<strong>Redis好像完全可以复用C语言中对字符串的实现呀？</strong></p><p>但实际上，我们在使用C语言字符串时，经常需要手动检查和分配字符串空间，而这就会增加代码开发的工作量。而且，图片等数据还无法用字符串保存，也就限制了应用范围。</p><!-- [[[read_end]]] --><p>那么，从系统设计的角度来看，我们该如何设计实现字符串呢？</p><p>其实，Redis设计了<strong>简单动态字符串</strong>（Simple Dynamic String，SDS）的结构，用来表示字符串。相比于C语言中的字符串实现，SDS这种字符串的实现方式，会<strong>提升字符串的操作效率，并且可以用来保存二进制数据</strong>。</p><p>所以今天这节课，我就来给你介绍下SDS结构的设计思想和实现技巧，这样你就既可以掌握char*实现方法的不足和SDS的优势，还能学习到紧凑型内存结构的实现技巧。如果你要在自己的系统软件中实现字符串类型，就可以参考Redis的设计思想，来更好地提升操作效率，节省内存开销。</p><p>好，接下来，我们先来了解下为什么Redis没有复用C语言的字符串实现方法。</p><h2>为什么Redis不用char*？</h2><p>实际上，要想解答这个问题，我们需要先知道char*字符串数组的结构特点，还有Redis对字符串的需求是什么，所以下面我们就来具体分析一下。</p><h3>char*的结构设计</h3><p>首先，我们来看看char*字符数组的结构。</p><p><code>char*</code>字符数组的结构很简单，就是<strong>一块连续的内存空间，依次存放了字符串中的每一个字符</strong>。比如，下图显示的就是字符串“redis”的<code>char*</code>数组结构。</p><p><img src=\"https://static001.geekbang.org/resource/image/0f/03/0f8b2de0dc4b30392e155f0bdca0d003.jpg?wh=2000x608\" alt=\"\"></p><p>从图中可以看到，字符数组的最后一个字符是“\\0”，这个字符的作用是什么呢？其实，C语言在对字符串进行操作时，char*指针只是指向字符数组的起始位置，而<strong>字符数组的结尾位置就用“\\0”表示，意思是指字符串的结束</strong>。</p><p>这样一来，C语言标准库中字符串的操作函数，就会通过检查字符数组中是否有“\\0”，来判断字符串是否结束。比如，strlen函数就是一种字符串操作函数，它可以返回一个字符串的长度。这个函数会遍历字符数组中的每一个字符，并进行计数，直到检查的字符为“\\0”。此时，strlen函数会停止计数，返回已经统计到的字符个数。下图显示了strlen函数的执行流程：</p><p><img src=\"https://static001.geekbang.org/resource/image/7d/41/7de1b18d30280645c17yydf14afde541.jpg?wh=2000x1125\" alt=\"\"></p><p>我们再通过一段代码，来看下<strong>“\\0”结束字符对字符串长度的影响</strong>。这里我创建了两个字符串变量a和b，分别给它们赋值为“red\\0is”和“redis\\0”。然后，我用strlen函数计算这两个字符串长度，如下所示：</p><pre><code>\t#include &lt;stdio.h&gt;\n\t#include &lt;string.h&gt;\n\tint main()\n\t{\n\t   char *a = &quot;red\\0is&quot;;\n\t   char *b = &quot;redis\\0&quot;;\n\t   printf(&quot;%lu\\n&quot;, strlen(a));\n\t   printf(&quot;%lu\\n&quot;, strlen(b));\n\t   return 0;\n\t}\n</code></pre><p>当程序执行完这段代码后，输出的结果分别是3和5，表示a和b的长度分别是3个字符和5个字符。这是因为a中在“red”这3个字符后，就有了结束字符“\\0”，而b中的结束字符是在“redis”5个字符后。</p><p>也就是说，char*字符串以“\\0”表示字符串的结束，其实会给我们保存数据带来一定的负面影响。如果我们要保存的数据中，本身就有“\\0”，那么数据在“\\0”处就会被截断，而这就<strong>不符合Redis希望能保存任意二进制数据的需求</strong>了。</p><h3>操作函数复杂度</h3><p>而除了char*字符数组结构的设计问题以外，使用“\\0”作为字符串的结束字符，虽然可以让字符串操作函数判断字符串的结束位置，但它也会带来另一方面的负面影响，也就是会导致操作函数的复杂度增加。</p><p>我还是以strlen函数为例，该函数需要遍历字符数组中的每一个字符，才能得到字符串长度，所以这个操作函数的复杂度是O(N)。</p><p>我们再来看另一个常用的操作函数：<strong>字符串追加函数strcat</strong>。strcat函数是将一个源字符串src追加到一个目标字符串的末尾。该函数的代码如下所示：</p><pre><code>\tchar *strcat(char *dest, const char *src) {\n\t   //将目标字符串复制给tmp变量\n\t   char *tmp = dest;\n\t   //用一个while循环遍历目标字符串，直到遇到“\\0”跳出循环，指向目标字符串的末尾\n\t   while(*dest)\n\t      dest++;\n\t   //将源字符串中的每个字符逐一赋值到目标字符串中，直到遇到结束字符\n\t   while((*dest++ = *src++) != '\\0' )\n\t   return tmp;\n\t}\n</code></pre><p>从代码中可以看到，strcat函数和strlen函数类似，复杂度都很高，也都需要先通过遍历字符串才能得到目标字符串的末尾。然后对于strcat函数来说，还要再遍历源字符串才能完成追加。另外，它在把源字符串追加到目标字符串末尾时，还需要确认目标字符串具有足够的可用空间，否则就无法追加。</p><p>所以，这就要求开发人员在调用strcat时，要保证目标字符串有足够的空间，不然就需要开发人员动态分配空间，从而增加了编程的复杂度。而操作函数的复杂度一旦增加，就会影响字符串的操作效率，这就<strong>不符合Redis对字符串高效操作的需求</strong>了。</p><p>好了，综合以上在C语言中使用char*实现字符串的两大不足之处以后，我们现在就需要找到新的实现字符串的方式了。所以接下来，我们就来学习下，Redis是如何对字符串的实现进行设计考虑的。</p><h2>SDS的设计思想</h2><p>因为Redis是使用C语言开发的，所以为了保证能尽量复用C标准库中的字符串操作函数，Redis保留了使用字符数组来保存实际的数据。但是，和C语言仅用字符数组不同，Redis还专门设计了SDS（即简单动态字符串）的数据结构。下面我们一起来看看。</p><h3>SDS结构设计</h3><p>首先，SDS结构里包含了一个字符数组buf[]，用来保存实际数据。同时，SDS结构里还包含了三个元数据，分别是<strong>字符数组现有长度len</strong>、<strong>分配给字符数组的空间长度alloc</strong>，以及<strong>SDS类型flags</strong>。其中，Redis给len和alloc这两个元数据定义了多种数据类型，进而可以用来表示不同类型的SDS，稍后我会给你具体介绍。下图显示了SDS的结构，你可以先看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/77/a3/772d340bfbfe52de3a66fbb011ac22a3.jpg?wh=1891x647\" alt=\"\"></p><p>另外，如果你在Redis源码中查找过SDS的定义，那你可能会看到，Redis使用typedef给char*类型定义了一个别名，这个别名就是sds，如下所示：</p><pre><code>typedef char *sds;\n</code></pre><p>其实，这是因为SDS本质还是字符数组，只是在字符数组基础上增加了额外的元数据。在Redis中需要用到字符数组时，就直接使用sds这个别名。</p><p>同时，在创建新的字符串时，Redis会调用SDS创建函数sdsnewlen。sdsnewlen函数会新建sds类型变量（也就是char*类型变量），并新建SDS结构体，把SDS结构体中的数组buf[] 赋给sds类型变量。最后，sdsnewlen函数会把要创建的字符串拷贝给sds变量。下面的代码就显示了sdsnewlen函数的这个操作逻辑，你可以看下。</p><pre><code>sds sdsnewlen(const void *init, size_t initlen) {\n    void *sh;  //指向SDS结构体的指针\n    sds s;     //sds类型变量，即char*字符数组\n\n    ...\n    sh = s_malloc(hdrlen+initlen+1);   //新建SDS结构，并分配内存空间\n    ...\n    s = (char*)sh+hdrlen;              //sds类型变量指向SDS结构体中的buf数组，sh指向SDS结构体起始位置，hdrlen是SDS结构体中元数据的长度\n    ...\n    if (initlen &amp;&amp; init)\n        memcpy(s, init, initlen);    //将要传入的字符串拷贝给sds变量s\n    s[initlen] = '\\0';               //变量s末尾增加\\0，表示字符串结束\n    return s;\n</code></pre><p>好了，了解了SDS结构的定义后，我们再来看看，相比传统C语言字符串，SDS操作效率的改进之处。</p><h3>SDS操作效率</h3><p>因为SDS结构中记录了字符数组已占用的空间和被分配的空间，这就比传统C语言实现的字符串能带来更高的操作效率。</p><p>我还是以字符串追加操作为例。Redis中实现字符串追加的函数是sds.c文件中的<strong>sdscatlen函数</strong>。这个函数的参数一共有三个，分别是目标字符串s、源字符串t和要追加的长度len，源码如下所示：</p><pre><code>sds sdscatlen(sds s, const void *t, size_t len) {\n    //获取目标字符串s的当前长度\n    size_t curlen = sdslen(s);\n    //根据要追加的长度len和目标字符串s的现有长度，判断是否要增加新的空间\n    s = sdsMakeRoomFor(s,len);\n    if (s == NULL) return NULL;\n    //将源字符串t中len长度的数据拷贝到目标字符串结尾\n    memcpy(s+curlen, t, len);\n    //设置目标字符串的最新长度：拷贝前长度curlen加上拷贝长度\n    sdssetlen(s, curlen+len);\n    //拷贝后，在目标字符串结尾加上\\0\n    s[curlen+len] = '\\0';\n    return s;\n}\n</code></pre><p>通过分析这个函数的源码，我们可以看到sdscatlen的实现较为简单，其执行过程分为三步：</p><ul>\n<li>首先，获取目标字符串的当前长度，并调用sdsMakeRoomFor函数，根据当前长度和要追加的长度，判断是否要给目标字符串新增空间。这一步主要是保证，目标字符串有足够的空间接收追加的字符串。</li>\n<li>其次，在保证了目标字符串的空间足够后，将源字符串中指定长度len的数据追加到目标字符串。</li>\n<li>最后，设置目标字符串的最新长度。</li>\n</ul><p>我画了一张图，显示了sdscatlen的执行过程，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/84/3d/845fd7e227f419b1e6c084cdf051ec3d.jpg?wh=2000x1125\" alt=\"\"></p><p>所以，到这里你就能发现，和C语言中的字符串操作相比，SDS通过记录字符数组的使用长度和分配空间大小，避免了对字符串的遍历操作，降低了操作开销，进一步就可以帮助诸多字符串操作更加高效地完成，比如创建、追加、复制、比较等，这一设计思想非常值得我们学习。</p><p>此外，SDS把目标字符串的<strong>空间检查和扩容封装在了sdsMakeRoomFor函数中</strong>，并且在涉及字符串空间变化的操作中，如追加、复制等，会直接调用该函数。</p><p>这一设计实现，就避免了开发人员因忘记给目标字符串扩容，而导致操作失败的情况。比如，我们使用函数strcpy (char *dest, const char *src)时，如果src的长度大于dest的长度，代码中我们也没有做检查的话，就会造成内存溢出。所以这种封装操作的设计思想，同样值得我们学习。</p><p>那么，除了使用元数据记录字符串数组长度和封装操作的设计思想，SDS还有什么优秀的设计与实现值得我们学习呢？这就和我刚才给你介绍的Redis对内存节省的需求相关了。</p><p>所以接下来，我们就来看看SDS在编程技巧上是如何实现节省内存的。</p><h2>紧凑型字符串结构的编程技巧</h2><p>前面我提到，SDS结构中有一个元数据flags，表示的是SDS类型。事实上，SDS一共设计了5种类型，分别是sdshdr5、sdshdr8、sdshdr16、sdshdr32和sdshdr64。这5种类型的<strong>主要区别就在于</strong>，它们数据结构中的字符数组现有长度len和分配空间长度alloc，这两个元数据的数据类型不同。</p><p>因为sdshdr5这一类型Redis已经不再使用了，所以我们这里主要来了解下剩余的4种类型。以sdshdr8为例，它的定义如下所示：</p><pre><code>struct __attribute__ ((__packed__)) sdshdr8 {\n    uint8_t len; /* 字符数组现有长度*/\n    uint8_t alloc; /* 字符数组的已分配空间，不包括结构体和\\0结束字符*/\n    unsigned char flags; /* SDS类型*/\n    char buf[]; /*字符数组*/\n};\n</code></pre><p>我们可以看到，现有长度len和已分配空间alloc的数据类型都是uint8_t。<strong>uint8_t是8位无符号整型</strong>，会占用1字节的内存空间。当字符串类型是sdshdr8时，它能表示的字符数组长度（包括数组最后一位\\0）不会超过256字节（2的8次方等于256）。</p><p>而对于sdshdr16、sdshdr32、sdshdr64三种类型来说，它们的len和alloc数据类型分别是uint16_t、uint32_t、uint64_t，即它们能表示的字符数组长度，分别不超过2的16次方、32次方和64次方。这两个元数据各自占用的内存空间在sdshdr16、sdshdr32、sdshdr64类型中，则分别是2字节、4字节和8字节。</p><p>实际上，<strong>SDS之所以设计不同的结构头（即不同类型），是为了能灵活保存不同大小的字符串，从而有效节省内存空间。</strong>因为在保存不同大小的字符串时，结构头占用的内存空间也不一样，这样一来，在保存小字符串时，结构头占用空间也比较少。</p><p>否则，假设SDS都设计一样大小的结构头，比如都使用uint64_t类型表示len和alloc，那么假设要保存的字符串是10个字节，而此时结构头中len和alloc本身就占用了16个字节了，比保存的数据都多了。所以这样的设计对内存并不友好，也不满足Redis节省内存的需求。</p><p>好了，除了设计不同类型的结构头，Redis在编程上还<strong>使用了专门的编译优化来节省内存空间</strong>。在刚才介绍的sdshdr8结构定义中，我们可以看到，在struct和sdshdr8之间使用了<code>__attribute__ ((__packed__))</code>，如下所示：</p><pre><code>struct __attribute__ ((__packed__)) sdshdr8\n</code></pre><p>其实这里，<code>__attribute__ ((__packed__))</code>的作用就是告诉编译器，在编译sdshdr8结构时，不要使用字节对齐的方式，而是<strong>采用紧凑的方式分配内存</strong>。这是因为在默认情况下，编译器会按照8字节对齐的方式，给变量分配内存。也就是说，即使一个变量的大小不到8个字节，编译器也会给它分配8个字节。</p><p>为了方便你理解，我给你举个例子。假设我定义了一个结构体s1，它有两个成员变量，类型分别是char和int，如下所示：</p><pre><code>\t#include &lt;stdio.h&gt;\n\tint main() {\n\t   struct s1 {\n\t      char a;\n\t      int b;\n\t   } ts1;\n\t   printf(&quot;%lu\\n&quot;, sizeof(ts1));\n\t   return 0;\n\t}\n</code></pre><p>虽然char类型占用1个字节，int类型占用4个字节，但是如果你运行这段代码，就会发现打印出来的结果是8。这就是因为在默认情况下，编译器会给s1结构体分配8个字节的空间，而这样其中就有3个字节被浪费掉了。</p><p>为了节省内存，Redis在这方面的设计上可以说是精打细算的。所以，Redis采用了<code>__attribute__ ((__packed__))</code>属性定义结构体，这样一来，结构体实际占用多少内存空间，编译器就分配多少空间。</p><p>比如，我用<code>__attribute__ ((__packed__))</code>属性定义结构体s2，同样包含char和int两个类型的成员变量，代码如下所示：</p><pre><code>\t#include &lt;stdio.h&gt;\n\tint main() {\n\t   struct __attribute__((packed)) s2{\n\t      char a;\n\t      int b;\n\t   } ts2;\n\t   printf(&quot;%lu\\n&quot;, sizeof(ts2));\n\t   return 0;\n\t}\n</code></pre><p>当你运行这段代码时，你可以看到，打印的结果是5，表示编译器用了紧凑型内存分配，s2结构体只占用5个字节的空间。</p><p>好了，总而言之，如果你在开发程序时，希望能节省数据结构的内存开销，就可以把<code>__attribute__ ((__packed__))</code>这个编程方法用起来。</p><h2>小结</h2><p>这节课我主要给你介绍了Redis中字符串的设计与实现。你要知道，字符串的实现需要考虑操作高效、能保存任意二进制数据，以及节省内存的需求。而Redis中设计实现字符串的方式，就非常值得你学习和借鉴。</p><p>因此这节课，你需要重点关注三个要点，分别是：</p><ul>\n<li>C语言中使用char*实现字符串的不足，主要是因为使用“\\0”表示字符串结束，操作时需遍历字符串，效率不高，并且无法完整表示包含“\\0”的数据，因而这就无法满足Redis的需求。</li>\n<li>Redis中字符串的设计思想与实现方法。Redis专门设计了SDS数据结构，在字符数组的基础上，增加了字符数组长度和分配空间大小等元数据。这样一来，需要基于字符串长度进行的追加、复制、比较等操作，就可以直接读取元数据，效率也就提升了。而且，SDS不通过字符串中的“\\0”字符判断字符串结束，而是直接将其作为二进制数据处理，可以用来保存图片等二进制数据。</li>\n<li>SDS中是通过设计不同SDS类型来表示不同大小的字符串，并使用<code>__attribute__ ((__packed__))</code>这个编程小技巧，来实现紧凑型内存布局，达到节省内存的目的。</li>\n</ul><p>字符串看起来简单，但通过今天这节课的学习，你可以看到实现字符串有很多需要精巧设计的地方。C语言字符串的实现方法和SDS的联系与区别，也是Redis面试时经常会被问到的问题，所以我也希望你能通过今天这节课，掌握好它俩的区别。</p><h2>每课一问</h2><p>SDS字符串在Redis内部模块实现中也被广泛使用，你能在Redis server和客户端的实现中，找到使用SDS字符串的地方么？</p><p>欢迎在留言区分享你的思考和操作过程，我们一起交流讨论。如果觉得有收获，也欢迎你把今天的内容分享给更多的朋友。</p>","neighbors":{"left":{"article_title":"01 | 带你快速攻略Redis源码的整体架构","id":399866},"right":{"article_title":"03 | 如何实现一个性能优异的Hash表？","id":400379}}},{"article_id":400379,"article_title":"03 | 如何实现一个性能优异的Hash表？","article_content":"<p>你好，我是蒋德钧。今天，我们来聊聊Redis中的Hash。</p><p>我们知道，Hash表是一种非常关键的数据结构，在计算机系统中发挥着重要作用。比如在Memcached中，Hash表被用来索引数据；在数据库系统中，Hash表被用来辅助SQL查询。而对于Redis键值数据库来说，Hash表既是键值对中的一种值类型，同时，Redis也使用一个全局Hash表来保存所有的键值对，从而既满足应用存取Hash结构数据需求，又能提供快速查询功能。</p><p>那么，Hash表应用如此广泛的一个重要原因，就是从理论上来说，它能以O(1)的复杂度快速查询数据。Hash表通过Hash函数的计算，就能定位数据在表中的位置，紧接着可以对数据进行操作，这就使得数据操作非常快速。</p><p>Hash表这个结构也并不难理解，但是在实际应用Hash表时，当数据量不断增加，它的性能就经常会受到<strong>哈希冲突</strong>和<strong>rehash开销</strong>的影响。而这两个问题的核心，其实都来自于Hash表要保存的数据量，超过了当前Hash表能容纳的数据量。</p><p>那么要如何应对这两个问题呢？事实上，这也是在大厂面试中，面试官经常会考核的问题。所以你现在可以先想想，如果你在面试中遇到了这两个问题，你会怎么回答呢？</p><!-- [[[read_end]]] --><p>OK，思考先到这里，现在我来告诉你Redis是怎么很好地解决这两个问题的。</p><p>Redis为我们提供了一个经典的Hash表实现方案。针对哈希冲突，Redis采用了<strong>链式哈希</strong>，在不扩容哈希表的前提下，将具有相同哈希值的数据链接起来，以便这些数据在表中仍然可以被查询到；对于rehash开销，Redis实现了<strong>渐进式rehash设计</strong>，进而缓解了rehash操作带来的额外开销对系统的性能影响。</p><p>所以这节课，我就带你来学习Redis中针对Hash表的设计思路和实现方法，帮助你掌握应对哈希冲突和优化rehash操作性能的能力，并以此支撑你在实际使用Hash表保存大量数据的场景中，可以实现高性能的Hash表。</p><p>好了，接下来，我们就先来聊聊链式哈希的设计与实现。</p><h2>Redis如何实现链式哈希？</h2><p>不过，在开始学习链式哈希的设计实现之前，我们还需要明白Redis中Hash表的结构设计是啥样的，以及为何会在数据量增加时产生哈希冲突，这样也更容易帮助我们理解链式哈希应对哈希冲突的解决思路。</p><h3>什么是哈希冲突？</h3><p>实际上，一个最简单的Hash表就是一个数组，数组里的每个元素是一个哈希桶（也叫做Bucket），第一个数组元素被编为哈希桶0，以此类推。当一个键值对的键经过Hash函数计算后，再对数组元素个数取模，就能得到该键值对对应的数组元素位置，也就是第几个哈希桶。</p><p>如下图所示，key1经过哈希计算和哈希值取模后，就对应哈希桶1，类似的，key3和key16分别对应哈希桶7和桶4。</p><p><img src=\"https://static001.geekbang.org/resource/image/08/2f/08ac157a8fbf4d22f8a5217bfea79a2f.jpg?wh=2000x1029\" alt=\"\"></p><p>从图上我们还可以看到，需要写入Hash表的键空间一共有16个键，而Hash表的空间大小只有8个元素，这样就会导致有些键会对应到相同的哈希桶中。</p><p>我们在实际应用Hash表时，其实一般很难预估要保存的数据量，如果我们一开始就创建一个非常大的哈希表，当数据量较小时，就会造成空间浪费。所以，我们通常会给哈希表设定一个初始大小，而当数据量增加时，键空间的大小就会大于Hash表空间大小了。</p><p>也正是由于键空间会大于Hash表空间，这就导致在用Hash函数把键映射到Hash表空间时，不可避免地会出现不同的键被映射到数组的同一个位置上。而如果同一个位置只能保存一个键值对，就会导致Hash表保存的数据非常有限，这就是我们常说的<strong>哈希冲突</strong>。</p><p>比如下图中，key3和key100都被映射到了Hash表的桶5中，这样，当桶5只能保存一个key时，key3和key100就会有一个key无法保存到哈希表中了。</p><p><img src=\"https://static001.geekbang.org/resource/image/04/d8/04322775d11cea97049bcd4dd8109bd8.jpg?wh=2000x889\" alt=\"\"></p><p>那么我们该如何解决哈希冲突呢？可以考虑使用以下两种解决方案：</p><ul>\n<li>第一种方案，就是我接下来要给你介绍的<strong>链式哈希</strong>。这里你需要先知道，链式哈希的链不能太长，否则会降低Hash表性能。</li>\n<li>第二种方案，就是当链式哈希的链长达到一定长度时，我们可以使用<strong>rehash</strong>。不过，执行rehash本身开销比较大，所以就需要采用我稍后会给你介绍的渐进式rehash设计。</li>\n</ul><p>这里，我们先来了解链式哈希的设计和实现。</p><h3>链式哈希如何设计与实现？</h3><p>所谓的链式哈希，就是<strong>用一个链表把映射到Hash表同一桶中的键给连接起来</strong>。下面我们就来看看Redis是如何实现链式哈希的，以及为何链式哈希能够帮助解决哈希冲突。</p><p>首先，我们需要了解Redis源码中对Hash表的实现。Redis中和Hash表实现相关的文件主要是<strong>dict.h</strong>和<strong>dict.c</strong>。其中，dict.h文件定义了Hash表的结构、哈希项，以及Hash表的各种操作函数，而dict.c文件包含了Hash表各种操作的具体实现代码。</p><p>在dict.h文件中，Hash表被定义为一个二维数组（dictEntry **table），这个数组的每个元素是一个指向哈希项（dictEntry）的指针。下面的代码展示的就是在dict.h文件中对Hash表的定义，你可以看下：</p><pre><code>typedef struct dictht {\n    dictEntry **table; //二维数组\n    unsigned long size; //Hash表大小\n    unsigned long sizemask;\n    unsigned long used;\n} dictht;\n</code></pre><p>那么为了实现链式哈希， Redis在每个dictEntry的结构设计中，<strong>除了包含指向键和值的指针，还包含了指向下一个哈希项的指针</strong>。如下面的代码所示，dictEntry结构体中包含了指向另一个dictEntry结构的<strong>指针*next</strong>，这就是用来实现链式哈希的：</p><pre><code>typedef struct dictEntry {\n    void *key;\n    union {\n        void *val;\n        uint64_t u64;\n        int64_t s64;\n        double d;\n    } v;\n    struct dictEntry *next;\n} dictEntry;\n</code></pre><p>除了用于实现链式哈希的指针外，这里还有一个值得注意的地方，就是在dictEntry结构体中，键值对的值是由一个<strong>联合体v</strong>定义的。这个联合体v中包含了指向实际值的指针*val，还包含了无符号的64位整数、有符号的64位整数，以及double类的值。</p><p>我之所以要提醒你注意这里，其实是为了说明，<strong>这种实现方法是一种节省内存的开发小技巧</strong>，非常值得学习。因为当值为整数或双精度浮点数时，由于其本身就是64位，就可以不用指针指向了，而是可以直接存在键值对的结构体中，这样就避免了再用一个指针，从而节省了内存空间。</p><p>好了，那么到这里，你应该就了解了Redis中链式哈希的实现，不过现在你可能还是不太明白，为什么这种链式哈希可以帮助解决哈希冲突呢？</p><p>别着急，我就拿刚才的例子来说明一下，key3和key100都被映射到了Hash表的桶5中。而当使用了链式哈希，桶5就不会只保存key3或key100，而是会用一个链表把key3和key100连接起来，如下图所示。当有更多的key被映射到桶5时，这些key都可以用链表串接起来，以应对哈希冲突。</p><p><img src=\"https://static001.geekbang.org/resource/image/28/85/281919546bb9cf97cd70718072389585.jpg?wh=2000x866\" alt=\"\"></p><p>这样，当我们要查询key100时，可以先通过哈希函数计算，得到key100的哈希值被映射到了桶5中。然后，我们再逐一比较桶5中串接的key，直到查找到key100。如此一来，我们就能在链式哈希中找到所查的哈希项了。</p><p>不过，链式哈希也存在局限性，那就是随着链表长度的增加，Hash表在一个位置上查询哈希项的耗时就会增加，从而增加了Hash表的整体查询时间，这样也会导致Hash表的性能下降。</p><p>那么，有没有什么其他的方法可以减少对Hash表性能的影响呢？当然是有的，这就是接下来我要给你介绍的rehash的设计与实现了。</p><h2>Redis如何实现rehash？</h2><p>rehash操作，其实就是指扩大Hash表空间。而Redis实现rehash的基本思路是这样的：</p><ul>\n<li>首先，Redis准备了两个哈希表，用于rehash时交替保存数据。</li>\n</ul><p>我在前面给你介绍过，Redis在dict.h文件中使用dictht结构体定义了Hash表。不过，在实际使用Hash表时，Redis又在dict.h文件中，定义了一个dict结构体。这个结构体中有一个数组（ht[2]），包含了两个Hash表ht[0]和ht[1]。dict结构体的代码定义如下所示：</p><pre><code>typedef struct dict {\n    …\n    dictht ht[2]; //两个Hash表，交替使用，用于rehash操作\n    long rehashidx; //Hash表是否在进行rehash的标识，-1表示没有进行rehash\n    …\n} dict;\n</code></pre><ul>\n<li>其次，在正常服务请求阶段，所有的键值对写入哈希表ht[0]。</li>\n<li>接着，当进行rehash时，键值对被迁移到哈希表ht[1]中。</li>\n<li>最后，当迁移完成后，ht[0]的空间会被释放，并把ht[1]的地址赋值给ht[0]，ht[1]的表大小设置为0。这样一来，又回到了正常服务请求的阶段，ht[0]接收和服务请求，ht[1]作为下一次rehash时的迁移表。</li>\n</ul><p>这里我画了一张图，以便于你理解ht[0]和ht[1]交替使用的过程。</p><p><img src=\"https://static001.geekbang.org/resource/image/1b/7f/1bc5b729yy127de43e0548ce0b6e6c7f.jpg?wh=2000x1125\" alt=\"\"></p><p>好，那么在了解了Redis交替使用两个Hash表实现rehash的基本思路后，我们还需要明确的是：在实现rehash时，都需要解决哪些问题？我认为主要有以下三点：</p><ul>\n<li>什么时候触发rehash？</li>\n<li>rehash扩容扩多大？</li>\n<li>rehash如何执行？</li>\n</ul><p>所以下面，我就带你来逐一学习Redis对这三个问题的代码实现，通过代码实现，你就能明晰Redis针对这三个问题的设计思想了。</p><h3>什么时候触发rehash？</h3><p>首先要知道，Redis用来判断是否触发rehash的函数是<strong> _dictExpandIfNeeded</strong>。所以接下来我们就先看看，_dictExpandIfNeeded函数中进行扩容的触发条件；然后，我们再来了解下_dictExpandIfNeeded又是在哪些函数中被调用的。</p><p>实际上，_dictExpandIfNeeded函数中定义了三个扩容条件。</p><ul>\n<li>条件一：ht[0]的大小为0。</li>\n<li>条件二：ht[0]承载的元素个数已经超过了ht[0]的大小，同时Hash表可以进行扩容。</li>\n<li>条件三：ht[0]承载的元素个数，是ht[0]的大小的dict_force_resize_ratio倍，其中，dict_force_resize_ratio的默认值是5。</li>\n</ul><p>下面的代码就展示了_dictExpandIfNeeded函数对这三个条件的定义，你可以看下。</p><pre><code>//如果Hash表为空，将Hash表扩为初始大小\nif (d-&gt;ht[0].size == 0) \n   return dictExpand(d, DICT_HT_INITIAL_SIZE);\n \n//如果Hash表承载的元素个数超过其当前大小，并且可以进行扩容，或者Hash表承载的元素个数已是当前大小的5倍\nif (d-&gt;ht[0].used &gt;= d-&gt;ht[0].size &amp;&amp;(dict_can_resize ||\n              d-&gt;ht[0].used/d-&gt;ht[0].size &gt; dict_force_resize_ratio))\n{\n    return dictExpand(d, d-&gt;ht[0].used*2);\n}\n</code></pre><p>那么，对于条件一来说，此时Hash表是空的，所以Redis就需要将Hash表空间设置为初始大小，而这是初始化的工作，并不属于rehash操作。</p><p>而条件二和三就对应了rehash的场景。因为在这两个条件中，都比较了Hash表当前承载的元素个数（d-&gt;ht[0].used）和Hash表当前设定的大小（d-&gt;ht[0].size），这两个值的比值一般称为<strong>负载因子（load factor）</strong>。也就是说，Redis判断是否进行rehash的条件，就是看load factor是否大于等于1和是否大于5。</p><p>实际上，当load factor大于5时，就表明Hash表已经过载比较严重了，需要立刻进行库扩容。而当load factor大于等于1时，Redis还会再判断dict_can_resize这个变量值，查看当前是否可以进行扩容。</p><p>你可能要问了，这里的dict_can_resize变量值是啥呀？其实，这个变量值是在dictEnableResize和dictDisableResize两个函数中设置的，它们的作用分别是启用和禁止哈希表执行rehash功能，如下所示：</p><pre><code>void dictEnableResize(void) {\n    dict_can_resize = 1;\n}\n \nvoid dictDisableResize(void) {\n    dict_can_resize = 0;\n}\n</code></pre><p>然后，这两个函数又被封装在了updateDictResizePolicy函数中。</p><p>updateDictResizePolicy函数是用来启用或禁用rehash扩容功能的，这个函数调用dictEnableResize函数启用扩容功能的条件是：<strong>当前没有RDB子进程，并且也没有AOF子进程。</strong>这就对应了Redis没有执行RDB快照和没有进行AOF重写的场景。你可以参考下面给出的代码：</p><pre><code>void updateDictResizePolicy(void) {\n    if (server.rdb_child_pid == -1 &amp;&amp; server.aof_child_pid == -1)\n        dictEnableResize();\n    else\n        dictDisableResize();\n}\n</code></pre><p>好，到这里我们就了解了_dictExpandIfNeeded对rehash的判断触发条件，那么现在，我们再来看下Redis会在哪些函数中，调用_dictExpandIfNeeded进行判断。</p><p>首先，通过在<a href=\"https://github.com/redis/redis/blob/5.0/src/dict.c\">dict.c</a>文件中查看_dictExpandIfNeeded的被调用关系，我们可以发现，_dictExpandIfNeeded是被_dictKeyIndex函数调用的，而_dictKeyIndex函数又会被dictAddRaw函数调用，然后dictAddRaw会被以下三个函数调用。</p><ul>\n<li>dictAdd：用来往Hash表中添加一个键值对。</li>\n<li>dictRelace：用来往Hash表中添加一个键值对，或者键值对存在时，修改键值对。</li>\n<li>dictAddorFind：直接调用dictAddRaw。</li>\n</ul><p>因此，当我们往Redis中写入新的键值对或是修改键值对时，Redis都会判断下是否需要进行rehash。这里你可以参考下面给出的示意图，其中就展示了_dictExpandIfNeeded被调用的关系。</p><p><img src=\"https://static001.geekbang.org/resource/image/90/11/90c261fce9dfe604e29239ba283cef11.jpg?wh=2000x969\" alt=\"\"></p><p>好了，简而言之，Redis中触发rehash操作的关键，就是_dictExpandIfNeeded函数和updateDictResizePolicy函数。<strong>_dictExpandIfNeeded函数</strong>会根据Hash表的负载因子以及能否进行rehash的标识，判断是否进行rehash，而<strong>updateDictResizePolicy函数</strong>会根据RDB和AOF的执行情况，启用或禁用rehash。</p><p>接下来，我们继续探讨Redis在实现rehash时，要解决的第二个问题：rehash扩容扩多大？</p><h3>rehash扩容扩多大？</h3><p>在Redis中，rehash对Hash表空间的扩容是通过<strong>调用dictExpand函数</strong>来完成的。dictExpand函数的参数有两个，<strong>一个是要扩容的Hash表，另一个是要扩到的容量</strong>，下面的代码就展示了dictExpand函数的原型定义：</p><pre><code>int dictExpand(dict *d, unsigned long size);\n</code></pre><p>那么，对于一个Hash表来说，我们就可以根据前面提到的_dictExpandIfNeeded函数，来判断是否要对其进行扩容。而一旦判断要扩容，Redis在执行rehash操作时，对Hash表扩容的思路也很简单，就是<strong>如果当前表的已用空间大小为size，那么就将表扩容到size*2的大小。</strong></p><p>如下所示，当_dictExpandIfNeeded函数在判断了需要进行rehash后，就调用dictExpand进行扩容。这里你可以看到，rehash的扩容大小是当前ht[0]已使用大小的2倍。</p><pre><code>dictExpand(d, d-&gt;ht[0].used*2);\n</code></pre><p>而在dictExpand函数中，具体执行是由_dictNextPower函数完成的，以下代码显示的Hash表扩容的操作，就是从Hash表的初始大小（DICT_HT_INITIAL_SIZE），不停地乘以2，直到达到目标大小。</p><pre><code>static unsigned long _dictNextPower(unsigned long size)\n{\n    //哈希表的初始大小\n    unsigned long i = DICT_HT_INITIAL_SIZE;\n    //如果要扩容的大小已经超过最大值，则返回最大值加1\n    if (size &gt;= LONG_MAX) return LONG_MAX + 1LU;\n    //扩容大小没有超过最大值\n    while(1) {\n        //如果扩容大小大于等于最大值，就返回截至当前扩到的大小\n        if (i &gt;= size)\n            return i;\n        //每一步扩容都在现有大小基础上乘以2\n        i *= 2;\n    }\n}\n</code></pre><p>好，下面我们再来看看Redis要解决的第三个问题，即rehash要如何执行？而这个问题，本质上就是Redis要如何实现渐进式rehash设计。</p><h3>渐进式rehash如何实现？</h3><p>那么这里，我们要先搞清楚一个问题，就是<strong>为什么要实现渐进式rehash？</strong></p><p>其实这是因为，Hash表在执行rehash时，由于Hash表空间扩大，原本映射到某一位置的键可能会被映射到一个新的位置上，因此，很多键就需要从原来的位置拷贝到新的位置。而在键拷贝时，由于Redis主线程无法执行其他请求，所以键拷贝会阻塞主线程，这样就会产生<strong>rehash开销</strong>。</p><p>而为了降低rehash开销，Redis就提出了渐进式rehash的方法。</p><p>简单来说，渐进式rehash的意思就是Redis并不会一次性把当前Hash表中的所有键，都拷贝到新位置，而是会分批拷贝，每次的键拷贝只拷贝Hash表中一个bucket中的哈希项。这样一来，每次键拷贝的时长有限，对主线程的影响也就有限了。</p><p><strong>那么，渐进式rehash在代码层面是如何实现的呢？</strong>这里有两个关键函数：dictRehash和_dictRehashStep。</p><p>我们先来看<strong>dictRehash函数</strong>，这个函数实际执行键拷贝，它的输入参数有两个，分别是全局哈希表（即前面提到的dict结构体，包含了ht[0]和ht[1]）和需要进行键拷贝的桶数量（bucket数量）。</p><p>dictRehash函数的整体逻辑包括两部分：</p><ul>\n<li>首先，该函数会执行一个循环，根据要进行键拷贝的bucket数量n，依次完成这些bucket内部所有键的迁移。当然，如果ht[0]哈希表中的数据已经都迁移完成了，键拷贝的循环也会停止执行。</li>\n<li>其次，在完成了n个bucket拷贝后，dictRehash函数的第二部分逻辑，就是判断ht[0]表中数据是否都已迁移完。如果都迁移完了，那么ht[0]的空间会被释放。因为Redis在处理请求时，代码逻辑中都是使用ht[0]，所以当rehash执行完成后，虽然数据都在ht[1]中了，但Redis仍然会把ht[1]赋值给ht[0]，以便其他部分的代码逻辑正常使用。</li>\n<li>而在ht[1]赋值给ht[0]后，它的大小就会被重置为0，等待下一次rehash。与此同时，全局哈希表中的rehashidx变量会被标为-1，表示rehash结束了（这里的rehashidx变量用来表示rehash的进度，稍后我会给你具体解释）。</li>\n</ul><p>我画了下面这张图，展示了dictRehash的主要执行流程，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/e5/d1/e54b90dc143ba7e6eae2cda418ce20d1.jpg?wh=2000x1125\" alt=\"\"></p><p>同时，你也可以通过下面代码，来了解dictRehash函数的主要执行逻辑。</p><pre><code>int dictRehash(dict *d, int n) {\n    int empty_visits = n*10;\n    ...\n    //主循环，根据要拷贝的bucket数量n，循环n次后停止或ht[0]中的数据迁移完停止\n    while(n-- &amp;&amp; d-&gt;ht[0].used != 0) {\n       ...\n    }\n    //判断ht[0]的数据是否迁移完成\n    if (d-&gt;ht[0].used == 0) {\n        //ht[0]迁移完后，释放ht[0]内存空间\n        zfree(d-&gt;ht[0].table);\n        //让ht[0]指向ht[1]，以便接受正常的请求\n        d-&gt;ht[0] = d-&gt;ht[1];\n        //重置ht[1]的大小为0\n        _dictReset(&amp;d-&gt;ht[1]);\n        //设置全局哈希表的rehashidx标识为-1，表示rehash结束\n        d-&gt;rehashidx = -1;\n        //返回0，表示ht[0]中所有元素都迁移完\n        return 0;\n    }\n    //返回1，表示ht[0]中仍然有元素没有迁移完\n    return 1;\n}\n</code></pre><p>好，在了解了dictRehash函数的主体逻辑后，我们再看下渐进式rehash是如何按照bucket粒度拷贝数据的，这其实就和全局哈希表dict结构中的rehashidx变量相关了。</p><p>rehashidx变量表示的是<strong>当前rehash在对哪个bucket做数据迁移</strong>。比如，当rehashidx等于0时，表示对ht[0]中的第一个bucket进行数据迁移；当rehashidx等于1时，表示对ht[0]中的第二个bucket进行数据迁移，以此类推。</p><p>而dictRehash函数的主循环，首先会判断rehashidx指向的bucket是否为空，如果为空，那就将rehashidx的值加1，检查下一个bucket。</p><p><strong>那么，有没有可能连续几个bucket都为空呢？</strong>其实是有可能的，在这种情况下，渐进式rehash不会一直递增rehashidx进行检查。这是因为一旦执行了rehash，Redis主线程就无法处理其他请求了。</p><p>所以，渐进式rehash在执行时设置了一个<strong>变量empty_visits</strong>，用来表示已经检查过的空bucket，当检查了一定数量的空bucket后，这一轮的rehash就停止执行，转而继续处理外来请求，避免了对Redis性能的影响。下面的代码显示了这部分逻辑，你可以看下。</p><pre><code>while(n-- &amp;&amp; d-&gt;ht[0].used != 0) {\n    //如果当前要迁移的bucket中没有元素\n    while(d-&gt;ht[0].table[d-&gt;rehashidx] == NULL) {\n        //\n        d-&gt;rehashidx++;\n        if (--empty_visits == 0) return 1;\n    }\n    ...\n}\n</code></pre><p>而如果rehashidx指向的bucket有数据可以迁移，那么Redis就会把这个bucket中的哈希项依次取出来，并根据ht[1]的表空间大小，重新计算哈希项在ht[1]中的bucket位置，然后把这个哈希项赋值到ht[1]对应bucket中。</p><p>这样，每做完一个哈希项的迁移，ht[0]和ht[1]用来表示承载哈希项多少的变量used，就会分别减一和加一。当然，如果当前rehashidx指向的bucket中数据都迁移完了，rehashidx就会递增加1，指向下一个bucket。下面的代码显示了这一迁移过程。</p><pre><code>while(n-- &amp;&amp; d-&gt;ht[0].used != 0) {\n    ...\n    //获得哈希表中哈希项\n    de = d-&gt;ht[0].table[d-&gt;rehashidx];\n    //如果rehashidx指向的bucket不为空\n    while(de) {\n        uint64_t h;\n        //获得同一个bucket中下一个哈希项\n        nextde = de-&gt;next;\n        //根据扩容后的哈希表ht[1]大小，计算当前哈希项在扩容后哈希表中的bucket位置\n        h = dictHashKey(d, de-&gt;key) &amp; d-&gt;ht[1].sizemask;\n        //将当前哈希项添加到扩容后的哈希表ht[1]中\n        de-&gt;next = d-&gt;ht[1].table[h];\n        d-&gt;ht[1].table[h] = de;\n        //减少当前哈希表的哈希项个数\n        d-&gt;ht[0].used--;\n        //增加扩容后哈希表的哈希项个数\n        d-&gt;ht[1].used++;\n        //指向下一个哈希项\n        de = nextde;\n    }\n    //如果当前bucket中已经没有哈希项了，将该bucket置为NULL\n    d-&gt;ht[0].table[d-&gt;rehashidx] = NULL;\n    //将rehash加1，下一次将迁移下一个bucket中的元素\n    d-&gt;rehashidx++;\n}\n</code></pre><p>好了，到这里，我们就已经基本了解了dictRehash函数的全部逻辑。</p><p>现在我们知道，dictRehash函数本身是按照bucket粒度执行哈希项迁移的，它内部执行的bucket迁移个数，主要由传入的循环次数变量n来决定。但凡Redis要进行rehash操作，最终都会调用dictRehash函数。</p><p>接下来，我们来学习和渐进式rehash相关的第二个关键函数<strong> _dictRehashStep</strong>，这个函数实现了每次只对一个bucket执行rehash。</p><p>从Redis的源码中我们可以看到，一共会有5个函数通过调用_dictRehashStep函数，进而调用dictRehash函数，来执行rehash，它们分别是：dictAddRaw，dictGenericDelete，dictFind，dictGetRandomKey，dictGetSomeKeys。</p><p>其中，dictAddRaw和dictGenericDelete函数，分别对应了往Redis中增加和删除键值对，而后三个函数则对应了在Redis中进行查询操作。下图展示了这些函数间的调用关系：</p><p><img src=\"https://static001.geekbang.org/resource/image/05/0a/050cdce01b19a8d03834c18d1feab20a.jpg?wh=2000x820\" alt=\"\"></p><p>但你要注意，不管是增删查哪种操作，这5个函数调用的_dictRehashStep函数，给dictRehash传入的循环次数变量n的值都为1，下面的代码就显示了这一传参的情况。</p><pre><code>static void _dictRehashStep(dict *d) {\n//给dictRehash传入的循环次数参数为1，表明每迁移完一个bucket ，就执行正常操作\n    if (d-&gt;iterators == 0) dictRehash(d,1);\n}\n</code></pre><p>这样一来，每次迁移完一个bucket，Hash表就会执行正常的增删查请求操作，这就是在代码层面实现渐进式rehash的方法。</p><h2>小结</h2><p>实现一个高性能的Hash表不仅是Redis的需求，也是很多计算机系统开发过程中的重要目标。而要想实现一个性能优异的Hash表，就需要重点解决哈希冲突和rehash开销这两个问题。</p><p>今天这节课，我带你学习了Redis中Hash表的结构设计、链式哈希方法的实现，以及渐进式rehash方法的设计实现。Redis中Hash表的结构设计很特别，它的每个哈希项都包含了一个指针，用于实现链式哈希。同时，Redis在全局哈希表中还包含了两个Hash表，这种设计思路也是为了在实现rehash时，帮助数据从一个表迁移到另一个表。</p><p>此外，Redis实现的渐进式rehash是一个用于Hash表扩容的通用方法，非常值得我们学习。这个设计方法的关键是每次仅迁移有限个数的bucket，避免一次性迁移给所有bucket带来的性能影响。当你掌握了渐进式rehash这个设计思想和实现方法，你就可以把它应用到自己的Hash表实现场景中。</p><h2>每课一问</h2><p>Hash函数会影响Hash表的查询效率及哈希冲突情况，那么，你能从Redis的源码中，找到Hash表使用的是哪一种Hash函数吗？</p><p>欢迎在留言区分享你的答案，如果觉得有收获，也欢迎你把今天的内容分享给更多的朋友。</p>","neighbors":{"left":{"article_title":"02 | 键值对中字符串的实现，用char*还是结构体？","id":400314},"right":{"article_title":"04 | 内存友好的数据结构该如何细化设计？","id":402223}}},{"article_id":402223,"article_title":"04 | 内存友好的数据结构该如何细化设计？","article_content":"<p>你好，我是蒋德钧。今天我们来聊聊，Redis中是如何通过优化设计数据结构，来提升内存利用率的。</p><p>我们知道Redis是内存数据库，所以，高效使用内存对Redis的实现来说非常重要。而实际上，Redis主要是通过两大方面的技术来提升内存使用效率的，分别是<strong>数据结构的优化设计与使用</strong>，以及<strong>内存数据按一定规则淘汰</strong>。</p><p>关于内存数据按规则淘汰，这是通过Redis内存替换策略实现的，也就是将很少使用的数据从内存中淘汰，从而把有限的内存空间用于保存会被频繁访问的数据。这部分的设计与实现，主要和内存替换策略有关，我会在后面的缓存模块给你详细介绍。</p><p>所以这节课，我主要是带你学习Redis数据结构在面向内存使用效率方面的优化，其中包括两方面的设计思路：一是<strong>内存友好的数据结构设计</strong>；二是<strong>内存友好的数据使用方式</strong>。</p><p>这两方面的设计思路和实现方法是具有通用性的，当你在设计系统软件时，如果需要对内存使用精打细算，以便节省内存开销，这两种设计方法和实现考虑就非常值得学习和掌握。</p><p>好，接下来，我们就先来学习下内存友好的数据结构设计。</p><h2>内存友好的数据结构</h2><p>首先要知道，在Redis中，有三种数据结构针对内存使用效率做了设计优化，分别是简单动态字符串（SDS）、压缩列表（ziplist）和整数集合（intset）。下面，我们就分别来学习一下。</p><!-- [[[read_end]]] --><h3>SDS的内存友好设计</h3><p>实际上，我在<a href=\"https://time.geekbang.org/column/article/400314\">第2讲</a>中就已经给你介绍过SDS的结构设计，这里我们先做个简单的回顾：SDS设计了不同类型的结构头，包括sdshdr8、sdshdr16、sdshdr32和sdshdr64。这些不同类型的结构头可以适配不同大小的字符串，从而避免了内存浪费。</p><p>不过，SDS除了使用精巧设计的结构头外，在保存较小字符串时，其实还使用了<strong>嵌入式字符串</strong>的设计方法。这种方法避免了给字符串分配额外的空间，而是可以让字符串直接保存在Redis的基本数据对象结构体中。</p><p>所以这也就是说，要想理解嵌入式字符串的设计与实现，我们就需要先来了解下，Redis使用的基本数据对象结构体redisObject是什么样的。</p><h4>redisObject结构体与位域定义方法</h4><p>redisObject结构体是在server.h文件中定义的，主要功能是用来保存键值对中的值。这个结构一共定义了4个元数据和一个指针。</p><ul>\n<li><strong>type</strong>：redisObject的数据类型，是应用程序在Redis中保存的数据类型，包括String、List、Hash等。</li>\n<li><strong>encoding</strong>：redisObject的编码类型，是Redis内部实现各种数据类型所用的数据结构。</li>\n<li><strong>lru</strong>：redisObject的LRU时间。</li>\n<li><strong>refcount</strong>：redisObject的引用计数。</li>\n<li><strong>ptr</strong>：指向值的指针。</li>\n</ul><p>下面的代码展示了redisObject结构体的定义：</p><pre><code>typedef struct redisObject {\n    unsigned type:4; //redisObject的数据类型，4个bits\n    unsigned encoding:4; //redisObject的编码类型，4个bits\n    unsigned lru:LRU_BITS;  //redisObject的LRU时间，LRU_BITS为24个bits\n    int refcount; //redisObject的引用计数，4个字节\n    void *ptr; //指向值的指针，8个字节\n} robj;\n</code></pre><p>从代码中我们可以看到，在type、encoding和lru三个变量后面都有一个冒号，并紧跟着一个数值，表示该元数据占用的比特数。其中，type和encoding分别占4bits。而lru占用的比特数，是由server.h中的宏定义LRU_BITS决定的，它的默认值是24bits，如下所示：</p><pre><code>#define LRU_BITS 24\n</code></pre><p>而这里我想让你学习掌握的，就是这种<strong>变量后使用冒号和数值的定义方法</strong>。这实际上是C语言中的<strong>位域定义方法</strong>，可以用来有效地节省内存开销。</p><p>这种方法比较适用的场景是，当一个变量占用不了一个数据类型的所有bits时，就可以使用位域定义方法，把一个数据类型中的bits，划分成多个位域，每个位域占一定的bit数。这样一来，一个数据类型的所有bits就可以定义多个变量了，从而也就有效节省了内存开销。</p><p>此外，你可能还会发现，对于type、encoding和lru三个变量来说，它们的数据类型都是unsigned。已知一个unsigned类型是4字节，但这三个变量，是分别占用了一个unsigned类型4字节中的4bits、4bits和24bits。因此，相较于三个变量，每个变量用一个4字节的unsigned类型定义来说，使用位域定义方法可以让三个变量只用4字节，最后就能节省8字节的开销。</p><p>所以，当你在设计开发内存敏感型的软件时，就可以把这种位域定义方法使用起来。</p><p>好，了解了redisObject结构体和它使用的位域定义方法以后，我们再来看嵌入式字符串是如何实现的。</p><h4>嵌入式字符串</h4><p>前面我说过，SDS在保存比较小的字符串时，会使用嵌入式字符串的设计方法，将字符串直接保存在redisObject结构体中。然后在redisObject结构体中，存在一个指向值的指针ptr，而一般来说，这个ptr指针会指向值的数据结构。</p><p>这里我们就以创建一个String类型的值为例，Redis会调用<strong>createStringObject函数</strong>，来创建相应的redisObject，而这个redisObject中的ptr指针，就会指向SDS数据结构，如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/f6/23/f6be6811ea3618a8aae047b29b0bfa23.jpg?wh=1909x749\" alt=\"\"></p><p>在Redis源码中，createStringObject函数会根据要创建的字符串的长度，决定具体调用哪个函数来完成创建。</p><p>那么针对这个createStringObject函数来说，它的参数是<strong>字符串ptr</strong>和<strong>字符串长度len</strong>。当len的长度大于OBJ_ENCODING_EMBSTR_SIZE_LIMIT这个宏定义时，createStringObject函数会调用createRawStringObject函数，否则就调用createEmbeddedStringObject函数。而在我们分析的Redis 5.0.8源码版本中，这个OBJ_ENCODING_EMBSTR_SIZE_LIMIT默认定义为44字节。</p><p>这部分代码如下所示：</p><pre><code>#define OBJ_ENCODING_EMBSTR_SIZE_LIMIT 44\nrobj *createStringObject(const char *ptr, size_t len) {\n    //创建嵌入式字符串，字符串长度小于等于44字节\n    if (len &lt;= OBJ_ENCODING_EMBSTR_SIZE_LIMIT)\n        return createEmbeddedStringObject(ptr,len);\n    //创建普通字符串，字符串长度大于44字节\n    else\n        return createRawStringObject(ptr,len);\n}\n</code></pre><p>现在，我们就来分析一下createStringObject函数的源码实现，以此了解大于44字节的普通字符串和小于等于44字节的嵌入式字符串分别是如何创建的。</p><p>首先，对于<strong>createRawStringObject函数</strong>来说，它在创建String类型的值的时候，会调用createObject函数。</p><blockquote>\n<p>补充：createObject函数主要是用来创建Redis的数据对象的。因为Redis的数据对象有很多类型，比如String、List、Hash等，所以在createObject函数的两个参数中，有一个就是用来表示所要创建的数据对象类型，而另一个是指向数据对象的指针。</p>\n</blockquote><p>然后，createRawStringObject函数在调用createObject函数时，会传递OBJ_STRING类型，表示要创建String类型的对象，以及传递指向SDS结构的指针，如以下代码所示。这里<strong>需要注意</strong>的是，指向SDS结构的指针是由sdsnewlen函数返回的，而sdsnewlen函数正是用来创建SDS结构的。</p><pre><code>robj *createRawStringObject(const char *ptr, size_t len) {\n    return createObject(OBJ_STRING, sdsnewlen(ptr,len));\n}\n</code></pre><p>最后，我们再来进一步看下<strong>createObject函数</strong>。这个函数会把参数中传入的、指向SDS结构体的指针直接赋值给redisObject中的ptr，这部分的代码如下所示：</p><pre><code>robj *createObject(int type, void *ptr) {\n    //给redisObject结构体分配空间\n\t  robj *o = zmalloc(sizeof(*o));\n\t  //设置redisObject的类型\n\t  o-&gt;type = type;\n\t  //设置redisObject的编码类型，此处是OBJ_ENCODING_RAW，表示常规的SDS\n\t  o-&gt;encoding = OBJ_ENCODING_RAW;\n\t  //直接将传入的指针赋值给redisObject中的指针。\n    o-&gt;ptr = ptr;\n    o-&gt;refcount = 1;\n    …\n    return o;\n}\n</code></pre><p>为了方便理解普通字符串创建方法，我画了一张图，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/92/ba/92ba6c70129843d7e48a7c074a5737ba.jpg?wh=2000x940\" alt=\"\"></p><p>这也就是说，在创建普通字符串时，Redis需要分别给redisObject和SDS分别分配一次内存，这样就既带来了内存分配开销，同时也会导致内存碎片。因此，当字符串小于等于44字节时，Redis就使用了嵌入式字符串的创建方法，以此减少内存分配和内存碎片。</p><p>而这个创建方法，就是由我们前面提到的<strong>createEmbeddedStringObject函数</strong>来完成的，该函数会使用一块连续的内存空间，来同时保存redisObject和SDS结构。这样一来，内存分配只有一次，而且也避免了内存碎片。</p><p>createEmbeddedStringObject函数的原型定义如下，它的参数就是从createStringObject函数参数中获得的字符串指针ptr，以及字符串长度len。</p><pre><code>robj *createEmbeddedStringObject(const char *ptr, size_t len)\n</code></pre><p>那么下面，我们就来具体看看，createEmbeddedStringObject函数是如何把redisObject和SDS放置在一起的。</p><p>首先，createEmbeddedStringObject函数会<strong>分配一块连续的内存空间</strong>，这块内存空间的大小等于redisObject结构体的大小、SDS结构头sdshdr8的大小和字符串大小的总和，并且再加上1字节。注意，这里最后的1字节是SDS中加在字符串最后的结束字符“\\0”。</p><p>这块连续内存空间的分配情况如以下代码所示：</p><pre><code>robj *o = zmalloc(sizeof(robj)+sizeof(struct sdshdr8)+len+1);\n</code></pre><p>你也可以参考下图，其中展示了这块内存空间的布局。</p><p><img src=\"https://static001.geekbang.org/resource/image/ec/e1/ec4aed7402b4d5310c37a468e5e403e1.jpg?wh=2000x426\" alt=\"\"></p><p>好，那么createEmbeddedStringObject函数在分配了内存空间之后，就会<strong>创建SDS结构的指针sh，并把sh指向这块连续空间中SDS结构头所在的位置</strong>，下面的代码显示了这步操作。其中，o是redisObject结构体的变量，o+1表示将内存地址从变量o开始移动一段距离，而移动的距离等于redisObject这个结构体的大小。</p><pre><code>struct sdshdr8 *sh = (void*)(o+1);\n</code></pre><p>经过这步操作后，sh指向的位置就如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/cd/56/cdf446e96d90ff03db1083a0bd557056.jpg?wh=2000x487\" alt=\"\"></p><p>紧接着，createEmbeddedStringObject函数会<strong>把redisObject中的指针ptr，指向SDS结构中的字符数组</strong>。</p><p>如以下代码所示，其中sh是刚才介绍的指向SDS结构的指针，属于sdshdr8类型。而sh+1表示把内存地址从sh起始地址开始移动一定的大小，移动的距离等于sdshdr8结构体的大小。</p><pre><code>o-&gt;ptr = sh+1;\n</code></pre><p>这步操作完成后，redisObject结构体中的指针ptr的指向位置就如下图所示，它会指向SDS结构头的末尾，同时也是字符数组的起始位置：</p><p><img src=\"https://static001.geekbang.org/resource/image/2e/0d/2e8f1387e6e7b7a6c6b9e431e53dd60d.jpg?wh=2000x539\" alt=\"\"></p><p>最后，createEmbeddedStringObject函数会<strong>把参数中传入的指针ptr指向的字符串，拷贝到SDS结构体中的字符数组，并在数组最后添加结束字符</strong>。这部分代码如下所示：</p><pre><code>memcpy(sh-&gt;buf,ptr,len);\nsh-&gt;buf[len] = '\\0';\n</code></pre><p>下面这张图，也展示了createEmbeddedStringObject创建嵌入式字符串的过程，你可以再整体来看看。</p><p><img src=\"https://static001.geekbang.org/resource/image/b3/72/b3153b3064e8edea801c5b1b4f6d9372.jpg?wh=2000x1125\" alt=\"\"></p><p>总之，你可以记住，Redis会通过设计实现一块连续的内存空间，把redisObject结构体和SDS结构体紧凑地放置在一起。这样一来，对于不超过44字节的字符串来说，就可以避免内存碎片和两次内存分配的开销了。</p><p>而除了嵌入式字符串之外，Redis还设计了压缩列表和整数集合，这也是两种紧凑型的内存数据结构，所以下面我们再来学习下它们的设计思路。</p><h3>压缩列表和整数集合的设计</h3><p>首先你要知道，List、Hash和Sorted Set这三种数据类型，都可以使用压缩列表（ziplist）来保存数据。压缩列表的函数定义和实现代码分别在ziplist.h和ziplist.c中。</p><p>不过，我们在ziplist.h文件中其实根本看不到压缩列表的结构体定义。这是因为压缩列表本身就是一块连续的内存空间，它通过使用不同的编码来保存数据。</p><p>这里为了方便理解压缩列表的设计与实现，我们先来看看它的<strong>创建函数ziplistNew</strong>，如下所示：</p><pre><code>unsigned char *ziplistNew(void) {\n    //初始分配的大小\n    unsigned int bytes = ZIPLIST_HEADER_SIZE+ZIPLIST_END_SIZE;\n    unsigned char *zl = zmalloc(bytes);\n    …\n   //将列表尾设置为ZIP_END\n    zl[bytes-1] = ZIP_END;\n    return zl;\n}\n</code></pre><p>实际上，ziplistNew函数的逻辑很简单，就是创建一块连续的内存空间，大小为ZIPLIST_HEADER_SIZE和ZIPLIST_END_SIZE的总和，然后再把该连续空间的最后一个字节赋值为ZIP_END，表示列表结束。</p><p>另外你要注意的是，在上面代码中定义的三个宏ZIPLIST_HEADER_SIZE、ZIPLIST_END_SIZE和ZIP_END，在ziplist.c中也分别有定义，分别表示ziplist的列表头大小、列表尾大小和列表尾字节内容，如下所示。</p><pre><code>//ziplist的列表头大小，包括2个32 bits整数和1个16bits整数，分别表示压缩列表的总字节数，列表最后一个元素的离列表头的偏移，以及列表中的元素个数\n#define ZIPLIST_HEADER_SIZE     (sizeof(uint32_t)*2+sizeof(uint16_t))\n//ziplist的列表尾大小，包括1个8 bits整数，表示列表结束。\n#define ZIPLIST_END_SIZE        (sizeof(uint8_t))\n//ziplist的列表尾字节内容\n#define ZIP_END 255 \n</code></pre><p>那么，在创建一个新的ziplist后，该列表的内存布局就如下图所示。注意，此时列表中还没有实际的数据。</p><p><img src=\"https://static001.geekbang.org/resource/image/a0/10/a09c893fe8bbafca9ec61b38165f3810.jpg?wh=2000x349\" alt=\"\"></p><p>然后，当我们往ziplist中插入数据时，ziplist就会根据数据是字符串还是整数，以及它们的大小进行不同的编码。这种根据数据大小进行相应编码的设计思想，正是Redis为了节省内存而采用的。</p><p><strong>那么，ziplist是如何进行编码呢？</strong>要学习编码的实现，我们要先了解ziplist中列表项的结构。</p><p>ziplist列表项包括三部分内容，分别是<strong>前一项的长度（prevlen）</strong>、<strong>当前项长度信息的编码结果（encoding）</strong>，以及<strong>当前项的实际数据（data）</strong>。下面的图展示了列表项的结构（图中除列表项之外的内容分别是ziplist内存空间的起始和尾部）。</p><p><img src=\"https://static001.geekbang.org/resource/image/86/d5/864539a743ab9911fde71366463fc8d5.jpg?wh=2000x749\" alt=\"\"></p><p>实际上，所谓的编码技术，就是指<strong>用不同数量的字节来表示保存的信息</strong>。在ziplist中，编码技术主要应用在列表项中的prevlen和encoding这两个元数据上。而当前项的实际数据data，则正常用整数或是字符串来表示。</p><p>所以这里，我们就先来看下<strong>prevlen的编码设计</strong>。ziplist中会包含多个列表项，每个列表项都是紧挨着彼此存放的，如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/eb/fc/eb734ed4a3718b28404ba90fdbe1a5fc.jpg?wh=2000x723\" alt=\"\"></p><p>而为了方便查找，每个列表项中都会记录前一项的长度。因为每个列表项的长度不一样，所以如果使用相同的字节大小来记录prevlen，就会造成内存空间浪费。</p><p>我给你举个例子，假设我们统一使用4字节记录prevlen，如果前一个列表项只是一个字符串“redis”，长度为5个字节，那么我们用1个字节（8 bits）就能表示256字节长度（2的8次方等于256）的字符串了。此时，prevlen用4字节记录，其中就有3字节是浪费掉了。</p><p>好，我们再回过头来看，ziplist在对prevlen编码时，会先调用<strong>zipStorePrevEntryLength函数</strong>，用于判断前一个列表项是否小于254字节。如果是的话，那么prevlen就使用1字节表示；否则，zipStorePrevEntryLength函数就调用zipStorePrevEntryLengthLarge函数进一步编码。这部分代码如下所示：</p><pre><code>//判断prevlen的长度是否小于ZIP_BIG_PREVLEN，ZIP_BIG_PREVLEN等于254\nif (len &lt; ZIP_BIG_PREVLEN) {\n   //如果小于254字节，那么返回prevlen为1字节\n   p[0] = len;\n   return 1;\n} else {\n   //否则，调用zipStorePrevEntryLengthLarge进行编码\n   return zipStorePrevEntryLengthLarge(p,len);\n}\n</code></pre><p>也就是说，<strong>zipStorePrevEntryLengthLarge函数</strong>会先将prevlen的第1字节设置为254，然后使用内存拷贝函数memcpy，将前一个列表项的长度值拷贝至prevlen的第2至第5字节。最后，zipStorePrevEntryLengthLarge函数返回prevlen的大小，为5字节。</p><pre><code>if (p != NULL) {\n    //将prevlen的第1字节设置为ZIP_BIG_PREVLEN，即254\n    p[0] = ZIP_BIG_PREVLEN;\n\t//将前一个列表项的长度值拷贝至prevlen的第2至第5字节，其中sizeof(len)的值为4\n    memcpy(p+1,&amp;len,sizeof(len));\n    …\n}\n//返回prevlen的大小，为5字节\nreturn 1+sizeof(len);\n</code></pre><p>好，在了解了prevlen使用1字节和5字节两种编码方式后，我们再来学习下<strong>encoding的编码方法</strong>。</p><p>我们知道，一个列表项的实际数据，既可以是整数也可以是字符串。整数可以是16、32、64等字节长度，同时字符串的长度也可以大小不一。</p><p>所以，ziplist在zipStoreEntryEncoding函数中，针对整数和字符串，就分别使用了不同字节长度的编码结果。下面的代码展示了zipStoreEntryEncoding函数的部分代码，你可以看到当数据是不同长度字符串或是整数时，编码结果的长度len大小不同。</p><pre><code>//默认编码结果是1字节\n\tunsigned char len = 1;\n\t//如果是字符串数据\n\tif (ZIP_IS_STR(encoding)) {\n\t    //字符串长度小于等于63字节（16进制为0x3f）\n        if (rawlen &lt;= 0x3f) {\n            //默认编码结果是1字节\n            …\n        }\n    //字符串长度小于等于16383字节（16进制为0x3fff） \n        else if (rawlen &lt;= 0x3fff) {   \n            //编码结果是2字节\n            len += 1;\n            …\n        }\n    //字符串长度大于16383字节\n \n        else {\n            //编码结果是5字节\n            len += 4;\n            …\n        }\n    } else {\n        /* 如果数据是整数，编码结果是1字节*/\n        if (!p) return len;\n        ...\n    }\n</code></pre><p>简而言之，针对不同长度的数据，使用不同大小的元数据信息（prevlen和encoding），这种方法可以有效地节省内存开销。当然，除了ziplist之外，Redis还设计了一个内存友好的数据结构，这就是<strong>整数集合（intset）</strong>，它是作为底层结构来实现Set数据类型的。</p><p>和SDS嵌入式字符串、ziplist类似，整数集合也是一块连续的内存空间，这一点我们从整数集合的定义中就可以看到。intset.h和intset.c分别包括了整数集合的定义和实现。</p><p>下面的代码展示了intset的结构定义。我们可以看到，整数集合结构体中记录数据的部分，就是一个int8_t类型的整数数组contents。从内存使用的角度来看，整数数组就是一块连续内存空间，所以这样就避免了内存碎片，并提升了内存使用效率。</p><pre><code>typedef struct intset {\n    uint32_t encoding;\n    uint32_t length;\n    int8_t contents[];\n} intset;\n</code></pre><p>好了，到这里，我们就已经了解了Redis针对内存开销所做的数据结构优化，分别是SDS嵌入式字符串、压缩列表和整数集合。</p><p>而除了对数据结构做优化，Redis在数据访问上，也会尽量节省内存开销，接下来我们就一起来学习下。</p><h2>节省内存的数据访问</h2><p>我们知道，在Redis实例运行时，有些数据是会被经常访问的，比如常见的整数，Redis协议中常见的回复信息，包括操作成功（“OK”字符串）、操作失败（ERR），以及常见的报错信息。</p><p>所以，为了避免在内存中反复创建这些经常被访问的数据，Redis就采用了<strong>共享对象</strong>的设计思想。这个设计思想很简单，就是把这些常用数据创建为共享对象，当上层应用需要访问它们时，直接读取就行。</p><p>现在我们就来做个假设。有1000个客户端，都要保存“3”这个整数。如果Redis为每个客户端，都创建了一个值为3的redisObject，那么内存中就会有大量的冗余。而使用了共享对象方法后，Redis在内存中只用保存一个3的redisObject就行，这样就有效节省了内存空间。</p><p>以下代码展示的是server.c文件中，<strong>创建共享对象的函数createSharedObjects</strong>，你可以看下。</p><pre><code>void createSharedObjects(void) {\n   …\n   //常见回复信息\n   shared.ok = createObject(OBJ_STRING,sdsnew(&quot;+OK\\r\\n&quot;));\n   shared.err = createObject(OBJ_STRING,sdsnew(&quot;-ERR\\r\\n&quot;));\n   …\n   //常见报错信息\n shared.nokeyerr = createObject(OBJ_STRING,sdsnew(&quot;-ERR no such key\\r\\n&quot;));\n shared.syntaxerr = createObject(OBJ_STRING,sdsnew(&quot;-ERR syntax error\\r\\n&quot;));\n   //0到9999的整数\n   for (j = 0; j &lt; OBJ_SHARED_INTEGERS; j++) {\n        shared.integers[j] =\n          makeObjectShared(createObject(OBJ_STRING,(void*)(long)j));\n        …\n    }\n   …\n}\n</code></pre><h2>小结</h2><p>降低内存开销，对于Redis这样的内存数据库来说非常重要。今天这节课，我们了解了Redis用于优化内存使用效率的两种方法：内存优化的数据结构设计和节省内存的共享数据访问。</p><p>那么，对于实现数据结构来说，如果想要节省内存，Redis就给我们提供了两个优秀的设计思想：一个是<strong>使用连续的内存空间</strong>，避免内存碎片开销；二个是<strong>针对不同长度的数据，采用不同大小的元数据</strong>，以避免使用统一大小的元数据，造成内存空间的浪费。</p><p>另外在数据访问方面，你也要知道，<strong>使用共享对象</strong>其实可以避免重复创建冗余的数据，从而也可以有效地节省内存空间。不过，共享对象主要适用于<strong>只读场景</strong>，如果一个字符串被反复地修改，就无法被多个请求共享访问了。所以这一点，你在应用时也需要注意一下。</p><h2>每课一问</h2><p>SDS判断是否使用嵌入式字符串的条件是44字节，你知道为什么是44字节吗？</p><p>欢迎在留言区分享你的思考过程，我们一起交流讨论。如果觉得有收获，也欢迎你把今天的内容分享给更多的朋友。</p>","neighbors":{"left":{"article_title":"03 | 如何实现一个性能优异的Hash表？","id":400379},"right":{"article_title":"05 | 有序集合为何能同时支持点查询和范围查询？","id":404391}}},{"article_id":404391,"article_title":"05 | 有序集合为何能同时支持点查询和范围查询？","article_content":"<p>你好，我是蒋德钧。</p><p>有序集合（Sorted Set）是Redis中一种重要的数据类型，它本身是集合类型，同时也可以支持集合中的元素带有权重，并按权重排序。</p><p>而曾经就有一位从事Redis开发的同学问我：为什么Sorted Set能同时提供以下两种操作接口，以及它们的复杂度分别是O(logN)+M和O(1)呢？</p><ul>\n<li>ZRANGEBYSCORE：按照元素权重返回一个范围内的元素。</li>\n<li>ZSCORE：返回某个元素的权重值。</li>\n</ul><p>实际上，这个问题背后的本质是：<strong>为什么Sorted Set既能支持高效的范围查询，同时还能以O(1)复杂度获取元素权重值？</strong></p><p>这其实就和Sorted Set底层的设计实现有关了。Sorted Set能支持范围查询，这是因为它的核心数据结构设计采用了跳表，而它又能以常数复杂度获取元素权重，这是因为它同时采用了哈希表进行索引。</p><p>那么，你是不是很好奇，Sorted Set是如何把这两种数据结构结合在一起的？它们又是如何进行协作的呢？今天这节课，我就来给你介绍下Sorted Set采用的双索引的设计思想和实现。理解和掌握这种双索引的设计思想，对于我们实现数据库系统是具有非常重要的参考价值的。</p><p>好，接下来，我们就先来看看Sorted Set的基本结构。</p><!-- [[[read_end]]] --><h2>Sorted Set基本结构</h2><p>要想了解Sorted Set的结构，就需要阅读它的代码文件。这里你需要注意的是，在Redis源码中，Sorted Set的代码文件和其他数据类型不太一样，它并不像哈希表的dict.c/dict.h，或是压缩列表的ziplist.c/ziplist.h，具有专门的数据结构实现和定义文件。</p><p>Sorted Set的<strong>实现代码在</strong><a href=\"https://github.com/redis/redis/blob/5.0/src/t_zset.c\"><strong>t_zset.c</strong></a><strong>文件中</strong>，包括Sorted Set的各种操作实现，同时Sorted Set相关的<strong>结构定义在</strong><a href=\"https://github.com/redis/redis/blob/5.0/src/server.h\"><strong>server.h</strong></a><strong>文件中</strong>。如果你想要了解学习Sorted Set的模块和操作，注意要从t_zset.c和server.h这两个文件中查找。</p><p>好，在知道了Sorted Set所在的代码文件之后，我们可以先来看下它的结构定义。Sorted Set结构体的名称为zset，其中包含了两个成员，分别是哈希表dict和跳表zsl，如下所示。</p><pre><code>typedef struct zset {\n    dict *dict;\n    zskiplist *zsl;\n} zset;\n</code></pre><p>在这节课一开始，我就说过Sorted Set这种同时采用跳表和哈希表两个索引结构的设计思想，是非常值得学习的。因为这种设计思想充分利用了跳表高效支持范围查询（如ZRANGEBYSCORE操作），以及哈希表高效支持单点查询（如ZSCORE操作）的特征。这样一来，我们就可以在一个数据结构中，同时高效支持范围查询和单点查询，这是单一索引结构比较难达到的效果。</p><p>不过，既然Sorted Set采用了跳表和哈希表两种索引结构来组织数据，我们在实现Sorted Set时就会面临以下两个问题：</p><ul>\n<li><strong>跳表或是哈希表中，各自保存了什么样的数据？</strong></li>\n<li><strong>跳表和哈希表保存的数据是如何保持一致的？</strong></li>\n</ul><p>因为我已经在<a href=\"https://time.geekbang.org/column/article/400379\">第3讲</a>中给你介绍了Redis中哈希表的实现思路，所以接下来，我主要是给你介绍下跳表的设计和实现。通过学习跳表，你可以了解到跳表中保存的数据，以及跳表的常见操作。然后，我再带你来探究下Sorted Set如何将哈希表和跳表组合起来使用的，以及这两个索引结构中的数据是如何保持一致的。</p><h2>跳表的设计与实现</h2><p>首先，我们来了解下什么是跳表（skiplist）。</p><p><strong>跳表其实是一种多层的有序链表。</strong>在课程中，为了便于说明，我把跳表中的层次从低到高排个序，最底下一层称为level0，依次往上是level1、level2等。</p><p>下图展示的是一个3层的跳表。其中，头结点中包含了三个指针，分别作为leve0到level2上的头指针。</p><p><img src=\"https://static001.geekbang.org/resource/image/35/23/35b2c22120952e1fac46147664e75b23.jpg?wh=2000x626\" alt=\"\"></p><p>可以看到，在level 0上一共有7个结点，分别是3、11、23、33、42、51、62，这些结点会通过指针连接起来，同时头结点中的level0指针会指向结点3。然后，在这7个结点中，结点11、33和51又都包含了一个指针，同样也依次连接起来，且头结点的level 1指针会指向结点11。这样一来，这3个结点就组成了level 1上的所有结点。</p><p>最后，结点33中还包含了一个指针，这个指针会指向尾结点，同时，头结点的level 2指针会指向结点33，这就形成了level 2，只不过level 2上只有1个结点33。</p><p>好，在对跳表有了直观印象后，我们再来看看跳表实现的具体数据结构。</p><h3>跳表数据结构</h3><p>我们先来看下跳表结点的结构定义，如下所示。</p><pre><code>typedef struct zskiplistNode {\n    //Sorted Set中的元素\n    sds ele;\n    //元素权重值\n    double score;\n    //后向指针\n    struct zskiplistNode *backward;\n    //节点的level数组，保存每层上的前向指针和跨度\n    struct zskiplistLevel {\n        struct zskiplistNode *forward;\n        unsigned long span;\n    } level[];\n} zskiplistNode;\n</code></pre><p>首先，因为Sorted Set中既要保存元素，也要保存元素的权重，所以对应到跳表结点的结构定义中，就对应了sds类型的变量ele，以及double类型的变量score。此外，为了便于从跳表的尾结点进行倒序查找，每个跳表结点中还保存了一个后向指针（<code>*backward</code>），指向该结点的前一个结点。</p><p>然后，因为跳表是一个多层的有序链表，每一层也是由多个结点通过指针连接起来的。因此在跳表结点的结构定义中，还包含了一个zskiplistLevel结构体类型的<strong>level数组</strong>。</p><p>level数组中的每一个元素对应了一个zskiplistLevel结构体，也对应了跳表的一层。而zskiplistLevel结构体定义了一个指向下一结点的前向指针（<code>*forward</code>），这就使得结点可以在某一层上和后续结点连接起来。同时，zskiplistLevel结构体中还定义了<strong>跨度</strong>，这是用来记录结点在某一层上的<code>*forward</code>指针和该指针指向的结点之间，跨越了level0上的几个结点。</p><p>我们来看下面这张图，其中就展示了33结点的level数组和跨度情况。可以看到，33结点的level数组有三个元素，分别对应了三层level上的指针。此外，在level数组中，level 2、level1和level 0的跨度span值依次是3、2、1。</p><p><img src=\"https://static001.geekbang.org/resource/image/fb/e7/fb90e5eb40d39ced5d5896b3e10640e7.jpg?wh=2000x552\" alt=\"\"></p><p>最后，因为跳表中的结点都是按序排列的，所以，对于跳表中的某个结点，我们可以把从头结点到该结点的查询路径上，各个结点在所查询层次上的<code>*forward</code>指针跨度，做一个累加。这个累加值就可以用来计算该结点在整个跳表中的顺序，另外这个结构特点还可以用来实现Sorted Set的rank操作，比如ZRANK、ZREVRANK等。</p><p>好，了解了跳表结点的定义后，我们可以来看看跳表的定义。在跳表的结构中，定义了跳表的头结点和尾结点、跳表的长度，以及跳表的最大层数，如下所示。</p><pre><code>typedef struct zskiplist {\n    struct zskiplistNode *header, *tail;\n    unsigned long length;\n    int level;\n} zskiplist;\n</code></pre><p>因为跳表的每个结点都是通过指针连接起来的，所以我们在使用跳表时，只需要从跳表结构体中获得头结点或尾结点，就可以通过结点指针访问到跳表中的各个结点。</p><p>那么，当我们在Sorted Set中查找元素时，就对应到了Redis在跳表中查找结点，而此时，查询代码是否需要像查询常规链表那样，逐一顺序查询比较链表中的每个结点呢？</p><p>其实是不用的，因为这里的查询代码，可以使用跳表结点中的level数组来加速查询。</p><h3>跳表结点查询</h3><p>事实上，当查询一个结点时，跳表会先从头结点的最高层开始，查找下一个结点。而由于跳表结点同时保存了元素和权重，所以跳表在比较结点时，相应地有<strong>两个判断条件</strong>：</p><ol>\n<li>当查找到的结点保存的元素权重，比要查找的权重小时，跳表就会继续访问该层上的下一个结点。</li>\n<li>当查找到的结点保存的元素权重，等于要查找的权重时，跳表会再检查该结点保存的SDS类型数据，是否比要查找的SDS数据小。如果结点数据小于要查找的数据时，跳表仍然会继续访问该层上的下一个结点。</li>\n</ol><p>但是，当上述两个条件都不满足时，跳表就会用到当前查找到的结点的level数组了。跳表会使用当前结点level数组里的下一层指针，然后沿着下一层指针继续查找，这就相当于跳到了下一层接着查找。</p><p>这部分的代码逻辑如下所示，因为在跳表中进行查找、插入、更新或删除操作时，都需要用到查询的功能，你可以重点了解下。</p><pre><code>//获取跳表的表头\nx = zsl-&gt;header;\n//从最大层数开始逐一遍历\nfor (i = zsl-&gt;level-1; i &gt;= 0; i--) {\n   ...\n   while (x-&gt;level[i].forward &amp;&amp; (x-&gt;level[i].forward-&gt;score &lt; score || (x-&gt;level[i].forward-&gt;score == score \n    &amp;&amp; sdscmp(x-&gt;level[i].forward-&gt;ele,ele) &lt; 0))) {\n      ...\n      x = x-&gt;level[i].forward;\n    }\n    ...\n}\n</code></pre><h3>跳表结点层数设置</h3><p>这样一来，有了level数组之后，一个跳表结点就可以在多层上被访问到了。而一个结点的level数组的层数也就决定了，该结点可以在几层上被访问到。</p><p>所以，当我们要决定结点层数时，实际上是要决定level数组具体有几层。</p><p>一种设计方法是，让每一层上的结点数约是下一层上结点数的一半，就像下面这张图展示的。第0层上的结点数是7，第1层上的结点数是3，约是第0层上结点数的一半。而第2层上的结点就33一个，约是第1层结点数的一半。</p><p><img src=\"https://static001.geekbang.org/resource/image/4e/b3/4ed4fce0d36bd4c4d2ec99cd2e4bb9b3.jpg?wh=2000x525\" alt=\"\"></p><p>这种设计方法带来的好处是，当跳表从最高层开始进行查找时，由于每一层结点数都约是下一层结点数的一半，这种查找过程就类似于二分查找，<strong>查找复杂度可以降低到O(logN)</strong>。</p><p>但这种设计方法也会带来负面影响，那就是为了维持相邻两层上结点数的比例为2:1，一旦有新的结点插入或是有结点被删除，那么插入或删除处的结点，及其后续结点的层数都需要进行调整，而这样就带来了额外的开销。</p><p>我先来给你举个例子，看下不维持结点数比例的影响，这样虽然可以不调整层数，但是会增加查询复杂度。</p><p>首先，假设当前跳表有3个结点，其数值分别是3、11、23，如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/e8/bf/e86e7ac5938a17120bd84c158a5f8fbf.jpg?wh=1610x418\" alt=\"\"></p><p>接着，假设现在要插入一个结点15，如果我们不调整其他结点的层数，而是直接插入结点15的话，那么插入后，跳表level 0和level 1两层上的结点数比例就变成了为4:1，如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/4b/a4/4ba3e67fd4c66a0b79fcd87bf918e2a4.jpg?wh=1783x431\" alt=\"\"></p><p>而假设我们持续插入多个结点，但是仍然不调整其他结点的层数，这样一来，level0上的结点数就会越来越多，如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/54/eb/54745b8f90ac9872fa3f5ca947df20eb.jpg?wh=2000x491\" alt=\"\"></p><p>相应的，如果我们要查找大于11的结点，就需要在level 0的结点中依次顺序查找，复杂度就是O(N)了。所以，为了降低查询复杂度，我们就需要维持相邻层结点数间的关系。</p><p>好，接下来，我们再来看下维持相邻层结点数为2:1时的影响。</p><p>比如，我们可以把结点23的level数组中增加一层指针，如下图所示。这样一来，level 0和level 1上的结点数就维持在了2:1。但相应的代价就是，我们也需要给level数组重新分配空间，以便增加一层指针。</p><p><img src=\"https://static001.geekbang.org/resource/image/ea/e1/ea55df10ae9c88a0bbafca8d4af509e1.jpg?wh=2000x421\" alt=\"\"></p><p>类似的，如果我们要在有7个结点的跳表中删除结点33，那么结点33后面的所有结点都要进行调整：</p><p><img src=\"https://static001.geekbang.org/resource/image/e8/1a/e8e2ae100c81fcf2dc9bc66d3b3cc51a.jpg?wh=2000x466\" alt=\"\"></p><p>调整后的跳表如下图所示。你可以看到，结点42和62都要新增level数组空间，这样能分别保存3层的指针和2层的指针，而结点51的level数组则需要减少一层。也就是说，这样的调整会带来额外的操作开销。</p><p><img src=\"https://static001.geekbang.org/resource/image/cd/75/cdf7eb5543d757399c6edd18385ebf75.jpg?wh=2000x491\" alt=\"\"></p><p>因此，为了避免上述问题，跳表在创建结点时，采用的是另一种设计方法，即<strong>随机生成每个结点的层数</strong>。此时，相邻两层链表上的结点数并不需要维持在严格的2:1关系。这样一来，当新插入一个结点时，只需要修改前后结点的指针，而其他结点的层数就不需要随之改变了，这就降低了插入操作的复杂度。</p><p>在Redis源码中，跳表结点层数是由<strong>zslRandomLevel函数</strong>决定。zslRandomLevel函数会把层数初始化为1，这也是结点的最小层数。然后，该函数会生成随机数，如果随机数的值小于ZSKIPLIST_P（指跳表结点增加层数的概率，值为0.25），那么层数就增加1层。因为随机数取值到[0,0.25)范围内的概率不超过25%，所以这也就表明了，每增加一层的概率不超过25%。下面的代码展示了zslRandomLevel函数的执行逻辑，你可以看下。</p><pre><code>#define ZSKIPLIST_MAXLEVEL 64  //最大层数为64\n#define ZSKIPLIST_P 0.25       //随机数的值为0.25\nint zslRandomLevel(void) {\n    //初始化层为1\n    int level = 1;\n    while ((random()&amp;0xFFFF) &lt; (ZSKIPLIST_P * 0xFFFF))\n        level += 1;\n    return (level&lt;ZSKIPLIST_MAXLEVEL) ? level : ZSKIPLIST_MAXLEVEL;\n}\n</code></pre><p>好，现在我们就了解了跳表的基本结构、查询方式和结点层数设置方法，那么下面我们接着来学习下，Sorted Set中是如何将跳表和哈希表组合起来使用的，以及是如何保持这两个索引结构中的数据是一致的。</p><h2>哈希表和跳表的组合使用</h2><p>其实，哈希表和跳表的组合使用并不复杂。</p><p>首先，我们从刚才介绍的Sorted Set结构体中可以看到，Sorted Set中已经同时包含了这两种索引结构，这就是组合使用两者的第一步。然后，我们还可以在Sorted Set的创建代码（<a href=\"https://github.com/redis/redis/blob/5.0/src/t_zset.c\">t_zset.c</a>文件）中，进一步看到跳表和哈希表被相继创建。</p><p>当创建一个zset时，代码中会相继调用<strong>dictCreate函数</strong>创建zset中的哈希表，以及调用<strong>zslCreate函数</strong>创建跳表，如下所示。</p><pre><code> zs = zmalloc(sizeof(*zs));\n zs-&gt;dict = dictCreate(&amp;zsetDictType,NULL);\n zs-&gt;zsl = zslCreate();\n</code></pre><p>这样，在Sorted Set中同时有了这两个索引结构以后，接下来，我们要想组合使用它们，就需要保持这两个索引结构中的数据一致了。简单来说，这就需要我们在往跳表中插入数据时，同时也向哈希表中插入数据。</p><p>而这种保持两个索引结构一致的做法其实也不难，当往Sorted Set中插入数据时，zsetAdd函数就会被调用。所以，我们可以通过阅读Sorted Set的元素添加函数zsetAdd了解到。下面我们就来分析一下zsetAdd函数的执行过程。</p><ul>\n<li><strong>首先，zsetAdd函数会判定Sorted Set采用的是ziplist还是skiplist的编码方式。</strong></li>\n</ul><p>注意，在不同编码方式下，zsetAdd函数的执行逻辑也有所区别。这一讲我们重点关注的是skiplist的编码方式，所以接下来，我们就主要来看看当采用skiplist编码方式时，zsetAdd函数的逻辑是什么样的。</p><p>zsetAdd函数会先使用哈希表的dictFind函数，查找要插入的元素是否存在。如果不存在，就直接调用跳表元素插入函数zslInsert和哈希表元素插入函数dictAdd，将新元素分别插入到跳表和哈希表中。</p><p>这里你需要注意的是，Redis并没有把哈希表的操作嵌入到跳表本身的操作函数中，而是在zsetAdd函数中依次执行以上两个函数。这样设计的好处是保持了跳表和哈希表两者操作的独立性。</p><ul>\n<li><strong>然后，如果zsetAdd函数通过dictFind函数发现要插入的元素已经存在，那么zsetAdd函数会判断是否要增加元素的权重值。</strong></li>\n</ul><p>如果权重值发生了变化，zsetAdd函数就会调用zslUpdateScore函数，更新跳表中的元素权重值。紧接着，zsetAdd函数会把哈希表中该元素（对应哈希表中的key）的value指向跳表结点中的权重值，这样一来，哈希表中元素的权重值就可以保持最新值了。</p><p>下面的代码显示了zsetAdd函数的执行流程，你可以看下。</p><pre><code> //如果采用ziplist编码方式时，zsetAdd函数的处理逻辑\n if (zobj-&gt;encoding == OBJ_ENCODING_ZIPLIST) {\n   ...\n}\n//如果采用skiplist编码方式时，zsetAdd函数的处理逻辑\nelse if (zobj-&gt;encoding == OBJ_ENCODING_SKIPLIST) {\n        zset *zs = zobj-&gt;ptr;\n        zskiplistNode *znode;\n        dictEntry *de;\n        //从哈希表中查询新增元素\n        de = dictFind(zs-&gt;dict,ele);\n        //如果能查询到该元素\n        if (de != NULL) {\n            /* NX? Return, same element already exists. */\n            if (nx) {\n                *flags |= ZADD_NOP;\n                return 1;\n            }\n            //从哈希表中查询元素的权重\n            curscore = *(double*)dictGetVal(de);\n\n\n            //如果要更新元素权重值\n            if (incr) {\n                //更新权重值\n               ...\n            }\n\n\n            //如果权重发生变化了\n            if (score != curscore) {\n                //更新跳表结点\n                znode = zslUpdateScore(zs-&gt;zsl,curscore,ele,score);\n                //让哈希表元素的值指向跳表结点的权重\n                dictGetVal(de) = &amp;znode-&gt;score; \n                ...\n            }\n            return 1;\n        }\n       //如果新元素不存在\n        else if (!xx) {\n            ele = sdsdup(ele);\n            //新插入跳表结点\n            znode = zslInsert(zs-&gt;zsl,score,ele);\n            //新插入哈希表元素\n            serverAssert(dictAdd(zs-&gt;dict,ele,&amp;znode-&gt;score) == DICT_OK);\n            ...\n            return 1;\n        } \n        ..\n</code></pre><p>总之，你可以记住的是，Sorted Set先是通过在它的数据结构中同时定义了跳表和哈希表，来实现同时使用这两种索引结构。然后，Sorted Set在执行数据插入或是数据更新的过程中，会依次在跳表和哈希表中插入或更新相应的数据，从而保证了跳表和哈希表中记录的信息一致。</p><p>这样一来，Sorted Set既可以使用跳表支持数据的范围查询，还能使用哈希表支持根据元素直接查询它的权重。</p><h2>小结</h2><p>这节课，我给你介绍了Sorted Set数据类型的底层实现。Sorted Set为了能同时支持按照权重的范围查询，以及针对元素权重的单点查询，在底层数据结构上设计了<strong>组合使用跳表和哈希表</strong>的方法。</p><p>跳表是一个多层的有序链表，在跳表中进行查询操作时，查询代码可以从最高层开始查询。层数越高，结点数越少，同时高层结点的跨度会比较大。因此，在高层查询结点时，查询一个结点可能就已经查到了链表的中间位置了。</p><p>这样一来，跳表就会先查高层，如果高层直接查到了等于待查元素的结点，那么就可以直接返回。如果查到第一个大于待查元素的结点后，就转向下一层查询。下层上的结点数多于上层，所以这样可以在更多的结点中进一步查找待查元素是否存在。</p><p>跳表的这种设计方法就可以节省查询开销，同时，跳表设计采用随机的方法来确定每个结点的层数，这样就可以避免新增结点时，引起结点连锁更新问题。</p><p>此外，Sorted Set中还将元素保存在了哈希表中，作为哈希表的key，同时将value指向元素在跳表中的权重。使用了哈希表后，Sorted Set可以通过哈希计算直接查找到某个元素及其权重值，相较于通过跳表查找单个元素，使用哈希表就有效提升了查询效率。</p><p>总之，组合使用两种索引结构来对数据进行管理，比如Sorted Set中组合使用跳表和哈希表，这是一个很好的设计思路，希望你也能应用在日常的系统开发中。</p><h2>每课一问</h2><p>在使用跳表和哈希表相结合的双索引机制时，在获得高效范围查询和单点查询的同时，你能想到这种双索引机制有哪些不足之处吗？</p>","neighbors":{"left":{"article_title":"04 | 内存友好的数据结构该如何细化设计？","id":402223},"right":{"article_title":"06 | 从ziplist到quicklist，再到listpack的启发","id":405387}}},{"article_id":405387,"article_title":"06 | 从ziplist到quicklist，再到listpack的启发","article_content":"<p>你好，我是蒋德钧。</p><p>在前面的<a href=\"https://time.geekbang.org/column/article/402223\">第4讲</a>，我介绍Redis优化设计数据结构来提升内存利用率的时候，提到可以使用压缩列表（ziplist）来保存数据。所以现在你应该也知道，ziplist的最大特点，就是它被设计成一种内存紧凑型的数据结构，占用一块连续的内存空间，以达到节省内存的目的。</p><p>但是，<strong>在计算机系统中，任何一个设计都是有利有弊的</strong>。对于ziplist来说，这个道理同样成立。</p><p>虽然ziplist节省了内存开销，可它也存在两个设计代价：一是不能保存过多的元素，否则访问性能会降低；二是不能保存过大的元素，否则容易导致内存重新分配，甚至可能引发连锁更新的问题。所谓的连锁更新，简单来说，就是ziplist中的每一项都要被重新分配内存空间，造成ziplist的性能降低。</p><p>因此，针对ziplist在设计上的不足，Redis代码在开发演进的过程中，新增设计了两种数据结构：<strong>quicklist和listpack</strong>。这两种数据结构的设计目标，就是尽可能地保持ziplist节省内存的优势，同时避免ziplist潜在的性能下降问题。</p><p>今天这节课，我就来给你详细介绍下quicklist和listpack的设计思想和实现思路，不过在具体讲解这两种数据结构之前，我想先带你来了解下为什么ziplist的设计会存在缺陷。这样一来，你在学习quicklist和listpack时，可以和ziplist的设计进行对比，进一步就能更加容易地掌握quicklist和listpack的设计考虑了。</p><!-- [[[read_end]]] --><p>而且，ziplist和quicklist的区别，也是经常被问到的面试题，而listpack数据结构因为比较新，你对它的设计实现可能了解得并不多。那在学完了这节课之后，你其实就可以很轻松地应对这三种数据结构的使用问题了。此外，你还可以从这三种数据结构的逐步优化设计中，学习到Redis数据结构在内存开销和访问性能之间，采取的设计取舍思想。如果你需要开发高效的数据结构，你就可以把这种设计思想应用起来。</p><p>好，那么接下来，我们就先来了解下ziplist在设计与实现上存在的缺陷。</p><h2>ziplist的不足</h2><p>你已经知道，一个ziplist数据结构在内存中的布局，就是一块连续的内存空间。这块空间的起始部分是大小固定的10字节元数据，其中记录了ziplist的总字节数、最后一个元素的偏移量以及列表元素的数量，而这10字节后面的内存空间则保存了实际的列表数据。在ziplist的最后部分，是一个1字节的标识（固定为255），用来表示ziplist的结束，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/08/6d/08fe01427f264234c59951c8293d466d.jpg?wh=2000x795\" alt=\"\"></p><p>不过，虽然ziplist通过紧凑的内存布局来保存数据，节省了内存空间，但是ziplist也面临着随之而来的两个不足：查找复杂度高和潜在的连锁更新风险。那么下面，我们就分别来了解下这两个问题。</p><h3>查找复杂度高</h3><p>因为ziplist头尾元数据的大小是固定的，并且在ziplist头部记录了最后一个元素的位置，所以，当在ziplist中查找第一个或最后一个元素的时候，就可以很快找到。</p><p>但问题是，当要查找列表中间的元素时，ziplist就得从列表头或列表尾遍历才行。而当ziplist保存的元素过多时，查找中间数据的复杂度就增加了。更糟糕的是，如果ziplist里面保存的是字符串，ziplist在查找某个元素时，还需要逐一判断元素的每个字符，这样又进一步增加了复杂度。</p><p>也正因为如此，我们在使用ziplist保存Hash或Sorted Set数据时，都会在redis.conf文件中，通过hash-max-ziplist-entries和zset-max-ziplist-entries两个参数，来控制保存在ziplist中的元素个数。</p><p>不仅如此，除了查找复杂度高以外，ziplist在插入元素时，如果内存空间不够了，ziplist还需要重新分配一块连续的内存空间，而这还会进一步引发连锁更新的问题。</p><h3>连锁更新风险</h3><p>我们知道，因为ziplist必须使用一块连续的内存空间来保存数据，所以当新插入一个元素时，ziplist就需要计算其所需的空间大小，并申请相应的内存空间。这一系列操作，我们可以从ziplist的元素插入函数__ziplistInsert中看到。</p><p><strong>__ziplistInsert函数首先会计算获得当前ziplist的长度</strong>，这个步骤通过ZIPLIST_BYTES宏定义就可以完成，如下所示。同时，该函数还声明了reqlen变量，用于记录插入元素后所需的新增空间大小。</p><pre><code>//获取当前ziplist长度curlen；声明reqlen变量，用来记录新插入元素所需的长度\nsize_t curlen = intrev32ifbe(ZIPLIST_BYTES(zl)), reqlen;\n</code></pre><p>然后，<strong>__ziplistInsert函数会判断当前要插入的位置是否是列表末尾</strong>。如果不是末尾，那么就需要获取位于当前插入位置的元素的prevlen和prevlensize。这部分代码如下所示：</p><pre><code>//如果插入的位置不是ziplist末尾，则获取前一项长度\n   if (p[0] != ZIP_END) {\n\t  ZIP_DECODE_PREVLEN(p, prevlensize, prevlen);\n\t  } else {\n\t     …\n\t  }\n</code></pre><p>实际上，在ziplist中，每一个元素都会记录其<strong>前一项的长度，也就是prevlen</strong>。然后，为了节省内存开销，ziplist会使用不同的空间记录prevlen，这个<strong>prevlen空间大小就是prevlensize</strong>。</p><p>举个简单的例子，当在一个元素A前插入一个新的元素B时，A的prevlen和prevlensize都要根据B的长度进行相应的变化。</p><p>那么现在，我们假设A的prevlen原本只占用1字节（也就是prevlensize等于1），而能记录的前一项长度最大为253字节。此时，如果B的长度超过了253字节，A的prevlen就需要使用5个字节来记录（prevlen具体的编码方式，你可以复习回顾下第4讲），这样就需要申请额外的4字节空间了。不过，如果元素B的插入位置是列表末尾，那么插入元素B时，我们就不用考虑后面元素的prevlen了。</p><p>我画了下面这张图，以便于你理解数据插入过程对插入位置元素的影响。</p><p><img src=\"https://static001.geekbang.org/resource/image/de/45/de43202b0afb4e5394c5323fc9f93a45.jpg?wh=2000x1125\" alt=\"\"></p><p>因此，为了保证ziplist有足够的内存空间，来保存插入元素以及插入位置元素的prevlen信息，<strong>__ziplistInsert函数在获得插入位置元素的prevlen和prevlensize后，紧接着就会计算插入元素的长度</strong>。</p><p>现在我们已知，一个ziplist元素包括了prevlen、encoding和实际数据data三个部分。所以，在计算插入元素的所需空间时，__ziplistInsert函数也会分别计算这三个部分的长度。这个计算过程一共可以分成四步来完成。</p><ul>\n<li>第一步，计算实际插入元素的长度。</li>\n</ul><p>首先你要知道，这个计算过程和插入元素是整数还是字符串有关。__ziplistInsert函数会先调用zipTryEncoding函数，这个函数会判断插入元素是否为整数。如果是整数，就按照不同的整数大小，计算encoding和实际数据data各自所需的空间；如果是字符串，那么就先把字符串长度记录为所需的新增空间大小。这一过程的代码如下所示：</p><pre><code>\tif (zipTryEncoding(s,slen,&amp;value,&amp;encoding)) {\n\t        reqlen = zipIntSize(encoding);\n\t    } else {\n\t        reqlen = slen;\n\t    }\n</code></pre><ul>\n<li>第二步，调用zipStorePrevEntryLength函数，将插入位置元素的prevlen也计算到所需空间中。</li>\n</ul><p>这是因为在插入元素后，__ziplistInsert函数可能要为插入位置的元素分配新增空间。这部分代码如下所示：</p><pre><code>reqlen += zipStorePrevEntryLength(NULL,prevlen);\n</code></pre><ul>\n<li>第三步，调用zipStoreEntryEncoding函数，根据字符串的长度，计算相应encoding的大小。</li>\n</ul><p>在刚才的第一步中，__ziplistInsert函数对于字符串数据，只是记录了字符串本身的长度，所以在第三步中，__ziplistInsert函数还会调用zipStoreEntryEncoding函数，根据字符串的长度来计算相应的encoding大小，如下所示：</p><pre><code>reqlen += zipStoreEntryEncoding(NULL,encoding,slen);\n</code></pre><p>好了，到这里，__ziplistInsert函数就已经在reqlen变量中，记录了插入元素的prevlen长度、encoding大小，以及实际数据data的长度。这样一来，插入元素的整体长度就有了，这也是插入位置元素的prevlen所要记录的大小。</p><ul>\n<li>第四步，调用zipPrevLenByteDiff函数，判断插入位置元素的prevlen和实际所需的prevlen大小。</li>\n</ul><p>最后，__ziplistInsert函数会调用zipPrevLenByteDiff函数，用来判断插入位置元素的prevlen和实际所需的prevlen，这两者间的大小差别。这部分代码如下所示，prevlen的大小差别是使用nextdiff来记录的：</p><pre><code>nextdiff = (p[0] != ZIP_END) ? zipPrevLenByteDiff(p,reqlen) : 0;\n</code></pre><p>那么在这里，如果nextdiff大于0，就表明插入位置元素的空间不够，需要新增nextdiff大小的空间，以便能保存新的prevlen。然后，<strong>__ziplistInsert函数在新增空间时，就会调用ziplistResize函数，来重新分配ziplist所需的空间</strong>。</p><p>ziplistResize函数接收的参数分别是待重新分配的ziplist和重新分配的空间大小。而__ziplistInsert函数传入的重新分配大小的参数，是三个长度之和。</p><p>那么是哪三个长度之和呢？</p><p>这三个长度分别是ziplist现有大小（curlen）、待插入元素自身所需的新增空间（reqlen），以及插入位置元素prevlen所需的新增空间（nextdiff）。下面的代码显示了ziplistResize函数的调用和参数传递逻辑：</p><pre><code>zl = ziplistResize(zl,curlen+reqlen+nextdiff);\n</code></pre><p>进一步，那么ziplistResize函数在获得三个长度总和之后，具体是如何扩容呢？</p><p>我们可以进一步看下ziplistResize函数的实现，这个函数会调用<strong>zrealloc函数</strong>，来完成空间的重新分配，而重新分配的空间大小就是由<strong>传入参数len</strong>决定的。这样，我们就了解到了ziplistResize函数涉及到内存分配操作，因此如果我们往ziplist频繁插入过多数据的话，就可能引起多次内存分配，从而会对Redis性能造成影响。</p><p>下面的代码显示了ziplistResize函数的部分实现，你可以看下。</p><pre><code>unsigned char *ziplistResize(unsigned char *zl, unsigned int len) {\n    //对zl进行重新内存空间分配，重新分配的大小是len\n    zl = zrealloc(zl,len);\n    …\n    zl[len-1] = ZIP_END;\n    return zl;\n}\n</code></pre><p>好了，到这里，我们就了解了ziplist在新插入元素时，会计算其所需的新增空间，并进行重新分配。而当新插入的元素较大时，就会引起插入位置的元素prevlensize增加，进而就会导致插入位置的元素所占空间也增加。</p><p>而如此一来，这种空间新增就会引起连锁更新的问题。</p><p>实际上，所谓的<strong>连锁更新</strong>，就是指当一个元素插入后，会引起当前位置元素新增prevlensize的空间。而当前位置元素的空间增加后，又会进一步引起该元素的后续元素，其prevlensize所需空间的增加。</p><p>这样，一旦插入位置后续的所有元素，都会因为前序元素的prevlenszie增加，而引起自身空间也要增加，这种每个元素的空间都需要增加的现象，就是连锁更新。我画了下面这张图，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/b7/4c/b7f75261e8e72832220c98bf73a0eb4c.jpg?wh=2000x1125\" alt=\"\"></p><p>连锁更新一旦发生，就会导致ziplist占用的内存空间要多次重新分配，这就会直接影响到ziplist的访问性能。</p><p>所以说，虽然ziplist紧凑型的内存布局能节省内存开销，但是如果保存的元素数量增加了，或是元素变大了，ziplist就会面临性能问题。那么，有没有什么方法可以避免ziplist的问题呢？</p><p>这就是接下来我要给你介绍的quicklist和listpack，这两种数据结构的设计思想了。</p><h2>quicklist设计与实现</h2><p>我们先来学习下quicklist的实现思路。</p><p>quicklist的设计，其实是结合了链表和ziplist各自的优势。简单来说，<strong>一个quicklist就是一个链表，而链表中的每个元素又是一个ziplist。</strong></p><p>我们来看下quicklist的数据结构，这是在<a href=\"https://github.com/redis/redis/tree/5.0/src/quicklist.h\">quicklist.h</a>文件中定义的，而quicklist的具体实现是在<a href=\"https://github.com/redis/redis/tree/5.0/src/quicklist.c\">quicklist.c</a>文件中。</p><p>首先，quicklist元素的定义，也就是quicklistNode。因为quicklist是一个链表，所以每个quicklistNode中，都包含了分别指向它前序和后序节点的<strong>指针<code>*prev</code>和<code>*next</code></strong>。同时，每个quicklistNode又是一个ziplist，所以，在quicklistNode的结构体中，还有指向ziplist的<strong>指针<code>*zl</code></strong>。</p><p>此外，quicklistNode结构体中还定义了一些属性，比如ziplist的字节大小、包含的元素个数、编码格式、存储方式等。下面的代码显示了quicklistNode的结构体定义，你可以看下。</p><pre><code>typedef struct quicklistNode {\n    struct quicklistNode *prev;     //前一个quicklistNode\n    struct quicklistNode *next;     //后一个quicklistNode\n    unsigned char *zl;              //quicklistNode指向的ziplist\n    unsigned int sz;                //ziplist的字节大小\n    unsigned int count : 16;        //ziplist中的元素个数 \n    unsigned int encoding : 2;   //编码格式，原生字节数组或压缩存储\n    unsigned int container : 2;  //存储方式\n    unsigned int recompress : 1; //数据是否被压缩\n    unsigned int attempted_compress : 1; //数据能否被压缩\n    unsigned int extra : 10; //预留的bit位\n} quicklistNode;\n</code></pre><p>了解了quicklistNode的定义，我们再来看下quicklist的结构体定义。</p><p>quicklist作为一个链表结构，在它的数据结构中，是定义了<strong>整个quicklist的头、尾指针</strong>，这样一来，我们就可以通过quicklist的数据结构，来快速定位到quicklist的链表头和链表尾。</p><p>此外，quicklist中还定义了quicklistNode的个数、所有ziplist的总元素个数等属性。quicklist的结构定义如下所示：</p><pre><code>typedef struct quicklist {\n    quicklistNode *head;      //quicklist的链表头\n    quicklistNode *tail;      //quicklist的链表尾\n    unsigned long count;     //所有ziplist中的总元素个数\n    unsigned long len;       //quicklistNodes的个数\n    ...\n} quicklist;\n</code></pre><p>然后，从quicklistNode和quicklist的结构体定义中，我们就能画出下面这张quicklist的示意图。</p><p><img src=\"https://static001.geekbang.org/resource/image/bc/0e/bc725a19b5c1fd25ba7740bab5f9220e.jpg?wh=2000x890\" alt=\"\"></p><p>而也正因为quicklist采用了链表结构，所以当插入一个新的元素时，quicklist首先就会检查插入位置的ziplist是否能容纳该元素，这是通过 <strong>_quicklistNodeAllowInsert函数</strong>来完成判断的。</p><p>_quicklistNodeAllowInsert函数会计算新插入元素后的大小（new_sz），这个大小等于quicklistNode的当前大小（node-&gt;sz）、插入元素的大小（sz），以及插入元素后ziplist的prevlen占用大小。</p><p>在计算完大小之后，_quicklistNodeAllowInsert函数会依次判断新插入的数据大小（sz）是否满足要求，即<strong>单个ziplist是否不超过8KB，或是单个ziplist里的元素个数是否满足要求</strong>。</p><p>只要这里面的一个条件能满足，quicklist就可以在当前的quicklistNode中插入新元素，否则quicklist就会新建一个quicklistNode，以此来保存新插入的元素。</p><p>下面代码显示了是否允许在当前quicklistNode插入数据的判断逻辑，你可以看下。</p><pre><code>unsigned int new_sz = node-&gt;sz + sz + ziplist_overhead;\nif (likely(_quicklistNodeSizeMeetsOptimizationRequirement(new_sz, fill)))\n    return 1;\nelse if (!sizeMeetsSafetyLimit(new_sz))\n    return 0;\nelse if ((int)node-&gt;count &lt; fill)\n    return 1;\nelse\n    return 0;\n</code></pre><p>这样一来，quicklist通过控制每个quicklistNode中，ziplist的大小或是元素个数，就有效减少了在ziplist中新增或修改元素后，发生连锁更新的情况，从而提供了更好的访问性能。</p><p>而Redis除了设计了quicklist结构来应对ziplist的问题以外，还在5.0版本中新增了listpack数据结构，用来彻底避免连锁更新。下面我们就继续来学习下它的设计实现思路。</p><h2>listpack设计与实现</h2><p>listpack也叫紧凑列表，它的特点就是<strong>用一块连续的内存空间来紧凑地保存数据</strong>，同时为了节省内存空间，<strong>listpack列表项使用了多种编码方式，来表示不同长度的数据</strong>，这些数据包括整数和字符串。</p><p>和listpack相关的实现文件是<a href=\"https://github.com/redis/redis/tree/5.0/src/listpack.c\">listpack.c</a>，头文件包括<a href=\"https://github.com/redis/redis/tree/5.0/src/listpack.h\">listpack.h</a>和<a href=\"https://github.com/redis/redis/tree/5.0/src/listpack_malloc.h\">listpack_malloc.h</a>。我们先来看下listpack的<strong>创建函数lpNew</strong>，因为从这个函数的代码逻辑中，我们可以了解到listpack的整体结构。</p><p>lpNew函数创建了一个空的listpack，一开始分配的大小是LP_HDR_SIZE再加1个字节。LP_HDR_SIZE宏定义是在listpack.c中，它默认是6个字节，其中4个字节是记录listpack的总字节数，2个字节是记录listpack的元素数量。</p><p>此外，listpack的最后一个字节是用来标识listpack的结束，其默认值是宏定义LP_EOF。和ziplist列表项的结束标记一样，LP_EOF的值也是255。</p><pre><code>unsigned char *lpNew(void) {\n    //分配LP_HRD_SIZE+1\n    unsigned char *lp = lp_malloc(LP_HDR_SIZE+1);\n    if (lp == NULL) return NULL;\n    //设置listpack的大小\n    lpSetTotalBytes(lp,LP_HDR_SIZE+1);\n    //设置listpack的元素个数，初始值为0\n    lpSetNumElements(lp,0);\n    //设置listpack的结尾标识为LP_EOF，值为255\n    lp[LP_HDR_SIZE] = LP_EOF;\n    return lp;\n}\n</code></pre><p>你可以看看下面这张图，展示的就是大小为LP_HDR_SIZE的listpack头和值为255的listpack尾。当有新元素插入时，该元素会被插在listpack头和尾之间。</p><p><img src=\"https://static001.geekbang.org/resource/image/d6/60/d6ef170068fc14c7d901b9ff4935yy60.jpg?wh=2000x562\" alt=\"\"></p><p>好了，了解了listpack的整体结构后，我们再来看下listpack列表项的设计。</p><p>和ziplist列表项类似，listpack列表项也包含了元数据信息和数据本身。不过，为了避免ziplist引起的连锁更新问题，listpack中的每个列表项不再像ziplist列表项那样，保存其前一个列表项的长度，<strong>它只会包含三个方面内容</strong>，分别是当前元素的编码类型（entry-encoding）、元素数据(entry-data)，以及编码类型和元素数据这两部分的长度(entry-len)，如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/60/27/60833af3db19ccf12957cfe6467e9227.jpg?wh=2000x786\" alt=\"\"></p><p>这里，关于listpack列表项的设计，你需要重点掌握两方面的要点，分别是列表项元素的编码类型，以及列表项避免连锁更新的方法。下面我就带你具体了解下。</p><h3>listpack列表项编码方法</h3><p>我们先来看下listpack元素的编码类型。如果你看了listpack.c文件，你会发现该文件中有大量类似LP_ENCODING__XX_BIT_INT和LP_ENCODING__XX_BIT_STR的宏定义，如下所示：</p><pre><code>#define LP_ENCODING_7BIT_UINT 0\n#define LP_ENCODING_6BIT_STR 0x80\n#define LP_ENCODING_13BIT_INT 0xC0\n...\n#define LP_ENCODING_64BIT_INT 0xF4\n#define LP_ENCODING_32BIT_STR 0xF0\n</code></pre><p>这些宏定义其实就对应了listpack的元素编码类型。具体来说，<strong>listpack元素会对不同长度的整数和字符串进行编码</strong>，这里我们分别来看下。</p><p>首先，对于<strong>整数编码</strong>来说，当listpack元素的编码类型为LP_ENCODING_7BIT_UINT时，表示元素的实际数据是一个7 bit的无符号整数。又因为LP_ENCODING_7BIT_UINT本身的宏定义值为0，所以编码类型的值也相应为0，占1个bit。</p><p>此时，编码类型和元素实际数据共用1个字节，这个字节的最高位为0，表示编码类型，后续的7位用来存储7 bit的无符号整数，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/8c/fb/8c4bd520d3953f7e70b6e3f08543c6fb.jpg?wh=1752x710\" alt=\"\"></p><p>而当编码类型为LP_ENCODING_13BIT_INT时，这表示元素的实际数据是13 bit的整数。同时，因为LP_ENCODING_13BIT_INT的宏定义值为0xC0，转换为二进制值是1100 0000，所以，这个二进制值中的后5位和后续的1个字节，共13位，会用来保存13bit的整数。而该二进制值中的前3位110，则用来表示当前的编码类型。我画了下面这张图，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/3e/d7/3ecbb8412d41d0a36587dfdaf49714d7.jpg?wh=1897x712\" alt=\"\"></p><p>好，在了解了LP_ENCODING_7BIT_UINT和LP_ENCODING_13BIT_INT这两种编码类型后，剩下的LP_ENCODING_16BIT_INT、LP_ENCODING_24BIT_INT、LP_ENCODING_32BIT_INT和LP_ENCODING_64BIT_INT，你应该也就能知道它们的编码方式了。</p><p>这四种类型是分别用2字节（16 bit）、3字节（24 bit）、4字节（32 bit）和8字节（64 bit）来保存整数数据。同时，它们的编码类型本身占1字节，编码类型值分别是它们的宏定义值。</p><p>然后，对于<strong>字符串编码</strong>来说，一共有三种类型，分别是LP_ENCODING_6BIT_STR、LP_ENCODING_12BIT_STR和LP_ENCODING_32BIT_STR。从刚才的介绍中，你可以看到，整数编码类型名称中BIT前面的数字，表示的是整数的长度。因此类似的，字符串编码类型名称中BIT前的数字，表示的就是字符串的长度。</p><p>比如，当编码类型为LP_ENCODING_6BIT_STR时，编码类型占1字节。该类型的宏定义值是0x80，对应的二进制值是1000 0000，这其中的前2位是用来标识编码类型本身，而后6位保存的是字符串长度。然后，列表项中的数据部分保存了实际的字符串。</p><p>下面的图展示了三种字符串编码类型和数据的布局，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/9c/25/9c17c0be0519100c509e2378acd6e125.jpg?wh=2000x1125\" alt=\"\"></p><h3>listpack避免连锁更新的实现方式</h3><p>最后，我们再来了解下listpack列表项是如何避免连锁更新的。</p><p>在listpack中，因为每个列表项只记录自己的长度，而不会像ziplist中的列表项那样，会记录前一项的长度。所以，当我们在listpack中新增或修改元素时，实际上只会涉及每个列表项自己的操作，而不会影响后续列表项的长度变化，这就避免了连锁更新。</p><p>不过，你可能会有疑问：<strong>如果listpack列表项只记录当前项的长度，那么listpack支持从左向右正向查询列表，或是从右向左反向查询列表吗？</strong></p><p>其实，listpack是能支持正、反向查询列表的。</p><p><strong>当应用程序从左向右正向查询listpack时</strong>，我们可以先调用lpFirst函数。该函数的参数是指向listpack头的指针，它在执行时，会让指针向右偏移LP_HDR_SIZE大小，也就是跳过listpack头。你可以看下lpFirst函数的代码，如下所示：</p><pre><code>unsigned char *lpFirst(unsigned char *lp) {\n    lp += LP_HDR_SIZE; //跳过listpack头部6个字节\n    if (lp[0] == LP_EOF) return NULL;  //如果已经是listpack的末尾结束字节，则返回NULL\n    return lp;\n}\n</code></pre><p>然后，再调用lpNext函数，该函数的参数包括了指向listpack某个列表项的指针。lpNext函数会进一步调用lpSkip函数，并传入当前列表项的指针，如下所示：</p><pre><code>unsigned char *lpNext(unsigned char *lp, unsigned char *p) {\n    ...\n    p = lpSkip(p);  //调用lpSkip函数，偏移指针指向下一个列表项\n    if (p[0] == LP_EOF) return NULL;\n    return p;\n}\n</code></pre><p>最后，lpSkip函数会先后调用lpCurrentEncodedSize和lpEncodeBacklen这两个函数。</p><p>lpCurrentEncodedSize函数是根据当前列表项第1个字节的取值，来计算当前项的编码类型，并根据编码类型，计算当前项编码类型和实际数据的总长度。然后，lpEncodeBacklen函数会根据编码类型和实际数据的长度之和，进一步计算列表项最后一部分entry-len本身的长度。</p><p>这样一来，lpSkip函数就知道当前项的编码类型、实际数据和entry-len的总长度了，也就可以将当前项指针向右偏移相应的长度，从而实现查到下一个列表项的目的。</p><p>下面代码展示了lpEncodeBacklen函数的基本计算逻辑，你可以看下。</p><pre><code>unsigned long lpEncodeBacklen(unsigned char *buf, uint64_t l) {\n    //编码类型和实际数据的总长度小于等于127，entry-len长度为1字节\n    if (l &lt;= 127) {\n        ...\n        return 1;\n    } else if (l &lt; 16383) { //编码类型和实际数据的总长度大于127但小于16383，entry-len长度为2字节\n       ...\n        return 2;\n    } else if (l &lt; 2097151) {//编码类型和实际数据的总长度大于16383但小于2097151，entry-len长度为3字节\n       ...\n        return 3;\n    } else if (l &lt; 268435455) { //编码类型和实际数据的总长度大于2097151但小于268435455，entry-len长度为4字节\n        ...\n        return 4;\n    } else { //否则，entry-len长度为5字节\n       ...\n        return 5;\n    }\n}\n</code></pre><p>我也画了一张图，展示了从左向右遍历listpack的基本过程，你可以再回顾下。</p><p><img src=\"https://static001.geekbang.org/resource/image/a9/be/a9e7c837959f8d01bff8321135c484be.jpg?wh=2000x1125\" alt=\"\"></p><p>好，了解了从左向右正向查询listpack，我们再来看下<strong>从右向左反向查询listpack</strong>。</p><p>首先，我们根据listpack头中记录的listpack总长度，就可以直接定位到listapck的尾部结束标记。然后，我们可以调用lpPrev函数，该函数的参数包括指向某个列表项的指针，并返回指向当前列表项前一项的指针。</p><p>lpPrev函数中的关键一步就是调用lpDecodeBacklen函数。lpDecodeBacklen函数会从右向左，逐个字节地读取当前列表项的entry-len。</p><p>那么，<strong>lpDecodeBacklen函数如何判断entry-len是否结束了呢？</strong></p><p>这就依赖于entry-len的编码方式了。entry-len每个字节的最高位，是用来表示当前字节是否为entry-len的最后一个字节，这里存在两种情况，分别是：</p><ul>\n<li>最高位为1，表示entry-len还没有结束，当前字节的左边字节仍然表示entry-len的内容；</li>\n<li>最高位为0，表示当前字节已经是entry-len最后一个字节了。</li>\n</ul><p>而entry-len每个字节的低7位，则记录了实际的长度信息。这里你需要注意的是，entry-len每个字节的低7位采用了<strong>大端模式存储</strong>，也就是说，entry-len的低位字节保存在内存高地址上。</p><p>我画了下面这张图，展示了entry-len这种特别的编码方式，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/4a/5c/4ae6140ca6b08f35b9eb245c4627245c.jpg?wh=2000x1125\" alt=\"\"></p><p>实际上，正是因为有了entry-len的特别编码方式，lpDecodeBacklen函数就可以从当前列表项起始位置的指针开始，向左逐个字节解析，得到前一项的entry-len值。这也是lpDecodeBacklen函数的返回值。而从刚才的介绍中，我们知道entry-len记录了编码类型和实际数据的长度之和。</p><p>因此，lpPrev函数会再调用lpEncodeBacklen函数，来计算得到entry-len本身长度，这样一来，我们就可以得到前一项的总长度，而lpPrev函数也就可以将指针指向前一项的起始位置了。所以按照这个方法，listpack就实现了从右向左的查询功能。</p><h2>小结</h2><p>这节课，我从ziplist的设计不足出发，依次给你介绍了quicklist和listpack的设计思想。</p><p>你要知道，ziplist的不足主要在于<strong>一旦ziplist中元素个数多了，它的查找效率就会降低</strong>。而且如果在ziplist里新增或修改数据，ziplist占用的内存空间还需要重新分配；更糟糕的是，ziplist新增某个元素或修改某个元素时，可能会导致后续元素的prevlen占用空间都发生变化，从而引起连锁更新问题，导致每个元素的空间都要重新分配，这就会导致ziplist的访问性能下降。</p><p>所以，为了应对ziplist的问题，Redis先是在3.0版本中设计实现了quicklist。quicklist结构在ziplist基础上，使用链表将ziplist串联起来，链表的每个元素就是一个ziplist。这种设计<strong>减少了数据插入时内存空间的重新分配，以及内存数据的拷贝</strong>。同时，quicklist限制了每个节点上ziplist的大小，一旦一个ziplist过大，就会采用新增quicklist节点的方法。</p><p>不过，又因为quicklist使用quicklistNode结构指向每个ziplist，无疑增加了内存开销。为了<strong>减少内存开销，并进一步避免ziplist连锁更新问题</strong>，Redis在5.0版本中，就设计实现了listpack结构。listpack结构沿用了ziplist紧凑型的内存布局，把每个元素都紧挨着放置。</p><p>listpack中每个列表项不再包含前一项的长度了，因此当某个列表项中的数据发生变化，导致列表项长度变化时，其他列表项的长度是不会受影响的，因而这就避免了ziplist面临的连锁更新问题。</p><p>总而言之，Redis在内存紧凑型列表的设计与实现上，从ziplist到quicklist，再到listpack，你可以看到Redis在内存空间开销和访问性能之间的设计取舍，这一系列的设计变化，是非常值得你学习的。</p><h2>每课一问</h2><p>ziplist会使用zipTryEncoding函数计算插入元素所需的新增内存空间，假设插入的一个元素是整数，你知道ziplist能支持的最大整数是多大吗？</p><p>欢迎在留言区分享你的答案和思考过程，如果觉得有收获，也欢迎你把今天的内容分享给更多的朋友。</p>","neighbors":{"left":{"article_title":"05 | 有序集合为何能同时支持点查询和范围查询？","id":404391},"right":{"article_title":"07 | 为什么Stream使用了Radix Tree？","id":406284}}},{"article_id":406284,"article_title":"07 | 为什么Stream使用了Radix Tree？","article_content":"<p>你好，我是蒋德钧。这节课，我们继续从底层数据结构的视角出发，来聊聊Redis中的Stream数据类型是如何保存消息的。</p><p>Redis从5.0版本开始支持提供Stream数据类型，它可以用来保存消息数据，进而能帮助我们实现一个带有消息读写基本功能的消息队列，并用于日常的分布式程序通信当中。我在讲<a href=\"https://time.geekbang.org/column/article/284291\">如何使用Redis实现消息队列</a>的时候，曾介绍过Stream。当时，有不少同学就说想学习了解下Stream的实现，以便掌握Stream内部结构的操作特点，但自己对Stream类型不太熟悉，不知道Stream底层是采用怎样的数据结构来保存消息数据的。</p><p>其实，为了节省内存空间，在Stream数据类型的底层数据结构中，采用了<strong>Radix Tree和listpack</strong>两种数据结构来保存消息。我在<a href=\"https://time.geekbang.org/column/article/405387\">第6讲</a>已经给你介绍过了listpack，它是一个紧凑型列表，在保存数据时会非常节省内存。</p><p>所以今天这节课，我就来给你介绍下Stream用到的另一个数据结构Radix Tree。这个数据结构的<strong>最大特点是适合保存具有相同前缀的数据</strong>，从而实现节省内存空间的目标，以及支持范围查询。</p><p>同时，和常见的B树或B+树类似，Radix Tree也是一种重要的树型结构，在操作系统内核和数据库中也有应用。所以，了解Radix Tree的设计与实现，既可以帮助我们掌握Stream的实现思路，还可以让我们把Radix Tree应用到需要节省内存的有序树型索引场景中，进一步解决具有公共前缀的大量数据保存时的内存开销问题。</p><!-- [[[read_end]]] --><p>好，那么接下来，我们先来了解下Stream保存的消息数据的特征，这也是Redis使用Radix Tree和listpack作为底层结构保存消息的重要考虑因素。</p><h2>Stream消息数据的特征</h2><p>首先，Stream作为消息队列，它保存的消息通常具有以下两个特征：</p><ul>\n<li>一条消息由一个或多个键值对组成；</li>\n<li>每插入一条消息，这条消息都会对应一个消息ID。</li>\n</ul><blockquote>\n<p>我们一般会让Redis服务器自动生成递增的消息ID。此时，消息ID由时间戳和序号组成。其中，时间戳是消息插入时，以毫秒为单位的服务器当时时间，序号是插入消息在当前毫秒内的序号。</p>\n</blockquote><p>比如，我在Redis实例中执行以下操作，可以向名为devmsg的消息流中，连续插入5条消息。其中，每条消息记录的是某个设备ID对应的设备温度信息。</p><pre><code>127.0.0.1:6379&gt; XADD devmsg * dev 3 temp 26\n&quot;1628172536845-0&quot;\n127.0.0.1:6379&gt; XADD devmsg * dev 5 temp 28\n&quot;1628172545411-0&quot;\n127.0.0.1:6379&gt; XADD devmsg * dev 8 temp 24\n&quot;1628172553528-0&quot;\n127.0.0.1:6379&gt; XADD devmsg * dev 1 temp 25\n&quot;1628172560442-0&quot;\n127.0.0.1:6379&gt; XADD devmsg * dev 5 temp 26\n&quot;1628172565683-0&quot;\n</code></pre><p>从上面的插入数据和返回结果中，我们可以看到，对应Stream类型来说，它需要保存的数据也具有两个特征：</p><ul>\n<li>连续插入的消息ID，其前缀有较多部分是相同的。比如，刚才插入的5条消息，它们消息ID的前8位都是16281725。</li>\n<li>连续插入的消息，它们对应键值对中的键通常是相同的。比如，刚才插入的5条消息，它们消息中的键都是dev和temp。</li>\n</ul><p>那么，针对Stream的这两个数据特征，我们该设计使用什么样的数据结构来保存这些消息数据呢？</p><p>你可能会想到使用哈希表，一个消息ID对应哈希表中的一个key，消息内容对应这个key的value。但是，就像刚才介绍的数据特征一样，消息ID和消息中的键经常会有重复的部分。如果使用哈希表，就会导致有不少冗余数据，这会浪费Redis宝贵的内存空间。</p><p>因此，为了充分节省内存空间，Stream使用了两种内存友好的数据结构：listpack和Radix Tree。其中，<strong>消息ID是作为Radix Tree中的key，消息具体数据是使用listpack保存，并作为value和消息ID一起保存到Radix Tree中。</strong></p><p>你可以看看下面的Stream结构体定义，其中，消息就是使用Radix Tree类型的结构<code>*rax</code>来保存的。</p><pre><code>typedef struct stream {\n    rax *rax;               //保存消息的Radix Tree\n    uint64_t length;        //消息流中的消息个数\n    streamID last_id;       //当前消息流中最后插入的消息的ID\n    rax *cgroups;           //当前消息流的消费组信息，也是用Radix Tree保存\n} stream;\n</code></pre><p>好了，那么Radix Tree的结构到底是怎样的呢？下面我们就来学习下Radix Tree的基本结构。</p><h2>Radix Tree的基本结构</h2><p>Radix Tree是属于前缀树的一种类型。前缀树也称为Trie Tree，它的特点是，保存在树上的每个key会被拆分成单字符，然后逐一保存在树上的节点中。前缀树的根节点不保存任何字符，而除了根节点以外的其他节点，每个节点只保存一个字符。当我们把从根节点到当前节点的路径上的字符拼接在一起时，就可以得到相应key的值了。</p><p>下面这张图展示了一个简单的前缀树，你可以看下。图中的前缀树有两个叶子节点，将根节点到这两个叶子节点的路径上，对应的字符拼接起来后，就得到了两个key：read和real。</p><p><img src=\"https://static001.geekbang.org/resource/image/04/56/04f86e94817aca643a8d2c05c580c856.jpg?wh=2000x1125\" alt=\"\"></p><p>另外从图中，我们还可以看到，前缀树是把保存的key的公共前缀（即r、e、a）独立出来共享使用的。这样一来，就可以避免在树中对相同的字符做重复存储。</p><p>而如果不采用这种方法，只是把这两个key保存在哈希表中，那么key的相同前缀就会被单独存储，这样就会导致内存空间的浪费。所以，<strong>相比哈希表的保存方式，前缀树能够很好地节省内存空间，这对于Redis来说是非常重要的。</strong></p><h3>前缀树的不足和Radix Tree的改进</h3><p>当然，前缀树在每个节点中只保存一个字符，这样做的好处就是可以尽可能地共享不同key的公共前缀。但是，这也会导致key中的某些字符串，虽然不再被共享，可仍然会按照每个节点一个字符的形式来保存，这样反而会造成空间的浪费和查询性能的降低。</p><p>我来给你举个例子，假设有5个key，分别是radix、race、read、real和redis，它们在前缀树上的布局如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/f4/50/f44c4bc26d2d4b09a1701d09697c5550.jpg?wh=2000x1125\" alt=\"\"></p><p>对于“redis”来说，因为它和“read”“real”共享“r”和“e”，和“radix”“race”共享“r”，也就是说“r”和“e”节点都分别指向多个子节点。类似的，“real”和“read”共享了“r”“e”和“a”前缀，“a”节点也指向了多个子节点。所以，在前缀树的节点中单独保存“r”“e”“a”是很有必要的。</p><p>但是，我们还是看“redis”这个key，除了“r”“e”字符和其他key有共享外，“re”后面的“dis”没有再被其他key共享了。所以此时，其实并没有必要再对“dis”进行拆分，将其分成单个字符“d”“i”和“s”来保存，而是可以把它们合并在一起保存。</p><p>那么到这里，你就可以发现，在前缀树上，确实有的字符需要单独保存，用来作为不同key的公共前缀进行共享，但其实有的单字符节点可以和其他单字符节点进行合并，这样能进一步节省空间。</p><p>而从一个更加通用的角度来说，在前缀树的某个节点开始，如果从该节点到另外一个节点之间，每一个节点都只有一个子节点，那就表明这些节点对应的字符，并没有和其他节点共享了。那么如果我们还是按照前缀树的方式，为每一个字符创建一个节点进行保存的话，一是会<strong>浪费内存空间</strong>，二是在进行查询时，还需要逐一匹配每个节点表示的字符，<strong>对查询性能也会造成影响</strong>。</p><p>所以，在前缀树中，如果一系列单字符节点之间的分支连接是唯一的，那么这些单字符节点就可以合并成一个节点，而这种结构的树，就正是<strong>Radix Tree，也被称为基数树</strong>。相比前缀树来说，Radix Tree既可以节约内存的使用，同时还可以提高查询访问的效率。</p><p>我画了下面这张图，展示了刚才介绍的前缀树上的5个key（radix、race、read、real和redis），在Radix Tree上的布局，你可以对照着看下它们在前缀树布局上的不同之处。</p><p><img src=\"https://static001.geekbang.org/resource/image/52/84/5235453fd27d1f97fcc42abd22d04084.jpg?wh=2000x950\" alt=\"\"></p><h3>Radix Tree数据结构</h3><p>好了，从刚才介绍的Radix Tree的结构中，我们其实可以发现，在Radix Tree中存在两类节点。</p><p><strong>第一类节点是非压缩节点</strong>，这类节点会包含多个指向不同子节点的指针，以及多个子节点所对应的字符，比如前面Radix Tree例子中的节点“r”，这个节点就包含了指向子节点“a”和“e”的指针。同时，如果从根节点到一个非压缩节点的路径上的字符串，已经对应了Radix Tree中保存的一个key，那么这个非压缩节点中还包含了指向这个key对应的value的指针。</p><p>比如，下面这张图就显示了刚才例子中的节点r，它是一个非压缩节点，指向了两个子节点，这两个子节点对应的字符分别是“a”和“e”，这个非压缩节点包含了指向子节点a和e的指针。此外，非压缩节点头部保存的HDR，是Radix Tree节点数据结构中的元数据，我一会儿会给你具体介绍它。</p><p><img src=\"https://static001.geekbang.org/resource/image/61/62/61016426c97acb2b9465b2df5befb662.jpg?wh=2000x813\" alt=\"\"></p><p><strong>第二类节点是压缩节点</strong>，这类节点会包含一个指向子节点的指针，以及子节点所代表的合并的字符串。比如前面Radix Tree例子中的节点e，这个节点指向的子节点包含的字符串就是合并的字符串“dis”。和非压缩节点类似，如果从根节点到一个压缩节点的路径上的字符串，已经对应了Radix Tree中保存的一个key，那么，这个压缩节点中还包含指向这个key对应的value的指针。</p><p>下图展示的就是一个压缩节点，它包含一个指向子节点的指针，这个子节点表示的合并字符串是“is”，所以在当前这个压缩节点中，保存了合并字符“is”。而和非压缩节点类似，压缩节点的头部HDR，保存的也是Radix Tree节点结构中的元数据。</p><p><img src=\"https://static001.geekbang.org/resource/image/82/d0/822ebedaf35cb59c8be7ecd2c90b3dd0.jpg?wh=2000x735\" alt=\"\"></p><p>既然，这两类节点的头部HDR中都保存了元数据，下面我们就来看看，这些元数据都包括了什么内容。</p><p>首先，我们需要了解下Radix Tree的节点数据结构。Radix Tree节点的数据结构是由<a href=\"https://github.com/redis/redis/tree/5.0/src/rax.h\">rax.h</a>文件中的raxNode定义的，如下所示：</p><pre><code>typedef struct raxNode {\n    uint32_t iskey:1;     //节点是否包含key\n    uint32_t isnull:1;    //节点的值是否为NULL\n    uint32_t iscompr:1;   //节点是否被压缩\n    uint32_t size:29;     //节点大小\n    unsigned char data[]; //节点的实际存储数据\n} raxNode;\n</code></pre><p>该结构中的成员变量包括4个元数据，这四个元数据的含义分别如下。</p><ul>\n<li><strong>iskey</strong>：表示从Radix Tree的根节点到当前节点路径上的字符组成的字符串，是否表示了一个完整的key。如果是的话，那么iskey的值为1。否则，iskey的值为0。不过，这里需要注意的是，当前节点所表示的key，并不包含该节点自身的内容。</li>\n<li><strong>isnull</strong>：表示当前节点是否为空节点。如果当前节点是空节点，那么该节点就不需要为指向value的指针分配内存空间了。</li>\n<li><strong>iscompr</strong>：表示当前节点是非压缩节点，还是压缩节点。</li>\n<li><strong>size</strong>：表示当前节点的大小，具体值会根据节点是压缩节点还是非压缩节点而不同。如果当前节点是压缩节点，该值表示压缩数据的长度；如果是非压缩节点，该值表示该节点指向的子节点个数。</li>\n</ul><p>这4个元数据就对应了刚才介绍的压缩节点和非压缩节点头部的HDR，其中，iskey、isnull和iscompr分别用1 bit表示，而size占用29 bit。</p><p>另外，从raxNode结构体中，我们还可以看到，除了元数据，该结构体中还有char类型数组data。我们知道，data是用来保存实际数据的。不过，这里保存的数据会根据当前节点的类型而有所不同：</p><ul>\n<li><strong>对于非压缩节点来说</strong>，data数组包括子节点对应的字符、指向子节点的指针，以及节点表示key时对应的value指针；</li>\n<li><strong>对于压缩节点来说</strong>，data数组包括子节点对应的合并字符串、指向子节点的指针，以及节点为key时的value指针。</li>\n</ul><p>好了，到这里，你可能已经发现，在raxNode的实现中，无论是非压缩节点还是压缩节点，其实具有两个特点：</p><ul>\n<li>它们所代表的key，是从根节点到当前节点路径上的字符串，但并不包含当前节点；</li>\n<li>它们本身就已经包含了子节点代表的字符或合并字符串。而对于它们的子节点来说，也都属于非压缩或压缩节点，所以，<strong>子节点本身又会保存，子节点的子节点所代表的字符或合并字符串</strong>。</li>\n</ul><p>而这两个特点就给Radix Tree实际保存数据时的结构，带来了两个方面的变化。</p><p>一方面，Radix Tree非叶子节点，要不然是压缩节点，只指向单个子节点，要不然是非压缩节点，指向多个子节点，但每个子节点只表示一个字符。所以，<strong>非叶子节点无法同时指向表示单个字符的子节点和表示合并字符串的子节点</strong>。</p><p>我给你举个例子，在下图的左半部分，节点r的子节点a，它的两个子节点表示的都是合并字符串“dix”和“ce”。因此，节点a的raxNode结构，无法同时指向dix子节点和ce子节点。类似的，r节点的子节点e，它的两个子节点，一个表示的是单字符“a”，另一个表示的是合并字符串“dis”，节点e的raxNode结构也无法同时指向这两个子节点。</p><p>所以，在实际使用raxNode结构保存数据时，节点dix会被拆为节点d和ix，节点ce会被拆为节点c和e，节点dis会被拆为节点d和is，如下图的右半部分所示。这样一来，节点r的子节点a和e，就可以用非压缩节点的结构来保存了。</p><p><img src=\"https://static001.geekbang.org/resource/image/09/dd/09bd522df6dbaa3216acd20b0248a2dd.jpg?wh=2000x1003\" alt=\"\"></p><p>我们再来看另一方面，对于Radix Tree的叶子节点来说，因为它没有子节点了，所以，<strong>Redis会用一个不包含子节点指针的raxNode节点来表示叶子节点</strong>，也就是说，叶子节点的raxNode元数据size为0，没有子节点指针。如果叶子节点代表了一个key，那么它的raxNode中是会保存这个key的value指针的。</p><p>为了便于你理解非压缩节点、压缩节点和叶子节点的raxNode结构内容，我画了下面这张图，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/7c/cd/7c6b7d2a809178c80405bb5e667b21cd.jpg?wh=2000x1104\" alt=\"\"></p><p>这张图上显示了Radix Tree最右侧分支的4个节点r、e、d、is和它们各自的raxNode内容。其中，节点r、e和d都不代表key，所以它们的iskey值为0，isnull值为1，没有为value指针分配空间。</p><p>节点r和e指向的子节点都是单字符节点，所以它们不是压缩节点，iscompr值为0。而节点d的子节点包含了合并字符串“is”，所以该节点是压缩节点，iscompr值为1。最后的叶子节点is，它的raxNode的size为0，没有子节点指针。不过，因为从根节点到节点is路径上的字符串代表了key“redis”，所以，节点is的value指针指向了“redis”对应的value数据。</p><p>这里，你需要注意的是，<strong>为了满足内存对齐的需要，raxNode会根据保存的字符串长度，在字符串后面填充一些字节</strong>，也就是图中的padding部分。</p><p>好了，到这里，你应该就理解了Radix Tree中不同节点的raxNode结构内容。那么接下来，我们再来了解下Radix Tree的基本操作函数。</p><h2>Radix Tree的操作函数</h2><p>Radix Tree的基本操作函数都是在<a href=\"https://github.com/redis/redis/tree/5.0/src/rax.c\">rax.c</a>文件中实现的，主要有以下几种。</p><ul>\n<li><strong>raxNew函数</strong></li>\n</ul><p>该函数的原型如下，它会调用rax_malloc函数分配一个新的rax结构体空间。</p><pre><code>rax *raxNew(void) \n</code></pre><p>rax结构体的定义如下所示，其中包含了Radix Tree中的key个数、节点个数，以及指向头节点的指针，而raxNew函数会调用raxNewNode函数来创建头节点。</p><pre><code>typedef struct rax {\n    raxNode *head;  //Radix Tree的头指针\n    uint64_t numele;  //Radix Tree中key的个数\n    uint64_t numnodes; //Radix Tree中raxNode的个数\n} rax;\n</code></pre><ul>\n<li><strong>raxNewNode函数</strong></li>\n</ul><p>该函数的原型如下，用来创建一个新的非压缩节点。它的参数children表示该非压缩节点的子节点个数，参数datafield表示是否要为value指针分配空间。</p><pre><code>raxNode *raxNewNode(size_t children, int datafield) \n</code></pre><p>这里，你需要注意的是，压缩节点的创建并不是通过raxNewNode函数来完成的，而是通过raxCompressNode函数来实现的。</p><ul>\n<li><strong>raxGenericInsert函数</strong></li>\n</ul><p>该函数原型如下，用来向Radix Tree中插入一个长度为len的字符串s。</p><pre><code>int raxGenericInsert(rax *rax, unsigned char *s, size_t len, void *data, void **old, int overwrite) \n</code></pre><ul>\n<li><strong>raxLowWalk函数</strong></li>\n</ul><p>该函数原型如下，当需要在Radix Tree中查找、插入或是删除节点时，都会调用该函数。</p><pre><code>static inline size_t raxLowWalk(rax *rax, unsigned char *s, size_t len, raxNode **stopnode, raxNode ***plink, int *splitpos, raxStack *ts)\n</code></pre><ul>\n<li><strong>raxGetData/raxSetData函数</strong></li>\n</ul><p>这两个函数的原型如下所示，它们分别用来获得raxNode中保存的value指针，以及设置raxNode中保存的value指针。</p><pre><code>void *raxGetData(raxNode *n) \nvoid raxSetData(raxNode *n, void *data)\n</code></pre><p>好了，了解了Radix Tree的基本操作函数后，我们最后再来看下，Stream是如何把Radix Tree和listpack组合起来使用的。</p><h2>Stream如何组合使用Radix Tree和listpack？</h2><p>我们知道，Stream保存的消息数据，按照key-value形式来看的话，消息ID就相当于key，而消息内容相当于是value。也就是说，Stream会使用Radix Tree来保存消息ID，然后将消息内容保存在listpack中，并作为消息ID的value，用raxNode的value指针指向对应的listpack。</p><p>这里我放了一张图，展示了Stream结构、rax、raxNode以及listpack相互之间的关系。注意，在这张图中，我们假设就只有一个streamID作为key。</p><p><img src=\"https://static001.geekbang.org/resource/image/1e/0d/1e5aa7509b25bb94d53c183130d3460d.jpg?wh=2000x1125\" alt=\"\"></p><p>我们可以看到，stream结构体中的rax指针，指向了Radix Tree的头节点，也就是rax结构体。rax结构体中的头指针进一步指向了第一个raxNode。因为我们假设就只有一个streamID，暂时没有其他streamID和该streamID共享前缀，所以，当前这个streamID就可以用压缩节点保存。</p><p>然后，第一个raxNode指向了下一个raxNode，也是Radix Tree的叶子节点。这个节点的size为0，它的value指针指向了实际的消息内容。</p><p>而在消息内容这里，是使用了listpack进行保存的。你可以看到，listpack中是使用了master entry来保存键值对类型消息中的键，而值会在master entry后面保存。这种保存方式其实也是为了<strong>节省内存空间</strong>，这是因为很多消息的键是相同的，保存一份就行。关于在Stream中，将消息的键和值分开保存到listpack中的这种设计方法，我会在后面的课程中继续给你详细介绍。</p><h2>小结</h2><p>今天这节课上，我带你学习了Redis Stream数据类型的底层实现结构。现在你已经知道，Stream最主要的作用就是可以<strong>用来保存消息数据</strong>。</p><p>每条消息都会有一个时间戳和序号组成的消息ID，以及键值对组成的消息内容。而因为不同消息ID中的时间戳，通常会共享部分相同的前缀，如果采用诸如哈希表的结构来保存消息，每个消息ID都单独保存，容易造成空间浪费。因此，Stream为了节省内存空间，采用了Radix Tree来保存消息ID，同时使用listpack来保存消息本身的内容。</p><p>在Radix Tree的设计实现中，它的整体结构和节点数据结构是理解Radix Tree的重要基础，所以，你要重点关注Radix Tree的非压缩节点和压缩节点类型，以及源码中的实际数据结构raxNode。</p><p>另外，为了方便你更好地掌握非压缩节点和压缩节点，我再给你总结下它们的相同之处和区别，你也可以来整体回顾下。</p><p>它们的<strong>相同之处</strong>在于：</p><ul>\n<li>都有保存元数据的节点头HDR；</li>\n<li>都会包含指向子节点的指针，以及子节点所代表的字符串。</li>\n<li>从根节点到当前节点路径上的字符串如果是Radix Tree的一个key，它们都会包含指向key对应value的指针。</li>\n</ul><p><strong>不同之处</strong>在于：</p><ul>\n<li>非压缩节点指向的子节点，每个子节点代表一个字符，非压缩节点可以指向多个子节点；</li>\n<li>压缩节点指向的子节点，代表的是一个合并字符串，压缩节点只能指向一个子节点。</li>\n</ul><p>而除了学习raxNode，我还给你介绍了下Radix Tree中几个基本操作函数的作用，并展示了Stream类型是如何把消息ID和消息内容，分别保存在Radix Tree和listpack中的。</p><p>这里<strong>你要注意</strong>的是，因为Radix Tree在保存具有公共前缀的数据时，能有效节省内存开销。同时，Radix Tree本身也是有序的树型索引，可以支持单点和范围查询。所以，Redis把消息ID保存在Radix Tree中，既可以节省内存空间，也能高效支持消息ID的查询。而listpack本身是紧凑列表，在保存大量消息内容的同时，也能有效节省内存。</p><p>所以我希望，你能通过Stream对Radix Tree和listpack的使用，举一反三，把它们用在相应的消息存取或是大量字符串存取的场景中。</p><h2>每课一问</h2><p>作为有序索引，Radix Tree也能提供范围查询，那么与我们日常使用的B+树，以及<a href=\"https://time.geekbang.org/column/article/404391\">第5讲</a>中介绍的跳表相比，你觉得Radix Tree有什么优势和不足吗？</p><p>欢迎在留言区分享你的答案和思考过程，如果觉得有收获，也欢迎你把今天的内容分享给更多的朋友。</p>","neighbors":{"left":{"article_title":"06 | 从ziplist到quicklist，再到listpack的启发","id":405387},"right":{"article_title":"08 | Redis server启动后会做哪些操作？","id":406556}}},{"article_id":406556,"article_title":"08 | Redis server启动后会做哪些操作？","article_content":"<p>你好，我是蒋德钧。从这节课开始，我们就来到了课程的第二个模块，在这个模块里，我会带你了解和学习与Redis实例运行相关方面的知识，包括Redis server的启动过程、基于事件驱动框架的网络通信机制以及Redis线程执行模型。今天，我们先来学习下Redis server的启动过程。</p><p>我们知道，main函数是Redis整个运行程序的入口，并且Redis实例在运行时，也会从这个main函数开始执行。同时，由于Redis是典型的Client-Server架构，一旦Redis实例开始运行，Redis server也就会启动，而main函数其实也会负责Redis server的启动运行。</p><blockquote>\n<p>我在<a href=\"https://time.geekbang.org/column/article/399866\">第1讲</a>给你介绍过Redis源码的整体架构。其中，Redis运行的基本控制逻辑是在<a href=\"https://github.com/redis/redis/tree/5.0/src/server.c\">server.c</a>文件中完成的，而main函数就是在server.c中。</p>\n</blockquote><p>你平常在设计或实现一个网络服务器程序时，可能会遇到一个问题，那就是服务器启动时，应该做哪些操作、有没有一个典型的参考实现。所以今天这节课，我就从main函数开始，给你介绍下Redis server是如何在main函数中启动并完成初始化的。通过这节课内容的学习，你可以掌握Redis针对以下三个问题的实现思路：</p><!-- [[[read_end]]] --><ol>\n<li><strong>Redis server启动后具体会做哪些初始化操作？</strong></li>\n<li><strong>Redis server初始化时有哪些关键配置项？</strong></li>\n<li><strong>Redis server如何开始处理客户端请求？</strong></li>\n</ol><p>并且，Redis server设计和实现的启动过程也具有一定的代表性，你在学习后，就可以把其中的关键操作推而广之，用在自己的网络服务器实现中。</p><p>好了，接下来，我们先从main函数开始，来了解下它在Redis server中的设计实现思路。</p><h2>main函数：Redis server的入口</h2><p>一般来说，一个使用C开发的系统软件启动运行的代码逻辑，都是实现在了main函数当中，所以在正式了解Redis中main函数的实现之前，我想先给你分享一个小Tips，就是你在阅读学习一个系统的代码时，可以先找下main函数，看看它的执行过程。</p><p>那么，对于Redis的main函数来说，我把它执行的工作分成了五个阶段。</p><p><strong>阶段一：基本初始化</strong></p><p>在这个阶段，main函数主要是完成一些基本的初始化工作，包括设置server运行的时区、设置哈希函数的随机种子等。这部分工作的主要调用函数如下所示：</p><pre><code>//设置时区\nsetlocale(LC_COLLATE,&quot;&quot;);\ntzset();\n...\n//设置随机种子\nchar hashseed[16];\ngetRandomHexChars(hashseed,sizeof(hashseed));\ndictSetHashFunctionSeed((uint8_t*)hashseed);\n</code></pre><p>这里，你需要注意的是，在main函数的开始部分，有一段宏定义覆盖的代码。这部分代码的作用是，如果定义了REDIS_TEST宏定义，并且Redis server启动时的参数符合测试参数，那么main函数就会执行相应的测试程序。</p><p>这段宏定义的代码如以下所示，其中的示例代码就是调用ziplist的测试函数ziplistTest：</p><pre><code>#ifdef REDIS_TEST\n//如果启动参数有test和ziplist，那么就调用ziplistTest函数进行ziplist的测试\nif (argc == 3 &amp;&amp; !strcasecmp(argv[1], &quot;test&quot;)) {\n  if (!strcasecmp(argv[2], &quot;ziplist&quot;)) {\n     return ziplistTest(argc, argv);\n  }\n  ...\n}\n#endif\n</code></pre><p><strong>阶段二：检查哨兵模式，并检查是否要执行RDB检测或AOF检测</strong></p><p>Redis server启动后，可能是以哨兵模式运行的，而哨兵模式运行的server在参数初始化、参数设置，以及server启动过程中要执行的操作等方面，与普通模式server有所差别。所以，main函数在执行过程中需要根据Redis配置的参数，检查是否设置了哨兵模式。</p><p>如果有设置哨兵模式的话，main函数会调用initSentinelConfig函数，对哨兵模式的参数进行初始化设置，以及调用initSentinel函数，初始化设置哨兵模式运行的server。有关哨兵模式运行的Redis server相关机制，我会在第21讲中给你详细介绍。</p><p>下面的代码展示了main函数中对哨兵模式的检查，以及对哨兵模式的初始化，你可以看下：</p><pre><code>...\n//判断server是否设置为哨兵模式\nif (server.sentinel_mode) {\n        initSentinelConfig();  //初始化哨兵的配置\n        initSentinel();   //初始化哨兵模式\n}\n...\n</code></pre><p>除了检查哨兵模式以外，main函数还会检查是否要执行RDB检测或AOF检查，这对应了实际运行的程序是redis-check-rdb或redis-check-aof。在这种情况下，main函数会调用redis_check_rdb_main函数或redis_check_aof_main函数，检测RDB文件或AOF文件。你可以看看下面的代码，其中就展示了main函数对这部分内容的检查和调用：</p><pre><code>...\n//如果运行的是redis-check-rdb程序，调用redis_check_rdb_main函数检测RDB文件\nif (strstr(argv[0],&quot;redis-check-rdb&quot;) != NULL)\n   redis_check_rdb_main(argc,argv,NULL);\n//如果运行的是redis-check-aof程序，调用redis_check_aof_main函数检测AOF文件\nelse if (strstr(argv[0],&quot;redis-check-aof&quot;) != NULL)\n   redis_check_aof_main(argc,argv);\n...\n</code></pre><p><strong>阶段三：运行参数解析</strong></p><p>在这一阶段，main函数会对命令行传入的参数进行解析，并且调用loadServerConfig函数，对命令行参数和配置文件中的参数进行合并处理，然后为Redis各功能模块的关键参数设置合适的取值，以便server能高效地运行。</p><p><strong>阶段四：初始化server</strong></p><p>在完成对运行参数的解析和设置后，main函数会调用initServer函数，对server运行时的各种资源进行初始化工作。这主要包括了server资源管理所需的数据结构初始化、键值对数据库初始化、server网络框架初始化等。</p><p>而在调用完initServer后，main函数还会再次判断当前server是否为哨兵模式。如果是哨兵模式，main函数会调用sentinelIsRunning函数，设置启动哨兵模式。否则的话，main函数会调用loadDataFromDisk函数，从磁盘上加载AOF或者是RDB文件，以便恢复之前的数据。</p><p><strong>阶段五：执行事件驱动框架</strong></p><p>为了能高效处理高并发的客户端连接请求，Redis采用了事件驱动框架，来并发处理不同客户端的连接和读写请求。所以，main函数执行到最后时，会调用aeMain函数进入事件驱动框架，开始循环处理各种触发的事件。</p><p>我把刚才介绍的五个阶段涉及到的关键操作，画在了下面的图中，你可以再回顾下。</p><p><img src=\"https://static001.geekbang.org/resource/image/19/7b/1900f60f58048ac3095298da1057327b.jpg?wh=1999x1333\" alt=\"\"></p><p>那么，在这五个阶段当中，阶段三、四和五其实就包括了Redis server启动过程中的关键操作。所以接下来，我们就来依次学习下这三个阶段中的主要工作。</p><h2>Redis运行参数解析与设置</h2><p>我们知道，Redis提供了丰富的功能，既支持多种键值对数据类型的读写访问，还支持数据持久化保存、主从复制、切片集群等。而这些功能的高效运行，其实都离不开相关功能模块的关键参数配置。</p><p>举例来说，Redis为了节省内存，设计了内存紧凑型的数据结构来保存Hash、Sorted Set等键值对类型。但是在使用了内存紧凑型的数据结构之后，如果往数据结构存入的元素个数过多或元素过大的话，键值对的访问性能反而会受到影响。因此，为了平衡内存使用量和系统访问性能，我们就可以通过参数，来设置和调节内存紧凑型数据结构的使用条件。</p><p>也就是说，<strong>掌握这些关键参数的设置，可以帮助我们提升Redis实例的运行效率。</strong></p><p>不过，Redis的参数有很多，我们无法在一节课中掌握所有的参数设置。所以下面，我们可以先来学习下Redis的主要参数类型，这样就能对各种参数形成一个全面的了解。同时，我也会给你介绍一些和server运行关系密切的参数及其设置方法，以便你可以配置好这些参数，让server高效运行起来。</p><h3>Redis的主要参数类型</h3><p>首先，Redis运行所需的各种参数，都统一定义在了<a href=\"https://github.com/redis/redis/tree/5.0/src/server.h\">server.h</a>文件的redisServer结构体中。根据参数作用的范围，我把各种参数划分为了七大类型，包括通用参数、数据结构参数、网络参数、持久化参数、主从复制参数、切片集群参数、性能优化参数。具体你可以参考下面表格中的内容。</p><p><img src=\"https://static001.geekbang.org/resource/image/f4/73/f4b8477a07bed492aa3b8c89008f9a73.jpg?wh=1999x1333\" alt=\"\"></p><p>这样，如果你能按照上面的划分方法给Redis参数进行归类，那么你就可以发现，这些参数实际和Redis的主要功能机制是相对应的。所以，如果你要深入掌握这些参数的典型配置值，你就需要对相应功能机制的工作原理有所了解。我在接下来的课程中，也会在介绍Redis功能模块设计的同时，带你了解下其相应的典型参数配置。</p><p>好，现在我们就了解了Redis的七大参数类型，以及它们基本的作用范围，那么下面我们就接着来学习下，Redis是如何针对这些参数进行设置的。</p><h3>Redis参数的设置方法</h3><p>Redis对运行参数的设置实际上会经过三轮赋值，分别是默认配置值、命令行启动参数，以及配置文件配置值。</p><p>首先，Redis在main函数中会<strong>先调用initServerConfig函数，为各种参数设置默认值</strong>。参数的默认值统一定义在server.h文件中，都是以CONFIG_DEFAULT开头的宏定义变量。下面的代码显示的是部分参数的默认值，你可以看下。</p><pre><code>#define CONFIG_DEFAULT_HZ        10   //server后台任务的默认运行频率         \n#define CONFIG_MIN_HZ            1    // server后台任务的最小运行频率\n#define CONFIG_MAX_HZ            500 // server后台任务的最大运行频率\n#define CONFIG_DEFAULT_SERVER_PORT  6379  //server监听的默认TCP端口\n#define CONFIG_DEFAULT_CLIENT_TIMEOUT  0  //客户端超时时间，默认为0，表示没有超时限制\n</code></pre><p>在server.h中提供的默认参数值，一般都是典型的配置值。因此，如果你在部署使用Redis实例的过程中，对Redis的工作原理不是很了解，就可以使用代码中提供的默认配置。</p><p>当然，如果你对Redis各功能模块的工作机制比较熟悉的话，也可以自行设置运行参数。你可以在启动Redis程序时，在命令行上设置运行参数的值。比如，如果你想将Redis server监听端口从默认的6379修改为7379，就可以在命令行上设置port参数为7379，如下所示：</p><pre><code>./redis-server --port 7379\n</code></pre><p>这里，你需要注意的是，Redis的命令行参数设置需要使用<strong>两个减号“–”</strong>来表示相应的参数名，否则的话，Redis就无法识别所设置的运行参数。</p><p>Redis在使用initServerConfig函数对参数设置默认配置值后，接下来，main函数就会<strong>对Redis程序启动时的命令行参数进行逐一解析</strong>。</p><p>main函数会把解析后的参数及参数值保存成字符串，接着，main函数会<strong>调用loadServerConfig函数进行第二和第三轮的赋值</strong>。以下代码显示了main函数对命令行参数的解析，以及调用loadServerConfig函数的过程，你可以看下。</p><pre><code>int main(int argc, char **argv) {\n…\n//保存命令行参数\nfor (j = 0; j &lt; argc; j++) server.exec_argv[j] = zstrdup(argv[j]);\n…\nif (argc &gt;= 2) {\n   …\n   //对每个运行时参数进行解析\n   while(j != argc) {\n      …\n   }\n   …\n   //\n   loadServerConfig(configfile,options);\n}\n</code></pre><p>这里你要知道的是，loadServerConfig函数是在<a href=\"https://github.com/redis/redis/tree/5.0/src/config.c\">config.c</a>文件中实现的，该函数是以Redis配置文件和命令行参数的解析字符串为参数，将配置文件中的所有配置项读取出来，形成字符串。紧接着，loadServerConfig函数会把解析后的命令行参数，追加到配置文件形成的配置项字符串。</p><p>这样一来，配置项字符串就同时包含了配置文件中设置的参数，以及命令行设置的参数。</p><p>最后，loadServerConfig函数会进一步<strong>调用loadServerConfigFromString函数，对配置项字符串中的每一个配置项进行匹配</strong>。一旦匹配成功，loadServerConfigFromString函数就会按照配置项的值设置server的参数。</p><p>以下代码显示了loadServerConfigFromString函数的部分内容。这部分代码是使用了条件分支，来依次比较配置项是否是“timeout”和“tcp-keepalive”，如果匹配上了，就将server参数设置为配置项的值。</p><p>同时，代码还会检查配置项的值是否合理，比如是否小于0。如果参数值不合理，程序在运行时就会报错。另外对于其他的配置项，loadServerConfigFromString函数还会继续使用elseif分支进行判断。</p><pre><code>loadServerConfigFromString(char *config) {\n   …\n   //参数名匹配，检查参数是否为“timeout“\n   if (!strcasecmp(argv[0],&quot;timeout&quot;) &amp;&amp; argc == 2) {\n            //设置server的maxidletime参数\n\tserver.maxidletime = atoi(argv[1]);\n\t//检查参数值是否小于0，小于0则报错\n            if (server.maxidletime &lt; 0) {\n                err = &quot;Invalid timeout value&quot;; goto loaderr;\n            }\n   }\n  //参数名匹配，检查参数是否为“tcp-keepalive“\n  else if (!strcasecmp(argv[0],&quot;tcp-keepalive&quot;) &amp;&amp; argc == 2) {\n            //设置server的tcpkeepalive参数\n\tserver.tcpkeepalive = atoi(argv[1]);\n\t//检查参数值是否小于0，小于0则报错\n            if (server.tcpkeepalive &lt; 0) {\n                err = &quot;Invalid tcp-keepalive value&quot;; goto loaderr;\n            }\n   }\n   …\n}\n</code></pre><p>好了，到这里，你应该就了解了Redis server运行参数配置的步骤，我也画了一张图，以便你更直观地理解这个过程。</p><p><img src=\"https://static001.geekbang.org/resource/image/e7/0d/e7d8137ee5ee69f504cc8b662ebec60d.jpg?wh=1999x865\" alt=\"\"></p><p>在完成参数配置后，main函数会开始调用initServer函数，对server进行初始化。所以接下来，我们继续来了解Redis server初始化时的关键操作。</p><h2>initServer：初始化Redis server</h2><p>Redis server的初始化操作，主要可以分成三个步骤。</p><ul>\n<li>第一步，Redis server运行时需要对多种资源进行管理。</li>\n</ul><p>比如说，和server连接的客户端、从库等，Redis用作缓存时的替换候选集，以及server运行时的状态信息，这些资源的管理信息都会在<strong>initServer函数</strong>中进行初始化。</p><p>我给你举个例子，initServer函数会创建链表来分别维护客户端和从库，并调用evictionPoolAlloc函数（在<a href=\"https://github.com/redis/redis/tree/5.0/src/evict.c\">evict.c</a>中）采样生成用于淘汰的候选key集合。同时，initServer函数还会调用resetServerStats函数（在server.c中）重置server运行状态信息。</p><ul>\n<li>第二步，在完成资源管理信息的初始化后，initServer函数会对Redis数据库进行初始化。</li>\n</ul><p>因为一个Redis实例可以同时运行多个数据库，所以initServer函数会使用一个循环，依次为每个数据库创建相应的数据结构。</p><p>这个代码逻辑是实现在initServer函数中，<strong>它会为每个数据库执行初始化操作</strong>，包括创建全局哈希表，为过期key、被BLPOP阻塞的key、将被PUSH的key和被监听的key创建相应的信息表。</p><pre><code>for (j = 0; j &lt; server.dbnum; j++) {\n        //创建全局哈希表\n        server.db[j].dict = dictCreate(&amp;dbDictType,NULL);\n        //创建过期key的信息表\n        server.db[j].expires = dictCreate(&amp;keyptrDictType,NULL);\n        //为被BLPOP阻塞的key创建信息表\n        server.db[j].blocking_keys = dictCreate(&amp;keylistDictType,NULL);\n        //为将执行PUSH的阻塞key创建信息表\n        server.db[j].ready_keys = dictCreate(&amp;objectKeyPointerValueDictType,NULL);\n        //为被MULTI/WATCH操作监听的key创建信息表\n        server.db[j].watched_keys = dictCreate(&amp;keylistDictType,NULL);\n        …\n    }\n</code></pre><ul>\n<li>第三步，initServer函数会为运行的Redis server创建事件驱动框架，并开始启动端口监听，用于接收外部请求。</li>\n</ul><p>注意，为了高效处理高并发的外部请求，initServer在创建的事件框架中，针对每个监听IP上可能发生的客户端连接，都创建了监听事件，用来监听客户端连接请求。同时，initServer为监听事件设置了相应的<strong>处理函数acceptTcpHandler</strong>。</p><p>这样一来，只要有客户端连接到server监听的IP和端口，事件驱动框架就会检测到有连接事件发生，然后调用acceptTcpHandler函数来处理具体的连接。你可以参考以下代码中展示的处理逻辑：</p><pre><code>//创建事件循环框架\nserver.el = aeCreateEventLoop(server.maxclients+CONFIG_FDSET_INCR);\n…\n//开始监听设置的网络端口\nif (server.port != 0 &amp;&amp;\n        listenToPort(server.port,server.ipfd,&amp;server.ipfd_count) == C_ERR)\n        exit(1);\n…\n//为server后台任务创建定时事件\nif (aeCreateTimeEvent(server.el, 1, serverCron, NULL, NULL) == AE_ERR) {\n        serverPanic(&quot;Can't create event loop timers.&quot;);\n        exit(1);\n}\n…\n//为每一个监听的IP设置连接事件的处理函数acceptTcpHandler\nfor (j = 0; j &lt; server.ipfd_count; j++) {\n        if (aeCreateFileEvent(server.el, server.ipfd[j], AE_READABLE,\n            acceptTcpHandler,NULL) == AE_ERR)\n       { … }\n}\n</code></pre><p>那么到这里，Redis server在完成运行参数设置和初始化后，就可以开始处理客户端请求了。为了能持续地处理并发的客户端请求，<strong>server在main函数的最后，会进入事件驱动循环机制</strong>。而这就是接下来，我们要了解的事件驱动框架的执行过程。</p><h2>执行事件驱动框架</h2><p>事件驱动框架是Redis server运行的核心。该框架一旦启动后，就会一直循环执行，每次循环会处理一批触发的网络读写事件。关于事件驱动框架本身的设计思想与实现方法，我会在第9至11讲给你具体介绍。这节课，我们主要是学习Redis入口的main函数中，是如何转换到事件驱动框架进行执行的。</p><p>其实，进入事件驱动框架开始执行并不复杂，main函数直接调用事件框架的<strong>主体函数aeMain</strong>（在<a href=\"https://github.com/redis/redis/tree/5.0/src/ae.c\">ae.c</a>文件中）后，就进入事件处理循环了。</p><p>当然，在进入事件驱动循环前，main函数会分别调用aeSetBeforeSleepProc和aeSetAfterSleepProc两个函数，来设置每次进入事件循环前server需要执行的操作，以及每次事件循环结束后server需要执行的操作。下面代码显示了这部分的执行逻辑，你可以看下。</p><pre><code>int main(int argc, char **argv) {\n    …\n    aeSetBeforeSleepProc(server.el,beforeSleep);\n    aeSetAfterSleepProc(server.el,afterSleep);\n    aeMain(server.el);\n\taeDeleteEventLoop(server.el);\n\t...\n}\n</code></pre><h2>小结</h2><p>今天这节课，我们通过server.c文件中main函数的设计和实现思路，了解了Redis server启动后的五个主要阶段。在这五个阶段中，运行参数解析、server初始化和执行事件驱动框架则是Redis sever启动过程中的三个关键阶段。所以相应的，我们需要重点关注以下三个要点。</p><p>第一，main函数是使用initServerConfig给server运行参数设置默认值，然后会解析命令行参数，并通过loadServerConfig读取配置文件参数值，将命令行参数追加至配置项字符串。最后，Redis会调用loadServerConfigFromString函数，来完成配置文件参数和命令行参数的设置。</p><p>第二，在Redis server完成参数设置后，initServer函数会被调用，用来初始化server资源管理的主要结构，同时会初始化数据库启动状态，以及完成server监听IP和端口的设置。</p><p>第三，一旦server可以接收外部客户端的请求后，main函数会把程序的主体控制权，交给事件驱动框架的入口函数，也就aeMain函数。aeMain函数会一直循环执行，处理收到的客户端请求。到此为止，server.c中的main函数功能就已经全部完成了，程序控制权也交给了事件驱动循环框架，Redis也就可以正常处理客户端请求了。</p><p>实际上，Redis server的启动过程从基本的初始化操作，到命令行和配置文件的参数解析设置，再到初始化server各种数据结构，以及最后的执行事件驱动框架，这是一个典型的网络服务器执行过程，你在开发网络服务器时，就可以作为参考。</p><p>而且，掌握了启动过程中的初始化操作，还可以帮你解答一些使用中的疑惑。比如，Redis启动时是先读取RDB文件，还是先读取AOF文件。如果你了解了Redis server的启动过程，就可以从loadDataFromDisk函数中看到，Redis server会先读取AOF；而如果没有AOF，则再读取RDB。</p><p>所以，掌握Redis server启动过程，有助于你更好地了解Redis运行细节，这样当你遇到问题时，就知道还可以从启动过程中去溯源server的各种初始状态，从而助力你更好地解决问题。</p><h2>每课一问</h2><p>Redis源码的main函数在调用initServer函数之前，会执行如下的代码片段，你知道这个代码片段的作用是什么吗？</p><pre><code>int main(int argc, char **argv) {\n...\nserver.supervised = redisIsSupervised(server.supervised_mode);\nint background = server.daemonize &amp;&amp; !server.supervised;\nif (background) daemonize();\n...\n}\n</code></pre><p>欢迎在留言区分享你的答案和见解，我们一起交流讨论。如果觉得有收获，也欢迎你把今天的内容分享给更多的朋友。</p>","neighbors":{"left":{"article_title":"07 | 为什么Stream使用了Radix Tree？","id":406284},"right":{"article_title":"09 | Redis事件驱动框架（上）：何时使用select、poll、epoll？","id":407901}}},{"article_id":407901,"article_title":"09 | Redis事件驱动框架（上）：何时使用select、poll、epoll？","article_content":"<p>你好，我是蒋德钧。</p><p>Redis作为一个Client-Server架构的数据库，其源码中少不了用来实现网络通信的部分。而你应该也清楚，通常系统实现网络通信的基本方法是<strong>使用Socket编程模型</strong>，包括创建Socket、监听端口、处理连接请求和读写请求。但是，由于基本的Socket编程模型一次只能处理一个客户端连接上的请求，所以当要处理高并发请求时，一种方案就是使用多线程，让每个线程负责处理一个客户端的请求。</p><p>而Redis负责客户端请求解析和处理的线程只有一个，那么如果直接采用基本Socket模型，就会影响Redis支持高并发的客户端访问。</p><p>因此，为了实现高并发的网络通信，我们常用的Linux操作系统，就提供了select、poll和epoll三种编程模型，而在Linux上运行的Redis，通常就会采用其中的<strong>epoll模型</strong>来进行网络通信。</p><p>这里你可能就要问了：<strong>为啥Redis通常会选择epoll模型呢？这三种编程模型之间有什么区别？</strong>如果我们自己要开发高并发的服务器处理程序时，应该如何选择使用呢？</p><p>今天这节课，我就来和你聊聊，Redis在高并发网络通信编程模型上的选择和设计思想。通过这节课的学习，你可以掌握select、poll和epoll三种模型的工作机制和使用方法。了解这些内容，一方面可以帮助你理解Redis整体网络通信框架的工作基础，另一方面，也可以让你学会如何进行高并发网络通信的开发。</p><!-- [[[read_end]]] --><p>那么，要想理解select、poll和epoll的优势，我们需要有个对比基础，也就是基本的Socket编程模型。所以接下来，我们就先来了解下基本的Socket编程模型，以及它的不足之处。</p><h2>为什么Redis不使用基本的Socket编程模型？</h2><p>刚刚我们说过，使用Socket模型实现网络通信时，需要经过创建Socket、监听端口、处理连接和读写请求等多个步骤，现在我们就来具体了解下这些步骤中的关键操作，以此帮助我们分析Socket模型中的不足。</p><p>首先，当我们需要让服务器端和客户端进行通信时，可以在服务器端通过以下三步，来创建监听客户端连接的监听套接字（Listening Socket）：</p><ol>\n<li>调用socket函数，创建一个套接字。我们通常把这个套接字称为主动套接字（Active Socket）；</li>\n<li>调用bind函数，将主动套接字和当前服务器的IP和监听端口进行绑定；</li>\n<li>调用listen函数，将主动套接字转换为监听套接字，开始监听客户端的连接。</li>\n</ol><p><img src=\"https://static001.geekbang.org/resource/image/ea/05/eaf5b29b824994a6e9e3bc5bfdeb1a05.jpg?wh=1631x604\" alt=\"\"></p><p>在完成上述三步之后，服务器端就可以接收客户端的连接请求了。为了能及时地收到客户端的连接请求，我们可以运行一个循环流程，在该流程中调用accept函数，用于接收客户端连接请求。</p><p>这里你需要注意的是，accept函数是阻塞函数，也就是说，如果此时一直没有客户端连接请求，那么，服务器端的执行流程会一直阻塞在accept函数。一旦有客户端连接请求到达，accept将不再阻塞，而是处理连接请求，和客户端建立连接，并返回已连接套接字（Connected Socket）。</p><p>最后，服务器端可以通过调用recv或send函数，在刚才返回的已连接套接字上，接收并处理读写请求，或是将数据发送给客户端。</p><p>下面的代码展示了这一过程，你可以看下。</p><pre><code>listenSocket = socket(); //调用socket系统调用创建一个主动套接字\nbind(listenSocket);  //绑定地址和端口\nlisten(listenSocket); //将默认的主动套接字转换为服务器使用的被动套接字，也就是监听套接字\nwhile (1) { //循环监听是否有客户端连接请求到来\n   connSocket = accept(listenSocket); //接受客户端连接\n   recv(connsocket); //从客户端读取数据，只能同时处理一个客户端\n   send(connsocket); //给客户端返回数据，只能同时处理一个客户端\n}\n</code></pre><p>不过，从上述代码中，你可能会发现，虽然它能够实现服务器端和客户端之间的通信，但是程序每调用一次accept函数，只能处理一个客户端连接。因此，如果想要处理多个并发客户端的请求，我们就需要使用<strong>多线程</strong>的方法，来处理通过accept函数建立的多个客户端连接上的请求。</p><p>使用这种方法后，我们需要在accept函数返回已连接套接字后，创建一个线程，并将已连接套接字传递给创建的线程，由该线程负责这个连接套接字上后续的数据读写。同时，服务器端的执行流程会再次调用accept函数，等待下一个客户端连接。</p><p>以下给出的示例代码，就展示了使用多线程来提升服务器端的并发客户端处理能力：</p><pre><code>listenSocket = socket(); //调用socket系统调用创建一个主动套接字\nbind(listenSocket);  //绑定地址和端口\nlisten(listenSocket); //将默认的主动套接字转换为服务器使用的被动套接字，即监听套接字\nwhile (1) { //循环监听是否有客户端连接到来\n   connSocket = accept(listenSocket); //接受客户端连接，返回已连接套接字\n   pthread_create(processData, connSocket); //创建新线程对已连接套接字进行处理\n   \n}\n\n//处理已连接套接字上的读写请求\nprocessData(connSocket){\n   recv(connsocket); //从客户端读取数据，只能同时处理一个客户端\n   send(connsocket); //给客户端返回数据，只能同时处理一个客户端\n}\n</code></pre><p>不过，虽然这种方法能提升服务器端的并发处理能力，遗憾的是，<strong>Redis的主执行流程是由一个线程在执行，无法使用多线程的方式来提升并发处理能力。</strong>所以，该方法对Redis并不起作用。</p><p>那么，还有没有什么其他方法，能帮助Redis提升并发客户端的处理能力呢？</p><p>这就要用到操作系统提供的<strong>IO多路复用功能</strong>了。在基本的Socket编程模型中，accept函数只能在一个监听套接字上监听客户端的连接，recv函数也只能在一个已连接套接字上，等待客户端发送的请求。</p><p>而IO多路复用机制，可以让程序通过调用多路复用函数，同时监听多个套接字上的请求。这里既可以包括监听套接字上的连接请求，也可以包括已连接套接字上的读写请求。这样当有一个或多个套接字上有请求时，多路复用函数就会返回。此时，程序就可以处理这些就绪套接字上的请求，比如读取就绪的已连接套接字上的请求内容。</p><p>因为Linux操作系统在实际应用中比较广泛，所以这节课，我们主要来学习Linux上的IO多路复用机制。Linux提供的IO多路复用机制主要有三种，分别是select、poll和epoll。下面，我们就分别来学习下这三种机制的实现思路和使用方法。然后，我们再来看看，为什么Redis通常是选择使用epoll这种机制来实现网络通信。</p><h2>使用select和poll机制实现IO多路复用</h2><p>首先，我们来了解下select机制的编程模型。</p><p>不过在具体学习之前，我们需要知道，对于一种IO多路复用机制来说，我们需要掌握哪些要点，这样可以帮助我们快速抓住不同机制的联系与区别。其实，当我们学习IO多路复用机制时，我们需要能回答以下问题：</p><ul>\n<li>第一，多路复用机制会监听套接字上的哪些事件？</li>\n<li>第二，多路复用机制可以监听多少个套接字？</li>\n<li>第三，当有套接字就绪时，多路复用机制要如何找到就绪的套接字？</li>\n</ul><h3>select机制与使用</h3><p>select机制中的一个重要函数就是select函数。对于select函数来说，它的参数包括监听的文件描述符数量<code>__nfds</code>、被监听描述符的三个集合<code>*__readfds</code>、<code>*__writefds</code>和<code>*__exceptfds</code>，以及监听时阻塞等待的超时时长<code>*__timeout</code>。下面的代码显示了select函数的原型，你可以看下。</p><pre><code>int select (int __nfds, fd_set *__readfds, fd_set *__writefds, fd_set *__exceptfds, struct timeval *__timeout)\n</code></pre><p>这里你需要注意的是，Linux针对每一个套接字都会有一个文件描述符，也就是一个非负整数，用来唯一标识该套接字。所以，在多路复用机制的函数中，Linux通常会用文件描述符作为参数。有了文件描述符，函数也就能找到对应的套接字，进而进行监听、读写等操作。</p><p>所以，select函数的参数<code>__readfds</code>、<code>__writefds</code>和<code>__exceptfds</code>表示的是，被监听描述符的集合，其实就是被监听套接字的集合。那么，为什么会有三个集合呢？</p><p>这就和我刚才提出的第一个问题相关，也就是<strong>多路复用机制会监听哪些事件</strong>。select函数使用三个集合，表示监听的三类事件，分别是读数据事件（对应<code>__readfds</code>集合）、写数据事件（对应<code>__writefds</code>集合）和异常事件（对应<code>__exceptfds</code>集合）。</p><p>我们进一步可以看到，参数__readfds、__writefds和__exceptfds的类型是fd_set结构体，它主要定义部分如下所示。其中，<code>__fd_mask</code>类型是long int类型的别名，__FD_SETSIZE和__NFDBITS这两个宏定义的大小默认为1024和32。</p><pre><code>typedef struct {\n   …\n   __fd_mask  __fds_bits[__FD_SETSIZE / __NFDBITS];\n   …\n} fd_set\n</code></pre><p>所以，fd_set结构体的定义，其实就是一个long int类型的数组，该数组中一共有32个元素（1024/32=32），每个元素是32位（long int类型的大小），而每一位可以用来表示一个文件描述符的状态。</p><p>好了，了解了fd_set结构体的定义，我们就可以回答刚才提出的第二个问题了。select函数对每一个描述符集合，都可以监听1024个描述符。</p><p>接下来，我们再来了解下<strong>如何使用select机制来实现网络通信</strong>。</p><p>首先，我们在调用select函数前，可以先创建好传递给select函数的描述符集合，然后再创建监听套接字。而为了让创建的监听套接字能被select函数监控，我们需要把这个套接字的描述符加入到创建好的描述符集合中。</p><p>然后，我们就可以调用select函数，并把创建好的描述符集合作为参数传递给select函数。程序在调用select函数后，会发生阻塞。而当select函数检测到有描述符就绪后，就会结束阻塞，并返回就绪的文件描述符个数。</p><p>那么此时，我们就可以在描述符集合中查找哪些描述符就绪了。然后，我们对已就绪描述符对应的套接字进行处理。比如，如果是__readfds集合中有描述符就绪，这就表明这些就绪描述符对应的套接字上，有读事件发生，此时，我们就在该套接字上读取数据。</p><p>而因为select函数一次可以监听1024个文件描述符的状态，所以select函数在返回时，也可能会一次返回多个就绪的文件描述符。这样一来，我们就可以使用一个循环流程，依次对就绪描述符对应的套接字进行读写或异常处理操作。</p><p>我也画了张图，展示了使用select函数进行网络通信的基本流程，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/49/9f/49b513c6b9f9a440e8883ff93b33b49f.jpg?wh=2000x1125\" alt=\"\"></p><p>下面的代码展示的是使用select函数，进行并发客户端处理的关键步骤和主要函数调用：</p><pre><code>int sock_fd,conn_fd; //监听套接字和已连接套接字的变量\nsock_fd = socket() //创建套接字\nbind(sock_fd)   //绑定套接字\nlisten(sock_fd) //在套接字上进行监听，将套接字转为监听套接字\n\nfd_set rset;  //被监听的描述符集合，关注描述符上的读事件\n \nint max_fd = sock_fd\n\n//初始化rset数组，使用FD_ZERO宏设置每个元素为0 \nFD_ZERO(&amp;rset);\n//使用FD_SET宏设置rset数组中位置为sock_fd的文件描述符为1，表示需要监听该文件描述符\nFD_SET(sock_fd,&amp;rset);\n\n//设置超时时间 \nstruct timeval timeout;\ntimeout.tv_sec = 3;\ntimeout.tv_usec = 0;\n \nwhile(1) {\n   //调用select函数，检测rset数组保存的文件描述符是否已有读事件就绪，返回就绪的文件描述符个数\n   n = select(max_fd+1, &amp;rset, NULL, NULL, &amp;timeout);\n \n   //调用FD_ISSET宏，在rset数组中检测sock_fd对应的文件描述符是否就绪\n   if (FD_ISSET(sock_fd, &amp;rset)) {\n       //如果sock_fd已经就绪，表明已有客户端连接；调用accept函数建立连接\n       conn_fd = accept();\n       //设置rset数组中位置为conn_fd的文件描述符为1，表示需要监听该文件描述符\n       FD_SET(conn_fd, &amp;rset);\n   }\n\n   //依次检查已连接套接字的文件描述符\n   for (i = 0; i &lt; maxfd; i++) {\n        //调用FD_ISSET宏，在rset数组中检测文件描述符是否就绪\n       if (FD_ISSET(i, &amp;rset)) {\n         //有数据可读，进行读数据处理\n       }\n   }\n}\n</code></pre><p>不过从刚才的介绍中，你或许会发现select函数存在<strong>两个设计上的不足</strong>：</p><ul>\n<li>首先，select函数对单个进程能监听的文件描述符数量是有限制的，它能监听的文件描述符个数由__FD_SETSIZE决定，默认值是1024。</li>\n<li>其次，当select函数返回后，我们需要遍历描述符集合，才能找到具体是哪些描述符就绪了。这个遍历过程会产生一定开销，从而降低程序的性能。</li>\n</ul><p>所以，为了解决select函数受限于1024个文件描述符的不足，poll函数对此做了改进。</p><h3>poll机制与使用</h3><p>poll机制的主要函数是poll函数，我们先来看下它的原型定义，如下所示：</p><pre><code>int poll (struct pollfd *__fds, nfds_t __nfds, int __timeout);\n</code></pre><p>其中，参数*__fds是pollfd结构体数组，参数__nfds表示的是*__fds数组的元素个数，而__timeout表示poll函数阻塞的超时时间。</p><p>pollfd结构体里包含了要监听的描述符，以及该描述符上要监听的事件类型。这个我们可以从pollfd结构体的定义中看出来，如下所示。pollfd结构体中包含了三个成员变量fd、events和revents，分别表示要监听的文件描述符、要监听的事件类型和实际发生的事件类型。</p><pre><code>struct pollfd {\n    int fd;         //进行监听的文件描述符\n    short int events;       //要监听的事件类型\n    short int revents;      //实际发生的事件类型\n};\n</code></pre><p>pollfd结构体中要监听和实际发生的事件类型，是通过以下三个宏定义来表示的，分别是POLLRDNORM、POLLWRNORM和POLLERR，它们分别表示可读、可写和错误事件。</p><pre><code>#define POLLRDNORM  0x040       //可读事件\n#define POLLWRNORM  0x100       //可写事件\n#define POLLERR     0x008       //错误事件\n</code></pre><p>好了，了解了poll函数的参数后，我们来看下如何使用poll函数完成网络通信。这个流程主要可以分成三步：</p><ul>\n<li>第一步，创建pollfd数组和监听套接字，并进行绑定；</li>\n<li>第二步，将监听套接字加入pollfd数组，并设置其监听读事件，也就是客户端的连接请求；</li>\n<li>第三步，循环调用poll函数，检测pollfd数组中是否有就绪的文件描述符。</li>\n</ul><p>而在第三步的循环过程中，其处理逻辑又分成了两种情况：</p><ul>\n<li>如果是连接套接字就绪，这表明是有客户端连接，我们可以调用accept接受连接，并创建已连接套接字，并将其加入pollfd数组，并监听读事件；</li>\n<li>如果是已连接套接字就绪，这表明客户端有读写请求，我们可以调用recv/send函数处理读写请求。</li>\n</ul><p>我画了下面这张图，展示了使用poll函数的流程，你可以学习掌握下。</p><p><img src=\"https://static001.geekbang.org/resource/image/b1/19/b1dab536cc9509f476db2c527fdea619.jpg?wh=2000x1125\" alt=\"\"></p><p>另外，为了便于你掌握在代码中使用poll函数，我也写了一份示例代码，如下所示：</p><pre><code>int sock_fd,conn_fd; //监听套接字和已连接套接字的变量\nsock_fd = socket() //创建套接字\nbind(sock_fd)   //绑定套接字\nlisten(sock_fd) //在套接字上进行监听，将套接字转为监听套接字\n\n//poll函数可以监听的文件描述符数量，可以大于1024\n#define MAX_OPEN = 2048\n\n//pollfd结构体数组，对应文件描述符\nstruct pollfd client[MAX_OPEN];\n\n//将创建的监听套接字加入pollfd数组，并监听其可读事件\nclient[0].fd = sock_fd;\nclient[0].events = POLLRDNORM; \nmaxfd = 0;\n\n//初始化client数组其他元素为-1\nfor (i = 1; i &lt; MAX_OPEN; i++)\n    client[i].fd = -1; \n\nwhile(1) {\n   //调用poll函数，检测client数组里的文件描述符是否有就绪的，返回就绪的文件描述符个数\n   n = poll(client, maxfd+1, &amp;timeout);\n   //如果监听套件字的文件描述符有可读事件，则进行处理\n   if (client[0].revents &amp; POLLRDNORM) {\n       //有客户端连接；调用accept函数建立连接\n       conn_fd = accept();\n\n       //保存已建立连接套接字\n       for (i = 1; i &lt; MAX_OPEN; i++){\n         if (client[i].fd &lt; 0) {\n           client[i].fd = conn_fd; //将已建立连接的文件描述符保存到client数组\n           client[i].events = POLLRDNORM; //设置该文件描述符监听可读事件\n           break;\n          }\n       }\n       maxfd = i; \n   }\n   \n   //依次检查已连接套接字的文件描述符\n   for (i = 1; i &lt; MAX_OPEN; i++) {\n       if (client[i].revents &amp; (POLLRDNORM | POLLERR)) {\n         //有数据可读或发生错误，进行读数据处理或错误处理\n       }\n   }\n}\n</code></pre><p>其实，和select函数相比，poll函数的改进之处主要就在于，<strong>它允许一次监听超过1024个文件描述符</strong>。但是当调用了poll函数后，我们仍然需要遍历每个文件描述符，检测该描述符是否就绪，然后再进行处理。</p><p><strong>那么，有没有办法可以避免遍历每个描述符呢？</strong>这就是我接下来向你介绍的epoll机制。</p><h2>使用epoll机制实现IO多路复用</h2><p>首先，epoll机制是使用epoll_event结构体，来记录待监听的文件描述符及其监听的事件类型的，这和poll机制中使用pollfd结构体比较类似。</p><p>那么，对于epoll_event结构体来说，其中包含了epoll_data_t联合体变量，以及整数类型的events变量。epoll_data_t联合体中有记录文件描述符的成员变量fd，而events变量会取值使用不同的宏定义值，来表示epoll_data_t变量中的文件描述符所关注的事件类型，比如一些常见的事件类型包括以下这几种。</p><ul>\n<li>EPOLLIN：读事件，表示文件描述符对应套接字有数据可读。</li>\n<li>EPOLLOUT：写事件，表示文件描述符对应套接字有数据要写。</li>\n<li>EPOLLERR：错误事件，表示文件描述符对于套接字出错。</li>\n</ul><p>下面的代码展示了epoll_event结构体以及epoll_data联合体的定义，你可以看下。</p><pre><code>typedef union epoll_data\n{\n  ...\n  int fd;  //记录文件描述符\n  ...\n} epoll_data_t;\n\n\nstruct epoll_event\n{\n  uint32_t events;  //epoll监听的事件类型\n  epoll_data_t data; //应用程序数据\n};\n</code></pre><p>好了，现在我们知道，在使用select或poll函数的时候，创建好文件描述符集合或pollfd数组后，就可以往数组中添加我们需要监听的文件描述符。</p><p>但是对于epoll机制来说，我们则需要先调用epoll_create函数，创建一个epoll实例。这个epoll实例内部维护了两个结构，分别是<strong>记录要监听的文件描述符</strong>和<strong>已经就绪的文件描述符</strong>，而对于已经就绪的文件描述符来说，它们会被返回给用户程序进行处理。</p><p>所以，我们在使用epoll机制时，就不用像使用select和poll一样，遍历查询哪些文件描述符已经就绪了。这样一来， epoll的效率就比select和poll有了更高的提升。</p><p>在创建了epoll实例后，我们需要再使用epoll_ctl函数，给被监听的文件描述符添加监听事件类型，以及使用epoll_wait函数获取就绪的文件描述符。</p><p>我画了一张图，展示了使用epoll进行网络通信的流程，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/1e/fb/1ee730305558d9d83ff8e52eb4d966fb.jpg?wh=2000x1050\" alt=\"\"></p><p>下面的代码展示了使用epoll函数的流程，你也可以看下。</p><pre><code>int sock_fd,conn_fd; //监听套接字和已连接套接字的变量\nsock_fd = socket() //创建套接字\nbind(sock_fd)   //绑定套接字\nlisten(sock_fd) //在套接字上进行监听，将套接字转为监听套接字\n    \nepfd = epoll_create(EPOLL_SIZE); //创建epoll实例，\n//创建epoll_event结构体数组，保存套接字对应文件描述符和监听事件类型    \nep_events = (epoll_event*)malloc(sizeof(epoll_event) * EPOLL_SIZE);\n\n//创建epoll_event变量\nstruct epoll_event ee\n//监听读事件\nee.events = EPOLLIN;\n//监听的文件描述符是刚创建的监听套接字\nee.data.fd = sock_fd;\n\n//将监听套接字加入到监听列表中    \nepoll_ctl(epfd, EPOLL_CTL_ADD, sock_fd, &amp;ee); \n    \nwhile (1) {\n   //等待返回已经就绪的描述符 \n   n = epoll_wait(epfd, ep_events, EPOLL_SIZE, -1); \n   //遍历所有就绪的描述符     \n   for (int i = 0; i &lt; n; i++) {\n       //如果是监听套接字描述符就绪，表明有一个新客户端连接到来 \n       if (ep_events[i].data.fd == sock_fd) { \n          conn_fd = accept(sock_fd); //调用accept()建立连接\n          ee.events = EPOLLIN;  \n          ee.data.fd = conn_fd;\n          //添加对新创建的已连接套接字描述符的监听，监听后续在已连接套接字上的读事件      \n          epoll_ctl(epfd, EPOLL_CTL_ADD, conn_fd, &amp;ee); \n                \n       } else { //如果是已连接套接字描述符就绪，则可以读数据\n           ...//读取数据并处理\n       }\n   }\n}\n</code></pre><p>好了，到这里，你就了解了epoll函数的使用方法了。实际上，也正是因为epoll能自定义监听的描述符数量，以及可以直接返回就绪的描述符，Redis在设计和实现网络通信框架时，就基于epoll机制中的epoll_create、epoll_ctl和epoll_wait等函数和读写事件，进行了封装开发，实现了用于网络通信的事件驱动框架，从而使得Redis虽然是单线程运行，但是仍然能高效应对高并发的客户端访问。</p><h2>小结</h2><p>今天这节课，我给你介绍了Redis网络通信依赖的操作系统底层机制，也就是IO多路复用机制。</p><p>由于Redis是单线程程序，如果使用基本的Socket编程模型的话，只能对一个监听套接字或一个已连接套接字进行监听。而当Redis实例面临很多并发的客户端时，这种处理方式的效率就会很低。</p><p>所以，和基本的Socket通信相比，使用IO多路复用机制，就可以一次性获得就绪的多个套接字，从而避免了逐个检测套接字的开销。</p><p>这节课，我是以最常用的Linux操作系统为例，给你具体介绍了Linux系统提供的三种IO多路复用机制，分别是select、poll和epoll。这三种机制在能监听的描述符数量和查找就绪描述符的方法上是不一样的，你可以重点参考下图，来掌握它们的不同之处。这些差异，其实也决定了epoll相比于select和poll来说，效率更高，也应用更广泛。</p><p><img src=\"https://static001.geekbang.org/resource/image/c0/5c/c04feac38f984a0c407985ec793ca95c.jpg?wh=2000x827\" alt=\"\"></p><p>最后我想说的是，虽然这节课我没有给你介绍Redis的源码，但是学习IO多路复用的机制和使用流程，其实就是掌握Redis事件驱动框架的基础。Redis的<a href=\"https://github.com/redis/redis/tree/5.0/src/ae_select.c\">ae_select.c</a>和<a href=\"https://github.com/redis/redis/tree/5.0/src/ae_epoll.c\">ae_epoll.c</a>文件，就分别使用了select和epoll这两种机制，实现IO多路复用。而在接下来的第10、11两节课上，我还会给分别你介绍，Redis事件驱动框架是如何基于epoll进行封装开发和运行的，以及Redis事件驱动框架的事件类型和处理方法。这样一来，你就能对Redis事件驱动框架的底层支撑、框架运行和事件类型与处理，有个全面的掌握了。</p><h2>每课一问</h2><p>在Redis事件驱动框架代码中，分别使用了Linux系统上的select和epoll两种机制，你知道为什么Redis没有使用poll这一机制吗？</p>","neighbors":{"left":{"article_title":"08 | Redis server启动后会做哪些操作？","id":406556},"right":{"article_title":"10 | Redis事件驱动框架（中）：Redis实现了Reactor模型吗？","id":408491}}},{"article_id":408491,"article_title":"10 | Redis事件驱动框架（中）：Redis实现了Reactor模型吗？","article_content":"<p>你好，我是蒋德钧。今天，我们来聊聊Redis是如何实现Reactor模型的。</p><p>你在做Redis面试题的时候，或许经常会遇到这样一道经典的问题：Redis的网络框架是实现了Reactor模型吗？这看起来像是一道简单的“是/否”问答题，但是，如果你想给出一个让面试官满意的答案，这就非常考验你的<strong>高性能网络编程基础和对Redis代码的掌握程度</strong>了。</p><p>如果让我来作答这道题，我会把它分成两部分来回答：一是介绍Reactor模型是什么，二是说明Redis代码实现是如何与Reactor模型相对应的。这样一来，就既体现了我对网络编程的理解，还能体现对Redis源码的深入探究，进而面试官也就会对我刮目相看了。</p><p>实际上，Reactor模型是高性能网络系统实现高并发请求处理的一个重要技术方案。掌握Reactor模型的设计思想与实现方法，除了可以应对面试题，还可以指导你设计和实现自己的高并发系统。当你要处理成千上万的网络连接时，就不会一筹莫展了。</p><p>所以今天这节课，我会先带你了解下Reactor模型，然后一起来学习下如何实现Reactor模型。因为Redis的代码实现提供了很好的参考示例，所以我会通过Redis代码中的关键函数和流程，来给你展开介绍Reactor模型的实现。不过在学习Reactor模型前，你可以先回顾上节课我给你介绍的IO多路复用机制epoll，因为这也是学习今天这节课的基础。</p><!-- [[[read_end]]] --><h2>Reactor模型的工作机制</h2><p>好，首先，我们来看看什么是Reactor模型。</p><p>实际上，<strong>Reactor模型就是网络服务器端用来处理高并发网络IO请求的一种编程模型</strong>。我把这个模型的特征用两个“三”来总结，也就是：</p><ul>\n<li>三类处理事件，即连接事件、写事件、读事件；</li>\n<li>三个关键角色，即reactor、acceptor、handler。</li>\n</ul><p>那么，Reactor模型是如何基于这三类事件和三个角色来处理高并发请求的呢？下面我们就来具体了解下。</p><h3>事件类型与关键角色</h3><p>我们先来看看这三类事件和Reactor模型的关系。</p><p>其实，Reactor模型处理的是客户端和服务器端的交互过程，而这三类事件正好对应了客户端和服务器端交互过程中，不同类请求在服务器端引发的待处理事件：</p><ul>\n<li>当一个客户端要和服务器端进行交互时，客户端会向服务器端发送连接请求，以建立连接，这就对应了服务器端的一个<strong>连接事件</strong>。</li>\n<li>一旦连接建立后，客户端会给服务器端发送读请求，以便读取数据。服务器端在处理读请求时，需要向客户端写回数据，这对应了服务器端的<strong>写事件</strong>。</li>\n<li>无论客户端给服务器端发送读或写请求，服务器端都需要从客户端读取请求内容，所以在这里，读或写请求的读取就对应了服务器端的<strong>读事件</strong>。</li>\n</ul><p>如下所示的图例中，就展示了客户端和服务器端在交互过程中，不同类请求和Reactor模型事件的对应关系，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/d6/aa/d657443ded5c64a9yy32414e5e87eeaa.jpg?wh=1657x795\" alt=\"\"></p><p>好，在了解了Reactor模型的三类事件后，你现在可能还有一个疑问：这三类事件是由谁来处理的呢？</p><p>这其实就是模型中<strong>三个关键角色</strong>的作用了：</p><ul>\n<li>首先，连接事件由acceptor来处理，负责接收连接；acceptor在接收连接后，会创建handler，用于网络连接上对后续读写事件的处理；</li>\n<li>其次，读写事件由handler处理；</li>\n<li>最后，在高并发场景中，连接事件、读写事件会同时发生，所以，我们需要有一个角色专门监听和分配事件，这就是reactor角色。当有连接请求时，reactor将产生的连接事件交由acceptor处理；当有读写请求时，reactor将读写事件交由handler处理。</li>\n</ul><p>下图就展示了这三个角色之间的关系，以及它们和事件的关系，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/92/bb/926dea7b8925819f383efaf6f82c4fbb.jpg?wh=1831x644\" alt=\"\"></p><p>事实上，这三个角色都是Reactor模型中要实现的功能的抽象。当我们遵循Reactor模型开发服务器端的网络框架时，就需要在编程的时候，在代码功能模块中实现reactor、acceptor和handler的逻辑。</p><p>那么，现在我们已经知道，这三个角色是围绕事件的监听、转发和处理来进行交互的，那么在编程时，我们又该如何实现这三者的交互呢？这就离不开<strong>事件驱动框架</strong>了。</p><h3>事件驱动框架</h3><p>所谓的事件驱动框架，就是在实现Reactor模型时，需要实现的代码整体控制逻辑。简单来说，事件驱动框架包括了两部分：一是<strong>事件初始化</strong>；二是<strong>事件捕获、分发和处理主循环</strong>。</p><p>事件初始化是在服务器程序启动时就执行的，它的作用主要是创建需要监听的事件类型，以及该类事件对应的handler。而一旦服务器完成初始化后，事件初始化也就相应完成了，服务器程序就需要进入到事件捕获、分发和处理的主循环中。</p><p>在开发代码时，我们通常会用一个<strong>while循环</strong>来作为这个主循环。然后在这个主循环中，我们需要捕获发生的事件、判断事件类型，并根据事件类型，调用在初始化时创建好的事件handler来实际处理事件。</p><p>比如说，当有连接事件发生时，服务器程序需要调用acceptor处理函数，创建和客户端的连接。而当有读事件发生时，就表明有读或写请求发送到了服务器端，服务器程序就要调用具体的请求处理函数，从客户端连接中读取请求内容，进而就完成了读事件的处理。这里你可以参考下面给出的图例，其中显示了事件驱动框架的基本执行过程：</p><p><img src=\"https://static001.geekbang.org/resource/image/43/f4/432ec0735720dbf151e7d8bbd8c6d0f4.jpg?wh=1502x939\" alt=\"\"></p><p>那么到这里，你应该就已经了解了<strong>Reactor模型的基本工作机制</strong>：客户端的不同类请求会在服务器端触发连接、读、写三类事件，这三类事件的监听、分发和处理又是由reactor、acceptor、handler三类角色来完成的，然后这三类角色会通过事件驱动框架来实现交互和事件处理。</p><p>所以可见，实现一个Reactor模型的<strong>关键</strong>，就是要实现事件驱动框架。那么，如何开发实现一个事件驱动框架呢？</p><p>Redis提供了一个简洁但有效的参考实现，非常值得我们学习，而且也可以用于自己的网络系统开发。下面，我们就一起来学习下Redis中对Reactor模型的实现。</p><h2>Redis对Reactor模型的实现</h2><p>首先我们要知道的是，Redis的网络框架实现了Reactor模型，并且自行开发实现了一个事件驱动框架。这个框架对应的Redis代码实现文件是<a href=\"https://github.com/redis/redis/blob/5.0/src/ae.c\">ae.c</a>，对应的头文件是<a href=\"https://github.com/redis/redis/blob/5.0/src/ae.h\">ae.h</a>。</p><p>前面我们已经知道，事件驱动框架的实现离不开事件的定义，以及事件注册、捕获、分发和处理等一系列操作。当然，对于整个框架来说，还需要能一直运行，持续地响应发生的事件。</p><p>那么由此，我们从ae.h头文件中就可以看到，Redis为了实现事件驱动框架，相应地定义了<strong>事件的数据结构、框架主循环函数、事件捕获分发函数、事件和handler注册函数</strong>。所以接下来，我们就依次来了解学习下。</p><h3>事件的数据结构定义：以aeFileEvent为例</h3><p>首先，我们要明确一点，就是在Redis事件驱动框架的实现当中，事件的数据结构是关联事件类型和事件处理函数的关键要素。而Redis的事件驱动框架定义了两类事件：<strong>IO事件和时间事件</strong>，分别对应了客户端发送的网络请求和Redis自身的周期性操作。</p><p>这也就是说，<strong>不同类型事件的数据结构定义是不一样的</strong>。不过，由于这节课我们主要关注的是事件框架的整体设计与实现，所以对于不同类型事件的差异和具体处理，我会在下节课给你详细介绍。那么在今天的课程中，为了让你能够理解事件数据结构对框架的作用，我就以IO事件aeFileEvent为例，给你介绍下它的数据结构定义。</p><p>aeFileEvent是一个结构体，它定义了4个成员变量mask、rfileProce、wfileProce和clientData，如下所示：</p><pre><code>typedef struct aeFileEvent {\n    int mask; /* one of AE_(READABLE|WRITABLE|BARRIER) */\n    aeFileProc *rfileProc;\n    aeFileProc *wfileProc;\n    void *clientData;\n} aeFileEvent;\n</code></pre><ul>\n<li><strong>mask</strong>是用来表示事件类型的掩码。对于网络通信的事件来说，主要有AE_READABLE、AE_WRITABLE和AE_BARRIER三种类型事件。框架在分发事件时，依赖的就是结构体中的事件类型；</li>\n<li><strong>rfileProc和wfileProce</strong>分别是指向AE_READABLE和AE_WRITABLE这两类事件的处理函数，也就是Reactor模型中的handler。框架在分发事件后，就需要调用结构体中定义的函数进行事件处理；</li>\n<li>最后一个成员变量<strong>clientData</strong>是用来指向客户端私有数据的指针。</li>\n</ul><p>除了事件的数据结构以外，前面我还提到Redis在ae.h文件中，定义了支撑框架运行的主要函数，包括框架主循环的aeMain函数、负责事件捕获与分发的aeProcessEvents函数，以及负责事件和handler注册的aeCreateFileEvent函数，它们的原型定义如下：</p><pre><code>void aeMain(aeEventLoop *eventLoop);\nint aeCreateFileEvent(aeEventLoop *eventLoop, int fd, int mask, aeFileProc *proc, void *clientData);\nint aeProcessEvents(aeEventLoop *eventLoop, int flags);\n</code></pre><p>而这三个函数的实现，都是在对应的ae.c文件中，那么接下来，我就给你具体介绍下这三个函数的主体逻辑和关键流程。</p><h3>主循环：aeMain函数</h3><p>我们先来看下aeMain函数。</p><p>aeMain函数的逻辑很简单，就是用一个循环不停地判断事件循环的停止标记。如果事件循环的停止标记被设置为true，那么针对事件捕获、分发和处理的整个主循环就停止了；否则，主循环会一直执行。aeMain函数的主体代码如下所示：</p><pre><code>void aeMain(aeEventLoop *eventLoop) {\n    eventLoop-&gt;stop = 0;\n    while (!eventLoop-&gt;stop) {\n        …\n        aeProcessEvents(eventLoop, AE_ALL_EVENTS|AE_CALL_AFTER_SLEEP);\n    }\n}\n</code></pre><p>那么这里你可能要问了，<strong>aeMain函数是在哪里被调用的呢？</strong></p><p>按照事件驱动框架的编程规范来说，框架主循环是在服务器程序初始化完成后，就会开始执行。因此，如果我们把目光转向Redis服务器初始化的函数，就会发现服务器程序的main函数在完成Redis server的初始化后，会调用aeMain函数开始执行事件驱动框架。如果你想具体查看main函数，main函数在<a href=\"https://github.com/redis/redis/blob/5.0/src/server.c\">server.c</a>文件中，我们在<a href=\"https://time.geekbang.org/column/article/406556\">第8讲</a>中介绍过该文件，server.c主要用于初始化服务器和执行服务器整体控制流程，你可以回顾下。</p><p>不过，既然aeMain函数包含了事件框架的主循环，<strong>那么在主循环中，事件又是如何被捕获、分发和处理呢？</strong>这就是由aeProcessEvents函数来完成的了。</p><h3>事件捕获与分发：aeProcessEvents函数</h3><p>aeProcessEvents函数实现的主要功能，包括捕获事件、判断事件类型和调用具体的事件处理函数，从而实现事件的处理。</p><p>从aeProcessEvents函数的主体结构中，我们可以看到主要有三个if条件分支，如下所示：</p><pre><code>int aeProcessEvents(aeEventLoop *eventLoop, int flags)\n{\n    int processed = 0, numevents;\n \n    /* 若没有事件处理，则立刻返回*/\n    if (!(flags &amp; AE_TIME_EVENTS) &amp;&amp; !(flags &amp; AE_FILE_EVENTS)) return 0;\n    /*如果有IO事件发生，或者紧急的时间事件发生，则开始处理*/\n    if (eventLoop-&gt;maxfd != -1 || ((flags &amp; AE_TIME_EVENTS) &amp;&amp; !(flags &amp; AE_DONT_WAIT))) {\n       …\n    }\n    /* 检查是否有时间事件，若有，则调用processTimeEvents函数处理 */\n    if (flags &amp; AE_TIME_EVENTS)\n        processed += processTimeEvents(eventLoop);\n    /* 返回已经处理的文件或时间*/\n    return processed; \n}\n</code></pre><p>这三个分支分别对应了以下三种情况：</p><ul>\n<li>情况一：既没有时间事件，也没有网络事件；</li>\n<li>情况二：有IO事件或者有需要紧急处理的时间事件；</li>\n<li>情况三：只有普通的时间事件。</li>\n</ul><p>那么对于第一种情况来说，因为没有任何事件需要处理，aeProcessEvents函数就会直接返回到aeMain的主循环，开始下一轮的循环；而对于第三种情况来说，该情况发生时只有普通时间事件发生，所以aeMain函数会调用专门处理时间事件的函数processTimeEvents，对时间事件进行处理。</p><p>现在，我们再来看看第二种情况。</p><p>首先，当该情况发生时，Redis需要捕获发生的网络事件，并进行相应的处理。那么从Redis源码中我们可以分析得到，在这种情况下，<strong>aeApiPoll函数会被调用，用来捕获事件</strong>，如下所示：</p><pre><code>int aeProcessEvents(aeEventLoop *eventLoop, int flags){\n   ...\n   if (eventLoop-&gt;maxfd != -1 || ((flags &amp; AE_TIME_EVENTS) &amp;&amp; !(flags &amp; AE_DONT_WAIT))) {\n       ...\n       //调用aeApiPoll函数捕获事件\n       numevents = aeApiPoll(eventLoop, tvp);\n       ...\n    }\n    ...\n」\n</code></pre><p><strong>那么，aeApiPoll是如何捕获事件呢？</strong></p><p>实际上，Redis是依赖于操作系统底层提供的 <strong>IO多路复用机制</strong>，来实现事件捕获，检查是否有新的连接、读写事件发生。为了适配不同的操作系统，Redis对不同操作系统实现的网络IO多路复用函数，都进行了统一的封装，封装后的代码分别通过以下四个文件中实现：</p><ul>\n<li>ae_epoll.c，对应Linux上的IO复用函数epoll；</li>\n<li>ae_evport.c，对应Solaris上的IO复用函数evport；</li>\n<li>ae_kqueue.c，对应macOS或FreeBSD上的IO复用函数kqueue；</li>\n<li>ae_select.c，对应Linux（或Windows）的IO复用函数select。</li>\n</ul><p>这样，在有了这些封装代码后，Redis在不同的操作系统上调用IO多路复用API时，就可以通过统一的接口来进行调用了。</p><p>不过看到这里，你可能还是不太明白Redis封装的具体操作，所以这里，我就以在服务器端最常用的Linux操作系统为例，给你介绍下Redis是如何封装Linux上提供的IO复用API的。</p><p>首先，Linux上提供了<strong>epoll_wait API</strong>，用于检测内核中发生的网络IO事件。在<a href=\"https://github.com/redis/redis/blob/5.0/src/ae_epoll.c\">ae_epoll.c</a>文件中，<strong>aeApiPoll函数</strong>就是封装了对epoll_wait的调用。</p><p>这个封装程序如下所示，其中你可以看到，在aeApiPoll函数中直接调用了epoll_wait函数，并将epoll返回的事件信息保存起来的逻辑：</p><pre><code>static int aeApiPoll(aeEventLoop *eventLoop, struct timeval *tvp) {\n    …\n    //调用epoll_wait获取监听到的事件\n    retval = epoll_wait(state-&gt;epfd,state-&gt;events,eventLoop-&gt;setsize,\n            tvp ? (tvp-&gt;tv_sec*1000 + tvp-&gt;tv_usec/1000) : -1);\n    if (retval &gt; 0) {\n        int j;\n        //获得监听到的事件数量\n        numevents = retval;\n        //针对每一个事件，进行处理\n        for (j = 0; j &lt; numevents; j++) {\n             #保存事件信息\n        }\n    }\n    return numevents;\n}\n</code></pre><p>为了让你更加清晰地理解，事件驱动框架是如何实现最终对epoll_wait的调用，这里我也放了一张示意图，你可以看看整个调用链是如何工作和实现的。</p><p><img src=\"https://static001.geekbang.org/resource/image/92/e0/923921e50b117247de69fe6c657845e0.jpg?wh=1672x983\" alt=\"\"></p><p>OK，现在我们就已经在aeMain函数中，看到了aeProcessEvents函数被调用，并用于捕获和分发事件的基本处理逻辑。</p><p><strong>那么，事件具体是由哪个函数来处理的呢？</strong>这就和框架中的aeCreateFileEvents函数有关了。</p><h3>事件注册：aeCreateFileEvent函数</h3><p>我们知道，当Redis启动后，服务器程序的main函数会调用initSever函数来进行初始化，而在初始化的过程中，aeCreateFileEvent就会被initServer函数调用，用于注册要监听的事件，以及相应的事件处理函数。</p><p>具体来说，在initServer函数的执行过程中，initServer函数会根据启用的IP端口个数，为每个IP端口上的网络事件，调用aeCreateFileEvent，创建对AE_READABLE事件的监听，并且注册AE_READABLE事件的处理handler，也就是acceptTcpHandler函数。这一过程如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/a3/98/a37876d1e4330668ff8cab34af4d6098.jpg?wh=1349x833\" alt=\"\"></p><p>所以这里我们可以看到，<strong>AE_READABLE事件就是客户端的网络连接事件，而对应的处理函数就是接收TCP连接请求</strong>。下面的示例代码中，显示了initServer中调用aeCreateFileEvent的部分片段，你可以看下：</p><pre><code>void initServer(void) {\n    …\n    for (j = 0; j &lt; server.ipfd_count; j++) {\n        if (aeCreateFileEvent(server.el, server.ipfd[j], AE_READABLE,\n            acceptTcpHandler,NULL) == AE_ERR)\n            {\n                serverPanic(&quot;Unrecoverable error creating server.ipfd file event.&quot;);\n            }\n\t}\n\t…\n}\n</code></pre><p><strong>那么，aeCreateFileEvent如何实现事件和处理函数的注册呢？</strong>这就和刚才我介绍的Redis对底层IO多路复用函数封装有关了，下面我仍然以Linux系统为例，来给你说明一下。</p><p>首先，Linux提供了<strong>epoll_ctl API</strong>，用于增加新的观察事件。而Redis在此基础上，封装了aeApiAddEvent函数，对epoll_ctl进行调用。</p><p>所以这样一来，aeCreateFileEvent就会调用aeApiAddEvent，然后aeApiAddEvent再通过调用epoll_ctl，来注册希望监听的事件和相应的处理函数。等到aeProceeEvents函数捕获到实际事件时，它就会调用注册的函数对事件进行处理了。</p><p>好了，到这里，我们就已经全部了解了Redis中实现事件驱动框架的三个关键函数：aeMain、aeProcessEvents，以及aeCreateFileEvent。当你要去实现一个事件驱动框架时，Redis的设计思想就具有很好的参考意义。</p><p>最后我再带你来简单地回顾下，在实现事件驱动框架的时候，你需要先实现一个主循环函数（对应aeMain），负责一直运行框架。其次，你需要编写事件注册函数（对应aeCreateFileEvent），用来注册监听的事件和事件对应的处理函数。<strong>只有对事件和处理函数进行了注册，才能在事件发生时调用相应的函数进行处理。</strong></p><p>最后，你需要编写事件监听、分发函数（对应aeProcessEvents），负责调用操作系统底层函数来捕获网络连接、读、写事件，并分发给不同处理函数进一步处理。</p><h2>小结</h2><p>Redis一直被称为单线程架构，按照我们通常的理解，单个线程只能处理单个客户端的请求，但是在实际使用时，我们会看到Redis能同时和成百上千个客户端进行交互，这就是因为Redis基于Reactor模型，实现了高性能的网络框架，<strong>通过事件驱动框架，Redis可以使用一个循环来不断捕获、分发和处理客户端产生的网络连接、数据读写事件。</strong></p><p>为了方便你从代码层面掌握Redis事件驱动框架的实现，我总结了一个表格，其中列出了Redis事件驱动框架的主要函数和功能、它们所属的C文件，以及这些函数本身是在Redis代码结构中的哪里被调用。你可以使用这张表格，来巩固今天这节课学习的事件驱动框架。</p><p><img src=\"https://static001.geekbang.org/resource/image/66/64/66a020e9a6404fe5cef14eeab2deb364.jpg?wh=2000x872\" alt=\"\"></p><p>最后，我也再强调下，这节课我们主要关注的是，事件驱动框架的基本运行流程，并以客户端连接事件为例，将框架主循环、事件捕获分发和事件注册的关键步骤串起来，给你做了介绍。Redis事件驱动框架监听处理的事件，还包括客户端请求、服务器端写数据以及周期性操作等，这也是我下一节课要和你一起学习的主要内容。</p><h2>每课一问</h2><p>这节课我们学习了Reactor模型，除了Redis，你还了解什么软件系统使用了Reactor模型吗？</p>","neighbors":{"left":{"article_title":"09 | Redis事件驱动框架（上）：何时使用select、poll、epoll？","id":407901},"right":{"article_title":"11 | Redis事件驱动框架（下）：Redis有哪些事件？","id":408857}}},{"article_id":408857,"article_title":"11 | Redis事件驱动框架（下）：Redis有哪些事件？","article_content":"<p>你好，我是蒋德钧。</p><p>在<a href=\"https://time.geekbang.org/column/article/407901\">第9讲</a>中，我给你介绍了Linux提供的三种IO多路复用机制，分别是select、poll和epoll，这是Redis实现事件驱动框架的操作系统层支撑技术。</p><p>紧接着在上节课，我带你学习了Redis事件驱动框架的基本工作机制，其中介绍了事件驱动框架基于的Reactor模型，并以IO事件中的客户端连接事件为例，给你介绍了<strong>框架运行的基本流程</strong>：从server初始化时调用aeCreateFileEvent函数注册监听事件，到server初始化完成后调用aeMain函数，而aeMain函数循环执行aeProceeEvent函数，来捕获和处理客户端请求触发的事件。</p><p>但是在上节课当中，我们主要关注的是框架基本流程，所以到这里，你或许仍然存有一些疑问，比如说：</p><ul>\n<li>Redis事件驱动框架监听的IO事件，除了上节课介绍的客户端连接以外，还有没有其他事件？而除了IO事件以外，框架还会监听其他事件么？</li>\n<li>这些事件的创建和处理又分别对应了Redis源码中的哪些具体操作？</li>\n</ul><p>今天这节课，我就来给你介绍下Redis事件驱动框架中的两大类事件类型：<strong>IO事件和时间事件，以及它们相应的处理机制。</strong></p><p>事实上，了解和学习这部分内容，一方面可以帮助我们更加全面地掌握，Redis事件驱动框架是如何以事件形式，处理server运行过程中面临的请求操作和多种任务的。比如，正常的客户端读写请求是以什么事件、由哪个函数进行处理，以及后台快照任务又是如何及时启动的。</p><!-- [[[read_end]]] --><p>因为事件驱动框架是Redis server运行后的核心循环流程，了解它何时用什么函数处理哪种事件，对我们排查server运行过程中遇到的问题，是很有帮助的。</p><p>另一方面，我们还可以学习到如何在一个框架中，同时处理IO事件和时间事件。我们平时开发服务器端程序，经常需要处理周期性任务，而Redis关于两类事件的处理实现，就给了我们一个不错的参考。</p><p>好，为了对这两类事件有个相对全面的了解，接下来，我们先从事件驱动框架循环流程的数据结构及其初始化开始学起，因为这里面就包含了针对这两类事件的数据结构定义和初始化操作。</p><h2>aeEventLoop结构体与初始化</h2><p>首先，我们来看下Redis事件驱动框架循环流程对应的数据结构aeEventLoop。这个结构体是在事件驱动框架代码<a href=\"https://github.com/redis/redis/tree/5.0/src/ae.h\">ae.h</a>中定义的，记录了框架循环运行过程中的信息，其中，就包含了记录两类事件的变量，分别是：</p><ul>\n<li><strong>aeFileEvent类型的指针*events，表示IO事件</strong>。之所以类型名称为aeFileEvent，是因为所有的IO事件都会用文件描述符进行标识；</li>\n<li><strong>aeTimeEvent类型的指针*timeEventHead，表示时间事件</strong>，即按一定时间周期触发的事件。</li>\n</ul><p>此外，aeEventLoop结构体中还有一个<strong>aeFiredEvent类型的指针*fired</strong>，这个并不是一类专门的事件类型，它只是用来记录已触发事件对应的文件描述符信息。</p><p>下面的代码显示了Redis中事件循环的结构体定义，你可以看下。</p><pre><code>typedef struct aeEventLoop {\n    …\n    aeFileEvent *events; //IO事件数组\n    aeFiredEvent *fired; //已触发事件数组\n    aeTimeEvent *timeEventHead; //记录时间事件的链表头\n    …\n    void *apidata; //和API调用接口相关的数据\n    aeBeforeSleepProc *beforesleep; //进入事件循环流程前执行的函数\n    aeBeforeSleepProc *aftersleep;  //退出事件循环流程后执行的函数\n} aeEventLoop;\n</code></pre><p>了解了aeEventLoop结构体后，我们再来看下，这个结构体是如何初始化的，这其中就包括了IO事件数组和时间事件链表的初始化。</p><h3>aeCreateEventLoop函数的初始化操作</h3><p>因为Redis server在完成初始化后，就要开始运行事件驱动框架的循环流程，所以，aeEventLoop结构体在<a href=\"http://github.com/redis/redis/tree/5.0/src/server.c\">server.c</a>的initServer函数中，就通过调用<strong>aeCreateEventLoop函数</strong>进行初始化了。这个函数的参数只有一个，是setsize。</p><p>下面的代码展示了initServer函数中对aeCreateEventLoop函数的调用。</p><pre><code>initServer() {\n…\n//调用aeCreateEventLoop函数创建aeEventLoop结构体，并赋值给server结构的el变量\nserver.el = aeCreateEventLoop(server.maxclients+CONFIG_FDSET_INCR);\n…\n}\n</code></pre><p>从这里我们可以看到<strong>参数setsize</strong>的大小，其实是由server结构的maxclients变量和宏定义CONFIG_FDSET_INCR共同决定的。其中，maxclients变量的值大小，可以在Redis的配置文件redis.conf中进行定义，默认值是1000。而宏定义CONFIG_FDSET_INCR的大小，等于宏定义CONFIG_MIN_RESERVED_FDS的值再加上96，如下所示，这里的两个宏定义都是在<a href=\"https://github.com/redis/redis/blob/5.0/src/server.h\">server.h</a>文件中定义的。</p><pre><code>#define CONFIG_MIN_RESERVED_FDS 32\n#define CONFIG_FDSET_INCR (CONFIG_MIN_RESERVED_FDS+96)\n</code></pre><p>好了，到这里，你可能有疑问了：aeCreateEventLoop函数的参数setsize，设置为最大客户端数量加上一个宏定义值，可是<strong>这个参数有什么用呢</strong>？这就和aeCreateEventLoop函数具体执行的初始化操作有关了。</p><p>接下来，我们就来看下aeCreateEventLoop函数执行的操作，大致可以分成以下三个步骤。</p><p><strong>第一步，aeCreateEventLoop函数会创建一个aeEventLoop结构体类型的变量eventLoop</strong>。然后，该函数会给eventLoop的成员变量分配内存空间，比如，按照传入的参数setsize，给IO事件数组和已触发事件数组分配相应的内存空间。此外，该函数还会给eventLoop的成员变量赋初始值。</p><p><strong>第二步，aeCreateEventLoop函数会调用aeApiCreate函数</strong>。aeApiCreate函数封装了操作系统提供的IO多路复用函数，假设Redis运行在Linux操作系统上，并且IO多路复用机制是epoll，那么此时，aeApiCreate函数就会调用epoll_create创建epoll实例，同时会创建epoll_event结构的数组，数组大小等于参数setsize。</p><p>这里你需要注意，aeApiCreate函数是把创建的epoll实例描述符和epoll_event数组，保存在了aeApiState结构体类型的变量state，如下所示：</p><pre><code>typedef struct aeApiState {  //aeApiState结构体定义\n    int epfd;   //epoll实例的描述符\n    struct epoll_event *events;   //epoll_event结构体数组，记录监听事件\n} aeApiState;\n\nstatic int aeApiCreate(aeEventLoop *eventLoop) {\n    aeApiState *state = zmalloc(sizeof(aeApiState));\n    ...\n    //将epoll_event数组保存在aeApiState结构体变量state中\n    state-&gt;events = zmalloc(sizeof(struct epoll_event)*eventLoop-&gt;setsize);\n    ...\n    //将epoll实例描述符保存在aeApiState结构体变量state中\n    state-&gt;epfd = epoll_create(1024); \n</code></pre><p>紧接着，aeApiCreate函数把state变量赋值给eventLoop中的apidata。这样一来，eventLoop结构体中就有了epoll实例和epoll_event数组的信息，这样就可以用来基于epoll创建和处理事件了。我一会儿还会给你具体介绍。</p><pre><code>eventLoop-&gt;apidata = state;\n</code></pre><p><strong>第三步，aeCreateEventLoop函数会把所有网络IO事件对应文件描述符的掩码，初始化为AE_NONE，表示暂时不对任何事件进行监听。</strong></p><p>我把aeCreateEventLoop函数的主要部分代码放在这里，你可以看下。</p><pre><code>aeEventLoop *aeCreateEventLoop(int setsize) {\n    aeEventLoop *eventLoop;\n    int i;\n   \n    //给eventLoop变量分配内存空间\n\tif ((eventLoop = zmalloc(sizeof(*eventLoop))) == NULL) goto err;\n\t//给IO事件、已触发事件分配内存空间\n    eventLoop-&gt;events = zmalloc(sizeof(aeFileEvent)*setsize);\n    eventLoop-&gt;fired = zmalloc(sizeof(aeFiredEvent)*setsize);\n    …\n    eventLoop-&gt;setsize = setsize;\n    eventLoop-&gt;lastTime = time(NULL);\n    //设置时间事件的链表头为NULL\n    eventLoop-&gt;timeEventHead = NULL;\n\t…\n\t//调用aeApiCreate函数，去实际调用操作系统提供的IO多路复用函数\n\tif (aeApiCreate(eventLoop) == -1) goto err;\n\t \n    //将所有网络IO事件对应文件描述符的掩码设置为AE_NONE\n    for (i = 0; i &lt; setsize; i++)\n        eventLoop-&gt;events[i].mask = AE_NONE;\n    return eventLoop;\n \n    //初始化失败后的处理逻辑，\n    err:\n    …\n}\n</code></pre><p>好，那么从aeCreateEventLoop函数的执行流程中，我们其实可以看到以下<strong>两个关键点</strong>：</p><ul>\n<li>事件驱动框架监听的IO事件数组大小就等于参数setsize，这样决定了和Redis server连接的客户端数量。所以，当你遇到客户端连接Redis时报错“max number of clients reached”，你就可以去redis.conf文件修改maxclients配置项，以扩充框架能监听的客户端数量。</li>\n<li>当使用Linux系统的epoll机制时，框架循环流程初始化操作，会通过aeApiCreate函数创建epoll_event结构数组，并调用epoll_create函数创建epoll实例，这都是使用epoll机制的准备工作要求，你也可以再回顾下第9讲中对epoll使用的介绍。</li>\n</ul><p>到这里，框架就可以创建和处理具体的IO事件和时间事件了。所以接下来，我们就先来了解下IO事件及其处理机制。</p><h2>IO事件处理</h2><p>事实上，Redis的IO事件主要包括三类，分别是可读事件、可写事件和屏障事件。</p><p>其中，可读事件和可写事件其实比较好理解，也就是对应于Redis实例，我们可以<strong>从客户端读取数据或是向客户端写入数据</strong>。而屏障事件的主要作用是用来<strong>反转事件的处理顺序</strong>。比如在默认情况下，Redis会先给客户端返回结果，但是如果面临需要把数据尽快写入磁盘的情况，Redis就会用到屏障事件，把写数据和回复客户端的顺序做下调整，先把数据落盘，再给客户端回复。</p><p>我在上节课给你介绍过，在Redis源码中，IO事件的数据结构是aeFileEvent结构体，IO事件的创建是通过aeCreateFileEvent函数来完成的。下面的代码展示了aeFileEvent结构体的定义，你可以再回顾下：</p><pre><code>typedef struct aeFileEvent {\n    int mask; //掩码标记，包括可读事件、可写事件和屏障事件\n    aeFileProc *rfileProc;   //处理可读事件的回调函数\n    aeFileProc *wfileProc;   //处理可写事件的回调函数\n    void *clientData;  //私有数据\n} aeFileEvent;\n</code></pre><p>而对于aeCreateFileEvent函数来说，在上节课我们已经了解了它是通过aeApiAddEvent函数来完成事件注册的。那么接下来，我们再从代码级别看下它是如何执行的，这可以帮助我们更加透彻地理解，事件驱动框架对IO事件监听是如何基于epoll机制对应封装的。</p><h3>IO事件创建</h3><p>首先，我们来看aeCreateFileEvent函数的原型定义，如下所示：</p><pre><code>int aeCreateFileEvent(aeEventLoop *eventLoop, int fd, int mask, aeFileProc *proc, void *clientData)\n</code></pre><p>这个函数的参数有5个，分别是循环流程结构体*eventLoop、IO事件对应的文件描述符fd、事件类型掩码mask、事件处理回调函数<code>*proc</code>，以及事件私有数据<code>*clientData</code>。</p><p>因为循环流程结构体<code>*eventLoop</code>中有IO事件数组，这个数组的元素是aeFileEvent类型，所以，每个数组元素都对应记录了一个文件描述符（比如一个套接字）相关联的监听事件类型和回调函数。</p><p>aeCreateFileEvent函数会先根据传入的文件描述符fd，在eventLoop的IO事件数组中，获取该描述符关联的IO事件指针变量<code>*fe</code>，如下所示：</p><pre><code>aeFileEvent *fe = &amp;eventLoop-&gt;events[fd];\n</code></pre><p>紧接着，aeCreateFileEvent函数会调用aeApiAddEvent函数，添加要监听的事件：</p><pre><code>if (aeApiAddEvent(eventLoop, fd, mask) == -1)\n   return AE_ERR;\n</code></pre><p>aeApiAddEvent函数实际上会调用操作系统提供的IO多路复用函数，来完成事件的添加。我们还是假设Redis实例运行在使用epoll机制的Linux上，那么aeApiAddEvent函数就会调用epoll_ctl函数，添加要监听的事件。我在第9讲中其实已经给你介绍过epoll_ctl函数，这个函数会接收4个参数，分别是：</p><ul>\n<li>epoll实例；</li>\n<li>要执行的操作类型（是添加还是修改）；</li>\n<li>要监听的文件描述符；</li>\n<li>epoll_event类型变量。</li>\n</ul><p>那么，<strong>这个调用过程是如何准备epoll_ctl函数需要的参数，从而完成执行的呢？</strong></p><p>首先，epoll实例是我刚才给你介绍的aeCreateEventLoop函数，它是通过调用aeApiCreate函数来创建的，保存在了eventLoop结构体的apidata变量中，类型是aeApiState。所以，aeApiAddEvent函数会先获取该变量，如下所示：</p><pre><code>static int aeApiAddEvent(aeEventLoop *eventLoop, int fd, int mask) {\n    //从eventLoop结构体中获取aeApiState变量，里面保存了epoll实例\n\taeApiState *state = eventLoop-&gt;apidata;\n    ...\n }\n</code></pre><p>其次，对于要执行的操作类型的设置，aeApiAddEvent函数会根据传入的文件描述符fd，在eventLoop结构体中IO事件数组中查找该fd。因为IO事件数组的每个元素，都对应了一个文件描述符，而该数组初始化时，每个元素的值都设置为了AE_NONE。</p><p>所以，如果要监听的文件描述符fd在数组中的类型不是AE_NONE，则表明该描述符已做过设置，那么操作类型就是修改操作，对应epoll机制中的宏定义EPOLL_CTL_MOD。否则，操作类型就是添加操作，对应epoll机制中的宏定义EPOLL_CTL_ADD。这部分代码如下所示：</p><pre><code>//如果文件描述符fd对应的IO事件已存在，则操作类型为修改，否则为添加\n int op = eventLoop-&gt;events[fd].mask == AE_NONE ?\n            EPOLL_CTL_ADD : EPOLL_CTL_MOD;\n</code></pre><p>第三，epoll_ctl函数需要的监听文件描述符，就是aeApiAddEvent函数接收到的参数fd。</p><p>最后，epoll_ctl函数还需要一个epoll_event类型变量，因此aeApiAddEvent函数在调用epoll_ctl函数前，会新创建epoll_event类型<strong>变量ee。</strong>然后，aeApiAddEvent函数会设置变量ee中的监听事件类型和监听文件描述符。</p><p>aeApiAddEvent函数的参数mask，表示的是要监听的事件类型掩码。所以，aeApiAddEvent函数会根据掩码值是可读（AE_READABLE）或可写（AE_WRITABLE）事件，来设置ee监听的事件类型是EPOLLIN还是EPOLLOUT。这样一来，Redis事件驱动框架中的读写事件就能够和epoll机制中的读写事件对应上来。下面的代码展示了这部分逻辑，你可以看下。</p><pre><code>…\nstruct epoll_event ee = {0}; //创建epoll_event类型变量\n…\n//将可读或可写IO事件类型转换为epoll监听的类型EPOLLIN或EPOLLOUT\nif (mask &amp; AE_READABLE) ee.events |= EPOLLIN;\nif (mask &amp; AE_WRITABLE) ee.events |= EPOLLOUT;\nee.data.fd = fd;  //将要监听的文件描述符赋值给ee\n…\t\n</code></pre><p>好了，到这里，aeApiAddEvent函数就准备好了epoll实例、操作类型、监听文件描述符以及epoll_event类型变量，然后，它就会调用epoll_ctl开始实际创建监听事件了，如下所示：</p><pre><code>static int aeApiAddEvent(aeEventLoop *eventLoop, int fd, int mask) {\n...\n//调用epoll_ctl实际创建监听事件\nif (epoll_ctl(state-&gt;epfd,op,fd,&amp;ee) == -1) return -1;\nreturn 0;\n}\n</code></pre><p>了解了这些代码后，我们可以学习到事件驱动框架是如何基于epoll，封装实现了IO事件的创建。那么，在Redis server启动运行后，最开始监听的IO事件是可读事件，对应于客户端的连接请求。具体是initServer函数调用了aeCreateFileEvent函数，创建可读事件，并设置回调函数为acceptTcpHandler，用来处理客户端连接。这部分内容，你也可以再回顾下第10讲。</p><p>接下来，我们再来看下一旦有了客户端连接请求后，IO事件具体是如何处理的呢？</p><h3>读事件处理</h3><p>当Redis server接收到客户端的连接请求时，就会使用注册好的<strong>acceptTcpHandler函数</strong>进行处理。</p><p>acceptTcpHandler函数是在<a href=\"http://github.com/redis/redis/tree/5.0/src/networking.c\">networking.c</a>文件中，它会接受客户端连接，并创建已连接套接字cfd。然后，acceptCommonHandler函数（在networking.c文件中）会被调用，同时，刚刚创建的已连接套接字cfd会作为参数，传递给acceptCommonHandler函数。</p><p>acceptCommonHandler函数会调用createClient函数（在networking.c文件中）创建客户端。而在createClient函数中，我们就会看到，aeCreateFileEvent函数被再次调用了。</p><p>此时，aeCreateFileEvent函数会针对已连接套接字上，创建监听事件，类型为AE_READABLE，回调函数是readQueryFromClient（在networking.c文件中）。</p><p>好了，到这里，事件驱动框架就增加了对一个客户端已连接套接字的监听。一旦客户端有请求发送到server，框架就会回调readQueryFromClient函数处理请求。这样一来，客户端请求就能通过事件驱动框架进行处理了。</p><p>下面代码展示了createClient函数调用aeCreateFileEvent的过程，你可以看下。</p><pre><code>client *createClient(int fd) {\n…\nif (fd != -1) {\n        …\n        //调用aeCreateFileEvent，监听读事件，对应客户端读写请求，使用readQueryFromclient回调函数处理\n        if (aeCreateFileEvent(server.el,fd,AE_READABLE,\n            readQueryFromClient, c) == AE_ERR)\n        {\n            close(fd);\n            zfree(c);\n            return NULL;\n        } }\n…\n}\n</code></pre><p>为了便于你掌握从监听客户端连接请求到监听客户端常规读写请求的事件创建过程，我画了下面这张图，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/52/e9/5212d6d61a9e5d8aaefc88497fd5aee9.jpg?wh=2000x1093\" alt=\"\"></p><p>了解了事件驱动框架中的读事件处理之后，我们再来看下写事件的处理。</p><h3>写事件处理</h3><p>Redis实例在收到客户端请求后，会在处理客户端命令后，将要返回的数据写入客户端输出缓冲区。下图就展示了这个过程的函数调用逻辑：</p><p><img src=\"https://static001.geekbang.org/resource/image/31/df/3107452361f9366189e4d4080f3153df.jpg?wh=1888x1005\" alt=\"\"></p><p>而在Redis事件驱动框架每次循环进入事件处理函数前，也就是在框架主函数aeMain中调用aeProcessEvents，来处理监听到的已触发事件或是到时的时间事件之前，都会调用server.c文件中的<strong>beforeSleep函数</strong>，进行一些任务处理，这其中就包括了调用handleClientsWithPendingWrites函数，它会将Redis sever客户端缓冲区中的数据写回客户端。</p><p>下面给出的代码是事件驱动框架的主函数aeMain。在该函数每次调用aeProcessEvents函数前，就会调用beforeSleep函数，你可以看下。</p><pre><code>void aeMain(aeEventLoop *eventLoop) {\n    eventLoop-&gt;stop = 0;\n\twhile (!eventLoop-&gt;stop) {\n\t    //如果beforeSleep函数不为空，则调用beforeSleep函数\n        if (eventLoop-&gt;beforesleep != NULL)\n            eventLoop-&gt;beforesleep(eventLoop);\n        //调用完beforeSleep函数，再处理事件\n        aeProcessEvents(eventLoop, AE_ALL_EVENTS|AE_CALL_AFTER_SLEEP);\n    }\n}\n</code></pre><p>这里你要知道，beforeSleep函数调用的handleClientsWithPendingWrites函数，会遍历每一个待写回数据的客户端，然后调用writeToClient函数，将客户端输出缓冲区中的数据写回。下面这张图展示了这个流程，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/18/05/18c8bfaab29a890fb15edcca3971bb05.jpg?wh=2000x1125\" alt=\"\"></p><p>不过，如果输出缓冲区的数据还没有写完，此时，handleClientsWithPendingWrites函数就会<strong>调用aeCreateFileEvent函数，创建可写事件</strong>，并设置回调函数sendReplyToClient。sendReplyToClient函数里面会调用writeToClient函数写回数据。</p><p>下面的代码展示了handleClientsWithPendingWrite函数的基本流程，你可以看下。</p><pre><code>int handleClientsWithPendingWrites(void) {\n    listIter li;\n\tlistNode *ln;\n\t…\n    //获取待写回的客户端列表\n\tlistRewind(server.clients_pending_write,&amp;li);\n\t//遍历每一个待写回的客户端\n\twhile((ln = listNext(&amp;li))) {\n\t   client *c = listNodeValue(ln);\n\t   …\n\t   //调用writeToClient将当前客户端的输出缓冲区数据写回\n\t   if (writeToClient(c-&gt;fd,c,0) == C_ERR) continue;\n\t   //如果还有待写回数据\n\t   if (clientHasPendingReplies(c)) {\n\t            int ae_flags = AE_WRITABLE;\n\t            //创建可写事件的监听，以及设置回调函数\n\t             if (aeCreateFileEvent(server.el, c-&gt;fd, ae_flags,\n\t                sendReplyToClient, c) == AE_ERR)\n\t            {\n\t                   …\n\t            }\n\t  } }\n}\n</code></pre><p>好了，我们刚才了解的是读写事件对应的回调处理函数。实际上，为了能及时处理这些事件，Redis事件驱动框架的aeMain函数还会循环<strong>调用aeProcessEvents函数，来检测已触发的事件，并调用相应的回调函数进行处理。</strong></p><p>从aeProcessEvents函数的代码中，我们可以看到该函数会调用aeApiPoll函数，查询监听的文件描述符中，有哪些已经就绪。一旦有描述符就绪，aeProcessEvents函数就会根据事件的可读或可写类型，调用相应的回调函数进行处理。aeProcessEvents函数调用的基本流程如下所示：</p><pre><code>int aeProcessEvents(aeEventLoop *eventLoop, int flags){\n…\n//调用aeApiPoll获取就绪的描述符\nnumevents = aeApiPoll(eventLoop, tvp);\n…\nfor (j = 0; j &lt; numevents; j++) {\n\taeFileEvent *fe = &amp;eventLoop-&gt;events[eventLoop-&gt;fired[j].fd];\n\t…\n    //如果触发的是可读事件，调用事件注册时设置的读事件回调处理函数\n\tif (!invert &amp;&amp; fe-&gt;mask &amp; mask &amp; AE_READABLE) {\n\t      fe-&gt;rfileProc(eventLoop,fd,fe-&gt;clientData,mask);\n\t                fired++;\n\t}\n    //如果触发的是可写事件，调用事件注册时设置的写事件回调处理函数\n\tif (fe-&gt;mask &amp; mask &amp; AE_WRITABLE) {\n\t                if (!fired || fe-&gt;wfileProc != fe-&gt;rfileProc) {\n\t                    fe-&gt;wfileProc(eventLoop,fd,fe-&gt;clientData,mask);\n\t                    fired++;\n\t                }\n\t            }\n\t…\n\t} }\n\t…\n}\n</code></pre><p>到这里，我们就了解了IO事件的创建函数aeCreateFileEvent，以及在处理客户端请求时对应的读写事件和它们的处理函数。那么接下来，我们再来看看事件驱动框架中的时间事件是怎么创建和处理的。</p><h2>时间事件处理</h2><p>其实，相比于IO事件有可读、可写、屏障类型，以及不同类型IO事件有不同回调函数来说，时间事件的处理就比较简单了。下面，我们就来分别学习下它的定义、创建、回调函数和触发处理。</p><h3>时间事件定义</h3><p>首先，我们来看下时间事件的结构体定义，代码如下所示：</p><pre><code>typedef struct aeTimeEvent {\n    long long id; //时间事件ID\n    long when_sec; //事件到达的秒级时间戳\n    long when_ms; //事件到达的毫秒级时间戳\n    aeTimeProc *timeProc; //时间事件触发后的处理函数\n    aeEventFinalizerProc *finalizerProc;  //事件结束后的处理函数\n    void *clientData; //事件相关的私有数据\n    struct aeTimeEvent *prev;  //时间事件链表的前向指针\n    struct aeTimeEvent *next;  //时间事件链表的后向指针\n} aeTimeEvent;\n</code></pre><p>时间事件结构体中主要的变量，包括以秒记录和以毫秒记录的时间事件触发时的时间戳when_sec和when_ms，以及时间事件触发后的处理函数<code>*timeProc</code>。另外，在时间事件的结构体中，还包含了前向和后向指针<code>*prev</code>和<code>*next</code>，这表明<strong>时间事件是以链表的形式组织起来的</strong>。</p><p>在了解了时间事件结构体的定义以后，我们接着来看下，时间事件是如何创建的。</p><h3>时间事件创建</h3><p>与IO事件创建使用aeCreateFileEvent函数类似，<strong>时间事件的创建函数是aeCreateTimeEvent函数</strong>。这个函数的原型定义如下所示：</p><pre><code>long long aeCreateTimeEvent(aeEventLoop *eventLoop, long long milliseconds, aeTimeProc *proc, void *clientData, aeEventFinalizerProc *finalizerProc)\n</code></pre><p>在它的参数中，有两个需要我们重点了解下，以便于我们理解时间事件的处理。一个是<strong>milliseconds</strong>，这是所创建时间事件的触发时间距离当前时间的时长，是用毫秒表示的。另一个是*<strong>proc</strong>，这是所创建时间事件触发后的回调函数。</p><p>aeCreateTimeEvent函数的执行逻辑不复杂，主要就是创建一个时间事件的<strong>变量te</strong>，对它进行初始化，并把它插入到框架循环流程结构体eventLoop中的时间事件链表中。在这个过程中，aeCreateTimeEvent函数会<strong>调用aeAddMillisecondsToNow函数</strong>，根据传入的milliseconds参数，计算所创建时间事件具体的触发时间戳，并赋值给te。</p><p>实际上，Redis server在初始化时，除了创建监听的IO事件外，也会调用aeCreateTimeEvent函数创建时间事件。下面代码显示了initServer函数对aeCreateTimeEvent函数的调用：</p><pre><code>initServer() {\n…\n//创建时间事件\nif (aeCreateTimeEvent(server.el, 1, serverCron, NULL, NULL) == AE_ERR){\n… //报错信息\n}\n}\n</code></pre><p>从代码中，我们可以看到，<strong>时间事件触发后的回调函数是serverCron</strong>。所以接下来，我们就来了解下serverCron函数。</p><h3>时间事件回调函数</h3><p>serverCron函数是在server.c文件中实现的。<strong>一方面</strong>，它会顺序调用一些函数，来实现时间事件被触发后，执行一些后台任务。比如，serverCron函数会检查是否有进程结束信号，若有就执行server关闭操作。serverCron会调用databaseCron函数，处理过期key或进行rehash等。你可以参考下面给出的代码：</p><pre><code>...\n//如果收到进程结束信号，则执行server关闭操作\n if (server.shutdown_asap) {\n        if (prepareForShutdown(SHUTDOWN_NOFLAGS) == C_OK) exit(0);\n        ...\n }\n...\nclientCron();  //执行客户端的异步操作\ndatabaseCron(); //执行数据库的后台操作\n...\n</code></pre><p><strong>另一方面</strong>，serverCron函数还会以不同的频率周期性执行一些任务，这是通过执行宏run_with_period来实现的。</p><p>run_with_period宏定义如下，该宏定义会根据Redis实例配置文件redis.conf中定义的hz值，来判断参数_ms_表示的时间戳是否到达。一旦到达，serverCron就可以执行相应的任务了。</p><pre><code>#define run_with_period(_ms_) if ((_ms_ &lt;= 1000/server.hz) || !(server.cronloops%((_ms_)/(1000/server.hz))))\n</code></pre><p>比如，serverCron函数中会以1秒1次的频率，检查AOF文件是否有写错误。如果有的话，serverCron就会调用flushAppendOnlyFile函数，再次刷回AOF文件的缓存数据。下面的代码展示了这一周期性任务：</p><pre><code>serverCron() {\n   …\n   //每1秒执行1次，检查AOF是否有写错误\n   run_with_period(1000) {\n        if (server.aof_last_write_status == C_ERR)\n            flushAppendOnlyFile(0);\n    }\n   …\n}\n</code></pre><p>如果你想了解更多的周期性任务，可以再详细阅读下serverCron函数中，以run_with_period宏定义包含的代码块。</p><p>好了，了解了时间事件触发后的回调函数serverCron，我们最后来看下，时间事件是如何触发处理的。</p><h3>时间事件的触发处理</h3><p>其实，时间事件的检测触发比较简单，事件驱动框架的aeMain函数会循环调用aeProcessEvents函数，来处理各种事件。而aeProcessEvents函数在执行流程的最后，会<strong>调用processTimeEvents函数处理相应到时的任务</strong>。</p><pre><code>aeProcessEvents(){\n…\n//检测时间事件是否触发\nif (flags &amp; AE_TIME_EVENTS)\n        processed += processTimeEvents(eventLoop);\n…\n}\n</code></pre><p>那么，具体到proecessTimeEvent函数来说，它的基本流程就是从时间事件链表上逐一取出每一个事件，然后根据当前时间判断该事件的触发时间戳是否已满足。如果已满足，那么就调用该事件对应的回调函数进行处理。这样一来，周期性任务就能在不断循环执行的aeProcessEvents函数中，得到执行了。</p><p>下面的代码显示了processTimeEvents函数的基本流程，你可以再看下。</p><pre><code>static int processTimeEvents(aeEventLoop *eventLoop) {\n...\nte = eventLoop-&gt;timeEventHead;  //从时间事件链表中取出事件\nwhile(te) {\n   ...\n  aeGetTime(&amp;now_sec, &amp;now_ms);  //获取当前时间\n  if (now_sec &gt; te-&gt;when_sec || (now_sec == te-&gt;when_sec &amp;&amp; now_ms &gt;= te-&gt;when_ms))   //如果当前时间已经满足当前事件的触发时间戳\n  {\n     ...\n    retval = te-&gt;timeProc(eventLoop, id, te-&gt;clientData); //调用注册的回调函数处理\n    ...\n  }\n  te = te-&gt;next;   //获取下一个时间事件\n  ...\n}\n</code></pre><h2>小结</h2><p>这节课，我给你介绍了Redis事件驱动框架中的两类事件：IO事件和时间事件。</p><p>对于IO事件来说，它可以进一步分成可读、可写和屏障事件。因为可读、可写事件在Redis和客户端通信处理请求过程中使用广泛，所以今天我们重点学习了这两种IO事件。当Redis server创建Socket后，就会注册可读事件，并使用acceptTCPHandler回调函数处理客户端的连接请求。</p><p>当server和客户端完成连接建立后，server会在已连接套接字上监听可读事件，并使用readQueryFromClient函数处理客户端读写请求。这里，你需要再注意下，<strong>无论客户端发送的请求是读或写操作，对于server来说，都是要读取客户端的请求并解析处理</strong>。所以，server在客户端的已连接套接字上注册的是可读事件。</p><p>而当实例需要向客户端写回数据时，实例会在事件驱动框架中注册可写事件，并使用sendReplyToClient作为回调函数，将缓冲区中数据写回客户端。我总结了一张表格，以便你再回顾下IO事件和相应套接字、回调函数的对应关系。</p><p><img src=\"https://static001.geekbang.org/resource/image/4b/0c/4b354d1c4fd6eed66b58c14689018a0c.jpg?wh=2000x812\" alt=\"\"></p><p>然后，对于时间事件来说，它主要是用于在事件驱动框架中注册一些周期性执行的任务，以便Redis server进行后台处理。时间事件的回调函数是serverCron函数，你可以做进一步阅读了解其中的具体任务。</p><p>好了，从第9讲开始，我用了3节课，向你介绍Redis事件驱动框架的运行机制，本质上来说，事件驱动框架是基于操作系统提供的IO多路复用机制进行了封装，并加上了时间事件的处理。这是一个非常经典的事件框架实现，我希望你可以学习并掌握好它，然后用在你自己的系统开发中。</p><h2>每课一问</h2><p>已知，Redis事件驱动框架的aeApiCreate、aeApiAddEvent等等这些函数，是对操作系统提供的IO多路复用函数进行了封装，具体的IO多路复用函数分别是在<a href=\"https://github.com/redis/redis/tree/5.0/src/ae_epoll.c\">ae_epoll.c</a>，<a href=\"https://github.com/redis/redis/tree/5.0/src/ae_evport.c\">ae_evport.c</a>，<a href=\"https://github.com/redis/redis/tree/5.0/src/ae_kqueue.c\">ae_kqueue.c</a>，<a href=\"https://github.com/redis/redis/tree/5.0/src/ae_select.c\">ae_select.c</a>四个代码文件中定义的。那么你知道，Redis在调用aeApiCreate，aeApiAddEvent这些函数时，是根据什么条件来决定，具体调用哪个文件中的IO多路复用函数的吗？</p>","neighbors":{"left":{"article_title":"10 | Redis事件驱动框架（中）：Redis实现了Reactor模型吗？","id":408491},"right":{"article_title":"12 | Redis真的是单线程吗？","id":409927}}},{"article_id":409927,"article_title":"12 | Redis真的是单线程吗？","article_content":"<p>你好，我是蒋德钧。今天这节课，我们来聊聊Redis的执行模型。</p><p>所谓的执行模型，就是指Redis运行时使用的进程、子进程和线程的个数，以及它们各自负责的工作任务。</p><p>你在实际使用Redis的时候，可能经常会听到类似“Redis是单线程”“Redis的主IO线程”，“Redis包含多线程”等不同说法。我也听到不少同学提出困惑和疑问：<strong>Redis到底是不是一个单线程的程序？</strong></p><p>其实，彻底理解这个问题，有助于指导我们保持Redis高性能、低延迟的特性。如果说Redis就是单线程程序，那么，我们就需要避免所有容易引起线程阻塞的操作；而如果说Redis不只是单线程，还有其他线程在工作，那么，我们就需要了解多线程各自负责什么任务，负责请求解析和数据读写的线程有几个，有哪些操作是后台线程在完成，而不会影响请求解析和数据读写的。</p><p>所以，今天这节课，我就从Redis server启动后运行的进程开始，带你一边学习Redis源码中子进程和线程的创建方式，一边掌握Redis server运行时涉及到的进程、子进程和线程情况。</p><p>下面，我们先来看Redis server启动时的进程运行。</p><h2>从shell命令执行到Redis进程创建</h2><p>我们在启动Redis实例时，可以在shell命令行环境中，执行redis-server这个可执行文件，如下所示：</p><!-- [[[read_end]]] --><pre><code>./redis-server  /etc/redis/redis.conf\n</code></pre><p>shell运行这个命令后，它实际会调用fork系统调用函数，来新建一个进程。因为shell本身是一个进程，所以，这个通过fork新创建的进程就被称为是shell进程的子进程，而shell进程被称为父进程。关于fork函数的具体用法，我一会儿还会给你具体介绍。</p><p>紧接着，shell进程会调用execve系统调用函数，将子进程执行的主体替换成Redis的可执行文件。而Redis可执行文件的入口函数就是main函数，这样一来，子进程就会开始执行Redis server的main函数了。</p><p>下面的代码显示了execve系统调用函数原型。其中，filename是要运行的程序的文件名，argv[]和envp[]分别是要运行程序的参数和环境变量。</p><pre><code>int execve(const char *filename, char *const argv[], char *const envp[]))\n</code></pre><p>下图显示了从shell执行命令到创建Redis进程的过程，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/d7/b5/d7ec5ef2698cyyd1973a6afbb0c7dfb5.jpg?wh=2000x510\" alt=\"\"></p><p>当我们用刚才介绍的shell命令运行Redis server后，我们会看到Redis server启动后的日志输出会打印到终端屏幕上，如下所示：</p><pre><code>37807:M 19 Aug 2021 07:29:36.372 # Server initialized\n37807:M 19 Aug 2021 07:29:36.372 * DB loaded from disk: 0.000 seconds\n37807:M 19 Aug 2021 07:29:36.372 * Ready to accept connections\n</code></pre><p>这是因为shell进程调用fork函数创建的子进程，会从父进程中继承一些属性，比如父进程打开的文件描述符。对于shell进程来说，它打开的文件描述符包括0和1，这两个描述符分别代表了标准输入和标准输出。而execve函数只是把子进程的执行内容替换成Redis可执行文件，子进程从shell父进程继承到的标准输入和标准输出保持不变。</p><p>所以，Redis运行时通过serverLog函数打印的日志信息，就会默认输出到终端屏幕上了，也就是shell进程的标准输出。</p><p>而一旦Redis进程创建开始运行后，它就会从main函数开始执行。我们在<a href=\"https://time.geekbang.org/column/article/406556\">第8讲</a>中已经学习了main函数的主要执行过程，所以我们会发现，它会调用不同的函数来执行相关功能。比如，main函数调用initServerConfig函数初始化Redis server的运行参数，调用loadServerConfig函数解析配置文件参数。当main函数调用这些函数时，这些函数仍然是由原来的进程执行的。所以，在这种情况下，Redis仍然是单个进程在运行。</p><p>不过，在main函数完成参数解析后，会根据两个配置参数daemonize和supervised，来设置变量background的值。它们的含义分别是：</p><ul>\n<li>参数daemonize表示，是否要设置Redis以守护进程方式运行；</li>\n<li>参数supervised表示，是否使用upstart或是systemd这两种守护进程的管理程序来管理Redis。</li>\n</ul><p>那么，我们来进一步了解下守护进程。守护进程是在系统后台运行的进程，独立于shell终端，不再需要用户在shell中进行输入了。一般来说，守护进程用于执行周期性任务或是等待相应事件发生再进行处理。Redis server本身就是在启动后，等待客户端输入，再进行处理。所以对于Redis这类服务器程序来说，我们通常会让它以守护进程方式运行。</p><p>好了，如果设置了Redis以守护进程方式执行，那么守护进程具体是怎么创建的呢？这就和main函数调用的daemonize函数相关了。daemonize函数就是用来将Redis进程转换为守护进程来运行。</p><p>下面的代码显示了main函数根据变量background值，来判断是否执行daemonize函数的逻辑，你可以看下。</p><pre><code>//如果配置参数daemonize为1，supervised值为0，那么设置background值为1，否则，设置其为0。\nint main(int argc, char **argv) {\n…\nint background = server.daemonize &amp;&amp; !server.supervised;\n//如果background值为1，调用daemonize函数。\nif (background) daemonize();\n…\n}\n</code></pre><p>也就是说，如果background的值为1，就表示Redis被设置为以守护进程方式运行，因此main函数就会调用daemonize函数。</p><p>那么，接下来，我们就来学习下daemonize函数是如何将Redis转为守护进程运行的。</p><h2>从daemonize函数的执行学习守护进程的创建</h2><p>我们首先来看daemonize函数的部分执行内容，如下所示。我们可以看到，daemonize函数调用了fork函数，并根据fork函数返回值有不同的分支代码。</p><pre><code>void daemonize(void) {\n…\nif (fork() != 0) exit(0); //fork成功执行或失败，则父进程退出\nsetsid(); //创建新的session\n…\n}\n</code></pre><p>从刚才的介绍中，我们已经知道，当我们在一个程序的函数中调用fork函数时，fork函数会创建一个子进程。而原本这个程序对应的进程，就称为这个子进程的父进程。那么，fork函数执行后的不同分支和父、子进程是什么关系呢？这就和fork函数的使用有关了。</p><p>实际上，fork函数的使用是比较有意思的，我们可以根据fork函数的不同返回值，来编写相应的分支代码，这些分支代码就对应了父进程和子进程各自要执行的逻辑。</p><p>为了便于你理解，我给你举个例子。我写了一段示例代码，这段代码的main函数会调用fork函数，并进一步根据fork函数的返回值是小于0、等于0，还是大于0，来执行不同的分支。注意，fork函数的不同返回值，其实代表了不同的含义，具体来说：</p><ul>\n<li>当返回值小于0时，此时表明fork函数执行有误；</li>\n<li>当返回值等于0时，此时，返回值对应的代码分支就会在子进程中运行；</li>\n<li>当返回值大于0时，此时，返回值对应的代码分支仍然会在父进程中运行。</li>\n</ul><p>这段示例代码如下：</p><pre><code>#include &lt;stdio.h&gt;\n#include &lt;unistd.h&gt;\n \nint main(int argc, char *argv[]) {\n\tprintf(&quot;hello main\\n&quot;);\n    int rv = fork(); //fork函数的返回值\n    //返回值小于0，表示fork执行错误\n    if (rv &lt; 0) {\n        fprintf(stderr, &quot;fork failed\\n&quot;);\n\t}\n\t//返回值等于0，对应子进程执行\n    else if (rv == 0) {\n        printf(&quot;I am child process %d\\n&quot;, getpid());\n\t}\n\t//返回值大于0，对应父进程执行\n    else {\n        printf(&quot;I am parent process of (%d), %d\\n&quot;, rc, getpid());\n    }\n    return 0;\n}\n</code></pre><p>在这段代码中，我根据fork函数的返回值，分别写了三个分支代码，其中返回值等于0对应的代码分支，是子进程执行的代码。子进程会打印字符串“I am child process”，并打印子进程的进程号。而返回值大于0对应的代码分支，是父进程的代码。父进程会打印字符串“I am parent process of”，并打印它所创建的子进程进程号和它自身的进程号。</p><p>那么，如果你把这段代码编译后执行，你可以看到类似如下的结果，父进程打印了它的进程号62794，而子进程则打印了它的进程号62795。这表明刚才示例代码中的不同分支的确是由父、子进程来执行的。这也就是说，我们可以在fork函数执行后，使用不同分支，让父、子进程执行不同内容。</p><pre><code>hello main\nI am parent process of (62795), 62794\nI am child process 62795\n</code></pre><p>好了，了解了fork函数创建子进程的知识后，我们再来看下刚才介绍的daemonize函数。</p><p>现在我们已经知道，daemonize函数调用fork函数后，可以根据fork函数返回值设置不同代码分支，对应父、子进程执行内容。其实，daemonize函数也的确设置了两个代码分支。</p><ul>\n<li><strong>分支一</strong></li>\n</ul><p>这个分支对应fork函数返回值不为0，表示fork函数成功执行后的父进程执行逻辑或是fork函数执行失败的执行逻辑。此时，父进程会调用exit(0)函数退出。也就是说，如果fork函数成功执行，父进程就退出了。当然，如果fork函数执行失败了，那么子进程也没有能成功创建，父进程也就退出执行了。你可以看下下面的代码，展示了这个分支。</p><pre><code>void daemonize(void) {\n…\nif (fork() != 0) exit(0); //fork成功执行或失败，则父进程退出\n…\n}\n</code></pre><ul>\n<li><strong>分支二</strong></li>\n</ul><p>这个分支对应fork函数返回值为0，为子进程的执行逻辑。子进程首先会调用setsid函数，创建一个新的会话。</p><p>然后，子进程会用open函数打开/dev/null设备，并把它的标准输入、标准输出和标准错误输出，重新定向到/dev/null设备。因为守护进程是在后台运行，它的输入输出是独立于shell终端的。所以，为了让Redis能以守护进程方式运行，这几步操作的目的就是把当前子进程的输入、输出由原来的shell终端，转向/dev/null设备，这样一来，就不再依赖于shell终端了，满足了守护进程的要求。</p><p>我把daemonize函数的代码放在这里，你可以看下。</p><pre><code>void daemonize(void) {\n    …\n    setsid(); //为子进程创建新的session\n   \n    //将子进程的标准输入、标准输出、标准错误输出重定向到/dev/null中\n    if ((fd = open(&quot;/dev/null&quot;, O_RDWR, 0)) != -1) {\n        dup2(fd, STDIN_FILENO);\n        dup2(fd, STDOUT_FILENO);\n        dup2(fd, STDERR_FILENO);\n        if (fd &gt; STDERR_FILENO) close(fd);\n    }\n}\n</code></pre><p>好了，到这里，我们就了解了，Redis的main函数会根据配置参数daemonize和supervised，来判断是否以守护进程方式运行Redis。</p><p>那么，一旦Redis要以守护进程方式运行，main函数会调用daemonize函数。daemonize函数会进一步调用fork函数创建子进程，并根据返回值，分别执行父进程和子进程的代码分支。其中，父进程会退出。而子进程会代替原来的父进程，继续执行main函数的代码。</p><p>下面的图展示了daemonize函数调用fork函数后的两个分支的执行逻辑，你可以再回顾下。</p><p><img src=\"https://static001.geekbang.org/resource/image/b9/11/b9fa1ea3962e18be5ca9973a2feeb111.jpg?wh=2000x947\" alt=\"\"></p><p>事实上，Redis server启动后无论是否以守护进程形式运行，都还是一个进程在运行。对于一个进程来说，如果该进程启动后没有创建新的线程，那么这个进程的工作任务默认就是由一个线程来执行的，而这个线程我一般也称它为主线程。</p><p>对于Redis来说，它的主要工作，包括接收客户端请求、解析请求和进行数据读写等操作，都没有创建新线程来执行，所以，Redis主要工作的确是由单线程来执行的，这也是我们常说Redis是单线程程序的原因。因为Redis主要工作都是IO读写操作，所以，我也会把这个单线程称为主IO线程。</p><p>但其实，Redis 在3.0版本后，除了主IO线程外，的确还会启动一些后台线程来处理部分任务，从而避免这些任务对主IO线程的影响。那么，这些后台线程是在哪里启动的，又是如何执行的呢？</p><p>这就和Redis的<a href=\"https://github.com/redis/redis/tree/5.0/src/bio.c\">bio.c</a>文件相关了。接下来，我们就来从这个文件中学习下Redis的后台线程。</p><h2>从bio.c文件学习Redis的后台线程</h2><p>我们先来看下main函数在初始化过程最后调用的InitServerLast函数。InitServerLast函数的作用是进一步调用bioInit函数，来创建后台线程，让Redis把部分任务交给后台线程处理。这个过程如下所示。</p><pre><code>void InitServerLast() {\n    bioInit();\n    …\n}\n</code></pre><p>bioInit函数是在<a href=\"https://github.com/redis/redis/tree/5.0/src/bio.c\">bio.c</a>文件中实现的，它的主要作用调用pthread_create函数创建多个后台线程。不过在具体了解bioInit函数之前，我们先来看下bio.c文件中定义的主要数组，这也是在bioInit函数中要进行初始化的。</p><p>bio.c文件针对要创建的线程，定义了pthread_t类型的数组bio_threads，用来保存创建的线程描述符。此外，bio.c文件还创建了一个保存互斥锁的数组bio_mutex，以及两个保存条件变量的数组bio_newjob_cond和bio_step_cond。以下代码展示了这些数组的创建逻辑，你可以看下。</p><pre><code>//保存线程描述符的数组\nstatic pthread_t bio_threads[BIO_NUM_OPS]; \n//保存互斥锁的数组\nstatic pthread_mutex_t bio_mutex[BIO_NUM_OPS];\n//保存条件变量的两个数组\nstatic pthread_cond_t bio_newjob_cond[BIO_NUM_OPS];\nstatic pthread_cond_t bio_step_cond[BIO_NUM_OPS];\n</code></pre><p>从中你可以注意到，这些数组的大小都是宏定义BIO_NUM_OPS，这个宏定义是在<a href=\"https://github.com/redis/redis/tree/5.0/src/bio.h\">bio.h</a>文件中定义的，默认值为3。</p><p>同时在bio.h文件中，你还可以看到另外三个宏定义，分别是BIO_CLOSE_FILE、BIO_AOF_FSYNC和BIO_LAZY_FREE。它们的代码如下所示：</p><pre><code>#define BIO_CLOSE_FILE    0 /* Deferred close(2) syscall. */\n#define BIO_AOF_FSYNC    1 /* Deferred AOF fsync. */\n#define BIO_LAZY_FREE     2 /* Deferred objects freeing. */\n#define BIO_NUM_OPS       3\n</code></pre><p>其中，BIO_NUM_OPS表示的是Redis后台任务的类型有三种。而BIO_CLOSE_FILE、BIO_AOF_FSYNC和BIO_LAZY_FREE，它们分别表示三种后台任务的操作码，这些操作码可以用来标识不同的任务。</p><ul>\n<li><strong>BIO_CLOSE_FILE</strong>：文件关闭后台任务。</li>\n<li><strong>BIO_AOF_FSYNC</strong>：AOF日志同步写回后台任务。</li>\n<li><strong>BIO_LAZY_FREE</strong>：惰性删除后台任务。</li>\n</ul><p>实际上，bio.c文件创建的线程数组、互斥锁数组和条件变量数组，大小都是包含三个元素，也正是对应了这三种任务。</p><h3>bioInit函数：初始化数组</h3><p>接下来，我们再来了解下bio.c文件中的初始化和线程创建函数bioInit。我刚才也给你介绍过这个函数，它是main函数执行完server初始化后，通过InitServerLast函数调用的。也就是说，Redis在完成server初始化后，就会创建线程来执行后台任务。</p><p>所以从这里来看，<strong>Redis在运行时其实已经不止是单个线程（也就是主IO线程）在运行了，还会有后台线程在运行</strong>。如果你以后遇到Redis是否是单线程的问题时，你就可以给出准确答案了。</p><p>bioInit函数首先会初始化互斥锁数组和条件变量数组。然后，该函数会调用listCreate函数，给bio_jobs这个数组的每个元素创建一个列表，同时给bio_pending数组的每个元素赋值为0。这部分代码如下所示：</p><pre><code>  for (j = 0; j &lt; BIO_NUM_OPS; j++) {\n        pthread_mutex_init(&amp;bio_mutex[j],NULL);\n        pthread_cond_init(&amp;bio_newjob_cond[j],NULL);\n        pthread_cond_init(&amp;bio_step_cond[j],NULL);\n        bio_jobs[j] = listCreate();\n        bio_pending[j] = 0;\n    }\n</code></pre><p>那么，要想了解给bio_jobs数组和bio_pending数组元素赋值的作用，我们就需要先搞清楚这两个数组的含义：</p><ul>\n<li><strong>bio_jobs数组</strong>的元素是bio_jobs结构体类型，用来表示后台任务。该结构体的成员变量包括了后台任务的创建时间time，以及任务的参数。为该数组的每个元素创建一个列表，其实就是为每个后台线程创建一个要处理的任务列表。</li>\n<li><strong>bio_pending数组</strong>的元素类型是unsigned long long，用来表示每种任务中，处于等待状态的任务个数。将该数组每个元素初始化为0，其实就是表示初始时，每种任务都没有待处理的具体任务。</li>\n</ul><p>下面的代码展示了bio_job结构体，以及bio_jobs和bio_pending这两个数组的定义，你也可以看下。</p><pre><code>struct bio_job {\n    time_t time; //任务创建时间\n    void *arg1, *arg2, *arg3;  //任务参数\n};\n//以后台线程方式运行的任务列表\nstatic list *bio_jobs[BIO_NUM_OPS];\n//被阻塞的后台任务数组\nstatic unsigned long long bio_pending[BIO_NUM_OPS];\n</code></pre><p>好了，到这里，你就了解了bioInit函数执行时，会把线程互斥锁、条件变量对应数组初始化为NULL，同时会给每个后台线程创建一个任务列表（对应bio_jobs数组的元素），以及会设置每种任务的待处理个数为0（对应bio_pending数组的元素）。</p><h3>bioInit函数：设置线程属性并创建线程</h3><p>在完成了初始化之后，接下来，bioInit函数会先通过pthread_attr_t类型的变量，给线程设置属性。然后，bioInit函数会调用前面我提到的pthread_create函数来创建线程。</p><p>不过，为了能更好地理解bioInit函数设置线程属性和创建线程的过程，我们需要先对pthread_create函数本身有所了解，该函数的原型如下所示：</p><pre><code>int  pthread_create(pthread_t *tidp, const  pthread_attr_t *attr,\n( void *)(*start_routine)( void *), void  *arg);\n</code></pre><p>可以看到，pthread_create函数一共有4个参数，分别是：</p><ul>\n<li>*<strong>tidp</strong>，指向线程数据结构pthread_t的指针；</li>\n<li>*<strong>attr</strong>，指向线程属性结构pthread_attr_t的指针；</li>\n<li>*<strong>start_routine</strong>，线程所要运行的函数的起始地址，也是指向函数的指针；</li>\n<li>*<strong>arg</strong>，传给运行函数的参数。</li>\n</ul><p>了解了pthread_create函数之后，我们来看下bioInit函数的具体操作。</p><p>首先，bioInit函数会调用pthread_attr_init函数，初始化线程属性变量attr，然后调用pthread_attr_getstacksize函数，获取线程的栈大小这一属性的当前值，并根据当前栈大小和REDIS_THREAD_STACK_SIZE宏定义的大小（默认值为4MB），来计算最终的栈大小属性值。紧接着，bioInit函数会调用pthread_attr_setstacksize函数，来设置栈大小这一属性值。</p><p>下面的代码展示了线程属性的获取、计算和设置逻辑，你可以看下。</p><pre><code>pthread_attr_init(&amp;attr);\npthread_attr_getstacksize(&amp;attr,&amp;stacksize);\nif (!stacksize) stacksize = 1; /针对Solaris系统做处理\n    while (stacksize &lt; REDIS_THREAD_STACK_SIZE) stacksize *= 2;\n    pthread_attr_setstacksize(&amp;attr, stacksize);\n</code></pre><p>我也画了一张图，展示了线程属性的这一操作过程，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/0c/9a/0c9a1dd6f5038f05716d916c588d599a.jpg?wh=2000x1125\" alt=\"\"></p><p>在完成线程属性的设置后，接下来，bioInit函数会通过一个for循环，来依次为每种后台任务创建一个线程。循环的次数是由BIO_NUM_OPS宏定义决定的，也就是3次。相应的，bioInit函数就会调用3次pthread_create函数，并创建3个线程。bioInit函数让这3个线程执行的函数都是<strong>bioProcessBackgroundJobs</strong>。</p><p>不过这里要注意一点，就是在这三次线程的创建过程中，传给这个函数的参数分别是0、1、2。这个创建过程如下所示：</p><pre><code>for (j = 0; j &lt; BIO_NUM_OPS; j++) {\n        void *arg = (void*)(unsigned long) j;\n        if (pthread_create(&amp;thread,&amp;attr,bioProcessBackgroundJobs,arg) != 0) {\n            … //报错信息\n        }\n        bio_threads[j] = thread;\n    }\n</code></pre><p>你看了这个代码，可能会有一个小疑问：<strong>为什么创建的3个线程，它们所运行的bioProcessBackgroundJobs函数接收的参数分别是0、1、2呢？</strong></p><p>这就和bioProcessBackgroundJobs函数的实现有关了，我们来具体看下。</p><h3>bioProcessBackgroundJobs函数：处理后台任务</h3><p>首先，bioProcessBackgroundJobs函数会把接收到的参数arg，转成unsigned long类型，并赋值给type变量，如下所示：</p><pre><code>void *bioProcessBackgroundJobs(void *arg) {\n    …\n\tunsigned long type = (unsigned long) arg;\n\t…\n}\n</code></pre><p>而<strong>type变量表示的就是后台任务的操作码</strong>。这也是我刚才给你介绍的三种后台任务类型BIO_CLOSE_FILE、BIO_AOF_FSYNC和BIO_LAZY_FREE对应的操作码，它们的取值分别为0、1、2。</p><p>bioProcessBackgroundJobs函数的主要执行逻辑是一个while(1)的循环。在这个循环中，bioProcessBackgroundJobs函数会从bio_jobs这个数组中取出相应任务，并根据任务类型，调用具体的函数来执行。</p><p>我刚才已经介绍过，bio_jobs数组的每一个元素是一个队列。而因为bio_jobs数组的元素个数，等于后台任务的类型个数（也就是BIO_NUM_OPS），所以，bio_jobs数组的每个元素，实际上是对应了某一种后台任务的任务队列。</p><p>在了解了这一点后，我们就容易理解bioProcessBackgroundJobs函数中的while循环了。因为传给bioProcessBackgroundJobs函数的参数，分别是0、1、2，对应了三种任务类型，所以在这个循环中，bioProcessBackgroundJobs函数会一直不停地从某一种任务队列中，取出一个任务来执行。</p><p>同时，bioProcessBackgroundJobs函数会根据传入的任务操作类型调用相应函数，具体来说：</p><ul>\n<li>任务类型是BIO_CLOSE_FILE，则调用close函数；</li>\n<li>任务类型是BIO_AOF_FSYNC，则调用redis_fsync函数；</li>\n<li>任务类型是BIO_LAZY_FREE，则再根据参数个数等情况，分别调用lazyfreeFreeObjectFromBioThread、lazyfreeFreeDatabaseFromBioThread和lazyfreeFreeSlotsMapFromBioThread这三个函数。</li>\n</ul><p>最后，当某个任务执行完成后，bioProcessBackgroundJobs函数会从任务队列中，把这个任务对应的数据结构删除。我把这部分代码放在这里，你可以看下。</p><pre><code>while(1) {\n        listNode *ln;\n \n        …\n        //从类型为type的任务队列中获取第一个任务\n        ln = listFirst(bio_jobs[type]);\n        job = ln-&gt;value;\n        \n        …\n        //判断当前处理的后台任务类型是哪一种\n        if (type == BIO_CLOSE_FILE) {\n            close((long)job-&gt;arg1);  //如果是关闭文件任务，那就调用close函数\n        } else if (type == BIO_AOF_FSYNC) {\n            redis_fsync((long)job-&gt;arg1); //如果是AOF同步写任务，那就调用redis_fsync函数\n        } else if (type == BIO_LAZY_FREE) {\n            //如果是惰性删除任务，那根据任务的参数分别调用不同的惰性删除函数执行\n            if (job-&gt;arg1)\n                lazyfreeFreeObjectFromBioThread(job-&gt;arg1);\n            else if (job-&gt;arg2 &amp;&amp; job-&gt;arg3)\n                lazyfreeFreeDatabaseFromBioThread(job-&gt;arg2,job-&gt;arg3);\n            else if (job-&gt;arg3)\n                lazyfreeFreeSlotsMapFromBioThread(job-&gt;arg3);\n        } else {\n            serverPanic(&quot;Wrong job type in bioProcessBackgroundJobs().&quot;);\n        }\n        …\n        //任务执行完成后，调用listDelNode在任务队列中删除该任务\n        listDelNode(bio_jobs[type],ln);\n        //将对应的等待任务个数减一。\n        bio_pending[type]--;\n        …\n    }\n</code></pre><p>所以说，bioInit函数其实就是创建了3个线程，每个线程不停地去查看任务队列中是否有任务，如果有任务，就调用具体函数执行。</p><p>你可以再参考回顾下图所展示的bioInit函数和bioProcessBackgroundJobs函数的基本处理流程。</p><p><img src=\"https://static001.geekbang.org/resource/image/d8/c4/d8cb6f9f2e410e7680ef0e674b50efc4.jpg?wh=2000x1125\" alt=\"\"></p><p>不过接下来你或许还会疑惑：既然bioProcessBackgroundJobs函数是负责执行任务的，<strong>那么哪个函数负责生成任务呢？</strong></p><p>这就是下面，我要给你介绍的<strong>后台任务创建函数bioCreateBackgroundJob</strong>。</p><h3>bioCreateBackgroundJob函数：创建后台任务</h3><p>bioCreateBackgroundJob函数的原型如下，它会接收4个参数，其中，参数type表示该后台任务的类型，剩下来的3个参数，则对应了后台任务函数的参数，如下所示：</p><pre><code>void bioCreateBackgroundJob(int type, void *arg1, void *arg2, void *arg3)\n</code></pre><p>bioCreateBackgroundJob函数在执行时，会先创建bio_job，这是后台任务对应的数据结构。然后，后台任务数据结构中的参数，会被设置为bioCreateBackgroundJob函数传入的参数arg1、arg2和arg3。</p><p>最后，bioCreateBackgroundJob函数调用listAddNodeTail函数，将刚才创建的任务加入到对应的bio_jobs队列中，同时，将bio_pending数组的对应值加1，表示有个任务在等待执行。</p><pre><code>{\n    //创建新的任务\n    struct bio_job *job = zmalloc(sizeof(*job));\n    //设置任务数据结构中的参数\n    job-&gt;time = time(NULL);\n    job-&gt;arg1 = arg1;\n    job-&gt;arg2 = arg2;\n    job-&gt;arg3 = arg3;\n    pthread_mutex_lock(&amp;bio_mutex[type]);\n    listAddNodeTail(bio_jobs[type],job);  //将任务加到bio_jobs数组的对应任务列表中\n    bio_pending[type]++; //将对应任务列表上等待处理的任务个数加1\n    pthread_cond_signal(&amp;bio_newjob_cond[type]);\n    pthread_mutex_unlock(&amp;bio_mutex[type]);\n}\n</code></pre><p>好了，这样一来，当Redis进程想要启动一个后台任务时，只要调用bioCreateBackgroundJob函数，并设置好该任务对应的类型和参数即可。然后，bioCreateBackgroundJob函数就会把创建好的任务数据结构，放到后台任务对应的队列中。另一方面，bioInit函数在Redis server启动时，创建的线程会不断地轮询后台任务队列，一旦发现有任务可以执行，就会将该任务取出并执行。</p><p>其实，这种设计方式是典型的<strong>生产者-消费者模型</strong>。bioCreateBackgroundJob函数是生产者，负责往每种任务队列中加入要执行的后台任务，而bioProcessBackgroundJobs函数是消费者，负责从每种任务队列中取出任务来执行。然后Redis创建的后台线程，会调用bioProcessBackgroundJobs函数，从而实现一直循环检查任务队列。</p><p>下图展示的就是bioCreateBackgroundJob和bioProcessBackgroundJobs两者间的生产者-消费者模型，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/f5/ab/f5a7c20b6a826cf79c0675d11ea037ab.jpg?wh=2000x850\" alt=\"\"></p><p>好了，到这里，我们就学习了Redis后台线程的创建和运行机制。简单来说，主要是以下三个关键点：</p><ul>\n<li>Redis是先通过bioInit函数初始化和创建后台线程；</li>\n<li>后台线程运行的是bioProcessBackgroundJobs函数，这个函数会轮询任务队列，并根据要处理的任务类型，调用相应函数进行处理；</li>\n<li>后台线程要处理的任务是由bioCreateBackgroundJob函数来创建的，这些任务创建后会被放到任务队列中，等待bioProcessBackgroundJobs函数处理。</li>\n</ul><h2>小结</h2><p>今天这节课，我给你介绍了Redis的执行模型，并且也从源码的角度出发，通过分析代码，带你了解了Redis进程创建、以子进程方式创建的守护进程、以及后台线程和它们负责的工作任务。同时，这也解答了你在面试中可能经常会被问到的问题：<strong>Redis是单线程程序吗？</strong></p><p>事实上，Redis server启动后，它的主要工作包括接收客户端请求、解析请求和进行数据读写等操作，是由单线程来执行的，这也是我们常说Redis是单线程程序的原因。</p><p>但是，学完这节课你应该也知道，Redis还启动了3个线程来执行文件关闭、AOF同步写和惰性删除等操作，从这个角度来说，Redis又不能算单线程程序，它还是有多线程的。而且，在下节课，我会给你介绍Redis 6.0中多IO线程的实现，从多IO线程角度看，Redis也无法称为是单线程程序了。</p><p>另外学完了这节课之后，你还需要重点注意下，fork函数使用和生产者-消费者模型这两个关键知识点。</p><p><strong>首先是fork函数的使用</strong>。fork函数可以在一个进程运行时，再创建一个子进程。当Redis被配置为以守护进程方式运行时，Redis的main函数就是调用fork函数，创建子进程，让子进程以守护进程形式执行，并让一开始启动执行的父进程退出。因为，子进程会从父进程那继承代码，所以main函数中的执行逻辑就交给了子进程继续执行。</p><p><strong>其次是生产者-消费者模型</strong>。Redis在bio.c和bio.h文件中创建了后台线程，并实现了后台任务的执行。你要重点关注一下这里使用的生产者-消费者执行模型，这也是bio.c实现后台任务执行的核心设计思想。而且，当你需要实现异步的任务执行时，生产者-消费者模型就是一个很好的解决方案，你可以从Redis源码中掌握这个方案的实现思路。</p><h2>每课一问</h2><p>Redis后台任务使用bio_job结构体来描述，该结构体用了三个指针变量来表示任务参数，如下所示。如果我们创建的任务，所需要的参数大于3个，你有什么应对方法来传参么？</p><pre><code>struct bio_job {\n    time_t time;\n    void *arg1, *arg2, *arg3;  //传递给任务的参数\n};\n</code></pre><p>欢迎在留言区分享你的答案和思考过程，如果觉得有收获，也欢迎你把今天的内容分享给更多的朋友。</p>","neighbors":{"left":{"article_title":"11 | Redis事件驱动框架（下）：Redis有哪些事件？","id":408857},"right":{"article_title":"13 | Redis 6.0多IO线程的效率提高了吗？","id":410666}}},{"article_id":410666,"article_title":"13 | Redis 6.0多IO线程的效率提高了吗？","article_content":"<p>你好，我是蒋德钧。</p><p>通过上节课的学习，我们知道Redis server启动后的进程会以单线程的方式，执行客户端请求解析和处理工作。但是，Redis server也会通过bioInit函数启动三个后台线程，来处理后台任务。也就是说，Redis不再让主线程执行一些耗时操作，比如同步写、删除等，而是交给后台线程异步完成，从而避免了对主线程的阻塞。</p><p>实际上，在2020年5月推出的Redis 6.0版本中，Redis在执行模型中还进一步使用了多线程来处理IO任务，这样设计的目的，就是为了充分利用当前服务器的多核特性，使用多核运行多线程，让多线程帮助加速数据读取、命令解析以及数据写回的速度，提升Redis整体性能。</p><p><strong>那么，这些多线程具体是在什么时候启动，又是通过什么方式来处理IO请求的呢？</strong></p><p>今天这节课，我就来给你介绍下Redis 6.0实现的多IO线程机制。通过这部分内容的学习，你可以充分了解到Redis 6.0是如何通过多线程来提升IO请求处理效率的。这样你也就可以结合实际业务来评估，自己是否需要使用Redis 6.0了。</p><p>好，接下来，我们先来看下多IO线程的初始化。注意，因为我们之前课程中阅读的是Redis 5.0.8版本的代码，所以在开始学习今天的课程之前，你还需要下载<a href=\"https://github.com/redis/redis/tree/6.0\">Redis 6.0.15</a>的源码，以便能查看到和多IO线程机制相关的代码。</p><!-- [[[read_end]]] --><h2>多IO线程的初始化</h2><p>我在上一讲给你介绍过，Redis 5.0中的三个后台线程，是server在初始化过程的最后，调用InitSeverLast函数，而InitServerLast函数再进一步调用bioInit函数来完成的。如果我们在Redis 6.0中查看InitServerLast函数，会发现和Redis 5.0相比，该函数在调完bioInit函数后，又调用了<strong>initThreadedIO函数</strong>。而initThreadedIO函数正是用来初始化多IO线程的，这部分的代码调用如下所示：</p><pre><code>void InitServerLast() {\n    bioInit();\n    initThreadedIO();  //调用initThreadedIO函数初始化IO线程\n    set_jemalloc_bg_thread(server.jemalloc_bg_thread);\n    server.initial_memory_usage = zmalloc_used_memory();\n}\n</code></pre><p>所以下面，我们就来看下initThreadedIO函数的主要执行流程，这个函数是在<a href=\"http://github.com/redis/redis/tree/5.0/src/networking.c\">networking.c</a>文件中实现的。</p><p><strong>首先，initThreadedIO函数会设置IO线程的激活标志。</strong>这个激活标志保存在redisServer结构体类型的全局变量server当中，对应redisServer结构体的成员变量io_threads_active。initThreadedIO函数会把io_threads_active初始化为0，表示IO线程还没有被激活。这部分代码如下所示：</p><pre><code>void initThreadedIO(void) {\n\tserver.io_threads_active = 0;\n\t…\n}\n</code></pre><p>这里，你要注意一下，刚才提到的<strong>全局变量server</strong>是Redis server运行时，用来保存各种全局信息的结构体变量。我在<a href=\"https://time.geekbang.org/column/article/406556\">第8讲</a>给你介绍Redis server初始化过程的时候，提到过Redis server的各种参数初始化配置，都是保存在这个全局变量server中的。所以，当你在阅读Redis源码时，如果在某个函数中看到变量server，要知道其实就是这个全局变量。</p><p><strong>紧接着，initThreadedIO函数会对设置的IO线程数量进行判断。</strong>这个数量就是保存在全局变量server的成员变量io_threads_num中的。那么在这里，IO线程的数量判断会有三种结果。</p><p>第一种，如果IO线程数量为1，就表示只有1个主IO线程，initThreadedIO函数就直接返回了。此时，Redis server的IO线程和Redis 6.0之前的版本是相同的。</p><pre><code>if (server.io_threads_num == 1) return;\n</code></pre><p>第二种，如果IO线程数量大于宏定义IO_THREADS_MAX_NUM（默认值为128），那么initThreadedIO函数会报错，并退出整个程序。</p><pre><code>if (server.io_threads_num &gt; IO_THREADS_MAX_NUM) {\n        …  //报错日志记录\n        exit(1);  //退出程序\n }\n</code></pre><p>第三种，如果IO线程数量大于1，并且小于宏定义IO_THREADS_MAX_NUM，那么，initThreadedIO函数会执行一个循环流程，该流程的循环次数就是设置的IO线程数量。</p><p>如此一来，在该循环流程中，initThreadedIO函数就会给以下四个数组进行初始化操作。</p><ul>\n<li><strong>io_threads_list数组</strong>：保存了每个IO线程要处理的客户端，将数组每个元素初始化为一个List类型的列表；</li>\n<li><strong>io_threads_pending数组</strong>：保存等待每个IO线程处理的客户端个数；</li>\n<li><strong>io_threads_mutex数组</strong>：保存线程互斥锁；</li>\n<li><strong>io_threads数组</strong>：保存每个IO线程的描述符。</li>\n</ul><p>这四个数组的定义都在networking.c文件中，如下所示：</p><pre><code>pthread_t io_threads[IO_THREADS_MAX_NUM];   //记录线程描述符的数组\npthread_mutex_t io_threads_mutex[IO_THREADS_MAX_NUM];  //记录线程互斥锁的数组\n_Atomic unsigned long io_threads_pending[IO_THREADS_MAX_NUM];  //记录线程待处理的客户端个数\nlist *io_threads_list[IO_THREADS_MAX_NUM];  //记录线程对应处理的客户端\n</code></pre><p>然后，在对这些数组进行初始化的同时，initThreadedIO函数还会根据IO线程数量，<strong>调用pthread_create函数创建相应数量的线程</strong>。我在上节课给你介绍过，pthread_create函数的参数包括创建线程要运行的函数和函数参数（*tidp、*attr、*start_routine、*arg）。</p><p>所以，对于initThreadedIO函数来说，它创建的线程要运行的函数是<strong>IOThreadMain</strong>，参数是当前创建线程的编号。不过要注意的是，这个编号是从1开始的，编号为0的线程其实是运行Redis server主流程的主IO线程。</p><p>以下代码就展示了initThreadedIO函数对数组的初始化，以及创建IO线程的过程，你可以看下。</p><pre><code>for (int i = 0; i &lt; server.io_threads_num; i++) {\n \n        io_threads_list[i] = listCreate();\n        if (i == 0) continue; //编号为0的线程是主IO线程\n \n        pthread_t tid;\n        pthread_mutex_init(&amp;io_threads_mutex[i],NULL);  //初始化io_threads_mutex数组\n        io_threads_pending[i] = 0;   //初始化io_threads_pending数组\n        pthread_mutex_lock(&amp;io_threads_mutex[i]);\n        //调用pthread_create函数创建IO线程，线程运行函数为IOThreadMain\n        if (pthread_create(&amp;tid,NULL,IOThreadMain,(void*)(long)i) != 0) {\n            … //出错处理\n        }\n        io_threads[i] = tid;  //初始化io_threads数组，设置值为线程标识\n    }\n</code></pre><p>好了，现在我们再来看下，刚才介绍的IO线程启动后要运行的函数IOThreadMain。了解这个函数，可以帮助我们掌握IO线程实际做的工作。</p><h2>IO线程的运行函数IOThreadMain</h2><p>IOThreadMain函数也是在networking.c文件中定义的，它的主要执行逻辑是一个<strong>while(1)循环</strong>。在这个循环中，IOThreadMain函数会把io_threads_list数组中，每个IO线程对应的列表读取出来。</p><p>就像我在前面给你介绍的一样，io_threads_list数组中会针对每个IO线程，使用一个列表记录该线程要处理的客户端。所以，IOThreadMain函数就会从每个IO线程对应的列表中，进一步取出要处理的客户端，然后判断线程要执行的操作标记。这个操作标记是用变量io_threads_op表示的，它有两种取值。</p><ul>\n<li><strong>io_threads_op的值为宏定义IO_THREADS_OP_WRITE</strong>：这表明该IO线程要做的是写操作，线程会调用writeToClient函数将数据写回客户端。</li>\n<li><strong>io_threads_op的值为宏定义IO_THREADS_OP_READ</strong>：这表明该IO线程要做的是读操作，线程会调用readQueryFromClient函数从客户端读取数据。</li>\n</ul><p>这部分的代码逻辑你可以看看下面的代码。</p><pre><code>void *IOThreadMain(void *myid) {\n…\nwhile(1) {\n   listIter li;\n   listNode *ln;\n   //获取IO线程要处理的客户端列表\n   listRewind(io_threads_list[id],&amp;li);\n   while((ln = listNext(&amp;li))) {\n      client *c = listNodeValue(ln); //从客户端列表中获取一个客户端\n      if (io_threads_op == IO_THREADS_OP_WRITE) {\n         writeToClient(c,0);  //如果线程操作是写操作，则调用writeToClient将数据写回客户端\n       } else if (io_threads_op == IO_THREADS_OP_READ) {\n          readQueryFromClient(c-&gt;conn); //如果线程操作是读操作，则调用readQueryFromClient从客户端读取数据\n       } else {\n          serverPanic(&quot;io_threads_op value is unknown&quot;);\n       }\n   }\n   listEmpty(io_threads_list[id]); //处理完所有客户端后，清空该线程的客户端列表\n   io_threads_pending[id] = 0; //将该线程的待处理任务数量设置为0\n \n   }\n}\n</code></pre><p>我也画了下面这张图，展示了IOThreadMain函数的基本流程，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/03/5a/03232ff01d8b0fca4af0981b7097495a.jpg?wh=2000x1125\" alt=\"\"></p><p>好了，到这里你应该就了解了，每一个IO线程运行时，都会不断检查是否有等待它处理的客户端。如果有，就根据操作类型，从客户端读取数据或是将数据写回客户端。你可以看到，这些操作都是Redis要和客户端完成的IO操作，所以，这也是为什么我们把这些线程称为IO线程的原因。</p><p>那么，你看到这里，可能也会产生一些疑问，<strong>IO线程要处理的客户端是如何添加到io_threads_list数组中的呢？</strong></p><p>这就要说到Redis server对应的全局变量server了。server变量中有两个List类型的成员变量：clients_pending_write和clients_pending_read，它们分别记录了待写回数据的客户端和待读取数据的客户端，如下所示：</p><pre><code>struct redisServer {\n...\nlist *clients_pending_write;  //待写回数据的客户端\nlist *clients_pending_read;  //待读取数据的客户端\n...\n}\n</code></pre><p>你要知道，Redis server在接收到客户端请求和给客户端返回数据的过程中，会根据一定条件，推迟客户端的读写操作，并分别把待读写的客户端保存到这两个列表中。然后，Redis server在每次进入事件循环前，会再把列表中的客户端添加到io_threads_list数组中，交给IO线程进行处理。</p><p>所以接下来，我们就先来看下，Redis是如何推迟客户端的读写操作，并把这些客户端添加到clients_pending_write和clients_pending_read这两个列表中的。</p><h2>如何推迟客户端读操作？</h2><p>Redis server在和一个客户端建立连接后，就会开始监听这个客户端上的可读事件，而处理可读事件的回调函数是<strong>readQueryFromClient</strong>。我在<a href=\"https://time.geekbang.org/column/article/408857\">第11讲</a>中给你介绍了这个过程，你可以再去回顾下。</p><p>那么这里，我们再来看下Redis 6.0版本中的readQueryFromClient函数。这个函数一开始会先从传入参数conn中获取客户端c，紧接着就调用postponeClientRead函数，来判断是否推迟从客户端读取数据。这部分的执行逻辑如下所示：</p><pre><code>void readQueryFromClient(connection *conn) {\n    client *c = connGetPrivateData(conn);  //从连接数据结构中获取客户\n    ...\n    if (postponeClientRead(c)) return;  //判断是否推迟从客户端读取数据\n    ...\n}\n</code></pre><p>现在，我们就来看下<strong>postponeClientRead函数</strong>的执行逻辑。这个函数会根据四个条件判断能否推迟从客户端读取数据。</p><p><strong>条件一：全局变量server的io_threads_active值为1</strong></p><p>这表示多IO线程已经激活。我刚才说过，这个变量值在initThreadedIO函数中是会被初始化为0的，也就是说，多IO线程初始化后，默认还没有激活（我一会儿还会给你介绍这个变量值何时被设置为1）。</p><p><strong>条件二：全局变量server的io_threads_do_read值为1</strong></p><p>这表示多IO线程可以用于处理延后执行的客户端读操作。这个变量值是在Redis配置文件redis.conf中，通过配置项io-threads-do-reads设置的，默认值为no，也就是说，多IO线程机制默认并不会用于客户端读操作。所以，如果你想用多IO线程处理客户端读操作，就需要把io-threads-do-reads配置项设为yes。</p><p><strong>条件三：ProcessingEventsWhileBlocked变量值为0</strong></p><p>这表示processEventsWhileBlokced函数没有在执行。ProcessingEventsWhileBlocked是一个全局变量，它会在processEventsWhileBlokced函数执行时被设置为1，在processEventsWhileBlokced函数执行完成时被设置为0。</p><p>而processEventsWhileBlokced函数是在<a href=\"https://github.com/redis/redis/tree/5.0/src/networking.c\">networking.c</a>文件中实现的。当Redis在读取RDB文件或是AOF文件时，这个函数会被调用，用来处理事件驱动框架捕获到的事件。这样就避免了因读取RDB或AOF文件造成Redis阻塞，而无法及时处理事件的情况。所以，当processEventsWhileBlokced函数执行处理客户端可读事件时，这些客户端读操作是不会被推迟执行的。</p><p><strong>条件四：客户端现有标识不能有CLIENT_MASTER、CLIENT_SLAVE和CLIENT_PENDING_READ</strong></p><p>其中，CLIENT_MASTER和CLIENT_SLAVE标识分别表示客户端是用于主从复制的客户端，也就是说，这些客户端不会推迟读操作。CLIENT_PENDING_READ本身就表示一个客户端已经被设置为推迟读操作了，所以，对于已带有CLIENT_PENDING_READ标识的客户端，postponeClientRead函数就不会再推迟它的读操作了。</p><p>总之，只有前面这四个条件都满足了，postponeClientRead函数才会推迟当前客户端的读操作。具体来说，postponeClientRead函数会给该客户端设置CLIENT_PENDING_REA标识，并调用listAddNodeHead函数，把这个客户端添加到全局变量server的clients_pending_read列表中。</p><p>我把postponeClientRead函数的代码放在这里，你可以看下。</p><pre><code>int postponeClientRead(client *c) {\n    //判断IO线程是否激活，\n    if (server.io_threads_active &amp;&amp; server.io_threads_do_reads &amp;&amp;          \n         !ProcessingEventsWhileBlocked &amp;&amp;\n        !(c-&gt;flags &amp; (CLIENT_MASTER|CLIENT_SLAVE|CLIENT_PENDING_READ)))\n    {\n        c-&gt;flags |= CLIENT_PENDING_READ; //给客户端的flag添加CLIENT_PENDING_READ标记，表示推迟该客户端的读操作\n        listAddNodeHead(server.clients_pending_read,c); //将客户端添加到clients_pending_read列表中\n        return 1;\n    } else {\n        return 0;\n    }\n}\n</code></pre><p>好，现在你已经知道，Redis是在客户端读事件回调函数readQueryFromClient中，通过调用postponeClientRead函数来判断和推迟客户端读操作。下面，我再带你来看下Redis是如何推迟客户端写操作的。</p><h2>如何推迟客户端写操作？</h2><p>Redis在执行了客户端命令，要给客户端返回结果时，会调用<strong>addReply函数</strong>将待返回结果写入客户端输出缓冲区。</p><p>而在addReply函数的一开始，该函数会调用<strong>prepareClientToWrite函数</strong>，来判断是否推迟执行客户端写操作。下面代码展示了addReply函数对prepareClientToWrite函数的调用，你可以看下。</p><pre><code>void addReply(client *c, robj *obj) {\n    if (prepareClientToWrite(c) != C_OK) return;\n    ...\n}\n</code></pre><p>所以这里，我们继续来看下prepareClientToWrite函数。这个函数会根据客户端设置的标识进行一系列的判断。其中，该函数会调用<strong>clientHasPendingReplies函数</strong>，判断当前客户端是否还有留存在输出缓冲区中的数据等待写回。</p><p>如果没有的话，那么，prepareClientToWrite就会调用<strong>clientInstallWriteHandler函数</strong>，再进一步判断能否推迟该客户端写操作。下面的代码展示了这一调用过程，你可以看下。</p><pre><code>int prepareClientToWrite(client *c) {\n   ...\n   //如果当前客户端没有待写回数据，调用clientInstallWriteHandler函数\n   if (!clientHasPendingReplies(c)) clientInstallWriteHandler(c);\n   return C_OK;\n}\n</code></pre><p>那么这样一来，我们其实就知道了，能否推迟客户端写操作，最终是由clientInstallWriteHandler函数来决定的，这个函数会判断两个条件。</p><ul>\n<li><strong>条件一</strong>：客户端没有设置过CLIENT_PENDING_WRITE标识，即没有被推迟过执行写操作。</li>\n<li><strong>条件二</strong>：客户端所在实例没有进行主从复制，或者客户端所在实例是主从复制中的从节点，但全量复制的RDB文件已经传输完成，客户端可以接收请求。</li>\n</ul><p>一旦这两个条件都满足了，clientInstallWriteHandler函数就会把客户端标识设置为CLIENT_PENDING_WRITE，表示推迟该客户端的写操作。同时，clientInstallWriteHandler函数会把这个客户端添加到全局变量server的待写回客户端列表中，也就是clients_pending_write列表中。</p><pre><code>void clientInstallWriteHandler(client *c) {\n    //如果客户端没有设置过CLIENT_PENDING_WRITE标识，并且客户端没有在进行主从复制，或者客户端是主从复制中的从节点，已经能接收请求\n    if (!(c-&gt;flags &amp; CLIENT_PENDING_WRITE) &amp;&amp;\n        (c-&gt;replstate == REPL_STATE_NONE ||\n         (c-&gt;replstate == SLAVE_STATE_ONLINE &amp;&amp; !c-&gt;repl_put_online_on_ack)))\n    {\n        //将客户端的标识设置为待写回，即CLIENT_PENDING_WRITE\n        c-&gt;flags |= CLIENT_PENDING_WRITE;\n        listAddNodeHead(server.clients_pending_write,c);  //将可获得加入clients_pending_write列表\n    }\n}\n</code></pre><p>为了便于你更好地理解，我画了一张图，展示了Redis推迟客户端写操作的函数调用关系，你可以再回顾下。</p><p><img src=\"https://static001.geekbang.org/resource/image/67/50/672977e056fba83aba183f82600c6d50.jpg?wh=2000x949\" alt=\"\"></p><p>不过，当Redis使用clients_pending_read和clients_pending_write两个列表，保存了推迟执行的客户端后，<strong>这些客户端又是如何分配给多IO线程执行的呢？</strong>这就和下面两个函数相关了。</p><ul>\n<li>handleClientsWithPendingReadsUsingThreads函数：该函数主要负责将clients_pending_read列表中的客户端分配给IO线程进行处理。</li>\n<li>handleClientsWithPendingWritesUsingThreads函数：该函数主要负责将clients_pending_write列表中的客户端分配给IO线程进行处理。</li>\n</ul><p>所以接下来，我们就来看下这两个函数的具体操作。</p><h2>如何把待读客户端分配给IO线程执行？</h2><p>首先，我们来了解<strong>handleClientsWithPendingReadsUsingThreads函数</strong>。这个函数是在beforeSleep函数中调用的。</p><p>在Redis 6.0版本的代码中，事件驱动框架同样是调用aeMain函数来执行事件循环流程，该循环流程会调用aeProcessEvents函数处理各种事件。而在aeProcessEvents函数实际调用aeApiPoll函数捕获IO事件之前，beforeSleep函数会被调用。</p><p>这个过程如下图所示，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/b8/87/b823cf93b7dcyy10069136c4a5c78787.jpg?wh=2000x969\" alt=\"\"></p><p>handleClientsWithPendingReadsUsingThreads函数的主要执行逻辑可以分成四步。</p><p><strong>第一步</strong>，该函数会先根据全局变量server的io_threads_active成员变量，判定IO线程是否激活，并且根据server的io_threads_do_reads成员变量，判定用户是否设置了Redis可以用IO线程处理待读客户端。只有在IO线程激活，并且IO线程可以用于处理待读客户端时，handleClientsWithPendingReadsUsingThreads函数才会继续执行，否则该函数就直接结束返回了。这一步的判断逻辑如以下代码所示：</p><pre><code>if (!server.io_threads_active || !server.io_threads_do_reads) \nreturn 0;\n</code></pre><p><strong>第二步</strong>，handleClientsWithPendingReadsUsingThreads函数会获取clients_pending_read列表的长度，这代表了要处理的待读客户端个数。然后，该函数会从clients_pending_read列表中逐一取出待处理的客户端，并用客户端在列表中的序号，对IO线程数量进行取模运算。</p><p>这样一来，我们就可以根据取模得到的余数，把该客户端分配给对应的IO线程进行处理。紧接着，handleClientsWithPendingReadsUsingThreads函数会<strong>调用listAddNodeTail函数，把分配好的客户端添加到io_threads_list列表的相应元素中</strong>。我刚才给你介绍过，io_threads_list数组的每个元素是一个列表，对应保存了每个IO线程要处理的客户端。</p><p>为了便于你理解，我来给你举个例子。</p><p>假设IO线程数量设置为3，clients_pending_read列表中一共有5个待读客户端，它们在列表中的序号分别是0，1，2，3和4。在这一步中，0号到4号客户端对线程数量3取模的结果分别是0，1，2，0，1，这也对应了即将处理这些客户端的IO线程编号。这也就是说，0号客户端由0号线程处理，1号客户端有1号线程处理，以此类推。你可以看到，这个分配方式其实就是把待处理客户端，以<strong>轮询方式</strong>逐一分配给各个IO线程。</p><p>我画了下面这张图，展示了这个分配结果，你可以再看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/3e/cc/3ea75f26c5c1fb527e4ec99fe07a4ccc.jpg?wh=2000x790\" alt=\"\"></p><p>以下代码展示的就是以轮询方式将客户端分配给IO线程的执行逻辑：</p><pre><code>int processed = listLength(server.clients_pending_read);\nlistRewind(server.clients_pending_read,&amp;li);\nint item_id = 0;\nwhile((ln = listNext(&amp;li))) {\n        client *c = listNodeValue(ln);\n        int target_id = item_id % server.io_threads_num;\n        listAddNodeTail(io_threads_list[target_id],c);\n        item_id++;\n }\n</code></pre><p>这样，当handleClientsWithPendingReadsUsingThreads函数完成客户端的IO线程分配之后，它会将IO线程的操作标识设置为<strong>读操作</strong>，也就是IO_THREADS_OP_READ。然后，它会遍历io_threads_list数组中的每个元素列表长度，等待每个线程处理的客户端数量，赋值给 io_threads_pending数组。这一过程如下所示：</p><pre><code> io_threads_op = IO_THREADS_OP_READ;\n for (int j = 1; j &lt; server.io_threads_num; j++) {\n        int count = listLength(io_threads_list[j]);\n        io_threads_pending[j] = count;\n }\n</code></pre><p><strong>第三步</strong>，handleClientsWithPendingReadsUsingThreads函数会将io_threads_list数组0号列表（也就是io_threads_list[0]元素）中的待读客户端逐一取出来，并调用readQueryFromClient函数进行处理。</p><p>其实，handleClientsWithPendingReadsUsingThreads函数本身就是由IO主线程执行的，而io_threads_list数组对应的0号线程正是IO主线程，所以，这里就是让主IO线程来处理它的待读客户端。</p><pre><code>  listRewind(io_threads_list[0],&amp;li);  //获取0号列表中的所有客户端\n    while((ln = listNext(&amp;li))) {\n        client *c = listNodeValue(ln);\n        readQueryFromClient(c-&gt;conn);\n    }\n    listEmpty(io_threads_list[0]); //处理完后，清空0号列表\n</code></pre><p>紧接着，handleClientsWithPendingReadsUsingThreads函数会执行一个while(1)循环，等待所有IO线程完成待读客户端的处理，如下所示：</p><pre><code> while(1) {\n        unsigned long pending = 0;\n        for (int j = 1; j &lt; server.io_threads_num; j++)\n            pending += io_threads_pending[j];\n        if (pending == 0) break;\n    }\n</code></pre><p><strong>第四步</strong>，handleClientsWithPendingReadsUsingThreads函数会再次遍历一遍clients_pending_read列表，依次取出其中的客户端。紧接着，它会判断客户端的标识中是否有CLIENT_PENDING_COMMAND。如果有CLIENT_PENDING_COMMAND标识，表明该客户端中的命令已经被某一个IO线程解析过，已经可以被执行了。</p><p>此时，handleClientsWithPendingReadsUsingThreads函数会调用processCommandAndResetClient函数执行命令。最后，它会直接调用processInputBuffer函数解析客户端中所有命令并执行。</p><p>这部分的代码逻辑如下所示，你可以看下。</p><pre><code>while(listLength(server.clients_pending_read)) {\n        ln = listFirst(server.clients_pending_read);\n        client *c = listNodeValue(ln);\n        ...\n        //如果命令已经解析过，则执行该命令\n        if (c-&gt;flags &amp; CLIENT_PENDING_COMMAND) {\n            c-&gt;flags &amp;= ~CLIENT_PENDING_COMMAND;\n            if (processCommandAndResetClient(c) == C_ERR) {          \n                continue;\n            }\n        }\n        //解析并执行所有命令\n        processInputBuffer(c);\n}\n</code></pre><p>好了，到这里，你就了解了clients_pending_read列表中的待读客户端，是如何经过以上四个步骤来分配给IO线程进行处理的。下图展示了这个主要过程，你可以再回顾下。</p><p><img src=\"https://static001.geekbang.org/resource/image/1b/45/1b4bb7d5367d9184a9eacefbabfe3345.jpg?wh=2000x1125\" alt=\"\"></p><p>那么，接下来，我们再来看下待写客户端的分配和处理。</p><h2>如何把待写客户端分配给IO线程执行？</h2><p>和待读客户端的分配处理类似，待写客户端分配处理是由<strong>handleClientsWithPendingWritesUsingThreads函数</strong>来完成的。该函数也是在beforeSleep函数中被调用的。</p><p>handleClientsWithPendingWritesUsingThreads函数的主要流程同样也可以分成4步，其中，第2、3和4步的执行逻辑，和handleClientsWithPendingReadsUsingThreads函数类似。</p><p>简单来说，在第2步，handleClientsWithPendingWritesUsingThreads函数会把待写客户端，按照<strong>轮询方式</strong>分配给IO线程，添加到io_threads_list数组各元素中。</p><p>然后，在第3步，handleClientsWithPendingWritesUsingThreads函数会让主IO线程处理其待写客户端，并执行while(1)循环等待所有IO线程完成处理。</p><p>在第4步，handleClientsWithPendingWritesUsingThreads函数会再次检查clients_pending_write列表中，是否还有待写的客户端。如果有的话，并且这些客户端还有留存在缓冲区中的数据，那么，handleClientsWithPendingWritesUsingThreads函数就会调用connSetWriteHandler函数注册可写事件，而这个可写事件对应的回调函数是<strong>sendReplyToClient函数</strong>。</p><p>等到事件循环流程再次执行时，刚才handleClientsWithPendingWritesUsingThreads函数注册的可写事件就会被处理，紧接着sendReplyToClient函数会执行，它会直接调用writeToClient函数，把客户端缓冲区中的数据写回。</p><p>这里，<strong>你需要注意的是</strong>，connSetWriteHandler函数最终会映射为connSocketSetWriteHandler函数，而connSocketSetWriteHandler函数是在<a href=\"https://github.com/redis/redis/tree/5.0/src/connection.c\">connection.c</a>文件中实现的。connSocketSetWriteHandler函数会调用aeCreateFileEvent函数创建AE_WRITABLE事件，这就是刚才介绍的可写事件的注册（关于aeCreateFileEvent函数的使用，你也可以再回顾下第11讲）。</p><p>不过，和handleClientsWithPendingReadsUsingThreads函数不同的是在第1步，handleClientsWithPendingWritesUsingThreads函数，<strong>会判断IO线程数量是否为1，或者待写客户端数量是否小于IO线程数量的2倍。</strong></p><p>如果这两个条件中有一个条件成立，那么handleClientsWithPendingWritesUsingThreads函数就不会用多线程来处理客户端了，而是会调用handleClientsWithPendingWrites函数由主IO线程直接处理待写客户端。这样做的目的，主要是为了在待写客户端数量不多时，避免采用多线程，从而<strong>节省CPU开销</strong>。</p><p>这一步的条件判断逻辑如下所示。其中，stopThreadedIOIfNeeded函数主要是用来判断待写客户端数量，是否不足为IO线程数量的2倍。</p><pre><code>if (server.io_threads_num == 1 || stopThreadedIOIfNeeded()) {\n        return handleClientsWithPendingWrites();\n}\n</code></pre><p>另外，handleClientsWithPendingWritesUsingThreads函数在第1步中，还会<strong>判断IO线程是否已激活</strong>。如果没有激活，它就会调用startThreadedIO函数，把全局变量server的io_threads_active成员变量值设置为1，表示IO线程已激活。这步判断操作如下所示：</p><pre><code>if (!server.io_threads_active) startThreadedIO();\n</code></pre><p>总之你要知道的就是，Redis是通过handleClientsWithPendingWritesUsingThreads函数，把待写客户端按轮询方式分配给各个IO线程，并由它们来负责写回数据的。</p><h2>小结</h2><p>今天这节课，我给你介绍了Redis 6.0中新设计实现的<strong>多IO线程机制</strong>。这个机制的设计主要是为了使用多个IO线程，来并发处理客户端读取数据、解析命令和写回数据。使用了多线程后，Redis就可以充分利用服务器的多核特性，从而<strong>提高IO效率</strong>。</p><p>总结来说，Redis 6.0先是在初始化过程中，根据用户设置的IO线程数量，创建对应数量的IO线程。</p><p>当Redis server初始化完成后正常运行时，它会在readQueryFromClient函数中通过调用postponeClientRead函数来决定是否推迟客户端读操作。同时，Redis server会在addReply函数中通过调用prepareClientToWrite函数，来决定是否推迟客户端写操作。而待读写的客户端会被分别加入到clients_pending_read和clients_pending_write两个列表中。</p><p>这样，每当Redis server要进入事件循环流程前，都会在beforeSleep函数中分别调用handleClientsWithPendingReadsUsingThreads函数和handleClientsWithPendingWritesUsingThreads函数，将待读写客户端<strong>以轮询方式分配给IO线程</strong>，加入到IO线程的待处理客户端列表io_threads_list中。</p><p>而IO线程一旦运行后，本身会一直检测io_threads_list中的客户端，如果有待读写客户端，IO线程就会调用readQueryFromClient或writeToClient函数来进行处理。</p><p>最后，我也想再提醒你一下，<strong>多IO线程本身并不会执行命令</strong>，它们只是利用多核并行地读取数据和解析命令，或是将server数据写回（下节课我还会结合分布式锁的原子性保证，来给你介绍这一部分的源码实现。）。所以，<strong>Redis执行命令的线程还是主IO线程</strong>。这一点对于你理解多IO线程机制很重要，可以避免你误解Redis有多线程同时执行命令。</p><p>这样一来，我们原来针对Redis 单个主IO线程做的优化仍然有效，比如避免bigkey、避免阻塞操作等。</p><h2>每课一问</h2><p>Redis 多IO线程机制使用startThreadedIO函数和stopThreadedIO函数，来设置IO线程激活标识io_threads_active为1和为0。此处，这两个函数还会对线程互斥锁数组进行解锁和加锁操作，如下所示。你知道为什么这两个函数要执行解锁和加锁操作么？</p><pre><code>void startThreadedIO(void) {\n    ...\n    for (int j = 1; j &lt; server.io_threads_num; j++)\n        pthread_mutex_unlock(&amp;io_threads_mutex[j]);  //给互斥锁数组中每个线程对应的互斥锁做解锁操作\n    server.io_threads_active = 1;\n}\n\nvoid stopThreadedIO(void) {\n    ...\n    for (int j = 1; j &lt; server.io_threads_num; j++)\n        pthread_mutex_lock(&amp;io_threads_mutex[j]);  //给互斥锁数组中每个线程对应的互斥锁做加锁操作\n    server.io_threads_active = 0;\n}\n</code></pre><p>欢迎在留言区分享你的答案和思考过程，如果觉得有收获，也欢迎你把今天的内容分享给更多的朋友。</p>","neighbors":{"left":{"article_title":"12 | Redis真的是单线程吗？","id":409927},"right":{"article_title":"14 | 从代码实现看分布式锁的原子性保证","id":411558}}},{"article_id":411558,"article_title":"14 | 从代码实现看分布式锁的原子性保证","article_content":"<p>你好，我是蒋德钧。</p><p>分布式锁是Redis在实际业务场景中的一个重要应用。当有多个客户端并发访问某个共享资源时，比如要修改数据库中的某条记录，为了避免记录修改冲突，我们可以让所有客户端从Redis上获取分布式锁，只有拿到锁的客户端才能操作共享资源。</p><p>那么，对于分布式锁来说，它实现的关键就是要保证加锁和解锁两个操作是原子操作，这样才能保证多客户端访问时锁的正确性。而通过前面课程的学习，你知道Redis能通过事件驱动框架同时捕获多个客户端的可读事件，也就是命令请求。此外，在Redis 6.0版本中，多个IO线程会被用于并发地读取或写回数据。</p><p>而既然如此，你就可以来思考一个问题：<strong>分布式锁的原子性还能得到保证吗？</strong></p><p>今天这节课呢，我就带你来了解下一条命令在Redis server中的执行过程，然后结合分布式锁的要求，来带你看下命令执行的原子性是如何保证的。同时，我们再来看看在有IO多路复用和多IO线程的情况下，分布式锁的原子性是否会受到影响。</p><p>这样一来，你就既可以掌握客户端的一条命令是如何完成执行的，其原子性是如何得到保证的，而且还可以把之前学习到的知识点串接应用起来。要知道，了解客户端命令的执行过程，对于日常排查Redis问题也是非常有帮助的，你可以在命令执行的过程中加入检测点，以便分析和排查运行问题。</p><!-- [[[read_end]]] --><p>好，那么接下来，我们就先来了解下分布式锁的实现方法，这样就能知道分布式锁对应的实现命令，以便进行进一步分析。</p><h2>分布式锁的实现方法</h2><p>我们在第一季的课程中，有学习过<a href=\"https://time.geekbang.org/column/article/301092\">分布式锁的实现</a>，你可以再去回顾下。这里，我再来简要介绍下分布式锁的加锁和解锁实现的命令。</p><p>首先，对于分布式锁的<strong>加锁</strong>操作来说，我们可以使用<strong>Redis的SET命令</strong>。Redis SET命令提供了NX和EX选项，这两个选项的含义分别是：</p><ul>\n<li><strong>NX</strong>，表示当操作的key不存在时，Redis会直接创建；当操作的key已经存在了，则返回NULL值，Redis对key不做任何修改。</li>\n<li><strong>EX</strong>，表示设置key的过期时间。</li>\n</ul><p>因此，我们可以让客户端发送以下命令来进行加锁。其中，lockKey是锁的名称，uid是客户端可以用来唯一标记自己的ID，expireTime是这个key所代表的锁的过期时间，当这个过期时间到了之后，这个key会被删除，相当于锁被释放了，这样就避免了锁一直无法释放的问题。</p><pre><code>SET lockKey uid EX expireTime NX\n</code></pre><p>而如果还没有客户端创建过锁，那么，假设客户端A发送了这个SET命令给Redis，如下所示：</p><pre><code>SET stockLock 1033 EX 30 NX\n</code></pre><p>这样，Redis就会创建对应的key为stockLock，而键值对的value就是这个客户端的ID 1033。此时，假设有另一个客户端B也发送了SET命令，如下所示，表示要把key为stockLock的键值对值，改为客户端B的ID 2033，也就是要加锁。</p><pre><code>SET stockLock 2033 EX 30 NX\n</code></pre><p>由于使用了NX选项，如果stockLock的key已经存在了，客户端B就无法对其进行修改了，也就无法获得锁了，这样就实现了加锁的效果。</p><p>而对于<strong>解锁</strong>来说，我们可以使用如下的<strong>Lua脚本</strong>来完成，而Lua脚本会以EVAL命令的形式在Redis server中执行。客户端会使用GET命令读取锁对应key的value，并判断value是否等于客户端自身的ID。如果等于，就表明当前客户端正拿着锁，此时可以执行DEL命令删除key，也就是释放锁；如果value不等于客户端自身ID，那么该脚本会直接返回。</p><pre><code>if redis.call(&quot;get&quot;,lockKey) == uid then\n   return redis.call(&quot;del&quot;,lockKey)\nelse\n   return 0\nend\n</code></pre><p>这样一来，客户端就不会误删除别的客户端获得的锁了，从而保证了锁的安全性。</p><p>好，现在我们就了解了分布式锁的实现命令。那么在这里，我们需要搞明白的问题就是：无论是加锁的SET命令，还是解锁的Lua脚本和EVAL命令，在有IO多路复用时，会被同时执行吗？或者<strong>当我们使用了多IO线程后，会被多个线程同时执行吗？</strong></p><p>这就和Redis中命令的执行过程有关了。下面，我们就来了解下，一条命令在Redis是如何完成执行的。同时，我们还会学习到，IO多路复用引入的多个并发客户端，以及多IO线程是否会破坏命令的原子性。</p><h2>一条命令的处理过程</h2><p>现在我们知道，Redis server一旦和一个客户端建立连接后，就会在事件驱动框架中注册可读事件，这就对应了客户端的命令请求。而对于整个命令处理的过程来说，我认为主要可以分成四个阶段，它们分别对应了Redis源码中的不同函数。这里，我把它们对应的入口函数，也就是它们是从哪个函数开始进行执行的，罗列如下：</p><ul>\n<li>命令读取，对应readQueryFromClient函数；</li>\n<li>命令解析，对应processInputBufferAndReplicate函数；</li>\n<li>命令执行，对应processCommand函数；</li>\n<li>结果返回，对应addReply函数；</li>\n</ul><p>那么下面，我们就来分别看下这四个入口函数的基本流程，以及为了完成命令执行，它们内部的主要调用关系都是怎样的。</p><h3>命令读取阶段：readQueryFromClient函数</h3><p>首先，我们来了解下readQueryFromClient函数的基本流程。</p><p>readQueryFromClient函数会从客户端连接的socket中，读取最大为readlen长度的数据，readlen值大小是宏定义PROTO_IOBUF_LEN。该宏定义是在<a href=\"https://github.com/redis/redis/tree/5.0/src/server.h\">server.h</a>文件中定义的，默认值为16KB。</p><p>紧接着，readQueryFromClient函数会根据读取数据的情况，进行一些异常处理，比如数据读取失败或是客户端连接关闭等。此外，如果当前客户端是主从复制中的主节点，readQueryFromClient函数还会把读取的数据，追加到用于主从节点命令同步的缓冲区中。</p><p>最后，readQueryFromClient函数会调用processInputBufferAndReplicate函数，这就进入到了命令处理的下一个阶段，也就是命令解析阶段。</p><pre><code>void readQueryFromClient(aeEventLoop *el, int fd, void *privdata, int mask) {\n   ...\n   readlen = PROTO_IOBUF_LEN;  //从客户端socket中读取的数据长度，默认为16KB\n   ...\n   c-&gt;querybuf = sdsMakeRoomFor(c-&gt;querybuf, readlen);  //给缓冲区分配空间\n   nread = read(fd, c-&gt;querybuf+qblen, readlen);  //调用read从描述符为fd的客户端socket中读取数据\n    ...\n    processInputBufferAndReplicate(c);  //调用processInputBufferAndReplicate进一步处理读取内容\n}   \n</code></pre><p>我在下面画了张图，展示了readQueryFromClient函数的基本流程，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/da/12/da8d14b131cb3c82b88ce5c3dcf6df12.jpg?wh=2000x1125\" alt=\"\"></p><h3>命令解析阶段：processInputBufferAndReplicate函数</h3><p>processInputBufferAndReplicate函数（在<a href=\"http://github.com/redis/redis/tree/5.0/src/networking.c\">networking.c</a>文件中）会根据当前客户端是否有CLIENT_MASTER标记，来执行两个分支。</p><ul>\n<li><strong>分支一</strong></li>\n</ul><p>这个分支对应了<strong>客户端没有CLIENT_MASTER标记</strong>，也就是说当前客户端不属于主从复制中的主节点。那么，processInputBufferAndReplicate函数会直接调用processInputBuffer（在networking.c文件中）函数，对客户端输入缓冲区中的命令和参数进行解析。所以在这里，实际执行命令解析的函数就是processInputBuffer函数。我们一会儿来具体看下这个函数。</p><ul>\n<li><strong>分支二</strong></li>\n</ul><p>这个分支对应了<strong>客户端有CLIENT_MASTER标记</strong>，也就是说当前客户端属于主从复制中的主节点。那么，processInputBufferAndReplicate函数除了调用processInputBuffer函数，解析客户端命令以外，它还会调用replicationFeedSlavesFromMasterStream函数（在<a href=\"https://github.com/redis/redis/tree/5.0/src/replication.c\">replication.c</a>文件中），将主节点接收到的命令同步给从节点。</p><p>下图就展示了processInputBufferAndReplicate函数的基本执行逻辑，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/b0/0b/b051c8659de6fd532fa90f20555ddc0b.jpg?wh=2000x949\" alt=\"\"></p><p>好了，我们刚才了解了，<strong>命令解析实际是在processInputBuffer函数中执行的</strong>，所以下面，我们还需要清楚这个函数的基本流程是什么样的。</p><p>首先，processInputBuffer函数会执行一个while循环，不断地从客户端的输入缓冲区中读取数据。然后，它会<strong>判断读取到的命令格式，是否以“*”开头</strong>。</p><p>如果命令是以“*”开头，那就表明这个命令是PROTO_REQ_MULTIBULK类型的命令请求，也就是符合RESP协议（Redis客户端与服务器端的标准通信协议）的请求。那么，processInputBuffer函数就会进一步调用processMultibulkBuffer（在networking.c文件中）函数，来解析读取到的命令。</p><p>而如果命令不是以“*”开头，那则表明这个命令是PROTO_REQ_INLINE类型的命令请求，并不是RESP协议请求。这类命令也被称为<strong>管道命令</strong>，命令和命令之间是使用换行符“\\r\\n”分隔开来的。比如，我们使用Telnet发送给Redis的命令，就是属于PROTO_REQ_INLINE类型的命令。在这种情况下，processInputBuffer函数会调用processInlineBuffer（在networking.c文件中）函数，来实际解析命令。</p><p>这样，等命令解析完成后，processInputBuffer函数就会调用processCommand函数，开始进入命令处理的第三个阶段，也就是命令执行阶段。</p><p>下面的代码展示了processInputBuffer函数解析命令时的主要流程，你可以看下。</p><pre><code>void processInputBuffer(client *c) {\n   while(c-&gt;qb_pos &lt; sdslen(c-&gt;querybuf)) {\n      ...\n       if (!c-&gt;reqtype) {\n            //根据客户端输入缓冲区的命令开头字符判断命令类型\n            if (c-&gt;querybuf[c-&gt;qb_pos] == '*') {\n                c-&gt;reqtype = PROTO_REQ_MULTIBULK; //符合RESP协议的命令\n            } else {\n                c-&gt;reqtype = PROTO_REQ_INLINE; //管道类型命令\n            }\n        }\n        if (c-&gt;reqtype == PROTO_REQ_INLINE) {\n            if (processInlineBuffer(c) != C_OK) break;  //对于管道类型命令，调用processInlineBuffer函数解析\n        } else if (c-&gt;reqtype == PROTO_REQ_MULTIBULK) {\n            if (processMultibulkBuffer(c) != C_OK) break; //对于RESP协议命令，调用processMultibulkBuffer函数解析\n        }\n        ... \n       if (c-&gt;argc == 0) {\n            resetClient(c);\n        } else {\n            //调用processCommand函数，开始执行命令\n            if (processCommand(c) == C_OK) {\n               ...   } \n            ... }\n        }\n        ...\n}\n</code></pre><p>下图展示了processInputBuffer函数的基本执行流程，你可以再回顾下。</p><p><img src=\"https://static001.geekbang.org/resource/image/59/f8/59e07442a5f5531f3859a1af43b148f8.jpg?wh=2000x1125\" alt=\"\"></p><p>好，那么下面，我们接着来看第三个阶段，也就是命令执行阶段的processCommand函数的基本处理流程。</p><h3>命令执行阶段：processCommand函数</h3><p>首先，我们要知道，processCommand函数是在<a href=\"http://github.com/redis/redis/tree/5.0/src/server.c\">server.c</a>文件中实现的。它在实际执行命令前的主要逻辑可以分成三步：</p><ul>\n<li>第一步，processCommand函数会调用moduleCallCommandFilters函数（在<a href=\"http://github.com/redis/redis/tree/5.0/src/module.c\">module.c</a>文件），将Redis命令替换成module中想要替换的命令。</li>\n<li>第二步，processCommand函数会判断当前命令是否为quit命令，并进行相应处理。</li>\n<li>第三步，processCommand函数会调用lookupCommand函数，在全局变量server的commands成员变量中查找相关的命令。</li>\n</ul><p>这里，你需要注意下，全局变量server的<strong>commands成员变量是一个哈希表</strong>，它的定义是在<a href=\"http://github.com/redis/redis/tree/5.0/src/server.h\">server.h</a>文件中的redisServer结构体里面，如下所示：</p><pre><code>struct redisServer {\n   ...\n   dict *commands; \n   ...\n}\n</code></pre><p>另外，commands成员变量的初始化是在initServerConfig函数中，通过调用dictCreate函数完成哈希表创建，再通过调用populateCommandTable函数，将Redis提供的命令名称和对应的实现函数，插入到哈希表中的。</p><pre><code>void initServerConfig(void) {\n...\nserver.commands = dictCreate(&amp;commandTableDictType,NULL);\n...\npopulateCommandTable();\n...\n}\n</code></pre><p>而这其中的populateCommandTable函数，实际上是使用到了redisCommand结构体数组redisCommandTable。</p><p><strong>redisCommandTable数组</strong>是在server.c文件中定义的，它的每一个元素是一个redisCommand结构体类型的记录，对应了Redis实现的一条命令。也就是说，redisCommand结构体中就记录了当前命令所对应的实现函数是什么。</p><p>比如，以下代码展示了GET和SET这两条命令的信息，它们各自的实现函数分别是getCommand和setCommand。当然，如果你想进一步了解redisCommand结构体，也可以去看下它的定义，在server.h文件当中。</p><pre><code>struct redisCommand redisCommandTable[] = {\n    ...\n    {&quot;get&quot;,getCommand,2,&quot;rF&quot;,0,NULL,1,1,1,0,0},\n    {&quot;set&quot;,setCommand,-3,&quot;wm&quot;,0,NULL,1,1,1,0,0},\n    ...\n}\n</code></pre><p>好了，到这里，你就了解了lookupCommand函数会根据解析的命令名称，在commands对应的哈希表中查找相应的命令。</p><p>那么，一旦查到对应命令后，processCommand函数就会进行多种检查，比如命令的参数是否有效、发送命令的用户是否进行过验证、当前内存的使用情况，等等。这部分的处理逻辑比较多，你可以进一步阅读processCommand函数来了解下。</p><p>这样，等到processCommand函数对命令做完各种检查后，它就开始执行命令了。<strong>它会判断当前客户端是否有CLIENT_MULTI标记</strong>，如果有的话，就表明要处理的是Redis事务的相关命令，所以它会按照事务的要求，调用queueMultiCommand函数将命令入队保存，等待后续一起处理。</p><p>而如果没有，processCommand函数就会调用call函数来实际执行命令了。以下代码展示了这部分的逻辑，你可以看下。</p><pre><code>//如果客户端有CLIENT_MULTI标记，并且当前不是exec、discard、multi和watch命令\nif (c-&gt;flags &amp; CLIENT_MULTI &amp;&amp;\n        c-&gt;cmd-&gt;proc != execCommand &amp;&amp; c-&gt;cmd-&gt;proc != discardCommand &amp;&amp;\n        c-&gt;cmd-&gt;proc != multiCommand &amp;&amp; c-&gt;cmd-&gt;proc != watchCommand)\n    {\n        queueMultiCommand(c);  //将命令入队保存，等待后续一起处理\n        addReply(c,shared.queued);\n    } else {\n        call(c,CMD_CALL_FULL);  //调用call函数执行命令\n        ...\n    }\n</code></pre><p>这里你要知道，call函数是在server.c文件中实现的，它执行命令是通过调用命令本身，即redisCommand结构体中定义的函数指针来完成的。而就像我刚才所说的，每个redisCommand结构体中都定义了它对应的实现函数，在redisCommandTable数组中能查找到。</p><p>因为分布式锁的加锁操作就是使用SET命令来实现的，所以这里，我就以SET命令为例来介绍下它的实际执行过程。</p><p>SET命令对应的实现函数是<strong>setCommand</strong>，这是在<a href=\"http://github.com/redis/redis/tree/5.0/src/t_string.c\">t_string.c</a>文件中定义的。setCommand函数首先会对命令参数进行判断，比如参数是否带有NX、EX、XX、PX等这类命令选项，如果有的话，setCommand函数就会记录下这些标记。</p><p>然后，setCommand函数会调用setGenericCommand函数，这个函数也是在t_string.c文件中实现的。setGenericCommand函数会根据刚才setCommand函数记录的命令参数的标记，来进行相应处理。比如，如果命令参数中有NX选项，那么，setGenericCommand函数会调用lookupKeyWrite函数（在<a href=\"http://github.com/redis/redis/tree/5.0/src/db.c\">db.c</a>文件中），查找要执行SET命令的key是否已经存在。</p><p>如果这个key已经存在了，那么setGenericCommand函数就会调用addReply函数，返回NULL空值，而这也正是符合分布式锁的语义的。</p><p>下面的代码就展示了这个执行逻辑，你可以看下。</p><pre><code>//如果有NX选项，那么查找key是否已经存在\nif ((flags &amp; OBJ_SET_NX &amp;&amp; lookupKeyWrite(c-&gt;db,key) != NULL) ||\n        (flags &amp; OBJ_SET_XX &amp;&amp; lookupKeyWrite(c-&gt;db,key) == NULL))\n    {\n        addReply(c, abort_reply ? abort_reply : shared.nullbulk);  //如果已经存在，则返回空值\n        return;\n    }\n</code></pre><p>好，那么如果SET命令可以正常执行的话，也就是说命令带有NX选项但是key并不存在，或者带有XX选项但是key已经存在，这样setGenericCommand函数就会调用setKey函数（在db.c文件中）来完成键值对的实际插入，如下所示：</p><pre><code>setKey(c-&gt;db,key,val);\n</code></pre><p>然后，如果命令设置了过期时间，setGenericCommand函数还会调用setExpire函数设置过期时间。最后，setGenericCommand函数会<strong>调用addReply函数，将结果返回给客户端</strong>，如下所示：</p><pre><code>addReply(c, ok_reply ? ok_reply : shared.ok);\n</code></pre><p>好了，到这里，SET命令的执行就结束了，你也可以再看下下面的基本流程图。</p><p><img src=\"https://static001.geekbang.org/resource/image/b3/2a/b35026e984a057ef9968afe8dafc9c2a.jpg?wh=2000x1125\" alt=\"\"></p><p>而且你也可以看到，无论是在命令执行的过程中，发现不符合命令的执行条件，或是命令能成功执行，addReply函数都会被调用，用来返回结果。所以，这就进入到我所说的命令处理过程的最后一个阶段：结果返回阶段。</p><h3>结果返回阶段：addReply函数</h3><p>addReply函数是在networking.c文件中定义的。它的执行逻辑比较简单，主要是调用prepareClientToWrite函数，并在prepareClientToWrite函数中调用clientInstallWriteHandler函数，将待写回客户端加入到全局变量server的clients_pending_write列表中。</p><p>然后，addReply函数会调用_addReplyToBuffer等函数（在networking.c中），将要返回的结果添加到客户端的输出缓冲区中。</p><p>好，现在你就了解一条命令是如何从读取，经过解析、执行等步骤，最终将结果返回给客户端的了。下图展示了这个过程以及涉及的主要函数，你可以再回顾下。</p><p><img src=\"https://static001.geekbang.org/resource/image/3c/39/3c784ab5359bdd8ac4fc34a8a3e9a839.jpg?wh=2000x1125\" alt=\"\"></p><p>不过除此之外，你还需要注意一点，就是如果在前面的命令处理过程中，都是由IO主线程处理的，那么命令执行的原子性肯定能得到保证，分布式锁的原子性也就相应能得到保证了。</p><p>但是，如果这个处理过程配合上了我们前面介绍的IO多路复用机制和多IO线程机制，那么，这两个机制是在这个过程的什么阶段发挥作用的呢，以及会不会影响命令执行的原子性呢？</p><p>所以接下来，我们就来看下它们各自对原子性保证的影响。</p><h2>IO多路复用对命令原子性保证的影响</h2><p>首先你要知道，<strong>IO多路复用机制是在readQueryFromClient函数执行前发挥作用的</strong>。它实际是在事件驱动框架中调用aeApiPoll函数，获取一批已经就绪的socket描述符。然后执行一个循环，针对每个就绪描述符上的读事件，触发执行readQueryFromClient函数。</p><p>这样一来，即使IO多路复用机制同时获取了多个就绪socket描述符，在实际处理时，Redis的主线程仍然是针对每个事件逐一调用回调函数进行处理的。而且对于写事件来说，IO多路复用机制也是针对每个事件逐一处理的。</p><p>下面的代码展示了IO多路复用机制通过aeApiPoll函数获取一批事件，然后逐一处理的逻辑，你可以再看下。</p><pre><code>numevents = aeApiPoll(eventLoop, tvp);\n\nfor (j = 0; j &lt; numevents; j++) {\n   aeFileEvent *fe = &amp;eventLoop-&gt;events[eventLoop-&gt;fired[j].fd];\n   if (!invert &amp;&amp; fe-&gt;mask &amp; mask &amp; AE_READABLE) {\n                fe-&gt;rfileProc(eventLoop,fd,fe-&gt;clientData,mask);\n                fired++;\n   }\n</code></pre><p>所以这也就是说，<strong>即使使用了IO多路复用机制，命令的整个处理过程仍然可以由IO主线程来完成，也仍然可以保证命令执行的原子性。</strong>下图就展示了IO多路复用机制和命令处理过程的关系，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/24/1a/24744c89c31c2ee3eyy37fd69f67661a.jpg?wh=2000x1125\" alt=\"\"></p><p>接下来，我们再来看下多IO线程对命令原子性保证的影响。</p><h2>多IO线程对命令原子性保证的影响</h2><p>我们知道，多IO线程可以执行读操作或是写操作。那么，对于读操作来说，readQueryFromClient函数会在执行过程中，调用postponeClient将待读客户端加入clients_pending_read等待列表。这个过程你可以再回顾下<a href=\"https://time.geekbang.org/column/article/410666\">第13讲</a>。</p><p>然后，待读客户端会被分配给多IO线程执行，每个IO线程执行的函数就是readQueryFromClient函数，readQueryFromClient函数会读取命令，并进一步调用processInputBuffer函数解析命令，这个基本过程和Redis 6.0前的代码是一样的。</p><p>不过，相比于Redis 6.0前的代码，在Redis 6.0版本中，processInputBuffer函数中<strong>新增加了一个判断条件</strong>，也就是当客户端标识中有CLIENT_PENDING_READ的话，那么在解析完命令后，processInputBuffer函数只会把客户端标识改为CLIENT_PENDING_COMMAND，就退出命令解析的循环流程了。</p><p>此时，processInputBuffer函数只是解析了第一个命令，也并不会实际调用processCommand函数来执行命令，如下所示：</p><pre><code>void processInputBuffer(client *c) {\n    /* Keep processing while there is something in the input buffer */\n    while(c-&gt;qb_pos &lt; sdslen(c-&gt;querybuf)) {\n    ...\n   if (c-&gt;argc == 0) {\n            resetClient(c);\n        } else {\n            //如果客户端有CLIENT_PENDING_READ标识，将其改为CLIENT_PENDING_COMMAND，就退出循环，并不调用processCommandAndResetClient函数执行命令\n            if (c-&gt;flags &amp; CLIENT_PENDING_READ) {\n                c-&gt;flags |= CLIENT_PENDING_COMMAND;\n                break;\n            }\n            if (processCommandAndResetClient(c) == C_ERR) {\n                return;\n            }\n        }\n   }\n}\n</code></pre><p>这样，等到所有的IO线程都解析完了第一个命令后，IO主线程中执行的handleClientsWithPendingReadsUsingThreads函数，会再调用processCommandAndResetClient函数执行命令，以及调用processInputBuffer函数解析剩余命令，这部分的内容你也可以再回顾下第13讲。</p><p>所以现在，你就可以知道，<strong>即使使用了多IO线程，其实命令执行这一阶段也是由主IO线程来完成的，所有命令执行的原子性仍然可以得到保证</strong>，也就是说分布式锁的原子性也仍然可以得到保证。</p><p>我们再来看下写回数据的流程。</p><p>在这个阶段，addReply函数是将客户端写回操作推迟执行的，而此时Redis命令已经完成执行了，所以，即使有多个IO线程在同时将客户端数据写回，也只是把结果返回给客户端，并不影响命令在Redis server中的执行结果。也就是说，<strong>即使使用了多IO线程写回，Redis同样可以保证命令执行的原子性。</strong></p><p>下图展示了使用多IO线程机制后，命令处理过程各个阶段是由什么线程执行的，你可以再看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/7e/bb/7e5ba301bc334983e77206c52024cebb.jpg?wh=2000x1125\" alt=\"\"></p><h2>小结</h2><p>今天这节课我主要结合分布式锁的原子性保证需求，带你学习了Redis处理一条命令的整个过程。其中，你需要重点关注<strong>分布式锁实现的方法</strong>。</p><p>我们知道，加锁和解锁操作分别可以使用SET命令和Lua脚本与EVAL命令来完成。那么，分布式锁的原子性保证，就主要依赖SET和EVAL命令在Redis server中执行时的原子性保证了。</p><p>紧接着，我还带你具体剖析了下Redis中命令处理的整个过程。我把这个过程分成了四个阶段，分别是<strong>命令读取、命令解析、命令执行和结果返回</strong>。所以，你还需要了解这四个阶段中所执行函数的主要流程。</p><p>这四个阶段在Redis 6.0版本前都是由主IO线程来执行完成的。虽然Redis使用了IO多路复用机制，但是该机制只是一次性获取多个就绪的socket描述符，对应了多个发送命令请求的客户端。而Redis在主IO线程中，还是逐一来处理每个客户端上的命令的，所以命令执行的原子性依然可以得到保证。</p><p>而当使用了Redis 6.0版本后，命令处理过程中的读取、解析和结果写回，就由多个IO线程来处理了。不过你也不用担心，多个IO线程只是完成解析第一个读到的命令，命令的实际执行还是由主IO线程处理。当多个IO线程在并发写回结果时，命令就已经执行完了，不存在多IO线程冲突的问题。所以，使用了多IO线程后，命令执行的原子性仍然可以得到保证。</p><p>好，最后，我也想再说下我对多IO线程的看法。从今天课程介绍的内容中，你可以看到，<strong>多IO线程实际并不会加快命令的执行</strong>，而是只会将读取解析命令并行化执行，以及写回结果并行化执行，并且读取解析命令还是针对收到的第一条命令。实际上，这一设计考虑还是由于网络IO需要加速处理。那么，如果命令执行本身成为Redis运行时瓶颈了，你其实可以考虑使用Redis切片集群来提升处理效率。</p><h2>每课一问</h2><p>如果将命令处理过程中的命令执行也交给多IO线程执行，你觉得除了对原子性会有影响，还会有什么好处或是其他不好的影响吗？</p><p>欢迎在留言区分享你的答案和见解。如果觉得有收获，也欢迎你把今天的内容分享给更多的朋友。</p>","neighbors":{"left":{"article_title":"13 | Redis 6.0多IO线程的效率提高了吗？","id":410666},"right":{"article_title":"15 | 为什么LRU算法原理和代码实现不一样？","id":412164}}},{"article_id":412164,"article_title":"15 | 为什么LRU算法原理和代码实现不一样？","article_content":"<p>你好，我是蒋德钧。</p><p>从这节课开始，我们就进入了课程的第三个模块：缓存模块。在接下来的三节课当中，我会给你详细介绍LRU、LFU算法在Redis源码中的实现，以及Redis惰性删除对缓存的影响。</p><p>学习这部分内容，一方面可以让你掌握这些经典缓存算法在一个实际系统中该如何设计和实现；另一方面，你也可以学习到在计算机系统设计实现中的一个重要原则，也就是在进行系统设计开发的过程中，需要均衡算法复杂度和实现复杂度。另外，你还可以学习到缓存替换、惰性删除是如何释放Redis内存的。内存资源对Redis来说是非常宝贵的，所以掌握了这一点，你就可以有效减少Redis的内存使用问题了。</p><p>好，那么今天这节课呢，我们就先来学习下LRU算法在Redis中的实现。</p><h2>LRU算法的基本原理</h2><p>首先，我们需要理解LRU算法的基本原理。LRU算法就是指<strong>最近最少使用</strong>（Least Recently Used，LRU）算法，这是一个经典的缓存算法。</p><p>从基本原理上来说，LRU算法会使用一个链表来维护缓存中每一个数据的访问情况，并根据数据的实时访问，调整数据在链表中的位置，然后通过数据在链表中的位置，来表示数据是最近刚访问的，还是已经有一段时间没有访问了。</p><!-- [[[read_end]]] --><p>而具体来说，LRU算法会把链表的头部和尾部分别设置为MRU端和LRU端。其中，MRU是Most Recently Used的缩写，MRU端表示这里的数据是刚被访问的。而LRU端则表示，这里的数据是最近最少访问的数据。</p><p>我在第一季课程中曾介绍过<a href=\"https://time.geekbang.org/column/article/297270\">LRU算法的执行过程</a>，这里，我们来简要回顾下。LRU算法的执行，可以分成三种情况来掌握。</p><ul>\n<li><strong>情况一</strong>：当有新数据插入时，LRU算法会把该数据插入到链表头部，同时把原来链表头部的数据及其之后的数据，都向尾部移动一位。</li>\n<li><strong>情况二</strong>：当有数据刚被访问了一次之后，LRU算法就会把该数据从它在链表中的当前位置，移动到链表头部。同时，把从链表头部到它当前位置的其他数据，都向尾部移动一位。</li>\n<li><strong>情况三</strong>：当链表长度无法再容纳更多数据时，若再有新数据插入，LRU算法就会去除链表尾部的数据，这也相当于将数据从缓存中淘汰掉。</li>\n</ul><p>下图就展示了LRU算法执行过程的第二种情况，你可以看下。其中，链表长度为5，从链表头部到尾部保存的数据分别是5，33，9，10，8。假设数据9被访问了一次，那么9就会被移动到链表头部，同时，数据5和33都要向链表尾部移动一位。</p><p><img src=\"https://static001.geekbang.org/resource/image/4c/a4/4c248a9db073b56b11e05802eedd1ea4.jpg?wh=2000x1125\" alt=\"\"></p><p>所以你其实可以发现，如果要严格按照LRU算法的基本原理来实现的话，你需要在代码中实现如下内容：</p><ul>\n<li>要为Redis使用最大内存时，可容纳的所有数据维护一个链表；</li>\n<li>每当有新数据插入或是现有数据被再次访问时，需要执行多次链表操作。</li>\n</ul><p>而假设Redis保存的数据比较多的话，那么，这两部分的代码实现，就既需要额外的内存空间来保存链表，还会在访问数据的过程中，让Redis受到数据移动和链表操作的开销影响，从而就会降低Redis访问性能。</p><p>所以说，无论是为了节省宝贵的内存空间，还是为了保持Redis高性能，Redis源码并没有严格按照LRU算法基本原理来实现它，而是<strong>提供了一个近似LRU算法的实现</strong>。</p><p>那么接下来，我们就来了解下这种近似LRU算法究竟是如何实现的。</p><h2>Redis中近似LRU算法的实现</h2><p>不过，在了解Redis对近似LRU算法的实现之前，我们需要先来看下，Redis的内存淘汰机制是如何启用近似LRU算法的，这可以帮助我们了解和近似LRU算法相关的配置项。</p><p>实际上，这和Redis配置文件redis.conf中的两个配置参数有关：</p><ul>\n<li><strong>maxmemory</strong>，该配置项设定了Redis server可以使用的最大内存容量，一旦server使用的实际内存量超出该阈值时，server就会根据maxmemory-policy配置项定义的策略，执行内存淘汰操作；</li>\n<li><strong>maxmemory-policy</strong>，该配置项设定了Redis server的内存淘汰策略，主要包括近似LRU算法、LFU算法、按TTL值淘汰和随机淘汰等几种算法。</li>\n</ul><p>所以，一旦我们设定了maxmemory选项，并且将maxmemory-policy配置为allkeys-lru或是volatile-lru时，近似LRU算法就被启用了。这里，你需要注意的是，allkeys-lru和volatile-lru都会使用近似LRU算法来淘汰数据，它们的区别在于：采用allkeys-lru策略淘汰数据时，它是在所有的键值对中筛选将被淘汰的数据；而采用volatile-lru策略淘汰数据时，它是在设置了过期时间的键值对中筛选将被淘汰的数据。</p><p>好，了解了如何启用近似LRU算法后，我们就来具体学习下Redis是如何实现近似LRU算法的。这里，为了便于你理解，我把Redis对近似LRU算法的实现分成了三个部分。</p><ul>\n<li><strong>全局LRU时钟值的计算</strong>：这部分包括，Redis源码为了实现近似LRU算法的效果，是如何计算全局LRU时钟值的，以用来判断数据访问的时效性；</li>\n<li><strong>键值对LRU时钟值的初始化与更新</strong>：这部分包括，Redis源码在哪些函数中对每个键值对对应的LRU时钟值，进行初始化与更新；</li>\n<li><strong>近似LRU算法的实际执行</strong>：这部分包括，Redis源码具体如何执行近似LRU算法，也就是何时触发数据淘汰，以及实际淘汰的机制是怎么实现的。</li>\n</ul><p>那么下面，我们就先来看下全局LRU时钟值的计算。</p><h3>全局LRU时钟值的计算</h3><p>虽然Redis使用了近似LRU算法，但是，这个算法仍然<strong>需要区分不同数据的访问时效性</strong>，也就是说，Redis需要知道数据的最近一次访问时间。因此，Redis就设计了LRU时钟来记录数据每次访问的时间戳。</p><p>我们在<a href=\"https://time.geekbang.org/column/article/402223\">第4讲</a>中已经了解到，Redis在源码中对于每个键值对中的值，会使用一个redisObject结构体来保存指向值的指针。那么，redisObject结构体除了记录值的指针以外，它其实还会使用24 bits来保存LRU时钟信息，对应的是lru成员变量。所以这样一来，每个键值对都会把它最近一次被访问的时间戳，记录在lru变量当中。</p><p>redisOjbect结构体的定义是在<a href=\"https://github.com/redis/redis/tree/5.0/src/server.h\">server.h</a>中，其中就包含了lru成员变量的定义，你可以看下。</p><pre><code>typedef struct redisObject {\n    unsigned type:4;\n    unsigned encoding:4;\n    unsigned lru:LRU_BITS;  //记录LRU信息，宏定义LRU_BITS是24 bits\n    int refcount;\n    void *ptr;\n} robj;\n</code></pre><p><strong>那么，每个键值对的LRU时钟值具体是如何计算的呢？</strong>其实，Redis server使用了一个实例级别的全局LRU时钟，每个键值对的LRU时钟值会根据全局LRU时钟进行设置。</p><p>这个全局LRU时钟保存在了Redis全局变量server的成员变量<strong>lruclock</strong>中。当Redis server启动后，调用initServerConfig函数初始化各项参数时，就会对这个全局LRU时钟lruclock进行设置。具体来说，initServerConfig函数是调用getLRUClock函数，来设置lruclock的值，如下所示：</p><pre><code>void initServerConfig(void) {\n...\nunsigned int lruclock = getLRUClock(); //调用getLRUClock函数计算全局LRU时钟值\natomicSet(server.lruclock,lruclock);//设置lruclock为刚计算的LRU时钟值\n...\n}\n</code></pre><p>所以，<strong>全局LRU时钟值就是通过getLRUClock函数计算得到的</strong>。</p><p>getLRUClock函数是在<a href=\"https://github.com/redis/redis/tree/5.0/src/evict.c\">evict.c</a>文件中实现的，它会调用mstime函数（在<a href=\"https://github.com/redis/redis/tree/5.0/src/server.c\">server.c</a>文件中）获得以毫秒为单位计算的UNIX时间戳，然后将这个UNIX时间戳除以宏定义LRU_CLOCK_RESOLUTION。宏定义LRU_CLOCK_RESOLUTION是在server.h文件中定义的，它表示的是以毫秒为单位的LRU时钟精度，也就是以毫秒为单位来表示的LRU时钟最小单位。</p><p>因为LRU_CLOCK_RESOLUTION的默认值是1000，所以，LRU时钟精度就是1000毫秒，也就是<strong>1秒</strong>。</p><p>这样一来，你需要注意的就是，<strong>如果一个数据前后两次访问的时间间隔小于1秒，那么这两次访问的时间戳就是一样的</strong>。因为LRU时钟的精度就是1秒，它无法区分间隔小于1秒的不同时间戳。</p><p>好了，了解了宏定义LRU_CLOCK_RESOLUTION的含义之后，我们再来看下getLRUClock函数中的计算。</p><p>首先，getLRUClock函数将获得的UNIX时间戳，除以LRU_CLOCK_RESOLUTION后，就得到了以LRU时钟精度来计算的UNIX时间戳，也就是当前的LRU时钟值。</p><p>紧接着，getLRUClock函数会把LRU时钟值和宏定义LRU_CLOCK_MAX做与运算，其中宏定义LRU_CLOCK_MAX表示的是LRU时钟能表示的最大值。</p><p>以下代码就展示了刚才介绍到的宏定义，以及getLRUClock函数的执行逻辑，你可以看下。</p><pre><code>#define LRU_BITS 24  \n#define LRU_CLOCK_MAX ((1&lt;&lt;LRU_BITS)-1)  //LRU时钟的最大值\n#define LRU_CLOCK_RESOLUTION 1000 //以毫秒为单位的LRU时钟精度\n\nunsigned int getLRUClock(void) {\n    return (mstime()/LRU_CLOCK_RESOLUTION) &amp; LRU_CLOCK_MAX;\n}\n</code></pre><p>所以现在，你就知道了在默认情况下，全局LRU时钟值是以1秒为精度来计算的UNIX时间戳，并且它是在initServerConfig函数中进行了初始化。那么接下来，你可能还会困惑的问题是：<strong>在Redis server的运行过程中，全局LRU时钟值是如何更新的呢？</strong></p><p>这就和Redis server在事件驱动框架中，定期运行的时间事件所对应的<strong>serverCron函数</strong>有关了。</p><p>serverCron函数作为时间事件的回调函数，本身会按照一定的频率周期性执行，其频率值是由Redis配置文件redis.conf中的<strong>hz配置项</strong>决定的。hz配置项的默认值是10，这表示serverCron函数会每100毫秒（1秒/10 = 100毫秒）运行一次。</p><p>这样，在serverCron函数中，全局LRU时钟值就会按照这个函数的执行频率，定期调用getLRUClock函数进行更新，如下所示：</p><pre><code>int serverCron(struct aeEventLoop *eventLoop, long long id, void *clientData) {\n...\nunsigned long lruclock = getLRUClock(); //默认情况下，每100毫秒调用getLRUClock函数更新一次全局LRU时钟值\natomicSet(server.lruclock,lruclock); //设置lruclock变量\n...\n}\n</code></pre><p>所以这样一来，每个键值对就可以从全局LRU时钟获取最新的访问时间戳了。</p><p>好，那么接下来，我们就来了解下，对于每个键值对来说，它对应的redisObject结构体中的lru变量，是在哪些函数中进行初始化和更新的。</p><h3>键值对LRU时钟值的初始化与更新</h3><p>首先，对于一个键值对来说，它的LRU时钟值最初是在这个键值对被创建的时候，进行初始化设置的，这个初始化操作是在<strong>createObject函数</strong>中调用的。createObject函数实现在<a href=\"https://github.com/redis/redis/tree/5.0/src/object.c\">object.c</a>文件当中，当Redis要创建一个键值对时，就会调用这个函数。</p><p>而createObject函数除了会给redisObject结构体分配内存空间之外，它还会根据我刚才提到的maxmemory_policy配置项的值，来<strong>初始化设置redisObject结构体中的lru变量</strong>。</p><p>具体来说，就是如果maxmemory_policy配置为使用LFU策略，那么lru变量值会被初始化设置为LFU算法的计算值（关于LFU算法的代码实现，我会在下节课给你介绍）。而如果maxmemory_policy配置项没有使用LFU策略，那么，createObject函数就会调用LRU_CLOCK函数来设置lru变量的值，也就是键值对对应的LRU时钟值。</p><p>LRU_CLOCK函数是在evict.c文件中实现的，它的作用就是返回当前的全局LRU时钟值。因为一个键值对一旦被创建，也就相当于有了一次访问，所以它对应的LRU时钟值就表示了它的访问时间戳。</p><p>以下代码展示了这部分的执行逻辑，你可以看下。</p><pre><code>robj *createObject(int type, void *ptr) {\n    robj *o = zmalloc(sizeof(*o));\n    ...\n    //如果缓存替换策略是LFU，那么将lru变量设置为LFU的计数值\n    if (server.maxmemory_policy &amp; MAXMEMORY_FLAG_LFU) {\n        o-&gt;lru = (LFUGetTimeInMinutes()&lt;&lt;8) | LFU_INIT_VAL;\n    } else {\n        o-&gt;lru = LRU_CLOCK();   //否则，调用LRU_CLOCK函数获取LRU时钟值\n    }\n    return o;\n}\n</code></pre><p>那么到这里，又出现了一个新的问题：<strong>一个键值对的LRU时钟值又是在什么时候被再次更新的呢？</strong></p><p>其实，只要一个键值对被访问了，它的LRU时钟值就会被更新。而当一个键值对被访问时，访问操作最终都会调用<strong>lookupKey函数</strong>。</p><p>lookupKey函数是在<a href=\"http://github.com/redis/redis/tree/5.0/src/db.c\">db.c</a>文件中实现的，它会从全局哈希表中查找要访问的键值对。如果该键值对存在，那么lookupKey函数就会根据maxmemory_policy的配置值，来更新键值对的LRU时钟值，也就是它的访问时间戳。</p><p>而当maxmemory_policy没有配置为LFU策略时，lookupKey函数就会调用LRU_CLOCK函数，来获取当前的全局LRU时钟值，并将其赋值给键值对的redisObject结构体中的lru变量，如下所示：</p><pre><code>robj *lookupKey(redisDb *db, robj *key, int flags) {\n    dictEntry *de = dictFind(db-&gt;dict,key-&gt;ptr); //查找键值对\n    if (de) {\n        robj *val = dictGetVal(de); 获取键值对对应的redisObject结构体\n        ...\n        if (server.maxmemory_policy &amp; MAXMEMORY_FLAG_LFU) {\n                updateLFU(val);  //如果使用了LFU策略，更新LFU计数值\n        } else {\n                val-&gt;lru = LRU_CLOCK();  //否则，调用LRU_CLOCK函数获取全局LRU时钟值\n        }\n       ...\n}}\n</code></pre><p>这样一来，每个键值对一旦被访问，就能获得最新的访问时间戳了。不过现在，你可能要问了：这些访问时间戳最终是如何被用于近似LRU算法，来进行数据淘汰的呢？</p><p>接下来，我们就来学习下近似LRU算法的实际执行过程。</p><h2>近似LRU算法的实际执行</h2><p>现在我们已经知道，Redis之所以实现近似LRU算法的目的，是为了减少内存资源和操作时间上的开销。那么在这里，我们其实可以从两个方面来了解近似LRU算法的执行过程，分别是：</p><ul>\n<li>何时触发算法执行？</li>\n<li>算法具体如何执行？</li>\n</ul><h3>何时触发算法执行？</h3><p>首先，近似LRU算法的主要逻辑是在freeMemoryIfNeeded函数中实现的，而这个函数本身是在evict.c文件中实现。</p><p>freeMemoryIfNeeded函数是被freeMemoryIfNeededAndSafe函数（在evict.c文件中）调用，而freeMemoryIfNeededAndSafe函数又是被processCommand函数所调用的。你可以参考下面的图，展示了这三者的调用关系。</p><p><img src=\"https://static001.geekbang.org/resource/image/f1/61/f1fb3998bb859e973e95ab47003da961.jpg?wh=2000x778\" alt=\"\"></p><p>所以，我们看到processCommand函数，就应该知道这个函数是Redis处理每个命令时都会被调用的。我在<a href=\"https://time.geekbang.org/column/article/411558\">第14讲</a>中已经介绍过processCommand函数，你可以再去回顾下。</p><p>那么，processCommand函数在执行的时候，实际上会根据两个条件来判断是否调用freeMemoryIfNeededAndSafe函数。</p><ul>\n<li><strong>条件一：设置了maxmemory配置项为非0值。</strong></li>\n<li><strong>条件二：Lua脚本没有在超时运行。</strong></li>\n</ul><p>如果这两个条件成立，那么processCommand函数就会调用freeMemoryIfNeededAndSafe函数，如下所示：</p><pre><code>...\nif (server.maxmemory &amp;&amp; !server.lua_timedout) {\n        int out_of_memory = freeMemoryIfNeededAndSafe() == C_ERR;\n...\n</code></pre><p>然后，freeMemoryIfNeededAndSafe函数还会再次根据两个条件，来判断是否调用freeMemoryIfNeeded函数。</p><ul>\n<li><strong>条件一：Lua脚本在超时运行。</strong></li>\n<li><strong>条件二：Redis server正在加载数据。</strong></li>\n</ul><p>也就是说，只有在这两个条件都不成立的情况下，freeMemoryIfNeeded函数才会被调用。下面的代码展示了freeMemoryIfNeededAndSafe函数的执行逻辑，你可以看下。</p><pre><code>int freeMemoryIfNeededAndSafe(void) {\n    if (server.lua_timedout || server.loading) return C_OK;\n    return freeMemoryIfNeeded();\n}\n</code></pre><p>这样，一旦freeMemoryIfNeeded函数被调用了，并且maxmemory-policy被设置为了allkeys-lru或volatile-lru，那么近似LRU算法就开始被触发执行了。接下来，我们就来看下近似LRU算法具体是如何执行的，也就是来了解freeMemoryIfNeeded函数的主要执行流程。</p><h3>近似LRU算法具体如何执行？</h3><p>近似LRU算法的执行可以分成三大步骤，分别是判断当前内存使用情况、更新待淘汰的候选键值对集合、选择被淘汰的键值对并删除。下面我们就依次来看下。</p><ul>\n<li><strong>判断当前内存使用情况</strong></li>\n</ul><p>首先，freeMemoryIfNeeded函数会调用<strong>getMaxmemoryState函数</strong>，评估当前的内存使用情况。getMaxmemoryState函数是在evict.c文件中实现的，它会判断当前Redis server使用的内存容量是否超过了maxmemory配置的值。</p><p><strong>如果当前内存使用量没有超过maxmemory</strong>，那么，getMaxmemoryState函数会返回C_OK，紧接着，freeMemoryIfNeeded函数也会直接返回了。</p><pre><code>int freeMemoryIfNeeded(void) {\n...\nif (getMaxmemoryState(&amp;mem_reported,NULL,&amp;mem_tofree,NULL) == C_OK)\n        return C_OK;\n...\n}\n</code></pre><p>这里，<strong>你需要注意的是</strong>，getMaxmemoryState函数在评估当前内存使用情况的时候，如果发现已用内存超出了maxmemory，它就会计算需要释放的内存量。这个释放的内存大小等于已使用的内存量减去maxmemory。不过，已使用的内存量并不包括用于主从复制的复制缓冲区大小，这是getMaxmemoryState函数，通过调用freeMemoryGetNotCountedMemory函数来计算的。</p><p>我把getMaxmemoryState函数的基本执行逻辑代码放在这里，你可以看下。</p><pre><code>int getMaxmemoryState(size_t *total, size_t *logical, size_t *tofree, float *level) {\n...\nmem_reported = zmalloc_used_memory(); //计算已使用的内存量\n...\n//将用于主从复制的复制缓冲区大小从已使用内存量中扣除\nmem_used = mem_reported;\nsize_t overhead = freeMemoryGetNotCountedMemory();\nmem_used = (mem_used &gt; overhead) ? mem_used-overhead : 0;\n...\n//计算需要释放的内存量\nmem_tofree = mem_used - server.maxmemory;\n...\n}\n</code></pre><p><strong>而如果当前server使用的内存量，的确已经超出maxmemory的上限了</strong>，那么freeMemoryIfNeeded函数就会执行一个while循环，来淘汰数据释放内存。</p><p>其实，为了淘汰数据，Redis定义了一个数组EvictionPoolLRU，用来保存待淘汰的候选键值对。这个数组的元素类型是evictionPoolEntry结构体，该结构体保存了待淘汰键值对的空闲时间idle、对应的key等信息。以下代码展示了EvictionPoolLRU数组和evictionPoolEntry结构体，它们都是在evict.c文件中定义的。</p><pre><code>static struct evictionPoolEntry *EvictionPoolLRU;\n\nstruct evictionPoolEntry {\n    unsigned long long idle;    //待淘汰的键值对的空闲时间\n    sds key;                    //待淘汰的键值对的key\n    sds cached;                 //缓存的SDS对象\n    int dbid;                   //待淘汰键值对的key所在的数据库ID\n};\n</code></pre><p>这样，Redis server在执行initSever函数进行初始化时，会调用evictionPoolAlloc函数（在evict.c文件中）为EvictionPoolLRU数组分配内存空间，该数组的大小由宏定义EVPOOL_SIZE（在evict.c文件中）决定，默认是16个元素，也就是可以保存16个待淘汰的候选键值对。</p><p>那么，freeMemoryIfNeeded函数在淘汰数据的循环流程中，就会更新这个待淘汰的候选键值对集合，也就是EvictionPoolLRU数组。下面我就来给你具体介绍一下。</p><ul>\n<li><strong>更新待淘汰的候选键值对集合</strong></li>\n</ul><p>首先，freeMemoryIfNeeded函数会调用<strong>evictionPoolPopulate函数</strong>（在evict.c文件中），而evictionPoolPopulate函数会先调用dictGetSomeKeys函数（在dict.c文件中），从待采样的哈希表中随机获取一定数量的key。不过，这里还有两个地方你需要注意下。</p><p><strong>第一点</strong>，dictGetSomeKeys函数采样的哈希表，是由maxmemory_policy配置项来决定的。如果maxmemory_policy配置的是allkeys_lru，那么待采样哈希表就是Redis server的全局哈希表，也就是在所有键值对中进行采样；否则，待采样哈希表就是保存着设置了过期时间的key的哈希表。</p><p>以下代码是freeMemoryIfNeeded函数中对evictionPoolPopulate函数的调用过程，你可以看下。</p><pre><code>for (i = 0; i &lt; server.dbnum; i++) {\n       db = server.db+i;   //对Redis server上的每一个数据库都执行\n       //根据淘汰策略，决定使用全局哈希表还是设置了过期时间的key的哈希表\n       dict = (server.maxmemory_policy &amp; MAXMEMORY_FLAG_ALLKEYS) ? db-&gt;dict : db-&gt;expires;\n       if ((keys = dictSize(dict)) != 0) {\n           //将选择的哈希表dict传入evictionPoolPopulate函数，同时将全局哈希表也传给evictionPoolPopulate函数\n           evictionPoolPopulate(i, dict, db-&gt;dict, pool);\n           total_keys += keys;\n        }\n }\n</code></pre><p><strong>第二点</strong>，dictGetSomeKeys函数采样的key的数量，是由redis.conf中的配置项maxmemory-samples决定的，该配置项的默认值是5。下面代码就展示了evictionPoolPopulate函数对dictGetSomeKeys函数的调用：</p><pre><code>void evictionPoolPopulate(int dbid, dict *sampledict, dict *keydict, struct evictionPoolEntry *pool) {\n    ...\n    dictEntry *samples[server.maxmemory_samples];  //采样后的集合，大小为maxmemory_samples\n    //将待采样的哈希表sampledict、采样后的集合samples、以及采样数量maxmemory_samples，作为参数传给dictGetSomeKeys\n    count = dictGetSomeKeys(sampledict,samples,server.maxmemory_samples);\n    ...\n}\n</code></pre><p>如此一来，dictGetSomeKeys函数就能返回采样的键值对集合了。然后，evictionPoolPopulate函数会根据实际采样到的键值对数量count，执行一个循环。</p><p>在这个循环流程中，evictionPoolPopulate函数会调用estimateObjectIdleTime函数，来计算在采样集合中的每一个键值对的空闲时间，如下所示：</p><pre><code>for (j = 0; j &lt; count; j++) {\n...\nif (server.maxmemory_policy &amp; MAXMEMORY_FLAG_LRU) {\n            idle = estimateObjectIdleTime(o);\n}\n...\n</code></pre><p>紧接着，evictionPoolPopulate函数会遍历待淘汰的候选键值对集合，也就是EvictionPoolLRU数组。在遍历过程中，它会尝试把采样的每一个键值对插入EvictionPoolLRU数组，这主要取决于以下两个条件之一：</p><ul>\n<li>一是，它能在数组中找到一个尚未插入键值对的空位；</li>\n<li>二是，它能在数组中找到一个空闲时间小于采样键值对空闲时间的键值对。</li>\n</ul><p>这两个条件有一个成立的话，evictionPoolPopulate函数就可以把采样键值对插入EvictionPoolLRU数组。等所有采样键值对都处理完后，evictionPoolPopulate函数就完成对待淘汰候选键值对集合的更新了。</p><p>接下来，freeMemoryIfNeeded函数，就可以开始选择最终被淘汰的键值对了。</p><ul>\n<li><strong>选择被淘汰的键值对并删除</strong></li>\n</ul><p>因为evictionPoolPopulate函数已经更新了EvictionPoolLRU数组，而且这个数组里面的key，是按照空闲时间从小到大排好序了。所以，freeMemoryIfNeeded函数会遍历一次EvictionPoolLRU数组，从数组的最后一个key开始选择，如果选到的key不是空值，那么就把它作为最终淘汰的key。</p><p>这个过程的基本执行逻辑如下所示：</p><pre><code>for (k = EVPOOL_SIZE-1; k &gt;= 0; k--) { //从数组最后一个key开始查找\n   if (pool[k].key == NULL) continue; //当前key为空值，则查找下一个key\n   \n   ... //从全局哈希表或是expire哈希表中，获取当前key对应的键值对；并将当前key从EvictionPoolLRU数组删除\n\n    //如果当前key对应的键值对不为空，选择当前key为被淘汰的key\n    if (de) {\n      bestkey = dictGetKey(de);\n      break;\n     } else {} //否则，继续查找下个key\n}\n</code></pre><p>最后，一旦选到了被淘汰的key，freeMemoryIfNeeded函数就会根据Redis server的惰性删除配置，来执行同步删除或异步删除，如下所示：</p><pre><code>if (bestkey) {\n            db = server.db+bestdbid;\n            robj *keyobj = createStringObject(bestkey,sdslen(bestkey));        //将删除key的信息传递给从库和AOF文件\n            propagateExpire(db,keyobj,server.lazyfree_lazy_eviction);\n            //如果配置了惰性删除，则进行异步删除\n            if (server.lazyfree_lazy_eviction)\n                dbAsyncDelete(db,keyobj);\n            else  //否则进行同步删除\n                dbSyncDelete(db,keyobj);\n}\n</code></pre><p>好了，到这里，freeMemoryIfNeeded函数就淘汰了一个key。而如果此时，释放的内存空间还不够，也就是说没有达到我前面介绍的待释放空间，那么freeMemoryIfNeeded函数还会<strong>重复执行</strong>前面所说的更新待淘汰候选键值对集合、选择最终淘汰key的过程，直到满足待释放空间的大小要求。</p><p>下图就展示了freeMemoryIfNeeded函数涉及的基本流程，你可以再来整体回顾下。</p><p><img src=\"https://static001.geekbang.org/resource/image/2e/d4/2e3e63e1a83a39405825a564637463d4.jpg?wh=2000x1125\" alt=\"\"></p><p>其实，从刚才介绍的内容中，你就可以看到，近似LRU算法并没有使用耗时耗空间的链表，而是使用了<strong>固定大小的待淘汰数据集合</strong>，每次随机选择一些key加入待淘汰数据集合中。最后，再按照待淘汰集合中key的空闲时间长度，删除空闲时间最长的key。这样一来，Redis就近似实现了LRU算法的效果了。</p><h2>小结</h2><p>好了，今天这节课就到这里，我们来总结下。</p><p>今天这节课我给你介绍了Redis中，是如何实现LRU算法来进行缓存数据替换的。其中，我们根据LRU算法的基本原理，可以发现如果严格按照原理来实现LRU算法，那么开发的系统就需要用额外的内存空间来保存LRU链表，而且系统运行时也会受到LRU链表操作的开销影响。</p><p>而对于Redis来说，内存资源和性能都很重要，所以Redis实现了近似LRU算法。而为了实现近似LRU算法，Redis首先是设置了<strong>全局LRU时钟</strong>，并在键值对创建时获取全局LRU时钟值作为访问时间戳，以及在每次访问时获取全局LRU时钟值，更新访问时间戳。</p><p>然后，当Redis每处理一个命令时，都会<strong>调用freeMemoryIfNeeded函数</strong>来判断是否需要释放内存。如果已使用内存超出了maxmemory，那么，近似LRU算法就会随机选择一些键值对，组成待淘汰候选集合，并根据它们的访问时间戳，选出最旧的数据，将其淘汰。</p><p>实际上，通过学习这节课的内容，你可以体会到一个算法的基本原理和算法的实际执行，在系统开发中会有一定的折中选择，主要就是因为我们需要综合考虑所开发的系统，在资源和性能方面的要求，以避免严格按照算法实现带来的资源和性能开销。因此，这一点就是你在进行计算机系统开发时，要秉承的一个原则。</p><h2>每课一问</h2><p>现在你已经知道，Redis源码中提供了getLRUClock函数来计算全局LRU时钟值，同时键值对的LRU时钟值是通过LRU_CLOCK函数来获取的，以下代码就展示了LRU_CLOCK函数的执行逻辑。这个函数包括两个分支，一个分支是直接从全局变量server的lruclock中获取全局时钟值，另一个是调用getLRUClock函数获取全局时钟值。</p><p>那么你知道，为什么键值对的LRU时钟值，不是直接通过调用getLRUClock函数来获取的呢？</p><pre><code>unsigned int LRU_CLOCK(void) {\n    unsigned int lruclock;\n    if (1000/server.hz &lt;= LRU_CLOCK_RESOLUTION) {\n        atomicGet(server.lruclock,lruclock);\n    } else {\n        lruclock = getLRUClock();\n    }\n    return lruclock;\n}\n</code></pre><p>欢迎在留言区分享你的答案和思考过程，如果觉得有收获，也欢迎你把今天的内容分享给更多的朋友。</p>","neighbors":{"left":{"article_title":"14 | 从代码实现看分布式锁的原子性保证","id":411558},"right":{"article_title":"16 | LFU算法和其他算法相比有优势吗？","id":413038}}},{"article_id":413038,"article_title":"16 | LFU算法和其他算法相比有优势吗？","article_content":"<p>你好，我是蒋德钧。</p><p>上节课我给你介绍了Redis对缓存淘汰策略LRU算法的近似实现。其实，Redis在4.0版本后，还引入了LFU算法，也就是<strong>最不频繁使用</strong>（Least Frequently Used，LFU）算法。LFU算法在进行数据淘汰时，会把最不频繁访问的数据淘汰掉。而LRU算法是把最近最少使用的数据淘汰掉，看起来也是淘汰不频繁访问的数据。那么，<strong>LFU算法和LRU算法的区别到底有哪些呢？我们在实际场景中，需要使用LFU算法吗？</strong></p><p>其实，如果只是从基本定义来看的话，我们是不太容易区分出这两个算法的。所以，今天这节课，我就带你从源码层面来学习了解下LFU算法的设计与实现。这样，你就能更好地掌握LFU算法的优势和适用场景，当你要为Redis缓存设置淘汰策略时，就可以作出合适的选择了。</p><p>好，那么在开始学习LFU算法的实现代码之前，我们还是先来看下LFU算法的基本原理，以此更好地支撑我们掌握代码的执行逻辑。</p><h2>LFU算法的基本原理</h2><p>因为LFU算法是根据<strong>数据访问的频率</strong>来选择被淘汰数据的，所以LFU算法会记录每个数据的访问次数。当一个数据被再次访问时，就会增加该数据的访问次数。</p><p>不过，访问次数和访问频率还不能完全等同。<strong>访问频率是指在一定时间内的访问次数</strong>，也就是说，在计算访问频率时，我们不仅需要记录访问次数，还要记录这些访问是在多长时间内执行的。否则，如果只记录访问次数的话，就缺少了时间维度的信息，进而就无法按照频率来淘汰数据了。</p><!-- [[[read_end]]] --><p>我来给你举个例子，假设数据A在15分钟内访问了15次，数据B在5分钟内访问了10次。如果只是按访问次数来统计的话，数据A的访问次数大于数据B，所以淘汰数据时会优先淘汰数据B。不过，如果按照访问频率来统计的话，数据A的访问频率是1分钟访问1次，而数据B的访问频率是1分钟访问2次，所以按访问频率淘汰数据的话，数据A应该被淘汰掉。</p><p>所以说，当要实现LFU算法时，我们需要能统计到数据的访问频率，而不是简单地记录数据访问次数就行。</p><p>那么接下来，我们就来学习下Redis是如何实现LFU算法的。</p><h2>LFU算法的实现</h2><p>首先，和我们上节课介绍的LRU算法类似，LFU算法的启用，是通过设置Redis配置文件redis.conf中的maxmemory和maxmemory-policy。其中，maxmemory设置为Redis会用的最大内存容量，而maxmemory-policy可以设置为allkeys-lfu或是volatile-lfu，表示淘汰的键值对会分别从所有键值对或是设置了过期时间的键值对中筛选。</p><p>LFU算法的实现可以分成三部分内容，分别是键值对访问频率记录、键值对访问频率初始化和更新，以及LFU算法淘汰数据。下面，我们先来看下键值对访问频率记录。</p><h3>键值对访问频率记录</h3><p>通过LRU算法的学习，现在我们已经了解到，每个键值对的值都对应了一个redisObject结构体，其中有一个24 bits的lru变量。lru变量在LRU算法实现时，是用来记录数据的访问时间戳。因为Redis server每次运行时，只能将maxmemory-policy配置项设置为使用一种淘汰策略，所以，<strong>LRU算法和LFU算法并不会同时使用</strong>。而为了节省内存开销，Redis源码就复用了lru变量来记录LFU算法所需的访问频率信息。</p><p>具体来说，当lru变量用来记录LFU算法的所需信息时，它会用24 bits中的低8 bits作为计数器，来记录键值对的访问次数，同时它会用24 bits中的高16 bits，记录访问的时间戳。下图就展示了用来记录访问频率时的lru变量内容，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/1c/dc/1cfd742c59f0c2447ac9af0f9160a4dc.jpg?wh=1920x430\" alt=\"\"></p><p>好，了解了LFU算法所需的访问频率是如何记录的，接下来，我们再来看下键值对的访问频率是如何初始化和更新的。</p><h3>键值对访问频率的初始化与更新</h3><p>首先，我们要知道，LFU算法和LRU算法的基本步骤，实际上是<strong>在相同的入口函数中执行</strong>的。上节课围绕LRU算法的实现，我们已经了解到这些基本步骤包括数据访问信息的初始化、访问信息更新，以及实际淘汰数据。这些步骤对应的入口函数如下表所示，你也可以再去回顾下上节课的内容。</p><p><img src=\"https://static001.geekbang.org/resource/image/09/c4/0915155b20fee28776252f3b0c247ac4.jpg?wh=2000x783\" alt=\"\"></p><p>了解了这些入口函数后，我们再去分析LFU算法的实现，就容易找到对应的函数了。</p><p>对于键值对访问频率的初始化来说，当一个键值对被创建后，<strong>createObject函数</strong>就会被调用，用来分配redisObject结构体的空间和设置初始化值。如果Redis将maxmemory-policy设置为LFU算法，那么，键值对redisObject结构体中的lru变量初始化值，会由两部分组成：</p><ul>\n<li>第一部分是<strong>lru变量的高16位</strong>，是以1分钟为精度的UNIX时间戳。这是通过调用LFUGetTimeInMinutes函数（在evict.c文件中）计算得到的。</li>\n<li>第二部分是<strong>lru变量的低8位</strong>，被设置为宏定义LFU_INIT_VAL（在<a href=\"http://github.com/redis/redis/tree/5.0/src/server.h\">server.h</a>文件中），默认值为5。</li>\n</ul><p>你会发现，这和我刚才给你介绍的键值对访问频率记录是一致的，也就是说，当使用LFU算法时，lru变量包括了键值对的访问时间戳和访问次数。以下代码也展示了这部分的执行逻辑，你可以看下。</p><pre><code>robj *createObject(int type, void *ptr) {\n    robj *o = zmalloc(sizeof(*o));\n    ...\n    //使用LFU算法时，lru变量包括以分钟为精度的UNIX时间戳和访问次数5\n    if (server.maxmemory_policy &amp; MAXMEMORY_FLAG_LFU) {\n        o-&gt;lru = (LFUGetTimeInMinutes()&lt;&lt;8) | LFU_INIT_VAL;\n    } else {\n        o-&gt;lru = LRU_CLOCK();  //使用LRU算法时的设置\n    }\n    return o;\n}\n</code></pre><p>下面，我们再来看下键值对访问频率的更新。</p><p>当一个键值对被访问时，Redis会调用lookupKey函数进行查找。当maxmemory-policy设置使用LFU算法时，lookupKey函数会<strong>调用updateLFU函数来更新键值对的访问频率</strong>，也就是lru变量值，如下所示：</p><pre><code>robj *lookupKey(redisDb *db, robj *key, int flags) {\n...\nif (server.maxmemory_policy &amp; MAXMEMORY_FLAG_LFU) {\n                updateLFU(val); //使用LFU算法时，调用updateLFU函数更新访问频率\n} else {\n                val-&gt;lru = LRU_CLOCK(); //使用LRU算法时，调用LRU_CLOCK\n}\n...\n</code></pre><p>updateLFU函数是在<a href=\"https://github.com/redis/redis/tree/5.0/src/db.c\">db.c</a>文件中实现的，它的执行逻辑比较明确，一共分成三步。</p><p><strong>第一步，根据距离上次访问的时长，衰减访问次数。</strong></p><p>updateLFU函数首先会调用LFUDecrAndReturn函数（在evict.c文件中），对键值对的访问次数进行衰减操作，如下所示：</p><pre><code>void updateLFU(robj *val) {\n    unsigned long counter = LFUDecrAndReturn(val);\n    ...\n}\n</code></pre><p>看到这里，你可能会有疑问：<strong>访问键值对时不是要增加键值对的访问次数吗，为什么要先衰减访问次数呢？</strong></p><p>其实，这就是我在前面一开始和你介绍的，LFU算法是根据访问频率来淘汰数据的，而不只是访问次数。访问频率需要考虑键值对的访问是多长时间段内发生的。键值对的先前访问距离当前时间越长，那么这个键值对的访问频率相应地也就会降低。</p><p>我给你举个例子，假设数据A在时刻T到T+10分钟这段时间内，被访问了30次，那么，这段时间内数据A的访问频率可以计算为3次/分钟（30次/10分钟 = 3次/分钟）。</p><p>紧接着，在T+10分钟到T+20分钟这段时间内，数据A没有再被访问，那么此时，如果我们计算数据A在T到T+20分钟这段时间内的访问频率，它的访问频率就会降为1.5次/分钟（30次/20分钟 = 1.5次/分钟）。以此类推，随着时间的推移，如果数据A在T+10分钟后一直没有新的访问，那么它的访问频率就会逐步降低。这就是所谓的<strong>访问频率衰减</strong>。</p><p>因为Redis是使用lru变量中的访问次数来表示访问频率，所以在每次更新键值对的访问频率时，就会通过LFUDecrAndReturn函数对访问次数进行衰减。</p><p>具体来说，LFUDecrAndReturn函数会首先获取当前键值对的上一次访问时间，这是保存在lru变量高16位上的值。然后，LFUDecrAndReturn函数会根据全局变量server的lru_decay_time成员变量的取值，来计算衰减的大小num_period。</p><p>这个计算过程会判断lfu_decay_time的值是否为0。如果lfu_decay_time值为0，那么衰减大小也为0。此时，访问次数不进行衰减。</p><p>否则的话，LFUDecrAndReturn函数会调用LFUTimeElapsed函数（在evict.c文件中），计算距离键值对的上一次访问已经过去的时长。这个时长也是以1分钟为精度来计算的。有了距离上次访问的时长后，LFUDecrAndReturn函数会把这个时长除以lfu_decay_time的值，并把结果作为访问次数的衰减大小。</p><p>这里，<strong>你需要注意的是</strong>，lfu_decay_time变量值，是由redis.conf文件中的配置项lfu-decay-time来决定的。Redis在初始化时，会通过initServerConfig函数来设置lfu_decay_time变量的值，默认值为1。所以，<strong>在默认情况下，访问次数的衰减大小就是等于上一次访问距离当前的分钟数</strong>。比如，假设上一次访问是10分钟前，那么在默认情况下，访问次数的衰减大小就等于10。</p><p>当然，如果上一次访问距离当前的分钟数，已经超过访问次数的值了，那么访问次数就会被设置为0，这就表示键值对已经很长时间没有被访问了。</p><p>下面的代码展示了LFUDecrAndReturn函数的执行逻辑，你可以看下。</p><pre><code>unsigned long LFUDecrAndReturn(robj *o) {\n    unsigned long ldt = o-&gt;lru &gt;&gt; 8; //获取当前键值对的上一次访问时间\n    unsigned long counter = o-&gt;lru &amp; 255; //获取当前的访问次数\n    unsigned long num_periods = server.lfu_decay_time ? LFUTimeElapsed(ldt) / server.lfu_decay_time : 0;  //计算衰减大小\n    if (num_periods)   //如果衰减大小不为0\n        //如果衰减大小小于当前访问次数，那么，衰减后的访问次数是当前访问次数减去衰减大小；否则，衰减后的访问次数等于0\n        counter = (num_periods &gt; counter) ? 0 : counter - num_periods;\n    return counter;   //如果衰减大小为0，则返回原来的访问次数\n}\n</code></pre><p>好了，到这里，updateLFU函数就通过LFUDecrAndReturn函数，完成了键值对访问次数的衰减。紧接着，updateLFU函数还是会基于键值对当前的这次访问，来更新它的访问次数。</p><p><strong>第二步，根据当前访问更新访问次数。</strong></p><p>在这一步中，updateLFU函数会调用LFULogIncr函数，来增加键值对的访问次数，如下所示：</p><pre><code>void updateLFU(robj *val) {\n    ...\n    counter = LFULogIncr(counter);\n    ...\n}\n</code></pre><p>LFULogIncr函数是在evict.c文件中实现的，它的执行逻辑主要包括两个分支：</p><ul>\n<li><strong>第一个分支对应了当前访问次数等于最大值255的情况。</strong>此时，LFULogIncr函数不再增加访问次数。</li>\n<li><strong>第二个分支对应了当前访问次数小于255的情况。</strong>此时，LFULogIncr函数会计算一个阈值p，以及一个取值为0到1之间的随机概率值r。如果概率r小于阈值p，那么LFULogIncr函数才会将访问次数加1。否则的话，LFULogIncr函数会返回当前的访问次数，不做更新。</li>\n</ul><p>从这里你可以看到，因为概率值r是随机定的，所以，<strong>阈值p的大小</strong>就决定了访问次数增加的难度。阈值p越小，概率值r小于p的可能性也越小，此时，访问次数也越难增加；相反，如果阈值p越大，概率值r小于p的可能性就越大，访问次数就越容易增加。</p><p>而阈值p的值大小，其实是由两个因素决定的。一个是当前访问次数和宏定义LFU_INIT_VAL的<strong>差值baseval</strong>，另一个是redis.conf文件中定义的<strong>配置项lfu-log-factor</strong>。</p><p>当计算阈值p时，我们是把baseval和lfu-log-factor乘积后，加上1，然后再取其倒数。所以，baseval或者lfu-log-factor越大，那么其倒数就越小，也就是阈值p就越小；反之，阈值p就越大。也就是说，这里其实就对应了两种影响因素。</p><ul>\n<li>baseval的大小：这反映了当前访问次数的多少。比如，访问次数越多的键值对，它的访问次数再增加的难度就会越大；</li>\n<li>lfu-log-factor的大小：这是可以被设置的。也就是说，Redis源码提供了让我们人为调节访问次数增加难度的方法。</li>\n</ul><p>以下代码就展示了LFULogIncr函数的执行逻辑，你可以看下。</p><pre><code>uint8_t LFULogIncr(uint8_t counter) {\n    if (counter == 255) return 255; //访问次数已经等于255，直接返回255\n    double r = (double)rand()/RAND_MAX;  //计算一个随机数\n    double baseval = counter - LFU_INIT_VAL;  //计算当前访问次数和初始值的差值\n    if (baseval &lt; 0) baseval = 0; //差值小于0，则将其设为0\n    double p = 1.0/(baseval*server.lfu_log_factor+1); //根据baseval和lfu_log_factor计算阈值p\n    if (r &lt; p) counter++; //概率值小于阈值时,\n    return counter;\n}\n</code></pre><p>这样，等到LFULogIncr函数执行完成后，键值对的访问次数就算更新完了。</p><p><strong>第三步，更新lru变量值。</strong></p><p>最后，到这一步，updateLFU函数已经完成了键值对访问次数的更新。接着，它就会调用<strong>LFUGetTimeInMinutes函数</strong>，来获取当前的时间戳，并和更新后的访问次数组合，形成最新的访问频率信息，赋值给键值对的lru变量，如下所示：</p><pre><code>void updateLFU(robj *val) {\n    ...\n    val-&gt;lru = (LFUGetTimeInMinutes()&lt;&lt;8) | counter;\n}\n</code></pre><p>好了，到这里，你就了解了，Redis源码在更新键值对访问频率时，对于访问次数，它是先按照上次访问距离当前的时长，来对访问次数进行衰减。然后，再按照一定概率增加访问次数。这样的设计方法，就既包含了访问的时间段对访问频率的影响，也避免了8 bits计数器对访问次数的影响。而对于访问时间来说，Redis还会获取最新访问时间戳并更新到lru变量中。</p><p>那么最后，我们再来看下Redis是如何基于LFU算法淘汰数据的。</p><h3>LFU算法淘汰数据</h3><p>在实现使用LFU算法淘汰数据时，Redis是采用了和实现近似LRU算法相同的方法。也就是说，Redis会使用一个<strong>全局数组EvictionPoolLRU</strong>，来保存待淘汰候选键值对集合。然后，在processCommand函数处理每个命令时，它会调用freeMemoryIfNeededAndSafe函数和freeMemoryIfNeeded函数，来执行具体的数据淘汰流程。</p><p>这个淘汰流程我在上节课已经给你介绍过了，你可以再去整体回顾下。这里，我也再简要总结下，也就是分成三个步骤：</p><ul>\n<li>第一步，调用getMaxmemoryState函数计算待释放的内存空间；</li>\n<li>第二步，调用evictionPoolPopulate函数随机采样键值对，并插入到待淘汰集合EvictionPoolLRU中；</li>\n<li>第三步，遍历待淘汰集合EvictionPoolLRU，选择实际被淘汰数据，并删除。</li>\n</ul><p>虽然这个基本流程和LRU算法相同，但是你要<strong>注意</strong>，LFU算法在淘汰数据时，在第二步的evictionPoolPopulate函数中，使用了不同的方法来计算每个待淘汰键值对的空闲时间。</p><p>具体来说，在实现LRU算法时，待淘汰候选键值对集合EvictionPoolLRU中的每个元素，都使用<strong>成员变量idle</strong>来记录它距离上次访问的空闲时间。</p><p>而当实现LFU算法时，因为LFU算法会对访问次数进行衰减和按概率增加，所以，它是使用<strong>访问次数</strong>来近似表示访问频率的。相应的，LFU算法其实是用255减去键值对的访问次数，这样来计算EvictionPoolLRU数组中每个元素的idle变量值的。而且，在计算idle变量值前，LFU算法还会<strong>调用LFUDecrAndReturn函数，衰减一次键值对的访问次数</strong>，以便能更加准确地反映实际选择待淘汰数据时，数据的访问频率。</p><p>下面的代码展示了LFU算法计算idle变量值的过程，你可以看下。</p><pre><code> if (server.maxmemory_policy &amp; MAXMEMORY_FLAG_LRU) {\n            idle = estimateObjectIdleTime(o);\n } else if (server.maxmemory_policy &amp; MAXMEMORY_FLAG_LFU) {\n            idle = 255-LFUDecrAndReturn(o);\n}\n</code></pre><p>所以说，当LFU算法按照访问频率，计算了待淘汰键值对集合中每个元素的idle值后，键值对访问次数越大，它的idle值就越小，反之idle值越大。而EvictionPoolLRU数组中的元素，是按idle值从小到大来排序的。最后当freeMemoryIfNeeded函数按照idle值从大到小，遍历EvictionPoolLRU数组，选择实际被淘汰的键值对时，它就能选出访问次数小的键值对了，也就是把访问频率低的键值对淘汰出去。</p><p>这样，Redis就完成了按访问频率来淘汰数据的操作了。</p><h2>小结</h2><p>这节课我主要是给你介绍了Redis使用的LFU缓存淘汰策略。LFU算法会根据键值对的访问频率来淘汰数据，而和使用访问次数淘汰数据不同，使用访问频率，不仅需要统计访问次数，而且还要考虑所记录的访问距离当前时间的时长。</p><p>所以，正是基于这样的设计考虑，Redis源码在实现LFU算法时，在键值对的redisObject结构体中的lru变量里，会同时记录访问次数和访问时间戳。当键值对被再次访问时，lru变量中的访问次数，会先根据上一次访问距离当前的时长，执行衰减操作，然后才会执行增加操作。</p><p>不过，键值对的访问次数只能用lru变量中有限的8 bits来记录，最大值就是255。这样一来，如果每访问一次键值对，访问次数就加1的话，那么访问次数很容易就达到最大值了，这就无法区分不同的访问频率了。</p><p>为了区分不同的访问频率，LFU算法在实现时是采用了<strong>按概率增加访问次数</strong>的方法，也就是说，已有访问次数越大的键值对，它的访问次数就越难再增加。</p><p>另外你也要知道，对于LFU算法的执行流程来说，它和LRU算法的基本执行流程是相同的，这包括入口函数、待释放内存空间计算、更新待淘汰候选键值对集合，以及选择实际被淘汰数据这几个关键步骤。不同的是，LFU算法在待淘汰键值对集合中，是按照键值对的访问频率大小来排序和选择淘汰数据的，这也符合LFU算法本身的要求。</p><p>而且，正因为LFU算法会根据访问频率来淘汰数据，以及访问频率会随时间推移而衰减，所以，LFU算法相比其他算法来说，更容易把低频访问的冷数据尽早淘汰掉，这也是它的适用场景。</p><p>最后，从LFU算法的实现代码来看，当我们自己实现按访问频率进行操作的软件模块时，我觉得Redis采用的这两种设计方法：访问次数按时间衰减和访问次数按概率增加，其实是一个不错的参考范例。你在自己的实现场景中，就可以借鉴使用。</p><h2>每课一问</h2><p>LFU算法在初始化键值对的访问次数时，会将访问次数设置为LFU_INIT_VAL，它的默认值是5次。那么，你能结合这节课介绍的代码，说说如果LFU_INIT_VAL设置为1，会发生什么情况吗？</p>","neighbors":{"left":{"article_title":"15 | 为什么LRU算法原理和代码实现不一样？","id":412164},"right":{"article_title":"17 | Lazy Free会影响缓存替换吗？","id":413997}}},{"article_id":413997,"article_title":"17 | Lazy Free会影响缓存替换吗？","article_content":"<p>你好，我是蒋德钧。</p><p>Redis缓存淘汰算法的目的，其实是为了在Redis server内存使用量超过上限值的时候，筛选一些冷数据出来，把它们从Redis server中删除，以保证server的内存使用量不超出上限。我们在前两节课，已经分别学习了Redis源码对LRU算法和LFU算法的实现，这两种算法在最后淘汰数据的时候，都会删除被淘汰的数据。</p><p>不过，无论是LRU算法还是LFU算法，它们在删除淘汰数据时，实际上都会根据Redis server的<strong>lazyfree-lazy-eviction配置项</strong>，来决定是否使用Lazy Free，也就是惰性删除。</p><p>惰性删除是Redis 4.0版本后提供的功能，它会使用后台线程来执行删除数据的任务，从而避免了删除操作对主线程的阻塞。但是，<strong>后台线程异步删除数据能及时释放内存吗？它会影响到Redis缓存的正常使用吗？</strong></p><p>今天这节课，我就来给你介绍下惰性删除在缓存淘汰时的应用。了解这部分内容，你就可以掌握惰性删除启用后，会给Redis缓存淘汰和内存释放带来的可能影响。这样，当你在实际应用中，遇到Redis缓存内存容量的问题时，你就多了一条排查思路了。</p><p>好，那么接下来，我们就先来看下缓存淘汰时的数据删除的基本过程。不过在了解这个删除过程之前，我们需要先了解下Redis server启动惰性删除的配置。因为在Redis源码中，有不少地方都会根据server是否启动惰性删除，来执行不同的分支操作。</p><!-- [[[read_end]]] --><h2>惰性删除的设置</h2><p>首先，当Redis server希望启动惰性删除时，需要在redis.conf文件中设置和惰性删除相关的配置项。其中包括了四个配置项，分别对应了如下的四种场景。</p><ul>\n<li><strong>lazyfree-lazy-eviction</strong>：对应缓存淘汰时的数据删除场景。</li>\n<li><strong>lazyfree-lazy-expire</strong>：对应过期key的删除场景。</li>\n<li><strong>lazyfree-lazy-server-del</strong>：对应会隐式进行删除操作的server命令执行场景。</li>\n<li><strong>replica-lazy-flush</strong>：对应从节点完成全量同步后，删除原有旧数据的场景。</li>\n</ul><p>这四个配置项的默认值都是no。所以，如果要在缓存淘汰时启用，就需要将</p><p>lazyfree-lazy-eviction设置为yes。同时，Redis server在启动过程中进行配置参数初始化时，会根据redis.conf的配置信息，设置全局变量server的lazyfree_lazy_eviction成员变量。</p><p>这样一来，我们在Redis源码中，如果看到对server.lazyfree_lazy_eviction变量值进行条件判断，那其实就是Redis根据lazyfree-lazy-eviction配置项，来决定是否执行惰性删除。</p><p>好了，了解了如何在缓存淘汰场景中设置惰性删除之后，接下来，我们就来看下被淘汰数据的删除过程。</p><h2>被淘汰数据的删除过程</h2><p>其实通过前两节课程的学习，我们已经知道，Redis源码中的freeMemoryIfNeeded函数（在<a href=\"https://github.com/redis/redis/tree/5.0/src/evict.c\">evict.c</a>文件中）会负责执行数据淘汰的流程。而该函数在筛选出被淘汰的键值对后，就要开始删除被淘汰的数据，这个删除过程主要分成两步。</p><p><strong>第一步</strong>，freeMemoryIfNeeded函数会为被淘汰的key创建一个SDS对象，然后调用propagateExpire函数，如下所示：</p><pre><code>int freeMemoryIfNeeded(void) {\n   …\n   if (bestkey) {\n      db = server.db+bestdbid;\n      robj *keyobj = createStringObject(bestkey,sdslen(bestkey));\n\tpropagateExpire(db,keyobj,server.lazyfree_lazy_eviction);\n   …\n}\n</code></pre><p>propagateExpire函数是在<a href=\"https://github.com/redis/redis/tree/5.0/src/db.c\">db.c</a>文件中实现的。它会先创建一个redisObject结构体数组，该数组的第一个元素是删除操作对应的命令对象，而第二个元素是被删除的key对象。因为Redis server可能针对缓存淘汰场景启用了惰性删除，所以，<strong>propagateExpire函数会根据全局变量server的lazyfree_lazy_eviction成员变量的值，来决定删除操作具体对应的是哪个命令。</strong></p><p>如果lazyfree_lazy_eviction被设置为1，也就是启用了缓存淘汰时的惰性删除，那么，删除操作对应的命令就是UNLINK；否则的话，命令就是DEL。因为这些命令会被经常使用，所以Redis源码中会为这些命令创建共享对象。这些共享对象的数据结构是sharedObjectsStruct结构体，并用一个全局变量shared来表示。在该结构体中包含了指向共享对象的指针，这其中就包括了unlink和del命令对象。</p><p>以下代码展示了shared全局变量的定义以及sharedObjectsStruct结构体的定义，其中，shared变量是在<a href=\"https://github.com/redis/redis/tree/5.0/src/server.c\">server.c</a>文件中定义的，而sharedObjectsStruct结构体是在<a href=\"https://github.com/redis/redis/tree/5.0/src/server.h\">server.h</a>中定义的。</p><pre><code>struct sharedObjectsStruct shared;\n\nstruct sharedObjectsStruct {\n    ...\n    robj *del, *unlink,\n    ...\n}\n</code></pre><p>然后，propagateExpire函数在为删除操作创建命令对象时，就使用了shared变量中的unlink或del对象，这部分代码如下所示：</p><pre><code>void propagateExpire(redisDb *db, robj *key, int lazy) {\n    robj *argv[2];\n \n    argv[0] = lazy ? shared.unlink : shared.del;  //如果server启用了lazyfree-lazy-evict，那么argv[0]的值为unlink对象，否则为del对象\n    argv[1] = key; //被淘汰的key对象\n    ...\n}\n</code></pre><p>紧接着，propagateExpire函数会判断Redis server是否启用了AOF日志。如果启用了，那么propagateExpire函数会先把被淘汰key的删除操作记录到AOF文件中，以保证后续使用AOF文件进行Redis数据库恢复时，可以和恢复前保持一致。这一步是通过调用feedAppendOnlyFile函数（在<a href=\"https://github.com/redis/redis/tree/5.0/src/aof.c\">aof.c</a>文件中）来实现的。</p><p>然后，propagateExpire函数会调用replicationFeedSlaves函数（在<a href=\"https://github.com/redis/redis/tree/5.0/src/replication.c\">replication.c</a>文件中），把删除操作同步给从节点，以保证主从节点的数据一致。</p><p>下面代码展示了propagateExpire函数的基本流程，你可以看下。</p><pre><code>    …\n    //如果启用了AOF日志，则将删除操作写入AOF文件\n    if (server.aof_state != AOF_OFF)\n        feedAppendOnlyFile(server.delCommand,db-&gt;id,argv,2);\n    //将删除操作同步给从节点\n\t  replicationFeedSlaves(server.slaves,db-&gt;id,argv,2);\n\t  …\n</code></pre><p>为了便于你更直观地理解这个流程，我也画了一张图，你可以参考下。</p><p><img src=\"https://static001.geekbang.org/resource/image/74/9f/74200fb7ccbcb0cyya8cff7189e5009f.jpg?wh=1852x858\" alt=\"\"></p><p>这样接下来，freeMemoryIfNeeded函数就会开始执行删除操作。</p><p><strong>第二步</strong>，freeMemoryIfNeeded函数会根据server是否启用了惰性删除，分别执行两个分支。</p><ul>\n<li>分支一：如果server启用了惰性删除，freeMemoryIfNeeded函数会调用dbAsyncDelete函数进行异步删除。</li>\n<li>分支二：如果server未启用惰性删除，freeMemoryIfNeeded函数会调用dbSyncDelete函数进行同步删除。</li>\n</ul><p>而无论是执行异步删除还是同步删除，freeMemoryIfNeeded函数都会在调用删除函数前，调用<strong>zmalloc_used_memory函数</strong>（在<a href=\"http://github.com/redis/redis/tree/5.0/src/zmalloc.c\">zmalloc.c</a>文件中）计算当前使用的内存量。然后，它在调用删除函数后，会再次调用zmalloc_used_memory函数计算此时的内存使用量，并计算删除操作导致的内存使用量差值，这个差值就是通过删除操作而被释放的内存量。</p><p>所以，freeMemoryIfNeeded函数最后会把这部分释放的内存量和已释放的内存量相加，得到最新的内存释放量。这部分的执行逻辑如以下代码所示：</p><pre><code>delta = (long long) zmalloc_used_memory(); //获取当前内存使用量\nif (server.lazyfree_lazy_eviction)\n      dbAsyncDelete(db,keyobj);  //如果启用了惰性删除，则进行异步删除\nelse\n     dbSyncDelete(db,keyobj); //否则，进行同步删除\ndelta -= (long long) zmalloc_used_memory(); //根据当前内存使用量计算数据删除前后释放的内存量\nmem_freed += delta; //更新已释放的内存量\n</code></pre><p>所以到这里，我们就知道了freeMemoryIfNeeded函数在选定被删除的键值对后，可以通过异步或同步操作来完成数据的实际删除。那么，<strong>数据异步删除和同步删除具体又是如何执行的呢？</strong></p><p>下面，我们就来具体了解下。</p><h2>数据删除操作</h2><p>在学习数据异步或同步删除之前，你首先需要知道，删除操作实际上是包括了两步子操作。</p><ul>\n<li>子操作一：将被淘汰的键值对从哈希表中去除，这里的哈希表既可能是设置了过期key的哈希表，也可能是全局哈希表。</li>\n<li>子操作二：释放被淘汰键值对所占用的内存空间。</li>\n</ul><p>也就是说，如果这两个子操作一起做，那么就是<strong>同步删除</strong>；如果只做了子操作一，而子操作二由后台线程来执行，那么就是<strong>异步删除</strong>。</p><p>那么对于Redis源码来说，它是使用了<strong>dictGenericDelete函数</strong>，来实现前面介绍的这两个子操作。dictGenericDelete函数是在dict.c文件中实现的，下面我们就来了解下它的具体执行过程。</p><p><strong>首先，dictGenericDelete函数会先在哈希表中查找要删除的key。</strong>它会计算被删除key的哈希值，然后根据哈希值找到key所在的哈希桶。</p><p>因为不同key的哈希值可能相同，而Redis的哈希表是采用了链式哈希（你可以回顾下<a href=\"https://time.geekbang.org/column/article/400379\">第3讲</a>中介绍的链式哈希），所以即使我们根据一个key的哈希值，定位到了它所在的哈希桶，我们也仍然需要在这个哈希桶中去比对查找，这个key是否真的存在。</p><p>也正是由于这个原因，dictGenericDelete函数紧接着就会在哈希桶中，进一步比对查找要删除的key。如果找到了，它就先把这个key从哈希表中去除，也就是把这个key从哈希桶的链表中去除。</p><p><strong>然后，dictGenericDelete函数会根据传入参数nofree的值，决定是否实际释放key和value的内存空间。</strong>dictGenericDelete函数中的这部分执行逻辑如下所示：</p><pre><code>h = dictHashKey(d, key); //计算key的哈希值\nfor (table = 0; table &lt;= 1; table++) {\n   idx = h &amp; d-&gt;ht[table].sizemask;  //根据key的哈希值获取它所在的哈希桶编号\n   he = d-&gt;ht[table].table[idx];   //获取key所在哈希桶的第一个哈希项\n   prevHe = NULL;\n   while(he) {   //在哈希桶中逐一查找被删除的key是否存在\n      if (key==he-&gt;key || dictCompareKeys(d, key, he-&gt;key)) {\n         //如果找见被删除key了，那么将它从哈希桶的链表中去除\n         if (prevHe)\n            prevHe-&gt;next = he-&gt;next;\n         else\n            d-&gt;ht[table].table[idx] = he-&gt;next;\n          if (!nofree) {  //如果要同步删除，那么就释放key和value的内存空间\n             dictFreeKey(d, he); //调用dictFreeKey释放\n             dictFreeVal(d, he);\n             zfree(he);\n           }\n           d-&gt;ht[table].used--;\n           return he;\n      }\n      prevHe = he;\n       he = he-&gt;next;   //当前key不是要查找的key，再找下一个\n   }\n   ...\n}\n</code></pre><p>那么，从dictGenericDelete函数的实现中，你可以发现，dictGenericDelete函数实际上会根据nofree参数，来决定执行的是同步删除还是异步删除。而Redis源码在dictGenericDelete函数的基础上，还封装了<strong>两个函数dictDelete和dictUnlink</strong>。</p><p>这两个函数的区别就在于，它们给dictGenericDelete函数传递的nofree参数值是0，还是1。如果其中nofree的值为0，表示的就是同步删除，而nofree值为1，表示的则是异步删除。</p><p>下面的代码展示了dictGenericDelete函数原型，以及dictDelete和dictUnlink两个函数的实现，你可以看下。</p><pre><code>//dictGenericDelete函数原型，参数是待查找的哈希表，待查找的key，以及同步/异步删除标记\nstatic dictEntry *dictGenericDelete(dict *d, const void *key, int nofree) \n\n//同步删除函数，传给dictGenericDelete函数的nofree值为0\nint dictDelete(dict *ht, const void *key) {\n    return dictGenericDelete(ht,key,0) ? DICT_OK : DICT_ERR;\n}\n\n//异步删除函数，传给dictGenericDelete函数的nofree值为1\ndictEntry *dictUnlink(dict *ht, const void *key) {\n    return dictGenericDelete(ht,key,1);\n}\n</code></pre><p>好了，到这里，我们就了解了同步删除和异步删除的基本代码实现。下面我们就再来看下，在刚才介绍的freeMemoryIfNeeded函数中，它在删除键值对时，所调用的dbAsyncDelete和dbSyncDelete这两个函数，是如何使用dictDelete和dictUnlink来实际删除被淘汰数据的。</p><h3>基于异步删除的数据淘汰</h3><p>我们先来看下基于异步删除的数据淘汰过程。这个过程是由<strong>dbAsyncDelete函数</strong>执行的，它是在<a href=\"http://github.com/redis/redis/tree/5.0/src/lazyfree.c\">lazyfree.c</a>文件中实现的。而这个函数的执行逻辑其实并不复杂，主要可以分成三步。</p><p><strong>第一步</strong>，dbAsyncDelete函数会调用dictDelete函数，在过期key的哈希表中同步删除被淘汰的键值对，如下所示：</p><pre><code> if (dictSize(db-&gt;expires) &gt; 0) dictDelete(db-&gt;expires,key-&gt;ptr);\n</code></pre><p><strong>第二步</strong>，dbAsyncDelete函数会调用dictUnlink函数，在全局哈希表中异步删除被淘汰的键值对，如下所示：</p><pre><code>dictEntry *de = dictUnlink(db-&gt;dict,key-&gt;ptr);\n</code></pre><p>而到这里，被淘汰的键值对只是在全局哈希表中被移除了，它占用的内存空间还没有实际释放。所以此时，dbAsyncDelete函数会<strong>调用lazyfreeGetFreeEffort函数，来计算释放被淘汰键值对内存空间的开销</strong>。如果开销较小，dbAsyncDelete函数就直接在主IO线程中进行同步删除了。否则的话，dbAsyncDelete函数会创建惰性删除任务，并交给后台线程来完成。</p><p>这里，你需要注意的是，虽然dbAsyncDelete函数说是执行惰性删除，但其实，它在实际执行的过程中，会使用前面提到的这个lazyfreeGetFreeEffort函数来评估删除开销。</p><p>lazyfreeGetFreeEffort函数是在lazyfree.c文件中实现的，它对删除开销的评估逻辑很简单，就是根据<strong>要删除的键值对的类型</strong>，来计算删除开销。当键值对类型属于List、Hash、Set和Sorted Set这四种集合类型中的一种，并且没有使用紧凑型内存结构来保存的话，那么，这个键值对的删除开销就等于集合中的元素个数。否则的话，删除开销就等于1。</p><p>我举个简单的例子，以下代码就展示了lazyfreeGetFreeEffort函数，计算List和Set类型键值对的删除开销。可以看到，当键值对是Set类型，同时它是使用哈希表结构而不是整数集合来保存数据的话，那么它的删除开销就是Set中的元素个数。</p><pre><code>size_t lazyfreeGetFreeEffort(robj *obj) {\n    if (obj-&gt;type == OBJ_LIST) {  //如果是List类型键值对，就返回List的长度，也就其中元素个数\n        quicklist *ql = obj-&gt;ptr;\n        return ql-&gt;len;\n    } else if (obj-&gt;type == OBJ_SET &amp;&amp; obj-&gt;encoding == OBJ_ENCODING_HT) {\n        dict *ht = obj-&gt;ptr;\n        return dictSize(ht);   //如果是Set类型键值对，就返回Set中的元素个数\n    }\n    ...\n}\n</code></pre><p>这样，当dbAsyncDelete函数通过lazyfreeGetFreeEffort函数，计算得到被淘汰键值对的删除开销之后，接下来的<strong>第三步</strong>，它就会把删除开销和宏定义LAZYFREE_THRESHOLD（在lazyfree.c文件中）进行比较，这个宏定义的默认值是64。</p><p>所以，当被淘汰键值对是包含超过64个元素的集合类型时，dbAsyncDelete函数才会调用bioCreateBackgroundJob函数，来实际创建后台任务执行惰性删除。关于bioCreateBackgroundJob函数的作用和工作机制，我在<a href=\"https://time.geekbang.org/column/article/409927\">第12讲</a>中已经给你介绍过了，你可以再去回顾下。</p><p>不过，如果被淘汰键值对不是集合类型，或者是集合类型但包含的元素个数小于等于64个，那么dbAsyncDelete函数就直接调用<strong>dictFreeUnlinkedEntry函数</strong>（在dict.c文件中），来释放键值对所占的内存空间了。</p><p>以下代码就展示了dbAsyncDelete函数，使用后台任务或主IO线程释放内存空间的逻辑，你可以看下。</p><pre><code>//如果要淘汰的键值对包含超过64个元素\nif (free_effort &gt; LAZYFREE_THRESHOLD &amp;&amp; val-&gt;refcount == 1) {\n   atomicIncr(lazyfree_objects,1);\n   bioCreateBackgroundJob(BIO_LAZY_FREE,val,NULL,NULL); //创建惰性删除的后台任务，交给后台线程执行\n   dictSetVal(db-&gt;dict,de,NULL);  //将被淘汰键值对的value设置为NULL\n}\n\nif (de) {\n   dictFreeUnlinkedEntry(db-&gt;dict,de);\n   ...\n   return 1;\n}\n</code></pre><p>另外，你也可以根据下图来整体回顾下这个执行过程。</p><p><img src=\"https://static001.geekbang.org/resource/image/2e/cb/2ec7fcd7a52f4d5e1f2cf78bd44e5acb.jpg?wh=2000x916\" alt=\"\"></p><p>好，那么现在，我们也就了解了基于异步删除的数据淘汰过程，实际上会根据要删除的键值对包含的元素个数，来决定是实际使用后台线程还是主线程来进行删除操作。</p><p>不过，如果是使用了后台线程来释放内存，那么随之带来的一个问题就是：<strong>主线程如何知道后台线程释放的内存空间，已经满足待释放空间的大小呢？</strong></p><p>其实，freeMemoryIfNeeded函数本身在调用dbAsyncDelete或dbSyncDelete函数的前后，都会统计已经使用的内存量，并计算调用删除函数前后的差值，这样其实就可以获得已经释放的内存空间大小。</p><p>而除此之外，freeMemoryIfNeeded函数还会在调用dbAsyncDelete函数后，再次主动检测当前的内存使用量，是否已经满足最大内存容量要求。一旦满足了，freeMemoryIfNeeded函数就会停止淘汰数据的执行流程了。这步的执行逻辑，你可以参考以下给出的代码：</p><pre><code>int freeMemoryIfNeeded(void) {\n...\n//执行循环流程，删除淘汰数据\nwhile (mem_freed &lt; mem_tofree) {\n...\n//如果使用了惰性删除，并且每删除16个key后，统计下当前内存使用量\nif (server.lazyfree_lazy_eviction &amp;&amp; !(keys_freed % 16)) {\n   //计算当前内存使用量是否不超过最大内存容量\n   if (getMaxmemoryState(NULL,NULL,NULL,NULL) == C_OK) {\n      mem_freed = mem_tofree;  //如果满足最大容量要求，让已释放内存量等于待释放量，以便结束循环\n   }\n}\n...\n}}\n</code></pre><p>到这里，我们就了解了基于异步删除的数据淘汰实现过程。接下来，我们再来看下基于同步删除的数据淘汰实现。</p><h3>基于同步删除的数据淘汰</h3><p>其实，和基于异步删除的数据淘汰过程相比，基于同步删除的数据淘汰过程就比较简单了。这个过程是由<strong>dbSyncDelete函数</strong>（在db.c文件中）实现的。</p><p>dbSyncDelete函数主要是实现了两步操作。首先，它会调用dictDelete函数，在过期key的哈希表中删除被淘汰的键值对。紧接着，它会再次调用dictDelete函数，在全局哈希表中删除被淘汰的键值对。这样一来，同步删除的基本操作就完成了。</p><p>不过，<strong>这里你需要注意的是</strong>，dictDelete函数通过调用dictGenericDelete函数，来同步释放键值对的内存空间时，最终是通过分别调用dictFreeKey、dictFreeVal和zfree三个函数来释放key、value和键值对对应哈希项这三者占用的内存空间的。</p><p>其中，zfree函数是在zmalloc.c文件中实现的。而dictFreeKey、dictFreeVal这两个函数是在dict.h文件中定义的两个宏定义。它们的具体实现是根据操作的哈希表类型，调用相应的valDestructor函数和keyDestructor函数来释放内存。你可以看看下面的代码，其中就展示了dictFreeKey和dictFreeVal的宏定义。</p><pre><code>#define dictFreeVal(d, entry) \\\n    if ((d)-&gt;type-&gt;valDestructor) \\\n        (d)-&gt;type-&gt;valDestructor((d)-&gt;privdata, (entry)-&gt;v.val)\n\n#define dictFreeKey(d, entry) \\\n    if ((d)-&gt;type-&gt;keyDestructor) \\\n        (d)-&gt;type-&gt;keyDestructor((d)-&gt;privdata, (entry)-&gt;key)\n</code></pre><p>那么，为了方便你能找到最终进行内存释放操作的函数，下面我就<strong>以全局哈希表为例</strong>，来带你看下当操作全局哈希表时，键值对的dictFreeVal和dictFreeKey两个宏定义对应的函数。</p><p>首先，全局哈希表是在initServer函数中创建的。在创建时，全局哈希表的类型是dbDictType，如下所示：</p><pre><code>void initServer(void) {\n...\n for (j = 0; j &lt; server.dbnum; j++) {\n        server.db[j].dict = dictCreate(&amp;dbDictType,NULL);\n        server.db[j].expires = dictCreate(&amp;keyptrDictType,NULL);\n        ...\n}\n...\n}\n</code></pre><p>其中，dbDictType是一个dictType类型的结构体，dictType类型是在dict.h文件中定义的。它的最后两个成员变量，就是keyDestructor函数指针和valDestructor函数指针，如下所示：</p><pre><code>typedef struct dictType {\n    ...\n    void (*keyDestructor)(void *privdata, void *key);\n    void (*valDestructor)(void *privdata, void *obj);\n} dictType;\n</code></pre><p>然后，对于dbDictType来说，它是在server.c文件中定义的。因为它作为全局哈希表，保存的是SDS类型的key，以及多种数据类型的value。所以，dbDictType类型哈希表的key和value释放函数，实际上分别是dictSdsDestructor函数和dictObjectDestructor函数，如下所示：</p><pre><code>dictType dbDictType = {\n    ...\n    dictSdsDestructor,          //key的释放函数\n    dictObjectDestructor      //value的释放函数\n};\n</code></pre><p>这两个函数都是在server.c文件中实现的。</p><p>其中，dictSdsDestructor函数主要是直接调用sdsfree函数（在sds.c文件中），释放SDS字符串占用的内存空间。而dictObjectDestructor函数会调用decrRefCount函数（在object.c文件中），来执行释放操作，如下所示：</p><pre><code>void dictObjectDestructor(void *privdata, void *val)\n{\n    ...\n    decrRefCount(val);\n}\n</code></pre><p>那么在这里，你要知道的是，<strong>decrRefCount函数在执行时，会判断待释放对象的引用计数。</strong>只有当引用计数为1了，它才会根据待释放对象的类型，调用具体类型的释放函数来释放内存空间。否则的话，decrRefCount函数就只是把待释放对象的引用计数减1。</p><p>现在，我们来举个例子。如果待释放对象的引用计数为1，并且是String类型的话，那么decrRefCount函数就会调用freeStringObject函数，来执行最终的内存释放操作。而如果对象是List类型，那么decrRefCount函数则会调用freeListObject函数，来最终释放内存。这部分代码如下所示：</p><pre><code>void decrRefCount(robj *o) {\n    if (o-&gt;refcount == 1) {\n        switch(o-&gt;type) {\n        case OBJ_STRING: freeStringObject(o); break;\n        case OBJ_LIST: freeListObject(o); break;\n        ...\n        }\n        zfree(o);\n    } else {\n        ...\n        if (o-&gt;refcount != OBJ_SHARED_REFCOUNT) o-&gt;refcount--;\n    }\n}\n</code></pre><p>我也画了一张图，来展示decrRefCount函数的基本执行逻辑，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/1e/74/1e242ba4cf7bc7b5a34543bfea6d7474.jpg?wh=2000x865\" alt=\"\"></p><p>所以说，基于同步删除的数据淘汰过程，其实就是通过dictDelete函数，将被淘汰键值对从全局哈希表移除，并通过dictFreeKey、dictFreeVal和zfree三个函数来释放内存空间。而通过以上内容的学习，你就已经知道释放value空间的函数是decrRefCount函数，它会根据value的引用计数和类型，最终调用不同数据类型的释放函数来完成内存空间的释放。</p><p>而在这里，你也要注意的是，基于异步删除的数据淘汰，它通过后台线程执行的函数是<strong>lazyfreeFreeObjectFromBioThread函数</strong>（在lazyfree.c文件），而这个函数实际上也是调用了decrRefCount函数，来释放内存空间的。</p><h2>小结</h2><p>今天这节课，我给你介绍了Redis缓存在淘汰数据时，执行的数据删除流程。因为在Redis 4.0版本之后提供了惰性删除的功能，所以Redis缓存淘汰数据的时候，就会根据是否启用惰性删除，来决定是执行同步删除还是异步的惰性删除。</p><p>而你要知道，无论是同步删除还是异步的惰性删除，它们都会先把被淘汰的键值对从哈希表中移除。然后，同步删除就会紧接着调用dictFreeKey、dictFreeVal和zfree三个函数来分别释放key、value和键值对哈希项的内存空间。而异步的惰性删除，则是把空间释放任务交给了后台线程来完成。</p><p>注意，虽然惰性删除是由后台线程异步完成的，但是后台线程启动后会监听惰性删除的任务队列，一旦有了惰性删除任务，后台线程就会执行并释放内存空间。所以，从淘汰数据释放内存空间的角度来说，<strong>惰性删除并不会影响缓存淘汰时的空间释放要求</strong>。</p><p>不过在最后，我也想提醒你一下，就是后台线程需要<strong>通过同步机制获取任务</strong>，这个过程会引入一些额外的时间开销，会导致内存释放不像同步删除那样非常及时。实际上，这也是Redis在被淘汰数据是小集合（元素不超过64个）时，仍然使用主线程进行内存释放的设计考虑因素。</p><h2>每课一问</h2><p>请你思考一下，freeMemoryIfNeeded函数在使用后台线程，删除被淘汰数据的过程中，主线程是否仍然可以处理外部请求呢？</p><p>欢迎在留言区写下你的答案和思考。如果觉得有收获，也欢迎你把今天的内容分享给更多的朋友。</p>","neighbors":{"left":{"article_title":"16 | LFU算法和其他算法相比有优势吗？","id":413038},"right":{"article_title":"期中测试 | 这些Redis源码知识，你都掌握了吗？","id":417936}}},{"article_id":417936,"article_title":"期中测试 | 这些Redis源码知识，你都掌握了吗？","article_content":"<p>你好，我是蒋德钧。</p><p>时间过得真快，从7月26日上线到现在，我们已经走过了一个半月的学习之旅，不知道你的收获如何呢？</p><p>前面我其实也说过，阅读和学习Redis源码确实是一个比较烧脑的任务，需要你多花些时间钻研。而从我的经验来看，阶段性的验证和总结是非常重要的。所以在这里，我特别设置了期中考试周，从9月13日开始到9月19日结束，这期间我们会暂停更新正文内容，你可以好好利用这一周的时间，去回顾一下前20讲的知识，做一个巩固。</p><p>有标准才有追求，有追求才有动力，有动力才有进步。一起来挑战一下吧，开启你的期中考试之旅。</p><p>我给你出了一套测试题，包括一套选择题和一套问答题。</p><ul>\n<li>选择题：满分共 100 分，包含4道单选题和6道多选题。提交试卷之后，系统会自动评分。</li>\n<li>问答题：包括2道题目，不计入分数，但我希望你能认真回答这些问题，可以把你的答案写在留言区。在9月16日这一天，我会公布答案。</li>\n</ul><h3>选择题</h3><p><a href=\"http://time.geekbang.org/quiz/intro?act_id=926&exam_id=2699\"><img src=\"https://static001.geekbang.org/resource/image/28/a4/28d1be62669b4f3cc01c36466bf811a4.png\" alt=\"\"></a></p><h3>问答题</h3><p><strong>第一题</strong></p><p>Redis源码中实现的哈希表在rehash时，会调用dictRehash函数。dictRehash函数的原型如下，它的参数n表示本次rehash要搬移n个哈希桶（bucket）中的数据。假设dictRehash被调用，并且n的传入值为10。但是，在dictRehash查找的10个bucket中，前5个bucket有数据，而后5个bucket没有数据，那么，本次调用dictRehash是否就只搬移了前5个bucket中的数据？</p><!-- [[[read_end]]] --><pre><code>int dictRehash(dict *d, int n) \n</code></pre><p><strong>第二题</strong></p><p>Redis的事件驱动框架是基于操作系统IO多路复用机制进行了封装，以Linux的epoll机制为例，该机制调用epoll_create函数创建epoll实例，再调用epoll_ctl将监听的套接字加入监听列表，最后调用epoll_wait获取就绪的套接字再进行处理。请简述Redis事件驱动框架中哪些函数和epoll机制各主要函数有对应的调用关系。</p><p>好了，这节课就到这里。希望你能抓住期中周的机会，查漏补缺，快速提升Redis源码的阅读和学习能力。我们下节课再见！</p>","neighbors":{"left":{"article_title":"17 | Lazy Free会影响缓存替换吗？","id":413997},"right":{"article_title":"期中测试题答案 | 这些问题你都答对了吗？","id":418672}}},{"article_id":418672,"article_title":"期中测试题答案 | 这些问题你都答对了吗？","article_content":"<p>你好，我是蒋德钧。这节课，我来给你公布一下期中考试中问答题的答案。</p><h2>第一题</h2><p>Redis源码中实现的哈希表在rehash时，会调用dictRehash函数。dictRehash函数的原型如下，它的参数n表示本次rehash要搬移n个哈希桶（bucket）中的数据。假设dictRehash被调用，并且n的传入值为10。但是，在dictRehash查找的10个bucket中，前5个bucket有数据，而后5个bucket没有数据，那么，本次调用dictRehash是否就只搬移了前5个bucket中的数据？</p><pre><code class=\"language-plain\">int dictRehash(dict *d, int n) \n</code></pre><h3>答案分析</h3><p>当Redis哈希表在做rehash搬移数据时，如果遇到空的bucket，那么Redis会跳过空的bucket，再查找下一个bucket。但是，在dictRehash函数中，是使用了empty_visits变量，来记录跳过的空bucket数量，而empty_visits的值是被初始化成n*10，也就是要搬移的bucket数量的10倍。</p><p>因此，如果rehash过程中已经跳过了empty_visits数量的空bucket，那么本次dictRehash的执行就会直接返回了，而不会再查找bucket。这样设计的目的，也是为了<strong>避免本次rehash的执行一直无法结束，影响正常的请求处理</strong>。</p><!-- [[[read_end]]] --><p>所以，在题述场景中，dictRehash函数会在找到50个空bucket时，直接结束执行，即使此时还没有完成10个bucket数据的搬移。而如果在查找的10个bucket后面，紧接着就有5个bucket有数据，那么本次调用dictRehash仍然搬移了10个bucket的数据。</p><h2>第二题</h2><p>Redis的事件驱动框架是基于操作系统IO多路复用机制进行了封装，以Linux的epoll机制为例，该机制调用epoll_create函数创建epoll实例，再调用epoll_ctl将监听的套接字加入监听列表，最后调用epoll_wait获取就绪的套接字再进行处理。请简述Redis事件驱动框架中哪些函数和epoll机制各主要函数有对应的调用关系。</p><h3>答案分析</h3><p>Redis在initServer函数中，调用了aeCreateEventLoop函数初始化事件框架，其中，aeCreateEventLoop函数会调用aeApiCreate函数，而如果IO多路复用机制使用的是epoll机制，那么aeApiCreate函数就会调用epoll_create函数，创建epoll实例。这个调用关系如下：</p><pre><code class=\"language-plain\">aeCreateEventLoop --&gt; aeApiCreate --&gt; epoll_create\n</code></pre><p>然后，当事件驱动框架初始化完成后，initServer函数就会调用aeCreateFileEvent函数，而aeCreateFileEvent函数会调用aeApiAddEvent函数，进而调用epoll_ctl将监听套接字加入监听列表。这个调用关系为：</p><pre><code class=\"language-plain\">aeCreateFileEvent --&gt; aeApiAddEvent --&gt; epoll_ctl\n</code></pre><p>这样一来，Redis server在完成初始化后，就会调用aeMain函数，进入事件框架的循环流程。在这个流程中，<strong>aeProcessEvents函数</strong>会被循环调用，用于不断处理事件。aeProcessEvents函数会调用aeApiPoll函数，而aeApiPoll函数就会调用epoll_wait，进而获取就绪的套接字，从而可以处理套接字上的事件了。这个调用关系，你可以参考以下代码：</p><pre><code class=\"language-plain\">aeMain --&gt; aeProcessEvents --&gt; aeApiPoll --&gt; epoll_wait\n</code></pre><p>好了，这节课就到这里。期中周转眼就过去了一大半，希望你抓住最后的几天时间，好好地巩固一下所学的内容。我们下节课再见。</p>","neighbors":{"left":{"article_title":"期中测试 | 这些Redis源码知识，你都掌握了吗？","id":417936},"right":{"article_title":"18 | 如何生成和解读RDB文件？","id":415563}}},{"article_id":415563,"article_title":"18 | 如何生成和解读RDB文件？","article_content":"<p>你好，我是蒋德钧。</p><p>从今天这节课开始，我们又将进入一个新的模块，也就是可靠性保证模块。在这个模块中，我会先带你了解Redis数据持久化的实现，其中包括Redis内存快照RDB文件的生成方法，以及AOF日志的记录与重写。了解了这部分内容，可以让你掌握RDB文件的格式，学习到如何制作数据库镜像，并且你也会进一步掌握AOF日志重写对Redis性能的影响。</p><p>然后，我还会围绕Redis主从集群的复制过程、哨兵工作机制和故障切换这三个方面，来给你介绍它们的代码实现。因为我们知道，主从复制是分布式数据系统保证可靠性的一个重要机制，而Redis就给我们提供了非常经典的实现，所以通过学习这部分内容，你就可以掌握到在数据同步实现过程中的一些关键操作和注意事项，以免踩坑。</p><p>好，那么今天这节课，我们就先从RDB文件的生成开始学起。下面呢，我先带你来了解下RDB创建的入口函数，以及调用这些函数的地方。</p><h2>RDB创建的入口函数和触发时机</h2><p>Redis源码中用来创建RDB文件的函数有三个，它们都是在<a href=\"http://github.com/redis/redis/tree/5.0/src/rdb.c\">rdb.c</a>文件中实现的，接下来我就带你具体了解下。</p><ul>\n<li><strong>rdbSave函数</strong></li>\n</ul><p>这是Redis server在本地磁盘创建RDB文件的入口函数。它对应了Redis的save命令，会在save命令的实现函数saveCommand（在rdb.c文件中）中被调用。而rdbSave函数最终会调用rdbSaveRio函数（在rdb.c文件中）来实际创建RDB文件。rdbSaveRio函数的执行逻辑就体现了RDB文件的格式和生成过程，我稍后向你介绍。</p><!-- [[[read_end]]] --><ul>\n<li><strong>rdbSaveBackground函数</strong></li>\n</ul><p>这是Redis server使用后台子进程方式，在本地磁盘创建RDB文件的入口函数。它对应了Redis的bgsave命令，会在bgsave命令的实现函数bgsaveCommand（在rdb.c文件中）中被调用。这个函数会调用fork创建一个子进程，让子进程调用rdbSave函数来继续创建RDB文件，而父进程，也就是主线程本身可以继续处理客户端请求。</p><p>下面的代码展示了rdbSaveBackground函数创建子进程的过程，你可以看下。我在<a href=\"https://time.geekbang.org/column/article/409927\">第12讲</a>中也向你介绍过fork的使用，你可以再回顾下。</p><pre><code>int rdbSaveBackground(char *filename, rdbSaveInfo *rsi) {\n...\nif ((childpid = fork()) == 0) {  //子进程的代码执行分支\n   ...\n   retval = rdbSave(filename,rsi);  //调用rdbSave函数创建RDB文件\n   ...\n   exitFromChild((retval == C_OK) ? 0 : 1);  //子进程退出\n} else {\n   ...  //父进程代码执行分支\n}\n}\n</code></pre><ul>\n<li><strong>rdbSaveToSlavesSockets函数</strong></li>\n</ul><p>这是Redis server在采用不落盘方式传输RDB文件进行主从复制时，创建RDB文件的入口函数。它会被startBgsaveForReplication函数调用（在<a href=\"http://github.com/redis/redis/tree/5.0/src/replication.c\">replication.c</a>文件中）。而startBgsaveForReplication函数会被replication.c文件中的syncCommand函数和replicationCron函数调用，这对应了Redis server执行主从复制命令，以及周期性检测主从复制状态时触发RDB生成。</p><p>和rdbSaveBackground函数类似，rdbSaveToSlavesSockets函数也是通过fork创建子进程，让子进程生成RDB。不过和rdbSaveBackground函数不同的是，rdbSaveToSlavesSockets函数是通过网络<strong>以字节流的形式，直接发送RDB文件的二进制数据给从节点</strong>。</p><p>而为了让从节点能够识别用来同步数据的RDB内容，rdbSaveToSlavesSockets函数调用<strong>rdbSaveRioWithEOFMark函数</strong>（在rdb.c文件中），在RDB二进制数据的前后加上了标识字符串，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/d8/25/d8b79034afb8180721b7978b0063bb25.jpg?wh=2000x412\" alt=\"\"></p><p>以下代码也展示了rdbSaveRioWithEOFMark函数的基本执行逻辑。你可以看到，它除了写入前后标识字符串之外，还是会调用rdbSaveRio函数实际生成RDB内容。</p><pre><code>int rdbSaveRioWithEOFMark(rio *rdb, int *error, rdbSaveInfo *rsi) {\n...\ngetRandomHexChars(eofmark,RDB_EOF_MARK_SIZE); //随机生成40字节的16进制字符串，保存在eofmark中，宏定义RDB_EOF_MARK_SIZE的值为40\nif (rioWrite(rdb,&quot;$EOF:&quot;,5) == 0) goto werr;  //写入$EOF\nif (rioWrite(rdb,eofmark,RDB_EOF_MARK_SIZE) == 0) goto werr; //写入40字节的16进制字符串eofmark\nif (rioWrite(rdb,&quot;\\r\\n&quot;,2) == 0) goto werr; //写入\\r\\n\nif (rdbSaveRio(rdb,error,RDB_SAVE_NONE,rsi) == C_ERR) goto werr; //生成RDB内容\nif (rioWrite(rdb,eofmark,RDB_EOF_MARK_SIZE) == 0) goto werr; //再次写入40字节的16进制字符串eofmark\n...\n}\n</code></pre><p>好了，了解了RDB文件创建的三个入口函数后，我们也看到了，RDB文件创建的三个时机，分别是save命令执行、bgsave命令执行以及主从复制。那么，<strong>除了这三个时机外，在Redis源码中，还有哪些地方会触发RDB文件创建呢？</strong></p><p>实际上，因为rdbSaveToSlavesSockets函数只会在主从复制时调用，所以，我们只要通过在Redis源码中查找<strong>rdbSave、rdbSaveBackground</strong>这两个函数，就可以了解触发RDB文件创建的其他时机。</p><p>那么经过查找，我们可以发现在Redis源码中，rdbSave还会在<strong>flushallCommand函数</strong>（在<a href=\"http://github.com/redis/redis/tree/5.0/src/db.c\">db.c</a>文件中）、<strong>prepareForShutdown函数</strong>（在<a href=\"https://github.com/redis/redis/tree/5.0/src/server.c\">server.c</a>文件中）中被调用。这也就是说，Redis在执行flushall命令以及正常关闭时，会创建RDB文件。</p><p>对于rdbSaveBackground函数来说，它除了在执行bgsave命令时被调用，当主从复制采用落盘文件方式传输RDB时，它也会被startBgsaveForReplication函数调用。此外，Redis server运行时的周期性执行函数serverCron（在<a href=\"https://github.com/redis/redis/tree/5.0/src/server.c\">server.c</a>文件中），也会调用rdbSaveBackground函数来创建RDB文件。</p><p>为了便于你掌握RDB文件创建的整体情况，我画了下面这张图，展示了Redis源码中创建RDB文件的函数调用关系，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/93/a9/939b3b3fb530668d7c91c94cb05510a9.jpg?wh=2000x1125\" alt=\"\"></p><p>好了，到这里，你可以看到，实际最终生成RDB文件的函数是rdbSaveRio。所以接下来，我们就来看看rdbSaveRio函数的执行过程。同时，我还会给你介绍RDB文件的格式是如何组织的。</p><h2>RDB文件是如何生成的？</h2><p>不过在了解rdbSaveRio函数具体是如何生成RDB文件之前，你还需要先了解下RDB文件的基本组成部分。这样，你就可以按照RDB文件的组成部分，依次了解rdbSaveRio函数的执行逻辑了。</p><p>那么，一个RDB文件主要是由三个部分组成的。</p><ul>\n<li><strong>文件头</strong>：这部分内容保存了Redis的魔数、RDB版本、Redis版本、RDB文件创建时间、键值对占用的内存大小等信息。</li>\n<li><strong>文件数据部分</strong>：这部分保存了Redis数据库实际的所有键值对。</li>\n<li><strong>文件尾</strong>：这部分保存了RDB文件的结束标识符，以及整个文件的校验值。这个校验值用来在Redis server加载RDB文件后，检查文件是否被篡改过。</li>\n</ul><p>下图就展示了RDB文件的组成，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/b0/86/b031cb3c43ce9563f07f3ffb591cc486.jpg?wh=1804x1020\" alt=\"\"></p><p>好，接下来，我们就来看看rdbSaveRio函数是如何生成RDB文件中的每一部分的。这里，为了方便你理解RDB文件格式以及文件内容，你可以先按照如下步骤准备一个RDB文件。</p><p>第一步，在你电脑上Redis的目录下，启动一个用来测试的Redis server，可以执行如下命令：</p><pre><code>./redis-server\n</code></pre><p>第二步，执行flushall命令，清空当前的数据库：</p><pre><code>./redis-cli flushall   \n</code></pre><p>第三步，使用redis-cli登录刚启动的Redis server，执行set命令插入一个String类型的键值对，再执行hmset命令插入一个Hash类型的键值对。执行save命令，将当前数据库内容保存到RDB文件中。这个过程如下所示：</p><pre><code>127.0.0.1:6379&gt;set hello redis\nOK\n127.0.0.1:6379&gt;hmset userinfo uid 1 name zs age 32\nOK\n127.0.0.1:6379&gt; save\nOK\n</code></pre><p>好了，到这里，你就可以在刚才执行redis-cli命令的目录下，找见刚生成的RDB文件，文件名应该是dump.rdb。</p><p>不过，因为RDB文件实际是一个二进制数据组成的文件，所以如果你使用一般的文本编辑软件，比如Linux系统上的Vim，在打开RDB文件时，你会看到文件中都是乱码。所以这里，我给你提供一个小工具，如果你想查看RDB文件中二进制数据和对应的ASCII字符，你可以使用<strong>Linux上的od命令</strong>，这个命令可以用不同进制的方式展示数据，并显示对应的ASCII字符。</p><p>比如，你可以执行如下的命令，读取dump.rdb文件，并用十六进制展示文件内容，同时文件中每个字节对应的ASCII字符也会被对应显示出来。</p><pre><code>od -A x -t x1c -v dump.rdb\n</code></pre><p>以下代码展示的就是我用od命令，查看刚才生成的dump.rdb文件后，输出的从文件头开始的部分内容。你可以看到这四行结果中，第一和第三行是用十六进制显示的dump.rdb文件的字节内容，这里每两个十六进制数对应了一个字节。而第二和第四行是od命令生成的每个字节所对应的ASCII字符。</p><p><img src=\"https://static001.geekbang.org/resource/image/09/yy/092af3cc2dcda84307bc2e30a6fc47yy.jpg?wh=2000x775\" alt=\"\"></p><p>这也就是说，在刚才生成的RDB文件中，如果想要转换成ASCII字符，它的文件头内容其实就已经包含了REDIS的字符串和一些数字，而这正是RDB文件头包含的内容。</p><p>那么下面，我们就来看看RDB文件的文件头是如何生成的。</p><h3>生成文件头</h3><p>就像刚才给你介绍的，RDB文件头的内容首先是<strong>魔数</strong>，这对应记录了RDB文件的版本。在rdbSaveRio函数中，魔数是通过snprintf函数生成的，它的具体内容是字符串“REDIS”，再加上RDB版本的宏定义RDB_VERSION（在<a href=\"http://github.com/redis/redis/tree/5.0/src/rdb.h\">rdb.h</a>文件中，值为9）。然后，rdbSaveRio函数会调用rdbWriteRaw函数（在rdb.c文件中），将魔数写入RDB文件，如下所示：</p><pre><code>snprintf(magic,sizeof(magic),&quot;REDIS%04d&quot;,RDB_VERSION);  //生成魔数magic\nif (rdbWriteRaw(rdb,magic,9) == -1) goto werr;  //将magic写入RDB文件\n</code></pre><p>刚才用来写入魔数的<strong>rdbWriteRaw函数</strong>，它实际会调用rioWrite函数（在rdb.h文件中）来完成写入。而rioWrite函数是RDB文件内容的最终写入函数，它负责根据要写入数据的长度，把待写入缓冲区中的内容写入RDB。这里，<strong>你需要注意的是</strong>，RDB文件生成过程中，会有不同的函数负责写入不同部分的内容，不过这些函数最终都还是调用rioWrite函数，来完成数据的实际写入的。</p><p>好了，当在RDB文件头中写入魔数后，rdbSaveRio函数紧接着会调用<strong>rdbSaveInfoAuxFields函数</strong>，将和Redis server相关的一些属性信息写入RDB文件头，如下所示：</p><pre><code>if (rdbSaveInfoAuxFields(rdb,flags,rsi) == -1) goto werr; //写入属性信息\n</code></pre><p>rdbSaveInfoAuxFields函数是在rdb.c文件中实现的，它会使用键值对的形式，在RDB文件头中记录Redis server的属性信息。下表中列出了RDB文件头记录的一些主要信息，以及它们对应的键和值，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/c7/01/c79a8314710d2b74483fd74d58ed5301.jpg?wh=2000x792\" alt=\"\"></p><p>那么，当属性值为字符串时，rdbSaveInfoAuxFields函数会调用<strong>rdbSaveAuxFieldStrStr函数</strong>写入属性信息；而当属性值为整数时，rdbSaveInfoAuxFields函数会调用<strong>rdbSaveAuxFieldStrInt函数</strong>写入属性信息，如下所示：</p><pre><code>if (rdbSaveAuxFieldStrStr(rdb,&quot;redis-ver&quot;,REDIS_VERSION) == -1) return -1;\nif (rdbSaveAuxFieldStrInt(rdb,&quot;redis-bits&quot;,redis_bits) == -1) return -1;\nif (rdbSaveAuxFieldStrInt(rdb,&quot;ctime&quot;,time(NULL)) == -1) return -1;\nif (rdbSaveAuxFieldStrInt(rdb,&quot;used-mem&quot;,zmalloc_used_memory()) == -1) return -1;\n</code></pre><p>这里，无论是rdbSaveAuxFieldStrStr函数还是rdbSaveAuxFieldStrInt函数，<strong>它们都会调用rdbSaveAuxField函数来写入属性值</strong>。rdbSaveAuxField函数是在rdb.c文件中实现的，它会分三步来完成一个属性信息的写入。</p><p><strong>第一步</strong>，它调用rdbSaveType函数写入一个操作码。这个操作码的目的，是用来在RDB文件中标识接下来的内容是什么。当写入属性信息时，这个操作码对应了宏定义RDB_OPCODE_AUX（在rdb.h文件中），值为250，对应的十六进制值为FA。这样一来，就方便我们解析RDB文件了。比如，在读取RDB文件时，如果程序读取到FA这个字节，那么，这就表明接下来的内容是一个属性信息。</p><p>这里，<strong>你需要注意的是</strong>，RDB文件使用了多个操作码，来标识文件中的不同内容。它们都是在rdb.h文件中定义的，下面的代码中展示了部分操作码，你可以看下。</p><pre><code>#define RDB_OPCODE_IDLE       248   //标识LRU空闲时间\n#define RDB_OPCODE_FREQ       249   //标识LFU访问频率信息\n#define RDB_OPCODE_AUX        250   //标识RDB文件头的属性信息\n#define RDB_OPCODE_EXPIRETIME_MS 252    //标识以毫秒记录的过期时间\n#define RDB_OPCODE_SELECTDB   254   //标识文件中后续键值对所属的数据库编号\n#define RDB_OPCODE_EOF        255   //标识RDB文件结束，用在文件尾\n</code></pre><p><strong>第二步</strong>，rdbSaveAuxField函数调用rdbSaveRawString函数（在rdb.c文件中）写入属性信息的键，而键通常是一个字符串。<strong>rdbSaveRawString函数</strong>是用来写入字符串的通用函数，它会先记录字符串长度，然后再记录实际字符串，如下图所示。这个长度信息是为了解析RDB文件时，程序可以基于它知道当前读取的字符串应该读取多少个字节。</p><p><img src=\"https://static001.geekbang.org/resource/image/2f/dd/2f5a8ec2219109178ca74e169d7974dd.jpg?wh=1669x334\" alt=\"\"></p><p>不过，为了节省RDB文件消耗的空间，如果字符串中记录的实际是一个整数，rdbSaveRawString函数还会<strong>调用rdbTryIntegerEncoding函数</strong>（在rdb.c文件中），尝试用<strong>紧凑结构</strong>对字符串进行编码。具体做法你可以进一步阅读rdbTryIntegerEncoding函数。</p><p>下图展示了rdbSaveRawString函数的基本执行逻辑，你可以看下。其中，它调用rdbSaveLen函数写入字符串长度，调用rdbWriteRaw函数写入实际数据。</p><p><img src=\"https://static001.geekbang.org/resource/image/c3/f7/c3be595bb11ce318239eee9a3828bdf7.jpg?wh=2000x986\" alt=\"\"></p><p><strong>第三步</strong>，rdbSaveAuxField函数就需要写入属性信息的值了。因为属性信息的值通常也是字符串，所以和第二步写入属性信息的键类似，rdbSaveAuxField函数会调用rdbSaveRawString函数来写入属性信息的值。</p><p>下面的代码展示了rdbSaveAuxField函数的执行整体过程，你可以再回顾下。</p><pre><code>ssize_t rdbSaveAuxField(rio *rdb, void *key, size_t keylen, void *val, size_t vallen) {\n    ssize_t ret, len = 0;\n    //写入操作码\n    if ((ret = rdbSaveType(rdb,RDB_OPCODE_AUX)) == -1) return -1;\n    len += ret;\n    //写入属性信息中的键\n    if ((ret = rdbSaveRawString(rdb,key,keylen)) == -1) return -1;\n    len += ret;\n    //写入属性信息中的值\n    if ((ret = rdbSaveRawString(rdb,val,vallen)) == -1) return -1;\n    len += ret;\n    return len;\n}\n</code></pre><p>到这里，RDB文件头的内容已经写完了。我把刚才创建的RDB文件头的部分内容，画在了下图当中，并且标识了十六进制对应的ASCII字符以及一些关键信息，你可以结合图例来理解刚才介绍的代码。</p><p><img src=\"https://static001.geekbang.org/resource/image/3b/34/3b7db22a0c7276fbe24afed80a3bc234.jpg?wh=2000x1125\" alt=\"\"></p><p>这样接下来，rdbSaveRio函数就要开始写入实际的键值对了，这也是文件中实际记录数据的部分。下面，我们就来具体看下。</p><h3>生成文件数据部分</h3><p>因为Redis server上的键值对可能被保存在不同的数据库中，所以，<strong>rdbSaveRio函数会执行一个循环，遍历每个数据库，将其中的键值对写入RDB文件</strong>。</p><p>在这个循环流程中，rdbSaveRio函数会先将<strong>SELECTDB操作码</strong>和对应的数据库编号写入RDB文件，这样一来，程序在解析RDB文件时，就可以知道接下来的键值对是属于哪个数据库的了。这个过程如下所示：</p><pre><code>...\nfor (j = 0; j &lt; server.dbnum; j++) { //循环遍历每一个数据库\n...\n//写入SELECTDB操作码\nif (rdbSaveType(rdb,RDB_OPCODE_SELECTDB) == -1) goto werr;\nif (rdbSaveLen(rdb,j) == -1) goto werr;  //写入当前数据库编号j\n...\n</code></pre><p>下图展示了刚才我创建的RDB文件中SELECTDB操作码的信息，你可以看到，数据库编号为0。</p><p><img src=\"https://static001.geekbang.org/resource/image/3c/73/3c3a9cc720506802fa75ba10276d7d73.jpg?wh=1551x461\" alt=\"\"></p><p>紧接着，rdbSaveRio函数会写入<strong>RESIZEDB操作码</strong>，用来标识全局哈希表和过期key哈希表中键值对数量的记录，这个过程的执行代码如下所示：</p><pre><code>...\ndb_size = dictSize(db-&gt;dict);   //获取全局哈希表大小\nexpires_size = dictSize(db-&gt;expires);  //获取过期key哈希表的大小\nif (rdbSaveType(rdb,RDB_OPCODE_RESIZEDB) == -1) goto werr;  //写入RESIZEDB操作码\nif (rdbSaveLen(rdb,db_size) == -1) goto werr;  //写入全局哈希表大小\nif (rdbSaveLen(rdb,expires_size) == -1) goto werr; //写入过期key哈希表大小\n...\n</code></pre><p>我也把刚才创建的RDB文件中，RESIZEDB操作码的内容画在了下图中，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/15/ff/15782167d58b478ffc08a38fca093fff.jpg?wh=1904x502\" alt=\"\"></p><p>你可以看到，在RESIZEDB操作码后，紧接着记录的是全局哈希表中的键值对，它的数量是2，然后是过期key哈希表中的键值对，其数量为0。我们刚才在生成RDB文件前，只插入了两个键值对，所以，RDB文件中记录的信息和我们刚才的操作结果是一致的。</p><p>好了，在记录完这些信息后，rdbSaveRio函数会接着<strong>执行一个循环流程</strong>，在该流程中，rdbSaveRio函数会取出当前数据库中的每一个键值对，并调用rdbSaveKeyValuePair函数（在rdb.c文件中），将它写入RDB文件。这个基本的循环流程如下所示：</p><pre><code> while((de = dictNext(di)) != NULL) {  //读取数据库中的每一个键值对\n    sds keystr = dictGetKey(de);  //获取键值对的key\n    robj key, *o = dictGetVal(de);  //获取键值对的value\n    initStaticStringObject(key,keystr);  //为key生成String对象\n    expire = getExpire(db,&amp;key);  //获取键值对的过期时间\n    //把key和value写入RDB文件\n    if (rdbSaveKeyValuePair(rdb,&amp;key,o,expire) == -1) goto werr;\n    ...\n}\n</code></pre><p>这里，<strong>rdbSaveKeyValuePair函数</strong>主要是负责将键值对实际写入RDB文件。它会先将键值对的过期时间、LRU空闲时间或是LFU访问频率写入RDB文件。在写入这些信息时，rdbSaveKeyValuePair函数都会先调用rdbSaveType函数，写入标识这些信息的操作码，你可以看下下面的代码。</p><pre><code>if (expiretime != -1) {\n    //写入过期时间操作码标识\n   if (rdbSaveType(rdb,RDB_OPCODE_EXPIRETIME_MS) == -1) return -1;\n   if (rdbSaveMillisecondTime(rdb,expiretime) == -1) return -1;\n}\nif (savelru) {\n   ...\n   //写入LRU空闲时间操作码标识\n   if (rdbSaveType(rdb,RDB_OPCODE_IDLE) == -1) return -1;\n   if (rdbSaveLen(rdb,idletime) == -1) return -1;\n}\nif (savelfu) {\n   ...\n   //写入LFU访问频率操作码标识\n   if (rdbSaveType(rdb,RDB_OPCODE_FREQ) == -1) return -1;\n   if (rdbWriteRaw(rdb,buf,1) == -1) return -1;\n}\n</code></pre><p>好了，到这里，rdbSaveKeyValuePair函数就要开始实际写入键值对了。为了便于解析RDB文件时恢复键值对，rdbSaveKeyValuePair函数会先调用rdbSaveObjectType函数，写入键值对的类型标识；然后调用rdbSaveStringObject写入键值对的key；最后，它会调用rdbSaveObject函数写入键值对的value。这个过程如下所示，这几个函数都是在rdb.c文件中实现的：</p><pre><code>if (rdbSaveObjectType(rdb,val) == -1) return -1;  //写入键值对的类型标识\nif (rdbSaveStringObject(rdb,key) == -1) return -1; //写入键值对的key\nif (rdbSaveObject(rdb,val,key) == -1) return -1; //写入键值对的value\n</code></pre><p>这里，你需要注意的是，<strong>rdbSaveObjectType函数会根据键值对的value类型，来决定写入到RDB中的键值对类型标识</strong>，这些类型标识在rdb.h文件中有对应的宏定义。比如，我在刚才创建RDB文件前，写入的键值对分别是String类型和Hash类型，而Hash类型因为它包含的元素个数不多，所以默认采用ziplist数据结构来保存。这两个类型标识对应的数值如下所示：</p><pre><code>#define RDB_TYPE_STRING   0\n#define RDB_TYPE_HASH_ZIPLIST  13\n</code></pre><p>我把刚才写入的String类型键值对“hello”“redis”在RDB文件中对应的记录内容，画在了下图中，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/78/1d/786363a521ae6e3911c8c4002b53331d.jpg?wh=1920x514\" alt=\"\"></p><p>你可以看到，这个键值对的开头类型标识就是0，和刚才介绍的RDB_TYPE_STRING宏定义的值是一致的。而紧接着的key和value，它们都会先记录长度信息，然后才记录实际内容。</p><p>因为键值对的key都是String类型，所以rdbSaveKeyValuePair函数就用rdbSaveStringObject函数来写入了。而键值对的value有不同的类型，所以，rdbSaveObject函数会根据value的类型，执行不同的代码分支，将value底层数据结构中的内容写入RDB。</p><p>好了，到这里，我们就了解了rdbSaveKeyValuePair函数是如何将键值对写入RDB文件中的了。在这个过程中，除了键值对类型、键值对的key和value会被记录以外，键值对的过期时间、LRU空闲时间或是LFU访问频率也都会记录到RDB文件中。这就生成RDB文件的数据部分。</p><p>最后，我们再来看下RDB文件尾的生成。</p><h3>生成文件尾</h3><p>当所有键值对都写入RDB文件后，<strong>rdbSaveRio函数</strong>就可以写入文件尾内容了。文件尾的内容比较简单，主要包括两个部分，一个是RDB文件结束的操作码标识，另一个是RDB文件的校验值。</p><p>rdbSaveRio函数会先调用rdbSaveType函数，写入文件结束操作码RDB_OPCODE_EOF，然后调用rioWrite写入检验值，如下所示：</p><pre><code>...\n//写入结束操作码\nif (rdbSaveType(rdb,RDB_OPCODE_EOF) == -1) goto werr;\n\n//写入校验值\ncksum = rdb-&gt;cksum;\nmemrev64ifbe(&amp;cksum);\nif (rioWrite(rdb,&amp;cksum,8) == 0) goto werr;\n...\n</code></pre><p>下图展示了我刚才生成的RDB文件的文件尾，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/15/15/158b7b6f7315e6376428f9cc3e04a515.jpg?wh=1923x452\" alt=\"\"></p><p>这样，我们也就整体了解了RDB文件从文件头、文件数据部分再到文件尾的整个生成过程了。</p><h2>小结</h2><p>今天这节课，我给你介绍了Redis内存快照文件RDB的生成。你要知道，创建RDB文件的三个入口函数分别是rdbSave、rdbSaveBackground、rdbSaveToSlavesSockets，它们在Redis源码中被调用的地方，也就是触发RDB文件生成的时机。</p><p>另外，你也要重点关注RDB文件的基本组成，并且也要结合rdbSaveRio函数的执行流程，来掌握RDB文件头、文件数据部分和文件尾这三个部分的生成。我总结了以下两点，方便你对RDB文件结构和内容有个整体把握：</p><ul>\n<li>RDB文件使用多种操作码来标识Redis不同的属性信息，以及使用类型码来标识不同value类型；</li>\n<li>RDB文件内容是自包含的，也就是说，无论是属性信息还是键值对，RDB文件都会按照类型、长度、实际数据的格式来记录，这样方便程序对RDB文件的解析。</li>\n</ul><p>最后，我也想再说一下，RDB文件包含了Redis数据库某一时刻的所有键值对，以及这些键值对的类型、大小、过期时间等信息。当你了解了RDB文件的格式和生成方法后，其实你就可以根据需求，开发解析RDB文件的程序或是加载RDB文件的程序了。</p><p>比如，你可以在RDB文件中查找内存空间消耗大的键值对，也就是在优化Redis性能时通常需要查找的bigkey；你也可以分析不同类型键值对的数量、空间占用等分布情况，来了解业务数据的特点；你还可以自行加载RDB文件，用于测试或故障排查。</p><p>当然，这里我也再给你一个小提示，就是在你实际开发RDB文件分析工具之前，可以看下<a href=\"https://github.com/sripathikrishnan/redis-rdb-tools/\">redis-rdb-tools</a>这个工具，它能够帮助你分析RDB文件中的内容。而如果它还不能满足你的定制化需求，你就可以用上这节课学习的内容，来开发自己的RDB分析工具了。</p><h2>每课一问</h2><p>你能在serverCron函数中，查找到rdbSaveBackground函数一共会被调用执行几次吗？这又分别对应了什么场景呢？</p>","neighbors":{"left":{"article_title":"期中测试题答案 | 这些问题你都答对了吗？","id":418672},"right":{"article_title":"19 | AOF重写（上）：触发时机与重写的影响","id":416264}}},{"article_id":416264,"article_title":"19 | AOF重写（上）：触发时机与重写的影响","article_content":"<p>你好，我是蒋德钧。</p><p>我们知道，Redis除了使用内存快照RDB来保证数据可靠性之外，还可以使用AOF日志。不过，RDB文件是将某一时刻的内存数据保存成一个文件，而AOF日志则会记录接收到的所有写操作。如果Redis server的写请求很多，那么AOF日志中记录的操作也会越来越多，进而就导致AOF日志文件越来越大。</p><p>所以，为了避免产生过大的AOF日志文件，Redis会对AOF文件进行重写，也就是针对当前数据库中每个键值对的最新内容，记录它的插入操作，而不再记录它的历史写操作了。这样一来，重写后的AOF日志文件就能变小了。</p><p><strong>那么，AOF重写在哪些时候会被触发呢？以及AOF重写需要写文件，这个过程会阻塞Redis的主线程，进而影响Redis的性能吗？</strong></p><p>今天这节课，我就来给你介绍下AOF重写的代码实现过程，通过了解它的代码实现，我们就可以清楚地了解到AOF重写过程的表现，以及它对Redis server的影响。这样，当你再遇到Redis server性能变慢的问题时，你就可以排查是否是AOF重写导致的了。</p><p>好，接下来，我们先来看下AOF重写函数以及它的触发时机。</p><h2>AOF重写函数与触发时机</h2><p>首先，实现AOF重写的函数是<strong>rewriteAppendOnlyFileBackground</strong>，它是在<a href=\"https://github.com/redis/redis/tree/5.0/src/aof.c\">aof.c</a>文件中实现的。在这个函数中，会调用fork函数创建一个AOF重写子进程，来实际执行重写操作。关于这个函数的具体实现，我稍后会给你详细介绍。这里呢，我们先来看看，这个函数会被哪些函数调用，这样我们就可以了解AOF重写的触发时机了。</p><!-- [[[read_end]]] --><p>实际上，rewriteAppendOnlyFileBackground函数一共会在三个函数中被调用。</p><p><strong>第一个是bgrewriteaofCommand函数。</strong>这个函数是在aof.c文件中实现的，对应了我们在Redis server上执行bgrewriteaof命令，也就是说，我们手动触发了AOF rewrite的执行。</p><p>不过，即使我们手动执行了bgrewriteaof命令，bgrewriteaofCommand函数也会根据以下两个条件，来判断是否实际执行AOF重写。</p><ul>\n<li><strong>条件一：当前是否已经有AOF重写的子进程正在执行。</strong>如果有的话，那么bgrewriteaofCommand函数就不再执行AOF重写了。</li>\n<li><strong>条件二：当前是否有创建RDB的子进程正在执行。</strong>如果有的话，bgrewriteaofCommand函数会把全局变量server的aof_rewrite_scheduled成员变量设置为1，这个标志表明Redis server已经将AOF重写设为待调度运行，等后续条件满足时，它就会实际执行AOF重写（我们一会儿就会看到，当aof_rewrite_scheduled设置为1以后，Redis server会在哪些条件下实际执行重写操作）。</li>\n</ul><p>所以这也就是说，只有当前既没有AOF重写子进程也没有RDB子进程，bgrewriteaofCommand函数才会立即调用rewriteAppendOnlyFileBackground函数，实际执行AOF重写。</p><p>以下代码展示了bgrewriteaofCommand函数的基本执行逻辑，你可以看下。</p><pre><code>void bgrewriteaofCommand(client *c) {\n    if (server.aof_child_pid != -1) {\n        .. //有AOF重写子进程，因此不执行重写\n    } else if (server.rdb_child_pid != -1) {\n        server.aof_rewrite_scheduled = 1; //有RDB子进程，将AOF重写设置为待调度运行\n        ...\n    } else if (rewriteAppendOnlyFileBackground() == C_OK) { //实际执行AOF重写\n        ...\n    } \n    ...\n}\n</code></pre><p><strong>第二个是startAppendOnly函数。</strong>这个函数也是在aof.c文件中实现的，它本身会被configSetCommand函数（在<a href=\"https://github.com/redis/redis/tree/5.0/src/config.c\">config.c</a>文件中）和restartAOFAfterSYNC函数（在<a href=\"https://github.com/redis/redis/tree/5.0/src/replication.c\">replication.c</a>文件中）调用。</p><p>首先，对于configSetCommand函数来说，它对应了我们在Redis中执行config命令启用AOF功能，如下所示：</p><pre><code>config set appendonly yes\n</code></pre><p>这样，一旦AOF功能启用后，configSetCommand函数就会调用startAppendOnly函数，执行一次AOF重写。</p><p>而对于restartAOFAfterSYNC函数来说，它会在主从节点的复制过程中被调用。简单来说，就是当主从节点在进行复制时，如果从节点的AOF选项被打开，那么在加载解析RDB文件时，AOF选项就会被关闭。然后，无论从节点是否成功加载了RDB文件，restartAOFAfterSYNC函数都会被调用，用来恢复被关闭的AOF功能。</p><p>那么在这个过程中，restartAOFAfterSYNC函数就会调用startAppendOnly函数，并进一步调用rewriteAppendOnlyFileBackground函数，来执行一次AOF重写。</p><p>这里你要注意，和bgrewriteaofCommand函数类似，<strong>startAppendOnly函数也会判断当前是否有RDB子进程在执行</strong>，如果有的话，它会将AOF重写设置为待调度执行。除此之外，如果startAppendOnly函数检测到有AOF重写子进程在执行，那么它就会把该子进程先kill掉，然后再调用rewriteAppendOnlyFileBackground函数进行AOF重写。</p><p>所以到这里，我们其实可以发现，无论是bgrewriteaofCommand函数还是startAppendOnly函数，当它们检测到有RDB子进程在执行的时候，就会把aof_rewrite_scheduled变量设置为1，这表示AOF重写操作将在条件满足时再被执行。</p><p><strong>那么，Redis server什么时候会再检查AOF重写操作的条件是否满足呢？</strong>这就和rewriteAppendOnlyFileBackground函数被调用的第三个函数，serverCron函数相关了。</p><p><strong>第三个是serverCron函数。</strong>在Redis server运行时，serverCron函数是会被周期性执行的。然后它在执行的过程中，会做两次判断来决定是否执行AOF重写。</p><p>首先，serverCron函数会检测当前是否<strong>没有RDB子进程和AOF重写子进程在执行</strong>，并检测是否<strong>有AOF重写操作被设置为了待调度执行</strong>，也就是aof_rewrite_scheduled变量值为1。</p><p>如果这三个条件都满足，那么serverCron函数就会调用rewriteAppendOnlyFileBackground函数来执行AOF重写。serverCron函数里面的这部分执行逻辑如下所示：</p><pre><code>//如果没有RDB子进程，也没有AOF重写子进程，并且AOF重写被设置为待调度执行，那么调用rewriteAppendOnlyFileBackground函数进行AOF重写\nif (server.rdb_child_pid == -1 &amp;&amp; server.aof_child_pid == -1 &amp;&amp;\n        server.aof_rewrite_scheduled)\n{\n        rewriteAppendOnlyFileBackground();\n}\n</code></pre><p>事实上，这里的代码也回答了我们刚才提到的问题：待调度执行的AOF重写会在什么时候执行？</p><p>其实，如果AOF重写没法立即执行的话，我们也不用担心。因为<strong>只要aof_rewrite_scheduled变量被设置为1了，那么serverCron函数就默认会每100毫秒执行并检测这个变量值</strong>。所以，如果正在执行的RDB子进程和AOF重写子进程结束了之后，被调度执行的AOF重写就可以很快得到执行。</p><p>其次，即使AOF重写操作没有被设置为待调度执行，serverCron函数也会<strong>周期性判断是否需要执行AOF重写</strong>。这里的判断条件主要有三个，分别是AOF功能已启用、AOF文件大小比例超出阈值，以及AOF文件大小绝对值超出阈值。</p><p>这样一来，当这三个条件都满足时，并且也没有RDB子进程和AOF子进程在运行的话，此时，serverCron函数就会调用rewriteAppendOnlyFileBackground函数执行AOF重写。这部分的代码逻辑如下所示：</p><pre><code>//如果AOF功能启用、没有RDB子进程和AOF重写子进程在执行、AOF文件大小比例设定了阈值，以及AOF文件大小绝对值超出了阈值，那么，进一步判断AOF文件大小比例是否超出阈值\nif (server.aof_state == AOF_ON &amp;&amp; server.rdb_child_pid == -1 &amp;&amp; server.aof_child_pid == -1 &amp;&amp; server.aof_rewrite_perc &amp;&amp; server.aof_current_size &gt; server.aof_rewrite_min_size) {\n   //计算AOF文件当前大小超出基础大小的比例\n   long long base = server.aof_rewrite_base_size ? server.aof_rewrite_base_size : 1;\n   long long growth = (server.aof_current_size*100/base) - 100;\n   //如果AOF文件当前大小超出基础大小的比例已经超出预设阈值，那么执行AOF重写\n   if (growth &gt;= server.aof_rewrite_perc) {\n      ...\n      rewriteAppendOnlyFileBackground();\n   }\n}\n</code></pre><p>那么，从这里的代码中，你会看到，为了避免AOF文件过大导致占用过多的磁盘空间，以及增加恢复时长，你其实可以通过设置redis.conf文件中的以下两个阈值，来让Redis server自动重写AOF文件。</p><ul>\n<li><strong>auto-aof-rewrite-percentage</strong>：AOF文件大小超出基础大小的比例，默认值为100%，即超出1倍大小。</li>\n<li><strong>auto-aof-rewrite-min-size</strong>：AOF文件大小绝对值的最小值，默认为64MB。</li>\n</ul><p>好了，到这里，我们就了解了AOF重写的四个触发时机，这里我也给你总结下，方便你回顾复习。</p><ul>\n<li>时机一：bgrewriteaof命令被执行。</li>\n<li>时机二：主从复制完成RDB文件解析和加载（无论是否成功）。</li>\n<li>时机三：AOF重写被设置为待调度执行。</li>\n<li>时机四：AOF被启用，同时AOF文件的大小比例超出阈值，以及AOF文件的大小绝对值超出阈值。</li>\n</ul><p>另外，这里你还需要注意，在这四个时机下，其实都不能有正在执行的RDB子进程和AOF重写子进程，否则的话，AOF重写就无法执行了。</p><p>所以接下来，我们就来学习下AOF重写的基本执行过程。</p><h2>AOF重写的基本过程</h2><p>首先，我们再来看下刚才介绍的rewriteAppendOnlyFileBackground函数。这个函数的主体逻辑比较简单，一方面，它会通过调用fork函数创建一个子进程，然后在子进程中调用rewriteAppendOnlyFile函数进行AOF文件重写。</p><p>rewriteAppendOnlyFile函数是在aof.c文件中实现的。它主要会调用<strong>rewriteAppendOnlyFileRio函数</strong>（在aof.c文件中）来完成AOF日志文件的重写。具体来说，就是rewriteAppendOnlyFileRio函数会遍历Redis server的每一个数据库，把其中的每个键值对读取出来，然后记录该键值对类型对应的插入命令，以及键值对本身的内容。</p><p>比如，如果读取的是一个String类型的键值对，那么rewriteAppendOnlyFileRio函数，就会记录SET命令和键值对本身内容；而如果读取的是Set类型键值对，那么它会记录SADD命令和键值对内容。这样一来，当需要恢复Redis数据库时，我们重新执行一遍AOF重写日志中记录的命令操作，就可以依次插入所有键值对了。</p><p>另一方面，在父进程中，这个rewriteAppendOnlyFileBackground函数会<strong>把aof_rewrite_scheduled变量设置为0</strong>，同时记录AOF重写开始的时间，以及记录AOF子进程的进程号。</p><p>此外，rewriteAppendOnlyFileBackground函数还会调用<strong>updateDictResizePolicy函数</strong>，禁止在AOF重写期间进行rehash操作。这是因为rehash操作会带来较多的数据移动操作，对于AOF重写子进程来说，这就意味着父进程中的内存修改会比较多。因此，AOF重写子进程就需要执行更多的写时复制，进而完成AOF文件的写入，这就会给Redis系统的性能造成负面影响。</p><p>以下代码就展示了rewriteAppendOnlyFileBackground函数的基本执行逻辑，你可以看下。</p><pre><code>int rewriteAppendOnlyFileBackground(void) {\n   ...\n   if ((childpid = fork()) == 0) {  //创建子进程\n      ...\n      //子进程调用rewriteAppendOnlyFile进行AOF重写\n      if (rewriteAppendOnlyFile(tmpfile) == C_OK) {\n            size_t private_dirty = zmalloc_get_private_dirty(-1);\n            ...\n            exitFromChild(0);\n        } else {\n            exitFromChild(1);\n        }\n   }\n   else{ //父进程执行的逻辑\n      ...\n      server.aof_rewrite_scheduled = 0;  \n      server.aof_rewrite_time_start = time(NULL);\n      server.aof_child_pid = childpid; //记录重写子进程的进程号\n      updateDictResizePolicy(); //关闭rehash功能\n}\n</code></pre><p>而从这里，你可以看到，AOF重写和RDB创建是比较类似的，它们都会创建一个子进程来遍历所有的数据库，并把数据库中的每个键值对记录到文件中。不过，AOF重写和RDB文件又有两个不同的地方：</p><ul>\n<li>一是，AOF文件中是以“命令+键值对”的形式，来记录每个键值对的插入操作，而RDB文件记录的是键值对数据本身；</li>\n<li>二是，在AOF重写或是创建RDB的过程中，主进程仍然可以接收客户端写请求。不过，因为RDB文件只需要记录某个时刻下数据库的所有数据就行，而AOF重写则需要尽可能地把主进程收到的写操作，也记录到重写的日志文件中。所以，AOF重写子进程就需要有相应的机制来和主进程进行通信，以此来接收主进程收到的写操作。</li>\n</ul><p>下图就展示了rewriteAppendOnlyFileBackground函数执行的基本逻辑、主进程和AOF重写子进程各自执行的内容，以及主进程和子进程间的通信过程，你可以再来整体回顾下。</p><p><img src=\"https://static001.geekbang.org/resource/image/01/dd/01ce2381652fee284c081f7a376006dd.jpg?wh=2000x1125\" alt=\"\"></p><p>到这里，我们就大概掌握了AOF重写的基本执行过程。但是在这里，你可能还会有疑问，比如说，AOF重写的子进程和父进程，它们之间的通信过程是怎么样的呢？</p><p>其实，这个通信过程是通过操作系统的<strong>管道机制</strong>（pipe）来实现的，不过你也别着急，这部分内容，我会在下一讲给你详细介绍。</p><h2>小结</h2><p>今天这节课我给你介绍了Redis AOF重写机制的实现，你需要重点关注以下两个要点：</p><ul>\n<li><strong>AOF重写的触发时机</strong>。这既包括了我们主动执行bgrewriteaof命令，也包括了Redis server根据AOF文件大小而自动触发的重写。此外，在主从复制的过程中，从节点也会启动AOF重写，形成一份完整的AOF日志，以便后续进行恢复。当然你也要知道，当要触发AOF重写时，Redis server是不能运行RDB子进程和AOF重写子进程的。</li>\n<li><strong>AOF重写的基本执行过程</strong>。AOF重写和RDB创建的过程类似，它也是创建了一个子进程来完成重写工作。这是因为AOF重写操作，实际上需要遍历Redis server上的所有数据库，把每个键值对以插入操作的形式写入日志文件，而日志文件又要进行写盘操作。所以，Redis源码使用子进程来实现AOF重写，这就避免了阻塞主线程，也减少了对Redis整体性能的影响。</li>\n</ul><p>不过，你需要注意的是，虽然AOF重写和RDB创建都用了子进程，但是它们也有不同的地方，AOF重写过程中父进程收到的写操作，也需要尽量写入AOF重写日志，在这里，Redis源码是使用了<strong>管道机制</strong>来实现父进程和AOF重写子进程间的通信的。在下一讲中，我就会重点给你介绍，Redis是如何使用管道完成父子进程的通信，以及它们通过管道又传递了哪些数据或信息。</p><h2>每课一问</h2><p>RDB文件的创建是由一个子进程来完成的，而AOF重写也是由一个子进程完成的，这两个子进程可以各自单独运行。那么请你思考一下，为什么Redis源码中在有RDB子进程运行时，不会启动AOF重写子进程呢？</p>","neighbors":{"left":{"article_title":"18 | 如何生成和解读RDB文件？","id":415563},"right":{"article_title":"20 | AOF重写（下）：重写时的新写操作记录在哪里？","id":416276}}},{"article_id":416276,"article_title":"20 | AOF重写（下）：重写时的新写操作记录在哪里？","article_content":"<p>你好，我是蒋德钧。</p><p>在上节课，我给你介绍了AOF重写过程，其中我带你重点了解了AOF重写的触发时机，以及AOF重写的基本执行流程。现在你已经知道，AOF重写是通过重写子进程来完成的。</p><p></p><p>但是在上节课的最后，我也提到了在AOF重写时，主进程仍然在接收客户端写操作，<strong>那么这些新写操作会记录到AOF重写日志中吗？如果需要记录的话，重写子进程又是通过什么方式向主进程获取这些写操作的呢？</strong></p><p></p><p>今天这节课，我就来带你了解下AOF重写过程中所使用的管道机制，以及主进程和重写子进程的交互过程。这样一方面，你就可以了解AOF重写日志包含的写操作的完整程度，当你要使用AOF日志恢复Redis数据库时，就知道AOF能恢复到的程度是怎样的。另一方面，因为AOF重写子进程就是通过操作系统提供的管道机制，来和Redis主进程交互的，所以学完这节课之后，你还可以掌握管道技术，从而用来实现进程间的通信。</p><p></p><p>好了，接下来，我们就先来了解下管道机制。</p><p></p><h2>如何使用管道进行父子进程间通信？</h2><p>首先我们要知道，当进程A通过调用fork函数创建一个子进程B，然后进程A和B要进行通信时，我们通常都需要依赖操作系统提供的通信机制，而<strong>管道</strong>（pipe）就是一种用于父子进程间通信的常用机制。</p><!-- [[[read_end]]] --><p></p><p>具体来说，管道机制在操作系统内核中创建了一块缓冲区，父进程A可以打开管道，并往这块缓冲区中写入数据。同时，子进程B也可以打开管道，从这块缓冲区中读取数据。这里，<strong>你需要注意的是</strong>，进程每次往管道中写入数据时，只能追加写到缓冲区中当前数据所在的尾部，而进程每次从管道中读取数据时，只能从缓冲区的头部读取数据。</p><p>其实，管道创建的这块缓冲区就像一个先进先出的队列一样，写数据的进程写到队列尾部，而读数据的进程则从队列头读取。下图就展示了两个进程使用管道进行数据通信的过程，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/c1/ff/c16041a949bcef79fcb87805214715ff.jpg?wh=1768x465\" alt=\"图片\"></p><p></p><p>好了，了解了管道的基本功能后，我们再来看下使用管道时需要注意的一个关键点。<strong>管道中的数据在一个时刻只能向一个方向流动</strong>，这也就是说，如果父进程A往管道中写入了数据，那么此时子进程B只能从管道中读取数据。类似的，如果子进程B往管道中写入了数据，那么此时父进程A只能从管道中读取数据。而如果父子进程间需要同时进行数据传输通信，我们就需要创建两个管道了。</p><p></p><p>下面，我们就来看下怎么用代码实现管道通信。这其实是和操作系统提供的管道的系统调用pipe有关，pipe的函数原型如下所示：</p><pre><code class=\"language-plain\">int pipe(int pipefd[2]);&nbsp;\n</code></pre><p>你可以看到，pipe的参数是一个<strong>数组pipefd</strong>，表示的是管道的文件描述符。这是因为进程在往管道中写入或读取数据时，其实是使用write或read函数的，而write和read函数需要通过<strong>文件描述符</strong>才能进行写数据和读数据操作。</p><p></p><p>数组pipefd有两个元素pipefd[0]和pipefd[1]，分别对应了管道的读描述符和写描述符。这也就是说，当进程需要从管道中读数据时，就需要用到pipefd[0]，而往管道中写入数据时，就使用pipefd[1]。</p><p></p><p>这里我写了一份示例代码，展示了父子进程如何使用管道通信，你可以看下。</p><pre><code class=\"language-plain\">int main()&nbsp;\n{&nbsp;\n&nbsp;&nbsp;&nbsp; int fd[2], nr = 0, nw = 0;&nbsp;\n&nbsp;&nbsp;&nbsp; char buf[128];&nbsp;\n&nbsp;&nbsp;&nbsp; pipe(fd);&nbsp;\n&nbsp;&nbsp;&nbsp; pid = fork();&nbsp;\n&nbsp;&nbsp; &nbsp;&nbsp;\n\tif(pid == 0) {\n\t&nbsp;&nbsp;&nbsp; //子进程调用read从fd[0]描述符中读取数据\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; printf(\"child process wait for message\\n\");&nbsp;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; nr = read(fds[0], buf, sizeof(buf))&nbsp;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; printf(\"child process receive %s\\n\", buf);\n\t}else{&nbsp;\n\t&nbsp;&nbsp;&nbsp;&nbsp; //父进程调用write往fd[1]描述符中写入数据\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; printf(\"parent process send message\\n\");&nbsp;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; strcpy(buf, \"Hello from parent\");&nbsp;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; nw = write(fd[1], buf, sizeof(buf));&nbsp;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; printf(\"parent process send %d bytes to child.\\n\", nw);&nbsp;\n&nbsp;&nbsp;&nbsp; }&nbsp;\n&nbsp;&nbsp;&nbsp; return 0;&nbsp;\n}&nbsp;\n</code></pre><p>从代码中，你可以看到，在父子进程进行管道通信前，我们需要在代码中定义用于保存读写描述符的<strong>数组fd</strong>，然后调用pipe系统创建管道，并把数组fd作为参数传给pipe函数。紧接着，在父进程的代码中，父进程会调用write函数往管道文件描述符fd[1]中写入数据，另一方面，子进程调用read函数从管道文件描述符fd[0]中读取数据。</p><p>这里，为了便于你理解，我也画了一张图，你可以参考。</p><p><img src=\"https://static001.geekbang.org/resource/image/4a/a7/4a7932d7a371cfc610bb6d79fe0e96a7.jpg?wh=1920x1080\" alt=\"图片\"></p><p>好了，现在你就了解了如何使用管道来进行父子进程的通信了。那么下面，我们就来看下在AOF重写过程中，重写子进程是如何用管道和主进程（也就是它的父进程）进行通信的。</p><p></p><h2>AOF重写子进程如何使用管道和父进程交互？</h2><p>我们先来看下在AOF重写过程中，都创建了几个管道。</p><p>这实际上是AOF重写函数rewriteAppendOnlyFileBackground在执行过程中，通过调用<strong>aofCreatePipes函数</strong>来完成的，如下所示：</p><pre><code class=\"language-plain\">int rewriteAppendOnlyFileBackground(void) {\n…\nif (aofCreatePipes() != C_OK) return C_ERR;\n…\n}\n</code></pre><p>这个aofCreatePipes函数是在<a href=\"https://github.com/redis/redis/tree/5.0/src/aof.c\">aof.c</a>文件中实现的，它的逻辑比较简单，可以分成三步。</p><p><strong>第一步</strong>，aofCreatePipes函数创建了包含6个文件描述符元素的<strong>数组fds</strong>。就像我刚才给你介绍的，每一个管道会对应两个文件描述符，所以，数组fds其实对应了AOF重写过程中要用到的三个管道。紧接着，aofCreatePipes函数就调用pipe系统调用函数，分别创建三个管道。</p><p></p><p>这部分代码如下所示，你可以看下。</p><pre><code class=\"language-plain\">int aofCreatePipes(void) {\n&nbsp;&nbsp;&nbsp; int fds[6] = {-1, -1, -1, -1, -1, -1};\n&nbsp;&nbsp;&nbsp; int j;\n&nbsp;&nbsp;&nbsp; if (pipe(fds) == -1) goto error; /* parent -&gt; children data. */\n&nbsp;&nbsp;&nbsp; if (pipe(fds+2) == -1) goto error; /* children -&gt; parent ack. */\n\tif (pipe(fds+4) == -1) goto error;\n\t…}\n}\n</code></pre><p><strong>第二步</strong>，aofCreatePipes函数会调用<strong>anetNonBlock函数</strong>（在<a href=\"https://github.com/redis/redis/tree/5.0/src/anet.c\">anet.c</a>文件中），将fds</p><p>数组的第一和第二个描述符（fds[0]和fds[1]）对应的管道设置为非阻塞。然后，aofCreatePipes函数会调用<strong>aeCreateFileEvent函数</strong>，在数组fds的第三个描述符(fds[2])上注册了读事件的监听，对应的回调函数是aofChildPipeReadable。aofChildPipeReadable函数也是在aof.c文件中实现的，我稍后会给你详细介绍它。</p><p></p><pre><code class=\"language-plain\">int aofCreatePipes(void) {\n…\nif (anetNonBlock(NULL,fds[0]) != ANET_OK) goto error;\nif (anetNonBlock(NULL,fds[1]) != ANET_OK) goto error;\nif (aeCreateFileEvent(server.el, fds[2], AE_READABLE, aofChildPipeReadable, NULL) == AE_ERR) goto error;\n…\n}\n</code></pre><p>这样，在完成了管道创建、管道设置和读事件注册后，最后一步，aofCreatePipes函数会将数组fds中的六个文件描述符，分别复制给server变量的成员变量，如下所示：</p><pre><code class=\"language-plain\">int aofCreatePipes(void) {\n…\nserver.aof_pipe_write_data_to_child = fds[1];\nserver.aof_pipe_read_data_from_parent = fds[0];\nserver.aof_pipe_write_ack_to_parent = fds[3];\nserver.aof_pipe_read_ack_from_child = fds[2];\nserver.aof_pipe_write_ack_to_child = fds[5];\nserver.aof_pipe_read_ack_from_parent = fds[4];\n…\n}\n</code></pre><p>在这一步中，我们就可以从server变量的成员变量名中，看到aofCreatePipes函数创建的三个管道，以及它们各自的用途。</p><ul>\n<li><strong>fds[0]和fds[1]</strong>：对应了主进程和重写子进程间用于传递操作命令的管道，它们分别对应读描述符和写描述符。</li>\n<li><strong>fds[2]和fds[3]</strong>：对应了重写子进程向父进程发送ACK信息的管道，它们分别对应读描述符和写描述符。</li>\n<li><strong>fds[4]和fds[5]</strong>：对应了父进程向重写子进程发送ACK信息的管道，它们分别对应读描述符和写描述符。</li>\n</ul><p></p><p>下图也展示了aofCreatePipes函数的基本执行流程，你可以再回顾下。</p><p><img src=\"https://static001.geekbang.org/resource/image/39/18/3966573fd97e10f41e9bbbcc6e919718.jpg?wh=1920x1080\" alt=\"图片\"></p><p>好了，了解了AOF重写过程中的管道个数和用途后，下面我们再来看下这些管道具体是如何使用的。</p><p></p><h3>操作命令传输管道的使用</h3><p>实际上，当AOF重写子进程在执行时，主进程还会继续接收和处理客户端写请求。这些写操作会被主进程正常写入AOF日志文件，这个过程是由<strong>feedAppendOnlyFile函数</strong>（在aof.c文件中）来完成。</p><p>feedAppendOnlyFile函数在执行的最后一步，会判断当前是否有AOF重写子进程在运行。如果有的话，它就会调用<strong>aofRewriteBufferAppend函数</strong>（在aof.c文件中），如下所示：</p><pre><code class=\"language-plain\">if (server.aof_child_pid != -1)\n&nbsp; &nbsp; &nbsp; &nbsp; aofRewriteBufferAppend((unsigned char*)buf,sdslen(buf));\n</code></pre><p>aofRewriteBufferAppend函数的作用是将参数buf，追加写到全局变量server的aof_rewrite_buf_blocks这个列表中。<br>\n这里，你需要注意的是，<strong>参数buf是一个字节数组</strong>，feedAppendOnlyFile函数会将主进程收到的命令操作写入到buf中。而aof_rewrite_buf_blocks列表中的每个元素是<strong>aofrwblock结构体类型</strong>，这个结构体中包括了一个字节数组，大小是AOF_RW_BUF_BLOCK_SIZE，默认值是10MB。此外，aofrwblock结构体还记录了字节数组已经使用的空间和剩余可用的空间。</p><p>以下代码展示了aofrwblock结构体的定义，你可以看下。</p><pre><code class=\"language-plain\">typedef struct aofrwblock {\n&nbsp; &nbsp; unsigned long used, free; //buf数组已用空间和剩余可用空间\n&nbsp; &nbsp; char buf[AOF_RW_BUF_BLOCK_SIZE]; //宏定义AOF_RW_BUF_BLOCK_SIZE默认为10MB\n} aofrwblock;\n</code></pre><p>这样一来，aofrwblock结构体就相当于是一个10MB的数据块，记录了AOF重写期间主进程收到的命令，而aof_rewrite_buf_blocks列表负责将这些数据块连接起来。当aofRewriteBufferAppend函数执行时，它会从aof_rewrite_buf_blocks列表中取出一个aofrwblock类型的数据块，用来记录命令操作。</p><p>当然，如果当前数据块中的空间不够保存参数buf中记录的命令操作，那么aofRewriteBufferAppend函数就会再分配一个aofrwblock数据块。</p><p>好了，当aofRewriteBufferAppend函数将命令操作记录到aof_rewrite_buf_blocks列表中之后，它还会<strong>检查aof_pipe_write_data_to_child管道描述符上是否注册了写事件</strong>，这个管道描述符就对应了我刚才给你介绍的fds[1]。</p><p>如果没有注册写事件，那么aofRewriteBufferAppend函数就会调用<strong>aeCreateFileEvent函数</strong>，注册一个写事件，这个写事件会监听aof_pipe_write_data_to_child这个管道描述符，也就是主进程和重写子进程间的操作命令传输管道。</p><p>当这个管道可以写入数据时，写事件对应的回调函数aofChildWriteDiffData（在aof.c文件中）就会被调用执行。这个过程你可以参考下面的代码：</p><pre><code class=\"language-plain\">void aofRewriteBufferAppend(unsigned char *s, unsigned long len) {\n...\n//检查aof_pipe_write_data_to_child描述符上是否有事件\nif (aeGetFileEvents(server.el,server.aof_pipe_write_data_to_child) == 0) {\n     //如果没有注册事件，那么注册一个写事件，回调函数是aofChildWriteDiffData\n&nbsp; &nbsp; &nbsp;aeCreateFileEvent(server.el, server.aof_pipe_write_data_to_child,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; AE_WRITABLE, aofChildWriteDiffData, NULL);\n}\n...}\n</code></pre><p>其实，刚才我介绍的写事件回调函数aofChildWriteDiffData，它的<strong>主要作用</strong>是从aof_rewrite_buf_blocks列表中逐个取出数据块，然后通过aof_pipe_write_data_to_child管道描述符，将数据块中的命令操作通过管道发给重写子进程，这个过程如下所示：</p><pre><code class=\"language-plain\">void aofChildWriteDiffData(aeEventLoop *el, int fd, void *privdata, int mask) {\n...\nwhile(1) {\n   //从aof_rewrite_buf_blocks列表中取出数据块\n   ln = listFirst(server.aof_rewrite_buf_blocks);\n&nbsp; &nbsp;block = ln ? ln-&gt;value : NULL;\n   if (block-&gt;used &gt; 0) {\n      //调用write将数据块写入主进程和重写子进程间的管道\n&nbsp; &nbsp;   nwritten = write(server.aof_pipe_write_data_to_child,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;block-&gt;buf,block-&gt;used);\n      if (nwritten &lt;= 0) return;\n            ...\n        }\n ...}}\n</code></pre><p>好了，这样一来，你就了解了主进程其实是在正常记录AOF日志时，将收到的命令操作写入aof_rewrite_buf_blocks列表中的数据块，然后再通过aofChildWriteDiffData函数将记录的命令操作通过主进程和重写子进程间的管道发给子进程。</p><p>下图也展示了这个过程，你可以再来回顾下。</p><p><img src=\"https://static001.geekbang.org/resource/image/ef/a9/efe1a110e7062e17aa964a3b1781bfa9.jpg?wh=1920x1080\" alt=\"图片\"></p><p>然后，我们接着来看下重写子进程，是如何从管道中读取父进程发送的命令操作的。</p><p>这实际上是由<strong>aofReadDiffFromParent函数</strong>（在aof.c文件中）来完成的。这个函数会使用一个64KB大小的缓冲区，然后调用read函数，读取父进程和重写子进程间的操作命令传输管道中的数据。以下代码也展示了aofReadDiffFromParent函数的基本执行流程，你可以看下。</p><pre><code class=\"language-plain\">ssize_t aofReadDiffFromParent(void) {\n&nbsp; &nbsp; char buf[65536]; //管道默认的缓冲区大小\n&nbsp; &nbsp; ssize_t nread, total = 0;\n    //调用read函数从aof_pipe_read_data_from_parent中读取数据\n&nbsp; &nbsp; while ((nread =\n&nbsp; &nbsp; &nbsp; read(server.aof_pipe_read_data_from_parent,buf,sizeof(buf))) &gt; 0) {\n&nbsp; &nbsp; &nbsp; &nbsp; server.aof_child_diff = sdscatlen(server.aof_child_diff,buf,nread);\n&nbsp; &nbsp; &nbsp; &nbsp; total += nread;\n&nbsp; &nbsp; }\n&nbsp; &nbsp; return total;\n}\n</code></pre><p>那么，从代码中，你可以看到aofReadDiffFromParent函数会通过<strong>aof_pipe_read_data_from_parent描述符</strong>读取数据。然后，它会将读取的操作命令追加到全局变量server的aof_child_diff字符串中。而在AOF重写函数rewriteAppendOnlyFile的执行过程最后，<strong>aof_child_diff字符串</strong>会被写入AOF重写日志文件，以便我们在使用AOF重写日志时，能尽可能地恢复重写期间收到的操作。</p><p>这个aof_child_diff字符串写入重写日志文件的过程，你可以参考下面给出的代码：</p><pre><code class=\"language-plain\">int rewriteAppendOnlyFile(char *filename) {\n...\n//将aof_child_diff中累积的操作命令写入AOF重写日志文件\nif (rioWrite(&amp;aof,server.aof_child_diff,sdslen(server.aof_child_diff)) == 0)\n&nbsp; &nbsp; &nbsp; &nbsp; goto werr;\n...\n}\n</code></pre><p>所以也就是说，aofReadDiffFromParent函数实现了重写子进程向主进程读取操作命令。那么在这里，我们还需要搞清楚的问题是：aofReadDiffFromParent函数会在哪里被调用，也就是重写子进程会在什么时候从管道中读取主进程收到的操作。</p><p>其实，aofReadDiffFromParent函数一共会被以下三个函数调用。</p><ul>\n<li><strong>rewriteAppendOnlyFileRio函数</strong>：这个函数是由重写子进程执行的，它负责遍历Redis每个数据库，生成AOF重写日志，在这个过程中，它会不时地调用aofReadDiffFromParent函数。</li>\n<li><strong>rewriteAppendOnlyFile函数</strong>：这个函数是重写日志的主体函数，也是由重写子进程执行的，它本身会调用rewriteAppendOnlyFileRio函数。此外，它在调用完rewriteAppendOnlyFileRio函数后，还会多次调用aofReadDiffFromParent函数，以尽可能多地读取主进程在重写日志期间收到的操作命令。</li>\n<li><strong>rdbSaveRio函数</strong>：这个函数是创建RDB文件的主体函数。当我们使用AOF和RDB混合持久化机制时，这个函数也会调用aofReadDiffFromParent函数。</li>\n</ul><p>从这里，我们可以看到，Redis源码在实现AOF重写过程中，其实会多次让重写子进程向主进程读取新收到的操作命令，这也是为了让重写日志尽可能多地记录最新的操作，提供更加完整的操作记录。</p><p>最后，我们再来看下重写子进程和主进程间用来传递ACK信息的两个管道的使用。</p><h3>ACK管道的使用</h3><p>刚才在介绍主进程调用aofCreatePipes函数创建管道时，你就了解到了，主进程会在aof_pipe_read_ack_from_child管道描述符上注册读事件。这个描述符对应了重写子进程向主进程发送ACK信息的管道。同时，这个描述符是一个<strong>读描述符</strong>，表示主进程从管道中读取ACK信息。</p><p>其实，重写子进程在执行rewriteAppendOnlyFile函数时，这个函数在完成日志重写，以及多次向父进程读取操作命令后，就会调用write函数，向aof_pipe_write_ack_to_parent描述符对应的管道中<strong>写入“！”</strong>，这就是重写子进程向主进程发送ACK信号，让主进程停止发送收到的新写操作。这个过程如下所示：</p><pre><code class=\"language-plain\">int rewriteAppendOnlyFile(char *filename) {\n...\nif (write(server.aof_pipe_write_ack_to_parent,\"!\",1) != 1) goto werr;\n...}\n</code></pre><p>一旦重写子进程向主进程发送ACK信息的管道中有了数据，aof_pipe_read_ack_from_child管道描述符上注册的读事件就会被触发，也就是说，这个管道中有数据可以读取了。那么，aof_pipe_read_ack_from_child管道描述符上，注册的<strong>回调函数aofChildPipeReadable</strong>（在aof.c文件中）就会执行。</p><p>这个函数会判断从aof_pipe_read_ack_from_child管道描述符读取的数据是否是“！”，如果是的话，那它就会调用write函数，往aof_pipe_write_ack_to_child管道描述符上写入“！”，表示主进程已经收到重写子进程发送的ACK信息，同时它会给重写子进程回复一个ACK信息。这个过程如下所示：</p><pre><code class=\"language-plain\">void aofChildPipeReadable(aeEventLoop *el, int fd, void *privdata, int mask) {\n...\nif (read(fd,&amp;byte,1) == 1 &amp;&amp; byte == '!') {\n   ...\n   if (write(server.aof_pipe_write_ack_to_child,\"!\",1) != 1) { ...}\n}\n...\n}\n</code></pre><p>好了，到这里，我们就了解了，重写子进程在完成日志重写后，是先给主进程发送ACK信息。然后主进程在aof_pipe_read_ack_from_child描述符上监听读事件发生，并调用aofChildPipeReadable函数向子进程发送ACK信息。</p><p>最后，重写子进程执行的rewriteAppendOnlyFile函数，会调用<strong>syncRead函数</strong>，从aof_pipe_read_ack_from_parent管道描述符上，读取主进程发送给它的ACK信息，如下所示：</p><pre><code class=\"language-plain\">int rewriteAppendOnlyFile(char *filename) {\n...\nif (syncRead(server.aof_pipe_read_ack_from_parent,&amp;byte,1,5000) != 1  || byte != '!') goto werr\n...\n}\n</code></pre><p>下图也展示了ACK管道的使用过程，你可以再回顾下。</p><p><img src=\"https://static001.geekbang.org/resource/image/41/59/416bb56f2c5af3bac4f2c4374300c459.jpg?wh=1920x1080\" alt=\"图片\"></p><p>这样一来，重写子进程和主进程之间就通过两个ACK管道，相互确认重写过程结束了。</p><h2>小结</h2><p>今天这节课，我主要给你介绍了在AOF重写过程中，主进程和重写子进程间的管道通信。这里，你需要重点关注管道机制的使用，以及主进程和重写子进程使用管道通信的过程。</p><p>在这个过程中，AOF重写子进程和主进程是使用了一个操作命令传输管道和两个ACK信息发送管道。<strong>操作命令传输管道</strong>是用于主进程写入收到的新操作命令，以及用于重写子进程读取操作命令，而<strong>ACK信息发送管道</strong>是在重写结束时，重写子进程和主进程用来相互确认重写过程的结束。最后，重写子进程会进一步将收到的操作命令记录到重写日志文件中。</p><p>这样一来，AOF重写过程中主进程收到的新写操作，就不会被遗漏了。因为一方面，这些新写操作会被记录在正常的AOF日志中，另一方面，主进程会将新写操作缓存在aof_rewrite_buf_blocks数据块列表中，并通过管道发送给重写子进程。这样，就能尽可能地保证重写日志具有最新、最完整的写操作了。</p><p></p><p>最后，我也再提醒你一下，今天这节课我们学习的管道其实属于<strong>匿名管道</strong>，是用在父子进程间进行通信的。如果你在实际开发中，要在非父子进程的两个进程间进行通信，那么你就需要用到命名管道了。而命名管道会以一个文件的形式保存在文件系统中，并会有相应的路径和文件名。这样，非父子进程的两个进程通过命名管道的路径和文件名，就可以打开管道进行通信了。</p><p></p><h2>每课一问</h2><p>今天这节课，我给你介绍了重写子进程和主进程间进行操作命令传输、ACK信息传递用的三个管道。那么，你在Redis源码中还能找见其他使用管道的地方吗？</p><p></p><p></p>","neighbors":{"left":{"article_title":"19 | AOF重写（上）：触发时机与重写的影响","id":416264},"right":{"article_title":"21 | 主从复制：基于状态机的设计与实现","id":420285}}},{"article_id":420285,"article_title":"21 | 主从复制：基于状态机的设计与实现","article_content":"<p>你好，我是蒋德钧。这节课，我想跟你聊聊Redis是如何基于状态机的设计思路，来实现主从复制的。</p><p>主从复制技术我们应该都比较熟悉，因为在使用Redis或MySQL数据库时，我们经常会使用主从复制来实现主从节点间的数据同步，以此提升服务的高可用性。</p><p>从原理上来说，Redis的主从复制主要包括了<strong>全量复制、增量复制和长连接同步</strong>三种情况。全量复制传输RDB文件，增量复制传输主从断连期间的命令，而长连接同步则是把主节点正常收到的请求传输给从节点。</p><p>这三种情况看似简单，但是在实现的时候，我们通常都需要考虑主从连接建立、主从握手和验证、复制情况判断和数据传输等多种不同状态下的逻辑处理。</p><p>那么，<strong>如何才能高效地实现主从复制呢？</strong></p><p></p><p>实际上，Redis是采用了<strong>基于状态机</strong>的设计思想，来清晰地实现不同状态及状态间的跳转。而在我们实现网络功能的时候，这种设计和实现方法其实非常重要，它可以避免我们在处理不同状态时的逻辑冲突或遗漏。所以今天这节课，我就来给你介绍下如何基于状态机实现主从复制。</p><p>不过这里我也要说明一点，因为主从复制的状态比较多，如果一下子就学习每个状态细节，我们其实会很容易混淆不同状态的区别和转换关系。所以在今天的课程中，我会先给你介绍下复制整体过程的四个阶段，然后，我们再来逐一学习每个阶段中的状态与变化。</p><!-- [[[read_end]]] --><p></p><h2>主从复制的四大阶段</h2><p>首先，我们可以根据主从复制时的关键事件，把整个复制过程分成四个阶段，分别是初始化、建立连接、主从握手、复制类型判断与执行。下面，我们就来依次了解下每个阶段的主要工作。</p><p></p><p><strong>1.初始化阶段</strong></p><p>当我们把一个Redis实例A设置为另一个实例B的从库时，实例A会完成初始化操作，主要是获得了主库的IP和端口号。而这个初始化过程，我们可以用三种方式来设置。</p><ul>\n<li>方式一：在实例A上执行replicaof masterip masterport的主从复制命令，指明实例B的IP（masterip）和端口号（masterport）。</li>\n<li>方式二：在实例A的配置文件中设置replicaof masterip masterport，实例A可以通过解析文件获得主库IP和端口号。</li>\n<li>方式三：在实例A启动时，设置启动参数–replicaof [masterip] [masterport]。实例A解析启动参数，就能获得主库的IP和端口号。</li>\n</ul><p></p><p><strong>2.建立连接阶段</strong></p><p>接下来，一旦实例A获得了主库IP和端口号，该实例就会尝试和主库建立TCP网络连接，并且会在建立好的网络连接上，监听是否有主库发送的命令。</p><p></p><p><strong>3.主从握手阶段</strong></p><p>当实例A和主库建立好连接之后，实例A就开始和主库进行握手。简单来说，握手过程就是主从库间相互发送PING-PONG消息，同时从库根据配置信息向主库进行验证。最后，从库把自己的IP、端口号，以及对无盘复制和PSYNC 2协议的支持情况发给主库。</p><p></p><p>那么，和前两个阶段相比，主从握手阶段要执行的操作会比较多，涉及的状态也比较多，所以我们需要先掌握这个阶段要完成的操作，一会儿我就来给你具体介绍。</p><p></p><p><strong>4.复制类型判断与执行阶段</strong></p><p>这样，等到主从库之间的握手完成后，从库就会给主库发送PSYNC命令。紧接着，主库会根据从库发送的命令参数作出相应的三种回复，分别是<strong>执行全量复制、执行增量复制、发生错误</strong>。最后，从库在收到上述回复后，就会根据回复的复制类型，开始执行具体的复制操作。</p><p></p><p>下图展示了主从复制的整体过程及四个阶段，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/c0/c4/c0e917700f6146712bf9a74830d9d4c4.jpg?wh=1920x740\" alt=\"图片\"></p><p>好，了解了主从复制的主要阶段后，接下来，我们就具体学习下Redis是如何使用不同的状态及转换，来让从库完成和主库的数据复制操作的。</p><p></p><h2>基于状态机的主从复制实现</h2><p>首先你要知道，基于状态机实现主从复制的好处，就是当你在开发程序时，只需要考虑清楚在不同状态下具体要执行的操作，以及状态之间的跳转条件就行了。所以，Redis源码中采用的基于状态机跳转的设计思路和主从复制的实现，就是很值得你学习的一点。</p><p></p><p><strong>那么，主从复制中的状态机具体对应的是什么呢？</strong>这就和Redis实例的数据结构有关了。</p><p>每一个Redis实例在代码中都对应一个<strong>redisServer结构体</strong>，这个结构体包含了和Redis实例相关的各种配置，比如实例的RDB、AOF配置、主从复制配置、切片集群配置等。然后，与主从复制状态机相关的变量是<strong>repl_state</strong>，Redis在进行主从复制时，从库就是根据这个变量值的变化，来实现不同阶段的执行和跳转。下面代码显示了redisServer结构体中从库进行复制相关的变量，你可以看下。</p><pre><code class=\"language-plain\">struct redisServer {\n&nbsp; &nbsp;...\n&nbsp;&nbsp; /* 复制相关(slave) */\n&nbsp;&nbsp;&nbsp; char *masterauth;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* 用于和主库进行验证的密码*/\n&nbsp;&nbsp;&nbsp; char *masterhost;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* 主库主机名 */\n&nbsp;&nbsp;&nbsp; int masterport;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* 主库端口号r */\n&nbsp;&nbsp; &nbsp;…\n&nbsp;&nbsp;&nbsp; client *master;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;/* 从库上用来和主库连接的客户端 */\n&nbsp;&nbsp;&nbsp; client *cached_master; /* 从库上缓存的主库信息 */\n&nbsp;&nbsp;&nbsp; int repl_state;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* 从库的复制状态机 */\n&nbsp; &nbsp;...\n}\n</code></pre><p>好，接下来，我们就按照主从复制的四个阶段，来依次学习每个阶段中状态机的变迁，以及相应的代码实现。</p><h3><strong>初始化阶段</strong></h3><p>首先，当一个实例启动后，就会调用server.c中的initServerConfig函数，初始化redisServer结构体。此时，实例会把状态机的初始状态设置为<strong>REPL_STATE_NONE</strong>，如下所示：</p><pre><code class=\"language-plain\">void initServerConfig(void) {\n&nbsp;&nbsp; …\n&nbsp;&nbsp; server.repl_state = REPL_STATE_NONE;\n&nbsp;&nbsp; …\n}\n</code></pre><p>然后，一旦实例执行了replicaof masterip masterport命令，就会调用replication.c中的 <strong>replicaofCommand函数</strong>进行处理。replicaof命令携带的masterip和masterport参数对应了主库的IP和端口号，replicaofCommand函数如果判断发现实例并没有记录过主库的IP和端口号，就表明当前实例可以和设置的主库进行连接。<br>\n紧接着，replicaofCommand函数会调用replicationSetMaster函数设置主库的信息。这部分的代码逻辑如下所示：</p><pre><code class=\"language-plain\">/* 检查是否已记录主库信息，如果已经记录了，那么直接返回连接已建立的消息 */\n&nbsp;if (server.masterhost &amp;&amp; !strcasecmp(server.masterhost,c-&gt;argv[1]-&gt;ptr)&amp;&amp; server.masterport == port) {\n&nbsp; &nbsp; serverLog(LL_NOTICE,\"REPLICAOF would result into synchronization with the master we are already connected with. No operation performed.\");\n&nbsp; addReplySds(c,sdsnew(\"+OK Already connected to specified master\\r\\n\"));\n&nbsp; &nbsp; &nbsp; return;\n&nbsp; }\n&nbsp; /* 如果没有记录主库的IP和端口号，设置主库的信息 */\n&nbsp; replicationSetMaster(c-&gt;argv[1]-&gt;ptr, port);\n</code></pre><p>而replicationSetMaster函数除了会记录主库的IP、端口号之外，还会把从库实例的状态机设置为<strong>REPL_STATE_CONNECT</strong>。此时，主从复制的初始化阶段就完成了，状态机会从REPL_STATE_NONE变迁为REPL_STATE_CONNECT。这个过程如下所示：<br>\n<img src=\"https://static001.geekbang.org/resource/image/7c/e1/7c46c8f72f4391d29a6bcdyy8a64e6e1.jpg?wh=1920x749\" alt=\"图片\"></p><h3><strong>建立连接阶段</strong></h3><p>接着，我们来了解下建立连接阶段的状态机变化。</p><p>当从库实例进入这个阶段时，状态已经变成了REPL_STATE_CONNECT。那么，<strong>从库是何时开始和主库建立网络连接的呢？</strong></p><p></p><p>这就和Redis的<strong>周期性任务</strong>执行相关了。所谓周期性任务，我们在<a href=\"https://time.geekbang.org/column/article/408857\">第11讲</a>中已经初步了解过，就是指Redis实例在运行时，按照一定时间周期重复执行的任务。Redis的周期性任务很多，其中之一就是replicationCron()任务。这个任务的执行频率是每1000ms执行一次，如下面的代码所示：</p><pre><code class=\"language-plain\">int serverCron(struct aeEventLoop *eventLoop, long long id, void *clientData) {\n&nbsp;&nbsp; …\n&nbsp;&nbsp; run_with_period(1000) replicationCron();\n&nbsp;&nbsp; …\n}\n</code></pre><p>replicationCron()任务的函数实现逻辑是在server.c中，在该任务中，一个重要的判断就是，检查从库的复制状态机状态。如果状态机状态是REPL_STATE_CONNECT，那么从库就开始和主库建立连接。连接的建立是通过调用<strong>connectWithMaster()函数</strong>来完成的。</p><pre><code class=\"language-plain\">replicationCron() {\n&nbsp;&nbsp; …\n&nbsp;&nbsp; /* 如果从库实例的状态是REPL_STATE_CONNECT，那么从库通过connectWithMaster和主库建立连接 */\n&nbsp;&nbsp;&nbsp; if (server.repl_state == REPL_STATE_CONNECT) {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; serverLog(LL_NOTICE,\"Connecting to MASTER %s:%d\",\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; server.masterhost, server.masterport);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (connectWithMaster() == C_OK) {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; serverLog(LL_NOTICE,\"MASTER &lt;-&gt; REPLICA sync started\");\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }\n&nbsp; &nbsp; }\n&nbsp; &nbsp; …\n}\n</code></pre><p>这样，当从库实例调用connectWithMaster函数后，会先通过anetTcpNonBlockBestEffortBindConnect函数和主库建立连接。一旦连接建立成功后，从库实例就会在连接上创建读写事件，并且注册对读写事件进行处理的函数syncWithMaster。<br>\n最后，connectWithMaster函数会将从库实例的状态机置为REPL_STATE_CONNECTING。下面的代码显示了这部分的逻辑，你可以看下。</p><pre><code class=\"language-plain\">int connectWithMaster(void) {\n&nbsp;&nbsp;&nbsp; int fd;\n&nbsp;&nbsp;&nbsp; //从库和主库建立连接\n&nbsp;fd = anetTcpNonBlockBestEffortBindConnect(NULL, server.masterhost,server.masterport,NET_FIRST_BIND_ADDR);\n&nbsp; &nbsp; …\n&nbsp;\n//在建立的连接上注册读写事件，对应的回调函数是syncWithMaster\n&nbsp;if(aeCreateFileEvent(server.el,fd,AE_READABLE|AE_WRITABLE,syncWithMaster,&nbsp;NULL) ==AE_ERR)\n&nbsp;&nbsp;&nbsp; {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; close(fd);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; serverLog(LL_WARNING,\"Can't create readable event for SYNC\");\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return C_ERR;\n&nbsp;&nbsp;&nbsp; }\n&nbsp;\n&nbsp;&nbsp;&nbsp; //完成连接后，将状态机设置为REPL_STATE_CONNECTING\n&nbsp;&nbsp;&nbsp; …\n&nbsp;&nbsp;&nbsp; server.repl_state = REPL_STATE_CONNECTING;\n&nbsp;&nbsp;&nbsp; return C_OK;\n}\n</code></pre><p>所以，当从库实例的状态变为REPL_STATE_CONNECTING时，建立连接的阶段就完成了。这个初始化阶段和建立连接阶段的状态机变迁如下图所示，你可以参考下。<br>\n<img src=\"https://static001.geekbang.org/resource/image/dd/aa/dd6176abeb3ba492f15a93bd0b4a84aa.jpg?wh=1920x738\" alt=\"图片\"></p><h3><strong>主从握手阶段</strong></h3><p>接下来，当主从库建立网络连接后，从库实例其实并没有立即开始进行数据同步，而是会先和主库之间进行握手通信。</p><p>握手通信的目的，主要包括从库和主库进行验证，以及从库将自身的IP和端口号发给主库。如我前面所说，这个阶段涉及的状态变迁会比较多，不过其变迁的逻辑实际上是比较清晰的。</p><p></p><p>首先，在建立连接阶段的最后，从库实例的状态机处于<strong>REPL_STATE_CONNECTING</strong>状态。一旦主库和从库的连接建立后，从库实例的syncWithMaster函数就会被回调。在这个函数中，如果从库实例的状态是REPL_STATE_CONNECTING，那么实例会发送PING消息给主库，并将状态机置为<strong>REPL_STATE_RECEIVE_PONG</strong>。</p><p></p><p>当从库收到主库返回的PONG消息后，接下来，从库会依次给主库发送验证信息、端口号、IP、对RDB文件和无盘复制的支持情况。每一次的握手通信发送消息时，都会对应从库的一组状态变迁。比如，当从库要给主库发送验证信息前，会将自身状态机置为REPL_STATE_SEND_AUTH，然后，从库给主库发送实际的验证信息。验证信息发送完成后，从库状态机会变迁为REPL_STATE_RECEIVE_AUTH，并开始读取主库返回验证结果信息。</p><p></p><p>这样一来，当从库对端口号、IP，以及对RDB文件和无盘复制的支持情况进行握手时，也就是在SEND和RECEIVE两种状态间变迁。为了便于你掌握这些状态的变迁，这里我放了一张图，其中显示了从初始化阶段到主从握手阶段的各状态变化，你可以参考下。</p><p><img src=\"https://static001.geekbang.org/resource/image/c2/cf/c2946565d547bd52063ff1a79ec426cf.jpg?wh=1920x1080\" alt=\"图片\"></p><h3><strong>复制类型判断与执行阶段</strong></h3><p>当从库和主库完成握手后，从库会读取主库返回的CAPA消息响应，此时，状态机为<strong>REPL_STATE_RECEIVE_CAPA</strong>。紧接着，从库的状态变迁为<strong>REPL_STATE_SEND_PSYNC</strong>，表明要开始向主库发送PSYNC命令，开始实际的数据同步。</p><p>此时，从库会调用slaveTryPartialResynchronization函数，向主库发送PSYNC命令，并且状态机的状态会置为<strong>REPL_STATE_RECEIVE_PSYNC</strong>。下面的代码显示了这三个状态的变迁：</p><pre><code class=\"language-plain\">&nbsp;&nbsp;&nbsp; /* 从库状态机进入REPL_STATE_RECEIVE_CAPA. */\n&nbsp;&nbsp;&nbsp; if (server.repl_state == REPL_STATE_RECEIVE_CAPA) {\n\t…\n\t//读取主库返回的CAPA消息响应\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; server.repl_state = REPL_STATE_SEND_PSYNC;\n\t}\n\t//从库状态机变迁为REPL_STATE_SEND_PSYNC后，开始调用slaveTryPartialResynchronization函数向主库发送PSYNC命令，进行数据同步\n\tif (server.repl_state == REPL_STATE_SEND_PSYNC) {\n\t&nbsp;&nbsp;&nbsp;&nbsp; if (slaveTryPartialResynchronization(fd,0) == PSYNC_WRITE_ERROR) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n\t&nbsp;&nbsp;&nbsp;&nbsp; {\n\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; …\n\t&nbsp;&nbsp;&nbsp;&nbsp; }\n\t&nbsp;&nbsp;&nbsp;&nbsp; server.repl_state = REPL_STATE_RECEIVE_PSYNC;\n\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return;\n\t}\n</code></pre><p>然后，从库调用的slaveTryPartialResynchronization函数，负责向主库发送数据同步的命令。主库收到命令后，会根据从库发送的主库ID、复制进度值offset，来判断是进行全量复制还是增量复制，或者是返回错误。<br>\n以下代码就展示了slaveTryPartialResynchronization函数的基本分支，你可以看到从库会根据主库的回复消息，将slaveTryPartialResynchronization函数的返回值置为不同结果，分别对应了全量复制、增量复制，或是不支持PSYNC。</p><pre><code class=\"language-plain\">int slaveTryPartialResynchronization(int fd, int read_reply) {\n&nbsp;&nbsp; …\n&nbsp;&nbsp; //发送PSYNC命令\n&nbsp;&nbsp; if (!read_reply) {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //从库第一次和主库同步时，设置offset为-1\n\tserver.master_initial_offset = -1;\n\t…\n\t//调用sendSynchronousCommand发送PSYNC命令\n\treply =\n\tsendSynchronousCommand(SYNC_CMD_WRITE,fd,\"PSYNC\",psync_replid,psync_offset,NULL);\n\t&nbsp;…\n\t&nbsp;//发送命令后，等待主库响应\n\t&nbsp;return PSYNC_WAIT_REPLY;\n&nbsp;&nbsp; }\n&nbsp;\n&nbsp; //读取主库的响应\n&nbsp; reply = sendSynchronousCommand(SYNC_CMD_READ,fd,NULL);\n&nbsp;\n&nbsp;//主库返回FULLRESYNC，全量复制\n&nbsp; if (!strncmp(reply,\"+FULLRESYNC\",11)) {\n&nbsp; &nbsp;…\n&nbsp; &nbsp;return PSYNC_FULLRESYNC;\n&nbsp;&nbsp; }\n&nbsp;\n&nbsp; //主库返回CONTINUE，执行增量复制\n&nbsp; if (!strncmp(reply,\"+ CONTINUE\",11)) {\n\t…\n\treturn PSYNC_CONTINUE;\n&nbsp;&nbsp; }\n&nbsp;\n&nbsp; //主库返回错误信息\n&nbsp; if (strncmp(reply,\"-ERR\",4)) {\n&nbsp;&nbsp;&nbsp;&nbsp; …\n&nbsp; }\n&nbsp; return PSYNC_NOT_SUPPORTED;\n}\n</code></pre><p>因为slaveTryPartialResynchronization是在syncWithMaster函数中调用的，当该函数返回PSYNC命令不同的结果时，syncWithMaster函数就会根据结果值执行不同处理。<br>\n其中，值得关注的是<strong>全量复制</strong>，当主库对从库的PSYNC命令返回FULLRESYNC时，从库会在和主库的网络连接上注册readSyncBulkPayload回调函数，并将状态机置为<strong>REPL_STATE_TRANSFER</strong>，表示开始进行实际的数据同步，比如主库把RDB文件传输给从库。</p><pre><code class=\"language-plain\">//读取PSYNC命令的返回结果\npsync_result = slaveTryPartialResynchronization(fd,1);\n//PSYNC结果还没有返回，先从syncWithMaster函数返回处理其他操作\nif (psync_result == PSYNC_WAIT_REPLY) return;\n//如果PSYNC结果是PSYNC_CONTINUE，从syncWithMaster函数返回，后续执行增量复制\nif (psync_result == PSYNC_CONTINUE) {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; …\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return;\n}\n&nbsp;\n//如果执行全量复制的话，针对连接上的读事件，创建readSyncBulkPayload回调函数\nif (aeCreateFileEvent(server.el,fd, AE_READABLE,readSyncBulkPayload,NULL)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; == AE_ERR)\n&nbsp;&nbsp;&nbsp; {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; …\n&nbsp;&nbsp;&nbsp; }\n//将从库状态机置为REPL_STATE_TRANSFER\n&nbsp;&nbsp;&nbsp; server.repl_state = REPL_STATE_TRANSFER;\n</code></pre><p>好了，到这里，我们就学习了从库在复制类型判断和执行阶段的状态机变迁。我把主从复制各阶段的状态变迁整合在一起，画了下面这张图，以便你更好地掌握。</p><p><img src=\"https://static001.geekbang.org/resource/image/f6/97/f6e25eb125f0d70694d92597dca3e197.jpg?wh=1920x1080\" alt=\"图片\"></p><h2>小结</h2><p>主从复制是Redis、MySQL等数据库或存储系统，用来实现高可用性的方法。要实现主从复制，则需要应对整个过程中Redis在不同状态下的各种处理逻辑，因此，如何正确实现主从复制，并且不遗漏可能的状态，是我们在实际开发中需要面对的问题。</p><p>这节课我们学习了Redis主从复制的设计思想与实现方法。Redis采用了<strong>状态机驱动</strong>的方法，为从库实例设置状态变量。在整个复制过程中，代码逻辑会根据从库状态机的变迁，处理不同状态下的情况。</p><p>为了便于你掌握主从复制的实现，我将整个过程分解成四个阶段：初始化、建立连接、主从握手、复制类型判断与执行。在每个阶段中，从库的状态会不断变化，完成和主库建立网络连接、交换配置信息、发送同步命令，并根据主库对同步请求的返回结果，执行全量同步或增量同步。</p><p>状态机驱动的设计方法是一种通用的设计方法，在涉及网络通信的场景中应用广泛。Redis对主从复制的实现为我们提供了良好的参考示例，当你需要自行设计和实现网络功能时，就可以把状态机驱动的方法使用起来。</p><h2>每课一问</h2><p>这节课我们介绍的状态机是当实例为从库时会使用的。那么，当一个实例是主库时，为什么不需要使用一个状态机来实现主库在主从复制时的流程流转呢？</p>","neighbors":{"left":{"article_title":"20 | AOF重写（下）：重写时的新写操作记录在哪里？","id":416276},"right":{"article_title":"22 | 哨兵也和Redis实例一样初始化吗？","id":420759}}},{"article_id":420759,"article_title":"22 | 哨兵也和Redis实例一样初始化吗？","article_content":"<p>你好，我是蒋德钧。这节课，我们一起来看看Redis是如何在源码中实现哨兵机制的。</p><p>我们知道，Redis主从复制是保证Redis可用性的一个重要手段。而一旦Redis主节点发生故障，哨兵机制就会执行故障切换。这个故障切换过程实现起来其实比较复杂，涉及了哨兵Leader选举、新主节点选举和故障切换等关键操作。但同时，这个故障切换过程又是我们在实现高可用系统时经常要面对的开发需求。</p><p></p><p>所以从这节课开始，我就来给你逐一介绍下，Redis哨兵机制及其实现故障切换的关键技术设计与实现。通过这部分内容的学习，你既可以了解在故障切换过程中，起到重要作用的Raft协议是如何实现的，而且你还可以掌握在故障切换时，主节点、从节点和客户端相互之间如何完成切换通知的。</p><p></p><p>不过，在开始了解故障切换的关键技术之前，今天我们会先来了解哨兵实例本身的初始化和基本运行过程，这是因为从源码的角度来看，哨兵实例和常规Redis实例的实现都是在一套源码中的，它们共享了一些执行流程。所以了解这部分内容，也可以帮助我们更加清楚地掌握哨兵实例的实现机制。</p><p></p><p>好，下面我们就先来看下哨兵实例的初始化过程。</p><p></p><h2>哨兵实例的初始化</h2><p>因为哨兵实例是属于运行在一种特殊模式下的Redis server，而我在<a href=\"https://time.geekbang.org/column/article/406556\">第8讲</a>中，已经给你介绍过了Redis server启动后的入口函数main的整体执行过程。其实，这个过程就包含了哨兵实例的初始化操作。</p><!-- [[[read_end]]] --><p></p><p>所以，哨兵实例的初始化入口函数也是main（在server.c文件中）。那么，main函数在运行时，就会通过对运行参数的判断，来执行哨兵实例对应的运行逻辑。具体来说，main函数在调用initServerConfig函数初始化各种配置项之前，会调用<strong>checkForSentinelMode函数</strong>，来判断当前运行的是否为哨兵实例，如下所示：</p><pre><code class=\"language-plain\">server.sentinel_mode = checkForSentinelMode(argc,argv);\n</code></pre><p>checkForSentinelMode函数（在server.c文件中）的参数，是main函数收到的启动命令字符串<strong>argv</strong>和启动命令中的参数个数<strong>argc</strong>。然后，它会根据以下两个条件判断当前是否运行了哨兵实例。</p><ul>\n<li>条件一：执行的命令本身，也就是argv[0]，是否为“redis-sentinel”。</li>\n<li>条件二：执行的命令参数中，是否有“–sentinel”。</li>\n</ul><p>这部分代码如下所示：</p><pre><code class=\"language-plain\">int checkForSentinelMode(int argc, char **argv) {\n&nbsp; &nbsp;&nbsp;int j\n    //第一个判断条件，判断执行命令本身是否为redis-sentinel\n&nbsp;&nbsp;&nbsp; if (strstr(argv[0],\"redis-sentinel\") != NULL) return 1;\n&nbsp;&nbsp;&nbsp; for (j = 1; j &lt; argc; j++)\n        //第二个判断条件，判断命令参数是否有\"--sentienl\"\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (!strcmp(argv[j],\"--sentinel\")) return 1;\n&nbsp;&nbsp;&nbsp; return 0;\n}\n</code></pre><p>其实，这两个判断条件也就对应了我们在命令行启动哨兵实例的两种方式，一种是直接运行redis-sentinel命令，另一种是运行redis-server命令，但是带有“–sentinel”参数，如下所示：</p><pre><code class=\"language-plain\">redis-sentinel sentinel.conf文件路径\n或者\nredis-server sentinel.conf文件路径—sentinel\n</code></pre><p>所以，如果这两个条件中有一个成立，那么全局变量server的成员变量sentinel_mode，就会被设置为1，表明当前运行的是哨兵实例。这样一来，server.sentinel_mode这一配置项就会在源码的其他地方，被用来判断当前是否运行的是哨兵实例。</p><h3>初始化配置项</h3><p>好，在完成了对哨兵实例的运行判断之后，接下来，main函数还是会调用initServerConfig函数初始化各种配置项。但是，因为哨兵实例运行时所用的配置项和Redis实例是有区别的，所以，main函数会专门调用initSentinelConfig和initSentinel两个函数，来完成哨兵实例专门的配置项初始化，如下所示：</p><pre><code class=\"language-plain\">if (server.sentinel_mode) {\n   initSentinelConfig();\n&nbsp;&nbsp;&nbsp;initSentinel();\n}\n</code></pre><p>initSentinelConfig和initSentinel这两个函数都是在<a href=\"https://github.com/redis/redis/tree/5.0/src/sentinel.c\">sentinel.c</a>文件中实现的。</p><p>其中，<strong>initSentinelConfig函数</strong>主要是将当前server的端口号，改为哨兵实例专用的端口号REDIS_SENTINEL_PORT。这是个宏定义，它对应的默认值是26379。另外，这个函数还会把server的protected_mode设置为0，即允许外部连接哨兵实例，而不是只能通过127.0.0.1本地连接server。</p><p></p><p>而<strong>initSentinel函数</strong>则是在initSentinelConfig函数的基础上，进一步完成哨兵实例的初始化，这其中主要包括两部分工作。</p><p></p><ul>\n<li>首先，initSentinel函数会替换server能执行的命令表。</li>\n</ul><p>在initServerConfig函数执行的时候，Redis server会初始化一个执行命令表，并保存在全局变量server的commands成员变量中。这个命令表本身是一个哈希表，每个哈希项的键对应了一个命令的名称，而值对应了该命令实际的实现函数。</p><p></p><p>因为哨兵实例是运行在特殊模式的Redis server，它执行的命令和Redis实例也是有区别的，所以initSentinel函数会把server.commands对应的命令表清空，然后在其中添加哨兵对应的命令，如下所示：</p><pre><code class=\"language-plain\">&nbsp; dictEmpty(server.commands,NULL);\n&nbsp;&nbsp;&nbsp; for (j = 0; j &lt; sizeof(sentinelcmds)/sizeof(sentinelcmds[0]); j++) {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; …\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; struct redisCommand *cmd = sentinelcmds+j;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; retval = dictAdd(server.commands, sdsnew(cmd-&gt;name), cmd);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; …\n&nbsp;&nbsp;&nbsp; }\n</code></pre><p>从这里的代码中你可以看到，哨兵实例可以执行的命令保存在了<strong>sentinelcmds数组</strong>中，这个数组是在sentinel.c文件中定义的。</p><p>其中你需要注意的是，哨兵实例执行的一些命令，其名称虽然和Redis实例命令表中的命令名称一样，但它们的实现函数是<strong>针对哨兵实例专门实现的</strong>。比如，哨兵实例和Redis实例都可以执行publish、info、role命令，但是在哨兵实例中，这三个命令分别由sentinelPublishCommand、sentinelInfoCommand、sentinelRoleCommand这三个在sentinel.c文件中的函数来实现的。所以，当你需要详细了解哨兵实例运行命令的实现时，注意不要找错代码文件。</p><p></p><p>以下代码也展示了哨兵实例命令表中的部分命令，你可以看看。</p><pre><code class=\"language-plain\">struct redisCommand sentinelcmds[] = {\n&nbsp;&nbsp;&nbsp; {\"ping\",pingCommand,1,\"\",0,NULL,0,0,0,0,0},\n&nbsp;&nbsp;&nbsp; {\"sentinel\",sentinelCommand,-2,\"\",0,NULL,0,0,0,0,0},\n&nbsp;&nbsp; &nbsp;…\n&nbsp;&nbsp;&nbsp; {\"publish\",sentinelPublishCommand,3,\"\",0,NULL,0,0,0,0,0},\n&nbsp;&nbsp;&nbsp; {\"info\",sentinelInfoCommand,-1,\"\",0,NULL,0,0,0,0,0},\n&nbsp;&nbsp;&nbsp; {\"role\",sentinelRoleCommand,1,\"l\",0,NULL,0,0,0,0,0},\n&nbsp;&nbsp; &nbsp;…\n};\n</code></pre><ul>\n<li>其次，initSentinel函数在替换了命令表后，紧接着它会开始初始化哨兵实例用到的各种属性信息。</li>\n</ul><p>为了保存这些属性信息，哨兵实例定义了<strong>sentinelState结构体</strong>（在sentinel.c文件中），这其中包括了哨兵实例的ID、用于故障切换的当前纪元、监听的主节点、正在执行的脚本数量，以及与其他哨兵实例发送的IP和端口号等信息。下面的代码就展示了sentinelState结构体定义中的部分属性，你可以看下。</p><pre><code class=\"language-plain\">struct sentinelState {\n&nbsp;&nbsp;&nbsp; char myid[CONFIG_RUN_ID_SIZE+1]; &nbsp;//哨兵实例ID\n&nbsp;&nbsp;&nbsp; uint64_t current_epoch;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //当前纪元\n&nbsp;&nbsp;&nbsp; dict *masters;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //监听的主节点的哈希表\n&nbsp;&nbsp;&nbsp; int tilt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //是否处于TILT模式\n&nbsp;&nbsp;&nbsp; int running_scripts;&nbsp;&nbsp;&nbsp; //运行的脚本个数\n&nbsp;&nbsp;&nbsp; mstime_t tilt_start_time;&nbsp; //tilt模式的起始时间\n&nbsp;&nbsp;&nbsp; mstime_t previous_time;&nbsp;&nbsp;&nbsp;&nbsp; //上一次执行时间处理函数的时间\n&nbsp; &nbsp;&nbsp;list *scripts_queue;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //用于保存脚本的队列\n&nbsp;&nbsp;&nbsp; char *announce_ip;&nbsp; //向其他哨兵实例发送的IP信息\n&nbsp;&nbsp;&nbsp; int announce_port;&nbsp; //向其他哨兵实例发送的端口号\n&nbsp; &nbsp;&nbsp;…\n} sentinel;\n</code></pre><p>这样一来，initSentinel函数就主要会把这些属性设置为初始化值。比如，它会为监听的主节点创建一个哈希表，哈希项的键记录了主节点的名称，而值记录了对应的数据结构指针。</p><p></p><p>到这里，哨兵实例配置项的初始化工作就完成了。下图展示了这个初始化过程，你可以再回顾下。</p><p><img src=\"https://static001.geekbang.org/resource/image/6e/ac/6e692yy58da223d98b2d4d390c8e97ac.jpg?wh=1920x819\" alt=\"图片\"></p><p>接下来，main函数还会调用initServer函数完成server本身的初始化操作，这部分哨兵实例也是会执行的。然后，main函数就会调用<strong>sentinelIsRunning函数</strong>（在sentinel.c文件中）启动哨兵实例。</p><h3>启动哨兵实例</h3><p>sentinelIsRunning函数的执行逻辑比较简单，它首先会确认哨兵实例的配置文件存在并且可以正常写入。然后，它会检查哨兵实例是否设置了ID。如果没有设置ID的话，sentinelIsRunning函数就会为哨兵实例随机生成一个ID。</p><p>最后，sentinelIsRunning函数会调用sentinelGenerateInitialMonitorEvents函数（在sentinel.c文件中），给每个被监听的主节点发送事件信息。下图展示了sentinelIsRunning函数的基本执行流程，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/6a/bd/6a0241e822b02db8d907f7fdda48cebd.jpg?wh=1920x1080\" alt=\"图片\"></p><p>那么，<strong>sentinelIsRunning函数是如何获取到主节点的地址信息呢？</strong></p><p>这就和我刚才给你介绍的<strong>initSentinel函数</strong>有关了，它会初始化哨兵实例的数据结构sentinel.masters。这个结构是使用了一个哈希表记录监听的主节点，每个主节点会使用<strong>sentinelRedisInstance结构</strong>来保存。而在sentinelRedisInstance结构中，就包含了被监听主节点的地址信息。这个地址信息是由sentienlAddr结构体保存的，其中包括了节点的IP和端口号，如下所示：</p><pre><code class=\"language-plain\">typedef struct sentinelAddr {\n&nbsp; &nbsp; char *ip;\n&nbsp; &nbsp; int port;\n} sentinelAddr;\n</code></pre><p>此外，sentinelRedisInstance结构中还包括了一些和主节点、故障切换相关的其他信息，比如主节点名称、ID、监听同一个主节点的其他哨兵实例、主节点的从节点、主节点主观下线和客观下线的时长，等等。以下代码展示了sentinelRedisInstance结构的部分内容，你可以看看。</p><pre><code class=\"language-plain\">typedef struct sentinelRedisInstance {\n&nbsp; &nbsp; int flags;      //实例类型、状态的标记\n&nbsp; &nbsp; char *name;&nbsp; &nbsp; &nbsp;//实例名称\n&nbsp; &nbsp; char *runid;&nbsp; &nbsp; //实例ID\n&nbsp; &nbsp; uint64_t config_epoch;&nbsp; //配置的纪元\n&nbsp; &nbsp; sentinelAddr *addr; //实例地址信息\n    ...\n    mstime_t s_down_since_time; //主观下线的时长\n&nbsp; &nbsp; mstime_t o_down_since_time; //客观下线的时长\n    ...\n    dict *sentinels;&nbsp; &nbsp; //监听同一个主节点的其他哨兵实例\n&nbsp; &nbsp;dict *slaves;   //主节点的从节点\n   ...\n}\n</code></pre><p>这里，你需要注意下，sentinelRedisInstance是一个通用的结构体，<strong>它不仅可以表示主节点，也可以表示从节点或者其他的哨兵实例</strong>。</p><p>这个结构体的成员变量有一个<strong>flags</strong>，它可以设置为不同的值，从而表示不同类型的实例。比如，当flags设置为SRI_MASTER、SRI_SLAVE或SRI_SENTINEL这三种宏定义（在sentinel.c文件中）时，就分别表示当前实例是主节点、从节点或其他哨兵。你在阅读哨兵相关的源码时，可以看到代码中会对flags进行判断，获得当前实例类型，然后再执行相应的代码逻辑。</p><p>好了，到这里，你就知道当哨兵要和被监听的主节点通信时，它只需要从sentinel.masters结构中获取主节点对应的sentinelRedisInstance实例，然后就可以给主节点发送消息了。</p><p>这个sentinelGenerateInitialMonitorEvents函数的执行逻辑，你可以参考以下代码：</p><pre><code class=\"language-plain\">void sentinelGenerateInitialMonitorEvents(void) {\n&nbsp; &nbsp; dictIterator *di;\n&nbsp; &nbsp; dictEntry *de;\n\n&nbsp; &nbsp; di = dictGetIterator(sentinel.masters);//获取masters的迭代器\n&nbsp; &nbsp; while((de = dictNext(di)) != NULL) { //获取被监听的主节点\n&nbsp; &nbsp; &nbsp; &nbsp; sentinelRedisInstance *ri = dictGetVal(de);\n&nbsp; &nbsp; &nbsp; &nbsp; sentinelEvent(LL_WARNING,\"+monitor\",ri,\"%@ quorum %d\",ri-&gt;quorum);   //发送+monitor事件\n&nbsp; &nbsp; }\n&nbsp; &nbsp; dictReleaseIterator(di);\n}\n</code></pre><p>从代码中，你可以看到，sentinelGenerateInitialMonitorEvents函数是调用sentinelEvent函数（在sentinel.c文件中）来实际发送事件信息的。</p><p><strong>sentinelEvent函数</strong>的原型定义如下，它的参数level表示当前的日志级别，type表示发送事件信息所用的订阅频道，ri表示对应交互的主节点，fmt则表示发送的消息内容。</p><pre><code class=\"language-plain\">void sentinelEvent(int level, char *type, sentinelRedisInstance *ri, const char *fmt, ...) \n</code></pre><p>那么，sentinelEvent函数会先<strong>判断传入的消息内容开头的两个字符，是否为“%”和“@”</strong>，如果是的话，它就会判断监听实例的类型是否为主节点。然后如果是主节点，sentinelEvent函数会把监听实例的名称、IP和端口号加入到待发送的消息中，如下所示：</p><pre><code class=\"language-plain\">...\n//如果传递消息以\"%\"和\"@\"开头，就判断实例是否为主节点\nif (fmt[0] == '%' &amp;&amp; fmt[1] == '@') {\n   //判断实例的flags标签是否为SRI_MASTER，如果是，就表明实例是主节点\n   sentinelRedisInstance *master = (ri-&gt;flags &amp; SRI_MASTER) ?\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;NULL : ri-&gt;master;\n   //如果当前实例是主节点，根据实例的名称、IP地址、端口号等信息调用snprintf生成传递的消息msg\n&nbsp; &nbsp;if (master) {\n&nbsp; &nbsp;   snprintf(msg, sizeof(msg), \"%s %s %s %d @ %s %s %d\", sentinelRedisInstanceTypeStr(ri), ri-&gt;name, ri-&gt;addr-&gt;ip, ri-&gt;addr-&gt;port,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; master-&gt;name, master-&gt;addr-&gt;ip, master-&gt;addr-&gt;port);\n&nbsp; }\n        ...\n}\n...\n</code></pre><p>然后，sentinelEvent函数会把传入的消息中，除了开头两个字符以外的剩余内容加入到待发送的消息中。最后，sentinelEvent函数会调用pubsubPublishMessage函数（在pubsub.c文件中），将消息发送到对应的频道中，如下所示：</p><pre><code class=\"language-plain\">&nbsp;if (level != LL_DEBUG) {\n&nbsp; &nbsp; &nbsp; &nbsp; channel = createStringObject(type,strlen(type));\n&nbsp; &nbsp; &nbsp; &nbsp; payload = createStringObject(msg,strlen(msg));\n&nbsp; &nbsp; &nbsp; &nbsp; pubsubPublishMessage(channel,payload);\n&nbsp; &nbsp; &nbsp; &nbsp; ...\n  }\n</code></pre><p>另外这里你要注意一点，刚才我介绍的sentinelGenerateInitialMonitorEvents函数，它给sentinelEvent函数发送的参数type是“+monitor”，这就表明它会将事件信息发到\"+monitor\"频道上。</p><p>下面的图展示了sentinelEvent函数的执行流程，你可以再回顾下。</p><p><img src=\"https://static001.geekbang.org/resource/image/8f/6a/8f50ed685a3c66b34a2d1b2697b6e96a.jpg?wh=1920x1080\" alt=\"图片\"></p><p>好了，到这里，哨兵实例的初始化就基本完成了。接下来，哨兵就会和主节点进行通信，监听主节点的状态变化，我会在接下来的课程中给你具体介绍它们之间的通信过程。</p><p></p><h2>小结</h2><p>今天这节课，我给你介绍了哨兵实例的初始化过程。哨兵实例和Redis实例使用的是相同的入口main函数，但是由于哨兵实例在运行时使用的配置项、运行时信息、支持的可执行命令、事件处理和Redis实例又有所区别。</p><p>所以，main函数会先通过checkForSentinelMode函数来判断当前运行是否为哨兵实例，并相应地设置全局配置项<strong>server.sentinel_mode</strong>，这个配置项就会在源码其他地方被用于标识哨兵实例是否运行。</p><p>这样，当启动的是哨兵实例时，main函数会调用initSentinelConfig、initSentinel函数来完成哨兵实例的初始化，然后，main函数会调用sentinelIsRunning函数，来向被监听的主节点发送事件信息，从而开始监听主节点。</p><p>最后，我也想再提醒你一下，从今天这节课的内容中，我们可以看到哨兵实例在运行后，开始使用<strong>Pub/Sub订阅频道模式</strong>的通信方法，这种通信方法通常适用于多对多的通信场景中。</p><p>因为哨兵实例除了和主节点通信外，还需要和其他哨兵实例、客户端进行通信，而采用Pub/Sub通信方法，可以高效地完成这些通信过程。我在接下来的课程中还会给你介绍Pub/Sub通信方法在哨兵运行过程中的使用，也希望你在学完这部分课程内容之后，能够掌握这种通信方法的实现。</p><h2>每课一问</h2><p>哨兵实例本身是有配置文件sentinel.conf的，那么你能在哨兵实例的初始化过程中，找到解析这个配置文件的函数吗？</p>","neighbors":{"left":{"article_title":"21 | 主从复制：基于状态机的设计与实现","id":420285},"right":{"article_title":"23 | 从哨兵Leader选举学习Raft协议实现（上）","id":421736}}},{"article_id":421736,"article_title":"23 | 从哨兵Leader选举学习Raft协议实现（上）","article_content":"<p>你好，我是蒋德钧。</p><p></p><p>在上节课，我们了解了哨兵实例的初始化过程。哨兵实例一旦运行后，会周期性地检查它所监测的主节点的运行状态。当发现主节点出现客观下线时，哨兵实例就要开始执行故障切换流程了。</p><p></p><p>不过，我们在部署哨兵实例时，通常会部署多个哨兵来进行共同决策，这样就避免了单个哨兵对主节点状态的误判。但是这同时也给我们带来了一个问题，即<strong>当有多个哨兵判断出主节点故障后，究竟由谁来执行故障切换？</strong></p><p></p><p>实际上，这就和<strong>哨兵Leader选举</strong>有关了。而哨兵Leader选举，又涉及到分布式系统中经典的共识协议：Raft协议。学习和掌握Raft协议的实现，对于我们在分布式系统开发中实现分布式共识有着非常重要的指导作用。</p><p>所以接下来的两节课，我会带你了解Raft协议以及Redis源码中，基于Raft协议实现Leader选举的具体设计思路。今天我们先来学习下Raft协议的基本流程、它和哨兵Leader选举的关系，以及哨兵工作的整体执行流程，这部分内容也是我们学习哨兵Leader选举的必备知识。</p><p></p><h2>哨兵Leader选举和Raft协议</h2><p>当哨兵发现主节点有故障时，它们就会选举一个Leader出来，由这个Leader负责执行具体的故障切换流程。但因为哨兵本身会有多个实例，所以，在选举Leader的过程中，就需要按照一定的协议，让多个哨兵就“Leader是哪个实例”达成一致的意见，这也就是<strong>分布式共识</strong>。</p><!-- [[[read_end]]] --><p>而Raft协议可以用来实现分布式共识，这是一种在分布式系统中实现多节点达成一致性的算法，可以用来在多个节点中选举出Leader节点。为了实现这一目标，Raft协议把节点设计成了三种类型，分别是Leader、Follower和Candidate。</p><p>Raft协议对于Leader节点和Follower节点之间的交互有两种规定：</p><ul>\n<li>正常情况下，在一个稳定的系统中，只有Leader和Follower两种节点，并且Leader会向Follower发送心跳消息。</li>\n<li>异常情况下，如果Follower节点在一段时间内没有收到来自Leader节点的心跳消息，那么，这个Follower节点就会转变为Candidate节点，并且开始竞选Leader。</li>\n</ul><p>然后，当一个Candidate节点开始竞选Leader时，它会执行如下操作：</p><ul>\n<li>给自己投一票；</li>\n<li>向其他节点发送投票请求，并等待其他节点的回复；</li>\n<li>启动一个计时器，用来判断竞选过程是否超时。</li>\n</ul><p></p><p>在这个Candidate节点等待其他节点返回投票结果的过程中，如果它<strong>收到了Leader节点的心跳消息</strong>，这就表明，此时已经有Leader节点被选举出来了。那么，这个Candidate节点就会转换为Follower节点，而它自己发起的这轮竞选Leader投票过程就结束了。</p><p></p><p>而如果这个Candidate节点，<strong>收到了超过半数的其他Follower节点返回的投票确认消息</strong>，也就是说，有超过半数的Follower节点都同意这个Candidate节点作为Leader节点，那么这个Candidate节点就会转换为Leader节点，从而可以执行Leader节点需要运行的流程逻辑。</p><p></p><p>这里，你需要注意的是，每个Candidate节点发起投票时，都会记录当前的投票轮次，Follower节点在投票过程中，每一轮次只能把票投给一个Candidate节点。而一旦Follower节点投过票了，它就不能再投票了。如果在一轮投票中，没能选出Leader节点，比如有多个Candidate节点获得了相同票数，那么Raft协议会让Candidate节点进入下一轮，再次开始投票。</p><p></p><p>好了，现在你就了解了Raft协议中Leader选举的基本过程和原则。不过你还要清楚一点，就是<strong>Redis哨兵在实现时，并没有完全按照Raft协议来实现</strong>，这主要体现在，Redis哨兵实例在正常运行的过程中，不同实例间并不是Leader和Follower的关系，而是<strong>对等的关系</strong>。只有当哨兵发现主节点有故障了，此时哨兵才会按照Raft协议执行选举Leader的流程。</p><p>接下来，我们就从代码层面来看下，哨兵是如何执行Raft协议来选举Leader的。</p><p></p><h2>哨兵的时间事件处理函数sentinelTimer</h2><p>我们先来看下哨兵的时间事件处理函数sentinelTimer（在<a href=\"https://github.com/redis/redis/tree/5.0/src/sentinel.c\">sentinel.c</a>文件中），因为哨兵Leader选举是在这个函数执行过程中触发的。</p><p></p><p>sentinelTimer函数本身是在serverCron函数（在server.c文件中）中调用的，如下所示：</p><pre><code class=\"language-plain\">int serverCron(struct aeEventLoop *eventLoop, long long id, void *clientData) {\n…\nif (server.sentinel_mode) sentinelTimer(); //如果当前运行的是哨兵，则运行哨兵的时间事件处理函数\n…\n}\n</code></pre><p>serverCron函数每100ms执行一次，在执行过程中，它会检查<strong>server.sentinel_mode配置项</strong>，如果该配置项为1，就表明当前运行的是哨兵实例，紧接着它就会调用sentinelTimer函数。因此，sentinelTimer函数也会周期性执行。我在上节课给你介绍过server.sentinel_mode配置项的设置，你也可以再去回顾下。</p><p>接着，sentinelTimer会调用<strong>sentinelHandleDictOfRedisInstances函数</strong>。这个函数的原型如下，它的参数是一个哈希表：</p><pre><code class=\"language-plain\">void sentinelHandleDictOfRedisInstances(dict *instances)&nbsp;\n</code></pre><p>实际上，当sentinelTimer调用sentinelHandleDictOfRedisInstances时，传入的哈希表参数，就是当前哨兵实例状态信息sentinelState结构中维护的master哈希表，其中记录了当前哨兵监听的主节点，如下所示：</p><pre><code class=\"language-plain\">void sentinelTimer(void) {\n&nbsp; &nbsp; ...\n    //将当前哨兵监听的主节点作为参数传入sentinelHandleDictOfRedisInstances函数\n&nbsp; &nbsp; sentinelHandleDictOfRedisInstances(sentinel.masters); \n    ...\n}\n</code></pre><p>sentinelHandleDictOfRedisInstances函数会执行一个循环流程，在该流程中，它会从sentinel.master哈希表中逐一取出监听的主节点，并调用sentinelHandleRedisInstance函数对该主节点进行处理，如下所示：</p><pre><code class=\"language-plain\">void sentinelHandleDictOfRedisInstances(dict *instances) {\n&nbsp; &nbsp;...\n   di = dictGetIterator(instances); //获取哈希表的迭代器\n&nbsp; &nbsp;while((de = dictNext(di)) != NULL) {\n      //从哈希表中取出一个实例\n&nbsp; &nbsp; &nbsp; sentinelRedisInstance *ri = dictGetVal(de); \n      //调用sentinelHandleRedisInstance处理实例\n&nbsp; &nbsp; &nbsp; sentinelHandleRedisInstance(ri);\n      ...\n    }\n   ...\n}\n</code></pre><p>注意，这里的<strong>sentinelHandleRedisInstance函数</strong>是哨兵工作机制中的一个重要函数，它实现了哨兵实例工作的主体逻辑。下面我们就先来了解下它的主要执行步骤，然后我们再分别学习其中关键步骤的实现细节。</p><h3>sentinelHandleRedisInstance函数的执行流程</h3><p>首先你要知道，sentinelHandleRedisInstance函数会被周期性执行，用来检测哨兵监听的节点的状态。这个函数主要会依次执行以下四个步骤。</p><p><strong>第一步：重建连接</strong></p><p>sentinelHandleRedisInstance会调用sentinelReconnectInstance函数，尝试和断连的实例重新建立连接。</p><p></p><p><strong>第二步：发送命令</strong></p><p>sentinelHandleRedisInstance会调用sentinelSendPeriodicCommands函数，向实例发送PING、INFO等命令。</p><p></p><p><strong>第三步：判断主观下线</strong></p><p>sentinelHandleRedisInstance会调用sentinelCheckSubjectivelyDown函数，检查监听的实例是否主观下线。</p><p></p><p><strong>第四步：判断客观下线和执行故障切换</strong></p><p>在这一步中，sentinelHandleRedisInstance函数的运行逻辑主要是针对被监听的主节点来执行的，而这一步又可以分成以下四个小步骤：</p><ul>\n<li>首先，针对监听的主节点，调用sentinelCheckObjectivelyDown函数检查其是否客观下线。</li>\n<li>紧接着，调用sentinelStartFailoverIfNeeded函数判断是否要启动故障切换。如果要启动故障切换，就调用sentinelAskMasterStateToOtherSentinels函数，获取其他哨兵实例对主节点状态的判断，并向其他哨兵发送is-master-down-by-addr命令，发起Leader选举。</li>\n<li>然后，调用sentinelFailoverStateMachine执行故障切换。</li>\n<li>最后，再次调用sentinelAskMasterStateToOtherSentinels函数，获取其他哨兵实例对主节点状态的判断。</li>\n</ul><p></p><p>这里你需要注意下，因为sentinelHandleRedisInstance函数处理的对象是sentinelRedisInstance结构的实例，而sentinelRedisInstance结构可以表示主节点、从节点以及哨兵实例。在刚才介绍的四个大步骤中，第一、二和三步会对主节点、从节点和哨兵实例都执行，而第四步只有在当前sentinelRedisInstance表示主节点时，才会执行。</p><p>下图也展示了sentinelHandleRedisInstance函数执行的基本逻辑。</p><p><img src=\"https://static001.geekbang.org/resource/image/68/6b/6889167080a11c0506fe13b8f5c0586b.jpg?wh=2000x1125\" alt=\"\"></p><p>现在，我们就了解了sentinelHandleRedisInstance函数的基本执行过程。</p><p>另外，就像刚才给你介绍的，因为sentinelHandleDictOfRedisInstances函数接收的参数，是当前哨兵监听的主节点哈希表，而每个主节点又会记录同时监听它的其他哨兵实例以及它的从节点，这分别对应了主节点数据结构sentinelRedisInstance中的sentinels和slaves成员变量，这两个变量本身也是用哈希表来保存其他哨兵和从节点信息的，如下所示：</p><pre><code class=\"language-plain\">typedef struct sentinelRedisInstance {\n...\n&nbsp;dict *sentinels;&nbsp; &nbsp; //监听同一个主节点的其他哨兵实例\n dict *slaves;&nbsp;     //当前主节点的从节点\n...\n}\n</code></pre><p>所以，哨兵在sentinelHandleDictOfRedisInstances函数中，调用sentinelHandleRedisInstance处理完每个主节点后，还会针对监听主节点的其他哨兵实例，以及主节点的从节点，分别调用sentinelHandleDictOfRedisInstances函数进行处理，如下所示：</p><pre><code class=\"language-plain\">//如果当前是主节点，那么调用sentinelHandleDictOfRedisInstances分别处理该主节点的从节点，以及监听该主节点的其他哨兵\nif (ri-&gt;flags &amp; SRI_MASTER) {\n   sentinelHandleDictOfRedisInstances(ri-&gt;slaves);\n&nbsp; &nbsp;sentinelHandleDictOfRedisInstances(ri-&gt;sentinels);\n   ...\n}\n</code></pre><p>也就是说，<strong>sentinelTimer周期性执行的一个重要任务，就是sentinelHandleDictOfRedisInstances函数。</strong></p><p>那么，sentinelTimer除了调用sentinelHandleDictOfRedisInstances以外，它一开始还会调用<strong>sentinelCheckTiltCondition函数</strong>检查是否需要进入TILT模式。这里，你需要注意下，对于哨兵来说，TILT模式是一种特殊的运行模式，当哨兵连续两次的时间事件处理间隔时长为负值，或是间隔时长过长，那么哨兵就会进入TILT模式。在该模式下，哨兵只会定期发送命令收集信息，而不会执行故障切换流程。</p><p>此外，sentinelTimer函数在调用执行完sentinelHandleDictOfRedisInstances函数后，还会依次调用sentinelRunPendingScripts、sentinelCollectTerminatedScripts和sentinelKillTimedoutScripts这三个函数，来运行待执行的脚本、收集结束的脚本以及将超时的脚本kill掉。</p><p>最后，sentinelTimer函数会<strong>调整server.hz配置项</strong>，它会在server.hz默认值的基础上增加一个随机值，而这个配置项决定了sentinelTimer本身的执行频率。因此在调整后，sentinelTimer函数就会按照修改后的运行频率再次执行。</p><p>下面的代码展示了sentinelTimer函数的整体执行流程，你可以再回顾下。</p><pre><code class=\"language-plain\">void sentinelTimer(void) {\n&nbsp; &nbsp; sentinelCheckTiltCondition(); \n&nbsp; &nbsp; sentinelHandleDictOfRedisInstances(sentinel.masters);\n&nbsp; &nbsp; sentinelRunPendingScripts();\n&nbsp; &nbsp; sentinelCollectTerminatedScripts();\n&nbsp; &nbsp; sentinelKillTimedoutScripts();\n&nbsp; &nbsp; server.hz = CONFIG_DEFAULT_HZ + rand() % CONFIG_DEFAULT_HZ;\n}\n</code></pre><p>好了，到这里，我们就了解了哨兵实例的时间事件处理函数sentinelTimer。在该函数的执行流程中，你需要重点关注的是sentinelHandleRedisInstance函数，这是哨兵周期性检测主节点下线状态和执行故障切换的主要函数。并且一旦需要执行故障切换，哨兵的Leader选举也会发生在这里。所以接下来，我们就来具体学习下sentinelHandleRedisInstance函数的实现。</p><h2>sentinelHandleRedisInstance函数的内部实现</h2><p>通过前面针对sentinelHandleRedisInstance函数执行流程的介绍，现在我们知道，该函数首先会依次调用sentinelReconnectInstance、sentinelSendPeriodicCommand和sentinelCheckSubjectiveDown这三个函数。所以这里，我们先来看下这三个函数的实现和主要作用。然后在下节课，我会给你详细介绍sentinelHandleRedisInstance中其他函数的实现，以此帮助你全面掌握哨兵工作过程中的关键操作。</p><h3>sentinelReconnectInstance函数</h3><p>sentinelReconnectInstance函数的主要作用是<strong>判断哨兵实例和主节点间连接是否正常</strong>，如果发生了断连情况，它会重新建立哨兵和主节点的连接。</p><p>其实，哨兵在使用sentinelRedisInstance结构保存主节点信息时，在该结构中有一个instanceLink类型的成员变量<strong>link</strong>，该变量就记录了哨兵和主节点间的两个连接，分别对应用来发送命令的连接cc和用来发送Pub/Sub消息的连接pc，如下所示：</p><pre><code class=\"language-plain\">typedef struct instanceLink {\n...\nredisAsyncContext *cc; //用于发送命令的连接 \nredisAsyncContext *pc; //用于发送pub-sub消息的连接\n...\n}\n</code></pre><p>sentinelReconnectInstance函数执行时会<strong>检查这两个连接是否为NULL</strong>。如果是的话，那么它就会调用redisAsyncConnectBind函数（在<a href=\"https://github.com/redis/redis/tree/5.0/deps/hiredis/async.c\">async.c</a>文件中），重新和主节点建立这两个连接。</p><p>这是因为，哨兵在监听主节点状态过程中，正是要通过命令连接cc向主节点发送命令，而通过Pub/Sub连接pc，订阅主节点的Hello频道，从而就可以通过这个频道再发现监听同一主节点的其他哨兵实例。</p><p>这样，在完成了和主节点的连接重建后，哨兵会继续调用sentinelSendPeriodicCommands函数。</p><h3>sentinelSendPeriodicCommands函数</h3><p>sentinelSendPeriodicCommands的逻辑比较简单，它先是调用<strong>redisAsyncCommand函数</strong>（在async.c文件中），通过哨兵和主节点间的命令连接cc，向主节点发送INFO命令。然后，再通过<strong>sentinelSendPing函数</strong>（在sentinel.c文件中）向主节点发送PING命令（PING命令的发送也是通过哨兵和主节点的命令连接cc来完成的）。</p><p>最后，sentinelSendPeriodicCommands函数会调用<strong>sentinelSendHello函数</strong>（在sentinel.c文件中），通过哨兵和主节点的命令连接cc，向主节点发送PUBLISH命令，将哨兵自身的IP、端口号和ID号信息发送给主节点。</p><p>接下来，哨兵就会调用sentinelCheckSubjectivelyDown函数，来判断监听的主节点是否主观下线。</p><h3>sentinelCheckSubjectivelyDown函数</h3><p>sentinelCheckSubjectivelyDown函数首先会计算当前距离上次哨兵发送PING命令的时长elapsed，如下所示：</p><pre><code class=\"language-plain\">void sentinelCheckSubjectivelyDown(sentinelRedisInstance *ri) {\n...\nif (ri-&gt;link-&gt;act_ping_time)  //计算当前距离上一次发送PING命令的时长\n&nbsp; &nbsp; &nbsp; &nbsp; elapsed = mstime() - ri-&gt;link-&gt;act_ping_time;\nelse if (ri-&gt;link-&gt;disconnected) //如果哨兵和主节点的连接断开了，那么计算当前距离连接最后可用的时长\n&nbsp; &nbsp; &nbsp; &nbsp; elapsed = mstime() - ri-&gt;link-&gt;last_avail_time;\n...\n}\n</code></pre><p>计算完elapsed之后，sentinelCheckSubjectivelyDown函数会分别检测哨兵和主节点的命令发送连接，以及Pub/Sub连接的活跃程度。如果活跃度不够，那么哨兵会调用instanceLinkCloseConnection函数（在sentinel.c文件中），断开当前连接，以便重新连接。</p><p>紧接着，sentinelCheckSubjectivelyDown函数会根据以下两个条件，判断主节点是否为主观下线。</p><ul>\n<li><strong>条件一</strong>：当前距离上次发送PING的时长已经超过down_after_period阈值，还没有收到回复。down_after_period的值是由sentinel.conf配置文件中，down-after-milliseconds配置项决定的，其默认值是30s。</li>\n<li><strong>条件二</strong>：哨兵认为当前实例是主节点，但是这个节点向哨兵报告它将成为从节点，并且在down_after_period时长，再加上两个INFO命令间隔后，该节点还是没有转换成功。</li>\n</ul><p>当上面这两个条件有一个满足时，哨兵就判定主节点为主观下线了。然后，哨兵就会调用sentinelEvent函数发送“+sdown”事件信息。下面的代码展示了这部分的判断逻辑，你可以看下。</p><pre><code class=\"language-plain\">&nbsp;if (elapsed &gt; ri-&gt;down_after_period || \n&nbsp; (ri-&gt;flags &amp; SRI_MASTER &amp;&amp; ri-&gt;role_reported == SRI_SLAVE \n   &amp;&amp; &nbsp;mstime() - ri-&gt;role_reported_time &gt; (ri-&gt;down_after_period+SENTINEL_INFO_PERIOD*2)))\n&nbsp;{\n&nbsp; &nbsp; &nbsp; &nbsp; //判断主节点为主观下线\n&nbsp; &nbsp; &nbsp; &nbsp; if ((ri-&gt;flags &amp; SRI_S_DOWN) == 0) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sentinelEvent(LL_WARNING,\"+sdown\",ri,\"%@\");\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ri-&gt;s_down_since_time = mstime();\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ri-&gt;flags |= SRI_S_DOWN;\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; }&nbsp;\n</code></pre><p>好了，到这里，我们就先了解了sentinelHandleRedisInstance函数执行流程中的前三个关键操作。它们会分别用于重建哨兵和监控主节点的连接，向主节点发送检测命令，以及判断主节点主观下线状态。这三步也是哨兵每次执行周期性任务的必备操作。</p><h2>小结</h2><p>这节课，我主要是给你介绍了哨兵工作过程中的一个重要环节，也就是哨兵Leader的选举。这个选举过程是参考了分布式系统中常用的分布式共识协议Raft协议来实现的。所以，你需要先了解Raft协议的基本流程，包括<strong>Leader、Follower、Candidate三种节点类型</strong>，Follower成为Candidate的条件和具体操作，以及Leader投票的规则。</p><p>那么，对于哨兵Leader选举来说，它参考了Raft协议，但你需要注意的是，哨兵在正常运行时并不像Raft协议那样区分了三种节点类型，而是<strong>所有哨兵都是对等的</strong>。而当哨兵发现主节点故障，要执行故障切换时，会按照Raft协议中Leader选举的规则，进行投票选出Leader。这是哨兵Leader选举和Raft协议的区别与联系。</p><p>此外，我还介绍了哨兵的<strong>时间事件处理函数sentinelTimer</strong>，这个函数会对哨兵监听的每个主节点，周期性调用sentinelHandleRedisInstance函数，来检查主节点在线状态。当主节点客观下线了，哨兵会启动Leader选举并执行故障切换。这节课我们是先了解了sentinelHandleRedisInstance函数的整体执行流程，这样，你也能掌握哨兵的整体工作过程。同时，针对哨兵和主节点重建连接、发送命令和检查主观下线的三个函数，你也要有所了解，它们也是哨兵工作中的三个重要步骤。</p><p>那么，在下节课，我将带你了解哨兵Leader选举的具体过程以及故障切换的执行。</p><h2>每课一问</h2><p>哨兵实例执行的周期性函数sentinelTimer，它在函数执行逻辑的最后，会修改server.hz配置项，如下所示：</p><pre><code class=\"language-plain\">void sentinelTimer(void) {\n...\nserver.hz = CONFIG_DEFAULT_HZ + rand() % CONFIG_DEFAULT_HZ;\n}\n</code></pre><p>你知道调整server.hz的目的是什么吗？欢迎在留言区分享你的答案和思考，也欢迎你把今天的内容分享给更多的朋友。</p>","neighbors":{"left":{"article_title":"22 | 哨兵也和Redis实例一样初始化吗？","id":420759},"right":{"article_title":"24 | 从哨兵Leader选举学习Raft协议实现（下）","id":422625}}},{"article_id":422625,"article_title":"24 | 从哨兵Leader选举学习Raft协议实现（下）","article_content":"<p>你好，我是蒋德钧。</p><p></p><p>上节课，我给你介绍了Raft协议的基本流程，以及哨兵实例工作的基本过程。哨兵是通过serverCron函数的周期性执行，进而在serverCron中调用sentinelTimer函数，实现周期性处理哨兵相关的时间事件。而sentinelTimer函数处理的时间事件，就包括了对哨兵监听的每个主节点，它会通过调用sentinelHandleRedisInstance函数，来检查主节点的在线状态，并在主节点客观下线时进行故障切换。</p><p></p><p>另外，我还带你了解了sentinelHandleRedisInstance函数执行过程的前三步操作，分别是重连断连的实例、周期性给实例发送检测命令，检测实例是否主观下线，这也分别对应了sentinelReconnectInstance、sentinelSendPeriodicCommands和sentinelCheckSubjectivelyDown这三个函数，你可以再回顾下。</p><p></p><p>那么，今天这节课，我接着来给你介绍sentinelHandleRedisInstance函数执行过程中的剩余操作，分别是检测主节点是否客观下线、判断是否需要执行故障切换，以及需要故障切换时的哨兵Leader选举的具体过程。</p><!-- [[[read_end]]] --><p></p><p>学完这节课的内容，你就可以对哨兵工作的过程有个全面了解了。并且，你可以掌握如何在代码层面实现Raft协议来完成Leader选举。这样，当你日后在分布式系统中实现分布式共识时，这部分内容就能帮助指导你的代码设计与实现了。</p><p></p><p>接下来，我们先来看下主节点的客观下线判断。</p><p></p><h2>主节点客观下线判断</h2><p>现在我们知道，哨兵在sentinelHandleRedisInstance函数中会<strong>调用sentinelCheckObjectivelyDown函数</strong>（在sentinel.c文件中），来检测主节点是否客观下线。</p><p></p><p>而sentinelCheckObjectivelyDown函数在执行时，除了会检查当前哨兵对主节点主观下线的判断结果，还需要结合监听相同主节点的其他哨兵，对主节点主观下线的判断结果。它把这些判断结果综合起来，才能做出主节点客观下线的最终判断。</p><p></p><p>从代码实现层面来看，在哨兵用来记录主节点信息的<strong>sentinelRedisInstance结构体</strong>中，本身已经用哈希表保存了监听同一主节点的其他哨兵实例，如下所示：</p><pre><code class=\"language-plain\">typedef struct sentinelRedisInstance {\n…\ndict *sentinels;\n…\n}\n</code></pre><p>这样一来，sentinelCheckObjectivelyDown函数通过遍历主节点记录的sentinels哈希表，就可以获取其他哨兵实例对同一主节点主观下线的判断结果。这也是因为，sentinels哈希表中保存的哨兵实例，它们同样使用了sentinelRedisInstance这个结构体，而这个结构体的成员变量flags，会记录哨兵对主节点主观下线的判断结果。</p><p>具体来说，sentinelCheckObjectivelyDown函数会<strong>使用quorum变量，来记录判断主节点为主观下线的哨兵数量</strong>。如果当前哨兵已经判断主节点为主观下线，那么它会先把quorum值置为1。然后，它会依次判断其他哨兵的flags变量，<strong>检查是否设置了SRI_MASTER_DOWN的标记</strong>。如果设置了，它就会把quorum值加1。</p><p>当遍历完sentinels哈希表后，sentinelCheckObjectivelyDown函数会判断quorum值是否大于等于预设定的quorum阈值，这个阈值保存在了主节点的数据结构中，也就是master-&gt;quorum，而这个阈值是在sentinel.conf配置文件中设置的。</p><p>如果实际的quorum值大于等于预设的quorum阈值，sentinelCheckObjectivelyDown函数就判断主节点为客观下线，并<strong>设置变量odown为1，</strong>而这个变量就是用来表示当前哨兵对主节点客观下线的判断结果的。</p><p>这部分的判断逻辑如下代码所示，你可以看下：</p><pre><code class=\"language-plain\">void sentinelCheckObjectivelyDown(sentinelRedisInstance *master) {\n…\n//当前主节点已经被当前哨兵判断为主观下线\nif (master-&gt;flags &amp; SRI_S_DOWN) {\n&nbsp;&nbsp; quorum = 1; //当前哨兵将quorum值置为1\n&nbsp; &nbsp;\n&nbsp;&nbsp; di = dictGetIterator(master-&gt;sentinels);\n&nbsp;&nbsp; while((de = dictNext(di)) != NULL) {&nbsp; //遍历监听同一主节点的其他哨兵\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sentinelRedisInstance *ri = dictGetVal(de);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (ri-&gt;flags &amp; SRI_MASTER_DOWN) quorum++;\n&nbsp;&nbsp; }\n&nbsp;&nbsp; dictReleaseIterator(di);\n&nbsp;&nbsp; //如果quorum值大于预设的quorum阈值，那么设置odown为1。\n&nbsp;&nbsp; if (quorum &gt;= master-&gt;quorum) odown = 1;\n}\n</code></pre><p>另外，这里我也画了一张图，展示了该判断逻辑，你可以再来回顾下。<br>\n<img src=\"https://static001.geekbang.org/resource/image/c4/8f/c4201b2611c7e6c53604914b29b9418f.jpg?wh=1920x1080\" alt=\"图片\"></p><p>那么，一旦sentinelCheckObjectivelyDown函数判断主节点客观下线了，它就会调用sentinelEvent函数发送+odown事件消息，然后在主节点的flags变量中<strong>设置SRI_O_DOWN标记</strong>，如下所示：</p><pre><code class=\"language-plain\">//判断主节点为客观下线\nif (odown) {\n&nbsp;&nbsp; //如果没有设置SRI_O_DOWN标记\n&nbsp;&nbsp; if ((master-&gt;flags &amp; SRI_O_DOWN) == 0) {\n&nbsp;&nbsp;&nbsp; sentinelEvent(LL_WARNING,\"+odown\",master,\"%@ #quorum %d/%d\",\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; quorum, master-&gt;quorum); //发送+odown事件消息\n&nbsp;&nbsp; &nbsp;master-&gt;flags |= SRI_O_DOWN;&nbsp; //在主节点的flags中记录SRI_O_DOWN标记\n&nbsp;&nbsp;&nbsp; master-&gt;o_down_since_time = mstime(); //记录判断客观下线的时间\n&nbsp;&nbsp; }\n}\n</code></pre><p>也就是说，<strong>sentinelCheckObjectivelyDown函数是通过遍历监听同一主节点的其他哨兵的flags变量，来判断主节点是否客观下线的。</strong></p><p></p><p>不过，你看完刚才的代码可能会有一个疑问，在上节课学习的sentinelCheckSubjectivelyDown函数中，如果哨兵判断主节点为主观下线，是会在主节点的flags变量中<strong>设置SRI_S_DOWN标记</strong>，如下所示：</p><pre><code class=\"language-plain\">//哨兵已判断主节点为主观下线\n…\n//对应主节点的sentinelRedisInstance结构中flags没有记录主观下线\nif ((ri-&gt;flags &amp; SRI_S_DOWN) == 0) {\n&nbsp; &nbsp;…\n&nbsp;&nbsp; ri-&gt;flags |= SRI_S_DOWN;&nbsp; //在主节点的flags中记录主观下线的标记，\n}\n</code></pre><p>但是，sentinelCheckObjectivelyDown函数，是检查监听同一主节点的其他哨兵flags变量中的SRI_MASTER_DOWN标记，<strong>那么其他哨兵的SRI_MASTER_DOWN标记是如何设置的呢?</strong></p><p></p><p>这就和sentinelAskMasterStateToOtherSentinels函数（在sentinel.c文件中）有关系了，下面，我们来具体了解下这个函数。</p><p></p><h3>sentinelAskMasterStateToOtherSentinels函数</h3><p>sentinelAskMasterStateToOtherSentinels函数的主要目的，是向监听同一主节点的其他哨兵发送is-master-down-by-addr命令，进而询问其他哨兵对主节点的状态判断。</p><p></p><p>它会调用redisAsyncCommand函数（在<a href=\"https://github.com/redis/redis/tree/5.0/deps/hiredis/async.c\">async.c</a>文件中），依次向其他哨兵发送sentinel is-master-down-by-addr命令，同时，它设置了<strong>收到该命令返回结果的处理函数为sentinelReceiveIsMasterDownReply</strong>（在sentinel.c文件中），如下所示：</p><pre><code class=\"language-plain\">void sentinelAskMasterStateToOtherSentinels(sentinelRedisInstance *master, int flags) {\n…\ndi = dictGetIterator(master-&gt;sentinels);\n//遍历监听同一主节点的其他哨兵\nwhile((de = dictNext(di)) != NULL) {\n&nbsp;&nbsp; sentinelRedisInstance *ri = dictGetVal(de);\n&nbsp;&nbsp; …\n&nbsp;&nbsp; //发送sentinel is-master-down-by-addr命令\n&nbsp;&nbsp; retval = redisAsyncCommand(ri-&gt;link-&gt;cc,\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sentinelReceiveIsMasterDownReply, ri,\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \"%s is-master-down-by-addr %s %s %llu %s\",\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sentinelInstanceMapCommand(ri,\"SENTINEL\"),\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; master-&gt;addr-&gt;ip, port,\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sentinel.current_epoch,\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (master-&gt;failover_state &gt; SENTINEL_FAILOVER_STATE_NONE) ?\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sentinel.myid : \"*\");\n}\n…\n}\n</code></pre><p>另外从代码中，我们可以看到，sentinel is-master-down-by-addr命令中还包括主节点IP、主节点端口号、当前纪元（sentinel.current_epoch）和实例ID。下面展示的就是这个命令的格式：</p><pre><code class=\"language-plain\">sentinel is-master-down-by-addr 主节点IP 主节点端口 当前epoch 实例ID\n</code></pre><p>在这其中，哨兵会根据当前主节点所处的状态来设置实例ID。如果主节点已经要开始进行故障切换了，那么，实例ID会被设置为当前哨兵自身的ID，否则就会被设置为*号。</p><p>这里你需要注意的是，主节点的数据结构是使用了<strong>master-&gt;failover_state</strong>来记录故障切换的状态，其初始值为SENTINEL_FAILOVER_STATE_NONE（对应的数值为0），当主节点开始故障切换时，这个状态值就会大于SENTINEL_FAILOVER_STATE_NONE了。</p><p></p><p>好了，在了解了sentinelAskMasterStateToOtherSentinels函数的基本执行过程之后，我们还需要知道：sentinelAskMasterStateToOtherSentinels函数向其他哨兵发出了sentinel is-master-down-by-addr命令后，其他哨兵是如何处理的呢？</p><h3>sentinel is-master-down-by-addr命令的处理</h3><p>其实，哨兵对于sentinel开头的命令，都是在<strong>sentinelCommand函数</strong>（在sentinel.c文件）中进行处理的。sentinelCommand函数会根据sentinel命令后面跟的不同子命令，来执行不同的分支，而is-master-down-by-addr就是一条子命令。</p><p></p><p>在is-master-down-by-addr子命令对应的代码分支中，sentinelCommand函数会根据命令中的主节点IP和端口号，来获取主节点对应的sentinelRedisInstance结构体。</p><p>紧接着，它会判断主节点的flags变量中是否有SRI_S_DOWN和SRI_MASTER标记，也就是说，sentinelCommand函数会检查当前节点是否的确是主节点，以及哨兵是否已经将该节点标记为主观下线了。如果条件符合，那么它会设置<strong>isdown变量</strong>为1，而这个变量表示的就是哨兵对主节点主观下线的判断结果。</p><p></p><p>然后，sentinelCommand函数会把当前哨兵对主节点主观下线的判断结果，返回给发送sentinel命令的哨兵。它返回的结果主要包含三部分内容，分别是<strong>当前哨兵对主节点主观下线的判断结果</strong>、<strong>哨兵Leader的ID</strong>，以及<strong>哨兵Leader所属的纪元</strong>。</p><p></p><p>sentinelCommand函数，对sentinel命令处理的基本过程如下所示：</p><pre><code class=\"language-plain\">void sentinelCommand(client *c) {\n…\n// is-master-down-by-addr子命令对应的分支\nelse if (!strcasecmp(c-&gt;argv[1]-&gt;ptr,\"is-master-down-by-addr\")) {\n…\n//当前哨兵判断主节点为主观下线\nif (!sentinel.tilt &amp;&amp; ri &amp;&amp; (ri-&gt;flags &amp; SRI_S_DOWN) &amp;&amp; (ri-&gt;flags &amp; SRI_MASTER))\n&nbsp;&nbsp; isdown = 1;\n…\naddReplyMultiBulkLen(c,3); //哨兵返回的sentinel命令处理结果中包含三部分内容\naddReply(c, isdown ? shared.cone : shared.czero); //如果哨兵判断主节点为主观下线，第一部分为1，否则为0\naddReplyBulkCString(c, leader ? leader : \"*\"); //第二部分是Leader ID或者是*\naddReplyLongLong(c, (long long)leader_epoch); //第三部分是Leader的纪元\n…}\n…}\n</code></pre><p>你也可以参考下图：<br>\n<img src=\"https://static001.geekbang.org/resource/image/57/fd/573b2cb64005925500d338030f61a1fd.jpg?wh=1920x1080\" alt=\"图片\"></p><p>好了，到这里你就已经知道，哨兵会通过sentinelAskMasterStateToOtherSentinels函数，向监听同一节点的其他哨兵发送sentinel is-master-down-by-addr命令，来获取其他哨兵对主节点主观下线的判断结果。而其他哨兵是使用sentinelCommand函数，来处理sentinel is-master-down-by-addr命令，并在命令处理的返回结果中，包含自己对主节点主观下线的判断结果。</p><p></p><p>不过从刚才的代码中，你也可以看到，在其他哨兵返回的sentinel命令处理结果中，会包含哨兵Leader的信息。其实，这是因为sentinelAskMasterStateToOtherSentinels函数发送的sentinel is-master-down-by-addr命令本身，也可以用来<strong>触发哨兵Leader选举</strong>。这个我稍后会给你介绍。</p><p></p><p>那么，我们再回到前面讲主节点客观下线判断时提出的问题，sentinelCheckObjectivelyDown函数要检查监听同一主节点的其他哨兵flags变量中的SRI_MASTER_DOWN标记，但是，其他哨兵的SRI_MASTER_DOWN标记是如何设置的呢？</p><p></p><p>这实际上是和哨兵在sentinelAskMasterStateToOtherSentinels函数中，向其他哨兵发送sentinel is-master-down-by-addr命令时，设置的<strong>命令结果处理函数sentinelReceiveIsMasterDownReply</strong>有关。</p><p></p><h3>sentinelReceiveIsMasterDownReply函数</h3><p>在sentinelReceiveIsMasterDownReply函数中，它会判断其他哨兵返回的回复结果。回复结果会包含我刚才介绍的三部分内容，分别是当前哨兵对主节点主观下线的判断结果、哨兵Leader的ID，以及哨兵Leader所属的纪元。这个函数会进一步检查，其中第一部分内容“当前哨兵对主节点主观下线的判断结果”是否为1。</p><p>如果是的话，这就表明对应的哨兵已经判断主节点为主观下线了，那么当前哨兵就会把自己记录的对应哨兵的flags，设置为SRI_MASTER_DOWN。</p><p></p><p>下面的代码就展示了sentinelReceiveIsMasterDownReply函数判断其他哨兵回复结果的执行逻辑，你可以看下。</p><pre><code class=\"language-plain\">//r是当前哨兵收到的其他哨兵的命令处理结果\n//如果返回结果包含三部分内容，并且第一，二，三部分内容的类型分别是整数、字符串和整数\nif (r-&gt;type == REDIS_REPLY_ARRAY &amp;&amp; r-&gt;elements == 3 &amp;&amp;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; r-&gt;element[0]-&gt;type == REDIS_REPLY_INTEGER &amp;&amp;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; r-&gt;element[1]-&gt;type == REDIS_REPLY_STRING &amp;&amp;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; r-&gt;element[2]-&gt;type == REDIS_REPLY_INTEGER)\n{\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;ri-&gt;last_master_down_reply_time = mstime();\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //如果返回结果第一部分的值为1，则在对应哨兵的flags中设置SRI_MASTER_DOWN标记\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (r-&gt;element[0]-&gt;integer == 1) {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ri-&gt;flags |= SRI_MASTER_DOWN;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }\n</code></pre><p>所以到这里，你就可以知道，一个哨兵调用sentinelCheckObjectivelyDown函数，是直接检查其他哨兵的flags是否有SRI_MASTER_DOWN标记，而哨兵又是通过sentinelAskMasterStateToOtherSentinels函数，向其他哨兵发送sentinel is-master-down-by-addr命令，从而询问其他哨兵对主节点主观下线的判断结果的，并且会根据命令回复结果，在结果处理函数sentinelReceiveIsMasterDownReply中，设置其他哨兵的flags为SRI_MASTER_DOWN。下图也展示了这个执行逻辑，你可以再来整体回顾下。</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/51/7f/51c98fec129byy830c8878466c95337f.jpg?wh=1920x978\" alt=\"图片\"></p><p>那么，掌握了这个执行逻辑后，我们再来看下，哨兵选举是什么时候开始执行的。</p><p></p><h2>哨兵选举</h2><p>这里，为了了解哨兵选举的触发，我们先来复习下在上节课，我讲过的sentinelHandleRedisInstance函数中针对主节点的调用关系，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/27/f7/276ee9fb08acf2405aa24b4658387df7.jpg?wh=1920x1042\" alt=\"图片\"></p><p>从图中可以看到，sentinelHandleRedisInstance会先调用sentinelCheckObjectivelyDown函数，再调用sentinelStartFailoverIfNeeded函数，判断是否要开始故障切换，如果sentinelStartFailoverIfNeeded函数的返回值为<strong>非0值</strong>，那么sentinelAskMasterStateToOtherSentinels函数会被调用。否则的话，sentinelHandleRedisInstance就直接调用sentinelFailoverStateMachine函数，并再次调用sentinelAskMasterStateToOtherSentinels函数。</p><p></p><p>那么，在这个调用关系中，sentinelStartFailoverIfNeeded会判断是否要进行故障切换，它的<strong>判断条件</strong>有三个，分别是：</p><ul>\n<li>主节点的flags已经标记了SRI_O_DOWN；</li>\n<li>当前没有在执行故障切换；</li>\n<li>如果已经开始故障切换，那么开始时间距离当前时间，需要超过sentinel.conf文件中的sentinel failover-timeout配置项的2倍。</li>\n</ul><p></p><p>这三个条件都满足后，sentinelStartFailoverIfNeeded就会调用<strong>sentinelStartFailover函数</strong>，开始启动故障切换，而sentinelStartFailover会将主节点的failover_state设置为SENTINEL_FAILOVER_STATE_WAIT_START，同时在主节点的flags设置SRI_FAILOVER_IN_PROGRESS标记，表示已经开始故障切换，如下所示：</p><pre><code class=\"language-plain\">void sentinelStartFailover(sentinelRedisInstance *master) {\n…\nmaster-&gt;failover_state = SENTINEL_FAILOVER_STATE_WAIT_START;\nmaster-&gt;flags |= SRI_FAILOVER_IN_PROGRESS;\n…\n}\n</code></pre><p>而一旦sentinelStartFailover函数将主节点的failover_state设置为SENTINEL_FAILOVER_STATE_WAIT_START后，接下来，sentinelFailoverStateMachine函数就会执行状态机来完成实际的切换。不过，<strong>在实际切换前，sentinelAskMasterStateToOtherSentinels函数会被调用。</strong></p><p></p><p>看到这个调用关系，你可能会有个疑问：sentinelAskMasterStateToOtherSentinels函数是用来向其他哨兵询问对主节点主观下线的判断结果的，如果sentinelStartFailoverIfNeeded判断要开始执行故障切换，那么为什么还要调用sentinelAskMasterStateToOtherSentinels函数呢？</p><p></p><p>其实，这就和sentinelAskMasterStateToOtherSentinels函数的另一个作用有关了，这个函数除了会用来向其他哨兵询问对主节点状态的判断，它还可以用来<strong>向其他哨兵发起Leader选举</strong>。</p><p></p><p>在刚才给你介绍这个函数时，我提到它会给其他哨兵发送sentinel is-master-down-by-addr命令，这个命令包括主节点IP、主节点端口号、当前纪元（sentinel.current_epoch）和实例ID。其中，如果主节点的failover_state已经不再是SENTINEL_FAILOVER_STATE_NONE，那么实例ID会被设置为当前哨兵的ID。</p><p></p><p>而在sentinel命令处理函数中，如果检测到sentinel命令中的实例ID不为*号，那么就会调用<strong>sentinelVoteLeader函数</strong>来进行Leader选举。</p><pre><code class=\"language-plain\">//当前实例为主节点，并且sentinel命令的实例ID不等于*号\nif (ri &amp;&amp; ri-&gt;flags &amp; SRI_MASTER &amp;&amp; strcasecmp(c-&gt;argv[5]-&gt;ptr,\"*\")) {\n&nbsp;&nbsp; //调用sentinelVoteLeader进行哨兵Leader选举\n&nbsp;&nbsp; leader = sentinelVoteLeader(ri,(uint64_t)req_epoch, c-&gt;argv[5]-&gt;ptr,\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&amp;leader_epoch);\n}\n</code></pre><p>下面，我们来具体了解下这个sentinelVoteLeader函数。</p><h3>sentinelVoteLeader函数</h3><p>sentinelVoteLeader函数会实际执行投票逻辑，这里我通过一个例子来给你说明。</p><p></p><p>假设哨兵A判断主节点master客观下线了，它现在向哨兵B发起投票请求，哨兵A的ID是req_runid。那么哨兵B在执行sentinelVoteLeader函数时，这个函数会判断哨兵A的纪元（req_epoch）、哨兵B的纪元（sentinel.current_epoch），以及master记录的Leader的纪元（master-&gt;leader_epoch）。按照Raft协议的定义，哨兵A就是Candidate节点，而哨兵B就是Follower节点。</p><p></p><p>我在上节课给你介绍Raft协议时有提到过，Candidate发起投票都是有轮次记录的，Follower在一轮投票中只能投一票。这里的纪元正是起到了<strong>轮次记录</strong>的作用。而sentinelVoteLeader函数判断纪元也是按照Raft协议的要求，让Follower在一轮中只能投一票。</p><p></p><p>那么，<strong>sentinelVoteLeader函数让哨兵B投票的条件是</strong>：master记录的Leader的纪元小于哨兵A的纪元，同时，哨兵A的纪元要大于或等于哨兵B的纪元。这两个条件保证了哨兵B还没有投过票，否则的话，sentinelVoteLeader函数就直接返回当前master中记录的Leader ID了，这也是哨兵B之前投过票后记录下来的。</p><p></p><p>下面的代码展示了刚才介绍的这部分逻辑，你可以看下。</p><pre><code class=\"language-plain\">if (req_epoch &gt; sentinel.current_epoch) {\n&nbsp;&nbsp; sentinel.current_epoch = req_epoch;\n&nbsp;&nbsp; …\n&nbsp;&nbsp; sentinelEvent(LL_WARNING,\"+new-epoch\",master,\"%llu\",\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (unsigned long long) sentinel.current_epoch);\n}\n&nbsp;\nif (master-&gt;leader_epoch &lt; req_epoch &amp;&amp; sentinel.current_epoch &lt;= req_epoch)\n{\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sdsfree(master-&gt;leader);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; master-&gt;leader = sdsnew(req_runid);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; master-&gt;leader_epoch = sentinel.current_epoch;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; …\n}\nreturn master-&gt;leader ? sdsnew(master-&gt;leader) : NULL;\n</code></pre><p>那么现在，你就了解了sentinelVoteLeader函数是如何使用纪元判断来按照Raft协议完成哨兵Leader选举的了。</p><p>接下来，发起投票的哨兵仍然是通过sentinelReceiveIsMasterDownReply函数来处理其他哨兵对Leader投票的返回结果。这个返回结果，就像刚才给你介绍的，它的第二、三部分内容是哨兵Leader的ID，和哨兵Leader所属的纪元。发起投票的哨兵就可以从这个结果中获得其他哨兵对Leader的投票结果了。</p><p>最后，发起投票的哨兵在调用了sentinelAskMasterStateToOtherSentinels函数让其他哨兵投票后，会执行sentinelFailoverStateMachine函数。</p><p>如果主节点开始执行故障切换了，那么，主节点的failover_state，会被设置成SENTINEL_FAILOVER_STATE_WAIT_START。在这种状态下，sentinelFailoverStateMachine函数会调用sentinelFailoverWaitStart函数。而sentinelFailoverWaitStart函数，又会调用sentinelGetLeader函数，来判断发起投票的哨兵是否为哨兵Leader。发起投票的哨兵要想成为Leader，必须满足两个条件：</p><ul>\n<li>一是，获得超过半数的其他哨兵的赞成票</li>\n<li>二是，获得超过预设的quorum阈值的赞成票数。</li>\n</ul><p>这两个条件，也可以从sentinelGetLeader函数中的代码片段看到，如下所示。</p><pre><code class=\"language-plain\">//voters是所有哨兵的个数，max_votes是获得的票数\n&nbsp;voters_quorum = voters/2+1;  //赞成票的数量必须是超过半数以上的哨兵个数\n//如果赞成票数不到半数的哨兵个数或者少于quorum阈值，那么Leader就为NULL\n&nbsp;if (winner &amp;&amp; (max_votes &lt; voters_quorum || max_votes &lt; master-&gt;quorum))\n&nbsp; &nbsp; &nbsp; &nbsp; winner = NULL;\n//确定最终的Leader\nwinner = winner ? sdsnew(winner) : NULL;\n</code></pre><p>下图就展示了刚才介绍的确认哨兵Leader时的调用关系，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/19/52/192b72d0cf77cfefee8e26952b4f1652.jpg?wh=1920x839\" alt=\"图片\"></p><p>好了，到这里，最终的哨兵Leader就能被确定了。</p><p></p><h2>小结</h2><p>好了，今天这节课的内容就到这里，我们来小结下。</p><p></p><p>今天这节课，我在上节课的基础上，重点给你介绍了哨兵工作过程中的客观下线判断，以及Leader选举。因为这个过程涉及哨兵之间的交互询问，所以并不容易掌握，你需要好好关注以下我提到的重点内容。</p><p></p><p>首先，客观下线的判断涉及三个标记的判断，分别是主节点flags中的SRI_S_DOWN和SRI_O_DOWN，以及哨兵实例flags中的SRI_MASTER_DOWN，我画了下面这张表，展示了这三个标记的设置函数和条件，你可以再整体回顾下。</p><p><img src=\"https://static001.geekbang.org/resource/image/73/1f/738ea2375d2e302bb6742fa825650b1f.jpg?wh=1920x1027\" alt=\"图片\"></p><p>而一旦哨兵判断主节点客观下线了，那么哨兵就会<strong>调用sentinelAskMasterStateToOtherSentinels函数进行哨兵Leader选举</strong>。这里，你需要注意的是，向其他哨兵询问主节点主观下线状态，以及向其他哨兵发起Leader投票，都是通过sentinel is-master-down-by-addr命令实现的，而Redis源码是用了同一个函数sentinelAskMasterStateToOtherSentinels来发送该命令，所以你在阅读源码时，<strong>要注意区分sentinelAskMasterStateToOtherSentinels发送的命令是查询主节点主观下线状态还是进行投票</strong>。</p><p></p><p>最后，哨兵Leader选举的投票是在sentinelVoteLeader函数中完成的，为了符合Raft协议的规定，sentinelVoteLeader函数在执行时主要是要比较哨兵的纪元，以及master记录的Leader纪元，这样才能满足Raft协议对Follower在一轮投票中只能投一票的要求。</p><p>好了，到今天这节课，我们就了解了哨兵Leader选举的过程，你可以看到，虽然哨兵选举的最后执行逻辑就是在一个函数中，但是哨兵选举的触发逻辑是包含在了哨兵的整个工作过程中的，所以我们也需要掌握这个过程中的其他操作，比如主观下线判断、客观下线判断等。</p><p></p><h2>每课一问</h2><p>哨兵在sentinelTimer函数中调用sentinelHandleDictOfRedisInstances函数，对每个主节点都执行sentinelHandleRedisInstance函数，并且还会对主节点的所有从节点也执行sentinelHandleRedisInstance函数，那么，哨兵会判断从节点的主观下线和客观下线吗？</p>","neighbors":{"left":{"article_title":"23 | 从哨兵Leader选举学习Raft协议实现（上）","id":421736},"right":{"article_title":"25 | Pub/Sub在主从故障切换时是如何发挥作用的？","id":422627}}},{"article_id":422627,"article_title":"25 | Pub/Sub在主从故障切换时是如何发挥作用的？","article_content":"<p>你好，我是蒋德钧。</p><p></p><p>在前面两节课，我们学习了哨兵工作的基本过程：哨兵会使用sentinelRedisInstance结构体来记录主节点的信息，在这个结构体中又记录了监听同一主节点的其他哨兵的信息。<strong>那么，一个哨兵是如何获得其他哨兵的信息的呢？</strong></p><p></p><p>这其实就和哨兵在运行过程中，使用的<strong>发布订阅（Pub/Sub）</strong>通信方法有关了。Pub/Sub通信方法可以让哨兵订阅一个或多个频道，当频道中有消息时，哨兵可以收到相应消息；同时，哨兵也可以向频道中发布自己生成的消息，以便订阅该频道的其他客户端能收到消息。</p><p></p><p>今天这节课，我就带你来了解发布订阅通信方法的实现，以及它在哨兵工作过程中的应用。同时，你还可以了解哨兵之间是如何发现彼此的，以及客户端是如何知道故障切换完成的。Pub/Sub通信方法在分布式系统中可以用作多对多的信息交互，在学完这节课之后，当你要实现分布式节点间通信时，就可以把它应用起来。</p><p></p><p>好了，接下来，我们先来看下发布订阅通信方法的实现。</p><p></p><h2>发布订阅通信方法的实现</h2><p>发布订阅通信方法的基本模型是包含<strong>发布者、频道和订阅者</strong>，发布者把消息发布到频道上，而订阅者会订阅频道，一旦频道上有消息，频道就会把消息发送给订阅者。一个频道可以有多个订阅者，而对于一个订阅者来说，它也可以订阅多个频道，从而获得多个发布者发布的消息。</p><!-- [[[read_end]]] --><p>下图展示的就是发布者-频道-订阅者的基本模型，你可以看下。</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/b4/9d/b41f7bc078c210ef35d17bf3dc9be09d.jpg?wh=1920x789\" alt=\"图片\"></p><h3>频道的实现</h3><p>了解了发布订阅方法的基本模型后，我们就来看下频道是如何实现的，因为在发布订阅通信方法中，频道很重要，它是发布者和订阅者之间通信的基础。</p><p>其实，Redis的全局变量server使用了一个成员变量<strong>pubsub_channels</strong>来保存频道，pubsub_channels的初始化是在initServer函数（在<a href=\"https://github.com/redis/redis/tree/5.0/src/server.c\">server.c</a>文件中）中完成的。initServer函数会调用dictCreate创建一个<strong>keylistDictType类型的哈希表</strong>，然后用这个哈希表来保存频道的信息，如下所示：</p><pre><code class=\"language-plain\">void initServer(void) {\n…\nserver.pubsub_channels = dictCreate(&amp;keylistDictType,NULL);\n…\n}\n</code></pre><p>注意，当哈希表是keylistDictType类型时，它保存的哈希项的value就是一个列表。而之所以采用这种类型来保存频道信息，是因为Redis把频道的名称作为哈希项的key，而把订阅频道的订阅者作为哈希项的value。就像刚才我们介绍的，一个频道可以有多个订阅者，所以Redis在实现时，就会用列表把订阅同一个频道的订阅者保存起来。</p><p>pubsub_channels哈希表保存频道和订阅者的示意图如下所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/21/7f/21775d173b9db1650d3285a18d7d7a7f.jpg?wh=1920x874\" alt=\"图片\"></p><p>了解了频道是如何实现的之后，下面我们再分别看下发布命令和订阅命令的实现。</p><p></p><h3>发布命令的实现</h3><p>发布命令在Redis的实现中对应的是<strong>publish</strong>。我在<a href=\"https://time.geekbang.org/column/article/411558\">第14讲</a>中给你介绍过，Redis server在初始化时，会初始化一个命令表redisCommandTable，表中就记录了Redis支持的各种命令，以及对应的实现函数。</p><p></p><p>这张命令表是在server.c文件中定义的，当你需要了解Redis某个命令的具体实现函数时，一个快捷的方式就是在这张表中查找对应命令，然后就能定位到该命令的实现函数了。我们同样可以用这个方法来定位publish命令，这样就可以看到它<strong>对应的实现函数是publishCommand</strong>（在<a href=\"https://github.com/redis/redis/tree/5.0/src/pubsub.c\">pubsub.c</a>文件中），如下所示：</p><pre><code class=\"language-plain\">struct redisCommand redisCommandTable[] = {\n…\n{\"publish\",publishCommand,3,\"pltF\",0,NULL,0,0,0,0,0},\n…\n}\n</code></pre><p>我们来看下publishCommand函数，它是调用<strong>pubsubPublishMessage函数</strong>（在pubsub.c文件中）来完成消息的实际发送，然后，再返回接收消息的订阅者数量的，如下所示：</p><pre><code class=\"language-plain\">void publishCommand(client *c) {\n&nbsp;&nbsp;&nbsp; //调用pubsubPublishMessage发布消息\n&nbsp;&nbsp;&nbsp; int receivers = pubsubPublishMessage(c-&gt;argv[1],c-&gt;argv[2]);\n&nbsp;&nbsp;&nbsp; … //如果Redis启用了cluster，那么在集群中发送publish命令\n&nbsp;&nbsp;&nbsp; addReplyLongLong(c,receivers); //返回接收消息的订阅者数量\n}\n</code></pre><p>而对于pubsubPublishMessage函数来说，它的原型如下。你可以看到，它的两个参数分别是要<strong>发布消息的频道</strong>，以及<strong>要发布的具体消息</strong>。</p><pre><code class=\"language-plain\">int pubsubPublishMessage(robj *channel, robj *message)\n</code></pre><p>pubsubPublishMessage函数会在server.pubsub_channels哈希表中，查找要发布的频道。如果找见了，它就会遍历这个channel对应的订阅者列表，然后依次向每个订阅者发送要发布的消息。这样一来，只要订阅者订阅了这个频道，那么发布者发布消息时，它就能收到了。</p><pre><code class=\"language-plain\">//查找频道是否存在\nde = dictFind(server.pubsub_channels,channel);\n&nbsp;&nbsp;&nbsp; if (de) { //频道存在\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; …\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //遍历频道对应的订阅者，向订阅者发送要发布的消息\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; while ((ln = listNext(&amp;li)) != NULL) {\n&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;client *c = ln-&gt;value;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; …\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; addReplyBulk(c,channel);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; addReplyBulk(c,message);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; receivers++;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }\n&nbsp;&nbsp;&nbsp; }\n</code></pre><p>好了，了解了发布命令后，我们再来看下订阅命令的实现。</p><p></p><h3>订阅命令的实现</h3><p>和查找发布命令的方法一样，我们可以在redisCommandTable表中，找到订阅命令<strong>subscribe</strong>对应的实现函数是<strong>subscribeCommand</strong>（在pubsub.c文件中）。</p><p></p><p>subscribeCommand函数的逻辑比较简单，它会直接调用pubsubSubscribeChannel函数（在pubsub.c文件中）来完成订阅操作，如下所示：</p><p></p><pre><code class=\"language-plain\">void subscribeCommand(client *c) {\n&nbsp;&nbsp;&nbsp; int j;\n&nbsp;&nbsp;&nbsp; for (j = 1; j &lt; c-&gt;argc; j++)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; pubsubSubscribeChannel(c,c-&gt;argv[j]);\n&nbsp;&nbsp;&nbsp; c-&gt;flags |= CLIENT_PUBSUB;\n}\n</code></pre><p>从代码中，你可以看到，subscribeCommand函数的参数是client类型的变量，而它会根据client的<strong>argc</strong>成员变量执行一个循环，并把client的每个<strong>argv</strong>成员变量传给pubsubSubscribeChannel函数执行。</p><p>对于client的argc和argv来说，它们分别代表了要执行命令的参数个数和具体参数值，那么，<strong>这里的参数值是指什么呢?</strong></p><p></p><p>其实，我们来看下pubsubSubscribeChannel函数的原型就能知道了，如下所示：</p><pre><code class=\"language-plain\">int pubsubSubscribeChannel(client *c, robj *channel)\n</code></pre><p>pubsubSubscribeChannel函数的参数除了client变量外，还会<strong>接收频道的信息</strong>，这也就是说，subscribeCommand会按照subscribe执行时附带的频道名称，来逐个订阅频道。我也在下面展示了subscribe命令执行的一个示例，你可以看下。当这个subscribe命令执行时，它会订阅三个频道，分别是channel1、channel2和channel3：</p><pre><code class=\"language-plain\">subscribe channel1 channel2 channel3\n</code></pre><p>下面我们来具体看下pubsubSubscribeChannel函数的实现。这个函数的逻辑也比较清晰，主要可以分成三步。</p><p></p><p><strong>首先</strong>，它把要订阅的频道加入到server记录的pubsub_channels中。如果这个频道是新创建的，那么它会在pubsub_channels哈希表中新建一个哈希项，代表新创建的这个频道，并且会创建一个列表，用来保存这个频道对应的订阅者。</p><p></p><p>如果频道已经在pubsub_channels哈希表中存在了，那么pubsubSubscribeChannel函数就直接获取该频道对应的订阅者列表。</p><p></p><p><strong>然后</strong>，pubsubSubscribeChannel函数把执行subscribe命令的订阅者，加入到订阅者列表中。</p><p></p><p><strong>最后</strong>，pubsubSubscribeChannel函数会把成功订阅的频道个数返回给订阅者。</p><p></p><p>下面的代码展示了这部分的逻辑，你可以看下。</p><pre><code class=\"language-plain\">if (dictAdd(c-&gt;pubsub_channels,channel,NULL) == DICT_OK) {\n&nbsp;&nbsp; …\n&nbsp;&nbsp; de = dictFind(server.pubsub_channels,channel); //在pubsub_channels哈希表中查找频道\n&nbsp;&nbsp; if (de == NULL) { //如果频道不存在\n&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;clients = listCreate();&nbsp; //创建订阅者对应的列表\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; dictAdd(server.pubsub_channels,channel,clients); //新插入频道对应的哈希项\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; …\n&nbsp;&nbsp;&nbsp; } else {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; clients = dictGetVal(de); //频道已存在，获取订阅者列表\n&nbsp;&nbsp;&nbsp; }\n&nbsp;&nbsp;&nbsp; listAddNodeTail(clients,c); //将订阅者加入到订阅者列表\n}\n&nbsp;\n…\naddReplyLongLong(c,clientSubscriptionsCount(c)); //给订阅者返回成功订阅的频道数量\n</code></pre><p>现在，你就了解了Redis中发布订阅方法的实现。接下来，我们来看下哨兵在工作过程中，又是如何使用发布订阅功能的。</p><h2>发布订阅方法在哨兵中的应用</h2><p>首先，我们来看下哨兵用来发布消息的函数sentinelEvent。</p><h3>sentinelEvent函数与消息生成</h3><p>哨兵在使用发布订阅方法时，封装了<strong>sentinelEvent函数</strong>（在<a href=\"https://github.com/redis/redis/tree/5.0/src/sentinel.c\">sentinel.c</a>文件中），用来发布消息。所以，你在阅读sentinel.c文件中关于哨兵的源码时，如果看到sentinelEvent，这就表明哨兵正在用它来发布消息。</p><p>我在<a href=\"https://time.geekbang.org/column/article/420759\">第22讲</a>中给你介绍过sentinelEvent函数，你可以再回顾下。这个函数的原型如下所示：</p><pre><code class=\"language-plain\">void sentinelEvent(int level, char *type, sentinelRedisInstance *ri, const char *fmt, ...) \n</code></pre><p>实际上，这个函数最终是通过调用刚才我提到的pubsubPublishMessage函数，来实现向某一个频道发布消息的。那么，当我们要发布一条消息时，需要确定两个方面的内容：<strong>一个是要发布的频道，另一个是要发布的消息</strong>。</p><p>sentinelEvent函数的第二个参数type，表示的就是要发布的频道，而要发布的消息，就是由这个函数第四个参数fmt后面的省略号来表示的。</p><p>看到这里，你可以会有一个疑问，<strong>为什么sentinelEvent函数参数中会有省略号？</strong></p><p>其实，这里的省略号表示的是<strong>可变参数</strong>，当我们无法列出传递给函数的所有实参类型和数目时，我们可以用省略号来表示可变参数，这就是说，我们可以给sentinelEvent函数传递4个、5个、6个甚至更多的参数。</p><p>我在这里就以sentinelEvent函数的实现为例，给你介绍下可变参数的使用，这样一来，当你在开发分布式通信程序时，需要生成内容不定的消息时，就可以把哨兵源码中实现的方法用起来。</p><p>在sentinelEvent函数中，为了使用了可变参数，它主要包含了四个步骤：</p><ul>\n<li>首先，我们需要定义一个va_list类型的变量，假设是ap。这个变量是指向可变参数的指针。</li>\n<li>然后，当我们要在函数中使用可变参数了，就需要通过<strong>va_start宏</strong>来获取可变参数中的第一个参数。va_start宏有两个参数，一个是刚才定义的va_list类型变量ap，另一个是可变参数的前一个参数，也就是sentinelEvent函数参数中，省略号前的参数fmt。</li>\n<li>紧接着，我们可以使用vsnprintf函数，来按照fmt定义的格式，打印可变参数中的内容。vsnprintf函数会逐个获取可变参数中的每一个参数，并进行打印。</li>\n<li>最后，我们在获取完所有参数后，需要调用va_end宏将刚才创建的ap指针关闭。</li>\n</ul><p>下面的代码展示了刚才介绍的这个过程，你可以再看下。</p><pre><code class=\"language-plain\">void sentinelEvent(int level, char *type, sentinelRedisInstance *ri, const char *fmt, ...) {\n&nbsp; &nbsp; va_list ap;\n    ...&nbsp;\n    if (fmt[0] != '\\0') {\n&nbsp; &nbsp; &nbsp; &nbsp; va_start(ap, fmt);\n&nbsp; &nbsp; &nbsp; &nbsp; vsnprintf(msg+strlen(msg), sizeof(msg)-strlen(msg), fmt, ap);\n&nbsp; &nbsp; &nbsp; &nbsp; va_end(ap);\n&nbsp; &nbsp; }\n    ...\n}\n</code></pre><p>为了让你有个更加直观的了解，我在下面列了三个sentinelEvent函数的调用示例，你可以再学习掌握下。</p><p>第一个对应了哨兵调用sentinelCheckSubjectivelyDown函数<strong>检测出主节点主观下线后</strong>，sentinelCheckSubjectivelyDown函数调用sentinelEvent函数，向“+sdown”频道发布消息。此时，传递给sentinelEvent的参数就是4个，并没有可变参数，如下所示：</p><pre><code class=\"language-plain\">sentinelEvent(LL_WARNING,\"+sdown\",ri,\"%@\");\n</code></pre><p>第二个对应了<strong>哨兵在初始化时</strong>，在sentinelGenerateInitialMonitorEvents函数中，调用sentinelEvent函数向“+monitor”频道发布消息，此时，传递给sentinelEvent的参数有5个，包含了1个可变参数，表示的是哨兵的quorum阈值，如下所示：</p><pre><code class=\"language-plain\">sentinelEvent(LL_WARNING,\"+monitor\",ri,\"%@ quorum %d\",ri-&gt;quorum);\n</code></pre><p>最后一个对应了<strong>哨兵在完成主节点切换后</strong>，在sentinelFailoverSwitchToPromotedSlave函数中，调用sentinelEvent函数向“+switch-master”频道发布消息。此时，传递给sentinelEvent的可变参数一共有5个，对应了故障切换前的主节点名称、IP和端口号，以及切换后升级为主节点的从节点IP和端口号，如下所示：</p><pre><code class=\"language-plain\">sentinelEvent(LL_WARNING,\"+switch-master\",master,\"%s %s %d %s %d\",\n&nbsp; &nbsp; &nbsp; &nbsp; master-&gt;name, master-&gt;addr-&gt;ip, master-&gt;addr-&gt;port,\n&nbsp; &nbsp; &nbsp; &nbsp; ref-&gt;addr-&gt;ip, ref-&gt;addr-&gt;port);\n</code></pre><p>这样一来，你也就了解了，哨兵在工作过程中是通过sentinelEvent函数和pubsubPublishMessage函数，来实现消息的发布的。在哨兵的整个工作过程中，它会在一些关键节点上，<strong>使用sentinelEvent函数往不同的频道上发布消息</strong>。除了刚才给你举例的三个频道+monitor、+sdown、+switch-master以外，我还把哨兵在工作过程中会用到的消息发布频道列在了下表中，你可以了解下。</p><p><img src=\"https://static001.geekbang.org/resource/image/53/72/53c920eec89a2108351d816a80cbe272.jpg?wh=1920x1080\" alt=\"图片\"></p><p>其实，在哨兵的工作过程中，如果有客户端想要了解故障切换的整体情况或进度，比如主节点是否被判断为主观下线、主节点是否被判断为客观下线、Leader是否完成选举、新主节点是否切换完成，等等，就可以通过subscribe命令，订阅上面这张表中的相应频道。这样一来，客户端就可以了解故障切换的过程了。</p><p>好，下面我们再来看下，哨兵在工作过程中对消息的订阅是如何实现的。</p><h3>哨兵订阅与hello频道</h3><p>首先你要知道，每个哨兵会订阅它所监听的主节点的<code>\"__sentinel__:hello\"</code>频道。在<a href=\"https://time.geekbang.org/column/article/421736\">第23讲</a>中，我给你介绍过，哨兵会周期性调用sentinelTimer函数来完成周期性的任务，这其中，就有哨兵订阅主节点hello频道的操作。</p><p>具体来说，哨兵在周期性执行sentinelTimer函数时，会调用sentinelHandleRedisInstance函数，进而调用sentinelReconnectInstance函数。而在sentinelReconnectInstance函数中，哨兵会调用redisAsyncCommand函数，向主节点发送subscribe命令，订阅的频道由宏定义SENTINEL_HELLO_CHANNEL（在sentinel.c文件中）指定，也就是<code>\"__sentinel__:hello\"</code>频道。这部分的代码如下所示：</p><pre><code class=\"language-plain\">retval = redisAsyncCommand(link-&gt;pc,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sentinelReceiveHelloMessages, ri, \"%s %s\",\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sentinelInstanceMapCommand(ri,\"SUBSCRIBE\"),\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; SENTINEL_HELLO_CHANNEL);\n</code></pre><p>从代码中，我们也可以看到，当在<code>\"__sentinel__:hello\"</code>频道上收到hello消息后，哨兵会回调sentinelReceiveHelloMessages函数来进行处理。而sentinelReceiveHelloMessages函数，实际是通过调用<strong>sentinelProcessHelloMessage函数</strong>，来完成hello消息的处理的。</p><p>对于sentinelProcessHelloMessage函数来说，它主要是从hello消息中获得发布hello消息的哨兵实例的基本信息，比如IP、端口号、quorum阈值等。如果当前哨兵并没有记录发布hello消息的哨兵实例的信息，那么，sentinelProcessHelloMessage函数就会调用<strong>createSentinelRedisInstance函数</strong>，来创建发布hello消息的哨兵实例的信息记录，这样一来，当前哨兵就拥有了其他哨兵实例的信息了。</p><p>好了，了解了哨兵对<code>\"__sentinel__:hello\"</code>频道的订阅和处理后，我们还需要搞清楚一个问题，即<strong>哨兵是在什么时候发布hello消息的呢？</strong></p><p>这其实是哨兵在sentinelTimer函数中，调用sentinelSendPeriodicCommands函数时，由sentinelSendPeriodicCommands函数调用sentinelSendHello函数来完成的。</p><p><strong>sentinelSendHello函数</strong>会调用redisAsyncCommand函数，向主节点的<code>\"__sentinel__:hello\"</code>频道发布hello消息。在它发送的hello消息中，包含了发布hello消息的哨兵实例的IP、端口号、ID和当前的纪元，以及该哨兵监听的主节点的名称、IP、端口号和纪元信息。</p><p>下面的代码就展示了hello消息的生成和发布，你可以看下。</p><pre><code class=\"language-plain\">//hello消息包含的内容\nsnprintf(payload,sizeof(payload),\n&nbsp; &nbsp; &nbsp; &nbsp; \"%s,%d,%s,%llu,\" //当前哨兵实例的信息，包括ip、端口号、ID和当前纪元\n&nbsp; &nbsp; &nbsp; &nbsp; \"%s,%s,%d,%llu\", //当前主节点的信息，包括名称、IP、端口号和纪元\n&nbsp; &nbsp; &nbsp; &nbsp; announce_ip, announce_port, sentinel.myid,\n&nbsp; &nbsp; &nbsp; &nbsp; (unsigned long long) sentinel.current_epoch,\n&nbsp; &nbsp; &nbsp; &nbsp; master-&gt;name,master_addr-&gt;ip,master_addr-&gt;port,\n&nbsp; &nbsp; &nbsp; &nbsp; (unsigned long long) master-&gt;config_epoch);\n//向主节点的hello频道发布hello消息\nretval = redisAsyncCommand(ri-&gt;link-&gt;cc,\n&nbsp; &nbsp; &nbsp; &nbsp; sentinelPublishReplyCallback, ri, \"%s %s %s\",\n&nbsp; &nbsp; &nbsp; &nbsp; sentinelInstanceMapCommand(ri,\"PUBLISH\"),\n&nbsp; &nbsp; &nbsp; &nbsp; SENTINEL_HELLO_CHANNEL,payload);\n</code></pre><p>这样，当哨兵通过sentinelSendHello，向自己监听的主节点的<code>\"__sentinel__:hello\"</code>频道发布hello消息时，和该哨兵监听同一个主节点的其他哨兵，也会订阅主节点的<code>\"__sentinel__:hello\"</code>频道，从而就可以获得该频道上的hello消息了。</p><p>通过这样的通信方式，监听同一主节点的哨兵就能相互知道彼此的访问信息了。如此一来，哨兵就可以基于这些访问信息，执行主节点状态共同判断，以及进行Leader选举等操作了。</p><h2>小结</h2><p>今天这节课，我们了解了Redis实现的发布订阅通信方法。这个方法是提供了频道的方式，让要通信的双方按照频道来完成消息交互。而<strong>不同频道的不同名称，就代表了哨兵工作过程中的不同状态</strong>。当客户端需要了解哨兵的工作进度或是主节点的状态判断时，就可以通过订阅哨兵发布消息的频道来完成。</p><p>当然，对于一个哨兵来说，它一定会订阅的频道是它所监听的主节点的<code>\"__sentinel__:hello</code>\"频道。通过这个频道，监听同一主节点的不同哨兵就能通过频道上的hello消息，来交互彼此的访问信息了，比如哨兵的IP、端口号等。</p><p>此外，在这节课，我还给你介绍了一个<strong>C语言函数可变参数的使用小技巧</strong>，当你开发发布订阅功能时，都需要生成发布的消息，而可变参数就可以用来生成长度不定的消息。希望你能把这个小技巧应用起来。</p><p></p><h2>每课一问</h2><p>如果我们在哨兵实例上执行publish命令，那么，这条命令是不是就是由pubsub.c文件中的publishCommand函数来处理的呢?</p><p></p>","neighbors":{"left":{"article_title":"24 | 从哨兵Leader选举学习Raft协议实现（下）","id":422625},"right":{"article_title":"加餐1 | Redis性能测试工具的使用","id":414582}}},{"article_id":414582,"article_title":"加餐1 | Redis性能测试工具的使用","article_content":"<p>你好，我是蒋德钧。</p><p>咱们的课程已经更新过半了，在前面几个模块里，我带你从源码层面，分别了解和学习了Redis的数据结构、事件驱动框架和缓存算法的具体实现过程，相信你现在对Redis的数据类型和运行框架有了更加深入的认识。不过，阅读源码确实是一个比较烧脑的任务，需要你多花些时间钻研。所以，今天这节课，我们就通过加餐，来聊聊相对比较轻松的话题：Redis的性能测试工具。</p><p>我们在使用Redis的时候，经常会遇到需要评估Redis性能的场景。比如，当我们需要为部署Redis实例规划服务器配置规格时，或者当需要根据工作负载大小，决定Redis实例个数的时候，我们都需要了解Redis实例的运行性能。</p><p>那么这节课，我就来和你聊聊Redis的性能测试工具redis-benchmark，并带你了解下redis-benchmark的使用方法和基本实现。掌握了今天学习的内容之后，你既可以把redis-benchmark用在需要评估Redis性能的场景中，而且你还可以对redis-benchmark进行二次开发，添加新的功能特性，来满足实际业务场景中的需求。</p><p>好，下面，我们就先来看看redis-benchmark的使用。</p><!-- [[[read_end]]] --><h2>redis-benchmark的使用</h2><p>redis-benchmark这个工具是在Redis源码的<a href=\"https://github.com/redis/redis/tree/5.0/src/redis-benchmark.c\">redis-benchmark.c</a>文件中实现的。这个工具实际上是模拟多个客户端给Redis server发送请求。这些请求可以包括Redis对不同数据类型的多种操作，比如对String类型的GET、SET操作，对List类型的LPUSH、LPOP操作，等等。在测试的过程中，redis-benchmark工具会记录每个请求的响应时间，最后会把请求响应时间的分布以及请求吞吐率统计并打印出来。</p><p>现在，我们可以先运行一下这个工具，一是对redis-benchmark有个直观的印象，二是可以来学习下这个工具的使用。</p><p>我在一台启动了Redis server的机器上，直接执行redis-benchmark命令，如下所示：</p><pre><code>./redis-benchmark\n</code></pre><p>然后，我们就可以得到性能测试结果。以下给出的代码片段只是展示了一部分的测试结果，是所测试的Redis server执行SET和GET两个命令的性能结果。</p><pre><code>...\n====== SET ======\n  100000 requests completed in 1.43 seconds\n  50 parallel clients\n  3 bytes payload\n  keep alive: 1\n\n95.80% &lt;= 1 milliseconds\n99.04% &lt;= 2 milliseconds\n99.37% &lt;= 3 milliseconds\n99.50% &lt;= 4 milliseconds\n99.61% &lt;= 5 milliseconds\n99.68% &lt;= 6 milliseconds\n99.84% &lt;= 7 milliseconds\n100.00% &lt;= 8 milliseconds\n100.00% &lt;= 8 milliseconds\n69832.40 requests per second\n\n====== GET ======\n  100000 requests completed in 1.22 seconds\n  50 parallel clients\n  3 bytes payload\n  keep alive: 1\n\n99.79% &lt;= 1 milliseconds\n99.99% &lt;= 2 milliseconds\n100.00% &lt;= 2 milliseconds\n81766.15 requests per second\n...\n</code></pre><p>现在，我们来解读下这个测试结果，主要包括了两方面的信息。</p><p><strong>一方面，测试结果会展示测试的命令操作，以及测试的配置。</strong>其中，测试配置包括一共发送的请求个数、使用的并发客户端个数、键值对的value大小等。在刚才运行的测试中，我们没有设置任何选项，所以redis-benchmark使用了默认配置。</p><p>这里，我把redis-benchmark常用的配置项列在了下面的表中，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/86/b4/86973efc3c3c8acf49e9f4c71217b0b4.jpg?wh=2000x1125\" alt=\"\"></p><p>其中，和Redis server性能测试密切相关的选项主要是这几个：</p><ul>\n<li><strong>-c，-n选项</strong></li>\n</ul><p>我们可以增加它们的选项值，从而增加给Redis server发送请求的客户端数量，以及发送给Redis server的请求数量。这两个选项在对Redis server进行压力测试时，是非常重要的。因为在大压力情况下，Redis server通常要处理大并发客户端连接，以及大量的请求，通过增加这两个选项值，这样的测试结果能体现Redis server本身性能以及所使用的服务器硬件配置效果。</p><ul>\n<li><strong>-d选项</strong></li>\n</ul><p>我们可以根据实际业务场景中的value大小，来设置这个选项值。默认情况下，redis-benchmark测试的value大小只有3字节，而通常业务场景下，value的大小从几字节、几十字节到几百字节，甚至上千字节不等。</p><p>value的字节数越多，对Redis server的内存访问、网络传输、RDB/AOF文件读写影响越大。所以，如果我们只是使用默认配置，这样测试的性能结果不一定能反映业务场景下Redis server的真实表现。</p><ul>\n<li><strong>-r选项</strong></li>\n</ul><p>我们可以设置访问的key的随机性。如果不设置这个选项，那么，redis-benchmark访问的key是相同的，都是<code>\"key:__rand_int__\"</code>。比如，我们运行<code>./redis-benchmark -t set -n 1000</code>命令，测试1000次SET操作的性能。运行完之后，我们使用keys命令查看Redis数据库中的key，可以看到，其实这1000次SET操作都是访问同一个key，也就是<code>\"key:__rand_int__\"</code>。这个过程如下所示。</p><pre><code>./redis-benchmark -t set -n 1000\n...  //测试性能结果\n\n/redis-cli keys \\*\n1) &quot;key:__rand_int__&quot;\n</code></pre><p>当使用相同的key进行测试时，这会影响到我们评估Redis server随机访问性能的效果。而且，在实际业务场景中，key通常是随机的，所以，我们在实际测试过程中也需要把-r选项使用起来。</p><p>比如，我们执行<code>./redis-benchmark -t set -n 1000 -r 10</code>命令，测试1000次SET操作的性能。在这种情况下，这1000次SET操作实际访问的key，它们的值是在<code>\"key:000000000000\"</code>和<code>\"key:000000000009\"</code>之间，也就是说，-r选项的值N指定了key中的数字取值范围在大于等于0到小于N之间。这个过程如下所示：</p><pre><code>./redis-benchmark -t set -n 1000 -r 10\n...  //测试性能结果\n\n./redis-cli keys \\*\n 1) &quot;key:000000000000&quot;\n 2) &quot;key:000000000002&quot;\n 3) &quot;key:000000000007&quot;\n 4) &quot;key:000000000003&quot;\n 5) &quot;key:000000000008&quot;\n 6) &quot;key:000000000006&quot;\n 7) &quot;key:000000000001&quot;\n 8) &quot;key:000000000004&quot;\n 9) &quot;key:000000000005&quot;\n10) &quot;key:000000000009&quot;\n</code></pre><ul>\n<li><strong>-P选项</strong></li>\n</ul><p>我们可以通过该选项来设置Redis客户端以批处理的形式，让一个请求发送多个操作给Redis server，从而可以测试批处理发送操作，给Redis server吞吐率带来的性能提升效果。</p><p>比如，我们执行<code>./redis-benchmark -t set -n 1000000</code>命令，测试一百万次SET操作的性能。然后，我们再执行<code>./redis-benchmark -t set -n 1000000 -P 10</code>命令，同样测试一百万次SET操作的性能，不过此时，我们一个请求会发送10个操作。</p><p>下面的代码片段就展示了在这两种方式下，Redis server的性能结果。你可以看到，不批量发送操作的吞吐率是每秒68898个操作，而每次批量发送10个操作的吞吐率是每秒375798个操作。所以，批量发送操作能有效提升Redis server的性能。</p><pre><code>./redis-benchmark -t set -n 1000000 -q\nSET: 68898.99 requests per second\n\n./redis-benchmark -t set -n 1000000 -q -P 10\nSET: 375798.56 requests per second\n</code></pre><p>好了，了解了redis-benchmark的主要配置选项，以及这其中和性能评估密切相关的选项后，我们再来看下<strong>redis-benchmark运行后包含的另一方面信息，也就是测试性能结果信息</strong>。</p><p>redis-benchmark运行后提供的性能结果包括两部分：一是<strong>操作的延迟分布</strong>。这部分信息展示了不同百分比的操作，它们的延迟最大值。二是<strong>server的吞吐率</strong>，也就是每秒完成的操作数。下面的代码片段就展示了，我们测试1000次SET操作后的性能结果。其中，98.65%的操作延迟小于等于1毫秒，99.17%的操作延迟小于等于2毫秒，而所有操作（也就是100%操作）的延迟都小于等于3毫秒。</p><pre><code>./redis-benchmark -t set -n 10000\n====== SET ======\n  10000 requests completed in 0.13 seconds\n  50 parallel clients\n  3 bytes payload\n  keep alive: 1\n\n98.65% &lt;= 1 milliseconds\n99.17% &lt;= 2 milliseconds\n100.00% &lt;= 3 milliseconds\n75187.97 requests per second\n</code></pre><p>这里，你需要注意的是，在redis-benchmark的测试结果中，<strong>延迟分布对于Redis来说，是非常重要的信息</strong>。因为Redis通常需要服务大量的并发客户端，而以百分比统计的延迟分布，可以告诉我们这其中有多少比例的操作，它们的延迟较高。</p><p>为了帮助你更好地理解百分比延迟分布的作用，我给你举个例子。假设redis-benchmark的测试结果显示99%的操作延迟小于等于1毫秒，而所有操作，也就是100%的操作延迟小于等于5毫秒，那么就表明有1%的操作延迟是在1毫秒到5毫秒之间的。如果某个操作的延迟正好是5毫秒，那么和其他99%的操作相比，它的延迟就增加了5倍，这样一来，发送这个操作的客户端就会受到明显的性能影响。</p><p>我们再假设Redis server处理的请求数一共是100万个请求，那么1%的操作影响的就是1万个请求。而且Redis server处理的请求越多，这个影响的范围就越大。所以，这个以百分比统计的延迟分布可以帮助我们更加全面地评估Redis server的性能表现。</p><p>好了，到这里，我们就可以通过运行redis-benchmark这个工具，来了解我们所测试的Redis server处理不同请求操作的延迟分布和吞吐率了。</p><p>那么接下来，我们再来了解下redis-benchmark是怎么实现的。</p><h2>redis-benchmark的实现</h2><p>redis-benchmark本身可以单独运行，这是因为它本身就自带main函数。我们了解它的main函数，就可以了解redis-benchmark的基本实现。</p><p>它的main函数的主要执行流程可以分成三步。</p><p><strong>第一步</strong>，main函数设置各种配置参数的默认值，比如待测试的Redis server的IP、端口号、客户端数量、value大小，等等。紧接着，main函数会调用parseOptions函数，解析通过redis-benchmark命令传入的各项参数，这就包括了我刚才给你介绍的redis-benchmark的基本配置项。</p><p>另外在这一步中，main函数还会调用aeCreateEventLoop函数创建一个事件循环，如下所示。redis-benchmark在实际运行时，会通过这个事件循环流程，来处理客户端的读写事件。</p><pre><code>config.el = aeCreateEventLoop(1024*10);\n</code></pre><p><strong>第二步</strong>，main函数会检查redis-benchmark命令参数中是否包含了其他命令，如果有的话，那么redis-benchmark工具会调用benchmark函数（在redis-benchmark.c文件中），来实际测试这些命令操作。</p><p>benchmark函数会调用createClient函数（在redis-benchmark.c文件中）创建一个客户端。然后，它再调用createMissingClients函数（在redis-benchmark.c文件中），检查是否有多个并发客户端要创建。如果是的话，createMissingClients函数也会调用createClient函数，来创建剩余的客户端。</p><p>这里，<strong>你需要注意的是</strong>，createClient函数在创建完客户端后，只要redis-benchmark没有设置idle模式，也就是只创建客户端而不发送请求，那么，它就会调用aeCreateFileEvent函数在客户端上注册写事件。这里的写事件回调函数是writeHandler（在redis-benchmark.c文件中），负责向Redis server发送命令操作，如下所示：</p><pre><code>if (config.idlemode == 0)\n   aeCreateFileEvent(config.el,c-&gt;context-&gt;fd,AE_WRITABLE,writeHandler,c);\n</code></pre><p>而writeHandler函数完成命令操作发送后，会调用aeDeleteFileEvent函数将当前客户端上监听的写事件删除，同时，创建当前客户端上监听的读事件，读事件的回调函数是readHandler（在redis-benchmark.c文件中），负责读取Redis server的返回结果。</p><pre><code>if (sdslen(c-&gt;obuf) == c-&gt;written) {\n   aeDeleteFileEvent(config.el,c-&gt;context-&gt;fd,AE_WRITABLE);\n   aeCreateFileEvent(config.el,c-&gt;context-&gt;fd,AE_READABLE,readHandler,c);\n }\n</code></pre><p>那么，再回到benchmark函数中，在创建完客户端后，紧接着，benchmark函数会调用aeMain函数进入刚才第一步中创建的事件循环流程，开始处理读写事件。如果事件循环流程结束了，benchmark函数调用showLatencyReport函数（在redis-benchmark.c文件中）打印测试结果，并调用freeAllClients函数（在redis-benchmark.c文件中）释放所有客户端。</p><p>好了，到这里，你就了解了，benchmark函数是如何使用事件驱动框架来完成操作测试的。</p><p>实际上，如果redis-benchmark命令运行时自带了测试操作，此时，在main函数的第二步中，在完成这些操作测试后，redis-benchmark工具就运行结束了，而不会再测试它的-t选项设置的命令操作了。</p><p>而如果redis-benchmark命令运行时没有自带测试操作，那么main函数就会进入第三步。</p><p>在<strong>第三步</strong>中，main函数会调用test_is_selected函数（在redis-benchmark.c文件中），判断-t选项中设置了哪些命令操作，然后main函数调用benchmark函数来完成这些操作的测试。</p><p>这样一来，redis-benchmark工具的基本执行流程就结束了。</p><h2>小结</h2><p>今天这节课我给你介绍了redis-benchmark工具的使用。redis-benchmark是常用的Redis性能测试工具，它可以通过设置并发客户端、总操作数、value大小、key的随机性、批量发送等配置项，来给Redis server施加不同的压力。</p><p>redis-benchmark工具本身提供了一些常见命令的测试，比如SET、GET、LPUSH，等等。这些命令的测试是redis-benchmark在它的实现文件中固定写好的。你可以在redis-benchmark.c文件中的main函数里面，找到这些命令。而如果我们想要测试不在固定测试命令集中的其他命令，我们可以在redis-benchmark命令的最后，设置其他的Redis命令，从而可以测试其他命令的性能结果。</p><p>最后，我也给你介绍了redis-benchmark的基本实现。它其实是启动多个客户端向Redis server发送命令操作。这个过程中，redis-benchmark使用了事件驱动框架。每当启动一个测试客户端，这个客户端会在事件驱动框架中创建写事件和读事件。写事件对应了测试客户端向Redis server发送操作命令，而读事件对应了测试客户端从Redis server读取响应结果。</p><p>从这里，你可以看到，Redis实现的事件驱动框架不仅用在server的运行过程中，而且还用在了性能测试工具实现的客户端中。</p><h2>每课一问</h2><p>你在实际工作中，还用过什么其他的Redis性能测试工具吗？欢迎在留言区分享，我们一起交流探讨。</p>","neighbors":{"left":{"article_title":"25 | Pub/Sub在主从故障切换时是如何发挥作用的？","id":422627},"right":{"article_title":"加餐2 | 用户Kaito：我是怎么读Redis源码的？","id":419664}}},{"article_id":419664,"article_title":"加餐2 | 用户Kaito：我是怎么读Redis源码的？","article_content":"<p>你好，我是Kaito，也是两季Redis课程的课代表。今天，我想来和你分享一下我读源码的经验，希望能助力你更好地学习Redis源码。</p><p>首先，一提到读源码，很多人都会比较畏惧，认为读源码是高手才会做的事情。可能遇到问题时，他们更倾向于去找别人分享的答案。但往往很多时候，自己查到的资料并不能帮助解决所有问题，尤其是比较细节的问题。</p><p>那么从我的实践经验来看，遇到这种情况，通常就需要去源码中寻找答案了，因为在源码面前，这些细节会变得一览无余。而且我认为，掌握读源码的能力，是从只懂得如何使用Redis，到精通Redis实现原理的成长之路上，必须跨越的门槛。可是，<strong>面对庞大复杂的项目，我们怎样读源码才能更高效呢？</strong></p><p>所以下面，我就来和你聊一聊我在读源码时的经验和心得。</p><h2>找到地图</h2><p>很多开源项目的源码，代码量一般都比较庞大，如果在读代码之前，我们没有制定合理的方法，就一头扎进去读代码，势必会把自己搞晕。</p><p>所以，我在拿到一个项目的代码之后，并不会马上着手去读，而是会先对整个项目结构进行梳理，划分出项目具体包含的模块。这样，我就对整个项目有了一个宏观的了解。</p><p>因为读代码就好比去一个陌生城市旅行，这个旅途过程充满着未知。如果在出发之前，我们手里能有一张地图，那我们对自己的行程就可以有一个非常清晰的规划，我们就知道，如果想要到达目的地，需要从哪里出发、经过哪些地方、通过什么方式才能到达，<strong>有了地图就有了行进方向</strong>，否则很容易迷失。</p><!-- [[[read_end]]] --><p>因此，提前花一些时间梳理整个项目的结构和目录，对于后面更好地阅读代码是非常有必要的。就拿Redis来举例，在读Redis源码之前，我们可以先梳理出整个项目的功能模块，以及每个模块对应的代码文件，以下给出的就是src下的代码结构：</p><p><img src=\"https://static001.geekbang.org/resource/image/8d/fc/8de27eda5312b45e70f80e8d534ecafc.jpg?wh=1920x1561\" alt=\"图片\"></p><p>这样，有了这张地图之后，我们再去看代码的时候，就可以有重点地阅读了。</p><h2>前置知识准备</h2><p>在梳理完整个项目结构之后，我们就可以正式进入阅读环节当中了。</p><p>不过，在阅读代码之前，我们其实还需要预先掌握一些前置知识。因为一个完整的项目，必然综合了各个领域的技术知识点，比如数据结构、操作系统、网络协议、编程语言等，如果我们提前做好一些功课，在读源码的过程中就会轻松很多。以下是根据我在阅读Redis书籍和实战过程中，提取的读源码必备前置知识点，给你参考一下。</p><ul>\n<li>常用数据结构：数组、链表、哈希表、跳表。</li>\n<li>网络协议：TCP协议。</li>\n<li>网络IO模型：IO多路复用、非阻塞IO、Reactor网络模型。</li>\n<li>操作系统：写时复制（Copy On Write）、常见系统调用、磁盘IO机制。</li>\n<li>C语言基础：循环、分支、结构体、指针。</li>\n</ul><p>当然，在阅读源码的过程中，我们也可以根据实际问题再去查阅相关资料，但不管怎样，提前熟悉这些方面的知识，在真正读代码时就会省下不少时间。</p><h2>从基础模块开始读</h2><p>好，有了地图并掌握了前置知识之后，接下来我们就要进入主题了：<strong>读代码</strong>。但具体要从哪个地方开始读起呢？我认为要先从最基础的模块开始读起。</p><p>我在前面也分析了，一个完整的项目会划分很多的功能模块，但这些模块并不是孤立的，而很可能是有依赖关系的。比如说，Redis中的networking.c文件，表示处理网络IO的具体实现。而如果我们能在理解事件驱动模块ae.c的基础上，再去阅读网络IO模块，效率就会更高。</p><p>那么在Redis源码中，哪些是最基础的模块呢？想一下，我们在使用Redis时，接触最频繁的是哪些功能？</p><p>答案是<strong>各种数据类型</strong>。</p><p><strong>一切操作的基础，其实都是基于这些最常用的数据类型来做的</strong>，比如String、List、Hash、Set、Sorted Set等。所以，我们就可以从这些基础模块开始读起，也就是从t_string.c、t_list.c、t_hash.c、t_set.c、t_zset.c代码入手。</p><p>如果你对Redis的数据类型有所了解，就会看到这些数据类型在实现时，底层都对应了不同的数据结构。比如，String的底层是SDS，List的底层是ziplist + quicklist，Hash底层可能是ziplist，也可能是哈希表，等等。</p><p><img src=\"https://static001.geekbang.org/resource/image/7c/35/7cf142081a43bba5ee84904c80ec3635.jpg?wh=1920x792\" alt=\"图片\"></p><p>而由此一来，我们会发现，这些数据结构又是更为底层的模块，所以我们在阅读数据类型模块时，就需要重点聚焦在这些模块上，也就是sds.c、ziplist.c、quicklist.c、dict.c、intset.c文件，而且这些文件都是比较独立的，阅读起来就可以更加集中。</p><p>这样，当我们真正掌握了这些底层数据结构的实现后，就能更好地理解基于它们实现的各种数据类型了。<strong>这些基础模块就相当于一座大厦的地基，地基打好了，才能做到高楼耸立。</strong></p><h2>找到核心主线</h2><p>接着，掌握了数据结构模块之后，这时我们的重点就需要放在核心主线上来了。</p><p>在这个阶段，我们需要找到一个明确的目标，以这个目标为主线去读代码。因为读源码其实是一个很常见的需求，就是为了了解这个项目最核心功能的实现细节，我们只有以此为目标，找到这条主线去读代码，才能达到最终目的。</p><p>那么在读Redis源码时，什么才是它的核心主线呢？这里我分享一个非常好用的技巧，就是根据“<strong>Redis究竟是怎么处理客户端发来的命令的？</strong>”来梳理。</p><p>举个例子，当我们在执行SET testkey testval EX 60这样一条命令时，就需要搞清楚Redis是怎么执行这条命令的。也就是要明确，Redis从收到客户端请求，到把数据存到Redis中、设置过期时间，最后把响应结果返回给客户端，整个过程的每一个环节，到底是如何处理的。</p><p>有了这条主线，我们就有了非常明确的目标，而且沿着这条主线去读代码，我们还可以很清晰地把多个模块串联起来。比如从前面的例子中，我们会看到一条命令的执行，主要包含了这样几个阶段。</p><ul>\n<li><strong>Redis Server初始化</strong>：加载配置、监听端口、注册连接建立事件、启动事件循环（server.c、anet.c）。</li>\n<li><strong>接收、解析客户端请求</strong>：初始化Client、注册读事件、读客户端Socket（networking.c）。</li>\n<li><strong>处理具体的命令</strong>：找到对应的命令函数、执行命令（server.c、t_string.c、t_list.c、t_hash.c、t_set.c、t_zset.c）。</li>\n<li><strong>返回响应给客户端</strong>：写客户端缓冲区、注册写事件、写客户端Socket（networking.c）。</li>\n</ul><p><img src=\"https://static001.geekbang.org/resource/image/87/3e/87e8563785353f4947ef70283842573e.jpg?wh=1920x882\" alt=\"图片\"></p><p>沿着这条主线去读代码，我们就可以掌握一条命令的执行全过程。而且，由于这条主线的代码逻辑，已经覆盖了所有命令的执行流程，我们下次再去读其他命令时，比如SADD，就只需要关注处理命令部分的逻辑即可，其他逻辑有80%都是相同的。</p><h2>先整体后细节</h2><p>当然，在阅读主线代码的过程中，肯定也会遇到过于复杂的函数，第一次在读这种函数时，很容易就会陷进去，导致整个主线代码的阅读，无法继续推进下去。遇到这种情况其实是很正常的，可这时我们应该怎么办呢？</p><p>这里我的做法是，前期读到这种逻辑时，不要马上陷入到细节中去，而是要<strong>先抓整体</strong>。具体来说，对于复杂的函数逻辑，我们刚开始并不需要知道它的每一个细节是如何实现的，而是只需知道这个函数大致做了几件事情即可。</p><p>举个例子，在执行HSET命令时，有一段代码很复杂，其中包括了很多分支判断，一次很难读懂：</p><pre><code class=\"language-plain\">int hashTypeSet(robj *o, sds field, sds value, int flags) {\n&nbsp; &nbsp; int update = 0;\n\n&nbsp; &nbsp; if (o-&gt;encoding == OBJ_ENCODING_ZIPLIST) {\n&nbsp; &nbsp; &nbsp; &nbsp; unsigned char *zl, *fptr, *vptr;\n\n&nbsp; &nbsp; &nbsp; &nbsp; zl = o-&gt;ptr;\n&nbsp; &nbsp; &nbsp; &nbsp; fptr = ziplistIndex(zl, ZIPLIST_HEAD);\n&nbsp; &nbsp; &nbsp; &nbsp; if (fptr != NULL) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; fptr = ziplistFind(fptr, (unsigned char*)field, sdslen(field), 1);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (fptr != NULL) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /* Grab pointer to the value (fptr points to the field) */\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; vptr = ziplistNext(zl, fptr);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; serverAssert(vptr != NULL);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; update = 1;\n\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /* Delete value */\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; zl = ziplistDelete(zl, &amp;vptr);\n\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /* Insert new value */\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; zl = ziplistInsert(zl, vptr, (unsigned char*)value,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sdslen(value));\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; }\n\n&nbsp; &nbsp; &nbsp; &nbsp; if (!update) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; /* Push new field/value pair onto the tail of the ziplist */\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; zl = ziplistPush(zl, (unsigned char*)field, sdslen(field),\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ZIPLIST_TAIL);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; zl = ziplistPush(zl, (unsigned char*)value, sdslen(value),\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ZIPLIST_TAIL);\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; o-&gt;ptr = zl;\n\n&nbsp; &nbsp; &nbsp; &nbsp; /* Check if the ziplist needs to be converted to a hash table */\n&nbsp; &nbsp; &nbsp; &nbsp; if (hashTypeLength(o) &gt; server.hash_max_ziplist_entries)\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; hashTypeConvert(o, OBJ_ENCODING_HT);\n&nbsp; &nbsp; } else if (o-&gt;encoding == OBJ_ENCODING_HT) {\n&nbsp; &nbsp; &nbsp; &nbsp; dictEntry *de = dictFind(o-&gt;ptr,field);\n&nbsp; &nbsp; &nbsp; &nbsp; if (de) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sdsfree(dictGetVal(de));\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (flags &amp; HASH_SET_TAKE_VALUE) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dictGetVal(de) = value;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; value = NULL;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; } else {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dictGetVal(de) = sdsdup(value);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; update = 1;\n&nbsp; &nbsp; &nbsp; &nbsp; } else {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sds f,v;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (flags &amp; HASH_SET_TAKE_FIELD) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; f = field;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; field = NULL;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; } else {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; f = sdsdup(field);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (flags &amp; HASH_SET_TAKE_VALUE) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; v = value;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; value = NULL;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; } else {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; v = sdsdup(value);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dictAdd(o-&gt;ptr,f,v);\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; } else {\n&nbsp; &nbsp; &nbsp; &nbsp; serverPanic(\"Unknown hash encoding\");\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; /* Free SDS strings we did not referenced elsewhere if the flags\n&nbsp; &nbsp; &nbsp;* want this function to be responsible. */\n&nbsp; &nbsp; if (flags &amp; HASH_SET_TAKE_FIELD &amp;&amp; field) sdsfree(field);\n&nbsp; &nbsp; if (flags &amp; HASH_SET_TAKE_VALUE &amp;&amp; value) sdsfree(value);\n&nbsp; &nbsp; return update;\n}\n</code></pre><p>那么，我在读这段代码时，就可以先简化逻辑，把握整体思路：</p><pre><code class=\"language-plain\">// 执行 HSET 命令\nint hashTypeSet(robj *o, sds field, sds value, int flags) {\n    ...\n    // 如果当前是 ziplist 编码存储\n    if (o-&gt;encoding == OBJ_ENCODING_ZIPLIST) {\n        ...\n    // 如果是 hashtable 编码存储\n    } else if (o-&gt;encoding == OBJ_ENCODING_HT) {\n        ...\n    } else {\n        serverPanic(\"Unknown hash encoding\");\n    }\n    ...\n}\n</code></pre><p>之后，再了解每个分支大致做了哪些事情：</p><pre><code class=\"language-plain\">// 如果当前是 ziplist 编码存储\nif (o-&gt;encoding == OBJ_ENCODING_ZIPLIST) {\n    ...\n    // field 在 ziplist 中，从 ziplist 中删除，在插入新值\n    if (fptr != NULL) {\n        fptr = ziplistFind(fptr, (unsigned char*)field, sdslen(field), 1);\n        zl = ziplistDelete(zl, &amp;vptr);\n        zl = ziplistInsert(zl, vptr, (unsigned char*)value, sdslen(value));\n        ...\n    }\n\n    // field 不在 ziplist 中，则插入到 ziplist\n    if (!update) {\n        zl = ziplistPush(zl, (unsigned char*)field, sdslen(field),\n                    ZIPLIST_TAIL);\n        ...\n    }\n\n    // ziplist 元素超过阈值，转为 hashtable\n    if (hashTypeLength(o) &gt; server.hash_max_ziplist_entries) {\n        hashTypeConvert(o, OBJ_ENCODING_HT);\n    }\n}\n</code></pre><p>这样做的<strong>好处</strong>，一是不会被复杂的细节逻辑搞晕，打击自己的自信心；二是可以有效避免阅读的连贯性被打断，从而能持续推进我们把整个主线逻辑读完。<br>\n所以，这里的重点就是：先把复杂代码的主逻辑搞清楚，知道涉及的每个方法完成了什么事，心里要先搭建一个简单的框架，等有了框架之后，我们再去给框架填充细节。这样通过<strong>先整体后细节</strong>的方式，我们就可以不再畏惧代码中的复杂逻辑。</p><h2>先主线后支线</h2><p>不过，在阅读主线代码的过程中，我们肯定还会遇到各种支线逻辑，比如数据过期、替换淘汰、持久化、主从复制等。</p><p>其实，在阅读主线逻辑的时候，我们并不需要去重点关注这些支线，而当整个主线逻辑清晰起来之后，我们再去读这些支线模块，就会容易很多了。这时，我们就可以从这些支线中，选取下一个目标，带着这个目标去阅读，比如说：</p><ul>\n<li>过期策略是怎么实现的？（expire.c、lazyfree.c）</li>\n<li>淘汰策略是如何实现的？（evict.c）</li>\n<li>持久化 RDB、AOF 是怎么做的？（rdb.c、aof.c）</li>\n<li>主从复制是怎么做的？（replication.c）</li>\n<li>哨兵如何完成故障自动切换？（sentinel.c）</li>\n<li>分片逻辑如何实现？（cluster.c）</li>\n<li>….</li>\n</ul><p>有了新的支线目标后，我们依旧可以采用前面提到的先整体后细节的思路阅读相关模块，这样下来，整个项目的每个模块，就可以被逐一击破了。</p><h2>查漏补缺</h2><p>最后，我们还需要查漏补缺。</p><p>按照前面提到的方法，基本就可以把整个项目的主要模块读得七七八八了，这时我们基本已经对整个项目有了整体的把控。</p><p>不过，当我们在工作中遇到问题时，很有可能会发现，在当时读代码的过程中，有很多并不在意的细节被忽略了。所以这时，我们就可以<strong>再带着具体问题出发，聚焦这个问题相关的模块，再一次去读源码</strong>。这样一来，我们就可以填补当时阅读源码的空白区。</p><p>举个例子，当我们在阅读String底层数据结构SDS（简单动态字符串）的实现时，我们会看到当 SDS 需要追加新内容时会进行扩容，而我们之前阅读这部分代码时，<strong>很有可能只是了解到有这样的逻辑存在，但并没有在意扩容的相关细节（一次扩容多大）</strong>。</p><p>所以，当我们在工作中遇到这个细节问题后，就可以把目光聚焦在 SDS 的扩容逻辑上（sds.c 的sdsMakeRoomFor函数），而此时我们会发现，当需要申请的新内存小于1MB时，Redis就会翻倍申请内存，否则按1MB申请新内存。</p><p>采用这个方法进行查漏补缺，我们就可以对整个项目了解得更深入、更全面，真正把项目吃透。</p><h2>总结</h2><p>好了，以上就是我在阅读Redis源码时，总结出来的经验体会，这里我也把这七个步骤梳理总结下。</p><ol>\n<li><strong>找到地图</strong>：拿到项目代码后，提前梳理整个项目结构，知晓整个项目的模块划分，以及对应的代码文件。</li>\n<li><strong>前置知识准备</strong>：提前掌握项目中用到的前置知识，比如数据结构、操作系统原理、网络协议、网络 IO 模型、编程语言语法等等。</li>\n<li><strong>从基础模块开始读</strong>：从最底层的基础模块开始入手，先掌握了这些模块，之后基于它们构建的模块读起来会更加高效。</li>\n<li><strong>找到核心主线</strong>：找到整个项目中最核心的主线逻辑，以此为目标，了解各模块为了完成这个功能，是如何协作和组织的。</li>\n<li><strong>先整体后细节</strong>：对于复杂函数，不要上来就陷入细节，前期阅读只需了解这个函数大致做了什么事情，建立框架，等搭建起框架之后，再去填充细节。</li>\n<li><strong>先主线后支线</strong>：整个主线逻辑清晰之后，再去延伸阅读支线逻辑，因为支线逻辑肯定是服务主线逻辑的，读完主线后再去读这些支线，也会变得更简单。</li>\n<li><strong>查漏补缺</strong>：在工作中遇到具体问题，带着这些实际的问题出发再次去读源码，进行查漏补缺，填补之前读源码时没有注意到的地方。</li>\n</ol><p>当然，这个阅读源码的方法也并不局限于Redis，如果你在开发过程中，也有读源码的需要，希望这个方法能帮助你更好地吃透它。</p><p>最后，如果你也有自己的阅读源码的实践经验和方法，欢迎在留言区分享出来，我们一起交流，共同进步！</p>","neighbors":{"left":{"article_title":"加餐1 | Redis性能测试工具的使用","id":414582},"right":{"article_title":"加餐3 | 从Redis到其他键值数据库的学习体会","id":423388}}},{"article_id":423388,"article_title":"加餐3 | 从Redis到其他键值数据库的学习体会","article_content":"<p>你好，我是蒋德钧，欢迎来到课程的加餐环节。</p><p></p><p>我们的课程到了今天，已经过了一大半了，再加上我在第一季和你分享的内容，我们已经围绕着Redis的技术原理和源代码分析学习了七十多节课。这里我想先感谢你的坚持学习，也希望在后半部分的学习旅途中，你能一如既往地同我一起深入剖析Redis源码，理解Redis的底层实现。</p><p>掌握好Redis的关键技术，对于我们的实际应用是非常重要的。不过，在真实的业务场景中，除了Redis以外，还有不少其他类型的键值数据库也被广泛使用。我自己在日常工作中，也去学习了几种其他类型的键值数据库，包括<a href=\"http://www.mongodb.com\">MongoDB</a>、<a href=\"https://github.com/google/leveldb\">LevelDB</a>、<a href=\"http://rocksdb.org\">RocksDB</a>、<a href=\"https://tikv.org\">TiKV</a>等。在学习的过程中，我经常会把这些数据库和Redis进行对比。</p><p></p><p>所以今天这节课，我想来和你聊聊，我在学习Redis和这些键值数据库的时候，对它们的使用、关键技术和发展的一些体会。如果你在学习Redis之余，也想进一步了解其他的键值数据库，我希望这些体会能帮助你扩展了解Redis和其他键值数据库的联系与区别，让你能更好地开展后端开发工作。</p><p></p><h2>体会一：不同键值数据库的数据类型差异较大</h2><p>键值数据库属于后端系统，因此我们在选择键值数据库的时候，<strong>从业务应用的角度来看，首先就会考虑键值数据库能提供的数据类型有哪些</strong>。而对于Redis和其他键值数据库来说，虽然我们都称之为键值数据库，它们在保存数据时，实际也是按照键-值的方式来保存的，但是，它们呈现出来的数据类型还是有差别的。</p><!-- [[[read_end]]] --><p></p><p>我在学习Redis时，就对它提供丰富的数据类型印象深刻。而后我又去了解了MongoDB，它的数据类型相对与Redis来说，就具有不一样的特征。</p><p></p><p><strong>MongoDB提供的数据类型是文档</strong>，所谓的文档就是指一个键值对或多个键值对的组合，这和JSON格式的数据类型很相似。比如，我们要记录一个用户的ID、姓名、年龄等信息，在MongoDB中，我们可以使用如下的文档来记录：</p><pre><code class=\"language-plain\">{“uID”: 3032, “name”: “wang ”, “age”: 20}\n</code></pre><p>这个文档就包括了三个键值对，它们的key分别是“uID”“name”和“age”。而如果我们有很多用户的信息需要保存，我们可以继续在MongoDB中插入文档。不同文档中键值对的key可以是相同的，而value则要不同，比如在以下代码中，我们又增加了三个文档记录不同用户的信息：</p><pre><code class=\"language-plain\">{“uID”: 3033, “name”: “zhang ”, “age”: 21}\n{“uID”: 3034, “name”: “liu ”, “age”: 19}\n{“uID”: 3035, “name”: “chen ”, “age”: 22}\n</code></pre><p>MongoDB可以把这些文档逻辑上组织在一起，从而形成一个集合。更重要的是，MongoDB基于文档数据类型，它还支持应用对文档键值对中的key进行条件查询。比如，针对刚才介绍的四个文档，MongoDB支持查询age大于等于20的所有文档。</p><p></p><p>其实，这是MongoDB的一个特点，它的文档类似于SQL数据库提供的表记录。而MongoDB本身又能支持对文档键值对中的不同key进行查询，这也和SQL数据库中，对单张表的不同字段进行SQL查询很类似。</p><p></p><p>那么，和Redis相比，<strong>MongoDB基于文档数据类型，提供的类似单表SQL查询的功能，包括对单个key或多个key的丰富条件查询，就是它的一个显著特点</strong>。</p><p>而Redis的基本数据类型就是键值对，虽然键值对中的value可以有不同的数据类型，它提供的查询也<strong>主要是针对键值对中的key本身的</strong>。当然，当Redis键值对的value类型是Hash时，我们通过HGET也能查询哈希表中某个key的值，但是无法提供类似MongoDB那样丰富的条件查询。</p><p></p><p>所以，当我们在使用键值数据库时，如果有类似单表SQL查询的需求，就可以考虑把MongoDB使用起来，而这是Redis并不具备的特性。</p><p></p><p>接下来，我再和你聊聊我在学习RocksDB时，对比Redis来看持久化功能在键值数据库中的作用的体会。</p><p></p><h2>体会二：持久化数据对键值数据库的作用</h2><p>我在一开始学习Redis的时候，一直把Redis看作是持久化键值数据库。因为我觉得Redis用AOF和RDB，可以把数据持久化保存到磁盘等存储设备上。而直到我学习了LevelDB、RocksDB这些键值数据库之后，才发现原先的认知是有误的。</p><p></p><p>其实，<strong>持久化键值数据库，更多的是指数据本身的保存位置就是在磁盘</strong>，从而可以利用磁盘大容量的特点，保存更多的数据。而Redis的持久化功能，并不是为扩大Redis存储容量来设计的，它主要是为了<strong>提升Redis的可靠性</strong>，将数据在磁盘上保存一份，以便于Redis实例发生故障时，可以从磁盘恢复数据。</p><p>Redis本身的存储容量还是由实例所用的最大内存容量来决定的。这也是为什么业界有提出Pika的解决方案。这实际上就是为了实现，在保持Redis访问协议和接口的前提下，让Redis能用大容量的磁盘或SSD来保存数据。</p><p></p><p>而对于专门的持久化键值数据库来说，比如LevelDB、RocksDB等，内存只是用来缓存数据的，数据最终是在磁盘上保存的。因此，和Redis直接用RDB或AOF来持久化保存数据不同，<strong>持久化键值数据库的一个关键技术就是如何高效地在磁盘上读写数据</strong>。</p><p></p><p>以RocksDB为例，我在学习它的关键技术时，主要关注的是RocksDB用来快速写入数据的<strong>Log Structure Merge Tree结构</strong>（<a href=\"http://xn--LSM-Tree-v07qv87p\">LSM-Tree</a>）。LSM-Tree结构可以说是当前很多键值数据库都在采用的一种数据组织形式，简单来说，它的主要特点有两个。</p><p></p><p>一是，它把数据以日志追加写的方式写入到磁盘，而不是采用常用的原地更新方法来修改数据。</p><p>比如，现在键值数据库中有一个键值对是“mykey”:“myvalue”，我们现在要把它修改为“mykey”:“newvalue”。那么，如果是在Redis中，Redis就会直接修改“myvalue”为“newvalue”了。而在LSM结构下，键值数据库并不是直接修改的，它会新写入键值对“mykey”:“newvalue”，而原来的键值对“mykey”:“myvalue”就转变成了垃圾数据。这样做的好处是，键值数据库不用读取旧数据，从而可以较快地完成修改操作。</p><p></p><p>二是，在LSM结构下，当发生修改的数据，其旧数据变成垃圾数据之后，键值数据库会启用后台线程来完成垃圾数据的回收，也就是把垃圾数据清除，从而将垃圾数据占用的空间释放掉，避免在修改频繁的情况下，这些垃圾数据占用的空间越来越大。</p><p></p><p>那么，正是基于这两个特性，基于LSM结构的持久化键值数据库<strong>既能获得不错的写性能，而且也不会占满整个磁盘空间</strong>，因此，它们在实际业务场景中应用广泛。</p><p></p><p>如果你在学习Redis之余，想要进一步了解持久化键值数据库的话，那么LSM结构肯定就是你需要重点关注的一个关键技术了。</p><p></p><p>好了，最后，我再来和你聊聊，我在学习其他类型键值数据库时，看到的键值数据库发展趋势。</p><p></p><h2>体会三：键值数据库越来越重要</h2><p>我们都知道，Redis的一个重要应用场景是缓存场景，而缓存就是为了应对数据的访问局部性，把热点数据保存在快速的Redis中来加速访问。当前，在应用数据量日益增加的情况下，数据访问的局部性仍然会存在，而且需要缓存的数据量也会日益增加。</p><p>所以，Redis作为缓存应用的重要性会一直保持，而且大容量的Redis缓存集群也会越来越重要，因为这可以用来应对缓存数据量增加的场景。</p><p></p><p>那么，对于持久化键值数据库来说，比如RocksDB，我也看到它在分布式存储系统中的重要性越来越高。</p><p>分布式存储系统通常是应用在云计算场景当中，它在存储节点上的存储引擎，通常需要能快速写入数据，而像RocksDB这样基于LSM结构的持久化键值数据库，正好可以用来面向磁盘快速写入数据。所以，有些分布式存储系统就会使用RocksDB，或类似采用LSM结构的键值数据库，比如TiKV，来作为分布式存储节点的存储引擎。</p><p>因此，如果你需要开展分布式存储系统方面的工作时，你就可以重点关注下持久化键值数据库在这方面的重要作用。</p><p></p><h2>小结</h2><p>今天这节加餐课，我主要是和你聊了聊，我自己在学习Redis之余，学习其他键值数据库时的一些体会。</p><p>那么，我们可以从Redis和MongoDB键值数据库，不同数据类型的对比当中看到，虽然Redis提供了丰富的数据类型，但是MongoDB提供的文档数据类型，以及基于此的类似单表SQL查询功能，同样有着重要的应用场景。所以，当你在一些Web应用开发场景中，需要对JSON形式的应用数据进行条件查询时，你就可以把MongoDB使用起来。</p><p></p><p>另外我也跟你聊了下我对持久化键值数据库的理解，持久化键值数据库实际上是要用磁盘来保存所有数据的，而并不只是像Redis那样，用内存来保存，持久化保存数据只是为了提供可靠性保证。如果你开始学习持久化键值数据库，你也需要了解LSM结构在持久化键值数据库中的重要作用，这个结构是至关重要的。</p><p></p><p>最后，我想和你说的是，无论是Redis还是持久化键值数据库，它们的作用在当前大数据、云计算的场景中，都是越来越重要，希望你能通过这门课程的学习，先把Redis掌握好，然后再来学习这些有代表性的持久化键值数据库，来扩大你的知识面和技术栈的深度。</p><p></p><p></p><h2>每课一问</h2><p>你在日常的学习工作中，除了Redis，有了解或使用过其他类型的键值数据库吗？欢迎来分享些你的学习或使用体会。</p><p></p><p></p>","neighbors":{"left":{"article_title":"加餐2 | 用户Kaito：我是怎么读Redis源码的？","id":419664},"right":{"article_title":"加餐4 | RDB和AOF文件损坏了咋办？","id":423390}}},{"article_id":423390,"article_title":"加餐4 | RDB和AOF文件损坏了咋办？","article_content":"<p>你好，我是蒋德钧。今天的加餐课程，我来和你聊聊Redis对损坏的RDB和AOF文件的处理方法。</p><p>我们知道，Redis为了提升可靠性，可以使用AOF记录操作日志，或者使用RDB保存数据库镜像。AOF文件的记录和RDB文件的保存都涉及写盘操作，但是，如果在写盘过程中发生了错误，就会导致AOF或RDB文件不完整。而Redis使用不完整的AOF或RDB文件，是无法恢复数据库的。那么在这种情况下，我们该怎么处理呢？</p><p></p><p>实际上，Redis为了应对这个问题，就专门实现了针对AOF和RDB文件的完整性检测工具，也就是redis-check-aof和redis-check-rdb两个命令。今天这节课，我就来给你介绍下这两个命令的实现以及它们的作用。学完这节课后，如果你再遇到无法使用AOF或RDB文件恢复Redis数据库时，你就可以试试这两个命令。</p><p></p><p>接下来，我们先来看下AOF文件的检测和修复。</p><p></p><h2>AOF文件检测与修复</h2><p>要想掌握AOF文件的检测和修复，我们首先需要了解下，AOF文件的内容格式是怎样的。</p><p></p><h3>AOF文件的内容格式</h3><p>AOF文件记录的是Redis server运行时收到的操作命令。当Redis server往AOF文件中写入命令时，它会按照RESP 2协议的格式来记录每一条命令。当然，如果你使用了Redis 6.0版本，那么Redis会采用RESP 3协议。我在第一季的时候，曾经给你介绍过Redis客户端和server之间进行交互的<a href=\"https://time.geekbang.org/column/article/298504\">RESP 2协议</a>，你可以再去回顾下。</p><!-- [[[read_end]]] --><p></p><p>这里我们就简单来说下，RESP 2协议会为每条命令或每个数据进行编码，在每个编码结果后面增加一个<strong>换行符“\\r\\n”</strong>，表示一次编码结束。一条命令通常会包含命令名称和命令参数，RESP 2协议会使用数组编码类型来对命令进行编码。比如，当我们在AOF文件中记录一条SET course redis-code命令时，Redis会分别为命令本身SET、key和value的内容course和redis-code进行编码，如下所示：</p><pre><code class=\"language-plain\">*3\n$3\nSET\n$6\ncourse\n$10\nredis-code\n</code></pre><p><strong>注意</strong>，编码结果中以“<code>*</code>”或是“<code>$</code>”开头的内容很重要，因为“<code>*</code>”开头的编码内容中的数值，表示了一条命令操作包含的参数个数。当然，命令本身也被算为是一个参数，记录在了这里的数值当中。而“<code>$</code>”开头的编码内容中的数字，表示紧接着的字符串的长度。</p><p></p><p>在刚才介绍的例子中，“<code>*3</code>”表示接下来的命令有三个参数，这其实就对应了SET命令本身，键值对的key“course”和value“redis-code”。而“<code>$3</code>”表示接下来的字符串长度是3，这就对应了SET命令这个字符串本身的长度是3。</p><p></p><p>好了，了解了AOF文件中命令的记录方式之后，我们再来学习AOF文件的检测就比较简单了。这是因为RESP 2协议会将命令参数个数、字符串长度这些信息，通过编码也记录到AOF文件中，redis-check-aof命令在检测AOF文件时，就可以利用这些信息来判断一个命令是否完整记录了。</p><p></p><h3>AOF文件的检测过程</h3><p>AOF文件的检测是在redis-check-aof.c文件中实现的，这个文件的入口函数是<strong>redis_check_aof_main</strong>。在这个函数中，我们可以看到AOF检测的主要逻辑，简单来说可以分成三步。</p><p><strong>首先</strong>，redis_check_aof_main会调用fopen函数打开AOF文件，并调用redis_fstat函数获取AOF文件的大小size。</p><p></p><p><strong>其次</strong>，redis_check_aof_main会调用process函数，实际检测AOF文件。process函数会读取AOF文件中的每一行，并检测是否正确，我一会儿会给你具体介绍这个函数。这里你要知道，process函数在检测AOF文件时，如果发现有不正确或是不完整的命令操作，它就会停止执行，并且返回已经检测为正确的AOF文件位置。</p><p></p><p><strong>最后</strong>，redis_check_aof_main会根据process函数的返回值，来判断已经检测为正确的文件大小是否等于AOF文件本身大小。如果不等于的话，redis_check_aof_main函数会根据redis-check-aof命令执行时的fix选项，来决定是否进行修复。</p><p></p><p>下面的代码就展示了刚才介绍的AOF文件检测的基本逻辑，你可以看下。</p><pre><code class=\"language-plain\">//调用fopen打开AOF文件\nFILE *fp = fopen(filename,\"r+\");\n&nbsp;\n//调用redis_fstat获取文件大小size\nstruct redis_stat sb;\nif (redis_fstat(fileno(fp),&amp;sb) == -1) { …}\noff_t size = sb.st_size;\n…\noff_t pos = process(fp); //调用process检测AOF文件，返回AOF文件中已检测为正确的位置\noff_t diff = size-pos;&nbsp; //获取已检测正确的文件位置和文件大小的差距\nprintf(\"AOF analyzed: size=%lld, ok_up_to=%lld, diff=%lld\\n\", (long long) size, (long long) pos, (long long) diff);\nif (diff &gt; 0) { …} //如果检测正确的文件位置还小于文件大小，可以进行修复\nelse {\n&nbsp;&nbsp; printf(\"AOF is valid\\n\");\n}\n</code></pre><p>你也可以参考这里我给出的示意图：</p><p><img src=\"https://static001.geekbang.org/resource/image/8d/c3/8d71de18442494a5301c44faf0de16c3.jpg?wh=1920x1080\" alt=\"图片\"></p><p>OK，了解了AOF文件检测的基本逻辑后，我们再来看下刚才介绍的process函数。</p><p></p><p>process函数的主体逻辑，其实就是<strong>执行一个while(1)的循环流程</strong>。在这个循环中，process函数首先会调用readArgc函数，来获取每条命令的参数个数，如下所示：</p><p></p><pre><code class=\"language-plain\">int readArgc(FILE *fp, long *target) {\n&nbsp;&nbsp;&nbsp; return readLong(fp,'*',target);\n}\n</code></pre><p>readArgc函数会进一步调用readLong函数，而readLong函数是用来读取“<code>*</code>”“<code>$</code>”开头的这类编码结果的。readLong函数的原型如下所示，它的参数fp是指向AOF文件的指针，参数prefix是编码结果的开头前缀，比如“<code>*</code>”或“<code>$</code>”，而参数target则用来保存编码结果中的数值。</p><pre><code class=\"language-plain\">int readLong(FILE *fp, char prefix, long *target)\n</code></pre><p>这样一来，process函数通过调用readArgc就能获得命令参数个数了。不过，<strong>如果readLong函数从文件中读到的编码结果前缀，和传入的参数prefix不一致，那么它就会报错</strong>，从而让process函数检测到AOF文件中不正确的命令。</p><p></p><p>然后，process函数会根据命令参数的个数执行一个for循环，调用readString函数逐一读取命令的参数。而readString函数会先调用readLong函数，读取以“<code>$</code>”开头的编码结果，这也是让readString函数获得要读取的字符串的长度。</p><p>紧接着，readString函数就会调用readBytes函数，从AOF文件中读取相应长度的字节。不过，<strong>如果此时readBytes函数读取的字节长度，和readLong获得的字符串长度不一致，那么就表明AOF文件不完整</strong>，process函数也会停止读取命令参数，并进行报错。</p><p></p><p>下面的代码展示了readBytes函数的主要逻辑，你可以看下。</p><pre><code class=\"language-plain\">int readBytes(FILE *fp, char *target, long length) {\n&nbsp;&nbsp; &nbsp;…\n&nbsp;&nbsp;&nbsp; real = fread(target,1,length,fp);&nbsp; //从AOF文件中读取length长度的字节\n&nbsp;&nbsp;&nbsp; if (real != length) {&nbsp; //如果实际读取的字节不等于length，则报错\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ERROR(\"Expected to read %ld bytes, got %ld bytes\",length,real);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return 0;\n\t}\n\t…}\n</code></pre><p>这里你需要注意的是，如果process函数实际读取的命令参数个数，小于readArgc函数获取的参数个数，那么process函数也会停止继续检测AOF文件。</p><p></p><p>最后，process函数会打印检测AOF文件过程中遇到的错误，并返回已经检测正确的文件位置。</p><p></p><p>现在，我们就了解了AOF文件检测过程中的主要函数process，你也可以看下这里我给出的示意图。</p><p><img src=\"https://static001.geekbang.org/resource/image/03/c1/034349e8e77a5b7ae8355523ef2e4dc1.jpg?wh=1920x1080\" alt=\"图片\"></p><p>那么，就像我刚才给你介绍的，process函数返回已经检测的文件位置后，redis_check_aof_main函数会判断是否已经完成整个AOF文件的检查。如果没有的话，那么就说明在检测AOF文件的过程中，发生了某些错误，此时redis_check_aof_main函数会判断redis-check-aof命令执行时，<strong>是否带了“–fix”选项</strong>。</p><p>而如果有这一选项，redis_check_aof_main函数就会开始执行修复操作。接下来，我们就来看下AOF文件的修复。</p><p></p><h3>AOF文件的修复</h3><p>AOF文件的修复其实实现得很简单，它就是从AOF文件已经检测正确的位置开始，调用<strong>ftruncate函数</strong>执行截断操作。</p><p>这也就是说，redis-check-aof命令在对AOF文件进行修复时，一旦检测到有不完整或是不正确的操作命令时，它就只保留了从AOF文件开头到出现不完整，或是不正确的操作命令位置之间的内容，而不完整或是不正确的操作命令，以及其后续的内容就被直接删除了。</p><p>所以，我也给你一个<strong>小建议</strong>，当你使用redis-check-aof命令修复AOF文件时，最好是把原来的AOF文件备份一份，以免出现修复后原始AOF文件被截断，而带来的操作命令缺失问题。</p><p></p><p>下面的代码展示了redis_check_aof_main函数中对AOF文件进行修复的基本逻辑，你可以看下。</p><pre><code class=\"language-plain\">if (fix) {\n&nbsp;&nbsp; …\n&nbsp;&nbsp; if (ftruncate(fileno(fp), pos) == -1) {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; printf(\"Failed to truncate AOF\\n\");\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; exit(1);\n&nbsp;&nbsp;&nbsp; } else {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; printf(\"Successfully truncated AOF\\n\");\n&nbsp;}\n</code></pre><p>好了，到这里，你就了解了AOF文件的检测和修复。接下来，我们再来看下RDB文件的检测。</p><p></p><h2>RDB文件检测</h2><p>RDB文件检测是在redis-check-rdb.c文件中实现的，这个文件的入口函数是<strong>redis_check_rdb_main</strong>。它会调用redis_check_rdb函数，来完成检测。</p><p></p><p>这里你要知道，和AOF文件用RESP 2协议格式记录操作命令不一样，RDB文件是Redis数据库内存中的内容在某一时刻的快照，它包括了文件头、键值对数据部分和文件尾三个部分。而且，<strong>RDB文件是通过一定的编码来记录各种属性信息和键值对的</strong>。我在<a href=\"https://time.geekbang.org/column/article/415563\">第18讲</a>中给你介绍过RDB文件的组成和编码方式，建议你可以再去回顾下，毕竟只有理解了RDB文件的组成和编码，你才能更好地理解redis_check_rdb函数是如何对RDB文件进行检测的。</p><p></p><p>其实，redis_check_rdb函数检测RDB文件的逻辑比较简单，就是根据RDB文件的组成，逐一检测文件头的魔数、文件头中的属性信息、文件中的键值对数据，以及最后的文件尾校验和。下面，我们就来具体看下。</p><p></p><p>首先，redis_check_rdb函数<strong>先读取RDB文件头的9个字节</strong>，这是对应RDB文件的魔数，其中包含了“REDIS”字符串和RDB的版本号。redis_check_rdb函数会检测“REDIS”字符串和版本号是否正确，如下所示：</p><pre><code class=\"language-plain\">int redis_check_rdb(char *rdbfilename, FILE *fp) {\n…\nif (rioRead(&amp;rdb,buf,9) == 0) goto eoferr;&nbsp; //读取文件的头9个字节\nbuf[9] = '\\0';\nif (memcmp(buf,\"REDIS\",5) != 0) { //将前5个字节和“REDIS”比较，如果有误则报错\n&nbsp;&nbsp; rdbCheckError(\"Wrong signature trying to load DB from file\");\n&nbsp;&nbsp; goto err;\n}\nrdbver = atoi(buf+5); //读取版本号\nif (rdbver &lt; 1 || rdbver &gt; RDB_VERSION) { //如果有误，则报错\n&nbsp;&nbsp; rdbCheckError(\"Wrong signature trying to load DB from file\");\n&nbsp;&nbsp; goto err;\n}\n…}\n</code></pre><p>然后，redis_check_rdb函数会<strong>执行一个while(1)循环流程</strong>，在这个循环中，它会按照RDB文件的格式依次读取其中的内容。我在第18讲中也给你介绍过，RDB文件在文件头魔数后记录的内容，包括了Redis的属性、数据库编号、全局哈希表的键值对数量等信息。而在实际记录每个键值对之前，RDB文件还要记录键值对的过期时间、LRU或LFU等信息，这些信息都是按照操作码和实际内容来组织的。</p><p>比如，RDB文件中要记录Redis的版本号，它就会用十六进制的FA表示操作码，表明接下来的内容就是Redis版本号；当它要记录使用的数据库时，它会使用十六进制的FE操作码来表示。</p><p></p><p>好了，了解了RDB文件的这种内容组织方式后，我们接着来看下<strong>redis_check_rdb函数</strong>，它在循环流程中，就是先调用rdbLoadType函数读取操作码，然后，使用多个条件分支来匹配读取的操作码，并根据操作码含义读取相应的操作码内容。</p><p></p><p>以下代码就展示了这部分的操作码读取和分支判断逻辑，而对于每个分支中读取操作码的具体实现，你可以去仔细阅读一下源码。</p><pre><code class=\"language-plain\">if ((type = rdbLoadType(&amp;rdb)) == -1) goto eoferr;\nif (type == RDB_OPCODE_EXPIRETIME) { …} //表示过期时间的操作码\nelse if (type == RDB_OPCODE_EXPIRETIME_MS) {…} //表示毫秒记录的过期时间操的作码\nelse if (type == RDB_OPCODE_FREQ) {…} //表示LFU访问频率的操作码\nelse if (type == RDB_OPCODE_IDLE) {…} //表示LRU空闲时间的操作码\nelse if (type == RDB_OPCODE_EOF) {…} //表示RDB文件结束的操作码\nelse if (type == RDB_OPCODE_SELECTDB) {…} //表示数据库选择的操作码\nelse if (type == RDB_OPCODE_RESIZEDB) {…} //表示全局哈希表键值对数量的操作码\nelse if (type == RDB_OPCODE_AUX) {…} //表示Redis属性的操作码\nelse {…} //无法识别的操作码\n</code></pre><p>这样，在判断完操作码之后，redis_check_rdb函数就会调用rdbLoadStringObject函数，读取键值对的key，以及调用rdbLoadObject函数读取键值对的value。</p><p></p><p>最后，当读取完所有的键值对后，redis_check_rdb函数就会读取文件尾的校验和信息，然后验证校验和是否正确。</p><p></p><p>到这里，整个RDB文件的检测就完成了。在这个过程中，如果redis_check_rdb函数发现RDB文件有错误，就会将错误在文件中出现的位置、当前的检测操作、检测的键值对的key等信息打印出来，以便我们自行进一步检查。</p><h2>小结</h2><p>今天这节课，我带你了解了检测AOF文件和RDB文件正确性和完整性的两个命令，redis-check-aof和redis-check-rdb，以及它们各自的实现过程。</p><p>对于<strong>redis-check-aof命令</strong>来说，它是根据AOF文件中记录的操作命令格式，逐一读取命令，并根据命令参数个数、参数字符串长度等信息，进行命令正确性和完整性的判断。</p><p>对于<strong>redis-check-rdb命令</strong>来说，它的实现逻辑较为简单，也就是按照RDB文件的组织格式，依次读取RDB文件头、数据部分和文件尾，并在读取过程中判断内容是否正确，并进行报错。</p><p></p><p>事实上，Redis server在运行时，遇到故障而导致AOF文件或RDB文件没有记录完整，这种情况有时是不可避免的。当了解了redis-check-aof命令的实现后，我们就知道它可以提供出现错误或不完整命令的文件位置，并且，它本身提供了修复功能，可以从出现错误的文件位置处截断后续的文件内容。不过，如果我们不想通过截断来修复AOF文件的话，也可以尝试人工修补。</p><p>而在了解了redis-check-rdb命令的实现后，我们知道它可以发现RDB文件的问题所在。不过，redis-check-rdb命令目前并没有提供修复功能。所以如果我们需要修复的话，就只能通过人工自己来修复了。</p><h2>每课一问</h2><p>redis_check_aof_main函数是检测AOF文件的入口函数，但是它还会调用检测RDB文件的入口函数redis_check_rdb_main，那么你能找到这部分代码，并通过阅读说说它的作用吗？</p>","neighbors":{"left":{"article_title":"加餐3 | 从Redis到其他键值数据库的学习体会","id":423388},"right":{"article_title":"用户故事 | 曾轼麟：世上无难事，只怕有心人","id":423423}}},{"article_id":423423,"article_title":"用户故事 | 曾轼麟：世上无难事，只怕有心人","article_content":"<p>你好，我叫曾轼麟，目前在广州一家互联网公司，从事互动社交业务领域中的服务端开发工作。</p><p>我从《Redis核心技术与实战》的时候，就开始跟随蒋老师的脚步，一直在学习Redis相关的知识。在这个过程中，我收获了很多新的认知，也对Redis的使用及其底层实现有了不一样的理解，所以，很高兴能在这里跟你分享我学习课程的心得与体会、学习思路与方法。</p><h2>为什么学习Redis源码？</h2><p>其实早在老师开设这门课程之前，我就已经坚持阅读Redis源码一段时间了。</p><p>一开始我有想去阅读Redis源码的念头时，应该是在2020年初，那时候Redis 6.0版本新增了IO多线程的这个特性。而一直以单线程设计为主推的Redis，突然高调引入了多线程的设计，就让我对其新的设计思路感到非常好奇。</p><p>在随后的一段时间里，Redis社区也发生了重大的变化：安迪斯（Antirez，Redis之父）不再维护Redis，而是全权交给了社区进行维护。由此Redis开源的方式就由专制模式，转变为了社区自治模式。老实说，我其实挺期待这种变化会给Redis的未来带来什么样的影响。也是因为这种种原因，就促使我开展了源码阅读之旅。</p><p>到了2021年的1月份，公司上市后为了进一步抢占市场，领导和我们提出：市场今年需要发力，本年度的OKR可能会是5倍、10倍乃至30倍的DAU增长，而面临这样的增速，我认为对系统性能的优化要求就迫在眉睫。并且年初的时候由于DAU的增长，几乎每隔一天晚上，我都会被告警叫起来处理线上问题（我们做的是海外业务），在经历了半年的重构和优化后，目前已经趋于稳定。而在这半年的时间里，<strong>无论是研制新的缓存组件、改造现有缓存方案，还是新业务的发展，几乎都离不开Redis</strong>，甚至连运营和产品同学都会问我们，这次设计方案咱用Redis吗？</p><!-- [[[read_end]]] --><p>所以，除了我个人对于Redis的新特性和底层实现原理的关注之外，在工作上的各种变化和挑战，也驱动我想要快速提升阅读Redis源码的能力，并能通过读源码的设计思路，帮助指导和解决我在优化高性能接口上遇到的各种难题。</p><h2>我是怎么学习Redis源码的？</h2><p>那么，我是怎么学习源码的呢？</p><p>其实在一开始阅读Redis源码的时候，我也走了一些弯路，无论是从IDE的选择，还是确定代码阅读的切入点，我都花费了大量的时间，但最后我发现花费了时间却没达到理想的效果。所以这里，我先来分享一些我踩坑后总结的经验/建议，希望能通过这些经验/建议，帮助你更好地阅读源码。</p><ul>\n<li><strong>Linux</strong></li>\n</ul><p>首先，就是一定要有一套Linux的环境，它能自行编译打包源码，从而可以方便我们做调试，（Windows的同学可以使用虚拟机），这里可以参考Redis在GitHub上面的<a href=\"https://github.com/redis/redis\">文档</a>。我曾经尝试在Windows去编译Redis，但是最后发现成本比想象中的要高，而且Windows对编译环境不太友好，导致编译出来验证后的效果，不一定是和实际服务器的效果一致的。</p><ul>\n<li><strong>Clion</strong></li>\n</ul><p>为了方便阅读源码，我曾经选择过一些IDE工具来作为辅助，比如VS Code、Visual Studio，甚至是文本工具，但是最后为了保留Java开发者的快捷键习惯，我最后是选择使用了CLion这款软件。所以，如果你也是Java开发者，这里我建议你可以考虑把源码阅读环境和调试环境分离开，这样就可以避免很多不必要的环境冲突。比如在Windows下阅读代码，然后提交到虚拟机中的Linux进行断点调试。</p><ul>\n<li><strong>GDB</strong></li>\n</ul><p>关于Redis的调试，我非常推荐这款调试工具，它本身在Linux上就已经是兼容的了，每次我需要分析某个指针对象或者缓冲区空间内容的时候，都可以使用它，它甚至还能伪造一些阻塞的场景，比如下图是我在getGenericCommand方法入口进行断点，并输出Client结构体里面querybuf的内容（图中是RESP协议的字符串）。</p><p><img src=\"https://static001.geekbang.org/resource/image/31/16/31fcb1e8dc693f11bb2c54ff29622d16.jpg?wh=1920x399\" alt=\"图片\"></p><ul>\n<li><strong>不要忽略注释</strong></li>\n</ul><p>在Redis的源码中存在着很多注释，尤其是那些写在某一行代码上面的注释，这些注释很多时候能最直接代表作者的想法和思路，所以我认为这些注释是一定要翻译细读的，可以减少很多我们在阅读源码过程中的疑惑。比如在<a href=\"https://time.geekbang.org/column/article/421736\">《23 | 从哨兵Leader选举学习Raft协议实现（上）》</a>的每课一问中，蒋老师提出的问题就能在如下的注释中得到解答：</p><pre><code class=\"language-plain\">void sentinelTimer(void) {\n    sentinelCheckTiltCondition();\n    sentinelHandleDictOfRedisInstances(sentinel.masters);\n    sentinelRunPendingScripts();\n    sentinelCollectTerminatedScripts();\n    sentinelKillTimedoutScripts();\n    //这里就是&nbsp;server.hz 需要动态调整作者为此做出的解释\n    /* We continuously change the frequency of the Redis \"timer interrupt\"\n     * in order to desynchronize every Sentinel from every other.\n     * This non-determinism avoids that Sentinels started at the same time\n     * exactly continue to stay synchronized asking to be voted at the\n     * same time again and again (resulting in nobody likely winning the\n     * election because of split brain voting). */\n    server.hz = CONFIG_DEFAULT_HZ + rand() % CONFIG_DEFAULT_HZ;\n}\n</code></pre><ul>\n<li><strong>结合官网文档和GitHub的文档</strong></li>\n</ul><p>很多疑问和设计思路其实在这些地方都可以找到相应的解答，比如<a href=\"https://github.com/redis/redis\">GitHub</a>上面，我们可以找到Redis编译、配置相关的文档。而在<a href=\"https://redis.io/documentation\">官网</a>，我们可以了解到Redis的各种设计思想等。在学习课程的过程中，我认为还可以回到社区，去时常关注Redis正在发生的变化，这样来结合源码的解读和学习，就能帮助我们获得更好的学习效果。</p><p>而更重要的就是，刚刚开始阅读的同学，一定要跟随老师的脚步，因为老师会按照源码结构和知识点的内容划分模块，并通过课程讲述的逐渐推进，帮我们找到每个功能模块合适的切入点，这样能避免走很多弯路。我在自己阅读源码的时候，其实就是像瞎子过河一样，导致走了弯路，直到看完老师的课程才豁然开朗。</p><h3>基础知识很重要</h3><p>在学习和阅读Redis源码期间，我能很明显地感受到基础知识的重要性。<strong>万丈高楼平地起</strong>，无论是Redis中的跳表、Hash表的实现，还是Redis中多线程与多进程的协作，几乎都离不开基础知识。这里，我来推荐两本书和一个课程，这些内容对我理解Redis设计原理和阅读Redis源码帮助很大。</p><ul>\n<li><a href=\"https://book.douban.com/subject/26912767/\">《深入理解计算机系统》</a></li>\n</ul><p>CSAPP想必很多人都有所接触，这里我以第三版为例，书中的第八章到第十二章节中，就涵盖了Redis实现相关的基础知识内容，比如进程、虚拟内存、系统I/O、网络、并发编程，等等。比如：在Redis源码中使用的fork()在书中《进程》章节就有专门说明，还有写时复制形成原因，在《虚拟内存》的章节中也有。</p><ul>\n<li><a href=\"https://book.douban.com/subject/20432061/\">《算法导论》</a></li>\n</ul><p>可能很多人听到这个名字就感到害怕，但这本其实并不是每个章节都是晦涩难懂的，就以第三版为例，书中第三部分“数据结构-散列表”，以及第五部分“高级数据结构-B树”，在我们的这门Redis源码课的学习过程中，也时有提及。</p><ul>\n<li>徐文浩老师的课程<a href=\"https://time.geekbang.org/column/intro/100026001\">《深入浅出计算机组成原理》</a></li>\n</ul><p>在这门课程中，老师提到了内存伪共享、CPU缓存行和虚拟内存等相关知识，也有各种计算机结构相关的知识点。读完也许你就能明白：为什么Redis会一直坚持单线程的设计思路？以及为什么以前我们经常会建议，在部署Redis的时候进行绑核操作？</p><p>当然我这里也不是说，我们需要全部读完，而是可以结合着来学习，当我们遇到某些不太容易掌握的知识点的时候，可以尝试着去这些书籍课程中寻找相关的补充资料，这样更有助于深入理解Redis源码的设计初衷。</p><h3>实践和回馈也很重要</h3><p>读万卷书不如行万里路，对Redis的学习也一样，我们不能只阅读源码，还需要经常去做尝试（当然这里我不建议直接在线上尝试）。<strong>只有不断地试错，才能得到成长。</strong></p><p>我曾经就在线下，使用过不同的内存分配机制来编译Redis，最后通过压测工具去对比效果。或者是在Redis中，通过断点去观察querybuf中RESP协议的解析过程。在每次的尝试过程中，我都能有所收获，都能感受到动手实操所带来的愉悦感，并且愈发有深入学习下去的动力。</p><p>所以我建议你可以结合一些场景去进行实践，可以是对源码断点进行调试，也可以是针对源码的改造，哪怕只是一个日志输出，再或者是结合实际的业务场景做出一些改进，做出点成果，然后用这些成果来回馈自己。</p><p>而回到Redis源码的课程中，对于<strong>每课一问</strong>，我也是非常期待的，因为我总能看到一些同学有不一样的想法和观点，或者提出一些新颖的提问。在这个交流的过程中，其实也是一种学习的回馈。老师的提问，有助于引导我们去思考Redis这样设计的价值和意义。</p><h3>死磕精神和知识沉淀</h3><p>阅读源码的过程一定会伴随着枯燥，尤其是当遇到一个知识盲区，或者是自身无法理解的事物的时候，这种知识上的挑战所带来的焦虑的情绪，就会导致我们失去了继续看下去的动力。而每到这种时候，我就会让自己休息一下，换个心情，说不定第二天就想通了。</p><p>我还记得当时在阅读Redis生命周期相关代码的时候，我就整整花了一周的时间，去画出整个生命周期的时序图，最终才把整个流程和思路走通。后来我渐渐发现，每当我想起一个Redis的功能特性，几乎都能有办法迅速定位到源码的位置，而这就是我通过转换心情和坚持做事的死磕精神，给我带来的学习收益。</p><p>同时，在阅读Redis源码的过程中，我也会输出自己的知识文档/博客，每次阅读完某个功能的代码后，都会记录下当时的理解过程和思路。然后，每当我重新阅读这部分代码的时候，就会回来作对比，结果往往就会发现，随着我的知识面的拓展和对代码的深入理解，很多细节其实和当时的理解是有偏差的，那么这个时候我就会去修正文档，而这样对我自己来说，其实也是一种知识的沉淀和积累。</p><p>比如，下面展示的就是我之前所做的辅助理解图例。<br>\n<img src=\"https://static001.geekbang.org/resource/image/66/8c/66a4e8d1a96d605e72a5e36c01c8798c.jpg?wh=1920x941\" alt=\"图片\" title=\"字典数据结构图\"></p><h2>写在最后</h2><p>最后，很高兴能和大家一起学习Redis源码，并且能有机会分享自己的学习心得。</p><p>我觉得，订阅这门课程的同学，本身就是对技术有更高追求的，对技术都是有前瞻视野的。虽然Redis源码的学习是一个持续且漫长的过程，需要付出时间去坚持，我们可能一开始会备受打击，但是一旦学有所成，它带给我们的收获，一定是非常有价值的。</p><p>世上无难事，只怕有心人，祝大家在学习完课程后，自身的能力都能更上一层楼。也期待各位的留言，我们一起交流和讨论，一起学习，共同进步。</p>","neighbors":{"left":{"article_title":"加餐4 | RDB和AOF文件损坏了咋办？","id":423390},"right":{"article_title":"26 | 从Ping-Pong消息学习Gossip协议的实现","id":424827}}},{"article_id":424827,"article_title":"26 | 从Ping-Pong消息学习Gossip协议的实现","article_content":"<p>你好，我是蒋德钧。</p><p></p><p>从这节课开始，我们又将进入一个新的模块：“Redis Cluster”模块。在这个模块中，我会带你了解Redis Cluster的关键功能实现，包括了Gossip协议通信、集群关键命令和数据迁移等机制的设计与实现。</p><p></p><p>通过这些课程的学习，一方面，你可以深入了解Redis是如何完成集群关系维护、请求转发和数据迁移的。当你遇到集群问题时，这些知识可以帮助你排查问题。另一方面，当你在开发分布式集群时，不可避免地会遇到节点信息维护、数据放置和迁移等设计问题，接下来的几节课可以让你掌握Gossip协议、数据迁移等分布式集群中关键机制的典型设计和实现，而这些实现方法对于你开发分布式集群是很有帮助的。</p><p></p><p>那么接下来，我就先带你来学习Redis Cluster中节点的通信机制，而这个通信机制的关键是Gossip协议。所以今天这节课，我们主要来了解下Gossip协议在Redis中是如何实现的。</p><p></p><h2>Gossip协议的基本工作机制</h2><p>对于一个分布式集群来说，它的良好运行离不开集群节点信息和节点状态的正常维护。为了实现这一目标，通常我们可以选择<strong>中心化</strong>的方法，使用一个第三方系统，比如Zookeeper或etcd，来维护集群节点的信息、状态等。同时，我们也可以选择<strong>去中心化</strong>的方法，让每个节点都维护彼此的信息、状态，并且使用集群通信协议Gossip在节点间传播更新的信息，从而实现每个节点都能拥有一致的信息。</p><!-- [[[read_end]]] --><p></p><p>下图就展示了这两种集群节点信息维护的方法，你可以看下。</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/08/c7/08e25d1645b196f0143b495071d219c7.jpg?wh=1920x894\" alt=\"图片\"></p><p>我在<a href=\"https://time.geekbang.org/column/article/310347\">第一季</a>的“通信开销：限制Redis Cluster规模的关键因素”课程中，介绍过Gossip协议的工作机制，你可以去参考或回顾下。这里，我就简单介绍下Gossip协议的主要机制，来帮助你更好地理解接下来要学习的Gossip协议，在源码层面的设计与实现。</p><p></p><p>简单来说，在一个使用了Gossip协议的集群中，每个集群节点会维护一份集群的状态信息，包括集群中各节点的信息、运行状态，以及数据在各节点间的分布情况。</p><p></p><p>对于Redis来说，集群节点信息包括了节点名称、IP、端口号等，而节点运行状态主要用两个时间来表示，分别是节点向其他节点发送PING消息的时间，以及它自己收到其他节点返回的PONG消息的时间。最后，集群中数据的分布情况，在Redis中就对应了Redis Cluster的slots分配情况，也就是每个节点拥有哪些slots。</p><p></p><p>当集群节点按照Gossip协议工作时，每个节点会以一定的频率从集群中随机挑选一些其他节点，把自身的信息和已知的其他节点信息，用PING消息发送给选出的节点。而其他节点收到PING消息后，也会把自己的信息和已知的其他节点信息，用PONG消息返回给发送节点，这个过程如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/44/1b/44b8b114acyy59f9eb5ac410a28fe01b.jpg?wh=1920x489\" alt=\"图片\"></p><p>Gossip协议正是通过这种<strong>随机挑选通信节点</strong>的方法，让节点信息在整个集群中传播。当有节点维护的信息发生变化时，比如数据布局信息发生了改变，那么通过几轮通信后，其他节点也可以获得这一变化的信息了。这样一来，就实现了分布式集群所有节点维护一致的状态信息的目标。</p><p></p><p>好了，了解了Gossip协议的基本工作机制后，下面我们就来学习Redis中是如何实现Gossip协议的。</p><p></p><h2>Redis是如何实现Gossip通信的？</h2><p>首先，你要知道Redis Cluster的主要功能是在<strong>cluster.h和cluster.c</strong>两个文件中定义和实现的。如果你有进一步阅读源码的需求，可以重点从这两个文件中查找。</p><p></p><p>然后，我们来看下Redis Cluster中通信的消息有哪些，这也是Gossip协议通信的基础数据结构。</p><p></p><h3>节点通信的常见消息有哪些？</h3><p>Redis源码在cluster.h文件中，通过宏定义定义了节点间通信的消息类型。下面的代码列了几种常见的消息，包括<strong>Ping</strong>消息，这是一个节点用来向其他节点发送信息的消息类型，而<strong>Pong</strong>是对Ping消息的回复。<strong>Meet</strong>消息是一个节点表示要加入集群的消息类型，而<strong>Fail</strong>消息表示某个节点有故障。如果你想了解更多的消息类型，可以进一步阅读cluster.h文件。</p><pre><code class=\"language-plain\">#define CLUSTERMSG_TYPE_PING 0&nbsp; //Ping消息，用来向其他节点发送当前节点信息\n#define CLUSTERMSG_TYPE_PONG 1&nbsp; //Pong消息，对Ping消息的回复\n#define CLUSTERMSG_TYPE_MEET 2&nbsp; //Meet消息，表示某个节点要加入集群\n#define CLUSTERMSG_TYPE_FAIL 3&nbsp; //Fail消息，表示某个节点有故障\n</code></pre><p>刚才我介绍的是节点间通信的消息类型，那么，<strong>Redis源码中消息的数据结构具体是怎样的呢？</strong>这部分内容也是在cluster.h文件中定义的。</p><p></p><p>Redis定义了一个<strong>结构体clusterMsg</strong>，它用来表示节点间通信的一条消息。它包含的信息包括发送消息节点的名称、IP、集群通信端口和负责的slots，以及消息类型、消息长度和具体的消息体。下面的代码展示了clusterMsg定义中的部分重要内容，你可以看下。</p><pre><code class=\"language-plain\">typedef struct {\n&nbsp;&nbsp; …\n&nbsp;&nbsp; uint32_t totlen;&nbsp;&nbsp;&nbsp; //消息长度\n&nbsp;&nbsp; uint16_t type;&nbsp;&nbsp;&nbsp;&nbsp; //消息类型\n&nbsp;&nbsp; …\n&nbsp;&nbsp; char sender[CLUSTER_NAMELEN]; &nbsp;//发送消息节点的名称\n&nbsp;&nbsp; unsigned char myslots[CLUSTER_SLOTS/8]; //发送消息节点负责的slots\n&nbsp;&nbsp; char myip[NET_IP_STR_LEN];&nbsp; //发送消息节点的IP\n&nbsp;&nbsp; uint16_t cport;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //发送消息节点的通信端口\n&nbsp;&nbsp; …\n&nbsp;&nbsp; union clusterMsgData data;&nbsp; //消息体\n} clusterMsg;\n</code></pre><p>从clusterMsg数据结构中，我们可以看到它包含了一个<strong>联合体结构clusterMsgData</strong>，而这个数据结构正是定义了节点间通信的实际消息体。</p><p></p><p>在cluster.h文件中，我们可以看到clusterMsgData的定义，它包含了多种消息类型对应的数据结构，包括clusterMsgDataGossip、clusterMsgDataFail、clusterMsgDataPublish和clusterMsgDataUpdate，如下所示，而这些数据结构也就对应了不同类型消息的消息体。</p><p></p><pre><code class=\"language-plain\">union clusterMsgData {\n&nbsp;&nbsp;&nbsp; //Ping、Pong和Meet消息类型对应的数据结构\n&nbsp;&nbsp;&nbsp; struct {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; clusterMsgDataGossip gossip[1];\n&nbsp;&nbsp;&nbsp; } ping;\n&nbsp;\n&nbsp;&nbsp;&nbsp; //Fail消息类型对应的数据结构\n&nbsp;&nbsp;&nbsp; struct {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; clusterMsgDataFail about;\n&nbsp;&nbsp;&nbsp; } fail;\n&nbsp;\n&nbsp;&nbsp;&nbsp; //Publish消息类型对应的数据结构\n&nbsp;&nbsp;&nbsp; struct {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; clusterMsgDataPublish msg;\n&nbsp;&nbsp;&nbsp; } publish;\n&nbsp;\n&nbsp;&nbsp;&nbsp; //Update消息类型对应的数据结构\n&nbsp;&nbsp;&nbsp; struct {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; clusterMsgDataUpdate nodecfg;\n&nbsp;&nbsp;&nbsp; } update;\n&nbsp;\n&nbsp;&nbsp;&nbsp; //Module消息类型对应的数据结构\n&nbsp;&nbsp;&nbsp; struct {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; clusterMsgModule msg;\n&nbsp;&nbsp;&nbsp; } module;\n};\n</code></pre><p>在这个联合体结构中，我们重点看下<strong>clusterMsgDataGossip数据结构</strong>，因为它对应了Gossip协议通信过程中使用的Ping、Pong和Meet消息的消息体。clusterMsgDataGossip数据结构定义如下所示：</p><pre><code class=\"language-plain\">typedef struct {\n&nbsp;&nbsp;&nbsp; char nodename[CLUSTER_NAMELEN]; //节点名称\n&nbsp;&nbsp;&nbsp; uint32_t ping_sent;&nbsp; //节点发送Ping的时间\n&nbsp;&nbsp;&nbsp; uint32_t pong_received; //节点收到Pong的时间\n&nbsp;&nbsp;&nbsp; char ip[NET_IP_STR_LEN];&nbsp; //节点IP\n&nbsp;&nbsp;&nbsp; uint16_t port;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //节点和客户端的通信端口\n&nbsp;&nbsp;&nbsp; uint16_t cport;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //节点用于集群通信的端口\n&nbsp;&nbsp;&nbsp; uint16_t flags;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//节点的标记\n&nbsp;&nbsp;&nbsp; uint32_t notused1;&nbsp;&nbsp;&nbsp; //未用字段\n} clusterMsgDataGossip;\n</code></pre><p>从clusterMsgDataGossip数据结构中，我们可以看到，它里面包含了节点的基本信息，比如节点名称、IP和通信端口，以及使用Ping、Pong消息发送和接收时间来表示的节点运行状态。这就和我刚才给你介绍的Gossip协议工作机制中的通信内容对应上了。</p><p></p><p>那么，Gossip协议在通信过程中传播的slots分布信息，也已经在刚才介绍的clusterMsg数据结构中定义了。所以，<strong>Redis使用clusterMsg结构体作为节点间通信的消息，就可以实现Gossip协议的通信目的</strong>。如果你要开发Gossip协议，可以参考这里clusterMsg、clusterMsgData和clusterMsgDataGossip的定义。</p><p></p><p>好了，了解了Redis Cluster中节点通信的消息定义后，接下来，我们来看下Gossip协议中的收发消息具体是如何实现的。</p><p></p><h3>Ping消息的生成和发送</h3><p>Gossip协议是按一定的频率随机选一些节点进行通信的。那么在前面课程的学习中，我们已经知道，Redis的serverCron函数是在周期性执行的。而它会调用<strong>clusterCron函数</strong>（在cluster.c文件中）来实现集群的周期性操作，这就包括了Gossip协议的通信。</p><pre><code class=\"language-plain\">int serverCron(struct aeEventLoop *eventLoop, long long id, void *clientData) {\n&nbsp; &nbsp;…\n&nbsp; &nbsp;run_with_period(100) {\n&nbsp; &nbsp; &nbsp; //每100ms调用依次clusterCron函数\n&nbsp; &nbsp; &nbsp; if (server.cluster_enabled) clusterCron();&nbsp; \n&nbsp; &nbsp;}\n&nbsp; &nbsp;…\n}\n</code></pre><p>clusterCron函数的一个主要逻辑就是每经过10次执行，就会随机选五个节点，然后在这五个节点中，遴选出最早向当前节点发送Pong消息的那个节点，并向它发送Ping消息。而clusterCron函数本身是每1秒执行10次，所以，这也相当于是<strong>集群节点每1秒向一个随机节点发送Gossip协议的Ping消息</strong>。</p><p></p><p>下面的代码展示了clusterCron函数的这一执行逻辑，你可以看下。</p><pre><code class=\"language-plain\">void clusterCron(void) {\n&nbsp;&nbsp; …\n&nbsp;&nbsp; if (!(iteration % 10)) { //每执行10次clusterCron函数，执行1次该分支代码\n&nbsp;&nbsp; int j;\n&nbsp;&nbsp; for (j = 0; j &lt; 5; j++) { //随机选5个节点\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; de = dictGetRandomKey(server.cluster-&gt;nodes);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; clusterNode *this = dictGetVal(de);\n&nbsp;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //不向断连的节点、当前节点和正在握手的节点发送Ping消息\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;if (this-&gt;link == NULL || this-&gt;ping_sent != 0) continue;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (this-&gt;flags &amp; (CLUSTER_NODE_MYSELF|CLUSTER_NODE_HANDSHAKE))\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;continue;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //遴选向当前节点发送Pong消息最早的节点\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (min_pong_node == NULL || min_pong &gt; this-&gt;pong_received) {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; min_pong_node = this;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; min_pong = this-&gt;pong_received;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }\n&nbsp;&nbsp;&nbsp; }\n&nbsp;&nbsp;&nbsp; //如果遴选出了最早向当前节点发送Pong消息的节点，那么调用clusterSendPing函数向该节点发送Ping消息\n&nbsp;&nbsp;&nbsp; if (min_pong_node) {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; serverLog(LL_DEBUG,\"Pinging node %.40s\", min_pong_node-&gt;name);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; clusterSendPing(min_pong_node-&gt;link, CLUSTERMSG_TYPE_PING);\n&nbsp;&nbsp;&nbsp; }\n&nbsp; }\n&nbsp; …\n}\n</code></pre><p>从这段代码中，我们可以看到，向其他节点发送Ping消息的函数是<strong>clusterSendPing</strong>，而实际上，Ping消息也是在这个函数中完成构建和发送的。 clusterSendPing函数的主要逻辑可以分成三步，分别是：构建Ping消息头、构建Ping消息体和发送消息。我们分别来看下。</p><p></p><p><strong>第一步，构建Ping消息头</strong></p><p></p><p>clusterSendPing函数会调用<strong>clusterBuildMessageHdr函数</strong>来构建Ping消息头，如下所示：</p><pre><code class=\"language-plain\">if (link-&gt;node &amp;&amp; type == CLUSTERMSG_TYPE_PING)\n&nbsp;&nbsp; link-&gt;node-&gt;ping_sent = mstime(); //如果当前是Ping消息，那么在发送目标节点的结构中记录Ping消息的发送时间\nclusterBuildMessageHdr(hdr,type); //调用clusterBuildMessageHdr函数构建Ping消息头\n</code></pre><p>在刚才学习Redis Cluster节点间通信消息的数据结构时，我们知道了，每一条消息的数据结构是clusterMsg，所以在这里，clusterBuildMessageHdr函数也是设置clusterMsg结构体中的各个成员变量，比如消息类型，发送消息节点的名称、IP、slots分布等信息。你可以进一步仔细阅读clusterBuildMessageHdr函数的源码，了解这些成员变量的具体设置。</p><p></p><p>不过，clusterBuildMessageHdr函数并不会设置clusterMsg结构体中的data成员变量，这个成员变量就是刚才我介绍的clusterMsgData联合体，也就是Ping消息的消息体。因为在完成消息头的构建后，clusterSendPing函数就会来构建消息体。</p><p></p><p><strong>第二步，构建Ping消息体</strong></p><p>你可以再看下clusterMsgData的数据结构定义，如下所示。当它表示Ping、Pong消息时，其实是一个clusterMsgDataGossip类型的数组，这也就是说，一个Ping消息中会包含多个clusterMsgDataGossip结构体，而每个clusterMsgDataGossip结构体实际对应了一个节点的信息。</p><p></p><pre><code class=\"language-plain\">union clusterMsgData {\n&nbsp;&nbsp;&nbsp; struct {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //当消息是Ping或Pong时，使用clusterMsgDataGossip类型的数组\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; clusterMsgDataGossip gossip[1];\n\t} ping;\n\t…\n}\n</code></pre><p>所以，当clusterSendPing函数构建Ping消息体时，它会将多个节点的信息写入Ping消息。那么，<strong>clusterSendPing函数具体会写入多少个节点的信息呢？</strong>这其实是由三个变量控制的，分别是freshnodes、wanted和maxiterations。</p><p></p><p>其中，freshnodes的值等于集群节点数减2，如下所示：</p><pre><code class=\"language-plain\">int freshnodes = dictSize(server.cluster-&gt;nodes)-2;\n</code></pre><p>而wanted变量的值和freshnodes大小也有关，wanted的默认值是集群节点数的1/10，但是如果这个默认值小于3，那么wanted就等于3。如果这个默认值大于freshnodes，那么wanted就等于freshnodes的大小，这部分的计算逻辑如下所示：</p><pre><code class=\"language-plain\">wanted = floor(dictSize(server.cluster-&gt;nodes)/10);\nif (wanted &lt; 3) wanted = 3;\nif (wanted &gt; freshnodes) wanted = freshnodes;\n</code></pre><p>有了wanted值之后，maxiterations的值就等于wanted的三倍大小。</p><pre><code class=\"language-plain\">int maxiterations = wanted*3;\n</code></pre><p>在计算完freshnodes、wanted和maxiterations这三个值的大小后，clusterSendPing会根据这三个值的大小，执行一个<strong>循环流程</strong>，在这个循环中，它每次从集群节点中随机选一个节点出来，并调用clusterSetGossipEntry函数为这个节点设置相应的Ping消息体，也就是clusterMsgDataGossip结构。关于clusterSetGossipEntry函数对clusterMsgDataGossip结构的具体设置，你可以进一步看下它的源码。</p><p></p><p>当然，如果选出的节点是当前节点自身、可能有故障的节点、正在握手的节点、失联的节点以及没有地址信息的节点，那么clusterSendPing是不会为这些节点设置Ping消息体的。</p><p></p><p>下面的代码展示了clusterSendPing函数设置Ping消息体的基本逻辑，你可以看下。</p><pre><code class=\"language-plain\">while(freshnodes &gt; 0 &amp;&amp; gossipcount &lt; wanted &amp;&amp; maxiterations--) {\n&nbsp;&nbsp; dictEntry *de = dictGetRandomKey(server.cluster-&gt;nodes);\n&nbsp;&nbsp; clusterNode *this = dictGetVal(de);\n&nbsp;&nbsp; …\n&nbsp;&nbsp; clusterSetGossipEntry(hdr,gossipcount,this); //调用clusterSetGossipEntry设置Ping消息体\n&nbsp;&nbsp; freshnodes--;\n&nbsp;&nbsp; gossipcount++;\n}\n</code></pre><p>这里，你需要注意的是，对可能有故障的节点，clusterSendPing函数会将它们的信息放在Ping消息体的最后。</p><p></p><p><strong>第三步，发送Ping消息</strong></p><p>好了，到这里，Ping消息体的构建就完成了。那么，clusterSendPing函数主体逻辑的最后一步就是调用clusterSendMessage函数，将Ping消息发送给随机选出的目标节点。这样一来，Gossip协议要求的，向随机选出的节点发送当前节点信息的操作就完成了。</p><p></p><p>我画了下面的这张图，展示了clusterSendPing函数的主体逻辑，你可以再回顾下。</p><p><img src=\"https://static001.geekbang.org/resource/image/e4/da/e4fd8037321e805027d604ee130c70da.jpg?wh=1920x1080\" alt=\"图片\"></p><p>接下来，我们再来看下当节点收到Ping消息后的处理，也就是Pong消息的发送。</p><p></p><h3>Ping消息的处理和Pong消息的回复</h3><p>在刚才介绍的clusterCron函数中，节点在调用clusterSendPing函数向其他节点发送Ping消息前，会检查它和其他节点连接情况，如果连接断开了，节点会重新建立连接，如下所示：</p><pre><code class=\"language-plain\">void clusterCron(void) {\n…\ndi = dictGetSafeIterator(server.cluster-&gt;nodes);\nwhile((de = dictNext(di)) != NULL) {\n&nbsp;&nbsp; clusterNode *node = dictGetVal(de);\n&nbsp;&nbsp; …\n&nbsp;&nbsp; if (node-&gt;link == NULL) {\n&nbsp;&nbsp; &nbsp;…\n&nbsp;&nbsp;&nbsp; fd = anetTcpNonBlockBindConnect(server.neterr, node-&gt;ip,&nbsp;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; node-&gt;cport, NET_FIRST_BIND_ADDR);\n\t…\n\tlink = createClusterLink(node);\n\tlink-&gt;fd = fd;\n\tnode-&gt;link = link;\n\taeCreateFileEvent(server.el,link-&gt;fd,AE_READABLE, clusterReadHandler,link);\n\t…\n\t}\n\t…\n}\n…\n}\n</code></pre><p>从代码中，我们可以看到，一个节点在和其他节点建立的连接上，设置的<strong>监听函数是clusterReadHandler</strong>。所以，当一个节点收到Ping消息时，它就会在clusterReadHandler函数中进行处理，我们来看下这个函数。</p><p>clusterReadHandler函数执行一个while(1)循环，并在这个循环中读取收到的消息，当读到一个完整的消息后，它会调用<strong>clusterProcessPacket函数</strong>处理这个消息，如下所示：</p><pre><code class=\"language-plain\">void clusterReadHandler(aeEventLoop *el, int fd, void *privdata, int mask) {\n…\nwhile(1) { //持续读取收到的数据\n&nbsp;&nbsp; rcvbuflen = sdslen(link-&gt;rcvbuf);\n&nbsp;&nbsp; …\n&nbsp;&nbsp; nread = read(fd,buf,readlen); //读取收到的数据\n&nbsp;&nbsp; …\n&nbsp;&nbsp; //读取到一个完整的消息\n&nbsp;&nbsp; if (rcvbuflen &gt;= 8 &amp;&amp; rcvbuflen == ntohl(hdr-&gt;totlen)) {\n&nbsp;&nbsp; if (clusterProcessPacket(link)) { …} //调用clusterProcessPacket函数处理消息\n&nbsp;&nbsp; …\n}\n}\n</code></pre><p>因为节点间发送的消息类型不止Ping消息，所以clusterProcessPacket函数会先从收到的消息头中读取消息类型，然后根据不同的消息类型，执行不同的代码分支。</p><p></p><p>当收到的是Ping消息时，clusterProcessPacket函数会先调用clusterSendPing函数，向Ping消息发送节点返回Pong消息，如下所示：</p><pre><code class=\"language-plain\">int clusterProcessPacket(clusterLink *link) {\n&nbsp;&nbsp; …\n&nbsp;&nbsp; if (type == CLUSTERMSG_TYPE_PING || type == CLUSTERMSG_TYPE_MEET) {\n&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;… //处理Meet消息，将发送Meet消息的节点加入本地记录的节点列表中\n&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;clusterSendPing(link,CLUSTERMSG_TYPE_PONG); //调用clusterSendPing函数返回Pong消息。\n&nbsp;&nbsp; }\n&nbsp;&nbsp; …\n}\n</code></pre><p>从这里你可以看到，<strong>Ping和Pong消息使用的是同一个函数clusterSendPing来生成和发送的，所以它们包含的内容也是相同的</strong>。这也就是说，Pong消息中也包含了Pong消息发送节点的信息和它已知的其他节点信息。因此，Ping消息的发送节点从Pong消息中，也能获取其他节点的最新信息，这就能实现Gossip协议通过多轮消息传播，达到每个节点拥有一致信息的目的。</p><p>这里，你还需要注意的是，无论是Ping消息的目标节点收到Ping消息，还是发送Ping消息的节点收到目标节点返回的Pong消息，它们都会<strong>在clusterProcessPacket函数的同一个代码分支中进行处理</strong>，比如更新最新Pong消息的返回时间，根据消息头中的slots分布信息更新本地的slots信息。此外，clusterProcessPacket函数还会调用<strong>clusterProcessGossipSection函数</strong>，依次处理Ping-Pong消息中包含的多个消息体。</p><p></p><p>这样一来，收到Ping或Pong消息的节点，就可以根据消息体中的信息，更新本地记录的对应节点的信息了。你可以进一步阅读clusterProcessGossipSection函数源码，了解它根据消息体内容对本地记录的节点信息的更新设置。</p><p></p><p>下面的代码就展示了节点收到Ping-Pong消息后，对本地信息进行更新的代码分支，你可以看下。</p><pre><code class=\"language-plain\">int clusterProcessPacket(clusterLink *link) {\n&nbsp;&nbsp; …\n&nbsp;&nbsp; if (type == CLUSTERMSG_TYPE_PING || type == CLUSTERMSG_TYPE_PONG ||\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; type == CLUSTERMSG_TYPE_MEET)\n\t{\n\t&nbsp;&nbsp; …\n\t&nbsp;&nbsp; //当收到Pong消息时，更新本地记录的目标节点Pong消息最新返回时间\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (link-&gt;node &amp;&amp; type == CLUSTERMSG_TYPE_PONG) {\n&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;link-&gt;node-&gt;pong_received = mstime();\n&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;…\n\t}\n\t…//如果发送消息的节点是主节点，更新本地记录的slots分布信息\n\t//调用clusterProcessGossipSection函数处理Ping或Pong消息的消息体\n\tif (sender) clusterProcessGossipSection(hdr,link);\n\t}\n\t…\n}\n</code></pre><p>好了，到这里，我们就了解了按照Gossip协议发送的Ping、Pong消息的整体处理过程。从中，我们也看到了Redis实现Gossip协议用到的数据结构和主要函数，我画了两张表，分别汇总了刚才介绍的数据结构和函数，你可以再回顾下。</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/98/4b/9828680d9e8fe70c3af6e7b02484304b.jpg?wh=1920x778\" alt=\"图片\"><img src=\"https://static001.geekbang.org/resource/image/eb/20/ebfa014888404b1a0f087a43e0e61820.jpg?wh=1920x1080\" alt=\"图片\"></p><h2>小结</h2><p>今天这节课，我给你介绍了Redis Cluster使用的Gossip协议的设计和实现。Gossip协议实现的关键有两个，<strong>一个是要通过Ping-Pong消息发送节点自身的信息，以及节点已知的其他节点的信息</strong>。针对这一点，Redis是设计了clusterMsg结构的消息，其中消息头包含了发送消息节点自身的信息，比如名称、IP、端口号、slots分布等。</p><p>而clusterMsg结构中的消息体，是设计使用了<strong>clusterMsgDataGossip</strong>类型的数组，这个数组的每一个元素对应了发送消息节点已知的一个节点的信息。这样一来，发送消息节点通过Ping消息可以把自己的信息和已知的其他节点信息传播出去。</p><p>同样的，收到Ping消息的节点，也会使用同样结构的Pong消息将自己的信息和它已知的其他节点信息返回给发送节点。这样一来，就能实现Gossip协议的要求。</p><p></p><p><strong>Gossip协议实现的另一个关键就是要随机选择节点发送</strong>，这一点，Redis Cluster在源码中就比较容易实现了。其实，就是clusterCron函数先通过随机选择五个节点，然后，再在其中挑选和当前节点最长时间没有发送Pong消息的节点，作为目标节点，这样一来，也满足了Gossip协议的要求。</p><p></p><p>通过今天这节课的学习，我希望你能了解Redis Cluster设计的消息结构、周期发送Ping和Pong消息的整体执行逻辑。这些都是你可以用在自行开发Gossip协议时的经典参考设计。</p><p></p><p></p><h2>每课一问</h2><p>在今天课程介绍的源码中，你知道为什么clusterSendPing函数计算wanted值时，是用的集群节点个数的十分之一吗？</p>","neighbors":{"left":{"article_title":"用户故事 | 曾轼麟：世上无难事，只怕有心人","id":423423},"right":{"article_title":"27 | 从MOVED、ASK看集群节点如何处理命令？","id":425404}}},{"article_id":425404,"article_title":"27 | 从MOVED、ASK看集群节点如何处理命令？","article_content":"<p>你好，我是蒋德钧。</p><p></p><p>在上节课一开始我给你介绍了，我们在Redis Cluster这个模块中会学习三部分内容：节点间如何传递信息和运行状态、节点如何处理命令，以及数据如何在节点间迁移。那么通过上节课的学习，现在我们已经了解了Gossip协议的基本实现，也就是支持集群节点间信息和运行状态传递的数据结构、关键函数设计与实现。</p><p>所以在今天这节课，我们就来了解下集群命令处理的实现。这部分内容不仅包括了集群节点处理一个命令的基本流程，更重要的是，我们可以掌握集群特定命令MOVED、ASK是如何实现的。这两个命令对应了Redis Cluster中请求重定向的处理场景，了解了这部分内容之后，我们就可以参考Redis Cluster，来设计和实现分布式系统中的请求重定向。</p><p></p><p>接下来，我们先来看下集群节点处理一个命令的基本流程，这可以让我们对集群节点的实现有个整体观。</p><p></p><h2>集群节点处理命令的基本流程</h2><p>我在<a href=\"https://time.geekbang.org/column/article/411558\">第14讲</a>中提到过，Redis server处理一条命令的过程可以分成四个阶段，分别是<strong>命令读取、命令解析、命令执行和结果返回</strong>。而和单个Redis server一样，Redis Cluster中的节点，也是按照相同的阶段来处理命令的。</p><p>因此，集群节点在各阶段处理命令的入口函数和单个Redis server也是一样的，如下图所示。你也可以再去回顾下第14讲中，我介绍的命令处理详细流程。</p><!-- [[[read_end]]] --><p><img src=\"https://static001.geekbang.org/resource/image/53/b6/53b6b983f429fa7d298546dbc217d9b6.jpg?wh=1920x1080\" alt=\"图片\"></p><p>但是，在其中的命令执行阶段，如果Redis server是一个集群节点，那么在命令执行的过程中，就会增加额外的处理流程，而这个流程正对应了Redis Cluster中可能遇到的请求重定向问题。</p><p></p><p>这里所说的<strong>请求重定向</strong>，是指客户端给一个集群节点发送命令后，节点发现客户端请求的数据并不在本地。因此，节点需要让客户端的请求，重新定向发给实际拥有数据的节点，这样客户端的命令才能正常执行。</p><p></p><p>而你需要注意，请求重定向其实是分布式系统设计过程中需要面对的一个常见问题。尤其对于像Redis Cluster这样，没有使用中心化的第三方系统来维护数据分布的分布式系统来说，<strong>当集群由于负载均衡或是节点故障而导致数据迁移时，请求重定向是不可避免的</strong>。所以，了解这个设计环节，对于你开发分布式系统同样具有重要的参考价值。</p><p></p><p>那么，下面我们就先来看下在命令执行阶段中，针对集群节点增加的处理流程，这是在processCommand函数（在server.c文件）中实现的。</p><p></p><p>processCommand函数在执行过程中，会判断当前节点是否处于集群模式，这是通过全局变量server的<strong>cluster_enable标记</strong>来判断的。如果当前节点处于集群模式，processCommand函数会判断是否需要执行重定向。</p><p></p><p>当然，如果当前节点收到的命令来自于它在集群中的主节点，或者它收到的命令并没有带key参数，那么在这些情况下，集群节点并不会涉及重定向请求的操作。不过，这里有一个不带key参数的命令是一个例外，就是<strong>EXEC命令</strong>。如果当前节点收到EXEC命令，processCommand函数仍然会判断是否要进行请求重定向。</p><p></p><p>那么，processCommand函数具体是如何判断是否要执行请求重定向的呢？</p><p></p><p>其实，它是调用了<strong>getNodeByQuery函数</strong>（在<a href=\"https://github.com/redis/redis/tree/5.0/src/cluster.c\">cluster.c</a>文件中），来查询当前收到的命令能在哪个集群节点上进行处理。如果getNodeByQuery函数返回的结果是空，或者查询到的集群节点不是当前节点，那么，processCommand函数就会调用clusterRedirectClient函数（在cluster.c文件中），来实际执行请求重定向。</p><p></p><p>下面的代码展示了集群节点处理命令过程中针对请求重定向增加的流程，你可以看下。</p><pre><code class=\"language-plain\">int processCommand(client *c) {\n&nbsp;&nbsp; …\n&nbsp;&nbsp; //当前Redis server启用了Redis Cluster模式；收到的命令不是来自于当前借的主节点；收到的命令包含了key参数，或者命令是EXEC\n&nbsp;&nbsp; if (server.cluster_enabled &amp;&amp; !(c-&gt;flags &amp; CLIENT_MASTER)\n\t&amp;&amp; !(c-&gt;flags &amp; CLIENT_LUA &amp;&amp; server.lua_caller-&gt;flags &amp; CLIENT_MASTER)\n\t&amp;&amp; !(c-&gt;cmd-&gt;getkeys_proc == NULL &amp;&amp; c-&gt;cmd-&gt;firstkey == 0 &amp;&amp;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; c-&gt;cmd-&gt;proc != execCommand))\n\t{\n\t&nbsp;&nbsp; …\n\t&nbsp;&nbsp; clusterNode *n = getNodeByQuery(c,c-&gt;cmd,c-&gt;argv,c-&gt;argc, &amp;hashslot,&amp;error_code); //查询当前命令可以被哪个集群节点处理\n\t&nbsp;&nbsp; if (n == NULL || n != server.cluster-&gt;myself) {\n\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; …\n\t&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;clusterRedirectClient(c,n,hashslot,error_code); //实际执行请求重定向\n\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return C_OK;\n\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }\n\t&nbsp;&nbsp;&nbsp; }\n</code></pre><p>当然，如果不需要执行请求重定向，那么processCommand函数会继续执行后续的流程，并调用call函数实际运行命令。</p><p>下图展示了processCommand函数针对集群节点增加的基本执行逻辑，你可以再回顾下。</p><p><img src=\"https://static001.geekbang.org/resource/image/91/7d/91ce0579f5465806b6ed2c95b749c67d.jpg?wh=1920x1080\" alt=\"图片\"></p><p></p><p>好，接下来，我们就来看下getNodeByQuery函数是如何查询能处理一条命令的集群节点的。</p><p></p><h2>如何查询能运行命令的集群节点？</h2><p>首先，我们来看下getNodeByQuery函数的原型，如下所示：</p><pre><code class=\"language-plain\">clusterNode *getNodeByQuery(client *c, struct redisCommand *cmd, robj **argv, int argc, int *hashslot, int *error_code)\n</code></pre><p>它的函数参数包括了节点收到的命令及参数。同时，它的参数中还包括了两个指针：hashslot和error_code，这两个指针分别表示命令访问的key所在的slot（哈希槽），以及函数执行后的错误代码。此外，getNodeByQuery函数的返回值是clusterNode类型，表示的是能处理命令的集群节点。</p><p></p><p>然后，我们来看下getNodeByQuery函数的具体执行过程，这个过程基本可以分成三个步骤来完成。</p><p></p><h3>第一步，使用multiState结构体封装收到的命令</h3><p></p><p>因为集群节点可能收到<strong>MULTI命令</strong>，而MULTI命令表示紧接着它的多条命令是需要作为一个事务来执行的。当Redis server收到客户端发送的MULTI命令后，它会调用MULTI命令的处理函数multiCommand（在<a href=\"https://github.com/redis/redis/tree/5.0/src/multi.c\">multi.c</a>文件中），在表示客户端的结构体变量client中设置<strong>CLIENT_MULTI标记</strong>，如下所示：</p><pre><code class=\"language-plain\">void multiCommand(client *c) {\n&nbsp;&nbsp; …\n&nbsp;&nbsp; c-&gt;flags |= CLIENT_MULTI; //在客户端的标记中设置CLIENT_MULTI\n&nbsp;&nbsp; addReply(c,shared.ok);\n}\n</code></pre><p>而在刚才介绍的命令执行函数processCommand中，它在处理命令时，会判断客户端变量client中是否有CLIENT_MULTI标记。如果有的话，processCommand会调用<strong>queueMultiCommand函数</strong>，把后续收到的命令缓存在client结构体的mstate成员变量中。mstate成员变量的类型是<strong>multiState结构体</strong>，它记录了MULTI命令后的其他命令以及命令个数。</p><p></p><p>下面的代码展示了processCommand函数对CLIENT_MULTI标记的处理，你可以看下。你也可以进一步阅读queueMultiCommand函数（在multi.c文件中）和client结构体（在<a href=\"https://github.com/redis/redis/tree/5.0/src/server.h\">server.h</a>文件中），详细了解MULTI后续命令的记录过程。</p><pre><code class=\"language-plain\">int processCommand(client *c) {\n…\n//客户端有CLIENT_MULTI标记，同时当前命令不是EXEC，DISCARD, MULTI和WATCH\nif (c-&gt;flags &amp; CLIENT_MULTI &amp;&amp;\n&nbsp; c-&gt;cmd-&gt;proc != execCommand &amp;&amp; c-&gt;cmd-&gt;proc != discardCommand &amp;&amp;\n&nbsp; c-&gt;cmd-&gt;proc != multiCommand &amp;&amp; c-&gt;cmd-&gt;proc != watchCommand)\n&nbsp; {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; queueMultiCommand(c); //缓存命令\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; …\n&nbsp; }\n</code></pre><p>其实，刚才介绍的Redis server处理MULTI命令和缓存后续命令的流程，<strong>对于集群节点来说，也是同样适用的</strong>。也就是对于getNodeByQuery函数来说，它在查询命令访问的key时，就需要考虑MULTI命令的情况。</p><p>那么，为了使用同样的数据结构，来处理MULTI命令的后续命令和常规的单条命令，getNodeByQuery函数就使用了multiState结构体，来封装当前要查询的命令，如下所示：</p><pre><code class=\"language-plain\">multiState *ms, _ms; //使用multiState结构体封装要查询的命令\n…\nif (cmd-&gt;proc == execCommand) { //如果收到EXEC命令，那么就要检查MULTI后续命令访问的key情况，所以从客户端变量c中获取mstate\n&nbsp;&nbsp; …\n&nbsp;&nbsp; ms = &amp;c-&gt;mstate;\n} else {\n&nbsp;&nbsp; ms = &amp;_ms;&nbsp; //如果是其他命令，那么也使用multiState结构体封装命令\n&nbsp;&nbsp; _ms.commands = &amp;mc;\n&nbsp;&nbsp; _ms.count = 1;&nbsp; //封装的命令个数为1\n&nbsp;&nbsp; mc.argv = argv; //命令的参数\n&nbsp;&nbsp; mc.argc = argc; //命令的参数个数\n&nbsp;&nbsp; mc.cmd = cmd; //命令本身\n}\n</code></pre><p>这里你需要<strong>注意</strong>，MULTI命令后缓存的其他命令并不会立即执行，而是需要等到EXEC命令执行时才会执行。所以，在刚才的代码中，getNodeByQuery函数也是在收到EXEC命令时，才会从客户端变量c中获取缓存的命令mstate。</p><p>好了，到这里，你就可以看到，getNodeByQuery函数使用multiState结构体，封装了当前的命令。而接下来，它就会检查命令访问的key了。</p><p></p><h3>第二步，针对收到的每个命令，逐一检查这些命令访问的key所在的slots</h3><p></p><p>getNodeByQuery函数会根据multiState结构中记录的命令条数，执行一个循环，逐一检查每条命令访问的key。具体来说，它会调用<strong>getKeysFromCommand函数</strong>（在<a href=\"https://github.com/redis/redis/tree/5.0/src/db.c\">db.c</a>文件中）获取命令中的key位置和key个数。</p><p></p><p>然后，它会针对每个key，调用<strong>keyHashSlot函数</strong>（在cluster.c文件中）查询这个key所在的slot，并在全局变量server的cluster成员变量中，查找这个slot所属的集群节点，如下所示：</p><p></p><pre><code class=\"language-plain\">for (i = 0; i &lt; ms-&gt;count; i++) {\n&nbsp;&nbsp; …\n&nbsp;&nbsp; //获取命令中的key位置和key个数\n&nbsp;&nbsp; keyindex = getKeysFromCommand(mcmd,margv,margc,&amp;numkeys);\n   //针对每个key执行\n&nbsp;&nbsp; for (j = 0; j &lt; numkeys; j++) {\n\t…\n\tint thisslot = keyHashSlot((char*)thiskey-&gt;ptr, //获取key所属的slot&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sdslen(thiskey-&gt;ptr));\n\tif (firstkey == NULL) {\n\t&nbsp;&nbsp; …\n\t&nbsp;&nbsp; slot = thisslot;\n\t&nbsp;&nbsp; n = server.cluster-&gt;slots[slot]; //查找key所属的slot对应的集群节点\n\t}\n\t…\n&nbsp;&nbsp;&nbsp; }\n}\n</code></pre><p>紧接着，getNodeByQuery函数会根据查找的集群节点结果进行判断，主要有以下三种情况。</p><p></p><ul>\n<li>情况一：查找的集群节点为空，此时它会报错，将error_code设置为CLUSTER_REDIR_DOWN_UNBOUND。</li>\n</ul><pre><code class=\"language-plain\">if (n == NULL) {\n&nbsp;&nbsp; …\n&nbsp;&nbsp;&nbsp; if (error_code)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; *error_code = CLUSTER_REDIR_DOWN_UNBOUND;\n&nbsp;&nbsp;&nbsp; return NULL;\n}\n</code></pre><ul>\n<li>情况二：查找的集群节点就是当前节点，而key所属的slot正在<strong>做数据迁出操作</strong>，此时，getNodeByQuery函数会设置变量migrating_slot为1，表示正在做数据迁出。</li>\n</ul><p></p><ul>\n<li>情况三：key所属的slot正在<strong>做数据迁入操作</strong>，此时，getNodeByQuery函数会设置变量importing_slot为1，表示正在做数据迁入。</li>\n</ul><p>情况二和三的代码逻辑如下所示：</p><pre><code class=\"language-plain\">//如果key所属的slot正在迁出，则设置migrating_slot为1\nif (n == myself &amp;&amp; server.cluster-&gt;migrating_slots_to[slot] != NULL)\n{\n   migrating_slot = 1;\n} //如果key所属的slot正在迁入，则设置importing_slot为1\nelse if (server.cluster-&gt;importing_slots_from[slot] != NULL) {\n&nbsp;&nbsp;&nbsp;importing_slot = 1;\n}\n</code></pre><p>这里，你需要注意的是，如果命令包含的key不止1个，而且这些keys不在同一个slot，那么getNodeByQuery函数也会报错，并把error_code设置为CLUSTER_REDIR_CROSS_SLOT。</p><p>到这里，getNodeByQuery函数就查找到了命令访问的key所在的slot，以及对应的集群节点。而此时，如果节点正在做数据迁出或迁入，那么，getNodeByQuery函数就会调用<strong>lookupKeyRead函数</strong>（在db.c文件中），检查命令访问的key是否在当前节点的数据库中。如果没有的话，它会用一个变量<strong>missing_keys</strong>，记录缺失的key数量，如下所示：</p><pre><code class=\"language-plain\">//如果key所属slot正在迁出或迁入，并且当前访问的key不在本地数据库，那么增加missing_keys的大小\nif ((migrating_slot || importing_slot) &amp;&amp; lookupKeyRead(&amp;server.db[0],thiskey) == NULL)\n{\n&nbsp;   missing_keys++;\n}\n</code></pre><p>接下来，getNodeByQuery函数就会根据slot的检查情况来返回相应的结果了。</p><h3>第三步，根据slot的检查结果返回hashslot、error_code和相应的集群节点</h3><p>在getNodeByQuery函数的返回结果中，我们可以重点关注以下四种情况。</p><p><strong>情况一</strong>：命令访问key所属的slot没有对应的集群节点，此时，getNodeByQuery函数会返回当前节点。在这种情况下，有可能是集群有故障导致无法查找到slot所对应的节点，而error_code中会有相应的报错信息。</p><pre><code class=\"language-plain\">if (n == NULL) return myself;\n</code></pre><p><strong>情况二</strong>：命令访问key所属的slot正在做数据迁出或迁入，而且当前命令就是用来执行数据迁移的MIGRATE命令，那么，getNodeByQuery函数会返回当前节点，如下所示：</p><pre><code class=\"language-plain\">if ((migrating_slot || importing_slot) &amp;&amp; cmd-&gt;proc == migrateCommand)\n   return myself;\n</code></pre><p><strong>情况三</strong>：命令访问key所属的slot正在做数据迁出，并且命令访问的key在当前节点数据库中缺失了，也就是刚才介绍的missing_keys大于0。此时，getNodeByQuery函数会把error_code设置为CLUSTER_REDIR_ASK，并返回数据迁出的目标节点。</p><pre><code class=\"language-plain\">&nbsp;if (migrating_slot &amp;&amp; missing_keys) {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (error_code) *error_code = CLUSTER_REDIR_ASK;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return server.cluster-&gt;migrating_slots_to[slot];\n\t}\n</code></pre><p><strong>情况四</strong>：命令访问key所属的slot对应的节点不是当前节点，而是其他节点，此时，getNodeByQuery函数会把error_code设置为CLUSTER_REDIR_MOVED，并返回key所属slot对应的实际节点。</p><pre><code class=\"language-plain\">if (n != myself &amp;&amp; error_code) *error_code = CLUSTER_REDIR_MOVED;\n&nbsp;&nbsp;&nbsp; return n;\n</code></pre><p>好了，到这里，我们就了解了getNodeByQuery函数对命令访问key的查询过程了。我画了张图，展示了getNodeByQuery函数基本执行过程，你可以再回顾下。</p><p><img src=\"https://static001.geekbang.org/resource/image/72/65/727022d24a5f15d2fc2f8fa65dbda565.jpg?wh=1920x1080\" alt=\"图片\"></p><p>那么，有了key所属节点的查询结果后，processCommand函数接下来又会如何进行请求重定向呢?</p><p></p><p>实际上，这一步是通过执行请求重定向的函数<strong>clusterRedirectClient</strong>来完成的。</p><h2>请求重定向函数clusterRedirectClient的执行</h2><p>当getNodeByQuery函数查到的集群节点为空或者不是当前节点时，clusterRedirectClient函数就会被调用。</p><p>而clusterRedirectClient函数的逻辑比较简单，它就是<strong>根据getNodeByQuery函数返回的error_code的不同值，执行相应的代码分支</strong>，主要是把key所属slot对应集群节点的情况返回给客户端，从而让客户端根据返回的信息作出相应处理。比如：</p><ul>\n<li>当error_code被设置成<strong>CLUSTER_REDIR_CROSS_SLOT</strong>时，clusterRedirectClient函数就返回给客户端“key不在同一个slot中”的报错信息；</li>\n<li>当error_code被设置成<strong>CLUSTER_REDIR_MOVED</strong>时，clusterRedirectClient函数会返回MOVED命令，并把key所属的slot、slot实际所属的节点IP和端口号，返回给客户端；</li>\n<li>当error_code被设置成<strong>CLUSTER_REDIR_ASK</strong>时，clusterRedirectClient函数会返回ASK命令，并把key所属的slot、slot正在迁往的目标节点IP和端口号，返回给客户端。</li>\n</ul><p></p><p>下面的代码展示了刚才介绍的clusterRedirectClient函数对三种error_code的处理，你可以看下。</p><pre><code class=\"language-plain\">void clusterRedirectClient(client *c, clusterNode *n, int hashslot, int error_code) {\nif (error_code == CLUSTER_REDIR_CROSS_SLOT) {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; addReplySds(c,sdsnew(\"-CROSSSLOT Keys in request don't hash to the same slot\\r\\n\"));\n}\n…\nelse if (error_code == CLUSTER_REDIR_MOVED || error_code == CLUSTER_REDIR_ASK)\n&nbsp;&nbsp;&nbsp; {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; addReplySds(c,sdscatprintf(sdsempty(),\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \"-%s %d %s:%d\\r\\n\",\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(error_code == CLUSTER_REDIR_ASK) ? \"ASK\" : \"MOVED\",\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; hashslot,n-&gt;ip,n-&gt;port));\n\t}\n\t…\n}\n</code></pre><p>这样，集群节点处理收到的命令的过程就结束了。</p><p>最后，我还想提醒你注意一点，就是Redis Cluster的客户端和针对单个Redis server的客户端，在实现上是有差别的。Redis Cluster客户端需要能处理节点返回的报错信息，比如说，如果集群节点返回MOVED命令，客户端就需要根据这个命令，以及其中包含的实际节点IP和端口号，来访问实际有数据的节点。</p><p></p><h2>小结</h2><p>今天这节课，我给你介绍了集群节点对客户端命令的处理过程。和单个Redis server处理命令的过程相似，集群节点也会经历命令读取、解析、执行和返回结果四个阶段，并且集群节点也使用了和单Redis server相同的入口处理函数。</p><p></p><p>不过你要知道的是，Redis Cluster会因为负载均衡或节点故障等原因而执行数据迁移，而这就会导致客户端访问的key并不在接收到命令的集群节点上。因此，集群节点在命令执行函数processCommand中，针对集群模式，就增加了额外的处理逻辑。这主要是包括调用<strong>getNodeByQuery函数</strong>查询访问的key实际所属的节点，以及根据查询结果调用<strong>clusterRedirectClient函数</strong>执行请求重定向。</p><p></p><p>事实上，对于分布式集群来说，Redis Cluster设计实现的请求重定向机制是一个不错的参考示例。其中，MOVED和ASK两种重定向情况，就充分考虑了数据正在迁移的场景，这种设计值得我们学习。而且，getNodeByQuery函数在查询key所属的slot和节点时，也充分考虑了Redis的事务操作，在对命令访问key进行查询时，巧妙地使用了<strong>同一个数据结构multiState</strong>，来封装事务涉及的多条命令和常规的单条命令，增加了代码的复用程度，这一点也非常值得学习。</p><p></p><p>当然，在这节课里我们也多次提到了数据迁移，那么在下节课，我就会给你介绍Redis Cluster中数据迁移的具体实现。</p><p></p><p></p><h2>每课一问</h2><p>processCommand函数在调用完getNodeByQuery函数后，实际调用clusterRedirectClient函数进行请求重定向前，会根据当前命令是否是EXEC，分别调用discardTransaction和flagTransaction两个函数。那么，你能通过阅读源码，知道这里调用discardTransaction和flagTransaction的目的是什么吗?</p><pre><code class=\"language-plain\">int processCommand(client *c) {\n…\nclusterNode *n = getNodeByQuery(c,c-&gt;cmd,c-&gt;argv,c-&gt;argc,\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &amp;hashslot,&amp;error_code);\nif (n == NULL || n != server.cluster-&gt;myself) {\n&nbsp;&nbsp; if (c-&gt;cmd-&gt;proc == execCommand) {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; discardTransaction(c);\n&nbsp;&nbsp; } else {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; flagTransaction (c);\n&nbsp;&nbsp; }\n&nbsp;&nbsp; clusterRedirectClient(c,n,hashslot,error_code);\n&nbsp;&nbsp; return C_OK;\n\t}\n\t…\n\t}\n</code></pre>","neighbors":{"left":{"article_title":"26 | 从Ping-Pong消息学习Gossip协议的实现","id":424827},"right":{"article_title":"28 | Redis Cluster数据迁移会阻塞吗？","id":426420}}},{"article_id":426420,"article_title":"28 | Redis Cluster数据迁移会阻塞吗？","article_content":"<p>你好，我是蒋德钧。</p><p></p><p>上节课，我给你介绍了Redis Cluster节点处理命令的过程。现在你知道，在这个过程中，节点会调用<strong>getNodeByQuery函数</strong>检查访问的key所属的节点，如果收到命令的节点并不是key所属的节点，那么当前节点就会生成CLUSTER_REDIR_MOVED或者CLUSTER_REDIR_ASK的报错信息，并给客户端返回MOVED或ASK命令。</p><p></p><p>其实，这两个报错信息就对应了Redis Cluster的数据迁移。数据迁移是分布式存储集群经常会遇到的一个问题，当集群节点承担的负载压力不均衡时，或者有新节点加入或是已有节点下线时，那么，数据就需要在不同的节点间进行迁移。所以，<strong>如何设计和实现数据迁移也是在集群开发过程中，我们需要考虑的地方。</strong></p><p></p><p>那么今天这节课，我就来介绍下Redis Cluster是如何实现数据迁移的。从源码层面掌握这部分内容，可以帮助你了解数据迁移对集群节点正常处理命令的影响，这样你就可以选择合适时机进行迁移。而且，掌握Redis的数据迁移实现，也能为你自己开发集群提供一个不错的参考示例。</p><p></p><p>好了，接下来，我们就先来看下和数据迁移相关的主要数据结构。这些数据结构比较重要，它们记录了数据迁移的状态信息。</p><!-- [[[read_end]]] --><p></p><h2>记录数据迁移的数据结构</h2><p>首先你要知道，Redis Cluster是先把键值对映射到哈希槽（slots）中，然后通过给不同集群节点分配slots这样的方法，来完成数据在集群节点间的分配的。关于这部分的知识，你也可以去看看第一季的<a href=\"https://time.geekbang.org/column/article/276545\">第9讲</a>。</p><p></p><p>那么，在源码实现层面，Redis Cluster的每个集群节点都对应了一个<strong>clusterNode的结构体</strong>（在<a href=\"https://github.com/redis/redis/tree/5.0/src/cluster.h\">cluster.h</a>文件中）。这个结构体中包含了一个char类型的数组，用来记录当前节点在负责哪些slots。</p><p>这个数组的定义如下所示，它的长度是宏定义CLUSTER_SLOTS除以8，而CLUSTER_SLOTS宏定义的值是16384，表示的是Redis Cluster的slots总个数。这个值除以8之后，就意味着数组每个元素的每一位表示1个slot。如果数组元素某一位的值是1，那么就表明当前节点负责这一位对应的slot。</p><pre><code class=\"language-plain\">typedef struct clusterNode {\n&nbsp;&nbsp; …\n&nbsp;&nbsp; unsigned char slots[CLUSTER_SLOTS/8]\n&nbsp;&nbsp; …\n}\n</code></pre><p>但是，如果只是用clusterNodes中的slots数组，并不能记录数据迁入迁出的情况，所以，Redis Cluster针对整个集群设计了<strong>clusterState结构体</strong>（在cluster.h文件中）。这个结构体中包含了三个clusterNode类型的数组和一个rax类型的字典树。这三个数组的大小，都是集群slots的总个数16384，如下所示：</p><pre><code class=\"language-plain\">typedef struct clusterState {\n   ...&nbsp;&nbsp;&nbsp; \n   clusterNode *migrating_slots_to[CLUSTER_SLOTS];\n&nbsp;&nbsp;&nbsp;clusterNode *importing_slots_from[CLUSTER_SLOTS];\n&nbsp;&nbsp;&nbsp;clusterNode *slots[CLUSTER_SLOTS];\n&nbsp;&nbsp;&nbsp;rax *slots_to_keys;\n   ...\n}\n</code></pre><p>这几个结构主要是被用来记录数据迁入迁出的情况，它们的含义如下。</p><ul>\n<li><strong>migrating_slots_to数组</strong>：表示当前节点负责的slot正在迁往哪个节点。比如，migrating_slots_to[K] = node1，这就表示当前节点负责的slot K，正在迁往node1。</li>\n<li><strong>importing_slots_from数组</strong>：表示当前节点正在从哪个节点迁入某个slot。比如，importing_slots_from[L] = node3，这就表示当前节点正从node3迁入slot L。</li>\n<li><strong>slots数组</strong>：表示16384个slot分别是由哪个节点负责的。比如，slots[M] = node2，这就表示slot M是由node2负责的。</li>\n<li><strong>slots_to_keys字典树</strong>：用来记录slot和key的对应关系，可以通过它快速找到slot上有哪些keys。</li>\n</ul><p></p><p>好了，知道了用来记录数据迁入迁出情况的数据结构之后，我们就来学习数据迁移的具体过程。</p><p></p><h2>数据迁移过程的设计与实现</h2><p>Redis Cluster迁移数据的整个过程可以分成五个大步骤，分别是：</p><ul>\n<li>标记迁入、迁出节点；</li>\n<li>获取迁出的keys；</li>\n<li>源节点实际迁移数据；</li>\n<li>目的节点处理迁移数据；</li>\n<li>标记迁移结果。</li>\n</ul><p></p><p>下面，我们就分别来看下这五个步骤的源码实现。</p><p></p><h3>标记迁入、迁出节点</h3><p>在Redis Cluster中迁移数据时，我们需要先使用CLUSTER SETSLOT命令，在待迁入数据的目的节点上标记待迁出数据的源节点，使用的命令如下所示：</p><pre><code class=\"language-plain\">CLUSTER&nbsp; SETSLOT&nbsp; &lt;slot&gt;&nbsp; IMPORTING&nbsp; &lt;node&gt; //&lt;slot&gt;表示要迁入的哈希槽，&lt;node&gt;表示当前负责&lt;slot&gt;的节点\n</code></pre><p>然后，我们需要使用CLUSTER SETSLOT命令，在待迁出数据的源节点上标记将要迁入数据的目的节点，使用的命令如下所示：</p><pre><code class=\"language-plain\">CLUSTER&nbsp; SETSLOT&nbsp; &lt;slot&gt;&nbsp; MIGRATING&nbsp; &lt;node&gt; //&lt;slot&gt;表示要迁出的哈希槽，&lt;node&gt;表示&lt;slot&gt;要迁往的目的节点\n</code></pre><p>为了便于你理解，我来举个例子。假设slot 3在节点A上，现在我们要把slot 3从节点A上迁移到节点B上，那么，此时节点A就是待迁出数据的源节点，而节点B就是待迁入数据的目的节点。我们要先在节点B上执行如下命令，用来标记源节点。</p><pre><code class=\"language-plain\">CLUSTER&nbsp; SETSLOT&nbsp; slot3&nbsp; IMPORTING&nbsp; nodeA\n</code></pre><p>然后，我们在节点A上执行如下命令，用来标记目的节点。</p><pre><code class=\"language-plain\">CLUSTER&nbsp; SETSLOT&nbsp; slot3&nbsp; MIGRATING&nbsp; nodeB\n</code></pre><p>对于CLUSTER命令来说，它的处理函数是<strong>clusterCommand</strong>（在<a href=\"https://github.com/redis/redis/tree/5.0/src/cluster.c\">cluster.c</a>文件中）。在这个函数中，它会根据CLUSTER命令携带的不同选项，执行不同的代码分支。因此，对于刚才介绍的标记slot迁入、迁出的SETSLOT选项，它们在clusterCommand函数中对应的代码分支如下所示：</p><pre><code class=\"language-plain\">void clusterCommand(client *c) {\n…\n//处理SETSLOT选项\nelse if (!strcasecmp(c-&gt;argv[1]-&gt;ptr,\"setslot\") &amp;&amp; c-&gt;argc &gt;= 4) {\n&nbsp;&nbsp; …\n&nbsp;&nbsp; //处理migrating标记\n&nbsp;&nbsp; if (!strcasecmp(c-&gt;argv[3]-&gt;ptr,\"migrating\") &amp;&amp; c-&gt;argc == 5) {\n\t...\n&nbsp;&nbsp; }//处理importing标记\n&nbsp;&nbsp; else if (!strcasecmp(c-&gt;argv[3]-&gt;ptr,\"importing\") &amp;&amp; c-&gt;argc == 5) {\n\t…\n&nbsp;&nbsp; }\n}\n</code></pre><p>这里，我们来看一下处理migrating和importing标记的具体逻辑。其实，clusterCommand函数对这两个标记的处理逻辑基本都是分成三步。</p><p><strong>第一步</strong>，对于数据迁出来说，该函数会判断迁出的slot是否在当前节点；而对于数据迁入来说，该函数会判断迁入的slot是否在当前节点。如果迁出的slot不在当前节点，或者迁入的slot已在当前节点，那么clusterCommand函数就<strong>返回报错信息</strong>了。这是因为，在这两种情况下节点无法执行slot迁移。</p><p><strong>第二步</strong>，如果迁出的slot在当前节点，或者迁入的slot不在当前节点，那么，clusterCommand函数就会<strong>调用clusterLookupNode函数</strong>（在cluster.c文件中），来查询CLUSTER SETSLOT命令中包含的<node>。这主要是依赖于clusterLookupNode函数根据输入的节点ID，在全局变量server的cluster-&gt;nodes数组中，查找并返回对应节点。</node></p><p><strong>第三步</strong>，clusterCommand函数会把migrating_slots_to数组中迁出slot，或者importing_slots_from数组中迁入slot对应的节点，设置为clusterLookupNode函数查找的结果。</p><p>我也画了两张图，分别展示了clusterCommand函数处理CLUSTER SETSLOT命令的migrating和importing标记的基本逻辑，你可以再看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/f2/f0/f2e684ceb12727da52786f6479390ff0.jpg?wh=1920x1080\" alt=\"图片\" title=\"处理migrating标记\"></p><p><img src=\"https://static001.geekbang.org/resource/image/6a/cc/6af04dbe699ee54b11fe3640a51cb0cc.jpg?wh=1920x1080\" alt=\"图片\" title=\"处理importing标记\"></p><p>这样一来，当在Redis Cluster中标记完迁入和迁出的节点后，我们就可以使用CLUSTER GETKEYSINSLOT命令，来获取要迁出的keys了。下面我们来看下这步操作的实现。</p><h3>获取待迁出的keys</h3><p>我们用来获取待迁出的keys的具体命令如下所示，其中<slot>表示要迁移的slot，而<count>表示要迁移的key的数量。</count></slot></p><pre><code class=\"language-plain\">CLUSTER&nbsp; GETKEYSINSLOT&nbsp; &lt;slot&gt;&nbsp; &lt;count&gt;\n</code></pre><p>因为这里我们用的还是CLUSTER命令，所以，获取待迁出keys的命令处理也还是在<strong>clusterCommand函数</strong>中，对应了GETKEYSINSLOT选项的代码分支，如下所示：</p><pre><code class=\"language-plain\">void clusterCommand(client *c) {\n…\n//处理GETKEYSINSLOT选项\nelse if (!strcasecmp(c-&gt;argv[1]-&gt;ptr,\"getkeysinslot\") &amp;&amp; c-&gt;argc == 4) {...}\n...\n</code></pre><p>这个代码分支的处理逻辑也比较简单，它主要可以分成三步。</p><p><strong>首先</strong>，这个代码分支会<strong>调用getLongLongFromObjectOrReply函数</strong>（在<a href=\"https://github.com/redis/redis/tree/5.0/src/object.c\">object.c</a>文件中），从CLUSTER GETKEYSINSLOT命令中获取<slot>和<count>参数，这里的<count>参数会被赋值给maxkeys变量，如下所示：</count></count></slot></p><pre><code class=\"language-plain\">//解析获取slot参数\nif (getLongLongFromObjectOrReply(c,c-&gt;argv[2],&amp;slot,NULL) != C_OK)\n&nbsp; &nbsp; &nbsp; return;\n//解析获取count参数，赋值给maxkeys\nif (getLongLongFromObjectOrReply(c,c-&gt;argv[3],&amp;maxkeys,NULL)!= C_OK)\n&nbsp; &nbsp; &nbsp; return;\n</code></pre><p><strong>然后</strong>，clusterCommand函数会<strong>调用countKeysInSlot函数</strong>（在<a href=\"https://github.com/redis/redis/tree/5.0/src/db.c\">db.c</a>文件中），获取待迁移slot中实际的key的数量。如果刚才从命令中获取的key的迁移数量maxkeys，大于实际的key数量，那么maxkeys的值会被更新为实际的key数量。紧接着，clusterCommand函数会给这些key分配空间。</p><pre><code class=\"language-plain\">unsigned int keys_in_slot = countKeysInSlot(slot);  //获取迁移slot中实际的key数量\nif (maxkeys &gt; keys_in_slot) maxkeys = keys_in_slot; //如果实际的key数量小于maxkeys，将maxkeys更新为时间的key数量\nkeys = zmalloc(sizeof(robj*)*maxkeys); //给key分配空间\n</code></pre><p><strong>最后</strong>，这个代码分支会<strong>调用getKeysInSlot函数</strong>（在db.c文件中），从迁移slot中获取实际的key，并将这些key返回给客户端，如下所示：</p><pre><code class=\"language-plain\">numkeys = getKeysInSlot(slot, keys, maxkeys); //获取实际的key\naddReplyMultiBulkLen(c,numkeys); //将key返回给客户端\nfor (j = 0; j &lt; numkeys; j++) {\n&nbsp; &nbsp; &nbsp;addReplyBulk(c,keys[j]);\n&nbsp; &nbsp; &nbsp;decrRefCount(keys[j]);\n}\n</code></pre><p>好了，到这里，客户端就通过CLUSTER&nbsp; GETKEYSINSLOT命令，获得了一定数量的要迁移的key。接下来，我们就要开始执行实际的迁移操作了，我们来具体看下。</p><h3>源节点实际迁移数据</h3><p>在实际迁移数据时，我们需要在待迁出数据的源节点上<strong>执行MIGRATE命令</strong>。其实，MIGRATE命令既支持迁移单个key，也支持一次迁移多个key，它们的基本处理流程是相同的，都是在<strong>migrateCommand函数</strong>中实现的。</p><p>这里，我以一次迁移多个key的MIGRATE命令为例，这个命令的选项中包含了目的节点的IP、端口号、数据库编号，以及要迁移的多个key、迁移超时时间，它的格式如下所示：</p><pre><code class=\"language-plain\">MIGRATE host port \"\" dbid timeout [COPY | REPLACE] KEYS key1 key2 ... keyN \n</code></pre><p>从这个命令中，你也可以看到，它还包括了COPY或REPLACE选项，这两个选项的含义如下。</p><ul>\n<li><strong>COPY</strong>：如果目的节点已经存在待迁移的key，则报错；如果目的节点不存在待迁移的key，那么就正常迁移，并在迁移后，删除源节点上的key。</li>\n<li><strong>REPLACE</strong>：无论目的节点是否存在待迁移的key，都会正常执行迁移，并覆盖已经存在的key。</li>\n</ul><p>好，了解了MIGRATE命令的含义后，我们就来看下migrateCommand函数的基本处理流程，这个函数的执行过程主要可以分成四步。</p><p><strong>第一步，命令参数检查</strong></p><p>migrateCommand函数首先会检查MIGRATE命令携带的参数，比如是否有COPY或REPLACE标记、dbid和timeout是否能正常读取等。在这一步，migrateCommand函数如果检查到timeout值小于等于0了，它就会把timeout值设置为1000毫秒，用于迁移过程中的超时判断。</p><p><strong>第二步，读取要迁移的key和value</strong></p><p>检查完命令参数后，migrateCommand函数会分配两个数组ov和kv，它们的初始大小等于MIGRATE命令中要迁移的key的数量。然后，migrateCommand函数会调用lookupKeyRead函数（在db.c文件中），逐一检查要迁移的key是否存在。这是因为有的key在迁移时可能正好过期了，所以就不用迁移这些key了。这一步的最后，migrateCommand函数会根据实际存在的key数量，来设置要迁移的key数量。</p><p>下面的代码展示了这一步的基本逻辑，你可以看下。</p><pre><code class=\"language-plain\">ov = zrealloc(ov,sizeof(robj*)*num_keys);  //分配ov数组，保存要迁移的value\nkv = zrealloc(kv,sizeof(robj*)*num_keys); //分配kv数组，保存要迁移的key\n...\nfor (j = 0; j &lt; num_keys; j++) {\n    //逐一检查要迁移的key是否存在\n   if ((ov[oi] = lookupKeyRead(c-&gt;db,c-&gt;argv[first_key+j])) != NULL) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kv[oi] = c-&gt;argv[first_key+j]; //只记录存在的key\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; oi++;\n&nbsp; &nbsp;}\n}\nnum_keys = oi;  //要迁移的key数量等于实际存在的key数量\n</code></pre><p><strong>第三步，填充迁移用的命令、key和value</strong></p><p>接下来，migrateCommand函数就开始为迁移数据做准备了。这一步骤中的操作主要包括：</p><ul>\n<li>调用migrateGetSocket函数（在cluster.c文件中），和目的节点建立连接；</li>\n<li>调用rioInitWithBuffer函数初始化一块缓冲区，然后调用rioWriteBulkString、rioWriteBulkLongLong等函数（在<a href=\"https://github.com/redis/redis/tree/5.0/src/rio.c\">rio.c</a>文件中），往这个缓冲区中填充要发送给目的节点的命令、key和value。</li>\n</ul><p>下面的代码也展示了在这一步中主要填充的命令、key和value，你可以看下。</p><pre><code class=\"language-plain\">rioInitWithBuffer(&amp;cmd,sdsempty()); //初始化buffer\n...  //往buffer中填充SELECT命令\n//针对每一个要迁移的key，往buffer中填充命令、key和value\nfor (j = 0; j &lt; num_keys; j++) {\n    //在集群模式下，填充RESTORE-ASKING命令，用来发给目的节点\n   if (server.cluster_enabled)\n      serverAssertWithInfo(c,NULL, rioWriteBulkString(&amp;cmd,\"RESTORE-ASKING\",14));\n   ...\n   //填充key\n   serverAssertWithInfo(c,NULL,rioWriteBulkString(&amp;cmd,kv[j]-&gt;ptr,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sdslen(kv[j]-&gt;ptr)));\n   //填充TTL\n&nbsp; &nbsp;serverAssertWithInfo(c,NULL,rioWriteBulkLongLong(&amp;cmd,ttl));\n   //调用createDumpPayload函数序列化value\n   createDumpPayload(&amp;payload,ov[j],kv[j]);\n   //填充value\n&nbsp;  serverAssertWithInfo(c,NULL, rioWriteBulkString(&amp;cmd,payload.io.buffer.ptr,\n   ...\n}\n</code></pre><p>这里，你需要注意的是，migrateCommand函数会调用createDumpPayload函数（在cluster.c文件中）将迁移key的value序列化，以便于传输。在序列化的结果中，<strong>createDumpPayload函数会增加RDB版本号和CRC校验和</strong>。等目的节点收到迁移数据后，也会检查这两部分内容，我稍后还会给你介绍。<br>\n当在缓冲区中填充完要发送给目的节点的命令、key和value后，migrateCommand函数就开始发送这个缓冲区中的内容了。</p><p><strong>第四步，发送迁移用的命令和数据，并读取返回结果</strong></p><p>migrateCommand函数会调用syncWrite函数（在<a href=\"https://github.com/redis/redis/tree/5.0/src/syncio.c\">syncio.c</a>文件中），把缓冲区中的内容按照64KB的粒度发送给目的节点，如下所示：</p><pre><code class=\"language-plain\">while ((towrite = sdslen(buf)-pos) &gt; 0) {\n   towrite = (towrite &gt; (64*1024) ? (64*1024) : towrite);\n&nbsp; &nbsp;nwritten = syncWrite(cs-&gt;fd,buf+pos,towrite,timeout);\n&nbsp; &nbsp;...\n&nbsp; &nbsp;pos += nwritten;\n}\n</code></pre><p>然后，针对发送给目的节点的每个键值对，migrateCommand函数会调用syncReadLine函数（在syncio.c文件中），读取目的节点的返回结果。如果返回结果中有报错信息，那么它就会进行相应的处理。这部分的逻辑并不复杂，但是针对各种出错情况的处理会比较多，你可以进一步阅读源码来进行学习。</p><pre><code class=\"language-plain\">//针对迁移的每个键值对，调用syncReadLine函数读取目的节点返回结果\nfor (j = 0; j &lt; num_keys; j++) {\n   if (syncReadLine(cs-&gt;fd, buf2, sizeof(buf2), timeout) &lt;= 0) { ...}\n   ... //处理目的节点返回的结果\n}\n</code></pre><p>好了，到这里，你就了解了MIGRATE命令的执行基本过程，我把它执行过程的四大步骤也画在了下面的这张图中，你可以再回顾下。</p><p><img src=\"https://static001.geekbang.org/resource/image/61/ec/61caafdf1f4d5a5f6432b9182e549dec.jpg?wh=1920x1080\" alt=\"图片\"></p><p>其实在迁移数据的过程中，<strong>目的节点对迁移命令的处理也是迁移过程的一个重要环节</strong>。所以，下面我们就来看下，目的节点在收到RESTORE-ASKING命令后的处理过程。</p><h3>目的节点处理迁移数据</h3><p>目的节点在收到源节点发送的RESTORE-ASKING命令后，这个命令的实际处理函数是<strong>restoreCommand</strong>（在cluster.c文件中）。这个函数的处理逻辑并不复杂，主要可以分成三步。</p><p><strong>首先</strong>，它会解析收到的命令参数，包括是否覆盖数据的标记replace、key过期时间标记ttl、key的LRU标记idletime、key的LFU标记freq。接着，它就会根据这些标记执行一系列检查。</p><p>这其中就包括，如果检测到没有replace标记的话，它会调用lookupKeyWrite函数（在db.c文件中），检查目的节点数据库中是否有迁移的key，如果已经存在待迁移key的话，它就会返回报错信息，如下所示。此外，它还会检查TTL值是否小于0。</p><pre><code class=\"language-plain\">//如果没有replace标记，并且数据库中存在待迁移的key&nbsp;\nif (!replace &amp;&amp; lookupKeyWrite(c-&gt;db,c-&gt;argv[1]) != NULL) {\n&nbsp; &nbsp; &nbsp; &nbsp; addReply(c,shared.busykeyerr); //返回报错信息\n&nbsp; &nbsp; &nbsp; &nbsp; return;\n&nbsp;}\n</code></pre><p><strong>然后</strong>，restoreCommand函数会检查迁移key的value的序列化结果，就像我刚才介绍的，migrateCommand函数在实际迁移value时，会把value序列化后再传输。而序列化后的结果中包含了RDB版本和CRC校验和，restoreCommand函数会<strong>调用verifyDumpPayload函数</strong>（在cluster.c文件中），检测RDB版本和CRC校验和。如果这两部分内容不正确，它就会返回报错信息。</p><pre><code class=\"language-plain\">//检查value序列化结果中的RDB版本和CRC校验和\nif (verifyDumpPayload(c-&gt;argv[3]-&gt;ptr,sdslen(c-&gt;argv[3]-&gt;ptr)) == C_ERR)\n{\n&nbsp; &nbsp; &nbsp; &nbsp; addReplyError(c,\"DUMP payload version or checksum are wrong\");\n&nbsp; &nbsp; &nbsp; &nbsp; return;\n}\n</code></pre><p>紧接着，restoreCommand函数会调用rdbLoadObjectType函数和rdbLoadObject函数（在<a href=\"https://github.com/redis/redis/tree/5.0/src/rdb.c\">rdb.c</a>文件中），从序列化结果中解析出实际的value类型和value实际值。</p><p><strong>最后</strong>，restoreCommand函数会调用dbAdd函数，把解析得到key和value写入目的节点的数据库中。这里，你要注意的是，<strong>如果迁移命令中带有REPLACE标记</strong>，那么，restoreCommand函数会先调用dbDelete函数，删除在目的节点数据库中已经存在的迁移key，然后再调用dbAdd函数写入迁移key。此外，restoreCommand函数还会设置迁移key的过期时间，以及LRU或LFU信息，并最终返回成功信息。</p><p>下面的代码展示了restoreCommand函数最后一步的处理逻辑，你可以看下。</p><pre><code class=\"language-plain\">//如果有REPLACE标记，在目的节点数据库中删除已存在的迁移key\nif (replace) dbDelete(c-&gt;db,c-&gt;argv[1]);\n\n//将迁移key及value写入目的节点数据库\ndbAdd(c-&gt;db,c-&gt;argv[1],obj);\nif (ttl) {  //设置TTL时间\n&nbsp; &nbsp; &nbsp; &nbsp; if (!absttl) ttl+=mstime();\n&nbsp; &nbsp; &nbsp; &nbsp; setExpire(c,c-&gt;db,c-&gt;argv[1],ttl);\n}\nobjectSetLRUOrLFU(obj,lfu_freq,lru_idle,lru_clock); //设置LRU或LFU信息\n...\naddReply(c,shared.ok);  //返回成功信息\n</code></pre><p>我在这里也画了一张图，展示了目的节点处理迁移数据的基本过程，你可以再整体看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/19/2a/198d0629f86c440d9afee8678302252a.jpg?wh=1920x1080\" alt=\"图片\"></p><p>好了，到这里，你就了解了源节点发送迁移数据，以及目的节点接收迁移数据的基本过程实现了。最后，当迁移slot中的key全部完成迁移后，我们还需要执行CLUSTER SETSLOT命令，来标记迁移的最终结果，下面我们来看下。</p><h3>标记迁移结果</h3><p>在数据迁移完成后，我们需要先在目的节点上<strong>执行CLUSTER SETSLOT命令</strong>，向目的节点标记迁移slot的最终所属节点，如下所示。然后，我们需要在源节点上执行相同的命令，用来向源节点标记迁移slot的最终所属节点。</p><pre><code class=\"language-plain\">CLUSTER SETSLOT &lt;slot&gt; NODE &lt;node&gt;\n</code></pre><p>因为这个命令还是CLUSTER命令，所以它的处理仍然在<strong>clusterCommand函数</strong>中实现的。这个命令的选项是SETSLOT，并带有NODE标记，所以它对应的代码分支如下所示：</p><pre><code class=\"language-plain\">void clusterCommand(client *c) {\n   ... \n   //处理SETSLOT选项\n   else if (!strcasecmp(c-&gt;argv[1]-&gt;ptr,\"setslot\") &amp;&amp; c-&gt;argc &gt;= 4) {\n      ...\n      //处理NODE标记\n      else if (!strcasecmp(c-&gt;argv[3]-&gt;ptr,\"node\") &amp;&amp; c-&gt;argc == 5) { ...}\n      ...\n   }\n   ...\n}\n</code></pre><p>在刚才介绍的处理NODE标记的代码分支中，主要的工作是清除节点上migrating_slots_to数组和importing_slots_from数组中的标记。</p><p><strong>对于migrating_slots_to数组来说</strong>，在源节点上，这个数组中迁移slot所对应的元素，记录了目的节点。那么，在源节点上执行迁移结果标记命令时，处理NODE标记的代码分支，就会调用<strong>countKeysInSlot函数</strong>（在db.c文件中）检查迁移slot中是否还有key。如果没有key了，那么migrating_slots_to数组中迁移slot所对应的元素会被置为NULL，也就是取消了源节点上的迁出标记。</p><pre><code class=\"language-plain\">if (countKeysInSlot(slot) == 0 &amp;&amp; server.cluster-&gt;migrating_slots_to[slot]) //如果有迁出标记， 并且迁移slot中已经没有key\n&nbsp; &nbsp; server.cluster-&gt;migrating_slots_to[slot] = NULL; //将迁出标记置为NULL\n</code></pre><p><strong>而对于importing_slots_from数组来说</strong>，在目的节点上，这个数组中迁移slot所对应的元素记录了源节点。那么，在目的节点上执行迁移结果标记命令时，处理NODE标记的代码分支会<strong>检查命令参数中的<node>是否就是目的节点自身</node></strong>。如果是的话，importing_slots_from数组中迁移slot所对应的元素会被置为NULL，这就是取消了目的节点上的迁入标记。</p><pre><code class=\"language-plain\">//如果命令参数中的节点是当前节点，并且有迁入标记\n&nbsp;if (n == myself &amp;&amp; server.cluster-&gt;importing_slots_from[slot]) {\n    ...\n   server.cluster-&gt;importing_slots_from[slot] = NULL; //取消迁入标记\n}\n</code></pre><p>最后，处理NODE标记的代码分支，会调用clusterDelSlot和clusterAddSlot函数（在cluster.c文件中），分别更新slot迁移前和迁移后所属节点的slots数组，你可以去进一步阅读这两个函数的代码进行了解。</p><p>到这里，Redis Cluster中数据迁移的整个过程也就完成了。</p><h2>小结</h2><p>在今天的课程中，我给你介绍了Redis Cluster数据迁移过程的代码实现，你要掌握以下两个要点。</p><p><strong>首先是记录集群状态的数据结构clusterState。</strong>这个结构中是使用了migrating_slots_to和importing_slots_from两个数组，来记录数据迁出迁入情况，使用了slots数组记录每个slot所属的节点，以及使用slots_to_keys字典树记录slots中的keys。你需要掌握这几个数据结构的含义，因为在你阅读集群源码时，这几个结构是会频繁使用到的。</p><p><strong>然后是数据迁移过程的五大步骤。</strong>分别是：</p><ul>\n<li>标记迁入、迁出节点；</li>\n<li>获取待迁出的keys；</li>\n<li>源节点实际迁移数据；</li>\n<li>目的节点处理迁移数据；</li>\n<li>标记迁移结果。</li>\n</ul><p>这五个步骤对应了CLUSTER命令的不同选项、MIGRATE命令以及RESTORE命令，所以，它们的实现逻辑就主要对应在clusterCommand、migrateCommand和restoreCommand函数中。如果你想了解数据迁移的更多细节，你可以从这几个函数入手进一步学习。</p><p>最后，我也想再<strong>提醒你两个关键点</strong>。</p><p>一是，Redis Cluster在执行数据迁移时，会调用syncWrite和syncReadLine函数，向目的节点同步发送迁移数据，以及同步读取回复结果。而这个同步写和同步读的过程，会阻塞源节点正常处理请求。所以，你在迁移数据时要<strong>控制迁移的key数量和key大小</strong>，避免一次性迁移过多的key或是过大的key，而导致Redis阻塞。</p><p>二是，我们在实际应用中，会用到<strong>redis-cli工具</strong>，或者是Ruby开发的Redis Cluster集群<strong>运维工具redis-trib</strong>，来执行数据迁移。这些工具最终也会调用这节课中，我们介绍的命令来完成数据的实际迁移。所以，学习今天课程的内容，对于你在实际应用中，从代码层面排查redis-cli、redis-trib这些工具的问题也是有所帮助的。</p><p></p><h2>每课一问</h2><p>在维护Redis Cluster集群状态的数据结构clusterState中，有一个字典树slots_to_keys。当在数据库中插入key时它会被更新，你能在Redis源码文件db.c中，找到更新slots_to_keys字典树的相关函数调用吗？</p>","neighbors":{"left":{"article_title":"27 | 从MOVED、ASK看集群节点如何处理命令？","id":425404},"right":{"article_title":"29 | 如何正确实现循环缓冲区？","id":427126}}},{"article_id":427126,"article_title":"29 | 如何正确实现循环缓冲区？","article_content":"<p>你好，我是蒋德钧。</p><p></p><p>从今天开始，我们就进入了这门课程的最后一个模块，也就是“编程技巧模块”。Redis作为一个广泛使用的系统，除了它自身的功能实现和性能优化值得我们学习以外，它源码中的编程技巧也同样值得我们去了解和掌握。</p><p></p><p>在这个模块中，我会带你学习Redis在循环缓冲区、监控、功能扩展模块等方面的设计与实现，这些功能的开发对于后端系统软件来说都是非常重要的。</p><p></p><p>那么，今天这节课，我先带你来学习<strong>Redis中循环缓冲区的实现</strong>。</p><p>我们在开发后端数据系统时，都会面临数据同步的问题，在应对这个问题时，缓冲区的设计与实现是一定要考虑的。而循环缓冲区是缓冲区开发的一个常用技巧，所以，学习这节课的内容，可以让我们掌握如何实现循环缓冲区，尤其是实现难点的解决方法，从而可以给我们自己开发数据同步提供一个参考实现。</p><p></p><p>好了，下面我们先来看下循环缓冲区是如何工作的，有了这部分知识后，我们就能更好地理解和掌握Redis的代码实现了。</p><p></p><h2>循环缓冲区如何工作？</h2><p>在后端数据系统中，为了保证数据的可靠性，我们通常会采用主从集群的方式，在主节点和从节点之间同步数据。一般来说，主节点会先和从节点进行一次全量同步，把某个时刻的所有数据传输给从节点。</p><!-- [[[read_end]]] --><p></p><p>然后，主节点会持续将收到的命令发送给从节点。在这个发送的过程中，如果从节点和主节点网络断连了，主节点需要将发送给从节点的命令缓存起来。这样一来，当从节点恢复和主节点的网络连接后，主节点可以把缓存着的命令再发给从节点。在这种场景下，我们就需要用到缓冲区来暂存主节点收到的命令。</p><p></p><p>那么，在后端系统中设计缓冲区时，直接面临的一个问题就是，<strong>缓冲区空间不够用时该怎么办？</strong></p><p></p><p>我们比较容易想到的实现方案是，当缓冲区不够用时，系统再动态分配缓冲区。但是动态分配缓冲区会<strong>有一定的开销</strong>，而且如果一旦空间不够用了，就动态分配缓冲区，这也会造成缓冲区空间持续增长，<strong>占用过多内存资源</strong>。</p><p></p><p>而实际上，缓冲区中的数据在发送给从节点后，其实可以删除掉，这样就有新空间可以用了。这也就是说，缓冲区空间是可以复用的，如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/27/d9/27278ea3db0f74afb4ca7e576e9837d9.jpg?wh=1920x962\" alt=\"图片\"></p><p>那么，循环缓冲区的实现就是使用了复用缓冲区的设计思想，它的空间可以循环写入。从工作原理来说，它有两个特点：</p><ul>\n<li><strong>循环缓冲区有一个写指针，表示主节点在缓冲区中的当前写入位置。</strong>如果写指针已经指向了缓冲区末尾，那么此时主节点再写入数据，写指针就会重新指向缓冲区头部，从头部开始再次写入数据，这样就可以复用缓冲区空间了。</li>\n<li><strong>循环缓冲区有一个或多个读指针，表示不同从节点在缓冲区中的当前读取位置。</strong>当读指针指向缓冲区末尾时，从节点也会把读指针重新指向缓冲区头部，从缓冲区头部开始继续读取数据。</li>\n</ul><p></p><p>下图展示了循环缓冲区的写指针工作机制，你可以看下，读指针的工作机制和这个也是类似的。</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/d1/78/d1e86c89cb18540e9dae23b6496d6b78.jpg?wh=1920x999\" alt=\"图片\"></p><p></p><p>好了，了解了循环缓冲区的工作原理后，我们就来看下Redis中是如何实现循环缓冲区的。</p><p></p><h2>Redis中如何实现循环缓冲区？</h2><p>在Redis的主从复制代码实现中，循环缓冲区就是被用来暂存主节点收到的命令的。</p><p>不过，在了解它的具体实现前，我们要知道，在Redis主从复制中，主节点会累积记录它收到的要进行复制的命令总长度，这个总长度我们称之为<strong>全局范围内的复制偏移量</strong>（简称全局复制偏移量）。</p><p>在源码中，它对应了全局变量server的master_repl_offset成员变量。而从节点从主节点读取命令时，也会记录它读到的累积命令的位置，这个位置称之为<strong>全局范围内的读取偏移量</strong>（简称全局读取位置）。</p><p>为了便于你理解，我来给你举个例子。假设主节点收到三条命令，每条命令长度都是16字节，那么此时，全局复制偏移量是48。假设一个从节点从主节点上读了一条命令，此时，该从节点的全局读取位置就是16。</p><p>因为全局复制偏移量和全局读取位置在接下来介绍的循环缓冲区实现中会反复用到，所以你要了解它们的含义。</p><p>好了，下面我们来看循环缓冲区本身的数据结构。</p><p></p><h3>循环缓冲区的数据结构和初始化</h3><p>在Redis全局变量server对应的结构体redisServer中，包含了循环缓冲区的数据结构，如下所示：</p><pre><code class=\"language-plain\">struct redisServer {\n…\nchar *repl_backlog;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //基于字符数组的循环缓冲区\nlong long repl_backlog_size;&nbsp;&nbsp;&nbsp; //循环缓冲区总长度\nlong long repl_backlog_histlen; //循环缓冲区中当前累积的数据的长度\nlong long repl_backlog_idx;&nbsp;&nbsp;&nbsp;&nbsp; //循环缓冲区的写指针位置\nlong long repl_backlog_off;&nbsp;&nbsp;&nbsp;//循环缓冲区最早保存的数据的首字节在全局范围内的偏移\n…\n}\n</code></pre><p>从代码中你可以看到，循环缓冲区本身被设计为了一个<strong>字符类型的数组repl_backlog</strong>，然后Redis设计了以下的变量来描述循环缓冲区的状态，包括：</p><ul>\n<li><strong>repl_backlog_size</strong>：这个变量值记录的是循环缓冲区本身的总长度。这个值也对应了redis.conf配置文件中的repl-backlog-size配置项。</li>\n<li><strong>repl_backlog_histlen</strong>：这个变量值记录的是循环缓冲区中目前累积的数据的长度，这个值不会超过缓冲区的总长度。</li>\n<li><strong>repl_backlog_idx</strong>：这个变量值记录的是循环缓冲区接下来写数据时应该写入的位置，而它就对应了刚才向你介绍的循环缓冲区的写指针。</li>\n<li><strong>repl_backlog_off</strong>：这个变量值记录的是循环缓冲区中最早保存的数据的首字节，在全局范围内的偏移值。这里你需要注意的是，因为循环缓冲区会被重复使用，所以一旦缓冲区写满后，又开始从头写数据时，缓冲区中的旧数据会被覆盖。因此，这个值就记录了仍然保存在缓冲区中，又是最早写入的数据的首字节，在全局范围内的偏移量。</li>\n</ul><p></p><p>这几个变量在循环缓冲区的读写过程中会被反复使用，所以你需要掌握它们的含义，这样可以帮助你更好地理解循环缓冲区的实现。</p><p></p><p>接下来，我们来看下循环缓冲区的创建和读写过程。因为循环缓冲区是在主从节点复制过程中使用的，所以，它对应的相关操作函数也是在<a href=\"https://github.com/redis/redis/tree/5.0/src/replication.c\">replication.c</a>文件中实现的。</p><p></p><p>我们先来看下，循环缓冲区的<strong>创建函数createReplicationBacklog</strong>，这个函数的操作逻辑比较简单，就是从配置文件中读取循环缓冲区配置项repl-backlog-size的大小，然后根据这个配置项值给循环缓冲区分配空间。</p><p></p><p>紧接着，这个函数会把repl_backlog_histlen初始化为0，表示当前没有数据写入。同时，把repl_backlog_idx初始化为0，表示当前可以从缓冲区头开始写入数据。此外，createReplicationBacklog函数还会把repl_backlog_off，设置为master_repl_offset加1的值。</p><p></p><p>这部分的初始化代码如下所示：</p><pre><code class=\"language-plain\">void createReplicationBacklog(void) {\n&nbsp;&nbsp;&nbsp; serverAssert(server.repl_backlog == NULL);\n&nbsp;&nbsp;&nbsp; server.repl_backlog = zmalloc(server.repl_backlog_size);\n&nbsp;&nbsp;&nbsp; server.repl_backlog_histlen = 0;\n&nbsp;&nbsp;&nbsp; server.repl_backlog_idx = 0;\n&nbsp;&nbsp;&nbsp; server.repl_backlog_off = server.master_repl_offset+1;\n}\n</code></pre><p>这里你也需要注意的是，Redis是在syncCommand函数中，<strong>调用createReplicationBacklog函数来创建循环缓冲区</strong>的，这部分代码如下所示：</p><pre><code class=\"language-plain\">void syncCommand(client *c) {\n…\nif (listLength(server.slaves) == 1 &amp;&amp; server.repl_backlog == NULL) {\n&nbsp;&nbsp; …\n&nbsp;&nbsp; createReplicationBacklog();\n}\n…}\n</code></pre><p>从代码中，你可以看到，Redis创建循环缓冲区的条件是当前还没有循环缓冲区，以及当前的从节点只有1个。这也就是说，当一个主节点有多个从节点时，这些从节点其实会共享使用一个循环缓冲区，而这样<strong>设计的目的</strong>，主要是避免给每个从节点开辟一块缓冲区，造成内存资源浪费。</p><p>好了，了解了循环缓冲区的数据结构和初始化操作后，我们再来分别看下它的读写操作。</p><p></p><h3>循环缓冲区的写操作</h3><p>我们先来了解循环缓冲区的写操作，这是由<strong>feedReplicationBacklog函数</strong>实现的。这个函数的原型如下所示：</p><pre><code class=\"language-plain\">void feedReplicationBacklog(void *ptr, size_t len)\n</code></pre><p>feedReplicationBacklog函数的参数是一个<strong>指针ptr</strong>，它指向了要写入缓冲区的数据，以及一个<strong>整数len</strong>，它表示要写的数据长度。</p><p></p><p>循环缓冲区的写操作过程可以分成三个步骤。</p><p><strong>第一步</strong>，feedReplicationBacklog函数会更新全局变量server的master_repl_offset值，在当前值的基础上加上要写入的数据长度len，如下所示：</p><pre><code class=\"language-plain\">server.master_repl_offset += len;\n</code></pre><p><strong>第二步</strong>，feedReplicationBacklog函数会根据参数len执行一个循环流程，这个流程会循环执行，直到把要写入的数据都写进循环缓冲区。而这个循环流程执行的操作又可以分成三小步。</p><p></p><ul>\n<li><strong>首先，计算本轮循环能写入的数据长度。</strong></li>\n</ul><p>feedReplicationBacklog函数会计算循环缓冲区当前的剩余空间长度thislen。如果剩余空间长度大于要写入数据的长度，那么，它会把thislen设置为实际要写入的数据长度。这部分代码如下所示：</p><pre><code class=\"language-plain\">while(len) {\n&nbsp;&nbsp;size_t thislen = server.repl_backlog_size - server.repl_backlog_idx;\n&nbsp;&nbsp;if (thislen &gt; len) thislen = len;\n&nbsp;&nbsp; …\n}\n</code></pre><ul>\n<li><strong>其次，实际写入数据。</strong></li>\n</ul><p>根据第一步计算得到的thislen变量值，调用memcpy函数，将要写入的数据写到循环缓冲区中，写入的位置是repl_backlog_idx指向的位置，而写入的长度就是thislen。这步操作的代码如下所示：</p><pre><code class=\"language-plain\">memcpy(server.repl_backlog+server.repl_backlog_idx,p,thislen);\n</code></pre><p>结合前两小步的操作，你可以看到，feedReplicationBacklog函数在写入数据时，如果实际写入长度小于缓冲区剩余长度，那么就按实际写入长度写数据。否则，它就按剩余空间长度写入数据。这也就是说，feedReplicationBacklog函数每一轮都会尽量多写数据，不过每轮循环最多写入的数据长度也就是缓冲区的总长度。</p><p></p><p>好了，到这里，循环缓冲区中就写入了一次数据，接下来就是这轮循环中的最后第三小步。</p><ul>\n<li><strong>最后，更新循环缓冲区等状态信息。</strong></li>\n</ul><p></p><p>feedReplicationBacklog函数在每轮循环的最后，会更新循环缓冲区的状态信息，包括</p><p>repl_backlog_idx和repl_backlog_histlen。</p><p>对于repl_backlog_idx来说，它会增加刚才写入的数据长度thislen。不过因为缓冲区总长度repl_backlog_size的大小固定，所以，如果repl_backlog_idx的值等于repl_backlog_size的值了，那么，repl_backlog_idx的值会被置为0。这其实就表明，此时循环缓冲区已经写满了。那么，写指针会指向循环缓冲区的头部，从头开始再次写入。这部分的代码逻辑如下所示：</p><pre><code class=\"language-plain\">while(len) {\n   ...\n  server.repl_backlog_idx += thislen;\n  if (server.repl_backlog_idx == server.repl_backlog_size)\n       server.repl_backlog_idx = 0;\n  ...    \n}\n</code></pre><p>而对于repl_backlog_histlen来说，在每轮循环的最后，它都会加上刚刚写入的数据长度thislen。此外，feedReplicationBacklog函数还会更新待写入数据的剩余长度，以及待写入数据的指针位置。这几步操作的代码如下所示：</p><pre><code class=\"language-plain\">len -= thislen;&nbsp; //更新剩余要写入的数据长度\np += thislen;&nbsp; &nbsp; //更新要写入循环缓冲区的数据指针位置\nserver.repl_backlog_histlen += thislen;&nbsp; //更新repl_backlog_histlen\n</code></pre><p>好了，到这里，feedReplicationBacklog函数就完成了写入数据的一轮循环，那么，等到待写入数据都写完后，循环流程就会结束。</p><p>接下来，就是写操作过程的<strong>第三步</strong>，也是最后一步了。在这一步中，feedReplicationBacklog函数会检查repl_backlog_histlen的值，是否大于循环缓冲区总长度。如果大于的话，它会将repl_backlog_histlen的值设置为循环缓冲区总长度。这也就是说，一旦循环缓冲区被写满后，repl_backlog_histlen的值就会维持在循环缓冲区的总长度。</p><p>紧接着，repl_backlog_off值会被更新为全局复制偏移量，减去repl_backlog_histlen的值，再加1。</p><p>下面的代码展示了第三步的操作，你可以看下。</p><pre><code class=\"language-plain\">//如果repl_backlog_histlen的值大于循环缓冲区总长度，那么将该值设置为循环缓冲区总长度\nif (server.repl_backlog_histlen &gt; server.repl_backlog_size)\n   server.repl_backlog_histlen = server.repl_backlog_size;\nserver.repl_backlog_off = server.master_repl_offset - server.repl_backlog_histlen + 1;\n</code></pre><p>为了便于你理解刚才介绍的循环缓冲区写入过程，这里我也来给你举个例子。下面我会用表格展示数据写入过程中各状态值的变化，并辅以示意图说明。</p><p>首先，我们假设循环缓冲区总长度为8，也就是repl_backlog_size值为8，以及全局复制偏移量master_repl_offset初始值为0（这个值在代码中会随机生成）。按照刚才介绍的循环缓冲区初始化操作，repl_backlog_idx、repl_backlog_histlen的初始值为0，而repl_backlog_off初始值为1，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/99/90/991e1b4c813ca456dd54e16d079d4690.jpg?wh=1920x947\" alt=\"图片\"></p><p>假设第一次写入长度为5的数据“abcde”（len=5），此时，全局复制偏移量等于初始值0加上写入的数据长度5，结果为5，也就是master_repl_offset等于5。</p><p>那么，按照feedReplicationBacklog函数的执行逻辑，循环缓冲区的各状态值如下表所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/de/86/de2b3a9de0e8e8400ae076278d8f6986.jpg?wh=1920x1022\" alt=\"图片\"></p><p>下图也展示了写入长度为5的数据后，循环缓冲区中的内容以及全局范围内两个偏移量的值。</p><p><img src=\"https://static001.geekbang.org/resource/image/29/1b/29f456yy9cc5ddc96f4acf156568fc1b.jpg?wh=1920x912\" alt=\"图片\"></p><p>然后，假设第二次写入长度为16的数据“fghijklmnopqrstu”（len=16），此时，全局复制偏移量等于上一次的值5，加上本次写入的数据长度16，结果为21，也就是master_repl_offset等于21。</p><p>因为缓冲区总长度为8，目前已经写入5个字符，那么要再写入16个字符，按照feedReplicationBacklog函数的执行逻辑，就需要执行一个循环流程来写入数据，而每轮循环写入缓冲区的数据长度是缓冲区当前的剩余长度，最大为缓冲区总长度。</p><p>所以，当要再写入16个字符时，feedReplicationBacklog函数<strong>需要执行三轮循环</strong>，第一轮循环写入3个字符，第二轮循环写入8个字符，第三轮循环写入5个字符。这个写入过程中，循环缓冲区各状态信息如下面的三张表所示，你可以仔细看下。</p><p>第一轮循环写入“fgh”3个字符，缓冲区各状态信息如下表所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/36/d4/36715bcbfd624de950aefcf8ec4dc3d4.jpg?wh=1920x917\" alt=\"图片\"></p><p>此时，循环缓冲区中的内容，以及全局范围内两个偏移量的值，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/53/74/536fe9069dbd07b76b8d36e08f4d8074.jpg?wh=1920x923\" alt=\"图片\"></p><p>紧接着第二轮循环写入“ijklmnop”8个字符，缓冲区各状态信息如下表所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/0b/b1/0b2efc0fcc47f87b7817ebe4bbd452b1.jpg?wh=1920x907\" alt=\"图片\"></p><p>此时，循环缓冲区中的内容，以及全局范围内两个偏移量的值，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/9d/fb/9d298cf61128da29e0690a8c0986b1fb.jpg?wh=1920x916\" alt=\"图片\"></p><p>最后，第三轮循环写入“qrstu”5个字符，缓冲区各状态信息如下表所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/ef/60/ef56d5a6e4c550db7bab20841aaa6f60.jpg?wh=1920x959\" alt=\"图片\"></p><p>三轮循环结束后，因为repl_backlog_histlen已经大于缓冲区总长度了，所以它会被更新为缓冲区总长度8，而repl_backlog_off会被更新为14。此时，循环缓冲区中的内容，以及全局范围内两个偏移量的值，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/a3/4b/a328153f7049c5f20fbfdb2edf77yy4b.jpg?wh=1920x900\" alt=\"图片\"></p><p>好了，到这里，你就了解了循环缓冲区的写入过程。接下来，我们再来看下循环缓冲区的读取过程。</p><h3>循环缓冲区的读操作</h3><p>在Redis中，当从节点和主节点在断连后再次建立连接时，从节点会发送<strong>PSYNC命令</strong>给主节点，而这个命令中就<strong>包含了从节点的全局读取偏移量offset</strong>，如下所示：</p><pre><code class=\"language-plain\">PSYNC &lt;runid&gt; &lt;offset&gt;\n</code></pre><p>主节点收到PSYNC命令后，会在masterTryPartialResynchronization函数中处理这个命令，其中，就包含了<strong>调用addReplyReplicationBacklog函数，读取循环缓冲区中的数据</strong>。所以，我们可以从addReplyReplicationBacklog函数的实现中，了解循环缓冲区的读操作。</p><p>addReplyReplicationBacklog函数的执行逻辑可以分成三步。</p><p><strong>首先</strong>，它会把从节点发送的全局读取位置offset，减去repl_backlog_off的值，从而得到从节点读数据时要跳过的数据长度skip，如下所示：</p><pre><code class=\"language-plain\">skip = offset - server.repl_backlog_off;\n</code></pre><p>就像刚才给你介绍的，repl_backlog_off表示仍在缓冲区中的最早保存的数据的首字节，在全局范围内的偏移量。而从节点的全局读取位置和repl_backlog_off不一定一致，所以两者相减，就是从节点要跳过的数据长度。<br>\n<strong>然后</strong>，addReplyReplicationBacklog函数要计算缓冲区中，最早保存的数据的首字节对应在缓冲区中的位置。这个位置很重要，因为有了它，从节点才能把全局读取位置转换到缓冲区中的读取位置。这个位置的计算代码如下所示：</p><pre><code class=\"language-plain\">j = (server.repl_backlog_idx + (server.repl_backlog_size-server.repl_backlog_histlen)) % server.repl_backlog_size;\n</code></pre><p>其实，这里我们可以分成两种情况来理解这段计算代码。</p><p><strong>一是，缓冲区还没有写满。</strong>此时，repl_backlog_histlen就等于repl_backlog_idx，所以代码的计算相当于repl_backlog_size对它自己取模，结果为0。这也就是说，当缓冲区还没写满时，缓冲区中最早保存的数据的首字节，就是在缓冲区头，这也是因为缓冲区没有被覆盖重写。你可以看看下面的图。</p><p><img src=\"https://static001.geekbang.org/resource/image/3b/5c/3bd9d114a90212050a609271785f7e5c.jpg?wh=1920x616\" alt=\"图片\"></p><p><strong>二是，缓冲区已经写满过，并且已从头再次写入数据。</strong>此时，repl_backlog_histlen就等于缓冲区总长度repl_backlog_size。所以，代码的计算相当于repl_backlog_idx对repl_backlog_size取模，结果就是repl_backlog_idx。</p><p>这也好理解，repl_backlog_idx指向了下一次写入的数据位置，当缓冲区写满过，这个位置上是有数据的，而这个数据正是缓冲区中最早保存数据的首字节。一旦再次写入时，这个位置就会被覆盖重写了，你可以看看下图。</p><p><img src=\"https://static001.geekbang.org/resource/image/fd/7a/fdc78822a1dd8ef05289f164762c097a.jpg?wh=1920x636\" alt=\"图片\"></p><p>当计算得到缓冲区中最早保存数据的首字节，在缓冲区中的对应位置后，addReplyReplicationBacklog函数就会在此基础上，增加从节点要跳过的数据长度，得到一个新的位置值。因为这个位置值可能超越缓冲区长度边界，所以它要对repl_backlog_size取模。这样一来，就得到了从节点的全局读取位置在缓冲区中的对应位置了。</p><pre><code class=\"language-plain\">j = (j + skip) % server.repl_backlog_size;\n</code></pre><p>好了，到这里，我们就已经知道从节点要在缓冲区的哪个位置开始读取数据了。</p><p><strong>最后</strong>，addReplyReplicationBacklog函数会计算实际要读取的数据长度len，这是用缓冲区中数据的实际长度减去要跳过的数据长度，如下所示：</p><pre><code class=\"language-plain\">len = server.repl_backlog_histlen - skip;\n</code></pre><p>紧接着，addReplyReplicationBacklog函数会执行一个循环流程来实际读取数据。之所以要设计一个循环流程来读取数据，是因为在循环缓冲区中，从节点可能从读取起始位置一直读到缓冲区尾后，还没有读完，还要再从缓冲区头继续读取。这就要分成两次来读取了。<br>\n下面的代码展示了这个循环流程。</p><pre><code class=\"language-plain\">while(len) {\n   long long thislen = ((server.repl_backlog_size - j) &lt; len) ?\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (server.repl_backlog_size - j) : len;\n   ...\n   addReplySds(c,sdsnewlen(server.repl_backlog + j, thislen)); //实际读取并返回数据\n&nbsp; &nbsp;len -= thislen;\n&nbsp; &nbsp;j = 0;\n}\n</code></pre><p>你可以看到，当读取起始位置（j）到缓冲区尾（repl_backlog_size）的长度，小于要读取的长度（len），那么就表明从节点还要从头继续读数据。此时，函数就先从读取起始位置一直读到缓冲区末尾（server.repl_backlog_size - j）。</p><p>而当读取起始位置到缓冲区尾的长度（repl_backlog_size-j）大于要读取的长度（len）时，函数就直接读取要读的长度（len）就行。</p><p>在这个过程中，addReplyReplicationBacklog函数会<strong>调用addReplySds函数，来返回读取的数据</strong>。</p><p>好了，到这里，整个循环缓冲区的读写过程就介绍完了。你也可以从这个过程中看到，要理解循环缓冲区的读写，重点是要理解缓冲区长度、下次写入位置、最早保存数据在全局和缓冲区中对应位置，以及从节点全局读取位置对应的缓冲区位置等状态信息的计算。</p><h2>小结</h2><p>今天这节课的内容就到这里，我们来总结下。</p><p></p><p>在今天的课程中，我给你介绍了循环缓冲区的工作原理，以及Redis在主从复制中实现的循环缓冲区。那么从工作原理上来看，循环缓冲区似乎并不复杂，当缓冲区写满后，程序就会重新从头开始写入数据；而当程序已经读到缓冲区尾时，也会继续从头读取数据。</p><p>但是，我也想再提醒你注意下，在实现循环缓冲区时会面临的<strong>两个难点</strong>。</p><p>一是，累积要发送的数据长度可能会大于缓冲区长度，因此旧数据会被覆盖。在写入数据时，我们如何知道，仍在缓冲区中且是最早保存的数据的首字节，在全局范围内对应的位置。而这也是从节点能读取到的最早数据了。Redis源码使用repl_backlog_off变量来记录这个位置，你需要掌握这个值的计算和使用。</p><p>二是，在读取数据时，我们如何知道从节点发送的全局读取位置在循环缓冲区中的对应位置。因为只有有了这个位置的值，程序才能实际从缓冲区中读取数据。Redis源码在addReplyReplicationBacklog函数中，是分两步来计算这个位置值的。</p><p>它先是计算缓冲区中最早保存的数据的首字节，在缓冲区中的位置；然后，它在这个位置的基础上，会加上从节点要跳过的数据长度，这就得到了从节点全局读取位置。在缓冲区中的对应位置了。</p><p>实际上，循环缓冲区在数据同步、收发等场景中使用非常广泛，我希望你能理解和掌握Redis源码对循环缓冲区的实现，尤其是上面这两个难点的实现方法，这样，当你自己实现循环缓冲区时就比较容易了。</p><p></p><h2>每课一问</h2><p>在addReplyReplicationBacklog函数中，它会计算从节点在全局范围内要跳过的数据长度，如下所示：</p><pre><code class=\"language-plain\">skip = offset - server.repl_backlog_off;\n</code></pre><p>然后，它会根据这个跳过长度计算实际要读取的数据长度，如下所示：</p><pre><code class=\"language-plain\">len = server.repl_backlog_histlen - skip;\n</code></pre><p>请你阅读addReplyReplicationBacklog函数和调用它的masterTryPartialResynchronization函数，你觉得这里的skip会大于repl_backlog_histlen吗？</p>","neighbors":{"left":{"article_title":"28 | Redis Cluster数据迁移会阻塞吗？","id":426420},"right":{"article_title":"30 | 如何在系统中实现延迟监控？","id":427537}}},{"article_id":427537,"article_title":"30 | 如何在系统中实现延迟监控？","article_content":"<p>你好，我是蒋德钧。</p><p></p><p>我们知道，Redis的一个显著特征就是<strong>能提供低延迟的数据访问</strong>。而如果Redis在运行过程中变慢了，我们就需要有方法能监控到哪些命令执行变慢了。更进一步的需求，就是我们需要有方法监控到，是Redis运行过程中的哪些事件导致Redis变慢了。这样一来，我们就既可以检查这些慢命令，分析它们的操作类型和访问的数据量，进而提出应对方法，也可以检查监控记录的事件，分析事件发生的原因并提出应对方法。</p><p></p><p>那么，为了满足这些需求，我们就需要有一套监控框架，一方面能监测导致Redis变慢的事件，另一方面，能监控并记录变慢的命令。其实，这也是我们在开发后端系统时，经常会面临的一个运维开发需求，也就是<strong>如何监控后端系统的运行状态</strong>。</p><p></p><p>今天这节课，我就来带你了解Redis的延迟监控框架和慢命令日志的设计与实现。掌握今天的课程内容后，一方面，你可以把这套监控框架应用到实际的业务，而另一方面，你也可以参考Redis的实现，给自己的系统增加延迟监控功能。</p><p></p><p>下面，我们就先来看下Redis实现的延迟监控框架。</p><p></p><h2>延迟监控框架的实现</h2><p>实际上，Redis在运行过程中，以下表格中给出的几类事件都会导致Redis变慢，我们通常也把这些事件称为<strong>延迟事件</strong>。你可以参考表格中的这些事件类型，以及它们在源码中对应的事件名称。</p><!-- [[[read_end]]] --><p><img src=\"https://static001.geekbang.org/resource/image/db/73/db2c320f4af71fdc2c941dd9c58fff73.jpg?wh=1920x908\" alt=\"图片\"></p><p>那么针对这些事件，Redis实现了延迟监控框架，通过采样的方式来记录它们的执行情况。当需要排查问题时，延迟监控框架提供了<strong>latency history命令</strong>，以便运维人员检查这些事件。</p><p></p><p>下面，我们就来看下记录事件执行情况的数据结构。因为延迟监控框架是在<a href=\"https://github.com/redis/redis/tree/5.0/src/latency.h\">latency.h</a>和<a href=\"https://github.com/redis/redis/tree/5.0/src/latency.c\">latency.c</a>文件中实现的，你也可以在这两个文件中找到相应的数据结构和函数。</p><p></p><h3>记录事件执行情况的数据结构</h3><p>首先，Redis是使用了<strong>latencySample结构体</strong>，来记录延迟事件的采样时间和事件的实际执行时长，这个结构体的代码如下所示：</p><pre><code class=\"language-plain\">struct latencySample {\n&nbsp;&nbsp;&nbsp; int32_t time; &nbsp;//事件的采样时间\n&nbsp;&nbsp;&nbsp; uint32_t latency;&nbsp; //事件的执行时长（以毫秒为单位）\n};\n</code></pre><p>而在latencySample这个结构体基础上，Redis又设计了<strong>latencyTimeSeries结构体</strong>，这个结构体使用了一个latencySample类型的数组，记录了针对某一类事件的一系列采样结果，这样就可以为分析Redis变慢提供更多的事件信息。</p><pre><code class=\"language-plain\">struct latencyTimeSeries {\n&nbsp;&nbsp;&nbsp; int idx; &nbsp;//采样事件数组的写入位置\n&nbsp;&nbsp;&nbsp; uint32_t max;&nbsp; //当前事件的最大延迟\n&nbsp;&nbsp;&nbsp; struct latencySample samples[LATENCY_TS_LEN]; //采样事件数组，记录LATENCY_TS_LEN个采样结果，LATENCY_TS_LEN默认为160\n};\n</code></pre><p>另外，也因为延迟监控框架要记录的延迟事件有很多种，所以Redis还进一步设计了一个<strong>哈希表latency_events</strong>，作为全局变量server的一个成员变量，用来记录不同事件的采样结果数组，如下所示：</p><pre><code class=\"language-plain\">struct redisServer {\n&nbsp;&nbsp; …\n&nbsp;&nbsp; dict *latency_events;\n&nbsp;&nbsp; …\n}\n</code></pre><p>这个哈希表是在Redis server启动初始化的函数initServer中，通过调用latencyMonitorInit函数来完成创建的，如下所示：</p><pre><code class=\"language-plain\">void initServer(void) {\n&nbsp;&nbsp;&nbsp; …\n&nbsp;&nbsp;&nbsp; latencyMonitorInit();\n}\n&nbsp;\nvoid latencyMonitorInit(void) {\n&nbsp;&nbsp;&nbsp; server.latency_events = dictCreate(&amp;latencyTimeSeriesDictType,NULL);\n}\n</code></pre><p>好，了解了记录延迟事件的数据结构和初始化操作后，我们再来看下事件采样是如何实现的。</p><p></p><h3>如何实现延迟事件的采样？</h3><p>延迟事件的<strong>采样函数是latencyAddSample</strong>，它的函数原型如下所示。它的参数中包含了要记录的事件名称，这实际是对应了latency_events哈希表中的一个哈希项。此外，它的参数中还包括该事件的执行时长。</p><pre><code class=\"language-plain\">void latencyAddSample(char *event, mstime_t latency)\n</code></pre><p>latencyAddSample函数的执行逻辑并不复杂，主要可以分成三步。</p><p></p><p><strong>首先</strong>，它会根据传入的事件名称，在latency_events哈希表中查找该事件。如果该事件对应的哈希项还不存在，它就会在哈希表中加入该事件，如下所示：</p><p></p><pre><code class=\"language-plain\">//查找事件对应的哈希项\nstruct latencyTimeSeries *ts = dictFetchValue(server.latency_events,event);\n…\nif (ts == NULL) { //如果哈希项为空，就新建哈希项\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ts = zmalloc(sizeof(*ts));\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ts-&gt;idx = 0;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ts-&gt;max = 0;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; memset(ts-&gt;samples,0,sizeof(ts-&gt;samples));\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; dictAdd(server.latency_events,zstrdup(event),ts); //在哈希表中插入哈希项\n\t}\n</code></pre><p><strong>然后</strong>，latencyAddSample函数会根据传入的事件执行时间，更新当前记录的该类事件的最大执行时间，如下所示：</p><pre><code class=\"language-plain\">if (latency &gt; ts-&gt;max) ts-&gt;max = latency;\n</code></pre><p><strong>最后</strong>，latencyAddSample函数会实际记录当前的采样结果。</p><p>不过在这一步，如果它发现当前的采样结果，和前一个采样结果是在同一秒中获得的，并且如果当前采样结果的事件执行时长，大于前一个采样结果的话，那么latencyAddSample函数就会直接更新前一个采样结果中记录的执行时长了，而不是新插入一个采样结果。</p><p>否则的话，latencyAddSample函数才会新插入一个采样结果。这样设计的目的，也是为了避免在同一秒中记录过多的采样结果。</p><p></p><p>下面的代码展示了latencyAddSample函数实际记录采样结果的逻辑，你可以看下。</p><pre><code class=\"language-plain\">//获得同类事件的前一个采样结果\nprev = (ts-&gt;idx + LATENCY_TS_LEN - 1) % LATENCY_TS_LEN;\nif (ts-&gt;samples[prev].time == now) { //如果当前和前一个采样结果在同一秒中\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (latency &gt; ts-&gt;samples[prev].latency) //如果当前采用结果的执行时长大于前一个采样结果\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ts-&gt;samples[prev].latency = latency; //直接更新前一个采样结果的执行时长\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return;\n&nbsp;&nbsp;&nbsp; }\n//否则，新插入当前的采样结果\nts-&gt;samples[ts-&gt;idx].time = time(NULL);\nts-&gt;samples[ts-&gt;idx].latency = latency;\n</code></pre><p>而在这里，你也要注意一点，就是latencyAddSample函数在记录采样结果时，<strong>会重复使用采样结果数组latencyTimeSeries</strong>。所以，如果采样结果数量超过数组默认大小时，旧的采样结果是会被覆盖掉的。如果你要记录更多的采样结果，就需要扩大latencyTimeSeries数组的长度。</p><p></p><p>那么，latencyAddSample函数是在什么时候调用进行采样的呢?</p><p></p><p>其实，latencyAddSample函数是被封装在了<strong>latencyAddSampleIfNeeded函数</strong>中。在latencyAddSampleIfNeeded函数中，它只会在事件执行时长超过latency-monitor-threshold配置项的值时，才调用latencyAddSample函数记录采样结果。你可以看看下面给出的latencyAddSampleIfNeeded函数定义。</p><pre><code class=\"language-plain\">#define latencyAddSampleIfNeeded(event,var) \\\n&nbsp;&nbsp;&nbsp; if (server.latency_monitor_threshold &amp;&amp; \\\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (var) &gt;= server.latency_monitor_threshold) \\\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; latencyAddSample((event),(var));\n</code></pre><p>而latencyAddSampleIfNeeded函数，实际上会在刚才介绍的延迟事件发生时被调用。这里我来给你举两个例子。</p><p></p><p>比如，当Redis命令通过call函数（在server.c文件中）执行时，call函数就会调用latencyAddSampleIfNeeded函数进行采样，如下所示：</p><pre><code class=\"language-plain\">if (flags &amp; CMD_CALL_SLOWLOG &amp;&amp; c-&gt;cmd-&gt;proc != execCommand) {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //根据命令数据结构中flags的CMD_FAST标记，决定当前是fast-command事件还是command事件\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; char *latency_event = (c-&gt;cmd-&gt;flags &amp; CMD_FAST) ?\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \"fast-command\" : \"command\";\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; latencyAddSampleIfNeeded(latency_event,duration/1000);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; …\n}\n</code></pre><p>再比如，当Redis调用flushAppendOnlyFile函数写AOF文件时，如果AOF文件刷盘的配置项是AOF_FSYNC_ALWAYS，那么flushAppendOnlyFile函数就会调用latencyAddSampleIfNeeded函数，记录aof-fsync-always延迟事件的采样结果，如下所示：</p><pre><code class=\"language-plain\">void flushAppendOnlyFile(int force) {\n…\nif (server.aof_fsync == AOF_FSYNC_ALWAYS) {\nlatencyStartMonitor(latency); //调用latencyStartMonitor函数开始计时\nredis_fsync(server.aof_fd); //实际将数据写入磁盘\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; latencyEndMonitor(latency); //调用latencyEndMonitor结束计时，并计算时长\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; latencyAddSampleIfNeeded(\"aof-fsync-always\",latency);\n…}\n}\n</code></pre><p>那么在这里，你需要注意的是，Redis源码在调用latencyAddSampleIfNeeded函数记录采样结果时，经常会在延迟事件执行前，调用<strong>latencyStartMonitor函数</strong>开始计时，并在事件执行结束后，调用<strong>latencyEndMonitor函数</strong>结束计时和计算事件执行时长。</p><p></p><p>此外，你也可以在阅读Redis源码的工具中，比如sublime、sourceinsight等，通过查找函数关系调用，找到latencyAddSampleIfNeeded函数被调用的其他地方。</p><p></p><p>好了，到这里，Redis延迟监控框架就能通过latencyAddSampleIfNeeded函数，来记录延迟事件的采样结果了。而实际上，Redis延迟监控框架还实现了延迟分析，并能提供应对延迟变慢的建议，我们再来看下。</p><p></p><h3>延迟分析和提供应对措施建议</h3><p>首先，Redis是提供了latency doctor命令，来给出延迟分析结果和应对方法建议的。当我们执行这条命令的时候，Redis就会使用latencyCommand函数来处理。而在处理这个命令时，latencyCommand函数会调用<strong>createLatencyReport函数</strong>，来生成延迟分析报告和应对方法建议。</p><p></p><p>具体来说，createLatencyReport函数会针对latency_events哈希表中记录的每一类事件，先调用analyzeLatencyForEvent函数，计算获得采样的延迟事件执行时长的均值、最大/最小值等统计结果。具体的统计计算过程，你可以仔细阅读下analyzeLatencyForEvent函数的源码。</p><p></p><p>然后，createLatencyReport函数会针对这类事件，结合Redis配置项等信息给出应对措施。</p><p></p><p>其实，在createLatencyReport函数中，<strong>它定义了多个int变量，当这些变量的值为1时，就表示建议Redis使用者采用一种应对高延迟的措施</strong>。我在下面的代码中展示了部分应对措施对应的变量，你可以看下。另外你也可以阅读createLatencyReport函数源码，去了解所有的措施。</p><pre><code class=\"language-plain\">sds createLatencyReport(void) {\n…\nint advise_slowlog_enabled = 0; &nbsp;//建议启用slowlog\nint advise_slowlog_tuning = 0;&nbsp;&nbsp; //建议重新配置slowlog阈值\nint advise_slowlog_inspect = 0; &nbsp;&nbsp;//建议检查slowlog结果\nint advise_disk_contention = 0; &nbsp;&nbsp;//建议减少磁盘竞争\n…\n}\n</code></pre><p>我们也来简单举个例子。比如说，针对command事件，createLatencyReport函数就会根据slowlog的设置情况，给出启用slowlog、调整slowlog阈值、检查slowlog日志结果和避免使用bigkey的应对建议。这部分代码如下所示：</p><pre><code class=\"language-plain\">if (!strcasecmp(event,\"command\")) {\n&nbsp;&nbsp; //如果没有启用slowlog，则建议启用slowlog\n&nbsp;&nbsp; if (server.slowlog_log_slower_than &lt; 0) {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; advise_slowlog_enabled = 1;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; advices++;\n\t} &nbsp;//如果slowlog使用的命令时长阈值太大，建议调整slowlog阈值\n\telse if (server.slowlog_log_slower_than/1000 &gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; server.latency_monitor_threshold)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; advise_slowlog_tuning = 1;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; advices++;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; advise_slowlog_inspect = 1; //建议检查slowlog结果\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; advise_large_objects = 1; //建议避免使用bigkey\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; advices += 2;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }\n</code></pre><p>所以，像createLatencyReport函数这样在计算延迟统计结果的同时，也给出应对措施的设计就很不错，这也是从Redis开发者的角度给出的建议，它更具有针对性。</p><p></p><p>好了，到这里，我们就了解了延迟监控框架的实现。接下来，我们再来学习下Redis中慢命令日志的实现。</p><p></p><h2>慢命令日志的实现</h2><p>Redis是使用了一个较为简单的方法来记录慢命令日志，也就是用一个列表，把执行时间超出慢命令日志执行时间阈值的命令记录下来。</p><p></p><p>在Redis全局变量server对应的数据结构redisServer中，有一个list类型的成员变量<strong>slowlog</strong>，它就是用来记录慢命令日志的列表的，如下所示：</p><pre><code class=\"language-plain\">struct redisServer {\n…\nlist *slowlog;\n…}\n</code></pre><p>而实现慢命令日志记录功能的代码是在<a href=\"https://github.com/redis/redis/tree/5.0/src/slowlog.c\">slowlog.c</a>文件中。这里的主要函数是<strong>slowlogPushEntryIfNeeded</strong>，它的原型如下所示：</p><pre><code class=\"language-plain\">void slowlogPushEntryIfNeeded(client *c, robj **argv, int argc, long long duration)\n</code></pre><p>从代码中你可以看到，这个函数的参数包含了当前执行命令及其参数argv，以及当前命令的执行时长duration。</p><p></p><p>这个函数的逻辑也不复杂，它会判断当前命令的执行时长duration，是否大于redis.conf配置文件中的慢命令日志阈值slowlog-log-slower-than。如果大于的话，它就会调用slowlogCreateEntry函数，为这条命令创建一条慢命令日志项，并调用listAddNodeHeader函数，把这条日志项加入到日志列表头，如下所示：</p><pre><code class=\"language-plain\">//当前命令的执行时长是否大于配置项\nif (duration &gt;= server.slowlog_log_slower_than)\n&nbsp;&nbsp; listAddNodeHead(server.slowlog, slowlogCreateEntry(c,argv,argc,duration));\n</code></pre><p>当然，如果日志列表中记录了太多日志项，它消耗的内存资源也会增加。所以slowlogPushEntryIfNeeded函数在添加日志项时，会判断整个日志列表的长度是否超过配置项slowlog-max-len。一旦超过了，它就会把列表末尾的日志项删除，如下所示：</p><pre><code class=\"language-plain\">//如果日志列表超过阈值长度，就删除列表末尾的日志项\nwhile (listLength(server.slowlog) &gt; server.slowlog_max_len)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; listDelNode(server.slowlog,listLast(server.slowlog));\n</code></pre><p>现在，我们也就了解了记录慢命令日志项的主要函数，slowlogPushEntryIfNeeded的基本逻辑了。然后我们再来看下，它在记录日志项时调用的<strong>slowlogCreateEntry函数</strong>。</p><p>这个函数是用来创建一个慢命令日志项。慢命令日志项的数据结构是slowlogEntry，如下所示：</p><pre><code class=\"language-plain\">typedef struct slowlogEntry {\n&nbsp;&nbsp;&nbsp; robj **argv;&nbsp;&nbsp;&nbsp;&nbsp; //日志项对应的命令及参数\n&nbsp;&nbsp;&nbsp; int argc;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //日志项对应的命令及参数个数\n&nbsp;&nbsp;&nbsp; long long id;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //日志项的唯一ID\n&nbsp;&nbsp;&nbsp; long long duration; &nbsp;//日志项对应命令的执行时长（以微秒为单位）\n&nbsp;&nbsp;&nbsp; time_t time;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //日志项对应命令的执行时间戳\n&nbsp;&nbsp;&nbsp; sds cname;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //日志项对应命令的发送客户端名称\n&nbsp;&nbsp;&nbsp; sds peerid;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //日志项对应命令的发送客户端网络地址\n} slowlogEntry;\n</code></pre><p>从slowLogEntry的定义中，你可以看到，它会把慢命令及其参数，以及发送命令的客户端网络地址记录下来。<strong>这样设计的好处是</strong>，当我们分析慢命令日志时，就可以直接看到慢命令本身及其参数了，而且可以知道发送命令的客户端信息。而这些信息，就有利于我们排查慢命令的起因和来源。</p><p>比如说，如果我们发现日志中记录的命令参数非常多，那么它就可能是一条操作bigkey的命令。</p><p></p><p>当然，考虑到内存资源有限，slowlogCreateEntry函数在创建慢命令日志项时，也会判断命令参数个数。如果命令参数个数，超出了阈值SLOWLOG_ENTRY_MAX_ARGC这个宏定义的大小（默认32）时，它就不会记录超出阈值的参数了，而是记录下剩余的参数个数。这样一来，慢命令日志项中就既记录了部分命令参数，有助于排查问题，也避免了记录过多参数，占用过多内存。</p><p></p><p>下面的代码展示了slowlogCreateEntry的基本执行逻辑，你可以看下。</p><pre><code class=\"language-plain\">slowlogEntry *slowlogCreateEntry(client *c, robj **argv, int argc, long long duration) {\nslowlogEntry *se = zmalloc(sizeof(*se)); //分配日志项空间\nint j, slargc = argc;&nbsp; //待记录的参数个数，默认为当前命令的参数个数\n&nbsp;\n//如果当前命令参数个数超出阈值，则只记录阈值个数的参数\nif (slargc &gt; SLOWLOG_ENTRY_MAX_ARGC) slargc = SLOWLOG_ENTRY_MAX_ARGC;\nse-&gt;argc = slargc;\n…\nfor (j = 0; j &lt; slargc; j++) {&nbsp; //逐一记录命令及参数\n&nbsp;&nbsp; if (slargc != argc &amp;&amp; j == slargc-1) {&nbsp; //如果命令参数个数超出阈值，使用最后一个参数记录当前命令实际剩余的参数个数\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; se-&gt;argv[j] = createObject(OBJ_STRING,\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sdscatprintf(sdsempty(),\"... (%d more arguments)\",\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; argc-slargc+1));\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; } else {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; …&nbsp; //将命令参数填充到日志项中\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }}\n… //将命令执行时长、客户端地址等信息填充到日志项中\n}\n</code></pre><p>好了，到这里，你就了解了慢命令日志的实现。最后，你也要注意，<strong>慢命令日志只会记录超出执行时长阈值的命令信息</strong>，而不会像延迟监控框架那样记录多种事件。所以，记录日志的函数slowlogPushEntryIfNeeded，只会在命令执行函数call（在server.c文件中）中被调用，如下所示：</p><pre><code class=\"language-plain\">void call(client *c, int flags) {\n…\nstart = server.ustime; //命令执行前计时\nc-&gt;cmd-&gt;proc(c);&nbsp; //命令实际执行\nduration = ustime()-start; //命令执行完成计算耗时\n…\nif (flags &amp; CMD_CALL_SLOWLOG &amp;&amp; c-&gt;cmd-&gt;proc != execCommand) {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; …\n&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;//调用slowlogPushEntryIfNeeded函数记录慢命令\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; slowlogPushEntryIfNeeded(c,c-&gt;argv,c-&gt;argc,duration);\n\t}\n…}\n</code></pre><p></p><h2>小结</h2><p>今天这节课，我给你介绍了Redis实现的延迟监控框架和慢命令日志。你要知道，Redis源码会针对可能导致Redis运行变慢的五类事件，在它们执行时进行<strong>采样</strong>。而一旦这些事件的执行时长超过阈值时，监控框架就会将采样结果记录下来，以便后续分析使用。这种针对延迟事件进行采样记录的监控方法，其实是很值得我们学习的。</p><p></p><p>而慢命令日志的实现则较为简单，就是针对运行时长超出阈值的命令，使用一个<strong>列表</strong>把它们记录下来，这里面包括了命令及参数，以及发送命令的客户端信息，这样可以方便运维人员查看分析。</p><p></p><p>当然，Redis源码中实现的延迟监控框架主要是关注导致延迟增加的事件，它记录的延迟事件，也是和Redis运行过程中可能会导致运行变慢的操作<strong>紧耦合</strong>的。此外，Redis的INFO命令也提供了Redis运行时的监控信息，不过你要知道，INFO命令的实现，主要是在全局变量server的成员变量中，用来记录Redis实例的实时运行状态或是资源使用情况的。</p><p></p><h2>每课一问</h2><p>Redis在命令执行的call函数中，为什么不会针对EXEC命令，调用slowlogPushEntryIfNeeded函数记录慢命令呢？</p>","neighbors":{"left":{"article_title":"29 | 如何正确实现循环缓冲区？","id":427126},"right":{"article_title":"31 | 从Module的实现学习动态扩展功能","id":428471}}},{"article_id":428471,"article_title":"31 | 从Module的实现学习动态扩展功能","article_content":"<p>你好，我是蒋德钧。</p><p></p><p>Redis本身已经给我们提供了丰富的数据类型和数据读写功能，而且，Redis实现了基于IO复用的网络框架、数据主从复制和故障恢复机制，以及数据切片集群，这些功能通常都是后端系统所需的核心功能。</p><p></p><p>那么，当我们在实际应用中，既希望能用上Redis已经实现的核心功能，又需要新增一些额外的命令或是数据类型时，该怎么办呢？</p><p>其实，Redis从4.0版本开始，就提供了扩展模块（Module）的功能。这些扩展模块以动态链接库（so文件）的形式加载到Redis中，我们可以基于Redis来新增功能模块。这些模块通常包括了新增的命令和数据类型，与此同时，这些数据类型对应的数据会保存在Redis数据库中，从而保证了应用程序对这些数据的高性能访问。</p><p></p><p>新增功能模块是后端系统开发过程中经常会遇到的问题，那么今天这节课，我就带你学习Redis是如何实现新增一个功能模块的。掌握了今天的课程内容，你就可以参考Redis的实现方案，给自己的系统添加相应的功能模块扩展框架，从而增加系统的灵活性。</p><p></p><p>下面，我们就先来了解下Redis的扩展模块框架的初始化操作。因为和Redis扩展模块框架相关的功能主要是在<a href=\"https://github.com/redis/redis/tree/5.0/src/redismodule.h\">redismodule.h</a>和<a href=\"https://github.com/redis/redis/tree/5.0/src/module.c\">module.c</a>文件中定义和实现的，你可以在这两个文件中查找接下来要介绍的数据结构或函数。</p><!-- [[[read_end]]] --><p></p><h2>模块框架的初始化</h2><p>在Redis的入口main函数的执行流程中，会<strong>调用moduleInitModulesSystem函数</strong>（在module.c文件中）初始化扩展模块框架，如下所示：</p><pre><code class=\"language-plain\">int main(int argc, char **argv) {\n&nbsp;&nbsp; …\n&nbsp;&nbsp; moduleInitModulesSystem();\n…}\n</code></pre><p>这个moduleInitModulesSystem函数，主要是创建和初始化扩展模块框架运行所需的数据结构。这其中比较重要的初始化操作包括：</p><ul>\n<li>创建保存待加载模块的列表，这对应了全局变量server的loadmodule_queue成员变量；</li>\n<li>创建保存扩展模块的全局哈希表modules；</li>\n<li>调用moduleRegisterCoreAPI函数注册核心API。</li>\n</ul><p></p><p>这些操作的代码如下所示：</p><pre><code class=\"language-plain\">void moduleInitModulesSystem(void) {\n&nbsp;&nbsp; …\n&nbsp;&nbsp; server.loadmodule_queue = listCreate();\n&nbsp;&nbsp; modules = dictCreate(&amp;modulesDictType,NULL);\n&nbsp;&nbsp; …\n&nbsp;&nbsp; moduleRegisterCoreAPI();\n&nbsp;&nbsp; …\n}\n</code></pre><p>这里，我们先来看下其中的<strong>moduleRegisterCoreAPI函数</strong>的作用。</p><p>这个函数先是在全局变量server中，创建两个哈希表成员变量moduleapi和sharedapi，它们是分别用来保存模块向外暴露的API以及模块之间共享的API的。紧接着，这个函数会调用REGISTER_API宏，注册模块的核心API函数。</p><p></p><p>下面的代码展示了moduleRegisterCoreAPI函数的部分执行逻辑，你可以看到，其中就包含了调用REGISTER_API宏注册Alloc、CreateCommand、ReplyWithLongLong、RepyWithError这些API函数。</p><pre><code class=\"language-plain\">void moduleRegisterCoreAPI(void) {\n&nbsp;&nbsp;&nbsp; server.moduleapi = dictCreate(&amp;moduleAPIDictType,NULL); //创建哈希表保存模块核心API\n&nbsp;&nbsp;&nbsp; server.sharedapi = dictCreate(&amp;moduleAPIDictType,NULL); //创建哈希表保存模块共享API\n&nbsp;&nbsp;&nbsp; REGISTER_API(Alloc);&nbsp;&nbsp; //注册Alloc API函数\n&nbsp;&nbsp; &nbsp;…\n\tREGISTER_API(CreateCommand);&nbsp; //注册CreateCommand API函数\n\t…\n\tREGISTER_API(ReplyWithLongLong); //注册ReplyWithLongLong API函数\n\tREGISTER_API(ReplyWithError);&nbsp; //注册ReplyWithError API函数\n    ...\n    }\n</code></pre><p>这些API函数其实是Redis扩展模块框架自身已经实现好的，我们在开发扩展模块时都会用到它们。举个例子，当我们在开发新的扩展模块时，就会调用框架的CreateCommand API，来创建新增的命令，以及调用ReplyWithLongLong API来给客户端返回结果。<br>\n那么接下来，我们再来具体看下<strong>REGISTER_API宏</strong>的实现，它其实是由<strong>moduleRegisterApi函数</strong>来实现的。moduleRegisterApi函数会把“RedisModule_”开头的API函数，转换成“RM_”开头的API函数，并通过dictAdd函数，将API函数添加到全局的moduleapi哈希表中。</p><p>而在这个哈希表中，哈希项的key是API的名称，value是这个API对应的函数指针。这样一来，当我们开发模块要用到这些API时，就可以通过moduleapi哈希表查找API名称，然后获得API函数指针并进行使用了。</p><p></p><p>下面的代码展示了REGISTER_API宏定义和moduleRegisterApi函数的实现，你可以看下。</p><pre><code class=\"language-plain\">//将moduleRegisterApi函数定义为REGISTER_API宏\n#define REGISTER_API(name) \\\n\tmoduleRegisterApi(\"RedisModule_\" #name, (void *)(unsigned long)RM_ ## name)\n\t&nbsp;\nint moduleRegisterApi(const char *funcname, void *funcptr) {\n\treturn dictAdd(server.moduleapi, (char*)funcname, funcptr); //将API名称和对应的函数指针添加到moduleapi哈希表中\n\t}\n</code></pre><p>这样，我们也就了解了扩展模块框架初始化时的工作，它主要是完成了运行所需数据结构的初始化，并把框架提供的API的名称和实现函数，添加到moduleapi哈希表中。</p><p></p><p>那么接下来，我们就具体来看下如何实现一个模块，并看看这个模块是如何工作的。</p><p></p><h2>模块的实现和工作过程</h2><p>我们先来看一个简单的模块实现例子。假设我们要新增一个模块“helloredis”，这个模块包含一个命令“hello”，而这个命令的作用就是返回“hello redis”字符串。</p><p></p><p>那么，简单来说，要开发这个新增模块，我们需要开发两个函数，一个是RedisModule_OnLoad函数，它会在模块加载时被调用，初始化新增模块，并向Redis扩展模块框架注册模块和命令。另一个是新增模块具体功能的实现函数，我们在这里把它命名为Hello_NewCommand。</p><p>我们先来看初始化和注册新增模块的过程。</p><h3>新增模块的初始化与注册</h3><p>在Redis的入口main函数的执行流程中，在调用完moduleInitModulesSystem函数，完成扩展模块框架初始化后，实际上，main函数还会调用moduleLoadFromQueue函数，来加载扩展模块。</p><p>moduleLoadFromQueue函数会进一步调用<strong>moduleLoad函数</strong>，而moduleLoad函数会根据模块文件所在的路径、模块所需的参数来完成扩展模块的加载，如下所示：</p><pre><code class=\"language-plain\">void moduleLoadFromQueue(void) {\n...\n//加载扩展模块\nif (moduleLoad(loadmod-&gt;path,(void **)loadmod-&gt;argv,loadmod-&gt;argc)\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; == C_ERR)\n{...}\n}\n</code></pre><p>那么，在moduleLoad函数中，它会在我们自行开发的模块文件中查找“RedisModule_OnLoad”函数，并执行这个函数。然后，它会调用dictAdd函数，把成功加载的模块添加到全局哈希表modules中，如下所示：</p><pre><code class=\"language-plain\">int moduleLoad(const char *path, void **module_argv, int module_argc) {\n...\n//在模块文件中查找RedisModule_OnLoad函数\nonload = (int (*)(void *, void **, int))(unsigned long) dlsym(handle,\"RedisModule_OnLoad\");\n...\n//执行RedisModule_OnLoad函数\nif (onload((void*)&amp;ctx,module_argv,module_argc) == REDISMODULE_ERR) {...}\n \n...\ndictAdd(modules,ctx.module-&gt;name,ctx.module); //把加载的模块添加到全局哈希表modules\n}\n</code></pre><p>我在这里画了张图，展示了main函数加载新模块的过程，你可以再回顾下。</p><p><img src=\"https://static001.geekbang.org/resource/image/81/a9/8171506a203ea26c4967ce225fea56a9.jpg?wh=1920x1080\" alt=\"图片\"></p><p>从刚才介绍的main函数加载新增模块的过程中，你可以看到，模块框架会在模块文件中，会查找RedisModule_OnLoad函数。<strong>RedisModule_OnLoad是每个新增模块都必须包含的函数，它是扩展模块框架加载新增模块的入口。</strong>通过这个函数，我们可以把新增的模块命令注册到Redis的命令表中，从而可以在Redis中使用新增命令。这个函数的原型如下所示：</p><pre><code class=\"language-plain\">int RedisModule_OnLoad(RedisModuleCtx *ctx, RedisModuleString **argv, int argc)\n</code></pre><p>而当我们要实现RedisModule_OnLoad函数时，就要用到刚才介绍的扩展模块框架提供的API函数了。</p><p></p><p>首先，我们要调用<strong>RedisModule_Init函数</strong>（在redismodule.h文件中），来注册新增的模块，它的函数原型如下所示：</p><pre><code class=\"language-plain\">static int RedisModule_Init(RedisModuleCtx *ctx, const char *name, int ver, int apiver)\n</code></pre><p>其中，第一个<strong>参数ctx</strong>是RedisModuleCtx结构体类型变量，这个结构体记录了模块的指针、执行模块命令的客户端，以及运行时状态等信息。第二个<strong>参数name</strong>表示的新增模块的名称，而第三和第四个参数表示的是API版本。</p><p></p><p>然后，对于我们刚才要实现的“helloredis”模块，我们就可以按如下代码来调用RedisModule_Init函数，实现模块的注册。</p><pre><code class=\"language-plain\">if (RedisModule_Init(ctx,\"helloredis\",1,REDISMODULE_APIVER_1)\n&nbsp;&nbsp; == REDISMODULE_ERR) return REDISMODULE_ERR;\n</code></pre><p>而具体的注册过程，我们可以看下RedisModule_Init函数的实现。这个函数的主要工作可以分成三步。</p><p><strong>第一步是设置RedisModule_GetApi函数</strong>，让它等于RedisModuleCtx结构体中的函数指针getapifuncptr。</p><p></p><p><strong>第二步是调用REDISMODULE_GET_API宏</strong>，来获得扩展模块框架提供的API函数。这样一来，新增模块中就可以使用框架的API了。</p><p></p><p>这里，你需要注意下REDISMODULE_GET_API宏的定义，这个宏定义其实是使用了RedisModule_GetApi函数指针，如下所示：</p><pre><code class=\"language-plain\">#define REDISMODULE_GET_API(name) \\\n\tRedisModule_GetApi(\"RedisModule_\" #name, ((void **)&amp;RedisModule_ ## name))\n</code></pre><pre><code> \n</code></pre><p>而RedisModule_GetApi函数指针是通过<strong>REDISMODULE_API_FUNC</strong>这个宏定义来实现的。在这里，REDISMODULE_API_FUNC宏的作用是把它的参数设置为函数指针，如下所示：</p><pre><code class=\"language-plain\">#define REDISMODULE_API_FUNC(x) (*x) //设置x为函数指针\n</code></pre><p>那么，对于RedisModule_GetApi函数指针来说，它又进一步指向了API函数，它的参数就包括了API函数名称和指向API函数的指针。</p><pre><code class=\"language-plain\">int REDISMODULE_API_FUNC(RedisModule_GetApi)(const char *, void *); //设置RedisModule_GetApi为函数指针\n</code></pre><p>我们再来看刚才介绍的REDISMODULE_GET_API宏，如下所示：</p><pre><code class=\"language-plain\">#define REDISMODULE_GET_API(name) \\\n\tRedisModule_GetApi(\"RedisModule_\" #name, ((void **)&amp;RedisModule_ ## name))\n</code></pre><p>你会发现，这个宏会把传入的参数name，传递给RedisModule_GetApi函数指针，而RedisModule_GetApi函数指针会将参数name和“RedisModule_”字符串拼接起来，这就组成了模块框架中以“RedisModule_”开头的API函数的名称了，从而可以获得同名API函数的指针。</p><p></p><p>所以，在RedisModule_Init函数的第一步和第二步，都是通过RedisModule_GetApi来获得API函数的指针的。</p><p></p><p>那么，在RedisModule_Init函数的<strong>第三步，它会调用RedisModule_IsModuleNameBusy函数</strong>，检查当前注册的新增模块名称是否已经存在。</p><p>如果这个模块已经存在了，那么它就会报错返回。而如果模块不存在，它就调用<strong>RedisModule_SetModuleAttribs函数</strong>，给新增模块分配一个RedisModule结构体，并初始化这个结构体中的成员变量。而RedisModule结构体正是用来记录一个模块的相关属性的。</p><p></p><p>下面的代码展示了RedisModule_SetModuleAttribs函数的部分执行逻辑，你可以看下。这里，你要注意的是，刚才我介绍的moduleRegisterCoreAPI函数，它在模块框架初始化时，已经把以“RedisModule_”开头的函数指向了以“RM_”开头的函数，所以，当你看到“RedisModule_”开头的函数时，就需要在module.c文件中，查找以“RM_”开头而后缀相同的函数。</p><pre><code class=\"language-plain\">void RM_SetModuleAttribs(RedisModuleCtx *ctx, const char *name, int ver, int apiver) {\n&nbsp;&nbsp;&nbsp; RedisModule *module;\n&nbsp;\n&nbsp;&nbsp;&nbsp; if (ctx-&gt;module != NULL) return;\n&nbsp;&nbsp;&nbsp; module = zmalloc(sizeof(*module));&nbsp; //分配RedisModule结构体的空间\n&nbsp;&nbsp;&nbsp; module-&gt;name = sdsnew((char*)name); //设置模块名称\n&nbsp;&nbsp;&nbsp; module-&gt;ver = ver;&nbsp; //设置模板版本\n&nbsp; &nbsp;&nbsp;…\n&nbsp;&nbsp;&nbsp; ctx-&gt;module = module; //在记录模块运行状态的RedisModuleCtx变量中保存模块指针\n}\n</code></pre><p>好了，到这里，RedisModule_Init函数针对一个新增模块的初始化流程就执行完成了。下面的代码也展示了RedisModule_Init函数的主要执行逻辑，你可以再回顾下。</p><pre><code class=\"language-plain\">void *getapifuncptr = ((void**)ctx)[0];\nRedisModule_GetApi = (int (*)(const char *, void *)) (unsigned long)getapifuncptr;\nREDISMODULE_GET_API(Alloc);\n…\nREDISMODULE_GET_API(CreateCommand);\n…\nREDISMODULE_GET_API(ListPush);\nREDISMODULE_GET_API(ListPop);\n…\nREDISMODULE_GET_API(CreateString);\n…\n//检查是否有同名的模块\nif (RedisModule_IsModuleNameBusy &amp;&amp; RedisModule_IsModuleNameBusy(name)) return REDISMODULE_ERR;\nRedisModule_SetModuleAttribs(ctx,name,ver,apiver); //没有同名模块，则初始化模块的数据结构\nreturn REDISMODULE_OK; \n</code></pre><p>其实，从代码中你可以发现，RedisModule_Init函数在初始化新增模块时，会从框架中获得很多键值对常规操作的API函数，比如List的Push和Pop操作、创建String操作等等。你可以进一步阅读RedisModule_Init函数，来了解新增模块能获得的API。</p><p></p><p>那么，当我们调用RedisModule_Init函数，完成了新增模块的注册和初始化后，我们就可以调用<strong>RedisModule_CreateCommand函数</strong>来注册模块的新增命令。下面，我们就来看下这个执行过程。</p><p></p><h3>新增命令的注册</h3><p>对于我们刚才开发的新增模块来说，我们需要给它增加一个新命令“hello”，这主要就是通过在RedisModule_OnLoad函数中，调用RedisModule_CreateCommand函数来实现的。你可以先看看下面的代码，这部分代码实现了新增命令的注册。</p><p></p><pre><code class=\"language-plain\">int RedisModule_OnLoad(RedisModuleCtx *ctx, RedisModuleString **argv, int argc) {\n…\nif (RedisModule_CreateCommand(ctx,\"hello\", Hello_NewCommand, \"fast\",0, 0, 0) == REDISMODULE_ERR)\nreturn REDISMODULE_ERR;\n…}\n</code></pre><p>从代码中，你可以看到，RedisModule_CreateCommand的参数包括了新增的命令名称“hello”、这个命令对应的实现函数Hello_NewCommand，以及这个命令对应的属性标记“fast”。</p><p></p><p>那么，现在我们就来看下RedisModule_CreateCommand的执行过程，就像刚才我给你介绍的，它实际对应的实现函数是以“RM_”开头的<strong>RM_CreateCommand</strong>。</p><p></p><p>RM_CreateCommand函数的原型如下所示，它的第二、三和四个参数就对应了刚才我提到的新增命令的名称、命令对应实现函数和命令标记。</p><pre><code class=\"language-plain\">int RM_CreateCommand(RedisModuleCtx *ctx, const char *name, RedisModuleCmdFunc cmdfunc, const char *strflags, int firstkey, int lastkey, int keystep)\n</code></pre><p>而RM_CreateCommand函数的<strong>主要作用，是创建一个RedisModuleCommandProxy结构体类型的变量cp</strong>。这个变量类似于新增命令的代理命令，它本身记录了新增命令对应的实现函数，与此同时，它又创建了一个redisCommand结构体类型的成员变量<strong>rediscmd</strong>。</p><p></p><p>这里你需要注意的是，在Redis源码中，redisCommand类型的变量对应了Redis命令表中的一个命令。当Redis收到客户端发送的命令时，会在命令表中查找命令名称，以及命令对应的redisCommand变量。而redisCommand结构体中的<strong>成员变量proc</strong>，就对应了命令的实现函数。</p><p></p><pre><code class=\"language-plain\">struct redisCommand {\n&nbsp;&nbsp;&nbsp; char *name;&nbsp; //命令名称\n\tredisCommandProc *proc;&nbsp; //命令对应的实现函数\n\t…\n}\n</code></pre><p>在刚才介绍的cp变量中，它创建了redisCommand类型的成员变量rediscmd，并把它的proc变量设置为RedisModuleCommandDispatcher函数。<br>\n然后，RM_CreateCommand函数会把rediscmd添加到Redis的命令表中，这样一来，当客户端发送新增命令时，Redis会先从命令表中查找到，新增命令对应的执行函数是RedisModuleCommandDispatcher，然后就会执行RedisModuleCommandDispatcher这个函数。而RedisModuleCommandDispatcher函数接着才会实际调用新增模块命令所对应的实现函数。</p><p></p><p>下图就展示了RM_CreateCommand函数添加代理命令时，代理命令和模块新增命令之间的关系，你可以看下。</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/7e/50/7e9479c89f89ce58ed477bdc8b476150.jpg?wh=1920x1080\" alt=\"图片\"></p><p>下面的代码也展示了RM_CreateCommand函数创建代理命令，并在Redis命令表中添加代理命令的基本执行逻辑，你可以再回顾下。</p><pre><code class=\"language-plain\">struct redisCommand *rediscmd;&nbsp;\nRedisModuleCommandProxy *cp;&nbsp; //创建RedisModuleCommandProxy结构体变量\nsds cmdname = sdsnew(name); //新增命令的名称\ncp = zmalloc(sizeof(*cp));\ncp-&gt;module = ctx-&gt;module;&nbsp; //记录命令对应的模块\ncp-&gt;func = cmdfunc;&nbsp; //命令对应的实现函数\ncp-&gt;rediscmd = zmalloc(sizeof(*rediscmd));&nbsp; //创建一个redisCommand结构体，对应Redis命令表中的命令\ncp-&gt;rediscmd-&gt;name = cmdname; //命令表中的命令名称\ncp-&gt;rediscmd-&gt;proc = RedisModuleCommandDispatcher; //命令表中命令对应的函数\ndictAdd(server.commands,sdsdup(cmdname),cp-&gt;rediscmd);\n…\n</code></pre><p>这样，我们在开发新模块的RedisModule_OnLoad函数时，要完成的第二步操作，也就是调用RedisModule_CreateCommand函数，来完成新增命令在Redis命令表中的注册。</p><p>那么，你可以再来看看下面的代码，其中展示了到目前为止，我们开发的新增模块的代码内容。到这里，一个简单的RedisModule_OnLoad函数就开发完成了。</p><p></p><pre><code class=\"language-plain\">int RedisModule_OnLoad(RedisModuleCtx *ctx, RedisModuleString **argv, int argc) {\n  //初始化模块\n  if (RedisModule_Init(ctx,\"helloredis\",1,REDISMODULE_APIVER_1)\n   == REDISMODULE_ERR) return REDISMODULE_ERR;\n   \n  //注册命令\n  if (RedisModule_CreateCommand(ctx,\"hello\", Hello_NewCommand, \"fast\",0, 0, 0) == REDISMODULE_ERR)\nreturn REDISMODULE_ERR;\n  \n   return REDISMODULE_OK;\n}\n</code></pre><p>接下来，我们就需要开发新增命令实际对应的实现函数了。</p><p></p><h3>开发新增命令的实现函数</h3><p>开发新增命令的实现函数，主要就是为了实现我们新增模块的具体功能逻辑。在刚才举的例子中，新增模块“helloredis”的命令“hello”，它的功能逻辑很简单，就是返回一个“hello redis”的字符串。</p><p></p><p>而我们刚才在调用RedisModule_CreateCommand函数注册新命令的实现函数时，注册的是<strong>Hello_NewCommand函数</strong>。所以，这里我们就是要实现这个函数。</p><p></p><p>下面的代码展示了Hello_NewCommand函数的逻辑，你能看到，它就是调用RedisModule_ReplyWithString向客户端返回“hello redis”字符串。</p><pre><code class=\"language-plain\">int Hello_NewCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc) {\n&nbsp;&nbsp;&nbsp; return RedisModule_ReplyWithString(ctx, “hello redis”);\n}\n</code></pre><p>另外从代码中你还可以看到，我们开发的模块可以调用扩展模块框架提供的API函数，来完成一定的功能。比如，在刚才的代码中，Hello_NewCommand函数就是调用了RedisModule_ReplyWithString这个框架的API函数，来向客户端返回String类型的结果。</p><p>好了，到这里，我们就完成了一个简单的新增模块的开发。这个过程包括了开发用来初始化模块和注册新增命令的函数RedisModule_OnLoad，以及实际实现模块功能的Hello_NewCommand函数。</p><p></p><p>那么最后，我们来看下当Redis收到模块命令后是如何执行的。</p><p></p><h3>新增模块的命令执行</h3><p>刚才我介绍过，main函数在执行时，会调用moduleLoadFromQueue函数加载扩展模块。那么，当模块加载完成后，就可以接受它新增的命令了。</p><p></p><p>我在<a href=\"https://time.geekbang.org/column/article/411558\">第14讲</a>中给你介绍过一个命令的执行流程，对于扩展模块的新增命令来说，它也是按照这个流程来执行的。所以，当收到扩展模块的命令时，<strong>processCommand函数</strong>会被调用，然后这个函数会在命令表中查找收到的命令。如果找到这个命令，processCommand函数就会调用call函数执行这个命令。</p><p></p><p>而call函数是会根据客户端发送的命令，执行这个命令对应的redisCommand结构中的proc指针指向函数，如下所示：</p><pre><code class=\"language-plain\">void call(client *c, int flags) {\n…\nc-&gt;cmd-&gt;proc(c);\n…\n}\n</code></pre><p>注意，我刚才介绍的那个RM_CreateCommand函数在注册新命令时，它在命令表中给新增命令注册的对应函数，是<strong>RedisModuleCommandDispatcher</strong>，所以，当收到新增模块的命令时，也是执行RedisModuleCommandDispatcher函数。</p><p></p><p>而RedisModuleCommandDispatcher函数，会先获得刚才我介绍的代表代理命令的RedisModuleCommandProxy结构体的变量cp，并调用cp的<strong>func成员变量</strong>。这里的func成员变量在RM_CreateCommand函数执行时，已经被赋值了新增命令的实际实现函数。这样一来，通过RedisModuleCommandDispatcher函数，新增模块的命令也就能正常执行了。</p><p></p><p>下面的代码展示了RedisModuleCommandDispatche函数的基本逻辑，你可以看下。</p><pre><code class=\"language-plain\">void RedisModuleCommandDispatcher(client *c) {\n\tRedisModuleCommandProxy *cp = (void*)(unsigned long)c-&gt;cmd-&gt;getkeys_proc;\n\t…\n\tcp-&gt;func(&amp;ctx,(void**)c-&gt;argv,c-&gt;argc);\n\t…\n\t}\n</code></pre><p>好了，到这里，我们就了解了新增模块的命令是如何通过代理命令的实现函数RedisModuleCommandDispatcher来完成执行的了。这样一来，我们也就清楚了从模块自身的实现开发，到模块命令执行的整个过程。</p><p></p><h2>小结</h2><p>在今天的课程里，我给你介绍了Redis扩展模块框架的工作机制。我以一个简单的扩展模块为例，带你了解了扩展模块框架的初始化、新模块的初始化、新命令的注册与执行过程。那么在这个过程中，你需要重点掌握以下<strong>三个关键点</strong>。</p><p></p><p>一是，新增模块的程序中必须包含RedisModule_OnLoad函数，这是因为模块框架在加载模块时，会通过动态链接库操作函数dlsym在新增模块编译后的动态链接文件（so文件）中查找RedisModule_OnLoad函数，并会执行这个函数。所以，我们开发扩展模块时，就要在RedisModule_OnLoad函数中使用RedisModule_Init函数初始化模块，以及使用RedisModule_CreateCommand函数注册命令。</p><p></p><p>二是，扩展模块框架在Redis命令表中并没有直接添加新增命令的实现函数，而是把新增命令的执行函数先设置为RedisModuleCommandDispatcher，然后再由RedisModuleCommandDispatcher函数执行新增命令的实际实现函数。</p><p></p><p>三是，扩展模块框架自身通过“RM_”开头的API函数封装了很多Redis现有的操作功能，例如对不同数据类型的操作，给客户端回复不同类型的结果等。这方便了我们在开发新增模块时，复用Redis的已有功能。你可以进一步阅读module.c文件，了解扩展框架提供的具体API函数。</p><p></p><p>最后，前面总结的这三点内容，可以说既对我们开发扩展模块，了解它们运行机制有帮助，也给我们自己开发扩展模块框架提供了参考实现，我希望你能掌握好它们。</p><p></p><p></p><h2>每课一问</h2><p>你使用过哪些Redis的扩展模块，或者自行开发过扩展模块吗？欢迎在评论分享些你的经验。</p>","neighbors":{"left":{"article_title":"30 | 如何在系统中实现延迟监控？","id":427537},"right":{"article_title":"32 | 如何在一个系统中实现单元测试？","id":428474}}},{"article_id":428474,"article_title":"32 | 如何在一个系统中实现单元测试？","article_content":"<p>你好，我是蒋德钧。今天这节课，我来和你聊聊Redis中的单元测试。</p><p>单元测试通常是用来测试一个系统的某个特定功能模块，通过单元测试，我们可以检测开发的功能模块是否正常。对于一个像Redis这样包含很多功能模块的系统来说，单元测试就显得更为重要了。否则，如果让整个系统开发完成后直接进行整体测试，一旦出现问题，就很难定位了。</p><p></p><p>那么，<strong>对于一个包含多功能模块的系统来说，我们该如何进行单元测试呢？</strong>Redis源码中针对其主要功能模块，比如不同数据类型操作、AOF和RDB持久化、主从复制、集群等模块，提供了单元测试的框架。</p><p></p><p>今天这节课，我就带你来学习了解下Redis实现的单元测试框架。通过学习今天的课程内容，你可以掌握如何使用Tcl语言开发一个单元测试框架，这些测试开发方法也可以用在你日常的开发测试工作中。</p><p></p><p>接下来，我们就先来看看Redis针对主要功能模块实现的单元测试框架。</p><p></p><h2>Tcl语言基础</h2><p>通过课程的<a href=\"https://time.geekbang.org/column/article/399866\">第1讲</a>我们知道，在Redis源码目录中，专门有一个<a href=\"https://github.com/redis/redis/tree/5.0/tests\">tests子目录</a>，这个tests目录就包含了Redis单元测试框架的实现代码。而在了解这个单元测试框架之前，你首先需要知道，这个框架是使用了Tcl语言来开发的。</p><p>Tcl的全称是Tool Command Language，它是一种功能丰富并且很容易上手的动态编程语言，经常会被应用在程序测试、运维管理等场景中。这里，我先给你介绍下Tcl语言的一些基础知识和基本操作，当然你也可以在Tcl语言的<a href=\"https://www.tcl.tk/\">官网</a>上学习它更加全面的开发知识。</p><!-- [[[read_end]]] --><p></p><ul>\n<li><strong>Tcl程序执行</strong></li>\n</ul><p>Tcl语言本身属于解释性编程语言，所以，我们使用Tcl开发的程序不用编译和链接，它会对每条语句解释执行。</p><p></p><ul>\n<li><strong>数据类型与基本操作</strong></li>\n</ul><p>Tcl语言的数据类型很简单，就是字符串。我们可以使用set关键字来定义变量，并且不需要指定变量的类型。同时，我们可以使用puts关键字来进行输出操作。</p><p>关于变量的使用，我们还需要了解两个知识点：一是，在输出某个变量的值时，我们需要使用<code>$</code>符号来引用该变量；二是，我们可以使用两个冒号开头来定义一个全局变量，比如<code>::testnum</code>就定义了一个全局变量。</p><p></p><p>下面的代码就展示了变量a的定义和输出，其中变量a的值被定义为“hello tcl”。</p><pre><code class=\"language-plain\">set a “hello tcl”\nputs $a\n</code></pre><p>如果你的电脑上安装了tclsh的命令解释器，你可以直接在命令行上运行tclsh，这样就进入到了Tcl的命令解释执行环境中了。如果你没有安装，也可以在Tcl官网上下载安装<a href=\"https://www.tcl.tk/software/tcltk/8.6.html\">源码包</a>，进行编译安装。</p><p></p><p>然后，你可以把刚才介绍的两个语句在tclsh的执行环境中运行，如下所示：</p><pre><code class=\"language-plain\">tclsh&nbsp;&nbsp;&nbsp; //运行tclsh命令，需安装有tclsh命令解释器\n//进入tclsh的执行环境\n% set a \"hello tcl\"\nhello tcl\n% puts $a&nbsp;\nhello tcl\n</code></pre><p>好，刚才介绍的是Tcl设置和输出变量的基本操作，除此之外，我们还可以定义<strong>proc子函数</strong>，用来执行会经常用到的功能。以下代码就展示了一个proc子函数的定义：</p><pre><code class=\"language-plain\">proc sum {arg1 arg2} {\nset x [expr $arg1+$arg2];\nreturn $x\n}\n</code></pre><p>从代码中，你可以看到，proc关键字后面跟着的是函数名称sum。然后，函数参数arg1和arg2会使用花括号括起来表示。这个函数体是设置了变量x的值，而变量x的值等于arg1和arg2两个参数的和。<br>\n这里，你需要注意的是，<strong>在Tcl语言中，方括号可以将一条命令括起来，让该命令执行，并得到返回结果</strong>。所以，在刚才介绍的代码中，<code>[expr $arg1+$arg2]</code>就表示要计算arg1和arg2的和。最后，这个函数会返回变量x的值，这里也是使用了<code>$</code>符号来引用变量x。</p><p></p><p>现在，我们就了解了Tcl语言的一些基础知识和基本操作。接下来，我们来看下Redis中使用Tcl开发的单元测试框架。当然，在学习单元测试框架的过程中，我也会陆续给你介绍一些Tcl开发涉及的基础知识，以便你能理解测试框架的实现。</p><p></p><h2>Redis单元测试框架的实现</h2><p>当我们使用Redis的单元测试框架时，我们要在Redis源码的tests目录这一层执行测试脚本test_helper.tcl，如下所示：</p><pre><code class=\"language-plain\">tclsh tests/test_helper.tcl\n</code></pre><p>从这里，你可以看到，单元测试框架的入口是在test_helper.tcl文件中实现的。因为Tcl是解释性语言，所以test_helper.tcl在执行时，会依次解释执行其中的语句。不过你要注意的是，这些语句并不是proc子函数，proc子函数是要被调用执行的。下面呢，我们先来了解下test_helper.tcl执行时的基本操作。</p><p></p><h3>test_helper.tcl运行后的基本操作</h3><p>我们可以在test_helper.tcl中查找非proc开头的语句，来了解这个脚本运行后的基本操作。</p><p>实际上，test_helper.tcl运行后主要会执行以下三步操作。</p><p></p><ul>\n<li><strong>第一步，引入其他的tcl脚本文件和定义全局变量</strong></li>\n</ul><p></p><p>test_helper.tcl脚本首先使用source关键字，引入tests目录下support子目录中的redis.tcl、server.tcl等脚本文件。</p><p></p><p>这些脚本文件实现了单元测试框架所需的部分功能，比如server.tcl脚本文件中，就实现了启动Redis测试实例的子函数start_server，而redis.tcl脚本中实现了向测试用Redis实例发送命令的子函数。</p><p></p><p>而除了引入脚本文件之外，第一步操作还包括了定义全局变量。比如，测试框架定义了一个全局变量<code>::all_tests</code>，这个全局变量包含了所有预定义的单元测试。如果我们不加任何参数运行test_helper.tcl时，测试框架就会运行<code>::all_tests</code>定义的所有测试。此外，第一步定义的全局变量，还包括测试用主机IP、端口号、跳过的测试用例集合、单一测试的用例集合，等等。</p><p></p><p>下面的代码展示了这一步执行的部分内容，你可以看下。你也可以在test_helper.tcl文件中，查看所有的引入脚本和定义的全局变量。</p><pre><code class=\"language-plain\">source tests/support/redis.tcl\nsource tests/support/server.tcl\n…\n&nbsp;\nset ::all_tests {\n&nbsp;&nbsp;&nbsp; unit/printver\n&nbsp;&nbsp;&nbsp; unit/dump\n\tunit/auth\n\t… }\n&nbsp;\nset ::host 127.0.0.1&nbsp;\nset ::port 21111\n…\nset ::single_tests {}&nbsp; //单一测试用例集合\n</code></pre><p>了解了引入脚本和全局变量后，我们再来看下test_helper.tcl脚本执行的第二步操作，也就是解析脚本参数。</p><p></p><ul>\n<li><strong>第二步，解析脚本参数</strong></li>\n</ul><p>这一步操作是一个for循环，它会在test_helper.tcl脚本引入其他脚本和定义全局变量后，接着执行。</p><p></p><p>这个循环流程本身并不复杂，它的目的就是逐一解析test_helper.tcl脚本执行时携带的参数。不过想要理解这个流程，你还需要对Tcl语言的开发知识了解更多一些。比如，你要知道llength关键字是用来获取一个列表长度，而lindex是从一个列表中获取某个元素。</p><p></p><p>下面的代码展示了这个循环流程的基本结构，你可以看下其中的注释，这可以帮助你再多了解些Tcl语言开发知识。</p><pre><code class=\"language-plain\">for {set j 0} {$j &lt; [llength $argv]} {incr j} { // 使用llength获取参数列表argv的长度\n&nbsp;&nbsp;&nbsp; set opt [lindex $argv $j]&nbsp; //从argv参数列表中，使用lindex获取第j个参数\n&nbsp;&nbsp;&nbsp; set arg [lindex $argv [expr $j+1]]&nbsp; //从argv参数列表中获取第j+1个参数\n\tif {$opt eq {--tags}} { …}&nbsp;&nbsp;&nbsp;&nbsp; //处理“--tags”参数\n\telseif {$opt eq {--config}} { …}&nbsp; //处理“--config”参数\n\t…\n}\n</code></pre><p>那么，在解析参数过程中，如果test_helper.tcl脚本带有“–single”参数，就表示脚本并不是执行所有测试用例，而只是执行一个或多个测试用例。因此，脚本中的全局变量<code>::single_tests</code>，就会保存这些测试用例，并且把全局变量<code>::all_tests</code>设置为<code>::single_tests</code>的值，表示就执行<code>::single_tests</code>中的测试用例，如下所示：</p><pre><code class=\"language-plain\">if {[llength $::single_tests] &gt; 0} {\n&nbsp;&nbsp;&nbsp; set ::all_tests $::single_tests\n}\n</code></pre><p>好了，在完成了对运行参数的解析后，test_helper.tcl脚本的第三步就是启动实际的测试流程。</p><p></p><ul>\n<li><strong>第三步，启动测试流程</strong></li>\n</ul><p>在这一步，test_helper.tcl脚本会判断全局变量<code>::client</code>的值，而这个值表示是否启动测试客户端。如果<code>::client</code>的值为0，那么就表明当前不是启动测试客户端，因此，test_helper.tcl脚本会来执行test_server_main函数。否则的话，test_helper.tcl脚本会执行test_client_main函数。这部分逻辑如下所示：</p><p></p><pre><code class=\"language-plain\">if {$::client} {&nbsp; //当前是要启动测试客户端\n\tif {[catch { test_client_main $::test_server_port } err]} { //执行test_client_main\n\t…\n\t}\n\telse {&nbsp; //当前不是启动测试客户端\n\t&nbsp;&nbsp; …\n\t&nbsp;&nbsp; if {[catch { test_server_main } err]} { …}&nbsp; //执行test_server_main\n\t}\n}\n</code></pre><p>我在这里画了一张图，展示了&nbsp;test_helper.tcl脚本执行的基本流程，你可以再回顾下。</p><p><img src=\"https://static001.geekbang.org/resource/image/e4/a9/e4f15820ffb3afd24ef2abc543fe36a9.jpg?wh=1920x1080\" alt=\"图片\"></p><p>其实，test_server_main和test_client_main这两个函数都是为了最终启动测试流程的。那么，它们的作用分别是什么呢？下面我们就来了解下。</p><p></p><h3>test_server_main函数</h3><p>test_server_main函数的主要工作包括三步操作。</p><p></p><p><strong>首先，它会使用socket -server命令启动一个测试server。</strong>这个测试server会创建一个socket，监听来自测试客户端的消息。那么，一旦有客户端连接时，测试server会执行accept_test_clients函数。这个过程的代码如下所示：</p><pre><code class=\"language-plain\">socket -server accept_test_clients -myaddr 127.0.0.1 $port\n</code></pre><p>对于accept_test_clients函数来说，它会调用fileevent命令，监听客户端连接上是否有读事件发生。如果有读事件发生，这也就表示客户端有消息发送给测试server。那么，它会执行read_from_test_client函数。这个过程如下所示：</p><pre><code class=\"language-plain\">proc accept_test_clients {fd addr port} {\n&nbsp;&nbsp;&nbsp; …\n&nbsp;&nbsp;&nbsp; fileevent $fd readable [list read_from_test_client $fd]\n}\n</code></pre><p>而read_from_test_client函数，会根据测试客户端发送的不同消息来执行不同的代码分支。比如，当测试客户端发送的消息是“ready”，这就表明当前客户端是空闲的，那么，测试server可以把未完成的测试用例再发给这个客户端执行，这个过程是由signal_idel_client函数来完成的，你可以仔细阅读下它的源码。</p><p></p><p>再比如，当测试客户端发送的消息是“done”时，read_from_test_client函数会统计当前已经完成的测试用例数量，而且也会调用signal_idel_client函数，让当前客户端继续执行未完成的测试用例。关于read_from_test_client函数的不同执行分支，你也可以阅读它的代码来做进一步了解。</p><p></p><p>好了，在test_server_main函数的第一步，它主要是启动了测试server。那么<strong>接下来的第二步，它会开始启动测试客户端。</strong></p><p></p><p>test_server_main函数会执行一个for循环流程，在这个循环流程中，它会根据要启动的测试客户端数量，依次调用exec命令，执行tcl脚本。这里的测试客户端数量是由全局变量<code>::numclients</code>决定的，默认值是16。而执行的tcl脚本，正是当前运行的test_helper.tcl脚本，参数也和当前脚本的参数一样，并且还加上了“–client”参数，表示当前启动的是测试客户端。</p><p></p><p>下面的代码展示了刚才介绍的这个for循环流程，你可以看下。</p><pre><code class=\"language-plain\">for {set j 0} {$j &lt; $::numclients} {incr j} {\n&nbsp;&nbsp; set start_port [find_available_port $start_port] //设定测试客户端端口\n&nbsp;&nbsp; //使用exec命令执行test_helper.tcl脚本（script），脚本参数和当前脚本一致，增加client参数，表示启动的是测试客户端；增加port参数，表示客户端端口\n&nbsp;&nbsp; set p [exec $tclsh [info script] {*}$::argv \\\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; --client $port --port $start_port &amp;]\n&nbsp;&nbsp; lappend ::clients_pids $p&nbsp; //记录每个测试客户端脚本运行的进程号\n&nbsp;&nbsp; incr start_port 10 //递增测试客户端的端口号\n}\n</code></pre><p>这里，你要注意下，当test_helper.tcl脚本运行参数包含“–client”时，它在解析运行参数时，会把全局变量<code>::client</code>设置为1，如下所示：</p><pre><code class=\"language-plain\">for {set j 0} {$j &lt; [llength $argv]} {incr j} {\n&nbsp;&nbsp; …\n&nbsp;&nbsp; elseif {$opt eq {--client}} {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; set ::client 1\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; …\n\t}\n</code></pre><p>这样一来，我们在刚才介绍的循环流程中，执行的这个test_helper.tcl脚本，就会根据全局变量<code>::client</code>的值，实际启动测试客户端，也就是会执行test_client_main函数，如下所示：</p><pre><code class=\"language-plain\">if {$::client} {&nbsp; //如果::client值为1，那么执行test_client_main函数\n\tif {[catch { test_client_main $::test_server_port } err]} {…}\n}\n</code></pre><p>那么，在启动了测试客户端后，<strong>test_server_main函数的最后一步，就是每隔10s周期性地执行一次test_server_cron函数。</strong>而这个函数的主要工作是，当测试执行超时的时候，输出报错信息，并清理测试客户端和测试server。</p><p></p><p>好了，到这里，你就了解了测试server的执行函数test_server_main，主要是启动socket等待客户端连接和处理客户端消息，以及启动测试客户端。下图展示了test_server_main函数的基本流程，你可以再回顾下。</p><p><img src=\"https://static001.geekbang.org/resource/image/8e/0e/8e04995a359e109480a2183101ea1e0e.jpg?wh=1920x866\" alt=\"图片\"></p><p>那么接下来，我再带你来看下测试客户端对应的执行函数test_client_main。</p><p></p><h3>test_client_main函数</h3><p>test_client_main函数在执行时，会先向测试server发送一个“ready”的消息。而刚才我提到，测试server一旦监听到有客户端连接发送了“ready”消息，它就会通过<strong>signal_idle_client函数</strong>，把未完成的单元测试发送给这个客户端。</p><p></p><p>具体来说，signal_idle_client函数会发送“run 测试用例名”这样的消息给客户端。比如，当前未完成的测试用例是unit/type/string，那么signal_idle_client函数就会发送“run unit/type/string”消息给测试客户端。你也可以看看下面的代码：</p><pre><code class=\"language-plain\">send_data_packet $fd run [lindex $::all_tests $::next_test] //从::all_tests中取出下一个未测试的用例，发送给客户端，发送消息为“run 测试用例名”\n</code></pre><p>那么，当test_client_main函数在发送了“ready”消息之后，就会执行一个while循环流程，等待从测试server读取消息。等它收到测试server返回的“run 测试用例名”的消息时，它就会调用execute_tests函数，执行相应的测试用例。</p><p></p><p>下面的代码展示了刚才介绍的test_client_main函数的基本执行过程，你可以看下。</p><pre><code class=\"language-plain\">proc test_client_main fd {\n…\nsend_data_packet $::test_server_fd ready [pid] //向测试server发送ready消息\n&nbsp;&nbsp;&nbsp; while 1 {&nbsp;&nbsp; //读取测试server发送的单元测试信息\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; …\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; set payload [read $::test_server_fd $bytes]&nbsp; //读取测试server的消息\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; foreach {cmd data} $payload break //cmd为测试server发送的命令，data为cmd命令后的消息内容\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if {$cmd eq {run}} {&nbsp; //如果消息中有“run”命令\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; execute_tests $data&nbsp;&nbsp; //调用execute_tests执行data对应的测试用例\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }\n…}\n</code></pre><p>然后这里，我们再来看下<strong>执行测试用例的execute_tests函数</strong>。这个函数比较简单，它就是根据传入的测试用例名，用source命令把tests目录下，该用例对应的tcl脚本文件引入并执行。最后，给测试server发送“done”的消息。</p><p>这部分代码如下所示：</p><pre><code class=\"language-plain\">proc execute_tests name {\n&nbsp;&nbsp;&nbsp; set path \"tests/$name.tcl\"&nbsp; //在tests目录下找到对应测试用例文件\n&nbsp;&nbsp;&nbsp; set ::curfile $path\n&nbsp;&nbsp;&nbsp; source $path&nbsp; //引入并执行测试用例的脚本文件\n&nbsp;&nbsp;&nbsp; send_data_packet $::test_server_fd done \"$name\" //测试用例执行完后，发送“done”消息给测试server\n}\n</code></pre><p>从这里我们能发现，单元测试框架在测试时，其实就是执行每个测试用例的tcl脚本文件，这也就是说，每个测试用例对应的测试内容在它的测试脚本中都已经编写好了，框架直接执行测试脚本就行。</p><p></p><p>那么，下面我们就来看看测试用例的实现。</p><p></p><h3>测试用例的实现</h3><p>Redis单元测试框架中的测试用例有很多，在刚才介绍的全局变量<code>::all_tests</code>中都有定义。这里，我们以针对String数据类型的测试用例<strong>unit/type/string</strong>为例，来了解下框架中测试用例的开发实现。</p><p></p><p>unit/type/string测试用例对应的测试脚本是string.tcl。这个脚本<strong>首先会调用start_server函数</strong>，启动一个测试用Redis实例，而start_server函数是在server.tcl文件中定义的，你可以进一步阅读这个函数的源码了解它的实现。</p><p></p><p><strong>然后，测试脚本会分别测试不同的测试项</strong>，它会调用r函数来给测试用的Redis实例发送具体的命令。比如，在下面的代码中，测试脚本就发送测试了set和get两个命令。</p><pre><code class=\"language-plain\">start_server {tags {\"string\"}} {\n&nbsp;&nbsp;&nbsp; test {SET and GET an item} {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; r set x foobar\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; r get x\n\t} {foobar}\n\t…\n}\n</code></pre><p>那么，这里发送测试命令的<strong>r函数</strong>（在test_helper.tcl文件中），它其实会通过srv函数（在test_helper.tcl文件中），从框架配置中获取名为<code>::redis::redisHandle</code>的函数。</p><p>而这个<code>::redis::redisHandle</code>函数，是在redis.tcl文件中先和<code>::redis::__dispatch__</code>函数进行了关联，表示由<code>::redis::__dispatch__</code>函数来执行。不过，<code>::redis::__dispatch__</code>函数会进一步调用<code>::redis::__dispatch__raw__</code>函数，来实际发送测试命令。</p><p></p><p>这里，你需要注意的是，刚才介绍的这三个函数名中都会带有<strong>id号</strong>。这个id号是脚本在运行过程中动态赋值的，并且它表示的是，测试命令要发送的测试用Redis实例的socket描述符。</p><p></p><p>下面的代码展示了<code>::redis::redisHandle</code>函数的关联定义，以及<code>::redis::__dispatch__</code>函数的基本定义，你可以看下。</p><pre><code class=\"language-plain\">proc redis {{server 127.0.0.1} {port 6379} {defer 0}} {\n…\ninterp alias {} ::redis::redisHandle$id {} ::redis::__dispatch__ $id\n}\n&nbsp;\nproc ::redis::__dispatch__ {id method args} {\n\tset errorcode [catch {::redis::__dispatch__raw__ $id $method $args} retval]\n\t…\n}\n</code></pre><p>到这里，我们就知道<strong>最终实际发送测试命令的，其实是<code>::redis::__dispatch__raw__</code>函数</strong>，这个函数会按照RESP协议封装Redis命令，并发送给测试用的Redis实例，你可以看看下面的代码。</p><pre><code class=\"language-plain\">proc ::redis::__dispatch__raw__ {id method argv} {\nset fd $::redis::fd($id)&nbsp; //获取要发送的测试用Redis实例的socket描述符\n…\n//按照RESP协议封装Redis命令\nset cmd \"*[expr {[llength $argv]+1}]\\r\\n\"&nbsp; //封装命令及参数个数\nappend cmd \"$[string length $method]\\r\\n$method\\r\\n\" //封装命令名称\nforeach a $argv {&nbsp; //封装命令参数\n&nbsp;&nbsp; append cmd \"$[string length $a]\\r\\n$a\\r\\n\"\n}\n::redis::redis_write $fd $cmd&nbsp; //向测试用Redis实例发送测试命令\n…}\n</code></pre><p>这样一来，测试客户端就可以把测试用例中的命令发送给测试实例，并根据返回结果判断测试是否正常执行了。</p><p>我在画了一张图，展示了测试server、测试客户端和测试用例的交互，以及它们在测试框架中各自的主要职责，你可以再整体回顾下。</p><p><img src=\"https://static001.geekbang.org/resource/image/50/21/5038488c2eea78507e3aab07c4ea4321.jpg?wh=1920x1080\" alt=\"图片\"></p><h2>小结</h2><p>今天这节课，我们学习了Redis的单元测试框架。这个测试框架是用Tcl语言开发的，所以，在学习这个框架前，我们需要先掌握一些Tcl语言的开发基础知识。因为Tcl语言本身的数据类型比较简单，所以学习Tcl语言，主要就是了解它使用的众多的关键字命令。这也是你接下来可以重点去学习的内容。</p><p></p><p>而在单元测试框架的实现中，主要是包括了三个角色，分别是<strong>测试server、测试客户端和测试用例</strong>，它们之间的关系是这样的：</p><ul>\n<li>测试server启动后，负责启动测试客户端，并和测试客户端交互，通过“run 测试用例名”消息向测试客户端发送测试用例。</li>\n<li>测试客户端和测试server建立连接后，会向server发送“ready”消息。在接收到server发送的“run 测试用例名”消息后，客户端通过execute_tests函数引入并执行对应的测试脚本。</li>\n<li>测试脚本会通过start_server函数，启动测试用的Redis实例，然后使用测试客户端提供的r函数向测试实例发送测试命令，而r函数实际会调用<code>::redis::__dispatch__raw__</code>函数，来完成命令发送。</li>\n</ul><p></p><p>最后，我也想再提醒你一下，如果你想要进一步深入学习和掌握Redis单元测试框架的话，一定要厘清刚才总结的测试server、测试客户端和测试用例的关系，这样你才能理解整个测试过程是如何进行的。另外，因为Tcl语言的开发比较简单，所以你在学习了Redis单元测试框架后，也可以参考它实现自己的测试框架。</p><p></p><h2>每课一问</h2><p>Redis源码中还有一个针对SDS的小型测试框架，你知道这个测试框架是在哪个代码文件中吗？</p>","neighbors":{"left":{"article_title":"31 | 从Module的实现学习动态扩展功能","id":428471},"right":{"article_title":"答疑1 | 第1~6讲课后思考题答案及常见问题答疑","id":429370}}},{"article_id":429370,"article_title":"答疑1 | 第1~6讲课后思考题答案及常见问题答疑","article_content":"<p>你好，我是蒋德钧。</p><p>咱们的课程已经快接近尾声了，之前我主要把精力和时间集中在了课程内容的准备上，没有来得及及时给大家做答疑，以及回复同学们提出的问题，在这也和同学们说一声抱歉，接下来我会尽快来回复大家的疑问。但其实，在这期间我看到了很多同学的留言，既有针对咱们课程课后思考题的精彩解答，也有围绕课程内容本身提出的关键问题，而且这些问题的质量很高，非常值得好好讨论一下。</p><p></p><p>那么，今天这节课，我就先来对课程的前6节的思考题做一次答疑。你也可以借此机会再来回顾下咱们课程一开始时学习的内容，温故而知新。</p><p></p><h2><a href=\"https://time.geekbang.org/column/article/399866\">第1讲</a></h2><p><strong>问题：Redis从4.0版本开始，能够支持后台异步执行任务，比如异步删除数据，那么你能在Redis功能源码中，找到实现后台任务的代码文件吗？</strong></p><p></p><p>关于这个问题，@悟空聊架构、@小五、@Kaito等不少同学都给出了正确答案。我在这些同学回答的基础上，稍微做了些完善，你可以参考下。</p><p>Redis支持三类后台任务，它们本身是在<a href=\"https://github.com/redis/redis/tree/5.0/src/bio.h\">bio.h</a>文件中定义的，如下所示：</p><pre><code class=\"language-plain\">#define BIO_CLOSE_FILE&nbsp;&nbsp;&nbsp; 0 &nbsp;&nbsp;&nbsp;//后台线程关闭文件\n#define BIO_AOF_FSYNC&nbsp;&nbsp;&nbsp;&nbsp; 1 &nbsp;&nbsp;//后台线程刷盘\n#define BIO_LAZY_FREE&nbsp;&nbsp;&nbsp;&nbsp; 2&nbsp;&nbsp; //后台线程释放内存\n</code></pre><!-- [[[read_end]]] --><p>那么，在Redis server启动时，入口main函数会调用InitServerLast函数，而InitServerLast函数会调用bioInit函数，来创建这三类后台线程。这里的bioInit函数，则是在<a href=\"https://github.com/redis/redis/tree/5.0/src/bio.c\">bio.c</a>文件中实现的。</p><p></p><p>而对于这三类后台任务的执行来说，它们是在bioProcessBackgroundJobs函数（在bio.c文件中）中实现的。其中，BIO_CLOSE_FILE和BIO_AOF_FSYNC这两类后台任务的实现代码，分别对应了close函数和redis_fysnc函数。而BIO_LAZY_FREE任务根据参数不同，对应了lazyfreeFreeObjectFromBioThread、lazyfreeFreeDatabaseFromBioThread和lazyfreeFreeSlotsMapFromBioThread三处实现代码。而这些代码都是在<a href=\"https://github.com/redis/redis/tree/5.0/src/lazyfree.c\">lazyfree.c</a>文件中实现。</p><p></p><p>此外，还有一些同学给出了异步删除数据的执行流程和涉及函数，比如，@曾轼麟同学以unlink为例，列出了删除操作涉及的两个执行流程，我在这里也分享下。</p><p>unlink实际代码的执行流程如下所示：</p><ul>\n<li>使用异步删除时的流程：unlinkCommand -&gt; delGenericCommand -&gt; dbAsyncDelete -&gt; dictUnlink -&gt; bioCreateBackgroundJob创建异步删除任务 -&gt; 后台异步删除。</li>\n<li>不使用异步删除时的流程：unlinkCommand -&gt; delGenericCommand -&gt; dbAsyncDelete -&gt; dictUnlink -&gt; dictFreeUnlinkedEntry直接释放内存。</li>\n</ul><p></p><p>此外，@悟空聊架构同学还提到了在Redis 6.0中增加的IO多线程。不过，Redis 6.0中的多IO线程，主要是为了利用多核并行读取数据、解析命令，以及写回数据，这些线程其实是和主线程一起工作的，所以我通常还是把它们看作前台的工作线程。</p><p></p><h2><a href=\"https://time.geekbang.org/column/article/400314\">第2讲</a></h2><p><strong>问题：SDS字符串在Redis内部模块实现中也被广泛使用，你能在Redis server和客户端的实现中，找到使用SDS字符串的地方吗？</strong></p><p></p><p>我们可以直接在全局变量server对应的结构体redisServer中，查找使用sds进行定义的成员变量，其代码如下所示：</p><pre><code class=\"language-plain\">struct redisServer {\n…\nsds aof_buf;\nsds aof_child_diff;\n…}\n</code></pre><p>同样，我们可以在客户端对应的结构体client中查找sds定义的成员变量，如下代码所示：</p><pre><code class=\"language-plain\">typedef struct client {\n…\nsds querybuf;\nsds pending_querybuf;\nsds replpreamble;\nsds peerid;\n…} client;\n</code></pre><p>此外，你也要注意的是，在Redis中，<strong>键值对的key也都是SDS字符串</strong>。在执行将键值对插入到全局哈希表的函数dbAdd（在db.c文件）中的时候，键值对的key会先被创建为SDS字符串，然后再保存到全局哈希表中，你可以看看下面的代码。</p><pre><code class=\"language-plain\">void dbAdd(redisDb *db, robj *key, robj *val) {\n&nbsp;&nbsp;&nbsp; sds copy = sdsdup(key-&gt;ptr);&nbsp; //根据redisObject结构中的指针获得实际的key，调用sdsdup将其创建为一个SDS字符串\n\tint retval = dictAdd(db-&gt;dict, copy, val); //将键值对插入哈希表\n\t…\n}\n</code></pre><p></p><h2><a href=\"https://time.geekbang.org/column/article/400379\">第3讲</a></h2><p><strong>问题：Hash函数会影响Hash表的查询效率及哈希冲突情况，那么，你能从Redis的源码中，找到Hash表使用的是哪一种Hash函数吗？</strong></p><p>关于这个问题，@Kaito、@陌、@可怜大灰狼、@曾轼麟等不少同学都找到了Hash函数的实现，在这里我也总结下。</p><p>其实，我们在查看哈希表的查询函数dictFind时，可以看到它会调用dictHashKey函数，来计算键值对key的哈希值，如下所示：</p><pre><code class=\"language-plain\">dictEntry&nbsp;*dictFind(dict&nbsp;*d,&nbsp;const&nbsp;void&nbsp;*key)&nbsp;{\n    ...\n&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;计算&nbsp;key&nbsp;的哈希值\n&nbsp;&nbsp;&nbsp;&nbsp;h&nbsp;=&nbsp;dictHashKey(d,&nbsp;key);\n&nbsp;&nbsp;&nbsp;&nbsp;...\n}\n</code></pre><p>那么，我们进一步看dictHashKey函数，可以发现它是在dict.h文件中定义的，如下所示：</p><pre><code class=\"language-plain\">#define dictHashKey(d, key) (d)-&gt;type-&gt;hashFunction(key)\n</code></pre><p>从代码可以看到，dictHashKey函数会实际执行哈希表类型相关的hashFunction，来计算key的哈希值。所以，这实际上就和哈希表结构体中的type有关了。<br>\n这里，我们来看看哈希表对应的数据结构dict的定义，如下所示：</p><pre><code class=\"language-plain\">typedef struct dict {\n&nbsp; &nbsp; dictType *type;\n&nbsp;   ...\n} dict;\n</code></pre><p>dict结构体中的成员变量type类型是dictType结构体，而dictType里面，包含了哈希函数的函数指针hashFunction。</p><pre><code class=\"language-plain\">typedef struct dictType {\n&nbsp; &nbsp; uint64_t (*hashFunction)(const void *key);\n&nbsp; &nbsp; ...\n} dictType;\n</code></pre><p>那么，既然dictType里面有哈希函数的指针，所以比较直接的方法，就是去看哈希表在初始化时，是否设置了dictType中的哈希函数。</p><p>在Redis server初始化函数initServer中，会对数据库中的主要结构进行初始化，这其中就包括了对全局哈希表的初始化，如下所示：</p><pre><code class=\"language-plain\">void initServer(void) {\n...\nfor (j = 0; j &lt; server.dbnum; j++) {\n&nbsp; &nbsp; &nbsp; &nbsp; server.db[j].dict = dictCreate(&amp;dbDictType,NULL);  //初始化全局哈希表\n        ...}\n}\n</code></pre><p>从这里，你就可以看到<strong>全局哈希表对应的哈希表类型是dbDictType</strong>，而dbDictType是在<a href=\"https://github.com/redis/redis/tree/5.0/src/server.c\">server.c</a>文件中定义的，它设置的哈希函数是dictSdsHash（在server.c文件中），如下所示：</p><pre><code class=\"language-plain\">dictType dbDictType = {\n&nbsp; &nbsp; dictSdsHash,&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; //哈希函数\n&nbsp; &nbsp; ...\n};\n</code></pre><p>我们再进一步查看dictSdsHash函数的实现，可以发现它会调用dictGenHashFunction函数（在dict.c文件中），而dictGenHashFunction函数又会进一步调用siphash函数（在siphash.c文件中）来实际执行哈希计算。所以到这里，我们就可以知道全局哈希表使用的哈希函数是<strong>siphash</strong>。</p><p>下面的代码展示了dictSdsHash函数及其调用的关系，你可以看下。</p><pre><code class=\"language-plain\">uint64_t dictSdsHash(const void *key) {\n&nbsp; &nbsp; return dictGenHashFunction((unsigned char*)key, sdslen((char*)key));\n}\n\nuint64_t dictGenHashFunction(const void *key, int len) {\n&nbsp; &nbsp; return siphash(key,len,dict_hash_function_seed);\n}\n</code></pre><p>其实，Redis源码中很多地方都使用到了哈希表，它们的类型有所不同，相应的它们使用的哈希函数也有区别。在server.c文件中你可以看到有很多哈希表类型的定义，这里面就包含了不同类型哈希表使用的哈希函数，你可以进一步阅读源码看看。以下代码也展示了一些哈希表类型的定义，你可以看下。</p><pre><code class=\"language-plain\">dictType objectKeyPointerValueDictType = {\n&nbsp; &nbsp; dictEncObjHash,\n    ...\n}\n\ndictType setDictType = {\n&nbsp; &nbsp; dictSdsHash,\n    ...\n}\n\ndictType commandTableDictType = {\n&nbsp; &nbsp; dictSdsCaseHash,&nbsp;\n    ...\n}\n</code></pre><h2><a href=\"https://time.geekbang.org/column/article/402223\">第4讲</a></h2><p><strong>问题：SDS判断是否使用嵌入式字符串的条件是44字节，你知道为什么是44字节吗？</strong></p><p></p><p>这个问题，不少同学都是直接分析了redisObject和SDS的数据结构，作出了正确的解答。从留言中，也能看到同学们对Redis代码的熟悉程度是越来越高了。这里，我来总结下。</p><p></p><p>嵌入式字符串本身会把redisObject和SDS作为一个连续区域来分配内存，而就像@曾轼麟同学在解答时提到的，我们在考虑内存分配问题时，需要了解<strong>内存分配器的工作机制</strong>。那么，对于Redis使用的jemalloc内存分配器来说，它为了减少内存碎片，并不会按照实际申请多少空间就分配多少空间。</p><p>其实，jemalloc会根据申请的字节数N，找一个比N大，但是最接近N的2的幂次数来作为实际的分配空间大小，这样一来，既可以减少内存碎片，也能避免频繁的分配。在使用jemalloc时，它的常见分配大小包括8、16、32、64等字节。</p><p></p><p>对于redisObject来说，它的结构体是定义在<a href=\"https://github.com/redis/redis/tree/5.0/src/server.h\">server.h</a>文件中，如下所示：</p><pre><code class=\"language-plain\">typedef struct redisObject {\n&nbsp;&nbsp;&nbsp; unsigned type:4;&nbsp; &nbsp;// 4 bits\n&nbsp;&nbsp;&nbsp; unsigned encoding:&nbsp; &nbsp;//4 bits\n&nbsp;&nbsp;&nbsp; unsigned lru:LRU_BITS;&nbsp; //24 bits\n&nbsp;&nbsp;&nbsp; int refcount;&nbsp; //4字节\n&nbsp;&nbsp;&nbsp; void *ptr;&nbsp; &nbsp;//8字节\n} robj;\n</code></pre><p>从代码中可以看到，redisObject本身占据了16个字节的空间大小。而嵌入式字符串对应的SDS结构体sdshdr8，它的成员变量len、alloc和flags一共占据了3个字节。另外它包含的字符数组buf中，还会包括一个结束符“\\0”，占用1个字符。所以，这些加起来一共是4个字节。</p><pre><code class=\"language-plain\">struct __attribute__ ((__packed__)) sdshdr8 {\n&nbsp; &nbsp; uint8_t len;       // 1字节\n&nbsp; &nbsp; uint8_t alloc;    // 1字节\n&nbsp; &nbsp; unsigned char flags; // 1字节\n&nbsp; &nbsp; char buf[];   //字符数组末尾有一个结束符，占1个字节\n};\n</code></pre><p>对于嵌入式字符串来说，jemalloc给它分配的最大大小是64个字节，而这其中，redisObject、sdshdr结构体元数据和字符数组结束符，已经占了20个字节，所以这样算下来，嵌入式字符串剩余的空间大小，最大就是44字节了（64-20=44）。这也是SDS判断是否使用嵌入式字符串的条件是44字节的原因。</p><h2><a href=\"https://time.geekbang.org/column/article/404391\">第5讲</a></h2><p><strong>问题：在使用跳表和哈希表相结合的双索引机制时，在获得高效范围查询和单点查询的同时，你能想到这种双索引机制有哪些不足之处吗？</strong></p><p></p><p>其实，对于双索引机制来说，它的好处很明显，就是可以充分利用不同索引机制的访问特性，来提供高效的数据查找。但是，双索引机制的不足也比较明显，它要占用的空间比单索引要求的更多，这也是因为它需要维护两个索引结构，难以避免会占用较多的内存空间。</p><p>我看到有不少同学都提到了“以空间换时间”这一设计选择，我能感觉到大家已经开始注意透过设计方案，去思考和抓住设计的本质思路了，这一点非常棒！<strong>因为很多优秀的系统设计，其实背后就是计算机系统中很朴素的设计思想。</strong>如果你能有意识地积累这些设计思想，并基于这些思想去把握自己的系统设计核心出发点，那么，这可以让你对系统的设计和实现有一个更好的全局观，在你要做设计取舍时，也可以帮助你做决断。</p><p>就像这里的“以空间换时间”的设计思想，本身很朴素。而一旦你能抓住这个本质思想后，就可以根据自己系统对内存空间和访问时间哪一个要求更高，来决定是否采用双索引机制。</p><p>不过，这里我也想再提醒你<strong>注意一个关键点</strong>：对于双索引结构的更新来说，我们需要保证两个索引结构的一致性，不能出现一个索引结构更新了，而另一个索引没有相应的更新。比如，我们只更新了Hash，而没有更新跳表。这样一来，就会导致程序能在哈希上找到数据，但是进行范围查询时，就没法在跳表上找到相应的数据了。</p><p>对于Redis来说，因为它的主线程是单线程，而且它的索引结构本身是不做持久化的，所以双索引结构的一致性保证问题在Redis中不明显。但是，一旦在多线程的系统中，有多个线程会并发操作访问双索引时，这个一致性保证就显得很重要了。</p><p>如果我们采用同步的方式更新两个索引结构，这通常会对两个索引结构做加锁操作，保证更新的原子性，但是这会阻塞并发访问的线程，造成整体访问性能下降。不过，如果我们采用异步的方式更新两个索引结构，这会减少对并发线程的阻塞，但是可能导致两个索引结构上的数据不一致，而出现访问出错的情况。所以，在多线程情况下对双索引的更新是要重点考虑的设计问题。</p><p>另外，在同学们的解答中，我还看到@陌同学提到了一个观点，他把skiplist + hash实现的有序集合和double linked list + hash实现的LRU管理，进行了类比。其实，对LRU来说，它是使用链表结构来管理LRU链上的数据，从而实现LRU所要求的，数据根据访问时效性进行移动。而与此同时，使用的Hash可以帮助程序能在O(1)的时间复杂度内获取数据，从而加速数据的访问。</p><p>我觉得@陌同学的这个关联类比非常好，这本身也的确是组合式多数据结构协作，完成系统功能的一个典型体现。</p><p></p><h2><a href=\"https://time.geekbang.org/column/article/405387\">第6讲</a></h2><p><strong>问题：ziplist会使用zipTryEncoding函数，计算插入元素所需的新增内存空间。那么，假设插入的一个元素是整数，你知道ziplist能支持的最大整数是多大吗？</strong></p><p>ziplist的zipTryEncoding函数会判断整数的长度，如果整数长度大于等于32位时，zipTryEncoding函数就不将其作为整数计算长度了，而是作为字符串来计算长度了，所以最大整数是2的32次方。这部分代码如下所示：</p><pre><code class=\"language-plain\">int zipTryEncoding(unsigned char *entry, unsigned int entrylen, long long *v, unsigned char *encoding) {\n\t…\n\t//如果插入元素的长度entrylen大于等于32，直接返回0，表示将插入元素作为字符串处理\n\tif (entrylen &gt;= 32 || entrylen == 0) return 0;\n\t…\n}\n</code></pre><h2>小结</h2><p>好了，今天这节课就到这里。在前6讲中，我主要是给你介绍了Redis的数据结构，要想掌握好这几讲的内容，一个关键点是，你要理解这些数据结构本身的组成和操作，这样你在看代码时，才能结合着数据结构本身的设计来理解代码的设计和实现，从而获得更高的代码阅读效率。</p><p>非常感谢你对课后思考题的仔细思考和认真解答。在看留言的过程中，我从大家的答复中看到了更加全面或是更加深入的代码解读，我自己受益匪浅。接下来，我还会针对剩余的课后思考题，以及同学们的提问来做解答。也希望你将仍然存在的疑问提到留言区，我们来一起交流讨论。</p><p>让我们将学习进行到底！</p>","neighbors":{"left":{"article_title":"32 | 如何在一个系统中实现单元测试？","id":428474},"right":{"article_title":"答疑2 | 第7~12讲课后思考题答案及常见问题答疑","id":431791}}},{"article_id":431791,"article_title":"答疑2 | 第7~12讲课后思考题答案及常见问题答疑","article_content":"<p>你好，我是蒋德钧。</p><p>在今天的答疑中，我除了会解答课程之前的思考题以外，还会带你再进一步了解和数据结构设计、进程管理、高性能线程模型、IO复用、预定义宏等相关的开发知识。希望你能通过这节课的答疑，进一步扩展你的知识面。</p><p></p><h2><a href=\"https://time.geekbang.org/column/article/406284\">第7讲</a></h2><p><strong>问题：作为有序索引，Radix Tree也能提供范围查询，那么与我们日常使用的B+树，以及</strong><a href=\"https://time.geekbang.org/column/article/404391\">第5讲</a><strong>中介绍的跳表相比，你觉得Radix Tree有什么优势和不足吗？</strong></p><p></p><p>对于这道题，有不少同学比如@Kaito、@曾轼麟等同学，都对Radix Tree、B+树和跳表做了对比，这里我就来总结一下。</p><p><strong>Radix Tree的优势</strong></p><ul>\n<li>因为Radix Tree是前缀树，所以，当保存数据的key具有相同前缀时，Radix Tree会在不同的key间共享这些前缀，这样一来，和B+树、跳表相比，就节省内存空间。</li>\n<li>Radix Tree在查询单个key时，其查询复杂度O(K)只和key的长度k有关，和现存的总数据量无关。而B+树、跳表的查询复杂度和数据规模有关，所以Radix Tree查询单个key的效率要高于B+树、跳表。</li>\n<li>Radix Tree适合保存大量具有相同前缀的数据。比如一个典型场景，就是Linux内核中的page cache，使用了Radix Tree保存文件内部偏移位置和缓存页的对应关系，其中树上的key就是文件中的偏移值。</li>\n</ul><!-- [[[read_end]]] --><p></p><p><strong>Radix Tree的不足</strong></p><ul>\n<li>一般在实现Radix Tree时，每个叶子节点就保存一个key，它的范围查询性能没有B+树和跳表好。这是因为B+树，它的叶子节点可以保存多个key，而对于跳表来说，它可以遍历有序链表。因此，它们可以更快地支持范围查询。</li>\n<li>Radix Tree的原理较为复杂，实现复杂度要高于B+ 树和跳表。</li>\n</ul><p></p><h2><a href=\"https://time.geekbang.org/column/article/406556\">第8讲</a></h2><p><strong>问题：</strong><strong>Redis源码的main函数在调用initServer函数之前，会执行如下的代码片段，你知道这个代码片段的作用是什么吗？</strong></p><pre><code class=\"language-plain\">int main(int argc, char **argv) {\n...\nserver.supervised = redisIsSupervised(server.supervised_mode);\nint background = server.daemonize &amp;&amp; !server.supervised;\nif (background) daemonize();\n...\n}\n</code></pre><p>这段代码的目的呢，是先检查Redis是否设置成让upstart或systemd这样的系统管理工具，来启停Redis。这是由<strong>redisIsSupervised函数</strong>，来检查redis.conf配置文件中的supervised选项，而supervised选项的可用配置值，包括no、upstart、systemd、auto，其中no就表示不用系统管理工具来启停Redis，其他选项会用系统管理工具。</p><p>而如果Redis没有设置用系统管理工具，同时又设置了使用守护进程方式（对应配置项daemonize=yes，server.daemonize值为1），那么，这段代码就调用<strong>daemonize函数</strong>以守护进程的方式，启动Redis。</p><p></p><h2><a href=\"https://time.geekbang.org/column/article/407901\">第9讲</a></h2><p><strong>问题：</strong><strong>在Redis事件驱动框架代码中，分别使用了Linux系统上的select和epoll两种机制，<strong><strong>你知道为什么</strong></strong>Redis没有使用poll这一机制吗？</strong></p><p></p><p>这道题呢，主要是希望你对select和poll这两个IO多路复用机制，有进一步的了解。课程的留言区中有不少同学也都回答正确了，我在这里说下我的答案。</p><p>select机制的本质，是<strong>阻塞式监听存放文件描述符的集合</strong>，当监测到有描述符就绪时，select会结束监测返回就绪的描述符个数。而select机制的不足有两个：一是它对单个进程能监听的描述符数量是有限制的，默认是1024个；二是即使select监测到有文件描述符就绪，程序还是需要线性扫描描述符集合，才能知道具体是哪些文件描述符就绪了。</p><p></p><p>而poll机制相比于select机制，本质其实没有太大区别，它只是把select机制中文件描述符数量的限制给取消了，允许进程一次监听超过1024个描述符。<strong>在线性扫描描述符集合获得就绪的具体描述符这个操作上，poll并没有优化改进。</strong>所以，poll相比select改进比较有限。而且，就像@可怜大灰狼、@Kaito等同学提到的，select机制的兼容性好，可以在Linux和Windows上使用。</p><p></p><p>也正是因为poll机制改进有限，而且它对运行平台的支持度不及select，所以Redis的事件驱动框架就没有使用poll机制。在Linux上，事件驱动框架直接使用了epoll，而在Windows上，框架则使用的是select。</p><p>不过，这里你也要注意的是，Redis的ae.c文件实现了<strong>aeWait函数</strong>，这个函数实际会使用poll机制来监测文件描述符。而aeWait函数会被rewriteAppendOnlyFile函数（在aof.c文件中）和migrateGetSocket函数（在cluster.c文件中）调用。@可怜大灰狼同学在回答思考题时，就提到了这一点。</p><p></p><p>此外，在解答这道题的时候，@Darren、@陌等同学还进一步回答了epoll机制的实现细节，我在这里也简单总结下他们的答案，分享给你。</p><p>当某进程调用epoll_create方法时，Linux内核会创建一个eventpoll结构体，这个结构体中包含了一个红黑树rbr和一个双链表rdlist，如下所示：</p><pre><code class=\"language-plain\">struct eventpoll{\n&nbsp;&nbsp;&nbsp; //红黑树的根节点，树中存放着所有添加到epoll中需要监控的描述符\n&nbsp;&nbsp;&nbsp; struct rb_root rbr;\n&nbsp;&nbsp;&nbsp; //双链表中存放着已经就绪的描述符，会通过epoll_wait返回给调用程序\n&nbsp;&nbsp;&nbsp; struct list_head rdlist;\n&nbsp;&nbsp;&nbsp; ...\n}\n</code></pre><p>epoll_create创建了eventpoll结构体后，程序调用epoll_ctl函数，添加要监听的文件描述符时，这些描述符会被保存在红黑树上。<br>\n同时，当有描述符上有事件发生时，一个名为ep_poll_callback的函数会被调用。这个函数会把就绪的描述符添加到rdllist链表中。而epoll_wait函数，会检查rdlist链表中是否有描述符添加进来。如果rdlist链表不为空，那么epoll_wait函数，就会把就绪的描述符返回给调用程序了。</p><p></p><h2><a href=\"https://time.geekbang.org/column/article/408491\">第10讲</a></h2><p><strong>问题：这节课我们学习了Reactor模型，除了Redis，你还了解什么软件系统使用了Reactor模型吗？</strong></p><p></p><p>对于这道题，不少同学都给出了使用Reactor模型的其他软件系统，比如@Darren、@Kaito、@曾轼麟、@结冰的水滴等同学。那么，使用Reator模型的常见软件系统，实际上还包括Netty、Nginx、Memcached、Kafka等等。</p><p></p><p>在解答这道题的时候，我看到@Darren同学做了很好的扩展，回答了Reactor模型的三种类型。在这里，我也总结下分享给你。</p><ul>\n<li><strong>类型一：单reactor单线程</strong></li>\n</ul><p>在这个类型中，Reactor模型中的reactor、acceptor和handler的功能都是由一个线程来执行的。reactor负责监听客户端事件，一旦有连接事件发生，它会分发给acceptor，由acceptor负责建立连接，然后创建一个handler，负责处理连接建立后的事件。如果是有非连接的读写事件发生，reactor将事件分发给handler进行处理。handler负责读取客户端请求，进行业务处理，并最终给客户端返回结果。Redis就是典型的单reactor单线程类型。</p><p></p><ul>\n<li><strong>类型二：单reactor多线程</strong></li>\n</ul><p>在这个类型中，reactor、acceptor和handler的功能由一个线程来执行，与此同时，会有一个线程池，由若干worker线程组成。在监听客户端事件、连接事件处理方面，这个类型和单rector单线程是相同的，但是不同之处在于，在单reactor多线程类型中，handler只负责读取请求和写回结果，而具体的业务处理由worker线程来完成。</p><p></p><ul>\n<li><strong>类型三：主-从Reactor多线程</strong></li>\n</ul><p>在这个类型中，会有一个主reactor线程、多个子reactor线程和多个worker线程组成的一个线程池。其中，主reactor负责监听客户端事件，并在同一个线程中让acceptor处理连接事件。一旦连接建立后，主reactor会把连接分发给子reactor线程，由子reactor负责这个连接上的后续事件处理。</p><p>那么，子reactor会监听客户端连接上的后续事件，有读写事件发生时，它会让在同一个线程中的handler读取请求和返回结果，而和单reactor多线程类似，具体业务处理，它还是会让线程池中的worker线程处理。刚才介绍的Netty使用的就是这个类型。</p><p></p><p>我在下面画了三张图，展示了刚才介绍的三个类型的区别，你可以再整体回顾下。</p><p><img src=\"https://static001.geekbang.org/resource/image/20/89/209f9f5a83a6667c600b4cac7c03a189.jpg?wh=1388x648\" alt=\"图片\"><img src=\"https://static001.geekbang.org/resource/image/e4/41/e46d61c855b7658499439d03d1992f41.jpg?wh=1650x983\" alt=\"图片\"><img src=\"https://static001.geekbang.org/resource/image/d7/c3/d7e36a34a7538854f74227f0fc1289c3.jpg?wh=1694x1125\" alt=\"图片\"></p><h2><a href=\"https://time.geekbang.org/column/article/408857\">第11讲</a></h2><p><strong>问题：已知，Redis事件驱动框架的aeApiCreate、aeApiAddEvent等等这些函数，是对操作系统提供的IO多路复用函数进行了封装，具体的IO多路复用函数分别是在</strong><a href=\"https://github.com/redis/redis/tree/5.0/src/ae_epoll.c\">ae_epoll.c</a><strong>，</strong><a href=\"https://github.com/redis/redis/tree/5.0/src/ae_evport.c\">ae_evport.c</a><strong>，</strong><a href=\"https://github.com/redis/redis/tree/5.0/src/ae_kqueue.c\">ae_kqueue.c</a><strong>，</strong><a href=\"https://github.com/redis/redis/tree/5.0/src/ae_select.c\">ae_select.c</a><strong>四个代码文件中定义的。那么你知道，Redis在调用aeApiCreate、aeApiAddEvent这些函数时，是根据什么条件来决定，具体调用哪个文件中的IO多路复用函数的吗？</strong></p><p></p><p>其实，这道题的目的，主要是希望你能通过它进一步了解如何进行跨平台的编程开发。在实际业务场景中，我们开发的系统可能需要在不同的平台上运行，比如Linux和Windows。那么，我们在开发时，就需要用同一套代码支持在不同平台上的执行。</p><p></p><p>就像Redis中使用的IO多路复用机制一样，不同平台上支持的IO多路复用函数是不一样的。但是，使用这些函数的事件驱动整体框架又可以用一套框架来实现。所以，我们就需要在同一套代码中区分底层平台，从而可以正确地使用该平台对应函数。</p><p></p><p>对应Redis事件驱动框架来说，它是用aeApiCreate、aeApiAddEven等函数，封装了不同的IO多路复用函数，而在ae.c文件的开头部分，它使用了#ifdef、#else、#endif等<strong>条件编译指令</strong>，来区分封装的函数应该具体使用哪种IO多路复用函数。</p><p></p><p>下面的代码就展示了刚才介绍的条件编译。</p><pre><code class=\"language-plain\">#ifdef HAVE_EVPORT\n#include \"ae_evport.c\"\n#else\n&nbsp;&nbsp;&nbsp; #ifdef HAVE_EPOLL\n&nbsp;&nbsp;&nbsp; #include \"ae_epoll.c\"\n&nbsp;&nbsp;&nbsp; #else\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #ifdef HAVE_KQUEUE\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #include \"ae_kqueue.c\"\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #else\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #include \"ae_select.c\"\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #endif\n&nbsp;&nbsp;&nbsp; #endif\n#endif\n</code></pre><p>从这段代码中我们可以看到，如果 <code>HAVE_EPOLL</code> 宏被定义了，那么，代码就会包含ae_epoll.c文件，这也就是说，aeApiCreate、aeApiAddEven、aeApiPoll这些函数就会调用epoll_create、epoll_ctl、epoll_wait这些机制。</p><p>类似的，如果 <code>HAVE_KQUEUE</code> 宏被定义了，那么，代码就会包含ae_kqueue.c文件，框架函数也会实际调用kqueue的机制。</p><p>那么，接下来的一个问题就是，<strong><code>HAVE_EPOLL</code>、<code>HAVE_KQUEUE</code> 这些宏又是在哪里被定义的呢？</strong></p><p>其实，它们是在config.h文件中定义的。</p><p>在config.h文件中，代码会判断是否定义了<code>__linux__</code>宏，如果有的话，那么，代码就会定义 <code>HAVE_EPOLL</code> 宏。而如果定义了<code>__FreeBSD__</code>、<code>__OpenBSD__</code>等宏，那么代码就会定义 <code>HAVE_KQUEUE</code> 宏。</p><p>下面的代码展示了config.h中的这部分逻辑，你可以看下。</p><pre><code class=\"language-plain\">#ifdef __linux__\n#define HAVE_EPOLL 1\n#endif\n&nbsp;\n#if (defined(__APPLE__) &amp;&amp; defined(MAC_OS_X_VERSION_10_6)) || defined(__FreeBSD__) || defined(__OpenBSD__) || defined (__NetBSD__)\n#define HAVE_KQUEUE 1\n#endif\n</code></pre><p>好了，到这里，我们就知道了，Redis源码中是根据<code>__linux__</code>、<code>__FreeBSD__</code>、<code>__OpenBSD__</code>这些宏，来决定当前的运行平台是哪个平台，然后再设置相应的IO多路复用函数的宏。<strong>而<code>__linux__</code>、<code>__FreeBSD__</code>、<code>__OpenBSD__</code>这些宏，又是如何定义的呢？</strong></p><p>其实，这就和运行平台上的编译器有关了。编译器会根据所运行的平台提供预定义宏。像刚才的<code>__linux__</code>、<code>__FreeBSD__</code>这些都是属于预定义宏，这些预定义宏的名称都是以“__”两条下划线开头和结尾的。你在Linux的系统中，比如CentOS或者Ubuntu，运行如下所示的gcc命令，你就可以看到Linux中运行的gcc编译器，已经提供了<code>__linux__</code>这个预定义宏了。</p><pre><code class=\"language-plain\">gcc -dM -E -x c /dev/null | grep linux\n\n#define __linux 1\n#define __linux__ 1\n#define __gnu_linux_x 1\n#define linux 1\n</code></pre><p>而如果你在macOS的系统中运行如下所示的gcc命令，你也能看到macOS中运行的gcc编译器，已经提供了<code>__APPLE__</code>预定义宏。</p><pre><code class=\"language-plain\">gcc -dM -E -x c /dev/null | grep APPLE\n#define __APPLE__ 1\n</code></pre><p>这样一来，当我们在某个系统平台上使用gcc编译Redis源码时，就可以根据编译器提供的预定义宏，来决定当前究竟该使用哪个IO多路复用函数了。而此时使用的IO多路复用函数，也是和Redis当前运行的平台是匹配的。</p><h2><a href=\"https://time.geekbang.org/column/article/409927\">第12讲</a></h2><p><strong>问题：Redis后台任务使用了bio_job结构体来描述，该结构体用了三个指针变量来表示任务参数，如下所示。那么，如果你创建的任务所需要的参数大于3个，你有什么应对方法来传参吗？</strong></p><pre><code class=\"language-plain\">struct bio_job {\n&nbsp;&nbsp;&nbsp; time_t time;\n&nbsp;&nbsp;&nbsp; void *arg1, *arg2, *arg3;&nbsp; //传递给任务的参数\n};\n</code></pre><p>这道题其实是需要你了解在C函数开发时，如果想传递很多参数该如何处理。</p><p>其实，这里我们可以充分利用函数参数中的指针，让指针指向一个结构体，比如数组或哈希表。而数组或哈希表这样的结构体中，就可以保存很多参数了。这样一来，我们就可以通过指针指向结构体来传递多个参数了。</p><p>不过，你要注意的是，在函数使用参数时，还需要解析指针指向的结构体，这个会产生一些开销。</p><p></p><h2>小结</h2><p>这节课，我们解答了第7讲到第12讲的课后思考题。在设计这些思考题时，有些题我希望你能通过它们了解一些C语言编程开发的技巧，比如使用编译器提供的预定义宏实现跨平台的开发，或者是通过指针给C函数传递批量参数等。而有些题，我是希望你能对计算机系统的一些关键机制设计有更多的了解，比如IO多路复用机制的对比。</p><p></p><p>其实，在回答这些思考题的时候，你有没有感受到，Redis就像一个小宝藏一样，我们可以从中学到从编程开发、到系统管理、再到系统设计等多方面的知识。希望你能在阅读Redis源码的道路上充分挖掘这个宝藏，充实自己的知识财富。</p>","neighbors":{"left":{"article_title":"答疑1 | 第1~6讲课后思考题答案及常见问题答疑","id":429370},"right":{"article_title":"答疑3 | 第13~18讲课后思考题答案及常见问题答疑","id":432737}}},{"article_id":432737,"article_title":"答疑3 | 第13~18讲课后思考题答案及常见问题答疑","article_content":"<p>你好，我是蒋德钧。</p><p></p><p>今天这节课，我们继续来解答第13讲到第18讲的课后思考题。这些思考题除了涉及Redis自身的开发与实现机制外，还包含了多线程模型使用、系统调用优化等通用的开发知识，希望你能掌握这些扩展的通用知识，并把它们用在自己的开发工作中。</p><p></p><h2><a href=\"https://time.geekbang.org/column/article/410666\">第13讲</a></h2><p><strong>问题：</strong>Redis 多IO线程机制使用startThreadedIO函数和stopThreadedIO函数，来设置IO线程激活标识io_threads_active为1和为0。此处，这两个函数还会对线程互斥锁数组进行解锁和加锁操作，如下所示。那么，你知道为什么这两个函数要执行解锁和加锁操作吗？</p><pre><code class=\"language-plain\">void startThreadedIO(void) {\n&nbsp;&nbsp;&nbsp; ...\n&nbsp;&nbsp;&nbsp; for (int j = 1; j &lt; server.io_threads_num; j++)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; pthread_mutex_unlock(&amp;io_threads_mutex[j]);&nbsp; //给互斥锁数组中每个线程对应的互斥锁做解锁操作\n&nbsp;&nbsp;&nbsp; server.io_threads_active = 1;\n}\n&nbsp;\nvoid stopThreadedIO(void) {\n&nbsp;&nbsp;&nbsp; ...\n&nbsp;&nbsp;&nbsp; for (int j = 1; j &lt; server.io_threads_num; j++)\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; pthread_mutex_lock(&amp;io_threads_mutex[j]);&nbsp; //给互斥锁数组中每个线程对应的互斥锁做加锁操作\n&nbsp;&nbsp;&nbsp; server.io_threads_active = 0;\n}\n</code></pre><!-- [[[read_end]]] --><p>我设计这道题的目的，主要是希望你可以了解多线程运行时，如何通过互斥锁来控制线程运行状态的变化。这里我们就来看下线程在运行过程中，是如何使用互斥锁的。通过了解这个过程，你就能知道题目中提到的解锁和加锁操作的目的了。</p><p></p><p>首先，在初始化和启动多IO线程的<strong>initThreadedIO函数</strong>中，主线程会先获取每个IO线程对应的互斥锁。然后，主线程会创建IO线程。当每个IO线程启动后，就会运行IOThreadMain函数，如下所示：</p><p></p><pre><code class=\"language-plain\">void initThreadedIO(void) {\n&nbsp;&nbsp; …\n&nbsp;&nbsp; for (int i = 0; i &lt; server.io_threads_num; i++) {\n\t…\n\tpthread_mutex_init(&amp;io_threads_mutex[i],NULL);\n\t&nbsp;io_threads_pending[i] = 0;\n\t&nbsp;pthread_mutex_lock(&amp;io_threads_mutex[i]); //主线程获取每个IO线程的互斥锁\n\t&nbsp;if (pthread_create(&amp;tid,NULL,IOThreadMain,(void*)(long)i) != 0) {…} //启动IO线程，线程运行IOThreadMain函数\n\t…} …}\n</code></pre><p>而IOThreadMain函数会一直执行一个<strong>while(1)<strong>的循环流程。在这个流程中，线程又会先执行一个100万次的循环，而在这个循环中，线程会一直检查有没有待处理的任务，这些任务的数量是用</strong>io_threads_pending数组</strong>保存的。<br>\n在这个100万次的循环中，一旦线程检查到有待处理任务，也就是io_threads_pending数组中和当前线程对应的元素值不为0，那么线程就会跳出这个循环，并根据任务类型进行实际的处理。</p><p></p><p>下面的代码展示了这部分的逻辑，你可以看下。</p><pre><code class=\"language-plain\">void *IOThreadMain(void *myid) {\n&nbsp;…\n&nbsp;&nbsp;while(1) {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; //循环100万次，每次检查有没有待处理的任务\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for (int j = 0; j &lt; 1000000; j++) {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (io_threads_pending[id] != 0) break;&nbsp; //如果有任务就跳出循环\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; … //从io_threads_lis中取出待处理任务，根据任务类型，调用相应函数进行处理\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }\n…}\n</code></pre><p>而如果线程执行了100万次循环后，仍然没有任务处理。那么，它就会<strong>调用pthread_mutex_lock函数</strong>去获取它对应的互斥锁。但是，就像我刚才给你介绍的，在initThreadedIO函数中，主线程已经获得了IO线程的互斥锁了。所以，在IOThreadedMain函数中，线程会因为无法获得互斥锁，而进入等待状态。此时，线程不会消耗CPU。</p><p></p><p>与此同时，主线程在进入事件驱动框架的循环前，会<strong>调用beforeSleep函数</strong>，在这个函数中，主线程会进一步调用handleClientsWithPendingWritesUsingThreads函数，来给IO线程分配待写客户端。</p><p>那么，在handleClientsWithPendingWritesUsingThreads函数中，如果主线程发现IO线程没有被激活的话，它就会<strong>调用startThreadedIO函数</strong>。</p><p></p><p>好了，到这里，startThreadedIO函数就开始执行了。这个函数中会依次调用pthread_mutex_unlock函数，给每个线程对应的锁进行解锁操作。这里，你需要注意的是，startThreadedIO是在主线程中执行的，而每个IO线程的互斥锁也是在IO线程初始化时，由主线程获取的。</p><p>所以，主线程可以调用pthread_mutex_unlock函数来释放每个线程的互斥锁。</p><p></p><p>一旦主线程释放了线程的互斥锁，那么IO线程执行的IOThreadedMain函数，就能获得对应的互斥锁。紧接着，IOThreadedMain函数又会释放释放互斥锁，并继续执行while(1)，如下所示：</p><pre><code class=\"language-plain\">void *IOThreadMain(void *myid) {\n&nbsp;…\n&nbsp;&nbsp;while(1) {\n&nbsp;&nbsp;&nbsp;&nbsp; …\n&nbsp;&nbsp;&nbsp;&nbsp; if (io_threads_pending[id] == 0) {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; pthread_mutex_lock(&amp;io_threads_mutex[id]);&nbsp; //获得互斥锁\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; pthread_mutex_unlock(&amp;io_threads_mutex[id]); //释放互斥锁\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; continue;\n&nbsp;&nbsp;&nbsp;&nbsp; }\n&nbsp;&nbsp; …} …}\n</code></pre><p>那么，这里就是解答第13讲课后思考题的关键所在了。<br>\n在IO线程释放了互斥锁后，主线程可能正好在执行handleClientsWithPendingWritesUsingThreads函数，这个函数中除了刚才介绍的，会根据IO线程是否激活来启动IO线程之外，它也会<strong>调用stopThreadedIOIfNeeded函数，来判断是否需要暂停IO线程</strong>。</p><p>stopThreadedIOIfNeeded函数一旦发现待处理任务数，不足IO线程数的2倍，它就会调用stopThreadedIO函数来暂停IO线程。</p><p></p><p><strong>而暂停IO线程的办法，就是让主线程获得线程的互斥锁。</strong>所以，stopThreadedIO函数就会依次调用pthread_mutex_lock函数，来获取每个IO线程对应的互斥锁。刚才我们介绍的IOThreadedMain函数在获得互斥锁后，紧接着就释放互斥锁，其实就是希望主线程执行的stopThreadedIO函数，能在IO线程释放锁后的这个时机中，获得线程的互斥锁。</p><p></p><p>这样一来，因为IO线程执行IOThreadedMain函数时，会一直运行while(1)循环，并且一旦判断当前待处理任务为0时，它会去获取互斥锁。而此时，如果主线程已经拿到锁了，那么IO线程就只能进入等待状态了，这就相当于暂停了IO线程。</p><p></p><p>这里，你还需要注意的一点是，<strong>stopThreadedIO函数还会把表示当前IO线程激活的标记io_threads_active设为0</strong>，这样一来，主线程的handleClientsWithPendingWritesUsingThreads函数在执行时，又会根据这个标记来再次调用startThreadedIO启用IO线程。而就像刚才我们提到的，startThreadedIO函数会释放主线程拿的锁，让IO线程从等待状态进入运行状态。</p><p></p><p>关于这道题，不少同学都提到了，题目中所说的加解锁操作是为了控制IO线程的启停，而且像是@土豆种南城同学，还特别强调了IOThreadedMain函数中执行的100万次循环的作用。</p><p></p><p>因为这个题目涉及的锁操作在好几个函数间轮流执行，所以，我刚才也是把这个过程的整体流程给你做了解释。下面我也画了一张图，展示了主线程通过加解锁控制IO线程启停的基本过程，你可以再整体回顾下。</p><p></p><p><img src=\"https://static001.geekbang.org/resource/image/c3/01/c3d8dc9c44db04d15975cf8bfa4f0401.jpg?wh=1920x1039\" alt=\"图片\"></p><h2><a href=\"https://time.geekbang.org/column/article/411558\">第14讲</a></h2><p><strong>问题：</strong>如果我们将命令处理过程中的命令执行也交给多IO线程执行，你觉得除了对原子性有影响，会有什么好处或其他不足的影响吗？</p><p></p><p>这道题主要是希望你能对多线程执行模型的优势和不足，有进一步的思考。</p><p></p><p>其实，使用多IO线程执行命令的好处很直接，就是可以充分利用CPU的多核资源，让每个核上的IO线程并行处理命令，从而提升整体的吞吐率。</p><p></p><p>但是，这里你要注意的是，如果多个命令执行时要对同一个数据结构进行写操作，那么，此时也就是多个线程要并发写某个数据结构。为了保证操作正确性，我们就需要使用<strong>互斥方法</strong>，比如加锁，来提供并发控制。</p><p>这实际上是使用多IO线程时的不足，它会带来两个影响：一个是基于加锁等互斥操作的并发控制，会降低系统整体性能；二个是多线程并发控制的开发与调试比较难，会增加开发者的负担。</p><p></p><h2><a href=\"https://time.geekbang.org/column/article/412164\">第15讲</a></h2><p><strong>问题：</strong>Redis源码中提供了getLRUClock函数来计算全局LRU时钟值，同时键值对的LRU时钟值是通过LRU_CLOCK函数来获取的，以下代码也展示了LRU_CLOCK函数的执行逻辑，这个函数包括了两个分支，一个分支是直接从全局变量server的lruclock中获取全局时钟值，另一个是调用getLRUClock函数获取全局时钟值。</p><p>那么你知道，为什么键值对的LRU时钟值，不直接通过调用getLRUClock函数来获取呢？</p><pre><code class=\"language-plain\">unsigned int LRU_CLOCK(void) {\n&nbsp;&nbsp;&nbsp; unsigned int lruclock;\n&nbsp;&nbsp;&nbsp; if (1000/server.hz &lt;= LRU_CLOCK_RESOLUTION) {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; atomicGet(server.lruclock,lruclock);\n&nbsp;&nbsp;&nbsp; } else {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; lruclock = getLRUClock();\n&nbsp;&nbsp;&nbsp; }\n&nbsp;&nbsp;&nbsp; return lruclock;\n}\n</code></pre><p>这道题有不少同学都给出了正确答案，比如@可怜大灰狼、@Kaito、@曾轼麟等等。这里我来总结下。</p><p></p><p>其实，调用getLRUClock函数获取全局时钟值，它最终会调用<strong>gettimeofday</strong>这个系统调用来获取时间。而系统调用会触发用户态和内核态的切换，会带来微秒级别的开销。</p><p>而对于Redis来说，它的吞吐率是每秒几万QPS，所以频繁地执行系统调用，这里面带来的微秒级开销有些大。所以，<strong>Redis只是以固定频率调用getLRUClock函数</strong>，使用系统调用获取全局时钟值，然后将该时钟值赋值给全局变量server.lruclock。当要获取时钟时，直接从全局变量中获取就行，节省了系统调用的开销。</p><p></p><p>刚才介绍的这种实现方法，在系统的性能优化过程中是有不错的参考价值的，你可以重点掌握下。</p><p></p><h2><a href=\"https://time.geekbang.org/column/article/413038\">第16讲</a></h2><p><strong>问题：</strong>LFU算法在初始化键值对的访问次数时，会将访问次数设置为LFU_INIT_VAL，它的默认值是5次。那么，你能结合这节课介绍的代码，说说如果LFU_INIT_VAL设置为1，会发生什么情况吗？</p><p></p><p>这道题目主要是希望你能理解LFU算法实现时，对键值对访问次数的增加和衰减操作。<strong>LFU_INIT_VAL会在LFULogIncr函数中使用</strong>，如下所示：</p><pre><code class=\"language-plain\">uint8_t LFULogIncr(uint8_t counter) {\n…\ndouble r = (double)rand()/RAND_MAX;\n&nbsp;&nbsp;&nbsp; double baseval = counter - LFU_INIT_VAL;\n&nbsp;&nbsp;&nbsp; if (baseval &lt; 0) baseval = 0;\n&nbsp;&nbsp;&nbsp; double p = 1.0/(baseval*server.lfu_log_factor+1);\n\tif (r &lt; p) counter++;\n\t…}\n</code></pre><p>从代码中可以看到，如果LFU_INIT_VAL比较小，那么baseval值会比较大，这就导致p值比较小，那么counter++操作的机会概率就会变小，这也就是说，键值对访问次数counter不容易增加。</p><p>而另一方面，<strong>LFU算法在执行时，会调用LFUDecrAndReturn函数</strong>，对键值对访问次数counter进行衰减操作。counter值越小，就越容易被衰减后淘汰掉。所以，如果LFU_INIT_VAL值设置为1，就容易导致刚刚写入缓存的键值对很快被淘汰掉。</p><p>因此，为了避免这个问题，LFU_INIT_VAL值就要设置的大一些。</p><p></p><h2><a href=\"https://time.geekbang.org/column/article/413997\">第17讲</a></h2><p><strong>问题：</strong>freeMemoryIfNeeded函数在使用后台线程删除被淘汰数据的时候，你觉得在这个过程中，主线程仍然可以处理外部请求吗？</p><p></p><p>这道题像@Kaito等不少同学都给出了正确答案，我在这里总结下，也给你分享一下我的思考过程。</p><p>Redis主线程在执行freeMemoryIfNeeded函数时，这个函数确定了淘汰某个key&nbsp;之后，会先把这个key从全局哈希表中删除。然后，这个函数会在dbAsyncDelete函数中，<strong>调用lazyfreeGetFreeEffort函数，评估释放内存的代价。</strong></p><p>这个代价的计算，主要考虑的是要释放的键值对是集合时，集合中的元素数量。如果要释放的元素过多，主线程就会在后台线程中执行释放内存操作。此时，主线程就可以继续正常处理客户端请求了。而且因为被淘汰的key已从全局哈希表中删除，所以客户端也查询不到这个key了，不影响客户端正常操作。</p><p></p><h2><a href=\"https://time.geekbang.org/column/article/415563\">第18讲</a></h2><p><strong>问题：</strong>你能在serverCron函数中，查找到rdbSaveBackground函数一共会被调用执行几次么？这又分别对应了什么场景呢？</p><p></p><p>这道题，我们通过在serverCron函数中查找<strong>rdbSaveBackground函数</strong>，就可以知道它被调用执行了几次。@曾轼麟同学做了比较详细的查找，我整理了下他的答案，分享给你。</p><p></p><p>首先，在serverCron 函数中，它会直接调用rdbSaveBackground两次。</p><p></p><p><strong>第一次直接调用</strong>是在满足RDB生成的条件时，也就是修改的键值对数量和距离上次生成RDB的时间满足配置阈值时，serverCron函数会调用rdbSaveBackground函数，创建子进程生成RDB，如下所示：</p><pre><code class=\"language-plain\">if (server.dirty &gt;= sp-&gt;changes &amp;&amp; server.unixtime-server.lastsave &gt; sp-&gt;seconds &amp;&amp;\n(server.unixtime-server.lastbgsave_try&gt; CONFIG_BGSAVE_RETRY_DELAY\n|| server.lastbgsave_status == C_OK)) {\n…\nrdbSaveBackground(server.rdb_filename,rsiptr);\n…}\n</code></pre><p><strong>第二次直接调用</strong>是在客户端执行了BGSAVE命令后，Redis设置了rdb_bgsave_scheduled等于1，此时，serverCron函数会检查这个变量值以及当前RDB子进程是否运行。</p><p>如果子进程没有运行的话，那么serverCron函数就调用rdbSaveBackground函数，生成RDB，如下所示：</p><pre><code class=\"language-plain\">if (!hasActiveChildProcess() &amp;&amp; server.rdb_bgsave_scheduled &amp;&amp;\n(server.unixtime-server.lastbgsave_try &gt; CONFIG_BGSAVE_RETRY_DELAY ||\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; server.lastbgsave_status == C_OK)) {\n&nbsp;…\nif (rdbSaveBackground(server.rdb_filename,rsiptr) == C_OK)\n…}\n</code></pre><p>而除了刚才介绍的两次直接调用以外，在serverCron函数中，还会有两次对rdbSaveBackground的<strong>间接调用</strong>。</p><p></p><p>一次间接调用是通过replicationCron -&gt; startBgsaveForReplication -&gt; rdbSaveBackground这个调用关系，来间接调用rdbSaveBackground函数，为主从复制定时任务生成RDB文件。</p><p></p><p>另一次间接调用是通过checkChildrenDone –&gt; backgroundSaveDoneHandler -&gt; backgroundSaveDoneHandlerDisk -&gt; updateSlavesWaitingBgsave -&gt; startBgsaveForReplication -&gt; rdbSaveBackground这个调用关系，来生成RDB文件的。而这个调用主要是考虑到在主从复制过程中，有些从节点在等待当前的RDB生成过程结束，因此在当前的RDB子进程结束后，这个调用为这些等待的从节点新调度启动一次RDB子进程。</p><p></p><h2>小结</h2><p>好了，今天这节课就到这里了。我来总结下。</p><p></p><p>在今天的课程上，我给你解答了第13讲到第18讲的课后思考题。在这其中，我觉得有两个内容是你需要重点掌握的。</p><p><strong>一个是你要了解系统调用的开销</strong>。从绝对值上来看，系统调用开销并不高，但是对于像Redis这样追求高性能的系统来说，每一处值得优化的地方都要仔细考虑。避免额外的系统开销，就是高性能系统开发的一个重要设计指导原则。</p><p></p><p><strong>另一个是多IO线程模型的使用</strong>。我们通过思考题，了解了Redis会通过线程互斥锁，来实现对线程运行和等待状态的控制，以及多线程的优点和不足。现在的服务器硬件都是多核CPU，所以多线程模型也被广泛使用，用好多线程模型可以帮助我们实现系统性能的提升。</p><p>所以在最后，我也再给你关于多线程模型开发的三个小建议：</p><ul>\n<li>尽量减少共享数据结构的使用，比如采用key partition的方法，让每个线程负责一部分key的访问，这样可以减少并发访问的冲突。当然，如果要做范围查询，程序仍然需要访问多个线程负责的key。</li>\n<li>对共享数据结构进行优化，尽量采用原子操作来减少并发控制的开销。</li>\n<li>将线程和CPU核绑定，减少线程在不同核上调度时带来的切换开销。</li>\n</ul><p>欢迎继续给我留言，分享你在学习课程时的思考。</p>","neighbors":{"left":{"article_title":"答疑2 | 第7~12讲课后思考题答案及常见问题答疑","id":431791},"right":{"article_title":"答疑4 | 第19~24讲课后思考题答案及常见问题答疑","id":434382}}},{"article_id":434382,"article_title":"答疑4 | 第19~24讲课后思考题答案及常见问题答疑","article_content":"<p>你好，我是蒋德钧。这节课，我们继续来解答第19到24讲的课后思考题。</p><p>注意，今天讲解的这些思考题，一方面会涉及Redis哨兵实例的代码细节，以及管道机制在Redis中的应用；另一方面，这些思考题也是考查常用的开发知识，比如状态机、子进程使用等进程考查。希望你通过这节课的内容，可以再回顾下Redis哨兵实例的代码，并进一步了解题目解答中涉及的开发知识和技术。</p><h2><a href=\"https://time.geekbang.org/column/article/416264\">第19讲</a></h2><p><strong>问题：</strong>RDB文件的创建是由一个子进程来完成的，而AOF重写也是由一个子进程完成的，这两个子进程可以各自单独运行。那么请你思考一下，为什么Redis源码中在有RDB子进程运行时，不会启动AOF重写子进程呢？</p><p></p><p>我设计这道题的目的，是希望你能了解和掌握RDB文件创建和AOF重写这两个操作本身，涉及到的资源消耗。我们在开发系统软件时，对于使用子进程或是线程来进行并发处理，有时会存在<strong>一个误区：只要使用了多子进程或是多线程就可以加速并行执行的任务。</strong></p><p></p><p>但是，执行多子进程能够获得的收益还是要看这些子进程，对资源竞争的情况。就像这道题目提出的，虽然RDB创建和AOF重写可以会用两个子进程单独运行，但是从它们使用的资源角度来看，它们之间会存在竞争。</p><p></p><p>那么，一个最明显的资源竞争就是<strong>对磁盘的写竞争</strong>。创建RDB文件和重写AOF，都需要把数据写入磁盘，如果同时让这两个子进程写盘，就会给磁盘带来较大的压力。而除了磁盘资源竞争以外，RDB文件创建和AOF重写还需要读取Redis数据库中的所有键值对，如果这两个子进程同时执行，也会消耗CPU资源。</p><!-- [[[read_end]]] --><h2><a href=\"https://time.geekbang.org/column/article/416276\">第20讲</a></h2><p><strong>问题：</strong>这节课，我给你介绍了重写子进程和主进程间进行操作命令传输、ACK信息传递用的三个管道。那么，你在Redis源码中还能找到其他使用管道的地方吗？</p><p></p><p>这道题目，是希望你能更多地了解下管道在Redis中的应用。有不少同学都找到了多个使用管道的地方，我在这里总结下。</p><p></p><ul>\n<li><strong>首先，创建RDB、AOF重写和主从复制时会用到管道。</strong></li>\n</ul><p>在RDB文件的创建函数rdbSaveBackground、AOF重写的函数rewriteAppendOnlyFileBackground，以及把RDB通过socket传给从节点的函数rdbSaveToSlavesSockets中，它们都会调用openChildInfoPipe函数，创建一个管道<strong>child_info_pipe</strong>，这个管道的描述符数组，保存在了全局变量server中。</p><p>当RDB创建结束或是AOF文件重写结束后，这两个函数会调用sendChildInfo函数，通过刚才创建的管道child_info_pipe，把子进程写时复制的实际数据量发送给父进程。</p><p></p><p>下面的代码展示了rdbSaveBackground、rewriteAppendOnlyFileBackground、rdbSaveToSlavesSockets这三个函数使用管道的主要代码，你可以看下。</p><pre><code class=\"language-plain\">int rdbSaveBackground(char *filename, rdbSaveInfo *rsi) {\n…\nopenChildInfoPipe();\nif ((childpid = fork()) == 0) {\n…\nserver.child_info_data.cow_size = private_dirty; //记录实际的写时复制数据量\n\tsendChildInfo(CHILD_INFO_TYPE_RDB); //将写时复制数据量发送给父进程\n\t…} …}\n\t&nbsp;\nint rdbSaveToSlavesSockets(rdbSaveInfo *rsi) {\n…\nopenChildInfoPipe();\nif ((childpid = fork()) == 0) {\n…\nserver.child_info_data.cow_size = private_dirty; //记录实际的写时复制数据量\nsendChildInfo(CHILD_INFO_TYPE_RDB); //将写时复制数据量发送给父进程\n…} …}\n\n&nbsp;\nint rewriteAppendOnlyFileBackground(void) {\n…\nopenChildInfoPipe();&nbsp; //创建管道\n…\nif ((childpid = fork()) == 0) {\n…\nif (rewriteAppendOnlyFile(tmpfile) == C_OK) {\n…\nserver.child_info_data.cow_size = private_dirty; //记录实际写时复制的数据量\nsendChildInfo(CHILD_INFO_TYPE_AOF); //将写时复制的数据量发送给父进程\n…} …}\n…}\n</code></pre><p>此外，在刚才介绍的rdbSaveToSlavesSockets函数中，它还会创建一个管道。当子进程把数据传给从节点后，子进程会使用这个管道，向父进程发送成功接收到所有数据传输的从节点ID，你可以看看下面的代码。</p><pre><code class=\"language-plain\">int rdbSaveToSlavesSockets(rdbSaveInfo *rsi) {\n…\nif (pipe(pipefds) == -1) return C_ERR;\nserver.rdb_pipe_read_result_from_child = pipefds[0];&nbsp; //创建管道读端\nserver.rdb_pipe_write_result_to_parent = pipefds[1]; //创建管道写端\n…\nif ((childpid = fork()) == 0) {\n…\n//数据传输完成后，通过管道向父进程传输从节点ID\nif (*len == 0 || write(server.rdb_pipe_write_result_to_parent,msg,msglen) != msglen) {…}\n…} …}\n</code></pre><ul>\n<li><strong>其次，Redis module运行时会用到管道。</strong></li>\n</ul><p>在module的初始化函数moduleInitModulesSystem中，它会创建一个管道<strong>module_blocked_pipe</strong>，这个管道会用来唤醒由于处理module命令而阻塞的客户端。</p><p>下面的代码展示了管道在Redis module中的使用，你可以看下。</p><pre><code class=\"language-plain\">void moduleInitModulesSystem(void) {\n...\nif (pipe(server.module_blocked_pipe) == -1) {...} //创建管道\n...}\n\nint RM_UnblockClient(RedisModuleBlockedClient *bc, void *privdata) {\n...\nif (write(server.module_blocked_pipe[1],\"A\",1) != 1)&nbsp;{...} //向管道中写入“A”字符，表示唤醒被module阻塞的客户端\n...}\n\nvoid moduleHandleBlockedClients(void) {\n...\nwhile (read(server.module_blocked_pipe[0],buf,1) == 1); //从管道中读取字符\n...}\n</code></pre><ul>\n<li><strong>最后，linuxMadvFreeForkBugCheck函数会用到管道。</strong></li>\n</ul><p>基于arm64架构的Linux内核有一个Bug，这个Bug可能会导致数据损坏。而Redis源码就针对这个Bug，打了一个补丁，这个补丁在main函数的执行过程中，会调用linuxMadvFreeForkBugCheck函数，这个函数会fork一个子进程来判断是否发现Bug，而子进程会使用管道来和父进程交互检查结果。你也可以具体看下修复这个Bug的<a href=\"https://github.com/redis/redis/commit/b02780c41dbc5b28d265b5cf141c03c1a7383ef9\">补丁</a>。</p><h2><a href=\"https://time.geekbang.org/column/article/420285\">第21讲</a></h2><p><strong>问题：</strong>这节课我们介绍的状态机是当实例为从库时会使用的。那么，当一个实例是主库时，为什么不需要使用一个状态机，来实现主库在主从复制时的流程流转呢？</p><p></p><p>在Redis实现主从复制时，从库涉及到的状态变迁有很多，包括了发起连接、主从握手、复制类型判断、请求数据等。因此，使用状态机开发从库的复制流程，可以很好地帮助我们实现状态流转。</p><p></p><p>但是，如果你再去看下主从复制的启动，你会发现，<strong>主从复制都是由从库执行slaveof或replicaof命令而开始</strong>。这也就是说，主从复制的发起方是从库，而对于主库来说，它只是<strong>被动式地响应</strong>从库的各种请求，并根据从库的请求执行相应的操作，比如生成RDB文件或是传输数据等。</p><p>而且，从另外一个角度来说，主库可能和多个从库进行主从复制，而<strong>不同从库的复制进度和状态很可能并不一样</strong>，如果主库要维护状态机的话，那么，它还需要为每个从库维护一个状态机，这个既会增加开发复杂度，也会增加运行时的开销。正是因为这些原因，所以主库并不需要使用状态机进行状态流转。</p><p></p><p>除此之外， @曾轼麟同学也提到了一个原因，主库本身是可能发生故障，并要进行故障切换的。如果主库在执行主从复制时，也维护状态机，那么<strong>一旦主库发生了故障，也还需要考虑状态机的冗余备份和故障切换</strong>，这会给故障切换的开发和执行带来复杂度和开销。而从库维护状态机本身就已经能完成主从复制，所以没有必要让主库再维护状态机了。</p><h2><a href=\"https://time.geekbang.org/column/article/420759\">第22讲</a></h2><p><strong>问题：</strong>哨兵实例本身是有配置文件sentinel.conf的，那么你能在哨兵实例的初始化过程中，找到解析这个配置文件的函数吗？</p><p>在前面的<a href=\"https://time.geekbang.org/column/article/406556\">第8讲</a>中，我重点给你介绍了Redis server的启动和初始化过程。因为哨兵实例本身也是一个Redis server，所以它启动后的初始化代码执行路径，和Redis server是类似的。</p><p>哨兵实例启动后，它的入口函数是serve.c文件中的<strong>main函数</strong>。然后，main函数会调用loadServerConfig函数加载配置文件。而loadServerConfig会进一步调用loadServerConfigFromString函数，解析配置文件中的具体配置项。</p><p>那么，当loadServerConfigFromString函数在解析配置项时，它会使用条件分支判断来匹配不同的配置项。当它匹配到配置项为“<strong>sentinel</strong>”时，它就会执行解析哨兵实例配置项的代码分支了，具体来说，它会<strong>调用sentinelHandleConfiguration函数来进行解析</strong>，如下所示：</p><pre><code class=\"language-plain\">void loadServerConfigFromString(char *config) {\nelse if (!strcasecmp(argv[0],\"sentinel\")) {\n…\nerr = sentinelHandleConfiguration(argv+1,argc-1);\n…}…}\n</code></pre><p>sentinelHandleConfiguration函数是在sentinel.c文件中实现的，它和loadServerConfigFromString函数类似，也是匹配sentinel.conf中的不同配置项，进而执行不同的代码分支。你可以进一步阅读它的代码来进行了解。</p><p>我在这里也画了一张图，展示了哨兵实例解析配置项的函数调用关系，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/9c/cc/9c1d41a0164692e569f95d4db474e8cc.jpg?wh=1699x1037\" alt=\"图片\"></p><h2><a href=\"https://time.geekbang.org/column/article/421736\">第23讲</a></h2><p><strong>问题：</strong>哨兵实例执行的周期性函数sentinelTimer，它在函数执行逻辑的最后，会修改server.hz配置项，如下所示：</p><pre><code class=\"language-plain\">void sentinelTimer(void) {\n...\nserver.hz = CONFIG_DEFAULT_HZ + rand() % CONFIG_DEFAULT_HZ;\n}\n</code></pre><p>那么，你知道调整server.hz的目的是什么吗？</p><p>这道题目，像是@Kaito、@曾轼麟、@可怜大灰狼等不少同学，都给出了正确答案，这里我就来总结一下。</p><p></p><p>那么，要回答这道题目，首先你要知道<strong>server.hz表示的是定时任务函数serverCron的执行频率</strong>，而哨兵实例执行的周期性函数sentinelTimer，也是在serverCron中被调用执行的。所以，sentinelTimer函数的运行频率会按照server.hz来执行。</p><p></p><p>我在第23讲中给你介绍过，当哨兵实例判断了主节点客观下线后，它们就要开始选举Leader节点，以便进行故障切换。但是，Leader选举时，哨兵需要获得半数以上的赞成票，如果在一轮选举中没能选出Leader，此时，哨兵实例会再次进行选举。</p><p></p><p>但是，为了避免多个哨兵同时开始进行选举，又同时都没法获得超过半数的赞成票，而导致Leader选举失败，sentinelTimer函数在执行的最后一步，对server.hz做了微调：<strong>在默认值CONFIG_DEFAULT_HZ的基础上，增加一个随机值。</strong></p><p>这样一来，每个哨兵的执行频率就不会完全同步了。一轮选举失败后，哨兵再次选举时，不同哨兵的再次执行频率不一样，这就把它们发起投票的时机错开了，从而降低了它们都无法获得超过半数赞成票的概率，也就保证了Leader选举能快速完成，可以执行实际的故障切换。</p><p></p><p>所以，sentinelTimer函数修改server.hz，可以避免故障切换过程中，因为Leader节点选举不出来而导致无法完成的情况，提升了Redis的可用性。</p><h2><a href=\"https://time.geekbang.org/column/article/422625\">第24讲</a></h2><p><strong>问题：</strong>哨兵在sentinelTimer函数中会调用sentinelHandleDictOfRedisInstances函数，对每个主节点都执行sentinelHandleRedisInstance函数，并且还会对主节点的所有从节点，也执行sentinelHandleRedisInstance函数。那么，哨兵会判断从节点的主观下线和客观下线吗？</p><p></p><p>这道题目是希望你能进一步阅读sentinelHandleRedisInstance函数的源码，对它的执行流程有个更加详细的了解。</p><p></p><p>@曾轼麟同学在留言区就给出了比较详细的分析，我在此基础上做了些完善，分享给你。</p><p></p><p>首先，在sentinelHandleDictOfRedisInstances函数中，它会执行一个循环流程，针对当前哨兵实例监听的每个主节点，都<strong>执行sentinelHandleRedisInstance函数</strong>。</p><p>在这个处理过程中，存在一个<strong>递归调用</strong>，也就是说，如果当前处理的节点就是主节点，那么sentinelHandleDictOfRedisInstances函数，会进一步针对这个主节点的从节点，再次调用sentinelHandleDictOfRedisInstances函数，从而对每个从节点执行sentinelHandleRedisInstance函数。</p><p></p><p>这部分的代码逻辑如下所示：</p><pre><code class=\"language-plain\">void sentinelHandleDictOfRedisInstances(dict *instances) {\n…\ndi = dictGetIterator(instances);\nwhile((de = dictNext(di)) != NULL) {\n&nbsp;&nbsp; sentinelRedisInstance *ri = dictGetVal(de);&nbsp; //获取哨兵实例监听的每个主节点\n&nbsp;&nbsp; sentinelHandleRedisInstance(ri);&nbsp; //调用sentinelHandleRedisInstance\n&nbsp;&nbsp; if (ri-&gt;flags &amp; SRI_MASTER) {&nbsp; //如果当前节点是主节点，那么调用sentinelHandleDictOfRedisInstances对它的所有从节点进行处理。\n\tsentinelHandleDictOfRedisInstances(ri-&gt;slaves);\n\t…}\n…}…}\n</code></pre><p>然后，在sentinelHandleRedisInstance函数执行时，它会<strong>调用sentinelCheckSubjectivelyDown函数</strong>，来判断当前处理的实例是否主观下线。这步操作没有任何额外的条件约束，也就是说，无论当前是主节点还是从节点，都会被判断是否主观下线的。这部分代码如下所示：</p><pre><code class=\"language-plain\">void sentinelHandleRedisInstance(sentinelRedisInstance *ri) {\n…\nsentinelCheckSubjectivelyDown(ri);&nbsp; //无论是主节点还是从节点，都会检查是否主观下线\n…}\n</code></pre><p>但是要注意，sentinelHandleRedisInstance函数在调用sentinelCheckObjectivelyDown函数，判断实例客观下线状态时，它会检查当前实例是否有主节点标记，如下所示：</p><pre><code class=\"language-plain\">void sentinelHandleRedisInstance(sentinelRedisInstance *ri) {\n…\n&nbsp; if (ri-&gt;flags &amp; SRI_MASTER) {&nbsp; //只有当前是主节点，才检查是否客观下线\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sentinelCheckObjectivelyDown(ri);\n&nbsp;&nbsp; …}\n…}\n</code></pre><p>那么总结来说，对于主节点和从节点，它们的sentinelHandleRedisInstance函数调用路径就如下所示：</p><blockquote>\n<p>主节点：sentinelHandleRedisInstance -&gt; sentinelCheckSubjectivelyDown -&gt; sentinelCheckObjectivelyDown<br>\n从节点：sentinelHandleRedisInstance -&gt; sentinelCheckSubjectivelyDown</p>\n</blockquote><p>所以，回到这道题目的答案上来说，哨兵会判断从节点的主观下线，但不会判断其是否客观下线。</p><p>此外，@曾轼麟同学还通过分析代码，看到了<strong>从节点被判断为主观下线后，是不能被选举为新主节点的</strong>。这个过程是在sentinelSelectSlave函数中执行的，这个函数会遍历当前的从节点，依次检查它们的标记，如果一个从节点有主观下线标记，那么这个从节点就会被直接跳过，不会被选为新主节点。</p><p></p><p>下面的代码展示了sentinelSelectSlave函数这部分的逻辑，你可以看下。</p><pre><code class=\"language-plain\">sentinelRedisInstance *sentinelSelectSlave(sentinelRedisInstance *master) {\n…\ndi = dictGetIterator(master-&gt;slaves);\n&nbsp;&nbsp;&nbsp; while((de = dictNext(di)) != NULL) { //遍历主节点的每一个从节点\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sentinelRedisInstance *slave = dictGetVal(de);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; …\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (slave-&gt;flags &amp; (SRI_S_DOWN|SRI_O_DOWN)) continue; //如果从节点主观下线，那么直接跳过该节点，不能被选为新主节点\n&nbsp;&nbsp;&nbsp; …} …}\n</code></pre><h2>小结</h2><p>好了，今天这节课就到这里了，我们来总结下。</p><p></p><p>今天这节课，我主要给你解答了第19讲到24讲的课后思考题。这些题目有些是涉及Redis源码的细节，比如哨兵实例的初始化操作、周期性任务对主从节点执行的操作等。对于这部分内容，我希望你能结合代码做进一步的阅读，并掌握好它。</p><p></p><p>而有些题目，则是和通用的开发知识和技巧相关。比如，管道在子进程和父进程间提供的通信机制、状态机在复杂流程开发中的使用、分布式共识开发中的投票频率调整等。关于这部分内容，我希望你能结合它们在Redis代码实现中的应用，掌握它们的使用方法，并应用到你自己的系统开发中。</p>","neighbors":{"left":{"article_title":"答疑3 | 第13~18讲课后思考题答案及常见问题答疑","id":432737},"right":{"article_title":"答疑5 | 第25~32讲课后思考题答案及常见问题答疑","id":436330}}},{"article_id":436330,"article_title":"答疑5 | 第25~32讲课后思考题答案及常见问题答疑","article_content":"<p>你好，我是蒋德钧。今天这节课，我们来继续解答第25讲到32讲的课后思考题。</p><p>今天讲解的这些思考题，主要是围绕哨兵命令实现、Redis Cluster实现，以及常用开发技巧提出来的。你可以根据这些思考题的解答思路，进一步了解下哨兵实例命令和普通实例命令的区别、Redis Cluster对事务执行的支持情况，以及函数式编程方法在Redis测试中的应用等内容。</p><h2><a href=\"https://time.geekbang.org/column/article/422627\">第25讲</a></h2><p><strong>问题：</strong>如果我们在哨兵实例上执行publish命令，那么，这条命令是不是就是由pubsub.c文件中的publishCommand函数来处理的呢?</p><p>这道题目主要是希望你能了解，哨兵实例会使用到哨兵自身实现的命令，而不是普通Redis实例使用的命令。这一点我们从哨兵初始化的过程中就可以看到。</p><p>哨兵初始化时，会调用 <strong>initSentinel函数</strong>。而initSentinel函数会先把server.commands对应的命令表清空，然后执行一个循环，把哨兵自身的命令添加到命令表中。哨兵自身的命令是使用 <strong>sentinelcmds数组</strong>保存的。</p><p>那么从sentinelcmds数组中，我们可以看到publish命令对应的实现函数，其实是 <strong>sentinelPublishCommand</strong>。所以，我们在哨兵实例上执行publish命令，执行的并不是pubsub.c文件中的publishCommand函数。</p><!-- [[[read_end]]] --><p>下面的代码展示了initSentinel 函数先清空、再填充命令表的基本过程，以及sentinelcmds数组的部分内容，你可以看下。</p><pre><code class=\"language-plain\">void initSentinel(void) {\n&nbsp;&nbsp;&nbsp; ...\n&nbsp;&nbsp;&nbsp; dictEmpty(server.commands,NULL);&nbsp; //清空现有的命令表\n&nbsp;&nbsp;&nbsp; // 将sentinelcmds数组中的命令添加到命令表中\n&nbsp;&nbsp;&nbsp; for (j = 0; j &lt; sizeof(sentinelcmds)/sizeof(sentinelcmds[0]); j++) {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int retval;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; struct redisCommand *cmd = sentinelcmds+j;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; retval = dictAdd(server.commands, sdsnew(cmd-&gt;name), cmd);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;…\n&nbsp;&nbsp;&nbsp; }\n&nbsp;&nbsp;&nbsp; ...}\n&nbsp;\n//sentinelcmds数组的部分命令定义\nstruct redisCommand sentinelcmds[] = {\n&nbsp;&nbsp;&nbsp; ...\n&nbsp;&nbsp;&nbsp; {\"subscribe\",subscribeCommand,-2,\"\",0,NULL,0,0,0,0,0},\n&nbsp;&nbsp;&nbsp; {\"publish\",sentinelPublishCommand,3,\"\",0,NULL,0,0,0,0,0}, //publish命令对应哨兵自身实现的sentinelPublishCommand函数\n&nbsp;&nbsp;&nbsp; {\"info\",sentinelInfoCommand,-1,\"\",0,NULL,0,0,0,0,0},\n&nbsp;&nbsp;&nbsp; ...\n};\n</code></pre><h2><a href=\"https://time.geekbang.org/column/article/424827\">第26讲</a></h2><p><strong>问题：</strong>在今天课程介绍的源码中，你知道为什么clusterSendPing函数计算wanted值时，是用的集群节点个数的十分之一吗？</p><p>Redis Cluster在使用clusterSendPing函数，检测其他节点的运行状态时，<strong>既需要及时获得节点状态，又不能给集群的正常运行带来过大的额外通信负担。</strong></p><p>因此，clusterSendPing函数发送的Ping消息，其中包含的节点个数不能过多，否则会导致Ping消息体较大，给集群通信带来额外的负担，影响正常的请求通信。而如果Ping消息包含的节点个数过少，又会导致节点无法及时获知较多其他节点的状态。</p><p>所以，wanted默认设置为集群节点个数的十分之一，主要是为了避免上述两种情况的发生。</p><h2><a href=\"https://time.geekbang.org/column/article/425404\">第27讲</a></h2><p><strong>问题：</strong>processCommand函数在调用完getNodeByQuery函数后，实际调用clusterRedirectClient函数进行请求重定向前，会根据当前命令是否是EXEC，分别调用discardTransaction和flagTransaction两个函数。</p><p>那么，你能通过阅读源码，知道这里调用discardTransaction和flagTransaction的目的是什么吗?</p><pre><code class=\"language-plain\">int processCommand(client *c) {\n…\nclusterNode *n = getNodeByQuery(c,c-&gt;cmd,c-&gt;argv,c-&gt;argc,\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &amp;hashslot,&amp;error_code);\nif (n == NULL || n != server.cluster-&gt;myself) {\n&nbsp;&nbsp; if (c-&gt;cmd-&gt;proc == execCommand) {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; discardTransaction(c);\n&nbsp;&nbsp; } else {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; flagTransaction (c);\n&nbsp;&nbsp; }\n&nbsp;&nbsp; clusterRedirectClient(c,n,hashslot,error_code);\n&nbsp;&nbsp; return C_OK;\n\t}\n\t…\n\t}\n</code></pre><p>这道题目，像@Kaito、@曾轼麟等同学都给了较为详细的解释，我完善了下他们的答案，分享给你。</p><p>首先你要知道，当Redis Cluster运行时，它并不支持跨节点的事务执行。那么，我们从题目中的代码中可以看到，当getNodeByQuery函数返回null结果，或者查询的key不在当前实例时，discardTransaction或flagTransaction函数会被调用。</p><p>这里你要<strong>注意</strong>，getNodeByQuery函数返回null结果，通常是表示集群不可用、key找不到对应的slot、操作的key不在同一个 slot中、key正在迁移等这些情况。</p><p>那么，当这些情况发生，或者是查询的key不在当前实例时，如果client执行的是EXEC命令，<strong>discardTransaction函数</strong>就会被调用，它会放弃事务的执行，清空当前client之前缓存的命令，并对事务中的key执行unWatch操作，最后重置client的事务标记。</p><p></p><p>而如果当前client执行的是事务中的普通命令，那么 <strong>flagTransaction函数</strong>会被调用。它会给当前client设置标记CLIENT_DIRTY_EXEC。这样一来，当client后续执行EXEC命令时，就会根据这个标记，放弃事务执行。</p><p></p><p>总结来说，就是当集群不可用、key找不到对应的slot、key不在当前实例中、操作的key不在同一个slot中，或者key正在迁移等这几种情况发生时，事务的执行都会被放弃。</p><h2><a href=\"https://time.geekbang.org/column/article/426420\">第28讲</a></h2><p><strong>问题：</strong>在维护Redis Cluster集群状态的数据结构clusterState中，有一个字典树slots_to_keys。当在数据库中插入key时它会被更新，你能在Redis源码文件db.c中，找到更新slots_to_keys字典树的相关函数调用吗？</p><p></p><p>这道题目也有不少同学给出了正确答案，我来给你总结下。</p><p>首先，<strong>dbAdd函数是用来将键值对插入数据库中的</strong>。如果Redis Cluster被启用了，那么dbAdd函数会调用slotToKeyAdd函数，而slotToKeyAdd函数会调用slotToKeyUpdateKey函数。</p><p>那么在slotToKeyUpdateKey函数中，它会调用raxInsert函数更新slots_to_keys，调用链如下所示：</p><blockquote>\n<p>dbAdd -&gt; slotToKeyAdd -&gt; slotToKeyUpdateKey -&gt; raxInsert</p>\n</blockquote><p></p><p>然后，<strong>dbAsyncDelete和dbSyncDelete是用来删除键值对的</strong>。如果Redis Cluster被启用了，这两个函数都会调用slotToKeyUpdateKey函数。而在slotToKeyUpdateKey函数里，它会调用raxRemove函数更新slots_to_keys，调用链如下所示：</p><blockquote>\n<p>dbAsyncDelete/dbSyncDelete -&gt; slotToKeyDel -&gt; slotToKeyUpdateKey -&gt; raxRemove</p>\n</blockquote><p></p><p>另外，<strong>empytDb函数是用来清空数据库的</strong>。它会调用slotToKeyFlush函数，并由slotToKeyFlush函数，调用raxFree函数更新slots_to_keys，调用链如下所示：</p><blockquote>\n<p>empytDb -&gt; slotToKeyFlush -&gt; raxFree</p>\n</blockquote><p></p><p>还有在 <strong>getKeysInSlot函数</strong>中，它会调用raxStart获得slots_to_keys的迭代器，进而查询指定slot中的keys。而在 <strong>delKeysInSlot函数</strong>中，它也会调用raxStart获得slots_to_keys的迭代器，并删除指定slot中的keys。</p><p></p><p>此外，@曾轼麟同学还通过查阅Redis源码的git历史提交记录，发现slots_to_keys原先是使用跳表实现的，后来才替换成字典树。而这一替换的目的，也主要是为了方便通过slot快速查找到slot中的keys。</p><h2><a href=\"https://time.geekbang.org/column/article/427126\">第29讲</a></h2><p><strong>问题：</strong>在addReplyReplicationBacklog函数中，它会计算从节点在全局范围内要跳过的数据长度，如下所示：</p><pre><code class=\"language-plain\">skip = offset - server.repl_backlog_off;\n</code></pre><p>然后，它会根据这个跳过长度计算实际要读取的数据长度，如下所示：</p><pre><code class=\"language-plain\">len = server.repl_backlog_histlen - skip;\n</code></pre><p>请你阅读addReplyReplicationBacklog函数和调用它的masterTryPartialResynchronization函数，你觉得这里的skip会大于repl_backlog_histlen吗？</p><p>其实，在masterTryPartialResynchronization函数中，从节点要读取的全局位置对应了变量psync_offset，这个函数会比较psync_offset是否小于repl_backlog_off，以及psync_offset是否大于repl_backlog_off加上repl_backlog_histlen的和。</p><p>当这两种情况发生时，masterTryPartialResynchronization函数会进行<strong>全量复制</strong>，如下所示：</p><pre><code class=\"language-plain\">int masterTryPartialResynchronization(client *c) {\n…\n// psync_offset小于repl_backlog_off时，或者psync_offset 大于repl_backlog_off加repl_backlog_histlen的和时\nif (!server.repl_backlog ||\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; psync_offset &lt; server.repl_backlog_off ||\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; psync_offset &gt; (server.repl_backlog_off + server.repl_backlog_histlen)) {&nbsp;\n&nbsp;&nbsp; …\n&nbsp;&nbsp; goto need_full_resync;&nbsp; //进行全量复制\n}\n</code></pre><p>当psync_offset大于repl_backlog_off，并且小于repl_backlog_off加上repl_backlog_histlen的和，此时，masterTryPartialResynchronization函数会调用addReplyReplicationBacklog函数，进行<strong>增量复制</strong>。</p><p>而psync_offset会作为参数offset，传给addReplyReplicationBacklog函数。因此，在addReplyReplicationBacklog函数中计算skip时，就不会发生skip会大于repl_backlog_histlen的情况了，这种情况已经在masterTryPartialResynchronization函数中处理了。</p><h2><a href=\"https://time.geekbang.org/column/article/427537\">第30讲</a></h2><p><strong>问题：</strong>Redis在命令执行的call函数中，为什么不会针对EXEC命令，调用slowlogPushEntryIfNeeded函数来记录慢命令呢？</p><p></p><p>我设计这道题的主要目的，是希望你能理解EXEC命令的使用场景和事务执行的过程。</p><p><strong>EXEC命令是用来执行属于同一个事务的所有命令的</strong>。当程序要执行事务时，会先执行MULTI命令，紧接着，执行的命令并不会立即执行，而是被放到一个队列中缓存起来。等到EXEC命令执行时，在它之前被缓存起来等待执行的事务命令，才会实际执行。</p><p>因此，EXEC命令执行时，实际上会执行多条事务命令。此时，如果调用slowlogPushEntryIfNeeded函数记录了慢命令的话，并不能表示EXEC本身就是一个慢命令。而实际可能会耗时长的命令是事务中的命令，并不是EXEC命令自身，所以，这里不会针对EXEC命令，来调用slowlogPushEntryIfNeeded函数。</p><p></p><h2><a href=\"https://time.geekbang.org/column/article/428471\">第31讲</a></h2><p><strong>问题：</strong>你使用过哪些Redis的扩展模块，或者自行开发过扩展模块吗？欢迎分享一些你的经验。</p><p></p><p>我自己有使用过Redis的 <strong>TimeSeries扩展模块</strong>，用来在一个物联网应用的场景中保存一些时间序列数据。TimeSeries模块的功能特点是可以使用标签来对不同的数据集合进行过滤，通过集合标签筛选应用需要的集合数据。而且这个模块还支持对集合数据做聚合计算，比如直接求最大值、最小值等。</p><p></p><p>此外，我还使用过 <strong>RedisGraph扩展模块</strong>。这个模块支持把图结构的数据保存到Redis中，并充分利用了Redis使用内存读写数据的性能优势，提供对图数据进行快速创建、查询和条件匹配。你要是感兴趣，可以看下RedisGraph的<a href=\"https://redisgraph.io/\">官网</a>。</p><p></p><h2><a href=\"https://time.geekbang.org/column/article/428474\">第32讲</a></h2><p><strong>问题：</strong>Redis源码中还有一个针对SDS的小型测试框架，你知道这个测试框架是在哪个代码文件中吗?</p><p></p><p>这个小型测试框架是在testhelp.h文件中实现的。它定义了一个<strong>宏test_cond</strong>，而这个宏实际是一段测试代码，它的参数包括了测试项描述descr，以及具体的测试函数_c。</p><p></p><p>这里，你需要注意的是，在这个小框架中，测试函数是作为test_cond参数传递的，这体现了函数式编程的思想，而且这种开发方式使用起来也很简洁。</p><p></p><p>下面的代码展示了这个小测试框架的主要部分，你可以看下。</p><pre><code class=\"language-plain\">int __failed_tests = 0;&nbsp; //失败的测试项的数目\nint __test_num = 0;&nbsp;&nbsp;&nbsp; //已测试项的数目\n#define test_cond(descr,_c) do { \\\n&nbsp;&nbsp;&nbsp; __test_num++; printf(\"%d - %s: \", __test_num, descr); \\\n&nbsp;&nbsp;&nbsp; if(_c) printf(\"PASSED\\n\"); else {printf(\"FAILED\\n\"); __failed_tests++;} \\&nbsp; //运行测试函数_c，如果能通过，则打印PASSED，否则打印FAILED\n} while(0);\n</code></pre><p>那么，基于这个测试框架，在sds.c文件的sdsTest函数中，我就调用了test_cond宏，对SDS相关的多种操作进行了测试，你可以看看下面的示例代码。</p><pre><code class=\"language-plain\">int sdsTest(void) {\n&nbsp;&nbsp;&nbsp; {\n&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sds x = sdsnew(\"foo\");&nbsp; //调用sdsnew创建一个sds变量x\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; test_cond(\"Create a string and obtain the length\",\n\tsdslen(x) == 3 &amp;&amp; memcmp(x,\"foo\\0\",4) == 0)&nbsp; //调用test_cond测试sdsnew是否成功执行\n\t&nbsp;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; …\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; x = sdscat(x,\"bar\");&nbsp; //调用sdscat向sds变量x追求字符串\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; test_cond(\"Strings concatenation\",\n\tsdslen(x) == 5 &amp;&amp; memcmp(x,\"fobar\\0\",6) == 0); //调用test_cond测试sdscat是否成功执行\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; …}\n</code></pre><p></p><h2>小结</h2><p>今天这节课，也是我们最后一节答疑课，希望通过这5节答疑课程，解答了你对咱们课后思考题的疑问。同时也希望，你能通过这些课后思考题，去进一步扩展自己对Redis源码的了解，以及掌握Redis实现中的设计思想。</p><p>当然，如果你在看了答疑后，仍然有疑惑不解的话，也欢迎你在留言区写下你的疑问，我会和你继续探讨。</p><p></p><p></p><p></p>","neighbors":{"left":{"article_title":"答疑4 | 第19~24讲课后思考题答案及常见问题答疑","id":434382},"right":{"article_title":"结束语 | Redis源码阅读，让我们从新开始","id":437870}}},{"article_id":437870,"article_title":"结束语 | Redis源码阅读，让我们从新开始","article_content":"<p>你好，我是蒋德钧。不知不觉中，我和你又一起走过了3个多月的时光。在这3个多月的时间里，我和你一起并肩作战，去学习和了解了Redis的源码。跟第一季的课程内容相比，这一季学习的内容的确更有难度，也更加需要你能静下心来钻研。</p><p>这里先感谢你的一路陪伴，我们一起走到了现在。做这样一门专栏，我自己也是收获了很多、成长了很多。那么最后一节课，我就把我在做这门课程里三点最重要的认知分享给你，我们一起持续精进。</p><h2>用源码重新认知你的知识体系</h2><p>其实，要是用一句话来总结我的感受，那就是，阅读源码让我感到“<strong>从新开始</strong>”。</p><p>我在学习Redis源码之前，已经对Redis的一些基本原理、一些常见的后端系统设计都有了了解和掌握，本身也有一些C语言的开发经历。我相信，我当时的状态和此刻正在阅读这篇结束语的你可能很相似。</p><p>而在学习了Redis源码后，我发现自己在C语言编程技巧、计算机系统关键机制，还有系统设计原则等等很多方面，都有了新的认识。这些新认知，是源于对Redis源码设计与实现的学习，而源码学习本身又给我提供了高于Redis的通用知识的掌握，这让我受益匪浅。</p><p>就比如说，我以前在学习操作系统时，了解了进程间通信的方法有消息队列、命名管道、无名管道、共享内存等等，但是一直没能建立直观的认知。而在阅读Redis源码时，我发现Redis广泛地使用了无名管道，来支持父子进程间的通信。这一下子就在我的知识体系中，增加了对管道实际开发使用的新认知，这也让我有了一种实践正好结合理论的体会。</p><!-- [[[read_end]]] --><p>而另一方面，我以前在实现一些数据结构和算法时，都会按照它们在书本上的定义去实现。但是，在阅读Redis源码过程中，我发现其实实践和理论又是有差异的。就像Redis中的字符串根据不同长度，使用了不同的数据结构实现；有序集合使用了两种数据结构的组合来实现；以及LRU算法采用了近似方法来实现等等。</p><p>这些实际代码让我的知识体系，对实践结合理论又有了新的认识：其实在实际系统开发中，我们通常要考虑性能、空间、复杂度等约束条件，会在理论基础上进行优化开发。这一新认知对我后来的开发工作有了很大帮助，我会有意识地识别所开发系统面临的约束，进而优化自己的实现方法。</p><p>其实从Redis的源码中，我们可以掌握很多计算机系统知识，这些新知识，或许我们在目前的工作里还用不到，甚至在日后不断学习的过程中，还会被更新迭代掉。但是我们要清楚一点，就是<strong>我们在某一阶段所掌握的知识，往往会是下一阶段知识的基础。</strong></p><p>源码阅读本身就是一个结合之前学习的理论和开发知识，进一步学习实践开发知识的过程，这是一种从知识再到知识的过程，也是让我们重新认知自己知识体系的过程。</p><h2>用源码重新磨炼你的意志力</h2><p>阅读源码是一件很辛苦的事情，尤其是当我们面对一个庞大的代码结构时，往往就会感到无从下手了。而等到我们好不容易摸清了代码结构，知道了要从哪些关键函数开始看起时，我们又会面临代码中复杂的调用关系、高级的语法实现，同时，还要尝试去理解代码开发者的思路。这些都是我们在阅读代码过程中的拦路虎，很容易就让我们打退堂鼓了。</p><p>我自己在阅读源码时，这些问题也都碰到了。不过，<strong>我<strong><strong>把</strong></strong>这个过程看成是对自己意志力的一个磨炼，越是遇到困难，越要迎难而上，而不能轻言放弃。</strong></p><p>虽然我们也能通过坚持做某些事来磨炼自己的意志力，但是阅读代码的挑战性更大。这是因为代码是细节，而掌握细节需要我们有足够的静心、耐心和细心。这和学习原理不一样，学习原理的时候，我们的头脑往往转得很快，有些机制我们会想当然地认同了。</p><p>而阅读代码就不能这样了，一段代码不理解就是不理解，我们是无法想当然认同的。我们只有在不断尝试理解代码的过程中，<strong>正视自己想要放弃的心理和消极情绪，并能找到原因记录下来，然后逐渐减少阻力，以及慢慢提高自己想要放弃它的心理阈值</strong>。这正是阅读源码给我的意志力带来的新磨炼。</p><p>当然除了有意志力的支持，我们也需要有合理的方法。我之前看过一本书叫做《干劲的开关》，其中有句话是这样说的：“影响结果的不是斗志，而是科学”。所以我在读源码的时候，我就把阅读代码的目标拆分得更加细粒度化，每天、每周完成一些小目标，日积月累，等到我把Redis源码主要部分阅读完后，我收获了很大的成就感，因为我做到了。</p><p>而且在那之后，我也发现自己再做其他一些具有挑战性的工作时，阅读源码时得到磨炼的意志力就会发挥积极作用，让我自己不再畏惧困难，而是会积极应对。那么相对应地，我希望你在阅读源码的时候，也能够不要被代码的复杂结构或是错综调用关系所吓倒，而是规划好切实可达的目标，一步一个脚印地去完成代码的学习。</p><h2>用源码重新塑造你的做事原则</h2><p>我之前在做事时，通常都是直线思维，定了一个目标就希望一次性完成这个目标。但有时受限于自己的知识背景和能力，对如何一次性完成目标会感到很困惑。</p><p>而在阅读Redis源码时，我遇到了相同的困惑：我一直奔着一定要把主要代码和关键技术掌握好这个目标而学习。但是在源码阅读的过程中，我有时在阅读了部分代码后，又会忘了之前学习的一些细节。而且对于在学习时已经厘清的概念和方法，等过一段时间之后，我发现又会变得模糊了。</p><p>后来，我自己在开发一个系统时，经常会去再回顾Redis源码。等这个系统开发完成后，我发现，原先变得模糊的Redis代码细节，已经变成深刻的记忆沉淀下来了。</p><p>在那个时候，我想明白了，<strong>源码阅读从来都不是一个一次性的学习过程。相反，源码阅读过程就像是DNA的双螺旋结构一样，是一个循环向上的过程。</strong>从源码阅读中学习开发知识，了解系统实现，然后再用学到的知识反哺自己的系统开发。而在开发过程中，又会再次阅读源码，进行学习，将自己的认知重新提升一个层次。这个过程周而复始，循环向上。</p><p>其实，我们日常的学习和做事跟源码阅读也是很相似的，它是一个循环向上的过程。很多事情并不是一蹴而就的，我们需要经历“认知、实践、再认知、再实践”这样一个过程。在这个过程中，我们会遇到困难，也会有收获，但是这些困难或收获都是为了下一次的认知和实践打基础。所以，<strong>我们不要因为一时的挫折而气馁，也不要因为一时的成就而停滞，就像生命之源的DNA结构一样，我们螺旋上升。</strong></p><h2><strong>写在最后</strong></h2><p>今天正好是周六，是个承前启后的时刻，这一季课程也要在今天正式画上一个句号了。不过，这个句号既是一个阶段的结束，更是一个新阶段的开始。</p><p>其实很多时候，你的成功并不取决于你知道了多少，而是你知道在无知的时候该怎么做。我希望上面讲的三点关于阅读源码的认知，能够给你的工作和生活提供一些指导方向。当我们在学习一个不会的知识点时，当我们在学习一门新的语言时，当我们面对生活中各种各样的情况必须孤立地做出反应时，我希望你能联想到学习源码的底层逻辑，从而更好地作出自己的选择。</p><p>最后，到了我们说再见的时候了，再次感谢你的一路相伴，我相信现在我们都成长了很多。而从今天起，我们在学习的道路上又将是一个新征程，让我们从新开始，学以致用。</p><p>最后的最后，我还给你准备了一份毕业问卷，希望你能花两三分钟填写一下，我非常期待能听到你对这门课的反馈。</p><p><a href=\"https://jinshuju.net/f/vasdJg\"><img src=\"https://static001.geekbang.org/resource/image/64/bc/64c4e4174ab844d70307a87b42898abc.jpg?wh=1142x801\" alt=\"\"></a></p><p>好了，天长地久有时尽，学习之路绵绵无绝期，我们下一次再会！</p>","neighbors":{"left":{"article_title":"答疑5 | 第25~32讲课后思考题答案及常见问题答疑","id":436330},"right":{"article_title":"结课测试 | 一套习题，测测你的Redis源码知识掌握程度","id":464431}}},{"article_id":464431,"article_title":"结课测试 | 一套习题，测测你的Redis源码知识掌握程度","article_content":"<p>你好，我是蒋德钧。</p><p>《Redis源码剖析与实战》课程已经完结了，很感谢你一直以来的认真学习和支持！为了帮助你检验自己的学习效果，我给你准备了一套结课测试题。这套测试题共有10道题目，包括7道单选题，3道多选题，满分100分，系统会自动评分。点击下面按钮，马上开始测试吧！</p><p><a href=\"http://time.geekbang.org/quiz/intro?act_id=1188&exam_id=3234\"><img src=\"https://static001.geekbang.org/resource/image/28/a4/28d1be62669b4f3cc01c36466bf811a4.png\" alt=\"\"></a></p><p>最后，我很希望听听你学习这个课程的感受。这里我为你准备了一份<a href=\"https://jinshuju.net/f/vasdJg\">毕业问卷</a>，题目不多，希望你可以花两分钟填一下。</p><!-- [[[read_end]]] -->","neighbors":{"left":{"article_title":"结束语 | Redis源码阅读，让我们从新开始","id":437870},"right":[]}}]