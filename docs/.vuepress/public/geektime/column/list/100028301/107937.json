{"id":107937,"title":"24 | 实战：处理四层流量，实现Memcached Server","content":"<p>你好，我是温铭。</p><p>在前面几节课中，我们介绍了不少处理请求的 Lua API ，不过它们都是和七层相关的。除此之外，OpenResty 其实还提供了 <code>stream-lua-nginx-module</code> 模块来处理四层的流量。它提供的指令和 API ，与 <code>lua-nginx-module</code> 基本一致。</p><p>今天，我就带你一起用 OpenResty 来实现一个 memcached server，而且大概只需要 100 多行代码就可以完成。在这个小的实战中，我们会用到不少前面学过的内容，也会带入一些后面测试和性能优化章节的内容。</p><p>所以，我希望你能够明确一点，我们这节课的重点，不在于你必须读懂每一行代码的具体作用，而是你要从需求、测试、开发等角度，把 OpenResty 如何从零开发一个项目的全貌了然于心。</p><h2>原始需求和技术方案</h2><p>在开发之前，我们都需要明白需求是什么，到底是用来解决什么问题的，否则就会在迷失在技术选择中。比如看到我们今天的主题，你就应该先反问一下自己，为什么要实现一个 memcached server 呢？直接安装一个原版的 memcached 或者 redis 不就行了吗？</p><p>我们知道，HTTPS 流量逐渐成为主流，但一些比较老的浏览器并不支持 session ticket，那么我们就需要在服务端把 session ID 存下来。如果本地存储空间不够，就需要一个集群进行存放，而这个数据又是可以丢弃的，所以选用 memcached 就比较合适。</p><!-- [[[read_end]]] --><p>这时候，直接引入 memcached ，应该是最简单直接的方案。但出于以下几个方面的考虑，我还是选择使用 OpenResty 来造一个轮子：</p><ul>\n<li>第一，直接引入会多引入一个进程，增加部署和维护成本；</li>\n<li>第二，这个需求足够简单，只需要 get 和 set 操作，并且支持过期即可；</li>\n<li>第三，OpenResty 有 stream 模块，可以很快地实现这个需求。</li>\n</ul><p>既然要实现 memcached server，我们就需要先弄明白它的协议。memcached 的协议可以支持 TCP 和 UDP，这里我选择 TCP，下面是 get 和 set 命令的具体协议：</p><pre><code>Get\n根据 key 获取 value\nTelnet command: get &lt;key&gt;*\\r\\n\n\n示例：\nget key\nVALUE key 0 4 data END\n\n</code></pre><pre><code>Set\n存储键值对到 memcached 中\nTelnet command：set &lt;key&gt; &lt;flags&gt; &lt;exptime&gt; &lt;bytes&gt; [noreply]\\r\\n&lt;value&gt;\\r\\n\n\n示例：\nset key 0 900 4 data\nSTORED\n</code></pre><p>除了 get 和 set 外，我们还需要知道 memcached 的协议的“错误处理”是怎么样做的。“错误处理”对于服务端的程序是非常重要的，我们在编写程序时，除了要处理正常的请求，也要考虑到各种异常。比如下面这样的场景：</p><ul>\n<li>memcached 发送了一个get、set 之外的请求，我要怎么处理呢？</li>\n<li>服务端出错，我要给 memcached 的客户端一个什么样的反馈呢？</li>\n</ul><p>同时，我们希望写出能够兼容 memcached 的客户端程序。这样，使用者就不用区分这是 memcached 官方的版本，还是 OpenResty 实现的版本了。</p><p>下面这张图出自memcached 的文档，描述了出错的时候，应该返回什么内容和具体的格式，你可以用做参考：</p><p><img src=\"https://static001.geekbang.org/resource/image/37/b0/3767ed0047e34aabaa7bf7d568438ab0.png\" alt=\"\"></p><p>现在，再来确定下技术方案。我们知道，OpenResty 的 shared dict 可以跨各个 worker 来使用，把数据放在 shared dict 里面，和放在 memcached 里面非常类似——它们都支持 get 和 set 操作，并且在进程重启后数据就丢失了。所以，使用 shared dict 来模拟 memcached 是非常合适的，它们的原理和行为都是一致的。</p><h2>测试驱动开发</h2><p>接下来就要开始动工了。不过，基于测试驱动开发的思想，在写具体的代码之前，让我们先来构造一个最简单的测试案例。这里我们不用 <code>test::nginx</code> 框架，毕竟它的上手难度也不低，我们不妨先用熟悉的 <code>resty</code> 来手动测试下：</p><pre><code>$ resty -e 'local memcached = require &quot;resty.memcached&quot;\n    local memc, err = memcached:new()\n\n    memc:set_timeout(1000) -- 1 sec\n    local ok, err = memc:connect(&quot;127.0.0.1&quot;, 11212)\n    local ok, err = memc:set(&quot;dog&quot;, 32)\n    if not ok then\n        ngx.say(&quot;failed to set dog: &quot;, err)\n        return\n    end\n\n    local res, flags, err = memc:get(&quot;dog&quot;)\n    ngx.say(&quot;dog: &quot;, res)'\n</code></pre><p>这段测试代码，使用 <code>lua-rety-memcached</code> 客户端库发起 connect 和 set 操作，并假设 memcached 的服务端监听本机的 11212 端口。</p><p>看起来应该没有问题了吧。你可以在自己的机器上执行一下这段代码，不出意外的话，会返回 <code>failed to set dog: closed</code> 这样的错误提示，因为此时服务并没有启动。</p><p>到现在为止，你的技术方案就已经明确了，那就是使用 stream 模块来接收和发送数据，同时使用 shared dict 来存储数据。</p><p>衡量需求是否完成的指标也很明确，那就是跑通上面这段代码，并把 dog 的实际值给打印出来。</p><h2>搭建框架</h2><p>那还等什么，开始动手写代码吧！</p><p>我个人的习惯，是先搭建一个最小的可以运行的代码框架，然后再逐步地去填充代码。这样的好处是，在编码过程中，你可以给自己设置很多小目标；而且在完成一个小目标后，测试案例也会给你正反馈。</p><p>让我们先来设置好 Nginx 的配置文件，因为stream 和 shared dict 要在其中预设。下面是我设置的配置文件：</p><pre><code>stream {\n    lua_shared_dict memcached 100m;\n    lua_package_path 'lib/?.lua;;';\n    server {\n        listen 11212;\n        content_by_lua_block {\n            local m = require(&quot;resty.memcached.server&quot;)\n            m.run()\n        }\n    }\n}\n</code></pre><p>你可以看到，这段配置文件中有几个关键的信息：</p><ul>\n<li>首先，代码运行在 Nginx 的 stream 上下文中，而非 HTTP 上下文中，并且监听了 11212 端口；</li>\n<li>其次，shared dict 的名字为 memcached，大小是 100M，这些在运行期是不可以修改的；</li>\n<li>另外，代码所在目录为 <code>lib/resty/memcached</code>, 文件名为 <code>server.lua</code>, 入口函数为 <code>run()</code>，这些信息你都可以从<code>lua_package_path</code> 和 <code>content_by_lua_block</code> 中找到。</li>\n</ul><p>接着，就该搭建代码框架了。你可以自己先动手试试，然后我们一起来看下我的框架代码：</p><pre><code>local new_tab = require &quot;table.new&quot;\nlocal str_sub = string.sub\nlocal re_find = ngx.re.find\nlocal mc_shdict = ngx.shared.memcached\n\nlocal _M = { _VERSION = '0.01' }\n\nlocal function parse_args(s, start)\nend\n\nfunction _M.get(tcpsock, keys)\nend\n\nfunction _M.set(tcpsock, res)\nend\n\nfunction _M.run()\n    local tcpsock = assert(ngx.req.socket(true))\n\n    while true do\n        tcpsock:settimeout(60000) -- 60 seconds\n        local data, err = tcpsock:receive(&quot;*l&quot;)\n\n        local command, args\n        if data then\n            local from, to, err = re_find(data, [[(\\S+)]], &quot;jo&quot;)\n            if from then\n                command = str_sub(data, from, to)\n                args = parse_args(data, to + 1)\n            end\n        end\n\n        if args then\n            local args_len = #args\n            if command == 'get' and args_len &gt; 0 then\n                _M.get(tcpsock, args)\n            elseif command == &quot;set&quot; and args_len == 4 then\n                _M.set(tcpsock, args)\n            end\n        end\n    end\nend\n\nreturn _M\n</code></pre><p>这段代码，便实现了入口函数 <code>run()</code> 的主要逻辑。虽然我还没有做异常处理，依赖的 <code>parse_args</code>、<code>get</code> 和 <code>set</code> 也都是空函数，但这个框架已经完整表达了memcached server 的逻辑。</p><h2>填充代码</h2><p>接下来，让我们按照代码的执行顺序，逐个实现这几个空函数。</p><p>首先，我们可以根据 memcached <a href=\"https://github.com/memcached/memcached/blob/master/doc/protocol.txt\">的协议</a><a href=\"https://github.com/memcached/memcached/blob/master/doc/protocol.txt\">文档</a>，解析 memcached 命令的参数：</p><pre><code>local function parse_args(s, start)\n    local arr = {}\n\n    while true do\n        local from, to = re_find(s, [[\\S+]], &quot;jo&quot;, {pos = start})\n        if not from then\n            break\n        end\n\n        table.insert(arr, str_sub(s, from, to))\n\n        start = to + 1\n    end\n\n    return arr\nend\n</code></pre><p>这里，我的建议是，先用最直观的方式来实现一个版本，不用考虑任何性能的优化。毕竟，完成总是比完美更重要，而且，基于完成的逐步优化才可以趋近完美。</p><p>接下来，我们就来实现下 <code>get</code> 函数。它可以一次查询多个键，所以下面代码中我用了一个 for 循环：</p><pre><code>function _M.get(tcpsock, keys)\n    local reply = &quot;&quot;\n\n    for i = 1, #keys do\n        local key = keys[i]\n        local value, flags = mc_shdict:get(key)\n        if value then\n            local flags  = flags or 0\n            reply = reply .. &quot;VALUE&quot; .. key .. &quot; &quot; .. flags .. &quot; &quot; .. #value .. &quot;\\r\\n&quot; .. value .. &quot;\\r\\n&quot;\n        end\n    end\n    reply = reply ..  &quot;END\\r\\n&quot;\n\n    tcpsock:settimeout(1000)  -- one second timeout\n    local bytes, err = tcpsock:send(reply)\nend\n</code></pre><p>其实，这里最核心的代码只有一行：<code>local value, flags = mc_shdict:get(key)</code>，也就是从 shared dict 中查询到数据；至于其余的代码，都在按照 memcached 的协议拼接字符串，并最终 send 到客户端。</p><p>最后，我们再来看下 <code>set</code> 函数。它将接收到的参数转换为 shared dict API 的格式，把数据储存了起来；并在出错的时候，按照 memcached 的协议做出处理：</p><pre><code>function _M.set(tcpsock, res)\n    local reply =  &quot;&quot;\n\n    local key = res[1]\n    local flags = res[2]\n    local exptime = res[3]\n    local bytes = res[4]\n\n    local value, err = tcpsock:receive(tonumber(bytes) + 2)\n\n    if str_sub(value, -2, -1) == &quot;\\r\\n&quot; then\n        local succ, err, forcible = mc_shdict:set(key, str_sub(value, 1, bytes), exptime, flags)\n        if succ then\n            reply = reply .. “STORED\\r\\n&quot;\n        else\n            reply = reply .. &quot;SERVER_ERROR &quot; .. err .. “\\r\\n”\n        end\n    else\n        reply = reply .. &quot;ERROR\\r\\n&quot;\n    end\n\n    tcpsock:settimeout(1000)  -- one second timeout\n    local bytes, err = tcpsock:send(reply)\nend\n</code></pre><p>另外，在填充上面这几个函数的过程中，你可以用测试案例来做检验，并用 <code>ngx.log</code> 来做 debug。比较遗憾的是，OpenResty 中并没有断点调试的工具，所以我们都是使用 <code>ngx.say</code> 和 <code>ngx.log</code> 来调试的，在这方面可以说是还处于刀耕火种的时代。</p><h2>写在最后</h2><p>这个实战项目到现在就接近尾声了，最后，我想留一个动手作业。你可以把上面 memcached server 的实现代码，完整地运行起来，并通过测试案例吗？</p><p>今天的作业题估计要花费你不少的精力了，不过，这还是一个原始的版本，还没有错误处理、性能优化和自动化测试，这些就要放在后面继续完善了。我也希望通过后面内容的学习，你最终能够完成一个完善的版本。</p><p>如果对于今天的讲解或者自己的实践有什么疑惑，欢迎你留言和我讨论。也欢迎你把这篇文章转发给你的同事朋友，我们一起实战，一起进步。</p><p></p>","neighbors":{"left":{"article_title":"23 | [视频]导读lua-resty-requests：优秀的lua-resty-*是如何编写的？","id":105621},"right":{"article_title":"25 | 答疑（二）：特权进程的权限到底是什么？","id":108662}},"comments":[]}