{"id":81374,"title":"25 | 马尔科夫模型：从PageRank到语音识别，背后是什么模型在支撑？","content":"<p>你好，我是黄申。</p><p>上一节，我们介绍了基于概率的语言模型。概率语言模型的研究对象其实是一个词的序列，以及这个词序列出现的概率有多大。那语言模型是不是也可以用于估算其他序列出现的概率呢？答案是肯定的。</p><p>通过上一节我们知道，语言模型中有个重点：马尔科夫假设及对应的多元文法模型。如果我们把这一点进一步泛化，就能引出马尔科夫模型。也就是说，只要序列的每个状态之间存在转移的概率，那么我们就可以使用马尔科夫模型。有时候情况会更复杂，不仅每个状态之间的转移是按照一定概率进行的，就连每个状态本身也是按照一定概率分布出现的，那么还需要用到隐马尔科夫模型。</p><p>今天这一节，我们就来学习马尔科夫模型、隐马尔科夫模型，以及它们在PageRank和语音识别中的应用。</p><h2>马尔科夫模型</h2><p>在介绍语言模型的时候，我们提到了马尔科夫假设，这个假设是说，每个词出现的概率和之前的一个或若干个词有关。我们换个角度思考就是，<strong>每个词按照一定的概率转移到下一个词</strong>。怎么个转移呢？我来解释一下。</p><p>如果把词抽象为一个状态，那么我们就可以认为，状态到状态之间是有关联的。前一个状态有一定的概率可以转移到到下一个状态。如果多个状态之间的随机转移满足马尔科夫假设，那么这类随机过程就是一个马尔科夫随机过程。而刻画这类随机过程的统计模型，就是<strong>马尔科夫模型</strong>（Markov Model）。</p><!-- [[[read_end]]] --><p>前面讲多元文法的时候，我提到了二元文法、三元文法。对于二元文法来说，某个词出现的概率只和前一个词有关。对应的，在马尔科夫模型中，如果一个状态出现的概率只和前一个状态有关，那么我们称它为<strong>一阶马尔科夫模型</strong>或者<strong>马尔科夫链</strong>。对应于三元、四元甚至更多元的文法，我们也有二阶、三阶等马尔科夫模型。</p><p>我们先从最简单的<strong>马尔科夫模型-马尔科夫链</strong>开始看。我画了一张示意图，方便你理解马尔科夫链中各个状态的转移过程。</p><p><img src=\"https://static001.geekbang.org/resource/image/90/b9/90537ae6b49b65b154d2084e6e8385b9.jpg?wh=1142*567\" alt=\"\"></p><p>在这张图中，你可以看到，从状态A到B的概率是0.1，从状态B到状态C的概率是0.2等等。我们也可以使用状态转移表来表示这张图。</p><p><img src=\"https://static001.geekbang.org/resource/image/10/44/108c8b522bd4ff6d1793230260c2c644.png?wh=1308*308\" alt=\"\"></p><p>我们可以根据某个应用的需要，把上述状态转移表具体化。例如，对于语言模型中的二元文法模型，我这里列出了一个示意表。</p><p><img src=\"https://static001.geekbang.org/resource/image/90/f4/90796185dff6955b48cb300ea11839f4.png?wh=1338*322\" alt=\"\"></p><p>当然，除了二元文法模型，马尔科夫链还有很多应用的场景。</p><p>Google公司最引以为傲的PageRank链接分析算法，它的核心思想就是基于马尔科夫链。这个算法假设了一个“随机冲浪者”模型，冲浪者从某张网页出发，根据Web图中的链接关系随机访问。在每个步骤中，冲浪者都会从当前网页的链出网页中随机选取一张作为下一步访问的目标。在整个Web图中，绝大部分网页节点都会有链入和链出。那么冲浪者就可以永不停歇地冲浪，持续在图中走下去。</p><p>在随机访问的过程中，越是被频繁访问的链接，越是重要。可以看出，每个节点的PageRank值取决于Web图的链接结构。假如一个页面节点有很多的链入链接，或者是链入的网页有较高的被访问率，那么它也将会有更高的被访问概率。</p><p>那么，PageRank的公式和马尔科夫链有什么关系呢？我先给你看一张Web的拓扑图。</p><p><img src=\"https://static001.geekbang.org/resource/image/84/bf/842598a61f0edc622552544603dbe9bf.jpg?wh=1142*621\" alt=\"\"></p><p>其中A、B、C等结点分别代表了页面，而结点之间的有向边代表了页面之间的超链接。看了这张图，你是不是觉得Web拓扑图和马尔科夫链的模型图基本上是一致的？我们可以假设每张网页就是一个状态，而网页之间的链接表明了状态转移的方向。这样，我们很自然地就可以使用马尔科夫链来刻画“随机冲浪者”。</p><p>另外，在最基本的PageRank算法中，我们可以假设每张网页的出度是$n$，那么从这张网页转移到任何下一张相连网页的概率都是$\\frac{1}{n}$，因此这个转移的概率只和当前页面有关，满足一阶马尔科夫模型的假设。我在之前的拓扑结构中添加了转移的概率。</p><p><img src=\"https://static001.geekbang.org/resource/image/ea/5d/ea12a997c4dff97a31991021860d0c5d.jpg?wh=1142*621\" alt=\"\"></p><p>PageRank在标准的马尔科夫链上，引入了随机的跳转操作，也就是假设冲浪者不按照Web图的拓扑结构走下去，只是随机挑选了一张网页进行跳转。这样的处理是类比人们打开一张新网页的行为，也是符合实际情况的，避免了信息孤岛的形成。最终，根据马尔科夫链的状态转移和随机跳转，可以得到如下的PageRank公式。</p><p><img src=\"https://static001.geekbang.org/resource/image/9a/b2/9afb3366f6b4d4c9aeeebc7e59e96bb2.png?wh=560*136\" alt=\"\"></p><p>其中，$p_{i}$表示第$i$张网页，$M_{i}$是$p_{i}$的入链接集合，$p_{j}$是$M_{i}$集合中的第$j$张网页。$PR_{(p_{j})}$表示网页$p_{j}$的PageRank得分，$L_{(p_{j})}$表示网页$p_{j}$的出链接数量，$\\frac{1}{L_{(p_{j})}}$就表示从网页$p_{j}$跳转到$p_{i}$的概率。$α$是用户不进行随机跳转的概率，$N$表示所有网页的数量。</p><p>从最简单的马尔科夫链，到多阶的马尔科夫模型，它们都可以刻画基于马尔科夫假设的随机过程，例如概率语言模型中的多元文法和PageRank这类链接分析算法。但是，这些模型都是假设每个状态对我们都是已知的，比如在概率语言模型中，一个状态对应了单词“上学”，另一个状态对应了单词“书包”。可是，有没有可能某些状态我们是未知的呢？下面我们就来详细说说这种情况。</p><h2>隐马尔科夫模型</h2><p>在某些现实的应用场景中，我们是无法确定马尔科夫过程中某个状态的取值的。这种情况下，最经典的案例就是语音识别。使用概率对语音进行识别的过程，和语言模型类似，因此我们可以把每个等待识别的词对应为马尔科夫过程中的一个状态。不过，语音识别所面临的困难更大。为什么呢？你先看看下面这个句子。这个句子里全都是拼音，你能看出它表示什么意思吗？</p><pre><code>ni(三声) zhi(一声) dao(四声) wo(三声) zai(四声) deng(三声) ni(三声) ma(一声)\n</code></pre><p>中国有句古话说得好，“白纸黑字”，写在文档里的文字对于计算机是确定的，“嘛”“吗”“妈”不会弄错。可是，如果你说一句“你知道我在等你吗”，听众可能一直弄不明白为什么要等别人的妈妈，除非你给他们看到文字版的内容，证明最后一个字是口字旁的“吗”。另外，再加上各种地方的口音、唱歌的发音或者不标准的拼读，情况就更糟糕了。</p><p>计算机只知道某个词的发音，而不知道它具体怎么写，对于这种情况，我们就认为计算机只能观测到每个状态的部分信息，而另外一些信息被“隐藏”了起来。这个时候，我们就需要用隐马尔科夫模型来解决这种问题。隐马尔科夫模型有两层，一层是我们可以观测到的数据，称为“输出层”，另一层则是我们无法直接观测到的状态，称为“隐藏状态层”。我画了一张图方便你理解。</p><p><img src=\"https://static001.geekbang.org/resource/image/77/75/77593998432b6290808a80c63b830f75.jpg?wh=1142*531\" alt=\"\"></p><p>其中，$x_{1}，x_{2}，x_{3}$等等属于隐藏状态层，$a_{12}$表示了从状态$x_{1}$到$x_{2}$的转移概率，$a_{23}$表示了从状态$x_{2}$到$x_{3}$的转移概率。这一层和普通的马尔科夫模型是一致的，可惜在隐马尔科夫模型中我们无法通过数据直接观测到这一层。我们所能看到的是，$y_{1}，y_{2}，y_{3}$等等代表的“输出层”。另外，$b_{11}$表示了从状态$x_{1}$到$y_{1}$的输出概率，$b_{22}$表示了从状态$x_{2}$到$y_{2}$的输出概率，$b_{33}$表示了从状态$x_{3}$到$y_{3}$的输出概率等等。</p><p>那么在这个两层模型示例中，“隐藏状态层”产生“输出层”的概率是多少呢？这是一系列条件概率决定的，具体的公式我列在这里。</p><p><img src=\"https://static001.geekbang.org/resource/image/80/7a/80bd25ad15e9d852cbea8b4ef1f4a67a.png?wh=1028*152\" alt=\"\"></p><p>如果你觉得这个两层的模型不太好理解，我来给你说个浅显易懂的例子。假设正在进行普通话语音识别，计算机接受了一个词组的发音。我在下面列出了它的拼音。</p><pre><code>xiang(四声)mu(四声) kai(一声)fa(一声) shi(四声)jian(四声)\n</code></pre><p>假设根据我们手头上的语料数据，这个词组有多种可能，我列出两种。</p><h3>第一种情况</h3><p><img src=\"https://static001.geekbang.org/resource/image/f7/88/f7df10338a0fda0fbecc9046fc6ea388.jpg?wh=1142*464\" alt=\"\"></p><p>第一种情况下，三个确定的状态是“项目”“开发”和“时间”这三个词。从“项目”转移到“开发”的概率是0.25，从“开发”转移到“时间”的概率是0.3。从“项目”输出“xiang（三声）mu（四声）”的概率是0.1，输出“xiang（四声）mu（四声）”的概率是0.8，输出“xiang（四声）mu（一声）”的概率是0.1，“开发”和“时间”也有类似的输出概率。</p><p>这个时候你可能会奇怪，“项目”的普通话发音就是“xiang（四声）mu（四声）”，为什么还会输出其他的发音呢？这是因为，前面说的这些概率都是通过历史语料的数据统计而来。在进行语音识别的时候，我们会通过不同地区、不同性别、不同年龄等等的人群，采集发音的样本。如此一来，影响这个发音的因素就很多了，比如方言、口音、误读等等。当然，在正常情况下，大部分的发音还是标准的，所以“项目”这个词输出到“xiang（四声）mu（四声）”的概率是最高的。</p><p>好，有了这些概率的分布，我们来看看“项目开发时间”这个词组最后生成的概率是多少。在两层模型的条件概率公式中，我代入了具体的概率值并使用了如下的推导：</p><p><img src=\"https://static001.geekbang.org/resource/image/7f/f4/7fd2cf482bbd849ff0dfb64d90e3a9f4.png?wh=1430*136\" alt=\"\"></p><h3>第二种情况</h3><p><img src=\"https://static001.geekbang.org/resource/image/d9/01/d9e15463a4a6d6e227f614da19d2c601.jpg?wh=1142*539\" alt=\"\"></p><p>在第二种的可能性中，三个确定的状态是“橡木”“开发”和“事件”这三个词。从“橡木”转移到“开发”的概率是0.015，从“开发”转移到“事件”的概率是0.05。从“橡木”输出“xiang（一声）mu（四声）”的概率是0.2，输出“xiang（四声）mu（四声）”的概率是0.8，“开发”和“事件”也有类似的输出概率。和第一种情况类似，我们可以计算“橡木开发事件”这个词组最后生成的概率是多少，我用下面这个公式来推导：</p><p><img src=\"https://static001.geekbang.org/resource/image/c9/07/c91f4ed6837cd11e6231c237a2ab9707.png?wh=1436*140\" alt=\"\"></p><p>最后比较第一种和第二种情况产生的概率，分别是P(项目)x0.0027和P(橡木)x0.000459。假设P(项目)和P(橡木)相等，那么“项目开发时间”这个词组的概率更高。所以“xiang（四声）mu（四声）kai（一声）fa（一声）shi（四声）jian（四声）”这组发音，计算机会识别为“项目开发时间”。从中我们可以看出，尽管“事件”这个词产生“shi（四声）jian（四声）”这个发音的可能性更高，但是“橡木开发事件”这个词组出现的概率极低，因此最终计算机还是选择了“项目开发时间”，隐藏的状态层起到了关键的作用。</p><h2>总结</h2><p>马尔科夫模型考虑了n个状态之间的转移及其对应的关系。这个状态是比较抽象的含义，在不同的应用领域代表不同的含义。在概率语言模型中，状态表示不同的词，状态之间的转移就代表了词按照一定的先后顺序出现。在PageRank这种链接分析中，状态表示不同的网页，状态之间的转移就代表了人们在不同网页之间的跳转。</p><p>在马尔科夫模型中，我们知道了每种状态及其之间转移的概率，然后求解序列出现的概率。然而，有些现实的场景更为复杂，比如说我们观测到的不是状态本身，而是状态按照一定概率分布所产生的输出。针对这种情况，隐马尔科夫模型提出了一种两层的模型，同时考虑了状态之间转移的概率和状态产生输出的概率，为语音识别、手写识别、机器翻译等提供了可行的解决方案。</p><p>隐马尔科夫模型需要回答的最主要问题是：给定一个模型和某个特定的输出序列，如何找到最可能产生这个输出的状态序列？在本节中，我使用了“项目开发时间”这个例子展示隐马尔科夫模型是如何工作的。不过这个例子很简单，我只比较了两种可能性。但是，实际中可能性是非常多的，如果我们使用穷举法，那么复杂度一定很高。</p><p>我们可以把两层的模型看作图结构。其中，状态和输出是结点，转移和输出关系是边，相应的概率是边的权重，这个时候我们就可以对Dijkstra算法稍加修改，来找出权重乘积最大的最优路径，提升查找的效率。我们还可以利用状态序列之间存在的先后关系，使用基于动态规划的维特比（Viterbi）算法来找出最优路径。</p><h2>思考题</h2><p>机器翻译会使用大量的语料，自动学习不同语言之间词和词的匹配。如果在机器翻译中使用隐马尔科夫进行建模，你认为“隐藏状态层”表示的是什么？“输出层”表示的又是什么？</p><p><span class=\"orange\">欢迎留言和我分享，也欢迎你在留言区写下今天的学习笔记。你可以点击“请朋友读”，把今天的内容分享给你的好友，和他一起精进。</span></p>","comments":[{"had_liked":false,"id":73126,"user_name":"qinggeouye","can_delete":false,"product_type":"c1","uid":1251536,"ip_address":"","ucode":"5B53EEDD7BEC9C","user_header":"https://static001.geekbang.org/account/avatar/00/13/18/d0/49b06424.jpg","comment_is_top":false,"comment_ctime":1551804678,"is_pvip":false,"replies":[{"id":"26765","content":"是的，理解正确","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1551893873,"ip_address":"","comment_id":73126,"utype":1}],"discussion_count":3,"race_medal":0,"score":"96041085190","product_id":100021201,"comment_content":"机器翻译，比如一个中文句子翻译为英文，中文句子可拆分为多个词，每个中文词可能会匹配多个英文单词，一句中文翻译为英文，可能会有多种翻译结果。那么：<br>隐藏状态层 -&gt; 多种翻译结果可能性中的一种<br>输出层 -&gt; 每个中文词可能匹配多个英文单词<br><br>这样理解不知是否正确？","like_count":22,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":441927,"discussion_content":"是的，理解正确","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1551893873,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1025119,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/a4/5f/6892585a.jpg","nickname":"LiuHDme","note":"","ucode":"C8A1437DDD487E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":550878,"discussion_content":"输出层应该是每个英文单词可能匹配的多个中文词吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1644766976,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1082785,"avatar":"https://static001.geekbang.org/account/avatar/00/10/85/a1/2442332c.jpg","nickname":"郭俊杰","note":"","ucode":"D328E5738A4413","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":264655,"discussion_content":"the same to me, 理解正确，哈哈","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589341607,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":66290,"user_name":"Thinking","can_delete":false,"product_type":"c1","uid":1155754,"ip_address":"","ucode":"1AAD6AE9F6B678","user_header":"https://static001.geekbang.org/account/avatar/00/11/a2/aa/bf65e8be.jpg","comment_is_top":false,"comment_ctime":1549906355,"is_pvip":false,"replies":[{"id":"23624","content":"这个问题很好！这主要是从统计的可行性出发，以语音识别为例，我们的语料（或者说标注数据、历史数据）都是给定文本，比如说中文，然后收集用户的发音（如果是中文，发音也就对应是拼音），所以可以很自然的拿到P(拼音|中文)这种概率。","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1550006730,"ip_address":"","comment_id":66290,"utype":1}],"discussion_count":1,"race_medal":0,"score":"74564350387","product_id":100021201,"comment_content":"不理解一个地方，由读音推测汉字的过程为什么要算P(xiang(4)mu(4)|项目）概率而不是P(项目|xiang(4)mu(4)）概率？隐马尔科夫解决由输出层找到产生输出的隐藏状态层，为什么不换个角度说成由看得到的输入层找到隐藏状态层呢？","like_count":17,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438773,"discussion_content":"这个问题很好！这主要是从统计的可行性出发，以语音识别为例，我们的语料（或者说标注数据、历史数据）都是给定文本，比如说中文，然后收集用户的发音（如果是中文，发音也就对应是拼音），所以可以很自然的拿到P(拼音|中文)这种概率。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1550006730,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":69476,"user_name":"Joe","can_delete":false,"product_type":"c1","uid":1337998,"ip_address":"","ucode":"EC76699640B7BF","user_header":"https://static001.geekbang.org/account/avatar/00/14/6a/8e/7b6ea886.jpg","comment_is_top":false,"comment_ctime":1550753339,"is_pvip":false,"replies":[{"id":"24687","content":"是的👍","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1550770075,"ip_address":"","comment_id":69476,"utype":1}],"discussion_count":1,"race_medal":0,"score":"48795393595","product_id":100021201,"comment_content":"隐马尔科夫模型在语音中的应用，流程是：<br>1，根据拼音去找到单个对应的词语，不考虑声调的概率。<br>2，再根据词语之间转移的概率，词语对应目标音高的概率，进而求出整个句子输出的概率。概率越大，可能性越高。<br>因此第一个词可以是xiangmu 对应语料库的所有词，不一定是四声，可以是香木之类的词语。<br>不知道这样理解对不对？<br>","like_count":11,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":440139,"discussion_content":"是的👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1550770075,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":112892,"user_name":"Temme","can_delete":false,"product_type":"c1","uid":1310995,"ip_address":"","ucode":"BCBA3A5570216A","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/eyKgpIVFSDQBia7SJRVUKFh5qgwc3ohzEPSKvchLf9ZvwIO9CrS470ER7OhNzWTs0svECHCBiarQTa41BO3Hf0DA/132","comment_is_top":false,"comment_ctime":1562838218,"is_pvip":false,"replies":[{"id":"41396","content":"很好的总结，第3点可以使用贝叶斯定理推导出来，你可以尝试一下","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1563119725,"ip_address":"","comment_id":112892,"utype":1}],"discussion_count":1,"race_medal":0,"score":"27332641994","product_id":100021201,"comment_content":"学习了之后，又看了几篇隐马尔可夫的一些收获：<br>隐马尔科夫适用于，只知道表象（观测层或者输出层），而内部的状态是隐藏的，未知的，可能有无数种的。语音识别分为3步<br>1.表象推测出隐藏，比如xiangmu的拼音读音可以推出隐藏的的实际字是项目，也可以是香木，各自有一定的概率，也可以是木香，只不过概率为0。推出概率在一定值以上的，做为隐藏状态。<br>2.各自推出隐藏的状态后，这些状态可以组合成各种状态链，比如橡木凯发世间这种，可以想象会有各种诡异的词组，这时候就用到马尔科夫状态转移的方法，筛选出靠谱的词组，得出结论，比如项目转开发转时间，这个状态转移的概率很高。概率在一定值以上的，挑出来作为状态序列。<br>3.语音识别只需要一个解。也是隐马尔科夫的关键，隐藏层推出表象层的概率（有点反人类认知，但是贝叶斯告诉我们这个无非是个数学的转换），大概就是，p(隐藏)*p(表象|隐藏)。好像p(表象|隐藏)，就是隐藏推表象的概率，其实不然，这里的推出还要考虑到隐藏层本身是个状态转移。","like_count":6,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":457945,"discussion_content":"很好的总结，第3点可以使用贝叶斯定理推导出来，你可以尝试一下","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563119725,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":207387,"user_name":"罗耀龙@坐忘","can_delete":false,"product_type":"c1","uid":1917663,"ip_address":"","ucode":"3CEA258DE7F3C7","user_header":"https://static001.geekbang.org/account/avatar/00/1d/42/df/a034455d.jpg","comment_is_top":false,"comment_ctime":1587079520,"is_pvip":true,"discussion_count":0,"race_medal":5,"score":"10177014112","product_id":100021201,"comment_content":"茶艺师学编程<br><br>思考题：如果机器翻译中使用以马尔科夫进行建模，那么隐藏状态层表示是什么？输出层表示的又是什么？<br><br>就拿中文和日语互相翻译来说。<br><br>如果说是中文翻译成日文，隐藏状态层则表示“翻译成日语的可能结果之一”，输出层则表示“需要翻译的中文”。<br><br>为什么选中日语来举例子呢？因为日语有这么一个特点：日语中的一类说法等于中文的很多种说法，换句话说日语x能对应到中文的y1、y2、y3、y4……这样隐马尔科夫看起来也像一个“梯形”。<br><br>关于马尔科夫模型：<br><br>马尔可夫过程要求满足四个条件 ——<br><br>第一，系统中有有限多个状态。<br><br>第二，状态之间切换的概率是固定的。<br><br>第三，系统要具有遍历性，也就是从任何一个状态出发，都能找到一条路线，切换到任何一个其他的状态。<br><br>第四，其中没有循环的情况，不能说几个状态形成闭环，把其他状态排斥在外。<br><br>而数学定理说，只要是马尔可夫过程，不管你的初始值如何，也不管你在这个过程中有什么一次性的干预，它终究会演化到一个统计的*平衡态*：其中每个状态所占的比例是不变的。","like_count":2},{"had_liked":false,"id":73029,"user_name":"唯她命","can_delete":false,"product_type":"c1","uid":1240398,"ip_address":"","ucode":"8F687E8D306840","user_header":"https://static001.geekbang.org/account/avatar/00/12/ed/4e/ef406442.jpg","comment_is_top":false,"comment_ctime":1551780346,"is_pvip":false,"replies":[{"id":"26575","content":"我看你另外一个问题，应该是已经理解了“隐藏状态层”和“输出层”的概念，简单的来理解，就是“隐藏层”到“输出层”是有一定概率分布的，不是必然的。如果必然了，就不需要区分这两层了，直接把“输出层”当做“隐藏层”就好了。<br>也正是因为如此，公式推导使用了条件概率公式。在“隐藏层”的某个状态给定的情况下，出现“输出层”某个输出的概率是多少，以此类推。","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1551811780,"ip_address":"","comment_id":73029,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10141714938","product_id":100021201,"comment_content":"老师你好  ， “隐藏状态层”产生“输出层”的概率   这句话是什么意思。<br>还有  “隐藏状态层”产生“输出层”的概率 那个公式是怎么推导出来的。","like_count":2,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":441882,"discussion_content":"我看你另外一个问题，应该是已经理解了“隐藏状态层”和“输出层”的概念，简单的来理解，就是“隐藏层”到“输出层”是有一定概率分布的，不是必然的。如果必然了，就不需要区分这两层了，直接把“输出层”当做“隐藏层”就好了。\n也正是因为如此，公式推导使用了条件概率公式。在“隐藏层”的某个状态给定的情况下，出现“输出层”某个输出的概率是多少，以此类推。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1551811780,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":182407,"user_name":"J.Smile","can_delete":false,"product_type":"c1","uid":1336475,"ip_address":"","ucode":"C4D98DFDBF7584","user_header":"https://static001.geekbang.org/account/avatar/00/14/64/9b/0b578b08.jpg","comment_is_top":false,"comment_ctime":1582782003,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5877749299","product_id":100021201,"comment_content":"要点：<br>隐马尔科夫模型需要回答的最主要问题是：给定一个模型和某个特定的输出序列，如何找到最可能产生这个输出的状态序列。","like_count":1},{"had_liked":false,"id":169995,"user_name":"学习学个屁","can_delete":false,"product_type":"c1","uid":1049017,"ip_address":"","ucode":"DF2D61E6FB2FCE","user_header":"https://static001.geekbang.org/account/avatar/00/10/01/b9/73435279.jpg","comment_is_top":false,"comment_ctime":1578490070,"is_pvip":false,"replies":[{"id":"66327","content":"这里容易混淆，举个例子，如果我们想将英文翻译成中文，那么输出层是英文，而隐藏层是中文，我们要看哪种中文的隐藏层，可以输出目标英文的概率最大，那么这个中文是最可能的翻译","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1578851691,"ip_address":"","comment_id":169995,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5873457366","product_id":100021201,"comment_content":"输出层 是输出的文字（被正确翻译的句子）  隐藏层句子中每个字 单词 背后的意思 ， 连在一起组成的顺通句子。  可以这么理解吧。","like_count":1,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":480800,"discussion_content":"这里容易混淆，举个例子，如果我们想将英文翻译成中文，那么输出层是英文，而隐藏层是中文，我们要看哪种中文的隐藏层，可以输出目标英文的概率最大，那么这个中文是最可能的翻译","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1578851691,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":163119,"user_name":"teddytyy","can_delete":false,"product_type":"c1","uid":1268738,"ip_address":"","ucode":"E1569D81A4154E","user_header":"https://static001.geekbang.org/account/avatar/00/13/5c/02/e7af1750.jpg","comment_is_top":false,"comment_ctime":1576659567,"is_pvip":false,"replies":[{"id":"62090","content":"分词是其中一步，还有就是对应的翻译。另外，假设咱们要把中文翻译成英文，我理解你说的源语言和目标语言分别对应于中文和英文。如果是这样，需要对调，也就是源语言（中文）是我们所能观测到的输出层，而目标语言（英文）是要分析出的状态层。","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1576696888,"ip_address":"","comment_id":163119,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5871626863","product_id":100021201,"comment_content":"输出层是目标语言的分词，状态层是源语言的分词，这么建模对吗？","like_count":1,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":478248,"discussion_content":"分词是其中一步，还有就是对应的翻译。另外，假设咱们要把中文翻译成英文，我理解你说的源语言和目标语言分别对应于中文和英文。如果是这样，需要对调，也就是源语言（中文）是我们所能观测到的输出层，而目标语言（英文）是要分析出的状态层。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1576696888,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":73042,"user_name":"唯她命","can_delete":false,"product_type":"c1","uid":1240398,"ip_address":"","ucode":"8F687E8D306840","user_header":"https://static001.geekbang.org/account/avatar/00/12/ed/4e/ef406442.jpg","comment_is_top":false,"comment_ctime":1551783077,"is_pvip":false,"replies":[{"id":"26574","content":"对文中的例子，这个理解是对的。至于思考题，我暂时不回答，给其他读者更多的思考机会 😆","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1551811621,"ip_address":"","comment_id":73042,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5846750373","product_id":100021201,"comment_content":"老师  语音识别的例子 <br>隐藏层  ：项目开发时间  或者 橡木开发事件<br>输出层  ： xiang(四声)mu(四声) kai(一声)fa(一声) shi(四声)jian(四声)<br>               xiang(一声)mu(-声) kai(一声)fa(一声)  shi(四声)jian(四声)<br>               xiang(四声)mu(-声) kai(一声)fa(一声)  shi(二声)jian(四声)<br>               等等所有可能的音调<br>不知道这么理解对不对？<br><br>另外还望老师解答下课后思考题","like_count":1,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":441888,"discussion_content":"对文中的例子，这个理解是对的。至于思考题，我暂时不回答，给其他读者更多的思考机会 😆","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1551811621,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":71866,"user_name":"李皮皮皮皮皮","can_delete":false,"product_type":"c1","uid":1200281,"ip_address":"","ucode":"3BF1DEE4A12359","user_header":"https://static001.geekbang.org/account/avatar/00/12/50/99/44378317.jpg","comment_is_top":false,"comment_ctime":1551456475,"is_pvip":false,"replies":[{"id":"26035","content":"不是这个意思。实际上每条出链接上的概率，表示给定出发点，到目标点的概率，是一种条件概率。比如，从A到B的概率是0.1，就是P(B|A)=0.1。所以，不能把这些条件概率相加。<br><br>我这里只是示意图，A可能还会链接到其他我没有画在图中的点，从A到所有目标点的概率加起来应该是1。比如从A出发一共到三个点，B，X和Y，P(B|A)=0.1，P(X|A)=0.5，P(Z|A)=0.4，加起来是1","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1551461328,"ip_address":"","comment_id":71866,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5846423771","product_id":100021201,"comment_content":"讲马尔可夫链的第一张图中，就是ABC的那种图，链上的概率是如何得出的？<br>我的理解是：根据语境中出现的AB，BC这些组合的概率，比如说总共有10个二元组，AB出现了一次，所以A到B的链上概率是0.1。如果按这么理解的话，那么所以的概率之和应该等于1吧。但是我算了一下，图中概率和等于1.1。不知道我理解的对不对，望老师解答😢","like_count":1,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":441369,"discussion_content":"不是这个意思。实际上每条出链接上的概率，表示给定出发点，到目标点的概率，是一种条件概率。比如，从A到B的概率是0.1，就是P(B|A)=0.1。所以，不能把这些条件概率相加。\n\n我这里只是示意图，A可能还会链接到其他我没有画在图中的点，从A到所有目标点的概率加起来应该是1。比如从A出发一共到三个点，B，X和Y，P(B|A)=0.1，P(X|A)=0.5，P(Z|A)=0.4，加起来是1","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1551461328,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":66549,"user_name":"拉欧","can_delete":false,"product_type":"c1","uid":1206605,"ip_address":"","ucode":"40996A8093A95F","user_header":"https://static001.geekbang.org/account/avatar/00/12/69/4d/81c44f45.jpg","comment_is_top":false,"comment_ctime":1549957494,"is_pvip":false,"replies":[{"id":"23623","content":"思路是对的👍<br>","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1550006517,"ip_address":"","comment_id":66549,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5844924790","product_id":100021201,"comment_content":"输出层：被翻译语言，隐藏状态层：翻译语言<br>比如要翻译 get busy living ,or get busy dying<br>输出层为 get busy living ,or get busy dying<br>隐藏层可能为：<br>1、要么忙于生存，要么赶着去死<br>2、忙于活，或忙于死<br>。。。<br>然后按照隐马尔科夫概率乘积选择概率最大的<br>不知道这么理解对不对？<br>","like_count":1,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438831,"discussion_content":"思路是对的👍\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1550006517,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":66548,"user_name":"","can_delete":false,"product_type":"c1","uid":1031328,"ip_address":"","ucode":"1B73BA45ACD06C","user_header":"https://static001.geekbang.org/account/avatar/00/0f/bc/a0/97c7679b.jpg","comment_is_top":false,"comment_ctime":1549957371,"is_pvip":false,"replies":[{"id":"23620","content":"后面我会多一些关于公式的解释，帮助理解","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1549993137,"ip_address":"","comment_id":66548,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5844924667","product_id":100021201,"comment_content":"硬着头皮看完。比如英文翻译目标语言，我认为要翻译的文本的直接看出来的特征（单词包括的意思），单词之间的语法规则和词性，时态是隐藏层。<br>数学差看起来就是费劲o(╥﹏╥)o，英文差看不懂最新论文。不清楚大家啥水平，我建议老师多给几个例子好理解些。深刻体会到没多一个公式，少一分看下去的兴趣。","like_count":1,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438830,"discussion_content":"后面我会多一些关于公式的解释，帮助理解","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1549993137,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":352897,"user_name":"013923","can_delete":false,"product_type":"c1","uid":3035193,"ip_address":"陕西","ucode":"1214DAADBCA848","user_header":"","comment_is_top":false,"comment_ctime":1658998748,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1658998748","product_id":100021201,"comment_content":"学习了，谢谢！","like_count":0},{"had_liked":false,"id":299944,"user_name":"张祈璟","can_delete":false,"product_type":"c1","uid":1400950,"ip_address":"","ucode":"DC7DDB3881633F","user_header":"https://static001.geekbang.org/account/avatar/00/15/60/76/be584def.jpg","comment_is_top":false,"comment_ctime":1624931939,"is_pvip":false,"replies":[{"id":"109164","content":"这个类比很形象👍","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1625762979,"ip_address":"","comment_id":299944,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1624931939","product_id":100021201,"comment_content":"关于马尔可夫猜想，是不是因为大多数人的大脑一般也就是一二阶的样子，所以跟人相关的一系列活动基本上都是一二阶，跟人无关的或者因为阶数太多人无法理解的就无解了","like_count":0,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":522594,"discussion_content":"这个类比很形象👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1625762979,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":232045,"user_name":"A君","can_delete":false,"product_type":"c1","uid":1940105,"ip_address":"","ucode":"FE96F089C2312C","user_header":"https://static001.geekbang.org/account/avatar/00/1d/9a/89/babe8b52.jpg","comment_is_top":false,"comment_ctime":1593842431,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1593842431","product_id":100021201,"comment_content":"根据马尔科夫假设和二元文法得出一阶马尔科夫模型，即当前状态是由前一个状态根据一定概率转换而成，这种状态的随机转换过程称为马尔科夫过程。如果这些状态并不确定，而是呈现某种概率分布，就需要用到隐马尔科夫模型。隐马尔科夫模型是二阶马尔科夫模型，隐藏状态层的状态只表示确定状态的部分信息，例如某个单词的隐藏状态表示的只是这个单词的词性。隐马尔科夫模型的第二层是输出层，表示隐藏状态经某概率转换后得到的确定状态。状态与状态之间，状态与输出之间，会根据某种概率进行转换，要计算这个句子出现的概率，可以计算第一个单词出现的概率乘以所有状态与状态，状态与输出之间转换🉐概率。","like_count":0},{"had_liked":false,"id":232044,"user_name":"A君","can_delete":false,"product_type":"c1","uid":1940105,"ip_address":"","ucode":"FE96F089C2312C","user_header":"https://static001.geekbang.org/account/avatar/00/1d/9a/89/babe8b52.jpg","comment_is_top":false,"comment_ctime":1593841256,"is_pvip":true,"replies":[{"id":"86133","content":"很高兴对你有价值","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1594313809,"ip_address":"","comment_id":232044,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1593841256","product_id":100021201,"comment_content":"在机器翻译里用隐马尔科夫建模，得到的不就是RNN么？隐藏状态层表示的是模型从一个词那提取到的信息，这些信息又会传到下一个step来帮助提取下一个词的信息。输出层是二元文法的预测结果，根据前一个词来预测后一个词。状态与状态之间，状态和结果之间，它们的概率用权重表示，在代码里就是用线性层、全连接层表示。","like_count":0,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":500489,"discussion_content":"很高兴对你有价值","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1594313809,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1940105,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/9a/89/babe8b52.jpg","nickname":"A君","note":"","ucode":"FE96F089C2312C","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":290068,"discussion_content":"谢谢老师，讲解得很透彻👍🏻","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1594335011,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":224559,"user_name":"建强","can_delete":false,"product_type":"c1","uid":1397126,"ip_address":"","ucode":"62B03D0E0C64EC","user_header":"https://static001.geekbang.org/account/avatar/00/15/51/86/b5fd8dd8.jpg","comment_is_top":false,"comment_ctime":1591442815,"is_pvip":false,"replies":[{"id":"83390","content":"是的👍","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1592102265,"ip_address":"","comment_id":224559,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1591442815","product_id":100021201,"comment_content":"思考题：机器翻译中，使用隐马尔科夫模型，隐藏层表示的是目标语言组成的句子，在输出层表示的是用源语言表达的待翻译句子的各种组合形式","like_count":0,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":497524,"discussion_content":"是的👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1592102265,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":207713,"user_name":"刘桢","can_delete":false,"product_type":"c1","uid":1482815,"ip_address":"","ucode":"3BFAB1C9772EB4","user_header":"https://static001.geekbang.org/account/avatar/00/16/a0/3f/06b690ba.jpg","comment_is_top":false,"comment_ctime":1587150661,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1587150661","product_id":100021201,"comment_content":"等一个茶艺师","like_count":0},{"had_liked":false,"id":201706,"user_name":"猛仔","can_delete":false,"product_type":"c1","uid":1135420,"ip_address":"","ucode":"7EFC244D8726D7","user_header":"https://static001.geekbang.org/account/avatar/00/11/53/3c/c86e3052.jpg","comment_is_top":false,"comment_ctime":1585821861,"is_pvip":true,"replies":[{"id":"75887","content":"个人觉得概率语言模型是马尔科夫模型的一种应用","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1586109469,"ip_address":"","comment_id":201706,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1585821861","product_id":100021201,"comment_content":"老师可不可以说马尔科夫模型是语言模型的进阶？<br>","like_count":0,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":490400,"discussion_content":"个人觉得概率语言模型是马尔科夫模型的一种应用","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586109469,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":198405,"user_name":"拉普达","can_delete":false,"product_type":"c1","uid":1930686,"ip_address":"","ucode":"0E524C0D99B2A0","user_header":"https://static001.geekbang.org/account/avatar/00/1d/75/be/6f3ab95e.jpg","comment_is_top":false,"comment_ctime":1585449882,"is_pvip":false,"replies":[{"id":"75046","content":"是的，这是特殊的图，输出层结点没有出度，重点在Dijkstra算法的边如何计算，考虑到隐马尔科夫模型的特点，需要考虑每个结点的概率（权重）和输出概率（权重）的乘积","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1585629703,"ip_address":"","comment_id":198405,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1585449882","product_id":100021201,"comment_content":"“对 Dijkstra 算法稍加修改，来找出权重乘积最大的最优路径，提升查找的效率。”这句话没太理解。构造出来的图，所有的输出层节点是没有出度的。如果进行最优路径计算，起点和终点分别是什么？是不是增加一个起点和终点，起点转移到所有第一个音节的权重都是0，所有最后一个音节转移到终点的权重也是0。然后计算起点到终点经过隐层节点的的最长路径？<br>","like_count":0,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":489698,"discussion_content":"是的，这是特殊的图，输出层结点没有出度，重点在Dijkstra算法的边如何计算，考虑到隐马尔科夫模型的特点，需要考虑每个结点的概率（权重）和输出概率（权重）的乘积","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1585629703,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":174876,"user_name":"吴小智","can_delete":false,"product_type":"c1","uid":1310798,"ip_address":"","ucode":"C7C9F58B5C9F7B","user_header":"https://static001.geekbang.org/account/avatar/00/14/00/4e/be2b206b.jpg","comment_is_top":false,"comment_ctime":1580444525,"is_pvip":false,"replies":[{"id":"68013","content":"涉及到实践的话，要考虑的东西就比较多。作为数学模型，我们只需要知道PageRank的公式，可是如果Web网络的规模相当之大，那么实现的时候就无法只存储在内存之中，就需要考虑磁盘和内存的切换，或者采用分布式系统来利用多台机器的内存，或者是采用近似的优化，降低内存的消耗。","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1580593589,"ip_address":"","comment_id":174876,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1580444525","product_id":100021201,"comment_content":"希望老师可以说一下这些模型在实际的工程项目中，主要的难点在哪里？比如说，在运用语言模型来解决 PageRank 的实践中，在那个步骤会是难点。","like_count":0,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":482555,"discussion_content":"涉及到实践的话，要考虑的东西就比较多。作为数学模型，我们只需要知道PageRank的公式，可是如果Web网络的规模相当之大，那么实现的时候就无法只存储在内存之中，就需要考虑磁盘和内存的切换，或者采用分布式系统来利用多台机器的内存，或者是采用近似的优化，降低内存的消耗。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1580593589,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":161447,"user_name":"南边","can_delete":false,"product_type":"c1","uid":1504736,"ip_address":"","ucode":"7967C01AAB4A70","user_header":"https://static001.geekbang.org/account/avatar/00/16/f5/e0/76822dd9.jpg","comment_is_top":false,"comment_ctime":1576207616,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1576207616","product_id":100021201,"comment_content":"尝试推导一下音频解析的公式：","like_count":0},{"had_liked":false,"id":131326,"user_name":"Paul Shan","can_delete":false,"product_type":"c1","uid":1593140,"ip_address":"","ucode":"32D99989028284","user_header":"","comment_is_top":false,"comment_ctime":1567721427,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1567721427","product_id":100021201,"comment_content":"思考题<br>输出层是原语言的句子，隐藏状态层是目标语言的单词和句子，我们要求解的是找到隐藏层中的句子，使得输出层（原语句，也就是被翻译的句子）出现概率最大。","like_count":0},{"had_liked":false,"id":131325,"user_name":"Paul Shan","can_delete":false,"product_type":"c1","uid":1593140,"ip_address":"","ucode":"32D99989028284","user_header":"","comment_is_top":false,"comment_ctime":1567721023,"is_pvip":false,"replies":[{"id":"50124","content":"不完全是，实际上需要用到贝叶斯定理进行推导，并用马尔科夫假设简化","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1567795494,"ip_address":"","comment_id":131325,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1567721023","product_id":100021201,"comment_content":"隐式马尔可夫的公式是不是计算y1 y2 y3 出现的联合概率，如果是的话，感觉少乘了两个p(x 1)，不知道是不是这样.","like_count":0,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":466390,"discussion_content":"不完全是，实际上需要用到贝叶斯定理进行推导，并用马尔科夫假设简化","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567795494,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":131324,"user_name":"Paul Shan","can_delete":false,"product_type":"c1","uid":1593140,"ip_address":"","ucode":"32D99989028284","user_header":"","comment_is_top":false,"comment_ctime":1567720295,"is_pvip":false,"replies":[{"id":"50123","content":"这里假设，有(1-α)的概率，从当前页面跳转到任何一个其他的页面，假设页面总共有N张，所以就是1&#47;N的概率了。","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1567795464,"ip_address":"","comment_id":131324,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1567720295","product_id":100021201,"comment_content":"Pagerank公式可以分成两部分，第一部分,根据入链接，计算出每个入链接对该页面的PageRank贡献。第二部分，是把这个值和1&#47;N，用α和1-α加权。第一部分体现的是其他指向该网页贡献。但是第二部分，我看不懂，老师能否解释一下，为什么要和1&#47;N加权，多谢！","like_count":0,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":466389,"discussion_content":"这里假设，有(1-α)的概率，从当前页面跳转到任何一个其他的页面，假设页面总共有N张，所以就是1/N的概率了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567795464,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":115503,"user_name":"凝神寂照","can_delete":false,"product_type":"c1","uid":1583746,"ip_address":"","ucode":"E71DA5A0C39656","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLBemRWsNxJt0WmF3rswPMnsO2ibRKok3OiakicIsFTe8xEudicnytT7zv07E26LfMBG4ic0XsZ87WNPlA/132","comment_is_top":false,"comment_ctime":1563607085,"is_pvip":false,"replies":[{"id":"42283","content":"确实是可以的，我理解PageRank不用高阶是为了减少计算量","user_name":"作者回复","user_name_real":"黄申","uid":"1275061","ctime":1563734501,"ip_address":"","comment_id":115503,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1563607085","product_id":100021201,"comment_content":"老师您好，对于PageRank的web拓扑图，网页A链接网页B，网页B链接网页C,一个网页只和前一个网页有关，这是一个一阶的马尔科夫链，但实际中网页A也可能链接C吧，为什么PageRank不用高阶的马尔科夫链呢？","like_count":0,"discussions":[{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":459134,"discussion_content":"确实是可以的，我理解PageRank不用高阶是为了减少计算量","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563734501,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]}]}