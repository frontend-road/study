{"id":83915,"title":"34丨AdaBoost（上）：如何使用AdaBoost提升分类器性能？","content":"<p>今天我们学习AdaBoost算法。在数据挖掘中，分类算法可以说是核心算法，其中AdaBoost算法与随机森林算法一样都属于分类算法中的集成算法。</p><p>集成的含义就是集思广益，博取众长，当我们做决定的时候，我们先听取多个专家的意见，再做决定。集成算法通常有两种方式，分别是投票选举（bagging）和再学习（boosting）。投票选举的场景类似把专家召集到一个会议桌前，当做一个决定的时候，让K个专家（K个模型）分别进行分类，然后选择出现次数最多的那个类作为最终的分类结果。再学习相当于把K个专家（K个分类器）进行加权融合，形成一个新的超级专家（强分类器），让这个超级专家做判断。</p><p>所以你能看出来，投票选举和再学习还是有区别的。Boosting的含义是提升，它的作用是每一次训练的时候都对上一次的训练进行改进提升，在训练的过程中这K个“专家”之间是有依赖性的，当引入第K个“专家”（第K个分类器）的时候，实际上是对前K-1个专家的优化。而bagging在做投票选举的时候可以并行计算，也就是K个“专家”在做判断的时候是相互独立的，不存在依赖性。</p><h2>AdaBoost的工作原理</h2><p>了解了集成算法的两种模式之后，我们来看下今天要讲的AdaBoost算法。</p><!-- [[[read_end]]] --><p>AdaBoost的英文全称是Adaptive Boosting，中文含义是自适应提升算法。它由Freund等人于1995年提出，是对Boosting算法的一种实现。</p><p>什么是Boosting算法呢？Boosting算法是集成算法中的一种，同时也是一类算法的总称。这类算法通过训练多个弱分类器，将它们组合成一个强分类器，也就是我们俗话说的“三个臭皮匠，顶个诸葛亮”。为什么要这么做呢？因为臭皮匠好训练，诸葛亮却不好求。因此要打造一个诸葛亮，最好的方式就是训练多个臭皮匠，然后让这些臭皮匠组合起来，这样往往可以得到很好的效果。这就是Boosting算法的原理。</p><p><img src=\"https://static001.geekbang.org/resource/image/8e/b4/8e88b8a952d872ea46b7dd7c084747b4.jpg?wh=2102*1439\" alt=\"\"><br>\n我可以用上面的图来表示最终得到的强分类器，你能看出它是通过一系列的弱分类器根据不同的权重组合而成的。</p><p>假设弱分类器为$G_{i}(x)$，它在强分类器中的权重$α_{i}$，那么就可以得出强分类器f(x)：</p><p><img src=\"https://static001.geekbang.org/resource/image/58/4f/58f7ff50e49f3cd96f6d4f0e590da04f.png?wh=183*67\" alt=\"\"><br>\n有了这个公式，为了求解强分类器，你会关注两个问题：</p><ol>\n<li>\n<p>如何得到弱分类器，也就是在每次迭代训练的过程中，如何得到最优弱分类器？</p>\n</li>\n<li>\n<p>每个弱分类器在强分类器中的权重是如何计算的？</p>\n</li>\n</ol><p>我们先来看下第二个问题。实际上在一个由K个弱分类器中组成的强分类器中，如果弱分类器的分类效果好，那么权重应该比较大，如果弱分类器的分类效果一般，权重应该降低。所以我们需要基于这个弱分类器对样本的分类错误率来决定它的权重，用公式表示就是：</p><p><img src=\"https://static001.geekbang.org/resource/image/32/24/3242899fb2e4545f0aedaab7a9368724.png?wh=178*79\" alt=\"\"><br>\n其中$e_{i}$代表第i个分类器的分类错误率。</p><p>然后我们再来看下第一个问题，如何在每次训练迭代的过程中选择最优的弱分类器？</p><p>实际上，AdaBoost算法是通过改变样本的数据分布来实现的。AdaBoost会判断每次训练的样本是否正确分类，对于正确分类的样本，降低它的权重，对于被错误分类的样本，增加它的权重。再基于上一次得到的分类准确率，来确定这次训练样本中每个样本的权重。然后将修改过权重的新数据集传递给下一层的分类器进行训练。这样做的好处就是，通过每一轮训练样本的动态权重，可以让训练的焦点集中到难分类的样本上，最终得到的弱分类器的组合更容易得到更高的分类准确率。</p><p>我们可以用$D_{k+1}$代表第k+1轮训练中，样本的权重集合，其中$W_{k+1,1}$代表第k+1轮中第一个样本的权重，以此类推$W_{k+1,N}$代表第k+1轮中第N个样本的权重，因此用公式表示为：</p><p><img src=\"https://static001.geekbang.org/resource/image/d9/b6/d9b32e1d065e39861f266709640b2bb6.png?wh=331*61\" alt=\"\"><br>\n第k+1轮中的样本权重，是根据该样本在第k轮的权重以及第k个分类器的准确率而定，具体的公式为：</p><p><img src=\"https://static001.geekbang.org/resource/image/1a/58/1a6c650c3b7aa6d44cccf3b9dff81258.png?wh=393*71\" alt=\"\"></p><h2>AdaBoost算法示例</h2><p>了解AdaBoost的工作原理之后，我们看一个例子，假设我有10个训练样本，如下所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/73/38/734c8272df1f96903be1777733a10f38.png?wh=630*75\" alt=\"\"><br>\n现在我希望通过AdaBoost构建一个强分类器。</p><p>该怎么做呢？按照上面的AdaBoost工作原理，我们来模拟一下。</p><p>首先在第一轮训练中，我们得到10个样本的权重为1/10，即初始的10个样本权重一致，D1=(0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1)。</p><p>假设我有3个基础分类器：</p><p><img src=\"https://static001.geekbang.org/resource/image/32/a4/325756eb08b5b3fd55402c9a8ba4dca4.png?wh=194*233\" alt=\"\"><br>\n我们可以知道分类器f1的错误率为0.3，也就是x取值6、7、8时分类错误；分类器f2的错误率为0.4，即x取值0、1、2、9时分类错误；分类器f3的错误率为0.3，即x取值为3、4、5时分类错误。</p><p>这3个分类器中，f1、f3分类器的错误率最低，因此我们选择f1或f3作为最优分类器，假设我们选f1分类器作为最优分类器，即第一轮训练得到：</p><p><img src=\"https://static001.geekbang.org/resource/image/3d/fb/3dd329577aef1a810a1c130095a3e0fb.png?wh=179*72\" alt=\"\"><br>\n根据分类器权重公式得到：</p><p><img src=\"https://static001.geekbang.org/resource/image/f9/60/f92e515d7ad7c1ee5f3bf45574bf3060.png?wh=266*76\" alt=\"\"><br>\n然后我们对下一轮的样本更新求权重值，代入$W_{k+1,i}$和$D_{k+1}$的公式，可以得到新的权重矩阵：D2=(0.0715, 0.0715, 0.0715, 0.0715, 0.0715, 0.0715, 0.1666, 0.1666, 0.1666, 0.0715)。</p><p>在第二轮训练中，我们继续统计三个分类器的准确率，可以得到分类器f1的错误率为0.1666*3，也就是x取值为6、7、8时分类错误。分类器f2的错误率为0.0715*4，即x取值为0、1、2、9时分类错误。分类器f3的错误率为0.0715*3，即x取值3、4、5时分类错误。</p><p>在这3个分类器中，f3分类器的错误率最低，因此我们选择f3作为第二轮训练的最优分类器，即：</p><p><img src=\"https://static001.geekbang.org/resource/image/68/40/687202173085a62e2c7b32deb05e9440.png?wh=200*79\" alt=\"\"><br>\n根据分类器权重公式得到：</p><p><img src=\"https://static001.geekbang.org/resource/image/ce/8b/ce8a4e319726f159104681a4152e3a8b.png?wh=245*70\" alt=\"\"><br>\n同样，我们对下一轮的样本更新求权重值，代入$W_{k+1,i}$和$D_{k+1}$的公式，可以得到D3=(0.0455,0.0455,0.0455,0.1667, 0.1667,0.01667,0.1060, 0.1060, 0.1060, 0.0455)。</p><p>在第三轮训练中，我们继续统计三个分类器的准确率，可以得到分类器f1的错误率为0.1060*3，也就是x取值6、7、8时分类错误。分类器f2的错误率为0.0455*4，即x取值为0、1、2、9时分类错误。分类器f3的错误率为0.1667*3，即x取值3、4、5时分类错误。</p><p>在这3个分类器中，f2分类器的错误率最低，因此我们选择f2作为第三轮训练的最优分类器，即：</p><p><img src=\"https://static001.geekbang.org/resource/image/88/15/8847a9e60b38a79c08086e1620d6d915.png?wh=192*70\" alt=\"\"><br>\n我们根据分类器权重公式得到：</p><p><img src=\"https://static001.geekbang.org/resource/image/0e/c3/0efb64e73269ee142cde91de532627c3.png?wh=267*86\" alt=\"\"><br>\n假设我们只进行3轮的训练，选择3个弱分类器，组合成一个强分类器，那么最终的强分类器G(x) = 0.4236G1(x) + 0.6496G2(x)+0.7514G3(x)。</p><p>实际上AdaBoost算法是一个框架，你可以指定任意的分类器，通常我们可以采用CART分类器作为弱分类器。通过上面这个示例的运算，你体会一下AdaBoost的计算流程即可。</p><h2>总结</h2><p>今天我给你讲了AdaBoost算法的原理，你可以把它理解为一种集成算法，通过训练不同的弱分类器，将这些弱分类器集成起来形成一个强分类器。在每一轮的训练中都会加入一个新的弱分类器，直到达到足够低的错误率或者达到指定的最大迭代次数为止。实际上每一次迭代都会引入一个新的弱分类器（这个分类器是每一次迭代中计算出来的，是新的分类器，不是事先准备好的）。</p><p>在弱分类器的集合中，你不必担心弱分类器太弱了。实际上它只需要比随机猜测的效果略好一些即可。如果随机猜测的准确率是50%的话，那么每个弱分类器的准确率只要大于50%就可用。AdaBoost的强大在于迭代训练的机制，这样通过K个“臭皮匠”的组合也可以得到一个“诸葛亮”（强分类器）。</p><p>当然在每一轮的训练中，我们都需要从众多“臭皮匠”中选择一个拔尖的，也就是这一轮训练评比中的最优“臭皮匠”，对应的就是错误率最低的分类器。当然每一轮的样本的权重都会发生变化，这样做的目的是为了让之前错误分类的样本得到更多概率的重复训练机会。</p><p>同样的原理在我们的学习生活中也经常出现，比如善于利用错题本来提升学习效率和学习成绩。</p><p><img src=\"https://static001.geekbang.org/resource/image/10/00/10ddea37b3fdea2ec019f38b59ac6b00.png?wh=1483*419\" alt=\"\"><br>\n最后你能说说你是如何理解AdaBoost中弱分类器，强分类器概念的？另外，AdaBoost算法是如何训练弱分类器从而得到一个强分类器的？</p><p>欢迎你在评论区与我分享你的答案，也欢迎点击“请朋友读”，把这篇文章分享给你的朋友或者同事。</p><p></p>","neighbors":{"left":{"article_title":"33丨PageRank（下）：分析希拉里邮件中的人物关系","id":83471},"right":{"article_title":"35丨AdaBoost（下）：如何使用AdaBoost对房价进行预测？","id":84086}},"comments":[{"had_liked":false,"id":71709,"user_name":"third","can_delete":false,"product_type":"c1","uid":1025114,"ip_address":"","ucode":"9A37408A834F0B","user_header":"https://static001.geekbang.org/account/avatar/00/0f/a4/5a/e708e423.jpg","comment_is_top":false,"comment_ctime":1551418815,"is_pvip":false,"replies":[{"id":"40555","content":"总结笔记做的很完善。这里Zk是归一化因子，使得Dk+1成为一个概率分布。yi属于标记集合{-1,+1}，1代表分类正确，-1代表分类错误。","user_name":"编辑回复","user_name_real":"何昌梅","uid":"1165037","ctime":1562554717,"ip_address":"","comment_id":71709,"utype":2}],"discussion_count":2,"race_medal":0,"score":"87450764735","product_id":100021701,"comment_content":"<br>作业<br>1.假设分类正确就是吃鸡成功。<br><br>1）训练多个弱分类器，并不断迭代弱分类器，选择最优弱分类器<br>枪法，一个弱分类器，你可以通过玩的越来越多，练习越来越好<br>身法，一个弱分类器，同理<br>意识，一个弱分类器。同理<br>···<br><br><br>2）将弱分类器组合起来，形成一个强分类器<br><br>枪法，身法，眼神，你只有一个的话，实际上，你的吃鸡概率并不高。但是三个都好的人，吃鸡概率就是高。这就是强分类器。<br><br>2.把分类正确理解成功的的话，<br><br>1）训练多个弱分类器，并不断迭代弱分类器，选择最优弱分类器<br>努力获取了一个领域的知识和道理，就是一个弱分类器，不断地学习和精进，在一个知识领域变得更强<br><br>3）将弱分类器组合起来，形成一个强分类器<br>合理跨界，将两个领域的知识组合起来，产生新收益。比如软硬件结合的苹果，仅一家公司就占据了整个手机市场利润的50%以上。<br><br>两个领域的组合，就是一个强分类器。<br><br><br>理解<br>1.通过修改样本的数据分布来实现算法的。<br>正确分类的，就少分点<br>错误分类的，就多分点。<br><br>像做题，<br>做正确的题，下次就少做点，反正会了。<br>做错的题，下次多做点，集中在错题上<br>每次这个题都在变化，随着你学习的深入，你做错的题会越来越少。<br><br><br>2.样本的权重时根据之前的k论权重以及k个分类器的准确率而定的。<br><br>你决定做什么样题。<br>1.取决于你上次做对了什么题，做错了什么题<br>2.做正确了，你就少做点。<br>3.做错了，你就多做点。<br><br>提问：Zk是啥意思？，yi是啥意思？<br><br>流程<br>1.获取基础权重<br>2.获取基础分类器<br>3.计算错误率，选择错误率最低的为最优分类器<br>4.通过计算分类器权重公式，达到减少正确样本数据分布，增加错误样本数据分布<br>5.代入W k+1,i和D k+1 的公式，得到新的权重矩阵<br>7.在新的权重矩阵上，计算错误率，选择错误最低的为最优分类器<br>剩下的就是迭代，重复<br>直到迭代完成，获得强分类器<br>","like_count":20,"discussions":[{"author":{"id":1165037,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c6/ed/89a2dc13.jpg","nickname":"丢了个丢丢丢","note":"","ucode":"BDD7E97E0E5E96","race_medal":0,"user_type":4,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":441290,"discussion_content":"总结笔记做的很完善。这里Zk是归一化因子，使得Dk+1成为一个概率分布。yi属于标记集合{-1,+1}，1代表分类正确，-1代表分类错误。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562554717,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":4}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1107127,"avatar":"https://static001.geekbang.org/account/avatar/00/10/e4/b7/6ad0ce1a.jpg","nickname":"george","note":"","ucode":"1DCB8BA50B47B5","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":2874,"discussion_content":"boost本身并不会提高弱分类器的准确性，也就是说多轮训练并不会提高枪法或者别的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1564010500,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":146108,"user_name":"清夜","can_delete":false,"product_type":"c1","uid":1352823,"ip_address":"","ucode":"B2086F6CA5ACC5","user_header":"https://static001.geekbang.org/account/avatar/00/14/a4/77/12913b94.jpg","comment_is_top":false,"comment_ctime":1572433585,"is_pvip":false,"replies":[{"id":"62686","content":"哈哈 这个解释很赞","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577084494,"ip_address":"","comment_id":146108,"utype":1}],"discussion_count":1,"race_medal":0,"score":"48817073841","product_id":100021701,"comment_content":"多个弱分类器训练成为一个强分类器。<br>类比为：<br>全班同学都做一张正常的高中试卷，但是每道题无论大小都是一样的分数。<br>1.  给得分最高的同学赋予一个比他人更高的权重，并且他做错的题目分数都提高一些。<br>2. 重新计分，选择此时分数最高的人赋予一定权重，提高他做错题目的分数。<br>3. 不断重复以上步骤。<br>4. 每个同学都重新有了权重之后，一个强分类器就诞生了。","like_count":11,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":472712,"discussion_content":"哈哈 这个解释很赞","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577084494,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":71708,"user_name":"王彬成","can_delete":false,"product_type":"c1","uid":1015045,"ip_address":"","ucode":"386803B8FC2DD5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg","comment_is_top":false,"comment_ctime":1551418700,"is_pvip":false,"replies":[{"id":"40554","content":"对弱分类器，强分类器，以及如何训练AdaBoost分类器总结的很好。","user_name":"编辑回复","user_name_real":"何昌梅","uid":"1165037","ctime":1562554584,"ip_address":"","comment_id":71708,"utype":2}],"discussion_count":1,"race_medal":0,"score":"35911157068","product_id":100021701,"comment_content":"如何理解 AdaBoost 中弱分类器，强分类器概念的？另外，AdaBoost 算法是如何训练弱分类器从而得到一个强分类器的？<br><br>1、弱分类器，是指基础分类器，正确率略高于50%的那种。<br>强分类器是通过训练出多个弱分类器，并赋值权重，最后形成弱分类器+权重的模型。<br><br>2、得到强分类器的方法：<br>参考链接：https:&#47;&#47;www.cnblogs.com&#47;hlongch&#47;p&#47;5734293.html<br>adaboost算法的核心思想是针对同一个训练集训练不同的分类器(弱分类器)，然后把这些弱分类器集合起来，构成一个更强的最终分类器(强分类器)。<br><br>1.一开始，给训练数据中的每一个样本，赋予其一个权重，权重都初始化成相等值。如（1&#47;样本数量）<br>2.首先在训练数据中训练出一个弱分类器并计算改分类器的错误率，选取错误率最小的分类器，并基于分类器错误率计算其权重值alpha。<br>3.在分类器的第二次训练当中，将会重新调整每个样本的权重，其中第一次分对的样本的权重将会降低，而第一次分错的样本权重将会提高。然后在同一数据集上再次训练弱分类器。得出第二个错误率小的分类器，并基于错误率计算权重。<br>4.重复“重新分配样本权重——计算分类器错误率——选取分类器——计算分类器权重”<br><br>5.最后将每次训练得到的分类器最后融合起来，作为最后的决策分类器。","like_count":8,"discussions":[{"author":{"id":1165037,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c6/ed/89a2dc13.jpg","nickname":"丢了个丢丢丢","note":"","ucode":"BDD7E97E0E5E96","race_medal":0,"user_type":4,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":441289,"discussion_content":"对弱分类器，强分类器，以及如何训练AdaBoost分类器总结的很好。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562554584,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":4}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":72342,"user_name":"Ehh1ouyz","can_delete":false,"product_type":"c1","uid":1141281,"ip_address":"","ucode":"02901EF418B237","user_header":"https://static001.geekbang.org/account/avatar/00/11/6a/21/e252b092.jpg","comment_is_top":false,"comment_ctime":1551592046,"is_pvip":false,"replies":[{"id":"64474","content":"对的","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577619774,"ip_address":"","comment_id":72342,"utype":1}],"discussion_count":3,"race_medal":0,"score":"31616363118","product_id":100021701,"comment_content":"补充：这里的Zk是归一化因子。","like_count":7,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":441550,"discussion_content":"对的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577619774,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1705590,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/06/76/a295d568.jpg","nickname":"ABETTERLIFE","note":"","ucode":"099E930EEDA6CF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":377118,"discussion_content":"我猜就是第一轮的0.1的来源 10个样本每个样本的权重 1/10","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1622513885,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1916654,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/3e/ee/82c2ef12.jpg","nickname":"是海港呀","note":"","ucode":"32AD09DB7B1F3B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":291097,"discussion_content":"归一化因子是啥。。。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1594705809,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":212832,"user_name":"Geek_c9fa4e","can_delete":false,"product_type":"c1","uid":1972305,"ip_address":"","ucode":"391982F33C1AAA","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/ziaN7rOONp15HJm6A9JoAYicJL8VA59x10DX4JZyvcfqmmpCnumXgAkNn37aFoALftyTaQNlUF7te54LibvVm20TQ/132","comment_is_top":false,"comment_ctime":1588218908,"is_pvip":false,"replies":[{"id":"103961","content":"Geek_c9fa4e同学总结的很棒，大家可以看下","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1617288360,"ip_address":"","comment_id":212832,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10178153500","product_id":100021701,"comment_content":"1、假设AdaBoost算法是球队<br>弱分类器：在众多球队里，踢得不好的队伍<br>强分类器：通过在弱分类不断地寻找出弱分类里面踢得好的，最后组成一个强的球队<br>2、如何训练成强分类器：<br>  1、首先初始化一个相同权重。<br>  2、然后在训练数据中计算弱分类·的错误率，选择错误率最低的去计算该权重<br>  3、接着再次训练，重新调整每个样本的权重，其中第一次分对的样本的权重将会降低，而第一次分错的样本权重将会提高。然后在同一数据集上再次训练弱分类器。得出第二个错误率小的分类器，并基于错误率计算权重。<br>  4、重复此步骤<br>  5、最后将每次训练得到的分类器最后融合起来，作为最后的决策分类器。","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493623,"discussion_content":"Geek_c9fa4e同学总结的很棒，大家可以看下","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617288360,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":154833,"user_name":"Ronnyz","can_delete":false,"product_type":"c1","uid":1488280,"ip_address":"","ucode":"9F34527B1D343D","user_header":"https://static001.geekbang.org/account/avatar/00/16/b5/98/ffaf2aca.jpg","comment_is_top":false,"comment_ctime":1574576966,"is_pvip":false,"replies":[{"id":"59714","content":"对的","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1574737160,"ip_address":"","comment_id":154833,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10164511558","product_id":100021701,"comment_content":"弱分类器：分类准确率比较低，可能在(50%~70%)之间<br>强分类器：在AdaBoost算法中，将一系列的弱分类器以不同的权重比组合作为最终分类选择<br>在筛选每一轮的最优分类器后，调整样本的权重，以获得一个更优的弱分类器。","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":475591,"discussion_content":"对的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1574737160,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":79046,"user_name":"三硝基甲苯","can_delete":false,"product_type":"c1","uid":1141929,"ip_address":"","ucode":"C492B058C2A5C0","user_header":"","comment_is_top":false,"comment_ctime":1553331327,"is_pvip":false,"replies":[{"id":"64387","content":"Good Sharing","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577618145,"ip_address":"","comment_id":79046,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10143265919","product_id":100021701,"comment_content":"根据我的反推，首先这里的所有涉及到对数和指数的都是以e为底的，然后就是Dk+1这一步，需要先计算Zk，这个就是把 wk*e^(-ak*y*Gk(x))把全部的加起来就是了，然后再去算Wk+1，然后就进一步可以算出Dk+1。<br>个人理解就是AdaBoost就是先把数据通过权重的方式分割成不同的部分，然后每个部分再去交给在这些里较为专业的分类器去分类，通过迭代，再把计算的结果带上权重后，就是结果了。","like_count":2,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":444338,"discussion_content":"Good Sharing","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577618145,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":185616,"user_name":"Untitled","can_delete":false,"product_type":"c1","uid":1039464,"ip_address":"","ucode":"8DD6ABA3E81A2E","user_header":"https://static001.geekbang.org/account/avatar/00/0f/dc/68/006ba72c.jpg","comment_is_top":false,"comment_ctime":1583647377,"is_pvip":false,"discussion_count":0,"race_medal":1,"score":"5878614673","product_id":100021701,"comment_content":"整个算法流程我自己理解为把上一次分类错误的缺点放大，优点缩小，然后等另一个分类器来把放到的缺点进行优化。","like_count":1},{"had_liked":false,"id":71652,"user_name":"那时刻","can_delete":false,"product_type":"c1","uid":1150927,"ip_address":"","ucode":"B0D150856C3A4A","user_header":"https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg","comment_is_top":false,"comment_ctime":1551407628,"is_pvip":false,"discussion_count":0,"race_medal":1,"score":"5846374924","product_id":100021701,"comment_content":"老师，你好。请问样本权重的计算公式是个指数函数exp，为啥是指数函数？不用指数的话，有啥不同么？","like_count":1},{"had_liked":false,"id":343643,"user_name":"教育兴国，科技强国","can_delete":false,"product_type":"c1","uid":2250851,"ip_address":"","ucode":"072D9266A0BD87","user_header":"https://static001.geekbang.org/account/avatar/00/22/58/63/5c98ef22.jpg","comment_is_top":false,"comment_ctime":1650964530,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1650964530","product_id":100021701,"comment_content":"这个样本权重的公式是咋样来的啊？<br>第 k+1 轮中的样本权重，是根据该样本在第 k 轮的权重以及第 k 个分类器的准确率而定，具体的公式就是那个：w(k+i,i)=.....","like_count":0},{"had_liked":false,"id":309959,"user_name":"佳成_Cahen","can_delete":false,"product_type":"c1","uid":2324353,"ip_address":"","ucode":"88091603E3AD9B","user_header":"https://static001.geekbang.org/account/avatar/00/23/77/81/9bc87164.jpg","comment_is_top":false,"comment_ctime":1630413942,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1630413942","product_id":100021701,"comment_content":"W_k+1_i的公式里那个Z_k是什么含义没有说明","like_count":0},{"had_liked":false,"id":205138,"user_name":"猛仔","can_delete":false,"product_type":"c1","uid":1135420,"ip_address":"","ucode":"7EFC244D8726D7","user_header":"https://static001.geekbang.org/account/avatar/00/11/53/3c/c86e3052.jpg","comment_is_top":false,"comment_ctime":1586537045,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1586537045","product_id":100021701,"comment_content":"老师想问一下在构建好强分类器后，在用强分类器进行分类时，每个样本还会按照在构造强分类器时的权重在弱分类器中进行运算么？","like_count":0},{"had_liked":false,"id":205053,"user_name":"Simon","can_delete":false,"product_type":"c1","uid":1914504,"ip_address":"","ucode":"A8A2E3E57BD029","user_header":"https://static001.geekbang.org/account/avatar/00/1d/36/88/20b6a6ee.jpg","comment_is_top":false,"comment_ctime":1586516829,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1586516829","product_id":100021701,"comment_content":"一个好问题：为什么每次迭代后，错误样本的权重变大了，而正确样本的权重变小了？怎么看出来的？","like_count":0},{"had_liked":false,"id":189314,"user_name":"William～Zhang","can_delete":false,"product_type":"c1","uid":1527138,"ip_address":"","ucode":"8659B589428F11","user_header":"https://static001.geekbang.org/account/avatar/00/17/4d/62/0fe9cbb3.jpg","comment_is_top":false,"comment_ctime":1584499422,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"1584499422","product_id":100021701,"comment_content":"请问老师，在计算错误率的时候，为什么是用样本权重 直接乘以错误个数，而不是，再除以10？","like_count":0,"discussions":[{"author":{"id":1706074,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/08/5a/4d709cf5.jpg","nickname":"Pray、PF","note":"","ucode":"1E3E4073763490","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":282656,"discussion_content":"这是由于ei=wki*指示函数然后再对i从1加到样本总个数，正确分类指示函数为0，错误分类指示函数为1","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1592039048,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1914504,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/36/88/20b6a6ee.jpg","nickname":"Simon","note":"","ucode":"A8A2E3E57BD029","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":227798,"discussion_content":"分类错误样本的权重之和就是分类错误率。不用再除以10。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586516615,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":185615,"user_name":"Untitled","can_delete":false,"product_type":"c1","uid":1039464,"ip_address":"","ucode":"8DD6ABA3E81A2E","user_header":"https://static001.geekbang.org/account/avatar/00/0f/dc/68/006ba72c.jpg","comment_is_top":false,"comment_ctime":1583646787,"is_pvip":false,"discussion_count":1,"race_medal":1,"score":"1583646787","product_id":100021701,"comment_content":"老师，上面第2次算的样本权重，我花了一个早上，怎么都算不出来跟您同样的结果，可以详细给下计算过程吗？或者加个微信，看看我究竟错了哪里，拜托","like_count":0,"discussions":[{"author":{"id":1981878,"avatar":"https://static001.geekbang.org/account/avatar/00/1e/3d/b6/e4a72acc.jpg","nickname":"Geeky_Ben","note":"","ucode":"4889BFC8BF6EB3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":294908,"discussion_content":"0.0715*3 = .2145\n1-.2145 = .7855\nLN(.7855/.2145) = 1.298011\n1.298011/2 = .649005\n可能会有误差","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1596028139,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":125248,"user_name":"juixv3937","can_delete":false,"product_type":"c1","uid":1486338,"ip_address":"","ucode":"C164F6641FE043","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/1rd5KVxbBWO1Jnq3syrfRQg0NGerVl4Dt7uHTMcy9A7KTqxmy7iaoomoWsjuHM4n7fBr0ESG8OqfJKCDHExzjvQ/132","comment_is_top":false,"comment_ctime":1566130986,"is_pvip":false,"replies":[{"id":"62758","content":"可以理解是ln，也就是以e为底数","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577089802,"ip_address":"","comment_id":125248,"utype":1}],"discussion_count":3,"race_medal":0,"score":"1566130986","product_id":100021701,"comment_content":"log没有底数怎么计算啊","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":463495,"discussion_content":"可以理解是ln，也就是以e为底数","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577089802,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1258042,"avatar":"https://static001.geekbang.org/account/avatar/00/13/32/3a/2d8a2c67.jpg","nickname":"Kyle","note":"","ucode":"96DE706AAC9D97","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":16486,"discussion_content":"不是以10为底，计算了一下是以e为底。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1568896393,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1136881,"avatar":"https://static001.geekbang.org/account/avatar/00/11/58/f1/0e934ca8.jpg","nickname":"Maybrittnelson","note":"","ucode":"944C9AB458F479","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":6433,"discussion_content":"从结果来看是以10为底的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1566896680,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":88096,"user_name":"滨滨","can_delete":false,"product_type":"c1","uid":1334567,"ip_address":"","ucode":"881EFA798BEE34","user_header":"https://static001.geekbang.org/account/avatar/00/14/5d/27/74e152d3.jpg","comment_is_top":false,"comment_ctime":1555847342,"is_pvip":false,"replies":[{"id":"64234","content":"总结的不错","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577615010,"ip_address":"","comment_id":88096,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1555847342","product_id":100021701,"comment_content":"弱分类器分类正确率比随机稍微高一点，每次选择相对最优的分类器，然后对分类错误的部分加强训练，最后得到一个强分类器。<br><br>1.一开始，给训练数据中的每一个样本，赋予其一个权重，权重都初始化成相等值。如（1&#47;样本数量）<br>2.首先在训练数据中训练出一个弱分类器并计算改分类器的错误率，选取错误率最小的分类器，并基于分类器错误率计算其权重值alpha。<br>3.在分类器的第二次训练当中，将会重新调整每个样本的权重，其中第一次分对的样本的权重将会降低，而第一次分错的样本权重将会提高。然后在同一数据集上再次训练弱分类器。得出第二个错误率小的分类器，并基于错误率计算权重。<br>4.重复“重新分配样本权重——计算分类器错误率——选取分类器——计算分类器权重”<br><br>5.最后将每次训练得到的分类器最后融合起来，作为最后的决策分类器。","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":447725,"discussion_content":"总结的不错","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577615010,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":76841,"user_name":"李沛欣","can_delete":false,"product_type":"c1","uid":1362695,"ip_address":"","ucode":"98874954230D95","user_header":"https://static001.geekbang.org/account/avatar/00/14/cb/07/e34220d6.jpg","comment_is_top":false,"comment_ctime":1552725257,"is_pvip":false,"replies":[{"id":"64413","content":"对的 三个臭皮匠顶个诸葛亮","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577618816,"ip_address":"","comment_id":76841,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1552725257","product_id":100021701,"comment_content":"通过训练多个弱分类器，集成一个强分类器。","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":443464,"discussion_content":"对的 三个臭皮匠顶个诸葛亮","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577618816,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":71926,"user_name":"Python","can_delete":false,"product_type":"c1","uid":1276314,"ip_address":"","ucode":"969500D2A88AE6","user_header":"https://static001.geekbang.org/account/avatar/00/13/79/9a/4f907ad6.jpg","comment_is_top":false,"comment_ctime":1551487311,"is_pvip":false,"replies":[{"id":"64481","content":"对的 集成学习","user_name":"作者回复","user_name_real":"cy","uid":"1306094","ctime":1577619897,"ip_address":"","comment_id":71926,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1551487311","product_id":100021701,"comment_content":"弱分类器是决策层，强分类器是决策汇总后的结果","like_count":0,"discussions":[{"author":{"id":1306094,"avatar":"https://static001.geekbang.org/account/avatar/00/13/ed/ee/c4779b67.jpg","nickname":"cy","note":"","ucode":"50D653399A31F6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":441398,"discussion_content":"对的 集成学习","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577619897,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":71864,"user_name":"忠超","can_delete":false,"product_type":"c1","uid":1363541,"ip_address":"","ucode":"6423AB04C065A8","user_header":"https://static001.geekbang.org/account/avatar/00/14/ce/55/00846acb.jpg","comment_is_top":false,"comment_ctime":1551455770,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1551455770","product_id":100021701,"comment_content":"您好。我有两个地方不明白，请老师答疑。为什么每次迭代的权重的计算方式是那么设置？另外，每次迭代得到的分类器前面的权重之和也不为1？还有，错误率等于权重乘以分类错误的个数，这个也不太理解。","like_count":0},{"had_liked":false,"id":71683,"user_name":"未来已来","can_delete":false,"product_type":"c1","uid":1187130,"ip_address":"","ucode":"3A21ACFD53CB9C","user_header":"https://static001.geekbang.org/account/avatar/00/12/1d/3a/cdf9c55f.jpg","comment_is_top":false,"comment_ctime":1551412278,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1551412278","product_id":100021701,"comment_content":"请问每次迭代之后，错误率是如何进行计算的呢？","like_count":0,"discussions":[{"author":{"id":1914504,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/36/88/20b6a6ee.jpg","nickname":"Simon","note":"","ucode":"A8A2E3E57BD029","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":227805,"discussion_content":"错误率就是分类错误样本的权重之和。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586516702,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":71682,"user_name":"未来已来","can_delete":false,"product_type":"c1","uid":1187130,"ip_address":"","ucode":"3A21ACFD53CB9C","user_header":"https://static001.geekbang.org/account/avatar/00/12/1d/3a/cdf9c55f.jpg","comment_is_top":false,"comment_ctime":1551411645,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1551411645","product_id":100021701,"comment_content":"我的显示界面中，很多数学符号变成了[Math Processing Error]","like_count":0}]}