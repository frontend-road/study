{"id":67531,"title":"06 | 新技术层出不穷，HDFS依然是存储的王者","content":"<p>我们知道，Google大数据“三驾马车”的第一驾是GFS（Google 文件系统），而Hadoop的第一个产品是HDFS，可以说分布式文件存储是分布式计算的基础，也可见分布式文件存储的重要性。如果我们将大数据计算比作烹饪，那么数据就是食材，而Hadoop分布式文件系统HDFS就是烧菜的那口大锅。</p><p>厨师来来往往，食材进进出出，各种菜肴层出不穷，而不变的则是那口大锅。大数据也是如此，这些年来，各种计算框架、各种算法、各种应用场景不断推陈出新，让人眼花缭乱，但是大数据存储的王者依然是HDFS。</p><p>为什么HDFS的地位如此稳固呢？在整个大数据体系里面，最宝贵、最难以代替的资产就是数据，大数据所有的一切都要围绕数据展开。HDFS作为最早的大数据存储系统，存储着宝贵的数据资产，各种新的算法、框架要想得到人们的广泛使用，必须支持HDFS才能获取已经存储在里面的数据。所以大数据技术越发展，新技术越多，HDFS得到的支持越多，我们越离不开HDFS。<strong>HDFS也许不是最好的大数据存储技术，但依然最重要的大数据存储技术</strong>。</p><p>那我们就从HDFS的原理说起，今天我们来聊聊<span class=\"orange\">HDFS是如何实现大数据高速、可靠的存储和访问的</span>。</p><p>Hadoop分布式文件系统HDFS的设计目标是管理数以千计的服务器、数以万计的磁盘，将这么大规模的服务器计算资源当作一个单一的存储系统进行管理，对应用程序提供数以PB计的存储容量，让应用程序像使用普通文件系统一样存储大规模的文件数据。</p><!-- [[[read_end]]] --><p>如何设计这样一个分布式文件系统？其实思路很简单。</p><p>我们先复习一下专栏上一期，我讲了RAID磁盘阵列存储，RAID将数据分片后在多块磁盘上并发进行读写访问，从而提高了存储容量、加快了访问速度，并通过数据的冗余校验提高了数据的可靠性，即使某块磁盘损坏也不会丢失数据。将RAID的设计理念扩大到整个分布式服务器集群，就产生了分布式文件系统，Hadoop分布式文件系统的核心原理就是如此。</p><p>和RAID在多个磁盘上进行文件存储及并行读写的思路一样，HDFS是在一个大规模分布式服务器集群上，对数据分片后进行并行读写及冗余存储。因为HDFS可以部署在一个比较大的服务器集群上，集群中所有服务器的磁盘都可供HDFS使用，所以整个HDFS的存储空间可以达到PB级容量。</p><p><img src=\"https://static001.geekbang.org/resource/image/65/d7/65efd126cbcf3930a706f64c6e6457d7.jpg?wh=1920*1142\" alt=\"\"></p><p>上图是HDFS的架构图，从图中你可以看到HDFS的关键组件有两个，一个是DataNode，一个是NameNode。</p><p><strong>DataNode负责文件数据的存储和读写操作，HDFS将文件数据分割成若干数据块（Block），每个DataNode存储一部分数据块，这样文件就分布存储在整个HDFS服务器集群中</strong>。应用程序客户端（Client）可以并行对这些数据块进行访问，从而使得HDFS可以在服务器集群规模上实现数据并行访问，极大地提高了访问速度。</p><p>在实践中，HDFS集群的DataNode服务器会有很多台，一般在几百台到几千台这样的规模，每台服务器配有数块磁盘，整个集群的存储容量大概在几PB到数百PB。</p><p><strong>NameNode负责整个分布式文件系统的元数据（MetaData）管理，也就是文件路径名、数据块的ID以及存储位置等信息，相当于操作系统中文件分配表（FAT）的角色</strong>。HDFS为了保证数据的高可用，会将一个数据块复制为多份（缺省情况为3份），并将多份相同的数据块存储在不同的服务器上，甚至不同的机架上。这样当有磁盘损坏，或者某个DataNode服务器宕机，甚至某个交换机宕机，导致其存储的数据块不能访问的时候，客户端会查找其备份的数据块进行访问。</p><p>下面这张图是数据块多份复制存储的示意，图中对于文件/users/sameerp/data/part-0，其复制备份数设置为2，存储的BlockID分别为1、3。Block1的两个备份存储在DataNode0和DataNode2两个服务器上，Block3的两个备份存储DataNode4和DataNode6两个服务器上，上述任何一台服务器宕机后，每个数据块都至少还有一个备份存在，不会影响对文件/users/sameerp/data/part-0的访问。</p><p><img src=\"https://static001.geekbang.org/resource/image/6f/ac/6f2faa48524251ad77e55e3565095bac.jpg?wh=720*404\" alt=\"\"></p><p>和RAID一样，数据分成若干数据块后存储到不同服务器上，可以实现数据大容量存储，并且不同分片的数据可以并行进行读/写操作，进而实现数据的高速访问。你可以看到，HDFS的大容量存储和高速访问相对比较容易实现，但是HDFS是如何保证存储的高可用性呢？</p><p>我们尝试从不同层面来讨论一下HDFS的高可用设计。</p><p>1.数据存储故障容错</p><p>磁盘介质在存储过程中受环境或者老化影响，其存储的数据可能会出现错乱。HDFS的应对措施是，对于存储在DataNode上的数据块，计算并存储校验和（CheckSum）。在读取数据的时候，重新计算读取出来的数据的校验和，如果校验不正确就抛出异常，应用程序捕获异常后就到其他DataNode上读取备份数据。</p><p>2.磁盘故障容错</p><p>如果DataNode监测到本机的某块磁盘损坏，就将该块磁盘上存储的所有BlockID报告给NameNode，NameNode检查这些数据块还在哪些DataNode上有备份，通知相应的DataNode服务器将对应的数据块复制到其他服务器上，以保证数据块的备份数满足要求。</p><p>3.DataNode故障容错</p><p>DataNode会通过心跳和NameNode保持通信，如果DataNode超时未发送心跳，NameNode就会认为这个DataNode已经宕机失效，立即查找这个DataNode上存储的数据块有哪些，以及这些数据块还存储在哪些服务器上，随后通知这些服务器再复制一份数据块到其他服务器上，保证HDFS存储的数据块备份数符合用户设置的数目，即使再出现服务器宕机，也不会丢失数据。</p><p>4.NameNode故障容错</p><p>NameNode是整个HDFS的核心，记录着HDFS文件分配表信息，所有的文件路径和数据块存储信息都保存在NameNode，如果NameNode故障，整个HDFS系统集群都无法使用；如果NameNode上记录的数据丢失，整个集群所有DataNode存储的数据也就没用了。</p><p>所以，NameNode高可用容错能力非常重要。NameNode采用主从热备的方式提供高可用服务，请看下图。</p><p><img src=\"https://static001.geekbang.org/resource/image/7c/89/7cb2668644c32364beab0b69e60b3689.png?wh=722*470\" alt=\"\"></p><p>集群部署两台NameNode服务器，一台作为主服务器提供服务，一台作为从服务器进行热备，两台服务器通过ZooKeeper选举，主要是通过争夺znode锁资源，决定谁是主服务器。而DataNode则会向两个NameNode同时发送心跳数据，但是只有主NameNode才能向DataNode返回控制信息。</p><p>正常运行期间，主从NameNode之间通过一个共享存储系统shared edits来同步文件系统的元数据信息。当主NameNode服务器宕机，从NameNode会通过ZooKeeper升级成为主服务器，并保证HDFS集群的元数据信息，也就是文件分配表信息完整一致。</p><p>对于一个软件系统而言，性能差一点，用户也许可以接受；使用体验差，也许也能忍受。但是如果可用性差，经常出故障导致不可用，那就比较麻烦了；如果出现重要数据丢失，那开发工程师绝对是摊上大事了。</p><p>而分布式系统可能出故障地方又非常多，内存、CPU、主板、磁盘会损坏，服务器会宕机，网络会中断，机房会停电，所有这些都可能会引起软件系统的不可用，甚至数据永久丢失。</p><p>所以在设计分布式系统的时候，软件工程师一定要绷紧可用性这根弦，思考在各种可能的故障情况下，如何保证整个软件系统依然是可用的。</p><p>根据我的经验，一般说来，常用的保证系统可用性的策略有冗余备份、失效转移和降级限流。虽然这3种策略你可能早已耳熟能详，但还是有一些容易被忽略的地方。</p><p>比如<strong>冗余备份</strong>，任何程序、任何数据，都至少要有一个备份，也就是说程序至少要部署到两台服务器，数据至少要备份到另一台服务器上。此外，稍有规模的互联网企业都会建设多个数据中心，数据中心之间互相进行备份，用户请求可能会被分发到任何一个数据中心，即所谓的异地多活，在遭遇地域性的重大故障和自然灾害的时候，依然保证应用的高可用。</p><p>当要访问的程序或者数据无法访问时，需要将访问请求转移到备份的程序或者数据所在的服务器上，这也就是<strong>失效转移</strong>。失效转移你应该注意的是失效的鉴定，像NameNode这样主从服务器管理同一份数据的场景，如果从服务器错误地以为主服务器宕机而接管集群管理，会出现主从服务器一起对DataNode发送指令，进而导致集群混乱，也就是所谓的“脑裂”。这也是这类场景选举主服务器时，引入ZooKeeper的原因。ZooKeeper的工作原理，我将会在后面专门分析。</p><p>当大量的用户请求或者数据处理请求到达的时候，由于计算资源有限，可能无法处理如此大量的请求，进而导致资源耗尽，系统崩溃。这种情况下，可以拒绝部分请求，即进行<strong>限流</strong>；也可以关闭部分功能，降低资源消耗，即进行<strong>降级</strong>。限流是互联网应用的常备功能，因为超出负载能力的访问流量在何时会突然到来，你根本无法预料，所以必须提前做好准备，当遇到突发高峰流量时，就可以立即启动限流。而降级通常是为可预知的场景准备的，比如电商的“双十一”促销，为了保障促销活动期间应用的核心功能能够正常运行，比如下单功能，可以对系统进行降级处理，关闭部分非重要功能，比如商品评价功能。</p><h2>小结</h2><p>我们小结一下，看看HDFS是如何通过大规模分布式服务器集群实现数据的大容量、高速、可靠存储、访问的。</p><p>1.文件数据以数据块的方式进行切分，数据块可以存储在集群任意DataNode服务器上，所以HDFS存储的文件可以非常大，一个文件理论上可以占据整个HDFS服务器集群上的所有磁盘，实现了大容量存储。</p><p>2.HDFS一般的访问模式是通过MapReduce程序在计算时读取，MapReduce对输入数据进行分片读取，通常一个分片就是一个数据块，每个数据块分配一个计算进程，这样就可以同时启动很多进程对一个HDFS文件的多个数据块进行并发访问，从而实现数据的高速访问。关于MapReduce的具体处理过程，我们会在专栏后面详细讨论。</p><p>3.DataNode存储的数据块会进行复制，使每个数据块在集群里有多个备份，保证了数据的可靠性，并通过一系列的故障容错手段实现HDFS系统中主要组件的高可用，进而保证数据和整个系统的高可用。</p><h2>思考题</h2><p>今天留一道有意思的思考题，你可以先想象一个场景，我们想利用全世界的个人电脑、手机、平板上的空闲存储空间，构成一个可以付费共享的分布式文件系统，希望用户可以安装一个App在自己的个人设备上，将个人资料安全地存储到这个分布式文件系统中，并支付一定费用；用户也可以用这个App将自己设备上的空闲存储空间共享出去，成为这个分布式文件系统存储的一部分，并收取一定费用。</p><p>我想问你的是，如果是你来设计这个分布式文件系统，你是怎么思考的？你的设计方案是什么？</p><p>欢迎你写下自己的思考或疑问，与我和其他同学一起讨论。</p><p></p>","comments":[{"had_liked":false,"id":37987,"user_name":"上个纪元的赵天师","can_delete":false,"product_type":"c1","uid":1046954,"ip_address":"","ucode":"ACEFB2264D2D05","user_header":"https://static001.geekbang.org/account/avatar/00/0f/f9/aa/65e78697.jpg","comment_is_top":false,"comment_ctime":1541841087,"is_pvip":false,"replies":[{"id":"13777","content":"很周全","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1542032484,"ip_address":"","comment_id":37987,"utype":1}],"discussion_count":4,"race_medal":0,"score":"482578178239","product_id":100020201,"comment_content":"听过本期音频，我想，在现实的条件下，实现这样的设想非常困难，例如：【1】用户空间（尤其是手机，iPad）不能保障高可用的性能，随时被访问被验证；【2】网络条件要求过高，尤其是被需求或者需要均衡时频繁的文件迁移；【3】要验证HDFS所有备份块的可用性，因此个人中端上不能过多不同用户，过碎的数据块；【4】为了保证系统的高效一般一块数据不会过小，要不然会浪费过多的计算资源（进程），如果单块数据在128M左右，自然会受到终端存储规模的制约【5】等等诸多隐患。因此，稳定的分布式端点还是必要的，不然文件将在诸多节点中频繁移动浪费大量的网络资源。【补】过于复杂的架构网络，对验证的响应延时也造成了麻烦。边走边打字暂时先想到这些😬","like_count":113,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":428548,"discussion_content":"很周全","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1542032484,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1664820,"avatar":"https://static001.geekbang.org/account/avatar/00/19/67/34/950a561c.jpg","nickname":"周宇盛","note":"","ucode":"B1FDDA46C4B74F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":13056,"discussion_content":"IPFS是一个实现类似功能的项目，但是因为存在大量不稳定的个人终端，所以暂时还很低效。","likes_number":6,"is_delete":false,"is_hidden":false,"ctime":1568636750,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1014146,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/79/82/c3cccc38.jpg","nickname":"IT生涯路漫漫","note":"","ucode":"4954D1CBEB4E44","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":567291,"discussion_content":"区块链技术","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1650877487,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1005126,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/56/46/abb7bfe3.jpg","nickname":"Weihai","note":"","ucode":"FAC5027BC24AC7","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":3164,"discussion_content":"棒","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1564238090,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":38184,"user_name":"文大头","can_delete":false,"product_type":"c1","uid":1167453,"ip_address":"","ucode":"465AD1CA5B6A1A","user_header":"https://static001.geekbang.org/account/avatar/00/11/d0/5d/9f9d73fe.jpg","comment_is_top":false,"comment_ctime":1541984123,"is_pvip":false,"replies":[{"id":"13767","content":"想的很周全","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1542031457,"ip_address":"","comment_id":38184,"utype":1}],"discussion_count":1,"race_medal":0,"score":"173340675963","product_id":100020201,"comment_content":"1、互联网上用户交分散，需要用CDN的模式，分层分区域部署NameNode，NameNode上数据汇总到上级，上级数据按需分发到下级。同一个区域的用户（DataNode）分配到同一个NameNode<br>2、用户DataNode机器可用性极差，按10%算，平均一个数据需要10个备份。不过可以有一定策略改进，比如让用户活跃时间跟用户等级挂钩，等级跟功能挂钩，以鼓励用户增加在线时间；存储数据可以分级别，高级别数据备份更多，可用性安全性速度更高，级别低备份少。<br>3、安全性考虑，其他用户存储在NameNode上的数据，不能被宿主机破解查看和修改<br>暂时想了这些，感觉再想下去要变成百度网盘或者迅雷了","like_count":40,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":428634,"discussion_content":"想的很周全","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1542031457,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":37973,"user_name":"方得始终","can_delete":false,"product_type":"c1","uid":1229356,"ip_address":"","ucode":"6FBEDDACC32EA1","user_header":"https://static001.geekbang.org/account/avatar/00/12/c2/2c/900cb4f0.jpg","comment_is_top":false,"comment_ctime":1541833328,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"96031113840","product_id":100020201,"comment_content":"最近两大Hadoop发行商Cloudera 和Hortonworksg合并,网上包括极客时间也报道过HDFS跟云端对象存储系统已没有性能和价格上的优势.在我工作实践中也碰见过HDFS上存储的文件丢失,虽然只是一个机架(rack)断电.请问老师对此有何看法?","like_count":22,"discussions":[{"author":{"id":1316454,"avatar":"https://static001.geekbang.org/account/avatar/00/14/16/66/083e7f7e.jpg","nickname":"silent","note":"","ucode":"325D31F0608249","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":265507,"discussion_content":"如果是三副本默认策略的话是至少分两个机架，可能是配置不合理？当然hadoop的一个大问题就是配置复杂，无法开箱即用","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1589414813,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":153970,"user_name":"张小喵","can_delete":false,"product_type":"c1","uid":1708090,"ip_address":"","ucode":"2CD5003020D751","user_header":"https://static001.geekbang.org/account/avatar/00/1a/10/3a/053852ee.jpg","comment_is_top":false,"comment_ctime":1574338747,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"70293815483","product_id":100020201,"comment_content":"西电bbs，西电睿思就是使用这个原理，睿思上有庞大的数据，比如上万部电影，电视剧，学习资料，等等，都是分布式存储在睿思用户的本地pc上的，使用的是uTorrrent客户端，每次下载都是从在线的同学的pc上并行下载，下载速度很快，由于校园网内部之间走的流量是不计费的，所以在费用上面没有任何制约，本地存储的数据被他人下载的越多，会赢得更多的金币，使用金币可以去下载资源，以及“炫富”，伸手党如果总是关闭本地共享存储客户端，没有流量，那么他们能下载的资源会越来越有限，最后只能下载免费资源。金币奖励机制保证了平台的良性发展。很nice。 移动端作为共享存储客户端的话，我觉得流量费是个很大的限制，没有人想被在不知情的情况下被消费自己的移动流量，毕竟不是免费的。而且可恶的三大运营商还会限速.....我觉得，如果什么时候本地存储足够多了，流量足够便宜了，网速足够快了，客户端安全做的足够好了 那么这种共享存储的模式才会全面推广。","like_count":17,"discussions":[{"author":{"id":1372865,"avatar":"","nickname":"骆驼","note":"","ucode":"6488F52A953A9C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":385152,"discussion_content":"你这是p2p下载，早期的电驴原理","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1626921275,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":43513,"user_name":"多襄丸","can_delete":false,"product_type":"c1","uid":1074310,"ip_address":"","ucode":"1AA1497C5A293C","user_header":"https://static001.geekbang.org/account/avatar/00/10/64/86/f5a9403a.jpg","comment_is_top":false,"comment_ctime":1543234976,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"65967744416","product_id":100020201,"comment_content":"老师、我想提一个问题： 主NameNode 向 Sared Edits 写数据的过程中、主Namenade 没洗完的数据是不是会丢失？ 那这样 从NameNode被选举为主NameNode 后，是不是会有一部分数据找不见存在哪个DataNode上了？ 大家都可以回答哈 另外 一个数据块 在什么情况下、不是一个分区？","like_count":15},{"had_liked":false,"id":41133,"user_name":"牛油果","can_delete":false,"product_type":"c1","uid":1047154,"ip_address":"","ucode":"897D927418C609","user_header":"https://static001.geekbang.org/account/avatar/00/0f/fa/72/5c801d71.jpg","comment_is_top":false,"comment_ctime":1542730245,"is_pvip":true,"replies":[{"id":"14782","content":"深刻👍🏻","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1542764807,"ip_address":"","comment_id":41133,"utype":1}],"discussion_count":1,"race_medal":0,"score":"48787370501","product_id":100020201,"comment_content":"讲技术不讲技术脉络的也都是流氓啊。那些去中心化存储的区块链项目，就没谁写出去中心存储应是借鉴或发展于hdfs等分布式存储方案。raid到hdfs立马好理解多了。我是看过ipfs，storj，sia等几个去中心化的存储方案。通过看今天的内容，我突然感觉开窍了，他们整得太复杂了，基于hdfs加上存储时空证明就能实现去中心化存储，实现高可用的技术细节考虑的当然不同了，而存储时空权益就把终端的高可用工作分散到具体用户了。当然，namenode是中心化部署还是代理节点部署还是要考虑一下。另，通过用户贡献的存储时长和空间换来的受益，这对用户的约束可能会随时间变化而减少，进而存储的可用性是不稳定的，但这里我想了两个方案:1，用户贡献出来的资源是为了储值的，获得权益是要零存整取，加大惩罚成本(这个估计他们实际做的会想到，我当时看时反正没看到)；2，整个分布式系统加一套蓝光备份系统，这种低成本数据存储方案是对要求高可用数据的备选项。","like_count":11,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":429705,"discussion_content":"深刻👍🏻","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1542764807,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":61054,"user_name":"张晓生","can_delete":false,"product_type":"c1","uid":1228996,"ip_address":"","ucode":"42F6A91947F5E5","user_header":"https://static001.geekbang.org/account/avatar/00/12/c0/c4/dfbad982.jpg","comment_is_top":false,"comment_ctime":1547609252,"is_pvip":false,"replies":[{"id":"21814","content":"NameNode在本地有操作日志，可以利用这个日志进行恢复操作，但是前提是原来的主NameNode的硬盘没坏，还有就是恢复需要时间。","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1547688799,"ip_address":"","comment_id":61054,"utype":1}],"discussion_count":1,"race_medal":0,"score":"44497282212","product_id":100020201,"comment_content":"如果在一台nameNode服务器元数据有修改但是还没来得及热备到从nameNode服务器，这个时候刚好主nameNode服务器挂了，zookeeper选举出新的主服务器(之前的从节点)，就会造成当前的主nameNode节点数据不正确。请问这种问题怎么解决呢？","like_count":10,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":436725,"discussion_content":"NameNode在本地有操作日志，可以利用这个日志进行恢复操作，但是前提是原来的主NameNode的硬盘没坏，还有就是恢复需要时间。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1547688799,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":38018,"user_name":"朱国伟","can_delete":false,"product_type":"c1","uid":1083343,"ip_address":"","ucode":"A8547956D9C372","user_header":"https://static001.geekbang.org/account/avatar/00/10/87/cf/7bec93d8.jpg","comment_is_top":false,"comment_ctime":1541860724,"is_pvip":true,"replies":[{"id":"13773","content":"DataNode即使重启也认为其上的数据已经丢失，不会再使用。<br>","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1542032072,"ip_address":"","comment_id":38018,"utype":1}],"discussion_count":1,"race_medal":0,"score":"44491533684","product_id":100020201,"comment_content":"关于DataNode 故障容错感觉处理起来好复杂啊 假设numReplicas=2 由于机器故障导致DataNode 1宕机 此时为了保证numReplicas=2会复制数据 像下面的情况怎么处理呢<br>- 等全部复制完了  DataNode1重启了 那此时numReplicas=3 这种情况会处理吗？<br>- 或者复制到一半（即有些Block还没来得及复制） DataNode1重启了 这种情况又怎么办<br>- 或者集群勉强够用 实在没有多余的机器来复制DataNode1对应的数据了 又该如何<br><br>并且要是掉电或是网络异常 可能不是一个DataNode宕机 可能是怎个机架整个机房的DataNode的都宕机了 <br><br>","like_count":11,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":428563,"discussion_content":"DataNode即使重启也认为其上的数据已经丢失，不会再使用。\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1542032072,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":38232,"user_name":"落叶飞逝的恋","can_delete":false,"product_type":"c1","uid":1046429,"ip_address":"","ucode":"F9A95DB28BCF1E","user_header":"https://static001.geekbang.org/account/avatar/00/0f/f7/9d/be04b331.jpg","comment_is_top":false,"comment_ctime":1541995610,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"40196701274","product_id":100020201,"comment_content":"关于思考题的想法:首先这个就是各大厂商的提出的云服务的概念。而对于手机、ipad的这些设备作为分布式容器的一部分，是不可取的。首先不能不确保手机的网速的可用性，而且三大运营商都有流量这个概念。第二，手机无法实时的给NameNode进行发送心跳，因为用户可以主动关闭网络，或者用户在无网区域。","like_count":9,"discussions":[{"author":{"id":1025474,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/a5/c2/41fa26df.jpg","nickname":"楊威","note":"","ucode":"8BA77716CE8179","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":540528,"discussion_content":"筛选出十分之一较稳定的用户也很大规模了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1640076099,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":38424,"user_name":"鸠摩智","can_delete":false,"product_type":"c1","uid":1106201,"ip_address":"","ucode":"853E584FC4CD64","user_header":"https://static001.geekbang.org/account/avatar/00/10/e1/19/c756aaed.jpg","comment_is_top":false,"comment_ctime":1542033775,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"35901772143","product_id":100020201,"comment_content":"如果在hdfs上存储了大量的小文件，每个文件都不到一个块（128M）大小。而每个文件确实是单独的，比如一张张图片，不能把它们合并为一个大文件，这样即使一个文件namenode只存储几字节的元数据，是不是也有可能超出namenode单台机器限制了呢？","like_count":8},{"had_liked":false,"id":38167,"user_name":"wmg","can_delete":false,"product_type":"c1","uid":1070036,"ip_address":"","ucode":"BA4CED171B59E9","user_header":"https://static001.geekbang.org/account/avatar/00/10/53/d4/2ed767ea.jpg","comment_is_top":false,"comment_ctime":1541983219,"is_pvip":false,"replies":[{"id":"13768","content":"很赞，不过NameNode不应该是存储空间的制约，该怎么办？","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1542031619,"ip_address":"","comment_id":38167,"utype":1}],"discussion_count":1,"race_medal":0,"score":"31606754291","product_id":100020201,"comment_content":"类似于hdfs的机制，只不过将用户设备作为datanode，namenode是中心化的（否则和区块链就比较类似）。有几个问题需要考虑：1.用户设备存储空间有限，所以block的大小不能太大；2.由于block不能太大所以元数据会比较大，对namenode存储空间要求较高；3.由于datanode是不可信的，所以需要对datanode设计身份识别机制，存储的数据也必须是加密，副本数量也要设置的多一些；4.由于所有的datanode都需要和namenode通信，所以datanode的数量会有限制，这样就限制了整个集群的存储空间，可以考虑多集群的方式，用户注册的时候利用负载平衡算法将用户划分到其中一个集群。暂时想到这么多，请老师指教。","like_count":7,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":428628,"discussion_content":"很赞，不过NameNode不应该是存储空间的制约，该怎么办？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1542031619,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":37926,"user_name":"一步","can_delete":false,"product_type":"c1","uid":1005391,"ip_address":"","ucode":"73CEA468CE70C3","user_header":"https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg","comment_is_top":false,"comment_ctime":1541812709,"is_pvip":true,"replies":[{"id":"13781","content":"是的","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1542032978,"ip_address":"","comment_id":37926,"utype":1}],"discussion_count":1,"race_medal":1,"score":"27311616485","product_id":100020201,"comment_content":"这个思考题的实现思路是和IPFS的实现思路应该一样的","like_count":7,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":428528,"discussion_content":"是的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1542032978,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":42689,"user_name":"Jack Zhu","can_delete":false,"product_type":"c1","uid":1266238,"ip_address":"","ucode":"8425B570880F28","user_header":"https://static001.geekbang.org/account/avatar/00/13/52/3e/a0614b62.jpg","comment_is_top":false,"comment_ctime":1543020879,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"18722890063","product_id":100020201,"comment_content":"“如果 DataNode 监测到本机的某块磁盘损坏，就将该块磁盘上存储的所有 BlockID 报告给NameNode。”<br>有个疑问，望解答:磁盘损坏，怎么获得BlockID，BlockID存在哪？","like_count":4,"discussions":[{"author":{"id":1207581,"avatar":"https://static001.geekbang.org/account/avatar/00/12/6d/1d/ad948ab8.jpg","nickname":"1","note":"","ucode":"2E427E32669F76","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":4412,"discussion_content":"分发的时候Namenode会记录","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1565393779,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":299982,"user_name":"阿文","can_delete":false,"product_type":"c1","uid":1467219,"ip_address":"","ucode":"B53454CA52BD7E","user_header":"https://static001.geekbang.org/account/avatar/00/16/63/53/b4590ccc.jpg","comment_is_top":false,"comment_ctime":1624946424,"is_pvip":false,"replies":[{"id":"108789","content":"设计上是不需要的，client开始访问NameNode的时候已经获取了所有副本的信息，一个副本出错，client可以自己决定是否切换其他副本。<br><br>实现中client应该需要向NameNode汇报错误，NameNode可以据此修正出错的副本。","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1624953855,"ip_address":"","comment_id":299982,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14509848312","product_id":100020201,"comment_content":"请问下，数据报错转到其他 DataNode 上读取备份数据。这个过程需要 经过 NameNode 吗？","like_count":3,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":522604,"discussion_content":"设计上是不需要的，client开始访问NameNode的时候已经获取了所有副本的信息，一个副本出错，client可以自己决定是否切换其他副本。\n\n实现中client应该需要向NameNode汇报错误，NameNode可以据此修正出错的副本。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1624953855,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":171517,"user_name":"极无宪","can_delete":false,"product_type":"c1","uid":1309726,"ip_address":"","ucode":"B86438E0930A95","user_header":"https://static001.geekbang.org/account/avatar/00/13/fc/1e/1e48fd05.jpg","comment_is_top":false,"comment_ctime":1578959804,"is_pvip":false,"replies":[{"id":"66477","content":"不是","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1578964530,"ip_address":"","comment_id":171517,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14463861692","product_id":100020201,"comment_content":"如果 DataNode 监测到本机的某块磁盘损坏，就将该块磁盘上存储的所有 BlockID 报告给 NameNode？<br>如果已经损坏了，DataNode怎么获取到BlockID的，BlockID与数据不是存在一起的吗？","like_count":3,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":481393,"discussion_content":"不是","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1578964530,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":153972,"user_name":"张小喵","can_delete":false,"product_type":"c1","uid":1708090,"ip_address":"","ucode":"2CD5003020D751","user_header":"https://static001.geekbang.org/account/avatar/00/1a/10/3a/053852ee.jpg","comment_is_top":false,"comment_ctime":1574339381,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"14459241269","product_id":100020201,"comment_content":"补充一点，西电睿思平台的 也有“冗余备份“的思想，学生使用ut客户端下载了电影、学习资料等文件到本地pc，那么这个pc就是一个DataNode，一个电影肯定会有很多人下载，那么这些所有下载了这个电影的同学的pc中的下载数据就形成了“冗余备份”","like_count":3},{"had_liked":false,"id":37924,"user_name":"姜文","can_delete":false,"product_type":"c1","uid":1235142,"ip_address":"","ucode":"338CC5635B02BC","user_header":"https://static001.geekbang.org/account/avatar/00/12/d8/c6/1f471053.jpg","comment_is_top":false,"comment_ctime":1541812104,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"14426713992","product_id":100020201,"comment_content":"首先要部署个name node存储元数据，记录用户数据存储的位置，为保证name node的高可用，必须做备份，通过zookeeper选举主 name node，data node就是全世界的移动设备，用户的数据要做备份，至少三份，用户的app必须和name node的主备服务器做心跳，用于移动设备故障时能主动上报或者name node能及时发现保证数据可用。用户如果要存储数据必须通知name node做好元数据记录及datanode的数据备份。第一次回答，请老师指教。","like_count":3},{"had_liked":false,"id":252256,"user_name":"a(๑≖ิټ≖ิ)✌","can_delete":false,"product_type":"c1","uid":1392431,"ip_address":"","ucode":"AEF9B5CA1605DF","user_header":"https://static001.geekbang.org/account/avatar/00/15/3f/2f/8513c4d3.jpg","comment_is_top":false,"comment_ctime":1602214935,"is_pvip":false,"discussion_count":0,"race_medal":1,"score":"10192149527","product_id":100020201,"comment_content":"IPFS和迅雷的玩客云不都是这样设计的吗，涉及到很多用户的话，肯定要多冗余一些备份，这样挂掉一堆依然保证可用；为了保证速度，用户在首次取数据时把数据存在本地和周边用户节点上，下次查询就会很快了。这个系统最重要的问题是成本问题吧","like_count":2},{"had_liked":false,"id":177147,"user_name":"龙儿快看我的大雕","can_delete":false,"product_type":"c1","uid":1423442,"ip_address":"","ucode":"263E71448EEC05","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/F9CTB6Fkv6pyaP3iaYkSDC6ksv0GXsZOXyzeudxPDiczxuAibQNNibNXc4HRScMQyrSoZ4b2cEfkNlO6uM7hhJyURg/132","comment_is_top":false,"comment_ctime":1581303032,"is_pvip":false,"replies":[{"id":"68784","content":"你看的应该是没有实现高可用NameNode的部署方法。https:&#47;&#47;hadoop.apache.org&#47;docs&#47;stable&#47;hadoop-project-dist&#47;hadoop-hdfs&#47;HDFSHighAvailabilityWithNFS.html#Automatic_Failover","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1581314026,"ip_address":"","comment_id":177147,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10171237624","product_id":100020201,"comment_content":"老师，您说hadoop的hdfs是依赖zookeeper实现的，但是我在网上跟着集群搭建的步骤来弄，都没看到要安装zookeeper，这是咋回事？","like_count":2,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":483321,"discussion_content":"你看的应该是没有实现高可用NameNode的部署方法。https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithNFS.html#Automatic_Failover","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1581314026,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":139532,"user_name":"达子不一般","can_delete":false,"product_type":"c1","uid":1315527,"ip_address":"","ucode":"A91C8DB45184F7","user_header":"https://static001.geekbang.org/account/avatar/00/14/12/c7/a7a5df8b.jpg","comment_is_top":false,"comment_ctime":1570673558,"is_pvip":false,"replies":[{"id":"54050","content":"复制成功后返回客户端写入成功。","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1570773325,"ip_address":"","comment_id":139532,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10160608150","product_id":100020201,"comment_content":"dataNode1应该是返回客户端写成功之后然后再异步复制到其他dataNode2上吧？这个时候如果dataNode1宕机了怎么办？","like_count":2,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":469984,"discussion_content":"复制成功后返回客户端写入成功。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570773325,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":93794,"user_name":"子榕","can_delete":false,"product_type":"c1","uid":1048188,"ip_address":"","ucode":"943C2A27B9D7C5","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83ep8ibEQqN1Slfh9Vg0YJcXcico7NKfl9evCeMpNKZCVE2KWtz3f404LejIsGFFzcubpW5WvhC9ibYevQ/132","comment_is_top":false,"comment_ctime":1557597373,"is_pvip":false,"replies":[{"id":"33529","content":"大数据对于硬件和环境没有约束和要求的，主要是看你的业务场景是否适合","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1557658624,"ip_address":"","comment_id":93794,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10147531965","product_id":100020201,"comment_content":"老师请问下hdfs一般集群规模都会上百吗？那像我们小公司是不是没有意义啦，我们现在每天日志量100g左右，适合用hdfs来存储吗？单机采购什么规格的合适（几核几g多少t存储）？","like_count":2,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":449773,"discussion_content":"大数据对于硬件和环境没有约束和要求的，主要是看你的业务场景是否适合","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1557658624,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":88550,"user_name":"之外^Excepts","can_delete":false,"product_type":"c1","uid":1035331,"ip_address":"","ucode":"FD2284F65DB22F","user_header":"https://static001.geekbang.org/account/avatar/00/0f/cc/43/59a9b4ae.jpg","comment_is_top":false,"comment_ctime":1555940338,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10145874930","product_id":100020201,"comment_content":"这讲的诸多点让我想到了区块链，脑裂，不就是共识算法问题引起的经典拜占庭问题( •̥́ ˍ •̀ू )。这把客户端当数据存储节点也是各种币做交易记录数据库的玩儿法","like_count":2},{"had_liked":false,"id":50132,"user_name":"dingwood","can_delete":false,"product_type":"c1","uid":1153828,"ip_address":"","ucode":"460EB0C6E8C611","user_header":"https://static001.geekbang.org/account/avatar/00/11/9b/24/1e4883c6.jpg","comment_is_top":false,"comment_ctime":1544876174,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10134810766","product_id":100020201,"comment_content":"Shared edits是啥。。网上搜半天没找到，求指点","like_count":2},{"had_liked":false,"id":39299,"user_name":"谢烟客","can_delete":false,"product_type":"c1","uid":1004766,"ip_address":"","ucode":"DC9E1F82AFE67D","user_header":"https://static001.geekbang.org/account/avatar/00/0f/54/de/fabe5f93.jpg","comment_is_top":false,"comment_ctime":1542244781,"is_pvip":false,"replies":[{"id":"14146","content":"没有必要，DataNode已经是对多个数据块并行访问磁盘，所以无需raid0","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1542294563,"ip_address":"","comment_id":39299,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10132179373","product_id":100020201,"comment_content":"既然 DataNode 已经完成了冗余备份了，是不是我们就可以在 DataNode 节点的存储选用上使用 raid0 提升一下性能呢？","like_count":3,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":429002,"discussion_content":"没有必要，DataNode已经是对多个数据块并行访问磁盘，所以无需raid0","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1542294563,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":39048,"user_name":"小文同学","can_delete":false,"product_type":"c1","uid":1001893,"ip_address":"","ucode":"48F2AEB989C12A","user_header":"https://static001.geekbang.org/account/avatar/00/0f/49/a5/e4c1c2d4.jpg","comment_is_top":false,"comment_ctime":1542178782,"is_pvip":false,"replies":[{"id":"14015","content":"会重新备份","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1542239051,"ip_address":"","comment_id":39048,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10132113374","product_id":100020201,"comment_content":"关于分布式文件系统，我想向老师提个问题：<br>DataNode的备份在同步过程中假如出现了错误，NameNode在读取时校验后放弃某个DataNode的数据块，那么会重新为DataNode的那块数据生成新的备份么？<br>这些极端的情况，分布式文件系统是不是也无法百分百顾及，在设计上还是会保留容忍么？","like_count":2,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":428893,"discussion_content":"会重新备份","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1542239051,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":37918,"user_name":"鸠摩智","can_delete":false,"product_type":"c1","uid":1106201,"ip_address":"","ucode":"853E584FC4CD64","user_header":"https://static001.geekbang.org/account/avatar/00/10/e1/19/c756aaed.jpg","comment_is_top":false,"comment_ctime":1541809589,"is_pvip":true,"replies":[{"id":"13783","content":"实践中并不会发生这种情况～<br>一个block 64M，NameNode只需要记录几个字节","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1542033370,"ip_address":"","comment_id":37918,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10131744181","product_id":100020201,"comment_content":"如果hdfs的元数据信息超过了单台namenode的存储上限，要怎么解决呢？","like_count":2,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":428526,"discussion_content":"实践中并不会发生这种情况～\n一个block 64M，NameNode只需要记录几个字节","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1542033370,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":37908,"user_name":"往事随风，顺其自然","can_delete":false,"product_type":"c1","uid":1235692,"ip_address":"","ucode":"F266EC6B143E38","user_header":"https://static001.geekbang.org/account/avatar/00/12/da/ec/779c1a78.jpg","comment_is_top":false,"comment_ctime":1541803627,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10131738219","product_id":100020201,"comment_content":"可以先通过定位寻找离自己近的人的手机存储容量，如果不够就扩大搜索范围直到可以满足自己需求，然后给对应这些设备设置一个哈稀函数，怎么来存储对应分片数据，根据不同分钱到的对应设备上付钱，并且设置一个校验的设备，定时的去检测设备，哪些可用，哪些不可用，然后进行数据转移备份","like_count":2},{"had_liked":false,"id":324835,"user_name":"黄谦敏","can_delete":false,"product_type":"c1","uid":2836611,"ip_address":"","ucode":"057CB1810E2366","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/WN351R6WwfnlILLdnH4xsUTJCG2mYFRuibdNHBJFicTHXGiaR3lxBYGmagJhicibRWFPB7fGYnDrtV9GFQtwDo1d73A/132","comment_is_top":false,"comment_ctime":1638675781,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5933643077","product_id":100020201,"comment_content":"主要解决问题<br><br>  1如何管理这样一个超大规模的分布式文件系统？<br><br>    1.1DataNode的大小不一、性能不一、网络状况不一。<br><br>    1.2DataNode注销频繁<br><br>    1.3DataNode上可能出现的影响可用性的问题<br><br>      1.3.1文件被修改（人为删除，恶意修改）<br><br>      1.3.2 DataNode完全不可用（网络问题、用户直接卸载、刷机）<br><br>      1.3.3 占用设备过多存储空间，影响设备正常使用（定位是利用闲置空间，不能影响其他功能）<br><br>      1.3.4 占用设备过多网络资源，影响设备正常使用。<br><br>    1.4对NameNode的处理能力要求超高<br><br>    1.5网络交换问题<br><br>    1.6数据安全问题<br><br>    1.7 进行高效的读写<br><br>  2如何向使用方收取费用<br><br>  3如何向服务方支付费用<br><br>解决方案<br><br>  从基础的HDFS架构出发<br><br>  1.1客户端注册为集群DataNode时，需要向NameNode提交可提供的存储大小。集群在收到注册请求后，向客户端发送一些测试数据，以检测DataNode的处理能力，并对处理能力进行评级。并向DataNode返回结果——注册成功或不成功。<br><br>  1.2对于正常注销，NameNode收到注销请求后，查找该DataNode有哪些数据块，分配任务给具有相同数据块的DataNode，并让其再备份一份数据到其他DataNode。<br><br>  1.3.1对于存储在 DataNode 上的数据块，计算并存储校验和（CheckSum）。在读取数据的时候，重新计算读取出来的数据的校验和，如果校验不正确就抛出异常，应用程序捕获异常后就到其他 DataNode 上读取备份数据。——抄的。<br><br>  每次DataNode的异常都把情况记录在DataNode。对于频繁出现异常的DataNode，通过客户端向对其使用者进行提醒并指导处理方法，并提示可能被取消资格的风险。对于指导后可用性依然很差的DataNode，注销其资格，转移备份并结算费用。<br><br>  1.3.2心跳通信，如果超时为发送，以宕机处理，频繁宕机的设备需要降级处理。<br><br>  1.3.3DataNode提供修改闲置空间的功能，如果需要减少闲置空间，分析新闲置空间下，需要删除数据块，并告知NameNode，NameNode进行记录，并返回新DataNode地址，旧DataNode把数据块发向新DataNode。完成后删除旧DataNode中的传输出去的数据块。<br><br>  1.3.4DataNode在客户端设置闲置带宽，并告知NameNode，NameNode对DataNode进行降级。如果实在不能再降，则劝退DataNode。<br><br>  1.4把NameNode从服务器上升为集群，即有两个NameNode集群，通过ZooKeeper选举主NameNode集群。全球的DataNode的元数据信息分布式地存储在NameNode的集群当中。（自认为这点还是有点创新，也有点套娃。）<br><br>  1.5依旧是对DataNode进行评级<br><br>  1.6依旧是对DataNode进行评级，传输的文件进行加密处理（本人加密门外汉）<br><br>  1.7 通过DataNode评级。在高等级DataNode中存储高访问频率数据，高等级用户的数据。评级低的DataNode存储不常访问的数据、或注销资格。<br><br>  2.根据需要的网络传输级别、实际使用的空间大小、实际使用的时长，支付费用。<br><br>  3.根据服务能力评级、实际支出空间大小、实际使用时长，收取费用。<br><br>写的有点多。","like_count":1},{"had_liked":false,"id":235105,"user_name":"常振华","can_delete":false,"product_type":"c1","uid":2062252,"ip_address":"","ucode":"D61B40E1CCEFD5","user_header":"","comment_is_top":false,"comment_ctime":1594893035,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5889860331","product_id":100020201,"comment_content":"区块链火的时候不是有这种系统出现吗？出租自己的硬盘空间，可以获取某种数字货币。需要考虑的主要私人电脑的系统状态是否可用的问题，另外不同的存储节点的网络状态千差万别。","like_count":1},{"had_liked":false,"id":176958,"user_name":"Citizen Z","can_delete":false,"product_type":"c1","uid":1125104,"ip_address":"","ucode":"9CA547640A8629","user_header":"https://static001.geekbang.org/account/avatar/00/11/2a/f0/41590e10.jpg","comment_is_top":false,"comment_ctime":1581236490,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5876203786","product_id":100020201,"comment_content":"这个产品复刻 HDFS 原理是可以的。<br>NameNode 必须由运营者管理，解决了目录控制权就解决了绝大部分问题。<br>用户终端全是 DataNode，架构模型上没问题，但细节问题很多。<br>一类客观问题：网络环境、容量、读写速度这种，可以通过市场手段调节分配，比如在分享时可以设置该文件需要分几片、分多少节点、在哪些地域分散、最多存多久，付费者甚至可设置奖金激励存储者提供服务。当然最好的做法的是把这些规则打包成一个花“多少钱享受多少 SLA”的大众可理解的服务套餐，把存储节点的分布规则设成基于大数据统计预测后动态匹配的，淘汰表现不佳的存储节点，促使贡献者买“矿机”哈哈。<br>二类安全问题：如何防止存储者作恶，数据加密、校验是基本的安全设计也不难解决，最要命的是如何审计数据，识别用户谎报的信息，这个场景就像网络游戏外挂攻防一样，要做好全方位的通信安全，防止分享者花小钱存大文件，防止存储者用小流量赚大佣金，APP 也不能被破解，否则通信的来源也是不可信的，很容易造成恶意节点发送错误数据。<br><br>这东西要做肯定要费老功夫，如果研发难度太高，还是选择租机房开展云存储服务或卖终端级 CDN 设备（优酷路由宝、迅雷赚钱宝这种），这个容易些，商业逻辑也成立。","like_count":1},{"had_liked":false,"id":155202,"user_name":"Coding小先","can_delete":false,"product_type":"c1","uid":1051563,"ip_address":"","ucode":"965B1CC757E026","user_header":"https://static001.geekbang.org/account/avatar/00/10/0b/ab/0e2857e5.jpg","comment_is_top":false,"comment_ctime":1574662195,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5869629491","product_id":100020201,"comment_content":"我直接放弃，不设计。因为可用性无法得到保证。我记得有个贡献CPU时间参与科学计算的，这种特点是要移动数据量小，计算时间长，收到结果后起码要有两份结果一致才会认为可信的。<br><br>这两种共同特点是用户可以随时退出，但用于科学计算的话，大不了下次再找个计算机发个他重新计算，用户退出了就可以不理他；但用来分布式存储数据的话，GG了，你得实时关注用户有没有退出，退出后的用户那部分数据要不要重新弄个备份，要读取数据时候需要同时读取和验证多少份数据才会认为是可信的，如何抵御被攻击等等，太难了，考虑不过来","like_count":1},{"had_liked":false,"id":67701,"user_name":"BW-Panda","can_delete":false,"product_type":"c1","uid":1073461,"ip_address":"","ucode":"227409E313C47B","user_header":"https://static001.geekbang.org/account/avatar/00/10/61/35/114c045d.jpg","comment_is_top":false,"comment_ctime":1550225322,"is_pvip":false,"replies":[{"id":"24135","content":"✅IPFS是其中一种实现。","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1550454082,"ip_address":"","comment_id":67701,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5845192618","product_id":100020201,"comment_content":"思考题答案就是现在IPFS的实现吧","like_count":1,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":439335,"discussion_content":"✅IPFS是其中一种实现。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1550454082,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":50758,"user_name":"Sam.张朝","can_delete":false,"product_type":"c1","uid":1132448,"ip_address":"","ucode":"FB20554D94B250","user_header":"https://static001.geekbang.org/account/avatar/00/11/47/a0/f12115b7.jpg","comment_is_top":false,"comment_ctime":1545040220,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"5840007516","product_id":100020201,"comment_content":"从第一篇看到第六篇，感觉脑袋有点装不下了。","like_count":1},{"had_liked":false,"id":355968,"user_name":"Sudouble","can_delete":false,"product_type":"c1","uid":1365574,"ip_address":"北京","ucode":"B369B09DAF8D20","user_header":"https://static001.geekbang.org/account/avatar/00/14/d6/46/5eb5261b.jpg","comment_is_top":false,"comment_ctime":1661875443,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1661875443","product_id":100020201,"comment_content":"美剧《硅谷》里的Pied Piper，非常像是同一个理念？！<br>主要需要解决网络接入、数据可用性、付费模式的问题。<br>1. 对于网络接入，不是所有用户在所有时间的网络都是高速可靠的，有时的网络状况确实糟糕。<br>2. 数据可用性，用户设备也存在没电、故障、存储空间不足的问题<br>3. 得出一个合理可行的数据付费模式，在既能提供服务的同时，也有能保证对用户提供的服务。","like_count":0},{"had_liked":false,"id":328263,"user_name":"易飞","can_delete":false,"product_type":"c1","uid":2630424,"ip_address":"","ucode":"32AC28754237F7","user_header":"https://static001.geekbang.org/account/avatar/00/28/23/18/4284361f.jpg","comment_is_top":false,"comment_ctime":1640648624,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1640648624","product_id":100020201,"comment_content":"最主要的还是高可用不能保证","like_count":0},{"had_liked":false,"id":321510,"user_name":"oxygen_酱","can_delete":false,"product_type":"c1","uid":2734372,"ip_address":"","ucode":"F042A44E05051D","user_header":"https://static001.geekbang.org/account/avatar/00/29/b9/24/0351fe33.jpg","comment_is_top":false,"comment_ctime":1636911224,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1636911224","product_id":100020201,"comment_content":"最后的问题很像ipfs","like_count":0},{"had_liked":false,"id":292255,"user_name":"Sawyer","can_delete":false,"product_type":"c1","uid":1011280,"ip_address":"","ucode":"34DC7FBB01FE6E","user_header":"https://static001.geekbang.org/account/avatar/00/0f/6e/50/c85284da.jpg","comment_is_top":false,"comment_ctime":1620742284,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1620742284","product_id":100020201,"comment_content":"思考题：如果想使用个人pc作为分布式文件系统的DataNode需要考虑到的不确定性因素会更多。比如设备离线，设备可用存储容量，设备中数据丢失及篡改的问题。每次进行读操作时，客户端需要先获取数据存储块的列表，判断设备是否在线，然后还要各个设备当前的网络通信情况，并且判断数据是否存在以及检验数据的checksum是否正确。在写操作时，还要判断设备可用存储容量。最重要的问题是设备的离线以及设备的网络通信情况的复杂性。","like_count":0},{"had_liked":false,"id":289537,"user_name":"levi","can_delete":false,"product_type":"c1","uid":1501281,"ip_address":"","ucode":"41AFA57F56C15E","user_header":"https://static001.geekbang.org/account/avatar/00/16/e8/61/47293afd.jpg","comment_is_top":false,"comment_ctime":1619068518,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1619068518","product_id":100020201,"comment_content":"这个问题实际上会比较复杂。不能简单的套用HDFS的设计思路就能解决，但是一些设计经验可以借鉴。<br>1. 首先要考虑的是移动设备的空间较小，且并不规则。因此block也需要相应的减小，block减小带来的就是文件数目增大，meta增大。因此，第一个难题就是如何应对小文件和大meta问题。<br>2. 其次要考虑的就是移动设备的不稳定性。这个不稳定性包括了很多方面，比如cpu不强劲，内存不够大，存储有限，网络时断时续。这个不稳定性会衍生出来很多问题需要解决，比如系统的容错性，性能，如何冗余备份等。<br>3. 再次还要考虑用户的自主权限较高。由于用户自主权限较高，他可以合法的增删查改一些文件，破坏文件的完整性等等，如果容错也带来了更高的要求。<br>4. 最后还要考虑这套方式并不是像HDFS那样统一维护在某个企业内部，其安全性较高，而这套方式分散在全球各地各个移动设备上面，任何一个移动设备被入侵都可能导致这些文件被滥用，或者说这个文件系统的漏洞也有可能导致系统漏洞。","like_count":0},{"had_liked":false,"id":286449,"user_name":"简单","can_delete":false,"product_type":"c1","uid":2546519,"ip_address":"","ucode":"640B84253343AB","user_header":"https://static001.geekbang.org/account/avatar/00/26/db/57/67084c71.jpg","comment_is_top":false,"comment_ctime":1617324676,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1617324676","product_id":100020201,"comment_content":"很多同学提到宿主设备的性能、网络等因素会影响数据的可用性，我觉得在大数据时代可以对数据分布存储做到更灵活、更可靠，而不是简单平均式将数据存储在N个设备。我们可以使用程序分析宿主设备的性能、使用习惯、网络环境等因素，甚至预测宿主主人未来即将报废设备等行为，将数据有倾向性的放在某些设备，提高数据的使用效率、可靠性。","like_count":0},{"had_liked":false,"id":283086,"user_name":"李郝","can_delete":false,"product_type":"c1","uid":1590465,"ip_address":"","ucode":"4818313D933CE6","user_header":"https://static001.geekbang.org/account/avatar/00/18/44/c1/ebe870bb.jpg","comment_is_top":false,"comment_ctime":1615542232,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1615542232","product_id":100020201,"comment_content":"请教老师几个问题：<br>1、从NameNode如果也挂掉，是不是整个集群就挂掉了？如果是这样的话Hadoop还算是高可用吗？<br>2、Shared Edits这个共享存储是如何保证“数据存储磁盘容错”的呢？","like_count":0},{"had_liked":false,"id":268207,"user_name":"小阳、style","can_delete":false,"product_type":"c1","uid":1422651,"ip_address":"","ucode":"33C212CD7592A8","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eqOtlleRvQ1BiaicabUUmUQVSMr3fnPVmCS0RQrkSWYu5rGLdyyJWKE3cdkT8Libe1R9wKFEL5LYO0PA/132","comment_is_top":false,"comment_ctime":1608101108,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1608101108","product_id":100020201,"comment_content":"打卡，讲的很清晰","like_count":0},{"had_liked":false,"id":257654,"user_name":"MOIC💅","can_delete":false,"product_type":"c1","uid":1821592,"ip_address":"","ucode":"B307B4C7984F35","user_header":"https://static001.geekbang.org/account/avatar/00/1b/cb/98/be4b2e33.jpg","comment_is_top":false,"comment_ctime":1604049881,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1604049881","product_id":100020201,"comment_content":"用户移动设备，私有设备可控性查，外界因素太多，运营商，出厂商，用户个人因素，都是不可控的，但是如果是云端share，应该是ok的。类似于百度云，用户share一部分空间，这部分的运维还是掌控在百度云，所以外界因素的少了很多。","like_count":0},{"had_liked":false,"id":255221,"user_name":"李郝","can_delete":false,"product_type":"c1","uid":1590465,"ip_address":"","ucode":"4818313D933CE6","user_header":"https://static001.geekbang.org/account/avatar/00/18/44/c1/ebe870bb.jpg","comment_is_top":false,"comment_ctime":1603284681,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1603284681","product_id":100020201,"comment_content":"用户的手机几乎是5个9的状态，适合做个人的NameNode，而且手机端的App网络传输的数据大是有很大影响和风险的，不适合做频繁的数据传输，而且手机上的数据大多数是被备份的需要。用户的平板几乎是看电视的工具，适合DataNode，同时可以使用蓝牙备份用户个人数据。个人PC大多办公游戏，家里wifi大量时间空闲，如果多个家里的PC的话更适合共享的DataNode以及个人的Secondary NameNode，感觉这样客户更愿意接受，否则出于安全角度考虑很少有人愿意将自己经常使用的手机做为他人的存储介质","like_count":0},{"had_liked":false,"id":226341,"user_name":"iWill","can_delete":false,"product_type":"c1","uid":1110120,"ip_address":"","ucode":"5F29DAF5472E17","user_header":"https://static001.geekbang.org/account/avatar/00/10/f0/68/afb36ef6.jpg","comment_is_top":false,"comment_ctime":1592041593,"is_pvip":false,"replies":[{"id":"84437","content":"不会","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1592878790,"ip_address":"","comment_id":226341,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1592041593","product_id":100020201,"comment_content":"如果有多个从NameNode， DataNode 也会向所有的从NameNode上报数据吗？","like_count":0,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":498203,"discussion_content":"不会","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1592878790,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":222580,"user_name":"漩涡鸣人","can_delete":false,"product_type":"c1","uid":1503139,"ip_address":"","ucode":"0C02F07B2ABD5C","user_header":"https://wx.qlogo.cn/mmopen/vi_32/mvxl1xzYcAfJERgGHBCswnbeibZJmS1IlP1z9P7KsSh2EPuM78DqPKPicAmHXPYUib6RPcjGcf5vrXkQXAiaLorB2w/132","comment_is_top":false,"comment_ctime":1590841652,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1590841652","product_id":100020201,"comment_content":"😂这个分布式文件系统 有点区块链技术的感觉 ","like_count":0},{"had_liked":false,"id":187992,"user_name":"undefined","can_delete":false,"product_type":"c1","uid":1587803,"ip_address":"","ucode":"867405CA5A9FB7","user_header":"https://static001.geekbang.org/account/avatar/00/18/3a/5b/ce1724ca.jpg","comment_is_top":false,"comment_ctime":1584289512,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1584289512","product_id":100020201,"comment_content":"思考题听着和 P2P 下载很像，改成付费版了。","like_count":0},{"had_liked":false,"id":182824,"user_name":"鹏","can_delete":false,"product_type":"c1","uid":1009228,"ip_address":"","ucode":"243E408E2094E1","user_header":"https://static001.geekbang.org/account/avatar/00/0f/66/4c/39a6829c.jpg","comment_is_top":false,"comment_ctime":1582871301,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1582871301","product_id":100020201,"comment_content":"你的这个思考题，就是现在的“玩客云”的模式","like_count":0},{"had_liked":false,"id":136479,"user_name":"钱","can_delete":false,"product_type":"c1","uid":1009652,"ip_address":"","ucode":"2C92A243A463D4","user_header":"https://static001.geekbang.org/account/avatar/00/0f/67/f4/9a1feb59.jpg","comment_is_top":false,"comment_ctime":1569458054,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1569458054","product_id":100020201,"comment_content":"1、本文核心观点：<br>1-1：RAID 磁盘阵列存储——RAID 将数据分片后在多块磁盘上并发进行读写访问，从而提高了存储容量、加快了访问速度，并通过数据的冗余校验提高了数据的可靠性，即使某块磁盘损坏也不会丢失数据。<br>和 RAID 在多个磁盘上进行文件存储及并行读写的思路一样，HDFS 是在一个大规模分布式服务器集群上，对数据分片后进行并行读写及冗余存储。<br>1-2：DataNode 负责文件数据的存储和读写操作，HDFS 将文件数据分割成若干数据块（Block），每个 DataNode 存储一部分数据块，这样文件就分布存储在整个 HDFS 服务器集群中<br>1-3：NameNode 负责整个分布式文件系统的元数据（MetaData）管理，也就是文件路径名、数据块的 ID 以及存储位置等信息，相当于操作系统中文件分配表（FAT）的角色。<br>1-4：老师认为集群的高可用性是最难实现的，因为变量太多，根据CAP定律，当发生P时，也只能在CA上二选一，而大部分场景会选A。实现高可用的思路有三个冗余备份、失效转移、限流降级。<br>这些我觉得好理解，大家也都这么玩，不过怎么分片？怎么存储数据？怎么存取数据？怎么聚合数据？各家却各不相同，这些差异性，我觉得是一个学习的痛点。<br>2：课后思考及问题<br>课后的思考题很有意思，如果所有的电脑都属于一个人，只是借给全世界的人使用就好控制啦！给他们限定权限，一不能关机不能断网，二只能使用部分存储空间，剩下的事情其实就是hdfs的事情了。<br>对于上面两个问题，直接实现是不可能的，那只能曲线救国，使用更多的分布式副本，至少在某一时刻总有人在线，第二个那就需要加密处理，但也不能保证她不删除数据，现在能想到的技术方案还是分布式副本，只要程序不删再把数据复制一份过去，另外，就是非技术的约束了，给用户分级既然签约有收益也就有惩罚，来加强用户的在线时长和数据安全性。<br>","like_count":0},{"had_liked":false,"id":125610,"user_name":"半瓶醋","can_delete":false,"product_type":"c1","uid":1282746,"ip_address":"","ucode":"8C898E244D0417","user_header":"https://static001.geekbang.org/account/avatar/00/13/92/ba/9833f06f.jpg","comment_is_top":false,"comment_ctime":1566211922,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1566211922","product_id":100020201,"comment_content":"我是小白，也说说我的想法😅<br>1.保证安全可靠性:冗余备份。<br>2.保证可用性:主从机制，监听各个节点健康状态<br>3.保证容错:故障恢复<br>4.保证并发性: 建立文件索引，查询快<br>","like_count":0},{"had_liked":false,"id":115818,"user_name":"Cutler","can_delete":false,"product_type":"c1","uid":1228136,"ip_address":"","ucode":"2EDECFE039845B","user_header":"https://static001.geekbang.org/account/avatar/00/12/bd/68/3fd6428d.jpg","comment_is_top":false,"comment_ctime":1563754741,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1563754741","product_id":100020201,"comment_content":"ipfs就是一种p2p文件分布式存储系统","like_count":0},{"had_liked":false,"id":102361,"user_name":"泽泽_2010","can_delete":false,"product_type":"c1","uid":1237883,"ip_address":"","ucode":"D6424E98BB5A18","user_header":"https://static001.geekbang.org/account/avatar/00/12/e3/7b/463312ad.jpg","comment_is_top":false,"comment_ctime":1560213086,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1560213086","product_id":100020201,"comment_content":"前三楼的都这么厉害，分析得头头是道👍","like_count":0},{"had_liked":false,"id":100165,"user_name":"水电工٩(｡•ω•｡)﻿و","can_delete":false,"product_type":"c1","uid":1348364,"ip_address":"","ucode":"C43B6B4DDA9BE7","user_header":"https://static001.geekbang.org/account/avatar/00/14/93/0c/dd383681.jpg","comment_is_top":false,"comment_ctime":1559465913,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1559465913","product_id":100020201,"comment_content":"由于在这方面几乎是个小白，各种计算机原理并不理解，所以我就只能大概说说需要考虑哪些方面。<br>一是存储资料安全性，当个人设备空闲空间分享出去后，需要保证用户在这些分享空间存储资料的安全性、私密性，即不被他人破获。<br>二是对各区域的管理，假设这是一个全球性的系统，所以所有分享的空间以及申请存储服务应该以区域为划分，那按什么规则去划分区域，是否是要跨区域备份数据，如何检查区域内磁盘、DataNode等是否正常运行。<br>三是如何处理DataNode和NameNode之间的通信。由于个人用户可能存在断网的情况，这样会阻碍到DataNode进行心跳，导致失效认证认证出错。","like_count":0},{"had_liked":false,"id":89061,"user_name":"gkb111","can_delete":false,"product_type":"c1","uid":1224217,"ip_address":"","ucode":"9B3154BCC9046B","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLLUic3XzxET3L3QXxcTbeg96GMx1HkiaiaZdudchmOmtPnuEPHK5vYEeMkvJR098XljMbXDialYib3z6w/132","comment_is_top":false,"comment_ctime":1556070549,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1556070549","product_id":100020201,"comment_content":"数据冗余存储，并计算存储校验和，不一致则访问其他存储块","like_count":0},{"had_liked":false,"id":88556,"user_name":"雪候鸟","can_delete":false,"product_type":"c1","uid":1121047,"ip_address":"","ucode":"B7A82676DFD39F","user_header":"https://static001.geekbang.org/account/avatar/00/11/1b/17/64e18a78.jpg","comment_is_top":false,"comment_ctime":1555941617,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1555941617","product_id":100020201,"comment_content":"看了您讲的这节，感觉分布式其实就是单机技术的横向扩展，现在流行的Tidb的底层的分布式存储的原理跟hdfs的底层存储方式感觉挺像，其实灵感都来源于RAID的磁盘存储原理。","like_count":0},{"had_liked":false,"id":88201,"user_name":"彬清","can_delete":false,"product_type":"c1","uid":1220372,"ip_address":"","ucode":"04620BAC60F15F","user_header":"https://static001.geekbang.org/account/avatar/00/12/9f/14/b9505789.jpg","comment_is_top":false,"comment_ctime":1555893466,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1555893466","product_id":100020201,"comment_content":"感觉kafka的存储原理就是参考hdfs的，一份数据拆成多个数据块存储在不同服务器上，每个数据库有多份拷贝。","like_count":0},{"had_liked":false,"id":84932,"user_name":"车小勺的男神","can_delete":false,"product_type":"c1","uid":1285577,"ip_address":"","ucode":"6D5C959139D40B","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJutT9JkFAcOk1JxOBdPuLgROpvcuxD9ROP9ACILAHITjcaYGNrZ5lHMZORYM6ibCuScDibYlgRvAIw/132","comment_is_top":false,"comment_ctime":1554946368,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1554946368","product_id":100020201,"comment_content":"李老师你好，请问有没有比较权威什么工具用于测试 Hadoop FileSystem 接口的兼容性呢","like_count":0},{"had_liked":false,"id":78832,"user_name":"珠闪闪","can_delete":false,"product_type":"c1","uid":1300447,"ip_address":"","ucode":"45BE0D586A3839","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eov38ZkwCyNoBdr5drgX0cp2eOGCv7ibkhUIqCvcnFk8FyUIS6K4gHXIXh0fu7TB67jaictdDlic4OwQ/132","comment_is_top":false,"comment_ctime":1553252065,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1553252065","product_id":100020201,"comment_content":"零基础看大数据，果然是看到第二遍才有感觉，赞(&#47;≧▽≦&#47;)","like_count":0},{"had_liked":false,"id":70013,"user_name":"张飞","can_delete":false,"product_type":"c1","uid":1405598,"ip_address":"","ucode":"836F612B8E9C8A","user_header":"https://static001.geekbang.org/account/avatar/00/15/72/9e/69606254.jpg","comment_is_top":false,"comment_ctime":1550936858,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1550936858","product_id":100020201,"comment_content":"老师，请问像阿里云、腾讯云这些云端本身的高可用是怎么做到的呢？ 如果一个HDFS系统的namenode的高可用仅仅依赖云平台本身（即本身只做了secondaryNamenode），这样的系统是不是很不稳定？又或者是因为云技术的高可用可以达到Namenode HA的效果呢？","like_count":0},{"had_liked":false,"id":64793,"user_name":"水迹","can_delete":false,"product_type":"c1","uid":1329148,"ip_address":"","ucode":"46E4C69DC64C1A","user_header":"https://static001.geekbang.org/account/avatar/00/14/47/fc/95ac4b1a.jpg","comment_is_top":false,"comment_ctime":1548912154,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1548912154","product_id":100020201,"comment_content":"我立刻想到了当年快播的雷达功能，哈哈，扫描到附近人的共享盘，可以获取到内容，大家共享。","like_count":0},{"had_liked":false,"id":64218,"user_name":"lics2562","can_delete":false,"product_type":"c1","uid":1391185,"ip_address":"","ucode":"715440D9598CF6","user_header":"https://static001.geekbang.org/account/avatar/00/15/3a/51/3325b616.jpg","comment_is_top":false,"comment_ctime":1548720973,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1548720973","product_id":100020201,"comment_content":"李老师，如果我们想实践一下上面的思想。数据和服务器怎么获取呢？","like_count":0},{"had_liked":false,"id":62510,"user_name":"杰之7","can_delete":false,"product_type":"c1","uid":1297232,"ip_address":"","ucode":"F7DA2E21085332","user_header":"https://static001.geekbang.org/account/avatar/00/13/cb/50/66d0bd7f.jpg","comment_is_top":false,"comment_ctime":1548077837,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1548077837","product_id":100020201,"comment_content":"通过这一节的复习，对HDFS的分布式储存和快速访问及可用性有了更好的认识。<br><br>HDFS中储存着海量的数据，所以HDFS本身的地位是不可被替代的。在HDFS中，NameDode负责对元数据的管理，DataNodes负责对数据块的管理。由于HDFS可以部署成千上万的服务器，这样保证了大容量的储存和高速访问。<br><br>对于用户来说，性能、体验差点可以接受，但是数据的可用性丢失是不可接受的。HDFS在数据的储存故障，磁盘故障，DataNode容错，NameNode容错上提供了可用保障。<br><br>对于可用性策略，老师提了三种方法，冗余备份，既程序、数据至少在另一台服务器上备份。失效转移，当数据、程序无法访问时，请求转移到备份的程序或者数据所在的服务器上。降级限流，提前设置流量的阀值和对一些功能的处理。<br><br>回到老师的问题，老师说连接全世界所有的个人电脑，手机形成分布式文件系统，用APP储存和分享。我考虑的点是用HDFS连接这些设备来管理，既然是全世界的，需要如何设置网络服务的配置。对于增加更多的电脑手机设备，HDFS的扩容性需要进一步跟上。","like_count":0},{"had_liked":false,"id":61802,"user_name":"刘胜","can_delete":false,"product_type":"c1","uid":1251625,"ip_address":"","ucode":"487374D72543E3","user_header":"https://static001.geekbang.org/account/avatar/00/13/19/29/f9490983.jpg","comment_is_top":false,"comment_ctime":1547803063,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1547803063","product_id":100020201,"comment_content":"我的设计基本思路还是hdfs这一套，但是心跳机制不太好实现，这会导致有的硬盘的可使用状态变得无法琢磨。","like_count":0},{"had_liked":false,"id":57171,"user_name":"钟悠","can_delete":false,"product_type":"c1","uid":1114612,"ip_address":"","ucode":"5AF2CAE1737927","user_header":"https://static001.geekbang.org/account/avatar/00/11/01/f4/3dc9bcce.jpg","comment_is_top":false,"comment_ctime":1546671441,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1546671441","product_id":100020201,"comment_content":"网络情况过于复杂，而且存储设备处于持续移动🀄️，开机和关机操作也过于频繁，不够稳定","like_count":0},{"had_liked":false,"id":56707,"user_name":"YOLO","can_delete":false,"product_type":"c1","uid":1195160,"ip_address":"","ucode":"C2A1BA3DA68C68","user_header":"https://static001.geekbang.org/account/avatar/00/12/3c/98/dbfd02b7.jpg","comment_is_top":false,"comment_ctime":1546525582,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1546525582","product_id":100020201,"comment_content":"1: 如果可以的话，想个办法统计各个DataNode的可靠性，比如掉线时常、掉线频率、掉线后恢复速率、数据备份&#47;读取速率，对节点做评估，优质节点提供高一点儿的用户补偿（资金、资源），对低级资源甚至于垃圾资源建立黑名单或冷却复活制度，降低垃圾资源占用带宽和捣乱节点的出现；（似乎这里要占用不少资源，不论是计算还是存储，可以调整一下统计频率减少消耗）<br>2: 对于数据请求和访问分区域，最近节点形成群组概念，优化资源互拷速度；<br>3: 针对数据区分冷热，热数据更多利用缓存，冷数据更多利用硬盘；<br>4: 避免区域性灾难，按地域做互拷备份；<br>5: 极冷数据可以使用压缩技术备份；<br>6: 呃……话说突然想到了，这么多节点，锁岂不是很耽误速度？能否对数据进行分类，对不会产生冲突的数据就不加锁了，只有会冲突的字段加锁……呃……分类锁？字段锁？<br>","like_count":0},{"had_liked":false,"id":55268,"user_name":"安静","can_delete":false,"product_type":"c1","uid":1212634,"ip_address":"","ucode":"7C4DB6D81A48EB","user_header":"https://static001.geekbang.org/account/avatar/00/12/80/da/9c0c458c.jpg","comment_is_top":false,"comment_ctime":1546084026,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1546084026","product_id":100020201,"comment_content":"干货足，分布式架构组件设计原理都类似，namenode这种架构属于集中式管理集群状态信息，使用zk实现namenode主从切换，namenode保证datanode的高可用。高可用的一般做法，冗余设计，失效转移，降级限流。","like_count":0},{"had_liked":false,"id":54081,"user_name":"随时都有好心情","can_delete":false,"product_type":"c1","uid":1168769,"ip_address":"","ucode":"85F8E3DE9CFDDC","user_header":"https://static001.geekbang.org/account/avatar/00/11/d5/81/708301e1.jpg","comment_is_top":false,"comment_ctime":1545792258,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1545792258","product_id":100020201,"comment_content":"希望老师能解释一些比较基础的概念，比如，什么是心跳？","like_count":0},{"had_liked":false,"id":52574,"user_name":"DayDayUp","can_delete":false,"product_type":"c1","uid":1340195,"ip_address":"","ucode":"DD78C53719B773","user_header":"https://static001.geekbang.org/account/avatar/00/14/73/23/df27697d.jpg","comment_is_top":false,"comment_ctime":1545442746,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1545442746","product_id":100020201,"comment_content":"用喷泉码+bt协议","like_count":0},{"had_liked":false,"id":52295,"user_name":"aof","can_delete":false,"product_type":"c1","uid":1062864,"ip_address":"","ucode":"5815D63C4926BC","user_header":"https://static001.geekbang.org/account/avatar/00/10/37/d0/26975fba.jpg","comment_is_top":false,"comment_ctime":1545359739,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1545359739","product_id":100020201,"comment_content":"1、DataNode节点会非常多，可能不是几千几万台了，过多的数据节点会产生过多的元数据，对于NameNode会造成很大的压力，最后会导致访问的速度比较慢吧<br>2、如果是手机作为DataNode的话，其实比服务器的故障率要高很多，这样对于副本数也会有比较高的要求，副本数一旦比较多的话，写数据的性能也会随之下降<br>3、集群网络的性能和稳定性方面也无法得到保证<br>4、手机作为数据节点，因为用户也一直在使用手机存储空间，当超过已剩空间，要使用分配出去的那一部分空间的时候，该怎么处理<br>......<br>总之，这个想法挺新颖，但实现的可能性很小","like_count":0},{"had_liked":false,"id":52097,"user_name":"karas","can_delete":false,"product_type":"c1","uid":1349594,"ip_address":"","ucode":"836873D0D9973B","user_header":"https://static001.geekbang.org/account/avatar/00/14/97/da/ae765e15.jpg","comment_is_top":false,"comment_ctime":1545309850,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1545309850","product_id":100020201,"comment_content":"话说把自己的资料放到某个莫名其妙的私人电脑里会不会不安全啥的。而且你自家搭建的文件系统基本可控的，坏掉也是遵循概率的。换成共享的，人家大半夜的都睡觉了，关电脑，那岂不是相当于几十万台机器同时宕机，某些信息的全部备份当场去世😂总之环境太不可控了8","like_count":0},{"had_liked":false,"id":51958,"user_name":"弦亚","can_delete":false,"product_type":"c1","uid":1306192,"ip_address":"","ucode":"64536E913AE6AE","user_header":"https://static001.geekbang.org/account/avatar/00/13/ee/50/ed7b9e19.jpg","comment_is_top":false,"comment_ctime":1545281946,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1545281946","product_id":100020201,"comment_content":"这个问题挺有意思的，我立即想到的是本地分享软件μtorrent的运行原理，咱们可以结合HDFS的存储与管理的架构，通过类似BT本地传输的模式将剩余算力统筹规划起来","like_count":0},{"had_liked":false,"id":51466,"user_name":"swift","can_delete":false,"product_type":"c1","uid":1156148,"ip_address":"","ucode":"B243DCD10B04F0","user_header":"https://static001.geekbang.org/account/avatar/00/11/a4/34/0ab08db6.jpg","comment_is_top":false,"comment_ctime":1545186345,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1545186345","product_id":100020201,"comment_content":"1、应该有个服务存放用户的逻辑文件结构，如文件夹、文件名等，并为每个文件分配一个唯一的URI。<br>2、根据负载需要，建立多个DFS分区，可以部署到不同地理位置，每个用户（或文件URI）只对应一个分区。<br>3、分区里的建设类似于HDFS，服务器作为NAMENODE，用户设备作为DATANODE，文件URI就是文件路径。<br>4、因为个人设备通常在网关内，客户端访问DATANODE的方式需要用类似于迅雷、BITTORRENT的技术。<br>5、数据的每个块都要加密，密钥与数据所有者用户绑定。<br>6、为防止持有某数据块的所有用户设备都离线，需要有服务器端的DATANODE来做最后的备份。<br>7、因为用户设备会频繁上线、离线，只有在发现设备上数据块丢失或设备离线超时的时候才在其他用户设备上创建新的备份。<br>8、对于大文件才使用设备端DATANODE，小文件直接映射到一个网盘服务代替……","like_count":0},{"had_liked":false,"id":45503,"user_name":"小老鼠","can_delete":false,"product_type":"c1","uid":1257460,"ip_address":"","ucode":"C663A0C863A515","user_header":"https://static001.geekbang.org/account/avatar/00/13/2f/f4/2dede51a.jpg","comment_is_top":false,"comment_ctime":1543656407,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1543656407","product_id":100020201,"comment_content":"分布式架构硬件拓扑结构图可否介绍下。叧外如何把写的mapreduce方法在分布式中运行？","like_count":0},{"had_liked":false,"id":43937,"user_name":"杰之7","can_delete":false,"product_type":"c1","uid":1297232,"ip_address":"","ucode":"F7DA2E21085332","user_header":"https://static001.geekbang.org/account/avatar/00/13/cb/50/66d0bd7f.jpg","comment_is_top":false,"comment_ctime":1543330040,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1543330040","product_id":100020201,"comment_content":"新计算框架，算法层出不穷，但HDFS依然是最主要的分布式文件系统，因为框架、算法可以变，但最重要的资源数据依然是大数据技术的基础，即而HDFS就成了选择的标准。在HDFS的结构，主要有NameNode和DataNode两部分，NameNode负责元数据的储存，相当于操作系统的FAT,DataNode存储文件里的数据。在海量数据如此重要的情况下，对于HDFS的性能就非常重要，数据存储故障，磁盘故障，DataNode和NameNode故障，每一个都需要有相对于的措施防护。","like_count":0},{"had_liked":false,"id":42073,"user_name":"蔓蔓玖零","can_delete":false,"product_type":"c1","uid":1282902,"ip_address":"","ucode":"0CC5C9663B4918","user_header":"","comment_is_top":false,"comment_ctime":1542902847,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1542902847","product_id":100020201,"comment_content":"分布式计算方法的核心是去中心化。但是namenode 相当于一个反馈信息的核心，所以如果运用到个人闲置存储空间，哪一个用作namenode呢？如何保证namenode 的信息加密不泄漏给出租者，以及出租者不会篡改信息。仍然不能像区块链技术一样完全去中心化。并且怎么保证随着修改的内容增多，需要的内存增多，那么此时在一台手机上的存储空间必须随时调整。如何灵活满足变化呢？","like_count":0},{"had_liked":false,"id":40944,"user_name":"zjhiphop","can_delete":false,"product_type":"c1","uid":1007091,"ip_address":"","ucode":"F4B8FF50364214","user_header":"https://static001.geekbang.org/account/avatar/00/0f/5d/f3/e12aee93.jpg","comment_is_top":false,"comment_ctime":1542700250,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1542700250","product_id":100020201,"comment_content":"基于用户手机的分布式文件服务实现轻量级的数据通信， 通过区块链和DAG来实现可用性和节点造假问题， 但是要实现大文件的存储，不太可行，可用性无法保证， 对终端的配置， 网络环境要求比较高","like_count":0},{"had_liked":false,"id":40127,"user_name":"胖子贝贝要喝水","can_delete":false,"product_type":"c1","uid":1261565,"ip_address":"","ucode":"F9CEA06BBC4248","user_header":"https://static001.geekbang.org/account/avatar/00/13/3f/fd/b2c260e7.jpg","comment_is_top":false,"comment_ctime":1542512327,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1542512327","product_id":100020201,"comment_content":"我觉得有两种思路:元数据存在云端，元数据下沉到用户端，前者效率会更高(例如storej)，后者就是区块链的技术了。个人觉得对于企业来说，结合边缘计算，是可以考虑类似的存储方案的。","like_count":0},{"had_liked":false,"id":39843,"user_name":"小高","can_delete":false,"product_type":"c1","uid":1283052,"ip_address":"","ucode":"FCD422249F7355","user_header":"https://static001.geekbang.org/account/avatar/00/13/93/ec/985675c8.jpg","comment_is_top":false,"comment_ctime":1542365414,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1542365414","product_id":100020201,"comment_content":"对思考题：谁来做Namenode最合适？按照思考题的要求、感觉Namenode需要部署很多个、而且要每个Namenode都要保持通信、还有就是Datanode在线问题、我也觉得可以采用付费方式鼓励用户持续在线。","like_count":0},{"had_liked":false,"id":39142,"user_name":"Rock.Luo","can_delete":false,"product_type":"c1","uid":1283237,"ip_address":"","ucode":"700654B68AF1DF","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/bX0Axom5S7Kxyvvtv2eibS4vWIzZWPOHQSGD2rOxyDx7NPOA1BGWx9hXq6ricq4mwcNHd6PMmHyKZoKgH4vK6tdQ/132","comment_is_top":false,"comment_ctime":1542197631,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1542197631","product_id":100020201,"comment_content":"实现这个构想，采用无中心的架构比较容易实现，C2C的方式，用户自由交易，多副本保证可用性，服务承诺等等","like_count":0},{"had_liked":false,"id":38667,"user_name":"scorpiozj","can_delete":false,"product_type":"c1","uid":1031677,"ip_address":"","ucode":"C66EA76809F9BF","user_header":"https://static001.geekbang.org/account/avatar/00/0f/bd/fd/3f5d5db5.jpg","comment_is_top":false,"comment_ctime":1542101254,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1542101254","product_id":100020201,"comment_content":"个人存储设备作为data node<br>根据地理位置设置若干name node，name node需要管理文件存储&#47;备份策略（如根据位置网速等决定data node等等）；费用管理","like_count":0},{"had_liked":false,"id":38580,"user_name":"老男孩","can_delete":false,"product_type":"c1","uid":1134514,"ip_address":"","ucode":"CEC6D47412F620","user_header":"https://static001.geekbang.org/account/avatar/00/11/4f/b2/1e8b5616.jpg","comment_is_top":false,"comment_ctime":1542076576,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1542076576","product_id":100020201,"comment_content":"1.首先要有一个用户中心（类似nameNode）。它负责记录用户上传的数据分成了多少块，备份了多少份，保存那些个人设备上了等信息。<br>2.一个统一透明的读写接口，用户只知道我要写数据读数据，不关心写到哪里，从哪里读出来。而且要保证数据安全性，不能被某个终端把信息破解了，造成用户个人信息泄露。<br>3.对于大数据计算分析，服务端把数据分成很多块很多份，分发给个人终端设备进行计算，就算有的终端设备由于网络原因或者其他原因不能将计算结果上报到服务端也没关系，因为其他的设备会上报计算结果。服务端再对这些计算结果进行提取计算。<br><br>由于分配给个人终端的计算量不大，用户基本上不会有什么感知，但数以亿计的用户用自己的终端设备进行这种计算，那么效率就是惊人的。如果全中国每个人给你一毛钱，那么你瞬间就身价过亿了。","like_count":0},{"had_liked":false,"id":38537,"user_name":"hua168","can_delete":false,"product_type":"c1","uid":1065255,"ip_address":"","ucode":"CFF9A7E86EBA48","user_header":"https://static001.geekbang.org/account/avatar/00/10/41/27/3ff1a1d6.jpg","comment_is_top":false,"comment_ctime":1542072505,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1542072505","product_id":100020201,"comment_content":"Hadoop的框架最核心的设计就是：HDFS和MapReduce。HDFS为海量的数据提供了存储，而MapReduce则为海量的数据提供了计算。<br><br>HDFS 并不是一个万能的文件系统。它的主要目的是支持以流的形式访问写入的大型文件。<br><br>从上面理解是不是大于块(64M)的海量文件可以考虑用HDFS存储，支持流形式的文件最适合，对吧？","like_count":0},{"had_liked":false,"id":38474,"user_name":"足迹","can_delete":false,"product_type":"c1","uid":1105779,"ip_address":"","ucode":"38134D1A6B8DC2","user_header":"https://static001.geekbang.org/account/avatar/00/10/df/73/4a4ce2b5.jpg","comment_is_top":false,"comment_ctime":1542060519,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1542060519","product_id":100020201,"comment_content":"看到题目，马上想到是区块链技术，区块链不就是很多矿工结点自己接进来挖矿吗？只不过目前的矿机是专业的机器，随着技术的不断发展，个人设备作为存储也不是不可能，就如bt下载就是用到了这技术。","like_count":0},{"had_liked":false,"id":38445,"user_name":"暴风雪","can_delete":false,"product_type":"c1","uid":1283139,"ip_address":"","ucode":"BF1523D69866FF","user_header":"https://static001.geekbang.org/account/avatar/00/13/94/43/46a7d0a8.jpg","comment_is_top":false,"comment_ctime":1542036230,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1542036230","product_id":100020201,"comment_content":"通过对NameNode的故障容错处理，我终于明白了Zookeeper的原理，也明白了曾经看过的Zookeeper+kafka集群原理","like_count":0},{"had_liked":false,"id":38358,"user_name":"好好学习","can_delete":false,"product_type":"c1","uid":1258789,"ip_address":"","ucode":"63A002997462E3","user_header":"https://static001.geekbang.org/account/avatar/00/13/35/25/bab760a1.jpg","comment_is_top":false,"comment_ctime":1542026300,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1542026300","product_id":100020201,"comment_content":"网格计算里的存储，这个模型和k8s很像，人人接入集群中心，每个人的设备就是一个node，灵活调配，真正地实现人人为我，我为人人了。","like_count":0},{"had_liked":false,"id":38324,"user_name":"frankie","can_delete":false,"product_type":"c1","uid":1021805,"ip_address":"","ucode":"162F203BE0CC6D","user_header":"https://static001.geekbang.org/account/avatar/00/0f/97/6d/abb7bfe3.jpg","comment_is_top":false,"comment_ctime":1542021571,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1542021571","product_id":100020201,"comment_content":"这个分布式分件系统感觉比特币已经实现了。<br>除了HDFS要考虑的因素，应该还要重点考虑压缩存储，压缩传输，数据加解密。namenode应该要放服务器上了。","like_count":0},{"had_liked":false,"id":38257,"user_name":"Reiser","can_delete":false,"product_type":"c1","uid":1078669,"ip_address":"","ucode":"E5DBBBA2F86FCE","user_header":"https://static001.geekbang.org/account/avatar/00/10/75/8d/c6a2a048.jpg","comment_is_top":false,"comment_ctime":1542004220,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1542004220","product_id":100020201,"comment_content":"将每台设备作为 DataNode，服务器作为 NameNode。数据备份我觉得应该至少备份到两个 DataNode，因为有可能备份时某台 DataNode 没有开机或者断网了。","like_count":0},{"had_liked":false,"id":38254,"user_name":"猫头鹰爱拿铁","can_delete":false,"product_type":"c1","uid":1105958,"ip_address":"","ucode":"24266B58968428","user_header":"https://static001.geekbang.org/account/avatar/00/10/e0/26/4942a09e.jpg","comment_is_top":false,"comment_ctime":1542003273,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1542003273","product_id":100020201,"comment_content":"老师 想了解具体的数据分片的过程","like_count":0},{"had_liked":false,"id":38100,"user_name":"hua168","can_delete":false,"product_type":"c1","uid":1065255,"ip_address":"","ucode":"CFF9A7E86EBA48","user_header":"https://static001.geekbang.org/account/avatar/00/10/41/27/3ff1a1d6.jpg","comment_is_top":false,"comment_ctime":1541934986,"is_pvip":false,"replies":[{"id":"13769","content":"不合适，hdfs解决大数据计算问题，不适合电商在线系统。","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1542031731,"ip_address":"","comment_id":38100,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1541934986","product_id":100020201,"comment_content":"HDFS块大小是M，如200M，电商类文件小而多，请求多，用hadoop合适吗？反应慢怎么解决，每台机子放少点？有直接监控hadoop的工具吗？","like_count":0,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":428602,"discussion_content":"不合适，hdfs解决大数据计算问题，不适合电商在线系统。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1542031731,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":37999,"user_name":"张闯","can_delete":false,"product_type":"c1","uid":1090513,"ip_address":"","ucode":"D5AD46A8DD6FB7","user_header":"https://static001.geekbang.org/account/avatar/00/10/a3/d1/a30a4d06.jpg","comment_is_top":false,"comment_ctime":1541847260,"is_pvip":false,"replies":[{"id":"13774","content":"不用这么复杂～","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1542032271,"ip_address":"","comment_id":37999,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1541847260","product_id":100020201,"comment_content":"将用户设备作为DataNodes，平台部署服务器作为NameNode。为提高文件访问性能，一方面，用户数据块优先存储一份在自己的设备上。另一方面，用户设备也同时作为微型NameNode，缓存当前用户自己的数据块信息。仅在写入新数据时需要访问中心NameNode，并通过中心服务器传输数据块到其他用户的设备。","like_count":0,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":428557,"discussion_content":"不用这么复杂～","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1542032271,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":37962,"user_name":"纯洁的憎恶","can_delete":false,"product_type":"c1","uid":1130512,"ip_address":"","ucode":"5E9757DE6F45DF","user_header":"https://static001.geekbang.org/account/avatar/00/11/40/10/b6bf3c3c.jpg","comment_is_top":false,"comment_ctime":1541826958,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1541826958","product_id":100020201,"comment_content":"HDFS要应对磁盘中数据错乱、整块磁盘故障、DataNode服务器宕机、NameNode服务器宕机、数据丢失、用户或处理请求激增等高可用性挑战。","like_count":0},{"had_liked":false,"id":37942,"user_name":"胡杨","can_delete":false,"product_type":"c1","uid":1282449,"ip_address":"","ucode":"2772C05696F688","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/hEOjv6QSUzoksATK55ib2ORZURG4s8oVlI6CTH2TLXkqVHwLeMRpLBmUYOKib6WrrboU8LSklUFWBvR59Dmmu79A/132","comment_is_top":false,"comment_ctime":1541819407,"is_pvip":false,"replies":[{"id":"13778","content":"确实","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1542032743,"ip_address":"","comment_id":37942,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1541819407","product_id":100020201,"comment_content":"这个问题更像区块链的设计，可以说每个设备都可以成为数据中心","like_count":0,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":428535,"discussion_content":"确实","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1542032743,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":37925,"user_name":"姜文","can_delete":false,"product_type":"c1","uid":1235142,"ip_address":"","ucode":"338CC5635B02BC","user_header":"https://static001.geekbang.org/account/avatar/00/12/d8/c6/1f471053.jpg","comment_is_top":false,"comment_ctime":1541812105,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1541812105","product_id":100020201,"comment_content":"首先要部署个name node存储元数据，记录用户数据存储的位置，为保证name node的高可用，必须做备份，通过zookeeper选举主 name node，data node就是全世界的移动设备，用户的数据要做备份，至少三份，用户的app必须和name node的主备服务器做心跳，用于移动设备故障时能主动上报或者name node能及时发现保证数据可用。用户如果要存储数据必须通知name node做好元数据记录及datanode的数据备份。第一次回答，请老师指教。","like_count":0},{"had_liked":false,"id":37917,"user_name":"鸠摩智","can_delete":false,"product_type":"c1","uid":1106201,"ip_address":"","ucode":"853E584FC4CD64","user_header":"https://static001.geekbang.org/account/avatar/00/10/e1/19/c756aaed.jpg","comment_is_top":false,"comment_ctime":1541809272,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1541809272","product_id":100020201,"comment_content":"如果hdfs上存储的文件数量很多，元数据信息超出了namenode的内存限制，怎么解决呢？","like_count":0},{"had_liked":false,"id":37916,"user_name":"每天晒白牙","can_delete":false,"product_type":"c1","uid":1004698,"ip_address":"","ucode":"A1B102CD933DEA","user_header":"https://static001.geekbang.org/account/avatar/00/0f/54/9a/76c0af70.jpg","comment_is_top":false,"comment_ctime":1541808941,"is_pvip":false,"discussion_count":0,"race_medal":1,"score":"1541808941","product_id":100020201,"comment_content":"把多个个人空闲存储空间看做一个datanode","like_count":0},{"had_liked":false,"id":37911,"user_name":"jon","can_delete":false,"product_type":"c1","uid":1253287,"ip_address":"","ucode":"5768A34E292CAA","user_header":"https://static001.geekbang.org/account/avatar/00/13/1f/a7/d379ca4f.jpg","comment_is_top":false,"comment_ctime":1541806156,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1541806156","product_id":100020201,"comment_content":"每个用户的共享存储可以看成一个datanode，主要考虑datanode的可用性问题。","like_count":0}]}