{"id":646363,"title":"11｜省下钱买显卡，如何利用开源模型节约成本？","content":"<p>你好，我是徐文浩。</p><p>不知道课程上到这里，你账户里免费的5美元的额度还剩下多少了？如果你尝试着完成我给的几个数据集里的思考题，相信这个额度应该是不太够用的。而ChatCompletion的接口，又需要传入大量的上下文信息，实际消耗的Token数量其实比我们感觉的要多。</p><p>而且，除了费用之外，还有一个问题是数据安全。因为每个国家的数据监管要求不同，并不是所有的数据，都适合通过OpenAI的API来处理的。所以，从这两个角度出发，我们需要一个OpenAI以外的解决方案。那对于没有足够技术储备的中小型公司来说，最可行的一个思路就是利用好开源的大语言模型。</p><h2>在Colab里使用GPU</h2><p>因为这一讲我们要使用一些开源模型，但不是所有人的电脑里都有一个强劲的NVidia GPU的。所以，我建议你通过Colab来运行对应的Notebook，并且注意，要把对应的运行环境设置成GPU。</p><p><img src=\"https://static001.geekbang.org/resource/image/1c/21/1c0791bd5c1e088eeb527f2acb81a021.png?wh=1255x584\" alt=\"图片\"></p><ol>\n<li>你先选择菜单栏里的Runtime，然后点击Change runtime type。</li>\n</ol><p><img src=\"https://static001.geekbang.org/resource/image/50/23/502a4baceab267e949957c6477bc5823.png?wh=1257x489\" alt=\"图片\"></p><ol start=\"2\">\n<li>然后在弹出的对话框里，把Hardware accelerator换成GPU，然后点击Save就可以了。</li>\n</ol><p>只要用得不是太多，Colab的GPU是可以免费使用的。</p><h2>HuggingfaceEmbedding，你的开源伙伴</h2><!-- [[[read_end]]] --><p>其实我们之前在 <a href=\"https://time.geekbang.org/column/article/642224\">第 4 讲</a>对比零样本分类效果的时候，就已经使用过Google开源的模型T5了。那个模型的效果，虽然比OpenAI的API还是要差一些，但是其实90%的准确率也还算不错了。那么联想一下，上一讲我们使用的llama-index向量搜索部分，是不是可以用开源模型的Embedding给替换掉呢？</p><p>当然是可以的，llama-index支持你自己直接定义一个定制化的Embedding，对应的代码我放在了下面。</p><pre><code class=\"language-python\">conda install -c conda-forge sentence-transformers\n</code></pre><p><span class=\"reference\">注：我们需要先安装一下sentence-transformers这个库。</span></p><pre><code class=\"language-python\">import openai, os\nimport faiss\nfrom llama_index import SimpleDirectoryReader, LangchainEmbedding, GPTFaissIndex, ServiceContext\nfrom langchain.embeddings.huggingface import HuggingFaceEmbeddings\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom llama_index.node_parser import SimpleNodeParser\n\nopenai.api_key = \"\"\n\ntext_splitter = CharacterTextSplitter(separator=\"\\n\\n\", chunk_size=100, chunk_overlap=20)\nparser = SimpleNodeParser(text_splitter=text_splitter)\ndocuments = SimpleDirectoryReader('./data/faq/').load_data()\nnodes = parser.get_nodes_from_documents(documents)\n\nembed_model = LangchainEmbedding(HuggingFaceEmbeddings(\n    model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n))\nservice_context = ServiceContext.from_defaults(embed_model=embed_model)\n\ndimension = 768\nfaiss_index = faiss.IndexFlatIP(dimension)\nindex = GPTFaissIndex(nodes=nodes,faiss_index=faiss_index, service_context=service_context)\n</code></pre><p>输出结果：</p><pre><code class=\"language-python\">INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-mpnet-base-v2\nINFO:sentence_transformers.SentenceTransformer:Use pytorch device: cpu\nWARNING:root:Created a chunk of size 130, which is longer than the specified 100\n……\nINFO:llama_index.token_counter.token_counter:&gt; [build_index_from_documents] Total LLM token usage: 0 tokens\nINFO:llama_index.token_counter.token_counter:&gt; [build_index_from_documents] Total embedding token usage: 3198 tokens\n</code></pre><p>在这个例子里面，我们使用了一个面向电商的FAQ的纯文本文件作为输入。里面是一系列预设好的FAQ问答对。为了确保我们没有使用OpenAI的API，我们先把openai.api_key给设成了一个空字符串。然后，我们定义了一个embeded_model，这个embeded_model里面，我们包装的是一个HuggingFaceEmbeddings的类。</p><p>因为HuggingFace为基于transformers的模型定义了一个标准，所以大部分模型你只需要传入一个模型名称，HuggingFacebEmbedding这个类就会下载模型、加载模型，并通过模型来计算你输入的文本的Embedding。使用HuggingFace的好处是，你可以通过一套代码使用所有的transfomers类型的模型。</p><p><a href=\"https://sbert.net/\">sentence-transformers</a> 是目前效果最好的语义搜索类的模型，它在BERT的基础上采用了对比学习的方式，来区分文本语义的相似度，它包括了一系列的预训练模型。我们在这里，选用的是 sentence-transformers下面的 paraphrase-multilingual-mpnet-base-v2&nbsp;模型。顾名思义，这个是一个支持多语言（multilingual）并且能把语句和段落（paraphrase）变成向量的一个模型。因为我们给的示例都是中文，所以选取了这个模型。你可以根据你要解决的实际问题，来选取一个适合自己的模型。</p><p>我们还是使用Faiss这个库来作为我们的向量索引库，所以需要指定一下向量的维度，paraphrase-multilingual-mpnet-base-v2&nbsp;这个模型的维度是768，所以我们就把维度定义成768维。</p><p>相应的对文档的切分，我们使用的是CharacterTextSplitter，并且在参数上我们做了一些调整。</p><p>首先，我们把“\\n\\n”这样两个连续的换行符作为一段段文本的分隔符，因为我们的FAQ数据里，每一个问答对都有一个空行隔开，正好是连续两个换行。</p><p>然后，我们把chunk_size设置得比较小，只有100。这是因为我们所使用的开源模型是个小模型，这样我们才能在单机加载起来。它能够支持的输入长度有限，只有128个Token，超出的部分会进行截断处理。如果我们不设置chunk_size，llama-index会自动合并多个chunk变成一个段落。</p><p>其次，我们还增加了一个小小的参数，叫做chunk_overlap。这个参数代表我们自动合并小的文本片段的时候，可以接受多大程度的重叠。它的默认值是200，超过了单段文档的chunk_size，所以我们这里要把它设小一点，不然程序会报错。</p><p>我们可以在对应的verbose日志里看到，这里的Embedding使用了3198个Token，不过这些Token都是我们通过sentence_transformers类型的开源模型计算的，不需要花钱。你的成本就节约下来了。</p><p>在创建完整个索引之后，我们就可以拿一些常见的电商类型的FAQ问题试一试。</p><p>问题1：</p><pre><code class=\"language-plain\">from llama_index import QueryMode\n\nopenai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n\nresponse = index.query(\n    \"请问你们海南能发货吗？\", \n    mode=QueryMode.EMBEDDING,\n    verbose=True, \n)\nprint(response)\n</code></pre><p>输出结果：</p><pre><code class=\"language-plain\">&gt; Got node text: Q: 支持哪些省份配送？\nA: 我们支持全国大部分省份的配送，包括北京、上海、天津、重庆、河北、山西、辽宁、吉林、黑龙江、江苏、浙江、安徽、福建、江西、山东、河南、湖北、湖南、广东、海南、四川、贵州、云南、陕西、甘肃、青海、台湾、内蒙古、广西、西藏、宁夏和新疆...\n\nINFO:llama_index.token_counter.token_counter:&gt; [query] Total LLM token usage: 341 tokens\nINFO:llama_index.token_counter.token_counter:&gt; [query] Total embedding token usage: 24 tokens\n\n是的，我们支持海南省的配送。\n</code></pre><p>问题2：</p><pre><code class=\"language-plain\">response = index.query(\n    \"你们用哪些快递公司送货？\", \n    mode=QueryMode.EMBEDDING,\n    verbose=True, \n)\nprint(response)\n</code></pre><p>输出结果：</p><pre><code class=\"language-plain\">&gt; Got node text: Q: 提供哪些快递公司的服务？\nA: 我们与顺丰速运、圆通速递、申通快递、韵达快递、中通快递、百世快递等多家知名快递公司合作。...\nINFO:llama_index.token_counter.token_counter:&gt; [query] Total LLM token usage: 281 tokens\nINFO:llama_index.token_counter.token_counter:&gt; [query] Total embedding token usage: 27 tokens\n\n我们与顺丰速运、圆通速递、申通快递、韵达快递、中通快递、百世快递等多家知名快递公司合作，用他们的服务送货。\n</code></pre><p>问题3：</p><pre><code class=\"language-plain\">response = index.query(\n    \"你们的退货政策是怎么样的？\", \n    mode=QueryMode.EMBEDDING,\n    verbose=True, \n)\nprint(response)\n</code></pre><p>输出结果：</p><pre><code class=\"language-plain\">&gt; Got node text: Q: 退货政策是什么？\nA: 自收到商品之日起7天内，如产品未使用、包装完好，您可以申请退货。某些特殊商品可能不支持退货，请在购买前查看商品详情页面的退货政策。...\nINFO:llama_index.token_counter.token_counter:&gt; [query] Total LLM token usage: 393 tokens\nINFO:llama_index.token_counter.token_counter:&gt; [query] Total embedding token usage: 27 tokens\n\n我们的退货政策是自收到商品之日起7天内，如产品未使用、包装完好，您可以申请退货。某些特殊商品可能不支持退货，请在购买前查看商品详情页面的退货政策。\n</code></pre><p>我们在问问题的时候，指定了query的mode是Embedding。通过三个常用的问题，我们可以看到，AI都给出了正确的回答，效果还是不错的。</p><h2>使用ChatGLM提供对话效果</h2><p>通过上面的代码，我们已经把生成Embedding以及利用Embedding的相似度进行搜索搞定了。但是，我们在实际问答的过程中，使用的还是OpenAI的Completion API。那么这一部分我们有没有办法也替换掉呢？</p><p>同样的，我们寻求开源模型的帮助。在这里，我们就不妨来试一下来自清华大学的ChatGLM语言模型，看看中文的开源语言模型，是不是也有基本的知识理解和推理能力。</p><p>首先我们还是要安装一些依赖包，因为icetk我没有找到Conda的源，所以我们这里通过pip来安装，但是在Conda的包管理器里一样能够看到。</p><pre><code class=\"language-python\">pip install icetk\npip install cpm_kernels\n</code></pre><p>然后，我们还是先通过transformers来加载模型。<a href=\"https://github.com/THUDM/GLM-130B\">ChatGLM</a> 最大的一个模型有1300亿个参数。</p><pre><code class=\"language-python\">from transformers import AutoTokenizer, AutoModel\ntokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm-6b-int4\", trust_remote_code=True)\nmodel = AutoModel.from_pretrained(\"THUDM/chatglm-6b-int4\", trust_remote_code=True).half().cuda()\nmodel = model.eval()\n</code></pre><p>输出结果：</p><pre><code class=\"language-python\">Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\nExplicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\nExplicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\nNo compiled kernel found.\nCompiling kernels : /root/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b-int4/dac03c3ac833dab2845a569a9b7f6ac4e8c5dc9b/quantization_kernels.c\nCompiling gcc -O3 -fPIC -std=c99 /root/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b-int4/dac03c3ac833dab2845a569a9b7f6ac4e8c5dc9b/quantization_kernels.c -shared -o /root/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b-int4/dac03c3ac833dab2845a569a9b7f6ac4e8c5dc9b/quantization_kernels.so\nKernels compiled : /root/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b-int4/dac03c3ac833dab2845a569a9b7f6ac4e8c5dc9b/quantization_kernels.so\nLoad kernel : /root/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b-int4/dac03c3ac833dab2845a569a9b7f6ac4e8c5dc9b/quantization_kernels.so\nUsing quantization cache\nApplying quantization to glm layers\n</code></pre><p>但是这么大的模型，无论是你自己的电脑，还是Colab提供的GPU和TPU显然都放不了。所以我们只能选用一个裁剪后的60亿个参数的版本，并且我们还必须用int-4量化的方式，而不是用float16的浮点数。所以，这里我们的模型名字就叫做 chatglm-6b-int4，也就是 6B的参数量，通过int-4量化。然后，在这里，我们希望通过GPU进行模型的计算，所以加载模型的时候调用了.cuda()。</p><p>这里加载模型的时候，我们还设置了一个 trust_remote_code = true 的参数，这是因为ChatGLM的模型不是一个Huggingface官方发布的模型，而是由用户贡献的，所以需要你显式确认你信任这个模型的代码，它不会造成恶意的破坏。我们反正是在Colab里面运行这个代码，所以倒是不用太担心。</p><p>如果你想要用CPU运行，可以把模型加载的代码换成下面这样。</p><pre><code class=\"language-python\">model = AutoModel.from_pretrained(\"THUDM/chatglm-6b-int4\",trust_remote_code=True).float()\n</code></pre><p>不过，我不建议你这么做。你没有GPU的话，还是直接使用Colab的GPU就好了。因为CPU在运行对话的时候非常慢。</p><p>在拿到模型之后我们就可以尝试着通过这个模型来进行问答了。</p><p>问题1：</p><pre><code class=\"language-python\">question = \"\"\"\n自收到商品之日起7天内，如产品未使用、包装完好，您可以申请退货。某些特殊商品可能不支持退货，请在购买前查看商品详情页面的退货政策。\n\n根据以上信息，请回答下面的问题：\n\nQ: 你们的退货政策是怎么样的？\n\"\"\"\nresponse, history = model.chat(tokenizer, question, history=[])\nprint(response)\n</code></pre><p>输出结果：</p><pre><code class=\"language-python\">我们的退货政策是在产品未使用、包装完好的情况下，自收到商品之日起7天内可以退货。请注意，某些特殊商品可能不支持退货，在购买前请查看商品详情页面的退货政策，以了解具体情况。\n</code></pre><p>可以看到，ChatGLM的回答，的确是按照我们提示语里面有的上下文给出的。我们可以试着去掉提供的FAQ的内容，看看它的回答是怎样的。</p><p>问题2：</p><pre><code class=\"language-python\">question = \"\"\"\nQ: 你们的退货政策是怎么样的？\nA: \n\"\"\"\nresponse, history = model.chat(tokenizer, question, history=[])\nprint(response)\n</code></pre><p>输出结果：</p><pre><code class=\"language-python\">我们公司的政策是，如果您在购买后的7天内发现我们的产品不符合您的期望，可以申请退货。退货条件如下：\n1. 符合退货政策要求的产品；\n2. 未使用或损坏的产品；\n3. 符合退货地点的要求，即退货地址与购买地址相同；\n4. 符合退货流程的要求，即您需要提供有效的退货单并完成退货流程。\n如果符合上述退货政策要求，我们将尽快处理您的退货申请，并为您退款。请注意，如果您已经使用了我们的产品，或者产品有损坏或变质等情况，我们将无法为您提供退货服务。\n</code></pre><p>可以看到，在没有合适的上下文信息的时候，它编造出了一些原本没有的要求，比如“退货地址与购买地址相同”。</p><p>我们再来看一个例子，看看它能不能拥有简单的推理能力。我们的上下文里只说了可以送到海南，没有说是否支持三亚这个城市，看看这个时候AI能不能回答对这个问题。</p><p>问题3：</p><pre><code class=\"language-python\">question = \"\"\"\n我们支持全国大部分省份的配送，包括北京、上海、天津、重庆、河北、山西、辽宁、吉林、黑龙江、江苏、浙江、安徽、福建、江西、山东、河南、湖北、湖南、广东、海南、四川、贵州、云南、陕西、甘肃、青海、台湾、内蒙古、广西、西藏、宁夏和新疆.\n\n根据以上信息，请回答下面的问题：\n\nQ: 你们能配送到三亚吗？\n\"\"\"\nresponse, history = model.chat(tokenizer, question, history=[])\nprint(response)\n</code></pre><p>输出结果：</p><pre><code class=\"language-python\">是的，我们支持全国大部分省份的配送，包括三亚市。\n</code></pre><p>可以看到，ChatGLM知道是可以配送到三亚的。不过万一是巧合呢？我们再看看在上下文里面，去掉了东三省，然后问问它能不能送到哈尔滨。</p><p>问题4：</p><pre><code class=\"language-python\">question = \"\"\"\n我们支持全国大部分省份的配送，包括北京、上海、天津、重庆、河北、山西、江苏、浙江、安徽、福建、江西、山东、河南、湖北、湖南、广东、海南、四川、贵州、云南、陕西、甘肃、青海、台湾、内蒙古、广西、西藏、宁夏和新疆.但是不能配送到东三省\n\n根据以上信息，请回答下面的问题：\n\nQ: 你们能配送到哈尔滨吗？\n\"\"\"\nresponse, history = model.chat(tokenizer, question, history=[])\nprint(response)\n</code></pre><p>回答：</p><pre><code class=\"language-python\">很抱歉，我们目前不能配送到哈尔滨。\n</code></pre><p>结果也是正确的，这个时候，ChatGLM会回答我们是送不到哈尔滨的。既然ChatGLM能够正确回答这个问题，那我们的FAQ问答就可以用ChatGLM来搞定了。</p><h2>将ChatGLM封装成LLM</h2><p>不过上面的代码里面，我们用的还是原始的ChatGLM的模型代码，还不能直接通过query来访问llama-index直接得到答案。要做到这一点倒也不难，我们把它封装成一个LLM类，让我们的index使用这个指定的大语言模型就好了。对应的 <a href=\"https://gpt-index.readthedocs.io/en/latest/how_to/customization/custom_llms.html\">llama-index 的文档</a>，你也可以自己去看一下。</p><pre><code class=\"language-python\">import openai, os\nimport faiss\nfrom llama_index import SimpleDirectoryReader, LangchainEmbedding, GPTFaissIndex, ServiceContext\nfrom langchain.embeddings.huggingface import HuggingFaceEmbeddings\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom llama_index.node_parser import SimpleNodeParser\n\nfrom langchain.llms.base import LLM\nfrom llama_index import LLMPredictor\nfrom typing import Optional, List, Mapping, Any\n\nclass CustomLLM(LLM):\n    def _call(self, prompt: str, stop: Optional[List[str]] = None) -&gt; str:\n        response, history = model.chat(tokenizer, prompt, history=[])\n        return response\n\n    @property\n    def _identifying_params(self) -&gt; Mapping[str, Any]:\n        return {\"name_of_model\": \"chatglm-6b-int4\"}\n\n    @property\n    def _llm_type(self) -&gt; str:\n        return \"custom\"\n</code></pre><p>我们把这个CustomLLM对象，传入index的构造函数里，重新运行一下我们的问题，看看效果是怎样的。</p><pre><code class=\"language-python\">from langchain.text_splitter import SpacyTextSplitter\n\nllm_predictor = LLMPredictor(llm=CustomLLM())\n\ntext_splitter = CharacterTextSplitter(separator=\"\\n\\n\", chunk_size=100, chunk_overlap=20)\nparser = SimpleNodeParser(text_splitter=text_splitter)\ndocuments = SimpleDirectoryReader('./drive/MyDrive/colab_data/faq/').load_data()\nnodes = parser.get_nodes_from_documents(documents)\n\nembed_model = LangchainEmbedding(HuggingFaceEmbeddings(\n    model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n))\nservice_context = ServiceContext.from_defaults(embed_model=embed_model, llm_predictor=llm_predictor)\n\ndimension = 768\nfaiss_index = faiss.IndexFlatIP(dimension)\nindex = GPTFaissIndex(nodes=nodes, faiss_index=faiss_index, service_context=service_context)\n</code></pre><pre><code class=\"language-python\">from llama_index import QuestionAnswerPrompt\nfrom llama_index import QueryMode\n\nQA_PROMPT_TMPL = (\n    \"{context_str}\"\n    \"\\n\\n\"\n    \"根据以上信息，请回答下面的问题：\\n\"\n    \"Q: {query_str}\\n\"\n    )\nQA_PROMPT = QuestionAnswerPrompt(QA_PROMPT_TMPL)\n\nresponse = index.query(\n    \"请问你们海南能发货吗？\", \n    mode=QueryMode.EMBEDDING,\n    text_qa_template=QA_PROMPT,\n    verbose=True, \n)\nprint(response)\n</code></pre><p>输出结果：</p><pre><code class=\"language-python\">&gt; Got node text: Q: 支持哪些省份配送？\nA: 我们支持全国大部分省份的配送，包括北京、上海、天津、重庆、河北、山西、辽宁、吉林、黑龙江、江苏、浙江、安徽、福建、江西、山东、河南、湖北、湖南、广东、海南、四川、贵州、云南、陕西、甘肃、青海、台湾、内蒙古、广西、西藏、宁夏和新疆...\n\n海南能发货。\n</code></pre><p>可以看到，这样处理之后，我们就可以直接使用ChatGLM的模型，来进行我们的FAQ的问答了。</p><p>现在，我们有了一个通过paraphrase-multilingual-mpnet-base-v2模型来计算Embeddding并进行语义搜索，然后通过chatglm-6b-int4的模型来进行问答的解决方案了。而且这两个模型，可以跑在一块家用级别的显卡上。是不是很厉害？</p><h2>开源模型的不足之处</h2><p>看起来，我们这个本机就能运行的小模型似乎已经完成了。数据安全，又不用担心花费。但显然，事情没有那么简单。因为刚才我们处理的电商FAQ问题比较简单，我们再拿一个稍微复杂一点的问题来看看效果。</p><pre><code class=\"language-python\">text_splitter = SpacyTextSplitter(pipeline=\"zh_core_web_sm\", chunk_size = 128, chunk_overlap=32)\nparser = SimpleNodeParser(text_splitter=text_splitter)\ndocuments = SimpleDirectoryReader('./drive/MyDrive/colab_data/zhaohuaxishi/').load_data()\nnodes = parser.get_nodes_from_documents(documents)\n\nembed_model = LangchainEmbedding(HuggingFaceEmbeddings(\n    model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n))\nservice_context = ServiceContext.from_defaults(embed_model=embed_model, llm_predictor=llm_predictor)\n\ndimension = 768\nfaiss_index = faiss.IndexFlatIP(dimension)\nindex = GPTFaissIndex(nodes=nodes, faiss_index=faiss_index, service_context=service_context)\n</code></pre><p>输出结果：</p><pre><code class=\"language-python\">INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-mpnet-base-v2\nINFO:sentence_transformers.SentenceTransformer:Use pytorch device: cpu\n……\nINFO:llama_index.token_counter.token_counter:&gt; [build_index_from_documents] Total LLM token usage: 0 tokens\nINFO:llama_index.token_counter.token_counter:&gt; [build_index_from_documents] Total embedding token usage: 91882 tokens\n</code></pre><p>这一次，我们输入索引起来的数据，是鲁迅先生整套《朝花夕拾》的散文集。选用这个是因为对应作品的版权已经过了保护期。我们来看看，在这套文集的内容里面，使用我们上面的纯开源方案，效果会是怎样的。</p><p>对应的模型和索引加载的代码基本一致，只有一个小小的区别，就是在文本分割的时候，我们用了上一讲介绍过的SpacyTextSplitter，因为这里都是散文的内容，而不是确定好格式的QA对。所以通过SpacyTextSplitter来分句，并在允许的时候合并小的片段是有意义的。</p><p>然后，我们试着问一下上一讲我们问过的问题，看看效果怎么样。</p><p>问题1：</p><pre><code class=\"language-python\"># query will use the same embed_model\nfrom llama_index import QueryMode\nfrom llama_index import QuestionAnswerPrompt\n\nopenai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n\nQA_PROMPT_TMPL = (\n    \"下面的内容来自鲁迅先生的散文集《朝花夕拾》，很多内容是以第一人称写的 \\n\"\n    \"---------------------\\n\"\n    \"{context_str}\"\n    \"\\n---------------------\\n\"\n    \"根据这些信息，请回答问题: {query_str}\\n\"\n    \"如果您不知道的话，请回答不知道\\n\"\n)\nQA_PROMPT = QuestionAnswerPrompt(QA_PROMPT_TMPL)\n\nresponse = index.query(\n    \"鲁迅先生在日本学习医学的老师是谁？\", \n    mode=QueryMode.EMBEDDING,\n    similarity_top_k = 1,\n    text_qa_template=QA_PROMPT,\n    verbose=True, \n)\nprint(response)\n</code></pre><p>输出结果：</p><pre><code class=\"language-python\">&gt; Got node text: 一将书放在讲台上，便用了缓慢而很有顿挫的声调，向学生介绍自己道：—— \n    “我就是叫作藤野严九郎的……。”\n\n    \n后面有几个人笑起来了。\n他接着便讲述解剖学在日本发达的历史，那些大大小小的书，便是从最初到现今关于这一门学问的著作。...\n\n鲁迅先生在日本学习医学的老师是藤野严九郎。\n</code></pre><p>问题2：</p><pre><code class=\"language-python\">response = index.query(\n    \"鲁迅先生是在日本的哪个城市学习医学的？\", \n    mode=QueryMode.EMBEDDING, \n    similarity_top_k = 1,   \n    text_qa_template=QA_PROMPT,\n    verbose=True, \n)\nprint(response)\n</code></pre><p>输出结果：</p><pre><code class=\"language-python\">&gt; Got node text: 有时我常常想：他的对于我的热心的希望，不倦的教诲，小而言之，是为中国，就是希望中国有新的医学；大而言之，是为学术，就是希望新的医学传到中国去。...\n\n根据这些信息，无法得出鲁迅先生是在日本的哪个城市学习医学的答案。\n</code></pre><p>可以看到，有些问题在这个模式下，定位到的文本片段是正确的。但是有些问题，虽然定位的还算是一个相关的片段，但是的确无法得出答案。</p><p>在这个过程中，我们可以观察到这样一个问题： 那就是单机的开源小模型能够承载的文本输入的长度问题。在我们使用OpenAI的gpt-3.5-turbo模型的时候，我们最长支持4096个Token，也就是一个文本片段可以放上上千字在里面。但是我们这里单机用的paraphrase-multilingual-mpnet-base-v2模型，只能支持128个Token的输入，虽然对应的Tokenizer不一样，但是就算一个字一个Token，也就100个字而已。这使得我们检索出来的内容的上下文太少了，很多时候没有足够的信息，让语言模型去回答。</p><p>当然，这个问题并不是无法弥补的。我们可以通过把更大规模的模型，部署到云端来解决。这个内容，我们课程的第三部分专门有一讲会讲解。</p><p>不过，有一个更难解决的问题，就是模型的推理能力问题。比如，我们可以再试试<a href=\"https://time.geekbang.org/column/article/641742\">第 1 讲</a>里给商品总结英文名称和卖点的例子。</p><pre><code class=\"language-python\">question = \"\"\"Consideration proudct : 工厂现货PVC充气青蛙夜市地摊热卖充气玩具发光蛙儿童水上玩具\n\n1. Compose human readale product title used on Amazon in english within 20 words.\n2. Write 5 selling points for the products in Amazon.\n3. Evaluate a price range for this product in U.S.\n\nOutput the result in json format with three properties called title, selling_points and price_range\"\"\"\nresponse, history = model.chat(tokenizer, question, history=[])\nprint(response)\n</code></pre><p>输出结果：</p><pre><code class=\"language-python\">1. title: 充气玩具青蛙夜市地摊卖\n2. selling_points:\n    - 工厂现货：保证产品质量\n    - PVC充气：环保耐用\n    - 夜市地摊：方便销售\n    - 热卖：最受欢迎产品\n    - 儿童水上玩具：适合各种年龄段儿童\n3. price_range: (in USD)\n    - low:   $1.99\n    - high:   $5.99\n</code></pre><p>可以看到，虽然这个结果不算太离谱，多少和问题还是有些关系的。但是无论是翻译成英文，还是使用JSON返回，模型都没有做到。给到的卖点也没有任何“推理出来”的性质，都是简单地对标题的重复描述。即使你部署一个更大版本的模型到云端，也好不到哪里去。</p><p>这也是ChatGPT让人震撼的原因，的确目前它的效果还是要远远超出任何一个竞争对手和开源项目的。</p><h2>小结</h2><p>好了，最后我们来回顾一下。这一讲里，我们一起尝试用开源模型来代替ChatGPT。我们通过sentence_transfomers类型的模型，生成了文本分片的Embedding，并且基于这个Embedding来进行语义检索。我们通过 ChatGLM 这个开源模型，实现了基于上下文提示语的问答。在简单的电商QA这样的场景里，效果也还是不错的。即使我们使用的都是单机小模型，它也能正确回答出来。这些方法，也能节约我们的成本。不用把钱都交给OpenAI，可以攒着买显卡来训练自己的模型。</p><p>但是，当我们需要解决更加复杂的问题时，比如需要更长的上下文信息，或者需要模型本身更强的推理能力的时候，这样的小模型就远远不够用了。更长的上下文信息检索，我们还能够通过在云端部署更大规模的模型，解决部分问题。但是模型的推理能力，目前的确没有好的解决方案。</p><p>所以不得不佩服，OpenAI的在AGI这个目标上耕耘多年后震惊世人的效果。</p><h2>思考题</h2><p>最后，给你留一个思考题。ChatGLM并不是唯一的中文大语言模型，开源社区目前在快速推进，尝试用各种方式提供更好的开源大模型。比如基于斯坦福的Alpaca数据集进行微调的 <a href=\"https://github.com/ymcui/Chinese-LLaMA-Alpaca\">Chinese-LLaMA-Alpaca</a>，链家科技开源的 <a href=\"https://github.com/LianjiaTech/BELLE\">BELLE</a>。你可以挑选一个模型试一试，看看它们的效果和ChatGLM比起来怎么样。欢迎你把你的评测结果分享出来，也欢迎你把这节课分享给需要的朋友，共同参谋，一起进步。我们下节课再见。</p><h2>推荐阅读</h2><p>基于开源模型来解决问题的思路并非我的原创，网上也有不少其他朋友用类似的方式解决了自己的问题。比如<a href=\"https://mp.weixin.qq.com/s/iplUoK_JYeL_9EC7Ttt3tw\">《让 LLM 回答问题更靠谱》这篇文章</a>就组合了三个模型来完成了医学领域的语义搜索、语义匹配排序，以及最终的问答语句生成。你可以读一下。</p>","neighbors":{"left":{"article_title":"10｜AI连接外部资料库，让Llama Index带你阅读一本书","id":645305},"right":{"article_title":"12｜让AI帮你写个小插件，轻松处理Excel文件","id":646801}},"comments":[{"had_liked":false,"id":373394,"user_name":"zhihai.tu","can_delete":false,"product_type":"c1","uid":1045888,"ip_address":"上海","ucode":"61371EA3EF6988","user_header":"https://static001.geekbang.org/account/avatar/00/0f/f5/80/baddf03b.jpg","comment_is_top":false,"comment_ctime":1682471310,"is_pvip":true,"replies":[{"id":136482,"content":"https:&#47;&#47;ayoolafelix.hashnode.dev&#47;how-to-permanently-install-a-module-on-google-colab-ckixqrvs40su044s187y274tc\n\n可以把安装路径都设置到 mount的google drive里，这样以后每次都只需要配置一下路径，不需要再重新安装了。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1683086482,"ip_address":"上海","comment_id":373394,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"老师，想请教一下，我发现我用colab跑了程序，如果第二天再打开这个程序，相应的已经跑过得脚本，效果都失效了，比如pip安装过的都还原了，另外磁盘目录上生成的文件夹和文件也没了。想请问下如何解决这个问题呢？不然相当的麻烦。谢谢。","like_count":5,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":616718,"discussion_content":"https://ayoolafelix.hashnode.dev/how-to-permanently-install-a-module-on-google-colab-ckixqrvs40su044s187y274tc\n\n可以把安装路径都设置到 mount的google drive里，这样以后每次都只需要配置一下路径，不需要再重新安装了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683086482,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":372448,"user_name":"Toni","can_delete":false,"product_type":"c1","uid":3206957,"ip_address":"瑞士","ucode":"E6B2FACCC1E000","user_header":"https://static001.geekbang.org/account/avatar/00/30/ef/2d/757bb0d3.jpg","comment_is_top":false,"comment_ctime":1681157365,"is_pvip":false,"replies":[{"id":135955,"content":"👍","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1681181911,"ip_address":"上海","comment_id":372448,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"在第二讲中，用亚马逊提供的用户对一些食物评价的真实数据集进行了情感分析。当时为了避免重新调用 OpenAI 的 API 浪费钱，老师推荐使用已经计算好的含有 Embedding 的数据。用openai.embeddings_utils 中的 get_embedding (EMBEDDING_MODEL = &quot;text-embedding-ada-002&quot;)不仅费钱还耗时。我试着跑过100个数据，好像用了20分钟，花费也不少。\n\n本节课中老师介绍了免费的 sentence_transformers 正好可以拿来用在情感数据分析上，\n选用 model = SentenceTransformer(&#39;paraphrase-multilingual-mpnet-base-v2&#39;)。同样计算1000个数据的 embedding，速度很快，且无费用，适合练手。\n\n测试结果如下:\n                     precision    recall  f1-score   support\n        negative      0.77      0.78      0.77       148\n         positive      0.96      0.95      0.96       773\n       accuracy                               0.93       921\n    macro avg       0.86      0.87      0.86       921\nweighted avg       0.93      0.93      0.93       921\n\n为了对比，将第二讲中老师用 OpenAI 的方法得到的结果放在了这里:\n\n                    precision    recall  f1-score   support\n        negative      0.98      0.73      0.84       136\n         positive      0.96      1.00      0.98       789\n       accuracy                               0.96       925\n    macro avg       0.97      0.86      0.91       925\nweighted avg       0.96      0.96      0.96       925\n\n使用的方法不用，结果也不同。OpenAI 的准确率更高。","like_count":5,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":613194,"discussion_content":"👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1681181911,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":372236,"user_name":"东方奇骥","can_delete":false,"product_type":"c1","uid":1354850,"ip_address":"四川","ucode":"DEE7085F7E55A4","user_header":"https://static001.geekbang.org/account/avatar/00/14/ac/62/37912d51.jpg","comment_is_top":false,"comment_ctime":1680863901,"is_pvip":false,"replies":[{"id":135860,"content":"显存需要比较大，建议在colab下运行，我给了一个可以在Colab下单独运行的Notebook。\n\nhttps:&#47;&#47;github.com&#47;xuwenhao&#47;geektime-ai-course&#47;blob&#47;main&#47;11_colab_chatglm_opensource.ipynb","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1680972376,"ip_address":"中国香港","comment_id":372236,"utype":1}],"discussion_count":3,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"老师，是不是要4080显卡才跑得动？单机能跑得动吗","like_count":4,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612855,"discussion_content":"显存需要比较大，建议在colab下运行，我给了一个可以在Colab下单独运行的Notebook。\n\nhttps://github.com/xuwenhao/geektime-ai-course/blob/main/11_colab_chatglm_opensource.ipynb","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680972376,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"中国香港","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":1049690,"avatar":"https://static001.geekbang.org/account/avatar/00/10/04/5a/abe070ba.jpg","nickname":"阿白","note":"","ucode":"382614F906D30A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":623997,"discussion_content":"徐老师能不能标注下各个依赖的版本，这个Notebook 各种依赖报错，现在跑不起来","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1690107803,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":612855,"ip_address":"立陶宛","group_id":0},"score":623997,"extra":""}]},{"author":{"id":1941114,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK84c6OjMQM8qCibsCVlytMgQsh1u9FN2CAyNwSLIEfwHN7psOCzt7Wyic0mMF7cR2H7avJyCicIl01w/132","nickname":"ZJS张家书","note":"","ucode":"824D6B964DDEFA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":624207,"discussion_content":"查了一下推荐显存\n量化等级\t最低 GPU 显存\nFP16（无量化）\t13 GB\nINT8\t10 GB\nINT4\t6 GB\n4080有16g，应该是没问题的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1690298024,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":373147,"user_name":"胖子","can_delete":false,"product_type":"c1","uid":2408754,"ip_address":"中国香港","ucode":"2C80824B0D9278","user_header":"https://static001.geekbang.org/account/avatar/00/24/c1/32/778f18b9.jpg","comment_is_top":false,"comment_ctime":1682137742,"is_pvip":true,"replies":[{"id":136513,"content":"感觉是 protobuf 版本的问题，试试看更新一下protobuf版本？\n\npip install --upgrade protobuf\n","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1683091694,"ip_address":"上海","comment_id":373147,"utype":1}],"discussion_count":5,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"AttributeError                            Traceback (most recent call last)\n&lt;ipython-input-54-086bfff09511&gt; in &lt;cell line: 8&gt;()\n      6 Q: 你们的退货政策是怎么样的？\n      7 &quot;&quot;&quot;\n----&gt; 8 response, history = model.chat(tokenizer, question, history=[])\n      9 print(response)\n\n21 frames\n&#47;usr&#47;local&#47;lib&#47;python3.9&#47;dist-packages&#47;google&#47;protobuf&#47;unknown_fields.py in &lt;module&gt;\n     42 from google.protobuf.internal import api_implementation\n     43 \n---&gt; 44 if api_implementation._c_module is not None:  # pylint: disable=protected-access\n     45   UnknownFieldSet = api_implementation._c_module.UnknownFieldSet  # pylint: disable=protected-access\n     46 else:\n\nAttributeError: module &#39;google.protobuf.internal.api_implementation&#39; has no attribute &#39;_c_module&#39;\n\n\n搞不定","like_count":2,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":616754,"discussion_content":"感觉是 protobuf 版本的问题，试试看更新一下protobuf版本？\n\npip install --upgrade protobuf\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683091694,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2238528,"avatar":"https://static001.geekbang.org/account/avatar/00/22/28/40/82d748e6.jpg","nickname":"小理想。","note":"","ucode":"EDC35A907570DB","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":625166,"discussion_content":"我也是这个错，更新不好使","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1691414652,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1812201,"avatar":"https://wx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLm8skz4F7FGGBTXWUMia6qVEc00BddeXapicv5FkAx62GmOnUNEcE4scSR60AmappQoNdIQhccKsBA/132","nickname":"末日，成欢","note":"","ucode":"BBAEBB9C93558A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":615957,"discussion_content":"!pip install protobuf==4.21","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1682516092,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"美国","group_id":0},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":2238528,"avatar":"https://static001.geekbang.org/account/avatar/00/22/28/40/82d748e6.jpg","nickname":"小理想。","note":"","ucode":"EDC35A907570DB","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1812201,"avatar":"https://wx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLm8skz4F7FGGBTXWUMia6qVEc00BddeXapicv5FkAx62GmOnUNEcE4scSR60AmappQoNdIQhccKsBA/132","nickname":"末日，成欢","note":"","ucode":"BBAEBB9C93558A","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":625167,"discussion_content":"感谢，可以了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1691414740,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":615957,"ip_address":"北京","group_id":0},"score":625167,"extra":""}]},{"author":{"id":1194643,"avatar":"https://static001.geekbang.org/account/avatar/00/12/3a/93/d7be8a1a.jpg","nickname":"晓小东","note":"","ucode":"93F9462EAAA63C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":615700,"discussion_content":"也是这个错","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1682402317,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":372213,"user_name":"川月","can_delete":false,"product_type":"c1","uid":3579438,"ip_address":"四川","ucode":"CAB1218259CFC5","user_header":"https://static001.geekbang.org/account/avatar/00/36/9e/2e/e46ab171.jpg","comment_is_top":false,"comment_ctime":1680851066,"is_pvip":false,"replies":[{"id":135896,"content":"embedding可以存储到向量数据库，比如 pgvector, milvus, pinecone 等等\n索引可以save下来变成json文件\n\n更详细的手工管理索引的方式，可以看一下 llama-index 的官方文档 https:&#47;&#47;gpt-index.readthedocs.io&#47;en&#47;latest&#47;\n","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1680974839,"ip_address":"日本","comment_id":372213,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"使用这个开源模型获取的index怎么保存啊，使用之前的方法并不行，还有生成的index可以追加吗，不然每次有新数据的时候都要重新跑一边，或者可以使用数据库存储吗，希望老师讲解一下","like_count":2,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612892,"discussion_content":"embedding可以存储到向量数据库，比如 pgvector, milvus, pinecone 等等\n索引可以save下来变成json文件\n\n更详细的手工管理索引的方式，可以看一下 llama-index 的官方文档 https://gpt-index.readthedocs.io/en/latest/\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680974839,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"日本","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1018079,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/88/df/e7bf1bdb.jpg","nickname":"银河系","note":"","ucode":"3BC7FFEDC9F94A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":613162,"discussion_content":"浩哥，faiss保存然后加载一直报错！因为使用自定义的llm和embeding，可以给个例子呢？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1681139408,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":373915,"user_name":"༺ღ天口²º²²ღ༻","can_delete":false,"product_type":"c1","uid":3009561,"ip_address":"上海","ucode":"8052C0A58FFB4C","user_header":"https://static001.geekbang.org/account/avatar/00/2d/ec/19/38511eaf.jpg","comment_is_top":false,"comment_ctime":1683341996,"is_pvip":false,"replies":[{"id":136840,"content":"https:&#47;&#47;github.com&#47;xuwenhao&#47;geektime-ai-course 的 data 目录下","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1684746697,"ip_address":"上海","comment_id":373915,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"老师，FAQ数据在哪里？","like_count":1,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":619014,"discussion_content":"https://github.com/xuwenhao/geektime-ai-course 的 data 目录下","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1684746697,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":372100,"user_name":"孟健","can_delete":false,"product_type":"c1","uid":1373593,"ip_address":"广东","ucode":"E20ECD1823E877","user_header":"https://static001.geekbang.org/account/avatar/00/14/f5/99/5bf198e3.jpg","comment_is_top":false,"comment_ctime":1680731433,"is_pvip":false,"replies":[{"id":135890,"content":"目前 llama 没有公开渠道可以直接获得模型，所以不适合作为课程的一部分\n目前从有限体验来看，裁剪到单机可以加载的情况下，没有觉得在中文上比 ChatGLM 好","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1680974543,"ip_address":"日本","comment_id":372100,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"Meta最近也开源了大语言模型，好像更好一些？","like_count":1,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612886,"discussion_content":"目前 llama 没有公开渠道可以直接获得模型，所以不适合作为课程的一部分\n目前从有限体验来看，裁剪到单机可以加载的情况下，没有觉得在中文上比 ChatGLM 好","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680974543,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"日本","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":374769,"user_name":"地平线","can_delete":false,"product_type":"c1","uid":1482026,"ip_address":"美国","ucode":"F50717D6244867","user_header":"https://static001.geekbang.org/account/avatar/00/16/9d/2a/3e57b54a.jpg","comment_is_top":false,"comment_ctime":1684402593,"is_pvip":false,"replies":[{"id":136788,"content":"llama index 最近又更新了大版本，接口又改了一遍。如果要立刻可以运行，可以先 pip install --force-reinstall -v &quot;llama-index==0.5.27&quot; 退回到 0.5 系列的版本\n\n晚点我看一下更新代码到0.6.x 版本","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1684720467,"ip_address":"新加坡","comment_id":374769,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"由于llama-index 升级，我使用的版本是0.6.8，修改了llama-index代码，程序运行没有报错，但是没有输出内容\n\nfrom langchain.text_splitter import SpacyTextSplitter\n\nllm_predictor = LLMPredictor(llm=CustomLLM())\n\ntext_splitter = CharacterTextSplitter(separator=&quot;\\n\\n&quot;, chunk_size=100, chunk_overlap=20)\nparser = SimpleNodeParser(text_splitter=text_splitter)\ndocuments = SimpleDirectoryReader(&#39;.&#47;drive&#47;MyDrive&#47;colab_data&#47;faq&#47;&#39;).load_data()\nnodes = parser.get_nodes_from_documents(documents)\n\nembed_model = LangchainEmbedding(HuggingFaceEmbeddings(\n    model_name=&quot;sentence-transformers&#47;paraphrase-multilingual-mpnet-base-v2&quot;\n))\nservice_context = ServiceContext.from_defaults(embed_model=embed_model, llm_predictor=llm_predictor)\n\ndimension = 768\nfaiss_index = faiss.IndexFlatIP(dimension)\n\n# index = GPTListIndex(nodes=nodes, faiss_index=faiss_index, service_context=service_context)\nindex = GPTListIndex(nodes=nodes, service_context=service_context)\n\nfrom llama_index import QuestionAnswerPrompt\n\nQA_PROMPT_TMPL = (\n    &quot;{context_str}&quot;\n    &quot;\\n\\n&quot;\n    &quot;根据以上信息，请回答下面的问题：\\n&quot;\n    &quot;Q: {query_str}\\n&quot;\n    )\nQA_PROMPT = QuestionAnswerPrompt(QA_PROMPT_TMPL)\n\nquery_engine = index.as_query_engine(\n    retriever_mode=&quot;embedding&quot;, \n    verbose=True, \n    text_qa_template=QA_PROMPT,\n)\nresponse = query_engine.query(&quot;请问你们海南能发货吗？&quot;)\nprint(response)","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":618920,"discussion_content":"llama index 最近又更新了大版本，接口又改了一遍。如果要立刻可以运行，可以先 pip install --force-reinstall -v &#34;llama-index==0.5.27&#34; 退回到 0.5 系列的版本\n\n晚点我看一下更新代码到0.6.x 版本","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684720467,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"新加坡","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2559238,"avatar":"https://static001.geekbang.org/account/avatar/00/27/0d/06/970cc957.jpg","nickname":"Charles","note":"","ucode":"8ACBA423B5A505","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":621807,"discussion_content":"老师，llama-index 0.6版本怎么写呢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1687664671,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":374729,"user_name":"茶桁","can_delete":false,"product_type":"c1","uid":2254242,"ip_address":"上海","ucode":"3EC3D9C6BF9091","user_header":"https://static001.geekbang.org/account/avatar/00/22/65/a2/88aca8f7.jpg","comment_is_top":false,"comment_ctime":1684370980,"is_pvip":false,"replies":[{"id":136793,"content":"llama index 最近又更新了大版本，接口又改了一遍。如果要立刻可以运行，可以先 pip install --force-reinstall -v &quot;llama-index==0.5.27&quot; 退回到 0.5 系列的版本\n\n晚点我看一下更新代码到0.6.x 版本","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1684720693,"ip_address":"新加坡","comment_id":374729,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"老师，“GPTFaissIndex”这个方法似乎没有了，替换的其他方法不知道是什么，怎么用。","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":618925,"discussion_content":"llama index 最近又更新了大版本，接口又改了一遍。如果要立刻可以运行，可以先 pip install --force-reinstall -v &#34;llama-index==0.5.27&#34; 退回到 0.5 系列的版本\n\n晚点我看一下更新代码到0.6.x 版本","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684720693,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"新加坡","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":374415,"user_name":"horn","can_delete":false,"product_type":"c1","uid":3621427,"ip_address":"北京","ucode":"3EB5C0EAC060A4","user_header":"https://static001.geekbang.org/account/avatar/00/37/42/33/13b19797.jpg","comment_is_top":false,"comment_ctime":1684120268,"is_pvip":false,"replies":[{"id":136806,"content":"llama index 最近又更新了大版本，接口又改了一遍。如果要立刻可以运行，可以先 pip install --force-reinstall -v &quot;llama-index==0.5.27&quot; 退回到 0.5 系列的版本\n\n晚点我看一下更新代码到0.6.x 版本","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1684725367,"ip_address":"新加坡","comment_id":374415,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100541001,"comment_content":"Colab报错怎么回事呢\nImportError: cannot import name &#39;GPTFaissIndex&#39; from &#39;llama_index&#39; (&#47;usr&#47;local&#47;lib&#47;python3.10&#47;dist-packages&#47;llama_index&#47;__init__.py)","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":618951,"discussion_content":"llama index 最近又更新了大版本，接口又改了一遍。如果要立刻可以运行，可以先 pip install --force-reinstall -v &#34;llama-index==0.5.27&#34; 退回到 0.5 系列的版本\n\n晚点我看一下更新代码到0.6.x 版本","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684725367,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"新加坡","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":374250,"user_name":"haha","can_delete":false,"product_type":"c1","uid":1041547,"ip_address":"广东","ucode":"F4F3EAB4A15989","user_header":"https://static001.geekbang.org/account/avatar/00/0f/e4/8b/8a0a6c86.jpg","comment_is_top":false,"comment_ctime":1683783883,"is_pvip":false,"replies":[{"id":136814,"content":"PaLM2没有开源，只能调用Google的API呀，这样和OpenAI对比就显得没啥优势。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1684726406,"ip_address":"新加坡","comment_id":374250,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"PaLM2呢，今天被公众号刷屏了","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":618960,"discussion_content":"PaLM2没有开源，只能调用Google的API呀，这样和OpenAI对比就显得没啥优势。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684726406,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"新加坡","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":374213,"user_name":"Geek_9znsx3","can_delete":false,"product_type":"c1","uid":2005535,"ip_address":"广东","ucode":"BBCD62B306BF23","user_header":"","comment_is_top":false,"comment_ctime":1683712718,"is_pvip":true,"replies":[{"id":136875,"content":"应该是不需要依赖tensorflow的呀？你找一个低一点版本的tensorflow能够兼容 protobuf-3.18 的试试？","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1684754051,"ip_address":"上海","comment_id":374213,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"在colab运行11_colab_chatglm_opensource.ipynb，安装python包时报错，protobuf包版本冲突，请问这个怎么解决？从报错信息看是由于tensorflow-2.12.0依赖protobuf3.20.3，但是icetk-0.0.7依赖 protobuf-3.18.3\nInstalling collected packages: protobuf, icetk\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\nERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n........\ntensorflow 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,&lt;5.0.0dev,&gt;=3.20.3, but you have protobuf 3.18.3 which is incompatible.\ntensorflow-datasets 4.9.2 requires protobuf&gt;=3.20, but you have protobuf 3.18.3 which is incompatible.\ntensorflow-hub 0.13.0 requires protobuf&gt;=3.19.6, but you have protobuf 3.18.3 which is incompatible.\ntensorflow-metadata 1.13.1 requires protobuf&lt;5,&gt;=3.20.3, but you have protobuf 3.18.3 which is incompatible.\nSuccessfully installed icetk-0.0.7 protobuf-3.18.3","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":619064,"discussion_content":"应该是不需要依赖tensorflow的呀？你找一个低一点版本的tensorflow能够兼容 protobuf-3.18 的试试？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684754051,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":373887,"user_name":"李文龙","can_delete":false,"product_type":"c1","uid":1006210,"ip_address":"北京","ucode":"F809A671D72D2E","user_header":"https://static001.geekbang.org/account/avatar/00/0f/5a/82/4d55f0b7.jpg","comment_is_top":false,"comment_ctime":1683290450,"is_pvip":false,"replies":[{"id":136827,"content":"llama index 最近又更新了大版本，接口又改了一遍。如果要立刻可以运行，可以先 pip install --force-reinstall -v &quot;llama-index==0.5.27&quot; 退回到 0.5 系列的版本\n\n晚点我看一下更新代码到0.6.x 版本","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1684741733,"ip_address":"上海","comment_id":373887,"utype":1}],"discussion_count":3,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"请问使用 llama_index 0.6.1 版本，使用 Faiss，代码如下，有报错。\nimport faiss\nfrom llama_index.vector_stores import FaissVectorStore\nfrom llama_index import GPTVectorStoreIndex, StorageContext\n\ndimension = 768\nfaiss_index = faiss.IndexFlatIP(dimension)\nstorage_context = StorageContext.from_defaults(\n    vector_store=FaissVectorStore(faiss_index)\n)\nprint(len(nodes))\nindex = GPTVectorStoreIndex(nodes, storage_context=storage_context)\n\nquery_engine = index.as_query_engine(\n    retriever_mode=&quot;embedding&quot;,\n    verbose=True,\n    service_context = service_context,\n)\n\n报错：\n&#47;usr&#47;local&#47;lib&#47;python3.10&#47;dist-packages&#47;faiss&#47;__init__.py in replacement_add(self, x)\n    212 \n    213         n, d = x.shape\n--&gt; 214         assert d == self.d\n    215         self.add_c(n, swig_ptr(x))\n    216 ","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":618994,"discussion_content":"llama index 最近又更新了大版本，接口又改了一遍。如果要立刻可以运行，可以先 pip install --force-reinstall -v &#34;llama-index==0.5.27&#34; 退回到 0.5 系列的版本\n\n晚点我看一下更新代码到0.6.x 版本","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684741733,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2559238,"avatar":"https://static001.geekbang.org/account/avatar/00/27/0d/06/970cc957.jpg","nickname":"Charles","note":"","ucode":"8ACBA423B5A505","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":621806,"discussion_content":"同问0.6版本的代码怎么写","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1687664567,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3619482,"avatar":"https://static001.geekbang.org/account/avatar/00/37/3a/9a/58a5ebfa.jpg","nickname":"如今无心心自宽","note":"","ucode":"9CFBC78A3EEB12","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":619267,"discussion_content":"请问解决了吗","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684919732,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"中国香港","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":373084,"user_name":"Santiago","can_delete":false,"product_type":"c1","uid":3572315,"ip_address":"山西","ucode":"E7301F6A5076DC","user_header":"https://static001.geekbang.org/account/avatar/00/36/82/5b/df97e03c.jpg","comment_is_top":false,"comment_ctime":1682002042,"is_pvip":false,"replies":[{"id":136493,"content":"ChatGLM 6G不太够，Colab报错具体是在哪一行代码报错？","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1683087329,"ip_address":"上海","comment_id":373084,"utype":1}],"discussion_count":4,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"老师我想问一下 我用colab报错 \nKeyError: &#39;-1&#39;\n这是咋回事呀，还有就是我用3060的显卡6G，直接爆显存了","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":616730,"discussion_content":"ChatGLM 6G不太够，Colab报错具体是在哪一行代码报错？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683087329,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1029016,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/b3/98/2ad8b465.jpg","nickname":"Hugh","note":"","ucode":"126A56632CB09A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":621695,"discussion_content":"这个错误应该是文本数据没有加载到","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1687510122,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1707839,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/0f/3f/8b96cd8a.jpg","nickname":"包子先生","note":"","ucode":"4332DB98492EE2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":621120,"discussion_content":"llama_index/indices/vector_store/base_query.py&#34;, line 86,node_ids = [self._index_struct.nodes_dict[idx] for idx in query_result.ids]\nKeyError: &#39;-1&#39;","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1686830061,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1707839,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/0f/3f/8b96cd8a.jpg","nickname":"包子先生","note":"","ucode":"4332DB98492EE2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":621119,"discussion_content":"我也遇到同样的报错KeyError  ","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1686830049,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":372985,"user_name":"Santiago","can_delete":false,"product_type":"c1","uid":3572315,"ip_address":"山西","ucode":"E7301F6A5076DC","user_header":"https://static001.geekbang.org/account/avatar/00/36/82/5b/df97e03c.jpg","comment_is_top":false,"comment_ctime":1681892230,"is_pvip":false,"replies":[{"id":136472,"content":"试着pip重新安装一下pillow\n\npip install -U pillow","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1683085215,"ip_address":"上海","comment_id":372985,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"RuntimeError: Failed to import transformers.models.t5.configuration_t5 because of the following error (look up to see its traceback):\nFailed to import transformers.onnx.config because of the following error (look up to see its traceback):\nDLL load failed while importing _imaging: 找不到指定的模块。","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":616702,"discussion_content":"试着pip重新安装一下pillow\n\npip install -U pillow","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683085215,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":372929,"user_name":"良辰美景","can_delete":false,"product_type":"c1","uid":1074803,"ip_address":"上海","ucode":"B36E6955A2872D","user_header":"https://static001.geekbang.org/account/avatar/00/10/66/73/fd1e37a2.jpg","comment_is_top":false,"comment_ctime":1681808578,"is_pvip":false,"replies":[{"id":136466,"content":"1. 云平台可以直接购买安装了GPU的服务器\n2. 单机多卡的情况下，一台机器可以多块GPU。并且NVLink可以把8块卡串联到一起\n3. 调度问题，有kubeflow这样的方案通过 kubernetes\n\nMLOps特别是大模型领域还是一个比较新的方向，业界有各种解决方案，但是目前还谈不上形成标准。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1683084054,"ip_address":"上海","comment_id":372929,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"老师， 问一个工程上的问题， 像这种要求大量计算资源AI系统， 在工程上如何能做到可用呢， 需要购买大量的GPU这个可以想到。 购买的这些芯片如何能够串联形成类似“云”的能力？ 这个是各个公司需要有自己的解决方案还是业界已经有成熟的解决方案了？ ","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":616692,"discussion_content":"1. 云平台可以直接购买安装了GPU的服务器\n2. 单机多卡的情况下，一台机器可以多块GPU。并且NVLink可以把8块卡串联到一起\n3. 调度问题，有kubeflow这样的方案通过 kubernetes\n\nMLOps特别是大模型领域还是一个比较新的方向，业界有各种解决方案，但是目前还谈不上形成标准。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1683084054,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":372850,"user_name":"Geek_3d7708","can_delete":false,"product_type":"c1","uid":2601970,"ip_address":"中国香港","ucode":"9F707F39739109","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTISHN4HwTsOicDUzB1jyzlxzriaI3S7tAfoPzicSfuTbxLxRjkCic2eBwRWxJTrwTpiaYP8Hg8vqWgNE2w/132","comment_is_top":false,"comment_ctime":1681721792,"is_pvip":false,"replies":[{"id":136251,"content":"https:&#47;&#47;github.com&#47;jerryjliu&#47;llama_index&#47;blob&#47;main&#47;examples&#47;vector_indices&#47;FaissIndexDemo.ipynb\n\n调用 index 的 save_to_disk 方法就可以了呀\n","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1681794027,"ip_address":"上海","comment_id":372850,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"dimension = 768faiss_index = faiss.IndexFlatIP(dimension)index = index=GPTFaissIndex(nodes=nodes,faiss_index=faiss_index, service_context=service_context)\n\n这个 index  结果怎么保存？ 我折腾2天了都不行，没有save，没index , 老师能告诉我怎么保存吗？","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":614453,"discussion_content":"https://github.com/jerryjliu/llama_index/blob/main/examples/vector_indices/FaissIndexDemo.ipynb\n\n调用 index 的 save_to_disk 方法就可以了呀\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1681794027,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":372425,"user_name":"银河系","can_delete":false,"product_type":"c1","uid":1018079,"ip_address":"广东","ucode":"3BC7FFEDC9F94A","user_header":"https://static001.geekbang.org/account/avatar/00/0f/88/df/e7bf1bdb.jpg","comment_is_top":false,"comment_ctime":1681124707,"is_pvip":false,"replies":[{"id":135949,"content":"报什么错呢？\n\n","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1681142409,"ip_address":"上海","comment_id":372425,"utype":1}],"discussion_count":3,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"openai.api_key = os.environ.get(&quot;OPENAI_API_KEY&quot;)\n\nlogging.basicConfig(stream=sys.stdout, level=logging.INFO)\nlogging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n\n# dimensions of text-ada-embedding-002\nd = 768\nfaiss_index = faiss.IndexFlatL2(d)\ntext_splitter = CharacterTextSplitter(separator=&quot;\\n\\n&quot;, chunk_size=100, chunk_overlap=20)\nparser = SimpleNodeParser(text_splitter=text_splitter)\ndocuments = SimpleDirectoryReader(&#39;.&#47;data&#47;test&#39;).load_data()\nnodes = parser.get_nodes_from_documents(documents)\nllm_predictor = LLMPredictor(llm=ChatOpenAI(temperature=0, model_name=&quot;gpt-3.5-turbo&quot;, max_tokens=1024))\nembed_model = LangchainEmbedding(HuggingFaceEmbeddings(\n        model_name=&quot;sentence-transformers&#47;paraphrase-multilingual-mpnet-base-v2&quot;\n    ))\nservice_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, embed_model=embed_model)\nindex = GPTFaissIndex(nodes=nodes, faiss_index=faiss_index, service_context=service_context)\n# save index to diskIM5最有特色的使用场景\nindex.save_to_disk(\n    &#39;index_faiss.json&#39;,\n    faiss_index_save_path=&quot;index_faiss_core.index&quot;\n)\n\n# load index from disk\nindex = GPTFaissIndex.load_from_disk(&#39;index_faiss.json&#39;,faiss_index_save_path=&quot;index_faiss_core.index&quot;)\nresponse = index.query(&quot;xxxxx&quot;,mode=QueryMode.EMBEDDING,verbose=True)\nprint(response)\n这个代码报错呢","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":613169,"discussion_content":"报什么错呢？\n\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1681142409,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":1018079,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/88/df/e7bf1bdb.jpg","nickname":"银河系","note":"","ucode":"3BC7FFEDC9F94A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":613542,"discussion_content":"测试过了代码，只要自定义embding，保存好了，重新加载，就会报错","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1681384268,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":613169,"ip_address":"广东","group_id":0},"score":613542,"extra":""}]},{"author":{"id":1018079,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/88/df/e7bf1bdb.jpg","nickname":"银河系","note":"","ucode":"3BC7FFEDC9F94A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":613192,"discussion_content":"感谢浩哥百忙回复，我贴出最后三行吧。\n\n  File &#34;/Users/xxxx/miniconda3/envs/chatbot/lib/python3.8/site-packages/llama_index/indices/vector_store/base_query.py&#34;, line 57, in _retrieve\n    query_result = self._vector_store.query(\n  File &#34;/Users/xxxx/miniconda3/envs/chatbot/lib/python3.8/site-packages/llama_index/vector_stores/faiss.py&#34;, line 137, in query\n    dists, indices = self._faiss_index.search(query_embedding_np, similarity_top_k)\n  File &#34;/Users/xxxx/miniconda3/envs/chatbot/lib/python3.8/site-packages/faiss/__init__.py&#34;, line 308, in replacement_search\n    assert d == self.d\nAssertionError","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1681181605,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":372424,"user_name":"银河系","can_delete":false,"product_type":"c1","uid":1018079,"ip_address":"广东","ucode":"3BC7FFEDC9F94A","user_header":"https://static001.geekbang.org/account/avatar/00/0f/88/df/e7bf1bdb.jpg","comment_is_top":false,"comment_ctime":1681124095,"is_pvip":false,"replies":[{"id":135952,"content":"这一讲的Demo里，embedding就是用自己的，也是在本地的，并没有使用云服务呀？\n\n还是我理解错了你的问题？","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1681143216,"ip_address":"上海","comment_id":372424,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"faiss保存在本地而且使用自己的embedding的可否给个demo？","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":613172,"discussion_content":"这一讲的Demo里，embedding就是用自己的，也是在本地的，并没有使用云服务呀？\n\n还是我理解错了你的问题？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1681143216,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":372234,"user_name":"xbc","can_delete":false,"product_type":"c1","uid":2187437,"ip_address":"海南","ucode":"03F1FD7B8CA32F","user_header":"https://static001.geekbang.org/account/avatar/00/21/60/ad/03351e6e.jpg","comment_is_top":false,"comment_ctime":1680862811,"is_pvip":false,"replies":[{"id":135901,"content":"我晚点试一下，我测试过应该是设置了 \nopenai.api_key = &quot;&quot;\n去query触发调用OpenAI是会报错的\n\n不过这个不影响实际的embedding是调用了我们指定的sentence_transfomers的embedding","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1680975371,"ip_address":"日本","comment_id":372234,"utype":1}],"discussion_count":4,"race_medal":0,"score":3,"product_id":100541001,"comment_content":"```\n\nimport openai, os\nimport faiss\nfrom llama_index import SimpleDirectoryReader, LangchainEmbedding, GPTFaissIndex, ServiceContext\nfrom langchain.embeddings.huggingface import HuggingFaceEmbeddings\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom llama_index.node_parser import SimpleNodeParser\n\nopenai.api_key = &quot;&quot;\n\ntext_splitter = CharacterTextSplitter(separator=&quot;\\n\\n&quot;, chunk_size=100, chunk_overlap=20)\nparser = SimpleNodeParser(text_splitter=text_splitter)\ndocuments = SimpleDirectoryReader(&#39;.&#47;data&#47;faq&#47;&#39;).load_data()\nnodes = parser.get_nodes_from_documents(documents)\n\nembed_model = LangchainEmbedding(HuggingFaceEmbeddings(\n    model_name=&quot;sentence-transformers&#47;paraphrase-multilingual-mpnet-base-v2&quot;\n))\nservice_context = ServiceContext.from_defaults(embed_model=embed_model)\n\ndimension = 768\nfaiss_index = faiss.IndexFlatIP(dimension)\nindex = GPTFaissIndex(nodes=nodes,faiss_index=faiss_index, service_context=service_context)\n```\n\n这段代码会报错，老师的环境里面可能有了 env OPENAI_API_KEY.\n\n我这里放的py文件执行：\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)\n\n","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612898,"discussion_content":"我晚点试一下，我测试过应该是设置了 \nopenai.api_key = &#34;&#34;\n去query触发调用OpenAI是会报错的\n\n不过这个不影响实际的embedding是调用了我们指定的sentence_transfomers的embedding","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680975371,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"日本","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2147220,"avatar":"https://static001.geekbang.org/account/avatar/00/20/c3/94/e89ebc50.jpg","nickname":"神毓逍遥","note":"","ucode":"83351CB18B190E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":622074,"discussion_content":"没办法解决么？我看注释了 openai 还是会报错","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1687880668,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1707839,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/0f/3f/8b96cd8a.jpg","nickname":"包子先生","note":"","ucode":"4332DB98492EE2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":614737,"discussion_content":"Traceback (most recent call last):\n  File &#34;/Users/jianbinchen/PycharmProjects/clound/embedding.py&#34;, line 22, in &lt;module&gt;\n    service_context = ServiceContext.from_defaults(embed_model=embed_model)\n  File &#34;/Users/jianbinchen/.local/lib/python3.9/site-packages/llama_index/indices/service_context.py&#34;, line 69, in from_defaults\n    llm_predictor = llm_predictor or LLMPredictor()\n  File &#34;/Users/jianbinchen/.local/lib/python3.9/site-packages/llama_index/llm_predictor/base.py&#34;, line 164, in __init__\n    self._llm = llm or OpenAI(temperature=0, model_name=&#34;text-davinci-003&#34;)\n  File &#34;pydantic/main.py&#34;, line 341, in pydantic.main.BaseModel.__init__\npydantic.error_wrappers.ValidationError: 1 validation error for OpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1681891264,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1707839,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/0f/3f/8b96cd8a.jpg","nickname":"包子先生","note":"","ucode":"4332DB98492EE2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":614736,"discussion_content":"请问这个是怎么解决的，我这边一直运行不了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1681891231,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":372164,"user_name":"Toni","can_delete":false,"product_type":"c1","uid":3206957,"ip_address":"瑞士","ucode":"E6B2FACCC1E000","user_header":"https://static001.geekbang.org/account/avatar/00/30/ef/2d/757bb0d3.jpg","comment_is_top":false,"comment_ctime":1680793255,"is_pvip":false,"replies":[{"id":135862,"content":"👍 单独句子文本的 sentence_transformer的效果还是不错的。可以试着在整个数据集上跑一下看看效果分享一下给大家。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1680972488,"ip_address":"中国香港","comment_id":372164,"utype":1}],"discussion_count":2,"race_medal":0,"score":4,"product_id":100541001,"comment_content":"将第二讲情感分析中的这段代码\n\ngood_restraurant = get_embedding(&quot;这家餐馆太好吃了，一点都不糟糕&quot;)\nbad_restraurant = get_embedding(&quot;这家餐馆太糟糕了，一点都不好吃&quot;)\ngood_score = get_score(good_restraurant)\nbad_score = get_score(bad_restraurant)\nprint(&quot;好评餐馆的评分 : %f&quot; % (good_score))\nprint(&quot;差评餐馆的评分 : %f&quot; % (bad_score))\n\n用sentence_transformers 替代openai.embeddings_utils 又跑了一下\n在选用 model = SentenceTransformer(&#39;paraphrase-multilingual-mpnet-base-v2&#39;) 的情况下\n得到的如下结果\n好评例子的评分 : 0.215761\n差评例子的评分 : -0.361450\n比 openai.embeddings_utils import cosine_similarity, get_embedding\nEMBEDDING_MODEL = &quot;text-embedding-ada-002&quot; 的结果更好些\n好评例子的评分 : 0.062719\n差评例子的评分 : -0.074591","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612857,"discussion_content":"👍 单独句子文本的 sentence_transformer的效果还是不错的。可以试着在整个数据集上跑一下看看效果分享一下给大家。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680972488,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"中国香港","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3206957,"avatar":"https://static001.geekbang.org/account/avatar/00/30/ef/2d/757bb0d3.jpg","nickname":"Toni","note":"","ucode":"E6B2FACCC1E000","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612998,"discussion_content":"明天在大数据集上试试","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1681073898,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"瑞士","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":372162,"user_name":"xbc","can_delete":false,"product_type":"c1","uid":2187437,"ip_address":"海南","ucode":"03F1FD7B8CA32F","user_header":"https://static001.geekbang.org/account/avatar/00/21/60/ad/03351e6e.jpg","comment_is_top":false,"comment_ctime":1680792861,"is_pvip":false,"replies":[{"id":135878,"content":"sentence_transfomers会截断长文本，设2048会丢很多信息，warning只是告诉你部分它没法切到100以内，没关系的。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1680973818,"ip_address":"日本","comment_id":372162,"utype":1}],"discussion_count":1,"race_medal":0,"score":4,"product_id":100541001,"comment_content":"WARNING:root:Created a chunk of size 130, which is longer than the specified 100\n\n一大堆这些，不过可以忽略。\n\n最好改用： text_splitter = SpacyTextSplitter(pipeline=&quot;zh_core_web_sm&quot;, chunk_size = 2048)","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612873,"discussion_content":"sentence_transfomers会截断长文本，设2048会丢很多信息，warning只是告诉你部分它没法切到100以内，没关系的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680973818,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"日本","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":372112,"user_name":"mao","can_delete":false,"product_type":"c1","uid":1114652,"ip_address":"北京","ucode":"C8E0700E9A108A","user_header":"https://static001.geekbang.org/account/avatar/00/11/02/1c/a0aba121.jpg","comment_is_top":false,"comment_ctime":1680749678,"is_pvip":false,"replies":[{"id":135891,"content":"应该是可以的，我还没试过","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1680974569,"ip_address":"日本","comment_id":372112,"utype":1}],"discussion_count":1,"race_medal":0,"score":4,"product_id":100541001,"comment_content":"ChatGLM 是不是可以通过对QA数据集进行微调，得到一个专用的问答模型。","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612887,"discussion_content":"应该是可以的，我还没试过","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680974569,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"日本","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":372106,"user_name":"BashBIGBANG","can_delete":false,"product_type":"c1","uid":1032818,"ip_address":"广东","ucode":"FDC25B00489500","user_header":"https://static001.geekbang.org/account/avatar/00/0f/c2/72/fb00cd31.jpg","comment_is_top":false,"comment_ctime":1680743380,"is_pvip":false,"replies":[{"id":135880,"content":"感谢指出，不过应该暂时不会重录一遍了，重录一遍太费时间了。","user_name":"作者回复","user_name_real":"编辑","uid":1053568,"ctime":1680973902,"ip_address":"日本","comment_id":372106,"utype":1}],"discussion_count":1,"race_medal":0,"score":4,"product_id":100541001,"comment_content":"llama 两个 l 只读一个l 的音","like_count":0,"discussions":[{"author":{"id":1053568,"avatar":"https://static001.geekbang.org/account/avatar/00/10/13/80/8de66543.jpg","nickname":"徐文浩","note":"","ucode":"1D39AC564172E9","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612875,"discussion_content":"感谢指出，不过应该暂时不会重录一遍了，重录一遍太费时间了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1680973902,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"日本","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":376222,"user_name":"Geek_6bdac7","can_delete":false,"product_type":"c1","uid":1503717,"ip_address":"上海","ucode":"E4AAB2DD740050","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eoWZh2ibhHevq5ndQFMK0Z28fO0bFVd3WxslfkHUlX5YPMPhSq0dqyn4F1ozeLcf8wHGfwG6EiaV5Qw/132","comment_is_top":false,"comment_ctime":1686557202,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100541001,"comment_content":"【解决】colab运行模式改为gpu，可以pip安装 pip install faiss-gpu  \n\n\n老师请问下colab上faiss怎么安装，试了不同方法还是在import faiss时导入报错，无faiss模块 \n!wget  https:&#47;&#47;anaconda.org&#47;pytorch&#47;faiss-gpu&#47;1.2.1&#47;download&#47;linux-64&#47;faiss-gpu-1.2.1-py36_cuda9.0.176_1.tar.bz2\n!tar xvjf faiss-gpu-1.2.1-py36_cuda9.0.176_1.tar.bz2\n!cp -r lib&#47;python3.6&#47;site-packages&#47;* &#47;usr&#47;local&#47;lib&#47;python3.6&#47;dist-packages&#47;\n!pip install mkl","like_count":1},{"had_liked":false,"id":373595,"user_name":"aoe","can_delete":false,"product_type":"c1","uid":1121758,"ip_address":"浙江","ucode":"1C6201EDB4E954","user_header":"https://static001.geekbang.org/account/avatar/00/11/1d/de/62bfa83f.jpg","comment_is_top":false,"comment_ctime":1682733836,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100541001,"comment_content":"看完后我还是用显卡玩游戏吧","like_count":1},{"had_liked":false,"id":394475,"user_name":"Geek_78a551","can_delete":false,"product_type":"c1","uid":3784461,"ip_address":"北京","ucode":"CCADD2F766E193","user_header":"","comment_is_top":false,"comment_ctime":1726907434,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100541001,"comment_content":"我把你github上的代码下载下来执行后, 会请求gpt, 跟你说的不符合, 报错信息是api_key错误","like_count":0},{"had_liked":false,"id":394461,"user_name":"Geek_78a551","can_delete":false,"product_type":"c1","uid":3784461,"ip_address":"北京","ucode":"CCADD2F766E193","user_header":"","comment_is_top":false,"comment_ctime":1726847596,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100541001,"comment_content":"更新到llma-index 0.11了, 代码全不能运行","like_count":0},{"had_liked":false,"id":390726,"user_name":"学习中的安老师","can_delete":false,"product_type":"c1","uid":2838153,"ip_address":"广东","ucode":"67DF9E4EC02E03","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/4EspenNOwzy5VI6PiaT5nDbibhGa3utic5UTTv42ib8MCj0lFv83WHtcCfxxiadbp95XpdiafazhmHfYVstmUGKvVBgQ/132","comment_is_top":false,"comment_ctime":1716107030,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100541001,"comment_content":"写的代码一点注释都不写，让人怎么看","like_count":0},{"had_liked":false,"id":389564,"user_name":"Geek_a38da8","can_delete":false,"product_type":"c1","uid":2437521,"ip_address":"北京","ucode":"E03AB3067312B0","user_header":"","comment_is_top":false,"comment_ctime":1712891217,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100541001,"comment_content":"from transformers import AutoTokenizer, AutoModel\ntokenizer = AutoTokenizer.from_pretrained(&quot;THUDM&#47;chatglm-6b-int4&quot;, trust_remote_code=True)\nmodel = AutoModel.from_pretrained(&quot;THUDM&#47;chatglm-6b-int4&quot;,trust_remote_code=True).float()\nmodel = model.eval()直接pip install transformers，下载当前最新版本报AttributeError: &#39;ChatGLMTokenizer&#39; object has no attribute &#39;sp_tokenizer&#39;，重新安装transformers 4.33.1即可","like_count":0},{"had_liked":false,"id":389563,"user_name":"Geek_a38da8","can_delete":false,"product_type":"c1","uid":2437521,"ip_address":"北京","ucode":"E03AB3067312B0","user_header":"","comment_is_top":false,"comment_ctime":1712891111,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100541001,"comment_content":"from transformers import AutoTokenizer, AutoModel\ntokenizer = AutoTokenizer.from_pretrained(&quot;THUDM&#47;chatglm-6b-int4&quot;, trust_remote_code=True)\nmodel = AutoModel.from_pretrained(&quot;THUDM&#47;chatglm-6b-int4&quot;,trust_remote_code=True).float()\nmodel = model.eval()","like_count":0},{"had_liked":false,"id":388860,"user_name":"茂松","can_delete":false,"product_type":"c1","uid":1052375,"ip_address":"广东","ucode":"458A6FBC49C48E","user_header":"https://static001.geekbang.org/account/avatar/00/10/0e/d7/7d7579c1.jpg","comment_is_top":false,"comment_ctime":1711013534,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100541001,"comment_content":"运行下面这段代码时报错  AttributeError: module &#39;openai&#39; has no attribute &#39;error&#39;\n\nfrom llama_index import QuestionAnswerPrompt\nfrom llama_index import QueryMode\nQA_PROMPT_TMPL = ( &quot;{context_str}&quot; &quot;\\n\\n&quot; &quot;根据以上信息，请回答下面的问题：\\n&quot; &quot;Q: {query_str}\\n&quot; )QA_PROMPT = QuestionAnswerPrompt(QA_PROMPT_TMPL)response = index.query( &quot;请问你们海南能发货吗？&quot;, mode=QueryMode.EMBEDDING, text_qa_template=QA_PROMPT, verbose=True, )print(response)","like_count":0},{"had_liked":false,"id":380552,"user_name":"Geek_731528","can_delete":false,"product_type":"c1","uid":3179207,"ip_address":"浙江","ucode":"75F5EF7EBB7BFB","user_header":"","comment_is_top":false,"comment_ctime":1693812385,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100541001,"comment_content":"KeyError                                  Traceback (most recent call last)\nCell In[13], line 12\n      4 QA_PROMPT_TMPL = (\n      5     &quot;{context_str}&quot;\n      6     &quot;\\n\\n&quot;\n      7     &quot;根据以上信息，请回答下面的问题：\\n&quot;\n      8     &quot;Q: {query_str}\\n&quot;\n      9     )\n     10 QA_PROMPT = QuestionAnswerPrompt(QA_PROMPT_TMPL)\n---&gt; 12 response = index.query(\n     13     &quot;请问你们海南能发货吗？&quot;, \n     14     mode=QueryMode.EMBEDDING,\n     15     text_qa_template=QA_PROMPT,\n     16     verbose=True, \n     17 )\n\nKeyError: &#39;-1&#39;\n\n请问老这个错误是什么意思","like_count":0},{"had_liked":false,"id":379139,"user_name":"小理想。","can_delete":false,"product_type":"c1","uid":2238528,"ip_address":"北京","ucode":"EDC35A907570DB","user_header":"https://static001.geekbang.org/account/avatar/00/22/28/40/82d748e6.jpg","comment_is_top":false,"comment_ctime":1691402914,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100541001,"comment_content":"老师想问一下，执行咱们这个课程第一个示例，还是要了openai的key，不填上一直报错，填上key就没问题了，执行完了，这是怎么回事，就是如下代码？\nimport openai, os\nimport faiss\nfrom llama_index import SimpleDirectoryReader, LangchainEmbedding, GPTFaissIndex, ServiceContext\nfrom langchain.embeddings.huggingface import HuggingFaceEmbeddings\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom llama_index.node_parser import SimpleNodeParser\n\nopenai.api_key = &quot;&quot;\n\ntext_splitter = CharacterTextSplitter(separator=&quot;\\n\\n&quot;, chunk_size=100, chunk_overlap=20)\nparser = SimpleNodeParser(text_splitter=text_splitter)\ndocuments = SimpleDirectoryReader(&#39;.&#47;data&#47;faq&#47;&#39;).load_data()\nnodes = parser.get_nodes_from_documents(documents)\n\nembed_model = LangchainEmbedding(HuggingFaceEmbeddings(\n    model_name=&quot;sentence-transformers&#47;paraphrase-multilingual-mpnet-base-v2&quot;\n))\nservice_context = ServiceContext.from_defaults(embed_model=embed_model)\n\ndimension = 768\nfaiss_index = faiss.IndexFlatIP(dimension)\nindex = GPTFaissIndex(nodes=nodes,faiss_index=faiss_index, service_context=service_context)\n报错如下：还是要了openai的key，不填上一直报错\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)","like_count":0},{"had_liked":false,"id":378241,"user_name":"BIN","can_delete":false,"product_type":"c1","uid":1105397,"ip_address":"上海","ucode":"0ACB97396577B9","user_header":"https://static001.geekbang.org/account/avatar/00/10/dd/f5/7c88efce.jpg","comment_is_top":false,"comment_ctime":1689931492,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100541001,"comment_content":"如何计算模型的FLOPs值","like_count":0},{"had_liked":false,"id":378240,"user_name":"BIN","can_delete":false,"product_type":"c1","uid":1105397,"ip_address":"上海","ucode":"0ACB97396577B9","user_header":"https://static001.geekbang.org/account/avatar/00/10/dd/f5/7c88efce.jpg","comment_is_top":false,"comment_ctime":1689931259,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100541001,"comment_content":"请教一个问题：算力的成本如何计算？影响的因素有哪些？目前能想到可能的因素是模型的参数量、推理请求的并发数、推理响应时间、输入和输出长度；具体应该如何评估购买什么配置的GPU呢？望老师指点下，谢谢","like_count":0},{"had_liked":false,"id":377435,"user_name":"RCPatton","can_delete":false,"product_type":"c1","uid":2267708,"ip_address":"山西","ucode":"F6D9D39516D841","user_header":"https://static001.geekbang.org/account/avatar/00/22/9a/3c/ab32ff62.jpg","comment_is_top":false,"comment_ctime":1688484881,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100541001,"comment_content":"好消息，chatglm可以直接通过API调用了！！","like_count":0},{"had_liked":false,"id":376986,"user_name":"神毓逍遥","can_delete":false,"product_type":"c1","uid":2147220,"ip_address":"上海","ucode":"83351CB18B190E","user_header":"https://static001.geekbang.org/account/avatar/00/20/c3/94/e89ebc50.jpg","comment_is_top":false,"comment_ctime":1687791159,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100541001,"comment_content":"大赞","like_count":0},{"had_liked":false,"id":376693,"user_name":"呼呼","can_delete":false,"product_type":"c1","uid":1038798,"ip_address":"四川","ucode":"5D7B57C05B5D8C","user_header":"https://static001.geekbang.org/account/avatar/00/0f/d9/ce/4528cb4b.jpg","comment_is_top":false,"comment_ctime":1687233561,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100541001,"comment_content":"同样的代码，chatglm，问题4，回答我：根据提供的信息，可以配送到哈尔滨。","like_count":0},{"had_liked":false,"id":376472,"user_name":"Penguin Shi","can_delete":false,"product_type":"c1","uid":3646806,"ip_address":"广东","ucode":"477A24D7ECE09A","user_header":"https://static001.geekbang.org/account/avatar/00/37/a5/56/b3cf71a9.jpg","comment_is_top":false,"comment_ctime":1686834046,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100541001,"comment_content":"徐老师，我现在想用AI或者开源模型，实现自有文本数据的挖掘。想请教一下，我应该用哪个模型和具体的哪个库。我们公司数据库里有很多销售和客户的聊天文本，是客户每次到店的聊天记录。我想通过这些文本，提取关键词，或者统计词频，找出整个公司客户的客户画像（您看是用词频好，还是关键词好）。而针对每个客户，我想把她过往的聊天记录，提取摘要或者关键词，方便销售快速回忆起客户的特点。我现在用jiaba统计了词频和关键词，跟用chatGPT3.5聊天提取的关键词，差别还是很大。我用openAI的API，调用003,结果没有提取出关键词和摘要，不知道是不是这个库不适用于中文。我刚开始接触python和AI，请老师赐教。","like_count":0},{"had_liked":false,"id":372165,"user_name":"Ethan New","can_delete":false,"product_type":"c1","uid":2063962,"ip_address":"浙江","ucode":"9CA2EF39E58030","user_header":"https://static001.geekbang.org/account/avatar/00/1f/7e/5a/da39f489.jpg","comment_is_top":false,"comment_ctime":1680793331,"is_pvip":true,"replies":null,"discussion_count":0,"race_medal":4,"score":6,"product_id":100541001,"comment_content":"学习打卡","like_count":0},{"had_liked":false,"id":372128,"user_name":"John","can_delete":false,"product_type":"c1","uid":1020861,"ip_address":"加拿大","ucode":"E4ADF8488953FB","user_header":"https://static001.geekbang.org/account/avatar/00/0f/93/bd/f3977ebb.jpg","comment_is_top":false,"comment_ctime":1680768066,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":6,"product_id":100541001,"comment_content":"那俩模型没看到说token数量呀? 想一想GPT4-32K 不禁唏嘘","like_count":0},{"had_liked":false,"id":372108,"user_name":"Viktor","can_delete":false,"product_type":"c1","uid":1520703,"ip_address":"四川","ucode":"DCAFD1DD5C6A0C","user_header":"https://static001.geekbang.org/account/avatar/00/17/34/3f/4b6cd370.jpg","comment_is_top":false,"comment_ctime":1680743675,"is_pvip":false,"replies":null,"discussion_count":2,"race_medal":0,"score":6,"product_id":100541001,"comment_content":"对于我们这些非算法工程师的同学来说，使用第三方开源模型很难做出一个较好的效果。而且遇到模型问题，也没有办法进行调优。所以还是比较倾向于像ChatGPT这样的产物。","like_count":0,"discussions":[{"author":{"id":1338098,"avatar":"https://static001.geekbang.org/account/avatar/00/14/6a/f2/db90fa96.jpg","nickname":"Oli张帆","note":"","ucode":"6E60A370C3C14A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":612581,"discussion_content":"对的对的，不过知道有其他选择，还是不错。不过我估计OpenAI的成本下降速度应该也会遵循摩尔定律吧。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1680790823,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1222233,"avatar":"https://static001.geekbang.org/account/avatar/00/12/a6/59/1689ea0c.jpg","nickname":"金hb.Ryan 冷空氣駕到","note":"","ucode":"CAD363576696E4","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":618861,"discussion_content":"对哦，规模化之前没必要上三方，或者就本地玩玩","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1684657726,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}