{"id":81844,"title":"41 | 实战MNIST Softmax网络（下）","content":"<h2>课件及源码下载地址：</h2><p><a href=\"https://gitee.com/geektime-geekbang/tensorflow-101/tree/master/beginners\">https://gitee.com/geektime-geekbang/tensorflow-101/tree/master/beginners</a></p>","comments":[{"had_liked":false,"id":71773,"user_name":"calmer","can_delete":false,"product_type":"c3","uid":1285297,"ip_address":"","ucode":"F6D0DB0992A1AB","user_header":"https://static001.geekbang.org/account/avatar/00/13/9c/b1/00b1a416.jpg","comment_is_top":false,"comment_ctime":1551429865,"is_pvip":false,"replies":[{"id":26632,"content":"2个隐藏层是考虑到识别任务的难度和数据量多少。\n512是经验数值，也可以用 256或者128。大家在很多论文中看到对于这类超参数的选择，通常都是基于某个数据集上，根据性能表现最终选择了某个值。\n相比 sigmoid 和 tanh，使用relu 激活函数计算速度更快，也是大家现在常用的激活函数。","user_name":"作者回复","user_name_real":"彭靖田","uid":1067283,"ctime":1551846990,"ip_address":"","comment_id":71773,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100023001,"comment_content":"没讲为什么2个隐藏层，每个隐藏层的神经元是512个，为什么用relu激活函数","like_count":1,"discussions":[{"author":{"id":1067283,"avatar":"https://static001.geekbang.org/account/avatar/00/10/49/13/51b1fe81.jpg","nickname":"彭靖田","note":"","ucode":"D3F1C281F38390","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":441324,"discussion_content":"2个隐藏层是考虑到识别任务的难度和数据量多少。\n512是经验数值，也可以用 256或者128。大家在很多论文中看到对于这类超参数的选择，通常都是基于某个数据集上，根据性能表现最终选择了某个值。\n相比 sigmoid 和 tanh，使用relu 激活函数计算速度更快，也是大家现在常用的激活函数。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1551846990,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":82938,"user_name":"Geek_f57db5","can_delete":false,"product_type":"c3","uid":1359491,"ip_address":"","ucode":"08AC35F0B4B2B8","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erxia5dpTeXMHQjIMLDUNLk2jKosibARWdgwsDFicX24SFaLe6iaGJicvGXP17sDkEvaaYtmRd5kPCBsyw/132","comment_is_top":false,"comment_ctime":1554352320,"is_pvip":false,"replies":[{"id":36090,"content":"对呀，横坐标为0时就是第1个epoch训练完的结果。\n因为训练数据也有标签呀。","user_name":"作者回复","user_name_real":"彭靖田","uid":1067283,"ctime":1559538221,"ip_address":"","comment_id":82938,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100023001,"comment_content":"彭老师，您在解释训练过程中第一轮val_acc比acc高的时候出现了一处问题：通过对比数据可以发现，横坐标0实际上对应着第1轮训练完成后的结果（因为横坐标的范围是0到4，同时纵坐标的值也可以佐证），所以横坐标为0时，val_acc和acc不都应该是第一轮训练结果之后的值吗。同时，有个问题想要请教：为什么训练数据也会有准确率（acc）？这个准确率（acc）是怎么算出来的？","like_count":0,"discussions":[{"author":{"id":1067283,"avatar":"https://static001.geekbang.org/account/avatar/00/10/49/13/51b1fe81.jpg","nickname":"彭靖田","note":"","ucode":"D3F1C281F38390","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":445787,"discussion_content":"对呀，横坐标为0时就是第1个epoch训练完的结果。\n因为训练数据也有标签呀。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1559538221,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":82107,"user_name":"索菲","can_delete":false,"product_type":"c3","uid":1370800,"ip_address":"","ucode":"3624D1304C4C34","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLVibd2dnILTz1UYPJKcUf0OvpY3JaZm5WwxqVeXfuju1gPhHotJUcjXD3krSD6451Wgq1w37urpwA/132","comment_is_top":false,"comment_ctime":1554121179,"is_pvip":false,"replies":[{"id":36062,"content":"👍👍","user_name":"作者回复","user_name_real":"彭靖田","uid":1067283,"ctime":1559534197,"ip_address":"","comment_id":82107,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100023001,"comment_content":"彭老师，我好像找到原因了，模型参数的问题，我应该是开始训练的时候，模型参数没有清除。我把输出都清除之后，从头开始训练就差不多。","like_count":0,"discussions":[{"author":{"id":1067283,"avatar":"https://static001.geekbang.org/account/avatar/00/10/49/13/51b1fe81.jpg","nickname":"彭靖田","note":"","ucode":"D3F1C281F38390","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":445470,"discussion_content":"👍👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1559534197,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":79695,"user_name":"1","can_delete":false,"product_type":"c3","uid":1370892,"ip_address":"","ucode":"BFED958955C1A3","user_header":"https://static001.geekbang.org/account/avatar/00/14/eb/0c/9ea7491c.jpg","comment_is_top":false,"comment_ctime":1553522230,"is_pvip":false,"replies":[{"id":36066,"content":"因为在训练时，我们梯度下降的情况或许会有不同，所以不会输出完全一样的 loss 和 acc 哈。但是最终收敛的结果差距很小。","user_name":"作者回复","user_name_real":"彭靖田","uid":1067283,"ctime":1559534980,"ip_address":"","comment_id":79695,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100023001,"comment_content":"我的训练的时候的耗时和loss的值以及准确率怎么跑出来的结果和您的不一样呢\nTrain on 60000 samples, validate on 10000 samples\nEpoch 1&#47;5\n - 10s - loss: 0.1820 - acc: 0.9474 - val_loss: 1.1927 - val_acc: 0.9260\nEpoch 2&#47;5\n - 9s - loss: 0.1601 - acc: 0.9524 - val_loss: 0.9594 - val_acc: 0.9404\nEpoch 3&#47;5\n - 9s - loss: 0.1408 - acc: 0.9582 - val_loss: 0.9494 - val_acc: 0.9411\nEpoch 4&#47;5\n - 10s - loss: 0.1234 - acc: 0.9637 - val_loss: 0.9348 - val_acc: 0.9420\nEpoch 5&#47;5\n - 10s - loss: 0.1086 - acc: 0.9678 - val_loss: 0.9655 - val_acc: 0.9401","like_count":0,"discussions":[{"author":{"id":1067283,"avatar":"https://static001.geekbang.org/account/avatar/00/10/49/13/51b1fe81.jpg","nickname":"彭靖田","note":"","ucode":"D3F1C281F38390","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":444585,"discussion_content":"因为在训练时，我们梯度下降的情况或许会有不同，所以不会输出完全一样的 loss 和 acc 哈。但是最终收敛的结果差距很小。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1559534980,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":74473,"user_name":"白鹤之盾","can_delete":false,"product_type":"c3","uid":1385054,"ip_address":"","ucode":"4D2DEFAF48DB17","user_header":"https://static001.geekbang.org/account/avatar/00/15/22/5e/50d4a354.jpg","comment_is_top":false,"comment_ctime":1552228338,"is_pvip":false,"replies":[{"id":36091,"content":"因为右边的结果是 (numpy.array)的形式，[0] 就可以取出 tuple 中的 numpy.array.","user_name":"作者回复","user_name_real":"彭靖田","uid":1067283,"ctime":1559538519,"ip_address":"","comment_id":74473,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100023001,"comment_content":"correct_indices = np.nonzero(predicted_classes == y_test)[0]  这为什么要加一个[0]？javascript:;","like_count":0,"discussions":[{"author":{"id":1067283,"avatar":"https://static001.geekbang.org/account/avatar/00/10/49/13/51b1fe81.jpg","nickname":"彭靖田","note":"","ucode":"D3F1C281F38390","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":442580,"discussion_content":"因为右边的结果是 (numpy.array)的形式，[0] 就可以取出 tuple 中的 numpy.array.","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1559538519,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":72319,"user_name":"王健","can_delete":false,"product_type":"c3","uid":1146674,"ip_address":"","ucode":"8E999AB61E62EA","user_header":"https://static001.geekbang.org/account/avatar/00/11/7f/32/422429f9.jpg","comment_is_top":false,"comment_ctime":1551585168,"is_pvip":false,"replies":[{"id":26626,"content":"因为大部分学员建议用高层次 API。入门的话，Keras 更好上手，也是大部分AI用户的选择。TF 低层次 API 讲起来比较复杂，并且最近大量都 depreacated。等 2.0 出来了，可以基于 TensorFlow Eager 跟大家讲讲动态图","user_name":"作者回复","user_name_real":"彭靖田","uid":1067283,"ctime":1551846401,"ip_address":"","comment_id":72319,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100023001,"comment_content":"老师,  这个例子里面, 用的keras , 这个算是tensorflow吗,  为啥不用ts呢,  不是keras能做的ts不都能做吗 , 不是面向ts实战吗","like_count":0,"discussions":[{"author":{"id":1067283,"avatar":"https://static001.geekbang.org/account/avatar/00/10/49/13/51b1fe81.jpg","nickname":"彭靖田","note":"","ucode":"D3F1C281F38390","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":441541,"discussion_content":"因为大部分学员建议用高层次 API。入门的话，Keras 更好上手，也是大部分AI用户的选择。TF 低层次 API 讲起来比较复杂，并且最近大量都 depreacated。等 2.0 出来了，可以基于 TensorFlow Eager 跟大家讲讲动态图","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1551846401,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":70440,"user_name":"EthanLifeGreat","can_delete":false,"product_type":"c3","uid":1387496,"ip_address":"","ucode":"5470768FAC7E8F","user_header":"https://static001.geekbang.org/account/avatar/00/15/2b/e8/04416725.jpg","comment_is_top":false,"comment_ctime":1551098303,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100023001,"comment_content":"# 绘制错误的手写体数字，其中A为正确标签\nfig = plt.figure()\nfor i in range(15):\n    plt.subplot(3,5,i+1) # 绘制前 15 个手写体，以 3 行 5 列子图形式展示\n    plt.tight_layout()   # 自适应子图尺寸\n    plt.imshow(x_test[incorrect_indices[i]], cmap=&#39;Greys&#39;) \n    plt.title(&quot;{}    A:{}&quot;.format(predicted_classes[incorrect_indices[i]],y_test[incorrect_indices[i]])) # 设置对应标签为子图标题\n    plt.xticks([]) # 删除 x 轴标记\n    plt.yticks([]) # 删除 y 轴标记\n ","like_count":4},{"had_liked":false,"id":268093,"user_name":"不接地气的马三岁","can_delete":false,"product_type":"c3","uid":1455741,"ip_address":"","ucode":"9146DED62DF724","user_header":"https://static001.geekbang.org/account/avatar/00/16/36/7d/96f0457e.jpg","comment_is_top":false,"comment_ctime":1608051232,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100023001,"comment_content":"怎么讲着讲着变成keras了，现在国内很多一线互联网公司还是tf1.10-15","like_count":0}]}