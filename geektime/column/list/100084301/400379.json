{"id":400379,"title":"03 | 如何实现一个性能优异的Hash表？","content":"<p>你好，我是蒋德钧。今天，我们来聊聊Redis中的Hash。</p><p>我们知道，Hash表是一种非常关键的数据结构，在计算机系统中发挥着重要作用。比如在Memcached中，Hash表被用来索引数据；在数据库系统中，Hash表被用来辅助SQL查询。而对于Redis键值数据库来说，Hash表既是键值对中的一种值类型，同时，Redis也使用一个全局Hash表来保存所有的键值对，从而既满足应用存取Hash结构数据需求，又能提供快速查询功能。</p><p>那么，Hash表应用如此广泛的一个重要原因，就是从理论上来说，它能以O(1)的复杂度快速查询数据。Hash表通过Hash函数的计算，就能定位数据在表中的位置，紧接着可以对数据进行操作，这就使得数据操作非常快速。</p><p>Hash表这个结构也并不难理解，但是在实际应用Hash表时，当数据量不断增加，它的性能就经常会受到<strong>哈希冲突</strong>和<strong>rehash开销</strong>的影响。而这两个问题的核心，其实都来自于Hash表要保存的数据量，超过了当前Hash表能容纳的数据量。</p><p>那么要如何应对这两个问题呢？事实上，这也是在大厂面试中，面试官经常会考核的问题。所以你现在可以先想想，如果你在面试中遇到了这两个问题，你会怎么回答呢？</p><!-- [[[read_end]]] --><p>OK，思考先到这里，现在我来告诉你Redis是怎么很好地解决这两个问题的。</p><p>Redis为我们提供了一个经典的Hash表实现方案。针对哈希冲突，Redis采用了<strong>链式哈希</strong>，在不扩容哈希表的前提下，将具有相同哈希值的数据链接起来，以便这些数据在表中仍然可以被查询到；对于rehash开销，Redis实现了<strong>渐进式rehash设计</strong>，进而缓解了rehash操作带来的额外开销对系统的性能影响。</p><p>所以这节课，我就带你来学习Redis中针对Hash表的设计思路和实现方法，帮助你掌握应对哈希冲突和优化rehash操作性能的能力，并以此支撑你在实际使用Hash表保存大量数据的场景中，可以实现高性能的Hash表。</p><p>好了，接下来，我们就先来聊聊链式哈希的设计与实现。</p><h2>Redis如何实现链式哈希？</h2><p>不过，在开始学习链式哈希的设计实现之前，我们还需要明白Redis中Hash表的结构设计是啥样的，以及为何会在数据量增加时产生哈希冲突，这样也更容易帮助我们理解链式哈希应对哈希冲突的解决思路。</p><h3>什么是哈希冲突？</h3><p>实际上，一个最简单的Hash表就是一个数组，数组里的每个元素是一个哈希桶（也叫做Bucket），第一个数组元素被编为哈希桶0，以此类推。当一个键值对的键经过Hash函数计算后，再对数组元素个数取模，就能得到该键值对对应的数组元素位置，也就是第几个哈希桶。</p><p>如下图所示，key1经过哈希计算和哈希值取模后，就对应哈希桶1，类似的，key3和key16分别对应哈希桶7和桶4。</p><p><img src=\"https://static001.geekbang.org/resource/image/08/2f/08ac157a8fbf4d22f8a5217bfea79a2f.jpg?wh=2000x1029\" alt=\"\"></p><p>从图上我们还可以看到，需要写入Hash表的键空间一共有16个键，而Hash表的空间大小只有8个元素，这样就会导致有些键会对应到相同的哈希桶中。</p><p>我们在实际应用Hash表时，其实一般很难预估要保存的数据量，如果我们一开始就创建一个非常大的哈希表，当数据量较小时，就会造成空间浪费。所以，我们通常会给哈希表设定一个初始大小，而当数据量增加时，键空间的大小就会大于Hash表空间大小了。</p><p>也正是由于键空间会大于Hash表空间，这就导致在用Hash函数把键映射到Hash表空间时，不可避免地会出现不同的键被映射到数组的同一个位置上。而如果同一个位置只能保存一个键值对，就会导致Hash表保存的数据非常有限，这就是我们常说的<strong>哈希冲突</strong>。</p><p>比如下图中，key3和key100都被映射到了Hash表的桶5中，这样，当桶5只能保存一个key时，key3和key100就会有一个key无法保存到哈希表中了。</p><p><img src=\"https://static001.geekbang.org/resource/image/04/d8/04322775d11cea97049bcd4dd8109bd8.jpg?wh=2000x889\" alt=\"\"></p><p>那么我们该如何解决哈希冲突呢？可以考虑使用以下两种解决方案：</p><ul>\n<li>第一种方案，就是我接下来要给你介绍的<strong>链式哈希</strong>。这里你需要先知道，链式哈希的链不能太长，否则会降低Hash表性能。</li>\n<li>第二种方案，就是当链式哈希的链长达到一定长度时，我们可以使用<strong>rehash</strong>。不过，执行rehash本身开销比较大，所以就需要采用我稍后会给你介绍的渐进式rehash设计。</li>\n</ul><p>这里，我们先来了解链式哈希的设计和实现。</p><h3>链式哈希如何设计与实现？</h3><p>所谓的链式哈希，就是<strong>用一个链表把映射到Hash表同一桶中的键给连接起来</strong>。下面我们就来看看Redis是如何实现链式哈希的，以及为何链式哈希能够帮助解决哈希冲突。</p><p>首先，我们需要了解Redis源码中对Hash表的实现。Redis中和Hash表实现相关的文件主要是<strong>dict.h</strong>和<strong>dict.c</strong>。其中，dict.h文件定义了Hash表的结构、哈希项，以及Hash表的各种操作函数，而dict.c文件包含了Hash表各种操作的具体实现代码。</p><p>在dict.h文件中，Hash表被定义为一个二维数组（dictEntry **table），这个数组的每个元素是一个指向哈希项（dictEntry）的指针。下面的代码展示的就是在dict.h文件中对Hash表的定义，你可以看下：</p><pre><code>typedef struct dictht {\n    dictEntry **table; //二维数组\n    unsigned long size; //Hash表大小\n    unsigned long sizemask;\n    unsigned long used;\n} dictht;\n</code></pre><p>那么为了实现链式哈希， Redis在每个dictEntry的结构设计中，<strong>除了包含指向键和值的指针，还包含了指向下一个哈希项的指针</strong>。如下面的代码所示，dictEntry结构体中包含了指向另一个dictEntry结构的<strong>指针*next</strong>，这就是用来实现链式哈希的：</p><pre><code>typedef struct dictEntry {\n    void *key;\n    union {\n        void *val;\n        uint64_t u64;\n        int64_t s64;\n        double d;\n    } v;\n    struct dictEntry *next;\n} dictEntry;\n</code></pre><p>除了用于实现链式哈希的指针外，这里还有一个值得注意的地方，就是在dictEntry结构体中，键值对的值是由一个<strong>联合体v</strong>定义的。这个联合体v中包含了指向实际值的指针*val，还包含了无符号的64位整数、有符号的64位整数，以及double类的值。</p><p>我之所以要提醒你注意这里，其实是为了说明，<strong>这种实现方法是一种节省内存的开发小技巧</strong>，非常值得学习。因为当值为整数或双精度浮点数时，由于其本身就是64位，就可以不用指针指向了，而是可以直接存在键值对的结构体中，这样就避免了再用一个指针，从而节省了内存空间。</p><p>好了，那么到这里，你应该就了解了Redis中链式哈希的实现，不过现在你可能还是不太明白，为什么这种链式哈希可以帮助解决哈希冲突呢？</p><p>别着急，我就拿刚才的例子来说明一下，key3和key100都被映射到了Hash表的桶5中。而当使用了链式哈希，桶5就不会只保存key3或key100，而是会用一个链表把key3和key100连接起来，如下图所示。当有更多的key被映射到桶5时，这些key都可以用链表串接起来，以应对哈希冲突。</p><p><img src=\"https://static001.geekbang.org/resource/image/28/85/281919546bb9cf97cd70718072389585.jpg?wh=2000x866\" alt=\"\"></p><p>这样，当我们要查询key100时，可以先通过哈希函数计算，得到key100的哈希值被映射到了桶5中。然后，我们再逐一比较桶5中串接的key，直到查找到key100。如此一来，我们就能在链式哈希中找到所查的哈希项了。</p><p>不过，链式哈希也存在局限性，那就是随着链表长度的增加，Hash表在一个位置上查询哈希项的耗时就会增加，从而增加了Hash表的整体查询时间，这样也会导致Hash表的性能下降。</p><p>那么，有没有什么其他的方法可以减少对Hash表性能的影响呢？当然是有的，这就是接下来我要给你介绍的rehash的设计与实现了。</p><h2>Redis如何实现rehash？</h2><p>rehash操作，其实就是指扩大Hash表空间。而Redis实现rehash的基本思路是这样的：</p><ul>\n<li>首先，Redis准备了两个哈希表，用于rehash时交替保存数据。</li>\n</ul><p>我在前面给你介绍过，Redis在dict.h文件中使用dictht结构体定义了Hash表。不过，在实际使用Hash表时，Redis又在dict.h文件中，定义了一个dict结构体。这个结构体中有一个数组（ht[2]），包含了两个Hash表ht[0]和ht[1]。dict结构体的代码定义如下所示：</p><pre><code>typedef struct dict {\n    …\n    dictht ht[2]; //两个Hash表，交替使用，用于rehash操作\n    long rehashidx; //Hash表是否在进行rehash的标识，-1表示没有进行rehash\n    …\n} dict;\n</code></pre><ul>\n<li>其次，在正常服务请求阶段，所有的键值对写入哈希表ht[0]。</li>\n<li>接着，当进行rehash时，键值对被迁移到哈希表ht[1]中。</li>\n<li>最后，当迁移完成后，ht[0]的空间会被释放，并把ht[1]的地址赋值给ht[0]，ht[1]的表大小设置为0。这样一来，又回到了正常服务请求的阶段，ht[0]接收和服务请求，ht[1]作为下一次rehash时的迁移表。</li>\n</ul><p>这里我画了一张图，以便于你理解ht[0]和ht[1]交替使用的过程。</p><p><img src=\"https://static001.geekbang.org/resource/image/1b/7f/1bc5b729yy127de43e0548ce0b6e6c7f.jpg?wh=2000x1125\" alt=\"\"></p><p>好，那么在了解了Redis交替使用两个Hash表实现rehash的基本思路后，我们还需要明确的是：在实现rehash时，都需要解决哪些问题？我认为主要有以下三点：</p><ul>\n<li>什么时候触发rehash？</li>\n<li>rehash扩容扩多大？</li>\n<li>rehash如何执行？</li>\n</ul><p>所以下面，我就带你来逐一学习Redis对这三个问题的代码实现，通过代码实现，你就能明晰Redis针对这三个问题的设计思想了。</p><h3>什么时候触发rehash？</h3><p>首先要知道，Redis用来判断是否触发rehash的函数是<strong> _dictExpandIfNeeded</strong>。所以接下来我们就先看看，_dictExpandIfNeeded函数中进行扩容的触发条件；然后，我们再来了解下_dictExpandIfNeeded又是在哪些函数中被调用的。</p><p>实际上，_dictExpandIfNeeded函数中定义了三个扩容条件。</p><ul>\n<li>条件一：ht[0]的大小为0。</li>\n<li>条件二：ht[0]承载的元素个数已经超过了ht[0]的大小，同时Hash表可以进行扩容。</li>\n<li>条件三：ht[0]承载的元素个数，是ht[0]的大小的dict_force_resize_ratio倍，其中，dict_force_resize_ratio的默认值是5。</li>\n</ul><p>下面的代码就展示了_dictExpandIfNeeded函数对这三个条件的定义，你可以看下。</p><pre><code>//如果Hash表为空，将Hash表扩为初始大小\nif (d-&gt;ht[0].size == 0) \n   return dictExpand(d, DICT_HT_INITIAL_SIZE);\n \n//如果Hash表承载的元素个数超过其当前大小，并且可以进行扩容，或者Hash表承载的元素个数已是当前大小的5倍\nif (d-&gt;ht[0].used &gt;= d-&gt;ht[0].size &amp;&amp;(dict_can_resize ||\n              d-&gt;ht[0].used/d-&gt;ht[0].size &gt; dict_force_resize_ratio))\n{\n    return dictExpand(d, d-&gt;ht[0].used*2);\n}\n</code></pre><p>那么，对于条件一来说，此时Hash表是空的，所以Redis就需要将Hash表空间设置为初始大小，而这是初始化的工作，并不属于rehash操作。</p><p>而条件二和三就对应了rehash的场景。因为在这两个条件中，都比较了Hash表当前承载的元素个数（d-&gt;ht[0].used）和Hash表当前设定的大小（d-&gt;ht[0].size），这两个值的比值一般称为<strong>负载因子（load factor）</strong>。也就是说，Redis判断是否进行rehash的条件，就是看load factor是否大于等于1和是否大于5。</p><p>实际上，当load factor大于5时，就表明Hash表已经过载比较严重了，需要立刻进行库扩容。而当load factor大于等于1时，Redis还会再判断dict_can_resize这个变量值，查看当前是否可以进行扩容。</p><p>你可能要问了，这里的dict_can_resize变量值是啥呀？其实，这个变量值是在dictEnableResize和dictDisableResize两个函数中设置的，它们的作用分别是启用和禁止哈希表执行rehash功能，如下所示：</p><pre><code>void dictEnableResize(void) {\n    dict_can_resize = 1;\n}\n \nvoid dictDisableResize(void) {\n    dict_can_resize = 0;\n}\n</code></pre><p>然后，这两个函数又被封装在了updateDictResizePolicy函数中。</p><p>updateDictResizePolicy函数是用来启用或禁用rehash扩容功能的，这个函数调用dictEnableResize函数启用扩容功能的条件是：<strong>当前没有RDB子进程，并且也没有AOF子进程。</strong>这就对应了Redis没有执行RDB快照和没有进行AOF重写的场景。你可以参考下面给出的代码：</p><pre><code>void updateDictResizePolicy(void) {\n    if (server.rdb_child_pid == -1 &amp;&amp; server.aof_child_pid == -1)\n        dictEnableResize();\n    else\n        dictDisableResize();\n}\n</code></pre><p>好，到这里我们就了解了_dictExpandIfNeeded对rehash的判断触发条件，那么现在，我们再来看下Redis会在哪些函数中，调用_dictExpandIfNeeded进行判断。</p><p>首先，通过在<a href=\"https://github.com/redis/redis/blob/5.0/src/dict.c\">dict.c</a>文件中查看_dictExpandIfNeeded的被调用关系，我们可以发现，_dictExpandIfNeeded是被_dictKeyIndex函数调用的，而_dictKeyIndex函数又会被dictAddRaw函数调用，然后dictAddRaw会被以下三个函数调用。</p><ul>\n<li>dictAdd：用来往Hash表中添加一个键值对。</li>\n<li>dictRelace：用来往Hash表中添加一个键值对，或者键值对存在时，修改键值对。</li>\n<li>dictAddorFind：直接调用dictAddRaw。</li>\n</ul><p>因此，当我们往Redis中写入新的键值对或是修改键值对时，Redis都会判断下是否需要进行rehash。这里你可以参考下面给出的示意图，其中就展示了_dictExpandIfNeeded被调用的关系。</p><p><img src=\"https://static001.geekbang.org/resource/image/90/11/90c261fce9dfe604e29239ba283cef11.jpg?wh=2000x969\" alt=\"\"></p><p>好了，简而言之，Redis中触发rehash操作的关键，就是_dictExpandIfNeeded函数和updateDictResizePolicy函数。<strong>_dictExpandIfNeeded函数</strong>会根据Hash表的负载因子以及能否进行rehash的标识，判断是否进行rehash，而<strong>updateDictResizePolicy函数</strong>会根据RDB和AOF的执行情况，启用或禁用rehash。</p><p>接下来，我们继续探讨Redis在实现rehash时，要解决的第二个问题：rehash扩容扩多大？</p><h3>rehash扩容扩多大？</h3><p>在Redis中，rehash对Hash表空间的扩容是通过<strong>调用dictExpand函数</strong>来完成的。dictExpand函数的参数有两个，<strong>一个是要扩容的Hash表，另一个是要扩到的容量</strong>，下面的代码就展示了dictExpand函数的原型定义：</p><pre><code>int dictExpand(dict *d, unsigned long size);\n</code></pre><p>那么，对于一个Hash表来说，我们就可以根据前面提到的_dictExpandIfNeeded函数，来判断是否要对其进行扩容。而一旦判断要扩容，Redis在执行rehash操作时，对Hash表扩容的思路也很简单，就是<strong>如果当前表的已用空间大小为size，那么就将表扩容到size*2的大小。</strong></p><p>如下所示，当_dictExpandIfNeeded函数在判断了需要进行rehash后，就调用dictExpand进行扩容。这里你可以看到，rehash的扩容大小是当前ht[0]已使用大小的2倍。</p><pre><code>dictExpand(d, d-&gt;ht[0].used*2);\n</code></pre><p>而在dictExpand函数中，具体执行是由_dictNextPower函数完成的，以下代码显示的Hash表扩容的操作，就是从Hash表的初始大小（DICT_HT_INITIAL_SIZE），不停地乘以2，直到达到目标大小。</p><pre><code>static unsigned long _dictNextPower(unsigned long size)\n{\n    //哈希表的初始大小\n    unsigned long i = DICT_HT_INITIAL_SIZE;\n    //如果要扩容的大小已经超过最大值，则返回最大值加1\n    if (size &gt;= LONG_MAX) return LONG_MAX + 1LU;\n    //扩容大小没有超过最大值\n    while(1) {\n        //如果扩容大小大于等于最大值，就返回截至当前扩到的大小\n        if (i &gt;= size)\n            return i;\n        //每一步扩容都在现有大小基础上乘以2\n        i *= 2;\n    }\n}\n</code></pre><p>好，下面我们再来看看Redis要解决的第三个问题，即rehash要如何执行？而这个问题，本质上就是Redis要如何实现渐进式rehash设计。</p><h3>渐进式rehash如何实现？</h3><p>那么这里，我们要先搞清楚一个问题，就是<strong>为什么要实现渐进式rehash？</strong></p><p>其实这是因为，Hash表在执行rehash时，由于Hash表空间扩大，原本映射到某一位置的键可能会被映射到一个新的位置上，因此，很多键就需要从原来的位置拷贝到新的位置。而在键拷贝时，由于Redis主线程无法执行其他请求，所以键拷贝会阻塞主线程，这样就会产生<strong>rehash开销</strong>。</p><p>而为了降低rehash开销，Redis就提出了渐进式rehash的方法。</p><p>简单来说，渐进式rehash的意思就是Redis并不会一次性把当前Hash表中的所有键，都拷贝到新位置，而是会分批拷贝，每次的键拷贝只拷贝Hash表中一个bucket中的哈希项。这样一来，每次键拷贝的时长有限，对主线程的影响也就有限了。</p><p><strong>那么，渐进式rehash在代码层面是如何实现的呢？</strong>这里有两个关键函数：dictRehash和_dictRehashStep。</p><p>我们先来看<strong>dictRehash函数</strong>，这个函数实际执行键拷贝，它的输入参数有两个，分别是全局哈希表（即前面提到的dict结构体，包含了ht[0]和ht[1]）和需要进行键拷贝的桶数量（bucket数量）。</p><p>dictRehash函数的整体逻辑包括两部分：</p><ul>\n<li>首先，该函数会执行一个循环，根据要进行键拷贝的bucket数量n，依次完成这些bucket内部所有键的迁移。当然，如果ht[0]哈希表中的数据已经都迁移完成了，键拷贝的循环也会停止执行。</li>\n<li>其次，在完成了n个bucket拷贝后，dictRehash函数的第二部分逻辑，就是判断ht[0]表中数据是否都已迁移完。如果都迁移完了，那么ht[0]的空间会被释放。因为Redis在处理请求时，代码逻辑中都是使用ht[0]，所以当rehash执行完成后，虽然数据都在ht[1]中了，但Redis仍然会把ht[1]赋值给ht[0]，以便其他部分的代码逻辑正常使用。</li>\n<li>而在ht[1]赋值给ht[0]后，它的大小就会被重置为0，等待下一次rehash。与此同时，全局哈希表中的rehashidx变量会被标为-1，表示rehash结束了（这里的rehashidx变量用来表示rehash的进度，稍后我会给你具体解释）。</li>\n</ul><p>我画了下面这张图，展示了dictRehash的主要执行流程，你可以看下。</p><p><img src=\"https://static001.geekbang.org/resource/image/e5/d1/e54b90dc143ba7e6eae2cda418ce20d1.jpg?wh=2000x1125\" alt=\"\"></p><p>同时，你也可以通过下面代码，来了解dictRehash函数的主要执行逻辑。</p><pre><code>int dictRehash(dict *d, int n) {\n    int empty_visits = n*10;\n    ...\n    //主循环，根据要拷贝的bucket数量n，循环n次后停止或ht[0]中的数据迁移完停止\n    while(n-- &amp;&amp; d-&gt;ht[0].used != 0) {\n       ...\n    }\n    //判断ht[0]的数据是否迁移完成\n    if (d-&gt;ht[0].used == 0) {\n        //ht[0]迁移完后，释放ht[0]内存空间\n        zfree(d-&gt;ht[0].table);\n        //让ht[0]指向ht[1]，以便接受正常的请求\n        d-&gt;ht[0] = d-&gt;ht[1];\n        //重置ht[1]的大小为0\n        _dictReset(&amp;d-&gt;ht[1]);\n        //设置全局哈希表的rehashidx标识为-1，表示rehash结束\n        d-&gt;rehashidx = -1;\n        //返回0，表示ht[0]中所有元素都迁移完\n        return 0;\n    }\n    //返回1，表示ht[0]中仍然有元素没有迁移完\n    return 1;\n}\n</code></pre><p>好，在了解了dictRehash函数的主体逻辑后，我们再看下渐进式rehash是如何按照bucket粒度拷贝数据的，这其实就和全局哈希表dict结构中的rehashidx变量相关了。</p><p>rehashidx变量表示的是<strong>当前rehash在对哪个bucket做数据迁移</strong>。比如，当rehashidx等于0时，表示对ht[0]中的第一个bucket进行数据迁移；当rehashidx等于1时，表示对ht[0]中的第二个bucket进行数据迁移，以此类推。</p><p>而dictRehash函数的主循环，首先会判断rehashidx指向的bucket是否为空，如果为空，那就将rehashidx的值加1，检查下一个bucket。</p><p><strong>那么，有没有可能连续几个bucket都为空呢？</strong>其实是有可能的，在这种情况下，渐进式rehash不会一直递增rehashidx进行检查。这是因为一旦执行了rehash，Redis主线程就无法处理其他请求了。</p><p>所以，渐进式rehash在执行时设置了一个<strong>变量empty_visits</strong>，用来表示已经检查过的空bucket，当检查了一定数量的空bucket后，这一轮的rehash就停止执行，转而继续处理外来请求，避免了对Redis性能的影响。下面的代码显示了这部分逻辑，你可以看下。</p><pre><code>while(n-- &amp;&amp; d-&gt;ht[0].used != 0) {\n    //如果当前要迁移的bucket中没有元素\n    while(d-&gt;ht[0].table[d-&gt;rehashidx] == NULL) {\n        //\n        d-&gt;rehashidx++;\n        if (--empty_visits == 0) return 1;\n    }\n    ...\n}\n</code></pre><p>而如果rehashidx指向的bucket有数据可以迁移，那么Redis就会把这个bucket中的哈希项依次取出来，并根据ht[1]的表空间大小，重新计算哈希项在ht[1]中的bucket位置，然后把这个哈希项赋值到ht[1]对应bucket中。</p><p>这样，每做完一个哈希项的迁移，ht[0]和ht[1]用来表示承载哈希项多少的变量used，就会分别减一和加一。当然，如果当前rehashidx指向的bucket中数据都迁移完了，rehashidx就会递增加1，指向下一个bucket。下面的代码显示了这一迁移过程。</p><pre><code>while(n-- &amp;&amp; d-&gt;ht[0].used != 0) {\n    ...\n    //获得哈希表中哈希项\n    de = d-&gt;ht[0].table[d-&gt;rehashidx];\n    //如果rehashidx指向的bucket不为空\n    while(de) {\n        uint64_t h;\n        //获得同一个bucket中下一个哈希项\n        nextde = de-&gt;next;\n        //根据扩容后的哈希表ht[1]大小，计算当前哈希项在扩容后哈希表中的bucket位置\n        h = dictHashKey(d, de-&gt;key) &amp; d-&gt;ht[1].sizemask;\n        //将当前哈希项添加到扩容后的哈希表ht[1]中\n        de-&gt;next = d-&gt;ht[1].table[h];\n        d-&gt;ht[1].table[h] = de;\n        //减少当前哈希表的哈希项个数\n        d-&gt;ht[0].used--;\n        //增加扩容后哈希表的哈希项个数\n        d-&gt;ht[1].used++;\n        //指向下一个哈希项\n        de = nextde;\n    }\n    //如果当前bucket中已经没有哈希项了，将该bucket置为NULL\n    d-&gt;ht[0].table[d-&gt;rehashidx] = NULL;\n    //将rehash加1，下一次将迁移下一个bucket中的元素\n    d-&gt;rehashidx++;\n}\n</code></pre><p>好了，到这里，我们就已经基本了解了dictRehash函数的全部逻辑。</p><p>现在我们知道，dictRehash函数本身是按照bucket粒度执行哈希项迁移的，它内部执行的bucket迁移个数，主要由传入的循环次数变量n来决定。但凡Redis要进行rehash操作，最终都会调用dictRehash函数。</p><p>接下来，我们来学习和渐进式rehash相关的第二个关键函数<strong> _dictRehashStep</strong>，这个函数实现了每次只对一个bucket执行rehash。</p><p>从Redis的源码中我们可以看到，一共会有5个函数通过调用_dictRehashStep函数，进而调用dictRehash函数，来执行rehash，它们分别是：dictAddRaw，dictGenericDelete，dictFind，dictGetRandomKey，dictGetSomeKeys。</p><p>其中，dictAddRaw和dictGenericDelete函数，分别对应了往Redis中增加和删除键值对，而后三个函数则对应了在Redis中进行查询操作。下图展示了这些函数间的调用关系：</p><p><img src=\"https://static001.geekbang.org/resource/image/05/0a/050cdce01b19a8d03834c18d1feab20a.jpg?wh=2000x820\" alt=\"\"></p><p>但你要注意，不管是增删查哪种操作，这5个函数调用的_dictRehashStep函数，给dictRehash传入的循环次数变量n的值都为1，下面的代码就显示了这一传参的情况。</p><pre><code>static void _dictRehashStep(dict *d) {\n//给dictRehash传入的循环次数参数为1，表明每迁移完一个bucket ，就执行正常操作\n    if (d-&gt;iterators == 0) dictRehash(d,1);\n}\n</code></pre><p>这样一来，每次迁移完一个bucket，Hash表就会执行正常的增删查请求操作，这就是在代码层面实现渐进式rehash的方法。</p><h2>小结</h2><p>实现一个高性能的Hash表不仅是Redis的需求，也是很多计算机系统开发过程中的重要目标。而要想实现一个性能优异的Hash表，就需要重点解决哈希冲突和rehash开销这两个问题。</p><p>今天这节课，我带你学习了Redis中Hash表的结构设计、链式哈希方法的实现，以及渐进式rehash方法的设计实现。Redis中Hash表的结构设计很特别，它的每个哈希项都包含了一个指针，用于实现链式哈希。同时，Redis在全局哈希表中还包含了两个Hash表，这种设计思路也是为了在实现rehash时，帮助数据从一个表迁移到另一个表。</p><p>此外，Redis实现的渐进式rehash是一个用于Hash表扩容的通用方法，非常值得我们学习。这个设计方法的关键是每次仅迁移有限个数的bucket，避免一次性迁移给所有bucket带来的性能影响。当你掌握了渐进式rehash这个设计思想和实现方法，你就可以把它应用到自己的Hash表实现场景中。</p><h2>每课一问</h2><p>Hash函数会影响Hash表的查询效率及哈希冲突情况，那么，你能从Redis的源码中，找到Hash表使用的是哪一种Hash函数吗？</p><p>欢迎在留言区分享你的答案，如果觉得有收获，也欢迎你把今天的内容分享给更多的朋友。</p>","comments":[{"had_liked":false,"id":304894,"user_name":"Kaito","can_delete":false,"product_type":"c1","uid":1020042,"ip_address":"","ucode":"79775FA35A95F2","user_header":"https://static001.geekbang.org/account/avatar/00/0f/90/8a/288f9f94.jpg","comment_is_top":false,"comment_ctime":1627670149,"is_pvip":true,"discussion_count":11,"race_medal":0,"score":"396764661381","product_id":100084301,"comment_content":"1、Redis 中的 dict 数据结构，采用「链式哈希」的方式存储，当哈希冲突严重时，会开辟一个新的哈希表，翻倍扩容，并采用「渐进式 rehash」的方式迁移数据<br><br>2、所谓「渐进式 rehash」是指，把很大块迁移数据的开销，平摊到多次小的操作中，目的是降低主线程的性能影响<br><br>3、Redis 中凡是需要 O(1) 时间获取 k-v 数据的场景，都使用了 dict 这个数据结构，也就是说 dict 是 Redis 中重中之重的「底层数据结构」<br><br>4、dict 封装好了友好的「增删改查」API，并在适当时机「自动扩容、缩容」，这给上层数据类型（Hash&#47;Set&#47;Sorted Set）、全局哈希表的实现提供了非常大的便利<br><br>5、例如，Redis 中每个 DB 存放数据的「全局哈希表、过期key」都用到了 dict：<br><br>&#47;&#47; server.h<br>typedef struct redisDb {<br>    dict *dict;     &#47;&#47; 全局哈希表，数据键值对存在这<br>    dict *expires;  &#47;&#47; 过期 key + 过期时间 存在这<br>    ...<br>}<br><br>6、「全局哈希表」在触发渐进式 rehash 的情况有 2 个：<br><br>- 增删改查哈希表时：每次迁移 1 个哈希桶（文章提到的 dict.c 中的 _dictRehashStep 函数）<br>- 定时 rehash：如果 dict 一直没有操作，无法渐进式迁移数据，那主线程会默认每间隔 100ms 执行一次迁移操作。这里一次会以 100 个桶为基本单位迁移数据，并限制如果一次操作耗时超时 1ms 就结束本次任务，待下次再次触发迁移（文章没提到这个，详见 dict.c 的 dictRehashMilliseconds 函数）<br><br>（注意：定时 rehash 只会迁移全局哈希表中的数据，不会定时迁移 Hash&#47;Set&#47;Sorted Set 下的哈希表的数据，这些哈希表只会在操作数据时做实时的渐进式 rehash）<br><br>7、dict 在负载因子超过 1 时（used: bucket size &gt;= 1），会触发 rehash。但如果 Redis 正在 RDB 或 AOF rewrite，为避免父进程大量写时复制，会暂时关闭触发 rehash。但这里有个例外，如果负载因子超过了 5（哈希冲突已非常严重），依旧会强制做 rehash（重点）<br><br>8、dict 在 rehash 期间，查询旧哈希表找不到结果，还需要在新哈希表查询一次<br><br>课后题：Hash 函数会影响 Hash 表的查询效率及哈希冲突情况，那么，你能从 Redis 的源码中，找到 Hash 表使用的是哪一种 Hash 函数吗？<br><br>找到 dict.c 的 dictFind 函数，可以看到查询一个 key 在哈希表的位置时，调用了 dictHashKey 计算 key 的哈希值：<br><br>dictEntry *dictFind(dict *d, const void *key) {<br>    &#47;&#47; 计算 key 的哈希值<br>    h = dictHashKey(d, key);<br>    ...<br>}<br><br>继续跟代码可以看到 dictHashKey 调用了 struct dict 下 dictType 的 hashFunction 函数：<br><br>&#47;&#47; dict.h<br>dictHashKey(d, key) (d)-&gt;type-&gt;hashFunction(key)<br><br>而这个 hashFunction 是在初始化一个 dict 时，才会指定使用哪个哈希函数的。<br><br>当 Redis Server 在启动时会创建「全局哈希表」：<br><br>&#47;&#47; 初始化 db 下的全局哈希表<br>for (j = 0; j &lt; server.dbnum; j++) {<br>    &#47;&#47; dbDictType 中指定了哈希函数<br>    server.db[j].dict = dictCreate(&amp;dbDictType,NULL);<br>    ...<br>}<br><br>这个 dbDictType struct 指定了具体的哈希函数，跟代码进去能看到，使用了 SipHash 算法，具体实现逻辑在 siphash.c。<br><br>（SipHash 哈希算法是在 Redis 4.0 才开始使用的，3.0-4.0 使用的是 MurmurHash2 哈希算法，3.0 之前是 DJBX33A 哈希算法）","like_count":93,"discussions":[{"author":{"id":1296063,"avatar":"https://static001.geekbang.org/account/avatar/00/13/c6/bf/52b3f71d.jpg","nickname":"dawn","note":"","ucode":"1757B28F1EF5C4","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":585464,"discussion_content":"看过java hashmap的源码，再看redis的，就不那么难了，entry bucket之类的概念理解起来很容易","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1661582017,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"江苏"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2743620,"avatar":"","nickname":"Geek_8d3e0a","note":"","ucode":"D387929EE2B37B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":557593,"discussion_content":"我爱课代表~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1647874115,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1254968,"avatar":"https://static001.geekbang.org/account/avatar/00/13/26/38/ef063dc2.jpg","nickname":"Darren","note":"","ucode":"CCD2B2C492BE9A","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":386926,"discussion_content":"大佬，第6点的注意事情：定时 rehash 只会迁移全局哈希表中的数据，不会定时迁移 Hash/Set/Sorted Set 下的哈希表的数据，这些哈希表只会在操作数据时做实时的渐进式 rehash。--这个是什么意思呀？那如果一部分数据永远不会被操作，那么岂不是永远不会rehash成功？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627894767,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":2,"child_discussions":[{"author":{"id":2094925,"avatar":"https://static001.geekbang.org/account/avatar/00/1f/f7/4d/09554c96.jpg","nickname":"iron bo","note":"","ucode":"4BFB1331637AA3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1254968,"avatar":"https://static001.geekbang.org/account/avatar/00/13/26/38/ef063dc2.jpg","nickname":"Darren","note":"","ucode":"CCD2B2C492BE9A","race_medal":0,"user_type":1,"is_pvip":true},"discussion":{"id":387005,"discussion_content":"定时rehash操作的是全局哈希表，在这个表中，存储的是string也好，set也好，都只是当做一个指针而已。hash表只是一种数据结构而已。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627951158,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":386926,"ip_address":""},"score":387005,"extra":""},{"author":{"id":1254968,"avatar":"https://static001.geekbang.org/account/avatar/00/13/26/38/ef063dc2.jpg","nickname":"Darren","note":"","ucode":"CCD2B2C492BE9A","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":2094925,"avatar":"https://static001.geekbang.org/account/avatar/00/1f/f7/4d/09554c96.jpg","nickname":"iron bo","note":"","ucode":"4BFB1331637AA3","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":387045,"discussion_content":"我理解保存的是指针，但是rehash的时候，只需要移动全局哈希表，因此指针指向的内容是不需要移动的，但是看大神的留言感觉还是要移动的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627960001,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":387005,"ip_address":""},"score":387045,"extra":""}]},{"author":{"id":1312635,"avatar":"https://static001.geekbang.org/account/avatar/00/14/07/7b/db7fa67e.jpg","nickname":"阿梵杰～","note":"","ucode":"EBF291933B16E3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":386770,"discussion_content":"大神第6、7、8点总结很给力，学到了 ","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627789506,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1812201,"avatar":"https://wx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLm8skz4F7FGGBTXWUMia6qVEc00BddeXapicv5FkAx62GmOnUNEcE4scSR60AmappQoNdIQhccKsBA/132","nickname":"末日，成欢","note":"","ucode":"BBAEBB9C93558A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":386682,"discussion_content":"大佬，我想问下全局的hash表在哪个文件","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627722689,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1045455,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/f3/cf/851dab01.jpg","nickname":"Milittle","note":"","ucode":"80E566639A8ABB","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1812201,"avatar":"https://wx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLm8skz4F7FGGBTXWUMia6qVEc00BddeXapicv5FkAx62GmOnUNEcE4scSR60AmappQoNdIQhccKsBA/132","nickname":"末日，成欢","note":"","ucode":"BBAEBB9C93558A","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":386883,"discussion_content":"server.db里面的dict，这里db有16个，也就是我们平时说的redis默认有16个db，每一个db里面都有全局dict。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1627876072,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":386682,"ip_address":""},"score":386883,"extra":""}]},{"author":{"id":1005391,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg","nickname":"一步","note":"","ucode":"73CEA468CE70C3","race_medal":1,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":386634,"discussion_content":"dict 在 rehash 期间，查询旧哈希表找不到结果，还需要在新哈希表查询一次\n\n这个解答了我的疑问，在rehash 的过程中如果bucket迁移之后，再来的新key 会保存到哪个hash上，应该是保存到新的 hash 中","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627702594,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":2,"child_discussions":[{"author":{"id":1045455,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/f3/cf/851dab01.jpg","nickname":"Milittle","note":"","ucode":"80E566639A8ABB","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1005391,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg","nickname":"一步","note":"","ucode":"73CEA468CE70C3","race_medal":1,"user_type":1,"is_pvip":true},"discussion":{"id":386648,"discussion_content":"这个确实一般的rehash都是这种解决方案","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627707342,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":386634,"ip_address":""},"score":386648,"extra":""},{"author":{"id":1020042,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/90/8a/288f9f94.jpg","nickname":"Kaito","note":"","ucode":"79775FA35A95F2","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1005391,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg","nickname":"一步","note":"","ucode":"73CEA468CE70C3","race_medal":1,"user_type":1,"is_pvip":true},"discussion":{"id":386668,"discussion_content":"新key直接写新哈希表","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627718498,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":386634,"ip_address":""},"score":386668,"extra":""}]}]},{"had_liked":false,"id":305009,"user_name":"悟空聊架构","can_delete":false,"product_type":"c1","uid":1123163,"ip_address":"","ucode":"C2F482A0CF8AF1","user_header":"https://static001.geekbang.org/account/avatar/00/11/23/5b/983408b9.jpg","comment_is_top":false,"comment_ctime":1627747791,"is_pvip":true,"replies":[{"id":"110483","content":"太赞了！<br><br>感谢分享这么详细的代码查找过程。其实，查找某个函数是我们在阅读源码过程中最常遇到的问题。你分享的过程给了一个非常棒的示范！尤其是第5，6、7步在线索断了后，如何再进行查找。<br><br>其实，我在想，你在第7步，找到49个相关调用，有没有想过直接看server.c文件 ：）<br>","user_name":"作者回复","user_name_real":"蒋德钧","uid":"1609687","ctime":1628040146,"ip_address":"","comment_id":305009,"utype":1}],"discussion_count":3,"race_medal":0,"score":"100411995599","product_id":100084301,"comment_content":"说下我是怎么找到这个 Hash 函数的吧。有点艰辛...<br><br>（1）文中也提到了 rehash 的主要函数就是 dictRehash 函数，所以我们可以直接在这个函数里面找： <br><br>h = dictHashKey(d, de-&gt;key) &amp; d-&gt;ht[1].sizemask;<br><br>代码含义：根据扩容后的哈希表ht[1]大小，计算当前哈希项在扩容后哈希表中的bucket位置。<br><br>（2）点进这个方法里面，发现如下：<br><br>\\#define dictHashKey(d, key) (d)-&gt;type-&gt;hashFunction(key)<br><br>最后调用的是一个 hashFunction，但是你会发现，不能跳转到这个方法里面。这样来看似乎线索断了。<br><br>（3）我们可以 hashFunction 是被 type 调用的，那么这个 type 其实 dict 的一个属性。那我们就直接去看下 dict 结构体，再 dict.h 中定义了 struct dict。里面可以找到 type 属性：<br><br>  dictType *type;<br><br>那这个 dictType 又是什么呢？<br><br>（4）我们点进去看下，发现 dictType 也是一个结构体，定义了 hash 函数的指针：<br><br>uint64_t (*hashFunction)(const void *key);<br><br>但是这里还是没有看到指针指向哪个 hash 函数，线索似乎又断了。<br><br>（5）这个时候，只能到 dict.c 中看下有没有线索。发现有一个 dictCreate 函数，里面指定了 type：<br><br>dict *dictCreate(dictType *type, void *privDataPtr)<br><br>所以我们只要找到调用 dictCreate 的地方，看下传的什么 type 就知道调用的是哪个 hash 函数了。<br><br>（6）全局搜 dictCreate 函数。发现有 53 个地方调用了，第一个文件时 deps\\hiredis\\async.c，到这里，其实再点进去没有意义了，因为 deps 文件夹属于第三方依赖库，和 redis 的核心源码没有关系，那就继续找。<br><br>（7）把 deps 排除掉，剩余 49 个结果，第一个是 cluster.c 中调用的，cluster 是 Redis 集群初始化相关的<br><br>  server.cluster-&gt;nodes = dictCreate(&amp;clusterNodesDictType,NULL);<br><br>这里用到的 clusterNodesDictType 中指定了 Hash 函数：dictSdsHash<br><br>（8）dictSdsHash 点进去，发现还是回到了 dict.c 文件中，调用了 dictGenHashFunction 函数，如下所示：<br><br>uint64_t dictGenHashFunction(const void *key, int len) {<br><br>  return siphash(key,len,dict_hash_function_seed);<br><br>}<br><br>调用的就是 siphash 函数，这就是我们要找的 hash 函数。<br><br>（9）siphash 点进去，跳转到了 siphash.c 文件，定义了 siphash 函数。<br><br>（10）第 7 步中，搜索结果我是看的 cluster.c 文件，如果想看下 Redis 服务端初始化相关的代码，就在 server.c 中找。搜索结果中有一条相关的，初始化 Redis 数据库：<br><br>server.db[j].dict = dictCreate(&amp;dbDictType,NULL);<br><br>dbDictType 点进去，发现用到了 dictSdsHash 函数：<br><br>再从 dictSdsHash 函数点进去，发现还是用到了 dict.c 中的 dictGenHashFunction 函数，和第十步找到的一样，同一个 dictGenHashFunction 函数，顿时感觉神清气爽。<br><br>------<br><br>总结：<br><br>1. 其实可以直接从 server.c 中来找创建 dict 的地方，会省很多步，这是一个正向的思维，但往往排查问题时，我们用的是逆向思维，虽然逆向思维苦了点，但是会有一种柳暗花明又一村的感觉。<br><br>2. 寻找的过程比较艰辛，但是对源码理解更深了。<br><br>3. 可以看 Redis 5 设计与源码实现作为本专栏的补充。比如缩容时也会触发渐见式 hash。当使用量不到总空间 10% 时，则进行缩容。缩容时空间大小则为能恰好包含 d-&gt;ht[0].used 个节点的 2^N 次方幂整数，并把字典中字段 rehashidx 标识为 0。在 server.h 文件中有定义：#define HASHTABLE_MIN_FILL    10。","like_count":24,"discussions":[{"author":{"id":1609687,"avatar":"https://static001.geekbang.org/account/avatar/00/18/8f/d7/fb60129d.jpg","nickname":"蒋德钧","note":"","ucode":"833985C2C37C0A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":524249,"discussion_content":"太赞了！\n\n感谢分享这么详细的代码查找过程。其实，查找某个函数是我们在阅读源码过程中最常遇到的问题。你分享的过程给了一个非常棒的示范！尤其是第5，6、7步在线索断了后，如何再进行查找。\n\n其实，我在想，你在第7步，找到49个相关调用，有没有想过直接看server.c文件 ：）\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1628040146,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1657561,"avatar":"https://static001.geekbang.org/account/avatar/00/19/4a/d9/b8046b4b.jpg","nickname":"zhangm365","note":"","ucode":"60E7DEFB3F5840","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":392043,"discussion_content":"大神，siphash这个哈希函数具体怎么操作的，没看到怎么哈希的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1630802085,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1123163,"avatar":"https://static001.geekbang.org/account/avatar/00/11/23/5b/983408b9.jpg","nickname":"悟空聊架构","note":"","ucode":"C2F482A0CF8AF1","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":387335,"discussion_content":"看到过server.c，不过对这个文件还比较模糊，所以和第一个搜索结果同等对待了，后来看了server.c的源码，有种释然的感觉，redis的文件结构太棒了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1628128503,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":304915,"user_name":"曾轼麟","can_delete":false,"product_type":"c1","uid":1451391,"ip_address":"","ucode":"D418371AC11270","user_header":"https://static001.geekbang.org/account/avatar/00/16/25/7f/473d5a77.jpg","comment_is_top":false,"comment_ctime":1627700337,"is_pvip":false,"discussion_count":3,"race_medal":0,"score":"70347177073","product_id":100084301,"comment_content":"首先回答老师的提问：Redis使用的hash函数算法是siphash，其代码位于siphash.c的siphash函数中，上层函数是dictGenHashFunction 【注意】：在查找dictGenHashFunction的时候如果发现算法是time33，其实你找到的是C的redis客户端框架hiredis实现的hash函数，并不是redis本身的hash函数<br><br><br>此外阅读完文章我产生了三个问题并且自己给出自己的理解：<br><br>问题一：<br><br>    redis的dict结构核心就是链式hash，其原理其实和JDK的HashMap类似（JDK1.7之前的版本，1.8开始是红黑树或链表），这里就有一个问题为什么Redis要使用链式而不引入红黑树呢，或者直接使用红黑树？<br><br>答：<br>    1、hash冲突不使用红黑树：redis需要高性能，如果hash冲突使用红黑树，红黑树和链表的转换会引起不必要的开销（hash冲突不大的情况下红黑树其实比链表沉重，还会浪多余的空间）<br>    2、dict不采用红黑树：在负载因子较低，hash冲突较低的情况下，hash表的效率O(1)远远高于红黑树<br>    3、当采用渐进式rehash的时候，以上问题都可以解决<br><br><br>问题二：<br><br>    何为渐进式rehash？本质原理是什么？当内存使用变小会缩容吗？<br><br>答：<br>    1、渐进式rehash的本质是分治思想，通过把大任务划分成一个个小任务，每个小任务只执行一小部分数据，最终完成整个大任务的过程<br>    2、渐进式rehash可以在不影响运行中的redis使用来完成整改hash表的扩容（每次可以控制只执行1ms）<br>    3、初步判定会，因为dictResize中用于计算hash表大小的minimal就是来源于实际使用的大小，并且htNeedsResize方法中（used*100&#47;size &lt; HASHTABLE_MIN_FILL）来判断是否触发缩容来节约内存，而缩容也是渐进式rehash<br><br><br>问题三：<br><br>    渐进式rehash怎么去执行？<br><br>答：<br>    在了解渐进式rehash之前，我们需要了解一个事情，就是正在运行执行任务的redis，其实本身就是一个单线程的死循环（不考虑异步以及其他fork的场景），其循环的方法为aeMain(),位于ae.c文件中，在这个循环中每次执行都会去尝试执行已经触发的时间事件和文件事件，而渐进式rehash的每个小任务就是位于redis，serverCron时间事件中，redis每次循环的时候其实都会经过如下所示的调用流程：<br><br>    1、serverCron -&gt; updateDictResizePolicy (先判断是否能执行rehash，当AOF重写等高压力操作时候不执行)<br>    2、serverCron -&gt; databasesCron -&gt; incrementallyRehash -&gt; dictRehashMilliseconds -&gt; dictRehash (dictRehashMilliseconds默认要求每次rehash最多只能执行1ms)<br><br>    通过这种方式最终完成整改hash表的扩容","like_count":16,"discussions":[{"author":{"id":3070975,"avatar":"","nickname":"Geek_2676fe","note":"","ucode":"9AEB8043677302","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":581641,"discussion_content":"为啥java不用渐进式rehash","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1658906426,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1365206,"avatar":"https://static001.geekbang.org/account/avatar/00/14/d4/d6/1d4543ac.jpg","nickname":"云海","note":"","ucode":"0C6CA0BE58EA21","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":388923,"discussion_content":"你好，缩容时控制最多只执行1ms。我看了源码，是通过 while 循环 来控制执行时间的。\ntimeInMilliseconds内部调用了gettimeofday(&amp;tv,NULL)。\n那么问题来了，大量的 gettimeofday获取时间是否有性能问题呢？ java里的 System.currentTimeMillis() 底层native实现也是 gettimeofday，java 层面在并发环境下 currentTimeMillis 会有性能问题，C 环境下 gettimeofday 也会有性能问题吗？\n\n    while(dictRehash(d,100)) {\n        rehashes += 100;\n        if (timeInMilliseconds()-start > ms) break;\n    }","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1629043220,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1123163,"avatar":"https://static001.geekbang.org/account/avatar/00/11/23/5b/983408b9.jpg","nickname":"悟空聊架构","note":"","ucode":"C2F482A0CF8AF1","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":386720,"discussion_content":"自问自答太棒了！点赞","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627742296,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":305065,"user_name":"叶坚","can_delete":false,"product_type":"c1","uid":1113335,"ip_address":"","ucode":"97804011A3C03E","user_header":"https://static001.geekbang.org/account/avatar/00/10/fc/f7/457c14b2.jpg","comment_is_top":false,"comment_ctime":1627797890,"is_pvip":true,"discussion_count":5,"race_medal":0,"score":"23102634370","product_id":100084301,"comment_content":"咨询个问题，当部分bucket 执行 rehash，部分bucket还没有执行rehash，这时增删查请求操作是对ht[1]操作，还是ht[0]，谢谢<br>","like_count":5,"discussions":[{"author":{"id":1365917,"avatar":"https://static001.geekbang.org/account/avatar/00/14/d7/9d/3008ed30.jpg","nickname":"小怪兽打奥特曼","note":"","ucode":"364189B7BCB47C","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":554305,"discussion_content":"增：操作ht1;dict.c:309\n删：先ht0,如果没有（说明hash到ht1或者本来就没有）再执行ht1;dict.c:375\n找：操作ht0,如果没有再执行ht1;dict.c:485","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1646309390,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2420294,"avatar":"https://static001.geekbang.org/account/avatar/00/24/ee/46/7d65ae37.jpg","nickname":"木几丶","note":"","ucode":"FFDB958DA64F8C","race_medal":5,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":386912,"discussion_content":"新增往ht[1]，删除先从ht[0]没找到再从ht[1]，查询也是先从ht[0]没找到再从ht[1]。\n比如删除操作可以在dict.c  dictDenericDelete函数中看到，在执行完第一个哈希表后如果没找到且正在rehash会继续执行第二个哈希表","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1627890537,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1045455,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/f3/cf/851dab01.jpg","nickname":"Milittle","note":"","ucode":"80E566639A8ABB","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":386844,"discussion_content":"重新回答一下：新增，当时是走ht 1，删除走的那一定应该是ht 0， 请求操作就是先看ht 0有没有，没有的话，会从ht 1中再找一遍。 我个人理解。这个还得具体看代码分析","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627834764,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1045455,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/f3/cf/851dab01.jpg","nickname":"Milittle","note":"","ucode":"80E566639A8ABB","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":386812,"discussion_content":"可以从_dictKeyIndex，if （！dictIsRehashing（d））break；看出来","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627813356,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1045455,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/f3/cf/851dab01.jpg","nickname":"Milittle","note":"","ucode":"80E566639A8ABB","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":386802,"discussion_content":"都做请求 ","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627809440,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":326096,"user_name":"onno","can_delete":false,"product_type":"c1","uid":1024726,"ip_address":"","ucode":"FB7E829037DA10","user_header":"https://static001.geekbang.org/account/avatar/00/0f/a2/d6/97370dfc.jpg","comment_is_top":false,"comment_ctime":1639376652,"is_pvip":false,"discussion_count":3,"race_medal":0,"score":"18819245836","product_id":100084301,"comment_content":"为啥说dictht里的**table是一个二维数组啊，不是一个二级指针的一位数组吗？","like_count":5,"discussions":[{"author":{"id":1438381,"avatar":"https://static001.geekbang.org/account/avatar/00/15/f2/ad/c7011fd8.jpg","nickname":"！","note":"","ucode":"831FDAACFFF192","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":561547,"discussion_content":"因为table 指向的是dictEntry的指针的首地址，加1时指向dictEntry的指针的第二个地址，相同类型的连续地址和数组申请是一样的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1649668190,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1385483,"avatar":"https://static001.geekbang.org/account/avatar/00/15/24/0b/8690964e.jpg","nickname":"或许","note":"","ucode":"97D14FAB1F239C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":542067,"discussion_content":"这一点我也没看太明白","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1640656913,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2239839,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/u1Zr9yTrTibSWicFFophCK9KvSkt5ETLfxoL4eejFoPOZJTYorjibK3y0s4odHmUphHwcrHtDfYiag4bId4Cr6zfuw/132","nickname":"solk","note":"","ucode":"7246DBAED4ABB5","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":539052,"discussion_content":"赞同，感觉作者这儿说的确实不对。源代码使用和逻辑上来说，都不可能是二维数组。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1639582461,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":305043,"user_name":"陌","can_delete":false,"product_type":"c1","uid":1152678,"ip_address":"","ucode":"13FF1D4B3181F0","user_header":"https://static001.geekbang.org/account/avatar/00/11/96/a6/aac2a550.jpg","comment_is_top":false,"comment_ctime":1627789023,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"14512690911","product_id":100084301,"comment_content":"Hash 表使用的是哪一种 Hash 函数?<br><br>各个类型的 dictType 在 server.c 中被初始化，常用的包括 setDictType、zsetDictType 以及 16 个 database 所使用的 dbDictType。<br>此时就可以找到 hashFunction 的实现为 dictSdsHash()，最终的底层实现为 siphash()。<br><br>dict 对象的使用除了理解最基本的拉链法处理哈希冲突、使用渐进式 rehash 的方式进行扩容以外，我认为还需要从全局的角度来考虑。也就是 Redis Server 在运行时<br>使用了哪些功能的 dict。这部分内容可以在 server.c&#47;initServer() 方法中找到答案:<br><br>```<br>for (j = 0; j &lt; server.dbnum; j++) {<br>    &#47;&#47; 创建基础 hashmap，也就是 set key value 所使用的 hashmap<br>    server.db[j].dict = dictCreate(&amp;dbDictType,NULL);<br><br>    &#47;&#47; 创建 expires hashmap，用于实现 TTL，调用可见 dbAsyncDelete()<br>    server.db[j].expires = dictCreate(&amp;dbExpiresDictType,NULL);<br><br>    &#47;&#47; 创建 blocking_keys hashmap，用于记录阻塞信息，调用可见 serveClientsBlockedOnListKey()<br>    server.db[j].blocking_keys = dictCreate(&amp;keylistDictType,NULL);<br><br>    &#47;&#47; 创建 ready_keys hashmap，调用可见 handleClientsBlockedOnKeys()<br>    server.db[j].ready_keys = dictCreate(&amp;objectKeyPointerValueDictType,NULL);<br><br>    &#47;&#47; 创建 watched_keys hashmap，调用可见 watchForKey()<br>    server.db[j].watched_keys = dictCreate(&amp;keylistDictType,NULL);<br><br>    ......<br>}<br>```<br><br>也就是说，Redis 在启动时将会创建 16 * 5 个功能性的 dict，这些 dcit 是实现 TTL、BLPOP&#47;BRPOP 等功能的关键组件。","like_count":3},{"had_liked":false,"id":332058,"user_name":"shp","can_delete":false,"product_type":"c1","uid":2086578,"ip_address":"","ucode":"1FE3758AD999CF","user_header":"https://static001.geekbang.org/account/avatar/00/1f/d6/b2/449b4ae3.jpg","comment_is_top":false,"comment_ctime":1643002209,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10232936801","product_id":100084301,"comment_content":"需要注意的是在渐进式rehash的过程，如果有增删改查操作时，如果index大于rehashindex，访问ht[0]，否则访问ht[1]","like_count":2},{"had_liked":false,"id":304971,"user_name":"木几丶","can_delete":false,"product_type":"c1","uid":2420294,"ip_address":"","ucode":"FFDB958DA64F8C","user_header":"https://static001.geekbang.org/account/avatar/00/24/ee/46/7d65ae37.jpg","comment_is_top":false,"comment_ctime":1627724718,"is_pvip":true,"discussion_count":8,"race_medal":5,"score":"10217659310","product_id":100084301,"comment_content":"老师你好，有几个问题想请教下：<br>1、判断是否扩容并rehash的条件是d-&gt;ht[0].used &gt;= d-&gt;ht[0].size &amp;&amp;(dict_can_resize || d-&gt;ht[0].used&#47;d-&gt;ht[0].size &gt; dict_force_resize_ratio)，这句逻辑好像不对？应该写成d-&gt;ht[0].used &gt;= d-&gt;ht[0].size &amp;&amp; dict_can_resize || d-&gt;ht[0].used&#47;d-&gt;ht[0].size &gt; dict_force_resize_ratio？<br>2、在函数dictRehash中有一段代码是  assert(d-&gt;ht[0].size &gt; (unsigned long)d-&gt;rehashidx)，这是断言rehashidx是否越界，rehashidx为什么会有越界的情况？<br>3、另外问个代码上的问题（有可能钻牛角尖了），作为性能抠的很细的redis来说，在计算新哈希表大小的时候需要从初始大小4频繁*2得到最终size，这里为什么不直接用移位操作提升效率？","like_count":2,"discussions":[{"author":{"id":2420294,"avatar":"https://static001.geekbang.org/account/avatar/00/24/ee/46/7d65ae37.jpg","nickname":"木几丶","note":"","ucode":"FFDB958DA64F8C","race_medal":5,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":386906,"discussion_content":"第一个问题明白了。。这两句语义其实是一样的，把源码做下分配律就是我那样了 : )","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627889002,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1045455,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/f3/cf/851dab01.jpg","nickname":"Milittle","note":"","ucode":"80E566639A8ABB","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":386843,"discussion_content":"第三问题：从代码提交记录来看，09年的代码，再没有人更新过，应该是历史包袱（猜测）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627834670,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":3,"child_discussions":[{"author":{"id":1188710,"avatar":"https://static001.geekbang.org/account/avatar/00/12/23/66/413c0bb5.jpg","nickname":"LDxy","note":"","ucode":"956432CE7B7761","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1045455,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/f3/cf/851dab01.jpg","nickname":"Milittle","note":"","ucode":"80E566639A8ABB","race_medal":0,"user_type":1,"is_pvip":true},"discussion":{"id":392520,"discussion_content":"这可不是什么历史包袱啊，常用的C编译器都能把乘除2^n的运算优化为对应的移位运算。所以没必要写成移位的方式，这样降低了代码的可读性","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631026045,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":386843,"ip_address":""},"score":392520,"extra":""},{"author":{"id":1045455,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/f3/cf/851dab01.jpg","nickname":"Milittle","note":"","ucode":"80E566639A8ABB","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1188710,"avatar":"https://static001.geekbang.org/account/avatar/00/12/23/66/413c0bb5.jpg","nickname":"LDxy","note":"","ucode":"956432CE7B7761","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":392564,"discussion_content":"可否给个链接，上面的也是估计，自认为从代码可读性有点牵强","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631061707,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":392520,"ip_address":""},"score":392564,"extra":""},{"author":{"id":1188710,"avatar":"https://static001.geekbang.org/account/avatar/00/12/23/66/413c0bb5.jpg","nickname":"LDxy","note":"","ucode":"956432CE7B7761","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1045455,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/f3/cf/851dab01.jpg","nickname":"Milittle","note":"","ucode":"80E566639A8ABB","race_medal":0,"user_type":1,"is_pvip":true},"discussion":{"id":392603,"discussion_content":"这是一个对于编译器来说非常容易实现的优化，目的就是让你在写代码时该用乘法时就大胆的用乘法，该用移位时就用移位，不需要考虑执行效率的问题。链接你可以看这个 https://qastack.cn/software/250635/when-i-test-out-the-difference-in-time-between-shifting-and-multiplying-in-c-th","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1631068487,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":392564,"ip_address":""},"score":392603,"extra":""}]},{"author":{"id":1045455,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/f3/cf/851dab01.jpg","nickname":"Milittle","note":"","ucode":"80E566639A8ABB","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":386842,"discussion_content":"第二个问题，我的理解是用来测试代码是否有bug的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627834565,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":2420294,"avatar":"https://static001.geekbang.org/account/avatar/00/24/ee/46/7d65ae37.jpg","nickname":"木几丶","note":"","ucode":"FFDB958DA64F8C","race_medal":5,"user_type":1,"is_pvip":true},"reply_author":{"id":1045455,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/f3/cf/851dab01.jpg","nickname":"Milittle","note":"","ucode":"80E566639A8ABB","race_medal":0,"user_type":1,"is_pvip":true},"discussion":{"id":386908,"discussion_content":"看了下应该是调试用的，自己业务代码里用的少，不太熟悉这种应用场景","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627889745,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":386842,"ip_address":""},"score":386908,"extra":""}]},{"author":{"id":1045455,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/f3/cf/851dab01.jpg","nickname":"Milittle","note":"","ucode":"80E566639A8ABB","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":386813,"discussion_content":"第一个问题：或的语法，会提前返回的，逻辑是如果有后台子进程，那么就会走到是否大于5的这个条件，仔细品😂是不是","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627814095,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":307317,"user_name":"云海","can_delete":false,"product_type":"c1","uid":1365206,"ip_address":"","ucode":"0C6CA0BE58EA21","user_header":"https://static001.geekbang.org/account/avatar/00/14/d4/d6/1d4543ac.jpg","comment_is_top":false,"comment_ctime":1629024696,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"5923991992","product_id":100084301,"comment_content":"如果当前表的已用空间大小为 size，那么就将表扩容到 size*2 的大小。<br>这里应该笔误了。<br>从_dictNextPower 可以看出，这里的描述有点歧义，size 应该是 hash 表的容量，而不是 hash 表已使用的空间。 <br>扩容是从 4开始一直乘以2，直到大于 当前已使用空间+1（下面代码里的size 实际是 used+1）<br>static unsigned long _dictNextPower(unsigned long size)<br>{<br>    unsigned long i = DICT_HT_INITIAL_SIZE;<br><br>    if (size &gt;= LONG_MAX) return LONG_MAX + 1LU;<br>    while(1) {<br>        if (i &gt;= size)<br>            return i;<br>        i *= 2;<br>    }<br>}","like_count":1,"discussions":[{"author":{"id":1318468,"avatar":"","nickname":"极客—月","note":"","ucode":"EE12EEBF242B1D","race_medal":1,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":577179,"discussion_content":"size就是used","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1655956580,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":305095,"user_name":".","can_delete":false,"product_type":"c1","uid":2460839,"ip_address":"","ucode":"1D7B236E828571","user_header":"https://static001.geekbang.org/account/avatar/00/25/8c/a7/3a696385.jpg","comment_is_top":false,"comment_ctime":1627809899,"is_pvip":false,"replies":[{"id":"110468","content":"dictRehash迁移的桶个数n，是dictRehash函数的参数，所以不是固定的。<br><br>以Redis 5.0.8代码为例，有两处调用了dictRehash，一个是_dictRehashStep函数（dict.c），这个函数传入的n是1；另一个是dictRehashMilliseconds函数(dict.c)， 这个函数传入的n是100。","user_name":"作者回复","user_name_real":"蒋德钧","uid":"1609687","ctime":1627980731,"ip_address":"","comment_id":305095,"utype":1}],"discussion_count":3,"race_medal":0,"score":"5922777195","product_id":100084301,"comment_content":"老师，您好！我有个疑问，dictRehash 进行迁移n个桶 ，这个n是固定吗？如果不是固定怎么确定呢？","like_count":2,"discussions":[{"author":{"id":1609687,"avatar":"https://static001.geekbang.org/account/avatar/00/18/8f/d7/fb60129d.jpg","nickname":"蒋德钧","note":"","ucode":"833985C2C37C0A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":524272,"discussion_content":"dictRehash迁移的桶个数n，是dictRehash函数的参数，所以不是固定的。\n\n以Redis 5.0.8代码为例，有两处调用了dictRehash，一个是_dictRehashStep函数（dict.c），这个函数传入的n是1；另一个是dictRehashMilliseconds函数(dict.c)， 这个函数传入的n是100。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627980731,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2420294,"avatar":"https://static001.geekbang.org/account/avatar/00/24/ee/46/7d65ae37.jpg","nickname":"木几丶","note":"","ucode":"FFDB958DA64F8C","race_medal":5,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":386915,"discussion_content":"如果是操作触发的迁移，那固定是1个桶；如果是系统定时触发的迁移，那一次会迁移100个桶。\n可以跟踪下dictRehash函数看下调用情况","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627890792,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1266052,"avatar":"https://static001.geekbang.org/account/avatar/00/13/51/84/5b7d4d95.jpg","nickname":"冷峰","note":"","ucode":"E6B7DA545E7961","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":386863,"discussion_content":"n为1，固定的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627867820,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":304926,"user_name":"可怜大灰狼","can_delete":false,"product_type":"c1","uid":1928373,"ip_address":"","ucode":"6CA9D6D460B967","user_header":"https://static001.geekbang.org/account/avatar/00/1d/6c/b5/32374f93.jpg","comment_is_top":false,"comment_ctime":1627704116,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"5922671412","product_id":100084301,"comment_content":"dict.c中dictGenHashFunction调用的是siphash.c中siphash方法。我想从MurmurHash2到siphash，也是看重哈希洪水攻击。不过java的HashMap还是通过平衡树来处理同一位置超过8个元素的哈希碰撞。","like_count":1},{"had_liked":false,"id":304916,"user_name":"Milittle","can_delete":false,"product_type":"c1","uid":1045455,"ip_address":"","ucode":"80E566639A8ABB","user_header":"https://static001.geekbang.org/account/avatar/00/0f/f3/cf/851dab01.jpg","comment_is_top":false,"comment_ctime":1627700596,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"5922667892","product_id":100084301,"comment_content":"使用的hash函数是siphash","like_count":1},{"had_liked":false,"id":355575,"user_name":"王飞","can_delete":false,"product_type":"c1","uid":3010843,"ip_address":"浙江","ucode":"5F029E870B200F","user_header":"https://static001.geekbang.org/account/avatar/00/2d/f1/1b/0957d4c5.jpg","comment_is_top":false,"comment_ctime":1661504387,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1661504387","product_id":100084301,"comment_content":"触发refresh条件：<br>\t① 负载因子(load factor)大于5<br>\t② 负载因子(load factor)大于等于1，且当前没有RDB子进程、也没有AOF子进程 (dict_can_resize = 1)","like_count":0},{"had_liked":false,"id":352656,"user_name":"问月","can_delete":false,"product_type":"c1","uid":2312847,"ip_address":"","ucode":"669B39C8768D0E","user_header":"https://static001.geekbang.org/account/avatar/00/23/4a/8f/ca11d7ad.jpg","comment_is_top":false,"comment_ctime":1658840307,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1658840307","product_id":100084301,"comment_content":"dictGetIterator dictGetSafeIterator 这两个有课代表总结么？ 看代码感觉safeIterator也不会safe， <br>1、定时任务会更新全局的dict<br>2、什么时候决定该用哪个，如果对于单线程来说，不是一般都是执行完这个线程就释放了么","like_count":0},{"had_liked":false,"id":350410,"user_name":"花花世界小人物","can_delete":false,"product_type":"c1","uid":2662844,"ip_address":"","ucode":"3E995D63845C06","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTL3xax4aG4h59x50C7LQ5K7BicvIEicakyfE0lV4Pyib6OsYc1jC7Qa37g2v8qhib5BQiaB2DfB4DMG5Cw/132","comment_is_top":false,"comment_ctime":1656902925,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1656902925","product_id":100084301,"comment_content":"老师有一点不明白<br>rehash 是两个数组之前的数据拷贝。在执行rehash但是未执行完成,有新增或者删除操作相当于更新了原本的h[0]数组，rehashidx是递增的，redis是怎么保证这个新增和删除的数据同步到h[1]的<br>我是做java,也试着去代码中找了，找的迷迷糊糊的也没搞清楚，老师见笑了","like_count":0},{"had_liked":false,"id":345470,"user_name":"Jaime","can_delete":false,"product_type":"c1","uid":1078333,"ip_address":"","ucode":"904192CC4E916F","user_header":"https://static001.geekbang.org/account/avatar/00/10/74/3d/54bbc1df.jpg","comment_is_top":false,"comment_ctime":1652315265,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1652315265","product_id":100084301,"comment_content":"使用了siphash算法，<br>uint64_t siphash(const uint8_t *in, const size_t inlen, const uint8_t *k) {<br>.....<br>}<br>","like_count":0},{"had_liked":false,"id":342236,"user_name":"再见理想","can_delete":false,"product_type":"c1","uid":1245999,"ip_address":"","ucode":"FAC88B3F6F6DFD","user_header":"https://static001.geekbang.org/account/avatar/00/13/03/2f/0a5e0751.jpg","comment_is_top":false,"comment_ctime":1650120982,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1650120982","product_id":100084301,"comment_content":"Redis主要的一种数据类型 和数据结构hash.<br>Hash表在使用中会面对两个问题 hash冲突和rehash<br>Redis使用hash链表的方式存储hash冲突的键值。<br>当hash的负载因子越来越大时，冲突会越来越多，导致hash的查询性能降低，这个时候就需要扩大hash的桶数量，redis使用渐进式rehash的方式，创建一个新的size*2的hash表，将现有hash表的数据迁移到新的表中，再将hash的指针引用到新的hash表，清空旧表，完成rehash操作。<br>Rehash的时机<br>负载因子大于1并且(可以扩容或者负载因子大于5)","like_count":0},{"had_liked":false,"id":335789,"user_name":"徐志超-Klaus","can_delete":false,"product_type":"c1","uid":2343086,"ip_address":"","ucode":"CF26B39965F2A2","user_header":"https://static001.geekbang.org/account/avatar/00/23/c0/ae/e5e62510.jpg","comment_is_top":false,"comment_ctime":1645689510,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1645689510","product_id":100084301,"comment_content":"Redis 的 Hashes是有存储顺序的吗？就像java的LinkedHashMap那样？hkeys 是按存储顺序返回的？","like_count":0},{"had_liked":false,"id":320419,"user_name":"Benson_Geek","can_delete":false,"product_type":"c1","uid":1519415,"ip_address":"","ucode":"D95B5C2BA09961","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/dr34H3hOMVsibL0XV1iaBWFiaTnYssX8sNjmJDpiaBUVv2X39nFzDjNpe288cKkZfH3P9sVRxZ1lzYZEcRR3vJNYtA/132","comment_is_top":false,"comment_ctime":1636303113,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"1636303113","product_id":100084301,"comment_content":"有个点始终想不明白。<br>看到源码dictFind函数，<br>dictEntry *dictFind(dict *d, const void *key)<br>{<br>    dictEntry *he;<br>    uint64_t h, idx, table;<br><br>    if (d-&gt;ht[0].used + d-&gt;ht[1].used == 0) return NULL; &#47;* dict is empty *&#47;<br>    if (dictIsRehashing(d)) _dictRehashStep(d);<br>    h = dictHashKey(d, key);<br>    for (table = 0; table &lt;= 1; table++) {<br>        idx = h &amp; d-&gt;ht[table].sizemask;<br>        he = d-&gt;ht[table].table[idx];<br>        while(he) {<br>            if (key==he-&gt;key || dictCompareKeys(d, key, he-&gt;key))<br>                return he;<br>            he = he-&gt;next;<br>        }<br>        if (!dictIsRehashing(d)) return NULL;<br>    }<br>    return NULL;<br>}<br>----<br><br>确实在查找的时候，rehash期间需要查找两个表，<br>我问题是，不是可以计算出当前要查询的key的index，然后跟ht[0]中的rehashidx对比一下，<br>要是index &lt; rehashidx，不就说明了这个key所在的bucket已经是搬迁完毕到ht[1]中了？<br>那么这时候就直接去读ht[1]，而不用读一遍ht[0]，再读一遍ht[1]这样两次读操作。<br>求大佬们谁能解答一下我这个疑问，是否有啥原因而不能这么做？？？<br>我都能想到这种方式减少一次读没理由官方想不到？跪求解！！！","like_count":0,"discussions":[{"author":{"id":2542376,"avatar":"https://static001.geekbang.org/account/avatar/00/26/cb/28/21a8a29e.jpg","nickname":"夏天","note":"","ucode":"5F224DDAC94DFF","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":551749,"discussion_content":"这里感觉没啥必要改。if 比较和数组定位时间差不了多少。大概率都在 table[0]，rehash 毕竟是少数操作。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1645102875,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1008257,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/62/81/ad80f427.jpg","nickname":"Lane","note":"","ucode":"F70459D1BBD9F4","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":533004,"discussion_content":"同问。  我拍脑门想：不rehash时100%在table[0]里，rehash时有50%的可能会直接在table[0]中拿到，而rehash又是少数情况，所以直接从table[0]中拿是可以满足觉大多数情况的。  但是，if idx&gt;rehashidx也不耗资源啊","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1637752598,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"user_type\":1}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":313690,"user_name":"thomas","can_delete":false,"product_type":"c1","uid":1016777,"ip_address":"","ucode":"9AB945308F1B50","user_header":"https://static001.geekbang.org/account/avatar/00/0f/83/c9/5d03981a.jpg","comment_is_top":false,"comment_ctime":1632621719,"is_pvip":true,"discussion_count":2,"race_medal":0,"score":"1632621719","product_id":100084301,"comment_content":"&#47;&#47;将当前哈希项添加到扩容后的哈希表ht[1]中        <br>de-&gt;next = d-&gt;ht[1].table[h];       第一步<br>d-&gt;ht[1].table[h] = de;<br>---------------------------------------&gt;<br>没想明白，为什么需要第一步的操作？","like_count":0,"discussions":[{"author":{"id":1657561,"avatar":"https://static001.geekbang.org/account/avatar/00/19/4a/d9/b8046b4b.jpg","nickname":"zhangm365","note":"","ucode":"60E7DEFB3F5840","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":402328,"discussion_content":"头插法插入链表中","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1633864856,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2028409,"avatar":"https://static001.geekbang.org/account/avatar/00/1e/f3/79/9ef9213f.jpg","nickname":"Dream","note":"","ucode":"04F084107098D8","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":401883,"discussion_content":"以de为头节点插入，后面跟着之前的链表","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633757984,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":313521,"user_name":"路遥知码力","can_delete":false,"product_type":"c1","uid":2698825,"ip_address":"","ucode":"1EF9655BEDAFA6","user_header":"https://static001.geekbang.org/account/avatar/00/29/2e/49/a04480a9.jpg","comment_is_top":false,"comment_ctime":1632473297,"is_pvip":true,"discussion_count":1,"race_medal":0,"score":"1632473297","product_id":100084301,"comment_content":"有一个疑问，如果rehash的过程中，因为数据量的暴增（默认扩容是size*2n次方），新设置的rehashht[1]在可以预见完全迁移数据的未来，也不够了（预见性发生hash冲突），甚至超过了强制rehash值dict_force_resize_ratio，咋办？","like_count":0,"discussions":[{"author":{"id":2698825,"avatar":"https://static001.geekbang.org/account/avatar/00/29/2e/49/a04480a9.jpg","nickname":"路遥知码力","note":"","ucode":"1EF9655BEDAFA6","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":397229,"discussion_content":"源码里有答案：redis不管这种情况，因为永远只有ht[0]和ht[1]，只有rehashidx=-1，从进行一下轮的rehash。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1632578890,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":310566,"user_name":"lhgdy","can_delete":false,"product_type":"c1","uid":1301502,"ip_address":"","ucode":"92140E9AB7659A","user_header":"https://static001.geekbang.org/account/avatar/00/13/db/fe/90446b61.jpg","comment_is_top":false,"comment_ctime":1630746824,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1630746824","product_id":100084301,"comment_content":"int dictExpand(dict *d, unsigned long size)<br>{<br>    &#47;* the size is invalid if it is smaller than the number of<br>     * elements already inside the hash table *&#47;<br>    if (dictIsRehashing(d) || d-&gt;ht[0].used &gt; size)<br>        return DICT_ERR;<br><br>    dictht n; &#47;* the new hash table *&#47;                                      这个地方是局部变量吧？ 局部变量被赋值给别的变量后还是会产生内存问题的吧？  请大佬解读下<br>    unsigned long realsize = _dictNextPower(size);<br><br>    &#47;* Rehashing to the same table size is not useful. *&#47;<br>    if (realsize == d-&gt;ht[0].size) return DICT_ERR;<br><br>    &#47;* Allocate the new hash table and initialize all pointers to NULL *&#47;<br>    n.size = realsize;<br>    n.sizemask = realsize-1;<br>    n.table = zcalloc(realsize*sizeof(dictEntry*));<br>    n.used = 0;<br><br>    &#47;* Is this the first initialization? If so it&#39;s not really a rehashing<br>     * we just set the first hash table so that it can accept keys. *&#47;<br>    if (d-&gt;ht[0].table == NULL) {<br>        d-&gt;ht[0] = n;<br>        return DICT_OK;<br>    }<br><br>    &#47;* Prepare a second hash table for incremental rehashing *&#47;<br>    d-&gt;ht[1] = n;<br>    d-&gt;rehashidx = 0;<br>    return DICT_OK;<br>}<br>","like_count":0},{"had_liked":false,"id":310278,"user_name":"请叫我猿叔叔","can_delete":false,"product_type":"c1","uid":1460069,"ip_address":"","ucode":"44BD74AF78E1DF","user_header":"https://static001.geekbang.org/account/avatar/00/16/47/65/5534850b.jpg","comment_is_top":false,"comment_ctime":1630575932,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1630575932","product_id":100084301,"comment_content":"想问一下渐进式是根据bucket来操作的，  一个hash里面bucket的数量是怎么决定的","like_count":0,"discussions":[{"author":{"id":2542376,"avatar":"https://static001.geekbang.org/account/avatar/00/26/cb/28/21a8a29e.jpg","nickname":"夏天","note":"","ucode":"5F224DDAC94DFF","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":551753,"discussion_content":"参数决定的，定时迁移，每个 bucket 大小为 1000。操作里迁移，每个 bucket 大小为 10","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1645103399,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":310171,"user_name":"ikel","can_delete":false,"product_type":"c1","uid":1009002,"ip_address":"","ucode":"1D5CE7803C1C2B","user_header":"https://static001.geekbang.org/account/avatar/00/0f/65/6a/be36c108.jpg","comment_is_top":false,"comment_ctime":1630510764,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1630510764","product_id":100084301,"comment_content":"rehash是把ht[0]数据在ht[1]中用两倍的桶数量存，然后再把数据完整拷贝回ht[0]？程序会根据数据量大小自动rehash么","like_count":0,"discussions":[{"author":{"id":2542376,"avatar":"https://static001.geekbang.org/account/avatar/00/26/cb/28/21a8a29e.jpg","nickname":"夏天","note":"","ucode":"5F224DDAC94DFF","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":551757,"discussion_content":"不用拷啦，交换指针就好","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1645104054,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":309965,"user_name":"伟伟哦","can_delete":false,"product_type":"c1","uid":1394961,"ip_address":"","ucode":"51E5FC28E6F0B3","user_header":"https://static001.geekbang.org/account/avatar/00/15/49/11/31d961a1.jpg","comment_is_top":false,"comment_ctime":1630416574,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"1630416574","product_id":100084301,"comment_content":"老师 我有一点没懂 <br>rehash以后，会出现   ht[0] 和 ht[1]两个哈希表。<br>ht[0]迁移到ht[1] ,如果ht[1]要是满了，会有ht[2] 、ht[3]以此类推吗？<br>","like_count":0,"discussions":[{"author":{"id":2542376,"avatar":"https://static001.geekbang.org/account/avatar/00/26/cb/28/21a8a29e.jpg","nickname":"夏天","note":"","ucode":"5F224DDAC94DFF","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":551758,"discussion_content":"不会，ht[0] 满了，扩容 ht[1]，然后将 ht[1] 和 ht[0] 交换，释放 ht[1]。总之 ht[0] 永远是核心的 table","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1645104123,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2420294,"avatar":"https://static001.geekbang.org/account/avatar/00/24/ee/46/7d65ae37.jpg","nickname":"木几丶","note":"","ucode":"FFDB958DA64F8C","race_medal":5,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":400082,"discussion_content":"ht[1]满了就用ht[0]，他俩轮着倒","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633160697,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":309825,"user_name":"King","can_delete":false,"product_type":"c1","uid":1360108,"ip_address":"","ucode":"6AA0FF81FA05D3","user_header":"https://static001.geekbang.org/account/avatar/00/14/c0/ec/1403f7b2.jpg","comment_is_top":false,"comment_ctime":1630348702,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1630348702","product_id":100084301,"comment_content":"老师，如果在rehash的过程中，添加了大量的数据，导致在rehash的过程中满足了，Hash表承载的元素个数已是当前大小的5倍，导致进行扩容，此时的h0还有数据，没办法释放，此时的Redis会怎样处理呢？","like_count":0,"discussions":[{"author":{"id":2542376,"avatar":"https://static001.geekbang.org/account/avatar/00/26/cb/28/21a8a29e.jpg","nickname":"夏天","note":"","ucode":"5F224DDAC94DFF","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":551760,"discussion_content":"不管的，要等当前 rehash 结束","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1645104314,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":309788,"user_name":"test","can_delete":false,"product_type":"c1","uid":1065849,"ip_address":"","ucode":"9A4973E591DD12","user_header":"https://static001.geekbang.org/account/avatar/00/10/43/79/18073134.jpg","comment_is_top":false,"comment_ctime":1630333449,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1630333449","product_id":100084301,"comment_content":"dict使用的siphash。","like_count":0},{"had_liked":false,"id":309050,"user_name":"日落黄昏下","can_delete":false,"product_type":"c1","uid":1464032,"ip_address":"","ucode":"A97725B81D86BC","user_header":"https://static001.geekbang.org/account/avatar/00/16/56/e0/d34f57b3.jpg","comment_is_top":false,"comment_ctime":1629904725,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1629904725","product_id":100084301,"comment_content":"我看源码好像扩容并不是双倍的used大小，在_dictNextPower中要计算出来的新容量是2的n次幂。","like_count":0,"discussions":[{"author":{"id":2542376,"avatar":"https://static001.geekbang.org/account/avatar/00/26/cb/28/21a8a29e.jpg","nickname":"夏天","note":"","ucode":"5F224DDAC94DFF","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":551763,"discussion_content":"对的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1645104723,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":307218,"user_name":"n的n次方","can_delete":false,"product_type":"c1","uid":2054237,"ip_address":"","ucode":"4053B5444222FC","user_header":"https://static001.geekbang.org/account/avatar/00/1f/58/5d/bb5f1ec5.jpg","comment_is_top":false,"comment_ctime":1628944345,"is_pvip":false,"discussion_count":2,"race_medal":1,"score":"1628944345","product_id":100084301,"comment_content":"希望老师不要说什么大厂面试，合着看书就是为了面试？为了大厂面试也不是您这本书的卖点","like_count":0,"discussions":[{"author":{"id":1024994,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/a3/e2/5cb4f43f.jpg","nickname":"laolinshi","note":"","ucode":"269B879389D7D5","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":557259,"discussion_content":"人家面试就喜欢问这样的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1647743922,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1197964,"avatar":"https://static001.geekbang.org/account/avatar/00/12/47/8c/9708a8c5.jpg","nickname":"XIII","note":"","ucode":"14ACE12BF06D64","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":390219,"discussion_content":"ETC","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1629716953,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":306812,"user_name":"gogocx123","can_delete":false,"product_type":"c1","uid":2035421,"ip_address":"","ucode":"DA9C6C51597455","user_header":"https://static001.geekbang.org/account/avatar/00/1f/0e/dd/9fa6b37f.jpg","comment_is_top":false,"comment_ctime":1628733093,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1628733093","product_id":100084301,"comment_content":"static unsigned int dictGenHashFunction(const unsigned char *buf, int len) {<br>    unsigned int hash = 5381;<br><br>    while (len--)<br>        hash = ((hash &lt;&lt; 5) + hash) + (*buf++); &#47;* hash * 33 + c *&#47;<br>    return hash;<br>}<br>","like_count":0},{"had_liked":false,"id":305796,"user_name":"91、洲先生","can_delete":false,"product_type":"c1","uid":1136904,"ip_address":"","ucode":"285C552078E192","user_header":"https://static001.geekbang.org/account/avatar/00/11/59/08/e33bfa11.jpg","comment_is_top":false,"comment_ctime":1628167577,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1628167577","product_id":100084301,"comment_content":"dictRehash触发的方式有两种，一种是以定时任务的形式注册在service启动的时候，另一种就是增删改的时候每次迁移哈希表中一个桶，为什么后面这种方式还需要看私有数据中那个迭代器是否安全，而第一种却不考虑是否安全呢？","like_count":0},{"had_liked":false,"id":305531,"user_name":"thomas","can_delete":false,"product_type":"c1","uid":1016777,"ip_address":"","ucode":"9AB945308F1B50","user_header":"https://static001.geekbang.org/account/avatar/00/0f/83/c9/5d03981a.jpg","comment_is_top":false,"comment_ctime":1628034955,"is_pvip":true,"discussion_count":2,"race_medal":0,"score":"1628034955","product_id":100084301,"comment_content":"结构体dictht中sizemask的作用是什么？","like_count":0,"discussions":[{"author":{"id":2420294,"avatar":"https://static001.geekbang.org/account/avatar/00/24/ee/46/7d65ae37.jpg","nickname":"木几丶","note":"","ucode":"FFDB958DA64F8C","race_medal":5,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":387214,"discussion_content":"掩码，用于计算索引值，比如哈希表长度是8，那sizemark就是7，如果一个key hash值是8，跟7做&amp;操作后就是0，表示在第0个桶","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1628057055,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2698825,"avatar":"https://static001.geekbang.org/account/avatar/00/29/2e/49/a04480a9.jpg","nickname":"路遥知码力","note":"","ucode":"1EF9655BEDAFA6","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":396653,"discussion_content":"先获得hash值，再进行索引值计算，index = hash&amp;dict->ht[0].sizemask = 8 &amp; 3 = 0","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1632470907,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":305238,"user_name":"BrightLoong","can_delete":false,"product_type":"c1","uid":1165304,"ip_address":"","ucode":"361FB1840C2977","user_header":"https://static001.geekbang.org/account/avatar/00/11/c7/f8/6b311ad9.jpg","comment_is_top":false,"comment_ctime":1627889531,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"1627889531","product_id":100084301,"comment_content":"<br>typedef struct dictht {<br>    dictEntry **table; &#47;&#47;二维数组<br>    unsigned long size; &#47;&#47;Hash表大小<br>    unsigned long sizemask;<br>    unsigned long used;<br>} dictht;<br><br>不太明白这里为什么是个二维数组，不应该是一维数组里面存的指向 dictEntry 的指针吗，C语言已经忘差不多了，不太理解，我是觉得按照hashtable的数据结构来看，就应该是个一维数组。","like_count":0,"discussions":[{"author":{"id":1107305,"avatar":"https://static001.geekbang.org/account/avatar/00/10/e5/69/719ec5d0.jpg","nickname":"Jian","note":"","ucode":"17ED4919F22DEC","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":388692,"discussion_content":"你也可以不把它当成二维数组，把它当做一维数组，只是一维数组的元素是指针","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1628914150,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1197964,"avatar":"https://static001.geekbang.org/account/avatar/00/12/47/8c/9708a8c5.jpg","nickname":"XIII","note":"","ucode":"14ACE12BF06D64","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":388477,"discussion_content":"二维数组，是数组的数组，外面的数组是桶，桶里面的数组是 dictEntry  组成的链式结构","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1628777022,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":304987,"user_name":"董宗磊","can_delete":false,"product_type":"c1","uid":1095445,"ip_address":"","ucode":"D7005A328BC2EE","user_header":"https://static001.geekbang.org/account/avatar/00/10/b7/15/6a2b6b83.jpg","comment_is_top":false,"comment_ctime":1627734376,"is_pvip":false,"discussion_count":3,"race_medal":0,"score":"1627734376","product_id":100084301,"comment_content":"static final int tableSizeFor(int cap) {<br>        int n = cap - 1;<br>        n |= n &gt;&gt;&gt; 1;<br>        n |= n &gt;&gt;&gt; 2;<br>        n |= n &gt;&gt;&gt; 4;<br>        n |= n &gt;&gt;&gt; 8;<br>        n |= n &gt;&gt;&gt; 16;<br>        return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;<br>    }<br><br>redis 是不是可以参考 JDK 里面初始化 HashMap 容量的算法，这个时间复杂度 O(1)， Redis 中的 O(logN) 啊？","like_count":0,"discussions":[{"author":{"id":1365206,"avatar":"https://static001.geekbang.org/account/avatar/00/14/d4/d6/1d4543ac.jpg","nickname":"云海","note":"","ucode":"0C6CA0BE58EA21","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":388928,"discussion_content":"antirez 针对这个问题做过说明的，这里的扩容仅在hash表调整大小时调用，调用次数很少。现有的方法已经足够快了，新方法在实际使用中没有太多差异，所以没有必要引入更加复杂的代码了。\n\nantirez commented on 8 Jun 2018\nHey, I feel like this will never be important, since computing the power of two even with a stupid algorithm is always fast enough for the dict.c case, it is impossible to see any difference in the real world, so why adding more complex code?\n\n原文地址：https://github.com/redis/redis/pull/4774 ","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1629045784,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2268230,"avatar":"","nickname":"zeus-01","note":"","ucode":"3F3F7C6C43923B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":387895,"discussion_content":"+1,忽略这一细节","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1628491084,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2420294,"avatar":"https://static001.geekbang.org/account/avatar/00/24/ee/46/7d65ae37.jpg","nickname":"木几丶","note":"","ucode":"FFDB958DA64F8C","race_medal":5,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":386917,"discussion_content":"+1","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627891285,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":304985,"user_name":"董宗磊","can_delete":false,"product_type":"c1","uid":1095445,"ip_address":"","ucode":"D7005A328BC2EE","user_header":"https://static001.geekbang.org/account/avatar/00/10/b7/15/6a2b6b83.jpg","comment_is_top":false,"comment_ctime":1627733749,"is_pvip":false,"replies":[{"id":"110484","content":"是的。这个时候Redis的设计考虑是，hash表的负载已经很重了，bucket的链表可能比较长了，对Redis性能影响比较大了。此时，就需要做rehash扩容，以便减少bucket链表长度。","user_name":"作者回复","user_name_real":"蒋德钧","uid":"1609687","ctime":1628040308,"ip_address":"","comment_id":304985,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1627733749","product_id":100084301,"comment_content":"老师，当负载因子 &gt; 5 的时候，是不是就不再考虑有没有 RDB 或者 AOF 进程在运行？？","like_count":0,"discussions":[{"author":{"id":1609687,"avatar":"https://static001.geekbang.org/account/avatar/00/18/8f/d7/fb60129d.jpg","nickname":"蒋德钧","note":"","ucode":"833985C2C37C0A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":524237,"discussion_content":"是的。这个时候Redis的设计考虑是，hash表的负载已经很重了，bucket的链表可能比较长了，对Redis性能影响比较大了。此时，就需要做rehash扩容，以便减少bucket链表长度。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1628040308,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1045455,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/f3/cf/851dab01.jpg","nickname":"Milittle","note":"","ucode":"80E566639A8ABB","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":386804,"discussion_content":"yes","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627809602,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":304984,"user_name":"董宗磊","can_delete":false,"product_type":"c1","uid":1095445,"ip_address":"","ucode":"D7005A328BC2EE","user_header":"https://static001.geekbang.org/account/avatar/00/10/b7/15/6a2b6b83.jpg","comment_is_top":false,"comment_ctime":1627733027,"is_pvip":false,"discussion_count":4,"race_medal":0,"score":"1627733027","product_id":100084301,"comment_content":"我之所以要提醒你注意这里，其实是为了说明，这种实现方法是一种节省内存的开发小技巧，非常值得学习。因为当值为整数或双精度浮点数时，由于其本身就是 64 位，就可以不用指针指向了，而是可以直接存在键值对的结构体中，这样就避免了再用一个指针，从而节省了内存空间。<br><br>老师，这段内容是什么意思，不太懂呢？？","like_count":0,"discussions":[{"author":{"id":2488913,"avatar":"https://static001.geekbang.org/account/avatar/00/25/fa/51/5da91010.jpg","nickname":"Miroticwillbeforever","note":"","ucode":"1DDD8AECD93EA8","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":388532,"discussion_content":"我的理解是。union 联合体中不是有一个 void * val 。这个 val 作为指针指向了一个值。\n这个值本身时 64位的话，就直接在这个 union 存就好了。不用再花一个指针的空间额外开销去指向。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1628825524,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1133945,"avatar":"https://static001.geekbang.org/account/avatar/00/11/4d/79/803537db.jpg","nickname":"慢动作","note":"","ucode":"62C944F4A4D8AC","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":2488913,"avatar":"https://static001.geekbang.org/account/avatar/00/25/fa/51/5da91010.jpg","nickname":"Miroticwillbeforever","note":"","ucode":"1DDD8AECD93EA8","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":389263,"discussion_content":"道理很浅显，不知道怎么操作，不熟悉c","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1629196276,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":388532,"ip_address":""},"score":389263,"extra":""}]},{"author":{"id":2420294,"avatar":"https://static001.geekbang.org/account/avatar/00/24/ee/46/7d65ae37.jpg","nickname":"木几丶","note":"","ucode":"FFDB958DA64F8C","race_medal":5,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":386918,"discussion_content":"假如值是double类型且用了指针，那内存消耗就是结构体里的指针内存+double自身内存，而如果这个double直接存在结构体中就只需要double自身内存省去指针的内存","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627891572,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1045455,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/f3/cf/851dab01.jpg","nickname":"Milittle","note":"","ucode":"80E566639A8ABB","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":386803,"discussion_content":"union是一个联合体，一个指针在64平台就占64位，如果一个val可以直接用值表示，就不需要额外的指针占用了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627809594,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}