{"id":80147,"title":"35 | join语句怎么优化？","content":"<p>在上一篇文章中，我和你介绍了join语句的两种算法，分别是Index Nested-Loop Join(NLJ)和Block Nested-Loop Join(BNL)。</p><p>我们发现在使用NLJ算法的时候，其实效果还是不错的，比通过应用层拆分成多个语句然后再拼接查询结果更方便，而且性能也不会差。</p><p>但是，BNL算法在大表join的时候性能就差多了，比较次数等于两个表参与join的行数的乘积，很消耗CPU资源。</p><p>当然了，这两个算法都还有继续优化的空间，我们今天就来聊聊这个话题。</p><p>为了便于分析，我还是创建两个表t1、t2来和你展开今天的问题。</p><pre><code>create table t1(id int primary key, a int, b int, index(a));\ncreate table t2 like t1;\ndrop procedure idata;\ndelimiter ;;\ncreate procedure idata()\nbegin\n  declare i int;\n  set i=1;\n  while(i&lt;=1000)do\n    insert into t1 values(i, 1001-i, i);\n    set i=i+1;\n  end while;\n  \n  set i=1;\n  while(i&lt;=1000000)do\n    insert into t2 values(i, i, i);\n    set i=i+1;\n  end while;\n\nend;;\ndelimiter ;\ncall idata();\n</code></pre><p>为了便于后面量化说明，我在表t1里，插入了1000行数据，每一行的a=1001-id的值。也就是说，表t1中字段a是逆序的。同时，我在表t2中插入了100万行数据。</p><h1>Multi-Range Read优化</h1><p>在介绍join语句的优化方案之前，我需要先和你介绍一个知识点，即：Multi-Range Read优化(MRR)。这个优化的主要目的是尽量使用顺序读盘。</p><p>在<a href=\"https://time.geekbang.org/column/article/69236\">第4篇文章</a>中，我和你介绍InnoDB的索引结构时，提到了“回表”的概念。我们先来回顾一下这个概念。回表是指，InnoDB在普通索引a上查到主键id的值后，再根据一个个主键id的值到主键索引上去查整行数据的过程。</p><!-- [[[read_end]]] --><p>然后，有同学在留言区问到，回表过程是一行行地查数据，还是批量地查数据？</p><p>我们先来看看这个问题。假设，我执行这个语句：</p><pre><code>select * from t1 where a&gt;=1 and a&lt;=100;\n</code></pre><p>主键索引是一棵B+树，在这棵树上，每次只能根据一个主键id查到一行数据。因此，回表肯定是一行行搜索主键索引的，基本流程如图1所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/97/05/97ae269061192f6d7a632df56fa03605.png?wh=1142*880\" alt=\"\"></p><center><span class=\"reference\">图1 基本回表流程</span></center><p>如果随着a的值递增顺序查询的话，id的值就变成随机的，那么就会出现随机访问，性能相对较差。虽然“按行查”这个机制不能改，但是调整查询的顺序，还是能够加速的。</p><p><strong>因为大多数的数据都是按照主键递增顺序插入得到的，所以我们可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。</strong></p><p>这，就是MRR优化的设计思路。此时，语句的执行流程变成了这样：</p><ol>\n<li>\n<p>根据索引a，定位到满足条件的记录，将id值放入read_rnd_buffer中;</p>\n</li>\n<li>\n<p>将read_rnd_buffer中的id进行递增排序；</p>\n</li>\n<li>\n<p>排序后的id数组，依次到主键id索引中查记录，并作为结果返回。</p>\n</li>\n</ol><p>这里，read_rnd_buffer的大小是由read_rnd_buffer_size参数控制的。如果步骤1中，read_rnd_buffer放满了，就会先执行完步骤2和3，然后清空read_rnd_buffer。之后继续找索引a的下个记录，并继续循环。</p><p>另外需要说明的是，如果你想要稳定地使用MRR优化的话，需要设置<code>set optimizer_switch=\"mrr_cost_based=off\"</code>。（官方文档的说法，是现在的优化器策略，判断消耗的时候，会更倾向于不使用MRR，把mrr_cost_based设置为off，就是固定使用MRR了。）</p><p>下面两幅图就是使用了MRR优化后的执行流程和explain结果。</p><p><img src=\"https://static001.geekbang.org/resource/image/d5/c7/d502fbaea7cac6f815c626b078da86c7.jpg?wh=1142*880\" alt=\"\"></p><center><span class=\"reference\">图2 MRR执行流程</span></center><p><img src=\"https://static001.geekbang.org/resource/image/a5/32/a513d07ebaf1ae044d44391c89bc6432.png?wh=1583*149\" alt=\"\"></p><center><span class=\"reference\">图3 MRR执行流程的explain结果</span></center><p>从图3的explain结果中，我们可以看到Extra字段多了Using MRR，表示的是用上了MRR优化。而且，由于我们在read_rnd_buffer中按照id做了排序，所以最后得到的结果集也是按照主键id递增顺序的，也就是与图1结果集中行的顺序相反。</p><p>到这里，我们小结一下。</p><p><strong>MRR能够提升性能的核心</strong>在于，这条查询语句在索引a上做的是一个范围查询（也就是说，这是一个多值查询），可以得到足够多的主键id。这样通过排序以后，再去主键索引查数据，才能体现出“顺序性”的优势。</p><h1>Batched Key Access</h1><p>理解了MRR性能提升的原理，我们就能理解MySQL在5.6版本后开始引入的Batched Key Access(BKA)算法了。这个BKA算法，其实就是对NLJ算法的优化。</p><p>我们再来看看上一篇文章中用到的NLJ算法的流程图：</p><p><img src=\"https://static001.geekbang.org/resource/image/10/3d/10e14e8b9691ac6337d457172b641a3d.jpg?wh=1142*880\" alt=\"\"></p><center><span class=\"reference\">图4 Index Nested-Loop Join流程图</span></center><p>NLJ算法执行的逻辑是：从驱动表t1，一行行地取出a的值，再到被驱动表t2去做join。也就是说，对于表t2来说，每次都是匹配一个值。这时，MRR的优势就用不上了。</p><p>那怎么才能一次性地多传些值给表t2呢？方法就是，从表t1里一次性地多拿些行出来，一起传给表t2。</p><p>既然如此，我们就把表t1的数据取出来一部分，先放到一个临时内存。这个临时内存不是别人，就是join_buffer。</p><p>通过上一篇文章，我们知道join_buffer 在BNL算法里的作用，是暂存驱动表的数据。但是在NLJ算法里并没有用。那么，我们刚好就可以复用join_buffer到BKA算法中。</p><p>如图5所示，是上面的NLJ算法优化后的BKA算法的流程。</p><p><img src=\"https://static001.geekbang.org/resource/image/68/88/682370c5640244fa3474d26cc3bc0388.png?wh=1142*880\" alt=\"\"></p><center><span class=\"reference\">图5 Batched Key Access流程</span></center><p>图中，我在join_buffer中放入的数据是P1~P100，表示的是只会取查询需要的字段。当然，如果join buffer放不下P1~P100的所有数据，就会把这100行数据分成多段执行上图的流程。</p><p>那么，这个BKA算法到底要怎么启用呢？</p><p>如果要使用BKA优化算法的话，你需要在执行SQL语句之前，先设置</p><pre><code>set optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';\n</code></pre><p>其中，前两个参数的作用是要启用MRR。这么做的原因是，BKA算法的优化要依赖于MRR。</p><h1>BNL算法的性能问题</h1><p>说完了NLJ算法的优化，我们再来看BNL算法的优化。</p><p>我在上一篇文章末尾，给你留下的思考题是，使用Block Nested-Loop Join(BNL)算法时，可能会对被驱动表做多次扫描。如果这个被驱动表是一个大的冷数据表，除了会导致IO压力大以外，还会对系统有什么影响呢？</p><p>在<a href=\"https://time.geekbang.org/column/article/79407\">第33篇文章</a>中，我们说到InnoDB的LRU算法的时候提到，由于InnoDB对Bufffer Pool的LRU算法做了优化，即：第一次从磁盘读入内存的数据页，会先放在old区域。如果1秒之后这个数据页不再被访问了，就不会被移动到LRU链表头部，这样对Buffer Pool的命中率影响就不大。</p><p>但是，如果一个使用BNL算法的join语句，多次扫描一个冷表，而且这个语句执行时间超过1秒，就会在再次扫描冷表的时候，把冷表的数据页移到LRU链表头部。</p><p>这种情况对应的，是冷表的数据量小于整个Buffer Pool的3/8，能够完全放入old区域的情况。</p><p>如果这个冷表很大，就会出现另外一种情况：业务正常访问的数据页，没有机会进入young区域。</p><p>由于优化机制的存在，一个正常访问的数据页，要进入young区域，需要隔1秒后再次被访问到。但是，由于我们的join语句在循环读磁盘和淘汰内存页，进入old区域的数据页，很可能在1秒之内就被淘汰了。这样，就会导致这个MySQL实例的Buffer Pool在这段时间内，young区域的数据页没有被合理地淘汰。</p><p>也就是说，这两种情况都会影响Buffer Pool的正常运作。</p><p><strong>大表join操作虽然对IO有影响，但是在语句执行结束后，对IO的影响也就结束了。但是，对Buffer Pool的影响就是持续性的，需要依靠后续的查询请求慢慢恢复内存命中率。</strong></p><p>为了减少这种影响，你可以考虑增大join_buffer_size的值，减少对被驱动表的扫描次数。</p><p>也就是说，BNL算法对系统的影响主要包括三个方面：</p><ol>\n<li>\n<p>可能会多次扫描被驱动表，占用磁盘IO资源；</p>\n</li>\n<li>\n<p>判断join条件需要执行M*N次对比（M、N分别是两张表的行数），如果是大表就会占用非常多的CPU资源；</p>\n</li>\n<li>\n<p>可能会导致Buffer Pool的热数据被淘汰，影响内存命中率。</p>\n</li>\n</ol><p>我们执行语句之前，需要通过理论分析和查看explain结果的方式，确认是否要使用BNL算法。如果确认优化器会使用BNL算法，就需要做优化。优化的常见做法是，给被驱动表的join字段加上索引，把BNL算法转成BKA算法。</p><p>接下来，我们就具体看看，这个优化怎么做？</p><h1>BNL转BKA</h1><p>一些情况下，我们可以直接在被驱动表上建索引，这时就可以直接转成BKA算法了。</p><p>但是，有时候你确实会碰到一些不适合在被驱动表上建索引的情况。比如下面这个语句：</p><pre><code>select * from t1 join t2 on (t1.b=t2.b) where t2.b&gt;=1 and t2.b&lt;=2000;\n</code></pre><p>我们在文章开始的时候，在表t2中插入了100万行数据，但是经过where条件过滤后，需要参与join的只有2000行数据。如果这条语句同时是一个低频的SQL语句，那么再为这个语句在表t2的字段b上创建一个索引就很浪费了。</p><p>但是，如果使用BNL算法来join的话，这个语句的执行流程是这样的：</p><ol>\n<li>\n<p>把表t1的所有字段取出来，存入join_buffer中。这个表只有1000行，join_buffer_size默认值是256k，可以完全存入。</p>\n</li>\n<li>\n<p>扫描表t2，取出每一行数据跟join_buffer中的数据进行对比，</p>\n<ul>\n<li>如果不满足t1.b=t2.b，则跳过；</li>\n<li>如果满足t1.b=t2.b, 再判断其他条件，也就是是否满足t2.b处于[1,2000]的条件，如果是，就作为结果集的一部分返回，否则跳过。</li>\n</ul>\n</li>\n</ol><p>我在上一篇文章中说过，对于表t2的每一行，判断join是否满足的时候，都需要遍历join_buffer中的所有行。因此判断等值条件的次数是1000*100万=10亿次，这个判断的工作量很大。</p><p><img src=\"https://static001.geekbang.org/resource/image/92/60/92fbdbfc35da3040396401250cb33f60.png?wh=1776*169\" alt=\"\"></p><center><span class=\"reference\">图6 explain结果</span></center><p><img src=\"https://static001.geekbang.org/resource/image/d8/9c/d862bc3e88305688df2c354a4b26809c.png?wh=550*130\" alt=\"\"></p><center><span class=\"reference\">图7 语句执行时间</span></center><p>可以看到，explain结果里Extra字段显示使用了BNL算法。在我的测试环境里，这条语句需要执行1分11秒。</p><p>在表t2的字段b上创建索引会浪费资源，但是不创建索引的话这个语句的等值条件要判断10亿次，想想也是浪费。那么，有没有两全其美的办法呢？</p><p>这时候，我们可以考虑使用临时表。使用临时表的大致思路是：</p><ol>\n<li>\n<p>把表t2中满足条件的数据放在临时表tmp_t中；</p>\n</li>\n<li>\n<p>为了让join使用BKA算法，给临时表tmp_t的字段b加上索引；</p>\n</li>\n<li>\n<p>让表t1和tmp_t做join操作。</p>\n</li>\n</ol><p>此时，对应的SQL语句的写法如下：</p><pre><code>create temporary table temp_t(id int primary key, a int, b int, index(b))engine=innodb;\ninsert into temp_t select * from t2 where b&gt;=1 and b&lt;=2000;\nselect * from t1 join temp_t on (t1.b=temp_t.b);\n</code></pre><p>图8就是这个语句序列的执行效果。</p><p><img src=\"https://static001.geekbang.org/resource/image/a8/c7/a80cdffe8173fa0fd8969ed976ac6ac7.png?wh=1130*547\" alt=\"\"></p><center> 图8 使用临时表的执行效果</center><p>可以看到，整个过程3个语句执行时间的总和还不到1秒，相比于前面的1分11秒，性能得到了大幅提升。接下来，我们一起看一下这个过程的消耗：</p><ol>\n<li>\n<p>执行insert语句构造temp_t表并插入数据的过程中，对表t2做了全表扫描，这里扫描行数是100万。</p>\n</li>\n<li>\n<p>之后的join语句，扫描表t1，这里的扫描行数是1000；join比较过程中，做了1000次带索引的查询。相比于优化前的join语句需要做10亿次条件判断来说，这个优化效果还是很明显的。</p>\n</li>\n</ol><p>总体来看，不论是在原表上加索引，还是用有索引的临时表，我们的思路都是让join语句能够用上被驱动表上的索引，来触发BKA算法，提升查询性能。</p><h1>扩展-hash join</h1><p>看到这里你可能发现了，其实上面计算10亿次那个操作，看上去有点儿傻。如果join_buffer里面维护的不是一个无序数组，而是一个哈希表的话，那么就不是10亿次判断，而是100万次hash查找。这样的话，整条语句的执行速度就快多了吧？</p><p>确实如此。</p><p>这，也正是MySQL的优化器和执行器一直被诟病的一个原因：不支持哈希join。并且，MySQL官方的roadmap，也是迟迟没有把这个优化排上议程。</p><p>实际上，这个优化思路，我们可以自己实现在业务端。实现流程大致如下：</p><ol>\n<li>\n<p><code>select * from t1;</code>取得表t1的全部1000行数据，在业务端存入一个hash结构，比如C++里的set、PHP的数组这样的数据结构。</p>\n</li>\n<li>\n<p><code>select * from t2 where b&gt;=1 and b&lt;=2000;</code> 获取表t2中满足条件的2000行数据。</p>\n</li>\n<li>\n<p>把这2000行数据，一行一行地取到业务端，到hash结构的数据表中寻找匹配的数据。满足匹配的条件的这行数据，就作为结果集的一行。</p>\n</li>\n</ol><p>理论上，这个过程会比临时表方案的执行速度还要快一些。如果你感兴趣的话，可以自己验证一下。</p><h1>小结</h1><p>今天，我和你分享了Index Nested-Loop Join（NLJ）和Block Nested-Loop Join（BNL）的优化方法。</p><p>在这些优化方法中：</p><ol>\n<li>\n<p>BKA优化是MySQL已经内置支持的，建议你默认使用；</p>\n</li>\n<li>\n<p>BNL算法效率低，建议你都尽量转成BKA算法。优化的方向就是给被驱动表的关联字段加上索引；</p>\n</li>\n<li>\n<p>基于临时表的改进方案，对于能够提前过滤出小数据的join语句来说，效果还是很好的；</p>\n</li>\n<li>\n<p>MySQL目前的版本还不支持hash join，但你可以配合应用端自己模拟出来，理论上效果要好于临时表的方案。</p>\n</li>\n</ol><p>最后，我给你留下一道思考题吧。</p><p>我们在讲join语句的这两篇文章中，都只涉及到了两个表的join。那么，现在有一个三个表join的需求，假设这三个表的表结构如下：</p><pre><code>CREATE TABLE `t1` (\n `id` int(11) NOT NULL,\n `a` int(11) DEFAULT NULL,\n `b` int(11) DEFAULT NULL,\n `c` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\n\ncreate table t2 like t1;\ncreate table t3 like t2;\ninsert into ... //初始化三张表的数据\n</code></pre><p>语句的需求实现如下的join逻辑：</p><pre><code>select * from t1 join t2 on(t1.a=t2.a) join t3 on (t2.b=t3.b) where t1.c&gt;=X and t2.c&gt;=Y and t3.c&gt;=Z;\n</code></pre><p>现在为了得到最快的执行速度，如果让你来设计表t1、t2、t3上的索引，来支持这个join语句，你会加哪些索引呢？</p><p>同时，如果我希望你用straight_join来重写这个语句，配合你创建的索引，你就需要安排连接顺序，你主要考虑的因素是什么呢？</p><p>你可以把你的方案和分析写在留言区，我会在下一篇文章的末尾和你讨论这个问题。感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。</p><h1>上期问题时间</h1><p>我在上篇文章最后留给你的问题，已经在本篇文章中解答了。</p><p>这里我再根据评论区留言的情况，简单总结下。根据数据量的大小，有这么两种情况：</p><ul>\n<li>@长杰 和 @老杨同志 提到了数据量小于old区域内存的情况；</li>\n<li>@Zzz 同学，很认真地看了其他同学的评论，并且提了一个很深的问题。对被驱动表数据量大于Buffer Pool的场景，做了很细致的推演和分析。</li>\n</ul><p>给这些同学点赞，非常好的思考和讨论。</p><p></p>","comments":[{"had_liked":false,"id":68300,"user_name":"IceGeek17","can_delete":false,"product_type":"c1","uid":1103101,"ip_address":"","ucode":"1B42D7260449B4","user_header":"https://static001.geekbang.org/account/avatar/00/10/d4/fd/43802282.jpg","comment_is_top":false,"comment_ctime":1550480567,"is_pvip":false,"discussion_count":12,"race_medal":0,"score":"272133420215","product_id":100020801,"comment_content":"节后补课，有几个问题：<br><br>问题一：<br>对于BKA算法的流程理解，用文中的例子，先把t1表（小表）中查询需要的字段放入join_buffer, 然后把join_buffer里的字段值批量传给t2表，先根据索引a查到id，然后得到一批主键id，再根据主键id排序，然后再根据排完序的id去主键索引查数据（这里用到MRR）<br>理解是否正确？<br>这里对于主键id排序是在哪里做的，是在join_buffer里，还是另外再开辟一块临时内存？如果在join_buffer里，那join_buffer里的每行内容是不是：t2.id + t1查询必须的字段，并且join_buffer里是根据id排序的？<br><br>问题二：<br>虽然MySQL官方没有支持hash join，但是之前看到文章说，MariaDB已经支持hash join，能不能后续在答疑文章中简单总结下mariaDB支持的join算法<br><br>问题三：<br>在实际项目中，一个比较困惑的问题，看到过这样的类似写法：<br>select xxx from t1 join t2 on t1.id = t2.id  for update （目的是获取几个表上最新的数据，并且加上锁，防止数据被更新）<br>这里有几个问题：<br>1) 像这样 join + for update，表上的加锁规则是怎么样的？是不是在需要join的两个表上根据具体的查询执行过程都加上锁？<br>2）像这样 join + for update 的用法是否合理？碰到这样的场景，应该怎么去做？<br><br>问题四：<br>看过阿里输出的开发手册里，强调 “最多不超过三表join”，实际项目中，给我感觉很难做到所有业务都不超过三表join，那这里的问题就是，有什么相关的经验方法，可以尽量降低参与join的数据表？<br>比如，在数据表里添加冗余字段，可以降低参与join的数据表数量，还有什么其他好的方法？<br><br><br>","like_count":64,"discussions":[{"author":{"id":1043325,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/c9xpiakQ3OC1AlfCeW03lLnnb7mj5v35Hib8YDs66zpnVib2n2qFichFmFp2Ec4QDPR0dKh38MkBBLyD3bE4NiaanZQ/132","nickname":"龙晓","note":"","ucode":"FAF34F1C65D103","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":359225,"discussion_content":"问题一：这里对于主键id排序是在哪里做的，是在join_buffer里，还是另外再开辟一块临时内存？\n--是用于MRR排序的read_rnd_buffer，join_buffer是缓存t1表过滤后的必须字段结果集。\n\n关于第四个问题，老师在评论区有这样一段留言：\nXD\n老师，三个表关联的执行流程也是一样的吗？记得阿里的mysql规范里有一条不允许3个及以上表进行join操作，这个原因是？\n\n作者回复: 其实就是怕出事儿，需要精确的控制，如果是两个Index Nested-Loop join 其实还好啦\n只是作成规范，用join次数限制，规范比较好执行\n","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1616145332,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1140175,"avatar":"https://static001.geekbang.org/account/avatar/00/11/65/cf/326c0eea.jpg","nickname":"x-ray","note":"","ucode":"8363F0C4D0AC0B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":339601,"discussion_content":"按照老师的这个说法，把t1表里的数据取出来，临时放到join buffer里，这应该只是放一下，然后一口气传给t2，此时t2进行join匹配，其实可以看成是一个范围查找，这时候应该是在t2表里做了MRR。","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1609745191,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1700634,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJrGia7c6VRslfS3YJfHib84mibKGnGshUn3cWFJxhm9MjEMuwJibsTpvZI2yW2LJO1bLBgcglVdRxMZA/132","nickname":"赫拉","note":"","ucode":"F8368316AA6F01","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":327179,"discussion_content":"个人看法:首先MRR是对NLJ算法回表的优化，老师说的BNL转BKA最简单的方法是被驱动表有索引，其实这就转为了NLJ，只是对回表再做一个优化，就成了BKA","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1605760762,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1986739,"avatar":"https://static001.geekbang.org/account/avatar/00/1e/50/b3/9269cd59.jpg","nickname":"LWD","note":"","ucode":"DDA444DB113C01","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":588210,"discussion_content":"读了三遍说一下我的理解；\n1.mrr是innodb对索引再优化，比如wher a in(1,3,6,7)，如果命中索引a就会拿到这些记录根据主键排序后再回表，这里排序缓存用的是innodb的read buffer；\n2.在NLJ原始算法里面只能进行单值的树搜索，为了使用到mrr就得使其满足范围查询，所以server层就用join_buffer来充当容器，然后再按批量查询的形式去查；","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1663592568,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2355100,"avatar":"https://static001.geekbang.org/account/avatar/00/23/ef/9c/545b9f82.jpg","nickname":"frode","note":"","ucode":"AF53674FD78084","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":384534,"discussion_content":"8.0.20已经彻底支持hash join了，把bnl删除了","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1626654196,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1966533,"avatar":"https://static001.geekbang.org/account/avatar/00/1e/01/c5/b48d25da.jpg","nickname":"cake","note":"","ucode":"55A7FC6CC1204C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":548813,"discussion_content":"很烦","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1643383413,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1966533,"avatar":"https://static001.geekbang.org/account/avatar/00/1e/01/c5/b48d25da.jpg","nickname":"cake","note":"","ucode":"55A7FC6CC1204C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":548812,"discussion_content":"林晓兵不屑于回答垃圾问题","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1643383406,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1020492,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/92/4c/40783447.jpg","nickname":"何骧","note":"","ucode":"11DCC74CE2F300","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1966533,"avatar":"https://static001.geekbang.org/account/avatar/00/1e/01/c5/b48d25da.jpg","nickname":"cake","note":"","ucode":"55A7FC6CC1204C","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":585273,"discussion_content":"哈哈哈 老师正忙着炒股呢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1661429245,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":548812,"ip_address":"广东"},"score":585273,"extra":""}]},{"author":{"id":1140175,"avatar":"https://static001.geekbang.org/account/avatar/00/11/65/cf/326c0eea.jpg","nickname":"x-ray","note":"","ucode":"8363F0C4D0AC0B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":339598,"discussion_content":"这里确实有点疑问，个人觉得，如果只是在t2表里做MRR，那BKA算法不需要在join buffer里做任何事情，因为这个join的字段又不是主键，直接扔过去就完事了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1609744687,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1809802,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/8a/a2d34896.jpg","nickname":"一元(wx:abley1874)","note":"","ucode":"5E7A33642FC767","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":307258,"discussion_content":"对于第一个问题，我也是理解得稀里糊涂的！\nBKA为啥要依赖MRR？BKA算法为啥不直接使用MRR中的read_rnd_buffer来做数据缓存，为什么偏偏用join_buffer，感觉多此一举了。即然用了join_buffer为啥还要依赖MRR？老师你倒是讲清楚啊！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1600573297,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2043565,"avatar":"https://static001.geekbang.org/account/avatar/00/1f/2e/ad/01051c36.jpg","nickname":"你别说话","note":"","ucode":"165787E07E823C","race_medal":2,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":300730,"discussion_content":"@版主","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1598250211,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1900601,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/00/39/33fe53a9.jpg","nickname":"alin","note":"","ucode":"FC6FB85ADA6AA2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":200785,"discussion_content":"怎么没人回答","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1583722034,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":3,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":65026,"user_name":"老杨同志","can_delete":false,"product_type":"c1","uid":1246199,"ip_address":"","ucode":"3F334F0CFD3DE6","user_header":"https://static001.geekbang.org/account/avatar/00/13/03/f7/3a493bec.jpg","comment_is_top":false,"comment_ctime":1549006607,"is_pvip":false,"replies":[{"id":"23071","content":"对，好问题，用了order by就不用MRR了","user_name":"作者回复","comment_id":65026,"uid":"1264162","ip_address":"","utype":1,"ctime":1549039038,"user_name_real":"林晓斌"}],"discussion_count":5,"race_medal":0,"score":"242067175183","product_id":100020801,"comment_content":"我准备给<br>t1增加索引c<br>t2增加组合索引b,c<br>t3增加组合索引b,c<br>select * from t1 straight_join t2 on(t1.a=t2.a)  straight_join  t3 on (t2.b=t3.b) where t1.c&gt;=X and t2.c&gt;=Y and t3.c&gt;=Z;<br><br>另外我还有个问题，开篇提到的这句sql select * from t1 where a&gt;=1 and a&lt;=100;<br>a是索引列，如果这句索引有order by a，不使用MRR 优化，查询出来就是按a排序的，使用了mrr优化，是不是要额外排序<br><br>","like_count":57,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438284,"discussion_content":"对，好问题，用了order by就不用MRR了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1549039038,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2009461,"avatar":"https://static001.geekbang.org/account/avatar/00/1e/a9/75/dbccd12d.jpg","nickname":"稻草人","note":"","ucode":"6694EE2CD36B8C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":356921,"discussion_content":"应该是order by desc a吧？这样查出来的id才是正序的。而且t2应该是增加组合索引a,c吧。。","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1615707613,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":2027690,"avatar":"https://static001.geekbang.org/account/avatar/00/1e/f0/aa/6ba4a1ab.jpg","nickname":"℡ㄨ和尚ふ","note":"","ucode":"E26B2BC7D8E4FC","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2009461,"avatar":"https://static001.geekbang.org/account/avatar/00/1e/a9/75/dbccd12d.jpg","nickname":"稻草人","note":"","ucode":"6694EE2CD36B8C","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":382102,"discussion_content":"这个老哥的意思应该是如果这个sql后面有order by a，那么我最后回表查出来的结果集应该是按照a升序的，但是如果使用了mrr，虽然回表是按照id升序顺序io，但是最后的结果集也是按照id升序排列的，又因为有order by a 的存在，就最后还要对结果集按照a进行一次排序，所以这种情况下就没必要使用mrr了","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1625412165,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":356921,"ip_address":""},"score":382102,"extra":""}]},{"author":{"id":1986739,"avatar":"https://static001.geekbang.org/account/avatar/00/1e/50/b3/9269cd59.jpg","nickname":"LWD","note":"","ucode":"DDA444DB113C01","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":588212,"discussion_content":"说明explain里面即使走索引结果也不一定是按索引有序排列的；","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1663592682,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1518795,"avatar":"","nickname":"Geek_2ac804","note":"","ucode":"EDF69B20030BB8","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":554825,"discussion_content":"t2应该是增加a,c吧？","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1646634352,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":65169,"user_name":"Mr.Strive.Z.H.L","can_delete":false,"product_type":"c1","uid":1030198,"ip_address":"","ucode":"6D97E159E2EECD","user_header":"https://static001.geekbang.org/account/avatar/00/0f/b8/36/542c96bf.jpg","comment_is_top":false,"comment_ctime":1549084702,"is_pvip":false,"replies":[{"id":"23091","content":"新年快乐，分析得很好。<br><br>可以再补充一句，会更好理解你说的这个过程 ：<br>  如果采用BKA进行优化,每多一个join，就多一个join_buffer","user_name":"作者回复","comment_id":65169,"uid":"1264162","ip_address":"","utype":1,"ctime":1549097989,"user_name_real":"林晓斌"}],"discussion_count":1,"race_medal":0,"score":"194822613022","product_id":100020801,"comment_content":"老师您好，新年快乐~~<br><br>关于三表join有一个疑惑点需要确认：<br><br>老师您在评论中说到，三表join不会是前两个表join后得到结果集，再和第三张表join。<br>针对这句话，我的理解是：<br>假设我们不考虑BKA，就按照一行行数据来判断的话，流程应该如下（我会将server端和innodb端分的很清楚）：<br>表是t1 ,t2 ,t3。  t1 straight_join t2 straight_join t3，这样的join顺序。<br>1. 调用innodb接口，从t1中取一行数据，数据返回到server端。<br>2. 调用innodb接口，从t2中取满足条件的数据，数据返回到server端。<br>3. 调用innodb接口，从t3中取满足条件的数据，数据返回到server端。<br>上面三步之后，驱动表 t1的一条数据就处理完了，接下来重复上述过程。<br>（如果采用BKA进行优化，可以理解为不是一行行数据的提取，而是一个范围内数据的提取）。<br><br>按照我上面的描述，确实没有前两表先join得结果集，然后再join第三张表的过程。<br>不知道我上面的描述的流程对不对？（我个人觉得，将innodb的处理和server端的处理分隔清晰，对于sql语句的理解，会透彻很多）","like_count":46,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438345,"discussion_content":"新年快乐，分析得很好。\n\n可以再补充一句，会更好理解你说的这个过程 ：\n  如果采用BKA进行优化,每多一个join，就多一个join_buffer","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1549097989,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":66774,"user_name":"天王","can_delete":false,"product_type":"c1","uid":1239337,"ip_address":"","ucode":"C074B2F9A5F007","user_header":"https://static001.geekbang.org/account/avatar/00/12/e9/29/629d9bb0.jpg","comment_is_top":false,"comment_ctime":1550019297,"is_pvip":false,"replies":[{"id":"23987","content":"👍","user_name":"作者回复","comment_id":66774,"uid":"1264162","ip_address":"","utype":1,"ctime":1550297037,"user_name_real":"林晓斌"}],"discussion_count":2,"race_medal":0,"score":"126104070881","product_id":100020801,"comment_content":"join语句的优化，NLJ算法的优化，MRR优化器会在join_buffer进行主键的排序，然后去主键索引树上一个个的查找，因为按照主键顺序去主键索引树上查找，性能会比较高，MRR优化接近顺序读，性能会比较高。BKA算法是对NLJ算法的优化，一次取出一批数据的字段到join_buffer中，然后批量join，性能会比较好。BKA算法依赖于MRR，因为批量join找到被驱动表的非聚集索引字段通过MRR去查找行数据","like_count":29,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438901,"discussion_content":"👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1550297037,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1202230,"avatar":"https://static001.geekbang.org/account/avatar/00/12/58/36/7b0ce1db.jpg","nickname":"断鸿","note":"","ucode":"B46B608239C33F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":202412,"discussion_content":"按照老师的讲解的话MRR的排序不是在read_rnd_buffer里面的吗？初步理解的话我这边觉得应该是join_buffer里面保存的是驱动表需要过滤之后的数据，然后和被驱动表进行匹配之后的on关联字段非聚集索引和主键信息存放在read_rnd_buffer? 或者说join_buffer存放了俩者所有的信息吗？","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1583914727,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":65590,"user_name":"郭健","can_delete":false,"product_type":"c1","uid":1102204,"ip_address":"","ucode":"169645EBF3B46C","user_header":"https://static001.geekbang.org/account/avatar/00/10/d1/7c/4639f22c.jpg","comment_is_top":false,"comment_ctime":1549469116,"is_pvip":false,"replies":[{"id":"23226","content":"1. 正常是会自己找到合理的，但是用前explain是好习惯哈<br>2. 这个问题的展开我放到答疑文章中哈<br>3. 这也是好问题，需要分析是使用哪种算法，也放到答疑文章展开哈。<br><br>新年快乐~<br>","user_name":"作者回复","comment_id":65590,"uid":"1264162","ip_address":"","utype":1,"ctime":1549503144,"user_name_real":"林晓斌"}],"discussion_count":2,"race_medal":0,"score":"117513586108","product_id":100020801,"comment_content":"老师，有几个问题还需要请教一下:<br>1.上一章t1表100条数据，t21000条数据，mysql会每次都会准确的找出哪张表是合理的驱动表吗？还是需要人为的添加straight_join。<br>2.像left join这种，左边一定是驱动表吧？以左边为标准查看右边有符合的条件，拼成一条数据，看到你给其他同学的评论说可能不是，这有些疑惑。<br>3.在做join的时候，有些条件是可以放在on中也可以放在where中，比如(t1.yn=1 和t2.yn=1)这种简单判断是否删除的。最主要的是，需要根据两个条件才能join的(productCode和custCode),需要两个都在on里，还是一个在on中，一个在where中更好呢？","like_count":27,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438511,"discussion_content":"1. 正常是会自己找到合理的，但是用前explain是好习惯哈\n2. 这个问题的展开我放到答疑文章中哈\n3. 这也是好问题，需要分析是使用哪种算法，也放到答疑文章展开哈。\n\n新年快乐~\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1549503144,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1179312,"avatar":"https://static001.geekbang.org/account/avatar/00/11/fe/b0/260f41f0.jpg","nickname":"loris","note":"","ucode":"00842745CF4B31","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":83811,"discussion_content":"放在where条件中，要考虑语义的正确性","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1576466596,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":102321,"user_name":"纸片人","can_delete":false,"product_type":"c1","uid":1358508,"ip_address":"","ucode":"84490E7CEF59A4","user_header":"https://static001.geekbang.org/account/avatar/00/14/ba/ac/b44b256a.jpg","comment_is_top":false,"comment_ctime":1560199267,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"104639414371","product_id":100020801,"comment_content":"知识点总结<br>1、翻译嵌套查询过程<br>Join = 嵌套查询<br>示例：t1 join t2 on t1.a=t2.a where t1.id&gt;=X and t2.id&gt;=Y<br>已知：驱动表t1的规模是N，被驱动表t2的规模是M<br>伪代码：<br>SNLJ: 扫描次数NxM, 计算次数NxM<br>for r1 in t1 &#47;* read from ~~disk~~ InnoDB(storage engine) *&#47;<br>  for r2 in t2<br>    if r1.a=r2.a<br>      if r1.id&gt;=X and r2.id&gt;=Y<br>        add r1+r2 into result_set<br>  end<br>end<br><br><br>BNLJ: 扫描次数N+KxM，计算次数NxM，K = Nxrow_size&#47;join_buffer_size+1<br>for r1 in t1<br>  add r1 into join_buffer<br>end<br>for r2 in t2<br>  for r1 in join_buffer &#47;* read from ~~memory~~ join_buffer which is controlled by Server *&#47;<br>    if r1.a=r2.a<br>      if r1.id&gt;=X and r2.id&gt;=Y<br>        add r1+r2 into result_set<br>  end<br>end<br><br><br>INLJ: 扫描次数&lt;N+N，计算次数N + Nx2xlnM&#47;ln2<br>for r1 in t1<br>  locate r1.a on t2 with index a  &#47;* search B+Tree *&#47;<br>  if r1.id&gt;=X and r2.id&gt;=Y<br>    add r1+r2 into result_set<br>end<br><br><br><br>2、Join优化思路<br>MRR优化思想：回表前，按主键排序，执行读取操作，以保证顺序读。<br>BKA算法：先按BNLJ的思想批量扫描驱动表数据，再将之按被驱动表上的索引排序，取值。<br>示例：t1 join t2 on t1.a=t2.b where t1.id&gt;=X and t2.id&gt;=Y<br>伪代码：<br>for r1 in t1<br>  add r1 into join_buffer<br>end <br>sort join_buffer by r1.a<br>for r1 in sort_buffer<br>  locate r1.a on t2 with index b  &#47;* search B+Tree *&#47;<br>  if r1.id&gt;=X and r2.id&gt;=Y<br>    add r1+r2 into result_set<br>end<br><br><br>3、BNLJ转BKA<br>方案一：在被驱动表的join字段上添加索引，相当于BNLJ先转INLJ再转BKA。<br>方案二：不适宜添加索引的情况（查询语句使用频率较低），引入临时表。具体操作步骤如下：<br>   a. 先根据where过滤被驱动表t2，并将结果存入临时表tmp_t；<br>   b. 在临时表上为join字段b添加索引；<br>   c. 让驱动表t1连接临时表tmp_t。<br>（注意，由于步骤b中需要为临时表创建索引，所以此方案当且仅当tmp_t规模远小于t2时才划算！）<br><br><br>4、扩展hash-join<br>可视为BNLJ进阶，将join_buffer变成Hash表，处理流程如下：<br><br>hash-join:<br>for r1 in t1<br>  add &lt;key:r1.a,value:r1&gt; into join_buffer<br>end<br>for r2.a in t2 <br>  locate r2.a in t1 with hash index &#47;* read from join_buffer *&#47;<br>  if r1.id&gt;=X and r2.id&gt;=Y<br>    add r1+r2 into result_set<br>end<br><br><br>分析：<br>   a. 驱动表在内环，以降低内存占用率。<br>   b. 如果t1的尺寸大于join_buffer，那么我们就不得不多次全表扫描t2了。因为过滤条件的逻辑运算符号是and，所以还有优化的余地，可将驱动表的过滤提前，来降低t1的大小。<br>for r1 in t1<br>  if r1.id&gt;=X<br>    add &lt;key:r1.a,value:r1&gt; into join_buffer<br>end<br>for r2.a in t2 <br>  locate r2.a in t1 with hash index &#47;* read from join_buffer *&#47;<br>  if r2.id&gt;=Y<br>    add r1+r2 into result_set<br>end<br>","like_count":25,"discussions":[{"author":{"id":3041125,"avatar":"https://static001.geekbang.org/account/avatar/00/2e/67/65/b5b06719.jpg","nickname":"jz","note":"","ucode":"D7ECCBC55DC197","race_medal":3,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":590549,"discussion_content":"4、扩展hash-join中，key 为 索引a，那在普通索引场景下，多条数据重复加入hash结构会发生覆盖，这样结果不就不对了吗（结果集变少了）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1665853308,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"北京"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":64978,"user_name":"asdf100","can_delete":false,"product_type":"c1","uid":1043738,"ip_address":"","ucode":"39D8D71453E575","user_header":"https://static001.geekbang.org/account/avatar/00/0f/ed/1a/ce7f7d54.jpg","comment_is_top":false,"comment_ctime":1548990021,"is_pvip":false,"replies":[{"id":"23016","content":"不需要手动排序<br><br>不过5万个值太凶残了，语句太长不太好<br><br>这种就是手动创建内存临时表，建上hash索引，填入数据，然后join","user_name":"作者回复","comment_id":64978,"uid":"1264162","ip_address":"","utype":1,"ctime":1548993437,"user_name_real":"林晓斌"}],"discussion_count":8,"race_medal":0,"score":"100333237829","product_id":100020801,"comment_content":"最近遇到这个需求，in里面的值个数有5万左右，出现的情况很少但存在，这种情况怎么处理。？手动创建临时表再join？<br><br>另外in内的值用不用手动排序？","like_count":23,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438259,"discussion_content":"不需要手动排序\n\n不过5万个值太凶残了，语句太长不太好\n\n这种就是手动创建内存临时表，建上hash索引，填入数据，然后join","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1548993437,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1308729,"avatar":"https://static001.geekbang.org/account/avatar/00/13/f8/39/4089c9b5.jpg","nickname":"胖子罗","note":"","ucode":"AF45AEED6064B3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":554831,"discussion_content":"考虑把in里的东西分批拆分 代码上做改造来支持","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1646636221,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1181206,"avatar":"https://static001.geekbang.org/account/avatar/00/12/06/16/e85c1fa8.jpg","nickname":"滴答丶滴","note":"","ucode":"2093C2948B4327","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":196978,"discussion_content":"分批量查？可行吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1583391128,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":3,"child_discussions":[{"author":{"id":1043738,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ed/1a/ce7f7d54.jpg","nickname":"asdf100","note":"","ucode":"39D8D71453E575","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1181206,"avatar":"https://static001.geekbang.org/account/avatar/00/12/06/16/e85c1fa8.jpg","nickname":"滴答丶滴","note":"","ucode":"2093C2948B4327","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":197724,"discussion_content":"肯定不行的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1583424482,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":196978,"ip_address":""},"score":197724,"extra":""},{"author":{"id":1335293,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKR3ibELhjgVicCNShZCBwvaDxibnzibggG4wUzVkS2mkDxUBZyIs87nDEdJ7PiahJBVoZcuhQ84RxAziag/132","nickname":"周治慧","note":"","ucode":"7D56C4E66BEE17","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1181206,"avatar":"https://static001.geekbang.org/account/avatar/00/12/06/16/e85c1fa8.jpg","nickname":"滴答丶滴","note":"","ucode":"2093C2948B4327","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":200637,"discussion_content":"分批查询不行  分批查询limit时也需要扫描满足条件的行了后在筛选了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1583705547,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":196978,"ip_address":""},"score":200637,"extra":""},{"author":{"id":1986739,"avatar":"https://static001.geekbang.org/account/avatar/00/1e/50/b3/9269cd59.jpg","nickname":"LWD","note":"","ucode":"DDA444DB113C01","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1181206,"avatar":"https://static001.geekbang.org/account/avatar/00/12/06/16/e85c1fa8.jpg","nickname":"滴答丶滴","note":"","ucode":"2093C2948B4327","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":588215,"discussion_content":"走in字段的索引，对in进行拆分；拆分的时候感觉可以先排个序在split；","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1663593207,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":196978,"ip_address":"广东"},"score":588215,"extra":""}]},{"author":{"id":1043738,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ed/1a/ce7f7d54.jpg","nickname":"asdf100","note":"","ucode":"39D8D71453E575","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":41915,"discussion_content":"语句太长的意思就是in值太多","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1572531360,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1672786,"avatar":"https://static001.geekbang.org/account/avatar/00/19/86/52/91c7d112.jpg","nickname":"Garen","note":"","ucode":"0608C88F83EF0C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":41727,"discussion_content":"我也经常遇到这样的情况，这种情况是不是只要不超过Mysql语句长度限制，就没太大的问题啊？不用排序倒是能理解，in查询时一个一个取出来查询的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1572493997,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":65156,"user_name":"HuaMax","can_delete":false,"product_type":"c1","uid":1118488,"ip_address":"","ucode":"2E78DE1AF098AF","user_header":"https://static001.geekbang.org/account/avatar/00/11/11/18/8cee35f9.jpg","comment_is_top":false,"comment_ctime":1549078955,"is_pvip":false,"replies":[{"id":"23190","content":"👍 很深入的思考哈<br>1. select * ，所以放整行；你说得对，select * 不是好习惯；<br>2. 第一次join后就筛选；第二次join再筛选；<br>新春快乐~","user_name":"作者回复","comment_id":65156,"uid":"1264162","ip_address":"","utype":1,"ctime":1549271015,"user_name_real":"林晓斌"}],"discussion_count":1,"race_medal":0,"score":"83153457579","product_id":100020801,"comment_content":"前提假设：t1.c&gt;=X可以让t1成为小表。同时打开BKA和MRR。<br>1、t1表加（c,a)索引。理由：A、t1.c&gt;=X可以使用索引；B、加上a的联合索引，join buffer里放入的是索引（c,a）而不是去主键表取整行，用于与表t2的t1.a = t2.a的join查询，不过返回SELECT * 最终还是需要回表。<br>2、t2表加(a,b,c)索引。理由：A、加上a避免与t1表join查询的BNL；B、理由同【1-B】；C、加上c不用回表判断t2.c&gt;=Y的筛选条件<br>3、t3表加（b,c）索引。理由：A、避免与t2表join查询的BNL;C、理由同【2-C】<br><br>问题：<br>1、【1-B】和【2-B】由于select *要返回所有列数据，不敢肯定join buffer里是回表的整行数据还是索引（c,a)的数据，需要老师解答一下；不过值得警惕的是，返回的数据列对sql的执行策略有非常大的影响。<br>2、在有join查询时，被驱动表是先做join连接查询，还是先筛选数据再从筛选后的临时表做join连接？这将影响上述的理由【2-C】和【3-C】<br><br>使用straight_join强制指定驱动表，我会改写成这样:select * from t2 STRAIGHT_JOIN t1 on(t1.a=t2.a) STRAIGHT_JOIN t3 on (t2.b=t3.b)  where t1.c&gt;=X and t2.c&gt;=Y and t3.c&gt;=Z;<br>考虑因素包括：<br>1、驱动表使用过滤条件筛选后的数据量，使其成为小表，上面的改写也是基于t2是小表<br>2、因为t2是跟t1,t3都有关联查询的，这样的话我猜测对t1,t3的查询是不是可以并行执行，而如果使用t1,t3作为主表的话，是否会先跟t2生成中间表，是个串行的过程？<br>3、需要给t1加（a,c)索引，给t2加（c,a,b）索引。","like_count":19,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438339,"discussion_content":"👍 很深入的思考哈\n1. select * ，所以放整行；你说得对，select * 不是好习惯；\n2. 第一次join后就筛选；第二次join再筛选；\n新春快乐~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1549271015,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":243264,"user_name":"林肯","can_delete":false,"product_type":"c1","uid":1008582,"ip_address":"","ucode":"D2C97220230DE5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/63/c6/d6ea3df3.jpg","comment_is_top":false,"comment_ctime":1598005194,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"66022514634","product_id":100020801,"comment_content":"可喜的是：MySQL8.0已经支持hash join了","like_count":16},{"had_liked":false,"id":66065,"user_name":"WL","can_delete":false,"product_type":"c1","uid":1173771,"ip_address":"","ucode":"6277DCD776B87E","user_header":"https://static001.geekbang.org/account/avatar/00/11/e9/0b/1171ac71.jpg","comment_is_top":false,"comment_ctime":1549868406,"is_pvip":false,"replies":[{"id":"23405","content":"1. 通过普通索引也会，InnoDB的访问模式都是先内存，不在内存中，才到磁盘找；<br>2. 是以数据页的方式读到内存的，然后在从内存的这个数据页（默认16k）里面找到数据。","user_name":"作者回复","comment_id":66065,"uid":"1264162","ip_address":"","utype":1,"ctime":1549873836,"user_name_real":"林晓斌"}],"discussion_count":2,"race_medal":0,"score":"65974377846","product_id":100020801,"comment_content":"请教老师两个问题:<br>1. 通过主键索引找到的数据会会不会先在内存中查询, 如果没有再去磁盘查询?<br>2. 为什么在通过主键索引查询数据时, 符合条件的数据以单条数据的方式读到内存中而不是以一整个数据页的方式读到内存中? ","like_count":16,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438691,"discussion_content":"1. 通过普通索引也会，InnoDB的访问模式都是先内存，不在内存中，才到磁盘找；\n2. 是以数据页的方式读到内存的，然后在从内存的这个数据页（默认16k）里面找到数据。","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1549873836,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1341276,"avatar":"https://static001.geekbang.org/account/avatar/00/14/77/5c/8d53165e.jpg","nickname":"bingo","note":"","ucode":"DD96820EC8871D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":404812,"discussion_content":"磁盘和内存的交换单位一定是页。以前操作系统是用4kB作为一页，mysql是自己维护了一套逻辑，用 16KB 作为一页。即使涉及的数据量小于一页也会把一整页全部读出来。","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1634419453,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":77926,"user_name":"涛哥哥","can_delete":false,"product_type":"c1","uid":1361159,"ip_address":"","ucode":"329A1384E3AB5E","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eqJobg767PUeqrqQQ4B6YvMatj2SRyOicKZZ4gWTf30dMketiaj58Gc3RFTmckGxAXlL9ERSxGovq9g/132","comment_is_top":false,"comment_ctime":1553042814,"is_pvip":false,"replies":[{"id":"28906","content":"固态硬盘的顺序写还是比随机写快的","user_name":"作者回复","comment_id":77926,"uid":"1264162","ip_address":"","utype":1,"ctime":1553415800,"user_name_real":"林晓斌"}],"discussion_count":1,"race_medal":0,"score":"44502715774","product_id":100020801,"comment_content":"老师，对于现在的固态硬盘，这样类似顺序读写的数据库优化，不就不起作用了啊？","like_count":11,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":443899,"discussion_content":"固态硬盘的顺序写还是比随机写快的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1553415800,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":65020,"user_name":"TKbook","can_delete":false,"product_type":"c1","uid":1073829,"ip_address":"","ucode":"F6E0E99CC79059","user_header":"https://static001.geekbang.org/account/avatar/00/10/62/a5/43aa0c27.jpg","comment_is_top":false,"comment_ctime":1549004425,"is_pvip":false,"replies":[{"id":"23041","content":"对的，👍细致<br><br>已经发起勘误，谢谢你哦，新年快乐","user_name":"作者回复","comment_id":65020,"uid":"1264162","ip_address":"","utype":1,"ctime":1549008528,"user_name_real":"林晓斌"}],"discussion_count":1,"race_medal":0,"score":"40203710089","product_id":100020801,"comment_content":"BNL 算法效率低，建议你都尽量转成 BKA 算法。优化的方向就是给驱动表的关联字段加上索引；<br>老师最后总结的时候，这句话后面那句，应该是给被驱动表的关联字段加上索引吧。","like_count":10,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438278,"discussion_content":"对的，👍细致\n\n已经发起勘误，谢谢你哦，新年快乐","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1549008528,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":66851,"user_name":"憶海拾貝","can_delete":false,"product_type":"c1","uid":1054727,"ip_address":"","ucode":"99E883A8601DED","user_header":"https://static001.geekbang.org/account/avatar/00/10/18/07/9f5f5dd3.jpg","comment_is_top":false,"comment_ctime":1550029407,"is_pvip":false,"replies":[{"id":"23670","content":"如果是非随机的主键，确实没必要了😅<br><br>优化第一步还是应该把主键处理一下<br>","user_name":"作者回复","comment_id":66851,"uid":"1264162","ip_address":"","utype":1,"ctime":1550047494,"user_name_real":"林晓斌"}],"discussion_count":8,"race_medal":0,"score":"35909767775","product_id":100020801,"comment_content":"节后开工宜补课.<br><br>按照文中说明的MRR设计思路, 是否可以反推出: 被驱动表使用非递增主键(比如UUID作为主键),就没有必要开启MRR?","like_count":8,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438945,"discussion_content":"如果是非随机的主键，确实没必要了😅\n\n优化第一步还是应该把主键处理一下\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1550047494,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1928368,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLCKzC0IPq9HSaMiaySKyviaBftvz2EjgqKNCwia9C0xIfYnuE7qntQ6fQ9oL2sEyJGWu0Mmj7EbWicrg/132","nickname":"FL","note":"","ucode":"C82D077D6C2277","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":282045,"discussion_content":"这里有疑问  虽然是非递增主键 但是在主键索引树上 不是还是按照递增的吗","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1591869355,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":6,"child_discussions":[{"author":{"id":1054727,"avatar":"https://static001.geekbang.org/account/avatar/00/10/18/07/9f5f5dd3.jpg","nickname":"憶海拾貝","note":"","ucode":"99E883A8601DED","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1928368,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLCKzC0IPq9HSaMiaySKyviaBftvz2EjgqKNCwia9C0xIfYnuE7qntQ6fQ9oL2sEyJGWu0Mmj7EbWicrg/132","nickname":"FL","note":"","ucode":"C82D077D6C2277","race_medal":0,"user_type":1,"is_pvip":true},"discussion":{"id":282330,"discussion_content":"从整颗索引树来看所有主键是可以认为递增的没错,但是某次查询到的多条记录的主键并不一定挨得近,有可能在很&#34;远&#34;的位置","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1591942314,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":282045,"ip_address":""},"score":282330,"extra":""},{"author":{"id":1526355,"avatar":"https://static001.geekbang.org/account/avatar/00/17/4a/53/063f9d17.jpg","nickname":"moonfox","note":"","ucode":"902BFF40EFA9FA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1054727,"avatar":"https://static001.geekbang.org/account/avatar/00/10/18/07/9f5f5dd3.jpg","nickname":"憶海拾貝","note":"","ucode":"99E883A8601DED","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":329136,"discussion_content":"主键只有保证在每次插入的时候都是递增的才可以使用mrr，是么？普通索引因为是随机插入，所以无法使用mrr，毕竟数据没有挨在一起","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606316445,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":282330,"ip_address":""},"score":329136,"extra":""},{"author":{"id":1341276,"avatar":"https://static001.geekbang.org/account/avatar/00/14/77/5c/8d53165e.jpg","nickname":"bingo","note":"","ucode":"DD96820EC8871D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1526355,"avatar":"https://static001.geekbang.org/account/avatar/00/17/4a/53/063f9d17.jpg","nickname":"moonfox","note":"","ucode":"902BFF40EFA9FA","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":404813,"discussion_content":"innodb索引在逻辑上和物理上都是有序的，和插入方式无关的。无论随机插入还是顺序插入，在磁盘层面都是挨在一起的。比如插入 1，5, 10 这三个值，如果插入的顺序是什么，最终在磁盘里都是 1 --> 10 --> 5 排序的。如果先插两头的数据，再插中间的数据，那么磁盘页会自动分裂，如果删除了中间的很多数据，那么磁盘页会自动合并","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1634420117,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":329136,"ip_address":""},"score":404813,"extra":""}]}]},{"had_liked":false,"id":65024,"user_name":"poppy","can_delete":false,"product_type":"c1","uid":1182792,"ip_address":"","ucode":"2ED2BDF703D0D9","user_header":"https://static001.geekbang.org/account/avatar/00/12/0c/48/ba59d28d.jpg","comment_is_top":false,"comment_ctime":1549005870,"is_pvip":false,"replies":[{"id":"23077","content":"嗯 这个问题就是留给大家自己设定条件然后分析的，分析得不错哦","user_name":"作者回复","comment_id":65024,"uid":"1264162","ip_address":"","utype":1,"ctime":1549039965,"user_name_real":"林晓斌"}],"discussion_count":2,"race_medal":0,"score":"35908744238","product_id":100020801,"comment_content":"select * from t1 join t2 on(t1.a=t2.a) join t3 on (t2.b=t3.b) where t1.c&gt;=X and t2.c&gt;=Y and t3.c&gt;=Z;<br>老师，我的理解是真正做join的三张表的大小实际上是t1.c&gt;=X、t2.c&gt;=Y、t3.c&gt;=Z对应满足条件的行数，为了方便快速定位到满足条件的数据，t1、t2和t3的c字段最好都建索引。对于join操作，按道理mysql应该会优先选择join之后数量比较少的两张表先来进行join操作，例如满足t1.a=t2.a的行数小于满足t2.b=t3.b的行数，那么就会优先将t1和t2进行join，选择t1.c&gt;=X、t2.c&gt;=Y中行数少的表作为驱动表，另外一张作为被驱动表，在被驱动表的a的字段上建立索引，这样就完成了t1和t2的join操作并把结果放入join_buffer准备与t3进行join操作，则在作为被驱动表的t3的b字段上建立索引。不知道举的这个例子分析得是否正确，主要是这里不知道t1、t2、t3三张表的数据量，以及满足t1.c&gt;=X ，t2.c&gt;=Y ，t3.c&gt;=Z的数据量，还有各个字段的区分度如何，是否适合建立索引等。","like_count":8,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438282,"discussion_content":"嗯 这个问题就是留给大家自己设定条件然后分析的，分析得不错哦","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1549039965,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1227366,"avatar":"https://static001.geekbang.org/account/avatar/00/12/ba/66/7d9f45e7.jpg","nickname":"太空牛仔","note":"","ucode":"0205635C3854AF","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":543699,"discussion_content":"如果两张表连接字段有索引 那只能利用到被驱动表连接字段的索引 因为拿到驱动表的数据会去被驱动表根据连接字段查数据 然后回表 根据主键索引的行数据 再判断条件是否满足 这个时候如果还要查被驱动表where条件字段的索引 那就还要多一次回表了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1641274989,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":64963,"user_name":"dzkk","can_delete":false,"product_type":"c1","uid":1301932,"ip_address":"","ucode":"A81EFDB1D43C0D","user_header":"https://static001.geekbang.org/account/avatar/00/13/dd/ac/f40bbd15.jpg","comment_is_top":false,"comment_ctime":1548986169,"is_pvip":false,"replies":[{"id":"23015","content":"你了解得比较全面哈<br><br>不过我怕在文章中写这么多概念，会看得晕。<br><br>实际上现在 Simple Nested-Loop Join 已经不会用了（太慢），有使用的就是 Index Nested-Loop Join 和 BKA优化哈。<br><br>MariaDB在优化器上做了很多工作，之前的文章本来也想介绍，后来发现得先把官方版本的说明白，然后我们可以在评论区扩展讨论。<br><br>BNLH 在MariaDB 5.3就引入了，流程跟我们“扩展-hash join”这段类似，对于等值join的效果还是很好的。","user_name":"作者回复","comment_id":64963,"uid":"1264162","ip_address":"","utype":1,"ctime":1548990591,"user_name_real":"林晓斌"}],"discussion_count":1,"race_medal":0,"score":"35908724537","product_id":100020801,"comment_content":"老师，记得我之前看mysql的join是和版本有关系的，另外NLJ是一个统称，被分为了SNLJ(Simple Nested-Loop Join，5.5版本之前采用的，当被驱动表上没有索引的时候使用，该方法比较粗暴，所以后来通过BNLJ进行了优化)、INLJ(Index Nested-Loop Join，被驱动表上有索引)、BNLJ(Block Nested-Loop Join，被驱动表上没有索引)，另外了解到mariadb是支持了hash join的Block Nested Loop Hash (BNLH) join，没有使用过，不知道效果怎么样。不知道我了解的信息对不对。","like_count":9,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438253,"discussion_content":"你了解得比较全面哈\n\n不过我怕在文章中写这么多概念，会看得晕。\n\n实际上现在 Simple Nested-Loop Join 已经不会用了（太慢），有使用的就是 Index Nested-Loop Join 和 BKA优化哈。\n\nMariaDB在优化器上做了很多工作，之前的文章本来也想介绍，后来发现得先把官方版本的说明白，然后我们可以在评论区扩展讨论。\n\nBNLH 在MariaDB 5.3就引入了，流程跟我们“扩展-hash join”这段类似，对于等值join的效果还是很好的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1548990591,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":65191,"user_name":"bluefantasy3","can_delete":false,"product_type":"c1","uid":1299930,"ip_address":"","ucode":"9D6FF2811F7465","user_header":"","comment_is_top":false,"comment_ctime":1549098333,"is_pvip":false,"replies":[{"id":"23125","content":"1. 是MySQL 自己管理的<br>2. 一般只有数据文件是o_direct的，redo log 和 binlog 都是有用到文件系统的page cache, 因此多少有影响的<br><br>好问题👍🏿 ","user_name":"作者回复","comment_id":65191,"uid":"1264162","ip_address":"","utype":1,"ctime":1549155915,"user_name_real":"林晓斌"}],"discussion_count":2,"race_medal":0,"score":"31613869405","product_id":100020801,"comment_content":"请教老师一个问题：innodb的Buffer Pool的内存是innodb自己管理还是使用OS的page cache? 我理解应该是innodb自己管理。我在另一个课程里看到如果频繁地把OS的&#47;proc&#47;sys&#47;vm&#47;drop_caches 改成 1会影响MySQL的性能，如果buffer pool是MySQL自己管理，应该不受这个参数影响呀？请解答。","like_count":7,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438354,"discussion_content":"1. 是MySQL 自己管理的\n2. 一般只有数据文件是o_direct的，redo log 和 binlog 都是有用到文件系统的page cache, 因此多少有影响的\n\n好问题👍🏿 ","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1549155915,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1302631,"avatar":"https://static001.geekbang.org/account/avatar/00/13/e0/67/6db879e4.jpg","nickname":"phantom","note":"","ucode":"C4FCE4A04D32CA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":37819,"discussion_content":"请问老师，若binlog生成过大，导致占用cache过高，从而导致swap高，有什么好方法呢？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1571669622,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":65008,"user_name":"读书看报","can_delete":false,"product_type":"c1","uid":1306147,"ip_address":"","ucode":"3B4717314B52A9","user_header":"https://static001.geekbang.org/account/avatar/00/13/ee/23/b92b0811.jpg","comment_is_top":false,"comment_ctime":1548999150,"is_pvip":false,"replies":[{"id":"23043","content":"这正常的，一种可能是这样的： <br>   Using where 就是顺序扫，但是这个上要扫很久才能扫到满足条件的20个记录；<br>   虽然有filesort，但是如果参与排序的行数少，可能速度就更快，而且limit 有堆排序优化哦","user_name":"作者回复","comment_id":65008,"uid":"1264162","ip_address":"","utype":1,"ctime":1549008745,"user_name_real":"林晓斌"}],"discussion_count":1,"race_medal":0,"score":"31613770222","product_id":100020801,"comment_content":"order by cjsj desc limit 0,20 explain  Extra只是显示 Using where ，执行时间 7秒钟<br>order by cjsj desc limit 5000,20 explain  Extra只是显示 Using index condition; Using where; Using filesort,  执行时间 0.1 秒<br>有些许的凌乱了@^^@","like_count":7,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438270,"discussion_content":"这正常的，一种可能是这样的： \n   Using where 就是顺序扫，但是这个上要扫很久才能扫到满足条件的20个记录；\n   虽然有filesort，但是如果参与排序的行数少，可能速度就更快，而且limit 有堆排序优化哦","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1549008745,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":263920,"user_name":"moonfox","can_delete":false,"product_type":"c1","uid":1526355,"ip_address":"","ucode":"902BFF40EFA9FA","user_header":"https://static001.geekbang.org/account/avatar/00/17/4a/53/063f9d17.jpg","comment_is_top":false,"comment_ctime":1606294383,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"23081130863","product_id":100020801,"comment_content":"感觉有一点没有讲清楚，当然也可能是我理解的问题。MRR在 表 Join的时候，主要起到的做用就是加速了被驱动表的普通索引A的回表速度，而不是加速普通索引A的查询速度，因为普通索引A的数据是随机插入的，所以无法使用MRR的优势。BKA算法的主要作用就是一次性的把驱动表中参与查询的数据传给被驱动表，以便让被驱动表在索引A上回表时使用MRR算法，其实就是对MRR算法的辅助。","like_count":6},{"had_liked":false,"id":66840,"user_name":"Mr.Strive.Z.H.L","can_delete":false,"product_type":"c1","uid":1030198,"ip_address":"","ucode":"6D97E159E2EECD","user_header":"https://static001.geekbang.org/account/avatar/00/0f/b8/36/542c96bf.jpg","comment_is_top":false,"comment_ctime":1550028109,"is_pvip":false,"replies":[{"id":"23988","content":"你这两个语句是一样的。。是不是第二个语句多了left？<br><br>left join因为语义上要求所有左边表的数据行都必须存在结果里面，所以执行流程不太一样，我在答疑文章中说哈","user_name":"作者回复","comment_id":66840,"uid":"1264162","ip_address":"","utype":1,"ctime":1550297120,"user_name_real":"林晓斌"}],"discussion_count":1,"race_medal":0,"score":"23024864589","product_id":100020801,"comment_content":"老师你好，今天在回顾这篇文章做总结的时候，突然有一个疑惑：<br><br>我们假设t2的b上面有索引，该语句是左连接<br><br>select * from t1  left join t2 on (t1.b=t2.b) where t2.b&gt;=1 and t2.b&lt;=2000;<br><br>和<br><br>select * from t1  left join t2 on (t1.b=t2.b) and t2.b&gt;=1 and t2.b&lt;=2000;<br><br>到底在内部执行流程上到底有什么区别？？<br>因为实际工作中左连接用得挺多的。<br>（这篇文章都是直连，所以使用on和where最后的结果都一样，但是左连接就不是了）<br>","like_count":5,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438939,"discussion_content":"你这两个语句是一样的。。是不是第二个语句多了left？\n\nleft join因为语义上要求所有左边表的数据行都必须存在结果里面，所以执行流程不太一样，我在答疑文章中说哈","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1550297120,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":65043,"user_name":"库淘淘","can_delete":false,"product_type":"c1","uid":1310240,"ip_address":"","ucode":"90813B0C46E978","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eqibSwKPg7hiapc49qoM4dibhM3fYANPjfltF2ibBZ3dHX2hibjg5EIIcziahrmjO5R2XrcRibvU39TQS7jg/132","comment_is_top":false,"comment_ctime":1549010556,"is_pvip":false,"replies":[{"id":"23076","content":"👍<br><br>BKA是从Index Nexted-Loop join 优化而来的，并不是“t1和t2join得结果集再与t3join”，而是直接嵌套循环执行下去。<br><br>这个效果相当不错了，MRR，BKA都用上","user_name":"作者回复","comment_id":65043,"uid":"1264162","ip_address":"","utype":1,"ctime":1549039912,"user_name_real":"林晓斌"}],"discussion_count":1,"race_medal":0,"score":"23023847036","product_id":100020801,"comment_content":"set optimizer_switch=&#39;mrr=on,mrr_cost_based=off,batched_key_access=on&#39;;<br>create index idx_c on t2(c);<br>create index idx_a_c on t1(a,c);<br>create index idx_b_c on t3(b,c);<br>mysql&gt; explain select * from t2 <br>    -&gt; straight_join t1 on(t1.a=t2.a)<br>    -&gt; straight_join t3 on(t2.b=t3.b)   <br>    -&gt; where t1.c&gt; 800 and t2.c&gt;=600 and t3.c&gt;=500;<br>+----+-------------+-------+------------+---------------------------------------<br>| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra +----------------------------------------<br>| 1 | SIMPLE | t2 | NULL | range | idx_c | idx_c | 5 | NULL | 401 | 100.00 | Using index condition; Using where; Using MRR |<br>| 1 | SIMPLE | t1 | NULL | ref | idx_a_c | idx_a_c | 5 | test.t2.a | 1 | 33.33 | Using index condition; Using join buffer (Batched Key Access) |<br>| 1 | SIMPLE | t3 | NULL | ref | idx_b_c | idx_b_c | 5 | test.t2.b | 1 | 33.33 | Using index condition; Using join buffer (Batched Key Access) |<br>+----+-------------+-------+------------+-----+---------------------------------------<br>3 rows in set, 1 warning (0.00 sec)<br>以自己理解如下，有问题请老师能够指出<br>1.根据查询因是select * 肯定回表的，其中在表t2创建索引idx_c,为了能够使用ICP,MRR，如果c字段重复率高或取值行数多，可以考虑不建索引<br>2.已t2 作为驱动表，一方面考虑其他两表都有关联,t2表放入join buffer后关联t1后，再关联t2 得出结果 再各回t2,t3表取出 得到结果集（之前理解都是t1和t2join得结果集再与t3join，本次理解太确定）<br>3.t2、t3表建立联合查询目的能够使用ICP","like_count":6,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438293,"discussion_content":"👍\n\nBKA是从Index Nexted-Loop join 优化而来的，并不是“t1和t2join得结果集再与t3join”，而是直接嵌套循环执行下去。\n\n这个效果相当不错了，MRR，BKA都用上","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1549039912,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":65041,"user_name":"读书看报","can_delete":false,"product_type":"c1","uid":1306147,"ip_address":"","ucode":"3B4717314B52A9","user_header":"https://static001.geekbang.org/account/avatar/00/13/ee/23/b92b0811.jpg","comment_is_top":false,"comment_ctime":1549009844,"is_pvip":false,"replies":[{"id":"23075","content":"嗯，这个跟我们第十篇那个例子挺像的<br><br>我们把limit 1 改成limit 100的时候，MySQL认为，要扫描到“100行那么多”，<br>你这里是limit 5000，200， 这个5000会让优化器认为，选txsj会要扫“很多行，可能很久”<br><br>这个确实是优化器还不够完善的地方，有时候不得不用force index~","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1549039764,"ip_address":"","comment_id":65041,"utype":1}],"discussion_count":2,"race_medal":0,"score":"23023846324","product_id":100020801,"comment_content":"刚刚凌乱了的那个问题，经explain验证，explain SELECT a.* FROM sys_xxtx a JOIN baq_ryxx r ON a.ryid = r.ID WHERE a.dwbh = &#39;7E0A13A14101D0A8E0430A0F23BCD0A8&#39; ORDER BY txsj DESC LIMIT 0,20;<br>使用的索引是txsj ；<br>explain SELECT a.* FROM sys_xxtx a JOIN baq_ryxx r ON a.ryid = r.ID WHERE a.dwbh = &#39;7E0A13A14101D0A8E0430A0F23BCD0A8&#39; ORDER BY txsj DESC LIMIT 5000,20;使用的索引是dwbh ；<br>然后回忆起了第10张：MySQL为什么有时候会选错索引？<br>但是从扫描行数、是否使用排序等来看在 LIMIT 5000,20时候也应该优选txsj ?可是这个时候选择的索引是dwbh, 查询时间也大大缩短","like_count":5,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438291,"discussion_content":"嗯，这个跟我们第十篇那个例子挺像的\n\n我们把limit 1 改成limit 100的时候，MySQL认为，要扫描到“100行那么多”，\n你这里是limit 5000，200， 这个5000会让优化器认为，选txsj会要扫“很多行，可能很久”\n\n这个确实是优化器还不够完善的地方，有时候不得不用force index~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1549039764,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2086624,"avatar":"https://static001.geekbang.org/account/avatar/00/1f/d6/e0/3ccaaa7b.jpg","nickname":"领子","note":"","ucode":"64AC4E6AB74E68","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":295392,"discussion_content":"建一个(dwbh,txsj)的联合索引不更好吗，既能走索引过滤，又能避免排序","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1596181301,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":64988,"user_name":"郭江伟","can_delete":false,"product_type":"c1","uid":1313994,"ip_address":"","ucode":"613D638619B5A2","user_header":"https://static001.geekbang.org/account/avatar/00/14/0c/ca/6173350b.jpg","comment_is_top":false,"comment_ctime":1548992341,"is_pvip":false,"replies":[{"id":"23023","content":"👍验证的结果最有说服力","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1549003142,"ip_address":"","comment_id":64988,"utype":1}],"discussion_count":2,"race_medal":0,"score":"23023828821","product_id":100020801,"comment_content":"select * from t1 join t2 on(t1.a=t2.a) join t3 on (t2.b=t3.b) where t1.c&gt;=X and t2.c&gt;=Y and t3.c&gt;=Z;<br>这个语句建索引需要考虑三个表的数据量和相关字段的数据分布、选择率、每个条件返回行数占比等<br>我的测试场景是：<br>t1 1000行数据  t2 100w行数据  t3 100w行，关联字段没有重复值，条件查询返回行数占比很少，此时索引为： <br>alter table t1 add key t1_c(c);<br>alter table t2 add key t2_ac(a,c);<br>alter table t3 add key t3_bc(b,c);<br>测试sql无索引是执行需要2分钟多，加了索引后需要0.01秒，加索引后执行计划为：<br>mysql&gt; explain select * from t1 join t2 on(t1.a=t2.a) join t3 on (t2.b=t3.b) where t1.c&gt;=100 and t2.c&gt;=10 and t3.c&gt;=90;<br>+----+-------------+-------+------------+------+---------------+-------+---------+---------------+------+----------+------------------------------------+<br>| id | select_type | table | partitions | type | possible_keys | key   | key_len | ref           | rows | filtered | Extra                              |<br>+----+-------------+-------+------------+------+---------------+-------+---------+---------------+------+----------+------------------------------------+<br>|  1 | SIMPLE      | t1    | NULL       | ALL  | t1_a          | NULL  | NULL    | NULL          | 1000 |    90.10 | Using where                        |<br>|  1 | SIMPLE      | t2    | NULL       | ref  | t2_ac         | t2_ac | 5       | sysbench.t1.a |    1 |    33.33 | Using index condition; Using where |<br>|  1 | SIMPLE      | t3    | NULL       | ref  | t3_bc         | t3_bc | 5       | sysbench.t2.b |    1 |    33.33 | Using index condition              |<br>+----+-------------+-------+------------+------+---------------+-------+---------+---------------+------+----------+------------------------------------+<br>另外，select * 如果改成具体字段的话考虑覆盖索引 可能需要建立不同的索引。<br>","like_count":5,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438262,"discussion_content":"👍验证的结果最有说服力","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1549003142,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1111974,"avatar":"https://static001.geekbang.org/account/avatar/00/10/f7/a6/c863c65b.jpg","nickname":"西瓜刀","note":"","ucode":"3978348547499D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":98285,"discussion_content":"optimizer_switch=&#34;mrr_cost_based=off&#34;   这个我按照你的方式测试了下，反而速度要慢1倍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577152809,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":185198,"user_name":"Direction","can_delete":false,"product_type":"c1","uid":1731977,"ip_address":"","ucode":"298D5109EA28EE","user_header":"https://static001.geekbang.org/account/avatar/00/1a/6d/89/14031273.jpg","comment_is_top":false,"comment_ctime":1583511454,"is_pvip":false,"discussion_count":4,"race_medal":0,"score":"14468413342","product_id":100020801,"comment_content":"老师，问下join on 和 where的优先级哪个高呢？是先执行ON里面的比较，然后再过滤where条件里面的数据吗？但是我做了验证显示的扫描行数不一样。<br><br>例如：explain select * from t1 straight_join t2 on (t1.b=t2.b) where t2.id&lt;=50;<br><br>1\tSIMPLE\tt1\t\tALL\t\t\t\t\t100\t100.00\t<br>1\tSIMPLE\tt2\t\trange\tPRIMARY\tPRIMARY\t4\t\t50\t10.00\tUsing where; Using join buffer (Block Nested Loop)<br>实际上t2只扫描了50行，这个很不理解，盼回复哦。","like_count":4,"discussions":[{"author":{"id":1435733,"avatar":"https://static001.geekbang.org/account/avatar/00/15/e8/55/92f82281.jpg","nickname":"MClink","note":"","ucode":"F479190923355C","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":300898,"discussion_content":"先执行on获取结果集，再进行条件过滤","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1598314762,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1484273,"avatar":"https://static001.geekbang.org/account/avatar/00/16/a5/f1/8e3ce0e4.jpg","nickname":"🍋🥬🐟","note":"","ucode":"4191D6E6CB6D3B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":296368,"discussion_content":"我理解 left join 是 on 先执行，where 后执行","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1596523029,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1901867,"avatar":"","nickname":"青石路","note":"","ucode":"9012B9ED314FED","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":200058,"discussion_content":"我也有同样的疑问，希望老师回复下\non 和 where的生效时机问题","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1583653334,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1986739,"avatar":"https://static001.geekbang.org/account/avatar/00/1e/50/b3/9269cd59.jpg","nickname":"LWD","note":"","ucode":"DDA444DB113C01","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1901867,"avatar":"","nickname":"青石路","note":"","ucode":"9012B9ED314FED","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":588219,"discussion_content":"外部查询需要先on再where；内部查询的on会改写到where里面","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1663593797,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":200058,"ip_address":"广东"},"score":588219,"extra":""}]}]},{"had_liked":false,"id":176800,"user_name":"万明丞","can_delete":false,"product_type":"c1","uid":1649414,"ip_address":"","ucode":"A7BA8672E68F26","user_header":"","comment_is_top":false,"comment_ctime":1581170054,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"14466071942","product_id":100020801,"comment_content":"老师，对于select * from t1 join t2 on (t1.b=t2.b) where t2.b&gt;=1 and t2.b&lt;=2000;<br>如果改写成select * from t2 STRAIGHT_JOIN t1 on (t1.b=t2.b) where t2.b&gt;=1 and t2.b&lt;=2000;<br>在做内存比对时就是2000*1000，远远小于10亿，性能能够提升很多，也不需要建临时表。Mysql实现上为什么不先做where过滤再比对数据？","like_count":3},{"had_liked":false,"id":81793,"user_name":"~玲玲玲~子~哥~","can_delete":false,"product_type":"c1","uid":1302741,"ip_address":"","ucode":"89379F3A0427EA","user_header":"https://static001.geekbang.org/account/avatar/00/13/e0/d5/7485e51f.jpg","comment_is_top":false,"comment_ctime":1554037202,"is_pvip":false,"replies":[{"id":"30159","content":"不是，要看join算法。<br><br>比如如果都是BKA算法，那就是1关联2再马上关联3，得到结果，这样循环","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1554616591,"ip_address":"","comment_id":81793,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14438939090","product_id":100020801,"comment_content":"老师好。<br>这节课评论我看好多人都问三表连接时的步骤，您指出和第三个表关联不是前两个表的结果集和第三张表关联。<br>那是第一张表和第二张表关联，然后第一张表在和第三张表关联，最后这两个结果集在关联？请纠正。","like_count":4,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":445347,"discussion_content":"不是，要看join算法。\n\n比如如果都是BKA算法，那就是1关联2再马上关联3，得到结果，这样循环","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1554616591,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":66786,"user_name":"天王","can_delete":false,"product_type":"c1","uid":1239337,"ip_address":"","ucode":"C074B2F9A5F007","user_header":"https://static001.geekbang.org/account/avatar/00/12/e9/29/629d9bb0.jpg","comment_is_top":false,"comment_ctime":1550020769,"is_pvip":false,"replies":[{"id":"23676","content":"👍","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1550049106,"ip_address":"","comment_id":66786,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14434922657","product_id":100020801,"comment_content":"BNL算法优化，BNL算法，如果读取的是冷表，而且量比较大，循环读取，第一次数据会进入old区域，如果一秒之后没有访问，不会移到LRU头部，大表join对io影响查询完就结束了，但是buffer pool需要大量的查询把冷数据冲掉。BNL算法有3个问题，1 多次扫描被驱动表，占用磁盘io 2 判断join会耗费大量的cpu资源 3 会热数据淘汰，影响buffer pool的命中率","like_count":3,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438910,"discussion_content":"👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1550049106,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":65210,"user_name":"Ryoma","can_delete":false,"product_type":"c1","uid":1130590,"ip_address":"","ucode":"7F692369239692","user_header":"https://static001.geekbang.org/account/avatar/00/11/40/5e/b8fada94.jpg","comment_is_top":false,"comment_ctime":1549110083,"is_pvip":true,"replies":[{"id":"23126","content":"你说得对，多谢<br><br>发起勘误了<br><br>新年快乐","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1549156404,"ip_address":"","comment_id":65210,"utype":1}],"discussion_count":1,"race_medal":2,"score":"14434011971","product_id":100020801,"comment_content":"read_rnd_buffer_length 参数应该是 read_rnd_buffer_size，见文档：https:&#47;&#47;dev.mysql.com&#47;doc&#47;refman&#47;8.0&#47;en&#47;server-system-variables.html#sysvar_read_rnd_buffer_size","like_count":3,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438360,"discussion_content":"你说得对，多谢\n\n发起勘误了\n\n新年快乐","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1549156404,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":65182,"user_name":"信信","can_delete":false,"product_type":"c1","uid":1303865,"ip_address":"","ucode":"8DF0EC045579FD","user_header":"https://static001.geekbang.org/account/avatar/00/13/e5/39/951f89c8.jpg","comment_is_top":false,"comment_ctime":1549091569,"is_pvip":false,"replies":[{"id":"23090","content":"1. 写straight_join能确定顺序，也可以的，这里写join 也ok的<br><br>2. 是进行了1000次树搜索<br>","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1549097857,"ip_address":"","comment_id":65182,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14433993457","product_id":100020801,"comment_content":"老师好，有两点疑问请老师解惑：<br>1、图8上面提到的关于临时表的第三句是不是还是使用straight_join好一些？不然有可能temp_t被选为驱动表？<br>2、图8下面提到join过程中做了1000次带索引的查询，这里的1000也是在打开mrr的情况下的吗？是进行了1000次树搜索，还是找到第一个后，依次挨着读呢？<br>","like_count":3,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438351,"discussion_content":"1. 写straight_join能确定顺序，也可以的，这里写join 也ok的\n\n2. 是进行了1000次树搜索\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1549097857,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":276119,"user_name":"hzy","can_delete":false,"product_type":"c1","uid":2265274,"ip_address":"","ucode":"B5486275D148E1","user_header":"https://static001.geekbang.org/account/avatar/00/22/90/ba/fb490062.jpg","comment_is_top":false,"comment_ctime":1611799518,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10201734110","product_id":100020801,"comment_content":"8已经支持hash join了","like_count":2},{"had_liked":false,"id":114732,"user_name":"Huan","can_delete":false,"product_type":"c1","uid":1443773,"ip_address":"","ucode":"24F1657DDEC117","user_header":"https://static001.geekbang.org/account/avatar/00/16/07/bd/00a3f6aa.jpg","comment_is_top":false,"comment_ctime":1563372341,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10153306933","product_id":100020801,"comment_content":"老师，我想请教下，在inner join  on后面加过滤条件，与呀where后面加过滤条件，性能是一样的吗？","like_count":2},{"had_liked":false,"id":84274,"user_name":"唯她命","can_delete":false,"product_type":"c1","uid":1240398,"ip_address":"","ucode":"8F687E8D306840","user_header":"https://static001.geekbang.org/account/avatar/00/12/ed/4e/ef406442.jpg","comment_is_top":false,"comment_ctime":1554817590,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"10144752182","product_id":100020801,"comment_content":"存储过程 插入100万<br>Query OK, 1 row affected (1 hour 53 min 57.59 sec)<br>这么恐怖😱！","like_count":2,"discussions":[{"author":{"id":1287774,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a6/5e/b05254a6.jpg","nickname":"Mhy","note":"","ucode":"DE19BCAD1F856E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":6129,"discussion_content":"set sync_bin=0;set innodb_flush_log_at_trx_commit=0;老师之前教过","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1566718354,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1093819,"avatar":"https://static001.geekbang.org/account/avatar/00/10/b0/bb/fc698888.jpg","nickname":"leozhang","note":"","ucode":"DAC9015821DAF1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":8783,"discussion_content":" 这个和事务有关，在开始循环时候 开启事务，最后结束循环后 提交事务，非常快几分钟一百万数据","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1568047031,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":65212,"user_name":"Geek_02538c","can_delete":false,"product_type":"c1","uid":1336903,"ip_address":"","ucode":"26E208B5AB7D7F","user_header":"","comment_is_top":false,"comment_ctime":1549113144,"is_pvip":true,"replies":[{"id":"23127","content":"你说得对^_^  第37篇就是，新年快乐","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1549156451,"ip_address":"","comment_id":65212,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10139047736","product_id":100020801,"comment_content":"过年了，还有新文章，给个赞。 另，where  和 order  与索引的关系，都讲过了，group by 是否也搞个篇章说一下。","like_count":2,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438361,"discussion_content":"你说得对^_^  第37篇就是，新年快乐","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1549156451,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":190027,"user_name":"Mao","can_delete":false,"product_type":"c1","uid":1759620,"ip_address":"","ucode":"1C821B0208B45F","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaELbYFAXthMl6KBS3dKjYX2lAicRL7ZhahfCkabo12dQjhkvxGCc0BaC0IxibOjZdO5RWibD8CIcELb1Q/132","comment_is_top":false,"comment_ctime":1584595705,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5879563001","product_id":100020801,"comment_content":"MySQL 8.0开始支持hash join了","like_count":1},{"had_liked":false,"id":158224,"user_name":"脱缰的野马__","can_delete":false,"product_type":"c1","uid":1447569,"ip_address":"","ucode":"D5F993E7232C61","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/WtHCCMoLJ2DvzqQwPYZyj2RlN7eibTLMHDMTSO4xIKjfKR1Eh9L98AMkkZY7FmegWyGLahRQJ5ibPzeeFtfpeSow/132","comment_is_top":false,"comment_ctime":1575353605,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"5870320901","product_id":100020801,"comment_content":"老师您好，“Multi-Range Read 优化 (MRR)，这个优化的主要目的是尽量使用顺序读盘”<br>我更底层的理解是：顺序读之所以更优，是不是因为innodb在查数据的时候，如果内存缓存的所有数据页都没有当前要查的数据，就会进行磁盘IO从磁盘将要查询的数据刷新到内存，而刷新的时候又是按页刷新到内存（那对于数据页肯定是按主键顺序递增保存的），也就是说后续的顺序读在内存中的命中率会高，进行磁盘IO的次数也就会降低，并且如果不是随机查，内存缓存数据页的刷新也不会非常频繁，进而起到了更优的效果。请问老师这样理解是否正确呢？","like_count":1,"discussions":[{"author":{"id":1246178,"avatar":"https://static001.geekbang.org/account/avatar/00/13/03/e2/5768d26e.jpg","nickname":"inrtyx","note":"","ucode":"81CD18FF34ABAB","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":118300,"discussion_content":"跟磁盘的读取数据的机制有关","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1578151233,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":132567,"user_name":"骑龟的兔子","can_delete":false,"product_type":"c1","uid":1308854,"ip_address":"","ucode":"3B3AF0A4F324D3","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLHKka9hn8hYxxXLOX7spkMRUAUiauzwib2po1aNWDfqHf5jh2EHX9DdI3zvdXL6KVaiajIU01bd8wyA/132","comment_is_top":false,"comment_ctime":1568166921,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5863134217","product_id":100020801,"comment_content":"我觉的老师关于bka 说法有误，mrr 肯定触发在驱动表减少回表时候的ramdom acess io 那么如果触发在别驱动表 就是bka 而不是 老师说 驱动表 一次给多条数据给被驱动表 ，mrr和bka 都是针对回表做的优化，一个是驱动表一个是被驱动表","like_count":1},{"had_liked":false,"id":98895,"user_name":"Lane","can_delete":false,"product_type":"c1","uid":1008257,"ip_address":"","ucode":"F70459D1BBD9F4","user_header":"https://static001.geekbang.org/account/avatar/00/0f/62/81/ad80f427.jpg","comment_is_top":false,"comment_ctime":1559113891,"is_pvip":true,"discussion_count":1,"race_medal":0,"score":"5854081187","product_id":100020801,"comment_content":"老师，既然MRR和BKA好，为什么却不默认开启，就一定是有一些弊端吧，那么Mysql的顾忌在哪里？","like_count":1,"discussions":[{"author":{"id":1518795,"avatar":"","nickname":"Geek_2ac804","note":"","ucode":"EDF69B20030BB8","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":555152,"discussion_content":"我觉得需要内存支持吧？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1646787870,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":70048,"user_name":"live fast","can_delete":false,"product_type":"c1","uid":1198218,"ip_address":"","ucode":"D5ECDDA2DBE5AE","user_header":"https://static001.geekbang.org/account/avatar/00/12/48/8a/a20396e9.jpg","comment_is_top":false,"comment_ctime":1550976077,"is_pvip":false,"replies":[{"id":"24974","content":"是哦,多谢,我勘误一下","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1550980845,"ip_address":"","comment_id":70048,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5845943373","product_id":100020801,"comment_content":"老师，PHP 的 dict 这样的数据结构。应该是python,php只有数组","like_count":1,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":440416,"discussion_content":"是哦,多谢,我勘误一下","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1550980845,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1185046,"avatar":"https://static001.geekbang.org/account/avatar/00/12/15/16/0aae41a1.jpg","nickname":"no13bus","note":"","ucode":"69FA1A719DA4F6","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":21421,"discussion_content":"关联数组","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1569481891,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":69204,"user_name":"Lukia","can_delete":false,"product_type":"c1","uid":1028698,"ip_address":"","ucode":"C19472337BCCC6","user_header":"https://static001.geekbang.org/account/avatar/00/0f/b2/5a/574f5bb0.jpg","comment_is_top":false,"comment_ctime":1550676982,"is_pvip":false,"replies":[{"id":"24991","content":"是一个个查，但是是一批发给被驱动表的，后面用的mrr","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1550997823,"ip_address":"","comment_id":69204,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5845644278","product_id":100020801,"comment_content":"老师好，针对BKA的描述：<br>“之后的 join 语句，扫描表 t1，这里的扫描行数是 1000；join 比较过程中，做了 1000 次带索引的查询。”<br>是不是可以理解为被扫描表的索引其实还是一个一个查的，只是在通过被扫描表的索引去访问主键索引的时候用了mrr？","like_count":1,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":439998,"discussion_content":"是一个个查，但是是一批发给被驱动表的，后面用的mrr","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1550997823,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":65880,"user_name":"郭健","can_delete":false,"product_type":"c1","uid":1102204,"ip_address":"","ucode":"169645EBF3B46C","user_header":"https://static001.geekbang.org/account/avatar/00/10/d1/7c/4639f22c.jpg","comment_is_top":false,"comment_ctime":1549718050,"is_pvip":false,"replies":[{"id":"23406","content":"嗯，首先DBA开发这个界面工具还是很有必要的，这样可以控制输入的语句，避免人工查询对库造成太大的影响。<br><br>如果这类查询比较多，并且人工查询的条件很复杂，经常容易用不上索引的话， 在createTime创建索引还是挺有必要的。。","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1549874078,"ip_address":"","comment_id":65880,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5844685346","product_id":100020801,"comment_content":"老师，新年快乐！！看到您给我提问的回答，特别期待您之后的答疑，因为dba怕我们查询数据库时连接时间过长，影响线上实际运行。所以就开发出一个网页，让我们进行查询，但是超过几秒(具体不知道，查询一个200w的数据，条件没有加索引有时候都会)就会返回time out，所以当查询大表并join的时候，就会很吃力！想法设法的缩小单位，一般我们都不会为createTime建一个索引，所以在根据时间缩小范围的时候有时候也并不是很好的选择。我们线上做统计sql的时候，因为数据量比较大，筛选条件也比较多，一个sql可能在0.4s多，这已经是属于慢sql了。感谢老师对我提问的回答！！","like_count":1,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438624,"discussion_content":"嗯，首先DBA开发这个界面工具还是很有必要的，这样可以控制输入的语句，避免人工查询对库造成太大的影响。\n\n如果这类查询比较多，并且人工查询的条件很复杂，经常容易用不上索引的话， 在createTime创建索引还是挺有必要的。。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1549874078,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":65250,"user_name":"磊","can_delete":false,"product_type":"c1","uid":1070732,"ip_address":"","ucode":"858BF8BFBFB0B8","user_header":"https://static001.geekbang.org/account/avatar/00/10/56/8c/a8317e23.jpg","comment_is_top":false,"comment_ctime":1549161601,"is_pvip":true,"replies":[{"id":"23147","content":"这一期45篇 join差不多就讲这些了😆<br><br>有问题在评论区提出来哈","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1549166802,"ip_address":"","comment_id":65250,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5844128897","product_id":100020801,"comment_content":"一直对多表的join有些迷惑，希望老师后面专门把这块给讲的透彻些","like_count":1,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438373,"discussion_content":"这一期45篇 join差不多就讲这些了😆\n\n有问题在评论区提出来哈","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1549166802,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":64993,"user_name":"John","can_delete":false,"product_type":"c1","uid":1020861,"ip_address":"","ucode":"E4ADF8488953FB","user_header":"https://static001.geekbang.org/account/avatar/00/0f/93/bd/f3977ebb.jpg","comment_is_top":false,"comment_ctime":1548993656,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5843960952","product_id":100020801,"comment_content":"期待這一篇很久啦 終於出來啦 臨時表和範圍搜索實在是醍醐灌頂 謝謝老師","like_count":1},{"had_liked":false,"id":64992,"user_name":"Dovelol","can_delete":false,"product_type":"c1","uid":1253384,"ip_address":"","ucode":"9B5DDF7720F307","user_header":"https://static001.geekbang.org/account/avatar/00/13/20/08/bc06bc69.jpg","comment_is_top":false,"comment_ctime":1548993606,"is_pvip":false,"replies":[{"id":"23024","content":"贴一下errorlog里面看看有没有异常信息 如果比较大的文件可以发我微博私信附件<br><br>写文章的过程中根据大家的评论问题，发现有些知识点应该优先写，目录有做调整哈","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1549003322,"ip_address":"","comment_id":64992,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5843960902","product_id":100020801,"comment_content":"老师，记得之前看目录之后要将一篇标题大概为“我的mysql为啥莫名其妙重启了”，最近看怎么没有了？我们确实遇到这种问题，在系统日志里也找不到OOM信息，现象是半个月左右就会自动重启一下，时间不固定，想请教下是什么问题呢？","like_count":1,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438263,"discussion_content":"贴一下errorlog里面看看有没有异常信息 如果比较大的文件可以发我微博私信附件\n\n写文章的过程中根据大家的评论问题，发现有些知识点应该优先写，目录有做调整哈","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1549003322,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":348235,"user_name":"geek","can_delete":false,"product_type":"c1","uid":1764320,"ip_address":"","ucode":"431C838A6491B0","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/SKPfibfoMmlNicmhj6e84Pt7Z5eZ4iaKXqqkKbQpIx2qZ0BYQkXs0H3fOw7e8AGXEg27uic6hxt0MLenutViaaWblNA/132","comment_is_top":false,"comment_ctime":1654855165,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1654855165","product_id":100020801,"comment_content":"select * from t2 straight_join t1 on (t1.b=t2.b) where t2.id&lt;=50;<br>例子上的这个，为什么t2的表只用放50行到joinbuffer中就可以了？<br>他不是生成了临时表再判断where中的条件吗","like_count":0},{"had_liked":false,"id":342829,"user_name":"哲子兄","can_delete":false,"product_type":"c1","uid":1348819,"ip_address":"","ucode":"6D6B6FE1ED2583","user_header":"https://static001.geekbang.org/account/avatar/00/14/94/d3/1861fa96.jpg","comment_is_top":false,"comment_ctime":1650500651,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1650500651","product_id":100020801,"comment_content":"假如以t2表为驱动，首先t2.c加上索引，然后t2表关联t1，给t1加上t1.a索引扫描最少行，在join_buffer中判断t1.c＞x所以t1.c不用加索引，t2和t1联表的结果与t3关联，需要给t3加上t3.b索引。<br>结论：t2表作为驱动表，加t2.c，t1.a，t3.b索引","like_count":0},{"had_liked":false,"id":339226,"user_name":"yinwenping","can_delete":false,"product_type":"c1","uid":1088594,"ip_address":"","ucode":"90310F95D8B72F","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83er6ADlY3IFt3Rs1aVDyrTO2ytQZDiciaXVKgxCnsqZJUQHzH6I0I6PYvdoiaI6rkm7OLOxHia7t1icDyBQ/132","comment_is_top":false,"comment_ctime":1647999998,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1647999998","product_id":100020801,"comment_content":"老师好，有个问题想请教下，下面的两个sql有什么区别吗？<br>select * from t1, t2 where t1.a=t2.a;<br>select * from t1 join t2 on t1.a=t2.a;","like_count":0},{"had_liked":false,"id":331688,"user_name":"idiot","can_delete":false,"product_type":"c1","uid":2526391,"ip_address":"","ucode":"D7A6E980B530B4","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/fcftgBsticCicEEkuzB0GTkHIocX62YVTSvnhR1c94sccj42lVaYXrmcZyhzUI3l9NcvuN1rXLhXt2eBrZZ0Tw7A/132","comment_is_top":false,"comment_ctime":1642726107,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1642726107","product_id":100020801,"comment_content":"随机读写转顺序读写真是经典思路，LSM也是这样。<br>给大的被驱动表加索引，要锁表比较久，影响线上业务。<br>后面的带where的例子其实还是小表join小表了，不过临时表加索引的方案有些意思，hash join的方案对于大数据感觉怎么都不适用。","like_count":0},{"had_liked":false,"id":328356,"user_name":"第二次","can_delete":false,"product_type":"c1","uid":1605637,"ip_address":"","ucode":"E0E5F3209D4378","user_header":"https://static001.geekbang.org/account/avatar/00/18/80/05/5e80a2b4.jpg","comment_is_top":false,"comment_ctime":1640684650,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1640684650","product_id":100020801,"comment_content":"老师，我有个疑问<br>Multi-Range Read 优化 和 Batched Key Access优化，mysql默认不都没开启嘛，那这和我<br>怎么优化join有什么关系嘛，是说这个配置我们还是开启比较好嘛，有些不太理解","like_count":0},{"had_liked":false,"id":325661,"user_name":"山鬼谣","can_delete":false,"product_type":"c1","uid":1543162,"ip_address":"","ucode":"E25F498B85A01B","user_header":"https://static001.geekbang.org/account/avatar/00/17/8b/fa/103e6900.jpg","comment_is_top":false,"comment_ctime":1639067005,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1639067005","product_id":100020801,"comment_content":"mrr就是针对回头的顺序读优化。一个前提条件就是主键ID量要足够多才有意义","like_count":0},{"had_liked":false,"id":317310,"user_name":"innovationmech","can_delete":false,"product_type":"c1","uid":1232321,"ip_address":"","ucode":"9377EAD5C6373E","user_header":"https://static001.geekbang.org/account/avatar/00/12/cd/c1/19531313.jpg","comment_is_top":false,"comment_ctime":1634737481,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1634737481","product_id":100020801,"comment_content":"mysql 8.0 好像支持 hash join 了，执行 explain select * from t1 join t2 on (t1.b=t2.b) where t2.b&gt;=1 and t2.b&lt;=2000; 后在 Extra 里看到有 hash join","like_count":0},{"had_liked":false,"id":303377,"user_name":"马成","can_delete":false,"product_type":"c1","uid":1486895,"ip_address":"","ucode":"664F2BAA2E0F0B","user_header":"https://static001.geekbang.org/account/avatar/00/16/b0/2f/e2096905.jpg","comment_is_top":false,"comment_ctime":1626762219,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1626762219","product_id":100020801,"comment_content":"read_rnd_buffer 是引擎层的缓存，而read_rnd_buffer 是server层的缓存；那么使用BKA时，是不是除了使用read_rnd_buffer 临时存放要驱动表的数据外，InnoDB内部使用MRR优化时，依旧需要使用read_rnd_buffe？","like_count":0},{"had_liked":false,"id":303366,"user_name":"lleft","can_delete":false,"product_type":"c1","uid":1970443,"ip_address":"","ucode":"D573EB509455AE","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIx1V1QAxC4NHaxYZGyuibBN8lcURJWc5nrnO4yic1kxnDemYV2FJGialf47kYX9qtDnZZOfe1SJeLicg/132","comment_is_top":false,"comment_ctime":1626753595,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1626753595","product_id":100020801,"comment_content":"BKA算法使用的join buffer来存储查询需要的字段，然后跟被驱动表关联查询是在join buffer中排序还是在MRR中排序呢？后面老师说BKA算法依赖MRR，那么就是说从join buffer中取出关联字段在MRR中排序之后再批量去被驱动表中查询数据？每太理解这之间的关系","like_count":0},{"had_liked":false,"id":301581,"user_name":"张滔","can_delete":false,"product_type":"c1","uid":1322636,"ip_address":"","ucode":"87ABAFF0E861E0","user_header":"https://static001.geekbang.org/account/avatar/00/14/2e/8c/b261e15a.jpg","comment_is_top":false,"comment_ctime":1625749753,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1625749753","product_id":100020801,"comment_content":"老师，请教个问题。<br><br>有如下两个sql：<br>第一个sql：select * from T1 left join T2 on T1.a=T2.a and T2.b is null where T1.a=&quot;888&quot;;<br>第二个sql：select * from T1 left join T2 on T1.a=T2.a where T1.a=&quot;888&quot; and T2.b is null;<br><br>其中T1.a，T2.a和T2.b都有索引，T1的数据量大约3万行，T2的数据量大约100万行。<br><br>为什么第一个sql只有1毫秒，而第二个sql要3秒？","like_count":0},{"had_liked":false,"id":301580,"user_name":"张滔","can_delete":false,"product_type":"c1","uid":1322636,"ip_address":"","ucode":"87ABAFF0E861E0","user_header":"https://static001.geekbang.org/account/avatar/00/14/2e/8c/b261e15a.jpg","comment_is_top":false,"comment_ctime":1625749744,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1625749744","product_id":100020801,"comment_content":"老师，请教个问题。<br><br>有如下两个sql：<br>第一个sql：select * from T1 left join T2 on T1.a=T2.a and T2.b is null where T1.a=&quot;888&quot;;<br>第二个sql：select * from T1 left join T2 on T1.a=T2.a where T1.a=&quot;888&quot; and T2.b is null;<br><br>其中T1.a，T2.a和T2.b都有索引，T1的数据量大约3万行，T2的数据量大约100万行。<br><br>为什么第一个sql只有1毫秒，而第二个sql要3秒？","like_count":0},{"had_liked":false,"id":294906,"user_name":"大漠","can_delete":false,"product_type":"c1","uid":1124461,"ip_address":"","ucode":"B7973B9FD7CB61","user_header":"https://static001.geekbang.org/account/avatar/00/11/28/6d/d776d35a.jpg","comment_is_top":false,"comment_ctime":1622127420,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1622127420","product_id":100020801,"comment_content":"创建临时表的方式能不能换成子查询的方式来join呢？<br>select * from t1 join (select * from t2 where b&gt;=1 and b&lt;=2000) temp_t on (t1.b=temp_t.b);","like_count":0},{"had_liked":false,"id":292632,"user_name":"ub8","can_delete":false,"product_type":"c1","uid":1481811,"ip_address":"","ucode":"0D937C3EAEB781","user_header":"https://static001.geekbang.org/account/avatar/00/16/9c/53/ade0afb0.jpg","comment_is_top":false,"comment_ctime":1620903863,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1620903863","product_id":100020801,"comment_content":"我是跳的看到这的，感觉文章还是要挨着看 😄","like_count":0},{"had_liked":false,"id":292631,"user_name":"ub8","can_delete":false,"product_type":"c1","uid":1481811,"ip_address":"","ucode":"0D937C3EAEB781","user_header":"https://static001.geekbang.org/account/avatar/00/16/9c/53/ade0afb0.jpg","comment_is_top":false,"comment_ctime":1620903801,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1620903801","product_id":100020801,"comment_content":"感觉挺深的啊这一节，虽然在开发环境都没有用够join 函数 但是看完这篇文章还是有感触的比如 join_buffer 所有的系统为了提高吞吐量都是添加缓存的方式。","like_count":0},{"had_liked":false,"id":287048,"user_name":"新手","can_delete":false,"product_type":"c1","uid":1155356,"ip_address":"","ucode":"8CCB8497102BA5","user_header":"https://static001.geekbang.org/account/avatar/00/11/a1/1c/abb7bfe3.jpg","comment_is_top":false,"comment_ctime":1617759097,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1617759097","product_id":100020801,"comment_content":"mysql8也支持hash join了，https:&#47;&#47;mysqlserverteam.com&#47;hash-join-in-mysql-8&#47;","like_count":0},{"had_liked":false,"id":282500,"user_name":"帝江","can_delete":false,"product_type":"c1","uid":1590610,"ip_address":"","ucode":"93CBA4E4D05DA5","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/B9vSOjMc2a86kYA8R5yDkVdFiaj2JeBZ1PuI9oUKhbnvuZwuibdUam6FTcGzDaiaFdk2GWJveUGhfCVpv4KaOdicoQ/132","comment_is_top":false,"comment_ctime":1615279731,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1615279731","product_id":100020801,"comment_content":"用程序扩展 -hash join 那里.php的数组应该指的是&quot;关联数组&quot;,并且是以关联字段当做key的关联数组.php一般意义上的数组是&quot;索引数组&quot;.类似其他语言的list.","like_count":0},{"had_liked":false,"id":280763,"user_name":"泽阳","can_delete":false,"product_type":"c1","uid":1622176,"ip_address":"","ucode":"C3275E8DC964DC","user_header":"https://static001.geekbang.org/account/avatar/00/18/c0/a0/ee2921fe.jpg","comment_is_top":false,"comment_ctime":1614350441,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1614350441","product_id":100020801,"comment_content":"老师，请问Id in (7,4,9,3,17...)这种语句在开启MRR时会对in后面的值排序后再去查聚簇索引吗？还是说优化器本来就是这样做的，不需要MRR做？还有就是这种批量查询的方式是多次读盘还是一次读盘就可以了？","like_count":0},{"had_liked":false,"id":277255,"user_name":"慕荣","can_delete":false,"product_type":"c1","uid":1445941,"ip_address":"","ucode":"76AD15446B8F31","user_header":"https://static001.geekbang.org/account/avatar/00/16/10/35/d0c21796.jpg","comment_is_top":false,"comment_ctime":1612334791,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1612334791","product_id":100020801,"comment_content":"如果随着 a 的值递增顺序查询的话，id 的值就变成随机的，那么就会出现随机访问：<br>索引a是一颗b+tree，叶子节点是按顺序存放的，那取出的主键应该就是顺序的呀，上文中数据已经顺序入库了，这里没太理解","like_count":0},{"had_liked":false,"id":273251,"user_name":"赫拉","can_delete":false,"product_type":"c1","uid":1700634,"ip_address":"","ucode":"F8368316AA6F01","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJrGia7c6VRslfS3YJfHib84mibKGnGshUn3cWFJxhm9MjEMuwJibsTpvZI2yW2LJO1bLBgcglVdRxMZA/132","comment_is_top":false,"comment_ctime":1610512178,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1610512178","product_id":100020801,"comment_content":"老师，如果是left或者right join，那执行流程跟join有什么区别吗？","like_count":0},{"had_liked":false,"id":272795,"user_name":"刘玉龙","can_delete":false,"product_type":"c1","uid":1500821,"ip_address":"","ucode":"02BCA2E78C1AD7","user_header":"https://static001.geekbang.org/account/avatar/00/16/e6/95/99d51e08.jpg","comment_is_top":false,"comment_ctime":1610286092,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1610286092","product_id":100020801,"comment_content":"老师 那如果主键是 uuid， 那这时候排序还有效果吗","like_count":0},{"had_liked":false,"id":268825,"user_name":"凹凸鸿","can_delete":false,"product_type":"c1","uid":1915334,"ip_address":"","ucode":"A458BAEBF314B2","user_header":"https://static001.geekbang.org/account/avatar/00/1d/39/c6/1e12f271.jpg","comment_is_top":false,"comment_ctime":1608363380,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1608363380","product_id":100020801,"comment_content":"老师，上亿级别数据的项目数据库要怎么设计？怎么做到查询最优，现在一个400万数据的表查询花了30秒","like_count":0},{"had_liked":false,"id":267139,"user_name":"伟程","can_delete":false,"product_type":"c1","uid":1095173,"ip_address":"","ucode":"E62433F24C14A1","user_header":"https://static001.geekbang.org/account/avatar/00/10/b6/05/bb034c2c.jpg","comment_is_top":false,"comment_ctime":1607606611,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1607606611","product_id":100020801,"comment_content":"给被驱动表的join字段加上索引，把BNL算法转成BKA算法，根据这个解决一个现网慢sql问题，学到了","like_count":0},{"had_liked":false,"id":265373,"user_name":"TinyCalf","can_delete":false,"product_type":"c1","uid":2137418,"ip_address":"","ucode":"0A3EF213359388","user_header":"https://static001.geekbang.org/account/avatar/00/20/9d/4a/09a5041e.jpg","comment_is_top":false,"comment_ctime":1606879826,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1606879826","product_id":100020801,"comment_content":"我的版本是8.0.20，看起来已经有hash join了<br>explain select * from t1 straight_join t2 on (t1.a=t2.b);<br>+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+--------------------------------------------+<br>| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra                                      |<br>+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+--------------------------------------------+<br>|  1 | SIMPLE      | t1    | NULL       | ALL  | a             | NULL | NULL    | NULL |  100 |   100.00 | NULL                                       |<br>|  1 | SIMPLE      | t2    | NULL       | ALL  | NULL          | NULL | NULL    | NULL | 1000 |    10.00 | Using where; Using join buffer (hash join) |<br>+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+--------------------------------------------+","like_count":0},{"had_liked":false,"id":265284,"user_name":"Shan","can_delete":false,"product_type":"c1","uid":1666954,"ip_address":"","ucode":"4F158016B0D590","user_header":"https://static001.geekbang.org/account/avatar/00/19/6f/8a/bea966ac.jpg","comment_is_top":false,"comment_ctime":1606838944,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1606838944","product_id":100020801,"comment_content":"老师你好，对于MRR优化我提出一些疑问：<br>1、如果使用辅助索引进行范围查询，就像例子中的a的范围是[1,100]，得到的ID值是逆序，但是ID逆序和顺序不都是顺序IO吗，因为ID的地址偏向于连续。<br>2、一般查询都会将对应的数据页放入到缓存把，下次查询就不会读磁盘，那么如果是逆序的话，如果ID是紧凑的，是不是也会使用到缓存的优化。","like_count":0},{"had_liked":false,"id":262809,"user_name":"AluAlu","can_delete":false,"product_type":"c1","uid":1309974,"ip_address":"","ucode":"ACDE9CD9D7B459","user_header":"https://static001.geekbang.org/account/avatar/00/13/fd/16/719fa5c3.jpg","comment_is_top":false,"comment_ctime":1605848963,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1605848963","product_id":100020801,"comment_content":"表t和t1各有1000行数据，为什么执行explain select * from t straight_join t1 on t.a=t1.a<br>Extra 列显示using index ,using blocked  nested  loop join<br>跟我预期不太一样。。。","like_count":0},{"had_liked":false,"id":253741,"user_name":"Geek8819","can_delete":false,"product_type":"c1","uid":2028950,"ip_address":"","ucode":"521AEDAB2EED81","user_header":"https://static001.geekbang.org/account/avatar/00/1e/f5/96/e963b41b.jpg","comment_is_top":false,"comment_ctime":1602849336,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1602849336","product_id":100020801,"comment_content":"BNL 算法效率低，建议你都尽量转成 BKA 算法。优化的方向就是给被驱动表的关联字段加上索引<br>想问一下加上索引不就变成NLJ了么","like_count":0,"discussions":[{"author":{"id":1526355,"avatar":"https://static001.geekbang.org/account/avatar/00/17/4a/53/063f9d17.jpg","nickname":"moonfox","note":"","ucode":"902BFF40EFA9FA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":329142,"discussion_content":"NLJ优化后不就是bka么？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606317729,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":248610,"user_name":"shenfl","can_delete":false,"product_type":"c1","uid":1184233,"ip_address":"","ucode":"607CD894152241","user_header":"https://static001.geekbang.org/account/avatar/00/12/11/e9/b6aa6364.jpg","comment_is_top":false,"comment_ctime":1600241017,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1600241017","product_id":100020801,"comment_content":"BNL算法可以先判断t2.b是不是在1-2000，如果是的再遍历join_buffer中t1做匹配，这样是不是就不用临时表了？mysql底层为啥不是这样处理呢？","like_count":0},{"had_liked":false,"id":238715,"user_name":"与路同飞","can_delete":false,"product_type":"c1","uid":1138821,"ip_address":"","ucode":"2985F1440A1962","user_header":"https://static001.geekbang.org/account/avatar/00/11/60/85/f72f1d94.jpg","comment_is_top":false,"comment_ctime":1596270008,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1596270008","product_id":100020801,"comment_content":"时隔一年半过来回复，mysql8已经支持hash join了","like_count":0},{"had_liked":false,"id":237901,"user_name":" 莎瓦迪卡","can_delete":false,"product_type":"c1","uid":1243452,"ip_address":"","ucode":"2F27017E82EB2D","user_header":"https://static001.geekbang.org/account/avatar/00/12/f9/3c/42b96095.jpg","comment_is_top":false,"comment_ctime":1596001066,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1596001066","product_id":100020801,"comment_content":"如果满足 t1.b=t2.b, 再判断其他条件，也就是是否满足 t2.b 处于[1,2000]的条件，如果是，就作为结果集的一部分返回，否则跳过。<br>------------------------------------<br>这里不会优化一下吗？难道2001开始后面的记录，都需要去跟t1表记录比较？没必要呀","like_count":0},{"had_liked":false,"id":235085,"user_name":"Yayu","can_delete":false,"product_type":"c1","uid":1058015,"ip_address":"","ucode":"5E7842458D8229","user_header":"https://static001.geekbang.org/account/avatar/00/10/24/df/645f8087.jpg","comment_is_top":false,"comment_ctime":1594888124,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1594888124","product_id":100020801,"comment_content":"mysql 8.0 已经支持 hash join 了！","like_count":0},{"had_liked":false,"id":232845,"user_name":"Damo","can_delete":false,"product_type":"c1","uid":1599197,"ip_address":"","ucode":"F332EA67F5A40C","user_header":"https://static001.geekbang.org/account/avatar/00/18/66/dd/c9f17139.jpg","comment_is_top":false,"comment_ctime":1594128832,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1594128832","product_id":100020801,"comment_content":"前提<br>使用存储过程往表里面各插入 1000条数，然后使用老师的 sql 查询很快就出来了。感觉是数据太少了，然后重新往各个表中插入 10w 数据，再次用 sql 查询，慢的一逼。使用 explain 分析，走的是BNL，那么这里就是需要让他走 BKA。查询的每一次都让被驱动表走索引，就可以提高性能。<br><br>那么根据 sql 来看，就需要添加一下 index<br>t1 <br>alter table t1 add index a(a);<br>alter table t1 add index c(c);<br><br>t2<br>alter table t2 add index a(a);<br>alter table t2 add index b(b);<br>alter table t2 add index c(c);<br><br>t3 <br>alter table t3 add index b(b);<br>alter table t3 add index c(c);<br><br>添加索引后，原来的 BNL，就变成了 BKA。<br><br>我的查询语句为<br>“select * from t1 straight_join t2 on(t1.a=t2.a) straight_join t3 on (t2.b=t3.b) where t1.c&gt;=100 and t2.c&gt;=100 and t3.c&gt;=100”<br><br>存储过程代码为<br>“<br>drop table t1, t2, t3;<br>CREATE TABLE `t1` (<br>`id` int(11) NOT NULL, <br>`a` int(11) DEFAULT NULL, <br>`b` int(11) DEFAULT NULL, <br>`c` int(11) DEFAULT NULL, <br>PRIMARY KEY (`id`)) ENGINE=InnoDB;<br><br>create table t2 like t1;<br>create table t3 like t2;<br><br>drop procedure idata;<br>delimiter ;;<br>create procedure idata()<br>begin<br>  declare i int;<br><br>  set i=1;<br>  while(i&lt;=100000)do<br>    insert into t1 values(i, i, i, i);<br>    set i=i+1;<br>  end while;<br>  <br>  set i=1;<br>  while(i&lt;=100000)do<br>    insert into t2 values(i, i, i, i);<br>    set i=i+1;<br>  end while;<br><br>  set i=1;<br>  while(i&lt;=100000)do<br>    insert into t3 values(i, i, i, i);<br>    set i=i+1;<br>  end while;<br><br>end;;<br>delimiter ;<br>call idata();<br>”","like_count":0},{"had_liked":false,"id":225833,"user_name":"FL","can_delete":false,"product_type":"c1","uid":1928368,"ip_address":"","ucode":"C82D077D6C2277","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLCKzC0IPq9HSaMiaySKyviaBftvz2EjgqKNCwia9C0xIfYnuE7qntQ6fQ9oL2sEyJGWu0Mmj7EbWicrg/132","comment_is_top":false,"comment_ctime":1591868745,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1591868745","product_id":100020801,"comment_content":"select * from t1 join t2 on(t1.a=t2.a) join t3 on (t2.b=t3.b) where t1.c&gt;=X and t2.c&gt;=Y and t3.c&gt;=Z;<br>如果X&gt;Y 去t1.a上加索引让 t1作为被驱动表 否则去t2.a上加索引  <br>如果Y&gt;Z  去t2.b上加索引 否则去t3.b加索引<br><br>顺序的话我考虑让小表作为驱动表,大表作为被驱动表吧","like_count":0},{"had_liked":false,"id":221878,"user_name":"文古","can_delete":false,"product_type":"c1","uid":1313934,"ip_address":"","ucode":"9A3991AA033EB4","user_header":"https://static001.geekbang.org/account/avatar/00/14/0c/8e/8a39ee55.jpg","comment_is_top":false,"comment_ctime":1590627230,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1590627230","product_id":100020801,"comment_content":"你好老师，possible_keys显示有一个可用的索引，但是key却显示没用到。主要是什么原因造成mysql不走索引的呢","like_count":0},{"had_liked":false,"id":221739,"user_name":"星期八","can_delete":false,"product_type":"c1","uid":1440429,"ip_address":"","ucode":"D8C66E7F61B0D1","user_header":"https://static001.geekbang.org/account/avatar/00/15/fa/ad/3fa02ac7.jpg","comment_is_top":false,"comment_ctime":1590579745,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1590579745","product_id":100020801,"comment_content":"Index Nested-Loop Join NLJ<br>Simple Nested-Loop Join SNLJ<br>Block Nested-Loop Join BNL<br>Muti-Range Read MRR<br>Batch Key Access BKA<br>加索引<br>jion_buffer +where<br>sort_buffer 没有where<br>","like_count":0},{"had_liked":false,"id":208035,"user_name":"bin","can_delete":false,"product_type":"c1","uid":1460880,"ip_address":"","ucode":"6628A5A146D7AA","user_header":"https://static001.geekbang.org/account/avatar/00/16/4a/90/1209b51c.jpg","comment_is_top":false,"comment_ctime":1587261845,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1587261845","product_id":100020801,"comment_content":"林老师您好,有个关于join的场景想请教一下: <br><br>班主任表(t_teacher) ,数据量1000<br>CREATE TABLE `t_teacher` (<br>  `id` int(10)  NOT NULL AUTO_INCREMENT COMMENT &#39;主键&#39;,<br>  `name` varchar(100) NOT NULL ,<br>   age int(10)<br>  PRIMARY KEY (`id`),<br> KEY key_age (`age`)   <br>) ENGINE=InnoDB ;<br><br>学生表(t_stu),数据量300万<br>CREATE TABLE `t_stu` (<br>  `id` int(10)  NOT NULL AUTO_INCREMENT COMMENT &#39;主键&#39;,<br>  `name` varchar(100) NOT NULL ,<br>   teacher_id int(10),<br>  PRIMARY KEY (`id`) ,<br>  KEY key_tid (`teacher_id`) <br>) ENGINE=InnoDB ;<br><br>需求: 根据班主任名称查询学生<br>sql一(先where过滤再join):    select * from (select id from t_teacher where t_teacher.age &gt;= 50)t_tea  join t_stu on t_stu.teacher_id = t_tea.id <br>sql二(join之后再where过滤):  select from t_teacher t_tea join t_stu on t_stu.teacher_id = t_tea.id where t_tea.age &gt;= 50<br><br>结论: sql一 比sql二快(避免了很多不必要的join) ,性能更优(节约内存) 。<br><br><br><br>推论: 因为sql一先查age&gt;50的班主任(mysql会将t_tea子查询的结果按id排序) ,再join学生表。<br>就好比学校, 有班主任表、学生表 ， 现指定某几个班主任的班级到操场开会(班主任表关联学生表) ， <br>sql一: 把全校的班主任叫到操场然后指定几个班主任(where根据班主任过滤)，叫他们喊自己班的学生来<br>sql二: 把全校的班主任、学生都叫到操场，然后指定几个班主任的对应的班级留下(where根据班主任过滤) ， 其他班级的回去 。<br><br>请问我的理解正确吗?","like_count":0},{"had_liked":false,"id":205433,"user_name":"天","can_delete":false,"product_type":"c1","uid":1310629,"ip_address":"","ucode":"664E42100DE272","user_header":"https://static001.geekbang.org/account/avatar/00/13/ff/a5/02953912.jpg","comment_is_top":false,"comment_ctime":1586616298,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1586616298","product_id":100020801,"comment_content":"看着看着不知道我的理解是否正确<br><br>总结，能用被驱动表的索引的时候，就是INL（循环的直接用匹配到的join的索引字段去被驱动表树搜索）,如果用不了，用Simple Nested-Loop Join（直接用匹配的join字段去对被驱动表做全表扫描）数据量太大，一般都不用，其实用的是BNL（产生了join buffer概念，把驱动表的尽量一次装里面，然后扫描被驱动表的东西，说白了把需要多次全表扫描变成在内存比较）<br><br>然后BKA依赖MRR ，BKA对NLJ的优化方式是主要优化的是把join的字段批量放到join_buffer里达到顺序性，而对BNL的优化方式也一样，也是放到join_buffer,但是前提是要创建被驱动表的索引，也就是说兜了一大圈，BNL适用于数据量不大的，数据量大了就加索引（其实就是变得很想NLJ），开启MRR，触发BKA，对已经很像NLJ的BNL进行最后的MRR优化，不知这个理解对不对？","like_count":0},{"had_liked":false,"id":195045,"user_name":"森林木，","can_delete":false,"product_type":"c1","uid":1756086,"ip_address":"","ucode":"B25D6EC73F56EF","user_header":"https://static001.geekbang.org/account/avatar/00/1a/cb/b6/62f6b5df.jpg","comment_is_top":false,"comment_ctime":1585131007,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1585131007","product_id":100020801,"comment_content":"林老师如果用到了BKA算法，那么这个join_buffer是经过排序后有序的吧？然后在去被驱动表上的index上顺序读取。","like_count":0},{"had_liked":false,"id":194963,"user_name":"xuty","can_delete":false,"product_type":"c1","uid":1310250,"ip_address":"","ucode":"986CF5DCF02762","user_header":"https://static001.geekbang.org/account/avatar/00/13/fe/2a/5ee47dda.jpg","comment_is_top":false,"comment_ctime":1585124363,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1585124363","product_id":100020801,"comment_content":"MRR对于物理读有提升，如果数据本身就存在与innodb_buffer_pool中，反而会造成多余的排序开销嘛？","like_count":0},{"had_liked":false,"id":192430,"user_name":"明歌","can_delete":false,"product_type":"c1","uid":1445986,"ip_address":"","ucode":"2E91A2203052B6","user_header":"https://static001.geekbang.org/account/avatar/00/16/10/62/335856f7.jpg","comment_is_top":false,"comment_ctime":1584850351,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1584850351","product_id":100020801,"comment_content":"老师能否简单介绍一下使用in子查询和exists执行的原理及如何选择驱动表？","like_count":0},{"had_liked":false,"id":183993,"user_name":"毛立凡","can_delete":false,"product_type":"c1","uid":1067251,"ip_address":"","ucode":"7B3BD84187D39D","user_header":"https://static001.geekbang.org/account/avatar/00/10/48/f3/e7f9a26b.jpg","comment_is_top":false,"comment_ctime":1583198818,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1583198818","product_id":100020801,"comment_content":"“这个临时内存不是别人，就是 join_buffer”<br><br>哈哈 莫名被戳到萌点，还是我们的老朋友：join_buffer ！","like_count":0},{"had_liked":false,"id":176511,"user_name":"torres","can_delete":false,"product_type":"c1","uid":1108761,"ip_address":"","ucode":"34DABCFC7B74EA","user_header":"https://static001.geekbang.org/account/avatar/00/10/eb/19/76b0b98c.jpg","comment_is_top":false,"comment_ctime":1581077248,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1581077248","product_id":100020801,"comment_content":"老师，您好。 看文章中说，MRR是默认关闭的。我有个疑问，为什么默认关闭？ 是因为在某些没有必要使用的地方，会导致多余的内存开销？","like_count":0},{"had_liked":false,"id":175392,"user_name":"陈扬鸿","can_delete":false,"product_type":"c1","uid":1284708,"ip_address":"","ucode":"DDDA8493CDC83C","user_header":"https://static001.geekbang.org/account/avatar/00/13/9a/64/eea9aa33.jpg","comment_is_top":false,"comment_ctime":1580704311,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1580704311","product_id":100020801,"comment_content":"老师 我的mysql碰到如下性能问题 套一个子查询发现基本上要扫表所有的查 username是有索引的 但是如果把子查询的结果直接写到查询中 查询很快 这是mysql的优化器问题吗 如下是两种查询的结果<br>select sum(power) from t2 where username in (SELECT username from t2 a WHERE  `a`.`inviter` = &#39;xxxx&#39;  AND `a`.`type` &gt;= 1);<br>+------------------+<br>| sum(power)       |<br>+------------------+<br>| 788.000000000000 |<br>+------------------+<br>1 row in set (3.073 sec)<br><br>SELECT username from t2 a WHERE  `a`.`inviter` = &#39;xxxx&#39;  AND `a`.`type` &gt;= 1 的结果为&#39;xx1&#39;, &#39;xx2&#39;<br><br>select sum(power) from t2 where username in (&#39;xx1&#39;, &#39;xx2&#39;);<br>+------------------+<br>| sum(power)       |<br>+------------------+<br>| 788.000000000000 |<br>+------------------+<br>1 row in set (0.001 sec)","like_count":0},{"had_liked":false,"id":173896,"user_name":"Geek_eb2e49","can_delete":false,"product_type":"c1","uid":1637789,"ip_address":"","ucode":"21671F0C4E7872","user_header":"https://wx.qlogo.cn/mmopen/vi_32/4PvDe2mRia2vdMGyickA40y2libhpf8ibmIEQquLUZFMXUMqqDjfVb96Y69p7bS6USgxicOKCCHxQHczHBnNb5L9nfA/132","comment_is_top":false,"comment_ctime":1579766516,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1579766516","product_id":100020801,"comment_content":"老师，您好，刚开始学习mysql,很多词汇都比较陌生，想要请教下文中的BKA算法中。您说<br>‘NLJ 算法执行的逻辑是：从驱动表 t1，一行行地取出 a 的值，再到被驱动表 t2 去做 join。也就是说，对于表 t2 来说，每次都是匹配一个值。这时，MRR 的优势就用不上了。那怎么才能一次性地多传些值给表 t2 呢？方法就是，从表 t1 里一次性地多拿些行出来，一起传给表 t2。’<br>这里不是很明白，将把表 t1 的数据取出来一部分，先放到一个临时内存 join_buffer中，请问join_buffer中数据是如何与t2进行匹配的？全部一起传过去给表t2 ? 全部传过去以后接下来是怎么处理呢？","like_count":0},{"had_liked":false,"id":166252,"user_name":"Anthony","can_delete":false,"product_type":"c1","uid":1309908,"ip_address":"","ucode":"9E0C98A9123365","user_header":"https://static001.geekbang.org/account/avatar/00/13/fc/d4/743d3f02.jpg","comment_is_top":false,"comment_ctime":1577424266,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1577424266","product_id":100020801,"comment_content":"老师 结合上一节的知识 想到将<br>select * from t1 join t2 on (t1.b=t2.b) where t2.b&gt;=1 and t2.b&lt;=2000; 改成<br>select * from t2 straight_join t1 on (t1.b=t2.b) where t2.b&gt;=1 and t2.b&lt;=2000;就只需要比较2000*1000次了","like_count":0},{"had_liked":false,"id":156495,"user_name":"何妨","can_delete":false,"product_type":"c1","uid":1385377,"ip_address":"","ucode":"EC3983BFF7992A","user_header":"https://static001.geekbang.org/account/avatar/00/15/23/a1/b08f3ee7.jpg","comment_is_top":false,"comment_ctime":1574903035,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1574903035","product_id":100020801,"comment_content":"看到老师说的回表问题，说到了主键连续的问题，我想问一下老师是如何看 数据库自增主键和我们自己生成的唯一主键呢？在建表的时候该如果权衡呢？","like_count":0},{"had_liked":false,"id":153945,"user_name":"随心而至","can_delete":false,"product_type":"c1","uid":1097836,"ip_address":"","ucode":"31866865255101","user_header":"https://static001.geekbang.org/account/avatar/00/10/c0/6c/29be1864.jpg","comment_is_top":false,"comment_ctime":1574334819,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1574334819","product_id":100020801,"comment_content":"缓存，顺序读写比随机读写快得多等等，我发现大牛们都在想方设法利用这些最基本的原理，计算机科学真有趣。","like_count":0},{"had_liked":false,"id":153406,"user_name":"Jayden 王凯豪","can_delete":false,"product_type":"c1","uid":1592236,"ip_address":"","ucode":"6CAADB9B449892","user_header":"https://static001.geekbang.org/account/avatar/00/18/4b/ac/2a48928f.jpg","comment_is_top":false,"comment_ctime":1574231305,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1574231305","product_id":100020801,"comment_content":"MySQL 8.0.18 默认已经开启hash join","like_count":0},{"had_liked":false,"id":147993,"user_name":"tiger54910","can_delete":false,"product_type":"c1","uid":1500686,"ip_address":"","ucode":"F4D5BE1864E097","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Qq9IlgLjo8CVKTc93AHsicwDMJq3sbN4UsubLJXUQxWKDkEblaUHYviaq8TuVWygqkubwFEAa4qLiaQF6PyrfEQDg/132","comment_is_top":false,"comment_ctime":1572925375,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1572925375","product_id":100020801,"comment_content":"老师，请问下怎么使用flexview物化视图，因为我的检索用了七八个表join，查询速度很慢，谢谢","like_count":0},{"had_liked":false,"id":134187,"user_name":"从心开始","can_delete":false,"product_type":"c1","uid":1187225,"ip_address":"","ucode":"7BC50E93FE52F6","user_header":"https://static001.geekbang.org/account/avatar/00/12/1d/99/9fae83db.jpg","comment_is_top":false,"comment_ctime":1568772169,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1568772169","product_id":100020801,"comment_content":"老师，现有商品和商品分类两个表，建表语句如下，查询商品和商品的分类信息，下面的SQL能如何优化一下吗？<br>  <br>#商品信息表<br>CREATE TABLE `goods` (<br>  `ID` BIGINT(20) UNSIGNED NOT NULL AUTO_INCREMENT,<br>  `GOODS_NO` VARCHAR(30) DEFAULT NULL COMMENT &#39;商品代码&#39;,<br>  `GOODS_NAME` VARCHAR(500) DEFAULT NULL COMMENT &#39;名称&#39;,<br>  `GOODS_TYPE_NO` VARCHAR(50) DEFAULT NULL COMMENT &#39;商品分类&#39;,<br>  PRIMARY KEY (`ID`),<br>  UNIQUE KEY `idx_uni_goodsNo` (`GOODS_NO`),<br>  KEY `idx_base_goodsTypeNo` (`GOODS_TYPE_NO`)<br>) ENGINE=INNODB DEFAULT CHARSET=utf8     <br><br><br>#商品分类 记录了1级,2级，3级分类，行记录包含父类分类号<br><br>CREATE TABLE `goods_catalog` (<br>  `ID` BIGINT(20) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT &#39;编号&#39;,<br>  `GOODS_TYPE_NO` VARCHAR(10) DEFAULT NULL COMMENT &#39;商品类别编码&#39;,<br>  `CATALOG_NAME` VARCHAR(100) DEFAULT NULL COMMENT &#39;商品类别名称&#39;,<br>  `CATALOG_LEVEL` VARCHAR(10) DEFAULT NULL COMMENT &#39;类别层级&#39;,<br>  `PARENTID` DECIMAL(15,4) DEFAULT NULL COMMENT &#39;父类别&#39;,<br>  PRIMARY KEY (`ID`),<br>  KEY `idx_parentid` (`PARENTID`),<br>  KEY `ix_goods_type_No_uni` (`GOODS_TYPE_NO`) USING BTREE<br>) ENGINE=INNODB DEFAULT CHARSET=utf8 COMMENT=&#39;商品分类&#39;<br><br><br>#查询某个商品的1,2,3级分类信息，如何优化<br>DESC SELECT goods_no, goods_name,c3.`CATALOG_NAME` ,c2.`CATALOG_NAME`,c1.`CATALOG_NAME`<br> FROM goods g INNER JOIN <br>goods_catalog c3 ON g.`GOODS_TYPE_NO` = c3.`GOODS_TYPE_NO`<br>INNER JOIN goods_catalog c2 ON c2.`GOODS_TYPE_NO` = c3.`PARENTID`<br>INNER JOIN goods_catalog c1 ON c1.`GOODS_TYPE_NO` = c2.`PARENTID`<br>WHERE goods_no = &#39;sku1&#39;;<br>","like_count":0},{"had_liked":false,"id":127823,"user_name":"༺ཉི།渔夫།ཉྀ༻","can_delete":false,"product_type":"c1","uid":1498344,"ip_address":"","ucode":"207C67021ADF39","user_header":"https://static001.geekbang.org/account/avatar/00/16/dc/e8/11377f97.jpg","comment_is_top":false,"comment_ctime":1566798398,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1566798398","product_id":100020801,"comment_content":"阿里巴巴java开发手册上说写超过三张表禁止join，这是为什么？不让用join用where？","like_count":0},{"had_liked":false,"id":120994,"user_name":"钱","can_delete":false,"product_type":"c1","uid":1009652,"ip_address":"","ucode":"2C92A243A463D4","user_header":"https://static001.geekbang.org/account/avatar/00/0f/67/f4/9a1feb59.jpg","comment_is_top":false,"comment_ctime":1565046456,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1565046456","product_id":100020801,"comment_content":"SQL语句优化的思路，也适用于其他的性能优化<br>1：使用上索引<br>2：缩小查找范围<br>3：尽量在内存中操作<br>是否使用索引及查找范围大小，可以使用explain来看，如果用上了索引且范围已经最小，应该不慢，如果还嫌慢，可以考虑缓存。","like_count":0},{"had_liked":false,"id":120545,"user_name":"null","can_delete":false,"product_type":"c1","uid":1024294,"ip_address":"","ucode":"F9039EFED6B55D","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaELZPnUAiajaR5C25EDLWeJURggyiaOP5GGPe2qlwpQcm5e3ybib8OsP4tvddFDLVRSNNGL5I3SFPJHsA/132","comment_is_top":false,"comment_ctime":1564926396,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1564926396","product_id":100020801,"comment_content":"课后思考题：<br>select * from t1 <br>join t2 on(t1.a=t2.a) <br>join t3 on (t2.b=t3.b) <br>where t1.c&gt;=X and t2.c&gt;=Y and t3.c&gt;=Z;<br><br>结论：<br>t1 加 c 索引<br>t2 加 a 索引<br>t3 加 b 索引<br><br>思考过程：<br>t1：<br>加 c 索引是为了从驱动表取数到 join_buffer 时（假设开启 mmr 优化），可以走索引快速检索。<br><br>t2：<br>加 a 索引是被驱动表可以用 NLJ 算法，也可以优化成 BKA 算法。因为是 select *，所以不加 a,c 联合索引，反正都是要走 t2 主键索引。<br><br>t3：<br>加 b 索引的理由同 t2。不加 b,c 联合索引的理由也同 t2。","like_count":0},{"had_liked":false,"id":115273,"user_name":"ZHANG","can_delete":false,"product_type":"c1","uid":1442437,"ip_address":"","ucode":"BAFD110AE33328","user_header":"https://static001.geekbang.org/account/avatar/00/16/02/85/9a81a973.jpg","comment_is_top":false,"comment_ctime":1563522792,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1563522792","product_id":100020801,"comment_content":"老师，这个地方不太明白<br>如果要使用 BKA 优化算法的话，你需要在执行 SQL 语句之前，先设置<br>set optimizer_switch=‘mrr=on,mrr_cost_based=off,batched_key_access=on’;<br>这个设置以后是只对当前SQL生效吗，当前SQL执行完以后会影响其他SQL吗<br>","like_count":0,"discussions":[{"author":{"id":1622109,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erPMtAfnQdpx1yOZQ2ic7icqUs3tvibEjUXQMUXKiaakyuIho6k6vmdl46nrdWjXIjPIRg9Pmco00tR5w/132","nickname":"小氘","note":"","ucode":"DA55B9A02D9EE0","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":16532,"discussion_content":"应该是只对当前线程有效，断开连接后就无效了。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1568898821,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":97472,"user_name":"lmdcx","can_delete":false,"product_type":"c1","uid":1334409,"ip_address":"","ucode":"F2CDD0091ADFD7","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIjRETqRjvLESLDZkNTjIiaSibtNYBaS1o8WMUicOFn3ycF3Mgh6LRJibqSBjVBjiaO2ibW0gHkafATb21A/132","comment_is_top":false,"comment_ctime":1558679032,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1558679032","product_id":100020801,"comment_content":"我看了半天不知道理解的是否有误：<br>1. 针对单表的回表查询的优化叫 MRR<br>2. 针对两张表做关联查询的优化叫 BKA，当然这里面也用了BNL<br>当然前提是 回表 、 关联查询用的是主外键做关联<br>对吗？<br>（如果对的话，感觉老外就是喜欢啥东西都愿意多搞个概念把别人套路住，以便于得人心？）","like_count":0},{"had_liked":false,"id":84549,"user_name":"Lukia","can_delete":false,"product_type":"c1","uid":1028698,"ip_address":"","ucode":"C19472337BCCC6","user_header":"https://static001.geekbang.org/account/avatar/00/0f/b2/5a/574f5bb0.jpg","comment_is_top":false,"comment_ctime":1554873882,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1554873882","product_id":100020801,"comment_content":"老师好，请教一个关于mrr的问题，如果根据索引a的范围查询得到主键的集合值是很松散的情况（不够紧凑连续，导致需要连续扫描大量的磁盘块），在这种情况下使用mrr的提升可能也会得不偿失吧","like_count":0},{"had_liked":false,"id":82832,"user_name":"My dream","can_delete":false,"product_type":"c1","uid":1077733,"ip_address":"","ucode":"2FEFB344230C17","user_header":"https://static001.geekbang.org/account/avatar/00/10/71/e5/bcdc382a.jpg","comment_is_top":false,"comment_ctime":1554337650,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1554337650","product_id":100020801,"comment_content":"老师，有这样一种常用的场景：MySQL实现在同一表中的节点级联查询，我看网上很多方案是通过函数来实现的：<br>根据根节点id查询其所有子节点id（包含根节点）<br>CREATE TABLE `sys_dept` (<br>  `dept_id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#39;部门ID&#39;,<br>  `parent_id` bigint(20) NOT NULL COMMENT &#39;上级部门ID&#39;,<br>  `name` varchar(60) NOT NULL COMMENT &#39;部门&#47;小组名&#39;,<br>  `dept_type` int(3) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;部门类型（1部门，2小组）&#39;,<br>  `order_num` int(11) NOT NULL COMMENT &#39;排序&#39;,<br>  `del_flag` tinyint(4) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;是否删除（-1：已删除，0：正常）&#39;,<br>  PRIMARY KEY (`dept_id`)<br>) ENGINE=InnoDB AUTO_INCREMENT=9 DEFAULT CHARSET=utf8 COMMENT=&#39;部门表&#39;;<br>实现的方法是：<br>节点级联查询函数：<br>delimiter &#47;&#47; <br>CREATE FUNCTION `getChildList`(rootId bigint)<br>RETURNS varchar(1000) <br><br>BEGIN<br>\tDECLARE temp VARCHAR(1000);<br>    DECLARE tempChild VARCHAR(1000);<br><br>    SET temp = &#39;$&#39;;<br>    SET tempChild =cast(rootId as CHAR);<br><br>    WHILE tempChild is not null DO<br>    \tSET temp = concat(temp,&#39;,&#39;,tempChild);<br>        SELECT group_concat(dept_id) INTO tempChild FROM  sys_dept where FIND_IN_SET(parent_id,tempChild) &gt; 0;<br>   \tEND WHILE;<br>    RETURN temp; <br>END<br>&#47;&#47;<br>在查询是就直接：查询根节点id为4的子节点id<br>select dept_id from sys_dept where FIND_IN_SET(dept_id,getChildList(4));<br>我想请教的是，这样的实现方法效率高不高？还有没有更好更简单的办法？特别是在无限级联的情况下","like_count":0},{"had_liked":false,"id":81676,"user_name":"不忘初心","can_delete":false,"product_type":"c1","uid":1015494,"ip_address":"","ucode":"5B5F45564DDBE7","user_header":"https://static001.geekbang.org/account/avatar/00/0f/7e/c6/83684988.jpg","comment_is_top":false,"comment_ctime":1554003527,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1554003527","product_id":100020801,"comment_content":"基于临时表的改进方案，对于能够提前过滤出小数据的 join 语句来说，效果还是很好的；<br>--&gt;可以当成子查询？","like_count":0},{"had_liked":false,"id":81636,"user_name":"啊啊啊哦哦","can_delete":false,"product_type":"c1","uid":1309877,"ip_address":"","ucode":"68C7153ECAAC57","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/RNO4yZyBvic914hewmNNE8iblYDcfv5yGHZ9OnKuCuZXNmGR0F5qV3icKLT2xpMt66GyEpicZVvrmz8A6TIqt92MQg/132","comment_is_top":false,"comment_ctime":1553992998,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1553992998","product_id":100020801,"comment_content":"问题一 mrr算法 会导致返回的数据 顺序上不一样吗。  比如。本来id等于3的排在第一条。id等于1的排在第二条。 优化后返回的列表顺序是否会对调<br>问题二。select * from a left join b on a.c =b.<br>c  limit 10。c字段无索引。   这种join的语句假设a是小表。  执行语句是否是a 表要执行全表扫描<br>然后。b表只要扫描过程中只要找到10条就立即终于。 类似的如果要连。 比如5张表。 是否要正常执行完前4次表的搜索然后。在第5张的时候找到对应limit 的时候立刻终止。  文章中并没有 limit的情况。所以想问下","like_count":0,"discussions":[{"author":{"id":1185046,"avatar":"https://static001.geekbang.org/account/avatar/00/12/15/16/0aae41a1.jpg","nickname":"no13bus","note":"","ucode":"69FA1A719DA4F6","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":21408,"discussion_content":"explain了下，发现表a和表b扫描的行数和没limit的情况是一样的。应该是select结束后，从结果集里面limit 10条出来","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1569479787,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":76533,"user_name":"天使梦泪","can_delete":false,"product_type":"c1","uid":1235750,"ip_address":"","ucode":"782991747DD424","user_header":"https://static001.geekbang.org/account/avatar/00/12/db/26/3c8d68fb.jpg","comment_is_top":false,"comment_ctime":1552628848,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1552628848","product_id":100020801,"comment_content":"老师，我有个问题，可以给讲下left join和inner join的主要区别吗？数据量很大时在驱动表和性能方面的不同。","like_count":0},{"had_liked":false,"id":72875,"user_name":"小徐","can_delete":false,"product_type":"c1","uid":1303757,"ip_address":"","ucode":"522B5CD3732313","user_header":"https://static001.geekbang.org/account/avatar/00/13/e4/cd/fc140973.jpg","comment_is_top":false,"comment_ctime":1551749660,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1551749660","product_id":100020801,"comment_content":"With MRR, the scan is broken up into multiple ranges, each for a single value of key_part1 (1000,<br>1001, ... , 1999). Each of these scans need look only for tuples with key_part2 = 10000. If the index<br>contains many tuples for which key_part2 is not 10000, MRR results in many fewer index tuples<br>being read.<br>感觉这个ICP功能了？<br>","like_count":0},{"had_liked":false,"id":71630,"user_name":"immortalCockroach","can_delete":false,"product_type":"c1","uid":1157912,"ip_address":"","ucode":"9A4F497BEA7DFB","user_header":"https://static001.geekbang.org/account/avatar/00/11/ab/18/b01e71d1.jpg","comment_is_top":false,"comment_ctime":1551403005,"is_pvip":false,"replies":[{"id":"25738","content":"细致<br>就是故意设计成递增的^_^<br>mrr的过程中会对id做排序，体现这个优化的作用","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1551404943,"ip_address":"","comment_id":71630,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1551403005","product_id":100020801,"comment_content":"在MRR优化那段，这个例子中a是递增，对应id列是递减，刚好和id递增相反，那这样难道不能“逆序”顺序磁盘读吗？谢谢老师","like_count":0,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":441243,"discussion_content":"细致\n就是故意设计成递增的^_^\nmrr的过程中会对id做排序，体现这个优化的作用","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1551404943,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1148537,"avatar":"https://static001.geekbang.org/account/avatar/00/11/86/79/28fcafa6.jpg","nickname":"胡红伟","note":"","ucode":"33F12A97311F63","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":279419,"discussion_content":"mysql并不知道查出来的id是什么顺序","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1591342921,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":71456,"user_name":"ghostjia","can_delete":false,"product_type":"c1","uid":1109757,"ip_address":"","ucode":"61BF8E6903EE85","user_header":"https://static001.geekbang.org/account/avatar/00/10/ee/fd/a29a201f.jpg","comment_is_top":false,"comment_ctime":1551345593,"is_pvip":false,"replies":[{"id":"25552","content":"看你这个查询， 第一个表满足条件的有37278条呢。。<br>单表自己查是快的，但是第二个语句是要做37278次主键查询","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1551350665,"ip_address":"","comment_id":71456,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1551345593","product_id":100020801,"comment_content":"遇到一种情况 单表sum 很快，当时和一张大表join 时就很慢，求解决思路：<br> SELECT rp.products_id AS ProductsId, sum( rp.products_quantity) AS saleCount FROM test_orders_products AS rp  WHERE  rp.products_id = 740818 ;<br>+------------+-----------+<br>| ProductsId | saleCount |<br>+------------+-----------+<br>|     740818 |     20772 |<br>+------------+-----------+<br>1 row in set (0.01 sec)<br><br><br><br>但是和一张大表做join,数据就出不来。<br>mysql&gt; desc SELECT rp.products_id AS ProductsId, sum( rp.products_quantity) AS saleCount FROM test_orders_products AS rp  JOIN test_orders as r ON rp.orders_id = r.orders_id WHERE  rp.products_id = 740818 ;<br>+----+-------------+-------+--------+------------------------------------------------------------+----------+---------+--------------------------------+-------+-------------+<br>| id | select_type | table | type   | possible_keys                                              | key      | key_len | ref                            | rows  | Extra       |<br>+----+-------------+-------+--------+------------------------------------------------------------+----------+---------+--------------------------------+-------+-------------+<br>|  1 | SIMPLE      | rp    | ref    | idx_orders_id_prod_id_zen,idx_orders_products_pid,idx_test | idx_test | 4       | const                          | 37278 |             |<br>|  1 | SIMPLE      | r     | eq_ref | PRIMARY                                                    | PRIMARY  | 4       | litb_inbox_master.rp.orders_id |     1 | Using index |<br>+----+-------------+-------+--------+------------------------------------------------------------+----------+---------+--------------------------------+-------+-------------+<br>2 rows in set (0.00 sec)<br>问题是也走了被驱动表的primary key了。 还是会慢。<br>求解决思路。","like_count":0,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":441162,"discussion_content":"看你这个查询， 第一个表满足条件的有37278条呢。。\n单表自己查是快的，但是第二个语句是要做37278次主键查询","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1551350665,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":70450,"user_name":"super blue cat","can_delete":false,"product_type":"c1","uid":1078411,"ip_address":"","ucode":"27DBB28EF19AB3","user_header":"https://static001.geekbang.org/account/avatar/00/10/74/8b/840afbd8.jpg","comment_is_top":false,"comment_ctime":1551100386,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"1551100386","product_id":100020801,"comment_content":"为什么Id增序才比较接近顺序读呢？ 原因是磁盘扫数据是单向的吗？🧐","like_count":0,"discussions":[{"author":{"id":1065351,"avatar":"https://static001.geekbang.org/account/avatar/00/10/41/87/d26efb2e.jpg","nickname":"SuperSnow","note":"","ucode":"84C89AA8083E6A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":181231,"discussion_content":"B+TREE规则","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1582349131,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1526355,"avatar":"https://static001.geekbang.org/account/avatar/00/17/4a/53/063f9d17.jpg","nickname":"moonfox","note":"","ucode":"902BFF40EFA9FA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1065351,"avatar":"https://static001.geekbang.org/account/avatar/00/10/41/87/d26efb2e.jpg","nickname":"SuperSnow","note":"","ucode":"84C89AA8083E6A","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":329151,"discussion_content":"逆序数据在文件末端，读取他前面的数据叶磁盘要再转一圈才可以","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606319006,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":181231,"ip_address":""},"score":329151,"extra":""}]}]},{"had_liked":false,"id":65031,"user_name":"dzkk","can_delete":false,"product_type":"c1","uid":1301932,"ip_address":"","ucode":"A81EFDB1D43C0D","user_header":"https://static001.geekbang.org/account/avatar/00/13/dd/ac/f40bbd15.jpg","comment_is_top":false,"comment_ctime":1549007480,"is_pvip":false,"replies":[{"id":"23070","content":"未知效果选择 是啥意思^_^","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1549038976,"ip_address":"","comment_id":65031,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1549007480","product_id":100020801,"comment_content":"老师，对于关联查询（inner join），个人有几点理解，请帮助审核是否正确，谢了。<br>正确选择：<br>    结果集小的为驱动表，且被驱动表有索引<br>未知效果选择：<br>    1）结果集小的为驱动表，但是被驱动表没有索引<br>    2）结果集大的为驱动表，但是被驱动表有索引<br>最差选择：<br>    结果集大的为驱动表，且被驱动表没有索引<br>","like_count":0,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438286,"discussion_content":"未知效果选择 是啥意思^_^","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1549038976,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":64998,"user_name":"读书看报","can_delete":false,"product_type":"c1","uid":1306147,"ip_address":"","ucode":"3B4717314B52A9","user_header":"https://static001.geekbang.org/account/avatar/00/13/ee/23/b92b0811.jpg","comment_is_top":false,"comment_ctime":1548994787,"is_pvip":false,"replies":[{"id":"23025","content":"这个信息太不足了😅<br>我第一时间反应是不是有limit？<br><br>你给贴一下表结构，<br>sql语句，还有explain这个语句的结果😆，我们再来分析下哈","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1549003437,"ip_address":"","comment_id":64998,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1548994787","product_id":100020801,"comment_content":"YEAR(txsj) = &#39;2018&#39; 有结果集，YEAR(txsj) = &#39;2019&#39; 无结果集，<br>YEAR(txsj) = &#39;2018&#39; 和 YEAR(txsj) = &#39;2019&#39; 查询所需时间 后者是前者的10倍<br>请老师分析下大概什么原因？","like_count":0,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438266,"discussion_content":"这个信息太不足了😅\n我第一时间反应是不是有limit？\n\n你给贴一下表结构，\nsql语句，还有explain这个语句的结果😆，我们再来分析下哈","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1549003437,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":64966,"user_name":"库淘淘","can_delete":false,"product_type":"c1","uid":1310240,"ip_address":"","ucode":"90813B0C46E978","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eqibSwKPg7hiapc49qoM4dibhM3fYANPjfltF2ibBZ3dHX2hibjg5EIIcziahrmjO5R2XrcRibvU39TQS7jg/132","comment_is_top":false,"comment_ctime":1548987265,"is_pvip":false,"replies":[{"id":"23013","content":"啥意思，语句写2000，还是要取2000行的呀","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1548989560,"ip_address":"","comment_id":64966,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1548987265","product_id":100020801,"comment_content":"select * from t2 where b&gt;=1 and b&lt;=2000; 这个b取1000不就行了，为何2000没看懂","like_count":0,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438255,"discussion_content":"啥意思，语句写2000，还是要取2000行的呀","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1548989560,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":64953,"user_name":"书策稠浊","can_delete":false,"product_type":"c1","uid":1307497,"ip_address":"","ucode":"A29875CE15FDA3","user_header":"https://static001.geekbang.org/account/avatar/00/13/f3/69/7039d03f.jpg","comment_is_top":false,"comment_ctime":1548984141,"is_pvip":false,"replies":[{"id":"23011","content":"实践验证一下哈","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1548987139,"ip_address":"","comment_id":64953,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1548984141","product_id":100020801,"comment_content":"有点记不清楚。","like_count":0,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438248,"discussion_content":"实践验证一下哈","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1548987139,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]}]}