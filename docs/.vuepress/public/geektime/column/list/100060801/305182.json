{"id":305182,"title":"15 | 协同过滤：最经典的推荐模型，我们应该掌握什么？","content":"<p>你好，我是王喆。今天我们要开启推荐模型篇的学习。</p><p>推荐模型篇是整个课程中最重要的一个模块，因为推荐模型直接决定了最终物品排序的结果，它的好坏也直接影响着推荐效果的优劣。而且，从某种意义上讲，推荐系统的整体架构都是围绕着推荐模型搭建的，用于支持推荐模型的上线、训练、评估、服务。因此，我一直把<strong>推荐模型称作“推荐系统这个皇冠上的明珠”</strong>。</p><p>而提起推荐模型，我们就不能不提协同过滤算法。它可能是推荐系统自诞生以来最经典的算法，且没有之一。虽然我们课程的主题是“深度学习”推荐系统，但协同过滤以及它后续衍生出来的各类模型，都与深度学习推荐模型有着千丝万缕的联系。因此，在进入深度学习模型之前，掌握协同过滤及其衍生模型是非常有必要的。</p><p>今天，我就来给你讲讲经典协同过滤和它的衍生模型矩阵分解的原理，以及相关的Spark实现。</p><h2>协同过滤算法的基本原理</h2><p>我在特征工程篇曾经提到过：<strong>“用户行为数据是推荐系统最常用，也是最关键的数据。用户的潜在兴趣、用户对物品的评价好坏都反映在用户的行为历史中”</strong>。</p><p>而协同过滤算法，就是一种完全依赖用户和物品之间行为关系的推荐算法。我们从它的名字“协同过滤”中，也可以窥探到它背后的原理，就是 <strong>“协同大家的反馈、评价和意见一起对海量的信息进行过滤，从中筛选出用户可能感兴趣的信息”</strong>。</p><!-- [[[read_end]]] --><p>这么说可能还是太抽象了，接下来，我们就一起看一个电商场景下的例子。通过分析这个例子，你就能搞清楚协同过滤算法的推荐过程了。这个电商推荐系统从得到原始数据到生成最终推荐分数，全过程一共可以总结为6个步骤，如下所示。下面，我们一一来讲。</p><p><img src=\"https://static001.geekbang.org/resource/image/39/42/3960001f6c049652160cb16ff3ddee42.jpg?wh=2136*1452\" alt=\"\" title=\"图1 协同过滤的过程 （来自《深度学习推荐系统》）\"></p><p>首先，我们可以看到，电商网站的商品库里一共有4件商品：一个游戏机、一本小说、一本杂志，以及一台电视机。假设，现在有一名用户X访问了这个电商网站，电商网站的推荐系统需要决定是否推荐电视机给用户X。</p><p>为了进行这项预测，推荐系统可以利用的数据有用户X对其他商品的历史评价数据，以及其他用户对这些商品的历史评价数据。我在图1(b)中用绿色“点赞”的标志表示好评，用红色“踩”的标志表示了差评。这样一来，用户、商品和评价记录就构成了带有标识的有向图。</p><p>接下来，为了方便计算，我们将有向图转换成矩阵的形式。这个矩阵表示了物品共同出现的情况，因此被称为“共现矩阵”。其中，用户作为矩阵行坐标，物品作为列坐标，我们再把“点赞”和“踩”的用户行为数据转换为矩阵中相应的元素值。这里，我们将“点赞”的值设为1，将“踩”的值设为-1，“没有数据”置为0（如果用户对物品有具体的评分，那么共现矩阵中的元素值可以取具体的评分值，没有数据时的默认评分也可以取评分的均值）。</p><p>你发现了吗，生成共现矩阵之后，推荐问题就转换成了预测矩阵中问号元素（图1(d)所示）的值的问题。由于在“协同”过滤算法中，推荐的原理是让用户考虑与自己兴趣相似用户的意见。因此，我们预测的第一步就是找到与用户X兴趣最相似的n（Top n用户，这里的n是一个超参数）个用户，然后综合相似用户对“电视机”的评价，得出用户X对“电视机”评价的预测。</p><p>从共现矩阵中我们可以知道，用户B和用户C由于跟用户X的行向量近似，被选为Top n（这里假设n取2）相似用户，接着在图1(e)中我们可以看到，用户B和用户C对“电视机”的评价均是负面的。因为相似用户对“电视机”的评价是负面的，所以我们可以预测出用户X对“电视机”的评价也是负面的。在实际的推荐过程中，推荐系统不会向用户X推荐“电视机”这一物品。</p><p>到这里，协同过滤的算法流程我们就说完了。也许你也已经发现了，这个过程中有两点不严谨的地方，一是用户相似度到底该怎么定义，二是最后我们预测用户X对“电视机”的评价也是负面的，这个负面程度应该有一个分数来衡量，但这个推荐分数该怎么计算呢？</p><h3>计算用户相似度</h3><p>首先，我们来解决计算用户相似度的问题。计算用户相似度其实并不是什么难事，因为在共现矩阵中，每个用户对应的行向量其实就可以当作一个用户的Embedding向量。相信你早已经熟悉Embedding相似度的计算方法，那我们这里依葫芦画瓢就可以知道基于共现矩阵的用户相似度计算方法啦。</p><p>最经典的方法就是利用余弦相似度了，它衡量了用户向量i和用户向量j之间的向量夹角大小。夹角越小，余弦相似度越大，两个用户越相似，它的定义如下：</p><center>$\\operatorname{sim}(i, j)=\\cos (\\vec{\\\\i}, \\vec{\\\\j})=\\frac{\\\\{\\\\i} \\cdot \\vec{\\\\j}}{\\\\||\\vec{\\\\i}\\\\|| \\times\\|\\vec{j}\\\\||}$</center><p>除了最常用的余弦相似度之外，相似度的定义还有皮尔逊相关系数、欧式距离等等。咱们课程主要使用的是余弦相似度，因此你只要掌握它就可以了，其他的定义我这里不再多说了。</p><h3>用户评分的预测</h3><p>接下来，我们再来看看推荐分数的计算。在获得Top n个相似用户之后，利用Top n用户生成最终的用户$u$对物品$p$的评分是一个比较直接的过程。这里，我们假设的是“目标用户与其相似用户的喜好是相似的”，根据这个假设，我们可以利用相似用户的已有评价对目标用户的偏好进行预测。最常用的方式是，利用用户相似度和相似用户评价的加权平均值，来获得目标用户的评价预测，公式如下所示。</p><p>$$<br>\n\\mathrm{R}_{u, p}=\\frac{\\sum_{s \\epsilon S}\\left(w_{u, s} \\cdot R_{s, p}\\right)}{\\sum_{s \\in S} w_{u, s}}<br>\n$$</p><p>其中，权重$w_{u, s}$是用户$u$和用户$s$的相似度，$R_{s, p}$ 是用户$s$对物品$p$的评分。</p><p>在获得用户$u$对不同物品的评价预测后，最终的推荐列表根据评价预测得分进行排序即可得到。到这里，我们就完成了协同过滤的全部推荐过程。</p><h2>矩阵分解算法的原理</h2><p>虽然说协同过滤是目前公认的最经典的推荐算法，但我们还是可以轻松找出它的缺点，那就是共现矩阵往往非常稀疏，在用户历史行为很少的情况下，寻找相似用户的过程并不准确。于是，著名的视频流媒体公司Netflix对协同过滤算法进行了改进，提出了矩阵分解算法，加强了模型处理稀疏矩阵的能力。</p><p>这里，我们还是用一个直观的例子来理解一下什么叫做矩阵分解。这次我从Netflix的矩阵分解论文中截取了两张示意图（图2），来比较协同过滤和矩阵分解的原理。</p><p><img src=\"https://static001.geekbang.org/resource/image/63/f8/63f52fe38288a9b31c2d8e7640f8c4f8.jpg?wh=1920*804\" alt=\"\" title=\"图2 “协同过滤（左a）”和“矩阵分解（右b）”的原理图\"></p><p>如图2(a)所示，协同过滤算法找到用户可能喜欢的视频的方式很直观，就是利用用户的观看历史，找到跟目标用户Joe看过同样视频的相似用户，然后找到这些相似用户喜欢看的其他视频，推荐给目标用户Joe。</p><p>矩阵分解算法则是期望为每一个用户和视频生成一个隐向量，将用户和视频定位到隐向量的表示空间上（如图2(b)所示），距离相近的用户和视频表明兴趣特点接近，在推荐过程中，我们就应该把距离相近的视频推荐给目标用户。例如，如果希望为图2(b)中的用户Dave推荐视频，我们可以找到离Dave的用户向量最近的两个视频向量，它们分别是《Ocean’s 11》和《The Lion King》，然后我们可以根据向量距离由近到远的顺序生成Dave的推荐列表。</p><p>这个时候你肯定觉得，矩阵分解不就是相当于一种Embedding方法嘛。没错，<strong>矩阵分解的主要过程，就是先分解协同过滤生成的共现矩阵，生成用户和物品的隐向量，再通过用户和物品隐向量间的相似性进行推荐</strong>。</p><p>那这个过程的关键就在于如何分解这个共现矩阵了。从形式上看，矩阵分解的过程是直观的，就是把一个mxn的共现矩阵，分解成一个mxk的用户矩阵和kxn的物品矩阵相乘的形式（如图3）。</p><p><img src=\"https://static001.geekbang.org/resource/image/60/fb/604b312899bff7922528df4836c10cfb.jpeg?wh=1920*646\" alt=\"\" title=\"图3 矩阵分解示意图\"></p><p>有了用户矩阵和物品矩阵，用户隐向量和物品隐向量就非常好提取了。用户隐向量就是用户矩阵相应的行向量，而物品隐向量就是物品矩阵相应的列向量。</p><p>那关键问题就剩下一个，也就是我们该通过什么方法把共现矩阵分解开呢？最常用的方法就是梯度下降。梯度下降的原理我们在<a href=\"https://time.geekbang.org/column/article/291245\">第3讲</a>学习过，简单来说就是通过求取偏导的形式来更新权重。梯度更新的公式是 $(w^{t+1}=w^{t}-\\alpha * \\frac{\\partial L}{\\partial w})$。为了实现梯度下降，最重要的一步是定义损失函数$L$，定义好损失函数我们才能够通过求导的方式找到梯度方向，这里我们就给出矩阵分解损失函数的定义如下。</p><p><img src=\"https://static001.geekbang.org/resource/image/30/3e/3034f1205b8f9ce0d2f736957ff1933e.jpeg?wh=1920*438\" alt=\"\"></p><p>这个目标函数里面，${r}_{u i}$ 是共现矩阵里面用户$u$对物品$i$的评分，${q}_{i}$ 是物品向量，${p}_{u}$ 是用户向量，K是所有用户评分物品的全体集合。通过目标函数的定义我们可以看到，我们要求的物品向量和用户向量，是希望让物品向量和用户向量之积跟原始的评分之差的平方尽量小。简单来说就是，我们希望用户矩阵和物品矩阵的乘积尽量接近原来的共现矩阵。</p><p>在通过训练得到用户隐向量和物品隐向量之后，在服务器内部的推荐过程跟我们之前讲过的Embedding推荐是一样的，你也已经在Sparrow RecSys里面实践过，是这方面的专家了，我就不再多说了。</p><h2>矩阵分解算法的Spark实现</h2><p>基础知识学完，接下来又到了show me the code时间了。这里，我们继续使用Spark实现矩阵分解算法，我会结合下面的关键代码一起来讲。</p><p>我们可以看到，因为Spark MLlib已经帮我们封装好了模型，所以矩阵分解算法实现起来非常简单，还是通过我们熟悉的三步来完成，分别是定义模型，使用fit函数训练模型，提取物品和用户向量。</p><p>但是有一点我们需要注意，就是在模型中，我们需要在模型中指定训练样本中用户ID对应的列userIdInt和物品ID对应的列movieIdInt，并且两个ID列对应的数据类型需要是int类型的。</p><pre><code>// 建立矩阵分解模型\nval als = new ALS()\n  .setMaxIter(5)\n  .setRegParam(0.01)\n  .setUserCol(&quot;userIdInt&quot;)\n  .setItemCol(&quot;movieIdInt&quot;)\n  .setRatingCol(&quot;ratingFloat&quot;)\n\n\n//训练模型\nval model = als.fit(training)\n\n\n//得到物品向量和用户向量\nmodel.itemFactors.show(10, truncate = false)\nmodel.userFactors.show(10, truncate = false\n\n</code></pre><p>其实，矩阵分解算法得出的结果，你完全可以把它当作Embedding来处理。具体怎么做呢？在讲Redis的时候，我们就已经实现过物品Embedding和用户Embedding的存储和线上预估的过程了，你可以直接参考它。最后，我建议你利用矩阵分解后的用户和物品隐向量，仿照其他Embedding的实现，在Sparrow RecSys中动手实现一下线上部署的过程，这样你就可以看到矩阵分解模型的实际效果了。</p><h2>小结</h2><p>这节课我们一起学习了协同过滤算法，以及它的后续算法矩阵分解，它是最经典的推荐算法。</p><p>总结来说，协同过滤是一种协同大家的反馈、评价和意见，对海量的信息进行过滤，从中筛选出用户感兴趣信息的一种推荐算法。它的实现过程主要有三步，先根据用户行为历史创建共现矩阵，然后根据共现矩阵查找相似用户，再根据相似用户喜欢的物品，推荐目标用户喜欢的物品。</p><p>但是协同过滤处理稀疏矩阵的能力比较差，因此，矩阵分解算法被提出了，它通过分解共现矩阵，生成用户向量矩阵和物品向量矩阵，进而得到用户隐向量和物品隐向量。你可以完全把最后的结果当作用户Embedding和物品Embedding来处理。</p><p>针对这节课的重要知识点，我把它们都列在了下面的表格里，你可以看看。</p><p><img src=\"https://static001.geekbang.org/resource/image/5f/12/5f02442573af2202a85eb3e4bb895212.jpeg?wh=1920*755\" alt=\"\"></p><h2>课后思考</h2><p>1.基于协同过滤算法，你能找到进行相似“物品”推荐的方法吗？</p><p>2.在MovieLens数据集中，不同用户对物品打分的标准不尽相同。比如说，有的人可能爱打高分，评价的影片得分都在4分以上，有的人爱打低分，大部分影片都在3分以下。你觉得这样的偏好对于推荐结果有影响吗？我们能不能在算法中消除这种偏好呢？</p><p>关于矩阵分解算法的实现你学会了吗？欢迎把你的疑问和思考分享到留言区，也欢迎你能把这节课转发出去，我们下节课见！</p>","comments":[{"had_liked":false,"id":259688,"user_name":"Geek_63ee39","can_delete":false,"product_type":"c1","uid":2202096,"ip_address":"","ucode":"A41379ADD76480","user_header":"https://static001.geekbang.org/account/avatar/00/21/99/f0/ba3c0208.jpg","comment_is_top":false,"comment_ctime":1604811786,"is_pvip":false,"replies":[{"id":"94401","content":"这个思路我之前还没想到，但感觉应该是work的，可以尝试。<br><br>经典的做法是在生成共现矩阵的时候对用户的评分进行用户级别的校正或者归一化，用当前得分减去用户平均得分作为共现矩阵里面的值。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1604863500,"ip_address":"","comment_id":259688,"utype":1}],"discussion_count":6,"race_medal":0,"score":"212058209290","product_id":100060801,"comment_content":"问题2:<br>可以采用余弦相似度可以消除这种影响，例如:用户甲习惯打高分，对A, B, C三个物品打分为[5, 2, 5]；用户乙习惯打低分，对A, B, C打分为为[3, 1, 3]，虽然这两个评分向量的欧式距离比较远，但它们的余弦相似度比较高，约等于0.96","like_count":50,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509005,"discussion_content":"这个思路我之前还没想到，但感觉应该是work的，可以尝试。\n\n经典的做法是在生成共现矩阵的时候对用户的评分进行用户级别的校正或者归一化，用当前得分减去用户平均得分作为共现矩阵里面的值。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1604863500,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2411441,"avatar":"","nickname":"Geek_65b3bd","note":"","ucode":"1155A4FDDC34AC","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":342698,"discussion_content":"感觉在构建矩阵时对用户评分进行用户粒度的归一化，其实就是在对用户向量进行归一化。而计算两个归一化向量的内积，就等价于求向量间的余弦相似度。","likes_number":5,"is_delete":false,"is_hidden":false,"ctime":1610781591,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":587147,"discussion_content":"在计算用户相似度的时候，原文已经使用了余弦相似度，所以这点上用不用rescale应该没有影响。不过，对于之后计算加权平均的评分时，rescale还是必要的。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1662827282,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"美国"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2156292,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/4icayE3ic5IA7RWwZcrxpMZE4T1WViakEgPsDC3UnhZwU83ad65IjmxPficy0vNZz6Q6vCiclnmyBDc5IYf7soHAXrQ/132","nickname":"Geek_790c43","note":"","ucode":"FFFAE0636A91EF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":379116,"discussion_content":"用皮尔森相关系数 就可以了 因为比余弦多了一步标准化","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1623713195,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2106574,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKHFicKDOJk2zNE09HNL5ykibFV7a9I4r8435Y7P1FJbxzTwTGDDRCfBqYrmQKuHrgLJAV3onrOReTw/132","nickname":"Geek_04634b","note":"","ucode":"A6CB8AF3E0EC41","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":350101,"discussion_content":"余弦相似度和欧式距离在l2归一化后是等价的。所以只需要归一化就好了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1613707814,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1147142,"avatar":"https://static001.geekbang.org/account/avatar/00/11/81/06/d7c6d511.jpg","nickname":"杜军","note":"","ucode":"878C542E1D17AD","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":323081,"discussion_content":"好像有点绕","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1604883969,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":259990,"user_name":"Sebastian","can_delete":false,"product_type":"c1","uid":1797634,"ip_address":"","ucode":"62E6FC13DB00E3","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/55lYKUdcPFgUHibRYmaRiaBdrsmnLGOHdPp4OicjBh197X0vyGa9qAwruEqicAPuUgibXO4Lz5jLudlcbtsqq2p3CpA/132","comment_is_top":false,"comment_ctime":1604904116,"is_pvip":false,"replies":[{"id":"94490","content":"正常的技术迭代。五年前的推荐系统，矩阵分解是很主流的技术方案。但是矩阵分解没法引入除用户行为外的其他特征，深度学习出来之后就逐渐被取代了。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1604966036,"ip_address":"","comment_id":259990,"utype":1}],"discussion_count":2,"race_medal":0,"score":"151928759476","product_id":100060801,"comment_content":"老师好，矩阵分解在工业界落地好像并不常见，从工程实践角度来讲，是有什么特殊的原因吗？","like_count":36,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509080,"discussion_content":"正常的技术迭代。五年前的推荐系统，矩阵分解是很主流的技术方案。但是矩阵分解没法引入除用户行为外的其他特征，深度学习出来之后就逐渐被取代了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1604966036,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1275061,"avatar":"https://static001.geekbang.org/account/avatar/00/13/74/b5/b68e3740.jpg","nickname":"黄申","note":"","ucode":"EE9AC074A322FF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":587148,"discussion_content":"矩阵分解可能对内存要求比较高","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1662827324,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"美国"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":260538,"user_name":"Geek_3c29c3","can_delete":false,"product_type":"c1","uid":2203358,"ip_address":"","ucode":"3D2E73AB1D08FA","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLaoiaerNMy7eoSA5yfibPNhta51jkhPTTL1dD1HGlnjaGnFQ6Uzbbce82Kpnic3g1JlD7rtm41Y83PA/132","comment_is_top":false,"comment_ctime":1605058250,"is_pvip":false,"replies":[{"id":"94639","content":"这是一个非常好的业界问题。我之前也是做计算广告的，确实有过类似的经历。我感觉从数据上说，第二个原因的可能性非常大，你其实可以分析一下原始的数据，是不是说点击人群的范围确实比较小。<br><br>至于解决方法我建议从特征设计的角度入手，看看能不能加入一些能增强模型泛化能力的特征，比如大家都有的一些人口属性特征，广告的分类结构特征之类的，希望能把特定人群的一些行为泛化出去。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1605079704,"ip_address":"","comment_id":260538,"utype":1}],"discussion_count":4,"race_medal":0,"score":"74619502282","product_id":100060801,"comment_content":"老师您好，业务的指标是给不同用户推送可能点击概率比较大的广告，提高不同用户对不同广告的点击率，我这边是利用CTR模型来做的，预测每个用户点击某一个广告的概率，最后发现对于不同的广告，点击概率&gt;0.5的人群重合度很大，目前分析有两个原因，一是测试所用的广告标签类似，导致可能点击用户群体相同；二是最可能的，就是喜欢点击广告的，就是那一波人，另外一波人无论什么广告都没有兴趣点击。老师有遇到过这种情况吗？是怎么解决的？","like_count":18,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509224,"discussion_content":"这是一个非常好的业界问题。我之前也是做计算广告的，确实有过类似的经历。我感觉从数据上说，第二个原因的可能性非常大，你其实可以分析一下原始的数据，是不是说点击人群的范围确实比较小。\n\n至于解决方法我建议从特征设计的角度入手，看看能不能加入一些能增强模型泛化能力的特征，比如大家都有的一些人口属性特征，广告的分类结构特征之类的，希望能把特定人群的一些行为泛化出去。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605079704,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2203358,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLaoiaerNMy7eoSA5yfibPNhta51jkhPTTL1dD1HGlnjaGnFQ6Uzbbce82Kpnic3g1JlD7rtm41Y83PA/132","nickname":"Geek_3c29c3","note":"","ucode":"3D2E73AB1D08FA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":324260,"discussion_content":"老师的意思是将比较具体的特征变得general一些来提高模型的泛化能力吗？","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1605081576,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":2203358,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLaoiaerNMy7eoSA5yfibPNhta51jkhPTTL1dD1HGlnjaGnFQ6Uzbbce82Kpnic3g1JlD7rtm41Y83PA/132","nickname":"Geek_3c29c3","note":"","ucode":"3D2E73AB1D08FA","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":325050,"discussion_content":"不是变得general一点，是加入更多general一点的特征，如果确实没有的话，我觉得这个问题比较难做，因为可利用数据确实过少了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605229022,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":324260,"ip_address":""},"score":325050,"extra":""}]},{"author":{"id":2202225,"avatar":"https://static001.geekbang.org/account/avatar/00/21/9a/71/7347008c.jpg","nickname":"小泥鳅","note":"","ucode":"AE7E3223F8618F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":398903,"discussion_content":"王老师，我觉得碰到这种问题，就是特征没有区分度吧，需要设计一些有区分度的特征","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1632875123,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":260277,"user_name":"那时刻","can_delete":false,"product_type":"c1","uid":1150927,"ip_address":"","ucode":"B0D150856C3A4A","user_header":"https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg","comment_is_top":false,"comment_ctime":1604975046,"is_pvip":false,"replies":[{"id":"94628","content":"SVD一般不用在工业级应用上，因为在求解大规模稀疏矩阵时复杂度过高。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1605079022,"ip_address":"","comment_id":260277,"utype":1}],"discussion_count":2,"race_medal":0,"score":"70324451782","product_id":100060801,"comment_content":"请问老师，文中提到的梯度下降方法对共现矩阵进行分解，和传统的SVD矩阵分解，有什么异同么？","like_count":17,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509155,"discussion_content":"SVD一般不用在工业级应用上，因为在求解大规模稀疏矩阵时复杂度过高。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605079022,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1815397,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/b3/65/ef77d180.jpg","nickname":"H、","note":"","ucode":"04A245FA9E6D21","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":364323,"discussion_content":"SDV分解的前提是矩阵稠密","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1617443158,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":279291,"user_name":"Geek_04634b","can_delete":false,"product_type":"c1","uid":2106574,"ip_address":"","ucode":"A6CB8AF3E0EC41","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKHFicKDOJk2zNE09HNL5ykibFV7a9I4r8435Y7P1FJbxzTwTGDDRCfBqYrmQKuHrgLJAV3onrOReTw/132","comment_is_top":false,"comment_ctime":1613710195,"is_pvip":false,"replies":[{"id":"101709","content":"说的非常好，推荐参考。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1614046360,"ip_address":"","comment_id":279291,"utype":1}],"discussion_count":1,"race_medal":0,"score":"57448285043","product_id":100060801,"comment_content":"第一个问题既然已经有物品向量了应该直接求cosine sim取topk就行了，第二个问题，均值方差归一化是最标准的做法，我看评论里有说用cosine的，其实cosine和欧氏距离在l2归一化的条件下在数学上是等价的，本质还是要归一化。","like_count":14,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":515695,"discussion_content":"说的非常好，推荐参考。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1614046360,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":262192,"user_name":"吴十一","can_delete":false,"product_type":"c1","uid":1658932,"ip_address":"","ucode":"47232ED3225081","user_header":"https://static001.geekbang.org/account/avatar/00/19/50/34/172342fd.jpg","comment_is_top":false,"comment_ctime":1605661742,"is_pvip":false,"replies":[{"id":"95232","content":"其实没有什么magic，工作中常用的就是负样本欠采样，和正样本过采样，或者增大正样本学习的权重。<br><br>还有一种方法叫SMOTE，可以搜一下，大致意思是通过合成的方式过采样正样本。可以尝试但有一定风险。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1605747608,"ip_address":"","comment_id":262192,"utype":1}],"discussion_count":3,"race_medal":0,"score":"57440236590","product_id":100060801,"comment_content":"老师，我这边做点击推荐的时候正负样本比例相差很大，除了随机抽样负样本，还有什么比较好的办法呢？","like_count":14,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509727,"discussion_content":"其实没有什么magic，工作中常用的就是负样本欠采样，和正样本过采样，或者增大正样本学习的权重。\n\n还有一种方法叫SMOTE，可以搜一下，大致意思是通过合成的方式过采样正样本。可以尝试但有一定风险。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605747608,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1050518,"avatar":"https://static001.geekbang.org/account/avatar/00/10/07/96/d01ebfe7.jpg","nickname":"archmageforac","note":"","ucode":"782B46B42EEF65","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":556377,"discussion_content":"常用的这几种，西瓜书有讲~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1647334737,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2829048,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/2a/f8/1af3bba6.jpg","nickname":"m-rui","note":"","ucode":"75C9CBB9580C88","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":531453,"discussion_content":"很奇怪，据说smote有用，但我在几个表格类数据的模型里使用，都没有增益，反而效果降了。不知道有没有可能是因为正样本可能有聚类效果？插值的时候可能插进了负样本中间？或者数据本身的噪音就太大也有可能","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1637314583,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"user_type\":1}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":261231,"user_name":"Chaosnow","can_delete":false,"product_type":"c1","uid":2200500,"ip_address":"","ucode":"FDA78DEFF4C2F9","user_header":"https://static001.geekbang.org/account/avatar/00/21/93/b4/8571958c.jpg","comment_is_top":false,"comment_ctime":1605246858,"is_pvip":false,"replies":[{"id":"94813","content":"MF没法做增量更新，新数据来了之后，共现矩阵都变了，整个求解的目标都变了，只能全量更新。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1605258263,"ip_address":"","comment_id":261231,"utype":1}],"discussion_count":3,"race_medal":0,"score":"31670017930","product_id":100060801,"comment_content":"请问老师，MF如何做到迭代增量训练模型呢？每天全量更新做不到的情况下，只针对每天生产出的新数据训练是否会导致效果变差，比如更新了一部分item的向量从而影响到原本的相对距离。","like_count":7,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509427,"discussion_content":"MF没法做增量更新，新数据来了之后，共现矩阵都变了，整个求解的目标都变了，只能全量更新。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605258263,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1025119,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/a4/5f/6892585a.jpg","nickname":"LiuHDme","note":"","ucode":"C8A1437DDD487E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":357813,"discussion_content":"假如昨天来了n个新用户，现在要计算这些新用户的embedding，就可以把这些用户昨天的交互记录作为训练数据，来训练当前的MF模型，训练结束后，得到的是这n个新用户的embedding和他们交互过的item的更新后的embedding。感觉理论上可以按照上述方法做啊，为什么MF不能增量更新呢？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1615872764,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":2414668,"avatar":"","nickname":"夜枭","note":"","ucode":"7A09EC9E003379","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1025119,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/a4/5f/6892585a.jpg","nickname":"LiuHDme","note":"","ucode":"C8A1437DDD487E","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":558827,"discussion_content":"请问有对增量进行实践吗？采用ALS优化的话，固定user矩阵去更新item或者固定item矩阵去更新user，看腾讯的分享是可以实现增量的，不知道具体操作如何","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1648478508,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":357813,"ip_address":""},"score":558827,"extra":""}]}]},{"had_liked":false,"id":259876,"user_name":"你笑起来真好看","can_delete":false,"product_type":"c1","uid":1565857,"ip_address":"","ucode":"0A51EC1CA4BC1C","user_header":"https://static001.geekbang.org/account/avatar/00/17/e4/a1/2f5b9764.jpg","comment_is_top":false,"comment_ctime":1604881029,"is_pvip":false,"replies":[{"id":"94420","content":"隐式行为正反馈取值1，负反馈取值0或-1，默认取0。比如点击取1，曝光无点击取0或-1，无交互取0。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1604895988,"ip_address":"","comment_id":259876,"utype":1}],"discussion_count":4,"race_medal":0,"score":"23079717509","product_id":100060801,"comment_content":"如果用户只有隐式因为，那如何构建als模型的数据集呢？","like_count":5,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509053,"discussion_content":"隐式行为正反馈取值1，负反馈取值0或-1，默认取0。比如点击取1，曝光无点击取0或-1，无交互取0。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1604895988,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2156292,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/4icayE3ic5IA7RWwZcrxpMZE4T1WViakEgPsDC3UnhZwU83ad65IjmxPficy0vNZz6Q6vCiclnmyBDc5IYf7soHAXrQ/132","nickname":"Geek_790c43","note":"","ucode":"FFFAE0636A91EF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":379118,"discussion_content":"无交互其实什么值都不用取吧 因为als也不用无交互的输入","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1623713388,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2404074,"avatar":"","nickname":"Geek_ba0116","note":"","ucode":"53EF2FB84A20DF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":341547,"discussion_content":"能否同时选取多个隐式反馈呢，如果可以，那么怎么选","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1610449508,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":2156292,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/4icayE3ic5IA7RWwZcrxpMZE4T1WViakEgPsDC3UnhZwU83ad65IjmxPficy0vNZz6Q6vCiclnmyBDc5IYf7soHAXrQ/132","nickname":"Geek_790c43","note":"","ucode":"FFFAE0636A91EF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2404074,"avatar":"","nickname":"Geek_ba0116","note":"","ucode":"53EF2FB84A20DF","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":379117,"discussion_content":"浏览取1 转发取2 购买取3 举报取0 哈哈","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1623713323,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":341547,"ip_address":""},"score":379117,"extra":""}]}]},{"had_liked":false,"id":273435,"user_name":"Macielyoung","can_delete":false,"product_type":"c1","uid":2298734,"ip_address":"","ucode":"DC33AC43B0B5BA","user_header":"https://static001.geekbang.org/account/avatar/00/23/13/6e/f1e23980.jpg","comment_is_top":false,"comment_ctime":1610595036,"is_pvip":false,"replies":[{"id":"99135","content":"非常好，就是经典的做法了","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1610660245,"ip_address":"","comment_id":273435,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14495496924","product_id":100060801,"comment_content":"我觉得消除用户评分偏差可以根据用户的平均评分标准化，即原始向量【x1,x2,x3】变成【x1-xp,x2-xp,x3-xp】，这样有利于弱化个人评分标准不同的影响","like_count":4,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":513605,"discussion_content":"非常好，就是经典的做法了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1610660245,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":260486,"user_name":"JustDoDT","can_delete":false,"product_type":"c1","uid":1127175,"ip_address":"","ucode":"6AF0B80F00EAEF","user_header":"https://static001.geekbang.org/account/avatar/00/11/33/07/8f351609.jpg","comment_is_top":false,"comment_ctime":1605022312,"is_pvip":false,"replies":[{"id":"94633","content":"没必要这么理解，Spark的ALS指的就通过交替最小二乘法分解共现矩阵，没有必要联系到LFM和LSA上去。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1605079368,"ip_address":"","comment_id":260486,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14489924200","product_id":100060801,"comment_content":"常见隐模型矩阵分解有两种<br>隐语义（隐因子）模型LFM（latent factor model）<br>LSA(latent semantic analysis)潜在语义分析<br>SparkMl 的 ALS 实现的是LSA吗？","like_count":3,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509207,"discussion_content":"没必要这么理解，Spark的ALS指的就通过交替最小二乘法分解共现矩阵，没有必要联系到LFM和LSA上去。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605079368,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":260334,"user_name":"科科科科科科名儿","can_delete":false,"product_type":"c1","uid":2196731,"ip_address":"","ucode":"F123608183E8AF","user_header":"https://static001.geekbang.org/account/avatar/00/21/84/fb/b656405c.jpg","comment_is_top":false,"comment_ctime":1604986576,"is_pvip":false,"replies":[{"id":"94627","content":"推荐使用双塔模型，或者阿里的EGES。双塔模型我们之后的课程会涉及到。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1605078975,"ip_address":"","comment_id":260334,"utype":1}],"discussion_count":5,"race_medal":0,"score":"14489888464","product_id":100060801,"comment_content":"王老师 ： 若采用item2vec的算法 ，输入为用户的观看序列（即观看的电影序列），训练得出一个向量查找表（向量权重），再根据每个观看的电影 embedding的向量与向量权重计算相似度，推荐出相似度比较高的电影，如果我想加入电影的标签（主演，导演）等，应该从那个方面尝试入手？","like_count":3,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509170,"discussion_content":"推荐使用双塔模型，或者阿里的EGES。双塔模型我们之后的课程会涉及到。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605078975,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2402565,"avatar":"https://static001.geekbang.org/account/avatar/00/24/a9/05/6822b8a5.jpg","nickname":"灯灯灯","note":"","ucode":"A801439F74127C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":345235,"discussion_content":"你好！请问提到的向量查找表（向量权重）是什么呀？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1611704407,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":325551,"discussion_content":"文本类的特征还是建议先预训练一个nlp的模型，做embedding化之后再输入推荐模型。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605344159,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":2106574,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKHFicKDOJk2zNE09HNL5ykibFV7a9I4r8435Y7P1FJbxzTwTGDDRCfBqYrmQKuHrgLJAV3onrOReTw/132","nickname":"Geek_04634b","note":"","ucode":"A6CB8AF3E0EC41","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":350104,"discussion_content":"老师，请问EGES现在淘宝还在用吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1613709891,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":325551,"ip_address":""},"score":350104,"extra":""}]},{"author":{"id":2196731,"avatar":"https://static001.geekbang.org/account/avatar/00/21/84/fb/b656405c.jpg","nickname":"科科科科科科名儿","note":"","ucode":"F123608183E8AF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":324254,"discussion_content":"王老师，若加入的标签是节目描述或者节目主题，也没有什么区别吧，也可以参考双塔模型吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605079848,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":265376,"user_name":"范闲","can_delete":false,"product_type":"c1","uid":1073125,"ip_address":"","ucode":"F21FD7DF6BA53C","user_header":"https://static001.geekbang.org/account/avatar/00/10/5f/e5/54325854.jpg","comment_is_top":false,"comment_ctime":1606880183,"is_pvip":false,"replies":[{"id":"96524","content":"正确","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1606940459,"ip_address":"","comment_id":265376,"utype":1}],"discussion_count":3,"race_medal":0,"score":"10196814775","product_id":100060801,"comment_content":"问题一:<br>相似物品推荐可以从item embedding做top n的召回<br>问题二:<br>对用用户打分做归一化处理（cur-average)&#47;(max_min)","like_count":2,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":510907,"discussion_content":"正确","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606940459,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2156292,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/4icayE3ic5IA7RWwZcrxpMZE4T1WViakEgPsDC3UnhZwU83ad65IjmxPficy0vNZz6Q6vCiclnmyBDc5IYf7soHAXrQ/132","nickname":"Geek_790c43","note":"","ucode":"FFFAE0636A91EF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":346004,"discussion_content":"请问做完归一化之后als的implicitPrefs应该是false还是true","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1611837336,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1073125,"avatar":"https://static001.geekbang.org/account/avatar/00/10/5f/e5/54325854.jpg","nickname":"范闲","note":"","ucode":"F21FD7DF6BA53C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2156292,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/4icayE3ic5IA7RWwZcrxpMZE4T1WViakEgPsDC3UnhZwU83ad65IjmxPficy0vNZz6Q6vCiclnmyBDc5IYf7soHAXrQ/132","nickname":"Geek_790c43","note":"","ucode":"FFFAE0636A91EF","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":351898,"discussion_content":"归一化以后要么是true，要么是false。具体你看怎么做。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1614513816,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":346004,"ip_address":""},"score":351898,"extra":""}]}]},{"had_liked":false,"id":260825,"user_name":"Geek_3c29c3","can_delete":false,"product_type":"c1","uid":2203358,"ip_address":"","ucode":"3D2E73AB1D08FA","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLaoiaerNMy7eoSA5yfibPNhta51jkhPTTL1dD1HGlnjaGnFQ6Uzbbce82Kpnic3g1JlD7rtm41Y83PA/132","comment_is_top":false,"comment_ctime":1605138520,"is_pvip":false,"replies":[{"id":"94720","content":"人口属性特征就是性别年龄、常驻城市、手机型号等呗；<br>是的<br><br>广告的分类结构特征又是什么意思呢？将广告的标签打成泛泛的类别吗？<br>广告一般都有分类体系对吧，行业-&gt;细分行业之类，可以把用户点击、购买过的广告标签放到特征工程中。<br><br>把特定人群的一些行为泛化出去的意思是让每个广告&gt;0.5的人群覆盖度更广，差别度更大吗？<br>是的。<br><br><br>","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1605144280,"ip_address":"","comment_id":260825,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10195073112","product_id":100060801,"comment_content":"老师早，<br>人口数型特征就是性别年龄、常驻城市、手机型号等呗；<br>广告的分类结构特征又是什么意思呢？将广告的标签打成泛泛的类别吗？<br>把特定人群的一些行为泛化出去的意思是让每个广告&gt;0.5的人群覆盖度更广，差别度更大吗？<br>--------------------------------<br>之前的问题：<br>老师您好，业务的指标是给不同用户推送可能点击概率比较大的广告，提高不同用户对不同广告的点击率，我这边是利用CTR模型来做的，预测每个用户点击某一个广告的概率，最后发现对于不同的广告，点击概率&gt;0.5的人群重合度很大，目前分析有两个原因，一是测试所用的广告标签类似，导致可能点击用户群体相同；二是最可能的，就是喜欢点击广告的，就是那一波人，另外一波人无论什么广告都没有兴趣点击。老师有遇到过这种情况吗？是怎么解决的？<br>---------------------------<br>作者回复: 这是一个非常好的业界问题。我之前也是做计算广告的，确实有过类似的经历。我感觉从数据上说，第二个原因的可能性非常大，你其实可以分析一下原始的数据，是不是说点击人群的范围确实比较小。<br><br>至于解决方法我建议从特征设计的角度入手，看看能不能加入一些能增强模型泛化能力的特征，比如大家都有的一些人口属性特征，广告的分类结构特征之类的，希望能把特定人群的一些行为泛化出去。","like_count":3,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509298,"discussion_content":"人口属性特征就是性别年龄、常驻城市、手机型号等呗；\n是的\n\n广告的分类结构特征又是什么意思呢？将广告的标签打成泛泛的类别吗？\n广告一般都有分类体系对吧，行业-&amp;gt;细分行业之类，可以把用户点击、购买过的广告标签放到特征工程中。\n\n把特定人群的一些行为泛化出去的意思是让每个广告&amp;gt;0.5的人群覆盖度更广，差别度更大吗？\n是的。\n\n\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605144280,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":260390,"user_name":"因子分解机","can_delete":false,"product_type":"c1","uid":2202320,"ip_address":"","ucode":"B605322D225B7F","user_header":"https://static001.geekbang.org/account/avatar/00/21/9a/d0/b54a96f2.jpg","comment_is_top":false,"comment_ctime":1604996548,"is_pvip":false,"replies":[{"id":"94630","content":"完全正确","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1605079126,"ip_address":"","comment_id":260390,"utype":1}],"discussion_count":5,"race_medal":0,"score":"10194931140","product_id":100060801,"comment_content":"问题2：<br>可以引入用户和物品偏置项来对用户的打分习惯和物品的被打分情况进行建模。","like_count":2,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509182,"discussion_content":"完全正确","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605079126,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1150927,"avatar":"https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg","nickname":"那时刻","note":"","ucode":"B0D150856C3A4A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":324645,"discussion_content":"请问大佬，您提到用户和物品偏置项怎么理解呢？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605147238,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":3,"child_discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":1150927,"avatar":"https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg","nickname":"那时刻","note":"","ucode":"B0D150856C3A4A","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":327097,"discussion_content":"就是用户打分的平均分，和物品打分的平均分。在生成共现矩阵时，可以用当前打分减去平均分消除偏置。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1605747783,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":324645,"ip_address":""},"score":327097,"extra":""},{"author":{"id":2343345,"avatar":"https://static001.geekbang.org/account/avatar/00/23/c1/b1/dcde3850.jpg","nickname":"💤","note":"","ucode":"EEED6754B25626","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":332281,"discussion_content":"老师，是怎么个减法，打分直接减去两个平均分的和(这种可能很多为负值)？还是比如先减去用户平均分，然后再求出每个物品的平均分，再减一次？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1607146929,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":327097,"ip_address":""},"score":332281,"extra":""},{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":2343345,"avatar":"https://static001.geekbang.org/account/avatar/00/23/c1/b1/dcde3850.jpg","nickname":"💤","note":"","ucode":"EEED6754B25626","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":334059,"discussion_content":"不能同时减去，两次相减的话，本来无偏也变成有偏了。一般是选择一项去消除，用评分减去用户的平均打分。负数没有关系，评分高低的相对关系保持就可以了","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1607716510,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":332281,"ip_address":""},"score":334059,"extra":""}]}]},{"had_liked":false,"id":260042,"user_name":"Geek_3c29c3","can_delete":false,"product_type":"c1","uid":2203358,"ip_address":"","ucode":"3D2E73AB1D08FA","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLaoiaerNMy7eoSA5yfibPNhta51jkhPTTL1dD1HGlnjaGnFQ6Uzbbce82Kpnic3g1JlD7rtm41Y83PA/132","comment_is_top":false,"comment_ctime":1604913365,"is_pvip":false,"replies":[{"id":"94491","content":"描述不太清楚，到底你在做计算广告，还是在做推荐，还是在做CTR模型？点击广告的永远是那一批人说明泛化性不够？","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1604966186,"ip_address":"","comment_id":260042,"utype":1}],"discussion_count":3,"race_medal":0,"score":"10194847957","product_id":100060801,"comment_content":"老师您好，我目前做的这个CTR有点偏推荐，不像计算广告，在做CTR预估的时候，发现预测每个广告会点击的用户重叠度很大，也就是说会点广告的永远是那一批人，这个问题一般是怎么解决的啊？？","like_count":2,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509095,"discussion_content":"描述不太清楚，到底你在做计算广告，还是在做推荐，还是在做CTR模型？点击广告的永远是那一批人说明泛化性不够？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1604966186,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2203358,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLaoiaerNMy7eoSA5yfibPNhta51jkhPTTL1dD1HGlnjaGnFQ6Uzbbce82Kpnic3g1JlD7rtm41Y83PA/132","nickname":"Geek_3c29c3","note":"","ucode":"3D2E73AB1D08FA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":324104,"discussion_content":"老师您好，业务的指标是给不同用户推送可能点击概率比较大的广告，提高不同用户对不同广告的点击率，我这边是利用CTR模型来做的，预测每个用户点击某一个广告的概率，最后发现对于不同的广告，点击概率>0.5的人群重合度很大，目前分析有两个原因，一是测试所用的广告标签类似，导致可能点击用户群体相同；二是最可能的，就是喜欢点击广告的，就是那一波人，另外一波人无论什么广告都没有兴趣点击。老师有遇到过这种情况吗？是怎么解决的？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605058200,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":2106574,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKHFicKDOJk2zNE09HNL5ykibFV7a9I4r8435Y7P1FJbxzTwTGDDRCfBqYrmQKuHrgLJAV3onrOReTw/132","nickname":"Geek_04634b","note":"","ucode":"A6CB8AF3E0EC41","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2203358,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLaoiaerNMy7eoSA5yfibPNhta51jkhPTTL1dD1HGlnjaGnFQ6Uzbbce82Kpnic3g1JlD7rtm41Y83PA/132","nickname":"Geek_3c29c3","note":"","ucode":"3D2E73AB1D08FA","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":350105,"discussion_content":"这明显是数据问题，看看你都有什么特征就知道了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1613710002,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":324104,"ip_address":""},"score":350105,"extra":""}]}]},{"had_liked":false,"id":279292,"user_name":"Geek_04634b","can_delete":false,"product_type":"c1","uid":2106574,"ip_address":"","ucode":"A6CB8AF3E0EC41","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKHFicKDOJk2zNE09HNL5ykibFV7a9I4r8435Y7P1FJbxzTwTGDDRCfBqYrmQKuHrgLJAV3onrOReTw/132","comment_is_top":false,"comment_ctime":1613710265,"is_pvip":false,"replies":[{"id":"101710","content":"其实大家用的都是稀疏矩阵，不可能真正建立一个1亿*1亿的稠密矩阵。而且运算的时候是只对非零的部分做运算，并没有想象中运算量那么大。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1614046429,"ip_address":"","comment_id":279292,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5908677561","product_id":100060801,"comment_content":"请问老师如果有上亿user和上亿item也能矩阵分解吗？这需要创建一个1亿*1亿的矩阵。工业界对此是如何处理的。","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":515696,"discussion_content":"其实大家用的都是稀疏矩阵，不可能真正建立一个1亿*1亿的稠密矩阵。而且运算的时候是只对非零的部分做运算，并没有想象中运算量那么大。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1614046429,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":260244,"user_name":"haydenlo","can_delete":false,"product_type":"c1","uid":1594293,"ip_address":"","ucode":"D9EEF8226C3D81","user_header":"","comment_is_top":false,"comment_ctime":1604969730,"is_pvip":false,"replies":[{"id":"94629","content":"als是矩阵分解方法最常用的方法。你说的lfm也可以理解为一种矩阵分解方法，可以看作是MF的进化版本，因为lfm可以加入一阶部分，而且可以加入其他特征，更灵活一些。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1605079113,"ip_address":"","comment_id":260244,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5899937026","product_id":100060801,"comment_content":"请问老师，lfm是否也是一种矩阵分解的方法，在实践中感觉计算量很大，在这里用als是否因为基于spark框架且运算量较少？","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509141,"discussion_content":"als是矩阵分解方法最常用的方法。你说的lfm也可以理解为一种矩阵分解方法，可以看作是MF的进化版本，因为lfm可以加入一阶部分，而且可以加入其他特征，更灵活一些。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605079113,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":259725,"user_name":"sljoai","can_delete":false,"product_type":"c1","uid":1018071,"ip_address":"","ucode":"FF88C4BA265DE0","user_header":"https://static001.geekbang.org/account/avatar/00/0f/88/d7/07f8bc6c.jpg","comment_is_top":false,"comment_ctime":1604821001,"is_pvip":false,"replies":[{"id":"95559","content":"因为矩阵分解最终也是生成了用户隐向量和物品隐向量，相当于是物品embedding向量和物品embedding向量。<br><br>这和其他embedding方法的生成结果是一样的。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1606115312,"ip_address":"","comment_id":259725,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5899788297","product_id":100060801,"comment_content":"老师能否再解释一下矩阵分解算是embedding的一种？还是不理解","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509009,"discussion_content":"因为矩阵分解最终也是生成了用户隐向量和物品隐向量，相当于是物品embedding向量和物品embedding向量。\n\n这和其他embedding方法的生成结果是一样的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606115312,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":259613,"user_name":"浣熊当家","can_delete":false,"product_type":"c1","uid":1952248,"ip_address":"","ucode":"939F06050423E4","user_header":"https://static001.geekbang.org/account/avatar/00/1d/c9/f8/72955ef9.jpg","comment_is_top":false,"comment_ctime":1604775865,"is_pvip":false,"replies":[{"id":"94368","content":"广义讲矩阵分解就是embedding的一种。你说的都没错，但我觉得没必要强行比较这两种方法。只要分别清楚他们的原理和细节就可以了。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1604810870,"ip_address":"","comment_id":259613,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5899743161","product_id":100060801,"comment_content":"请问老师，矩阵分解可以算是embedding的一种吗？可以把embedding定义为降维的手段的统称吗？然后我的理解是矩阵分解和item2vec的主要区别有两点：1是输入：矩阵分解用到的是共现矩阵， item2vec用到的是序列矩阵，2是算法：矩阵分解的求解用到了交叉最小二乘，而item2vec用到了神经网络（不清楚神经网络内是不是也有als？），3是结果：矩阵分解直接得到每个用户得电影推荐列表，item2vec得到的是电影的相似度，如果需要进一步得到推荐列表还需要进一步操作。想请教老师我理解的对不对，问题有点多，是我一直都没有弄清楚的，期待老师的指导！","like_count":2,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":508980,"discussion_content":"广义讲矩阵分解就是embedding的一种。你说的都没错，但我觉得没必要强行比较这两种方法。只要分别清楚他们的原理和细节就可以了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1604810870,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":336600,"user_name":"凌一","can_delete":false,"product_type":"c1","uid":2931009,"ip_address":"","ucode":"81F030000AB3BC","user_header":"https://static001.geekbang.org/account/avatar/00/2c/b9/41/bdcf239f.jpg","comment_is_top":false,"comment_ctime":1646233324,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1646233324","product_id":100060801,"comment_content":"目前算法应用比较多的是搜广推，目前在网上看到比较多的是推荐算法，NLP，图像识别，想了解下，搜广推的技术原理是否大致一致？召回+排序为主线？算法原理是否相通的？","like_count":0},{"had_liked":false,"id":329048,"user_name":"CY","can_delete":false,"product_type":"c1","uid":2739849,"ip_address":"","ucode":"7428A545F40705","user_header":"https://static001.geekbang.org/account/avatar/00/29/ce/89/72982409.jpg","comment_is_top":false,"comment_ctime":1641081110,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1641081110","product_id":100060801,"comment_content":"王老师您好，请问矩阵分解得到的中间产物user embedding和item embedding，是否算在一个向量空间？我看到您有回复别人说不能保证user embedding和item embedding在同一个向量空间，而是要相乘打分排序。但相乘打分排序其实不就是内积相似度？     另外，在讲deep cross的时候也有回复评论说，如果把user和item embedding从concat变成dot product，就能把user embedding和item embedding放入一个向量空间。此处所谓的dot product，不就是矩阵分解里的计算吗？","like_count":0},{"had_liked":false,"id":311775,"user_name":"sky","can_delete":false,"product_type":"c1","uid":2325199,"ip_address":"","ucode":"C7BA135845E1FF","user_header":"https://static001.geekbang.org/account/avatar/00/23/7a/cf/c42dd74e.jpg","comment_is_top":false,"comment_ctime":1631455933,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1631455933","product_id":100060801,"comment_content":"什么时候回触发推荐呢？感觉推荐没有搜索那么清晰","like_count":0},{"had_liked":false,"id":306574,"user_name":"Geek_8a732a","can_delete":false,"product_type":"c1","uid":2723806,"ip_address":"","ucode":"97A312D97F7B91","user_header":"","comment_is_top":false,"comment_ctime":1628610668,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1628610668","product_id":100060801,"comment_content":"问题1：从item embedding中找到top n召回<br>问题2：使用余弦夹角消除这种影响，看了下面说要归一化，学习到了~","like_count":0},{"had_liked":false,"id":297677,"user_name":"魔法海","can_delete":false,"product_type":"c1","uid":2015537,"ip_address":"","ucode":"ACC78501A9980F","user_header":"https://static001.geekbang.org/account/avatar/00/1e/c1/31/e991c364.jpg","comment_is_top":false,"comment_ctime":1623726334,"is_pvip":false,"replies":[{"id":"108162","content":"协同过滤无法引入其他特征，可以参考后续的模型，比如双塔模型，看能否满足你的要求。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1623876650,"ip_address":"","comment_id":297677,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1623726334","product_id":100060801,"comment_content":"老师， 我目前在做召回层的工作，在测试als的效果，这个als是不是只能输入3元组（用户id， 搜索词id， 还有喜好程度）？那我如何在als中加入其他相关的信息呢？比如我有2百万的用户，2亿个搜索词，搜索词很可能不会出现重复，喜好程度使用的搜索词在百度上的排名(1-14）,目前生成出来的embeddings出现大量的0，或者很多关键词出现重复，包括用户也是一样的，要想形成更大的差异性，是我自己将其他特征根据权重加成一个数，还是说这个可以喜好程度可以变成一个数组输入？","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":521902,"discussion_content":"协同过滤无法引入其他特征，可以参考后续的模型，比如双塔模型，看能否满足你的要求。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1623876650,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":290970,"user_name":"DENNY","can_delete":false,"product_type":"c1","uid":1616014,"ip_address":"","ucode":"CC940775EEA213","user_header":"https://static001.geekbang.org/account/avatar/00/18/a8/8e/cb6dd10d.jpg","comment_is_top":false,"comment_ctime":1619885105,"is_pvip":false,"replies":[{"id":"105451","content":"当然不能保证矩阵分解中的用户向量和物品向量相似，而就是希望得到用户对物品的打分，再根据打分来进行排名。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1620011449,"ip_address":"","comment_id":290970,"utype":1}],"discussion_count":3,"race_medal":0,"score":"1619885105","product_id":100060801,"comment_content":"老师您好，<br>embedding中用户的embedding是由用户所喜欢的物品的embedding计算获得，所以用户的embedding会和他喜欢的物品embedding相似。<br>但是矩阵分解的损失函数只保证“用户矩阵和物品矩阵的乘积尽量接近原来的共现矩阵”，那怎么保证分解后的用户隐向量和用户喜欢的物品的隐向量相似呢","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":519331,"discussion_content":"当然不能保证矩阵分解中的用户向量和物品向量相似，而就是希望得到用户对物品的打分，再根据打分来进行排名。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1620011449,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":2,"child_discussions":[{"author":{"id":2739849,"avatar":"https://static001.geekbang.org/account/avatar/00/29/ce/89/72982409.jpg","nickname":"CY","note":"","ucode":"7428A545F40705","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":543310,"discussion_content":"老师您好。相乘打分排序其实不就是内积相似度？那么分解后的embeddings应该可以看作在同一向量空间，且能够计算user embedding和item embedd ing的相似度呀。     在讲deep cross的时候您也有回复评论说，如果把user和item embedding从concat变成dot product，就能把user embedding和item embedding放入一个向量空间。此处所谓的dot product，不就是矩阵分解里的计算吗？您还在后续的回复里说“因为矩阵分解使用点积操作作为最后的输出层，所以他们在一个空间内。而这里的stacking操作，不同embedding之间没有直接关系，也没有互操作，所以他们不在一个向量空间。”","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1641082153,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":519331,"ip_address":""},"score":543310,"extra":""},{"author":{"id":2739849,"avatar":"https://static001.geekbang.org/account/avatar/00/29/ce/89/72982409.jpg","nickname":"CY","note":"","ucode":"7428A545F40705","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":543311,"discussion_content":"在矩阵分解中，user embedding应该和他喜欢的物品的embedding在内积相似度上很相似呀。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1641082216,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":519331,"ip_address":""},"score":543311,"extra":""}]}]},{"had_liked":false,"id":279954,"user_name":"鹏程","can_delete":false,"product_type":"c1","uid":1589765,"ip_address":"","ucode":"1EFDCC21E3FDAB","user_header":"https://static001.geekbang.org/account/avatar/00/18/42/05/1e32d6f6.jpg","comment_is_top":false,"comment_ctime":1614021951,"is_pvip":false,"replies":[{"id":"101716","content":"不是非常明白这个bias item具体怎么用，可以详细说说。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1614046775,"ip_address":"","comment_id":279954,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1614021951","product_id":100060801,"comment_content":"对于问题2，增加一个 bias item 应该也可以建模用户差异吧？","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":515939,"discussion_content":"不是非常明白这个bias item具体怎么用，可以详细说说。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1614046775,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":277083,"user_name":"阿阳","can_delete":false,"product_type":"c1","uid":2405800,"ip_address":"","ucode":"9FDF1921E299EB","user_header":"https://static001.geekbang.org/account/avatar/00/24/b5/a8/b53b2c91.jpg","comment_is_top":false,"comment_ctime":1612255991,"is_pvip":false,"replies":[{"id":"100806","content":"这是个无所谓的问题，放哪都可以。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1612595066,"ip_address":"","comment_id":277083,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1612255991","product_id":100060801,"comment_content":"矩阵分解也是一种embedding生成的方法，那为什么不将其和Item2vec等embedding方法都放在特征工程篇呢？","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":514924,"discussion_content":"这是个无所谓的问题，放哪都可以。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1612595066,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":276223,"user_name":"Geek_790c43","can_delete":false,"product_type":"c1","uid":2156292,"ip_address":"","ucode":"FFFAE0636A91EF","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/4icayE3ic5IA7RWwZcrxpMZE4T1WViakEgPsDC3UnhZwU83ad65IjmxPficy0vNZz6Q6vCiclnmyBDc5IYf7soHAXrQ/132","comment_is_top":false,"comment_ctime":1611837219,"is_pvip":false,"replies":[{"id":"100797","content":"1. 非常好的点，这其实就是默认值选取的问题。理论上没必要只选取0或者1，可以多尝试不同的默认值选取。<br>2.完全可以","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1612594425,"ip_address":"","comment_id":276223,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1611837219","product_id":100060801,"comment_content":"1. 对于隐式行为，如果正反馈为1， 负反馈和无交互都取0会不会有问题？模型如何区分到底是没看过还是不喜欢？<br>2. 如果数据是视频的播放完成率，能不能把这个隐式行为分箱到1至5的rating再去做als( implicitPrefs=False)","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":514633,"discussion_content":"1. 非常好的点，这其实就是默认值选取的问题。理论上没必要只选取0或者1，可以多尝试不同的默认值选取。\n2.完全可以","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1612594425,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":262269,"user_name":"大魔王","can_delete":false,"product_type":"c1","uid":1308552,"ip_address":"","ucode":"5EB049D18E122F","user_header":"https://static001.geekbang.org/account/avatar/00/13/f7/88/da243c77.jpg","comment_is_top":false,"comment_ctime":1605681951,"is_pvip":false,"replies":[{"id":"95228","content":"1. 对的。<br>2. 貌似不太对，我们希望在构建共现矩阵的时候就把用户打分的偏置来消除，这样矩阵分解后的结果就是消除偏置后的结果了。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1605747147,"ip_address":"","comment_id":262269,"utype":1}],"discussion_count":3,"race_medal":0,"score":"1605681951","product_id":100060801,"comment_content":"问题一:<br>相似物品推荐不是取topn个相似物品 从 u2i,i2i,或者u2u2i等里计算出就行了吧。<br>问题二:<br>for u in sim:<br>      s = 0<br>      for v in sim[u][v]:<br>           s += sim[u][v]<br>      if s &gt; 0:<br>         for v in sim[u]:<br>              sim[u][v] &#47;= s<br><br>","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509760,"discussion_content":"1. 对的。\n2. 貌似不太对，我们希望在构建共现矩阵的时候就把用户打分的偏置来消除，这样矩阵分解后的结果就是消除偏置后的结果了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605747147,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1308552,"avatar":"https://static001.geekbang.org/account/avatar/00/13/f7/88/da243c77.jpg","nickname":"大魔王","note":"","ucode":"5EB049D18E122F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":327092,"discussion_content":"直接用皮尔逊相似度就可以了吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605747338,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":1308552,"avatar":"https://static001.geekbang.org/account/avatar/00/13/f7/88/da243c77.jpg","nickname":"大魔王","note":"","ucode":"5EB049D18E122F","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":327685,"discussion_content":"最好是在构建共现矩阵的时候就消除偏置，在计算相似度时用皮尔逊相似度也能达到这个目的，但总归没有从根本上解决这个问题。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605913779,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":327092,"ip_address":""},"score":327685,"extra":""}]}]}]}