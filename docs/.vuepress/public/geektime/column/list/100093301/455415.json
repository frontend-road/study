{"id":455415,"title":"20 | 图像分割（下）：如何构建一个图像分割模型？","content":"<p>你好，我是方远。</p><p>在上一节课中，我们掌握了图像分割的理论知识，你是不是已经迫不及待要上手体验一下，找找手感了呢？</p><p>今天我们就从头开始，来完成一个图像分割项目。项目的内容是，对图片中的小猫进行语义分割。为了实现这个项目，我会引入一个简单但实用的网络结构：UNet。通过这节课的学习，你不但能再次体验一下完整机器学习的模型实现过程，还能实际训练一个语义分割模型。</p><p>课程代码你可以从<a href=\"https://github.com/syuu1987/geekTime-semantic-segmentation/tree/main\">这里</a>下载。</p><h2>数据部分</h2><p>我们还是从机器学习开发三件套：数据、训练、评估说起。首先是数据准备部分，我们先对训练数据进行标记，然后完成数据读取工作。</p><h3>分割图像的标记</h3><p>之前也提到过，图像分割的准备相比图像分类的准备更加复杂。那我们如何标记语义分割所需要的图片呢？在图像分割中，我们使用的每张图片都要有一张与之对应的Mask，如下所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/c2/db/c258c4f2ffd1f819c662aa1e9f6a8cdb.jpg?wh=1024x640\" alt=\"图片\"><br>\n<img src=\"https://static001.geekbang.org/resource/image/1a/a0/1a35623ceccb0750cd8058568d847fa0.png?wh=1024x640\" alt=\"图片\"></p><p>上节课我们说过，Mask就是含有像素类别的特征图。结合这里的示例图片，我们可以看到，Mask就是原图所对应的一张图片，它的每个位置都记录着原图每个位置对应的像素类别。对于Mask的标记，我们需要使用到Labelme工具。</p><p>标记的方法一共包括七步，我们挨个看一下。</p><p>第一步，下载安装<a href=\"https://github.com/wkentaro/labelme\">Labelme</a>。我们按照Github中的安装方式进行安装即可。如果安装比较慢的话，你可以使用国内的镜像（例如清华的）进行安装。</p><!-- [[[read_end]]] --><p>第二步，我们要将需要标记的图⽚放到⼀个⽂件夹中。这里我是将所有猫的图片放入到cats文件夹中了。</p><p><img src=\"https://static001.geekbang.org/resource/image/f3/04/f3c8cc99959c74f363ec290558a51d04.png?wh=1722x882\" alt=\"图片\"></p><p>第三步，我们事先准备好⼀个label.txt的⽂件，⾥⾯每⼀⾏写好的需要标记的类别。我的label.txt如下：</p><pre><code class=\"language-python\">__ignore__\n_background_\ncat\n</code></pre><p>这里我要提醒你的是，前两行最好这么写。不这样写的话，使用label2voc.py转换就会报错，但label2voc.py不是唯一的数据转换方式（还可以使用labelme_json_to_dataset，但推荐你使用label2voc.py）。从第三行开始，表示要标记的类别。</p><p>第四步，执行后面的这条命令，就会自动启动Labelme。</p><pre><code class=\"language-python\">labelme --labels labels.txt --nodata\n</code></pre><p>第五步，点我们击左侧的Open Dir，选择第二步中的文件夹，就会自动导入需要标记的图片。在右下角选择需要标记的文件后，会自动显示出来，如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/0d/81/0d37591417e44d51a21bac11f409c381.png?wh=1780x1470\" alt=\"图片\"></p><p>第六步：点击左侧的Create Polygons。就可以开始标注了。标记的方式就是将小猫沿着它的边界给圈出来，当形成一个闭环的时候，Labelme会自动提示你输入类别，我们选择cat类即可。</p><p>标记成功后，结果如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/88/y6/888dc5b576ccc9629cd1f3fd2d9cbyy6.png?wh=1676x1438\" alt=\"图片\"></p><p>当标记完成后，我们需要保存一下，保存之后会生成标记好的json文件。如下所示：</p><pre><code class=\"language-python\">fangyuan@geektime data $ ls cats\n1.jpeg&nbsp; 1.json&nbsp; 10.jpeg 10.json 2.jpeg&nbsp; 3.jpeg&nbsp; 4.jpeg&nbsp; 4.json\n</code></pre><p>第七步，执行下面的代码，将标记好的数据转换成Mask。</p><pre><code class=\"language-python\">python label2voc.py cats cats_output --label label.txt&nbsp;\n</code></pre><p>上面代码里用到的label2voc.py，你可以通过后面这个链接获取它：<a href=\"https://github.com/wkentaro/labelme/blob/main/examples/semantic_segmentation/labelme2voc.py\">https://github.com/wkentaro/labelme/blob/main/examples/semantic_segmentation/labelme2voc.py</a>。</p><p>其中，cats为标记好的数据，cats_output为输出文件夹。在cats_output下会自动生成4个文件夹，我们只需要两个文件夹，分别是JPEGImages（训练原图）与SegmentationClassPNG（转换后的Mask）。</p><p>到此为止，我们的数据就准备好了。我一共标记了8张图片，如下所示。当然了，在实际的项目中需要大量标记好的图片，这里主要是为了方便演示。</p><p><img src=\"https://static001.geekbang.org/resource/image/7c/1d/7ca1ecafd3ce893610c5eb89yy7ca51d.png?wh=686x285\" alt=\"图片\"></p><p><img src=\"https://static001.geekbang.org/resource/image/53/67/53e088956a41de56ea1010af8a2a6d67.png?wh=703x324\" alt=\"图片\"></p><p>到此为止，标记工作宣告完成。</p><h3>数据读取</h3><p>完成了标记工作之后，我们就要用PyTorch把这些数据给读入进来了，我们把数据相关的写在dataset.py中。具体还是和之前讲的一样，要继承Dataset类，然后实现__init__、__len__和__getitem__方法。</p><p>dataset.py的代码如下所示，我已经在代码中写好注释了，相信结合注释你很容易就能领会意思。</p><pre><code class=\"language-python\">import os\nimport torch\nimport numpy as np\n\nfrom torch.utils.data import Dataset\nfrom PIL import Image \n\n\nclass CatSegmentationDataset(Dataset):\n    \n    # 模型输入是3通道数据\n    in_channels = 3\n    # 模型输出是1通道数据\n    out_channels = 1\n\n    def __init__(\n        self,\n        images_dir,\n        image_size=256,\n    ):\n\n        print(\"Reading images...\")\n        # 原图所在的位置\n        image_root_path = images_dir + os.sep + 'JPEGImages'\n        # Mask所在的位置\n        mask_root_path = images_dir + os.sep + 'SegmentationClassPNG'\n        # 将图片与Mask读入后，分别存在image_slices与mask_slices中\n        self.image_slices = []\n        self.mask_slices = []\n        for im_name in os.listdir(image_root_path):\n            # 原图与mask的名字是相同的，只不过是后缀不一样\n            mask_name = im_name.split('.')[0] + '.png' \n\n            image_path = image_root_path + os.sep + im_name\n            mask_path = mask_root_path + os.sep + mask_name\n\n            im = np.asarray(Image.open(image_path).resize((image_size, image_size)))\n            mask = np.asarray(Image.open(mask_path).resize((image_size, image_size)))\n            self.image_slices.append(im / 255.)\n            self.mask_slices.append(mask)\n\n    def __len__(self):\n        return len(self.image_slices)\n\n    def __getitem__(self, idx):\n\n        image = self.image_slices[idx] \n        mask = self.mask_slices[idx] \n\n        # tensor的顺序是（Batch_size, 通道，高，宽）而numpy读入后的顺序是(高，宽，通道)\n        image = image.transpose(2, 0, 1)\n        # Mask是单通道数据，所以要再加一个维度\n        mask = mask[np.newaxis, :, :]\n\n        image = image.astype(np.float32)\n        mask = mask.astype(np.float32)\n\n        return image, mask\n</code></pre><p>然后，我们的训练代码写在train.py中，train.py中的main函数为主函数，在main中，我们会调用data_loaders来加载数据。代码如下所示：</p><pre><code class=\"language-python\">import torch\n\nfrom torch.utils.data import DataLoader \nfrom torch.utils.data import DataLoader\nfrom dataset import CatSegmentationDataset as Dataset\n\ndef data_loaders(args):\n    dataset_train = Dataset(\n        images_dir=args.images,\n        image_size=args.image_size,\n    )\n\n    loader_train = DataLoader(\n        dataset_train,\n        batch_size=args.batch_size,\n        shuffle=True,\n        num_workers=args.workers,\n    )\n\n    return loader_train\n\n# args是传入的参数\ndef main(args):\n    loader_train = data_loaders(args)\n</code></pre><p>以上就是数据处理的全部内容了。接下来，我们再来看看模型训练部分的内容。</p><h2>模型训练</h2><p>我们先来回忆一下，模型训练的老三样，分别是网络结构、损失函数和优化方法。</p><p>先从网络结构说起，今天我要为你介绍一个叫做UNet的语义分割网络。</p><h3>网络结构：UNet</h3><p><a href=\"https://arxiv.org/pdf/1505.04597.pdf\">UNet</a>是一个非常实用的网络。它是一个典型的Encoder-Decoder类型的分割网络，网络结构非常简单，如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/11/b9/1196c6fcff2fe8c601f608b01bf82ab9.jpg?wh=1920x1130\" alt=\"图片\" title=\"图片来自论文：https://arxiv.org/pdf/1505.04597.pdf\"></p><p>它的网络结构虽然简单，但是效果并不“简单”，我在很多项目中都用它与一些主流的语义分割做对比，而UNet都取得了非常好的效果。</p><p>整体网络结构跟论文中给出的示意图一样，我们重点去关注几个实现细节。</p><p>第一点，图中横向蓝色的箭头，它们都是重复的相同结构，都是由两个3x3的卷积层组合而成的，在每层卷积之后会跟随一个BN层与ReLU的激活层。按照<a href=\"https://time.geekbang.org/column/article/442442\">第14节课</a>讲的，这一部分重复的组织是可以单独提取出来的。我们先来创建一个unet.py文件，用来定义网络结构。</p><p>现在unet.py中创建Block类，它是用来定义刚才所说的重复的卷积块：</p><pre><code class=\"language-python\">class Block(nn.Module):\n\n&nbsp; &nbsp; def __init__(self, in_channels, features):\n&nbsp; &nbsp; &nbsp; &nbsp; super(Block, self).__init__()\n\n&nbsp; &nbsp; &nbsp; &nbsp; self.features = features\n&nbsp; &nbsp; &nbsp; &nbsp; self.conv1 = nn.Conv2d(\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; in_channels=in_channels,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; out_channels=features,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kernel_size=3,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; padding='same',\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; )\n&nbsp; &nbsp; &nbsp; &nbsp; self.conv2 = nn.Conv2d(\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; in_channels=features,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; out_channels=features,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kernel_size=3,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; padding='same',\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; )\n\n&nbsp; &nbsp; def forward(self, input):\n&nbsp; &nbsp; &nbsp; &nbsp; x = self.conv1(input)\n&nbsp; &nbsp; &nbsp; &nbsp; x = nn.BatchNorm2d(num_features=self.features)(x)\n&nbsp; &nbsp; &nbsp; &nbsp; x = nn.ReLU(inplace=True)(x)\n&nbsp; &nbsp; &nbsp; &nbsp; x = self.conv2(x)\n&nbsp; &nbsp; &nbsp; &nbsp; x = nn.BatchNorm2d(num_features=self.features)(x)\n&nbsp; &nbsp; &nbsp; &nbsp; x = nn.ReLU(inplace=True)(x)\n\n&nbsp; &nbsp; &nbsp; &nbsp; return x\n</code></pre><p>这里需要注意的是，同一个块内，特征图的尺寸是不变的，所以padding为same。</p><p>第二点，就是绿色向上的箭头，也就是上采样的过程。这块的实现就是采用上一节课所讲的转置卷积来实现的。</p><p>最后一点，我们现在是要对小猫进行分割，也就是说一共有两个类别——猫与背景。对于二分类的问题，我们可以直接输出一张特征图，然后通过概率来进行判断是正例（猫）还是负例（背景），也就是下面代码中的第71行。同时，下述代码也补全了unet.py中的所有代码。</p><pre><code class=\"language-python\">import torch\nimport torch.nn as nn\n\nclass Block(nn.Module):\n    ...\nclass UNet(nn.Module):\n\n&nbsp; &nbsp; def __init__(self, in_channels=3, out_channels=1, init_features=32):\n&nbsp; &nbsp; &nbsp; &nbsp; super(UNet, self).__init__()\n\n&nbsp; &nbsp; &nbsp; &nbsp; features = init_features\n&nbsp; &nbsp; &nbsp; &nbsp; self.conv_encoder_1 = Block(in_channels, features)\n&nbsp; &nbsp; &nbsp; &nbsp; self.conv_encoder_2 = Block(features, features * 2)\n&nbsp; &nbsp; &nbsp; &nbsp; self.conv_encoder_3 = Block(features * 2, features * 4)\n&nbsp; &nbsp; &nbsp; &nbsp; self.conv_encoder_4 = Block(features * 4, features * 8)\n\n&nbsp; &nbsp; &nbsp; &nbsp; self.bottleneck = Block(features * 8, features * 16)\n\n&nbsp; &nbsp; &nbsp; &nbsp; self.upconv4 = nn.ConvTranspose2d(\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; features * 16, features * 8, kernel_size=2, stride=2\n&nbsp; &nbsp; &nbsp; &nbsp; )\n&nbsp; &nbsp; &nbsp; &nbsp; self.conv_decoder_4 = Block((features * 8) * 2, features * 8)\n&nbsp; &nbsp; &nbsp; &nbsp; self.upconv3 = nn.ConvTranspose2d(\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; features * 8, features * 4, kernel_size=2, stride=2\n&nbsp; &nbsp; &nbsp; &nbsp; )\n&nbsp; &nbsp; &nbsp; &nbsp; self.conv_decoder_3 = Block((features * 4) * 2, features * 4)\n&nbsp; &nbsp; &nbsp; &nbsp; self.upconv2 = nn.ConvTranspose2d(\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; features * 4, features * 2, kernel_size=2, stride=2\n&nbsp; &nbsp; &nbsp; &nbsp; )\n&nbsp; &nbsp; &nbsp; &nbsp; self.conv_decoder_2 = Block((features * 2) * 2, features * 2)\n&nbsp; &nbsp; &nbsp; &nbsp; self.upconv1 = nn.ConvTranspose2d(\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; features * 2, features, kernel_size=2, stride=2\n&nbsp; &nbsp; &nbsp; &nbsp; )\n&nbsp; &nbsp; &nbsp; &nbsp; self.decoder1 = Block(features * 2, features)\n\n&nbsp; &nbsp; &nbsp; &nbsp; self.conv = nn.Conv2d(\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; in_channels=features, out_channels=out_channels, kernel_size=1\n&nbsp; &nbsp; &nbsp; &nbsp; )\n\n&nbsp; &nbsp; def forward(self, x):\n&nbsp; &nbsp; &nbsp; &nbsp; conv_encoder_1_1 = self.conv_encoder_1(x)\n&nbsp; &nbsp; &nbsp; &nbsp; conv_encoder_1_2 = nn.MaxPool2d(kernel_size=2, stride=2)(conv_encoder_1_1)\n\n&nbsp; &nbsp; &nbsp; &nbsp; conv_encoder_2_1 = self.conv_encoder_2(conv_encoder_1_2)\n&nbsp; &nbsp; &nbsp; &nbsp; conv_encoder_2_2 = nn.MaxPool2d(kernel_size=2, stride=2)(conv_encoder_2_1)\n\n&nbsp; &nbsp; &nbsp; &nbsp; conv_encoder_3_1 = self.conv_encoder_3(conv_encoder_2_2)\n&nbsp; &nbsp; &nbsp; &nbsp; conv_encoder_3_2 = nn.MaxPool2d(kernel_size=2, stride=2)(conv_encoder_3_1)\n\n&nbsp; &nbsp; &nbsp; &nbsp; conv_encoder_4_1 = self.conv_encoder_4(conv_encoder_3_2)\n&nbsp; &nbsp; &nbsp; &nbsp; conv_encoder_4_2 = nn.MaxPool2d(kernel_size=2, stride=2)(conv_encoder_4_1)\n\n&nbsp; &nbsp; &nbsp; &nbsp; bottleneck = self.bottleneck(conv_encoder_4_2)\n\n&nbsp; &nbsp; &nbsp; &nbsp; conv_decoder_4_1 = self.upconv4(bottleneck)\n&nbsp; &nbsp; &nbsp; &nbsp; conv_decoder_4_2 = torch.cat((conv_decoder_4_1, conv_encoder_4_1), dim=1)\n&nbsp; &nbsp; &nbsp; &nbsp; conv_decoder_4_3 = self.conv_decoder_4(conv_decoder_4_2)\n\n&nbsp; &nbsp; &nbsp; &nbsp; conv_decoder_3_1 = self.upconv3(conv_decoder_4_3)\n&nbsp; &nbsp; &nbsp; &nbsp; conv_decoder_3_2 = torch.cat((conv_decoder_3_1, conv_encoder_3_1), dim=1)\n&nbsp; &nbsp; &nbsp; &nbsp; conv_decoder_3_3 = self.conv_decoder_3(conv_decoder_3_2)\n\n&nbsp; &nbsp; &nbsp; &nbsp; conv_decoder_2_1 = self.upconv2(conv_decoder_3_3)\n&nbsp; &nbsp; &nbsp; &nbsp; conv_decoder_2_2 = torch.cat((conv_decoder_2_1, conv_encoder_2_1), dim=1)\n&nbsp; &nbsp; &nbsp; &nbsp; conv_decoder_2_3 = self.conv_decoder_2(conv_decoder_2_2)\n\n&nbsp; &nbsp; &nbsp; &nbsp; conv_decoder_1_1 = self.upconv1(conv_decoder_2_3)\n&nbsp; &nbsp; &nbsp; &nbsp; conv_decoder_1_2 = torch.cat((conv_decoder_1_1, conv_encoder_1_1), dim=1)\n&nbsp; &nbsp; &nbsp; &nbsp; conv_decoder_1_3 = self.decoder1(conv_decoder_1_2)\n\n&nbsp; &nbsp; &nbsp; &nbsp; return torch.sigmoid(self.conv(conv_decoder_1_3))\n</code></pre><p>到这里，网络结构我们就搭建好了，然后我们来我看看损失函数。</p><h3>损失函数：Dice Loss</h3><p>这里我们来看一下语义分割中常用的损失函数，Dice Loss。</p><p>想要知道这个损失函数如何生成，你需要先了解一个语义分割的评价指标（但更常用的还是后面要讲的的mIoU），它就是Dice系数，常用于计算两个集合的相似度，取值范围在0-1之间。</p><p>Dice系数的公式如下。</p><p>$$Dice=\\frac{2|P\\cap G|}{|P|+|G|}$$</p><p>其中，$|P\\cap G|$是集合P与集合G之间交集元素的个数，$|P|$和$|G|$分别表示集合P和G的元素个数。分子的系数2，这是为了抵消分母中P和G之间的共同元素。对语义分割任务而言，集合P就是预测值的Mask，集合G就是真实值的Mask。</p><p>根据Dice系数我们就能设计出一种损失函数，也就是Dice Loss。它的计算公式非常简单，如下所示。</p><p>$$Dice Loss=1-\\frac{2|P\\cap G|}{|P|+|G|}$$</p><p>从公式中可以看出，当预测值的Mask与GT越相似，损失就越小；当预测值的Mask与GT差异度越大，损失就越大。</p><p>对于二分类问题，GT只有0和1两个值。当我们直接使用模型输出的预测概率而不是使用阈值将它们转换为二值Mask时，这种损失函数就被称为Soft Dice Loss。此时，$|P\\cap G|$的值近似为GT与预测概率矩阵的点乘。</p><p>定义损失函数的代码如下。</p><pre><code class=\"language-python\">import torch.nn as nn\n\nclass DiceLoss(nn.Module):\n&nbsp; &nbsp; def __init__(self):\n&nbsp; &nbsp; &nbsp; &nbsp; super(DiceLoss, self).__init__()\n&nbsp; &nbsp; &nbsp; &nbsp; self.smooth = 1.0\n\n&nbsp; &nbsp; def forward(self, y_pred, y_true):\n&nbsp; &nbsp; &nbsp; &nbsp; assert y_pred.size() == y_true.size()\n&nbsp; &nbsp; &nbsp; &nbsp; y_pred = y_pred[:, 0].contiguous().view(-1)\n&nbsp; &nbsp; &nbsp; &nbsp; y_true = y_true[:, 0].contiguous().view(-1)\n&nbsp; &nbsp; &nbsp; &nbsp; intersection = (y_pred * y_true).sum()\n&nbsp; &nbsp; &nbsp; &nbsp; dsc = (2. * intersection + self.smooth) / (\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; y_pred.sum() + y_true.sum() + self.smooth\n&nbsp; &nbsp; &nbsp; &nbsp; )\n&nbsp; &nbsp; &nbsp; &nbsp; return 1. - dsc\n</code></pre><p>其中，self.smooth是一个平滑值，这是为了防止分子和分母为0的情况。</p><h3>训练流程</h3><p>最后，我们将模型、损失函数和优化方法串起来，看下整体的训练流程，训练的代码如下。</p><pre><code class=\"language-python\">def main(args):\n&nbsp; &nbsp; makedirs(args)\n    # 根据cuda可用情况选择使用cpu或gpu\n&nbsp; &nbsp; device = torch.device(\"cpu\" if not torch.cuda.is_available() else args.device)\n    # 加载训练数据\n&nbsp; &nbsp; loader_train = data_loaders(args)\n    # 实例化UNet网络模型\n&nbsp; &nbsp; unet = UNet(in_channels=Dataset.in_channels, out_channels=Dataset.out_channels)\n&nbsp; &nbsp; # 将模型送入gpu或cpu中\n    unet.to(device)\n    # 损失函数\n&nbsp; &nbsp; dsc_loss = DiceLoss()\n    # 优化方法\n&nbsp; &nbsp; optimizer = optim.Adam(unet.parameters(), lr=args.lr)\n\n&nbsp; &nbsp; loss_train = []\n&nbsp; &nbsp; step = 0\n    # 训练n个Epoch\n&nbsp; &nbsp; for epoch in tqdm(range(args.epochs), total=args.epochs):\n&nbsp; &nbsp; &nbsp; &nbsp; unet.train()\n&nbsp; &nbsp; &nbsp; &nbsp; for i, data in enumerate(loader_train):\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; step += 1\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; x, y_true = data\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; x, y_true = x.to(device), y_true.to(device)\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; y_pred = unet(x)\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; optimizer.zero_grad()\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; loss = dsc_loss(y_pred, y_true)\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; loss_train.append(loss.item())\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; loss.backward()\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; optimizer.step()\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (step + 1) % 10 == 0:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print('Step ', step, 'Loss', np.mean(loss_train))\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; loss_train = []\n&nbsp; &nbsp; &nbsp; &nbsp; torch.save(unet, args.weights + '/unet_epoch_{}.pth'.format(epoch))\n</code></pre><p>需要注意的点，我都在注释中进行了说明，你可以自己看一看。其实就是我们一直说的模型训练的那几件事情：数据加载、构建网络以及迭代更新网络参数。</p><p>我用训练数据训练了若干个Epoch，同时也保存了若干个模型，保存为pth格式。到这里就完成了模型训练的整个环节，我们可以使用保存好的模型进行预测，来看看分割效果如何。</p><h2>模型预测</h2><p>现在我们要用训练生成的模型来进行语义分割，看看结果是什么样子的。</p><p>模型预测的代码如下。</p><pre><code class=\"language-python\">import torch\nimport numpy as np\n\nfrom PIL import Image\n\nimg_size = (256, 256)\n# 加载模型\nunet = torch.load('./weights/unet_epoch_51.pth')\nunet.eval()\n# 加载并处理输入图片\nori_image = Image.open('data/JPEGImages/6.jpg')\nim = np.asarray(ori_image.resize(img_size))\nim = im / 255.\nim = im.transpose(2, 0, 1)\nim = im[np.newaxis, :, :]\nim = im.astype('float32')\n# 模型预测\noutput = unet(torch.from_numpy(im)).detach().numpy()\n# 模型输出转化为Mask图片\noutput = np.squeeze(output)\noutput = np.where(output&gt;0.5, 1, 0).astype(np.uint8)\nmask = Image.fromarray(output, mode='P')\nmask.putpalette([0,0,0, 0,128,0])\nmask = mask.resize(ori_image.size)\nmask.save('output.png')\n</code></pre><p>这段代码也很好理解。首先，用torch.load函数加载模型。接着加载一张待分割的图片，并进行数据预处理。然后将处理好的数据送入模型中，得到预测值output。最后将预测值转化为可视化的Mask图片进行保存。</p><p>输入图片也就是待分割的图片，如下左图所示。最终的输出，即可视化的Mask图片如下右图所示。</p><table>\n<thead>\n<tr>\n<th style=\"text-align:left\"><img src=\"https://static001.geekbang.org/resource/image/c2/db/c258c4f2ffd1f819c662aa1e9f6a8cdb.jpeg?wh=1024x640\" alt=\"图片\"></th>\n<th style=\"text-align:left\"><img src=\"https://static001.geekbang.org/resource/image/fb/61/fbfecd56d8c31589890fcd05c7995461.png?wh=1024x640\" alt=\"图片\"></th>\n</tr>\n</thead>\n<tbody></tbody>\n</table><p>在将预测值转化为Mask图片的过程中，最终预测值的概率卡了0.5的阈值，超过阈值的像素点，在output矩阵中的值为1，表示猫的区域，没有超过阈值的像素点，在output矩阵中的值为0，表示背景区域。</p><p>为了将output矩阵输出为可视化的图像，我们使用Image.fromarray函数，将Numpy的array转化为Image格式，并将模式设置为“P”，即调色板模式。然后用putpalette函数来给Image对象上色。</p><p>其中，putpalette函数的参数是一个列表：[0, 0, 0, 0, 128, 0]，列表前三个数表示值为0的像素的RGB（[0, 0, 0]表示黑色），列表后三个数表示值为1的像素的RGB（[0, 128, 0]表示绿色）。这样，我们保存的Mask图片，黑色部分即为背景区域，绿色部分即为猫的区域。</p><p>不过，这样分开的轮廓图，可能无法让我们很直观地看出语义分割的效果。所以我们将原图和Mask合成一张图片来看看效果。具体的代码如下。</p><pre><code class=\"language-python\">image = ori_image.convert('RGBA')\nmask = mask.convert('RGBA')\n# 合成\nimage_mask = Image.blend(image, mask, 0.3)\nimage_mask.save(\"output_mask.png\")\n</code></pre><p>首先，我们将原图image和Mask图片都转换为’RGBA’带透明度的模式。然后使用Image.blend函数将两张图片合成一张图片，最后一个参数0.3表示Mask图片透明度为30%，原图的透明度为70%。<br>\n最终的结果如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/4d/7b/4d804527a87cc92aab8173da85f0ff7b.png?wh=1024x640\" alt=\"图片\"></p><p>这样我们就可以直观地看出哪些地方预测得不准确了。</p><h2>模型评估</h2><p>在语义分割中，常用的评价指标是mIoU。mIoU全称为mean Intersection over Union，即平均交并比。交并比是真实值和预测值的交集和并集之比。</p><p>真实值就是我们刚刚用labelme标注的Mask，也是Ground Truth（GT）。如下左图所示。</p><p>预测值就是模型预测出的Mask，用Prediction表示。如后面右图所示。</p><table>\n<thead>\n<tr>\n<th style=\"text-align:left\"><img src=\"https://static001.geekbang.org/resource/image/61/0b/61afb79172dfa0bd652f237fd1c5bd0b.png?wh=1024x640\" alt=\"图片\"></th>\n<th style=\"text-align:left\"><img src=\"https://static001.geekbang.org/resource/image/c3/9d/c31ec50a2a67262728a9fd8e84a1729d.png?wh=1024x640\" alt=\"图片\"></th>\n</tr>\n</thead>\n<tbody></tbody>\n</table><p>交集是指真实值与预测值的交集，如下图黄色区域所示。并集是指真实值与预测值的并集，如下图蓝色区域所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/53/29/53e81fae1ceb5f21a269c3a461c6b129.png?wh=1024x640\" alt=\"图片\"></p><p>通过上面几个图，我们很容易就能理解mIoU了。mIoU的公式如下所示。</p><p>$$mIoU=\\frac{1}{k}\\sum_{i=1}^{k}{\\frac{P\\cap G}{P\\cup G}}$$</p><p>其中，k为所有类别数，在我们的例子中，只有“cat”一类，因此k为1，我们通常不将背景计算到mIoU中；P为预测值；G是真实值。</p><h2>小结</h2><p>恭喜你，完成了今天的学习任务。这节课我们一起完成了一个图像分割项目的实践。</p><p>首先，我带你了解了图像分割的数据准备，需要使用Labelme工具为图像做标记。数据质量的好坏决定了最终模型的质量，所以你要对数据的标注好好把握。在使用Labelme标记完成之后，我们可以使用label2voc.py将json转换为Mask。</p><p>之后我们学习了一种非常高效且实用的模型–UNet，并使用PyTorch实现了其网络结构。</p><p>然后，我为你讲解了图像分割的评估指标mIoU和损失函数Dice Loss。</p><p>mIoU的公式如下：</p><p>$$mIoU=\\frac{1}{k}\\sum_{i=1}^{k}{\\frac{P\\cap G}{P\\cup G}}$$</p><p>mIoU主要是从预测结果与GT的重合度这一角度，来衡量分割模型的好与坏的，它是图像分割中经常使用的评价指标。</p><p>最后，我们使用训练好的模型进行预测，并对分割结果进行了可视化绘制。相信通过之前学习的图像分类项目与今天学习的图像分割项目，对于图像处理，你会获得更深层次的理解。</p><h2>每课一练</h2><p>你可以根据今天的内容，自己动手试试建立一个图像分割模型，然后用一张图片来测一下效果如何。</p><p>欢迎你在留言区跟我交流讨论，也推荐你把今天的内容分享给更多同事、朋友，我们下节课见。</p><h1></h1>","neighbors":{"left":{"article_title":"19 | 图像分割（上）：详解图像分割原理与图像分割模型","id":450898},"right":{"article_title":"21 | NLP基础（上）：详解自然语言处理原理与常用算法","id":460504}},"comments":[{"had_liked":false,"id":334251,"user_name":"克bug体质","can_delete":false,"product_type":"c1","uid":2860418,"ip_address":"","ucode":"F810FAB99C7799","user_header":"https://static001.geekbang.org/account/avatar/00/2b/a5/82/183bc76c.jpg","comment_is_top":false,"comment_ctime":1644828154,"is_pvip":false,"replies":[{"id":"122142","content":"hi，原因是如果在forward中使用了nn调用网络中的层的话，它默认会放在cpu上计算。<br>解决的办法就是把bn和relu放到__init__中，如下代码所示。<br><br>class Block(nn.Module):<br><br>    def __init__(self, in_channels, features):<br>        super().__init__()<br>        self.features = features<br><br>        self.conv1 = nn.Conv2d(<br>                            in_channels=in_channels,<br>                            out_channels=features,<br>                            kernel_size=3,<br>                            padding=&#39;same&#39;,<br>                        )<br>        self.bn1 = nn.BatchNorm2d(num_features=self.features)<br>        self.relu1 = nn.ReLU()<br>        self.conv2 = nn.Conv2d(<br>                            in_channels=features,<br>                            out_channels=features,<br>                            kernel_size=3,<br>                            padding=&#39;same&#39;,<br>                        )<br>        self.bn2 = nn.BatchNorm2d(num_features=self.features)<br>        self.relu2 = nn.ReLU()<br><br>    def forward(self, input):<br>        x = self.conv1(input)<br>        x = self.bn1(x)<br>        x = self.relu1(x)<br>        x = self.conv2(x)<br>        x = self.bn2(x)<br>        x = self.relu2(x)<br>        return x<br>同理U-Net中的pooling也要放到__init__()中。","user_name":"作者回复","user_name_real":"编辑","uid":"2802608","ctime":1644913232,"ip_address":"","comment_id":334251,"utype":1}],"discussion_count":3,"race_medal":0,"score":"18824697338","product_id":100093301,"comment_content":"老师你好，Loss也要放到放到gpu后也会报和之前一样的错误：【<br>Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument weight in method wrapper__cudnn_batch_norm)<br>  File &quot;D:\\U-Net\\unet.py&quot;, line 25, in forward<br>    x = nn.BatchNorm2d(num_features=self.features)(x)<br>  File &quot;D:\\U-Net\\unet.py&quot;, line 67, in forward<br>    conv_encoder_1_1 = self.conv_encoder_1(x)<br>  File &quot;D:\\U-Net\\train.py&quot;, line 50, in main<br>    y_pred = unet(x)<br>  File &quot;D:\\U-Net\\train.py&quot;, line 136, in &lt;module&gt;<br>    main(args)<br>】<br>我尝试在unet.py文件中的创建class UNet中self.conv_encoder_1 = Block(in_channels, features)改为：self.conv_encoder_1 = Block(in_channels, features).to(device)后也没解决这个问题，会报一样的错。","like_count":4,"discussions":[{"author":{"id":2802608,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK1ZkL9L7CEicI87xicpIhXAIhVdVWpJKBsD8Jpzg9iaAwFcDEhTvdRwuKItJS14mYznT2w2YQvn8QsQ/132","nickname":"方远","note":"","ucode":"248B1DE180EB4C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":551157,"discussion_content":"hi，原因是如果在forward中使用了nn调用网络中的层的话，它默认会放在cpu上计算。\n解决的办法就是把bn和relu放到__init__中，如下代码所示。\n\nclass Block(nn.Module):\n\n    def __init__(self, in_channels, features):\n        super().__init__()\n        self.features = features\n\n        self.conv1 = nn.Conv2d(\n                            in_channels=in_channels,\n                            out_channels=features,\n                            kernel_size=3,\n                            padding=&#39;same&#39;,\n                        )\n        self.bn1 = nn.BatchNorm2d(num_features=self.features)\n        self.relu1 = nn.ReLU()\n        self.conv2 = nn.Conv2d(\n                            in_channels=features,\n                            out_channels=features,\n                            kernel_size=3,\n                            padding=&#39;same&#39;,\n                        )\n        self.bn2 = nn.BatchNorm2d(num_features=self.features)\n        self.relu2 = nn.ReLU()\n\n    def forward(self, input):\n        x = self.conv1(input)\n        x = self.bn1(x)\n        x = self.relu1(x)\n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu2(x)\n        return x\n同理U-Net中的pooling也要放到__init__()中。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1644913232,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":2,"child_discussions":[{"author":{"id":2860418,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/a5/82/183bc76c.jpg","nickname":"克bug体质","note":"","ucode":"F810FAB99C7799","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2802608,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK1ZkL9L7CEicI87xicpIhXAIhVdVWpJKBsD8Jpzg9iaAwFcDEhTvdRwuKItJS14mYznT2w2YQvn8QsQ/132","nickname":"方远","note":"","ucode":"248B1DE180EB4C","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":551380,"discussion_content":"好的，感谢老师！学习到了🙏","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1645003284,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":551157,"ip_address":""},"score":551380,"extra":""},{"author":{"id":2802608,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK1ZkL9L7CEicI87xicpIhXAIhVdVWpJKBsD8Jpzg9iaAwFcDEhTvdRwuKItJS14mYznT2w2YQvn8QsQ/132","nickname":"方远","note":"","ucode":"248B1DE180EB4C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":2860418,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/a5/82/183bc76c.jpg","nickname":"克bug体质","note":"","ucode":"F810FAB99C7799","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":551383,"discussion_content":"不客气不客气^^  ","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1645003592,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":551380,"ip_address":""},"score":551383,"extra":""}]}]},{"had_liked":false,"id":346957,"user_name":"亚林","can_delete":false,"product_type":"c1","uid":1018972,"ip_address":"","ucode":"4A5A6D24314B79","user_header":"https://static001.geekbang.org/account/avatar/00/0f/8c/5c/3f164f66.jpg","comment_is_top":false,"comment_ctime":1653559170,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5948526466","product_id":100093301,"comment_content":"照着抄，抄出来了","like_count":1},{"had_liked":false,"id":344824,"user_name":"..................","can_delete":false,"product_type":"c1","uid":2980638,"ip_address":"","ucode":"3203CA634FC3A7","user_header":"https://static001.geekbang.org/account/avatar/00/2d/7b/1e/8bb7c7fe.jpg","comment_is_top":false,"comment_ctime":1651809546,"is_pvip":false,"replies":[{"id":"126006","content":"^^ 感谢支持，加油","user_name":"作者回复","user_name_real":"编辑","uid":"2802608","ctime":1652163178,"ip_address":"","comment_id":344824,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5946776842","product_id":100093301,"comment_content":"真的很棒，我要亲手操作一遍","like_count":1,"discussions":[{"author":{"id":2802608,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK1ZkL9L7CEicI87xicpIhXAIhVdVWpJKBsD8Jpzg9iaAwFcDEhTvdRwuKItJS14mYznT2w2YQvn8QsQ/132","nickname":"方远","note":"","ucode":"248B1DE180EB4C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":571267,"discussion_content":"^^ 感谢支持，加油","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1652163178,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":331758,"user_name":"蓝色天空  好萌啊","can_delete":false,"product_type":"c1","uid":2642907,"ip_address":"","ucode":"2D4620E82BC4A2","user_header":"https://static001.geekbang.org/account/avatar/00/28/53/db/244953c6.jpg","comment_is_top":false,"comment_ctime":1642752330,"is_pvip":false,"replies":[{"id":"121299","content":"hello，你好，我传到这里了。<br>https:&#47;&#47;github.com&#47;syuu1987&#47;geekTime-semantic-segmentation&#47;tree&#47;main","user_name":"作者回复","user_name_real":"编辑","uid":"2802608","ctime":1642987078,"ip_address":"","comment_id":331758,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5937719626","product_id":100093301,"comment_content":"老师你好，请问有这节课的完整代码地址吗？","like_count":1,"discussions":[{"author":{"id":2802608,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK1ZkL9L7CEicI87xicpIhXAIhVdVWpJKBsD8Jpzg9iaAwFcDEhTvdRwuKItJS14mYznT2w2YQvn8QsQ/132","nickname":"方远","note":"","ucode":"248B1DE180EB4C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":547978,"discussion_content":"hello，你好，我传到这里了。\nhttps://github.com/syuu1987/geekTime-semantic-segmentation/tree/main","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1642987078,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":326185,"user_name":"Geek_a95f0e","can_delete":false,"product_type":"c1","uid":2824511,"ip_address":"","ucode":"C0B7418FD1D2B5","user_header":"","comment_is_top":false,"comment_ctime":1639407259,"is_pvip":false,"replies":[{"id":"118449","content":"hi 你好。感谢你的留言。<br>这块可能我误导你了，都是一样的。<br>Python3中super().__init__()代替了Python2中的super(class_name,self).__init__() ","user_name":"作者回复","user_name_real":"编辑","uid":"2802608","ctime":1639447249,"ip_address":"","comment_id":326185,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5934374555","product_id":100093301,"comment_content":"方老师，可不可以解释一下自定义类中 super().__init__() 和super(class_name,self).__init__() 有什么区别？","like_count":1,"discussions":[{"author":{"id":2802608,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK1ZkL9L7CEicI87xicpIhXAIhVdVWpJKBsD8Jpzg9iaAwFcDEhTvdRwuKItJS14mYznT2w2YQvn8QsQ/132","nickname":"方远","note":"","ucode":"248B1DE180EB4C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":538564,"discussion_content":"hi 你好。感谢你的留言。\n这块可能我误导你了，都是一样的。\nPython3中super().__init__()代替了Python2中的super(class_name,self).__init__() ","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1639447249,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":2824511,"avatar":"","nickname":"Geek_a95f0e","note":"","ucode":"C0B7418FD1D2B5","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2802608,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK1ZkL9L7CEicI87xicpIhXAIhVdVWpJKBsD8Jpzg9iaAwFcDEhTvdRwuKItJS14mYznT2w2YQvn8QsQ/132","nickname":"方远","note":"","ucode":"248B1DE180EB4C","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":538619,"discussion_content":"好的，谢谢。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1639455186,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":538564,"ip_address":""},"score":538619,"extra":""}]}]},{"had_liked":false,"id":323605,"user_name":"vcjmhg","can_delete":false,"product_type":"c1","uid":1526461,"ip_address":"","ucode":"B508D1E9B3F974","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/j24oyxHcpB5AMR9pMO6fITqnOFVOncnk2T1vdu1rYLfq1cN6Sj7xVrBVbCvHXUad2MpfyBcE4neBguxmjIxyiaQ/132","comment_is_top":false,"comment_ctime":1638014229,"is_pvip":false,"replies":[{"id":"117498","content":"hello，小物体分割不好的一个原因是在backbone的特征提取过程中，小物体的信息已经被忽略了。<br>举个例子，假设输入是256x256的数据，经过多层的特征提取后特征图依次为128x128，64x64，32x32，16x16。有可能小物体的信息在32x32那里就消失了。<br>从这个角度出发，可以看看能不能调整网络最小的特征图的大小，来解决小物体分割不好的问题（比如Unet中，删除最后一次下采样）。另外，你也要看看小物体是不是resize到训练数据尺寸的时候已经没有了。","user_name":"作者回复","user_name_real":"编辑","uid":"2802608","ctime":1638147536,"ip_address":"","comment_id":323605,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5932981525","product_id":100093301,"comment_content":"老师您好，我自己有尝试复现deeplab v3+这个比较主流的语义分割网络，然后发现针对一些尺寸较大的目标其分割效果还是比较不错的，但是对小的目标分割效果很差，甚至好多时候都分割不到，请问针对这种小目标，除了在数据集上做处理外，还有哪些好的处理或者优化方法呢？","like_count":1,"discussions":[{"author":{"id":2802608,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK1ZkL9L7CEicI87xicpIhXAIhVdVWpJKBsD8Jpzg9iaAwFcDEhTvdRwuKItJS14mYznT2w2YQvn8QsQ/132","nickname":"方远","note":"","ucode":"248B1DE180EB4C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":534230,"discussion_content":"hello，小物体分割不好的一个原因是在backbone的特征提取过程中，小物体的信息已经被忽略了。\n举个例子，假设输入是256x256的数据，经过多层的特征提取后特征图依次为128x128，64x64，32x32，16x16。有可能小物体的信息在32x32那里就消失了。\n从这个角度出发，可以看看能不能调整网络最小的特征图的大小，来解决小物体分割不好的问题（比如Unet中，删除最后一次下采样）。另外，你也要看看小物体是不是resize到训练数据尺寸的时候已经没有了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1638147536,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":360994,"user_name":"汪zZ","can_delete":false,"product_type":"c1","uid":1234757,"ip_address":"北京","ucode":"8B93062A683902","user_header":"https://static001.geekbang.org/account/avatar/00/12/d7/45/d1621188.jpg","comment_is_top":false,"comment_ctime":1667097819,"is_pvip":true,"replies":[{"id":"131435","content":"理论上，代码是肯定能执行通过的。不过我对视频没有研究，不知道分割效果如何。","user_name":"作者回复","user_name_real":"编辑","uid":"2802608","ctime":1667459648,"ip_address":"北京","comment_id":360994,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1667097819","product_id":100093301,"comment_content":"方老师，请教一下：<br>如果我不是对图片进行语义分割，而是对类似视频，比如（400,384,288）的数据立方体进行语义分割，还可以使用unet吗？如果使用的话，这个示例里的通道数是从3-&gt;512-&gt;32-&gt;1，那么这种400通道的该怎么处理？<br>谢谢。","like_count":0,"discussions":[{"author":{"id":2802608,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK1ZkL9L7CEicI87xicpIhXAIhVdVWpJKBsD8Jpzg9iaAwFcDEhTvdRwuKItJS14mYznT2w2YQvn8QsQ/132","nickname":"方远","note":"","ucode":"248B1DE180EB4C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":592519,"discussion_content":"理论上，代码是肯定能执行通过的。不过我对视频没有研究，不知道分割效果如何。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1667459648,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京"},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":357525,"user_name":"gavin","can_delete":false,"product_type":"c1","uid":1099142,"ip_address":"辽宁","ucode":"3D99ADC89699FE","user_header":"https://static001.geekbang.org/account/avatar/00/10/c5/86/1134c2f1.jpg","comment_is_top":false,"comment_ctime":1663334025,"is_pvip":false,"replies":[{"id":"130150","content":"您好，多分类时让网络最终输出的个数等于类别数，然后加softmax即可。","user_name":"作者回复","user_name_real":"编辑","uid":"2802608","ctime":1663416879,"ip_address":"辽宁","comment_id":357525,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1663334025","product_id":100093301,"comment_content":"方老师，请问一下如果是多分类，特征图输出要怎么弄？","like_count":0,"discussions":[{"author":{"id":2802608,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK1ZkL9L7CEicI87xicpIhXAIhVdVWpJKBsD8Jpzg9iaAwFcDEhTvdRwuKItJS14mYznT2w2YQvn8QsQ/132","nickname":"方远","note":"","ucode":"248B1DE180EB4C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":587976,"discussion_content":"您好，多分类时让网络最终输出的个数等于类别数，然后加softmax即可。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1663416879,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"辽宁"},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":355255,"user_name":"John(易筋)","can_delete":false,"product_type":"c1","uid":1180202,"ip_address":"北京","ucode":"BB4E58DD4B8F15","user_header":"https://static001.geekbang.org/account/avatar/00/12/02/2a/90e38b94.jpg","comment_is_top":false,"comment_ctime":1661229627,"is_pvip":true,"replies":[{"id":"129286","content":"hi，你好。感谢留言。<br>这个尺寸是取决于网络的设计。<br>256x256的分割结果是可以resize回1024x640的。<br>当然，如果你设计的网络的输入输出支持1024x640的等比例缩放，也是可以的。","user_name":"作者回复","user_name_real":"编辑","uid":"2802608","ctime":1661319334,"ip_address":"北京","comment_id":355255,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1661229627","product_id":100093301,"comment_content":"predict_single.py 代码改了一下文件的相对路径可以跑通，发现output.jpg 大小为256x256. 原图微1024x640. 请教方老师，为啥语义分割出来的图片不是原始图片的等比缩小呢？ 谢谢<br>```<br>import torch<br>import numpy as np<br><br>from PIL import Image<br><br>img_size = (256, 256)<br>unet = torch.load(&#39;.&#47;ckpts&#47;unet_epoch_51.pth&#39;)<br><br>unet.eval()<br><br><br>im = np.asarray(Image.open(&#39;.&#47;data&#47;JPEGImages&#47;6.jpg&#39;).resize(img_size))<br><br>im = im &#47; 255.<br>im = im.transpose(2, 0, 1)<br>im = im[np.newaxis, :, :]<br>im = im.astype(&#39;float32&#39;)<br>output = unet(torch.from_numpy(im)).detach().numpy()<br><br>output = np.squeeze(output)<br>output = np.where(output&gt;0.5, 150, 0).astype(np.uint8)<br>print(output.shape, type(output))<br>im = Image.fromarray(output)<br>im.save(&#39;.&#47;output.jpg&#39;)<br>```","like_count":0,"discussions":[{"author":{"id":2802608,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK1ZkL9L7CEicI87xicpIhXAIhVdVWpJKBsD8Jpzg9iaAwFcDEhTvdRwuKItJS14mYznT2w2YQvn8QsQ/132","nickname":"方远","note":"","ucode":"248B1DE180EB4C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":585062,"discussion_content":"hi，你好。感谢留言。\n这个尺寸是取决于网络的设计。\n256x256的分割结果是可以resize回1024x640的。\n当然，如果你设计的网络的输入输出支持1024x640的等比例缩放，也是可以的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1661319334,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京"},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":350348,"user_name":"万化8af10b","can_delete":false,"product_type":"c1","uid":1916746,"ip_address":"","ucode":"A5A212C8AE843E","user_header":"https://static001.geekbang.org/account/avatar/00/1d/3f/4a/b1c9e5e3.jpg","comment_is_top":false,"comment_ctime":1656839600,"is_pvip":true,"replies":[{"id":"127493","content":"Hi, 你好，感谢你的留言。<br>看起来是你要调用你训练了51个epoch的模型，可以看看你保存或者调用的路径写没写错。","user_name":"作者回复","user_name_real":"编辑","uid":"2802608","ctime":1656982070,"ip_address":"","comment_id":350348,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1656839600","product_id":100093301,"comment_content":"请问&#47;weights&#47;unet_epoch_51.Pth找不到，谢谢","like_count":0,"discussions":[{"author":{"id":2802608,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK1ZkL9L7CEicI87xicpIhXAIhVdVWpJKBsD8Jpzg9iaAwFcDEhTvdRwuKItJS14mYznT2w2YQvn8QsQ/132","nickname":"方远","note":"","ucode":"248B1DE180EB4C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":578701,"discussion_content":"Hi, 你好，感谢你的留言。\n看起来是你要调用你训练了51个epoch的模型，可以看看你保存或者调用的路径写没写错。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1656982071,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":347260,"user_name":"zhangting","can_delete":false,"product_type":"c1","uid":2950861,"ip_address":"","ucode":"565BB6CEE694E0","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/ajNVdqHZLLDm5eHbw1fuicJiaXercgBI48O0Idt2mHUElmZyBM4o119NkndU1SNpsv8rZzKFibj8z1FibFAdNEO3zw/132","comment_is_top":false,"comment_ctime":1653881453,"is_pvip":false,"replies":[{"id":"126647","content":"您好，已上传至github^^","user_name":"作者回复","user_name_real":"编辑","uid":"2802608","ctime":1653958979,"ip_address":"","comment_id":347260,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1653881453","product_id":100093301,"comment_content":"老师，这个猫的数据集可以分享一下么？","like_count":0,"discussions":[{"author":{"id":2802608,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK1ZkL9L7CEicI87xicpIhXAIhVdVWpJKBsD8Jpzg9iaAwFcDEhTvdRwuKItJS14mYznT2w2YQvn8QsQ/132","nickname":"方远","note":"","ucode":"248B1DE180EB4C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":574288,"discussion_content":"您好，已上传至github^^","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1653958979,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":341050,"user_name":"Geek_709f77","can_delete":false,"product_type":"c1","uid":2843530,"ip_address":"","ucode":"25F56EFCD3795F","user_header":"","comment_is_top":false,"comment_ctime":1649314317,"is_pvip":true,"replies":[{"id":"124686","content":"可以根据自己操作系统以及开发ide，参照Github上的下载方式再试试，正常来说Github上提供的应该没有问题～","user_name":"编辑回复","user_name_real":"编辑","uid":"1501385","ctime":1649331697,"ip_address":"","comment_id":341050,"utype":2}],"discussion_count":1,"race_medal":0,"score":"1649314317","product_id":100093301,"comment_content":"lebelme那个github上的zip包下载后怎么解压的时候报文件已损坏啊？","like_count":0,"discussions":[{"author":{"id":1501385,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e8/c9/59bcd490.jpg","nickname":"听水的湖","note":"","ucode":"B1759F90165D81","race_medal":0,"user_type":8,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":560445,"discussion_content":"可以根据自己操作系统以及开发ide，参照Github上的下载方式再试试，正常来说Github上提供的应该没有问题～","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1649331697,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":8}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":340299,"user_name":"Cougar","can_delete":false,"product_type":"c1","uid":2952163,"ip_address":"","ucode":"C8507485ADF278","user_header":"https://static001.geekbang.org/account/avatar/00/2d/0b/e3/4b9cac41.jpg","comment_is_top":false,"comment_ctime":1648731477,"is_pvip":false,"replies":[{"id":"124463","content":"你好，Cougar，感谢留言。<br>数据标准化的一种方式，减均值再除标准差也可以。","user_name":"作者回复","user_name_real":"编辑","uid":"2802608","ctime":1648792142,"ip_address":"","comment_id":340299,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1648731477","product_id":100093301,"comment_content":"self.image_slices.append(im &#47; 255.)<br>请问这里为什么要除以一个255呢","like_count":0,"discussions":[{"author":{"id":2802608,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK1ZkL9L7CEicI87xicpIhXAIhVdVWpJKBsD8Jpzg9iaAwFcDEhTvdRwuKItJS14mYznT2w2YQvn8QsQ/132","nickname":"方远","note":"","ucode":"248B1DE180EB4C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":559480,"discussion_content":"你好，Cougar，感谢留言。\n数据标准化的一种方式，减均值再除标准差也可以。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1648792142,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":330076,"user_name":"dndidoflbup","can_delete":false,"product_type":"c1","uid":1201908,"ip_address":"","ucode":"69B726F947065F","user_header":"https://static001.geekbang.org/account/avatar/00/12/56/f4/6c57f148.jpg","comment_is_top":false,"comment_ctime":1641788059,"is_pvip":false,"replies":[{"id":"120262","content":"hello，dndidoflbup，感谢你的留言。<br>因为经历了四次下采样。所以宽高必须是能被16整除的。","user_name":"作者回复","user_name_real":"编辑","uid":"2802608","ctime":1641802468,"ip_address":"","comment_id":330076,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1641788059","product_id":100093301,"comment_content":"老师好，对于输入图片的尺寸有要求么，我自己用900*900的学习，报错如下：<br><br>conv_decoder_3_2 = torch.cat((conv_decoder_3_1, conv_encoder_3_1), dim=1)<br>RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 224 but got size 225 for tensor number 1 in the list.","like_count":0,"discussions":[{"author":{"id":2802608,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK1ZkL9L7CEicI87xicpIhXAIhVdVWpJKBsD8Jpzg9iaAwFcDEhTvdRwuKItJS14mYznT2w2YQvn8QsQ/132","nickname":"方远","note":"","ucode":"248B1DE180EB4C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":545017,"discussion_content":"hello，dndidoflbup，感谢你的留言。\n因为经历了四次下采样。所以宽高必须是能被16整除的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1641802468,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":327008,"user_name":"Geek_a95f0e","can_delete":false,"product_type":"c1","uid":2824511,"ip_address":"","ucode":"C0B7418FD1D2B5","user_header":"","comment_is_top":false,"comment_ctime":1639833149,"is_pvip":false,"replies":[{"id":"118978","content":"你好，能把你的代码给我看看嘛？","user_name":"作者回复","user_name_real":"编辑","uid":"2802608","ctime":1639960941,"ip_address":"","comment_id":327008,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1639833149","product_id":100093301,"comment_content":"方老师，经过试验，本课自定义类的dataset，在实例化时，transform参数是不起作用的，请问这是什么原因呢？如果要让自定义类的dataset也能对transform参数起作用，该怎么操作呢？","like_count":0,"discussions":[{"author":{"id":2802608,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK1ZkL9L7CEicI87xicpIhXAIhVdVWpJKBsD8Jpzg9iaAwFcDEhTvdRwuKItJS14mYznT2w2YQvn8QsQ/132","nickname":"方远","note":"","ucode":"248B1DE180EB4C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":540091,"discussion_content":"你好，能把你的代码给我看看嘛？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1639960941,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2824511,"avatar":"","nickname":"Geek_a95f0e","note":"","ucode":"C0B7418FD1D2B5","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":540815,"discussion_content":"自定义类CatSegmentationDataset的代码和课程一致，测试代码如下：\n\nfrom torchvision import transforms\ndataset_ToTensor=CatSegmentationDataset(&#39;./data/train/duck_output&#39;,\n                              transform=transforms.ToTensor())\n\ntensor_iter=iter(dataset_ToTensor)\nfor item in next(dataset_iter):\n    print(&#39;the type of item from dataset is: %s&#39;%type(item[0]))\n#输出\nthe type of item from dataset is: &lt;class &#39;numpy.ndarray&#39;&gt;\nthe type of item from dataset is: &lt;class &#39;numpy.ndarray&#39;&gt;\n\n从以上看来，transforms.ToTensor()似乎没有起作用","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1640175976,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":326085,"user_name":"李雄","can_delete":false,"product_type":"c1","uid":2805175,"ip_address":"","ucode":"ABC36CFEEEE41B","user_header":"https://static001.geekbang.org/account/avatar/00/2a/cd/b7/6efa2c68.jpg","comment_is_top":false,"comment_ctime":1639370414,"is_pvip":false,"replies":[{"id":"118290","content":"hi，你好，李雄。<br>1）Unet收敛速度很快，不使用预训练模型效果也不错。我在我的真实项目中就没有使用预训练模型。<br>2）数据量肯定多多益善了。<br>3) 我用的是LabelImg（https:&#47;&#47;github.com&#47;tzutalin&#47;labelImg）标记目标检测的数据，不过labelme好像也可以，你可以研究研究^^。","user_name":"作者回复","user_name_real":"作者","uid":"2802608","ctime":1639381891,"ip_address":"","comment_id":326085,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1639370414","product_id":100093301,"comment_content":"老师您好，首先感谢老师的简洁讲述，但我仍有几个问题想请教：<br>（1）关于使用Unet能否使用预训练模型？或者说是否有预训练模型？<br>（2）Unet的训练数据量最少大致为多少呢？能否给个具体的参考？<br>（3）老师能否推荐一个目标检测数据标注工具呢？我最近要标注一个自己的目标检测数据集？<br>感谢老师！！！","like_count":0,"discussions":[{"author":{"id":2802608,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK1ZkL9L7CEicI87xicpIhXAIhVdVWpJKBsD8Jpzg9iaAwFcDEhTvdRwuKItJS14mYznT2w2YQvn8QsQ/132","nickname":"方远","note":"","ucode":"248B1DE180EB4C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":538249,"discussion_content":"hi，你好，李雄。\n1）Unet收敛速度很快，不使用预训练模型效果也不错。我在我的真实项目中就没有使用预训练模型。\n2）数据量肯定多多益善了。\n3) 我用的是LabelImg（https://github.com/tzutalin/labelImg）标记目标检测的数据，不过labelme好像也可以，你可以研究研究^^。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1639381891,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":323734,"user_name":"zhaobk","can_delete":false,"product_type":"c1","uid":1291596,"ip_address":"","ucode":"30BEE12D2CF020","user_header":"https://static001.geekbang.org/account/avatar/00/13/b5/4c/6b9528f8.jpg","comment_is_top":false,"comment_ctime":1638147218,"is_pvip":false,"replies":[{"id":"117508","content":"hello，你好。<br><br>你的疑问是为什么要单独写一个Block类吗？<br>不单独一写也可以，就是个人习惯。<br><br>如果疑问是为什么class UNet中是像文中那样堆叠卷积层的话。<br>那么回答是根据论文来搭建的。<br><br>如果需要实现其他算法，可以直接使用torchvision中封装好的模型，或者找找有没有已经实现好的开源代码，然后基于他们的代码做改进。<br>实际上，很少有项目是从0开始一点点写代码的。","user_name":"作者回复","user_name_real":"编辑","uid":"2802608","ctime":1638150386,"ip_address":"","comment_id":323734,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1638147218","product_id":100093301,"comment_content":"老师您好。关于class Block(nn.Module): class UNet(nn.Module):这两个类，我有点不明白，为什么要这么实现？是根据论文来搭建的吗？如果需要实现其他算法，也是要根据相关论文来自己搭建这种结构吗？","like_count":0,"discussions":[{"author":{"id":2802608,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK1ZkL9L7CEicI87xicpIhXAIhVdVWpJKBsD8Jpzg9iaAwFcDEhTvdRwuKItJS14mYznT2w2YQvn8QsQ/132","nickname":"方远","note":"","ucode":"248B1DE180EB4C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":534252,"discussion_content":"hello，你好。\n\n你的疑问是为什么要单独写一个Block类吗？\n不单独一写也可以，就是个人习惯。\n\n如果疑问是为什么class UNet中是像文中那样堆叠卷积层的话。\n那么回答是根据论文来搭建的。\n\n如果需要实现其他算法，可以直接使用torchvision中封装好的模型，或者找找有没有已经实现好的开源代码，然后基于他们的代码做改进。\n实际上，很少有项目是从0开始一点点写代码的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1638150386,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1291596,"avatar":"https://static001.geekbang.org/account/avatar/00/13/b5/4c/6b9528f8.jpg","nickname":"zhaobk","note":"","ucode":"30BEE12D2CF020","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":534266,"discussion_content":"谢谢老师。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1638152429,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":323435,"user_name":"官","can_delete":false,"product_type":"c1","uid":1696727,"ip_address":"","ucode":"E3FF6D04B9846B","user_header":"https://static001.geekbang.org/account/avatar/00/19/e3/d7/d7b3505f.jpg","comment_is_top":false,"comment_ctime":1637903159,"is_pvip":false,"replies":[{"id":"117365","content":"也可以，得改进一下。不过他和dice loss很像。","user_name":"作者回复","user_name_real":"编辑","uid":"2802608","ctime":1637929293,"ip_address":"","comment_id":323435,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1637903159","product_id":100093301,"comment_content":"感觉mIoU也可以用在语义分割模型里，不知道有没有这种可能","like_count":0,"discussions":[{"author":{"id":2802608,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK1ZkL9L7CEicI87xicpIhXAIhVdVWpJKBsD8Jpzg9iaAwFcDEhTvdRwuKItJS14mYznT2w2YQvn8QsQ/132","nickname":"方远","note":"","ucode":"248B1DE180EB4C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":533667,"discussion_content":"也可以，得改进一下。不过他和dice loss很像。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1637929293,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":323431,"user_name":"十里秋波不起雨","can_delete":false,"product_type":"c1","uid":1239581,"ip_address":"","ucode":"8440019270D50F","user_header":"https://static001.geekbang.org/account/avatar/00/12/ea/1d/1954451e.jpg","comment_is_top":false,"comment_ctime":1637901038,"is_pvip":false,"replies":[{"id":"117364","content":"谢谢认可，加油😊","user_name":"作者回复","user_name_real":"编辑","uid":"2802608","ctime":1637929203,"ip_address":"","comment_id":323431,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1637901038","product_id":100093301,"comment_content":"收获颇丰","like_count":0,"discussions":[{"author":{"id":2802608,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK1ZkL9L7CEicI87xicpIhXAIhVdVWpJKBsD8Jpzg9iaAwFcDEhTvdRwuKItJS14mYznT2w2YQvn8QsQ/132","nickname":"方远","note":"","ucode":"248B1DE180EB4C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":533666,"discussion_content":"谢谢认可，加油😊","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1637929203,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":323377,"user_name":"hbuelgr","can_delete":false,"product_type":"c1","uid":1723473,"ip_address":"","ucode":"D56AC31048AB49","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epJHlrZ1pcs2sxHpxW6EaDmUq8sMD85vm3hskWVn2LmlcUI84tARViam4vAuS0uVibpFq1uRAABff6g/132","comment_is_top":false,"comment_ctime":1637881804,"is_pvip":false,"replies":[{"id":"117363","content":"感谢认可^^，希望与你一起学习进步。","user_name":"作者回复","user_name_real":"编辑","uid":"2802608","ctime":1637929185,"ip_address":"","comment_id":323377,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1637881804","product_id":100093301,"comment_content":"收获很多，每天听听。","like_count":0,"discussions":[{"author":{"id":2802608,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK1ZkL9L7CEicI87xicpIhXAIhVdVWpJKBsD8Jpzg9iaAwFcDEhTvdRwuKItJS14mYznT2w2YQvn8QsQ/132","nickname":"方远","note":"","ucode":"248B1DE180EB4C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":533664,"discussion_content":"感谢认可^^，希望与你一起学习进步。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1637929185,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]}]}