{"id":106904,"title":"18 | Kafka中位移提交那些事儿","content":"<p>你好，我是胡夕。今天我们来聊聊Kafka中位移提交的那些事儿。</p><p>之前我们说过，Consumer端有个位移的概念，它和消息在分区中的位移不是一回事儿，虽然它们的英文都是Offset。今天我们要聊的位移是Consumer的消费位移，它记录了Consumer要消费的下一条消息的位移。这可能和你以前了解的有些出入，不过切记是下一条消息的位移，而不是目前最新消费消息的位移。</p><p>我来举个例子说明一下。假设一个分区中有10条消息，位移分别是0到9。某个Consumer应用已消费了5条消息，这就说明该Consumer消费了位移为0到4的5条消息，此时Consumer的位移是5，指向了下一条消息的位移。</p><p><strong>Consumer需要向Kafka汇报自己的位移数据，这个汇报过程被称为提交位移</strong>（Committing Offsets）。因为Consumer能够同时消费多个分区的数据，所以位移的提交实际上是在分区粒度上进行的，即<strong>Consumer需要为分配给它的每个分区提交各自的位移数据</strong>。</p><p>提交位移主要是为了表征Consumer的消费进度，这样当Consumer发生故障重启之后，就能够从Kafka中读取之前提交的位移值，然后从相应的位移处继续消费，从而避免整个消费过程重来一遍。换句话说，位移提交是Kafka提供给你的一个工具或语义保障，你负责维持这个语义保障，即如果你提交了位移X，那么Kafka会认为所有位移值小于X的消息你都已经成功消费了。</p><!-- [[[read_end]]] --><p>这一点特别关键。因为位移提交非常灵活，你完全可以提交任何位移值，但由此产生的后果你也要一并承担。假设你的Consumer消费了10条消息，你提交的位移值却是20，那么从理论上讲，位移介于11～19之间的消息是有可能丢失的；相反地，如果你提交的位移值是5，那么位移介于5～9之间的消息就有可能被重复消费。所以，我想再强调一下，<strong>位移提交的语义保障是由你来负责的，Kafka只会“无脑”地接受你提交的位移</strong>。你对位移提交的管理直接影响了你的Consumer所能提供的消息语义保障。</p><p>鉴于位移提交甚至是位移管理对Consumer端的巨大影响，Kafka，特别是KafkaConsumer API，提供了多种提交位移的方法。<strong>从用户的角度来说，位移提交分为自动提交和手动提交；从Consumer端的角度来说，位移提交分为同步提交和异步提交</strong>。</p><p>我们先来说说自动提交和手动提交。所谓自动提交，就是指Kafka Consumer在后台默默地为你提交位移，作为用户的你完全不必操心这些事；而手动提交，则是指你要自己提交位移，Kafka Consumer压根不管。</p><p>开启自动提交位移的方法很简单。Consumer端有个参数enable.auto.commit，把它设置为true或者压根不设置它就可以了。因为它的默认值就是true，即Java Consumer默认就是自动提交位移的。如果启用了自动提交，Consumer端还有个参数就派上用场了：auto.commit.interval.ms。它的默认值是5秒，表明Kafka每5秒会为你自动提交一次位移。</p><p>为了把这个问题说清楚，我给出了完整的Java代码。这段代码展示了设置自动提交位移的方法。有了这段代码做基础，今天后面的讲解我就不再展示完整的代码了。</p><pre><code>Properties props = new Properties();\n     props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);\n     props.put(&quot;group.id&quot;, &quot;test&quot;);\n     props.put(&quot;enable.auto.commit&quot;, &quot;true&quot;);\n     props.put(&quot;auto.commit.interval.ms&quot;, &quot;2000&quot;);\n     props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);\n     props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);\n     KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props);\n     consumer.subscribe(Arrays.asList(&quot;foo&quot;, &quot;bar&quot;));\n     while (true) {\n         ConsumerRecords&lt;String, String&gt; records = consumer.poll(100);\n         for (ConsumerRecord&lt;String, String&gt; record : records)\n             System.out.printf(&quot;offset = %d, key = %s, value = %s%n&quot;, record.offset(), record.key(), record.value());\n     }\n</code></pre><p>上面的第3、第4行代码，就是开启自动提交位移的方法。总体来说，还是很简单的吧。</p><p>和自动提交相反的，就是手动提交了。开启手动提交位移的方法就是设置enable.auto.commit为false。但是，仅仅设置它为false还不够，因为你只是告诉Kafka Consumer不要自动提交位移而已，你还需要调用相应的API手动提交位移。</p><p>最简单的API就是<strong>KafkaConsumer#commitSync()</strong>。该方法会提交KafkaConsumer#poll()返回的最新位移。从名字上来看，它是一个同步操作，即该方法会一直等待，直到位移被成功提交才会返回。如果提交过程中出现异常，该方法会将异常信息抛出。下面这段代码展示了commitSync()的使用方法：</p><pre><code>while (true) {\n            ConsumerRecords&lt;String, String&gt; records =\n                        consumer.poll(Duration.ofSeconds(1));\n            process(records); // 处理消息\n            try {\n                        consumer.commitSync();\n            } catch (CommitFailedException e) {\n                        handle(e); // 处理提交失败异常\n            }\n}\n</code></pre><p>可见，调用consumer.commitSync()方法的时机，是在你处理完了poll()方法返回的所有消息之后。如果你莽撞地过早提交了位移，就可能会出现消费数据丢失的情况。那么你可能会问，自动提交位移就不会出现消费数据丢失的情况了吗？它能恰到好处地把握时机进行位移提交吗？为了搞清楚这个问题，我们必须要深入地了解一下自动提交位移的顺序。</p><p>一旦设置了enable.auto.commit为true，Kafka会保证在开始调用poll方法时，提交上次poll返回的所有消息。从顺序上来说，poll方法的逻辑是先提交上一批消息的位移，再处理下一批消息，因此它能保证不出现消费丢失的情况。但自动提交位移的一个问题在于，<strong>它可能会出现重复消费</strong>。</p><p>在默认情况下，Consumer每5秒自动提交一次位移。现在，我们假设提交位移之后的3秒发生了Rebalance操作。在Rebalance之后，所有Consumer从上一次提交的位移处继续消费，但该位移已经是3秒前的位移数据了，故在Rebalance发生前3秒消费的所有数据都要重新再消费一次。虽然你能够通过减少auto.commit.interval.ms的值来提高提交频率，但这么做只能缩小重复消费的时间窗口，不可能完全消除它。这是自动提交机制的一个缺陷。</p><p>反观手动提交位移，它的好处就在于更加灵活，你完全能够把控位移提交的时机和频率。但是，它也有一个缺陷，就是在调用commitSync()时，Consumer程序会处于阻塞状态，直到远端的Broker返回提交结果，这个状态才会结束。在任何系统中，因为程序而非资源限制而导致的阻塞都可能是系统的瓶颈，会影响整个应用程序的TPS。当然，你可以选择拉长提交间隔，但这样做的后果是Consumer的提交频率下降，在下次Consumer重启回来后，会有更多的消息被重新消费。</p><p>鉴于这个问题，Kafka社区为手动提交位移提供了另一个API方法：<strong>KafkaConsumer#commitAsync()</strong>。从名字上来看它就不是同步的，而是一个异步操作。调用commitAsync()之后，它会立即返回，不会阻塞，因此不会影响Consumer应用的TPS。由于它是异步的，Kafka提供了回调函数（callback），供你实现提交之后的逻辑，比如记录日志或处理异常等。下面这段代码展示了调用commitAsync()的方法：</p><pre><code>while (true) {\n            ConsumerRecords&lt;String, String&gt; records = \n\tconsumer.poll(Duration.ofSeconds(1));\n            process(records); // 处理消息\n            consumer.commitAsync((offsets, exception) -&gt; {\n\tif (exception != null)\n\thandle(exception);\n\t});\n}\n</code></pre><p>commitAsync是否能够替代commitSync呢？答案是不能。commitAsync的问题在于，出现问题时它不会自动重试。因为它是异步操作，倘若提交失败后自动重试，那么它重试时提交的位移值可能早已经“过期”或不是最新值了。因此，异步提交的重试其实没有意义，所以commitAsync是不会重试的。</p><p>显然，如果是手动提交，我们需要将commitSync和commitAsync组合使用才能达到最理想的效果，原因有两个：</p><ol>\n<li>我们可以利用commitSync的自动重试来规避那些瞬时错误，比如网络的瞬时抖动，Broker端GC等。因为这些问题都是短暂的，自动重试通常都会成功，因此，我们不想自己重试，而是希望Kafka Consumer帮我们做这件事。</li>\n<li>我们不希望程序总处于阻塞状态，影响TPS。</li>\n</ol><p>我们来看一下下面这段代码，它展示的是如何将两个API方法结合使用进行手动提交。</p><pre><code>   try {\n           while(true) {\n                        ConsumerRecords&lt;String, String&gt; records = \n                                    consumer.poll(Duration.ofSeconds(1));\n                        process(records); // 处理消息\n                        commitAysnc(); // 使用异步提交规避阻塞\n            }\n} catch(Exception e) {\n            handle(e); // 处理异常\n} finally {\n            try {\n                        consumer.commitSync(); // 最后一次提交使用同步阻塞式提交\n\t} finally {\n\t     consumer.close();\n}\n}\n</code></pre><p>这段代码同时使用了commitSync()和commitAsync()。对于常规性、阶段性的手动提交，我们调用commitAsync()避免程序阻塞，而在Consumer要关闭前，我们调用commitSync()方法执行同步阻塞式的位移提交，以确保Consumer关闭前能够保存正确的位移数据。将两者结合后，我们既实现了异步无阻塞式的位移管理，也确保了Consumer位移的正确性，所以，如果你需要自行编写代码开发一套Kafka Consumer应用，那么我推荐你使用上面的代码范例来实现手动的位移提交。</p><p>我们说了自动提交和手动提交，也说了同步提交和异步提交，这些就是Kafka位移提交的全部了吗？其实，我们还差一部分。</p><p>实际上，Kafka Consumer API还提供了一组更为方便的方法，可以帮助你实现更精细化的位移管理功能。刚刚我们聊到的所有位移提交，都是提交poll方法返回的所有消息的位移，比如poll方法一次返回了500条消息，当你处理完这500条消息之后，前面我们提到的各种方法会一次性地将这500条消息的位移一并处理。简单来说，就是<strong>直接提交最新一条消息的位移</strong>。但如果我想更加细粒度化地提交位移，该怎么办呢？</p><p>设想这样一个场景：你的poll方法返回的不是500条消息，而是5000条。那么，你肯定不想把这5000条消息都处理完之后再提交位移，因为一旦中间出现差错，之前处理的全部都要重来一遍。这类似于我们数据库中的事务处理。很多时候，我们希望将一个大事务分割成若干个小事务分别提交，这能够有效减少错误恢复的时间。</p><p>在Kafka中也是相同的道理。对于一次要处理很多消息的Consumer而言，它会关心社区有没有方法允许它在消费的中间进行位移提交。比如前面这个5000条消息的例子，你可能希望每处理完100条消息就提交一次位移，这样能够避免大批量的消息重新消费。</p><p>庆幸的是，Kafka Consumer API为手动提交提供了这样的方法：commitSync(Map&lt;TopicPartition, OffsetAndMetadata&gt;)和commitAsync(Map&lt;TopicPartition, OffsetAndMetadata&gt;)。它们的参数是一个Map对象，键就是TopicPartition，即消费的分区，而值是一个OffsetAndMetadata对象，保存的主要是位移数据。</p><p>就拿刚刚提过的那个例子来说，如何每处理100条消息就提交一次位移呢？在这里，我以commitAsync为例，展示一段代码，实际上，commitSync的调用方法和它是一模一样的。</p><pre><code>private Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets = new HashMap&lt;&gt;();\nint count = 0;\n……\nwhile (true) {\n            ConsumerRecords&lt;String, String&gt; records = \n\tconsumer.poll(Duration.ofSeconds(1));\n            for (ConsumerRecord&lt;String, String&gt; record: records) {\n                        process(record);  // 处理消息\n                        offsets.put(new TopicPartition(record.topic(), record.partition()),\n                                   new OffsetAndMetadata(record.offset() + 1)；\n                       if（count % 100 == 0）\n                                    consumer.commitAsync(offsets, null); // 回调处理逻辑是null\n                        count++;\n\t}\n}\n</code></pre><p>简单解释一下这段代码。程序先是创建了一个Map对象，用于保存Consumer消费处理过程中要提交的分区位移，之后开始逐条处理消息，并构造要提交的位移值。还记得之前我说过要提交下一条消息的位移吗？这就是这里构造OffsetAndMetadata对象时，使用当前消息位移加1的原因。代码的最后部分是做位移的提交。我在这里设置了一个计数器，每累计100条消息就统一提交一次位移。与调用无参的commitAsync不同，这里调用了带Map对象参数的commitAsync进行细粒度的位移提交。这样，这段代码就能够实现每处理100条消息就提交一次位移，不用再受poll方法返回的消息总数的限制了。</p><h2>小结</h2><p>好了，我们来总结一下今天的内容。Kafka Consumer的位移提交，是实现Consumer端语义保障的重要手段。位移提交分为自动提交和手动提交，而手动提交又分为同步提交和异步提交。在实际使用过程中，推荐你使用手动提交机制，因为它更加可控，也更加灵活。另外，建议你同时采用同步提交和异步提交两种方式，这样既不影响TPS，又支持自动重试，改善Consumer应用的高可用性。总之，Kafka Consumer API提供了多种灵活的提交方法，方便你根据自己的业务场景定制你的提交策略。</p><p><img src=\"https://static001.geekbang.org/resource/image/a6/d1/a6e24c364321aaa44b8fedf3836bccd1.jpg?wh=2069*2569\" alt=\"\"></p><h2>开放讨论</h2><p>实际上，手动提交也不能避免消息重复消费。假设Consumer在处理完消息和提交位移前出现故障，下次重启后依然会出现消息重复消费的情况。请你思考一下，如何实现你的业务场景中的去重逻辑呢？</p><p>欢迎写下你的思考和答案，我们一起讨论。如果你觉得有所收获，也欢迎把文章分享给你的朋友。</p>","comments":[{"had_liked":false,"id":159559,"user_name":"水天一色","can_delete":false,"product_type":"c1","uid":1299931,"ip_address":"","ucode":"863643303BBB39","user_header":"https://static001.geekbang.org/account/avatar/00/13/d5/db/c45b90c8.jpg","comment_is_top":false,"comment_ctime":1575683617,"is_pvip":false,"replies":[{"id":"60990","content":"只要consumer没有重启，不会发生重复消费。因为在运行过程中consumer会记录已获取的消息位移","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1575719944,"ip_address":"","comment_id":159559,"utype":1}],"discussion_count":13,"race_medal":0,"score":"207734113825","product_id":100029201,"comment_content":"消费者提了异步 commit 实际还没更新完offset，消费者再不断地poll，其实会有重复消费的情况吧？","like_count":48,"discussions":[{"author":{"id":2577451,"avatar":"","nickname":"Geek_9c6c3e","note":"","ucode":"F3B71465B25BC6","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":371394,"discussion_content":"需要提交的位移应该主要是为了保证重启之后恢复消息进度，consumer本地内存会记录当前consumer消费位移，改位移对应此consumer此分区，保证了消费不重复也不丢失。","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1619753916,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1132315,"avatar":"https://static001.geekbang.org/account/avatar/00/11/47/1b/64262861.jpg","nickname":"胡小禾","note":"","ucode":"1C23B7492C0C9E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":262460,"discussion_content":"“ 只要consumer没有重启，不会发生重复消费。因为在运行过程中consumer会记录已获取的消息位移‘’\n\n这句话，老师的意思是：虽然不能保证先异步commit成功，然后开始从commit的地方poll，但是consumer 由于记录了之前获取的消息位移，所以下次poll时，实际是从还没commit 的offset 开始poll?","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1589101577,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":2,"child_discussions":[{"author":{"id":1336475,"avatar":"https://static001.geekbang.org/account/avatar/00/14/64/9b/0b578b08.jpg","nickname":"J.Smile","note":"","ucode":"C4D98DFDBF7584","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1132315,"avatar":"https://static001.geekbang.org/account/avatar/00/11/47/1b/64262861.jpg","nickname":"胡小禾","note":"","ucode":"1C23B7492C0C9E","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":284084,"discussion_content":"应该是这个意思吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1592442751,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":262460,"ip_address":""},"score":284084,"extra":""},{"author":{"id":1702857,"avatar":"https://static001.geekbang.org/account/avatar/00/19/fb/c9/28e33d91.jpg","nickname":"养生咖啡","note":"","ucode":"500DEDB969C9B4","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1132315,"avatar":"https://static001.geekbang.org/account/avatar/00/11/47/1b/64262861.jpg","nickname":"胡小禾","note":"","ucode":"1C23B7492C0C9E","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":292664,"discussion_content":"我的理解是有两个位移和一个临时唯一，一个是不断更新consumer端的位移A以及要提交给broker从位移A某个时间点拷贝的临时位移a。每次poll以位移A为准。最后一个位移B位于broker端，是consumer提交过来的临时位移a的备份，如果consumer重启会丢失位移A，a，此时需要去broker拉取备份的位移B","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1595300785,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":262460,"ip_address":""},"score":292664,"extra":""}]},{"author":{"id":3069067,"avatar":"","nickname":"Geek_bd79d4","note":"","ucode":"63C47892E8F7B1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":584459,"discussion_content":"Java doc回答了你这个疑问\n\nThis is an asynchronous call and will not block. Any errors encountered are either passed to the callback (if provided) or discarded.\nOffsets committed through multiple calls to this API are guaranteed to be sent in the same order as the invocations. Corresponding commit callbacks are also invoked in the same order. Additionally note that offsets committed through this API are guaranteed to complete before a subsequent call to commitSync() (and variants) returns.","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1660830434,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"上海"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1024294,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaELZPnUAiajaR5C25EDLWeJURggyiaOP5GGPe2qlwpQcm5e3ybib8OsP4tvddFDLVRSNNGL5I3SFPJHsA/132","nickname":"null","note":"","ucode":"F9039EFED6B55D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":540873,"discussion_content":"我们线上遇到了这个问题，消费者获取消息列表，包含消息1，2，3。\n消息1成功消费，消息2消费失败，这时不执行手动 commit offset(如果1，2，3都成功消费，会执行手动 commit offset)。\n下一次获取的消息为4，5，6。消息 1，2，3 不会再被获取到。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1640186468,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":477097,"discussion_content":"只要consumer没有重启，不会发生重复消费。因为在运行过程中consumer会记录已获取的消息位移","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1575719944,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1109389,"avatar":"https://static001.geekbang.org/account/avatar/00/10/ed/8d/377c106a.jpg","nickname":"KW💤","note":"","ucode":"290DD7016F4EE0","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":409284,"discussion_content":"每次poll前会把上次poll的最大位移同步commit","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1635409362,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":2912918,"avatar":"","nickname":"Geek_284c06","note":"","ucode":"4BD6D4449D4F1A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1109389,"avatar":"https://static001.geekbang.org/account/avatar/00/10/ed/8d/377c106a.jpg","nickname":"KW💤","note":"","ucode":"290DD7016F4EE0","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":577444,"discussion_content":"不一定吧   如果还未到间隔时间怎么提交","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1656120710,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":409284,"ip_address":""},"score":577444,"extra":""}]},{"author":{"id":2114744,"avatar":"https://static001.geekbang.org/account/avatar/00/20/44/b8/d5fe40fb.jpg","nickname":"Vndi","note":"","ucode":"23DA6A7BE63E9F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":379252,"discussion_content":"那如果是消费者组呢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1623771479,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1589328,"avatar":"","nickname":"Cjmedia","note":"","ucode":"E1EEA0194078A2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":292514,"discussion_content":"正是我想问的问题","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1595248932,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1065849,"avatar":"https://static001.geekbang.org/account/avatar/00/10/43/79/18073134.jpg","nickname":"test","note":"","ucode":"9A4973E591DD12","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":286608,"discussion_content":"一直困惑我的问题。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1593243866,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1636410,"avatar":"https://static001.geekbang.org/account/avatar/00/18/f8/3a/e0c14cb3.jpg","nickname":"lizhibo","note":"","ucode":"FDF4FA12C699B3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":275444,"discussion_content":"老师好，我想咨询下，如果我消费端代码出现异常，我怎么设置体检位移让他可以自动消费重试","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1590715978,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":113321,"user_name":"nightmare","can_delete":false,"product_type":"c1","uid":1056314,"ip_address":"","ucode":"EF2E51C2122A86","user_header":"https://static001.geekbang.org/account/avatar/00/10/1e/3a/5b21c01c.jpg","comment_is_top":false,"comment_ctime":1562951588,"is_pvip":false,"discussion_count":3,"race_medal":0,"score":"181951578020","product_id":100029201,"comment_content":"老师手动提交的设计很优美，先用异步提交不影响程序的性能，再用consumer关闭时同步提交来确保位移一定提交成功。这里我有个疑问，比如我程序运行期间有多次异步提交没有成功，比如101的offset和201的offset没有提交成功，程序关闭的时候501的offset提交成功了，是不是就代表前面500条我还是消费成功了，只要最新的位移提交成功，就代表之前的消息都提交成功了？第二点 就是批量提交哪里，如果一个消费者晓得多个分区的消息，封装在一个Map对象里面消费者也能正确的对多个分区的位移都保证正确的提交吗？","like_count":42,"discussions":[{"author":{"id":1400754,"avatar":"https://static001.geekbang.org/account/avatar/00/15/5f/b2/c4780c10.jpg","nickname":"曹伟雄","note":"","ucode":"9740E426C0742C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":1886,"discussion_content":"第1个问题，是你说的那样","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1563034260,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1336951,"avatar":"https://static001.geekbang.org/account/avatar/00/14/66/77/194ba21d.jpg","nickname":"lzh","note":"","ucode":"C3D83DF4230109","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":324627,"discussion_content":"第一个问题，文章开头应该跟你说的这种场景类似吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605145472,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1034204,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/c7/dc/9408c8c2.jpg","nickname":"ban","note":"","ucode":"E523CE97E48266","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":1889,"discussion_content":"第二个问题：offsets.put(new TopicPartition(record.topic(), record.partition())\nmap里面已经区别了topic和分区了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563037136,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":207098,"user_name":"Roy Liang","can_delete":false,"product_type":"c1","uid":1098898,"ip_address":"","ucode":"1DF5FC831A35DA","user_header":"https://static001.geekbang.org/account/avatar/00/10/c4/92/338b5609.jpg","comment_is_top":false,"comment_ctime":1587006256,"is_pvip":false,"replies":[{"id":"77468","content":"一直以来，在业务端实现去重或幂等都是避免消费的不二法则。单纯依赖Kafka避免重复消费很难做到~","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1587089644,"ip_address":"","comment_id":207098,"utype":1}],"discussion_count":3,"race_medal":0,"score":"164795763504","product_id":100029201,"comment_content":"要彻底避免消息重复消费，这样是否可行？在consumer端进行幂等操作。这样kafka就可以设置自动提交位移了","like_count":38,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492009,"discussion_content":"一直以来，在业务端实现去重或幂等都是避免消费的不二法则。单纯依赖Kafka避免重复消费很难做到~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587089644,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1054827,"avatar":"https://static001.geekbang.org/account/avatar/00/10/18/6b/a1448af1.jpg","nickname":"贝影","note":"","ucode":"19545C8DCBF8A2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":544177,"discussion_content":"确实","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1641435018,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2550743,"avatar":"https://static001.geekbang.org/account/avatar/00/26/eb/d7/90391376.jpg","nickname":"if...else...","note":"","ucode":"D0565908C99695","race_medal":4,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":386777,"discussion_content":"嗯，正解","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627794153,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":113489,"user_name":"ban","can_delete":false,"product_type":"c1","uid":1034204,"ip_address":"","ucode":"E523CE97E48266","user_header":"https://static001.geekbang.org/account/avatar/00/0f/c7/dc/9408c8c2.jpg","comment_is_top":false,"comment_ctime":1563030688,"is_pvip":false,"replies":[{"id":"41420","content":"不会的。consumer内部维护了一个指针，能够探测到下一条要消费的数据","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563156819,"ip_address":"","comment_id":113489,"utype":1}],"discussion_count":4,"race_medal":0,"score":"87462376608","product_id":100029201,"comment_content":"老师，你好。有个场景不太明白。我做个假设，比如说我的模式是自动提交，自动提交间隔是20秒一次，那我消费了10个消息，很快一秒内就结束。但是这时候我自动提交时间还没到（那是不是意味着不会提交offer），然后这时候我又去poll获取消息，会不会导致一直获取上一批的消息？<br><br>还是说如果consumer消费完了，自动提交时间还没到，如果你去poll，这时候会自动提交，就不会出现重复消费的情况。","like_count":20,"discussions":[{"author":{"id":1132315,"avatar":"https://static001.geekbang.org/account/avatar/00/11/47/1b/64262861.jpg","nickname":"胡小禾","note":"","ucode":"1C23B7492C0C9E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":262481,"discussion_content":"假如 自动提交，间隔20s；一次poll 10个消息，1s 结束，显然，自动提交的时刻未到；\n此时再 poll，实际上会从新的位置开始poll，而不是之前的位置。\n\n其实这里有个细节：\n我们常说，conusmer poll 是从commit 的位置开始的；但也未尽然。持续消费的时候，就会利用consumer 内部指针探测到下一次poll的位置，可能这个位置还没commit 呢。\n\n","likes_number":29,"is_delete":false,"is_hidden":false,"ctime":1589104608,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":2912918,"avatar":"","nickname":"Geek_284c06","note":"","ucode":"4BD6D4449D4F1A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1132315,"avatar":"https://static001.geekbang.org/account/avatar/00/11/47/1b/64262861.jpg","nickname":"胡小禾","note":"","ucode":"1C23B7492C0C9E","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":577388,"discussion_content":"所以他在还没提交位移的时候的拉取还是会把上次消费过的消息拉取下来。\n只不过会通过comsumer里面的指针，来防止重复消费，对吗","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1656061695,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":262481,"ip_address":""},"score":577388,"extra":""}]},{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":458246,"discussion_content":"不会的。consumer内部维护了一个指针，能够探测到下一条要消费的数据","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1563156819,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":2912918,"avatar":"","nickname":"Geek_284c06","note":"","ucode":"4BD6D4449D4F1A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":577452,"discussion_content":"它究竟会不会把已经消费的数据拉下来呢。\n我猜在没有committed位移的时候去poll应该是会拉取下来的吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1656122878,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":458246,"ip_address":""},"score":577452,"extra":""}]}]},{"had_liked":false,"id":206721,"user_name":"july","can_delete":false,"product_type":"c1","uid":1344289,"ip_address":"","ucode":"E081987929063A","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLEYbNElGIxY6Le1rfiakWJecz8JIOp06Y9JQFR2YBn3T3gx3icI5CKxZNgxgqiaKbfVOicXquO3QBw9w/132","comment_is_top":false,"comment_ctime":1586921315,"is_pvip":false,"replies":[{"id":"77328","content":"基本上是这样。","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1587003781,"ip_address":"","comment_id":206721,"utype":1}],"discussion_count":3,"race_medal":0,"score":"70306398051","product_id":100029201,"comment_content":"老师你好，这里是否可以理解为 自动提交逻辑是在poll方法中，如果间隔大于最小提交间隔，就会运行逻辑进行offset提交，如果小于最小间隔，则忽略offset提交逻辑？也就是说上次poll 的数据即便处理结束，没有调用下一次poll，那么offset也不会提交？","like_count":16,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491878,"discussion_content":"基本上是这样。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587003781,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1618235,"avatar":"https://static001.geekbang.org/account/avatar/00/18/b1/3b/f7453caa.jpg","nickname":"暗杠","note":"","ucode":"4BF154C17691AA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":360433,"discussion_content":"如果第二次没有pull ，即使超过间隔时间也不会自动提交吗","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616433205,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1346215,"avatar":"https://static001.geekbang.org/account/avatar/00/14/8a/a7/674c1864.jpg","nickname":"William","note":"","ucode":"55F5D9DEE485B1","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1618235,"avatar":"https://static001.geekbang.org/account/avatar/00/18/b1/3b/f7453caa.jpg","nickname":"暗杠","note":"","ucode":"4BF154C17691AA","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":544524,"discussion_content":"个人理解，若没有第二次pull，超过了间隔时间就会提交。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1641545999,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":360433,"ip_address":""},"score":544524,"extra":""}]}]},{"had_liked":false,"id":115655,"user_name":"无菇朋友","can_delete":false,"product_type":"c1","uid":1035562,"ip_address":"","ucode":"80482C5F0464A3","user_header":"https://static001.geekbang.org/account/avatar/00/0f/cd/2a/bdbed6ed.jpg","comment_is_top":false,"comment_ctime":1563685136,"is_pvip":false,"replies":[{"id":"42307","content":"嗯， 严格来说。提交频率指的是最小的提交间隔。比如设置5s，Kafka保证至少等待5s才会自动提交一次。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563752607,"ip_address":"","comment_id":115655,"utype":1}],"discussion_count":4,"race_medal":0,"score":"65988194576","product_id":100029201,"comment_content":"老师您好，有一个疑问，为什么poll之前的提交和按频率自动提交是一个时机，假如频率是5s提交一次，某两次poll之间的间隔是6s，这时候是怎么处理提交的？忘老师解答下，着实没想通这个地方","like_count":15,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":459210,"discussion_content":"嗯， 严格来说。提交频率指的是最小的提交间隔。比如设置5s，Kafka保证至少等待5s才会自动提交一次。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563752607,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1132315,"avatar":"https://static001.geekbang.org/account/avatar/00/11/47/1b/64262861.jpg","nickname":"胡小禾","note":"","ucode":"1C23B7492C0C9E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":262474,"discussion_content":"那假如： commit 频率是5 s ，poll 频率是 4s ,这种情况下， 实际 poll 也会变成 5s？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589103477,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":2,"child_discussions":[{"author":{"id":1257422,"avatar":"https://static001.geekbang.org/account/avatar/00/13/2f/ce/c72d4c67.jpg","nickname":"movesan","note":"","ucode":"29CDF0F2B604C8","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1132315,"avatar":"https://static001.geekbang.org/account/avatar/00/11/47/1b/64262861.jpg","nickname":"胡小禾","note":"","ucode":"1C23B7492C0C9E","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":296897,"discussion_content":"应该是poll的时候提交，commit的频率是最小提交间隔，假如poll的频率是2秒，实际上前两次poll 的时候应该不会提交，而是在第三次poll的时候也就是6秒的时候提交，个人理解","likes_number":10,"is_delete":false,"is_hidden":false,"ctime":1596699328,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":262474,"ip_address":""},"score":296897,"extra":""},{"author":{"id":2226367,"avatar":"https://static001.geekbang.org/account/avatar/00/21/f8/bf/59f2e600.jpg","nickname":"月明风清","note":"","ucode":"65A97CF2E320FA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1257422,"avatar":"https://static001.geekbang.org/account/avatar/00/13/2f/ce/c72d4c67.jpg","nickname":"movesan","note":"","ucode":"29CDF0F2B604C8","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":572896,"discussion_content":"如果你没有提交，两次 poll，不会读到重复的消息吗","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1653032727,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":296897,"ip_address":""},"score":572896,"extra":""}]}]},{"had_liked":false,"id":148016,"user_name":"注定非凡","can_delete":false,"product_type":"c1","uid":1113597,"ip_address":"","ucode":"80673056E131B7","user_header":"https://static001.geekbang.org/account/avatar/00/10/fd/fd/326be9bb.jpg","comment_is_top":false,"comment_ctime":1572929219,"is_pvip":true,"discussion_count":1,"race_medal":0,"score":"61702471363","product_id":100029201,"comment_content":"1 概念区分<br>\tA ：Consumer端的位移概念和消息分区的位移概念不是一回事。<br>\tB ：Consumer的消费位移，记录的是Consumer要消费的下一条消息的位移。<br><br>2 提交位移<br>\tA ：Consumer 要向Kafka汇报自己的位移数据，这个汇报过程被称为提交位移（Committing Offsets）。<br>\tB ：Consumer需要为分配给它的每个分区提交各自的位移数据。<br><br>3提交位移的作用<br>\tA ：提交位移主要是为了表征Consumer的消费进度，这样当Consumer发生故障重启后，能够从kafka中读取之前提交的位移值，从相应的位置继续消费，避免从头在消费一遍。<br><br>4 位移提交的特点<br>\tA ：位移提交的语义保障是由你来负责的，Kafka只会“无脑”地接受你提交的位移。位移提交错误，就会消息消费错误。<br><br>5 位移提交方式<br>\tA ：从用户的角度讲，位移提交分为自动提交和手动提交；从Consumer端的角度而言，位移提交分为同步提交和异步提交。<br><br>\tB ：自动提交：由Kafka consumer在后台默默的执行提交位移，用户不用管。开启简单，使用方便，但可能会出现重复消费。<br><br>\tC ：手动提交：好处在更加灵活，完全能够把控位移提交的时机和频率。<br>\t\t（1）同步提交：在调用commitSync()时，Consumer程序会处于阻塞状态，直到远端Broker返回提交结果，这个状态才会结束。对TPS影响显著<br>\t\t（2）异步提交：在调用commitAsync()时，会立即给响应，但是出问题了它不会自动重试。<br>\t\t（3）手动提交最好是同步和异步结合使用，正常用异步提交，如果异步提交失败，用同步提交方式补偿提交。<br>\t<br>\tD ：批次提交：对于一次要处理很多消费的Consumer而言，将一个大事务分割成若干个小事务分别提交。这可以有效减少错误恢复的时间，避免大批量的消息重新消费。<br>\t\t（1）使用commitSync（Map&lt;TopicPartition，Offset&gt;）和commitAsync(Map&lt;TopicPartition，OffsetAndMetadata&gt;)。<br>","like_count":14,"discussions":[{"author":{"id":2739957,"avatar":"","nickname":"Geek_39299b","note":"","ucode":"908C2FC4DECD33","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":389448,"discussion_content":"非凡哥 终于来了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1629279530,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":113356,"user_name":"lmtoo","can_delete":false,"product_type":"c1","uid":1133918,"ip_address":"","ucode":"FCD5B9C941D448","user_header":"https://static001.geekbang.org/account/avatar/00/11/4d/5e/c5c62933.jpg","comment_is_top":false,"comment_ctime":1562983838,"is_pvip":false,"replies":[{"id":"41422","content":"如果调用没有参数的commit，那么提交的是500","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563157078,"ip_address":"","comment_id":113356,"utype":1}],"discussion_count":11,"race_medal":0,"score":"53102591390","product_id":100029201,"comment_content":"对于手动同步和异步提交结合的场景，如果poll出来的消息是500条，而业务处理200条的时候，业务抛异常了，后续消息根本就没有被遍历过，finally里手动同步提交的是201还是000，还是501？","like_count":12,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":458184,"discussion_content":"如果调用没有参数的commit，那么提交的是500","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563157078,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1096652,"avatar":"https://static001.geekbang.org/account/avatar/00/10/bb/cc/fac12364.jpg","nickname":"xxx","note":"","ucode":"E79CEA70430449","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":584319,"discussion_content":"同有此问，所以老师那个例子不能这么玩，除非业务不要求精确","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1660744643,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"江苏"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1547667,"avatar":"https://static001.geekbang.org/account/avatar/00/17/9d/93/4159edaa.jpg","nickname":"朴素柠檬c","note":"","ucode":"2D4CBB70D801B1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":329418,"discussion_content":"手动提交，应该是等500条都消费在提交，下回 消费应该从0开始吧，因为你都没提交offset，为啥很多人说500？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606381404,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1529871,"avatar":"https://static001.geekbang.org/account/avatar/00/17/58/0f/c412b4a9.jpg","nickname":"Curry","note":"","ucode":"AABD3AA2EB2C95","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":258148,"discussion_content":"请问老师那这些没消费的数据岂不是丢失了？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588653463,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":2,"child_discussions":[{"author":{"id":1132315,"avatar":"https://static001.geekbang.org/account/avatar/00/11/47/1b/64262861.jpg","nickname":"胡小禾","note":"","ucode":"1C23B7492C0C9E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1529871,"avatar":"https://static001.geekbang.org/account/avatar/00/17/58/0f/c412b4a9.jpg","nickname":"Curry","note":"","ucode":"AABD3AA2EB2C95","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":262469,"discussion_content":"严格来说，这种情况下的防“丢失”不是kafka客户端要做的。\n而是由业务代码自己保证的。\n按照老师同步 、异步提交结合的范例代码，其实是要求业务上做好 process() 中的异常处理的。","likes_number":4,"is_delete":false,"is_hidden":false,"ctime":1589102514,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":258148,"ip_address":""},"score":262469,"extra":""},{"author":{"id":1132315,"avatar":"https://static001.geekbang.org/account/avatar/00/11/47/1b/64262861.jpg","nickname":"胡小禾","note":"","ucode":"1C23B7492C0C9E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1529871,"avatar":"https://static001.geekbang.org/account/avatar/00/17/58/0f/c412b4a9.jpg","nickname":"Curry","note":"","ucode":"AABD3AA2EB2C95","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":262471,"discussion_content":"简单粗暴理解：\n一次poll 成功 的 消息集合，在kafka看来，就是 “消费”成功了，即使在业务上看并非如此。\n","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1589102694,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":258148,"ip_address":""},"score":262471,"extra":""}]},{"author":{"id":1134861,"avatar":"https://static001.geekbang.org/account/avatar/00/11/51/0d/fc1652fe.jpg","nickname":"James","note":"","ucode":"48B0F2A334D1C1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":52299,"discussion_content":"马克","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1574037451,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1503593,"avatar":"https://static001.geekbang.org/account/avatar/00/16/f1/69/19a0a4ce.jpg","nickname":"Tears灬T","note":"","ucode":"2AD0EE638D3DDB","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":6640,"discussion_content":"500吧，0~499","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567006036,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1050508,"avatar":"https://static001.geekbang.org/account/avatar/00/10/07/8c/0d886dcc.jpg","nickname":"蚂蚁内推+v","note":"","ucode":"24B10AEE54B3FD","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1503593,"avatar":"https://static001.geekbang.org/account/avatar/00/16/f1/69/19a0a4ce.jpg","nickname":"Tears灬T","note":"","ucode":"2AD0EE638D3DDB","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":85516,"discussion_content":"那200-500的消息岂不是就未消费？","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1576551503,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":6640,"ip_address":""},"score":85516,"extra":""}]},{"author":{"id":1400754,"avatar":"https://static001.geekbang.org/account/avatar/00/15/5f/b2/c4780c10.jpg","nickname":"曹伟雄","note":"","ucode":"9740E426C0742C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":1887,"discussion_content":"是501","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563034389,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1134861,"avatar":"https://static001.geekbang.org/account/avatar/00/11/51/0d/fc1652fe.jpg","nickname":"James","note":"","ucode":"48B0F2A334D1C1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1400754,"avatar":"https://static001.geekbang.org/account/avatar/00/15/5f/b2/c4780c10.jpg","nickname":"曹伟雄","note":"","ucode":"9740E426C0742C","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":279133,"discussion_content":"0-499 500","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1591284987,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":1887,"ip_address":""},"score":279133,"extra":""}]}]},{"had_liked":false,"id":219191,"user_name":"我已经设置了昵称","can_delete":false,"product_type":"c1","uid":1364034,"ip_address":"","ucode":"ED672C5EBDBDC4","user_header":"https://static001.geekbang.org/account/avatar/00/14/d0/42/6fd01fb9.jpg","comment_is_top":false,"comment_ctime":1589964031,"is_pvip":false,"replies":[{"id":"80978","content":"这个参数其实有点误导。它其实的意思是至少5秒。可能多于5秒","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1589974335,"ip_address":"","comment_id":219191,"utype":1}],"discussion_count":1,"race_medal":0,"score":"35949702399","product_id":100029201,"comment_content":"auto.commit.interval.ms为5秒，且为自动提交<br>如果业务5秒内还没处理完，这个客户端怎么处理offset","like_count":8,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":495708,"discussion_content":"这个参数其实有点误导。它其实的意思是至少5秒。可能多于5秒","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589974335,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":136243,"user_name":"Algoric","can_delete":false,"product_type":"c1","uid":1298722,"ip_address":"","ucode":"78D9850A88C254","user_header":"https://static001.geekbang.org/account/avatar/00/13/d1/22/706c492e.jpg","comment_is_top":false,"comment_ctime":1569394766,"is_pvip":false,"replies":[{"id":"52218","content":"hmmm... 其实我一直觉得提交间隔这个参数的命名有些问题。它实际保证的是位移至少要隔一段时间才会提交，如果你是单线程处理消息，那么只有处理完消息后才会提交位移，可能远比你设置的间隔长。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1569409730,"ip_address":"","comment_id":136243,"utype":1}],"discussion_count":8,"race_medal":0,"score":"31634165838","product_id":100029201,"comment_content":"自动提交一定不会消息丢失吗，如果每次poll的数据过多，在提交时间内没有处理完，这时达到提交时间，那么Kafka还是重复提交上次poll的最大位移吗，还是讲本次poll的消息最大位移提交？","like_count":7,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":468523,"discussion_content":"hmmm... 其实我一直觉得提交间隔这个参数的命名有些问题。它实际保证的是位移至少要隔一段时间才会提交，如果你是单线程处理消息，那么只有处理完消息后才会提交位移，可能远比你设置的间隔长。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1569409730,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2213774,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLWlndLduM3SGiauJvia0oVdhH8FhbviaS9EsD0fM93PwEKg0Syk1I5strKbsZNoXE0klauTGAwW1DGQ/132","nickname":"陈新卫","note":"","ucode":"6EF232730D0FD7","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":333303,"discussion_content":"如果自动提交位移的逻辑在poll里面，那如果我这次拉取了10条消息，然后不再调用poll,那么这10条消息对应的位移还会提交吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1607498128,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":2,"child_discussions":[{"author":{"id":1618235,"avatar":"https://static001.geekbang.org/account/avatar/00/18/b1/3b/f7453caa.jpg","nickname":"暗杠","note":"","ucode":"4BF154C17691AA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2213774,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLWlndLduM3SGiauJvia0oVdhH8FhbviaS9EsD0fM93PwEKg0Syk1I5strKbsZNoXE0klauTGAwW1DGQ/132","nickname":"陈新卫","note":"","ucode":"6EF232730D0FD7","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":360434,"discussion_content":"如果你时间太长，会触发重平衡，会重新消费","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616433443,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":333303,"ip_address":""},"score":360434,"extra":""},{"author":{"id":1336951,"avatar":"https://static001.geekbang.org/account/avatar/00/14/66/77/194ba21d.jpg","nickname":"lzh","note":"","ucode":"C3D83DF4230109","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2213774,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLWlndLduM3SGiauJvia0oVdhH8FhbviaS9EsD0fM93PwEKg0Syk1I5strKbsZNoXE0klauTGAwW1DGQ/132","nickname":"陈新卫","note":"","ucode":"6EF232730D0FD7","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":379675,"discussion_content":"如果自动提交的时间到了，然后距上次提交也超过了auto.commit.interval.ms，那本次自动提交就会成功。而且应该不会不调用poll，这不相当于consumer不在干活？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1624069309,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":333303,"ip_address":""},"score":379675,"extra":""}]},{"author":{"id":1344289,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLEYbNElGIxY6Le1rfiakWJecz8JIOp06Y9JQFR2YBn3T3gx3icI5CKxZNgxgqiaKbfVOicXquO3QBw9w/132","nickname":"july","note":"","ucode":"E081987929063A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":233371,"discussion_content":"老师你好，这里是否可以理解为 自动提交逻辑是在poll方法中，如果间隔大于最小提交间隔，就会运行逻辑进行offset提交，如果小于最小间隔，则忽略offset提交逻辑？也就是说上次poll 的数据即便处理结束，没有调用下一次poll，那么offset也不会提交？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586921235,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1736462,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/7f/0e/e3a8dbd9.jpg","nickname":"Liujun","note":"","ucode":"3DB1F3CA57B5B3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1344289,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLEYbNElGIxY6Le1rfiakWJecz8JIOp06Y9JQFR2YBn3T3gx3icI5CKxZNgxgqiaKbfVOicXquO3QBw9w/132","nickname":"july","note":"","ucode":"E081987929063A","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":390146,"discussion_content":"是的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1629689986,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":233371,"ip_address":""},"score":390146,"extra":""}]},{"author":{"id":1398824,"avatar":"https://static001.geekbang.org/account/avatar/00/15/58/28/c86340ca.jpg","nickname":"达文西","note":"","ucode":"01C1063F23D634","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":53379,"discussion_content":"mark,  auto.commit.interval.ms 设置的是最小提交间隔","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1574162923,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1298722,"avatar":"https://static001.geekbang.org/account/avatar/00/13/d1/22/706c492e.jpg","nickname":"Algoric","note":"","ucode":"78D9850A88C254","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":21011,"discussion_content":"原来是这样，谢谢解答","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1569412361,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":113760,"user_name":"Liam","can_delete":false,"product_type":"c1","uid":1094597,"ip_address":"","ucode":"1D15D3B64F2606","user_header":"https://static001.geekbang.org/account/avatar/00/10/b3/c5/7fc124e2.jpg","comment_is_top":false,"comment_ctime":1563152385,"is_pvip":false,"replies":[{"id":"41414","content":"它们实际上是一个时机","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563156066,"ip_address":"","comment_id":113760,"utype":1}],"discussion_count":4,"race_medal":0,"score":"23037988865","product_id":100029201,"comment_content":"所以自动提交有2个时机吗？<br><br>1 固定频率提及，例如5s提及一次<br>2 poll新数据之前提交前面消费的数据","like_count":5,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":458372,"discussion_content":"它们实际上是一个时机","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563156066,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1473167,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/et0qH6zf5icoo6YJoH2WDyia7MTtdQiasicFecfMupzT5VD18aOjzoiaym1OP9RGUEUvLsPRUmCZVSTbrmydpNicVAPA/132","nickname":"GeekJohn","note":"","ucode":"C00462E2195C81","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":576593,"discussion_content":"auto.commit.interval.ms只是确定了提交位移的最小时间间隔，而提交位移的动作是隐藏在每一次的poll方法中的，这一次的poll会先提交上一次的位移，poll方法的时候，如果时间间隔大于auto.commit.interval.ms设置的时间间隔，就会进行位移提交，如果小于，则不会进行提交。当然，如果过了auto.commit.interval.ms的时间间隔，仍然没有下一次的poll方法，那么依然不会进行位移提交。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1655692590,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1001861,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/49/85/3f161d95.jpg","nickname":"Alpha","note":"","ucode":"60CA15A25EC796","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":310659,"discussion_content":"不太明白为什么是同一个时机？如果是poll时触发提交，那并不是固定频率吧？","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1601975439,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2213774,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLWlndLduM3SGiauJvia0oVdhH8FhbviaS9EsD0fM93PwEKg0Syk1I5strKbsZNoXE0klauTGAwW1DGQ/132","nickname":"陈新卫","note":"","ucode":"6EF232730D0FD7","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":333302,"discussion_content":"有明白的童鞋帮忙解释一下吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1607497559,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":113497,"user_name":"aof","can_delete":false,"product_type":"c1","uid":1062864,"ip_address":"","ucode":"5815D63C4926BC","user_header":"https://static001.geekbang.org/account/avatar/00/10/37/d0/26975fba.jpg","comment_is_top":false,"comment_ctime":1563033123,"is_pvip":false,"discussion_count":6,"race_medal":0,"score":"23037869603","product_id":100029201,"comment_content":"先说一下，课后思考，解决的办法应该就是，将消息处理和位移提交放在一个事务里面，要么都成功，要么都失败。<br><br>老师文章里面的举的一个例子没有很明白，能不能再解释一下。就是那个位移提交后Rebalance的例子。","like_count":5,"discussions":[{"author":{"id":1336009,"avatar":"https://static001.geekbang.org/account/avatar/00/14/62/c9/7da27891.jpg","nickname":"DKSky","note":"","ucode":"69371A81033949","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":268120,"discussion_content":"rebalance之前consumer记录了offset信息，不会重复消费。rebalance之后consumer重新分配了分区，导致记录的offset信息失效，需要从内部位移主题中获取offset，就会的导致重新消费","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1589727832,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1656848,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/fy2rpUzbSEeIAQHfbt0EkYkMIIuEPhWO6GFkjJNmLy5gbRp2UnNlrLh1fAAU52bQKfiahl17ZTOjhbYiatmrNibDg/132","nickname":"杨小曹","note":"","ucode":"D266D0A11BC573","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1336009,"avatar":"https://static001.geekbang.org/account/avatar/00/14/62/c9/7da27891.jpg","nickname":"DKSky","note":"","ucode":"69371A81033949","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":380558,"discussion_content":"那手工提交也有这个问题吧？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1624580950,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":268120,"ip_address":""},"score":380558,"extra":""}]},{"author":{"id":1521451,"avatar":"https://static001.geekbang.org/account/avatar/00/17/37/2b/b32f1d66.jpg","nickname":"Ball","note":"","ucode":"1EE949E68D84CA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":129165,"discussion_content":"这个想法挺好的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1578670946,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1712090,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/1f/da/698cd223.jpg","nickname":"banderSnatch🐱","note":"","ucode":"66C08C96E0D51A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":115771,"discussion_content":"重平衡后位移会回到上次提交的地方，不重平衡的话就算不提交位移也会往下走，不会重复消费。我试了一下是这样的，原理上就不知道了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1578034104,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1196886,"avatar":"https://static001.geekbang.org/account/avatar/00/12/43/56/62c38c36.jpg","nickname":"欧阳","note":"","ucode":"2612576E262813","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1712090,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/1f/da/698cd223.jpg","nickname":"banderSnatch🐱","note":"","ucode":"66C08C96E0D51A","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":229484,"discussion_content":"应该是consumer自己会记录已经消费(poll)的位移信息","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586656901,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":115771,"ip_address":""},"score":229484,"extra":""}]},{"author":{"id":1134861,"avatar":"https://static001.geekbang.org/account/avatar/00/11/51/0d/fc1652fe.jpg","nickname":"James","note":"","ucode":"48B0F2A334D1C1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":52300,"discussion_content":"我也是，可惜没回答。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1574037477,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":113377,"user_name":"Tony Du","can_delete":false,"product_type":"c1","uid":1001661,"ip_address":"","ucode":"F5FCC400E615EA","user_header":"https://static001.geekbang.org/account/avatar/00/0f/48/bd/6c7d4230.jpg","comment_is_top":false,"comment_ctime":1562988382,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"23037824862","product_id":100029201,"comment_content":"老师，您好～ 看了今天的教程我有两个问题想请教下，希望老师能赐教。<br>1. 从文中的代码看上去，使用commitAsync提供offset，不需要等待异步执行结果再次poll就能拿到下一批消息，是那么这个offset的最新值是不是理解为其实是在consumer client的内存中管理的（因为实际commitAsync如果失败的话，offset不会写入broker中）？如果是这样的话，如果在执行到commitSync之前，consumer client进程重启了，就有可能会消费到因commitAsync失败产生的重复消息。<br>2. 教程中手动提交100条消息的代码是一个同步处理的代码，我在实际工程中遇到的问题是，为了提高消息处理效率，coumser poll到一批消息后会提交到一个thread pool中处理，这种情况下，请教下怎样做到控制offset分批提交？<br>谢谢","like_count":5,"discussions":[{"author":{"id":1132315,"avatar":"https://static001.geekbang.org/account/avatar/00/11/47/1b/64262861.jpg","nickname":"胡小禾","note":"","ucode":"1C23B7492C0C9E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":262465,"discussion_content":"关于第2 点：\n\n原生客户端做不到。你的需求是使用更多的线程以提高效率，那可以多建分区，每个分区分配一个consumer，每个consumer同步消费，效果也是类似的","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1589102187,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":257200,"user_name":"Luke","can_delete":false,"product_type":"c1","uid":1590953,"ip_address":"","ucode":"2C8A1FAB8B6301","user_header":"https://static001.geekbang.org/account/avatar/00/18/46/a9/70fa676f.jpg","comment_is_top":false,"comment_ctime":1603878813,"is_pvip":false,"replies":[{"id":"93981","content":"同意。事实上，Kafka事务对producer端的重复生产消息解决很好，但对消费者端避免重复消费保证依然是弱的。","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1604283894,"ip_address":"","comment_id":257200,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18783747997","product_id":100029201,"comment_content":"我的理解，不管怎样做，单靠Kafka无法保证消息不被重复消费，无论时候自动提交还是手动提交，同步提交还是异步提交，消息的下游消费都要做去重和幂等处理。除非能够保证消息的消费和位点的提交是一个原子操作。而这个原子性太难保证了，基本上又要引入分布式一致性的那一套东西了。","like_count":4,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":508253,"discussion_content":"同意。事实上，Kafka事务对producer端的重复生产消息解决很好，但对消费者端避免重复消费保证依然是弱的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1604283894,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":178467,"user_name":"bbbi","can_delete":false,"product_type":"c1","uid":1682175,"ip_address":"","ucode":"9A539AEF791428","user_header":"https://static001.geekbang.org/account/avatar/00/19/aa/ff/e2c331e0.jpg","comment_is_top":false,"comment_ctime":1581694535,"is_pvip":false,"replies":[{"id":"69230","content":"offset是long型的，几乎不可能用完。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1581728689,"ip_address":"","comment_id":178467,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18761563719","product_id":100029201,"comment_content":"老师您好！有一个问题时。Kafka的offset是一个数字，那么这个数值最大时多少？有没有可能存在用完的情况？","like_count":4,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":483837,"discussion_content":"offset是long型的，几乎不可能用完。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1581728689,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":162592,"user_name":"猫哭","can_delete":false,"product_type":"c1","uid":1319617,"ip_address":"","ucode":"17358613AABE3D","user_header":"https://static001.geekbang.org/account/avatar/00/14/22/c1/3ba7deca.jpg","comment_is_top":false,"comment_ctime":1576561867,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"18756431051","product_id":100029201,"comment_content":"业务端来保证；业务端重复消费是否是幂等的？如果是幂等，对业务无影响，重复消费没关系；如果不是幂等，在生产者给kafka发送消息的时候，给每条消息生成一个唯一ID，消费端，视业务场景而言，分两种情况：1.如果是敏感业务，如与钱相关，在数据库建一张消费消息的流水表，每次消费前到数据库去查询一下，看是否消费过，消费过就忽略，没有消费过就消费。2.非敏感业务，可以存到redis，消费前去redis查询，该条消息是否消费过","like_count":4},{"had_liked":false,"id":114219,"user_name":"z.l","can_delete":false,"product_type":"c1","uid":1181055,"ip_address":"","ucode":"805CC5784D3F76","user_header":"https://static001.geekbang.org/account/avatar/00/12/05/7f/d35ab9a1.jpg","comment_is_top":false,"comment_ctime":1563254408,"is_pvip":false,"replies":[{"id":"41685","content":"是的。这取决于你对异常的处理态度。如果你觉得处理异常后还能继续消费，也可以将try-catch放入while内","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563274400,"ip_address":"","comment_id":114219,"utype":1}],"discussion_count":3,"race_medal":0,"score":"18743123592","product_id":100029201,"comment_content":"try {<br>        while (true) {<br>            ConsumerRecords&lt;String, String&gt; records = <br>                        consumer.poll(Duration.ofSeconds(1));<br>            process(records); &#47;&#47; 处理消息<br>            commitAysnc(); &#47;&#47; 使用异步提交规避阻塞<br>        }<br>     } catch (Exception e) {<br>        handle(e); &#47;&#47; 处理异常<br>    } finally {<br>        try {<br>            consumer.commitSync(); &#47;&#47; 最后一次提交使用同步阻塞式提交<br>        } finally {<br>            consumer.close();<br>        }<br>    }<br>这段代码如果异常了，不就退出while循环了么？也就相当于消费者线程异常退出？","like_count":4,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":458562,"discussion_content":"是的。这取决于你对异常的处理态度。如果你觉得处理异常后还能继续消费，也可以将try-catch放入while内","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563274400,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1253384,"avatar":"https://static001.geekbang.org/account/avatar/00/13/20/08/bc06bc69.jpg","nickname":"Dovelol","note":"","ucode":"9B5DDF7720F307","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":2103,"discussion_content":"当前这个消费者结束了，但是保证的是提交了正确的offset，这样在重启consumer或者其它consumer接管的时候不会重复消费。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563261322,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1547667,"avatar":"https://static001.geekbang.org/account/avatar/00/17/9d/93/4159edaa.jpg","nickname":"朴素柠檬c","note":"","ucode":"2D4CBB70D801B1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1253384,"avatar":"https://static001.geekbang.org/account/avatar/00/13/20/08/bc06bc69.jpg","nickname":"Dovelol","note":"","ucode":"9B5DDF7720F307","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":329420,"discussion_content":"那这必然导致消息丢失，所以 异常里面可以进行后续的补偿","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606381555,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":2103,"ip_address":""},"score":329420,"extra":""}]}]},{"had_liked":false,"id":113554,"user_name":"kursk.ye","can_delete":false,"product_type":"c1","uid":1015995,"ip_address":"","ucode":"9D6A3854E408F9","user_header":"https://static001.geekbang.org/account/avatar/00/0f/80/bb/c0ed9d76.jpg","comment_is_top":false,"comment_ctime":1563076011,"is_pvip":false,"replies":[{"id":"41416","content":"首先，poll(10)不是获取10条消息的意思。<br>其次，consumer获取的位移是它之前最新一次提交的位移，因此是99","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563156649,"ip_address":"","comment_id":113554,"utype":1}],"discussion_count":3,"race_medal":0,"score":"18742945195","product_id":100029201,"comment_content":"我现在有点糊涂了，kafka的offset是以broker发消息给consumer时，broker的offset为准；还是以consumer 的commit offset为准？比如，一个partition现在的offset是99，执行poll(10)方法时，broker给consumer发送了10条记录，在broker中offset变为109；假如 enable.auto.commit 为false，为手动提交consumer offset,但是cosumer在执行consumer.commitSync()或consumer.commitAsync()时进程失败，整个consumer进程都崩溃了；于是一个新的consumer接替原consumer继续消费，那么他是从99开始消费，还是从109开始消费？","like_count":4,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":458275,"discussion_content":"首先，poll(10)不是获取10条消息的意思。\n其次，consumer获取的位移是它之前最新一次提交的位移，因此是99","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563156649,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1547667,"avatar":"https://static001.geekbang.org/account/avatar/00/17/9d/93/4159edaa.jpg","nickname":"朴素柠檬c","note":"","ucode":"2D4CBB70D801B1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":329436,"discussion_content":"poll 里面的参数是超时时间","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1606383931,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1881786,"avatar":"https://static001.geekbang.org/account/avatar/00/1c/b6/ba/f76d996b.jpg","nickname":"机车","note":"","ucode":"CD32A645AE310A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":341038,"discussion_content":"broker里的offset是为了故障重启用的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1610269844,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":236184,"user_name":"J.Smile","can_delete":false,"product_type":"c1","uid":1336475,"ip_address":"","ucode":"C4D98DFDBF7584","user_header":"https://static001.geekbang.org/account/avatar/00/14/64/9b/0b578b08.jpg","comment_is_top":false,"comment_ctime":1595339404,"is_pvip":false,"replies":[{"id":"87311","content":"不要通过Kafka manager查，用kafka-consumer-groups命令查","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1595386696,"ip_address":"","comment_id":236184,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14480241292","product_id":100029201,"comment_content":"老师，我真的遇到了无论是自动提交或者是手动提交，没有报错，但是消费位移就是没有增长，心塞塞！！！求助🆘","like_count":3,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":501975,"discussion_content":"不要通过Kafka manager查，用kafka-consumer-groups命令查","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1595386696,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":201115,"user_name":"火力全开","can_delete":false,"product_type":"c1","uid":1412220,"ip_address":"","ucode":"8CE1733A2F618C","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEIaTvOKvUt4WnuSjkBp0tjd6O6vvVyw5fcib3UgZibE8tz2ICbTfkwbzs8MHNMJjV6W2mLjywLsvBibg/132","comment_is_top":false,"comment_ctime":1585718170,"is_pvip":false,"replies":[{"id":"75361","content":"可以的，使用Consumer的seekToEnd","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1585792194,"ip_address":"","comment_id":201115,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14470620058","product_id":100029201,"comment_content":"请问老师Kafka能配置成每次连接只消费最新的消息吗？","like_count":3,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":490243,"discussion_content":"可以的，使用Consumer的seekToEnd","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1585792194,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":144605,"user_name":"不忘初心丶方得始终","can_delete":false,"product_type":"c1","uid":1176917,"ip_address":"","ucode":"2D16DBA695D347","user_header":"https://static001.geekbang.org/account/avatar/00/11/f5/55/5ba20e79.jpg","comment_is_top":false,"comment_ctime":1571978321,"is_pvip":false,"replies":[{"id":"55957","content":"如果是批任务，能否等到数据抽取完了再进行消费。如果是streaming任务，这是经典的table-table join，最好使用特定的流处理框架来处理","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1572225077,"ip_address":"","comment_id":144605,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14456880209","product_id":100029201,"comment_content":"老师你好，问个问题，目前公司要用kafka同步老数据库数据，同步过程是按照老数据库的bin.log日志顺序进行同步，但是在同步过程中，有些表是有关联的，加入将数据放到多个分区，不同分区数据消费顺序不一样，就会导致数据同步出现关联问题，如果设置一个分区……这样又太慢，有什么好的建议吗？","like_count":3,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":472027,"discussion_content":"如果是批任务，能否等到数据抽取完了再进行消费。如果是streaming任务，这是经典的table-table join，最好使用特定的流处理框架来处理","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1572225077,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":119955,"user_name":"Li Shunduo","can_delete":false,"product_type":"c1","uid":1222882,"ip_address":"","ucode":"6C5AB4129E9780","user_header":"https://static001.geekbang.org/account/avatar/00/12/a8/e2/f8e51df2.jpg","comment_is_top":false,"comment_ctime":1564737181,"is_pvip":false,"replies":[{"id":"44266","content":"将offset提交与事件处理结果放入一个支持原子性操作的存储可以避免，类似于事务。另外Kafka Streams支持精确一次处理语义，也可以一试","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1564966668,"ip_address":"","comment_id":119955,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14449639069","product_id":100029201,"comment_content":"从文章看，无论是自动提交还是手动提交，都是有可能存在消息重复消费的。请问有没有办法通过offset管理避免重复消费呢？还是要借助外部的工具做消费前的检查。","like_count":3,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":461148,"discussion_content":"将offset提交与事件处理结果放入一个支持原子性操作的存储可以避免，类似于事务。另外Kafka Streams支持精确一次处理语义，也可以一试","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1564966668,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":113337,"user_name":"WL","can_delete":false,"product_type":"c1","uid":1173771,"ip_address":"","ucode":"6277DCD776B87E","user_header":"https://static001.geekbang.org/account/avatar/00/11/e9/0b/1171ac71.jpg","comment_is_top":false,"comment_ctime":1562978200,"is_pvip":false,"replies":[{"id":"41425","content":"嗯嗯，我的意思是consumer提交的位移值虽然就是消息在分区中的位移值，但这个提交位移的概念和分区中的位移概念是不同的。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563157357,"ip_address":"","comment_id":113337,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14447880088","product_id":100029201,"comment_content":"我感觉有点不是很理解消费者端的位移概念和消息在分区中的位移为啥不是一回事，我理像是一回事，因为消费者端把自己消费的位移提交到Broker的位移主题里不就定义了下次消费的起点了吗，为啥说不是一回事呢，有啥区别呢，请老师具体指导一下。","like_count":3,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":458175,"discussion_content":"嗯嗯，我的意思是consumer提交的位移值虽然就是消息在分区中的位移值，但这个提交位移的概念和分区中的位移概念是不同的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563157357,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":315792,"user_name":"xzy","can_delete":false,"product_type":"c1","uid":1002095,"ip_address":"","ucode":"1A44368083A19E","user_header":"https://static001.geekbang.org/account/avatar/00/0f/4a/6f/e36b3908.jpg","comment_is_top":false,"comment_ctime":1634002700,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"10223937292","product_id":100029201,"comment_content":"<br>   try {<br>           while(true) {<br>                        ConsumerRecords&lt;String, String&gt; records = <br>                                    consumer.poll(Duration.ofSeconds(1));<br>                        process(records); &#47;&#47; 处理消息<br>                        commitAysnc(); &#47;&#47; 使用异步提交规避阻塞<br>            }<br>} catch(Exception e) {<br>            handle(e); &#47;&#47; 处理异常<br>} finally {<br>            try {<br>                        consumer.commitSync(); &#47;&#47; 最后一次提交使用同步阻塞式提交<br>  } finally {<br>       consumer.close();<br>}<br>}<br><br>感觉这段代码有很严重的bug，如果在处理第一条消息时发生了异常，那么这次poll()的消息会全部丢失","like_count":2,"discussions":[{"author":{"id":2113978,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLLniccwC1Mootc7IQsRGUTX3ZkkCKPc7lYV0g8CAqscWtAjd8xkHYcY3UFbYvicm42FXuAO5bZP6WQ/132","nickname":"Geek_417e74","note":"","ucode":"BEA8915879274D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":558625,"discussion_content":"这里sync提交的语义是consumer关闭时，只是伪代码。你poll的消息自然要保证把它处理完","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1648407047,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":294354,"user_name":"张三丰","can_delete":false,"product_type":"c1","uid":1155275,"ip_address":"","ucode":"3A6215A40B3B21","user_header":"https://static001.geekbang.org/account/avatar/00/11/a0/cb/aab3b3e7.jpg","comment_is_top":false,"comment_ctime":1621911415,"is_pvip":false,"replies":[{"id":"107173","content":"Kafka没有这个所谓的功能。。。","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1622353715,"ip_address":"","comment_id":294354,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10211846007","product_id":100029201,"comment_content":"老师，我有一个疑问，<br>由于位移提交是有序的，比如前5次的异步提交，其中第3次提交时候发生网络抖动，这个时候第3次的异步提交开始同步重试，但是第4次和第5次的已经异步提交成功，这个时候这个”同步重试“应该被忽略，否则位移数据将被覆盖了吧。","like_count":2,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":520618,"discussion_content":"Kafka没有这个所谓的功能。。。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1622353715,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":258530,"user_name":"张三丰","can_delete":false,"product_type":"c1","uid":1155275,"ip_address":"","ucode":"3A6215A40B3B21","user_header":"https://static001.geekbang.org/account/avatar/00/11/a0/cb/aab3b3e7.jpg","comment_is_top":false,"comment_ctime":1604475849,"is_pvip":false,"replies":[{"id":"94414","content":"1. 重试时挂起消费线程，直到retry成功，同时也不会更新位移。<br>2. 可能出现。rebalance可能会影响消息提交。不论是自动还是手动。","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1604887575,"ip_address":"","comment_id":258530,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10194410441","product_id":100029201,"comment_content":"老师有两个地方搞不明白<br>1.spring boot kafkaTemplate提供重试功能，也就是同步和异步都支持重试，它怎么做到避免位移过期问题的？<br>2.手动提交不会出现重复消费的情况吗？重平衡不会影响手动提交吗？","like_count":2,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":508682,"discussion_content":"1. 重试时挂起消费线程，直到retry成功，同时也不会更新位移。\n2. 可能出现。rebalance可能会影响消息提交。不论是自动还是手动。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1604887575,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":130026,"user_name":"盘尼西林","can_delete":false,"product_type":"c1","uid":1197347,"ip_address":"","ucode":"B59569FC25144F","user_header":"https://static001.geekbang.org/account/avatar/00/12/45/23/28311447.jpg","comment_is_top":false,"comment_ctime":1567353366,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10157287958","product_id":100029201,"comment_content":"发生重平衡之前可以添加一个ConsumerRebalanceListener，防止offset丢失。 在一个消费者对一个分区失去所有权之前 会调用这个ConsumerRebalanceListener，ConsumerRebalanceListener在调用subscribe()方法传进去，这个时候我们可以在这个listener中添加commit offset","like_count":2},{"had_liked":false,"id":115877,"user_name":"李坤","can_delete":false,"product_type":"c1","uid":1134503,"ip_address":"","ucode":"288994A8EAA913","user_header":"https://static001.geekbang.org/account/avatar/00/11/4f/a7/f7124e0f.jpg","comment_is_top":false,"comment_ctime":1563760963,"is_pvip":false,"replies":[{"id":"42574","content":"consumer一直在消费时就可以出现","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563849551,"ip_address":"","comment_id":115877,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10153695555","product_id":100029201,"comment_content":"老师您好，异步提交重试时提交的位移值可能早已经“过期”或不是最新值了。什么情况下会出现呢？","like_count":2,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":459327,"discussion_content":"consumer一直在消费时就可以出现","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563849551,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":113984,"user_name":"我已经设置了昵称","can_delete":false,"product_type":"c1","uid":1364034,"ip_address":"","ucode":"ED672C5EBDBDC4","user_header":"https://static001.geekbang.org/account/avatar/00/14/d0/42/6fd01fb9.jpg","comment_is_top":false,"comment_ctime":1563198411,"is_pvip":false,"replies":[{"id":"41583","content":"自动提交就是在poll方法调用过程中执行的，如果设置了5秒，表示至少5秒提交一次","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563237614,"ip_address":"","comment_id":113984,"utype":1}],"discussion_count":3,"race_medal":0,"score":"10153133003","product_id":100029201,"comment_content":"看下来感觉自动提交有两个提交方法，1.\b默认5秒一次，2.每次调用poll方法的时候。是这样吗？","like_count":2,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":458467,"discussion_content":"自动提交就是在poll方法调用过程中执行的，如果设置了5秒，表示至少5秒提交一次","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563237614,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1736462,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/7f/0e/e3a8dbd9.jpg","nickname":"Liujun","note":"","ucode":"3DB1F3CA57B5B3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":390148,"discussion_content":"执行 poll() 方法的时候，会检查距离上一次自动提交的间隔是否超过 5 秒，超过了就会提交，没有就不会提交，你的举例中，业务处理 6 秒，那下一次 poll() 的时候就会触发上一批消息的位移提交。如果你的业务处理 花费 3 秒，那么这一次 poll() 不会提交位移，需要等待到下一次，下一次的 poll() 就会提交两批的数据。","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1629690697,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1636683,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJkTktMhVRbkn7U3mvnHUBBKkbzf17l98iaYZ35MQibvZPeZfXDV1licucYOI1Z70hk51X7TB9K8erpg/132","nickname":"刘鑫","note":"","ucode":"E818077E19CD98","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":38615,"discussion_content":"如果是5秒，业务处理耗时6秒，怎么保证至少5秒提交的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1571809812,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":280400,"user_name":"estimator","can_delete":false,"product_type":"c1","uid":1491721,"ip_address":"","ucode":"99A8643B11E7A8","user_header":"https://static001.geekbang.org/account/avatar/00/16/c3/09/027f2f17.jpg","comment_is_top":false,"comment_ctime":1614178306,"is_pvip":false,"replies":[{"id":"101803","content":"不会，只是重复消费","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1614217245,"ip_address":"","comment_id":280400,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5909145602","product_id":100029201,"comment_content":"老师您好，如果异步提交位移成功了，但是由于网络抖动返回失败了。那么同步提交又会提交一次，这时就会丢消息吧。","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":516084,"discussion_content":"不会，只是重复消费","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1614217245,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":275291,"user_name":"归零","can_delete":false,"product_type":"c1","uid":1103208,"ip_address":"","ucode":"C99B8E93009A46","user_header":"https://static001.geekbang.org/account/avatar/00/10/d5/68/2201b6b9.jpg","comment_is_top":false,"comment_ctime":1611451834,"is_pvip":true,"replies":[{"id":"99930","content":"consumer首先会从broker处获取拉取位移的位置，之后就是自己维护这个位置不断更新","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1611539058,"ip_address":"","comment_id":275291,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5906419130","product_id":100029201,"comment_content":"consumer去拉消息的时候怎么知道位移的数据？是broker记录这个数据，还是本地存储的(同时异常重启后从broker获取)","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":514296,"discussion_content":"consumer首先会从broker处获取拉取位移的位置，之后就是自己维护这个位置不断更新","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1611539058,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1736462,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/7f/0e/e3a8dbd9.jpg","nickname":"Liujun","note":"","ucode":"3DB1F3CA57B5B3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":390152,"discussion_content":"consumer 本地缓存一份维护分区消费位置，并维护和更新，consumer  以本地维护的为主，没有再到 __consumer_offset 主题找","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1629690965,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":271780,"user_name":"张三丰","can_delete":false,"product_type":"c1","uid":1155275,"ip_address":"","ucode":"3A6215A40B3B21","user_header":"https://static001.geekbang.org/account/avatar/00/11/a0/cb/aab3b3e7.jpg","comment_is_top":false,"comment_ctime":1609807650,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5904774946","product_id":100029201,"comment_content":"老师，以下这个不算缺点吧，因为自动提交也是同步阻塞的。不能算两者比较后的缺点。<br><br><br>反观手动提交位移，它的好处就在于更加灵活，你完全能够把控位移提交的时机和频率。但是，它也有一个缺陷，就是在调用 commitSync() 时，Consumer 程序会处于阻塞状态，直到远端的 Broker 返回提交结果，这个状态才会结束。","like_count":1},{"had_liked":false,"id":224144,"user_name":"James","can_delete":false,"product_type":"c1","uid":1134861,"ip_address":"","ucode":"48B0F2A334D1C1","user_header":"https://static001.geekbang.org/account/avatar/00/11/51/0d/fc1652fe.jpg","comment_is_top":false,"comment_ctime":1591284542,"is_pvip":false,"replies":[{"id":"82549","content":"嗯，确实要看具体的场景来决定恰当的方案","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1591323759,"ip_address":"","comment_id":224144,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5886251838","product_id":100029201,"comment_content":"如果数据是实时且非必须处理,比如的士实时坐标数据,可以判断时间是否实时来过滤,即使重复消费也不会再次消费这条数据,因为过期了..<br>如果是必须处理的数据只能通过查询数据处理来判断是否重复消费了.","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":497374,"discussion_content":"嗯，确实要看具体的场景来决定恰当的方案","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1591323759,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":214959,"user_name":"thomas","can_delete":false,"product_type":"c1","uid":1016777,"ip_address":"","ucode":"9AB945308F1B50","user_header":"https://static001.geekbang.org/account/avatar/00/0f/83/c9/5d03981a.jpg","comment_is_top":false,"comment_ctime":1588857602,"is_pvip":true,"replies":[{"id":"79680","content":"是可能重复消费的，毕竟消费和位移提交不是原子性操作。这和是否是一个group id关系不大。<br>“位移其实是消费者在控制，customer_offset主题只是为了保持消费者位移的持久性” —— 我基本同意。","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1588983521,"ip_address":"","comment_id":214959,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5883824898","product_id":100029201,"comment_content":"老师，若是多台机器，即使配置相同的groupID，是不是也会重复消费？位移其实是消费者在控制，customer_offset主题只是为了保持消费者位移的持久性","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":494258,"discussion_content":"是可能重复消费的，毕竟消费和位移提交不是原子性操作。这和是否是一个group id关系不大。\n“位移其实是消费者在控制，customer_offset主题只是为了保持消费者位移的持久性” —— 我基本同意。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588983521,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":149289,"user_name":"惜昔","can_delete":false,"product_type":"c1","uid":1441589,"ip_address":"","ucode":"B3478E40B612FC","user_header":"https://static001.geekbang.org/account/avatar/00/15/ff/35/b744c027.jpg","comment_is_top":false,"comment_ctime":1573183776,"is_pvip":false,"replies":[{"id":"57424","content":"有可能的~","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1573212022,"ip_address":"","comment_id":149289,"utype":1}],"discussion_count":6,"race_medal":0,"score":"5868151072","product_id":100029201,"comment_content":"老师 手动提交位移的时候 如果一个某个消费者组的一个消费者实例从offset下标4开始消费的 但是消费者的消费逻辑比较重量级，处理的时间比较长，还没有提交。这时候另外一个消费者组的一个消费者实例来相同的分区来拿消息，会不会拿的是上一个消费者已经拿过的消费，从而重复消费？","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":473808,"discussion_content":"有可能的~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1573212022,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1398824,"avatar":"https://static001.geekbang.org/account/avatar/00/15/58/28/c86340ca.jpg","nickname":"达文西","note":"","ucode":"01C1063F23D634","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":53376,"discussion_content":"同一个topic下的某个分区不是只会被分配给唯一的一个消费者吗?这种情况怎么会重复消费呢?","likes_number":5,"is_delete":false,"is_hidden":false,"ctime":1574162789,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1240624,"avatar":"https://static001.geekbang.org/account/avatar/00/12/ee/30/cfdd1b86.jpg","nickname":"刘浩","note":"","ucode":"81F5D6E62751C6","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":200994,"discussion_content":"你这是订阅模型，怎么可以叫重复消费呢","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1583750398,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1112415,"avatar":"https://static001.geekbang.org/account/avatar/00/10/f9/5f/b0a125a9.jpg","nickname":"chp","note":"","ucode":"F0A2442230CD45","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":146315,"discussion_content":"n你都说了是另一个消费者组了，两个消费者组的消费进度没有关系","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1579608115,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1736462,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/7f/0e/e3a8dbd9.jpg","nickname":"Liujun","note":"","ucode":"3DB1F3CA57B5B3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":390153,"discussion_content":"你能问这样的问题，说明你已经不具备往下看的条件了，老师也是在搞笑，回去看基础部分吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1629691105,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1606581,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJIIibocUHNRgafeNUvibW0YI2v1qDaiaZCVQ37FcrMs0ettIDD0snhsy4Ac2ADnLmjM7KGNeznj2hrg/132","nickname":"一十六夜","note":"","ucode":"41D4A6695B2A7B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":214591,"discussion_content":"同一个分区可以被多个消费者组消费么？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1585212103,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":135623,"user_name":"jc9090kkk","can_delete":false,"product_type":"c1","uid":1338831,"ip_address":"","ucode":"6C992D07A2E78F","user_header":"https://static001.geekbang.org/account/avatar/00/14/6d/cf/ec335526.jpg","comment_is_top":false,"comment_ctime":1569230456,"is_pvip":false,"replies":[{"id":"51994","content":"如果没有达到提交时间就不会提交，自动提交完全由consumer自行维护，确实可能造成数据的重复消费。你的理解完全没有问题：）<br><br>目前单纯依赖consumer是无法避免消息的重复消费的，Kafka默认提供的消息处理语义就是至少一次处理。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1569230859,"ip_address":"","comment_id":135623,"utype":1}],"discussion_count":4,"race_medal":0,"score":"5864197752","product_id":100029201,"comment_content":"感觉老师分享，对于文章中的那个自动提交的例子有点疑惑，希望老师能解答一下：<br>auto.commit.interval.ms设置为5s，也就是说consumer每5秒才提交一次位移信息，那consumer如果每消费一条数据，但是没有达到自动提交的时间，这个位移信息该如何管理？consumer自己做维护吗？但是也需要跟broker端进行位移信息同步的吧？ 不然可能会造成数据的重复消费？还是每5s的提交和consumer自动提交的时候都会伴随位移信息的同步？是我的理解有问题吗？","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":468276,"discussion_content":"如果没有达到提交时间就不会提交，自动提交完全由consumer自行维护，确实可能造成数据的重复消费。你的理解完全没有问题：）\n\n目前单纯依赖consumer是无法避免消息的重复消费的，Kafka默认提供的消息处理语义就是至少一次处理。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1569230859,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1031756,"avatar":"","nickname":"小小","note":"","ucode":"AF1F011FDDE29B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":282623,"discussion_content":"感觉老师都回答前后矛盾了，“consumer内部维护了一个指针” 上面有个问题，他是这样回答的。。我现在真晕了，谁能解惑下","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1592032366,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1336951,"avatar":"https://static001.geekbang.org/account/avatar/00/14/66/77/194ba21d.jpg","nickname":"lzh","note":"","ucode":"C3D83DF4230109","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1031756,"avatar":"","nickname":"小小","note":"","ucode":"AF1F011FDDE29B","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":379677,"discussion_content":"就是consumer自己也记录一个offset啊，每次拉取都按自己的offset拉啊，自己挂了重启才从offset_topic里拿offset啊，consumer自己维护一个offset就是避免异步保存offset不及时之类的问题啊","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1624069894,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":282623,"ip_address":""},"score":379677,"extra":""}]},{"author":{"id":1172145,"avatar":"https://static001.geekbang.org/account/avatar/00/11/e2/b1/d00399c0.jpg","nickname":"心有林夕","note":"","ucode":"BC6E1AE557BFF4","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":43137,"discussion_content":"不太理解，不是说pull之前会保证提交上次pull的位移么？这两个概念不是冲突么？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1572859720,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":132458,"user_name":"谢特","can_delete":false,"product_type":"c1","uid":1248684,"ip_address":"","ucode":"9C30DBFECFE649","user_header":"https://static001.geekbang.org/account/avatar/00/13/0d/ac/09678490.jpg","comment_is_top":false,"comment_ctime":1568126559,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5863093855","product_id":100029201,"comment_content":"不漏不重复很难做到，我现在都不知道怎么弄，读偏移量容易，提交太难","like_count":1},{"had_liked":false,"id":114315,"user_name":"calljson","can_delete":false,"product_type":"c1","uid":1505262,"ip_address":"","ucode":"A5F81A6A5B4497","user_header":"https://static001.geekbang.org/account/avatar/00/16/f7/ee/6eeb58a3.jpg","comment_is_top":false,"comment_ctime":1563270506,"is_pvip":false,"replies":[{"id":"41681","content":"1. 会的<br>2. 一个KafkaConsumer实例就算一个客户端","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563274203,"ip_address":"","comment_id":114315,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5858237802","product_id":100029201,"comment_content":"请教老师两个问题，<br>1.  consumer.close()会触发rebalance吗？<br>2. 一个consumer实例就是一个客户端吗？比如：线程池中new了两个consumer实例，是不是意味着开启了两个客户端？<br>麻烦老师解惑，谢谢您","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":458604,"discussion_content":"1. 会的\n2. 一个KafkaConsumer实例就算一个客户端","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563274203,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":114115,"user_name":"Liam","can_delete":false,"product_type":"c1","uid":1094597,"ip_address":"","ucode":"1D15D3B64F2606","user_header":"https://static001.geekbang.org/account/avatar/00/10/b3/c5/7fc124e2.jpg","comment_is_top":false,"comment_ctime":1563239383,"is_pvip":false,"replies":[{"id":"41688","content":"自动提交自动就能保证正确性，只是有可能重复消费","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563274557,"ip_address":"","comment_id":114115,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5858206679","product_id":100029201,"comment_content":"自动提交模式下，多线程消费，Kafka client 如何保证位移提交的正确性？","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":458524,"discussion_content":"自动提交自动就能保证正确性，只是有可能重复消费","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563274557,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":113684,"user_name":"双叶","can_delete":false,"product_type":"c1","uid":1009260,"ip_address":"","ucode":"6DA1D477F9D580","user_header":"https://static001.geekbang.org/account/avatar/00/0f/66/6c/4a68a916.jpg","comment_is_top":false,"comment_ctime":1563117438,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"5858084734","product_id":100029201,"comment_content":"我理解中的 enable.auto.commit 跟文章中说的不太一样，我理解设置为 true 的时候提供的是至多一次的语义，而不是至少一次的语义。<br><br>我不用 java，看的是 librdkafka 的文档。enable.auto.commit 的文档说明是：Automatically and periodically commit offsets in the background. 也就是说他会定期提交 offset，但是这里没有明说提交的 offset 是什么时候记录的，我的理解是记录是由 enable.auto.offset.store 决定的。<br><br>enable.auto.offset.store 文档说明是：Automatically store offset of last message provided to application. The offset store is an in-memory store of the next offset to (auto-)commit for each partition. 也就是说如果设置成 true（默认值），他会自动把上个提交给应用程序的offset 记录到内存中。<br><br>也就是说，如果应用拿到一个 offset 了，librdkafka 就会把这个 offset 记录到内存中，然后默认情况下至多 5s 之后，就会提交给 broker。这时候如果应用还没有完成这个 offset 的处理时，发生了崩溃，这个 offset 就丢掉了，所以是一个至多一次的语义。<br><br>我理解中提供至少一次语义需要关掉 enable.auto.commit 自己控制提交才行。","like_count":1,"discussions":[{"author":{"id":1736462,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/7f/0e/e3a8dbd9.jpg","nickname":"Liujun","note":"","ucode":"3DB1F3CA57B5B3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":390154,"discussion_content":"自动提交就是至少一次语义，因为消息位移的提交只发生在 poll() 方法里，没有所谓其他地方或者子线程触发提交这个操作。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1629691520,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1900382,"avatar":"","nickname":"Geek_b924b4","note":"","ucode":"B071335B28CE04","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":343553,"discussion_content":"提交由poll里面完成，单线程消费不会\n但是多线程消费就会发生消息丢失","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1611071930,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":113323,"user_name":"nightmare","can_delete":false,"product_type":"c1","uid":1056314,"ip_address":"","ucode":"EF2E51C2122A86","user_header":"https://static001.geekbang.org/account/avatar/00/10/1e/3a/5b21c01c.jpg","comment_is_top":false,"comment_ctime":1562951762,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"5857919058","product_id":100029201,"comment_content":"对于重复消费既然避免不了就把消息的业务逻辑唯一性存储下来，如果已经存储就不消费，而没有再消费，比如存储到mongodb中，如果考虑性能redis也可以，如果业务比较重要可以用数据库的乐观锁来保证幂等性，因为重复消费毕竟是小概率事件","like_count":1,"discussions":[{"author":{"id":1676519,"avatar":"https://static001.geekbang.org/account/avatar/00/19/94/e7/bfef4648.jpg","nickname":"飞天大白菜","note":"","ucode":"77344998A30D6E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":21790,"discussion_content":"其实就是end-to-end arguments in system design。即使中间件如kafka提供了&#34;exactly once&#34;语义，最后end systems仍然要自己去实现dedup。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1569520963,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":360307,"user_name":"beifengzhishen001","can_delete":false,"product_type":"c1","uid":2109853,"ip_address":"重庆","ucode":"77D42B7DD9E754","user_header":"","comment_is_top":false,"comment_ctime":1666417638,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1666417638","product_id":100029201,"comment_content":"看了部分评论总结下：1.客户端提交位移是为了再平衡后能得知各个分区从哪开始消费,对于消费者组正常消费未发生再平衡的情况下，每个消费者是在内存里维护着自己负责的各个分区的消费进度的，不会重复拉取消息，即使上一次拉取消息处理消息后，提交偏移量失败，也不会导致下一次拉取重复的消息<br>因此，假设某个消费者拉去到了某分区1～3偏移量的消息，即使没有将偏移量4提交，下次拉取依然不会拉去到123消息。另外，如果消费者消费1～3失败，对于kafka而言，这三条消息对于该消费者也已经消费过，下次拉取依然从4开始拉取，即使消费失败后没有手动提交偏移量，因此业务上的消费消息和Kafka本身的消费消息是两个概念（kafka:给你机会可你不中用啊）。当然，此时如果发生再平衡，新分配到这个分区的消费者则会重复消费到1～3消息。<br>2.那个自动提交位移偏移量时间间隔是个自动提交时间间隔下限，只有两次poll时间间隔超过它，第二次poll才会提交位移偏移量，不是说过了该时间间隔就自动提交位移，还是要靠poll来触发","like_count":0},{"had_liked":false,"id":354865,"user_name":"Geek_bd79d4","can_delete":false,"product_type":"c1","uid":3069067,"ip_address":"上海","ucode":"63C47892E8F7B1","user_header":"","comment_is_top":false,"comment_ctime":1660830410,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1660830410","product_id":100029201,"comment_content":"如果两个commitAsync如何保证顺序，以及commitAsync和commitSync如何保证顺序<br><br>This is an asynchronous call and will not block. Any errors encountered are either passed to the callback (if provided) or discarded.<br>Offsets committed through multiple calls to this API are guaranteed to be sent in the same order as the invocations. Corresponding commit callbacks are also invoked in the same order. Additionally note that offsets committed through this API are guaranteed to complete before a subsequent call to commitSync() (and variants) returns.","like_count":0},{"had_liked":false,"id":350044,"user_name":"Geek_f8f454","can_delete":false,"product_type":"c1","uid":1436394,"ip_address":"","ucode":"C9E9E20A3C45C5","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJNnicJ5b5NnXIXamjcgibvs7DujIIuBZQr17Ke1q9HQvI4GD1rFjupxwXDoZHias41wRD2XFS5yZ8Ww/132","comment_is_top":false,"comment_ctime":1656517787,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1656517787","product_id":100029201,"comment_content":"老师有一个问题请教下，<br>如果每次只poll 一条数据，拿到数据扔到线程池中去执行业务，业务需要的时间不固定；在此期间如果线程池的等待队列满了，循环poll会阻塞，超过一定时间会触发重平衡；针对这种业务场景，有没有什么好的办法。<br>我设想自己维护一个计数器，记录offset,循环时根据offset poll数据，如果发现队列不满就扔进去，计数器+1,如果发现满了，继续循环，不知是否可行。","like_count":0},{"had_liked":false,"id":346311,"user_name":"月明风清","can_delete":false,"product_type":"c1","uid":2226367,"ip_address":"","ucode":"65A97CF2E320FA","user_header":"https://static001.geekbang.org/account/avatar/00/21/f8/bf/59f2e600.jpg","comment_is_top":false,"comment_ctime":1653015855,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1653015855","product_id":100029201,"comment_content":"文章中多次提到了“语义保障”，我不太理解这个词，想问一下老师。","like_count":0},{"had_liked":false,"id":345966,"user_name":"二十二","can_delete":false,"product_type":"c1","uid":2310614,"ip_address":"","ucode":"F3B89CBAC6C905","user_header":"https://static001.geekbang.org/account/avatar/00/23/41/d6/412e9fa4.jpg","comment_is_top":false,"comment_ctime":1652722333,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1652722333","product_id":100029201,"comment_content":"消费者位移表示下一条要消费的消息位置不太准确，只能说是下一条待提交位移的消息的的位置。自动提交时可能poll多次，手动提交也可以多次poll，最后再提交一次位移","like_count":0},{"had_liked":false,"id":342247,"user_name":"绘世浮夸 つ","can_delete":false,"product_type":"c1","uid":1763933,"ip_address":"","ucode":"6A3960195753BA","user_header":"https://static001.geekbang.org/account/avatar/00/1a/ea/5d/ccb4c205.jpg","comment_is_top":false,"comment_ctime":1650126182,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1650126182","product_id":100029201,"comment_content":"老师，我是不是可以理解消息消费后的Offset既会在__consumer_offset这个位移主题中存储其offset偏移量，也会在各自的topic中存储存储一份以消费到的offset，也就是offset+1，下一个需要消费的位置","like_count":0},{"had_liked":false,"id":339951,"user_name":"i_chase","can_delete":false,"product_type":"c1","uid":1795511,"ip_address":"","ucode":"09C41C863F4EA3","user_header":"https://static001.geekbang.org/account/avatar/00/1b/65/b7/058276dc.jpg","comment_is_top":false,"comment_ctime":1648482002,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1648482002","product_id":100029201,"comment_content":"想问一下consumer的消费流程，是不是下面这样：<br>consumer消费的时候，会记录已经拉取过的消息的offset。poll消息时，即使之前的消息还没有提交offset，也不会重复拉取。只要consumer没有重启，那么poll消息时的offset是客户端内部维护记录的。只有consumer第一次或者重启后，才会去_consumer_offsets topic获取消费进度","like_count":0},{"had_liked":false,"id":339832,"user_name":"张三丰","can_delete":false,"product_type":"c1","uid":1155275,"ip_address":"","ucode":"3A6215A40B3B21","user_header":"https://static001.geekbang.org/account/avatar/00/11/a0/cb/aab3b3e7.jpg","comment_is_top":false,"comment_ctime":1648430921,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1648430921","product_id":100029201,"comment_content":"老师这句话不是特别理解，其实自动提交也存在阻塞的问题，这不能算是手动的一个缺点吧。这是自动提交和手动的同步提交的共同的缺点。<br><br>它也有一个缺陷，就是在调用 commitSync() 时，Consumer 程序会处于阻塞状态","like_count":0},{"had_liked":false,"id":333693,"user_name":"追风筝的人","can_delete":false,"product_type":"c1","uid":1488020,"ip_address":"","ucode":"2993D60F94C396","user_header":"https://static001.geekbang.org/account/avatar/00/16/b4/94/2796de72.jpg","comment_is_top":false,"comment_ctime":1644476210,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1644476210","product_id":100029201,"comment_content":"enable.auto.commit 为 true  自动提交， <br>enable.auto.commit 为 false时候   调用 consumer.commitSync() 方法   关闭自动提交，<br>从用户的角度来说，位移提交分为自动提交和手动提交；从 Consumer 端的角度来说，位移提交分为同步提交和异步提交。","like_count":0},{"had_liked":false,"id":332978,"user_name":"陈斌","can_delete":false,"product_type":"c1","uid":1367048,"ip_address":"","ucode":"B639AB5F6AA03D","user_header":"https://static001.geekbang.org/account/avatar/00/14/dc/08/64f5ab52.jpg","comment_is_top":false,"comment_ctime":1643907258,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1643907258","product_id":100029201,"comment_content":"老师您好~<br>消费失败后，我能不能立即重新消费，而不是等到Consumer下次重新启动时去消费？<br>还有一个问题，Consumer在什么情况下会被重启，我理解一般情况我的Consumer不会挂掉。如果我的Consumer不挂掉的话我没有提交的消息是不是永远不会被重新消费？","like_count":0},{"had_liked":false,"id":329822,"user_name":"William","can_delete":false,"product_type":"c1","uid":1346215,"ip_address":"","ucode":"55F5D9DEE485B1","user_header":"https://static001.geekbang.org/account/avatar/00/14/8a/a7/674c1864.jpg","comment_is_top":false,"comment_ctime":1641552337,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1641552337","product_id":100029201,"comment_content":"关于自动提交查询到有4个地方（看的csnd的博客）。<br><br>1、消费者手动指定自己需要消费的分区(此处是异步提交)<br>  KafkaConsumer#assign#内部调用了 <br>    this.coordinator.maybeAutoCommitOffsetsAsync(this.time.milliseconds());<br><br>2、消费者拉取消息的时候(此处是异步提交)<br>调用栈：<br>KafkaConsumer#poll--&gt;this.updateAssignmentMetadataIfNeeded(timer, false);<br>--&gt;!this.coordinator.poll(timer, waitForJoinGroup)<br>--&gt;this.maybeAutoCommitOffsetsAsync(timer.currentTimeMs());<br><br><br>public void maybeAutoCommitOffsetsAsync(long now) {<br>        if (this.autoCommitEnabled) {<br>            this.nextAutoCommitTimer.update(now);<br>            if (this.nextAutoCommitTimer.isExpired()) {<br>                this.nextAutoCommitTimer.reset((long)this.autoCommitIntervalMs);<br>                this.doAutoCommitOffsetsAsync();<br>            }<br>        }<br><br>    }<br><br>3、消费者以消费者组模式启动，加入组重新rebalance之前(此处是同步提交)<br><br>AbstractCoordinator#ensureActiveGroup<br><br>AbstractCoordinator#joinGroupIfNeeded<br>AbstractCoordinator#onJoinPrepare<br>ConsumerCoordinator#maybeAutoCommitOffsetsSync<br>只要开启了自动提交，此处是一定会向协调者同步提交位移，因为需要重新rebalance，消费者组中各个消费者的分区既有可能会发生改变，重新消费之前一定要获取最新的唯一，尽最大努力避免重复消费。<br><br>4、 消费者关闭的时候， 也会出发rebalance<br>ConsumerCoordinator#close<br>关闭的时候肯定是要同步提交消费位移的。<br><br>","like_count":0},{"had_liked":false,"id":328688,"user_name":"水滴s","can_delete":false,"product_type":"c1","uid":1264431,"ip_address":"","ucode":"1C684514B54B6F","user_header":"https://static001.geekbang.org/account/avatar/00/13/4b/2f/2f73fd52.jpg","comment_is_top":false,"comment_ctime":1640843021,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1640843021","product_id":100029201,"comment_content":"手动提交位移能提交不属于分配给自己分区的位移吗，如果可以，每次提交后都要清空自己保存位移的Map吧，防止rebalance后Map中有别的分区的位移信息？","like_count":0},{"had_liked":false,"id":323875,"user_name":"最烦起名字","can_delete":false,"product_type":"c1","uid":2153662,"ip_address":"","ucode":"405A886940AD46","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIXbxuhFpUq10M3H87WiaE4bbqI5gTtmxfQCZDPUad4KrCJn8NiaPxhask5YSzRyQiaRaEJqaGoax35A/132","comment_is_top":false,"comment_ctime":1638190478,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1638190478","product_id":100029201,"comment_content":"try {<br>           while(true) {<br>                        ConsumerRecords&lt;String, String&gt; records = <br>                                    consumer.poll(Duration.ofSeconds(1));<br>                        process(records); &#47;&#47; 处理消息<br>                        commitAysnc(); &#47;&#47; 使用异步提交规避阻塞<br>            }<br>} catch(Exception e) {<br>            handle(e); &#47;&#47; 处理异常<br>} finally {<br>            try {<br>                        consumer.commitSync(); &#47;&#47; 最后一次提交使用同步阻塞式提交<br>  } finally {<br>       consumer.close();<br>}<br>}<br><br><br>老师，这段代码，是不是位移被提交了两次呢","like_count":0},{"had_liked":false,"id":314520,"user_name":"刘国","can_delete":false,"product_type":"c1","uid":2780661,"ip_address":"","ucode":"BED5A222F32C0C","user_header":"https://static001.geekbang.org/account/avatar/00/2a/6d/f5/d5c528c1.jpg","comment_is_top":false,"comment_ctime":1633167121,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1633167121","product_id":100029201,"comment_content":"如果业务执行时间3s，最小提交时间5s，那么下一次poll不会提交offset，要等到下次poll超过5s了才提交。","like_count":0},{"had_liked":false,"id":306448,"user_name":"艾文","can_delete":false,"product_type":"c1","uid":2304575,"ip_address":"","ucode":"44D35A7248F7B0","user_header":"https://static001.geekbang.org/account/avatar/00/23/2a/3f/a97fe8ef.jpg","comment_is_top":false,"comment_ctime":1628565999,"is_pvip":false,"replies":[{"id":"111187","content":"通常表示消息丢失了","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1628841981,"ip_address":"","comment_id":306448,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1628565999","product_id":100029201,"comment_content":"老师，什么情况下kafka的消息堆积量LAG会为负数了，例如-1200","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":524769,"discussion_content":"通常表示消息丢失了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1628841981,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":298755,"user_name":"大叮当","can_delete":false,"product_type":"c1","uid":1181578,"ip_address":"","ucode":"418EEFBD0C5A85","user_header":"https://static001.geekbang.org/account/avatar/00/12/07/8a/4bef6202.jpg","comment_is_top":false,"comment_ctime":1624290141,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1624290141","product_id":100029201,"comment_content":"老师您好，好像commitAsync方法很好就不再抛出异常了？https:&#47;&#47;issues.apache.org&#47;jira&#47;browse&#47;KAFKA-5052","like_count":0},{"had_liked":false,"id":298149,"user_name":"拉可里啦","can_delete":false,"product_type":"c1","uid":1230293,"ip_address":"","ucode":"26E20DF096BDAF","user_header":"https://static001.geekbang.org/account/avatar/00/12/c5/d5/90ca8efe.jpg","comment_is_top":false,"comment_ctime":1623924487,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1623924487","product_id":100029201,"comment_content":"原来如此，提交位移是为了防止消费者重启找不到消费位置才有的。不重启的话，消费者自己会保存消费位移的，不会出现消息错位的，一旦重启了，消费者保存在内存中的位移就没了，就需要将位移提交到远程持久化了","like_count":0},{"had_liked":false,"id":294417,"user_name":"大力水手Jerry","can_delete":false,"product_type":"c1","uid":1227840,"ip_address":"","ucode":"E4A6C71E275DB5","user_header":"https://static001.geekbang.org/account/avatar/00/12/bc/40/2279cfb5.jpg","comment_is_top":false,"comment_ctime":1621935613,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1621935613","product_id":100029201,"comment_content":"老师，异步全量提交模式的例子中“<br>while (true) {<br>            ConsumerRecords&lt;String, String&gt; records = <br>  consumer.poll(Duration.ofSeconds(1));<br>            process(records); &#47;&#47; 处理消息<br>            consumer.commitAsync((offsets, exception) -&gt; {<br>  if (exception != null)<br>  handle(exception);<br>  });<br>}”<br>应该是 “consumer.commitAsync((exception) -&gt; {&quot;，不需要offset参数。","like_count":0},{"had_liked":false,"id":291336,"user_name":"Zain","can_delete":false,"product_type":"c1","uid":1920896,"ip_address":"","ucode":"03EDF7B1BE9CF8","user_header":"https://static001.geekbang.org/account/avatar/00/1d/4f/80/19f946ba.jpg","comment_is_top":false,"comment_ctime":1620215161,"is_pvip":false,"replies":[{"id":"105695","content":"1. “消息拉回来了但是业务还没处理完，这时提交位移的话” --- 不会出现这种情况。消息处理完成后才会提交位移<br>2. 同上：）","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1620613897,"ip_address":"","comment_id":291336,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1620215161","product_id":100029201,"comment_content":"老师，我看了这节课所有的评论，基本都是在问这两个问题，能不能麻烦您抽空再解释一下<br>1. consumer自动提交的情况下，auto.commit.interval.ms 设置的比较短，消息拉回来了但是业务还没处理完，这时提交位移的话，万一后续未处理的业务报错，那是不是就表示这次的信息丢了一部分，下次也消费不到这部分了<br>2.也是自动提交，poll比auto.commit.interval.ms频繁的话，是不是每poll一次就提交一次位移，等到间隔到了也会再提交一次<br><br>谢谢老师","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":519443,"discussion_content":"1. “消息拉回来了但是业务还没处理完，这时提交位移的话” --- 不会出现这种情况。消息处理完成后才会提交位移\n2. 同上：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1620613897,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2083187,"avatar":"https://static001.geekbang.org/account/avatar/00/1f/c9/73/047f51d2.jpg","nickname":"ybonfire","note":"","ucode":"9A8D541DEFFBB4","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":372814,"discussion_content":"我的理解是，不存在消息拉回来业务还没处理完的情况。如果出现了这个情况，就要触发REBALANCE了，这次的位移不会提交","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1620469347,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":290912,"user_name":"石栖","can_delete":false,"product_type":"c1","uid":1496443,"ip_address":"","ucode":"35600F645A479F","user_header":"https://static001.geekbang.org/account/avatar/00/16/d5/7b/c512da6a.jpg","comment_is_top":false,"comment_ctime":1619855681,"is_pvip":false,"replies":[{"id":"105699","content":" 抱歉，不太清楚spring-kafka客户端的实现。如果你觉得解决了问题，那应该就没问题了<br>","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1620614328,"ip_address":"","comment_id":290912,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1619855681","product_id":100029201,"comment_content":"老师，您好。我最近莫名其妙遇到一个问题。Kafka版本试过：2.0.1&#47;2.3.1&#47;2.6 都是一样的。我的客户端是：Spring-Kafka：2.2.3 + kafka-clients: 2.3.1. Consumer的配置：enable.auto.commit = true， auto.commit.interval.ms = 5000 （5s）， max.poll.interval.ms = 300000 （5 min），max.poll.records = 500 。使用的时候，发现auto-commit形同虚设，如果每5s会提交，不该出现大面积的重复消费。现在只要5min无法把所有消息处理完，就会导致不断重新消费。然后出现死循环。后来发现spring-kafka还有一个AckMode可以配置，默认值是Batch （也就是只有在下次poll的时候，才会一起提交）。按照官方文档https:&#47;&#47;docs.spring.io&#47;spring-kafka&#47;reference&#47;html&#47;#committing-offsets，我的理解是只有在enable.auto.commit=false的时候，才会生效。但是我把AckMode修改成Record（也就是每条记录处理完，就会直接提交），就没有前面说的死循环的问题了。但是这块我没法理解，enable.auto.commit=true的时候，还是有影响。我感觉自己发现了问题的root cause，但是没法自圆其说，更没法跟其他人去说。。。因为我发现的跟官方文档 以及 google&#47;百度到的，不一样。我觉得这个跟我客户端版本应该关系不大吧。。因为Kafka server的版本也都试过很多了。我后面也换个客户端版本试试。。。","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":519320,"discussion_content":" 抱歉，不太清楚spring-kafka客户端的实现。如果你觉得解决了问题，那应该就没问题了\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1620614328,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":290792,"user_name":"Geek_9c6c3e","can_delete":false,"product_type":"c1","uid":2577451,"ip_address":"","ucode":"F3B71465B25BC6","user_header":"","comment_is_top":false,"comment_ctime":1619753703,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1619753703","product_id":100029201,"comment_content":"分区+group的设计是为了保证：高可用，负载均衡，可拓展。","like_count":0},{"had_liked":false,"id":290578,"user_name":"石栖","can_delete":false,"product_type":"c1","uid":1496443,"ip_address":"","ucode":"35600F645A479F","user_header":"https://static001.geekbang.org/account/avatar/00/16/d5/7b/c512da6a.jpg","comment_is_top":false,"comment_ctime":1619626698,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1619626698","product_id":100029201,"comment_content":"如果enable.auto.commit=true, auto.commit.interval.ms=5s，max.poll.interval.ms=5m。然后consumer一次拉了100条过来，5m之内只处理了30条，大概10s一条。这个时候会发生，rebalance。然后下次可能会继续从第30&#47;31条，开始继续消费（第30条可能会重复消费）。那下次发生rebalance 和重复消费的message，大概应该是第60条；一次类推，后面应该是第90条；最后还是会全部执行完。  可是我遇到了一个很奇怪的问题，就是从第30条开始，到第100条，全部一直无限循环去消费处理。。。。我不能理解，希望作者 或者 其他大牛可以解答一下。","like_count":0},{"had_liked":false,"id":288628,"user_name":"Edon du","can_delete":false,"product_type":"c1","uid":1074742,"ip_address":"","ucode":"1648624751AAE9","user_header":"https://static001.geekbang.org/account/avatar/00/10/66/36/b4a4e6fb.jpg","comment_is_top":false,"comment_ctime":1618567600,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1618567600","product_id":100029201,"comment_content":"文章作者说了是Rebalance后进行了重复消费，我给分析一下<br>也希望有同学补充一下：<br><br>消费者组的每个成员内部维护了一个  分区:位移的map<br>consumer0维护了 partition0:10, partition1:20<br>consumer1维护了 partition2:10, partition3:20<br>consumer2维护了 partition4:10, partition5:20<br><br>这时候consumer2执行了poll方法，需要先提交了上一批10个消息的位移，假如说是分partition4的位移<br>这时候consumer2的状态是<br>consumer2维护了 partition4:21, partition5:20<br>紧接着拉取了10条消息，进行处理，处理了3秒处理了8条消息，这时候consumer0挂了，系统要进行重平衡<br>重平衡后的结果为<br>consumer1维护了 partition2:10, partition3:20, partition4:21<br>consumer2维护了 partition0:10, partition1:20, partition5:20<br><br>这时候consumer2再执行poll方法是不能提交上一批的位移的，因为上一批的位移所在的分区已经不属于它了<br>如果还能提交旧分区的位移，这时候旧分区所归属的consumer1已经开始消费了，是否也重复消费了呢<br>所以我猜想，kafka内部的设计就是重平衡后需要重新从分区的最新位移进行消费","like_count":0},{"had_liked":false,"id":285511,"user_name":"Allan","can_delete":false,"product_type":"c1","uid":1310388,"ip_address":"","ucode":"8DA4DBECC2C45C","user_header":"https://static001.geekbang.org/account/avatar/00/13/fe/b4/295338e7.jpg","comment_is_top":false,"comment_ctime":1616852880,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1616852880","product_id":100029201,"comment_content":"1、对于重复消费，如果要避免，只消费一次，其实可以把每次消费的结果存储在一个位置，比如 存入redis，下次消费如果消息存在redis中，那么就不用再次处理了。","like_count":0},{"had_liked":false,"id":273847,"user_name":"Edward Lee","can_delete":false,"product_type":"c1","uid":1228518,"ip_address":"","ucode":"156223F1D7E94A","user_header":"https://static001.geekbang.org/account/avatar/00/12/be/e6/7808520d.jpg","comment_is_top":false,"comment_ctime":1610695635,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1610695635","product_id":100029201,"comment_content":"既然重复消费无法避免，那么消费应用程序就必须要考虑重复消费的情况，然而应用程序已经考虑了去重的情况，那么使用 enable.auto.commit= true，也是一个不错的选择（注意 Log Cleaner 不能停）<br><br>课后讨论<br>1. 对于可持续更新类的消息增加一个最后更新时间，消费者程序需要对比最后的更新时间，较早期的消息忽略处理（类似于消息的版本号）<br>2. 对于一次性的消息，使用数据唯一标识，消费者只需要简单查询匹配去重<br><br>使用 commitSync(Map) 和 commitAsync(Map) 的前提是 poll 下来的消息的 offset 必须以按照各个分区的从小到大顺序排列，避免提交的 offset 会大小颠倒问题","like_count":0},{"had_liked":false,"id":272765,"user_name":"机车","can_delete":false,"product_type":"c1","uid":1881786,"ip_address":"","ucode":"CD32A645AE310A","user_header":"https://static001.geekbang.org/account/avatar/00/1c/b6/ba/f76d996b.jpg","comment_is_top":false,"comment_ctime":1610268681,"is_pvip":false,"replies":[{"id":"99093","content":"不会啊。从0开始，到99，正好100条消息","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1610620993,"ip_address":"","comment_id":272765,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1610268681","product_id":100029201,"comment_content":"初始值 count=1 才对吧，不然第一次提交是消费101条数据","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":513377,"discussion_content":"不会啊。从0开始，到99，正好100条消息","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1610620993,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":264989,"user_name":"wind","can_delete":false,"product_type":"c1","uid":1507189,"ip_address":"","ucode":"5EC77AEB18130E","user_header":"https://static001.geekbang.org/account/avatar/00/16/ff/75/9c1b2ece.jpg","comment_is_top":false,"comment_ctime":1606729342,"is_pvip":false,"replies":[{"id":"96630","content":"这取决于你如何处理消费失败，如果直接吞了，是可以继续消费下面的，如果fail fast就另说了","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1607078089,"ip_address":"","comment_id":264989,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1606729342","product_id":100029201,"comment_content":"如果设置手动提交但是因为出现消费失败的情况没有提交，是不是后面的消息都消费不了了？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":510761,"discussion_content":"这取决于你如何处理消费失败，如果直接吞了，是可以继续消费下面的，如果fail fast就另说了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1607078089,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":264227,"user_name":"朴素柠檬c","can_delete":false,"product_type":"c1","uid":1547667,"ip_address":"","ucode":"2D4CBB70D801B1","user_header":"https://static001.geekbang.org/account/avatar/00/17/9d/93/4159edaa.jpg","comment_is_top":false,"comment_ctime":1606384716,"is_pvip":false,"replies":[{"id":"95848","content":"不冲突。你能看到的位移是已提交的位移，你看不到的位移则是poll内部维护的","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1606438323,"ip_address":"","comment_id":264227,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1606384716","product_id":100029201,"comment_content":"一会说下次poll的时候 提交上次的消息的offset，一会又说调用poll的过程中，现在又说在poll自己维护，乱了乱了，到底是文中说的还是评论中说的啊？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":510472,"discussion_content":"不冲突。你能看到的位移是已提交的位移，你看不到的位移则是poll内部维护的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606438323,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":264212,"user_name":"朴素柠檬c","can_delete":false,"product_type":"c1","uid":1547667,"ip_address":"","ucode":"2D4CBB70D801B1","user_header":"https://static001.geekbang.org/account/avatar/00/17/9d/93/4159edaa.jpg","comment_is_top":false,"comment_ctime":1606381002,"is_pvip":false,"replies":[{"id":"95851","content":"嗯嗯，差不多。总之是提交位移是在poll方法中完成的","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1606439355,"ip_address":"","comment_id":264212,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1606381002","product_id":100029201,"comment_content":"自动提交 当前poll方法，提桥上传poll执行的消息偏移，这块没明白，while循环下次执行的时候，上次业务代码已经执行完了，然后在执行自动提交偏移？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":510464,"discussion_content":"嗯嗯，差不多。总之是提交位移是在poll方法中完成的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606439355,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":261729,"user_name":"～风铃～","can_delete":false,"product_type":"c1","uid":1116191,"ip_address":"","ucode":"4EEA12C17BA913","user_header":"https://static001.geekbang.org/account/avatar/00/11/08/1f/b24a561d.jpg","comment_is_top":false,"comment_ctime":1605506753,"is_pvip":true,"replies":[{"id":"95342","content":"嗯嗯，文中只是一个示例。你当然可以结合自己的消费策略选择是否继续等待收集剩下的99条，还是实现即时消息处理","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1605838437,"ip_address":"","comment_id":261729,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1605506753","product_id":100029201,"comment_content":"老师，您好！批量提交那里我有个疑问：每100条消息提交一次，那么如果有5001条，剩下这1条消息怎么办？ 从这个代码看是消费不了的","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509586,"discussion_content":"嗯嗯，文中只是一个示例。你当然可以结合自己的消费策略选择是否继续等待收集剩下的99条，还是实现即时消息处理","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605838437,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":255607,"user_name":"Impassive","can_delete":false,"product_type":"c1","uid":1639924,"ip_address":"","ucode":"4C386167F67559","user_header":"https://static001.geekbang.org/account/avatar/00/19/05/f4/216ad755.jpg","comment_is_top":false,"comment_ctime":1603378339,"is_pvip":false,"replies":[{"id":"93385","content":"没太懂。map里面都是不同的key，也就是不同的分区，都会提交的","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1603675558,"ip_address":"","comment_id":255607,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1603378339","product_id":100029201,"comment_content":"老师，有一个问题就是如果放到map里面提交，是map里面的所有值都会提交一次，还是只会选择其中最大的一个值？谢谢老师","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":507768,"discussion_content":"没太懂。map里面都是不同的key，也就是不同的分区，都会提交的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1603675558,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1069755,"avatar":"https://static001.geekbang.org/account/avatar/00/10/52/bb/225e70a6.jpg","nickname":"hunterlodge","note":"","ucode":"5B83A79E784161","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":328633,"discussion_content":"我本来也有此一问，不过推敲了一番，发现没有问题。因为从TopicPartition的hashCode及equals代码判断，同一个topic的同一个partition，他们的hashCode值相同且equal，所以如果被map put了多次，则后面的数据会覆盖前面的数据，即map中只会保存最新一次的位移值（即最大值)。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1606199696,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":253067,"user_name":"对与错","can_delete":false,"product_type":"c1","uid":1682027,"ip_address":"","ucode":"EF55733E3BD78B","user_header":"https://static001.geekbang.org/account/avatar/00/19/aa/6b/ab9a072a.jpg","comment_is_top":false,"comment_ctime":1602584208,"is_pvip":false,"replies":[{"id":"92488","content":"&quot;当前消费进度被更新为15，那中间消费失败的几条消息会随着重启消费者而重新消费吗？&quot; -- 不会<br><br>不会被删除，只是之前提交的进度会被新的进度废弃","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1602636643,"ip_address":"","comment_id":253067,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1602584208","product_id":100029201,"comment_content":"请问kafka消费者使用手动提交位移的方式，当前消费进度为10，,然后消费几条失败之后，提交位移失败，后面消费新的消息成功之后，当前消费进度被更新为15，那中间消费失败的几条消息会随着重启消费者而重新消费吗？位移主题里面的消费进度会随着重启消费者而被删除吗?如果不被删除，那应该不会重新消费失败的那几条消息吧？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":506962,"discussion_content":"&amp;quot;当前消费进度被更新为15，那中间消费失败的几条消息会随着重启消费者而重新消费吗？&amp;quot; -- 不会\n\n不会被删除，只是之前提交的进度会被新的进度废弃","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1602636643,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":251923,"user_name":"Alpha","can_delete":false,"product_type":"c1","uid":1001861,"ip_address":"","ucode":"60CA15A25EC796","user_header":"https://static001.geekbang.org/account/avatar/00/0f/49/85/3f161d95.jpg","comment_is_top":false,"comment_ctime":1601975239,"is_pvip":false,"replies":[{"id":"92144","content":"auto.commit.interval.ms实际上是最低的提交间隔，比如设置5s，Kafka至少会保证5秒内不提交位移。至于是否能够精准地5秒提交，取决于poll调用的时机","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1602205872,"ip_address":"","comment_id":251923,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1601975239","product_id":100029201,"comment_content":"关于自动提交，既然是单独的线程来提交，那么 auto.commit.interval.ms 时间一到就提交，为何会跟poll()有关系呢？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":506664,"discussion_content":"auto.commit.interval.ms实际上是最低的提交间隔，比如设置5s，Kafka至少会保证5秒内不提交位移。至于是否能够精准地5秒提交，取决于poll调用的时机","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1602205872,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":251423,"user_name":"Geek_58a455","can_delete":false,"product_type":"c1","uid":1519269,"ip_address":"","ucode":"C20E856D38D338","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/2qHhibwFEiaNWNjCqTpe8kCHqWian0rBdkulmkvVXpkr4CSOpuibVHNVozHUERAmvMDMticfycjzgwYDv6Gfav1dZ3A/132","comment_is_top":false,"comment_ctime":1601542287,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1601542287","product_id":100029201,"comment_content":"总结一下：<br>消息处理逻辑：先是业务处理，然后提交位移；这个大体思路是没得问题的，所以在处理和提交位移之前出问题了，那么下次出现重复消费肯定是业务的问题喽，所以最好的办法是在业务处理上，消费一条，确认一条，最大限度防止全部消费，然后再确认，再提交位移的情况出现，嗯，好像没有100%防止丢失的办法，只能尽量吧。如果在确认一条的过程中出现问题了，也有问题，主要还是没有办法保证process业务和确认是事务的过程，如果能够保证事务性就好了","like_count":0},{"had_liked":false,"id":251225,"user_name":"timmy21","can_delete":false,"product_type":"c1","uid":1174860,"ip_address":"","ucode":"9D6DED247B1F38","user_header":"https://static001.geekbang.org/account/avatar/00/11/ed/4c/8674b6ad.jpg","comment_is_top":false,"comment_ctime":1601429485,"is_pvip":false,"replies":[{"id":"92156","content":"不是。poll内部维持了一个位移，只不过这个位移对用户不可见","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1602208265,"ip_address":"","comment_id":251225,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1601429485","product_id":100029201,"comment_content":"老师每次从kafka poll消息都是从已提交的位移处读取？如果是这样的话，每一次poll处理完必须提交位移，不然下次poll就会重复消费？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":506420,"discussion_content":"不是。poll内部维持了一个位移，只不过这个位移对用户不可见","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1602208265,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1547667,"avatar":"https://static001.geekbang.org/account/avatar/00/17/9d/93/4159edaa.jpg","nickname":"朴素柠檬c","note":"","ucode":"2D4CBB70D801B1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":329439,"discussion_content":"一会说下次poll的时候 提交上次的消息的offset，一会又说调用poll的过程中，现在又说在poll自己维护，乱了乱了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606384680,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":247009,"user_name":"多襄丸","can_delete":false,"product_type":"c1","uid":1074310,"ip_address":"","ucode":"1AA1497C5A293C","user_header":"https://static001.geekbang.org/account/avatar/00/10/64/86/f5a9403a.jpg","comment_is_top":false,"comment_ctime":1599556843,"is_pvip":false,"replies":[{"id":"90936","content":"是这样的。而且producer会复用之前batch size大小的bytebuffer。","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1599791056,"ip_address":"","comment_id":247009,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1599556843","product_id":100029201,"comment_content":"胡老师您好，你的源码阅读课我也是一开始就订阅了的。只是还没开启阅读之旅。<br>这两天看producer有个疑问哈，accumulator中的bufferpool 默认是32MB。但是我看它不是立即分配内存，所以它不是连续的叭？<br>因为它也只是来一条消息，才会去分配byteBuffer嘛，<br>所以producer在bufferpool这里的设计是通过逻辑上的手段管理内存哈，并没有管理一个连续的32MB大小的内存块哈？<br>我就是想找您求证一下，谢谢胡老师～","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":505286,"discussion_content":"是这样的。而且producer会复用之前batch size大小的bytebuffer。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1599791056,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1074310,"avatar":"https://static001.geekbang.org/account/avatar/00/10/64/86/f5a9403a.jpg","nickname":"多襄丸","note":"","ucode":"1AA1497C5A293C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":305135,"discussion_content":"谢谢胡老师","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1599792507,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":244808,"user_name":"genshen","can_delete":false,"product_type":"c1","uid":1100042,"ip_address":"","ucode":"155B3484DBAD26","user_header":"https://static001.geekbang.org/account/avatar/00/10/c9/0a/5bb778eb.jpg","comment_is_top":false,"comment_ctime":1598687499,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1598687499","product_id":100029201,"comment_content":"讲的通俗易懂，感谢老师","like_count":0},{"had_liked":false,"id":243502,"user_name":"单朋荣","can_delete":false,"product_type":"c1","uid":1272662,"ip_address":"","ucode":"8AD121BEDD9675","user_header":"https://static001.geekbang.org/account/avatar/00/13/6b/56/37a4cea7.jpg","comment_is_top":false,"comment_ctime":1598156532,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1598156532","product_id":100029201,"comment_content":"同步&#47;异步结合使用，除了在最后一次能规避异步提交位移不能重试的问题，中间出问题了（程序非正常关闭，应该解决不了。<br>这让我想到了另一个问题，rebalance时，消费后再提交位移，因受rebalance的影响，“异步”提交的问题会不会超过关闭前的“同步”最后一次位移，会不会出现消息丢失的问题啊？<br>整体来看，还是用效率换准确率的做法，只能用最后一次的“同步”位移提交，来一定程度上规避“异步”存在的问题。","like_count":0},{"had_liked":false,"id":242509,"user_name":"J.Smile","can_delete":false,"product_type":"c1","uid":1336475,"ip_address":"","ucode":"C4D98DFDBF7584","user_header":"https://static001.geekbang.org/account/avatar/00/14/64/9b/0b578b08.jpg","comment_is_top":false,"comment_ctime":1597744659,"is_pvip":false,"replies":[{"id":"89549","content":"对于新的group而言，这是正常的现象，因为没有任何提交位移，所以会“found no committed&quot;，从而”resetting offset....&quot; ","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1597885796,"ip_address":"","comment_id":242509,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1597744659","product_id":100029201,"comment_content":"老师好，消费重启后会从分区上次提交位移的地方开始消费，那么报:Found no committed offset for partition xx_topic-0,这样的日志是不是有问题？<br>实际中遇到过这种问题就是：只有指定的groupId可以正常消费，其他的任意groupid全部报这个日志。然后还有Resetting offset for partition xx_topic-0 to offset 2365(2365是我的分区最新位移)，但实际上我的groupid从未消费过这个主题。老师有遇到过这个问题吗 可能的原因是啥呢？请老师指点迷津","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":504024,"discussion_content":"对于新的group而言，这是正常的现象，因为没有任何提交位移，所以会“found no committed&amp;quot;，从而”resetting offset....&amp;quot; ","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1597885796,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":238876,"user_name":"夜里吃西瓜","can_delete":false,"product_type":"c1","uid":1066678,"ip_address":"","ucode":"362817AF375E38","user_header":"https://static001.geekbang.org/account/avatar/00/10/46/b6/edfe7ce8.jpg","comment_is_top":false,"comment_ctime":1596353867,"is_pvip":false,"replies":[{"id":"88292","content":"自动提交和手动提交都是外围的事情，本质上都是写位移主题消息","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1596425904,"ip_address":"","comment_id":238876,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1596353867","product_id":100029201,"comment_content":"老师，你好。这篇说的位移提交也是提交到所谓的位移主题中吗（__consumer_offsets）。这篇文章中说的自动提交与手动提交的配置都与16章节说的一致，所以这两个内容还是有点模糊","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":502878,"discussion_content":"自动提交和手动提交都是外围的事情，本质上都是写位移主题消息","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1596425904,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":236798,"user_name":"J.Smile","can_delete":false,"product_type":"c1","uid":1336475,"ip_address":"","ucode":"C4D98DFDBF7584","user_header":"https://static001.geekbang.org/account/avatar/00/14/64/9b/0b578b08.jpg","comment_is_top":false,"comment_ctime":1595552614,"is_pvip":false,"replies":[{"id":"87678","content":"不会。不同消费者组之间毫不影响，没有关联","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1595811077,"ip_address":"","comment_id":236798,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1595552614","product_id":100029201,"comment_content":"老师，如果说“Kafka 只会“无脑”地接受你提交的位移”，那么当启动两个groupid不同，topic相同的consumer，会不会出现同样分区X的消息被groupidA的消费者消费且提交了位移，导致groupidB的消费者消费不到？那对于groupidB这个消费者来说， 分区X中的数据就是丢失了吧？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":502213,"discussion_content":"不会。不同消费者组之间毫不影响，没有关联","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1595811077,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":226739,"user_name":"见南山","can_delete":false,"product_type":"c1","uid":1118111,"ip_address":"","ucode":"6A8BB82B7573CA","user_header":"https://static001.geekbang.org/account/avatar/00/11/0f/9f/f4b06bd5.jpg","comment_is_top":false,"comment_ctime":1592192578,"is_pvip":false,"replies":[{"id":"83669","content":"没错，业务去重是一种方式","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1592297166,"ip_address":"","comment_id":226739,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1592192578","product_id":100029201,"comment_content":"将消息处理和位移提交放到一个事务逻辑中，一起失败或成功。<br>但是，在实际处理中，可以直接在业务端去重，比如某个字段作为消息的唯一值，如果重复则将消息直接丢弃即可","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":498348,"discussion_content":"没错，业务去重是一种方式","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1592297166,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":226311,"user_name":"小小","can_delete":false,"product_type":"c1","uid":1031756,"ip_address":"","ucode":"AF1F011FDDE29B","user_header":"","comment_is_top":false,"comment_ctime":1592033187,"is_pvip":false,"replies":[{"id":"83440","content":"第一个问题讨论的是正常情况下consumer如何避免重复消费的事情；第二个问题说的是当出现问题时consumer无法避免重复消费。","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1592183597,"ip_address":"","comment_id":226311,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1592033187","product_id":100029201,"comment_content":"老师您好，我是最近才开始看这个课的，不知道您会不会看到留言，进行回复。<br><br>1、针对ban同学的问题“老师，你好。有个场景不太明白。我做个假设，比如说我的模式是自动提交，自动提交间隔是20秒一次，那我消费了10个消息，很快一秒内就结束。但是这时候我自动提交时间还没到（那是不是意味着不会提交offer），然后这时候我又去poll获取消息，会不会导致一直获取上一批的消息？<br>还是说如果consumer消费完了，自动提交时间还没到，如果你去poll，这时候会自动提交，就不会出现重复消费的情况。”<br><br>您的回复是 “不会的。consumer内部维护了一个指针，能够探测到下一条要消费的数据”<br><br><br>2、针对jc9090kkk同学的提问“感觉老师分享，对于文章中的那个自动提交的例子有点疑惑，希望老师能解答一下：<br>auto.commit.interval.ms设置为5s，也就是说consumer每5秒才提交一次位移信息，那consumer如果每消费一条数据，但是没有达到自动提交的时间，这个位移信息该如何管理？consumer自己做维护吗？但是也需要跟broker端进行位移信息同步的吧？ 不然可能会造成数据的重复消费？还是每5s的提交和consumer自动提交的时候都会伴随位移信息的同步？是我的理解有问题吗？”<br><br>您的回复是“如果没有达到提交时间就不会提交，自动提交完全由consumer自行维护，确实可能造成数据的重复消费。你的理解完全没有问题：）”<br><br>我的疑问是：<br>这个两个答案是不是矛盾呢，还是我有哪里没有理解正确呢，希望老师看到了的话，解答一下，我看评论里面，好多人都对这个问题有疑问，谢谢","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":498184,"discussion_content":"第一个问题讨论的是正常情况下consumer如何避免重复消费的事情；第二个问题说的是当出现问题时consumer无法避免重复消费。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1592183597,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1031756,"avatar":"","nickname":"小小","note":"","ucode":"AF1F011FDDE29B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":283138,"discussion_content":"谢谢 老师的解答。后面又来了几遍。理解了\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1592193817,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":224148,"user_name":"James","can_delete":false,"product_type":"c1","uid":1134861,"ip_address":"","ucode":"48B0F2A334D1C1","user_header":"https://static001.geekbang.org/account/avatar/00/11/51/0d/fc1652fe.jpg","comment_is_top":false,"comment_ctime":1591285600,"is_pvip":false,"replies":[{"id":"82548","content":"我们编写代码可以保证线程处理完成之后再进行提交。多线程的主要问题是提交的顺序问题","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1591323732,"ip_address":"","comment_id":224148,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1591285600","product_id":100029201,"comment_content":"请问下,文章的位移提交代码假设是多线程执行,那么异步提交会不会出现问题..实际上多线程的消息还没消费完成,就提交位移的情况下..","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":497376,"discussion_content":"我们编写代码可以保证线程处理完成之后再进行提交。多线程的主要问题是提交的顺序问题","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1591323732,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":222204,"user_name":"lizhibo","can_delete":false,"product_type":"c1","uid":1636410,"ip_address":"","ucode":"FDF4FA12C699B3","user_header":"https://static001.geekbang.org/account/avatar/00/18/f8/3a/e0c14cb3.jpg","comment_is_top":false,"comment_ctime":1590716223,"is_pvip":false,"replies":[{"id":"81992","content":"如果消费者异常，程序会捕获这个异常，等你处理完了再继续消费。如果事件读取与处理在不同线程，那么使用seek方法重设位移值重新消费+处理","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1590750324,"ip_address":"","comment_id":222204,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1590716223","product_id":100029201,"comment_content":"老师好，我想咨询下如果消费者异常，我怎么提交位移可以进行自动重试","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":496713,"discussion_content":"如果消费者异常，程序会捕获这个异常，等你处理完了再继续消费。如果事件读取与处理在不同线程，那么使用seek方法重设位移值重新消费+处理","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1590750324,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":200407,"user_name":"Sruby","can_delete":false,"product_type":"c1","uid":1016232,"ip_address":"","ucode":"A7D1B93F41DA0F","user_header":"https://static001.geekbang.org/account/avatar/00/0f/81/a8/559afe8b.jpg","comment_is_top":false,"comment_ctime":1585580643,"is_pvip":false,"replies":[{"id":"75001","content":"业务端去重的确是消息去重的一个重要手段","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1585618008,"ip_address":"","comment_id":200407,"utype":1}],"discussion_count":1,"race_medal":1,"score":"1585580643","product_id":100029201,"comment_content":"在消息中增加唯一标识做消息的去重，实现消息去重后再开启自动提交，这样是不是可以简化消息处理的逻辑。","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":490017,"discussion_content":"业务端去重的确是消息去重的一个重要手段","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1585618008,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":171521,"user_name":"Sancho","can_delete":false,"product_type":"c1","uid":1436391,"ip_address":"","ucode":"78849913082622","user_header":"https://static001.geekbang.org/account/avatar/00/15/ea/e7/9ce305ec.jpg","comment_is_top":false,"comment_ctime":1578961013,"is_pvip":false,"replies":[{"id":"66481","content":"5000条消息。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1578968220,"ip_address":"","comment_id":171521,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1578961013","product_id":100029201,"comment_content":"文中的场景：poll方法返回5000条消息，指的是5000条消息集合，还是单条消息？如果是单条消息的话，处理完100条单条消息就提交位移，会导致Broker解开消息集合吗？<br>我的猜测：不会解开消息集合，如果5000条消息在一个消息集合里，就算没有被完全提交位移，下次重新poll时，还是会返回5000条完整的消息集合，只不过此时消费位移不是从这5000条的开始位移，Consumer自然会跳过这部分已经提交过的位移数据，从中间某个位移开始消费消息。","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":481394,"discussion_content":"5000条消息。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1578968220,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":168263,"user_name":"banderSnatch🐱","can_delete":false,"product_type":"c1","uid":1712090,"ip_address":"","ucode":"66C08C96E0D51A","user_header":"https://static001.geekbang.org/account/avatar/00/1a/1f/da/698cd223.jpg","comment_is_top":false,"comment_ctime":1578039777,"is_pvip":false,"replies":[{"id":"65582","content":"抱歉，不太清楚spring-kafka的实现细节。。。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1578280037,"ip_address":"","comment_id":168263,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1578039777","product_id":100029201,"comment_content":"有个问题，spring-kafka框架有控制手动异步提交位移的方法吗？网上查了一些资料都没找到。只有一个Acknowledgement对象的acknowledge()方法手动提交。但是试了一下发现速度比较慢。","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":480175,"discussion_content":"抱歉，不太清楚spring-kafka的实现细节。。。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1578280037,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":166268,"user_name":"w h l","can_delete":false,"product_type":"c1","uid":1170172,"ip_address":"","ucode":"89D52C49E80366","user_header":"https://static001.geekbang.org/account/avatar/00/11/da/fc/49a90c01.jpg","comment_is_top":false,"comment_ctime":1577428654,"is_pvip":false,"replies":[{"id":"63377","content":"不确定百分之百地理解了您的问题。通常来说，当调用KafkaConsumer.close方法时consumer会关闭。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1577435278,"ip_address":"","comment_id":166268,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1577428654","product_id":100029201,"comment_content":"老师，你好，请问一下consume关闭的时机是什么时候呢，这里可以解释下吗","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":479467,"discussion_content":"不确定百分之百地理解了您的问题。通常来说，当调用KafkaConsumer.close方法时consumer会关闭。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577435278,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":153581,"user_name":"James","can_delete":false,"product_type":"c1","uid":1134861,"ip_address":"","ucode":"48B0F2A334D1C1","user_header":"https://static001.geekbang.org/account/avatar/00/11/51/0d/fc1652fe.jpg","comment_is_top":false,"comment_ctime":1574262441,"is_pvip":false,"replies":[{"id":"59024","content":"偶发的提交失败也不一定就意味着重复消费，看consumer程序的运行情况。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1574295841,"ip_address":"","comment_id":153581,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1574262441","product_id":100029201,"comment_content":"你好，请问下分区自动提交失败，请求超时。会导致什么后果呢<br>重复消费吗。","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":475218,"discussion_content":"偶发的提交失败也不一定就意味着重复消费，看consumer程序的运行情况。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1574295841,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1134861,"avatar":"https://static001.geekbang.org/account/avatar/00/11/51/0d/fc1652fe.jpg","nickname":"James","note":"","ucode":"48B0F2A334D1C1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":54332,"discussion_content":"然后多次这样，过段时间直接内存溢出。\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1574296114,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":152609,"user_name":"xiaoniu","can_delete":false,"product_type":"c1","uid":1166713,"ip_address":"","ucode":"837893E7D9691E","user_header":"https://static001.geekbang.org/account/avatar/00/11/cd/79/00dc7885.jpg","comment_is_top":false,"comment_ctime":1574049404,"is_pvip":true,"replies":[{"id":"58750","content":"如果不重启的话，程序里面是否显式调用了seek重新调整了offset呢？如果没有就无法重新消费那些已经消费的消息","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1574130640,"ip_address":"","comment_id":152609,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1574049404","product_id":100029201,"comment_content":"老师 你好 问个问题，Kafka对未提交的消息一定要等到消费工程重启才重新消费吗？比如：我的消费工程 支持幂等性，可以重复消费，但是由于某时刻数据库挂了，导致消息未提交，但隔了一段时间数据库又好了，之前未提交的消息可以在不重启的情况下再次消费下吗？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":474873,"discussion_content":"如果不重启的话，程序里面是否显式调用了seek重新调整了offset呢？如果没有就无法重新消费那些已经消费的消息","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1574130640,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":131216,"user_name":"DFighting","can_delete":false,"product_type":"c1","uid":1233193,"ip_address":"","ucode":"F3BA2426FF8582","user_header":"https://static001.geekbang.org/account/avatar/00/12/d1/29/1b1234ed.jpg","comment_is_top":false,"comment_ctime":1567672589,"is_pvip":true,"replies":[{"id":"49809","content":"我觉得说的挺好的：）","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1567731024,"ip_address":"","comment_id":131216,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1567672589","product_id":100029201,"comment_content":"每个Consumer消费完数据后需要暂存下offset，考虑到一个分区的数据只会被一个当前组下的一个Consumer消费，那么有仨种情况要处理：<br>1、继续消费时，那么可以判断后续poll到的offset和自己保存的值的大小，只消费不小于的消息<br>2、处理最后一个消息时，这时候可以仿照TCP的最后一次挥手中的CLOSE_WAIT状态，设定一个超时时间——这需要结合日常的业务场景，至少要取最大传输时延的2倍，因为大多数情况下消息是不断到达的，所以这个时间设定稍微久远一点也是可以的。<br>3、前两种都是成功消费的情况，如果消费失败导致位移更新失败，那么这个机制就没有任何生效的意义了，这时候重复消费就不可避免了。<br>自己的一些见解，有什么不合适的情况望老师指点一二","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":466339,"discussion_content":"我觉得说的挺好的：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567731024,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":125062,"user_name":"嘉嘉☕","can_delete":false,"product_type":"c1","uid":1059771,"ip_address":"","ucode":"632A5CC4B53BB1","user_header":"https://static001.geekbang.org/account/avatar/00/10/2b/bb/5cf70df8.jpg","comment_is_top":false,"comment_ctime":1566053178,"is_pvip":false,"replies":[{"id":"46042","content":"“还没处理完呢, 就调用了它的close方法” --- 不会啊。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1566181992,"ip_address":"","comment_id":125062,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1566053178","product_id":100029201,"comment_content":"老师, 请问一下, <br>如果consumer拉过来一批消息, 还没处理完呢, 就调用了它的close方法, consumer会继续消费完成吗 ? 还是会做出一些其他的行为 ?<br>谢谢","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":463420,"discussion_content":"“还没处理完呢, 就调用了它的close方法” --- 不会啊。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1566181992,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":124637,"user_name":"钱","can_delete":false,"product_type":"c1","uid":1009652,"ip_address":"","ucode":"2C92A243A463D4","user_header":"https://static001.geekbang.org/account/avatar/00/0f/67/f4/9a1feb59.jpg","comment_is_top":false,"comment_ctime":1565933996,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1565933996","product_id":100029201,"comment_content":"0：位移是指什么？<br>今天我们要聊的位移是 Consumer 的消费位移，它记录了 Consumer 要消费的下一条消息的位移。这可能和你以前了解的有些出入，不过切记是下一条消息的位移，而不是目前最新消费消息的位移。<br>consumer侧的位移，表示consumer消费消息的进度和即将要消费的消息在分区中的具体位置。<br><br>1：提交位移是指什么意思？<br>Consumer 需要向 Kafka 汇报自己的位移数据，这个汇报过程被称为提交位移（Committing Offsets）。因为 Consumer 能够同时消费多个分区的数据，所以位移的提交实际上是在分区粒度上进行的，即Consumer 需要为分配给它的每个分区提交各自的位移数据<br><br>2：提交位移的作用是啥？<br>提交位移主要是为了表征 Consumer 的消费进度，这样当 Consumer 发生故障重启之后，就能够从 Kafka 中读取之前提交的位移值，然后从相应的位移处继续消费，从而避免整个消费过程重来一遍。换句话说，位移提交是 Kafka 提供给你的一个工具或语义保障，你负责维持这个语义保障，即如果你提交了位移 X，那么 Kafka 会认为所有位移值小于 X 的消息你都已经成功消费了。<br><br>2：提交位移的方式有哪些？<br>从用户的角度来说，位移提交分为自动提交和手动提交；从 Consumer 端的角度来说，位移提交分为同步提交和异步提交。<br>自动提交位移，嫩个保证消息不丢失，但是可能存在消息的重复消费。<br>手动提交位移，kafka提供了同步和异步的API，老师也提供了手动提交的代码范例。<br>老师推荐手动提交，灵活，可控，同步异步结合使用。<br>需要注意的是位移提交如果错误会出现消息丢失或重复消费的情况。手动提交时，位移提交的语义保障是由我们自己来负责的，Kafka 只会“无脑”地接受我们提交的位移。我们对位移提交的管理直接影响了我们的 Consumer 所能提供的消息语义保障。<br><br>请问老师，手动提交位移时，kafka对边界值有校验嘛？比如：一个分区有0～9十个位置，我传过去一个-1或者11，kafka会将所有消息重复消费或全部丢掉嘛？<br>业务侧来进行消息去重，可以利用数据库的唯一索引，这需要一个唯一的业务字段，比如：订单号<br>如果不能利用数据库来做，我觉得可以缓存消息，然后用于消息去重，消息重复发送的时机应该时差比较短。<br>再请教一个问题，假如现在只有一个producer、一个broker、一个分区、一个consumer，位移从producer的角度有一个，从consumer的角度有一个，不过全是针对这一个分区而言的对吗？如果是，我还想再问一次分区的数据结构是什么？看之前的图像是数组，是不是数组呢？如果是，一端负责写入数据，一端负责读取数据，都是通过位移来控制的，也能理解。只是这数组的长度和删除消息的操作怎么控制的呢？<br>","like_count":0},{"had_liked":false,"id":122717,"user_name":"Devin","can_delete":false,"product_type":"c1","uid":1025067,"ip_address":"","ucode":"7BDCD517BD8DD2","user_header":"https://static001.geekbang.org/account/avatar/00/0f/a4/2b/3ba9f64b.jpg","comment_is_top":false,"comment_ctime":1565501188,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1565501188","product_id":100029201,"comment_content":"“手动异步提交位移”理论上是不是容易出现重复消费的情况？<br>举例：A分区当前消费者位移是100，consumer 继续消费 101~200，然后调用异步 commitAsync(201)，假设在commitAsync(201)还未被成功处理完成前 consumer 又去取消息，这时取的消息还是 101~200 吧，那这就“重复消费”了。<br>如果举例成立的话，感觉这个理论上还是比价容易发生的，如何避免？","like_count":0,"discussions":[{"author":{"id":1613002,"avatar":"https://wx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK8ZEzZjlpMkibWlbuyablZ4An03be8uGBYqU95yIxQeicHFqnSiaqiaiaTxZRlWSh9R1qMYG3OLcVrhUw/132","nickname":"Geek_d62be1","note":"","ucode":"68EBEBC8B637EB","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":19676,"discussion_content":"offset在内存中应该是有值的，类似于全局变量，每次去获取消息，用的是内存中的offset,提交位移，只是为了恢复或者rebalence等情况保证消息语义使用的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1569216056,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":121937,"user_name":"盘尼西林","can_delete":false,"product_type":"c1","uid":1197347,"ip_address":"","ucode":"B59569FC25144F","user_header":"https://static001.geekbang.org/account/avatar/00/12/45/23/28311447.jpg","comment_is_top":false,"comment_ctime":1565252711,"is_pvip":false,"replies":[{"id":"44818","content":"到底是丢失还是重复呢？自动提交应该不会造成数据丢失，但确实可能造成数据重复","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1565276895,"ip_address":"","comment_id":121937,"utype":1}],"discussion_count":3,"race_medal":0,"score":"1565252711","product_id":100029201,"comment_content":"我也有一个疑问就是自动提交rebalance导致数据丢失的情况，是不是 自动提交的时候当consumer消费完一个数据的时候，此时的offset没有被提交 而是在内存中等待后台cron线程 或者下次poll的时候刷入磁盘，中间发生重启或者rebalance这部分数据就丢失了，最后导致重复消费","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":462014,"discussion_content":"到底是丢失还是重复呢？自动提交应该不会造成数据丢失，但确实可能造成数据重复","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1565276895,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1980201,"avatar":"https://static001.geekbang.org/account/avatar/00/1e/37/29/b3af57a7.jpg","nickname":"凯文小猪","note":"","ucode":"36D8AD0229547F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":398458,"discussion_content":"数据是不会丢失 他们已经通过追加的方式写入日志 除非日志持久化失败。那也就意味着偏移量可能会误报 这就是重消费的由来","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1632795410,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1197347,"avatar":"https://static001.geekbang.org/account/avatar/00/12/45/23/28311447.jpg","nickname":"盘尼西林","note":"","ucode":"B59569FC25144F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":7091,"discussion_content":"丢失offset","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567353767,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":121705,"user_name":"james","can_delete":false,"product_type":"c1","uid":1049208,"ip_address":"","ucode":"5701899403917C","user_header":"https://static001.geekbang.org/account/avatar/00/10/02/78/23c56bce.jpg","comment_is_top":false,"comment_ctime":1565187795,"is_pvip":false,"replies":[{"id":"44745","content":"看你的场景了。消费者碰到严重异常要退出也是很正常的情况","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1565225068,"ip_address":"","comment_id":121705,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1565187795","product_id":100029201,"comment_content":"老师，异步和同步结合那段代码，当消费出异常就在finally中把消费者close了？？不是这样的吧，消费者永远不应该close","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":461913,"discussion_content":"看你的场景了。消费者碰到严重异常要退出也是很正常的情况","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1565225068,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":119634,"user_name":"EricJones","can_delete":false,"product_type":"c1","uid":1207580,"ip_address":"","ucode":"0A80B609400D6B","user_header":"https://static001.geekbang.org/account/avatar/00/12/6d/1c/d9746372.jpg","comment_is_top":false,"comment_ctime":1564641928,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1564641928","product_id":100029201,"comment_content":"老师手动提交的设计很优美，先用异步提交不影响程序的性能，再用consumer关闭时同步提交来确保位移一定提交成功。这里我有个疑问，比如我程序运行期间有多次异步提交没有成功，比如101的offset和201的offset没有提交成功，程序关闭的时候501的offset提交成功了，是不是就代表前面500条我还是消费成功了，只要最新的位移提交成功，就代表之前的消息都提交成功了？<br>老师这个问题 岂不是丢数据了？<br>commitAsync 异步提交，然后会继续消费 poll 的消息，比如上一个poll 到 101 下面一个到 201。上一个到101 位移消息提交了。继续消费101-201的消息。这是已经消费到200了，上次poll 的消息 101位移提交失败，然后在调用 commitSync 同步提交这里的逻辑，然后已经消费到200 的消息不是就白消费了？这里应该是怎么个逻辑？是consumer 关闭，然后在poll 消息那还是poll 的101-201 。刚才的消费到200 就又重复了。","like_count":0},{"had_liked":false,"id":117793,"user_name":"老鱼","can_delete":false,"product_type":"c1","uid":1221974,"ip_address":"","ucode":"2C873D9E34CB00","user_header":"https://static001.geekbang.org/account/avatar/00/12/a5/56/d1f70c0d.jpg","comment_is_top":false,"comment_ctime":1564132095,"is_pvip":false,"replies":[{"id":"43218","content":"不是，是向位移主题提交位移","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1564216299,"ip_address":"","comment_id":117793,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1564132095","product_id":100029201,"comment_content":"老师，poll时会自动提交位移，这里的位移是分区中位移主题的位移？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":460119,"discussion_content":"不是，是向位移主题提交位移","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1564216299,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":116077,"user_name":"来碗绿豆汤","can_delete":false,"product_type":"c1","uid":1070051,"ip_address":"","ucode":"B0AB63B8D9729F","user_header":"https://static001.geekbang.org/account/avatar/00/10/53/e3/39dcfb11.jpg","comment_is_top":false,"comment_ctime":1563782366,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1563782366","product_id":100029201,"comment_content":"如果消息被处理了，但是offset提交失败，那从broker的角度来看就是消息没被处理，下次肯定还会重复被消费；但是从consumer的角度看的话是消息被处理了，然后又要被处理一遍。这时候如果我们的业务逻辑如果是等幂的，则无所谓；如果不是，我能相对两种方案：1， 有个事务存在，数据处理和提交offset在一个事务里面，如果有一个失败则都回滚；2，自己在业务逻辑端加一个验证，判断消息是否是重复消费。","like_count":0},{"had_liked":false,"id":115106,"user_name":"曹伟雄","can_delete":false,"product_type":"c1","uid":1400754,"ip_address":"","ucode":"9740E426C0742C","user_header":"https://static001.geekbang.org/account/avatar/00/15/5f/b2/c4780c10.jpg","comment_is_top":false,"comment_ctime":1563496176,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1563496176","product_id":100029201,"comment_content":"老师你好，能否说一下spring kafka手到提交的最佳实践，谢谢!","like_count":0},{"had_liked":false,"id":114819,"user_name":"lujg","can_delete":false,"product_type":"c1","uid":1054963,"ip_address":"","ucode":"6CCCD89A29B06D","user_header":"https://static001.geekbang.org/account/avatar/00/10/18/f3/cd07e64c.jpg","comment_is_top":false,"comment_ctime":1563412136,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1563412136","product_id":100029201,"comment_content":"其实总结来说1，2，4都是在消费者端缩短poll到commit间的处理时间，而3是增加poll到commit间允许的时长，从而确保poll到commit间的时间小于系统配置的时间。","like_count":0},{"had_liked":false,"id":114720,"user_name":"信信","can_delete":false,"product_type":"c1","uid":1303865,"ip_address":"","ucode":"8DF0EC045579FD","user_header":"https://static001.geekbang.org/account/avatar/00/13/e5/39/951f89c8.jpg","comment_is_top":false,"comment_ctime":1563370180,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1563370180","product_id":100029201,"comment_content":"和一楼有同样的疑惑：同时使用commitSync() 和 commitAsync()方案，一样可能会出现：早已经“过期”或不是最新值了 的情况啊。。。因为异步返回exception 的时候，可能出错的那条消息之后的位移已经被更新了。","like_count":0,"discussions":[{"author":{"id":1470958,"avatar":"https://static001.geekbang.org/account/avatar/00/16/71/ee/31b19304.jpg","nickname":"小可爱","note":"","ucode":"5379D1F00E8796","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":6500,"discussion_content":"我也是诶","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1566931277,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":114516,"user_name":"Jason_鹏","can_delete":false,"product_type":"c1","uid":1179329,"ip_address":"","ucode":"4A3DCAAC531724","user_header":"https://static001.geekbang.org/account/avatar/00/11/fe/c1/6c99fff4.jpg","comment_is_top":false,"comment_ctime":1563328233,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1563328233","product_id":100029201,"comment_content":"自动提交也会出现消息丢失的情况吧，例如消费者poll了10个条消息，假设这10条消息的偏移量是0到9，当消费者消费到偏移量为5的消息时，自动提交消费位移为10，后续发生rbalance或者消费者异常重启，再次poll时会poll偏移量为10的消息，那6到9的消息就丢失了。","like_count":0,"discussions":[{"author":{"id":1308502,"avatar":"https://wx.qlogo.cn/mmopen/vi_32/DYAIOgq83erabhkvu3jKSia1Y3l7pvicBy1YibN6GuIxLuZmI9E9icR8zdjP7BZ570PsDXv7ZLlMTU4Xr3Xz6N9bZg/132","nickname":"Geek_669721","note":"","ucode":"631471460ACFF3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":23510,"discussion_content":"这种情况不会自动提交的，自动提交会在下一次poll的时候才会提交上一次的offset","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1569828773,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":114459,"user_name":"james","can_delete":false,"product_type":"c1","uid":1049208,"ip_address":"","ucode":"5701899403917C","user_header":"https://static001.geekbang.org/account/avatar/00/10/02/78/23c56bce.jpg","comment_is_top":false,"comment_ctime":1563322031,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1563322031","product_id":100029201,"comment_content":"可以给消息添加一个key，rocketmq就有的，消费完之后写布隆过滤器，如redis的插件，每次消费前看里面有没有，但是消费成功插布隆过滤器有可能失败就又无解了，哈哈","like_count":0},{"had_liked":false,"id":114399,"user_name":"October","can_delete":false,"product_type":"c1","uid":1137879,"ip_address":"","ucode":"CEDA78F4A5F8B1","user_header":"https://static001.geekbang.org/account/avatar/00/11/5c/d7/e4673fde.jpg","comment_is_top":false,"comment_ctime":1563289843,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1563289843","product_id":100029201,"comment_content":"我认为避免重复消费这个问题是要有条件的，需要保证偏移量的提交和消息的消费能够在一个支持回滚的事务内进行，偏移量可以回滚，消息的消费也可以回滚，比如消息的消费逻辑是存入RDBMS，可以明显看出这种方式的应用场景非常局限。其他避免重复消费的问题，还得请老师指正。","like_count":0},{"had_liked":false,"id":114320,"user_name":"Walking In The Air","can_delete":false,"product_type":"c1","uid":1198231,"ip_address":"","ucode":"8142444472AD8E","user_header":"https://static001.geekbang.org/account/avatar/00/12/48/97/520f3511.jpg","comment_is_top":false,"comment_ctime":1563271823,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1563271823","product_id":100029201,"comment_content":"老师有没有了解过nats, 能不能做个简单对比说下","like_count":0},{"had_liked":false,"id":114291,"user_name":"Geek_817ea4","can_delete":false,"product_type":"c1","uid":1579066,"ip_address":"","ucode":"D1194D33C4DC11","user_header":"https://static001.geekbang.org/account/avatar/00/18/18/3a/b407889c.jpg","comment_is_top":false,"comment_ctime":1563266753,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1563266753","product_id":100029201,"comment_content":"val redisManage: Map[TopicPartition, Long] = new RedisOffset().getLastCommittedOffsets(properties.getProperty(&quot;topic&quot;))<br>    val result: InputDStream[ConsumerRecord[String, String]] = if (redisManage.isEmpty) {<br>      KafkaUtils.createDirectStream[String, String](sc, LocationStrategies.PreferConsistent, ConsumerStrategies.Subscribe[String, String](topics, kafkaPrograms))<br>    } else {<br>      KafkaUtils.createDirectStream[String, String](sc, LocationStrategies.PreferConsistent, ConsumerStrategies.Assign[String, String](redisManage.keys, kafkaPrograms, redisManage))<br>    }<br>    &#47;&#47;业务逻辑处理<br>    result.foreachRDD({ (rdd: RDD[ConsumerRecord[String, String]]) =&gt;<br>      &#47;&#47;获取Jedis对象<br>      val jedis: Jedis = new RedisClient().getJedis<br>      &#47;&#47;获得偏移量对象数组<br>      val offsetRanges: Array[OffsetRange] = rdd.asInstanceOf[HasOffsetRanges].offsetRanges<br>      rdd.foreachPartition({ (it: Iterator[ConsumerRecord[String, String]]) =&gt;<br>        &#47;&#47;数据逻辑处理<br>        it.foreach(f = (pair: ConsumerRecord[String, String]) =&gt; {<br>\t\t逻辑代码略<br>        })<br>      })<br>      &#47;&#47;更新offset<br>      offsetRanges.foreach { (offsetRange: OffsetRange) =&gt;<br>        jedis.hset(properties.getProperty(&quot;group.id&quot;), offsetRange.topic + &quot;-&quot; + offsetRange.partition, offsetRange.untilOffset.toString)<br>      }<br>我是把offset保存在了redis，虽然不会丢数据，但是还是会发生会重复消费，应该怎么设计！","like_count":0},{"had_liked":false,"id":114155,"user_name":"Dovelol","can_delete":false,"product_type":"c1","uid":1253384,"ip_address":"","ucode":"9B5DDF7720F307","user_header":"https://static001.geekbang.org/account/avatar/00/13/20/08/bc06bc69.jpg","comment_is_top":false,"comment_ctime":1563244040,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1563244040","product_id":100029201,"comment_content":"老师还，还是关于几个时间参数的配置和重复消费，前提是自动提交，参数和代码为：max.poll.interval.ms=5s，auto.commit.interval.ms=10s，consumer.poll(Duration.ofSeconds(1))，然后在consumer while(true)最后Thread.sleep(6000L); 休眠6s，发现会一直重复消费，这是为什么呢，通过控制变量法= =，我发现只要consumer消费的时间大于max.poll.interval.ms的设置，就会一直重复消费，也就是没有成功提交offset吗？为什么和max.poll.interval.ms有关系呢，反而和auto.commit.interval.ms没关系似的，老师能详细讲讲吗？我看kafka默认的max.poll.interval.ms=300s，是不是不应该把这个时间调的太小，这样会引起重复消费。","like_count":0},{"had_liked":false,"id":114100,"user_name":"Liam","can_delete":false,"product_type":"c1","uid":1094597,"ip_address":"","ucode":"1D15D3B64F2606","user_header":"https://static001.geekbang.org/account/avatar/00/10/b3/c5/7fc124e2.jpg","comment_is_top":false,"comment_ctime":1563238178,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1563238178","product_id":100029201,"comment_content":"追问我的上一个问题：为什么说是一个时机，是因为5s poll一次吗","like_count":0},{"had_liked":false,"id":114004,"user_name":"德惠先生","can_delete":false,"product_type":"c1","uid":1178969,"ip_address":"","ucode":"FD8AEBEC32085F","user_header":"https://static001.geekbang.org/account/avatar/00/11/fd/59/4416b40f.jpg","comment_is_top":false,"comment_ctime":1563202922,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1563202922","product_id":100029201,"comment_content":"普通的做法是用redis或者数据库做一个消费锁，消费之前获取，消费之后释放。获取到之后如果发现已经被消费过则丢弃这次消费。但这样的做法需要引入新的外部依赖，会变得很重，而且对消费性能也会影响，并且中央式服务也容易成为扩展的瓶颈。老师有什么好方法吗？","like_count":0},{"had_liked":false,"id":113957,"user_name":"Dovelol","can_delete":false,"product_type":"c1","uid":1253384,"ip_address":"","ucode":"9B5DDF7720F307","user_header":"https://static001.geekbang.org/account/avatar/00/13/20/08/bc06bc69.jpg","comment_is_top":false,"comment_ctime":1563194078,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1563194078","product_id":100029201,"comment_content":"老师好，还是consumer消费的问题，我看有人问了，如果自动提交时间设置为20s，那么中间消费完了，然后又去拉取新消息，怎么保证不重复消费呢？我看回复的是“consumer内部有个指针，会探测到下一条要消费的数据”，这个意思是虽然没有提交offset，但是consumer端有自己的offset，可以保证从上次消费过后的位置拉取新消息，如果在这个中间，consumer挂了，那就会有重复消费的情况。是这样的吗？这样的话其实consumer消费数据是和这个指针的位置有关系，至于提交的offset仅仅是为了保证consumer关闭重启时确定开始消费的位置。还有一种方式是，consumer每次消费数据就是以提交的offset为准，把这些数据都拉取到，但是consumer端会按照自己的指针，只处理指针位置后面的数据，之前的数据跳过掉。","like_count":0},{"had_liked":false,"id":113767,"user_name":"曾轼麟","can_delete":false,"product_type":"c1","uid":1451391,"ip_address":"","ucode":"D418371AC11270","user_header":"https://static001.geekbang.org/account/avatar/00/16/25/7f/473d5a77.jpg","comment_is_top":false,"comment_ctime":1563153314,"is_pvip":false,"replies":[{"id":"41413","content":"是的","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563156036,"ip_address":"","comment_id":113767,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1563153314","product_id":100029201,"comment_content":"不过老师有一个问题，poll下来的数据是有序的吗？同一个partition中各个消息的相对顺序，当然不同partition应该是不一定的","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":458375,"discussion_content":"是的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563156036,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":113765,"user_name":"曾轼麟","can_delete":false,"product_type":"c1","uid":1451391,"ip_address":"","ucode":"D418371AC11270","user_header":"https://static001.geekbang.org/account/avatar/00/16/25/7f/473d5a77.jpg","comment_is_top":false,"comment_ctime":1563153154,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1563153154","product_id":100029201,"comment_content":"我们目前的做法是kafka消费前都有一个消息接口表，可以使用Redis或者MySQL(Redis只存最近100个消息)，然后会设置consumer拉取消息的大小极限，保证消息数量不超过100(这个阈值可以自行调整)，其中我们会保证kafka消息的key是全局唯一的，比如使用雪花算法，在进行消费的时候可以通过前置表进行幂等性去重","like_count":0},{"had_liked":false,"id":113754,"user_name":"ikimiy","can_delete":false,"product_type":"c1","uid":1067295,"ip_address":"","ucode":"CC67E87B99EE3C","user_header":"https://static001.geekbang.org/account/avatar/00/10/49/1f/37e18877.jpg","comment_is_top":false,"comment_ctime":1563151833,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1563151833","product_id":100029201,"comment_content":"老师 consumer offset在spark程序中如何控制手动提交的 有没有sample code可以参考的 thks","like_count":0},{"had_liked":false,"id":113753,"user_name":"calljson","can_delete":false,"product_type":"c1","uid":1505262,"ip_address":"","ucode":"A5F81A6A5B4497","user_header":"https://static001.geekbang.org/account/avatar/00/16/f7/ee/6eeb58a3.jpg","comment_is_top":false,"comment_ctime":1563151808,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1563151808","product_id":100029201,"comment_content":"避免重复消费：<br>1. （不考虑rebalance）producer在生成消息体是，里面加上唯一标识符比如：唯一Id，即保证消息的幂等性，consumer在处理消息的过程中，将消费后的消息Id存储到数据库中或者redis，等消息处理完毕后在手动提交offset<br>2. （考虑rebalance）监听consumer的rebalance，rebalance发生前将topic-partion-offset存入数据库，rebalance后根据获取到的分区信息到数据库中查找上次消费到的位置seek到上次消费位置，在处理消息中，利用数据库事务管理处理消息<br>2. ","like_count":0,"discussions":[{"author":{"id":1618482,"avatar":"https://static001.geekbang.org/account/avatar/00/18/b2/32/d26f92c5.jpg","nickname":"墨小雨的猫","note":"","ucode":"A14EBA5949837D","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":8047,"discussion_content":"怎么知道rebalance即将发生？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1567766446,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":113689,"user_name":"z.l","can_delete":false,"product_type":"c1","uid":1181055,"ip_address":"","ucode":"805CC5784D3F76","user_header":"https://static001.geekbang.org/account/avatar/00/12/05/7f/d35ab9a1.jpg","comment_is_top":false,"comment_ctime":1563118842,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1563118842","product_id":100029201,"comment_content":"消费者端实现消费幂等。具体做法：创建本地消息表，以messageId作为主键。消费消息的同时也插入消息表，把消费逻辑的sql语句和消息表的insert语句放在同一个数据库事务中。","like_count":0},{"had_liked":false,"id":113549,"user_name":"电光火石","can_delete":false,"product_type":"c1","uid":1013160,"ip_address":"","ucode":"3AD33BB4AA940F","user_header":"https://static001.geekbang.org/account/avatar/00/0f/75/a8/dfe4cade.jpg","comment_is_top":false,"comment_ctime":1563075358,"is_pvip":false,"replies":[{"id":"41417","content":"可以控制，使用KafkaConsumer.seek可以精确控制你要开始消费的位移","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563156672,"ip_address":"","comment_id":113549,"utype":1}],"discussion_count":3,"race_medal":0,"score":"1563075358","product_id":100029201,"comment_content":"老师好，consumer的api在读取的时候能指定从某个partition的某个offset开始读取吗？看参数只能用latest,oldest进行指定，然后用kafka记录的offset进行读取，我们能自己控制起始的offset吗，这样可以做更精准的exact once的语义","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":458273,"discussion_content":"可以控制，使用KafkaConsumer.seek可以精确控制你要开始消费的位移","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563156672,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1134861,"avatar":"https://static001.geekbang.org/account/avatar/00/11/51/0d/fc1652fe.jpg","nickname":"James","note":"","ucode":"48B0F2A334D1C1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":52450,"discussion_content":"马克","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1574052462,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1009260,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/66/6c/4a68a916.jpg","nickname":"双叶","note":"","ucode":"6DA1D477F9D580","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":1950,"discussion_content":"可以 seek","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563116030,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":113494,"user_name":"ban","can_delete":false,"product_type":"c1","uid":1034204,"ip_address":"","ucode":"E523CE97E48266","user_header":"https://static001.geekbang.org/account/avatar/00/0f/c7/dc/9408c8c2.jpg","comment_is_top":false,"comment_ctime":1563031425,"is_pvip":false,"replies":[{"id":"41419","content":"try不是在while外面吗？","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563156769,"ip_address":"","comment_id":113494,"utype":1}],"discussion_count":3,"race_medal":0,"score":"1563031425","product_id":100029201,"comment_content":"老师，有个疑问。commitSync 和 commitAsync 组合这个代码，捕获异常在while循环外面，如果发生异常不就不走了吗，程序也就停止。是不是放在while循环比较好，既可以处理异常，还能提交偏移量，还能继续消费处理消息？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":458249,"discussion_content":"try不是在while外面吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563156769,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1034204,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/c7/dc/9408c8c2.jpg","nickname":"ban","note":"","ucode":"E523CE97E48266","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":1981,"discussion_content":"放在while循环里面，这样处理完异常还能继续消费消息","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1563160752,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1034204,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/c7/dc/9408c8c2.jpg","nickname":"ban","note":"","ucode":"E523CE97E48266","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":1982,"discussion_content":"这样会不会更好一点","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563160812,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":113464,"user_name":"明翼","can_delete":false,"product_type":"c1","uid":1068361,"ip_address":"","ucode":"E77F86BEB3D5C1","user_header":"https://static001.geekbang.org/account/avatar/00/10/4d/49/28e73b9c.jpg","comment_is_top":false,"comment_ctime":1563023378,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1563023378","product_id":100029201,"comment_content":"有同学问offset是否在内存控制等问题，可能是没用过kafka，kafka的消费者启动时候可以设置参数从什么位置开始读，有的是从最新的开始读，有的是从最老的开始读，从最新位置读就是从上次提交的位移读，所以提交的offset是用作下一次程序启动或重新平衡后读取的位置的。同样像老师这种先异步再同步提交数据的场景如果一次拉500条数据，消费到200条之后异常了，同步提交是提交500条的，我觉得是不是可以类似下面分批提交的方法提交不知道此方法有同步的吗？有的话应该会比较完美解决。<br><br>对于老师的问题，想不重复只有自己在程序中保留offsetid.如果后端系统有数据库类似数据库主建机制，可以用这个方法判断，插入报约束冲突就忽视…","like_count":0,"discussions":[{"author":{"id":1034204,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/c7/dc/9408c8c2.jpg","nickname":"ban","note":"","ucode":"E523CE97E48266","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":1890,"discussion_content":"文中已经有分批同步的方法\ncommitSync(Map<TopicPartition, OffsetAndMetadata>)","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563037705,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":113453,"user_name":"蛋炒番茄","can_delete":false,"product_type":"c1","uid":1095049,"ip_address":"","ucode":"3F963347C4A97C","user_header":"https://static001.geekbang.org/account/avatar/00/10/b5/89/9a1b4dee.jpg","comment_is_top":false,"comment_ctime":1563015536,"is_pvip":false,"replies":[{"id":"41421","content":"不能绝对保证","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563156927,"ip_address":"","comment_id":113453,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1563015536","product_id":100029201,"comment_content":"自动提交就一定能够保证不丢消息吗？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":458230,"discussion_content":"不能绝对保证","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563156927,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1308401,"avatar":"https://static001.geekbang.org/account/avatar/00/13/f6/f1/5ccbe3fe.jpg","nickname":"老醋","note":"","ucode":"D6DF921AAB9E7A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":1936,"discussion_content":"能吧，老师讲了下次pool时先提交上次消费的位移，只可能导致重复消费的情况","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563108870,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":113380,"user_name":"科莫湖畔的球童","can_delete":false,"product_type":"c1","uid":1025780,"ip_address":"","ucode":"E63B6D4F7EA129","user_header":"https://static001.geekbang.org/account/avatar/00/0f/a6/f4/f641a356.jpg","comment_is_top":false,"comment_ctime":1562988975,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1562988975","product_id":100029201,"comment_content":"Consumer自己记录一下最近一次已消费的offset","like_count":0},{"had_liked":false,"id":113365,"user_name":"海贼王","can_delete":false,"product_type":"c1","uid":1396015,"ip_address":"","ucode":"EAF7CE34AF05DC","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/T2WIS5gJVKoeQHPohZ0SkCZRjChjyqRJ7v0Urw2UTuWrUX3mBb3Om0PGGRFosb6Avibyab4661jCqrTsFrnPC6A/132","comment_is_top":false,"comment_ctime":1562984681,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1562984681","product_id":100029201,"comment_content":"自动提交也可能出现消息丢失的情况，如果拉取消息和处理消息是两个线程去处理的就可能发生拉取线程拉取了两次，处理线程第一次的消息没处理完，崩溃恢复后再消费导致可能丢失某些消息。不过我觉得这不能怪kafka了，这种丢失超出kafka的责任边界了","like_count":0},{"had_liked":false,"id":113358,"user_name":"lmtoo","can_delete":false,"product_type":"c1","uid":1133918,"ip_address":"","ucode":"FCD5B9C941D448","user_header":"https://static001.geekbang.org/account/avatar/00/11/4d/5e/c5c62933.jpg","comment_is_top":false,"comment_ctime":1562984019,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1562984019","product_id":100029201,"comment_content":"关于业务去重的逻辑，可以考虑在业务字段里加一个txid，用consumer的offset值表示事务id，如果有这个id表示被处理过了，如果没有，则表示还没处理过，这样可以利用mysql或者MongoDB来实现避免重复消费","like_count":0},{"had_liked":false,"id":113347,"user_name":"nico","can_delete":false,"product_type":"c1","uid":1209075,"ip_address":"","ucode":"DDB5EFE9F3A70E","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Pr8laRQY3skrzzgen37ZIt4HQvtaThAcqvyK8eAzc9DRiak803q5HS7gCnXFxpx6CWibqT1Sic0h1TLMmVNUpJRibA/132","comment_is_top":false,"comment_ctime":1562982074,"is_pvip":true,"replies":[{"id":"41424","content":"要看数据量是否skewed","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563157282,"ip_address":"","comment_id":113347,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1562982074","product_id":100029201,"comment_content":"老师，请教个问题，我这面用spring的注解方式消费kafka消息，使用的是手动提交位移，我将一个java应用，部署在两台机器上面启动，同一个消费组，一共30个partition,发现部分1-25的partition堆积，25-30的消费正常，这个要怎么分析？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":458179,"discussion_content":"要看数据量是否skewed","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563157282,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1209075,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Pr8laRQY3skrzzgen37ZIt4HQvtaThAcqvyK8eAzc9DRiak803q5HS7gCnXFxpx6CWibqT1Sic0h1TLMmVNUpJRibA/132","nickname":"nico","note":"","ucode":"DDB5EFE9F3A70E","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":2101,"discussion_content":"数据没有skewed,堆积的partition和没有堆积的，生产的offset都在一个范围","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563259849,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}