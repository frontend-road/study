{"id":225505,"title":"58 | 神经网络的训练：学习率和Warm-up","content":"<p><strong>课件和Demo地址</strong><br>\n<a href=\"https://gitee.com/geektime-geekbang/NLP\">https://gitee.com/geektime-geekbang/NLP</a></p>","comments":[{"had_liked":false,"id":207226,"user_name":"小川","can_delete":false,"product_type":"c3","uid":1688300,"ip_address":"","ucode":"F4DB89C6379E08","user_header":"https://static001.geekbang.org/account/avatar/00/19/c2/ec/0ed5f9e5.jpg","comment_is_top":false,"comment_ctime":1587028937,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100046401,"comment_content":"王老师讲的很好，补充：针对cv领域关于lr,wd等超参优化(hpo)现已经过大规模Automl可以搜出来在特定数据集上比较work的超参，Amazon Web Services团队paper 《Bag of Tricks for Image Classification with Convolutional Neural Networks》做了一些ensemble的工作，code也realease，值得推荐。","like_count":2},{"had_liked":false,"id":252891,"user_name":"冷谦","can_delete":false,"product_type":"c3","uid":1238093,"ip_address":"","ucode":"AC38FFE7B36AAA","user_header":"https://static001.geekbang.org/account/avatar/00/12/e4/4d/0f8bbda1.jpg","comment_is_top":false,"comment_ctime":1602507655,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":2,"product_id":100046401,"comment_content":"想问下老师adam和warm-up更推荐使用哪种方式呢 我一般都是无脑Adam,,\n","like_count":0,"discussions":[{"author":{"id":1341502,"avatar":"https://static001.geekbang.org/account/avatar/00/14/78/3e/f60ea472.jpg","nickname":"grok","note":"","ucode":"4744AB3FA28FE2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":635094,"discussion_content":"Adam 和 Warm-up 是两种不同的概念，可以配合使用，而不是相互替代。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1704410521,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"美国","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":208905,"user_name":"行者","can_delete":false,"product_type":"c3","uid":1885085,"ip_address":"","ucode":"BE28413DD00A5F","user_header":"https://static001.geekbang.org/account/avatar/00/1c/c3/9d/f23a9458.jpg","comment_is_top":false,"comment_ctime":1587462057,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100046401,"comment_content":"每调一次lr或其它超参数都要重新训练吗 调了参数后训练，是否需要先加载上次保存的模型参数以加快训练速度，还是说从0开始训练","like_count":0}]}