{"id":806130,"title":"02｜对话模式：构建RAG应用的核心密码之一","content":"<p>你好，我是叶伟民。</p><p>上一节课我们看到，使用RAG改造之后的MIS系统，从以前的通过增删改查界面与数据交互变成了通过一问一答的对话模式交互。是的，所有RAG应用本质上都是通过对话模式交互的，即使少数看起来不是对话模式的RAG应用（例如后面几节提到的返回结构化数据的应用），其底层也是通过对话模式交互的。</p><p>今天我们就来深入探索上一节课的基础对话模式，为后面的实现环节打好基础。</p><h2>对话模式以及相关概念</h2><p>对话模式顾名思义，就是两个角色进行对话。体现在RAG里面，就是用户与AI进行对话。例如：</p><pre><code class=\"language-sql\">用户：客户A的款项到账了多少？\nAI：已到账款项为57980。\n</code></pre><h3>用户、AI与系统</h3><p>在RAG里面，以上例子中的用户一般称为<strong>user</strong>（就是用户的英文），但是AI一般称为 <strong>assistant</strong>（助理的英文）。</p><p>比较特殊的是，从ChatGPT（GPT3.5）开始，OpenAI新增了一个角色——<strong>system</strong>（系统的英文），这个角色有助于设置助理的行为。你可以在system角色里面，描述助理在整个对话过程中应该如何表现。于是如果你使用OpenAI的大模型，上述用例就会变成这样：</p><pre><code class=\"language-sql\">系统：你是一个ERP MIS系统\n用户：客户A的款项到账了多少？\nAI：已到账款项为57980。\n</code></pre><!-- [[[read_end]]] --><p>但有两点需要我们注意。第一，系统消息是可选的。第二，目前除了OpenAI之外，很多大模型都不支持系统这一角色。因此我们课程里的对话模式也不会考虑系统角色。</p><h3>记忆</h3><p>正如人类之间的对话不止一个来回，对话模式也是如此。例如以上用例可以扩展为：</p><pre><code class=\"language-sql\">用户：客户A的款项到账了多少？\nAI：已到账款项为57980。\n用户：还剩多少？\nAI：客户A的剩余到账款项为2908元。\n</code></pre><p>我们可以发现，在用户第二次提问时，用户并没有提到“客户A”，也没有提到“款项”和“到账”。但是AI能够正确判断出用户问的是“客户A”还剩多少“款项”没“到账”。那是因为AI根据前面的对话判断出来的，这里前面的对话就叫<strong>记忆（memory）</strong>。</p><p>正如人会遗忘，AI的记忆也是有上限的，不同的大模型甚至同一个大模型在不同版本所支持的记忆上限是不同的，但是有一点是肯定的，就是记忆是有上限的，区别只是上限有多高而已。就像天才和普通人一样，都是会遗忘，只不过天才能够记住的东西更多而已。</p><h3>RAG</h3><p>如何解决保留记忆的问题呢？都说好记性不如烂笔头，AI也同样如此。</p><p>因此在对话模式中，我们可以从我们的“烂笔头”，也就是外部的知识库（数据库）检索出相关的知识放进对话模式里面，这就是我们这门课程的主题——RAG。</p><p>RAG全称是“Retrieval-Augmented Generation”，即“检索增强的生成”。</p><p>RAG的核心思想是利用外部知识库或数据集来辅助模型的生成过程。具体来说，RAG通常包含以下关键步骤。</p><ol>\n<li>检索阶段：首先，模型会根据输入的查询或问题，从预先构建的索引中检索出最相关的数据、文档或文本片段。这些数据、文档或片段在我们这门课程中将会是你熟悉的MIS关系数据库里面的数据（实战案例1）、日常看的IT技术新闻（实战案例3）等等。</li>\n<li>生成阶段：随后，模型会使用这个综合的表示来生成答案或输出文本。在问答任务中，这通常意味着生成一个对原始查询的直接回答。</li>\n</ol><p>通俗地讲，就是用户问AI一个问题，然后AI马上去知识库（类似于翻书、翻词典）找到对应的词条，然后根据这个词条回答用户。</p><p>看过其他文章的同学可能会问，为什么这里少了两个阶段：</p><ol>\n<li>编码阶段：检索到的文档或文本片段会与原始查询一起被编码成高维向量（多维数组的专业说法，只不过这里的多维多到几百、上千的那种）。</li>\n<li>融合阶段：编码后的向量会进行融合，以生成一个综合的表示，这个表示同时包含了原始查询和检索到的相关信息。</li>\n</ol><p>这个问题问得好，的确很多RAG应用（包括这门课后面的实战案例）是包含以上两个步骤的，也就是说会包含四个阶段：</p><ol>\n<li>检索阶段</li>\n<li>编码阶段</li>\n<li>融合阶段</li>\n<li>生成阶段</li>\n</ol><p>但是我们的实战案例1并不需要编码和融合阶段，所以我们可以看出，编码和融合阶段并不是RAG应用必需的，检索和生成阶段才是RAG应用必需的。</p><p>根据奥卡姆剃刀原则，如无必要，勿增实体。我们在规划设计一个RAG应用的时候，也尽量勿增实体，如果不需要添加编码和融合阶段，那我们就不添加。在这方面，我们的实战案例1就是一个很好的例子。</p><h2>对话模式在代码上是如何表示的</h2><p>好了，前面讲了这么多，都还是停留在文字上。那么前面的例子和概念在代码上是如何表示的呢？</p><p>前面的例子在OpenAI的ChatGPT表现为：</p><pre><code class=\"language-python\">import openai\nopenai.ChatCompletion.create(\n&nbsp; model=\"gpt-3.5-turbo\",\n&nbsp; messages=[\n&nbsp; &nbsp; &nbsp; &nbsp; {\"role\": \"system\", \"content\": \"你是一个ERP MIS系统\"},\n&nbsp; &nbsp; &nbsp; &nbsp; {\"role\": \"user\", \"content\": \"客户A的款项到账了多少？\"},\n&nbsp; &nbsp; &nbsp; &nbsp; {\"role\": \"assistant\", \"content\": \"已到账款项为57980。\"},\n&nbsp; &nbsp; &nbsp; &nbsp; {\"role\": \"user\", \"content\": \"还剩多少？\"},\n&nbsp; &nbsp; &nbsp; &nbsp; {\"role\": \"assistant\", \"content\": \"剩余到账款项为2908元。\"}\n&nbsp; &nbsp; ]\n)\n</code></pre><p>我们课程里使用了百度ERNIE-Lite-8K大模型，因为它不支持系统（system）角色，所以表现为：</p><pre><code class=\"language-python\">messages=[\n      {\"role\": \"user\", \"content\": \"客户A的款项到账了多少？\"},\n      {\"role\": \"assistant\", \"content\": \"已到账款项为57980。\"},\n      {\"role\": \"user\", \"content\": \"还剩多少？\"},\n      {\"role\": \"assistant\", \"content\": \"剩余到账款项为2908元。\"}\n  ]\n</code></pre><p>其中messages所支持的数量依赖于大模型对记忆的支持。</p><h2>RAG在代码上是如何表示的</h2><p>以上代码还没有用到外部知识库，使用了外部知识库，也就是RAG应用，在代码上是这么表现的：</p><pre><code class=\"language-python\">从外部知识库检索到的知识=\"客户：A 入账日期：2024-07-06T00:00:00Z 入账金额：9527 已到账款项：57980 剩余到账款项：2908&nbsp;\"\n根据外部知识组装的语言 = f\"\"\"\n您已经知道以下信息：\n{从外部知识库检索到的知识},\n请根据以上您所知道的信息回答用户的问题: \n\"\"\"\nmessages=[\n      {\"role\": \"user\", \"content\": 根据外部知识组装的语言 + \"客户A的款项到账了多少？\"},\n      {\"role\": \"assistant\", \"content\": \"已到账款项为57980。\"},\n      {\"role\": \"user\", \"content\": 根据外部知识组装的语言 + \"还剩多少？\"},\n      {\"role\": \"assistant\", \"content\": \"剩余到账款项为2908元。\"}\n  ]\n</code></pre><p>以上代码的第1到6行就是从外部知识库检索的过程。第8行和第10行则是将检索到的外部知识提供给大模型的代码。</p><p>那么从上面的代码中我们能够发现什么规律呢？</p><p>第一，组装之后的知识是放在user角色里面的，而不是assistant角色。这点跟前面的比喻不同。前面比喻提到的流程是：</p><ol>\n<li>用户问AI一个问题。</li>\n<li>然后AI马上去知识库（类似于翻书翻词典）找到对应的词条。</li>\n<li>最后AI根据这个词条回答用户。</li>\n</ol><p>而实际表现在代码上，应该是这样的。</p><ol>\n<li>用户提出一个问题。</li>\n<li>我们的RAG应用马上去知识库（类似于翻书、翻词典）找到对应的词条。</li>\n<li>然后我们的RAG应用把这个词条用语言组装一下再加上用户提出的问题，一起交给AI。</li>\n<li>AI根据我们给出的这些内容进行回答。</li>\n</ol><p>第二，检索到的知识是需要组装的，如果我们直接将代码第1行的知识喂给大模型，而不经过代码第2行的语言进行组装，大模型是很难正确处理的。</p><p>第三，有些同学可能发现，以上示例代码中，检索和组装外部知识的过程过于简单，并不足以支撑整个示例运行。</p><p>是的，为了让你把注意力先聚焦在基础概念上，我对这段代码做了一些简化。而这部分被简化的代码就是RAG应用的核心，这是这门课后续的内容。等同学们学习完后面的实战案例之后，你会发现，以上代码的其他部分基本就定型了，也没有太多的扩展，主要扩展的都是检索和组装外部知识部分的代码。我们下一节课就从检索外部知识所需的基本概念—— 返回结构化数据讲起。</p><h2>小结</h2><p>好了，今天这一讲到这里就结束了，最后我们来回顾一下。这一讲我们学会了两件事情。</p><p>第一件事情是三个概念以及这些概念在代码上的表示。</p><ul>\n<li>第一个概念是对话模式的角色。对话模式可以包括三个角色：用户（user）、AI（assistant）与系统（system）。注意，很多大模型目前还不支持系统角色。即使支持系统角色的大模型，系统角色也不是必需的。</li>\n<li>第二个概念是记忆。通过记忆，用户只需要输入有限的文字，AI就能够根据记忆补全其他信息来回答用户的问题。</li>\n<li>第三个概念就是我们课程的主题RAG。好记性不如烂笔头，RAG就是用外部知识库这个烂笔头来代替记忆。</li>\n</ul><p>第二件事情是RAG的整个流程。用户提出一个问题，我们的RAG应用检索到对应的知识，再加上用户的提问一起交给AI，AI根据这些内容进行回答。</p><p><img src=\"https://static001.geekbang.org/resource/image/d4/63/d470e5afd888f6db3a9dcd04e4f9b663.jpg?wh=7265x2680\" alt=\"\"></p><h2>思考题</h2><p>如果用户与AI进行了一万次对话（一万次应该超出了目前所有大模型的记忆上限），那么我们的应用如何处理呢？</p><p>欢迎你在留言区和我交流互动，如果这节课对你有启发，也推荐分享给身边更多朋友。</p>","neighbors":{"left":{"article_title":"01｜提效利器：RAG为传统MIS系统大幅提效，门槛并不高","id":806091},"right":{"article_title":"03｜返回结构化数据：构建RAG应用的核心密码之二","id":806979}},"comments":[{"had_liked":false,"id":394003,"user_name":"张申傲","can_delete":false,"product_type":"c1","uid":1182372,"ip_address":"北京","ucode":"22D46BC529BA8A","user_header":"https://static001.geekbang.org/account/avatar/00/12/0a/a4/828a431f.jpg","comment_is_top":false,"comment_ctime":1725522406,"is_pvip":false,"replies":[{"id":143064,"content":"回答得很赞！LangChain确实包含了很多内置的组件，我去年也是用LangChain。不过LangChain目前根据实际业务场景定制化的限制太多，随着项目的深入，不得不把LangChain的模块换掉。","user_name":"作者回复","user_name_real":"编辑","uid":1337319,"ctime":1725800441,"ip_address":"广东","comment_id":394003,"utype":1}],"discussion_count":2,"race_medal":2,"score":2,"product_id":100817901,"comment_content":"第2讲打卡~\n思考题：这种多轮对话的场景，通常需要系统支持Memory记忆功能，简单来说就是将用户与LLM的聊天记录保存下来，并在下次生成内容时传递给LLM。常用的记忆模式包括缓冲记忆、摘要记忆、混合记忆、向量数据库记忆等等，这些功能在LangChain中大多包含了内置的组件。关于Memory系统的实现，感兴趣的同学可以参考下我的文章：https:&#47;&#47;blog.csdn.net&#47;weixin_34452850&#47;article&#47;details&#47;141716143","like_count":6,"discussions":[{"author":{"id":1337319,"avatar":"https://static001.geekbang.org/account/avatar/00/14/67/e7/0d92745d.jpg","nickname":"Billy火炎焱燚(不羁的风)","note":"","ucode":"63DED1EB2CF6AE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":650889,"discussion_content":"回答得很赞！LangChain确实包含了很多内置的组件，我去年也是用LangChain。不过LangChain目前根据实际业务场景定制化的限制太多，随着项目的深入，不得不把LangChain的模块换掉。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1725800441,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":1,"child_discussions":[{"author":{"id":1182372,"avatar":"https://static001.geekbang.org/account/avatar/00/12/0a/a4/828a431f.jpg","nickname":"张申傲","note":"","ucode":"22D46BC529BA8A","race_medal":2,"user_type":1,"is_pvip":false},"reply_author":{"id":1337319,"avatar":"https://static001.geekbang.org/account/avatar/00/14/67/e7/0d92745d.jpg","nickname":"Billy火炎焱燚(不羁的风)","note":"","ucode":"63DED1EB2CF6AE","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":650951,"discussion_content":"感谢老师的回复~我们项目中使用LangChain还挺多的，我自己也是LangChain的Contributor，对LangChain还算比较熟悉，请问下老师在使用LangChain时具体遇到了哪些痛点呢？能否给几个具体场景？","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1725931211,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":650889,"ip_address":"北京","group_id":0},"score":650951,"extra":""}]}]},{"had_liked":false,"id":393979,"user_name":"kevin","can_delete":false,"product_type":"c1","uid":1629537,"ip_address":"江苏","ucode":"8A0F58E2723893","user_header":"https://static001.geekbang.org/account/avatar/00/18/dd/61/544c2838.jpg","comment_is_top":false,"comment_ctime":1725493155,"is_pvip":true,"replies":[{"id":143057,"content":"你回答得很对，给你点赞","user_name":"作者回复","user_name_real":"编辑","uid":1337319,"ctime":1725799649,"ip_address":"广东","comment_id":393979,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100817901,"comment_content":"在编码阶段，将历史问答进行压缩","like_count":2,"discussions":[{"author":{"id":1337319,"avatar":"https://static001.geekbang.org/account/avatar/00/14/67/e7/0d92745d.jpg","nickname":"Billy火炎焱燚(不羁的风)","note":"","ucode":"63DED1EB2CF6AE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":650880,"discussion_content":"你回答得很对，给你点赞","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1725799649,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":394037,"user_name":"NEO","can_delete":false,"product_type":"c1","uid":1441673,"ip_address":"广东","ucode":"8B9A665CD78C6A","user_header":"https://static001.geekbang.org/account/avatar/00/15/ff/89/2e2211d3.jpg","comment_is_top":false,"comment_ctime":1725604192,"is_pvip":false,"replies":[{"id":143056,"content":"这是一个很不错的流程！很赞！","user_name":"作者回复","user_name_real":"编辑","uid":1337319,"ctime":1725799569,"ip_address":"广东","comment_id":394037,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100817901,"comment_content":"提问--&gt;LLM对问题进行完善丰富--&gt;向量数据库根据完善后的提问进行检索---&gt;编码--&gt;融合--&gt;生成--&gt;prompt反馈--&gt;优化......","like_count":1,"discussions":[{"author":{"id":1337319,"avatar":"https://static001.geekbang.org/account/avatar/00/14/67/e7/0d92745d.jpg","nickname":"Billy火炎焱燚(不羁的风)","note":"","ucode":"63DED1EB2CF6AE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":650878,"discussion_content":"这是一个很不错的流程！很赞！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1725799569,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":394022,"user_name":"grok","can_delete":false,"product_type":"c1","uid":1341502,"ip_address":"美国","ucode":"4744AB3FA28FE2","user_header":"https://static001.geekbang.org/account/avatar/00/14/78/3e/f60ea472.jpg","comment_is_top":false,"comment_ctime":1725577977,"is_pvip":false,"replies":[{"id":143061,"content":"1. claude、gemini目前并没有采用跟openai一样的形式来支持系统角色。但是有类似的功能，gemini对应文档是：https:&#47;&#47;ai.google.dev&#47;gemini-api&#47;docs&#47;system-instructions?hl=zh-cn&amp;lang=python。claude对应文档是：https:&#47;&#47;docs.anthropic.com&#47;en&#47;docs&#47;build-with-claude&#47;prompt-engineering&#47;system-prompts#legal-contract-analysis-without-role-prompting\n另外本专栏采用的百度文心大模型还不支持\n2. 就本专栏的3个实战案例而言，都不受超长窗口的LLM影响。因为本专栏的3个实战案例都是检索私有的知识喂给LLM处理","user_name":"作者回复","user_name_real":"作者","uid":1337319,"ctime":1725800145,"ip_address":"广东","comment_id":394022,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100817901,"comment_content":"请教两个问题：\n1. 系统角色在其他主流LLM支持吗 比如claude&#47;gemini&#47;grok\n2. 超长窗口的LLM不断出现，会给RAG带来任何影响吗，比如https:&#47;&#47;magic.dev&#47;blog&#47;100m-token-context-windows","like_count":1,"discussions":[{"author":{"id":1337319,"avatar":"https://static001.geekbang.org/account/avatar/00/14/67/e7/0d92745d.jpg","nickname":"Billy火炎焱燚(不羁的风)","note":"","ucode":"63DED1EB2CF6AE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":650886,"discussion_content":"1. claude、gemini目前并没有采用跟openai一样的形式来支持系统角色。但是有类似的功能，gemini对应文档是：https://ai.google.dev/gemini-api/docs/system-instructions?hl=zh-cn&lang=python。claude对应文档是：https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/system-prompts#legal-contract-analysis-without-role-prompting\n另外本专栏采用的百度文心大模型还不支持\n2. 就本专栏的3个实战案例而言，都不受超长窗口的LLM影响。因为本专栏的3个实战案例都是检索私有的知识喂给LLM处理","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1725800145,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":394208,"user_name":"明辰","can_delete":false,"product_type":"c1","uid":1557878,"ip_address":"浙江","ucode":"0DB5393DF7EC56","user_header":"https://static001.geekbang.org/account/avatar/00/17/c5/76/e269369e.jpg","comment_is_top":false,"comment_ctime":1726126078,"is_pvip":false,"replies":[{"id":143120,"content":"关于第一点，在去年我们还在用OpenAI的时候，OpenAI明确说了system和role区别不大。\n后来我们改用国产大模型之后，就没有把精力放在OpenAI上面了。我们使用OpenAI掉过很多坑，当然用国产大模型也掉过很多坑。但是国产大模型的客服给力啊，会帮我们解决问题。OpenAI的客服等于没有。所以除了考虑质量之外，客服（也就是帮助客户解决实际问题的能力和态度）也是很重要的参考因素。 毕竟我们不是搞学术的，我们是搞落地的。\n关于第二点和第三点，后面章节有讲","user_name":"作者回复","user_name_real":"作者","uid":1337319,"ctime":1726236016,"ip_address":"广东","comment_id":394208,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100817901,"comment_content":"老师，我仔细看了您的课，有3个问题想请教一下\n1、对话中输入的内容，我们一般全部放到role里，但是OpenAI额外增加了system，哪些指令应该放到system中，哪些放到role中\n2、您提到编码、融合过程，是不是可以理解为这部分已经由基座模型实现了，一般我们不需要太多关注\n3、您提到的“外部知识组装”环节应该怎么理解，是说检索到的信息需要改写成固定的格式再给到模型嘛\n期待老师的解答～","like_count":0,"discussions":[{"author":{"id":1337319,"avatar":"https://static001.geekbang.org/account/avatar/00/14/67/e7/0d92745d.jpg","nickname":"Billy火炎焱燚(不羁的风)","note":"","ucode":"63DED1EB2CF6AE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":651126,"discussion_content":"关于第一点，在去年我们还在用OpenAI的时候，OpenAI明确说了system和role区别不大。\n后来我们改用国产大模型之后，就没有把精力放在OpenAI上面了。我们使用OpenAI掉过很多坑，当然用国产大模型也掉过很多坑。但是国产大模型的客服给力啊，会帮我们解决问题。OpenAI的客服等于没有。所以除了考虑质量之外，客服（也就是帮助客户解决实际问题的能力和态度）也是很重要的参考因素。 毕竟我们不是搞学术的，我们是搞落地的。\n关于第二点和第三点，后面章节有讲","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1726236016,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":394168,"user_name":"叶绘落","can_delete":false,"product_type":"c1","uid":1652234,"ip_address":"广东","ucode":"81A249CC67B9A9","user_header":"https://static001.geekbang.org/account/avatar/00/19/36/0a/a14b6af4.jpg","comment_is_top":false,"comment_ctime":1726036238,"is_pvip":false,"replies":[{"id":143114,"content":"这是一个不错的思路。。当然，也可以把一万次对话做成知识库，这样后面就把所有知识库的技术都可以应用上了。","user_name":"作者回复","user_name_real":"作者","uid":1337319,"ctime":1726235055,"ip_address":"广东","comment_id":394168,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100817901,"comment_content":"将一万次对话进行切片，如每 10 、100 次对话为一个切片（每个切片进行持久化存储），将前一个切片交给 LLM 归纳总结，归纳结果作为下一个切片的上下文，以此类推，最终得到一万次对话的最终归纳结果，并将其持久化存储。\n\n如有新提问，就以最终归纳结果和最近的一个对话切片作为上下文，结合新提问，交给 LLM 处理。","like_count":0,"discussions":[{"author":{"id":1337319,"avatar":"https://static001.geekbang.org/account/avatar/00/14/67/e7/0d92745d.jpg","nickname":"Billy火炎焱燚(不羁的风)","note":"","ucode":"63DED1EB2CF6AE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":651120,"discussion_content":"这是一个不错的思路。。当然，也可以把一万次对话做成知识库，这样后面就把所有知识库的技术都可以应用上了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1726235055,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":394066,"user_name":"爬行的蜗牛","can_delete":false,"product_type":"c1","uid":1033956,"ip_address":"四川","ucode":"6623B62DE63CE9","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/QD6bf8hkS5dHrabdW7M7Oo9An1Oo3QSxqoySJMDh7GTraxFRX77VZ2HZ13x3R4EVYddIGXicRRDAc7V9z5cLDlA/132","comment_is_top":false,"comment_ctime":1725699586,"is_pvip":false,"replies":[{"id":143116,"content":"这种思路也不错。当然，也可以把一万次对话做成知识库，这样后面就把所有知识库的技术都可以应用上了。","user_name":"作者回复","user_name_real":"编辑","uid":1337319,"ctime":1726235334,"ip_address":"广东","comment_id":394066,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100817901,"comment_content":"方式一：对一万次会话进行总结，提取要点再作为Memory.\n方式二：切片去最近的部分。","like_count":0,"discussions":[{"author":{"id":1337319,"avatar":"https://static001.geekbang.org/account/avatar/00/14/67/e7/0d92745d.jpg","nickname":"Billy火炎焱燚(不羁的风)","note":"","ucode":"63DED1EB2CF6AE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":651122,"discussion_content":"这种思路也不错。当然，也可以把一万次对话做成知识库，这样后面就把所有知识库的技术都可以应用上了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1726235334,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":394591,"user_name":"石云升","can_delete":false,"product_type":"c1","uid":1024195,"ip_address":"广东","ucode":"78F1DD33EFD000","user_header":"https://static001.geekbang.org/account/avatar/00/0f/a0/c3/c5db35df.jpg","comment_is_top":false,"comment_ctime":1727253910,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":1,"score":2,"product_id":100817901,"comment_content":"长期记忆压缩存储关键信息。","like_count":0}]}