{"id":623419,"title":"88｜理论盘点：数据采集的方法与 HTTP 协议","content":"<p><strong>课后习题</strong><br>\n请你使用 requests 库采集一周内的天气（气温 + 降水），存入文本文件中。</p><p><strong>课程代码、课件及其他相关资料地址</strong><br>\n<a href=\"https://gitee.com/wilsonyin/zero-basics-python\">https://gitee.com/wilsonyin/zero-basics-python</a></p>","comments":[{"had_liked":false,"id":390662,"user_name":"Geek_319047","can_delete":false,"product_type":"c3","uid":3872613,"ip_address":"安徽","ucode":"3C4A83EAA88129","user_header":"","comment_is_top":false,"comment_ctime":1715911001,"is_pvip":false,"replies":[{"id":142158,"content":"错误信息json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)表明解析JSON时遇到了问题，可能是因为服务器返回了空响应\n\n怎么检查呢？\n\n1 你可以打印出r.text来查看服务器返回的原始响应内容。 print(r.text)\n2 检查HTTP响应的状态码，以确认请求是否成功。 print(r.status_code)\n如果状态码不是200，说明请求没有成功\n\n如果返回的是空，使用浏览器访问网站，访问时通过浏览器调试功能f12，看一下浏览器的请求头，把请求头部放在python里，让python模拟浏览器。\n\n如果返回的r.text非空，那么就是返回的不是标准的json格式，需要对返回内容进行其他格式的处理，比如xml。\n\n你也可以对返回的部分增加异常处理\ntry:\n    datas = r.json()\nexcept ValueError:\n    print(&quot;Response content is not valid JSON&quot;)\n    # 这里可以添加更多的错误处理逻辑，比如增加xml或者html格式处理代码\n\n这样即使不是json也能优雅处理错误，","user_name":"作者回复","user_name_real":"编辑","uid":1056235,"ctime":1716564563,"ip_address":"广东","comment_id":390662,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100310001,"comment_content":"求助：输入课程的代码：import requests\nimport json\nheaders={&quot;User-Agent&quot;:&quot;Mozilla&#47;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#47;537.36 (KHTML, like Gecko) Chrome&#47;54.0.2840.99 Safari&#47;537.36&quot;}\ndata={&quot;ids&quot;:[100310001],&quot;with_first_articles&quot;:False}\nr=requests.post(&#39;https:&#47;&#47;time.geekbang.org&#47;serv&#47;v3&#47;product&#47;infos&#39;,headers=headers, json=data)\ndatas=r.json()\nname=datas[&quot;data&quot;][&quot;infos&quot;][0][&quot;author&quot;][&quot;name&quot;]\nprint(name)\nTraceback (most recent call last):\n  File &quot;C:\\Users\\39893\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\requests\\models.py&quot;, line 971, in json\n    return complexjson.loads(self.text, **kwargs)\n  File &quot;C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1008.0_x64__qbz5n2kfra8p0\\Lib\\json\\__init__.py&quot;, line 346, in loads\n    return _default_decoder.decode(s)\n  File &quot;C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1008.0_x64__qbz5n2kfra8p0\\Lib\\json\\decoder.py&quot;, line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File &quot;C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1008.0_x64__qbz5n2kfra8p0\\Lib\\json\\decoder.py&quot;, line 355, in raw_decode\n    raise JSONDecodeError(&quot;Expecting value&quot;, s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;h:\\零基础python（2023版）\\python课件代码\\第11章数据采集、处理、展示\\88数据采集的方法与HTTP协议.PY&quot;, line 24, in &lt;module&gt;\n    datas=r.json()\n  File &quot;C:\\Users\\39893\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\requests\\models.py&quot;, line 975, in json\n    raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)\nrequests.exceptions.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\n\n怎么回事，搞了好几天了，没找到问题，急急急，微电18156299696","like_count":0,"discussions":[{"author":{"id":1056235,"avatar":"https://static001.geekbang.org/account/avatar/00/10/1d/eb/b2123759.jpg","nickname":"尹会生","note":"","ucode":"D1093DBD093617","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":645707,"discussion_content":"错误信息json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)表明解析JSON时遇到了问题，可能是因为服务器返回了空响应\n\n怎么检查呢？\n\n1 你可以打印出r.text来查看服务器返回的原始响应内容。 print(r.text)\n2 检查HTTP响应的状态码，以确认请求是否成功。 print(r.status_code)\n如果状态码不是200，说明请求没有成功\n\n如果返回的是空，使用浏览器访问网站，访问时通过浏览器调试功能f12，看一下浏览器的请求头，把请求头部放在python里，让python模拟浏览器。\n\n如果返回的r.text非空，那么就是返回的不是标准的json格式，需要对返回内容进行其他格式的处理，比如xml。\n\n你也可以对返回的部分增加异常处理\ntry:\n    datas = r.json()\nexcept ValueError:\n    print(&#34;Response content is not valid JSON&#34;)\n    # 这里可以添加更多的错误处理逻辑，比如增加xml或者html格式处理代码\n\n这样即使不是json也能优雅处理错误，","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1716564563,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":367232,"user_name":"Cy23","can_delete":false,"product_type":"c3","uid":1591293,"ip_address":"辽宁","ucode":"8DC561C5151758","user_header":"https://static001.geekbang.org/account/avatar/00/18/47/fd/895f0c27.jpg","comment_is_top":false,"comment_ctime":1675061490,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100310001,"comment_content":"import requests\nfrom bs4 import BeautifulSoup\n\nurl = &#39;https:&#47;&#47;www.tianqi.com&#47;shenyang&#47;7&#47;&#39;\n\ndef getHTMLtext(url):   \n  &quot;&quot;&quot;请求获得网页内容&quot;&quot;&quot;\n  headers = {&quot;User-Agent&quot;: &quot;Mozilla&#47;5.0 (Windows NT 10.0; WOW64) AppleWebKit&#47;537.36 (KHTML, like Gecko) Chrome&#47;86.0.4240.198 Safari&#47;537.36&quot;}\n  try:        \n   r = requests.get(url, timeout = 30, headers = headers)    \n   r.raise_for_status()        \n   r.encoding = r.apparent_encoding     \n   print(&quot;成功访问&quot;)        \n   return r.text    \n  except:        \n   print(&quot;访问错误&quot;)       \n   return&quot; &quot;\ndef get_content(html):\n  &quot;&quot;&quot;处理得到有用信息保存数据文件&quot;&quot;&quot;\n  final = &quot;&quot;          # 初始化一个列表保存数据\n  bs = BeautifulSoup(html, &quot;html.parser&quot;)  # 创建BeautifulSoup对象\n  body = bs.body\n  ul = body.find(&#39;ul&#39;, {&#39;class&#39;: &#39;weaul&#39;})    # 找到ul标签且class = weaul\n  li = ul.find_all(&#39;li&#39;)      # 找到左右的li标签\n  i = 0     # 控制爬取的天数\n  for day in li:          # 遍历找到的每一个li\n    if i &lt; 30 and i &gt; 0:\n      temp = &quot;&quot;          # 临时存放每天的数据\n      date = day.find(attrs={&#39;class&#39;:&#39;fl&#39;}).string     # 得到日期\n      temp += date + &quot; &quot;\n\n      inf = day.find_all(attrs={&#39;class&#39;:&#39;weaul_z&#39;})      # 找出li下面的weaul_z,提取第一个weaul_z标签的值，即天气\n      temp += inf[0].string + &quot; &quot;\n      tem = inf[1].find_all(&#39;span&#39;)   \n      tem_low = tem[0].string   # 找到最低温度 \n      tem_high = tem[1].string    # 找到最高温度 \n      temp  += tem_low+&#39;~&#39;+tem_high+&#39;℃&#39; + &quot;\\r&quot;\n      final += temp\n    i = i + 1\n\n  return final\n\nif __name__ == &#39;__main__&#39;:\n  html_text = getHTMLtext(url)\n  data = get_content(html_text)\n  with open(&#39;weather.txt&#39;, &#39;w&#39;, encoding=&#39;UTF-8&#39;) as f:\n    f.write(str(data))","like_count":2},{"had_liked":false,"id":383132,"user_name":"MarkG","can_delete":false,"product_type":"c3","uid":3675806,"ip_address":"山东","ucode":"454082595FE769","user_header":"https://static001.geekbang.org/account/avatar/00/38/16/9e/48621655.jpg","comment_is_top":false,"comment_ctime":1698496584,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100310001,"comment_content":"发现可以通过添加头信息来绕过检查：除了添加User-Agent外，还需要添加 Origin，加上就可以请求的通了","like_count":1},{"had_liked":false,"id":391931,"user_name":"liu","can_delete":false,"product_type":"c3","uid":2558086,"ip_address":"四川","ucode":"394B26B414CA03","user_header":"https://static001.geekbang.org/account/avatar/00/27/08/86/741dce69.jpg","comment_is_top":false,"comment_ctime":1719414351,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100310001,"comment_content":"课后习题答案：\nimport requests\nfrom bs4 import BeautifulSoup\n\nhds = {&quot;User-Agent&quot;: &quot;Mozilla&#47;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#47;537.36 (KHTML, like Gecko) Chrome&#47;126.0.0.0 Safari&#47;537.36&quot;}\nurl = &#39;https:&#47;&#47;www.tianqi.com&#47;kunming&#47;7&#47;&#39;\nweather_file = &#39;weather.txt&#39;\n\nresp = requests.get(url, headers=hds)\nif resp.status_code == 200:\n    soup = BeautifulSoup(resp.text, &#39;html.parser&#39;)\n    weather = soup.find(&#39;ul&#39;, class_=&#39;weaul&#39;)\n    wlist = weather.find_all(&#39;li&#39;)\n    with open(weather_file, &#39;w&#39;, encoding=&#39;UTF-8&#39;) as f:\n        for item in wlist:\n            date = item.find(&#39;span&#39;, class_=&#39;fl&#39;).text.strip()\n            wea = item.find(&#39;div&#39;, class_=&#39;weaul_z&#39;).text.strip()\n            f.write(f&quot;{date}: {wea}\\n&quot;)\n    print(&#39;Success to save&#39;)       \nelse:\n    print(f&quot;Request error with status code: {resp.status_code}&quot;)","like_count":0},{"had_liked":false,"id":390700,"user_name":"Geek_319047","can_delete":false,"product_type":"c3","uid":3872613,"ip_address":"安徽","ucode":"3C4A83EAA88129","user_header":"","comment_is_top":false,"comment_ctime":1716032153,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100310001,"comment_content":"import requests\nimport json\nheaders={&quot;User-Agent&quot;:&quot;Mozilla&#47;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#47;537.36 (KHTML, like Gecko) Chrome&#47;54.0.2840.99 Safari&#47;537.36&quot;}\ndata={&quot;ids&quot;:[100310001],&quot;with_first_articles&quot;:False}\nr=requests.post(&#39;https:&#47;&#47;time.geekbang.org&#47;serv&#47;v3&#47;product&#47;infos&#39;,headers=headers, json=data)\ndatas=r.json()\nname=datas[&quot;data&quot;][&quot;infos&quot;][0][&quot;author&quot;][&quot;name&quot;]\nprint(name)\n现在运行这个老出错为什么错误提示如下\n File &quot;C:\\Users\\39893\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\requests\\models.py&quot;, line 971, in json\n    return complexjson.loads(self.text, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &quot;C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1008.0_x64__qbz5n2kfra8p0\\Lib\\json\\__init__.py&quot;, line 346, in loads\n    return _default_decoder.decode(s)\n  File &quot;C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1008.0_x64__qbz5n2kfra8p0\\Lib\\json\\decoder.py&quot;, line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File &quot;C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1008.0_x64__qbz5n2kfra8p0\\Lib\\json\\decoder.py&quot;, line 355, in raw_decode\n    raise JSONDecodeError(&quot;Expecting value&quot;, s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;h:\\零基础python（2023版）\\python课件代码\\第11章数据采集、处理、展示\\88数据采集的方法与HTTP协议.PY&quot;, line 24, in &lt;module&gt;\n    datas=r.json()\n  File &quot;C:\\Users\\39893\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\requests\\models.py&quot;, line 975, in json\n    raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)\nrequests.exceptions.JSONDecodeError: Expecting value: line 1 column 1 (char 0)","like_count":0},{"had_liked":false,"id":387847,"user_name":"你好极客时间","can_delete":false,"product_type":"c3","uid":2113412,"ip_address":"四川","ucode":"EC1AE9FD105234","user_header":"https://static001.geekbang.org/account/avatar/00/20/3f/84/47f7b661.jpg","comment_is_top":false,"comment_ctime":1708681585,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100310001,"comment_content":"from multiprocessing import Process,Queue\nimport random\n\n\nclass Producer(Process):\n\n    def __init__(self,queue):\n        super().__init__()\n        self.queue = queue\n\n    def run(self):# 启动任务\n        self.create()\n\n    def create(self):\n        num = random.randint(1,10000)\n        self.queue.put(num)\n\nclass Consumer(Process):\n\n    def __init__(self,queue):\n        super().__init__()\n        self.queue = queue\n\n    def run(self):# 启动任务\n        self.get_result()\n\n    def get_result(self):\n\n        random_num = self.queue.get()\n\n        if random_num % 7 ==0:\n            print(&quot;The number is&quot;,random_num,&quot;, is divisible by 7.&quot;)\n        else:\n            print(&quot;Generated number&quot;, random_num, &quot;is not divisible by 7.&quot;)\n\nif __name__ == &#39;__main__&#39;:\n    queue = Queue()\n\n    process1 = Producer(queue)\n    process2 = Consumer(queue)\n\n    process1.start()\n    process2.start()  # 启动进程\n\n    process1.join()   # 结束进程\n    process2.join()","like_count":0},{"had_liked":false,"id":385204,"user_name":"Geek_631607","can_delete":false,"product_type":"c3","uid":3789991,"ip_address":"广东","ucode":"EAF874838F0BE4","user_header":"","comment_is_top":false,"comment_ctime":1702283253,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100310001,"comment_content":"import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# 抓取深圳的天气情况\nurl = &quot;http:&#47;&#47;www.weather.com.cn&#47;weather&#47;101280601.shtml&quot;\nresponse = requests.get(url)\nresponse.encoding = &#39;UTF-8&#39;\n# print(response)\nsoup = BeautifulSoup(response.text, &#39;html.parser&#39;)\n# print(soup)\n\n# 解析网页，获取日期、最高温度和最低温度\ndates = [item.get_text() for item in soup.select(&#39;.t li h1&#39;)]\ndates = [item.get_text() for item in soup.select(&#39;.t li h1&#39;)]\nhigh_temps = [int(item.get_text().replace(&#39;℃&#39;, &#39;&#39;)) for item in soup.select(&#39;.t li .tem span&#39;)]\nlow_temps = [int(item.get_text().replace(&#39;℃&#39;, &#39;&#39;)) for item in soup.select(&#39;.t li .tem i&#39;)]\n\n# 将数据保存到 DataFrame 中\ndf = pd.DataFrame({\n    &#39;date&#39;: dates,\n    &#39;high_temp&#39;: high_temps,\n    &#39;low_temp&#39;: low_temps\n})\n\n# 将 DataFrame 保存到 CSV 文件中\ndf.to_csv(&#39;shenzhen_weather.csv&#39;, index=False)\n\n# 从 CSV 文件中读取 DataFrame\ndf = pd.read_csv(&#39;shenzhen_weather.csv&#39;)\n\n# 绘制最高温度和最低温度的折线图\nplt.rcParams[&#39;font.sans-serif&#39;] = [&#39;Arial Unicode MS&#39;]\nplt.plot(df[&#39;date&#39;], df[&#39;high_temp&#39;], label=&#39;High Temperature&#39;)\nplt.plot(df[&#39;date&#39;], df[&#39;low_temp&#39;], label=&#39;Low Temperature&#39;)\nplt.xlabel(&#39;Date&#39;)\nplt.ylabel(&#39;Temperature (℃)&#39;)\nplt.title(&#39;Shenzhen Weather&#39;)\nplt.legend()\nplt.show()","like_count":0},{"had_liked":false,"id":384890,"user_name":"依托答辩","can_delete":false,"product_type":"c3","uid":2383299,"ip_address":"上海","ucode":"4BE79E8A030813","user_header":"https://static001.geekbang.org/account/avatar/00/24/5d/c3/b8bb888c.jpg","comment_is_top":false,"comment_ctime":1701759086,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100310001,"comment_content":"# 没找到降水的信息在哪\n\nimport requests\nfrom bs4 import BeautifulSoup\nimport os\nimport json\n\ndef getHtml(url):\n  header = {\n    &#39;User-Agent&#39;: &#39;Mozilla&#47;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#47;537.36 (KHTML, like Gecko) Chrome&#47;92.0.4515.131 Safari&#47;537.36&#39;\n  }\n  try:\n    r = requests.get(url, headers=header)\n    r.raise_for_status()\n    return r.text\n  except:\n    print(&#39;请求失败&#39;)\n\ndef getContent():\n  html = getHtml(&#39;https:&#47;&#47;www.tianqi.com&#47;shanghai&#47;7&#47;&#39;)\n  soup = BeautifulSoup(html, &#39;html.parser&#39;)\n  # 找到展示天气的标签\n  body = soup.body\n  ul = body.find(&#39;ul&#39;, {&#39;class&#39;: &#39;weaul&#39;})\n  li = ul.find_all(&#39;li&#39;) # 每天的天气信息放在li标签中\n  wea_list = []\n  for i in li:\n    date = i.find(&#39;div&#39;, {&#39;class&#39;: &#39;weaul_q&#39;}).text.split(&#39;\\n&#39;)[0]\n    wea_wrapper = i.find(&#39;div&#39;, {&#39;class&#39;: &#39;weaul_z&#39;})\n    wea = wea_wrapper.text\n    temp = wea_wrapper.find_next_sibling(&#39;div&#39;, {&#39;class&#39;: &#39;weaul_z&#39;}).text\n    wea_list.append({\n      &#39;date&#39;: date,\n      &#39;temp&#39;: temp,\n      &#39;wea&#39;: wea\n    })\n  return wea_list\n\npath = os.getcwd()\nBASE_PATH = f&quot;{path}&#47;tong_zheng&#47;2023_12_04_homework&#47;&quot; # 绝对路径基本\ndef saveContent():\n  with open(f&quot;{BASE_PATH}weather.json&quot;, &#39;w&#39;, encoding=&#39;utf-8&#39;) as f:\n    content = getContent()\n    json.dump(content, f, ensure_ascii=False)\nsaveContent()","like_count":0},{"had_liked":false,"id":384031,"user_name":"xiaon","can_delete":false,"product_type":"c3","uid":2819380,"ip_address":"北京","ucode":"464C34A720305B","user_header":"","comment_is_top":false,"comment_ctime":1700124835,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":2,"product_id":100310001,"comment_content":"有两个地方没明白，\n第一，获取数据中的文字，为什么从浏览器F12中的&quot;预览&quot;项中获取，而不是&quot;响应&quot;项\n第二，代码中 data = {&quot;ids&quot;:[100008801],&quot;with_first_articles&quot;:False} 中的 ids 是什么意思啊，为什么不写成 id 或者 abc 呢","like_count":0,"discussions":[{"author":{"id":2383299,"avatar":"https://static001.geekbang.org/account/avatar/00/24/5d/c3/b8bb888c.jpg","nickname":"依托答辩","note":"","ucode":"4BE79E8A030813","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":633014,"discussion_content":"一、预览和响应里的数据都是一样的，只不过预览里是格式化后的数据，看起来清晰一点，易读。\n二、根据视频中的内容（27:48处），infos这个接口要求的参数就有ids。肯定就不能自己随便写了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1701747934,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":383130,"user_name":"MarkG","can_delete":false,"product_type":"c3","uid":3675806,"ip_address":"山东","ucode":"454082595FE769","user_header":"https://static001.geekbang.org/account/avatar/00/38/16/9e/48621655.jpg","comment_is_top":false,"comment_ctime":1698496115,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":2,"product_id":100310001,"comment_content":"老师，目前按视频中的接口，已经走不通了返回451了","like_count":0,"discussions":[{"author":{"id":1938853,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/95/a5/de5df896.jpg","nickname":"JSJohnsonJS","note":"","ucode":"732F8EA6078302","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":636250,"discussion_content":"hds = {&#34;User-Agent&#34;:&#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36&#34;,&#34;Referer&#34;:&#34;https://time.geekbang.org/resource?tab=lecture&amp;c=12&#34;}\n\n要加上Referer，否则返回451","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1705909489,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"四川","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":381592,"user_name":"Geek_Mike","can_delete":false,"product_type":"c3","uid":3196376,"ip_address":"云南","ucode":"CFA942192C3B74","user_header":"https://static001.geekbang.org/account/avatar/00/30/c5/d8/c5509b9c.jpg","comment_is_top":false,"comment_ctime":1695484904,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100310001,"comment_content":"import requests\nimport datetime\nfrom matplotlib import pyplot\n\ndef get_data(accesskey, citycode, date):\n    url = f&quot;http:&#47;&#47;service.envicloud.cn:8082&#47;v2&#47;weatherhistory&#47;{accesskey}&#47;{citycode}&#47;{date}&quot;\n    payload = &quot;&quot;\n    headers = {&#39;cache-control&#39;: &quot;no-cache&quot;}\n    response = requests.request(&quot;GET&quot;, url, data=payload, headers=headers)\n    return response.json()\n\n\ndef save_data(data):\n    date = data[&#39;date&#39;]\n    tem_max = data[&#39;tem_max&#39;]\n    tem_min = data[&#39;tem_min&#39;]\n\n    filename = &#39;&#47;Users&#47;mike&#47;Desktop&#47;zero-basics-python&#47;0&#47;weather_data.txt&#39;\n    with open(filename, &#39;a&#39;) as file:\n            file.write(f&#39;{date},{tem_max},{tem_min}\\n&#39;)\n\n\ndef show_data():\n    filename = &#39;&#47;Users&#47;mike&#47;Desktop&#47;zero-basics-python&#47;0&#47;weather_data.txt&#39;\n    dates, highs, lows = [], [], []\n    with open(filename, &#39;r&#39;) as file:\n        line = file.readline()\n        while line:\n            line_list = line.split(&#39;,&#39;)\n            dates.append(line_list[0])\n            highs.append(line_list[1])\n            lows.append(line_list[2])\n            line = file.readline()\n    \n    fig = pyplot.figure(dpi=128, figsize=(10, 6))\n    pyplot.plot(dates, highs, c=&#39;red&#39;, alpha=0.5)\n    pyplot.plot(dates, lows, c=&#39;blue&#39;, alpha=0.5)\n    pyplot.fill_between(dates, highs, lows, facecolor=&#39;blue&#39;, alpha=0.1)\n\n    pyplot.title(&#39;Daily high and low tempertures&#39;, fontsize=24)\n    pyplot.xlabel(&#39;&#39;, fontsize=16)\n    fig.autofmt_xdate()\n    pyplot.ylabel(&#39;Temperature&#39;, fontsize=16)\n    pyplot.tick_params(axis=&#39;both&#39;, which=&#39;major&#39;, labelsize=16)\n\n    pyplot.show()\n    \n\ntoday = datetime.date.today()\n\nfor i in range(1,8):\n    format_today = today.strftime(&#39;%Y%m%d&#39;)\n    data = get_data(accesskey=&#39;xxx&#39;,\n                            citycode=&#39;xxx&#39;, \n                            date=format_today)\n    save_data(data)\n    today = today - datetime.timedelta(days=i)\n\nshow_data()","like_count":0},{"had_liked":false,"id":373814,"user_name":"Ying","can_delete":false,"product_type":"c3","uid":1110414,"ip_address":"上海","ucode":"BC35B2A63AA12F","user_header":"https://static001.geekbang.org/account/avatar/00/10/f1/8e/bf53c3be.jpg","comment_is_top":false,"comment_ctime":1683193956,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100310001,"comment_content":"# 请求所在城市7天的天气数据, 并存入本地文本\n# https:&#47;&#47;www.tianqi.com&#47;shenyang&#47;7&#47;\nimport requests\nfrom bs4 import BeautifulSoup\n\nurlstr = &quot;https:&#47;&#47;www.tianqi.com&#47;shanghai&#47;7&#47;&quot;\nheader = {\n    &quot;User-Agent&quot;: &quot;Mozilla&#47;5.0 (Windows NT 10.0; WOW64) AppleWebKit&#47;537.36 (KHTML, like Gecko) Chrome&#47;86.0.4240.198 Safari&#47;537.36&quot;\n}\nr = requests.get(urlstr, headers=header)\n\nbs = BeautifulSoup(r.text, &quot;html.parser&quot;)\n# bs.body html的主体\n# print(bs.body)\nbody = bs.body\nul = body.find(&quot;ul&quot;, {&quot;class&quot;: &quot;weaul&quot;})\n# print(ul)\nli = ul.find_all(&quot;li&quot;)\n# print(li)\ntemp = &quot;&quot;\nfor day in li:\n    print(day)\n    date = day.find(&quot;span&quot;, {&quot;class&quot;: &quot;fr&quot;}).string\n    temp += date\n    temp += &quot;  &quot;\n    temp += day.find(&quot;div&quot;, {&quot;class&quot;: &quot;weaul_z&quot;}).string\n    temp += &quot;\\n&quot;\n\nprint(temp)\nwith open(&quot;weather.txt&quot;, &quot;w&quot;, encoding=&quot;UTF-8&quot;) as f:\n    f.write(temp)","like_count":0},{"had_liked":false,"id":366751,"user_name":"Matthew","can_delete":false,"product_type":"c3","uid":2843865,"ip_address":"江苏","ucode":"96093089773740","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEKSVuNarJuDhBSvHY0giaq6yriceEBKiaKuc04wCYWOuso50noqDexaPJJibJN7PHwvcQppnzsDia1icZkw/132","comment_is_top":false,"comment_ctime":1674141431,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100310001,"comment_content":"# 用format()将结果打印输出\ndef print_data(final_list, num):\n    print(&quot;{:^10}\\t{:^8}\\t{:^8}\\t{:^8}\\t{:^8}&quot;.format(&#39;日期&#39;, &#39;天气&#39;, &#39;最高温度&#39;, &#39;最低温度&#39;, &#39;风级&#39;))\n    for i in range(num):\n        final = final_list[i]\n        print(&quot;{:^10}\\t{:^8}\\t{:^8}\\t{:^8}\\t{:^8}&quot;.format(final[0], final[1], final[2], final[3], final[4]))\n\n# 测试\nif __name__ == &#39;__main__&#39;:\n    # 中国天气网\n    url = &quot;http:&#47;&#47;www.weather.com.cn&#47;weather&#47;101190101.shtml&quot;\n    \n    # 调用函数，爬取网站数据，整合成列表\n    html = getHTMLText(url)\n    final_list = get_data(html)\n    print_data(final_list, 7)\n\n    # 将未来7天的日期、天气、最高温度、最低温度、风级数据写入文件\n    with open(&quot;天气.txt&quot;, mode=&#39;w&#39;, encoding=&#39;utf-8&#39;) as f:\n        f.write(str(final_list))","like_count":0},{"had_liked":false,"id":366750,"user_name":"Matthew","can_delete":false,"product_type":"c3","uid":2843865,"ip_address":"江苏","ucode":"96093089773740","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEKSVuNarJuDhBSvHY0giaq6yriceEBKiaKuc04wCYWOuso50noqDexaPJJibJN7PHwvcQppnzsDia1icZkw/132","comment_is_top":false,"comment_ctime":1674141417,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100310001,"comment_content":"import requests\nfrom bs4 import BeautifulSoup\n\n# 根据 url 获取 html\ndef getHTMLText(url, timeout=30):\n    try:\n        r = requests.get(url, timeout=30)  # 用requests抓取网页信息\n        r.raise_for_status()  # 可以让程序产生异常时停止程序\n        r.encoding = r.apparent_encoding\n        return r.text\n    except:\n        return &#39;产生异常&#39;\n\n# 根据 html 得到 最近7天的天气数据（list）\ndef get_data(html):\n    final_list = []\n    soup = BeautifulSoup(html, &#39;html.parser&#39;)  # 用BeautifulSoup库解析网页\n    body = soup.body\n    data = body.find(&#39;div&#39;, {&#39;id&#39;: &#39;7d&#39;})\n    ul = data.find(&#39;ul&#39;)\n    lis = ul.find_all(&#39;li&#39;)\n\n    for day in lis:\n        temp_list = []\n\n        date = day.find(&#39;h1&#39;).string  # 找到日期\n        temp_list.append(date)\n\n        info = day.find_all(&#39;p&#39;)  # 找到所有的p标签\n        temp_list.append(info[0].string)\n\n        if info[1].find(&#39;span&#39;) is None:  # 找到p标签中的第二个值&#39;span&#39;标签——最高温度\n            temperature_highest = &#39; &#39;  # 用一个判断是否有最高温度\n        else:\n            temperature_highest = info[1].find(&#39;span&#39;).string\n            temperature_highest = temperature_highest.replace(&#39;℃&#39;, &#39; &#39;)\n\n        if info[1].find(&#39;i&#39;) is None:  # 找到p标签中的第二个值&#39;i&#39;标签——最高温度\n            temperature_lowest = &#39; &#39;  # 用一个判断是否有最低温度\n        else:\n            temperature_lowest = info[1].find(&#39;i&#39;).string\n            temperature_lowest = temperature_lowest.replace(&#39;℃&#39;, &#39; &#39;)\n\n        temp_list.append(temperature_highest)  # 将最高气温添加到temp_list中\n        temp_list.append(temperature_lowest)  # 将最低气温添加到temp_list中\n\n        wind_scale = info[2].find(&#39;i&#39;).string  # 找到p标签的第三个值&#39;i&#39;标签——风级，添加到temp_list中\n        temp_list.append(wind_scale)\n\n        final_list.append(temp_list)  # 将temp_list列表添加到final_list列表中\n    return final_list","like_count":0}]}