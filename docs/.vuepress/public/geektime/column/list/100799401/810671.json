{"id":810671,"title":"19｜优化器成本模型：优化器为什么选择这个执行计划？","content":"<p>你好，我是俊达。</p><p>上一讲中，我们通过四十多个SQL，演示了MySQL各种不同的执行计划。对于给定的一个SQL语句，MySQL为什么选择了某一个执行计划，而没有采用其他的执行计划呢？优化器会评估每一个可能的执行计划的成本，从中选择一个成本最低的作为最终的执行计划。这一讲中我们就来聊一聊执行计划的成本是怎么计算的。</p><h2>SQL预处理</h2><p>一个SQL，在进行具体的成本计算之前，会先进行一系列的预处理。首先需要对SQL文本进行词法分析和语法解析，生成语法树。然后基于关系代数的一些基本规则，对SQL语句进行转换和改写。</p><p>常见的改写有以下几种方式。</p><ul>\n<li>等值条件传播</li>\n</ul><p>如果A=B，并且B=C，则A=C。</p><p>下面这个SQL中，原始条件是t1.a = t2.a and t2.a = t3.a，转换后，得到t1.a = t2.a and t1.a = t3.a，观察执行计划中的ref列就可以看到这一点。</p><pre><code class=\"language-plain\">mysql&gt; explain select * from tab t1, tab t2, tab t3 \n  where t1.a = t2.a \n  and t2.a = t3.a;\n\n+----+-------------+-------+------+---------------+---------+---------+----------+------+----------+-------+\n| id | select_type | table | type | possible_keys | key     | key_len | ref      | rows | filtered | Extra |\n+----+-------------+-------+------+---------------+---------+---------+----------+------+----------+-------+\n|  1 | SIMPLE      | t1    | ALL  | idx_abc       | NULL    | NULL    | NULL     | 9913 |   100.00 | NULL  |\n|  1 | SIMPLE      | t2    | ref  | idx_abc       | idx_abc | 4       | rep.t1.a | 3304 |   100.00 | NULL  |\n|  1 | SIMPLE      | t3    | ref  | idx_abc       | idx_abc | 4       | rep.t1.a | 3304 |   100.00 | NULL  |\n+----+-------------+-------+------+---------------+---------+---------+----------+------+----------+-------+\n</code></pre><!-- [[[read_end]]] --><ul>\n<li>常量传播</li>\n</ul><p>如果A=B，并且 B=1，那么可以得到A=1。下面这个例子中， 通过show warnings可以看到，WHERE条件被写成了t1.a = 1 and t2.b = 1。</p><pre><code class=\"language-plain\">mysql&gt; explain select * from tab t1, tab t2    where t1.a = t2.b and t2.b = 1;\n+----+-------------+-------+------+---------------+------+---------+------+------+----------+--------------------------------------------+\n| id | select_type | table | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra                                      |\n+----+-------------+-------+------+---------------+------+---------+------+------+----------+--------------------------------------------+\n|  1 | SIMPLE      | t2    | ALL  | NULL          | NULL | NULL    | NULL | 9913 |    10.00 | Using where                                |\n|  1 | SIMPLE      | t1    | ALL  | idx_abc       | NULL | NULL    | NULL | 9913 |    33.62 | Using where; Using join buffer (hash join) |\n+----+-------------+-------+------+---------------+------+---------+------+------+----------+--------------------------------------------+\n\nmysql&gt; show warnings\\G\n*************************** 1. row ***************************\n  Level: Note\n   Code: 1003\nMessage: /* select#1 */ select `rep`.`t1`.`id` AS `id`,`rep`.`t1`.`a` AS `a`,\n     `rep`.`t1`.`b` AS `b`,`rep`.`t1`.`c` AS `c`,`rep`.`t1`.`padding` AS `padding`,\n     `rep`.`t2`.`id` AS `id`,`rep`.`t2`.`a` AS `a`,`rep`.`t2`.`b` AS `b`,\n     `rep`.`t2`.`c` AS `c`,`rep`.`t2`.`padding` AS `padding` \n  from `rep`.`tab` `t1` join `rep`.`tab` `t2` \n   where ((`rep`.`t2`.`b` = 1) \n   and (`rep`.`t1`.`a` = 1))\n</code></pre><ul>\n<li>移除重复或多余的条件</li>\n</ul><pre><code class=\"language-plain\">mysql&gt; explain select * from tab where a = 5 and a between 1 and 10;\n+----+-------------+-------+------+---------------+---------+---------+-------+------+----------+-------+\n| id | select_type | table | type | possible_keys | key     | key_len | ref   | rows | filtered | Extra |\n+----+-------------+-------+------+---------------+---------+---------+-------+------+----------+-------+\n|  1 | SIMPLE      | tab   | ref  | idx_abc       | idx_abc | 4       | const |    1 |   100.00 | NULL  |\n+----+-------------+-------+------+---------------+---------+---------+-------+------+----------+-------+\n</code></pre><ul>\n<li>移除永远为真的条件</li>\n</ul><p>条件1=1永远成立，优化器会直接移除类似这样的条件。</p><pre><code class=\"language-plain\">mysql&gt; explain select * from tab where 1=1;\n+----+-------------+-------+------+---------------+------+---------+------+------+----------+-------+\n| id | select_type | table | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra |\n+----+-------------+-------+------+---------------+------+---------+------+------+----------+-------+\n|  1 | SIMPLE      | tab   | ALL  | NULL          | NULL | NULL    | NULL | 9913 |   100.00 | NULL  |\n+----+-------------+-------+------+---------------+------+---------+------+------+----------+-------+\n</code></pre><ul>\n<li>对于永远无法满足的条件，直接返回无数据</li>\n</ul><p>下面这个例子中，t1.a &lt; 0 and t1.a &gt; 0逻辑上就不成立，因此查询可以直接返回无数据。</p><pre><code class=\"language-plain\">mysql&gt; explain select * from tab t1, tab t2 \n  where t1.a = t2.a and t1.a &lt; 0 and t1.a &gt; 0;\n+----+-------------+-------+------+---------------+------+---------+------+------+----------+--------------------------------+\n| id | select_type | table | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra                          |\n+----+-------------+-------+------+---------------+------+---------+------+------+----------+--------------------------------+\n|  1 | SIMPLE      | NULL  | NULL | NULL          | NULL | NULL    | NULL | NULL |     NULL | no matching row in const table |\n+----+-------------+-------+------+---------------+------+---------+------+------+----------+--------------------------------+\n</code></pre><ul>\n<li>外连接改写为内连接</li>\n</ul><p>下面这个SQL中，由于t2.a &gt; 0这个条件，left join被转换成了普通的join。</p><pre><code class=\"language-plain\">mysql&gt; explain select * from tab t1 left join t2 on t1.a = t2.a where t2.a &gt; 0;\n+----+-------------+-------+------+---------------+---------+---------+----------+------+----------+-------------+\n| id | select_type | table | type | possible_keys | key     | key_len | ref      | rows | filtered | Extra       |\n+----+-------------+-------+------+---------------+---------+---------+----------+------+----------+-------------+\n|  1 | SIMPLE      | t1    | ALL  | idx_abc       | NULL    | NULL    | NULL     | 9913 |    67.25 | Using where |\n|  1 | SIMPLE      | t2    | ref  | idx_abc       | idx_abc | 4       | rep.t1.a | 3304 |   100.00 | NULL        |\n+----+-------------+-------+------+---------------+---------+---------+----------+------+----------+-------------+\n    \nmysql&gt; show warnings\\G\n*************************** 1. row ***************************\n  Level: Note\n   Code: 1003\nMessage: /* select#1 */ select `rep`.`t1`.`id` AS `id`,`rep`.`t1`.`a` AS `a`,\n    `rep`.`t1`.`b` AS `b`,`rep`.`t1`.`c` AS `c`,`rep`.`t1`.`padding` AS `padding`,\n    `rep`.`t2`.`id` AS `id`,`rep`.`t2`.`a` AS `a`,`rep`.`t2`.`b` AS `b`,\n    `rep`.`t2`.`c` AS `c`,`rep`.`t2`.`padding` AS `padding` \nfrom `rep`.`tab` `t1` join `rep`.`tab` `t2`\nwhere ((`rep`.`t2`.`a` = `rep`.`t1`.`a`) \nand (`rep`.`t1`.`a` &gt; 0))\n</code></pre><ul>\n<li>子查询转换为SEMIJOIN</li>\n</ul><p>下面这个例子中，子查询被转换成了普通的表连接。注意到ID为1的两个查询单元，select_type都是SIMPLE。</p><pre><code class=\"language-plain\">mysql&gt; explain select * from tab where a in (select b from tab);\n+----+--------------+-------------+--------+---------------------+---------------------+---------+-----------+------+----------+-------------+\n| id | select_type  | table       | type   | possible_keys       | key                 | key_len | ref       | rows | filtered | Extra       |\n+----+--------------+-------------+--------+---------------------+---------------------+---------+-----------+------+----------+-------------+\n|  1 | SIMPLE       | tab         | ALL    | idx_abc             | NULL                | NULL    | NULL      | 9913 |   100.00 | NULL        |\n|  1 | SIMPLE       | &lt;subquery2&gt; | eq_ref | &lt;auto_distinct_key&gt; | &lt;auto_distinct_key&gt; | 4       | rep.tab.a |    1 |   100.00 | NULL        |\n|  2 | MATERIALIZED | tab         | index  | NULL                | idx_abc             | 12      | NULL      | 9913 |   100.00 | Using index |\n+----+--------------+-------------+--------+---------------------+---------------------+---------+-----------+------+----------+-------------+\n</code></pre><p>当然，满足一定条件的子查询才能转换为普通的表连接，而且为了SQL能查询得到一样的数据，转换为普通表连接后，还需要进行一些特殊的处理。后续我们会有一讲专门介绍子查询的转换。</p><h2>基于成本的优化</h2><p>MySQL使用了基于成本的优化器。我们通过一些具体的例子来说明成本的一些计算方式。</p><p>先创建一个测试表，初始化一些数据，这里的numbers就是上一讲开头创建的那个视图。</p><pre><code class=\"language-plain\">mysql&gt; create table t_cost (\n  id int not null auto_increment,\n  a int not null,\n  b int not null,\n  c int not null,\n  d int not null,\n  padding varchar(7000) DEFAULT NULL,\n  primary key (id),\n  key idx_ac(a,c),\n  key idx_bc(b,c)\n) engine=InnoDB;\n\nmysql&gt; insert into t_cost (a,b,c,d, padding)\nselect n%6, n%1000, n%100, n%100, rpad('', 2000, 'ABCDEFG XYZ') \nfrom \nnumbers;\n\nmysql&gt; analyze table t_cost;\n</code></pre><p>我们先来看这个SQL的执行计划。</p><pre><code class=\"language-plain\">mysql&gt; explain \nselect * \nfrom t_cost \nwhere a=3 \nand b between 90 and 100 \nand c in (1,2,3,4,5,6,7,8,9,10)\\G\n\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: t_cost\n   partitions: NULL\n         type: range\npossible_keys: idx_ac,idx_bc\n          key: idx_bc\n      key_len: 8\n          ref: NULL\n         rows: 110\n     filtered: 2.00\n        Extra: Using index condition; Using where\n</code></pre><p>对于上面这个SQL，优化器最终从全表扫描、使用索引idx_ac、使用索引idx_bc这几种可能的路径中选择了idx_bc。优化器认为通过索引idx_bc需要访问110行数据。</p><p>我们可以使用优化器跟踪来查看优化器的思考过程。先设置会话变量optimizer_trace，再执行SQL或Explain命令，然后就可以从information_schema.optimizer_trace查看优化器的跟踪信息了。</p><pre><code class=\"language-plain\">mysql&gt; set optimizer_trace='enabled=on';\nQuery OK, 0 rows affected (0.00 sec)\n\n\nmysql&gt; select *  from t_cost  \n  where a=3  \n  and b between 90 and 100  \n  and c in (1,2,3,4,5,6,7,8,9,10) ;\nEmpty set (0.01 sec)\n\nmysql&gt; select * from information_schema.optimizer_trace\\G\n*************************** 1. row ***************************\nQUERY: select *  from t_cost  where a=3  and b between 90 and 100  \n    and c in (1,2,3,4,5,6,7,8,9,10)\nTRACE: {\n  \"steps\": [\n    {\n      \"join_preparation\": {\n        \"select#\": 1,\n        \"steps\": [\n          {\n            \"IN_uses_bisection\": true\n          },\n          {\n......\n</code></pre><p>optimizer_trace的输出内容比较长，我们来看一下其中比较关键的几个部分。</p><ul>\n<li>table_scan</li>\n</ul><p>table_scan部分记录了全表扫描的成本，这里是扫描8580行记录，成本是1220.85。</p><pre><code class=\"language-plain\">{\n  \"rows_estimation\": [\n    {\n      \"table\": \"`t_cost`\",\n      \"range_analysis\": {\n        \"table_scan\": {\n          \"rows\": 8580,\n          \"cost\": 1220.85\n        }\n</code></pre><ul>\n<li>range_scan_alternatives</li>\n</ul><p>range_scan_alternatives中记录了索引扫描的成本，优化器分别计算了使用idx_ac和idx_bc这两个索引的访问成本。使用idx_ac时，需要扫描172行数据，成本是62.71。使用idx_bc时，需要扫描110行数据，成本是38.76。</p><pre><code class=\"language-plain\">\"analyzing_range_alternatives\": {\n \"range_scan_alternatives\": [\n   {\n     \"index\": \"idx_ac\",\n     \"ranges\": [\n       \"a = 3 AND c = 1\",\n       \"a = 3 AND c = 2\",\n       \"a = 3 AND c = 3\",\n       \"a = 3 AND c = 4\",\n       \"a = 3 AND c = 5\",\n       \"a = 3 AND c = 6\",\n       \"a = 3 AND c = 7\",\n       \"a = 3 AND c = 8\",\n       \"a = 3 AND c = 9\",\n       \"a = 3 AND c = 10\"\n     ],\n     \"index_dives_for_eq_ranges\": true,\n     \"rowid_ordered\": false,\n     \"using_mrr\": false,\n     \"index_only\": false,\n     \"in_memory\": 1,\n     \"rows\": 172,\n     \"cost\": 62.71,\n     \"chosen\": true\n   },\n   {\n     \"index\": \"idx_bc\",\n     \"ranges\": [\n       \"90 &lt;= b &lt;= 100\"\n     ],\n     \"index_dives_for_eq_ranges\": true,\n     \"rowid_ordered\": false,\n     \"using_mrr\": false,\n     \"index_only\": false,\n     \"in_memory\": 1,\n     \"rows\": 110,\n     \"cost\": 38.76,\n     \"chosen\": true\n   }\n ]\n</code></pre><ul>\n<li>best_access_path</li>\n</ul><p>best_access_path记录了优化器最终选择的执行计划，由于使用idx_bc成本最低，优化器最终选择了这个执行计划。</p><pre><code class=\"language-plain\">\"best_access_path\": {\n  \"considered_access_paths\": [\n    {\n      \"access_type\": \"ref\",\n      \"index\": \"idx_ac\",\n      \"chosen\": false,\n      \"cause\": \"range_uses_more_keyparts\"\n    },\n    {\n      \"rows_to_scan\": 110,\n      \"access_type\": \"range\",\n      \"range_details\": {\n        \"used_index\": \"idx_bc\"\n      },\n      \"resulting_rows\": 110,\n      \"cost\": 49.76,\n      \"chosen\": true\n    }\n  ]\n}\n</code></pre><p>优化器是怎么来评估这几种不同的执行路径的成本的呢？执行路径的成本主要由IO成本和CPU成本组成。</p><ul>\n<li>IO成本</li>\n</ul><p>IO成本是从内存或磁盘中读写数据块的成本。如果查询涉及到物化操作，IO成本还包括创建临时表、读写临时表的成本。IO成本和需要访问的数据块的数量相关。</p><ul>\n<li>CPU成本</li>\n</ul><p>CPU成本包括行评估成本（行评估成本可以理解为判断一行记录是否满足SQL表达式中的条件），KEY比较的成本（比如在进行排序操作时，需要比较记录排序字段的大小）。</p><p>具体怎么计算IO成本和CPU成本呢？</p><h3>优化器成本模型</h3><p>首先优化器有一个成本模型，设置了一些基本操作的成本，比如读取1个数据块的成本是多少、评估1行记录的成本是多少。我把优化器中的成本模型常量整理成了下面这两个表格，你可以参考一下。</p><ul>\n<li>Server层常量</li>\n</ul><p><img src=\"https://static001.geekbang.org/resource/image/36/34/3602c82ba75fef40a3f642f0fb90e634.png?wh=1920x905\" alt=\"图片\"></p><ul>\n<li>存储引擎层常量</li>\n</ul><p><img src=\"https://static001.geekbang.org/resource/image/ab/d1/ab4fed7807460246539455f7432078d1.png?wh=1920x472\" alt=\"图片\"></p><p>上面这两个表格中常量的取值从MySQL 8.0.32的代码中获取。不同的版本可能会设置不同的默认值，如果你去看5.7版本的源码，会发现有些常量的值不一样。一般我们并不需要修改这些常量，也不需要知道这些常量的具体取值，只有当我们想知道某个成本值具体是如何计算得到的时候，才会用到这些常量。</p><p>你还可以通过修改mysql库中的server_cost和engine_cost这2个表来改变某个成本常量的值，当然一般不会去修改这些值。</p><pre><code class=\"language-plain\">mysql&gt; select cost_name, cost_value, default_value from mysql.server_cost;\n+------------------------------+------------+---------------+\n| cost_name                    | cost_value | default_value |\n+------------------------------+------------+---------------+\n| disk_temptable_create_cost   |       NULL |            20 |\n| disk_temptable_row_cost      |       NULL |           0.5 |\n| key_compare_cost             |       NULL |          0.05 |\n| memory_temptable_create_cost |       NULL |             1 |\n| memory_temptable_row_cost    |       NULL |           0.1 |\n| row_evaluate_cost            |       NULL |           0.1 |\n+------------------------------+------------+---------------+\n6 rows in set (0.00 sec)\n\nmysql&gt; select engine_name, device_type, cost_name, cost_value, default_value \n    from mysql.engine_cost;\n+-------------+-------------+------------------------+------------+---------------+\n| engine_name | device_type | cost_name              | cost_value | default_value |\n+-------------+-------------+------------------------+------------+---------------+\n| default     |           0 | io_block_read_cost     |       NULL |             1 |\n| default     |           0 | memory_block_read_cost |       NULL |          0.25 |\n+-------------+-------------+------------------------+------------+---------------+\n</code></pre><p>如果你更新了这两个表，要执行FLUSH OPTIMIZER_COSTS命令后才会真正生效。</p><h3>成本计算</h3><p>MySQL怎么评估某个执行访问路径需要读取多少个数据块、扫描多少行数据呢？这里分为几种情况。对于全表扫描，MySQL会通过统计信息来估算。对于索引访问，MySQL会使用Index Dive机制来评估行数，或者使用索引统计信息来评估。接下来我们分别介绍这几种情况。</p><h4>全表扫描成本计算</h4><p><img src=\"https://static001.geekbang.org/resource/image/a6/8e/a66217358cd599b4ce9a8bfa814e9a8e.jpg?wh=1132x373\" alt=\"图片\"></p><p>全表扫描需要读取表中的所有数据页。全表扫描的成本会根据表的统计信息来评估。InnoDB表的统计信息存储在mysql.innodb_table_stats表中。在我们的测试表中，统计信息是这样的。</p><pre><code class=\"language-plain\">mysql&gt; select * from mysql.innodb_table_stats where table_name = 't_cost'\\G\n*************************** 1. row ***************************\n           database_name: rep\n              table_name: t_cost\n             last_update: 2024-08-22 16:14:21\n                  n_rows: 8580\n    clustered_index_size: 1443\nsum_of_other_index_sizes: 46\n</code></pre><p>这几个字段的含义我整理到表格中了，供你参考。</p><p><img src=\"https://static001.geekbang.org/resource/image/a3/60/a3343bdede38a11d3c9d8a992b6f2060.png?wh=1920x868\" alt=\"图片\"></p><p>我们来回顾一下前面全表扫描的成本。</p><pre><code class=\"language-plain\">\"table_scan\": {\n  \"rows\": 8580,\n  \"cost\": 1220.85\n}\n</code></pre><p>访问行数rows就是从统计信息中直接获取的。访问成本的计算公式，我使用下面这段python代码来表示。</p><pre><code class=\"language-plain\">ROW_EVALUATE_COST = 0.1\nMEMORY_BLOCK_READ_COST = 0.25\nIO_BLOCK_READ_COST = 1\n\ndef io_cost(pages, in_mem_pct):\n    in_mem_pages = pages * in_mem_pct\n    disk_pages = pages - in_mem_pages\n    cost = in_mem_pages * MEMORY_BLOCK_READ_COST + disk_pages * IO_BLOCK_READ_COST\n    return cost\n\ndef row_eval_cost(rows):\n    cost = rows * ROW_EVALUATE_COST\n    return cost\n    \ndef scan_cost(pages, rows, in_mem_pct):\n    cost = io_cost(pages, in_mem_pct)\n    row_cost = row_eval_cost(rows)\n    return cost + row_cost + 1.1 + 1\n</code></pre><p>函数scan_cost的参数中，pages是表统计信息中的clustered_index_size字段，rows是统计信息中的n_rows字段，in_mem_pct是表缓存在内存中的一个预估的比例，在我们这个例子中，缓存率是100。计算全表扫描的成本时，优化器还加上了一些固定的成本，就是公式中的 1.1 + 1。<br>\n将统计信息中的数据代入scan_cost函数，就得到了全表扫描的成本1220.85。</p><pre><code class=\"language-plain\">&gt;&gt;&gt; scan_cost(pages=1443, rows=8580, in_mem_pct=1.0)\n1220.85\n</code></pre><h4>索引访问成本计算</h4><p>我们先来回顾下索引访问的大致步骤。下面这张图描述了普通非覆盖索引的访问步骤。</p><ol>\n<li>根据索引条件，在索引中定位到索引条目。</li>\n<li>根据索引条目中的主键信息，到聚簇索引中查找数据。</li>\n</ol><p>一个SQL中，可能需要访问多个索引范围，比如在where中使用了or或者in条件。</p><p><img src=\"https://static001.geekbang.org/resource/image/c6/75/c62f9f5ab202a373eyy4d53be20aaa75.png?wh=1920x873\" alt=\"图片\"></p><p>从上面的示意图中，可以看出索引访问的成本主要包括：</p><ol>\n<li>需要访问的索引条目数量，以及这些条目分布在多少个页面中。</li>\n<li>索引的区间数量。</li>\n<li>需要读取的InnoDB聚簇索引的页面数量。</li>\n</ol><p>我们回顾下测试案例中两个索引的访问成本。使用索引idx_ac需要访问10个区间，总共172行记录，成本是62.71。</p><pre><code class=\"language-plain\">{\n  \"index\": \"idx_ac\",\n  \"ranges\": [\n    \"a = 3 AND c = 1\",\n    \"a = 3 AND c = 2\",\n    \"a = 3 AND c = 3\",\n    \"a = 3 AND c = 4\",\n    \"a = 3 AND c = 5\",\n    \"a = 3 AND c = 6\",\n    \"a = 3 AND c = 7\",\n    \"a = 3 AND c = 8\",\n    \"a = 3 AND c = 9\",\n    \"a = 3 AND c = 10\"\n  ],\n  \"index_dives_for_eq_ranges\": true,\n  \"rowid_ordered\": false,\n  \"using_mrr\": false,\n  \"index_only\": false,\n  \"in_memory\": 1,\n  \"rows\": 172,\n  \"cost\": 62.71,\n  \"chosen\": true\n}\n</code></pre><p>使用索引idx_bc需要访问1个区间，110行记录，成本是38.76。</p><pre><code class=\"language-plain\">   \n{\n  \"index\": \"idx_bc\",\n  \"ranges\": [\n    \"90 &lt;= b &lt;= 100\"\n  ],\n  \"index_dives_for_eq_ranges\": true,\n  \"rowid_ordered\": false,\n  \"using_mrr\": false,\n  \"index_only\": false,\n  \"in_memory\": 1,\n  \"rows\": 110,\n  \"cost\": 38.76,\n  \"chosen\": true\n}\n</code></pre><p>可以看到，索引访问时，需要扫描的记录数决定了访问的成本。那么优化器怎么知道，访问索引的某一个区间时，需要扫描多少行记录呢？InnoDB使用了index dive机制来评估记录数。简单地说，index dive就是根据区间的边界值，到索引中统计区间内的记录数，后续我们再对index dive的原理做进一步介绍，这里先记住一个结论：<strong>使用index dive机制通常能得到记录数比较准确的一个估计。</strong></p><p>得到索引区间内的记录数之后，（非覆盖索引）索引访问成本的计算公式，我使用下面这段python代码来表示。</p><pre><code class=\"language-plain\">MEMORY_BLOCK_READ_COST = 0.25\nIO_BLOCK_READ_COST = 1\nROW_EVALUATE_COST = 0.1\n\ndef row_evaluate_cost(rows):\n    return rows * ROW_EVALUATE_COST\n\ndef page_read_cost(in_mem_pct):\n    return MEMORY_BLOCK_READ_COST * in_mem_pct + IO_BLOCK_READ_COST * (1-in_mem_pct)\n\ndef range_normal_io_cost(ranges, rows, in_mem_pct):\n    pages = ranges + rows\n    result = pages * page_read_cost(in_mem_pct)\n    return result\n\ndef range_normal_cost(ranges, rows, in_mem_pct):\n    io_cost = range_normal_io_cost(ranges, rows, in_mem_pct)\n    result = io_cost + row_evaluate_cost(rows) + 0.01\n    return result\n</code></pre><p>索引访问成本由IO成本和行评估成本组成。而IO的次数是怎么评估的呢？ MySQL认为每一行记录需要访问1次IO，此外，每一个区间需要访问1次IO。</p><p>根据上面的公式，可以计算出我们例子中两个索引的访问成本。</p><p>索引idx_ac的访问成本：</p><pre><code class=\"language-plain\">&gt;&gt;&gt; range_normal_cost(ranges=10, rows=172, in_mem_pct=1.0)\n62.71\n</code></pre><p>索引index_bc的访问成本：</p><pre><code class=\"language-plain\">&gt;&gt;&gt; range_normal_cost(ranges=1,  rows=110, in_mem_pct=1.0)\n38.76\n</code></pre><p>我们这里介绍了非覆盖索引range执行路径下的访问成本。实际上索引访问还存在其他情况，比如上一讲中讲到，有一种ref的访问路径，此外，还存在覆盖索引的情况，这些情况下，索引访问的成本计算方式会有一些差异，我们下一讲再具体分析。</p><h4>索引统计信息的作用</h4><p>使用index dive通常能得到索引区间内记录数比较准确的一个估计。但是有些情况下，并不能使用index dive机制。比如在表连接的时候，连接条件来自于驱动表，而优化器并不知道连接条件的具体取值，因此无法使用index dive。另外一种情况是，如果待查询的区间数量特别多，对每一个区间都做一次index dive的开销太大了。当区间的数量超过参数eq_range_index_dive_limit的设置时，优化器就会放弃index dive。</p><p>我们来测试一下这种情况。</p><pre><code class=\"language-plain\">mysql&gt; explain select * from t_cost \n  where b in (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15) \n  and c in (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15);\n+----+-------------+--------+-------+---------------+--------+---------+------+------+----------+-----------------------+\n| id | select_type | table  | type  | possible_keys | key    | key_len | ref  | rows | filtered | Extra                 |\n+----+-------------+--------+-------+---------------+--------+---------+------+------+----------+-----------------------+\n|  1 | SIMPLE      | t_cost | range | idx_bc        | idx_bc | 8       | NULL | 1800 |   100.00 | Using index condition |\n+----+-------------+--------+-------+---------------+--------+---------+------+------+----------+-----------------------+\n</code></pre><p>eq_range_index_dive_limit默认为200，上面这个测试SQL中，总共有225个区间，因此优化器会放弃使用index dive。</p><p>从optimizer trace中，可以看到index_dives_for_eq_ranges为false，rows为1800，成本为686.26。</p><pre><code class=\"language-plain\">{\n  \"index\": \"idx_bc\",\n  \"ranges\": [\n    \"b = 1 AND c = 1\",\n    \"b = 1 AND c = 2\",\n    \"b = 1 AND c = 3\",\n   ......\n    \"b = 15 AND c = 14\",\n    \"b = 15 AND c = 15\"\n  ],\n  \"index_dives_for_eq_ranges\": false,\n  \"rowid_ordered\": false,\n  \"using_mrr\": false,\n  \"index_only\": false,\n  \"in_memory\": 0,\n  \"rows\": 1800,\n  \"cost\": 686.26,\n  \"chosen\": true\n}\n</code></pre><p>根据前面的计算公式，可以得到执行计划的成本。</p><pre><code class=\"language-plain\">&gt;&gt;&gt; range_normal_cost(ranges=225,  rows=1800, in_mem_pct=1)\n686.26\n</code></pre><p>那么这里的记录数是怎么评估出来的呢？这需要用到索引统计信息。索引统计信息可以通过information_schema.statistics表查看，也可以通过show indexes命令查看。</p><pre><code class=\"language-plain\">mysql&gt; show indexes from t_cost;\n+------------+----------+--------------+-------------+-----------+-------------+\n| Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality |\n+------------+----------+--------------+-------------+-----------+-------------+\n|          0 | PRIMARY  |            1 | id          | A         |        8580 |\n|          1 | idx_ac   |            1 | a           | A         |           6 |\n|          1 | idx_ac   |            2 | c           | A         |         300 |\n|          1 | idx_bc   |            1 | b           | A         |        1000 |\n|          1 | idx_bc   |            2 | c           | A         |        1000 |\n+------------+----------+--------------+-------------+-----------+-------------+\n</code></pre><p>索引统计信息字段含义我整理在了这个表格中。</p><p><img src=\"https://static001.geekbang.org/resource/image/4a/d3/4a3b0cf663da0820c11c2c588166bbd3.png?wh=1920x889\" alt=\"图片\"></p><p>索引统计信息中最重要字段是基数。对于组合索引，字段的基数是当前字段以及序号比当前字段小的那些字段的组合字段的唯一值。基数值越大，则通常说明索引的选择性越高。当然在实际情况中，可能会存在数据分布不均匀的情况，某些值的记录数会特别高或特别低。</p><p>我们的例子中，索引idx_bc的基数为1000，因此对于where b=xx and c=xx 这样的条件，匹配到的记录数是8580/1000，然后再取整，得到行数是8。我们的例子中有225个这样的区间，因此总记录数是225 * 8，也就是1800。你也可以在mysql.innodb_index_stats表中查看索引统计信息，有兴趣的可以自己去试一试。</p><h2>统计信息</h2><p>通过前面这几个简单的例子，你可以看到统计信息的重要作用了。准确的统计信息对于优化器是否能找到最优的执行计划起着关键的作用。如果统计信息不准确，则优化器可能会选择错误的执行计划。那么应该如何维护统计信息呢？</p><p>有几个参数控制了InnoDB收集统计信息的行为。</p><ul>\n<li>innodb_stats_auto_recalc</li>\n</ul><p>该参数控制InnoDB是否开启统计信息自动收集。如果开启了统计信息自动收集，则当表中的数据变化超过10%时，InnoDB后台会自动重新计算表的相关统计信息。该参数默认开启。如果关闭统计信息自动收集，则需要执行analyze table来更新表的统计信息。</p><ul>\n<li>innodb_stats_persistent</li>\n</ul><p>该参数控制是否持久化存储InnoDB统计信息，默认开启。如果没有开启统计信息持久化存储，则统计信息只存在内存中，则当MySQL重启后，所有InnoDB表的统计信息都缺失。查询语句访问到缺失统计信息的表时，会收集统计信息。</p><ul>\n<li>innodb_stats_persistent_sample_pages</li>\n</ul><p>该参数指定收集统计信息时扫描的页面数。该参数设置得越大，则analyze table得到的统计信息越精确，但是收集统计信息的时间会变长，也会消耗更多的系统IO。</p><ul>\n<li>innodb_stats_transient_sample_pages</li>\n</ul><p>innodb_stats_persistent设置为OFF时，使用该参数来控制收集统计信息时扫描的页面数。</p><ul>\n<li>innodb_stats_on_metadata</li>\n</ul><p>该参数用于控制在查看表的元数据时（如执行SHOW TABLE STATUS命令、查看information_schema中的TABLES、STATISTICS表），是否更新统计信息。该参数只有当统计信息没有持久化时才生效，默认关闭。</p><p>上述参数在全局控制统计信息收集行为。InnoDB也支持在表级别指定统计信息的收集策略。可以在create table或alter table语句中指定STATS_AUTO_RECALC、STATS_PERSISTENT、STATS_SAMPLE_PAGES这几个选项：</p><pre><code class=\"language-plain\">alter table tab \n    STATS_AUTO_RECALC = {DEFAULT|0|1},\n    STATS_PERSISTENT = {DEFAULT|0|1},\n    STATS_SAMPLE_PAGES = n;\n</code></pre><p>我们也可以使用ANALYZE TABLE命令来收集表的统计信息。</p><pre><code class=\"language-plain\">ANALYZE [NO_WRITE_TO_BINLOG] TABLE tbl_name;\n\nANALYZE [NO_WRITE_TO_BINLOG | LOCAL]\n    TABLE tbl_name\n    UPDATE HISTOGRAM ON col_name\n    [WITH N BUCKETS];\n</code></pre><p>ANALYZE TABLE命令的执行时间跟参数innodb_stats_persistent_sample_pages设置的采样页面数、索引字段的数量以及表的分区数相关。</p><h2>表连接的成本评估</h2><p>对于多表连接，优化器需要评估不同的连接顺序下的成本。</p><pre><code class=\"language-plain\">select * \nfrom t1, t2, t3\nwhere t1.c1 = t1.c1\nand t2.c1 = t3.c1\nand ...\n</code></pre><p>比如对于上面这个简单的三表连接查询，就存在6种可能的连接顺序。优化器需要评估每一个可能的执行路径的成本，从其中选择成本最低的执行路径来执行查询。</p><p><img src=\"https://static001.geekbang.org/resource/image/9e/7f/9e8216c2f71f64e739910905813e457f.jpg?wh=1382x764\" alt=\"图片\"></p><p>表连接的成本评估，以及表连接的执行，我们后续有专门的一节课来介绍。</p><h2>影响执行计划的其他因素</h2><p>优化器最终会选择哪个执行计划，还受到其他一些因素的影响。</p><ol>\n<li>优化器参数</li>\n</ol><p>前面我们介绍了参数eq_range_index_dive_limit的作用。还有其他几个参数也会影响优化器。</p><p>参数range_optimizer_max_mem_size用来限制range优化能使用的内存。对于where a in (x,x,x) and b in (x,x,x) and c in (x,x,x)这样的条件，每一个组合都会消耗一定的内存，当组合的数量特别多时，如果内存消耗量超出了range_optimizer_max_mem_size的限制，优化器就会放弃这个range优化，改为使用全表扫描。</p><p>下面这个例子中，我们将range_optimizer_max_mem_size设置得小一些，就能看到这样的waning信息“Memory capacity of 16384 bytes for ‘range_optimizer_max_mem_size’ exceeded”。现实中，我也遇到过由于in的组合数太多导致的全表扫描。这种情况下，即使使用了FORCE INDEX提示，优化器还是会使用全表扫描。</p><pre><code class=\"language-plain\">mysql&gt; set range_optimizer_max_mem_size=16384;\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql&gt; explain   select * from tab\n         where a in (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20)\n         and  b in (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20)\n         and c in (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20) ;\n+----+-------------+-------+------+---------------+------+---------+------+------+----------+-------------+\n| id | select_type | table | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra       |\n+----+-------------+-------+------+---------------+------+---------+------+------+----------+-------------+\n|  1 | SIMPLE      | tab   | ALL  | idx_abc       | NULL | NULL    | NULL | 9913 |    12.50 | Using where |\n+----+-------------+-------+------+---------------+------+---------+------+------+----------+-------------+\n1 row in set, 2 warnings (0.00 sec)\n\n\nmysql&gt; explain   select * from tab force index(idx_abc)\n     where a in (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20)\n     and  b in (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20)\n     and c in (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20) ;\n+----+-------------+-------+------+---------------+------+---------+------+------+----------+-------------+\n| id | select_type | table | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra       |\n+----+-------------+-------+------+---------------+------+---------+------+------+----------+-------------+\n|  1 | SIMPLE      | tab   | ALL  | idx_abc       | NULL | NULL    | NULL | 9913 |    12.50 | Using where |\n+----+-------------+-------+------+---------------+------+---------+------+------+----------+-------------+\n1 row in set, 2 warnings (0.00 sec)\n</code></pre><pre><code class=\"language-plain\">mysql&gt; show warnings\\G\n*************************** 1. row ***************************\n  Level: Warning\n   Code: 3170\nMessage: Memory capacity of 16384 bytes for 'range_optimizer_max_mem_size' exceeded. Range optimization was not done for this query.\n</code></pre><p>参数optimizer_switch提供了优化器很多功能的开关。后续的几讲中，我会对这里面的部分选项做一些介绍。</p><pre><code class=\"language-plain\">mysql&gt; show variables like 'optimizer_switch'\\G\n*************************** 1. row ***************************\nVariable_name: optimizer_switch\n        Value: index_merge=on,index_merge_union=on,index_merge_sort_union=on,index_merge_intersection=on,engine_condition_pushdown=on,index_condition_pushdown=on,mrr=on,mrr_cost_based=on,block_nested_loop=on,batched_key_access=off,materialization=on,semijoin=on,loosescan=on,firstmatch=on,duplicateweedout=on,subquery_materialization_cost_based=on,use_index_extensions=on,condition_fanout_filter=on,derived_merge=on,use_invisible_indexes=off,skip_scan=on,hash_join=on,subquery_to_derived=off,prefer_ordering_index=on,hypergraph_optimizer=off,derived_condition_pushdown=on\n</code></pre><p>参数optimizer_search_depth和optimizer_prune_level对多表接连查询有影响，我们在表连接那一讲中再来介绍。</p><ol start=\"2\">\n<li>优化器提示（hint）</li>\n</ol><p>优化器提示也能影响执行计划，上一讲中我们就使用了NO_SEMIJOIN、QB_NAME、BKA等提示来固定查询的执行计划。</p><p>平时比较常用的可能是FORCE INDEX、IGNORE INDEX、USE INDEX这些提示。FORCE INDEX中，可以指定多个索引。语句中加入force index提示后，优化器只会考虑使用这里面指定的索引。</p><p>下面的这个测试SQL使用了force index(idx_ac, idx_bc)，虽然ID是主键，但是可以看到，优化器没有考虑使用PRIMARY这个索引，而是使用了全表扫描。注意执行计划中，possible_keys为NULL。</p><pre><code class=\"language-plain\">mysql&gt; explain select * from t_cost force index(idx_ac, idx_bc) where id = 1;\n+----+-------------+--------+------+---------------+------+---------+------+------+----------+-------------+\n| id | select_type | table  | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra       |\n+----+-------------+--------+------+---------------+------+---------+------+------+----------+-------------+\n|  1 | SIMPLE      | t_cost | ALL  | NULL          | NULL | NULL    | NULL | 8580 |     0.01 | Using where |\n+----+-------------+--------+------+---------------+------+---------+------+------+----------+-------------+\n</code></pre><p>FORCE INDEX还有另外一个效果，如果语句可以使用到提示中的某个索引，那么就不使用全表扫描。</p><pre><code class=\"language-plain\">mysql&gt; explain select * from t_merge where a&gt;0;\n+----+-------------+---------+------+---------------+------+---------+------+----------+-------------+\n| id | select_type | table   | type | possible_keys | key  | key_len | rows | filtered | Extra       |\n+----+-------------+---------+------+---------------+------+---------+------+----------+-------------+\n|  1 | SIMPLE      | t_merge | ALL  | idx_ad        | NULL | NULL    | 9737 |    49.99 | Using where |\n+----+-------------+---------+------+---------------+------+---------+------+----------+-------------+\n\nmysql&gt; explain select * from t_merge force index(idx_ad, idx_bd)  where a &gt; 0;\n+----+-------------+---------+-------+---------------+--------+---------+------+----------+-----------------------+\n| id | select_type | table   | type  | possible_keys | key    | key_len | rows | filtered | Extra                 |\n+----+-------------+---------+-------+---------------+--------+---------+------+----------+-----------------------+\n|  1 | SIMPLE      | t_merge | range | idx_ad        | idx_ad | 4       | 4868 |   100.00 | Using index condition |\n+----+-------------+---------+-------+---------------+--------+---------+------+----------+-----------------------+\n</code></pre><h2>总结</h2><p>这一讲中，我们学习了MySQL优化器的一些工作原理。优化器会选择成本最低的执行计划。我们介绍了全表扫描和索引范围扫描这两种最基本，也是最重要的访问路径的成本计算方法。</p><p>实际工作中优化SQL时，我们并不需要真的知道某个执行计划的成本，那是优化器要计算的。但是我们需要理解全表扫描和索引访问大致的原理，理解这两种执行计划的开销来自哪里。</p><p>统计信息对优化器很重要，如果统计信息不准确，优化器很可能会选择错误的执行计划。我们还可以通过优化器参数、SQL提示来影响优化器。一般情况下我建议尽量少用SQL提示，让优化器自己选择最优的执行计划。在一些比较复杂的场景下，如果优化器确实选不到最优的执行计划时，再考虑使用SQL提示。</p><h2>思考题</h2><p>有时我们需要分段处理全表的数据。如果表使用了单列主键，那么可以很方便地按主键范围来进行数据分片。但有些情况下，业务使用了联合主键，那么此时你应该怎么按主键范围来对数据进行分片呢？</p><pre><code class=\"language-plain\">create table t_business(\n  id1 varchar(30) not null,\n  id2 varchar(30) not null,\n  id3 varchar(30) not null,\n  col1 ...,\n  col2 ...,\n  primry key(id1, id2, id3)\n) engine=innodb;\n</code></pre><p>考虑上面这个表，使用了联合主键(id1, id2, id3)。你需要分片处理这个表的数据，每次处理1000行数据，要求不要重复处理数据，但也不要漏掉任何一条数据。整个表的数据量比较大，要尽可能保证性能。你会怎么来写这个分页的SQL呢？</p><p>期待你的思考，欢迎在留言区中与我交流。如果今天的课程让你有所收获，也欢迎转发给有需要的朋友。我们下节课再见！</p>","neighbors":{"left":{"article_title":"18｜读懂MySQL中的执行计划（下）","id":810868},"right":{"article_title":"20｜单表查询：如何评估单表访问成本？","id":810682}},"comments":[{"had_liked":false,"id":394810,"user_name":"叶明","can_delete":false,"product_type":"c1","uid":1412429,"ip_address":"江苏","ucode":"D0B4B7660DA766","user_header":"https://static001.geekbang.org/account/avatar/00/15/8d/4d/992070e8.jpg","comment_is_top":false,"comment_ctime":1728458947,"is_pvip":false,"replies":[{"id":143373,"content":"这种写法是我能想到的，在这个场景下最好的方法。\n👍👍","user_name":"作者回复","user_name_real":"编辑","uid":3898827,"ctime":1728553084,"ip_address":"浙江","comment_id":394810,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100799401,"comment_content":"  \n另外，我看 gh-ost 的实现方式是另外一种，从左右边界和联合主键中字段之间的区间来考虑\n  1. 最左边的边界: id1=&#39;a&#39; and id2=&#39;a&#39; and id3=&#39;1&#39;，可以通过这个查询条件来拿到最左边界的记录\n  2. 联合主键 (id1, id2, id3) 中 id1 处于索引中第一列，因此 id1 是有序的，查询条件 id1&gt;&#39;a&#39; 拿到除 id1=&#39;a&#39; 之外的所有记录\n  3. 步骤2完成后，只需要考虑 id1=&#39;a&#39; 的最后一条记录与第一条记录 (id1=&#39;a&#39;, id2=&#39;a&#39;, id3=&#39;1&#39;) 这段范围的记录了\n  4. 当 id1=&#39;a&#39; and id2=&#39;a&#39; 时，要想访问 id3 的所有记录，查询条件得为 id3 &gt; &#39;1&#39;，这样就能拿到 id1, id2 为固定值时，id3 &gt; &#39;1&#39; 的所有记录，id3 = 1 的边界值在步骤 1 中已经拿到了\n  5. 步骤4完成后，满足 id1=&#39;a&#39; and id2=&#39;a&#39; 条件的所有记录已经能拿到了，接下来，拿 id1 = &#39;a&#39; 时，id2 &gt; &#39;a&#39; 的所有记录，这样，id1=&#39;a&#39; 的所有记录就都能拿到了\n\nselect\n  &#47;* gh-ost `test`.`t_business` iteration:0 *&#47; `id1`,\n  `id2`,\n  `id3`\nfrom\n  `test`.`t_business`\nwhere\n  (\n    (`id1` &gt; _binary &#39;a&#39;)\n    or (\n      ((`id1` = _binary &#39;a&#39;))\n      AND (`id2` &gt; _binary &#39;a&#39;)\n    )\n    or (\n      (\n        (`id1` = _binary &#39;a&#39;)\n        and (`id2` = _binary &#39;a&#39;)\n      )\n      AND (`id3` &gt; _binary &#39;1&#39;)\n    )\n    or (\n      (`id1` = _binary &#39;a&#39;)\n      and (`id2` = _binary &#39;a&#39;)\n      and (`id3` = _binary &#39;1&#39;)\n    )\n  )\n  and (\n    (`id1` &lt; _binary &#39;d&#39;)\n    or (\n      ((`id1` = _binary &#39;d&#39;))\n      AND (`id2` &lt; _binary &#39;a&#39;)\n    )\n    or (\n      (\n        (`id1` = _binary &#39;d&#39;)\n        and (`id2` = _binary &#39;a&#39;)\n      )\n      AND (`id3` &lt; _binary &#39;9990&#39;)\n    )\n    or (\n      (`id1` = _binary &#39;d&#39;)\n      and (`id2` = _binary &#39;a&#39;)\n      and (`id3` = _binary &#39;9990&#39;)\n    )\n  )\norder by\n  `id1` asc,\n  `id2` asc,\n  `id3` asc\nlimit\n  1\noffset\n  99","like_count":1,"discussions":[{"author":{"id":3898827,"avatar":"https://static001.geekbang.org/account/avatar/00/3b/7d/cb/fa3dae58.jpg","nickname":"俊达","note":"","ucode":"F79BF9651AD086","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":652261,"discussion_content":"这种写法是我能想到的，在这个场景下最好的方法。\n👍👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1728553084,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":394809,"user_name":"叶明","can_delete":false,"product_type":"c1","uid":1412429,"ip_address":"江苏","ucode":"D0B4B7660DA766","user_header":"https://static001.geekbang.org/account/avatar/00/15/8d/4d/992070e8.jpg","comment_is_top":false,"comment_ctime":1728458935,"is_pvip":false,"replies":[{"id":143372,"content":"是的。你想的这种方式，(id1, id2, id3) &gt;= (&#39;a&#39;, &#39;a&#39;, &#39;1&#39;) 我也尝试过，这种写法MySQL好像会全表扫描。😭😭","user_name":"作者回复","user_name_real":"编辑","uid":3898827,"ctime":1728552938,"ip_address":"浙江","comment_id":394809,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100799401,"comment_content":"联合主键的最小和最大值比较容易确定，比如我这里的最小值 (&#39;a&#39;, &#39;a&#39;, &#39;1&#39;)，最大值 (&#39;d&#39;, &#39;a&#39;, &#39;9990&#39;)，不能通过 id1&gt;=&#39;a&#39; and id2&gt;=&#39;a&#39; and id3&gt;=&#39;1&#39; 以及 id1&lt;=&#39;d&#39; and id2&lt;=&#39;a&#39; and id3 &lt;= &#39;9990&#39; 来进行数据分片，\n这是因为这三个字段作为联合主键，三个字段作为一个整体是有序的，但细化到 id2, id3 字段，则是当前面字段的值固定时，后面的字段才是有序的，如果按照 id1&gt;=&#39;a&#39; and id2&gt;=&#39;a&#39; and id3&gt;=&#39;1&#39; 去匹配，那么会漏掉一些数据。\n我想到的一种方式是将联合字段作为一个整体去匹配，例如 (id1, id2, id3) &gt;= (&#39;a&#39;, &#39;a&#39;, &#39;1&#39;)。","like_count":0,"discussions":[{"author":{"id":3898827,"avatar":"https://static001.geekbang.org/account/avatar/00/3b/7d/cb/fa3dae58.jpg","nickname":"俊达","note":"","ucode":"F79BF9651AD086","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":652260,"discussion_content":"是的。你想的这种方式，(id1, id2, id3) &gt;= (&#39;a&#39;, &#39;a&#39;, &#39;1&#39;) 我也尝试过，这种写法MySQL好像会全表扫描。😭😭","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1728552938,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":394801,"user_name":"ls","can_delete":false,"product_type":"c1","uid":1001037,"ip_address":"上海","ucode":"C18E208B1DFDA7","user_header":"https://static001.geekbang.org/account/avatar/00/0f/46/4d/161f3779.jpg","comment_is_top":false,"comment_ctime":1728448782,"is_pvip":true,"replies":[{"id":143374,"content":"这也是一种解法，避免了分页SQL。不过要注意，客户端要使用流式处理，不要一次性把整个表的数据都缓存在客户端。","user_name":"作者回复","user_name_real":"编辑","uid":3898827,"ctime":1728553296,"ip_address":"浙江","comment_id":394801,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100799401,"comment_content":"循环主键，根据主键去批量更新1000行，每1000行提交一次。是不是就可以了","like_count":0,"discussions":[{"author":{"id":3898827,"avatar":"https://static001.geekbang.org/account/avatar/00/3b/7d/cb/fa3dae58.jpg","nickname":"俊达","note":"","ucode":"F79BF9651AD086","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":652262,"discussion_content":"这也是一种解法，避免了分页SQL。不过要注意，客户端要使用流式处理，不要一次性把整个表的数据都缓存在客户端。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1728553296,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"浙江","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]}]}