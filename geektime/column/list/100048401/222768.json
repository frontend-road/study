{"id":222768,"title":"07 | NoSQL检索：为什么日志系统主要用LSM树而非B+树？","content":"<p>你好，我是陈东。</p><p>B+树作为检索引擎中的核心技术得到了广泛的使用，尤其是在关系型数据库中。</p><p>但是，在关系型数据库之外，还有许多常见的大数据应用场景，比如，日志系统、监控系统。这些应用场景有一个共同的特点，那就是数据会持续地大量生成，而且相比于检索操作，它们的写入操作会非常频繁。另外，即使是检索操作，往往也不是全范围的随机检索，更多的是针对近期数据的检索。</p><p>那对于这些应用场景来说，使用关系型数据库中的B+树是否合适呢？</p><p>我们知道，B+树的数据都存储在叶子节点中，而叶子节点一般都存储在磁盘中。因此，每次插入的新数据都需要随机写入磁盘，而随机写入的性能非常慢。如果是一个日志系统，每秒钟要写入上千条甚至上万条数据，这样的磁盘操作代价会使得系统性能急剧下降，甚至无法使用。</p><p>那么，针对这种频繁写入的场景，是否有更合适的存储结构和检索技术呢？今天，我们就来聊一聊另一种常见的设计思路和检索技术：<strong>LSM树</strong>（Log Structured Merge Trees）。LSM树也是近年来许多火热的NoSQL数据库中使用的检索技术。</p><h2>如何利用批量写入代替多次随机写入？</h2><p>刚才我们提到B+树随机写入慢的问题，对于这个问题，我们现在来思考一下优化想法。操作系统对磁盘的读写是以块为单位的，我们能否以块为单位写入，而不是每次插入一个数据都要随机写入磁盘呢？这样是不是就可以大幅度减少写入操作了呢？</p><!-- [[[read_end]]] --><p>LSM树就是根据这个思路设计了这样一个机制：当数据写入时，延迟写磁盘，将数据先存放在内存中的树里，进行常规的存储和查询。当内存中的树持续变大达到阈值时，再批量地以块为单位写入磁盘的树中。因此，LSM树至少需要由两棵树组成，一棵是存储在内存中较小的C0树，另一棵是存储在磁盘中较大的C1树。简单起见，接下来我们就假设只有C0树和C1树。<br>\n<img src=\"https://static001.geekbang.org/resource/image/32/61/3254e0cc752753de51e436e0f18ea761.jpg?wh=2007*900\" alt=\"\"></p><center><span class=\"reference\">LSM树由至少2部分组成：内存的C0树和磁盘的C1树</span></center><p>C1树存储在磁盘中，因此我们可以直接使用B+树来生成。那对于全部存储在内存中的C0树，我们该如何生成呢？在上一讲的重点回顾中我们分析过，在数据都能加载在内存中的时候，B+树并不是最合适的选择，它的效率并不会更高。因此，C0树我们可以选择其他的数据结构来实现，比如平衡二叉树甚至跳表等。但是为了让你更简单、清晰地理解LSM树的核心理念，我们可以假设C0树也是一棵B+树。</p><p>那现在C0树和C1树就都是B+树生成的了，但是相比于普通B+树生成的C0树，C1树有一个特点：所有的叶子节点都是满的。为什么会这样呢？原因就是，C1树不需要支持随机写入了，我们完全可以等内存中的数据写满一个叶子节点之后，再批量写入磁盘。因此，每个叶子节点都是满的，不需要预留空位来支持新数据的随机写入。</p><h2>如何保证批量写之前系统崩溃可以恢复？</h2><p>B+树随机写入慢的问题，我们已经知道解决的方案了。现在第二个问题来了：如果机器断电或系统崩溃了，那内存中还未写入磁盘的数据岂不就永远丢失了？这种情况我们该如何解决呢？</p><p>为了保证内存中的数据在系统崩溃后能恢复，工业界会使用<strong>WAL技术</strong>（Write Ahead Log，预写日志技术）将数据第一时间高效写入磁盘进行备份。WAL技术保存和恢复数据的具体步骤，我这里总结了一下。</p><ol>\n<li>内存中的程序在处理数据时，会先将对数据的修改作为一条记录，顺序写入磁盘的log文件作为备份。由于磁盘文件的顺序追加写入效率很高，因此许多应用场景都可以接受这种备份处理。</li>\n<li>在数据写入log文件后，备份就成功了。接下来，该数据就可以长期驻留在内存中了。</li>\n<li>系统会周期性地检查内存中的数据是否都被处理完了（比如，被删除或者写入磁盘），并且生成对应的检查点（Check Point）记录在磁盘中。然后，我们就可以随时删除被处理完的数据了。这样一来，log文件就不会无限增长了。</li>\n<li>系统崩溃重启，我们只需要从磁盘中读取检查点，就能知道最后一次成功处理的数据在log文件中的位置。接下来，我们就可以把这个位置之后未被处理的数据，从log文件中读出，然后重新加载到内存中。</li>\n</ol><p>通过这种预先将数据写入log文件备份，并在处理完成后生成检查点的机制，我们就可以安心地使用内存来存储和检索数据了。</p><h2>如何将内存数据与磁盘数据合并？</h2><p>解决了内存中数据备份的问题，我们就可以接着写入数据了。内存中C0树的大小是有上限的，那当C0树被写满之后，我们要怎么把它转换到磁盘中的C1树上呢？这就涉及<strong>滚动合并</strong>（Rolling Merge）的过程了。</p><p>我们可以参考两个有序链表归并排序的过程，将C0树和C1树的所有叶子节点中存储的数据，看作是两个有序链表，那滚动合并问题就变成了我们熟悉的两个有序链表的归并问题。不过由于涉及磁盘操作，那为了提高写入效率和检索效率，我们还需要针对磁盘的特性，在一些归并细节上进行优化。<br>\n<img src=\"https://static001.geekbang.org/resource/image/5e/6e/5ef5e0fde225587076b2f6d673f1c26e.jpg?wh=1983*959\" alt=\"\"></p><center><span class=\"reference\">C0树和C1树滚动合并可以视为有序链表归并</span></center><p>由于磁盘具有顺序读写效率高的特性，因此，为了提高C1树中节点的读写性能，除了根节点以外的节点都要尽可能地存放到连续的块中，让它们能作为一个整体单位来读写。这种包含多个节点的块就叫作<strong>多页块</strong>（Multi-Pages Block）。</p><p>下面，我们来讲一下滚动归并的过程。在进行滚动归并的时候，系统会遵循以下几个步骤。</p><p>第一步，以多页块为单位，将C1树的当前叶子节点从前往后读入内存。读入内存的多页块，叫作清空块（Emptying Block），意思是处理完以后会被清空。</p><p>第二步，将C0树的叶子节点和清空块中的数据进行归并排序，把归并的结果写入内存的一个新块中，叫作填充块（Filling Block）。</p><p>第三步，如果填充块写满了，我们就要将填充块作为新的叶节点集合顺序写入磁盘。这个时候，如果C0树的叶子节点和清空块都没有遍历完，我们就继续遍历归并，将数据写入新的填充块。如果清空块遍历完了，我们就去C1树中顺序读取新的多页块，加载到清空块中。</p><p>第四步，重复第三步，直到遍历完C0树和C1树的所有叶子节点，并将所有的归并结果写入到磁盘。这个时候，我们就可以同时删除C0树和C1树中被处理过的叶子节点。这样就完成了滚动归并的过程。<br>\n<img src=\"https://static001.geekbang.org/resource/image/8d/b1/8d66098f003da6d5845993f6f5cee1b1.jpeg?wh=1920*1080\" alt=\"\"></p><center><span class=\"reference\">使用清空块和填充块进行滚动归并</span></center><p>在C0树到C1树的滚动归并过程中，你会看到，几乎所有的读写操作都是以多页块为单位，将多个叶子节点进行顺序读写的。而且，因为磁盘的顺序读写性能和内存是一个数量级的，这使得LSM树的性能得到了大幅的提升。</p><h2>LSM树是如何检索的？</h2><p>现在你已经知道LSM树的组织过程了，我们可以来看，LSM树是如何完成检索的。</p><p>因为同时存在C0和C1树，所以要查询一个key时，我们会先到C0树中查询。如果查询到了则直接返回，不用再去查询C1树了。</p><p>而且，C0树会存储最新的一批数据，所以C0树中的数据一定会比C1树中的新。因此，如果一个系统的检索主要是针对近期数据的，那么大部分数据我们都能在内存中查到，检索效率就会非常高。</p><p>那如果我们在C0树中没有查询到key呢？这个时候，系统就会去磁盘中的C1树查询。在C1树中查到了，我们能直接返回吗？如果没有特殊处理的话，其实并不能。你可以先想想，这是为什么。</p><p>我们先来考虑一种情况：一个数据已经被写入系统了，并且我们也把它写入C1树了。但是，在最新的操作中，这个数据被删除了，那我们自然不会在C0树中查询到这个数据。可是它依然存在于C1树之中。</p><p>这种情况下，我们在C1树中检索到的就是过期的数据。既然是过期的数据，那为了不影响检索结果，我们能否从C1树中将这个数据删除呢？删除的思路没有错，但是不要忘了，我们不希望对C1树进行随机访问。这个时候，我们又该怎么处理呢？</p><p>我们依然可以采取延迟写入和批量操作的思路。对于被删除的数据，我们会将这些数据的key插入到C0树中，并且存入删除标志。如果C0树中已经存有这些数据，我们就将C0树中这些数据对应的key都加上删除标志。</p><p>这样一来，当我们在C0树中查询时，如果查到了一个带着删除标志的key，就直接返回查询失败，我们也就不用去查询C1树了。在滚动归并的时候，我们会查看数据在C0树中是否带有删除标志。如果有，滚动归并时就将它放弃。这样C1树就能批量完成“数据删除”的动作。</p><h2>重点回顾</h2><p>好了，今天的内容就先讲到这里。我们一起来回顾一下，你要掌握的重点内容。</p><p>在写大于读的应用场景下，尤其是在日志系统和监控系统这类应用中，我们可以选用基于LSM树的NoSQL数据库，这是比B+树更合适的技术方案。</p><p>LSM树具有以下3个特点：</p><ol>\n<li>将索引分为内存和磁盘两部分，并在内存达到阈值时启动树合并（Merge Trees）；</li>\n<li>用批量写入代替随机写入，并且用预写日志WAL技术保证内存数据，在系统崩溃后可以被恢复；</li>\n<li>数据采取类似日志追加写的方式写入（Log Structured）磁盘，以顺序写的方式提高写入效率。</li>\n</ol><p>LSM树的这些特点，使得它相对于B+树，在写入性能上有大幅提升。所以，许多NoSQL系统都使用LSM树作为检索引擎，而且还对LSM树进行了优化以提升检索性能。在后面的章节中我们会介绍，工业界中实际使用的LSM树是如何实现的，帮助你对LSM树有更深入的认识。</p><h2>课堂讨论</h2><p>为了方便你理解，文章中我直接用B+树实现的C0树。但是，对于纯内存操作，其他的类树结构会更合适。如果让你来设计的话，你会采用怎么样的结构作为C0树呢？</p><p>欢迎在留言区畅所欲言，说出你的思考过程和最终答案。如果有收获，也欢迎把这篇文章分享给你的朋友。</p>","comments":[{"had_liked":false,"id":204924,"user_name":"xzy","can_delete":false,"product_type":"c1","uid":1082132,"ip_address":"","ucode":"483350A630625E","user_header":"https://static001.geekbang.org/account/avatar/00/10/83/14/099742ae.jpg","comment_is_top":false,"comment_ctime":1586491922,"is_pvip":false,"replies":[{"id":76586,"content":"你这个问题很好！我提炼出来有三个点:\n1.wal的日志文件能否保证在物理空间上是顺序的?\n这个是可以做到的。日志文件都是追加写模式，包括可以提前分配好连续的磁盘空间，不受其他文件干扰。因此是可以保证空间的连续性。\n2.wal的日志文件和其他数据文件在一个磁盘，那么是否依然会面临磁头来回移动寻道寻址的问题?\n这个问题的确存在，如果日志文件和数据文件在同一个盘上，的确可能面临一个磁头来回移动的情况。因此，尽量不要在一个磁盘上同时开太多进程太多文件进行随机写。包括你看lsm的写磁盘，也是采用了顺序写。\n3.如果第二个问题存在，那么wal依然高效么？\nwal依然是高效的。一方面，如果是wal连续写(没有其他进程和文件竞争磁头)，那么效率自然提升；另一方面，往磁盘的日志文件中简单地追加写，总比处理好数据，组织好b+树的索引结构再写磁盘快很多。\n","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1586501255,"ip_address":"","comment_id":204924,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"请问，如果wal所在的盘和数据在同一个盘，那怎么保证wal落盘是顺序写呢，我理解也得寻道寻址","like_count":25},{"had_liked":false,"id":204958,"user_name":"兰柯一梦","can_delete":false,"product_type":"c1","uid":1064990,"ip_address":"","ucode":"C51330CAA4EAB7","user_header":"https://static001.geekbang.org/account/avatar/00/10/40/1e/910aef6a.jpg","comment_is_top":false,"comment_ctime":1586500639,"is_pvip":false,"replies":[{"id":76607,"content":"你说的很对，取决于使用场景。有的系统的确是使用哈希表的。还有使用红黑树和跳表的都有。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1586511636,"ip_address":"","comment_id":204958,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"感觉取决于系统需要提供什么样的功能，如果系统需要提供高效的查询不需要范围scan那么C0用hashmap都可以，如果需要scan那么平衡树或者skiplist比较合适。leveldb是使用skiplist来实现的，这里的checkpoint主要目的是定期将数据落盘后用来对log文件进行清理的，使得系统重启时不需要重放过多的log影响性能","like_count":21,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491325,"discussion_content":"你这个问题很好！我提炼出来有三个点:\n1.wal的日志文件能否保证在物理空间上是顺序的?\n这个是可以做到的。日志文件都是追加写模式，包括可以提前分配好连续的磁盘空间，不受其他文件干扰。因此是可以保证空间的连续性。\n2.wal的日志文件和其他数据文件在一个磁盘，那么是否依然会面临磁头来回移动寻道寻址的问题?\n这个问题的确存在，如果日志文件和数据文件在同一个盘上，的确可能面临一个磁头来回移动的情况。因此，尽量不要在一个磁盘上同时开太多进程太多文件进行随机写。包括你看lsm的写磁盘，也是采用了顺序写。\n3.如果第二个问题存在，那么wal依然高效么？\nwal依然是高效的。一方面，如果是wal连续写(没有其他进程和文件竞争磁头)，那么效率自然提升；另一方面，往磁盘的日志文件中简单地追加写，总比处理好数据，组织好b+树的索引结构再写磁盘快很多。\n","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1586501255,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1082132,"avatar":"https://static001.geekbang.org/account/avatar/00/10/83/14/099742ae.jpg","nickname":"xzy","note":"","ucode":"483350A630625E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":227698,"discussion_content":"赞同","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1586513519,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":220146,"user_name":"Joe Black","can_delete":false,"product_type":"c1","uid":1052528,"ip_address":"","ucode":"21FE222A286445","user_header":"https://static001.geekbang.org/account/avatar/00/10/0f/70/cdef7a3d.jpg","comment_is_top":false,"comment_ctime":1590188414,"is_pvip":false,"replies":[{"id":81285,"content":"你思考得很细致。关于wal技术，我补充一下:\n1.wal文件自身是个普通的文件。不过在如何处理这个文件上，也有一些特殊的方案。比如说预分配空间，就是为了保证这个文件在物理上是连续的，提高写入效率。预分配空间可以使用fallocate来实现。\n此外，为了避免不停的删除旧数据，追加新数据造成的文件操作性能问题，wal文件采用的是“循环写”机制。就是讲文件看着是一个循环数组，如果写入到文件尾了，那么就回到文件头继续写(前提是文件前面的数据已经被处理，标为无效)。\n2.wal文件的写入其实也是批量写，而不是每来一条记录就直接写磁盘。因此的确有可能出现wal文件也是不完整的现象。如果连wal文件都没有记录下来的数据，那么就是会丢失的数据。当然，wal文件会尽可能地完成文件落盘，而不是像c0树会在内存中保存那么久才落盘。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1590206160,"ip_address":"","comment_id":220146,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"请问WAL文件有什么特殊之处吗？还是说就是一个以append only方式打开的文件？写入日志后，是否每次都要同步到磁盘呢？如果不同步，那可能只在操作系统页面缓存吧？一断电不就也没了？另外老师说可以提前给日志文件分配空间，这个是具体怎么分配呢？seek过去写一下再seek回去吗？","like_count":11,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491337,"discussion_content":"你说的很对，取决于使用场景。有的系统的确是使用哈希表的。还有使用红黑树和跳表的都有。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586511636,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":205137,"user_name":"innocent","can_delete":false,"product_type":"c1","uid":1197455,"ip_address":"","ucode":"368659A0DDE7E4","user_header":"https://static001.geekbang.org/account/avatar/00/12/45/8f/a56b2214.jpg","comment_is_top":false,"comment_ctime":1586536849,"is_pvip":false,"replies":[{"id":76679,"content":"你提到了性能问题，的确是这样的。在高性能的lsm树实现中，不仅仅是内存中要有两棵，磁盘上还要有多棵。\n具体工业界是怎么真正实现一个高性能的lsm树，后面我会再具体介绍。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1586570292,"ip_address":"","comment_id":205137,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"为了性能内存中的树至少有两棵吧","like_count":10,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":496057,"discussion_content":"你思考得很细致。关于wal技术，我补充一下:\n1.wal文件自身是个普通的文件。不过在如何处理这个文件上，也有一些特殊的方案。比如说预分配空间，就是为了保证这个文件在物理上是连续的，提高写入效率。预分配空间可以使用fallocate来实现。\n此外，为了避免不停的删除旧数据，追加新数据造成的文件操作性能问题，wal文件采用的是“循环写”机制。就是讲文件看着是一个循环数组，如果写入到文件尾了，那么就回到文件头继续写(前提是文件前面的数据已经被处理，标为无效)。\n2.wal文件的写入其实也是批量写，而不是每来一条记录就直接写磁盘。因此的确有可能出现wal文件也是不完整的现象。如果连wal文件都没有记录下来的数据，那么就是会丢失的数据。当然，wal文件会尽可能地完成文件落盘，而不是像c0树会在内存中保存那么久才落盘。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1590206160,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":212670,"user_name":"taotaowang","can_delete":false,"product_type":"c1","uid":1365177,"ip_address":"","ucode":"108489DD55723A","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIvMlvSXsYgJibgutQdyFT6LsrXuvbjWVh0UpcF4esLzlWzBRlsFHA9MyBY38ibngKAN8mDn6DdHnMQ/132","comment_is_top":false,"comment_ctime":1588172213,"is_pvip":false,"replies":[{"id":79041,"content":"你的问题很好！进行对比和分析是很好的学习了解知识点的方式。\nlsm不是没有缺点的，它的读效率会比较差，并且存在写放大问题。这是因为，为了保证内存数据能高效写入磁盘(具体我会在17讲中分析)，其实磁盘上是有多棵树(c1树到ck树)，而不是只有一棵c1树。这会造成一次写操作会被放大n倍的问题。并且在查询的时候，如果查询数据不是最近的数据，那么会多次查询磁盘上的多棵树，使得lsm树的查询性能没有b+树好。这也是为什么它更适合用在写多读少的日志或监控系统中的缘故。\n另一方面，其实现在的b+树的工业实现也会借鉴lsm树的一些设计思想来提高效率。比如使用wal+内存来提高检索效率，然后在修改叶子节点的时候也是批量操作。如果两个新数据都是写入同一个叶子节点，那么效率就会比原先的每个数据修改一次叶子节点效率更高。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1588214804,"ip_address":"","comment_id":212670,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"有个疑问想请教老师 Lsm树读写性能都优于B+树，那关系型数据库为什么不采取这种数据结构存储呢？","like_count":8,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491402,"discussion_content":"你提到了性能问题，的确是这样的。在高性能的lsm树实现中，不仅仅是内存中要有两棵，磁盘上还要有多棵。\n具体工业界是怎么真正实现一个高性能的lsm树，后面我会再具体介绍。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586570292,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1197455,"avatar":"https://static001.geekbang.org/account/avatar/00/12/45/8f/a56b2214.jpg","nickname":"innocent","note":"","ucode":"368659A0DDE7E4","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":228698,"discussion_content":"感谢老师回复","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586570338,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":205043,"user_name":"xzy","can_delete":false,"product_type":"c1","uid":1082132,"ip_address":"","ucode":"483350A630625E","user_header":"https://static001.geekbang.org/account/avatar/00/10/83/14/099742ae.jpg","comment_is_top":false,"comment_ctime":1586514265,"is_pvip":false,"replies":[{"id":76628,"content":"这是一个好问题！对于SSD，这些理论和方法是否依然有效?答案是yes。\n考虑这么两点:\n1.SSD是以page作为读写单位，以block作为垃圾回收单位，因此，批量顺序写性能依然大幅高于随机写！\n2.SSD的性能和内存相比依然有差距，因此，先在内存处理好，再批量写入SSD依然是高效的。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1586519297,"ip_address":"","comment_id":205043,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"你好，这里还有个问题：如果是ssd，顺序写和随机写的差异不大，那么是否还有必要写wal， 毕竟写wal相当于double写了数据，那直接就写数据是否性能还会更好呢","like_count":8,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491365,"discussion_content":"这是一个好问题！对于SSD，这些理论和方法是否依然有效?答案是yes。\n考虑这么两点:\n1.SSD是以page作为读写单位，以block作为垃圾回收单位，因此，批量顺序写性能依然大幅高于随机写！\n2.SSD的性能和内存相比依然有差距，因此，先在内存处理好，再批量写入SSD依然是高效的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586519297,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":280488,"user_name":"快跑","can_delete":false,"product_type":"c1","uid":1564645,"ip_address":"","ucode":"90ED7E6D40C58E","user_header":"https://static001.geekbang.org/account/avatar/00/17/df/e5/65e37812.jpg","comment_is_top":false,"comment_ctime":1614233174,"is_pvip":false,"replies":[{"id":102782,"content":"总结得很好，所以你会看到，不同的设计其实有不同的取舍，这些取舍就会导致它们的特性和适用场景不同。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1615714793,"ip_address":"","comment_id":280488,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"随着越来越理解B+树和LSM树，\nB+树是写入的时候就找好key的位置，读取的时候直接根据索引查找key的值\nLSM是写入是可能一个key存在不同层的树上，读取的时候，需要合并key不同树上的值。\n相当于B+树是写入时merge，LSM是读取时候merge","like_count":7,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491365,"discussion_content":"这是一个好问题！对于SSD，这些理论和方法是否依然有效?答案是yes。\n考虑这么两点:\n1.SSD是以page作为读写单位，以block作为垃圾回收单位，因此，批量顺序写性能依然大幅高于随机写！\n2.SSD的性能和内存相比依然有差距，因此，先在内存处理好，再批量写入SSD依然是高效的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586519297,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":204989,"user_name":"奕","can_delete":false,"product_type":"c1","uid":1005391,"ip_address":"","ucode":"73CEA468CE70C3","user_header":"https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg","comment_is_top":false,"comment_ctime":1586504603,"is_pvip":false,"replies":[{"id":76627,"content":"你提了一个非常好的问题！把c1树的全部叶子节点处理一次的确效率不高，因此实际上会有多棵不同大小的磁盘上的树。包括工业界还有其他的优化思路。后面会介绍。\n此外，直接把c0树的叶子节点放在c1树后面，这样的话叶子节点就不是有序的了，就无法高效检索了。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1586518965,"ip_address":"","comment_id":204989,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"当内存的C0 树满时， 都要 把磁盘的 C1 树的全部数据 加载到内存中合并生成新树吗？ 我感觉这样性能不高啊。\n\n还有就是 类型日志系统，都是天然按照时间排序；这样的话 ，就可以直接把 C0 树的叶子节点直接放到 C1 树的叶子节点后面啊，没有必要在进行合并生成新树了","like_count":7,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":516113,"discussion_content":"总结得很好，所以你会看到，不同的设计其实有不同的取舍，这些取舍就会导致它们的特性和适用场景不同。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1615714793,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":204985,"user_name":"奕","can_delete":false,"product_type":"c1","uid":1005391,"ip_address":"","ucode":"73CEA468CE70C3","user_header":"https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg","comment_is_top":false,"comment_ctime":1586504204,"is_pvip":false,"replies":[{"id":76626,"content":"是新的磁盘空间。因为c1树要保证在磁盘上的连续性，如果是利用原c1树的旧空间的话，可能会放不下(因为合并了c0树的数据)。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1586518704,"ip_address":"","comment_id":204985,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"填充块写满了，我们就要将填充块作为新的叶节点集合顺序写入磁盘，\n\n这个时候 填充快写的磁盘位置会是之前C1 叶子节点 清空块的位置吗？ 还是另外开辟有个新的空间，当新的树生成后，在把旧的C1树 磁盘数据空间在标记为删除？","like_count":6,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491343,"discussion_content":"是新的磁盘空间。因为c1树要保证在磁盘上的连续性，如果是利用原c1树的旧空间的话，可能会放不下(因为合并了c0树的数据)。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586518704,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":204786,"user_name":"峰","can_delete":false,"product_type":"c1","uid":1056019,"ip_address":"","ucode":"C53CB64E8E7D19","user_header":"https://static001.geekbang.org/account/avatar/00/10/1d/13/31ea1b0b.jpg","comment_is_top":false,"comment_ctime":1586471932,"is_pvip":false,"replies":[{"id":76535,"content":"全内存数据库的确是一个研究热点。Redis的广泛流行也是这个潮流的一个例子。\nb+树即使能全部缓存到内存中，但你思考一下它插入删除的效率(分裂合并节点)，它不会比红黑树这些结构效率高。因此，纯内存的环境下，红黑树和跳表这类结构更受欢迎。\n","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1586483477,"ip_address":"","comment_id":204786,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"考虑的点\n1 随机和顺序存取差距不大\n2 什么样的有序结构适合高并发的写入\n对于2，必须插入的时候只影响局部，这样上锁这样开销就只在局部细粒度上，如果是树可能存在需要调整树高的各种旋转或者分裂合并操作。对于1，在说不用像b树那样降低树高，底层数据节点搞比较大的块，可以充分利用指针这种随机读取的力量，当然块太小有内存碎片之类的问题，以及jvm老年代跨代引用新生代之类问题，所以hbase中跳表的实现是基于chunk的。\n感觉自己好像逻辑不是很通，自己还想的不够透彻，其实也在思考全内存的数据库和基于b树这样的数据库在它的缓存可以容纳全部块，不用换入换出，这两种情况下全内存数据库的优势在哪里。","like_count":4,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491290,"discussion_content":"全内存数据库的确是一个研究热点。Redis的广泛流行也是这个潮流的一个例子。\nb+树即使能全部缓存到内存中，但你思考一下它插入删除的效率(分裂合并节点)，它不会比红黑树这些结构效率高。因此，纯内存的环境下，红黑树和跳表这类结构更受欢迎。\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586483477,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":204924,"user_name":"xzy","can_delete":false,"product_type":"c1","uid":1082132,"ip_address":"","ucode":"483350A630625E","user_header":"https://static001.geekbang.org/account/avatar/00/10/83/14/099742ae.jpg","comment_is_top":false,"comment_ctime":1586491922,"is_pvip":false,"replies":[{"id":76586,"content":"你这个问题很好！我提炼出来有三个点:\n1.wal的日志文件能否保证在物理空间上是顺序的?\n这个是可以做到的。日志文件都是追加写模式，包括可以提前分配好连续的磁盘空间，不受其他文件干扰。因此是可以保证空间的连续性。\n2.wal的日志文件和其他数据文件在一个磁盘，那么是否依然会面临磁头来回移动寻道寻址的问题?\n这个问题的确存在，如果日志文件和数据文件在同一个盘上，的确可能面临一个磁头来回移动的情况。因此，尽量不要在一个磁盘上同时开太多进程太多文件进行随机写。包括你看lsm的写磁盘，也是采用了顺序写。\n3.如果第二个问题存在，那么wal依然高效么？\nwal依然是高效的。一方面，如果是wal连续写(没有其他进程和文件竞争磁头)，那么效率自然提升；另一方面，往磁盘的日志文件中简单地追加写，总比处理好数据，组织好b+树的索引结构再写磁盘快很多。\n","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1586501255,"ip_address":"","comment_id":204924,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"请问，如果wal所在的盘和数据在同一个盘，那怎么保证wal落盘是顺序写呢，我理解也得寻道寻址","like_count":25,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491325,"discussion_content":"你这个问题很好！我提炼出来有三个点:\n1.wal的日志文件能否保证在物理空间上是顺序的?\n这个是可以做到的。日志文件都是追加写模式，包括可以提前分配好连续的磁盘空间，不受其他文件干扰。因此是可以保证空间的连续性。\n2.wal的日志文件和其他数据文件在一个磁盘，那么是否依然会面临磁头来回移动寻道寻址的问题?\n这个问题的确存在，如果日志文件和数据文件在同一个盘上，的确可能面临一个磁头来回移动的情况。因此，尽量不要在一个磁盘上同时开太多进程太多文件进行随机写。包括你看lsm的写磁盘，也是采用了顺序写。\n3.如果第二个问题存在，那么wal依然高效么？\nwal依然是高效的。一方面，如果是wal连续写(没有其他进程和文件竞争磁头)，那么效率自然提升；另一方面，往磁盘的日志文件中简单地追加写，总比处理好数据，组织好b+树的索引结构再写磁盘快很多。\n","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1586501255,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1082132,"avatar":"https://static001.geekbang.org/account/avatar/00/10/83/14/099742ae.jpg","nickname":"xzy","note":"","ucode":"483350A630625E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":227698,"discussion_content":"赞同","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1586513519,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":204958,"user_name":"兰柯一梦","can_delete":false,"product_type":"c1","uid":1064990,"ip_address":"","ucode":"C51330CAA4EAB7","user_header":"https://static001.geekbang.org/account/avatar/00/10/40/1e/910aef6a.jpg","comment_is_top":false,"comment_ctime":1586500639,"is_pvip":false,"replies":[{"id":76607,"content":"你说的很对，取决于使用场景。有的系统的确是使用哈希表的。还有使用红黑树和跳表的都有。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1586511636,"ip_address":"","comment_id":204958,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"感觉取决于系统需要提供什么样的功能，如果系统需要提供高效的查询不需要范围scan那么C0用hashmap都可以，如果需要scan那么平衡树或者skiplist比较合适。leveldb是使用skiplist来实现的，这里的checkpoint主要目的是定期将数据落盘后用来对log文件进行清理的，使得系统重启时不需要重放过多的log影响性能","like_count":21,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491337,"discussion_content":"你说的很对，取决于使用场景。有的系统的确是使用哈希表的。还有使用红黑树和跳表的都有。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586511636,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":220146,"user_name":"Joe Black","can_delete":false,"product_type":"c1","uid":1052528,"ip_address":"","ucode":"21FE222A286445","user_header":"https://static001.geekbang.org/account/avatar/00/10/0f/70/cdef7a3d.jpg","comment_is_top":false,"comment_ctime":1590188414,"is_pvip":false,"replies":[{"id":81285,"content":"你思考得很细致。关于wal技术，我补充一下:\n1.wal文件自身是个普通的文件。不过在如何处理这个文件上，也有一些特殊的方案。比如说预分配空间，就是为了保证这个文件在物理上是连续的，提高写入效率。预分配空间可以使用fallocate来实现。\n此外，为了避免不停的删除旧数据，追加新数据造成的文件操作性能问题，wal文件采用的是“循环写”机制。就是讲文件看着是一个循环数组，如果写入到文件尾了，那么就回到文件头继续写(前提是文件前面的数据已经被处理，标为无效)。\n2.wal文件的写入其实也是批量写，而不是每来一条记录就直接写磁盘。因此的确有可能出现wal文件也是不完整的现象。如果连wal文件都没有记录下来的数据，那么就是会丢失的数据。当然，wal文件会尽可能地完成文件落盘，而不是像c0树会在内存中保存那么久才落盘。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1590206160,"ip_address":"","comment_id":220146,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"请问WAL文件有什么特殊之处吗？还是说就是一个以append only方式打开的文件？写入日志后，是否每次都要同步到磁盘呢？如果不同步，那可能只在操作系统页面缓存吧？一断电不就也没了？另外老师说可以提前给日志文件分配空间，这个是具体怎么分配呢？seek过去写一下再seek回去吗？","like_count":11,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":496057,"discussion_content":"你思考得很细致。关于wal技术，我补充一下:\n1.wal文件自身是个普通的文件。不过在如何处理这个文件上，也有一些特殊的方案。比如说预分配空间，就是为了保证这个文件在物理上是连续的，提高写入效率。预分配空间可以使用fallocate来实现。\n此外，为了避免不停的删除旧数据，追加新数据造成的文件操作性能问题，wal文件采用的是“循环写”机制。就是讲文件看着是一个循环数组，如果写入到文件尾了，那么就回到文件头继续写(前提是文件前面的数据已经被处理，标为无效)。\n2.wal文件的写入其实也是批量写，而不是每来一条记录就直接写磁盘。因此的确有可能出现wal文件也是不完整的现象。如果连wal文件都没有记录下来的数据，那么就是会丢失的数据。当然，wal文件会尽可能地完成文件落盘，而不是像c0树会在内存中保存那么久才落盘。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1590206160,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":205137,"user_name":"innocent","can_delete":false,"product_type":"c1","uid":1197455,"ip_address":"","ucode":"368659A0DDE7E4","user_header":"https://static001.geekbang.org/account/avatar/00/12/45/8f/a56b2214.jpg","comment_is_top":false,"comment_ctime":1586536849,"is_pvip":false,"replies":[{"id":76679,"content":"你提到了性能问题，的确是这样的。在高性能的lsm树实现中，不仅仅是内存中要有两棵，磁盘上还要有多棵。\n具体工业界是怎么真正实现一个高性能的lsm树，后面我会再具体介绍。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1586570292,"ip_address":"","comment_id":205137,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"为了性能内存中的树至少有两棵吧","like_count":10,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491402,"discussion_content":"你提到了性能问题，的确是这样的。在高性能的lsm树实现中，不仅仅是内存中要有两棵，磁盘上还要有多棵。\n具体工业界是怎么真正实现一个高性能的lsm树，后面我会再具体介绍。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586570292,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1197455,"avatar":"https://static001.geekbang.org/account/avatar/00/12/45/8f/a56b2214.jpg","nickname":"innocent","note":"","ucode":"368659A0DDE7E4","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":228698,"discussion_content":"感谢老师回复","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586570338,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":212670,"user_name":"taotaowang","can_delete":false,"product_type":"c1","uid":1365177,"ip_address":"","ucode":"108489DD55723A","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIvMlvSXsYgJibgutQdyFT6LsrXuvbjWVh0UpcF4esLzlWzBRlsFHA9MyBY38ibngKAN8mDn6DdHnMQ/132","comment_is_top":false,"comment_ctime":1588172213,"is_pvip":false,"replies":[{"id":79041,"content":"你的问题很好！进行对比和分析是很好的学习了解知识点的方式。\nlsm不是没有缺点的，它的读效率会比较差，并且存在写放大问题。这是因为，为了保证内存数据能高效写入磁盘(具体我会在17讲中分析)，其实磁盘上是有多棵树(c1树到ck树)，而不是只有一棵c1树。这会造成一次写操作会被放大n倍的问题。并且在查询的时候，如果查询数据不是最近的数据，那么会多次查询磁盘上的多棵树，使得lsm树的查询性能没有b+树好。这也是为什么它更适合用在写多读少的日志或监控系统中的缘故。\n另一方面，其实现在的b+树的工业实现也会借鉴lsm树的一些设计思想来提高效率。比如使用wal+内存来提高检索效率，然后在修改叶子节点的时候也是批量操作。如果两个新数据都是写入同一个叶子节点，那么效率就会比原先的每个数据修改一次叶子节点效率更高。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1588214804,"ip_address":"","comment_id":212670,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"有个疑问想请教老师 Lsm树读写性能都优于B+树，那关系型数据库为什么不采取这种数据结构存储呢？","like_count":8,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493577,"discussion_content":"你的问题很好！进行对比和分析是很好的学习了解知识点的方式。\nlsm不是没有缺点的，它的读效率会比较差，并且存在写放大问题。这是因为，为了保证内存数据能高效写入磁盘(具体我会在17讲中分析)，其实磁盘上是有多棵树(c1树到ck树)，而不是只有一棵c1树。这会造成一次写操作会被放大n倍的问题。并且在查询的时候，如果查询数据不是最近的数据，那么会多次查询磁盘上的多棵树，使得lsm树的查询性能没有b+树好。这也是为什么它更适合用在写多读少的日志或监控系统中的缘故。\n另一方面，其实现在的b+树的工业实现也会借鉴lsm树的一些设计思想来提高效率。比如使用wal+内存来提高检索效率，然后在修改叶子节点的时候也是批量操作。如果两个新数据都是写入同一个叶子节点，那么效率就会比原先的每个数据修改一次叶子节点效率更高。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588214804,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":205043,"user_name":"xzy","can_delete":false,"product_type":"c1","uid":1082132,"ip_address":"","ucode":"483350A630625E","user_header":"https://static001.geekbang.org/account/avatar/00/10/83/14/099742ae.jpg","comment_is_top":false,"comment_ctime":1586514265,"is_pvip":false,"replies":[{"id":76628,"content":"这是一个好问题！对于SSD，这些理论和方法是否依然有效?答案是yes。\n考虑这么两点:\n1.SSD是以page作为读写单位，以block作为垃圾回收单位，因此，批量顺序写性能依然大幅高于随机写！\n2.SSD的性能和内存相比依然有差距，因此，先在内存处理好，再批量写入SSD依然是高效的。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1586519297,"ip_address":"","comment_id":205043,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"你好，这里还有个问题：如果是ssd，顺序写和随机写的差异不大，那么是否还有必要写wal， 毕竟写wal相当于double写了数据，那直接就写数据是否性能还会更好呢","like_count":8,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493577,"discussion_content":"你的问题很好！进行对比和分析是很好的学习了解知识点的方式。\nlsm不是没有缺点的，它的读效率会比较差，并且存在写放大问题。这是因为，为了保证内存数据能高效写入磁盘(具体我会在17讲中分析)，其实磁盘上是有多棵树(c1树到ck树)，而不是只有一棵c1树。这会造成一次写操作会被放大n倍的问题。并且在查询的时候，如果查询数据不是最近的数据，那么会多次查询磁盘上的多棵树，使得lsm树的查询性能没有b+树好。这也是为什么它更适合用在写多读少的日志或监控系统中的缘故。\n另一方面，其实现在的b+树的工业实现也会借鉴lsm树的一些设计思想来提高效率。比如使用wal+内存来提高检索效率，然后在修改叶子节点的时候也是批量操作。如果两个新数据都是写入同一个叶子节点，那么效率就会比原先的每个数据修改一次叶子节点效率更高。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588214804,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":280488,"user_name":"快跑","can_delete":false,"product_type":"c1","uid":1564645,"ip_address":"","ucode":"90ED7E6D40C58E","user_header":"https://static001.geekbang.org/account/avatar/00/17/df/e5/65e37812.jpg","comment_is_top":false,"comment_ctime":1614233174,"is_pvip":false,"replies":[{"id":102782,"content":"总结得很好，所以你会看到，不同的设计其实有不同的取舍，这些取舍就会导致它们的特性和适用场景不同。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1615714793,"ip_address":"","comment_id":280488,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"随着越来越理解B+树和LSM树，\nB+树是写入的时候就找好key的位置，读取的时候直接根据索引查找key的值\nLSM是写入是可能一个key存在不同层的树上，读取的时候，需要合并key不同树上的值。\n相当于B+树是写入时merge，LSM是读取时候merge","like_count":7,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":516113,"discussion_content":"总结得很好，所以你会看到，不同的设计其实有不同的取舍，这些取舍就会导致它们的特性和适用场景不同。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1615714793,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":204989,"user_name":"奕","can_delete":false,"product_type":"c1","uid":1005391,"ip_address":"","ucode":"73CEA468CE70C3","user_header":"https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg","comment_is_top":false,"comment_ctime":1586504603,"is_pvip":false,"replies":[{"id":76627,"content":"你提了一个非常好的问题！把c1树的全部叶子节点处理一次的确效率不高，因此实际上会有多棵不同大小的磁盘上的树。包括工业界还有其他的优化思路。后面会介绍。\n此外，直接把c0树的叶子节点放在c1树后面，这样的话叶子节点就不是有序的了，就无法高效检索了。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1586518965,"ip_address":"","comment_id":204989,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"当内存的C0 树满时， 都要 把磁盘的 C1 树的全部数据 加载到内存中合并生成新树吗？ 我感觉这样性能不高啊。\n\n还有就是 类型日志系统，都是天然按照时间排序；这样的话 ，就可以直接把 C0 树的叶子节点直接放到 C1 树的叶子节点后面啊，没有必要在进行合并生成新树了","like_count":7,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491345,"discussion_content":"你提了一个非常好的问题！把c1树的全部叶子节点处理一次的确效率不高，因此实际上会有多棵不同大小的磁盘上的树。包括工业界还有其他的优化思路。后面会介绍。\n此外，直接把c0树的叶子节点放在c1树后面，这样的话叶子节点就不是有序的了，就无法高效检索了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586518965,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1218937,"avatar":"https://static001.geekbang.org/account/avatar/00/12/99/79/74d4f24f.jpg","nickname":"anker","note":"","ucode":"6EDF1FB9D45238","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":387362,"discussion_content":"实际上，业界处理C0树满的方案是多个磁盘树，写满了就往磁盘里面写，检索数据的时候会从新到旧找磁盘树，找到没有为止。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1628134972,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":204985,"user_name":"奕","can_delete":false,"product_type":"c1","uid":1005391,"ip_address":"","ucode":"73CEA468CE70C3","user_header":"https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg","comment_is_top":false,"comment_ctime":1586504204,"is_pvip":false,"replies":[{"id":76626,"content":"是新的磁盘空间。因为c1树要保证在磁盘上的连续性，如果是利用原c1树的旧空间的话，可能会放不下(因为合并了c0树的数据)。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1586518704,"ip_address":"","comment_id":204985,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"填充块写满了，我们就要将填充块作为新的叶节点集合顺序写入磁盘，\n\n这个时候 填充快写的磁盘位置会是之前C1 叶子节点 清空块的位置吗？ 还是另外开辟有个新的空间，当新的树生成后，在把旧的C1树 磁盘数据空间在标记为删除？","like_count":6,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491345,"discussion_content":"你提了一个非常好的问题！把c1树的全部叶子节点处理一次的确效率不高，因此实际上会有多棵不同大小的磁盘上的树。包括工业界还有其他的优化思路。后面会介绍。\n此外，直接把c0树的叶子节点放在c1树后面，这样的话叶子节点就不是有序的了，就无法高效检索了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586518965,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1218937,"avatar":"https://static001.geekbang.org/account/avatar/00/12/99/79/74d4f24f.jpg","nickname":"anker","note":"","ucode":"6EDF1FB9D45238","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":387362,"discussion_content":"实际上，业界处理C0树满的方案是多个磁盘树，写满了就往磁盘里面写，检索数据的时候会从新到旧找磁盘树，找到没有为止。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1628134972,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":204786,"user_name":"峰","can_delete":false,"product_type":"c1","uid":1056019,"ip_address":"","ucode":"C53CB64E8E7D19","user_header":"https://static001.geekbang.org/account/avatar/00/10/1d/13/31ea1b0b.jpg","comment_is_top":false,"comment_ctime":1586471932,"is_pvip":false,"replies":[{"id":76535,"content":"全内存数据库的确是一个研究热点。Redis的广泛流行也是这个潮流的一个例子。\nb+树即使能全部缓存到内存中，但你思考一下它插入删除的效率(分裂合并节点)，它不会比红黑树这些结构效率高。因此，纯内存的环境下，红黑树和跳表这类结构更受欢迎。\n","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1586483477,"ip_address":"","comment_id":204786,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100048401,"comment_content":"考虑的点\n1 随机和顺序存取差距不大\n2 什么样的有序结构适合高并发的写入\n对于2，必须插入的时候只影响局部，这样上锁这样开销就只在局部细粒度上，如果是树可能存在需要调整树高的各种旋转或者分裂合并操作。对于1，在说不用像b树那样降低树高，底层数据节点搞比较大的块，可以充分利用指针这种随机读取的力量，当然块太小有内存碎片之类的问题，以及jvm老年代跨代引用新生代之类问题，所以hbase中跳表的实现是基于chunk的。\n感觉自己好像逻辑不是很通，自己还想的不够透彻，其实也在思考全内存的数据库和基于b树这样的数据库在它的缓存可以容纳全部块，不用换入换出，这两种情况下全内存数据库的优势在哪里。","like_count":4,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491343,"discussion_content":"是新的磁盘空间。因为c1树要保证在磁盘上的连续性，如果是利用原c1树的旧空间的话，可能会放不下(因为合并了c0树的数据)。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586518704,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":205197,"user_name":"pedro","can_delete":false,"product_type":"c1","uid":1200704,"ip_address":"","ucode":"F40C839DDFD599","user_header":"https://static001.geekbang.org/account/avatar/00/12/52/40/e57a736e.jpg","comment_is_top":false,"comment_ctime":1586569415,"is_pvip":false,"replies":[{"id":76678,"content":"很好！你提到了bitcask，它是用哈希表作为内存索引的。其他的一些nosql实现，还有选择红黑树和跳表的。因此你会发现，对于内存中高效检索的技术选型，不同应用会根据自己的需求，选择我们在基础篇介绍过的适用技术。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1586570120,"ip_address":"","comment_id":205197,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"不知道为什么我昨天发布成功的评论没有被通过，可能 bug了，那我重说一次😭。\n\n问题，前面的文章提到 B 树是为了解决磁盘 io 的问题而引入的，所以 B 树自然不适合做内存索引，适合的是红黑球和跳表。\n\n当然也有例外，如小而美的 Bitcask 就选择了哈希表作为内存索引，是学习 Log-structure 的最佳入门数据库。","like_count":3},{"had_liked":false,"id":231240,"user_name":"图灵机","can_delete":false,"product_type":"c1","uid":2034632,"ip_address":"","ucode":"EB02DB653AD591","user_header":"https://static001.geekbang.org/account/avatar/00/1f/0b/c8/15f055d3.jpg","comment_is_top":false,"comment_ctime":1593612742,"is_pvip":false,"replies":[{"id":85471,"content":"谢谢支持。越看越爽，说明你能感受到了内容递进的魅力，再坚持一下，后面更酸爽哦。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1593700420,"ip_address":"","comment_id":231240,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"每天回家最享受的时间就是看这个课程，越看越爽","like_count":2,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491420,"discussion_content":"很好！你提到了bitcask，它是用哈希表作为内存索引的。其他的一些nosql实现，还有选择红黑树和跳表的。因此你会发现，对于内存中高效检索的技术选型，不同应用会根据自己的需求，选择我们在基础篇介绍过的适用技术。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586570120,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":214254,"user_name":"fengyi","can_delete":false,"product_type":"c1","uid":1258324,"ip_address":"","ucode":"C6FA77BE015F5A","user_header":"https://static001.geekbang.org/account/avatar/00/13/33/54/595be268.jpg","comment_is_top":false,"comment_ctime":1588685411,"is_pvip":false,"replies":[{"id":79334,"content":"因为所有的数据要么在c0中，要么在c1中，因此，c0和c1包含了所有的数据。\n由于c0写满以后，才会合并到c1中去。因此，c0中的数据一定是新数据，而c1的数据都会比c0的老。\n因此，如果你想找一个老数据的话，那么c0树中很可能找不到，需要到c1树中去找。并不需要新建c0。\n还有，c0是否要新建，只和c0是否写满了有关，和我们是否在查找老数据没关系。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1588697125,"ip_address":"","comment_id":214254,"utype":1}],"discussion_count":3,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"想请问一下。C0 和 C1 里面有包含所有的数据吗？如果搜寻一个比较老旧的数据。会需要建立一个新的C0吗？","like_count":1,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":500212,"discussion_content":"谢谢支持。越看越爽，说明你能感受到了内容递进的魅力，再坚持一下，后面更酸爽哦。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1593700420,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":211211,"user_name":"aoe","can_delete":false,"product_type":"c1","uid":1121758,"ip_address":"","ucode":"1C6201EDB4E954","user_header":"https://static001.geekbang.org/account/avatar/00/11/1d/de/62bfa83f.jpg","comment_is_top":false,"comment_ctime":1587915472,"is_pvip":false,"replies":[{"id":78556,"content":"欢迎多在讨论区提问和交流，相信对自己和对别人都是有帮助的~","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1587950989,"ip_address":"","comment_id":211211,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"评论很精彩，又学到了很多","like_count":1,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493220,"discussion_content":"欢迎多在讨论区提问和交流，相信对自己和对别人都是有帮助的~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587950989,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":206492,"user_name":"yang","can_delete":false,"product_type":"c1","uid":1074310,"ip_address":"","ucode":"1AA1497C5A293C","user_header":"https://static001.geekbang.org/account/avatar/00/10/64/86/f5a9403a.jpg","comment_is_top":false,"comment_ctime":1586869605,"is_pvip":false,"replies":[{"id":77151,"content":"这个不就是我在04课和测试题里出现的例子么？赶紧翻一下04课看一看就知道啦","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1586871420,"ip_address":"","comment_id":206492,"utype":1}],"discussion_count":2,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"老师我问个面试题啊：\n\n现在爬了100亿条URL ，每条url 64字节，我该怎么存在？\n\n然后问如何快速检索某条url在不在其中？\n\n每条64B，100亿条就是640G，这个好大。\n想了一下编号，实在太大了，100亿条。\n可以打标签吗？\n或者针对域名的开始的字母按顺序建立B+树的索引？ \n完整数据按块存储在叶子结点上？ 这样可以加快查询吧","like_count":1,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491812,"discussion_content":"这个不就是我在04课和测试题里出现的例子么？赶紧翻一下04课看一看就知道啦","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586871420,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1121758,"avatar":"https://static001.geekbang.org/account/avatar/00/11/1d/de/62bfa83f.jpg","nickname":"aoe","note":"","ucode":"1C6201EDB4E954","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":249309,"discussion_content":"布隆过滤器\n数据分片存","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1587915210,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":205155,"user_name":"那时刻","can_delete":false,"product_type":"c1","uid":1150927,"ip_address":"","ucode":"B0D150856C3A4A","user_header":"https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg","comment_is_top":false,"comment_ctime":1586559259,"is_pvip":false,"replies":[{"id":76686,"content":"1.check point的信息是独立存在的，和wal的日志文件是不同文件。\n2.check point的触发条件可以有多个，比如说间隔时长达到了预定时间，比如说wal文件增长到一定程度，甚至还可以主动调用check point相关命令强制执行。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1586573423,"ip_address":"","comment_id":205155,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"请问两个关于检查点check point的问题。\n1.检查点也是要落盘，和WAL一样的位置么？\n2.在数据删除和同步到硬盘之后会生成检查点，还有其它情况会生成检查点么？","like_count":1,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491409,"discussion_content":"1.check point的信息是独立存在的，和wal的日志文件是不同文件。\n2.check point的触发条件可以有多个，比如说间隔时长达到了预定时间，比如说wal文件增长到一定程度，甚至还可以主动调用check point相关命令强制执行。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586573423,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":204788,"user_name":"每天晒白牙","can_delete":false,"product_type":"c1","uid":1004698,"ip_address":"","ucode":"A1B102CD933DEA","user_header":"https://static001.geekbang.org/account/avatar/00/0f/54/9a/76c0af70.jpg","comment_is_top":false,"comment_ctime":1586473481,"is_pvip":false,"replies":[{"id":76536,"content":"是的。如果你有关注一些内存数据库，你会发现，有好些是使用跳表和红黑树来实现的。比如Redis。\n可见，b+树不是万能的。我们理解了存储介质的特性以后，能帮助我们在合适的场景做出正确的技术选型。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1586483733,"ip_address":"","comment_id":204788,"utype":1}],"discussion_count":2,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"思考题\n对于c0树因为是存放在内存中的，可以用平衡二叉树或跳表来代替 B+ 树","like_count":1,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491409,"discussion_content":"1.check point的信息是独立存在的，和wal的日志文件是不同文件。\n2.check point的触发条件可以有多个，比如说间隔时长达到了预定时间，比如说wal文件增长到一定程度，甚至还可以主动调用check point相关命令强制执行。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586573423,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":315572,"user_name":"armatrix","can_delete":false,"product_type":"c1","uid":2803119,"ip_address":"","ucode":"CCBF1181DDCD23","user_header":"https://static001.geekbang.org/account/avatar/00/2a/c5/af/174261ab.jpg","comment_is_top":false,"comment_ctime":1633921974,"is_pvip":false,"replies":[{"id":116693,"content":"是的，删除采用flag标志在许多场景都有使用。这是一个很常见的技巧","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1636813497,"ip_address":"","comment_id":315572,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"c0树和c1树flag的使用，同样也可以应用在一些业务上状态在cache和持久化存储之间吧？","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":528094,"discussion_content":"是的，删除采用flag标志在许多场景都有使用。这是一个很常见的技巧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1636813497,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":292746,"user_name":"森林木","can_delete":false,"product_type":"c1","uid":1220089,"ip_address":"","ucode":"79A06FCC43673B","user_header":"https://static001.geekbang.org/account/avatar/00/12/9d/f9/b98d9c40.jpg","comment_is_top":false,"comment_ctime":1620959838,"is_pvip":false,"replies":[{"id":107520,"content":"在这一篇中，主要还还是介绍了lsm树的原理，真正的工业实现的确需要考虑很多细节问题。在后面你会看到，真实的工业界的lsm树是用不一样的方式实现的。\n不过一个高效设计的原则，就是磁盘上的节点是只读的，这样就不会有读写的问题;而内存中的节点可能会同时有读写，那么可以加锁。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1622900778,"ip_address":"","comment_id":292746,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"老师，问一下如果在归并的过程中又有写入该怎么处理?","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":519944,"discussion_content":"在这一篇中，主要还还是介绍了lsm树的原理，真正的工业实现的确需要考虑很多细节问题。在后面你会看到，真实的工业界的lsm树是用不一样的方式实现的。\n不过一个高效设计的原则，就是磁盘上的节点是只读的，这样就不会有读写的问题;而内存中的节点可能会同时有读写，那么可以加锁。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1622900778,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":286478,"user_name":"entropy","can_delete":false,"product_type":"c1","uid":2464905,"ip_address":"","ucode":"0CDF7EC5A3AF75","user_header":"","comment_is_top":false,"comment_ctime":1617334857,"is_pvip":false,"replies":[{"id":104104,"content":"在这一篇原理介绍中，假设只有两棵树，c0树和c1树。c0树在内存中，受限于内存大小，因此较小;c1树在磁盘中，是c0树不停归并而成，因此会较大。\n当然，在工业界的实际系统实现中，磁盘中不是只有一颗c1树，而是多个文件块，具体的实现方式的确如你所说的，直接把内存刷入磁盘中。当然，磁盘中有多棵树以后，后续处理会变复杂，具体可以看我后面的leveldb的介绍。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1617447180,"ip_address":"","comment_id":286478,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"为什么C0小而C1大呢，如果C0和C1一样大，每次内存到达阈值（这时候应该是多个块大小吧），直接刷到硬盘呢？","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":518001,"discussion_content":"在这一篇原理介绍中，假设只有两棵树，c0树和c1树。c0树在内存中，受限于内存大小，因此较小;c1树在磁盘中，是c0树不停归并而成，因此会较大。\n当然，在工业界的实际系统实现中，磁盘中不是只有一颗c1树，而是多个文件块，具体的实现方式的确如你所说的，直接把内存刷入磁盘中。当然，磁盘中有多棵树以后，后续处理会变复杂，具体可以看我后面的leveldb的介绍。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617447180,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":205197,"user_name":"pedro","can_delete":false,"product_type":"c1","uid":1200704,"ip_address":"","ucode":"F40C839DDFD599","user_header":"https://static001.geekbang.org/account/avatar/00/12/52/40/e57a736e.jpg","comment_is_top":false,"comment_ctime":1586569415,"is_pvip":false,"replies":[{"id":76678,"content":"很好！你提到了bitcask，它是用哈希表作为内存索引的。其他的一些nosql实现，还有选择红黑树和跳表的。因此你会发现，对于内存中高效检索的技术选型，不同应用会根据自己的需求，选择我们在基础篇介绍过的适用技术。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1586570120,"ip_address":"","comment_id":205197,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"不知道为什么我昨天发布成功的评论没有被通过，可能 bug了，那我重说一次😭。\n\n问题，前面的文章提到 B 树是为了解决磁盘 io 的问题而引入的，所以 B 树自然不适合做内存索引，适合的是红黑球和跳表。\n\n当然也有例外，如小而美的 Bitcask 就选择了哈希表作为内存索引，是学习 Log-structure 的最佳入门数据库。","like_count":3,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491420,"discussion_content":"很好！你提到了bitcask，它是用哈希表作为内存索引的。其他的一些nosql实现，还有选择红黑树和跳表的。因此你会发现，对于内存中高效检索的技术选型，不同应用会根据自己的需求，选择我们在基础篇介绍过的适用技术。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586570120,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":231240,"user_name":"图灵机","can_delete":false,"product_type":"c1","uid":2034632,"ip_address":"","ucode":"EB02DB653AD591","user_header":"https://static001.geekbang.org/account/avatar/00/1f/0b/c8/15f055d3.jpg","comment_is_top":false,"comment_ctime":1593612742,"is_pvip":false,"replies":[{"id":85471,"content":"谢谢支持。越看越爽，说明你能感受到了内容递进的魅力，再坚持一下，后面更酸爽哦。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1593700420,"ip_address":"","comment_id":231240,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"每天回家最享受的时间就是看这个课程，越看越爽","like_count":2,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":500212,"discussion_content":"谢谢支持。越看越爽，说明你能感受到了内容递进的魅力，再坚持一下，后面更酸爽哦。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1593700420,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":214254,"user_name":"fengyi","can_delete":false,"product_type":"c1","uid":1258324,"ip_address":"","ucode":"C6FA77BE015F5A","user_header":"https://static001.geekbang.org/account/avatar/00/13/33/54/595be268.jpg","comment_is_top":false,"comment_ctime":1588685411,"is_pvip":false,"replies":[{"id":79334,"content":"因为所有的数据要么在c0中，要么在c1中，因此，c0和c1包含了所有的数据。\n由于c0写满以后，才会合并到c1中去。因此，c0中的数据一定是新数据，而c1的数据都会比c0的老。\n因此，如果你想找一个老数据的话，那么c0树中很可能找不到，需要到c1树中去找。并不需要新建c0。\n还有，c0是否要新建，只和c0是否写满了有关，和我们是否在查找老数据没关系。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1588697125,"ip_address":"","comment_id":214254,"utype":1}],"discussion_count":3,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"想请问一下。C0 和 C1 里面有包含所有的数据吗？如果搜寻一个比较老旧的数据。会需要建立一个新的C0吗？","like_count":1,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":494001,"discussion_content":"因为所有的数据要么在c0中，要么在c1中，因此，c0和c1包含了所有的数据。\n由于c0写满以后，才会合并到c1中去。因此，c0中的数据一定是新数据，而c1的数据都会比c0的老。\n因此，如果你想找一个老数据的话，那么c0树中很可能找不到，需要到c1树中去找。并不需要新建c0。\n还有，c0是否要新建，只和c0是否写满了有关，和我们是否在查找老数据没关系。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588697125,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1258324,"avatar":"https://static001.geekbang.org/account/avatar/00/13/33/54/595be268.jpg","nickname":"fengyi","note":"","ucode":"C6FA77BE015F5A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":259221,"discussion_content":"了解了。所以搜索旧的数据就需要从c1里拿。c0只是用来加速新数据的搜索和写入。\n另外有点困惑的是，如果c1过于庞大。在归并的过程中不会有内存放不下的情况吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588769438,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1809802,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/8a/a2d34896.jpg","nickname":"一元(eudict)","note":"","ucode":"5E7A33642FC767","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1258324,"avatar":"https://static001.geekbang.org/account/avatar/00/13/33/54/595be268.jpg","nickname":"fengyi","note":"","ucode":"C6FA77BE015F5A","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":260013,"discussion_content":"并不会哦，因为在归并数据时，并不是将所有C1数据直接加载到内存中，而是将一个包含多个叶子节点的块（多页块）加载到内存中进行归并，归并结果在内存中形成新的填充块，如果填充块写满，就将其顺序写入磁盘中新的连续的地址。然后重复上述步骤，直到遍历完C0树和C1树的所有叶子结点完成归并。这些内容文章中都有详细讲解，看来同学没有认真听课哦！😄","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1588838679,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":259221,"ip_address":"","group_id":0},"score":260013,"extra":""}]}]},{"had_liked":false,"id":211211,"user_name":"aoe","can_delete":false,"product_type":"c1","uid":1121758,"ip_address":"","ucode":"1C6201EDB4E954","user_header":"https://static001.geekbang.org/account/avatar/00/11/1d/de/62bfa83f.jpg","comment_is_top":false,"comment_ctime":1587915472,"is_pvip":false,"replies":[{"id":78556,"content":"欢迎多在讨论区提问和交流，相信对自己和对别人都是有帮助的~","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1587950989,"ip_address":"","comment_id":211211,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"评论很精彩，又学到了很多","like_count":1,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":494001,"discussion_content":"因为所有的数据要么在c0中，要么在c1中，因此，c0和c1包含了所有的数据。\n由于c0写满以后，才会合并到c1中去。因此，c0中的数据一定是新数据，而c1的数据都会比c0的老。\n因此，如果你想找一个老数据的话，那么c0树中很可能找不到，需要到c1树中去找。并不需要新建c0。\n还有，c0是否要新建，只和c0是否写满了有关，和我们是否在查找老数据没关系。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588697125,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1258324,"avatar":"https://static001.geekbang.org/account/avatar/00/13/33/54/595be268.jpg","nickname":"fengyi","note":"","ucode":"C6FA77BE015F5A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":259221,"discussion_content":"了解了。所以搜索旧的数据就需要从c1里拿。c0只是用来加速新数据的搜索和写入。\n另外有点困惑的是，如果c1过于庞大。在归并的过程中不会有内存放不下的情况吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588769438,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1809802,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/8a/a2d34896.jpg","nickname":"一元(eudict)","note":"","ucode":"5E7A33642FC767","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1258324,"avatar":"https://static001.geekbang.org/account/avatar/00/13/33/54/595be268.jpg","nickname":"fengyi","note":"","ucode":"C6FA77BE015F5A","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":260013,"discussion_content":"并不会哦，因为在归并数据时，并不是将所有C1数据直接加载到内存中，而是将一个包含多个叶子节点的块（多页块）加载到内存中进行归并，归并结果在内存中形成新的填充块，如果填充块写满，就将其顺序写入磁盘中新的连续的地址。然后重复上述步骤，直到遍历完C0树和C1树的所有叶子结点完成归并。这些内容文章中都有详细讲解，看来同学没有认真听课哦！😄","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1588838679,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":259221,"ip_address":"","group_id":0},"score":260013,"extra":""}]}]},{"had_liked":false,"id":206492,"user_name":"yang","can_delete":false,"product_type":"c1","uid":1074310,"ip_address":"","ucode":"1AA1497C5A293C","user_header":"https://static001.geekbang.org/account/avatar/00/10/64/86/f5a9403a.jpg","comment_is_top":false,"comment_ctime":1586869605,"is_pvip":false,"replies":[{"id":77151,"content":"这个不就是我在04课和测试题里出现的例子么？赶紧翻一下04课看一看就知道啦","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1586871420,"ip_address":"","comment_id":206492,"utype":1}],"discussion_count":2,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"老师我问个面试题啊：\n\n现在爬了100亿条URL ，每条url 64字节，我该怎么存在？\n\n然后问如何快速检索某条url在不在其中？\n\n每条64B，100亿条就是640G，这个好大。\n想了一下编号，实在太大了，100亿条。\n可以打标签吗？\n或者针对域名的开始的字母按顺序建立B+树的索引？ \n完整数据按块存储在叶子结点上？ 这样可以加快查询吧","like_count":1,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493220,"discussion_content":"欢迎多在讨论区提问和交流，相信对自己和对别人都是有帮助的~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587950989,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":205155,"user_name":"那时刻","can_delete":false,"product_type":"c1","uid":1150927,"ip_address":"","ucode":"B0D150856C3A4A","user_header":"https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg","comment_is_top":false,"comment_ctime":1586559259,"is_pvip":false,"replies":[{"id":76686,"content":"1.check point的信息是独立存在的，和wal的日志文件是不同文件。\n2.check point的触发条件可以有多个，比如说间隔时长达到了预定时间，比如说wal文件增长到一定程度，甚至还可以主动调用check point相关命令强制执行。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1586573423,"ip_address":"","comment_id":205155,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"请问两个关于检查点check point的问题。\n1.检查点也是要落盘，和WAL一样的位置么？\n2.在数据删除和同步到硬盘之后会生成检查点，还有其它情况会生成检查点么？","like_count":1,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491812,"discussion_content":"这个不就是我在04课和测试题里出现的例子么？赶紧翻一下04课看一看就知道啦","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586871420,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1121758,"avatar":"https://static001.geekbang.org/account/avatar/00/11/1d/de/62bfa83f.jpg","nickname":"aoe","note":"","ucode":"1C6201EDB4E954","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":249309,"discussion_content":"布隆过滤器\n数据分片存","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1587915210,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":204788,"user_name":"每天晒白牙","can_delete":false,"product_type":"c1","uid":1004698,"ip_address":"","ucode":"A1B102CD933DEA","user_header":"https://static001.geekbang.org/account/avatar/00/0f/54/9a/76c0af70.jpg","comment_is_top":false,"comment_ctime":1586473481,"is_pvip":false,"replies":[{"id":76536,"content":"是的。如果你有关注一些内存数据库，你会发现，有好些是使用跳表和红黑树来实现的。比如Redis。\n可见，b+树不是万能的。我们理解了存储介质的特性以后，能帮助我们在合适的场景做出正确的技术选型。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1586483733,"ip_address":"","comment_id":204788,"utype":1}],"discussion_count":2,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"思考题\n对于c0树因为是存放在内存中的，可以用平衡二叉树或跳表来代替 B+ 树","like_count":1,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491291,"discussion_content":"是的。如果你有关注一些内存数据库，你会发现，有好些是使用跳表和红黑树来实现的。比如Redis。\n可见，b+树不是万能的。我们理解了存储介质的特性以后，能帮助我们在合适的场景做出正确的技术选型。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586483733,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1197455,"avatar":"https://static001.geekbang.org/account/avatar/00/12/45/8f/a56b2214.jpg","nickname":"innocent","note":"","ucode":"368659A0DDE7E4","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":352010,"discussion_content":"HBase和Lucene也是使用的跳表","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1614567803,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":315572,"user_name":"armatrix","can_delete":false,"product_type":"c1","uid":2803119,"ip_address":"","ucode":"CCBF1181DDCD23","user_header":"https://static001.geekbang.org/account/avatar/00/2a/c5/af/174261ab.jpg","comment_is_top":false,"comment_ctime":1633921974,"is_pvip":false,"replies":[{"id":116693,"content":"是的，删除采用flag标志在许多场景都有使用。这是一个很常见的技巧","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1636813497,"ip_address":"","comment_id":315572,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"c0树和c1树flag的使用，同样也可以应用在一些业务上状态在cache和持久化存储之间吧？","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491291,"discussion_content":"是的。如果你有关注一些内存数据库，你会发现，有好些是使用跳表和红黑树来实现的。比如Redis。\n可见，b+树不是万能的。我们理解了存储介质的特性以后，能帮助我们在合适的场景做出正确的技术选型。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586483733,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1197455,"avatar":"https://static001.geekbang.org/account/avatar/00/12/45/8f/a56b2214.jpg","nickname":"innocent","note":"","ucode":"368659A0DDE7E4","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":352010,"discussion_content":"HBase和Lucene也是使用的跳表","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1614567803,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":292746,"user_name":"森林木","can_delete":false,"product_type":"c1","uid":1220089,"ip_address":"","ucode":"79A06FCC43673B","user_header":"https://static001.geekbang.org/account/avatar/00/12/9d/f9/b98d9c40.jpg","comment_is_top":false,"comment_ctime":1620959838,"is_pvip":false,"replies":[{"id":107520,"content":"在这一篇中，主要还还是介绍了lsm树的原理，真正的工业实现的确需要考虑很多细节问题。在后面你会看到，真实的工业界的lsm树是用不一样的方式实现的。\n不过一个高效设计的原则，就是磁盘上的节点是只读的，这样就不会有读写的问题;而内存中的节点可能会同时有读写，那么可以加锁。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1622900778,"ip_address":"","comment_id":292746,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"老师，问一下如果在归并的过程中又有写入该怎么处理?","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":528094,"discussion_content":"是的，删除采用flag标志在许多场景都有使用。这是一个很常见的技巧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1636813497,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":286478,"user_name":"entropy","can_delete":false,"product_type":"c1","uid":2464905,"ip_address":"","ucode":"0CDF7EC5A3AF75","user_header":"","comment_is_top":false,"comment_ctime":1617334857,"is_pvip":false,"replies":[{"id":104104,"content":"在这一篇原理介绍中，假设只有两棵树，c0树和c1树。c0树在内存中，受限于内存大小，因此较小;c1树在磁盘中，是c0树不停归并而成，因此会较大。\n当然，在工业界的实际系统实现中，磁盘中不是只有一颗c1树，而是多个文件块，具体的实现方式的确如你所说的，直接把内存刷入磁盘中。当然，磁盘中有多棵树以后，后续处理会变复杂，具体可以看我后面的leveldb的介绍。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1617447180,"ip_address":"","comment_id":286478,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100048401,"comment_content":"为什么C0小而C1大呢，如果C0和C1一样大，每次内存到达阈值（这时候应该是多个块大小吧），直接刷到硬盘呢？","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":519944,"discussion_content":"在这一篇中，主要还还是介绍了lsm树的原理，真正的工业实现的确需要考虑很多细节问题。在后面你会看到，真实的工业界的lsm树是用不一样的方式实现的。\n不过一个高效设计的原则，就是磁盘上的节点是只读的，这样就不会有读写的问题;而内存中的节点可能会同时有读写，那么可以加锁。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1622900778,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":278487,"user_name":"愤怒的虾干","can_delete":false,"product_type":"c1","uid":1266043,"ip_address":"","ucode":"CEBD1B2BE7BCEE","user_header":"https://static001.geekbang.org/account/avatar/00/13/51/7b/191a2112.jpg","comment_is_top":false,"comment_ctime":1612969710,"is_pvip":false,"replies":[{"id":102777,"content":"你的问题很好。这涉及到nosql的完整的工业实现。的确可以对合并后的c1树重建索引。不过在工业界中，要解决的问题更多，所以在后面我们还会介绍leveldb的实现方案供参考。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1615713760,"ip_address":"","comment_id":278487,"utype":1}],"discussion_count":1,"race_medal":0,"score":4,"product_id":100048401,"comment_content":"您好，当与内存中的最新数据合并完成后写入磁盘，此时写入的也只是b+树的数据节点（叶子节点），其索引节点创建过程是什么样的？（我的理解是这样合并的b+树类似满二叉树，可以自底向上快速建立索引，不知道对不对？）","like_count":0},{"had_liked":false,"id":268763,"user_name":"Bachue Zhou","can_delete":false,"product_type":"c1","uid":1494491,"ip_address":"","ucode":"3175754775CA32","user_header":"https://static001.geekbang.org/account/avatar/00/16/cd/db/7467ad23.jpg","comment_is_top":false,"comment_ctime":1608343262,"is_pvip":false,"replies":[{"id":98007,"content":"是的。所以lsm树更适合近期内的数据查找。比如说用在时序数据库的场景就很适合。\n但是如果是范围查询，lsm树就不是最合适的数据结构了。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1609077018,"ip_address":"","comment_id":268763,"utype":1}],"discussion_count":1,"race_medal":0,"score":4,"product_id":100048401,"comment_content":"感觉 LSM Tree 还存在一个问题，对于范围查询的场景，c0 无论查到多少数据，都依然需要再查一次 c1，然后合并结果，这样 c0 相当于无法起到优化的效果。","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":512026,"discussion_content":"是的。所以lsm树更适合近期内的数据查找。比如说用在时序数据库的场景就很适合。\n但是如果是范围查询，lsm树就不是最合适的数据结构了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1609077018,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":268762,"user_name":"Bachue Zhou","can_delete":false,"product_type":"c1","uid":1494491,"ip_address":"","ucode":"3175754775CA32","user_header":"https://static001.geekbang.org/account/avatar/00/16/cd/db/7467ad23.jpg","comment_is_top":false,"comment_ctime":1608342891,"is_pvip":false,"replies":[{"id":98005,"content":"这一篇更多是介绍lsm树的理论，真实的工业界的lsm树会采用和b+树不一样的数据结构来实现。我在后面会以leveldb为例子进行解析。\n至于你的写日志的效率问题，其实wal技术也是批量写日志的，等到内存中的数据满了一个块(或到了一定时间)就会写磁盘。而且由于是追加写，不是随机写，也会避免一些额外的寻址时间开销。\n","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1609076929,"ip_address":"","comment_id":268762,"utype":1}],"discussion_count":2,"race_medal":0,"score":4,"product_id":100048401,"comment_content":"这是我见过对 LSM Tree 最清晰的教程了，以前就一直没搞懂为何放着这么好的 B+ Tree 不用要用一个分层的数据结构，现在才知道他只是 B+ Tree 的加强版本，更好的利用内存充当磁盘缓冲区的做法而已，它也并没有必要是 NoSQL only 的，一样可以给传统 SQL 数据库服务。但我依然有一件事不明白，请老师指点，“数据采取类似日志追加写的方式写入磁盘，以顺序写的方式提高写入效率。”一般来说，一条日志尺寸并不会太大，至少不可能一个盘块这么大，而且一旦用户发起操作，数据库必须等待日志写入磁盘才能告知用户操作成功，日志永远不可能延迟写入，因此，如果每次操作都必须高频率地向磁盘的同一个盘块追加日志，由于磁盘写入必须是以块为单位，存在写放大，即使是SSD都不能幸免，那么写日志和写整个盘块没有区别，因此这个盘块就相当于被高频的反复重写，这样的操作为什么会被认为高效呢？","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":512026,"discussion_content":"是的。所以lsm树更适合近期内的数据查找。比如说用在时序数据库的场景就很适合。\n但是如果是范围查询，lsm树就不是最合适的数据结构了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1609077018,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":264660,"user_name":"小山猫","can_delete":false,"product_type":"c1","uid":1369437,"ip_address":"","ucode":"D9A5D96113063B","user_header":"https://static001.geekbang.org/account/avatar/00/14/e5/5d/b6378027.jpg","comment_is_top":false,"comment_ctime":1606566140,"is_pvip":false,"replies":[{"id":95960,"content":"levelDB和HBASE都是基于lsm的开源实现，可以参考","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1606620570,"ip_address":"","comment_id":264660,"utype":1}],"discussion_count":2,"race_medal":0,"score":4,"product_id":100048401,"comment_content":"请问老师，有没有好的开源实现呢？ 现在有一些业务数据就是树形的，存储检索都是通过mysql做的。一直考虑找一种更好的方案。","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":510642,"discussion_content":"levelDB和HBASE都是基于lsm的开源实现，可以参考","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606620570,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1130929,"avatar":"https://static001.geekbang.org/account/avatar/00/11/41/b1/565d0f56.jpg","nickname":".cc","note":"","ucode":"D99025BD7626C6","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":351847,"discussion_content":"es也是基于LSM实现","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1614493913,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":247289,"user_name":"青鸟飞鱼","can_delete":false,"product_type":"c1","uid":1807943,"ip_address":"","ucode":"8C64517DA556FE","user_header":"https://static001.geekbang.org/account/avatar/00/1b/96/47/93838ff7.jpg","comment_is_top":false,"comment_ctime":1599649609,"is_pvip":false,"replies":[{"id":90873,"content":"“这样一来，当我们在 C0 树中查询时，如果查到了一个带着删除标志的 key，就直接返回查询失败，我们也就不用去查询 C1 树了。在滚动归并的时候，我们会查看数据在 C0 树中是否带有删除标志。如果有，滚动归并时就将它放弃。这样 C1 树就能批量完成“数据删除”的动作。”\n你是针对这一段提问的么？我可以换个角度再解释一下lsm树的删除原理。\n如果一个数据是存在于c1树中，如果我们想要删除它，为了保证系统性能，我们不应该每接到一个删除请求就去磁盘上的c1树中做操作。合理的解决方案是“将要删除的数据记录在c0树中，然后在合并的时候批量更新c1树”。这样就能保持lsm树的批量写的高性能设计了。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1599702164,"ip_address":"","comment_id":247289,"utype":1}],"discussion_count":1,"race_medal":0,"score":4,"product_id":100048401,"comment_content":"老师，你好，有个疑问，为什么从c0查不到数据，从c1查到的数据，要删除标记呢？是因为c1已经存在了，合并时不需要再合并了，是这么理解吗？","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":505367,"discussion_content":"“这样一来，当我们在 C0 树中查询时，如果查到了一个带着删除标志的 key，就直接返回查询失败，我们也就不用去查询 C1 树了。在滚动归并的时候，我们会查看数据在 C0 树中是否带有删除标志。如果有，滚动归并时就将它放弃。这样 C1 树就能批量完成“数据删除”的动作。”\n你是针对这一段提问的么？我可以换个角度再解释一下lsm树的删除原理。\n如果一个数据是存在于c1树中，如果我们想要删除它，为了保证系统性能，我们不应该每接到一个删除请求就去磁盘上的c1树中做操作。合理的解决方案是“将要删除的数据记录在c0树中，然后在合并的时候批量更新c1树”。这样就能保持lsm树的批量写的高性能设计了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1599702164,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":227471,"user_name":"青鸟飞鱼","can_delete":false,"product_type":"c1","uid":1807943,"ip_address":"","ucode":"8C64517DA556FE","user_header":"https://static001.geekbang.org/account/avatar/00/1b/96/47/93838ff7.jpg","comment_is_top":false,"comment_ctime":1592387774,"is_pvip":false,"replies":[{"id":83827,"content":"可以说说对了一半吧。\n“合并后，c0树就没有数据”这一句是对的，c0树会被清空，用来准备存储接下来要到来的新数据。\n但是“最新的数据就查不到”这一句不太正确，因为c0树和c1树合并后，原来的“最新的数据”就会被合并到c1树中，尽管在c0树中查不到，但是lsm树接下来会去c1树中查找，这时候就可以查到了。因此不能说“最新的数据就查不到”。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1592396083,"ip_address":"","comment_id":227471,"utype":1}],"discussion_count":1,"race_medal":0,"score":4,"product_id":100048401,"comment_content":"老师，你好，每次刷都有新的收获和问题。在c0和c1合并后，c0树就没有数据，最新的数据就查不到，是这么理解的吗？","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":505367,"discussion_content":"“这样一来，当我们在 C0 树中查询时，如果查到了一个带着删除标志的 key，就直接返回查询失败，我们也就不用去查询 C1 树了。在滚动归并的时候，我们会查看数据在 C0 树中是否带有删除标志。如果有，滚动归并时就将它放弃。这样 C1 树就能批量完成“数据删除”的动作。”\n你是针对这一段提问的么？我可以换个角度再解释一下lsm树的删除原理。\n如果一个数据是存在于c1树中，如果我们想要删除它，为了保证系统性能，我们不应该每接到一个删除请求就去磁盘上的c1树中做操作。合理的解决方案是“将要删除的数据记录在c0树中，然后在合并的时候批量更新c1树”。这样就能保持lsm树的批量写的高性能设计了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1599702164,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":225512,"user_name":"青鸟飞鱼","can_delete":false,"product_type":"c1","uid":1807943,"ip_address":"","ucode":"8C64517DA556FE","user_header":"https://static001.geekbang.org/account/avatar/00/1b/96/47/93838ff7.jpg","comment_is_top":false,"comment_ctime":1591773763,"is_pvip":false,"replies":[{"id":83186,"content":"你说的是什么树呢？是b树么？b树的叶子节点之间没有链表连接，但是每个节点内数据还是有序的。MongoDB就是使用b树实现的。(这个问题我应该回答过你)\n其实不管是什么树，我们都要了解它的特点，判断是否符合我们的应用场景，只要适合就可以应用。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1591871088,"ip_address":"","comment_id":225512,"utype":1}],"discussion_count":1,"race_medal":0,"score":4,"product_id":100048401,"comment_content":"老师你好，之前看到一种树，类似于B+树，所有的数据不是有序的，但是每页的数据的有序的，这样子可以提高写的效率，降低读效率，不知道这种树应用于NoSQL吗？","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":498653,"discussion_content":"可以说说对了一半吧。\n“合并后，c0树就没有数据”这一句是对的，c0树会被清空，用来准备存储接下来要到来的新数据。\n但是“最新的数据就查不到”这一句不太正确，因为c0树和c1树合并后，原来的“最新的数据”就会被合并到c1树中，尽管在c0树中查不到，但是lsm树接下来会去c1树中查找，这时候就可以查到了。因此不能说“最新的数据就查不到”。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1592396083,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":212198,"user_name":"xaviers","can_delete":false,"product_type":"c1","uid":1879918,"ip_address":"","ucode":"58D51C4DDC5BA8","user_header":"https://static001.geekbang.org/account/avatar/00/1c/af/6e/30fb83f1.jpg","comment_is_top":false,"comment_ctime":1588073618,"is_pvip":false,"replies":[{"id":78874,"content":"第17讲就是，马上就到了。敬请期待哦。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1588078820,"ip_address":"","comment_id":212198,"utype":1}],"discussion_count":1,"race_medal":0,"score":4,"product_id":100048401,"comment_content":"东哥晚上好，请问下“工业界具体怎么实现一个高性能的lsm树”这一节在哪啊，没找到。是还没出吗？","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":497875,"discussion_content":"你说的是什么树呢？是b树么？b树的叶子节点之间没有链表连接，但是每个节点内数据还是有序的。MongoDB就是使用b树实现的。(这个问题我应该回答过你)\n其实不管是什么树，我们都要了解它的特点，判断是否符合我们的应用场景，只要适合就可以应用。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1591871088,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":204823,"user_name":"Mq","can_delete":false,"product_type":"c1","uid":1178359,"ip_address":"","ucode":"041F572AFAB275","user_header":"https://static001.geekbang.org/account/avatar/00/11/fa/f7/91ac44c5.jpg","comment_is_top":false,"comment_ctime":1586479716,"is_pvip":false,"replies":[{"id":76532,"content":"在内存数据库里面，Redis是一个典型的代表，它的确就是使用跳表的。\n另外两点:\n1.b+树块内的查找，可以使用二分查找，而不是顺序查找，这样能加快检索效率。\n2.你说的是否“c0和c1树写错”的地方，这个的确没有写错哦，你可以仔细想一想，为什么c1树有这个特点“叶子节点是全满的”。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1586481917,"ip_address":"","comment_id":204823,"utype":1}],"discussion_count":3,"race_medal":0,"score":4,"product_id":100048401,"comment_content":"B+树数据存储是以块为单位的，读到内存也是以块为单位，一个块里面如果数据多了顺序查找也不是太快。\n内存存储我觉得应该选择跳表，他的查找、插入、删除都跟树一样，只是空间上会多一些消耗，他对范围查找的支持是其他内存数据结构一大优势。\n另外，我感觉文章中有把c0写成c1的地方，不知道我理解对不‘和普通的 B+ 树相比，C1 树有一个特点’\n","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491299,"discussion_content":"在内存数据库里面，Redis是一个典型的代表，它的确就是使用跳表的。\n另外两点:\n1.b+树块内的查找，可以使用二分查找，而不是顺序查找，这样能加快检索效率。\n2.你说的是否“c0和c1树写错”的地方，这个的确没有写错哦，你可以仔细想一想，为什么c1树有这个特点“叶子节点是全满的”。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586481917,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1200704,"avatar":"https://static001.geekbang.org/account/avatar/00/12/52/40/e57a736e.jpg","nickname":"pedro","note":"","ucode":"F40C839DDFD599","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":227350,"discussion_content":"前面的文章也提到了，B 树是为了解决以页读磁盘的问题，那么 B 树自然就不适合在内存中做存储，在内存中适合做存储的有红黑球和跳表，当然也有例外，像小而美的 Bitcask 直接使用了哈希表作为内存索引，写磁盘也不使用树，直接日志追加，是学习 Log-Structured 类数据库的最佳入门选择。","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1586485140,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1010914,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEIgYQgM25OaLGNWPUg5NSrQuCrPNicHqNgB9lsJGMalNU18sibF4cdYxKPuwgVsIc1m5ha5voHrY9Lg/132","nickname":"jacoffee","note":"","ucode":"B3BFD39138400B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":554543,"discussion_content":"&#34;针对B+树一个块里面如果数据多了顺序查找也不是太快&#34;，实际中肯定还有进一步优化。比如说MySQL就借助页目录(page directory)，简单来说就是页记录分组 + 稀疏索引的方式来优化，避免查找时的O(n)遍历，从而转化为基于二分法的查找。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1646457225,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":204972,"user_name":"奕","can_delete":false,"product_type":"c1","uid":1005391,"ip_address":"","ucode":"73CEA468CE70C3","user_header":"https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg","comment_is_top":false,"comment_ctime":1586502790,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100048401,"comment_content":"对于 对数据敏感的数据库，基本上都会采用 WAL 技术，来防止数据在内存中丢失， 比如 MySQL 的 redo log ","like_count":2,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491299,"discussion_content":"在内存数据库里面，Redis是一个典型的代表，它的确就是使用跳表的。\n另外两点:\n1.b+树块内的查找，可以使用二分查找，而不是顺序查找，这样能加快检索效率。\n2.你说的是否“c0和c1树写错”的地方，这个的确没有写错哦，你可以仔细想一想，为什么c1树有这个特点“叶子节点是全满的”。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586481917,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1200704,"avatar":"https://static001.geekbang.org/account/avatar/00/12/52/40/e57a736e.jpg","nickname":"pedro","note":"","ucode":"F40C839DDFD599","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":227350,"discussion_content":"前面的文章也提到了，B 树是为了解决以页读磁盘的问题，那么 B 树自然就不适合在内存中做存储，在内存中适合做存储的有红黑球和跳表，当然也有例外，像小而美的 Bitcask 直接使用了哈希表作为内存索引，写磁盘也不使用树，直接日志追加，是学习 Log-Structured 类数据库的最佳入门选择。","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1586485140,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1010914,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEIgYQgM25OaLGNWPUg5NSrQuCrPNicHqNgB9lsJGMalNU18sibF4cdYxKPuwgVsIc1m5ha5voHrY9Lg/132","nickname":"jacoffee","note":"","ucode":"B3BFD39138400B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":554543,"discussion_content":"&#34;针对B+树一个块里面如果数据多了顺序查找也不是太快&#34;，实际中肯定还有进一步优化。比如说MySQL就借助页目录(page directory)，简单来说就是页记录分组 + 稀疏索引的方式来优化，避免查找时的O(n)遍历，从而转化为基于二分法的查找。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1646457225,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":278487,"user_name":"愤怒的虾干","can_delete":false,"product_type":"c1","uid":1266043,"ip_address":"","ucode":"CEBD1B2BE7BCEE","user_header":"https://static001.geekbang.org/account/avatar/00/13/51/7b/191a2112.jpg","comment_is_top":false,"comment_ctime":1612969710,"is_pvip":false,"replies":[{"id":102777,"content":"你的问题很好。这涉及到nosql的完整的工业实现。的确可以对合并后的c1树重建索引。不过在工业界中，要解决的问题更多，所以在后面我们还会介绍leveldb的实现方案供参考。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1615713760,"ip_address":"","comment_id":278487,"utype":1}],"discussion_count":1,"race_medal":0,"score":4,"product_id":100048401,"comment_content":"您好，当与内存中的最新数据合并完成后写入磁盘，此时写入的也只是b+树的数据节点（叶子节点），其索引节点创建过程是什么样的？（我的理解是这样合并的b+树类似满二叉树，可以自底向上快速建立索引，不知道对不对？）","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":515400,"discussion_content":"你的问题很好。这涉及到nosql的完整的工业实现。的确可以对合并后的c1树重建索引。不过在工业界中，要解决的问题更多，所以在后面我们还会介绍leveldb的实现方案供参考。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1615713760,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":268763,"user_name":"Bachue Zhou","can_delete":false,"product_type":"c1","uid":1494491,"ip_address":"","ucode":"3175754775CA32","user_header":"https://static001.geekbang.org/account/avatar/00/16/cd/db/7467ad23.jpg","comment_is_top":false,"comment_ctime":1608343262,"is_pvip":false,"replies":[{"id":98007,"content":"是的。所以lsm树更适合近期内的数据查找。比如说用在时序数据库的场景就很适合。\n但是如果是范围查询，lsm树就不是最合适的数据结构了。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1609077018,"ip_address":"","comment_id":268763,"utype":1}],"discussion_count":1,"race_medal":0,"score":4,"product_id":100048401,"comment_content":"感觉 LSM Tree 还存在一个问题，对于范围查询的场景，c0 无论查到多少数据，都依然需要再查一次 c1，然后合并结果，这样 c0 相当于无法起到优化的效果。","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":515400,"discussion_content":"你的问题很好。这涉及到nosql的完整的工业实现。的确可以对合并后的c1树重建索引。不过在工业界中，要解决的问题更多，所以在后面我们还会介绍leveldb的实现方案供参考。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1615713760,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":268762,"user_name":"Bachue Zhou","can_delete":false,"product_type":"c1","uid":1494491,"ip_address":"","ucode":"3175754775CA32","user_header":"https://static001.geekbang.org/account/avatar/00/16/cd/db/7467ad23.jpg","comment_is_top":false,"comment_ctime":1608342891,"is_pvip":false,"replies":[{"id":98005,"content":"这一篇更多是介绍lsm树的理论，真实的工业界的lsm树会采用和b+树不一样的数据结构来实现。我在后面会以leveldb为例子进行解析。\n至于你的写日志的效率问题，其实wal技术也是批量写日志的，等到内存中的数据满了一个块(或到了一定时间)就会写磁盘。而且由于是追加写，不是随机写，也会避免一些额外的寻址时间开销。\n","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1609076929,"ip_address":"","comment_id":268762,"utype":1}],"discussion_count":2,"race_medal":0,"score":4,"product_id":100048401,"comment_content":"这是我见过对 LSM Tree 最清晰的教程了，以前就一直没搞懂为何放着这么好的 B+ Tree 不用要用一个分层的数据结构，现在才知道他只是 B+ Tree 的加强版本，更好的利用内存充当磁盘缓冲区的做法而已，它也并没有必要是 NoSQL only 的，一样可以给传统 SQL 数据库服务。但我依然有一件事不明白，请老师指点，“数据采取类似日志追加写的方式写入磁盘，以顺序写的方式提高写入效率。”一般来说，一条日志尺寸并不会太大，至少不可能一个盘块这么大，而且一旦用户发起操作，数据库必须等待日志写入磁盘才能告知用户操作成功，日志永远不可能延迟写入，因此，如果每次操作都必须高频率地向磁盘的同一个盘块追加日志，由于磁盘写入必须是以块为单位，存在写放大，即使是SSD都不能幸免，那么写日志和写整个盘块没有区别，因此这个盘块就相当于被高频的反复重写，这样的操作为什么会被认为高效呢？","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":512025,"discussion_content":"这一篇更多是介绍lsm树的理论，真实的工业界的lsm树会采用和b+树不一样的数据结构来实现。我在后面会以leveldb为例子进行解析。\n至于你的写日志的效率问题，其实wal技术也是批量写日志的，等到内存中的数据满了一个块(或到了一定时间)就会写磁盘。而且由于是追加写，不是随机写，也会避免一些额外的寻址时间开销。\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1609076929,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2343516,"avatar":"https://static001.geekbang.org/account/avatar/00/23/c2/5c/791d0f5e.jpg","nickname":"易企秀-郭彦超","note":"","ucode":"2E25574FAB1B3B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":344740,"discussion_content":"【其实wal技术也是批量写日志的，等到内存中的数据满了一个块(或到了一定时间)就会写磁盘】所以wal日志也不能100%不丢数据啊？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1611566218,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":264660,"user_name":"小山猫","can_delete":false,"product_type":"c1","uid":1369437,"ip_address":"","ucode":"D9A5D96113063B","user_header":"https://static001.geekbang.org/account/avatar/00/14/e5/5d/b6378027.jpg","comment_is_top":false,"comment_ctime":1606566140,"is_pvip":false,"replies":[{"id":95960,"content":"levelDB和HBASE都是基于lsm的开源实现，可以参考","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1606620570,"ip_address":"","comment_id":264660,"utype":1}],"discussion_count":2,"race_medal":0,"score":4,"product_id":100048401,"comment_content":"请问老师，有没有好的开源实现呢？ 现在有一些业务数据就是树形的，存储检索都是通过mysql做的。一直考虑找一种更好的方案。","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":512025,"discussion_content":"这一篇更多是介绍lsm树的理论，真实的工业界的lsm树会采用和b+树不一样的数据结构来实现。我在后面会以leveldb为例子进行解析。\n至于你的写日志的效率问题，其实wal技术也是批量写日志的，等到内存中的数据满了一个块(或到了一定时间)就会写磁盘。而且由于是追加写，不是随机写，也会避免一些额外的寻址时间开销。\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1609076929,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2343516,"avatar":"https://static001.geekbang.org/account/avatar/00/23/c2/5c/791d0f5e.jpg","nickname":"易企秀-郭彦超","note":"","ucode":"2E25574FAB1B3B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":344740,"discussion_content":"【其实wal技术也是批量写日志的，等到内存中的数据满了一个块(或到了一定时间)就会写磁盘】所以wal日志也不能100%不丢数据啊？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1611566218,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":247289,"user_name":"青鸟飞鱼","can_delete":false,"product_type":"c1","uid":1807943,"ip_address":"","ucode":"8C64517DA556FE","user_header":"https://static001.geekbang.org/account/avatar/00/1b/96/47/93838ff7.jpg","comment_is_top":false,"comment_ctime":1599649609,"is_pvip":false,"replies":[{"id":90873,"content":"“这样一来，当我们在 C0 树中查询时，如果查到了一个带着删除标志的 key，就直接返回查询失败，我们也就不用去查询 C1 树了。在滚动归并的时候，我们会查看数据在 C0 树中是否带有删除标志。如果有，滚动归并时就将它放弃。这样 C1 树就能批量完成“数据删除”的动作。”\n你是针对这一段提问的么？我可以换个角度再解释一下lsm树的删除原理。\n如果一个数据是存在于c1树中，如果我们想要删除它，为了保证系统性能，我们不应该每接到一个删除请求就去磁盘上的c1树中做操作。合理的解决方案是“将要删除的数据记录在c0树中，然后在合并的时候批量更新c1树”。这样就能保持lsm树的批量写的高性能设计了。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1599702164,"ip_address":"","comment_id":247289,"utype":1}],"discussion_count":1,"race_medal":0,"score":4,"product_id":100048401,"comment_content":"老师，你好，有个疑问，为什么从c0查不到数据，从c1查到的数据，要删除标记呢？是因为c1已经存在了，合并时不需要再合并了，是这么理解吗？","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":510642,"discussion_content":"levelDB和HBASE都是基于lsm的开源实现，可以参考","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606620570,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1130929,"avatar":"https://static001.geekbang.org/account/avatar/00/11/41/b1/565d0f56.jpg","nickname":".cc","note":"","ucode":"D99025BD7626C6","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":351847,"discussion_content":"es也是基于LSM实现","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1614493913,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":227471,"user_name":"青鸟飞鱼","can_delete":false,"product_type":"c1","uid":1807943,"ip_address":"","ucode":"8C64517DA556FE","user_header":"https://static001.geekbang.org/account/avatar/00/1b/96/47/93838ff7.jpg","comment_is_top":false,"comment_ctime":1592387774,"is_pvip":false,"replies":[{"id":83827,"content":"可以说说对了一半吧。\n“合并后，c0树就没有数据”这一句是对的，c0树会被清空，用来准备存储接下来要到来的新数据。\n但是“最新的数据就查不到”这一句不太正确，因为c0树和c1树合并后，原来的“最新的数据”就会被合并到c1树中，尽管在c0树中查不到，但是lsm树接下来会去c1树中查找，这时候就可以查到了。因此不能说“最新的数据就查不到”。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1592396083,"ip_address":"","comment_id":227471,"utype":1}],"discussion_count":1,"race_medal":0,"score":4,"product_id":100048401,"comment_content":"老师，你好，每次刷都有新的收获和问题。在c0和c1合并后，c0树就没有数据，最新的数据就查不到，是这么理解的吗？","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":498653,"discussion_content":"可以说说对了一半吧。\n“合并后，c0树就没有数据”这一句是对的，c0树会被清空，用来准备存储接下来要到来的新数据。\n但是“最新的数据就查不到”这一句不太正确，因为c0树和c1树合并后，原来的“最新的数据”就会被合并到c1树中，尽管在c0树中查不到，但是lsm树接下来会去c1树中查找，这时候就可以查到了。因此不能说“最新的数据就查不到”。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1592396083,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":225512,"user_name":"青鸟飞鱼","can_delete":false,"product_type":"c1","uid":1807943,"ip_address":"","ucode":"8C64517DA556FE","user_header":"https://static001.geekbang.org/account/avatar/00/1b/96/47/93838ff7.jpg","comment_is_top":false,"comment_ctime":1591773763,"is_pvip":false,"replies":[{"id":83186,"content":"你说的是什么树呢？是b树么？b树的叶子节点之间没有链表连接，但是每个节点内数据还是有序的。MongoDB就是使用b树实现的。(这个问题我应该回答过你)\n其实不管是什么树，我们都要了解它的特点，判断是否符合我们的应用场景，只要适合就可以应用。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1591871088,"ip_address":"","comment_id":225512,"utype":1}],"discussion_count":1,"race_medal":0,"score":4,"product_id":100048401,"comment_content":"老师你好，之前看到一种树，类似于B+树，所有的数据不是有序的，但是每页的数据的有序的，这样子可以提高写的效率，降低读效率，不知道这种树应用于NoSQL吗？","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":497875,"discussion_content":"你说的是什么树呢？是b树么？b树的叶子节点之间没有链表连接，但是每个节点内数据还是有序的。MongoDB就是使用b树实现的。(这个问题我应该回答过你)\n其实不管是什么树，我们都要了解它的特点，判断是否符合我们的应用场景，只要适合就可以应用。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1591871088,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":212198,"user_name":"xaviers","can_delete":false,"product_type":"c1","uid":1879918,"ip_address":"","ucode":"58D51C4DDC5BA8","user_header":"https://static001.geekbang.org/account/avatar/00/1c/af/6e/30fb83f1.jpg","comment_is_top":false,"comment_ctime":1588073618,"is_pvip":false,"replies":[{"id":78874,"content":"第17讲就是，马上就到了。敬请期待哦。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1588078820,"ip_address":"","comment_id":212198,"utype":1}],"discussion_count":1,"race_medal":0,"score":4,"product_id":100048401,"comment_content":"东哥晚上好，请问下“工业界具体怎么实现一个高性能的lsm树”这一节在哪啊，没找到。是还没出吗？","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493451,"discussion_content":"第17讲就是，马上就到了。敬请期待哦。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588078820,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":204823,"user_name":"Mq","can_delete":false,"product_type":"c1","uid":1178359,"ip_address":"","ucode":"041F572AFAB275","user_header":"https://static001.geekbang.org/account/avatar/00/11/fa/f7/91ac44c5.jpg","comment_is_top":false,"comment_ctime":1586479716,"is_pvip":false,"replies":[{"id":76532,"content":"在内存数据库里面，Redis是一个典型的代表，它的确就是使用跳表的。\n另外两点:\n1.b+树块内的查找，可以使用二分查找，而不是顺序查找，这样能加快检索效率。\n2.你说的是否“c0和c1树写错”的地方，这个的确没有写错哦，你可以仔细想一想，为什么c1树有这个特点“叶子节点是全满的”。","user_name":"作者回复","user_name_real":"陈东","uid":1165703,"ctime":1586481917,"ip_address":"","comment_id":204823,"utype":1}],"discussion_count":3,"race_medal":0,"score":4,"product_id":100048401,"comment_content":"B+树数据存储是以块为单位的，读到内存也是以块为单位，一个块里面如果数据多了顺序查找也不是太快。\n内存存储我觉得应该选择跳表，他的查找、插入、删除都跟树一样，只是空间上会多一些消耗，他对范围查找的支持是其他内存数据结构一大优势。\n另外，我感觉文章中有把c0写成c1的地方，不知道我理解对不‘和普通的 B+ 树相比，C1 树有一个特点’\n","like_count":0,"discussions":[{"author":{"id":1165703,"avatar":"https://static001.geekbang.org/account/avatar/00/11/c9/87/7a96366d.jpg","nickname":"陈东","note":"","ucode":"97CF7C67D83851","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493451,"discussion_content":"第17讲就是，马上就到了。敬请期待哦。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588078820,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":204972,"user_name":"奕","can_delete":false,"product_type":"c1","uid":1005391,"ip_address":"","ucode":"73CEA468CE70C3","user_header":"https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg","comment_is_top":false,"comment_ctime":1586502790,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100048401,"comment_content":"对于 对数据敏感的数据库，基本上都会采用 WAL 技术，来防止数据在内存中丢失， 比如 MySQL 的 redo log ","like_count":2},{"had_liked":false,"id":372397,"user_name":"ifelse","can_delete":false,"product_type":"c1","uid":2550743,"ip_address":"浙江","ucode":"D0565908C99695","user_header":"https://static001.geekbang.org/account/avatar/00/26/eb/d7/90391376.jpg","comment_is_top":false,"comment_ctime":1681098764,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":3,"score":5,"product_id":100048401,"comment_content":"学习了\nWAL，树归并，延时操作，批量处理综合应用","like_count":1},{"had_liked":false,"id":391547,"user_name":"Geek_7b1aa5","can_delete":false,"product_type":"c1","uid":3865678,"ip_address":"北京","ucode":"0A301F16479A6E","user_header":"","comment_is_top":false,"comment_ctime":1718508497,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100048401,"comment_content":"LSM磁盘树可以很多层，每层可有多个SSTable，多个SSTable不像单个B+树那样可以直接按照key查找值，而是一个key可以存在不同层的不同SSTable中（一层多个SSTable只能有一个相同key），这样查时间比较久的数据的时候如何保证找到最新的key以及值？一个key可以存在不同level中，但是上一层的level的key新鲜度总是高于下层的，同一层中多个SSTable只有一个key。","like_count":0},{"had_liked":false,"id":350994,"user_name":"刘德聪","can_delete":false,"product_type":"c1","uid":1316662,"ip_address":"","ucode":"2968605D077072","user_header":"https://static001.geekbang.org/account/avatar/00/14/17/36/3d8e86e6.jpg","comment_is_top":false,"comment_ctime":1657442852,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100048401,"comment_content":"老师， 如果C0和C1合并后的某个data节点数据超过一个data阈值， 那接下来会发生什么？  \n我想到两种可能。\n1. 磁盘上B+树有多颗，每一颗的data节点容拿大小也不同， C1树最小节点data剩余容量会大于内存C0树的节点最大容量， 所以合并的时候， 不会出现data节点装不下问题。\n2. C0和C1同一个data节点合并之后超过阈值， 会重新调整数据， 把当前节点data合并之后多余的数据写入到下一个节点，当写一个节点满了，剩余数据写入到下下个节点，如果没有节点不存在，新建一个。  ","like_count":0},{"had_liked":false,"id":349954,"user_name":"阿甘","can_delete":false,"product_type":"c1","uid":1057843,"ip_address":"","ucode":"BC93175B70E05D","user_header":"https://static001.geekbang.org/account/avatar/00/10/24/33/bcf37f50.jpg","comment_is_top":false,"comment_ctime":1656470515,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100048401,"comment_content":"老师，请问Lucene的每个segment是不是就是一棵LSM树啊，不可修改，标记删除，不断合并。","like_count":0},{"had_liked":false,"id":332843,"user_name":"果果","can_delete":false,"product_type":"c1","uid":2027828,"ip_address":"","ucode":"458AC5EC0A8790","user_header":"https://static001.geekbang.org/account/avatar/00/1e/f1/34/6978db6a.jpg","comment_is_top":false,"comment_ctime":1643723288,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100048401,"comment_content":"如果内存中的数据都被处理完了，刚好在写check point的时候宕机了怎么办","like_count":0},{"had_liked":false,"id":372397,"user_name":"ifelse","can_delete":false,"product_type":"c1","uid":2550743,"ip_address":"浙江","ucode":"D0565908C99695","user_header":"https://static001.geekbang.org/account/avatar/00/26/eb/d7/90391376.jpg","comment_is_top":false,"comment_ctime":1681098764,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":3,"score":5,"product_id":100048401,"comment_content":"学习了\nWAL，树归并，延时操作，批量处理综合应用","like_count":1},{"had_liked":false,"id":391547,"user_name":"Geek_7b1aa5","can_delete":false,"product_type":"c1","uid":3865678,"ip_address":"北京","ucode":"0A301F16479A6E","user_header":"","comment_is_top":false,"comment_ctime":1718508497,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100048401,"comment_content":"LSM磁盘树可以很多层，每层可有多个SSTable，多个SSTable不像单个B+树那样可以直接按照key查找值，而是一个key可以存在不同层的不同SSTable中（一层多个SSTable只能有一个相同key），这样查时间比较久的数据的时候如何保证找到最新的key以及值？一个key可以存在不同level中，但是上一层的level的key新鲜度总是高于下层的，同一层中多个SSTable只有一个key。","like_count":0},{"had_liked":false,"id":350994,"user_name":"刘德聪","can_delete":false,"product_type":"c1","uid":1316662,"ip_address":"","ucode":"2968605D077072","user_header":"https://static001.geekbang.org/account/avatar/00/14/17/36/3d8e86e6.jpg","comment_is_top":false,"comment_ctime":1657442852,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100048401,"comment_content":"老师， 如果C0和C1合并后的某个data节点数据超过一个data阈值， 那接下来会发生什么？  \n我想到两种可能。\n1. 磁盘上B+树有多颗，每一颗的data节点容拿大小也不同， C1树最小节点data剩余容量会大于内存C0树的节点最大容量， 所以合并的时候， 不会出现data节点装不下问题。\n2. C0和C1同一个data节点合并之后超过阈值， 会重新调整数据， 把当前节点data合并之后多余的数据写入到下一个节点，当写一个节点满了，剩余数据写入到下下个节点，如果没有节点不存在，新建一个。  ","like_count":0},{"had_liked":false,"id":349954,"user_name":"阿甘","can_delete":false,"product_type":"c1","uid":1057843,"ip_address":"","ucode":"BC93175B70E05D","user_header":"https://static001.geekbang.org/account/avatar/00/10/24/33/bcf37f50.jpg","comment_is_top":false,"comment_ctime":1656470515,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100048401,"comment_content":"老师，请问Lucene的每个segment是不是就是一棵LSM树啊，不可修改，标记删除，不断合并。","like_count":0},{"had_liked":false,"id":332843,"user_name":"果果","can_delete":false,"product_type":"c1","uid":2027828,"ip_address":"","ucode":"458AC5EC0A8790","user_header":"https://static001.geekbang.org/account/avatar/00/1e/f1/34/6978db6a.jpg","comment_is_top":false,"comment_ctime":1643723288,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":5,"product_id":100048401,"comment_content":"如果内存中的数据都被处理完了，刚好在写check point的时候宕机了怎么办","like_count":0}]}