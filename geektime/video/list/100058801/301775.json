{"id":301775,"title":"52｜Table API/SQL核心概念","content":"<p><strong>课件和Demo地址</strong><br>\n<a href=\"https://gitee.com/geektime-geekbang/geektime-Flink\">https://gitee.com/geektime-geekbang/geektime-Flink</a></p>","comments":[{"had_liked":false,"id":327711,"user_name":"hujihu33","can_delete":false,"product_type":"c3","uid":1078729,"ip_address":"","ucode":"686860FE2DFABB","user_header":"https://static001.geekbang.org/account/avatar/00/10/75/c9/fb23007c.jpg","comment_is_top":false,"comment_ctime":1640247141,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100058801,"comment_content":"视频内容总结：\n1，旧的计划器和Blink新的计划器的几个不同点，之后会用Blink的计划器\n2，table api 和 SQL 的程序的结构--table connect (sink&#47;source) 创建表， 之后可以通过from , select 或者是 sqlQuery() 对数据源表进行操作并建立相应的table 对象，之后就是executeinsert()\n3, tableEnvironment 能够做什么事情\n4, flink sreaming query 和 flink batch query  、blink streaming query (使用 blinkplanner)、blink batch query\n5, 基于table api的查询\n6, 基于sql的查询 sqlQuery\n7,数据的输出，怎么定义输出sink，之后就 result.executeinsert()","like_count":1},{"had_liked":false,"id":276408,"user_name":"颜颜颜爱学习","can_delete":false,"product_type":"c3","uid":2357748,"ip_address":"","ucode":"C9358DD7245617","user_header":"","comment_is_top":false,"comment_ctime":1611911954,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100058801,"comment_content":"老师你好，对于flink1.12.0版本的流批一体测试时，我发现了一个小问题，就是对于离线数据分词统计时，sum为1 的单词不会被打印出来，sum 大于 1 的才会打印出来，能帮忙解释一下为什么会这样么？\n\n代码：\n    val env = StreamExecutionEnvironment.getExecutionEnvironment\n \n    env.setRuntimeMode(RuntimeExecutionMode.BATCH)  &#47;&#47; 在DataStream API上以批处理方式执行\n\n    &#47;&#47; 本地测试文件\n    val inputStream = env.readTextFile(getClass.getResource(&quot;&#47;hello.txt&quot;).getPath)\n\n    &#47;&#47; 分词统计，问题：批处理模式的时候，sum 为 1 的单词不会被打印\n    val resultStream = inputStream\n      .flatMap(_.split(&quot;,&quot;))\n      .filter(_.nonEmpty)\n      .map((_, 1))\n      .keyBy(_._1)\n      .sum(1)\n    resultStream.print()\n    env.execute(&quot;word count&quot;)\n\n测试文件的数据内容：\nhello,flink\nhello,flink\nhello,hive\nhello,hive\nhello,hbase\nhello,hbase\nhello,scala\nhello,kafka\nhello,kafka\n\n\n测试结果：hello&#47;flink&#47;hive&#47;hbase&#47;kafka的和大于1，会打印出来；但是 scala的个数为1，不会被打印出来","like_count":1},{"had_liked":false,"id":380645,"user_name":"Geek_591cf9","can_delete":false,"product_type":"c3","uid":3684583,"ip_address":"广东","ucode":"DBC0F916BC2B53","user_header":"","comment_is_top":false,"comment_ctime":1693926140,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100058801,"comment_content":"老师讲这么多源码，能不能提供一个思路怎么看flink项目的源码","like_count":0},{"had_liked":false,"id":348717,"user_name":"☺","can_delete":false,"product_type":"c3","uid":2292510,"ip_address":"","ucode":"33FF874C8CF748","user_header":"https://static001.geekbang.org/account/avatar/00/22/fb/1e/ab333cf9.jpg","comment_is_top":false,"comment_ctime":1655346282,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100058801,"comment_content":"老师，您好，通过sql api除了能进行查询输出结果外，还能不能对输入的数据做一些自定义的计算得出结果？以及如果结果有多个，能不能输出到不同的sink？谢谢","like_count":0}]}