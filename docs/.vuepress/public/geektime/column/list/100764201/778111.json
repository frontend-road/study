{"id":778111,"title":"04｜用Assistants中的File search（RAG）工具做知识检索","content":"<p>你好，我是黄佳。</p><p>上一课中，我们学习了如何基于Code Interpreter做自然语言驱动的数据分析。今天我们来看Assistant中的最后一个，也是超级强大的工具 —— File search（原名Retrieval，也就是文件检索，或者叫RAG）。通过File search，你的Assistant将获得从外部知识库中检索信息的能力，犹如装备了“千里眼”。</p><p><img src=\"https://static001.geekbang.org/resource/image/1b/9a/1b283c5f403e41d68f80cf3e9cb5299a.png?wh=1130x937\" alt=\"图片\" title=\"Playground 中 Assistant 的 File search 工具\"></p><p>根据OpenAI的说法，目前新版本可以检索多至10000个文档，果真如此，则OpenAI Assistants实在是一个强大的智能助理。</p><h2>什么是 File search（Retrieval）</h2><p>File search或Retrieval就是“检索”，是赋予Assistant查阅外部知识的能力。外部知识可以是你的企业内部文档、产品说明书、客户反馈等各种非结构化数据。有了这些额外的知识补充，Assistant可以更好地理解用户需求，给出更加准确、个性化的回复。</p><p>“检索”的实现原理并不复杂。当你上传一份文档后，OpenAI会自动对文档分块、创建索引，并使用向量搜索从中检索与用户查询最相关的内容。这一切都在File search工具内部自动完成，作为开发者的你并不需要关心其中的细节（当然，在后面的课程中，我也会带着你手动实现具体RAG步骤）。现在，你只管把数据“喂”给File search工具就可以啦。</p><!-- [[[read_end]]] --><p>当我们把Retrieval和LLM结合在一起，也就是在信息检索的基础上加上了LLM的内容生成和对话功能，就诞生了RAG（Retrieval-Augmented Generation）。这个过程，正如下面这张图所展示的那样。</p><p><img src=\"https://static001.geekbang.org/resource/image/b8/49/b898d27a7b5c8db7220146aab548c249.jpg?wh=1600x1150\" alt=\"图片\"></p><p>在这里：</p><ol>\n<li>用户先提出一个问题，如 “Did I meet my spending goal last month?”。</li>\n<li>RAG系统从知识库中检索出与问题最相关的片段，比如上个月的支出数据报告。</li>\n<li>然后系统将原始问题和检索到的相关知识一起输入到LLM中。</li>\n<li>LLM根据问题和相关背景知识，生成最终的回答：“Yes, you stayed under budget by $50 last month. Good Job!”</li>\n</ol><p>可以看到，RAG赋予了LLM利用外部知识库进行问答的能力。关键就在于Retrieval首先过滤掉了大量无关信息，只提取最相关的少量片段给LLM。这一方面降低了对LLM记忆容量的要求，另一方面也提高了LLM输出内容的准确性和可解释性。</p><p><strong>Retrieval让LLM真正成为了一个“知识的容器”，而不仅仅是一个“语言的模仿者”。</strong>通过给LLM灌输特定领域知识，我们可以打造出适用于各行各业的垂直助理，如客服、销售、法律、医疗等。这极大拓展了LLM的应用边界，为各行业的智能化升级赋能。</p><p>因此，很多人都认为，RAG系统，或者说RAG这个基于大语言模型的设计模式，点燃了最早一批AI大模型应用。实际情况也的确如此，我目前参与的很多项目，多多少少都有RAG的身影。</p><p>那么，OpenAI通过Assistants功能，就提供了一个开箱即用的File search工具，这实际上就是一个极简的RAG系统。开发者只需上传自己的知识文件，设置好Assistant的执行逻辑，就可以实现一个基于私有数据的智能问答系统，而无需自己搭建和训练复杂的 RAG模型。</p><h2>使用 Playground 中的 File search 工具</h2><p>我们还是先通过Playground中的File search来看看它的使用机理。</p><p>第一步，选择Create Assistant新建一个Assistant，并命名为RAG小能手（名字随意）。</p><p><img src=\"https://static001.geekbang.org/resource/image/eb/3e/ebed3b18bc2b530e4b5458dea6aed33e.png?wh=884x801\" alt=\"图片\"></p><p>第二步，开启File search功能，并通过Add功能上传数据文件。此处，要注意的是，目前只有较新的模型，如gpt-4-turbo-preview有这个功能。</p><p><img src=\"https://static001.geekbang.org/resource/image/d4/66/d4e2becd9bd4b1e8ca22d77c2ee6f566.png?wh=1111x579\" alt=\"图片\"></p><p>我上传了一篇PDF格式的论文，同时也上传了之前你已经见过的鲜花销售数据表。这里要注意的地方是，csv格式的文件目前还不被File search工具所支持，因此我是把相同的数据放进了word文档中。</p><p><img src=\"https://static001.geekbang.org/resource/image/b8/46/b8b2293735f7ac475e39b7dd108ca346.png?wh=741x290\" alt=\"图片\" title=\"我把鲜花销售数据放进 Word 文档中\"></p><p>选择Attach之后，文件就被导入到File search工具。</p><p><img src=\"https://static001.geekbang.org/resource/image/2e/13/2e2e73335277484d9f6a06cea9235c13.png?wh=534x548\" alt=\"图片\"></p><p>此处，如果选择Select vector store，那么，还有一个附加步骤，就是选择一个向量存储库来管理文件。</p><p><img src=\"https://static001.geekbang.org/resource/image/b3/bc/b3816bbdc21689e42637713bef94f3bc.png?wh=531x537\" alt=\"图片\"></p><p>不过，如果我们不选择任何一个向量存储库（也就是Vector Stores）的ID，OpenAI也会把文件存储在Storage的Files中，而且会为这些文件自动创建一个向量存储库，如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/4e/96/4ecdfa770dc6byy685808ba516740596.png?wh=876x277\" alt=\"图片\"></p><p>如果我们希望选择已经存在的向量存储库来管理文件，也可以，只需要在导入文件时选择Select vector store，并指定之前已经创建的向量存储库的ID。</p><p><img src=\"https://static001.geekbang.org/resource/image/1e/b2/1ed6690db18fbd451933d651bca535b2.png?wh=1736x423\" alt=\"图片\"></p><p>下一步，输入想要问的问题：“在鲜花的销售中，我们哪个产品销量最好？哪个卖得最差，对于卖得差的产品，应该采取什么推广策略？”</p><p>然后点击Run按钮，Retrival工具就开始工作了。</p><p><img src=\"https://static001.geekbang.org/resource/image/e6/7a/e694946f129d0c4ed5c073a3b91ef47a.png?wh=1900x1708\" alt=\"图片\"></p><p>那么，假设没有Retrieval这个附加流程，那么，大模型给出的答案有两种可能：要么是直接说信息不足，无法回答问题；而弱一点的模型就可能会产生幻觉，以为自己“知道”，从而胡说一个答案。而有了Retrieval的加持，可以看出GPT-4-Turbo-Preview这个模型给出了精准的回答。</p><h2>OpenAI 中的向量存储库</h2><p>在LangChain实战课的 <a href=\"https://time.geekbang.org/column/article/712147\">RAG</a> 章节中，我曾经介绍过各种商用和开源的向量数据库（向量数据库也就是向量存储库，同一个意思），那么现在，随着OpenAI 的Assistant迭代到第二版，OpenAI也拥有了自己的向量存储解决方案。</p><p>向量存储库是一种专门的数据库，允许通过语义和关键字搜索文件内容，支持高级搜索功能，包括语义搜索和关键字搜索。OpenAI中的向量存储库通过解析、分块、嵌入和存储文件到向量数据库，使用工具如助手（Assistant）和线程（Thread）来直接实现高级文件搜索功能。这样，你就不必再去寻找其它商用的向量数据库和GPT模型进行配合啦。就像好用的数据分析工具（Code Interpreter）一样，OpenAI再次成功地为我们提供了一站式的RAG解决方案。</p><p>每个向量存储库可以包含多达10,000个文件，每个助手和每个线程最多可以附加一个向量存储库。向量存储库中的文件限制为512 MB和500万个令牌。</p><p>可以通过单个API调用添加文件到向量存储库，此操作是异步的。操作包括创建向量存储库、添加单个文件或批量添加文件（每批最多500个文件）。在文件检索之前，要确保文件在向量存储库中已经完全处理好。</p><p>OpenAI 的Assistant的文件搜索功能支持多种文件格式，如PDF、Markdown和DOCX，以适应不同的文档类型。File search工具所支持的具体文件类型，可以参考 <a href=\"https://platform.openai.com/docs/assistants/tools/supported-files\">OpenAI 文档</a>。</p><h2>使用 OpenAI Assistant API 中的 File search 工具</h2><p>使用OpenAI Assistant API中的File search工具的具体流程和使用Code Intepreter的流程非常类似。</p><p>我们仍然是导入所需的库，并创建一个OpenAI client。</p><pre><code class=\"language-plain\"># 导入所需的库\nfrom dotenv import load_dotenv\nload_dotenv()\n# 创建Client\nfrom openai import OpenAI\nclient = OpenAI()\n# 设置Logging机制\nimport logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n</code></pre><p>先创建一个Assistant，或者你也可以直接检索刚才在Playground中创建的Assistant。</p><pre><code class=\"language-plain\">def create_assistant(instructions):\n&nbsp; &nbsp; try:\n&nbsp; &nbsp; &nbsp; &nbsp; # 创建一个启用了file_search工具的Assistant\n&nbsp; &nbsp; &nbsp; &nbsp; assistant = client.beta.assistants.create(\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; name=\"Sales Data Analyst\",\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; instructions=instructions,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; model=\"gpt-4-turbo\", \n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; tools=[{\"type\": \"file_search\"}],\n&nbsp; &nbsp; &nbsp; &nbsp; )\n&nbsp; &nbsp; &nbsp; &nbsp; return assistant\n&nbsp; &nbsp; except Exception as e:\n&nbsp; &nbsp; &nbsp; &nbsp; logger.error(f\"创建Assistant失败: {e}\")\n&nbsp; &nbsp; &nbsp; &nbsp; raise e\n</code></pre><p>然后创建新的Vector Store，用于存储文档。</p><pre><code class=\"language-plain\">def create_vector_store(name, file_paths):\n&nbsp; &nbsp; try:\n&nbsp; &nbsp; &nbsp; &nbsp; # 创建一个新的Vector Store\n&nbsp; &nbsp; &nbsp; &nbsp; vector_store = client.beta.vector_stores.create(name=name)\n&nbsp; &nbsp; &nbsp; &nbsp; \n&nbsp; &nbsp; &nbsp; &nbsp; # 准备要上传到OpenAI的文件\n&nbsp; &nbsp; &nbsp; &nbsp; file_streams = [open(path, \"rb\") for path in file_paths]\n&nbsp; &nbsp; &nbsp; &nbsp; \n&nbsp; &nbsp; &nbsp; &nbsp; # 使用SDK的上传和轮询辅助方法来上传文件,将它们添加到Vector Store中,\n&nbsp; &nbsp; &nbsp; &nbsp; # 并轮询文件批次的状态直到完成\n&nbsp; &nbsp; &nbsp; &nbsp; file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; vector_store_id=vector_store.id, files=file_streams\n&nbsp; &nbsp; &nbsp; &nbsp; )\n&nbsp; &nbsp; &nbsp; &nbsp; \n&nbsp; &nbsp; &nbsp; &nbsp; # 打印批次的状态和文件计数,查看此操作的结果\n&nbsp; &nbsp; &nbsp; &nbsp; logger.info(f\"文件批次状态: {file_batch.status}\") &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; logger.info(f\"文件计数: {file_batch.file_counts}\")\n\n&nbsp; &nbsp; &nbsp; &nbsp; return vector_store, file_batch\n&nbsp; &nbsp; except Exception as e: &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; logger.error(f\"创建Vector Store失败: {e}\")\n&nbsp; &nbsp; &nbsp; &nbsp; raise e\n</code></pre><p>下面，把Vector Store链接至刚刚创建的Assistant，这样我们就可以检索文件的内容。</p><pre><code class=\"language-plain\">def update_assistant_vector_store(assistant_id, vector_store_id):\n&nbsp; &nbsp; try:\n&nbsp; &nbsp; &nbsp; &nbsp; # 更新Assistant的tool_resources,使新的Vector Store可用\n&nbsp; &nbsp; &nbsp; &nbsp; assistant = client.beta.assistants.update(\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; assistant_id=assistant_id,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store_id]}},\n&nbsp; &nbsp; &nbsp; &nbsp; )\n&nbsp; &nbsp; &nbsp; &nbsp; return assistant\n&nbsp; &nbsp; except Exception as e:\n&nbsp; &nbsp; &nbsp; &nbsp; logger.error(f\"更新Assistant的Vector Store失败: {e}\")\n&nbsp; &nbsp; &nbsp; &nbsp; raise e\n</code></pre><p>然后定义创建线程的函数。</p><pre><code class=\"language-plain\">def create_thread(user_message, file_id):\n&nbsp; &nbsp; try:\n&nbsp; &nbsp; &nbsp; &nbsp; # 创建一个Thread并将文件ID附加到消息中 &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; thread = client.beta.threads.create(\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; messages=[\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"role\": \"user\", \n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"content\": user_message,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"attachments\": [\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; { \"file_id\": file_id, \"tools\": [{\"type\": \"file_search\"}] } &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ],\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ]\n&nbsp; &nbsp; &nbsp; &nbsp; )\n&nbsp; &nbsp; &nbsp; &nbsp; logger.info(f\"Thread的tool_resources: {thread.tool_resources}\")\n&nbsp; &nbsp; &nbsp; &nbsp; return thread\n&nbsp; &nbsp; except Exception as e: &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; logger.error(f\"创建Thread失败: {e}\")\n&nbsp; &nbsp; &nbsp; &nbsp; raise e\n</code></pre><p>之后，创建运行Assistant的函数。</p><pre><code class=\"language-plain\">def run_assistant(thread_id, assistant_id, instructions):\n&nbsp; &nbsp; try:\n&nbsp; &nbsp; &nbsp; &nbsp; # 使用create_and_poll SDK辅助方法创建run并轮询状态直到完成 \n&nbsp; &nbsp; &nbsp; &nbsp; run = client.beta.threads.runs.create_and_poll(\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; thread_id=thread_id, assistant_id=assistant_id,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; instructions=instructions \n&nbsp; &nbsp; &nbsp; &nbsp; )\n\n&nbsp; &nbsp; &nbsp; &nbsp; # 获取run生成的消息\n&nbsp; &nbsp; &nbsp; &nbsp; messages = list(client.beta.threads.messages.list(thread_id=thread_id, run_id=run.id))\n&nbsp; &nbsp; &nbsp; &nbsp; \n&nbsp; &nbsp; &nbsp; &nbsp; # 提取消息的文本内容\n&nbsp; &nbsp; &nbsp; &nbsp; message_content = messages[0].content[0].text\n&nbsp; &nbsp; &nbsp; &nbsp; annotations = message_content.annotations\n&nbsp; &nbsp; &nbsp; &nbsp; citations = []\n\n&nbsp; &nbsp; &nbsp; &nbsp; # 处理文件引用,将原文中的引用替换为[index]的形式\n&nbsp; &nbsp; &nbsp; &nbsp; for index, annotation in enumerate(annotations):\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if file_citation := getattr(annotation, \"file_citation\", None):\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cited_file = client.files.retrieve(file_citation.file_id) \n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; citations.append(f\"[{index}] {cited_file.filename}\")\n\n&nbsp; &nbsp; &nbsp; &nbsp; print(message_content.value)\n&nbsp; &nbsp; &nbsp; &nbsp; print(\"\\n\".join(citations))\n&nbsp; &nbsp; &nbsp; &nbsp; \n&nbsp; &nbsp; except Exception as e:\n&nbsp; &nbsp; &nbsp; &nbsp; logger.error(f\"运行Assistant失败: {e}\")\n&nbsp; &nbsp; &nbsp; &nbsp; raise e\n</code></pre><p>此处，run_assistant() 函数接受Thread ID和Assistant ID以及instruction作为参数，在指定的Thread上运行Assistant。在这个函数中，还通过create_and_poll对Run进行轮询，一直到交互结束，用client.beta.threads.messages.list提取消息的文本内容，并输出。</p><p>接着，创建轮询Run状态的函数。</p><pre><code class=\"language-plain\">def poll_run_status(client, thread_id, run_id, interval=5):\n    while True:\n        run = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run_id)\n        logger.info(f\"Run轮询状态: {run.status}\")\n        \n        if run.status in ['requires_action', 'completed']:\n            return run\n        time.sleep(interval)\n</code></pre><p>poll_run_status() 函数接受客户端、Thread ID、Run ID和轮询间隔作为参数，持续轮询Run的执行状态，直到Run完成或需要用户操作。它使用client.beta.threads.runs.retrieve()方法获取Run的最新状态，并记录到日志中。如果Run的状态变为requires_action或completed，则返回Run对象，否则按照指定的时间间隔继续轮询。</p><p>之后，获取Assistant回复。</p><pre><code class=\"language-plain\">def get_assistant_reply(thread_id):\n    try:\n        response = client.beta.threads.messages.list(thread_id=thread_id)\n\n        for message in response.data:\n            if message.role == 'assistant':\n                reply = message.content[0].text.value\n                logger.info(f\"Assistant回复: {reply}\")\n                return reply\n\n        logger.warning(\"Assistant没有生成有效回复\") \n        return None\n    except Exception as e:\n        logger.error(f\"获取Assistant回复失败: {e}\")\n        raise e\n</code></pre><p>此处，get_assistant_reply() 函数接受Thread ID作为参数，从指定Thread中获取Assistant的回复消息。它使用client.beta.threads.messages.list()方法列出Thread中的所有消息，然后遍历消息列表，找到角色为Assistant的消息，提取其文本内容作为回复。</p><p>最后就是主程序入口啦。</p><pre><code class=\"language-plain\">def main():\n&nbsp; &nbsp; instructions = \"你是一位销售数据分析助手。请利用提供的销售数据,尽可能准确完整地回答用户的问题。\"\n&nbsp; &nbsp; \n&nbsp; &nbsp; # 创建启用了file_search工具的Assistant\n&nbsp; &nbsp; assistant = create_assistant(instructions)\n&nbsp; &nbsp; logger.info(f\"创建Assistant成功,ID: {assistant.id}\") &nbsp;\n\n&nbsp; &nbsp; # 创建Vector Store并上传销售数据文件\n&nbsp; &nbsp; file_paths = [r\"01_Assitants\\Retrieval\\flower_sales.docx\"] &nbsp;\n&nbsp; &nbsp; vector_store, file_batch = create_vector_store(\"Sales Data\", file_paths)\n\n&nbsp; &nbsp; # 将新的Vector Store关联到Assistant &nbsp;\n&nbsp; &nbsp; assistant = update_assistant_vector_store(assistant.id, vector_store.id)\n&nbsp; &nbsp; \n&nbsp; &nbsp; user_message = \"请分析一下各种花卉的销售情况,哪个品种卖得最好,哪个卖得最差?对于销量不佳的品种,有什么推广建议吗?\"\n&nbsp; &nbsp; \n&nbsp; &nbsp; # 获取Vector Store中的文件列表\n&nbsp; &nbsp; files = list(client.beta.vector_stores.files.list(vector_store.id))\n&nbsp; &nbsp; file_id = files[0].id &nbsp;# 获取第一个文件的ID\n\n&nbsp; &nbsp; # 创建Thread并附加文件ID\n&nbsp; &nbsp; thread = create_thread(user_message, file_id)\n&nbsp; &nbsp; logger.info(f\"创建Thread成功,ID: {thread.id}\")\n&nbsp;\n&nbsp; &nbsp; # 在Thread上运行Assistant\n&nbsp; &nbsp; run_instructions = \"以花店店长的身份回答问题。\" \n&nbsp; &nbsp; run_assistant(thread.id, assistant.id, run_instructions)\n\nif __name__ == \"__main__\":\n&nbsp; &nbsp; main()\n</code></pre><p>主程序中，我们创建Assistant、创建并附加向量存储库、创建Thread、运行Assistant，并记录日志。这个程序流程非常清晰。</p><p>下面就是Asssitant运行后的输出，也非常令人满意。</p><pre><code class=\"language-plain\">INFO:httpx:HTTP Request: POST https://api.openai.com/v1/assistants \"HTTP/1.1 200 OK\"\nINFO:__main__:创建Assistant成功,ID: asst_2sc4224nnJxhOrIPN03KP3N3\nINFO:httpx:HTTP Request: POST https://api.openai.com/v1/vector_stores \"HTTP/1.1 200 OK\"\nINFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\nINFO:httpx:HTTP Request: POST https://api.openai.com/v1/vector_stores/vs_lIlA3S1N70YwMK1ZvGVVd6NZ/file_batches \"HTTP/1.1 200 OK\"\nINFO:httpx:HTTP Request: GET https://api.openai.com/v1/vector_stores/vs_lIlA3S1N70YwMK1ZvGVVd6NZ/file_batches/vsfb_ecae4aaea913467cafac56c6b69b6506 \"HTTP/1.1 200 OK\"\nINFO:httpx:HTTP Request: GET https://api.openai.com/v1/vector_stores/vs_lIlA3S1N70YwMK1ZvGVVd6NZ/file_batches/vsfb_ecae4aaea913467cafac56c6b69b6506 \"HTTP/1.1 200 OK\"\nINFO:__main__:文件批次状态: completed\nINFO:__main__:文件计数: FileCounts(cancelled=0, completed=1, failed=0, in_progress=0, total=1)\nINFO:httpx:HTTP Request: POST https://api.openai.com/v1/assistants/asst_2sc4224nnJxhOrIPN03KP3N3 \"HTTP/1.1 200 OK\"\nINFO:httpx:HTTP Request: GET https://api.openai.com/v1/vector_stores/vs_lIlA3S1N70YwMK1ZvGVVd6NZ/files \"HTTP/1.1 200 OK\"\nINFO:httpx:HTTP Request: GET https://api.openai.com/v1/vector_stores/vs_lIlA3S1N70YwMK1ZvGVVd6NZ/files?after=file-9VVUSDXsNZ2KFJzMYUQEcYJU \"HTTP/1.1 200 OK\"\nINFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\nINFO:__main__:Thread的tool_resources: ToolResources(code_interpreter=None, file_search=ToolResourcesFileSearch(vector_store_ids=['vs_s6piHqEThJ4BSuvnlrk0Cfou']))\nINFO:__main__:创建Thread成功,ID: thread_gNRSn5iB9hIOJIS95TP8iy7n\nINFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_gNRSn5iB9hIOJIS95TP8iy7n/runs/run_dGMXDzKquLYB11G8dK6ZBwTA \"HTTP/1.1 200 OK\"\nINFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_gNRSn5iB9hIOJIS95TP8iy7n/runs/run_dGMXDzKquLYB11G8dK6ZBwTA \"HTTP/1.1 200 OK\"\nINFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_gNRSn5iB9hIOJIS95TP8iy7n/runs/run_dGMXDzKquLYB11G8dK6ZBwTA \"HTTP/1.1 200 OK\"\nINFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_gNRSn5iB9hIOJIS95TP8iy7n/messages?run_id=run_dGMXDzKquLYB11G8dK6ZBwTA \"HTTP/1.1 200 OK\"\nINFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_gNRSn5iB9hIOJIS95TP8iy7n/messages?run_id=run_dGMXDzKquLYB11G8dK6ZBwTA&amp;after=msg_uxxkKXF7PtXxRVMPpjPVUYu5 \"HTTP/1.1 200 OK\"\nINFO:httpx:HTTP Request: GET https://api.openai.com/v1/files/file-9VVUSDXsNZ2KFJzMYUQEcYJU \"HTTP/1.1 200 OK\"\nINFO:httpx:HTTP Request: GET https://api.openai.com/v1/files/file-9VVUSDXsNZ2KFJzMYUQEcYJU \"HTTP/1.1 200 OK\"\nINFO:httpx:HTTP Request: GET https://api.openai.com/v1/files/file-9VVUSDXsNZ2KFJzMYUQEcYJU \"HTTP/1.1 200 OK\"\nINFO:httpx:HTTP Request: GET https://api.openai.com/v1/files/file-9VVUSDXsNZ2KFJzMYUQEcYJU \"HTTP/1.1 200 OK\"\n\n根据提供的数据文件，以下是不同花卉的销售情况分析：\n\n1. **最佳销售品种**：\n&nbsp; &nbsp;- 玫瑰（Rose）通常的销售情况较好，具体表现在销售数量和利润上[0]。\n&nbsp; &nbsp;- 百合（Lily）的销售情况也不错，尤其是在利润方面[1]。\n\n2. **销售表现较差的品种**：\n&nbsp; &nbsp;- 太阳花（Sunflower）在多次销售中表现不佳，损失相对较高[2]。\n&nbsp; &nbsp;- 雏菊（Daisy）也有一些销售记录显示亏损[0]。\n\n3. **对于销量不佳的品种的推广建议**：\n&nbsp; &nbsp;- **打折促销**：对于销售不佳的花卉如太阳花和雏菊，可以尝试短期打折促销，吸引顾客购买。\n&nbsp; &nbsp;- **捆绑销售**：将销售表现不佳的花卉与热门品种如玫瑰或百合一起捆绑销售，提高销售量。\n&nbsp; &nbsp;- **增加曝光**：通过社交媒体推广和花店内的显眼摆放，增加这些花卉的曝光率，引起顾客的注意。\n&nbsp; &nbsp;- **提供创意玩法**：组织相关的花艺工作坊，教授顾客如何用这些花卉进行创意装饰，提高顾客的购买兴趣。\n\n以上是基于现有数据的分析和建议，希望能帮助你提升花店的整体销售业绩。\n[0] flower_sales.docx\n[1] flower_sales.docx\n[2] flower_sales.docx\n[3] flower_sales.docx\n</code></pre><p>这个输出的亮点不仅仅在于包含了详细的API日志，而且还巧妙地通过脚注的方式列出了信息来源，这对于RAG系统的可信度有非常大的帮助。这是个新功能，因为在Assistant v1版本中，我可没有见过！</p><h2>总结时刻</h2><p>在本课中，我们深入探讨了Assistant中的File search工具。File search赋予了大语言模型从外部知识库中检索信息的能力，让其从单纯的“语言模型”升级为更加智能和全能的“知识工作者”。通过将文件检索与大语言模型相结合，诞生了RAG这一强大的范式。RAG让大语言模型拥有了更广阔的“知识视野”，能够借助外部信息来回答更加开放和专业的问题，其潜力之大，令人无限遐想。</p><p>OpenAI在其Assistant产品中提供了一个极简版的Retrieval工具，让开发者无需搭建和训练复杂的RAG模型，即可实现基于特定领域知识的智能对话功能。这极大降低了RAG技术的使用门槛，为各行各业打造定制化AI助手铺平了道路。</p><p>当然，生产环境中的RAG系统的实现，也许有些需求Assistant的File search无法完全满足，或者你不希望每天为OpenAI付费，因此你还是决定自己定制RAG系统。在这里我们只是初窥门径，对RAG有了一个初步的认识。在后续的课程（或新课程）中，我将带你更彻底地拆解RAG的技术架构，手把手教你从0到1构建更复杂的RAG应用，带着你全面掌握RAG的原理和开发流程，通过不同的技巧（如更好的文档分割、更高效的检索）提升检索和回答的准确率。敬请期待！</p><h2>思考题</h2><p>以下是几个思考题，可以帮助你更好地理解File search工具和RAG技术。</p><ol>\n<li>File search目前支持多种主流文件格式。假如你要为一家律师事务所公司搭建一个基于File search的客服系统，你会把哪些类型的数据纳入知识库？要让Assistant具备哪些核心功能? 如果是搭建律师使用的检索助手系统呢？</li>\n<li>现在，你已经学完了启程篇，完全掌握了Assistant这个工具，你觉得，它实现了吴恩达老师提出的Agent模式中的哪几种？为什么？</li>\n<li>知识获取是RAG的关键，但并非所有知识都是结构化或半结构化的，还有大量散落在视频、音频、图像等非结构化数据中的知识。如何将多模态信息纳入RAG的知识库，让大语言模型也能看图、听音、看视频，进而回答相关问题？（提示：这是我们后续课程要讲述的内容，你可以先自己研究一下。）</li>\n</ol><p>好啦，今天的内容就到这里。RAG为大语言模型带来了知识库这个强大的“外挂”，必将带来智能对话领域的新变革。希望这节课能让你对RAG有更深刻的理解，也期待在后续的讨论中听到你的想法和体会。</p><p>如果今天的内容让你有所收获，也欢迎你把这节课转发给有需要的朋友！我们下节课再见！</p>","neighbors":{"left":{"article_title":"03｜用Assistants中的Code interpreter做数据分析","id":777441},"right":{"article_title":"05｜用5种不同模型展示模型交互5大基本原则","id":778871}},"comments":[{"had_liked":false,"id":391016,"user_name":"Mr King","can_delete":false,"product_type":"c1","uid":1024151,"ip_address":"江苏","ucode":"F0084F824F74C8","user_header":"https://static001.geekbang.org/account/avatar/00/0f/a0/97/7b9f4b52.jpg","comment_is_top":false,"comment_ctime":1717058615,"is_pvip":false,"replies":[{"id":142231,"content":"有啊，国内的大模型做的也都不错，可以调用API试一试。当然目前Function Calling的能力，可能还是国外的几个模型最强（OpenAI-GPT，Google-Gemini，Claude），国内模型我没用过进行Function Call。","user_name":"作者回复","user_name_real":"编辑","uid":1809833,"ctime":1717217981,"ip_address":"新加坡","comment_id":391016,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100764201,"comment_content":"具备感知输入、利用内部知识进行分析和推理、最终产生输出的能力","like_count":0,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":646052,"discussion_content":"有啊，国内的大模型做的也都不错，可以调用API试一试。当然目前Function Calling的能力，可能还是国外的几个模型最强（OpenAI-GPT，Google-Gemini，Claude），国内模型我没用过进行Function Call。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1717217981,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"新加坡","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1024151,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/a0/97/7b9f4b52.jpg","nickname":"Mr King","note":"","ucode":"F0084F824F74C8","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":646136,"discussion_content":"突破上下文长度限制（说胡话）目前是不是还没啥办法可以解决，例如一个中型的前后端的项目工程几十mb甚至上百mb的都有，然后利用ai它来修改以前的老的逻辑，还需要加新的API和页面布局。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1717429903,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":391015,"user_name":"Mr King","can_delete":false,"product_type":"c1","uid":1024151,"ip_address":"江苏","ucode":"F0084F824F74C8","user_header":"https://static001.geekbang.org/account/avatar/00/0f/a0/97/7b9f4b52.jpg","comment_is_top":false,"comment_ctime":1717058520,"is_pvip":false,"replies":[{"id":142230,"content":"有啊，国内的大模型做的也都不错，可以调用API试一试。当然目前Function Calling的能力，可能还是国外的几个模型最强（OpenAI-GPT，Google-Gemini，Claude），国内模型我没用过进行Function Call。","user_name":"作者回复","user_name_real":"编辑","uid":1809833,"ctime":1717217972,"ip_address":"新加坡","comment_id":391015,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100764201,"comment_content":"国内的 质朴轻言 有这个能力么？","like_count":0,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":646051,"discussion_content":"有啊，国内的大模型做的也都不错，可以调用API试一试。当然目前Function Calling的能力，可能还是国外的几个模型最强（OpenAI-GPT，Google-Gemini，Claude），国内模型我没用过进行Function Call。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1717217973,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"新加坡","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":390926,"user_name":"qinsi","can_delete":false,"product_type":"c1","uid":1667175,"ip_address":"上海","ucode":"090D9C4068FF12","user_header":"https://static001.geekbang.org/account/avatar/00/19/70/67/0c1359c2.jpg","comment_is_top":false,"comment_ctime":1716774733,"is_pvip":true,"replies":[{"id":142219,"content":"肯定会取代搜索引擎的。目前GPT-4的搜索功能已经蛮不错的，反正我google访问量少了很多。一般我和GPT对话较新的内容，我就在最后加一句，你搜一下。他就会先搜索，再回复。","user_name":"作者回复","user_name_real":"编辑","uid":1809833,"ctime":1717080709,"ip_address":"新加坡","comment_id":390926,"utype":1}],"discussion_count":3,"race_medal":0,"score":2,"product_id":100764201,"comment_content":"chatgpt刚出来那会看到铺天盖地炒作AI是下一代的搜索引擎时就觉得纳闷，没有时效性，胡言乱语，甚至参考资料都可以编造出来的玩意儿要怎么取代搜索引擎？有了rag以后感觉似乎有希望了，不过那么久了还没看到商业上成功的AI搜索引擎出现又是为什么？","like_count":0,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":645997,"discussion_content":"肯定会取代搜索引擎的。目前GPT-4的搜索功能已经蛮不错的，反正我google访问量少了很多。一般我和GPT对话较新的内容，我就在最后加一句，你搜一下。他就会先搜索，再回复。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1717080709,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"新加坡","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3574694,"avatar":"https://static001.geekbang.org/account/avatar/00/36/8b/a6/5f32a2f9.jpg","nickname":"单向地铁","note":"","ucode":"72E611CA0EBA18","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":645840,"discussion_content":"ai搜索引擎已经有不少了吧，国外的perplexity，国内的秘塔AI搜索、360搜索、ThinkAny。不过我个人用不惯这种ai搜索，总感觉不自己点进网页看一下不放心😂","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1716879298,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"安徽","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3600600,"avatar":"https://static001.geekbang.org/account/avatar/00/36/f0/d8/c344594a.jpg","nickname":"🇾.🇨.","note":"","ucode":"C033E961553EA3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":645786,"discussion_content":"比起这个我更好奇以后真实现了百度会往AI搜索里塞广告吗哈哈哈哈","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1716777312,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"英国","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":395693,"user_name":"coderlee","can_delete":false,"product_type":"c1","uid":1027564,"ip_address":"福建","ucode":"09569C08693514","user_header":"https://static001.geekbang.org/account/avatar/00/0f/ad/ec/406130f3.jpg","comment_is_top":false,"comment_ctime":1731731105,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100764201,"comment_content":"Q1:\n1）常见问题、流程引导、律所介绍等\n2）检索、归纳总结、建议、\n3）历年案例、司法等\nQ2:\n1.反思（Reflection）\n2.工具使用（Tool use）\n3.规划（Planning）\n4.多Agent协作（Multiagent collaboration）\n都具备。理由：从代码执行的各个步骤以及输出结果来看，从1-4都可以看到影子。\nQ3:\n1.直接将非结构化数据存入知识库\n2.借助自定义工具（例如，深度学习训练出来的模型对视音频进行分析后得出的结论）存入知识库\n3.本地模型与大模型相结合\n4.领域多模态大模型的微调训练","like_count":0},{"had_liked":false,"id":391564,"user_name":"Alex","can_delete":false,"product_type":"c1","uid":1352753,"ip_address":"江苏","ucode":"1770CA7050647A","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTI8qibAw4lRCic1pbnA6yzQU3UqtQm3NqV1bUJ5EiaUnJ24V1yf4rtY7n2Wx7ZVvTemqq5a61ERWrrHA/132","comment_is_top":false,"comment_ctime":1718530459,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100764201,"comment_content":"main方法中:\n# 将新的Vector Store关联到Assistant \nassistant = update_assistant_vector_store(assistant.id, vector_store.id)\n这里 assistant 会覆盖掉 assistant.id会为None (python 3.11  openai 1.25.0)","like_count":0}]}