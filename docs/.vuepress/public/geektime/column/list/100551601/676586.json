{"id":676586,"title":"15｜数据迁移：如何在不停机的情况下保证迁移数据的一致性？","content":"<p>你好，我是大明。今天我们来聊聊数据迁移的问题。</p><p>我之前就注意到很多人的简历里面都会提到数据迁移方面的内容。比如：</p><ul>\n<li>重构老系统：使用新的表结构来存储数据；</li>\n<li>单库拆分分库分表、分库分表扩容；</li>\n<li>大表修改表结构定义。</li>\n</ul><p>但是在面试的时候，他们就是说不清楚数据迁移究竟应该怎么做，又或者说自己是停机迁移数据的。</p><p>这就是小看了数据迁移这个面试点。数据迁移其实是一个很能够综合体现你设计复杂方案解决棘手问题的点，它能进一步凸显你在数据库方面的积累，所以千万不能忽视。今天我就给你展示一个非常全面的不停机数据迁移的方案。</p><h2>数据备份工具</h2><p>这里我先来介绍一下 MySQL 上常用的两款数据备份工具：mysqldump和XtraBackup。</p><ul>\n<li>mysqldump：一个用于备份和恢复 MySQL 数据库的命令行工具。它允许用户导出 MySQL 数据库的结构、数据以及表之间的关系，以便在数据库发生问题时进行恢复。它是一个逻辑备份工具，导出的内容是一条条 SQL。</li>\n<li>XtraBackup：它使用了 InnoDB 存储引擎的数据备份技术，支持增量备份和恢复，并且支持多主机备份和恢复。它是一个物理备份工具，相当于直接复制 InnoDB 的底层存储文件。</li>\n</ul><p><img src=\"https://static001.geekbang.org/resource/image/e3/d0/e341443c3cc11c3b04d17a28134cbbd0.png?wh=1920x712\" alt=\"图片\"></p><p>如果你使用的不是 MySQL，可以自己收集一下你使用的数据库的工具。要注意分析这些工具的优缺点，尤其是导入导出速度以及可行的优化手段。</p><!-- [[[read_end]]] --><h2>innodb_autoinc_lock_mode</h2><p>innodb_autoinc_lock_mode 是 InnoDB 引擎里面控制自增主键生成策略的参数，它有三个取值。</p><ul>\n<li>0：使用表自增锁，但是锁在 INSERT 语句结束之后就释放了。</li>\n<li>1：使用表自增锁，如果是普通的 INSERT INTO VALUE 或者 INSERT INTO VALUES 语句，申请了主键就释放锁，而不是整个 INSERT 语句执行完毕才释放。如果是 INSERT SELECT 等语句，因为无法确定究竟要插入多少行，所以都是整个 INSERT 语句执行完毕才释放。</li>\n<li>2：使用表自增锁，所有的语句都是申请了主键就立刻释放。</li>\n</ul><p>这里我额外提一点，就是在执行 INSERT INTO VALUES 的时候，不管插入多少行，都只申请一次主键，一次申请够，这些主键<strong>必然是连续的</strong>。所以你可以从返回的最后一个 ID 推测出全部 ID。</p><h2>面试准备</h2><p>在面试之前，你需要了解清楚几个信息。</p><ul>\n<li>innodb_autoinc_lock_mode 的值，这会影响主键生成策略，而你在数据迁移的时候是需要考虑处理主键问题的。</li>\n<li>公司 binlog 的模式，在后面增量校验和修复数据里面使用的是行模式的 binlog。</li>\n<li>公司是否有统一的数据库规范，比如说必须要更新时间戳，不能硬删除，只能软删除。</li>\n<li>你使用的 ORM 框架怎么实现双写？</li>\n<li>公司是否做过数据迁移？如果做过，具体的方案是什么？当然，如果你做过数据迁移，那就最好不过了。</li>\n</ul><p>正常来说，如果你真的解决过复杂的数据迁移，那么它完全可以作为一个独立的项目写到简历里面。又或者你在讲到某个项目的时候，可以说自己设计过一个非常复杂的数据迁移方案。我用重构系统作为例子，给你展示一下这个话术。</p><blockquote>\n<p>这个系统是我们公司的一个核心系统，但是又有非常悠久的历史。在我刚接手的时候，它已经处于无法维护的边缘了。但是不管是重构这个系统，还是重新写一个类似的系统，已有的数据都是不能丢的。所以我的核心任务就是重新设计表结构，并且完成数据迁移。为此我设计了一个高效、稳定的数据迁移方案。</p>\n</blockquote><p>如果你实际落地了单库拆分分库分表，或者你们公司单库拆分了分库分表，你也可以这样说。</p><blockquote>\n<p>我进公司的时候，刚好遇上单库拆分分库分表。我主要负责的事情就是设计一个数据迁移方案，把数据从单库迁移到分库分表上。</p>\n</blockquote><p>我建议你在实践中推演一下这个方案。有条件的话，自己准备两个数据库尝试一下会更好。</p><h2>解决方案</h2><p>下面我们来看一看数据迁移方案的基本步骤。</p><ol>\n<li>创建目标表。</li>\n<li>用源表的数据初始化目标表。</li>\n<li>执行一次校验，并且修复数据，此时用源表数据修复目标表数据。</li>\n<li>业务代码开启双写，此时读源表，并且先写源表，数据以源表为准。</li>\n<li>开启增量校验和数据修复，保持一段时间。</li>\n<li>切换双写顺序，此时读目标表，并且先写目标表，数据以目标表为准。</li>\n<li>继续保持增量校验和数据修复。</li>\n<li>切换为目标表单写，读写都只操作目标表。</li>\n</ol><p>如果不考虑数据校验，那么整个数据迁移过程是这样的。</p><p><img src=\"https://static001.geekbang.org/resource/image/2b/20/2b23d430a4284b860be2876f11174c20.png?wh=1920x1222\" alt=\"图片\"></p><p>所以比较简单的方式就是记住图里的四步，图右边的两步都要考虑校验和修复数据的问题。接下来我带你分析一下方案里的关键步骤。</p><h3>初始化目标表数据</h3><p>在创建了一个目标表之后，第一步是先尝试初始化目标数据，问题是<strong>你怎么拿到源表数据？</strong>那么基本思路有两个：一是使用源表的历史备份，基本上数据库都会有备份机制，那么你自然可以利用这些备份来初始化目标表的数据。二是源表导出数据，导出数据的时候，你可以使用我介绍的那些工具。大部分情况下，使用 mysqldump 是不会出问题的，无非就是导出导入慢一些，而这也恰好是你刷亮点的地方。</p><p>那么我们就以 mysqldump 为例来聊一下，这里的关键词就是<strong>加快导入和导出速度</strong>。</p><blockquote>\n<p>我选择了从源表导出数据，使用的是 mysqldump 工具。mysqldump 是一个开源的逻辑备份工具，优点是使用简单，能够直接导出整个数据库。缺点则是导出和导入的速度都比较慢，尤其是在数据量非常大的情况下。所以我针对 mysqldump 做了一些优化，来提高导出和导入的性能。加快导出速度能做的事情并不多，主要就是开启 extended-insert 选项，将多行合并为一个 INSERT 语句。<br>\n&nbsp;<br>\n加快导入速度就可以做比较多的事情。</p>\n<ol>\n<li>关闭唯一性检查和外键检查，源表已经保证了这两项，所以目标表并不需要检查。</li>\n<li>关闭 binlog，毕竟导入数据用不着 binlog。</li>\n<li>调整 redo log 的刷盘时机，把 innodb_flush_log_at_trx_commit 设置为 0。</li>\n</ol>\n</blockquote><p>注意在第2、3点里面，可以把话题引向上一节课的 binlog 和 redolog 内容。反过来，你也可以利用 binlog 和 redolog 把话题引导到这一节课的内容，灵活应对就可以。</p><h3>第一次校验与修复</h3><p>在初始化数据之后，你可以先尝试立刻校验和修复一下数据，因为如果你前面用的是备份数据，那么备份数据已经落后生产数据了。比如说你用的是昨天的备份，那么今天的修改目标表就没有。还有如果你是导出的数据，那么导出数据到你导入数据这段时间，数据发生了变化，目标表依旧是没有的。</p><p>如果你们公司有明确的数据库规范的话，比如说所有的表都需要有 update_time 这个字段，那么你在校验和修复的时候就可以采用增量的方案。因为只有 update_time 晚于你导出数据的那个时间点，才说明这一行的数据已经发生了变更。在修复的时候就<strong>直接用源表的数据覆盖掉目标表的数据</strong>。</p><h3>业务开启双写，以源表为准</h3><p>首先你要解释清楚你是怎么做到双写的。支持双写大体上有两个方向：侵入式和非侵入式两种。<strong>侵入式方案就是直接修改业务代码</strong>。要求业务代码在写了源表之后再写目标表。但是侵入式方案是不太可行的，或者说代价很高。因为这意味着所有的业务都要检查一遍，然后修改。既然修改了，那自然还要测试。所以，一句话总结就是工作量大还容易出错。</p><p><strong>非侵入式一般和你使用的数据库中间件有关</strong>，比如说 ORM 框架。这一类框架一般会提供两种方式来帮你解决类似的问题。</p><ul>\n<li>AOP（Aspect Oriented Program 面向切面编程）方案：不同框架有不同叫法，比如说可能叫做 interceptor、middleware、hook、handler、filter。这个方案的关键就是捕捉到发起的增删改调用，篡改为双写模式。</li>\n</ul><p><img src=\"https://static001.geekbang.org/resource/image/a4/17/a4dd67afc39b5664d12yyd487c960d17.png?wh=1920x957\" alt=\"图片\"></p><ul>\n<li>数据库操作抽象：可能叫做 Session、Connection、Connection Pool、Executor 等，就是将对源表的操作修改为双写模式。</li>\n</ul><p>不管你采用哪个方案，你都要确保一个东西，就是双写可以在运行期随时切换状态，单写源表、先写源表、先写目标表、单写目标表都可以。</p><p>大多数时候都是利用一个标记位，然后你可以通过配置中心或者接口直接修改它的值。</p><p><img src=\"https://static001.geekbang.org/resource/image/dc/dd/dce6cf90a5123bcc29c7bcbf3b5741dd.png?wh=1920x1046\" alt=\"图片\"></p><p>我以 Go 语言的 GORM 为例，给你展示基本的回答。</p><blockquote>\n<p>开启双写在 GORM 上面还是比较容易做到的。最开始我觉得可以考虑使用 GORM 的 Hook 机制，用 DELETE 和 SAVE 两个 Hook 就可以了。但是这要求我必须给每一个模型或表都定义类似的 Hook，还是比较麻烦的。后来我仔细翻了 GORM 的文档，确认可以考虑使用 GORM 的 ConnPool 接口。所以我用装饰器模式封装了两个数据源，每次执行语句的时候，都根据标记位来执行双写逻辑。</p>\n</blockquote><p>我这里给你看一个伪代码，让你有一个直观的认知。</p><pre><code class=\"language-go\">func (m *DouleWritePool) QueryContext(ctx context.Context, query string, args ...interface{}) (*sql.Rows, error) {\n    if m.mode == '源表优先' {\n      err = m.source.QueryContext(ctx, query, args...)\n      if err == nil {\n         m.target.QueryContext(ctx, query, args...)\n      }\n    } else if {\n      //...\n    }\n}\n</code></pre><p>很多时候，你在简历里面写上自己精通某个框架，但是都缺乏说服力，那么这个就可以作为一个证明。在双写的时候，你可以往两个方向进一步刷亮点：数据一致性问题和主键问题。</p><h4>数据一致性问题</h4><p>正常面试官都可能会问到，如果在双写过程中，写入源表成功了，但是写入目标表失败了，该怎么办？那么最基础的回答就是<strong>不管。</strong></p><blockquote>\n<p>写入源表成功，但是写入目标表失败，这个是可以不管的。因为我后面有数据校验和修复机制，还有增量校验和修复机制，都可以发现这个问题。</p>\n</blockquote><p>然后你可以提出一个曾经思考过但是最终没有实施的方案，这能够证明你在数据一致性上有过很深入的思考，关键词是<strong>难以确定被影响的行</strong>。</p><blockquote>\n<p>在设计方案的时候，我考虑过在写入目标表失败的时候，发一个消息到消息队列，然后尝试修复数据。但是这个其实很难做到，因为我不知道该修复哪些数据。比如说一个 UPDATE 语句在目标表上执行失败，我没办法根据 UPDATE 语句推断出源表上哪些行被影响到了。</p>\n</blockquote><p><img src=\"https://static001.geekbang.org/resource/image/29/e3/29f5c51cc8575a35f55e1fc0d3eb80e3.png?wh=1920x761\" alt=\"图片\"></p><h4>主键问题</h4><p>如果在源表中使用的是自增主键，那么在双写的时候写入目标表要不要写入主键？答案是要的。也就是说，你需要在写入源表的时候拿到自增主键，然后写入目标表的时候设置好主键。因为你其实并不能确保目标表自增的主键，和你源表自增的主键是同一个值。比如说在并发场景下，两次插入。</p><p><img src=\"https://static001.geekbang.org/resource/image/4d/30/4d4975674fb45806d0b89d1e33311530.png?wh=1920x1045\" alt=\"图片\"></p><p>因此你可以介绍你是如何处理这个问题的。</p><blockquote>\n<p>在双写的时候比较难以处理的问题是自增主键问题。为了保持源表和目标表的数据完全一致，需要在源表插入的时候拿到自增主键的值，然后用这个值作为目标表插入的主键。</p>\n</blockquote><p><img src=\"https://static001.geekbang.org/resource/image/f3/94/f30c10ab32ce6fab3081yy1176189294.png?wh=1920x979\" alt=\"图片\"></p><p>此外你还可以进一步展示一个更加高级的亮点，也就是我在前置知识里面说到的 <strong>innodb_autoinc_lock_mode</strong> 取值会影响自增主键的连续性，抓住关键词<strong>自增主键的连续性</strong>。</p><blockquote>\n<p>在处理批量插入的时候要更加小心一些。正常来说，批量插入如果用的是 VALUES 语法，那么生成的主键是连续的，就可以从返回的最后一个主键推测出前面其他行的主键。即便 innodb_autoinc_lock_mode 取值是 2 也能保证这一点。但是如果用的是多个 INSERT INTO VALUE 语句，或者 INSERT SELECT语句，这些语句生成的主键就可能不连续。在双写之前，就要先改造这一类的业务。</p>\n</blockquote><h3>增量校验和数据修复</h3><p>增量校验基本上就是一边保持双写，一边校验最新修改的数据，如果不一致，就要进行修复。这里我们也有两个方案。第一个方案是利用更新时间戳，比如说 update_time 这种列；第二个方案是利用 binlog。相比之下 binlog 更加高级一点，在面试的时候你应该优先考虑用这个方案。</p><h4>利用更新时间戳</h4><p>利用更新时间戳的思路很简单，就是定时查询每一张表，然后根据更新时间戳来判断某一行数据有没有发生变化。我们用伪代码来描述一下。</p><pre><code class=\"language-sql\">for {\n  // 执行查询\n  // SELECT * FROM xx WHERE update_time &gt;= last_time\n  rows := findUpdatedRows()\n  for row in rows {\n    // 找到目标行，要用主键来找，用唯一索引也可以，看你支持到什么程度\n    tgtRow = findTgt(row.id)\n    if row != tgtRow {\n      // 修复数据\n      fix()\n    }\n  }\n  // 用这一批数据里面最大的更新时间戳作为下一次的起始时间戳\n  last_time = maxUpdateTime(row)\n  // 睡眠一下\n  sleep(1s)\n}\n</code></pre><p>所以你可以介绍基本的策略，关键词是<strong>更新时间戳。</strong></p><blockquote>\n<p>我们采用的方案是利用更新时间戳找出最近更新过的记录，然后再去目标表里面找到对应的数据，如果两者不相等，就用源表的数据去修复目标表的数据。这个方案有两个条件：所有的表都是有更新时间戳的，并且删除是软删除的。</p>\n</blockquote><p><img src=\"https://static001.geekbang.org/resource/image/29/40/29b2341c9dc65b165e036cc46949cc40.png?wh=1920x1045\" alt=\"图片\"></p><p>我们在这里提到的第二个条件就是准备展示的第一个亮点。你可以等面试官追问为什么必须是软删除，也可以自己接着回答。</p><blockquote>\n<p>如果不是软删除的，那么源表删掉数据之后，如果目标表没删除，在我们的匹配逻辑里面是找不到的。在这种场景下，还有一个补救措施，就是反向全量校验。也就是说从目标表里面再次查询全量数据，再去源表里找对应的数据。如果源表里面没有找到，就说明源表已经删了数据，那么目标表就可以删除数据了。</p>\n</blockquote><p><img src=\"https://static001.geekbang.org/resource/image/83/43/83a2d7e9373a93f3a6290107be69af43.png?wh=2432x1314\" alt=\"\"></p><p>接下来我们可以进一步展示第二个亮点，这个亮点就是<strong>主从同步延迟</strong>引发的问题。假设你在校验和修复的时候，读的都是从库，那么你会遇到两种异常情况。一种是目标表主从延迟，另一种是源表主从延迟。</p><p><img src=\"https://static001.geekbang.org/resource/image/f7/8c/f7289b8470e352yy329a000de2b3038c.png?wh=1920x1092\" alt=\"图片\"></p><p>那么怎么解决呢？简单粗暴的方法就是全部读主库，校验和修复都以主库数据为准。<strong>缺点就是对主库的压力会比较大</strong>。</p><p>我这里给你一个更加高级的方案：<strong>双重校验</strong>。</p><blockquote>\n<p>校验和修复的时候都要小心主从同步的问题，如果校验和修复都使用从库的话，那么就会出现校验出错，或者修复出错的情况。按照道理来说，强制走主库就可以解决问题，但是这样对主库的压力是比较大的。<br>\n&nbsp;<br>\n所以我采用的是双重校验方案。第一次校验的时候读从库，如果发现数据不一致，再读主库，用主库的数据再校验一次。修复的时候就只能以主库数据为准。这种方案的基本前提是，主从延迟和数据不一致的情况是小概率的，所以最终会走到主库也是小概率的。</p>\n</blockquote><p>在这个回答里面你没有提到任何异常情况的具体场景，如果面试官问到了，你就回答上面图里面的两种情况。这个亮点能够凸显你在主从延迟方面的积累，也会把话题引到主从模式和主从同步上，所以你要做好准备。</p><h4>利用 binlog</h4><p>binlog是一个更加高级的方案，它还有一些变种，所以理解和记忆的难度也更高一些。注意，我这里说的 binlog 是指<strong>基于行的 binlog 模式</strong>。我先从最简单的形态说起。</p><p>最简单的形态就是将 binlog 当做一个触发器，我们回答的关键词就是<strong>binlog触发。</strong></p><blockquote>\n<p>在校验和修复的数据时候，我采用的是监听 binlog 的方案。binlog 只用于触发校验和修复这个动作，当我收到 binlog 之后，我会用 binlog 中的主键，去查询源表和目标表，再比较两者的数据。如果不一致，就用源表的数据去修复目标表。</p>\n</blockquote><p><img src=\"https://static001.geekbang.org/resource/image/a5/b3/a55512d1a5bc219fac47c7b7f7652eb3.png?wh=1920x1068\" alt=\"图片\"></p><p>如果更进一步，你会觉得 binlog 里面本来就有数据，那么干嘛不直接用 binlog 里面的数据呢？所以就有了第二个形态：<strong>binlog 的数据被看作源表数据</strong>。</p><blockquote>\n<p>拿到 binlog 之后，我用主键去目标表查询数据，然后把 binlog 里面的内容和目标表的数据进行比较。如果数据不一致，再用 binlog 的主键去源表里面查询到数据，直接覆盖目标表的数据。</p>\n</blockquote><p><img src=\"https://static001.geekbang.org/resource/image/da/01/da5e3799cca5372d3218773464ba4e01.png?wh=1920x1068\" alt=\"图片\"></p><p>这里有一点不同，就是你发现不一样之后，需要查询源表，再用查询到的数据去覆盖目标表的数据，而不是直接用 binlog 的数据去覆盖目标表的数据。因为你要防止 binlog 是很古老的数据，而目标表是更加新的数据这种情况。</p><p>紧接着，你会发现目标表也有 binlog，所以干嘛不直接比较源表的 binlog 和目标表的 binlog？如果 binlog 不一样，那不就是说明目标表那边出了问题吗？</p><p>这种方案理论上是可行的，但是它有两个非常棘手的问题。</p><ol>\n<li>\n<p>一次双写，你可能立刻就收到了源表的 binlog，但是你过了好久才收到目标表的 binlog。反过来，先收到目标表的 binlog，隔了很久才收到源表的 binlog也一样。所以你需要缓存住一端的 binlog，再等待另外一端的 binlog。</p>\n</li>\n<li>\n<p>顺序问题，如果有两次双写操作的是同一行，那么你可能先收到源表第一次的 binlog，再收到目标表第二次双写的 binlog，你怎么解决这个问题呢？你只能考虑利用消息队列之类的东西给 binlog 排个序，确保 binlog 收到的顺序和产生的顺序一致。</p>\n</li>\n</ol><p>它虽然能够进一步减轻数据库查询的压力，但是实在过于复杂，得不偿失。所以不管是实践，还是面试，我都建议你不要使用这个方案。</p><h3>切换双写顺序</h3><p>这一步本身就是一个亮点。因为很多人都是在双写的时候直接切换到目标表单写。但是这样直接切换的风险太大了，万一出了问题都没法回滚。</p><p><img src=\"https://static001.geekbang.org/resource/image/ab/5d/abe7d3cf65906e6ffc3b0f566700b75d.png?wh=2240x1320\" alt=\"\"></p><p>所以中间要引入一个双写的时候先写目标表，且业务读目标表的步骤。这样万一切换到写目标表出了问题还可以回滚。也就是说，你有后悔药可以吃。</p><p>所以你可以考虑在介绍这一步的时候补充说明一下。</p><blockquote>\n<p>引入这一步，是为了能够在切换到以目标表为准之前，有一个过渡阶段。也就是说，通过先写目标表，再写源表这种方式，万一发现数据迁移出现了问题，还可以回滚为先写源表，再写目标表，确保业务没有问题。</p>\n</blockquote><p><img src=\"https://static001.geekbang.org/resource/image/26/c5/26555ec60ae4bdea9ca51d6c529910c5.png?wh=1920x1222\" alt=\"图片\"></p><h3>保持增量校验和修复</h3><p>在切换了双写顺序之后，保持增量校验和修复是顺理成章的，方案和步骤 5 一样。不过步骤 5 的校验和修复都是以源表为准，那么在这一步，就是以目标表为准。</p><p>我整理了一些能够帮助你进一步理解整个方案的要点。</p><ul>\n<li>不管什么先后顺序问题、什么并发问题，在修复的时候你永远用主表的最新数据去修复，绝对不会出问题。</li>\n<li>如果源表或者目标表本身也是分库分表的，那么无非就是查询、修复数据的时候使用对应的分库分表规则而已。</li>\n<li>整个方案在第八步之前，都是可以回滚的。但是一旦切换到第八步，就不可能回滚了。</li>\n</ul><h2>面试思路总结</h2><p>这节课我给你介绍了数据备份工具和影响到主键生成策略的<strong>innodb_autoinc_lock_mode参数</strong>，还给出了<strong>数据迁移的完整方案</strong>，你可以参考我给出的思维导图自己整理一下。</p><p>在讲这节课内容的时候，我想起了之前我在做简历辅导的时候，遇到过好几个同学他们的简历里面都涉及了数据迁移，然后我问他们数据迁移怎么做的，他们的答案都是停机迁移。但是你想，如果你是面试官，听到答案是停机迁移，你会觉得候选人实力不错吗？</p><p>不会的，所以实际上即便你真的是停机迁移，你也要回答不停机迁移的方案。至少你要在回答了停机迁移之后，提起你做过不停机迁移的方案，只是没有采用而已。在类似的场景下，虽然你的公司可能用的是低端解决方案，但你面试的时候一定要记得强调你了解高端方案或者曾经实施过高端方案，因为高端的东西才是拉开差距的地方。</p><p><img src=\"https://static001.geekbang.org/resource/image/ba/21/ba4ed5baf976bcffbf2ba73a62c5cf21.png?wh=1920x2307\" alt=\"图片\"></p><h2>思考题</h2><p>最后请你思考几个问题。</p><ul>\n<li>在方案第二步，我提到要先初始化一下目标表，那么如果直接把目标表做成源表的一个从库会出现什么问题呢？</li>\n<li>我在开启双写那里说过一个不可行的消息队列修复数据的方案，不可行的原因是难以确定受影响的行。那么我能不能在消息里面放源表执行的 SQL，然后在消费消息的时候，在目标表上执行相同的 SQL 呢？</li>\n</ul><p>你可以好好思考一下，欢迎你把思考后的结果分享到评论区，也欢迎你把这节课的内容分享给需要的朋友，邀他一起学习，我们下节课再见！</p>","neighbors":{"left":{"article_title":"14｜数据库事务：事务提交了，你的数据就一定不会丢吗？","id":675812},"right":{"article_title":"16｜分库分表主键生成：如何设计一个主键生成算法？","id":676793}},"comments":[{"had_liked":false,"id":378139,"user_name":"Johar","can_delete":false,"product_type":"c1","uid":1101969,"ip_address":"重庆","ucode":"834136A6F64CDC","user_header":"https://static001.geekbang.org/account/avatar/00/10/d0/91/89123507.jpg","comment_is_top":false,"comment_ctime":1689815322,"is_pvip":false,"replies":[{"id":137824,"content":"赞！\n而且第二个问题还要考虑数据覆盖的问题，所以不怎么适合。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1689953056,"ip_address":"广东","comment_id":378139,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"1.由于目标表没有数据需要全量同步源表数据，会占用源库的资源，可能影响性能，此外，在进行检验恢复数据时，需要切换目标表为主库，才能写目标表。\n2.可以，但是不好确认目标库数据是否已经入库，同时插入可能存在冲突，考虑这种情况，可以使用消息总线的延时队列，另外在双写目标库时使用insert into ignore进行写入。","like_count":5,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":623891,"discussion_content":"赞！\n而且第二个问题还要考虑数据覆盖的问题，所以不怎么适合。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1689953056,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3033755,"avatar":"","nickname":"汪广","note":"","ucode":"C274ECB4E02DEB","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":640904,"discussion_content":"update语句重复执行，语义可能改变，因为可能不带where条件：\nUpdate t1 set a=a+1;\n这条语句如果部分失败了，再次执行的话，就不是等价的了！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1711981435,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"湖南","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":378123,"user_name":"peter","can_delete":false,"product_type":"c1","uid":1058183,"ip_address":"北京","ucode":"261C3FC001DE2D","user_header":"https://static001.geekbang.org/account/avatar/00/10/25/87/f3a69d1b.jpg","comment_is_top":false,"comment_ctime":1689775242,"is_pvip":false,"replies":[{"id":137826,"content":"1. 你不需要关心截止点。你只需要在导入数据之后，找到每张表对应的最后更新时间，就可以认为是那个截止点。\n2. 严格做法就是逐行比对。有些公司会抽样比对，但是抽样比对我个人认为效果很差。比如说你一千万行数据，出错几率是万分之一，你抽样是百分之一，你发现错误的几率，也就是百分之一。就是执行时间会很长，我们之前逐行比对，有执行过好几天。\n3. 业务代码管理，MySQL 没有感知。\n4. 你可以拿到 last insert id。这是 mysql 协议规定的。但是你用的 ORM 框架可能屏蔽了，所以你需要找找。\n5. 感谢提醒，我们修复一下。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1689953351,"ip_address":"广东","comment_id":378123,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"请教老师几个问题：\nQ1：导出源表时，截止点怎么定？数据一直在写入，在哪一行停止导出？\nQ2：假设表中有一百万行数据，导出到目的表后，需要校验数据的正确性吗？ 怎么校验？逐行对比，而且每一行都对比每一列吗？\nQ3：标记位是业务代码中设置的吗？还是MySQL中设置的？\nQ4：Insert语句怎么拿到主键？Insert执行后返回0或1，表示插入是否成功，也没有返回主键啊。\nQ5：切换双写部分的第一个图，没有目标表，可能是个笔误。","like_count":3,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":623893,"discussion_content":"1. 你不需要关心截止点。你只需要在导入数据之后，找到每张表对应的最后更新时间，就可以认为是那个截止点。\n2. 严格做法就是逐行比对。有些公司会抽样比对，但是抽样比对我个人认为效果很差。比如说你一千万行数据，出错几率是万分之一，你抽样是百分之一，你发现错误的几率，也就是百分之一。就是执行时间会很长，我们之前逐行比对，有执行过好几天。\n3. 业务代码管理，MySQL 没有感知。\n4. 你可以拿到 last insert id。这是 mysql 协议规定的。但是你用的 ORM 框架可能屏蔽了，所以你需要找找。\n5. 感谢提醒，我们修复一下。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1689953351,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":389993,"user_name":"哆啦a喵","can_delete":false,"product_type":"c1","uid":3601364,"ip_address":"北京","ucode":"AE5E51BB43753D","user_header":"https://static001.geekbang.org/account/avatar/00/36/f3/d4/86a99ae0.jpg","comment_is_top":false,"comment_ctime":1714044649,"is_pvip":false,"replies":[{"id":141971,"content":"这个我就不懂了，你要找的话，要记住找辅导内容大于形式的。也就是如果辅导你怎么把简历排版好看一些这种就没必要，那种帮你挖掘项目亮点，教你话术的就有价值。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1715230403,"ip_address":"广东","comment_id":389993,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"顺便问问老师，哪里能找到做简历辅导的靠谱机构或者个人呀，比如老师您自己 = =","like_count":2,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":644391,"discussion_content":"这个我就不懂了，你要找的话，要记住找辅导内容大于形式的。也就是如果辅导你怎么把简历排版好看一些这种就没必要，那种帮你挖掘项目亮点，教你话术的就有价值。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1715230403,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":383105,"user_name":"jCodePorter","can_delete":false,"product_type":"c1","uid":1904645,"ip_address":"河南","ucode":"39F43B9A705543","user_header":"https://static001.geekbang.org/account/avatar/00/1d/10/05/af45721e.jpg","comment_is_top":false,"comment_ctime":1698417304,"is_pvip":false,"replies":[{"id":139757,"content":"以前的工作代码写过，但是开源的没有。\n有很多做法：\n1. 利用 spring 的 AOP，拦截数据库操作，而后引入双写步骤\n2. 利用连接池的扩展机制，把单写变成双写。比如说一般连接池都有类似于 Conn 的抽象，Conn 就会发起真的查询，那么你就可以扩展一个实现。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1699282916,"ip_address":"广东","comment_id":383105,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"老师有没有Java版本实现双写的案例参考","like_count":1,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":631072,"discussion_content":"以前的工作代码写过，但是开源的没有。\n有很多做法：\n1. 利用 spring 的 AOP，拦截数据库操作，而后引入双写步骤\n2. 利用连接池的扩展机制，把单写变成双写。比如说一般连接池都有类似于 Conn 的抽象，Conn 就会发起真的查询，那么你就可以扩展一个实现。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1699282916,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":382837,"user_name":"sheep","can_delete":false,"product_type":"c1","uid":2770150,"ip_address":"广东","ucode":"DAC2036F08CE27","user_header":"https://static001.geekbang.org/account/avatar/00/2a/44/e6/2c97171c.jpg","comment_is_top":false,"comment_ctime":1698111342,"is_pvip":false,"replies":[{"id":139767,"content":"赞！\n1. 要考虑的问题就是很多，主键冲突是一方面，还有就是主键过来一个 UPDATE，而我连初始数据都没有，就更加麻烦了。\n2. 嗯，要考虑覆盖数据，以及乱序的问题。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1699284277,"ip_address":"广东","comment_id":382837,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"回答课后问题：\n1. 初始化时目标表数据为空，作为源表的一个从库的话，同步过程中会占用源库的资源，影响性能。另外从库一般只提供读功能，此时要实现双写的话，就得把从库readonly=true关闭，另外此时支持从库支持写入后，从库同步应用主库过来的数据往往会有意想不到的问题（比如：主键冲突）\n2. 可以，但得考虑的消费SQL时候，可能找不到对应数据了","like_count":1,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":631083,"discussion_content":"赞！\n1. 要考虑的问题就是很多，主键冲突是一方面，还有就是主键过来一个 UPDATE，而我连初始数据都没有，就更加麻烦了。\n2. 嗯，要考虑覆盖数据，以及乱序的问题。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1699284277,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":382511,"user_name":"sheep","can_delete":false,"product_type":"c1","uid":2770150,"ip_address":"广东","ucode":"DAC2036F08CE27","user_header":"https://static001.geekbang.org/account/avatar/00/2a/44/e6/2c97171c.jpg","comment_is_top":false,"comment_ctime":1697506852,"is_pvip":false,"replies":[{"id":139350,"content":"1. 一直失败就确实得管，这种时候多半是代码有问题，比如说我们之前目标表的列类型变了，导致源表的数据读到程序里面，再存储的时候，就发现数据库类型-Go类型-数据库类型这个转换崩了，只能是打补丁。\n2. 因为当你收到消息的时候，原本 a= 123 的可能又被修改为 a = 124 了，所以你找不到。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1697724582,"ip_address":"广东","comment_id":382511,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"1. “数据一致性问题”这里，&quot;写入源表成功了，但是写入目标表失败了，该怎么办？那么最基础的回答就是不管&quot;。这里一两条的话，确实可以通过后面修复机制去完善。但是这里一直失败的话，也不管么\n2. &quot;数据一致性问题&quot;这里，&quot;UPDATE xxx WHERE a = 123&quot;什么情况下目标表会写入失败呢？另外为啥通过消息队列的处理方式没办法定位到源表的哪一行？不就是a = 123这一行么","like_count":1,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":629853,"discussion_content":"1. 一直失败就确实得管，这种时候多半是代码有问题，比如说我们之前目标表的列类型变了，导致源表的数据读到程序里面，再存储的时候，就发现数据库类型-Go类型-数据库类型这个转换崩了，只能是打补丁。\n2. 因为当你收到消息的时候，原本 a= 123 的可能又被修改为 a = 124 了，所以你找不到。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1697724582,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":378210,"user_name":"ZhiguoXue_IT","can_delete":false,"product_type":"c1","uid":2639055,"ip_address":"北京","ucode":"EAA83F53B54520","user_header":"https://static001.geekbang.org/account/avatar/00/28/44/cf/791d0f5e.jpg","comment_is_top":false,"comment_ctime":1689907395,"is_pvip":false,"replies":[{"id":137815,"content":"一般也没说十年……毕竟十年你早跑路了。从实用的角度来说，就是确保你扩容之后，在你待在这家公司的时间内不会出现扩容就行。\n\n有钱你就直接一步到位，按照国际大厂一次性扩到足够，永不扩容。\n\n不然你就看 2 倍，4 倍，8 倍...哪个合适挑一个就行。三年还是五年，并不重要。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1689952059,"ip_address":"广东","comment_id":378210,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"迁移数据的时候，新的分表分库的容量大小一般如何制定，是预估十年的存储量吗？作者这块有啥经验","like_count":1,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":623881,"discussion_content":"一般也没说十年……毕竟十年你早跑路了。从实用的角度来说，就是确保你扩容之后，在你待在这家公司的时间内不会出现扩容就行。\n\n有钱你就直接一步到位，按照国际大厂一次性扩到足够，永不扩容。\n\n不然你就看 2 倍，4 倍，8 倍...哪个合适挑一个就行。三年还是五年，并不重要。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1689952059,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":389991,"user_name":"哆啦a喵","can_delete":false,"product_type":"c1","uid":3601364,"ip_address":"北京","ucode":"AE5E51BB43753D","user_header":"https://static001.geekbang.org/account/avatar/00/36/f3/d4/86a99ae0.jpg","comment_is_top":false,"comment_ctime":1714043940,"is_pvip":false,"replies":[{"id":141972,"content":"我没理解？你是说用 Binlog 同步来取代双写吗？这种思路是可行的，但是要小心 binlog 的数据同步延迟。你在数据校验（全量或者增量）的时候都要考虑这一点。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1715230462,"ip_address":"广东","comment_id":389991,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"老师想问一下，“业务开启双写，以源表为准” 以及 “切换双写顺序” 的时候通过消费binlog同步，这种方案会有问题么？结合上一节课的内容，只要binlog保证能消费到，应该是ok的？但是感觉会把系统变得更复杂？","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":644392,"discussion_content":"我没理解？你是说用 Binlog 同步来取代双写吗？这种思路是可行的，但是要小心 binlog 的数据同步延迟。你在数据校验（全量或者增量）的时候都要考虑这一点。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1715230462,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":389916,"user_name":"Z.","can_delete":false,"product_type":"c1","uid":1568589,"ip_address":"北京","ucode":"9C9C97C470D761","user_header":"https://static001.geekbang.org/account/avatar/00/17/ef/4d/83a56dad.jpg","comment_is_top":false,"comment_ctime":1713880274,"is_pvip":false,"replies":[{"id":141975,"content":"你可以在新增数据的时候，将更新时间设置为创建时间。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1715230636,"ip_address":"广东","comment_id":389916,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"我有一个疑惑的点，增量校验的时候，如果出现异常的数据是一条新增的数据，那如果使用更新时间戳的话，一般新增的数据是没有更新时间戳的，那我应该怎么解决这个问题","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":644395,"discussion_content":"你可以在新增数据的时候，将更新时间设置为创建时间。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1715230636,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":387686,"user_name":"nadream","can_delete":false,"product_type":"c1","uid":1337149,"ip_address":"浙江","ucode":"B907871D6414FC","user_header":"https://static001.geekbang.org/account/avatar/00/14/67/3d/71031021.jpg","comment_is_top":false,"comment_ctime":1708422069,"is_pvip":false,"replies":[{"id":141347,"content":"好问题。第一次校验与修复，你随便跑一下就可以，后面还要持续运行增量校验，也可以设置增量校验的起始时间从你第一次校验跑完之后的时间点之后开始进行。\n\n后续要是觉得不保险你就可以运行全量校验或者增量校验。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1709715240,"ip_address":"广东","comment_id":387686,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"什么时候停止第一次校验与修复？是在开启双写前吗？那停止第一次校验与修复步骤与开启双写步骤会不会存在时间差，导致这段时间内的数据丢失。","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":638596,"discussion_content":"好问题。第一次校验与修复，你随便跑一下就可以，后面还要持续运行增量校验，也可以设置增量校验的起始时间从你第一次校验跑完之后的时间点之后开始进行。\n\n后续要是觉得不保险你就可以运行全量校验或者增量校验。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1709715240,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":386855,"user_name":"nadream","can_delete":false,"product_type":"c1","uid":1337149,"ip_address":"浙江","ucode":"B907871D6414FC","user_header":"https://static001.geekbang.org/account/avatar/00/14/67/3d/71031021.jpg","comment_is_top":false,"comment_ctime":1705720948,"is_pvip":false,"replies":[{"id":141051,"content":"只能追求最终一致性。也就是说，源表对应多个目标表，如果目标表在不同的数据库上（你没有办法用本地事务），那么就做好监控、告警以及数据校验和修复。实际上，它只是放大了不一致的风险。写单表还是写多表，监控、告警和数据校验与修复都少不了。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1705926928,"ip_address":"广东","comment_id":386855,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100551601,"comment_content":"双写的时候，一个源表可能对应多个目标表，该怎么处理呢？","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":636297,"discussion_content":"只能追求最终一致性。也就是说，源表对应多个目标表，如果目标表在不同的数据库上（你没有办法用本地事务），那么就做好监控、告警以及数据校验和修复。实际上，它只是放大了不一致的风险。写单表还是写多表，监控、告警和数据校验与修复都少不了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1705926928,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":386854,"user_name":"nadream","can_delete":false,"product_type":"c1","uid":1337149,"ip_address":"浙江","ucode":"B907871D6414FC","user_header":"https://static001.geekbang.org/account/avatar/00/14/67/3d/71031021.jpg","comment_is_top":false,"comment_ctime":1705719797,"is_pvip":false,"replies":[{"id":141050,"content":"我给训练营上课写的一个，你可以参考。https:&#47;&#47;gitee.com&#47;geektime-geekbang_admin&#47;geektime-basic-go&#47;blob&#47;master&#47;webook&#47;pkg&#47;gormx&#47;connpool&#47;doublewrite.go","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1705926858,"ip_address":"广东","comment_id":386854,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100551601,"comment_content":"GORM ConnPool 替换这块有详细代码吗？看的不是很明白","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":636296,"discussion_content":"我给训练营上课写的一个，你可以参考。https://gitee.com/geektime-geekbang_admin/geektime-basic-go/blob/master/webook/pkg/gormx/connpool/doublewrite.go","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1705926858,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":386188,"user_name":"Geek_6c2524","can_delete":false,"product_type":"c1","uid":2225632,"ip_address":"上海","ucode":"148788C1DA6D0C","user_header":"","comment_is_top":false,"comment_ctime":1704282250,"is_pvip":false,"replies":[{"id":141062,"content":"一般来说，在运行增量校验和修复一段时间之后，发现系统运行很平稳，就可以切换了。实际上这个过程也没想的那么高危，毕竟你可以再切换回来。实在不放心，就挑个半夜凌晨切换。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1705927816,"ip_address":"广东","comment_id":386188,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100551601,"comment_content":"老师，想请教下，切换写入流程的时间节点是什么时候？比如，双写开始多久之后从——读写源表+写目标表，切换到读写目标表+写源表；多久之后，系统从双写切换到最终的单写到新目标表里？","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":636309,"discussion_content":"一般来说，在运行增量校验和修复一段时间之后，发现系统运行很平稳，就可以切换了。实际上这个过程也没想的那么高危，毕竟你可以再切换回来。实在不放心，就挑个半夜凌晨切换。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1705927816,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":385197,"user_name":"Geek_3d0fe8","can_delete":false,"product_type":"c1","uid":3794407,"ip_address":"广东","ucode":"E75EACDA00E7A6","user_header":"","comment_is_top":false,"comment_ctime":1702281087,"is_pvip":false,"replies":[{"id":140763,"content":"其实你这就是用户粒度上的控制而已。也就是，每一个用户都可以单独控制，本质上没区别的。\n\n我个人认为，没太大必要。在经过双写以目标表为准的阶段之后，直接切也没问题。\n\n用户维度的控制，对于数据校验来说，很难搞，你得明确知道用源表数据，还是用目标表数据来校验和修复。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1704189856,"ip_address":"广东","comment_id":385197,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100551601,"comment_content":"一下子切换到新系统太粗暴了，我们之前的做法是每个用户都打上状态的标记，决定读写走哪个系统","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":634922,"discussion_content":"其实你这就是用户粒度上的控制而已。也就是，每一个用户都可以单独控制，本质上没区别的。\n\n我个人认为，没太大必要。在经过双写以目标表为准的阶段之后，直接切也没问题。\n\n用户维度的控制，对于数据校验来说，很难搞，你得明确知道用源表数据，还是用目标表数据来校验和修复。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1704189856,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":382056,"user_name":"木木夕","can_delete":false,"product_type":"c1","uid":1526471,"ip_address":"广东","ucode":"EA5D709D0DE50E","user_header":"https://static001.geekbang.org/account/avatar/00/17/4a/c7/0cff4a59.jpg","comment_is_top":false,"comment_ctime":1696620112,"is_pvip":false,"replies":[{"id":139221,"content":"差不多，但是要复杂一些。因为数据校验和修复的过程，都涉及到了分库分表。\n\n举个例子，你从源库读到一条数据，迁移到目标库，就得自己写代码查询出来，执行分库分表规则，确定目标表，然后写进去。\n\n修复的时候也是这样。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1696922780,"ip_address":"广东","comment_id":382056,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100551601,"comment_content":"比如原数据是不分库分表的，要前迁移到分库分表后目标数据库，也是按照你这个步骤迁移？","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":629289,"discussion_content":"差不多，但是要复杂一些。因为数据校验和修复的过程，都涉及到了分库分表。\n\n举个例子，你从源库读到一条数据，迁移到目标库，就得自己写代码查询出来，执行分库分表规则，确定目标表，然后写进去。\n\n修复的时候也是这样。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1696922780,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":380787,"user_name":"浩仔是程序员","can_delete":false,"product_type":"c1","uid":1104601,"ip_address":"广东","ucode":"A7E5CF9E1571A2","user_header":"https://static001.geekbang.org/account/avatar/00/10/da/d9/f051962f.jpg","comment_is_top":false,"comment_ctime":1694155022,"is_pvip":false,"replies":[{"id":138627,"content":"做过，确实比较难。基本上当时的思路就是，以 A 表为准。从 A 表中循环查询数据，根据 A 表的每一条，再去查询 B 表，C 表之类的，然后迁移过去新 A 表。\n\n这个过程会有更加严重的不一致性问题，要做好检测和修复工具。检测代码和修复代码也更加复杂=。=","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1694182029,"ip_address":"广东","comment_id":380787,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100551601,"comment_content":"老师，有没有过多个表聚合到同一张表的数据迁移数据，比如一个用户的信息，之前的数据比较分散，需要连表查询，聚合在一起方便管理和查询","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":627477,"discussion_content":"做过，确实比较难。基本上当时的思路就是，以 A 表为准。从 A 表中循环查询数据，根据 A 表的每一条，再去查询 B 表，C 表之类的，然后迁移过去新 A 表。\n\n这个过程会有更加严重的不一致性问题，要做好检测和修复工具。检测代码和修复代码也更加复杂=。=","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1694182029,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":380233,"user_name":"Geek_0e1759","can_delete":false,"product_type":"c1","uid":3640912,"ip_address":"浙江","ucode":"F7042D9911FCEE","user_header":"","comment_is_top":false,"comment_ctime":1693236582,"is_pvip":false,"replies":[{"id":138547,"content":"不会，举个例子，假如说你用源表的老数据覆盖了目标表的新数据，那么很快又会发现数据不一致。这时候会再次出发修复，你会用源表的新数据覆盖了目标表的老数据。\n\n当然，如果你有 update_time 这种字段，你可以说覆盖只会覆盖时间点更早的数据，","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1693489188,"ip_address":"广东","comment_id":380233,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100551601,"comment_content":"老师，我想问一下，在增量校验和数据修复过程中，会不会跟正常的业务读写产生覆盖的问题发生","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":626929,"discussion_content":"不会，举个例子，假如说你用源表的老数据覆盖了目标表的新数据，那么很快又会发现数据不一致。这时候会再次出发修复，你会用源表的新数据覆盖了目标表的老数据。\n\n当然，如果你有 update_time 这种字段，你可以说覆盖只会覆盖时间点更早的数据，","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1693489188,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":378855,"user_name":"卖藥郎","can_delete":false,"product_type":"c1","uid":1231829,"ip_address":"北京","ucode":"0539EF1D335918","user_header":"https://static001.geekbang.org/account/avatar/00/12/cb/d5/fab32cf7.jpg","comment_is_top":false,"comment_ctime":1690883325,"is_pvip":false,"replies":[{"id":138079,"content":"咔嚓一下就直接切换了。如果你切换后也保持双写，就是以源为准切换到以目标为准，那么事务并不会失败。但是如果你是切换到单写，那么事务就会失败。\n写目标库异步不是不行，就是小心点写入失败以及并发问题就可以。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1691048320,"ip_address":"广东","comment_id":378855,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100551601,"comment_content":"老师 在切换读写顺序的时候 是一下子就切换吗？正在进行的事务怎么办，需要暂时停写吗？还有写目标库可不可以异步","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":624905,"discussion_content":"咔嚓一下就直接切换了。如果你切换后也保持双写，就是以源为准切换到以目标为准，那么事务并不会失败。但是如果你是切换到单写，那么事务就会失败。\n写目标库异步不是不行，就是小心点写入失败以及并发问题就可以。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1691048321,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":378851,"user_name":"卖藥郎","can_delete":false,"product_type":"c1","uid":1231829,"ip_address":"北京","ucode":"0539EF1D335918","user_header":"https://static001.geekbang.org/account/avatar/00/12/cb/d5/fab32cf7.jpg","comment_is_top":false,"comment_ctime":1690879425,"is_pvip":false,"replies":[{"id":138044,"content":"什么？","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1690890023,"ip_address":"广东","comment_id":378851,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100551601,"comment_content":"老师 课后题什么时候整理一波\n","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":624744,"discussion_content":"什么？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1690890023,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":378847,"user_name":"卖藥郎","can_delete":false,"product_type":"c1","uid":1231829,"ip_address":"北京","ucode":"0539EF1D335918","user_header":"https://static001.geekbang.org/account/avatar/00/12/cb/d5/fab32cf7.jpg","comment_is_top":false,"comment_ctime":1690878635,"is_pvip":false,"replies":[{"id":138043,"content":"增删改就会有 binlog，也就是会触发你校验数据。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1690890012,"ip_address":"广东","comment_id":378847,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100551601,"comment_content":"老师 binlog 触发 何时触发呀","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":624743,"discussion_content":"增删改就会有 binlog，也就是会触发你校验数据。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1690890012,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":378612,"user_name":"陆美芳","can_delete":false,"product_type":"c1","uid":2084000,"ip_address":"广东","ucode":"8C3F5FB3A8B3DA","user_header":"https://static001.geekbang.org/account/avatar/00/1f/cc/a0/bd31d495.jpg","comment_is_top":false,"comment_ctime":1690503134,"is_pvip":false,"replies":[{"id":137983,"content":"好家伙，这个问题我没遇到过。要去看看 xtrabackup 里面有没有一些配置可以解决这个问题，据我了解，好像没有=。=","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1690605889,"ip_address":"广东","comment_id":378612,"utype":1}],"discussion_count":1,"race_medal":0,"score":4,"product_id":100551601,"comment_content":"我想问一下老师，xtrabackup备份迁移，如果恢复的时候my.cnf数据目录改了，行不行？我现在就是目录不一样了，因为新服务器分区目录不一样，启动时报错，错误日志里面有问是不是改了目录，在想是不是得重做系统？","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":624482,"discussion_content":"好家伙，这个问题我没遇到过。要去看看 xtrabackup 里面有没有一些配置可以解决这个问题，据我了解，好像没有=。=","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1690605889,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":378418,"user_name":"humor","can_delete":false,"product_type":"c1","uid":1181867,"ip_address":"浙江","ucode":"9B48C4C7BEC92C","user_header":"https://static001.geekbang.org/account/avatar/00/12/08/ab/caec7bca.jpg","comment_is_top":false,"comment_ctime":1690204179,"is_pvip":false,"replies":[{"id":137903,"content":"是的，INSERT SELECT MySQL 是在需要的过程中就去申请主键，用完再拿，而不是一次性拿到。所以会出现拿到的 ID 不是连续的问题。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1690259044,"ip_address":"广东","comment_id":378418,"utype":1}],"discussion_count":1,"race_medal":0,"score":4,"product_id":100551601,"comment_content":"当innodb_autoinc_lock_mode等于2时，mysql怎么处理insert select这种情况呢？这种语句是要执行完才能知道需要多少个主键的吧","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":624149,"discussion_content":"是的，INSERT SELECT MySQL 是在需要的过程中就去申请主键，用完再拿，而不是一次性拿到。所以会出现拿到的 ID 不是连续的问题。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1690259044,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":378389,"user_name":"3.0的A7","can_delete":false,"product_type":"c1","uid":1211991,"ip_address":"北京","ucode":"23C5F02B45CE39","user_header":"https://static001.geekbang.org/account/avatar/00/12/7e/57/8c1051b6.jpg","comment_is_top":false,"comment_ctime":1690172004,"is_pvip":false,"replies":[{"id":137906,"content":"如果原本是集群分片部署的话，是不是要换分库分表规则？这种情况下，你只能考虑自己一条条迁移了。之前我们解决一个业务分库分表扩容就是一条条数据读出来，然后按照新的分库分表规则插入到新的分片里面。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1690259282,"ip_address":"广东","comment_id":378389,"utype":1}],"discussion_count":1,"race_medal":0,"score":4,"product_id":100551601,"comment_content":"mysqldump ，如果原表是集群分片部署的，就不太行了呀","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":624152,"discussion_content":"如果原本是集群分片部署的话，是不是要换分库分表规则？这种情况下，你只能考虑自己一条条迁移了。之前我们解决一个业务分库分表扩容就是一条条数据读出来，然后按照新的分库分表规则插入到新的分片里面。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1690259282,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":378359,"user_name":"陈斌","can_delete":false,"product_type":"c1","uid":1367048,"ip_address":"广东","ucode":"B639AB5F6AA03D","user_header":"https://static001.geekbang.org/account/avatar/00/14/dc/08/64f5ab52.jpg","comment_is_top":false,"comment_ctime":1690137677,"is_pvip":false,"replies":[{"id":137910,"content":"大概率不可以。因为一般表结构变化引起业务逻辑变化，都会导致你插入、更新或者删除的行为和业务强耦合。这种情况下只能是在业务里面修改。但是你可以考虑抽象一个业务接口（最好是限制到 DAO 接口），然后提供老表和新表的两种实现，这样来控制双写。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1690259848,"ip_address":"广东","comment_id":378359,"utype":1}],"discussion_count":1,"race_medal":0,"score":4,"product_id":100551601,"comment_content":"重构之后表结构改变了，表结构变化蛮大的，业务逻辑也简化了一些，这种场景能做到使用非侵入方案做到双写吗？","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":624157,"discussion_content":"大概率不可以。因为一般表结构变化引起业务逻辑变化，都会导致你插入、更新或者删除的行为和业务强耦合。这种情况下只能是在业务里面修改。但是你可以考虑抽象一个业务接口（最好是限制到 DAO 接口），然后提供老表和新表的两种实现，这样来控制双写。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1690259848,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":378269,"user_name":"ZhiguoXue_IT","can_delete":false,"product_type":"c1","uid":2639055,"ip_address":"山西","ucode":"EAA83F53B54520","user_header":"https://static001.geekbang.org/account/avatar/00/28/44/cf/791d0f5e.jpg","comment_is_top":false,"comment_ctime":1689991850,"is_pvip":false,"replies":[{"id":137865,"content":"1. 扩容其实正常来说，就是 2 倍、4 倍、8 倍这样扩容。所以你综合考察你的业务数据量，增长趋势，来确定多大的容量。\n2. 你说的是一些实现。比如说 Redis 和 Go 的 map 都不是这种形态，它们是渐进式扩容。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1690109114,"ip_address":"广东","comment_id":378269,"utype":1}],"discussion_count":1,"race_medal":0,"score":4,"product_id":100551601,"comment_content":"1）比如12个库，每个库有12张表，此时业务量增长，当前的数据库已经快不够了，扩容的时候，要扩容的大小有什么策略吗？\n2）hashmap当数据量达到临界值的时候，此时会进行扩容两倍，然后进行全量迁移，然后在进行查询新的数据，从这样理解上，hashmap的扩容是不是一种停机迁移","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":624000,"discussion_content":"1. 扩容其实正常来说，就是 2 倍、4 倍、8 倍这样扩容。所以你综合考察你的业务数据量，增长趋势，来确定多大的容量。\n2. 你说的是一些实现。比如说 Redis 和 Go 的 map 都不是这种形态，它们是渐进式扩容。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1690109114,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":394325,"user_name":"彭俊","can_delete":false,"product_type":"c1","uid":1054541,"ip_address":"广东","ucode":"FBEDBCCF22F1D0","user_header":"https://static001.geekbang.org/account/avatar/00/10/17/4d/7e13ec93.jpg","comment_is_top":false,"comment_ctime":1726489924,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100551601,"comment_content":"请教老师几个问题：\n关于利用binlog校验和修复的数据，\n1. 有办法直接通过go语言获取binlog吗？\n2. 我目前已知的是，通过canal伪装成从库接收binlog。如果用这个方案，会有以下问题：1. 比起update_time方案，这个方案重很多。2. 引入新的中间件，考虑这个中间件的可用性和维护成本。老师是怎么看这两个缺点的。","like_count":0},{"had_liked":false,"id":394228,"user_name":"Geek_175c29","can_delete":false,"product_type":"c1","uid":2571871,"ip_address":"湖北","ucode":"3FEAA79F93CFC0","user_header":"","comment_is_top":false,"comment_ctime":1726160203,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100551601,"comment_content":"一次双写，你可能立刻就收到了源表的 binlog，但是你过了好久才收到目标表的 binlog。这样会有什么问题吗。没看懂","like_count":0},{"had_liked":false,"id":393978,"user_name":"JasonZhi","can_delete":false,"product_type":"c1","uid":1282818,"ip_address":"广东","ucode":"6C23DCD592636D","user_header":"https://static001.geekbang.org/account/avatar/00/13/93/02/fcab58d1.jpg","comment_is_top":false,"comment_ctime":1725478546,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100551601,"comment_content":"请教一下老师；旧表一直处于高频写入的状态，然后双写切换为新表作为主导；但是此时新表依然是落后于旧表的进度；开始增量校验修复后，旧表较新的数据反而被新表所覆盖；","like_count":0},{"had_liked":false,"id":392609,"user_name":"Haapy","can_delete":false,"product_type":"c1","uid":3890297,"ip_address":"北京","ucode":"214B78A9DD9BC4","user_header":"https://static001.geekbang.org/account/avatar/00/3b/5c/79/efa0f16f.jpg","comment_is_top":false,"comment_ctime":1721292889,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":4,"product_id":100551601,"comment_content":"老师，增量校验和修复那一小节的binlog方案有疑问，就是如果我双写用的是aop，利用binlog监听源表，那是不是在写目标表之前，binlog就监听到源表发生改变而触发校验和修复操作了，那这校验和修复感觉没意义啊","like_count":0}]}