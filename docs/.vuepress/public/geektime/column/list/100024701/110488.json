{"id":110488,"title":"52 | 计算虚拟化之内存：如何建立独立的办公室？","content":"<p>上一节，我们解析了计算虚拟化之CPU。可以看到，CPU的虚拟化是用户态的qemu和内核态的KVM共同配合完成的。它们二者通过ioctl进行通信。对于内存管理来讲，也是需要这两者配合完成的。</p><p>咱们在内存管理的时候讲过，操作系统给每个进程分配的内存都是虚拟内存，需要通过页表映射，变成物理内存进行访问。当有了虚拟机之后，情况会变得更加复杂。因为虚拟机对于物理机来讲是一个进程，但是虚拟机里面也有内核，也有虚拟机里面跑的进程。所以有了虚拟机，内存就变成了四类：</p><ul>\n<li><strong>虚拟机里面的虚拟内存</strong>（Guest OS Virtual Memory，GVA），这是虚拟机里面的进程看到的内存空间；</li>\n<li><strong>虚拟机里面的物理内存</strong>（Guest OS Physical Memory，GPA），这是虚拟机里面的操作系统看到的内存，它认为这是物理内存；</li>\n<li><strong>物理机的虚拟内存</strong>（Host Virtual Memory，HVA），这是物理机上的qemu进程看到的内存空间；</li>\n<li><strong>物理机的物理内存</strong>（Host Physical Memory，HPA），这是物理机上的操作系统看到的内存。</li>\n</ul><p>咱们内存管理那一章讲的两大内容，一个是内存管理，它变得非常复杂；另一个是内存映射，具体来说就是，从GVA到GPA，到HVA，再到HPA，这样几经转手，计算机的性能就会变得很差。当然，虚拟化技术成熟的今天，有了一些优化的手段，具体怎么优化呢？我们这一节就来一一解析。</p><!-- [[[read_end]]] --><h2>内存管理</h2><p>我们先来看内存管理的部分。</p><p>由于CPU和内存是紧密结合的，因而内存虚拟化的初始化过程，和CPU虚拟化的初始化是一起完成的。</p><p>上一节说CPU虚拟化初始化的时候，我们会调用kvm_init函数，这里面打开了\"/dev/kvm\"这个字符文件，并且通过ioctl调用到内核kvm的KVM_CREATE_VM操作，除了这些CPU相关的调用，接下来还有内存相关的。我们来看看。</p><pre><code>static int kvm_init(MachineState *ms)\n{\n    MachineClass *mc = MACHINE_GET_CLASS(ms);\n......\n    kvm_memory_listener_register(s, &amp;s-&gt;memory_listener,\n                                 &amp;address_space_memory, 0);\n    memory_listener_register(&amp;kvm_io_listener,\n                             &amp;address_space_io);\n......\n}\n\nAddressSpace address_space_io;\nAddressSpace address_space_memory;\n</code></pre><p>这里面有两个地址空间AddressSpace，一个是系统内存的地址空间address_space_memory，一个用于I/O的地址空间address_space_io。这里我们重点看address_space_memory。</p><pre><code>struct AddressSpace {\n    /* All fields are private. */\n    struct rcu_head rcu;\n    char *name;\n    MemoryRegion *root;\n\n    /* Accessed via RCU.  */\n    struct FlatView *current_map;\n\n    int ioeventfd_nb;\n    struct MemoryRegionIoeventfd *ioeventfds;\n    QTAILQ_HEAD(, MemoryListener) listeners;\n    QTAILQ_ENTRY(AddressSpace) address_spaces_link;\n};\n</code></pre><p>对于一个地址空间，会有多个内存区域MemoryRegion组成树形结构。这里面，root是这棵树的根。另外，还有一个MemoryListener链表，当内存区域发生变化的时候，需要做一些动作，使得用户态和内核态能够协同，就是由这些MemoryListener完成的。</p><p>在kvm_init这个时候，还没有内存区域加入进来，root还是空的，但是我们可以先注册MemoryListener，这里注册的是KVMMemoryListener。</p><pre><code>void kvm_memory_listener_register(KVMState *s, KVMMemoryListener *kml,\n                                  AddressSpace *as, int as_id)\n{\n    int i;\n\n    kml-&gt;slots = g_malloc0(s-&gt;nr_slots * sizeof(KVMSlot));\n    kml-&gt;as_id = as_id;\n\n    for (i = 0; i &lt; s-&gt;nr_slots; i++) {\n        kml-&gt;slots[i].slot = i;\n    }\n\n    kml-&gt;listener.region_add = kvm_region_add;\n    kml-&gt;listener.region_del = kvm_region_del;\n    kml-&gt;listener.priority = 10;\n\n    memory_listener_register(&amp;kml-&gt;listener, as);\n}\n</code></pre><p>在这个KVMMemoryListener中是这样配置的：当添加一个MemoryRegion的时候，region_add会被调用，这个我们后面会用到。</p><p>接下来，在qemu启动的main函数中，我们会调用cpu_exec_init_all-&gt;memory_map_init.</p><pre><code>static void memory_map_init(void)\n{\n    system_memory = g_malloc(sizeof(*system_memory));\n\n    memory_region_init(system_memory, NULL, &quot;system&quot;, UINT64_MAX);\n    address_space_init(&amp;address_space_memory, system_memory, &quot;memory&quot;);\n\n    system_io = g_malloc(sizeof(*system_io));\n    memory_region_init_io(system_io, NULL, &amp;unassigned_io_ops, NULL, &quot;io&quot;,\n                          65536);\n    address_space_init(&amp;address_space_io, system_io, &quot;I/O&quot;);\n}\n</code></pre><p>在这里，对于系统内存区域system_memory和用于I/O的内存区域system_io，我们都进行了初始化，并且关联到了相应的地址空间AddressSpace。</p><pre><code>void address_space_init(AddressSpace *as, MemoryRegion *root, const char *name)\n{\n    memory_region_ref(root);\n    as-&gt;root = root;\n    as-&gt;current_map = NULL;\n    as-&gt;ioeventfd_nb = 0;\n    as-&gt;ioeventfds = NULL;\n    QTAILQ_INIT(&amp;as-&gt;listeners);\n    QTAILQ_INSERT_TAIL(&amp;address_spaces, as, address_spaces_link);\n    as-&gt;name = g_strdup(name ? name : &quot;anonymous&quot;);\n    address_space_update_topology(as);\n    address_space_update_ioeventfds(as);\n}\n</code></pre><p>对于系统内存地址空间address_space_memory，我们需要把它里面内存区域的根root设置为system_memory。</p><p>另外，在这里，我们还调用了address_space_update_topology。</p><pre><code>static void address_space_update_topology(AddressSpace *as)\n{\n    MemoryRegion *physmr = memory_region_get_flatview_root(as-&gt;root);\n\n    flatviews_init();\n    if (!g_hash_table_lookup(flat_views, physmr)) {\n        generate_memory_topology(physmr);\n    }\n    address_space_set_flatview(as);\n}\n\nstatic void address_space_set_flatview(AddressSpace *as)\n{\n    FlatView *old_view = address_space_to_flatview(as);\n    MemoryRegion *physmr = memory_region_get_flatview_root(as-&gt;root);\n    FlatView *new_view = g_hash_table_lookup(flat_views, physmr);\n\n    if (old_view == new_view) {\n        return;\n    }\n......\n    if (!QTAILQ_EMPTY(&amp;as-&gt;listeners)) {\n        FlatView tmpview = { .nr = 0 }, *old_view2 = old_view;\n\n        if (!old_view2) {\n            old_view2 = &amp;tmpview;\n        }\n        address_space_update_topology_pass(as, old_view2, new_view, false);\n        address_space_update_topology_pass(as, old_view2, new_view, true);\n    }\n\n    /* Writes are protected by the BQL.  */\n    atomic_rcu_set(&amp;as-&gt;current_map, new_view);\n......\n}\n</code></pre><p>这里面会生成AddressSpace的flatview。flatview是什么意思呢？</p><p>我们可以看到，在AddressSpace里面，除了树形结构的MemoryRegion之外，还有一个flatview结构，其实这个结构就是把这样一个树形的内存结构变成平的内存结构。因为树形内存结构比较容易管理，但是平的内存结构，比较方便和内核里面通信，来请求物理内存。虽然操作系统内核里面也是用树形结构来表示内存区域的，但是用户态向内核申请内存的时候，会按照平的、连续的模式进行申请。这里，qemu在用户态，所以要做这样一个转换。</p><p>在address_space_set_flatview中，我们将老的flatview和新的flatview进行比较。如果不同，说明内存结构发生了变化，会调用address_space_update_topology_pass-&gt;MEMORY_LISTENER_UPDATE_REGION-&gt;MEMORY_LISTENER_CALL。</p><p>这里面调用所有的listener。但是，这个逻辑这里不会执行的。这是因为这里内存处于初始化的阶段，全局的flat_views里面肯定找不到。因而generate_memory_topology第一次生成了FlatView，然后才调用了address_space_set_flatview。这里面，老的flatview和新的flatview一定是一样的。</p><p>但是，请你记住这个逻辑，到这里我们还没解析qemu有关内存的参数，所以这里添加的MemoryRegion虽然是一个根，但是是空的，是为了管理使用的，后面真的添加内存的时候，这个逻辑还会调用到。</p><p>我们再回到qemu启动的main函数中。接下来的初始化过程会调用pc_init1。在这里面，对于CPU虚拟化，我们会调用pc_cpus_init。这个我们在上一节已经讲过了。另外，pc_init1还会调用pc_memory_init，进行内存的虚拟化，我们这里解析这一部分。</p><pre><code>void pc_memory_init(PCMachineState *pcms,\n                    MemoryRegion *system_memory,\n                    MemoryRegion *rom_memory,\n                    MemoryRegion **ram_memory)\n{\n    int linux_boot, i;\n    MemoryRegion *ram, *option_rom_mr;\n    MemoryRegion *ram_below_4g, *ram_above_4g;\n    FWCfgState *fw_cfg;\n    MachineState *machine = MACHINE(pcms);\n    PCMachineClass *pcmc = PC_MACHINE_GET_CLASS(pcms);\n......\n    /* Allocate RAM.  We allocate it as a single memory region and use\n     * aliases to address portions of it, mostly for backwards compatibility with older qemus that used qemu_ram_alloc().\n     */\n    ram = g_malloc(sizeof(*ram));\n    memory_region_allocate_system_memory(ram, NULL, &quot;pc.ram&quot;,\n                                         machine-&gt;ram_size);\n    *ram_memory = ram;\n    ram_below_4g = g_malloc(sizeof(*ram_below_4g));\n    memory_region_init_alias(ram_below_4g, NULL, &quot;ram-below-4g&quot;, ram,\n                             0, pcms-&gt;below_4g_mem_size);\n    memory_region_add_subregion(system_memory, 0, ram_below_4g);\n    e820_add_entry(0, pcms-&gt;below_4g_mem_size, E820_RAM);\n    if (pcms-&gt;above_4g_mem_size &gt; 0) {\n        ram_above_4g = g_malloc(sizeof(*ram_above_4g));\n        memory_region_init_alias(ram_above_4g, NULL, &quot;ram-above-4g&quot;, ram, pcms-&gt;below_4g_mem_size, pcms-&gt;above_4g_mem_size);\n        memory_region_add_subregion(system_memory, 0x100000000ULL,\n                                    ram_above_4g);\n        e820_add_entry(0x100000000ULL, pcms-&gt;above_4g_mem_size, E820_RAM);\n    }\n......\n}\n</code></pre><p>在pc_memory_init中，我们已经知道了虚拟机要申请的内存ram_size，于是通过memory_region_allocate_system_memory来申请内存。</p><p>接下来的调用链为：memory_region_allocate_system_memory-&gt;allocate_system_memory_nonnuma-&gt;memory_region_init_ram_nomigrate-&gt;memory_region_init_ram_shared_nomigrate。</p><pre><code>void memory_region_init_ram_shared_nomigrate(MemoryRegion *mr,\n                                             Object *owner,\n                                             const char *name,\n                                             uint64_t size,\n                                             bool share,\n                                             Error **errp)\n{\n    Error *err = NULL;\n    memory_region_init(mr, owner, name, size);\n    mr-&gt;ram = true;\n    mr-&gt;terminates = true;\n    mr-&gt;destructor = memory_region_destructor_ram;\n    mr-&gt;ram_block = qemu_ram_alloc(size, share, mr, &amp;err);\n......\n}\n\nstatic\nRAMBlock *qemu_ram_alloc_internal(ram_addr_t size, ram_addr_t max_size, void (*resized)(const char*,uint64_t length,void *host),void *host, bool resizeable, bool share,MemoryRegion *mr, Error **errp)\n{\n    RAMBlock *new_block;\n    size = HOST_PAGE_ALIGN(size);\n    max_size = HOST_PAGE_ALIGN(max_size);\n    new_block = g_malloc0(sizeof(*new_block));\n    new_block-&gt;mr = mr;\n    new_block-&gt;resized = resized;\n    new_block-&gt;used_length = size;\n    new_block-&gt;max_length = max_size;\n    new_block-&gt;fd = -1;\n    new_block-&gt;page_size = getpagesize();\n    new_block-&gt;host = host;\n......\n    ram_block_add(new_block, &amp;local_err, share);\n    return new_block;\n}\n\nstatic void ram_block_add(RAMBlock *new_block, Error **errp, bool shared)\n{\n    RAMBlock *block;\n    RAMBlock *last_block = NULL;\n    ram_addr_t old_ram_size, new_ram_size;\n    Error *err = NULL;\n    old_ram_size = last_ram_page();\n    new_block-&gt;offset = find_ram_offset(new_block-&gt;max_length);\n    if (!new_block-&gt;host) {\n        new_block-&gt;host = phys_mem_alloc(new_block-&gt;max_length, &amp;new_block-&gt;mr-&gt;align, shared);\n......\n        }\n    }\n......\n}\n</code></pre><p>这里面，我们会调用qemu_ram_alloc，创建一个RAMBlock用来表示内存块。这里面调用ram_block_add-&gt;phys_mem_alloc。phys_mem_alloc是一个函数指针，指向函数qemu_anon_ram_alloc，这里面调用qemu_ram_mmap，在qemu_ram_mmap中调用mmap分配内存。</p><pre><code>static void *(*phys_mem_alloc)(size_t size, uint64_t *align, bool shared) = qemu_anon_ram_alloc;\n\nvoid *qemu_anon_ram_alloc(size_t size, uint64_t *alignment, bool shared)\n{\n    size_t align = QEMU_VMALLOC_ALIGN;\n    void *ptr = qemu_ram_mmap(-1, size, align, shared);\n......\n    if (alignment) {\n        *alignment = align;\n    }\n    return ptr;\n}\n\nvoid *qemu_ram_mmap(int fd, size_t size, size_t align, bool shared)\n{\n    int flags;\n    int guardfd;\n    size_t offset;\n    size_t pagesize;\n    size_t total;\n    void *guardptr;\n    void *ptr;\n......\n    total = size + align;\n    guardfd = -1;\n    pagesize = getpagesize();\n    flags = MAP_PRIVATE | MAP_ANONYMOUS;\n    guardptr = mmap(0, total, PROT_NONE, flags, guardfd, 0);\n......\n    flags = MAP_FIXED;\n    flags |= fd == -1 ? MAP_ANONYMOUS : 0;\n    flags |= shared ? MAP_SHARED : MAP_PRIVATE;\n    offset = QEMU_ALIGN_UP((uintptr_t)guardptr, align) - (uintptr_t)guardptr;\n    ptr = mmap(guardptr + offset, size, PROT_READ | PROT_WRITE, flags, fd, 0);\n......\n    return ptr;\n}\n</code></pre><p>我们回到pc_memory_init，通过memory_region_allocate_system_memory申请到内存以后，为了兼容过去的版本，我们分成两个MemoryRegion进行管理，一个是ram_below_4g，一个是ram_above_4g。对于这两个MemoryRegion，我们都会初始化一个alias，也即别名，意思是说，两个MemoryRegion其实都指向memory_region_allocate_system_memory分配的内存，只不过分成两个部分，起两个别名指向不同的区域。</p><p>这两部分MemoryRegion都会调用memory_region_add_subregion，将这两部分作为子的内存区域添加到system_memory这棵树上。</p><p>接下来的调用链为：memory_region_add_subregion-&gt;memory_region_add_subregion_common-&gt;memory_region_update_container_subregions。</p><pre><code>static void memory_region_update_container_subregions(MemoryRegion *subregion)\n{\n    MemoryRegion *mr = subregion-&gt;container;\n    MemoryRegion *other;\n\n    memory_region_transaction_begin();\n\n    memory_region_ref(subregion);\n    QTAILQ_FOREACH(other, &amp;mr-&gt;subregions, subregions_link) {\n        if (subregion-&gt;priority &gt;= other-&gt;priority) {\n            QTAILQ_INSERT_BEFORE(other, subregion, subregions_link);\n            goto done;\n        }\n    }\n    QTAILQ_INSERT_TAIL(&amp;mr-&gt;subregions, subregion, subregions_link);\ndone:\n    memory_region_update_pending |= mr-&gt;enabled &amp;&amp; subregion-&gt;enabled;\n    memory_region_transaction_commit();\n}\n</code></pre><p>在memory_region_update_container_subregions中，我们会将子区域放到链表中，然后调用memory_region_transaction_commit。在这里面，我们会调用address_space_set_flatview。因为内存区域变了，flatview也会变，就像上面分析过的一样，listener会被调用。</p><p>因为添加了一个MemoryRegion，region_add也即kvm_region_add。</p><pre><code>static void kvm_region_add(MemoryListener *listener,\n                           MemoryRegionSection *section)\n{\n    KVMMemoryListener *kml = container_of(listener, KVMMemoryListener, listener);\n    kvm_set_phys_mem(kml, section, true);\n}\n\nstatic void kvm_set_phys_mem(KVMMemoryListener *kml,\n                             MemoryRegionSection *section, bool add)\n{\n    KVMSlot *mem;\n    int err;\n    MemoryRegion *mr = section-&gt;mr;\n    bool writeable = !mr-&gt;readonly &amp;&amp; !mr-&gt;rom_device;\n    hwaddr start_addr, size;\n    void *ram;\n......\n    size = kvm_align_section(section, &amp;start_addr);\n......\n    /* use aligned delta to align the ram address */\n    ram = memory_region_get_ram_ptr(mr) + section-&gt;offset_within_region + (start_addr - section-&gt;offset_within_address_space);\n......\n    /* register the new slot */\n    mem = kvm_alloc_slot(kml);\n    mem-&gt;memory_size = size;\n    mem-&gt;start_addr = start_addr;\n    mem-&gt;ram = ram;\n    mem-&gt;flags = kvm_mem_flags(mr);\n\n    err = kvm_set_user_memory_region(kml, mem, true);\n......\n}\n</code></pre><p>kvm_region_add调用的是kvm_set_phys_mem，这里面分配一个用于放这块内存的KVMSlot结构，就像一个内存条一样，当然这是在用户态模拟出来的内存条，放在KVMState结构里面。这个结构是我们上一节创建虚拟机的时候创建的。</p><p>接下来，kvm_set_user_memory_region就会将用户态模拟出来的内存条，和内核中的KVM模块关联起来。</p><pre><code>static int kvm_set_user_memory_region(KVMMemoryListener *kml, KVMSlot *slot, bool new)\n{\n    KVMState *s = kvm_state;\n    struct kvm_userspace_memory_region mem;\n    int ret;\n\n    mem.slot = slot-&gt;slot | (kml-&gt;as_id &lt;&lt; 16);\n    mem.guest_phys_addr = slot-&gt;start_addr;\n    mem.userspace_addr = (unsigned long)slot-&gt;ram;\n    mem.flags = slot-&gt;flags;\n......\n    mem.memory_size = slot-&gt;memory_size;\n    ret = kvm_vm_ioctl(s, KVM_SET_USER_MEMORY_REGION, &amp;mem);\n    slot-&gt;old_flags = mem.flags;\n......\n    return ret;\n}\n</code></pre><p>终于，在这里，我们又看到了可以和内核通信的kvm_vm_ioctl。我们来看内核收到KVM_SET_USER_MEMORY_REGION会做哪些事情。</p><pre><code>static long kvm_vm_ioctl(struct file *filp,\n               unsigned int ioctl, unsigned long arg)\n{\n    struct kvm *kvm = filp-&gt;private_data;\n    void __user *argp = (void __user *)arg;\n    switch (ioctl) {\n    case KVM_SET_USER_MEMORY_REGION: {\n        struct kvm_userspace_memory_region kvm_userspace_mem;\n        if (copy_from_user(&amp;kvm_userspace_mem, argp,\n                        sizeof(kvm_userspace_mem)))\n            goto out;   \n        r = kvm_vm_ioctl_set_memory_region(kvm, &amp;kvm_userspace_mem);\n        break;  \n    }   \n......\n}\n</code></pre><p>接下来的调用链为：kvm_vm_ioctl_set_memory_region-&gt;kvm_set_memory_region-&gt;__kvm_set_memory_region。</p><pre><code>int __kvm_set_memory_region(struct kvm *kvm,\n\t\t\t    const struct kvm_userspace_memory_region *mem)\n{\n\tint r;\n\tgfn_t base_gfn;\n\tunsigned long npages;\n\tstruct kvm_memory_slot *slot;\n\tstruct kvm_memory_slot old, new;\n\tstruct kvm_memslots *slots = NULL, *old_memslots;\n\tint as_id, id;\n\tenum kvm_mr_change change;\n......\n\tas_id = mem-&gt;slot &gt;&gt; 16;\n\tid = (u16)mem-&gt;slot;\n\n\tslot = id_to_memslot(__kvm_memslots(kvm, as_id), id);\n\tbase_gfn = mem-&gt;guest_phys_addr &gt;&gt; PAGE_SHIFT;\n\tnpages = mem-&gt;memory_size &gt;&gt; PAGE_SHIFT;\n......\n\tnew = old = *slot;\n\n\tnew.id = id;\n\tnew.base_gfn = base_gfn;\n\tnew.npages = npages;\n\tnew.flags = mem-&gt;flags;\n......\n \tif (change == KVM_MR_CREATE) {\n\t\tnew.userspace_addr = mem-&gt;userspace_addr;\n\n\t\tif (kvm_arch_create_memslot(kvm, &amp;new, npages))\n\t\t\tgoto out_free;\n\t}\n......\n\tslots = kvzalloc(sizeof(struct kvm_memslots), GFP_KERNEL);\n\tmemcpy(slots, __kvm_memslots(kvm, as_id), sizeof(struct kvm_memslots));\n......\n\tr = kvm_arch_prepare_memory_region(kvm, &amp;new, mem, change);\n\n\tupdate_memslots(slots, &amp;new);\n\told_memslots = install_new_memslots(kvm, as_id, slots);\n\n\tkvm_arch_commit_memory_region(kvm, mem, &amp;old, &amp;new, change);\n\treturn 0;\n......\n}\n</code></pre><p>在用户态每个KVMState有多个KVMSlot，在内核里面，同样每个struct kvm也有多个struct kvm_memory_slot，两者是对应起来的。</p><pre><code>//用户态\nstruct KVMState\n{\n......\n    int nr_slots;\n......\n    KVMMemoryListener memory_listener;\n......\n};\n\ntypedef struct KVMMemoryListener {\n    MemoryListener listener;\n    KVMSlot *slots;\n    int as_id;\n} KVMMemoryListener\n\ntypedef struct KVMSlot\n{\n    hwaddr start_addr;\n    ram_addr_t memory_size;\n    void *ram;\n    int slot;\n    int flags;\n    int old_flags;\n} KVMSlot;\n\n//内核态\nstruct kvm {\n\tspinlock_t mmu_lock;\n\tstruct mutex slots_lock;\n\tstruct mm_struct *mm; /* userspace tied to this vm */\n\tstruct kvm_memslots __rcu *memslots[KVM_ADDRESS_SPACE_NUM];\n......\n}\n\nstruct kvm_memslots {\n\tu64 generation;\n\tstruct kvm_memory_slot memslots[KVM_MEM_SLOTS_NUM];\n\t/* The mapping table from slot id to the index in memslots[]. */\n\tshort id_to_index[KVM_MEM_SLOTS_NUM];\n\tatomic_t lru_slot;\n\tint used_slots;\n};\n\nstruct kvm_memory_slot {\n\tgfn_t base_gfn;//根据guest_phys_addr计算\n\tunsigned long npages;\n\tunsigned long *dirty_bitmap;\n\tstruct kvm_arch_memory_slot arch;\n\tunsigned long userspace_addr;\n\tu32 flags;\n\tshort id;\n};\n</code></pre><p>并且，id_to_memslot函数可以根据用户态的slot号得到内核态的slot结构。</p><p>如果传进来的参数是KVM_MR_CREATE，表示要创建一个新的内存条，就会调用kvm_arch_create_memslot来创建kvm_memory_slot的成员kvm_arch_memory_slot。</p><p>接下来就是创建kvm_memslots结构，填充这个结构，然后通过install_new_memslots将这个新的内存条，添加到struct kvm结构中。</p><p>至此，用户态的内存结构和内核态的内存结构算是对应了起来。</p><h2>页面分配和映射</h2><p>上面对于内存的管理，还只是停留在元数据的管理。对于内存的分配与映射，我们还没有涉及，接下来，我们就来看看，页面是如何进行分配和映射的。</p><p>上面咱们说了，内存映射对于虚拟机来讲是一件非常麻烦的事情，从GVA到GPA到HVA到HPA，性能很差，为了解决这个问题，有两种主要的思路。</p><h3>影子页表</h3><p>第一种方式就是软件的方式，<strong>影子页表</strong>  （Shadow Page Table）。</p><p>按照咱们在内存管理那一节讲的，内存映射要通过页表来管理，页表地址应该放在cr3寄存器里面。本来的过程是，客户机要通过cr3找到客户机的页表，实现从GVA到GPA的转换，然后在宿主机上，要通过cr3找到宿主机的页表，实现从HVA到HPA的转换。</p><p>为了实现客户机虚拟地址空间到宿主机物理地址空间的直接映射。客户机中每个进程都有自己的虚拟地址空间，所以KVM需要为客户机中的每个进程页表都要维护一套相应的影子页表。</p><p>在客户机访问内存时，使用的不是客户机的原来的页表，而是这个页表对应的影子页表，从而实现了从客户机虚拟地址到宿主机物理地址的直接转换。而且，在TLB和CPU 缓存上缓存的是来自影子页表中客户机虚拟地址和宿主机物理地址之间的映射，也因此提高了缓存的效率。</p><p>但是影子页表的引入也意味着 KVM 需要为每个客户机的每个进程的页表都要维护一套相应的影子页表，内存占用比较大，而且客户机页表和和影子页表也需要进行实时同步。</p><h3>扩展页表</h3><p>于是就有了第二种方式，就是硬件的方式，Intel的EPT（Extent Page Table，扩展页表）技术。</p><p>EPT在原有客户机页表对客户机虚拟地址到客户机物理地址映射的基础上，又引入了 EPT页表来实现客户机物理地址到宿主机物理地址的另一次映射。客户机运行时，客户机页表被载入 CR3，而EPT页表被载入专门的EPT 页表指针寄存器 EPTP。</p><p>有了EPT，在客户机物理地址到宿主机物理地址转换的过程中，缺页会产生EPT 缺页异常。KVM首先根据引起异常的客户机物理地址，映射到对应的宿主机虚拟地址，然后为此虚拟地址分配新的物理页，最后 KVM 再更新 EPT 页表，建立起引起异常的客户机物理地址到宿主机物理地址之间的映射。</p><p>KVM 只需为每个客户机维护一套 EPT 页表，也大大减少了内存的开销。</p><p>这里，我们重点看第二种方式。因为使用了EPT之后，客户机里面的页表映射，也即从GVA到GPA的转换，还是用传统的方式，和在内存管理那一章讲的没有什么区别。而EPT重点帮我们解决的就是从GPA到HPA的转换问题。因为要经过两次页表，所以EPT又称为tdp（two dimentional paging）。</p><p>EPT的页表结构也是分为四层，EPT Pointer （EPTP）指向PML4的首地址。</p><p><img src=\"https://static001.geekbang.org/resource/image/02/30/02e4740398bc3685f366351260ae7230.jpg?wh=2263*3112\" alt=\"\"></p><p>管理物理页面的Page结构和咱们讲内存管理那一章是一样的。EPT页表也需要存放在一个页中，这些页要用kvm_mmu_page这个结构来管理。</p><p>当一个虚拟机运行，进入客户机模式的时候，我们上一节解析过，它会调用vcpu_enter_guest函数，这里面会调用kvm_mmu_reload-&gt;kvm_mmu_load。</p><pre><code>int kvm_mmu_load(struct kvm_vcpu *vcpu)\n{\n......\n\tr = mmu_topup_memory_caches(vcpu);\n\tr = mmu_alloc_roots(vcpu);\n\tkvm_mmu_sync_roots(vcpu);\n\t/* set_cr3() should ensure TLB has been flushed */\n\tvcpu-&gt;arch.mmu.set_cr3(vcpu, vcpu-&gt;arch.mmu.root_hpa);\n......\n}\n\nstatic int mmu_alloc_roots(struct kvm_vcpu *vcpu)\n{\n\tif (vcpu-&gt;arch.mmu.direct_map)\n\t\treturn mmu_alloc_direct_roots(vcpu);\n\telse\n\t\treturn mmu_alloc_shadow_roots(vcpu);\n}\n\nstatic int mmu_alloc_direct_roots(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_mmu_page *sp;\n\tunsigned i;\n\n\tif (vcpu-&gt;arch.mmu.shadow_root_level == PT64_ROOT_LEVEL) {\n\t\tspin_lock(&amp;vcpu-&gt;kvm-&gt;mmu_lock);\n\t\tmake_mmu_pages_available(vcpu);\n\t\tsp = kvm_mmu_get_page(vcpu, 0, 0, PT64_ROOT_LEVEL, 1, ACC_ALL);\n\t\t++sp-&gt;root_count;\n\t\tspin_unlock(&amp;vcpu-&gt;kvm-&gt;mmu_lock);\n\t\tvcpu-&gt;arch.mmu.root_hpa = __pa(sp-&gt;spt);\n\t} \n......\n}\n</code></pre><p>这里构建的是页表的根部，也即顶级页表，并且设置cr3来刷新TLB。mmu_alloc_roots会调用mmu_alloc_direct_roots，因为我们用的是EPT模式，而非影子表。在mmu_alloc_direct_roots中，kvm_mmu_get_page会分配一个kvm_mmu_page，来存放顶级页表项。</p><p>接下来，当虚拟机真的要访问内存的时候，会发现有的页表没有建立，有的物理页没有分配，这都会触发缺页异常，在KVM里面会发送VM-Exit，从客户机模式转换为宿主机模式，来修复这个缺失的页表或者物理页。</p><pre><code>static int (*const kvm_vmx_exit_handlers[])(struct kvm_vcpu *vcpu) = {\n    [EXIT_REASON_EXCEPTION_NMI]           = handle_exception,\n    [EXIT_REASON_EXTERNAL_INTERRUPT]      = handle_external_interrupt,\n    [EXIT_REASON_IO_INSTRUCTION]          = handle_io,\n......\n    [EXIT_REASON_EPT_VIOLATION]       = handle_ept_violation,\n......\n}\n</code></pre><p>咱们前面讲过，虚拟机退出客户机模式有很多种原因，例如接收到中断、接收到I/O等，EPT的缺页异常也是一种类型，我们称为EXIT_REASON_EPT_VIOLATION，对应的处理函数是handle_ept_violation。</p><pre><code>static int handle_ept_violation(struct kvm_vcpu *vcpu)\n{\n\tgpa_t gpa;\n......\n\tgpa = vmcs_read64(GUEST_PHYSICAL_ADDRESS);\n......\n\tvcpu-&gt;arch.gpa_available = true;\n\tvcpu-&gt;arch.exit_qualification = exit_qualification;\n\n\treturn kvm_mmu_page_fault(vcpu, gpa, error_code, NULL, 0);\n}\n\nint kvm_mmu_page_fault(struct kvm_vcpu *vcpu, gva_t cr2, u64 error_code,\n\t\t       void *insn, int insn_len)\n{\n......\n\tr = vcpu-&gt;arch.mmu.page_fault(vcpu, cr2, lower_32_bits(error_code),false);\n......\n}\n</code></pre><p>在handle_ept_violation里面，我们从VMCS中得到没有解析成功的GPA，也即客户机的物理地址，然后调用kvm_mmu_page_fault，看为什么解析不成功。kvm_mmu_page_fault会调用page_fault函数，其实是tdp_page_fault函数。tdp的意思就是EPT，前面我们解释过了。</p><pre><code>static int tdp_page_fault(struct kvm_vcpu *vcpu, gva_t gpa, u32 error_code, bool prefault)\n{\n\tkvm_pfn_t pfn;\n\tint r;\n\tint level;\n\tbool force_pt_level;\n\tgfn_t gfn = gpa &gt;&gt; PAGE_SHIFT;\n\tunsigned long mmu_seq;\n\tint write = error_code &amp; PFERR_WRITE_MASK;\n\tbool map_writable;\n\n\tr = mmu_topup_memory_caches(vcpu);\n\tlevel = mapping_level(vcpu, gfn, &amp;force_pt_level);\n......\n\tif (try_async_pf(vcpu, prefault, gfn, gpa, &amp;pfn, write, &amp;map_writable))\n\t\treturn 0;\n\n\tif (handle_abnormal_pfn(vcpu, 0, gfn, pfn, ACC_ALL, &amp;r))\n\t\treturn r;\n\n\tmake_mmu_pages_available(vcpu);\n\tr = __direct_map(vcpu, write, map_writable, level, gfn, pfn, prefault);\n......\n}\n</code></pre><p>既然没有映射，就应该加上映射，tdp_page_fault就是干这个事情的。</p><p>在tdp_page_fault这个函数开头，我们通过gpa，也即客户机的物理地址得到客户机的页号gfn。接下来，我们要通过调用try_async_pf得到宿主机的物理地址对应的页号，也即真正的物理页的页号，然后通过__direct_map将两者关联起来。</p><pre><code>static bool try_async_pf(struct kvm_vcpu *vcpu, bool prefault, gfn_t gfn, gva_t gva, kvm_pfn_t *pfn, bool write, bool *writable)\n{\n\tstruct kvm_memory_slot *slot;\n\tbool async;\n\n\tslot = kvm_vcpu_gfn_to_memslot(vcpu, gfn);\n\tasync = false;\n\t*pfn = __gfn_to_pfn_memslot(slot, gfn, false, &amp;async, write, writable);\n\tif (!async)\n\t\treturn false; /* *pfn has correct page already */\n\n\tif (!prefault &amp;&amp; kvm_can_do_async_pf(vcpu)) {\n\t\tif (kvm_find_async_pf_gfn(vcpu, gfn)) {\n\t\t\tkvm_make_request(KVM_REQ_APF_HALT, vcpu);\n\t\t\treturn true;\n\t\t} else if (kvm_arch_setup_async_pf(vcpu, gva, gfn))\n\t\t\treturn true;\n\t}\n\t*pfn = __gfn_to_pfn_memslot(slot, gfn, false, NULL, write, writable);\n\treturn false;\n}\n</code></pre><p>在try_async_pf中，要想得到pfn，也即物理页的页号，会先通过kvm_vcpu_gfn_to_memslot，根据客户机的物理地址对应的页号找到内存条，然后调用__gfn_to_pfn_memslot，根据内存条找到pfn。</p><pre><code>kvm_pfn_t __gfn_to_pfn_memslot(struct kvm_memory_slot *slot, gfn_t gfn,bool atomic, bool *async, bool write_fault,bool *writable)\n{\n\tunsigned long addr = __gfn_to_hva_many(slot, gfn, NULL, write_fault);\n......\n\treturn hva_to_pfn(addr, atomic, async, write_fault,\n\t\t\t  writable);\n}\n</code></pre><p>在__gfn_to_pfn_memslot中，我们会调用__gfn_to_hva_many，从客户机物理地址对应的页号，得到宿主机虚拟地址hva，然后从宿主机虚拟地址到宿主机物理地址，调用的是hva_to_pfn。</p><p>hva_to_pfn会调用hva_to_pfn_slow。</p><pre><code>static int hva_to_pfn_slow(unsigned long addr, bool *async, bool write_fault,\n\t\t\t   bool *writable, kvm_pfn_t *pfn)\n{\n\tstruct page *page[1];\n\tint npages = 0;\n......\n\tif (async) {\n\t\tnpages = get_user_page_nowait(addr, write_fault, page);\n\t} else {\n......\n\t\tnpages = get_user_pages_unlocked(addr, 1, page, flags);\n\t}\n......\n\t*pfn = page_to_pfn(page[0]);\n\treturn npages;\n}\n</code></pre><p>在hva_to_pfn_slow中，我们要先调用get_user_page_nowait，得到一个物理页面，然后再调用page_to_pfn将物理页面转换成为物理页号。</p><p>无论是哪一种get_user_pages_XXX，最终都会调用__get_user_pages函数。这里面会调用faultin_page，在faultin_page中我们会调用handle_mm_fault。看到这个是不是很熟悉？这就是咱们内存管理那一章讲的缺页异常的逻辑，分配一个物理内存。</p><p>至此，try_async_pf得到了物理页面，并且转换为对应的物理页号。</p><p>接下来，__direct_map会关联客户机物理页号和宿主机物理页号。</p><pre><code>static int __direct_map(struct kvm_vcpu *vcpu, int write, int map_writable,\n\t\t\tint level, gfn_t gfn, kvm_pfn_t pfn, bool prefault)\n{\n\tstruct kvm_shadow_walk_iterator iterator;\n\tstruct kvm_mmu_page *sp;\n\tint emulate = 0;\n\tgfn_t pseudo_gfn;\n\n\tif (!VALID_PAGE(vcpu-&gt;arch.mmu.root_hpa))\n\t\treturn 0;\n\n\tfor_each_shadow_entry(vcpu, (u64)gfn &lt;&lt; PAGE_SHIFT, iterator) {\n\t\tif (iterator.level == level) {\n\t\t\temulate = mmu_set_spte(vcpu, iterator.sptep, ACC_ALL,\n\t\t\t\t\t       write, level, gfn, pfn, prefault,\n\t\t\t\t\t       map_writable);\n\t\t\tdirect_pte_prefetch(vcpu, iterator.sptep);\n\t\t\t++vcpu-&gt;stat.pf_fixed;\n\t\t\tbreak;\n\t\t}\n\n\t\tdrop_large_spte(vcpu, iterator.sptep);\n\t\tif (!is_shadow_present_pte(*iterator.sptep)) {\n\t\t\tu64 base_addr = iterator.addr;\n\n\t\t\tbase_addr &amp;= PT64_LVL_ADDR_MASK(iterator.level);\n\t\t\tpseudo_gfn = base_addr &gt;&gt; PAGE_SHIFT;\n\t\t\tsp = kvm_mmu_get_page(vcpu, pseudo_gfn, iterator.addr,\n\t\t\t\t\t      iterator.level - 1, 1, ACC_ALL);\n\n\t\t\tlink_shadow_page(vcpu, iterator.sptep, sp);\n\t\t}\n\t}\n\treturn emulate;\n}\n</code></pre><p>__direct_map首先判断页表的根是否存在，当然存在，我们刚才初始化了。</p><p>接下来是for_each_shadow_entry一个循环。每一个循环中，先是会判断需要映射的level，是否正是当前循环的这个iterator.level。如果是，则说明是叶子节点，直接映射真正的物理页面pfn，然后退出。接着是非叶子节点的情形，判断如果这一项指向的页表项不存在，就要建立页表项，通过kvm_mmu_get_page得到保存页表项的页面，然后将这一项指向下一级的页表页面。</p><p>至此，内存映射就结束了。</p><h2>总结时刻</h2><p>我们这里来总结一下，虚拟机的内存管理也是需要用户态的qemu和内核态的KVM共同完成。为了加速内存映射，需要借助硬件的EPT技术。</p><p>在用户态qemu中，有一个结构AddressSpace address_space_memory来表示虚拟机的系统内存，这个内存可能包含多个内存区域struct MemoryRegion，组成树形结构，指向由mmap分配的虚拟内存。</p><p>在AddressSpace结构中，有一个struct KVMMemoryListener，当有新的内存区域添加的时候，会被通知调用kvm_region_add来通知内核。</p><p>在用户态qemu中，对于虚拟机有一个结构struct KVMState表示这个虚拟机，这个结构会指向一个数组的struct KVMSlot表示这个虚拟机的多个内存条，KVMSlot中有一个void *ram指针指向mmap分配的那块虚拟内存。</p><p>kvm_region_add是通过ioctl来通知内核KVM的，会给内核KVM发送一个KVM_SET_USER_MEMORY_REGION消息，表示用户态qemu添加了一个内存区域，内核KVM也应该添加一个相应的内存区域。</p><p>和用户态qemu对应的内核KVM，对于虚拟机有一个结构struct kvm表示这个虚拟机，这个结构会指向一个数组的struct kvm_memory_slot表示这个虚拟机的多个内存条，kvm_memory_slot中有起始页号，页面数目，表示这个虚拟机的物理内存空间。</p><p>虚拟机的物理内存空间里面的页面当然不是一开始就映射到物理页面的，只有当虚拟机的内存被访问的时候，也即mmap分配的虚拟内存空间被访问的时候，先查看EPT页表，是否已经映射过，如果已经映射过，则经过四级页表映射，就能访问到物理页面。</p><p>如果没有映射过，则虚拟机会通过VM-Exit指令回到宿主机模式，通过handle_ept_violation补充页表映射。先是通过handle_mm_fault为虚拟机的物理内存空间分配真正的物理页面，然后通过__direct_map添加EPT页表映射。</p><p><img src=\"https://static001.geekbang.org/resource/image/01/9b/0186c533b7ef706df880dfd775c2449b.jpg?wh=4132*2968\" alt=\"\"></p><h2>课堂练习</h2><p>这一节，影子页表我们没有深入去讲，你能自己研究一下，它是如何实现的吗？</p><p>欢迎留言和我分享你的疑惑和见解，也欢迎收藏本节内容，反复研读。你也可以把今天的内容分享给你的朋友，和他一起学习和进步。</p><p><img src=\"https://static001.geekbang.org/resource/image/8c/37/8c0a95fa07a8b9a1abfd394479bdd637.jpg?wh=1110*659\" alt=\"\"></p>","neighbors":{"left":{"article_title":"51 | 计算虚拟化之CPU（下）：如何复用集团的人力资源？","id":109904},"right":{"article_title":"53 | 存储虚拟化（上）：如何建立自己保管的单独档案库？","id":110697}},"comments":[{"had_liked":false,"id":118871,"user_name":"ClassCastException","can_delete":false,"product_type":"c1","uid":1175060,"ip_address":"","ucode":"491D1D45A6455A","user_header":"https://static001.geekbang.org/account/avatar/00/11/ee/14/46442742.jpg","comment_is_top":false,"comment_ctime":1564455096,"is_pvip":false,"replies":[{"id":"46391","content":"加油","user_name":"作者回复","comment_id":118871,"uid":"1001590","ip_address":"","utype":1,"ctime":1566298146,"user_name_real":"刘超@网易云"}],"discussion_count":3,"race_medal":0,"score":"91758768312","product_id":100024701,"comment_content":"别管看不看的懂，能坚持到这的也是神级人物了","like_count":21,"discussions":[{"author":{"id":1001590,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/48/76/0c7d4d23.jpg","nickname":"刘超","note":"","ucode":"196BF3F499E8FE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":460629,"discussion_content":"加油","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1566298146,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2911482,"avatar":"https://static001.geekbang.org/account/avatar/00/2c/6c/fa/4893f0f8.jpg","nickname":"(๑•ั็ω•็ั๑)","note":"","ucode":"2236C1E1FD1DE8","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":563251,"discussion_content":"加油","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1649953828,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1229171,"avatar":"https://static001.geekbang.org/account/avatar/00/12/c1/73/a7da4215.jpg","nickname":"盖满京","note":"","ucode":"B22D394FC4327B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":534483,"discussion_content":"加油","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1638198619,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":138392,"user_name":"Spring","can_delete":false,"product_type":"c1","uid":1222211,"ip_address":"","ucode":"8175463FB4705B","user_header":"https://static001.geekbang.org/account/avatar/00/12/a6/43/cb6ab349.jpg","comment_is_top":false,"comment_ctime":1570195422,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"57404770270","product_id":100024701,"comment_content":"总结下来就是：虚拟机用户态qemu中的KVMSlot结构维护虚拟机进程的虚拟地址，虚拟机内核态kvm_memory_slot结构维护虚拟机的物理页面，二者通过普通页表建立映射关系。当访问虚拟机虚拟页面发生缺页异常时，切换到宿主机中分配真正的物理页面，然后通过EPT（扩展页表）建立虚拟机物理地址到宿主机物理地址的映射关系。","like_count":13},{"had_liked":false,"id":118257,"user_name":"没心没肺","can_delete":false,"product_type":"c1","uid":1258867,"ip_address":"","ucode":"121FD3AEBA3BEA","user_header":"https://static001.geekbang.org/account/avatar/00/13/35/73/46d6dadc.jpg","comment_is_top":false,"comment_ctime":1564303619,"is_pvip":false,"replies":[{"id":"46397","content":"加油，多看几遍就好了","user_name":"作者回复","comment_id":118257,"uid":"1001590","ip_address":"","utype":1,"ctime":1566298800,"user_name_real":"刘超@网易云"}],"discussion_count":1,"race_medal":0,"score":"35924041987","product_id":100024701,"comment_content":"快要被劝退了，硬着头皮看。","like_count":8,"discussions":[{"author":{"id":1001590,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/48/76/0c7d4d23.jpg","nickname":"刘超","note":"","ucode":"196BF3F499E8FE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":460326,"discussion_content":"加油，多看几遍就好了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1566298800,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":146208,"user_name":"zKerry","can_delete":false,"product_type":"c1","uid":1497740,"ip_address":"","ucode":"9FB006D1A38D3F","user_header":"","comment_is_top":false,"comment_ctime":1572457656,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"27342261432","product_id":100024701,"comment_content":"感觉怼到了一堵墙上，请问刘老师，你当初是怎么整明白的？","like_count":6},{"had_liked":false,"id":117609,"user_name":"小龙的城堡","can_delete":false,"product_type":"c1","uid":1005727,"ip_address":"","ucode":"7F1F9704548E2D","user_header":"https://static001.geekbang.org/account/avatar/00/0f/58/9f/abb7bfe3.jpg","comment_is_top":false,"comment_ctime":1564102361,"is_pvip":false,"replies":[{"id":"46411","content":"是的，很惊艳","user_name":"作者回复","comment_id":117609,"uid":"1001590","ip_address":"","utype":1,"ctime":1566299141,"user_name_real":"刘超@网易云"}],"discussion_count":2,"race_medal":0,"score":"18743971545","product_id":100024701,"comment_content":"把c语言写出面相对象，确实有意思！","like_count":4,"discussions":[{"author":{"id":1001590,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/48/76/0c7d4d23.jpg","nickname":"刘超","note":"","ucode":"196BF3F499E8FE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":460050,"discussion_content":"是的，很惊艳","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1566299141,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1258402,"avatar":"https://static001.geekbang.org/account/avatar/00/13/33/a2/6c0ffc15.jpg","nickname":"皮皮侠","note":"","ucode":"04205990C1DE1F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":356964,"discussion_content":"怪不得linus不喜欢C++","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1615715335,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":118026,"user_name":"LDxy","can_delete":false,"product_type":"c1","uid":1188710,"ip_address":"","ucode":"956432CE7B7761","user_header":"https://static001.geekbang.org/account/avatar/00/12/23/66/413c0bb5.jpg","comment_is_top":false,"comment_ctime":1564214446,"is_pvip":false,"replies":[{"id":"46401","content":"其实还好，多看几遍","user_name":"作者回复","comment_id":118026,"uid":"1001590","ip_address":"","utype":1,"ctime":1566298918,"user_name_real":"刘超@网易云"}],"discussion_count":1,"race_medal":0,"score":"10154149038","product_id":100024701,"comment_content":"真难","like_count":2,"discussions":[{"author":{"id":1001590,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/48/76/0c7d4d23.jpg","nickname":"刘超","note":"","ucode":"196BF3F499E8FE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":460228,"discussion_content":"其实还好，多看几遍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1566298918,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":117643,"user_name":"起飞的鸭子","can_delete":false,"product_type":"c1","uid":1093056,"ip_address":"","ucode":"F04049210F7DF7","user_header":"https://static001.geekbang.org/account/avatar/00/10/ad/c0/ea2b3a14.jpg","comment_is_top":false,"comment_ctime":1564104735,"is_pvip":false,"replies":[{"id":"46410","content":"不是的","user_name":"作者回复","comment_id":117643,"uid":"1001590","ip_address":"","utype":1,"ctime":1566299127,"user_name_real":"刘超@网易云"}],"discussion_count":1,"race_medal":0,"score":"10154039327","product_id":100024701,"comment_content":"这配图是网易吗","like_count":2,"discussions":[{"author":{"id":1001590,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/48/76/0c7d4d23.jpg","nickname":"刘超","note":"","ucode":"196BF3F499E8FE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":460064,"discussion_content":"不是的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1566299127,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":256644,"user_name":"Ascend","can_delete":false,"product_type":"c1","uid":1965188,"ip_address":"","ucode":"B2F3EBEFE89C9C","user_header":"https://static001.geekbang.org/account/avatar/00/1d/fc/84/30af1749.jpg","comment_is_top":false,"comment_ctime":1603695284,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"5898662580","product_id":100024701,"comment_content":"我感觉这章没有先讲qemu的宏观架构，直接引入qemu细节代码，有点吃力","like_count":1},{"had_liked":false,"id":241027,"user_name":"No","can_delete":false,"product_type":"c1","uid":2033599,"ip_address":"","ucode":"7D79AD4759A836","user_header":"https://static001.geekbang.org/account/avatar/00/1f/07/bf/d4d4417c.jpg","comment_is_top":false,"comment_ctime":1597154842,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"5892122138","product_id":100024701,"comment_content":"老师，你讲的这个深度作为一个虚拟化运维工程师或者云计算运维工程师是否要掌握的很熟悉？","like_count":1,"discussions":[{"author":{"id":1965188,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/fc/84/30af1749.jpg","nickname":"Ascend","note":"","ucode":"B2F3EBEFE89C9C","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":318275,"discussion_content":"我感觉运维不需要掌握到这个程度吧，如果是去做开发那是必须的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1603694757,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":182225,"user_name":"why","can_delete":false,"product_type":"c1","uid":1012937,"ip_address":"","ucode":"C9E796E53F6F5E","user_header":"https://static001.geekbang.org/account/avatar/00/0f/74/c9/d3439ca4.jpg","comment_is_top":false,"comment_ctime":1582730462,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"5877697758","product_id":100024701,"comment_content":"是不是 qemu 维护的 slot 相当于 gpa，KVM 维护的 slot 相当于 hva。","like_count":1,"discussions":[{"author":{"id":1266698,"avatar":"https://static001.geekbang.org/account/avatar/00/13/54/0a/9a002ad5.jpg","nickname":"Adam Lau","note":"","ucode":"7E542D6E789500","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":237085,"discussion_content":"slot是什么意思？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587134232,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":117924,"user_name":"浪子","can_delete":false,"product_type":"c1","uid":1142287,"ip_address":"","ucode":"321C295455CD08","user_header":"https://static001.geekbang.org/account/avatar/00/11/6e/0f/d6773c7e.jpg","comment_is_top":false,"comment_ctime":1564193198,"is_pvip":false,"replies":[{"id":"46404","content":"没有分析内存overcommit的部分。","user_name":"作者回复","comment_id":117924,"uid":"1001590","ip_address":"","utype":1,"ctime":1566298965,"user_name_real":"刘超@网易云"}],"discussion_count":1,"race_medal":0,"score":"5859160494","product_id":100024701,"comment_content":"超哥会讲overcommit吗","like_count":1,"discussions":[{"author":{"id":1001590,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/48/76/0c7d4d23.jpg","nickname":"刘超","note":"","ucode":"196BF3F499E8FE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":460182,"discussion_content":"没有分析内存overcommit的部分。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1566298965,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":323892,"user_name":"盖满京","can_delete":false,"product_type":"c1","uid":1229171,"ip_address":"","ucode":"B22D394FC4327B","user_header":"https://static001.geekbang.org/account/avatar/00/12/c1/73/a7da4215.jpg","comment_is_top":false,"comment_ctime":1638198513,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1638198513","product_id":100024701,"comment_content":"能不能在虚拟机里安装虚拟机？会怎样？","like_count":0},{"had_liked":false,"id":317190,"user_name":"马振","can_delete":false,"product_type":"c1","uid":1136329,"ip_address":"","ucode":"94234F533219C1","user_header":"https://static001.geekbang.org/account/avatar/00/11/56/c9/7b3cd3e0.jpg","comment_is_top":false,"comment_ctime":1634701685,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1634701685","product_id":100024701,"comment_content":"AddressSpace address_space_memory 来表示虚拟机的系统内存，这个就是GVA？虚拟机有一个结构 struct KVMState 表示这个虚拟机，这个结构会指向一个数组的 struct KVMSlot 表示这个虚拟机的多个内存条，这个就是GPA?","like_count":0},{"had_liked":false,"id":304287,"user_name":"Corner","can_delete":false,"product_type":"c1","uid":1446316,"ip_address":"","ucode":"7862D593172536","user_header":"https://static001.geekbang.org/account/avatar/00/16/11/ac/9cc5e692.jpg","comment_is_top":false,"comment_ctime":1627315720,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1627315720","product_id":100024701,"comment_content":"mmap得到的宿主机虚拟地址和虚拟机的物理地址在kvm_memory_slot中进行了联系，但并没有使用这层关系，而是直接使用EPT来建立虚拟机物理地址到宿主机物理地址的关系","like_count":0},{"had_liked":false,"id":263298,"user_name":"小呆瓜","can_delete":false,"product_type":"c1","uid":1411640,"ip_address":"","ucode":"1A35FA65F23995","user_header":"https://static001.geekbang.org/account/avatar/00/15/8a/38/a3260945.jpg","comment_is_top":false,"comment_ctime":1606095228,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1606095228","product_id":100024701,"comment_content":"只要牵扯到页面页表我就开始听不懂","like_count":0}]}