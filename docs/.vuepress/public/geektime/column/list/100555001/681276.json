{"id":681276,"title":"06 | 颠覆者扩散模型：直观去理解加噪与去噪","content":"<p>你好，我是南柯。</p><p>上一讲我们结识了旧画师GAN，提到了扩散模型在内容精致度、风格多样性和通用编辑等能力上弥补了GAN的不足之处。如果说GAN是旧画师，扩散模型无疑就是当下最受追捧的新画师。DALL-E 2、Imagen、Stable Diffusion这些大名鼎鼎的模型，它们背后的魔术师都是扩散模型。</p><p>用过Midjourney的同学也许都注意过这样的现象，随着图像生成的进度条推进，图像也是从模糊到清晰。你可以点开下面的图片查看这个过程。</p><p><img src=\"https://static001.geekbang.org/resource/image/40/4d/403f88e39646693d91080699af3ac84d.jpg?wh=4409x1240\" alt=\"\"></p><p>聪明的你应该猜到了，这背后的技巧大概率也是扩散模型！之所以说大概，是因为Midjourney并没有对外公布其背后的算法原理，后面我们会用专门的一讲带你推测Midjourney背后的技术方案，这里先卖个关子。</p><p>那么，扩散模型的工作原理是怎样的呢？算法优化目标是什么？与GAN相比有哪些异同？这一讲我们便从这些基础问题出发，开始今天的扩散模型学习之旅。</p><h2>初识扩散模型</h2><p>扩散模型的灵感源自热力学。我们可以想象一下这样的过程，朝着一杯清水中滴入一滴有色碘伏，然后观察这杯水。</p><p>你会发现，碘伏在水中会有一个扩散的过程，最终完全在水中呈现出均匀的状态。扩散效应代表从有序到混乱的过程。比如下面这张图，把一滴红色的液体滴入清水中，颜色会逐渐扩散开，最终整杯水都变为红色。</p><!-- [[[read_end]]] --><p><img src=\"https://static001.geekbang.org/resource/image/b9/bf/b9a441bdc01880f9fa52b70f7cfe1fbf.jpg?wh=4409x2480\" alt=\"\"></p><p>AI绘画中的扩散模型和上面的例子类似，对于一张图片，逐渐加入噪声，最终图像将变成一张均匀的噪声图。我在下面放了一张图例，展示了这个过程。</p><p><img src=\"https://static001.geekbang.org/resource/image/63/c4/63e3c220ab0c9cff5f2f525e0cb422c4.jpg?wh=4409x1688\" alt=\"\"></p><p>如果把这个过程反过来，从一个随机噪声图出发，逐步去除噪声，可以生成一张高质量的图片，这便达成了AI绘画的目的。<strong>基于扩散模型实现AI绘画的精髓就在于，如何实现这个逐步去除噪声的过程</strong>。在每一步的去噪过程中，起作用的是一个需要训练的神经网络，也就是一个UNet。UNet的细节我们下一讲再展开，这里你可以先把它当成一个黑盒子。</p><p><img src=\"https://static001.geekbang.org/resource/image/66/b1/6624807c268f8a1d76e0ccc0b17c09b1.jpg?wh=4409x1617\" alt=\"\"></p><p>从上面的过程我们可以知道，基于扩散模型实现AI绘画包括两个过程——加噪过程和去噪过程。</p><p>无论是把一张图片加噪到纯噪声（即全是噪点的图片），还是把纯噪声做去噪处理，生成一张干净的图片，都需要多次操作。为了衡量转化过程到底需要多少步操作，就要引入一个时间步t的概念。t的取值为1-1000中的一个整数，代表加噪声的步数。</p><p>实验中整个加噪过程中需要1000次加噪操作。直觉上，从纯噪声去噪得到图像也需要1000次去噪操作来完成。不过，实际使用中，通过数学推导的方式可以证明并不需要1000步，比如我们第1讲中用到的Eular采样器，只需要20~30步去噪，便可以从纯噪声去噪得到清晰的图片。</p><p>对于Diffusion模型的加噪过程，每一步加噪依赖于时间步t。t越接近0，当前加噪结果越靠近原始图像；t越接近1000，当前加噪结果越靠近纯噪声。</p><p><img src=\"https://static001.geekbang.org/resource/image/5d/e7/5d7d09834f4215fd6e6bf1d2917641e7.jpg?wh=4409x1122\" alt=\"\"></p><p>当我们通过训练得到神经网络UNet后，从原始噪声图出发，时间步取1000，UNet便可以预测第一次要去除的噪声值。然后，采样器便可以根据原始噪声图去除当前噪声值得到一张清晰一点儿的带噪声图像。反复重复这个过程，便完成了AI绘画的过程。</p><p><img src=\"https://static001.geekbang.org/resource/image/8b/d3/8be4e96813e1ac816c964376b50297d3.jpg?wh=4409x1240\" alt=\"\"></p><p>你可能已经注意到了，每一步的加噪结果仅依赖于上一步的加噪结果和一个加噪过程，而这个加噪过程依赖于当前时间步t，因此整个加噪过程可以看成参数化的马尔科夫链。</p><p>马尔可夫链是一种数学模型，用于描述随机事件的序列，其中每个事件的概率仅取决于上一个事件的状态，而与过去的事件无关。关于马尔可夫链的更多知识，你可以点开<a href=\"https://en.wikipedia.org/wiki/Markov_chain\">链接</a>了解。</p><h2>细节探究</h2><p>理解了扩散模型的整体思路，我们再来探究下加噪和去噪的算法细节。</p><h3>加噪过程</h3><p>对于加噪过程，每一步的加噪结果是可以根据上一步的加噪结果和当前时间步t计算得到的，计算公式如下所示。</p><p>$$x_t = \\sqrt{\\alpha_t}x_{t-1} + \\sqrt{1-\\alpha_t}\\epsilon$$</p><p>公式中，$x_t$表示第t步的加噪结果；$x_{t-1}$表示第t-1步的加噪结果；$\\alpha_t$是一个预先设置的超参数，用于控制随时间步的加噪强弱，你可以理解为预先设定从$\\alpha_1$到$\\alpha_{1000}$ 1000个参数；$\\epsilon$表示一个随机的高斯噪声。</p><p>经过数学推导，$x_t$也可以从原始图像$x_0$一次计算得到，你可以看下面的公式。</p><p>$$x_t = \\sqrt{\\hat\\alpha_t}x_{0} + \\sqrt{1-\\hat\\alpha_t}\\epsilon$$</p><p>公式中$x_0$表示原始干净的图像，$\\hat\\alpha_t$表示从$\\alpha_1$到$\\alpha_t$的乘积。</p><p>如果你对推导过程感兴趣，可以<a href=\"https://readpaper.com/pdf-annotate/note?pdfId=4557071478495911937&noteId=1833652073759793152\">点击链接</a>去看看原始论文。到这里，你只需要记住一个事情，<strong>对于一张干净的图像，可以通过一次计算得到任意t步加噪声的结果</strong>。</p><h3>去噪过程</h3><p>学习完加噪的过程，我们再来看看去噪。去噪的过程包括两层含义。</p><p>第一，如何根据当前时间步的噪声图预测上一步加入的噪声？</p><p>第二，如何在当前时间步的噪声图上去除这些噪声？</p><p>先看第一层含义，如何根据加噪结果和时间步t预测噪声呢？这里深度学习模型就能派上用场了！我们希望得到这样一个模型，输入第t步加噪结果和时间步t，预测从第t-1步到第t步噪声值。</p><p>主流的方法是训练一个UNet模型来预测噪声图。因为噪声值和输入图的分辨率是一致的，而UNet模型常用于图像分割任务，输入输出的分辨率相同，使用UNet来完成这个任务再合适不过了。</p><p><img src=\"https://static001.geekbang.org/resource/image/4e/ba/4ec9ef7434a0bedd19699e4318bfeaba.jpg?wh=4409x2480\" alt=\"\"></p><p>接下来是第二层含义。假定我们能够成功预测出这个噪声图，又如何去除噪声呢？</p><p>答案是采样器，你可能已经从WebUI中见到过各种各样的采样器，比如DDIM、Eular A等。采样器的作用便是根据加噪结果和噪声值，准确地去除噪声。</p><p><img src=\"https://static001.geekbang.org/resource/image/9f/fb/9f9547b04ac5935165d1abb59f9baafb.jpg?wh=4409x2480\" alt=\"\"></p><h3>训练和推理</h3><p>知道了加噪和去噪的过程，我们再来看看扩散模型的训练和推理环节，这里的训练针对的是刚刚提到的UNet黑盒，推理环节指的是从一个高斯噪声出发得到一张干净的图片。</p><p>你可以点开下面的图片查看原始论文中给出的总结，图片中推理环节对应的采样器为DDPM采样器，我们用这个采样器来帮助我们理解算法原理。</p><p><img src=\"https://static001.geekbang.org/resource/image/d5/cd/d5bb89b63d4e2d9779528c3db6a173cd.png?wh=2790x740\" alt=\"\"></p><p>这个总结是不是看着有点懵？我来为你稍作解释。</p><p>首先对于训练过程，假定我们已经收集了一个用于训练扩散模型的训练集，整个训练过程便是不断重复下面这六个步骤。</p><ol>\n<li>每次从数据集中随机抽取一张图片。</li>\n<li>随机从1至1000中选择一个时间步t。</li>\n<li>随机生成一个高斯噪声。</li>\n<li>根据上述加噪环节的公式，一次计算直接得到第t步加噪的结果图像。</li>\n<li>将时间步t和加噪图像作为UNet的输入去预测一个噪声值。</li>\n<li>使用第五步预测的噪声值和第三步随机生成的噪声值，计算数值误差，并回传梯度。</li>\n</ol><p>计算数值误差的公式如下图所示，细心的你一定已经发现了，这里用到的正是L2损失。</p><p><img src=\"https://static001.geekbang.org/resource/image/b7/38/b7736ea921b8f0b6c2462a38cef12338.png?wh=5100x260\" alt=\"图片\"></p><p>当我们反复循环上面的过程，直到UNet的损失函数逐渐收敛到较小的数值时，比如观测一段时间，损失函数的数值不再降低，就代表我们的扩散模型就训练完成了！</p><p>训练过程的理论学完以后，我们不妨趁热打铁，再看一下训练的代码，加深理解。</p><pre><code class=\"language-python\">for i, (x_0) in enumerate(tqdm_data_loader): \n    # 将数据加载至相应的运行设备(device)\n    x_0 = x_0.to(device)  \n    \n    # 对每一张图片随机在1~T的扩散步中进行采样\n    t = torch.randint(1, T, size=(x_0.shape[0],), device=device)\n    \n    # 取得不同t下的 根号下alpha_t的连乘  \n    sqrt_alpha_t_bar = torch.gather(sqrt_alphas_bar, dim=0, index=t).reshape(-1, 1, 1, 1)  \n    \n    # 取得不同t下的 根号下的一减alpha_t的连乘\n    sqrt_one_minus_alpha_t_bar = torch.gather(sqrt_one_minus_alphas_bar, dim=0, index=t).reshape(-1, 1, 1, 1)\n    \n    # 从标准正态分布中采样得到 \\epsilon \n    noise = torch.randn_like(x_0).to(device) \n    \n    # 计算x_t \n    x_t = sqrt_alpha_t_bar * x_0 + sqrt_one_minus_alpha_t_bar * noise  \n    \n    # 将x_t输入模型 unet，得到输出\n    out = net_model(x_t, t)  \n    \n    loss = loss_function(out, noise) # 将模型的输出，同添加的噪声做损失\n    optimizer.zero_grad()  # 优化器的梯度清零\n    loss.backward()  # 由损失反向求导\n    optimizer.step()  # 优化器更新参数\n</code></pre><p>训练好了UNet模型以后，我们就可以用它来进行推理了，也就是从噪声开始生成图像。一次去噪过程包括三步。</p><ol>\n<li>我们随机生成一个高斯噪声，作为第1000步加噪之后的结果。</li>\n<li>将这个噪声和时间步1000作为已经训练好的UNet的输入，预测第999步引入的噪声。</li>\n<li>使用采样器在步骤1的高斯噪声中去除步骤2预测的噪声，得到一张干净一点的图像。</li>\n</ol><p>这样我们就完成了一次去噪，然后以刚得到的干净一点的图像作为起点，重复第二步、第三步，便可以得到进一步去噪的图像。对于DDPM这个“黑盒”采样器来说，将上述过程重复1000次，我们便完成了从高斯噪声得到清晰图片的过程。</p><p>我们看一下推理的代码。</p><pre><code class=\"language-python\">for t_step in reversed(range(T)):  # 从T开始向零迭代\n    t = t_step\n    t = torch.tensor(t).to(device)\n    # 如果t大于零，则采样自标准正态分布，否则为零\n    z = torch.randn_like(x_t,device=device) if t_step &gt; 0 else 0  \n    \n    \"\"\"这里作为示例，按照DDPM采样器公式计算\"\"\"\n    x_t_minus_one = torch.sqrt(1/alphas[t])*\n           (x_t-(1-alphas[t])*model(x_t, t.reshape(1,))/torch.sqrt(1-alphas_bar[t]))\n           +torch.sqrt(betas[t])*z\n    \n    x_t = x_t_minus_one   \n</code></pre><p>到此为止，我们已经知道了扩散模型的算法原理。</p><h2>扩散模型 vs GAN</h2><p>你可以参考后面的对比图，来理解扩散模型和GAN的原理。</p><p><img src=\"https://static001.geekbang.org/resource/image/b4/8a/b4e35e9a2e18e733b49b26efd3c20b8a.jpg?wh=1080x352\" alt=\"\"></p><p>GAN是通过生成器、判别器对抗训练的方式来实现图像生成能力的，本质上是神经网络的左右互搏。而这一讲的扩散模型，则是通过学习一个去除噪声的过程来实现图像生成的。</p><p>通过对比的方式进行学习有助于我们加深理解，整合知识。所以我们这就来从多个维度，对比一下GAN和扩散模型的特点，你可以参考后面的表格。</p><p><img src=\"https://static001.geekbang.org/resource/image/ee/7f/eefcc0a4732d493306059ca6e670087f.jpg?wh=4262x2312\" alt=\"\"></p><h2>总结时刻</h2><p>这一讲，我们从热力学中的扩散过程出发，理论结合实践，建立起对图像扩散模型的整体认识。</p><p>加噪过程的是通过参数化马尔可夫链将干净的图片逐步变为纯噪声；去噪的过程就是从噪声出发，逐步预测噪声并去除噪声。神经网络UNet被用于预测噪声，各式各样的采样器则用于去除噪声。</p><p>之后我们一起探究了扩散模型的算法细节，包括如何从干净图片通过一步计算到达任意步数的噪声图，如何通过DDPM采样器将噪声去除。之后还了解了如何训练一个扩散模型，以及如何使用扩散模型进行推理的过程。后面第12讲里，我们还会一起动手，从头开始训练一个扩散模型，这里先埋个伏笔。</p><p>课程最后，我们结合上一讲的内容，对于扩散模型和GAN做了对比，现在你应该对新旧两代画师各自的优缺点有了更深的认识。这里我还想提示你一下，在学习扩散模型的学习过程中，如果有不懂的概念，这时我非常鼓励你去和ChatGPT聊一聊！</p><p><img src=\"https://static001.geekbang.org/resource/image/54/69/54fc3a5cd8dc7b3a8eb37ac30de52269.jpg?wh=3000x2854\" alt=\"\"></p><h2>思考题</h2><p>扩散模型生成速度慢是当前的痛点之一。了解了扩散模型的整体思路，你认为扩散模型的推理可以怎样加速呢？</p><p>欢迎你在留言区和我交流互动，也推荐你把这节课分享给有需要的朋友，说不定就能帮他更好地理解扩散模型。</p>","neighbors":{"left":{"article_title":"05｜ 旧画师GAN：天生有缺陷还是学艺不精湛？","id":678249},"right":{"article_title":"07｜AIGC的核心魔法：搞懂Transformer","id":682762}},"comments":[{"had_liked":false,"id":378831,"user_name":"springXu","can_delete":false,"product_type":"c1","uid":2064750,"ip_address":"上海","ucode":"F5DB0B963C894F","user_header":"","comment_is_top":false,"comment_ctime":1690861907,"is_pvip":true,"replies":[{"id":138101,"content":"你好。这是个很好的问题，当前UNet仍旧是去噪的主要方案，主要原因是UNet的输出和输入尺度相同，对于噪声预测比较友好（可以看下第8讲）。学者们也在试图换掉扩散模型中的 UNet 结构，比如 2022 年 12 月 UC 伯克利的学者提出了使用纯粹的Transformer 替代 UNet 结构（https:&#47;&#47;arxiv.org&#47;abs&#47;2212.09748），仍旧使用扩散模型的基本思路进行图像生成。感兴趣的话你可以看看这篇论文。希望能帮助到你。","user_name":"作者回复","user_name_real":"编辑","uid":2288210,"ctime":1691072824,"ip_address":"北京","comment_id":378831,"utype":1}],"discussion_count":4,"race_medal":0,"score":2,"product_id":100555001,"comment_content":"unet这个模型是唯一选择么？  为什么不能用其他的？  有使用其他的模型，但也是用扩散的方法的么？","like_count":2,"discussions":[{"author":{"id":2288210,"avatar":"https://static001.geekbang.org/account/avatar/00/22/ea/52/c6f6ed5a.jpg","nickname":"南柯","note":"","ucode":"957ACF2DCCD2F7","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":624943,"discussion_content":"你好。这是个很好的问题，当前UNet仍旧是去噪的主要方案，主要原因是UNet的输出和输入尺度相同，对于噪声预测比较友好（可以看下第8讲）。学者们也在试图换掉扩散模型中的 UNet 结构，比如 2022 年 12 月 UC 伯克利的学者提出了使用纯粹的Transformer 替代 UNet 结构（https://arxiv.org/abs/2212.09748），仍旧使用扩散模型的基本思路进行图像生成。感兴趣的话你可以看看这篇论文。希望能帮助到你。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1691072824,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":3,"child_discussions":[{"author":{"id":2064750,"avatar":"","nickname":"springXu","note":"","ucode":"F5DB0B963C894F","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":2288210,"avatar":"https://static001.geekbang.org/account/avatar/00/22/ea/52/c6f6ed5a.jpg","nickname":"南柯","note":"","ucode":"957ACF2DCCD2F7","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":624996,"discussion_content":"谢谢老师的回复。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1691147108,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":624943,"ip_address":"上海","group_id":0},"score":624996,"extra":""},{"author":{"id":1501385,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e8/c9/59bcd490.jpg","nickname":"听水的湖","note":"","ucode":"B1759F90165D81","race_medal":0,"user_type":8,"is_pvip":false},"reply_author":{"id":2064750,"avatar":"","nickname":"springXu","note":"","ucode":"F5DB0B963C894F","race_medal":0,"user_type":1,"is_pvip":true},"discussion":{"id":625421,"discussion_content":"多思考多提问是学习效果增倍的诀窍。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1691658500,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":624996,"ip_address":"北京","group_id":0},"score":625421,"extra":""},{"author":{"id":2064750,"avatar":"","nickname":"springXu","note":"","ucode":"F5DB0B963C894F","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1501385,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e8/c9/59bcd490.jpg","nickname":"听水的湖","note":"","ucode":"B1759F90165D81","race_medal":0,"user_type":8,"is_pvip":false},"discussion":{"id":625439,"discussion_content":"努力学习中。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1691681270,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":625421,"ip_address":"上海","group_id":0},"score":625439,"extra":""}]}]},{"had_liked":false,"id":379267,"user_name":"AdamLing","can_delete":false,"product_type":"c1","uid":3678674,"ip_address":"上海","ucode":"6538A08E352D7B","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK9TicPMurialE9OmDvQklo01poma2JDjZuaGom9bQ1SCumItbaRk0RBwrpjicHlOwHSpBpMiaSU6F2Dw/132","comment_is_top":false,"comment_ctime":1691638277,"is_pvip":false,"replies":[{"id":138199,"content":"建议先把握主线，比如尝试留言复述一下整体原理，借这种书面总结的方法检验一下自己理解程度。至于具体数学公式那里可以多看看，还可以和GPT聊一聊（21年前的知识他应该掌握得还好）。","user_name":"编辑回复","user_name_real":"编辑","uid":1501385,"ctime":1691658267,"ip_address":"北京","comment_id":379267,"utype":2}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100555001,"comment_content":"这节课对数学小白好难懂","like_count":1,"discussions":[{"author":{"id":1501385,"avatar":"https://static001.geekbang.org/account/avatar/00/16/e8/c9/59bcd490.jpg","nickname":"听水的湖","note":"","ucode":"B1759F90165D81","race_medal":0,"user_type":8,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":625417,"discussion_content":"建议先把握主线，比如尝试留言复述一下整体原理，借这种书面总结的方法检验一下自己理解程度。至于具体数学公式那里可以多看看，还可以和GPT聊一聊（21年前的知识他应该掌握得还好）。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1691658267,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":8}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":381140,"user_name":"bookchan","can_delete":false,"product_type":"c1","uid":1327497,"ip_address":"广东","ucode":"6C40EEAC767E25","user_header":"https://static001.geekbang.org/account/avatar/00/14/41/89/77d3e613.jpg","comment_is_top":false,"comment_ctime":1694709423,"is_pvip":false,"replies":[{"id":138997,"content":"你好。x_t 可以从原始图像 x_0 一次计算得到，这是因为在噪声计算的过程中做了近似，从x_0计算x_1、从x_1计算x_2、最终计算到x_t，把每一步加入的噪声用统一的高斯分布ϵ来表示，可以理解为是一种偷懒的加噪计算。而去噪过程是不能这样近似算的，我们要预测的就是第t步到第t-1步的噪声ϵ。而不是第t步到第0步的噪声ϵ。关于这个过程，推荐仔细看看DDPM论文的推导过程。希望对你有帮助。","user_name":"作者回复","user_name_real":"编辑","uid":2288210,"ctime":1695567625,"ip_address":"北京","comment_id":381140,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100555001,"comment_content":"有公式使得x_t 也可以从原始图像 x_0 一次计算得到，unet预测的是最开始的随机噪声。那么推理的时候，随机生成t步的加噪图片，根据unet预测随机噪声，那么公式反过来，我们不就一步可以直接计算得到x_0了，也就是原图，为啥还得那么多步采样。","like_count":0,"discussions":[{"author":{"id":2288210,"avatar":"https://static001.geekbang.org/account/avatar/00/22/ea/52/c6f6ed5a.jpg","nickname":"南柯","note":"","ucode":"957ACF2DCCD2F7","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":628596,"discussion_content":"你好。x_t 可以从原始图像 x_0 一次计算得到，这是因为在噪声计算的过程中做了近似，从x_0计算x_1、从x_1计算x_2、最终计算到x_t，把每一步加入的噪声用统一的高斯分布ϵ来表示，可以理解为是一种偷懒的加噪计算。而去噪过程是不能这样近似算的，我们要预测的就是第t步到第t-1步的噪声ϵ。而不是第t步到第0步的噪声ϵ。关于这个过程，推荐仔细看看DDPM论文的推导过程。希望对你有帮助。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1695567625,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":381139,"user_name":"bookchan","can_delete":false,"product_type":"c1","uid":1327497,"ip_address":"广东","ucode":"6C40EEAC767E25","user_header":"https://static001.geekbang.org/account/avatar/00/14/41/89/77d3e613.jpg","comment_is_top":false,"comment_ctime":1694707754,"is_pvip":false,"replies":[{"id":138996,"content":"你好。在实际训练过程中，我们是按照batch训练的，而且通常会使用较大的batch_size。这里说的随机抽取一张图片是针对伪代码的解读，方便读者理解。","user_name":"作者回复","user_name_real":"编辑","uid":2288210,"ctime":1695566843,"ip_address":"北京","comment_id":381139,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100555001,"comment_content":"老师，训练说到“每次从数据集中随机抽取一张图片”。不能够随机抽取batch张图片，提高训练并发度吗？","like_count":0,"discussions":[{"author":{"id":2288210,"avatar":"https://static001.geekbang.org/account/avatar/00/22/ea/52/c6f6ed5a.jpg","nickname":"南柯","note":"","ucode":"957ACF2DCCD2F7","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":628595,"discussion_content":"你好。在实际训练过程中，我们是按照batch训练的，而且通常会使用较大的batch_size。这里说的随机抽取一张图片是针对伪代码的解读，方便读者理解。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1695566844,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":380556,"user_name":"互联网砖瓦匠","can_delete":false,"product_type":"c1","uid":1856981,"ip_address":"北京","ucode":"7A70CFADCBEEC4","user_header":"","comment_is_top":false,"comment_ctime":1693816642,"is_pvip":false,"replies":[{"id":138667,"content":"你好，为了降低理解难度，我们跳过了很多数学推导。如果不是相关算法从业者，只需要了解整体思路、清楚扩散模型和GAN是不同的算法原理即可。希望能帮助到你。","user_name":"作者回复","user_name_real":"编辑","uid":2288210,"ctime":1694268329,"ip_address":"北京","comment_id":380556,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100555001,"comment_content":"我感觉这些原理我看了顶多是做个了解了 数学渣渣 哈哈。","like_count":0,"discussions":[{"author":{"id":2288210,"avatar":"https://static001.geekbang.org/account/avatar/00/22/ea/52/c6f6ed5a.jpg","nickname":"南柯","note":"","ucode":"957ACF2DCCD2F7","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":627557,"discussion_content":"你好，为了降低理解难度，我们跳过了很多数学推导。如果不是相关算法从业者，只需要了解整体思路、清楚扩散模型和GAN是不同的算法原理即可。希望能帮助到你。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1694268329,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":379991,"user_name":"明远","can_delete":false,"product_type":"c1","uid":1060611,"ip_address":"湖北","ucode":"DF81DF678CB0B1","user_header":"https://static001.geekbang.org/account/avatar/00/10/2f/03/f2c008fc.jpg","comment_is_top":false,"comment_ctime":1692793139,"is_pvip":false,"replies":[{"id":138502,"content":"你好，这个问题在第9讲采样器中会展开讨论，这里我简单解释一下。我们在训练扩散模型的时候，加噪的方式非常朴素，每一步等于上一步加上一个高斯噪声。训练的过程是拟合这个噪声，训练过程和采样器是完全解耦的，并没有特意去遵循某种采样器的计算方法。希望能够帮助到你。","user_name":"作者回复","user_name_real":"编辑","uid":2288210,"ctime":1693380637,"ip_address":"北京","comment_id":379991,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100555001,"comment_content":"&gt;&gt; 公式中，xt​ 表示第 t 步的加噪结果；xt−1​ 表示第 t-1 步的加噪结果；αt​ 是一个预先设置的超参数，用于控制随时间步的加噪强弱，你可以理解为预先设定从 α1​ 到 α1000​ 1000 个参数；ϵ 表示一个随机的高斯噪声。\n\n为什么采样器不会影响加噪的结果，这个公式是不是将加噪采样器设定为固定值了？为什么去噪声的过程可以使用不同的采样器呢？\n","like_count":0,"discussions":[{"author":{"id":2288210,"avatar":"https://static001.geekbang.org/account/avatar/00/22/ea/52/c6f6ed5a.jpg","nickname":"南柯","note":"","ucode":"957ACF2DCCD2F7","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":626779,"discussion_content":"你好，这个问题在第9讲采样器中会展开讨论，这里我简单解释一下。我们在训练扩散模型的时候，加噪的方式非常朴素，每一步等于上一步加上一个高斯噪声。训练的过程是拟合这个噪声，训练过程和采样器是完全解耦的，并没有特意去遵循某种采样器的计算方法。希望能够帮助到你。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1693380637,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":379382,"user_name":"cmsgoogle","can_delete":false,"product_type":"c1","uid":1746343,"ip_address":"浙江","ucode":"CD69D796709195","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLhs7ykGEy46a8ljg3LPvXTRxpgMLEhvZoAYIQL6I46OEqbNV4U1mXryhJt1bE3mhf7ey6jfl3IyQ/132","comment_is_top":false,"comment_ctime":1691852588,"is_pvip":false,"replies":[{"id":138307,"content":"你好。推理过程伪代码展示的是DDPM的采样过程，torch.sqrt(betas[t])*z这一项其实是引入了随机噪声，可以理解为高斯分布中的方差项，因此每一步采样都具有一定随机性。事实上在DDIM采样器中，这一项就被拿掉了，采样过程变得确定。 希望能帮助到你。","user_name":"作者回复","user_name_real":"编辑","uid":2288210,"ctime":1692324811,"ip_address":"北京","comment_id":379382,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100555001,"comment_content":"推理过程的伪代码第4行X\\_t-1的生成，第一部分是去噪，第二部分为什么又加了一个噪音，应该去再解释一下。或者留个伏笔在后续章节再详细解释。","like_count":0,"discussions":[{"author":{"id":2288210,"avatar":"https://static001.geekbang.org/account/avatar/00/22/ea/52/c6f6ed5a.jpg","nickname":"南柯","note":"","ucode":"957ACF2DCCD2F7","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":625913,"discussion_content":"你好。推理过程伪代码展示的是DDPM的采样过程，torch.sqrt(betas[t])*z这一项其实是引入了随机噪声，可以理解为高斯分布中的方差项，因此每一步采样都具有一定随机性。事实上在DDIM采样器中，这一项就被拿掉了，采样过程变得确定。 希望能帮助到你。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1692324811,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":378690,"user_name":"一只豆","can_delete":false,"product_type":"c1","uid":1003886,"ip_address":"广东","ucode":"73953B25ADC953","user_header":"https://static001.geekbang.org/account/avatar/00/0f/51/6e/efb76357.jpg","comment_is_top":false,"comment_ctime":1690620490,"is_pvip":false,"replies":[{"id":137985,"content":"你好。这是个很好的问题，也是当下很多企业在做的事情。假定A100显卡充足、资金充足、标注员充足，我个人觉得有两种思路：第一，从各种渠道抓取海量数据、找标注员做美学标注，然后用海量优质的数据去finetune最头部的开源模型。这种模式得到的模型在垂类领域大概率会比开源社区好不少。第二，探索Parti这类自回归的方案。这条路的问题在于训练框架没有SD成熟，但搞不好能做出更颠覆的东西。效果上，企业最想拿到的应该还是对标Midjourney的大模型、指令级修图能力、单图不训练的「妙鸭相机」类效果等，这几个事情至少当前开源社区轻量化的方法还是做不到的。也感谢你的建议，在第三章（经典模型方案），我们会更多探讨这些问题。感谢你的反馈，希望能帮到你。","user_name":"作者回复","user_name_real":"编辑","uid":2288210,"ctime":1690646538,"ip_address":"北京","comment_id":378690,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100555001,"comment_content":"周末看咱们整体课程目录，畅想这个单元“基础篇：AI绘画原理揭秘”的学习，看到单元末尾处的“实战项目（二）动手训练一个你自己的扩散模型” 时忽然冒出一个问题：\n现在 Embedding&#47;LoRa&#47;Hypernetwork这么流行(还可多个相互配合使用)，还有Controlnet这种可控出图的神器，那么，在何种情况下（假设预算充足，追求垂直领域效果世界一流），对 Diffusion model进行什么样的定制化训练能够实现上面这些 轻量级方法不能达到的 什么样的效果呢？\n我相信未来的几节原理课可能会点点滴滴的回答这个问题～ 但也许可以把这个问题当作一个 核心问题 脉络化在未来的几节课程中。。。再次感谢老师深入浅出的课程设置思想。","like_count":0,"discussions":[{"author":{"id":2288210,"avatar":"https://static001.geekbang.org/account/avatar/00/22/ea/52/c6f6ed5a.jpg","nickname":"南柯","note":"","ucode":"957ACF2DCCD2F7","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":624522,"discussion_content":"你好。这是个很好的问题，也是当下很多企业在做的事情。假定A100显卡充足、资金充足、标注员充足，我个人觉得有两种思路：第一，从各种渠道抓取海量数据、找标注员做美学标注，然后用海量优质的数据去finetune最头部的开源模型。这种模式得到的模型在垂类领域大概率会比开源社区好不少。第二，探索Parti这类自回归的方案。这条路的问题在于训练框架没有SD成熟，但搞不好能做出更颠覆的东西。效果上，企业最想拿到的应该还是对标Midjourney的大模型、指令级修图能力、单图不训练的「妙鸭相机」类效果等，这几个事情至少当前开源社区轻量化的方法还是做不到的。也感谢你的建议，在第三章（经典模型方案），我们会更多探讨这些问题。感谢你的反馈，希望能帮到你。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1690646538,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":1003886,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/51/6e/efb76357.jpg","nickname":"一只豆","note":"","ucode":"73953B25ADC953","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2288210,"avatar":"https://static001.geekbang.org/account/avatar/00/22/ea/52/c6f6ed5a.jpg","nickname":"南柯","note":"","ucode":"957ACF2DCCD2F7","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":624530,"discussion_content":"多谢指点，我会在第三章的学习过程中更多体会这个问题。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1690649406,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":624522,"ip_address":"广东","group_id":0},"score":624530,"extra":""}]}]},{"had_liked":false,"id":378671,"user_name":"peter","can_delete":false,"product_type":"c1","uid":1058183,"ip_address":"北京","ucode":"261C3FC001DE2D","user_header":"https://static001.geekbang.org/account/avatar/00/10/25/87/f3a69d1b.jpg","comment_is_top":false,"comment_ctime":1690581276,"is_pvip":false,"replies":[{"id":137986,"content":"你好。针对Q1，讨论加噪是为了用干净的图片训练UNet模型，我们最终的目标是从随机噪声出发、生成干净图片（也就是去噪过程，这样不就能创造全新的图像了么）。所以，你可以这样理解，加噪针对训练过程、去噪针对使用过程。课程中我们并没有过多论述加噪去噪背后的数学推导，只是给出结论从噪声到图像是可行的（推导部分更加烧脑，可以看看DDPM论文的论证部分）。针对Q2，数字人想过可以了解下MSRA的rodin（https:&#47;&#47;www.microsoft.com&#47;en-us&#47;research&#47;publication&#47;rodin-a-generative-model-for-sculpting-3d-digital-avatars-using-diffusion&#47;），真正可商用的3D AIGC数字人还没有看到很靠谱的。希望能帮助到你。","user_name":"作者回复","user_name_real":"编辑","uid":2288210,"ctime":1690647001,"ip_address":"北京","comment_id":378671,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100555001,"comment_content":"请教老师两个问题：\nQ1：先加噪声，再去噪，还是不太理解为什么这样做？\n喝了一口水，然后再吐掉，有意思吗？为什么就有作用？\n\nQ2：前导篇中提到的数字人有具体产品吗？\n具体产品是指：具体的网站，或者具体的客户端软件，都可以，能做出数字人。我想做一个数字人，需要用具体产品，但不知道哪个产品能做出数字人。","like_count":0,"discussions":[{"author":{"id":2288210,"avatar":"https://static001.geekbang.org/account/avatar/00/22/ea/52/c6f6ed5a.jpg","nickname":"南柯","note":"","ucode":"957ACF2DCCD2F7","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":624523,"discussion_content":"你好。针对Q1，讨论加噪是为了用干净的图片训练UNet模型，我们最终的目标是从随机噪声出发、生成干净图片（也就是去噪过程，这样不就能创造全新的图像了么）。所以，你可以这样理解，加噪针对训练过程、去噪针对使用过程。课程中我们并没有过多论述加噪去噪背后的数学推导，只是给出结论从噪声到图像是可行的（推导部分更加烧脑，可以看看DDPM论文的论证部分）。针对Q2，数字人想过可以了解下MSRA的rodin（https://www.microsoft.com/en-us/research/publication/rodin-a-generative-model-for-sculpting-3d-digital-avatars-using-diffusion/），真正可商用的3D AIGC数字人还没有看到很靠谱的。希望能帮助到你。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1690647002,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":378669,"user_name":"AI悦创","can_delete":false,"product_type":"c1","uid":1525309,"ip_address":"福建","ucode":"D1007711CB0A79","user_header":"https://static001.geekbang.org/account/avatar/00/17/46/3d/55653953.jpg","comment_is_top":false,"comment_ctime":1690563614,"is_pvip":false,"replies":[{"id":137989,"content":"你好。感谢你的反馈。这一讲对于扩散模型初学者会有难度，可以先通过这一讲建立整体的认识，知道加噪用于训练、去噪用于生成，以及关键结论即可。初期不必过度关注数学部分。第二章更完，你可以试着把06-11讲的知识点串起来，才能理解技术全貌。课程中的数学部分，我会根据同学们的反馈再做完善。再次感谢你的建议。","user_name":"作者回复","user_name_real":"编辑","uid":2288210,"ctime":1690647490,"ip_address":"北京","comment_id":378669,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100555001,"comment_content":"到这条评论的时候，我读完了。\n\n个人感受：这篇文章写的感觉很不错，但是读了之后但又有一些不理解的地方，具体例如：数学公式、数学公式的讲解等等知识点，感觉云里雾里，我觉得不好说好不好，希望老师后面有时间完善完善，我也会这几天再重新阅读一下，再次评论。期待老师的回复。","like_count":0,"discussions":[{"author":{"id":2288210,"avatar":"https://static001.geekbang.org/account/avatar/00/22/ea/52/c6f6ed5a.jpg","nickname":"南柯","note":"","ucode":"957ACF2DCCD2F7","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":624526,"discussion_content":"你好。感谢你的反馈。这一讲对于扩散模型初学者会有难度，可以先通过这一讲建立整体的认识，知道加噪用于训练、去噪用于生成，以及关键结论即可。初期不必过度关注数学部分。第二章更完，你可以试着把06-11讲的知识点串起来，才能理解技术全貌。课程中的数学部分，我会根据同学们的反馈再做完善。再次感谢你的建议。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1690647490,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":378665,"user_name":"AI悦创","can_delete":false,"product_type":"c1","uid":1525309,"ip_address":"福建","ucode":"D1007711CB0A79","user_header":"https://static001.geekbang.org/account/avatar/00/17/46/3d/55653953.jpg","comment_is_top":false,"comment_ctime":1690554219,"is_pvip":false,"replies":[{"id":137991,"content":"你好。因为我们默认，x0代表原图，x1000代表纯粹的噪声。这只是扩散模型中大家的约定说法。希望有帮助～","user_name":"作者回复","user_name_real":"编辑","uid":2288210,"ctime":1690647636,"ip_address":"北京","comment_id":378665,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100555001,"comment_content":"对于 Diffusion 模型的加噪过程，每一步加噪依赖于时间步 t。t 越接近 0，当前加噪结果越靠近原始图像；t 越接近 1000，当前加噪结果越靠近纯噪声。\n\n问题：为什么接近0就是原图？没 get 到","like_count":0,"discussions":[{"author":{"id":2288210,"avatar":"https://static001.geekbang.org/account/avatar/00/22/ea/52/c6f6ed5a.jpg","nickname":"南柯","note":"","ucode":"957ACF2DCCD2F7","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":624528,"discussion_content":"你好。因为我们默认，x0代表原图，x1000代表纯粹的噪声。这只是扩散模型中大家的约定说法。希望有帮助～","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1690647637,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":378664,"user_name":"AI悦创","can_delete":false,"product_type":"c1","uid":1525309,"ip_address":"福建","ucode":"D1007711CB0A79","user_header":"https://static001.geekbang.org/account/avatar/00/17/46/3d/55653953.jpg","comment_is_top":false,"comment_ctime":1690553772,"is_pvip":false,"replies":[{"id":137990,"content":"是的，webUI中，我们选择的采样步数，就是这里去噪的步数。你的理解完全准确。","user_name":"作者回复","user_name_real":"编辑","uid":2288210,"ctime":1690647549,"ip_address":"北京","comment_id":378664,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100555001,"comment_content":"这个步数：实验中整个加噪过程中需要 1000 次加噪操作。直觉上，从纯噪声去噪得到图像也需要 1000 次去噪操作来完成。不过，实际使用中，通过数学推导的方式可以证明并不需要 1000 步，比如我们第 1 讲中用到的 Eular 采样器，只需要 20~30 步去噪，便可以从纯噪声去噪得到清晰的图片。\n\n是不是就是 webui 中的那个步数？","like_count":0,"discussions":[{"author":{"id":2288210,"avatar":"https://static001.geekbang.org/account/avatar/00/22/ea/52/c6f6ed5a.jpg","nickname":"南柯","note":"","ucode":"957ACF2DCCD2F7","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":624527,"discussion_content":"是的，webUI中，我们选择的采样步数，就是这里去噪的步数。你的理解完全准确。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1690647549,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":378628,"user_name":"王大叶","can_delete":false,"product_type":"c1","uid":1217905,"ip_address":"北京","ucode":"AA4BA0EF1D8AC0","user_header":"https://static001.geekbang.org/account/avatar/00/12/95/71/20b96bc8.jpg","comment_is_top":false,"comment_ctime":1690513908,"is_pvip":false,"replies":[{"id":137988,"content":"你好。1000这个数是大家常用的超参数，实际上，用其他数值也是可以的。推理过程的Sampling steps就是去噪步数，理论上也需要1000，但实际上经常用20、30、50这样的步数。以20为例，相当于一次性去除1000&#47;20=50步的噪声。采样器那一讲我们会深入探讨这个问题。希望能帮助到你。","user_name":"作者回复","user_name_real":"编辑","uid":2288210,"ctime":1690647288,"ip_address":"北京","comment_id":378628,"utype":1}],"discussion_count":2,"race_medal":0,"score":3,"product_id":100555001,"comment_content":"「t 的取值为 1-1000 中的一个整数，代表加噪声的步数」 这里的 1000 是固定取值吗，为什么是 1000？这个和推理过程中的 Sampling steps 是什么关系？ ","like_count":0,"discussions":[{"author":{"id":2288210,"avatar":"https://static001.geekbang.org/account/avatar/00/22/ea/52/c6f6ed5a.jpg","nickname":"南柯","note":"","ucode":"957ACF2DCCD2F7","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":624525,"discussion_content":"你好。1000这个数是大家常用的超参数，实际上，用其他数值也是可以的。推理过程的Sampling steps就是去噪步数，理论上也需要1000，但实际上经常用20、30、50这样的步数。以20为例，相当于一次性去除1000/20=50步的噪声。采样器那一讲我们会深入探讨这个问题。希望能帮助到你。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1690647288,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":3683389,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/ccCGDRLarBQWib8tSOpV4jgh7x86BjI4AjWWbaiaWuwzbibzh4OWU0IxvjVmvEhEkzCB8fn2CyJpauH7mSVAXQFVA/132","nickname":"Geek_a7f70d","note":"","ucode":"99425463EC8D02","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":624406,"discussion_content":"2000也可以的，看你想设定多少步而已，建模时可以多尝试不同的时间步，哪个效果好，最终就采用哪个。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1690537425,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":378616,"user_name":"和某欢","can_delete":false,"product_type":"c1","uid":2120663,"ip_address":"四川","ucode":"5E0F27533597F1","user_header":"https://static001.geekbang.org/account/avatar/00/20/5b/d7/d88c1850.jpg","comment_is_top":false,"comment_ctime":1690505900,"is_pvip":false,"replies":[{"id":137987,"content":"马上我们就要拆解SD模型的各个模块，继续加油！","user_name":"作者回复","user_name_real":"编辑","uid":2288210,"ctime":1690647144,"ip_address":"北京","comment_id":378616,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100555001,"comment_content":"经历了前面几篇文章的铺垫，终于来到了sd详解篇章！感谢老师的讲解，现在对于sd模型有了大概的了解🫡","like_count":0,"discussions":[{"author":{"id":2288210,"avatar":"https://static001.geekbang.org/account/avatar/00/22/ea/52/c6f6ed5a.jpg","nickname":"南柯","note":"","ucode":"957ACF2DCCD2F7","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":624524,"discussion_content":"马上我们就要拆解SD模型的各个模块，继续加油！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1690647144,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":390245,"user_name":"hallo128","can_delete":false,"product_type":"c1","uid":1212044,"ip_address":"云南","ucode":"3921D6E11CFCB1","user_header":"https://static001.geekbang.org/account/avatar/00/12/7e/8c/f029535a.jpg","comment_is_top":false,"comment_ctime":1714896500,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100555001,"comment_content":"扩散模型的数学公式推导，可以去看下这篇文献：Understanding Diffusion Models: A Unified Perspective。当然，我也做了这篇文献的精读视频，感兴趣的伙伴可以去看下：\n【https:&#47;&#47;www.bilibili.com&#47;video&#47;BV1Em421s7WB&#47;?share_source=copy_web&amp;vd_source=591ed5b4226ab314d67afd7e30b5aac5】","like_count":1}]}