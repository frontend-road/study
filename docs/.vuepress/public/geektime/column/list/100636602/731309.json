{"id":731309,"title":"ChatGPT 的训练","content":"<p>我们已经概述了 ChatGPT 在设置后的工作方式。但是它是如何设置的呢？那 1750 亿个神经元的权重是如何确定的呢？基本上，这是基于包含人类所写文本的巨型语料库（来自互联网、书籍等），通过大规模训练得出的结果。正如我们所说，即使有所有这些训练数据，也不能肯定神经网络能够成功地产生“类人”文本。似乎需要细致的工程设计才能实现这一点。但是，ChatGPT 带来的一大惊喜和发现是，它完全可以做到。实际上，“只有 1750 亿个权重”的神经网络就可以构建出人类所写文本的一个“合理模型”。</p><p>现代社会中，人类写的很多文本以数字（digital）形式存在。公共互联网上至少有数十亿个包含人类所写文本的网页，总词数可能达到万亿级别。如果包括非公开的网页，词数可能会增加至少 100 倍。到目前为止，已经有超过 500 万本电子书可供阅读（全球发行的图书品种总数为 1 亿左右），提供了另外约 1000 亿个词的文本。这还不包括视频中的口述文本等。（就个人而言，我一生中发表的文字总量不到 300 万个词，在过去 30 年中写下了约 1500 万个词的电子邮件，总共敲了大约 5000 万个词—而且仅在过去几年的直播中，我就说了超过 1000 万个词。是的，我会从中训练一个机器人。）</p><!-- [[[read_end]]] --><p>但是，有了所有这些数据，要如何训练神经网络呢？基本过程与上面讨论的简单示例非常相似：先提供一批样例，然后调整网络中的权重，以最小化网络在这些样例上的误差（“损失”）。根据误差“反向传播”的主要问题在于，每次执行此操作时，网络中的每个权重通常都至少会发生微小的变化，而且有很多权重需要处理。（实际的“反向传播”通常只比前向传播难一点儿—相差一个很小的常数系数。）</p><p>使用现代 GPU 硬件，可以轻松地从成千上万个样例中并行计算出结果。但是，当涉及实际更新神经网络中的权重时，当前的方法基本上会要求逐批进行。（是的，这可能是结合了计算元素和记忆元素的真实大脑至少在现阶段具有架构优势的地方。）</p><p>即使在学习数值函数这样看似简单的案例中，我们通常也需要使用数百万个样例才能成功地训练网络，至少对于从头开始训练来说是这样的。那么需要多少样例才能训练出“类人语言”模型呢？似乎无法通过任何基本的“理论”方法知道。但在实践中，ChatGPT 成功地在包含几百亿个词的文本上完成了训练。</p><p>虽然有些文本被输入了多次，有些只输入了一次，但 ChatGPT 从它看到的文本中“得到了所需的信息”。考虑到有这么多文本需要学习，它需要多大的网络才能“学得好”呢？目前，我们还没有基本的理论方法来回答这个问题。最终，就像下面将进一步讨论的那样，对于人类语言和人类通常用它说什么，可能有某种“总体算法内容”。而下一个问题是：神经网络在基于该算法内容实现模型时会有多高效？我们还是不知道，尽管 ChatGPT 的成功表明它是相当高效的。</p><p>最终，我们只需注意到 ChatGPT 使用了近 2000 亿个权重来完成其工作—数量与其接受的训练数据中的词（或标记）的总数相当。在某些方面，运作良好的“网络的规模”与“训练数据的规模”如此相似或许令人惊讶（在与 ChatGPT 结构相似的较小网络中实际观察到的情况也是如此）。毕竟，ChatGPT 内部并没有直接存储来自互联网、书籍等的所有文本。因为 ChatGPT 内部实际上是一堆数（精度不到 10 位），它们是所有文本的总体结构的某种分布式编码。</p><p>换句话说，我们可以问人类语言的“有效信息”是什么，以及人类通常用它说些什么。我们有语言样例的原始语料库。在 ChatGPT 的神经网络中，还有对它们的表示。这些表示很可能远非“算法上最小”的表示，正如下面将讨论的那样。但它们是神经网络可以轻松使用的表示。在这种表示中，训练数据的“压缩”程度似乎很低。平均而言，似乎只需要不到一个神经网络的权重就可以承载一个词的训练数据的“信息内容”。</p><p>当我们运行 ChatGPT 来生成文本时，基本上每个权重都需要使用一次。因此，如果有 <em>n</em> 个权重，就需要执行约 <em>n</em> 个计算步骤—尽管在实践中，许多计算步骤通常可以在 GPU 中并行执行。但是，如果需要约 <em>n</em> 个词的训练数据来设置这些权重，那么如上所述，我们可以得出结论：需要约<em>n</em>²个计算步骤来进行网络的训练。这就是为什么使用当前的方法最终需要耗费数十亿美元来进行训练。</p><br style=\"page-break-after:always\">","neighbors":{"left":{"article_title":"ChatGPT 的内部原理","id":731308},"right":{"article_title":"在基础训练之外","id":731310}},"comments":[]}