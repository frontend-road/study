{"id":363445,"title":"16 | 内存视角（二）：如何有效避免Cache滥用？","content":"<p>你好，我是吴磊。</p><p>在Spark的应用开发中，有效利用Cache往往能大幅提升执行性能。</p><p>但某一天，有位同学却和我说，自己加了Cache之后，执行性能反而变差了。仔细看了这位同学的代码之后，我吓了一跳。代码中充斥着大量的<code>.cache</code>，无论是RDD，还是DataFrame，但凡有分布式数据集的地方，后面几乎都跟着个<code>.cache</code>。显然，Cache滥用是执行性能变差的始作俑者。</p><p>实际上，在有些场景中，Cache是灵丹妙药，而在另一些场合，大肆使用Cache却成了饮鸩止渴。那Cache到底该在什么时候用、怎么用，都有哪些注意事项呢？今天这一讲，我们先一起回顾Cache的工作原理，再来回答这些问题。</p><h2>Cache的工作原理</h2><p>在<a href=\"https://time.geekbang.org/column/article/355081\">存储系统</a>那一讲，我们其实介绍过RDD的缓存过程，只不过当时的视角是以MemoryStore为中心，目的在于理解存储系统的工作原理，今天咱们把重点重新聚焦到缓存上来。</p><p>Spark的Cache机制主要有3个方面需要我们掌握，它们分别是：</p><ul>\n<li>缓存的存储级别：它限定了数据缓存的存储介质，如内存、磁盘等</li>\n<li>缓存的计算过程：从RDD展开到分片以Block的形式，存储于内存或磁盘的过程</li>\n<li>缓存的销毁过程：缓存数据以主动或是被动的方式，被驱逐出内存或是磁盘的过程</li>\n</ul><!-- [[[read_end]]] --><p>下面，我们一一来看。</p><h3>存储级别</h3><p>Spark中的Cache支持很多种存储级别，比如MEMORY_AND_DISK_SER_2、MEMORY_ONLY等等。这些长得差不多的字符串我们该怎么记忆和区分呢？其实，<strong>每一种存储级别都包含3个基本要素</strong>。</p><ul>\n<li>存储介质：内存还是磁盘，或是两者都有。</li>\n<li>存储形式：对象值还是序列化的字节数组，带SER字样的表示以序列化方式存储，不带SER则表示采用对象值。</li>\n<li>副本数量：存储级别名字最后的数字代表拷贝数量，没有数字默认为1份副本。</li>\n</ul><p><img src=\"https://static001.geekbang.org/resource/image/4e/e2/4ecdfd4b62b1c6e151d029c38088yye2.jpeg?wh=1920*1000\" alt=\"\" title=\"Cache存储级别\"></p><p>当我们对五花八门的存储级别拆解之后就会发现，它们不过是存储介质、存储形式和副本数量这3类不同基本元素的排列组合而已。我在上表中列出了目前Spark支持的所有存储级别，你可以通过它加深理解。</p><p>尽管缓存级别多得让人眼花缭乱，但实际上<strong>最常用的只有两个：MEMORY_ONLY和MEMORY_AND_DISK，它们分别是RDD缓存和DataFrame缓存的默认存储级别</strong>。在日常的开发工作中，当你在RDD和DataFrame之上调用<code>.cache</code>函数时，Spark默认采用的就是MEMORY_ONLY和MEMORY_AND_DISK。</p><h3>缓存的计算过程</h3><p>在MEMORY_AND_DISK模式下，Spark会优先尝试把数据集全部缓存到内存，内存不足的情况下，再把剩余的数据落盘到本地。MEMORY_ONLY则不管内存是否充足，而是一股脑地把数据往内存里塞，即便内存不够也不会落盘。不难发现，<strong>这两种存储级别都是先尝试把数据缓存到内存</strong>。数据在内存中的存储过程我们在<a href=\"https://time.geekbang.org/column/article/355081\">第6讲</a>中讲过了，这里我们再一起回顾一下。</p><p><img src=\"https://static001.geekbang.org/resource/image/8f/e2/8fc350146a7yyb0448303d7f1f094be2.jpg?wh=3936*1818\" alt=\"\" title=\"分布式数据集缓存到内存\"></p><p>无论是RDD还是DataFrame，它们的数据分片都是以迭代器Iterator的形式存储的。因此，要把数据缓存下来，我们先得把迭代器展开成实实在在的数据值，这一步叫做Unroll，如步骤1所示。展开的对象值暂时存储在一个叫做ValuesHolder的数据结构里，然后转换为MemoryEntry。转换的实现方式是toArray，因此它不产生额外的内存开销，这一步转换叫做Transfer，如步骤2所示。最终，MemoryEntry和与之对应的BlockID，以Key、Value的形式存储到哈希字典（LinkedHashMap）中，如图中的步骤3所示。</p><p>当分布式数据集所有的数据分片都从Unroll到Transfer，再到注册哈希字典之后，数据在内存中的缓存过程就宣告完毕。</p><h3>缓存的销毁过程</h3><p>但是很多情况下，应用中数据缓存的需求会超过Storage Memory区域的空间供给。虽然缓存任务可以抢占Execution Memory区域的空间，但“出来混，迟早是要还的”，随着执行任务的推进，缓存任务抢占的内存空间还是要“吐”出来。这个时候，Spark就要执行缓存的销毁过程。</p><p>你不妨把Storage Memory想象成一家火爆的网红餐厅，待缓存的数据分片是一位又一位等待就餐的顾客。当需求大于供给，顾客数量远超餐位数量的时候，Spark自然要制定一些规则，来合理地“驱逐”那些尸位素餐的顾客，把位置腾出来及时服务那些排队等餐的人。</p><p>那么问题来了，Spark基于什么规则“驱逐”顾客呢？接下来，我就以同时缓存多个分布式数据集的情况为例，带你去分析一下在内存受限的情况下会发生什么。</p><p>我们用一张图来演示这个过程，假设MemoryStore中存有4个RDD/Data  Frame的缓存数据，这4个分布式数据集各自缓存了一些数据分片之后，Storage Memory区域就被占满了。当RDD1尝试把第6个分片缓存到MemoryStore时，却发现内存不足，塞不进去了。</p><p>这种情况下，<strong>Spark就会逐一清除一些“尸位素餐”的MemoryEntry来释放内存，从而获取更多的可用空间来存储新的数据分片</strong>。这个过程叫做Eviction，它的中文翻译还是蛮形象的，就叫做驱逐，也就是把MemoryStore中那些倒霉的MemoryEntry驱逐出内存。</p><p><img src=\"https://static001.geekbang.org/resource/image/b7/14/b73308328ef549579d02c72afb2ab114.jpg?wh=5828*1798\" alt=\"\" title=\"多个分布式数据集同时缓存到内存\"></p><p>回到刚才的问题，Spark是根据什么规则选中的这些倒霉蛋呢？这个规则叫作LRU（Least Recently Used），基于这个算法，最近访问频率最低的那个家伙就是倒霉蛋。因为<a href=\"https://baike.baidu.com/item/LRU/1269842?fr=aladdin\">LRU</a>是比较基础的数据结构算法，笔试、面试的时候经常会考，所以它的概念我就不多说了。</p><p>我们要知道的是，Spark是如何实现LRU的。这里，<strong>Spark使用了一个巧妙的数据结构：LinkedHashMap，这种数据结构天然地支持LRU算法</strong>。</p><p>LinkedHashMap使用两个数据结构来维护数据，一个是传统的HashMap，另一个是双向链表。HashMap的用途在于快速访问，根据指定的BlockId，HashMap以O(1)的效率返回MemoryEntry。双向链表则不同，它主要用于维护元素（也就是BlockId和MemoryEntry键值对）的访问顺序。凡是被访问过的元素，无论是插入、读取还是更新都会被放置到链表的尾部。因此，链表头部保存的刚好都是“最近最少访问”的元素。</p><p>如此一来，当内存不足需要驱逐缓存的数据块时，Spark只利用LinkedHashMap就可以做到按照“最近最少访问”的原则，去依次驱逐缓存中的数据分片了。</p><p>除此之外，在存储系统那一讲，有同学问MemoryStore为什么使用LinkedHashMap，而不用普通的Map来存储BlockId和MemoryEntry的键值对。我刚才说的就是答案了。</p><p>回到图中的例子，当RDD1试图缓存第6个数据分片，但可用内存空间不足时，Spark 会对LinkedHashMap从头至尾扫描，边扫描边记录MemoryEntry大小，当倒霉蛋的总大小超过第6个数据分片时，Spark停止扫描。</p><p>有意思的是，<strong>倒霉蛋的选取规则遵循“兔子不吃窝边草”，同属一个RDD的MemoryEntry不会被选中</strong>。就像图中的步骤4展示的一样，第一个蓝色的MemoryEntry会被跳过，紧随其后打叉的两个MemoryEntry被选中。</p><p>因此，总结下来，在清除缓存的过程中，Spark遵循两个基本原则：</p><ul>\n<li>LRU：按照元素的访问顺序，优先清除那些“最近最少访问”的BlockId、MemoryEntry键值对</li>\n<li>兔子不吃窝边草：在清除的过程中，同属一个RDD的MemoryEntry拥有“赦免权”</li>\n</ul><h3>退化为MapReduce</h3><p>尽管有缓存销毁这个环节的存在，Storage Memory内存空间也总会耗尽，MemoryStore也总会“驱无可驱”。这个时候，MEMORY_ONLY模式就会放弃剩余的数据分片。比如，在Spark UI上，你时常会看到Storage Tab中的缓存比例低于100%。而我们从Storage Tab也可以观察到，在MEMORY_AND_DISK模式下，数据集在内存和磁盘中各占一部分比例。</p><p>这是因为对于MEMORY_AND_DISK存储级别来说，当内存不足以容纳所有的RDD数据分片的时候，Spark会把尚未展开的RDD分片通过DiskStore缓存到磁盘中。DiskStore的工作原理，我们在存储系统那一讲有过详细介绍，你可以回去看一看，我建议你结合DiskStore的知识把RDD分片在磁盘上的缓存过程推导出来。</p><p>因此，<strong>相比MEMORY_ONLY，MEMORY_AND_DISK模式能够保证数据集100%地物化到存储介质</strong>。对于计算链条较长的RDD或是DataFrame来说，把数据物化到磁盘也是值得的。但是，我们也不能逢RDD、DataFrame就调用<code>.cache</code>，因为在最差的情况下，Spark的内存计算就会退化为Hadoop MapReduce根据磁盘的计算模式。</p><p>比如说，你用DataFrame API开发应用，计算过程涉及10次DataFrame之间的转换，每个DataFrame都调用<code>.cache</code>进行缓存。由于Storage Memory内存空间受限，MemoryStore最多只能容纳两个DataFrame的数据量。因此，MemoryStore会有8次以DataFrame为粒度的换进换出。最终，MemoryStore存储的是访问频次最高的DataFrame数据分片，其他的数据分片全部被驱逐到了磁盘上。也就是说，平均下来，至少有8次DataFrame的转换都会将计算结果落盘，这不就是Hadoop的MapReduce计算模式吗？</p><p>当然，咱们考虑的是最差的情况，但这也能让我们体会到滥用Cache可能带来的隐患和危害了。</p><h2>Cache的用武之地</h2><p>既然滥用Cache危害无穷，那在什么情况下适合使用Cache呢？我建议你在做决策的时候遵循以下2条基本原则：</p><ul>\n<li>如果RDD/DataFrame/Dataset在应用中的引用次数为1，就坚决不使用Cache</li>\n<li>如果引用次数大于1，且运行成本占比超过30%，应当考虑启用Cache</li>\n</ul><p>第一条很好理解，我们详细说说第二条。这里咱们定义了一个新概念：<strong>运行成本占比。它指的是计算某个分布式数据集所消耗的总时间与作业执行时间的比值</strong>。我们来举个例子，假设我们有个数据分析的应用，端到端的执行时间为1小时。应用中有个DataFrame被引用了2次，从读取数据源，经过一系列计算，到生成这个DataFrame需要花费12分钟，那么这个DataFrame的运行成本占比应该算作：12 * 2 / 60 = 40%。</p><p>你可能会说：“作业执行时间好算，直接查看Spark UI就好了，DataFrame的运行时间怎么算呢？”这里涉及一个小技巧，我们可以从现有应用中 把DataFrame的计算逻辑单拎出来，然后利用Spark 3.0提供的Noop来精确地得到DataFrame的运行时间。假设df是那个被引用2次的DataFrame，我们就可以把df依赖的所有代码拷贝成一个新的作业，然后在df上调用Noop去触发计算。Noop的作用很巧妙，它只触发计算，而不涉及落盘与数据存储，因此，新作业的执行时间刚好就是DataFrame的运行时间。</p><pre><code>//利用noop精确计算DataFrame运行时间\ndf.write\n.format(“noop”)\n.save()\n</code></pre><p>你可能会觉得每次计算占比会很麻烦，但只要你对数据源足够了解、对计算DataFrame的中间过程心中有数了之后，其实不必每次都去精确地计算运行成本占比，尝试几次，你就能对分布式数据集的运行成本占比估摸得八九不离十了。</p><h2>Cache的注意事项</h2><p>弄清楚了应该什么时候使用Cache之后，我们再来说说Cache的注意事项。</p><p>首先，我们都知道，<code>.cache</code>是惰性操作，因此在调用<code>.cache</code>之后，需要先用Action算子触发缓存的物化过程。但是，我发现很多同学在选择Action算子的时候很随意，first、take、show、count中哪个顺手就用哪个。</p><p>这肯定是不对的，<strong>这4个算子中只有count才会触发缓存的完全物化，而first、take和show这3个算子只会把涉及的数据物化</strong>。举个例子，show默认只产生20条结果，如果我们在.cache之后调用show算子，它只会缓存数据集中这20条记录。</p><p>选择好了算子之后，我们再来讨论一下怎么Cache这个问题。你可能会说：“这还用说吗？在RDD、DataFrame后面调用<code>.cache</code>不就得了”。还真没这么简单，我出一道选择题来考考你，如果给定包含数十列的DataFrame df和后续的数据分析，你应该采用下表中的哪种Cache方式？</p><pre><code>val filePath: String = _\nval df: DataFrame = spark.read.parquet(filePath)\n \n//Cache方式一\nval cachedDF = df.cache\n//数据分析\ncachedDF.filter(col2 &gt; 0).select(col1, col2)\ncachedDF.select(col1, col2).filter(col2 &gt; 100)\n \n//Cache方式二\ndf.select(col1, col2).filter(col2 &gt; 0).cache\n//数据分析\ndf.filter(col2 &gt; 0).select(col1, col2)\ndf.select(col1, col2).filter(col2 &gt; 100)\n \n//Cache方式三\nval cachedDF = df.select(col1, col2).cache\n//数据分析\ncachedDF.filter(col2 &gt; 0).select(col1, col2)\ncachedDF.select(col1, col2).filter(col2 &gt; 100)\n\n</code></pre><p>我们都知道，由于Storage Memory内存空间受限，因此Cache应该遵循<strong>最小公共子集原则</strong>，也就是说，开发者应该仅仅缓存后续操作必需的那些数据列。按照这个原则，实现方式1应当排除在外，毕竟df是一张包含数十列的宽表。</p><p>我们再来看第二种Cache方式，方式2缓存的数据列是<code>col1</code>和<code>col2</code>，且<code>col2</code>数值大于0。第一条分析语句只是把<code>filter</code>和<code>select</code>调换了顺序；第二条语句<code>filter</code>条件限制<code>col2</code>数值要大于100，那么，这个语句的结果就是缓存数据的子集。因此，乍看上去，两条数据分析语句在逻辑上刚好都能利用缓存的数据内容。</p><p>但遗憾的是，这两条分析语句都会跳过缓存数据，分别去磁盘上读取Parquet源文件，然后从头计算投影和过滤的逻辑。这是为什么呢？究其缘由是，<strong>Cache Manager要求两个查询的Analyzed Logical Plan必须完全一致，才能对DataFrame的缓存进行复用</strong>。</p><p>Analyzed Logical Plan是比较初级的逻辑计划，主要负责AST查询语法树的语义检查，确保查询中引用的表、列等元信息的有效性。像谓词下推、列剪枝这些比较智能的推理，要等到制定Optimized Logical Plan才会生效。因此，即使是同一个查询语句，仅仅是调换了<code>select</code>和<code>filter</code>的顺序，在Analyzed Logical Plan阶段也会被判定为不同的逻辑计划。</p><p>因此，为了避免因为Analyzed Logical Plan不一致造成的Cache miss，我们应该采用第三种实现方式，把我们想要缓存的数据赋值给一个变量，凡是在这个变量之上的分析操作，都会完全复用缓存数据。你看，缓存的使用可不仅仅是调用<code>.cache</code>那么简单。</p><p>除此之外，我们也应当及时清理用过的Cache，尽早腾出内存空间供其他数据集消费，从而尽量避免Eviction的发生。一般来说，我们会用.unpersist来清理弃用的缓存数据，它是.cache的逆操作。unpersist操作支持同步、异步两种模式：</p><ul>\n<li>异步模式：调用unpersist()或是unpersist(False)</li>\n<li>同步模式：调用unpersist(True)</li>\n</ul><p>在异步模式下，Driver把清理缓存的请求发送给各个Executors之后，会立即返回，并且继续执行用户代码，比如后续的任务调度、广播变量创建等等。在同步模式下，Driver发送完请求之后，会一直等待所有Executors给出明确的结果（缓存清除成功还是失败）。各个Executors清除缓存的效率、进度各不相同，Driver要等到最后一个Executor返回结果，才会继续执行Driver侧的代码。显然，同步模式会影响Driver的工作效率。因此，通常来说，在需要主动清除Cache的时候，我们往往采用异步的调用方式，也就是调用unpersist()或是unpersist(False)。</p><h2>小结</h2><p>想要有效避免Cache的滥用，我们必须从Cache的工作原理出发，先掌握Cache的3个重要机制，分别是存储级别、缓存计算和缓存的销毁过程。</p><p>对于存储级别来说，实际开发中最常用到的有两个，MEMORY_ONLY和MEMORY_AND_DISK，它们分别是RDD缓存和DataFrame缓存的默认存储级别。</p><p>对于缓存计算来说，它分为3个步骤，第一步是Unroll，把RDD数据分片的Iterator物化为对象值，第二步是Transfer，把对象值封装为MemoryEntry，第三步是把BlockId、MemoryEntry价值对注册到LinkedHashMap数据结构。</p><p>另外，当数据缓存需求远大于Storage Memory区域的空间供给时，Spark利用LinkedHashMap数据结构提供的特性，会遵循LRU和兔子不吃窝边草这两个基本原则来清除内存空间：</p><ul>\n<li>LRU：按照元素的访问顺序，优先清除那些“最近最少访问”的BlockId、MemoryEntry键值对</li>\n<li>兔子不吃窝边草：在清除的过程中，同属一个RDD的MemoryEntry拥有“赦免权”</li>\n</ul><p>其次，我们要掌握使用Cache的一般性原则和注意事项，我把它们总结为3条：</p><ul>\n<li>如果RDD/DataFrame/Dataset在应用中的引用次数为1，我们就坚决不使用Cache</li>\n<li>如果引用次数大于1，且运行成本占比超过30%，我们就考虑启用Cache（其中，运行成本占比的计算，可以利用Spark 3.0推出的noop功能）</li>\n<li>Action算子要选择count才能完全物化缓存数据，以及在调用Cache的时候，我们要把待缓存数据赋值给一个变量。这样一来，只要是在这个变量之上的分析操作都会完全复用缓存数据。</li>\n</ul><h2>每日一练</h2><ol>\n<li>你能结合DiskStore的知识，推导出MEMORY_AND_DISK模式下RDD分片缓存到磁盘的过程吗？</li>\n<li>你觉得，为什么Eviction规则要遵循“兔子不吃窝边草”呢？如果允许同一个RDD的MemoryEntry被驱逐，有什么危害吗？</li>\n<li>对于DataFrame的缓存复用，Cache Manager为什么没有采用根据Optimized Logical Plan的方式，你觉得难点在哪里？如果让你实现Cache Manager的话，你会怎么做？</li>\n</ol><p>期待在留言区看到你的思考和答案，如果你的朋友也正在为怎么使用Cache而困扰，也欢迎你把这一讲转发给他。我们下一讲见！</p>","comments":[{"had_liked":false,"id":301487,"user_name":"陈威洋","can_delete":false,"product_type":"c1","uid":2264679,"ip_address":"","ucode":"DCF84B4D3A7354","user_header":"https://static001.geekbang.org/account/avatar/00/22/8e/67/afb412fb.jpg","comment_is_top":false,"comment_ctime":1625713415,"is_pvip":false,"replies":[{"id":"109202","content":"好问题哈，第三问确实很难，这里老哥我挖了个天坑，老弟见谅哈~<br><br>Spark使用cachedData = IndexedSeq[CachedData]()来存储（LogicalPlan，InMemoryRelation）键值对列表，其中的LogicalPlan就是Analyzed Logical Plan。咱们的问题是，为什么Spark选择了使用Analyzed LP作为Key，而没有选择Optimized LP。这个问题的关键，其实是Spark如何判断一个待计算的执行计划是否已经存在缓存结果了。Spark怎么来判断呢？简单的说，就是通过规范化的Logical Plan（CanonicalizedPlan）来进行对比，如果两个查询的CanonicalizedPlan是完全一致的，那么Spark SQL认为：OK，这个计划在缓存中已经有结果了，直接拿来用就好。<br><br>那么接下来的问题就是，给定一个Logical Plan，Spark SQL如何生产CanonicalizedPlan，简单来说，就是把AST语法树中的fields、ids不太归一化的字段进行归一化，从而消除不同查询计划之间那些“无关痛痒”的细微差别，这些细微差别与查询结果无关，所以在生成CanonicalizedPlan的过程中，Spark会把这些“细微差别”去掉，从而不影响两个CanonicalizedPlan之间是否相同的对比。<br><br>但是，这个规范化或是归一化的过程，Spark SQL其实并不敢完全保证。也就是说，本来计算结果相同的两个查询，他们的CanonicalizedPlan依然有可能不一样，也就是所谓的false negative。对于两个Plan之间CanonicalizedPlan的对比，Spark SQL采取保守的策略，就是宁可错杀1000，也不能漏放一个。也就是，Spark SQL宁可把两个执行结果一样的Logical Plan判定为不同，也要100%地保证：执行结果不同的两个查询，他们的CanonicalizedPlan一定是100%是不同的，也就是不能允许出现false positive的情况。<br><br>正是因为CanonicalizedPlan无法完全确保执行计划与计算结果完全一一对应，所以cachedData这个东西越早检查越省事，如果推迟到Optimized Logical Plan之后，那么大多数情况下，要么缓存很难命中，要么缓存好不容易命中了，但是Optimized阶段的优化就都白做了。所以总结下来，把Cache检查放在Analyzed LP之后、Optimized LP之前，就是上面说的这个原因。这个确实比较变态，root cause分析起来很困难，这个其实需要结合源码去顺藤摸瓜。辛苦老弟了哈~ <br><br>另外分享给老弟一个小tips：当你发现，你的问题，百度、google或是身边的人，都没办法帮你解答的时候，源码是最好的“老师”，我觉得这个是开源项目最大的意义，分享给老弟~","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1625817439,"ip_address":"","comment_id":301487,"utype":1}],"discussion_count":2,"race_medal":0,"score":"53165320967","product_id":100073401,"comment_content":"老师，您好！~我的知识盲区突现了：<br>对于老师的第三问，自己摸不着头脑，看老师和同学的回答也看得蒙蒙，感觉缺少了某部分基础知识，但又不知道从哪里补，这种感觉很痛苦~<br><br>希望老师能指点迷津。","like_count":13,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":523010,"discussion_content":"好问题哈，第三问确实很难，这里老哥我挖了个天坑，老弟见谅哈~\n\nSpark使用cachedData = IndexedSeq[CachedData]()来存储（LogicalPlan，InMemoryRelation）键值对列表，其中的LogicalPlan就是Analyzed Logical Plan。咱们的问题是，为什么Spark选择了使用Analyzed LP作为Key，而没有选择Optimized LP。这个问题的关键，其实是Spark如何判断一个待计算的执行计划是否已经存在缓存结果了。Spark怎么来判断呢？简单的说，就是通过规范化的Logical Plan（CanonicalizedPlan）来进行对比，如果两个查询的CanonicalizedPlan是完全一致的，那么Spark SQL认为：OK，这个计划在缓存中已经有结果了，直接拿来用就好。\n\n那么接下来的问题就是，给定一个Logical Plan，Spark SQL如何生产CanonicalizedPlan，简单来说，就是把AST语法树中的fields、ids不太归一化的字段进行归一化，从而消除不同查询计划之间那些“无关痛痒”的细微差别，这些细微差别与查询结果无关，所以在生成CanonicalizedPlan的过程中，Spark会把这些“细微差别”去掉，从而不影响两个CanonicalizedPlan之间是否相同的对比。\n\n但是，这个规范化或是归一化的过程，Spark SQL其实并不敢完全保证。也就是说，本来计算结果相同的两个查询，他们的CanonicalizedPlan依然有可能不一样，也就是所谓的false negative。对于两个Plan之间CanonicalizedPlan的对比，Spark SQL采取保守的策略，就是宁可错杀1000，也不能漏放一个。也就是，Spark SQL宁可把两个执行结果一样的Logical Plan判定为不同，也要100%地保证：执行结果不同的两个查询，他们的CanonicalizedPlan一定是100%是不同的，也就是不能允许出现false positive的情况。\n\n正是因为CanonicalizedPlan无法完全确保执行计划与计算结果完全一一对应，所以cachedData这个东西越早检查越省事，如果推迟到Optimized Logical Plan之后，那么大多数情况下，要么缓存很难命中，要么缓存好不容易命中了，但是Optimized阶段的优化就都白做了。所以总结下来，把Cache检查放在Analyzed LP之后、Optimized LP之前，就是上面说的这个原因。这个确实比较变态，root cause分析起来很困难，这个其实需要结合源码去顺藤摸瓜。辛苦老弟了哈~ \n\n另外分享给老弟一个小tips：当你发现，你的问题，百度、google或是身边的人，都没办法帮你解答的时候，源码是最好的“老师”，我觉得这个是开源项目最大的意义，分享给老弟~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1625817439,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2264679,"avatar":"https://static001.geekbang.org/account/avatar/00/22/8e/67/afb412fb.jpg","nickname":"陈威洋","note":"","ucode":"DCF84B4D3A7354","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":383008,"discussion_content":"非常感谢老师的回复，我已经看了3遍多，开始有点头绪，心情也慢慢恢复一些[哭]，还会继续深入研究，老师的提示非常重要，源码确实非常重要，那么问题又来了（请原谅我），磊哥，对于还没看过Spark源码，有编程经验的人来说，如何科学的学习Spark源码，哪部分功能先入手比较好？（就是想从简单的开始学习~~）","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1625822122,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":289075,"user_name":"Fendora范东_","can_delete":false,"product_type":"c1","uid":1187106,"ip_address":"","ucode":"63EE9DBEE08D70","user_header":"https://static001.geekbang.org/account/avatar/00/12/1d/22/f04cea4c.jpg","comment_is_top":false,"comment_ctime":1618842735,"is_pvip":false,"replies":[{"id":"104939","content":"答得都对，具体细节刚刚在上一个thread都展开了，可以看看哈~","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1618916148,"ip_address":"","comment_id":289075,"utype":1}],"discussion_count":1,"race_medal":0,"score":"27388646511","product_id":100073401,"comment_content":"1.M_A_D在storage memory可用的情况下，缓存block过程和M_O过程一样，区别在于storage_memory不够情况下的处理。M_O是通过LRU来驱逐block来获取可用缓存;而M_A_D是通过落盘，落盘流程就是把unroll出来的block，通过putBytes()方法直接进行落盘，BlockID为落盘文件名，便于查找。<br>2.在M_O模式下，为啥不驱逐同一个RDD的memoryentry。我理解，当前RDD正在缓存，那它马上被用到的概率是最高的(类似LRU思想)，如果它里面memoryentry被驱逐，那需要用的时候又要重新计算，白白增加耗时。<br>3.在analyzed阶段匹配，我记得是因为在analyzer生效阶段会把unresolverelation直接解析为InMemoryRelation。这样在在Optimizer阶段有些优化规则就省略了，避免应用规则浪费时间","like_count":7,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":518808,"discussion_content":"答得都对，具体细节刚刚在上一个thread都展开了，可以看看哈~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618916148,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":289077,"user_name":"Fendora范东_","can_delete":false,"product_type":"c1","uid":1187106,"ip_address":"","ucode":"63EE9DBEE08D70","user_header":"https://static001.geekbang.org/account/avatar/00/12/1d/22/f04cea4c.jpg","comment_is_top":false,"comment_ctime":1618843429,"is_pvip":false,"replies":[{"id":"104938","content":"好问题~<br><br>1. 是的，一个空间不够，因此继续向后扫描，扫了两个之后，发现空间够了，就停止了。<br><br>2. 这个要赞一个~ 👍，思考很细致。这里咱们图省事，我没有交代的特别清楚，实际上，blockId不是String，而是一个sealed class，也就是一个类。这个类有不少属性，其中一个是asRDDId，这个函数就可以用来获取RDD Id，从而区分扫描的Block，是属于哪个RDD的，从而实现“兔子不吃窝边草”~<br><br>3. 对，现在的设计，是放在Analyzed LP之后、Optimized LP之前，相当于是一种逻辑优化，就像你说的，能省略掉一些Rules、或者选取一些更优的Rules。<br><br>关于Cache Manager的优化，有个思路是SQL Re-write，其实这个思路就来源于传统的DBMS，Spark SQL没有这个环节。如果能够用SQL Re-writer，把Analyzed LP重写，那么其实potentially，很多的Analyzed LP都可以共享一份数据。Query Re-writer本身也并不复杂，参考传统DBMS，就可以很快实现出一个来。如果Cache Manager参考的，不再是“纯字符串”的Analyzed LP，而是重写之后的查询，想必效果要好很多~","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1618915835,"ip_address":"","comment_id":289077,"utype":1}],"discussion_count":1,"race_medal":0,"score":"23093679909","product_id":100073401,"comment_content":"还有几个疑问，<br>1.驱逐memoryentry的时候，图上两个打叉，我理解如果驱逐一个内存还是不够，就驱逐了两个？<br>2.linkedhashmap是怎样区分不同RDD的block的，k是blockid，v是memoryentry。没看到所属RDD的属性<br>3.自己设计cacheManager没啥更好想法，求磊哥提示下。。。我理解这个东西放在最前面比较合理，后面针对缓存的逻辑计划进一步应用或省略优化规则","like_count":5,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":518810,"discussion_content":"好问题~\n\n1. 是的，一个空间不够，因此继续向后扫描，扫了两个之后，发现空间够了，就停止了。\n\n2. 这个要赞一个~ 👍，思考很细致。这里咱们图省事，我没有交代的特别清楚，实际上，blockId不是String，而是一个sealed class，也就是一个类。这个类有不少属性，其中一个是asRDDId，这个函数就可以用来获取RDD Id，从而区分扫描的Block，是属于哪个RDD的，从而实现“兔子不吃窝边草”~\n\n3. 对，现在的设计，是放在Analyzed LP之后、Optimized LP之前，相当于是一种逻辑优化，就像你说的，能省略掉一些Rules、或者选取一些更优的Rules。\n\n关于Cache Manager的优化，有个思路是SQL Re-write，其实这个思路就来源于传统的DBMS，Spark SQL没有这个环节。如果能够用SQL Re-writer，把Analyzed LP重写，那么其实potentially，很多的Analyzed LP都可以共享一份数据。Query Re-writer本身也并不复杂，参考传统DBMS，就可以很快实现出一个来。如果Cache Manager参考的，不再是“纯字符串”的Analyzed LP，而是重写之后的查询，想必效果要好很多~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618915835,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":291458,"user_name":"静心","can_delete":false,"product_type":"c1","uid":1789481,"ip_address":"","ucode":"B80DE4B5C923D3","user_header":"https://static001.geekbang.org/account/avatar/00/1b/4e/29/adcb78e7.jpg","comment_is_top":false,"comment_ctime":1620294581,"is_pvip":false,"replies":[{"id":"105586","content":"好问题，RDD确实不存在Cache miss的问题；咱们文中说的Cache miss，都是围绕着DataFrame，DataFrame、Dataset、SQL都走Spark SQL优化流程。Spark SQL有单独的Cache Manager来管理Cache复用，它本身的一些缺陷，会导致上述这些API，在开发的过程中，会有Cache miss的隐患~ <br><br>关于Spark SQL的优化流程，可以参考后面Spark SQL那三讲，那几讲展开的比较细哈~","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1620312458,"ip_address":"","comment_id":291458,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18800163765","product_id":100073401,"comment_content":"老师，RDD调用 Cache 的时候，文中讲到我们要把待缓存数据赋值给一个变量，然后基于这个变量做后续的etl，能够防止cache miss问题，但是我看了一下rdd cache源码，返回值就是原来的RDD，只是更改了rdd的storageLevel为MEMORY_ONLY（rdd默认缓存级别），所以rdd 调用cache后赋值到一个新变量再做etl 与 不赋值而是基于原有RDD进行etl应该不会有cache miss问题吧，有点不太理解，望老师解疑，谢谢。","like_count":4,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":519476,"discussion_content":"好问题，RDD确实不存在Cache miss的问题；咱们文中说的Cache miss，都是围绕着DataFrame，DataFrame、Dataset、SQL都走Spark SQL优化流程。Spark SQL有单独的Cache Manager来管理Cache复用，它本身的一些缺陷，会导致上述这些API，在开发的过程中，会有Cache miss的隐患~ \n\n关于Spark SQL的优化流程，可以参考后面Spark SQL那三讲，那几讲展开的比较细哈~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1620312458,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":292032,"user_name":"科学养牛","can_delete":false,"product_type":"c1","uid":1489525,"ip_address":"","ucode":"B205209A814AC8","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTI9X140JXPuaDB8PibXpwFWds6mZvg1w7THkyB6NjBkP7x4HqSk2wuUvcmDb9O2l0fCkxvB3ibL0L2A/132","comment_is_top":false,"comment_ctime":1620649986,"is_pvip":false,"replies":[{"id":"105751","content":"对，是的，要先用Action算子来触发缓存的计算，让Spark真正把分布式数据集缓存到内存或是磁盘中去。否则的话，就像你说的，“就算用了cachedRdd这个变量多次缓存也不起效果”。","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1620661063,"ip_address":"","comment_id":292032,"utype":1}],"discussion_count":2,"race_medal":0,"score":"14505551874","product_id":100073401,"comment_content":"老师，你的意思是调用.cache之后，需要马上接一个action算子吗？<br>如果我不马上接action算子，只在最后调用一个action算子，比如saveAsTable，那在之前就算用了cachedRdd这个变量多次缓存也不起效果是吗？","like_count":3,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":519642,"discussion_content":"对，是的，要先用Action算子来触发缓存的计算，让Spark真正把分布式数据集缓存到内存或是磁盘中去。否则的话，就像你说的，“就算用了cachedRdd这个变量多次缓存也不起效果”。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1620661063,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2767208,"avatar":"https://static001.geekbang.org/account/avatar/00/2a/39/68/56dfc8c0.jpg","nickname":"子兮","note":"","ucode":"BA213EAB26DF16","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":531344,"discussion_content":"老师， b = a.map.cache;   c= b.map;   d = b.map;   d.count; 这种在spark graphx 里bRDD 不能被cache 吗？ 我理解是cache 也是lazy 算子和map 一样， count 生成job ，执行dag , 就会缓存，还请老师指教，谢谢老师","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1637290099,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"user_type\":1}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":291291,"user_name":"aof","can_delete":false,"product_type":"c1","uid":1062864,"ip_address":"","ucode":"5815D63C4926BC","user_header":"https://static001.geekbang.org/account/avatar/00/10/37/d0/26975fba.jpg","comment_is_top":false,"comment_ctime":1620190234,"is_pvip":false,"replies":[{"id":"105749","content":"1 没问题，我之前看过你的回答~<br><br>2、3 也都对，满分💯~","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1620659469,"ip_address":"","comment_id":291291,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10210124826","product_id":100073401,"comment_content":"1. 第一题，在前面广播变量那一节的课后思考题已经回答过整个MemoryStore和DiskStore的缓存过程了哈哈<br>2. 因为同一个RDD的Block大概率在接下来就会被用到，因为本身要缓存的就是同一个RDD的其他Block，如果不这样做的话，很可能要缓存的Block被缓存到内存了，却发现要用的Block却被驱逐出内存了<br>3. 这是我自己的猜测不知道对不对哈哈：像第二种方式那样在数据集上做了一些处理之后进行cache，后续Cache Manager如果采用根据 Optimized Logical Plan 的方式来进行优化的话，那后面所有用到df这个Dataframe的地方，Spark都要解析对应的Optimized Logical Plan和我们之前cache的那个是否相同，这将会非常不可控。而且由于RDD&#47;Dataset&#47;Dataframe的不可变性，我们每次在对数据集进行处理之后，其实都应该养成将其赋值给一个新变量的习惯。","like_count":2,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":519431,"discussion_content":"1 没问题，我之前看过你的回答~\n\n2、3 也都对，满分💯~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1620659469,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":289273,"user_name":"辰","can_delete":false,"product_type":"c1","uid":2172635,"ip_address":"","ucode":"2E898EAC5AA141","user_header":"https://static001.geekbang.org/account/avatar/00/21/26/db/27724a6f.jpg","comment_is_top":false,"comment_ctime":1618965321,"is_pvip":false,"replies":[{"id":"105006","content":"物化（Materialization）：把分布式数据集的Iterator迭代器，展开并存储到内存或是磁盘的过程。","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1619018930,"ip_address":"","comment_id":289273,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5913932617","product_id":100073401,"comment_content":"以及缓存的完全物化的物化是指什么意思呢","like_count":1,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":518870,"discussion_content":"物化（Materialization）：把分布式数据集的Iterator迭代器，展开并存储到内存或是磁盘的过程。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1619018930,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":289272,"user_name":"辰","can_delete":false,"product_type":"c1","uid":2172635,"ip_address":"","ucode":"2E898EAC5AA141","user_header":"https://static001.geekbang.org/account/avatar/00/21/26/db/27724a6f.jpg","comment_is_top":false,"comment_ctime":1618965246,"is_pvip":false,"replies":[{"id":"105005","content":"文中的三种方式，主要是为了区别示意哈，目的是为了说清楚缓存复用。实际开发的时候，肯定是需要Action算子来触发缓存计算的。","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1619018857,"ip_address":"","comment_id":289272,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5913932542","product_id":100073401,"comment_content":"老师，文中的三种cache方式，我看都没有调用action算子（排除第二种不会cache的场景），是不是意味着都不会缓存落盘的操作","like_count":1,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":518869,"discussion_content":"文中的三种方式，主要是为了区别示意哈，目的是为了说清楚缓存复用。实际开发的时候，肯定是需要Action算子来触发缓存计算的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1619018857,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":289008,"user_name":"Jay","can_delete":false,"product_type":"c1","uid":1066131,"ip_address":"","ucode":"488BF5D01D3CFD","user_header":"https://static001.geekbang.org/account/avatar/00/10/44/93/2d3d5868.jpg","comment_is_top":false,"comment_ctime":1618818515,"is_pvip":false,"replies":[{"id":"104940","content":"不是哈，RDD还不如DataFrame，因为DF会走Spark SQL，Cache Manager是Spark SQL的组件之一。虽然CM效率不高、容易miss，但是Spark SQL好歹还有这么个组件帮他复用Cache。<br><br>RDD更惨，没有哪个组件来帮他做“复用”这件事，所以，要想充分利用、复用RDD Cache，你只能用第三种方式，也就是变量赋值的方式，明确地引用RDD Cache。","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1618916524,"ip_address":"","comment_id":289008,"utype":1}],"discussion_count":4,"race_medal":0,"score":"5913785811","product_id":100073401,"comment_content":"老师，如果用的是RDD，文中的“Cache方式二”是不是就没有问题了？ ","like_count":1,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":518792,"discussion_content":"不是哈，RDD还不如DataFrame，因为DF会走Spark SQL，Cache Manager是Spark SQL的组件之一。虽然CM效率不高、容易miss，但是Spark SQL好歹还有这么个组件帮他复用Cache。\n\nRDD更惨，没有哪个组件来帮他做“复用”这件事，所以，要想充分利用、复用RDD Cache，你只能用第三种方式，也就是变量赋值的方式，明确地引用RDD Cache。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618916524,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1021794,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/97/62/1a2d7825.jpg","nickname":"臻果爸爸","note":"","ucode":"03DC9615B024A4","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":385713,"discussion_content":"如果把df注册为临时表，后续基于这个表的sparksql都会复用缓存吧，这样方式二和三就没有区别吧，源码里面返回的也是同一个引用","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627222381,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1021794,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/97/62/1a2d7825.jpg","nickname":"臻果爸爸","note":"","ucode":"03DC9615B024A4","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":385712,"discussion_content":"方式2应该会使用缓存的吧，","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1627221911,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1168504,"avatar":"https://static001.geekbang.org/account/avatar/00/11/d4/78/66b3f2a2.jpg","nickname":"斯盖丸","note":"","ucode":"B881D14B028F14","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":368805,"discussion_content":"不是，也有的，缓存和引用的不是同一个东西。函数式操作每次都返回一个新变量","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618836011,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":354960,"user_name":"三胖","can_delete":false,"product_type":"c1","uid":1373454,"ip_address":"北京","ucode":"CD69FCD606FC5C","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/1hp9kzzuLUVHzmmddIPIO2OgUWr1ibJRr8cMoB7K0fwx8Vmn34L8yN2NoYUtgNicfPGaXKF02pQ2huXd59r2I0kw/132","comment_is_top":false,"comment_ctime":1660911287,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1660911287","product_id":100073401,"comment_content":"老师，如果缓存级别是MEMORY_ONLY，然后多个rdd抢占资源，结果导致各个rdd的缓存比例都没有达到100%，说明缓存的数据是缺失的，下游要用到缓存的rdd，但是拿到的是有缺失的数据，这还能用吗","like_count":0},{"had_liked":false,"id":348333,"user_name":"Geek_73cee2","can_delete":false,"product_type":"c1","uid":2828185,"ip_address":"","ucode":"54848FF6BE74B1","user_header":"","comment_is_top":false,"comment_ctime":1655002612,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1655002612","product_id":100073401,"comment_content":"老师 您说的这些内存是整个集群的 而不是单个的executors内有多少内存吗  比如storage memory usermemory  还有呢个resever m 300m那个","like_count":0},{"had_liked":false,"id":322786,"user_name":"tiankonghewo","can_delete":false,"product_type":"c1","uid":1476427,"ip_address":"","ucode":"7A55A9C17DD9DF","user_header":"https://static001.geekbang.org/account/avatar/00/16/87/4b/16ea3997.jpg","comment_is_top":false,"comment_ctime":1637587294,"is_pvip":false,"replies":[{"id":"117412","content":"并没有重复计算的情况哈，Spark的运行机制是Lazy evaluation，所以说，加了cache，一定要先trigger计算，否则后面的多个action，没有办法利用到缓存的优势。具体来说，是后面最近的那个action，没法利用缓存。<br><br>老弟不妨再回顾下DAG、内存计算那两讲，关于延迟计算，那里面介绍的比较多","user_name":"作者回复","user_name_real":"编辑","uid":"1043100","ctime":1637986923,"ip_address":"","comment_id":322786,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1637587294","product_id":100073401,"comment_content":"为什么cache要在action算子之后,再单独启动一个job缓存数据,这样不是重复计算了吗?已经计算一遍了,为什么不利用呢?","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":533823,"discussion_content":"并没有重复计算的情况哈，Spark的运行机制是Lazy evaluation，所以说，加了cache，一定要先trigger计算，否则后面的多个action，没有办法利用到缓存的优势。具体来说，是后面最近的那个action，没法利用缓存。\n\n老弟不妨再回顾下DAG、内存计算那两讲，关于延迟计算，那里面介绍的比较多","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1637986923,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":313355,"user_name":"Hiway","can_delete":false,"product_type":"c1","uid":1169895,"ip_address":"","ucode":"3E97C70A04018C","user_header":"https://static001.geekbang.org/account/avatar/00/11/d9/e7/45d9e964.jpg","comment_is_top":false,"comment_ctime":1632387185,"is_pvip":false,"replies":[{"id":"113542","content":"是的，是这样的哈。cache的目的是复用，没有action的话，cache不会生效。只有遇到action算子，cache才会触发，才会真的缓存数据到内存或磁盘。count这种操作，没有多大开销的，相比业务逻辑，count可以忽略不计","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1632484700,"ip_address":"","comment_id":313355,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1632387185","product_id":100073401,"comment_content":"老师，您好。看到你之前的回答“是的，要先用Action算子来触发缓存的计算，让Spark真正把分布式数据集缓存到内存或是磁盘中去。”我对这句话有点疑惑，请问实际工作环境使用cache也是这样的吗？cache完后接一个count用于触发cache计算。然后再继续写业务逻辑吗？<br>那不是除了cache的开销，还多了一个count计算的开销","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527324,"discussion_content":"是的，是这样的哈。cache的目的是复用，没有action的话，cache不会生效。只有遇到action算子，cache才会触发，才会真的缓存数据到内存或磁盘。count这种操作，没有多大开销的，相比业务逻辑，count可以忽略不计","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1632484700,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":306047,"user_name":"wow_xiaodi","can_delete":false,"product_type":"c1","uid":1511712,"ip_address":"","ucode":"B3FB301556A7EA","user_header":"https://static001.geekbang.org/account/avatar/00/17/11/20/9f31c4f4.jpg","comment_is_top":false,"comment_ctime":1628320336,"is_pvip":false,"replies":[{"id":"111330","content":"一个个来说哈~<br><br>1. 优先内存，内存不足放磁盘，磁盘文件前缀是broadcast<br><br>2. 好问题，我们知道，同一个RDD，是“兔子不吃窝边草”，同一个RDD如果内存不足，后面的分片是不会驱逐内存当中同一个RDD的分片的。但如果是不同的RDD，内存放不下，就会尝试去驱赶其他RDD已经缓存的数据分片，比较野蛮<br><br>3. 这个比例咱们开发者事先是算不出来的，不过，你倒是可以通过Spark UI来看Storage Tab，观察每个RDD的缓存情况，它会列出，多少数据缓存到内存，多少数据缓存到磁盘。","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1629127803,"ip_address":"","comment_id":306047,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1628320336","product_id":100073401,"comment_content":"老师，您好，有几个问题想问下：<br>(1)广播变量默认是存储级别是？如果内存不足，是否是存到disk中？<br>(2)对于memory only模式，采用lru淘汰缓存。那么如果是memory and disk模式，此时如果内存不足，是否先进行lru淘汰呢？<br>(3)memory and disk文中说到部分内存，部分disk，那么这个存储占比如何去确定呢？","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":524607,"discussion_content":"一个个来说哈~\n\n1. 优先内存，内存不足放磁盘，磁盘文件前缀是broadcast\n\n2. 好问题，我们知道，同一个RDD，是“兔子不吃窝边草”，同一个RDD如果内存不足，后面的分片是不会驱逐内存当中同一个RDD的分片的。但如果是不同的RDD，内存放不下，就会尝试去驱赶其他RDD已经缓存的数据分片，比较野蛮\n\n3. 这个比例咱们开发者事先是算不出来的，不过，你倒是可以通过Spark UI来看Storage Tab，观察每个RDD的缓存情况，它会列出，多少数据缓存到内存，多少数据缓存到磁盘。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1629127803,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1549032,"avatar":"","nickname":"Zzz","note":"","ucode":"9323254354868B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":395963,"discussion_content":"应该是直接丢弃和存入磁盘的区别，lru的机智都一样，具体可以看下源码","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1632369176,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":301543,"user_name":"阳台","can_delete":false,"product_type":"c1","uid":2340596,"ip_address":"","ucode":"CD76C0917139AF","user_header":"","comment_is_top":false,"comment_ctime":1625733301,"is_pvip":false,"replies":[{"id":"109184","content":"好问题，3个土豆（更准确地说，是多个，三个麻袋里面的所有土豆）一起，构成一个RDD哈~ RDD是数据“抽象”，它是用来“囊括”分布式数据集的，分布式数据集由数据分片&#47;分区构成，土豆工坊里面的每一个土豆，都是一个RDD数据分片，不是RDD本身，他们凑在一起，够了一个RDD。<br><br>RDD是抽象的概念，而数据分片是实体。","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1625802161,"ip_address":"","comment_id":301543,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1625733301","product_id":100073401,"comment_content":"请问一下老师，什么是同属一个Rdd数据？第一节里面的一个土豆是一个rdd数据，还是三个土豆在一起被称为一个rdd数据","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":523024,"discussion_content":"好问题，3个土豆（更准确地说，是多个，三个麻袋里面的所有土豆）一起，构成一个RDD哈~ RDD是数据“抽象”，它是用来“囊括”分布式数据集的，分布式数据集由数据分片/分区构成，土豆工坊里面的每一个土豆，都是一个RDD数据分片，不是RDD本身，他们凑在一起，够了一个RDD。\n\nRDD是抽象的概念，而数据分片是实体。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1625802161,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1811813,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/a5/65/898bc6c5.jpg","nickname":"wayne","note":"","ucode":"988E1F2F0B419A","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":543866,"discussion_content":"老师 spark.sql(sql_query).cache().createorreplacetempview()这种方式也需要action算子触发吗？\n这种方式也遵循您说的cache miss规则吗？\n怎么使用比较好","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1641334415,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}