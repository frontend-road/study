{"id":808229,"title":"09｜进阶（一）：Advanced RAG与Modular RAG","content":"<blockquote>\n<p><span class=\"reference\">本门课程为精品小课，不标配音频。</span></p>\n</blockquote><p>你好，我是常扬。</p><p>在之前的课程中，我们已经详细讨论了RAG（Retrieval Augmented Generation）检索增强生成的技术架构以及相关的效果优化技术，涵盖了其核心流程：索引（Indexing）、检索（Retrieval）和生成（Generation）。这些流程共同作用，提升了大模型的领域知识生成能力。这节课我们将深入介绍 <strong>Advanced RAG（进阶 RAG）</strong>与 <strong>Modular RAG（模块化 RAG）</strong>，进一步加深对 RAG 技术范式发展的理解，为进一步优化和提升RAG产品的效果提供研发基础。</p><p>RAG技术在适应复杂应用场景和不断发展的技术需求中，经历了从最初的 <strong>Naive RAG （朴素 RAG）</strong>，到流程优化的 <strong>Advanced RAG</strong>，再到更具灵活性的 <strong>Modular RAG</strong> 的演变。值得注意的是，这三个范式之间具有<strong>继承与发展</strong>的关系：Advanced RAG 是 Modular RAG 的一种特例形式，而 Naive RAG 则是 Advanced RAG 的基础特例。通过这种逐步演进，RAG技术不断优化，以应对更复杂的任务和场景需求，如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/7c/a0/7c3ebbe6ec9d9f2886881d7e534396a0.jpg?wh=1920x1129\" alt=\"图片\" title=\"图片源自于 https://arxiv.org/pdf/2312.10997\"></p><p>Naive RAG 是最基础的形式，它依赖核心的索引和检索策略来增强生成模型的输出，适用于一些基础任务和产品 MVP（Minimum Viable Product，最小可用版本）阶段。Advanced RAG  则通过增加检索前、检索中以及检索后的优化策略，提高了检索的准确性和生成的关联性，特别是在复杂任务中表现更为出色。Modular RAG 则进一步打破了传统的链式结构，允许不同模块之间的灵活组合以及流程的适应性编排，提供了更高的灵活性和可扩展性，用于处理多样化的需求和复杂任务。</p><!-- [[[read_end]]] --><h2>Advanced RAG</h2><p>随着RAG产品化和场景化应用的不断深入，用户对RAG系统效果的要求越来越高，Advanced RAG 成为解决 Naive RAG 局限性的有效范式。通过优化<strong>检索前、检索中、检索后</strong>的各个环节，RAG在索引质量、检索效果以及生成内容的上下文相关性方面都取得了显著提升。在之前的课程中，我们已经介绍了部分优化方案，而这节课我们将结合案例对这些优化策略进行系统性总结，并深入分析它们对 RAG 技术性能提升的具体作用。</p><p>先展示案例：</p><p><img src=\"https://static001.geekbang.org/resource/image/c5/98/c5f95a67ed97acda364yy666f1e7ab98.jpg?wh=1440x2384\" alt=\"图片\" title=\"图片源自于 https://arxiv.org/pdf/2407.21059\"></p><p>上图对比了在回答复杂问题时使用两种不同的 RAG 范式的效果：<strong>Naive RAG 和 Advanced RAG</strong>。问题要求分析Nvidia和Apple过去三年的财务表现，并判断哪家公司更值得投资。问题涉及：</p><ol>\n<li>明确的<strong>时间范围</strong>（三年）与<strong>多文档的信息</strong>（Nvidia与Apple的材料）。</li>\n<li>复杂的<strong>要求</strong>，需要分析<strong>专业领域指标（财务）</strong>并做出投资价值的判断。</li>\n</ol><h3><strong>Naive RAG 流程</strong></h3><ol>\n<li><strong>索引流程：</strong>系统对多个文档进行切分和嵌入处理，包括2021、2022和2023年的Apple和Nvidia年度报告。</li>\n<li><strong>检索流程：</strong>系统从索引的文档中检索内容，但检索到的信息不充分，原因包括：</li>\n</ol><ul>\n<li>检索到的是不同年度Nvidia报告中的同一章节内容。</li>\n<li>时间范围可能错误（混合了不同年份的数据）。</li>\n<li>Apple相关内容缺失。</li>\n<li>检索过程缺乏处理复杂问题需求的足够上下文。</li>\n</ul><ol start=\"3\">\n<li><strong>生成流程：</strong>生成的回答只提供了Nvidia及一些大盘指数（如标普500和纳斯达克100）的股票价格信息，但未能给出深层次的分析或直接比较；最终回答质量较差，无法根据财务表现确定哪家公司更值得投资。</li>\n</ol><h3><strong>Advanced RAG流程</strong></h3><ol>\n<li><strong>检索前优化</strong></li>\n</ol><ul>\n<li>\n<p>带有层次结构的PDF文档解析的索引</p>\n<ul>\n<li>使用分层结构对PDF文档进行索引，捕捉不同章节（如业务、风险因素）和段落的内容，帮助系统更精确地进行检索。</li>\n</ul>\n</li>\n<li>\n<p>将原问题重写为更清晰、更具体的查询</p>\n<ul>\n<li>重点关注关键财务指标和股票价格，确保检索目标更加明确。</li>\n</ul>\n</li>\n</ul><ol start=\"2\">\n<li>\n<p><strong>检索优化：</strong>借助层次结构改进检索，返回相关的段落、表格和财务指标</p>\n</li>\n<li>\n<p><strong>检索后优化：</strong>使用问题与检索内容的相关性对检索到的内容进行重排序</p>\n</li>\n<li>\n<p><strong>生成：</strong>生成的回答包含了Nvidia和Apple的财务表现数据，如收入和波动性比较，以及提供了投资机会分析。明显提高了分析和生成的质量，但仍有效果提升的空间。</p>\n</li>\n</ol><p>上述案例展示了 Advanced RAG 通过引入多种技术，采用了检索前、检索中、检索后的优化策略，显著提高了检索质量。</p><p>下面我们按照<strong>检索前、检索、检索后</strong>策略分类，系统性地展现当前主流的优化技术方案。</p><h3><strong>检索前优化</strong></h3><p>检索前优化通过索引、分块、查询优化以及内容向量化等技术手段，提高检索内容的精确性和生成内容的相关性。</p><ol>\n<li>\n<p><strong>滑动窗口方法</strong>：经典的分块技术，通过在相邻的文本块之间创建重叠区域，确保关键信息不会因简单的分段而丢失。这种方法在索引过程中通过在块之间保留重复部分，保证了检索时上下文信息的连贯性，进而提高了检索的精度。</p>\n</li>\n<li>\n<p><strong>元数据添加</strong>：为每个分块添加元数据（如创建日期、章节名称、文档类型等），能够使系统在检索时快速过滤掉无关内容。例如，用户在查询时可以通过元数据筛选特定时间段的文档，减少不相关信息的干扰。</p>\n</li>\n<li>\n<p><strong>分层索引</strong>：在索引过程中，可以采用句子级、段落级甚至文档级的多层次嵌入方法。这样，系统可以根据查询的具体要求，灵活地在不同层次进行检索。比如，当用户输入较为复杂的长句查询时，段落级别的嵌入能够提供更加全面的语义匹配；而对于简短查询，句子级的嵌入能够提供更精确的结果。</p>\n</li>\n<li>\n<p><strong>句子窗口检索</strong>：这种方法通过将文档中的每个句子独立嵌入，从而提高检索的精确度。在检索过程中，系统找到与查询最相关的句子后，会扩展句子前后的上下文窗口，保证生成模型能够获取足够的背景信息进行推理。这种方式既能够精准定位关键信息，又能确保生成的上下文连贯性。</p>\n</li>\n<li>\n<p><strong>查询重写：</strong>针对用户输入的原始查询进行重新表述，使其更加清晰易懂，并且与检索任务匹配。例如，针对用户模糊或含糊的提问，系统可以通过重写，使查询更加具体化，从而检索到更加精准的内容。</p>\n</li>\n<li>\n<p><strong>查询扩展</strong>：查询扩展通过增加同义词、相关词汇或概念扩展用户的原始查询，增加了检索结果的广度。这样，当用户输入简短或不完整的查询时，系统能够通过扩展词汇找到更多潜在相关的内容，从而提升检索效果。</p>\n</li>\n<li>\n<p><strong>长短不一的内容向量化：</strong>RAG系统中，文档或查询的长度对向量化过程有着显著的影响。对于短句子或短语，其生成的向量更加聚焦于具体细节，能够实现更精确的句子级别匹配。段落或文档级别的向量化涵盖了更广泛的上下文信息，能够捕捉到内容的整体语义。</p>\n</li>\n</ol><h3><strong>检索优化</strong></h3><p>检索优化是RAG系统中直接影响检索效果和质量的核心环节。通过增强向量搜索、动态嵌入模型、混合检索等技术手段，系统能够高效、精准地找到与用户查询最相关的内容。</p><ol>\n<li>\n<p><strong>动态嵌入</strong>：RAG系统通过动态嵌入模型根据上下文变化实时调整单词的嵌入表示，能够捕捉单词在不同上下文中的不同含义。例如，“bank”在“river bank”（河岸）和“financial bank”（银行）中的语义完全不同，动态嵌入可以根据具体语境生成合适的向量，从而提高检索的精准性。</p>\n</li>\n<li>\n<p><strong>领域特定嵌入微调</strong>：在实际应用中，不同领域的数据语境差异较大，通用的嵌入模型往往无法覆盖某些领域的专业术语或特定语义。通过对嵌入模型进行微调，可以增强其在特定领域中的表现。例如，针对医学、法律等专业领域，可以对嵌入模型进行定制化训练/微调，使其更好地理解这些领域中的特有词汇和语境。</p>\n</li>\n<li>\n<p><strong>假设文档嵌入</strong>：假设文档嵌入（Hypothetical Document Embeddings，HyDE）是一种创新的检索技术。HyDE 方法通过生成假设文档并将其向量化，以提升查询与检索结果之间的语义匹配度。当用户输入一个查询时，LLM首先基于查询生成一个假设性答案，这个答案不一定是真实存在的文档内容，但它反映了查询的核心语义。然后，系统将该假设性答案向量化，与数据库中的向量进行匹配，寻找最接近的文档。例如，用户询问“拔除智齿需要多长时间？”，系统会生成一个假设性回答“拔智齿通常需要30分钟到两小时”，然后根据该假设文档进行检索，系统可能最终找到类似的真实文档，如“拔智齿的过程通常持续几分钟到20分钟以上”。通过假设文档，系统可以捕捉到更准确的相关文档。</p>\n</li>\n<li>\n<p><strong>混合检索</strong>：混合检索是结合向量搜索与关键词搜索等多种检索方法的混合方法，能够同时利用语义匹配与关键词匹配的优势。</p>\n</li>\n<li>\n<p><strong>小到大检索</strong>：这种方法首先通过较小的内容块（如单个句子或短段落）进行嵌入和检索，确保模型能找到与查询最匹配的小范围上下文。检索到相关内容后，再在生成阶段使用对应的较大文本块（如完整段落或全文）为模型提供更广泛的上下文支持。小块检索有助于提高精度，而大块生成则提供丰富的背景信息，使得生成的内容更加全面。</p>\n</li>\n<li>\n<p><strong>递归块合并</strong>：通过逐级扩展检索内容，确保生成阶段能够捕捉到更全面的上下文信息。该技术在细粒度的子块检索后，自动将相关的父块合并，以便提供完整的上下文供生成模型参考。</p>\n</li>\n</ol><h3><strong>检索后优化</strong></h3><p>检索后优化目的是对已经检索到的内容进行进一步的处理和筛选，常用的技术包括重排序、提示压缩等，以确保最终生成的答案具有高度的相关性和准确性。</p><ol>\n<li>\n<p><strong>重排序</strong>：在RAG系统中，虽然初始检索可以找到多个与查询相关的内容块，但这些内容的相关性可能存在差异，因此需要进一步排序以优化生成结果。重排序通过重排序模型根据上下文的重要性、相关性评分等因素对已检索内容重新打分，以确保最相关的信息被优先处理。</p>\n</li>\n<li>\n<p><strong>提示压缩</strong>：通过删除冗余信息、合并相关内容、突出关键信息等方式来压缩提示，为生成模型提供更简洁、更相关的输入。</p>\n</li>\n<li>\n<p><strong>上下文重构</strong>：通过对检索到的内容进行再加工或重组，以便更好地符合查询的需求。常见的做法是将多个检索到的上下文片段整合成一个更具连贯性的文本块，减少重复或冲突的内容，从而为生成模型提供一个统一、清晰的输入。</p>\n</li>\n<li>\n<p><strong>内容过滤</strong>：根据预先设定的规则进行，包括过滤掉与查询无直接关联的内容、语义相似度较低的片段、冗长且无关的背景信息等，避免对生成结果产生负面影响。</p>\n</li>\n<li>\n<p><strong>多跳推理</strong>：系统通过多个推理步骤，逐步整合信息，以回答复杂查询。通常用于需要跨多个上下文或多步推理的问题。例如，用户询问“某个技术的演化历程”，系统可能先检索到该技术的某个时间点的关键事件，然后再通过进一步检索，找到关于这些关键事件的详细说明，最终给出完整的回答。</p>\n</li>\n<li>\n<p><strong>知识注入</strong>：在检索后通过外部知识库或预定义的领域知识，增强生成的上下文内容。这种方式适用于对准确性要求较高的场景，尤其是在特定领域或技术场景下，系统需要补充额外的专业知识。</p>\n</li>\n</ol><h2>Modular RAG</h2><p><strong>Modular RAG（模块化 RAG）</strong>架构超越了前两种 RAG 范式，提供了更强的适应性和灵活性。它通过多种优化策略和独有的编排功能提高 RAG 系统的场景适应性。尽管具有独特性，Modular RAG 仍然沿袭了 Naive RAG 和 Advanced RAG 的核心原则，充分体现了 RAG 技术体系的不断进化和完善。</p><p><img src=\"https://static001.geekbang.org/resource/image/62/e8/6279b3f987db3c0270b8a81e1fbf4ae8.jpg?wh=1920x994\" alt=\"图片\" title=\"图片源自于 https://arxiv.org/pdf/2407.21059\"></p><p>上图展示了三种不同的 RAG 范式的架构设计，突出表现了 Modular RAG 的部分，Modular RAG 将 RAG 的过程细分为多个可优化的模块，以支持高度定制化和优化。Modular RAG 通过将 Advanced RAG 的优化策略自由组合，根据不同的应用场景定制化处理检索和生成任务，显著提升效率和效果。</p><p>在 Modular RAG 架构中，<strong>Orchestration（编排）</strong> 是区别于 Advanced RAG 最显著的部分，它通过自由的流程控制和决策来优化检索和生成的全流程。这一部分的核心思想是通过智能路由和调度，动态地决定查询处理的路径和步骤，从而在复杂场景下提升 RAG 系统的性能。</p><ol>\n<li><strong>Routing（路由）</strong></li>\n</ol><p>路由是编排流程中的关键步骤。它的主要功能是在收到用户查询后，根据查询的特点和上下文，选择最合适的流程。具体来说，Routing 模块依赖于以下两部分：</p><p>a. <strong>Query Analysis（查询分析）</strong>：首先，对用户的查询进行语义分析，判断其类型和难度。例如，一个直接问答式的查询可能不需要复杂的检索过程，而一个涉及多步推理的复杂问题则可能需要走更长的检索路径。</p><p>b. <strong>Pipeline Selection（管道选择）</strong>：根据查询分析的结果，Routing 模块会动态选择合适的流程（Pipeline）。比如针对简单的查询，可以仅用大模型的知识来回答，效率高。而针对需要领域知识及复杂推理的查询，系统会使用更多的检索步骤，结合外部文档及知识进行深度检索生成。</p><ol start=\"2\">\n<li><strong>Scheduling（调度）</strong></li>\n</ol><p>调度的作用是管理查询的执行顺序，并动态调整检索和生成步骤。</p><p>a. <strong>Query Scheduling（查询调度）</strong>：当系统接收到查询时，调度模块会判断是否需要进行检索。调度模块根据查询的重要性、上下文信息、已有生成结果的质量等多维度因素进行评估。</p><p>b. <strong>Judgment of Retrieval Needs（检索需求判断）</strong>：调度还通过特定的判断节点来确定是否需要额外检索。在某些情况下，系统可能会多次判断是否有必要执行新一轮的检索。</p><ol start=\"3\">\n<li><strong>Knowledge Guide（知识引导）</strong></li>\n</ol><p>知识引导是结合知识图谱和推理路径来增强查询处理过程。</p><p>a. <strong>Knowledge Graph（知识图谱）</strong>：在处理复杂查询时，系统可以调用知识图谱来辅助检索。这不仅提升了检索结果的准确性，还可以通过知识图谱中的上下文关系来推导出更为精确的答案。例如，若查询涉及多个实体的关系或多个时间点，知识图谱能够提供更深层次的推理支持。</p><p>b. <strong>Reasoning Path（推理路径）</strong>：通过推理路径，系统可以设计出一条符合查询需求的推理链条，系统可以根据这一链条进行逐步地推理和检索。这在处理具有强逻辑性的问题时非常有效，例如跨多个文档的关系推理或时间序列推导。</p><p><strong>编排模块</strong>是 Modular RAG 区别于 Advanced RAG 的核心，它通过灵活的路由、调度、知识引导与推理路径来动态决定处理流程，从而提升了整个系统在复杂查询场景下的适应性和处理能力。</p><h2>总结</h2><p>这节课我们讲解了 <strong>Advanced RAG</strong>与 <strong>Modular RAG</strong>。</p><p><strong>Advanced RAG</strong> 通过在<strong>检索前、检索中、以及检索后</strong>对RAG系统进行优化，显著提升了检索的精准性和生成内容的上下文相关性。具体优化措施包括且不限于滑动窗口方法、元数据添加、分层索引、句子窗口检索、查询重写、查询扩展、长短不一的内容向量化、动态嵌入、领域特定嵌入微调、假设文档嵌入、混合检索、小到大检索、递归块合并、重排序、提示压缩、上下文重构、内容过滤、多跳推理、知识注入等，使得 RAG 在复杂任务中的表现效果更加优越。</p><p><strong>Modular RAG 进一步增强了 RAG 系统的灵活性和适应性</strong>，允许通过不同模块的自由组合来应对多样化的应用场景。与 Advanced RAG 相比，Modular RAG 最大的不同之处在于其引入了<strong>编排机制，包括路由、调度和知识引导</strong>等模块，实现了更加智能的流程控制和动态决策。</p><h2>思考题</h2><p>编排机制可以根据查询的复杂性动态调整流程，你能想到哪些复杂的应用场景可以从这种编排机制中获益？对于某些看似简单的任务，编排机制是否也会带来意想不到的提升？欢迎你在留言区分享，和我一起讨论，也欢迎你把这节课的内容分享给对RAG感兴趣的朋友，我们下节课再见！</p>","comments":[{"had_liked":false,"id":394515,"user_name":"i33","can_delete":false,"product_type":"c1","uid":3952531,"ip_address":"广东","ucode":"6C7C35A4413C28","user_header":"https://static001.geekbang.org/account/avatar/00/3c/4f/93/76d800ca.jpg","comment_is_top":false,"comment_ctime":1727019818,"is_pvip":false,"replies":[{"id":143210,"content":"有实现的设计，推荐你两篇文章，其中有实例代码。https:&#47;&#47;mp.weixin.qq.com&#47;s&#47;OjPaCW8Z-kXh6KU2CmI42A\n\nhttps:&#47;&#47;mp.weixin.qq.com&#47;s&#47;MzdKPYNYcwna06Evyl4_Mg\n","user_name":"作者回复","user_name_real":"编辑","uid":3954065,"ctime":1727057032,"ip_address":"上海","comment_id":394515,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100804101,"comment_content":"你好  我是刚做RAG相关开发，目前遇到一个项目中涉及技术是将长句切分成短句和query做匹配，然后返回来找对应的长句 类似于句子窗口检索 小到大检索  这种目前有实现的设计吗  想学习一下","like_count":3,"discussions":[{"author":{"id":3954065,"avatar":"https://static001.geekbang.org/account/avatar/00/3c/55/91/e3c96b88.jpg","nickname":"常扬","note":"","ucode":"11B62CDABBE875","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":651550,"discussion_content":"有实现的设计，推荐你两篇文章，其中有实例代码。https://mp.weixin.qq.com/s/OjPaCW8Z-kXh6KU2CmI42A\n\nhttps://mp.weixin.qq.com/s/MzdKPYNYcwna06Evyl4_Mg\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1727057032,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":396098,"user_name":"冰炎","can_delete":false,"product_type":"c1","uid":1252610,"ip_address":"广东","ucode":"CC3AD46AB3659C","user_header":"https://static001.geekbang.org/account/avatar/00/13/1d/02/60c52ddc.jpg","comment_is_top":false,"comment_ctime":1733121129,"is_pvip":false,"replies":[{"id":143831,"content":"会存在，所以需要进行加权得分来做调整。","user_name":"作者回复","user_name_real":"编辑","uid":3954065,"ctime":1733478125,"ip_address":"上海","comment_id":396098,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100804101,"comment_content":"对于近义词查询扩展如果把原始问题，原始问题检索结果、近义词查询扩展结果送给交叉编码器进行重排序会不会存在模型倾向于给与原始查询召回的文档更高的相关性评分、而相对忽略了通过近义词扩展召回的文档的风险","like_count":0,"discussions":[{"author":{"id":3954065,"avatar":"https://static001.geekbang.org/account/avatar/00/3c/55/91/e3c96b88.jpg","nickname":"常扬","note":"","ucode":"11B62CDABBE875","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":654802,"discussion_content":"会存在，所以需要进行加权得分来做调整。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1733478125,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":396097,"user_name":"冰炎","can_delete":false,"product_type":"c1","uid":1252610,"ip_address":"广东","ucode":"CC3AD46AB3659C","user_header":"https://static001.geekbang.org/account/avatar/00/13/1d/02/60c52ddc.jpg","comment_is_top":false,"comment_ctime":1733120516,"is_pvip":false,"replies":[{"id":143830,"content":"两种方法没有绝对好坏，只有优劣势不同，按照实际使用场景去选择。一个开销小，一个更广泛。融合用加权最理想，但权重的定量是难点。","user_name":"作者回复","user_name_real":"编辑","uid":3954065,"ctime":1733477991,"ip_address":"上海","comment_id":396097,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100804101,"comment_content":"您好，请问对于查询扩展（比如同义词扩展）应如何输出？是组成新查询去检索并重排序还是说各自检索并重排然后使用最大值或平均值或加权平均输出？业界有没有相关的一些探索或论文","like_count":0,"discussions":[{"author":{"id":3954065,"avatar":"https://static001.geekbang.org/account/avatar/00/3c/55/91/e3c96b88.jpg","nickname":"常扬","note":"","ucode":"11B62CDABBE875","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":654801,"discussion_content":"两种方法没有绝对好坏，只有优劣势不同，按照实际使用场景去选择。一个开销小，一个更广泛。融合用加权最理想，但权重的定量是难点。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1733477991,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":395258,"user_name":"kevin","can_delete":false,"product_type":"c1","uid":3920101,"ip_address":"广东","ucode":"19E83C631DF25E","user_header":"https://static001.geekbang.org/account/avatar/00/3b/d0/e5/0a3ee17c.jpg","comment_is_top":false,"comment_ctime":1729911849,"is_pvip":false,"replies":[{"id":143530,"content":"Advanced RAG 和 Modular RAG 是对 RAG 框架的优化范式，课程中对检索前和检索后的优化的案例其实就是属于Advanced RAG。","user_name":"作者回复","user_name_real":"编辑","uid":3954065,"ctime":1730455505,"ip_address":"上海","comment_id":395258,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100804101,"comment_content":"请问Advanced RAG 与Modular RAG章节的代码案例有吗？","like_count":0,"discussions":[{"author":{"id":3954065,"avatar":"https://static001.geekbang.org/account/avatar/00/3c/55/91/e3c96b88.jpg","nickname":"常扬","note":"","ucode":"11B62CDABBE875","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":653231,"discussion_content":"Advanced RAG 和 Modular RAG 是对 RAG 框架的优化范式，课程中对检索前和检索后的优化的案例其实就是属于Advanced RAG。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1730455505,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":394607,"user_name":"梦典","can_delete":false,"product_type":"c1","uid":1203920,"ip_address":"辽宁","ucode":"0A6F91068A13E8","user_header":"https://static001.geekbang.org/account/avatar/00/12/5e/d0/e676ac19.jpg","comment_is_top":false,"comment_ctime":1727283287,"is_pvip":false,"replies":[{"id":143251,"content":"1. 初步文档检索，知识注入为检索后补充文档中涉及的专业知识。比如：医疗问答中，用户提出关于某种疾病的治疗方案问题。我们从医院的病历、指南、论文文档中检索出初步回答。但是由于医疗领域知识的专业性和准确性要求高，系统可以从外部的知识库比如PubMed，或者预定义的医疗领域知识库，再补充对应药物的说明、适应症、禁忌症等信息。\n2. Modular RAG的参考代码可以看开源的一些RAG代码库，都具备可编排的能力。比如 https:&#47;&#47;github.com&#47;netease-youdao&#47;QAnything，https:&#47;&#47;github.com&#47;infiniflow&#47;ragflow 等\n","user_name":"作者回复","user_name_real":"编辑","uid":3954065,"ctime":1727408688,"ip_address":"上海","comment_id":394607,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100804101,"comment_content":"1.请问检索后优化策略之知识注入没有很理解，能举个例子更加详细描述一下吗？\n2.针对思考题，我觉得业务场景比较多，并且各个场景需要的RAG策略并不相同，并且对输出时间要求并不苛刻，非常适合Modular RAG，提升最终生成效果，并且能够自适应；Modular RAG有代码实现吗？","like_count":0,"discussions":[{"author":{"id":3954065,"avatar":"https://static001.geekbang.org/account/avatar/00/3c/55/91/e3c96b88.jpg","nickname":"常扬","note":"","ucode":"11B62CDABBE875","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":651766,"discussion_content":"1. 初步文档检索，知识注入为检索后补充文档中涉及的专业知识。比如：医疗问答中，用户提出关于某种疾病的治疗方案问题。我们从医院的病历、指南、论文文档中检索出初步回答。但是由于医疗领域知识的专业性和准确性要求高，系统可以从外部的知识库比如PubMed，或者预定义的医疗领域知识库，再补充对应药物的说明、适应症、禁忌症等信息。\n2. Modular RAG的参考代码可以看开源的一些RAG代码库，都具备可编排的能力。比如 https://github.com/netease-youdao/QAnything，https://github.com/infiniflow/ragflow 等\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1727408688,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":394553,"user_name":"药师","can_delete":false,"product_type":"c1","uid":1213258,"ip_address":"四川","ucode":"14BB054A38A2F0","user_header":"https://static001.geekbang.org/account/avatar/00/12/83/4a/3e08427e.jpg","comment_is_top":false,"comment_ctime":1727146401,"is_pvip":false,"replies":[{"id":143225,"content":"是的，现代的高质量嵌入模型本质上都是动态的，本质上是通过上下文信息进行训练并生成动态的嵌入表示，例如 bge 和 OpenAI 的 embedding model等。传统的嵌入模型，如 Word2Vec 和 GloVe，是基于预先构建的词汇表生成的，每个单词的嵌入是固定不变的，无法根据上下文变化进行调整。现在rag中用到的都是现代的","user_name":"作者回复","user_name_real":"编辑","uid":3954065,"ctime":1727232234,"ip_address":"上海","comment_id":394553,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100804101,"comment_content":"老师您好，动态嵌入这项是否大部分模型都是支持的，还是需要做定制处理呢？","like_count":0,"discussions":[{"author":{"id":3954065,"avatar":"https://static001.geekbang.org/account/avatar/00/3c/55/91/e3c96b88.jpg","nickname":"常扬","note":"","ucode":"11B62CDABBE875","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":651659,"discussion_content":"是的，现代的高质量嵌入模型本质上都是动态的，本质上是通过上下文信息进行训练并生成动态的嵌入表示，例如 bge 和 OpenAI 的 embedding model等。传统的嵌入模型，如 Word2Vec 和 GloVe，是基于预先构建的词汇表生成的，每个单词的嵌入是固定不变的，无法根据上下文变化进行调整。现在rag中用到的都是现代的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1727232234,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"上海","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1213258,"avatar":"https://static001.geekbang.org/account/avatar/00/12/83/4a/3e08427e.jpg","nickname":"药师","note":"","ucode":"14BB054A38A2F0","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":651710,"discussion_content":"感谢老师答疑","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1727316878,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"四川","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":395307,"user_name":"张申傲","can_delete":false,"product_type":"c1","uid":1182372,"ip_address":"北京","ucode":"22D46BC529BA8A","user_header":"https://static001.geekbang.org/account/avatar/00/12/0a/a4/828a431f.jpg","comment_is_top":false,"comment_ctime":1730173032,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":2,"score":2,"product_id":100804101,"comment_content":"第9讲打卡~","like_count":1}]}