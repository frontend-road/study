{"id":718592,"title":"21｜部署一个鲜花网络电商的人脉工具（下）","content":"<p>你好，我是黄佳，欢迎来到LangChain实战课！</p><p>在上节课中，我们通过LangChain，找到了适合为某一类鲜花做推广的微博大V，并且爬取了他的信息。下面，我带着你继续完成易速鲜花电商人脉工具的后续部分。</p><h2>项目步骤复习</h2><p>先复习一下项目实现过程的五个具体步骤。</p><p><strong>第一步：</strong>通过LangChain的搜索工具，以模糊搜索的方式，帮助运营人员找到微博中有可能对相关鲜花推广感兴趣的大V（比如喜欢牡丹花的大V），并返回UID。</p><p><strong>第二步：</strong>根据微博UID，通过爬虫工具拿到相关大V的微博公开信息，并以JSON格式返回大V的数据。</p><p><strong>第三步：</strong>通过LangChain调用LLM，通过信息整合以及文本生成功能，根据大V的个人信息，写一篇热情洋溢的介绍型文章，谋求与该大V的合作。</p><p><strong>第四步：</strong>把LangChain输出解析功能加入进来，让LLM生成可以嵌入提示模板的格式化数据结构。</p><p><strong>第五步：</strong>添加HTML、CSS，并用Flask创建一个App，在网络上部署及发布这个鲜花电商人脉工具，供市场营销部门的人员使用。</p><p><img src=\"https://static001.geekbang.org/resource/image/27/23/27d8byyfcacec4e4d584ba5f55b70a23.jpg?wh=1744x2038\" alt=\"\" title=\"人脉工具成品\"></p><h2><strong>第三步</strong><strong>：</strong><strong>生成介绍文章</strong></h2><p>下面我们开始第三个步骤，把步骤二中返回的JSON数据（大V的个人简介）传递给LLM，发挥大模型超强的总结整理和文本生成能力，帮助运营人员创建文案。</p><!-- [[[read_end]]] --><p>这个文案可以有很多种形式，比如说可以总结一下大V的特点，根据他的自我介绍猜测一下他的兴趣爱好，还可以让LLM帮助运营人员撰写一篇联络信件的草稿。</p><p>这就看我们如何设计提示模板了。</p><p>重构之后的 findbigV.py 代码如下：</p><pre><code class=\"language-plain\"># 设置OpenAI API密钥\nimport os\nos.environ[\"OPENAI_API_KEY\"] = 'Your OpenAI Key'\nos.environ[\"SERPAPI_API_KEY\"] = 'Your SerpAPI Key'\n\n# 导入所取的库\nimport re\nfrom agents.weibo_agent import lookup_V\nfrom tools.general_tool import remove_non_chinese_fields\nfrom tools.scraping_tool import get_data\nfrom langchain.prompts import PromptTemplate\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.chains import LLMChain\n\nif __name__ == \"__main__\":\n\n&nbsp; &nbsp; # 拿到UID\n&nbsp; &nbsp; response_UID = lookup_V(flower_type = \"牡丹\" )\n\n&nbsp; &nbsp; # 抽取UID里面的数字\n&nbsp; &nbsp; UID = re.findall(r'\\d+', response_UID)[0]\n&nbsp; &nbsp; print(\"这位鲜花大V的微博ID是\", UID)\n\n&nbsp; &nbsp; # 根据UID爬取大V信息\n&nbsp; &nbsp; person_info = get_data(UID)\n&nbsp; &nbsp; print(person_info)\n\n&nbsp; &nbsp; # 移除无用的信息\n&nbsp; &nbsp; remove_non_chinese_fields(person_info)\n&nbsp; &nbsp; print(person_info)\n\n    # 设计提示模板\n&nbsp; &nbsp; letter_template = \"\"\"\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;下面是这个人的微博信息 {information}\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;请你帮我:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;1. 写一个简单的总结\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;2. 挑两件有趣的事情说一说\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;3. 找一些他比较感兴趣的事情\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;4. 写一篇热情洋溢的介绍信\n&nbsp; &nbsp; &nbsp;\"\"\" \n&nbsp; &nbsp; prompt_template = PromptTemplate(\n&nbsp; &nbsp; &nbsp; &nbsp; input_variables=[\"information\"],\n&nbsp; &nbsp; &nbsp; &nbsp; template=letter_template\n&nbsp; &nbsp; )\n\n    # 初始化大模型\n&nbsp; &nbsp; llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\") &nbsp; &nbsp;\n\n    # 初始化链\n&nbsp; &nbsp; chain = LLMChain(llm=llm, prompt=prompt_template)\n\n    # 生成文案\n&nbsp; &nbsp; result = chain.run(information = person_info)\n&nbsp; &nbsp; print(result)\n</code></pre><p>运行程序之后，LLM没有让我们失望，给出了相当专业的文案。</p><p><img src=\"https://static001.geekbang.org/resource/image/20/f9/20469bcbe91f6803fdb3c7da8cbe9af9.jpg?wh=1380x1010\" alt=\"\"></p><p>下面我整理一下程序，把生成文案的功能放在 \\tools\\textgen_tool.py 中，定义为 generate_letter 函数。这样主程序显得比较清爽。</p><p>新的 findbigV.py 代码如下：</p><pre><code class=\"language-plain\"># 导入所取的库\nimport re\nfrom agents.weibo_agent import lookup_V\nfrom tools.general_tool import remove_non_chinese_fields\nfrom tools.scraping_tool import get_data\nfrom tools.textgen_tool import generate_letter\n\n\n\nif __name__ == \"__main__\":\n\n&nbsp; &nbsp; # 拿到UID\n&nbsp; &nbsp; response_UID = lookup_V(flower_type = \"牡丹\" )\n\n&nbsp; &nbsp; # 抽取UID里面的数字\n&nbsp; &nbsp; UID = re.findall(r'\\d+', response_UID)[0]\n&nbsp; &nbsp; print(\"这位鲜花大V的微博ID是\", UID)\n\n&nbsp; &nbsp; # 根据UID爬取大V信息\n&nbsp; &nbsp; person_info = get_data(UID)\n&nbsp; &nbsp; print(person_info)\n\n&nbsp; &nbsp; # 移除无用的信息\n&nbsp; &nbsp; remove_non_chinese_fields(person_info)\n&nbsp; &nbsp; print(person_info)\n\n    # 调用函数根据大V信息生成文本\n&nbsp; &nbsp; result = generate_letter(information = person_info)\n&nbsp; &nbsp; print(result)\n</code></pre><h2><strong>第四步</strong><strong>：</strong><strong>加入输出解析</strong></h2><p>上面的文案已经非常到位，但是你需要把文字Copy Paste出来才能够使用。下面，我们要通过LangChain的输出解析器一步到位，让LLM给我们生成有良好结构的JSON文档，便于下一步集成到 HTML 中进行展示。</p><p>在 tools 文件夹中，新建一个 tools\\ParsingTool.py 文件。</p><pre><code class=\"language-plain\"># 导入所需的类\nfrom langchain.output_parsers import PydanticOutputParser\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\n# 定义一个名为TextParsing的模型，描述了如何解析大V信息\nclass TextParsing(BaseModel):\n&nbsp; &nbsp; summary: str = Field(description=\"大V个人简介\") &nbsp;# 大V的简介或背景信息\n&nbsp; &nbsp; facts: List[str] = Field(description=\"大V的特点\") &nbsp;# 大V的一些显著特点或者事实\n&nbsp; &nbsp; interest: List[str] = Field(description=\"这个大V可能感兴趣的事情\") &nbsp;# 大V可能感兴趣的主题或活动\n&nbsp; &nbsp; letter: List[str] = Field(description=\"一篇联络这个大V的邮件\") &nbsp;# 联络大V的建议邮件内容\n\n&nbsp; &nbsp; # 将模型对象转换为字典\n&nbsp; &nbsp; def to_dict(self):\n&nbsp; &nbsp; &nbsp; &nbsp; return {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"summary\": self.summary,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"facts\": self.facts,\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"interest\": self.interest, &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"letter\": self.letter, &nbsp; &nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; }\n\n# 创建一个基于Pydantic模型的解析器，用于将文本输出解析为特定的结构\nletter_parser: PydanticOutputParser = PydanticOutputParser(\n&nbsp; &nbsp; pydantic_object=TextParsing\n)\n</code></pre><p>此处，TextParsing 是一个用 Pydantic 定义的数据模型，描述了一个大V的个人信息如何被解析和组织。该模型包含四个字段：summary（简介）、facts（事实）、interest（兴趣）、letter（信件）。而to_dict是一个实例方法，它可以将该模型的实例转换为一个字典。最后，我们创建了一个PydanticOutputParser对象，该对象基于TextParsing模型，可以被用来解析一段文本并填充到这个数据模型中。</p><p>然后，我们更新 \\tools\\textgen_tool.py 文件。</p><pre><code class=\"language-plain\"># 导入所需要的库\nfrom langchain.prompts import PromptTemplate\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.chains import LLMChain\nfrom tools.parsing_tool import letter_parser\n\n\n\n# 生成文案的函数\ndef generate_letter(information):\n\n&nbsp; &nbsp; # 设计提示模板\n&nbsp; &nbsp; letter_template = \"\"\"\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;下面是这个人的微博信息 {information}\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;请你帮我:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;1. 写一个简单的总结\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;2. 挑两件有趣的特点说一说\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;3. 找一些他比较感兴趣的事情\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;4. 写一篇热情洋溢的介绍信\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\\n{format_instructions}\"\"\"\n&nbsp; &nbsp; \n&nbsp; &nbsp; prompt_template = PromptTemplate(\n&nbsp; &nbsp; &nbsp; &nbsp; input_variables=[\"information\"],\n&nbsp; &nbsp; &nbsp; &nbsp; template=letter_template,\n&nbsp; &nbsp; &nbsp; &nbsp; partial_variables={\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"format_instructions\": letter_parser.get_format_instructions()\n&nbsp; &nbsp; &nbsp; &nbsp; }, &nbsp; &nbsp; &nbsp; &nbsp; \n&nbsp; &nbsp; )\n\n&nbsp; &nbsp; # 初始化大模型\n&nbsp; &nbsp; llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\") &nbsp; &nbsp;\n\n&nbsp; &nbsp; # 初始化链\n&nbsp; &nbsp; chain = LLMChain(llm=llm, prompt=prompt_template)\n\n&nbsp; &nbsp; # 生成文案\n&nbsp; &nbsp; result = chain.run(information = information)\n&nbsp; &nbsp; return result\n</code></pre><p>通过 {format_instructions} 和 partial_variables 参数，我们利用输出解析器增强了这个提示模板，让 LLM 直接返回我们所需要的格式。</p><p>重新运行 findbigV.py，可以看到，输出已经被解析为标准的JSON格式。</p><p><img src=\"https://static001.geekbang.org/resource/image/c2/a2/c2e1ceb17f44133195d6da9eb4b93ba2.jpg?wh=1328x239\" alt=\"\"></p><p>不过，此时的文案似乎和鲜花运营缺少了一些关联，你可以尝试着调整提示模板中的内容，让这封信写得更加贴合我们鲜花运营的具体意图。</p><h2>第五步：部署人脉工具</h2><p>好啦，到目前为止，这个人脉工具的所有功能都已经完善。我们利用LangChain自动做了好多事。</p><p>下面，我们就制作一个前端页面，同时把这个工具部署到服务器上面去，让我们的运营人员能够随时访问它。</p><h3>HTML 文件</h3><p>首先，创建一个 HTML 文件，用于交互展示，这个文件放在 templates 目录下。</p><pre><code class=\"language-plain\">&lt;!-- templates/index.html --&gt;\n\n&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n&lt;head&gt;\n&nbsp; &nbsp; &lt;meta charset=\"UTF-8\"&gt;\n&nbsp; &nbsp; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;\n&nbsp; &nbsp; &lt;link rel=\"stylesheet\" href=\"{{ url_for('static', filename='css/style.css') }}\"&gt;\n&nbsp; &nbsp; &lt;script src=\"https://code.jquery.com/jquery-3.6.0.min.js\"&gt;&lt;/script&gt;\n&nbsp; &nbsp; &lt;title&gt;Ice Breaker&lt;/title&gt;\n&nbsp; &nbsp; &lt;link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.0/css/all.min.css\" /&gt;\n&nbsp; &nbsp; &lt;div class=\"spinner-container\" id=\"spinner-container\" style=\"display: none;\"&gt;\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;i id=\"loading-spinner\" class=\"fas fa-spinner fa-spin\"&gt;&lt;/i&gt;\n&nbsp; &nbsp; &lt;/div&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&nbsp; &nbsp; &lt;div class=\"container\"&gt;\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;h1&gt;易速鲜花人脉工具&lt;/h1&gt;\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;form id=\"name-form\"&gt;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;input type=\"text\" id=\"flower\" name=\"flower\" placeholder=\"输入一种花（或者其它东西也行）\"&gt;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;button id=\"magic-button\" type=\"submit\"&gt;找到大V&lt;/button&gt;\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;/form&gt;\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;div id=\"result\"&gt;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;img id=\"profile-pic\" src=\"\" alt=\"Profile Picture\" style=\"display: none; max-width: 100%; height: auto; border-radius: 50%; margin-bottom: 20px;\"&gt;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;h2&gt;基本情况&lt;/h2&gt;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;p id=\"summary\"&gt;&lt;/p&gt;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;h2&gt;特色内容&lt;/h2&gt;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;div id=\"facts\"&gt;&lt;/div&gt;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;h2&gt;可能感兴趣的事儿&lt;/h2&gt;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;div id=\"interest\"&gt;&lt;/div&gt;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;h2&gt;联络邮件&lt;/h2&gt;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;div id=\"letter\"&gt;&lt;/div&gt;\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;/div&gt;\n&nbsp; &nbsp; &lt;/div&gt;\n&nbsp; &nbsp; &lt;script&gt;\n&nbsp; &nbsp; &nbsp; &nbsp; $(document).ready(function () {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $('#name-form').on('submit', function (e) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; e.preventDefault();\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $('#spinner-container').show();\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $.ajax({\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; url: '/process',\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; data: $('#name-form').serialize(),\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; type: 'POST',\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; success: function (response) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $('#profile-pic').attr('src', '你的URL'); \n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $('#profile-pic').show(); \n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $('#summary').text(response.summary);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $('#facts').html('&lt;ul&gt;' + response.facts.map(fact =&gt; '&lt;li&gt;' + fact + '&lt;/li&gt;').join('') + '&lt;/ul&gt;');\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $('#interest').html('&lt;ul&gt;' + response.interest.map(interest =&gt; '&lt;li&gt;' + interest + '&lt;/li&gt;').join('') + '&lt;/ul&gt;');\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $('#letter').text(response.letter);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; },\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; error: function (error) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; console.log(error);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; },\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; complete: function () {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $('#spinner-container').hide();\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; });\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; });\n&nbsp; &nbsp; &nbsp; &nbsp; });\n&nbsp; &nbsp; &lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre><h3>CSS 文件</h3><p>为了让 HTML 美一点，我们还制作了一个 CSS 文件 style.css，放在 \\static\\css\\ 目录下。</p><p><img src=\"https://static001.geekbang.org/resource/image/4e/e0/4e067ac76ab579f3f8029a1631f336e0.jpg?wh=130x84\" alt=\"\"></p><p>这个文件就请你去咱们的 <a href=\"https://github.com/huangjia2019/langchain\">GitHub Repo</a> 下载，我就不在这儿展示了。</p><h3>重构 findbigV.py</h3><p>下一步是重构 findbigV.py，把功能封装到一个函数中。</p><pre><code class=\"language-plain\">def find_bigV(flower: str) :\n&nbsp; &nbsp; # 拿到UID\n&nbsp; &nbsp; response_UID = lookup_V(flower_type = flower )\n\n&nbsp; &nbsp; # 抽取UID里面的数字\n&nbsp; &nbsp; UID = re.findall(r'\\d+', response_UID)[0]\n&nbsp; &nbsp; print(\"这位鲜花大V的微博ID是\", UID)\n\n&nbsp; &nbsp; # 根据UID爬取大V信息\n&nbsp; &nbsp; person_info = get_data(UID)\n&nbsp; &nbsp; print(person_info)\n\n&nbsp; &nbsp; # 移除无用的信息\n&nbsp; &nbsp; remove_non_chinese_fields(person_info)\n&nbsp; &nbsp; print(person_info)\n\n    # 调用函数根据大V信息生成文本\n&nbsp; &nbsp; result = generate_letter(information = person_info)\n&nbsp; &nbsp; print(result)\n\n&nbsp; &nbsp; return result\n</code></pre><h3>创建 app.py</h3><p>下面，我们创建一个基于 Flask 的 Web应用，主要用于显示一个输入表单，供大家提交花的名称，并返回市场营销人员所需要的内容，在网页中展示。</p><pre><code class=\"language-plain\"># 导入所需的库和模块\nfrom flask import Flask, render_template, request, jsonify\nfrom findbigV import find_bigV\nimport json\n\n# 实例化Flask应用\napp = Flask(__name__)\n\n# 主页路由，返回index.html模板\n@app.route(\"/\")\ndef index():\n&nbsp; &nbsp; return render_template(\"index.html\")\n\n# 处理请求的路由，仅允许POST请求\n@app.route(\"/process\", methods=[\"POST\"])\ndef process():\n&nbsp; &nbsp; # 获取提交的花的名称\n&nbsp; &nbsp; flower = request.form[\"flower\"]\n&nbsp; &nbsp; # 使用find_bigV函数获取相关数据\n&nbsp; &nbsp; response_str = find_bigV(flower=flower)\n&nbsp; &nbsp; # 使用json.loads将字符串解析为字典\n&nbsp; &nbsp; response = json.loads(response_str)\n\n&nbsp; &nbsp; # 返回数据的json响应\n&nbsp; &nbsp; return jsonify(\n&nbsp; &nbsp; &nbsp; &nbsp; {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"summary\": response[\"summary\"],\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"facts\": response[\"facts\"],\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"interest\": response[\"interest\"],\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"letter\": response[\"letter\"],\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; ) &nbsp; &nbsp;\n\n# 判断是否是主程序运行，并设置Flask应用的host和debug模式\nif __name__ == \"__main__\":\n&nbsp; &nbsp; app.run(host=\"0.0.0.0\", debug=True)\n</code></pre><p>程序非常简单，简单介绍下。</p><ol>\n<li>导入库和模块：这部分导入了Flask框架的相关模块，以及find_bigV函数和JSON库。<br>\n&nbsp;</li>\n<li>创建了一个Flask应用实例。<br>\n&nbsp;</li>\n<li>定义主页路由：当用户访问这个路由时，它将返回一个叫 index.html 的模板。<br>\n&nbsp;</li>\n<li>定义处理请求的路由：这是一个专门处理 POST 请求的路由。其流程如下：<br>\n&nbsp;\n<ul>\n<li>从表单数据中获取名为 <code>\"flower\"</code> 的字段</li>\n<li>使用 find_bigV 函数查询与该花名相关的数据</li>\n<li>解析返回的数据（字符串格式）为 Python 字典</li>\n<li>将这些数据整理并返回为 JSON 格式的响应<br>\n&nbsp;</li>\n</ul>\n</li>\n<li>启动 Flask 应用，监听所有公开的 IP 地址，并在调试模式中运行。</li>\n</ol><p>这样，我们就真正大功告成了，系统上线，运营人员可以在网页中调用我们的产品了。</p><p>运行App程序，就看到了这个人脉工具。</p><p><img src=\"https://static001.geekbang.org/resource/image/26/4d/262yyb04ccde1a3f49b4e9173527df4d.jpg?wh=1152x762\" alt=\"\"></p><p>刚才我一直用牡丹花进行测试，下面使用月季花进行测试，看看能否找出月季花的爱好者。</p><p><img src=\"https://static001.geekbang.org/resource/image/a0/9f/a01632933a6ee20af3646d9008a1249f.jpg?wh=3840x2076\" alt=\"\"></p><p>不辱使命，天狼月季和天狼园艺旗舰店老板，华冠园创园艺科技有限公司的董事长，被我们的大V搜索器发现。我相信，和他联络并且建立合作关系，能够大大拓展易速鲜花的花卉事业。</p><p>有了人脉搜索工具，我对自己的事业充满了进一步的期待！你呢？</p><h2>总结时刻</h2><p>项目完成了！整体程序结构如下：</p><p><img src=\"https://static001.geekbang.org/resource/image/7c/cc/7cdd3207cea4d75ebc3f6c2658a1e0cc.jpg?wh=168x462\" alt=\"\"></p><p>说老实话，这是一个创意和创造力兼备的Project，没有LangChain，很难想象用这么简单的方式，在这么短的时间内，就可以构建出这么有特色的项目。</p><p>此处，我们一块复习了LangChain中的链、代理、工具（特别是标准工具不灵光时，自定义了新工具）、LLM的文本摘要和生成功能、提示模板、输出解析。可以说，这个项目把前面讲的几乎所有最重要的LangChain模块都贯串起来了。</p><p>在这里，我要感谢Eden Marco先生，这个人脉项目的设计（<strong>注意：只是这个项目，可不是整个<strong><strong>专栏的</strong></strong>课程设计</strong>），受到了他的启发（Udemy 课程《Learn LangChain by building FAST a real world generative ai LLM powered application LLM (Python)，Section 3》），并在他的程序架构上进行了大刀阔斧的扩充优化。创意部分，不敢掠美，特此说明。</p><p><img src=\"https://static001.geekbang.org/resource/image/27/a2/271f4b899703yy033324828f862d93a2.jpg?wh=3842x1944\" alt=\"\"></p><p>你可以把这个项目当作一次复习，也可以把它当作一个启发，开发出属于你的、更有创意的程序。</p><h2>思考题</h2><ol>\n<li>修改提示模板，让LLM为你生成更多更有创意、业务上更实用的文案。</li>\n<li>试试爬取其他网站（比如豆瓣）上的公开数据，制作更全面的人脉工具。</li>\n<li>你或许已经发现，我的这个程序不够鲁棒。这里，我用了牡丹、月季进行了测试，程序都找到了相关的UID，但是当我使用其他一些花的时候，比如玫瑰、野菊花，会出现各种各样的错误。你能否修改程序（比如提示模板、输出解析、整体结构），让程序更健壮？</li>\n</ol><p>期待在留言区看到你的成果分享，如果觉得内容对你有帮助，也欢迎分享给有需要的朋友！</p>","comments":[{"had_liked":false,"id":382991,"user_name":"蝈蝈","can_delete":false,"product_type":"c1","uid":2444823,"ip_address":"湖北","ucode":"2B14CECEFD7F46","user_header":"https://static001.geekbang.org/account/avatar/00/25/4e/17/2e131ff0.jpg","comment_is_top":false,"comment_ctime":1698284754,"is_pvip":false,"replies":[{"id":139530,"content":"同学你好，有很多种方式。这里我给你一个RetrievalQAWithSourcesChain，可能是比较简单的方法。下面的Sample代码你跟着这个框架可以实现一下。\n\nfrom langchain.chains import RetrievalQAWithSourcesChain\nfrom langchain.vectorstores import FAISS\nfrom langchain.embeddings import OpenAIEmbeddings\n\n# Load documents into FAISS index\ndoc_store = FAISS.from_documents(documents, OpenAIEmbeddings()) \n\n# Add metadata like title, url, etc to documents\ndoc_store.update_document_metadata(0, {&quot;title&quot;: &quot;Document 1&quot;, &quot;url&quot;: &quot;http:&#47;&#47;example.com&#47;doc1&quot;})\n\n# Initialize chain \nqa_chain = RetrievalQAWithSourcesChain(\n    vectorstore=doc_store, \n    retriever=doc_store.get_dense_retriever(),\n    qa_model=QAModel()  \n)\n\n# Get answer and sources\nresult = qa_chain(question, return_only_outputs=True)\n\nprint(result[&quot;answer&quot;]) \nprint(result[&quot;sources&quot;])","user_name":"作者回复","user_name_real":"编辑","uid":1809833,"ctime":1698382053,"ip_address":"瑞士","comment_id":382991,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100617601,"comment_content":"老师您好，我想请教一个问题，如何在向量库检索之后得到答案的出处。有个场景是这样的，我有三篇文章加载到了向量库，接下来我开始提问，我想在返回的答案时，带上这个答案出自哪片文章，这个需求的实现思路可以简单说一下吗？","like_count":3,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":630393,"discussion_content":"同学你好，有很多种方式。这里我给你一个RetrievalQAWithSourcesChain，可能是比较简单的方法。下面的Sample代码你跟着这个框架可以实现一下。\n\nfrom langchain.chains import RetrievalQAWithSourcesChain\nfrom langchain.vectorstores import FAISS\nfrom langchain.embeddings import OpenAIEmbeddings\n\n# Load documents into FAISS index\ndoc_store = FAISS.from_documents(documents, OpenAIEmbeddings()) \n\n# Add metadata like title, url, etc to documents\ndoc_store.update_document_metadata(0, {&#34;title&#34;: &#34;Document 1&#34;, &#34;url&#34;: &#34;http://example.com/doc1&#34;})\n\n# Initialize chain \nqa_chain = RetrievalQAWithSourcesChain(\n    vectorstore=doc_store, \n    retriever=doc_store.get_dense_retriever(),\n    qa_model=QAModel()  \n)\n\n# Get answer and sources\nresult = qa_chain(question, return_only_outputs=True)\n\nprint(result[&#34;answer&#34;]) \nprint(result[&#34;sources&#34;])","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1698382053,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"瑞士","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":384189,"user_name":"鲸鱼","can_delete":false,"product_type":"c1","uid":1052643,"ip_address":"北京","ucode":"71437C1C601040","user_header":"https://static001.geekbang.org/account/avatar/00/10/0f/e3/c49aa508.jpg","comment_is_top":false,"comment_ctime":1700477047,"is_pvip":false,"replies":[{"id":140172,"content":"好的好的，肯定有很多代码细节值得优化。这个点就很好。我制作这个东西的时候粗糙了一些，欢迎同学们进行大刀阔斧的探讨。","user_name":"作者回复","user_name_real":"编辑","uid":1809833,"ctime":1700578371,"ip_address":"瑞士","comment_id":384189,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100617601,"comment_content":"老师您好，我觉得有些代码可以优化下。app.py中将find_bigV返回的字符串反序列化为json，然后又将其转换为字典，我这边有时会遇到llm返回的json前面带了一句话，导致json反序列化失败；其实通过前面定义的输出解析器可以直接拿到最终的dict，而且解析器内部是通过正则匹配json也避免了额外语句导致的解析失败\n\n    result_dict = letter_parser.parse(response).to_dict()","like_count":1,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":632215,"discussion_content":"好的好的，肯定有很多代码细节值得优化。这个点就很好。我制作这个东西的时候粗糙了一些，欢迎同学们进行大刀阔斧的探讨。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1700578371,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"瑞士","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":383307,"user_name":"打奥特曼的小怪兽","can_delete":false,"product_type":"c1","uid":1060596,"ip_address":"上海","ucode":"DE9FF2D598BED2","user_header":"https://static001.geekbang.org/account/avatar/00/10/2e/f4/1e4d6941.jpg","comment_is_top":false,"comment_ctime":1698833898,"is_pvip":false,"replies":[{"id":139680,"content":"同学你好，想要得到稳定的输出，每一次调用LLM时（或者链和Agent）所有的Temperature参数都要设置为0。","user_name":"作者回复","user_name_real":"作者","uid":1809833,"ctime":1699008081,"ip_address":"瑞士","comment_id":383307,"utype":1}],"discussion_count":3,"race_medal":0,"score":2,"product_id":100617601,"comment_content":"老师您好，我这边是第一次接触 LangChain 和LLM。在运行这个Demo的时候，不能很稳定的获得GTP的输出。\n有时候会获得\nletter_parser.get_format_instructions() 的内容。\n{&quot;properties&quot;: {&quot;summary&quot;: {&quot;description&quot;: &quot;大V个人简介&quot;, &quot;title&quot;: &quot;Summary&quot;, &quot;type&quot;: &quot;string&quot;}, &quot;facts&quot;: {&quot;description&quot;: &quot;大V的特点&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}, &quot;title&quot;: &quot;Facts&quot;, &quot;type&quot;: &quot;array&quot;}, &quot;interest&quot;: {&quot;description&quot;: &quot;这个大V可能感兴趣的事情&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}, &quot;title&quot;: &quot;Interest&quot;, &quot;type&quot;: &quot;array&quot;}, &quot;letter&quot;: {&quot;description&quot;: &quot;一篇联系这个大V的邮件&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}, &quot;title&quot;: &quot;Letter&quot;, &quot;type&quot;: &quot;array&quot;}}, &quot;required&quot;: [&quot;summary&quot;, &quot;facts&quot;, &quot;interest&quot;, &quot;letter&quot;]}。\n想请教下 怎么添加调试代码，感谢！","like_count":1,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":630893,"discussion_content":"同学你好，想要得到稳定的输出，每一次调用LLM时（或者链和Agent）所有的Temperature参数都要设置为0。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1699008081,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"瑞士","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1118978,"avatar":"https://static001.geekbang.org/account/avatar/00/11/13/02/cb050516.jpg","nickname":"qkyong","note":"","ucode":"641B0E9D9BC170","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":631501,"discussion_content":"我调试时也出现这个现象，把输出解析去除后，llm就可以返回正常的响应\n    prompt_template = PromptTemplate(\n        input_variables=[&#34;information&#34;],\n        template=letter_template,\n        # partial_variables={\n        #     &#34;format_instructions&#34;: letter_parser.get_format_instructions()\n        # },\n    )\n这块是llm对输出解析指令的理解问题？还是我们写的输出解析类有问题？\n请老师指教","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1699620010,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"加拿大","group_id":0},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1052643,"avatar":"https://static001.geekbang.org/account/avatar/00/10/0f/e3/c49aa508.jpg","nickname":"鲸鱼","note":"","ucode":"71437C1C601040","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1118978,"avatar":"https://static001.geekbang.org/account/avatar/00/11/13/02/cb050516.jpg","nickname":"qkyong","note":"","ucode":"641B0E9D9BC170","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":632106,"discussion_content":"注释掉这部分，llm还会返回json？不可能吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1700476453,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":631501,"ip_address":"北京","group_id":0},"score":632106,"extra":""}]}]},{"had_liked":false,"id":384110,"user_name":"招谁惹谁","can_delete":false,"product_type":"c1","uid":1014054,"ip_address":"浙江","ucode":"F4B43C8C098E96","user_header":"https://static001.geekbang.org/account/avatar/00/0f/79/26/9ac98036.jpg","comment_is_top":false,"comment_ctime":1700310342,"is_pvip":false,"replies":[{"id":140180,"content":"进行Server-Sent Events (SSE)请求的压力测试这块我不大熟，希望有经验的同学给讨论讨论。我回答的话我只能问ChatGPT。。。","user_name":"作者回复","user_name_real":"编辑","uid":1809833,"ctime":1700581353,"ip_address":"瑞士","comment_id":384110,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100617601,"comment_content":"请问老师，最后如果流式输出，怎么对sse请求做压测来评估性能呢？","like_count":0,"discussions":[{"author":{"id":1809833,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/a9/4602808f.jpg","nickname":"黄佳","note":"","ucode":"8EC41D2EAB0E3C","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":632228,"discussion_content":"进行Server-Sent Events (SSE)请求的压力测试这块我不大熟，希望有经验的同学给讨论讨论。我回答的话我只能问ChatGPT。。。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1700581353,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"瑞士","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]}]}