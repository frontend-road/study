{"id":99379,"title":"22 | Apache Beam的前世今生","content":"<p>你好，我是蔡元楠。</p><p>今天我要与你分享的主题是“ Apache Beam的前世今生”。</p><p>从这一讲开始，我们将进入一个全新的篇章。在这一讲中，我将会带领你了解Apache Beam的完整诞生历程。</p><p>让我们一起来感受一下，<span class=\"orange\">Google是如何从处理框架上的一无所有，一直发展到推动、制定批流统一的标准的</span>。除此之外，我还会告诉你，在2004年发布了MapReduce论文之后，Google在大规模数据处理实战中到底经历了哪些技术难题和技术变迁。我相信通过这一讲，你将会完整地认识到为什么Google会强力推崇Apache Beam。</p><p>在2003年以前，Google内部其实还没有一个成熟的处理框架来处理大规模数据。而当时Google的搜索业务又让工程师们不得不面临着处理大规模数据的应用场景，像计算网站URL访问量、计算网页的倒排索引（Inverted Index）等等。</p><p>那该怎么办呢？这个答案既简单又复杂：自己写一个。</p><p>没错，当时的工程师们需要自己写一个自定义的逻辑处理架构来处理这些数据。因为需要处理的数据量非常庞大，业务逻辑不太可能只放在一台机器上面运行。很多情况下，我们都必须把业务逻辑部署在分布式环境中。所以，这个自定义的逻辑处理架构还必须包括容错系统（Fault Tolerant System）的设计。</p><!-- [[[read_end]]] --><p>久而久之，Google内部不同组之间都会开发出一套自己组内的逻辑处理架构。因为工程师们遇到的问题很多都是相似的，开发出来的这些逻辑处理架构很多时候也都是大同小异，只是有一些数据处理上的逻辑差别而已。这无疑就变成了大家一起重复造轮子的情况。</p><p>这时候，就有工程师想到，能不能改善这一种状况。MapReduce的架构思想也就由此应运而生。</p><h2>MapReduce</h2><p>其实MapReduce的架构思想可以从两个方面来看。</p><p>一方面，它希望能<span class=\"orange\">提供一套简洁的API来表达工程师数据处理的逻辑</span>。另一方面，要<span class=\"orange\">在这一套API底层嵌套一套扩展性很强的容错系统</span>，使得工程师能够将心思放在逻辑处理上，而不用过于分心去设计分布式的容错系统。</p><p>这个架构思想的结果你早就已经知道了。MapReduce这一套系统在Google获得了巨大成功。在2004年的时候，Google发布的一篇名为“MapReduce: Simplified Data Processing on Large Clusters”的论文就是这份成果的总结。</p><p>在MapReduce的计算模型里，它将数据的处理抽象成了以下这样的计算步骤</p><ul>\n<li>Map：计算模型从输入源（Input Source）中读取数据集合，这些数据在经过了用户所写的逻辑后生成出一个临时的键值对数据集（Key/Value Set）。MapReduce计算模型会将拥有相同键（Key）的数据集集中起来然后发送到下一阶段。这一步也被称为Shuffle阶段。</li>\n<li>Reduce：接收从Shuffle阶段发送过来的数据集，在经过了用户所写的逻辑后生成出零个或多个结果。</li>\n</ul><p>很多人都说，这篇MapReduce论文是具有划时代意义的。可你知道为什么都这么说吗？</p><p>这是因为Map和Reduce这两种抽象其实可以适用于非常多的应用场景，而MapReduce论文里面所阐述的容错系统，可以让我们所写出来的数据处理逻辑在分布式环境下有着很好的可扩展性（Scalability）。</p><p>MapReduce在内部的成功使得越来越多的工程师希望使用MapReduce来解决自己项目的难题。</p><p>但是，就如我在模块一中所说的那样，使用MapReduce来解决一个工程难题往往会涉及到非常多的步骤，而每次使用MapReduce的时候我们都需要在分布式环境中启动机器来完成Map和Reduce步骤，以及启动Master机器来协调这两个步骤的中间结果（Intermediate Result），消耗不少硬件上的资源。</p><p>这样就给工程师们带来了以下一些疑问：</p><ul>\n<li>我们的项目数据规模是否真的需要运用MapReduce来解决呢？是否可以在一台机器上的内存中解决呢？</li>\n<li>我们所写的MapReduce项目是否已经是最优的呢？因为每一个Map和Reduce步骤这些中间结果都需要写在磁盘上，会十分耗时。是否有些步骤可以省略或者合并呢？我们是否需要让工程师投入时间去手动调试这些MapReduce项目的性能呢？</li>\n</ul><p>问题既然已经提出来了，Google的工程师们便开始考虑是否能够解决上述这些问题。最好能够让工程师（无论是新手工程师亦或是经验老到的工程师）都能专注于数据逻辑上的处理，而不用花更多时间在测试调优上。</p><p>FlumeJava就是在这样的背景下诞生的。</p><h2>FlumeJava</h2><p>这里，我先将FlumeJava的成果告诉你。因为FlumeJava的思想又在Google内容获得了巨大成功，Google也希望将这个思想分享给业界。所以在2010年的时候，Google公开了FlumeJava架构思想的论文。</p><p><img src=\"https://static001.geekbang.org/resource/image/8b/f4/8be0a05a553f505368eecd5acf78b9f4.png?wh=1600*800\" alt=\"unpreview\"></p><p>FlumeJava的思想是<span class=\"orange\">将所有的数据都抽象成名为PCollection的数据结构</span>，无论是从内存中读取的数据，还是在分布式环境下所读取的文件。</p><p>这样的抽象对于测试代码中的逻辑是十分有好处的。要知道，想测试MapReduce的话，你可能需要读取测试数据集，然后在分布式环境下运行，来测试代码逻辑。但如果你有了PCollection这一层抽象的话，你的测试代码可以在内存中读取数据然后跑测试文件，也就是同样的逻辑既可以在分布式环境下运行也可以在单机内存中运行。</p><p>而FlumeJava在MapReduce框架中Map和Reduce思想上，抽象出4个了原始操作（Primitive Operation），分别是parallelDo、groupByKey、 combineValues和flatten，让工程师可以利用这4种原始操作来表达任意Map或者Reduce的逻辑。</p><p>同时，FlumeJava的架构运用了一种Deferred Evaluation的技术，来优化我们所写的代码。</p><p>对于Deferred Evaluation，你可以理解为FlumeJava框架会首先会将我们所写的逻辑代码静态遍历一次，然后构造出一个执行计划的有向无环图。这在FlumeJava框架里被称为Execution Plan Dataflow Graph。</p><p>有了这个图之后，FlumeJava框架就会自动帮我们优化代码。例如，合并一些本来可以通过一个Map和Reduce来表达，却被新手工程师分成多个Map和Reduce的代码。</p><p>FlumeJava框架还可以通过我们的输入数据集规模，来预测输出结果的规模，从而自行决定代码是放在内存中跑还是在分布式环境中跑。</p><p>总的来说，FlumeJava是非常成功的。但是，FlumeJava也有一个弊端，那就是FlumeJava基本上只支持批处理（Batch Execution）的任务，对于无边界数据（Unbounded Data）是不支持的。所以，Google内部有着另外一个被称为Millwheel的项目来支持处理无边界数据，也就是流处理框架。</p><p>在2013年的时候，Google也公开了Millwheel思想的论文。</p><p><img src=\"https://static001.geekbang.org/resource/image/b4/28/b49ae286ad9952a10d2762e4bafdcb28.png?wh=1600*799\" alt=\"unpreview\"></p><p>这时Google的工程师们回过头看，感叹了一下成果，并觉得自己可以再优秀一些：<span class=\"orange\">既然我们已经创造出好几个优秀的大规模数据处理框架了，那我们能不能集合这几个框架的优点，推出一个统一的框架呢？</span></p><p>这也成为了Dataflow Model诞生的契机。</p><h2>Dataflow Model</h2><p>在2015年时候，Google公布了Dataflow Model的论文，同时也推出了基于Dataflow Model思想的平台Cloud Dataflow，让Google以外的工程师们也能够利用这些SDK来编写大规模数据处理的逻辑。</p><p><img src=\"https://static001.geekbang.org/resource/image/b7/10/b7e96f551dd36d11efab22b666558f10.png?wh=1600*752\" alt=\"\"></p><p>讲到这么多，你可能会有个疑问了，怎么Apache Beam还没有出场呢？别着急，Apache Beam的登场契机马上就到了。</p><h2>Apache Beam</h2><p>前面我说了，Google基于Dataflow Model的思想推出了Cloud Dataflow云平台，但那毕竟也需要工程师在Google的云平台上面运行程序才可以。如果有的工程师希望在别的平台上面跑该如何解决呢？</p><p>所以，为了解决这个问题，Google在2016年的时候联合了Talend、Data Artisans、Cloudera这些大数据公司，基于Dataflow Model的思想开发出了一套SDK，并贡献给了Apache Software Foundation。而它Apache Beam的名字是怎么来的呢？就如下图所示，Beam的含义就是统一了批处理和流处理的一个框架。</p><p><img src=\"https://static001.geekbang.org/resource/image/87/ec/873099f513c51a8ecce528f0d6e600ec.png?wh=1142*621\" alt=\"unpreview\"></p><p>这就是Apache Beam的发展历史，从中你可以看到它拥有很多优点，而这也是我们需要Beam的原因。</p><p>在现实世界中，很多时候我们不可避免地需要对数据同时进行批处理和流处理。<span class=\"orange\">Beam提供了一套统一的API来处理这两种数据处理模式，让我们只需要将注意力专注于在数据处理的算法上，而不用再花时间去对两种数据处理模式上的差异进行维护。</span></p><p>它能够将工程师写好的算法逻辑很好地与底层的运行环境分隔开。也就是说，当我们通过Beam提供的API写好数据处理逻辑后，这个逻辑可以不作任何修改，直接放到任何支持Beam API的底层系统上运行。</p><p>关于怎么理解这个优点，其实我们可以借鉴一下SQL（Structure Query Language）的运行模式。</p><p>我们在学习SQL语言的时候，基本上都是独立于底层数据库系统来学习的。而在我们写完一个分析数据的Query之后，只要底层数据库的Schema不变，这个Query是可以放在任何数据库系统上运行的，例如放在MySql上或者Oracle DB上。</p><p>同样的，我们用Beam API写好的数据处理逻辑无需改变，可以根据自身的需求，将逻辑放在Google Cloud Dataflow上跑，也可以放在Apache Flink上跑。在Beam上，这些底层运行的系统被称为Runner。现阶段Apache Beam支持的Runner有近十种，包括了我们很熟悉的Apache Spark和Apache Flink。</p><p>当然最后Apache Beam也是希望对自身的SDK能够支持任意多的语言来编写。现阶段Beam支持Java、Python和Golang。</p><p><img src=\"https://static001.geekbang.org/resource/image/56/48/56637be15a6c3ad47fda35731ff88448.png?wh=1593*1226\" alt=\"unpreview\"></p><p>也就是说，通过Apache Beam，最终我们可以用自己喜欢的编程语言，通过一套Beam Model统一地数据处理API，编写好符合自己应用场景的数据处理逻辑，放在自己喜欢的Runner上运行。</p><h2>小结</h2><p>今天，我与你一起回顾了Apache Beam的完整诞生历程。</p><p>通过这一讲，我希望你知道每一项技术都不会毫无理由地诞生，而每一项技术诞生的背后都是为了解决某些特定问题的。了解前人一步步解决问题的过程，有助于我们更有层次地理解一项技术产生的根本原因。在学习一项技术之前，先了解了它的历史源流，可以让我们做到知其然，并知其所以然。</p><h2>思考题</h2><p>你也能分享一些你所经历过的技术变迁或是技术诞生的故事吗？</p><p>欢迎你把答案写在留言区，与我和其他同学一起讨论。如果你觉得有所收获，也欢迎把文章分享给你的朋友。</p><p></p>","neighbors":{"left":{"article_title":"21 | 深入对比Spark与Flink：帮你系统设计两开花","id":99152},"right":{"article_title":"23 | 站在Google的肩膀上学习Beam编程模型","id":100478}},"comments":[{"had_liked":false,"id":102065,"user_name":"JohnT3e","can_delete":false,"product_type":"c1","uid":1063982,"ip_address":"","ucode":"CF4AAAC933529C","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLdWHFCr66TzHS2CpCkiaRaDIk3tU5sKPry16Q7ic0mZZdy8LOCYc38wOmyv5RZico7icBVeaPX8X2jcw/132","comment_is_top":false,"comment_ctime":1560128095,"is_pvip":false,"replies":[{"id":"36793","content":"👍","user_name":"作者回复","comment_id":102065,"uid":"1568170","ip_address":"","utype":1,"ctime":1560129460,"user_name_real":"Geek_Test"}],"discussion_count":2,"race_medal":0,"score":"319387707999","product_id":100025301,"comment_content":"文章中的几篇论文地址：<br>0. MapReduce: https:&#47;&#47;research.google.com&#47;archive&#47;map reduce-osdi04.pdf <br>1. Flumejava: https:&#47;&#47;research.google.com&#47;pubs&#47;archive&#47;35650.pdf<br>2. MillWheel: https:&#47;&#47;research.google.com&#47;pubs&#47;archive&#47;41378.pdf<br>3. Data flow Model: https:&#47;&#47;www.vldb.org&#47;pvldb&#47;vol8&#47;p1792-Akidau.pdf<br><br>个人认为还是应该读一读的，毕竟几十年的发展不能靠看一两篇文章就搞清楚的<br>","like_count":75,"discussions":[{"author":{"id":1568170,"avatar":"https://static001.geekbang.org/account/avatar/00/17/ed/aa/c2b9e399.jpg","nickname":"Geek_Test","note":"","ucode":"2A70B596E8F49D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":453242,"discussion_content":"👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1560129460,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":1}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1004264,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/52/e8/92a2e66d.jpg","nickname":"第二少","note":"","ucode":"4A09D1E7589F67","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":547782,"discussion_content":"👍 更正一下，多了个空格\n0. MapReduce: https://research.google.com/archive/mapreduce-osdi04.pdf","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1642860338,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":103559,"user_name":"渡码","can_delete":false,"product_type":"c1","uid":1348536,"ip_address":"","ucode":"8FD8B863D1DA0C","user_header":"https://static001.geekbang.org/account/avatar/00/14/93/b8/6510592e.jpg","comment_is_top":false,"comment_ctime":1560473022,"is_pvip":false,"replies":[{"id":"37516","content":"谢谢分享！这个例子我觉得非常棒！","user_name":"作者回复","comment_id":103559,"uid":"1503187","ip_address":"","utype":1,"ctime":1560495345,"user_name_real":"Geek_88e0d7"}],"discussion_count":1,"race_medal":0,"score":"160474262974","product_id":100025301,"comment_content":"我举一个前端技术变迁的例子，移动端开发最早分android和iOS分别开发，往往相同逻辑要不同团队开发两次，成本大且重复。后来出现h5 ，但h5性能不行。再后来fb推react native，在原生开发之上加了一层bridge，上层提供统一接口，下层分平台调用，这解决了h5的性能问题，但应用大了以后上层与原生层通信又是影响性能的瓶颈。后来谷歌推出了flutter 直接编译成不同平台运行代码，减少了中间通信过程，有点beam的意思。看来谷歌挺热衷于干这事","like_count":38,"discussions":[{"author":{"id":1503187,"avatar":"","nickname":"Geek_88e0d7","note":"","ucode":"3E2596F3EB9165","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":453920,"discussion_content":"谢谢分享！这个例子我觉得非常棒！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1560495345,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":1}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":102566,"user_name":"coder","can_delete":false,"product_type":"c1","uid":1399673,"ip_address":"","ucode":"929E3FFD14EFC8","user_header":"https://static001.geekbang.org/account/avatar/00/15/5b/79/d55044ac.jpg","comment_is_top":false,"comment_ctime":1560253476,"is_pvip":false,"replies":[{"id":"37128","content":"谢谢你的留言！非常好的总结！","user_name":"作者回复","comment_id":102566,"uid":"1503187","ip_address":"","utype":1,"ctime":1560281366,"user_name_real":"Geek_88e0d7"}],"discussion_count":2,"race_medal":0,"score":"61689795620","product_id":100025301,"comment_content":"感觉MapReduce、FlumeJava、Spark等这些框架的思想跟目前在ML领域大火的tensorflow类似。TensorFlow是把数据抽象成Tensor，有一系列对它的操作，conv、pooling等，dnn模型在框架内部的表示也是图的形式，计算图，节点表示计算，边表示tensor，通过在计算图上做调度和优化，转换成比较高效的计算图。再通过stream executor映射到具体的计算平台上，e.g. TPU，GPU等，操作会转换成库调用或者通过xla编译器转换成hlo IR，再经过一系列的优化，最终转换成具体硬件平台的指令。总之，这些框架背后的思想挺类似的","like_count":15,"discussions":[{"author":{"id":1503187,"avatar":"","nickname":"Geek_88e0d7","note":"","ucode":"3E2596F3EB9165","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":453481,"discussion_content":"谢谢你的留言！非常好的总结！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1560281366,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":1}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1970391,"avatar":"https://static001.geekbang.org/account/avatar/00/1e/10/d7/65ff6e5d.jpg","nickname":"机智的李赛艇","note":"","ucode":"66794F6816DD26","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":344907,"discussion_content":"同理beam是不是类似于Keras，底层可以说tensor\nflow也可以是Theano","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1611625049,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":110550,"user_name":"CoderLean","can_delete":false,"product_type":"c1","uid":1518409,"ip_address":"","ucode":"DC9E25428EDB3F","user_header":"https://static001.geekbang.org/account/avatar/00/17/2b/49/e94b2a35.jpg","comment_is_top":false,"comment_ctime":1562292860,"is_pvip":false,"discussion_count":4,"race_medal":0,"score":"18742162044","product_id":100025301,"comment_content":"一直有个疑问，既然StructedStreaming已经实现了流批一致的API，为什么还要学Beam","like_count":5,"discussions":[{"author":{"id":1116191,"avatar":"https://static001.geekbang.org/account/avatar/00/11/08/1f/b24a561d.jpg","nickname":"～风铃～","note":"","ucode":"4EEA12C17BA913","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":326029,"discussion_content":"感觉更多的是谷歌自己用，","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605502496,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1897610,"avatar":"","nickname":"Fiery","note":"","ucode":"CDB000687A6B14","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":203539,"discussion_content":"Spark/Flink/Beam其实在获取用户这个层面现在是竞争关系。。。Beam背后的意思其实是Google希望使用Beam的公司可以无缝转到GCP上，但别忘记了，Spark和Flink背后也都是商业公司，所以至少隐形的竞争是存在的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1584052958,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1068372,"avatar":"https://static001.geekbang.org/account/avatar/00/10/4d/54/9c214885.jpg","nickname":"kylexy_0817","note":"","ucode":"392DD9DD5E4B6E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":70604,"discussion_content":"Beam统一了批流处理，并且可以跑在不同的runner上，一次编译，多处运行","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1575372626,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1110662,"avatar":"https://static001.geekbang.org/account/avatar/00/10/f2/86/d689f77e.jpg","nickname":"Hank_Yan","note":"","ucode":"86899B561C502B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1068372,"avatar":"https://static001.geekbang.org/account/avatar/00/10/4d/54/9c214885.jpg","nickname":"kylexy_0817","note":"","ucode":"392DD9DD5E4B6E","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":289659,"discussion_content":"那也得其他平台配合吧，总觉得很鸡肋","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1594173533,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":70604,"ip_address":""},"score":289659,"extra":""}]}]},{"had_liked":false,"id":102395,"user_name":"morgan","can_delete":false,"product_type":"c1","uid":1261716,"ip_address":"","ucode":"11949530DF354E","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/1o8gB5DOdHfAMQb91icmGDvTLhC4N9gusYGryBOxhtEeEDhWlzCkLib06hIeCejwuxBiaXpAZ17JVAtcVbmKfat5Q/132","comment_is_top":false,"comment_ctime":1560215762,"is_pvip":false,"replies":[{"id":"36977","content":"谢谢提问！Spark可以作为Beam的一个底层Runner来运行通过Beam SDK所编写的数据处理逻辑。我觉得在读完第23讲中所讲述的Beam生态圈后，你会对这个概念有一个更好的认识。","user_name":"作者回复","comment_id":102395,"uid":"1503187","ip_address":"","utype":1,"ctime":1560237928,"user_name_real":"Geek_88e0d7"}],"discussion_count":1,"race_medal":0,"score":"14445117650","product_id":100025301,"comment_content":"您好，beam和spark是什么关系呢？","like_count":3,"discussions":[{"author":{"id":1503187,"avatar":"","nickname":"Geek_88e0d7","note":"","ucode":"3E2596F3EB9165","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":453398,"discussion_content":"谢谢提问！Spark可以作为Beam的一个底层Runner来运行通过Beam SDK所编写的数据处理逻辑。我觉得在读完第23讲中所讲述的Beam生态圈后，你会对这个概念有一个更好的认识。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1560237928,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":1}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":196489,"user_name":"Eden2020","can_delete":false,"product_type":"c1","uid":1899158,"ip_address":"","ucode":"0DEE62F2335237","user_header":"https://static001.geekbang.org/account/avatar/00/1c/fa/96/4a7b7505.jpg","comment_is_top":false,"comment_ctime":1585285469,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5880252765","product_id":100025301,"comment_content":"经历过数据库技术变迁，关系数据库，面向分析的列式数据库，分布式文档数据库，时序数据库，图数据库等等","like_count":2},{"had_liked":false,"id":118120,"user_name":"住羽光","can_delete":false,"product_type":"c1","uid":1145157,"ip_address":"","ucode":"11E48DEB421D9C","user_header":"https://static001.geekbang.org/account/avatar/00/11/79/45/05a88185.jpg","comment_is_top":false,"comment_ctime":1564248064,"is_pvip":false,"replies":[{"id":"43289","content":"谢谢你的提问！这个要靠平时多看看论文和听听大数据处理的Summit，当然其中也有和其他工程师交流知道的信息。","user_name":"作者回复","comment_id":118120,"uid":"1503187","ip_address":"","utype":1,"ctime":1564268864,"user_name_real":"Geek_88e0d7"}],"discussion_count":1,"race_medal":0,"score":"5859215360","product_id":100025301,"comment_content":"请问老师，是如何了解这些大数据处理框架的历史呢？，老师自己，有什么查找资料的好方法吗？","like_count":1,"discussions":[{"author":{"id":1503187,"avatar":"","nickname":"Geek_88e0d7","note":"","ucode":"3E2596F3EB9165","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":460271,"discussion_content":"谢谢你的提问！这个要靠平时多看看论文和听听大数据处理的Summit，当然其中也有和其他工程师交流知道的信息。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1564268864,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":1}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":104211,"user_name":"linuxfans","can_delete":false,"product_type":"c1","uid":1193815,"ip_address":"","ucode":"0C0BEE82F8A409","user_header":"https://static001.geekbang.org/account/avatar/00/12/37/57/750c641d.jpg","comment_is_top":false,"comment_ctime":1560682178,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5855649474","product_id":100025301,"comment_content":"如蔡老师所说，任何新技术都要了解来龙去脉，尤其是如何解决当前问题的。但实际上操作起来，尤其在国内，我们是无法在网上找到线索或者文章分析新技术的动机和理念的，通常就是直接告诉你，我这个技术多好，可往往未必适合自己的场景，这个如何破？","like_count":2},{"had_liked":false,"id":106716,"user_name":"Milittle","can_delete":false,"product_type":"c1","uid":1045455,"ip_address":"","ucode":"80E566639A8ABB","user_header":"https://static001.geekbang.org/account/avatar/00/0f/f3/cf/851dab01.jpg","comment_is_top":false,"comment_ctime":1561377287,"is_pvip":true,"replies":[{"id":"38627","content":"谢谢分享啊！","user_name":"作者回复","comment_id":106716,"uid":"1503187","ip_address":"","utype":1,"ctime":1561401387,"user_name_real":"Geek_88e0d7"}],"discussion_count":1,"race_medal":0,"score":"1561377287","product_id":100025301,"comment_content":"onnx走的路子和beam一致呀","like_count":0,"discussions":[{"author":{"id":1503187,"avatar":"","nickname":"Geek_88e0d7","note":"","ucode":"3E2596F3EB9165","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":455192,"discussion_content":"谢谢分享啊！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561401387,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":1}","child_discussion_number":0,"child_discussions":[]}]}]}