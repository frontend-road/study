{"id":731314,"title":"那么，ChatGPT 到底在做什么？它为什么能做到这些？","content":"<p>ChatGPT 的基本概念在某种程度上相当简单：首先从互联网、书籍等获取人类创造的海量文本样本，然后训练一个神经网络来生成“与之类似”的文本。特别是，它能够从“提示”开始，继续生成“与其训练数据相似的文本”。</p><p>正如我们所见，ChatGPT 中的神经网络实际上由非常简单的元素组成，尽管有数十亿个。神经网络的基本操作也非常简单，本质上是对于它生成的每个新词（或词的一部分），都将根据目前生成的文本得到的输入依次传递“给其所有元素一次”（没有循环等）。</p><p>值得注意和出乎意料的是，这个过程可以成功地产生与互联网、书籍等中的内容“相似”的文本。ChatGPT 不仅能产生连贯的人类语言，而且能根据“阅读”过的内容来“循着提示说一些话”。它并不总是能说出“在全局上有意义”（或符合正确计算）的话，因为（如果没有利用 Wolfram|Alpha 的“计算超能力”）它只是在根据训练材料中的内容“听起来像什么”来说出“听起来正确”的话。</p><p>ChatGPT 的具体工程非常引人注目。但是，（至少在它能够使用外部工具之前）ChatGPT“仅仅”是从其积累的“传统智慧的统计数据”中提取了一些“连贯的文本线索”。但是，结果的类人程度已经足够令人惊讶了。正如我所讨论的那样，这表明了一些至少在科学上非常重要的东西：人类语言及其背后的思维模式在结构上比我们想象的更简单、更“符合规律”。ChatGPT 已经隐含地发现了这一点。但是我们可以用语义语法、计算语言等来明确地揭开它的面纱。</p><!-- [[[read_end]]] --><p>ChatGPT 在生成文本方面表现得非常出色，结果通常非常类似于人类创作的文本。这是否意味着 ChatGPT 的工作方式像人类的大脑一样？它的底层人工神经网络结构说到底是对理想化大脑的建模。当人类生成语言时，许多方面似乎非常相似。</p><p>当涉及训练（即学习）时，大脑和当前计算机在“硬件”（以及一些未开发的潜在算法思想）上的不同之处会迫使 ChatGPT 使用一种可能与大脑截然不同的策略（在某些方面不太有效率）。还有一件事值得一提：甚至与典型的算法计算不同，ChatGPT 内部没有“循环”或“重新计算数据”。这不可避免地限制了其计算能力—即使与当前的计算机相比也是如此，更谈不上与大脑相比了。</p><p>我们尚不清楚如何在“修复”这个问题的同时仍然让系统以合理的效率进行训练。但这样做可能会使未来的 ChatGPT 能够执行更多“类似大脑的事情”。当然，有许多事情大脑并不擅长，特别是涉及不可约计算的事情。对于这些问题，大脑和像 ChatGPT 这样的东西都必须寻求“外部工具”，比如 Wolfram 语言的帮助。</p><p>但是就目前而言，看到 ChatGPT 已经能够做到的事情是非常令人兴奋的。在某种程度上，它是一个极好的例子，说明了大量简单的计算元素可以做出非凡、惊人的事情。它也为我们提供了 2000 多年以来的最佳动力，来更好地理解人类条件（human condition）的核心特征—人类语言及其背后的思维过程—的本质和原则。</p><br style=\"page-break-after:always\">","comments":[{"had_liked":false,"id":386703,"user_name":"3.141516","can_delete":false,"product_type":"c1","uid":1013309,"ip_address":"广东","ucode":"34AF71B02692F3","user_header":"https://static001.geekbang.org/account/avatar/00/0f/76/3d/8120438b.jpg","comment_is_top":false,"comment_ctime":1705375401,"is_pvip":true,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100636602,"comment_content":"人类语言及其背后的思维模式在结构上比我们想象的更简单、更“符合规律”。ChatGPT 已经隐含地发现了这一点。但是我们可以用语义语法、计算语言等来明确地揭开它的面纱。","like_count":1}]}