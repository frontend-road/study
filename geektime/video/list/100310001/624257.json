{"id":624257,"title":"97｜如何扩展数据类型？","content":"<p><strong>课后习题</strong><br>\n请你编写程序，统计一篇文章中出现频率在前五的单词，并将单词和出现次数一起输出到终端。</p><p><strong>课程代码、课件及其他相关资料地址</strong><br>\n<a href=\"https://gitee.com/wilsonyin/zero-basics-python\">https://gitee.com/wilsonyin/zero-basics-python</a></p>","comments":[{"had_liked":false,"id":367406,"user_name":"Cy23","can_delete":false,"product_type":"c3","uid":1591293,"ip_address":"辽宁","ucode":"8DC561C5151758","user_header":"https://static001.geekbang.org/account/avatar/00/18/47/fd/895f0c27.jpg","comment_is_top":false,"comment_ctime":1675217253,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100310001,"comment_content":"import re\nfrom collections import Counter\n\nwith open(&#39;1.txt&#39;,&#39;r&#39;) as f:\n    data = f.read().lower()\nwords = re.findall(r&#39;\\w+&#39;, data)\nprint(Counter(words).most_common(5))","like_count":1},{"had_liked":false,"id":366976,"user_name":"PatrickL","can_delete":false,"product_type":"c3","uid":1341431,"ip_address":"上海","ucode":"EF0EC18639B9B2","user_header":"https://static001.geekbang.org/account/avatar/00/14/77/f7/11548247.jpg","comment_is_top":false,"comment_ctime":1674724685,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100310001,"comment_content":"import re\nfrom collections import Counter\nwith open(&#39;hamlet.txt&#39;,&#39;r&#39;) as f:\n    data = f.read().lower()\nwords = re.findall(r&#39;\\w+&#39;, data)\nprint(Counter(words).most_common(5))","like_count":1},{"had_liked":false,"id":385246,"user_name":"Geek_631607","can_delete":false,"product_type":"c3","uid":3789991,"ip_address":"广东","ucode":"EAF874838F0BE4","user_header":"","comment_is_top":false,"comment_ctime":1702347538,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100310001,"comment_content":"你可以使用 Python 的 `collections` 库中的 `Counter` 类来统计一篇文章中出现频率在前五的单词。以下是一个示例代码：\n\n```python\nfrom collections import Counter\nimport re\n\n# 假设这是你的文章\narticle = &quot;&quot;&quot;\n在 Python 中，你可以使用各种库来抓取和保存非文字类数据。以下是一些基本的步骤和代码示例：\n获取数据的地址：通常，非文字类数据（如图片或声音文件）在网页上以链接的形式存在。你可以使用 requests 库来获取网页的内容，然后使用 BeautifulSoup 库来解析网页并提取出数据的链接。以下是一个简单的代码示例：\n&quot;&quot;&quot;\n\n# 使用正则表达式将文章分割成单词\nwords = re.findall(r&#39;\\w+&#39;, article)\n\n# 使用 Counter 统计每个单词的出现次数\nword_counts = Counter(words)\n\n# 找出出现频率在前五的单词\ntop_five = word_counts.most_common(5)\n\n# 输出结果\nfor word, count in top_five:\n    print(f&#39;单词 &quot;{word}&quot; 出现了 {count} 次&#39;)\n```\n\n这段代码会读取文章，然后统计每个单词的出现次数，并输出出现频率在前五的单词及其出现次数。你可以根据实际的文章内容修改 `article` 变量。希望这个答案对你有所帮助！\n\n当然，这是一个使用英文文章的示例。假设我们有以下的英文文章：\n\n```python\nfrom collections import Counter\nimport re\n\n# 假设这是你的文章\narticle = &quot;&quot;&quot;\nIn Python, you can use various libraries to scrape and save non-text data. Here are some basic steps and code examples:\nGetting the data address: Usually, non-text data (such as images or sound files) exist on the web page in the form of links. You can use the requests library to get the content of the web page, then use the BeautifulSoup library to parse the web page and extract the data link. Here is a simple code example:\n&quot;&quot;&quot;\n\n# 使用正则表达式将文章分割成单词\nwords = re.findall(r&#39;\\w+&#39;, article.lower())\n\n# 使用 Counter 统计每个单词的出现次数\nword_counts = Counter(words)\n\n# 找出出现频率在前五的单词\ntop_five = word_counts.most_common(5)\n\n# 输出结果\nfor word, count in top_five:\n    print(f&#39;Word &quot;{word}&quot; appears {count} times&#39;)\n```\n\n这段代码会读取文章，然后统计每个单词的出现次数，并输出出现频率在前五的单词及其出现次数。你可以根据实际的文章内容修改 `article` 变量。希望这个答案对你有所帮助！","like_count":0},{"had_liked":false,"id":383101,"user_name":"Geek_Mike","can_delete":false,"product_type":"c3","uid":3196376,"ip_address":"云南","ucode":"CFA942192C3B74","user_header":"https://static001.geekbang.org/account/avatar/00/30/c5/d8/c5509b9c.jpg","comment_is_top":false,"comment_ctime":1698411788,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100310001,"comment_content":"&#39;&#39;&#39;统计一篇文章中出现频率在前五的单词，并将单词和出现次数一起输出到终端&#39;&#39;&#39;\nimport collections\nimport docx\n\npath = &#39;&#47;Users&#47;mike&#47;Desktop&#47;zero-basics-python&#47;0&#47;demo.docx&#39;\ndoc = docx.Document(path)\n\nwords = []\nfor para in doc.paragraphs:\n    for word in para.runs:\n        words.extend(word.text.split( ))\n\ncounter = collections.Counter()\nfor word in words:\n    counter[word] += 1\n\nprint(counter.most_common(5))","like_count":0},{"had_liked":false,"id":383100,"user_name":"Geek_Mike","can_delete":false,"product_type":"c3","uid":3196376,"ip_address":"云南","ucode":"CFA942192C3B74","user_header":"https://static001.geekbang.org/account/avatar/00/30/c5/d8/c5509b9c.jpg","comment_is_top":false,"comment_ctime":1698411568,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100310001,"comment_content":"import collections\nimport docx\n\npath = &#39;.&#47;demo.docx&#39;\ndoc = docx.Document(path)\n\nwords = []\nfor para in doc.paragraphs:\n    for word in para.runs:\n        words.extend(word.text.split( ))\n\ncounter = collections.Counter()\nfor word in words:\n    counter[word] += 1\n\nprint(counter)","like_count":0}]}