{"id":111686,"title":"55 | 网络虚拟化：如何成立独立的合作部？","content":"<p>上一节，我们讲了存储虚拟化，这一节我们来讲网络虚拟化。</p><p>网络虚拟化有和存储虚拟化类似的地方，例如，它们都是基于virtio的，因而我们在看网络虚拟化的过程中，会看到和存储虚拟化很像的数据结构和原理。但是，网络虚拟化也有自己的特殊性。例如，存储虚拟化是将宿主机上的文件作为客户机上的硬盘，而网络虚拟化需要依赖于内核协议栈进行网络包的封装与解封装。那怎么实现客户机和宿主机之间的互通呢？我们就一起来看一看。</p><h2>解析初始化过程</h2><p>我们还是从Virtio Network Device这个设备的初始化讲起。</p><pre><code>static const TypeInfo device_type_info = {\n    .name = TYPE_DEVICE,\n    .parent = TYPE_OBJECT,\n    .instance_size = sizeof(DeviceState),\n    .instance_init = device_initfn,\n    .instance_post_init = device_post_init,\n    .instance_finalize = device_finalize,\n    .class_base_init = device_class_base_init,\n    .class_init = device_class_init,\n    .abstract = true,\n    .class_size = sizeof(DeviceClass),\n};\n\nstatic const TypeInfo virtio_device_info = {\n    .name = TYPE_VIRTIO_DEVICE,\n    .parent = TYPE_DEVICE,\n    .instance_size = sizeof(VirtIODevice),\n    .class_init = virtio_device_class_init,\n    .instance_finalize = virtio_device_instance_finalize,\n    .abstract = true,\n    .class_size = sizeof(VirtioDeviceClass),\n};\n\nstatic const TypeInfo virtio_net_info = {\n    .name = TYPE_VIRTIO_NET,\n    .parent = TYPE_VIRTIO_DEVICE,\n    .instance_size = sizeof(VirtIONet),\n    .instance_init = virtio_net_instance_init,\n    .class_init = virtio_net_class_init,\n};\n\nstatic void virtio_register_types(void)\n{\n    type_register_static(&amp;virtio_net_info);\n}\n\ntype_init(virtio_register_types)\n</code></pre><p>Virtio Network Device这种类的定义是有多层继承关系的，TYPE_VIRTIO_NET的父类是TYPE_VIRTIO_DEVICE，TYPE_VIRTIO_DEVICE的父类是TYPE_DEVICE，TYPE_DEVICE的父类是TYPE_OBJECT，继承关系到头了。</p><p>type_init用于注册这种类。这里面每一层都有class_init，用于从TypeImpl生成xxxClass，也有instance_init，会将xxxClass初始化为实例。</p><p>TYPE_VIRTIO_NET层的class_init函数virtio_net_class_init，定义了DeviceClass的realize函数为virtio_net_device_realize，这一点和存储块设备是一样的。</p><!-- [[[read_end]]] --><pre><code>static void virtio_net_device_realize(DeviceState *dev, Error **errp)\n{\n    VirtIODevice *vdev = VIRTIO_DEVICE(dev);\n    VirtIONet *n = VIRTIO_NET(dev);\n    NetClientState *nc;\n    int i;\n......\n    virtio_init(vdev, &quot;virtio-net&quot;, VIRTIO_ID_NET, n-&gt;config_size);\n\n    /*\n     * We set a lower limit on RX queue size to what it always was.\n     * Guests that want a smaller ring can always resize it without\n     * help from us (using virtio 1 and up).\n     */\n    if (n-&gt;net_conf.rx_queue_size &lt; VIRTIO_NET_RX_QUEUE_MIN_SIZE ||\n        n-&gt;net_conf.rx_queue_size &gt; VIRTQUEUE_MAX_SIZE ||\n        !is_power_of_2(n-&gt;net_conf.rx_queue_size)) {\n......\n        return;\n    }\n\n    if (n-&gt;net_conf.tx_queue_size &lt; VIRTIO_NET_TX_QUEUE_MIN_SIZE ||\n        n-&gt;net_conf.tx_queue_size &gt; VIRTQUEUE_MAX_SIZE ||\n        !is_power_of_2(n-&gt;net_conf.tx_queue_size)) {\n......\n        return;\n    }\n\n    n-&gt;max_queues = MAX(n-&gt;nic_conf.peers.queues, 1);\n    if (n-&gt;max_queues * 2 + 1 &gt; VIRTIO_QUEUE_MAX) {\n......\n        return;\n    }\n    n-&gt;vqs = g_malloc0(sizeof(VirtIONetQueue) * n-&gt;max_queues);\n    n-&gt;curr_queues = 1;\n......\n    n-&gt;net_conf.tx_queue_size = MIN(virtio_net_max_tx_queue_size(n),\n                                    n-&gt;net_conf.tx_queue_size);\n\n    for (i = 0; i &lt; n-&gt;max_queues; i++) {\n        virtio_net_add_queue(n, i);\n    }\n\n    n-&gt;ctrl_vq = virtio_add_queue(vdev, 64, virtio_net_handle_ctrl);\n    qemu_macaddr_default_if_unset(&amp;n-&gt;nic_conf.macaddr);\n    memcpy(&amp;n-&gt;mac[0], &amp;n-&gt;nic_conf.macaddr, sizeof(n-&gt;mac));\n    n-&gt;status = VIRTIO_NET_S_LINK_UP;\n\n    if (n-&gt;netclient_type) {\n        n-&gt;nic = qemu_new_nic(&amp;net_virtio_info, &amp;n-&gt;nic_conf,\n                              n-&gt;netclient_type, n-&gt;netclient_name, n);\n    } else {\n        n-&gt;nic = qemu_new_nic(&amp;net_virtio_info, &amp;n-&gt;nic_conf,\n                              object_get_typename(OBJECT(dev)), dev-&gt;id, n);\n    }\n......\n}\n</code></pre><p>这里面创建了一个VirtIODevice，这一点和存储虚拟化也是一样的。virtio_init用来初始化这个设备。VirtIODevice结构里面有一个VirtQueue数组，这就是virtio前端和后端互相传数据的队列，最多有VIRTIO_QUEUE_MAX个。</p><p>刚才我们说的都是一样的地方，其实也有不一样的地方，我们下面来看。</p><p>你会发现，这里面有这样的语句n-&gt;max_queues * 2 + 1 &gt; VIRTIO_QUEUE_MAX。为什么要乘以2呢？这是因为，对于网络设备来讲，应该分发送队列和接收队列两个方向，所以乘以2。</p><p>接下来，我们调用virtio_net_add_queue来初始化队列，可以看出来，这里面就有发送tx_vq和接收rx_vq两个队列。</p><pre><code>typedef struct VirtIONetQueue {\n    VirtQueue *rx_vq;\n    VirtQueue *tx_vq;\n    QEMUTimer *tx_timer;\n    QEMUBH *tx_bh;\n    uint32_t tx_waiting;\n    struct {\n        VirtQueueElement *elem;\n    } async_tx;\n    struct VirtIONet *n;\n} VirtIONetQueue;\n\nstatic void virtio_net_add_queue(VirtIONet *n, int index)\n{\n    VirtIODevice *vdev = VIRTIO_DEVICE(n);\n\n    n-&gt;vqs[index].rx_vq = virtio_add_queue(vdev, n-&gt;net_conf.rx_queue_size, virtio_net_handle_rx);\n\n......\n\n    n-&gt;vqs[index].tx_vq = virtio_add_queue(vdev, n-&gt;net_conf.tx_queue_size, virtio_net_handle_tx_bh);\n    n-&gt;vqs[index].tx_bh = qemu_bh_new(virtio_net_tx_bh, &amp;n-&gt;vqs[index]);\n    n-&gt;vqs[index].n = n;\n}\n</code></pre><p>每个VirtQueue中，都有一个vring用来维护这个队列里面的数据；另外还有函数virtio_net_handle_rx用于处理网络包的接收；函数virtio_net_handle_tx_bh用于网络包的发送，这个函数我们后面会用到。</p><pre><code>NICState *qemu_new_nic(NetClientInfo *info,\n                       NICConf *conf,\n                       const char *model,\n                       const char *name,\n                       void *opaque)\n{\n    NetClientState **peers = conf-&gt;peers.ncs;\n    NICState *nic;\n    int i, queues = MAX(1, conf-&gt;peers.queues);\n......\n    nic = g_malloc0(info-&gt;size + sizeof(NetClientState) * queues);\n    nic-&gt;ncs = (void *)nic + info-&gt;size;\n    nic-&gt;conf = conf;\n    nic-&gt;opaque = opaque;\n\n    for (i = 0; i &lt; queues; i++) {\n        qemu_net_client_setup(&amp;nic-&gt;ncs[i], info, peers[i], model, name, NULL);\n        nic-&gt;ncs[i].queue_index = i;\n    }\n\n    return nic;\n}\n\nstatic void qemu_net_client_setup(NetClientState *nc,\n                                  NetClientInfo *info,\n                                  NetClientState *peer,\n                                  const char *model,\n                                  const char *name,\n                                  NetClientDestructor *destructor)\n{\n    nc-&gt;info = info;\n    nc-&gt;model = g_strdup(model);\n    if (name) {\n        nc-&gt;name = g_strdup(name);\n    } else {\n        nc-&gt;name = assign_name(nc, model);\n    }\n\n    QTAILQ_INSERT_TAIL(&amp;net_clients, nc, next);\n\n    nc-&gt;incoming_queue = qemu_new_net_queue(qemu_deliver_packet_iov, nc);\n    nc-&gt;destructor = destructor;\n    QTAILQ_INIT(&amp;nc-&gt;filters);\n}\n</code></pre><p>接下来，qemu_new_nic会创建一个虚拟机里面的网卡。</p><h2>qemu的启动过程中的网络虚拟化</h2><p>初始化过程解析完毕以后，我们接下来从qemu的启动过程看起。</p><p>对于网卡的虚拟化，qemu的启动参数里面有关的是下面两行：</p><pre><code>-netdev tap,fd=32,id=hostnet0,vhost=on,vhostfd=37\n-device virtio-net-pci,netdev=hostnet0,id=net0,mac=fa:16:3e:d1:2d:99,bus=pci.0,addr=0x3\n</code></pre><p>qemu的main函数会调用net_init_clients进行网络设备的初始化，可以解析net参数，也可以在net_init_clients中解析netdev参数。</p><pre><code>int net_init_clients(Error **errp)\n{\n    QTAILQ_INIT(&amp;net_clients);\n    if (qemu_opts_foreach(qemu_find_opts(&quot;netdev&quot;),\n                          net_init_netdev, NULL, errp)) {\n        return -1;\n    }\n    if (qemu_opts_foreach(qemu_find_opts(&quot;nic&quot;), net_param_nic, NULL, errp)) {\n        return -1;\n   }\n    if (qemu_opts_foreach(qemu_find_opts(&quot;net&quot;), net_init_client, NULL, errp)) {\n        return -1;\n    }\n    return 0;\n}  \n</code></pre><p>net_init_clients会解析参数。上面的参数netdev会调用net_init_netdev-&gt;net_client_init-&gt;net_client_init1。</p><p>net_client_init1会根据不同的driver类型，调用不同的初始化函数。</p><pre><code>static int (* const net_client_init_fun[NET_CLIENT_DRIVER__MAX])(\n    const Netdev *netdev,\n    const char *name,\n    NetClientState *peer, Error **errp) = {\n        [NET_CLIENT_DRIVER_NIC]       = net_init_nic,\n        [NET_CLIENT_DRIVER_TAP]       = net_init_tap,\n        [NET_CLIENT_DRIVER_SOCKET]    = net_init_socket,\n        [NET_CLIENT_DRIVER_HUBPORT]   = net_init_hubport,\n......\n};\n</code></pre><p>由于我们配置的driver的类型是tap，因而这里会调用net_init_tap-&gt;net_tap_init-&gt;tap_open。</p><pre><code>#define PATH_NET_TUN &quot;/dev/net/tun&quot;\n\nint tap_open(char *ifname, int ifname_size, int *vnet_hdr,\n             int vnet_hdr_required, int mq_required, Error **errp)\n{\n    struct ifreq ifr;\n    int fd, ret;\n    int len = sizeof(struct virtio_net_hdr);\n    unsigned int features;\n\n    TFR(fd = open(PATH_NET_TUN, O_RDWR));\n    memset(&amp;ifr, 0, sizeof(ifr));\n    ifr.ifr_flags = IFF_TAP | IFF_NO_PI;\n\n    if (ioctl(fd, TUNGETFEATURES, &amp;features) == -1) {\n        features = 0;\n    }\n\n    if (features &amp; IFF_ONE_QUEUE) {\n        ifr.ifr_flags |= IFF_ONE_QUEUE;\n    }\n\n    if (*vnet_hdr) {\n        if (features &amp; IFF_VNET_HDR) {\n            *vnet_hdr = 1;\n            ifr.ifr_flags |= IFF_VNET_HDR;\n        } else {\n            *vnet_hdr = 0;\n        }\n        ioctl(fd, TUNSETVNETHDRSZ, &amp;len);\n    }\n......\n    ret = ioctl(fd, TUNSETIFF, (void *) &amp;ifr);\n......\n    fcntl(fd, F_SETFL, O_NONBLOCK);\n    return fd;\n}\n</code></pre><p>在tap_open中，我们打开一个文件\"/dev/net/tun\"，然后通过ioctl操作这个文件。这是Linux内核的一项机制，和KVM机制很像。其实这就是一种通过打开这个字符设备文件，然后通过ioctl操作这个文件和内核打交道，来使用内核的能力。</p><p><img src=\"https://static001.geekbang.org/resource/image/24/d3/243e93913b18c3ab00be5676bef334d3.png?wh=1546*1303\" alt=\"\"></p><p>为什么需要使用内核的机制呢？因为网络包需要从虚拟机里面发送到虚拟机外面，发送到宿主机上的时候，必须是一个正常的网络包才能被转发。要形成一个网络包，我们那就需要经过复杂的协议栈，协议栈的复杂咱们在<a href=\"https://time.geekbang.org/column/article/106490\">发送网络包</a>那一节讲过了。</p><p>客户机会将网络包发送给qemu。qemu自己没有网络协议栈，现去实现一个也不可能，太复杂了。于是，它就要借助内核的力量。</p><p>qemu会将客户机发送给它的网络包，然后转换成为文件流，写入\"/dev/net/tun\"字符设备。就像写一个文件一样。内核中TUN/TAP字符设备驱动会收到这个写入的文件流，然后交给TUN/TAP的虚拟网卡驱动。这个驱动会将文件流再次转成网络包，交给TCP/IP栈，最终从虚拟TAP网卡tap0发出来，成为标准的网络包。后面我们会看到这个过程。</p><p>现在我们到内核里面，看一看打开\"/dev/net/tun\"字符设备后，内核会发生什么事情。内核的实现在drivers/net/tun.c文件中。这是一个字符设备驱动程序，应该符合字符设备的格式。</p><pre><code>module_init(tun_init);\nmodule_exit(tun_cleanup);\nMODULE_DESCRIPTION(DRV_DESCRIPTION);\nMODULE_AUTHOR(DRV_COPYRIGHT);\nMODULE_LICENSE(&quot;GPL&quot;);\nMODULE_ALIAS_MISCDEV(TUN_MINOR);\nMODULE_ALIAS(&quot;devname:net/tun&quot;);\n\nstatic int __init tun_init(void)\n{\n......\n\tret = rtnl_link_register(&amp;tun_link_ops);\n......\n\tret = misc_register(&amp;tun_miscdev);\n......\n\tret = register_netdevice_notifier(&amp;tun_notifier_block);\n......\n}\n</code></pre><p>这里面注册了一个tun_miscdev字符设备，从它的定义可以看出，这就是\"/dev/net/tun\"字符设备。</p><pre><code>static struct miscdevice tun_miscdev = {\n\t.minor = TUN_MINOR,\n\t.name = &quot;tun&quot;,\n\t.nodename = &quot;net/tun&quot;,\n\t.fops = &amp;tun_fops,\n};\n\nstatic const struct file_operations tun_fops = {\n\t.owner\t= THIS_MODULE,\n\t.llseek = no_llseek,\n\t.read_iter  = tun_chr_read_iter,\n\t.write_iter = tun_chr_write_iter,\n\t.poll\t= tun_chr_poll,\n\t.unlocked_ioctl\t= tun_chr_ioctl,\n\t.open\t= tun_chr_open,\n\t.release = tun_chr_close,\n\t.fasync = tun_chr_fasync,\n};\n</code></pre><p>qemu的tap_open函数会打开这个字符设备PATH_NET_TUN。打开字符设备的过程我们不再重复。我就说一下，到了驱动这一层，调用的是tun_chr_open。</p><pre><code>static int tun_chr_open(struct inode *inode, struct file * file)\n{\n\tstruct tun_file *tfile;\n\ttfile = (struct tun_file *)sk_alloc(net, AF_UNSPEC, GFP_KERNEL,\n\t\t\t\t\t    &amp;tun_proto, 0);\n\tRCU_INIT_POINTER(tfile-&gt;tun, NULL);\n\ttfile-&gt;flags = 0;\n\ttfile-&gt;ifindex = 0;\n\n\tinit_waitqueue_head(&amp;tfile-&gt;wq.wait);\n\tRCU_INIT_POINTER(tfile-&gt;socket.wq, &amp;tfile-&gt;wq);\n\n\ttfile-&gt;socket.file = file;\n\ttfile-&gt;socket.ops = &amp;tun_socket_ops;\n\n\tsock_init_data(&amp;tfile-&gt;socket, &amp;tfile-&gt;sk);\n\n\ttfile-&gt;sk.sk_write_space = tun_sock_write_space;\n\ttfile-&gt;sk.sk_sndbuf = INT_MAX;\n\n\tfile-&gt;private_data = tfile;\n\tINIT_LIST_HEAD(&amp;tfile-&gt;next);\n\n\tsock_set_flag(&amp;tfile-&gt;sk, SOCK_ZEROCOPY);\n\n\treturn 0;\n}\n</code></pre><p>在tun_chr_open的参数里面，有一个struct file，这是代表什么文件呢？它代表的就是打开的字符设备文件\"/dev/net/tun\"，因而往这个字符设备文件中写数据，就会通过这个struct file写入。这个struct file里面的file_operations，按照字符设备打开的规则，指向的就是tun_fops。</p><p>另外，我们还需要在tun_chr_open创建了一个结构struct tun_file，并且将struct file的private_data指向它。</p><pre><code>/* A tun_file connects an open character device to a tuntap netdevice. It\n * also contains all socket related structures \n * to serve as one transmit queue for tuntap device. \n */\nstruct tun_file {\n\tstruct sock sk;\n\tstruct socket socket;\n\tstruct socket_wq wq;\n\tstruct tun_struct __rcu *tun;\n\tstruct fasync_struct *fasync;\n\t/* only used for fasnyc */\n\tunsigned int flags;\n\tunion {\n\t\tu16 queue_index;\n\t\tunsigned int ifindex;\n\t};\n\tstruct list_head next;\n\tstruct tun_struct *detached;\n\tstruct skb_array tx_array;\n};\n\nstruct tun_struct {\n\tstruct tun_file __rcu\t*tfiles[MAX_TAP_QUEUES];\n\tunsigned int            numqueues;\n\tunsigned int \t\tflags;\n\tkuid_t\t\t\towner;\n\tkgid_t\t\t\tgroup;\n\n\tstruct net_device\t*dev;\n\tnetdev_features_t\tset_features;\n\tint\t\t\talign;\n\tint\t\t\tvnet_hdr_sz;\n\tint\t\t\tsndbuf;\n\tstruct tap_filter\ttxflt;\n\tstruct sock_fprog\tfprog;\n\t/* protected by rtnl lock */\n\tbool\t\t\tfilter_attached;\n\tspinlock_t lock;\n\tstruct hlist_head flows[TUN_NUM_FLOW_ENTRIES];\n\tstruct timer_list flow_gc_timer;\n\tunsigned long ageing_time;\n\tunsigned int numdisabled;\n\tstruct list_head disabled;\n\tvoid *security;\n\tu32 flow_count;\n\tu32 rx_batched;\n\tstruct tun_pcpu_stats __percpu *pcpu_stats;\n};\n\nstatic const struct proto_ops tun_socket_ops = {\n\t.peek_len = tun_peek_len,\n\t.sendmsg = tun_sendmsg,\n\t.recvmsg = tun_recvmsg,\n};\n</code></pre><p>在struct tun_file中，有一个成员struct tun_struct，它里面有一个struct net_device，这个用来表示宿主机上的tuntap网络设备。在struct tun_file中，还有struct socket和struct sock，因为要用到内核的网络协议栈，所以就需要这两个结构，这在<a href=\"https://time.geekbang.org/column/article/105338\">网络协议</a>那一节已经分析过了。</p><p>所以，按照struct tun_file的注释说的，这是一个很重要的数据结构。\"/dev/net/tun\"对应的struct file的private_data指向它，因而可以接收qemu发过来的数据。除此之外，它还可以通过struct sock来操作内核协议栈，然后将网络包从宿主机上的tuntap网络设备发出去，宿主机上的tuntap网络设备对应的struct net_device也归它管。</p><p>在qemu的tap_open函数中，打开这个字符设备文件之后，接下来要做的事情是，通过ioctl来设置宿主机的网卡TUNSETIFF。</p><p>接下来，ioctl到了内核里面，会调用tun_chr_ioctl。</p><pre><code>static long __tun_chr_ioctl(struct file *file, unsigned int cmd,\n\t\t\t    unsigned long arg, int ifreq_len)\n{\n\tstruct tun_file *tfile = file-&gt;private_data;\n\tstruct tun_struct *tun;\n\tvoid __user* argp = (void __user*)arg;\n\tstruct ifreq ifr;\n\tkuid_t owner;\n\tkgid_t group;\n\tint sndbuf;\n\tint vnet_hdr_sz;\n\tunsigned int ifindex;\n\tint le;\n\tint ret;\n\n\tif (cmd == TUNSETIFF || cmd == TUNSETQUEUE || _IOC_TYPE(cmd) == SOCK_IOC_TYPE) {\n\t\tif (copy_from_user(&amp;ifr, argp, ifreq_len))\n\t\t\treturn -EFAULT;\n\t} \n......\n\ttun = __tun_get(tfile);\n\tif (cmd == TUNSETIFF) {\n\t\tifr.ifr_name[IFNAMSIZ-1] = '\\0';\n\t\tret = tun_set_iff(sock_net(&amp;tfile-&gt;sk), file, &amp;ifr);\n......\n\t\tif (copy_to_user(argp, &amp;ifr, ifreq_len))\n\t\t\tret = -EFAULT;\n\t}\n......\n}\n</code></pre><p>在__tun_chr_ioctl中，我们首先通过copy_from_user把配置从用户态拷贝到内核态，调用tun_set_iff设置tuntap网络设备，然后调用copy_to_user将配置结果返回。</p><pre><code>static int tun_set_iff(struct net *net, struct file *file, struct ifreq *ifr)\n{\n\tstruct tun_struct *tun;\n\tstruct tun_file *tfile = file-&gt;private_data;\n\tstruct net_device *dev;\n......\n\tchar *name;\n\tunsigned long flags = 0;\n\tint queues = ifr-&gt;ifr_flags &amp; IFF_MULTI_QUEUE ?\n\t\t\t     MAX_TAP_QUEUES : 1;\n\n\tif (ifr-&gt;ifr_flags &amp; IFF_TUN) {\n\t\t/* TUN device */\n\t\tflags |= IFF_TUN;\n\t\tname = &quot;tun%d&quot;;\n\t} else if (ifr-&gt;ifr_flags &amp; IFF_TAP) {\n\t\t/* TAP device */\n\t\tflags |= IFF_TAP;\n\t\tname = &quot;tap%d&quot;;\n\t} else\n\t\treturn -EINVAL;\n\n\tif (*ifr-&gt;ifr_name)\n\t\tname = ifr-&gt;ifr_name;\n\n\tdev = alloc_netdev_mqs(sizeof(struct tun_struct), name,\n\t\t\t\t       NET_NAME_UNKNOWN, tun_setup, queues,\n\t\t\t\t       queues);\n\n\terr = dev_get_valid_name(net, dev, name);\n\tdev_net_set(dev, net);\n\tdev-&gt;rtnl_link_ops = &amp;tun_link_ops;\n\tdev-&gt;ifindex = tfile-&gt;ifindex;\n\tdev-&gt;sysfs_groups[0] = &amp;tun_attr_group;\n\n\ttun = netdev_priv(dev);\n\ttun-&gt;dev = dev;\n\ttun-&gt;flags = flags;\n\ttun-&gt;txflt.count = 0;\n\ttun-&gt;vnet_hdr_sz = sizeof(struct virtio_net_hdr);\n\n\ttun-&gt;align = NET_SKB_PAD;\n\ttun-&gt;filter_attached = false;\n\ttun-&gt;sndbuf = tfile-&gt;socket.sk-&gt;sk_sndbuf;\n\ttun-&gt;rx_batched = 0;\n\n\ttun_net_init(dev);\n\ttun_flow_init(tun);\n\n\terr = tun_attach(tun, file, false);\n\terr = register_netdevice(tun-&gt;dev);\n\n\tnetif_carrier_on(tun-&gt;dev);\n\n\tif (netif_running(tun-&gt;dev))\n\t\tnetif_tx_wake_all_queues(tun-&gt;dev);\n\n\tstrcpy(ifr-&gt;ifr_name, tun-&gt;dev-&gt;name);\n\treturn 0;\n}\n</code></pre><p>tun_set_iff创建了struct tun_struct和struct net_device，并且将这个tuntap网络设备通过register_netdevice注册到内核中。这样，我们就能在宿主机上通过ip addr看到这个网卡了。</p><p><img src=\"https://static001.geekbang.org/resource/image/98/fd/9826223c7375bec19bd13588f3875ffd.png?wh=3463*1903\" alt=\"\"></p><p>至此宿主机上的内核的数据结构也完成了。</p><h2>关联前端设备驱动和后端设备驱动</h2><p>下面，我们来解析在客户机中发送一个网络包的时候，会发生哪些事情。</p><p>虚拟机里面的进程发送一个网络包，通过文件系统和Socket调用网络协议栈，到达网络设备层。只不过这个不是普通的网络设备，而是virtio_net的驱动。</p><p>virtio_net的驱动程序代码在Linux操作系统的源代码里面，文件名为drivers/net/virtio_net.c。</p><pre><code>static __init int virtio_net_driver_init(void)\n{\n    ret = register_virtio_driver(&amp;virtio_net_driver);\n......\n}\nmodule_init(virtio_net_driver_init);\nmodule_exit(virtio_net_driver_exit);\n\nMODULE_DEVICE_TABLE(virtio, id_table);\nMODULE_DESCRIPTION(&quot;Virtio network driver&quot;);\nMODULE_LICENSE(&quot;GPL&quot;);\n\nstatic struct virtio_driver virtio_net_driver = {\n\t.driver.name =\tKBUILD_MODNAME,\n\t.driver.owner =\tTHIS_MODULE,\n\t.id_table =\tid_table,\n\t.validate =\tvirtnet_validate,\n\t.probe =\tvirtnet_probe,\n\t.remove =\tvirtnet_remove,\n\t.config_changed = virtnet_config_changed,\n......\n};\n</code></pre><p>在virtio_net的驱动程序的初始化代码中，我们需要注册一个驱动函数virtio_net_driver。</p><p>当一个设备驱动作为一个内核模块被初始化的时候，probe函数会被调用，因而我们来看一下virtnet_probe。</p><pre><code>static int virtnet_probe(struct virtio_device *vdev)\n{\n\tint i, err;\n\tstruct net_device *dev;\n\tstruct virtnet_info *vi;\n\tu16 max_queue_pairs;\n\tint mtu;\n\n\t/* Allocate ourselves a network device with room for our info */\n\tdev = alloc_etherdev_mq(sizeof(struct virtnet_info), max_queue_pairs);\n\n\t/* Set up network device as normal. */\n\tdev-&gt;priv_flags |= IFF_UNICAST_FLT | IFF_LIVE_ADDR_CHANGE;\n\tdev-&gt;netdev_ops = &amp;virtnet_netdev;\n\tdev-&gt;features = NETIF_F_HIGHDMA;\n\n\tdev-&gt;ethtool_ops = &amp;virtnet_ethtool_ops;\n\tSET_NETDEV_DEV(dev, &amp;vdev-&gt;dev);\n......\n\t/* MTU range: 68 - 65535 */\n\tdev-&gt;min_mtu = MIN_MTU;\n\tdev-&gt;max_mtu = MAX_MTU;\n\n\t/* Set up our device-specific information */\n\tvi = netdev_priv(dev);\n\tvi-&gt;dev = dev;\n\tvi-&gt;vdev = vdev;\n\tvdev-&gt;priv = vi;\n\tvi-&gt;stats = alloc_percpu(struct virtnet_stats);\n\tINIT_WORK(&amp;vi-&gt;config_work, virtnet_config_changed_work);\n......\n\tvi-&gt;max_queue_pairs = max_queue_pairs;\n\n\t/* Allocate/initialize the rx/tx queues, and invoke find_vqs */\n\terr = init_vqs(vi);\n\tnetif_set_real_num_tx_queues(dev, vi-&gt;curr_queue_pairs);\n\tnetif_set_real_num_rx_queues(dev, vi-&gt;curr_queue_pairs);\n\n\tvirtnet_init_settings(dev);\n\n\terr = register_netdev(dev);\n\tvirtio_device_ready(vdev);\n\tvirtnet_set_queues(vi, vi-&gt;curr_queue_pairs);\n......\n}\n</code></pre><p>在virtnet_probe中，会创建struct net_device，并且通过register_netdev注册这个网络设备，这样在客户机里面，就能看到这个网卡了。</p><p>在virtnet_probe中，还有一件重要的事情就是，init_vqs会初始化发送和接收的virtqueue。</p><pre><code>static int init_vqs(struct virtnet_info *vi)\n{\n\tint ret;\n\n\t/* Allocate send &amp; receive queues */\n\tret = virtnet_alloc_queues(vi);\n\tret = virtnet_find_vqs(vi);\n......\n\tget_online_cpus();\n\tvirtnet_set_affinity(vi);\n\tput_online_cpus();\n\n\treturn 0;\n}\n\nstatic int virtnet_alloc_queues(struct virtnet_info *vi)\n{\n\tint i;\n\n\tvi-&gt;sq = kzalloc(sizeof(*vi-&gt;sq) * vi-&gt;max_queue_pairs, GFP_KERNEL);\n\tvi-&gt;rq = kzalloc(sizeof(*vi-&gt;rq) * vi-&gt;max_queue_pairs, GFP_KERNEL);\n\n\tINIT_DELAYED_WORK(&amp;vi-&gt;refill, refill_work);\n\tfor (i = 0; i &lt; vi-&gt;max_queue_pairs; i++) {\n\t\tvi-&gt;rq[i].pages = NULL;\n\t\tnetif_napi_add(vi-&gt;dev, &amp;vi-&gt;rq[i].napi, virtnet_poll,\n\t\t\t       napi_weight);\n\t\tnetif_tx_napi_add(vi-&gt;dev, &amp;vi-&gt;sq[i].napi, virtnet_poll_tx,\n\t\t\t\t  napi_tx ? napi_weight : 0);\n\n\t\tsg_init_table(vi-&gt;rq[i].sg, ARRAY_SIZE(vi-&gt;rq[i].sg));\n\t\tewma_pkt_len_init(&amp;vi-&gt;rq[i].mrg_avg_pkt_len);\n\t\tsg_init_table(vi-&gt;sq[i].sg, ARRAY_SIZE(vi-&gt;sq[i].sg));\n\t}\n\n\treturn 0;\n}\n</code></pre><p>按照上一节的virtio原理，virtqueue是一个介于客户机前端和qemu后端的一个结构，用于在这两端之间传递数据，对于网络设备来讲有发送和接收两个方向的队列。这里建立的struct virtqueue是客户机前端对于队列的管理的数据结构。</p><p>队列的实体需要通过函数virtnet_find_vqs查找或者生成，这里还会指定接收队列的callback函数为skb_recv_done，发送队列的callback函数为skb_xmit_done。那当buffer使用发生变化的时候，我们可以调用这个callback函数进行通知。</p><pre><code>static int virtnet_find_vqs(struct virtnet_info *vi)\n{\n\tvq_callback_t **callbacks;\n\tstruct virtqueue **vqs;\n\tint ret = -ENOMEM;\n\tint i, total_vqs;\n\tconst char **names;\n\n\t/* Allocate space for find_vqs parameters */\n\tvqs = kzalloc(total_vqs * sizeof(*vqs), GFP_KERNEL);\n\tcallbacks = kmalloc(total_vqs * sizeof(*callbacks), GFP_KERNEL);\n\tnames = kmalloc(total_vqs * sizeof(*names), GFP_KERNEL);\n\n\t/* Allocate/initialize parameters for send/receive virtqueues */\n\tfor (i = 0; i &lt; vi-&gt;max_queue_pairs; i++) {\n\t\tcallbacks[rxq2vq(i)] = skb_recv_done;\n\t\tcallbacks[txq2vq(i)] = skb_xmit_done;\n\t\tnames[rxq2vq(i)] = vi-&gt;rq[i].name;\n\t\tnames[txq2vq(i)] = vi-&gt;sq[i].name;\n\t}\n\n\tret = vi-&gt;vdev-&gt;config-&gt;find_vqs(vi-&gt;vdev, total_vqs, vqs, callbacks, names, ctx, NULL);\n......\n\tfor (i = 0; i &lt; vi-&gt;max_queue_pairs; i++) {\n\t\tvi-&gt;rq[i].vq = vqs[rxq2vq(i)];\n\t\tvi-&gt;rq[i].min_buf_len = mergeable_min_buf_len(vi, vi-&gt;rq[i].vq);\n\t\tvi-&gt;sq[i].vq = vqs[txq2vq(i)];\n\t}\n......\n}\n</code></pre><p>这里的find_vqs是在struct virtnet_info里的struct virtio_device里的struct virtio_config_ops *config里面定义的。</p><p>根据virtio_config_ops的定义，find_vqs会调用vp_modern_find_vqs，到这一步和块设备是一样的了。</p><p>在vp_modern_find_vqs中，vp_find_vqs会调用vp_find_vqs_intx。在vp_find_vqs_intx中，通过request_irq注册一个中断处理函数vp_interrupt。当设备向队列中写入信息时，会产生一个中断，也就是vq中断。中断处理函数需要调用相应的队列的回调函数，然后根据队列的数目，依次调用vp_setup_vq完成virtqueue、vring的分配和初始化。</p><p>同样，这些数据结构会和virtio后端的VirtIODevice、VirtQueue、vring对应起来，都应该指向刚才创建的那一段内存。</p><p>客户机同样会通过调用专门给外部设备发送指令的函数iowrite告诉外部的pci设备，这些共享内存的地址。</p><p>至此前端设备驱动和后端设备驱动之间的两个收发队列就关联好了，这两个队列的格式和块设备是一样的。</p><h2>发送网络包过程</h2><p>接下来，我们来看当真的发送一个网络包的时候，会发生什么。</p><p>当网络包经过客户机的协议栈到达virtio_net驱动的时候，按照net_device_ops的定义，start_xmit会被调用。</p><pre><code>static const struct net_device_ops virtnet_netdev = {\n\t.ndo_open            = virtnet_open,\n\t.ndo_stop   \t     = virtnet_close,\n\t.ndo_start_xmit      = start_xmit,\n\t.ndo_validate_addr   = eth_validate_addr,\n\t.ndo_set_mac_address = virtnet_set_mac_address,\n\t.ndo_set_rx_mode     = virtnet_set_rx_mode,\n\t.ndo_get_stats64     = virtnet_stats,\n\t.ndo_vlan_rx_add_vid = virtnet_vlan_rx_add_vid,\n\t.ndo_vlan_rx_kill_vid = virtnet_vlan_rx_kill_vid,\n\t.ndo_xdp\t\t= virtnet_xdp,\n\t.ndo_features_check\t= passthru_features_check,\n};\n</code></pre><p>接下来的调用链为：start_xmit-&gt;xmit_skb-&gt; virtqueue_add_outbuf-&gt;virtqueue_add，将网络包放入队列中，并调用virtqueue_notify通知接收方。</p><pre><code>static netdev_tx_t start_xmit(struct sk_buff *skb, struct net_device *dev)\n{\n\tstruct virtnet_info *vi = netdev_priv(dev);\n\tint qnum = skb_get_queue_mapping(skb);\n\tstruct send_queue *sq = &amp;vi-&gt;sq[qnum];\n\tint err;\n\tstruct netdev_queue *txq = netdev_get_tx_queue(dev, qnum);\n\tbool kick = !skb-&gt;xmit_more;\n\tbool use_napi = sq-&gt;napi.weight;\n......\n\t/* Try to transmit */\n\terr = xmit_skb(sq, skb);\n......\n\tif (kick || netif_xmit_stopped(txq))\n\t\tvirtqueue_kick(sq-&gt;vq);\n\treturn NETDEV_TX_OK;\n}\n\nbool virtqueue_kick(struct virtqueue *vq)\n{\n\tif (virtqueue_kick_prepare(vq))\n\t\treturn virtqueue_notify(vq);\n\treturn true;\n}\n</code></pre><p>写入一个I/O会使得qemu触发VM exit，这个逻辑我们在解析CPU的时候看到过。</p><p>接下来，我们那会调用VirtQueue的handle_output函数。前面我们已经设置过这个函数了，其实就是virtio_net_handle_tx_bh。</p><pre><code>static void virtio_net_handle_tx_bh(VirtIODevice *vdev, VirtQueue *vq)\n{\n    VirtIONet *n = VIRTIO_NET(vdev);\n    VirtIONetQueue *q = &amp;n-&gt;vqs[vq2q(virtio_get_queue_index(vq))];\n\n    q-&gt;tx_waiting = 1;\n\n    virtio_queue_set_notification(vq, 0);\n    qemu_bh_schedule(q-&gt;tx_bh);\n}\n</code></pre><p>virtio_net_handle_tx_bh调用了qemu_bh_schedule，而在virtio_net_add_queue中调用qemu_bh_new，并把函数设置为virtio_net_tx_bh。</p><p>virtio_net_tx_bh函数调用发送函数virtio_net_flush_tx。</p><pre><code>static int32_t virtio_net_flush_tx(VirtIONetQueue *q)\n{\n    VirtIONet *n = q-&gt;n;\n    VirtIODevice *vdev = VIRTIO_DEVICE(n);\n    VirtQueueElement *elem;\n    int32_t num_packets = 0;\n    int queue_index = vq2q(virtio_get_queue_index(q-&gt;tx_vq));\n\n    for (;;) {\n        ssize_t ret;\n        unsigned int out_num;\n        struct iovec sg[VIRTQUEUE_MAX_SIZE], sg2[VIRTQUEUE_MAX_SIZE + 1], *out_sg;\n        struct virtio_net_hdr_mrg_rxbuf mhdr;\n\n        elem = virtqueue_pop(q-&gt;tx_vq, sizeof(VirtQueueElement));\n        out_num = elem-&gt;out_num;\n        out_sg = elem-&gt;out_sg;\n......\n        ret = qemu_sendv_packet_async(qemu_get_subqueue(n-&gt;nic, queue_index),out_sg, out_num, virtio_net_tx_complete);\n    }\n......\n    return num_packets;\n}\n</code></pre><p>virtio_net_flush_tx会调用virtqueue_pop。这里面，我们能看到对于vring的操作，也即从这里面将客户机里面写入的数据读取出来。</p><p>然后，我们调用qemu_sendv_packet_async发送网络包。接下来的调用链为：qemu_sendv_packet_async-&gt;qemu_net_queue_send_iov-&gt;qemu_net_queue_flush-&gt;qemu_net_queue_deliver。</p><p>在qemu_net_queue_deliver中，我们会调用NetQueue的deliver函数。前面qemu_new_net_queue会把deliver函数设置为qemu_deliver_packet_iov。它会调用nc-&gt;info-&gt;receive_iov。</p><pre><code>static NetClientInfo net_tap_info = {\n    .type = NET_CLIENT_DRIVER_TAP,\n    .size = sizeof(TAPState),\n    .receive = tap_receive,\n    .receive_raw = tap_receive_raw,\n    .receive_iov = tap_receive_iov,\n    .poll = tap_poll,\n    .cleanup = tap_cleanup,\n    .has_ufo = tap_has_ufo,\n    .has_vnet_hdr = tap_has_vnet_hdr,\n    .has_vnet_hdr_len = tap_has_vnet_hdr_len,\n    .using_vnet_hdr = tap_using_vnet_hdr,\n    .set_offload = tap_set_offload,\n    .set_vnet_hdr_len = tap_set_vnet_hdr_len,\n    .set_vnet_le = tap_set_vnet_le,\n    .set_vnet_be = tap_set_vnet_be,\n};\n</code></pre><p>根据net_tap_info的定义调用的是tap_receive_iov。他会调用tap_write_packet-&gt;writev写入这个字符设备。</p><p>在内核的字符设备驱动中，tun_chr_write_iter会被调用。</p><pre><code>static ssize_t tun_chr_write_iter(struct kiocb *iocb, struct iov_iter *from)\n{\n\tstruct file *file = iocb-&gt;ki_filp;\n\tstruct tun_struct *tun = tun_get(file);\n\tstruct tun_file *tfile = file-&gt;private_data;\n\tssize_t result;\n\n\tresult = tun_get_user(tun, tfile, NULL, from,\n\t\t\t      file-&gt;f_flags &amp; O_NONBLOCK, false);\n\n\ttun_put(tun);\n\treturn result;\n}\n</code></pre><p>当我们使用writev()系统调用向tun/tap设备的字符设备文件写入数据时，tun_chr_write函数将被调用。它会使用tun_get_user，从用户区接收数据，将数据存入skb中，然后调用关键的函数netif_rx_ni(skb) ，将skb送给tcp/ip协议栈处理，最终完成虚拟网卡的数据接收。</p><p>至此，从虚拟机内部到宿主机的网络传输过程才算结束。</p><h2>总结时刻</h2><p>最后，我们把网络虚拟化场景下网络包的发送过程总结一下。</p><ul>\n<li>在虚拟机里面的用户态，应用程序通过write系统调用写入socket。</li>\n<li>写入的内容经过VFS层，内核协议栈，到达虚拟机里面的内核的网络设备驱动，也即virtio_net。</li>\n<li>virtio_net网络设备有一个操作结构struct net_device_ops，里面定义了发送一个网络包调用的函数为start_xmit。</li>\n<li>在virtio_net的前端驱动和qemu中的后端驱动之间，有两个队列virtqueue，一个用于发送，一个用于接收。然后，我们需要在start_xmit中调用virtqueue_add，将网络包放入发送队列，然后调用virtqueue_notify通知qemu。</li>\n<li>qemu本来处于KVM_RUN的状态，收到通知后，通过VM exit指令退出客户机模式，进入宿主机模式。发送网络包的时候，virtio_net_handle_tx_bh函数会被调用。</li>\n<li>接下来是一个for循环，我们需要在循环中调用virtqueue_pop，从传输队列中获取要发送的数据，然后调用qemu_sendv_packet_async进行发送。</li>\n<li>qemu会调用writev向字符设备文件写入，进入宿主机的内核。</li>\n<li>在宿主机内核中字符设备文件的file_operations里面的write_iter会被调用，也即会调用tun_chr_write_iter。</li>\n<li>在tun_chr_write_iter函数中，tun_get_user将要发送的网络包从qemu拷贝到宿主机内核里面来，然后调用netif_rx_ni开始调用宿主机内核协议栈进行处理。</li>\n<li>宿主机内核协议栈处理完毕之后，会发送给tap虚拟网卡，完成从虚拟机里面到宿主机的整个发送过程。</li>\n</ul><p><img src=\"https://static001.geekbang.org/resource/image/e3/44/e329505cfcd367612f8ae47054ec8e44.jpg?wh=3586*5503\" alt=\"\"></p><h2>课堂练习</h2><p>这一节我们解析的是发送过程，请你根据类似的思路，解析一下接收过程。</p><p>欢迎留言和我分享你的疑惑和见解，也欢迎收藏本节内容，反复研读。你也可以把今天的内容分享给你的朋友，和他一起学习和进步。</p><p><img src=\"https://static001.geekbang.org/resource/image/8c/37/8c0a95fa07a8b9a1abfd394479bdd637.jpg?wh=1110*659\" alt=\"\"></p>","neighbors":{"left":{"article_title":"54 | 存储虚拟化（下）：如何建立自己保管的单独档案库？","id":111522},"right":{"article_title":"56 | 容器：大公司为保持创新，鼓励内部创业","id":113370}},"comments":[{"had_liked":false,"id":148849,"user_name":"💢 星星💢","can_delete":false,"product_type":"c1","uid":1254392,"ip_address":"","ucode":"A402B765222C35","user_header":"https://static001.geekbang.org/account/avatar/00/13/23/f8/24fcccea.jpg","comment_is_top":false,"comment_ctime":1573094641,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"57407669489","product_id":100024701,"comment_content":"我感觉每次看看总结就差不多了。。一看到文中的代码，头很疼，本人c语言基础一般，调用来调用去。头很晕。每次看老师的文章。我先是大致看一下文章的大概意思，最后认真看一下总结。但是第二天好像又忘得七七八八了。自己基础还是太差了。刘老师的功底，太过于深厚。佩服。","like_count":12,"discussions":[{"author":{"id":1377393,"avatar":"https://static001.geekbang.org/account/avatar/00/15/04/71/0b949a4c.jpg","nickname":"何用","note":"","ucode":"B0C6E8176AE6FD","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":381264,"discussion_content":"像故事一样的操作系统入门课！作者怕是对故事有啥误解","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1624973783,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1317847,"avatar":"https://static001.geekbang.org/account/avatar/00/14/1b/d7/868d26ce.jpg","nickname":"songhyunmin","note":"","ucode":"D5A98668CD8532","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1377393,"avatar":"https://static001.geekbang.org/account/avatar/00/15/04/71/0b949a4c.jpg","nickname":"何用","note":"","ucode":"B0C6E8176AE6FD","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":550985,"discussion_content":"谈不上有趣。完全就是硬扒代码了。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1644835958,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":381264,"ip_address":""},"score":550985,"extra":""}]}]},{"had_liked":false,"id":126053,"user_name":"zhj","can_delete":false,"product_type":"c1","uid":1311772,"ip_address":"","ucode":"65B9E222D6E075","user_header":"https://static001.geekbang.org/account/avatar/00/14/04/1c/b0c6c009.jpg","comment_is_top":false,"comment_ctime":1566301928,"is_pvip":false,"replies":[{"id":"46533","content":"当然能优化呀，所以才有DPDK，virio vhost，SR-IOV等，所以这里分析的是传统的模式","user_name":"作者回复","user_name_real":"刘超@网易云","uid":"1001590","ctime":1566354813,"ip_address":"","comment_id":126053,"utype":1}],"discussion_count":1,"race_medal":0,"score":"53105909480","product_id":100024701,"comment_content":"不仅是走了两次协议栈，关键是客户机内核栈封包--&gt;宿主机内核栈解包，然后又利用宿主机协议栈封包发出去，这个流程感觉好怪异，两次走协议栈，三次动包，这个不能优化吗","like_count":13,"discussions":[{"author":{"id":1001590,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/48/76/0c7d4d23.jpg","nickname":"刘超","note":"","ucode":"196BF3F499E8FE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":463803,"discussion_content":"当然能优化呀，所以才有DPDK，virio vhost，SR-IOV等，所以这里分析的是传统的模式","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1566354813,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":124341,"user_name":"饭粒","can_delete":false,"product_type":"c1","uid":1153455,"ip_address":"","ucode":"4C3220B0D43997","user_header":"https://static001.geekbang.org/account/avatar/00/11/99/af/d29273e2.jpg","comment_is_top":false,"comment_ctime":1565863010,"is_pvip":false,"replies":[{"id":"46273","content":"加油","user_name":"作者回复","user_name_real":"刘超@网易云","uid":"1001590","ctime":1566280682,"ip_address":"","comment_id":124341,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18745732194","product_id":100024701,"comment_content":"写的真好，尤其总结精华。一篇内容要断断续续看好久。。","like_count":5,"discussions":[{"author":{"id":1001590,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/48/76/0c7d4d23.jpg","nickname":"刘超","note":"","ucode":"196BF3F499E8FE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":463124,"discussion_content":"加油","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1566280682,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":165008,"user_name":"williamcai","can_delete":false,"product_type":"c1","uid":1158294,"ip_address":"","ucode":"B158F52C2D39BC","user_header":"https://static001.geekbang.org/account/avatar/00/11/ac/96/46b13896.jpg","comment_is_top":false,"comment_ctime":1577147405,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10167081997","product_id":100024701,"comment_content":"能大概理解虚拟化原来是这么回事，用软件来模拟设备，最后还是要真正的设备来处理","like_count":2},{"had_liked":false,"id":236865,"user_name":"青年祭司","can_delete":false,"product_type":"c1","uid":1259156,"ip_address":"","ucode":"C88EDAE3FF09AE","user_header":"https://static001.geekbang.org/account/avatar/00/13/36/94/0b969588.jpg","comment_is_top":false,"comment_ctime":1595571470,"is_pvip":false,"discussion_count":0,"race_medal":5,"score":"5890538766","product_id":100024701,"comment_content":"老师，如果是一个宿主机上的两个虚拟机之间互相发送数据，会有优化吗","like_count":1},{"had_liked":false,"id":120410,"user_name":"kkxue","can_delete":false,"product_type":"c1","uid":1159904,"ip_address":"","ucode":"0DCB861D5543D6","user_header":"https://static001.geekbang.org/account/avatar/00/11/b2/e0/bf56878a.jpg","comment_is_top":false,"comment_ctime":1564886129,"is_pvip":true,"replies":[{"id":"46364","content":"别这样说，诚惶诚恐","user_name":"作者回复","user_name_real":"刘超@网易云","uid":"1001590","ctime":1566297149,"ip_address":"","comment_id":120410,"utype":1}],"discussion_count":1,"race_medal":5,"score":"5859853425","product_id":100024701,"comment_content":"学了这么多年的虚拟网络，不及老师一节课的深度啊","like_count":1,"discussions":[{"author":{"id":1001590,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/48/76/0c7d4d23.jpg","nickname":"刘超","note":"","ucode":"196BF3F499E8FE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":461326,"discussion_content":"别这样说，诚惶诚恐","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1566297149,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":120192,"user_name":"leslie","can_delete":false,"product_type":"c1","uid":1324255,"ip_address":"","ucode":"798E7C1CC98CC2","user_header":"https://static001.geekbang.org/account/avatar/00/14/34/df/64e3d533.jpg","comment_is_top":false,"comment_ctime":1564805097,"is_pvip":false,"replies":[{"id":"46369","content":"谢谢夸奖","user_name":"作者回复","user_name_real":"刘超@网易云","uid":"1001590","ctime":1566297300,"ip_address":"","comment_id":120192,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5859772393","product_id":100024701,"comment_content":"       学习了：跟完刘老师的趣谈网络协议再跟着linux系统，发现收获又不一样；同时在跟老师的网络协议的过程中，还被迫去跟着学习刘文浩老师的计算机组成原理-否则没法理解老师的一些概念。<br>       这大概就是老师之前说的学习方法吧：书阅读越厚、读书的过程中不断去相应的扩展、学习、提升理解，然后整理出自己的东西-书就薄了；虽然书薄了，可是笔记和自己的学习笔录却反而越来越厚了；感谢老师简单形象的教诲。","like_count":1,"discussions":[{"author":{"id":1001590,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/48/76/0c7d4d23.jpg","nickname":"刘超","note":"","ucode":"196BF3F499E8FE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":461232,"discussion_content":"谢谢夸奖","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1566297300,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":119788,"user_name":"安排","can_delete":false,"product_type":"c1","uid":1260026,"ip_address":"","ucode":"F78CFA9624CAEF","user_header":"https://static001.geekbang.org/account/avatar/00/13/39/fa/a7edbc72.jpg","comment_is_top":false,"comment_ctime":1564703284,"is_pvip":false,"replies":[{"id":"46375","content":"是的，两次协议栈","user_name":"作者回复","user_name_real":"刘超@网易云","uid":"1001590","ctime":1566297684,"ip_address":"","comment_id":119788,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5859670580","product_id":100024701,"comment_content":"网络包是什么样的？经过协议栈处理之前的还是之后的？这样看来虚拟机里面发送网络数据要走两次协议栈吗？因为虚拟机本身也有自己的协议栈，经过虚拟机协议栈处理的数据qemu会进行拆包重新还原出原始的数据吗？","like_count":1,"discussions":[{"author":{"id":1001590,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/48/76/0c7d4d23.jpg","nickname":"刘超","note":"","ucode":"196BF3F499E8FE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":461072,"discussion_content":"是的，两次协议栈","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1566297684,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1153455,"avatar":"https://static001.geekbang.org/account/avatar/00/11/99/af/d29273e2.jpg","nickname":"饭粒","note":"","ucode":"4C3220B0D43997","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":4982,"discussion_content":"个人觉得 qemu 没有拆包，qemu 没有协议栈，应该也不能拆包。然后文中“tun_get_user 将要发送的网络包从 qemu 拷贝到宿主机内核里面来”拷贝出来的还是网络包。\n简化的数据流转大致流程：\n客户机用户态 {write 数据} -> 客户机内核态{协议栈处理为网络包} -> qemu{循环从队列中获取网络包，再向字符设备写入数据流}  -> 宿主机用户态{dev/net/tun 字符设备接收数据流} -> 宿主机内核态{将网络包拷贝到宿主机内核里面来，协议栈处理} -> 宿主机用户态{虚拟网卡发送}","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1565862916,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":343442,"user_name":"呆萌白的大白。","can_delete":false,"product_type":"c1","uid":1284870,"ip_address":"","ucode":"A0DA4F8B5C892D","user_header":"https://static001.geekbang.org/account/avatar/00/13/9b/06/a1b0bd54.jpg","comment_is_top":false,"comment_ctime":1650855377,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1650855377","product_id":100024701,"comment_content":"有几个问题还是想请教一下作者：<br>一:课程中讲的virtio-net后端是vhost-net吗?<br>二:vhost-net模式下,guestos中的网络IO一定会引起vmexit吗?<br>三:vmexit之后,KVM是怎么通知给vhost-net内核线程的,KVM直接调用vhost-net模块吗?<br>四:前端肯定都是virtio-net了,vhost-net后端跟virtio-net后端,vmexit之后都是KVM模块直接调用后端的驱动代码吗,那这段时间guestos始终出去vmexit状态,不做任何操作吗?<br>五:vhost-net怎么把包传递给guestos啊,也是KVM直接调用代码吗?那是guestos发包,vmexit然后一直等着,对端回包之后KVM再vmentry吗?因为IO中断就一直阻塞是不是效率太差了,而且非常用可能外部访问虚拟机提供的服务啊,这时候虚拟机本身就是在vmentry已进入的状态啊,这就矛盾了啊.","like_count":0},{"had_liked":false,"id":310932,"user_name":"古古惑惑","can_delete":false,"product_type":"c1","uid":1039710,"ip_address":"","ucode":"37724A018564FF","user_header":"https://static001.geekbang.org/account/avatar/00/0f/dd/5e/2354204d.jpg","comment_is_top":false,"comment_ctime":1630991394,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1630991394","product_id":100024701,"comment_content":"老师功力太深了，膜拜。","like_count":0},{"had_liked":false,"id":250347,"user_name":"莫名","can_delete":false,"product_type":"c1","uid":1007254,"ip_address":"","ucode":"E28F2602BA25DD","user_header":"https://static001.geekbang.org/account/avatar/00/0f/5e/96/a03175bc.jpg","comment_is_top":false,"comment_ctime":1601034833,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1601034833","product_id":100024701,"comment_content":"🐮🍺","like_count":0},{"had_liked":false,"id":249320,"user_name":"呆瓜","can_delete":false,"product_type":"c1","uid":1655940,"ip_address":"","ucode":"C98C7B224D0640","user_header":"https://static001.geekbang.org/account/avatar/00/19/44/84/4da14994.jpg","comment_is_top":false,"comment_ctime":1600590896,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1600590896","product_id":100024701,"comment_content":"老师内力太过深厚,吾等难以望其项背!","like_count":0},{"had_liked":false,"id":149115,"user_name":"Geek_366a52","can_delete":false,"product_type":"c1","uid":1291105,"ip_address":"","ucode":"B6AE9146878244","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJnRUibp7LV1lyHFWEUz5pIwvuXVIJ9ZlFKFOOQQEc7FO3Umt03FUrvYHa3gXQbvT3M70m6V0LibXvw/132","comment_is_top":false,"comment_ctime":1573143414,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1573143414","product_id":100024701,"comment_content":"图中的虚拟网卡tap0和物理网卡应该是在内核态部分的吧？","like_count":0}]}