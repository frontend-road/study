{"id":310938,"title":"69｜项目实战：基于Flink SQL实现Top10商品统计","content":"<p><strong>课件和Demo地址</strong><br>\n<a href=\"https://gitee.com/geektime-geekbang/geektime-Flink\">https://gitee.com/geektime-geekbang/geektime-Flink</a></p>","comments":[{"had_liked":false,"id":285223,"user_name":"hjw","can_delete":false,"product_type":"c3","uid":1654183,"ip_address":"","ucode":"7D359F536E9297","user_header":"https://static001.geekbang.org/account/avatar/00/19/3d/a7/d1f3c319.jpg","comment_is_top":false,"comment_ctime":1616674299,"is_pvip":false,"replies":null,"discussion_count":2,"race_medal":0,"score":2,"product_id":100058801,"comment_content":"老师好，请问每10分钟统计一天累计独立用户数课件上的sql是对的吗。这样的写法应该不是只当天的，而是往前推所有的数据，是吗","like_count":3,"discussions":[{"author":{"id":1101234,"avatar":"https://static001.geekbang.org/account/avatar/00/10/cd/b2/807137b9.jpg","nickname":"北方易初","note":"","ucode":"C57FDBD37F43E6","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":634652,"discussion_content":"大错特错。请参考 Flink 官方的这个实例\nhttps://flink.apache.org/2020/07/28/flink-sql-demo-building-an-end-to-end-streaming-application/","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1703767862,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"日本","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1511712,"avatar":"https://static001.geekbang.org/account/avatar/00/17/11/20/9f31c4f4.jpg","nickname":"wow_xiaodi","note":"","ucode":"B3FB301556A7EA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":390998,"discussion_content":"10分钟的统计频率也没有体现出来，就算sql写对了，基于一天的count(distinct(user_id))得维护多大的状态数据才可以去重啊，生产不会那么做的。建议count(distinct)写成自定义function，结合redis的bitmap或者布隆过滤器来去重","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1630223217,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":311660,"user_name":"Geek_74dea9","can_delete":false,"product_type":"c3","uid":2760246,"ip_address":"","ucode":"14092EEBC08171","user_header":"","comment_is_top":false,"comment_ctime":1631371260,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100058801,"comment_content":"第一个要统计每小时的成交量，应该需要带个日期字段吧。\n第二个统计1天累计用户， 应该限定是当天吧。\n\n","like_count":1},{"had_liked":false,"id":319563,"user_name":"sunny.","can_delete":false,"product_type":"c3","uid":2230220,"ip_address":"","ucode":"E9EE293CB4042B","user_header":"https://static001.geekbang.org/account/avatar/00/22/07/cc/6e682144.jpg","comment_is_top":false,"comment_ctime":1635850830,"is_pvip":false,"replies":null,"discussion_count":1,"race_medal":0,"score":2,"product_id":100058801,"comment_content":"数据集怎么写入到kafka里面","like_count":0,"discussions":[{"author":{"id":1101234,"avatar":"https://static001.geekbang.org/account/avatar/00/10/cd/b2/807137b9.jpg","nickname":"北方易初","note":"","ucode":"C57FDBD37F43E6","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":634653,"discussion_content":"用 Python 脚本写或者自己写个 Flink job producer 写入下","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1703767974,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"日本","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}