{"id":70253,"title":"14 | BigTable的开源实现：HBase","content":"<p>我们知道，Google发表GFS、MapReduce、BigTable三篇论文，号称“三驾马车”，开启了大数据的时代。那和这“三驾马车”对应的有哪些开源产品呢？我们前面已经讲过了GFS对应的Hadoop分布式文件系统HDFS，以及MapReduce对应的Hadoop分布式计算框架MapReduce，今天我们就来领略一下<span class=\"orange\">BigTable对应的NoSQL系统HBase</span>，看看它是如何大规模处理海量数据的。</p><p>在计算机数据存储领域，一直是关系数据库（RDBMS）的天下，以至于在传统企业的应用领域，许多应用系统设计都是面向数据库设计，也就是<strong>先设计数据库然后设计程序</strong>，从而导致<strong>关系模型绑架对象模型</strong>，并由此引申出旷日持久的业务对象贫血模型与充血模型之争。</p><p>业界为了解决关系数据库的不足，提出了诸多方案，比较有名的是对象数据库，但是这些数据库的出现似乎只是进一步证明关系数据库的优越而已。直到人们遇到了关系数据库难以克服的缺陷——糟糕的海量数据处理能力及僵硬的设计约束，局面才有所改善。从Google的BigTable开始，一系列的可以进行海量数据存储与访问的数据库被设计出来，更进一步说，NoSQL这一概念被提了出来。</p><!-- [[[read_end]]] --><p>NoSQL，主要指非关系的、分布式的、支持海量数据存储的数据库设计模式。也有许多专家将 NoSQL解读为Not Only SQL，表示NoSQL只是关系数据库的补充，而不是替代方案。其中，HBase是这一类NoSQL系统的杰出代表。</p><p>HBase之所以能够具有海量数据处理能力，其根本在于和传统关系型数据库设计的不同思路。传统关系型数据库对存储在其上的数据有很多约束，学习关系数据库都要学习数据库设计范式，事实上，是在数据存储中包含了一部分业务逻辑。而NoSQL数据库则简单暴力地认为，数据库就是存储数据的，业务逻辑应该由应用程序去处理，有时候不得不说，简单暴力也是一种美。</p><h2>HBase可伸缩架构</h2><p>我们先来看看HBase的架构设计。HBase为可伸缩海量数据储存而设计，实现面向在线业务的实时数据访问延迟。HBase的伸缩性主要依赖其可分裂的HRegion及可伸缩的分布式文件系统HDFS实现。</p><p><img src=\"https://static001.geekbang.org/resource/image/9f/f7/9f4220274ef0a6bcf253e8d012a6d4f7.png?wh=1396*454\" alt=\"\"></p><p>HRegion是HBase负责数据存储的主要进程，应用程序对数据的读写操作都是通过和HRegion通信完成。上面是HBase架构图，我们可以看到在HBase中，数据以HRegion为单位进行管理，也就是说应用程序如果想要访问一个数据，必须先找到HRegion，然后将数据读写操作提交给HRegion，由 HRegion完成存储层面的数据操作。</p><p>HRegionServer是物理服务器，每个HRegionServer上可以启动多个HRegion实例。当一个 HRegion中写入的数据太多，达到配置的阈值时，一个HRegion会分裂成两个HRegion，并将HRegion在整个集群中进行迁移，以使HRegionServer的负载均衡。</p><p>每个HRegion中存储一段Key值区间[key1, key2)的数据，所有HRegion的信息，包括存储的Key值区间、所在HRegionServer地址、访问端口号等，都记录在HMaster服务器上。为了保证HMaster的高可用，HBase会启动多个HMaster，并通过ZooKeeper选举出一个主服务器。</p><p>下面是一张调用时序图，应用程序通过ZooKeeper获得主HMaster的地址，输入Key值获得这个Key所在的HRegionServer地址，然后请求HRegionServer上的HRegion，获得所需要的数据。</p><p><img src=\"https://static001.geekbang.org/resource/image/9f/ab/9fd982205b06ecd43053202da2ae08ab.png?wh=1406*600\" alt=\"\"></p><p>数据写入过程也是一样，需要先得到HRegion才能继续操作。HRegion会把数据存储在若干个HFile格式的文件中，这些文件使用HDFS分布式文件系统存储，在整个集群内分布并高可用。当一个HRegion中数据量太多时，这个HRegion连同HFile会分裂成两个HRegion，并根据集群中服务器负载进行迁移。如果集群中有新加入的服务器，也就是说有了新的HRegionServer，由于其负载较低，也会把HRegion迁移过去并记录到HMaster，从而实现HBase的线性伸缩。</p><p>先小结一下上面的内容，HBase的核心设计目标是解决海量数据的分布式存储，和Memcached这类分布式缓存的路由算法不同，HBase的做法是按Key的区域进行分片，这个分片也就是HRegion。应用程序通过HMaster查找分片，得到HRegion所在的服务器HRegionServer，然后和该服务器通信，就得到了需要访问的数据。</p><h2>HBase可扩展数据模型</h2><p>传统的关系数据库为了保证关系运算（通过SQL语句）的正确性，在设计数据库表结构的时候，需要指定表的schema也就是字段名称、数据类型等，并要遵循特定的设计范式。这些规范带来了一个问题，就是僵硬的数据结构难以面对需求变更带来的挑战，有些应用系统设计者通过预先设计一些冗余字段来应对，但显然这种设计也很糟糕。</p><p>那有没有办法能够做到可扩展的数据结构设计呢？不用修改表结构就可以新增字段呢？当然有的，许多NoSQL数据库使用的列族（ColumnFamily）设计就是其中一个解决方案。列族最早在Google的BigTable中使用，这是一种面向列族的稀疏矩阵存储格式，如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/74/6f/74b3aac940abae8a571cc94f2226656f.png?wh=1188*210\" alt=\"\"></p><p>这是一个学生的基本信息表，表中不同学生的联系方式各不相同，选修的课程也不同，而且将来还会有更多联系方式和课程加入到这张表里，如果按照传统的关系数据库设计，无论提前预设多少冗余字段都会捉襟见肘、疲于应付。</p><p>而使用支持列族结构的NoSQL数据库，在创建表的时候，只需要指定列族的名字，无需指定字段（Column）。那什么时候指定字段呢？可以在数据写入时再指定。通过这种方式，数据表可以包含数百万的字段，这样就可以随意扩展应用程序的数据结构了。并且这种数据库在查询时也很方便，可以通过指定任意字段名称和值进行查询。</p><p>HBase这种列族的数据结构设计，实际上是把字段的名称和字段的值，以Key-Value的方式一起存储在HBase中。实际写入的时候，可以随意指定字段名称，即使有几百万个字段也能轻松应对。</p><h2>HBase的高性能存储</h2><p>还记得专栏第5期讲RAID时我留给你的思考题吗？当时很多同学答得都很棒。传统的机械式磁盘的访问特性是<strong>连续读写很快，随机读写很慢</strong>。这是因为机械磁盘靠电机驱动访问磁盘上的数据，电机要将磁头落到数据所在的磁道上，这个过程需要较长的寻址时间。如果数据不连续存储，磁头就要不停地移动，浪费了大量的时间。</p><p>为了提高数据写入速度，HBase使用了一种叫作<strong>LSM树</strong>的数据结构进行数据存储。LSM树的全名是Log Structed Merge Tree，翻译过来就是Log结构合并树。数据写入的时候以Log方式连续写入，然后异步对磁盘上的多个LSM树进行合并。</p><p><img src=\"https://static001.geekbang.org/resource/image/5f/3b/5fbd17a9c0b9f1a10347a4473d00ad3b.jpg?wh=4411*1911\" alt=\"\"></p><p>LSM树可以看作是一个N阶合并树。数据写操作（包括插入、修改、删除）都在内存中进行，并且都会创建一个新记录（修改会记录新的数据值，而删除会记录一个删除标志）。这些数据在内存中仍然还是一棵排序树，当数据量超过设定的内存阈值后，会将这棵排序树和磁盘上最新的排序树合并。当这棵排序树的数据量也超过设定阈值后，会和磁盘上下一级的排序树合并。合并过程中，会用最新更新的数据覆盖旧的数据（或者记录为不同版本）。</p><p>在需要进行读操作时，总是从内存中的排序树开始搜索，如果没有找到，就从磁盘 上的排序树顺序查找。</p><p>在LSM树上进行一次数据更新不需要磁盘访问，在内存即可完成。当数据访问以写操作为主，而读操作则集中在最近写入的数据上时，使用LSM树可以极大程度地减少磁盘的访问次数，加快访问速度。</p><h2>小结</h2><p>最后，总结一下我们今天讲的内容。HBase作为Google BigTable的开源实现，完整地继承了BigTable的优良设计。架构上通过数据分片的设计配合HDFS，实现了数据的分布式海量存储；数据结构上通过列族的设计，实现了数据表结构可以在运行期自定义；存储上通过LSM树的方式，使数据可以通过连续写磁盘的方式保存数据，极大地提高了数据写入性能。</p><p>这些优良的设计结合Apache开源社区的高质量开发，使得HBase在NoSQL众多竞争产品中保持领先优势，逐步成为NoSQL领域最具影响力的产品。</p><h2>思考题</h2><p>HBase的列族数据结构虽然有灵活的优势，但是也有缺点。请你思考一下，列族结构的缺点有哪些？如何在应用开发的时候克服这些缺点？哪些场景最好还是使用MySQL这类关系数据库呢？</p><p>欢迎你写下自己的思考或疑问，与我和其他同学一起讨论。如果你学完今天的内容有所收获的话，也欢迎你点击“请朋友读”，把今天的文章分享给你的朋友。</p>","comments":[{"had_liked":false,"id":44532,"user_name":"大马猴","can_delete":false,"product_type":"c1","uid":1012528,"ip_address":"","ucode":"E3482CBDF43CDE","user_header":"https://static001.geekbang.org/account/avatar/00/0f/73/30/fd602742.jpg","comment_is_top":false,"comment_ctime":1543455367,"is_pvip":false,"discussion_count":3,"race_medal":0,"score":"409565348487","product_id":100020201,"comment_content":"提一个建议，大家尽量发一些跟技术主题相关的评论，这才是对作者劳动成果的尊重，也请作者少放那些吹捧和自说自话的评论，提高阅读体验。","like_count":96,"discussions":[{"author":{"id":1003969,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/51/c1/e092ae64.jpg","nickname":"JonSlow","note":"","ucode":"277D416BA3B5B3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":220632,"discussion_content":"那些“自说自话”是作者对相关主题的主观总结，是专栏的精华。技术细节请学会查看官方文档。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1585909496,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":2,"child_discussions":[{"author":{"id":1012528,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/73/30/fd602742.jpg","nickname":"大马猴","note":"","ucode":"E3482CBDF43CDE","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1003969,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/51/c1/e092ae64.jpg","nickname":"JonSlow","note":"","ucode":"277D416BA3B5B3","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":243069,"discussion_content":"我说的是评论，不是作者，汗","likes_number":7,"is_delete":false,"is_hidden":false,"ctime":1587518963,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":220632,"ip_address":""},"score":243069,"extra":""},{"author":{"id":1133206,"avatar":"https://static001.geekbang.org/account/avatar/00/11/4a/96/8756eaa2.jpg","nickname":"王也","note":"","ucode":"9EA69B51ECC99F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1003969,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/51/c1/e092ae64.jpg","nickname":"JonSlow","note":"","ucode":"277D416BA3B5B3","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":391467,"discussion_content":"兄弟理解力堪忧啊.","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1630477963,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":220632,"ip_address":""},"score":391467,"extra":""}]}]},{"had_liked":false,"id":44487,"user_name":"Kaer","can_delete":false,"product_type":"c1","uid":1113558,"ip_address":"","ucode":"1BD233D3FAC2B1","user_header":"https://static001.geekbang.org/account/avatar/00/10/fd/d6/71e1cc29.jpg","comment_is_top":false,"comment_ctime":1543453202,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"336550902290","product_id":100020201,"comment_content":"1:列族不好查询，没有传统sql那样按照不同字段方便，只能根据rowkey查询，范围查询scan性能低。2:查询也没有mysql一样的走索引优化，因为列不固定 3:列族因为不固定，所以很难做一些业务约束，比如uk等等。4:做不了事务控制","like_count":79},{"had_liked":false,"id":52344,"user_name":"special","can_delete":false,"product_type":"c1","uid":1239961,"ip_address":"","ucode":"6D7C91041FD88F","user_header":"https://static001.geekbang.org/account/avatar/00/12/eb/99/5b6d689c.jpg","comment_is_top":false,"comment_ctime":1545364535,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"143279285303","product_id":100020201,"comment_content":"看了十多篇文章了，大都是从大数据领域相关技术的特点，原理及应用场景等方面来阐述，讲得很不错，不过有不少内容需要具备一定的大数据实践及理论基础才能很好的吸收，文章没有针对大数据相关框架或工具的实践介绍，比如环境搭建，操作使用等。这也可以理解，这些放在文章中进行介绍也不大合适。<br>我最近学习了大数据快一年了，对于大数据领域的常用工具，如hdfs,hbase,mapreduce,yarn,hive,sqoop,pig,flume,storm,spark等的实践内容，如环境搭建，架构原理，基本操作，Java基本编程等，做了总结，全部以文章的形式发表在个人公众号里:程序猿的修身养性，有兴趣的朋友可以关注下，一起交流学习！","like_count":34,"discussions":[{"author":{"id":1052191,"avatar":"https://static001.geekbang.org/account/avatar/00/10/0e/1f/d0472177.jpg","nickname":"厉害了我的国","note":"","ucode":"CD0A54A1B998AA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":5084,"discussion_content":"环境搭建、基本使用看官方文档啊。别搞什么公众号毒害他人了，浪费时间","likes_number":9,"is_delete":false,"is_hidden":false,"ctime":1565932597,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1524709,"avatar":"https://static001.geekbang.org/account/avatar/00/17/43/e5/f415d117.jpg","nickname":"下一块巧克力","note":"","ucode":"66E1279DF3C038","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1052191,"avatar":"https://static001.geekbang.org/account/avatar/00/10/0e/1f/d0472177.jpg","nickname":"厉害了我的国","note":"","ucode":"CD0A54A1B998AA","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":330113,"discussion_content":"人家喜欢搞是自己的事情，如果确实能提供质量更好的学习资料也是件好事","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606533266,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":5084,"ip_address":""},"score":330113,"extra":""}]}]},{"had_liked":false,"id":44481,"user_name":"夏一Sunny","can_delete":false,"product_type":"c1","uid":1189599,"ip_address":"","ucode":"91E5C73D50BE7E","user_header":"https://static001.geekbang.org/account/avatar/00/12/26/df/b56721f0.jpg","comment_is_top":false,"comment_ctime":1543452710,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"117507569702","product_id":100020201,"comment_content":"对于LSM树的合并和高效，还是不太理解。","like_count":28,"discussions":[{"author":{"id":1197455,"avatar":"https://static001.geekbang.org/account/avatar/00/12/45/8f/a56b2214.jpg","nickname":"innocent","note":"","ucode":"368659A0DDE7E4","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":336221,"discussion_content":"就像经典的算法题，合并两个有序数组","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1608532880,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":45079,"user_name":"shangyu","can_delete":false,"product_type":"c1","uid":1011389,"ip_address":"","ucode":"13A26E53508D75","user_header":"https://static001.geekbang.org/account/avatar/00/0f/6e/bd/b83ad32d.jpg","comment_is_top":false,"comment_ctime":1543544158,"is_pvip":true,"replies":[{"id":"16226","content":"还有一个写操作日志记录数据，所以数据不会丢，但是宕机恢复需要时间，就是根据日志恢复数据，这段时间部分数据更新访问不到。","user_name":"作者回复","comment_id":45079,"uid":"1007349","ip_address":"","utype":1,"ctime":1543676341,"user_name_real":"李智慧"}],"discussion_count":6,"race_medal":0,"score":"83147922782","product_id":100020201,"comment_content":"内存写操作 如何保证突然掉电的话不丢数据呢","like_count":20,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":430916,"discussion_content":"还有一个写操作日志记录数据，所以数据不会丢，但是宕机恢复需要时间，就是根据日志恢复数据，这段时间部分数据更新访问不到。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1543676341,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1276795,"avatar":"https://static001.geekbang.org/account/avatar/00/13/7b/7b/5b39b47b.jpg","nickname":"TIAN","note":"","ucode":"CCCF80602C1753","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":299304,"discussion_content":"有点像mysql redo log","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1597650660,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1624590,"avatar":"https://static001.geekbang.org/account/avatar/00/18/ca/0e/5009c5ff.jpg","nickname":"遇见","note":"","ucode":"FAF53CD4C28494","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":219794,"discussion_content":"写日志应该是顺序写磁盘 速度快","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1585809402,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1161325,"avatar":"https://static001.geekbang.org/account/avatar/00/11/b8/6d/aeb34336.jpg","nickname":"黄文昊","note":"","ucode":"FC5F74FB91C8CB","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":410,"discussion_content":"既然都写日志记录了，那么已经访问磁盘了，为什么不直接把数据记下来","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1561536889,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":2,"child_discussions":[{"author":{"id":1014665,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/7b/89/34f2cbcc.jpg","nickname":"杨宇","note":"","ucode":"EB74DF6E269F03","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1161325,"avatar":"https://static001.geekbang.org/account/avatar/00/11/b8/6d/aeb34336.jpg","nickname":"黄文昊","note":"","ucode":"FC5F74FB91C8CB","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":174360,"discussion_content":"类似于MySQL的刷盘策略，0 1 2可以选择。主要是异步+顺序写","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1581909704,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":410,"ip_address":""},"score":174360,"extra":""},{"author":{"id":1062848,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83ersGSic8ib7OguJv6CJiaXY0s4n9C7Z51sWxTTljklFpq3ZAIWXoFTPV5oLo0GMTkqW5sYJRRnibNqOJQ/132","nickname":"walle斌","note":"","ucode":"0DB3243004951F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1161325,"avatar":"https://static001.geekbang.org/account/avatar/00/11/b8/6d/aeb34336.jpg","nickname":"黄文昊","note":"","ucode":"FC5F74FB91C8CB","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":344057,"discussion_content":"hbase的最终落盘数据到hdfs上边。。所以确实数据记录下来了，但是仅仅做一个wal机制保证而已","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1611276094,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":410,"ip_address":""},"score":344057,"extra":""}]}]},{"had_liked":false,"id":44524,"user_name":"纯齐","can_delete":false,"product_type":"c1","uid":1056485,"ip_address":"","ucode":"20306095ABA7CB","user_header":"https://static001.geekbang.org/account/avatar/00/10/1e/e5/140b334e.jpg","comment_is_top":false,"comment_ctime":1543454857,"is_pvip":true,"discussion_count":4,"race_medal":0,"score":"83147833481","product_id":100020201,"comment_content":"文中提到hbase数据的修改在内存中处理，就是说如果机器断电的话数据会丢失，请问hbase有没有措施来保证数据不丢失？","like_count":20,"discussions":[{"author":{"id":1812949,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/a9/d5/400035c8.jpg","nickname":"地瓜","note":"","ucode":"F35013CAA80862","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":205391,"discussion_content":"其实是先写在hlog日志里面的，比如断电重启的话会加载hlog，这样就可以恢复数据了","likes_number":5,"is_delete":false,"is_hidden":false,"ctime":1584288884,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":2,"child_discussions":[{"author":{"id":1667714,"avatar":"https://static001.geekbang.org/account/avatar/00/19/72/82/24fb9d18.jpg","nickname":"慕然","note":"","ucode":"8622102560A80F","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1812949,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/a9/d5/400035c8.jpg","nickname":"地瓜","note":"","ucode":"F35013CAA80862","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":331116,"discussion_content":"这种方式岂不是和mysql中的redo log一样了，那这样不就比较容易能支持事务了么？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606790325,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":205391,"ip_address":""},"score":331116,"extra":""},{"author":{"id":1197455,"avatar":"https://static001.geekbang.org/account/avatar/00/12/45/8f/a56b2214.jpg","nickname":"innocent","note":"","ucode":"368659A0DDE7E4","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1667714,"avatar":"https://static001.geekbang.org/account/avatar/00/19/72/82/24fb9d18.jpg","nickname":"慕然","note":"","ucode":"8622102560A80F","race_medal":0,"user_type":1,"is_pvip":true},"discussion":{"id":347521,"discussion_content":"MySQL的事务支持不是(只)靠redo完成的，redo和HLog最多解决的是崩溃恢复，大概对应的ACID中的持久化。","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1612249201,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":331116,"ip_address":""},"score":347521,"extra":""}]},{"author":{"id":1318540,"avatar":"https://static001.geekbang.org/account/avatar/00/14/1e/8c/450fe5cb.jpg","nickname":"花儿少年","note":"","ucode":"CFE4F64243673B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":292279,"discussion_content":"是的，hlog 是追加写的，数据变更操作变成了一次追加写日志，和内存修改，所以性能较好","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1595164870,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":45544,"user_name":"Jowin","can_delete":false,"product_type":"c1","uid":1114356,"ip_address":"","ucode":"19017F7D06C22A","user_header":"https://static001.geekbang.org/account/avatar/00/11/00/f4/cc5f0896.jpg","comment_is_top":false,"comment_ctime":1543667079,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"65968176519","product_id":100020201,"comment_content":"列族数据组织方式的缺点：<br>1）在需要读取整条记录的时候，需要访问多个列族组合数据，效率会降低，可以通过字段冗余来解决一些问题。<br>2）只能提供Key值和全表扫描两种访问方式，很多情况下需要自己建耳机索引。<br>3）数据是非结构化，或者说是半结构化的，应用在处理数据时要费点心，不像关系数据库那么省心。<br><br>在数据完全结构化，很少变动，需要事务的场景使用Mysql等关系数据库比较合适。","like_count":16},{"had_liked":false,"id":45089,"user_name":"落叶飞逝的恋","can_delete":false,"product_type":"c1","uid":1046429,"ip_address":"","ucode":"F9A95DB28BCF1E","user_header":"https://static001.geekbang.org/account/avatar/00/0f/f7/9d/be04b331.jpg","comment_is_top":false,"comment_ctime":1543544842,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"48788185098","product_id":100020201,"comment_content":"其实所谓的列组就是相当于定义一个范围宽泛一点的名称定义的JSON。比如课程成绩。就是一个宽泛的定义，使用这种就是能方便的进行动态扩展。不像传统的关系型数据库就需要定义数学成绩、英语成绩等具体科目字段。但是虽然列祖能解决动态扩展，但是对于查询不友好，特别是查询单科成绩，需要解析这个课程成绩的JSON，再筛选出单科。而传统关系型数据库就能精准快速的查询出来。这两个可以互取长处使用。","like_count":12,"discussions":[{"author":{"id":1008582,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/63/c6/d6ea3df3.jpg","nickname":"林肯","note":"","ucode":"D2C97220230DE5","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":411590,"discussion_content":"从这一点考虑，mysql5.7已经支持json类型了，那么hbase还有什么优势呢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1635951348,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1057843,"avatar":"https://static001.geekbang.org/account/avatar/00/10/24/33/bcf37f50.jpg","nickname":"阿甘","note":"","ucode":"BC93175B70E05D","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1008582,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/63/c6/d6ea3df3.jpg","nickname":"林肯","note":"","ucode":"D2C97220230DE5","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":552668,"discussion_content":"关键还是列式存储+自动分裂吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1645540839,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":411590,"ip_address":""},"score":552668,"extra":""}]}]},{"had_liked":false,"id":44434,"user_name":"伊森","can_delete":false,"product_type":"c1","uid":1142172,"ip_address":"","ucode":"270A665771F463","user_header":"https://static001.geekbang.org/account/avatar/00/11/6d/9c/beaf7642.jpg","comment_is_top":false,"comment_ctime":1543447657,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"48788087913","product_id":100020201,"comment_content":"李老师，hbase对olap的分析场景支持不行吧？这也是我正想问的问题，一般都咋么解决，那种可变化的数据的实时统计分析场景的？","like_count":11},{"had_liked":false,"id":91766,"user_name":"why","can_delete":false,"product_type":"c1","uid":1123113,"ip_address":"","ucode":"FCB4E466C8D690","user_header":"https://static001.geekbang.org/account/avatar/00/11/23/29/fe0242da.jpg","comment_is_top":false,"comment_ctime":1557105370,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"44506778330","product_id":100020201,"comment_content":"1，什么是HBASE？<br>Google三驾马车之BigTable的开源实现，配合HDFS，实现了数据的分布式海量存储。<br>2，为什么会出现HBASE？<br>传统关系型数据库，关系模型绑架对象模型、僵硬的约束设计及设计范式使得存储数据包含了一部分业务逻辑，而且糟糕的海量数据处理能力引出了各种NoSql设计，HBASE简单粗暴，数据库就是存储数据，业务由应用去处理。<br>3，HBASE设计特点？<br>a，可伸缩<br>HBASE以key的区域进行分片形成HRegion（HBASE数据管理的基本单位），一个HRegion中数据量超过阈值，会一分为二，并在集群中进行负载均衡。<br>数据读写：application Zookeeper  HMaster HRegionServer HRegion HFile<br>b，可扩展数据模型<br>列族设计，具体字段（column）在写入时指定，轻松支持百万字段的扩展<br>c，高性能存储<br>数据写入时通过log连续写入，异步与磁盘上的多个LSM树进行合并。<br>数据写操作（i，u，d）都在内存中进行（也是一颗排序树），超过内存阈值，与磁盘上最新的LSM树合并","like_count":11},{"had_liked":false,"id":48110,"user_name":"足迹","can_delete":false,"product_type":"c1","uid":1105779,"ip_address":"","ucode":"38134D1A6B8DC2","user_header":"https://static001.geekbang.org/account/avatar/00/10/df/73/4a4ce2b5.jpg","comment_is_top":false,"comment_ctime":1544358086,"is_pvip":false,"replies":[{"id":"17340","content":"每个DataNode安装多个hregion","user_name":"作者回复","comment_id":48110,"uid":"1007349","ip_address":"","utype":1,"ctime":1544487978,"user_name_real":"李智慧"}],"discussion_count":1,"race_medal":0,"score":"40199063750","product_id":100020201,"comment_content":"HBase是基于HDFS存储的，那实际应用中是不是应该每台DataNode节点安装一个Region?","like_count":10,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":432030,"discussion_content":"每个DataNode安装多个hregion","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1544487978,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":111943,"user_name":"Geek_c991e0","can_delete":false,"product_type":"c1","uid":1206623,"ip_address":"","ucode":"5B6391E2D69D50","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epLLXBLBLgticobxvBYRezd304Y66Q8ibYCl7mG9dvTHGrx9obRcn7ZmJBcib3ibsQPIX3xIbNYiaAUrOA/132","comment_is_top":false,"comment_ctime":1562640889,"is_pvip":false,"replies":[{"id":"41629","content":"key按照区间分片，所以第一次请求后，这个key所在的分片信息就会缓存在client，所以并不需要每次请求组都先到HMaster，但是HMaster还是需要很多台机器，一则是为了应付访问压力，但是主要是为了高可用，当主HMaster宕机后，可选举新的主HMaster出来。","user_name":"作者回复","comment_id":111943,"uid":"1007349","ip_address":"","utype":1,"ctime":1563247610,"user_name_real":"李智慧"}],"discussion_count":2,"race_medal":0,"score":"31627411961","product_id":100020201,"comment_content":"老是，所有的请求都会先到HMaster，HMaster是不是也要多台机器才行，要不压力太大吧。如果多台主从是不是又会有同步的问题","like_count":7,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":457510,"discussion_content":"key按照区间分片，所以第一次请求后，这个key所在的分片信息就会缓存在client，所以并不需要每次请求组都先到HMaster，但是HMaster还是需要很多台机器，一则是为了应付访问压力，但是主要是为了高可用，当主HMaster宕机后，可选举新的主HMaster出来。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563247610,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1210519,"avatar":"https://static001.geekbang.org/account/avatar/00/12/78/97/fa101174.jpg","nickname":"年轻人","note":"","ucode":"CDD4612BAE3247","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":558653,"discussion_content":"只有表结构的维护（表的创建、修改、删除）才通过HMaster，其它访问都是从zk去获取区间，然后进行表内的数据读写操作了。当表创建后之后，如果HMaster挂了，ZK 和 RegionServer正常的话，针对表的读写操作都是可以正常进行的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1648432472,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":44778,"user_name":"M","can_delete":false,"product_type":"c1","uid":1117633,"ip_address":"","ucode":"88F6F1433A01A3","user_header":"https://static001.geekbang.org/account/avatar/00/11/0d/c1/d36816df.jpg","comment_is_top":false,"comment_ctime":1543491319,"is_pvip":false,"replies":[{"id":"16232","content":"zk查询哪个master是主master。<br><br>如果直接查询zk地址，HBASE的设计目标是支持万亿级数据，zk根本存储不来。","user_name":"作者回复","comment_id":44778,"uid":"1007349","ip_address":"","utype":1,"ctime":1543677124,"user_name_real":"李智慧"}],"discussion_count":3,"race_medal":0,"score":"27313295095","product_id":100020201,"comment_content":"老师文中的读写都是通过HMaster获取HRegionServer的地址，再进行读写操作。怎么和我在其他地方学的不一样。不是应该通过zk查询的吗？","like_count":6,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":430831,"discussion_content":"zk查询哪个master是主master。\n\n如果直接查询zk地址，HBASE的设计目标是支持万亿级数据，zk根本存储不来。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1543677124,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1066752,"avatar":"https://static001.geekbang.org/account/avatar/00/10/47/00/3202bdf0.jpg","nickname":"piboye","note":"","ucode":"7CFD8712857A85","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":545576,"discussion_content":"region 信息是存储在 zk 还是 master 上？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1641996742,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1210519,"avatar":"https://static001.geekbang.org/account/avatar/00/12/78/97/fa101174.jpg","nickname":"年轻人","note":"","ucode":"CDD4612BAE3247","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1066752,"avatar":"https://static001.geekbang.org/account/avatar/00/10/47/00/3202bdf0.jpg","nickname":"piboye","note":"","ucode":"7CFD8712857A85","race_medal":0,"user_type":1,"is_pvip":true},"discussion":{"id":558654,"discussion_content":"我看到的信息应该是存储在zk的。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1648432550,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":545576,"ip_address":""},"score":558654,"extra":""}]}]},{"had_liked":false,"id":44817,"user_name":"足迹","can_delete":false,"product_type":"c1","uid":1105779,"ip_address":"","ucode":"38134D1A6B8DC2","user_header":"https://static001.geekbang.org/account/avatar/00/10/df/73/4a4ce2b5.jpg","comment_is_top":false,"comment_ctime":1543496014,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"23018332494","product_id":100020201,"comment_content":"hbase不支持二级索引，只能通过类似es这样的组件来实现。还是就是事务处理。所以一般oltp还是选择关系型数据库。","like_count":5},{"had_liked":false,"id":142323,"user_name":"simon","can_delete":false,"product_type":"c1","uid":1056668,"ip_address":"","ucode":"77F8D34328603D","user_header":"https://static001.geekbang.org/account/avatar/00/10/1f/9c/6e37e32b.jpg","comment_is_top":false,"comment_ctime":1571353356,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"14456255244","product_id":100020201,"comment_content":"hbase在hdfs之前，那是不是hbase的读写也是走hdfs的流程，先去namenode查询，再访问对应的datanode，如果是，那速度会不会很慢？如果不是，那其实没有完全用hdfs而只是简单利用hdfs相同的文件格式存储数据？","like_count":3},{"had_liked":false,"id":45106,"user_name":"姜戈","can_delete":false,"product_type":"c1","uid":1058972,"ip_address":"","ucode":"45C4BE93C8E4CC","user_header":"https://static001.geekbang.org/account/avatar/00/10/28/9c/73e76b19.jpg","comment_is_top":false,"comment_ctime":1543546759,"is_pvip":false,"replies":[{"id":"16225","content":"列族个数不会影响io","user_name":"作者回复","comment_id":45106,"uid":"1007349","ip_address":"","utype":1,"ctime":1543676210,"user_name_real":"李智慧"}],"discussion_count":1,"race_medal":0,"score":"14428448647","product_id":100020201,"comment_content":"针对问题：是不是列族不能太多，会影响IO","like_count":4,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":430923,"discussion_content":"列族个数不会影响io","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1543676210,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":44528,"user_name":"毛毛","can_delete":false,"product_type":"c1","uid":1249698,"ip_address":"","ucode":"AD520D0011227D","user_header":"https://static001.geekbang.org/account/avatar/00/13/11/a2/33be69a6.jpg","comment_is_top":false,"comment_ctime":1543455280,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"14428357168","product_id":100020201,"comment_content":"外行人强答一下。<br>我记得parquet文件的大小和列数有很大关系。如果可以随便增加列，文件会变得很大，增加的列可能包含的数据很少。<br>个人感觉这种可拓展性强的数据库更适合类似于电商的情况多变的业务。","like_count":3},{"had_liked":false,"id":44403,"user_name":"往事随风，顺其自然","can_delete":false,"product_type":"c1","uid":1235692,"ip_address":"","ucode":"F266EC6B143E38","user_header":"https://static001.geekbang.org/account/avatar/00/12/da/ec/779c1a78.jpg","comment_is_top":false,"comment_ctime":1543421958,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"14428323846","product_id":100020201,"comment_content":"LSM树的合并过程是咋样的，还有分区是怎么分的，存储到不同节点上","like_count":3},{"had_liked":false,"id":295291,"user_name":"Geek_6580e3","can_delete":false,"product_type":"c1","uid":2071189,"ip_address":"","ucode":"EBA5D606A268A5","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKrAnvnf7bm30wuzkns2eLt15libqTv5ardAAQZNx67NuHPzib0kVXaFHGHE7IE19IiargjtWJgC9D9g/132","comment_is_top":false,"comment_ctime":1622350456,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10212285048","product_id":100020201,"comment_content":"OLTP更适合mysql数据库，hbase只有在根据rowkey查询的时候效率才高，使用中需要借助es建立二级索引来加速","like_count":2},{"had_liked":false,"id":182528,"user_name":" 臣馟飞扬","can_delete":false,"product_type":"c1","uid":1116188,"ip_address":"","ucode":"F2F882B7678055","user_header":"https://static001.geekbang.org/account/avatar/00/11/08/1c/ef15e661.jpg","comment_is_top":false,"comment_ctime":1582803661,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"10172738253","product_id":100020201,"comment_content":"hadoop中已经存在hdfs了，应用程序读写直接跟hdfs交互就可以了，为什么还会再出现hbase呢？","like_count":2,"discussions":[{"author":{"id":2066849,"avatar":"https://static001.geekbang.org/account/avatar/00/1f/89/a1/2e2d6d0b.jpg","nickname":"莎思比亚","note":"","ucode":"71A9C184E9832C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":365366,"discussion_content":"hbase的核心是数据结构，也就是数据在存储前按什么结构存储，hdfs只是文件系统，最终的数据按内部结构编排后，以文件的方式存储在文件系统上","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1617783787,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1518310,"avatar":"https://static001.geekbang.org/account/avatar/00/17/2a/e6/c788257f.jpg","nickname":"geek_arong2048","note":"","ucode":"AB575BE100E4A9","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":399092,"discussion_content":"可以理解hbase为大数据存储+keyvalue存储的结合体","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1632905957,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":85408,"user_name":"Tomcat","can_delete":false,"product_type":"c1","uid":1346364,"ip_address":"","ucode":"B270CEED693256","user_header":"https://static001.geekbang.org/account/avatar/00/14/8b/3c/0462eca7.jpg","comment_is_top":false,"comment_ctime":1555054766,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10144989358","product_id":100020201,"comment_content":"批处理是对历史大量数据的离线计算处理，而流计算则是对实时流入的数据进行实时响应。<br><br>Storm模仿消息队列的处理方式，并进行了也许和技术的抽象，使得业务和技术分离，这是一种典型的架构设计方式。而且，storm 也采用了主从架构默契，很好的贯彻了分布式的典型思路。<br><br>Spark Stream 主要是使用了Spark Stream 的数据分段作用，如果在分片的时间足够短，那么数据就不会太大，然后将分段分片后的少量数据，提交给Spark 处理，就会在毫秒级得到结果。<br><br>Flink的主要思想则跟Spark 反过来，也就是说，在Flink的世界里，流是一等公民，而批处理只能退而其次。","like_count":2},{"had_liked":false,"id":45742,"user_name":"暴风雪","can_delete":false,"product_type":"c1","uid":1283139,"ip_address":"","ucode":"BF1523D69866FF","user_header":"https://static001.geekbang.org/account/avatar/00/13/94/43/46a7d0a8.jpg","comment_is_top":false,"comment_ctime":1543764822,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"10133699414","product_id":100020201,"comment_content":"根据老师的说法，LSM数据先是存储在内存中，当到达阈值的时候才会和磁盘合并（个人理解为序列化），当时如何保证断电的时候，内存中的数据会丢失的问题？","like_count":2,"discussions":[{"author":{"id":2066849,"avatar":"https://static001.geekbang.org/account/avatar/00/1f/89/a1/2e2d6d0b.jpg","nickname":"莎思比亚","note":"","ucode":"71A9C184E9832C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":365365,"discussion_content":"WAL(Write-Ahead log)机制保证数据不会丢失","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617783630,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":44488,"user_name":"胡家鹏","can_delete":false,"product_type":"c1","uid":1109940,"ip_address":"","ucode":"1636F84062948B","user_header":"https://static001.geekbang.org/account/avatar/00/10/ef/b4/61fb4dba.jpg","comment_is_top":false,"comment_ctime":1543453247,"is_pvip":true,"replies":[{"id":"16233","content":"拼写错误，尽快改正，谢谢纠正","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1543677341,"ip_address":"","comment_id":44488,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10133387839","product_id":100020201,"comment_content":"“HRegion 是 HBase 负责数据存储的主要进程，应用程序对数据的读写操作都是通过和 HRetion 通信完成。”没有看到HRetion","like_count":2,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":430774,"discussion_content":"拼写错误，尽快改正，谢谢纠正","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1543677341,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":251114,"user_name":"superMO潼","can_delete":false,"product_type":"c1","uid":1131414,"ip_address":"","ucode":"AEE2274BF75E44","user_header":"https://static001.geekbang.org/account/avatar/00/11/43/96/5bbfc853.jpg","comment_is_top":false,"comment_ctime":1601367734,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5896335030","product_id":100020201,"comment_content":"实际应用中，为了列的动态扩展，一张表是不是只有一个列族。如果有多个列族，难免有当前列族不能包含新列的含义，能否动态增加列族","like_count":1},{"had_liked":false,"id":48066,"user_name":"liin","can_delete":false,"product_type":"c1","uid":1038705,"ip_address":"","ucode":"92AE8958DDED4E","user_header":"https://static001.geekbang.org/account/avatar/00/0f/d9/71/8e38dc01.jpg","comment_is_top":false,"comment_ctime":1544339429,"is_pvip":true,"discussion_count":0,"race_medal":1,"score":"5839306725","product_id":100020201,"comment_content":"列族存储，对于复杂的条件查询、数据筛选支持不足。还有就是数据的分组聚合、求和等的操作。","like_count":1},{"had_liked":false,"id":46555,"user_name":"风中有个肉做的人","can_delete":false,"product_type":"c1","uid":1205160,"ip_address":"","ucode":"2E702EB457369A","user_header":"https://static001.geekbang.org/account/avatar/00/12/63/a8/013965d6.jpg","comment_is_top":false,"comment_ctime":1543935609,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5838902905","product_id":100020201,"comment_content":"传统业务还是使用关系数据库，列结构没啥使用经验，想想聚合计算不方便","like_count":1},{"had_liked":false,"id":45475,"user_name":"杰之7","can_delete":false,"product_type":"c1","uid":1297232,"ip_address":"","ucode":"F7DA2E21085332","user_header":"https://static001.geekbang.org/account/avatar/00/13/cb/50/66d0bd7f.jpg","comment_is_top":false,"comment_ctime":1543651323,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5838618619","product_id":100020201,"comment_content":"通过本节学习了代表NoSQL的Hbase,Hbase可通过HDFS分区对海量数据进行分布式存储，具有可伸缩的特性。同时，具有MySQL等关系数据库不具备的可拓展模型。Hbase通过LSM树结构满足高性能储存。最后，我认为关系数据库发展到今天依然是数据库的主流，具备了其他类型的数据库不具有的特征，所以NoSQL数据库是关系数据库的补充，而不是替代。","like_count":1},{"had_liked":false,"id":44964,"user_name":"多襄丸","can_delete":false,"product_type":"c1","uid":1074310,"ip_address":"","ucode":"1AA1497C5A293C","user_header":"https://static001.geekbang.org/account/avatar/00/10/64/86/f5a9403a.jpg","comment_is_top":false,"comment_ctime":1543535938,"is_pvip":false,"replies":[{"id":"16228","content":"hfile是一个hdfs文件，本身就分片后多个备份存储，不需要迁移。","user_name":"作者回复","user_name_real":"李智慧","uid":"1007349","ctime":1543676601,"ip_address":"","comment_id":44964,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5838503234","product_id":100020201,"comment_content":"一台HRegionServer上可以有多个HRegion实例。<br><br>那请问：<br>1.一台HRegion 上 有多少个HFile啊？<br>2.HFile随着HRegion的迁移而迁移，意思是像HDFS的分片数据一样，复制在其他Data Node节点上一样，复制在其他HRegionServer上的HRegion上吗？<br><br>老师可以简单解释一下嘛？<br><br>","like_count":1,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":430880,"discussion_content":"hfile是一个hdfs文件，本身就分片后多个备份存储，不需要迁移。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1543676601,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":44766,"user_name":"Q_x H!","can_delete":false,"product_type":"c1","uid":1117900,"ip_address":"","ucode":"A5388D4DD50557","user_header":"https://static001.geekbang.org/account/avatar/00/11/0e/cc/766a0e62.jpg","comment_is_top":false,"comment_ctime":1543488273,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"5838455569","product_id":100020201,"comment_content":"我也想知道lsm树是怎么合并的","like_count":1,"discussions":[{"author":{"id":1046584,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/f8/38/8af56e18.jpg","nickname":"知识没学到","note":"","ucode":"5D819DFFC7AB08","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":362946,"discussion_content":"推荐“检索技术核心20讲”~ https://time.geekbang.org/column/article/222768","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617078299,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":44763,"user_name":"纯洁的憎恶","can_delete":false,"product_type":"c1","uid":1130512,"ip_address":"","ucode":"5E9757DE6F45DF","user_header":"https://static001.geekbang.org/account/avatar/00/11/40/10/b6bf3c3c.jpg","comment_is_top":false,"comment_ctime":1543488039,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"5838455335","product_id":100020201,"comment_content":"列族的思路和LMS树没看懂","like_count":1},{"had_liked":false,"id":44690,"user_name":"Albert","can_delete":false,"product_type":"c1","uid":1047406,"ip_address":"","ucode":"F38347B2F33BF8","user_header":"https://static001.geekbang.org/account/avatar/00/0f/fb/6e/c10b9c25.jpg","comment_is_top":false,"comment_ctime":1543476432,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5838443728","product_id":100020201,"comment_content":"HBase只能通过key操作数据，不像关系数据库那么灵活，所以需要根据应用程序怎样去操作数据来设计表；字段是以key-value形式存储的，key应该会存在大量冗余","like_count":1},{"had_liked":false,"id":44457,"user_name":"Li Shunduo","can_delete":false,"product_type":"c1","uid":1222882,"ip_address":"","ucode":"6C5AB4129E9780","user_header":"https://static001.geekbang.org/account/avatar/00/12/a8/e2/f8e51df2.jpg","comment_is_top":false,"comment_ctime":1543451483,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5838418779","product_id":100020201,"comment_content":"HBase的一个缺点是非key列的查找没有索引支持，非常慢。","like_count":1},{"had_liked":false,"id":343212,"user_name":"冯仁彬","can_delete":false,"product_type":"c1","uid":2960877,"ip_address":"","ucode":"6E5CA08BC6366B","user_header":"","comment_is_top":false,"comment_ctime":1650709295,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1650709295","product_id":100020201,"comment_content":"HBase从物理上看实际上是一个KV结构的数据库，使用Map结构，当然不是一个普通的Map，而是一个“多维稀疏排序”的Map，其中key是由rowkey+column+type+timestamp组成的","like_count":0},{"had_liked":false,"id":338811,"user_name":"长期规划","can_delete":false,"product_type":"c1","uid":1019332,"ip_address":"","ucode":"5EF65E9115834B","user_header":"https://static001.geekbang.org/account/avatar/00/0f/8d/c4/6f97daea.jpg","comment_is_top":false,"comment_ctime":1647747739,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1647747739","product_id":100020201,"comment_content":"提高了写性能，使用追加方式，弱化了读（查询）性能，不支持二级索引，只能rowkey。需借助ES建二级索引","like_count":0},{"had_liked":false,"id":330494,"user_name":"piboye","can_delete":false,"product_type":"c1","uid":1066752,"ip_address":"","ucode":"7CFD8712857A85","user_header":"https://static001.geekbang.org/account/avatar/00/10/47/00/3202bdf0.jpg","comment_is_top":false,"comment_ctime":1641996858,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1641996858","product_id":100020201,"comment_content":"hregion 信息的高可靠是怎么保障的？ 这里可以细说吗？","like_count":0},{"had_liked":false,"id":312104,"user_name":"钱鹏 Allen","can_delete":false,"product_type":"c1","uid":2518863,"ip_address":"","ucode":"7E95E82C0717DA","user_header":"https://static001.geekbang.org/account/avatar/00/26/6f/4f/3cf1e9c4.jpg","comment_is_top":false,"comment_ctime":1631626583,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1631626583","product_id":100020201,"comment_content":"可能会产生关键的信息缺失和重复。当需要结构化的存储时，需要使用关系类数据库。","like_count":0},{"had_liked":false,"id":290490,"user_name":"BBQ","can_delete":false,"product_type":"c1","uid":1656804,"ip_address":"","ucode":"683BBF7F7AE370","user_header":"https://static001.geekbang.org/account/avatar/00/19/47/e4/17cb3df1.jpg","comment_is_top":false,"comment_ctime":1619588827,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1619588827","product_id":100020201,"comment_content":"在需要数据强一致性的场景，还是要用RDBMS，通过ACID 和事务来保证强一致性，比如涉及到金融数据时。","like_count":0},{"had_liked":false,"id":288283,"user_name":"karl chow","can_delete":false,"product_type":"c1","uid":1878903,"ip_address":"","ucode":"E5FC3487343C21","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLoTUo5Lse2svDzhXW0blun2jHvXrdWVcibOk0ffJWhU5KAE5Zn20oatr23hWgf8TTaSWCaXeOEib5g/132","comment_is_top":false,"comment_ctime":1618391719,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1618391719","product_id":100020201,"comment_content":"感觉是nosql的通用缺点，联合查询很麻烦","like_count":0},{"had_liked":false,"id":279249,"user_name":"eden","can_delete":false,"product_type":"c1","uid":1907540,"ip_address":"","ucode":"CF8F33380D2C4D","user_header":"https://static001.geekbang.org/account/avatar/00/1d/1b/54/c0f328ab.jpg","comment_is_top":false,"comment_ctime":1613695457,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1613695457","product_id":100020201,"comment_content":"请教一下老师：我看key应该就是主键，然后value这块应该是每一列一个；那这个HRegionServer是不是就是每一个或者两个server对应管理一个列字段的value；这样组成的？","like_count":0},{"had_liked":false,"id":269922,"user_name":"刘江","can_delete":false,"product_type":"c1","uid":2369389,"ip_address":"","ucode":"3E31A2D41C7106","user_header":"https://static001.geekbang.org/account/avatar/00/24/27/6d/2f24cfbe.jpg","comment_is_top":false,"comment_ctime":1608857167,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1608857167","product_id":100020201,"comment_content":"面向列族存储的话，如果我需要查找整个rowkey的数据就会很很慢，因为需要去访问去多个文件","like_count":0},{"had_liked":false,"id":193600,"user_name":"不记年","can_delete":false,"product_type":"c1","uid":1045945,"ip_address":"","ucode":"287E40C68356DC","user_header":"https://static001.geekbang.org/account/avatar/00/0f/f5/b9/888fe350.jpg","comment_is_top":false,"comment_ctime":1584932255,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1584932255","product_id":100020201,"comment_content":"不适合OLAP场景<br>粒度太粗，增加开发负担<br><br>可以采用HIVE作为操作HBase的客户端<br>","like_count":0},{"had_liked":false,"id":188353,"user_name":"Geek_76616d","can_delete":false,"product_type":"c1","uid":1744992,"ip_address":"","ucode":"809765A24C4E70","user_header":"","comment_is_top":false,"comment_ctime":1584344073,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1584344073","product_id":100020201,"comment_content":"列组查询有很多情况","like_count":0},{"had_liked":false,"id":181769,"user_name":"学技术攒钱开宠物店","can_delete":false,"product_type":"c1","uid":1849036,"ip_address":"","ucode":"3EA297FD4C9635","user_header":"https://static001.geekbang.org/account/avatar/00/1c/36/cc/499625d3.jpg","comment_is_top":false,"comment_ctime":1582631730,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1582631730","product_id":100020201,"comment_content":"感觉rowkey的设计比较关键，设计不合理容易导致数据倾斜。","like_count":0},{"had_liked":false,"id":173348,"user_name":"jun.hai","can_delete":false,"product_type":"c1","uid":1702947,"ip_address":"","ucode":"9740C5118DE6DC","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epx1w8VkC30tcu4GlOCkUZB7picI2xesBBZF3rGWVPp9tHZfJdkc5iaqhSg7LOsvtefiajkM1YPno2JA/132","comment_is_top":false,"comment_ctime":1579508796,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1579508796","product_id":100020201,"comment_content":"1.Mysql为关系型数据库，行存储，面向OLTP，支持事务和索引，有事务性要求的场景下选用Mysql，数据量增大到海量时结合业务场景，历史数据可以写入到NoSQL数据库上；<br>2.HBase为列式存储，面向OLAP，用了LSM数据结构高性能存储，海量数据的支持，缺点为不支持事务，不适合事务性强的业务场景；<br>以上为我的理解，请老师指正～","like_count":0},{"had_liked":false,"id":142327,"user_name":"simon","can_delete":false,"product_type":"c1","uid":1056668,"ip_address":"","ucode":"77F8D34328603D","user_header":"https://static001.geekbang.org/account/avatar/00/10/1f/9c/6e37e32b.jpg","comment_is_top":false,"comment_ctime":1571353949,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1571353949","product_id":100020201,"comment_content":"lsm树每个节点的内容是数据本身，还是一个数据的指引？日志是记录在硬盘，lsm树是记录在内存，对吗？另外在找数据的过程，遍历整颗树，跟寻址的优势？谢谢老师解答","like_count":0},{"had_liked":false,"id":137202,"user_name":"钱","can_delete":false,"product_type":"c1","uid":1009652,"ip_address":"","ucode":"2C92A243A463D4","user_header":"https://static001.geekbang.org/account/avatar/00/0f/67/f4/9a1feb59.jpg","comment_is_top":false,"comment_ctime":1569648571,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1569648571","product_id":100020201,"comment_content":"课后思考及问题<br>1：按 Key 的区域进行分片？redis的分片方式是solt=crc16(key)%16384 先定位到槽位再定位到具体的分片。HBase具体是怎么按key的区域来进行分片的？<br>2：列族的设计具体是怎么样的？比如：有一个列族的名称是lz，在添加数据时指定列字段，并以kv的形式存储，假如，我要增加name和age两列，那key就是lz:name-zhihui lz:age-18这样子吗？<br>","like_count":0},{"had_liked":false,"id":132909,"user_name":"aof","can_delete":false,"product_type":"c1","uid":1062864,"ip_address":"","ucode":"5815D63C4926BC","user_header":"https://static001.geekbang.org/account/avatar/00/10/37/d0/26975fba.jpg","comment_is_top":false,"comment_ctime":1568272113,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1568272113","product_id":100020201,"comment_content":"老师这句话具体该怎么理解？——“当数据量超过设定的内存阈值后，会将这棵排序树和磁盘上最新的排序树合并。”","like_count":0},{"had_liked":false,"id":86986,"user_name":"王建","can_delete":false,"product_type":"c1","uid":1153792,"ip_address":"","ucode":"68000818D8AA41","user_header":"https://static001.geekbang.org/account/avatar/00/11/9b/00/8c1b9631.jpg","comment_is_top":false,"comment_ctime":1555492464,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1555492464","product_id":100020201,"comment_content":"HRegionServer 是物理服务器，每个 HRegionServer 上可以启动多个 HRegion 实例。当一个 HRegion 中写入的数据太多，达到配置的阈值时，一个 HRegion 会分裂成两个 HRegion，并将 HRegion 在整个集群中进行迁移，以使 HRegionServer 的负载均衡。<br><br>疑问:region是谁在管理","like_count":0},{"had_liked":false,"id":86983,"user_name":"王建","can_delete":false,"product_type":"c1","uid":1153792,"ip_address":"","ucode":"68000818D8AA41","user_header":"https://static001.geekbang.org/account/avatar/00/11/9b/00/8c1b9631.jpg","comment_is_top":false,"comment_ctime":1555492189,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1555492189","product_id":100020201,"comment_content":"HRegionServer  Hregion  region的逻辑关系和物理关系没有搞懂，请解答下","like_count":0},{"had_liked":false,"id":86979,"user_name":"王建","can_delete":false,"product_type":"c1","uid":1153792,"ip_address":"","ucode":"68000818D8AA41","user_header":"https://static001.geekbang.org/account/avatar/00/11/9b/00/8c1b9631.jpg","comment_is_top":false,"comment_ctime":1555491806,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1555491806","product_id":100020201,"comment_content":"HRegionServer是物理机，还是region的管理者？或者说hmaster才是region的管理者，网上说HRegionServer管理的个数需要根据内存计算，中间的关系搞不清楚了_(:з」∠)_","like_count":0},{"had_liked":false,"id":71815,"user_name":"张飞","can_delete":false,"product_type":"c1","uid":1405598,"ip_address":"","ucode":"836F612B8E9C8A","user_header":"https://static001.geekbang.org/account/avatar/00/15/72/9e/69606254.jpg","comment_is_top":false,"comment_ctime":1551441619,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1551441619","product_id":100020201,"comment_content":"1.HBase的lsm结构决定在磁盘上的文件可能是多个排序树，相比关系型数据库单个排序树的结构查找性能低，当然内存中的数据读取会很快<br>2. 当需要某个用户的所有信息时，即按行查询效率低<br>3. 以key value的形式存储，即每个value （列）的存储都要保存该用户的key，有大量的列就导致有大量的冗余信息存储<br>4. 在做文件合并时的性能相比不合并时性能差很多，需要合理控制文件合并的频率及时间<br>5. key value的形式也导致了只能按key查找，对字段匹配的查询可能有问题（推测）<br>6. 对于数据分析的场景，个人觉得也不合适<br><br>如果以上理解有错误，还请老师指正，或者给予补充。","like_count":0},{"had_liked":false,"id":68757,"user_name":"小谢同学","can_delete":false,"product_type":"c1","uid":1032544,"ip_address":"","ucode":"E809E6BC470631","user_header":"https://static001.geekbang.org/account/avatar/00/0f/c1/60/fc3689d0.jpg","comment_is_top":false,"comment_ctime":1550593469,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1550593469","product_id":100020201,"comment_content":"请问老师hbase和Cassandra 的主要区别在哪里？","like_count":0},{"had_liked":false,"id":64949,"user_name":"Lev","can_delete":false,"product_type":"c1","uid":1086394,"ip_address":"","ucode":"30FAB27A6C7EE7","user_header":"https://static001.geekbang.org/account/avatar/00/10/93/ba/45d127b8.jpg","comment_is_top":false,"comment_ctime":1548983402,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1548983402","product_id":100020201,"comment_content":"老师，列族数据是一个同性质列存储在一个LSM数吗？LSM树的最小节点是&lt;key,value&gt;吗？<br>比如有多列A-Z,<br>hbase是怎么知道该去哪个LSM树找B列和Z列的，谢谢。","like_count":0},{"had_liked":false,"id":62163,"user_name":"eldon","can_delete":false,"product_type":"c1","uid":1368116,"ip_address":"","ucode":"3165FDE0FACB9A","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLeKdLZTWmcxDE7AUnM90naTbDzynshqzILrQAweQXicGgvdg1gImWxeZabiay9LVLsnOCfjj2nZaBA/132","comment_is_top":false,"comment_ctime":1547965752,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1547965752","product_id":100020201,"comment_content":"NoSQL缺点:许多更多的业余业务来调用数据","like_count":0},{"had_liked":false,"id":61439,"user_name":"小老鼠","can_delete":false,"product_type":"c1","uid":1257460,"ip_address":"","ucode":"C663A0C863A515","user_header":"https://static001.geekbang.org/account/avatar/00/13/2f/f4/2dede51a.jpg","comment_is_top":false,"comment_ctime":1547698501,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1547698501","product_id":100020201,"comment_content":"NoSQL容易造成数据冗余与不一致性吧？","like_count":0},{"had_liked":false,"id":56310,"user_name":"RayBan","can_delete":false,"product_type":"c1","uid":1344666,"ip_address":"","ucode":"CEE82B170CA320","user_header":"https://static001.geekbang.org/account/avatar/00/14/84/9a/a83ec31d.jpg","comment_is_top":false,"comment_ctime":1546419513,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1546419513","product_id":100020201,"comment_content":"单一RowKey决定了Hbase不支持多条件查询的弊端","like_count":0},{"had_liked":false,"id":51198,"user_name":"ming","can_delete":false,"product_type":"c1","uid":1054341,"ip_address":"","ucode":"63135A86598E64","user_header":"https://static001.geekbang.org/account/avatar/00/10/16/85/e4d53282.jpg","comment_is_top":false,"comment_ctime":1545132742,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1545132742","product_id":100020201,"comment_content":"列族设计没有约束，如果开发的人很多他们对同一个字段没有约定好，就容易导致不同的开发者用了不同的字段名去表示同一个字段，数据就乱。","like_count":0},{"had_liked":false,"id":51179,"user_name":"Sam.张朝","can_delete":false,"product_type":"c1","uid":1132448,"ip_address":"","ucode":"FB20554D94B250","user_header":"https://static001.geekbang.org/account/avatar/00/11/47/a0/f12115b7.jpg","comment_is_top":false,"comment_ctime":1545126361,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1545126361","product_id":100020201,"comment_content":"成熟的框架怎么会不考虑断电情况呢？哈哈哈","like_count":0},{"had_liked":false,"id":49525,"user_name":"ming","can_delete":false,"product_type":"c1","uid":1054341,"ip_address":"","ucode":"63135A86598E64","user_header":"https://static001.geekbang.org/account/avatar/00/10/16/85/e4d53282.jpg","comment_is_top":false,"comment_ctime":1544705743,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1544705743","product_id":100020201,"comment_content":"非大数据量的信息系统都应该使用关系型数据库。数据改动频繁的系统也应该使用关系型数据库。","like_count":0},{"had_liked":false,"id":48202,"user_name":"scorpiozj","can_delete":false,"product_type":"c1","uid":1031677,"ip_address":"","ucode":"C66EA76809F9BF","user_header":"https://static001.geekbang.org/account/avatar/00/0f/bd/fd/3f5d5db5.jpg","comment_is_top":false,"comment_ctime":1544402115,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1544402115","product_id":100020201,"comment_content":"我也想到了不好查询 如查询列族中某些key的情形","like_count":0},{"had_liked":false,"id":47154,"user_name":"小千","can_delete":false,"product_type":"c1","uid":1280968,"ip_address":"","ucode":"BF12E4ABD69FA8","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKPBiaSZVibZwoUEUcvbF4JCfOghmvPdUfbFHeDd2g5m6NbuzeN3S3b7KxZCA8FmtrH9N51Z5P177iaA/132","comment_is_top":false,"comment_ctime":1544064797,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1544064797","product_id":100020201,"comment_content":"hbase这样的列族没法像传统数据库那样做约束吧，存储的数据准确性要比传统数据库差","like_count":0},{"had_liked":false,"id":45788,"user_name":"！null","can_delete":false,"product_type":"c1","uid":1242483,"ip_address":"","ucode":"4E5B7922980397","user_header":"https://static001.geekbang.org/account/avatar/00/12/f5/73/f7d3a996.jpg","comment_is_top":false,"comment_ctime":1543796743,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1543796743","product_id":100020201,"comment_content":"每次输入key和value，会不会出现描述同一属性用不同的key完成？比如，用户名用id和username？","like_count":0},{"had_liked":false,"id":45179,"user_name":"🐱您的好友William🐱","can_delete":false,"product_type":"c1","uid":1215456,"ip_address":"","ucode":"427786DB178965","user_header":"https://static001.geekbang.org/account/avatar/00/12/8b/e0/9a79ddac.jpg","comment_is_top":false,"comment_ctime":1543556982,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1543556982","product_id":100020201,"comment_content":"我能想到的是，可能做不了事务隔离，同时加不了索引可能在一些场景下有束缚（刚开始学极客时间的MySQL专栏，哈哈）","like_count":0},{"had_liked":false,"id":45105,"user_name":"姜戈","can_delete":false,"product_type":"c1","uid":1058972,"ip_address":"","ucode":"45C4BE93C8E4CC","user_header":"https://static001.geekbang.org/account/avatar/00/10/28/9c/73e76b19.jpg","comment_is_top":false,"comment_ctime":1543546698,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1543546698","product_id":100020201,"comment_content":"最近买了老师2013出版的大型网站技术架构这本书，发现不少内容关于大数据的，就感觉自己OUT了，还差一个月就2019年了，在6年前这块就已然成为大家熟悉了解的知识；但同样庆幸的是，这块知识原理几乎没什么大变化...","like_count":0},{"had_liked":false,"id":45003,"user_name":"Mcnulty","can_delete":false,"product_type":"c1","uid":1143536,"ip_address":"","ucode":"3DD71D84B58A16","user_header":"https://static001.geekbang.org/account/avatar/00/11/72/f0/abb7bfe3.jpg","comment_is_top":false,"comment_ctime":1543538908,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1543538908","product_id":100020201,"comment_content":"将数据读写操作提交给 HRegion，由 HRegion 完成存储层面的数据操作。HRegion 操作HDFS中的Hfile ，那么Hfile是怎么和内存或者物理树交互的呢？","like_count":0},{"had_liked":false,"id":44663,"user_name":"蚂蚁内推+v","can_delete":false,"product_type":"c1","uid":1050508,"ip_address":"","ucode":"24B10AEE54B3FD","user_header":"https://static001.geekbang.org/account/avatar/00/10/07/8c/0d886dcc.jpg","comment_is_top":false,"comment_ctime":1543471902,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1543471902","product_id":100020201,"comment_content":"1.列族可以理解成，一个大列（列中就是用 多个map《key,value》存储吗）<br>2LSM 树那块没理解清楚，老师可以稍微详细说下嘛","like_count":0},{"had_liked":false,"id":44620,"user_name":"梁中华","can_delete":false,"product_type":"c1","uid":1006789,"ip_address":"","ucode":"52FE40242CBAD0","user_header":"https://static001.geekbang.org/account/avatar/00/0f/5c/c5/1231d633.jpg","comment_is_top":false,"comment_ctime":1543464643,"is_pvip":true,"discussion_count":1,"race_medal":1,"score":"1543464643","product_id":100020201,"comment_content":"有个问题没搞明白，连续写磁盘的Log好内存中的LSM 是什么关系？文中没看到这个log 的作用，是做异常恢复用的？","like_count":0,"discussions":[{"author":{"id":1046584,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/f8/38/8af56e18.jpg","nickname":"知识没学到","note":"","ucode":"5D819DFFC7AB08","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":362949,"discussion_content":"预写日志WAL","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617078383,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}