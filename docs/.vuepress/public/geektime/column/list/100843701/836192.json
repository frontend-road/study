{"id":836192,"title":"08｜并发map：百万数据本地缓存，如何降延时减毛刺？","content":"<p>你好，我是徐逸。</p><p>在上节课的内容中，我们一起学习了锁和无锁编程技术，还使用分段锁和map类型，实现了一个缓存结构。不过，值得留意的是，其实 Go 语言的 sync 包已经提供了一种并发安全的 Map 类型。</p><p>今天，我就以大规模数据缓存的数据结构设计要点为例，带你掌握sync.Map类型以及针对map的GC优化技巧。</p><p>假如我们现在需要实现一个key-value类型的本地缓存，且缓存的key特别多，达到百万甚至千万级别，那么我们该怎么设计，才能在并发环境下高性能、安全地访问这个缓存呢？</p><p>针对大规模数据缓存的场景，我们在数据结构设计上要考虑的技术点有两个。</p><ol>\n<li>如何实现并发安全的map类型。</li>\n<li>如何减少甚至避免因大规模数据缓存导致的GC开销。</li>\n</ol><h2>并发map选择</h2><p>实际上，大规模且有读写操作的数据缓存，咱们可以考虑的map类型有两种，一个是分段锁实现的map类型，另一个是sync包提供的Map类型。</p><p>那么我们到底该选择哪个呢？</p><p>在选型之前，我们需要先掌握sync.Map类型的基础知识和原理。</p><p>sync.Map是 Go 语言sync包中提供的一个内置的并发安全的map类型。它在设计上考虑了高并发场景，尽量避免加锁操作从而提升读写性能。</p><p>sync.Map该如何使用呢？下面我给了一段简单的代码，这段代码使用了sync.Map提供的Store、Load和Delete方法，分别用于写、读和删除操作。</p><!-- [[[read_end]]] --><pre><code class=\"language-go\">package main\n\nimport (\n    \"fmt\"\n    \"sync\"\n)\n\nfunc main() {\n    var m sync.Map\n    m.Store(\"key1\", \"value1\")\n    m.Store(\"key2\", 2)\n    value, ok := m.Load(\"key1\")\n    if ok {\n        fmt.Println(\"Value:\", value)\n    }\n    m.Delete(\"key1\")\n    value, ok = m.Load(\"key1\")\n    if ok {\n        fmt.Println(\"Value:\", value)\n    } else {\n        fmt.Println(\"Key not found\")\n    }\n}\n</code></pre><p>sync.Map是如何实现并发高性能操作的呢？</p><p>首先，我们来看下sync.Map的底层数据结构，它的核心是read和dirty两个map结构。read存储了部分写入Map的内容，用来加速读操作。而dirty存储了全量内容，需要加锁才能读写数据。</p><pre><code class=\"language-go\">type Map struct {\n    mu Mutex\n    read atomic.Pointer[readOnly] // 无锁读map\n    dirty map[any]*entry // 加锁读写map\n    misses int\n}\n\n// readOnly is an immutable struct stored atomically in the Map.read field.\ntype readOnly struct {\n    m       map[any]*entry\n    amended bool // true if the dirty map contains some key not in m.\n}\n</code></pre><p>接着，让我们来看下写入操作。当有key-value值写入时，如果这个key在read中不存在，接下来就要做新增操作，它会加锁写入dirty map中，并且将amended标记设置为true。而amended标记用于表示dirty中是否有不在read中的key-value值。</p><p>这个操作过程你可以结合后面的示意图看一下，这样理解起来更直观。</p><p><img src=\"https://static001.geekbang.org/resource/image/ey/7d/eyybed76bbdd94d0d86057dd02ab3b7d.jpg?wh=2900x1683\" alt=\"\" title=\"图1 key-value 写入\"></p><p>如果这个key在read中存在，则会进行更新操作，由于read map和dirty map里面存储的值是entry类型的指针，且entry类型的成员变量也是atomic.Pointer类型（如后面代码所示）。</p><pre><code class=\"language-go\">// An entry is a slot in the map corresponding to a particular key.\ntype entry struct {\n    p atomic.Pointer[any]\n}\n</code></pre><p>因此在更新时就像下面的图那样，可以直接用CAS无锁操作替换指针p指向的变量，而无需做加锁操作。</p><p><img src=\"https://static001.geekbang.org/resource/image/28/6b/2818fca6cdc5aeeb89111640a52c616b.jpg?wh=2800x1239\" alt=\"\" title=\"图2 value 更新\"></p><p>然后，让我们来看看读取操作，我们还是结合具体代码来理解。</p><pre><code class=\"language-go\">// Load returns the value stored in the map for a key, or nil if no\n// value is present.\n// The ok result indicates whether value was found in the map.\nfunc (m *Map) Load(key any) (value any, ok bool) {\n    read := m.loadReadOnly()\n    e, ok := read.m[key]\n    if !ok &amp;&amp; read.amended {\n        m.mu.Lock()\n        // Avoid reporting a spurious miss if m.dirty got promoted while we were\n        // blocked on m.mu. (If further loads of the same key will not miss, it's\n        // not worth copying the dirty map for this key.)\n        read = m.loadReadOnly()\n        e, ok = read.m[key]\n        if !ok &amp;&amp; read.amended {\n            e, ok = m.dirty[key]\n            // Regardless of whether the entry was present, record a miss: this key\n            // will take the slow path until the dirty map is promoted to the read\n            // map.\n            m.missLocked()\n        }\n        m.mu.Unlock()\n    }\n    if !ok {\n        return nil, false\n    }\n    return e.load()\n}\n</code></pre><p>当读取key对应的值时，会先从read中读取，当read中读不到，并且amended为true时，则会加锁从dirty map中读。<strong>这里可能导致从sync.Map读取的性能劣化，因为它既要从read中读一遍，又要加锁从dirty map中读一遍。</strong></p><p><img src=\"https://static001.geekbang.org/resource/image/2f/f5/2f59ace16127a243ebc620d9b4d78cf5.jpg?wh=2900x1857\" alt=\"\" title=\"图3 读 Key 数据\"></p><p>同时，每次read读不到，从dirty map中读时，它会调用missLocked方法，这个方法用于将map的misses字段加1，misses字段用于表示read读未命中次数，如果misses值比较大，说明read map的数据可能比dirty map少了很多。为了提升读性能，missLocked方法里会将dirty map变成新的read map，代码如下。</p><pre><code class=\"language-go\">func (m *Map) missLocked() {\n    m.misses++\n    if m.misses &lt; len(m.dirty) {\n        return\n    }\n    m.read.Store(&amp;readOnly{m: m.dirty})\n    m.dirty = nil\n    m.misses = 0\n}\n</code></pre><p><img src=\"https://static001.geekbang.org/resource/image/3b/fe/3bd3484c3532bfa5e7108280b23e52fe.jpg?wh=2653x1688\" alt=\"\" title=\"图4 dirty 切换为 read\"></p><p>最后，让我们来看看另一个可能导致写入sync.Map的性能劣化的点。上面的missLocked方法，会将dirty map置为nil，当有新的key-value值写入时，为了能保持dirty map有全量数据，就像下面代码的swap方法，它会加锁并且调用dirtyLocked方法，遍历read map并全量赋值拷贝给dirty map。</p><p>你可以看看后面的代码，再想想这样写会不会有什么问题？</p><pre><code class=\"language-go\">// Swap swaps the value for a key and returns the previous value if any.\n// The loaded result reports whether the key was present.\nfunc (m *Map) Swap(key, value any) (previous any, loaded bool) {\n    ...\n    m.mu.Lock()\n    if !read.amended {\n        // We're adding the first new key to the dirty map.\n        // Make sure it is allocated and mark the read-only map as incomplete.\n        m.dirtyLocked()\n        m.read.Store(&amp;readOnly{m: read.m, amended: true})\n    }\n    m.dirty[key] = newEntry(value)\n    m.mu.Unlock()\n    return previous, loaded\n}\n\nfunc (m *Map) dirtyLocked() {\n    if m.dirty != nil {\n        return\n    }\n    // read map全量复制到dirty\n    read := m.loadReadOnly()\n    m.dirty = make(map[any]*entry, len(read.m))\n    for k, e := range read.m {\n        if !e.tryExpungeLocked() {\n            m.dirty[k] = e\n        }\n    }\n}\n</code></pre><p>不知道你有没有发现？当数据量比较大时，这样会导致大量数据的拷贝，性能会劣化严重。比如我们缓存几百万条数据，就存在几百万条数据的赋值拷贝。</p><p>通过上面sync.Map的原理分析，我们可以看出，sync.Map是通过两个map来实现读写分离，从而达到高性能读的目的。不过它存在下面几个缺点。</p><ol>\n<li>由于有两个map，因此占用内存会比较高。</li>\n<li>更适用于读多写少的场景，当由于写比较多或者本地缓存没有全量数据时，会导致读map经常读不到数据，而需要加锁再读一次，从而导致读性能退化。</li>\n<li>当数据量比较大时，如果写入触发读map向写map拷贝，会导致较大的性能开销。</li>\n</ol><p>可以看出来，sync.Map的使用场景还是比较苛刻的。</p><p>那回到刚开始的问题，在大规模数据缓存时，我们是该选择分段锁实现的map还是sync.Map类型来缓存数据呢？</p><p>答案是分段锁map。原因是我们很难准确地预估读写比例，而且读写比例也会随着业务的发展变化。此外，在大规模数据缓存时，两个map的内存和拷贝开销也是不得不考虑的稳定性风险点，因此在大规模数据缓存时，我们一般使用分段锁实现的map来缓存数据。</p><h2>map gc优化</h2><p>在做了并发map的选型之后，我们还需要考虑的一点是在缓存大量数据时，如何避免GC导致的性能开销。</p><p>我以下面的代码为例，分别测试key、value为string类型的map在不同数据规模下的GC开销。</p><pre><code class=\"language-go\">import (\n    \"fmt\"\n    \"runtime\"\n    \"testing\"\n    \"time\"\n)\n\n// Test1kGCDuration 测试小规模数据gc时长\nfunc Test1kGCDuration(t *testing.T) {\n    size := 1000\n    m := GenerateStringMap(size)\n    runtime.GC()\n    gcCost := timeGC()\n    t.Logf(\"size %d GC duration: %v\\n\", size, gcCost)\n    _ = m[\"1\"]\n}\n\n// 测试大规模数据gc时长\nfunc Test500wGCDuration(t *testing.T) {\n    size := 5000000\n    m := GenerateStringMap(size)\n    runtime.GC()\n    gcCost := timeGC()\n    t.Logf(\"size %d GC duration: %v\\n\", size, gcCost)\n    _ = m[\"1\"]\n}\nfunc GenerateStringMap(size int) map[string]string {\n    // 在这里执行一些可能会触发GC的操作，例如创建大量对象等\n    // 以下示例创建一个较大的map并填充数据\n    m := make(map[string]string)\n    for i := 0; i &lt; size; i++ {\n        key := fmt.Sprintf(\"key_%d\", i)\n        value := fmt.Sprintf(\"val_%d\", i)\n        m[key] = value\n\n    }\n    return m\n}\n\nfunc timeGC() time.Duration {\n    // 记录GC开始时间\n    gcStartTime := time.Now()\n    // 手动触发GC，以便更准确地测量此次操作相关的GC时长\n    runtime.GC()\n\n    // 计算总的GC时长\n    gcCost := time.Since(gcStartTime)\n    return gcCost\n}\n</code></pre><p>测试结果出来了，<strong>map中储存1k条数据和500w条数据的GC耗时差异巨大</strong>。500w条数据，GC耗时290ms，而1k条数据耗时只需要480µs，有600倍的性能差异。</p><pre><code class=\"language-shell\">killianxu@KILLIANXU-MB0 8 % go test -gcflags=all=-l gc_size_test.go -v\n=== RUN   Test1kGCDuration\n    gc_size_test.go:16: size 1000 GC duration: 480.718µs\n--- PASS: Test1kGCDuration (0.00s)\n=== RUN   Test500wGCDuration\n    gc_size_test.go:26: size 5000000 GC duration: 290.422382ms\n--- PASS: Test500wGCDuration (5.12s)\n</code></pre><p>那么在大规模数据缓存下，GC为什么耗时会这么长呢？</p><p>这是因为GC在做对象扫描标记时，需要扫描标记map里面的全量key-value对象，数据越多，需要扫描的对象越多，GC时间也就越长。</p><p>扫描标记的耗时过长，会引发一系列不良影响。它不仅会大量消耗 CPU 资源，降低服务吞吐，而且在标记工作未能及时完成的情况下，GC 会要求处理请求的协程暂停手头的业务逻辑处理流程，转而协助 GC 开展标记任务。这样一来，部分请求的响应延时将会不可避免地大幅升高，严重影响系统的响应效率与性能表现。</p><p>为了避免GC对程序性能造成影响，对于map类型，Golang在 <a href=\"https://go-review.googlesource.com/c/go/+/3288\">1.5版本</a>提供了一种绕过GC扫描的方法。绕过GC要满足下面两个条件。</p><p><strong>第一，map的key-value类型不能是指针类型且内部不能包含指针</strong>。比如string类型，它的底层数据结构中有指向数组的指针，因此不满足这个条件。</p><pre><code class=\"language-go\">// 字符串数据结构\ntype stringStruct struct {\n    str unsafe.Pointer //指针类型，指向字节数组\n    len int\n}\n</code></pre><p>那到底不含指针类型，能不能缩短GC开销呢？咱们将代码里map的key-value类型换成int类型再试一下。</p><pre><code class=\"language-go\">// 测试key-value非指针类型,int的gc开销\nfunc Test500wIntGCDuration(t *testing.T) {\n    size := 5000000\n    m := GenerateIntMap(size)\n    runtime.GC()\n    gcCost := timeGC()\n    t.Logf(\"size %d GC duration: %v\\n\", size, gcCost)\n    _ = m[1]\n}\nfunc GenerateIntMap(size int) map[int]int {\n    // 在这里执行一些可能会触发GC的操作，例如创建大量对象等\n    // 以下示例创建一个较大的map并填充数据\n    m := make(map[int]int)\n    for i := 0; i &lt; size; i++ {\n        m[i] = i\n\n    }\n    return m\n}\n</code></pre><p><strong>你会发现，key-value换成int类型的map，gc性能提升非常明显</strong>，gc时间从290ms变成了2.3ms，提升了几百倍。</p><pre><code class=\"language-plain\">killianxu@KILLIANXU-MB0 8 % go test -gcflags=all=-l -run Test500wIntGCDuration -v\n=== RUN   Test500wIntGCDuration\n    gc_type_test.go:14: size 5000000 GC duration: 2.29631ms\n--- PASS: Test500wIntGCDuration (1.33s)\n</code></pre><p><strong>第二，key-value除了需要满足非指针这个条件，key/value的大小也不能超过 128 字节，如果超过128字节，key-value就会退化成指针，导致被GC扫描。</strong></p><p>我们用value大小分别是128、129字节的结构体测试一下，测试代码如下。</p><pre><code class=\"language-go\">func TestSmallStruct(t *testing.T) {\n    type SmallStruct struct {\n        data [128]byte\n    }\n    m := make(map[int]SmallStruct)\n    size := 5000000\n    for i := 0; i &lt; size; i++ {\n        m[i] = SmallStruct{}\n    }\n    runtime.GC()\n    gcCost := timeGC()\n    t.Logf(\"size %d GC duration: %v\\n\", size, gcCost)\n    _ = m[1]\n}\nfunc TestBigStruct(t *testing.T) {\n    type BigStruct struct {\n        data [129]byte\n    }\n    m := make(map[int]BigStruct)\n    size := 5000000\n    for i := 0; i &lt; size; i++ {\n        m[i] = BigStruct{}\n    }\n    runtime.GC()\n    gcCost := timeGC()\n    t.Logf(\"size %d GC duration: %v\\n\", size, gcCost)\n    _ = m[1]\n}\n</code></pre><p><strong>果然，key-value的大小超过128字节会导致GC性能开销变大。</strong>对于129字节的结构体，GC耗时264ms，而128字节，只需要2.4ms，性能差距高达百倍。</p><pre><code class=\"language-shell\">killianxu@KILLIANXU-MB0 8 % go test -gcflags=all=-l -run \"TestSmallStruct|TestBigStruct\" -v\n=== RUN   TestSmallStruct\n    gc_type_test.go:39: size 5000000 GC duration: 2.444276ms\n--- PASS: TestSmallStruct (4.13s)\n=== RUN   TestBigStruct\n    gc_type_test.go:53: size 5000000 GC duration: 264.834283ms\n--- PASS: TestBigStruct (2.07s)\n</code></pre><p>通过前面的测试，我们知道了，<strong>在缓存大规模数据时，为了避免GC开销，key-value不能含指针类型且key-value的大小不能超过128字节。</strong></p><p>实际上，咱们在缓存大规模数据时，可以使用成熟的开源库来实现，比如 <a href=\"https://github.com/allegro/bigcache/tree/main\">bigcache</a>、<a href=\"https://github.com/coocood/freecache\">freecache</a> 等。它们的底层就是使用分段锁加map类型来实现数据存储的，同时，它们也利用了刚刚讲过的map的key-value特性，来避免GC扫描。</p><p>以bigcache为例，它的使用比较简单。通过Get和Set方法就可以实现读写操作。</p><pre><code class=\"language-go\">import (\n     \"fmt\"\"context\"\"github.com/allegro/bigcache/v3\"\n)\n\ncache, _ := bigcache.New(context.Background(), bigcache.DefaultConfig(10 * time.Minute))\n\ncache.Set(\"my-unique-key\", []byte(\"value\"))\n\nentry, _ := cache.Get(\"my-unique-key\")\nfmt.Println(string(entry))\n</code></pre><h2>小结</h2><p>今天这节课，我以大规模数据缓存的场景为例，带你学习了golang sync包的Map类型以及map的gc优化技巧。</p><p>现在让我们回顾一下sync.Map的知识以及map的zero gc特性。</p><p>sync.Map 在底层巧妙地借助两个 map 来达成读写分离的设计架构，以此实现高性能的读取操作。然而，这种设计并非毫无瑕疵，它存在着一些不容忽视的问题。</p><p>一方面，其内存占用相对较高；另一方面，当写入操作较为频繁时，读取性能会出现明显的退化现象。</p><p>此外，由于其基于两个 map 的架构特性，在数据处理过程中还会产生两个 map 之间的数据拷贝开销，这在一定程度上影响了整体的性能表现与资源利用效率。正因为 sync.Map 的使用场景较为严苛，在实际的编程实践中，使用这个方法的频率反倒比较低。</p><p>当map中缓存的数据比较多时，为了避免GC开销，我们可以将map中的key-value类型设计成非指针类型且大小不超过128字节，从而避免GC扫描。</p><p>希望你能够用心去体会map gc的优化技巧。在今后遇到大规模数据缓存的场景，别忘了用上学到的技巧去做GC优化。</p><h2>思考题</h2><p>在大规模数据缓存时，我们虽然可以用bigcache来避免gc，但是却会引起其它开销，那么是哪些开销呢？</p><p>欢迎你把你的答案分享在评论区，也欢迎你把这节课的内容分享给需要的朋友，我们下节课再见！</p>","neighbors":{"left":{"article_title":"07｜并发安全：如何为不同并发场景选择合适的锁？","id":835226},"right":[]},"comments":[{"had_liked":false,"id":396620,"user_name":"lJ","can_delete":false,"product_type":"c1","uid":2562558,"ip_address":"江苏","ucode":"CC29D06A16FF93","user_header":"https://static001.geekbang.org/account/avatar/00/27/19/fe/d31344db.jpg","comment_is_top":false,"comment_ctime":1735109890,"is_pvip":false,"replies":[{"id":143966,"content":"👍👍序列化反序列化本身，也会导致性能变差。比如我们做请求处理，如果一次要从缓存里获取很多条数据并反序列化出来做一些逻辑处理，这时候大量的反序列化，也会导致接口延时也会上涨。","user_name":"作者回复","user_name_real":"编辑","uid":1313417,"ctime":1735136988,"ip_address":"广东","comment_id":396620,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100843701,"comment_content":"1. 只支持 []byte 类型的数据存储，不支持复杂的数据结构，需要自行序列化和反序列化数据，增加了开发复杂度。\n2. 使用环形缓冲区存储数据，数据写入时是连续分配的，但删除时只标记为无效，不回收空间。导致内存利用率降低。","like_count":0,"discussions":[{"author":{"id":1313417,"avatar":"https://static001.geekbang.org/account/avatar/00/14/0a/89/eb8c28a4.jpg","nickname":"徐逸","note":"","ucode":"DCFDEE08FD263A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":655525,"discussion_content":"👍👍序列化反序列化本身，也会导致性能变差。比如我们做请求处理，如果一次要从缓存里获取很多条数据并反序列化出来做一些逻辑处理，这时候大量的反序列化，也会导致接口延时也会上涨。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1735136988,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":396614,"user_name":"快叫我小白","can_delete":false,"product_type":"c1","uid":3571201,"ip_address":"上海","ucode":"7CAD65E36601A2","user_header":"https://static001.geekbang.org/account/avatar/00/36/7e/01/1660e1e8.jpg","comment_is_top":false,"comment_ctime":1735103706,"is_pvip":false,"replies":[{"id":143967,"content":"第一次调用是为了让GC清理掉我们因为生成这个map而分配的一些临时变量。第二次调用基本就是GC扫描标记map的时间。这个的目的确实是测试GC在map上花费的时间。因为我们做本地缓存，map是个全局变量，虽然不会回收这个map，但是每次GC都会扫描","user_name":"作者回复","user_name_real":"编辑","uid":1313417,"ctime":1735137266,"ip_address":"广东","comment_id":396614,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100843701,"comment_content":"runtime.GC 这个函数为何在函数内外都调用一次呀？而且测试函数似乎没产生需要回收的临时结构体，我们调用GC函数仅仅是为了观察垃圾回收的扫描时间吗？","like_count":0,"discussions":[{"author":{"id":1313417,"avatar":"https://static001.geekbang.org/account/avatar/00/14/0a/89/eb8c28a4.jpg","nickname":"徐逸","note":"","ucode":"DCFDEE08FD263A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":655526,"discussion_content":"第一次调用是为了让GC清理掉我们因为生成这个map而分配的一些临时变量。第二次调用基本就是GC扫描标记map的时间。这个的目的确实是测试GC在map上花费的时间。因为我们做本地缓存，map是个全局变量，虽然不会回收这个map，但是每次GC都会扫描","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1735137266,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]}]}