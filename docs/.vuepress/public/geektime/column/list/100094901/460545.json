{"id":460545,"title":"14 | CPU Cache：访存速度是如何大幅提升的？","content":"<p>你好，我是海纳。</p><p>经过上一节课的学习，我们了解到不同的物理器件，它们的访问速度是不一样的：速度快的往往代价高、容量小；代价低且容量大的，速度通常比较慢。为了充分发挥各种器件的优点，计算机存储数据的物理器件不会只选择一种，而是以CPU为核心，由内而外地组建了一整套的存储体系结构。它将各种不同的器件组合成一个体系，让各种器件扬长避短，从而形成一种快速、大容量、低成本的内存系统。</p><p>而我们要想写出高性能的程序，就必须理解这个存储体系结构，并运用好它。因此，今天这节课我们就来看看常见的存储结构是如何搭建的，并借此把握好影响程序性能的主要因素，从而对程序性能进行优化。</p><h2>存储体系结构的核心</h2><p>作为程序员，我们肯定是希望有无限资源的快速存储器，来存放程序的数据。而现实是，快速存储器的制造成本很高，速度慢的存储器相对便宜。所以从成本角度来说，计算机的存储结构被设计成分层的，一般包括寄存器、缓存、内存、磁盘等。</p><p>其中，缓存又是整个存储体系结构的灵魂，它让内存访问的速度接近于寄存器的访问速度。所以，要想深入理解存储体系结构，我们就要围绕“缓存”这个核心来学习。</p><p>在过去的几十年，处理器速度的增长远远超过了内存速度的增长。尤其是在2001～2005年间，处理器的时钟频率在以55%的速度增长，而同期内存速度的增长仅为7%。为了缩小处理器和内存之间的速度差距，缓存被设计出来。</p><!-- [[[read_end]]] --><p>我们说，距离处理器越近，访问速度就越快，造价也就越高，同时容量也会更小。缓存是处理器和内存之间的一个桥梁，通常分为多层，包括L1层、L2层、L3层等等。缓存的速度介于处理器和内存之间，访问处理器内部寄存器的速度在1ns以内（一个时钟周期），访问内存的速度通常在50～100ns（上百个时钟周期）之间。那么对于缓存来讲，靠近处理器最近的L1层缓存的访问速度在1ns～2ns（3个时钟周期）左右，外层L2和L3层的访问速度在10ns～20ns（几十个时钟周期）之间。</p><p><img src=\"https://static001.geekbang.org/resource/image/21/3e/2188f0ef807cc3802f176a480cyyab3e.jpg?wh=2284x1062\" alt=\"\"></p><p>根据程序的空间局部性和时间局部性原理，一个处理得当的程序，缓存命中率要想达到70～90%并非难事。因此，<strong>在存储系统中加入缓存，可以让整个存储系统的性能接近寄存器，并且每字节的成本都接近内存，甚至是磁盘</strong>。</p><p>可见缓存结合了寄存器速度快和内存造价低的优点，是整个存储体系的灵魂之所在。明白了这一点后，接下来我们拆解一下缓存的物理架构。</p><h2>缓存的物理架构</h2><p>缓存是由SRAM（静态随机存储）组成的，它的本质是一种时序逻辑电路，具体的每个单元（比特）由一个个锁存器构成，锁存器的功能就是让电路具有记忆功能，这一点我们在之前讲过。</p><p>SRAM的单位造价还是比较高的，而且要远高于内存的组成结构“DRAM（动态随机存储）”的造价。这是因为要实现一个锁存器需要六个晶体管，而实现一个DRAM仅需要一个晶体管和一个电容，但是DRAM因为结构简单，单位面积可以存放更多数据，所以更适合做内存。为了兼顾这两者的优缺点，于是它们中间需要加入缓存。</p><p>在制造方面，DRAM因为有电容的存在，不再是单纯的逻辑电路，所以不能用CMOS工艺制造，而SRAM可以。这也是为什么缓存可以集成到芯片内部，而内存是和芯片分开制造的。</p><p>在了解了缓存的内部构成之后，我们再来看看缓存是怎样集成到芯片上的。</p><p>缓存集成到芯片的方式有多种。在过去的单核时代，处理器和各级缓存都只有一个，因此缓存的集成方式相对单一，就是把处理器和缓存直接相连。2004年，Intel取消了4GHz奔腾处理器的研发计划，这意味着处理器以提升主频榨取性能的时代结束，多核处理器开始成为主流。</p><p>在多核芯片上，缓存集成的方式主要有以下三种：</p><ul>\n<li><strong>集中式缓存</strong>：一个缓存和所有处理器直接相连，多个核共享这一个缓存；</li>\n<li><strong>分布式缓存</strong>：一个处理器仅和一个缓存相连，一个处理器对应一个缓存；</li>\n<li><strong>混合式缓存</strong>：在L3采用集中式缓存，在L1和L2采用分布式缓存。</li>\n</ul><p><img src=\"https://static001.geekbang.org/resource/image/d7/96/d7ae48f9f7d705b22cb95c53e423d096.jpg?wh=2284x1392\" alt=\"\"></p><p>现代的多核处理器大都采用混合式的方式将缓存集成到芯片上，一般情况下，L3是所有处理器核共享的，L1和L2是每个处理器核特有的。</p><p>了解了缓存的物理架构后，我们来看一下缓存的工作原理</p><h2>缓存的工作原理</h2><p>首先，我们来理解一个概念，cache line。cache line是缓存进行管理的一个最小存储单元，也叫缓存块。从内存向缓存加载数据也是按缓存块进行加载的，一个缓存块和一个内存中相同容量的数据块（下称内存块）对应。这里，我们先从如何管理缓存块的角度，来看下缓存块的组织形式：</p><p><img src=\"https://static001.geekbang.org/resource/image/28/65/28b90193d04c1247f8e3fbb076b15965.jpg?wh=2284x1312\" alt=\"\"></p><p>上图中的小方框就代表一个缓存块。从图中，你也可以看到，整个缓存由组（set）构成，每个组由路（way）构成。所以整个缓存容量等于组数、路数和缓存块大小的乘积：</p><p>$整个缓存容量=组数\\times路数\\times缓存块大小$</p><p>为了简化寻址方式，内存地址确定的数据块总是会被放在一个固定的组，但可以放在组内的任意路上，也就是说，对于一个特定地址数据的访问，它如果要载入缓存，那么它放在上图中的行数是固定的，但是具体放到哪一列是不固定的。根据缓存中组数和路数的不同，我们将缓存的映射方式分为三类：</p><ul>\n<li><strong>直接相连映射</strong>：缓存只有一个路，一个内存块只能放置在特定的组上；</li>\n<li><strong>全相连映射</strong>：缓存只有一个组，所有的内存块都放在这一个组的不同路上；</li>\n<li><strong>组组相连映射</strong>：缓存同时由多个组和多个路。</li>\n</ul><p>对于直接相连映射，当多个内存块映射到同一组时，会产生冲突，因为只有一列，这个时候就需要将旧的缓存块换出，同时将新的缓存块放入，所以<strong>直接相连映射会导致缓存块被频繁替换</strong>。</p><p>而<strong>全相连映射可以在很大程度上避免冲突，不过，当要查询某个缓存块时，需要逐个遍历每个路，而且电路实现也比较困难</strong>。一个折中的办法就是，采用组组相连映射。这种方式与直接相连映射相比，产生冲突的可能性更小，与全相连映射相比，查询效率更高，实现也更简单。</p><p>上面的举例比较简单，我们再来看这样一种情况：缓存的组数一直是$2^{n}$。虽然组数为$2^{n}$利于查询和定位，但是如果一个程序刚好以$2^{n}$间隔寻址，就会导致地址更多的被映射到同一个组，而另外一些组就会被映射得很少。因此，也有些缓存的组数会设计成一个质数，这样即便程序以$2^{n}$间隔寻址，落到相同组的可能性会大大减小，这样一来，缓存各个组的利用率就会相对均衡。</p><p>那一个内存块具体是怎样映射到一个缓存块的呢？我们先来看看缓存块的内部结构：</p><p><img src=\"https://static001.geekbang.org/resource/image/df/ce/dfcfd3dc2b0a6cc3305ed6188c24cece.jpg?wh=2284x798\" alt=\"\"></p><p>其中，V（valid）表示这个缓存块是否有效，或者说是否正在被使用；M（modified）表示这个缓存块是否被写，也就是“脏”位；B表示缓存块的bit个数。</p><p>假设要寻址一个32位的地址，缓存块的大小是64字节，缓存组织方式是4路组相连，缓存大小是8K。经过计算我们得到缓存一共有32个组（$8\\times1024\\div64\\div4=32$）。那么对于任意一个32位的地址Addr ，它映射到缓存的组号（set index）为 Addr对组数32取模，组号同时也等于Addr的第6~10位（ (Addr &gt;&gt; 6) &amp; 0x1F ），Addr的低6位很好理解，它是缓存块的内部偏移（$2^{6}$为64字节），那么高21位是用来干嘛的呢？我们接着往下看。</p><p>确定需要被映射到哪个组之后，我们需要在该组的路中进行查询。查询方式也很简单，直接将每个缓存块tag的bit位和地址Addr的高21位逐一进行匹配。如果相等，就说明该内存块已经载入到缓存中；如果没有匹配的tag，就说明缓存缺失，需要将内存块放到该组的一个空闲缓存块上；如果所有路的缓存块都正在被使用，那么需要选择一个缓存块，将其移出缓存，把新的内存块载入。</p><p>上面这个过程涉及到缓存块状态转换，而状态转换又涉及到有效位V、脏位M、标签tag。总体来讲，缓存的状态转换有以下几种情况：</p><p><img src=\"https://static001.geekbang.org/resource/image/6d/c2/6d2bfe107cb8a633ea8d9eb363021dc2.jpg?wh=2284x1296\" alt=\"\"></p><p>这里我们提到了缓存块替换，当同组的缓存块都被用完时，需要选择一个缓存块被换出，那么应该选谁被换出呢？这就和缓存块替换策略有关了。</p><h2>缓存块替换策略</h2><p>缓存块替换策略需要达到的一个目标是：<strong>被替换出的数据块应该是将来最晚会被访问的块</strong>。然而，对将来即将发生的事情是没有办法预测的，因为处理器并不知道程序将来会访问哪个地址。因此，<strong>现在的缓存替换策略都采用了最近最少使用算法（Least Recently Used ，LRU）或者是类似LRU的算法</strong>。</p><p>LRU的原理很简单，比如程序要顺序访问 B1 、B2、B3、B4、B5这几个地址块，并且这几个缓存块都映射到缓存的同一个组，同时我们假设缓存采用4路组组相连映射，那么当访问B5时，B1就需要被替换出来。要实现这一点，有很多种方式，其中最简单也最容易实现的是利用位矩阵来实现。</p><p>首先，我们定义一个行、列都与缓存路数相同的矩阵。当访问某个路对应的缓存块时，先将该路对应的所有行置为1，然后再将该路对应的所有列置为0。最终结果体现为，缓存块访问时间的先后顺序，由矩阵行中1的个数决定，最近最常访问缓存块对应行1的个数最多。</p><p>假设现在一个四路相连的缓存组包含数据块 B1、B2、B3、B4, 数据块的访问顺序为 B2、B3、B1、B4，那么LRU矩阵在每次访问后的变化如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/d5/8e/d5f649a8cfff5fea806122bc18b0fb8e.jpg?wh=2284x725\" alt=\"\"></p><p>你会发现，最终B2对应行的1的个数最少，所以B2将会被优先替换。</p><p>在理解了缓存结构和它的工作原理以后，我们就可以来讨论这节课的核心内容了：如何正确地使用缓存，才可以写出高性能的程序？</p><h2>缓存对程序性能的影响</h2><p>通过前面的分析，我们已经知道，CPU将未来最有可能被用到的内存数据加载进缓存。<strong>如果下次访问内存时，数据已经在缓存中了，这就是缓存命中，它获取目标数据的速度非常快。如果数据没在缓存中，这就是缓存缺失，此时要启动内存数据传输，而内存的访问速度相比缓存差很多</strong>。所以我们要避免这种情况。下面，我们先来了解一下哪些情况容易造成缓存缺失，以及具体会对程序性能带来怎样的影响。</p><h3>缓存缺失</h3><p>缓存性能主要取决于缓存命中率，也就说缓存缺失（cache miss）越少，缓存的性能就越好。一般来说，引起缓存缺失的类型主要有三种：</p><ul>\n<li><strong>强制缺失</strong>：第一次将数据块读入到缓存所产生的缺失，也被称为冷缺失（cold miss），因为当发生缓存缺失时，缓存是空的（冷的）；</li>\n<li><strong>冲突缺失</strong>：由于缓存的相连度有限导致的缺失；</li>\n<li><strong>容量缺失</strong>：由于缓存大小有限导致的缺失。</li>\n</ul><p>第一类强制缺失最容易理解，因为第一次将数据读入缓存时，缓存中不会有数据，这种缺失无法避免。</p><p>第二类冲突缺失是因为相连度有限导致的，这里我用一个例子给你说明一下。在这个例子中，第一步我们可以通过getconf命令查看缓存的信息：</p><pre><code># getconf -a |grep CACHE\nLEVEL1_ICACHE_SIZE                 32768\nLEVEL1_ICACHE_ASSOC                8\nLEVEL1_ICACHE_LINESIZE             64\nLEVEL1_DCACHE_SIZE                 32768\nLEVEL1_DCACHE_ASSOC                8\nLEVEL1_DCACHE_LINESIZE             64\nLEVEL2_CACHE_SIZE                  262144\nLEVEL2_CACHE_ASSOC                 4\nLEVEL2_CACHE_LINESIZE              64\nLEVEL3_CACHE_SIZE                  3145728\nLEVEL3_CACHE_ASSOC                 12\nLEVEL3_CACHE_LINESIZE              64\nLEVEL4_CACHE_SIZE                  0\nLEVEL4_CACHE_ASSOC                 0\nLEVEL4_CACHE_LINESIZE              0\n</code></pre><p>在这个缓存的信息中，L1Cache（LEVEL1_ICACHE和LEVEL1_DCACHE分别表示指令缓存和数据缓存，这里我们只关注数据缓存）的cache line 大小为64字节，路数为8路，大小为32K，可以计算出缓存的组数为64组（$32K\\div8\\div64=64$）。</p><p>第二步，我们使用一个程序来测试缓存的影响：</p><pre><code>// cache.c\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n \n#define M  64\n#define N  10000000\nint main( )\n{\n   printf(&quot;%ld&quot;,sizeof(long long));\n   long long (*a)[N] = (long long(*)[N])calloc(M * N, sizeof(long long));\n \n   for(int i = 0; i &lt; 100000000; i++) {\n       for(int j = 0; j &lt; 4096; j+=512) {\n           a[5][j]++;\n       }\n   }\n   return 0;\n}\n</code></pre><p>上面代码中定义了一个二维数组，数组中元素的类型为long long ，元素大小为8字节。所以一个cache line 可以存放 $64\\div8$=$8$个元素。一组是8路，所以一组可以存放$8\\times8$=$64$个元素。一路包含64个cache line，因为前面计算出缓存的组数为64，所以一路可以存放$8\\times64$=$512$个元素。</p><p>代码中的第一层循环是执行次数，第二层循环是以512 为间隔访问元素，即每次访问都会落在同一个组内的不同cache line ，因为一组有8路，所以我们迭代到 $512\\times8$=$4096$的位置。这样可以使同一组刚好可以容纳二层循环需要的地址空间。运行结果如下：</p><pre><code># gcc cache.c\n# time ./a.out\n8\nreal 0m2.670s\nuser 0m2.671s\nsys 0m0.001s\n</code></pre><p>第三步，当我们将第二层循环的迭代次数扩大一倍，也就是8192时，运行结果如下：</p><pre><code># gcc cache.c\n# time ./a.out\n8\nreal 0m16.693s\nuser 0m16.700s\nsys 0m0.001s\n</code></pre><p><strong>虽然运算量增加了一倍，但运行时间却增加了6倍，相当于性能劣化三倍</strong>。劣化的根本原因就是当i &gt; 4096时，也就是访问4096之后的元素，同一组的cache line 已经全部使用，必须进行替换，并且之后的每次访问都会发生冲突，导致缓存块频繁替换，性能劣化严重。</p><p>第三类缓存容量缺失，可以认为是除了强制缺失和冲突缺失之外的缺失，也很好理解，当程序运行的某段时间内，访问地址范围超过缓存大小很多，这样缓存的容量就会成为缓存性能的瓶颈，这里要注意和冲突缺失加以区别，冲突缺失指的是在同一组内的缺失，而容量缺失描述范围是整个缓存。</p><h3>程序局部性</h3><p>在<a href=\"https://time.geekbang.org/column/article/430073\">第1节课</a>里，我们已经讲过，程序局部性分为时间局部性和空间局部性。如果程序有非常好的局部性，那么在程序运行期间，缓存缺失就很少发生。</p><p>我们对上面的例子进行修改，以此来验证程序局部性对缓存命中率的影响，进一步可以观察它对性能产生怎样的影响。</p><pre><code>#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n \n#define M  10000\n#define N  10000\nint main( )\n{\n   printf(&quot;%ld&quot;,sizeof(long long));\n   long long (*a)[N] = (long long(*)[N])calloc(M * N, sizeof(long long));\n   \n   for(int i = 0; i &lt; M; i++) {\n       for(int j = 0; j &lt; N; j++) {\n           a[i][j]++;\n       }\n   }\n   return 0;\n}\n</code></pre><p>这里主要进行了两处修改：<strong>一是修改了迭代次数，方便测试；二是将之前间隔访问数组中的部分元素修改为顺序访问整个数组，访问方式按二维数组的行逐次访问</strong>。测试结果如下：</p><pre><code># gcc -O0 cache.c\n# time ./a.out\n8\nreal 0m1.245s\nuser 0m0.797s\nsys 0m0.449s\n</code></pre><p>但当我们按列访问时，也就是将内层循环条件提到外面：</p><pre><code>for(int j = 0; j &lt; N; j++) {\n    for(int i = 0; i &lt; M; i++) {\n        a[i][j]++;\n    }\n}\n</code></pre><p>运行结果为：</p><pre><code># gcc -O0 cache.c\n# time ./a.out\n8\nreal 0m2.527s\nuser 0m1.980s\nsys 0m0.548s\n</code></pre><p>可以看到，性能也出现了2倍的劣化，这次劣化的主要原因是当按行访问时地址是连续的，下次访问的元素和当前大概率在同一个cache line（一个元素8字节，而一个cache line 可以容纳8个元素），但是当按列访问时，由于地址跨度大，下次访问的元素基本不可能还在同一个cache line，因此就会增加cache line被替换的次数，所以性能劣化。</p><p>你需要注意的是，<strong>这次编译选项都添加了-O0选项，告诉编译器不要进行优化，因为现在的编译器很聪明，能够识别出这种循环外提的优化，所以我们要先关掉优化</strong>。</p><p>在理解了缓存缺失对程序性能的影响后，我们来看一类非常典型的因为缓存使用不当而引起的性能下降的问题，这类问题统称为伪共享。</p><h2>伪共享</h2><p>伪共享（false-sharing）的意思是说，<strong>当两个线程同时各自修改两个相邻的变量，由于缓存是按缓存块来组织的，当一个线程对一个缓存块执行写操作时，必须使其他线程含有对应数据的缓存块无效。这样两个线程都会同时使对方的缓存块无效，导致性能下降</strong>。</p><p>我们具体来看这样一个例子：</p><pre><code>#include &lt;stdio.h&gt;\n#include &lt;pthread.h&gt;\n \nstruct S{\n   long long a;\n   long long b;\n} s;\n \nvoid *thread1(void *args)\n{\n    for(int i = 0;i &lt; 100000000; i++){\n        s.a++;\n    }\n    return NULL;\n}\n \nvoid *thread2(void *args)\n{\n    for(int i = 0;i &lt; 100000000; i++){\n        s.b++;\n    }\n    return NULL;\n}\n \nint main(int argc, char *argv[]) {\n    pthread_t t1, t2;\n    s.a = 0;\n    s.b = 0;\n    pthread_create(&amp;t1, NULL, thread1, NULL);\n    pthread_create(&amp;t2, NULL, thread2, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    printf(&quot;a = %lld, b = %lld\\n&quot;, s.a, s.b);\n    return 0;\n}\n</code></pre><p>在这个例子中，main函数中创建了两个线程，分别修改结构体S中的a 、b 变量。a 、b均为long long 类型，都占8字节，所以a 、b 在同一个cache line中，因此会发生为伪共享的情况。程序的运行结果为：</p><pre><code># gcc -Wall false_sharing.c -lpthread\n# time ./a.out\na = 100000000, b = 100000000\n \nreal 0m0.790s\nuser 0m1.481s\nsys 0m0.008s\n</code></pre><p>解决伪共享的办法是，将a 、b不要放在同一个cache line，这样两个线程分别操作不同的cache line 不会相互影响。具体来讲，我们需要对结构体S做出如下修改：</p><pre><code>struct S{\n   long long a;\n   long long nop_0;\n   long long nop_1;\n   long long nop_2;\n   long long nop_3;\n   long long nop_4;\n   long long nop_5;\n   long long nop_6;\n   long long nop_7;\n   long long b;\n} s;\n</code></pre><p>因为在a、b中间插入了8个long long类型的变量，中间隔了64字节，所以a、b会被映射到不同的缓存块，程序执行结果如下：</p><pre><code># gcc -Wall false_sharing.c -lpthread\n# time ./a.out\na = 100000000, b = 100000000\n \nreal 0m0.347s\nuser 0m0.693s\nsys 0m0.001s\n</code></pre><p>在这个结果中，你可以看到，性能有一倍的提升。</p><p>其实，伪共享是一种典型的缓存缺失问题，在并发场景中很常见。<strong>在Java的并发库里经常会看到为了解决伪共享而进行的数据填充。这是大家在写并发程序时也要加以注意的</strong>。</p><h2>总结</h2><p>今天这节课，我们先介绍了存储体系结构的架构和工作原理。其中，缓存又是整个存储体系结构的灵魂，它让内存访问的速度接近于寄存器的访问速度。缓存对程序员是透明的，程序员不必使用特定的API接口来操作缓存工作，它是自动工作的。但如果我们的代码写得不好的话，我们就会感受到缓存不能起作用时的性能下降了。</p><p>缓存的映射方式包括了直接相连、全相连、组组相连三种。直接相连映射会导致缓存块被频繁替换；而全相连映射可以很大程度上避免冲突，但查询效率低；组组相连映射，与直接相连映射相比，产生冲突的可能性更小，与全相连映射相比，查询效率更高，实现也更简单。</p><p>如果要访问的数据不在缓存中，这就是缓存缺失。当发生缓存缺失时，就需要往缓存中加载目标地址的数据。如果缓存空间不足了，就需要对缓存块进行替换，替换的策略多采用LRU策略。</p><p>缓存缺失对性能影响非常大。缓存缺失主要包括强制缺失，冲突缺失和容量缺失。为了避免缓存缺失我们一定要注意程序的局部性，虽然编译器会帮我们做很多事情，但编译器还是有很多情况是无法优化的。</p><p>伪共享是一类非常典型的缓存缺失问题。它是由于多个线程都反复使对方的缓存块无效，带来的性能下降。为了解决这一类问题，我们可以考虑让多个线程所共同访问的对象，在物理上隔离开，保证它们不会落在同一个缓存块里。</p><p>好了，这节课到这里就结束了。下节课，我将带你探讨缓存一致性问题是如何解决的。</p><h2>思考题</h2><p>cache被翻译成缓存，buffer被翻译成缓冲区。那么，请你思考一下，cache和buffer这两个词的区别是什么？它们分别用在什么场景下？除了我们这节课所讲的物理缓存外，你还知道哪些缓存结构？</p><p><img src=\"https://static001.geekbang.org/resource/image/37/02/37f9f73e902efa495855c083f5997f02.jpg?wh=2284x1608\" alt=\"\"></p><p>好啦，这节课到这就结束啦。欢迎你把这节课分享给更多对计算机内存感兴趣的朋友。我是海纳，我们下节课再见！</p>","comments":[{"had_liked":false,"id":327012,"user_name":"ZR2021","can_delete":false,"product_type":"c1","uid":1707352,"ip_address":"","ucode":"4F685C7516F057","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKwGurTWOiaZ2O2oCdxK9kbF4PcwGg0ALqsWhNq87hWvwPy8ZU9cxRzmcGOgdIeJkTOoKfbxgEKqrg/132","comment_is_top":false,"comment_ctime":1639837234,"is_pvip":false,"replies":[{"id":"119045","content":"第一个问题，是物理地址，其实你后面第二题的分析差不多就能推导出来这里必须用物理地址了。你的第二和第三问，猜想都是对的。你掌握得很好嘛！","user_name":"作者回复","user_name_real":"编辑","uid":"1360512","ctime":1640017096,"ip_address":"","comment_id":327012,"utype":1}],"discussion_count":3,"race_medal":0,"score":"14524739122","product_id":100094901,"comment_content":"老师太棒了，这是我见过将缓存讲的最详细的文章，课买的真值！！！<br>不过有几个问题想请教下老师：<br>1. 文章中提到的根据32位地址确定缓存的组和路，这个地址是虚拟地址还是物理地址？ 后面的案例里的数组的地址是虚拟的连续地址，映射到物理地址的话不一定连续，所以当第二层4096循环的时候不一定会落到同一组；如果是物理地址的话，那就是说也得经过页表转换，这个转换是不是先经过TLB的转换，如果TLB miss里再到内存里加载新的页表？<br>2. 缓存伪共享看样子只会出现在多线程的场景下，单进程的话每个进程内存映射后的物理地址的间隔远远大于一个cache line，所以不会出现多进程访问了同一个cache line的情况<br>3. 进程切换比线程切换的代价小是不是有一部分就是这个cache line 缺失导致的，因为切换到新的进程后，里面的数据要从内存重新加载到cache line中，频繁的进程切换导致的cache 缺失也挺严重的<br><br>希望得到老师的解答，万分感谢！！！","like_count":3,"discussions":[{"author":{"id":1360512,"avatar":"https://static001.geekbang.org/account/avatar/00/14/c2/80/6ebf32e8.jpg","nickname":"海纳","note":"","ucode":"AB9F7ADB1428D2","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":540326,"discussion_content":"第一个问题，是物理地址，其实你后面第二题的分析差不多就能推导出来这里必须用物理地址了。你的第二和第三问，猜想都是对的。你掌握得很好嘛！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1640017096,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1432830,"avatar":"https://static001.geekbang.org/account/avatar/00/15/dc/fe/f11f25dd.jpg","nickname":"左星辰","note":"","ucode":"A67D772F6AA584","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":548234,"discussion_content":"第三问说反了吧，应该是线程切换比进程切换的代价小才对吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1643095234,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1707352,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKwGurTWOiaZ2O2oCdxK9kbF4PcwGg0ALqsWhNq87hWvwPy8ZU9cxRzmcGOgdIeJkTOoKfbxgEKqrg/132","nickname":"ZR2021","note":"","ucode":"4F685C7516F057","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":540620,"discussion_content":"啊，谢谢老师的回答，谢谢老师的夸奖！！！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1640097927,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":333417,"user_name":"张Dave","can_delete":false,"product_type":"c1","uid":2440338,"ip_address":"","ucode":"0E8B6FDEB7505B","user_header":"https://static001.geekbang.org/account/avatar/00/25/3c/92/81fa306d.jpg","comment_is_top":false,"comment_ctime":1644334245,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"5939301541","product_id":100094901,"comment_content":"第二层循环是以 512 为间隔访问元素，即每次访问都会落在同一个组内的不同 cache line ，因为一组有 8 路。<br>有点疑问：<br>一个组内有8路，8条cacheline，可容纳64元素。为什么不是按照64元素间隔遍历，这样就可以把一个组内的cacheline都替换完啊，为什么要按照512元素遍历？","like_count":2},{"had_liked":false,"id":326714,"user_name":"满分💯","can_delete":false,"product_type":"c1","uid":2758349,"ip_address":"","ucode":"E074D9761DBC23","user_header":"https://static001.geekbang.org/account/avatar/00/2a/16/cd/226cd9f1.jpg","comment_is_top":false,"comment_ctime":1639642095,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"5934609391","product_id":100094901,"comment_content":"看完收获很多，最近看了一票文章 ，结合这看，效果更加 https:&#47;&#47;coolshell.cn&#47;articles&#47;20793.html<br> ","like_count":1},{"had_liked":false,"id":325933,"user_name":"aikeke","can_delete":false,"product_type":"c1","uid":1057623,"ip_address":"","ucode":"42974797A75EA7","user_header":"https://static001.geekbang.org/account/avatar/00/10/23/57/5ba842bc.jpg","comment_is_top":false,"comment_ctime":1639242019,"is_pvip":true,"replies":[{"id":"118512","content":"有专门的电路呀。它不占据缓存块的空间哈。你后面引用的那个公式里是不包含这几个字段的。","user_name":"作者回复","user_name_real":"编辑","uid":"1360512","ctime":1639489249,"ip_address":"","comment_id":325933,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5934209315","product_id":100094901,"comment_content":"老师，一个cache line里，V（valid）、M（modified）以及tag这几个字段是保存在哪里呢？&quot;假设要寻址一个 32 位的地址，缓存块的大小是 64 字节，缓存组织方式是 4 路组相连，缓存大小是 8K。经过计算我们得到缓存一共有 32 个组（8×1024÷64÷4=32）&quot;","like_count":1,"discussions":[{"author":{"id":1360512,"avatar":"https://static001.geekbang.org/account/avatar/00/14/c2/80/6ebf32e8.jpg","nickname":"海纳","note":"","ucode":"AB9F7ADB1428D2","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":538705,"discussion_content":"有专门的电路呀。它不占据缓存块的空间哈。你后面引用的那个公式里是不包含这几个字段的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1639489249,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1057623,"avatar":"https://static001.geekbang.org/account/avatar/00/10/23/57/5ba842bc.jpg","nickname":"aikeke","note":"","ucode":"42974797A75EA7","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":538182,"discussion_content":"是不是一个cache line里，V（valid）、M（modified）以及tag这三个字段的存储是cache硬件实现的？我们平常说的缓存大小8KB只是指实际的数据存储部分的大小？并没有包括V（valid）、M（modified）以及tag这些所谓控制字段的大小？","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1639361973,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":323825,"user_name":"相逢是缘","can_delete":false,"product_type":"c1","uid":1060730,"ip_address":"","ucode":"CB299F53A95654","user_header":"https://static001.geekbang.org/account/avatar/00/10/2f/7a/ab6c811c.jpg","comment_is_top":false,"comment_ctime":1638175880,"is_pvip":false,"replies":[{"id":"117804","content":"1. 你的猜想是对的。如果读取的时候缓存不命中，这一次读数据往往都要上百年时钟周期。但是访存却不必要等cache line全部填完，它只要拿到自己想要的数据就可以了，cache line可以交给其他模块继续填充。CPU的模块之间是并行的。还有一点，如果是连续的内存读取的话，内存控制器这个模块是可以做加速的，这种优化就可以让访存和总线传输足够快。<br>2. 一般来说，L1&#47;L2是SRAM，L3常见的是STT-MRAM或者是eDRAM。价格是一方面吧，关键是CPU的面积，就算你不计成本的话，功耗，散热都会受面积的影响，我们不可能无限制地增加电路面积。制程的缩小有利于在同样面积的芯片上刻录更多的电路。<br>3. 确实，你学习得很深入。我们课里没有提icache，是觉得概念比较多，我希望尽量简化。没有更多的icache缓存是因为没有必要，因为指令毕竟还是顺序执行的最多。不像数据cache，访问哪个内存块随机性大一些。","user_name":"作者回复","user_name_real":"编辑","uid":"1360512","ctime":1638538800,"ip_address":"","comment_id":323825,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5933143176","product_id":100094901,"comment_content":"老师，我可能陷入思维误区了，有几个问题请教一下<br>1、CPU如何把数据读取到cache的呢？<br>某个时刻一个CPU指令访问数据地址0，一个cache line 64个字节，CPU会把0~63这64个字节全部读取到cache line，假如数据线是64位，一次能读取8个字节，也需要读取8次，如果读取一次需要100个CPU时钟周期，那读取一个cache line需要800个时钟周期。但是下条指令访问的数据地址可能是0x100000，这时CPU是插入NOP操作，等待800个时钟周期等着cache line填充完吗？还是怎么操作的呢？<br>2、缓存做成多级，每一级电路上有什么不同吗（都是SRAM？），主要是因为硬件集成电路价格的原因去分为这么多级缓存吗？<br>3、了解到L1级缓存一般都分为指令Icache和数据Dcache，而到L2、L3就不分了Icache和Dcache了呢？","like_count":1,"discussions":[{"author":{"id":1360512,"avatar":"https://static001.geekbang.org/account/avatar/00/14/c2/80/6ebf32e8.jpg","nickname":"海纳","note":"","ucode":"AB9F7ADB1428D2","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":535774,"discussion_content":"1. 你的猜想是对的。如果读取的时候缓存不命中，这一次读数据往往都要上百年时钟周期。但是访存却不必要等cache line全部填完，它只要拿到自己想要的数据就可以了，cache line可以交给其他模块继续填充。CPU的模块之间是并行的。还有一点，如果是连续的内存读取的话，内存控制器这个模块是可以做加速的，这种优化就可以让访存和总线传输足够快。\n2. 一般来说，L1/L2是SRAM，L3常见的是STT-MRAM或者是eDRAM。价格是一方面吧，关键是CPU的面积，就算你不计成本的话，功耗，散热都会受面积的影响，我们不可能无限制地增加电路面积。制程的缩小有利于在同样面积的芯片上刻录更多的电路。\n3. 确实，你学习得很深入。我们课里没有提icache，是觉得概念比较多，我希望尽量简化。没有更多的icache缓存是因为没有必要，因为指令毕竟还是顺序执行的最多。不像数据cache，访问哪个内存块随机性大一些。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1638538800,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":357119,"user_name":"Chunel","can_delete":false,"product_type":"c1","uid":2011779,"ip_address":"江苏","ucode":"CBD0C1A2B962AE","user_header":"https://static001.geekbang.org/account/avatar/00/1e/b2/83/7cf8e650.jpg","comment_is_top":false,"comment_ctime":1662973908,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1662973908","product_id":100094901,"comment_content":"老师，请问：<br>我new了两个类对象，分别在两个线程里做 i++<br>我怎么确定，这两个类中的 i 变量，在不在一个cacheline，从而避免伪共享呢？","like_count":0},{"had_liked":false,"id":352925,"user_name":"Samaritan.","can_delete":false,"product_type":"c1","uid":2523660,"ip_address":"陕西","ucode":"A3730B90313C26","user_header":"https://static001.geekbang.org/account/avatar/00/26/82/0c/cc106ab1.jpg","comment_is_top":false,"comment_ctime":1659014970,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1659014970","product_id":100094901,"comment_content":"老师你好，我想请教一个问题:<br>对组数 32 取模，组号同时也等于 Addr 的第 6~10 位（ (Addr &gt;&gt; 6) &amp; 0x1F ）<br><br>是根据什么信息得出，组号等于addr第二的第6~10位呢？主号不可以使用地址的高5位，而使用地址中间的21位作为tag吗？","like_count":0},{"had_liked":false,"id":338421,"user_name":"联通","can_delete":false,"product_type":"c1","uid":2839104,"ip_address":"","ucode":"EAA1331CFAFDA3","user_header":"https://static001.geekbang.org/account/avatar/00/2b/52/40/1fe5be2b.jpg","comment_is_top":false,"comment_ctime":1647495377,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1647495377","product_id":100094901,"comment_content":"cache一般是缓存，在读场景中用的比较懂，比如加载的文件缓存内存中，当下次读取就不用去磁盘加载；buffer一般缓冲区，在写场景中用的比较多，比如写一个文件，可以将多次写的数据先缓存下来，然后一次性写入磁盘，减少IO等待的时间","like_count":0},{"had_liked":false,"id":324065,"user_name":"🐮","can_delete":false,"product_type":"c1","uid":2112298,"ip_address":"","ucode":"3FAD9EA59E1713","user_header":"https://static001.geekbang.org/account/avatar/00/20/3b/2a/f05e546a.jpg","comment_is_top":false,"comment_ctime":1638277158,"is_pvip":true,"replies":[{"id":"117802","content":"其实核心点不在于读和写，而在于是否在多线程之间共享。单线程的话，读写都可以加速。多线程就要小心了，如果都有写操作的话，要注意伪共享的情况。","user_name":"作者回复","user_name_real":"编辑","uid":"1360512","ctime":1638538137,"ip_address":"","comment_id":324065,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1638277158","product_id":100094901,"comment_content":"老师，你好，平台我们为提升读取数据性能，会把所需要的数据尽量放在同一个cache line中，但如果存在多个进程会对相临数据写时又要尽量不要把数据放在同一个cache line中，这块是否是从读和写来理解比较好啊，如果是读，就放一起，多进程写就不要放一起；","like_count":0,"discussions":[{"author":{"id":1360512,"avatar":"https://static001.geekbang.org/account/avatar/00/14/c2/80/6ebf32e8.jpg","nickname":"海纳","note":"","ucode":"AB9F7ADB1428D2","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":535771,"discussion_content":"其实核心点不在于读和写，而在于是否在多线程之间共享。单线程的话，读写都可以加速。多线程就要小心了，如果都有写操作的话，要注意伪共享的情况。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1638538137,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":323955,"user_name":"那时刻","can_delete":false,"product_type":"c1","uid":1150927,"ip_address":"","ucode":"B0D150856C3A4A","user_header":"https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg","comment_is_top":false,"comment_ctime":1638239572,"is_pvip":false,"replies":[{"id":"117803","content":"谢谢~其实我们第15节课就已经解释了，你可以对照一下~","user_name":"作者回复","user_name_real":"编辑","uid":"1360512","ctime":1638538177,"ip_address":"","comment_id":323955,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1638239572","product_id":100094901,"comment_content":"从文件角度理解，buffer可以理解为是一类特殊文件的cache，这类特殊文件就是设备文件，比如&#47;dev&#47;sda1, 这类设备文件的内容被读到内存后就是buffer。而cache则是普通文件的内容被读到了内存。","like_count":0,"discussions":[{"author":{"id":1360512,"avatar":"https://static001.geekbang.org/account/avatar/00/14/c2/80/6ebf32e8.jpg","nickname":"海纳","note":"","ucode":"AB9F7ADB1428D2","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":535772,"discussion_content":"谢谢~其实我们第15节课就已经解释了，你可以对照一下~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1638538177,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":323859,"user_name":"大豆","can_delete":false,"product_type":"c1","uid":1350130,"ip_address":"","ucode":"BC78EF2336DBD0","user_header":"https://static001.geekbang.org/account/avatar/00/14/99/f2/c74d24d7.jpg","comment_is_top":false,"comment_ctime":1638185059,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1638185059","product_id":100094901,"comment_content":"1，我认为cache是真实存在的硬件，buffer是人为抽象出来的。buffer所对应的区域可以在cache中，也可以在内存中。它们共同的目的都是为了提高运行效率。<br>2，我认为buffer实际上是一种预热操作，通过cache及局部性来实现了高效，在需要及时响应场景用的多;而cache则是一个通用的操作，可以用于任何场景。","like_count":0},{"had_liked":false,"id":323836,"user_name":"linker","can_delete":false,"product_type":"c1","uid":1803259,"ip_address":"","ucode":"6C5799F2FC2C82","user_header":"https://static001.geekbang.org/account/avatar/00/1b/83/fb/621adceb.jpg","comment_is_top":false,"comment_ctime":1638177942,"is_pvip":false,"replies":[{"id":"117806","content":"对的，是啊：）","user_name":"作者回复","user_name_real":"编辑","uid":"1360512","ctime":1638539056,"ip_address":"","comment_id":323836,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1638177942","product_id":100094901,"comment_content":"LEVEL1_ICACHE_SIZE                 32768<br>LEVEL1_ICACHE_ASSOC                8<br>LEVEL1_ICACHE_LINESIZE             64<br>LEVEL1_DCACHE_SIZE                 32768<br>LEVEL1_DCACHE_ASSOC                8<br>LEVEL1_DCACHE_LINESIZE             64<br><br>一个cacheline == 64bytes, 总共有8路，64组，64*64*8=32768bytes是这样吗？<br>如果是这样的话，每个路就相当于一个cacheline","like_count":0,"discussions":[{"author":{"id":1360512,"avatar":"https://static001.geekbang.org/account/avatar/00/14/c2/80/6ebf32e8.jpg","nickname":"海纳","note":"","ucode":"AB9F7ADB1428D2","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":535777,"discussion_content":"对的，是啊：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1638539056,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":323810,"user_name":"linker","can_delete":false,"product_type":"c1","uid":1803259,"ip_address":"","ucode":"6C5799F2FC2C82","user_header":"https://static001.geekbang.org/account/avatar/00/1b/83/fb/621adceb.jpg","comment_is_top":false,"comment_ctime":1638170237,"is_pvip":false,"replies":[{"id":"117805","content":"不是吧。我的原文里是写cache的大小是组数，路数和cache line size的乘积。这句话你明白了吗？那么一个cache line就是64字节，我们看到总共有8路，所以算的是64组呀。我觉得这里写得还算清楚，你再看一下原文？","user_name":"作者回复","user_name_real":"编辑","uid":"1360512","ctime":1638539040,"ip_address":"","comment_id":323810,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1638170237","product_id":100094901,"comment_content":"大佬，L1 cache，一路等于64个cacheline， 这个是怎么计算出来的，有点懵？","like_count":0,"discussions":[{"author":{"id":1360512,"avatar":"https://static001.geekbang.org/account/avatar/00/14/c2/80/6ebf32e8.jpg","nickname":"海纳","note":"","ucode":"AB9F7ADB1428D2","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":535776,"discussion_content":"不是吧。我的原文里是写cache的大小是组数，路数和cache line size的乘积。这句话你明白了吗？那么一个cache line就是64字节，我们看到总共有8路，所以算的是64组呀。我觉得这里写得还算清楚，你再看一下原文？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1638539040,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":323781,"user_name":"shenglin","can_delete":false,"product_type":"c1","uid":1487222,"ip_address":"","ucode":"0F9A8243EA800A","user_header":"","comment_is_top":false,"comment_ctime":1638159573,"is_pvip":false,"replies":[{"id":"117807","content":"OK。我们第15节课也有解释，可以对照着理解一下。","user_name":"作者回复","user_name_real":"编辑","uid":"1360512","ctime":1638539081,"ip_address":"","comment_id":323781,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1638159573","product_id":100094901,"comment_content":"cache的物理介质是SRAM，存储的是主存里某些地址上的数据，buffer是主存的一部分，物理介质是DRAM，存储的是业务的缓冲数据。","like_count":0,"discussions":[{"author":{"id":1360512,"avatar":"https://static001.geekbang.org/account/avatar/00/14/c2/80/6ebf32e8.jpg","nickname":"海纳","note":"","ucode":"AB9F7ADB1428D2","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":535778,"discussion_content":"OK。我们第15节课也有解释，可以对照着理解一下。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1638539081,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":323733,"user_name":"费城的二鹏","can_delete":false,"product_type":"c1","uid":1101293,"ip_address":"","ucode":"DE768A0CC3053D","user_header":"https://static001.geekbang.org/account/avatar/00/10/cd/ed/825d84ee.jpg","comment_is_top":false,"comment_ctime":1638146402,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1638146402","product_id":100094901,"comment_content":"cache是缓存的数据，一般是完整的数据。buffer是缓冲数据，类似于看视频时，加载当前到几分钟以后的内容。<br><br>不知道这样解释对不对。","like_count":0}]}