{"id":226294,"title":"08 | 交付速度和质量问题解决了，老板说还得“省”","content":"<p>你好，我是郭忆。</p><p>在上一节课中，我们讨论了如何保障数据中台的数据质量，让数据做到“准”。我认为，除了“快”和“准”，数据中台还离不开一个“省”字。尤其是随着数据规模越来越大，成本越来越高，如果不能合理控制成本，还没等你挖掘出数据的应用价值，企业利润就已经被消耗完了。</p><p>所以，能否做到精细化的成本管理，关乎数据中台项目的成败。还是分享一个我见过的事儿。</p><p><img src=\"https://static001.geekbang.org/resource/image/ab/cf/abd782015625ed0497a401b1b2eab7cf.png?wh=854*568\" alt=\"\" title=\"某电商业务数据建设资源增长趋势（CU= 1vcpu + 4G memory）\"></p><p>这张图展示了某电商平台的大数据资源消耗增长趋势，尤其值得你关注的是，到了2019年，全年的资源规模已经达到了25000CU，全年机器预算达到了3500W。对一个在创业的企业来说，这显然是一笔不小的开支。</p><p>终于有一天，数据团队的负责人李好看（化名）就被CEO叫到了办公室，CEO问了几个问题：</p><ul>\n<li>这3500W花在什么业务上？</li>\n<li>你们做了哪些成本优化的举措，效果如何？</li>\n</ul><p>一系列的灵魂拷问，直接把李好看问懵了，他心想：团队的成本是按机器又不是数据应用核算的。在数据中台中，数据应用之间的底层数据是复用的，那具体每个数据产品或者报表花了多少钱，自己没有这样的数据啊，怎么可能知道。</p><p>可对CEO来说，这些问题很重要，因为资源总是有限的，他必须确保资源都用在战略目标的关键节点上。比如，对于电商团队，今年的核心KPI是提升单个注册会员在平台的消费额，那从老板角度来讲，他必须确保资源都投入与KPI相关业务中，例如基于数据对注册会员进行精准化营销，来提升会员在平台的消费额。</p><!-- [[[read_end]]] --><p>讲到这儿，你可以想一想，自己所在的团队是否发生过类似的事情？ 我相信，数据部门是企业的成本中心，如果要展现自己的价值，一方面是支撑好业务，获得业务的认可；另外一方面就是精简成本，为公司省钱。</p><p>所以，今天我们就把重点放在省钱上，聊一聊数据中台的精细化成本管理。</p><h2>有哪些成本的陷阱？</h2><p>在一开始建设数据中台时，你往往会关注新业务的接入，数据的整合，数据价值的挖掘上，忽略成本管控的问题，从而落入陷阱中，造成成本爆炸式的增长。所以，你有必要深入了解一下有哪些陷阱，从而尽量在日常开发中避免。</p><p>在这里，我总结了8种陷阱，其中：</p><ul>\n<li>1~3是广泛存在，但是容易被忽略的，需要你格外注意；</li>\n<li>4~8涉及数据开发中一些技能，你在开发过程中注意一下就可以了。</li>\n</ul><p>除此之外，在学习这部分知识的过程中，我建议你“知其然，更要知其所以然”，这样才能发现问题的本质，从而深入掌握解决问题的方法。</p><p><strong>第一，数据上线容易下线难。</strong></p><p><img src=\"https://static001.geekbang.org/resource/image/e5/5d/e5db0e377d41724e387a0d2fc0e8bb5d.png?wh=1058*655\" alt=\"\"></p><p>先来看一组统计数据，这是某数据中台项目，表相关的使用统计。从中你可以发现，有一半的表在30天内都没有访问，而这些表占用了26%的存储空间。如果我们把这些表的产出任务单独拎出来，在高峰期需要消耗5000Core CPU的计算资源，换算成服务器需要125台（按照一台服务器可分配CPU 40Core计算），折合成本一年接近500W。</p><p>是不是觉得自己竟然有这么多没用的数据？我经常把数据比作手机中的图片，我们总是不断地拍照，生成图片，却懒得清理，最终手机里面的存储经常不够用。</p><p>对于无法及时清理数据，数据开发其实也有苦衷。他们并不知道一个表还有哪些任务在引用，还有哪些人在查询，自然不敢停止这个表的数据加工，那造成的后果就是数据上线容易，下线难。</p><p><strong>第二，低价值的数据应用消耗了大量的资源。</strong></p><p>我们的数据看上去每天都在被访问，但究竟产出了多少价值，投入和产出是否匹配呢？作为一个数据部门，我们要问一问自己。</p><p>我们曾经有一个宽表（拥有很多列的表，经常出现在数据中台下游的汇总层数据中），算上上游加工链路的任务，每天加工这张宽表要消耗6000块钱，一年要200W，可追查后我们发现，这张宽表实际每天只有一个人在使用，还是一个运营的实习生。显然，投入和产出极不匹配。</p><p>这其实间接说明，数据部门比较关注新的数据产品带给业务的价值，却忽略了已经存在的产品或者报表是否还存在价值，最终导致低价值的应用仍然在大量消耗资源。</p><p><strong>第三，烟囱式的开发模式。</strong></p><p>烟囱式的开发不仅会带来研发效率低的问题，同时因为数据重复加工，还会存在资源浪费的问题。我们来算一笔账，一张500T的表，加工这张表，计算任务需要高峰期消耗300Core，折合7台服务器（按照一台服务器可分配CPU 40Core计算），再加上存储盘的成本(按照0.7 元/TB*天计算)，一年需要消耗40W。</p><p>而这张表每复用一次，就可以节省40W的成本。所以通过模型复用，还可以实现省钱的目的。</p><p><strong>第四，数据倾斜。</strong></p><p>数据倾斜会让任务性能变差，也会浪费大量的资源，那什么是数据倾斜呢？</p><p><img src=\"https://static001.geekbang.org/resource/image/83/c8/83bb148a5b12651be930df928d170fc8.jpg?wh=1142*1026\" alt=\"\" title=\"单Stage阶段Spark任务数据分片运行图\"></p><p>你肯定听说过木桶效应吧？一个木桶装多少水，主要取决于最短的那块板。对于一个分布式并行计算框架来说，这个效应同样存在。对于Spark计算引擎来说，它可以将海量的数据切分成不同的分片（Partition），分配到不同机器运行的任务中，进行并行计算，从而实现计算能力水平扩展。</p><p>但是整个任务的运行时长，其实取决于运行最长的那个任务。因为每个分片的数据量可能不同，每个任务需要的资源也不相同。由于不同的任务不能分配不同的资源，所以，总任务消耗资源=max{单个任务消耗的资源} * 任务数量。这样一来，数据量小的任务会消耗更多的资源，就会造成资源的浪费。</p><p>我们还是举个电商场景的例子。</p><p>假设你需要按照商户粒度统计每个商户的交易金额，此时，我们需要对订单流水表按照商户进行group by计算。在平台上，每个商户的订单交易量实际差距很大，有的订单交易量很多，有的却比较少。</p><p><img src=\"https://static001.geekbang.org/resource/image/f2/a9/f267e8c7f4d1b03ff464e349cbd98ba9.jpg?wh=1142*747\" alt=\"\"></p><p>我们利用Spark SQL完成计算过程。</p><p><img src=\"https://static001.geekbang.org/resource/image/11/0c/1152306e695043efba993f303e31720c.jpg?wh=1142*550\" alt=\"\" title=\"数据倾斜示意图\"></p><p>在上图中，任务A 读取了左边某个分片的数据，按照供应商进行聚合，然后输出给下一个Stage的B、C、D任务。</p><p>你可以看到，聚合后，B、C和D任务输入的数据量有很大的不同，B处理的数据量比C和D多，消耗的内存自然更多，假设单个Executor需要分配16G，而B、C、D不能设置不同的内存大小，所以C和D也都设置了16G。可实际上，按照C和D的数据量，只需要4G就够了。这就造成了C和D 任务资源分配的浪费。</p><p><strong>第五，数据未设置生命周期。</strong></p><p>在<a href=\"https://time.geekbang.org/column/article/224516\">06讲</a>中，我强调，一般原始数据和明细数据，会保留完整的历史数据。而在汇总层、集市层或者应用层，考虑到存储成本，数据建议按照生命周期来管理，通常保留几天的快照或者分区。如果存在大表没有设置生命周期，就会浪费存储资源。</p><p><strong>第六，调度周期不合理。</strong></p><p><img src=\"https://static001.geekbang.org/resource/image/91/52/913db7534374e4da5b2bf1a4c2f84052.png?wh=854*568\" alt=\"\"></p><p>通过这张图你可以看到，大数据任务的资源消耗有很明显的高峰和低谷效应，一般晚上12点到第二天的9点是高峰期，9点到晚上12点，是低谷期。</p><p>虽然任务有明显的高峰低谷效应，但是服务器资源不是弹性的，所以就会出现服务器在低谷期比较空闲，在高峰期比较繁忙的情况，整个集群的资源配置取决于高峰期的任务消耗。所以，把一些不必要在高峰期内运行任务迁移到低谷期运行，也可以节省资源的消耗。</p><p><strong>第七，任务参数配置。</strong></p><p>任务参数配置的不合理，往往也会浪费资源。比如在Spark中，Executor 内存设置的过大；CPU设置的过多；还有Spark 没有开启动态资源分配策略，一些已经运行完Task的Executor 不能释放，持续占用资源，尤其是遇到数据倾斜的情况，资源浪费会更加明显。</p><p><strong>第八，数据未压缩。</strong></p><p>Hadoop 的HDFS 为了实现高可用，默认数据存储3副本，所以大数据的物理存储量消耗是比较大的。尤其是对于一些原始数据层和明细数据层的大表，动辄500多T，折合物理存储需要1.5P（三副本，所以实际物理存储500*3），大约需要16台物理服务器（一台服务器可分配存储按照12*8T计算），如果不启用压缩，存储资源成本会很高。</p><p>另外，在Hive或者Spark 计算过程中，中间结果也需要压缩，可以降低网络传输量，提高Shuffer (在Hive或者Spark 计算过程中，数据在不同节点之间的传输过程)性能。</p><p>你看，我为你列举了8个典型的成本陷阱，那你可能会问了，老师，我已经中招了，该怎么办呢？ 别急，接下来我们就看一看，如何进行精细化的成本管理。</p><h2>如何实现精细化成本管理？</h2><p>我认为，成本治理应该遵循全局盘点、发现问题、治理优化和效果评估四个步骤。</p><p><img src=\"https://static001.geekbang.org/resource/image/b7/bb/b72d173eee93d56100bcc7f53da0a1bb.jpg?wh=1142*1060\" alt=\"\"></p><h3>全局资产盘点</h3><p>精细化成本管理的第一步，就是要对数据中台中，所有的数据进行一次全面盘点，基于元数据中心提供的数据血缘，建立全链路的数据资产视图。</p><p><img src=\"https://static001.geekbang.org/resource/image/fc/64/fc9f418642523cc955ba91575f240064.jpg?wh=1142*719\" alt=\"\"></p><p>从这个图中你可以看到，全链路数据资产视图的下游末端关联到了数据应用（报表：财务分析），而上游的起点是刚进入数据中台的原始数据。数据之间通过任务进行连接。</p><p>接下来，我们要计算全链路数据资产视图中，末端数据的成本和价值（末端数据就是加工链路最下游的表，例如图中TableA，Table G）。</p><p>为什么一定要从末端开始呢？ 因为中间数据，在计算价值的时候，还要考虑下游表被使用的情况，比较难计算清楚，所以我们选择从末端数据开始。这与我们下线表的顺序也是一致的，如果数据的价值很低，成本很高，我们也是从末端数据开始下线的。</p><p><strong>那么数据成本该如何计算呢？</strong></p><p>我们要对上图中财务分析报表核算成本，这个报表上游链路中涉及到a，b，c，3个任务，A，B，C，D，E，F， 6张表，那么：</p><blockquote>\n<p>这张报表的成本=3个任务加工消耗的计算资源成本+6张表消耗的存储资源的成本。</p>\n</blockquote><p>另外，需要注意的是，如果一个表被多个下游应用复用，那这个表的存储资源成本以及产出任务消耗的成本，需要分摊给多个应用。</p><p><strong>那价值又该如何计算呢？</strong></p><p><img src=\"https://static001.geekbang.org/resource/image/e4/63/e4a0117a42386ad9c8bec7a418d89563.jpg?wh=1142*346\" alt=\"\"></p><p>我们来分析一下这张图。</p><p>如果末端数据是一张应用层的表，它对接的是一个数据报表，那衡量这个数据的价值，主要是看报表的使用范围和使用频率。在计算使用范围时，通常用周活来评估，同时还要考虑不同管理级别的人权重，对于老板，他一个人的权重可以相当于1000个普通员工。</p><p>之所以这样设计，是考虑到管理级别越高，做出的商业决策影响就越大，自然这个价值也就越大。使用频率一般使用单个用户每周查看报表的次数来衡量，次数越高，说明报表价值越大。</p><p>如果末端数据对接的不是一个数据报表，而是面向特定场景的数据应用（比如我之前提到过的供应链分析决策系统，它面向的人群主要是供应链部门）。衡量这类产品的价值，主要考虑目标人群的覆盖率和直接业务价值产出。什么是直接业务价值产出呢？，在供应链决策系统中，就是通过系统自动生成的采购订单占所有采购订单的比例。</p><p>除此之外，末端数据，可能还是一张集市层的表，它主要用于提供给分析师做探索式查询。这类表的价值主要看它被哪些分析师使用，使用频率如何。同样，在使用范围评估时，要对分析师按照级别进行加权。</p><h3>发现问题</h3><p>全局盘点，为我们发现问题提供了数据支撑，而你需要重点关注下面三类问题：</p><ul>\n<li>持续产生成本，但是已经没有使用的末端数据（“没有使用”一般指30天内没有访问）；</li>\n<li>数据应用价值很低，成本却很高，这些数据应用上游链路上的所有相关数据；</li>\n<li>高峰期高消耗的数据。</li>\n</ul><p>那么为什么你要关注这三类数据呢？</p><ul>\n<li>其实第一类就是没有使用，但一直在消耗成本的表，对应的就是我提到的陷阱1。</li>\n<li>第二类其实就是低价值产出，高成本的数据应用，对应的是陷阱2。</li>\n<li>第三类高成本的数据，对应的就是陷阱4～8。</li>\n</ul><p><img src=\"https://static001.geekbang.org/resource/image/86/36/86978c0d60e6cc050b1b9fc512221b36.png?wh=2239*1376\" alt=\"\"></p><p>陷阱3实际是在第6节模型设计中解决的。</p><h3>治理优化</h3><p>针对这三类问题，我们需要制订相应的策略。</p><p>对于第一类问题，应该对表进行下线。 数据下线要谨慎，你可以参考这张数据下线的执行过程图：</p><p><img src=\"https://static001.geekbang.org/resource/image/9a/3b/9a782afd76ce95cab7e224afb97e123b.jpg?wh=1142*635\" alt=\"\"></p><p>末端数据删除后，原先末端数据的上游数据会成为新的末端数据，同样还要按发现问题到治理优化进行重复，直到所有的末端数据都不满足下线策略为止。</p><p>对第二类问题，我们需要按照应用粒度评估应用是否还有存在的必要。对于报表，可以按照30天内没有访问的应用自动下线的策略，先对报表进行销毁，然后对报表上游的表进行下线，如果该表还被其他的应用引用，就不能下线。<strong>下线步骤可以参考前面的下线步骤。</strong></p><p>第三类问题，主要是针对高消耗的数据，又具体分为产出数据的任务高消耗和数据存储高消耗。对于产出任务高消耗，首先要考虑是不是数据倾斜。具体怎么判断呢？其实你可以通过MR或者Spark日志中，Shuffer的数据量进行判断。如果有某一个Task 数据量非常大，其他的很少，就可以判定出现了数据倾斜。</p><p><img src=\"https://static001.geekbang.org/resource/image/bb/4a/bb6bff0893077c370c812911684ed24a.png?wh=2655*1451\" alt=\"\" title=\"图 Spark task shuffer records\"></p><p><img src=\"https://static001.geekbang.org/resource/image/ce/62/ce3feb95851ef24d662127dae42cf062.png?wh=2654*1421\" alt=\"\" title=\"图 MR reduce task records\"></p><p>如果出现数据倾斜，该如何处理呢？</p><p>数据倾斜的处理方法有很多，不同的场景有一些适用的解决方案：比如在一些大表和小表关联时，Key 分布不均造成的数据倾斜，可以使用mapjoin的方式解决；另外还有一些比较通用的处理方式，例如把热点的Key 进行单独的处理，然后对剩下的Key进行处理，然后对结果进行并集。</p><p>因为它不是本文的重点，所以这里就不再详细展开，之前有一篇美团的文章，对数据倾斜有比较深入的分析，推荐给你做课下学习的<a href=\"https://tech.meituan.com/2016/05/12/spark-tuning-pro.html\">资料。</a></p><p>除了数据倾斜，我们还应该检查任务的配置参数。例如对于Spark 执行引擎，Executor 个数是否开的过大，executor-cores和executor-memory是否开的过多，利用率比较低。一般来说，executors-memorty 设置为4G-8G为宜，executor-cores设置为2-4个为宜（这是我们实践过利用率最高的配置选项）。</p><p>另外，你还要考虑任务是否真的有必要在高峰期执行，可以根据集群的负载情况，尽量将任务迁移到非高峰期执行，我将这个步骤称为“削峰填谷”。</p><p>上面几点是产出任务高消耗的情况，那么对于存储消耗比较大的任务，你首先要考虑是否要压缩，尤其是对于原始数据层和明细数据层，建议压缩，压缩的方式有这样几种：</p><p><img src=\"https://static001.geekbang.org/resource/image/9c/fd/9c17d6c8975d68ca3679a201fd05dcfd.jpg?wh=1142*410\" alt=\"\"></p><p>整体来看，对于小文件的压缩，不考虑split，gzip比较合适；对于大文件，推荐使用lzo，支持split，在保证压缩效率的前提下，有着相对稳定的压缩比。</p><p>除此之外，还需要考虑生命周期是否设置：</p><ul>\n<li>对于ODS原始数据层和DWD 明细数据层，比较适合用永久保留的策略；</li>\n<li>对于一些商品、用户维表，可以考虑3年或者5年的保留策略。</li>\n</ul><p>整体上，底层表都是长期保留的。所以你的关注重点应该是汇总层以上的表（包括汇总层），一般可以根据数据的重要性，制订7天，1个月的保留策略。</p><h3>治理效果评估</h3><p>现在，通过我介绍的这几个方法，你已经能够节省大量的资源消耗，那如何量化我们的治理成果呢？</p><p>五个字：省了多少钱。不过，如果直接拿服务器的数量来衡量，其实并不能真实地反应治理效果，因为还要考虑业务增长的原因。业务不是停止不动的，所以你可以围绕任务和数据的成本考虑这样几点：</p><ul>\n<li>下线了多少任务和数据；</li>\n<li>这些任务每日消耗了多少资源；</li>\n<li>数据占用了多少存储空间。</li>\n</ul><p>拿这些资源来计算成本，这样就能够算出来省了多少钱。我还是拿本节课开始的例子来看，任务A 运行时长 3个小时，在运行过程中，共消耗5384503 cpu*s，37007892 GB *s, 假设我们1个CU （1 cpu， 4g memeory）一年是1300元成本，折合每天为3.5元（计算公式为1300/365）。</p><p><strong>这里需要特别强调，</strong>不论是优化或者下线任务，我们只统计高峰时间段内，因为优化低峰时间，并不能实际节省资源。</p><p>高峰时间段为8个小时，那折合每秒的费用为0.00012153, 那该任务的费用为max{5384503*0.00012153, 37007892/4 * 0.00012153} = max{654, 1124} = 1124 。那下线这个任务后，就节省1124元，再加上表 A占用的存储空间大小乘以每GB的成本，就可以得出数据表A下线节省的费用。</p><h2>成本治理中心</h2><p>成本治理不是一劳永逸的工作，需要持之以恒，不断发现问题，然后治理优化，建立长久运行机制的前提是必须降低成本治理的门槛，接下来，看一下网易的一个成本治理的平台，EasyCost。<br>\n<img src=\"https://static001.geekbang.org/resource/image/94/8d/94acdfab6f168b955d16109748abed8d.png?wh=2696*1579\" alt=\"\"></p><p>系统提供了数据诊断的功能，可以按照访问时间、访问频率、关联的应用，设置下线策略，支持一键灰度下线，大幅提高了管理的效率。</p><p><img src=\"https://static001.geekbang.org/resource/image/04/f4/047cef40dba74b20b9d97f31d92216f4.png?wh=2657*1578\" alt=\"\"></p><p>通过介绍EasyCost，我想告诉你的是，今天的内容，其实可以通过系统化的方式沉淀到产品中，然后通过产品提高管理的效率，从而实现治理机制的长久落地。</p><h2>课堂总结</h2><p>总的来说，通过数据中台，一方面你可以获得大数据作为资产中心带来的红利，另一方面，你也有可能陷入成本的深渊，为野蛮增长的大数据费用买单。</p><p>今天这节课，我从常见的8个成本陷阱入手，带你分析了可能造成成本浪费的原因，然后介绍了精细化成本管理的方法，在最后，我想再强调几个你可能忽略的点：</p><ul>\n<li>\n<p>无用数据的下线应该从全链路数据资产视图的末端入手，然后抽丝剥茧，一层一层，向数据加工链路的上游推进。</p>\n</li>\n<li>\n<p>应用层表的价值应该以数据应用的价值来衡量，对于低价值产出的应用，应该以应用为粒度进行下线。</p>\n</li>\n<li>\n<p>对高消耗任务的优化只要关注集群高峰期的任务，项目的整体资源消耗只取决于高峰期的任务消耗，当然，如果你使用的是公有云的资源，可以高峰和低谷实施差异化的成本结算，那低谷期的也是要关注的。</p>\n</li>\n</ul><p><img src=\"https://static001.geekbang.org/resource/image/c2/b7/c233339ec939674b3e1517d69d7b9bb7.jpg?wh=1142*857\" alt=\"\"></p><h2>思考时间</h2><p>在数据中台的集市层，会存在一些大的宽表，这些宽表可能存在几百个字段，上游可能有数十个表，如果要计算这个表的成本会非常高。在这个表中，字段的访问频率是不相同，有的字段频率很高，有的字段频率很低，如果要对这张宽表做优化，你觉得如何来做呢?</p><p>最后感谢你的阅读，如果这节课让你有所收获，也欢迎你分享给更多的朋友。</p>","comments":[{"had_liked":false,"id":208431,"user_name":"大北","can_delete":false,"product_type":"c1","uid":1201843,"ip_address":"","ucode":"A1125F0CA4E75D","user_header":"https://static001.geekbang.org/account/avatar/00/12/56/b3/29c814af.jpg","comment_is_top":false,"comment_ctime":1587356971,"is_pvip":true,"replies":[{"id":"78993","content":"思路挺好的~可以通过字段血缘，获取字段的访问热度~<br><br>感谢你的回答~期待与你在留言区再次相遇~","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1588160132,"ip_address":"","comment_id":208431,"utype":1}],"discussion_count":1,"race_medal":0,"score":"53126964523","product_id":100049101,"comment_content":"根据字段访问频率和指标时效性，通常优化大宽表的思路有：<br>一、优化访问频率低并且时效性低的字段：对宽表的任务进行拆分，将这些字段拆出来一个或多个任务单独跑，根据实际情况设置每个任务执行计划cron的频率。这些任务会生成临时变，保留最近的数据。在宽表任务中进行字段合并union all，拆出来的字段就不需要再计算。<br>二、优化时效性高的字段，例如客流量越实时越好。同样拆出来单独任务跑数据，生成临时表，设置高频率任务执行计划，根据一致的维度，对宽表进行字段更新。","like_count":11,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492453,"discussion_content":"思路挺好的~可以通过字段血缘，获取字段的访问热度~\n\n感谢你的回答~期待与你在留言区再次相遇~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588160132,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":223055,"user_name":"Nick","can_delete":false,"product_type":"c1","uid":1136345,"ip_address":"","ucode":"2E8CF62EBEBAAB","user_header":"https://static001.geekbang.org/account/avatar/00/11/56/d9/66aa42d6.jpg","comment_is_top":false,"comment_ctime":1590990713,"is_pvip":false,"replies":[{"id":"83569","content":"感谢你的认可啦，其实有写书的想法，我连名字都想好了，《网易数据中台实践之路》，只是想拿极客时间先练练手~祝好~","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1592222543,"ip_address":"","comment_id":223055,"utype":1}],"discussion_count":4,"race_medal":0,"score":"31655761785","product_id":100049101,"comment_content":"收货良多，简直太赞了~<br>如果郭忆出实体书我第一时间购买😊","like_count":8,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":497000,"discussion_content":"感谢你的认可啦，其实有写书的想法，我连名字都想好了，《网易数据中台实践之路》，只是想拿极客时间先练练手~祝好~","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1592222543,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2368247,"avatar":"https://static001.geekbang.org/account/avatar/00/24/22/f7/616e5fd0.jpg","nickname":"NULL","note":"","ucode":"2B0089F4857C07","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":335157,"discussion_content":"哈哈哈，同感，希望尽快出书","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1608107783,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1124637,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJoiar0OoeEdc1l1UiaKKLjKblibqda3fxzibXibiahMqsvAanS3Gzu1CF4xupc6wPzmbpQqr2MMWkGeXeA/132","nickname":"vkingnew","note":"","ucode":"16E37A23BFE579","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":307949,"discussion_content":"啥时候上市啊？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1600791933,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1352737,"avatar":"https://static001.geekbang.org/account/avatar/00/14/a4/21/fda2ae09.jpg","nickname":"唐永军","note":"","ucode":"F4879648F85B8B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":302666,"discussion_content":"同感，希望尽快出书吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1599005441,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":208555,"user_name":"Geek_f071bc","can_delete":false,"product_type":"c1","uid":1945778,"ip_address":"","ucode":"B98A0BD2B4620A","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/zgnl95XDvXnicWoGibeAdicWrBYj8UgYGAayxcrJcaFLSbENX402AsVCtRibg3G1tuWrpZwymicribdug9PaHMeGK1Xw/132","comment_is_top":false,"comment_ctime":1587380469,"is_pvip":false,"replies":[{"id":"78982","content":"你好，yarn 上面的任务日志中都有相关的信息，通过解析日志可以获取的到任务每个application消耗的资源。<br><br>哪些用户使用了哪些表，可以通过数据血缘和执行时用户的keytab建立关系，或者再简单一点，再提供SQL查询的系统中，记录用户和SQL的关系。但是这样可能覆盖率不全。<br><br>感谢你的阅读~","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1588158588,"ip_address":"","comment_id":208555,"utype":1}],"discussion_count":3,"race_medal":0,"score":"14472282357","product_id":100049101,"comment_content":"老师，请问下。怎么获取到高峰时期一个任务使用了多少核cpu，多少G内存资源的数据?如何获取哪些用户使用了哪些表？","like_count":4,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492509,"discussion_content":"你好，yarn 上面的任务日志中都有相关的信息，通过解析日志可以获取的到任务每个application消耗的资源。\n\n哪些用户使用了哪些表，可以通过数据血缘和执行时用户的keytab建立关系，或者再简单一点，再提供SQL查询的系统中，记录用户和SQL的关系。但是这样可能覆盖率不全。\n\n感谢你的阅读~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588158588,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1050677,"avatar":"https://static001.geekbang.org/account/avatar/00/10/08/35/9e337d35.jpg","nickname":"邓","note":"","ucode":"B50430A31BB817","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":243052,"discussion_content":"yarn界面会显示消耗多少内存秒和cpu 核数秒，仔细看下","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587518235,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":1050677,"avatar":"https://static001.geekbang.org/account/avatar/00/10/08/35/9e337d35.jpg","nickname":"邓","note":"","ucode":"B50430A31BB817","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":252843,"discussion_content":"bingo！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588201949,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":243052,"ip_address":""},"score":252843,"extra":""}]}]},{"had_liked":false,"id":208305,"user_name":"leslie","can_delete":false,"product_type":"c1","uid":1324255,"ip_address":"","ucode":"798E7C1CC98CC2","user_header":"https://static001.geekbang.org/account/avatar/00/14/34/df/64e3d533.jpg","comment_is_top":false,"comment_ctime":1587334982,"is_pvip":false,"replies":[{"id":"78994","content":"你好，看到你也遇到了一样的问题。<br><br>拆表是解决方案，可以根据字段血缘，按照字段的使用热度进行拆分。<br><br>关于应用层的修改，可以通过数据服务的逻辑模型解决。<br><br>感谢你的提问，希望能够对你的日常工作提供一些思路~","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1588160196,"ip_address":"","comment_id":208305,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14472236870","product_id":100049101,"comment_content":"其实最大的问题不只是表过于宽，而是这种表的做了所有重负荷的操作且索引的效率很难平衡到最合理，甚至设计方面就有缺陷，这才是后面处理起来最麻烦的事情。<br>关于老师今天课程的问题其实有一个最简单的方式-分表，不过分表必然带来程序端大量的改动这是无法避免但是可能是最快捷实际的方式。<br>可能最近的课程刚好是我看到和碰到的一些典型问题，有时确实觉得处理起来很棘手；中台其实就是在解决各种棘手的问题。<br>谢谢老师今天的分享，期待后续课程。","like_count":3,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492410,"discussion_content":"你好，看到你也遇到了一样的问题。\n\n拆表是解决方案，可以根据字段血缘，按照字段的使用热度进行拆分。\n\n关于应用层的修改，可以通过数据服务的逻辑模型解决。\n\n感谢你的提问，希望能够对你的日常工作提供一些思路~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588160196,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":213164,"user_name":"你好","can_delete":false,"product_type":"c1","uid":1945987,"ip_address":"","ucode":"F6ED43EF5FD164","user_header":"https://static001.geekbang.org/account/avatar/00/1d/b1/83/c6dd1322.jpg","comment_is_top":false,"comment_ctime":1588319359,"is_pvip":false,"replies":[{"id":"80220","content":"<br>你好，一般lzo用的比较多，支持 split，在保证压缩效率的前提下，有着相对稳定的压缩比。<br><br>","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1589370804,"ip_address":"","comment_id":213164,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10178253951","product_id":100049101,"comment_content":"老师，还有一个问题，<br>网易的ods和dwd分别是什么压缩格式，parquit还是lzo？考虑压缩率和分片了吗，谢谢","like_count":2,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493697,"discussion_content":"\n你好，一般lzo用的比较多，支持 split，在保证压缩效率的前提下，有着相对稳定的压缩比。\n\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589370804,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":210674,"user_name":"Olivia_饶","can_delete":false,"product_type":"c1","uid":1779565,"ip_address":"","ucode":"CD2CEC066C914E","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/AoXC8Dwxrs9cia2MFhHjvnjSJMbs0CmxqGR7qJQpwbWJ3M55VKiatlNRN5LF1X2uYTA42nbn3GicJd6JaKy8zaVbA/132","comment_is_top":false,"comment_ctime":1587805889,"is_pvip":false,"replies":[{"id":"78440","content":"你好~ 感谢你的认可，希望对你有所帮助，能够解决你的问题。<br><br>期待在留言区与你交流~","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1587826659,"ip_address":"","comment_id":210674,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10177740481","product_id":100049101,"comment_content":"满满的干货","like_count":2,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493081,"discussion_content":"你好~ 感谢你的认可，希望对你有所帮助，能够解决你的问题。\n\n期待在留言区与你交流~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587826659,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":208293,"user_name":"蒋良俊","can_delete":false,"product_type":"c1","uid":1596908,"ip_address":"","ucode":"E1FA95BE36D110","user_header":"https://static001.geekbang.org/account/avatar/00/18/5d/ec/3c78de6e.jpg","comment_is_top":false,"comment_ctime":1587318072,"is_pvip":false,"replies":[{"id":"77861","content":"感谢你的认可和鼓励，希望对你有帮助，期望与你再次相遇。","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1587355197,"ip_address":"","comment_id":208293,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10177252664","product_id":100049101,"comment_content":"非常实用的经验，谢谢分享。","like_count":2,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492406,"discussion_content":"感谢你的认可和鼓励，希望对你有帮助，期望与你再次相遇。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587355197,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":220533,"user_name":"Samlam","can_delete":false,"product_type":"c1","uid":1486147,"ip_address":"","ucode":"0476A38604EB6B","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLP2UJppatJRLr9R9BvS4UUyGkX9IG2S2wHlNoyickYrM5ul8THrCp2LAB5CKmGDAlOmUvHNNwOMUQ/132","comment_is_top":false,"comment_ctime":1590283245,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5885250541","product_id":100049101,"comment_content":"老师，对于写hive，如果有一张处理后的大表（上亿行）会被重复调用，那么是放在 with中快，还是直接把这张表落地到tmp库，然后后续被下面的执行过程调用快呢？","like_count":1},{"had_liked":false,"id":213161,"user_name":"你好","can_delete":false,"product_type":"c1","uid":1945987,"ip_address":"","ucode":"F6ED43EF5FD164","user_header":"https://static001.geekbang.org/account/avatar/00/1d/b1/83/c6dd1322.jpg","comment_is_top":false,"comment_ctime":1588319047,"is_pvip":false,"replies":[{"id":"80214","content":"你好<br>1. 不重复， 你说的接入层，是指原始数据ODS嘛？ ODS是贴源的数据，就是业务系统是什么样子的，到数据中台中就是什么样子的。DWD 是明细数据，清洗后的数据，比如一些非法的数据格式已经过滤掉了，另外还聚合了一些基本的维度信息。所以ODS和DWD 并不存在重复的问题。<br><br>2. 汇总层的数据一般不保留全部历史数据，归档一般在明细数据层保存完整的历史数据。<br><br>感谢你的提问~","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1589369590,"ip_address":"","comment_id":213161,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5883286343","product_id":100049101,"comment_content":"老师，<br>1，对于接入层和明细层这两层都全量存储是不是有点重复？<br>2，汇总层存储周期设置为一月或一年，那有必要添加一个归档层吗？<br>网易是咋设置的？<br>谢谢","like_count":1,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493696,"discussion_content":"你好\n1. 不重复， 你说的接入层，是指原始数据ODS嘛？ ODS是贴源的数据，就是业务系统是什么样子的，到数据中台中就是什么样子的。DWD 是明细数据，清洗后的数据，比如一些非法的数据格式已经过滤掉了，另外还聚合了一些基本的维度信息。所以ODS和DWD 并不存在重复的问题。\n\n2. 汇总层的数据一般不保留全部历史数据，归档一般在明细数据层保存完整的历史数据。\n\n感谢你的提问~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589369590,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":209195,"user_name":"邓","can_delete":false,"product_type":"c1","uid":1050677,"ip_address":"","ucode":"B50430A31BB817","user_header":"https://static001.geekbang.org/account/avatar/00/10/08/35/9e337d35.jpg","comment_is_top":false,"comment_ctime":1587518547,"is_pvip":false,"replies":[{"id":"78995","content":"你好，说的思路是对的，这个要根据字段血缘，计算字段的访问热度解决~","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1588160219,"ip_address":"","comment_id":209195,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5882485843","product_id":100049101,"comment_content":"我觉得要根据计算成本和使用频度把表拆开成多张表，使用频度低计算成本高的字段独拆出来，方便计算成本和降低风险","like_count":1,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492735,"discussion_content":"你好，说的思路是对的，这个要根据字段血缘，计算字段的访问热度解决~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588160219,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":209177,"user_name":"Jie","can_delete":false,"product_type":"c1","uid":1045078,"ip_address":"","ucode":"AB94041E548FEB","user_header":"https://static001.geekbang.org/account/avatar/00/0f/f2/56/c39046c0.jpg","comment_is_top":false,"comment_ctime":1587517423,"is_pvip":false,"replies":[{"id":"78152","content":"对的，离线和在线混部是未来的一个重要方向，可以进一步提升资源的利用率。但是也面临不少挑战，因为离线很多任务都需要SLA保障的，如果根据服务负载随时Kill离线任务，对于离线数据的保障，有很大的挑战。<br><br>感谢你的阅读~ ","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1587523624,"ip_address":"","comment_id":209177,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5882484719","product_id":100049101,"comment_content":"容器化后在线实时和离线批量混合部署可以优化高低峰资源配置","like_count":1,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492730,"discussion_content":"对的，离线和在线混部是未来的一个重要方向，可以进一步提升资源的利用率。但是也面临不少挑战，因为离线很多任务都需要SLA保障的，如果根据服务负载随时Kill离线任务，对于离线数据的保障，有很大的挑战。\n\n感谢你的阅读~ ","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587523624,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":208683,"user_name":"Limpidzhao","can_delete":false,"product_type":"c1","uid":1162079,"ip_address":"","ucode":"42DE85A6CF638F","user_header":"https://static001.geekbang.org/account/avatar/00/11/bb/5f/1f374a9b.jpg","comment_is_top":false,"comment_ctime":1587400914,"is_pvip":false,"replies":[{"id":"78981","content":"你好，看到是一个有钱企业。<br><br>其实呢，即使再有钱，也得考虑机器用的合不合理的问题，因为大数据的话，一个表很大，对资源的浪费也很大。如果你不管，很快，就买的机器就不够用了。<br><br>性能和成本也是相对的，我曾经遇到一些企业用户，用impala直接查原始数据，一个SQL几亿条记录查询，你说它能快了么，他还反怨你说，你提供的查询引擎，你就应该能快啊！ 再快也需要资源，资源不是无限的，所以，还是要平衡二者，尽量引导用户使用加工好的数据，汇总数据，这就意味着你的汇总层数据的建设要足够的完善，这个可以通过查询的覆盖率来统计，也可以把一些经常查询的底层明细表，反推汇总层数据的建设，来不断晚上汇总数据的建设。<br><br>我还是那句话，资源不可能无限扩展，在数据建设中，还是要尽量引导用户更合理的使用数据。<br><br>感谢你的阅读~","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1588158469,"ip_address":"","comment_id":208683,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5882368210","product_id":100049101,"comment_content":"对于银行的数据中台项目，成本并不是考虑的重点，指标的全面性和查询的性能是关键，请问老师，在这种情况下如何兼顾成本和性能之间的关系？","like_count":1,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492576,"discussion_content":"你好，看到是一个有钱企业。\n\n其实呢，即使再有钱，也得考虑机器用的合不合理的问题，因为大数据的话，一个表很大，对资源的浪费也很大。如果你不管，很快，就买的机器就不够用了。\n\n性能和成本也是相对的，我曾经遇到一些企业用户，用impala直接查原始数据，一个SQL几亿条记录查询，你说它能快了么，他还反怨你说，你提供的查询引擎，你就应该能快啊！ 再快也需要资源，资源不是无限的，所以，还是要平衡二者，尽量引导用户使用加工好的数据，汇总数据，这就意味着你的汇总层数据的建设要足够的完善，这个可以通过查询的覆盖率来统计，也可以把一些经常查询的底层明细表，反推汇总层数据的建设，来不断晚上汇总数据的建设。\n\n我还是那句话，资源不可能无限扩展，在数据建设中，还是要尽量引导用户更合理的使用数据。\n\n感谢你的阅读~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588158469,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1369756,"avatar":"https://wx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIopdUJmtgpsr9GibAibcZgS7h23P4FrgBfed3WveI4b4f8Vl2JjibhCzib9Y8Vs2M1PGQr7cwoKADxZQ/132","nickname":"秦道","note":"","ucode":"BE195C09BD14A5","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":309000,"discussion_content":"同意，根据历史查询涉及良好的轻度汇聚层，提高查询效率，节省成本","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1601168366,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":208660,"user_name":"aof","can_delete":false,"product_type":"c1","uid":1062864,"ip_address":"","ucode":"5815D63C4926BC","user_header":"https://static001.geekbang.org/account/avatar/00/10/37/d0/26975fba.jpg","comment_is_top":false,"comment_ctime":1587396514,"is_pvip":false,"replies":[{"id":"78980","content":"看来那篇文章对你感触很深，很好的一篇文章。<br><br>关于思考题，其实可以根据字段血缘，解析出不同字段的使用情况，将高频和低频，甚至不用的字段进行拆分。这个是一个比较好的解决方式。<br><br>感谢你的阅读@aof","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1588158212,"ip_address":"","comment_id":208660,"utype":1}],"discussion_count":7,"race_medal":0,"score":"5882363810","product_id":100049101,"comment_content":"那篇关于数据倾斜的文章，之前读过好几遍，确实很经典，也很有参考价值！<br><br>思考题：可以通过列式存储(比如parquet)来优化，列式存储在查询的时候只会加载指定的列(不过一般情况下，保存表都会用列式存储的吧)。如果可以拆分的话，可以考虑拆分成两个小宽表","like_count":1,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492567,"discussion_content":"看来那篇文章对你感触很深，很好的一篇文章。\n\n关于思考题，其实可以根据字段血缘，解析出不同字段的使用情况，将高频和低频，甚至不用的字段进行拆分。这个是一个比较好的解决方式。\n\n感谢你的阅读@aof","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588158212,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1945987,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/b1/83/c6dd1322.jpg","nickname":"你好","note":"","ucode":"F6ED43EF5FD164","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":254363,"discussion_content":"我认为，列式存储不适合存储宽表。。。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588318554,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1062864,"avatar":"https://static001.geekbang.org/account/avatar/00/10/37/d0/26975fba.jpg","nickname":"aof","note":"","ucode":"5815D63C4926BC","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1945987,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/b1/83/c6dd1322.jpg","nickname":"你好","note":"","ucode":"F6ED43EF5FD164","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":255075,"discussion_content":"那应该用什么格式来存储呢？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588371531,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":254363,"ip_address":""},"score":255075,"extra":""}]},{"author":{"id":1104958,"avatar":"https://static001.geekbang.org/account/avatar/00/10/dc/3e/abb7bfe3.jpg","nickname":"小崔","note":"","ucode":"4E537416787752","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":244501,"discussion_content":"哦哦，我看到了，美团的那篇是么","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587606500,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1104958,"avatar":"https://static001.geekbang.org/account/avatar/00/10/dc/3e/abb7bfe3.jpg","nickname":"小崔","note":"","ucode":"4E537416787752","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":244147,"discussion_content":"请问是哪篇文章？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587569397,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":2,"child_discussions":[{"author":{"id":1062864,"avatar":"https://static001.geekbang.org/account/avatar/00/10/37/d0/26975fba.jpg","nickname":"aof","note":"","ucode":"5815D63C4926BC","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1104958,"avatar":"https://static001.geekbang.org/account/avatar/00/10/dc/3e/abb7bfe3.jpg","nickname":"小崔","note":"","ucode":"4E537416787752","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":244269,"discussion_content":"就是老师推荐的那一篇a","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587571891,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":244147,"ip_address":""},"score":244269,"extra":""},{"author":{"id":1104958,"avatar":"https://static001.geekbang.org/account/avatar/00/10/dc/3e/abb7bfe3.jpg","nickname":"小崔","note":"","ucode":"4E537416787752","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1062864,"avatar":"https://static001.geekbang.org/account/avatar/00/10/37/d0/26975fba.jpg","nickname":"aof","note":"","ucode":"5815D63C4926BC","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":244500,"discussion_content":"是在本篇里推荐的么？我仔细谈了下数据倾斜的部分，没有看到推荐篇目啊。方便告知一下么","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587606425,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":244269,"ip_address":""},"score":244500,"extra":""}]}]},{"had_liked":false,"id":347444,"user_name":"汤姆猫","can_delete":false,"product_type":"c1","uid":1157226,"ip_address":"","ucode":"1CA5D0582BBF61","user_header":"https://static001.geekbang.org/account/avatar/00/11/a8/6a/18d8f64a.jpg","comment_is_top":false,"comment_ctime":1654046086,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1654046086","product_id":100049101,"comment_content":"大宽表就是为了串联多个主题之间的数据，方便分析师或olap的使用，而不用每次都进行关联，这才是宽表存在的价值呀！<br>为何还要进行字段热度拆表呢？如果使用场景只用部分字段，直接用宽表上游对应的主题表即可吧？<br>","like_count":0},{"had_liked":false,"id":261932,"user_name":"bin","can_delete":false,"product_type":"c1","uid":2223272,"ip_address":"","ucode":"7E392576D7711A","user_header":"https://static001.geekbang.org/account/avatar/00/21/ec/a8/963624d4.jpg","comment_is_top":false,"comment_ctime":1605582143,"is_pvip":true,"discussion_count":1,"race_medal":0,"score":"1605582143","product_id":100049101,"comment_content":"郭忆老师：<br>关于计算出末端表使用的计算资源，通过血缘进行查询即可，但是往往血缘是比较复杂，存在递归查询的逻辑，那你们一般实现是怎么去做的呢？","like_count":0,"discussions":[{"author":{"id":1497221,"avatar":"https://static001.geekbang.org/account/avatar/00/16/d8/85/f31e8841.jpg","nickname":"大魔王or","note":"","ucode":"2E3DFD4E90FF6B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":391605,"discussion_content":"可以了解一下图计算","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1630548797,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":258411,"user_name":"jonathan","can_delete":false,"product_type":"c1","uid":1011736,"ip_address":"","ucode":"F9A44BDD366304","user_header":"https://static001.geekbang.org/account/avatar/00/0f/70/18/abb7bfe3.jpg","comment_is_top":false,"comment_ctime":1604416260,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1604416260","product_id":100049101,"comment_content":"收获很大，本篇文章我的收获是：要有成本意识，数据价值意识。这个应该是之前老师在前文提到的ROI","like_count":0},{"had_liked":false,"id":245598,"user_name":"唐永军","can_delete":false,"product_type":"c1","uid":1352737,"ip_address":"","ucode":"F4879648F85B8B","user_header":"https://static001.geekbang.org/account/avatar/00/14/a4/21/fda2ae09.jpg","comment_is_top":false,"comment_ctime":1599005709,"is_pvip":false,"replies":[{"id":"90672","content":"感谢你的认可，希望可以对你的工作有帮助。","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1599476892,"ip_address":"","comment_id":245598,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1599005709","product_id":100049101,"comment_content":"写的很具体，很实用，可操作性很强。<br>谢谢郭老师了","like_count":0,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":504926,"discussion_content":"感谢你的认可，希望可以对你的工作有帮助。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1599476892,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":241422,"user_name":"追梦","can_delete":false,"product_type":"c1","uid":1183831,"ip_address":"","ucode":"54C6E76E8FE033","user_header":"https://static001.geekbang.org/account/avatar/00/12/10/57/1adfd4f7.jpg","comment_is_top":false,"comment_ctime":1597289669,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1597289669","product_id":100049101,"comment_content":"对于 ODS 原始数据层和 DWD 明细数据层，比较适合用永久保留的策略；<br>老师，请教一下，这两层都是全量快照分区吗？如果不是，什么样的存储策略更好呢","like_count":0},{"had_liked":false,"id":215533,"user_name":"XiangJiawei","can_delete":false,"product_type":"c1","uid":1324641,"ip_address":"","ucode":"AAC11557A3477B","user_header":"https://static001.geekbang.org/account/avatar/00/14/36/61/8863e18c.jpg","comment_is_top":false,"comment_ctime":1589011995,"is_pvip":true,"replies":[{"id":"80233","content":"你好， 是的，数据中台的成本管理，也是由易到难，你说的把低价值的数据下线，这是第一步，低价值其实也要分，是没有使用，成本比较高，还是低频使用。<br><br>对表进行拆分，属于高级阶段了。<br>","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1589373535,"ip_address":"","comment_id":215533,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1589011995","product_id":100049101,"comment_content":"这个应该是针对客户的数据利用率已经非常高的场景了，可以去选择性的下线；而对于一个刚刚建立的数据中台，我的理解是要想办法把利用率低的数据识别出来，找到业务价值让业务部门把数据用起来。","like_count":0,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":494468,"discussion_content":"你好， 是的，数据中台的成本管理，也是由易到难，你说的把低价值的数据下线，这是第一步，低价值其实也要分，是没有使用，成本比较高，还是低频使用。\n\n对表进行拆分，属于高级阶段了。\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589373535,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":210677,"user_name":"Olivia_饶","can_delete":false,"product_type":"c1","uid":1779565,"ip_address":"","ucode":"CD2CEC066C914E","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/AoXC8Dwxrs9cia2MFhHjvnjSJMbs0CmxqGR7qJQpwbWJ3M55VKiatlNRN5LF1X2uYTA42nbn3GicJd6JaKy8zaVbA/132","comment_is_top":false,"comment_ctime":1587806060,"is_pvip":false,"replies":[{"id":"78984","content":"嗯，对的，拆分的原则，最好是以字段血缘来判断，每个字段的访问热度，然后把无用的字段也可以去掉。<br><br>感谢你的阅读~","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1588158846,"ip_address":"","comment_id":210677,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1587806060","product_id":100049101,"comment_content":"我们目前也遇到这类问题比较多,咱们的解决办法是通过拆成小窄表的方法来做","like_count":0,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":493082,"discussion_content":"嗯，对的，拆分的原则，最好是以字段血缘来判断，每个字段的访问热度，然后把无用的字段也可以去掉。\n\n感谢你的阅读~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588158846,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":209248,"user_name":"张振华","can_delete":false,"product_type":"c1","uid":1201810,"ip_address":"","ucode":"292EFD886FC55A","user_header":"https://static001.geekbang.org/account/avatar/00/12/56/92/5cea89e6.jpg","comment_is_top":false,"comment_ctime":1587523439,"is_pvip":true,"replies":[{"id":"79004","content":"你好，数据屏幕？打错了吧？是数据中台？<br><br>我们是通过数据传输中心同步的， 支持全量同步和增量同步两种方式，还支持实时和批量。<br><br>对于全量的同步，如果出错的话，可以单个线程重试解决。对于增量同步，根据checkpoint重新拉就可以了。<br><br>感谢你的阅读~","user_name":"作者回复","user_name_real":"郭忆","uid":"1319022","ctime":1588161146,"ip_address":"","comment_id":209248,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1587523439","product_id":100049101,"comment_content":"老师，从业务数据库中把源数据导入到数据屏幕中，这个数据同步的过程是怎么处理的，是定时全量同步，还是增量同步，如果中间出问题了，怎么处理？有没有类似的方案，推荐下","like_count":0,"discussions":[{"author":{"id":1319022,"avatar":"https://static001.geekbang.org/account/avatar/00/14/20/6e/ad4dac0a.jpg","nickname":"郭忆","note":"","ucode":"496AEB07A40140","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":492748,"discussion_content":"你好，数据屏幕？打错了吧？是数据中台？\n\n我们是通过数据传输中心同步的， 支持全量同步和增量同步两种方式，还支持实时和批量。\n\n对于全量的同步，如果出错的话，可以单个线程重试解决。对于增量同步，根据checkpoint重新拉就可以了。\n\n感谢你的阅读~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588161146,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]}]}