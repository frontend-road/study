{"id":133971,"title":"46 | 答疑（四）：共享字典的缓存是必须的吗？","content":"<p>你好，我是温铭。</p><p>专栏更新到现在，OpenResty第四版块 OpenResty 性能优化篇，我们就已经学完了。恭喜你没有掉队，仍然在积极学习和实践操作，并且热情地留下了你的思考。</p><p>很多留言提出的问题很有价值，大部分我都已经在App里回复过，一些手机上不方便回复的或者比较典型、有趣的问题，我专门摘了出来，作为今天的答疑内容，集中回复。另一方面，也是为了保证所有人都不漏掉任何一个重点。</p><p>下面我们来看今天的这 5 个问题。</p><h2>问题一：如何完成 Lua 模块的动态加载？</h2><p>Q：关于OpenResty 实现的动态加载，我有个疑问：在完成新文件替换后，如何用 loadstring 函数完成新文件的加载呢 ？我了解到，loadstring 只能加载字符串，如果要重新加载一个 lua 文件/模块，在 OpenResty 中要如何做到呢？</p><p>A：我们知道，loadstring 是加载字符串使用的，而loadfile 可以加载指定的文件，比如： <code>loadfile(\"foo.lua\")</code>。事实上，这两个命令达到的效果是一样的。</p><p>至于如何加载 Lua 模块，下面是一个具体的示例：</p><pre><code>resty -e 'local s = [[\nlocal ngx = ngx\nlocal _M = {}\nfunction _M.f()\n    ngx.say(&quot;hello world&quot;)\nend\nreturn _M\n]]\nlocal lua = loadstring(s)\nlocal ret, func = pcall(lua)\nfunc.f()'\n</code></pre><p>这里的字符串 <code>s</code>，它的内容就是一个完整的 Lua 模块。所以，在发现这个模块的代码有变化时，你可以用 loadstring 或者 loadfile 来重启加载。这样，其中的函数和变量都会随之更新。</p><!-- [[[read_end]]] --><p>更进一步，你也把可以把获取变化和重新加载，用名为 <code>code_loader</code> 函数做一层包装：</p><pre><code>local func = code_loader(name)\n</code></pre><p>这样一来，代码更新就会变得更为简洁；同时， <code>code_loader</code> 中我们一般会用 lru cache 对 <code>s</code> 做一层缓存，避免每一次都去调用 loadstring。这差不多就是一个完整的实现了。</p><h2>问题二：OpenResty 为什么不禁用阻塞操作？</h2><p>Q：这些年来，我一直有个疑虑，既然这些阻塞调用是官方极力不鼓励的，为什么不直接禁用呢？或者加一个 flag 让用户选择禁用呢？</p><p>A：这里说一下我个人的看法。首先是因为 OpenResty 的周边生态还不够完善，有时候我们不得不调用阻塞的库来实现一些功能。比如 ，在1.15.8 版本之前，调用外部的命令行还需要走 Lua 库的 <code>os.execute</code>，而不是 <code>lua-resty-shell</code>；再如，在 OpenResty 中，读写文件至今还是只能走 Lua 的 I/O 库，并没有非阻塞的方式来替代。</p><p>其次，OpenResty 在这种优化上的态度是很谨慎的。比如， <code>lua-resty-core</code> 已经开发完成很长时间了，但一直都没有默认开启，需要你手工来调用 <code>require 'resty.core'</code>。直到最新的 1.15.8版本，它才得以转正。</p><p>最后，OpenResty 的维护者更希望，通过编译器和 DSL自动生成高度优化过的 Lua 代码，这种方式来规范阻塞方式的调用。所以，大家并没有在 OpenResty 平台本身上，去做类似 flag 选项的努力。当然，这种方向是否能够解决实际的问题，我是保留态度的。</p><p>站在外部开发者的角度，如何避免这种阻塞，才是更为实际的问题。我们可以扩展 Lua 代码的检测工具，比如 luacheck 等，发现并对常见的阻塞操作进行告警；也可以直接通过改写 <code>_G</code> 的方式，来侵入式地禁止或者改写某些函数，比如：</p><pre><code>resty -e '_G.ngx.print = function()\nngx.say(&quot;hello&quot;)\nend\nngx.print()'\nhello\n</code></pre><p>这样的示例代码，就可以直接改写 <code>ngx.print</code> 函数了。</p><h2>问题三：LuaJIT 的 NYI 的操作，是否会对性能有很大影响？</h2><p>Q：loadstring 在 LuaJIT 的 NYI 列表是 never，会不会对性能有很大影响？</p><p>A：关于 LuaJIT 的 NYI，我们不用矫枉过正。对于可以 JIT 的操作，自然是 JIT 的方式最好；但对于还不能 JIT 的操作，我们也不是不能使用。</p><p>对于性能优化，我们需要用基于统计的科学方法来看待，这也就是火焰图采样的意义。过早优化是万恶之源。对于那些调用次数频繁、消耗 CPU 很高的热代码，我们才有优化的必要。</p><p>回到loadstring 的问题，我们只会在代码发生变化的时候，才会调用它重新加载，和请求多少无关，所以它并不是一个频繁的操作。这个时候，我们就不用担心它对系统整体性能的影响。</p><p>结合第二个阻塞的问题，在 OpenResty 中，我们有些时候也会在 init 和 init worker 阶段，去调用阻塞的文件 I/O 操作。这种操作比 NYI 更加影响性能，但因为它只在服务启动的时候执行一次，所以也是可以被我们接受的。</p><p>还是那句话，性能优化要从宏观的视角来看待，这是你特别需要注意的一个点。否则，纠结于某一细节，就很有可能优化了半天，却并没有起到很好的效果。</p><h2>问题四：动态上游可以自己来实现吗？</h2><p>Q：动态上游这块，我的做法是为一个服务设置 2 个 upstream，然后根据路由条件选择不同的 upstream，当机器 IP 有变化时，直接修改 upstream 中的 IP 即可。这样的做法，和直接使用 <code>balancer_by_lua</code> 相比，有什么劣势或坑吗？</p><p>A：单独看这个案例。<code>balancer_by_lua</code> 的优势，是可以让用户选择负载均衡的算法，比如是用roundrobin 还是 chash，又或者是用户自己实现的其他算法都可以，灵活而且性能很高。</p><p>如果按照路由规则的方式来做，从最终结果上来看是一样的。但上游健康检查需要你自己来实现，增加了不少额外的工作量。</p><p>我们也可以扩展下这个提问，对于 abtest 这种需要不同上游的场景，我们应该如何去实现呢？</p><p>你可以在 <code>balancer_by_lua</code> 阶段中，根据 uri、host、参数等来决定使用哪一个上游。你也可以使用 API 网关，把这些判断变为路由的规则，在最开始的 <code>access</code> 阶段，通过判断决定使用哪一个路由，再通过路由和上游的绑定关系找到指定的上游。这就是 API 网关的常见做法，后面在实战章节中，我们会更具体地聊到。</p><h2>问题五：共享字典的缓存是必须的吗？</h2><p>Q：在实际的生产应用中，我认为 shared dict 这一层缓存是必须的。貌似大家都只记得 lruca  che 的好，数据格式没限制、不需要反序列化、不需要根据 k/v 体积算内存空间、worker 间独立不相互争抢、没有读写锁、性能高云云。</p><p>但是，却忘记了它最致命的一个弱点，就是 lru  cache 的生命周期是跟着 worker 走的。每当Nginx reload 时，这部分缓存会全部丢失，这时候，如果没有 shared dict，那 L3 的数据源分分钟被打挂。</p><p>当然，这是并发比较高的情况下，但是既然用到了缓存，就说明业务体量肯定不会小，也就是刚刚的分析仍然适用。不知道我的这个观点对吗？</p><p>A：大部分情况下，确实如你所说，共享字典在 reload 的时候不会丢失，所以它有存在的必要性。但也有一种特例，那就是，如果在 <code>init</code> 阶段或者 <code>init_worker</code> 阶段，就能从 L3 也就是数据源主动获取到所有数据，那么只有 lru cache 也是可以接受的。</p><p>举例来说，比如开源 API 网关 <a href=\"https://github.com/iresty/apisix\">APISIX</a> 的数据源在 etcd 中，它只在 <code>init_worker</code> 阶段，从 etcd 中获取数据并缓存在lru cache 中，后面的缓存更新，都是通过 etcd 的 watch 机制来主动获取的。这样一来，即使 Nginx reload ，也不会有缓存风暴产生。</p><p>所以，对待技术的选择，我们可以有倾向，但还是不要一概而论绝对化，因为并没有一个可以适合所有缓存场景的银弹。根据实际场景的需要，构建一个最小化可用的方案，然后逐步地增加，是一个不错的法子。</p><p>今天主要解答这几个问题。最后，欢迎你继续在留言区写下你的疑问，我会持续不断地解答。希望可以通过交流和答疑，帮你把所学转化为所得。也欢迎你把这篇文章转发出去，我们一起交流、一起进步。</p><p></p>","comments":[{"had_liked":false,"id":153244,"user_name":"Shliesce","can_delete":false,"product_type":"c1","uid":1198028,"ip_address":"","ucode":"75B1DCE6989B38","user_header":"https://static001.geekbang.org/account/avatar/00/12/47/cc/04a749e1.jpg","comment_is_top":false,"comment_ctime":1574207724,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10164142316","product_id":100028301,"comment_content":"哈哈哈，第五个问题是我对于共享内存的理解，有点偏主观意识了，见笑了。结合我们公司的场景来看这个问题，我们的数据源也是存在consul或者etcd这样的组件中，与openresty是两个团队分开维护的，如果不使用shared dict的话，一旦数据源故障，就会导致openresty无法正常reload，所以如果我们有shared dict这一层缓存的话就可以与数据源解耦，解决强依赖的问题，哪怕数据源故障，仍然可以正常变更openresty，只是无法新增数据。我们认为这个方案会更优雅一些。","like_count":2},{"had_liked":false,"id":334940,"user_name":"杨文波","can_delete":false,"product_type":"c1","uid":2593364,"ip_address":"","ucode":"44C39D3274861B","user_header":"","comment_is_top":false,"comment_ctime":1645192520,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1645192520","product_id":100028301,"comment_content":"问一节和这章无关的问题，若在upstream列出的机器，balancer_by_lua里面计算出来的机器不在upstream里面，nginx的keepalive连接池还有作用吗？","like_count":0},{"had_liked":false,"id":251446,"user_name":"Geek_6a1df0","can_delete":false,"product_type":"c1","uid":2215324,"ip_address":"","ucode":"152BC14A18345D","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/edgBnRiaTyX7zlDysxcvgfYtESpsN0Aiawr3KDibEiceWcr7ADRia82vIr0l4EC9ErqTMenIZtzfrzpvN7RaRQFzYug/132","comment_is_top":false,"comment_ctime":1601562876,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"1601562876","product_id":100028301,"comment_content":"etcd 的 watch 机制，可以用来解决 OpenResty 缺少 worker 进程间直接通信的这个问题吗？","like_count":0,"discussions":[{"author":{"id":1532404,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEIvUlicgrWtibbDzwhLw5cQrDSy2JuE1mVvmXq11KQIwpLicgDuWfpp9asE0VCN6HhibPDWn7wBc2lfmA/132","nickname":"a、","note":"","ucode":"590FE8DB111492","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":577275,"discussion_content":"这么做是不太行，如果只有一个worker同步，然后写shared dicr，有请求进来，worker是一直读shared dict还是读自己worker里的缓存，如果是读shared dict，那么性能没有读自己worker里的缓存速度快，如果是读worker自己缓存里的，那么shared dict里的缓存和worker自己缓存不一致怎么解决？通过定时任务同步？那还不如在init阶段，所有的worker都去watch这个key，就不需要shared dict这层了，还更快","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1655998581,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1286269,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a0/7d/a520e81c.jpg","nickname":"ggsddu","note":"","ucode":"5D31F484BA17EE","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":321862,"discussion_content":"同问：老师到意思是每个worker都去watch，然后缓存到LRU中吗？是否可以使用一个worker去watch，然后通过shared dict去同步给其他worker？这样就不用每个worker都去同步配置了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1604642087,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":132339,"user_name":"东不懂","can_delete":false,"product_type":"c1","uid":1305375,"ip_address":"","ucode":"58387685F71BC9","user_header":"https://static001.geekbang.org/account/avatar/00/13/eb/1f/ffbfd707.jpg","comment_is_top":false,"comment_ctime":1568089704,"is_pvip":false,"replies":[{"id":"50712","content":"我用的是 vscode","user_name":"作者回复","user_name_real":"温铭@OpenResty","uid":"1017955","ctime":1568171848,"ip_address":"","comment_id":132339,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1568089704","product_id":100028301,"comment_content":"用vim开发OpenResty，没有找到合适的代码补齐插件，写的还挺难受的。想问下，你这方面开发用的什么环境","like_count":0,"discussions":[{"author":{"id":1017955,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/88/63/88cf886d.jpg","nickname":"温铭@APISIX","note":"","ucode":"343567571DA16A","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":466885,"discussion_content":"我用的是 vscode","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1568171848,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1105161,"avatar":"https://static001.geekbang.org/account/avatar/00/10/dd/09/feca820a.jpg","nickname":"helloworld","note":"","ucode":"1EECCA0F43E278","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":10628,"discussion_content":"vim配置好，也一样非常好用","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1568298733,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}