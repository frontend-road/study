{"id":685914,"title":"24｜消息顺序：保证消息有序，一个 topic 只能有一个 partition 吗？","content":"<p>你好，我是大明。我们今天接着学习消息队列的新主题——有序消息。</p><p>在消息队列的相关的面试里面，有序消息和消息不丢失、消息重复消费是三个并列的面试热点，同时在实践中也很容易遇到要求使用有序消息的场景。但是大部分人在面试的时候，无法深入透彻地讨论这个问题。大多数时候，只能说出 topic 只能有一个分区这种最简单的方案。当面试官追问这种方案有什么缺陷的时候就开始答不上来了。</p><p>所以今天我就带你深入了解有序消息的方方面面，深挖解决方案的缺陷以及对应的改进策略。</p><h2>消息在分区上的组织方式</h2><p>在 Kafka 中，消息是以分区为单位进行存储的。分区是逻辑上的概念，用于对消息进行水平划分和并行处理。每个 topic 都可以被划分为一个或多个分区，每个分区都是一个<strong>有序、不可变</strong>的消息日志。</p><p>Kafka 使用 WAL （write-ahead-log）日志来存储消息。每个分区都有一个对应的日志文件，新的消息会被追加到文件的末尾，而已经加入日志里的消息，就不会再被修改了。</p><p><img src=\"https://static001.geekbang.org/resource/image/73/70/73ef185e2011f444026cff4d140caf70.png?wh=1920x806\" alt=\"图片\"></p><p>每个消息在分区日志里都有一个唯一的偏移量（offset），用来标识消息在分区里的位置。<strong>Kafka 保证同一分区内的消息顺序，但不保证不同分区之间的顺序</strong>。</p><p>而 Kafka 本身暴露了对应的接口，也就是说你可以显式地指定消息要发送到哪个分区，也可以显式地指定消费哪个分区的数据。</p><!-- [[[read_end]]] --><h2>什么是有序消息？</h2><p>在消息队列里面，有序消息是指消费者消费某个 topic 消息的顺序，和生产者生产消息的顺序一模一样，它也叫做顺序消息。</p><p>前面你应该注意到了，Kafka 并不能保证不同分区之间的顺序。也就是说，如果业务上有先后顺序的消息被发送到不同的分区上，那么你难以确定哪一个消息会先被消费。</p><p>你需要注意一点语义上的差别，这里说生产者生产消息的顺序，不是指你创建出来消息那个实例的先后顺序，而是指broker收到的顺序。比如说你有两个生产者，一个生产者先生产了 msg1，另外一个生产者生产了 msg2，但是 msg2 先发到了broker上。那么实际上我们认为 msg2 是先于 msg1 的。</p><p><img src=\"https://static001.geekbang.org/resource/image/26/f7/2682e2f251a64e06e24ae7012337e8f7.png?wh=1920x941\" alt=\"图片\"></p><p>如果你要求的是两个生产者，一个生产者一定要先于另外一个生产者发送一条消息，那么这实际上已经超出了消息队列要解决的问题的范畴了，它属于在分布式环境下如何协调不同节点按照先后顺序执行一定的步骤这个问题范畴。有序消息强调的是某个 topic 内，而不是跨 topic 的有序消息。</p><h2>跨 topic 的有序消息</h2><p>不过有些时候可能因为业务特征或者历史问题，业务会要求你在不同的 topic 之间也保证消息是有序的。比如说 msg1 先发送到了 topic_a 上， msg2 被发送到了 topic_b 上。但是在业务层面上，要求 msg1 一定要先于 msg2 消费。</p><p>这种场景在事件驱动的架构中更加常见。在复杂的事件驱动架构下，我们可能会倾向于使用不同的 topic 来代表不同的事件，那么就会遇到要求在不同的 topics 下消息依旧需要保持有序的问题。</p><p>这一类的问题是不能依赖于消息队列来解决的。要想支持这种跨 topic 的有序消息，一定要引入一个协调者，这个协调者负责把消息重组为有序消息。比如说，如果 msg2 先到了，但是 msg1 还没出来，那么这个协调者要有办法让 msg2 的消费者 B 停下来，暂时不消费 msg2。而在 msg1 来了之后，唤醒消费者 A 消费 msg1，并且在消费完 msg1 之后要再唤醒消费者 B 处理 msg2。</p><p>应当说，这是一个全新的话题，面试基本上不会出现这一类问题，你心中有个基本的概念就可以了。</p><h2>面试准备</h2><p>在准备面试的时候，你需要了解一下公司内部使用有序消息的情况。</p><ul>\n<li>在什么业务场景下，你需要用到有序消息？</li>\n<li>你是如何解决有序消息这个问题的？用的是哪种方案？</li>\n<li>如果你用的是单分区解决方案，那么有没有消息积压问题？如果有，你是怎么解决的？</li>\n<li>如果你用的是多分区解决方案，那么有没有分区负载不均衡的问题？如果有，你是怎么解决的？</li>\n</ul><p>你可以在简历介绍技能的部分或者项目部分点出你解决过消息有序性的问题。基本上你只要介绍到了，面试官就肯定会问你这方面的问题。</p><p>如果你自己在实践中真的用了全局有序的单分区解决方案，但是业务层面上其实并不要求全局有序，那么你可以尝试使用一下多分区解决方案。这样一来，你就会对两个方案有非常深入的理解，也能把握更多细节。</p><p>除此之外，如果面试官问到了这些问题，你也可以把话题引导到有序消息这个话题上。</p><ol>\n<li>增加分区的问题，后面的多分区方案专门讨论了增加分区可能带来的消息失序的问题。</li>\n<li>Redis 的槽和槽分配。</li>\n<li>负载均衡，你记得回答一致性哈希，然后把话题引导到利用一致性哈希来解决多分区数据分布不均匀的问题。</li>\n<li>消息积压的问题，你可以把话题引导到单分区方案和多分区方案上。</li>\n</ol><h2>基本思路</h2><p>我在前置知识里面已经说了 Kafka 分区是如何存储数据的。所以你很容易就猜到第一个解决方案，就是每一个 topic 只使用一个分区，也就是所谓的单分区解决方案。</p><p><img src=\"https://static001.geekbang.org/resource/image/d5/23/d5b8898e6905940312cedee64fa7e523.png?wh=1920x941\" alt=\"图片\"></p><p>所以你可以简单介绍这个方案。</p><blockquote>\n<p>要保证消息有序，最简单的做法就是让特定的 topic 只有一个分区。这样所有的消息都发到同一个分区上，那么自然就是有序的。</p>\n</blockquote><p>这个方案的优点是简单，并且是全局有序。但是这个方案有一个很严重的问题：性能太差。因为你一个 topic 只有一个分区，它就没办法支撑高并发。</p><p>所以你可以在回答中补充这一点，关键词是<strong>性能差</strong>。</p><blockquote>\n<p>这种只有一个分区的方案性能差，没办法支撑高并发。对于生产端来说，所有的消息都在一个分区上，也同时意味着所有的消息都发送到了同一个broker上，这个服务器很可能撑不住压力；对于消费端来说，只有一个分区，那么就只能有一个消费者消费，很容易出现消息积压的问题。</p>\n</blockquote><p><img src=\"https://static001.geekbang.org/resource/image/37/b3/377e7d99d997ea28f29e7ce17fd232b3.png?wh=1920x941\" alt=\"图片\"></p><p>既然你说了这个点，自然就是为了引出改进方案。不过改进方案都有一个基本的前提，消息需要保持有序，但不是全局有序，而是同一个业务内有序。</p><p>如果业务要求的是全局有序，那就没什么优化手段，只能是换用更加强大的机器。但是你设想一下真实的业务场景，大部分业务强调的有序是全局有序吗？并不是，而是<strong>业务内有序</strong>。比如说在下单的场景下，会产生创建订单消息和完成支付消息。业务上只会要求同一个订单的创建订单消息应该优先于完成支付消息，但是不会要求订单 A 的创建消息需要先于订单 B 的支付消息。</p><p>所以你可以先暂时澄清一下同一个业务内有序的概念，然后引出优化方案。</p><blockquote>\n<p>如果我们要求的是全局有序，那除了换更加强大的机器就没别的办法了。而事实上，大部分的业务场景要求的都不是全局有序，而是业务内有序。例如要求同一个订单创建订单的消息应该先于完成支付消息，但是不会要求不同订单之间的消息是有序的。在这种场景下，还有两个改进方案可以考虑。一个是异步消费，还有一个是多分区方案。</p>\n</blockquote><h3>异步消费</h3><p>在单分区方案里，最容易遇到的问题就是消息积压，因为你只有一个消费者。在遇到消息积压的情况下，你可以考虑异步消费。但是这里的异步消费和上节课讲的比起来，有点不一样，这里你要关注一个问题：如何维持顺序？</p><p>这里说的顺序，就是同一个业务内的顺序。所以我们可以考虑在异步消费时，当消费者从队列取出来消息之后，把同一个业务的消息丢到同一个队列里。你可以看一下整体的架构图。</p><p><img src=\"https://static001.geekbang.org/resource/image/0c/f2/0c23f9fa9600707333d3f4c9efafc3f2.png?wh=1920x916\" alt=\"图片\"></p><p>图中有一个消费者负责从 Kafka 里拉取消息，然后发送到基于内存的队列里面。在发送的时候，它会根据 id 做一个简单的取余操作来筛选队列。然后工作线程从队列里面拿取消息，真正执行业务逻辑。</p><p>这个例子用的是 id，但是你可以根据自己的业务来选择其他字段，你选择的这些字段就被叫做业务特征。</p><p>你抓住关键字<strong>异步消费</strong>介绍这个方案。</p><blockquote>\n<p>第一个方案是异步消费，这个方案和解决消息积压的异步消费方案差不多，但是要做一点改进。消费者线程从 Kafka 里获取消息，然后转发到内存队列里面。在转发的时候，要把同一个业务的消息转发到同一个队列里面。一般来说可以根据业务特征字段计算一个哈希值，比如说直接使用业务 id 作为哈希值。利用这个哈希值除以工作线程数量，然后取余数，得到对应的内存队列。<br>\n&nbsp;<br>\n这种做法的缺陷就是存在消息未消费的问题。也就是消费线程取出来了，转发到队列之后，工作线程还没来得及处理，消费者整体就宕机了，那么这些消息就存在丢失的可能。</p>\n</blockquote><p>最后提到了一个消息未处理的问题，我们上节课已经聊过了，那么你就可以灵活地把话题引导到消息积压的问题上去。</p><p>如果你仔细观察，你就会发现，既然我可以用内存队列，我干嘛不直接使用多个分区呢？这也就是我们的第二个改进方案：多分区。</p><h2>亮点方案：多分区</h2><p>这个方案在面试的时候也有一些人能回答出来，但是很少有人能够深入讨论这个方案的潜在问题和对应的解决方案，所以这也就是你拉开差距的地方。</p><p>第二个方案和第一个方案差不多，就是把内存队列换成了多个分区。原本同一个业务的消息发送到同一个队列，这里是同一个业务的消息要发送到同一个分区。</p><blockquote>\n<p>第二个方案就是直接扩展为使用多个分区，只需要确保同一个业务的消息发送到同一个分区就可以保证同一个业务的消息是有序的。</p>\n</blockquote><p>面试官自然就会追问，怎么保证同一个业务的消息必然发送到同一个分区呢？做法也很简单，只需要生产者在发送消息的时候，根据业务特征，比如说业务 ID 计算出目标分区，在发送的时候显式地指定分区就可以了。</p><p><img src=\"https://static001.geekbang.org/resource/image/ed/80/ed75cffc180df3eccf3dbfe1f0977880.png?wh=1920x989\" alt=\"图片\"></p><p>这里你抓住关键词<strong>计算分区</strong>回答。</p><blockquote>\n<p>要想确保同一个业务的消息都发送到同一个分区，那么只需要发送者自己根据业务特征，直接计算出来一个目标分区。比如说最简单的策略就是根据业务 ID 对分区数量取余，余数就是目标分区。</p>\n</blockquote><p>就像我之前所说的，所有的方案都有优缺点，这个方案也不例外。它的优点是足够简单，业务方需要做的改动很小。但是缺点有两个，一个是数据不均匀，另一个是增加分区可能导致消息失序。</p><p>我们先来看第一个缺点。</p><h3>数据不均匀</h3><p>这个缺点很容易理解，因为发送方要按照业务特征来选择分区，自然就容易导致一些分区有很多数据，而另外一些分区数据很少。而如果某个分区有很多数据的话，消费者来不及消费也是正常的事情。</p><p><img src=\"https://static001.geekbang.org/resource/image/16/79/1621e78eafde1138214b080ba3974579.png?wh=1920x917\" alt=\"图片\"></p><blockquote>\n<p>数据不均匀一般是业务造成的。在我们的方案里面，分区是根据业务特征来选择的，那么自然有一些分区有很多数据，有一些分区数据很少。比如说万一我们不小心把热点用户的消息都发到了同一个分区里面，那么这个分区的 QPS 就会很高，消费者也不一定来得及消费，就可能引起消息积压。</p>\n</blockquote><p>怎么解决这个问题呢？</p><blockquote>\n<p>要想解决这个问题，可以通过改进计算目标分区的方式来解决，比如说采用类似于 Redis 中槽和槽分配的机制，又或者说一致性哈希算法，基本上就能解决这个问题了。</p>\n</blockquote><p>这两个解决思路，我建议你不要等面试官追问，而是自己直接接着说，因为到这里你讨论的深度大概率已经超出了一般面试官的经验范畴了，所以他们可能想不到该怎么问你。</p><h4>槽与槽分配</h4><p>这种解决方案的基本思路就是借鉴 Redis 的数据分布方案。你可以根据业务特征计算一个哈希值，然后映射到槽上。这里，你可以参考 Redis，使用 16384 个槽，不过如果业务体量不是那种几百万 QPS 的，你用 1024 个槽就可以。</p><p>你再通过指定不同的槽把数据分配到不同的分区上，这个时候你就可以根据你的业务特征合理分配槽，从而保证分区之间数据分布是均匀的。</p><p>整个架构如图：</p><p><img src=\"https://static001.geekbang.org/resource/image/9c/93/9c0e58fe55c8b65d4c2b28f836971393.png?wh=1920x820\" alt=\"图片\"></p><p>你抓住关键词<strong>槽</strong>回答。</p><blockquote>\n<p>第一种思路是借鉴 Redis 的槽与槽分配方案。不过 Redis 使用了 16384 个槽，一般的业务用不上那么多槽，所以可以考虑用 1024 个槽。根据业务的特征来计算一个哈希值，再除以 1024 取余就可以得到所在的槽。再根据不同槽的数据多少，合理地把槽分配到不同的分区。最好把槽和分区的绑定关系做成动态的，也就是说我可以随时调整槽到分区的映射关系，保证所有的分区负载都是均匀的。</p>\n</blockquote><p>最后我们提到的动态调整槽与分区的绑定关系，可以借助于配置中心来完成。比如说最开始你把槽 1 绑定到分区 2 上，后面在运行的时候你发现分区 2 数据太多，就把槽 1 重新绑定到了分区 3 上。</p><p>当然，因为这个回答的核心是借鉴了 Redis，那么就有可能把话题引导到 Redis 那里。不过你也不用担心，课程后面你会了解到和 Redis 有关的内容。</p><p>但是这个过程还是有问题的，可能会引起消息失序，和增加新的分区指向了同一个问题。所以你可以参考增加分区引起消息失序部分来回答。接下来，我们再来看看一致性哈希是怎么解决问题的。</p><h4>一致性哈希</h4><p>你已经接触过一致性哈希这个算法很多次了。那么在这里使用哈希一致性算法，就是把分区分散在哈希环上。你根据业务特征计算出一个哈希值之后，根据哈希值在这个环上找到合适的分区，然后把消息发送过去。</p><p>你只要通过调整不同分区之间的间隔，就能控制分区上的数据分布。</p><p><img src=\"https://static001.geekbang.org/resource/image/8c/71/8c9fd7c86f8830ec3aaf542192909271.png?wh=1920x1144\" alt=\"图片\"></p><blockquote>\n<p>另外一种思路是使用一致性哈希算法来筛选分区。首先要根据数据分布的整体情况，把分区分布在哈希环上，确保每一个分区上的数据分布大体上是均匀的。如果一部分哈希值上数据较多，就多插入几个分区节点。然后根据业务特征计算一个哈希值，从哈希环上找到对应的分区。</p>\n</blockquote><p>最后你可以进一步总结，升华一下。</p><blockquote>\n<p>这种槽分配和一致性哈希算法非常适合解决数据或者流量分布不均匀的问题，因为我们总是可以通过手工调整槽的映射关系或者哈希环上节点的分布来保证数据或者流量在每一个节点上的分布大体是均匀的。</p>\n</blockquote><p>到这里，我们已经彻底解决了数据不均匀的问题，接下来就要讨论增加分区引起消息失序的问题了。</p><h3>增加分区引起消息失序</h3><p>你可以结合下面这张图来理解。</p><p><img src=\"https://static001.geekbang.org/resource/image/12/69/125a0070a6d42117e6bbb5e728d58569.png?wh=1920x1023\" alt=\"图片\"></p><p>在面试的时候，你可以先介绍这个缺点，关键词是<strong>增加分区会引起消息失序</strong>，同时补充一个例子。</p><blockquote>\n<p>它还有另外一个缺点，就是如果中间有增加新的分区，那么就可能引起消息失序。比如说最开始 id 为 3 的订单消息 msg1 发到分区 0 上，但是这时候很不幸分区 0 上积攒了很多消息，所以 msg1 迟迟得不到消费。<br>\n&nbsp;<br>\n紧接着我们扩容，增加了一个新的分区。如果这时候来了一个消息 msg2，那么它会被转发到分区 3 上。分区 3 上面没有积攒什么数据，所以消费者 3 直接就消费了这个消息。<br>\n&nbsp;<br>\n这时候我们发现，本来 msg1 应该先于 msg2 被消费。而增加分区之后 msg2 反而被先消费了。这就是一个典型的消息失序场景。</p>\n</blockquote><p>那么针对这个缺点我们也可以进一步提出解决方案。这个消息失序的场景解决起来倒也很简单，就是新增加了分区之后，这些新分区的消费者先等一段时间，比如说三分钟，确保同一个业务在其他分区上的消息已经被消费了。</p><blockquote>\n<p>要解决这个问题也很容易。对于新加入的分区，可以暂停消费一段时间。比如说在前面的例子中，如果我们估算 msg1 会在一分钟内被消费，那么新加入的分区的消费者可以在三分钟后再开始消费。那么大概率 msg1 就会先于 msg2 消费。不过这种等待的解决方式并不能解决根本问题，只能说是很大程度上缓解了问题。但是本身增加分区也是一个很不常见的操作，再叠加消息失序的概率也很低，所以我们也可以通过监控发现这种失序场景，然后再手工修复一下就可以了。</p>\n</blockquote><p>到了这一步，常规的方案和升级的多分区版本已经聊得差不多了。最后我再来教你一个面试的小技巧。</p><h3>基于优化的面试思路</h3><p>刚刚我们从单分区讨论到多分区，就是一个关于性能优化的非常好的案例，我们如何通过这个案例来让我们的能力更加突出呢？这里可以利用我们之前学过的一个面试小技巧，关键词就是<strong>优化 + 前后对比。</strong></p><blockquote>\n<p>最开始我进公司的时候就遇到了一个 Kafka 的线上故障。我司有一个业务需要用到有序消息，所以最开始的设计就是对应的 topic 只有一个分区，从而保证了消息有序。<br>\n&nbsp;<br>\n可是随着业务增长，一个分区很快就遇到了性能瓶颈。只有一个分区，也就意味着只有一个消费者，所以在业务增长之后，就开始出现了消息积压。另外一方面，这个分区所在的broker的负载也明显比其他服务器要大，偶尔也会有一些性能抖动的问题。<br>\n&nbsp;<br>\n后来我仔细看了我们的业务，实际上，我们的业务要求的不是全局有序，而是业务内有序。<br>\n&nbsp;<br>\n换句话来说，不一定非得用一个分区，而是可以考虑使用多个分区。所以我就给这个 topic 增加了几个分区，同时也增加了消费者。优化完之后，到目前为止，还没有出现过消息积压的问题。</p>\n</blockquote><p>这里你应该注意到，从单个分区增加到多个分区，还是会出现前面说的消息失序的问题。我建议你主动提起这个问题，展开聊一聊你的应对方案。</p><blockquote>\n<p>当然，为了避免在单分区增加到多分区的时候，出现消息失序的问题，我用了一个很简单的方案，就是对应的消费者在启动之后，并没有立刻消费，而是停顿了三分钟，从而避免了潜在的消息失序问题。</p>\n</blockquote><p>注意，这里的停顿三分钟的前提是你要先把积压的消息消费掉。如果积压的消息还需要三十分钟，那你这里就至少要停顿三十分钟。</p><h2>面试思路总结</h2><p>这节课我们了解了有序消息的基本概念，还有一个看起来有点接近但是完全不同的话题：跨 topic 的有序消息。其中有一个关键问题，就是消息在分区上是如何组织的，这里你记住 <strong>WAL 和分区内有序</strong>这两个关键词就可以了。</p><p>在这个基础上，我们讨论了最常规的方案，也就是保证<strong>全局有序的单分区方案</strong>，并且进一步解释了如果在单分区上消息积压了，可以通过<strong>异步消费</strong>来解决问题。</p><p>然后我们重点讨论了<strong>多分区方案</strong>，这里你要记住多分区方案的两个缺陷，还有应对策略。</p><ol>\n<li>数据不均匀。对应的解决方案是借鉴 Redis 的槽与槽分配的方案和一致性哈希方案。</li>\n<li>增加分区引起的消息失序。要解决这个问题也很简单，就是新增加的分区暂时不要消费，确保在别的分区上的消息已经被消费完了再消费。</li>\n</ol><p>RabbitMQ 和 RocketMQ 里面消息有序性的解法也是差不多的。不同的是，在 RabbitMQ 里面使用的是 queue，因为 RabbitMQ 没有分区的概念。而 RocketMQ 里面内置了有序消息的功能，底层原理也基本相似。</p><p><img src=\"https://static001.geekbang.org/resource/image/8y/5c/8yy49b0e01ae1e565c7a4d97c5175c5c.jpg?wh=2933x1896\" alt=\"\"></p><h2>思考题</h2><p>最后请你来思考两个问题。</p><ul>\n<li>你觉得在多分区方案里面，如果某个分区消息积压了就启用异步消费，这种解决思路你觉得怎么样？</li>\n<li>我在最后总结了一个槽分配和一致性哈希非常适合用于解决数据或者流量分布不均匀问题的观点，你还在什么地方见过类似的解决思路？</li>\n</ul><p>欢迎你把你的答案分享在评论区，也欢迎你把这节课的内容分享给需要的朋友，我们下节课再见！</p>","neighbors":{"left":{"article_title":"23｜延迟消息：怎么在 Kafka 上支持延迟消息？","id":685187},"right":{"article_title":"25｜消息积压：业务突然增长，导致消息消费不过来怎么办？","id":685943}},"comments":[{"had_liked":false,"id":380028,"user_name":"ZhiguoXue_IT","can_delete":false,"product_type":"c1","uid":2639055,"ip_address":"北京","ucode":"EAA83F53B54520","user_header":"https://static001.geekbang.org/account/avatar/00/28/44/cf/791d0f5e.jpg","comment_is_top":false,"comment_ctime":1692859176,"is_pvip":false,"replies":[{"id":138401,"content":"好问题。盲猜你是用了不同的 topic 是不是？就是退单的消息用了一个 topic，但是下单的用了另外一个 topic。\n\n如果你是这种的话，只能用我提到的跨 topic 有序的方案，要有一个协调者进来，这个协调者在收到退单的时候，要先去看看有没有收到下单的消息。\n\n但是一般用不着这样，以为你只需要检测有没有这个订单，或者状态是否符合，不符合你就丢回去原本的 topic 里面。或者你设定一个时间，比如说三十分钟之后再处理这个退单消息，然后预期三十分钟内应该能收到下单消息。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1692891325,"ip_address":"广东","comment_id":380028,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"在订单的业务场景下，有下单消息，退单退款消息，按照订单号进行分区，保证同一个订单的数据一致性，如果是分布式环境下，退单的消息比下单的消息先到，业务一般如何处理呢","like_count":7,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":626416,"discussion_content":"好问题。盲猜你是用了不同的 topic 是不是？就是退单的消息用了一个 topic，但是下单的用了另外一个 topic。\n\n如果你是这种的话，只能用我提到的跨 topic 有序的方案，要有一个协调者进来，这个协调者在收到退单的时候，要先去看看有没有收到下单的消息。\n\n但是一般用不着这样，以为你只需要检测有没有这个订单，或者状态是否符合，不符合你就丢回去原本的 topic 里面。或者你设定一个时间，比如说三十分钟之后再处理这个退单消息，然后预期三十分钟内应该能收到下单消息。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1692891325,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":380908,"user_name":"H·H","can_delete":false,"product_type":"c1","uid":2108194,"ip_address":"上海","ucode":"113E95BA6B6F51","user_header":"https://static001.geekbang.org/account/avatar/00/20/2b/22/79d183db.jpg","comment_is_top":false,"comment_ctime":1694433529,"is_pvip":false,"replies":[{"id":138857,"content":"老大难的问题了，哈哈哈哈。\n\n说实在的，我也没特别好的的办法。如果你们本身就有那种排序机制，比如说我可以通过状态来判定消息是不是失序了，比如说当状态还是未支付的时候，你收到取消消息，这肯定是乱序了。那么你就可以尝试把取消消息重新发回去原本的消息队列上。\n\n另外一种有漏洞的做法就是借助延迟消息。比如说你 A1 消息在重试，A2 不管知不知道 A1 在重试，直接自己延迟一分钟发送。“一分钟”是假定你的 A1 肯定能在一分钟之内重试完成。\n\n当然，如果 A2 的发送者有办法知道 A1 还没发，那么就可以优化成只有当 A1 没发，A2 才会延迟，当然 A3，A4... 显然也要跟着延迟。\n\n比如说，你可以借助 redis，假设 key1=1 的时候，代表 A1 还没发。key1=2 的时候，A1 已经发了。那么 A2 的发送者看一眼 Redis 就知道了。\n\n不过，我的个人看法是……除非是面试吹牛，不然实践中直接告警拉到。就是在真的发现消息失序的时候，告警，人手工微调一下就可以。可用性高的话，你可能一个月才有一个两个这种失序的问题。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1694782475,"ip_address":"广东","comment_id":380908,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"消息重试这个怎么保证有序？","like_count":3,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":628043,"discussion_content":"老大难的问题了，哈哈哈哈。\n\n说实在的，我也没特别好的的办法。如果你们本身就有那种排序机制，比如说我可以通过状态来判定消息是不是失序了，比如说当状态还是未支付的时候，你收到取消消息，这肯定是乱序了。那么你就可以尝试把取消消息重新发回去原本的消息队列上。\n\n另外一种有漏洞的做法就是借助延迟消息。比如说你 A1 消息在重试，A2 不管知不知道 A1 在重试，直接自己延迟一分钟发送。“一分钟”是假定你的 A1 肯定能在一分钟之内重试完成。\n\n当然，如果 A2 的发送者有办法知道 A1 还没发，那么就可以优化成只有当 A1 没发，A2 才会延迟，当然 A3，A4... 显然也要跟着延迟。\n\n比如说，你可以借助 redis，假设 key1=1 的时候，代表 A1 还没发。key1=2 的时候，A1 已经发了。那么 A2 的发送者看一眼 Redis 就知道了。\n\n不过，我的个人看法是……除非是面试吹牛，不然实践中直接告警拉到。就是在真的发现消息失序的时候，告警，人手工微调一下就可以。可用性高的话，你可能一个月才有一个两个这种失序的问题。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1694782475,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1072095,"avatar":"https://static001.geekbang.org/account/avatar/00/10/5b/df/bd258088.jpg","nickname":"focus","note":"","ucode":"D410E1E356BB29","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":640957,"discussion_content":"如果判断消费的是失序的消息，可不可以直接不做业务逻辑提交这个消息再发送一条到队列中","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1712023732,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":385410,"user_name":"sheep","can_delete":false,"product_type":"c1","uid":2770150,"ip_address":"广东","ucode":"DAC2036F08CE27","user_header":"https://static001.geekbang.org/account/avatar/00/2a/44/e6/2c97171c.jpg","comment_is_top":false,"comment_ctime":1702603733,"is_pvip":false,"replies":[{"id":140756,"content":"丢回去原本的分区就可以了，啥也不用做。但是消息积压的时候，你这个消息就要过很久才能消费到。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1704189297,"ip_address":"广东","comment_id":385410,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"ZhiguoXue_IT的留言中，老师这里回复了“你只需要检测有没有这个订单，或者状态是否符合，不符合你就丢回去原本的 topic 里面”，这里是丢回到原来的分区尾部？还是说创建一个生产者往对应topic发送原来的消息呢？","like_count":1,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":634915,"discussion_content":"丢回去原本的分区就可以了，啥也不用做。但是消息积压的时候，你这个消息就要过很久才能消费到。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1704189297,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":384835,"user_name":"LargeOrange","can_delete":false,"product_type":"c1","uid":1226255,"ip_address":"北京","ucode":"CDDB0E6E4F09C8","user_header":"https://static001.geekbang.org/account/avatar/00/12/b6/0f/e3550f48.jpg","comment_is_top":false,"comment_ctime":1701668653,"is_pvip":false,"replies":[{"id":140340,"content":"最简单的做法，就是重新哈希之后，目标分区暂停消费一会。举个例子来说，原本消息是哈希到 A 分区的，后面重新哈希到 B 了，那么 B 暂停一会就可以。暂停的时间就是考虑到 A 上的都被消费了的时间。如果有 A 上有消息积压就会有比较多的问题。\n\n如果业务上能够检测出来，那么就在 B 上消费的时候，重新丢回去 B 里面。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1701846304,"ip_address":"广东","comment_id":384835,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"老师你好，引入hash槽可以解决数据量平衡的问题，顺序消费的场景下，当某个槽被重新映射到新的partition下，怎么保证消息的顺序消费呢","like_count":1,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":633115,"discussion_content":"最简单的做法，就是重新哈希之后，目标分区暂停消费一会。举个例子来说，原本消息是哈希到 A 分区的，后面重新哈希到 B 了，那么 B 暂停一会就可以。暂停的时间就是考虑到 A 上的都被消费了的时间。如果有 A 上有消息积压就会有比较多的问题。\n\n如果业务上能够检测出来，那么就在 B 上消费的时候，重新丢回去 B 里面。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1701846304,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":380225,"user_name":"Sampson","can_delete":false,"product_type":"c1","uid":1418226,"ip_address":"上海","ucode":"BA78CA29A6D898","user_header":"https://static001.geekbang.org/account/avatar/00/15/a3/f2/ab8c5183.jpg","comment_is_top":false,"comment_ctime":1693228211,"is_pvip":false,"replies":[{"id":138546,"content":"分区挂了倒还好，毕竟生产者都发不出来。要解决 rebalance，有一个不太好的办法，但是勉强能用。就是消费者这边手动指定分区。\n\n这样做的话，就是要做好监控。一旦消费特定分区的消费者崩溃了，要及时启动另外一个消费者来消费同样地分区。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1693489105,"ip_address":"广东","comment_id":380225,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"老师这里有在使用kafka的多分区方案的时候有一个点，如果某个分区挂了，或者出发了rebalance，那消息岂不是无序了，而且对于其他业务来说也是不友好的。我之前会经常遇到这个问题，请教下这里改怎么弄呢","like_count":1,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":626927,"discussion_content":"分区挂了倒还好，毕竟生产者都发不出来。要解决 rebalance，有一个不太好的办法，但是勉强能用。就是消费者这边手动指定分区。\n\n这样做的话，就是要做好监控。一旦消费特定分区的消费者崩溃了，要及时启动另外一个消费者来消费同样地分区。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1693489105,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":1044292,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ef/44/5e172496.jpg","nickname":"Zen","note":"","ucode":"32DB75B62FE095","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":651522,"discussion_content":"借楼补充问一下。新增partition会不会触发rebalance， 除了assign绑定，怎么保证在不rebalance的情况下让新增的消费者消费新的partition","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1727004377,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":626927,"ip_address":"湖北","group_id":0},"score":651522,"extra":""}]}]},{"had_liked":false,"id":379875,"user_name":"Zwh","can_delete":false,"product_type":"c1","uid":1567820,"ip_address":"中国台湾","ucode":"1666710BE75CC8","user_header":"https://static001.geekbang.org/account/avatar/00/17/ec/4c/93a84658.jpg","comment_is_top":false,"comment_ctime":1692632179,"is_pvip":false,"replies":[{"id":138409,"content":"可以。你的思路就是，如果我前置消息不满足，我就临时放一个地方。控制住重试就可以。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1692892898,"ip_address":"广东","comment_id":379875,"utype":1}],"discussion_count":2,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"对于多分区下可能会出现的消息失序问题，新增一个乱序队列，消费者判断业务前置条件是否达成，若否就放入乱序队列，考虑增加延时和重试次数控制，乱序队列消费者收到消息后根据业务状态判断是否进行处理还是继续乱序，请问老师这个方案可行吗","like_count":1,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":626424,"discussion_content":"可以。你的思路就是，如果我前置消息不满足，我就临时放一个地方。控制住重试就可以。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1692892898,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2768731,"avatar":"","nickname":"public","note":"","ucode":"EF597BADCC526B","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":627605,"discussion_content":"那为什么不直接使用mq的重试机制？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1694334655,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":379310,"user_name":"利见大人","can_delete":false,"product_type":"c1","uid":1351552,"ip_address":"上海","ucode":"CBF390ECE3F8B5","user_header":"https://static001.geekbang.org/account/avatar/00/14/9f/80/2ead2573.jpg","comment_is_top":false,"comment_ctime":1691714132,"is_pvip":false,"replies":[{"id":138213,"content":"1. 你是说那个内存队列？就是载体不同。如果是内存队列，那么宕机就没了。\n2. 一样会有数据不均匀的问题，但是更加容易解决，因为你开启队列的时候，自己应用一下一致性哈希之类的算法就可以解决了。\n\n不过其实你可以考虑只用一个队列，线程都从这里面取。就是在最后要协调大家停下来批量提交麻烦一点，倒也还可以接受。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1691755011,"ip_address":"广东","comment_id":379310,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"老师您好，您好像忘更了关于解决消息堆积的章节哈！\n这章我有两个疑问？\n异步消费方案中的队列和多分区方案中的分区有什么分别？\n异步消息方案中的队列不会出现数据不均匀的问题吗？","like_count":1,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":625495,"discussion_content":"1. 你是说那个内存队列？就是载体不同。如果是内存队列，那么宕机就没了。\n2. 一样会有数据不均匀的问题，但是更加容易解决，因为你开启队列的时候，自己应用一下一致性哈希之类的算法就可以解决了。\n\n不过其实你可以考虑只用一个队列，线程都从这里面取。就是在最后要协调大家停下来批量提交麻烦一点，倒也还可以接受。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1691755011,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":390232,"user_name":"Z.","can_delete":false,"product_type":"c1","uid":1568589,"ip_address":"北京","ucode":"9C9C97C470D761","user_header":"https://static001.geekbang.org/account/avatar/00/17/ef/4d/83a56dad.jpg","comment_is_top":false,"comment_ctime":1714813222,"is_pvip":false,"replies":[{"id":141961,"content":"你首先要解决积压的问题，然后做好观测。你只要确定你最早的一个没有消费的消息，都过了你产生新分区的那个时间点，就可以开始让新分区消费者继续消费。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1715228760,"ip_address":"广东","comment_id":390232,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"我有一个疑问，在新增分区失序的问题中，让新分区消费者等待一段时间在消费，这个时间是积压消息来决定的，那么等待的这段时间会产生新的消息，那要怎么界定积压消息","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":644381,"discussion_content":"你首先要解决积压的问题，然后做好观测。你只要确定你最早的一个没有消费的消息，都过了你产生新分区的那个时间点，就可以开始让新分区消费者继续消费。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1715228760,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":387911,"user_name":"蓬蒿","can_delete":false,"product_type":"c1","uid":1316758,"ip_address":"江苏","ucode":"893F958B9DD161","user_header":"https://static001.geekbang.org/account/avatar/00/14/17/96/a10524f5.jpg","comment_is_top":false,"comment_ctime":1708918405,"is_pvip":false,"replies":[{"id":141343,"content":"1. 确实，极端情况会出现你说的问题。但是并不影响我这里的方案解决了大部分的数据倾斜问题。而且短时间的 QPS 激增不需要去管它，本身 Kafka 就能削峰。而如果你说长时间持续性的单个用户 QPS 激增，你给它一个白名单，让它自己独享一个 topic，彻底隔离掉；\n2. 它只会引起新分区上的消息短暂积压，不会引起失序。当你都积压了一大堆数据，比如说要好几个小时才能消费完的时候，你需要的不是增加分区，而是考虑先用异步消费的方案解决。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1709715016,"ip_address":"广东","comment_id":387911,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"我有两点疑问：\n1. 使用一致性哈希解决数据倾斜问题，但无法解决单个用户的热点，比如同一个用户，使用用户ID来选择分区，短时间内这个用户的qps激增一样会出现热点以及数据倾斜\n2. 增加分区导致消息失序的解决方案怎么看都不靠谱，因为消息积压了才要增加分区，说明积压消息的分区一直处于满载且缓慢流动的状态，等待3分钟可能解决了msg2和msg1的顺序问题，但会增加msg15和msg16失序的问题，本质上没有解决问题。\n\n以上是个人浅见。","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":638590,"discussion_content":"1. 确实，极端情况会出现你说的问题。但是并不影响我这里的方案解决了大部分的数据倾斜问题。而且短时间的 QPS 激增不需要去管它，本身 Kafka 就能削峰。而如果你说长时间持续性的单个用户 QPS 激增，你给它一个白名单，让它自己独享一个 topic，彻底隔离掉；\n2. 它只会引起新分区上的消息短暂积压，不会引起失序。当你都积压了一大堆数据，比如说要好几个小时才能消费完的时候，你需要的不是增加分区，而是考虑先用异步消费的方案解决。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1709715016,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":386239,"user_name":"Qualifor","can_delete":false,"product_type":"c1","uid":1658706,"ip_address":"北京","ucode":"8F42453286719C","user_header":"https://static001.geekbang.org/account/avatar/00/19/4f/52/791d0f5e.jpg","comment_is_top":false,"comment_ctime":1704365965,"is_pvip":false,"replies":[{"id":141061,"content":"有一个简单的做法，你可以尝试，就是这个特定的分区，你会消费，但是你只是读了消息之后啥也不干。等到你确定老分区上的老数据消费之后，你可以重置这个分区的偏移量，这一次消费就是真的执行业务逻辑了。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1705927762,"ip_address":"广东","comment_id":386239,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100551601,"comment_content":"你好，请问下老师，如何做到新增的分区不让消费者消费呢？kafka 有对应的功能吗？","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":636308,"discussion_content":"有一个简单的做法，你可以尝试，就是这个特定的分区，你会消费，但是你只是读了消息之后啥也不干。等到你确定老分区上的老数据消费之后，你可以重置这个分区的偏移量，这一次消费就是真的执行业务逻辑了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1705927762,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":385366,"user_name":"sheep","can_delete":false,"product_type":"c1","uid":2770150,"ip_address":"广东","ucode":"DAC2036F08CE27","user_header":"https://static001.geekbang.org/account/avatar/00/2a/44/e6/2c97171c.jpg","comment_is_top":false,"comment_ctime":1702520875,"is_pvip":false,"replies":[{"id":140759,"content":"1.1 不需要调整。你可以认为，你的环是不变的，变的是上面的节点；\n1.2 也可以。\n2 看你业务有没有这个要求。在有序消息的场景下，就是需要的。最好就是调整后的新分区，暂时停止一段时间消费。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1704189477,"ip_address":"广东","comment_id":385366,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100551601,"comment_content":"“手工调整槽的映射关系或者哈希环上节点的分布”，\n1. 这里使用一致性哈希算法时候，采用插入几个分区节点来分散数据较多的分区\n 1.1 这里多几个分区后，是不是一致性哈希算法的计算方法也要调整，否则只会定位在之前的分区所组成的哈希环上？\n 1.2 那这里我可以不插入几个分区，转为调整发布者的一致性哈希算法，让指定分区的哈希范围变长或变短来分散数据。这样子的话，除了每个发布者都要调整算法之外，还会有其他什么问题？\n2. 手工调整槽的映射关系\n  2.1 会出现被调整的槽上有数据的情况吗(比如: 槽5属于分区2，然后上有槽上5个数据，这时候要调整到分区1)，这时候是否需要等待数据消费完，再进行调整呢?\n  2.2 调整槽所属的分区，也会出现消息失序的情况吧？","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":634918,"discussion_content":"1.1 不需要调整。你可以认为，你的环是不变的，变的是上面的节点；\n1.2 也可以。\n2 看你业务有没有这个要求。在有序消息的场景下，就是需要的。最好就是调整后的新分区，暂时停止一段时间消费。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1704189477,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2,\"source\":0}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":383319,"user_name":"KK","can_delete":false,"product_type":"c1","uid":1324863,"ip_address":"北京","ucode":"FFC31A3FE3A285","user_header":"https://static001.geekbang.org/account/avatar/00/14/37/3f/a9127a73.jpg","comment_is_top":false,"comment_ctime":1698843580,"is_pvip":false,"replies":[{"id":139751,"content":"你的哈希算法不变，并且队列数量也不变，那就肯定是有序的。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1699282596,"ip_address":"广东","comment_id":383319,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100551601,"comment_content":"在【异步消费】中，消费者线程，从kafka中取出消息之后，通过根据业务把hash放到对应的队列中，在队列中的消息一定是有序的吗？","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":631066,"discussion_content":"你的哈希算法不变，并且队列数量也不变，那就肯定是有序的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1699282596,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":383300,"user_name":"KK","can_delete":false,"product_type":"c1","uid":1324863,"ip_address":"北京","ucode":"FFC31A3FE3A285","user_header":"https://static001.geekbang.org/account/avatar/00/14/37/3f/a9127a73.jpg","comment_is_top":false,"comment_ctime":1698829888,"is_pvip":false,"replies":[{"id":139752,"content":"显示指定分区，我是指有多个分区的情况。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1699282646,"ip_address":"广东","comment_id":383300,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100551601,"comment_content":"“对于消费端来说，只有一个分区，那么就只能有一个消费者消费”，与前文&quot;可以显式地指定消费哪个分区的数据&quot;,是否矛盾呀？只有一个分区，就只能有一个消费者消费吗？","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":631067,"discussion_content":"显示指定分区，我是指有多个分区的情况。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1699282646,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":380273,"user_name":"itschenxiang","can_delete":false,"product_type":"c1","uid":1519547,"ip_address":"广东","ucode":"7D90194AC52435","user_header":"https://static001.geekbang.org/account/avatar/00/17/2f/bb/f663ac5a.jpg","comment_is_top":false,"comment_ctime":1693295249,"is_pvip":false,"replies":[{"id":138540,"content":"不不不，这个的关键点是你可以引入逻辑上槽的概念，你不一定非得用 CRC16 来计算槽。你可以说选择你的业务特征，用几个哈希函数，一通猛算，得到一个值，这个值就是你的槽的号。我这里用 1024 只是举个例子。\n\n更好的做法是固定分配。比如说我直接指定，一通猛算出来的值如果是 1，2,1023,345 就到分区 0。就有点你手动分配槽到 Redis 节点上的意思。借助配置中心还可以动态更新这个分配，也很方便。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1693488453,"ip_address":"广东","comment_id":380273,"utype":1}],"discussion_count":2,"race_medal":0,"score":3,"product_id":100551601,"comment_content":"多分区，哈希槽方案我有点不太理解，通过crc16(key) &amp; 1024是能够比较均匀地分配到每个槽中吗？","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":626921,"discussion_content":"不不不，这个的关键点是你可以引入逻辑上槽的概念，你不一定非得用 CRC16 来计算槽。你可以说选择你的业务特征，用几个哈希函数，一通猛算，得到一个值，这个值就是你的槽的号。我这里用 1024 只是举个例子。\n\n更好的做法是固定分配。比如说我直接指定，一通猛算出来的值如果是 1，2,1023,345 就到分区 0。就有点你手动分配槽到 Redis 节点上的意思。借助配置中心还可以动态更新这个分配，也很方便。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1693488454,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":1519547,"avatar":"https://static001.geekbang.org/account/avatar/00/17/2f/bb/f663ac5a.jpg","nickname":"itschenxiang","note":"","ucode":"7D90194AC52435","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":627172,"discussion_content":"那这么看，为了保证均匀分配，还是结合业务key设计分配算法，感觉和redis槽模型关系不大😂","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1693878314,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":626921,"ip_address":"广东","group_id":0},"score":627172,"extra":""}]}]},{"had_liked":false,"id":379384,"user_name":"陈斌","can_delete":false,"product_type":"c1","uid":1367048,"ip_address":"广东","ucode":"B639AB5F6AA03D","user_header":"https://static001.geekbang.org/account/avatar/00/14/dc/08/64f5ab52.jpg","comment_is_top":false,"comment_ctime":1691859221,"is_pvip":false,"replies":[{"id":138261,"content":"你的思考很有深度！\n你说的是两件事，但是可以通过一个手段来解决。要保持异步消费还要有序，是不能用线程池的，理由你已经分析到了。你只能考虑手动启动多个线程。当然，如果你用的是 JAVA，那么你可以用只有一个线程的线程池。而后，剩下的事情就都是你分发的事情了，比如说你可以说编号为 1，2,3 的线程池就是给你不忙的业务用的，其它就是给你忙的业务用的。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1692079991,"ip_address":"广东","comment_id":379384,"utype":1}],"discussion_count":2,"race_medal":0,"score":3,"product_id":100551601,"comment_content":"\n老师你好~\n1、如果某个分区消息积压了就启用异步消费，我认为思路整体方向肯定可行的，这个解决方案也会引入更多的思考点。\n例如：这个解决思路就是使用线程池去异步处理消息，这就有会引出一个问题：线程池的核心线程数的问题（需要根据处理消息是CPU密集型还是IO密集型来设置核心线程个数）。还有如果要求业务内消息有序，需要考虑到同一个业务的消息应该被同一个线程执行，这个时候是否还能使用线程池去异步处理消息，线程池没有指定那个消息被那个线程消费的能力。只能手动给线程编号，然后根据业务ID去分配消息被那个线程处理，同样如果消息又被积压，一样会有增加线程数而引起消息失序的问题。还有一个问题就是如果该分区处理了10个业务的消息，其中只有2个业务消息特别多，我需要怎么把其他8个不怎么忙的业务通过异步消费的方式隔离出来，怎么做到业务之间相互解耦。  （说的有点乱）\n\n2、数据分布不均匀：例如分库分表怎么使得分片后的数据均匀分布。流量分布不均匀：初步想到是Nginx的负载均衡算法会用到这个。","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":625700,"discussion_content":"你的思考很有深度！\n你说的是两件事，但是可以通过一个手段来解决。要保持异步消费还要有序，是不能用线程池的，理由你已经分析到了。你只能考虑手动启动多个线程。当然，如果你用的是 JAVA，那么你可以用只有一个线程的线程池。而后，剩下的事情就都是你分发的事情了，比如说你可以说编号为 1，2,3 的线程池就是给你不忙的业务用的，其它就是给你忙的业务用的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1692079991,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2328971,"avatar":"","nickname":"Geek8004","note":"","ucode":"B3828F6414BDB0","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":626787,"discussion_content":"老师好,hash槽的方案,如果槽和分区的关系发生了变化,那么会不会造成分区里面的数据此时顺序乱掉了?","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1693381727,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"中国香港","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":379353,"user_name":"peter","can_delete":false,"product_type":"c1","uid":1058183,"ip_address":"北京","ucode":"261C3FC001DE2D","user_header":"https://static001.geekbang.org/account/avatar/00/10/25/87/f3a69d1b.jpg","comment_is_top":false,"comment_ctime":1691806901,"is_pvip":false,"replies":[{"id":138259,"content":"1. 你在设计槽的时候，根据业务特征来确定的槽，那就不会。比如说你用 ID % 1024 来选择槽，那么同一个 ID  的肯定在同一个槽。\n2. 不成立……我没听 Kafka 的团队出来说我们就是为了大数据搞出来的。相反，先在稍微有点规模的公司，都会使用。但是也得承认， Kafka 在大数据下表现极其优异。","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1692078610,"ip_address":"广东","comment_id":379353,"utype":1}],"discussion_count":2,"race_medal":0,"score":3,"product_id":100551601,"comment_content":"请教老师两个问题：\nQ1：借用Redis槽的思想来解决数据分布不均匀的问题，那么，同一个业务的消息会被分配到不同的分区上吗？如果同一个业务的消息被分配到不同的分区上，那么，会产生消息失序的问题吗？\nQ2：有个说法是：kafka是专门用于大数据处理的消息队列，是专为大数据而生的。这个说法成立吗？（这个问题在第22课提问过了，当时打错了几个关键字，导致老师不理解，抱歉）","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":625695,"discussion_content":"1. 你在设计槽的时候，根据业务特征来确定的槽，那就不会。比如说你用 ID % 1024 来选择槽，那么同一个 ID  的肯定在同一个槽。\n2. 不成立……我没听 Kafka 的团队出来说我们就是为了大数据搞出来的。相反，先在稍微有点规模的公司，都会使用。但是也得承认， Kafka 在大数据下表现极其优异。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1692078611,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2328971,"avatar":"","nickname":"Geek8004","note":"","ucode":"B3828F6414BDB0","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":626786,"discussion_content":"楼主好,我有两个问题想讨论下:\n1.给线程编号也解决不了有序性的问题吧.线程之间是抢占的,比如来了3,4,5,6的消息,按道理按照应该按照从小到大的顺序3,4,5,6进行消费,但是你手动编号3,4,5,6编号的线程,子线程之间有可能先执行4,再执行3,这是一个无序的.\n2. 线程之间采用join()的方式可能能解决但是这样性能会不会太差了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1693381654,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"中国香港","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":379315,"user_name":"进击的和和","can_delete":false,"product_type":"c1","uid":2986043,"ip_address":"","ucode":"8978AF077FA6AD","user_header":"https://static001.geekbang.org/account/avatar/00/2d/90/3b/791d0f5e.jpg","comment_is_top":false,"comment_ctime":1691719319,"is_pvip":false,"replies":[{"id":138262,"content":"1. 感谢勘误！\n2. 没……应该说思路都是要协调，不过怎么协调是有很多做法的。比如说可以考虑事件驱动中的前置事件检测，也可以考虑中间引入一个什么东西来辅助排队。不过都是协调者的事情。\n3. 答案就是你的槽只要足够多，就不会有均匀性问题。如果你只有十个槽，那么可能某个槽数据很多。但是你有一万个槽，那么你就可以通过合理分配业务到不同的槽上，保证数据均匀分散了。\n4. 哈哈哈，虽然没用过你的思路，但是我一琢磨还是可以的，这个东西可以让中间件研发的人来封装。难点我觉得应该是我发现 topic 数量修改了之后，我该发消息到原本的分区，那么什么时候发到新的分区呢？","user_name":"作者回复","user_name_real":"编辑","uid":1176655,"ctime":1692080233,"ip_address":"广东","comment_id":379315,"utype":1}],"discussion_count":1,"race_medal":0,"score":3,"product_id":100551601,"comment_content":"老师你好\n(1)如果 msg2 先到了，但是 msg1 还没出来，那么这个协调者要有办法让 msg2 的消费者 B 停下来，暂时不消费 msg1。这里好像想表达的是描述的写反了。\n(2)如果想保证一个topic在多个分区有序还有什么别的思路和方法吗?\n(3)关于多分区数据不均匀。因为发送方要按照业务特征来选择分区,可能造成数据不均匀,如果使用了redis的哈希槽,只是槽多了,但是这个特征还是会分配到某些槽上,这些槽对应的映射还是数据较多的那几个分区,这里还要用方式或方法来计算下呢\n(4)增加分区引起消息失序。假设分区里的数据很少,等三分钟这个只是概率上会降低失序的可能,还可以监控发现问题,手动修复一下就好了。这里能不能用某种方式监控分区了没有数据才加入分区,或者说才开始给新的分区分配数据。但是就是因为消息积压严重,才需要立刻增加分区减轻消极积压分区的负担,所以不应该等消息积压分区消费完成才进行分配。这里可以在业务msg2的业务中增加逻辑,某个topic下最近一次的分区数,如发现某个topic下分区数发生变化,这个消息还是发给之前那个分区,然后修改最近一次的分区数,不知道这样行不行,并且业务逻辑太麻烦了,还有什么好的方式吗","like_count":0,"discussions":[{"author":{"id":1176655,"avatar":"https://static001.geekbang.org/account/avatar/00/11/f4/4f/aa916c8c.jpg","nickname":"邓小明","note":"","ucode":"02243D1F7492A6","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":625701,"discussion_content":"1. 感谢勘误！\n2. 没……应该说思路都是要协调，不过怎么协调是有很多做法的。比如说可以考虑事件驱动中的前置事件检测，也可以考虑中间引入一个什么东西来辅助排队。不过都是协调者的事情。\n3. 答案就是你的槽只要足够多，就不会有均匀性问题。如果你只有十个槽，那么可能某个槽数据很多。但是你有一万个槽，那么你就可以通过合理分配业务到不同的槽上，保证数据均匀分散了。\n4. 哈哈哈，虽然没用过你的思路，但是我一琢磨还是可以的，这个东西可以让中间件研发的人来封装。难点我觉得应该是我发现 topic 数量修改了之后，我该发消息到原本的分区，那么什么时候发到新的分区呢？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1692080233,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":390330,"user_name":"达芬奇","can_delete":false,"product_type":"c1","uid":2451310,"ip_address":"北京","ucode":"B174F5347557B3","user_header":"https://static001.geekbang.org/account/avatar/00/25/67/6e/ec7299ec.jpg","comment_is_top":false,"comment_ctime":1715142017,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":3,"product_id":100551601,"comment_content":"文章写得非常好，点赞","like_count":0}]}