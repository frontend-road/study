{"id":423602,"title":"09 | Bigtable（二）：不认识“主人”的分布式架构","content":"<p>你好，我是徐文浩。上一讲里我们一起分析了如何对一个MySQL集群进行扩容，来支撑更高的随机读写请求。而在扩容过程中遇到的种种不便，也让我们深入理解了Bigtable的设计中需要重点解决的问题。</p><p>第一个问题，自然还是如何支撑好每秒十万、乃至百万级别的随机读写请求。</p><p>第二个问题，则是如何解决好“可伸缩性”和“可运维性”的问题。在一个上千台服务器的集群上，Bigtable怎么能够做到自动分片和灾难恢复。</p><p>今天我们就先来看看第二个问题，其实也是Bigtable的整体架构。而第一个问题，一半要依赖第二个问题，也就是可以不断将集群扩容到成百上千个节点。另一半，则取决于在每一个节点上，Bigtable的读写操作是怎么进行的，这一部分我们会放到下一讲，也就是Bigtable的底层存储SSTable究竟是怎么一回事儿。</p><p>那么接下来，我们就一起来看看Bigtable的整体架构。在学完这一讲后，希望你可以掌握Bigtable三个重要的知识点：</p><ul>\n<li>第一个，Bigtable是如何进行数据分区，使得整个集群灵活可扩展的；</li>\n<li>第二个，Bigtable是如何设计，使得Master不会成为单点故障，乃至单点性能的瓶颈；</li>\n<li>最后，自然是整个Bigtable的整体架构和组件由哪些东西组成。</li>\n</ul><!-- [[[read_end]]] --><p>相信在学完这一讲后，你也能自己设计一个分布式数据库的基本架构。并且，你也会对分布式数据库设计的分区和复制机制、系统整体架构设计，以及如何分析和优化整个架构的瓶颈所在，有一个清晰的了解。</p><h2>理解Bigtable的基本数据模型</h2><p>在进入到针对Bigtable的架构设计解读之前，我们先来弄清楚Bigtable基本的数据模型。</p><p>上一讲里，我们举了很多MySQL的例子。在这个过程中，相信你会发现，一旦我们开始分库分表了，我们就很难使用关系数据库的一系列的特性了。比如SQL里面的Join功能，或者是跨行的事务。因为这些功能在分库分表的场景下，都要涉及到多台服务器，不是说做不到，但是问题一下子就复杂了。</p><p>所以，Bigtable在一开始，也不准备先考虑事务、Join等高级的功能，而是<strong>把核心放在了“可伸缩性”上</strong>。因此，Bigtable自己的数据模型也特别简单，是一个很宽的稀疏表。</p><p>每一张Bigtable的表都特别简单，每一行就是一条数据：</p><ul>\n<li>一条数据里面，有一个行键（Row Key），也就是这条数据的主键，Bigtable提供了通过这个行键随机读写这条记录的接口。因为总是通过行键来读写数据，所以很多人也把这样的数据库叫做<strong>KV数据库</strong>。</li>\n<li>每一行里的数据呢，你需要指定一些列族（Column Family），每个列族下，你不需要指定列（Column）。<strong>每一条数据都可以有属于自己的列，每一行数据的列也可以完全不一样</strong>，因为列不是固定的。这个所谓不是固定的，其实就是列下面没有值。因为Bigtable在底层存储数据的时候，每一条记录都要把列和值存下来，没有值，意味着对应的这一行就没有这个列。这也是为什么说Bigtable是一个“稀疏”的表。</li>\n<li>列下面如果有值的话，可以存储多个版本，不同版本都会存上对应版本的时间戳（Timestamp），你可以指定保留最近的N个版本（比如N=3，就是保留时间戳最近的三个版本），也可以指定保留某一个时间点之后的版本。</li>\n</ul><p><img src=\"https://static001.geekbang.org/resource/image/8a/ac/8a03591283de69a12e1b9fe9179815ac.jpg?wh=2000x1125\" alt=\"\"></p><p>其实，这里的有些命名容易让人误解，比如列族，这个名字很容易让人误解Bigtable是一个基于列存储的数据库。但事实完全不是这样，我觉得<strong>对于列族，更合理的解读是，它是一张“物理表”，同一个列族下的数据会在物理上存储在一起。而整个表，是一张“逻辑表”。</strong></p><p>在现实当中，Bigtable的开源实现HBase，就是把每一个列族的数据存储在同一个HFile文件里。而在Bigtable的论文中，Google定义了一个叫做<strong>本地组</strong>（Locality Group）的概念，我们可以把多个列族放在同一个本地组中，而同一个本地组的所有列的数据，都会存储在同一个SSTable文件里。</p><p>这个设计，就使得我们不需要针对字段多的数据表，像MySQL那样，进行纵向拆表了。</p><p>Bigtable的这个数据模型，使得我们能很容易地去增加列，而且增加列并不算是修改Bigtable里一张表的Schema，而是在某些这个列需要有值的行里面，直接写入数据就好了。这里的列和值，其实是直接以key-value键值对的形式直接存储下来的。</p><p>这个灵活、稀疏而又宽的表，特别适合早期的互联网业务。虽然数据量很大，但是数据本身的Schema我们可能没有想清楚，加减字段都不需要停机或者锁表。要知道，MySQL直到5.5版本，用ALTER命令修改表结构仍然需要将整张表锁住。并且在锁住这张表的时候，我们是不能往表里写数据的。对于一张数据量很大的表来说，这会让整张表有很长一段时间不能写入数据。</p><p>而Bigtable这个稀疏列的设计，就为我们带来了很大的灵活性，如同《架构整洁之道》的作者<a href=\"http://cleancoder.com/products\">Uncle Bob</a>说的那样：“架构师的工作不是作出决策，而是尽可能久地推迟决策，在现在不作出重大决策的情况下构建程序，以便以后有足够信息时再作出决策。”</p><h2>数据分区，可伸缩的第一步</h2><p>搞清楚了Bigtable的数据模型，我们再来一起看一看，Bigtable是怎么解决上一讲MySQL集群解决不好的<strong>水平分库问题</strong>的。</p><p>把一个数据表，根据主键的不同，拆分到多个不同的服务器上，在分布式数据库里被称之为<strong>数据分区</strong>（ Paritioning）。分区之后的每一片数据，在不同的分布式系统里有不同的名字，在MySQL里呢，我们一般叫做Shard，Bigtable里则叫做Tablet。</p><p>上一讲里，MySQL集群的分区之所以遇到种种困难，是因为我们通过取模函数来进行分区，也就是所谓的<strong>哈希分区</strong>。我们会拿一个字段哈希取模，然后划分到预先定好N个分片里面。这里最大的问题，在于分区需要在一开始就设计好，而不是自动随我们的数据变化动态调整的。</p><p>但是往往计划不如变化快，当我们的业务变化和计划稍有不同，就会遇到需要搬运数据或者各个分片负载不均衡的情况。你可以看一下我从上一讲里搬过来的这张图，当我们将4台服务器扩展到6台服务器的时候，哈希分区的方式使得我们要在网络上搬运整个数据库2/3的数据。</p><p><img src=\"https://static001.geekbang.org/resource/image/57/72/57f28c2598ec283c97d103c0ccb81572.jpg?wh=1920x1080\" alt=\"图片\" title=\"上一讲里，我们看过这个图片，哈希分区如果不是翻倍扩容，就需要搬运大量数据\"></p><p>所以，在Bigtable里，我们就采用了另外一种分区方式，也就是<strong>动态区间分区</strong>。我们不再是一开始就定义好需要多少个机器，应该怎么分区，而是采用了一种<strong>自动去“分裂”（split）的方式</strong>来动态地进行分区。</p><p>我们的整个数据表，会按照行键排好序，然后按照连续的行键一段段地分区。如果某一段行键的区间里，写的数据越来越多，占用的存储空间越来越大，那么整个系统会自动地将这个分区一分为二，变成两个分区。而如果某一个区间段的数据被删掉了很多，占用的空间越来越小了，那么我们就会自动把这个分区和它旁边的分区合并到一起。</p><p>这个分区的过程，就好像你按照A~Z的字母顺序去管理你的书的过程。一开始，你只有一个空箱子放在地上，然后你把你的书按照书名的拼音，从上到下放在箱子里。当有一本新书需要放进来的时候，你就按照字母顺序插在某两本书中间。而当箱子放不下的时候，你就再拿一个空箱子，放在放不下的箱子下面，然后把之前的箱子里的图书从中间一分，把下面的一半放到新箱子里。</p><p>而我们删除数据的时候，就要把书从箱子里面拿走。当两个相邻的箱子里都很空的时候，我们就可以把两个箱子里面的书放到一个箱子里面，然后把腾出来的空箱子挪走。这里的一个个“箱子”就是我们的分片，这里面的一本本书，就是我们的一行数据，而书名的拼音，就是我们的行键。可能以A、B、C开头的书多一些，那么它们占用的分区就会多一些，以U、V、W开头的书少一些，可能这些书就都在一个分区里面。</p><p><img src=\"https://static001.geekbang.org/resource/image/07/b2/07fbab143fd8df45bcd3ae0064fa41b2.jpg?wh=2000x1344\" alt=\"\" title=\"动态区间分区：自动根据当前数据分布，进行分区或者合并\"></p><p>采用这样的方式，你会发现，你可以动态地调整数据是如何分区的，并且每个分区在数据量上，都会相对比较均匀。而且，在分区发生变化的时候，你需要调整的只有一个分区，再没有需要大量搬运数据的压力了。</p><h2>通过Master + Chubby进行分区管理</h2><p>那么看到这儿，你可能要问了：要是上一讲的MySQL集群也用这样的分区方式，问题是不是就解决了？</p><p>答案当然是办不到了。因为我们还需要有一套存储、管理分区信息的机制，这在哈希分片的MySQL集群里是没有的。在Bigtable里，我们是通过<strong>Master和Chubby</strong>这两个组件来完成这个任务的。这两个组件，加上每个分片提供服务的<strong>Tablet Server</strong>，以及实际存储数据的<strong>GFS</strong>，<strong>共同组成了整个Bigtable集群</strong>。</p><h3>Master、Chubby和Tablet Server的用途</h3><p>Tablet Server的角色最明确，就是用来<strong>实际提供数据读写服务</strong>的。一个Tablet Server上会分配到10到1000个Tablets，Tablet Server就去负责这些Tablets的读写请求，并且在单个Tablet太大的时候，对它们进行分裂。</p><p>而哪些Tablets分配给哪个Tablet Server，自然是由Master负责的，而且Master可以根据每个Tablet Server的负载进行动态的调度，也就是Master还能起到<strong>负载均衡</strong>（load balance）的作用。而这一点，也是MySQL集群很难做到的。</p><p>这是因为，Bigtable的Tablet Server只负责在线服务，不负责数据存储。实际的存储，是通过一种叫做SSTable的数据格式写入到GFS上的。也就是<strong>Bigtable里，数据存储和在线服务的职责是完全分离的</strong>。我们调度Tablet的时候，只是调度在线服务的负载，并不需要把数据也一并搬运走。</p><p>而在上一讲里的<strong>MySQL集群，服务职责和数据存储是在同一个节点上的</strong>。我们要想把负载大的节点调度到其他地方去，就意味着数据也要一并迁移走，而复制和迁移数据又会进一步加大节点的负载，很有可能造成雪崩效应。</p><p><img src=\"https://static001.geekbang.org/resource/image/0e/44/0ea783a0ce3218bc4af2aeaec29yy344.jpg?wh=2000x1125\" alt=\"\" title=\"Bigtable的集群，在线服务和存储是分离的，数据存储依赖GFS[br]我们可以把Bigtable的进程直接部署在GFS里[br]但即便这样，我们也并不保障Tablet Server所服务的Tablets下的底层SSTable数据，在同一个物理服务器上\"></p><p>事实上，Master一共会负责5项工作：</p><ul>\n<li>分配Tablets给Tablet Server；</li>\n<li>检测Tablet Server的新增和过期；</li>\n<li>平衡Tablet Server的负载；</li>\n<li>对于GFS上的数据进行垃圾回收（GC）；</li>\n<li>管理表（Table）和列族的Schema变更，比如表和列族的创建与删除。</li>\n</ul><p>那看到这里你可能要问了，好像Master加上Tablet Server就足以组成Bigtable了，<strong>为什么还有一个Chubby这个组件呢？</strong>别着急，你接着往下看。</p><p>Bigtable需要Chubby来搞定这么几件事儿：</p><ul>\n<li>确保我们只有一个Master；</li>\n<li>存储Bigtable数据的引导位置（Bootstrap Location）；</li>\n<li>发现Tablet Servers以及在它们终止之后完成清理工作；</li>\n<li>存储Bigtable的Schema信息；</li>\n<li>存储ACL，也就是Bigtable的访问权限。</li>\n</ul><p>这里面的最后两项只是简单的数据存储功能，我们就不多讲了，我们重点来看看前三项。</p><p>如果没有Chubby的话，我能想到最直接的集群管理方案，就是让所有的Tablet Server直接和Master通信，把分区信息以及Tablets分配到哪些Tablet Server，也直接放在Master的内存里面。这个办法，就和我们之前在GFS里的办法一样。但是这个方案，也就使得Master变成了一个<strong>单点故障点</strong>（SPOF-Single Point of Failure）。当然，我们可以通过Backup Master以及Shadow Master等方式，来尽可能提升可用性。</p><p>可是这样第一个问题就来了，我们在GFS的论文里面说过，我们可以通过一个外部服务去监控Master的存活，等它挂了之后，自动切换到Backup Master。但是，<strong>我们怎么知道Master是真的挂了，还是只是“外部服务”和Master之间的网络出现故障了呢？</strong></p><p>如果是后者的话，我们很有可能会遇到一个很糟糕的情况，就是系统里面出现了两个Master。这个时候，可能两个客户端分别认为这两个Master是真的，当它们分头在两边写入数据的时候，我们就会遇到<strong>数据不一致</strong>的问题。</p><p>那么Chubby，就是这里的这个<strong>外部服务</strong>，不过Chubby不是1台服务器，而是5台服务器组成的一个集群，它会通过Paxos这样的共识算法，来确保不会出现误判。而且因为它有5台服务器，所以也一并解决了高可用的问题，就算挂个1~2台，也并不会丢数据。关于具体Chubby的原理和使用，我们会在后面讲解Chubby论文的时候专门介绍，今天就先不展开了。</p><h3>为什么数据读写不需要Master？</h3><p>Chubby帮我们保障了只有一个Master，那么我们再来看看分区和Tablets的分配信息，这些信息也没有放在Master。Bigtable在这里用了一个很巧妙的方法，就是直接把这个信息，存成了Bigtable的一张<strong>METADATA表</strong>，而这张表在哪里呢，它是直接存放在Bigtable集群里面的，其实METADATA表自己就是一张Bigtable的数据表。</p><p>这其实有点像MySQL里面的information_schema表，也就是数据库定义了一张特殊的表，用来存放自己的元数据。不过，Bigtable是一个分布式数据库，所以我们还要知道，这个元数据究竟存放在哪个Tablet Server里，这个就需要通过Chubby来告诉我们了。</p><ul>\n<li>Bigtable在Chubby里的一个指定的文件里，存放了一个叫做<strong>Root Tablet</strong>的分区所在的位置。</li>\n<li>然后，这个Root Tablet的分区，是METADATA表的第一个分区，<strong>这个分区永远不会分裂</strong>。它里面存的，是METADATA里其他Tablets所在的位置。</li>\n<li>而METADATA剩下的这些Tablets，每一个Tablet中，都存放了用户创建的那些数据表，所包含的Tablets所在的位置，也就是所谓的User Tablets的位置。</li>\n</ul><p><img src=\"https://static001.geekbang.org/resource/image/aa/2c/aa09087c19f6a358c7769272yy2f442c.jpg?wh=2000x1344\" alt=\"\"></p><p>这里我们来看一个具体的Bigtable数据读写的例子，来帮助你理解这样一个三层结构。比如，客户端想要根据订单号，查找我们的订单信息，订单都存在Bigtable的ECOMMERCE_ORDERS表里，这张要查的订单号，就是A20210101RST。</p><p>那么，我们的客户端具体是怎么查询的呢？</p><ol>\n<li>客户端先去发起请求，查询Chubby，看我们的Root Tablet在哪里。</li>\n<li>Chubby会告诉客户端，Root Tablet在5号Tablet Server，这里我们简写成TS5。</li>\n<li>客户端呢，会再向TS5发起请求，说我要查Root Tablet，告诉我哪一个METADATA Tablet里，存放了ECOMMERCE_ORDERS业务表，行键为A20210101RST的记录的位置。</li>\n<li>TS5会从Root Tablet里面查询，然后告诉客户端，说这个记录的位置啊，你可以从TS8上面的METADATA的tablet 107，找到这个信息。</li>\n<li>然后，客户端再发起请求到TS8，说我要在tablet 107里面，找ECOMMERCE_ORDERS表，行键为A20210101RST具体在哪里。</li>\n<li>TS8告诉客户端，这个数据在TS20的tablet 253里面。</li>\n<li>客户端发起最后一次请求，去问TS20的tablet 253，问ECOMMERCE_ORDERS表，行键为A20210101RST的具体数据。</li>\n<li>TS20最终会把数据返回给客户端。</li>\n</ol><p><img src=\"https://static001.geekbang.org/resource/image/28/5a/28c60e5ed395652894dd9f6b91b2475a.jpg?wh=1920x1290\" alt=\"图片\" title=\"一次Bigtable的查询过程[br]会有3次网络请求，找到数据所在的位置[br]再通过1次网络请求获取到具体数据\"></p><p>可以看到，在这个过程里，我们用了三次网络查询，找到了想要查询的数据的具体位置，然后再发起一次请求拿到最终的实际数据。一般我们会把前三次查询位置结果缓存起来，以减少往返的网络查询次数。而对于整个METADATA表来说，我们都会把它们保留在<strong>内存</strong>里，这样每个Bigtable请求都要读写的数据，就不需要通过访问GFS来读取到了。</p><p>这个Tablet分区信息，其实是一个三层Tablet信息存储的架构，<strong>而三层结构让Bigtable可以“伸缩”到足够大</strong>。METADATA的一条记录，大约是1KB，而METADATA的Tablet如果限制在128MB，三层记录可以存下大约<code> (128*1000)**2=2**34</code>个Tablet的位置，也就是大约160亿个Tablet，肯定是够用了。</p><p>这个设计带来了一个很大的好处，就是<strong>查询Tablets在哪里这件事情，尽可能地被分摊到了Bigtable的整个集群，而不是集中在某一个Master节点上。</strong>而唯一所有人都需要查询的Root Tablet的位置和里面的数据，考虑到Root Tablet不会分裂，并且客户端可以有缓存，Chubby和Root Tablet所在的Tablet服务器也不会有太大压力。</p><p>另外你还会发现，在整个数据读写的过程中，客户端是不需要经过Master的。即使Master节点已经挂掉了，也不会影响数据的正常读写。客户端不需要认识Master这个“主人”，也不依赖Master这个“主人”为我们提供服务。这个设计，让Bigtable更加“高可用”了。</p><p>而如果我们回顾前面整个查询过程，其实就很容易理解，为什么Chubby里面存的叫做Bigtable的引导位置，因为这个过程和操作系统启动的过程很类似，都是要从一个固定的位置读取信息，来获得后面的动态的信息。在操作系统里，这个是读取硬盘的第一个扇区，而在Bigtable里，则是Chubby里存放Root Tablet位置的固定文件。</p><h3>Master的调度者角色</h3><p>的确，在单纯的数据读写的过程中不需要Master。Master只负责Tablets的调度而已，而且这个调度功能，也对Chubby有所依赖。我们来看一看这个过程是怎么样的：</p><ol>\n<li>所有的Tablet Server，一旦上线，就会在Chubby下的一个指定目录，获得一个和自己名字相同的<strong>独占锁</strong>（exclusive lock）。你可以看作是，Tablet Server把自己注册到集群上了。</li>\n<li>Master会一直监听这个目录，当发现一个Tablet Server注册了，它就知道有一个新的Tablet Server可以用了，也就是可以分配Tablets。</li>\n<li>分配Tablets的情况很多，可能是因为其他的Tablet Server挂了，导致部分Tablets没有分配出去，或者因为别的Tablet Server的负载太大，这些情况都可以让Master去重新分配Tablet。具体的分配策略论文里并没有说，你可以根据自己的需要实现对应的分配策略。</li>\n<li>Tablet Server本身，是根据<strong>是否还独占着Chubby上对应的锁，以及锁文件是否还在</strong>，来确定自己是否还为自己分配到的Tablets服务。比如Tablet Server到Chubby的网络中断了，那么Tablet Server就会失去这个独占锁，也就不再为原先分配到的Tablets提供服务了。</li>\n<li>而如果我们把Tablet Server从集群中挪走，那么Tablet Server会主动释放锁，当然它也不再服务那些Tablets了，这些Tablets都需要重新分配。</li>\n<li>无论是前面的第4、5点这样异常或者正常的情况，都是由Master来检测Tablet Server是不是正常工作的。检测的方法也不复杂，其实就是通过<strong>心跳</strong>。Master会定期问Tablets，你是不是还占着独占锁呀？无论是Tablet Server说它不再占有锁了，还是Master连不上Tablet Server了，Master都会做一个小小的测试，就是自己去获取这个锁。如果Master能够拿到这个锁，说明Chubby还活得好好的，那么一定是Tablet Server那边出了问题，Master就会删除这个锁，确保Tablet Server不会再为Tablets提供服务。而原先Tablet Server上的Tablets就会变回一个未分配的状态，需要回到上面的第3点重新分配。</li>\n<li>而Master自己，一旦和Chubby之间的网络连接出现问题，也就是它和Chubby之间的会话过期了，它就会选择“自杀”，这个是为了<strong>避免出现两个Master而不自知</strong>的情况。反正，Master的存活与否，不影响已经存在的Tablets分配关系，也不会影响到整个Bigtable数据读写的过程。</li>\n</ol><h2>小结</h2><p>好了，到了这里，相信你对整个Bigtable的系统架构就有一个清晰的了解了，现在我们就一起来回顾一下。</p><p>整个Bigtable是由4个组件组成的，分别是：</p><ul>\n<li>负责存储数据的GFS；</li>\n<li>负责作为分布式锁和目录服务的Chubby；</li>\n<li>负责实际提供在线服务的Tablet Server；</li>\n<li>负责调度Tablet和调整负载的Master。</li>\n</ul><p><img src=\"https://static001.geekbang.org/resource/image/8d/7c/8dc1681b5723d5f48426f8d6c23a5f7c.jpg?wh=1920x1117\" alt=\"图片\" title=\"Bigtable的四个组成部分\"></p><p>而通过<strong>动态区域分区</strong>的方式，Bigtable的分区策略需要的数据搬运工作量会很小。在Bigtable里，Master并不负责保存分区信息，也不负责为分区信息提供查询服务。</p><p>Bigtable是通过把分区信息直接做成了<strong>三层树状结构的Bigtable表</strong>，来让查询分区位置的请求分散到了整个Bigtable集群里，并且通过<strong>把查询的引导位置放在Chubby中</strong>，解决了和操作系统类似的“如何启动”问题。而整个系统的<strong>分区分配工作，由Master完成</strong>。通过对于Chubby锁的使用，就解决了Master、Tablet Server进出整个集群的问题。</p><p>到这里，Bigtable的基础架构就介绍完了。不过我们还有两个非常重要的知识点需要深入探讨，一个是单个Tablet的底层存储和读写，具体是如何实现来做到高性能的，另一个是今天出现的神奇的Chubby到底是什么。接下来的两节课，我们就会一起来寻找答案。</p><h2>推荐阅读</h2><p>对于数据分区可以有哪些方法，<a href=\"https://book.douban.com/subject/30329536/\">《数据密集型应用系统设计》</a>的第6章做了非常详尽的讲解，你可以去好好读一下。另外，对于Bigtable本身的论文，我也建议你多花时间去弄清楚，因为后续的Megastore、Spanner等等的论文，都只是Bigtable的升级改进而已，底层的基本原理是不变的。</p><h2>思考题</h2><p>Bigtable论文里的第7部分“性能评估”里，你可以看到Bigtable在随机读数据上的性能表现并不好，无法真正做到随着节点数的增加线性增长。这是为什么呢？这个和我们今天讲的Bigtable的设计中的哪一个设计点相关？</p>","comments":[{"had_liked":false,"id":315276,"user_name":"在路上","can_delete":false,"product_type":"c1","uid":1402511,"ip_address":"","ucode":"6E31908EFE1107","user_header":"https://static001.geekbang.org/account/avatar/00/15/66/8f/02be926d.jpg","comment_is_top":false,"comment_ctime":1633779501,"is_pvip":false,"discussion_count":4,"race_medal":0,"score":"31698550573","product_id":100091101,"comment_content":"徐老师好，在Bigtable论文的第 7 部分“性能评估”里写道：<br>Each random read involves the transfer of a 64 KB SSTable block over the network from GFS to a tablet server, out of which only a single 1000-byte value is used……<br>Random and sequential writes perform better than random reads since each tablet server appends all incoming writes to a single commit log and uses group commit to stream these writes efficiently to GFS.<br><br>随机写和顺序写的性能旗鼓相当，不仅在单台tablet server上表现类似，在tablet server集群上表现也几乎一样。原因是它们都会先写commit log，同步修改内存中的数据，异步修改SSTable中的数据。随机写和顺序写的差异在于SSTable的变更，由于这个操作被异步执行，所以它们的性能没有差异。<br>如果SSTable的不缓存在tablet server上，随机读的性能非常差，比写入操作几乎慢一个数量级。原因是不管要实际需要多小的数据，都需要从GFS上加载64k的SSTable块数据。它的瓶颈不在于tablet server的多少，而在于从GFS上读取数据。<br><br>我在学习今天的课程和阅读Bigtable论文的时候，有三个疑问：<br>1.课程中提到通过外部服务去监控Master的存活，可能会导致系统中出现两个Master，那么GFS没有这个问题吗？如果有的话不会造成严重的后果吗？<br>2.当我向bigtable写入数据时，metadata的三层结构会如何变更？变更的过程如何避免加锁？如果需要全局锁的话，我想读写性能肯定上不去。<br>3.随机读比写入操作慢一个数量级我还是很惊讶，因为写入操作的commit log需要写入GFS，同样有GFS操作，怎么能差出一个数量级？","like_count":8,"discussions":[{"author":{"id":1096652,"avatar":"https://static001.geekbang.org/account/avatar/00/10/bb/cc/fac12364.jpg","nickname":"xxx","note":"","ucode":"E79CEA70430449","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":533607,"discussion_content":"答案很赞，期待老师的点评。前两个问题不会，第三个问题你看完下一篇应该就明白了。","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1637916294,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2069664,"avatar":"https://static001.geekbang.org/account/avatar/00/1f/94/a0/84342a0d.jpg","nickname":"@","note":"","ucode":"BD87484261ED85","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":547693,"discussion_content":"你的第一点问题 个人觉得  GFS 的master不会出现脑裂问题 他就是一个设计上的单点故障点  ，通过主从复制进行容错，   而GFS的脑裂可能会出现在ChunkServer的主从之间（chunk的副本 和primary）  这一点 GFS采用租约来避免脑裂问题  ","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1642829075,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1131300,"avatar":"https://static001.geekbang.org/account/avatar/00/11/43/24/3f9f7c70.jpg","nickname":"zixuan","note":"","ucode":"C72920DD05B074","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":543901,"discussion_content":"1. gfs也用了chubby\n2. metadata表即使普通bigtable表，就和你写入用户表一样的, 支持并发读写\n3. commit log是顺序写，比随机读当然块","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1641350839,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1501234,"avatar":"","nickname":"Geek_88604f","note":"","ucode":"33DD1318E53814","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":402432,"discussion_content":"应该只有在分裂或合并的时候才改变metadata的结构。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633877288,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":317770,"user_name":"thomas","can_delete":false,"product_type":"c1","uid":1016777,"ip_address":"","ucode":"9AB945308F1B50","user_header":"https://static001.geekbang.org/account/avatar/00/0f/83/c9/5d03981a.jpg","comment_is_top":false,"comment_ctime":1634956451,"is_pvip":true,"discussion_count":3,"race_medal":0,"score":"10224891043","product_id":100091101,"comment_content":"METADATA 的一条记录，大约是 1KB，而 METADATA 的 Tablet 如果限制在 128MB，三层记录可以存下大约 (128*1000)2=234 个 Tablet 的位置，也就是大约 160 亿个 Tablet<br>=============================================》<br>这个是如何算出来的？","like_count":2,"discussions":[{"author":{"id":1096652,"avatar":"https://static001.geekbang.org/account/avatar/00/10/bb/cc/fac12364.jpg","nickname":"xxx","note":"","ucode":"E79CEA70430449","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":533626,"discussion_content":"这里应该是笔误了。想写的估计是 (128*1000)^2","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1637918059,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1131300,"avatar":"https://static001.geekbang.org/account/avatar/00/11/43/24/3f9f7c70.jpg","nickname":"zixuan","note":"","ucode":"C72920DD05B074","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":544106,"discussion_content":"一个tablet 128M，每条记录 1K, 则共有128M/1K = 2^17 个索引位, 2层就是 (2^17)^2 = 2^34.","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1641397153,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1043306,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/eb/6a/da88102a.jpg","nickname":"阿东","note":"","ucode":"221E334D79F5FB","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":410746,"discussion_content":"（128*1000）*（128*1000）=2**34 差不多是160亿","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1635769175,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":315064,"user_name":"陈迪","can_delete":false,"product_type":"c1","uid":1019744,"ip_address":"","ucode":"1A64122CC47337","user_header":"https://static001.geekbang.org/account/avatar/00/0f/8f/60/be0a8805.jpg","comment_is_top":false,"comment_ctime":1633678112,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"5928645408","product_id":100091101,"comment_content":"问老师：<br>10多年前的Bigable架构是否是一种符合当下潮流的“存储和计算分离”的架构？存储GFS做得够了，就用GFS单独存，前面哪个tablet压力大可以调度出来多一点。<br>当下则是objcet storage又便宜又可靠，不要share nothing本机再做一遍存储了，都交给object storage","like_count":1,"discussions":[{"author":{"id":1045724,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/f4/dc/2bd409a5.jpg","nickname":"rayallen335","note":"","ucode":"C39AD40AEAA60C","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":531889,"discussion_content":"这个评论写的有悟性","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1637459643,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"user_type\":1}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2822342,"avatar":"https://static001.geekbang.org/account/avatar/00/2b/10/c6/5e7f3148.jpg","nickname":"Somnus💫","note":"","ucode":"4719F7FDC4CFA2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":407365,"discussion_content":"我比较同意你的看法，为什么科研，科研就是解决当前的瓶颈。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1634991590,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":315046,"user_name":"陈迪","can_delete":false,"product_type":"c1","uid":1019744,"ip_address":"","ucode":"1A64122CC47337","user_header":"https://static001.geekbang.org/account/avatar/00/0f/8f/60/be0a8805.jpg","comment_is_top":false,"comment_ctime":1633670709,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5928638005","product_id":100091101,"comment_content":"随机读，最差情况下，要网络走查元数据+从gfs读出来，gfs一读一block就是64mb，一个key value大小往往远小于这个数字。写的话就没这个问题，读内存也会快，顺序读的话key排序+ gfs支持得本来也好。相比之下，随机读显得很糟糕了","like_count":1},{"had_liked":false,"id":315043,"user_name":"那时刻","can_delete":false,"product_type":"c1","uid":1150927,"ip_address":"","ucode":"B0D150856C3A4A","user_header":"https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg","comment_is_top":false,"comment_ctime":1633669315,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5928636611","product_id":100091101,"comment_content":"Bigtable数据随机读写慢，我想到的原因是：其一是个三层 Tablet 信息存储的架构，读写有多次网络请求。其二是tablet的分裂和合并，使数据产生迁移。","like_count":2},{"had_liked":false,"id":314991,"user_name":"峰","can_delete":false,"product_type":"c1","uid":1056019,"ip_address":"","ucode":"C53CB64E8E7D19","user_header":"https://static001.geekbang.org/account/avatar/00/10/1d/13/31ea1b0b.jpg","comment_is_top":false,"comment_ctime":1633646018,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"5928613314","product_id":100091101,"comment_content":"随机读最后只落在一台sever上，不能并行，再加上一次读取转换成了串行的三次读，自然相较而言是慢的。","like_count":1},{"had_liked":false,"id":330868,"user_name":"piboye","can_delete":false,"product_type":"c1","uid":1066752,"ip_address":"","ucode":"7CFD8712857A85","user_header":"https://static001.geekbang.org/account/avatar/00/10/47/00/3202bdf0.jpg","comment_is_top":false,"comment_ctime":1642236391,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1642236391","product_id":100091101,"comment_content":"tablet迁移是怎么搞的？ 迁移会带来短时间不可以用吧？","like_count":0},{"had_liked":false,"id":329610,"user_name":"Geek_80bb15","can_delete":false,"product_type":"c1","uid":2798515,"ip_address":"","ucode":"F13C533E0E6FD2","user_header":"","comment_is_top":false,"comment_ctime":1641445244,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1641445244","product_id":100091101,"comment_content":"徐老师好，HBase把Root表干掉了，是怎么解决Meta表的热点访问问题的呢？多谢","like_count":0},{"had_liked":false,"id":329184,"user_name":"zixuan","can_delete":false,"product_type":"c1","uid":1131300,"ip_address":"","ucode":"C72920DD05B074","user_header":"https://static001.geekbang.org/account/avatar/00/11/43/24/3f9f7c70.jpg","comment_is_top":false,"comment_ctime":1641198786,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1641198786","product_id":100091101,"comment_content":"请问老师，5.1 Tablet Location 这里的 Location指的是tablet的gfs文件路径，还是其所述的tablet server的地址？","like_count":0},{"had_liked":false,"id":328622,"user_name":"Helios","can_delete":false,"product_type":"c1","uid":1380758,"ip_address":"","ucode":"BE6B98EE8F0D09","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKJrOl63enWXCRxN0SoucliclBme0qrRb19ATrWIOIvibKIz8UAuVgicBMibIVUznerHnjotI4dm6ibODA/132","comment_is_top":false,"comment_ctime":1640790760,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1640790760","product_id":100091101,"comment_content":"因为sstable这种格式是用lsm tree实现的更加适合顺序读，b tree更适合随机读","like_count":0},{"had_liked":false,"id":322818,"user_name":"核桃","can_delete":false,"product_type":"c1","uid":1385204,"ip_address":"","ucode":"7AB05270CBCCCB","user_header":"https://static001.geekbang.org/account/avatar/00/15/22/f4/9fd6f8f0.jpg","comment_is_top":false,"comment_ctime":1637600406,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1637600406","product_id":100091101,"comment_content":"这里有几个问题不太理解。<br><br>1.首先读可以不经过master能理解，写也不经过就有点困惑了，既然master就是负责平衡tablet server的，那么写入的时候，到底指定哪个server写入?这个该由谁来负责呢？如果不是master，那么必然就可能会有数据倾斜问题吧。<br>2.文件查询过程那里，三次请求获取到具体数据所在的tablet server的tablets上面，这里有个疑惑。三级架构下和文件系统的文件目录树类似嘛，但是访问root tablet的时候，怎么会知道你所在的表在哪个节点呢？这里又不像域名访问那样，一个root tablet不可能具体知道你这个表可以从哪里读取的呀，应该是只有下面一层数据所对应的上级才真正知道的。","like_count":0},{"had_liked":false,"id":321435,"user_name":"林军人","can_delete":false,"product_type":"c1","uid":2220955,"ip_address":"","ucode":"37A126E92E8B52","user_header":"https://static001.geekbang.org/account/avatar/00/21/e3/9b/b045124d.jpg","comment_is_top":false,"comment_ctime":1636877319,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1636877319","product_id":100091101,"comment_content":"老师看完这节,我有两个问题:<br>1.虽然BT在进行读写的时候, 不需要经过Master, 但是Root Tablet 本身会不会成为系统的瓶颈呢, 如果同时有大量第一次请求的客户端, 都去访问Root Tablet, 而Root Tablet又不会分片, BT会怎么处理呢?<br>2.MetaData表中的行键是怎么设计的呢？ 是 &quot;表名+对应Tablet起始行键&quot; 吗？","like_count":0,"discussions":[{"author":{"id":1385204,"avatar":"https://static001.geekbang.org/account/avatar/00/15/22/f4/9fd6f8f0.jpg","nickname":"核桃","note":"","ucode":"7AB05270CBCCCB","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":532455,"discussion_content":"第一个问题，root tablet可以理解为静态数据了，那么直接在各个chubby节点缓存一下root tablet所在节点不就可以了，占用空间不大的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1637600035,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"user_type\":1}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":318276,"user_name":"Helios","can_delete":false,"product_type":"c1","uid":1380758,"ip_address":"","ucode":"BE6B98EE8F0D09","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKJrOl63enWXCRxN0SoucliclBme0qrRb19ATrWIOIvibKIz8UAuVgicBMibIVUznerHnjotI4dm6ibODA/132","comment_is_top":false,"comment_ctime":1635227430,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1635227430","product_id":100091101,"comment_content":"原来Bigtable集群Chubby才是核心<br>","like_count":0},{"had_liked":false,"id":317844,"user_name":"Somnus💫","can_delete":false,"product_type":"c1","uid":2822342,"ip_address":"","ucode":"4719F7FDC4CFA2","user_header":"https://static001.geekbang.org/account/avatar/00/2b/10/c6/5e7f3148.jpg","comment_is_top":false,"comment_ctime":1634991678,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1634991678","product_id":100091101,"comment_content":"感觉看完一遍之后还有一些些乱。还要多学几次，反过来再看。<br>","like_count":0},{"had_liked":false,"id":317131,"user_name":"Geek_fe2f4c","can_delete":false,"product_type":"c1","uid":2171894,"ip_address":"","ucode":"18AAC3DC04B1B7","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTL33HdAfZA9cQseTJ5HIWZ2XNVes8X29E5VabpU1q0UicxClNppEwUcMOXEZnTxPUEibv8uic5Oiaia8lQ/132","comment_is_top":false,"comment_ctime":1634693499,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1634693499","product_id":100091101,"comment_content":"客户端如果需要做特殊缓存，那就还是需要客户端做特殊设计，对吧","like_count":0},{"had_liked":false,"id":317100,"user_name":"CRT","can_delete":false,"product_type":"c1","uid":1442864,"ip_address":"","ucode":"59F5C8C0674ADC","user_header":"https://static001.geekbang.org/account/avatar/00/16/04/30/7f2cb8e3.jpg","comment_is_top":false,"comment_ctime":1634688820,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1634688820","product_id":100091101,"comment_content":"检测的方法也不复杂，其实就是通过心跳。Master 会定期问 Tablets，你是不是还占着独占锁呀？<br>这个应该是定期问Tablets Server？","like_count":0},{"had_liked":false,"id":316342,"user_name":"thomas","can_delete":false,"product_type":"c1","uid":1016777,"ip_address":"","ucode":"9AB945308F1B50","user_header":"https://static001.geekbang.org/account/avatar/00/0f/83/c9/5d03981a.jpg","comment_is_top":false,"comment_ctime":1634279172,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1634279172","product_id":100091101,"comment_content":"老师，Bigtable 的基本数据模型 希望举个实际的数据应用场景","like_count":0},{"had_liked":false,"id":316033,"user_name":"灰灰","can_delete":false,"product_type":"c1","uid":1122397,"ip_address":"","ucode":"907A2FD339E158","user_header":"https://static001.geekbang.org/account/avatar/00/11/20/5d/69170b96.jpg","comment_is_top":false,"comment_ctime":1634112023,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1634112023","product_id":100091101,"comment_content":"打卡，不是很仔细，还需要重新读。","like_count":0},{"had_liked":false,"id":315398,"user_name":"webmin","can_delete":false,"product_type":"c1","uid":1047014,"ip_address":"","ucode":"98B0CA882454E8","user_header":"https://static001.geekbang.org/account/avatar/00/0f/f9/e6/47742988.jpg","comment_is_top":false,"comment_ctime":1633878109,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1633878109","product_id":100091101,"comment_content":"思考题：<br>1. 随机读无法真正做到随着节点数的增加线性增长，这是为什么呢？<br>读取1000字节的值，需要从GFS读取一个64KB的Block，随着机器的增加1Gbps 网络带宽达到饱和，每个节点的吞吐量都有显示下降，瓶颈在网络总带宽。<br>2. 这个和我们今天讲的 Bigtable 的设计中的哪一个设计点相关？<br>Bigtable的tablet的三层结构设计有关","like_count":0},{"had_liked":false,"id":315226,"user_name":"吴小智","can_delete":false,"product_type":"c1","uid":1310798,"ip_address":"","ucode":"C7C9F58B5C9F7B","user_header":"https://static001.geekbang.org/account/avatar/00/14/00/4e/be2b206b.jpg","comment_is_top":false,"comment_ctime":1633757008,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1633757008","product_id":100091101,"comment_content":"想请教老师，metadata 里面具体存了什么呢？与 gfs 中文件的位置的关联的信息是怎么存的？","like_count":0},{"had_liked":false,"id":315081,"user_name":"吴小智","can_delete":false,"product_type":"c1","uid":1310798,"ip_address":"","ucode":"C7C9F58B5C9F7B","user_header":"https://static001.geekbang.org/account/avatar/00/14/00/4e/be2b206b.jpg","comment_is_top":false,"comment_ctime":1633682264,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1633682264","product_id":100091101,"comment_content":"想请教老师，tablet 的 split 具体会做些什么？会涉及到 gfs 中数据的迁移吗？还是仅涉及到 metadata 的修改？","like_count":0},{"had_liked":false,"id":315061,"user_name":"吴小智","can_delete":false,"product_type":"c1","uid":1310798,"ip_address":"","ucode":"C7C9F58B5C9F7B","user_header":"https://static001.geekbang.org/account/avatar/00/14/00/4e/be2b206b.jpg","comment_is_top":false,"comment_ctime":1633676860,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"1633676860","product_id":100091101,"comment_content":"METADATA 的一条记录，大约是 1KB，而 METADATA 的 Tablet 如果限制在 128MB，三层记录可以存下大约 (128*1000)2=234 个 Tablet 的位置，也就是大约 160 亿个 Tablet，肯定是够用了。  中  (128*1000)2=234  这个怎么理解？","like_count":0,"discussions":[{"author":{"id":1051022,"avatar":"https://static001.geekbang.org/account/avatar/00/10/09/8e/2ff2823e.jpg","nickname":"howhigh","note":"","ucode":"C21ABC017C145D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":538643,"discussion_content":"1mb/1kb=1024≈1000","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1639467716,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1059926,"avatar":"https://static001.geekbang.org/account/avatar/00/10/2c/56/ff7a9730.jpg","nickname":"许灵","note":"","ucode":"0296EC9929B570","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":401930,"discussion_content":"（128*1000)^2 = (2^7*2^10)^2 = 2^34","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633767754,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}