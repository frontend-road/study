{"id":213841,"title":"25 | PyTorch简介：Tensor和相关运算","content":"<p><strong>课件和Demo地址</strong><br>\n<a href=\"https://gitee.com/geektime-geekbang/NLP\">https://gitee.com/geektime-geekbang/NLP</a></p>","comments":[{"had_liked":false,"id":190124,"user_name":"Tofacto","can_delete":false,"product_type":"c3","uid":1888008,"ip_address":"","ucode":"52C83F46206D7B","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/wg4obeslvaze1cqWEuIqwrcibbUIKs8LOycSSKxj3Exo5v5Zo4kFd2TFgVjuBugXTJD6FGnvtFmic6OibeibkvWCHA/132","comment_is_top":false,"comment_ctime":1584604681,"is_pvip":false,"replies":[{"id":73205,"content":"不行的话我重新录一下这个然后在白板上解释一下吧。","user_name":"作者回复","user_name_real":"王然","uid":1813673,"ctime":1584631007,"ip_address":"","comment_id":190124,"utype":1}],"discussion_count":3,"race_medal":0,"score":2,"product_id":100046401,"comment_content":"视频的最后\nA = torch.randn(3, 5, 4)\nl = torch.randn(2, 5)\nr = torch.randn(2, 4)\ntorch.einsum(&#39;bn, anm, bm-&gt;ba&#39;, l, A, r)\n最终结果是ba，没有出现n和m\n在视频中讲解n和m是怎么操作的时候，老师说：“它就是对应地去把它加起来，做这样的一个求和的操作，那么对应的实际上就是一个Bilinear过程”\n请问老师这句话是什么意思？听不明白！请在这里给解释一下吧，谢谢\n我用程序跑了一下，得到的结果是：\ntensor([[10.3107, -2.2290, -1.1836],\n        [ 7.3258,  2.1568, -3.5209]])\n不过还是看不明白，请老师回复，谢谢！","like_count":5,"discussions":[{"author":{"id":1813673,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/ac/a9/fbcddd1f.jpg","nickname":"王然","note":"","ucode":"45A7F34120DF47","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":487895,"discussion_content":"不行的话我重新录一下这个然后在白板上解释一下吧。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1584631007,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1673587,"avatar":"https://static001.geekbang.org/account/avatar/00/19/89/73/9a7b0dfe.jpg","nickname":"Ayaya","note":"","ucode":"FC47B194CFD014","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":210487,"discussion_content":"这里我的理解是, 在 einsum 中, 相邻两个张量会首先进行维度扩展(其实也应该就是 broadcast), 然后按位相乘之后, 按需相加, 对此我进行了一些测试.\n\nimport torch\n# 准备数据\nA = torch.arange(60).reshape(3,5,4)\nl = torch.arange(10).reshape(2,5)\nr = torch.arange(8).reshape(2,4)    # 这样是为了易于手动计算验证, 并且易复线\n# 为了方便, 列出 einsum 中字母对应维度大小: b=2, a=3, n=5, m=4\n\n# 经过我的测试, 原式可分解为两步\noutput1 = torch.einsum(&#39;bn, anm, bm->ba&#39;, l, A, r)      # original\nmeta1 = torch.einsum(&#39;bn, anm->bam&#39;, l, A)              # First Step\noutput = torch.einsum(&#39;bam, bm->ba&#39;, meta1, r)        # Second Step\n\n# 这说明多项 einsum 的工作顺序是从左到右, 且有\noutput1 == output\n\n# 然后关于第一步, 其实可以理解为\nl1 = l.unsqueeze(-1).expand(2, 5, 4)    \nmeta2 = torch.einsum(&#39;bnm, anm->bam&#39;, l1, A)\n\n# 也就是说先做了一个扩维, 然后进行对应位按位乘. 可以测试 \nmeta1 == meta2  # Return a bool matrix of size (2, 3, 4)\n\n# 那么在计算 meta2 的过程中, 实际上 einsum 做的事情是这样的(这里用 meta3 和 meta4 变量演示): \nmeta3 = torch.empty(2, 3, 5, 4)\nfor i in range(2):\n    for j in range(3):\n            meta3[i, j, :, :] = l1[i] * A[j] \n\nmeta4 = meta3.sum(dim=2)   # 不要的 n 在 dim=2 的位置, 因为这个时候 meta3 的 shape 是 (b, a, n, m)\n# 可以测试: \nmeta4 == meta2 \n\n# 然后第二步呢, 其实和第一步一模一样, 只是由于扩展后维度相等, 可以更简易一点:\nmeta5 = (r.unsqueeze(1).expand(2,3,4) * meta1).sum(dim=2)\nmeta5 == output\n\n为了方便你 copy 进行测试, 这里所有的说明我都使用了注释, 你可以直接全部 copy 并测试.\n然后想补充的一点是, 这里我是用**扩展维度**的方式来理解的, 但是实际上, 应该是通过 pytorch 的 broadcast 机制完成这些任务. 不过按照我的理解, broadcast 应该也是靠这种 expand 的方式实现的.\n\n另外是我发现的一个别人的回答. 希望对你有帮助\nhttps://stackoverflow.com/questions/55894693/understanding-pytorch-einsum\n如果我的理解或者程序中有任何的错误, 希望你能帮我指正, 我将无比感谢.","likes_number":4,"is_delete":false,"is_hidden":false,"ctime":1584742637,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1888008,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/wg4obeslvaze1cqWEuIqwrcibbUIKs8LOycSSKxj3Exo5v5Zo4kFd2TFgVjuBugXTJD6FGnvtFmic6OibeibkvWCHA/132","nickname":"Tofacto","note":"","ucode":"52C83F46206D7B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":211408,"discussion_content":"谢谢，我仔细看看(^_^)","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1584848291,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":190982,"user_name":"人工智能混饭人","can_delete":false,"product_type":"c3","uid":1104354,"ip_address":"","ucode":"71CF953311BD81","user_header":"https://static001.geekbang.org/account/avatar/00/10/d9/e2/d75009ef.jpg","comment_is_top":false,"comment_ctime":1584715740,"is_pvip":false,"replies":[{"id":73363,"content":"具体指哪里呢？可以具体说一下么？","user_name":"作者回复","user_name_real":"王然","uid":1813673,"ctime":1584756560,"ip_address":"","comment_id":190982,"utype":1}],"discussion_count":3,"race_medal":0,"score":2,"product_id":100046401,"comment_content":"一直对这些tensor的形状变换理解不是很清楚，老师有什么方法可以讲一下吗？","like_count":1,"discussions":[{"author":{"id":1813673,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/ac/a9/fbcddd1f.jpg","nickname":"王然","note":"","ucode":"45A7F34120DF47","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":488093,"discussion_content":"具体指哪里呢？可以具体说一下么？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1584756560,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1914504,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/36/88/20b6a6ee.jpg","nickname":"Simon","note":"","ucode":"A8A2E3E57BD029","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":229642,"discussion_content":"需要知道每一层网络的具体操作。比如CNN，卷积核多大，步长是多少，filter有几个。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586677291,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1104354,"avatar":"https://static001.geekbang.org/account/avatar/00/10/d9/e2/d75009ef.jpg","nickname":"人工智能混饭人","note":"","ucode":"71CF953311BD81","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":210656,"discussion_content":"就是经过各种网络之后tensor的形状，这个是只需要记住呢？还是需要自己推理一下。涉及到维度比较高的，理解起来就很抽象","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1584758368,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":323224,"user_name":"EiLen🍖","can_delete":false,"product_type":"c3","uid":2760384,"ip_address":"","ucode":"998AADC238AACC","user_header":"https://static001.geekbang.org/account/avatar/00/2a/1e/c0/fa6afd6a.jpg","comment_is_top":false,"comment_ctime":1637768209,"is_pvip":false,"replies":[{"id":117740,"content":"感谢～的确是错误","user_name":"作者回复","user_name_real":"编辑","uid":1813673,"ctime":1638448615,"ip_address":"","comment_id":323224,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100046401,"comment_content":"老师的白板写成了bc.. 其实是ba","like_count":0,"discussions":[{"author":{"id":1813673,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/ac/a9/fbcddd1f.jpg","nickname":"王然","note":"","ucode":"45A7F34120DF47","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":535468,"discussion_content":"感谢～的确是错误","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1638448615,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":229399,"user_name":"伟大的小明","can_delete":false,"product_type":"c3","uid":2042843,"ip_address":"","ucode":"1337BCD4A417DA","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/XeCJSINicu0zWk9v9JDNkAib2yfsFpocjewiaf5Cw2icN23W65Ayiba1WkfXgSEpWAS7Y8NUHBjp38Awsz0zsaTpTMQ/132","comment_is_top":false,"comment_ctime":1592984754,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100046401,"comment_content":"Einsum建议按照老师16分30秒左右的想法，看一下https:&#47;&#47;www.cnblogs.com&#47;mengnan&#47;p&#47;10319701.html","like_count":4},{"had_liked":false,"id":250101,"user_name":"Jinru Wu 吴琎如","can_delete":false,"product_type":"c3","uid":1193229,"ip_address":"","ucode":"16D012A47E8E47","user_header":"https://static001.geekbang.org/account/avatar/00/12/35/0d/8cb4c57f.jpg","comment_is_top":false,"comment_ctime":1600935324,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100046401,"comment_content":"einsum数学上的讲解可以参考这两个视频：\nhttps:&#47;&#47;www.youtube.com&#47;watch?v=CLrTj7D2fLM \nhttps:&#47;&#47;www.youtube.com&#47;watch?v=-SYDZXNFWXg\n刚看一头雾水，但看完自己在纸上做一遍 torch.einsum(&#39;bn,anm,bm-&gt;ba&#39;, l, A, r) 这里的三个矩阵乘法就能大致理解了。\n","like_count":2},{"had_liked":false,"id":289175,"user_name":"hallo128","can_delete":false,"product_type":"c3","uid":1212044,"ip_address":"","ucode":"3921D6E11CFCB1","user_header":"https://static001.geekbang.org/account/avatar/00/12/7e/8c/f029535a.jpg","comment_is_top":false,"comment_ctime":1618903210,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100046401,"comment_content":"梯度下降：https:&#47;&#47;pytorch.apachecn.org&#47;docs&#47;1.7&#47;04.html\n张量tensor介绍：https:&#47;&#47;pytorch.apachecn.org&#47;docs&#47;1.7&#47;03.html","like_count":0},{"had_liked":false,"id":193126,"user_name":"JaneIDK","can_delete":false,"product_type":"c3","uid":1883313,"ip_address":"","ucode":"8F6E293767C62B","user_header":"https://static001.geekbang.org/account/avatar/00/1c/bc/b1/3ba14f09.jpg","comment_is_top":false,"comment_ctime":1584884249,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100046401,"comment_content":"啊信息量好大","like_count":0},{"had_liked":false,"id":192445,"user_name":"韩向民","can_delete":false,"product_type":"c3","uid":1310021,"ip_address":"","ucode":"C0335C3785C303","user_header":"https://static001.geekbang.org/account/avatar/00/13/fd/45/a498dcb9.jpg","comment_is_top":false,"comment_ctime":1584851288,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100046401,"comment_content":"该讲需要反复实际的操作来达到熟练","like_count":0}]}