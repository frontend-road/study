{"id":103844,"title":"13 |  Java生产者是如何管理TCP连接的？","content":"<p>你好，我是胡夕。今天我要和你分享的主题是：Kafka的Java生产者是如何管理TCP连接的。</p><h2>为何采用TCP？</h2><p>Apache Kafka的所有通信都是基于TCP的，而不是基于HTTP或其他协议。无论是生产者、消费者，还是Broker之间的通信都是如此。你可能会问，为什么Kafka不使用HTTP作为底层的通信协议呢？其实这里面的原因有很多，但最主要的原因在于TCP和HTTP之间的区别。</p><p>从社区的角度来看，在开发客户端时，人们能够利用TCP本身提供的一些高级功能，比如多路复用请求以及同时轮询多个连接的能力。</p><p>所谓的多路复用请求，即multiplexing request，是指将两个或多个数据流合并到底层单一物理连接中的过程。TCP的多路复用请求会在一条物理连接上创建若干个虚拟连接，每个虚拟连接负责流转各自对应的数据流。其实严格来说，TCP并不能多路复用，它只是提供可靠的消息交付语义保证，比如自动重传丢失的报文。</p><p>更严谨地说，作为一个基于报文的协议，TCP能够被用于多路复用连接场景的前提是，上层的应用协议（比如HTTP）允许发送多条消息。不过，我们今天并不是要详细讨论TCP原理，因此你只需要知道这是社区采用TCP的理由之一就行了。</p><!-- [[[read_end]]] --><p>除了TCP提供的这些高级功能有可能被Kafka客户端的开发人员使用之外，社区还发现，目前已知的HTTP库在很多编程语言中都略显简陋。</p><p>基于这两个原因，Kafka社区决定采用TCP协议作为所有请求通信的底层协议。</p><h2>Kafka生产者程序概览</h2><p>Kafka的Java生产者API主要的对象就是KafkaProducer。通常我们开发一个生产者的步骤有4步。</p><p>第1步：构造生产者对象所需的参数对象。</p><p>第2步：利用第1步的参数对象，创建KafkaProducer对象实例。</p><p>第3步：使用KafkaProducer的send方法发送消息。</p><p>第4步：调用KafkaProducer的close方法关闭生产者并释放各种系统资源。</p><p>上面这4步写成Java代码的话大概是这个样子：</p><pre><code>Properties props = new Properties ();\nprops.put(“参数1”, “参数1的值”)；\nprops.put(“参数2”, “参数2的值”)；\n……\ntry (Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props)) {\n            producer.send(new ProducerRecord&lt;String, String&gt;(……), callback);\n\t……\n}\n</code></pre><p>这段代码使用了Java 7 提供的try-with-resource特性，所以并没有显式调用producer.close()方法。无论是否显式调用close方法，所有生产者程序大致都是这个路数。</p><p>现在问题来了，当我们开发一个Producer应用时，生产者会向Kafka集群中指定的主题（Topic）发送消息，这必然涉及与Kafka Broker创建TCP连接。那么，Kafka的Producer客户端是如何管理这些TCP连接的呢？</p><h2>何时创建TCP连接？</h2><p>要回答上面这个问题，我们首先要弄明白生产者代码是什么时候创建TCP连接的。就上面的那段代码而言，可能创建TCP连接的地方有两处：Producer producer = new KafkaProducer(props)和producer.send(msg, callback)。你觉得连向Broker端的TCP连接会是哪里创建的呢？前者还是后者，抑或是两者都有？请先思考5秒钟，然后我给出我的答案。</p><p>首先，生产者应用在创建KafkaProducer实例时是会建立与Broker的TCP连接的。其实这种表述也不是很准确，应该这样说：<strong>在创建KafkaProducer实例时，生产者应用会在后台创建并启动一个名为Sender的线程，该Sender线程开始运行时首先会创建与Broker的连接</strong>。我截取了一段测试环境中的日志来说明这一点：</p><blockquote>\n<p>[2018-12-09 09:35:45,620] DEBUG [Producer clientId=producer-1] Initialize connection to node <span class=\"orange\">localhost:9093 (id: -2 rack: null) </span>for sending metadata request (org.apache.kafka.clients.NetworkClient:1084)</p>\n</blockquote><blockquote>\n<p>[2018-12-09 09:35:45,622] DEBUG [Producer clientId=producer-1] Initiating connection to node <span class=\"orange\">localhost:9093 (id: -2 rack: null) </span>using address localhost/127.0.0.1 (org.apache.kafka.clients.NetworkClient:914)</p>\n</blockquote><blockquote>\n<p>[2018-12-09 09:35:45,814] DEBUG [Producer clientId=producer-1] Initialize connection to node <span class=\"orange\">localhost:9092 (id: -1 rack: null)</span> for sending metadata request (org.apache.kafka.clients.NetworkClient:1084)</p>\n</blockquote><blockquote>\n<p>[2018-12-09 09:35:45,815] DEBUG [Producer clientId=producer-1] Initiating connection to node <span class=\"orange\">localhost:9092 (id: -1 rack: null) </span>using address localhost/127.0.0.1 (org.apache.kafka.clients.NetworkClient:914)</p>\n</blockquote><blockquote>\n<p>[2018-12-09 09:35:45,828] DEBUG [Producer clientId=producer-1] Sending metadata request (type=MetadataRequest, topics=) to node localhost:9093 (id: -2 rack: null) (org.apache.kafka.clients.NetworkClient:1068)</p>\n</blockquote><p>你也许会问：怎么可能是这样？如果不调用send方法，这个Producer都不知道给哪个主题发消息，它又怎么能知道连接哪个Broker呢？难不成它会连接bootstrap.servers参数指定的所有Broker吗？嗯，是的，Java Producer目前还真是这样设计的。</p><p>我在这里稍微解释一下bootstrap.servers参数。它是Producer的核心参数之一，指定了这个Producer启动时要连接的Broker地址。请注意，这里的“启动时”，代表的是Producer启动时会发起与这些Broker的连接。因此，如果你为这个参数指定了1000个Broker连接信息，那么很遗憾，你的Producer启动时会首先创建与这1000个Broker的TCP连接。</p><p>在实际使用过程中，我并不建议把集群中所有的Broker信息都配置到bootstrap.servers中，通常你指定3～4台就足以了。因为Producer一旦连接到集群中的任一台Broker，就能拿到整个集群的Broker信息，故没必要为bootstrap.servers指定所有的Broker。</p><p>让我们回顾一下上面的日志输出，请注意我标为橙色的内容。从这段日志中，我们可以发现，在KafkaProducer实例被创建后以及消息被发送前，Producer应用就开始创建与两台Broker的TCP连接了。当然了，在我的测试环境中，我为bootstrap.servers配置了localhost:9092、localhost:9093来模拟不同的Broker，但是这并不影响后面的讨论。另外，日志输出中的最后一行也很关键：它表明Producer向某一台Broker发送了METADATA请求，尝试获取集群的元数据信息——这就是前面提到的Producer能够获取集群所有信息的方法。</p><p>讲到这里，我有一些个人的看法想跟你分享一下。通常情况下，我都不认为社区写的代码或做的设计就一定是对的，因此，很多类似的这种“质疑”会时不时地在我脑子里冒出来。</p><p>拿今天的这个KafkaProducer创建实例来说，社区的官方文档中提及KafkaProducer类是线程安全的。我本人并没有详尽地去验证过它是否真的就是thread-safe的，但是大致浏览一下源码可以得出这样的结论：KafkaProducer实例创建的线程和前面提到的Sender线程共享的可变数据结构只有RecordAccumulator类，故维护了RecordAccumulator类的线程安全，也就实现了KafkaProducer类的线程安全。</p><p>你不需要了解RecordAccumulator类是做什么的，你只要知道它主要的数据结构是一个ConcurrentMap&lt;TopicPartition, Deque&gt;。TopicPartition是Kafka用来表示主题分区的Java对象，本身是不可变对象。而RecordAccumulator代码中用到Deque的地方都有锁的保护，所以基本上可以认定RecordAccumulator类是线程安全的。</p><p>说了这么多，我其实是想说，纵然KafkaProducer是线程安全的，我也不赞同创建KafkaProducer实例时启动Sender线程的做法。写了《Java并发编程实践》的那位布赖恩·格茨（Brian Goetz）大神，明确指出了这样做的风险：在对象构造器中启动线程会造成this指针的逃逸。理论上，Sender线程完全能够观测到一个尚未构造完成的KafkaProducer实例。当然，在构造对象时创建线程没有任何问题，但最好是不要同时启动它。</p><p>好了，我们言归正传。针对TCP连接何时创建的问题，目前我们的结论是这样的：<strong>TCP连接是在创建KafkaProducer实例时建立的</strong>。那么，我们想问的是，它只会在这个时候被创建吗？</p><p>当然不是！<strong>TCP连接还可能在两个地方被创建：一个是在更新元数据后，另一个是在消息发送时</strong>。为什么说是可能？因为这两个地方并非总是创建TCP连接。当Producer更新了集群的元数据信息之后，如果发现与某些Broker当前没有连接，那么它就会创建一个TCP连接。同样地，当要发送消息时，Producer发现尚不存在与目标Broker的连接，也会创建一个。</p><p>接下来，我们来看看Producer更新集群元数据信息的两个场景。</p><p>场景一：当Producer尝试给一个不存在的主题发送消息时，Broker会告诉Producer说这个主题不存在。此时Producer会发送METADATA请求给Kafka集群，去尝试获取最新的元数据信息。</p><p>场景二：Producer通过metadata.max.age.ms参数定期地去更新元数据信息。该参数的默认值是300000，即5分钟，也就是说不管集群那边是否有变化，Producer每5分钟都会强制刷新一次元数据以保证它是最及时的数据。</p><p>讲到这里，我们可以“挑战”一下社区对Producer的这种设计的合理性。目前来看，一个Producer默认会向集群的所有Broker都创建TCP连接，不管是否真的需要传输请求。这显然是没有必要的。再加上Kafka还支持强制将空闲的TCP连接资源关闭，这就更显得多此一举了。</p><p>试想一下，在一个有着1000台Broker的集群中，你的Producer可能只会与其中的3～5台Broker长期通信，但是Producer启动后依次创建与这1000台Broker的TCP连接。一段时间之后，大约有995个TCP连接又被强制关闭。这难道不是一种资源浪费吗？很显然，这里是有改善和优化的空间的。</p><h2>何时关闭TCP连接？</h2><p>说完了TCP连接的创建，我们来说说它们何时被关闭。</p><p>Producer端关闭TCP连接的方式有两种：<strong>一种是用户主动关闭；一种是Kafka自动关闭</strong>。</p><p>我们先说第一种。这里的主动关闭实际上是广义的主动关闭，甚至包括用户调用kill -9主动“杀掉”Producer应用。当然最推荐的方式还是调用producer.close()方法来关闭。</p><p>第二种是Kafka帮你关闭，这与Producer端参数connections.max.idle.ms的值有关。默认情况下该参数值是9分钟，即如果在9分钟内没有任何请求“流过”某个TCP连接，那么Kafka会主动帮你把该TCP连接关闭。用户可以在Producer端设置connections.max.idle.ms=-1禁掉这种机制。一旦被设置成-1，TCP连接将成为永久长连接。当然这只是软件层面的“长连接”机制，由于Kafka创建的这些Socket连接都开启了keepalive，因此keepalive探活机制还是会遵守的。</p><p>值得注意的是，在第二种方式中，TCP连接是在Broker端被关闭的，但其实这个TCP连接的发起方是客户端，因此在TCP看来，这属于被动关闭的场景，即passive close。被动关闭的后果就是会产生大量的CLOSE_WAIT连接，因此Producer端或Client端没有机会显式地观测到此连接已被中断。</p><h2>小结</h2><p>我们来简单总结一下今天的内容。对最新版本的Kafka（2.1.0）而言，Java Producer端管理TCP连接的方式是：</p><ol>\n<li>KafkaProducer实例创建时启动Sender线程，从而创建与bootstrap.servers中所有Broker的TCP连接。</li>\n<li>KafkaProducer实例首次更新元数据信息之后，还会再次创建与集群中所有Broker的TCP连接。</li>\n<li>如果Producer端发送消息到某台Broker时发现没有与该Broker的TCP连接，那么也会立即创建连接。</li>\n<li>如果设置Producer端connections.max.idle.ms参数大于0，则步骤1中创建的TCP连接会被自动关闭；如果设置该参数=-1，那么步骤1中创建的TCP连接将无法被关闭，从而成为“僵尸”连接。</li>\n</ol><p><img src=\"https://static001.geekbang.org/resource/image/de/38/de71cc4b496a22e47b4ce079dbe99238.jpg?wh=2069*2560\" alt=\"\"></p><h2>开放讨论</h2><p>对于今天我们“挑战”的社区设计，你有什么改进的想法吗？</p><p>欢迎写下你的思考和答案，我们一起讨论。如果你觉得有所收获，也欢迎把文章分享给你的朋友。</p><p></p>","neighbors":{"left":{"article_title":"12 | 客户端都有哪些不常见但是很高级的功能？","id":103397},"right":{"article_title":"14 | 幂等生产者和事务生产者是一回事吗？","id":103974}},"comments":[{"had_liked":false,"id":146243,"user_name":"注定非凡","can_delete":false,"product_type":"c1","uid":1113597,"ip_address":"","ucode":"80673056E131B7","user_header":"https://static001.geekbang.org/account/avatar/00/10/fd/fd/326be9bb.jpg","comment_is_top":false,"comment_ctime":1572482869,"is_pvip":true,"replies":[{"id":"56452","content":"总结得相当强：）","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1572485667,"ip_address":"","comment_id":146243,"utype":1}],"discussion_count":6,"race_medal":0,"score":"186256076597","product_id":100029201,"comment_content":"Apache Kafka的所有通信都是基于TCP的，而不是于HTTP或其他协议的<br>1 为什采用TCP?<br>（1）TCP拥有一些高级功能，如多路复用请求和同时轮询多个连接的能力。<br>\t（2）很多编程语言的HTTP库功能相对的比较简陋。<br>\t\t名词解释：<br>\t\t\t多路复用请求：multiplexing request，是将两个或多个数据合并到底层—物理连接中的过程。TCP的多路复用请求会在一条物理连接上创建若干个虚拟连接，每个虚拟连接负责流转各自对应的数据流。严格讲：TCP并不能多路复用，只是提供可靠的消息交付语义保证，如自动重传丢失的报文。<br><br>2 何时创建TCP连接？<br>\t（1）在创建KafkaProducer实例时，<br>A：生产者应用会在后台创建并启动一个名为Sender的线程，该Sender线程开始运行时，首先会创建与Broker的连接。<br>B：此时不知道要连接哪个Broker，kafka会通过METADATA请求获取集群的元数据，连接所有的Broker。<br>\t（2）还可能在更新元数据后，或在消息发送时<br>3 何时关闭TCP连接<br>\t（1）Producer端关闭TCP连接的方式有两种：用户主动关闭，或kafka自动关闭。<br>\t\tA：用户主动关闭，通过调用producer.close()方关闭，也包括kill -9暴力关闭。<br>\t\tB：Kafka自动关闭，这与Producer端参数connection.max.idles.ms的值有关，默认为9分钟，9分钟内没有任何请求流过，就会被自动关闭。这个参数可以调整。<br>\t\tC：第二种方式中，TCP连接是在Broker端被关闭的，但这个连接请求是客户端发起的，对TCP而言这是被动的关闭，被动关闭会产生大量的CLOSE_WAIT连接。<br>","like_count":43,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":472766,"discussion_content":"总结得相当强：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1572485667,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1580046,"avatar":"https://static001.geekbang.org/account/avatar/00/18/1c/0e/f2954d1c.jpg","nickname":"hy","note":"","ucode":"7D492373043C96","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":112406,"discussion_content":"TCP跟HTTP协议处于不同的层级，这两者直接比较总感觉有不妥之处吧？","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1577859330,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2833242,"avatar":"","nickname":"Geek_cec0e4","note":"","ucode":"DEEAFAE8190EFF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":532966,"discussion_content":"吔屎啦梁非凡","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1637742599,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"user_type\":1}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1017986,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/88/82/e26364d7.jpg","nickname":"ptrr","note":"","ucode":"DC093709E651E3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":375066,"discussion_content":"redis那课里 是不是也有你！！！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1621473384,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2289723,"avatar":"https://static001.geekbang.org/account/avatar/00/22/f0/3b/3a142c70.jpg","nickname":"大姐","note":"","ucode":"F23143AB43DDDF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":352983,"discussion_content":"到位","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1614936508,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1103208,"avatar":"https://static001.geekbang.org/account/avatar/00/10/d5/68/2201b6b9.jpg","nickname":"归零","note":"","ucode":"C99B8E93009A46","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":335078,"discussion_content":"赞一个\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1608086362,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":116458,"user_name":"旭杰","can_delete":false,"product_type":"c1","uid":1242099,"ip_address":"","ucode":"964603ACF81B28","user_header":"https://static001.geekbang.org/account/avatar/00/12/f3/f3/3fbb4c38.jpg","comment_is_top":false,"comment_ctime":1563852542,"is_pvip":false,"replies":[{"id":"42673","content":"向它认为当前负载最少的节点发送请求，所谓负载最少就是指未完成请求数最少的broker","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563929711,"ip_address":"","comment_id":116458,"utype":1}],"discussion_count":4,"race_medal":0,"score":"104643067646","product_id":100029201,"comment_content":"Producer 通过 metadata.max.age.ms定期更新元数据，在连接多个broker的情况下，producer是如何决定向哪个broker发起该请求？","like_count":24,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":459550,"discussion_content":"向它认为当前负载最少的节点发送请求，所谓负载最少就是指未完成请求数最少的broker","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563929711,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1336475,"avatar":"https://static001.geekbang.org/account/avatar/00/14/64/9b/0b578b08.jpg","nickname":"J.Smile","note":"","ucode":"C4D98DFDBF7584","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":285580,"discussion_content":"未完成的请求保存在InFlightsRequests中，结构是Map<Node,Deque<Request>>","likes_number":4,"is_delete":false,"is_hidden":false,"ctime":1592884009,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1057056,"avatar":"https://static001.geekbang.org/account/avatar/00/10/21/20/1299e137.jpg","nickname":"秋天","note":"","ucode":"A7E1D953EF7E17","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":532298,"discussion_content":"那问题来了，如果不和所有的broker建立连接，producer是怎么知道哪个broker的负载最少呢？老师","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1637569050,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"user_type\":1}","child_discussion_number":1,"child_discussions":[{"author":{"id":1807547,"avatar":"https://wx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKP3t4m8icCSqGkxAxNGAlorHfZm1PJY4I78EFx87MeIaO0l0Cic0RuzBicY2VkkxQIExKMqBYrsVZLA/132","nickname":"Geek_47e96c","note":"","ucode":"59FE9825C3F2A9","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1057056,"avatar":"https://static001.geekbang.org/account/avatar/00/10/21/20/1299e137.jpg","nickname":"秋天","note":"","ucode":"A7E1D953EF7E17","race_medal":0,"user_type":1,"is_pvip":true},"discussion":{"id":547747,"discussion_content":"producer的InFlightsRequests中维护着每个broker的等待回复消息的队列，所有队列中等待回复的消息数最少的这个队列所对应的broker就是负载最小的，因为等待数量越少说明broker处理速度越快，负载越小","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1642850369,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":532298,"ip_address":""},"score":547747,"extra":""}]}]},{"had_liked":false,"id":170277,"user_name":"小马","can_delete":false,"product_type":"c1","uid":1490686,"ip_address":"","ucode":"92B7ECD23BDCB5","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eoXW5rycAcrNTwgOvib8poPXO0zvIekIPzBZJfsnciaLPIw9Q1t3rsXeH6DR24QndpYQibvibhR1tKHPw/132","comment_is_top":false,"comment_ctime":1578559985,"is_pvip":false,"replies":[{"id":"66075","content":"如果你的producer长时间没有消息需要发送，TCP连接确实会定期关闭再重建的","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1578619114,"ip_address":"","comment_id":170277,"utype":1}],"discussion_count":2,"race_medal":0,"score":"83182938609","product_id":100029201,"comment_content":"老师有个问题请教下：<br>Producer 通过 metadata.max.age.ms 参数定期地去更新元数据信息，默认5分钟更新元数据，如果没建立TCP连接则会创建，而connections.max.idle.ms默认9分钟不使用该连接就会关闭。那岂不是会循环往复地不断地在创建关闭TCP连接了吗？","like_count":19,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":480917,"discussion_content":"如果你的producer长时间没有消息需要发送，TCP连接确实会定期关闭再重建的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1578619114,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1652895,"avatar":"https://static001.geekbang.org/account/avatar/00/19/38/9f/895353ab.jpg","nickname":"黄卫江","note":"","ucode":"0366942B81E7FC","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":573893,"discussion_content":"更新元数据只需连接某一个broker就行，而connections.max.idle.ms关闭所有空闲连接。并不会导致大批量连接循环重建","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1653716017,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":112584,"user_name":"Frank","can_delete":false,"product_type":"c1","uid":1419276,"ip_address":"","ucode":"FAACCA4E6D481F","user_header":"https://static001.geekbang.org/account/avatar/00/15/a8/0c/82ba8ef9.jpg","comment_is_top":false,"comment_ctime":1562765896,"is_pvip":false,"replies":[{"id":"40978","content":"topic数量只要不是太多，通常没有什么影响。如果单台broker上分区数超过2k，那么可能要关注是否会出现性能问题了。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1562804155,"ip_address":"","comment_id":112584,"utype":1}],"discussion_count":1,"race_medal":0,"score":"70282242632","product_id":100029201,"comment_content":"最近在使用kafka Connector做数据同步服务，在kafka中创建了许多topic，目前对kafka了解还不够深入，不知道这个对性能有什么影响？topic的数量多大范围比较合适？","like_count":16,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":457804,"discussion_content":"topic数量只要不是太多，通常没有什么影响。如果单台broker上分区数超过2k，那么可能要关注是否会出现性能问题了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562804155,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":109660,"user_name":"你好旅行者","can_delete":false,"product_type":"c1","uid":1154101,"ip_address":"","ucode":"5C72A428DC28F3","user_header":"https://static001.geekbang.org/account/avatar/00/11/9c/35/9dc79371.jpg","comment_is_top":false,"comment_ctime":1562072975,"is_pvip":false,"replies":[{"id":"39759","content":"1. 集群元数据持久化在ZooKeeper中，同时也缓存在每台Broker的内存中，因此不需要请求ZooKeeper<br>2. 就我个人认为，的确有一些不高效。所以我说这里有优化的空间的。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1562114716,"ip_address":"","comment_id":109660,"utype":1}],"discussion_count":4,"race_medal":0,"score":"65986582415","product_id":100029201,"comment_content":"老师好，看了今天的文章我有几个问题：<br><br>1.Kafka的元数据信息是存储在zookeeper中的，而Producer是通过broker来获取元数据信息的，那么这个过程是否是这样的，Producer向Broker发送一个获取元数据的请求给Broker，之后Broker再向zookeeper请求这个信息返回给Producer?<br><br>2.如果Producer在获取完元数据信息之后要和所有的Broker建立连接，那么假设一个Kafka集群中有1000台Broker，对于一个只需要与5台Broker交互的Producer，它连接池中的链接数量是不是从1000-&gt;5-&gt;1000-&gt;5?这样不是显得非常得浪费连接池资源？","like_count":15,"discussions":[{"author":{"id":1339409,"avatar":"https://static001.geekbang.org/account/avatar/00/14/70/11/42cf8f9d.jpg","nickname":"chenjia","note":"","ucode":"61983C29FF4987","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":366846,"discussion_content":"以前的版本都是直接连接zk的，后面才改为连接任意一个broker，大概是为了屏蔽内部的元数据管理方案吧，说不定哪天kafka就弃用zk了","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1618205602,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":2860851,"avatar":"","nickname":"Geek_e78fa5","note":"","ucode":"713677ED3B5745","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1339409,"avatar":"https://static001.geekbang.org/account/avatar/00/14/70/11/42cf8f9d.jpg","nickname":"chenjia","note":"","ucode":"61983C29FF4987","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":539505,"discussion_content":"最新版的已经弃用了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1639730851,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":366846,"ip_address":""},"score":539505,"extra":""}]},{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":456501,"discussion_content":"1. 集群元数据持久化在ZooKeeper中，同时也缓存在每台Broker的内存中，因此不需要请求ZooKeeper\n2. 就我个人认为，的确有一些不高效。所以我说这里有优化的空间的。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1562114716,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1543348,"avatar":"https://static001.geekbang.org/account/avatar/00/17/8c/b4/318ba5ef.jpg","nickname":"OldHemp","note":"","ucode":"8F58DA0BB478F4","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":3060,"discussion_content":"老师您好，有个问题，当producer第一次更新元数据要与所有的broker建立TCP连接，但是有些连接9min后会被broker主动关闭，那么下一次更新元数据的时候还是会和所有的broker建立连接吗?是不是一个循环的过程？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1564139302,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":109407,"user_name":"柠檬C","can_delete":false,"product_type":"c1","uid":1181505,"ip_address":"","ucode":"BC0EE704D952A4","user_header":"https://static001.geekbang.org/account/avatar/00/12/07/41/2d477385.jpg","comment_is_top":false,"comment_ctime":1562030273,"is_pvip":false,"discussion_count":4,"race_medal":0,"score":"65986539713","product_id":100029201,"comment_content":"应该可以用懒加载的方式，实际发送时再进行TCP连接吧，虽然这样第一次发送时因为握手的原因会稍慢一点","like_count":15,"discussions":[{"author":{"id":1502067,"avatar":"","nickname":"高大的霍比特人","note":"","ucode":"DB855B98D78281","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":538263,"discussion_content":"总得启动的。。。还得拿metadata呢。。。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1639387792,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1339409,"avatar":"https://static001.geekbang.org/account/avatar/00/14/70/11/42cf8f9d.jpg","nickname":"chenjia","note":"","ucode":"61983C29FF4987","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":366848,"discussion_content":"那首次访问岂不是很慢？服务预热本身就是一个问题","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618205647,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1186115,"avatar":"https://static001.geekbang.org/account/avatar/00/12/19/43/226ca347.jpg","nickname":"Michael 🛡YZY","note":"","ucode":"F1D2BF8489A7D2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":899,"discussion_content":"这样应该会是一个不错的选择，或者增加参数，用来调节这个建立连接的timing，同时设置一个默认值。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562143519,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1555695,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/k5OsGRHWreVATJ1tKJBrUO4s4HaeSibRia4FgcmsElibriarMZHg6ntgK6srAUsCohricBsfWRib6zAOy9cDQwzVpjicg/132","nickname":"Vince","note":"","ucode":"1D35072822C6F5","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1186115,"avatar":"https://static001.geekbang.org/account/avatar/00/12/19/43/226ca347.jpg","nickname":"Michael 🛡YZY","note":"","ucode":"F1D2BF8489A7D2","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":302904,"discussion_content":"懒加载其实也可能对吞吐量造成一定的影响，等到发消息是再去创建链接，会降低生产消息的效率","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1599060011,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":899,"ip_address":""},"score":302904,"extra":""}]}]},{"had_liked":false,"id":120511,"user_name":"蓝魔丶","can_delete":false,"product_type":"c1","uid":1219438,"ip_address":"","ucode":"2AE4359E263558","user_header":"https://static001.geekbang.org/account/avatar/00/12/9b/6e/edd2da0c.jpg","comment_is_top":false,"comment_ctime":1564920371,"is_pvip":false,"replies":[{"id":"44238","content":"问题在于客户端有可能一直hold住这个连接导致状态一直是CLOSE_WAIT。事实上，这是非常正确的做法，至少符合TCP协议的设计。当然，如果客户端关闭了连接，就像你说的，OS会发起FIN给远端","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1564965556,"ip_address":"","comment_id":120511,"utype":1}],"discussion_count":6,"race_medal":0,"score":"48809560627","product_id":100029201,"comment_content":"老师，如果Broker端被动关闭，会导致client端产生close_wait状态，这个状态持续一段时间之后，client端不是应该发生FIN完成TCP断开的正常四次握手吗？怎么感觉老师讲的这个FIN就不会再发了，导致了僵尸连接的产生？","like_count":11,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":461367,"discussion_content":"问题在于客户端有可能一直hold住这个连接导致状态一直是CLOSE_WAIT。事实上，这是非常正确的做法，至少符合TCP协议的设计。当然，如果客户端关闭了连接，就像你说的，OS会发起FIN给远端","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1564965556,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1319617,"avatar":"https://static001.geekbang.org/account/avatar/00/14/22/c1/3ba7deca.jpg","nickname":"猫哭","note":"","ucode":"17358613AABE3D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":85520,"discussion_content":"1.客户端程序写的有问题，收到对方broker发送的fin包，read()=0之后没有关闭socket的逻辑；2.客户端cpu太忙来不及调度，或者客户端在sleep等锁或者IO操作之类的，得不到CPU的及时调度，客户端关闭socket的操作被延时执行；3.客户端收到broker发送的fin包之后，这个只是关闭了broker到客户端的连接（此时broker不能写，但是还是能读，不过这个取决于broker是调用的close方法还是shutdown方法，客户端还能写还能读），客户端收到收到fin包的同时，如果发送缓冲区还有很多数据，是要等将发送缓冲区的数据发送给broker之后，才会给broker发送fin包，此期间也是close_wait状态","likes_number":17,"is_delete":false,"is_hidden":false,"ctime":1576551622,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":4,"child_discussions":[{"author":{"id":1151686,"avatar":"https://static001.geekbang.org/account/avatar/00/11/92/c6/84418347.jpg","nickname":"lucas","note":"","ucode":"683A6065CD2483","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1319617,"avatar":"https://static001.geekbang.org/account/avatar/00/14/22/c1/3ba7deca.jpg","nickname":"猫哭","note":"","ucode":"17358613AABE3D","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":260713,"discussion_content":"👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1588897072,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":85520,"ip_address":""},"score":260713,"extra":""},{"author":{"id":2860851,"avatar":"","nickname":"Geek_e78fa5","note":"","ucode":"713677ED3B5745","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1319617,"avatar":"https://static001.geekbang.org/account/avatar/00/14/22/c1/3ba7deca.jpg","nickname":"猫哭","note":"","ucode":"17358613AABE3D","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":539506,"discussion_content":"马克","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1639731246,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":85520,"ip_address":""},"score":539506,"extra":""},{"author":{"id":2897143,"avatar":"https://static001.geekbang.org/account/avatar/00/2c/34/f7/dee5feb9.jpg","nickname":"溯","note":"","ucode":"9E693CCB835FE0","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1319617,"avatar":"https://static001.geekbang.org/account/avatar/00/14/22/c1/3ba7deca.jpg","nickname":"猫哭","note":"","ucode":"17358613AABE3D","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":548226,"discussion_content":"make","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1643092303,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":85520,"ip_address":""},"score":548226,"extra":""}]}]},{"had_liked":false,"id":109556,"user_name":"kursk.ye","can_delete":false,"product_type":"c1","uid":1015995,"ip_address":"","ucode":"9D6A3854E408F9","user_header":"https://static001.geekbang.org/account/avatar/00/0f/80/bb/c0ed9d76.jpg","comment_is_top":false,"comment_ctime":1562056941,"is_pvip":false,"replies":[{"id":"39763","content":"嗯嗯，欢迎不同意见。Kafka对于创建连接没有做任何限制。如果一开始就创建所有TCP连接，之后因为超时的缘故又关闭这些连接，当真正使用时再次创建，那么为什么不把创建时机后延到真正需要的时候呢？实际场景中将TCP连接设置为长连接的情形并不多见，因此我说这种设计是可以改进的。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1562115108,"ip_address":"","comment_id":109556,"utype":1}],"discussion_count":11,"race_medal":0,"score":"48806697197","product_id":100029201,"comment_content":"试想一下，在一个有着 1000 台 Broker 的集群中，你的 Producer 可能只会与其中的 3～5 台 Broker 长期通信，但是 Producer 启动后依次创建与这 1000 台 Broker 的 TCP 连接。一段时间之后，大约有 995 个 TCP 连接又被强制关闭。这难道不是一种资源浪费吗？很显然，这里是有改善和优化的空间的。<br><br>这段不敢苟同。作为消息服务器中国，连接应该是种必要资源，所以部署时就该充分给予，而且创建连接会消耗CPU,用到时再创建不合适，我甚至觉得Kafka应该有连接池的设计。<br><br>另外最后一部分关于TCP关闭第二种情况，客户端到服务端没有关闭，只是服务端到客户端关闭了，tcp是四次断开，可以单方向关闭，另一方向继续保持连接","like_count":11,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":456463,"discussion_content":"嗯嗯，欢迎不同意见。Kafka对于创建连接没有做任何限制。如果一开始就创建所有TCP连接，之后因为超时的缘故又关闭这些连接，当真正使用时再次创建，那么为什么不把创建时机后延到真正需要的时候呢？实际场景中将TCP连接设置为长连接的情形并不多见，因此我说这种设计是可以改进的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562115108,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1036906,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/d2/6a/a9039139.jpg","nickname":"IT小僧","note":"","ucode":"4DC9B291AAD748","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":132103,"discussion_content":"另一方不会立即关闭，但是会关闭，而且不会继续保持连接","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1578881969,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1336951,"avatar":"https://static001.geekbang.org/account/avatar/00/14/66/77/194ba21d.jpg","nickname":"lzh","note":"","ucode":"C3D83DF4230109","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":322705,"discussion_content":"单方关闭，另一方继续保持连接？都没ACK了...怎么保持连接...这还叫TCP吗","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1604804605,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":2,"child_discussions":[{"author":{"id":1081299,"avatar":"https://static001.geekbang.org/account/avatar/00/10/7f/d3/b5896293.jpg","nickname":"Realm","note":"","ucode":"30CBEBE619D1A2","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1336951,"avatar":"https://static001.geekbang.org/account/avatar/00/14/66/77/194ba21d.jpg","nickname":"lzh","note":"","ucode":"C3D83DF4230109","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":552062,"discussion_content":"一方发送 FIN，表示这个连接开始关闭了，双方就都不会发送新的数据了？这也是很常见的误区。\n实际上，一方发送 FIN 只是表示这一方不再发送新的数据，但对方仍可以发送数据。\n还是在 Richard Stevens 的《TCP/IP 详解（第一卷）》中，明确提到 TCP 可以有“半关闭”的做法，也就是：\n一端（A）发送 FIN，表示“我要关闭，不再发送新的数据了，但我可以接收新的数据”。\n另一端（B）可以回复 ACK，表示“我知道你那头不会再发送了，我这头未必哦”。\nB 可以继续发送新的数据给 A，A 也会回复 ACK 表示确认收到新数据。\n在发送完这些新数据后，B 才启动了自己的关闭过程，也就是发送 FIN 给 A，表示“我的事情终于忙好了，我也要关闭，不会再发送新数据了”。\n这时候才是真正的两端都关闭了连接。","likes_number":6,"is_delete":false,"is_hidden":false,"ctime":1645264812,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":322705,"ip_address":""},"score":552062,"extra":""},{"author":{"id":2071279,"avatar":"https://static001.geekbang.org/account/avatar/00/1f/9a/ef/6162b0e0.jpg","nickname":"Rangarok","note":"","ucode":"D13AF6E247EFCF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1081299,"avatar":"https://static001.geekbang.org/account/avatar/00/10/7f/d3/b5896293.jpg","nickname":"Realm","note":"","ucode":"30CBEBE619D1A2","race_medal":0,"user_type":1,"is_pvip":true},"discussion":{"id":575453,"discussion_content":"Mark","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1654843359,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":552062,"ip_address":""},"score":575453,"extra":""}]},{"author":{"id":1036906,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/d2/6a/a9039139.jpg","nickname":"IT小僧","note":"","ucode":"4DC9B291AAD748","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":132099,"discussion_content":"tcp是四次断开，可以单方向关闭，另一方向继续保持连接。\n\n我想知道你这个逻辑是哪里来的？继续保持连接的意义是啥？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1578881835,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":5,"child_discussions":[{"author":{"id":1196886,"avatar":"https://static001.geekbang.org/account/avatar/00/12/43/56/62c38c36.jpg","nickname":"欧阳","note":"","ucode":"2612576E262813","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1036906,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/d2/6a/a9039139.jpg","nickname":"IT小僧","note":"","ucode":"4DC9B291AAD748","race_medal":0,"user_type":1,"is_pvip":true},"discussion":{"id":228545,"discussion_content":"同不明白。工作了这么多年，第一次听到有人说tcp可以一端关闭，另一端继续保持可用……","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1586559990,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":132099,"ip_address":""},"score":228545,"extra":""},{"author":{"id":1134861,"avatar":"https://static001.geekbang.org/account/avatar/00/11/51/0d/fc1652fe.jpg","nickname":"James","note":"","ucode":"48B0F2A334D1C1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1196886,"avatar":"https://static001.geekbang.org/account/avatar/00/12/43/56/62c38c36.jpg","nickname":"欧阳","note":"","ucode":"2612576E262813","race_medal":0,"user_type":1,"is_pvip":true},"discussion":{"id":265786,"discussion_content":"应该是理解出入吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589439205,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":228545,"ip_address":""},"score":265786,"extra":""},{"author":{"id":1503506,"avatar":"https://static001.geekbang.org/account/avatar/00/16/f1/12/7dac30d6.jpg","nickname":"你为啥那么牛","note":"","ucode":"1ABC604A54A8F6","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1196886,"avatar":"https://static001.geekbang.org/account/avatar/00/12/43/56/62c38c36.jpg","nickname":"欧阳","note":"","ucode":"2612576E262813","race_medal":0,"user_type":1,"is_pvip":true},"discussion":{"id":343455,"discussion_content":"称之为假连接","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1611048957,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":228545,"ip_address":""},"score":343455,"extra":""}]}]},{"had_liked":false,"id":216835,"user_name":"半瓶醋","can_delete":false,"product_type":"c1","uid":1282746,"ip_address":"","ucode":"8C898E244D0417","user_header":"https://static001.geekbang.org/account/avatar/00/13/92/ba/9833f06f.jpg","comment_is_top":false,"comment_ctime":1589352920,"is_pvip":true,"replies":[{"id":"80242","content":"最权威的数据保存在ZooKeeper中，Controller会从ZooKeeper中读取并保存在它自己的内存中，然后同步部分元数据给集群所有Broker","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1589382473,"ip_address":"","comment_id":216835,"utype":1}],"discussion_count":2,"race_medal":0,"score":"35949091288","product_id":100029201,"comment_content":"胡夕老师，Kafka集群的元数据信息是保存在哪里的呢，以CDH集群为例，我比较菜：）","like_count":8,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":494963,"discussion_content":"最权威的数据保存在ZooKeeper中，Controller会从ZooKeeper中读取并保存在它自己的内存中，然后同步部分元数据给集群所有Broker","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1589382473,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2860851,"avatar":"","nickname":"Geek_e78fa5","note":"","ucode":"713677ED3B5745","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":539507,"discussion_content":"马克","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1639731366,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":126020,"user_name":"yzh","can_delete":false,"product_type":"c1","uid":1395798,"ip_address":"","ucode":"B6C06FEB731BDC","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKcGBqEZQKHjq3XaSZRLmxrCykMEotI0yKWX7RbbPZh6xTdmNRsum2YxtHv33zHGFdVqxic1pIEn8Q/132","comment_is_top":false,"comment_ctime":1566294076,"is_pvip":false,"replies":[{"id":"46649","content":"1. 这些TCP连接只会被Producer实例下的Sender线程使用。多个Producer实例会创建各自的TCP连接<br>2. 从长期来看，只和需要交互的Broker有连接","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1566374795,"ip_address":"","comment_id":126020,"utype":1}],"discussion_count":1,"race_medal":0,"score":"35926032444","product_id":100029201,"comment_content":"老是您好，咨询两个问题。<br>1. Producer实例创建和维护的tcp连接在底层是否是多个Producer实例共享的，还是Jvm内，多个Producer实例会各自独立创建和所有broker的tcp连接<br>2.Producer实例会和所有broker维持连接，这里的所有，是指和topic下各个分区leader副本所在的broker进行连接的，还是所有的broker，即使该broker下的所有topic分区都是flower<br>","like_count":8,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":463789,"discussion_content":"1. 这些TCP连接只会被Producer实例下的Sender线程使用。多个Producer实例会创建各自的TCP连接\n2. 从长期来看，只和需要交互的Broker有连接","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1566374795,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":111098,"user_name":"电光火石","can_delete":false,"product_type":"c1","uid":1013160,"ip_address":"","ucode":"3AD33BB4AA940F","user_header":"https://static001.geekbang.org/account/avatar/00/0f/75/a8/dfe4cade.jpg","comment_is_top":false,"comment_ctime":1562472279,"is_pvip":false,"replies":[{"id":"40501","content":"1. 也不能说没有关系。客户端需要和topic下各个分区leader副本所在的broker进行连接的<br>2. 嗯嗯，目前客户端是直连broker的<br>3. 光看描述想不出具体的原因。有可能是频繁rebalance、long GC、消息corrupted或干脆就是一个已知的bug","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1562546346,"ip_address":"","comment_id":111098,"utype":1}],"discussion_count":1,"race_medal":0,"score":"23037308759","product_id":100029201,"comment_content":"谢谢老师。有几个问题请教一下：<br>1. producer连接是每个broker一个连接，跟topic没有关系是吗？（consumer也是这样是吗？）<br>2. 我们运维在所有的broker之前放了一个F5做负载均衡，但其实应该也没用，他会自动去获取kafka所有的broker，绕过这个F5，不知道我的理解是否正确？<br>3. 在线上我们有个kafka集群，大概200个topic，数据不是很均衡，有的一天才十几m，有的一天500G，我们是想consumer读取所有的topic，然后后面做分发，但是consumer会卡死在哪，也没有报错，也没有日志输出，不知道老师有没有思路可能是什么原因？<br>谢谢了！","like_count":5,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":457227,"discussion_content":"1. 也不能说没有关系。客户端需要和topic下各个分区leader副本所在的broker进行连接的\n2. 嗯嗯，目前客户端是直连broker的\n3. 光看描述想不出具体的原因。有可能是频繁rebalance、long GC、消息corrupted或干脆就是一个已知的bug","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562546346,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":109693,"user_name":"曾轼麟","can_delete":false,"product_type":"c1","uid":1451391,"ip_address":"","ucode":"D418371AC11270","user_header":"https://static001.geekbang.org/account/avatar/00/16/25/7f/473d5a77.jpg","comment_is_top":false,"comment_ctime":1562077910,"is_pvip":false,"replies":[{"id":"39756","content":"KafkaProducer是线程安全的，复用是没有问题的。只是要监控内存缓冲区的使用情况。毕竟如果多个线程都使用一个KafkaProducer实例，缓冲器被填满的速度会变快。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1562114284,"ip_address":"","comment_id":109693,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18741947094","product_id":100029201,"comment_content":"老师下面就有一个问题，KafkaProducer是建议创建实例后复用，像连接池那样使用，还是建议每次发送构造一个实例？听完这讲后感觉哪个都不合理，每次new会有很大的开销，但是一次new感觉又有僵尸连接，KafkaProducer适合池化吗？还是建议单例？","like_count":4,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":456519,"discussion_content":"KafkaProducer是线程安全的，复用是没有问题的。只是要监控内存缓冲区的使用情况。毕竟如果多个线程都使用一个KafkaProducer实例，缓冲器被填满的速度会变快。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562114284,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":109444,"user_name":"开水","can_delete":false,"product_type":"c1","uid":1528555,"ip_address":"","ucode":"651491C38B925B","user_header":"https://static001.geekbang.org/account/avatar/00/17/52/eb/eec719f3.jpg","comment_is_top":false,"comment_ctime":1562033308,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"18741902492","product_id":100029201,"comment_content":"觉得创建kafkaProducer的时候可以不用去创建sender线程去连接broker。<br>1. 第一次更新元数据的时候，配置一个并发连接参数，比如说10，按照该连接参数的余数去和配置中broker建立TCP连接。<br>2. 获取到相应的metadata信息后，再去和相应的broker进行连接，连接建立后关闭掉无用的连接。<br>3. 按照原有设计，发送数据时再次检查连接。<br><br>这样多余连接不会超过10，并且可配置。而且在更新metadata和发送数据时进行了连接的双重监测，不用进行三次监测。","like_count":4,"discussions":[{"author":{"id":1637632,"avatar":"https://static001.geekbang.org/account/avatar/00/18/fd/00/6cff1d24.jpg","nickname":"Y","note":"","ucode":"F57929C11BD34C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":41117,"discussion_content":"无法定义哪些链接是无用链接","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1572357038,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1528555,"avatar":"https://static001.geekbang.org/account/avatar/00/17/52/eb/eec719f3.jpg","nickname":"开水","note":"","ucode":"651491C38B925B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1637632,"avatar":"https://static001.geekbang.org/account/avatar/00/18/fd/00/6cff1d24.jpg","nickname":"Y","note":"","ucode":"F57929C11BD34C","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":46473,"discussion_content":"哪台broker上面没存相应partition的元信息不就是无用连接么？这个在目前版本里也有实现啊","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1573174080,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":41117,"ip_address":""},"score":46473,"extra":""}]}]},{"had_liked":false,"id":109428,"user_name":"诗泽","can_delete":false,"product_type":"c1","uid":1031865,"ip_address":"","ucode":"F28BE01C3FD12F","user_header":"https://static001.geekbang.org/account/avatar/00/0f/be/b9/f2481c2c.jpg","comment_is_top":false,"comment_ctime":1562031618,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"18741900802","product_id":100029201,"comment_content":"看来无论在bootstrap.servers中是否写全部broker 的地址接下来producer 还是会跟所有的broker 建立一次连接😂","like_count":4},{"had_liked":false,"id":116666,"user_name":"Wenthkim","can_delete":false,"product_type":"c1","uid":1111515,"ip_address":"","ucode":"24F387DA17D7DA","user_header":"https://static001.geekbang.org/account/avatar/00/10/f5/db/93d89a14.jpg","comment_is_top":false,"comment_ctime":1563887683,"is_pvip":false,"replies":[{"id":"42672","content":"为什么连不上了呢？是ulimit打满了吗？如果是可否调大一下？<br>","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1563929394,"ip_address":"","comment_id":116666,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14448789571","product_id":100029201,"comment_content":"老师，请教一个问题，目前遇到一个文中所提的一个问题，就是broker端被直接kill -9,然后产生不量的close_wait,导致重启broker后，producer和consumer都连不上，刷了大量的日志，把机器磁盘给刷爆了，请问老师这个问题我应该怎么去处理？","like_count":3,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":459630,"discussion_content":"为什么连不上了呢？是ulimit打满了吗？如果是可否调大一下？\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563929394,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":109653,"user_name":"吴宇晨","can_delete":false,"product_type":"c1","uid":1199968,"ip_address":"","ucode":"F8F45B7067DF6D","user_header":"https://static001.geekbang.org/account/avatar/00/12/4f/60/049a20e9.jpg","comment_is_top":false,"comment_ctime":1562071835,"is_pvip":false,"replies":[{"id":"39760","content":"Clients端有个参数metadata.max.age.ms强制刷新元数据，默认的确是5分钟。新版本Clients不会与ZooKeeper交互，所以感觉和ZooKeeper没什么关系。。。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1562114813,"ip_address":"","comment_id":109653,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14446973723","product_id":100029201,"comment_content":"老师你好，kafka更新元数据的方法只有每5分钟的轮训吗，如果有监控zk节点之类的，是不是可以把轮询元数据时间调大甚至取消","like_count":3,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":456499,"discussion_content":"Clients端有个参数metadata.max.age.ms强制刷新元数据，默认的确是5分钟。新版本Clients不会与ZooKeeper交互，所以感觉和ZooKeeper没什么关系。。。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562114813,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":109426,"user_name":"KEEPUP","can_delete":false,"product_type":"c1","uid":1436576,"ip_address":"","ucode":"D0B31031E2923F","user_header":"https://static001.geekbang.org/account/avatar/00/15/eb/a0/9d294a9a.jpg","comment_is_top":false,"comment_ctime":1562031455,"is_pvip":false,"discussion_count":3,"race_medal":0,"score":"14446933343","product_id":100029201,"comment_content":"KafkaProducer 实例只是在首次更新元数据信息之后，创建与集群中所有 Broker 的 TCP 连接，还是每次更新之后都要创建？为什么要创建与所有 Broker 的连接呢？","like_count":3,"discussions":[{"author":{"id":1319617,"avatar":"https://static001.geekbang.org/account/avatar/00/14/22/c1/3ba7deca.jpg","nickname":"猫哭","note":"","ucode":"17358613AABE3D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":85504,"discussion_content":"不是这样的，更新元数据信息的时候，是有要操作的该topic，然后返回的元数据信息里有该topic的ISR集合，应该是与这些ISR集合对应的broker建立连接。而不是所有的Broker","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1576550563,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1736462,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/7f/0e/e3a8dbd9.jpg","nickname":"Liujun","note":"","ucode":"3DB1F3CA57B5B3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1319617,"avatar":"https://static001.geekbang.org/account/avatar/00/14/22/c1/3ba7deca.jpg","nickname":"猫哭","note":"","ucode":"17358613AABE3D","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":389754,"discussion_content":"错","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1629423503,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":85504,"ip_address":""},"score":389754,"extra":""}]},{"author":{"id":1035562,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/cd/2a/bdbed6ed.jpg","nickname":"无菇朋友","note":"","ucode":"80482C5F0464A3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":813,"discussion_content":"同样的疑问🤔️","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562074625,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":109415,"user_name":"Liam","can_delete":false,"product_type":"c1","uid":1094597,"ip_address":"","ucode":"1D15D3B64F2606","user_header":"https://static001.geekbang.org/account/avatar/00/10/b3/c5/7fc124e2.jpg","comment_is_top":false,"comment_ctime":1562030727,"is_pvip":false,"replies":[{"id":"39766","content":"当需要用到连接而发现连接不可用的时候就会重建连接了","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1562115287,"ip_address":"","comment_id":109415,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14446932615","product_id":100029201,"comment_content":"producer是否会有类似于heart beat的机制去探测可能被broker关闭的连接然后建立重连呢？","like_count":3,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":456401,"discussion_content":"当需要用到连接而发现连接不可用的时候就会重建连接了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562115287,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":217211,"user_name":"James","can_delete":false,"product_type":"c1","uid":1134861,"ip_address":"","ucode":"48B0F2A334D1C1","user_header":"https://static001.geekbang.org/account/avatar/00/11/51/0d/fc1652fe.jpg","comment_is_top":false,"comment_ctime":1589441409,"is_pvip":false,"replies":[{"id":"80318","content":"目前的设计是不会，它只会与需要访问的主题分区所在的broker建立连接","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1589458593,"ip_address":"","comment_id":217211,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10179376001","product_id":100029201,"comment_content":"请问老师，<br>第一次创建实例，获取metadata数据，比如有1000个Broker，则会创建1000个连接吗<br>然后跟不存在的主题发送消息，也会获取metadata数据，然后也是创建1000个连接吗<br>最后，定时更新metadada也是会创建1000个连接吗<br><br>然后最大保活时间又删除无用的连接，是吧。","like_count":2,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":495079,"discussion_content":"目前的设计是不会，它只会与需要访问的主题分区所在的broker建立连接","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589458593,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":165427,"user_name":"张伯毅","can_delete":false,"product_type":"c1","uid":1099929,"ip_address":"","ucode":"E9EAF5ECFE32C7","user_header":"https://static001.geekbang.org/account/avatar/00/10/c8/99/22d2a6a7.jpg","comment_is_top":false,"comment_ctime":1577236962,"is_pvip":false,"replies":[{"id":"63192","content":"官方给的经验：）   最好还是结合自己实际场景而定","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1577322093,"ip_address":"","comment_id":165427,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10167171554","product_id":100029201,"comment_content":"整个集群 topic 的数量有限制嘛, 最大是多少 ?<br>单台broker上分区数最好不要超过 2k . 这个是根据经验来的嘛,还是官方有推荐.??","like_count":2,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":479156,"discussion_content":"官方给的经验：）   最好还是结合自己实际场景而定","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1577322093,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":124092,"user_name":"钱","can_delete":false,"product_type":"c1","uid":1009652,"ip_address":"","ucode":"2C92A243A463D4","user_header":"https://static001.geekbang.org/account/avatar/00/0f/67/f4/9a1feb59.jpg","comment_is_top":false,"comment_ctime":1565823876,"is_pvip":false,"replies":[{"id":"45518","content":"producer会向任意一个broker请求元数据，因为所有broker都缓存了相同的集群元数据信息","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1565827113,"ip_address":"","comment_id":124092,"utype":1}],"discussion_count":3,"race_medal":0,"score":"10155758468","product_id":100029201,"comment_content":"1：集群中的任意一台broker都拥有整个集群的所有broker的信息？<br>通过评论了解到，所有的元数据是存储在zookeeper集群节点中的，broker是缓存了这部分信息。元数据知都有主题的信息、都有broker的信息。<br><br>2：勇敢的质疑精神是，独立思考的前提<br><br>3：当Producer 尝试给一个不存在的主题发送消息时，Broker 会告诉 Producer 说这个主题不存在。此时 Producer 会发送 METADATA 请求给 Kafka 集群，去尝试获取最新的元数据信息。<br>这种情况是怎么发生的，一个主题如果不存在，producer怎么知道给那个broker建立连接，发送消息？","like_count":2,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":463007,"discussion_content":"producer会向任意一个broker请求元数据，因为所有broker都缓存了相同的集群元数据信息","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1565827113,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1009652,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/67/f4/9a1feb59.jpg","nickname":"钱","note":"","ucode":"2C92A243A463D4","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":4930,"discussion_content":"胡老师，我的疑惑是producer怎么会尝试给一个不存在的topic发送消息，因为我目前的认识，是假如没有topic，就不会为其分配broker，发送消息必定要知道发给那个 broker 的？\n对于获取broker的信息我是没疑问的，每台broker上都会缓存一份所有主题及broker的信息，那么去任意一台机器确实可以拿到对于的信息。\n如果方便还请解答一下，非常感谢!","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1565839053,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1762252,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/e3/cc/0947ff0b.jpg","nickname":"nestle","note":"","ucode":"469800BED81B54","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1009652,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/67/f4/9a1feb59.jpg","nickname":"钱","note":"","ucode":"2C92A243A463D4","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":301513,"discussion_content":"生产过程中topic被删除了？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1598542390,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":4930,"ip_address":""},"score":301513,"extra":""}]}]},{"had_liked":false,"id":109945,"user_name":"Li Shunduo","can_delete":false,"product_type":"c1","uid":1222882,"ip_address":"","ucode":"6C5AB4129E9780","user_header":"https://static001.geekbang.org/account/avatar/00/12/a8/e2/f8e51df2.jpg","comment_is_top":false,"comment_ctime":1562138337,"is_pvip":false,"replies":[{"id":"39910","content":"有可能，可能用于不同的目的，通常最终会收敛成一个","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1562202126,"ip_address":"","comment_id":109945,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10152072929","product_id":100029201,"comment_content":"请问Producer会和同一台broker建立多个TCP连接吗？","like_count":2,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":456650,"discussion_content":"有可能，可能用于不同的目的，通常最终会收敛成一个","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562202126,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":109364,"user_name":"明翼","can_delete":false,"product_type":"c1","uid":1068361,"ip_address":"","ucode":"E77F86BEB3D5C1","user_header":"https://static001.geekbang.org/account/avatar/00/10/4d/49/28e73b9c.jpg","comment_is_top":false,"comment_ctime":1562026950,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10151961542","product_id":100029201,"comment_content":"我的想法这样的，先用客户端去连配置的第一broker server，连不上就连接第二个，一旦连上了，就可以获取元数据信息了，这是创建produce实例时候动作，只发起一个TCP连接。再send时候发现没连接的再连接，至于其他的都还是很合理的。","like_count":2},{"had_liked":false,"id":232430,"user_name":"J.Smile","can_delete":false,"product_type":"c1","uid":1336475,"ip_address":"","ucode":"C4D98DFDBF7584","user_header":"https://static001.geekbang.org/account/avatar/00/14/64/9b/0b578b08.jpg","comment_is_top":false,"comment_ctime":1594002907,"is_pvip":false,"replies":[{"id":"85927","content":"“重新跟leader副本所在的broker节点建立连接？” -- 如果还需要发送请求则要建立连接。会不会rebalance与tcp连接无关<br>","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1594131813,"ip_address":"","comment_id":232430,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5888970203","product_id":100029201,"comment_content":"老师，深入思考🤔再追问下:<br>“如果某个 Socket 连接上连续 9 分钟都没有任何请求“过境”的话，那么消费者会强行“杀掉”这个 Socket 连接”，这个socket连接被杀掉后，还会重新跟leader副本所在的broker节点建立连接吗？如果会，这个应该是不会reblance因为跟心跳连接不是同一个。所以，会在啥场景重新建立？<br>","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":500641,"discussion_content":"“重新跟leader副本所在的broker节点建立连接？” -- 如果还需要发送请求则要建立连接。会不会rebalance与tcp连接无关\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1594131813,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":194308,"user_name":"SunshineBoy","can_delete":false,"product_type":"c1","uid":1160644,"ip_address":"","ucode":"FC54CD1815CCBA","user_header":"https://static001.geekbang.org/account/avatar/00/11/b5/c4/9148b40d.jpg","comment_is_top":false,"comment_ctime":1585048599,"is_pvip":false,"replies":[{"id":"74065","content":"长期来看，producer与N个broker通讯，那么就会维持与这N个Broker的TCP连接","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1585096228,"ip_address":"","comment_id":194308,"utype":1}],"discussion_count":1,"race_medal":1,"score":"5880015895","product_id":100029201,"comment_content":"假如broker leader副本有100台机器，bootStrap.servers配置了10个broker地址，kafkaProducer创建实例时，是创建100个Tcp连接还是110个Tcp连接？","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":488810,"discussion_content":"长期来看，producer与N个broker通讯，那么就会维持与这N个Broker的TCP连接","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1585096228,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":186366,"user_name":"咸淡一首诗","can_delete":false,"product_type":"c1","uid":1435869,"ip_address":"","ucode":"FEE5A9B5139BF1","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLl9nj9b6RydKADq82ZwOad0fQcvXWyQKk5U5RFC2kzHGI4GjIQsIZvHsEm7mFELgMiaGx3lGq9vag/132","comment_is_top":false,"comment_ctime":1583830585,"is_pvip":false,"replies":[{"id":"72115","content":"这个错误多是网络原因导致的，如果是瞬时错误可以不用理会，如果持续抛这个错误那么需要进一步看是什么原因了导致的了。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1583976032,"ip_address":"","comment_id":186366,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5878797881","product_id":100029201,"comment_content":"胡老师问一个问题，producer 异步发送数据时报这个错： The server disconnected before a response was received，想问一下这个可能导致的原因以及解决办法，kafka版本是0.10.1.1，谢谢老师。","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":486729,"discussion_content":"这个错误多是网络原因导致的，如果是瞬时错误可以不用理会，如果持续抛这个错误那么需要进一步看是什么原因了导致的了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1583976032,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1762252,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/e3/cc/0947ff0b.jpg","nickname":"nestle","note":"","ucode":"469800BED81B54","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":301514,"discussion_content":"我们在生产环境遇到过这个错误，是空闲连接超时，kafka主动断开了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1598542588,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":181216,"user_name":"HZ","can_delete":false,"product_type":"c1","uid":1371862,"ip_address":"","ucode":"883D79CEEA9C66","user_header":"https://static001.geekbang.org/account/avatar/00/14/ee/d6/0142c3a3.jpg","comment_is_top":false,"comment_ctime":1582519994,"is_pvip":false,"replies":[{"id":"70341","content":"并不会与所有broker建立TCP连接去获取元数据。随机找一个broker去获取的~<br>","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1582593607,"ip_address":"","comment_id":181216,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5877487290","product_id":100029201,"comment_content":"老师 有一点不明白，为什么更新元数据需要和所有的broker建立 tcp 连接呢？ 我感觉应该仅仅是controller或者某个broker吧。","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":484961,"discussion_content":"并不会与所有broker建立TCP连接去获取元数据。随机找一个broker去获取的~\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1582593607,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1344289,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLEYbNElGIxY6Le1rfiakWJecz8JIOp06Y9JQFR2YBn3T3gx3icI5CKxZNgxgqiaKbfVOicXquO3QBw9w/132","nickname":"july","note":"","ucode":"E081987929063A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":232240,"discussion_content":"你好，大牛，Producer更新元数据信息后会和所有的broker进行连接，然后没有数据交互，连接会被kafka关闭，然后Producer一段时间又会更新元数据，此时Producer还重新建立与那些曾经连过的但是断开了的broker的连接吗？如果新的元数据中包含了新加入的broker的话，Producer会与其建立连接吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586862562,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":128346,"user_name":"cgddw","can_delete":false,"product_type":"c1","uid":1316424,"ip_address":"","ucode":"621E250BC49C28","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLHKka9hn8hYyd7SD12PEYiazRKg2a5iaFibP7z13t9ARicUvbwItESpIYONxV6gHMFYTmdp4eGZ4YDsA/132","comment_is_top":false,"comment_ctime":1566872908,"is_pvip":false,"replies":[{"id":"47602","content":"可能有很多clients端连接过该broker，而clients又都没有正常关闭所致","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1566879709,"ip_address":"","comment_id":128346,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5861840204","product_id":100029201,"comment_content":"broker有很多time_wait端口，甚至比established多，这是什么情况","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":464909,"discussion_content":"可能有很多clients端连接过该broker，而clients又都没有正常关闭所致","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1566879709,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1439908,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/IPdZZXuHVMibwfZWmm7NiawzeEFGsaRoWjhuN99iaoj5amcRkiaOePo6rH1KJ3jictmNlic4OibkF4I20vOGfwDqcBxfA/132","nickname":"鱼向北游","note":"","ucode":"580EC7DCE57E9A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":32259,"discussion_content":"这个问题我和老师的观点不同，timewait会等2msl时间，规范上是2min，linux实现应该是30s，等完这个时间，tcp才会完全关闭，一般系统参数都会开启timewait的端口复用","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1571020014,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":124331,"user_name":"丽儿","can_delete":false,"product_type":"c1","uid":1386917,"ip_address":"","ucode":"3804ACF2C1D8A3","user_header":"https://static001.geekbang.org/account/avatar/00/15/29/a5/9c6e7526.jpg","comment_is_top":false,"comment_ctime":1565861745,"is_pvip":false,"replies":[{"id":"45633","content":"一般先随机选一个broker获取到所有集群信息，然后再有针对性地连接特定的broker","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1565875660,"ip_address":"","comment_id":124331,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5860829041","product_id":100029201,"comment_content":"请问一下老师客户端是怎么选择broker的","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":463119,"discussion_content":"一般先随机选一个broker获取到所有集群信息，然后再有针对性地连接特定的broker","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1565875660,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":119731,"user_name":"盘尼西林","can_delete":false,"product_type":"c1","uid":1197347,"ip_address":"","ucode":"B59569FC25144F","user_header":"https://static001.geekbang.org/account/avatar/00/12/45/23/28311447.jpg","comment_is_top":false,"comment_ctime":1564666905,"is_pvip":false,"replies":[{"id":"43963","content":"嗯嗯，集群中所有主题信息、所有broker信息等","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1564707912,"ip_address":"","comment_id":119731,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5859634201","product_id":100029201,"comment_content":"问一下元数据具体指的是什么？存放在broker端的维护topic的信息的元数据么？","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":461043,"discussion_content":"嗯嗯，集群中所有主题信息、所有broker信息等","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1564707912,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":119508,"user_name":"行则将至","can_delete":false,"product_type":"c1","uid":1542987,"ip_address":"","ucode":"DB972F2DF059C4","user_header":"https://static001.geekbang.org/account/avatar/00/17/8b/4b/fa52d222.jpg","comment_is_top":false,"comment_ctime":1564620446,"is_pvip":false,"replies":[{"id":"43870","content":"我建议直接使用kafka自己原生的api","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1564627803,"ip_address":"","comment_id":119508,"utype":1}],"discussion_count":1,"race_medal":1,"score":"5859587742","product_id":100029201,"comment_content":"老师，作为kafka的初学者来说。您建议使用kafka的原生API练习文中demo，还是使用被其他框架整合的kafka练习？","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":460935,"discussion_content":"我建议直接使用kafka自己原生的api","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1564627803,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":111793,"user_name":"金小璐","can_delete":false,"product_type":"c1","uid":1443031,"ip_address":"","ucode":"2B0B3BC55CA147","user_header":"https://static001.geekbang.org/account/avatar/00/16/04/d7/fa5583e5.jpg","comment_is_top":false,"comment_ctime":1562601021,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"5857568317","product_id":100029201,"comment_content":"tcp和http这部分的解释觉得有点怪。多路复用不是tcp协议栈特性，而且http也能做多路复用（如spdy），不能算作选型原因。http是基于tcp协议之上的，我理解如果不需要http协议特征，那选tcp一定比选http好，毕竟少了一层协议栈解析呀～","like_count":1,"discussions":[{"author":{"id":1762252,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/e3/cc/0947ff0b.jpg","nickname":"nestle","note":"","ucode":"469800BED81B54","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":383842,"discussion_content":"TCP多路复用这里我也没看懂","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1626251519,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":110301,"user_name":"燃烧的M豆","can_delete":false,"product_type":"c1","uid":1355000,"ip_address":"","ucode":"BEDA9FC8852F5D","user_header":"https://static001.geekbang.org/account/avatar/00/14/ac/f8/a56b7475.jpg","comment_is_top":false,"comment_ctime":1562226255,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5857193551","product_id":100029201,"comment_content":"c 包在v1.0.0 已经对这个问题采取了对策。所有使用基础 c 包 librdkafka 都因此受益<br><br>Sparse connections<br>In previous releases librdkafka would maintain open connections to all<br>brokers in the cluster and the bootstrap servers.<br><br>With this release librdkafka now connects to a single bootstrap server<br>to retrieve the full broker list, and then connects to the brokers<br>it needs to communicate with: partition leaders, group coordinators, etc.<br><br>For large scale deployments this greatly reduces the number of connections<br>between clients and brokers, and avoids the repeated idle connection closes<br>for unused connections.<br><br>Sparse connections is on by default (recommended setting), the old<br>behavior of connecting to all brokers in the cluster can be re-enabled<br>by setting enable.sparse.connections=false.<br><br>See Sparse connections in the manual for more information.<br><br>Original issue librdkafka #825.<br><br>为啥 java 目前还是这样或者一已经开始动手修改了？- -有点无法理解。","like_count":1},{"had_liked":false,"id":110264,"user_name":"JoeyLi666","can_delete":false,"product_type":"c1","uid":1564463,"ip_address":"","ucode":"734864661E4BE0","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJZCkGPSOcvucpfLqRP3aqp3qRpwJKyzjNms4jMwibIkxpjiaszqiazSItCeo3IxqQSFvMDh66XaJ2zw/132","comment_is_top":false,"comment_ctime":1562217170,"is_pvip":false,"replies":[{"id":"40149","content":"也可能是网络传输过程中出现的偶发情况，通常没有什么好的解决办法。。。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1562287014,"ip_address":"","comment_id":110264,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5857184466","product_id":100029201,"comment_content":"老师，最近使用kakfa，报了个异常：<br>Caused by: org.apache.kafka.common.KafkaException: Record batch for partition Notify-18 at offset 1803009 is invalid, cause: Record is corrupt (stored crc = 3092077514, computed crc = 2775748463)<br>kafka的数据还会损坏，不是有校验吗？","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":456792,"discussion_content":"也可能是网络传输过程中出现的偶发情况，通常没有什么好的解决办法。。。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562287014,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1564463,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJZCkGPSOcvucpfLqRP3aqp3qRpwJKyzjNms4jMwibIkxpjiaszqiazSItCeo3IxqQSFvMDh66XaJ2zw/132","nickname":"JoeyLi666","note":"","ucode":"734864661E4BE0","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":1195,"discussion_content":"老师，那针对这个异常，需要对consume.poll()加try-catch，然后手动commit掉这条消息？","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1562389515,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":109993,"user_name":"南辕北辙","can_delete":false,"product_type":"c1","uid":1214502,"ip_address":"","ucode":"03EC406AE0D591","user_header":"https://static001.geekbang.org/account/avatar/00/12/88/26/b8c53cee.jpg","comment_is_top":false,"comment_ctime":1562146687,"is_pvip":false,"replies":[{"id":"39914","content":"我不知道您这边是怎么实验的，但是我这边的确会创建新的TCP连接~~ ","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1562202838,"ip_address":"","comment_id":109993,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5857113983","product_id":100029201,"comment_content":"老师您好，我在本地分别用1.x版本和2.x版本的生产者去测试，为什么结果和老师的不一样呢。初始化KafkaProducer时，并没有与参数中设置的所有broker去建立连接，然后我sleep十秒，让sender线程有机会多运行会。但是还是没有看到去连接所有的broker。只有当运行到procuder.send时才会有Initialize connection日志输出，以及由于metadata的needUpdate被更新成true，sender线程会开始有机会去更新metadata去连接broker（产生Initialize connection to node...for sending metadata request）。之前学习源码的时候，也只注意到二个地方去连接broker（底层方法initiateConnect，更新metadata时建立连接以及发送数据时判断待发送的node是否建立了连接）。老师是我哪里疏忽了吗，还是理解有问题。翻阅老师的书上TCP管理这块貌似没有过多的讲解，求老师指导。。","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":456673,"discussion_content":"我不知道您这边是怎么实验的，但是我这边的确会创建新的TCP连接~~ ","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562202838,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1762252,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/e3/cc/0947ff0b.jpg","nickname":"nestle","note":"","ucode":"469800BED81B54","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":383875,"discussion_content":"新版本的客户端确实不会连接全部的bootstrap.servers，并且验证生产者也只会与leader建立连接","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1626265224,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":109953,"user_name":"ban","can_delete":false,"product_type":"c1","uid":1034204,"ip_address":"","ucode":"E523CE97E48266","user_header":"https://static001.geekbang.org/account/avatar/00/0f/c7/dc/9408c8c2.jpg","comment_is_top":false,"comment_ctime":1562139637,"is_pvip":false,"replies":[{"id":"39909","content":"一个KafkaProducer实例会开辟一块内存缓冲区，如果多个线程共用这部分buffer，自然buffer被填满的速度就会快很多。我是这个意思。。。。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1562202096,"ip_address":"","comment_id":109953,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5857106933","product_id":100029201,"comment_content":"如果多个线程都使用一个KafkaProducer实例，缓冲器被填满的速度会变快。<br>老师看评论这句话不太理解，多个线程共用一个实例，没有再new新的实例，为什么缓冲器很快填满，不是利用原有的实例的吗。","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":456651,"discussion_content":"一个KafkaProducer实例会开辟一块内存缓冲区，如果多个线程共用这部分buffer，自然buffer被填满的速度就会快很多。我是这个意思。。。。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562202096,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":109851,"user_name":"Geek_Sue","can_delete":false,"product_type":"c1","uid":1580774,"ip_address":"","ucode":"B2C9400D72BB1D","user_header":"","comment_is_top":false,"comment_ctime":1562120957,"is_pvip":false,"replies":[{"id":"39911","content":"如果 broker端和clients端的connections.max.idle.ms都是-1，就真是永不关闭了。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1562202230,"ip_address":"","comment_id":109851,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5857088253","product_id":100029201,"comment_content":"胡老师，我想请教一下。<br>connections.max.idle.ms这个值如果设置为-1，按照您文章里所说，KafkaProducer会创建bootstrap.servers中全部tcp连接，如果是1000个，那么就是说这1000个连接永远不会关闭了？","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":456604,"discussion_content":"如果 broker端和clients端的connections.max.idle.ms都是-1，就真是永不关闭了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562202230,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":109738,"user_name":"飞翔","can_delete":false,"product_type":"c1","uid":1068571,"ip_address":"","ucode":"65AF6AF292DAD6","user_header":"https://static001.geekbang.org/account/avatar/00/10/4e/1b/f4b786b9.jpg","comment_is_top":false,"comment_ctime":1562084385,"is_pvip":true,"replies":[{"id":"39753","content":"嗯嗯， 目前不是这样设计的。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1562113982,"ip_address":"","comment_id":109738,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5857051681","product_id":100029201,"comment_content":"KafkaProducer 实例首次更新元数据信息之后，还会再次创建与集群中所有 Broker 的 TCP 连接。    这里如果我有1000个broker，就建立1000个链接？ 为啥不是只根据元信息只建立有我要发的主题的broke的链接？","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":456545,"discussion_content":"嗯嗯， 目前不是这样设计的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562113982,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1736462,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/7f/0e/e3a8dbd9.jpg","nickname":"Liujun","note":"","ucode":"3DB1F3CA57B5B3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":389759,"discussion_content":"元数据信息怎么会知道你要发送的是哪个主题？而且发送时也会创建主题，官方这种做法是极其正确的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1629424461,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":109489,"user_name":"lmtoo","can_delete":false,"product_type":"c1","uid":1133918,"ip_address":"","ucode":"FCD5B9C941D448","user_header":"https://static001.geekbang.org/account/avatar/00/11/4d/5e/c5c62933.jpg","comment_is_top":false,"comment_ctime":1562042717,"is_pvip":false,"replies":[{"id":"39764","content":"有可能也会连接这些Broker的。Clients获取到集群元数据后知道了集群所有Broker的连接信息。下次再次获取元数据时，它会选择一个负载最少的Broker进行连接。如果发现没有连接也会创建Socket，但其实它并不需要向这个Broker发送任何消息。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1562115231,"ip_address":"","comment_id":109489,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5857010013","product_id":100029201,"comment_content":"Producer应该只跟Controller节点更新元数据，以及相关的topic机器交互数据，而不应该跟所有的机器创建连接；有个疑问，当 Producer 更新了集群的元数据信息之后，如果发现与某些broker没有连接，就去创建，为什么会去创建跟producer无关的连接？","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":456437,"discussion_content":"有可能也会连接这些Broker的。Clients获取到集群元数据后知道了集群所有Broker的连接信息。下次再次获取元数据时，它会选择一个负载最少的Broker进行连接。如果发现没有连接也会创建Socket，但其实它并不需要向这个Broker发送任何消息。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562115231,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":109482,"user_name":"张庆","can_delete":false,"product_type":"c1","uid":1050284,"ip_address":"","ucode":"17AE1E23B83304","user_header":"https://static001.geekbang.org/account/avatar/00/10/06/ac/604de2e8.jpg","comment_is_top":false,"comment_ctime":1562040007,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5857007303","product_id":100029201,"comment_content":"主要的资源浪费应该是在第一次获取元数据的时候创建所有的连接，应该是这个地方可以做一些优化吧，可以做一个最小初始化数量，从元数据中随机获取配置的最少数据，然后进行初始化。然后向Broker发送消息的时候在去判断，如果没有连接就创建连接，这样应该可以折中一下吧。","like_count":1},{"had_liked":false,"id":109343,"user_name":"songt","can_delete":false,"product_type":"c1","uid":1097118,"ip_address":"","ucode":"E6868282100139","user_header":"https://static001.geekbang.org/account/avatar/00/10/bd/9e/301600c4.jpg","comment_is_top":false,"comment_ctime":1562023615,"is_pvip":false,"replies":[{"id":"39591","content":"这两款MQ的吞吐量都很大，都能满足你们的需求。RocketMQ是阿里研发的，国内支持上要比Kafka好一些；Kafka比较成熟，社区也很完善，反正是各自有优缺点吧。至于网上那些比较的文章，我觉得它们的缺点在实际场景中都能规避，不存在绝对的孰强孰劣。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1562028099,"ip_address":"","comment_id":109343,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5856990911","product_id":100029201,"comment_content":"最近和同事梳理mq的中间件种类 提到使用Kafka还是rocketmq 同事强烈推荐使用rocketmq 其实我们的业务是可能有数据量较大情况的，之前不了解Rocketmq 老师能给些建议吗？","like_count":1,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":456367,"discussion_content":"这两款MQ的吞吐量都很大，都能满足你们的需求。RocketMQ是阿里研发的，国内支持上要比Kafka好一些；Kafka比较成熟，社区也很完善，反正是各自有优缺点吧。至于网上那些比较的文章，我觉得它们的缺点在实际场景中都能规避，不存在绝对的孰强孰劣。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562028099,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1130929,"avatar":"https://static001.geekbang.org/account/avatar/00/11/41/b1/565d0f56.jpg","nickname":".cc","note":"","ucode":"D99025BD7626C6","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":156462,"discussion_content":"主要看场景的吞吐量吧，RocketMQ 十万TPS量级，Kafka百万量级，大数据场景Kafka是标配，RocketMQ取代不了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1580367057,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":360742,"user_name":"青玄","can_delete":false,"product_type":"c1","uid":1356135,"ip_address":"四川","ucode":"C61BD9BCEFEF66","user_header":"https://static001.geekbang.org/account/avatar/00/14/b1/67/1d3c2f25.jpg","comment_is_top":false,"comment_ctime":1666799272,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1666799272","product_id":100029201,"comment_content":"文中第二种关闭连接的方式，在当前最新版本 Kafka3.3.1 TCP 连接超时关闭是有客户端完成的。","like_count":0},{"had_liked":false,"id":354756,"user_name":"Geek_06d12d","can_delete":false,"product_type":"c1","uid":1590623,"ip_address":"浙江","ucode":"1C5172C3BBAEC3","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eqGaJsoQicG7Bp8cUjUkevAp5Sm8ZXy5vl5TVk4CDrq5UAoI9VicK5wwjCdk66FVRbGziaWXHgO52l1Q/132","comment_is_top":false,"comment_ctime":1660746703,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1660746703","product_id":100029201,"comment_content":"TCP多路复用，指的不是不断开连接进行复用避免重复连接吗，没明白在一条物理连接上创建若干个虚拟连接是啥意思","like_count":0},{"had_liked":false,"id":349740,"user_name":"张伟明","can_delete":false,"product_type":"c1","uid":1229314,"ip_address":"","ucode":"E101C8E2833004","user_header":"https://static001.geekbang.org/account/avatar/00/12/c2/02/f20e09c5.jpg","comment_is_top":false,"comment_ctime":1656299874,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1656299874","product_id":100029201,"comment_content":"加入机器学习算法，使其保持最适合的连接数。","like_count":0},{"had_liked":false,"id":349374,"user_name":"机智的胖纸","can_delete":false,"product_type":"c1","uid":1430568,"ip_address":"","ucode":"0EEBC02FF9EB06","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK6yJ7MdMSUEuhaIFJ1VibttXlbrnqib1ubb5vOVC4V0XuoTP6qGpPmhA7p1fAeJ1Rm6ciayOUMc7xCA/132","comment_is_top":false,"comment_ctime":1655914973,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1655914973","product_id":100029201,"comment_content":"胡老师 我有一个问题 假如有10台broker 我设置某个topic有十个分区. 这十个分区（都是单副本）分布在不同的机器上. 如果某一台broker挂了 生产者是不是就会将这台broker的分区从分区列表里面剔除 不会继续往这个broker发数据了。在整体生产过程中（除了那台broker刚挂那段时间 发往这台分区的数据会丢失）会将数据发往其他的分区 不会继续发往这个分区了吧","like_count":0},{"had_liked":false,"id":335720,"user_name":"咸","can_delete":false,"product_type":"c1","uid":1349358,"ip_address":"","ucode":"1F189A2B1A6A71","user_header":"https://static001.geekbang.org/account/avatar/00/14/96/ee/9b21c199.jpg","comment_is_top":false,"comment_ctime":1645664341,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1645664341","product_id":100029201,"comment_content":"老师您好，再看kafka源码的时候，发展producer与broker通过tcp链接的实现是通过javanio来完成的，但是也是对javanio做了包装，能帮忙说说是如何包装的嘛？为什么不用netty来完成这个事呢","like_count":0},{"had_liked":false,"id":330563,"user_name":"小仙","can_delete":false,"product_type":"c1","uid":1866677,"ip_address":"","ucode":"9F94043DFCEC3A","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eq6pWvKsV4rzQ62z5MDEjaEU5MbDfmzbA62kUgoqia2tgKIIxw4ibkDhF7W48iat5dT8UB9Adky2NuzQ/132","comment_is_top":false,"comment_ctime":1642043138,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1642043138","product_id":100029201,"comment_content":"假设 producer 配置 bootstrap.servers ：kafka1:9192,kafka2:9192，但是kafka集群有100个broker<br>1.第一次 producer 创建 sender 线程，只会与 kafka1:9192,kafka2:9192 建立 TCP 连接<br>2.但是当 producer 实例首次更新元数据信息之后，还会再次创建与集群中所有 Broker（100个） 的 TCP 连接。","like_count":0},{"had_liked":false,"id":328216,"user_name":"马以","can_delete":false,"product_type":"c1","uid":1344431,"ip_address":"","ucode":"3FEA06CA14DE28","user_header":"https://static001.geekbang.org/account/avatar/00/14/83/af/1cb42cd3.jpg","comment_is_top":false,"comment_ctime":1640609582,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1640609582","product_id":100029201,"comment_content":"我很想问下，这里为啥要拿http和tcp来做对比？这两个协议完全不在同一个网络层啊？用TCP是因为TCP是一个可靠传输协议，这和用不用http没啥关系吧？","like_count":0},{"had_liked":false,"id":323594,"user_name":"最烦起名字","can_delete":false,"product_type":"c1","uid":2153662,"ip_address":"","ucode":"405A886940AD46","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIXbxuhFpUq10M3H87WiaE4bbqI5gTtmxfQCZDPUad4KrCJn8NiaPxhask5YSzRyQiaRaEJqaGoax35A/132","comment_is_top":false,"comment_ctime":1638008466,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1638008466","product_id":100029201,"comment_content":"老师 ，connections.max.idle.ms =-1 ，建立的TCP链接不会被关闭，那再将connections.max.idle.ms设置为一个大于0的值， 哪些僵尸链接会被关闭吗","like_count":0},{"had_liked":false,"id":312563,"user_name":"日就月将","can_delete":false,"product_type":"c1","uid":2651148,"ip_address":"","ucode":"0F9BA55A2898FF","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/cabLXAUXiavXnEckAgo971o4l1CxP4L9wOV2eUGTyKBUicTib6gJyKV9iatM4GG1scz5Ym17GOzXWQEGzhE31tXUtQ/132","comment_is_top":false,"comment_ctime":1631865734,"is_pvip":false,"replies":[{"id":"114439","content":"我是想说Kafka的协议类型底层走的是TCP的通道","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1634004604,"ip_address":"","comment_id":312563,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1631865734","product_id":100029201,"comment_content":"老师 HTTP协议不是基于TCP协议的吗 那HTTP没有TCP协议的功能吗？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527027,"discussion_content":"我是想说Kafka的协议类型底层走的是TCP的通道","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1634004604,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":307247,"user_name":"weirdw","can_delete":false,"product_type":"c1","uid":2597645,"ip_address":"","ucode":"CC97D762CF383A","user_header":"https://static001.geekbang.org/account/avatar/00/27/a3/0d/b3a40f90.jpg","comment_is_top":false,"comment_ctime":1628985229,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1628985229","product_id":100029201,"comment_content":"开放讨论的问题，是否可以设计一个Max connection 的参数比如3-5，如果因为各种网络原因connection减少了就重连或者连接其他的broker，而不是一上来就链接所有的broker","like_count":0},{"had_liked":false,"id":298763,"user_name":"✨胡小东","can_delete":false,"product_type":"c1","uid":1312339,"ip_address":"","ucode":"314D40A5857C17","user_header":"https://static001.geekbang.org/account/avatar/00/14/06/53/29fa4e12.jpg","comment_is_top":false,"comment_ctime":1624318400,"is_pvip":false,"replies":[{"id":"108485","content":"任何tcp连接，只要一段时间没有请求流经其上，都会被关闭","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1624497401,"ip_address":"","comment_id":298763,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1624318400","product_id":100029201,"comment_content":"如果设置 Producer 端 connections.max.idle.ms 参数大于 0，则步骤 1 中创建的 TCP 连接会被自动关闭？ 这里有点疑问？只会关闭第一次建立的tcp连接吗？通过元数据创建的tcp连接不会被关闭嘛？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":522234,"discussion_content":"任何tcp连接，只要一段时间没有请求流经其上，都会被关闭","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1624497401,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":295887,"user_name":"Geek1185","can_delete":false,"product_type":"c1","uid":2028954,"ip_address":"","ucode":"47BEE492EF4C1A","user_header":"https://static001.geekbang.org/account/avatar/00/1e/f5/9a/63dc81a2.jpg","comment_is_top":false,"comment_ctime":1622630549,"is_pvip":false,"replies":[{"id":"107774","content":"也不是了。总之，目前就是这样设计的，其实确实有一些可以优化的空间","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1623120250,"ip_address":"","comment_id":295887,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1622630549","product_id":100029201,"comment_content":"kafka Producer 启动后依次创建与这 1000 台 Broker 的 TCP 连接。但是producer短期内只与其中3-5台通信，一段时间之后，大约有 995 个 TCP 连接又被强制关闭。这其中是否存在资源的浪费？<br><br>是否是因为内网应用的长连接的资源损耗可以忽略？<br>","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":521253,"discussion_content":"也不是了。总之，目前就是这样设计的，其实确实有一些可以优化的空间","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1623120250,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":290148,"user_name":"worry","can_delete":false,"product_type":"c1","uid":1047773,"ip_address":"","ucode":"AF2BDAF6F6370E","user_header":"https://static001.geekbang.org/account/avatar/00/0f/fc/dd/0e17bf09.jpg","comment_is_top":false,"comment_ctime":1619403286,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1619403286","product_id":100029201,"comment_content":"bootstrap.servers这个参数的有些歧义，本意是配置几个broker做备用就可以了，不是所有的都配置上。这样的话，producer也就是和几个broker建立了链接，而不是所有。这样设计应该也算合理。","like_count":0},{"had_liked":false,"id":288578,"user_name":"双椒叔叔","can_delete":false,"product_type":"c1","uid":1395385,"ip_address":"","ucode":"9C4B1DB2E693AF","user_header":"https://static001.geekbang.org/account/avatar/00/15/4a/b9/1531ff1c.jpg","comment_is_top":false,"comment_ctime":1618547734,"is_pvip":false,"replies":[{"id":"105291","content":"增加下关闭连接的空闲时段阈值<br>","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1619600158,"ip_address":"","comment_id":288578,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1618547734","product_id":100029201,"comment_content":"老师，kafka（v0.11.0.1）日志中有很多<br>WARN Attempting to send response via channel for which there is no open connection, connection id<br>的告警，发现ip都来自同一个集群（以kafka为数据源进行60s poll一次）\b<br>这个现象持续很久了，是什么原因呢<br><br>而且在这个现象前提下，有一天controller节点突然很多CLOSE_WAITE，打满了socket,然后kafka就挂了，这个需要调整什么参数呢","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":518669,"discussion_content":"增加下关闭连接的空闲时段阈值\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1619600158,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":285009,"user_name":"肖恒","can_delete":false,"product_type":"c1","uid":1861000,"ip_address":"","ucode":"50B1118691B222","user_header":"","comment_is_top":false,"comment_ctime":1616577897,"is_pvip":false,"replies":[{"id":"103529","content":"我的意思是以现有producer和consumer的代码实现，它hi无法观察到的","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1616721419,"ip_address":"","comment_id":285009,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1616577897","product_id":100029201,"comment_content":"值得注意的是，在第二种方式中，TCP 连接是在 Broker 端被关闭的，但其实这个 TCP 连接的发起方是客户端，因此在 TCP 看来，这属于被动关闭的场景，即 passive close。被动关闭的后果就是会产生大量的 CLOSE_WAIT 连接，因此 Producer 端或 Client 端没有机会显式地观测到此连接已被中断。<br><br>请教下 Producer 或 Client 端没有机会显示关闭到此连接如何理解？如何这么说，在 netty 中 server 端关闭连接，client 端也检测不到？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":517551,"discussion_content":"我的意思是以现有producer和consumer的代码实现，它hi无法观察到的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616721419,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":263969,"user_name":"Coding小先","can_delete":false,"product_type":"c1","uid":1051563,"ip_address":"","ucode":"965B1CC757E026","user_header":"https://static001.geekbang.org/account/avatar/00/10/0b/ab/0e2857e5.jpg","comment_is_top":false,"comment_ctime":1606305467,"is_pvip":false,"replies":[{"id":"95853","content":"topic leader副本在哪些broker上本身就是不固定的","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1606440225,"ip_address":"","comment_id":263969,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1606305467","product_id":100029201,"comment_content":"老师，像一些大的 Kafka 集群，可能我们生产者只需要发送某个 Topic，是否可以增加这么一个设计，让 Producer 只连接到目标 Topic 所在的 Broker 就可以了。","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":510370,"discussion_content":"topic leader副本在哪些broker上本身就是不固定的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606440225,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":261501,"user_name":"winston","can_delete":false,"product_type":"c1","uid":1061885,"ip_address":"","ucode":"1A39D7A6574B27","user_header":"https://static001.geekbang.org/account/avatar/00/10/33/fd/2bfd537d.jpg","comment_is_top":false,"comment_ctime":1605364609,"is_pvip":false,"replies":[{"id":"94899","content":"通常都是因为无法连接Broker导致的。看下broker的连接信息是否是正确以及可连接的","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1605422843,"ip_address":"","comment_id":261501,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1605364609","product_id":100029201,"comment_content":"请教一下大家，客户端send(test, data)后，报异常：java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.TimeoutException: Topic test not present in metadata after 60000 ms<br>服务端是允许自动创建topic的。这是什么原因导致的？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":509503,"discussion_content":"通常都是因为无法连接Broker导致的。看下broker的连接信息是否是正确以及可连接的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605422843,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":247368,"user_name":"后端进阶","can_delete":false,"product_type":"c1","uid":1125656,"ip_address":"","ucode":"480F48F5378307","user_header":"https://static001.geekbang.org/account/avatar/00/11/2d/18/918eaecf.jpg","comment_is_top":false,"comment_ctime":1599674056,"is_pvip":false,"replies":[{"id":"91190","content":"producer被多个线程共享，但update不会被调用多次。","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1600053660,"ip_address":"","comment_id":247368,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1599674056","product_id":100029201,"comment_content":"老师，假设此时 Producer 被多个线程共享，Metadata#update 方法是否会造成多次更新问题？<br>我的理解是：update方法是线程安全的，在一条线程更新完元数据后，后面的线程会拿着他们当前的元数据版本调用update，此时版本号不一样了，就会造成update方法内再次将needUpdate设置为true。","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":505379,"discussion_content":"producer被多个线程共享，但update不会被调用多次。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1600053660,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":243514,"user_name":"叶峥瑶","can_delete":false,"product_type":"c1","uid":1797584,"ip_address":"","ucode":"170E0F29BC6D4D","user_header":"","comment_is_top":false,"comment_ctime":1598164724,"is_pvip":false,"replies":[{"id":"89759","content":"broker不会找consumer。相反地，consumer会找broker的","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1598232046,"ip_address":"","comment_id":243514,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1598164724","product_id":100029201,"comment_content":"老师你好，请问下broker收到消息后到然后consumer消费消息，中间发生了什么，broker如何找到对应的consumer.的","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":504311,"discussion_content":"broker不会找consumer。相反地，consumer会找broker的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1598232046,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":243236,"user_name":"单朋荣","can_delete":false,"product_type":"c1","uid":1272662,"ip_address":"","ucode":"8AD121BEDD9675","user_header":"https://static001.geekbang.org/account/avatar/00/13/6b/56/37a4cea7.jpg","comment_is_top":false,"comment_ctime":1597999722,"is_pvip":false,"replies":[{"id":"89769","content":"producer其实只和真正需要连接的broker建立长久的TCP连接","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1598232906,"ip_address":"","comment_id":243236,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1597999722","product_id":100029201,"comment_content":"胡老师，对于“挑战“的问题：我觉得是不是默认建立所有与broker的连接再关闭空闲的，会比需要时再一个个建立连接，权衡下来效益要高些，所以社区才会保留这种做法。<br>另外，我有一个不明白的点哈，建立连接需要先从bootstrap.servers获取信息（一般少许几台就行），然后获得metadata。这样的话，producer端是不是知道了初次需要建立连接的broker信息，直接建立需要的连接就行，没有必要建立所有连接吗？？还是说，默认场景和这个场景是不同的啊？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":504233,"discussion_content":"producer其实只和真正需要连接的broker建立长久的TCP连接","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1598232906,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":242887,"user_name":"张三丰","can_delete":false,"product_type":"c1","uid":1155275,"ip_address":"","ucode":"3A6215A40B3B21","user_header":"https://static001.geekbang.org/account/avatar/00/11/a0/cb/aab3b3e7.jpg","comment_is_top":false,"comment_ctime":1597885951,"is_pvip":false,"replies":[{"id":"89612","content":"只是想说明连接保活，Kafka通过这个参数在应用层面做了软件保活。还有一种保活机制是通过TCP的keepalive机制。","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1597976497,"ip_address":"","comment_id":242887,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1597885951","product_id":100029201,"comment_content":"这句话是什么意思？连接关了还是没关？ 什么是软件层面的长连接？<br><br>用户可以在 Producer 端设置 connections.max.idle.ms=-1 禁掉这种机制。一旦被设置成 -1，TCP 连接将成为永久长连接。当然这只是软件层面的“长连接”机制，由于 Kafka 创建的这些 Socket 连接都开启了 keepalive，因此 keepalive 探活机制还是会遵守的。","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":504123,"discussion_content":"只是想说明连接保活，Kafka通过这个参数在应用层面做了软件保活。还有一种保活机制是通过TCP的keepalive机制。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1597976497,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":241459,"user_name":"火狼","can_delete":false,"product_type":"c1","uid":2046978,"ip_address":"","ucode":"37BDE583E64D8C","user_header":"https://static001.geekbang.org/account/avatar/00/1f/3c/02/b7c27217.jpg","comment_is_top":false,"comment_ctime":1597300754,"is_pvip":false,"replies":[{"id":"89376","content":"嗯，如果集群有几百台机器，bootstrap.servers就太长了，这么想的话，这个建议还是有可取之处吧：）","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1597628316,"ip_address":"","comment_id":241459,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1597300754","product_id":100029201,"comment_content":"KafkaProducer对象创建的时候，会和参数 bootstrap.servers上的各个Broker建立TCP链接，同时获取集群的元数据信息，之后跟新Producer端的元数据，并与集群中没有建立TCP连接的Broker建立连接。也就是说无论  bootstrap.servers 指定几个Broker节点，Producer 都会和集群上的所有节点建立连接，那么文章中提到的 不建议把集群中所有的 Broker 信息都配置到 bootstrap.servers 中，感觉这个建议意义不太大！","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":503743,"discussion_content":"嗯，如果集群有几百台机器，bootstrap.servers就太长了，这么想的话，这个建议还是有可取之处吧：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1597628316,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":240081,"user_name":"Gavin","can_delete":false,"product_type":"c1","uid":1616970,"ip_address":"","ucode":"A5735665E303FD","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/2UXuSevhia94o9Eky4OfMuSictaldxcqpjGuvRCOcvjIIoVBAENLEZbv2lgwmwC8icK1ZrUcneNtiaeFBV8MT3uzNg/132","comment_is_top":false,"comment_ctime":1596757617,"is_pvip":false,"replies":[{"id":"88655","content":"嗯，你说的没错。另外，本文并未探讨IO多路复用。仅仅是讨论为什么使用TCP连接时谈到了TCP的多路复用：）","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1596771700,"ip_address":"","comment_id":240081,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1596757617","product_id":100029201,"comment_content":"所谓的多路复用请求，即 multiplexing request，是指将两个或多个数据流合并到底层单一物理连接中的过程。TCP 的多路复用请求会在一条物理连接上创建若干个虚拟连接，每个虚拟连接负责流转各自对应的数据流。其实严格来说，TCP 并不能多路复用，它只是提供可靠的消息交付语义保证，比如自动重传丢失的报文<br><br>io多路复用，是指一个线程监听多个socket连接，而不是一个连接建多个虚拟连接吧","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":503333,"discussion_content":"嗯，你说的没错。另外，本文并未探讨IO多路复用。仅仅是讨论为什么使用TCP连接时谈到了TCP的多路复用：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1596771700,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":233383,"user_name":"勿更改任何信息","can_delete":false,"product_type":"c1","uid":2028956,"ip_address":"","ucode":"575185C69C05A3","user_header":"","comment_is_top":false,"comment_ctime":1594304274,"is_pvip":false,"replies":[{"id":"86307","content":"它不会发现，而是通过broker告诉它的。producer向老leader所在的broker发送请求，broker返回异常告知producer：我已经不是leader了","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1594469100,"ip_address":"","comment_id":233383,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1594304274","product_id":100029201,"comment_content":"老师，你好，请教个问题，producer定时从某个broker获取元数据，当某个分区的leader发生了切换，sender是怎么及使发现，和新broker建立连接的？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":501004,"discussion_content":"它不会发现，而是通过broker告诉它的。producer向老leader所在的broker发送请求，broker返回异常告知producer：我已经不是leader了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1594469100,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":229064,"user_name":"J.Smile","can_delete":false,"product_type":"c1","uid":1336475,"ip_address":"","ucode":"C4D98DFDBF7584","user_header":"https://static001.geekbang.org/account/avatar/00/14/64/9b/0b578b08.jpg","comment_is_top":false,"comment_ctime":1592890413,"is_pvip":false,"replies":[{"id":"84612","content":"你当前的open file limit设置了多少呢？ 另外你的Broker上的分区数大概是什么量级的。Kafka的确会打开很多文件，而且是分区数越多open file handler占用越多，不过一般调大一点这个都不会有太多问题 的","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1592966657,"ip_address":"","comment_id":229064,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1592890413","product_id":100029201,"comment_content":"broker端通过prometheus监控到openfiles一直很高且降不下去，应该从哪个角度去找原因呢","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":499320,"discussion_content":"你当前的open file limit设置了多少呢？ 另外你的Broker上的分区数大概是什么量级的。Kafka的确会打开很多文件，而且是分区数越多open file handler占用越多，不过一般调大一点这个都不会有太多问题 的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1592966657,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":217222,"user_name":"James","can_delete":false,"product_type":"c1","uid":1134861,"ip_address":"","ucode":"48B0F2A334D1C1","user_header":"https://static001.geekbang.org/account/avatar/00/11/51/0d/fc1652fe.jpg","comment_is_top":false,"comment_ctime":1589442765,"is_pvip":false,"replies":[{"id":"80314","content":"不会复用一个tcp连接到多个broker上","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1589457824,"ip_address":"","comment_id":217222,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1589442765","product_id":100029201,"comment_content":"请问更新元数据后,与某些broker没有连接,则创建一个tcp连接；<br>比如3个broker没连接，则会创建3个连接？只是创建一个tcp连接多路复用。","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":495084,"discussion_content":"不会复用一个tcp连接到多个broker上","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589457824,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":217200,"user_name":"James","can_delete":false,"product_type":"c1","uid":1134861,"ip_address":"","ucode":"48B0F2A334D1C1","user_header":"https://static001.geekbang.org/account/avatar/00/11/51/0d/fc1652fe.jpg","comment_is_top":false,"comment_ctime":1589439121,"is_pvip":false,"replies":[{"id":"80316","content":"大体上就是发送时候创建，只是获取元数据有时是先于发送事件的","user_name":"作者回复","user_name_real":"胡夕","uid":"1288090","ctime":1589458249,"ip_address":"","comment_id":217200,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1589439121","product_id":100029201,"comment_content":"感觉那个功能好尴尬，获取所有broker并创建连接，然后又因为设置最大存活时间又断开连接；<br>感觉应该发送的时候创建连接，第一次可能会慢点。","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":495075,"discussion_content":"大体上就是发送时候创建，只是获取元数据有时是先于发送事件的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1589458249,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":209850,"user_name":"燃点丶","can_delete":false,"product_type":"c1","uid":1106277,"ip_address":"","ucode":"01E91FB4287535","user_header":"https://static001.geekbang.org/account/avatar/00/10/e1/65/0dd1abf7.jpg","comment_is_top":false,"comment_ctime":1587625288,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1587625288","product_id":100029201,"comment_content":"何时创建 TCP 连接？<br>KafkaProducer 实例创建时启动 Sender 线程，从而创建与 bootstrap.servers 中所有 Broker 的 TCP 连接。<br>KafkaProducer 实例首次更新元数据信息之后，还会再次创建与集群中所有 Broker 的 TCP 连接。<br>如果 Producer 端发送消息到某台 Broker 时发现没有与该 Broker 的 TCP 连接，那么也会立即创建连接。<br>如果设置 Producer 端 connections.max.idle.ms 参数大于 0，则步骤 1 中创建的 TCP 连接会被自动关闭；如果设置该参数 =-1，那么步骤 1 中创建的 TCP 连接将无法被关闭，从而成为“僵尸”连接。<br><br>何时关闭 TCP 连接？<br>Producer 端关闭 TCP 连接的方式有两种：一种是用户主动关闭；一种是 Kafka 自动关闭。<br>第一种。这里的主动关闭实际上是广义的主动关闭，甚至包括用户调用 kill -9 主动“杀掉”Producer 应用。当然最推荐的方式还是调用 producer.close() 方法来关闭。<br>第二种是 Kafka 帮你关闭，这与 Producer 端参数 connections.max.idle.ms 的值有关。默认情况下该参数值是 9 分钟，即如果在 9 分钟内没有任何请求“流过”某个 TCP 连接，那么 Kafka 会主动帮你把该 TCP 连接关闭。用户可以在 Producer 端设置 connections.max.idle.ms=-1 禁掉这种机制。一旦被设置成 -1，TCP 连接将成为永久长连接。当然这只是软件层面的“长连接”机制，由于 Kafka 创建的这些 Socket 连接都开启了 keepalive，因此 keepalive 探活机制还是会遵守的。","like_count":0},{"had_liked":false,"id":205135,"user_name":"WhatAKitty","can_delete":false,"product_type":"c1","uid":1135707,"ip_address":"","ucode":"911C089450926B","user_header":"https://static001.geekbang.org/account/avatar/00/11/54/5b/1a14d829.jpg","comment_is_top":false,"comment_ctime":1586536361,"is_pvip":false,"replies":[{"id":"76726","content":"你的理解没有问题：）","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1586609678,"ip_address":"","comment_id":205135,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1586536361","product_id":100029201,"comment_content":"看了下最新版本的源码，貌似在初始化的时候，只是获取集群信息内ready状态的Leader节点（存在未知leader的节点则会强制更新metadata信息）；然后与获取到的ready状态的Leader节点们发送一次请求以此建立TCP连接。<br><br>```java<br>RecordAccumulator.ReadyCheckResult result = this.accumulator.ready(cluster, now);<br><br>        &#47;&#47; if there are any partitions whose leaders are not known yet, force metadata update<br>        if (!result.unknownLeaderTopics.isEmpty()) {<br>            &#47;&#47; The set of topics with unknown leader contains topics with leader election pending as well as<br>            &#47;&#47; topics which may have expired. Add the topic again to metadata to ensure it is included<br>            &#47;&#47; and request metadata update, since there are messages to send to the topic.<br>            for (String topic : result.unknownLeaderTopics)<br>                this.metadata.add(topic, now);<br><br>            log.debug(&quot;Requesting metadata update due to unknown leader topics from the batched records: {}&quot;,<br>                result.unknownLeaderTopics);<br>            this.metadata.requestUpdate();<br>        }<br><br>        &#47;&#47; remove any nodes we aren&#39;t ready to send to<br>        Iterator&lt;Node&gt; iter = result.readyNodes.iterator();<br>```<br><br>Kafka客户端版本：2.4.1<br><br>是我理解的存在问题吗？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":491400,"discussion_content":"你的理解没有问题：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586609678,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":194348,"user_name":"SunshineBoy","can_delete":false,"product_type":"c1","uid":1160644,"ip_address":"","ucode":"FC54CD1815CCBA","user_header":"https://static001.geekbang.org/account/avatar/00/11/b5/c4/9148b40d.jpg","comment_is_top":false,"comment_ctime":1585053142,"is_pvip":false,"replies":[{"id":"74064","content":"也不算无效吧，只能说上面没有请求处理。版本的影响是存在的，不排除各个版本之间是否有对连接做了什么修改，毕竟不算什么重大的功能改进。最好还是以实际试验结果为准","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1585096183,"ip_address":"","comment_id":194348,"utype":1}],"discussion_count":1,"race_medal":1,"score":"1585053142","product_id":100029201,"comment_content":"作者你好，假如peoducer指定了connections.max.idle.ms = -1,bootStrap.servers指定了所有broker地址信息（TCP连接的关闭和创建也是有开销的，因此很多时候我们想要禁掉自动关闭机制），<br>假如boker数量是N，那么producer启动后创建2*N个TCP连接，不会被关闭，其中N个TCP连接是有效的，N个TCP连接是无效的，不知道这种观点是否正确？还是和kafka版本有关？<br>    了社区的一些评论","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":488814,"discussion_content":"也不算无效吧，只能说上面没有请求处理。版本的影响是存在的，不排除各个版本之间是否有对连接做了什么修改，毕竟不算什么重大的功能改进。最好还是以实际试验结果为准","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1585096183,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":177449,"user_name":"Geek_383ffd","can_delete":false,"product_type":"c1","uid":1834097,"ip_address":"","ucode":"C3E15ED58CB6DB","user_header":"","comment_is_top":false,"comment_ctime":1581394728,"is_pvip":false,"replies":[{"id":"68978","content":"Kafka不用http而选择tcp并非是因为tcp是传输层协议，http是应用层协议，因此我是这么看的：我们说的都是对的，只是回应得不是一个层面上的问题：）","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1581472149,"ip_address":"","comment_id":177449,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1581394728","product_id":100029201,"comment_content":"对于为何采用TCP而不用Http的原因描述有点疑问：Http是应用层的协议，而tcp是传输控制协议，即便使用http底层发送还是会用到tcp的不是吗？所以这个原因描述是否需要更正一下。","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":483431,"discussion_content":"Kafka不用http而选择tcp并非是因为tcp是传输层协议，http是应用层协议，因此我是这么看的：我们说的都是对的，只是回应得不是一个层面上的问题：）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1581472149,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":174201,"user_name":"夏目-Steve","can_delete":false,"product_type":"c1","uid":1037560,"ip_address":"","ucode":"3B8B66A75FC596","user_header":"https://static001.geekbang.org/account/avatar/00/0f/d4/f8/6a368642.jpg","comment_is_top":false,"comment_ctime":1580082792,"is_pvip":false,"replies":[{"id":"67905","content":"Broker端和Client端都有这个参数。Broker端参数的默认值的确是10分钟，Client端的则不是。","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1580368378,"ip_address":"","comment_id":174201,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1580082792","product_id":100029201,"comment_content":"connections.max.idle.ms 这个参数想确认一下, 是不是默认值为 600000 毫秒","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":482332,"discussion_content":"Broker端和Client端都有这个参数。Broker端参数的默认值的确是10分钟，Client端的则不是。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1580368378,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":138560,"user_name":"worry","can_delete":false,"product_type":"c1","uid":1047773,"ip_address":"","ucode":"AF2BDAF6F6370E","user_header":"https://static001.geekbang.org/account/avatar/00/0f/fc/dd/0e17bf09.jpg","comment_is_top":false,"comment_ctime":1570335790,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1570335790","product_id":100029201,"comment_content":"我觉得在创建KafkaProducer时就通过Sender线程与某些Broker创建连接的主要目的是获取集群元数据，不一定会和集群的所有broker创建连接。发送消息时，如果和leader节点没有连接就会创建，发送完消息如果没有数据要发送，连接就会被关闭释放资源。","like_count":0},{"had_liked":false,"id":138461,"user_name":"未来小娃","can_delete":false,"product_type":"c1","uid":1047329,"ip_address":"","ucode":"477D166EBB6B70","user_header":"https://static001.geekbang.org/account/avatar/00/0f/fb/21/d017438c.jpg","comment_is_top":false,"comment_ctime":1570259666,"is_pvip":true,"discussion_count":1,"race_medal":0,"score":"1570259666","product_id":100029201,"comment_content":"Kafka强依赖zookeeper还是有很大风险的，之前公司就出现zookeeper被打挂的场景","like_count":0,"discussions":[{"author":{"id":1521451,"avatar":"https://static001.geekbang.org/account/avatar/00/17/37/2b/b32f1d66.jpg","nickname":"Ball","note":"","ucode":"1EE949E68D84CA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":128652,"discussion_content":"为啥被打挂了，Kafka 也不会一直往 zk 写数据吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1578657621,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":138420,"user_name":"林肯","can_delete":false,"product_type":"c1","uid":1008582,"ip_address":"","ucode":"D2C97220230DE5","user_header":"https://static001.geekbang.org/account/avatar/00/0f/63/c6/d6ea3df3.jpg","comment_is_top":false,"comment_ctime":1570228905,"is_pvip":false,"replies":[{"id":"53467","content":"bootstrap.servers设置的是连接Kafka的broker信息，和副本没有关系啊","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1570495510,"ip_address":"","comment_id":138420,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1570228905","product_id":100029201,"comment_content":"第二章有写到：生产者总是向领导者副本写消息；而消费者总是从领导者副本读消息。至于追随者副本，它只做一件事：向领导者副本发送请求，请求领导者把最新生产的消息发给它，这样它能保持与领导者的同步。如果bootstrap.servers 参数中没有设置领导者副本地址，那么就得追随者副本同步数据到领导者副本？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":469516,"discussion_content":"bootstrap.servers设置的是连接Kafka的broker信息，和副本没有关系啊","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570495510,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":137594,"user_name":"云师兄","can_delete":false,"product_type":"c1","uid":1010459,"ip_address":"","ucode":"4475AF1598FBFD","user_header":"https://static001.geekbang.org/account/avatar/00/0f/6b/1b/4b397b80.jpg","comment_is_top":false,"comment_ctime":1569803567,"is_pvip":false,"replies":[{"id":"53471","content":"因为是被动关闭，所以才有CLOSE_WAIT，和是否有传输量关系不大","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1570495635,"ip_address":"","comment_id":137594,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1569803567","product_id":100029201,"comment_content":"Kafka自动关闭连接，被动关闭的后果就是会产生大量的 CLOSE_WAIT 连接，当发起端被确认为空闲才会被被动关闭，理论数据传输量没有了，那为什么还有很多close wait？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":469167,"discussion_content":"因为是被动关闭，所以才有CLOSE_WAIT，和是否有传输量关系不大","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1570495635,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":128087,"user_name":"cgddw","can_delete":false,"product_type":"c1","uid":1316424,"ip_address":"","ucode":"621E250BC49C28","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLHKka9hn8hYyd7SD12PEYiazRKg2a5iaFibP7z13t9ARicUvbwItESpIYONxV6gHMFYTmdp4eGZ4YDsA/132","comment_is_top":false,"comment_ctime":1566829823,"is_pvip":false,"replies":[{"id":"47547","content":"其他语言管理TCP资源的方式和Java版本的不一定相同。可以参考一下github官网，看看是否已知的bug。另外也取决于是什么语言？","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1566869377,"ip_address":"","comment_id":128087,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1566829823","product_id":100029201,"comment_content":"针对第二种出现的大量无用链接，有什么好的解决办法吗？生产中发现，非java语音出现过这种大量链接占满了broker机器的连接数<br>","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":464789,"discussion_content":"其他语言管理TCP资源的方式和Java版本的不一定相同。可以参考一下github官网，看看是否已知的bug。另外也取决于是什么语言？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1566869377,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":125268,"user_name":"扬一场远远的风","can_delete":false,"product_type":"c1","uid":1357801,"ip_address":"","ucode":"AB47E3D2EAB8A8","user_header":"https://static001.geekbang.org/account/avatar/00/14/b7/e9/5400cdf3.jpg","comment_is_top":false,"comment_ctime":1566134809,"is_pvip":false,"replies":[{"id":"46039","content":"查看一下Broker id=2的broker进程是否启动吧，从日志上来说，follower无法连接到这个broker上的leader了<br>","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1566181530,"ip_address":"","comment_id":125268,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1566134809","product_id":100029201,"comment_content":"内容与2018年出版的那本kafka差不多。请教一个问题，线上环境（量比较大，每天的消息量能达到1T）,连续性报“java.io.IOException: Connection to 2 was disconnected before the response was read”。我贴一下报错信息：<br>2019-08-18 11:46:37,499] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=2] Error sending fetch request (sessionId=88469530, epoch=INITIAL) to node 2: java.io.IOException: Connection to 2 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)<br>......... t-0-logs-11=(offset=0, logStartOffset=0, maxBytes=1698029824), t0_pt_error-6=(offset=9999, logStartOffset=9999, maxBytes=1698029824), t0_pt_find_pid-5=(offset=4439, logStartOffset=4439, maxBytes=1698029824), t0_pt_extract_patient-15=(offset=18400, logStartOffset=18400, maxBytes=1698029824), __consumer_offsets-25=(offset=83, logStartOffset=0, maxBytes=1698029824), t0_qmjkda_extract_patient-9=(offset=877, logStartOffset=12, maxBytes=1698029824), t0_qmjkda_find_pid-5=(offset=5105, logStartOffset=5105, maxBytes=1698029824), t0_pt_find_pid-35=(offset=4321, logStartOffset=4321, maxBytes=1698029824), bigscreenRdData-18=(offset=1, logStartOffset=1, maxBytes=1698029824), t0_pt_etldr_mapping-4=(offset=16075, logStartOffset=16075, maxBytes=1698029824)}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=88469530, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)<br>java.io.IOException: Connection to 2 was disconnected before the response was read<br>\tat org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)<br>\tat kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:96)<br>\tat kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:223)<br>\tat kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:43)<br>\tat kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:146)<br>\tat kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)<br>\tat kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":463502,"discussion_content":"查看一下Broker id=2的broker进程是否启动吧，从日志上来说，follower无法连接到这个broker上的leader了\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1566181530,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1357801,"avatar":"https://static001.geekbang.org/account/avatar/00/14/b7/e9/5400cdf3.jpg","nickname":"扬一场远远的风","note":"","ucode":"AB47E3D2EAB8A8","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":5329,"discussion_content":"三个broker 是docker容器化布署，关掉任意两个broker另一个broker能正常生产和消费，进程没啥问题。之前num.replica.fetchers，num.io.threads，num.network.threads调大了有一段时间好了，后来又重复报这个错。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1566182550,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":117667,"user_name":"Johnson","can_delete":false,"product_type":"c1","uid":1060473,"ip_address":"","ucode":"FF29D9659284FD","user_header":"https://static001.geekbang.org/account/avatar/00/10/2e/79/05261bd7.jpg","comment_is_top":false,"comment_ctime":1564108277,"is_pvip":false,"replies":[{"id":"43215","content":"应该是不一样的","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1564213526,"ip_address":"","comment_id":117667,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1564108277","product_id":100029201,"comment_content":"请问老师，除了Java库之外，其他语言的library，比如librdkafka的prodcuer管理TCP连接的方式与Java库的方式是一样的吗？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":460078,"discussion_content":"应该是不一样的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1564213526,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":112229,"user_name":"赌神很低调","can_delete":false,"product_type":"c1","uid":1168545,"ip_address":"","ucode":"1066778E1EDF26","user_header":"https://static001.geekbang.org/account/avatar/00/11/d4/a1/8bc8e7e1.jpg","comment_is_top":false,"comment_ctime":1562687418,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1562687418","product_id":100029201,"comment_content":"“KafkaProducer 实例创建时启动 Sender 线程，从而创建与 bootstrap.servers 中所有 Broker 的 TCP 连接。”——我觉得这个完全可以弄成随机连接呀，如果一个连不通再随机连另一个，不是任何一个broker都有元数据缓存吗，随机连一个取得元数据不就可以了，为什么要全连呢？","like_count":0},{"had_liked":false,"id":110059,"user_name":"流浪的阳光","can_delete":false,"product_type":"c1","uid":1307137,"ip_address":"","ucode":"0E534F8EE3AA3B","user_header":"https://static001.geekbang.org/account/avatar/00/13/f2/01/b78add60.jpg","comment_is_top":false,"comment_ctime":1562162759,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1562162759","product_id":100029201,"comment_content":"老师、各位专家好，请问kafca适合做两个系统之间的转账处理吗？<br><br>另外，请问kafca的使用案例中，最多支持过什么数量级的消费者和生产者？","like_count":0},{"had_liked":false,"id":109719,"user_name":"rm -rf 😊ི","can_delete":false,"product_type":"c1","uid":1070908,"ip_address":"","ucode":"BC448EC4206D95","user_header":"https://static001.geekbang.org/account/avatar/00/10/57/3c/081b89ec.jpg","comment_is_top":false,"comment_ctime":1562081996,"is_pvip":false,"replies":[{"id":"39755","content":"1. 是这个意思<br>2. 我是想说consumer端也是这个原理。因此加上了clients","user_name":"作者回复","user_name_real":"huxi_2b","uid":"1288090","ctime":1562114212,"ip_address":"","comment_id":109719,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1562081996","product_id":100029201,"comment_content":"您好，老师，你说的第二种关闭producer的方法是一个被动关闭，发起方是客户端。<br>1. 这个客户端指的是producer客户端？所以broker此时会可能出现close wait，是这个意思吗？<br>2. 还有这句“因此 Producer 端或 Client 端没有机会显式地.”也不是很理解，producer端和client端不是一个意思吗？","like_count":0,"discussions":[{"author":{"id":1288090,"avatar":"https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg","nickname":"胡夕","note":"","ucode":"5709A689B6683B","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":456536,"discussion_content":"1. 是这个意思\n2. 我是想说consumer端也是这个原理。因此加上了clients","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1562114212,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]}]}