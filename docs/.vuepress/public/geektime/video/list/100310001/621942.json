{"id":621942,"title":"84｜计算资源充足时，如何通过并行设计提高效率？","content":"<p><strong>课后习题</strong><br>\n请使用并发任务模型同时访问 5 个网站，并将网页的数据存储到不同的文件中。</p><p><strong>课程代码、课件及其他相关资料地址</strong><br>\n<a href=\"https://gitee.com/wilsonyin/zero-basics-python\">https://gitee.com/wilsonyin/zero-basics-python</a></p>","comments":[{"had_liked":false,"id":373311,"user_name":"Zhaohong","can_delete":false,"product_type":"c3","uid":3294277,"ip_address":"北京","ucode":"9F3A64E33AF5A0","user_header":"https://static001.geekbang.org/account/avatar/00/32/44/45/d926f8fb.jpg","comment_is_top":false,"comment_ctime":1682387336,"is_pvip":false,"replies":[{"id":136566,"content":"max_workers 没有推荐的数值，因为线程的工作量不同，执行时间长短不同，还有最重要的CPU性能不同。都会导致设置的值不同。要根据实际需求来制定。\n\n例如我之前的工作中使用nginx作为web服务器提供网页服务，nginx就是典型的多进程多线程服务器。进程数量，往往和逻辑CPU数量相同，如果提供的是php网页，且网页多为简单页面和图片，可以将每个核心的线程数量设置为10个，每个线程轮流处理，且不会导致用户卡顿，当短视频业务兴起时，后端是短视频服务器，会减少线程数量，因为用户每次请求和响应时长增加了，业务“重”了， 这时会减少线程数量，让用户不觉得卡顿，也让服务器的CPU占用率低于80% 。 这就是基于不同业务逻辑进行线程数量设置的基本方法\n\n简单来说是一只蜘蛛有一张嘴和八条腿，如果每条腿都拿勺子吃饭，要考虑嘴的大小，勺子的大小，勺子里面的饭的多少，让蜘蛛吃饱又不闲着，让嘴里放得下，勺子也不空着","user_name":"作者回复","user_name_real":"编辑","uid":1056235,"ctime":1683185113,"ip_address":"广东","comment_id":373311,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100310001,"comment_content":"多线程函数中的max_workers参数应该怎么设置呢，越大越好吗","like_count":3,"discussions":[{"author":{"id":1056235,"avatar":"https://static001.geekbang.org/account/avatar/00/10/1d/eb/b2123759.jpg","nickname":"尹会生","note":"","ucode":"D1093DBD093617","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":616902,"discussion_content":"max_workers 没有推荐的数值，因为线程的工作量不同，执行时间长短不同，还有最重要的CPU性能不同。都会导致设置的值不同。要根据实际需求来制定。\n\n例如我之前的工作中使用nginx作为web服务器提供网页服务，nginx就是典型的多进程多线程服务器。进程数量，往往和逻辑CPU数量相同，如果提供的是php网页，且网页多为简单页面和图片，可以将每个核心的线程数量设置为10个，每个线程轮流处理，且不会导致用户卡顿，当短视频业务兴起时，后端是短视频服务器，会减少线程数量，因为用户每次请求和响应时长增加了，业务“重”了， 这时会减少线程数量，让用户不觉得卡顿，也让服务器的CPU占用率低于80% 。 这就是基于不同业务逻辑进行线程数量设置的基本方法\n\n简单来说是一只蜘蛛有一张嘴和八条腿，如果每条腿都拿勺子吃饭，要考虑嘴的大小，勺子的大小，勺子里面的饭的多少，让蜘蛛吃饱又不闲着，让嘴里放得下，勺子也不空着","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1683185114,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":372582,"user_name":"有点怀旧","can_delete":false,"product_type":"c3","uid":2727663,"ip_address":"河南","ucode":"C774EEF86D181B","user_header":"https://static001.geekbang.org/account/avatar/00/29/9e/ef/b5c9f52e.jpg","comment_is_top":false,"comment_ctime":1681301183,"is_pvip":false,"replies":[{"id":136570,"content":"首先，导入多线程的库，再实例化一个锁对象， 加锁，之后在不需要解决锁冲突的地方释放锁。具体代码如下：\nimport threading \nlock = threading.Lock() # 初始化一个锁对象\n\nfor i in range(1, 100):\n    lock.acquire() #申请锁\n    sum += 1\n    lock.release() #释放锁","user_name":"作者回复","user_name_real":"编辑","uid":1056235,"ctime":1683185479,"ip_address":"广东","comment_id":372582,"utype":1}],"discussion_count":1,"race_medal":0,"score":2,"product_id":100310001,"comment_content":"请问这个库如果需要使用公共变量加锁应该怎么使用","like_count":1,"discussions":[{"author":{"id":1056235,"avatar":"https://static001.geekbang.org/account/avatar/00/10/1d/eb/b2123759.jpg","nickname":"尹会生","note":"","ucode":"D1093DBD093617","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":616906,"discussion_content":"首先，导入多线程的库，再实例化一个锁对象， 加锁，之后在不需要解决锁冲突的地方释放锁。具体代码如下：\nimport threading \nlock = threading.Lock() # 初始化一个锁对象\n\nfor i in range(1, 100):\n    lock.acquire() #申请锁\n    sum += 1\n    lock.release() #释放锁","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1683185479,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"广东","group_id":0},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":386291,"user_name":"Guan YD","can_delete":false,"product_type":"c3","uid":2000972,"ip_address":"陕西","ucode":"76540F350800A9","user_header":"https://static001.geekbang.org/account/avatar/00/1e/88/4c/9a732f67.jpg","comment_is_top":false,"comment_ctime":1704446438,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100310001,"comment_content":"import concurrent.futures\nimport urllib.request\n\nURLS = [&#39;http:&#47;&#47;www.baidu.com&#39;,\n        &#39;http:&#47;&#47;www.taobao.com&#39;,\n        &#39;http:&#47;&#47;www.jd.com&#39;,\n        &#39;http:&#47;&#47;www.zhihu.com&#39;,\n        &#39;https:&#47;&#47;redis.io&#39;,\n        ]\n\n\ndef load_url(url, timeout):\n    with urllib.request.urlopen(url, timeout=timeout) as conn:\n        return conn.read()\n\n\nwith concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n    future_to_url = {executor.submit(load_url, url, 60): url for url in URLS}\n\n    for future in concurrent.futures.as_completed(future_to_url):\n        url = future_to_url[future]\n        try:\n            data = future.result().decode(&#39;utf-8&#39;)\n        except Exception as exc:\n            print(f&quot;大哥出问题了诶{url,exc}&quot;)\n        else:\n            with open(f&quot;.&#47;{urllib.parse.urlparse(url).netloc}.txt&quot;, mode=&#39;w&#39;) as f:\n                f.write(data)\n            print(f&quot;搞完了搞完了&quot;)","like_count":2},{"had_liked":false,"id":366612,"user_name":"Matthew","can_delete":false,"product_type":"c3","uid":2843865,"ip_address":"江苏","ucode":"96093089773740","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEKSVuNarJuDhBSvHY0giaq6yriceEBKiaKuc04wCYWOuso50noqDexaPJJibJN7PHwvcQppnzsDia1icZkw/132","comment_is_top":false,"comment_ctime":1673970433,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100310001,"comment_content":"import concurrent.futures\nimport urllib.request\nimport ssl\n\n# 定义关于 url 的字典，元素为：（网站名称：url）\nurl_records = {&#39;极客时间&#39;:&#39;https:&#47;&#47;time.geekbang.org&#47;&#39;,\n               &#39;百度&#39;:&#39;https:&#47;&#47;www.baidu.com&#39;,\n               &#39;京东&#39;:&#39;https:&#47;&#47;www.jd.com&#39;,\n               &#39;淘宝&#39;:&#39;https:&#47;&#47;www.taobao.com&#39;,\n               &#39;天猫&#39;:&#39;https:&#47;&#47;www.tmall.com&#39;\n              }\n\n# 定义方法，访问网址并读取首页内容\ndef load_url(url, timeout):\n    context = ssl._create_unverified_context()  # url是https形式\n    with urllib.request.urlopen(url, timeout=timeout, context=context) as conn:\n        return conn.read()\n\n# 通过线程池，并行执行，并将文件内容写入”网站名称.txt“的文件中\nwith concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n    \n    future_to_url = {executor.submit(load_url, url_record[1], 60): url_record for url_record in list(url_records.items())}\n    \n    for future in concurrent.futures.as_completed(future_to_url):\n        url_name = future_to_url[future][0]\n        url_path = future_to_url[future][1]\n        \n        try:\n            data = future.result().decode(&#39;utf-8&#39;)\n        except Exception as exc:\n            print(&#39;%r generated an exception: %s&#39; % (url_path, exc))\n        else:\n            print(&#39;%r page is %d bytes&#39; % (url_path, len(data)))           \n            with open(f&#39;{url_name}.txt&#39;, &#39;w&#39;) as f:\n                f.write(data)","like_count":1},{"had_liked":false,"id":394197,"user_name":"刘立嘉","can_delete":false,"product_type":"c3","uid":2414637,"ip_address":"上海","ucode":"1241140EBE7FE3","user_header":"https://static001.geekbang.org/account/avatar/00/24/d8/2d/4b0355f3.jpg","comment_is_top":false,"comment_ctime":1726112250,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100310001,"comment_content":"import concurrent.futures\nimport urllib.request\n\nURLS = [\n    &#39;http:&#47;&#47;www.baidu.com&#39;,\n    &#39;http:&#47;&#47;www.sohu.com&#39;,\n    &#39;https:&#47;&#47;www.jb51.net&#47;python&#47;325028lx3.htm&#39;,\n    &#39;https:&#47;&#47;blog.csdn.net&#47;jjb520&#47;article&#47;details&#47;137648331&#39;,\n    &#39;https:&#47;&#47;redis.io&#47;docs&#47;latest&#47;operate&#47;oss_and_stack&#47;install&#47;install-redis&#47;install-redis-on-windows&#47;&#39;,\n]\n\ndef load_url(url, timeout):\n    with urllib.request.urlopen(url, timeout=timeout) as conn:\n        return conn.read()\n\nwith concurrent.futures.ThreadPoolExecutor(max_workers=6) as executor:\n    future_to_url = {executor.submit(load_url, url, 60): url for url in URLS}\n    i = 0\n    for future in concurrent.futures.as_completed(future_to_url):\n        i += 1\n        url = future_to_url[future]\n        try:\n            data = future.result()\n        except Exception as exc:\n            print(&#39;%r generated an exception: %s&#39; % (url, exc))\n        else:\n            result = f&#39;{url} page is {len(data)} bytes&#39;\n            with open(f&#39;file_{i}.txt&#39;, &#39;w&#39;, encoding=&#39;utf-8&#39;) as f:\n                f.write(result)","like_count":0},{"had_liked":false,"id":385173,"user_name":"Geek_631607","can_delete":false,"product_type":"c3","uid":3789991,"ip_address":"广东","ucode":"EAF874838F0BE4","user_header":"","comment_is_top":false,"comment_ctime":1702262401,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100310001,"comment_content":"from concurrent.futures import ThreadPoolExecutor\n\nimport concurrent.futures\nimport requests\nimport urllib.parse\n\nURLS =[&#39;https:&#47;&#47;docs.python.org&#47;&#39;, &#39;https:&#47;&#47;www.baidu.com&#39;, &#39;https:&#47;&#47;requests.readthedocs.io&#47;&#39;, &#39;https:&#47;&#47;copilot.microsoft.com&#47;&#39;, &#39;https:&#47;&#47;dev.mysql.com&#47;&#39;, &#39;https:&#47;&#47;redis.io&#47;&#39;]\n\ndef load_url(url, timeout):\n    with requests.get(url, timeout=timeout) as conn:\n        return conn.content    \n\nwith concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n    future_to_url = {executor.submit(load_url, url, 60): url for url in URLS}\n\n    for future in concurrent.futures.as_completed(future_to_url):\n        url = future_to_url[future]\n        try:\n            data = future.result()\n        except BaseException as exc:\n            print(&quot;%r generated an exception: %s&quot; %(url, exec))\n        else:\n            print(&quot;%r page is %d bytes&quot;%(url, len(data)))\n            with open(f&quot;.&#47;84&#47;{urllib.parse.urlparse(url).netloc}.txt&quot;, mode=&#39;w&#39;) as f:\n                f.write(data.decode())","like_count":0},{"had_liked":false,"id":380238,"user_name":"Geek_Mike","can_delete":false,"product_type":"c3","uid":3196376,"ip_address":"云南","ucode":"CFA942192C3B74","user_header":"https://static001.geekbang.org/account/avatar/00/30/c5/d8/c5509b9c.jpg","comment_is_top":false,"comment_ctime":1693240548,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100310001,"comment_content":"#请使用并发任务模型同时访问 5 个网站，并将网页的数据存储到不同的文件中\nimport requests\nimport concurrent.futures as cfs\n\nurls = [&#39;http:&#47;&#47;www.baidu.com&#39;,\n        &#39;https:&#47;&#47;www.taobao.com&#39;,\n        &#39;https:&#47;&#47;www.jd.com&#39;,\n        &#39;https:&#47;&#47;www.tmall.com&#39;,\n        &#39;https:&#47;&#47;cn.bing.com&#39;]\n\ndef get_pages(url, timeout):\n    response = requests.get(url=url, timeout=timeout)\n    if response.status_code == 200:\n        return response.text\n    else:\n        return None\n\nwith cfs.ThreadPoolExecutor(max_workers=5) as exe:\n    futures_dict = {exe.submit(get_pages, url, 10): url for url in urls}  \n  \n    for future in cfs.as_completed(futures_dict):\n        url = futures_dict[future]\n        try:\n            data = future.result()\n        except Exception:\n            print(f&#39;{url}数据存储出现异常:{Exception}&#39;)\n        else:\n            file_path = &#39;.&#47;&#39; + url.split(&#39;&#47;&#39;)[-1] + &#39;.html&#39;\n            with open(file_path, &#39;w&#39;) as f:\n                f.write(data)\n                print(f&#39;{url}存储数据{len(data)}字节&#39;)","like_count":0},{"had_liked":false,"id":367127,"user_name":"Cy23","can_delete":false,"product_type":"c3","uid":1591293,"ip_address":"辽宁","ucode":"8DC561C5151758","user_header":"https://static001.geekbang.org/account/avatar/00/18/47/fd/895f0c27.jpg","comment_is_top":false,"comment_ctime":1674962362,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100310001,"comment_content":"借鉴学习了下其他同学的，自己写了下，\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\nimport urllib.request\n\nURLS = [\n  &#39;https:&#47;&#47;time.geekbang.org&#39;,\n  &#39;https:&#47;&#47;www.taobao.com&#47;&#39;,\n  &#39;https:&#47;&#47;www.jd.com&#39;,\n  &#39;https:&#47;&#47;leetcode.cn&#39;,\n  &#39;https:&#47;&#47;www.zhihu.com&#39;\n]\n\ndef load_url(url, timeout):\n  with urllib.request.urlopen(url, timeout=timeout) as conn:\n    return conn.read()\n\nwith ThreadPoolExecutor(max_workers=5) as executor:\n\n  future_to_url = {executor.submit(load_url, url, 60): url for url in URLS}\n\n  for i,future in enumerate(as_completed(future_to_url)):\n    url = future_to_url[future]\n    try:\n      data = future.result().decode(&#39;utf-8&#39;)\n    except Exception as exc:\n      print(&#39;%r generated an exception: %s&#39; % (url, exc))\n    else:\n      with open(f&#39;.&#47;84&#47;{i+1}.txt&#39;, &#39;a&#39;, encoding=&#39;utf-8&#39;) as f:\n        f.write(data)\n      print(&#39;%r page is saved&#39; % (url))","like_count":0},{"had_liked":false,"id":366180,"user_name":"PatrickL","can_delete":false,"product_type":"c3","uid":1341431,"ip_address":"上海","ucode":"EF0EC18639B9B2","user_header":"https://static001.geekbang.org/account/avatar/00/14/77/f7/11548247.jpg","comment_is_top":false,"comment_ctime":1673442333,"is_pvip":false,"replies":null,"discussion_count":0,"race_medal":0,"score":2,"product_id":100310001,"comment_content":"import urllib\nimport concurrent\nfrom lxml import etree\nimport os\n\nURLS = [&#39;https:&#47;&#47;time.geekbang.org&#39;,\n        &#39;https:&#47;&#47;www.csdn.net&#47;&#39;,\n        &#39;https:&#47;&#47;www.jd.com&#39;,\n        &#39;https:&#47;&#47;leetcode.cn&#39;,\n        &#39;https:&#47;&#47;www.zhihu.com&#39;]\n\ndef load_url(url, timeout):\n    with urllib.request.urlopen(url, timeout=timeout) as conn:\n        return conn.read()\n\nwith concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n    future_to_url = {executor.submit(load_url, url, 60): url for url in URLS}\n    for i,future in enumerate(concurrent.futures.as_completed(future_to_url)):\n        url = future_to_url[future]\n        try:\n            data = future.result().decode(&#39;utf-8&#39;)\n        except Exception as exc:\n            print(f&#39;{url} generated an exception:{exc}&#39;)\n        else:\n            rst = etree.HTML(data).xpath(&#39;&#47;&#47;head&#47;title&#47;text()&#39;)[0]\n            print(f&#39;The title of {url} page is &quot;{rst}&quot;.&#39;)\n            with open(f&#39;{i+1}.txt&#39;, &#39;w&#39;) as f:\n                f.write(rst)\n#         os.remove(f&#39;{i+1}.txt&#39;)","like_count":0}]}