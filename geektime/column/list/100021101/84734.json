{"id":84734,"title":"30 | 数据评估（上）：如何实现高可用的上报组件？","content":"<p>无论是“高效测试”中的实时监控，还是“版本发布”中的数据校验平台，我都多次提到了数据的重要性。</p><p>对于数据评估，我们的期望是“又快又准”。“快”，表示数据的时效性。我们希望在1小时内，甚至1分钟内就可以对数据进行评估，而不需要等上1天或者几天。“准”，表示数据的准确性，保证数据可以反映业务的真实情况，不会因为数据不准确导致做出错误的产品决策。</p><p>但是“巧妇难为无米之炊”，数据平台的准确性和时效性依赖客户端数据采集和上报的能力。那应该如何保证客户端上报组件的实时性和准确性？如何实现一个“高可用”的上报组件呢？</p><h2>统一高可用的上报组件</h2><p>可能有同学会疑惑，究竟什么是“高可用”的上报组件？我认为至少需要达到三个目标：</p><ul>\n<li>\n<p><strong>数据不会丢失</strong>。数据不会由于应用崩溃、被系统杀死这些异常情况而导致丢失。</p>\n</li>\n<li>\n<p><strong>实时性高</strong>。无论是前台进程还是后台进程，所有的数据都可以在短时间内及时上报。</p>\n</li>\n<li>\n<p><strong>高性能</strong>。这里主要有卡顿和流量两个维度，应用不能因为上报组件的CPU和I/O过度占用导致卡顿，也不能因为设计不合理导致用户的流量消耗过多。</p>\n</li>\n</ul><p>但是数据的完整性、实时性和性能就像天平的两端，我们无法同时把这三者都做到最好。因此我们只能在兼顾性能的同时，尽可能地保证数据不会丢失，让上报延迟更小。</p><!-- [[[read_end]]] --><p>在“网络优化”中，我不止一次的提到网络库的统一。网络库作为一个重要的基础组件，无论是应用内不同的业务，还是Android和iOS多端，都应该用同一个网络库。</p><p>同理，上报组件也是应用重要的基础组件，我们希望打造的是统一并且高可用的上报组件。</p><p><img src=\"https://static001.geekbang.org/resource/image/bf/9a/bf769e6e280ebeb1f8d16cbe95fe5e9a.png?wh=1326*766\" alt=\"\"></p><p>一个数据埋点的过程，主要包括采样、存储、上报以及容灾这四个模块，下面我来依次拆解各个模块，一起看看其中的难点。</p><p><img src=\"https://static001.geekbang.org/resource/image/19/83/1933f4cf48667805a18e07ec425ea783.png?wh=1920*848\" alt=\"\"></p><p><strong>1. 采样模块</strong></p><p>某些客户端数据量可能会非常大，我们并不需要将它们全部都上报到后台。比如说卡顿和内存这些性能数据，我们只需要抽取小部分用户统计就可以了。</p><p>采样模块是很多同学在设计时容易忽视的，但它却是所有模块中最为复杂的一项，需要考虑下面一些策略的选择。</p><p><img src=\"https://static001.geekbang.org/resource/image/61/70/6175884b6d62d6ad5b974baa6c723870.png?wh=1276*504\" alt=\"\"></p><p>大多数的组件采用的都是PV次数采样，这样的确是最简单的。但是我们更多是在性能数据埋点上采样，为了降低用户的影响面，我更加倾向于使用UV采样的方式。而且为了可以让更多的用户上报，我也希望每天都可以更换一批新的用户。</p><p>最终我选择的方案是“UV采样 + 用户标识随机 + 每日更换用户”的方式，但是采样还需要满足三个标准。</p><ul>\n<li>\n<p><strong>准确性</strong>。如果配置了1%的采样比例，需要保证某一时刻只有1%的用户会上报这个数据。</p>\n</li>\n<li>\n<p><strong>均匀性</strong>。如果配置了1%的采样比例，每天都会更换不同的1%用户来上报这个数据。</p>\n</li>\n<li>\n<p><strong>切换的平滑性</strong>。用户的切换需要平滑，不能在用一个时间例如12点，所有用户同时切换，这样会导致后台数据不连贯。</p>\n</li>\n</ul><p>实现上面这三个标准并不容易，在微信中我们采用了下面这个算法：</p><pre><code>// id：用户标识，例如微信号、QQ号\nid_index = Hash(id) % 采样率倒数\ntime_index = (unix_timestamp / (24*60*60)) % 采样率倒数\n上报用户 =（id_index == time_index）\n</code></pre><p>每个采样持续24小时，使整个切换可以很平滑，不会出现所有用户同时在0点更换采样策略。有些用户在早上10点切换，有些用户在11点切换，会分摊到24小时中。并且从一个小时或者一天的维度来看，也都可以保证采样是准确的。</p><p>不同的埋点可以设置不同的采样率，它们之间是独立的、互不影响的。当然除了采样率，在采样策略里我们还可以增加其他的控制参数，例如：</p><ul>\n<li>\n<p><strong>上报间隔</strong>：可以配置每个埋点的上报间隔，例如1秒、1分钟、10分钟、60分钟等。</p>\n</li>\n<li>\n<p><strong>上报网络</strong>：控制某些点只允许WiFi上传。</p>\n</li>\n</ul><p><strong>2. 存储模块</strong></p><p>对于存储模块，我们的目标是在兼顾性能的同时，保证数据完全不会丢失。那应该如何实现呢？我们首先要思考进程和存储模式的选择。</p><p><img src=\"https://static001.geekbang.org/resource/image/c2/56/c279b91e975100271abb804280ed2356.png?wh=1274*422\" alt=\"\"></p><p>业内最常见的上报组件是“单进程写 + 文件存储 + 内存缓存”，虽然这种方式实现最为简单，但是无论是跨进程的IPC调用堆积（IPC调用总是很慢的）还是内存缓存，都可能会导致数据的丢失。</p><p>回顾一下在“I/O优化”中，我列出的mmap、内存与写文件的性能对比数据。</p><p>​<img src=\"https://static001.geekbang.org/resource/image/a8/8e/a898e4578fe7724cc654fa9acb3cdf8e.png?wh=1286*308\" alt=\"\"></p><p>你可以看到mmap的性能非常不错，所以我们最终选择的是 <strong>“多进程写 + mmap”的方案，并且完全抛弃了内存缓存</strong>。不过mmap的性能也并不完美，它在某些时刻依然会出现异步落盘，所以每个进程mmap操作需要放到单独的线程中处理。</p><p><img src=\"https://static001.geekbang.org/resource/image/a8/87/a8dfe16bc5476e7e21b755e5a62d4c87.png?wh=1850*788\" alt=\"\"></p><p><strong>“多进程写 + mmap”的方案可以实现完全无锁、无IPC并且数据基本不会丢失</strong>，看上去简直完美，但是真正实现时是不是像图中那么简单呢？肯定不会那么简单，因为我们需要考虑埋点数据的聚合以及上报数据优先级。</p><ul>\n<li>\n<p><strong>埋点数据的聚合</strong>。为了减少上报的数据量，尤其是部分性能埋点，我们需要支持聚合上报。大部分组件都是使用上报时聚合的方式，但是这样无法解决存储时的数据量问题。由于我们使用的是mmap，可以像操作内存一样操作文件中的数据，可以实现性能更优的埋点数据的聚合功能。</p>\n</li>\n<li>\n<p><strong>上报数据优先级</strong>。很多上报组件埋点时都会使用一个是否重要的参数，对于重要的数据采用直接落地的方式。对于我们的方案来说，已经默认所有的数据都是重要的。关于上报数据的优先级，我建议使用上报间隔来区分，例如1分钟、10分钟或者1小时。</p>\n</li>\n</ul><p><img src=\"https://static001.geekbang.org/resource/image/74/88/747ab81587c7c5d0ceebe4e8763aad88.png?wh=1864*764\" alt=\"\"></p><p>对于一些敏感数据，可能还需要支持加密。对于加密的数据，我建议使用单独的另一个mmap文件存储。</p><p>为什么上面我说的是数据基本不会丢失，而不是完全不会丢失呢？因为当数据还没有mmap落盘，也就是处于采样、存储内部逻辑时，这个时候如果应用崩溃依然会造成数据丢失。为了减少这种情况发生，我们做了两个优化。</p><ul>\n<li>\n<p><strong>精简处理逻辑</strong>。尽量减少每个埋点的处理耗时，每个埋点的数据处理时间需要压缩到0.1毫秒以内。</p>\n</li>\n<li>\n<p><strong>KillProcess等待</strong>。在应用主动KillProcess之前，需要调用单独的函数，先等待所有队列中的埋点处理完毕。</p>\n</li>\n</ul><p><strong>3. 上报模块</strong></p><p>对于上报模块，我们不仅需要满足上报实时性，还需要合理地优化流量的使用，主要需要考虑的策略有：</p><p><img src=\"https://static001.geekbang.org/resource/image/5e/66/5e995f63ce97465825cdd0cfea669466.png?wh=1280*808\" alt=\"\"></p><p>为了解决后台进程的上报实时性问题，我们采用了单进程上报的策略，我推荐使用保活能力比较强的进程作为唯一的上报进程。为了更加精细地控制上报间隔，我们采用更加复杂的班车制度模式。</p><p>后来经过仔细思考，最终的上报模块采用“多进程写 + 单进程上报”。这里有一个难点，那就是如何及时的收集所有已经停止的班车，会不会出现多进程同步的问题呢？我们是通过Linux的文件rename的原子性以及FileObserver机制，实现了一套完全无锁、高性能的文件同步模型。</p><p><img src=\"https://static001.geekbang.org/resource/image/c6/cd/c67bb5cb84ecc577e00f13af3d6c9bcd.png?wh=1920*860?wh=1920*860\" alt=\"\"></p><p>每个进程在对应优先级的文件“停车”的时候，负责把文件rename到上报数据存放的目录中。因为rename是原子操作，所以不用担心两个进程会同时操作到同一个文件。而对应的上报进程只需要监听上报数据目录的变化，就可以实现文件状态的同步。这样就避免了多进程同步操作同一个文件的问题，整个过程也无需使用到跨进程的锁。</p><p>当然上报模块里的坑还有很多很多，例如合并上报文件时应该优先选择高优先级的文件；对于上报的包大小，在移动网络需要设置的比WiFi小一些，而不同优先级的文件需要合并组包，尽量吃满带宽；而且在弱网络的时候，我们需要把数据包设置得更小一些，先上报最高优先级的数据。</p><p><strong>4. 容灾模块</strong></p><p>虽然我们设计得上报模块已经很强大，但是如果使用者调用不合理，也可能会导致严重的性能问题。我曾经遇到过，某个同学在一个for循环连续埋了一百万个点；还有一次是某个用户因为长期没有网络，导致本地堆积了大量的数据。</p><p>一个强大的组件，它还需要具备容灾的能力，本地一般可以有下面这些策略。</p><p>​<img src=\"https://static001.geekbang.org/resource/image/f3/3e/f3aaa8e7762bba6c6b3a9f88faacf83e.png?wh=1262*508\" alt=\"\"></p><p>容灾模块主要是保证即使出现开发者使用错误、组件内部异常等情况，也不会给用户的存储空间以及流量造成严重问题。</p><h2>数据自监控</h2><p>通过“多进程写 + mmap + 后台进程上报 + 班车模式”，我们实现了一套完全无锁、数据基本不会丢失、无跨进程IPC调用的高性能上报组件，并且通过容灾机制，它还可以实现异常情况的自动恢复。</p><p>那线上效果是不是真的这么完美？我们怎样确保上报组件的数据可靠性和时效性呢？答案依然是<strong>监控</strong>，我们需要建立一套完善的自监控体系，为后续进一步优化提供可靠的数据支撑。</p><p><strong>1. 质量监控</strong></p><p>上报组件的核心数据指标主要包括以下几个：</p><p><img src=\"https://static001.geekbang.org/resource/image/9f/79/9f62e5c711224b8589bce6ec125ed279.png?wh=1284*554\" alt=\"\"></p><p>当然，如果我们追求更高的实时性，可以选择计算小时到达率，甚至是分钟到达率。</p><p><strong>2. 容灾监控</strong></p><p>当客户端出现容灾处理时，我们也会将数据单独上报到后台监控起来。</p><p><img src=\"https://static001.geekbang.org/resource/image/59/f9/59cc80a728e17cecd23b710c29bbfdf9.png?wh=1248*316\" alt=\"\"></p><p>除了异常情况的监控，我们还希望将用户每日使用的移动流量和WiFi流量做更加细粒度的分区间监控，例如0～1MB的占比、1～5MB的占比等。</p><h2>总结</h2><p>网络和数据都是非常重要的基础组件，今天我们一起打造了一款跨平台、高可用的上报组件。这也是目前比较先进的方案，在各方面的质量指标都比传统的方案有非常大的提升。</p><p><img src=\"https://static001.geekbang.org/resource/image/02/b4/022ec87c80a928d1fa536dcde99bb3b4.png?wh=1105*776\" alt=\"\"></p><p>当然真正落实到编码，这里面还有非常多的细节需要考虑，也还有大大小小很多暗坑。而且虽然我们使用C++实现，但是也还需要处理不同平台的些许差异，比如iOS根本不需要考虑多进程问题等。</p><p>在实践中我的体会是，当我们亲自动手去实现一个网络库或者上报组件的时候，才会深深体会到把一个新东西做出来并不困难，但是如果想要做到极致，那必然需要经过精雕细琢，更需要经过长时间的迭代和优化。</p><h2>课后作业</h2><p>你所在的公司，目前正在使用哪个数据上报组件？它存在哪些问题呢？欢迎留言跟我和其他同学一起讨论。</p><p><span class=\"orange\">今天的课后作业是，在实现方案中我故意隐去了两个细节点，这里把它们当作课后作业留给你，请你在留言中写下自己的答案。</span></p><p><strong>1. 采样策略的更新</strong>。当我们服务器采样策略更新的时候，如果不使用推送，怎样保证新的采样策略可以以最快速度在客户端生效？<br>\n<strong>2. 埋点进程突然崩溃</strong>。你有没有想到，如果Process A突然崩溃，那哪个进程、在什么时机、以哪种方式，应该负责把Process A对应的埋点数据及时rename到上报数据目录？</p><p><img src=\"https://static001.geekbang.org/resource/image/c6/cd/c67bb5cb84ecc577e00f13af3d6c9bcd.png?wh=1920*860?wh=1920*860\" alt=\"\"></p><p>欢迎你点击“请朋友读”，把今天的内容分享给好友，邀请他一起学习。最后别忘了在评论区提交今天的作业，我也为认真完成作业的同学准备了丰厚的“学习加油礼包”，期待与你一起切磋进步哦。</p><p></p>","comments":[{"had_liked":false,"id":73692,"user_name":"刘伟","can_delete":false,"product_type":"c1","uid":1317862,"ip_address":"","ucode":"B62EF9B5E0C8E1","user_header":"https://static001.geekbang.org/account/avatar/00/14/1b/e6/6a88c8a3.jpg","comment_is_top":false,"comment_ctime":1551959753,"is_pvip":false,"replies":[{"id":"31097","content":"👍，八九不离十，具体答案后面有公布","user_name":"作者回复","comment_id":73692,"uid":"1009577","ip_address":"","utype":1,"ctime":1555396665,"user_name_real":"张绍文"}],"discussion_count":1,"race_medal":0,"score":"27321763529","product_id":100021101,"comment_content":"1. 不使用推送，可以在每次上报的时候，把最新的策略作为响应返回给客户端，告诉客户端在什么时候改更新策略。<br><br>2.  可以让上报进程来做，上报进程通过FileObserver 来监听每个进程日志文件的更改时间，如果指定时间内没有变化，则可以立马上报该进程的文件。","like_count":6,"discussions":[{"author":{"id":1009577,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/67/a9/e251ace7.jpg","nickname":"张绍文","note":"","ucode":"94B49E5F80BFDE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":442226,"discussion_content":"👍，八九不离十，具体答案后面有公布","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1555396665,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":73809,"user_name":"CoderAndy","can_delete":false,"product_type":"c1","uid":1330506,"ip_address":"","ucode":"497112D94DE297","user_header":"https://static001.geekbang.org/account/avatar/00/14/4d/4a/e13779af.jpg","comment_is_top":false,"comment_ctime":1552006532,"is_pvip":false,"replies":[{"id":"26950","content":"已经修正了，感谢提醒","user_name":"作者回复","comment_id":73809,"uid":"1009577","ip_address":"","utype":1,"ctime":1552011018,"user_name_real":"张绍文"}],"discussion_count":1,"race_medal":0,"score":"18731875716","product_id":100021101,"comment_content":"采样模块的算法有问题吧<br>上报用户 =（id_index == id_index）？<br>应该是id_index==time_index吧","like_count":4,"discussions":[{"author":{"id":1009577,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/67/a9/e251ace7.jpg","nickname":"张绍文","note":"","ucode":"94B49E5F80BFDE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":442288,"discussion_content":"已经修正了，感谢提醒","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1552011018,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":73620,"user_name":"奚岩","can_delete":false,"product_type":"c1","uid":1107769,"ip_address":"","ucode":"E7D3A56216EE47","user_header":"https://static001.geekbang.org/account/avatar/00/10/e7/39/b47b1bc0.jpg","comment_is_top":false,"comment_ctime":1551942014,"is_pvip":false,"replies":[{"id":"28199","content":"1.策略更新，的确是最新上报带回。不过没有使用fileobserver，因为如果每个进程都加上他的代价有点大。用broadcast就可以<br>2. 这里是通过上报进程每隔一段时间监测+崩溃进程下次启动自检测，两个手段同时保证<br>","user_name":"作者回复","comment_id":73620,"uid":"1009577","ip_address":"","utype":1,"ctime":1552917482,"user_name_real":"张绍文"}],"discussion_count":1,"race_medal":0,"score":"14436843902","product_id":100021101,"comment_content":"对于采样策略的更新，可以在最新一次上报后带回，放入另一 FileObserver  中 ，Process A 获取使用；<br>对于 Process A 的崩溃，要主进程来上报么？","like_count":3,"discussions":[{"author":{"id":1009577,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/67/a9/e251ace7.jpg","nickname":"张绍文","note":"","ucode":"94B49E5F80BFDE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":442188,"discussion_content":"1.策略更新，的确是最新上报带回。不过没有使用fileobserver，因为如果每个进程都加上他的代价有点大。用broadcast就可以\n2. 这里是通过上报进程每隔一段时间监测+崩溃进程下次启动自检测，两个手段同时保证\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1552917482,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":73586,"user_name":"CatTalk","can_delete":false,"product_type":"c1","uid":1057350,"ip_address":"","ucode":"353780AF4848D9","user_header":"https://static001.geekbang.org/account/avatar/00/10/22/46/df595e4a.jpg","comment_is_top":false,"comment_ctime":1551932767,"is_pvip":true,"replies":[{"id":"30778","content":"的确跟平台很有所关系，但是核心还是靠个人","user_name":"作者回复","comment_id":73586,"uid":"1009577","ip_address":"","utype":1,"ctime":1555167925,"user_name_real":"张绍文"}],"discussion_count":2,"race_medal":0,"score":"10141867359","product_id":100021101,"comment_content":"我相信大多数产品都有基本的埋点上报功能，但是估计自己研发一套高可用的上报组件的公司不是很多。工作两年多，我一直思考这种功能只有加入大公司的技术团队才有机会去做，还是发挥自己的积极主动性就能做出来。（客观说）感觉中小心公司一直是业务业务...基础架构投入不大，够用就行。我的疑惑哈，希望同行们解惑。","like_count":2,"discussions":[{"author":{"id":1009577,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/67/a9/e251ace7.jpg","nickname":"张绍文","note":"","ucode":"94B49E5F80BFDE","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":442170,"discussion_content":"的确跟平台很有所关系，但是核心还是靠个人","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1555167925,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1330065,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/N0NACGUr8dNAbN6BdiagPHBaB0EnyDsI9zWpwJteqTY38apOEnTOA7JkBAQnzYKJBgxu3Q8YMUILwLAB6camn4w/132","nickname":"Swing","note":"","ucode":"55FCA9ECEFBBEB","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":230680,"discussion_content":"投入少的话，凑合用就行。。。我们那边就是 c/s模式来搞得。\n相对于楼主的方法，性能相对差了不少。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1586761818,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":347183,"user_name":"黑色毛衣","can_delete":false,"product_type":"c1","uid":1135912,"ip_address":"","ucode":"FF7E235F91BA5C","user_header":"https://static001.geekbang.org/account/avatar/00/11/55/28/31b0cf2f.jpg","comment_is_top":false,"comment_ctime":1653798445,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1653798445","product_id":100021101,"comment_content":"采样率倒数 是个啥？？","like_count":0},{"had_liked":false,"id":330440,"user_name":"DK[rock].dE","can_delete":false,"product_type":"c1","uid":1297392,"ip_address":"","ucode":"A744676A6FE048","user_header":"https://static001.geekbang.org/account/avatar/00/13/cb/f0/50537098.jpg","comment_is_top":false,"comment_ctime":1641978246,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1641978246","product_id":100021101,"comment_content":"“在应用主动 KillProcess 之前，需要调用单独的函数...” 这个在 Android 上怎么实现呢，是监听信号吗","like_count":0},{"had_liked":false,"id":293193,"user_name":"CoderAndy","can_delete":false,"product_type":"c1","uid":1330506,"ip_address":"","ucode":"497112D94DE297","user_header":"https://static001.geekbang.org/account/avatar/00/14/4d/4a/e13779af.jpg","comment_is_top":false,"comment_ctime":1621260228,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1621260228","product_id":100021101,"comment_content":"多进程+mmap，我想应该不是不同进程映射同一个文件吧？否则如果作同步处理，会造成数据被覆盖","like_count":0},{"had_liked":false,"id":278168,"user_name":"haizhiyun","can_delete":false,"product_type":"c1","uid":1441194,"ip_address":"","ucode":"8EC129CA457125","user_header":"https://static001.geekbang.org/account/avatar/00/15/fd/aa/3353a9b0.jpg","comment_is_top":false,"comment_ctime":1612783361,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1612783361","product_id":100021101,"comment_content":"<br>&#47;&#47; id：用户标识，例如微信号、QQ号<br>id_index = Hash(id) % 采样率倒数<br>time_index = (unix_timestamp &#47; (24*60*60)) % 采样率倒数<br>上报用户 =（id_index == time_index）<br>----<br>请问下这个有什么数学推导吗（还是有什么注意事项），尝试了下，随机选择一个用户，采样率10%，并不能在10天之内找到一次命中，计算出来的多半是浮点数，要相等很难，当采样率》50%的时候，应该最多经过两次计算就能命中，但是计算结果不是","like_count":0},{"had_liked":false,"id":243031,"user_name":"Bradley_Cai","can_delete":false,"product_type":"c1","uid":1112410,"ip_address":"","ucode":"05F155FA6D38EC","user_header":"https://static001.geekbang.org/account/avatar/00/10/f9/5a/cacd7642.jpg","comment_is_top":false,"comment_ctime":1597925240,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1597925240","product_id":100021101,"comment_content":"海外产品，埋点一直用的是 Firebase Analytics，一直用着挺好，最近一段数据的回传时间延迟很大，愈发感叹这种核心模块还是把握在自己手里最好，不然出了问题都不知道找谁","like_count":0}]}