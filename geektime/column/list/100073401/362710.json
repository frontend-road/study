{"id":362710,"title":"14 | CPU视角：如何高效地利用CPU？","content":"<p>你好，我是吴磊。</p><p>在日常的开发与调优工作中，总有同学向我抱怨：“为什么我的应用CPU利用率这么低？偌大的集群，CPU利用率才10%！”确实，较低的CPU利用率不仅对宝贵的硬件资源来说是一种非常大的浪费，也会让应用端到端的执行性能很难达到令人满意的效果。那么，在分布式应用开发中，我们到底该如何高效地利用CPU？</p><p>我们说过，性能调优的最终目的，是在<strong>所有参与计算的硬件资源之间寻求协同与平衡</strong>，让硬件资源达到一种平衡、无瓶颈的状态。对于CPU来说，最需要协同和平衡的硬件资源非内存莫属。原因主要有两方面：一方面，在处理延迟方面，只有内存能望其项背；另一方面，在主板上内存通过数据总线直接向CPU寄存器供给数据。因此，理顺它们之间的关系，可以为性能调优奠定更好的基础。</p><p>那么，今天这一讲，我们就从硬件资源平衡的角度入手，去分析CPU与内存到底该如何合作。</p><h2>CPU与内存的平衡本质上是什么？</h2><p>我们知道，Spark将内存分成了Execution Memory和Storage Memory两类，分别用于分布式任务执行和RDD缓存。其中，RDD缓存虽然最终占用的是Storage Memory，但在RDD展开（Unroll）之前，计算任务消耗的还是Execution Memory。<strong>因此，Spark中CPU与内存的平衡，其实就是CPU与执行内存之间的协同与配比。</strong></p><!-- [[[read_end]]] --><p>要想平衡CPU与执行内存之间的协同和配比，我们需要使用3类配置参数，它们分别控制着并行度、执行内存大小和集群的并行计算能力。只有它们设置得当，CPU和执行内存才能同时得到充分利用。否则CPU与执行内存之间的平衡就会被打破，要么CPU工作不饱和，要么OOM内存溢出。</p><p>想要知道这3类参数都包含哪些具体的配置项，以及它们到底是怎么配置的，我们需要先弄清楚一些基础知识，也就是并行计算的线程之间是如何瓜分执行内存的。为了帮助你理解，我先来给你讲个故事。</p><h2>黄小乙的如意算盘：并行计算的线程如何瓜分执行内存？</h2><p>还记得地主招租的故事吗？与张麻子签订占地协议之后，黄小乙就开始盘算，自己分得的那块田地怎么经营才最划算。</p><p>他心想：“这么一大块地，我亲自种肯定划不来。一，我没有张麻子勤快；二，不管是种棉花还是咖啡都很耗时、费力，面朝黄土背朝天，我可耽误不起那功夫！不如，我把土地转让出去，让别人来种，我只管收购、销售，赚到的差价也够我吃穿不愁了！”</p><p>于是，他打定主意，贴出了一张告示。</p><p><img src=\"https://static001.geekbang.org/resource/image/d2/11/d27f69b8aca76677700914873fce7911.jpg?wh=2000*1213\" alt=\"\" title=\"黄小乙的告示\"></p><p>告示贴出去不到三天，十里八村的人都赶来承让土地，他们大部分都是吃苦耐劳的庄稼汉，一心想凭借这次机会改善生活，所以每个人恨不能把500顷的田地全都承让过来。</p><p>黄小乙见状，心中大喜，认为不仅自己的土地很快就可以被种满，还能名正言顺地去抢占张麻子的那块地。不过，也不能光图规模，还要确保棉花、咖啡的产出质量，更重要的是得想个办法让这种运作模式可持续。</p><p>于是，黄小乙追加了一项补充条款：“鉴于老乡们参与热情高涨，公平起见，我又制定了新的土地转让规则：<strong>首先，每位老乡能够获得的土地面积有上下限，它的具体数值由可耕种土地总面积和申请人数共同决定；其次，土地转让权的有效时间与农作物生长周期一致，一旦作物丰收，承让人需让出土地，如有意愿再次耕种需重新申请。</strong>”</p><p><img src=\"https://static001.geekbang.org/resource/image/18/54/182c868dc11e99b6dyy4cd5536711b54.jpg?wh=4778*1210\" alt=\"\" title=\"土地转让规则\"></p><p>比如说，现阶段可耕种土地总面积已由500顷扩张为800顷（这是黄小乙就抢占了张麻子的地之后的土地总面积），如果有400位老乡申请土地转让权，那么每位老乡最高可得2顷（800/400）的土地，最低可得1顷（800/400/2）土地。也就是说，如果老乡人数为N，那么每位老乡能够获得的土地面积会在（1/N/2，1/N）之间浮动。</p><p>这个规定大伙儿都心服口服，没过多久，800顷土地就全部转让完了。一笔多赢的买卖让大伙都能各取所需，也让老谋深算的黄四郎都不禁心挑大指，感叹道“真是长江水后浪催前浪，一代新人换旧人！”</p><p>好啦，故事到这里暂时告一段落，但是黄小乙这份如意算盘和今天要讲的内容有什么关系呢？</p><p>我们讲过，黄小乙租赁的土地类比的是内存区域中的Execution Memory。<strong>在今天的故事里，黄小乙招募的棉农和咖啡农对应的就是，Executor线程池中一个又一个执行分布式任务的线程。土地出让规则对应的就是，任务并发过程中多个线程抢占内存资源时需要遵循的基本逻辑。</strong></p><p>那么，执行内存抢占规则就是，在同一个Executor中，当有多个（记为N）线程尝试抢占执行内存时，需要遵循2条基本原则：</p><ul>\n<li>执行内存总大小（记为M）为两部分之和，一部分是Execution Memory初始大小，另一部分是Storage Memory剩余空间</li>\n<li>每个线程分到的可用内存有一定的上下限，下限是M/N/2，上限是M/N，也就是均值</li>\n</ul><h2>三足鼎立：并行度、并发度与执行内存</h2><p>理清了线程与执行内存的关系之后，我们再来说说与并发度、执行内存和并行度这三者对应的3类配置项分别是什么，以及它们如何影响CPU与计算内存之间的平衡。</p><h3>3类配置项</h3><p>我们讲过，并行度指的是为了实现分布式计算，分布式数据集被划分出来的份数。<strong>并行度明确了数据划分的粒度：并行度越高，数据的粒度越细，数据分片越多，数据越分散。</strong></p><p>并行度可以通过两个参数来设置，<strong>分别是spark.default.parallelism和spark.sql.shuffle.partitions</strong>。前者用于设置RDD的默认并行度，后者在Spark SQL开发框架下，指定了Shuffle Reduce阶段默认的并行度。</p><p>那什么是并发度呢？我们在<a href=\"https://time.geekbang.org/column/article/357342\">配置项那一讲</a>提到过，Executor的线程池大小由参数spark.executor.cores决定，每个任务在执行期间需要消耗的线程数由spark.task.cpus配置项给定。两者相除得到的商就是并发度，也就是同一时间内，一个Executor内部可以同时运行的最大任务数量。又因为，spark.task.cpus默认数值为1，并且通常不需要调整，所以，<strong>并发度基本由spark.executor.cores参数敲定</strong>。</p><p>就Executor的线程池来说，尽管线程本身可以复用，但每个线程在同一时间只能计算一个任务，每个任务负责处理一个数据分片。因此，<strong>在运行时，线程、任务与分区是一一对应的关系</strong>。</p><p>分布式任务由Driver分发到Executor后，Executor将Task封装为TaskRunner，然后将其交给可回收缓存线程池（newCachedThreadPool）。线程池中的线程领取到TaskRunner之后，向Execution Memory申请内存，然后开始执行任务。</p><p>如果我们把棉农、咖啡农类比CPU线程，那么TaskRunner就可以理解为锄具，Task要处理的数据分片可以理解为作物种子。有了锄具和种子之后，老乡们得去黄小乙那儿申请块地，才能开始耕种。</p><p>最后，我们再来说说执行内存。黄小乙的地就是执行内存，堆内执行内存的初始值由很多参数共同决定，具体的计算公式是：spark.executor.memory * spark.memory.fraction * (1 - spark.memory.storageFraction)。相比之下，堆外执行内存的计算稍微简单一些：spark.memory.offHeap.size * (1 - spark.memory.storageFraction)。</p><p>除此之外，在统一内存管理模式下，在Storage Memory没有被RDD缓存占满的情况下，执行任务可以动态地抢占Storage Memory。因此，在计算可用于分配给执行任务的内存总量时，还要把有希望抢占过来的这部分内存空间考虑进来。这也是为什么黄小乙的可耕种土地总面积，会从最开始的500顷逐渐扩展到800顷。</p><p>由此可见，<strong>可分配的执行内存总量会随着缓存任务和执行任务的此消彼长，而动态变化。但无论怎么变，可用的执行内存总量，都不会低于配置项设定的初始值</strong>。</p><p>好啦，搞明白并行度、并发度和执行内存的概念，以及各自的配置项之后，我们再通过两个经常影响CPU利用率的例子，来说说它们是怎么影响CPU与计算内存之间的平衡的，由此总结出提升CPU利用率的办法。</p><h3>CPU低效原因之一：线程挂起</h3><p>在给定执行内存总量M和线程总数N的情况下，为了保证每个线程都有机会拿到适量的内存去处理数据，Spark用HashMap数据结构，以（Key，Value）的方式来记录每个线程消耗的内存大小，并确保所有的Value值都不超过M/N。在一些极端情况下，有些线程申请不到所需的内存空间，能拿到的内存合计还不到M/N/2。这个时候，Spark就会把线程挂起，直到其他线程释放了足够的内存空间为止。</p><p>你可能会问：“既然每个线程能拿到的内存上限是M/N，也就是内存总量对线程数取平均值，为什么还会出现有的线程连M/N/2都拿不到呢？这在数学上也不成立呀！”这是个好问题。这种情况的出现，源于3方面的变化和作用：</p><ul>\n<li><strong>动态变化的执行内存总量M</strong></li>\n<li><strong>动态变化的并发度N~</strong></li>\n<li><strong>分布式数据集的数据分布</strong></li>\n</ul><p>首先，动态变化的执行内存总量M我们刚刚已经说过了。M的下限是Execution Memory初始值，上限是spark.executor.memory * spark.memory.fraction划定的所有内存区域。在应用刚刚开始执行的时候，M的取值就是这个上限，但随着RDD缓存逐渐填充Storage Memory，M的取值也会跟着回撤。</p><p>另外，到目前为止，（1/N/2，1/N）上下限的计算我们用的都是线程总数N，线程总数N是固定的。N的取值含义是一个Executor内最大的并发度，更严格的计算公式是spark.executor.cores除以spark.task.cpus。但实际上，上下限公式的计算用的不是N，而是N~。N~的含义是Executor内当前的并发度，也就是Executor中当前并行执行的任务数。显然N~ &lt;= N。</p><p>换句话说，尽管一个Executor中有N个CPU线程，但这N个线程不一定都在干活。在Spark任务调度的过程中，这N个线程不见得能同时拿到分布式任务，所以先拿到任务的线程就有机会申请到更多的内存。在某些极端的情况下，后拿到任务的线程甚至连一寸内存都申请不到。不过，随着任务执行和任务调度的推进，N~会迅速地趋近于N，CPU线程挂起和内存分配的情况也会逐渐得到改善。</p><p>就像黄小乙的补充条款中举的那个例子一样，当可耕种土地总面积为800顷的时候，如果有400位老乡申请土地转让权，那么每位老乡最多可得800/400=2顷土地，最低可得800/400/2=1顷土地。</p><p>但如果这400位老乡不是同时来的，而是分两批来的，每批来200人的话，就会出现问题。按照他的规则，先来的这200位老乡，每人最多可得800/200 = 4顷土地。咱们前面说了，每个申请的老乡都想通过这次机会发点小财，于是这200位老乡每人都申请了4顷地，黄小乙的地一下子就被分光了！后来的200位老乡就没地可种了，他们只能等到第一批老乡的棉花和咖啡丰收了，再重新一起申请土地转让权。</p><p>假设第一批老乡同时大丰收，按照黄小乙转让规则的第一条，第一批老乡要交出土地使用权，如果想要继续耕种的话，就得和第二批老乡一起重新申请。在这种情况下，上下限的计算才是黄小乙最开始举例的那种算法。</p><p>第三个影响任务并发度和内存分配的因素，是分布式数据集的分布情况。在刚才的例子中，如果第一批老乡每人只申请2顷土地，那么第二批老乡来了之后依然有地可种。每人申请多大的土地，取决于他手里有多少农作物种子，我们之前把每个Task需要处理的数据分片比作是作物种子，那么，数据分片的数据量决定了执行任务需要申请多少内存。<strong>如果分布式数据集的并行度设置得当，因任务调度滞后而导致的线程挂起问题就会得到缓解</strong>。</p><h3>CPU低效原因之二：调度开销</h3><p>线程挂起的问题得到缓解，CPU利用率就会有所改善。既然如此，是不是把并行度设置到最大，每个数据分片就都能足够小，小到每个CPU线程都能申请到内存，线程不再挂起就万事大吉了呢？</p><p>当然不是，并行度足够大，确实会让数据分片更分散、数据粒度更细，因此，每个执行任务所需消耗的内存更少。<strong>但是，数据过于分散会带来严重的副作用：调度开销骤增。</strong></p><p>对于每一个分布式任务，Dirver会将其封装为TaskDescription，然后分发给各个Executor。TaskDescription包含着与任务运行有关的所有信息，如任务ID、尝试ID、要处理的数据分片ID、开发者添加的本地文件和Jar包、任务属性、序列化的任务代码等等。Executor接收到TaskDescription之后，首先需要对TaskDescription反序列化才能读取任务信息，然后将任务代码再反序列化得到可执行代码，最后再结合其他任务信息创建TaskRunner。</p><p>因此你看，每个任务的调度与执行都需要Executor消耗CPU去执行上述一系列的操作步骤。数据分片与线程、执行任务一一对应，<strong>当数据过于分散，分布式任务数量会大幅增加，但每个任务需要处理的数据量却少之又少，就CPU消耗来说，相比花在数据处理上的比例，任务调度上的开销几乎与之分庭抗礼</strong>。显然，在这种情况下，CPU的有效利用率也是极低的。</p><h3>如何优化CPU利用率？</h3><p>你可能会说：“这也太尴尬了，并行度低了不行，容易让CPU线程挂起；高了也不行，调度开销太大，CPU有效利用率也不高。高也不行、低也不行，那我该怎么办呢？”</p><p>咱们不妨来算笔账。我们还是拿黄小乙的如意算盘来举例，如果400个老乡同时来申请他的800顷地，那么每个老乡能分到1到2顷土地不等。相应地，每位老乡需要购买的种子应该刚好够种满1到2顷地。因为，买多了种不下，买少了还亏。假设洼子村农产品交易市场的种子总量刚好够种1000顷地，从卖家的视角出发，这些种子应该售卖1000/2 =500到1000/1 = 1000次，才能赚到最多的钱。</p><p>因此，在给定Executor线程池和执行内存大小的时候，我们可以参考上面的算法，<strong>去计算一个能够让数据分片平均大小在（M/N/2, M/N）之间的并行度，这往往是个不错的选择</strong>。</p><p>总的来说，对CPU利用率来说，并行度、并发度与执行内存的关系就好像是一尊盛满沸水的三足鼎，三足齐平则万事大吉，但凡哪一方瘸腿儿，鼎内的沸水就会倾出伤及无辜。</p><p><img src=\"https://static001.geekbang.org/resource/image/4a/ce/4a5dc54813346924ec5611f6d1fa8fce.jpg?wh=4101*1043\" alt=\"\" title=\"三足鼎立\"></p><h2>小结</h2><p>今天这一讲，我们从CPU与执行内存平衡的角度，通过梳理Executor并行度、并发度和执行内存之间的关系，以及它们对CPU利用率的影响，总结出了有效提升CPU利用率的方法。</p><p>首先，在一个Executor中，每个CPU线程能够申请到的内存比例是有上下限的，最高不超过1/N，最低不少于1/N/2，其中N代表线程池大小。</p><p>其次，在给定线程池大小和执行内存的时候，并行度较低、数据分片较大容易导致CPU线程挂起，线程频繁挂起不利于提升CPU利用率，而并行度过高、数据过于分散会让调度开销更显著，也不利于提升CPU利用率。</p><p>最后，在给定执行内存M、线程池大小N和数据总量D的时候，想要有效地提升CPU利用率，我们就要计算出最佳并行度P，计算方法是让数据分片的平均大小D/P坐落在（M/N/2, M/N）区间。这样，在运行时，我们的CPU利用率往往不会太差。</p><h2>每日一练</h2><ol>\n<li>从Executor并发度、执行内存大小和分布式任务并行度出发，你认为在什么情况下会出现OOM的问题？</li>\n<li>由于执行内存总量M是动态变化的，并发任务数N~也是动态变化的，因此每个线程申请内存的上下限也是动态调整的，你知道这个调整周期以什么为准？</li>\n</ol><p>期待在留言区看到你的思考和答案，如果你的朋友也在为提高CPU利用率苦恼，欢迎你把这一讲转发给他，我们下一讲见！</p>","comments":[{"had_liked":false,"id":288582,"user_name":"Geek_d794f8","can_delete":false,"product_type":"c1","uid":2485585,"ip_address":"","ucode":"1E20DA4FF8B800","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIiaeebUYxl7e4jicPshDRKMbiculHUjKgZZ2ygDibn2S7bbsjeqYIdsEUdVyoryKNa43ZGnDQmWjv3ibQ/132","comment_is_top":false,"comment_ctime":1618551187,"is_pvip":false,"replies":[{"id":"104749","content":"都需要考虑，结合你这个例子，整体逻辑是这样的。<br><br>首先，Spark读取分布式文件，获取数据源，这个时候，并行度就是文件在分布式文件系统上的并行度，比如HDFS、比如S3。HDFS的分片可能是128M或是256M，那么它的并行度，就取决于文件总大小和分片大小的商。<br><br>这个时候，由于分片大小是固定的，你可以结合分片大小，去设置执行内存和并发度（executor线程池），让他们满足（1&#47;N&#47;2，1&#47;N）的关系。<br><br>然后，你设置的spark.sql.shuffle.partitions，会控制Joins之中的Shuffle Reduce阶段并行度，这个参数设置多少。其实取决于你Shuffle过后每个Reduce Task需要处理的数据分片大小。由于你之前是按照128M或是256M来设置的执行内存， 和并发度。这个时候，在设置spark.sql.shuffle.partitions这个值的时候，只要保证数据分片大小还是在128M或是256M左右（shuffle前可能有过滤、过程中还会有聚合，所以原来的并行度就不合适了），就依然能维持“三足鼎立”的计算平衡。<br><br>所以说，核心是维持这个平衡。在你这个case，核心思路是，根据“定下来的”，去调整“未定下来的”，就可以去设置每一个参数了。<br><br>在最开始，“定下来的”是并行度，因为这个是文件系统决定的，但是执行内存和并发度未定，所以你可以相应地去调整这两类参数。<br><br>后面Shuffle的时候，执行内存和并发度已经定下来了，但是spark.sql.shuffle.partitions未定，你再结合那个公式，去定这个参数的值就好了。思路就是这么个思路，其实还是万变不离其宗。","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1618566432,"ip_address":"","comment_id":288582,"utype":1}],"discussion_count":6,"race_medal":0,"score":"96107831699","product_id":100073401,"comment_content":"老师，在考虑并行度,内存,线程数三者之间的平衡时，spark.sql.shuffle.partitions的值是shuffle的reducer阶段的并行度，那么对于从数据源读取(比如读hive表)这个起始的map阶段的并行度是否需要考虑？这个阶段spark底层有某种默认的切片规则吗，需要在代码中人为的干预吗(比如coalesce)？ 我使用的是DataFrame和DataSet的api。","like_count":23,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":518671,"discussion_content":"都需要考虑，结合你这个例子，整体逻辑是这样的。\n\n首先，Spark读取分布式文件，获取数据源，这个时候，并行度就是文件在分布式文件系统上的并行度，比如HDFS、比如S3。HDFS的分片可能是128M或是256M，那么它的并行度，就取决于文件总大小和分片大小的商。\n\n这个时候，由于分片大小是固定的，你可以结合分片大小，去设置执行内存和并发度（executor线程池），让他们满足（1/N/2，1/N）的关系。\n\n然后，你设置的spark.sql.shuffle.partitions，会控制Joins之中的Shuffle Reduce阶段并行度，这个参数设置多少。其实取决于你Shuffle过后每个Reduce Task需要处理的数据分片大小。由于你之前是按照128M或是256M来设置的执行内存， 和并发度。这个时候，在设置spark.sql.shuffle.partitions这个值的时候，只要保证数据分片大小还是在128M或是256M左右（shuffle前可能有过滤、过程中还会有聚合，所以原来的并行度就不合适了），就依然能维持“三足鼎立”的计算平衡。\n\n所以说，核心是维持这个平衡。在你这个case，核心思路是，根据“定下来的”，去调整“未定下来的”，就可以去设置每一个参数了。\n\n在最开始，“定下来的”是并行度，因为这个是文件系统决定的，但是执行内存和并发度未定，所以你可以相应地去调整这两类参数。\n\n后面Shuffle的时候，执行内存和并发度已经定下来了，但是spark.sql.shuffle.partitions未定，你再结合那个公式，去定这个参数的值就好了。思路就是这么个思路，其实还是万变不离其宗。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618566432,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1199213,"avatar":"https://static001.geekbang.org/account/avatar/00/12/4c/6d/c20f2d5a.jpg","nickname":"LJK","note":"","ucode":"12B2441099FF1D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":391918,"discussion_content":"ShufflePartitions的配置是静态的，运行过程中数据量是动态变化的，这种情况下如何能设置一个好的ShufflePartitions呢？","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1630705339,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1813026,"avatar":"https://wx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJO944A1HeBCrewW7YHE1Ha3OVWDEz8iaXwD23iczWrG9eG6deJ0dK5qD1qJuLB0u7LnU4ujtokvjAg/132","nickname":"keeprun","note":"","ucode":"0D1FBBB98567D0","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":412736,"discussion_content":"读取文件的分区数还与文件个数相关，切割文件时不会跨文件。建议看下textFile对应的源码:getSplit。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1636274402,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1789481,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/4e/29/adcb78e7.jpg","nickname":"静心","note":"","ucode":"B80DE4B5C923D3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":403480,"discussion_content":"hdfs分片放置在内存，会膨胀！这怎么来调参数呢？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1634088801,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":2828185,"avatar":"","nickname":"Geek_73cee2","note":"","ucode":"54848FF6BE74B1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1789481,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/4e/29/adcb78e7.jpg","nickname":"静心","note":"","ucode":"B80DE4B5C923D3","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":575590,"discussion_content":"你直接看膨胀之后的大小不就行了  主要还是因为你存储的时候数据压缩或者格式问题 加载到内存就不一样了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1654942669,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":403480,"ip_address":""},"score":575590,"extra":""}]},{"author":{"id":1549032,"avatar":"","nickname":"Zzz","note":"","ucode":"9323254354868B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":394504,"discussion_content":"有点过于理论化，实际真的是这样调整过？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631926421,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":288772,"user_name":"zxk","can_delete":false,"product_type":"c1","uid":1221195,"ip_address":"","ucode":"4BB2BD9D2BCD04","user_header":"https://static001.geekbang.org/account/avatar/00/12/a2/4b/b72f724f.jpg","comment_is_top":false,"comment_ctime":1618664736,"is_pvip":false,"replies":[{"id":"104856","content":"没问题，满分💯 ~","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1618760635,"ip_address":"","comment_id":288772,"utype":1}],"discussion_count":3,"race_medal":0,"score":"57453239584","product_id":100073401,"comment_content":"问题一：并发度决定了数据分片的大小：<br>- 在每个线程都分配到了最大内存，即 M&#47;N 的内存时，如果 task 还需要更多的内存，那么就会发生 OOM。<br>- 在每个线程都分配到了最少内存，即 M&#47;2N的内存时，如果 task 还需要更多的内存，此时又没有其他线程释放内存供其使用，那么也会导致OOM。","like_count":14,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":518733,"discussion_content":"没问题，满分💯 ~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618760635,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1233398,"avatar":"https://static001.geekbang.org/account/avatar/00/12/d1/f6/d75afb79.jpg","nickname":"在路上","note":"","ucode":"F4CEB45076F9B8","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":535504,"discussion_content":"并发度决定数据分片大小没看懂，不是并行度决定数据分片大小么","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1638455574,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":2955154,"avatar":"https://static001.geekbang.org/account/avatar/00/2d/17/92/0af520ef.jpg","nickname":"十月","note":"","ucode":"95877CD3753595","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1233398,"avatar":"https://static001.geekbang.org/account/avatar/00/12/d1/f6/d75afb79.jpg","nickname":"在路上","note":"","ucode":"F4CEB45076F9B8","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":570803,"discussion_content":"因为并发度决定每个线程最多可使用的内存大小，从而影响每个分片可使用的内存大小","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1651914541,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":535504,"ip_address":""},"score":570803,"extra":""}]}]},{"had_liked":false,"id":288299,"user_name":"qconljk","can_delete":false,"product_type":"c1","uid":1005711,"ip_address":"","ucode":"E382B3C9041BB6","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIibtTdDicknUHXgxmEAs8ib88kGhcjOzeHo5GBs6RfFHjGypRicKYcMPFZ5dm5edlpqALoibPK90icuwwQ/132","comment_is_top":false,"comment_ctime":1618399583,"is_pvip":false,"replies":[{"id":"104700","content":"好问题，其实没有什么特别的含义，就是一种公平机制，就是保证至少有均值的1&#47;2可以满足，否则就不进行计算。<br><br>其实你说把它改成3成不成，我觉得也没什么不可以。但是，改成3之后，task最低内存保障更低了，即便你有1&#47;3给它，它也完不成计算，其实还是得挂起。<br><br>1&#47;2的保底，其实更make sense，因为1&#47;2的内存相比均值来说，只差了一半，这样有些任务你先分配了1&#47;2，运行的过程中，其他task还会释放内存，这个时候，这个task还是可以成功执行的。但如果是1&#47;3，你亏空的内存更多，需要等待的概率越大，挂起的概率也就越大。","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1618487218,"ip_address":"","comment_id":288299,"utype":1}],"discussion_count":4,"race_medal":0,"score":"35978137951","product_id":100073401,"comment_content":"首先，在一个 Executor 中，每个 CPU 线程能够申请到的内存比例是有上下限的，最高不超过 1&#47;N，最低不少于 1&#47;N&#47;2，其中 N 代表线程池大小。这个除以2，2代表什么？","like_count":8,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":518579,"discussion_content":"好问题，其实没有什么特别的含义，就是一种公平机制，就是保证至少有均值的1/2可以满足，否则就不进行计算。\n\n其实你说把它改成3成不成，我觉得也没什么不可以。但是，改成3之后，task最低内存保障更低了，即便你有1/3给它，它也完不成计算，其实还是得挂起。\n\n1/2的保底，其实更make sense，因为1/2的内存相比均值来说，只差了一半，这样有些任务你先分配了1/2，运行的过程中，其他task还会释放内存，这个时候，这个task还是可以成功执行的。但如果是1/3，你亏空的内存更多，需要等待的概率越大，挂起的概率也就越大。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618487218,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":367861,"discussion_content":"着急打字，没说完，再者，如果是1/3，OOM的几率也更大。因为相当于对于任务请求来说，你是宽进严出，就是只要有1/3，你就接受task请求，结果人家需要的内存空间，你根本满足不了，task跑到一半，需要更多内存，但是其他task又没有释放额外的内存，这个时候，要么挂起、要么OOM。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618487391,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1789481,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/4e/29/adcb78e7.jpg","nickname":"静心","note":"","ucode":"B80DE4B5C923D3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":404612,"discussion_content":"老师，您说的这种情况，到底是挂起还是会oom阿？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1634357364,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":367861,"ip_address":""},"score":404612,"extra":""}]},{"author":{"id":1271157,"avatar":"https://static001.geekbang.org/account/avatar/00/13/65/75/f9d7e8b7.jpg","nickname":"L3nvy","note":"","ucode":"0B74B27C121D56","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":367732,"discussion_content":"疑问加一！！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618452536,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":288188,"user_name":"斯盖丸","can_delete":false,"product_type":"c1","uid":1168504,"ip_address":"","ucode":"B881D14B028F14","user_header":"https://static001.geekbang.org/account/avatar/00/11/d4/78/66b3f2a2.jpg","comment_is_top":false,"comment_ctime":1618355050,"is_pvip":false,"replies":[{"id":"104645","content":"Spark UI有专门的配置页，记录了不同配置项的设置值，其中有默认并行度设置。<br><br>但重点不在这，重点是协调、平衡“三足鼎立”，也就是并行度、并发度、执行内存，去提升CPU利用率，所以你更需要使用系统工具、监控工具，比如ganglia、Prometheus、Grafana、nmon、htop等等，这些工具，去观察你的CPU利用率，然后回过头来，平衡三者，然后再去观察CPU利用率是不是提升了，通过这种方式，来去调优。","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1618394759,"ip_address":"","comment_id":288188,"utype":1}],"discussion_count":1,"race_medal":0,"score":"31683126122","product_id":100073401,"comment_content":"这讲看得有些迷，想请问下老师如何从UI角度看出来我任务的并行度是否合适呢？","like_count":7,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":518541,"discussion_content":"Spark UI有专门的配置页，记录了不同配置项的设置值，其中有默认并行度设置。\n\n但重点不在这，重点是协调、平衡“三足鼎立”，也就是并行度、并发度、执行内存，去提升CPU利用率，所以你更需要使用系统工具、监控工具，比如ganglia、Prometheus、Grafana、nmon、htop等等，这些工具，去观察你的CPU利用率，然后回过头来，平衡三者，然后再去观察CPU利用率是不是提升了，通过这种方式，来去调优。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618394759,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":305240,"user_name":"wow_xiaodi","can_delete":false,"product_type":"c1","uid":1511712,"ip_address":"","ucode":"B3FB301556A7EA","user_header":"https://static001.geekbang.org/account/avatar/00/17/11/20/9f31c4f4.jpg","comment_is_top":false,"comment_ctime":1627889894,"is_pvip":false,"replies":[{"id":"110541","content":"好问题~ 是这样，这个公式的目的，主要是让每个Task能够拿到并处理适量的数据，不至于因为数据分布本身，而带来OOM。<br><br>D&#47;P ~ （M&#47;N&#47;2, M&#47;N），也就是数据分片大小，让他与M&#47;N在同一个当量。这样基本能够保证每个Task处理的数据是适量的。<br><br>怎么理解适量呢，就是在消耗一定内存（如AppendOnlyMap）的基础上，有少量的溢出。我们知道，D&#47;P是原始数据的尺寸，真正到内存里去，是会翻倍的，至于翻多少倍，这个和文件格式有关系。不过，不管他翻多少倍，只要原始的D&#47;P和M&#47;N在一个当量，那么我们大概率就能避开OOM的问题，不至于某些Tasks需要处理的数据分片过大而OOM。<br><br>整体上是这么个逻辑，不确定我说清楚了没，有问题再讨论哈~","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1628060003,"ip_address":"","comment_id":305240,"utype":1}],"discussion_count":1,"race_medal":0,"score":"27397693670","product_id":100073401,"comment_content":"最佳并行度 P，计算方法是让数据分片的平均大小 D&#47;P 坐落在（M&#47;N&#47;2, M&#47;N）区间<br>这里很不解为何内存的大小和分片大小有直接联系，无论是计算过程还是shuffle过程，都是用到一些内存占用较小的数据结构去做的，就算内存不够用，也会有gc去保证。这个公式感觉就是让数据分片大小和执行内存等价了，让所有数据都在待在内存中一次性批处理，而不是处理一部分溢出落盘再继续处理？请老师指正","like_count":6,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":524330,"discussion_content":"好问题~ 是这样，这个公式的目的，主要是让每个Task能够拿到并处理适量的数据，不至于因为数据分布本身，而带来OOM。\n\nD/P ~ （M/N/2, M/N），也就是数据分片大小，让他与M/N在同一个当量。这样基本能够保证每个Task处理的数据是适量的。\n\n怎么理解适量呢，就是在消耗一定内存（如AppendOnlyMap）的基础上，有少量的溢出。我们知道，D/P是原始数据的尺寸，真正到内存里去，是会翻倍的，至于翻多少倍，这个和文件格式有关系。不过，不管他翻多少倍，只要原始的D/P和M/N在一个当量，那么我们大概率就能避开OOM的问题，不至于某些Tasks需要处理的数据分片过大而OOM。\n\n整体上是这么个逻辑，不确定我说清楚了没，有问题再讨论哈~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1628060003,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":288580,"user_name":"Geek_d794f8","can_delete":false,"product_type":"c1","uid":2485585,"ip_address":"","ucode":"1E20DA4FF8B800","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIiaeebUYxl7e4jicPshDRKMbiculHUjKgZZ2ygDibn2S7bbsjeqYIdsEUdVyoryKNa43ZGnDQmWjv3ibQ/132","comment_is_top":false,"comment_ctime":1618550437,"is_pvip":false,"replies":[{"id":"104750","content":"对，没错~","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1618566505,"ip_address":"","comment_id":288580,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18798419621","product_id":100073401,"comment_content":"我的理解是每个线程申请的内存上限是M&#47;N,那么当数据分片过少，某个task需要处理的数据量较大，M&#47;N的上限执行内存也不够时，就会出现OOM。<br>不知道这么理解对不对？","like_count":4,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":518670,"discussion_content":"对，没错~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618566505,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":288212,"user_name":"kingcall","can_delete":false,"product_type":"c1","uid":1056982,"ip_address":"","ucode":"508884DC684B5B","user_header":"https://static001.geekbang.org/account/avatar/00/10/20/d6/b9513db0.jpg","comment_is_top":false,"comment_ctime":1618365972,"is_pvip":false,"replies":[{"id":"104643","content":"没写错哟，上限就是 spark.executor.memory * spark.memory.fraction ，也就是storage memory + execution memory之和。Unified memory manager，在统一管理模式下，大家是可以互相抢占的，因此，如果没有分布式数据集缓存，storage memory那片内存区域，执行任务是都可以抢过来的，所以上限就是两者之和。","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1618394477,"ip_address":"","comment_id":288212,"utype":1}],"discussion_count":3,"race_medal":0,"score":"10208300564","product_id":100073401,"comment_content":"M 的下限是 Execution Memory 初始值，上限是 spark.executor.memory * spark.memory.fraction 划定的所有内存区域。这个老师笔误，写错了吧！","like_count":2,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":518549,"discussion_content":"没写错哟，上限就是 spark.executor.memory * spark.memory.fraction ，也就是storage memory + execution memory之和。Unified memory manager，在统一管理模式下，大家是可以互相抢占的，因此，如果没有分布式数据集缓存，storage memory那片内存区域，执行任务是都可以抢过来的，所以上限就是两者之和。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618394477,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1056982,"avatar":"https://static001.geekbang.org/account/avatar/00/10/20/d6/b9513db0.jpg","nickname":"kingcall","note":"","ucode":"508884DC684B5B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":367578,"discussion_content":"我理解错了，老师见谅！提交点的那一刻才意识到，奈何已经提交了","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1618398847,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":367865,"discussion_content":"没事的，多讨论讨论挺好的~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618487797,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":290873,"user_name":"小灵芝","can_delete":false,"product_type":"c1","uid":2071355,"ip_address":"","ucode":"6DCB7CF8D5A7F1","user_header":"https://static001.geekbang.org/account/avatar/00/1f/9b/3b/dc3f819f.jpg","comment_is_top":false,"comment_ctime":1619798030,"is_pvip":false,"replies":[{"id":"105412","content":"稍有差别，M、N是针对Executor的，也就是Executor的执行内存M、线程池大小N。<br><br>D和P不一样，它指的是你的分布式数据集，D是数据总量，比如20GB；而P指的是这份数据集的并行度，比如200，那么你的每个数据分片的大小D&#47;P，就是20GB&#47;200 = 100MB。<br><br>如果你的M是2GB，也就是2GB的执行内存，N是20，也就是20个线程，那么这个时候，M&#47;N就是100MB。那么，你的D&#47;P就刚好坐落在(M&#47;N&#47;2, M&#47;N)这个区间里。","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1619861364,"ip_address":"","comment_id":290873,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5914765326","product_id":100073401,"comment_content":"“在给定执行内存 M、线程池大小 N 和数据总量 D 的时候，想要有效地提升 CPU 利用率，我们就要计算出最佳并行度 P，计算方法是让数据分片的平均大小 D&#47;P 坐落在（M&#47;N&#47;2, M&#47;N）区间。这样，在运行时，我们的 CPU 利用率往往不会太差。”<br><br>请问老师，这里的M, N， D 都是针对一个executor而言的对吧？","like_count":1,"discussions":[{"author":{"id":2855459,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/icJzoUc02ECdBbFgGzVIwYfpRgL3TXuRRE5GsDqZFmAlAAm1KUQS1rHewgj5FB4TChovo3YaceicEZE2MgZJ1ftw/132","nickname":"Geek_eb29a4","note":"","ucode":"CF88D4ED5F4A25","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":538003,"discussion_content":"线程池大小N ，这个参数怎么设置？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1639295649,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":288523,"user_name":"来世愿做友人 A","can_delete":false,"product_type":"c1","uid":1181606,"ip_address":"","ucode":"EF20966B0F27E1","user_header":"https://static001.geekbang.org/account/avatar/00/12/07/a6/662bcc6b.jpg","comment_is_top":false,"comment_ctime":1618504418,"is_pvip":false,"replies":[{"id":"104758","content":"第二题完美~<br><br>第一题也对，不过算是edge case了。可以想想，一般情况下，in general，为啥task会OOM？","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1618585766,"ip_address":"","comment_id":288523,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5913471714","product_id":100073401,"comment_content":"1. excutor 并发度如果过高，考虑极端情况，storageMemery 还没有使用，这时候这部分内存是会被 task 所抢占的，每个任务的上限是 1&#47;N。但是对于 storage 和 execute pool 的池锁不是同一个锁。并发高的情况下，可能会出现 execute 剩余内存假设 1M，task 申请 execute 内存并且 size 申请成功，但是还没 alloc 内存。并行条件下，此时别的 task 线程刚好申请了 storage pool 的内存 0.8M 进行 block 存储，并且申请成功。然后申请 1M 的 task 线程才 allocate，却发现内存不够 OOM 了。不知道这样对不对<br>2. 其实在 task 每次的 allocatePage，都会动态计算 task 当先的上下限的申请大小。满足申请条件，返回。申请后可用大小加上当前已用不满足下限，则挂起等待其它 task 唤醒抢占。","like_count":1,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":518649,"discussion_content":"第二题完美~\n\n第一题也对，不过算是edge case了。可以想想，一般情况下，in general，为啥task会OOM？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618585766,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1181606,"avatar":"https://static001.geekbang.org/account/avatar/00/12/07/a6/662bcc6b.jpg","nickname":"来世愿做友人 A","note":"","ucode":"EF20966B0F27E1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":368193,"discussion_content":"看了@Geek 的评论，猜测可能看漏了那块，去看了下源码。纠正了自己的想法，以为一次 page 内存申请不够会挂起，原来是尽量全部分配，如果申请的 page 为 null 或者 size 小于请求的大小，spark 就会释放 抛出 SparkOutOfMemoryError","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1618590609,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":353970,"user_name":"칭찬하다","can_delete":false,"product_type":"c1","uid":1276001,"ip_address":"福建","ucode":"F6E3F358F3EBDF","user_header":"https://static001.geekbang.org/account/avatar/00/13/78/61/a1189d65.jpg","comment_is_top":false,"comment_ctime":1659963482,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1659963482","product_id":100073401,"comment_content":"老师，<br>「问题背景」：您提到“Executor 的线程池大小由参数 spark.executor.cores 决定，每个任务在执行期间需要消耗的线程数由 spark.task.cpus 配置项给定。两者相除得到的商就是并发度”<br>「问题描述」：这里的商是不是并行度呢？<br>「我的理解」：并行指最多可以同时运行的线程数，线程间是互不抢占 CPU 资源的。并发指一个 CPU 运行多个线程，会互相抢占 CPU 资源。这里商是不会互相抢占 CPU 资源的。<br>","like_count":0},{"had_liked":false,"id":348523,"user_name":"桐雨","can_delete":false,"product_type":"c1","uid":2719845,"ip_address":"","ucode":"AEE92AEE03778A","user_header":"https://static001.geekbang.org/account/avatar/00/29/80/65/9ec76b46.jpg","comment_is_top":false,"comment_ctime":1655170954,"is_pvip":true,"discussion_count":1,"race_medal":0,"score":"1655170954","product_id":100073401,"comment_content":"没有想清楚为啥 并发度 等于spark.executor.cores &#47; spark.task.cpus , 要说是这两者之间的乘积倒是能理解 , 这两者之间的商是什么含义呢?","like_count":0,"discussions":[{"author":{"id":1947809,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/b8/a1/019574ad.jpg","nickname":"松花酿酒，春水煎茶","note":"","ucode":"843A6AB55FCF99","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":580714,"discussion_content":"spark.executor.cores表示单个executor分配到的核数，spark.task.cpus单个任务需要消耗的核数，两者相除就表示单个executor最多能同时启动的task线程数","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1658332871,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":346617,"user_name":"斯盖丸","can_delete":false,"product_type":"c1","uid":1168504,"ip_address":"","ucode":"B881D14B028F14","user_header":"https://static001.geekbang.org/account/avatar/00/11/d4/78/66b3f2a2.jpg","comment_is_top":false,"comment_ctime":1653292876,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1653292876","product_id":100073401,"comment_content":"老师，假设我一个 Databricks集群 10 台，每台的executor memory56G，每台的executor cores16 个，那按照您的公式，我的数据分片大小应该在 (56&#47;32, 56&#47;16)，也就是(1.75G, 3.5G)之间吗？感觉这个值太大了吧。。。","like_count":0,"discussions":[{"author":{"id":3011130,"avatar":"","nickname":"Geek_3aa2a6","note":"","ucode":"1757BE9C365D9F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":574258,"discussion_content":"这里的executor_memory 肯定要小于56G，默认应该是0.3倍吧，fraction * （1-strorageFraction）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1653925753,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":344376,"user_name":"我爱夜来香","can_delete":false,"product_type":"c1","uid":2609930,"ip_address":"","ucode":"10761E677EF05F","user_header":"https://static001.geekbang.org/account/avatar/00/27/d3/0a/92640aae.jpg","comment_is_top":false,"comment_ctime":1651499685,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1651499685","product_id":100073401,"comment_content":"老师,如果设置shuffle.partition过大,AQE不是会自动合并吗?对reducer的数量设置要求是不是没那么严格了","like_count":0},{"had_liked":false,"id":341013,"user_name":"Ebdaoli","can_delete":false,"product_type":"c1","uid":1722878,"ip_address":"","ucode":"E45C113C1AFD12","user_header":"https://static001.geekbang.org/account/avatar/00/1a/49/fe/48846a6d.jpg","comment_is_top":false,"comment_ctime":1649295562,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1649295562","product_id":100073401,"comment_content":"磊哥，请教一下，如果是在spark sql场景中，a join b join c join d 这类似多表Join的情况下，在计算总数据集大小D的时候，这时候应该怎么计算呢？是否取加了filter条件后（还是scan前的数据大小？）的数据计算呢？以及是否需要对每一张表的总数据集大小进行计算（或者只取最大的一张表进行计算），应该取哪一个结果作为公式中的D？","like_count":0},{"had_liked":false,"id":331378,"user_name":"Sampson","can_delete":false,"product_type":"c1","uid":1418226,"ip_address":"","ucode":"BA78CA29A6D898","user_header":"https://static001.geekbang.org/account/avatar/00/15/a3/f2/ab8c5183.jpg","comment_is_top":false,"comment_ctime":1642565626,"is_pvip":true,"replies":[{"id":"121203","content":"这个需要熟悉shuffle里面，用到的内存数据结构，比如AppendOnlyMap，PartitionedPairBuffer，等等。在Shuffle map task阶段，Spark会利用类似的数据结构，来计算数据，当这些数据结构空间不足的时候，Spark会成倍扩容这些数据结构，但是只会扩容一次。想象一下，如果没有Spill机制，实际上Spark很容易OOM，因为扩容一次之后，也很难容下单个数据分片的全部数据","user_name":"作者回复","user_name_real":"编辑","uid":"1043100","ctime":1642779554,"ip_address":"","comment_id":331378,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1642565626","product_id":100073401,"comment_content":"老师您好，请教一下，在上文中有提到spill机制可以保护oom 的溢出，这个是怎么判断的呢 ","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":547648,"discussion_content":"这个需要熟悉shuffle里面，用到的内存数据结构，比如AppendOnlyMap，PartitionedPairBuffer，等等。在Shuffle map task阶段，Spark会利用类似的数据结构，来计算数据，当这些数据结构空间不足的时候，Spark会成倍扩容这些数据结构，但是只会扩容一次。想象一下，如果没有Spill机制，实际上Spark很容易OOM，因为扩容一次之后，也很难容下单个数据分片的全部数据","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1642779554,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":328140,"user_name":"Unknown element","can_delete":false,"product_type":"c1","uid":2028277,"ip_address":"","ucode":"34A129800D0238","user_header":"https://static001.geekbang.org/account/avatar/00/1e/f2/f5/b82f410d.jpg","comment_is_top":false,"comment_ctime":1640571091,"is_pvip":false,"replies":[{"id":"119853","content":"先来说第一个哈<br>（11765[Finished] + 6[Ongoing]) &#47; 11769[Total]<br>最后一个，11769，是Total tasks，所有tasks的数量；11765，是Finished的tasks数量，包括Failed，6是正在执行的tasks，两边加起来不一样，我理解是Finished里面有Failed，然后重试的<br><br>Tasks多倒不是什么大问题，主要是要结合“三足鼎立”，调整并行度，让CPU、内存、并行度保持一致就行","user_name":"作者回复","user_name_real":"编辑","uid":"1043100","ctime":1641003654,"ip_address":"","comment_id":328140,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1640571091","product_id":100073401,"comment_content":"老师您好 spark在计算过程中会输出类似这样的日志：<br>[Stage 1:==================================================&gt;(11765 + 6) &#47; 11769]<br>想问下这里的数字是 task 数吗？为什么括号里的两个task数加起来不等于外面task数呢？<br>另外这里的task是不是偏多？应该从哪些方面去排查问题呢？<br>谢谢老师","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":543192,"discussion_content":"先来说第一个哈\n（11765[Finished] + 6[Ongoing]) / 11769[Total]\n最后一个，11769，是Total tasks，所有tasks的数量；11765，是Finished的tasks数量，包括Failed，6是正在执行的tasks，两边加起来不一样，我理解是Finished里面有Failed，然后重试的\n\nTasks多倒不是什么大问题，主要是要结合“三足鼎立”，调整并行度，让CPU、内存、并行度保持一致就行","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1641003654,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":322168,"user_name":"子兮","can_delete":false,"product_type":"c1","uid":2767208,"ip_address":"","ucode":"BA213EAB26DF16","user_header":"https://static001.geekbang.org/account/avatar/00/2a/39/68/56dfc8c0.jpg","comment_is_top":false,"comment_ctime":1637218394,"is_pvip":false,"replies":[{"id":"117229","content":"先说1，完全有可能~ task对于内存的申请，是随需随用的，并不是一开始就分配M&amp;#47;N&amp;#47;2，所以跑得快的小task结束之后，空闲的内存，就可以留给大的task，当然，这里还要考虑gc的延迟。task数量有变化，Spark就会重新计算M&amp;#47;N，也就是你给的5&amp;#47;2=22.5M，所以18M的task，就不会OOM~<br><br>问题2的话，这个比较tricky，这个咱们很难on the fly地再去做调整，比较行之有效的办法，就是在最开始，结合原始数据量大小（内存中的大小），再结合CPU、内存配置，按照“三足鼎立”的思路，去设置","user_name":"作者回复","user_name_real":"编辑","uid":"1043100","ctime":1637662147,"ip_address":"","comment_id":322168,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1637218394","product_id":100073401,"comment_content":"老师，有没有可能：M&#47;N =45M&#47;3core=15M， 有三个分片 5M ，12M，18M,  理论来讲，18M 的task 会出现oom，三个task 同时执行，但在执行过程中，由于5M 的task 迅速执行完成，使得内存释放，这时18M 在执行时获得45&#47;2=22.5M，没有报oom ？<br>2 spark graphx 在执行时每个job 所需要处理的数据量都不同，没有办法实时评估更改，这时的设置应该怎样思考呢？","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":532658,"discussion_content":"先说1，完全有可能~ task对于内存的申请，是随需随用的，并不是一开始就分配M&amp;#47;N&amp;#47;2，所以跑得快的小task结束之后，空闲的内存，就可以留给大的task，当然，这里还要考虑gc的延迟。task数量有变化，Spark就会重新计算M&amp;#47;N，也就是你给的5&amp;#47;2=22.5M，所以18M的task，就不会OOM~\n\n问题2的话，这个比较tricky，这个咱们很难on the fly地再去做调整，比较行之有效的办法，就是在最开始，结合原始数据量大小（内存中的大小），再结合CPU、内存配置，按照“三足鼎立”的思路，去设置","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1637662147,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":318619,"user_name":"狗哭","can_delete":false,"product_type":"c1","uid":2725399,"ip_address":"","ucode":"56E48A6FC1298A","user_header":"https://static001.geekbang.org/account/avatar/00/29/96/17/200c21f0.jpg","comment_is_top":false,"comment_ctime":1635350359,"is_pvip":false,"replies":[{"id":"115572","content":"其实我理解这是两个问题，一个是locality wait问题，一个是CPU利用率低的问题。<br><br>先说CPU利用率低的事儿，其实这个就是本讲的重点，老弟可以考虑采用“三足鼎立”的思路来尝试<br><br>至于locality wait，这个本质上是个平衡，要么多花时间等待更好的locality，比如等待PROCESS_LOCAL或是NODE_LOCAL；要么，马上调度出去，不考虑locality。其实就是调度开销与执行效率的平衡。<br><br>我觉得可以两步走，第一步先用“三足鼎立”，消除CPU、内存、数据之间的不一致，而导致的CPU利用率过低。也就是说，先通过三足鼎立，保证这3者是一致的。然后，再去考虑locality的影响。<br><br>因为，就经验来说，locality对于执行性能来说，作用相对次之。而对于如何平衡wait的设置，坦白说，我也给不出一个量化的办法或者是公式，只能是case by case地去尝试、分析，找到一个合理的中间值~","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1635425166,"ip_address":"","comment_id":318619,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1635350359","product_id":100073401,"comment_content":"老师请教一个问题，spark中有这么一个配置，spark.locality.wait用来配置task数据本地化级别等待时常，默认是3s，但是发现有时候cpu利用率就很低，如果配成0发现task的数据本地化级别很多是node甚至rack级别的，请问这个该怎么平衡呢？或者有什么好的办法解决呢？","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":529316,"discussion_content":"其实我理解这是两个问题，一个是locality wait问题，一个是CPU利用率低的问题。\n\n先说CPU利用率低的事儿，其实这个就是本讲的重点，老弟可以考虑采用“三足鼎立”的思路来尝试\n\n至于locality wait，这个本质上是个平衡，要么多花时间等待更好的locality，比如等待PROCESS_LOCAL或是NODE_LOCAL；要么，马上调度出去，不考虑locality。其实就是调度开销与执行效率的平衡。\n\n我觉得可以两步走，第一步先用“三足鼎立”，消除CPU、内存、数据之间的不一致，而导致的CPU利用率过低。也就是说，先通过三足鼎立，保证这3者是一致的。然后，再去考虑locality的影响。\n\n因为，就经验来说，locality对于执行性能来说，作用相对次之。而对于如何平衡wait的设置，坦白说，我也给不出一个量化的办法或者是公式，只能是case by case地去尝试、分析，找到一个合理的中间值~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1635425166,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":316495,"user_name":"静心","can_delete":false,"product_type":"c1","uid":1789481,"ip_address":"","ucode":"B80DE4B5C923D3","user_header":"https://static001.geekbang.org/account/avatar/00/1b/4e/29/adcb78e7.jpg","comment_is_top":false,"comment_ctime":1634355449,"is_pvip":false,"replies":[{"id":"114671","content":"确实~<br><br>不过资源这几讲，都偏运行时一些，比较难用直观的方式做演示，更多的是理论上的指导和方法论~ 需要大家结合日常的实战，多实践、多反思、多思考","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1634534095,"ip_address":"","comment_id":316495,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1634355449","product_id":100073401,"comment_content":"老师，这一讲太理论范了，能不能举一些实际的例子，供大家学习加深理解，谢谢老师","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":528393,"discussion_content":"确实~\n\n不过资源这几讲，都偏运行时一些，比较难用直观的方式做演示，更多的是理论上的指导和方法论~ 需要大家结合日常的实战，多实践、多反思、多思考","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1634534095,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":315007,"user_name":"静心","can_delete":false,"product_type":"c1","uid":1789481,"ip_address":"","ucode":"B80DE4B5C923D3","user_header":"https://static001.geekbang.org/account/avatar/00/1b/4e/29/adcb78e7.jpg","comment_is_top":false,"comment_ctime":1633656454,"is_pvip":false,"replies":[{"id":"114415","content":"好问题~ Task对于内存的申请，是on demand的，也就是随用随申请，并不是一开始就一下子给它allocate M&#47;2那么大的空间，所以说并不存在浪费的问题。也就是说，假设Task所需的内存，连M&#47;2都不到，那么Spark是不会强行塞给它更多内存的。<br><br>M&#47;N&#47;2到M&#47;N，这里的限制，更多的是多个Tasks之间对于Executors中有限的内存形成抢占关系的时候，Spark从统计上的一种限制，主要是为了维持Task之间对于内存消耗上的一种公平或者说平衡机制。","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1633962733,"ip_address":"","comment_id":315007,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1633656454","product_id":100073401,"comment_content":"老师，关于executor每个core分配到的执行内存大小区间是M&#47;N&#47;2到M&#47;N，那若在某个时刻只有一个task调度了该executor，那么这个线程申请的内存大小至少是M&#47;2吗，相当于至少申请一半的执行内存。若实际用不到这么多那不就浪费了。","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527854,"discussion_content":"好问题~ Task对于内存的申请，是on demand的，也就是随用随申请，并不是一开始就一下子给它allocate M/2那么大的空间，所以说并不存在浪费的问题。也就是说，假设Task所需的内存，连M/2都不到，那么Spark是不会强行塞给它更多内存的。\n\nM/N/2到M/N，这里的限制，更多的是多个Tasks之间对于Executors中有限的内存形成抢占关系的时候，Spark从统计上的一种限制，主要是为了维持Task之间对于内存消耗上的一种公平或者说平衡机制。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633962733,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":315002,"user_name":"静心","can_delete":false,"product_type":"c1","uid":1789481,"ip_address":"","ucode":"B80DE4B5C923D3","user_header":"https://static001.geekbang.org/account/avatar/00/1b/4e/29/adcb78e7.jpg","comment_is_top":false,"comment_ctime":1633654829,"is_pvip":false,"replies":[{"id":"114464","content":"我们一直在推荐：<br>D&#47;P ~ （M&#47;N&#47;2，M&#47;N）这样一个最具配比公式，其中~线，表示左右两边在一个数量级。<br><br>但这里有个地方需要特别注意，就是Task的内存分配，是on demand的，就是随着计算的需要，而不断地分配内存，而内存的上下限，由（M&#47;N&#47;2，M&#47;N）划定。<br><br>所以，执行内存的消耗，一定是跟数据集（以及并行度）有关的，和M、N的关系就更大了。不妨从需求和供给的角度，去理解这个公式。<br><br>左边的D&#47;P，是需求，也就是一个Task需要处理的数据量，对应着的，就是内存需求；<br><br>而右边的（M&#47;N&#47;2，M&#47;N），是系统可以提供的per Task的内存供给，也就是说，系统层面，资源层面，能够给每个Task提供多少内存资源。<br><br>需求与供给，一定要匹配或者说一致，才能达到一种平衡的状态，也就是我们一直强调的“无瓶颈”的状态。","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1634050877,"ip_address":"","comment_id":315002,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1633654829","product_id":100073401,"comment_content":"老师关于cpu线程挂起，描述的是有cpu资源而没执行内存使用而挂起的情况，主要还是动态变化的M（执行内存）与动态变化N（当前使用的cores）的问题，文中提到线程申请内存的大小也是通过M和N计算的。但文中也提到和分布式数据集的数据分布也有关系，这里我不太理解，线程可使用执行内存大小是通过M和N计算的，这和分布式数据集的数据分布有什么关系呢？","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527853,"discussion_content":"我们一直在推荐：\nD/P ~ （M/N/2，M/N）这样一个最具配比公式，其中~线，表示左右两边在一个数量级。\n\n但这里有个地方需要特别注意，就是Task的内存分配，是on demand的，就是随着计算的需要，而不断地分配内存，而内存的上下限，由（M/N/2，M/N）划定。\n\n所以，执行内存的消耗，一定是跟数据集（以及并行度）有关的，和M、N的关系就更大了。不妨从需求和供给的角度，去理解这个公式。\n\n左边的D/P，是需求，也就是一个Task需要处理的数据量，对应着的，就是内存需求；\n\n而右边的（M/N/2，M/N），是系统可以提供的per Task的内存供给，也就是说，系统层面，资源层面，能够给每个Task提供多少内存资源。\n\n需求与供给，一定要匹配或者说一致，才能达到一种平衡的状态，也就是我们一直强调的“无瓶颈”的状态。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1634050877,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1947809,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/b8/a1/019574ad.jpg","nickname":"松花酿酒，春水煎茶","note":"","ucode":"843A6AB55FCF99","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":580715,"discussion_content":"D/P ~ （M/N/2，M/N）对这个公式还是有点困惑，假如我的任务是A表Join B表，那么我的D是以A表的数据量为准，还是以B表的数据量为准呢？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1658333984,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":309461,"user_name":"Sean","can_delete":false,"product_type":"c1","uid":2162751,"ip_address":"","ucode":"69234046BFD81B","user_header":"https://static001.geekbang.org/account/avatar/00/21/00/3f/a0f84788.jpg","comment_is_top":false,"comment_ctime":1630146380,"is_pvip":false,"replies":[{"id":"112653","content":"D&#47;P =&gt; (M&#47;N&#47;2,M&#47;N) ：<br> (6&#47;4&#47;2 ,6&#47;4)，这里没有--num-executors 80什么事，这个公式是per executor来计算的，不能把executors个数都加上，建议再读读原文哈~<br><br>而且，实际上这里也不能按6g来算，应该是Storage + Execution两部分内存才对，具体算法，你可以再看看文稿~ 6g是所有的内存，是Reserved + User + Storage + Execution。","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1630940278,"ip_address":"","comment_id":309461,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1630146380","product_id":100073401,"comment_content":"老师提到的从分片大小200M反推,来配置spark.sql.shuffle.partitions,spark.executor.memory,spark.executor.cores参数,不知道理解的对不对,在不考虑数据压缩的情况下,比如有1T的数据,那么按200分片考虑,最佳并行度计算按1048576M&#47;200M≈5243计算吗,set spark.sql.shuffle.partitions=5243,好像还没有get到这个资源计算公式的应用,<br>我结合这几个配置推导方式如下:--executor-cores 4  --executor-memory 6g  --num-executors 80<br>D&#47;P =&gt; (M&#47;N&#47;2,M&#47;N) =&gt; (6*80&#47;4&#47;2,6*80&#47;4) =&gt; (60G,120G) 这个配置显然不合适,修改一下参数--executor-cores 1500 得到:<br>D&#47;P =&gt; (M&#47;N&#47;2,M&#47;N) =&gt; (6*80&#47;1500&#47;2,6*80&#47;1500) =&gt; (164M,327M) 看着这个配置算是合理的利用cpu吗<br>根据这个配置得到的区间在继续推导:<br>如果数据总量D=1T≈1048576M,那并行度P:spark.sql.shuffle.partitions的大小在这(1048576&#47;164,1048576&#47;327)=&gt;(6394,3207)区间,感觉这个并行度好像太大,也不是很合理,不知道我理解的对不对","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":525882,"discussion_content":"D/P =&amp;gt; (M/N/2,M/N) ：\n (6/4/2 ,6/4)，这里没有--num-executors 80什么事，这个公式是per executor来计算的，不能把executors个数都加上，建议再读读原文哈~\n\n而且，实际上这里也不能按6g来算，应该是Storage + Execution两部分内存才对，具体算法，你可以再看看文稿~ 6g是所有的内存，是Reserved + User + Storage + Execution。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1630940278,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":299629,"user_name":"何西东","can_delete":false,"product_type":"c1","uid":1394628,"ip_address":"","ucode":"70A75C12DEC34B","user_header":"https://static001.geekbang.org/account/avatar/00/15/47/c4/c070afcf.jpg","comment_is_top":false,"comment_ctime":1624767885,"is_pvip":false,"replies":[{"id":"108791","content":"200M是个经验之谈哈，在之前碰到的大多数的计算场景里，200M都是个不错的起点，能够比较好地平衡三足鼎立里面涉及的：数据、CPU与内存。<br><br>其实200M算是一种偷懒的做法，就是跳过“三足鼎立”的复杂计算，跳过文中介绍的计算公式，快速进行配置的一种方法。","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1624955123,"ip_address":"","comment_id":299629,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1624767885","product_id":100073401,"comment_content":"老师,200m的依据是防止任务调度滞后而导致线程挂起吗","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":522489,"discussion_content":"200M是个经验之谈哈，在之前碰到的大多数的计算场景里，200M都是个不错的起点，能够比较好地平衡三足鼎立里面涉及的：数据、CPU与内存。\n\n其实200M算是一种偷懒的做法，就是跳过“三足鼎立”的复杂计算，跳过文中介绍的计算公式，快速进行配置的一种方法。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1624955123,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":297655,"user_name":"慢慢卢","can_delete":false,"product_type":"c1","uid":1329566,"ip_address":"","ucode":"853D399100D83B","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/IcDlyK6DaBrssVGlmosXnahdJ4bwCesjXa98iaapSDozBiagZTqSCok6iaktu2wOibvpNv9Pd6nfwMg7N7KTSTzYRw/132","comment_is_top":false,"comment_ctime":1623710521,"is_pvip":false,"replies":[{"id":"108105","content":"这个可以参考本章的“三足鼎立”哈~ 三足鼎立其实可以非常灵活，并行度、并发度与执行内存三者之间相互牵连、相互钳制。当其中一个因素受限时，其他两个因素可以相应地做调整、做适配，从而达到一种平衡的状态。","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1623748381,"ip_address":"","comment_id":297655,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1623710521","product_id":100073401,"comment_content":"老师能讲一讲spark.executor.core的配置原则吗","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":521895,"discussion_content":"这个可以参考本章的“三足鼎立”哈~ 三足鼎立其实可以非常灵活，并行度、并发度与执行内存三者之间相互牵连、相互钳制。当其中一个因素受限时，其他两个因素可以相应地做调整、做适配，从而达到一种平衡的状态。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1623748381,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":294972,"user_name":"斯盖丸","can_delete":false,"product_type":"c1","uid":1168504,"ip_address":"","ucode":"B881D14B028F14","user_header":"https://static001.geekbang.org/account/avatar/00/11/d4/78/66b3f2a2.jpg","comment_is_top":false,"comment_ctime":1622168691,"is_pvip":false,"replies":[{"id":"107202","content":"好问题，这个公式的作用其实是双向的，也即是给定资源，你可以算出并行度；反过来，找到合适的并行度，你也可以指导Spark集群资源的设定。<br><br>你说的没错，2GB的分片，确实太大了，通常来说，分片大小在200MB左右，是比较合适的，推荐把分片大小设定在这个范围。<br><br>有了分片大小，其实就可以反向指导Spark资源设定了。在你的例子里面，我理解资源是提前设定好了，也就是你说的堆内外分别9G，5个cores，也许这个设定是基于经验、也许是出于直觉。<br><br>如果用200MB分片大小反推过来的话，其实你可以考虑降低Executors的内存配置，或是提高它的CPU cores配置，这样把内存与CPU做到一个均衡配比，相比现在一个task要处理2GB的数据，效果要更好~<br><br>毕竟咱们性能调优的本质，是让硬件资源之间尽量去平衡，调节并行度也好、分片大小也好、各种资源参数也好，实际上都是手段。","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1622390292,"ip_address":"","comment_id":294972,"utype":1}],"discussion_count":3,"race_medal":0,"score":"1622168691","product_id":100073401,"comment_content":"老师，顺着王天雨同学的问题我接着问。我的executor memory为9G，executor的off heap memory也为9G，executor cores为5个，executor instances为30个。<br>以上是我的配置。<br>照您的公式，我的数据分片的大小就应该在(9G+9G)&#47;5&#47;2=1.8G到(9G+9G)&#47;5=3.6，即数据分片在（1.8G，3.6G）的范围内吗，那进一步说，我在Spark UI里，找到第一个读取parquet的任务，看shuffle read size这个指标，如果在（1.8G，3.6G）这个区间之内，说明就是可以的，是这样吗?<br><br>感觉这个分片好大哦~~","like_count":1,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":520899,"discussion_content":"好问题，这个公式的作用其实是双向的，也即是给定资源，你可以算出并行度；反过来，找到合适的并行度，你也可以指导Spark集群资源的设定。\n\n你说的没错，2GB的分片，确实太大了，通常来说，分片大小在200MB左右，是比较合适的，推荐把分片大小设定在这个范围。\n\n有了分片大小，其实就可以反向指导Spark资源设定了。在你的例子里面，我理解资源是提前设定好了，也就是你说的堆内外分别9G，5个cores，也许这个设定是基于经验、也许是出于直觉。\n\n如果用200MB分片大小反推过来的话，其实你可以考虑降低Executors的内存配置，或是提高它的CPU cores配置，这样把内存与CPU做到一个均衡配比，相比现在一个task要处理2GB的数据，效果要更好~\n\n毕竟咱们性能调优的本质，是让硬件资源之间尽量去平衡，调节并行度也好、分片大小也好、各种资源参数也好，实际上都是手段。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1622390292,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1943439,"avatar":"https://static001.geekbang.org/account/avatar/00/1d/a7/8f/0d8e6d34.jpg","nickname":"陈子","note":"","ucode":"CDC23530B6235A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":399352,"discussion_content":"假设斯盖丸同学 executor core 的数量提高到 10，但是物理机器的 core 依然是 5，在单位时间里 executor 内同时并行的线程依然是 5 个，这样的调整只能起到加大 executor 并发能力的作用，在整体上让每个 task 的处理时间变短，task 执行的数量变多对吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1632936651,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1172778,"avatar":"https://static001.geekbang.org/account/avatar/00/11/e5/2a/738f90d7.jpg","nickname":"Virgil 阿城","note":"","ucode":"308AA431057EC7","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":378769,"discussion_content":"老师，能给一个具体的反推案例吗？\n觉得课程讲的很好，但作为一名小白，shuffle报错的详细反馈过程，解决步骤，还是没明白（苦笑）。。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1623396576,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":293194,"user_name":"Geek","can_delete":false,"product_type":"c1","uid":2532766,"ip_address":"","ucode":"52E93A8CEEAFC3","user_header":"https://static001.geekbang.org/account/avatar/00/26/a5/9e/19871ffb.jpg","comment_is_top":false,"comment_ctime":1621260689,"is_pvip":false,"replies":[{"id":"106296","content":"好问题~<br><br>我们先说第二个问题，Spark考虑的，不是数据在磁盘中的存储大小，是内存中的存储大小，所以恰恰是Parquet+Snappy解压后、在内存中的存储大小~<br><br>再来说第一个，源文件通常指的是磁盘中的文件，因此我们也要计算它加载进内存的存储大小。现在假设加载进内存的大小是X，它比M&#47;N大。这个时候，通常来说，Spark并不会立即内存溢出OOM，因为它有Spill机制做保护，这部分细节可以参考Shuffle原理那一讲。Spill机制保证在Task内存不足的情况下，把内存中的数据排序并溢出到临时文件，因此，当X稍大于M&#47;N的情况下，Spark的Spill机制可以避免OOM的发生。<br><br>但是，当某个Task的X远大于M&#47;N，或是所有的Task的X都超过了M&#47;N，这个时候，OOM的概率会陡然上升。<br><br>为了有效降低OOM的概率和可能，同时为了叙述方便，我们在文中建议大家把X控制在[M&#47;N&#47;2，M&#47;N]之间。这么做到目的有几个：<br>1）一个是提升CPU利用率<br>2）一个是提升内存利用率<br>3）再有一个，就是有效避免OOM","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1621422006,"ip_address":"","comment_id":293194,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1621260689","product_id":100073401,"comment_content":"吴老师 请教2个问题哈<br>1、当一个源文件的大小超过了M&#47;N 的内存时，这种情况是不是会报OOM？<br>2、spark在加载parquet+snappy压缩文件时，它会考虑解压之后的文件大小吗？","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":520109,"discussion_content":"好问题~\n\n我们先说第二个问题，Spark考虑的，不是数据在磁盘中的存储大小，是内存中的存储大小，所以恰恰是Parquet+Snappy解压后、在内存中的存储大小~\n\n再来说第一个，源文件通常指的是磁盘中的文件，因此我们也要计算它加载进内存的存储大小。现在假设加载进内存的大小是X，它比M/N大。这个时候，通常来说，Spark并不会立即内存溢出OOM，因为它有Spill机制做保护，这部分细节可以参考Shuffle原理那一讲。Spill机制保证在Task内存不足的情况下，把内存中的数据排序并溢出到临时文件，因此，当X稍大于M/N的情况下，Spark的Spill机制可以避免OOM的发生。\n\n但是，当某个Task的X远大于M/N，或是所有的Task的X都超过了M/N，这个时候，OOM的概率会陡然上升。\n\n为了有效降低OOM的概率和可能，同时为了叙述方便，我们在文中建议大家把X控制在[M/N/2，M/N]之间。这么做到目的有几个：\n1）一个是提升CPU利用率\n2）一个是提升内存利用率\n3）再有一个，就是有效避免OOM","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1621422006,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2635387,"avatar":"https://static001.geekbang.org/account/avatar/00/28/36/7b/b06aad84.jpg","nickname":"空","note":"","ucode":"01F63669AE814A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":378190,"discussion_content":"老师shuffle spil有溢出到内存有溢出到磁盘，这里是指哪个呢？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1623082484,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":291897,"user_name":"Geek_81beba","can_delete":false,"product_type":"c1","uid":2540707,"ip_address":"","ucode":"FCED45C338D00F","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJt9RvLXn5KxqNiccCyxRGy0IDHdqOOiazoH7aqku4GlELB4guibOGibEqPF740iaNwKoe6BjicgmgjR6Vw/132","comment_is_top":false,"comment_ctime":1620576329,"is_pvip":false,"replies":[{"id":"105710","content":"默认并行度我理解你说的是下面这两个参数：<br>spark.default.parallelism<br>spark.sql.shuffle.partitions<br><br>不知道你说的shuffle partitions指的是什么呢？","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1620624987,"ip_address":"","comment_id":291897,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1620576329","product_id":100073401,"comment_content":"默认并行度和shuffle partitions哪个更优先呢","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":519597,"discussion_content":"默认并行度我理解你说的是下面这两个参数：\nspark.default.parallelism\nspark.sql.shuffle.partitions\n\n不知道你说的shuffle partitions指的是什么呢？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1620624987,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":291235,"user_name":"aof","can_delete":false,"product_type":"c1","uid":1062864,"ip_address":"","ucode":"5815D63C4926BC","user_header":"https://static001.geekbang.org/account/avatar/00/10/37/d0/26975fba.jpg","comment_is_top":false,"comment_ctime":1620133814,"is_pvip":false,"replies":[{"id":"105747","content":"没错，老弟代码看的很细致~ ","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1620658720,"ip_address":"","comment_id":291235,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1620133814","product_id":100073401,"comment_content":"每个线程申请执行内存的时候都会跟所请求的内存大小进行比较。为一个内存消费者（MemoryConsumer）申请执行内存的具体实现逻辑在TaskMemoryManager#acquireExecutionMemory()方法中，这个方法为内存消费者（consumer）申请指定大小的内存空间，如果没有足够的内存，将会对consumer进行spill()来释放更多内存，具体要对哪些consumer进行spill()，会有一个排序算法（使用了TreeMap）。","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":519409,"discussion_content":"没错，老弟代码看的很细致~ ","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1620658720,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":290867,"user_name":"小灵芝","can_delete":false,"product_type":"c1","uid":2071355,"ip_address":"","ucode":"6DCB7CF8D5A7F1","user_header":"https://static001.geekbang.org/account/avatar/00/1f/9b/3b/dc3f819f.jpg","comment_is_top":false,"comment_ctime":1619794295,"is_pvip":false,"replies":[{"id":"105415","content":"对，看你的应用使用哪个API，RDD的话，用前者；DF或是DS的话，用后者。","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1619862591,"ip_address":"","comment_id":290867,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1619794295","product_id":100073401,"comment_content":"“并行度可以通过两个参数来设置，分别是 spark.default.parallelism 和 spark.sql.shuffle.partitions。前者用于设置 RDD 的默认并行度，后者在 Spark SQL 开发框架下，指定了 Shuffle Reduce 阶段默认的并行度。”<br><br>请问老师，这两个参数是都要设置吗？还是说在用RDD的时候设置前者，Dataframe或者Dataset的时候设置后者即可？","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":519301,"discussion_content":"对，看你的应用使用哪个API，RDD的话，用前者；DF或是DS的话，用后者。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1619862591,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":288349,"user_name":"Fendora范东_","can_delete":false,"product_type":"c1","uid":1187106,"ip_address":"","ucode":"63EE9DBEE08D70","user_header":"https://static001.geekbang.org/account/avatar/00/12/1d/22/f04cea4c.jpg","comment_is_top":false,"comment_ctime":1618417042,"is_pvip":false,"replies":[{"id":"104701","content":"第二题答得很完美~ 💯<br><br>第一题也对。不过，结合（1&#47;N&#47;2，1&#47;N）的上下限，能再往细了说一说吗？","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1618487759,"ip_address":"","comment_id":288349,"utype":1}],"discussion_count":4,"race_medal":0,"score":"1618417042","product_id":100073401,"comment_content":"1.当executor内所有线程都在运行，实际需要内存比预估申请内存大，这个时候执行内存又不能继续扩展，就会出现oom<br>2.executor内正在运行的这批任务执行完，下一批任务被执行前，就进行资源调整。根据此时执行内存大小&#47;min(待分配任务数，executor.cores)进行内存分配","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":518597,"discussion_content":"第二题答得很完美~ 💯\n\n第一题也对。不过，结合（1/N/2，1/N）的上下限，能再往细了说一说吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618487759,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":2840248,"avatar":"","nickname":"Geek_e1ac69","note":"","ucode":"EE0B98D91211EA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":555930,"discussion_content":"老师请问下，第二题的答案里讲的分批执行完具体是什么意思？假设executor有2个core，是等着两个任务都执行完了，再去资源调整？还是执行完其中一个任务后，下一个任务执行前就去资源调整","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1647132592,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":518597,"ip_address":""},"score":555930,"extra":""}]},{"author":{"id":1187106,"avatar":"https://static001.geekbang.org/account/avatar/00/12/1d/22/f04cea4c.jpg","nickname":"Fendora范东_","note":"","ucode":"63EE9DBEE08D70","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":367887,"discussion_content":"第一题:参考了磊哥其他留言下的回答，有几个疑问:\n1.内存分配就是均分，范围是[1/2n,1/n]，只是我们自己要保证数据分片的大小也要落到这个区间，以此来保证分配给task内存是够用的。那这块就有问题，我理解数据分片是磁盘存储的压缩大小，一解压不就大于上面那个区间范围了吗？\n2.task拿到可运行所需内存下限时，大概率中间某个过程就需要更多内存。所以这个时候task被挂起还是oom改如何抉择呢？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618491462,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":1187106,"avatar":"https://static001.geekbang.org/account/avatar/00/12/1d/22/f04cea4c.jpg","nickname":"Fendora范东_","note":"","ucode":"63EE9DBEE08D70","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":369114,"discussion_content":"都是好问题，思考的很细致~ 咱们一个个说：\n1. 我们算并行度的时候，预估每个分片大小，应该是内存中的存储大小。对于从磁盘读取分布式文件的情况，我们之前介绍过怎么计算它在内存中的存储大小。另外，还有一种快捷方式，就是通过Spark UI来预估“磁盘文件在内存中的膨胀系数”，有了这个系数，大概就能算出磁盘数据在内存会翻多少倍。这个预估方法是：Memory Expansion Rate ≈ Shuffle spill (memory) / Shuffle spill (disk)\n\n2. OOM，task已经开始执行，如果中途申请内存被拒，就直接抛OOM了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618930565,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":367887,"ip_address":""},"score":369114,"extra":""}]}]},{"had_liked":false,"id":288240,"user_name":"王天雨","can_delete":false,"product_type":"c1","uid":2531597,"ip_address":"","ucode":"C2E4D769DA0BFA","user_header":"","comment_is_top":false,"comment_ctime":1618375594,"is_pvip":false,"replies":[{"id":"104641","content":"单个Executor的内存和核数，M和N，都是一个Executor内的范畴，方便理解和讨论~","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1618394334,"ip_address":"","comment_id":288240,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1618375594","product_id":100073401,"comment_content":"请问M 和 N 分别对应的是单个Executor的内存和核数，还是针对某个spark任务分配的总Executor数量和核数呢","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":518559,"discussion_content":"单个Executor的内存和核数，M和N，都是一个Executor内的范畴，方便理解和讨论~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618394334,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":288236,"user_name":"Fendora范东_","can_delete":false,"product_type":"c1","uid":1187106,"ip_address":"","ucode":"63EE9DBEE08D70","user_header":"https://static001.geekbang.org/account/avatar/00/12/1d/22/f04cea4c.jpg","comment_is_top":false,"comment_ctime":1618374917,"is_pvip":false,"replies":[{"id":"104642","content":"是啊，你说的没错，M&#47;2N，M&#47;N&#47;2，一个意思哈~","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1618394373,"ip_address":"","comment_id":288236,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1618374917","product_id":100073401,"comment_content":"磊哥，每个线程分配内存下限  我理解应该是M&#47;2N呢？","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":518558,"discussion_content":"是啊，你说的没错，M/2N，M/N/2，一个意思哈~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618394373,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]}]}