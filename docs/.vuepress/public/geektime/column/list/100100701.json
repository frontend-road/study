[{"article_id":464540,"article_title":"开篇词｜时至今日，如何更好地拥抱现代 C 语言？","article_content":"<p>你好，我是于航，目前在 PayPal 做软件研发与技术管理工作。</p><p>也许一些同学对我比较熟悉，我之前曾在极客时间开设过一门《WebAssembly 入门课》，并且还是多个 WebAssembly、C++ 相关每日一课视频的作者。而今天，我又设计了一门新课，想要带你从不同的视角来学习 “C” 这门语言。</p><p>我相信来学习这门课的大部分同学，都或多或少接触过一些 C 语言的基础知识。但是，我认为掌握 C 语言的基本语法并不困难，更重要的是能够灵活、高效地使用这门语言，并<strong>通过观察语言背后机器的执行细节，来深入了解关于编译优化、程序执行，以及计算机体系结构等其他相互关联的知识</strong>。</p><p>作为 WebAssembly 技术的研究者和使用者，C 语言是我在工作中使用最多的语言之一。由于C 语言语法简单、抽象层次较低，我能够通过它在进行原型验证时精确地控制程序的运行状态。另一方面，在接触操作系统、Unix 系统编程、语言运行时，以及系统库等相关内容时，我更深切地感受到了解 C 语言对于深入理解这些内容的重要性。</p><p>因此，这门课将不会介绍 C 语言的语法细节，而是结合 C 核心语法、汇编代码，以及计算机体系结构等相关知识，来<strong>讲述 C 语言、应用程序和操作系统三者之间的协作关系。</strong></p><!-- [[[read_end]]] --><h2>C 语言过时了吗？</h2><p>说到学习 C 语言，很多人都会有这样的问题：在新编程语言层出不穷的今天，C 语言已经诞生了这么久，会不会马上就要过时了？</p><p>对此，我的回答是：C 语言还远远没有过时，相反，学习 C 语言是非常有必要的。</p><p>从下图（图片来自<a href=\"https://www.tiobe.com/\">https://www.tiobe.com/</a>）中可以看到，自 2000 年以来，C 语言便一直处于 TIOBE 编程语言榜单的前两名。作为全球最知名的，反映编程语言热门程度的榜单，TIOBE 指数直接表明了哪些语言是应该被及时掌握的。它对世界范围内编程语言的整体走势有着重要意义。</p><p><img src=\"https://static001.geekbang.org/resource/image/ff/6c/ff57cf6e07a0eedd938c2e7c7e43fd6c.png?wh=1866x922\" alt=\"图片\"></p><p>不仅如此，C 语言本身也处在不断的“进化”过程中。下图展示了 C 语言诞生至今的几次重大版本的发布内容。可以看到，C 语言在发展的同时也在尽可能保持着自身的精简。而最近 C2x 标准草案的制定也证明了时至今日的 C 语言，仍然“老当益壮”。</p><p><img src=\"https://static001.geekbang.org/resource/image/08/a7/0858b40f96d674c2a525085a948b7fa7.jpg?wh=1920x898\" alt=\"图片\"></p><p>总之，C 语言远远没有过时。其实，<strong>C语言问世几十年来，一直都是使用最广泛的编程语言之一。</strong></p><p>作为一种静态编译型语言，C 语言有着其自身所适合的应用场景。确实，我们无法使用它来编写 Web 应用，也无法使用它来高效快捷地构建深度学习应用。但你要知道的是，用于支持这些应用正常运行的系统组件，乃至操作系统内核，都是使用 C 语言编写的。<strong>现如今，这个世界上几乎所有重要的软件都与 C 有着直接或间接的关系。</strong></p><p>C 语言被广泛应用于实现操作系统、嵌入式系统应用、编译器、数据库、驱动程序，以及服务器应用等较为底层和基础的系统级程序。除此之外，C 语言在诸如数值计算、工业控制、物联网，乃至科研领域也有着重要的应用。</p><p><img src=\"https://static001.geekbang.org/resource/image/7a/b3/7a6e97e3d9c806fyy15a2a619d6c2cb3.jpg?wh=1920x1853\" alt=\"图片\"></p><p><strong>那么，为什么C语言使用如此广泛呢？</strong>我认为原因有两个，一是它有着远优于大部分其他语言的程序精确控制能力，二是它高效的运行时性能。</p><h3><strong>精确控制程序</strong></h3><p>C 语言在设计上对平台独立的低层次汇编指令进行了适度的抽象，在大多数情况下，它的代码可以直接映射到硬件平台上的机器指令。因此，我们能够更加灵活地控制程序的具体表现行为。</p><p>我们来看个例子吧。使用 C 语言，我们甚至可以直接控制代码中某个变量值的存放位置，视情况来决定将它存放在栈内存中，还是寄存器中。如下图所示，这里，左右两个窗口中相同背景颜色的代码行，表示了 C 代码与其对应的汇编代码。可以看到，左侧 C 代码中第三行变量 <code>x</code> 的值被存放到了 <em>ebx</em> 寄存器中。</p><p><img src=\"https://static001.geekbang.org/resource/image/91/e7/91de0a9b1f989a6f4539303bb8ecf5e7.png?wh=1920x1063\" alt=\"图片\"></p><p>在某些特殊场景下，我们甚至可以直接在 C 代码中嵌入汇编代码，以更细粒度的方式来控制程序的执行，或直接与更底层的硬件进行交互。比如在下面这段代码中，我们使用 <code>asm</code> 关键字嵌入了两行汇编代码，你能猜出它们做了什么吗？可以在评论区留下你的答案。</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\nint main(void) {\n  int src = 1;\n  int dst;\n  asm (\"mov %1, %0\\n\\t\"\n&nbsp; &nbsp; &nbsp; &nbsp;\"add $1, %0\"\n&nbsp; &nbsp; &nbsp; &nbsp;: \"=r\" (dst)\n&nbsp; &nbsp; &nbsp; &nbsp;: \"r\" (src));\n  printf(\"%d\\n\", dst);\n}\n</code></pre><p>C 语言更贴近底层硬件的这一特征，就使得<strong>它非常适合被应用在需要细粒度控制资源，或与底层硬件打交道的场景中</strong>。实际上，这其中有很多优秀项目都是你所熟知，甚至在日常工作中都会经常使用到的。比如代码版本管理工具 Git、高性能 Web 服务器 Nginx、高性能 NoSQL 数据库 Redis，以及最知名、代码行数最多的开源项目 Linux 内核等。因此，如果你想要读懂它们的设计、搞懂它们的原理，那了解 C 语言便是一个必不可少的过程。</p><p>需要注意的是，C 语言也保持了高级语言的部分特性，比如提供了接近于自然语言的语法和关键字，且源代码可以做到独立于机器的分发和使用。因此，使用 C 语言，我们既能享受到它作为高级语言时的自然语法和特性，又能够做到同低级语言一样，精确地控制程序的执行细节，甚至直接与硬件交互。</p><h3><strong>高效的运行时性能</strong></h3><p>很明显，使用 C 语言正确实现的程序可以享受到最高的运行时性能。而通过内联汇编，它甚至可以与直接编写的汇编代码相比肩。</p><p>需要注意一点：和其他语言不同，C 并未提供语言内置的诸如垃圾回收（GC）等可能导致额外运行时开销的特性。在提升了性能的同时，你也需要正确处理内存的分配与回收过程，以避免出现诸如内存泄露等问题。在这门课里，我会为你介绍如何正确地编写 C 代码，来避免类似的问题。</p><h2>学习 C 语言，为什么是你修炼编程内功的必经之路？</h2><p>这时候，有同学可能会问了：我并不想做嵌入式、操作系统这些底层开发，平时的开发工作感觉 Java、Go 这些语言也够用了，为什么还要学习 C 语言呢？</p><p>对此我想说的是：即使你不使用 C 语言进行开发，深入学习 C 语言，也是你修炼内功、成为编程和计算机高手的必经之路。</p><p>为什么这么说呢？主要有三个原因。</p><p>第一，C 语言作为一门简单通用的早期编程语言，是 Go、Objective-C、C#、Java 这些高级编程语言在设计时所参考的<strong>“原型”语言</strong>。可以说，C 语言就是众多编程语言中的“九阳神功”，相信在你深入了解 C 语言后，再去学习其他语言，也会变得轻松许多。</p><p>第二，我们上面也提到过，C 语言是目前众多流行操作系统、编译器、上层实用软件与各类系统组件，乃至嵌入式开发所使用的源语言。因此，学习 C 语言也让我们具有了能够去<strong>探索优秀软件内部实现细节</strong>的能力，而这通常也是优秀工程师提升自我实力的一种快捷方式。</p><p>第三，C 语言的抽象程度非常低，是最适合用来帮助理解计算机系统底层运作机制的语言。在学习如何高效使用 C 语言的过程中，你将会学习到有关高速缓存、内存、寄存器，以及函数调用等相关的内容，而这无疑对你提升自身实力有着巨大的帮助。总之，<strong>深入学习 C 语言之后，我们就拥有了从“更低纬度”理解计算机运作机制的能力。</strong></p><p>网上流传的一个不太恰当的比喻是：学习 C 语言正如我们通过学习营养学、健康学来为自己合理地制定饮食计划。当然我们也可以选择直接购买市面上已经装配好的各类营养餐品，但当身体状况并没有按预期发展时，我们并不清楚问题出在哪里。并且，当需要实现一些特殊的定制化需求时，可能市面上的产品功能总会与我们的目标有所出入。</p><p>编程也是如此，相较于直接使用诸如 Python、Java 等高抽象粒度的编程语言，学习 C 语言能够让你从基础层面了解程序是如何工作的。<strong>理解了计算机系统的底层运作机制，你在设计更复杂、性能更高的程序时，便能够得心应手、融会贯通。</strong></p><p>所以，要想深入理解计算机系统的运行原理，学习 C 语言是一个必经之路。</p><h2>这门课是怎么设计的？</h2><p>为了达到灵活、高效地使用 C 语言，并借此深入理解计算机系统运行原理的目的，只掌握 C 语言的基本语法是远远不够的。我们还需要<strong>深入到 C 语言的内部，去了解⼀个 C 程序从编写到编译，再到被运⾏的整个流程细节</strong>。只有做到“知其然”并“知其所以然”，方能运用自如，百战不殆。</p><p>为了做到这一点，我们将从 C 语言的核心语法开始，先来了解编译器是如何在机器指令层面实现它们的。紧接着，我们会把目光移到标准库。标准库是扩展 C 语言功能的一大利器，我们将会介绍现代 C 语言标准库中的一些重要功能，以及这些功能背后的运作机制。除此之外，如何利用计算机体系结构来编写高性能的 C 代码，也是工程化相关的重要内容。然后，随着 C 代码被编译，我们将会探讨二进制可执行程序是如何在与操作系统的协同工作下被运行的。经过这几个步骤后，你将会对一个 C 程序的完整生命周期有着更深刻的理解。</p><p><img src=\"https://static001.geekbang.org/resource/image/a0/73/a034ffbd985827d70e485b5ae9fe2b73.jpg?wh=1920x762\" alt=\"图片\"></p><p>基于这个思路，这门课主要分为四个模块。</p><p>第一个模块是“<strong>前置篇</strong>”，我将为你讲解一些学习这门课所需要的基础知识。我们的课程中涉及到了有关计算机体系结构、汇编语言等较为底层的内容，因此我为你设计了一讲“课前热身”，向你简单介绍与基本数据量单位、汇编语言，以及指令集寄存器有关的内容。在这一模块中，我还会用一段相对复杂的代码作为例子，来带你回顾 C 语言的核心语法，并介绍 C 程序从编写到运行的基本步骤。</p><p>第二个模块是“<strong>C 核心语法实现篇</strong>”。我会梳理 C 语言 7 大核心语法“背后的故事”，带你了解编译器如何在汇编层面实现这些语法。学完这个模块，你会对 C 程序的运行细节有着更深刻的理解，从而更好地掌握并优化程序运行。</p><p>第三个模块是“<strong>C 工程实战篇</strong>”。在这个模块中，你会学习到 C 语言在大型工程实战中的必备技巧，主要包括：快速掌握 C 标准库的重要功能，以及这些功能背后的实现原理；掌握编写高性能 C 代码、编码规范、结构化测试、结构化编译这些 C 项目工程化的实用技巧。</p><p>第四个模块是“<strong>C 程序运行原理篇</strong>”。我会为你介绍一个 C 程序是如何通过编译，并最终被操作系统运行的。程序的运行涉及到众多与操作系统的交互细节，你将在这个模块里详细了解它们。</p><p><img src=\"https://static001.geekbang.org/resource/image/7e/96/7ed08b6a5154f8c83fab3bca39a23296.jpg?wh=1563x5870\" alt=\"图片\"></p><p>这门课涉及的内容，我都是基于 x86-64 平台下的 Linux 系统进行介绍的。当然，对于 macOS 和 Windows 系统来说，某些细节会有所不同，但基本原理是相通的。</p><p>时至今日，C 语言作为最“古老”的编程语言之一，仍然“老当益壮”、生生不息。这一切靠的不是巧合，而是绝对的实力。<strong>而要发挥 C 语言的最大威力，我们就不应该只简单了解它的语法，而应该在此基础上进一步了解代码如何被编译，程序如何被运行。</strong>只有当完整的“链路”建立在脑海中时，你才对程序有了最完全的把控。那接下来，就跟我来一趟不一样的 C 语言之旅吧！</p>","neighbors":{"left":[],"right":{"article_title":"课前热身｜学习这门课前，你需要了解哪些知识？","id":464543}}},{"article_id":464543,"article_title":"课前热身｜学习这门课前，你需要了解哪些知识？","article_content":"<p>你好，我是于航。</p><p>在我们正式进入到 C 语言课程的学习之前，为了帮助你更好地理解课程内容，我为你准备了一节基础知识讲解课。这是一节选学课，你可以根据自己的实际情况选择性学习。</p><p>在这一讲中，我会用通俗易懂的方式，为你介绍这门课中最常用的一些基础知识，分别是常见数据量单位、汇编语言，以及 CPU 指令集中涉及的不同类型的寄存器。如果你对这些内容还不太熟悉，那么通过这一讲，你可以对它们有一个大致的印象。我们后面的课程还会提到汇编指令或寄存器，我会视情况进行更加具体的讲解，帮你加深理解。</p><h2>数据量单位：位、字节和字</h2><p>位（bit）是计算机中最小的存储单位，每一个位可以存储一个二进制码值的 0 或 1。而字节（byte）则通常是由八个位组成的一个存储单元。在计算机中，字节是最小的可寻址单位，这意味着 CPU 在使用数据时，可以以字节为单位，为每一字节内存分配一个相应的独立地址。</p><p>位和字节是在我们的日常工作中最为常见的两个数据量概念，你应该很熟悉。不过，字（word）的概念就没有这么清晰了。字的大小并不固定，一个字的大小可能是 2 的幂次个位，比如 16 位、32 位，也有可能是 12 位、27 位等一些并不常见的大小。而这主要是因为字的概念与具体的处理器或硬件体系架构直接相关，它跟位、字节这种较为通用和统一的数据量概念并不相同。</p><!-- [[[read_end]]] --><p>字是处理器设计时使用的自然数据单位，通常，这个大小会反映在计算机结构和相关操作的多个方面中。比如，处理器中大多数寄存器的容量是与字同样大小的，处理器单个指令可以操作的最大内存块一般为一个字大小，而用于指定内存中某个具体位置的地址，一般也是以处理器的自然字为宽度的。</p><p>需要说明下，在这门课后面的内容中，<strong>所有给出的示例代码和相关分析，都是在平台类型为 x86-64 的实验机上进行的，而该平台的字长为 64 位。</strong></p><h2>汇编语言</h2><p>在计算机编程中，汇编语言（Assembly Language）是一种低级编程语言，语言使用的指令与具体平台紧密相关。这意味着，针对不同 CPU 体系架构设计的汇编语言无法共用，也不具备可移植性。</p><p>汇编代码可以经由汇编程序（如 as）进行转换，从而得到二进制的可执行代码。不同于高级编程语言，汇编语言在机器指令之上基本不具有任何抽象。因此，通过观察一个程序的汇编代码，我们可以详细了解到程序运行时的每一个具体步骤。所以，<strong>在这门课中，我们会通过汇编代码来观察 C 语法的实现细节，并同时探索程序运行时与操作系统交互的一些关键步骤。</strong></p><p>汇编语言使用助记符（Mnemonic）来表示每个低级的机器指令。助记符是一类带有自然语义的符号，比如 <code>mov</code> 指令，它是英文单词 “move” 的简写，这个指令用来将一个操作数从计算机中的某个位置移动到另一个位置。而 <code>add</code> 指令的语义就更加直观了，它用来将计算机中某个位置上的数据量累加到另一个数据量上。</p><p>不同的汇编指令可以使用不同的参数形式。比如，就 <code>mov</code> 指令来说，对于可以使用该指令来移动的数据，它们通常会位于计算机中三个不同的位置上：</p><ul>\n<li><em><strong>MOV r/m, r</strong></em></li>\n<li><em><strong>MOV r, r/m</strong></em></li>\n<li><em><strong>MOV r/m, imm</strong></em></li>\n</ul><p>在这些指令的参数中，r 表示 register，即寄存器；m 表示 memory，即内存中的某个具体位置；imm 表示 immediate，即直接书写在指令中的立即数。</p><p>为了跟这门课后续的内容保持一致，这里我们直接使用 x86-64 平台，并基于 Intel 指令集的方式来书写和解读汇编代码。因此，指令 <code>mov ebx, 1</code> 的正确含义是：将立即数 1 存放到寄存器 ebx 中（右侧参数为数据来源 src，左侧参数为移动的目的地 dest）。需要注意的是，在 x86 指令集中，受限于 CPU 实现的复杂度，不存在可以将两个内存地址同时作为 src 和 dest 参数的指令。</p><p>汇编指令由助记符组成，而汇编器则负责把这些助记符组成的有效语法格式转换成对应的二进制机器指令。比如就上面提到的汇编指令 <code>mov ebx, 1</code> 而言，它所对应的机器指令代码为二进制值 <code>bb 01 00 00 00</code> 。</p><p>与汇编代码不同的是，二进制机器指令代码的组成结构要复杂许多。上面的汇编指令对应的机器指令是由 OpCode 和 Immediate Data 两部分组成的。OpCode 在这里占用一个字节，这个字节是由指令对应的 0xb8 ，外加特定目的寄存器对应的寄存器域值 0x3 组成的。而紧跟着 OpCode 的，便是立即数 1 对应的部分。由于该指令用于传送 32 位数，因此立即数这里单独占用 4 个字节。需要注意的是，对于这段机器指令代码，最左侧的字节 0xbb 处在内存的低位（即小端序）。</p><p>在较为复杂的机器指令中，还可能包含有与 ModR/M、SIB、Displacement 以及 REX 等有关的信息。而这些信息有些并不会直接体现在上层的汇编代码中，它们大多仅与当前平台 CPU 的体系架构，或操作系统所处的模式有关。</p><h2>指令集中的寄存器</h2><p>在编写汇编语言代码时，我们经常会跟寄存器打交道。那么，什么是寄存器呢？</p><p>寄存器有时也被称为“寄存器文件（Register File）”，你可以把它简单理解为由 CPU 提供的一组位于芯片上的高速存储器硬件，可用于存储数据。通常来说，寄存器可以使用 SRAM 来实现。SRAM 是一种高速随机访问存储器，它将每个位的数据存放在一个对应的“双稳态”存储器中，从而保持较强的抗干扰能力和较快的数据访问速度。在整个计算机体系架构中，<strong>寄存器拥有最快的数据访问速度和最低的延迟</strong>。</p><p>通常来说，我们在汇编代码中使用的寄存器（比如之前提到的 ebx）可能并不与 CPU 上的物理寄存器完全一一对应，CPU 会使用额外的方式来保证它们之间的动态对应关系。这些参与到程序运行过程的寄存器，一般可以分为：通用目的寄存器、状态寄存器、系统寄存器，以及用于支持浮点数计算和 SIMD 的 AVX、SSE 寄存器等。</p><p>在这些寄存器中，通用目的寄存器一般用于存放程序运行过程中产生的临时数据，这些寄存器在大多数情况下都可以被当作普通寄存器使用。而在某些特殊情况下，它们可能会被用于存放指令计算结果、系统调用号，以及与栈帧相关的内存地址等信息。状态寄存器一般用于存放与指令执行结果相关的状态信息，比如指令执行是否引起进位、计算结果是否为 0 等。系统寄存器一般由操作系统使用，这些寄存器描述了与虚拟内存、中断、CPU 模式等有关的信息。</p><p>在 x86-64 架构下，CPU 指令集架构（ISA）中一共定义了 16 个通用目的寄存器。这些寄存器最大可以存放 4 个指令字，即 64 位长的数据。需要注意的是，<strong>这里我们提到的“指令字”与之前介绍的用于描述 CPU 硬件特征的“硬件字”有所不同</strong>（指令字与硬件字这两个叫法只是我用来区分这两种字概念的）。由于历史原因，在现代 x86 系列 CPU 的指令集文档中，你可能会看到对 WORD 一词的使用。虽然这个单词可以被翻译为“字”，但在这样的环境下，它实则代表着固定 16 位的长度。关于它的具体使用方式，我会在 <a href=\"https://time.geekbang.org/column/article/466203\">03 讲 </a>中详细介绍。</p><p>在汇编代码中，我们可以使用每个寄存器不同部分对应的别名，来针对性地访问它们的低 8 位、低 16 位、低 32 位，以及完整的 64 位数据。关于这些寄存器的具体名称，你可以参考下面这张图：</p><p><img src=\"https://static001.geekbang.org/resource/image/ed/0b/ed27329a1fb82df016d60a196yybb00b.jpg?wh=1920x2474\" alt=\"图片\"></p><p>这张图怎么看呢？这里以我们之前遇到的 ebx 寄存器为例：观察上图可以得知，通过 ebx，我们可以访问大小为 32 位的数据，该数据为寄存器 rbx 的低 32 位。因此，直接使用 rbx 便可访问该寄存器的全部 64 位数据。而使用 bx 与 bl ，便可相应访问该寄存器的低 16 位与低 8 位数据。</p><p>另外，还需注意的一点是：我们可以通过不同的寄存器别名来读写同一寄存器不同位置上的数据。当某个指令需要重写寄存器的低 16 位或低 8 位数据时，寄存器中其他位上的数据不会被修改。而当指令需要重写寄存器低 32 位的数据时，高 32 位的数据会被同时复位，即置零。</p><p>听到这里，你可能觉得理解起来有些困难，不用担心，在课程的后面我还会多次介绍有关寄存器的内容。你可以先试着在 x86-64 平台上使用 GNU GCC 编译和运行下面这段代码。这里注意，在编译时不要为编译器指定任何优化参数。</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\nint main(void) {\n  register long num asm(\"rax\") = 0x100000000;\n  asm(\"movl $0x1, %eax\");\n  // asm(\"movw $0x1, %ax\");\n  printf(\"%ld\\n\", num);\n  return 0;\n}\n</code></pre><p>这样，你就可以看到，当指令作用于寄存器的不同部分时，CPU 对寄存器其他部分的影响。这里我们将值 0x100000000 放入寄存器 rax 中，在该 64 位值（long）对应的二进制编码中，其第 32 位被置位。第一句汇编指令将值 0x1 通过 <code>movl</code> 移动到 rax 寄存器的低 32 位；而第二句汇编指令将值 0x1 通过 <code>movw</code> 移动到 rax 寄存器的低 16 位。那么，通过这两种方式分别处理后的变量 <code>num</code> 的值是否相同呢？你可以自己进行实践，并在评论区留下答案。</p><p>随着课程的学习，你会看到这门课给出的示例代码中，存在着大量对这些通用寄存器的使用过程。而如何高效、有序地分配和使用寄存器，是编译器的重要任务之一，你会在后面的课程中了解到编译器在使用不同优化等级时对待寄存器的区别。</p><h2>总结</h2><p>讲到这里，今天的内容也就基本结束了。最后我们来一起总结下吧。</p><p>今天我主要介绍了常见数据量单位、汇编语言，以及指令集中寄存器的相关知识，希望这些基础知识能够为你接下来的学习提供一些帮助。</p><p>常见数据量单位包括位、字节和字。其中，一个字节等于 8 位，而字的大小则与具体的 CPU 体系结构紧密相关，常见大小可以是 32 位与 64 位。</p><p>汇编语言是一种低级编程语言，它用助记符的形式来描述程序对应机器指令的基本逻辑。由于它直接对应于 CPU 指令集之上，因此不具有可移植性。</p><p>寄存器是位于 CPU 芯片上的高速数据存储单元，根据功能，它可以被分为通用目的寄存器、状态寄存器等多种类型。x86-64 一共提供了 16 个通用目的寄存器，通过在汇编代码中使用不同的寄存器别名，我们可以快速访问这些寄存器中存放的数据。</p><h2>思考题</h2><p>这里，我们来一起做个思考题，巩固下今天的学习内容吧。</p><p>阅读下面的汇编代码，并尝试分析：当所有指令执行完毕时，寄存器 eax 中的值是多少？</p><pre><code class=\"language-c++\">mov eax, 0x1\ninc eax\nsub eax, 10\nxor eax, eax\nadd eax, 1\nmul eax\n</code></pre><p>这节选学课到这里就结束了，希望可以帮助到你，也希望你在下方的留言区和我交流讨论。如果这节课对你有帮助，也欢迎你把它分享给你的朋友或者同事。</p>","neighbors":{"left":{"article_title":"开篇词｜时至今日，如何更好地拥抱现代 C 语言？","id":464540},"right":{"article_title":"01｜快速回顾：一个 C 程序的完整生命周期","id":464550}}},{"article_id":464550,"article_title":"01｜快速回顾：一个 C 程序的完整生命周期","article_content":"<p>你好，我是于航。</p><p>在深入了解 C 语言、做到“知其所以然”之前，我们需要先做到“知其然”，也就是知道 C 语言是如何使用的。所以这一讲，我会从语法细节和语言特性、微观和宏观相结合的角度，带你快速、直观地回顾 C 语言的一些基础内容。而通过本讲的学习，你也会更容易理解这门课接下来的内容。</p><p>首先，我会带你回顾一个 C 程序从源代码编写到编译，再到最后运行的完整过程。除此之外，我还会用一段相对复杂的示例代码，来带你快速回顾 C 语言中最常见的那些语法及使用方式。最后，我们还会从语言本身的角度，来探讨 C 语言与其他编程语言在编程范式上的不同之处。</p><h2>学习这门课，需要怎样的实践开发环境？</h2><p>在开始回顾这些内容之前，我要先向你推荐一些学习这门课时会用到的开发工具。你可以利用这些工具，自行编译和运行课程中给出的示例代码，以加深你对课程内容的理解。</p><p>对于编译工具，这门课会穿插使用运行于 x86-64 平台的 GCC 11.2 或 Clang 13.0.0 版本编译器。市面上有很多成熟的 C 编译器可以选择，但不同的编译器可能存在着所支持平台（类 Unix、Windows）以及 C 标准（C89、C99、C11、C17）上的差异，因此在选择时需要特别注意这些问题。这门课里使用的 GCC 和 Clang 都支持 C 语言的最新标准 C17，并且都可以运行在类 Unix 与 Windows 系统上。</p><!-- [[[read_end]]] --><p>当然，如果你在本地环境中没有安装上面这些编译器，那么也可以直接使用云编译器，比如 <a href=\"https://godbolt.org\">Godbolt</a>。相较于本地编译器，云编译器即开即用，而且可以随时灵活切换不同的编译器版本。</p><p>至于 IDE，那些常用的都可以，不过推荐你选择 Visual Studio Code，因为它较为轻量，且目前提供的插件能力也足够进行 C 语言开发。最后，这门课里出现的所有代码，我都会统一放在<a href=\"https://github.com/Becavalier/geektime-c\">这个代码库</a>中，你可以根据需要自行获取。</p><h2>用一个程序快速回顾 C 核心语法</h2><p>为了让你比较完整地回顾 C 语言的核心语法，我设计了一个相对复杂的 C 语言程序作为例子。在这里，你可以先试着阅读这段代码，思考下 C 语言的使用方式。代码如下所示：</p><pre><code>#include &lt;stdlib.h&gt; \n#include &lt;stdio.h&gt;\n#include &lt;stdint.h&gt;\n#include &lt;assert.h&gt;\n#include &lt;stdbool.h&gt;\n\n#define BOOL_TRUE 1  // 定义用到的宏常量与宏函数；\n#define BOOL_FALSE 0\n#define typename(x) _Generic((x), \\\n  unsigned short: &quot;unsigned short int&quot;, \\\n  unsigned long: &quot;unsigned long int&quot;, \\\n  default: &quot;unknown&quot;)\n\ntypedef enum { Host, IP } IP_ADDR_TYPE;  // 定义枚举类型 IP_ADDR_TYPE，用于表示联合中生效的字段；\ntypedef struct {  // 定义结构 CONN；\n  size_t id;\n  uint16_t port;\n  bool closed;\n  IP_ADDR_TYPE addr_type;\n  union {\n    char host_name[256];\n    char ip[24];\n  };\n} CONN;\n\ninline static const char* findAddr(const CONN* pip) {  // 定义函数 findAddr，用于打印 CONN 对象的信息；\n  assert(pip != NULL);  // 运行时断言，判断传入的 CONN 指针是否有效；\n  return pip-&gt;addr_type == Host ? pip-&gt;host_name : pip-&gt;ip;\n}\n\nint main(int argc, char* argv[]) {  // 入口函数；\n  static_assert(sizeof(CONN) &lt;= 0x400, &quot;the size of CONN object exceeds limit.&quot;);  // 静态断言，判断 CONN 对象的大小是否符合要求；\n  const CONN conns[] = {  // 构造一个数组，包含三个 CONN 对象；\n    [2] = { 1, 80, BOOL_TRUE, IP, { .ip = &quot;127.0.0.1&quot; } },\n    [0] = { 2, 8080, BOOL_FALSE, IP, { .ip = &quot;192.168.1.1&quot; } },\n    { 3, 8088, BOOL_FALSE, Host, { .host_name = &quot;http://localhost/&quot; } }\n  };\n\n  for (size_t i = 0; i &lt; (sizeof(conns) / sizeof(CONN)); ++i) {  // 遍历上述 CONN 数组，并打印其中的内容；\n    printf(\n      &quot;Port: %d\\n&quot;\n      &quot;Host/Addr: %s\\n&quot;\n      &quot;Internal type of `id` is: %s\\n\\n&quot;,\n      conns[i].port,\n      findAddr(&amp;conns[i]),\n      typename(conns[i].id)\n    );\n  }\n  return EXIT_SUCCESS; \n}\n</code></pre><p>这段代码用到了横跨 K&amp;R C 到 C17 标准的许多语言特性，创建了多个基于自定义类型构建的对象，并在程序的最后将这些对象的相关信息打印了出来。</p><p>下面，就来跟着我一起梳理这段代码中用到的 C 语法特性吧。我会按照程序代码的执行顺序，来分别介绍每一个执行步骤中涉及到的关键语言知识点。其中，相关的语言结构和语法特性可以被分为下面这些类别。</p><h3>入口函数</h3><p>现在，让我们来仔细观察这个程序。首先，我们的目光来到第 31 行上名为 main 的函数。</p><p>所有的 C 程序都会使用 main 函数作为入口函数。入口函数，就是指程序开始运行时，代码中会被首先调用的那个函数。在 main 函数中，我们可以通过它接收到的实际参数，来选择性地访问程序在开始运行时，由用户传递给程序的外部参数。</p><p>main 函数在执行结束时会返回一个整数，用于表示程序执行完毕时的状态，通常返回数字 0 表示程序正常退出，返回其他数字则代表异常退出。为了保持代码的可读性，这里我们使用标准库中定义的宏常量 EXIT_SUCCESS ，作为程序退出的返回值。顾名思义，这个宏常量对应的实际值就是数字 0。</p><h3>数组</h3><p>接下来，我们来到第 33 行。可以看到，在 main 函数内部，我们使用了“括号列表（brace-enclosed lists）”的方式，完成了对数组 conns 的初始化过程。</p><p>而在初始化列表中，我们还使用了指派初始化（为初始化列表中的项设定“指派符”）的方式，来明确指定这些项在数组中的具体位置。比如这里第一项对应的 “[2]” ，就表示将该项设置为数组 conns 中的第 3 个元素（索引从 0 开始）。</p><p>数组定义完毕后，第 44 到第 46 行的代码访问了其内部存放的元素。这里我们直接使用方括号加索引值的语法形式做到了这一点。</p><h3>结构与联合</h3><p>数组 conns 内部，存放有若干个类型为 CONN 的结构对象。在 C 语言中，结构和联合（有时也被称为结构体与联合体）通常用来组织复杂类型的自定义数据。在结构中，所有定义字段的对应数据按照内存连续的方向排列；而在联合中，定义的字段同一时间只会有一个“生效”。</p><p>观察第 15 行到 24 行，可以看到：在我们对结构 CONN 的定义过程中，使用了来自 C99 标准的 <code>_Bool</code> 类型（这里的宏 bool 会展开为该类型），以及来自 C11 标准的匿名联合体。</p><p>第 34 到第 36 行，在我们对结构 CONN 对象的初始化过程中，也同样使用了类似数组的括号列表初始化，以及指派初始化。但和前面数组初始化不同的是，这里的指派是针对结构与联合类型内部的成员字段的，因此需要使用 “.” 符号来引用某个具体成员，而非数组所使用的形式。</p><h3>控制结构</h3><p>在这段代码的第 39 行，我们使用了 for 语句以循环的形式遍历了数组 conns 中的内容。除此之外，C 语言中常用的控制结构还有 switch 语句、while 语句、以及 goto 语句等等。这些语句分别以选择、迭代，及跳转这三种不同方式控制着程序的实际执行逻辑。而程序本身也可以在这些控制语句的灵活组合下变得更加复杂。</p><h3>指针</h3><p>指针是 C 语言中最危险但也最强大的“武器”之一。借助指针，我们能够灵活地操控程序享有的内存资源。</p><p>在上面代码的第 45 行，我们将数组 conns 中各个元素的地址传递给了函数 findAddr，而该函数则接收一个指向 CONN 类型对象的常量指针。所以，通过该指针，我们无法在函数内部修改指针所指向对象的值。而这在一定程度上保证了函数仅能够拥有足够完成其任务的最小权限。</p><h3>宏</h3><p>编译器对 C 源代码的处理过程分为几个阶段，其中，宏是最先被处理的一个部分。在这段代码的开头处，我们通过宏指令 “#include” 引入了程序正常运行需要的一些外部依赖项，这些引入的内容会在程序编译时得到替换。随后，我们又通过 “#define” 指令定义了相应的宏常量与宏函数，而其中的宏函数 typename 则使用到了 C11 标准新引入的 <code>_Generic</code> 关键字，以用来实现基于宏的泛型。</p><h3>断言</h3><p>在这段代码的第 32 行，我们使用了 C11 标准中提供的静态断言能力，来保证结构类型 CONN 的大小不会超过一定的阈值。而在代码的第 27 行，我们还使用了运行时断言来保证传递给函数 findAddr 的 CONN 对象指针不为空。</p><p>在 C 代码中，我们通常会使用断言，来对某种需要支持程序正常运行的假设性条件进行检查。而当条件不满足时，则在程序编译或运行时终止，并向用户抛出相应的错误信息。C 语言提供静态与动态两种类型的断言，其中静态断言会在代码编译时进行检查；而动态断言则会在程序运行过程中，执行到该断言语句时再进行检查。</p><h3>函数内联</h3><p>在函数 findAddr 的定义代码中，我们为其添加了名为 <code>inline</code> 的关键字。通过使用该关键字，我们可以“建议”编译器将该函数的内部逻辑直接替换到函数的调用位置处，以减少函数调用时产生的开销。这种方式通常使用在那些函数体较小，且会被多次调用的函数上，以产生较为显著的性能提升。</p><h3>其他特性</h3><p>除了上面提到的内容，这段代码中还涉及到了一些基本的 C 语言特性：</p><ul>\n<li>使用 <code>const</code> 定义只读变量；</li>\n<li>使用 <code>typedef</code> 定义新类型；</li>\n<li>使用 <code>static</code> 声明静态函数；</li>\n<li>使用各类运算符；</li>\n<li>调用标准库函数；</li>\n<li>使用 <code>enum</code> 定义枚举类型；</li>\n<li>……</li>\n</ul><p>这些语法特性本身比较常用，且概念较为简单，这里我就不再单独介绍了。如果你对其中的一些特性感到陌生，可以选择在 <a href=\"https://www.geeksforgeeks.org/c-programming-language/?ref=ghm\">GeeksforGeeks</a>网站上直接查找特定主题并学习，或者查阅《C Primer Plus》这些入门书籍。</p><p>到这里，我们就把 C 语言的核心语法大致捋了一遍。你可以看到，C 语言的语法并不复杂。C 语言在设计上就十分精简，截止到 C17 标准，语言本身也仅有 44 个关键字。C 语言的强大并不是源于复杂的语法设计，相反，简单的语法给了 C 开发者更高的自由度，让我们可以更加灵活地设计程序的运行逻辑。</p><h2>C 语言的编程范式是怎样的？</h2><p>抛开语法细节，从总体上来看，C 语言是一种“命令式”编程语言，和它类似的还有 Java、C#、Go 等语言。</p><p>命令式编程（Imperative Programming）是这样一种编程范式：使用可以改变程序状态的代码语句，描述程序应该如何运行。这种方式更关注计算机完成任务所需要执行的具体步骤。</p><p>下面我们来看一个例子。对于“从一个包含有指定数字的集合中，筛选出大于 7 的所有数字”这个需求，按照命令式编程的思路，我们需要通过编程语言来告诉计算机具体的执行步骤。</p><p>以 C 语言为例，解决这个需求的步骤可能会是这样：</p><ol>\n<li>使用数组，构造一块可以存放这些数字的内存空间；</li>\n<li>使用循环控制语句，依次检查内存中的这些数字是否满足要求（即大于 7）；</li>\n<li>对于满足要求的数字，将它们拷贝到新的内存空间中，暂存为结果。<br>\n对应的代码可能如下所示：</li>\n</ol><pre><code class=\"language-c++\">#define ARR_LEN 5\nint main(void) {&nbsp;\n&nbsp; int arr[ARR_LEN] = { 1, 5, 10, 9, 0 };\n&nbsp; for (int i = 0; i &lt; ARR_LEN; ++i) {\n&nbsp; &nbsp; if (arr[i] &gt; 7) {\n&nbsp; &nbsp; &nbsp; // save this element somewhere else.\n&nbsp; &nbsp; }\n&nbsp; }\n&nbsp; return 0;\n}\n</code></pre><p>相对于命令式编程语言，其他语言一般会被归类为“声明式”编程语言。声明式编程（Declarative Programming）也是一种常见的编程范式。<strong>不同的是，这种范式更倾向于表达计算的逻辑，而非解决问题时计算机需要执行的具体步骤。</strong></p><p>比如说，还是刚才那个需求，在使用声明式编程语言时，对应的解决步骤可能是：</p><ol>\n<li>构建一个容器来存放数据；</li>\n<li>按照条件对容器数据进行筛选，并将符合条件的数据作为结果返回。<br>\n如果以 JavaScript 为例，对应的代码可能如下所示：</li>\n</ol><pre><code class=\"language-javascript\">let arr = [1, 5, 10, 9, 0]\nlet result = arr.filter(n =&gt; n &gt; 7)\n</code></pre><p>可以看到的是，相较于命令式编程，声明式编程更倾向于表达在解决问题时应该做什么（构建容器、筛选），而不是具体怎么做（分配内存、遍历、拷贝）。</p><p>通常来说，命令式编程语言和声明式编程语言的差异，主要体现在两者的语言特性相较于计算机指令集的抽象程度。其中，命令式编程语言的抽象程度更低，这意味着该类语言的语法结构可以直接由相应的机器指令来实现。而声明式编程语言的抽象程度更高，这类语言更倾向于以叙事的方式来描述程序逻辑，开发者无需关心语言背后在机器指令层面的实现细节。两种语言在使用上各有其适用场景，并无孰好孰坏之分。</p><p>那么，C 语言作为一种低抽象层次的命令式编程语言，它的各类语法结构是如何对应到不同机器指令的？我会在下一个模块“语法核心实现篇”里为你详细介绍。</p><h2>C 程序的编译和运行</h2><p>编写完一段 C 代码，接下来的步骤就是对这段代码进行编译了。在执行编译命令时，为了保证程序的健壮性，我们一般会同时附带参数 “-Wall”，让编译器明确指出程序代码中存在的所有语法使用不恰当的地方。</p><p>如果将那段用来回顾核心语法的 C 代码存放在名为 “demo.c” 的文件中，那我们可以使用下面这行命令来编译并运行这个程序：</p><pre><code class=\"language-bash\">gcc demo.c&nbsp;-o demo -Wall &amp;&amp; ./demo\n</code></pre><p>一般来说，C 代码的完整编译过程可以分为如下四个阶段：</p><p><img src=\"https://static001.geekbang.org/resource/image/95/c2/957691f0ac44315ebf5619d553df4ac2.jpg?wh=1920x571\" alt=\"图片\"></p><ol>\n<li><strong>代码预处理</strong>：编译器会首先移除源代码中的所有注释信息，并处理所有宏指令。其中包括进行宏展开、宏替换，以及条件编译等。</li>\n<li><strong>编译优化</strong>：编译器会分析和优化源代码，并将其编译成对应的汇编格式代码，这部分代码中含有使用汇编指令描述的原始 C 程序逻辑。</li>\n<li><strong>汇编</strong>：编译器会将这些汇编代码编译成具有一定格式，可以被操作系统使用的某种对象文件格式。</li>\n<li><strong>链接</strong>：通过链接处理，编译器会将所有程序目前需要的对象文件进行整合、设置好程序中所有调用函数的正确地址，并生成对应的二进制可执行文件。<br>\n编译结束后，我们就得到了可以直接运行的二进制文件。在不同的操作系统上，你可以通过不同的方式来运行这个程序，比如双击或通过命令行。</li>\n</ol><h2>总结</h2><p>讲到这里，今天的内容也就基本结束了，最后我来给你总结一下。</p><p>这一讲，我们通过一个实例，带你快速回顾了 C 语言的一些重要语法特性。为了方便你复习，我把这些涉及到的核心语法特性总结成了一张表格：</p><p><img src=\"https://static001.geekbang.org/resource/image/a3/16/a3797cfb319938f359812da1baf3b316.jpg?wh=1920x1783\" alt=\"图片\"></p><p>我还带你回顾了一个 C 程序的完整生命周期：代码编写、编译、运行。其中，C 代码的完整编译过程可以分为代码预处理、编译优化、汇编、链接四个阶段。程序的汇编、链接与运行，都会涉及与所在操作系统相关的一系列精细处理过程。我会在这门课的第四个模块中带你深入了解这些内容。</p><p>除此之外，我们还从语言本身的角度，探讨了 C 语言与其他编程语言的不同之处。C 语言作为一种命令式编程语言，抽象程度更低，语法结构可以直接由相应的机器指令经过简单的组合来实现。</p><h2>思考题</h2><p>最后，我们一起来做一个思考题吧。</p><p>在这一讲第一部分的 C 代码实例中，我们为何要给函数 findAddr 添加 <code>static</code> 关键字？不添加这个关键字的话，程序是否可以编译运行？欢迎在评论区分享你的思考和见解。</p><p>希望这一讲可以让你对 C 语言的基本情况有一个整体的感知。下一讲，我们会从一个 C 程序的基石，数据和量值出发，正式开始我们的 “C 语言核心语法实现”之旅，一起来看编译器是如何在背后实现这些基本语法的。我们下一讲见！</p>","neighbors":{"left":{"article_title":"课前热身｜学习这门课前，你需要了解哪些知识？","id":464543},"right":{"article_title":"02｜程序基石：数据与量值是如何被组织的？","id":465228}}},{"article_id":465228,"article_title":"02｜程序基石：数据与量值是如何被组织的？","article_content":"<p>你好，我是于航。</p><p>从这一讲开始，我们就进入到了“C 核心语法实现篇”的学习。在这一模块中，我们将围绕 C 语言的七大类核心语法，深入探寻隐藏在语法背后，程序代码的实际执行细节。</p><p>C 语言让我们能够用一种可移植、结构化，且具有人类可理解语义的方式，构建我们的程序。C 标准中详细描述了 C 语言在语法和语义两个层面的基本内容，但对于实现者，比如编译器来说，如何将这些语法和语义体现在具体的<strong>机器指令</strong>（汇编代码）上，标准并未给出详细规定。</p><p>所以问题来了：<strong>在这层抽象背后，一个 C 程序中的各类语法结构，究竟是如何映射到机器能够识别的不同指令上的？</strong>相信学完这一模块，你就能找到这个问题的答案，从而对程序的运行有更细粒度的把控。</p><p>今天，我们就从最基本的数据和量值开始。相信你在第一次接触编程这个概念时就会了解到，一个完整的程序是由“算法”与“数据结构”两部分组成的。其中，算法代表程序会以怎样的具体逻辑来运行；数据结构代表程序运行过程中涉及数据的具体组织方式。而在一门编程语言中，数据便是以不同类型“量值”的形式被组织在一起，并交由算法进行处理的。所以我们可以说，<strong>数据和量值是程序运行的基石。</strong></p><p>今天，我们先从日常使用 C 语言时最直观的编码方式开始，介绍 C 语言中的量值和数据。然后，由源代码的“表象”到计算机内部，我们来看看数据在计算机中存储时是如何被编码的。最后，我们再来一起看下，程序中的各类数据究竟被存放在哪里。</p><!-- [[[read_end]]] --><h2>C 语言中的量值与数据</h2><p>量值可以被粗略地分为变量（variable）与常量（constant），其中变量是指值可以在整个应用程序的生命周期中被多次改变的量；而常量则与之相反，在被定义后便无法被再次修改。作为一种高级语言，C 语言为我们提供了可用于定义常量与变量的语法。那么，首先我们就来看看不同的量值在 C 语言中是怎样体现的。</p><h3>变量</h3><p>C 语言为我们提供了众多的语言关键字（keyword）以用来定义相应类型的数据。比如在下面这个例子中，我们通过以下几步成功定义了多个变量：</p><ol>\n<li>使用 <code>int</code> 等关键字，来指定数据的具体类型；</li>\n<li>为该数据设置一个名称；</li>\n<li>通过 “=” 赋值运算符为该数据设定具体的值。</li>\n</ol><pre><code class=\"language-c++\">int x = -10;&nbsp; // 定义一个整型变量；\nchar y = 'c';&nbsp; // 定义一个字符变量；\ndouble z = 2.0;&nbsp; // 定义一个双精度浮点变量；\n</code></pre><p>这里的变量具有三部分信息，即变量对应的名称、所表示数据的具体类型，以及当前的数据值。接下来，我们围绕着 C 变量的类型、大小及符号性三个方面来详细地看一看。</p><p>C 语言提供了众多的关键字，可用来指定变量的类型，这些类型均以字节作为单位，来表示变量可容纳数据的最大宽度。例如，<code>char</code> 类型的数据仅占用 1 个字节，而 <code>long long</code> 类型则至少占用 8 个字节。除了最常见的用于表示数值的类型外，C90 与 C99 标准还提供了 <code>void</code>（空类型）、<code>_Bool</code>（布尔型）、<code>_Complex</code>（复数类型）等类型关键字，以用于指定其他非数值类型。</p><p>当然，<strong>C 语言中变量类型占用的具体字节大小</strong><strong>，</strong><strong>还与程序运行所在的硬件体系结构紧密相关</strong>，这也是 C 语言与其他高级编程语言有所不同的地方。</p><p>C 语言最初被设计时，高效性就是设计者考虑的一个主要因素。因此 C 标准委员会在考虑语言设计时，会参考来自于底层硬件体系的某些因素。比如，C 标准中规定，<code>int</code> 类型的大小为执行环境架构体系所建议的自然大小。所谓自然大小，可以简单理解为：对于该大小的数据，硬件体系能够以最高的效率进行处理。因此，硬件体系不同，对应的自然大小便也不同，这也就意味着同一种 C 变量类型在不同硬件体系上可能会有着不同的大小。</p><p>而对于 Rust 和 Java 这些语言来说，它们的语言标准中直接规定了各类型的具体大小。编译器作为编程语言与硬件体系之间的抽象层，它可以确保上层类型在被编译到机器指令时，不会给程序的实际运行带来可观测的差异。当然，保持完全不变的类型大小的代价是一定的性能开销，只是在大多数情况下，这部分开销并不可观。</p><p>除了可以为变量指定不同的数据类型外，同大多数其他静态类型语言类似，在 C 语言中，整型变量本身还需区分它们的“符号性（signedness）”。简单来说，其实就是两种情况：若类型仅可以存放正数，则为无符号（unsigned）类型；若正负数都可以存储，则为有符号（signed）类型。</p><p>比如下面这行代码中，我们定义了一个无符号整型变量：</p><pre><code class=\"language-plain\">unsigned int ux = 10;\n</code></pre><p>符号性上的区别有利于程序对某些特定的场景需求进行优化。比如，在编写一个票务系统时，每张票对应的编号只可能为正整数，因此在使用 C 语言编写程序时，便可将票编号对应的变量定义为无符号类型。这样，对于同样的整数类型，由于不用存储对应的符号位，便可以存放更多的正整数，其可表示的正整数范围会更大。</p><h3>常量</h3><p>说完了变量在 C 语言中的体现，我们再来看看常量。在 C 语言中，通过内联方式直接写到源代码中的字面量值一般被称为“常量”。</p><p>我们在前面提到过常量的一个性质，即“它们被定义后无法被再次修改”。这也就意味着，这些常量数据无法灵活地被开发者操控，它们只能在程序最开始出现的地方发挥作用。比如在前面定义变量的一系列代码中，出现的 “-10”、“2.0” 等数字值便是常量。这些值在被拷贝并赋值给相应的变量后便结束了使命。</p><p>这个时候可能有同学想问：用 <code>const</code> 关键字按照与定义变量相同语法定义的量，不也是常量吗？它与字面量常量有什么区别呢？</p><p>这是一个非常棒的问题。一般来说，我们会按照下面的方式使用 <code>const</code> 关键字：</p><pre><code class=\"language-plain\">const int vx = 10;\nconst int* px = &amp;vx;\n</code></pre><p>通常来说，在 C 语言中，使用 <code>const</code> 关键字修饰的变量定义语句，表示对于这些变量，我们无法在后续的程序中修改其对应或指针指向的值。因此，我们更倾向于称它们为“只读变量”，而非常量。当然，在程序的外在表现上，二者有一点是相同的：其值在第一次出现时便被确定，且无法在后续程序中被修改。</p><p>只读变量与字面量常量的一个最重要的不同点是，使用 <code>const</code> 修饰的只读变量不具有“常量表达式”的属性，因此无法用来表示定长数组大小，或使用在 <code>case</code> 语句中。常量表达式本身会在程序编译时被求值，而只读变量的值只能够在程序实际运行时才被得知。并且，编译器通常不会对只读变量进行内联处理，因此其求值不符合常量表达式的特征。</p><p>误用只读变量和常量会导致编译错误，下面这段代码展示了这类错误：</p><pre><code class=\"language-plain\">#include &lt;stdio.h&gt;\nint main(void) {\n&nbsp; const int vx = 10;\n&nbsp; const int vy = 10;\n&nbsp; int arr[vx] = {1, 2, 3};  // [错误1] 使用非常量表达式定义定长数组；\n&nbsp; switch(vy) {\n&nbsp; &nbsp; case vx: {  // [错误2] 非常量表达式应用于 case 语句；\n&nbsp; &nbsp; &nbsp; printf(\"Value matched!\");\n&nbsp; &nbsp; &nbsp; break;\n&nbsp; &nbsp; }\n&nbsp; }\n}\n</code></pre><h2>数据的存储形式</h2><p>上面，我们介绍了数据在编程语言中的体现方式，这是程序员能够接触到数据的最初位置。随着源代码被编译，数据的实际使用形式开始变得不透明起来。接下来我们就一起看看，在计算机内部，数据是以怎样的形式被存放的。</p><p>对于大多数计算机而言，通常其内部会使用补码（Two’s-complement）的格式来存放有符号整数，使用直接对应的二进制位格式来存放无符号整数，使用 IEEE-754 标准编码格式来存放浮点数，也就是小数。<strong>实际上，计算机在看待数据时，并不会区分其符号性，而符号性的差异仅体现在计算机指令操作数据时的具体使用方式上。</strong></p><p>在接下来的内容中，我不会过多讲解这三种编码方式的基本概念，而是会带你看看它们都有哪些值得关注的特征。因为无符号整数的存储格式较为直接和简单，因此我们主要来看下补码和 IEEE-754 这两种编码方式。</p><h3>补码</h3><p>我们先来看补码的几个特点。使用补码来存放有符号整数的一个优点是，CPU 在针对有符号数进行加减法计算时，不需要由于加数的符号性不同而采用多个底层加法电路，这样便可减轻电路设计的负担，另一方面也可以降低 CPU 的物理尺寸。</p><p>一个补码所表示的实际数值，由其负权重位的值与正权重位的值求和而来，其中负权重位对应于最高有效位（MSB）的符号位，即该位的二进制值在计算时按负值累加。其余各位一起对应正权重位，即这些位对应的二进制值在计算时按正值累加。那具体该怎样计算呢？我们来看一个简单的例子。</p><p>假设我们有一组补码 “1101”，那么应该如何得到它对应的有符号整数值呢？按照顺序，我们首先计算得到该补码对应负权重位的值为 -8，而正权重位的值为 5，因此该补码对应的实际值为 -3（-8+5）。具体计算步骤可以参考下图（图中的 B2T 表示 “Binary to Two’s-complement”，即“二进制转补码”）：</p><p><img src=\"https://static001.geekbang.org/resource/image/54/00/545317f11850fc7e757937b4b6531400.jpg?wh=1920x884\" alt=\"图片\"></p><p>在计算负权重位时，其权重应取负值，正权重位取正值。通过上面的计算过程，你可以清楚地看到，对于一个 4 位补码，它可以表示的最大值与最小值分别是多少。计算最大值时，符号位置 0，其他位均置 1，可以得到能表示的最大值 7。计算最小值时，符号位置 1，其他位均置 0，可以得到最小值 -8。负整数的值可表示范围比正整数多 1 个，这也是所有有符号整数的一个重要特征。</p><p>到这里，我们了解了补码的基本计算方式。那我要向你提出一个小问题：补码的英文名称是 Two’s-complement ，可直译为“对数字 2 的补充”，那为什么会叫这个名字呢？你可以先停下来思考一下，然后再来看看我的理解：</p><p>首先，我们来计算一下有符号整数 3 对应的四位补码，可以得到一个二进制序列 “0011”。将该二进制序列与上述 -3 对应的二进制序列相加，通过进位可以得到序列 “10000”，该序列可以表示无符号正整数 16。</p><p>因此，我们可以得到这样一个结论：对于非负数 x，我们可以用 $2^{w} - x$ 来计算 $-x$ 的 $w$ 位表示。套用在上述的例子中，可以得到“在四位补码的情况下，对于非负数 3，可以用无符号数 13 (即 $16 - 3$) 的位模式来表示有符号数 -3 的位模式”这个结论，即两者位模式相同。而补码的英文名称正是对 $x$、$-x$ 和 $2^{w}$ 三者之间的关系进行的总结。</p><p>我们在前面提到过，计算机不会区分数据的符号性，符号性的差异仅由计算机指令如何使用数据而定。比如在 C 语言中，当对某类型变量进行强制类型转换时，其底层存储的数据并不会发生实质的变化，而仅是程序对如何解读这部分数据的方式发生了改变。比如下面这个例子：</p><pre><code class=\"language-plain\">#include &lt;stdio.h&gt;\nint main(void) {\n&nbsp; signed char x = -10;\n&nbsp; unsigned char y = (unsigned char)x;\n&nbsp; printf(\"%d\\n\", y);&nbsp; // output: 246.\n&nbsp; return 0;\n}\n</code></pre><p>其中，有符号整型变量 <code>x</code> 会按照位模式 <code>1111 0110</code> 的补码形式存放有符号数 -10，而如果将该序列按照无符号整数的位模式进行解读，则可得到如程序运行输出一样的结果，即无符号整数值 246。 总之，程序在进行强制类型转换时，不会影响其底层数据的实际存储方式。</p><p>在 C 语言中，关于数据使用还有一个值得注意的问题：<strong>变量类型的隐式转换</strong>（Implicit Type Conversion）。C 语言作为一种相对而言的“弱类型”语言，其一大特征就是在某些特殊情况下，变量的实际类型会发生隐式转换。</p><p>在下面这个例子中，定义的两个变量 <code>x</code> 与 <code>y</code> 分别为有符号整数和无符号整数，且变量 <code>x</code> 的值明显小于变量 <code>y</code>，但程序在实际运行时却会进入到 <code>x &gt;= y</code> 的分支中，这就是因为发生了变量类型的隐式转换。</p><pre><code class=\"language-plain\">#include &lt;stdio.h&gt;\nint main(void) {\n&nbsp; int x = -10;\n&nbsp; unsigned int y = 1;\n&nbsp; if (x &lt; y) {\n&nbsp; &nbsp; printf(\"x is smaller than y.\");\n&nbsp; } else {\n&nbsp; &nbsp; printf(\"x is bigger than y.\");&nbsp; &nbsp;// this branch is picked!\n&nbsp; }\n&nbsp; return 0;\n}\n</code></pre><p>实际上，在上面的代码中，程序逻辑在真正进入到条件语句之前，变量 <code>x</code> 的类型会首先被隐式转换为 <code>unsigned int</code> ，即无符号整型。而根据数据类型的解释规则，原先存放有 -10 补码的位模式会被解释为一个十分庞大的正整数，而这个数则远远大于 1。</p><h3>IEEE-754</h3><p>我们上面主要介绍了有符号整数的补码，以及它在和无符号整数交互时的一些特性。而对于浮点数类型，大多数计算机体系会选择使用 IEEE-754 标准，作为其编码格式。</p><p>IEEE-754 是一个被众多硬件浮点计算单元（FPU）采用的浮点数标准，这个标准解决了浮点数在硬件实现上的很多问题，使其更具可移植性。</p><p>对于 IEEE-754，一个值得介绍的特点是它对浮点数的存储格式设计，使得计算机可以简单地使用对于整数的排序函数，来对浮点数进行排序。</p><p>举个例子，对于无符号数的二进制序列来说，<code>0010</code> 的值肯定要小于<code>1000</code> （2 &lt; 8）。这对计算机来说很好判断。而对基于 IEEE-754 编码的 8 位浮点数（4 位阶码位，3 位小数位）二进制序列  <code>0 0001 001</code> 和  <code>0 1110 111</code> 来说，判断其大小也同样十分简单。除去最左侧的符号位外，直接将其余各位当作无符号整数序列值进行比较，所得结果同样适用于对应的浮点数序列。</p><p><img src=\"https://static001.geekbang.org/resource/image/48/52/4837d03602cbb86accc0c1c2a1ac3152.jpg?wh=1920x859\" alt=\"图片\"></p><p>当然，同整数一样，C 语言在对浮点数进行类型转换时（无论隐式还是显式），也都不会对底层存放的浮点数据进行改动，而只是将对应位序列的解释方式从浮点数改为了其他方式。在 C 语言中，双精度浮点类型 <code>double</code> 具有作为隐式类型转换的最高优先级。当在一个表达式中存在该类型的变量时，计算机会首先将其他参与变量均转换为该类型，然后再进行表达式求值。</p><h2>数据的存储位置</h2><p>了解了数据的基本存储形式，我们再来看看数据会被存放在哪里。</p><p>在 C 语言中，通过不同的语法形式，我们可以定义具有不同数据类型的变量，这些变量按照其定义所在位置，可以被划分为局部变量、全局变量。进一步地，通过添加 <code>static</code> 关键字，可以将变量标记为静态类型，以延长变量的生存期，并限定其可见范围为当前编译单元，即当前所在源文件；通过添加 <code>register</code> 关键字，还可以建议编译器将变量值存放到寄存器中，以提升其读写性能。</p><p>对于上面提到的这些变量形式，其可能的数据存放位置均不尽相同。根据变量定义时使用的不同语法形式，我总结了变量数据的可能存放位置，如下表所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/e9/0c/e9bbce8219b8dd12992da0bcc9499e0c.jpg?wh=1920x805\" alt=\"图片\"></p><p>需要注意的是，表格里和这一讲后面提到的以 “.” 作为开头的标识，都指代对应的 Section 结构。这些结构，我会在第四个模块中为你详细介绍，这里你可以先有个整体感知。</p><p>接下来我将具体介绍这些变量数据的可能存放位置。先来看初始化的全局变量和静态变量，这类变量的值具有与应用程序同样长的生命周期，其值通常会被存放到进程 VAS（Virtual Address Space，虚拟地址空间）内的 .data 中。</p><p>VAS 我同样会在第四个模块中详细介绍，这里先不展开了。你可以先这样简单理解：应用程序在被正常加载和运行前，需要首先将应用程序代码，及其相关依赖项的数据映射到内存中的某个位置，这段包含有应用程序正常运行所必备数据的内存段即进程的 VAS。像 .data 等以 “.” 开头作为标记的 Section 结构，都代表着该内存段中的某个具体位置，这些 Section 结构都为应用的正常运行提供了各方面支持。</p><p>局部变量是我们在编写程序时最常使用的一种变量形式。一般来说，这些变量将被存放在寄存器或应用程序 VAS 的栈内存中，具体使用哪种方式则依赖于编译器的选择。</p><p>除此之外，未初始化的全局变量和静态变量，以及直接通过 <code>malloc</code>、<code>calloc</code> 等标准库函数创建的内存块中所包含的数据，其存放位置也有所不同。它们被分别存放到进程 VAS 的 .bss 以及堆内存中。这部分内容我也会在第四个模块中详细介绍。</p><p>最后，不同类型常量数据的存储方式也会有所不同。如下表所示，由于常量本身的不可变特征，它们会按照数据的大小和类型被选择性存放到进程 VAS 的 .rodata 以及 .text 中。其中，.rodata 用于存放只读（Read-only Data）数据，而 .text 通常用于存放程序本身的代码。</p><p><img src=\"https://static001.geekbang.org/resource/image/e4/70/e4d6f1acffe0ace77ae5993f17e59a70.jpg?wh=1920x532\" alt=\"图片\"></p><p>一般的规律是，若内联的常量值较大，则会被单独存放到 .rodata 中保存，否则会直接内联到应用程序代码中，作为机器指令（比如最常见的 <code>mov</code> 指令）的字面量参数。</p><h2>总结</h2><p>好了，讲到这里，今天的内容也就基本结束了。最后我来给你总结一下。</p><p>这一讲，我主要介绍了 C 语言中与量值和数据相关的基本语法形式、数据实际存储时的具体编码方式，以及数据在程序运行过程中的实际存储位置等相关知识。</p><p>在 C 语言中，我们可以通过多种语法形式来控制一个变量的属性，比如变量的类型、生存期、值存储位置等。数值类型变量所具有的符号性为我们进一步精细化程序逻辑提供了可能。</p><p>在计算机内部，数据以二进制比特位的形式进行存放和使用。根据类型，它们会被选择性地特殊编码为相应的补码或 IEEE-754 格式，C 语言仅决定了如何从程序逻辑方面解释和使用这些数据，而不会对数据怎样存储产生影响。</p><p>走入底层，不同的 C 变量定义语法形式决定了数据不同的存放位置，而寄存器、栈、堆，以及各类存在于进程 VAS 中的 Section 结构都可能成为数据的存放地点。</p><p>和变量相比，常量则显得“轻巧”很多，它们无法在程序运行过程中被灵活修改，其数据存放位置也失去了更多的可能性。</p><h2>思考题</h2><p>最后，我们来一起做个思考题吧。</p><p>C 语言中的一个常用类型 <code>size_t</code> 通常被用在哪些地方？它是整数类型吗？是有符号数还是无符号数？欢迎在评论区留下你的答案。</p><p>今天的课程就结束了，希望可以帮助到你，也欢迎你把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"01｜快速回顾：一个 C 程序的完整生命周期","id":464550},"right":{"article_title":"03｜计算单元：运算符是如何工作的？","id":466203}}},{"article_id":466203,"article_title":"03｜计算单元：运算符是如何工作的？","article_content":"<p>你好，我是于航。</p><p>运算符（operator）、表达式（expression）和语句（statement）是组成 C 程序的三个最基本的语法结构。在 C 语言中，这三种概念之间一般呈“包含”关系，即表达式中通常含有运算符，而语句中也可以包含有表达式。最终，众多的语句便组成了一个完整的 C 程序。</p><p>可见，一个完整的 C 程序是由不同粒度的语法单元自下而上一层层构建出来的。而在这层语法形式之下，运算符、表达式和语句究竟是怎样被编译，并通过机器指令表达的呢？</p><p>作为 C 语言中用于提供计算能力的核心语法结构，运算符在支持应用核心功能的构建过程中，起着不可或缺的作用。那么这一讲，我们就先来看看，C 语言中的运算符究竟是如何被编译器实现的。</p><h2>C 运算符的分类</h2><p>在目前最新的 C17 标准中，C 语言一共有 48 个运算符。按照这些运算符功能的不同，我们可以将它们分为七类（分类方式并不唯一），如下表所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/ef/38/efc411637eefb4cf8b05213d8a4d4238.jpg?wh=1920x945\" alt=\"图片\"></p><p>这七类运算符在功能上均有所不同，因此，使用机器指令进行表达的具体方式和复杂程度也不同。其中，算数、关系、位与赋值运算符由于功能较为基础，可以与某些机器指令一一对应，因此我们会放在一起进行介绍。而逻辑运算符、成员访问运算符及其他运算符，由于实现相对复杂，我会分开讲解。</p><!-- [[[read_end]]] --><h2>算数、关系、位、赋值运算符</h2><p>算数、关系、位、赋值这四类运算符在经过编译器处理后，一般都可以<strong>直接对应到由目标平台上相应机器指令组成的简单计算逻辑</strong>。</p><p>比如，在下面这段示例代码中，我们在 foo 函数的内部使用到了加法运算符 “+”、大于运算符 “&gt;”，以及按位或运算符 “|”。你可以通过右侧的输出内容，查看默认情况下（即不使用任何编译优化）左侧 C 源代码对应的汇编结果。</p><p><img src=\"https://static001.geekbang.org/resource/image/49/a8/49ce8cab93065b2d8d9d27b8520e7ea8.png?wh=1920x1085\" alt=\"图片\"></p><p>这里为了便于观察，我将代码中关键的三行 C 语句，以及它们对应的汇编代码用相同颜色的框标注了出来。<strong>下面我们来分别看看它们的实现方式。</strong></p><p>先来看左侧代码中用红色框标注的内容，这是一个使用了加法运算符 “+” 的 C 语句。在它对应的汇编代码中，前两行代码分别从栈内存中将变量 x 与 y 的值放入到了寄存器 <em>edx</em> 与 <em>eax</em> 里。紧接着，程序通过 <code>add</code> 机器指令计算这两个寄存器中的数字之和。随后，通过 <code>mov</code> 指令，程序将计算得到的结果值从寄存器 <em>eax</em> 移动到了局部变量 arithmetic 对应的栈内存中。至此，这行 C 代码便执行结束了。</p><p>实际上，这行 C 语句同时包含了对算数运算符 “+” 和赋值运算符 “=” 的使用过程。其中，汇编指令 <code>add</code> 直接对应于 C 代码中加法运算符的操作。而 <code>mov</code> 指令则对应于等号赋值运算符的操作。</p><p>在这门课后面的内容中，你还会多次看到编译器对 <code>mov</code> 指令的使用。这里我们采用的是 Intel 的汇编代码格式，因此，当该指令的源或目的操作数中涉及到某个具体的内存位置时，汇编代码中会出现类似 “DWORD PTR [rbp-8]” 的参数形式。</p><p>对此，你可以这样解读：将寄存器 <em>rbp</em> 中的值减去 8 得到的结果作为一个地址，然后在这个地址上读取/写入大小为 DWORD 的值。在 Intel 体系中，一个 WORD 表示 16 位，一个 DWORD 为 32 位，而一个 QWORD 表示 64 位。</p><p>接下来，我们继续观察另外两条 C 语句对应的汇编代码，你可以得到类似的结论。其中，绿色框标注的关系运算符大于号 “&gt;” 对应汇编指令 <code>cmp</code>。这个指令在被执行时，会首先比较变量 x 与 y 值的大小，并根据比较结果，动态调整 CPU 上 FLAGS 寄存器中的相应位。</p><p>为了帮你深入理解接下来的内容，我们先来熟悉一些相关概念。这里提到的 <strong>FLAGS 寄存器是一组用于反映程序当前运行状态的标志寄存器</strong>。许多机器指令在执行完毕时，都会同时调整 FLAGS 寄存器中对应位的值，以响应程序状态的变化。</p><p>比如，在上面这段代码中，汇编指令 <code>cmp</code> 的下一条汇编指令 <code>setg</code> 便会通过查看 FLAGS 寄存器中的 ZF 位是否为 0，且 SF 与 OF 位的值是否相等，来决定将寄存器 <em>al</em> 中的值置 1，还是置 0。而该寄存器中存放的数字值，便为变量 relational 的最终结果。</p><p>那么，ZF 位、SF 位、OF 位又是什么呢？它们其实都是 FLAGS 寄存器中的常用标志位，用来反映当前指令执行后引起的 CPU 状态变化。我把 FLAGS 寄存器中的常用标志位整理在了下面的表格中，你可以参考。<br>\n<img src=\"https://static001.geekbang.org/resource/image/8f/2e/8f0f1558af722f4e5d078a26266c642e.jpg?wh=2248x903\" alt=\"\"></p><p>理解了 FLAGS 寄存器和标志位的概念后，再来看 <code>cmp</code> 指令的具体执行流程，你应该会更加清楚了。</p><p>举一个简单的例子：假设这里函数 add 在调用时传入的值 x 为 3，y 为 2。那么，当 <code>cmp</code> 指令执行时，它首先会在 CPU 内部对这两个操作数进行隐式的减法运算，运算后得到结果 1。而 ZF、SF、OF 在这里都将被复位，而复位则代表着标志位所表示的状态为假。因此，FLAGS 寄存器的状态满足指令 <code>setg</code> 的置位条件（ZF=0 且 SF=OF），<em>al</em> 寄存器的值将被置 1。</p><p>到这里，我相信基本原理你已经理解了，不过还是建议你自己动手实践下。我给你留下了两个小问题，你可以在评论区和我讨论：</p><ul>\n<li>当改变值 x 与 y 的大小以及正负性时，<code>cmp</code> 指令的执行会对 FLAGS 寄存器有何影响？</li>\n<li>此时， FLAGS 寄存器中标志位的值变化是否符合指令 <code>setg</code> 的置位条件？</li>\n</ul><p>针对这两个问题，你需要注意下我在<a href=\"https://time.geekbang.org/column/article/465228\"> 02讲 </a>中提过的这一点：<strong>负值在寄存器中是以补码的形式存放的，而计算机在进行加减运算时，不需要区分操作数的符号性</strong>。</p><p>最后，再来看下这段代码中蓝色框标注的或运算符 “|”。可以很直观地看到，它所对应的汇编指令是 <code>or</code>。</p><p>针对这几类运算符，值得一提的是，即便是在开启了最高编译优化等级的情况下，编译器实现上述这些运算符的基本逻辑仍然不变，只不过会相对减少通过栈内存访问函数传入参数的过程，而在某些情况下会选用寄存器传值。</p><h2>逻辑运算符</h2><p>说完这四种较为直观的运算符，让我们再来看看逻辑运算符。这里，我们直接以逻辑与运算符 “&&” 为例，来看看编译器是如何实现它的。该类别下的其他运算符，实现方式与其类似，区别仅在于使用的具体指令可能有所不同。</p><p>首先，我们还是来看一段示例代码：</p><p><img src=\"https://static001.geekbang.org/resource/image/5c/72/5c6110c1d93a433d8b9f455e2fa84672.png?wh=1920x1318\" alt=\"图片\"></p><p>在 C 标准中，逻辑与运算符 “&&” 的语义是：如果它左右两侧的操作数都具有非零值，则产生计算结果值 1。而如果任一操作数为 0，则计算结果为 0。</p><p>不仅如此，标准还规定了该运算符在执行模型中的求值规则：如果通过逻辑与运算符左侧第一个操作数的求值结果就能确定表达式的值，就不再需要对第二个操作数进行求值了，这也就是我们常说的“短路与”。那么在汇编中，这个运算符是如何实现的呢？</p><p>逻辑与运算符并没有可与之直接对应的汇编指令。并且，为了满足“短路”要求，编译器在非优化的实现中通常会使用条件跳转指令，比如 <code>je</code>。<code>je</code> 指令会判断当前 FLAGS 寄存器中的标志位 ZF 是否为 1。若为 1，则会将程序执行直接跳转到给定标签所在地址上的指令。</p><p>上图中右侧输出的汇编代码里，程序会按顺序将位于栈内存中的变量 x 和 y 的值与数值 0 进行比较。若其中的某个比较结果相等，程序执行将会直接跳转到标签 “.L2” 的所在位置。在这里，值 0 会被直接放入寄存器 <em>eax</em>。而若变量 x 与 y 的值判断均不成立，则值 1 会被放入该寄存器。紧接着，标签 “.L3” 中的指令将接着执行。</p><p>到这里，寄存器 <em>eax</em> 中的值将会被作为最终结果，赋值给变量 logical。这里我再给你留个小问题：标签 “.L3” 中前两条汇编语句的作用是什么？欢迎在评论区留下你的看法。</p><p>当然，就逻辑与运算符来说，在使用高编译优化等级时，编译器还可能会采用下面这种方式来实现该运算符。这里，我们看到了新的汇编指令： <code>test</code> 、<code>setne</code> 和 <code>movzx</code> 。</p><pre><code class=\"language-c++\">test&nbsp; &nbsp; edi, edi  ; edi &lt;- x.\nsetne&nbsp; &nbsp;al\ntest&nbsp; &nbsp; esi, esi  ; esi &lt;- y.\nsetne&nbsp; &nbsp;sil\nmovzx&nbsp; &nbsp;esi, sil\nand&nbsp; &nbsp; &nbsp;esi, eax\n</code></pre><p><code>test</code> 指令的执行方式与 <code>cmp</code> 类似，只不过它会对传入的两个操作数做隐式的“与”操作，而非减法操作。在操作完成后，根据计算结果，指令会相应地修改 FLAGS 寄存器上的 SF、ZF 以及 PF 标志位。另外的 <code>setne</code> 指令则与 <code>setg</code> 指令类似，该指令将在 ZF 为 0 时把传入的寄存器置位，否则将其复位。最后的指令 <code>movzx</code> 实际上是 <code>mov</code> 指令的一种变体。这个指令将数据从源位置移动到目标位置后，会同时对目标位置上的数据进行零扩展（Zero Extension）。</p><p>了解了这些，我们就可以来尝试理解<strong>编译器在高优化等级下对逻辑与运算符的实现方式</strong>：首先，通过 <code>test</code> 指令，程序可以判断参数 x 与 y 是否为非零值。若为非零值，则相应的寄存器会被指令 <code>setne</code> 置位。在这种情况下，寄存器 <em>al</em> 与 <em>sil</em> 中便存放有用于表示变量 x 与 y 是否为零的布尔数字值 0 或 1。接下来，通过数据移动指令，寄存器 <em>sil</em> 中的值被移动到寄存器 <em>esi</em> 中。最后的 <code>and</code> 指令又会对 x 与 y 的布尔数字值再次进行与操作，得到的最终结果将被存放在目的寄存器，即 <em>esi</em> 中。</p><p>这种实现方式大量减少了对栈内存以及条件跳转指令的使用，使得程序减少了访问内存时产生的延迟，以及由于分支预测失败而导致的 CPU 周期浪费，从而执行性能得到了提升。</p><p>可以看到的是，在使用高编译优化等级的情况下，C 标准中逻辑与操作符的“短路”特性并没有体现出来，程序实际上同时对参数 x 与 y 的值进行了判断<strong>。</strong>而这也正是因为 <strong>C 语言的 “as-if” 性质给予了编译器更多的优化空间</strong>。C 标准中规定，除去几种特殊的情况外，在不影响一个程序的外部可观测行为的情况下，编译器可以不遵循 C 标准中对执行模型的规定，而是采用其特定的实现方式，优化程序的性能。</p><p>在非优化版本的实现中，编译器使用了 <code>je</code> 条件跳转指令。其实，现代流水线 CPU 通常会采用一种名为“<strong>投机执行</strong>”的方式来优化条件跳转指令的执行。所谓投机执行，是指 CPU 会通过分析历史的分支执行情况，来推测条件跳转指令将会执行的分支，并提前处理所预测分支上的指令。而等到 CPU 发现之前所预测的分支是错误的时候，它将不得不丢弃这个分支上指令的所有中间处理结果，并将执行流程转移到正确的分支上。很明显，这样就会浪费较多的时钟周期。</p><p>更多优化 C 程序性能的技巧，我会在“ C 工程实战篇”那个模块中详细讲解。相信在对 C 核心语法的实现细节有了更深入的理解后，你在学习这些知识时也会更容易、理解得更透彻。</p><h2>成员访问运算符</h2><p>接下来，让我们继续来看看成员访问运算符。这里我以取地址运算符 “&amp;”、解引用运算符 “*” 为例，来介绍编译器对它们的实现细节。来看下面这段代码：</p><p><img src=\"https://static001.geekbang.org/resource/image/e9/10/e944e2a1b5f31776be315902d5f6a110.png?wh=1920x1003\" alt=\"图片\"></p><p>如上图中红色框对应的 C 代码和汇编代码所示，对于取地址运算符 “&amp;”，实际上它一般会直接对应到名为 <code>lea</code> 的汇编指令。这个指令的全称为 “Load Effective Address”，顾名思义，它主要用来将操作数作为地址，并将这个地址以值的形式传送到其他位置。比如，上面代码中的 <code>lea</code> 指令将寄存器 <em>rbp</em> 中的值减去 16 后，直接存放到寄存器 <em>rax</em> 中，而此时该寄存器中的值就是局部变量 n 在栈上的地址。</p><p>而解引用运算符 “*”的行为与取地址运算符完全相反。当需要对位于某个地址上的值进行传送时，我们可以直接使用 <code>mov</code> 指令。上图中，在蓝色框的汇编代码里，第一条 <code>mov</code> 指令将变量 n_ptr 的值传送到了寄存器 <em>rax</em> 中。随后，第二条 <code>mov</code> 指令将 <em>rax</em> 寄存器中的值作为地址，并将该地址上的值以 DWORD，即 32 位值（对应  <code>int</code> 类型）的形式传送到 <em>eax</em> 寄存器中。最后，第三条 <code>mov</code> 指令将此时 <em>eax</em> 寄存器中的结果值传送到了变量 m 在栈内存上的存储位置。</p><p>至于该类别下的其他运算符，因为它们的本质都是访问位于某个内存地址上的数据，因此实现方式大同小异。这里我就不展开介绍了，建议你试着自己探索下，毕竟“实践出真知”。如果有问题，可以在评论区提出来，我们一起交流。</p><h2>其他运算符</h2><p>最后，让我们来看看除了上面那六类运算符之外的其他运算符，这里我主要介绍 <code>sizeof</code> 运算符和强制类型转换运算符 “(type) a”。至于函数调用运算符，由于内容较多，我会在后续的课程再单独为你介绍。我们还是通过一段示例代码，观察它们在默认情况下的汇编实现：</p><p><img src=\"https://static001.geekbang.org/resource/image/e2/5d/e23e323a086f364b2d5225e25d958e5d.png?wh=1920x817\" alt=\"图片\"></p><p>其中，<code>sizeof</code> 运算符是一个编译期运算符，这意味着编译器仅通过静态分析就能够将给定参数的大小计算出来。因此，在最终生成的汇编代码中，我们不会看到 <code>sizeof</code> 运算符对应于任何汇编指令。相反，运算符在编译过程中得到的计算结果值，将会以字面量值的形式直接“嵌入”到汇编代码中使用。你可以从上图中右侧红框内的汇编代码看到，C 代码 <code>sizeof(int)</code> 的计算结果 4 直接作为了 <code>mov</code> 指令的一个操作数。</p><p>至于强制类型转换运算符呢，其实也很好理解。这里，我们将变量 n 的值类型由原来的 <code>size_t</code> 转换为了 <code>short</code>。你可以从上图中蓝框内的汇编代码里看到，当 <code>mov</code> 指令将变量 n 的值移动到变量 f 所在的内存区域时，它仅移动了这个值从低位开始一个 WORD，即 16 位大小的部分。至于其他类型之间的转换过程，你可以简单理解成<strong>对同一块数据在不同机器指令下的不同“解读”方式</strong>。</p><p>在高编译优化等级下，上面介绍的成员访问运算符与强制类型转换运算符的实现方式并没有发生本质的变化。而与其他运算符类似的是，编译器会减少对栈内存的使用。同时，基于更强的静态分析能力，编译器甚至可以提前推算出某些变量的取值，并省去在程序运行过程中再进行类型转换的过程，从而进一步提升程序的运行时性能。</p><h2>总结</h2><p>好了，讲到这里，今天的内容也就基本结束了，我来给你总结一下。</p><p>今天我主要围绕 C 语言中的基本“计算单元”，运算符，讲解了 C 语言中的几类不同运算符是如何被编译器实现的。具体总结如下：</p><ul>\n<li>通常来说，算数、关系、位、赋值运算符的实现在大多数情况下，都会直接一一对应到特定的汇编指令上；</li>\n<li>逻辑运算符的实现方式则有些不同，它会首先借助 <code>test</code> 、 <code>cmp</code> 等指令，来判断操作数的状态，并在此基础上再进行相应的数值转换过程；</li>\n<li>在成员访问运算符中，取地址运算符一般对应于汇编指令 <code>lea</code> ，解引用运算符则可直接使用 <code>mov</code> 指令来实现；</li>\n<li>对于其他运算符，<code>sizeof</code> 运算符会在编译时进行求值，强制类型转换运算符则直接对应于不同指令对同一块数据的不同处理方式。</li>\n</ul><h2>思考题</h2><p>除了我在上面提到的三个问题外，我再给你留个思考题：编译器是通过哪类指令来实现三元运算符 “?:” 的？你可以自己动手实践，并在评论区给出你的答案。</p><p>今天的课程就结束了，希望可以帮助到你，也期待你在下方的留言区和我一起讨论。同时，欢迎把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"02｜程序基石：数据与量值是如何被组织的？","id":465228},"right":{"article_title":"04｜控制逻辑：表达式和语句是如何协调程序运行的？","id":467203}}},{"article_id":467203,"article_title":"04｜控制逻辑：表达式和语句是如何协调程序运行的？","article_content":"<p>你好，我是于航。今天，我们继续来看 C 基本语法结构背后的实现细节。</p><p>上一讲，我主要介绍了编译器是如何使用机器指令来实现各类 C 运算符的。在应用程序的构建过程中，运算符仅作为“计算单元”，为程序提供了基本的“原子”计算能力。而数据如何同时使用多种不同的运算符，以及按照怎样的逻辑来在不同位置上“流动”，这一切都是由表达式和语句进行控制的。这一讲，就让我们来看看 C 语言中，用来描述程序运行逻辑的这两种控制单元“背后的故事”。</p><h2>表达式</h2><p>表达式（expression）是由一系列运算符与操作数（operand）组成的一种语法结构。其中，操作数是参与运算符计算的独立单元，也即运算符所操作的对象。操作数可以是一个简单的字面量值，比如数字 2、字符串 “Hello, world!”；也可以是另一组复杂的表达式。举个例子：在表达式 <code>(1 + 2) * 3 + 4 / 5</code> 中，乘法运算符 “*” 所对应的两个操作数分别是字面量数值 3，和子表达式 <code>(1 + 2)</code>。</p><p>通常来说，表达式的求值（evaluation）过程需要依据所涉及运算符的优先级和结合性的不同，而按一定顺序进行。我们一起来看看上面提到的 <code>(1 + 2) * 3 + 4 / 5</code> 这个表达式的计算流程。</p><p>首先，需要根据表达式中运算符优先级的不同，来决定最先进行哪一部分运算。运算符的优先级很好理解，由于乘法运算符 “*” 与除法运算符 “/” 的优先级高于加法运算符 “+”，因此在计算整个表达式的值时，需要首先对由这两个运算符组成的子表达式进行求值。</p><!-- [[[read_end]]] --><p>当从上一步中“筛选出”的待计算运算符多于 1 个时，我们就需要再判断运算符的结合性，来决定优先计算哪一个。因为乘法运算符和除法运算符均具有左结合性，因此，由左侧乘法运算符构成的子表达式需要被优先求值。</p><p>当我们以这个表达式为视角，进行观察时，参与表达式计算的操作数分别为子表达式 <code>(1 + 2)</code>，以及字面量数值 3。这里，我们需要分别对这两部分进行求值，直至乘法运算符 “*” 两边的操作数可以直接参与计算为止。但需要注意的是，C 标准中并未规定运算符两侧操作数的具体求值顺序，因此具体方式由编译器选择。</p><p>因此我们可以说，<strong>对表达式的求值过程，实际上就是根据运算符的优先级和结合性，来对表达式和它所包含的子表达式进行递归求值的过程</strong>。从编译的角度来看，这个过程中所涉及到的操作数的实际求值顺序会在语法分析阶段被确定，并体现在源码对应的抽象语法树（AST，Abstract Syntax Tree）上。为了方便进一步观察，我将这个表达式整合到了下面的 C 代码里，并保存在文件 main.c 中：</p><pre><code class=\"language-c++\">int foo(void) {\n  return (1 + 2) * 3 + 4 / 5;\n}\n</code></pre><p>然后，借助 Clang 编译器提供的 “-ast-dump” 选项，我们可以编译并打印出这段 C 代码对应的 AST 结构。完整的编译命令如下：</p><pre><code class=\"language-bash\">clang -Xclang -ast-dump -fsyntax-only&nbsp;main.c\n</code></pre><p>上面的命令执行完毕后，部分输出结果如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/fc/0a/fcf686b1f02ba6340b9a51a85f60ee0a.png?wh=1266x496\" alt=\"图片\"></p><p>AST 作为用于表示源代码语法结构的一种树形数据结构，语法分析器会将表达式中操作数的整体求值顺序映射到树的结构上。因此，当我们以后序遍历（LRD）的方式遍历这棵树时，便可以直接得到正确的表达式求值顺序。</p><p>对于上面的 AST 来说，由叶子结点组成的子树需要被最先求值，因此我们首先可以得到括号内加法表达式的计算结果 3。然后，该结果将作为叶子结点上的操作数，参与乘法运算符的计算，从而得到计算结果 9。接下来，除法运算符所在的子表达式经过求值，得到结果 0。最后，该值再作为最后一个加法运算符的操作数，与字面量值 9 相加，进而得到整个表达式的最终计算结果 9。</p><p>你可以看到，表达式提供了这样一种能力：<strong>能够让数据同时参与到多个操作符的不同计算过程中</strong>。而通过提供对运算符优先级与结合性的规则限制，表达式可以控制整个计算过程的有序进行。</p><h2>语句</h2><p>语句（statement）是用来描述程序的基本构建块。和表达式不同，语句是构成 C 程序的最大粒度单元，在它的内部，可以包含有简单或复杂的表达式结构，但也可以不包含任何内容。除此之外，语句在执行时不返回任何结果，但可能会产生副作用。</p><p>在 C 语言中，语句可以被分为复合语句、表达式语句、选择语句、迭代语句、跳转语句五种类型。<strong>但无论是哪种类型，语句都必须以分号结尾，并按从上到下的顺序依次执行</strong>。</p><p>其中，复合语句是指由花括号 “{}” 标记的一块区域。在这个区域中，我们可以放置声明（declaration）和语句，而最常见的一种复合语句便是函数体。在函数体内部，我们可以定义变量，并通过结合各类其他语句来实现函数的功能。而表达式语句则是直接由表达式外加一个分号组成的语句，比如函数调用语句或变量赋值语句。当然，表达式语句中的表达式也可以为空，这样就成为了仅由一个 “;” 组成的空语句。</p><p>在下面这段代码里，我标注出了其中使用到的复合语句与表达式语句。你可以通过它们来加深对这两种语句的理解。</p><pre><code class=\"language-c++\">int foo(int x, int y) {  // 复合语句；\n&nbsp; int sum = x + y; // 表达式语句；\n  if (sum &lt; 0) {  // 复合语句；\n    sum = -sum;  // 表达式语句；\n  }\n&nbsp; return sum;\n}\n</code></pre><p>这两种类型的语句，它们的具体结构依程序设计细节的不同而不同，因此这里我们不再做更多的讨论。相对的，在 C 语言中，选择语句、迭代语句、跳转语句都有着它们相对应的特定语法结构。因此，接下来我们重点看看这几类语句，探究编译器是如何实现它们的。</p><h3>选择语句</h3><p>同其他大多数语言类似，在 C 语言中，选择语句主要是指由 if…else 和 switch…case 这两种语法结构组成的语句。它们的使用方式你应该很熟悉，这里就不多讲了。让我们直接通过一个例子，观察编译器在默认情况下是如何实现它们的。首先来看 if…else 语句：</p><p><img src=\"https://static001.geekbang.org/resource/image/f0/46/f0d196f56b772f3b97e6d25e01cd8c46.png?wh=1920x1610\" alt=\"图片\"></p><p>如上图所示，在左侧的 C 函数 foo 中，我们使用 if…else 语句构建了一个简单的程序逻辑。if 语句会在每一个条件分支中检测函数参数 v 的值，并根据匹配情况返回一个数值。若所有情况都没有命中，则最后的 else 语句生效，直接返回数值 4。相应的，在右侧，我们可以看到这个函数对应的汇编代码。</p><p>在这里，通过红框内的汇编代码可以看到，变量 v 的值被存放在栈内存中地址为 rbp 寄存器的值减去 4 的位置上。程序使用多个标签（如 .L2、.L3 等），分别划分不同分支对应的处理逻辑，而分支的判断过程则是由指令 <code>cmp</code> 与条件跳转指令 <code>je</code> 与 <code>jne</code> 共同完成的。<strong>汇编代码和 C 代码的整体逻辑基本是一一对应的关系。</strong>因此，在这种情况下，为了尽量保持程序的执行性能，你可以将命中几率较大的条件语句放在较前的位置上。</p><p>接着，我们再来看看 switch…case 语句。</p><p><img src=\"https://static001.geekbang.org/resource/image/65/c3/65cae8d9643d6e5b6e2cefc0c5c6fac3.png?wh=1370x1656\" alt=\"图片\"></p><p>这里，我只列出了部分汇编代码，但足够你理解编译器对 switch…case 语句的实现细节了。其中，标注为红色的汇编代码会通过 <code>cmp</code> 指令，判断寄存器 eax 中的值，即变量 v 的值是否大于 60。若判断成立，则直接将程序跳转到标签 .L2 处，并将数字 4 作为返回值；若条件不成立，程序将继续执行。接下来，蓝色部分的代码会基于变量 v 的值，来产生一个用于参与后续运算符的 “token” 值。这个值的生成步骤如下所示：</p><ol>\n<li>将寄存器 edx 的值设为 1；</li>\n<li>将寄存器 ecx 的值设为变量 v 的值；</li>\n<li>将寄存器 rdx 中的值左移 v 位（值被扩展为 64 位）；</li>\n<li>将此时寄存器 rdx 中的值移动到 rax 中留作待用。</li>\n</ol><p>接下来，通过上图中右侧虚线框内的代码，程序完成了对变量 v 的值的第一次筛选过程。这个过程很好理解，如果将其中第一行指令 <code>movabs</code> 的立即数操作数 1154047404513689600 以 64 位二进制的形式展开，你会发现其中只有第 50 和 60 位被置位。</p><p>而第二行的 <code>and</code> 指令，会将这个超长的立即数与之前根据变量 v 的值进行移位而得来的 token 值进行“与”操作。若操作得到的结果不为 0，则表示 token 值的第 50 或 60 位肯定不为 0，即变量 v 的值为 50 或 60。否则，变量 v 的值则不符合该 case 语句的筛选条件。到这里，筛选的基本逻辑相信你已经清楚了。</p><p>不过，通过“位映射”的方式进行分支筛选，并不能完美地覆盖所有情况。比如，当 case 语句的筛选值过大，无法使用寄存器来进行映射时，默认优化条件下，编译器会将 switch…case 的实现“回退”到与 if…else 类似的方式。也就是说，使用 <code>cmp</code> 指令与条件跳转指令来进行分支的筛选与转移。当然，具体采用哪种实现策略依据编译器的不同而有所不同。</p><p>除了上面介绍的 if…else 与 switch…case 语句实现方式外，在高优化等级下，编译器还可能会采用一种名为“跳表”的方式，来实现这两种条件选择语句。</p><p>下面是用这种方式修改后的 switch…case 语句实现，你可以先观察下，并思考这种方式的实现思路。</p><p><img src=\"https://static001.geekbang.org/resource/image/1d/b6/1de27b48eb7ceeb09dd81f8500yy97b6.png?wh=1598x1752\" alt=\"图片\"></p><p>可以看到，这里我们将 switch…case 语句中分支筛选的“跨度”进行了减小，即将其中的最大分支匹配条件由 60 减小到了 40。<strong>跳表是一种用空间换时间的条件匹配策略</strong>，让我们通过上图右侧的汇编代码，来了解它的实现过程。</p><p>首先，标注为红色的汇编代码将变量 v 的值减去了选择语句中最小匹配条件的值，这里也就是 10。然后，程序通过 <code>cmp</code> 与 <code>ja</code> 指令，判断变量 v 的值是否超过了选择语句中最大匹配条件与最小匹配条件之间的差值，这里也就是 30。若是，则程序直接跳转到标签 .LBB0_3 处，并返回数值 3。</p><p>否则，程序就会使用跳表来寻找变量 v 的值对应的正确分支。<strong>所谓跳表，即在一段连续内存中存放的，可用于辅助查找正确目标地址的地址信息</strong>。在上面这个例子中，跳表从标签 .LJTI0_0 处开始。在这段内存中，连续存放了筛选值 10 到 40 区间内，每一个整数值对应的正确分支处理地址。接下来的蓝色代码保存了当跳表第 0 项“命中”时，函数需要返回的值。</p><p>假设在调用函数 foo 时，传入变量 v 的值为 20。虚线框中的 <code>jmp</code> 指令在执行时，会根据 v 的值在跳表中找到它所对应的正确分支地址。由于这里 rdi 寄存器中的值为 10（20 - 10），因此正确的分支处理地址便是跳表中第十项对应的值。这里可以看到，在 .LJTI0_0 标签 +80 字节的位置（.quad 代表 8 字节数据）处，正对应着标签 .LBB0_4 的地址。而该标签的位置，正是变量 v 为值 20 时的正确分支处理地址。</p><p>除了上面提到的这些编译器在实现分支语句时使用的常用方式外，根据分支语句的具体情况，编译器还可能会采用某些针对特定形态代码的专用优化。而即使针对最“原始”的 <code>cmp</code> 加条件跳转语句组合这种实现方式，编译器也会根据 C 源代码的情况，适当使用“二分法”等优化策略，来加快条件的筛选过程。</p><h3>迭代语句</h3><p>在 C 语言中，迭代语句主要包含 do…while、for、while 这三种基本语法形式。这些语句除了在执行细节上有些许差异外，其对应的汇编实现思路大同小异。这里我以 do…while 语句为例来讲解，具体代码如下所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/df/1c/df301d794a335203bf7d172e67cbbc1c.png?wh=1262x826\" alt=\"图片\"></p><p>可以看到，在真正对变量 v 进行条件判断之前，程序已经执行了一次 <code>printf</code> 函数，而这便是 do…while 语句相较于其他迭代语句的特点。迭代过程以 .L2 标签作为每次的起始点，每次迭代都遵循着“先执行循环体，再判断条件”的规则。条件的判断和执行转移流程则分别由指令 <code>test</code> 与 <code>jne</code> 负责进行。</p><p>即使是在高优化等级下，C 语言中的这三种基本迭代语句在机器层面的汇编实现方式也不会有较大的差异，但这也并不意味着你可以随意使用它们。至少对于 do…while 与 while 而言，它们在执行细节上存在着差异，如果不假思索地使用，很可能会给你的程序招致不必要且难以调试的 BUG。</p><h3>跳转语句</h3><p>C 语言中的跳转语句主要指那些可以改变程序执行流程的语法结构，它们主要包括以下四种类型：</p><ul>\n<li>break 语句；</li>\n<li>continue 语句；</li>\n<li>return 语句；</li>\n<li>goto 语句。</li>\n</ul><p>其中，return 语句的执行细节涉及到了函数的调用与返回，因此我会在 05 讲中为你详细介绍。而对于另外三种语句，相信就算不参考实际代码，对于它们的实现“套路”，你也已经心中有数，因为它们的基本功能均是改变程序的具体执行流程。</p><p>在 C 代码中，用于控制程序执行逻辑的大部分语句，其背后都是通过条件跳转语句来实现的。编译器通过代码分析，可以找到程序中可能的“跳入点”与“跳出点”，并在机器指令层面通过 <code>je</code> 等条件跳转指令，来控制程序的执行流程在这些点之间进行转移。也就是说，只要理解了其他语句实现中对条件跳转指令的使用方式，这里你就能融会贯通。</p><h2>总结</h2><p>好了，讲到这里，今天的内容也就基本结束了。最后我来给你总结一下。</p><p>今天我主要讲解了 C 语言中用于描述程序运行逻辑的两种“控制单元”，即表达式和语句背后的实现细节。</p><p>表达式作为一种表达计算的基本语法结构，对它的求值过程需要根据参与运算符的结合性与优先级，按一定顺序进行。而计算的具体顺序则会在语法分析阶段，由编译器直接体现在对应的 AST 结构形态上。</p><p>语句是程序的基本构建块，通过不同种类语句的组合使用，我们可以控制程序的执行逻辑。C 语言中的语句主要包括复合语句、表达式语句、选择语句、迭代语句，以及跳转语句共五种。其中，由于前两种语句的展现形式较为动态，因此我着重讲解了语法结构和功能较为固定的后三种语句。</p><p>选择语句包含 if…else 与 switch…case 两种类型，编译器通常会采用位映射法、跳表法、基于二分法的测试与条件跳转语句的方式来实现它们。迭代语句则包含 while 语句、do…while 语句以及 for 语句，编译器实现它们时，通常也是采用基本的测试与条件跳转，但三种迭代语句在执行细节上稍有差异。最后的跳转语句包含 return 语句、continue 语句、break 语句以及 goto 语句。它们作为可以改变程序执行顺序的语句，大多也以类似的方式实现。</p><h2>思考题</h2><p>最后给你留一个小问题，你可以在留言区和我交流：空语句 <code>;</code> 在 C 语言中有哪些使用方式？</p><p>今天的课程就结束了，希望可以帮助到你，也希望你在下方的留言区和我一起讨论。同时，欢迎你把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"03｜计算单元：运算符是如何工作的？","id":466203},"right":{"article_title":"05｜代码封装（上）：函数是如何被调用的？","id":468171}}},{"article_id":468171,"article_title":"05｜代码封装（上）：函数是如何被调用的？","article_content":"<p>你好，我是于航。</p><p>在前两讲中，我介绍了 C 语言中的运算符、表达式、语句是如何被编译器实现的。不知你是否还记得，在介绍运算符时，我没有展开讲解有关函数调用运算符的内容。接下来，我就用专门的两讲内容，来带你深入看看 C 语言中有关函数调用的那些事儿。</p><p>这一讲，我们首先来看 C 语言中，编译器实现函数调用时所遵循的一系列规则。这些规则实际影响着函数调用时，在如何传参、如何使用寄存器和栈内存等问题上的处理细节。</p><p>除此之外，由于 C 语言中的函数调用过程与栈内存密切相关，我还会介绍栈和栈帧的概念。栈是 C 程序在运行时用于存放临时数据的一块内存，而每一个栈帧都对应着栈内存中的一段数据，这些数据是在函数调用过程中所必须使用的。通过这一讲的学习，你能了解到编译器对 C 函数调用的处理细节。而在下一讲中，我们将以此为基础，来深入探讨尾递归调用优化等更多函数调用的相关内容。</p><h2>快速回顾 C 语言中函数的使用方式</h2><p>函数的概念相信你已经十分熟悉了，这里我们先来快速回顾一下。</p><p>在编程语言中，函数是一种用于封装可重用代码的语法结构。函数可以接收从外部调用环境传入的数据，并在函数体内以复合语句的形式，使用这些数据构建独立的功能逻辑单元。<strong>借助函数，我们可以将一个程序的实现过程拆分为多个子步骤，并以结构化的方式来构建程序。</strong>这种方式可以减少程序中的重复代码，并通过抽象和替换来提高代码的整体可读性，以及可追溯性。</p><!-- [[[read_end]]] --><p>在 C 语言中，函数的定义与使用方式跟其他语言大同小异，我们先通过一个例子快速回顾一下。这里，你可以先停下来，尝试编译和运行下面这段代码，并观察其中的函数调用逻辑。需要注意的是，在编译时，我们要为编译器指定 “-lm” 参数，来让它链接程序运行所需要的数学库。</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\n#include &lt;tgmath.h&gt;\ntypedef struct {\n&nbsp; int x;\n&nbsp; int y;\n} Point;\nint foo(int x, int y, Point* p, int(handler)(int)) {\n&nbsp; return handler(x + y + p-&gt;x + p-&gt;y);\n}\nint handler(int n) {\n&nbsp; return sqrt(n);\n}\nint main(void) {\n&nbsp; int x = 2;\n&nbsp; int y = 3;\n&nbsp; Point p = { .x = 10, .y = 10 };\n&nbsp; printf(\"%d\", foo(x, y, &amp;p, handler));&nbsp; // 5.\n&nbsp; return 0;\n}&nbsp;\n</code></pre><p>在 C 语言中，函数有两种传递参数的方式，即通过“值”传递和通过“指针”传递。其中，对于值传递的方式，编译器会在函数调用时，将传入函数的参数值进行复制。因此，在这种情况下，调用时传入函数的参数与在函数内部使用的参数是两个不同的实体。而使用指针形式传入的参数，因为指针所表示的地址在传入函数前后均不会发生变化，所以如果在函数内部修改指针参数所指向的值，则发生在该值上的变化，在函数调用完成后也将一直存在。</p><p>这里在代码中，函数 foo 一共接收了四个参数，其中整型参数 x 与 y 均以值的方式传递。而对于紧接着的结构体与函数类型的参数，它们对应的变量 p 与 handler 则以指针的形式传递。需要注意的是，对于函数指针来说，可以在声明和调用时为其省略通常用于表明指针类型的 “*” 符号。这意味着函数 foo 的定义也可以写成如下形式：</p><pre><code class=\"language-c++\">int foo(int x, int y, Point* p, int(*handler)(int)) {\n&nbsp; return (*handler)(x + y + p-&gt;x + p-&gt;y);\n}\n</code></pre><h2>C 函数的调用约定</h2><p>我在<a href=\"https://time.geekbang.org/column/article/465228\"> 02 讲 </a>中和你提到过，C 标准中并未规定，语言的各类语法结构应该以怎样的方式来实现。但实际上，从编译器的角度来看，每一个函数在被调用时，应该以怎样的方式通过机器指令来实现其调用过程，却存在着相应的事实标准。而通常，我们把编译器实现函数调用时所遵循的一系列规则称为函数的“调用约定（Calling Convention）”。</p><p>调用约定规定了函数调用时需要关注的一系列问题，比如：如何将实参传递给被调用函数、如何将返回值从被调用函数中返回、如何管理寄存器，以及如何管理栈内存，等等。调用约定并非 C 语言标准的一部分，因此实际上每个编译器都可以使用自己独有的调用约定，来实现 C 函数的调用过程。但相应地，这也会导致另外一个问题：当具有外部链接的函数在多个不同编译单元内被使用，且这些不同编译单元对应的源文件通过不同的编译器进行编译时，那么它们各自生成的对象文件可能无法再被整合在一起，并生成最终的可执行文件。</p><p>幸运的是，对于 C 语言来说，运行在 x86-64 平台上的编译器基本都会根据所在操作系统的不同，选择使用几种常见的调用约定事实标准。比如，对于 Windows 来说，编译器会采用专有的 Microsoft x64 或 Vector 调用约定。而在 Unix 和类 Unix 系统上，则会使用名为 System V AMD64 ABI（后简称 “SysV”）的调用约定。类似地，对于 i386（IA32）、8086 等其他平台，它们也都有着对应的调用约定事实标准。<strong>而较为统一的调用约定，也在一定程度上保证了 C 程序在同一平台不同编译器下的最大可移植性。</strong></p><p>接下来，让我们看看 SysV 调用约定中都规定了哪些重要的实现细节。为了更直观地观察这些内容，让我们先来编写一段简单的 C 代码，并在 x86-64 平台上使用默认优化等级，通过 GCC 编译生成它所对应的汇编代码。具体如下图所示（在后面提到这张图时，我会统一用“图 A”代替）：</p><p><img src=\"https://static001.geekbang.org/resource/image/9c/28/9ca51546a4d204c6e5d5da2674c2a928.png?wh=1544x1686\" alt=\"图片\"></p><p>在上图中，左侧为 C 代码，右侧为对应的汇编代码，相同颜色的代码块表示源代码与汇编代码之间的对应关系。在 C 代码中，我们定义了名为 bar 与 foo 的两个函数，并在 foo 中调用了 bar。bar 函数不接收任何参数，调用后直接返回整型值 10。foo 函数共接收 8 个参数，调用后返回其内部整型变量 n 与函数 bar 调用返回值的和。在 main 函数中，定义有两个整型局部变量 x 与 y，而当函数 foo 被调用时，直接使用这两个局部变量，以及另外的 6 个字面量数字值作为它的参数。</p><p>实际上，在 x86-64 的机器指令中，函数调用是通过 <code>call</code> 指令来完成。而每一个函数体在执行完毕后，都需要再通过 <code>ret</code> 指令来退出函数的执行，并转移代码执行流程到之前函数调用指令的下一条指令上。你可以通过下面这张图来直观地感受这个流程。其中，箭头标注出了代码的整体执行顺序。</p><p><img src=\"https://static001.geekbang.org/resource/image/c9/b0/c906a7d607fcc4cd74b97df718a80cb0.jpg?wh=1920x661\" alt=\"图片\"></p><p>接下来，我们来具体看看 SysV 调用约定中都规定了函数调用时的哪些内容。</p><h3>参数传递</h3><p>SysV 调用约定的第一个规则是：在调用函数时，对于整型和指针类型的实参，需要分别使用寄存器 rdi、rsi、rdx、rcx、r8、r9，按函数定义时参数从左到右的顺序进行传值。而若一个函数接收的参数超过了 6 个，则余下参数将通过栈内存进行传送。此时，多出来的参数将按照从右往左（RTL）的顺序被逐个压入栈中。关于这一点，你可以通过图 A 右侧第 30 到 40 行红框内的汇编代码得到验证。</p><p>这里，函数 foo 在调用前，分别用寄存器 edi、esi 存放局部变量 x 与 y 的值，并用寄存器 edx、ecx、r8d、r9d 存放字面量值 3、4、5、6（如果你还不了解寄存器 rdi 与 edi 的关系，可以在<a href=\"https://time.geekbang.org/column/article/464543\">课前热身</a>一讲中得到答案）。而多出来的另外两个字面量值参数 7 和 8 ，则直接通过 <code>push</code> 指令被放在了栈内存中。你需要注意这里指令操作它们的先后顺序，因为要保证这些参数以从右向左的顺序被放入栈中。另外，由于 x、y 为局部变量，因此最开始它们会被存储在栈内存中。</p><p>除此之外，对于浮点参数，编译器将会使用另外的 xmm0到xmm7，共 8 个寄存器进行存储。对于更宽的值，也可能会使用 ymm 与 zmm 寄存器来替代 xmm 寄存器。而上面提到的 xmm、ymm、zmm 寄存器，都是由 x86 指令集架构中名为 AVX（Advanced Vector Extensions）的扩展指令集使用的。这些指令集一般专门用于浮点数计算以及 SIMD 相关的处理过程。</p><h3>返回值传递</h3><p>对于函数调用产生的返回值，SysV 调用约定也有相应的规则：当函数调用产生整数类型的返回值，且小于等于 64 位时，通过寄存器 rax 进行传递；当大于 64 位，小于等于 128 位时，则使用寄存器 rax 与 rdx 分别存储返回值的低 64 位与高 64 位。你可以参考图 A 右侧第 4、21、47 行蓝框内的代码，来验证这个规则。这三行代码分别处理了函数 bar、foo，以及 main 的返回值。需要注意的是，对于复合类型（比如结构体）的返回值，编译器可能会直接使用栈内存进行“中转”。</p><p>对于浮点数类型的返回值，同参数传递类似，编译器会默认使用 xmm0 与 xmm1 寄存器进行存储。而当返回值过大时，则会选择性使用 ymm 与 zmm 来替代 xmm 寄存器。</p><h3>寄存器使用</h3><p>SysV 调用约定对寄存器的使用也作出了规定：对于寄存器 rbx、rbp、rsp，以及 r12 到r15，若被调用函数需要使用它们，则需要该函数在使用之前将这些寄存器中的值进行暂存，并在函数退出之前恢复它们的值（callee-saved）。而对于其他寄存器，则根据调用方的需要，自行保存和恢复它们的值（caller-saved）。</p><h3>堆栈清理</h3><p>每一个函数在调用结束前，都需要由它自身完成堆栈的清理工作。比如在图 A 所示的代码中，foo 函数在被调用时，它在栈内存中分配了对应的空间，用于存放局部变量 n 的值。而在该函数执行完毕，准备退出前，便需要由它自己将之前在栈上分配的数据清理干净。而这个任务是可以由 <code>leave</code> 指令来完成的。我会在接下来讲解“栈帧”时，再深入介绍与该指令相关的内容。</p><p>除此之外，对于 foo 函数被调用前所传入实参的清理工作，则是由调用函数，也就是这里的 main 函数来完成的。可以看到，当 foo 函数调用结束，程序执行流程返回到之前 <code>call</code> 指令的下一条指令时，程序通过 <code>add</code> 指令修改了 rsp 寄存器的值。通过这种方式，main 函数对之前放入栈中传递给函数 foo 的实参进行了清理。</p><h3>其他约定</h3><p>除此之外，SysV 调用约定还有下面这几点规定：</p><ul>\n<li>函数在被 <code>call</code> 指令调用前，需要保证栈顶于 16 字节对齐，也就是栈顶的所在地址值（以字节为单位）是 16 的倍数；</li>\n<li>从栈顶向上保留 128 字节作为 “Red Zone”；</li>\n<li>不同于用户函数的调用过程，系统调用（System Call）函数需使用寄存器 rdi、rsi、rdx、r10、r8、r9 传递参数。</li>\n</ul><p>我们来重点看看第二点：Red Zone 是位于栈顶向上（低地址方向）的一段固定长度的内存段，这块区域通常可以被函数调用栈中的“叶子”函数（即不再调用其他函数的函数）使用。这样，在需要额外的栈内存时，就能在一定条件下省去先调整栈内存大小的过程。而有关第三点中涉及到的与系统调用相关的内容，我将在这门课的“C 程序运行原理篇”中再为你深入讲解。</p><h2>保存函数调用信息的栈帧</h2><p>函数的调用过程伴随着栈内存中数据的不断变化。从整体上来看，每一个函数在调用时，都会在栈内存中呈现出基本相同的数据布局结构。而通过这种方式划分出来的，对应于每一次函数调用的栈内存数据块，我们一般称它为“栈帧”。栈帧中存放有与每个函数调用相关的返回地址、实参、局部变量、返回值，以及暂存的寄存器值等信息。</p><p>在进程的 VAS 中，栈内存是从高地址向低地址逐渐增长的，即栈底位于高地址处，栈顶位于低地址处。而当一个函数在执行过程中需要使用更多的栈内存空间时，便需要首先通过某种方式来扩大进程的可用栈内存大小。</p><p>通过操作寄存器 rsp，我们便可完成这个操作。rsp 寄存器又被称为 Stack Pointer，该寄存器中一直存放着当前栈内存顶部（低位地址）的地址。也就是说，<strong>rsp 寄<strong><strong>存</strong></strong>器的值决定了进程所能够使用的栈内存大小</strong>。因此，通过减小该寄存器的值，我们便能够扩大进程的可用栈内存空间。你可以通过下图，直观地体会到它们之间的关系：</p><p><img src=\"https://static001.geekbang.org/resource/image/04/3f/04ba684d4063355929ff8c4d0714cf3f.jpg?wh=1920x1156\" alt=\"图片\"></p><p>现在让我们把目光移动到函数 bar 身上，来详细看看，它在通过 <code>call</code> 指令调用后都发生了什么。</p><p>当 <code>call</code> 指令执行时，函数执行完毕后的返回地址会被首先推入栈中。以 bar 函数为例，当该函数被调用时，图 A 中右侧代码第 20 行对应的机器指令地址便会被存放到栈内存中。接下来，函数的第一行指令 <code>push rbp</code> 会将当前寄存器 rbp 的值暂存到栈中，以便在函数执行完毕后恢复该寄存器的值。rbp 寄存器又被称为 Frame Pointer，即“栈帧寄存器”。通常情况下，它被用来存储函数调用前的“栈高度”，即寄存器 rsp 的旧值，以便用于在函数执行过程中进行栈帧中数据的寻址，并在函数退出前把栈中的数据恢复到函数调用前的状态。</p><p>紧接着，第二句指令 <code>mov rbp, rsp</code> 便将存有此刻栈高度的寄存器 rsp 的值“备份”到寄存器 rbp 中。当函数体的内容（第三条语句）执行完毕后，程序通过 <code>pop</code> 指令恢复寄存器 rbp 的值，并通过 <code>ret</code> 指令将程序的执行转移到函数调用前，存入栈中的那个返回地址上去。</p><p>在函数 bar 的执行过程中，由于我们没有在栈上分配任何数据，因此在函数实际执行结束前，也并不需要对栈进行任何清理工作。所以你会发现，和 foo 函数与 main 函数相比，bar 函数在 <code>ret</code> 指令之前少执行了一条 <code>leave</code> 指令。而事实上，这条指令便会通过恢复寄存器 rsp 的值来“清理”栈上的数据，并同时恢复寄存器 rbp 的值。</p><p>进一步观察 main 函数的实现细节，你会发现函数在执行时使用栈的痕迹。比如汇编代码中的第 29 行，这里通过 <code>sub</code> 指令减小了寄存器 rsp 的值，以将当前的可用栈空间扩大 16 个字节。接着，通过第 30、31 行指令，函数为局部变量 x 和 y 分配相应的栈内存，并将初始值 1 和 2 分别存放到了栈上 rbp-4 与 rbp-8 的位置，每一个占用 4 字节大小。随后，在代码的第 34、35 行，借助 <code>push</code> 指令，额外的两个 4 字节参数值同样被存放到了栈内存中。此时，main 函数对应的栈帧内容如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/01/18/01abd718698251019f7ec97649da0b18.jpg?wh=1920x1259\" alt=\"图片\"></p><p>到这里，相信你已经对函数的调用过程以及栈帧的概念有了大致的了解。可以看到的是，随着嵌套函数的不断调用，每一个调用过程所产生的栈帧都会按照函数的调用顺序被依次存放在栈内存中。而当嵌套函数的层级足够深，导致栈内存已达到可用的最大值，进而无法再存放栈帧时，便会发生我们常见的 “Stack Overflow”，即“栈溢出”的问题。而在下一讲中，我会带你一起看看，如何借助“尾递归优化”技巧来解决这个问题。</p><h2>总结</h2><p>好了，讲到这里，今天的内容也就基本结束了。最后我来给你总结一下。</p><p>这一讲，我首先带你快速回顾了 C 语言中函数的具体用法，然后介绍了编译器在实现 C 函数调用时需要关注的一系列规则，即 C 函数中的调用约定。在类 Unix 系统上，编译器通常会使用名为 System V AMD64 ABI 的调用约定，来作为实现函数调用的事实标准。SysV 调用约定中规定了函数在调用时需要注意的参数传递、寄存器使用，以及堆栈清理等方面的具体规则。</p><p>每一个被调用函数都会在栈内存中存放与其对应的栈帧结构。栈帧中包含着函数在被调用时需要的所有关键信息，其中包括函数返回地址、某些寄存器的旧值、函数调用过程中局部变量的值，等等。</p><h2>思考题</h2><p>在这一讲的最后，我们来一起做个思考题吧。</p><p>在不使用 <code>leave</code> 指令的情况下，你知道应该如何进行栈清理，并恢复寄存器 rbp 与 rsp 的值吗？而与它对应的 <code>enter</code> 指令又有什么作用呢？欢迎在评论区留下你的答案。</p><p>今天的课程就结束了，希望可以帮助到你，也希望你在下方的留言区和我一起讨论。同时，欢迎你把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"04｜控制逻辑：表达式和语句是如何协调程序运行的？","id":467203},"right":{"article_title":"06｜代码封装（下）：函数是如何被调用的？","id":469250}}},{"article_id":469250,"article_title":"06｜代码封装（下）：函数是如何被调用的？","article_content":"<p>你好，我是于航。</p><p>在上一讲中，我们主要围绕着 x86-64 平台上 C 函数被调用时需要遵循的一系列规则，即 System V AMD64 ABI 调用规范的内容展开了深入的探讨。而今天，我们将继续讨论有关 C 函数的话题，来看看参数求值顺序、递归调用、旧式声明的相关内容。这些内容将会帮助你更加深入地理解 C 函数的运作细节，写出更加健壮、性能更高的代码。</p><h2>编写不依赖于参数求值顺序的函数</h2><p>当一个函数被调用时，传递给它的实际参数应该按照怎样的顺序进行求值，这在 C 标准中并没有被明确规定。因此，对于某些特殊的代码形式，当运行使用不同编译器编译得到的二进制可执行文件时，可能会得到不同的计算结果。比如下面这段代码：</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\nint main(void) {\n&nbsp; int n = 1;\n&nbsp; printf(\"%d %d %d\", n++, n++, n++);\n&nbsp; return 0;\n}&nbsp;\n</code></pre><p>这里，我们使用 printf 函数，连续打印出了表达式 <code>n++</code> 的值。当使用 Clang 13.0.0 编译器进行编译并运行这段代码时，可以得到输出结果 “1 2 3”。而换成 GCC 11.2 时，则得到了不同的结果 “3 2 1”。通过查看汇编代码，我们能够看到：Clang 按照从左到右的顺序来依次计算表达式 <code>n++</code> 的值，而 GCC 则与之相反。</p><!-- [[[read_end]]] --><p>因此，你需要注意的是：<strong>为了保证 C 程序的健壮性及可移植性，不要编写需依赖特定函数参数求值顺序才能够正常运行的代码逻辑</strong>。</p><h2>尾递归调用优化</h2><p>对于“递归函数”，相信你并不陌生。简单来说，递归函数就是一种自己可能会调用自己的函数。比如在下面的 C 代码中，factorial 函数便是一个递归函数。</p><pre><code class=\"language-c++\">int factorial(int num) {\n&nbsp; if (num == 1 || num == 0)\n&nbsp; &nbsp; return 1;\n&nbsp; return num * factorial(num - 1);\n}\n</code></pre><p>factorial 函数主要用于计算给定数的阶乘。你可以在上述代码的第四行，看到它对自己的调用过程。接下来，我们使用 GCC 在默认优化等级情况下编译这段 C 代码，可以得到如下图所示的汇编代码：</p><p><img src=\"https://static001.geekbang.org/resource/image/c3/07/c31efd658886cd8a9811bac2de593507.png?wh=1496x790\" alt=\"图片\"></p><p>这里，在上图右侧的第 17 行处，我们可以看到 factorial 函数对自己的调用过程。</p><p>通过上一讲的学习我们得知，函数调用过程中所需要的数据是以栈帧的形式被存放在进程的栈内存中的。而对栈内存的清理工作，只有当被调用函数执行完毕，准备通过 <code>ret</code> 指令返回前，才能够通过调用 <code>leave</code> 指令等方式进行。</p><p>而对于正常的递归函数来说，由于函数不断调用自己，导致先前调用产生的函数栈帧只有在后续调用的函数正常返回后，才能够得到清理。随着函数的不断调用，产生的栈帧越来越多，因此在栈内存无法再继续增长的情况下，便会发生溢出，进而导致程序出现 “Segmentation Fault” 等错误。</p><p>除此之外，每次的函数调用都会进行栈帧的创建和销毁过程，而随着函数调用次数的增加，这部分开销也可能逐渐影响程序的外部可观测性能。</p><p>那有没有办法解决这两个问题呢？答案是有的，它正是我在这里要介绍的“尾递归调用优化（Tail-Call Optimization）”。</p><p>尾递归调用优化是指在一定条件下，编译器可以直接<strong>利用跳转指令取代函数调用指令</strong>，来“模拟”函数的调用过程。而这样做，便可以省去函数调用栈帧的不断创建和销毁过程。而且，递归函数在整个调用期间都仅在栈内存中维护着一个栈帧，因此只使用了有限的栈内存。对于函数体较为小巧，并且可能会进行较多次递归调用的函数，尾递归调用优化可以带来可观的执行效率提升。</p><p><strong>尾递归调用的一个重要条件是：递归调用语句必须作为函数返回前的最后一条语句。</strong>怎样理解这个约束条件呢？我们来看下面这个例子：</p><p><img src=\"https://static001.geekbang.org/resource/image/aa/c7/aa964ca47cb9aa93c23192ffa02a72c7.png?wh=1920x561\" alt=\"图片\"></p><p>这里的 C 代码和上面那段功能完全相同，只不过我们修改了函数 factorial 的实现逻辑，并且在编译时指定了最高的编译优化等级 “-O3”。通过查看右侧的汇编代码，你可以发现，编译器并没有进行任何 <code>call</code> 指令的调用过程。而这就是因为它使用了尾递归调用优化。</p><p>尾递归调用优化的一个最显著特征，就是编译器会<strong>使用跳转指令（如<code>je</code>、<code>jne</code>、<code>jle</code>等）来替换函数调用时所使用的 call指令</strong>。这里函数 factorial 在执行 <code>ret</code> 指令返回前，会判断寄存器 edi 的值是否为 0（ZF=1），来决定是跳转到 “.L2” 标签处继续“递归”执行该函数，还是直接返回。当然，由于这里“实现递归”的方式是通过跳转指令而非函数的再次调用，在函数 factorial 执行的整个过程中，栈内存中仅有其对应的一个栈帧（是由调用 factorial 的函数通过 <code>call</code> 指令创建的）。</p><p>此时，如果我们尝试违背尾递归优化的重要前提，会有什么结果呢？来看个例子：在 factorial 函数的第一种实现方式中，由于函数的前一次调用结果依赖于函数下一次调用的返回值，导致存放在栈帧中的局部变量 num 的值无法被清理，因此编译器也就无法通过消除历史函数调用栈帧的方式，来模拟函数的递归调用过程。</p><p>而这就是尾递归调用优化以“递归调用语句必须作为函数返回前的最后一条语句”为前提条件的原因。在这种情况下，编译器才能够确定函数的返回值没有被上一个栈帧所使用。</p><p>但还有一点需要注意：现代编译器具备十分强大的程序执行流分析能力。在很多情况下，它能够直接提取出程序中可以使用循环进行表达的部分，同时避免 <code>call</code> 指令的调用过程。因此，编译器是否采用了尾递归优化，在大多数情况下已经很难直接从程序对应的汇编代码中看出了。而我们能做的，只是根据编译器实现尾递归优化的理论基础，来尽可能地从代码层面优化我们的程序。但实际执行时的效果如何，就要取决于具体编译器的能力了。毕竟，与如今强大的 GCC 与 Clang 等编译器相比，还有很多开源编译器甚至连基本的 C 标准特性都没有完全支持。</p><p>尾递归调用优化可以帮助我们减少函数调用栈帧的创建与销毁次数，这个过程涉及到寄存器的保存与恢复、栈内存的分配与释放等。但需要注意的是，<strong>尾递归调用优化的效果在那些函数体本身较小，且递归调用次数较多的函数上体现得更加明显。</strong>这里我们需要平衡的一点是：函数自身的执行时间与栈帧的创建和销毁时间，二者哪个占比更大。很明显，选择优化对性能影响更大的因素，通常会得到更大的收益。</p><h2>废弃的 K&amp;R 函数声明</h2><p>在 1989 年 ANSI C 标准出现之前，我们在声明一个 C 函数时，可以不为其指定参数列表。而对于这种方式，我们一般称其为 K&amp;R 函数声明。比如下面这个例子：</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\nint add();\nint main(void) {\n&nbsp; printf(\"%d\", add(1));  // ?\n&nbsp; return 0;\n}\nint add(int x, int y) {\n&nbsp; return x + y;\n}\n</code></pre><p>这里你可以看到，在代码第 2 行函数 add 的声明中，我们并没有为其指定任何形式参数。但在代码第 7 行函数 add 的实现中，该函数在执行时实际上会接收两个整型参数。虽然函数在其声明与定义中使用的参数列表并没有完全匹配，但为了保证程序的兼容性，现代编译器都默认支持这种代码形式。</p><p>在继续学习之前，你可以先猜一猜代码第 4 行对函数 add 的调用结果是多少。注意，这里在调用时，我们仅为 add 函数传入了一个实参，即一个整型字面量值 1。</p><p>经过实践，理想情况下你会得到结果 1，不过也可能会得到看起来毫不相关的随机数。但无论如何，程序的运行确实偏离了预期，而这也正是 C 语言被标准化前，K&amp;R 函数声明被人诟病的一个原因。</p><p>下面，就让我们来看一看，在这种情况下的函数 add 是如何被调用的。使用默认优化等级进行编译，我们得到了如下图所示的汇编代码：</p><p><img src=\"https://static001.geekbang.org/resource/image/0b/33/0be52e7ff812c7d5384e83c47e9c6233.png?wh=1920x1362\" alt=\"图片\"></p><p>沿着在 main 函数内部调用 add 函数的执行链路进行寻找，我们可以轻松地发现问题所在。</p><p>在上一讲中我们已经了解过，SysV 调用约定会使用寄存器 rdi、rsi 来传递用户函数调用时的前两个参数。而这里在 main 函数对应的汇编代码中，可以看到 add 函数在被调用前，编译器仅通过蓝框内的汇编指令，对传入 add 函数的第一个参数进行了处理，将它存放到了寄存器 edi 中。而 add 函数在实际执行时，会通过红框内的指令，同时从寄存器 edi、esi 中初始化它所需要的两个参数。因此，此时寄存器 esi 中的值是什么，便决定了该函数的最终返回值。而它可能是 0，也有可能是各种随机数。</p><p>总的来看，<strong>出现问题的原因是编译器并没有强制要求函数声明、函数定义，以及函数调用三者的参数列表必须保持一致。</strong>因此，为了杜绝此类问题，ANSI C 标准化之后的 C 语言提出了新的“函数原型”概念，以取代旧时使用的函数声明方式。</p><p>和函数声明不同，函数原型强制程序员显式指出函数参数的使用方式，即使在没有参数时，也需要显式地将参数部分指定为 void。同时，对于函数原型、函数定义，以及函数调用，三者的参数列表必须保持一致，否则将无法通过编译。</p><p>上面的 C 代码在使用函数原型改写后如下所示：</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\nint add(int x, int y);\nint main(void) {\n&nbsp; printf(\"%d\", add(1));  // compiling error!\n&nbsp; return 0;\n}\nint add(int x, int y) {\n&nbsp; return x + y;\n}\n</code></pre><p>此时若再次进行编译，编译器将会提示“参数不匹配”的错误。</p><p>总而言之，言而总之，为了减少产生这种不必要问题的机会，<strong>请不要在 C 代码中使用古老的 K&amp;R 函数声明</strong>。换句话说，每一个函数参数列表都不应该为空。</p><h2>总结</h2><p>好了，讲到这里，今天的内容也就基本结束了。最后我来给你总结一下。</p><p>这一讲，我主要和你讨论了有关 C 函数的另外三个话题，分别是函数参数求值顺序、尾递归调用优化，以及 K&amp;R 函数声明。</p><p>首先，编译器对函数参数的求值顺序并不固定，因此，不要试图编写需要依赖于特定参数求值顺序才能正常运行的代码逻辑。</p><p>其次，对递归函数的不正确使用，可能会导致进程栈内存出现溢出。而通过尾递归优化，编译器可以将函数的递归调用实现由 <code>call</code> 指令转换为条件跳转指令，从而大大减少函数调用栈帧的产生，进而避免了栈溢出的问题。不仅如此，这种方式也在一定程度上提高了函数的执行性能。</p><p>最后，考虑到兼容性，现代编译器仍然支持旧式的 K&amp;R 函数声明式写法，但这种写法极易引入难以调试的程序问题。因此，请确保为每一个函数参数列表都指明它所需要的参数类型。</p><h2>思考题</h2><p>在课程的最后，我们来一起做个思考题吧。</p><p>除了我在这两讲中介绍的有关 C 函数的内容，现代 C 语言中还增加了很多有关函数的新特性。比如，C11 中新引入了一个名为 <code>_Noreturn</code> 的关键字，可参与函数的定义过程。你可以动手查查它的用处，思考它存在的意义，并在评论区交流。</p><p>今天的课程就结束了，希望可以帮助到你，也希望你在下方的留言区和我一起讨论。同时，欢迎你把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"05｜代码封装（上）：函数是如何被调用的？","id":468171},"right":{"article_title":"07｜整合数据：枚举、结构与联合是如何实现的？","id":471133}}},{"article_id":471133,"article_title":"07｜整合数据：枚举、结构与联合是如何实现的？","article_content":"<p>你好，我是于航。</p><p>C 语言为我们提供了高于机器指令的一定抽象能力，这使得我们能够以接近自然语言的方式来构建应用程序。如果说使用 C 语言是用砖块来造房子，那使用其他高抽象粒度编程语言，就是直接以墙面为单位来搭建。很明显，从这个角度来说，C 语言用起来不如其他高级语言方便，但它也同时给予了更细的构建粒度，让我们能够按照自己的想法，灵活自定义墙面的形态。</p><p>对于这里提到的砖块和墙面，你可以将它们简单理解为编程语言在构建程序时使用的数据类型。比如在 Python 语言中，我们可以使用集合（set）、字典（dict）等复杂数据类型。而在 Java 语言中，Map 本身又会被细分为 HashMap、LinkedHashMap、EnumMap 等多种类型，供不同应用场景使用。</p><p>为了在保持自身精简的同时也保证足够高的灵活性，C 语言在提供基本数值类型和指针类型的基础上，又为我们提供了结构（struct）、联合（union）与枚举（enum）这三种类型。结合使用这些类型，我们就能将小的“砖块”组合起来，从而将它们拼接成为更大的、具有特定功能结构的复杂构建单元。</p><p>接下来，就让我们一起看看：编译器是如何在背后实现这三种数据类型的？而在实现上，为了兼顾程序的性能要求，编译器又做了哪些特殊优化？</p><!-- [[[read_end]]] --><h2>枚举</h2><p>在编程语言中，枚举（Enumeration）这种数据类型可以由程序员自行定义，用来表示某类可取值范围有限的抽象概念。</p><p>下面我们来看一个经典的例子：应该如何使用编程语言来表示 “周工作日（weekday）” 这个概念呢？</p><p>周工作日属于现实世界中的一种抽象概念，它包含周一到周五共五个有效值。不同于数值、字符等概念，它无法直接对应到物理计算机中的任何软硬件实现上。因此，为了能够在程序中更加精确地表达这类信息，我们可以用枚举来自定义对应的类型。</p><p>在 C 语言中，我们可以这样实现：</p><p><img src=\"https://static001.geekbang.org/resource/image/45/d5/453a138a660a7e8f7c173391e17a75d5.png?wh=1920x1356\" alt=\"图片\"></p><p>为了便于观察，我直接展示了 C 代码及其对应的汇编代码。可以看到，编译器没有为左侧红框内的枚举类型定义生成任何的机器指令。实际上，在 C 语言中，每一个自定义枚举类型中的枚举值，都是以 <code>int</code> 类型的方式被存储的，因此，这些枚举值有时也被称为“具名整型”。你可以从上图右侧蓝框内的汇编代码中看到，当函数 foo 被调用时，传入的枚举值 Mon 正对应于通过 edi 寄存器传入的字面量数字 0。也就是说，枚举值 Mon 在底层是由数字值 0 表示的。</p><p>同样地，在左侧 C 代码的第 11 行，我们也使用了泛型宏来判断枚举值 Mon 的具体类型。你可以尝试运行这段代码，并观察程序的输出结果，以验证我们的结论。</p><p>需要注意的是，<strong>C 标准直接将枚举值当作整数进行处理的这种方式，可能会导致我们在构建程序时遇到意想不到的问题。</strong>比如，对于上述这段 C 代码，函数 foo 在被调用时，实际上允许传入任何可以被隐式转换为 <code>int</code> 类型的值，哪怕这个值来源于另一个枚举类型的变量。因此，让枚举类型有助于组织程序代码的同时并确保它不被乱用，也是我们在构建高质量程序时需要注意的一个问题。</p><h2>结构</h2><p>在 C 语言中，数组用来将一簇相同类型的数据存放在连续的内存段上。而结构（Struct）实际上与其类似，只不过在结构内部，我们可以存放不同类型的数据。先来看一段代码：</p><p><img src=\"https://static001.geekbang.org/resource/image/af/49/af6ffbd5313461163e28949d40636049.png?wh=1920x999\" alt=\"图片\"></p><p>在上图左侧的 C 代码中，我们定义了一个名为 S 的结构。对于每一个结构 S 的对象，其内部都会连续存放三个类型完全不同的数据值，即一个字符指针、一个字符值、一个长整型数值。</p><p>在代码的第 10 行，我们通过括号列表初始化的方式，构造了结构 S 的一个对象 s。通过右上方蓝框中的汇编代码，我们可以看到编译器是如何实现对它的初始化的。<strong>本质上，结构只是对其内部所包含各类数据的一个封装，因此从编译产物的角度来看，只需要把它封装的这些数据连续地存放在内存中即可。</strong>事实也正是如此，对结构 S 内部三个数据的初始化过程，均是由指令 <code>mov</code> 完成的，这些数据被初始化在栈内存中。</p><p>结构中的数据项被初始化在内存中，这毋庸置疑，但它们真的“连续”吗？</p><p>为了验证这个问题，我们在左侧 C 代码的第 12 行，通过 <code>sizeof</code> 运算符将结构 S 的大小打印了出来。按照结构 S 的定义方式和我们对“连续”一词的理解，它在 x86-64 平台上的大小应该为 17 字节。其中，字符指针 8 字节、字符 1 字节，最后的长整型数值 8 字节。但查看右侧黄框内的汇编代码后，你会发现事实并非如此：每一个结构 S 的对象竟然占用了多达 24 字节的内存。那这是为什么呢？</p><p>通过整理对象 s 在初始化时使用的汇编代码，我们可以得到其内部各个成员字段在栈内存中的实际布局情况。经过整理后，可以得到下面这张图：</p><p><img src=\"https://static001.geekbang.org/resource/image/43/d4/435e8e8e1c188698cccbf38e1ec719d4.jpg?wh=1920x475\" alt=\"图片\"></p><p>从左至右，这张图代表着栈内存的增长方向（高地址 -&gt; 低地址）。其中，寄存器 rsp 指向栈顶的低地址，而 rbp 寄存器则指向栈帧开始处的高地址。按照汇编代码中的指令，字符指针 p 位于 [rbp-32] 处，并占用 8 个字节；字符 c 位于 [rbp-24] 处，并占用 1 个字节。而长整型变量 x 则位于 [rbp-16] 处，并占用 8 个字节。</p><p>可以看到，编译器实际上并没有按照严格连续的方式来“摆放”这三个数据值，其中，[rbp-25] 到 [rbp-16] 中间的 7 个字节并没有存放任何数据。而编译器这样做的一个重要目的，便是为了“数据对齐”。</p><h3>内存数据对齐</h3><p>对于现代计算机而言，当内存中需要被读写的数据，其所在地址满足“自然对齐”时，CPU 通常能够以最高的效率进行数据操作。<strong>而所谓自然对齐，是指被操作数据的所在地址为该数据大小的整数倍。</strong>比如在 x86-64 架构中，若一个 <code>int</code> 类型的变量，其值在内存中连续存放，且最低有效位字节（LSB）的所在地址为 4 的整数倍，那我们就可以说该变量的值在内存中是对齐的。</p><p>自然对齐为什么能够发挥 CPU 最大的内存读取效率呢？这实际上与 CPU 和 MMU（内存管理单元）等内存读写相关核心硬件发展过程中的诸多限制性因素有关。比如，对于某些古老的 Sun SPARC 和 ARM 处理器来说，它们只能访问位于特定地址上的对齐数据，而对于非对齐数据的访问，则会产生异常。相反，有些处理器则能够支持对非对齐数据的访问，但由于设计工艺上的限制，对这些数据的访问需要花费更多的时钟周期。</p><p>因此，为了让代码适应不同处理器的“风格”，保证内存中的数据满足自然对齐要求，就成了大多数编译器在生成机器指令时达成的一个默认共识。哪怕在如今的现代 x86-64 处理器上，访问非对齐数据所产生的性能损耗在大多数情况下已微不足道。</p><h3>填充字节</h3><p>让我们再回到之前那个例子。可以看到的是，为了确保对象 s 中所有成员字段在栈内存中都满足自然对齐的要求，编译器会插入额外的“填充字节”，来动态调整结构对象中各个字段对应数据的起始位置。</p><p>除此之外，在某些情况下，即使结构对象内各个数据成员都满足自然对齐的要求，额外的填充字节也可能会被添加。比如下面这个例子：</p><pre><code class=\"language-c++\">struct Foo {\n&nbsp; char *p;&nbsp; // 8 bytes.\n&nbsp; char c;  // 1 bytes.\n  // (padding): 7 bytes.\n};\n</code></pre><p>这里可以看到，结构 Foo 中的两个成员字段在默认情况下已经满足自然对齐的要求（假设字符指针 p 的存放起始位置满足 8 字节对齐）。但实际上，在通过 <code>sizeof</code> 运算符对它进行求值时，我们会得到 16 字节大小的结果，而非直观的 9 字节。</p><p>之所以会出现这样的现象，就是因为编译器想要保证这一点：当结构对象被连续存放时（比如通过数组），前一个对象的结束位置正好可以满足后一个对象作为起始位置时的自然对齐要求。而这也就要求结构对象本身的大小必须是其内部最大成员大小的整数倍。因此，编译器会在结构最后一个成员的后面再填充适当字节，以满足这个条件。可以说，在这种情况下的结构对象，已经满足了在不同场景下的自然对齐条件，因此，此时的结构大小也会被作为 <code>sizeof</code> 运算符的最终计算结果。</p><h2>联合</h2><p>最后，我们再来看看 C 语言中的第三种功能强大的数据类型，“联合（Union）”。联合与“结构”在语法上的使用方式十分类似，只不过要把对应的语法关键字从 <code>struct</code> 更换为 <code>union</code> 。</p><p>除此之外，二者还有一个较大的区别，我们可以从“联合”这个名字谈起。顾名思义，“联合”就意味着定义在该结构内的所有数据字段，将会联合起来共享同一块内存区域。还是先来看一段代码：</p><p><img src=\"https://static001.geekbang.org/resource/image/46/18/4609c5e57d1b198884bf5b7d2ee86a18.png?wh=1920x1203\" alt=\"图片\"></p><p>这里，在左侧的 C 代码中，我们使用 “Tagged Union” 的模式对联合进行了封装。<strong>与结构不同，对于每一个单独的联合对象来说，在某一时刻其内部哪一个字段正在生效，我们无从得知。</strong>因此，Tagged Union 的使用方式要求我们为每一个联合设置单独的“标签”，用来明确指出当前联合内部正在生效的字段。在这种情况下，我们便需要将这个标签与联合进行封装，来将它们进行“绑定”。</p><p>可以看到，这里在结构 S 内部，枚举类型字段 type 就是用来标记当前匿名联合内部所存放的数据种类的。而在紧接着的匿名联合内部，整型成员 i 与字符成员 c 则共享该联合的内存空间。这便是 Tagged Union 在 C 语言中的基本使用方式。</p><p>一个联合对象的大小同该联合内部定义时所包含最大成员的大小相同，因此在上面这个例子中，结构 S 中的匿名联合大小便与联合定义内整型参数 i 的大小相同。这个大小在 x86-64 平台上为 4 字节。</p><p>从图片右侧蓝框内的汇编代码中，我们也可以得到相同的结论。第一行代码将整个结构对象 s 所占用的 8 字节空间全部置零，来为后续的匿名联合对象赋值做准备；第二行代码将枚举类型 CHAR 对应的值 1 赋值给结构对象 s 内的枚举字段 type；第三行代码将字符 “a” 对应的值 97 存放到结构对象 s 内的匿名联合对象中。这里可以看到，指令 <code>mov</code> 在进行数据传送时，在目的地参数中使用了 BYTE，也就是“取出”了联合对象所占用的 4 字节空间中的 1 个字节，将其作为存放字符数值的目标内存空间。</p><h2>总结</h2><p>好了，讲到这里，今天的内容也就基本结束了，最后我来给你总结一下。</p><p>这一讲我主要围绕着 C 语言中的枚举、结构与联合这三种数据类型展开了介绍，和你一起探究了它们在机器指令层面的具体实现方式。</p><p><strong>枚举这种数据类型，用于表示可取值范围有限的抽象实体。</strong>枚举类型中的枚举值又被称为“具名整型”，因此在 C 代码中，它可以直接被当作整数值来使用。同样地，在编译器生成的代码中，枚举值将被直接替换为对应的整数值。但需要注意的是，我们要在进行 C 编码时保证枚举值和它对应的整数值不被乱用。</p><p><strong>结构是一种用于组织异构数据的复合数据类型。</strong>在结构中，所有定义的数据字段在内存中按顺序排列。为了保证结构中各个字段最高效的数据访问速度，编译器在内存中布局这些字段数据时，会保证它们的起始地址满足自然对齐的标准。因此，结构中字段的不同定义顺序将直接影响结构对象的实际内存占用大小，而这也是我们进行程序优化的一个重要切入点。</p><p><strong>联合是一种特殊的复合数据类型，在其内部定义的所有数据字段将占用同一块内存空间。</strong>联合对象的实际大小与其内部所定义最大字段的大小相同。默认情况下，我们无法从外部得知一个联合对象中正在“生效”的字段类型，因此 Tagged Union 的使用方式便成为主流。将用来标识生效字段的枚举类型与联合进行“打包”，我们就可以在使用联合对象前进行相应的判断和准备，而这也为应用程序的健壮性打下了基础。</p><h2>思考题</h2><p>最后，我们一起做个思考题。</p><p>试着用与这一讲中类似的方式进行分析：下面这个结构体在经过 <code>sizeof</code> 运算符计算后，所得到的大小是多少？</p><pre><code class=\"language-c++\">struct {\n&nbsp; short a;\n&nbsp; char b;\n&nbsp; char c;\n&nbsp; int* d;\n&nbsp; union {\n&nbsp; &nbsp; double e;\n&nbsp; &nbsp; int f;\n&nbsp; };\n};\n</code></pre><p>今天的课程就结束了，希望可以帮助到你，也希望你在下方的留言区和我一起讨论。同时，欢迎你把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"06｜代码封装（下）：函数是如何被调用的？","id":469250},"right":{"article_title":"08｜操控资源：指针是如何灵活使用内存的？","id":471937}}},{"article_id":471937,"article_title":"08｜操控资源：指针是如何灵活使用内存的？","article_content":"<p>你好，我是于航。</p><p>“指针”是 C 语言为我们提供的最为强大的武器之一。借助指针，我们可以更加灵活地使用应用程序所享有的内存。</p><p>不同于 Python、Java 等语言，C 语言为我们提供了这样一种能力：可以让程序员根据需要，主动选择使用“按值传递”或“按指针传递”这两种不同的数据引用方式。通常，按值传递会涉及原始数据的复制过程，因此在某些情况下，可能会引入额外的性能开销。而按指针传递则使程序内存中的“数据共享”成为了可能。</p><p>这一讲，就让我们来一起看下，在 C 语言中指针都有哪些使用方式，以及在语法背后，这些方式都是如何通过机器指令来实现的。</p><h2>指针的基本使用</h2><p>使用 C 语法定义变量时，通过为类型说明符添加额外的 “ * ” 符号，我们可以定义一个指向该类型数据的指针。不仅如此，通过添加额外的 <code>const</code> 关键字，我们还能够限制使用该指针变量时所能够进行的操作类型。</p><p>比如在下面这个例子中，我们便定义了这样的一个指针。通过添加 <code>const</code> 关键字，编译器限制了对指针 npA 的使用，使得它自身无法被重新赋值，并且也无法通过它来修改所指向的数据。</p><p><img src=\"https://static001.geekbang.org/resource/image/3a/05/3a64f116672998af96b364b616a6e405.png?wh=1920x712\" alt=\"图片\"></p><p>指针不仅在 C 语言中的使用方式很简单，它在机器指令层面的实现也十分简单。还记得我们在 <a href=\"https://time.geekbang.org/column/article/466203\">03 讲</a> 中最后介绍过的取地址 “&amp;” 与解引用 “*” 运算符吗？通过使用这两个运算符，我们便能够完成对指针的最基本，也是最重要的两个操作，即取值与赋值。</p><!-- [[[read_end]]] --><p>观察上图中红框与蓝框内的 C 代码与汇编代码，我们来快速复习一下相关内容。取地址运算符可以用来获取内存中某个数据的所在地址，该过程一般会通过红框内的 <code>lea</code> 指令来实现，而解引用的过程正与此相反。如右侧蓝框内的第二行代码所示，直接通过 <code>mov</code> 指令，我们便可以按照所指向数据类型的固定大小（这里为 DWORD，即 32 位），来与对应内存地址上存放的数据值进行交互。</p><h2>指针与数组</h2><p>除了我们显式定义的各类指针变量外，指针与数组也有着千丝万缕的联系。数组是一块连续存放有相同类型数据的内存区域。在 C 语言中，数组有不同的使用方式，有些使用方式可能导致其被退化（dacay）为相应的指针类型。我们来看下面这个例子。</p><p><img src=\"https://static001.geekbang.org/resource/image/64/02/6478bb495988777e77c494192c7d3f02.png?wh=1920x1007\" alt=\"图片\"></p><p>从上图左侧红框内的 C 代码中可以看到，我们在主函数内定义了一个包含有 4 个整型元素的数组 arr。在默认情况下，数组中的元素会以相邻的方式分配在连续的栈内存中。从右侧红框内的汇编代码中，我们可以验证这一点。</p><p>紧接着，通过调用名为 sum 的函数，我们可以求得数组内所有元素的累加和。该函数共接收两个参数，第一个为目标数组，第二个为该数组包含的元素个数。这里，我们直接将 arr 作为第一个参数传入。而此时，通过 <code>sizeof</code> 运算符，我们也能够在编译时得到有关数组 arr 的大小信息，并动态计算出数组中元素的个数。</p><p>但当数组 arr 作为实参被传入函数 sum 后，事情发生了变化。从上图右侧蓝框内的汇编代码中可以看出，函数被调用前，rdi 寄存器内存放的是 rbp-16，也就是数组 arr 首个元素对应地址的值。因此，传递给函数 sum 的第一个参数实际上为一个指向 <code>int</code> 类型的指针，而有关数组 arr 的大小和类型的信息在此时已经全部丢失。对于这种情况，我们一般称其为“数组的退化”，即<strong>数组类型退化为指针类型</strong>。</p><h2>指针的其他运算</h2><p>在 C 语言中，除了可以对指针进行基本的解引用、赋值，甚至再次取地址的操作外，我们还可以对它进行算数与关系运算。但需要注意的是，指针的这两种运算不同于一般的数值类型。比如，对指针进行加法运算，就并不是将加数直接累加在对应的地址值上这么简单。你也可以再回顾一下上面讲解指针和数组时的示例代码，从函数 sum 的实现中，可以看到我们对退化指针 arr 的算数运算过程。</p><h3>算数运算</h3><p>总的来看，我们可以对指针类型进行这样几种算数运算：</p><ul>\n<li>单个指针与另一个整数相加/相减；</li>\n<li>单个指针自增/自减；</li>\n<li>两个指针求差。</li>\n</ul><p>指针在进行算数运算后，不能将其指向的、以固定长度字节作为整体的数据值“拆分”。因此，当我们对指针进行加法、减法、递增、递减运算时，编译器实际上是以当前指针所指向值对应的某个固定长度为单位，对指针中存放的地址值进行相应调整的。同样，对于指针之间的求差操作，求得的也并不是两个地址值之间以字节为单位的差，而是用这个差值除以上面提到的固定长度所得到的结果。</p><p>下面，让我们通过一个例子，来看看<strong>编译器是如何在背后处理针对指针的算数运算的</strong>。这里我介绍的是“单个指针与另一个整数相加”这种场景。由于其他指针算数运算的过程与此基本类似，相信理解了这一种，另外几种你也能融会贯通。</p><p><img src=\"https://static001.geekbang.org/resource/image/13/ba/13e25f1000d399993c79a81db8yy34ba.png?wh=1920x1229\" alt=\"图片\"></p><p>这里在 main 函数的开始，我们定义了一个名为 arr 的，具有 2 行 3 列，共 6 个元素的二维数组。从右侧对应的汇编代码中，可以看到这个数组内部的数据是以地址连续的方式被存放在栈内存中的。对于这个存储方式，你可以将其理解为<strong>编译器对 C 代码中的多维数组进行的扁平化（flatten）处理</strong>。</p><p>在接下来的 C 代码中，我们通过指针的方式获取并打印了位于数组 arr 中两个不同位置上的值。其中，蓝框内的表达式首先对二级指针 arr 进行了加一操作，然后返回了对这个经过“累加”后的地址进行两次解引用的结果值。从右侧相应的汇编代码中可以看到，对指针 arr 的加一操作导致 rax 寄存器中的值被增加 12。而该寄存器中原先存放有数组中第 1 行第 1 列元素对应的地址值，因此在经过计算后，我们得到了一个指向元素 4 的二级指针。</p><p>也就是说，对变量 arr 进行加一操作，导致该指针向栈中的高地址方向移动了 12 个字节。之所以会有这样的变化，是因为 arr 作为一个二级指针，它在这里所直接指向的数据，实际上是二维数组中的每一个包含有 3 个整型元素的一维数组。而每一个一维数组的大小都为固定的 12 字节。因此，当对指针 arr 进行算数运算时，编译器便会以它所指向的一维数组的大小为单位，来进行地址上的调整。</p><p>同样地，对于黄框内的第二次数组元素访问，由于 <code>*arr</code> 作为一级指针（经过了一次解引用），直接指向的是二维数组内某个一维数组中的整型元素，因此，对它进行加法运算，将会以 4 字节作为单位来进行地址上的调整。</p><p>这里我给你留一个小问题：按照类似的计算方式，你能否直接推算出下面这行语句在执行后的输出结果？欢迎在评论区留下你的答案。</p><pre><code class=\"language-c++\">printf(\"%d\\n\", *(*(arr + 1) + 1));&nbsp; // ?\n</code></pre><p>最后，需要注意的是，<strong>指针的算数运算在绝大多数情况下都只适用于数组相关的指针</strong>。而在其他场景中，即使程序可以正常编译运行，但由于标准中可能并未要求编译器的具体求值规则，因此其行为是未定义的，程序的运行结果无法得到保障。</p><h3>关系运算</h3><p>除了算数运算外，同一类型的不同指针之间还可以进行关系运算。</p><p>我已经在 <a href=\"https://time.geekbang.org/column/article/466203\">03 讲</a> 中介绍了关系运算符的机器指令实现方式。在大多数情况下，编译器会配合使用 <code>cmp</code> 与 <code>setg</code> 等指令来判断关系运算符两侧操作数的大小，并根据判断结果，进行相应的置位与复位操作，最终返回 0 或 1 作为结果。而对于指针之间的关系运算来说，其实现方式也是如此。</p><p>但需要注意一点：虽然在机器指令层面，指针的关系运算实际上是对指针内部所存放的地址值进行的大小判断，但从 C 语法的角度来看，具有实际意义的指针关系运算仅有为数不多的几种情况（你可以点击<a href=\"https://en.cppreference.com/w/c/language/operator_comparison\">这个链接</a>来详细了解）。除此之外，其他使用方式均会产生未定义行为（UB）。</p><h2>堆内存指针</h2><p>在我之前介绍的例子中，指针仅引用了位于栈内存中的数据。但实际上，指针还有另一个更重要的作用，那就是给予了我们<strong>灵活操控堆内存中数据</strong>的能力。</p><p>堆同栈类似，也是位于进程 VAS 中的一段专门用于存放数据的内存空间。栈中的数据随着函数的调用与返回，会被程序自动释放，而堆则有所不同。在堆中进行数据分配，需要借助特定的操作系统调用函数，并且被分配内存中的数据不会随着程序的运行而自动清除。因此，当这些数据不再被程序使用时，便需要显式地调用相应的系统函数，来将其释放。</p><p>幸运的是，C 标准库中已经为我们封装好了这样的一些函数。借助它们，我们可以方便地申请与释放堆内存，并享受堆分配算法带来的性能保障。这里我先带你回顾一下这些函数的使用方式，而它们的具体内容，我会在 15 讲 中再为你详细介绍。</p><p>通过下面这段示例代码，我们可以快速回顾一下标准库函数 <code>malloc</code> 与 <code>free</code> 的使用方式。对于其中的关键语句，你可以参考它们上方的注释。</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;string.h&gt;\n#define N 5\nint main(void) {\n&nbsp; int arr[] = { 1, 2, 3, 4, 5 };&nbsp;&nbsp;\n  // 分配用于存放 N 个整数的堆内存；\n&nbsp; int* p = (int*) malloc(sizeof(int) * N);\n&nbsp; // 将数组 arr 中的元素复制到分配的堆内存中；\n  memcpy(p, arr, sizeof(int) * N);  \n&nbsp; for (int i = 0; i &lt; N; ++i) {\n    // 通过指针遍历堆空间中的数据；\n&nbsp; &nbsp; printf(\"%d\\n\", *(p + i));\n&nbsp; }\n  // 释放先前分配的堆空间，让操作系统可以回收内存；\n&nbsp; free(p);  \n&nbsp; return 0;\n}\n</code></pre><p>在 VAS 中，堆内存的位置处于栈内存的“下方”，即低地址方向。与栈内存相反的是，堆内存的占用区域将随着程序的不断使用从低地址向高地址逐渐增长，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/b5/50/b5c30aac8babae5b3e354b8954991e50.jpg?wh=1920x1581\" alt=\"图片\"></p><p>看到这里，你可能会有这样的疑问：我平时写的 C 程序只需要临时变量就够用了，这些变量的值会被分配在栈内存中，那我们为什么还需要堆呢？</p><p>因为栈上的数据在函数返回时就会被释放，因此我们只能通过不断拷贝的方式保持其“存活”。而全局变量和静态变量的生存期虽然与整个程序保持一致，但也并没有办法在程序的运行过程中动态生成，且缺乏一定表现力。</p><p>而堆内存则可以很好地解决这些问题。存放在其内部的数据能够由程序动态地创建，而且可以保持与程序相同的最大生存期。不仅如此，和全局变量、静态变量这两种将值完全暴露给所有程序代码使用的方式相比，使用堆内存可以将数据的使用，限制在其所需要的最小范围内，这无疑加强了程序对内存资源的精细化管理程度。</p><h2>使用指针的注意事项</h2><p>借助指针，我们可以灵活地使用程序存放在堆内存与栈内存中的数据，但不当的指针使用方式也可能会导致程序出现难以调试、甚至是难以复现的 BUG。其中，你需要特别注意避免下面这些操作，因为它们会导致程序出现无法预测的未定义行为：</p><ul>\n<li>解引用未初始化的指针；</li>\n<li>函数返回指向其内部局部变量的指针；</li>\n<li>非指向同一数组内元素的两个指针之间的减法操作；</li>\n<li>……</li>\n</ul><p>除此之外，对堆指针进行有效的生命周期管理，也是我们在构建程序时需要注意的问题。由于同一个堆指针可能会在程序的不同函数中被使用，因此就要特别注意：我们应该通过 free 函数及时清理堆内存，以防止内存泄露；同时，又不应该去释放一块已经被释放过的堆内存（重复释放会产生异常）。</p><h2>总结</h2><p>好了，讲到这里，今天的内容也就基本结束了。最后我来给你总结一下。</p><p>这一讲，我主要介绍了 C 语言中有关指针的一些话题，包括指针在 C 语言中的基本使用方式、指针与数组的关系、指针的算数与关系运算，以及它们在机器指令层面的实现细节。同时，我还介绍了堆内存指针，并和你简单探讨了在使用 C 指针时需要注意的一些问题。</p><p>在 C 代码中，通过添加特定的 “ * ” 符号，我们可以声明所定义变量为一个指针类型。而与指针有关的两个常用操作符为取地址操作符 “&amp;” 与解引用操作符 “ * ”，它们一般可以通过 <code>lea</code> 指令与 <code>mov</code> 指令来实现。</p><p>指针与数组也有着密不可分的联系。在某些特定的使用方式下，编译器会将数组类型退化为指针类型，导致其丧失了有关数组的类型与大小等信息。</p><p>除此之外，指针类型还可以参与算数与关系运算。其中，算数运算主要涉及指针与整数的加/减运算、指针的自增/自减运算，以及两个同类型指针间的求差运算。而关系运算则同数值类型保持一致。但需要注意的是，标准中仅规定了上述运算类型对于指针的有限使用方式，而规定之外的使用方式则属于未定义行为。</p><p>同时，我还介绍了可以引用堆上数据的指针。堆是除栈之外的又一个重要的数据存放“容器”。相较于栈上数据，以及全局变量或静态变量中的数据，位于堆中的数据具有更加灵活的生存期，并且能够在程序运行过程中动态生成。</p><p>最后，我总结了在使用 C 指针时需要注意的问题。对指针的不当使用会使程序产生标准中未定义的行为。对于堆指针来说，除了未定义操作外，没有及时对相关资源进行清理，或重复清理，都会导致程序的运行产生异常。而这些都是我们在设计 C 程序结构时，需要特别注意的问题。毕竟，再强大的武器也是一把双刃剑。</p><h2>思考题</h2><p>下面这段代码可以正常编译吗？为什么？</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\nint main(void) {\n&nbsp; int arr[] = { 1, 2, 3, 4 };\n&nbsp; printf(\"%d\", arr[3] == 3[arr]);&nbsp;\n&nbsp; return 0;\n}\n</code></pre><p>今天的课程到这里就结束了，希望可以帮助到你，也希望你在下方的留言区和我一起讨论。同时，欢迎你把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"07｜整合数据：枚举、结构与联合是如何实现的？","id":471133},"right":{"article_title":"09｜编译准备：预处理器是怎样处理程序代码的？","id":472592}}},{"article_id":472592,"article_title":"09｜编译准备：预处理器是怎样处理程序代码的？","article_content":"<p>你好，我是于航。</p><p>C 预处理器是 C 标准中的另一块重要内容。对代码进行预处理，是 C 源代码在被“真正”编译，并生成机器代码前的重要一环。合理使用预处理指令，可以让源代码根据不同的环境信息进行动态变化，并生成适合在当前环境下编译的 C 代码。这里我们提到的“环境”，一般与目标操作系统、CPU 体系架构，以及当前平台上各系统库的支持情况有关。</p><p>除此之外，预处理器还为我们提供了一定的能力，可以更加高效、灵活地组织 C 源代码。比如，我们可以对一个完整的 C 程序进行结构化拆分，根据代码在语法结构或功能定位上的不同，将它们分别整理在独立的 C 源文件中。而在包含有程序入口 main 函数的源文件内，我们便可以通过 #include 预处理指令，在编译器开始真正处理 C 代码前，将程序运行所需要的其他代码依赖包含进来。</p><p>那么今天，我们就来看看有关 C 预处理器的内容。接下来，我将介绍 C 预处理器的相关背景知识、预处理的基本流程，以及宏编写技巧和使用注意事项。</p><h2>C 预处理器的相关背景知识</h2><p>预处理器被引入 C 标准的时间比 C 语言诞生晚了大约一年。1973 年左右，在贝尔实验室研究员 Alan Snyder 的敦促下，预处理器被正式整合至 C 语言中。它的最初版本只拥有基本的文件包含和字符串替换能力。而在此后不久，它被进一步扩展，加入了带参数的宏以及条件编译等功能。在随后发布的 ANSI C 标准中，预处理器的能力再次得到了加强。</p><!-- [[[read_end]]] --><p>另外你需要知道的是，C 预处理器并不仅仅可以用在 C 语言上，在 C++、Objective-C 等基于 C 的“后继语言”中，这套预处理器语法仍然适用。</p><p>除此之外，也许你也还并不清楚这一点：为什么使用预处理器语法 #define 定义出来的符号被称为宏（macro）？而那是因为在希腊语中，macro 通常会被作为一个单词前缀，用来表示体积或数量上的“大”和“多”。而在 C 代码中，当一个宏被展开和替换时，不是也有类似的效果吗？</p><p>到这里，有关 C 预处理器的一些背景知识我就介绍完了。下面，就让我们来看看编译器是如何对 C 代码进行预处理的。</p><h2>预处理是怎样进行的？</h2><p>对代码进行预处理是整个 C 程序编译流程中的第一环。在这一步中，编译器会对源代码进行分析，并通过查找以 “#” 字符开头的代码行，来确定预处理器指令的所在位置。接下来，通过下面这些步骤，编译器可以完成对代码的预处理工作：</p><ol>\n<li>删除源代码中的所有注释；</li>\n<li>处理所有宏定义（#define），并进行展开和替换；</li>\n<li>处理所有条件预编译指令（如 #if、#elif），仅保留符合条件的代码；</li>\n<li>处理文件包含预编译指令（#include），将被包含文件的内容插入到该指令的所在位置；</li>\n<li>处理其他可以识别的预处理指令（如 #pragma）；</li>\n<li>添加其他具有辅助性功能的注释信息。</li>\n</ol><p>为了进一步观察编译器在预处理阶段对 C 代码的处理过程，这里我们可以进行一个简单的实验：将下面这段代码保存在文件 “macro.c” 中，并通过命令 “gcc -O0 -Wall -E  ./macro.c -o macro.l” 对它进行编译。</p><pre><code class=\"language-c++\">#pragma GCC warning \"Just FYI!\"\n#include &lt;stdbool.h&gt;\n#define PI 3.14\n#define SQUARE(x) (x * x)\nint main(void) {\n#if defined PI\n&nbsp; // Some specific calculations.\n&nbsp; const double area = SQUARE(5) * PI;\n&nbsp; const bool isAreaGT100 = area &gt; 100.0;\n#endif\n&nbsp; return 0;\n}\n</code></pre><p>眼尖的你会发现，我们在编译命令中使用到了名为 “-E” 的参数。该参数的作用是让编译器仅对源代码执行预处理阶段的一系列操作，之后就停止运行。当编译完成后，你可以在编译目录内找到名为 “macro.l” 的文件。而在这个文件中，便包含有源代码在经过预处理阶段后得到的中间代码结果。其中的内容如下所示（注意，不同的编译器和版本生成的文件内容可能有所不同）：</p><pre><code class=\"language-c++\"># 1 \"macro.c\"\n# 1 \"&lt;built-in&gt;\"\n# 1 \"&lt;command-line&gt;\"\n# 31 \"&lt;command-line&gt;\"\n# 1 \"/usr/include/stdc-predef.h\" 1 3 4\n# 32 \"&lt;command-line&gt;\" 2\n# 1 \"macro.c\"\n\n# 1 \"/usr/lib/gcc/x86_64-redhat-linux/8/include/stdbool.h\" 1 3 4\n# 3 \"macro.c\" 2\n\n\n\nint main(void) {\n\n&nbsp; const double area = (5 * 5) * 3.14;\n&nbsp; const\n# 8 \"macro.c\" 3 4\n&nbsp; &nbsp; &nbsp; &nbsp;_Bool\n# 8 \"macro.c\"\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; isAreaGT100 = area &gt; 100.0;\n&nbsp; return 0;\n}\n</code></pre><p>可以看到，在这段文本中，所有之前在 C 源代码中以 “#” 开头的预处理指令都已经被移除；宏常量 PI 和宏函数 SQUARE 已经完成了展开和替换；头文件 “stdbool.h” 中的内容也已经被插入到了源文件中（该文件内为宏 bool 的定义，这里已被替换为了 _Bool）。除此之外，一些带有辅助功能的信息也以 linemarker 的形式插入到了该文件中，供后续编译阶段使用。</p><p>因为这些信息的组成形式和作用跟编译器的具体实现密切相关，这里我就不深入解读了。如果你对 GCC 如何使用 linemarker 感兴趣，可以点击<a href=\"https://gcc.gnu.org/onlinedocs/gcc-9.1.0/cpp/Preprocessor-Output.html#Preprocessor-Output\">这个链接</a>获得更多信息。</p><h2>定义宏函数时的常用技巧</h2><p>预处理器在进行宏展开和宏替换时，只会对源代码进行简单的文本替换。在某些情况下，这可能会导致<strong>宏函数所表达的计算逻辑与替换后 C 代码的实际计算逻辑产生很大差异</strong>。因此，在编写宏函数时，我们要特别注意函数展开后的逻辑是否正确，避免由 C 运算符优先级等因素导致的一系列问题。</p><p>接下来，就让我们一起看下：当在 C 代码中使用预处理器时，有哪些 tips 可以帮助我们避免这些问题。</p><h3>技巧一：为宏函数的返回值添加括号</h3><p>对于大多数刚刚接触 C 预处理器的同学来说，我们可能会在不经意间，写出类似下面这样的代码：</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\n#define FOO(x) 1 + x * x\nint main(void) {\n&nbsp; printf(\"%d\", 3 * FOO(2));\n&nbsp; return 0;\n}\n</code></pre><p>这里，我们定义了一个名为 FOO 的宏函数，该函数接收一个参数 x，并返回这个参数在经过表达式 <code>1 + x * x</code> 计算后的结果值。在 main 函数中，我们以数值 2 作为参数，调用了该宏函数，并通过 <code>printf</code> 函数打印了数字 3 与宏函数调用结果值的乘积。</p><p>按照我们对函数的理解，这里的宏函数在被“调用”后，会首先返回表达式的计算结果值 5（1 + 2 * 2）。随后，该结果值会再次参与到函数外部的乘积运算中，并得到最终的打印结果值 15。但事实真是如此吗？</p><p>实际上，宏函数的展开与 C 函数的调用过程并不相同。经过编译器的预处理后，上述代码中对第四行 <code>printf</code> 语句的调用过程会被变更为如下形式：</p><pre><code class=\"language-c++\">printf(\"%d\", 3 * 1 + 2 * 2);\n</code></pre><p>可以看到，这里的宏函数 FOO 在被展开时，并不会优先对其内部的表达式进行求值，相反，只是简单地对传入的参数进行了替换。因此，当编译器按照展开后的结果进行计算时，由于表达式中乘法运算符 “*” 的优先级较高，进而导致整个表达式的计算顺序发生了改变，所以，计算结果也就出现了偏差。那如果我们为宏函数的整个返回表达式都加上括号，结果会怎样呢？显而易见，此时表达式 <code>(1 + 2 * 2)</code> 会被优先求值。 <code>3 * FOO(2)</code> 的计算结果符合我们的预期。</p><h3>技巧二：为宏函数的参数添加括号</h3><p>用上面的技巧，我们已经对宏函数 FOO 进行了优化，以保证在某些情况下，“返回的”表达式能够被当作一个整体进行使用。但这样就万无一失了吗？其实，类似的问题还可能会出现在宏函数的参数上，比如下面这个例子：</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\n#define FOO(x) (1 + x * x)\nint main(void) {\n&nbsp; printf(\"%d\", FOO(1 + 2));\n&nbsp; return 0;\n}\n</code></pre><p>在这里，我们改变了宏函数 FOO 的使用方式，直接将表达式 <code>1 + 2</code> 作为参数传递给了它。同样地，由于编译器在处理宏函数时，仅会进行实参在各自位置上的文本替换，传入函数的表达式并不会在函数展开前进行求值。因此，经过编译器的预处理后，上述代码中第四行对 <code>printf</code> 语句的调用过程会被变更为如下形式：</p><pre><code class=\"language-c++\">printf(\"%d\", (1 + 1 + 2 * 1 + 2));\n</code></pre><p>由于乘法运算符 “*” 的存在，此时整个表达式的求值顺序发生了改变。本该被优先求值的子表达式 <code>1 + 2</code> 并没有被提前计算。很明显，这并不是我们在设计 FOO 函数时所期望的。而通过为宏函数定义中的每个参数都加上括号，我们便可以解决这个问题。</p><h3>技巧三：警惕宏函数导致的多次副作用</h3><p>那么，现在的宏函数 FOO 还会有问题吗？让我们继续来看这个例子：</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\n#define FOO(x) (1 + (x) * (x))\nint main(void) {\n  int i = 1;\n&nbsp; printf(\"%d\", FOO(++i));\n&nbsp; return 0;\n}\n</code></pre><p>在上面这段代码中，我们“装配”了经过两次优化升级的宏函数 FOO。只是相较于前两种使用方式，这里我们在调用该函数时，传入了基于自增运算符的表达式 <code>++i</code> 。按照常规的函数调用方式，变量 <code>i</code> 的值会首先进行自增，由 1 变为 2。然后，该结果值会作为传入参数，参与到宏函数中表达式  <code>1 + (x) * (x)</code> 的计算过程，由此可以得到计算结果 5。</p><p>但现实往往出人意料：同之前的例子类似，传入宏函数的表达式实际上并不会在函数被“调用”时提前求值。因此，上述 C 代码中的第五行语句在宏函数实际展开时，会变成如下形式：</p><pre><code class=\"language-c++\">printf(\"%d\", (1 + (++i) * (++i)));\n</code></pre><p>到这里，我想你已经知道了问题所在：经过宏替换的 C 代码导致多个自增运算符被同时应用在了表达式中，而该运算符对变量 <code>i</code> 的副作用产生了多次。</p><p>因此，在使用宏函数时需要注意，宏函数的“调用”与 C 函数的调用是完全不同的两种方式。前者不会产生任何栈帧，而只是对源代码文本进行简单的字符替换。所以，对于替换后产生的新代码，其计算逻辑可能已经发生了变化，而这可能会引起程序计算结果错误，或副作用产生多次等问题。</p><h3>技巧四：定义完备的多语句宏函数</h3><p>到这里，对于定义简单宏函数时可能遇到的一系列问题，相信你都能处理了。但当宏函数逐渐变得复杂，函数体内不再只有一条语句时，新的问题又出现了。</p><p>通常情况下，为了与 C 代码的风格保持一致，在调用宏函数时，我们也会习惯性地为每一个调用语句的末尾加上分号。但也正是因为这样，当含有多行语句的宏函数与某些控制语句一起配合使用时，可能会出现意想不到的结果。比如下面这个例子：</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\n#define SAY() printf(\"Hello, \"); printf(\"world!\")\nint main(void) {\n&nbsp; int input;\n&nbsp; scanf(\"%d\", &amp;input);&nbsp;&nbsp;\n&nbsp; if (input &gt; 0)\n&nbsp; &nbsp; SAY();\n&nbsp; return 0;\n}\n</code></pre><p>当我们习惯使用 C 代码的执行思维来看待宏函数时，上述代码的执行情况应该是这样的：程序接收用户输入的字符，并将其转换为数字值。若该值大于 0，则宏函数内的两条 <code>printf</code> 语句被执行，并输出字符串 “Hello, world!”。否则，程序直接退出。但现实的情况却是，无论用户输入何值，字符串 “world!” 都会被打印。</p><p>而问题就出现在<strong>宏函数 SAY 被展开和替换后</strong>，原本“封装”在一起的两条 <code>printf</code> 语句被拆分开来。其中的第一条语句成为了 if 条件控制语句的执行内容；而第二条语句由于没有大括号的包裹，则直接被“释放”到了 main 函数中，成为了该函数返回前最后一条会被执行的语句。</p><p>那么，应该怎样解决这个问题呢？</p><p>既然我们的目的是让编译器在处理程序代码时，能够将宏函数内的所有语句当作一个整体进行处理，那么有没有一种合法的 C 语言结构，它可以作为一种复合语句使用，其内部的语句只会被执行一次，并且在语法上，它还需要以分号结尾？</p><p>很巧，迭代语句 do…while 便可以满足这个要求。如下面这段代码所示，我们使用该语句，改写了宏函数 SAY 的实现方式。</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\n#define SAY() \\\n&nbsp; do { printf(\"Hello, \"); printf(\"world!\"); } while(0)\nint main(void) {\n&nbsp; int input;\n&nbsp; scanf(\"%d\", &amp;input);&nbsp;&nbsp;\n&nbsp; if (input &gt; 0)\n&nbsp; &nbsp; SAY();\n&nbsp; return 0;\n}\n</code></pre><p>可以看到，通过将 while 关键字中的参数设置为 0，我们可以保证整个迭代语句仅会被执行一次。而 do…while 语句“天生”需要以分号结尾的性质，也正好满足了宏函数替换后的 C 语法格式要求。并且，对于 while(0) 这种特殊的迭代形式，大多数编译器也会通过相应的优化，去掉不必要的循环控制结构，以降低对程序运行时性能的影响。</p><h2>何时使用预处理器？</h2><p>讲了这么多预处理器的使用技巧，最后还是要提醒你：预处理器是一把“双刃剑”。对它的合理使用，可以让我们的程序具备更强的动态扩展能力；相反，如果任意乱用，就会导致程序源代码的可读性大大降低，甚至引入难以调试的 BUG。</p><p>通常，在以下三个场景中，你可以视情况选择是否使用预处理器：</p><ul>\n<li>定义程序中使用到的魔数。这里提到的魔数，主要是指那些用于控制程序运行状态、具有特定功能意义的参数。这些参数可以使用预处理器以宏的形式定义，并在程序编译前内联到源代码中使用；</li>\n<li>基于特定运行环境的条件编译。我们可以通过特定的宏（比如编译器预定义宏、C 语言内置宏等）来检测当前编译环境的状态，并以此调整程序需要启用的特定功能；</li>\n<li>封装代码模板。我们可以通过宏的形式，封装需要重复出现的代码片段，并将它们应用在循环展开等场景中。</li>\n</ul><p>当然，真实的使用场景并不局限于这三类。但还是要强调下：在使用预处理器时，保持谨慎小心是必要的。</p><h2>总结</h2><p>好了，讲到这里，今天的内容也就基本结束了。最后我来给你总结一下。</p><p>今天我主要介绍了与 C 预处理器有关的一些内容，包括相关背景知识、编译器处理方式，以及使用技巧等。</p><p>通过 C 预处理器，我们可以让编译器在真正开始处理 C 语法代码前，先对源码进行一系列必要的转换。这些转换可以让我们引入代码正常编译所需要的各类依赖项，动态修改代码以适应不同的编译环境，甚至根据需要自动生成部分 C 代码。对预处理器的合理使用，可以让我们的程序具备一定的“弹性伸缩”能力，并使程序的可配置性大大增强。</p><p>另一方面，宏函数的运作方式又与 C 函数有着巨大的区别。其中，前者在“调用”时仅会做源代码文本上的匹配与替换。因此，在处理宏函数参数以及宏函数体内的多行语句时，需要通过添加括号、使用 do…while 语句等技巧，来对参数、返回值与函数体进行“封装”。</p><p>最后，需要注意预处理器的合适使用场景。在 C 语言中，预处理器通常可以被应用在程序魔数定义、代码条件编译，以及代码模版封装等场景中。只有谨慎、合理地使用，我们才能够享受到 C 预处理器带来的巨大价值。</p><h2>思考题</h2><p>你知道 C 预处理运算符 “#” 与 “##” 的用法吗？欢迎在评论区跟我讨论。</p><p>今天的课程到这里就结束了，希望可以帮助到你，也希望你在下方的留言区和我一起讨论。同时，欢迎你把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"08｜操控资源：指针是如何灵活使用内存的？","id":471937},"right":{"article_title":"10｜标准库：字符、字符串处理与数学计算","id":473400}}},{"article_id":473400,"article_title":"10｜标准库：字符、字符串处理与数学计算","article_content":"<p>你好，我是于航。从这一讲开始，我们将进入到 C 工程实战篇的学习。</p><p>在上一个模块中，我主要围绕着 C 语言的七大关键语法，介绍了它们在机器指令层面的实现细节。而接下来，走出语法，从微观到宏观，我们将开始进一步探索 C 语法之外，那些可以用来支撑大型 C 项目构建的特性和技术。</p><p>因此，在这一模块中，我会介绍和 C 语言标准库、工程化，以及性能优化等相关的内容。C 标准库是除 C 基本核心语法外，C 语言的另一个重要组成部分。C 标准库中提供了众多的类型、函数和宏，可供我们直接在程序中使用。这些“构建单元”的功能涵盖了多个方面，从简单的文本字符处理，到复杂的线程操作、内存管理等。在继续后面的内容之前，你可以先粗略浏览下图，以对 C 标准库提供的基本功能有个大致的印象。</p><p><img src=\"https://static001.geekbang.org/resource/image/6d/54/6dda718fc700a7c8f503e59daf442554.jpg?wh=1920x1732\" alt=\"图片\"></p><p>今天，我们就先来看看 C 标准库中与字符、字符串处理，以及数学运算相关的内容。</p><h2>C 语言中的字符和字符串</h2><p>在 C 语言中，字符用单引号表示，字符串用双引号表示。比如在下面这段代码中便定义有两个变量，它们分别存放了一个字符类型和一个字符串类型的值。</p><pre><code class=\"language-c++\">char c = 'a';\nconst char* str = \"Hello, geek!\";\n</code></pre><p>下面，我们就来分别看看与这两种类型有关的重要特性。</p><h3>字符</h3><p>在 C 语言标准中，不同于其他整数类型（比如 <code>int</code>），字符类型 <code>char</code> 并没有被规定默认的符号性，而其具体符号性则是由编译器和所在平台决定的。虽然在大多数情况下，编译器会选择将默认情况下的 <code>char</code> 类型视为有符号整数类型，但考虑到程序的可用性与可移植性，在实际编码中还是建议<strong>显式指定出所定义字符变量的符号性</strong>。</p><!-- [[[read_end]]] --><p>C 标准中之所以这样规定，主要源于其历史原因。比较有代表性的一种说法是：C 语言在设计之初参考了它的“前辈” B 语言。B 语言于 1969 年由 Ken Thompson 在贝尔实验室开发。作为一种无类型语言，它的字符类型仅用于存放字符，而不作数学运算之用。因此，并不需要特别区分符号性。所以在 C 语言中，作者也没有为字符类型规定默认的符号性。</p><p>另外，有关字符类型的另一个重要特征是，C 语言保证 <code>char</code> 类型只占用一个字节大小，因此在使用 <code>sizeof</code> 运算符计算该类型大小时，将永远得到结果 1。但事实上，并不是所有计算机体系都使用 8 位的字节大小。对于某些较为古老的计算机体系，一个字节可能对应大于或小于 8 位。</p><p>对于某些特殊的业务需求和功能场景，你可以通过访问标准库中定义的常量 CHAR_BIT ，来检查当前体系下一个字符类型所占用的位数，该常量的使用方式如下所示：</p><pre><code class=\"language-c++\">#include &lt;limits.h&gt;\n#include &lt;stdio.h&gt;\nint main(void) {\n&nbsp; printf(\"char type has %lu byte.\\n\", sizeof(char));&nbsp; // ...1.\n&nbsp; printf(\"char type has %d bits.\", CHAR_BIT);&nbsp; // ...8.\n}\n</code></pre><p>不过需要注意的是，自 C89 以来的标准中规定，CHAR_BIT 的值不能小于 8，因此对于单个字节数小于 8 位的体系架构，该常量并不能反映真实情况。</p><p>最后介绍一个编码方面的特性。C 语言中的 <code>char</code> 字符类型变量在按照字符类型打印时（比如使用 printf 函数，配合 “%c” 占位符），会使用 ASCII 编码来对数字值进行字符映射。这意味着，一个存储有整数 65 的字符类型变量，在将其打印输出时，会在命令行中直接得到字符 “A”。当然，你也需要确保命令行客户端的编码设置为 UTF-8，以与 ASCII 编码相兼容。</p><p>除了 <code>char</code> 类型以外，C 语言还在 C90 和 C11 标准中新增了可用于宽字符的类型，诸如 <code>wchar_t</code>、<code>char16_t</code>、<code>char32_t</code> 等。其中，<code>wchar_t</code> 类型的大小由具体的编译器实现决定。而 <code>char16_t</code> 和 <code>char32_t</code> 类型，其值则固定占用对应的 16 和 32 位。</p><h3>字符串</h3><p>在 C 语言中，我们可以通过下面这两种方式来定义字符串类型的变量，一种是指针形式，另一种是数组形式。当然，这里示例代码中我们定义的是只读字符串：</p><pre><code class=\"language-c++\">// read-only string.\nconst char strA[] = \"Hello, geek!\";&nbsp; \nconst char* strB = \"Hello\" \", geek!\";\n</code></pre><p>其中，由双引号括起来的部分一般称为“字符串字面量”。C 标准中规定，连续出现的字符串字面量之间如果仅由空格分隔，则会将它们视为一个整体。所以 <code>strA</code> 与 <code>strB</code> 这两个字符串的内容是完全一样的。本质上，这两种方式都展示出了字符串在 C 语言中的具体表现形式，即“带有终止符的字符数组”。</p><p>关于上述字符串在内存中的布局形式，我们可以用下面这张图来直观地理解一下。可以看到的是，字符串数据被存放在连续的内存段上，且每个字符串数据的最后都以空字符（<strong>\\0</strong>）作为表示结束的终止符。所以我们说，字符串并不是单纯的字符数组，而是带有隐式（定义时会被自动加上）终止符的字符数组。</p><p><img src=\"https://static001.geekbang.org/resource/image/39/3d/3944500a60ac5cdc067816b65f7c3e3d.jpg?wh=1920x638\" alt=\"图片\"></p><p>虽然通过上面这两种方式都可以定义字符串，但实际上，<strong>不同的定义方式在不同情况下可能会对程序运行产生不同的影响。</strong>这里你可以先思考下：假设我们有如下这段代码，它在运行时会有什么问题吗？如果有，那应该怎样改正？</p><pre><code class=\"language-c++\">#include &lt;string.h&gt;\n#include &lt;stdio.h&gt;\nint main (void) {&nbsp; &nbsp;\n&nbsp; /* get the first token */\n&nbsp; const char* token = strtok(\"Hello, geek!\", \"geek\");\n&nbsp; printf(\"%s\", token);\n&nbsp; return 0;\n}\n</code></pre><p>上面这段代码在不同平台上运行可能会得到不同的结果。比如在 Linux 上，你可能会得到名为 “Segmentation fault” 的系统错误。如果进一步用 LLDB 进行调试，你会发现错误原因是：“signal SIGSEGV: address access protected”，翻译过来就是访问了受保护的地址。那接下来我们一起看看为什么会这样。</p><p>我们在之前的内容中曾提到过，字符串常量一般会被存放在进程 VAS 的 .rodata Section（下文简称 .rodata）中，位于此处的数据一般可以在程序中被多次引用。而当数据需要被修改，或以较短生命周期的形式（如局部变量）存在时，其引用的相关数据可能需要从 .rodata 中被复制到其他位置。而上述这两种字符串定义方式便对应于这两种情况。</p><p>以本小节开头的代码为例，使用指针形式定义的字符串 strB ，实际上直接引用了 .rodata 中该字符串的所在位置，即字符指针 strB 的值为该位置对应的内存地址。而使用数组形式定义的字符串 strA ，则是将该字符串的数据从 .rodata 中复制到了其他地方，strA 的值为复制后该字符串第一个字符的所在地址。</p><p>我们可以通过下面这段代码来验证这个结论。</p><pre><code class=\"language-c++\">// string.c\n#include &lt;stdio.h&gt;\nint main(void) {\n&nbsp; const char strA[] = \"Hello, geek!\";\n&nbsp; const char* strB = \"Hello, geek!\";\n&nbsp; printf(\"%p\\n%p\", strA, strB);  \n  /**\n    Output:\n    0x7ffee84d3d0b\n    0x4006c8\n  */\n}\n</code></pre><p>上面的代码中，我们使用 “%p” 格式符来打印变量 strA 与 strB 这两个指针的值。可以看到，当在 Linux 下执行这段代码时，变量 strA 与 strB 分别对应两个完全不同长度的地址（参考代码后的注释）。此时，我们可以通过如下命令来查看当前进程的 VAS 分布情况。</p><pre><code class=\"language-shell\">pgrep string | xargs -I {} cat /proc/{}/maps\n</code></pre><p>命令执行后，会得到如下图所示结果：</p><p><img src=\"https://static001.geekbang.org/resource/image/ea/c3/eae6c0f6290b309fecbd90cdcc46a8c3.png?wh=1560x688\" alt=\"图片\"></p><p>可以看到，以字符数组形式定义的字符串，其对应变量 strA 的数据实际上会从 .rodata 中被复制到当前进程 VAS 的栈内存中。而当程序运行脱离 strA 所在的作用域时，该数组对应的值将会被释放。反观以指针形式定义的字符串 strB，通过执行以下命令，我们也可以证实其指针所指向的位置为 .rodata。</p><pre><code class=\"language-shell\">objdump -s string | grep .rodata -A 10\n</code></pre><p>该命令会直接打印出当前程序 .rodata 的相关情况。可以看到，最右侧解码后的 ASCII 字符串 “Hello, geek!” 正对应着值为 0x4006c8 的起始地址。</p><p><img src=\"https://static001.geekbang.org/resource/image/cc/05/cc8f619b54f1a4e38595342dd1908e05.png?wh=1136x194\" alt=\"图片\"></p><p>最后我们总结一下。使用数组和指针形式定义的字符串，其底层的数据引用方式会有所区别。其中数组方式会将字符串数据从 .rodata 中拷贝到其他位置（比如栈内存），因此修改这些数据不会改变存在于原始 .rodata 中的副本。而使用常量指针形式定义的数组，该指针会直接引用位于 .rodata 中的字符串数据。</p><p>因此，我们需要注意的一个问题是：当使用非 const 指针引用字符串时，通过该指针修改字符串的值，可能会影响到其他使用指针形式引用相同字符串的代码位置上的实际字符串值。当然在 C 标准中，这种修改方式本身是一种未定义行为，其产生的具体影响将由编译器和操作系统决定。但大多数情况下，该行为都会产生诸如 “Segmentation fault” 以及 “Bus error” 之类的系统错误。</p><h2>C 标准库中的字符、字符串处理</h2><p>C 标准库中提供了众多的函数，可供我们直接对字符和字符串数据进行处理，这里我选择性地介绍其中的一些常见用例。对于这些 C 标准库函数的更详细的使用方法，你可以在<a href=\"https://www.cplusplus.com/reference/\">这里</a>查阅相关文档。</p><h3>统计字符串长度</h3><pre><code class=\"language-c++\">#include &lt;string.h&gt;\n#include &lt;stdio.h&gt;\nint main(void) {\n&nbsp; const char str[10] = \"Hi\";\n&nbsp; printf(\"%zu\\n\", strlen(str));&nbsp; // 2.\n}\n</code></pre><p>这里我们直接使用标准库提供的 <code>strlen</code> 函数，<strong>该函数不会计入字符串中多余的终止符</strong>。</p><h3>拼接字符串</h3><pre><code class=\"language-c++\">#include &lt;string.h&gt;\n#include &lt;stdio.h&gt;\n#define STRLEN 14\nint main(void) {\n&nbsp; char strA[STRLEN] = \"Hello,\";\n&nbsp; char strB[] = \" world!\";\n&nbsp; strncat(strA, strB, STRLEN - strlen(strA) - 1);\n&nbsp; printf(\"%s\\n\", strA);&nbsp;\n}\n</code></pre><p>在这个例子中，我们选择使用 <code>strncat</code> 函数来进行字符串拼接。该函数相较于 <code>strcat</code> 函数，可以更好地控制被拼接字符串的长度，以防被拼接字符串过长导致的拼接字符串数组溢出。这里需要注意，在计算 <code>strncat</code> 函数的第三个参数，也就是被拼接字符串长度这个参数时，需要为字符串最后的终止符预留出 1 个字节的空间。</p><h3>拷贝字符串</h3><pre><code class=\"language-c++\">#include &lt;string.h&gt;\n#include &lt;stdio.h&gt;\nint main(void) {\n&nbsp; char strA[] = \"aaaaaa\";\n&nbsp; char strB[] = \"bbbbbbb\";\n&nbsp; printf(\"%s\\n\", strncpy(strA, strB, strlen(strA)));&nbsp; // \"bbbbbb\".\n}\n</code></pre><p>拷贝字符串函数 <code>strncpy</code> 的用法与 <code>strncat</code> 基本相同，我们可以控制其第三个参数，来决定将多少字符拷贝到目的字符串的数组中。这里我给你留下一个小问题：如果把 <code>strncpy</code> 函数中第三个参数使用的 <code>strlen</code> 函数更换成 <code>sizeof</code>，那么程序运行会得到什么结果？为什么？你可以在评论区和我交流讨论。</p><h3>格式化字符串</h3><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\n#define LEN 128\nint main(void) {\n&nbsp; char dest[LEN];\n&nbsp; const char strA[] = \"Hello, \";\n&nbsp; sprintf(dest, \"%sworld!\", strA);\n&nbsp; printf(\"%s\\n\", dest);\n}\n</code></pre><p>函数 <code>sprintf</code> 可用于格式化字符串，其第二个参数的形式与 <code>printf</code> 函数的第一个参数一致，只是后者会将内容输出到命令行中，而 <code>sprintf</code> 会将格式化后的字符串保存到通过其第一个参数传入的数组中。</p><h3>字符的判断与转换</h3><p>在 C 标准库头文件 ctype.h 中包含有众多可用于字符判断和转换的函数，这些函数自身的名称直接说明了它们的具体功能，使用方式十分简单。具体你可以参考下面这个实例。</p><pre><code class=\"language-c++\">#include &lt;ctype.h&gt;\n#include &lt;stdio.h&gt;\nint main(void) {\n&nbsp; char c = 'a';\n&nbsp; printf(\"%d\\n\", isalnum(c));&nbsp; // 1.\n&nbsp; printf(\"%d\\n\", isalpha(c));&nbsp; // 1.\n&nbsp; printf(\"%d\\n\", isblank(c));&nbsp; // 0.\n&nbsp; printf(\"%d\\n\", isdigit(c));&nbsp; // 0.\n&nbsp; printf(\"%c\\n\", toupper(c));&nbsp; // 'A'.\n}\n</code></pre><h2>C 标准库中的数学运算</h2><p>上面我介绍了 C 标准库中与字符和字符串处理相关函数的使用方式，除此之外，C 标准库中还提供了与数学运算有关的工具函数，基本上你都可以通过引入 math.h 和 stdlib.h 这两个头文件来使用。这些函数的使用方式都十分简单，你可以在<a href=\"https://en.cppreference.com/w/c/numeric/math\">这里</a>找到对它们用法的详细说明。不过有一点要注意：在编译时，你可能需要为链接器指定 “-lm” 参数以链接所需的数学库。</p><p>在下面这个简单的例子中，我们使用了标准库中的求绝对值函数。</p><pre><code class=\"language-c++\">#include &lt;math.h&gt;\n#include &lt;stdio.h&gt;\nint main(void) {\n  long double num = -10.1;\n  printf(\"%.1Lf\\n\", fabsl(num));\n}\n</code></pre><p>为了减少编码的工作量，我们也可以使用这些函数对应的泛型版本，这样就不需要根据传入的参数来手动选择合适的版本（比如这里的 <code>fabsl</code> 函数，它的后缀 “l” 表示 “long”）。比如，对于所有浮点类型的数字值，我们可以直接使用名为 <code>fabs</code> 的宏函数。该宏在展开时，会自动为你匹配对应的类型精确版本。不过，为了使用这些泛型宏，我们需要将原来的头文件 math.h 替换为 tgmath.h，如下代码所示：</p><pre><code class=\"language-c++\">#include &lt;tgmath.h&gt;\n#include &lt;stdio.h&gt;\nint main(void) {\n&nbsp; long double num = -10.1;\n&nbsp; printf(\"%.1Lf\\n\", fabs(num));\n}\n</code></pre><p>关于这些标准库函数的实现方式，如果我们进一步来看，会发现并非所有函数都是按照相应的数学算法来实现计算过程的。</p><p>这里用一个常见的数学运算“求平方根”举例子：通常来说，我们可以使用牛顿迭代法，以软件算法的形式计算一个数的平方根值。但实际上，当我们以 musl 这个 C 标准库为例，进一步查看其某版本的实现时，可以看到它在 i386 架构下直接使用了 FPU（浮点运算单元）提供的机器指令 <code>fsqrt</code> 来计算平方根的值，而并没有使用软件算法。在某种程度上，这可以极大提升计算性能。如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/c9/7d/c9ba68891c4ae6a3818ab8afcba72f7d.png?wh=1290x456\" alt=\"图片\"></p><p>因此，为了最大程度地利用硬件带来的计算性能优势，在准备自行编写相应算法时，可以先看看能否直接利用标准库提供的函数来完成你的工作。</p><h2>总结</h2><p>好了，讲到这里，今天的内容也就基本结束了。最后我来给你总结一下。</p><p>今天我主要介绍了 C 语言标准库中与字符、字符串处理，以及数学运算有关的内容。</p><p>首先，我介绍了 C 语言中字符和字符串类型变量的定义方式。字符以单引号形式定义，而字符串以双引号形式定义。字符串的不同定义方式还可能对程序的运行细节带来影响。其中，以字符数组形式定义的字符串包含有原始字符串在 .rodata 中的拷贝；而以指针形式定义的字符串变量则直接引用了 .rodata 中的字符串数据，且其值通常无法在程序运行时被动态修改。</p><p>接下来，我快速介绍了 C 标准库中与字符、字符串处理相关的一些函数的使用方式。最后，我介绍了 C 标准库中与数学运算相关的函数，math.h 头文件中包含有这些函数的精确类型版本，而 tgmath.h 头文件中则提供了对应的泛型宏函数版本。这些函数的一个重要特征是：某些常用的数学运算会被直接映射到对应的机器指令，和使用纯软件算法的实现相比，这通常可以获得更高的性能。</p><h2>思考题</h2><p>请了解一下 C 标准库中 <code>strtok</code> 函数的实现，并思考是哪一步引起了文中实例的 “Segmentation fault” 错误。然后，如果时间充足，可以尝试实现一个自己的版本，拥有与 <code>strtok</code> 函数一样的功能，但是不修改传入的源字符串。</p><p>今天的课程到这里就结束了，希望可以帮助到你，也希望你在下方的留言区和我一起讨论。同时，欢迎你把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"09｜编译准备：预处理器是怎样处理程序代码的？","id":472592},"right":{"article_title":"11｜标准库：深入理解标准 IO","id":475253}}},{"article_id":475253,"article_title":"11｜标准库：深入理解标准 IO","article_content":"<p>你好，我是于航。</p><p>输入输出（后面简称 “IO”）是应用程序不可或缺的一种基本能力。为了保持设计上的精简，C 语言并没有在核心语言层面提供对 IO 相关接口的支持，相反，采用了标准库的方式来实现。通过引用名为 stdio.h 的标准库头文件，我们便可以快捷地为 C 程序添加读取用户键盘输入、输出内容到控制台，乃至读写文件等一系列常规的 IO 功能。</p><p>这一讲，我将为你深入介绍 C 语言中的标准 IO 模型，以及它背后的一些原理。</p><h2>快速回顾 IO 接口的使用方法</h2><p>首先，让我们通过下面这段代码来快速回顾，应该如何在 C 语言中使用这些由标准库提供的 IO 接口。对于这些接口用法的更具体说明，你可以参考<a href=\"https://en.cppreference.com/w/c/io\">这个链接</a>。</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\nint main(void) {\n&nbsp; printf(\"Enter some characters:\\n\");\n&nbsp; FILE* fp = fopen(\"./temp.txt\", \"w+\");\n&nbsp; if (fp) {\n&nbsp; &nbsp; char ch;\n&nbsp; &nbsp; while (scanf(\"%c\", &amp;ch)) {\n      if (ch == 'z') break;\n&nbsp; &nbsp; &nbsp; putc(ch, fp);\n&nbsp; &nbsp; }\n&nbsp; } else {\n&nbsp; &nbsp; perror(\"File open failed.\");\n&nbsp; }\n&nbsp; fclose(fp);\n&nbsp; return 0;\n}\n</code></pre><p>这里，在 main 函数内部，我们通过多种不同的方式，让程序与进程预设的 IO 流以及我们自行打开的 IO 流产生了交互。</p><!-- [[[read_end]]] --><p>其中，代码第 3 行，通过 printf 函数，我们可以将指定的文本传送至标准输出流（stdout）中。紧接着，借助代码第 4 行的 fopen 函数，我们得以在当前目录下打开名为 “temp.txt” 的文件，并将其与一个特定的文件 IO 流相关联。而当文件打开失败时，通过代码第 12 行的 perror 函数，我们能够将特定的错误信息传送到标准错误流（stderr）。最后，在代码的第 7 行，scanf 函数的调用可以让我们从标准输入（stdin）流中，读取从外部环境输入的信息。</p><h2>IO 接口的不同级别</h2><p>通常来说，IO 接口可以被分为不同层次。其中，C 语言提供的 IO 接口属于“标准 IO”的范畴。与其相对的，是名为“低级 IO”的另一套编程模型。顾名思义，<strong>低级 IO 会使用与具体操作系统相关的一系列底层接口来提供相应的 IO 能力</strong>，比如常用于 Unix 与类 Unix 操作系统上的 POSIX 接口标准。如果我们将上面的示例程序完全用该标准进行重写，将会得到如下所示的代码：</p><pre><code class=\"language-c++\">#include &lt;unistd.h&gt;\n#include &lt;fcntl.h&gt;\nint main(void) {\n&nbsp; const char str[] = \"Enter some characters:\\n\";\n&nbsp; write(STDOUT_FILENO, str, sizeof(str));\n&nbsp; const int fd = open(\"./temp.txt\", O_RDWR | O_CREAT);\n&nbsp; if (fd &gt; 0) {\n&nbsp; &nbsp; char ch;\n&nbsp; &nbsp; while (read(STDIN_FILENO, &amp;ch, 1)) {\n      if (ch == 'z') break;\n&nbsp; &nbsp; &nbsp; write(fd, &amp;ch, sizeof(ch));&nbsp; &nbsp; \n&nbsp; &nbsp; }\n&nbsp; } else {\n&nbsp; &nbsp; const char errMsg[] = \"File open failed.\";\n&nbsp; &nbsp; write(STDERR_FILENO, errMsg, sizeof(errMsg));\n&nbsp; }\n&nbsp; close(fd);\n&nbsp; return 0;\n}\n</code></pre><p>可以看到，在使用低级 IO 接口进行编程时，我们需要处理与所进行 IO 操作有关的更多细节。比如，在调用 write 接口时，你必须要指定不同的文件描述符（File Descriptor），才能够区分所要进行的操作是“向屏幕上输出字符”，还是“向文件内写入数据”。相反，在高级 IO 的实现中，我们并不需要关注这些细节，接口的名称可以直接反映其具体用途。</p><p>两者之所以会在接口使用粒度上存在差异，是由于“低级 IO 与操作系统实现紧密相关”。对于 POSIX 标准来说，其所在系统会将绝大多数的 IO 相关资源，比如文档、目录、键盘、网络套接字，以及标准输入输出等，以“文件”的形式进行抽象，并使用相对统一的数据结构来表示。而在实际编码过程中，每一个可用的 IO 资源都会对应于一个唯一的整型文件描述符值。该值将被作为“单一可信源（The Single Source of Truth）”，供相关接口使用。</p><p>而标准 IO 在接口设计与使用方式上，却不会与某类特定的操作系统进行“绑定”。相反，它会提供更加统一和通用的接口，来屏蔽底层不同系统的不同实现细节，做到“一次编写，到处编译”。</p><p>除此之外，即使上述两段采用不同级别 IO 接口实现的 C 代码，在实际的可观测执行效果方面基本一致，但它们在程序运行时，资源的背后使用逻辑上却有着较大的差异。</p><h2>带缓冲的标准 IO 模型</h2><p>那么，这两种 IO 模型除了在接口使用方式上有不同外，还有哪些重要差异呢？简单来讲，<strong>与低级 IO 相比，标准 IO 会为我们提供带缓冲的输入与输出操作</strong>。事实上，标准 IO 接口在实现时，会直接使用所在平台提供的低级 IO 接口。而低级 IO 接口在每次调用时，都会通过系统调用来完成相应的 IO 操作。</p><p>关于系统调用的内容，这一讲的后面还会提到。并且，我也会在第 31 讲中再为你深入介绍。在这里你只需要知道，系统调用的过程涉及到进程在用户模式与内核模式之间的转换，其成本较高。为了提升 IO 操作的性能，同时保证开发者所指定的 IO 操作不会在程序运行时产生可观测的差异，标准 IO 接口在实现时通过添加缓冲区的方式，尽可能减少了低级 IO 接口的调用次数。</p><p>让我们再把目光移回到之前的两段示例代码上。不知道你在运行对应的两段程序时，是否有观察到它们之间的差异呢？实际上，使用低级 IO 接口实现的程序，会在用户每次输入新内容到标准输入流中时，同时更新文件 “temp.txt” 中的内容。而使用标准 IO 接口实现的程序，仅会在用户输入的内容达到一定数量或程序退出前，再更新文件中的内容。而在此之前，这些内容将会被存放到缓冲区中。</p><p>当然，C 标准中并未规定标准 IO 接口所使用的缓冲区在默认情况下的大小，对于其选择，将由具体标准库实现自行决定。</p><p>除此之外，标准 IO 还为我们提供了可以自由使用不同缓冲策略的能力。对于简单的场景，我们可以使用名为 fflush 的接口，来在任意时刻将临时存放在缓冲区中的数据立刻“冲刷”到对应的流中。而在相对复杂的场景中，我们甚至可以使用 setvbuf 等接口来精确地指定流的缓冲类型、所使用的缓冲区，以及可以使用的缓冲区大小。</p><p>比如，我们可以在上述标准 IO 实例对应 C 代码的第 4 行后面，插入以下两行代码：</p><pre><code class=\"language-c++\">// ...\nchar buf[1024];\nsetvbuf(fp, buf, _IOFBF, 5);\n// ...\n</code></pre><p>此时，再次编译并运行程序，其执行细节与之前相比会有什么不同？欢迎在评论区告诉我你的发现。</p><h2>用于低级 IO 接口的操作系统调用</h2><p>接下来，让我们再来看一看低级 IO 的相关实现细节。</p><p>在前面的内容中我曾提到过，低级 IO 接口在其内部会通过系统调用来完成相应的 IO 操作。那么，这个过程是怎样发生的呢？</p><p>实际上，你可以简单地将系统调用当作是由操作系统提供的一系列函数。只是相较于程序员在 C 源代码中自定义的“用户函数”来说，系统调用函数的使用方式有所不同。与调用用户函数所使用的 <code>call</code> 指令不同，在 x86-64 平台上，我们需要通过名为 <code>syscall</code> 的指令来执行一个系统调用函数。</p><p>操作系统会为每一个系统调用函数分配一个唯一的整型 ID，这个 ID 将会作为标识符，参与到系统调用函数的调用过程中。比如在 x86-64 平台上的 Linux 操作系统中，open 系统调用对应的 ID 值为 2，你会在接下来的例子中看到它的实际用法。</p><p>同用户函数类似的是，系统调用函数在被调用时，也需要通过相应的寄存器来实现参数传递的过程。而正如我在第 <a href=\"https://time.geekbang.org/column/article/468171\">05 讲</a> 中提到的那样，SysV 调用约定中规定，系统调用将会使用寄存器 rdi、rsi、rdx、r10、r8、r9 来进行实参的传递。当然，除此之外，rax 寄存器将专门用于存放系统调用对应的 ID，并接收系统调用完成后的返回值。</p><p>那么，让我们通过实际代码来看一看，如何在机器指令层面使用系统调用。在下面这段代码中，我们直接使用机器指令调用了 open 系统调用函数。</p><pre><code class=\"language-c++\">#include &lt;unistd.h&gt;\n#include &lt;fcntl.h&gt;\nint main(void) {\n&nbsp; const char str[] = \"Enter some characters:\\n\";\n&nbsp; write(STDOUT_FILENO, str, sizeof(str));\n&nbsp; const char* fileName = \"./temp.txt\";\n  // Call to `open` starts:\n  // const int fd = open(\"./temp.txt\", O_RDWR | O_CREAT);\n&nbsp; volatile int fd;\n&nbsp; asm(\"mov $2, %%rax\\n\\t\"\n&nbsp; &nbsp; &nbsp; \"mov %0, %%rdi\\n\\t\"\n&nbsp; &nbsp; &nbsp; \"mov $66, %%rsi\\n\\t\"  // 2 | 64 -&gt; 66;\n&nbsp; &nbsp; &nbsp; \"syscall\\n\\t\"\n&nbsp; &nbsp; &nbsp; \"mov %%rax, %1\\n\\t\"\n&nbsp; &nbsp; &nbsp; &nbsp;: \"=m\" (fileName)\n&nbsp; &nbsp; &nbsp; &nbsp;: \"m\" (fd));\n  // Call ended.\n&nbsp; if (fd &gt; 0) {\n&nbsp; &nbsp; char ch;\n&nbsp; &nbsp; while (read(STDIN_FILENO, &amp;ch, 1)) {\n      if (ch == 'z') break;\n&nbsp; &nbsp; &nbsp; write(fd, &amp;ch, sizeof(ch));\n&nbsp; &nbsp; }\n&nbsp; } else {\n&nbsp; &nbsp; const char errMsg[] = \"File open failed.\";\n&nbsp; &nbsp; write(STDERR_FILENO, errMsg, sizeof(errMsg));\n&nbsp; }\n&nbsp; close(fd);\n&nbsp; return 0;\n}\n</code></pre><p>可以看到，在上述代码的第 10 行，我们以内联汇编的形式，在程序的执行流中插入了 5 条机器指令。其中，第 1 条指令，我们将系统调用 open 对应的整型 ID 值 2 放入到了寄存器 rax 中；第 2 条指令，我们将存放有目标文件名称的字节数组 fileName 的首地址放到了寄存器 rdi 中，该参数也对应着低级 IO 接口 open 的第一个参数。接下来的一条指令，我们将配置参数对应表达式 <code>O_RDWR | O_CREAT</code> 的计算结果值 66 放入到了寄存器 rsi 中。最后，通过指令 <code>syscall</code>，我们得以调用对应的系统调用函数。</p><p>而当系统调用执行完毕后，其对应的返回值将会被放置在寄存器 rax 中。因此，你可以看到：在代码的第 14 行，我们将该寄存器中的值传送到了变量 fd 在栈内存中的位置。至此，程序对系统调用 open 的使用过程便结束了，是不是非常简单？</p><p>其实，除了低级 IO 接口以外，C 标准库中还有很多其他的功能函数，它们的实际执行也都依赖于所在操作系统提供的系统调用接口。因此，我们可以得到 C 标准库、系统调用，以及应用程序三者之间的依赖关系，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/65/93/65e41f456820119940e87250ed6ac693.jpg?wh=1920x1535\" alt=\"图片\"></p><p>这个关系看起来比较清晰，但隐藏在操作系统背后的系统调用函数实现细节，以及调用细节却非常复杂。与此相关的更多内容，我会在“C 程序运行原理篇”中再向你详细介绍。</p><h2>危险的 gets 函数</h2><p>最后，我们再来聊聊标准 IO 与代码安全的相关话题。</p><p>实际上，C 语言提供的标准 IO 接口并非都是完备的。自 C90 开始，一个名为 gets 的IO 函数被添加进标准库。该函数主要用于从标准输入流中读取一系列字符，并将它们存放到由函数实参指定的字符数组中。例如，你可以这样来使用这个函数：</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\nvoid foo(void) {\n&nbsp; char buffer[16];\n&nbsp; gets(buffer);\n}\nint main(void) {\n&nbsp; foo();\n&nbsp; return 0;&nbsp;\n}\n</code></pre><p>可以看到，函数的使用方式十分简单。在上述代码的第 3 行，我们声明了一个 16 字节大小的字符数组。紧接着，该数组作为实参被传递给了调用的 gets 函数。而此时，所有来自用户的输入都将被存放到这个名为 buffer 数组中。一切看似美好，但问题也随之而来。</p><p>实际上，gets 函数在其内部实现中，并没有对用户的输入内容进行边界检查（Bound Check）。因此，当用户实际输入的字符数量超过数组 buffer 所能承载的最大容量时，超出的内容将会直接覆盖掉栈帧中位于高地址处的其他数据。而当别有用心的攻击者精心设计输入内容时，甚至可以在某些情况下直接“篡改”当前函数栈帧的返回地址，并将其指向另外的，事先准备好的攻击代码。</p><p>正因如此，gets 函数已经在 C99 标准中被弃用，并在 C11 及以后的标准中移除。不仅如此，如今的主流编译器在遇到使用了 gets 函数的代码时，也会给予相应的安全性提示。另外，DEP、ASLR、Canary 等技术也在一定程度上降低了此类安全事故发生的风险。<strong>但无论如何，请不要在代码中使用 gets 函数</strong>。</p><h2>总结</h2><p>好了，讲到这里，今天的内容也就基本结束了。最后我来给你总结一下。</p><p>今天我主要介绍了 C 标准库中与标准 IO 相关的内容，包括 IO 接口的不同级别，它们之间的区别，以及背后的实现方式。</p><p>根据对操作系统依赖关系的强弱，IO 接口可以被分为“低级 IO”与“标准 IO”两种不同的层级。其中，低级 IO 的使用依赖于具体的操作系统，而标准 IO 则抽象出了通用的 IO 接口，因此更具可移植性。</p><p>标准 IO 一般会使用所在平台的低级 IO 接口来实现。而低级 IO 则通过调用操作系统内核提供的系统调用函数，来完成相应的 IO 操作。在 x86-64 平台上，系统调用通过 <code>syscall</code> 指令来执行。而在基于该平台的 Unix 与类 Unix 系统上，系统调用函数的执行会使用寄存器 rdi、rsi、rdx、r10、r8、r9 来进行参数的传递，rax 寄存器则用于传递系统调用 ID，以及接收系统调用的返回值。</p><p>最后，由于设计实现原因，标准库中的 gets 函数具有较大的安全风险，因此要避免在程序中使用。</p><h2>思考题</h2><p>最后，我们一起来做个思考题。</p><p>ungetc 函数有什么作用呢？对同一个流，它最多可以被连续调用多少次呢？欢迎在评论区留下你的答案。</p><p>今天的课程到这里就结束了，希望可以帮助到你，也希望你在下方的留言区和我一起讨论。同时，欢迎你把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"10｜标准库：字符、字符串处理与数学计算","id":473400},"right":{"article_title":"12｜标准库：非本地跳转与可变参数是怎样实现的？","id":475867}}},{"article_id":475867,"article_title":"12｜标准库：非本地跳转与可变参数是怎样实现的？","article_content":"<p>你好，我是于航。</p><p>我曾在第 <a href=\"https://time.geekbang.org/column/article/468171\">05 讲</a> 中介绍过，C 语言中的函数调用是在 <code>call</code> 与 <code>ret</code> 两个指令的共同协作下完成的。这个过程包括程序执行流的转移、栈帧的创建、函数代码的执行、资源的清理，一直到函数调用完毕并返回至调用点的下一条指令上。总的来看，函数在正常情况下的调用流程是稳定有序的。</p><p>但实际上，这种以函数为单位的“顺序”执行流并不能完全满足 C 语言在使用时的所有应用场景。因此，C 标准从 C90 开始，便为我们提供了名为 “setjmp.h” 的标准库头文件。通过使用该头文件提供的两个接口 setjmp 与 longjmp，我们能够在函数调用过程中，实现对执行流的跨函数作用域转变。而对于上述这种函数执行流程上的变化，我们一般称它为“<strong>非本地跳转</strong>（Non-local Jump）”。</p><p>除此之外，在正常的 C 语法中，函数在被实际调用时，只能接收与其函数原型和函数定义中标注的，类型及个数相同的实参。而为了进一步增强 C 函数在使用上的灵活性，同样是在 C90 之后的标准中，C 语言还为我们提供了名为 “stdarg.h” 的头文件。配合使用在该头文件中定义的宏，我们便可以在 C 代码中定义“<strong>可变参数函数</strong>（Variadic Function）”。而可变参数函数与普通函数的最大区别就在于，它们在被调用时可以接收任意多个实参，而无需提前在函数原型或定义中声明这些参数的信息。</p><!-- [[[read_end]]] --><p>那么，今天我们就来聊一聊 C 语言中的非本地跳转与可变参数函数。在接下来的内容中，我会分别介绍它们的基本用法与实现原理。</p><h2>非本地跳转</h2><p>非本地跳转的概念并不直观，既然如此，我们就换一个方式来理解它：在继续深入之前，我们先来看一个与它相对的简单概念，本地跳转（Local Jump）。相信了解过这个概念后，你会对非本地跳转与程序执行流变化的对应关系有更直观的理解。</p><h3>本地跳转</h3><p>在 C 语言中，本地跳转一般是指由 <code>goto</code> 语句完成的程序执行流的转移过程。这里我们来看一个简单的例子：</p><p><img src=\"https://static001.geekbang.org/resource/image/c2/1b/c24bd9b4fdd37bb6a4d74d5c59f0d11b.png?wh=1920x1090\" alt=\"图片\"></p><p>可以看到，在上图左侧的 C 代码中，我们通过设置标签 “head” 的方式，显式地指定了函数 main 内部一个可能的“执行跳入点”。随着程序的运行，当用户的输入满足 if 条件判断语句的要求时，我们便通过 <code>goto</code> 语句，将程序的执行流程重新转移到了标签 head 的所在位置。从右侧红框内的汇编代码中也可以看到，对应的执行流程转移过程是通过 <code>jmp</code> 指令来完成的。按照这样的方式，程序得以在 main 函数内部，根据外部的用户输入，动态地调整其执行流程。</p><p>而我们之所以称这种通过 <code>goto</code> 语句实现的程序执行流变化为本地跳转，是因为<strong>在这种方式下的执行流程转移仅能够发生在当前程序运行所在的某个具体函数中</strong>。相对地，程序无法做到从某个函数体的执行中途，直接将其执行流转移到其他函数的内部。“跨函数”的调用仅能够通过常规的 <code>call</code> 与 <code>ret</code> 指令来实现。</p><p>但是，非本地跳转却可以打破这个限制。接下来，我们具体看看与它有关的 setjmp 和 longjmp 函数。</p><h3>setjmp 与 longjmp 函数</h3><p>在 C 语言中，非本地跳转的实现依赖于标准库头文件 setjmp.h 内的两个函数 setjmp 与 longjmp。关于它们的具体使用方式，你可以点击<a href=\"https://en.cppreference.com/w/c/program/setjmp\">这个链接</a>参考更多信息，这里我就不展开了。</p><p>接下来，我们直接使用这两个函数编写一段简单的代码，并观察程序运行时非本地跳转的实际执行方式。代码如下所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/ef/08/efbb43133db05e51becf6364b3d0f508.png?wh=1894x1702\" alt=\"图片\"></p><p>上图中左侧为 C 代码，右侧为对应的汇编代码。此时，你可以先停下来，观察整个程序的大致实现方式。程序的实际运行结果是连续打印出了从 A 到 J 共 10 个字符。这里建议你动手实践下，并验证我们的结论。</p><p>接下来，回到左侧的 main 函数，让我们来看一下程序的执行细节。</p><p>首先，我们定义了名为 c 的字符变量，并将它的值初始化为字符 A。通过标注 <code>volatile</code> 关键字，编译器不会对该变量的使用过程进行任何优化。然后，我们在 if 条件语句中调用了函数 setjmp，并将声明为 jmp_buf 类型的全局变量 jb 传递给了它。该函数的调用返回值会与字符 J 进行比较，若满足小于关系，则会调用另外的函数 inspect 来打印变量 c 的内容，并同时递增 c 的值。</p><p>接下来把目光移到 C 代码的第 5 行，inspect 函数的定义部分。这里，该函数接收一个字符变量，并使用 putchar 函数将它的值打印了出来。可以看到，函数在定义时被标注了 <code>_Noreturn</code> 关键字，也就是说，inspect 函数在调用结束后不会通过正常的 <code>ret</code> 指令退出。而之所以会发生这样的情况，便是由于代码在第 7 行调用的 longjmp 函数。</p><p>实际上，随着 longjmp 函数执行完毕，程序的执行流程将会直接跳转到 main 函数中 <code>call setjmp</code> 指令（也就是调用 setjmp 函数的那条指令）的下一条指令上。在上图右侧的汇编代码中，我使用红色箭头标注出了程序在机器代码层面的具体执行顺序，其中，实线部分对应的机器代码将会在程序运行过程中执行多次。</p><p>可以看到，当程序执行流由 inspect 函数转移回 main 函数后，借由 <code>cmp</code> 指令，程序得以再次检查寄存器 rax 中的值是否小于字符 J 对应的 ASCII 码值 73。若条件成立，则重复之前的程序执行逻辑；否则，程序直接退出。此时，rax 寄存器中存放的值便对应于 longjmp 函数在被调用时传入的第二个参数值。</p><p>不同于常规的函数调用过程，<strong>非本地跳转为我们提供了一种可以暂存函数调用状态，并在未来某个时刻再恢复的能力</strong>。借助这种能力，我们便能够实现跨函数的、精确到某条具体语句的程序执行流程跳转。那这种能力是如何实现的呢？</p><h3>运作原理</h3><p>通过上面的例子我们得知，非本地跳转实际上是由 setjmp 与 longjmp 这两个函数共同协作完成的。我们来看看它们究竟都做了哪些事情。</p><p>setjmp 函数在执行时，会将程序此刻的函数调用环境信息，存储在由其第一个参数指定的 jmp_buf 类型的对象中，并同时将数值 0 作为函数调用结果返回。而当程序执行到 longjmp 函数时，该函数便会从同一个 jmp_buf 对象中再次恢复之前保存的函数调用上下文。通过这种方式，程序的执行流程得到了“重置”。</p><p>那么，与函数调用环境相关的信息有哪些呢？我曾在 <a href=\"https://time.geekbang.org/column/article/468171\">05 讲</a> 中介绍过，以 x86-64 为例，SysV 调用约定中规定，属于 Callee-saved 类型的寄存器信息需要在 <code>call</code> 指令调用时，由被调用函数负责保存和恢复。这也就意味着，这类寄存器中实际上存放着与当前调用函数（caller）有关的上下文状态信息。因此，当被调用函数通过 <code>ret</code> 指令返回时，这些寄存器中的“旧值”仍需要被调用函数继续使用。所以，对于 setjmp 函数的实现，是不是只要把所有 Callee-saved 寄存器中的值进行保存就可以了呢？让我们来做个实验吧！</p><h3>自定义实现</h3><p>在这个简单的实验中，我们将构建自己的 setjmp 与 longjmp 函数，并重新编译之前的 C 示例程序，来让它使用这两个函数的自定义实现。这里，我们将直接编写汇编代码，并在最后以对象文件的形式将它们链接到程序中使用。需要注意的是，下面我将要介绍的实现方式仅适用于 x86-64 平台。对于其他平台，使用的汇编指令以及需要保存的寄存器可能有所区别，但整体思路基本一致。</p><p>按照之前的方案，我们可以直接写出 setjmp 函数的汇编实现，代码如下所示：</p><pre><code class=\"language-c++\">.global setjmp\n.intel_syntax noprefix\nsetjmp:\n&nbsp; mov  QWORD PTR [rdi], rbx\n&nbsp; mov  QWORD PTR [rdi+0x8], rbp\n&nbsp; mov  QWORD PTR [rdi+0x10], r12\n&nbsp; mov  QWORD PTR [rdi+0x18], r13\n&nbsp; mov  QWORD PTR [rdi+0x20], r14\n&nbsp; mov  QWORD PTR [rdi+0x28], r15\n&nbsp; lea  rdx, [rsp+0x8]\n&nbsp; mov  QWORD PTR [rdi+0x30], rdx\n&nbsp; mov  rdx, QWORD PTR [rsp]\n&nbsp; mov  QWORD PTR [rdi+0x38], rdx\n&nbsp; xor  eax, eax\n&nbsp; ret\n</code></pre><p>其中，前两行以 “.” 开头的语句为汇编器指令，它们用来指示汇编器应该如何处理接下来的汇编代码。第一行的 “.global” 指令指示汇编器可以将符号 setjmp 暴露给链接器使用；第二行指令指示汇编器，接下来的汇编代码将采用 Intel 语法格式。</p><p>在 setjmp 的函数体实现中，由于 SysV 调用规范的约束，作为接收函数第一个实参的 rdi 寄存器，其内部将保存有传入的 jmp_buf 对象的首地址。你可以直接将该对象看成是一个具有足够大小的字节数组，而这里我们要做的，就是把各个 Callee-saved 寄存器中的值按顺序放入这个数组中进行暂存。</p><p>紧接着，第 4 ~ 9 行的代码将寄存器 rbx、rbp、r12、r13、r14，以及 r15 的值进行了暂存；第 10 ~ 11 行的代码将 setjmp 函数调用之前的 rsp 寄存器的值进行了暂存；第 12 ~ 13 行的代码将 setjmp 函数调用后的返回地址进行了暂存，这个地址将由 longjmp 函数进行使用。最后，第 14 行代码将寄存器 rax 的值置零，以作为该函数的返回值。至此，setjmp 函数的实现便完成了。</p><p>按照相同的思路，我们也可以直接得到 longjmp 函数实现的汇编代码，如下所示：</p><pre><code class=\"language-c++\">.global longjmp\n.intel_syntax noprefix\nlongjmp:\n&nbsp; xor&nbsp; eax, eax\n&nbsp; cmp&nbsp; esi, 0x1\n&nbsp; adc&nbsp; eax, esi\n&nbsp; mov&nbsp; rbx, QWORD PTR [rdi]\n&nbsp; mov&nbsp; rbp, QWORD PTR [rdi+0x8]\n&nbsp; mov&nbsp; r12, QWORD PTR [rdi+0x10]\n&nbsp; mov&nbsp; r13, QWORD PTR [rdi+0x18]\n&nbsp; mov&nbsp; r14, QWORD PTR [rdi+0x20]\n&nbsp; mov&nbsp; r15, QWORD PTR [rdi+0x28]\n&nbsp; mov&nbsp; rsp, QWORD PTR [rdi+0x30]\n&nbsp; jmp&nbsp; QWORD PTR [rdi+0x38]\n</code></pre><p>这里需要注意的是代码的第 5~6 行。longjmp 函数在调用时需要遵守的一个规则是：如果传递给它的第二个实参为 0，则使用数值 1 对其进行替换。这样做是为了能够通过 rax 寄存器中的不同“返回值”，区分当前代码是在 setjmp 函数调用后首次被执行的，还是由 longjmp 恢复函数调用环境后再次被执行的。这里我给你留个思考题：这两行汇编代码是如何实现上述的替换逻辑的？欢迎在评论区告诉我你的想法。</p><p>至此，setjmp 与 longjmp 这两个函数的自定义实现便准备完毕了。我们将这些汇编代码分别存放到名为 setjmp.s 与 longjmp.s 的文本文件中。然后，通过下面这两行命令，我们能够将它们编译成各自对应的 .o 对象文件。</p><pre><code class=\"language-c++\">gcc -c setjmp.s -o setjmp.o\ngcc -c longjmp.s -o longjmp.o\n</code></pre><p>接下来，为了在 C 代码中正确调用这两个函数，我们还需要为它们提供相应的函数原型，以及 jmp_buf 类型的详细定义。包含有上述这些内容以及原始示例程序的完整 C 代码如下所示：</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\n#include &lt;stdnoreturn.h&gt;\n// 定义 jmp_buf 类型；\ntypedef long jmp_buf[8];\n// 提供函数原型；\nint setjmp(jmp_buf);\nnoreturn void longjmp(jmp_buf, int);\n// 原始 C 示例程序代码；\njmp_buf jb;\nnoreturn void inspect(char val) {\n&nbsp; putchar(val);\n&nbsp; longjmp(jb, val);\n}\nint main(void) {\n&nbsp; volatile char count = 'A';\n&nbsp; if (setjmp(jb) &lt; 'J')\n&nbsp; &nbsp; inspect(count++);\n&nbsp; return 0;\n}\n</code></pre><p>在这段代码的第 4 行，我们为类型 jmp_buf 提供了相应的定义。由于该对象内部仅需要连续存放 8 个 64 位的寄存器值，因此我们将它定义为具有 8 个元素的长整型数组。紧接着，我们也分别为函数 setjmp 与 longjmp 提供了与标准库中实现完全一致的函数原型。最后，将这段代码保存在文件 main.c 中，然后通过下面的命令，我们便可以编译并运行整个程序。</p><pre><code class=\"language-c++\">gcc&nbsp;main.c setjmp.o longjmp.o -o main &amp;&amp; ./main\n</code></pre><p>请你动手实践下，并观察程序的输出。在正常情况下你将会得到同示例程序完全一致的运行结果。</p><p>当然，为了便于你理解，这里我简化了 setjmp 与 longjmp 函数的实现细节，但它们的“核心思想”却可以通过这短短的几行汇编代码完全体现出来。</p><p>通常来说，在 C 语言中，非本地跳转主要用来实现异常处理、协程等功能。标准中仅规定了 setjmp 函数可以正常使用的几种特定上下文情况，因此在使用它时，你需要十分小心，以防出现未定义行为。</p><h2>可变参数函数</h2><p>下面，我们来看另一个话题，可变参数函数。不知道你有没有察觉，这门课从开篇词开始，就一直在各个示例程序中使用这类函数。我们在初学 C 语言时，编写的第一个 “Hello, world” 程序中使用到的 printf 函数，就是其中一种。而仔细观察你会发现，printf 函数所能接收的参数个数，实际上完全取决于我们在它第一个参数，即格式控制字符串中指定的“格式控制符”的个数。</p><h3>基本使用</h3><p>可变参数函数能够接收不定数量的实参，而为了定义这样一个函数，我们需要配合使用由标准库头文件 stdarg.h 提供的类型与宏函数。让我们来看一个简单的例子，代码如下所示：</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\n#include &lt;stdarg.h&gt;\nvoid print_sum(int count, ...) {\n&nbsp; int sum = 0;\n&nbsp; va_list ap;\n&nbsp; va_start(ap, count);&nbsp;\n&nbsp; for (int i = 0; i &lt; count; ++i)\n&nbsp; &nbsp; sum += va_arg(ap, int);\n&nbsp; va_end(ap);\n&nbsp; printf(\"%d\\n\", sum);\n}\nint main(void) {\n&nbsp; print_sum(4, 1, 2, 3, 4);\n&nbsp; return 0;\n}\n</code></pre><p>这里我们定义了一个名为 print_sum 的可变参数函数，该函数会计算传递给它的所有实参（第一个实参除外）之和。而它的第一个参数，将被用来统计函数在调用时所传入的其余参数的个数。</p><p>到这里，你可以先暂缓脚步，仔细看看在上面的代码中，我们是如何使用类型 va_list，以及宏函数 va_start、va_arg，以及 va_end 的。如果你对它们还不太了解，可以先点击<a href=\"https://en.cppreference.com/w/c/variadic\">这个链接</a>来查看对它们用法的更多说明。</p><h3>运作原理</h3><p>接下来，让我们把目光放到上面所说的几种类型与宏函数的底层实现上，来探究它们在内部是如何对传入函数的多个实参进行管理的。</p><p>对于 Clang 和 GCC 来说，这些宏函数在展开后，会调用由编译器在内部实现的 builtin 函数。因此，如果想要了解它们的实现细节，便需要深入到编译器代码的内部。但由于编译器实现较为庞杂，这个方法并不适合我们快速了解相关内容。那有没有更方便的办法呢？答案是有的。</p><p>实际上，在遵循 System V AMD64 ABI 的 x86-64 计算机上，ABI 已经详细规定了编译器应该如何实现函数的可变参数列表。因此，通过阅读其对应的文档，我们便能够了解到上述这些宏函数和类型的一种实现方式。而对于其他平台，虽然实现细节上可能稍有不同，但整体思路不会有太大的差异。那么接下来，我就带你看看标准中的可变参数函数是如何定义的。</p><p>在我们继续之前，你可能会有这样的疑问：这里我提到的 System V AMD64 ABI 与在 <a href=\"https://time.geekbang.org/column/article/468171\">05 讲</a> 中介绍的同名调用约定有什么关系呢？</p><p>这是一个很好的问题。实际上，System V AMD64 ABI 的全称为 “System V AMD64 <strong>Application Binary Interface</strong>”。它是一种描述了应用程序应该如何在机器代码中进行某种操作的标准规范，而我们之前介绍的“函数调用约定”便是其重要内容之一。关于 ABI 的更多内容，我将在这门课的“C 程序运行原理篇”中再为你详细介绍。</p><p>SysV ABI 中详细规定了可变参数列表的实现要求，但信息较多，规则较为复杂。这里为了方便你理解，我会<strong>按照上述代码中函数 print_sum 的执行顺序，从整体的视角为你讲述它在机器指令层面对传入实参的处理方式</strong>。如果你想了解更多的细节性信息，可以通过<a href=\"https://github.com/hjl-tools/x86-psABI/wiki/x86-64-psABI-1.0.pdf\">这个链接</a>下载 ABI 文档，并参考从第 54 页开始的内容。</p><p>首先，当 print_sum 函数被 <code>call</code> 指令调用前，由于所传入的参数均为整型，因此它们可以被直接存放在由 SysV ABI 函数调用约定规定的参数寄存器中。这里，对应的 5 个数字值实参将被依次存放到寄存器 rdi、rsi、rdx、rcx，以及 r8 中。</p><p>接着，函数被调用。寄存器 al 中将会存放有传入函数的浮点参数的个数，该寄存器的值将会被编译器使用，以进行相应优化。同时，一块名为 “Register Save Area”（后简称 RSA）的栈内存区域将会被构建。而每一个通过寄存器传入函数的实参值，都会按照 rdi、rsi、rdx、rcx、r8、r9、xmm0~xmm15 的寄存器先后顺序，被拷贝并存放在这段内存中。</p><p>函数继续执行，在代码的第 5 行，va_list 类型的变量 ap 被定义，而其中存放有用于支持 va_arg 宏函数正常运作的必要信息。通常来说，该类型可以被定义为如下所示的 C 数据结构。可以看到，va_list 为一个指针，指向了包含有 4 个字段的结构对象。</p><pre><code class=\"language-c++\">typedef struct {\n&nbsp; unsigned int gp_offset;  // 下一个整型数据相较于 RSA 的偏移；\n&nbsp; unsigned int fp_offset;  // 下一个浮点数据相较于 RSA 的偏移；\n&nbsp; void *overflow_arg_area;  // 指向使用栈进行传递的数据；\n&nbsp; void *reg_save_area;  //  指向 RSA 的指针；\n} va_list[1];\n</code></pre><p>这里我将 va_list 所指向结构对象内部各个字段的具体功能，以注释的方式标注了出来。你可以先浏览一遍，有个大致的印象，下面我就向你介绍它们的用途。</p><p>在 print_sum 函数实现的第 3 行（即代码第 6 行），va_start 宏函数对 va_list 所指向的结构对象进行了初始化。在这个过程中，字段 gp_offset 将会被设置为下一次将要从 RSA 中读取的整型实参，其值距离 RSA 开始位置的偏移。类似地，fp_offset 则用于浮点实参值。除此之外，指针 overflow_arg_area 将会指向每一个使用栈进行传递的实参值；最后的 reg_save_area 将指向 RSA 的起始地址。</p><p>代码的第 8 行，va_arg 宏函数将会根据传入的 va_list 指针以及想要提取的实参类型，从 RSA 中取出相应的数据值。在这个过程中，ap 结构体内字段 gp_offset、fp_offset，以及 overflow_arg_area 的值会随着数据的不断提取而得到更新。在实现细节上，va_arg 在提取实参的过程中，还需要考虑对由多个寄存器存放的实参（大于 64 位）的处理，以及栈上数据指针对齐等问题。</p><p>最后，当传入的实参被提取完毕后，通过代码第 9 行的宏函数 va_end，ap 结构体得到了清理。</p><h2>总结</h2><p>好了，讲到这里，今天的内容也就基本结束了。最后我来给你总结一下。</p><p>今天我主要介绍了 C 语言中的非本地跳转与可变参数函数这两方面内容。通过使用由 C 标准库头文件 setjmp.h 与 stdarg.h 提供的一系列接口，我们能够在程序中轻松地使用这两种特性。</p><p>非本地跳转为我们提供了一种可以临时保存函数执行上下文，并在未来某时刻再重新恢复的能力。通过这种方式，我们可以在 C 语言中实现异常捕获、协程等特殊功能。非本地跳转的基本实现方式是在执行 setjmp 函数时，将此刻所有 Callee-saved 寄存器的值进行暂存。而在未来某一时刻 longjmp 函数调用时，再将这些寄存器的值进行复原。通过这种方式，Caller 函数的原始执行状态便会得到恢复。</p><p>可变参数函数则让我们使用函数的方式变得更加灵活。配合使用类型 va_list，以及宏函数 va_start、va_arg、va_end，我们可以在函数体内，依次获取由外部调用者传入的若干个不定参数。而为了保证兼容性，变长参数列表的实现细节需要遵循目标平台和操作系统对应的 ABI 规范。</p><h2>思考题</h2><p>你知道怎样使用非本地跳转来实现 try…catch 语句吗？可以尝试编写几个宏，来在 C 代码中实现类似的异常抛出和捕获效果，并在评论区分享你的实践经验。</p><p>今天的课程到这里就结束了，希望可以帮助到你，也希望你在下方的留言区和我一起讨论。同时，欢迎你把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"11｜标准库：深入理解标准 IO","id":475253},"right":{"article_title":"13｜标准库：你需要了解的 C 并发编程基础知识有哪些？","id":477358}}},{"article_id":477358,"article_title":"13｜标准库：你需要了解的 C 并发编程基础知识有哪些？","article_content":"<p>你好，我是于航。</p><p>在构建高性能应用时，并发编程是我们经常采用的一种技巧。它通过在程序的运行进程内提供可控制粒度更细的“线程”，从而将程序的整体功能拆分为更小的独立任务单元，并以此来进一步利用多核 CPU 的运算资源。</p><p>对于 C11 标准之前的 C 语言来说，想要构建多线程应用，只能依赖于所在平台上的专有接口，比如 Unix 与类 Unix 平台上广泛使用的 POSIX 模型，以及后起之秀 OpenMP 模型等。这些模型提供的编程接口，以及所支持平台都有很大的不同。因此，对于那时的 C 语言来说，想要编写高可移植性的多线程应用，仍需要花费很大功夫。</p><p>而自 C11 标准后，C 语言为我们专门提供了一套通用的并发编程接口，你可以通过标准库头文件 threads.h 与 stdatomic.h 来使用它们。其中，threads.h 中包含有与线程控制、互斥量、条件变量，以及线程本地存储相关的接口；而 stdatomic.h 中则包含有与原子操作相关的接口。这些接口提供了多种不同方式，可用来避免多线程应用在运行过程中可能遇到的各类线程同步问题。</p><p>C11 标准的发布，理论上使构建可移植的多线程 C 应用成为可能，但现实情况却并非这样理想。各类 C 标准库对 C11 中并发编程接口的支持程度不同，比如 Glibc（GNU C 标准库）在其 2018 年中旬发布的 2.28 版本中，才将相关接口进行了较为完整的实现。这就导致了 C11 标准中的这些重要特性，至今（2022 年初）仍然没有得到较为广泛的应用。</p><!-- [[[read_end]]] --><p>因此，接下来我将用两讲的篇幅，为你从零介绍有关并发编程的一些基础知识，以及 C11 并发编程相关接口的基本使用方式。当然，由于并发编程是一种完全不同的编程模型，短短几千字是无法详细梳理完所有相关内容的。但我希望通过对这两讲内容的学习，你能够对使用 C 语言开发多线程应用有一个全新的认识，并以此为起点，在未来进行更加深入的了解。</p><p>这一讲，就让我们来一起了解下并发编程的主角，线程，以及我们在围绕它进行多线程开发时可能遇到的一些常见问题。</p><h2>进程 vs 线程</h2><p>相信你对“进程”这个概念应该比较熟悉，那么线程与进程有哪些区别呢？我们来一起看一看。</p><p>默认情况下，操作系统会为每一个运行中的程序创建一个相应的进程，以作为它的运行实例。而进程中则包含与该程序有关的一系列运行时信息，比如 VAS、进程 ID、处理器上下文（如通用目的寄存器与指令寄存器中的值）、进程状态，以及操作系统分配给该进程的相关资源等。这些信息被统一存放在内核提供的，名为“进程控制块（PCB）”的数据结构中。</p><p>现代 CPU 通常会采用“抢占式”调度算法，来进行多个进程之间的任务切换过程。比如，当某个进程的执行时间超过一定阈值，或开始等待 IO 响应，或所在系统出现硬件中断等情况时，内核任务调度器可能会将该进程挂起，并将 CPU 资源“转移”给其他进程使用。通过这种方式，即使是在单核 CPU 上，操作系统也能够实现用户可观测的多任务处理过程。当然，具体的调度算法还会考虑进程的优先级权重、历史执行情况等因素。调度器只有在经过“综合评定”后，才会作出选择。</p><p><strong>而相较于进程，线程则为程序提供了更细粒度的运行单元。</strong>对于大多数传统操作系统实现来说，在默认情况下，每一个进程内部都会存在至少一个线程。其中，进程负责划分不同程序所享有资源的边界；而线程则在共享程序运行资源的情况下，负责程序某个子任务的具体执行过程。</p><p>此时，任务调度器也将以线程作为最小的调度实体，来更加精细地组织程序的运行。因此，通过增加进程中线程的个数，我们便能够将程序需要完成的任务进行更具体的划分（比如将 IO 相关操作单独分配给一个线程来执行），并同时进一步利用多核 CPU 的计算资源。</p><p>同进程类似，每一个线程所具有的不同状态信息被保存在内核中名为“线程控制块（TCB）”的数据结构中。其中包含有与特定线程运行紧密相关的处理器上下文、线程 ID、所属进程，以及状态信息，等等。可以看到的是，PCB 与 TCB 两者内部所包含的内容会有一定重合。这是由于在某些操作系统上，单进程（单线程）应用的运行可能会直接使用 PCB，来同时保存程序的资源描述信息与执行状态信息。而当运行多线程应用时，才会配合使用 PCB 与 TCB。这里，你可以通过下图来直观地对比进程与线程之间的区别和联系。当然，具体的实现方式并不唯一。</p><p><img src=\"https://static001.geekbang.org/resource/image/7b/81/7ba38592d36f442a3b16980fd39f9881.jpg?wh=1920x1127\" alt=\"图片\"></p><p>聊完了基本的理论知识，接下来就让我们看看如何在 C 代码中创建线程。</p><h2>线程的基本控制</h2><p>借助 threads.h 头文件提供的接口，我们可以实现对线程的创建、等待、阻塞、分离，以及重新调度等操作。来看下面这段示例代码：</p><pre><code class=\"language-c++\">#include &lt;threads.h&gt;\n#include &lt;stdio.h&gt;\nint run(void *arg) {\n  thrd_t id = thrd_current();  // 返回该函数运行所在线程的标识符；\n  printf((const char*) arg, id);\n  return thrd_success;\n}\nint main(void) {\n#ifndef __STDC_NO_THREADS__\n  thrd_t thread;\n  int result;\n  // 创建一个线程；\n  thrd_create(&amp;thread, run, \"Hello C11 thread with id: %lu.\\n\");\n  if (thrd_join(thread, &amp;result) == thrd_success) {\n    // 等待其他线程退出；\n    printf(\"Thread returns %d at the end.\\n\", result);  \n  }  \n#endif\n  return 0;\n}\n</code></pre><p>可以看到，在 main 函数的开头，我们首先通过判断宏 <strong>STDC_NO_THREADS</strong> 是否存在，来决定是否“启用”多线程相关的代码。C11 标准中规定，若编译器实现不支持并发编程相关接口，则需要定义该宏。</p><p>然后，在条件编译指令 <code>ifndef</code> 的内部，我们定义了类型为 <code>thrd_t</code> 的变量 thread。该类型为由具体实现定义的，用于标识某个线程的唯一对象。接下来，在代码的第 13 行，我们通过 thrd_create 函数创建了一个线程。这里，传入该函数的第二个参数为一个 <code>thrd_start_t</code> 类型的函数指针，该指针所指向函数将会在这个新线程内被执行，其接收到的参数为 thrd_create 函数调用时传入的第三个参数。</p><p>当新线程创建完毕后，其执行过程便与 main 函数所在线程发生了“分离”。因此，为了防止 main 函数执行结束前（即整个程序退出前），新线程内的代码还没有执行完成。这里，我们便需要通过 thrd_join 函数，来让 main 函数所在线程“等待”新线程的执行结束。当然，除此之外，如果仅是为了能让新线程顺利执行完毕，我们也可以用 thrd_exit 函数来达到这个目的。这里你可以思考下具体应该怎样做，并在评论区留下你的答案。</p><p>接下来，函数 run 在新线程中被执行。通过函数 thrd_current，我们可以得到当前代码执行所在线程的唯一标识符。然后，调用 printf 函数，我们将该标识符的值打印了出来。至此，新线程执行完毕并终止，执行流程又回到 main 函数所在线程中。</p><p>实际上，除了我们在上面例子中使用到的以 “thrd_” 开头的函数外，C11 还为我们提供了一些其他的线程控制函数。这里，我将它们整理到了下面的表格中，供你参考：</p><p><img src=\"https://static001.geekbang.org/resource/image/3b/d7/3b9248a4dc11b1228835d0547679c8d7.jpg?wh=1920x988\" alt=\"图片\"></p><p>随着多线程应用的功能变得逐渐复杂，共享变量可能会被多个线程同时访问。并且，不同线程可能会以不同的先后顺序，来执行程序中的同一段代码。除此之外，现代 CPU 采用的特殊指令处理方式，使得程序的实际执行流程与对应的汇编代码可能也不完全一致。而上述这三个因素，都确实会在某些情况下影响多线程应用的正常执行。</p><p>下面，我们就来了解一下与上述这三种情况相对应的三个概念，即：数据竞争、竞态条件，以及指令重排。</p><h2>数据竞争</h2><p>从定义上来讲，数据竞争（Data Race）是指在一个多线程环境中，有两个及以上的线程在同一时间对同一块内存中的数据进行了非原子操作，且其中至少有一个是写操作。在这种情况下，该数据值的最终状态可能与程序语义上希望表达的计算结果不一致。来看下面这个例子：</p><pre><code class=\"language-c++\">#include &lt;threads.h&gt;\n#include &lt;stdio.h&gt;\n#define THREAD_COUNT 20\n#define THREAD_LOOP 100000000\nlong counter = 0;&nbsp; // 全局变量，用来记录线程的累加值；\nint run(void* data) {\n&nbsp; for (int i = 0; i &lt; THREAD_LOOP; i++)\n&nbsp; &nbsp; counter++;&nbsp; // 在线程中递增全局变量的值；\n&nbsp; printf(\"Thread %d terminates.\\n\", *((int*) data));\n&nbsp; return thrd_success;\n}\nint main(void) {\n#ifndef __STDC_NO_THREADS__\n&nbsp; int ids[THREAD_COUNT];  // 用于存放线程序号的数组；\n&nbsp; thrd_t threads[THREAD_COUNT];&nbsp;&nbsp;\n&nbsp; for (int i = 0; i &lt; THREAD_COUNT; i++) {\n&nbsp; &nbsp; ids[i] = i + 1;\n&nbsp; &nbsp; thrd_create(&amp;threads[i], run, ids + i);&nbsp; // 创建 THREAD_COUNT 个线程；\n&nbsp; }\n&nbsp; for (int i = 0; i &lt; THREAD_COUNT; i++)\n&nbsp; &nbsp; thrd_join(threads[i], NULL);&nbsp; // 让当前线程等待其他线程执行完毕；\n&nbsp; printf(\"Counter value is: %ld.\\n\", counter);&nbsp; // 输出 counter 变量最终结果；\n#endif\n&nbsp; return 0;&nbsp;\n}&nbsp;&nbsp;\n</code></pre><p>在这段代码中，我们在 main 函数内创建了 20 个线程（由宏常量 THREAD_COUNT 指定），并让这些线程同时对全局变量 counter 进行值递增操作。由于 counter 的初始值被设置为 0，因此，如果代码按照我们的预期执行，20 个线程分别对该全局变量递增 1 亿次，程序在退出前打印的 counter 变量值应该为 20 亿。但实际情况可能并非如此，下面我们具体看下。</p><p>在非优化情况下编译并多次运行这段代码，你会发现程序打印出的 counter 变量值并不稳定。在某些情况下，这个值是准确的，而某些情况下却小于这个数字。这个问题便是由于多线程模型下的数据竞争引起的。</p><p>对于上面这个例子来说，编译器可能会将 run 函数内的 counter 变量自增语句，编译为如下所示的几条机器指令的组合：</p><pre><code class=\"language-c++\">mov eax, DWORD PTR counter[rip]\nadd eax, 1\nmov DWORD PTR counter[rip], eax\n</code></pre><p>在这种情况下，当多个线程在 CPU 的调度下交错运行时，便可能会发生这样一种情况：某个线程刚刚执行完上述代码的第一条指令，将变量 counter 的值暂存在了寄存器 rax 中。此时，操作系统开始调度线程，将当前线程挂起，并开始执行另一个线程的代码。</p><p>新的线程在执行递增时，由于需要再次从 counter 所在的原内存地址中读入数据，因此，该值与上一个线程读取到的数据是相同的。而这便会导致这两个线程在递增后得到的结果值也完全相同，两个线程对 counter 变量的两次递增过程仅使得它的原值增加了 1。</p><p>不仅如此，哪怕编译器在优化情况下，可以将上述递增语句实现为仅一条汇编指令，数据竞争的问题仍可能会存在。</p><p>比如，编译器将该递增操作实现为机器指令 <code>add&nbsp;DWORD PTR counter[rip], 1</code>（这里使用 RIP-relative 寻址）。现代 x86-64 处理器在处理这条 CISC 风格的机器指令时，可能会将其拆分为对应的三种不同“微指令（uOp）”：LOAD、ADD、STORE。其中，LOAD 指令会首先从给定内存地址处读出当前的数据值；ADD 指令则会根据用户传入的立即数参数，来计算出更新后的数据值；最后，STORE 指令会将这个结果数据值更新到对应的内存中。同之前多条机器指令的实现类似，这些微指令在操作系统的线程调度下，也可能存在着交替执行的过程，因此也有着产生数据竞争的风险。</p><h2>竞态条件</h2><p>竞态条件（Race Condition）是指由于程序中某些事件的发生时机与顺序不一致，从而影响程序运行正确性的一种缺陷。在某些情况下，数据竞争的存在可能会导致竞态条件的出现，但两者的出现实际上并没有太多联系（有部分人认为数据竞争是竞态条件的一种，但也有人持反对意见）。</p><p>不同于数据竞争的是，对程序中竞态条件的判断可能是非常困难的。竞态条件并没有可以精确到具体操作和行为上的定义，因此，它是否产生完全取决于程序的具体设计，以及是否存在可能影响程序运行的外部非确定性变化。</p><p>比如，我们来看下面这段仅含有竞态条件，但并没有数据竞争的示例代码：</p><pre><code class=\"language-c++\">#include &lt;threads.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdatomic.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;time.h&gt;\n#define THREAD_COUNT 10\natomic_int accountA = 100000000;&nbsp; // 转出账户初始金额；\natomic_int accountB = 0;&nbsp; // 转入账户初始金额；\nint run(void* v) {\n&nbsp; int _amount = *((int*) v);&nbsp; // 获得当前线程的转移金额；\n&nbsp; for(;;) {\n&nbsp; &nbsp; // 首先判断转出账户金额是否足够，不够则直接退出；\n&nbsp; &nbsp; if (accountA &lt; _amount) return thrd_error;&nbsp;&nbsp;\n&nbsp; &nbsp; atomic_fetch_add(&amp;accountB, _amount);&nbsp; // 将金额累加到转入账户；\n&nbsp; &nbsp; atomic_fetch_sub(&amp;accountA, _amount);&nbsp; // 将金额从转出账户中扣除；\n&nbsp; }\n}\nint main(void) {\n#if !defined(__STDC_NO_THREADS__) &amp;&amp; !defined(__STDC_NO_ATOMICS__)\n&nbsp; thrd_t threads[THREAD_COUNT];&nbsp;&nbsp;\n&nbsp; srand(time(NULL));\n&nbsp; for (int i = 0; i &lt; THREAD_COUNT; i++) {\n&nbsp; &nbsp; int amount = rand() % 50;&nbsp; // 为每一个线程生成一个随机转移金额；\n&nbsp; &nbsp; thrd_create(&amp;threads[i], run, &amp;amount);\n&nbsp; }\n&nbsp; for (int i = 0; i &lt; THREAD_COUNT; i++)\n&nbsp; &nbsp; thrd_join(threads[i], NULL);\n&nbsp; printf(\"A: %d\\nB: %d\", accountA, accountB);\n#endif\n&nbsp; return 0;&nbsp;\n}&nbsp;\n</code></pre><p>在这段代码中，我们以简化的方式实现了一个基本的金融场景，即账户 A 向账户 B 进行多次转账，且每次转账的金额都并不固定。在 main 函数的第 22~25 行，我们通过创建多个线程的方式来模拟两个账户之间分批、多次的财产转移过程。其中，每个线程会使用不同的固定份额来进行转账过程，而随机数 amount 便表示了这个额度。</p><p>线程开始运行后，在代码第 10 行的 run 函数内，我们通过一个线程本地变量 _amount 来存放传入的、当前线程需要使用的固定份额。接下来，在一个无限循环中，线程会通过以下三个步骤，来完成两个账户之间的转账过程：</p><ol>\n<li>判断账户 A 的剩余资金是否足够进行转账。若否，则直接退出；</li>\n<li>将转账的金额累加到账户 B 中；</li>\n<li>将转账的金额从账户 A 中扣除。</li>\n</ol><p>而当所有线程都退出时，则表示当前账户 A 中的剩余金额，无法再满足任何一个线程以它的固定金额为单位进行转账。最后，通过 printf 函数，我们将两个账户内的剩余资金打印了出来。按照我们对程序的理解，此时，两个账户中的金额应该都大于 0，且两者之和为 1 亿。</p><p>可以看到，程序的整个执行流程十分简单。不仅如此，我们还使用了原子操作，来保证程序对账户变量 accountA 与 accountB 的修改过程是不会产生数据竞争的。有关原子操作的更多内容，我会在下一讲中为你介绍，这里你可以先对它的用法有一个基本了解。</p><p>到这里，程序的逻辑看起来没有任何问题。但当我们真正运行它时，却可能会得到如下所示的输出结果：</p><pre><code class=\"language-c++\">A: -46\nB: 100000046\n</code></pre><p>可以看到，账户 A 的剩余金额变为了负数，程序运行出现了异常。如果仔细分析上述代码的执行逻辑，你会发现多个线程在对账户变量进行修改时，虽然没有数据竞争，但程序的不恰当设计导致其存在着竞态条件。</p><p>当多个线程在同时执行 run 函数内的逻辑时，操作系统中的任务调度器可能会在任意时刻暂停某个线程的执行，转而去运行另一个线程。因此，便可能出现这样一种情况：某个线程以原子形式，执行了代码的第 14 行语句，将金额累加到账户 A。而此时，调度器将执行流程转移给另一个线程。该线程在上一个线程还没有完成对账户 B 的扣减操作前，便直接使用未同步的值参与了下一次的转账操作。</p><p>因此，在这种情况下，程序的正确性实际上依赖于各个线程之间，按照一定顺序的执行过程。那么，应该如何修复这个程序呢？学完下一讲后，你就可以结合这两讲的知识，尝试解决这个问题了。</p><p>最后，我们再来看另一个与并发编程密切相关的话题，指令重排。</p><h2>指令重排</h2><p>现代编译器和处理器通常会采用名为“指令重排”（乱序执行的一种）的技术来进一步提升程序的运行效率。这种技术会在尽量不影响程序可观测执行结果的情况下，对生成的机器指令，或它们的实际执行顺序进行适当的重新排序。对于编译器来说，其表象是源代码中语句的出现顺序，与对应汇编代码的实现顺序不一致。而对于处理器来说，则是<strong>程序在真正执行时产生副作用的顺序（比如变量赋值），与汇编代码中指令的出现顺序不一致</strong>。</p><p>对多线程应用来说，即使编译器可以从静态分析的视角，来确保汇编指令的重排不影响程序的可观测执行结果，但当多个线程被调度到不同的物理 CPU 上执行时，不同 CPU 之间一般无法共享对应线程指令在执行时的重排信息。因此，当线程之间存在数据依赖关系时，程序的运行时正确性可能会受到影响。比如，我们来看下面这个例子：</p><pre><code class=\"language-c++\">#include &lt;threads.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdatomic.h&gt;\n#if !defined(__STDC_NO_ATOMICS__)\natomic_int x = 0, y = 0;\n#endif\nint run(void* v) {\n&nbsp; x = 10;\n&nbsp; y = 20;  // ！变量 y 的值可能被优先更新！\n}\nint observe(void* v) {\n&nbsp; while(y != 20) ;&nbsp; // 忙等待；\n&nbsp; printf(\"%d\", x);  // 只在 x 被更新后打印；\n}\nint main(void) {\n#if !defined(__STDC_NO_THREADS__)\n&nbsp; thrd_t threadA, threadB;&nbsp;&nbsp;\n&nbsp; thrd_create(&amp;threadA, run, NULL);\n&nbsp; thrd_create(&amp;threadB, observe, NULL);\n&nbsp; thrd_join(threadA, NULL);\n&nbsp; thrd_join(threadB, NULL);\n#endif\n&nbsp; return 0;&nbsp;\n}\n</code></pre><p>在这段代码中，我们在 main 函数内生成了两个线程，分别对应于函数 run 和 observe。其中，observe 线程在执行时会通过“忙等待”的方式，不断查询变量 y 的状态，并在发现其值变更为 20 后，再继续执行接下来的 printf 函数。而 run 线程在执行时，仅会简单地将变量 x 更新为值 10，然后再将变量 y 的值更新为 20。这是我们通过查看上述 C 代码得出的结论。</p><p>但由于指令重排的存在，run 函数在程序实际执行时，其内部对变量 x 与 y 的值变更过程，可能与我们在 C 代码中观察到的顺序并不一致。在某些情况下，变量 y 的值可能会被优先更新。而如果此时 observe 线程被重新调度，则 printf 语句便会打印出并非我们所期望的值。</p><p>为此，C 语言为我们提供了相应的被称为“内存顺序（Memory Order）”的一系列枚举值。通过配合特定的库函数一起使用，我们能够明确规定编译器及处理器应该如何对某段代码的指令重排进行约束。下一讲，在“使用原子操作”小节中，我们还会回顾上面的这个例子。</p><h2>总结</h2><p>好了，讲到这里，今天的内容也就基本结束了。最后我来给你总结一下。</p><p>这一讲，我主要介绍了与 C 并发编程有关的一些基本概念。当然，这些概念本身都较为通用，它们也可以应用在其他编程语言的环境中。</p><p>我们首先对比了进程与线程两者之间的不同。其中，进程主要划分了运行程序所享有的资源边界；而线程则在共享进程资源的情况下，独立负责不同子任务的执行流程。通过使用多线程，程序可以利用多核 CPU 的计算资源，做到真正的任务并行。</p><p>接下来，我介绍了如何在 C 代码中创建线程。C 标准将与线程控制相关的接口整合在了名为 threads.h 的头文件中。借助 thrd_create、thrd_join 等函数，我们可以实现对线程的创建、等待、阻塞、分离等一系列操作。</p><p>最后，多线程应用的正确执行离不开我们对程序的合理设计。我还讲解了由数据竞争、静态条件，以及指令重排等因素引起的潜在问题。掌握了这些知识，再合理使用我将在下一讲中介绍的其他 C11 并发编程特性，你就能在一定程度上解决和避免这些问题。</p><h2>思考题</h2><p>什么类型的应用更适合使用多线程技术来提升其运行时性能？你可以先试着查找资料，并在评论区分享你的思考。</p><p>今天的课程到这里就结束了，希望可以帮助到你，也希望你在下方的留言区和我一起讨论。同时，欢迎你把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"12｜标准库：非本地跳转与可变参数是怎样实现的？","id":475867},"right":{"article_title":"14｜标准库：如何使用互斥量等技术协调线程运行？","id":478213}}},{"article_id":478213,"article_title":"14｜标准库：如何使用互斥量等技术协调线程运行？","article_content":"<p>你好，我是于航。</p><p>在上一讲中，我主要介绍了有关并发编程的一些基础知识，并通过一个简单的例子展示了如何在 C 语言中进行线程创建等基本操作。同时我也向你介绍了，数据竞争、竞态条件，以及指令重排等因素，都在如何影响着多线程应用的执行正确性。那么，有哪些方法可以辅助我们解决这些问题呢？</p><p>今天我们就来看看 C 语言为并发编程提供的几大利器：互斥量、原子操作、条件变量，以及线程本地变量。</p><h2>使用互斥量</h2><p>从本质上来看，互斥量（Mutex）其实就是一把锁。一个线程在访问某个共享资源前，需要先对互斥量进行加锁操作。此时，其他任何想要再对互斥量进行加锁的线程都会被阻塞，直至当前线程释放该锁。而当锁被释放后，所有之前被阻塞的线程都开始继续运行，并再次重复之前的步骤，开始“争夺”可以对互斥量进行加锁的名额。通过这种方式，我们便可以保证每次在对多线程共享的资源进行操作时，都仅只有一个线程。</p><p>在 C 语言中，我们可以通过头文件 threads.h 提供的，以 “mtx_” 为前缀的相关接口来使用互斥量的能力。你应该还记得我在<a href=\"https://time.geekbang.org/column/article/477358\">上一讲</a>中提到的，那段存在数据竞争的 C 示例代码。这里我对它进行了改写，如下所示：</p><pre><code class=\"language-c++\">#include &lt;threads.h&gt;\n#include &lt;stdio.h&gt;\n#define THREAD_COUNT 10\n#define THREAD_LOOP 100000000\nmtx_t mutex;\nlong counter = 0;\nint run(void* data) {\n&nbsp; for (int i = 0; i &lt; THREAD_LOOP; i++) {\n&nbsp; &nbsp; mtx_lock(&amp;mutex);  // 对互斥量加锁，\n&nbsp; &nbsp; counter++;\n&nbsp; &nbsp; mtx_unlock(&amp;mutex);  // 释放一个互斥量；\n&nbsp; }\n&nbsp; printf(\"Thread %d terminates.\\n\", *((int*) data));\n&nbsp; return thrd_success;\n}\nint main(void) {\n#ifndef __STDC_NO_THREADS__\n&nbsp; int ids[THREAD_COUNT];\n&nbsp; mtx_init(&amp;mutex, mtx_plain);  // 创建一个简单、非递归的互斥量对象；\n&nbsp; thrd_t threads[THREAD_COUNT];\n&nbsp; for (int i = 0; i &lt; THREAD_COUNT; i++) {\n&nbsp; &nbsp; ids[i] = i + 1;\n&nbsp; &nbsp; thrd_create(&amp;threads[i], run, ids + i);&nbsp;\n&nbsp; }\n&nbsp; for (int i = 0; i &lt; THREAD_COUNT; i++)\n&nbsp; &nbsp; thrd_join(threads[i], NULL);\n&nbsp; printf(\"Counter value is: %ld.\\n\", counter);\n&nbsp; mtx_destroy(&amp;mutex);  // 销毁一个互斥量对象；\n#endif\n&nbsp; return 0;&nbsp;\n}\n</code></pre><!-- [[[read_end]]] --><p>可以看到，在代码的第 19 行，我们使用 mtx_init 函数创建了一个基本类型（mtx_plain）的互斥量对象（下文中简称互斥量）。紧接着，在 run 函数内部，对变量 counter 进行值累加操作前，我们需要通过 mtx_lock 函数，来对之前创建的互斥量进行加锁操作。同样地，当进程使用完共享变量后，还需要通过 mtx_unlock 函数对互斥量进行解锁，来让其他线程有机会继续对共享变量进行处理。最后，在代码的第 28 行，程序退出前，我们销毁了之前创建的互斥量。</p><p>总的来看，<strong>在 C 语言中，互斥量可以被分为三种类型</strong><strong>：</strong><strong>mtx_plain、mtx_recursive 与 mtx_timed</strong>。</p><p>其中，mtx_plain 为最简单类型的互斥量，我们可以对它进行基本的加锁和解锁，但不能将其用在需要“重复加锁”的场景（比如函数的递归调用）中。这是因为，即使当前线程拥有该锁，对同一个 mtx_plain 互斥量的再次加锁也会导致该线程被阻塞。而此时，便会产生死锁的问题，即当前线程等待自己解锁后才能够再次进行加锁，而想要解锁，则需要让线程先加锁以完成当前功能的执行。</p><p>相反，mtx_recursive 类型的互斥量也被称为“可重入互斥量（Reentrant Mutex）”，顾名思义，它可以被用在需要重复加锁的场景中。该类型互斥量可以被同一个线程重复锁定多次，而不会阻塞线程。但相应地，对它的完全解锁也需要执行对应多次的 mtx_unlock。</p><p>而最后一种是 mtx_timed 类型的互斥量，它具有特殊的“超时属性”。这意味着，通过配合使用 mtx_timedlock 函数，我们可以实现“带超时限制的互斥量加锁”，即线程在尝试给对应互斥量加锁时，只会以阻塞的方式等待一定时间。若超过给定时间后仍未给互斥量成功上锁，则线程继续执行。</p><p>除了上面提到过的函数，C 标准库还提供了另外两个与“互斥”有关的函数。这里，我将它们整理在了下面的表格中，供你参考。</p><p><img src=\"https://static001.geekbang.org/resource/image/78/17/78714c4df8217a2fc56b750301722817.jpg?wh=1920x536\" alt=\"图片\"></p><p>利用互斥锁能够帮助我们解决数据竞争问题，但在某些对性能要求更加严苛的场景下，它可能并非最好的选择。接下来，让我们来看看另一种可以避免数据竞争的方式，原子操作。</p><h2>使用原子操作</h2><p>原子是化学反应中不可被继续分割的基本微粒，那么顾名思义，“原子操作”的意思就是操作本身无法再被划分为更细的步骤。当我们在多个不同线程中对共享资源进行原子操作时，编译器和 CPU 将会保证这些操作的正确执行，即同一时刻只会有一个线程在进行这些操作。而只有在该线程将整个操作全部执行完毕后，其他线程才可以继续执行同样的操作。</p><p>类似地，通过 C11 提供的名为 stdatomic.h 的头文件，我们可以方便地使用这些原子操作能力。比如，在下面这段代码中，我们便通过这种方式，解决了<a href=\"https://time.geekbang.org/column/article/477358\">上一讲</a>中那个实例的数据竞争问题。</p><pre><code class=\"language-c++\">#include &lt;threads.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdatomic.h&gt;\n#define THREAD_COUNT 10\n#define THREAD_LOOP 100000000\n#if !defined(__STDC_NO_ATOMICS__)\n_Atomic long counter = 0;&nbsp; // 定义一个原子类型全局变量，用来记录线程的累加值；\n#endif\nint run(void* data) {\n&nbsp; for (int i = 0; i &lt; THREAD_LOOP; i++)\n&nbsp; &nbsp; atomic_fetch_add_explicit(&amp;counter, 1, memory_order_relaxed);  // 使用原子加法操作；\n&nbsp; printf(\"Thread %d terminates.\\n\", *((int*) data));\n&nbsp; return thrd_success;\n}\nint main(void) {\n#if !defined(__STDC_NO_THREADS__) || !defined(__STDC_NO_ATOMICS__)\n&nbsp; int ids[THREAD_COUNT];\n&nbsp; thrd_t threads[THREAD_COUNT];&nbsp;&nbsp;\n&nbsp; for (int i = 0; i &lt; THREAD_COUNT; i++) {\n&nbsp; &nbsp; ids[i] = i + 1;\n&nbsp; &nbsp; thrd_create(&amp;threads[i], run, ids + i);\n&nbsp; }\n&nbsp; for (int i = 0; i &lt; THREAD_COUNT; i++)\n&nbsp; &nbsp; thrd_join(threads[i], NULL);\n&nbsp; printf(\"Counter value is: %ld.\\n\", counter);\n#endif\n&nbsp; return 0;&nbsp;\n}\n</code></pre><p>与使用线程控制相关接口类似，我们也需要通过名为 <strong>STDC_NO_ATOMICS</strong> 的宏，来判断编译器是否对原子操作提供支持。可以看到，我们分别在代码的第 6 行与第 16 行进行了相应的预处理判断。</p><p>接下来，在代码的第 7 行，我们使用 C11 新引入的 <code>_Atomic</code> 关键字，修饰了原有的全局变量 counter，以将它定义为一个原子类型（这里也可以直接使用 C 标准库为我们封装好的宏 atomic_long）。</p><p>紧接着，在 run 函数内部，代码的第 11 行，我们使用名为 atomic_fetch_add_explicit 的函数来完成对 counter 变量的累加过程。该函数为我们提供了一种原子累加操作，可以使线程在进行数据累加时独占整个变量。除此之外，你还需要注意：通过该函数的第三个参数，我们还可以指定当前操作需要满足的内存顺序。</p><p>在上一讲中我提到，由于编译器和处理器可能会采用指令重排来优化程序的运行效率，因此，当在多核 CPU 上运行存在线程间数据依赖的多线程应用时，程序的正确性可能会出现问题。那么，怎样解决这个问题呢？我们来看下面这段代码。这里，我通过指定各个原子操作的具体内存顺序，修复了上一讲最后一小节中提到的例子。</p><pre><code class=\"language-c++\">#include &lt;threads.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdatomic.h&gt;\n#if !defined(__STDC_NO_ATOMICS__)\natomic_int x = 0, y = 0;\n#endif\nint run(void* v) {\n&nbsp; atomic_store_explicit(&amp;x, 10, memory_order_relaxed);\n&nbsp; atomic_store_explicit(&amp;y, 20, memory_order_release);\n}\nint observe(void* v) {\n&nbsp; while(atomic_load_explicit(&amp;y, memory_order_acquire) != 20);\n&nbsp; printf(\"%d\", atomic_load_explicit(&amp;x, memory_order_relaxed));\n}\nint main(void) {\n#if !defined(__STDC_NO_THREADS__) || !defined(__STDC_NO_ATOMICS__)\n&nbsp; thrd_t threadA, threadB;&nbsp;&nbsp;\n&nbsp; thrd_create(&amp;threadA, run, NULL);\n&nbsp; thrd_create(&amp;threadB, observe, NULL);\n&nbsp; thrd_join(threadA, NULL);\n&nbsp; thrd_join(threadB, NULL);\n#endif\n&nbsp; return 0;&nbsp;\n}\n</code></pre><p>可以看到，我们修改了线程 run 和 observe 中对原子类型变量 x 和 y 的读写操作。其中，函数 atomic_load_explicit 用来读取某个原子类型变量的值；而对它们的修改，则使用函数 atomic_store_explicit 进行。除此之外，这两个函数都支持通过它们的最后一个参数，来指定相应操作需要遵循的内存顺序。</p><p>在这段修改后的代码中，一共使用到了三种不同的内存顺序（对应三个枚举值）。首先，我们来看看它们的具体定义。为了方便你观察，我将这些信息整理在了下面的表格中。</p><p><img src=\"https://static001.geekbang.org/resource/image/37/3c/377071e6c666ddc088d3ea27f255793c.jpg?wh=1920x689\" alt=\"图片\"></p><p>相信看过这三种内存顺序的定义后，你已经对它们的作用有个大致了解了。其中，对于使用了 memory_order_relaxed 的操作，我们并不需要对它们的执行顺序做任何保证。相反，编译器和处理器可以按照需求进行适当的优化。</p><p>而在 run 线程中，为了保证对变量 x 的修改过程一定发生在变量 y 的值被修改前，我们便需要使用 memory_order_release 来限制对变量 y 的修改，一定要在之前的所有修改都完成后再进行。同样地，对于 observe 线程来说，为了防止处理器提前将变量 x 的值放入缓存，这里，我们也需要通过 memory_order_acquire，来保证对变量 y 进行的读操作一定会比对变量 x 的读操作先发生。你可以通过下面这张图片，直观地理解上面我们提到的各个操作之间的执行关系。</p><p><img src=\"https://static001.geekbang.org/resource/image/62/71/6249a06dd718c52159bd57a423005871.jpg?wh=2248x1467\" alt=\"\"></p><p>除了我们在上面的例子中用到的三种内存顺序外，C 语言还提供了另外 3 种不同的内存顺序，供我们在不同的场景中使用。如果想了解关于它们的更多信息，你可以参考<a href=\"https://en.cppreference.com/w/c/atomic/memory_order\">这个链接</a>。</p><p>总的来看，C11 通过 stdatomic.h 头文件为我们提供了大量可用于原子操作的相关类型、宏，以及函数。相较于使用互斥量，原子操作可以让我们更加清晰和方便地抽象并行代码，而不需要频繁进行加锁与释放锁的操作。</p><p>不仅如此，从执行性能角度，原子操作的执行通常直接依赖于 CPU 提供的相应的原子机器指令，比如在 x86-64 平台上，atomic_fetch_add_explicit 函数对应的 <code>lock add</code> 指令。而使用互斥量则需要让线程阻塞，还要频繁进行上下文切换，因此与之相比，原子操作的性能通常会更好。</p><p>这里，我将一些与原子操作相关的常用标准库函数整理在了下面的表格中，供你参考。你也可以点击<a href=\"https://en.cppreference.com/w/c/atomic\">这个链接</a>，查看更多信息。</p><p><img src=\"https://static001.geekbang.org/resource/image/01/7a/0162c8f6488551746c1364f39994f47a.jpg?wh=1920x1182\" alt=\"图片\"></p><h2>使用条件变量</h2><p>条件变量是一种常用的线程同步机制。通过上一小节的例子，你会发现，在多线程应用中，存在着一种十分常见的线程间同步模式，即某个线程的执行依赖于另一个线程对数据首先进行的预处理。在上面的例子中，observe 线程中某段逻辑的执行需要等待 run 线程将原子变量 y 的值变为 20。这里，我们通过“忙等待（Busy Waiting）”的方式实现了这个效果。</p><p>用忙等待虽然可以达到我们的预期，但这是一种十分“昂贵”的方式，甚至会被认为是一种反模式，应该避免使用。这是因为，忙等待需要让线程反复检查某个条件是否为真，因此，需要浪费大量宝贵的 CPU 资源在无用的活动上。那么，有没有更好的办法，既可以尽量减少处理器资源的浪费，又能够解决线程间数据依赖的问题呢？答案是有的，这个方法就是使用条件变量。</p><p>来看下面这个例子：</p><pre><code class=\"language-c++\">#include &lt;threads.h&gt;\n#include &lt;stdio.h&gt;\nmtx_t mutex;\ncnd_t cond;  // 定义一个条件变量；\nint done = 0;\nint run(void* data) {\n&nbsp; mtx_lock(&amp;mutex);&nbsp;\n&nbsp; done = 1;\n&nbsp; cnd_signal(&amp;cond);  // 通知等待中的线程；\n&nbsp; mtx_unlock(&amp;mutex);&nbsp;\n&nbsp; return thrd_success;\n}\nint main(void) {\n#ifndef __STDC_NO_THREADS__\n&nbsp; mtx_init(&amp;mutex, mtx_plain);&nbsp;\n&nbsp; cnd_init(&amp;cond);  // 初始化条件变量；\n&nbsp; thrd_t thread;&nbsp;&nbsp;\n&nbsp; thrd_create(&amp;thread, run, NULL);\n&nbsp; mtx_lock(&amp;mutex);&nbsp;\n&nbsp; while (done == 0) {\n&nbsp; &nbsp; cnd_wait(&amp;cond, &amp;mutex);  // 让当前线程进入等待队列；\n&nbsp; }\n&nbsp; mtx_unlock(&amp;mutex);&nbsp;\n&nbsp; printf(\"The value of done is: %d\", done);\n  mtx_destroy(&amp;mutex);\n  cnd_destroy(&amp;cond);  // 销毁条件变量；\n#endif\n&nbsp; return 0;&nbsp;\n}\n</code></pre><p>这段代码的基本逻辑与上一小节的例子类似。从第 23 行开始的代码，执行前需要等待 run 线程首先将全局变量 done 的值修改为 1。代码的第 15~16 行，我们初始化了需要使用的互斥量对象与条件变量对象。在 main 线程对应代码的第 19~23 行，我们使用了与条件变量相关的函数 cnd_wait。该函数在被调用时，需要当前线程获得一个互斥锁，并将其作为实参传递给它，函数调用后锁会被释放。同时，所有执行到此处的线程都将被阻塞。</p><p>接下来，让我们把目光移到 run 线程。</p><p>在 run 线程代码的第 8 行，我们将变量 done 的值修改为 1。紧接着，通过调用函数 cnd_signal，run 线程得以“通知”所有之前被阻塞在函数 cnd_wait 处的线程，来让它们中的一个可以继续运行。当然，在这个例子中，我们只有 main 函数对应的一个线程。此时，互斥量将被重新上锁，main 线程将继续执行接下来的指令。在代码的第 24~26 行，它打印出了全局变量 done 的值，并销毁了互斥量与条件变量对象。最后，程序执行完毕。</p><p>可以看到，实际上，<strong>条件变量为我<strong><strong>们</strong></strong>提供了一种线程间的“通知”能力</strong>。某个线程可以在完成了某件事情后，通知并唤醒等待线程，让其继续工作，完成接下来的任务。而在这个过程中，我们不需要通过忙等待的方式，让线程频繁查询标志量。因此，CPU 资源得到了更好的利用。</p><p>这里，我向你提一个小问题：为什么我们在代码的第 20 行使用 <code>while</code> 语句，而不是 <code>if</code> 语句呢？欢迎在评论区告诉我你的答案。</p><p>在并发编程中，条件变量是一个十分强大的武器。通过它，我们可以进一步实现监视器（Monitor）、管程等工具和同步原语。而且，它也可以很好地解决经典的生产者-消费者问题。如果你对这部分内容感兴趣，可以参考《C++ Concurrency in Action》和《现代操作系统》等书，来进行更加深入的学习。虽然它们并不会专门介绍基于 C 语言的并发编程，但其中的很多概念，甚至 C++ 接口，与 C 语言都是类似和相通的。</p><p>除了上述代码中用到的条件变量方法外，C 标准库还提供了另外两个常用函数。我将它们整理在了下面的表格中，供你参考。</p><p><img src=\"https://static001.geekbang.org/resource/image/b8/d9/b86fe8de3106d0430523ea29833d02d9.jpg?wh=1920x666\" alt=\"图片\"></p><p>最后，让我们再回过头来，看看与线程直接相关的另一个内容，线程本地变量。</p><h2>使用线程本地变量</h2><p>除了可以共享存在于进程内的全局变量外，线程还可以拥有属于它自己的线程本地变量（TLS）。</p><p>顾名思义，线程本地变量的值仅能够在某个具体线程的生存期内可用。变量的实际存储空间会在线程开始时分配，线程结束时回收。线程不会对这些变量的读写操作产生数据竞争。我们来看一个例子：</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\n#include &lt;threads.h&gt;\n#include &lt;stdatomic.h&gt;\n#define THREAD_COUNT 10\n#define THREAD_LOOP 10000\n_Thread_local int counter = 0;&nbsp; // 定义线程本地变量；\nint run(void *data) {\n&nbsp; for (int i = 0; i &lt; THREAD_LOOP; ++i)\n&nbsp; &nbsp; counter += 1;&nbsp; // 更新当前线程所属的 counter 变量值；\n&nbsp; return counter;\n}\nint main(int argc, char const *argv[]) {\n&nbsp; thrd_t threads[THREAD_COUNT];\n&nbsp; int sum = 0, result = 0;\n&nbsp; for (int i = 0; i &lt; THREAD_COUNT; ++i)\n&nbsp; &nbsp; thrd_create(&amp;threads[i], run, NULL);\n&nbsp; for (int i = 0; i &lt; THREAD_COUNT; ++i) {\n&nbsp; &nbsp; thrd_join(threads[i], &amp;result);\n&nbsp; &nbsp; sum += result;&nbsp; // 累加每个线程的计算值；\n&nbsp; }\n&nbsp; printf(\"The value of count is %d.\\n\", sum);\n&nbsp; return 0;\n}\n</code></pre><p>可以看到，这段代码的逻辑十分简单：我们创建了 10 个（对应 THREAD_COUNT）线程，让它们同时对全局变量 counter 进行累加，并持续 10000 次（对应 THREAD_LOOP）。然后，在 main 线程的最后，我们将累加后的值打印了出来。</p><p>看到这里，相信你的第一感觉肯定是：应该通过互斥锁或原子操作等方式，来防止多个线程在对 counter 变量进行修改时产生数据竞争。但在这里，我却没有这样做，而是采用了一种更加便捷的方式。这一切，都要得益于线程本地变量的存在。</p><p>在代码的第 6 行，我们使用 <code>_Thread_local</code> 关键字（也可以使用宏 thread_local），将全局变量 counter 标记为线程本地变量。这意味着，每个线程都会在创建时生成仅属于当前线程的变量 counter。因此，当本线程在对 counter 变量进行累加时，便不会受到其他线程的影响。而当线程退出时，通过代码第 18 行的 thrd_join，我们得以在 main 线程中将每个结束线程返回的，各自的 counter 值再进行统一累加，从而得到最后的计算结果。你可以通过下图来直观地理解这个过程。</p><p><img src=\"https://static001.geekbang.org/resource/image/1e/de/1e4ba90a95a72yyd1a458a50299b6cde.jpg?wh=2248x1764\" alt=\"\"></p><p>总之，线程本地变量为我们提供了另一种可以避免数据竞争的方式。除此之外，它也可以被用来存储线程独有的一些信息，比如 errno 的值。</p><p>我们在上面代码中使用的是<strong>以关键字来定义线程本地变量的方式</strong>，除此之外，标准库还提供了一系列的函数，可以实现同样的目的。但不同之处在于，通过 tss_create 等函数来创建线程本地变量时，还可以为其指定对应的析构函数。这样，当线程退出时，便可以确保相应的线程本地资源（比如堆内存）能够以正确的方式被清理。这里，我将相关的函数列在了下面的表格中，供你参考。你也可以点击<a href=\"https://en.cppreference.com/w/c/atomic\">这个链接</a>查看更多信息。</p><p><img src=\"https://static001.geekbang.org/resource/image/00/ec/00980e87a07d7e1f63f4yyc010033eec.jpg?wh=1920x653\" alt=\"图片\"></p><h2>总结</h2><p>好了，讲到这里，今天的内容也就基本结束了。最后我来给你总结一下。</p><p>在本讲中，我主要介绍了有关互斥量、原子操作、条件变量，以及线程本地变量的相关内容。合理地使用这些方式，我们就可以避免多线程应用经常会遇到的，由于数据竞争、竞态条件，以及指令重排引起的问题。</p><p>其中，互斥量让我们可以通过对它进行<strong>加锁与解锁</strong>的方式，来限制多个线程的执行，以让它们有序地使用共享资源。在 C 语言中，互斥量被分为三种类型，mtx_plain 为最基本类型，mtx_recursive 可以被用在需要重复加锁的场景中，而 mtx_timed 则使得互斥量具有了超时属性。通过与 mtx_timedlock 结合使用，它可以让线程在给互斥量加锁时，只尝试有限的一段时间。</p><p>原子操作是一种更便捷的可以用来避免数据竞争的方式。通过使用 <code>_Atomic</code> 关键字，我们可以将变量定义为原子类型。而当线程访问该类型变量时，便可<strong>按照“不可分割”的形式，一次性完成整个操作</strong>。不仅如此，在进行原子操作时，还可以同时指定操作需要满足的内存顺序。原子操作的实现通常依赖于所在平台的特殊机器指令，而 C 标准库则通过直接提供常用同步原语的方式，帮我们屏蔽了这些细节。</p><p><strong>条件变量提供了线程间的通知能力。</strong>它可以让线程在完成某件事情后，通知需要进行后续处理的等待线程，从而让具有数据依赖关系的线程以一种更加高效的方式进行同步。除此之外，条件变量还可被用于实现监视器、管程等更多复杂的同步机制。</p><p>最后，线程本地变量也是一种可用于解决数据竞争的常用方式。具体的操作是在 C 代码中，为全局变量添加 <code>_Thread_local</code> 关键字。<strong>这样，就会仅在线程创建时，才生成仅属于当前线程的本地同名变量。</strong> 因此，当前线程对该变量的修改便不会被其他线程影响。</p><h2>思考题</h2><p>x86-64 指令集中的 mfence、lfence 与 sfence 指令，它们具体有什么作用呢？试着查找资料了解一下，并在评论区分享你的发现。</p><p>今天的课程到这里就结束了，希望可以帮助到你，也希望你在下方的留言区和我一起讨论。同时，欢迎你把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"13｜标准库：你需要了解的 C 并发编程基础知识有哪些？","id":477358},"right":{"article_title":"15｜标准库：信号与操作系统软中断有什么关系？","id":479176}}},{"article_id":479176,"article_title":"15｜标准库：信号与操作系统软中断有什么关系？","article_content":"<p>你好，我是于航。</p><p>相信你在第一次学习编程时，也写出过与下面这段类似的代码：</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\nint main(void) {\n&nbsp; int x = 10;\n&nbsp; int y = 0;\n&nbsp; printf(\"%d\", x / y);\n  return 0;\n}\n</code></pre><p>可以很明显地看到，这里在代码中，我们通过 printf 函数打印出了除法表达式 <code>x / y</code> 的计算结果。但定睛一看，你就会发现：在这个表达式中，除数变量 y 对应的值为 0。因此，程序在运行时便会发生“除零异常”。</p><p>当然，你可能会说，这只是我们故意构造的一段带有问题的程序。但在真实场景中，四则运算作为最基本的数学运算，被广泛应用在各类大型 C 项目中。而当参与运算的具体操作数可以被来自于用户的输入影响，且程序实现并没有进行完备的边界条件检查时，类似的运行时异常难免会发生。</p><p>除此之外，程序在运行过程中，都会直接或间接地与操作系统，甚至底层硬件进行交互。因此，你可能会遇到下面这几种情况：</p><ul>\n<li>程序运行时，由于访问了非法的内存资源，导致出现 “Segmentation Fault” 等异常；</li>\n<li>用户想要结束程序，急切地按下了 Ctrl+C / Command+C 键；</li>\n<li>计算机底层硬件系统出现故障，导致无法实现某项特定功能；</li>\n<li>……</li>\n</ul><p>在这些情况下，应用程序应该如何响应？其实，我上面提到的所有问题，都可以通过“信号（Signal）”来解决。今天我们就来看看什么是信号，以及如何在 C 代码中通过标准库提供的相关接口与信号进行交互。</p><!-- [[[read_end]]] --><h2>什么是信号？</h2><p>从广义上来讲，信号实际上是操作系统提供的一种可以用来传递特定消息的机制。通过这种方式，操作系统可以将程序运行过程中发生的各类特殊情况转发给程序，并按照其指定的逻辑进行处理。每一种具体的信号都有它对应的名称，这些名称以 “SIG” 作为前缀。比如，当程序访问非法内存时，便会产生名为 SIGSEGV 的信号。而除零异常则对应着名为 SIGFPE 的信号。</p><p>信号的产生是一个随机的过程。毕竟，异常的出现并不是人们预期中会发生的事情。而这也就意味着，程序无法通过简单轮询某个全局变量值的方式，来检测信号是否出现，然后再进行相应处理。相对地，程序需要提前“告诉”操作系统：当某个信号到来时，应该按怎样的既定方式进行处理。而这，就是典型的<strong>异步事件处理方式</strong>。</p><p>如果我们再进一步，深入到操作系统内核，你会发现信号其实是一种“软中断”。</p><h2>信号与软件中断</h2><p>在计算机中，中断是指 CPU 需要临时暂停当前正在进行的活动，保存相应状态，然后转而去执行某个具体的中断服务程序（后面我将其简称为 ISR），以响应外部环境变化的过程。而在 ISR 执行完毕后，在大多数情况下，CPU 将继续执行之前暂停的任务。</p><p>通常来说，中断的触发分为两种形式，即硬件中断与软件中断（也被简称为硬中断与软中断）。其中，硬件中断是指<strong>与计算机硬件特定状态相关的中断过程</strong>，该过程直接由硬件触发。比如，当磁盘完成了某次由用户程序指定的 IO 操作后，便会通过硬件中断的方式来通知 CPU 这一消息，并让 CPU 进行后续的处理。在这个过程中，便存在着 CPU 执行流程从应用程序的某行机器指令，到磁盘中断处理程序代码的转移。</p><p>相对地，软件中断则是指由计算机软件，通过 <code>int</code> 等机器指令引起的 <strong>CPU 执行流程的临时转移过程</strong>。而我在这门课中多次提到过的“系统调用”便是其中的一种。在早期的 i386 架构中，用户程序需要通过指令 <code>int 0x80</code> 才能够借由软件中断从用户态进入到内核态，并使用内核提供的系统调用函数。同样地，在这个过程中也存在着 CPU 从用户代码到内核代码的执行流程转移。</p><p>回过头我们再来看看，为什么说信号也是一种软中断呢？其实很好理解。当特定事件（比如“除零”这个操作）发生时，操作系统会将对应的信号值（即对应的 SIGFPE）发送给相关程序。而通常情况下，如果应用程序并未设置自定义的信号处理程序，则操作系统将会执行默认信号处理程序中的逻辑。对于大多数信号来说，这个逻辑便是直接终止当前程序的运行。同样地，整个信号处理的过程中，也存在着 CPU 从用户程序到信号处理程序的执行流程转移。</p><p>讲到这里，我相信你已经基本理解了信号的概念。那么，在 C 程序中，应该如何与信号进行交互呢？</p><h2>在 C 代码中与信号交互</h2><p>C 语言自 C90 标准开始，便为我们提供了名为 signal.h 的头文件，以用于支持信号的相关功能。同样地，还是先来看一段代码：</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\n#include &lt;signal.h&gt;\n#include &lt;stdlib.h&gt;\nvoid sigHandler(int sig) {\n&nbsp; printf(\"Signal %d catched!\\n\", sig);\n&nbsp; exit(sig);\n}\nint main(void) {\n&nbsp; signal(SIGFPE, sigHandler);\n&nbsp; int x = 10;\n&nbsp; int y = 0;\n&nbsp; printf(\"%d\", x / y);\n}\n</code></pre><p>这里，我在本讲开头处代码的基础上，进行了适当改进。在这段代码中，我们首先在 main 函数的开头处，使用标准库提供的 signal 函数，为当前程序设置了一段针对信号 SIGFPE 的自定义处理逻辑。</p><p>其中，该函数的第一个参数为具体的某个信号。C 标准库一共提供了 6 种不同类型的信号，它们均以宏常量的形式被定义。我将它们的具体信息整理在了下面这个表格中，供你参考。</p><p><img src=\"https://static001.geekbang.org/resource/image/4e/2c/4eefcdb690a849f7daa3e60f7727472c.jpg?wh=1920x966\" alt=\"图片\"></p><p>需要注意的是，该参数也支持使用某些与具体操作系统实现相关的其他信号值，但需要确保程序运行所在的系统支持这些非 C 标准信号。</p><p>第二个参数为具体的信号处理函数，它的原型需要满足 <code>void (*handler) (int)</code> 这样一种形式，即接收一个整型的信号值，但不返回任何内容（void）。</p><p>随着程序的运行，当位于代码第 12 行的除法运算发生除零异常时，操作系统便会将信号 SIGFPE 发送给当前进程，并根据之前通过 signal 函数注册的信号处理信息，调用用户自定义或默认的信号处理函数。</p><p>需要注意的是，信号处理函数的调用过程是由来自操作系统内核的软中断触发的，因此，这个过程与我们平时见到的，通过 <code>call</code> 指令进行的函数调用过程并不相同。总的来看，上述应用程序和操作系统，围绕信号的基本交互逻辑可以被粗略地描述为以下几个步骤：</p><ol>\n<li>CPU 执行除法指令 <code>idiv</code>；</li>\n<li>发现除零异常，CPU 暂停当前程序运行，并将控制权转交给操作系统；</li>\n<li>操作系统将信号 SIGFPE 发送给出错的程序；</li>\n<li>操作系统根据情况执行相应的信号处理程序（函数）；</li>\n<li>信号处理程序执行完毕后，若程序未退出，则将程序执行恢复到之前的中断点，即 CPU 会重新执行 <code>idiv</code> 指令。</li>\n</ol><p>当然，除了上面这种自定义信号处理函数的方式外，C 标准库还为我们提供了两种基本的信号处理方式。同样地，它们也以宏的形式被定义，可以直接作为 signal 函数的第二个参数来使用。我将它们整理在了下面的表格中，供你参考：</p><p><img src=\"https://static001.geekbang.org/resource/image/c2/c1/c2d48c5925aa38e835569aae1be204c1.jpg?wh=1920x664\" alt=\"图片\"></p><p>其中，第一种 SIG_DFL 表示对信号进行默认处理，操作系统会按照信号既定的默认处理方式来处理程序；SIG_IGN 则会忽略程序收到的信号。</p><p>但需要注意的是，并非所有类型的信号都可以被忽略，比如某些难以恢复的软硬件异常对应的信号，或是 Linux 上专有的 SIGKILL 和 SIGSTOP 信号等。关于它们的一个简单使用示例如下所示：</p><pre><code class=\"language-c++\">#include &lt;signal.h&gt;\n#include &lt;stdio.h&gt;\nint main(void) {\n&nbsp; signal(SIGTERM, SIG_IGN);  // 忽略信号 SIGTERM；\n&nbsp; raise(SIGTERM);  // 向当前程序发送 SIGTERM 信号；\n&nbsp; printf(\"Reachable!\\n\");  // Reachable code!\n&nbsp; return 0;\n}\n</code></pre><p>这里，在代码的第 5 行，我们还使用了由标准库提供的 raise 函数。该函数可以让我们在代码中直接向当前程序发送指定的信号。在上面的代码中，我们为信号 SIGTERM 设置了 SIG_IGN 作为它的处理方式，因此，当执行到 raise 函数后，虽然它向程序发送了 SIGTERM 信号，但程序却不会被立即终止。相反，它将继续执行第 6 行的 printf 函数，然后以正常方式退出。</p><p>可以看到，操作系统对信号处理函数的调用，可能会发生在整个应用程序运行过程中的任意时刻。而在某些情况下，这可能会给程序的实际执行带来影响。接下来，让我们进一步看看这个过程是如何影响程序运行的。</p><h2>可重入函数</h2><p>试想这样一种情况：某一时刻，CPU 还在正常执行 main 函数内函数 A 的代码，而由于某些外部原因，程序在此刻收到了某个信号，操作系统便暂停当前程序运行，并将执行流程调度至对应的信号处理函数。而在这个信号处理函数中，函数 A 又被再次调用。当信号处理完毕后，执行流返回了之前的“中断点”，并继续处理 main 函数内，函数 A 中还未被执行到的指令。</p><p>那么，在这种情况下，信号处理函数中对函数 A 的再次调用，会不会影响之前还未调用完成的函数 A 的执行状态呢？让我们来看下面这段“模拟”代码：</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\n#include &lt;signal.h&gt;\n#include &lt;string.h&gt;\n#define BUF_SIZE 16  // 全局静态数组大小；\n#define FORMAT_NUM_(N) \" $\"#N\n#define FORMAT_NUM(N) FORMAT_NUM_(N)\n#define RAISE_EXP_false_ASM()\n// 调用 raise 函数向当前程序发送信号；\n#define RAISE_EXP_true_ASM() \\\n  \"movl    $4, %%edi\\n\\t\" \\\n  \"call    raise\\n\\t\"\n// 内联汇编实现；\n#define INLINE_ASM(ID, HAS_EXP) \\\n  \"mov     %0, %%r8\\n\\t\" /* 复制传入的字符串数据到全局静态数组 */ \\\n  \"testq   %%rsi, %%rsi\\n\\t\" \\\n  \"je      .L1\" #ID \"\\n\\t\" \\\n  \"xorl    %%eax, %%eax\\n\\t\" \\\n  \".L3\" #ID \":\\n\\t\" \\\n  \"movzbl  (%%rdi,%%rax), %%ecx\\n\\t\" \\\n  \"movb    %%cl, (%%r8,%%rax)\\n\\t\" \\\n  \"addq    $1, %%rax\\n\\t\" \\\n  \"cmpq    %%rsi, %%rax\\n\\t\" \\\n  \"jne     .L3\" #ID \"\\n\\t\" \\\n  \".L1\" #ID \":\\n\\t\" \\\n  RAISE_EXP_##HAS_EXP##_ASM() /* 选择性调用 raise 函数 */ \\\n  \"mov     $1, %%rax\\n\\t\" \\\n  \"mov     $1, %%rdi\\n\\t\" \\\n  \"mov     %0, %%rsi\\n\\t\" \\\n  \"mov\" FORMAT_NUM(BUF_SIZE) \", %%rdx\\n\\t\" \\\n  \"syscall\\n\\t\"  /* 触发系统调用，打印内容 */\n  \nstatic char buf[BUF_SIZE];  // 用于保存字符的全局静态数组；\nvoid print_with_exp(const char* str, size_t len) {  // 会引起信号中断的版本；\n  asm(INLINE_ASM(a, true) :: \"g\" (buf));\n}\nvoid print_normal(const char* str, size_t len) {  // 正常的版本；\n  asm(INLINE_ASM(b, false) :: \"g\" (buf));\n}\nvoid sigHandler(int sig) {\n  const char* str = \"Hello\";\n  print_normal(str, strlen(str));\n}\nint main(void) {\n  signal(SIGILL, sigHandler);\n  const char* str = \", world!\";\n  print_with_exp(str, strlen(str));\n  return 0;\n}\n</code></pre><p>第一眼看上去，这段代码可能稍显复杂，但它的执行逻辑实际上十分简单。在 main 函数中，我们首先通过 signal 函数，为信号 SIGILL 注册了一个自定义信号处理函数。接下来，我们调用了名为 print_with_exp 的函数，并传入了内容为 “Hello” 的字符串 str，以及相应的长度信息。函数在调用后会打印出这个字符串的完整内容。这里，借助函数 print_with_exp，我们将会模拟上面提到的，位于 main 函数中的函数 A 的执行流程。</p><p>但与真实案例稍有不同的是，为了模拟操作系统向程序随机发送信号的过程，这里我们选择直接在函数 print_with_exp 中，通过调用 raise 函数的方式来做到这一点。当然，你可能会说“这并不随机”，但在现实案例中，类似的情况却可能发生。</p><p>为了从更加细微的角度，直观地观察信号处理函数的调用对“函数重入”的影响，这里我们选择直接用内联汇编的方式来实现 print_with_exp 函数。相应地，名为 print_normal 的函数，其功能与 print_with_exp 相同，只是在这个函数中，我们不会调用 raise 函数。你可以简单地将这两个函数视为功能完全一致的 “print” 函数。</p><p>为了方便组织代码，以将相同功能的实现部分进行抽离，我们通过宏的方式“封装”了这两个函数的内联汇编内容。位于代码第 13 行的宏函数 INLINE_ASM，将会根据传入参数的不同，来选择性地生成不同的汇编代码。</p><p>在这两个函数的汇编实现中，我们首先会将由第一个参数传入的字符串内容，根据第二个参数传入的长度信息逐字符复制到程序中的全局静态数组 buf 中。然后，通过相应的系统调用，再将该数组中的内容输出到终端。只是对于 print_with_exp 函数来说，在此之前，我们会通过调用 raise 函数将信号 SIGILL 发送给当前程序。你可以参考代码中的注释来了解这部分实现。</p><p>到这里，按照我们的理解，程序正常运行后，应该会按顺序进行两次输出（对应两次系统调用），并完整打印字符串 “Hello, world!”。其中，前半段由首先调用完成的信号处理函数 sigHandler 中的 print_normal 函数输出；后半段由 main 函数内的 print_with_exp 函数输出。</p><p><strong>但真实情况却并非如此。</strong>程序运行后，你会发现实际的输出内容是 “Hellold!Hellold!”。这是为什么呢？</p><p>仔细查看代码可以看到，函数 print_with_exp 在调用时，存入全局静态数组 buf 中的字符串内容 “, world!”，会被信号处理代码中 print_normal 函数调用时存入的字符串 “Hello”，覆盖了一部分。而当执行流再次退回到 print_with_exp 函数中继续执行时，由于此时数组 buf 中的内容已经发生改变，因此便打印出了错误的结果。你可以参考下图，来理解上述程序的执行流程。</p><p><img src=\"https://static001.geekbang.org/resource/image/77/70/778b7e241a25febcabaebc5978540a70.jpg?wh=1920x1281\" alt=\"图片\"></p><p>对于这种一旦在执行中途被临时打断，在此刻再次调用就可能影响前一次调用正常执行的函数，我们一般称之为“不可重入函数”。相反，<strong>不受中途打断和重新调用影响的函数，便被称为“可重入函数”</strong>。而在信号处理程序中，“尽量使用可重入函数”便是我们需要遵守的首要规则。虽然大多数情况下，在信号处理代码中对它们的调用都可以正常工作，但从程序健壮性的角度来看，却并不推荐这样做。</p><p>实际上，包括 printf、exit，以及 malloc 在内的众多常用 C 标准库函数，它们都并非可重入函数。因此，我们能够在信号处理代码中进行的操作也并不多。而为了进一步简化信号处理模型，C 标准库为我们提供了一个名为 <code>sig_atomic_t</code> 的整数类型，该类型可以保证，<strong>即使存在可能由于中断导致的执行流程转移，对该类型变量的读写过程也都是原子的</strong>（注意，不要与并发编程中的原子类型混淆，标准中仅规定了 <code>sig_atomic_t</code> 类型在异步信号处理场景下的原子性）。</p><p>在这种情况下，对信号的处理过程可以变为如下代码所示的模式：</p><pre><code class=\"language-c++\">#include &lt;signal.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;stdlib.h&gt;\nvolatile sig_atomic_t sig = 0;\nvoid sigHandler(int signal) {\n&nbsp; sig = signal;\n}\nint main(void) {\n&nbsp; signal(SIGINT, sigHandler);\n&nbsp; int counter = 0;  // 计数器变量；\n&nbsp; while(1) {\n&nbsp; &nbsp; switch (sig) {  // 信号筛选与处理；\n      case SIGINT: {\n        printf(\"SignalValue: %d\", sig);\n        /* 异常处理的主要逻辑 */\n        exit(SIGINT);\n      }\n    }\n&nbsp; &nbsp; if (counter == 5) raise(SIGINT);\n&nbsp; &nbsp; printf(\"Counter: %d\\n\", counter++);\n&nbsp; &nbsp; sleep(1);\n&nbsp; }\n  return 0;\n}\n</code></pre><p>这里，在 main 函数中，我们使用死循环来表示一个常驻程序（比如 HTTP 服务器）的执行状态。在代码的第 10 行，通过 signal 函数，我们为信号 SIGINT 注册了相应的处理函数 sigHandler。在该函数内部，<code>sig_atomic_t</code> 类型变量 sig 的值被更新为收到的信号值。回到主函数，在代码的第 13~19 行，我们在主循环每次迭代的开头处，通过检测变量 sig 的值，来判断当前程序是否收到信号，并作出相应处理。而在第 18 行，当 counter 变量的值被递增到 5 时，raise 函数向当前程序发送了信号 SIGINT，从而模拟了程序收到信号，发生软中断时的场景。</p><p>这是一种常见的信号处理模式，并非适合所有场景。但无论如何，你都需要注意：对不可重入函数在信号处理程序中的不当使用，可能会给程序的运行埋下问题。</p><h2>多线程应用的信号处理</h2><p>学习到这里，对于单线程应用，我们已经可以很好地在程序中与信号进行交互。但遗憾的是，C 语言并没有对并发编程中的信号处理做任何规范上的约束和建议。这意味着，在多线程应用中使用 signal 和 raise 函数，可能会产生未定义行为。这些函数会如何影响程序执行，则取决于不同 C 标准库在具体操作系统上的实现。</p><p>所以，如果你对程序的可移植性及健壮性有要求，那么请不要在多线程应用中使用信号处理。作为替代，你可以考虑通过宏的方式来区分程序运行所在的不同操作系统，然后分别使用 POSIX、Win32 等 API ，来以不同方式实现多线程模式下的信号处理过程。</p><h2>总结</h2><p>好了，讲到这里，今天的内容也就基本结束了。最后我来给你总结一下。</p><p>这一讲我主要介绍了 C 语言中与信号处理相关的内容，包括信号的基本概念，如何在 C 程序中使用信号处理函数，以及信号中断可能对程序运行带来的影响等。</p><p>借助信号，操作系统可以将程序运行过程中发生的特殊情况及时通知给程序，并按照其要求的特定方式，或系统的默认方式进行处理。而信号本质上是一种软件中断，即操作系统通过特殊机器指令引起的 CPU 执行流程的临时转移。</p><p>在 C 语言中，可以通过引入标准库头文件 signal.h 的方式，来使用相关的信号处理接口。其中，通过 signal 函数，我们可以为当前程序设置针对某个信号的自定义处理程序；而 raise 函数则为我们提供了可以向当前程序发送指定信号的能力。C 标准中一共规定了 6 种不同类型的信号，以及两种默认的信号处理方式，它们均以宏的形式被定义。</p><p>信号的中断过程可以在任意时刻发生，因此，为了保证程序的健壮性，我们只能在信号处理程序中使用“可重入函数”。这类函数的重新执行，不会对前一个还未执行完成的函数的最终执行结果产生影响。为了简化信号的处理方式，C 标准还为我们提供了名为 <code>sig_atomic_t</code> 的整数类型。这也就意味着，标准可以保证即使在发生信号中断的情况下，对该类型变量的读写也都是原子性的。</p><p>最后，C 标准并未对如何在多线程应用中进行信号处理作过多说明。因此，在并发编程场景中，对 signal 和 raise 等函数的不当使用方式可能会产生未定义行为。</p><h2>思考题</h2><p>你知道 Linux 中的 sys_kill 系统调用有什么作用吗？常见的命令行操作 “kill -9” 又是什么意思呢？欢迎在评论区告诉我你的理解。</p><p>今天的课程到这里就结束了，希望可以帮助到你，也希望你在下方的留言区和我一起讨论。同时，欢迎你把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"14｜标准库：如何使用互斥量等技术协调线程运行？","id":478213},"right":{"article_title":"16｜标准库：日期、时间与实用函数","id":480150}}},{"article_id":480150,"article_title":"16｜标准库：日期、时间与实用函数","article_content":"<p>你好，我是于航。</p><p>在前面的几讲中，我都以较大的篇幅介绍了 C 标准库中的一些重要概念，和相关接口的使用方式。除此之外，标准库中还有一些功能十分明确，使用方式也十分简单的常用接口，这些接口也为日常的 C 应用开发提供了重要支持。因此，在接下来的两讲中，我将围绕这部分内容展开介绍。</p><p>今天，我们先来看看标准库中与日期、时间以及实用函数有关的内容。其中，日期与时间的相关接口由<strong>头文件 time.h</strong> 提供；而实用函数的功能则可被进一步细分为字符串与数值转换、随机数生成、动态内存管理，以及进程控制等不同的几类，这些功能对应的编程接口均由<strong>头文件 stdlib.h</strong> 提供。</p><p>下面，我们就来分别看看这两类接口的使用方式，以及它们背后的一些基本原理。</p><h2>日期与时间</h2><p>首先来看由头文件 time.h 提供的日期与时间相关接口。那么，在 C 语言中，日期与时间的概念是怎样体现的？又应该如何对它们进行操作和转换呢？</p><p>在构建应用程序时，我们经常会用到日期与时间这两种概念。比如，在记录日志时，通常需要保存每个事件的确切发生日期和时间；在进行优化时，则需要通过测量代码的运行时间来寻找性能痛点；而在生成随机数时，甚至需要使用当前时间，作为不同的随机种子。</p><p>看到这里，你可能已经发现了：这一讲中我们提到的“时间”，有两种不同的含义。一种是指时间上的跨度，而另一种则指以小时、分钟、秒组成的确切时间点。至于具体是哪一种含义，需要你结合上下文来理解。当然，在可能会引起误解的地方，我也会特别说明下。</p><!-- [[[read_end]]] --><h3>日历时间</h3><p>在 C 语言中，时间可以被分为“日历时间（Calendar Time）”与“处理器时间（Processor Time）”。其中，前者是指从世界协调时间（UTC）1970 年 1 月 1 日 00 时 00 分 00 秒，到当前 UTC 时间所经历的秒数，其中不包括闰秒。在 C 标准库中，该值由自定义的类型关键字 <code>time_t</code> 表示。该类型通常对应于一个整数类型，在某些老版本的标准库中，可能被实现为 32 位有符号整型。</p><p>同时，time.h 头文件也提供了一个非常直观的，名称为 time 的方法，可用于获取这个值。来看下面这个例子：</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\n#include &lt;time.h&gt;\nint main(void) {\n&nbsp; time_t currTime = time(NULL);\n&nbsp; if(currTime != (time_t)(-1))\n&nbsp; &nbsp; printf(\"The current timestamp is: %ld(s)\", currTime);\n&nbsp; return 0;\n}\n</code></pre><p>这里，我们将 time 方法调用后的返回值保存在了变量 currTime 中。而当方法调用成功后（即返回值不为 -1），该值通过 printf 函数被打印了出来。</p><p>不仅如此，在获取到这个整型时间值后，借由标准库提供的其他时间与日期处理函数，我们还可以对它做进一步处理。比如，将它格式化为本地时间，并以特定的格式输出。继续来看下面这个例子：</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\n#include &lt;time.h&gt;\nint main(void) {\n&nbsp; time_t currTime = time(NULL);\n&nbsp; if(currTime != (time_t)(-1)) {\n&nbsp; &nbsp; char buff[64];\n&nbsp; &nbsp; struct tm* tm = localtime(&amp;currTime);\n&nbsp; &nbsp; if (strftime(buff, sizeof buff, \"%A %c\", tm))\n&nbsp; &nbsp; &nbsp; printf(\"The current local time is: %s\", buff);  // \"The current local time is: Saturday Sat Jan&nbsp; 8 16:30:49 2022\".\n&nbsp; }\n&nbsp; return 0;\n}\n</code></pre><p>在这段代码中，我们用与之前类似的方式获取了当前的日历时间，该值被存放到变量 currTime 中。在代码的第 7 行，通过使用名为 localtime 的方法，我们可以将该日历时间转换成与本地时间相关的多种信息。这些信息将以不同字段的形式被存放在名为 tm 的结构对象中。</p><p>接着，通过调用 strftime 方法，我们可以继续对这个时间对象进行格式化。该方法调用后，会将生成的结果字符串存放到由变量 buff 对应的字符数组中。这里，传入的第三个参数为一个包含有格式控制占位符的字符串。其中，%A 用于显示完整的周工作日名称，%c 用于显示标准日期和时间字符串。strftime 方法将根据占位符字符串的具体组成格式，来输出相应的结果字符串。</p><h3>处理器时间</h3><p>接着，我们再来看处理器时间（CPU Time）。顾名思义，处理器时间，即 CPU 资源被调度以支持程序在某段时间内正常运作所花费的时间。需要注意的是，在默认情况下，这个时间应该是应用运行所涉及的所有独立 CPU 所消耗时间的总和。C 标准库也为我们提供了一个直观的，名称为 clock 的方法，可用于返回这个值。来看下面这个例子：</p><pre><code class=\"language-c++\">#include &lt;time.h&gt;\n#include &lt;stdio.h&gt;\nint main(void) {\n  clock_t startTime = clock();&nbsp; &nbsp;&nbsp;\n  for(int i = 0; i &lt; 10000000; i++) {}\n&nbsp; clock_t endTime = clock();\n&nbsp; printf(\"Consumed CPU time is：%fs\\n\",&nbsp;\n&nbsp; &nbsp;(double)(endTime - startTime) / CLOCKS_PER_SEC);&nbsp;\n  return 0;\n}&nbsp;\n</code></pre><p>位于代码第 4 行的 clock 方法在调用后会返回类型为 <code>clock_t</code> 的值。该类型由标准库的具体实现定义，因此，其值可能为整数，也可能为浮点数。不同于日历时间的是，为了更精确地计算 CPU 耗时，处理器时间并不直接以“秒”为单位，而是以 “clock tick” 为单位。为了将这个时间换算为秒，你需要将它除以标准库中提供的宏常量 CLOCKS_PER_SEC。该常量表明了，在当前系统上每 1 秒钟对应的 clock tick 次数。</p><p>需要注意的是，这里我们提到的 clock tick，与程序运行所在计算机的实际物理 CPU 频率没有直接关系。应用程序可以通过读取计算机上的硬件定时器，来获得对应进程的 CPU 使用时间。</p><p>对于程序运行来说，一段时间内花费的处理器时间与墙上时钟时间（Wall-clock Time）可能并不一致。前者依赖于程序使用的线程数量、所在平台的物理 CPU 核数，以及操作系统调度 CPU 的具体策略等。而后者则是现实世界的时间流逝，也就是一个恒定递增的值。因此，调用一次 clock 方法所返回的处理器时间一般没有太多意义。通常，我们会按照上面例子中的方式来使用这个时间，即<strong>在一段代码的前后，分两次获取处理器时间，并通过计算两者之间的差值</strong><strong>，</strong><strong>来了解 CPU 执行这段代码所花费的时间</strong>。</p><p>当然，为了方便你更好地理解处理器时间与墙上时钟时间的区别，你可以在具有多核 CPU 的计算机上编译和运行下面这段代码，并在评论区告诉我你的运行结果。关于代码的具体实现细节，你可以尝试参考注释进行理解，如果有问题，也可以在评论区随时跟我讨论。</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\n#include &lt;time.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;threads.h&gt;&nbsp;\ntypedef struct timespec ts_t;\nint run(void* data) {&nbsp; // 模拟的耗时任务；\n&nbsp; volatile double d = 0;\n&nbsp; for (int n = 0; n &lt; 10000; ++n)\n&nbsp; &nbsp; for (int m = 0; m &lt; 10000; ++m)\n&nbsp; &nbsp; &nbsp; d += d * n * m;\n&nbsp; return 0;\n}\nint main(void) {\n&nbsp; // 首次记录日历时间与处理器时间；\n&nbsp; ts_t ts1;\n&nbsp; timespec_get(&amp;ts1, TIME_UTC);\n&nbsp; clock_t t1 = clock();\n&nbsp; // 创建两个线程，做一些耗时任务；\n&nbsp; thrd_t thr1, thr2;\n&nbsp; thrd_create(&amp;thr1, run, NULL);\n&nbsp; thrd_create(&amp;thr2, run, NULL);\n&nbsp; thrd_join(thr1, NULL);\n&nbsp; thrd_join(thr2, NULL);\n&nbsp; // 再次记录日历时间与处理器时间；\n&nbsp; ts_t ts2;\n&nbsp; timespec_get(&amp;ts2, TIME_UTC);\n&nbsp; clock_t t2 = clock();\n&nbsp; // 分别计算和打印处理器时间与墙上时钟时间耗时；\n&nbsp; printf(\"CPU time used (per clock()): %.2f ms\\n\", 1000.0 * (t2 - t1) / CLOCKS_PER_SEC);\n&nbsp; printf(\"Wall time passed: %.2f ms\\n\",\n&nbsp;   1000.0 * ts2.tv_sec + 1e-6 * ts2.tv_nsec - (1000.0 * ts1.tv_sec + 1e-6 * ts1.tv_nsec));\n&nbsp; return 0;\n}\n</code></pre><h3>其他相关处理函数</h3><p>除了我在上面介绍过的一些常见日期与时间处理函数外，C 标准库还提供了另外一些相关函数，我将它们整理在了下面的表格中，供你参考。当然，这里并没有包含那些已经被标记为“废弃”的接口。你可以点击<a href=\"https://en.cppreference.com/w/c/chrono\">这个链接</a>，来查看更多信息。</p><p><img src=\"https://static001.geekbang.org/resource/image/56/b5/56dcacb1ef4b2f7946ab44bb92d7a8b5.jpg?wh=1920x833\" alt=\"图片\"></p><h3>Y2038 问题</h3><p>到这里，我讲完了如何在 C 代码中使用日期和时间操作的相关函数，接下来，我想和你讨论一个可能由 <code>time_t</code> 类型引发的问题。</p><p>我在讲日历时间的时候提到过，某些旧版本的 C 标准库在实现用于存放日历时间的 <code>time_t</code> 类型时，可能会采用 32 位有符号整数。而在这种情况下，<code>time_t</code> 所能够表示的时间跨度便会大大缩小，并会在不久之后的 UTC 时间 2038 年 1 月 19 日 03 时 14 分 08 秒发生上溢出。当该类型变量溢出后，其表示的具体日期和时间，将会从 1901 年开始“重新计时”。你可以通过下图（图片来自 <a href=\"https://en.wikipedia.org/wiki/Year_2038_problem\">Wikipedia</a>）来观察这个问题的发生过程。</p><p><img src=\"https://static001.geekbang.org/resource/image/93/b6/936f86f4d570ee9d478487d276bb99b6.gif?wh=400x130\" alt=\"图片\"></p><p>可以说，这是一个全球性问题，严重性甚至可以与 Y2K 等问题比肩。由于 C 语言被广泛应用在各类软硬件系统中，因此，从常见的交通设施、通信设备，到某些早期的计算机操作系统，它们都可能会在那时受到 Y2038 问题的影响。</p><p>看完了与头文件 time.h 相关的内容，接着，我们再来看看 stdlib.h 头文件提供的众多实用函数。由于这些函数的功能十分混杂，我将它们分为了几个不同的类别，来分别为你介绍。首先来看数值与字符串转换的相关接口。</p><h2>字符串到数值的转换</h2><p>这类接口的使用方式都十分简单，直接来看下面这段代码：</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;errno.h&gt;\nint main(void) {\n&nbsp; //&nbsp;一次性字符串到数值转换；\n&nbsp; const char* strA = \"1.0\";\n&nbsp; printf(\"%f\\n\", atof(strA));\n&nbsp;&nbsp;// 带溢出检查的转换函数，执行后会保存不能被转换部分的地址；\n&nbsp; const char* strB = \"200000000000000000000000000000.0\";\n&nbsp; char* end;\n&nbsp; double num = strtol(strB, &amp;end, 10);\n&nbsp; if (errno == ERANGE) {  // 判断转换结果是否发生溢出；\n&nbsp; &nbsp; printf(\"Range error, got: \");\n&nbsp; &nbsp; errno = 0;\n&nbsp; }\n&nbsp; printf(\"%f\\n\", num);\n&nbsp; return 0;\n}\n</code></pre><p>stdlib.h 头文件提供了众多函数，可用于将一个字符串转换为特定类型的数字值。在上面代码的第 7 行，我们使用名为 atof 的函数，将字符串 strA 转换为一个双精度浮点数。实际上，以字母 “a” 开头的这类函数，只能对字符串进行一次性转换。</p><p>相对地，在代码的第 11 行，名为 strtol 的函数将字符串 strB 转换为了对应的长整型数值。而这一类以 “str” 开头的函数，会在每次执行时判断转换结果是否发生溢出，同时保存不能被转换部分的地址。在这种情况下，通过再次调用这类函数，我们便能够对剩余部分的字符串继续进行转换，直至将整个字符串处理完毕。关于这些函数的更多信息，你可以点击<a href=\"https://en.cppreference.com/w/c/string/byte\">这个链接</a>进行查看。</p><h2>生成随机数</h2><p>作为实用函数的一部分，“随机数生成”是一个不可或缺的重要功能。同样地，我们也可以通过配合使用 stdlib.h 提供的 rand 与 srand 方法，来生成随机数。它们的基本用法如下所示：</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;&nbsp;\n#include &lt;stdlib.h&gt;&nbsp;\n#include &lt;time.h&gt;&nbsp;\nint main (void) {\n&nbsp; srand(time(NULL));&nbsp; // 初始化随机数种子；\n&nbsp; while (getchar() == '\\n')&nbsp;\n&nbsp; &nbsp; printf(\"%d\", rand() % 10);&nbsp; // 生成并打印 0-9 的随机数；\n&nbsp; return 0;&nbsp;\n}\n</code></pre><p>可以看到，我们首先在代码的第 5 行，使用 srand 方法设定了程序每次运行时需要使用的随机数种子。在代码第 7 行，rand 函数的调用会产生范围为 [0, RAND_MAX] 的随机数。通过对它进行求余处理，可以将结果限定到一个指定的范围。</p><p>对于大多数 C 标准库实现来说，rand 函数在内部会采用“线性同余发生器（Linear Congruential Generator）”等伪随机算法，来计算函数每次调用时需要产生的随机数。这也就意味着，该函数产生的随机数，本质上并不是随机的。如果我们没有使用 srand 函数设置新的随机数种子，那么，当每次程序重新运行时，通过 rand 函数产生的随机数序列都将会是相同的。而这个种子便会作为 rand 函数在计算下一个随机数时，所采用算法的输入参数。</p><p>事实上，计算机无法生成“真正的随机数”。正如 MIT 教授 Steve Ward 说的那样：“传统计算机系统最不擅长的一件事就是抛硬币”。计算机软件的执行会按照既定的算法展开，因此，当输入和算法不变时，输出结果就变得有迹可循。即使我们可以用更复杂的算法，来让输出的变化模式变得难以琢磨，但无论如何，这都并非真正的随机。</p><p>而伪随机数算法之所以可被用来生成随机数，则是因为从统计学角度来讲，其生成的数字符合随机数在均匀性、独立性等特征上的要求。并且，伪随机数的生成不需要特殊的硬件支持。同时，在大多数场景中，伪随机数也可以满足基本的使用需求。</p><h2>动态内存管理</h2><p>动态内存管理，本质上就是堆内存管理。我曾在 <a href=\"https://time.geekbang.org/column/article/471937\">08 讲</a> 中介绍过 VAS 中堆的概念，以及如何使用 malloc 与 free 函数，来在堆上分配和释放一段内存空间。但实际上，除这两个函数外，C 标准库还为我们提供了另外一些函数，可用于在分配堆内存时进行更加精确的控制。你可以通过下面的表格，来了解这几个函数的基本功能。由于它们的使用方式较为简单，这里我就不详细介绍了。</p><p><img src=\"https://static001.geekbang.org/resource/image/43/85/43681d805024cd0deb8fdb77yy553885.jpg?wh=1920x601\" alt=\"图片\"></p><h2>进程控制</h2><p>接下来，我们来看看实用函数中与进程控制相关的内容。虽然 C 标准库为我们提供了进程控制的相关能力，但这个能力实际上却十分有限。借助标准库提供的接口，我们可以控制程序的退出形式（正常终止、异常终止、快速终止等），获取当前系统的环境变量，或是与宿主机上的命令处理器进行交互。但除此之外，我们无法再控制进程的其他行为，比如创建进程，或使用进程间通信。对于其中几个函数的使用方式，你可以参考下面这个例子：</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\nvoid exitHandler() {\n&nbsp; printf(\"%s\\n\", getenv(\"PATH\"));\n}\nint main(void) {\n&nbsp; if (!atexit(exitHandler)) {\n&nbsp; &nbsp; exit(EXIT_SUCCESS);\n&nbsp; }\n&nbsp; return 0;\n}\n</code></pre><p>这里，在代码的第 7 行，我们使用函数 atexit 为程序注册了一个回调函数。这个函数会在程序显式调用 exit 函数时，或从 main 函数内正常退出时被触发。在对应的回调函数 exitHandler 中，我们使用 getenv 函数，获取并打印了当前宿主机上环境变量 PATH 的值。当回调函数注册成功后（返回整型数值 0），通过显式调用函数 exit，我们正常退出了当前程序。此时，回调函数被调用，环境变量 PATH 的值被打印了出来。</p><p>还有一些我没提到的函数，它们的使用方式也很简单。同样地，我将它们整理在了下面的表格中，供你参考。</p><p><img src=\"https://static001.geekbang.org/resource/image/f2/21/f2f27076ce8d76cfb8a6d349b7975421.jpg?wh=1920x755\" alt=\"图片\"></p><p>这里需要你注意，exit、quick_exit、_Exit，以及 abort 这四个可用于终止程序运行的函数，它们实际上对应着不同的使用场景。</p><p>其中，exit 函数在退出程序时，会进行一系列资源清理工作，比如冲刷并关闭各种 IO 流、移除由函数 tmpfile 创建的临时文件等。除此之外，它还会在中途触发用户注册的回调函数，以进行自定义的收尾工作。但相对地，quick_exit 函数在终止程序时，并不会进行上述资源清理工作。它仅会通过回调函数，来执行用户自定义的收尾工作。 _Exit 函数则更加彻底，它会直接终止程序的执行，而不做任何处理。</p><p>不同于这三类函数，abort 函数在调用时，会向当前程序发送信号 SIGABRT，并根据情况，选择终止程序或执行相应的信号处理程序。</p><h2>其他接口</h2><p>除了上面提到的这几类重要接口外，stdlib.h 中还包含有一些与搜索排序、整数算数、宽字符（串）转换相关的接口。它们的使用方式也十分简单，这里我就不一一介绍了。你可以参考下表来了解这些最常用接口的名称与功能，也可以点击<a href=\"https://en.cppreference.com/w/cpp/header/cstdlib\">这个链接</a>来了解有关它们的更多信息。</p><p><img src=\"https://static001.geekbang.org/resource/image/a0/63/a052c5d916a38a82b18fa4cc13dd1e63.jpg?wh=1920x849\" alt=\"图片\"></p><h2>总结</h2><p>好了，讲到这里，今天的内容也就基本结束了。最后我来给你总结一下。</p><p>这一讲，我主要介绍了 C 标准库中与时间（日期）处理、字符串和数值转换、随机数生成、动态内存管理、进程控制，以及搜索排序等功能相关的接口。其中，第一部分功能的接口由 time.h 提供，其余部分由 stdlib.h 提供。</p><p>C 语言中的时间可以被分为日历时间与处理器时间。通过名为 time 与 clock 的两个接口，我们可以分别获得与它们对应的两个值。进一步，借助 localtime 与 strftime 等接口，日历时间可以被转换为本地时间，并按照指定的形式进行格式化。而处理器时间由于在默认情况下以 clock tick 为单位，因此，需要将它除以宏常量 CLOCKS_PER_SEC，从而得到以秒为单位的值。</p><p>通过使用 atof 与 strtol 等接口，我们可以实现字符串到数字值的转换。其中，前一类以 “a” 开头的接口，仅能对字符串进行一次转换；而后一类以 “str” 开头的接口，则可在对字符串进行数值转换的基础上，同时检查转换结果是否发生溢出，并保存不能被转换部分的地址。</p><p>通过配合使用 rand 与 srand 接口，我们可以在 C 程序中生成伪随机数。在大多数标准库中，rand 函数会使用伪随机算法来实现。因此，为了使每次调用 rand 函数生成的随机数序列都不尽相同，在调用该接口前，可以配合使用 srand 与 time 函数，来为其设置随时间变化的不同随机数种子。</p><p>malloc、calloc，以及 free 等接口的实现，方便了我们在程序中动态操作堆内存。而通过调用 exit、abort、quick_exit 等接口，我们可以精确地控制程序在退出时的具体行为。除此之外，abs、qsort、bsearch、mblen 等接口的提供，也使得标准库在搜索排序、整数算数、宽字符（串）转换等方面，为 C 编程提供了一定帮助。</p><h2>思考题</h2><p>最后，让我们来讨论一个有意思的话题：既然计算机无法产生真正的随机数，那么有哪些方法可以用来产生真正的随机数呢？它们的原理是什么呢？欢迎在评论区告诉我你的发现。</p><p>今天的课程到这里就结束了，希望可以帮助到你，也希望你在下方的留言区和我一起讨论。同时，欢迎你把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"15｜标准库：信号与操作系统软中断有什么关系？","id":479176},"right":{"article_title":"17｜标准库：断言、错误处理与对齐","id":481159}}},{"article_id":481159,"article_title":"17｜标准库：断言、错误处理与对齐","article_content":"<p>你好，我是于航。</p><p>这一讲是这门课中关于 C 标准库的最后一讲。通过前面几讲的学习，相信你已经对 C 标准库提供的相关能力有了一个全面的认识。在此基础上，我们便可以使用这些成熟的接口，来更加方便地构建应用程序。这一讲后，在“ C 工程实战篇”的其他篇目中，我会和你一起讨论语言具体功能之外的性能优化、自动化测试、结构化编译等 C 工程化相关内容，并带你手把手实现一个简单的高性能 HTTP Server。</p><p>今天，我们来看一看与 C 标准库相关的最后三个话题：断言、错误处理，以及对齐。</p><p>断言为我们提供了一种可以静态或动态地检查程序在目标平台上整体状态的能力，与它相关的接口由头文件 assert.h 提供。错误处理则涉及 C 程序如何通过特定方式，判断其运行是否发生错误，以及错误的具体类型，头文件 errno.h 中则定义了与此相关的宏。除此之外，C 语言还具有自定义数据对齐方式的能力，借助 stdalign.h 头文件提供的宏，我们可以轻松地做到这一点。</p><h2>断言</h2><p>在计算机编程中，断言是一种可用于判断程序设计或运行是否符合开发者预期的逻辑判断式。与断言相关的编程接口由标准库头文件 assert.h 提供。</p><p>在 C 语言中，断言被分为静态断言与运行时断言。其中，静态断言主要用来约束程序在编译时需要满足的一定要求；运行时断言则可以在程序运行过程中，判断一些支持程序正常运行的假设性条件是否满足。我们来看下面这个例子：</p><!-- [[[read_end]]] --><pre><code class=\"language-c++\">#include &lt;assert.h&gt;\ndouble sqrt(double x) {\n&nbsp; // 检查函数使用时传入的参数；\n&nbsp; assert(x &gt; 0.0);\n&nbsp; // ...\n}\nint main(void) {\n&nbsp; // 检查程序的编译要求；\n&nbsp; static_assert(sizeof(int) &gt;= 4, \n    \"Integer should have at least 4 bytes length.\");\n&nbsp; // ...\n&nbsp; return 0;\n}\n</code></pre><p>可以很直观地看到，我们分别在代码的第 4 行和第 9 行使用到了运行时断言与静态断言。因为这里的重点内容是两种断言的具体使用方式，因此我们没有去实现一个完整的可运行程序，但这并不影响你对相关概念的理解。</p><p>接下来，我们进一步看看静态断言和运行时断言在 C 语言中的使用方式和适用场景。</p><h3>静态断言</h3><p>从刚才的例子中可以看到，在 main 函数内部，通过名为 static_assert 的宏，我们可以限定程序在被编译时，其所在平台上 <code>int</code> 类型的宽度需要大于等于 4 字节。否则，编译会被终止，对应的错误信息也会被打印出来。</p><p>实际上，在预处理阶段，static_assert 宏会被展开成名为 <code>_Static_assert</code> 的 C 关键字。该关键字以类似“函数调用”的形式在 C 代码中使用，它的第一个参数接收一个常量表达式。程序在被编译时，编译器会对该表达式进行求值，并将所得结果与数字 0 进行比较。若两者相等，则程序终止编译，并会将通过第二个参数指定的错误信息，与断言失败信息合并输出。若两者不相等，程序会被正常编译，且该关键字对应的 C 代码不会生成任何对应的机器指令。</p><p>一般来说，我们会在程序运行前使用静态断言，来检查它所需要满足的一系列要求。比如，在上面这个例子中，程序的正常运行便依赖于一个前置条件，即 <code>int</code> 类型的宽度需要满足至少 4 字节。而通过静态断言，开发者便可以提前得知，程序如果运行在当前平台上，是否能正常工作。</p><p>类似的用例还有很多，比如判断 <code>char</code> 类型的默认符号性（借助 CHAR_MIN 宏常量），或是判断指针类型与 <code>int</code> 类型的宽度是否相等，或是判断某个结构体的大小是否满足预期要求，等等。这些都是可能影响 C 程序运行正确性的因素，而通过静态断言，它们都可以在编译时被提前检测出来。</p><h3>运行时断言</h3><p>还是上面那段代码，在代码中名为 sqrt 的函数实现里，我们使用到了运行时断言。这里，通过名为 assert 的宏，程序可以在函数主要逻辑被调用时，首先判断用于支持函数正常运作的假设性条件是否成立。</p><p>这个函数的功能是计算给定数字值的平方根，因此要保证传入参数 x 的值大于 0。而通过运行时断言，我们便能够做到这一点。但与静态断言使用的 static_assert 不同，assert 并不支持自定义错误消息。那么，我在这里留下一个小问题：你知道怎样才能在运行时断言失败时，将我们自定义的错误消息也显示给开发者吗？欢迎在评论区分享你的思考。</p><p>另外还需要注意的是，C 程序中的运行时断言是否可用，也会受到宏常量 NDEBUG 的影响。当该宏常量的定义先于 <code>#include &lt;assert.h&gt;</code> 语句出现时，编译器会忽略对 assert 宏函数调用代码的编译。反之，它便会在程序运行时进行正常的断言检查。通过这种方式，我们可以相对灵活地控制运行时断言的启用与关闭。</p><p>通常来说，运行时断言可被应用于“<a href=\"https://www.eiffel.com/values/design-by-contract/introduction\">契约式编程</a>（Design by Contract）”与“<a href=\"https://interrupt.memfault.com/blog/defensive-and-offensive-programming\">防御式编程</a>（Defensive Programming）”这两种软件设计方法中。如果你对这两个概念感兴趣，可以点击链接来参考更多信息。</p><p>最后，让我们再从这两种软件设计方法的角度，回顾一下函数 sqrt 内部使用的运行时断言。这里，函数 sqrt 通过运行时断言，保证了它的主要逻辑被执行前，相关必要条件（即传入的参数值大于 0）需要被首先满足。从防御式编程的角度来看，这是预防函数调用时发生错误的一种措施。而从契约式编程的角度来看，这就是被调用函数进行契约（函数调用前置条件）检查的过程。</p><h2>错误处理</h2><p>在 C 语言中，名为 errno 的预处理器宏会被展开为一个 <code>int</code> 类型的可修改全局左值，也就是说，我们可以直接对它进行赋值操作（这里为了便于描述，下面我再次提及 errno 时，均指代这个左值）。</p><p>在这个值中，便存放有程序自上一次调用 C 标准库函数后的状态信息。该宏由标准库头文件 errno.h 提供，在默认情况下，errno 中存放着数字值 0，表示程序正常运行。随着程序不断调用各种标准库函数，当某一时刻某个函数的执行产生了不符合预期的结果时，函数便会通过修改 errno 的值，来向程序传达这一消息。我们来看下面这个例子：</p><pre><code class=\"language-c++\">#include &lt;tgmath.h&gt;\n#include &lt;string.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;errno.h&gt;\nint main(void) {\n&nbsp; sqrt(-1);\n&nbsp; fprintf(stderr, \"%s\\n\", strerror(errno));&nbsp; // \"Numerical argument out of domain\".\n&nbsp; return 0;\n}\n</code></pre><p>这里，在代码的第 6 行，我们用实参值 “-1” 调用了用于求取平方根的标准库函数 sqrt。可以看到，由于负数在实数域内没有平方根，因此这是一种错误的使用方式。我们在上一小节中使用了运行时断言来终止程序执行，而这里，标准库函数会通过设置 errno 来向程序反馈相应的错误信息，但不会终止程序的运行。</p><p>紧接着，在代码的第 7 行，我们可以通过 strerror 函数，来得到当前 errno 中存放的数字值所表示状态对应的可读文本。然后，借由 fprintf 函数，该文本被“发送”到标准错误流中。同样地，使用 string.h 头文件提供的 perror 函数，我们也可以达到类似的效果。</p><p>实际上，C11 标准中仅规定了 errno 可能取得的三个枚举值，我将它们的具体值，以及对这些值的描述信息整理在了下面的表格中，供你参考。</p><p><img src=\"https://static001.geekbang.org/resource/image/7d/a7/7dcd27fb67b64578bcd5a1cde09929a7.jpg?wh=1920x823\" alt=\"图片\"></p><p>除此之外，POSIX 标准、C++ 标准库，甚至不同的操作系统实现，都可能会为 errno 定义额外的可选枚举值，用来表示更多不同场景下的错误情况。</p><p>不仅如此，<strong>C 语言还为 errno 添加了线程本地属性</strong>。这也就意味着，在程序不同线程中发生的错误，将会使用专属于本线程的 errno 来存放相应的错误标识数值。你可以通过下面这段代码来验证这个结论：</p><pre><code class=\"language-c++\">#include &lt;threads.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;errno.h&gt;\n#include &lt;tgmath.h&gt;\nint run(void* data) {\n&nbsp; log(0.0);\n&nbsp; perror(\"Run\");  // \"Run: Numerical result out of range\".\n&nbsp; return thrd_success;\n}\nint main(void) {\n#ifndef __STDC_NO_THREADS__\n&nbsp; thrd_t thread;\n&nbsp; thrd_create(&amp;thread, run, NULL);\n&nbsp; thrd_join(thread, NULL);\n&nbsp; perror(\"Main\");  // \"Main: Success\".\n#endif\n&nbsp; return 0;&nbsp;\n}\n</code></pre><p>这样看起来，errno 在错误检查方面表现得还不错，但在使用时我们仍然需要注意很多问题。通常来说，我们可以把标准库函数在遇到执行错误时的具体行为分为下面四类：</p><ul>\n<li>设置 errno，并返回仅用于表示执行错误的值，如 ftell；</li>\n<li>设置 errno，并返回可同时用于表示执行错误及正常执行结果的值，如 strtol；</li>\n<li>不承诺设置 errno，但可能会返回表示执行错误的值，如 setlocale；</li>\n<li>在不同标准（比如 ISO C 和 POSIX）下有不同行为，如 fopen。</li>\n</ul><p>可以看到，在执行发生错误时，并非所有 C 标准库函数都会对 errno 的值进行合理的设置。因此，仅通过该值来判断函数执行是否正常可能并不明智。</p><p>更加合适的做法是，当你明确知道所调用库函数会返回唯一的、不具有歧义，且不会与其正常返回值混用的错误值时，应直接使用该值来进行判断。而当不满足这个条件时，再使用 errno 来判断错误是否发生，以及错误的具体类型。同时，建议你养成一个好习惯：<strong>每一次调用相应的库函数前，都应首先将 errno 置零，并在函数调用后</strong><strong>，</strong><strong>及时对它的值进行检测。</strong></p><h2>自定义数据对齐</h2><p>最后，我们再来看看有关对齐的内容。关于对齐的一些理论性知识，我曾在 <a href=\"https://time.geekbang.org/column/article/471133\">07 讲</a> 中为你介绍过。如果觉得记忆有些模糊了，可以先点击链接去那一讲温习下。</p><p>这里，我们来看看如何在 C 语言中为数据指定自定义的对齐方式。默认情况下，编译器会采用自然对齐，来约束数据在内存中的起始位置。但实际上，我们也可以使用 C11 提供的关键字 <code>_Alignas</code> ，来根据自身需求为数据指定特殊的对齐要求。并且，头文件 stdalign.h 还为我们提供了与其对应的宏 alignas，可以简化关键字的使用过程。来看下面这段代码：</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\n#include &lt;stdalign.h&gt;\nint main(void) {\n#if __alignas_is_defined == 1 &amp;&amp; __alignof_is_defined == 1\n&nbsp; alignas(1024) int n = 1;\n&nbsp; printf(\"The alignment of n is %zu\\n\", alignof(n));  // \"The alignment of n is 1024\".\n&nbsp; printf(\"The address of n is: %p\\n\", &amp;n);  // \"The address of n is: 0x7ffe80658c00\".\n#endif\n&nbsp; return 0;&nbsp;\n}\n</code></pre><p>这里，在代码的第 4 行，我们首先通过验证宏常量 __alignas_is_defined 与 __alignof_is_defined 的值是否为 1，来判断当前编译环境是否支持 alignas 与 alignof 这两个宏。</p><p>紧接着，在代码第 5 行，通过在变量 n 的定义中添加 <code>alignas(1024)</code> 标识符，我们可以限定，变量 n 的值被存放在内存中时，其起始地址必须为 1024 的倍数。而在接下来代码的第 6~7 行，我们分别通过使用 alignof 宏函数和直接查看地址这两种方式，来验证我们对变量 n 指定的对齐方式是否生效。</p><p>同 alignas 类似的是，宏函数 alignof 在展开后也会直接对应于 C11 新引入的运算符关键字 <code>_Alignof</code>，而该关键字可用于查看指定变量需要满足的对齐方式。并且，通过打印变量 n 的地址，你会发现，这个例子中结尾处的三位 16 进制数字 “c00”，也表示该地址已经在 1024 的边界上对齐。</p><p>表面上看，alignas 只是用来修改数据在内存中的对齐方式的。但实际上，合理地运用这个功能，我们还可以优化程序在某些情况下的运行时性能。在下一讲中，我会为你详细介绍这些内容。</p><h2>总结</h2><p>好了，讲到这里，今天的内容也就基本结束了。最后我来给你总结一下。</p><p>在这一讲中，我们主要讨论了如何借助 C 标准库提供的相关接口，在 C 程序中使用各种断言和检查库函数调用错误，以及使用自定义数据对齐方式。</p><p>通过 assert.h 头文件提供的 static_assert 与 assert 宏函数，我们可以在 C 代码中使用静态断言与运行时断言。其中，前者主要用于约束程序在编译时需要满足的环境要求，而后者则可被应用于防御式编程与契约式编程等程序设计方法中。</p><p>通过访问 errno.h 头文件提供的预处理器宏 errno，我们能够得知程序在调用某个标准库函数后，该函数的执行是否发生了错误。而通过定义在 stdalign.h 头文件中的宏函数 alignas 与 alignof，我们可以为数据指定除自然对齐外的其他对齐方式。</p><h2>思考题</h2><p>这一讲的最后，给你留个小作业：请你查阅相关文档，并在评论区告诉我你对契约式编程的理解。</p><p>今天的课程到这里就结束了，希望可以帮助到你，也希望你在下方的留言区和我一起讨论。同时，欢迎你把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"16｜标准库：日期、时间与实用函数","id":480150},"right":{"article_title":"18｜极致优化（上）：如何实现高性能的 C 程序？","id":481903}}},{"article_id":481903,"article_title":"18｜极致优化（上）：如何实现高性能的 C 程序？","article_content":"<p>你好，我是于航。</p><p>我在<a href=\"https://time.geekbang.org/column/article/464540\">开篇词</a>中曾提到过，使用 C 语言正确实现的程序可以享受到最高的运行时性能。因此，如何编写具有“最高”执行性能的代码，是每个 C 程序员都在竭尽所能去探索的一个问题。那么，接下来的两讲，我们就来看看，如何编写高质量的 C 代码，来让我们的程序达到最佳的运行状态。</p><p>这一讲，我主要会为你介绍四个优化 C 代码的技巧，它们分别是利用高速缓存、利用代码内联、利用 <code>restrict</code> 关键字，以及消除不必要内存引用。</p><h2>如何衡量程序的运行性能？</h2><p>在开始正式介绍常用的性能优化技巧前，我们首先需要知道如何衡量一个应用程序的运行性能。</p><p>通常我们可以采用最简单和直观的两个宽泛指标，即内存使用率和运行时间。对于具有相同功能的两个程序，在完成相同任务时，哪一个的<strong>内存使用率更低，且运行时间更短，则程序的整体性能相对更好</strong>。</p><p>我们可以将这两个指标再进一步细分。比如程序的内存使用率，可以细分为程序在单位时间内的主内存使用率、L1-L3 高速缓存使用率、程序堆栈内存使用率等指标。而运行时间也可以细分为程序总体运行时间（墙上时钟时间）、用户与操作系统时间（CPU 时间），以及空闲时间与 IO 等待时间等。</p><p>至于这些指标的制定和使用方式，属于性能监控的另一个话题，这里我们就不展开了。但你需要知道的是，无论程序多么复杂，运行时间和内存消耗这两个指标都是可用于观察程序性能情况的基本指标。</p><!-- [[[read_end]]] --><p>这一讲和下一讲，我们会主要讨论可用于优化程序性能的具体编码方式。而采用这些编码方式能够保证你的代码在所有运行环境中，都拥有一个相对稳定且高效的执行情况。但你也需要注意，程序的实际运行可能会受到操作系统、编译器、网络环境等多方面的影响，因此，即使采用这些编码方式，也并不一定保证程序可以在所有执行环境上都能够获得较大的性能提升。</p><p>另外需要说明的是，这一讲我会以程序对应的 x86-64 汇编代码为例，来深入介绍各种优化技巧背后的逻辑。不过，这些基于 C 代码的性能优化策略都是相通的，只要掌握了它们的原理，在不同的平台体系上，你都可以做到举一反三，运用自如。下面，我们就来看具体的编码技巧吧。</p><h2>技巧一：利用高速缓存</h2><p>相信你在选购电脑时，经常会遇到 L1、L2、L3 高速缓存这几个指标，由此可见这些概念在衡量计算机整体质量中的重要性。那么，它们究竟代表什么呢？</p><p>我们都清楚缓存的重要性，通过将常用数据保存在缓存中，当硬件或软件需要再次访问这些数据时，便能以相对更快的速度进行读取和使用。而在现代计算机体系中，L1、L2、L3（某些体系可能有 L4 缓存，但不普遍）一般分别对应于 CPU 芯片上的三个不同级别的高速缓存，这些缓存的数据读写速度依次降低，但可缓存数据的容量却依次升高。而这些位于 CPU 芯片上的缓存，则主要用于临时存放 CPU 在最近一段时间内经常使用的数据和指令。</p><p>L1 到 L3 缓存直接由 CPU 硬件进行管理，当 CPU 想要读取某个数据时，它会按照一定规则优先从 L1 缓存中查找，如果没有找到，则再查找 L2 缓存，以此类推。而当在所有高速缓存中都没有找到目标数据时，CPU 便会直接从内存中读取。与直接从 L1 中读取相比，这个过程花费的时间会多出上百倍，所以你可以很清楚地看到优先将数据存放在高速缓存中的重要性。</p><p>高速缓存之所以能够提升性能，一个重要的前提便在于“局部性（locality）原理”。该原理通常被分为两个方面，即“时间局部性”和“空间局部性”，它们的内容分别如下所示。</p><ul>\n<li><strong>时间局部性</strong>：被引用过一次的内存位置可能在不远的将来会再被多次引用；</li>\n<li><strong>空间局部性</strong>：如果一个内存位置被引用了一次，那么程序很可能在不久的将来引用其附近的另一个内存位置。</li>\n</ul><p>局部性本身是处理器访问内存行为的一种趋势，因此，如果一个程序在设计时能够很好地满足局部性原理，其运行便可能会有更高的性能表现。接下来我们就看看，如何让程序设计尽量满足这些原则。</p><p>在这里，我给出了一段不满足局部性原理的代码，你可以先思考下这段代码有什么问题，有没有可以进一步提升性能的空间。</p><pre><code class=\"language-c++\">#define M 128\n#define N 64\nint sum(int a[M][N]) {\n&nbsp; int i, j, sum = 0;\n&nbsp; for (j = 0; j &lt; N; ++j) {\n&nbsp; &nbsp; for (i = 0; i &lt; M; ++i) {\n&nbsp; &nbsp; &nbsp; sum += a[i][j];\n&nbsp; &nbsp; }\n&nbsp; }\n&nbsp; return sum;\n}\n</code></pre><p>可以看到的是，这段代码每次的内存访问过程（即访问数组 a 中的元素）都没有尽可能地集中在一段固定的内存区域上。相反，访存的过程发生在多个不同位置，且各个位置之间的跨度很大。这一点从代码中 sum 变量按照“列优先”顺序（先循环变量 i，后循环变量 j）访问数组元素的方式就可以得出。</p><p>我们知道，C 语言中二维数组的元素是按照“行优先”的方式存储的，也就是说，在上面的数组 a 中，连续不同的 j 将引用数组中连续的内存位置。CPU 在缓存数据时，会按照局部性原则，缓存第一次访问内存时其附近位置的一段连续数据。而列优先的访问方式则使得数组中数据的引用位置变得不连续，这在一定情况下可能会导致上一次已被放入高速缓存中的数据，在下一次数据访问时没有被命中。而由此带来的直接对内存的频繁访问，则会导致程序整体性能的降低。</p><p>因此我们的结论是，上述代码的设计并没有很好地满足空间局部性，其运行效率并没有被最大化。你可以通过下图来形象地理解这个问题：</p><p><img src=\"https://static001.geekbang.org/resource/image/5b/af/5b9702e408cc45e6a0ee16c34af3cdaf.jpg?wh=2284x655\" alt=\"\"></p><p>可以看到，当代码的内层循环第一次访问数组 a 时，假设 CPU 会将临近的 4 个元素放入到它的高速缓存中。而由于代码采用了“行优先”访问，因此当下一次访问数组元素时，位于高速缓存中的数据便不会被命中。以此类推，后续的每次访问都会产生这样的问题。</p><p>因此，为了能更好地利用 CPU 高速缓存，你可以参考这些原则来编写代码：</p><ul>\n<li>尽量确保定义的局部变量能够被多次引用；</li>\n<li>在循环结构中，以较短的步长访问数据；</li>\n<li>对于数组结构，使用行优先遍历；</li>\n<li>循环体越小，循环迭代次数越多，则局部性越好。</li>\n</ul><p>还记得我在上一讲中提到的自定义数据对齐吗？通过合理使用 <code>alignas</code> 关键字，我们也可以优化某些特定场景下的代码，来让它在最大程度上利用高速缓存。来看下面这个例子：</p><pre><code class=\"language-c++\">struct data {\n&nbsp; char x;\n&nbsp; alignas(64) char y[118];\n};\n</code></pre><p>在这段代码中，我们定义了一个名为 data 的结构。它包含两个字段，一个为字符类型的 x，另一个为包含有 118 个元素的字符数组 y。而通过指定 <code>alignas(64)</code> 标识符，我们限制字段 y 在内存中的起始地址需要在 64 字节上对齐。</p><p>实际上，在计算机内部，高速缓存是以“缓存行（Cache Line）”的形式被组织的。也就是说，一大块连续的高速缓存会被分为多个组，每个组中有多个行，而每个行则具有固定大小。当发生缓存不命中时，CPU 会将数据从低层次缓存中以固定的“块大小（通常为缓存行大小）”为单位，拷贝到高层次缓存中。<strong>而为了减少 CPU 需要进行的内存拷贝次数，我们希望连续的数据能被组织在尽可能少的缓存行中。</strong></p><p>另一方面，内存与高速缓存之间的映射关系一般与数据在内存中的具体地址有关。比如，对于采用“直接映射”方式的缓存来说，假设缓存行大小为 64 字节，若某段数据起始于内存中对齐到 64 字节的地址，而当它被拷贝到高速缓存中时，便会从缓存行的开头处开始放置数据，这在最大程度上减少了这段连续数据需要占用的缓存行个数（当从缓存行中间开始存放数据时，字段 y 可能需要占用三个缓存行）。上面那段代码便是如此。</p><h2>技巧二：代码内联</h2><p>第二种常用于性能优化的方式是代码内联（Inlining）。这种方式很好理解，下面我们直接来看个例子，由此理解内联的概念和它对程序运行的影响。</p><p>C99 标准引入了一个名为 <code>inline</code> 的关键字，通过该关键字，我们可以建议编译器，将某个方法的实现内联到它的实际调用处。来看下面这个简短的例子：</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\nstatic inline int foo() {\n  return 10;\n}\nint main(void) {\n  int v = foo();\n  printf(\"Output is: %d\\n\", v);\n  return 0;\n}\n</code></pre><p>在这段代码中，我们使用 <code>inline</code> 关键字标注了方法 foo，并在 main 函数内将 foo 方法的调用返回结果赋值给了变量 v。为了能够看清 <code>inline</code> 关键字对程序实际运行的影响，我们还需要查看上述 C 代码对应的汇编代码，具体如下所示：</p><pre><code class=\"language-c++\">.LC0:\n&nbsp; &nbsp; &nbsp; &nbsp; .string \"Output is: %d\\n\"\nmain:\n&nbsp; &nbsp; &nbsp; &nbsp; sub&nbsp; &nbsp; &nbsp;rsp, 8\n&nbsp; &nbsp; &nbsp; &nbsp; mov&nbsp; &nbsp; &nbsp;esi, 10\n&nbsp; &nbsp; &nbsp; &nbsp; mov&nbsp; &nbsp; &nbsp;edi, OFFSET FLAT:.LC0\n&nbsp; &nbsp; &nbsp; &nbsp; xor&nbsp; &nbsp; &nbsp;eax, eax\n&nbsp; &nbsp; &nbsp; &nbsp; call&nbsp; &nbsp; printf\n&nbsp; &nbsp; &nbsp; &nbsp; xor&nbsp; &nbsp; &nbsp;eax, eax\n&nbsp; &nbsp; &nbsp; &nbsp; add&nbsp; &nbsp; &nbsp;rsp, 8\n&nbsp; &nbsp; &nbsp; &nbsp; ret\n</code></pre><p>可以看到，在这段汇编代码中，实际上只有 main 函数的机器指令实现，而 foo 函数的具体定义则已经被替换到了它在 main 函数中的实际调用位置处（对应 <code>mov esi, 10</code> 这一行） 。</p><p>通过这种方式，程序不再需要使用 <code>call</code> 指令来调用 foo 函数。这样做的好处在于，可以省去 <code>call</code> 指令在执行时需要进行的函数栈帧创建和销毁过程，以节省部分 CPU 时钟周期。而通过这种方式得到的性能提升，通常在函数被多次调用的场景中更加显而易见。</p><p><code>inline</code> 固然好用，但我们也要注意这一点：函数本身作为 C 语言中对代码封装和复用的主体，不恰当的内联也会导致程序可执行二进制文件的增大，以及操作系统加载程序时的效率变低。一般情况下，内联仅适用于那些本身实现较为短小，且可能会被多次调用的函数。同时，<code>inline</code> 关键字也仅是程序员对编译器提出的一个建议，具体是否会被采纳，还要看具体编译器的实现。而对于大部分常用编译器来说，在高优化等级的情况下，它们也会默认采用内联来对代码进行优化。</p><p>当然，除此之外，你也可以选择通过宏来进行预处理时的代码内联。采用这种方式的话，你需要将 C 代码封装成对应的宏，并在需要内联的地方展开。</p><h2>技巧三：<code>restrict</code> 关键字</h2><p>C99 标准新增了一个名为 <code>restrict</code> 的关键字，可以优化代码的执行。该关键字只能用于指针类型，用以表明该指针是访问对应数据的唯一方式。</p><p>在计算机领域，有一个名为 aliasing 的概念。这个概念是说内存中的某一个位置，可以通过程序中多于一个的变量来访问或修改其包含的数据。而这可能会导致一个潜在的问题：即当通过其中的某个变量修改数据时，便会导致所有与其他变量相关的数据访问发生改变。</p><p>因此，aliasing 使得编译器难以对程序进行过多的优化。而在 C 语言中，<code>restrict</code> 关键字便可以解决这个问题。当然，如果你学习过 Rust，这也是其所有权机制的核心内容。下面我们来看一个例子。</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\nvoid foo(int* x, int* y, int* restrict z) {\n  *x += *z;\n  *y += *z;\n}\nint main(void) {\n  int x = 10, y = 20, z = 30;\n  foo(&amp;x, &amp;y, &amp;z);\n  printf(\"%d %d %d\", x, y, z);\n  return 0;\n}\n</code></pre><p>在这段代码中，函数 foo 共接收三个整型指针参数，它的功能是将第三个指针指向变量的值，累加到前两个指针指向的变量上。其中，第三个参数 <code>z</code> 被标记为了 <code>restrict</code> ，这表明我们向编译器做出了这样一个承诺：即在函数体 foo 内部，我们只会使用变量 <code>z</code> 来引用传入函数第三个指针参数对应的内存位置，而不会发生 aliasing。这样做使得编译器可以对函数的机器码生成做进一步优化。</p><p>来看下上面这段 C 代码对应的汇编代码：</p><pre><code class=\"language-c++\">foo:\n&nbsp; &nbsp; &nbsp; &nbsp; mov&nbsp; &nbsp; &nbsp;eax, DWORD PTR [rdx]\n&nbsp; &nbsp; &nbsp; &nbsp; add&nbsp; &nbsp; &nbsp;DWORD PTR [rdi], eax\n&nbsp; &nbsp; &nbsp; &nbsp; add&nbsp; &nbsp; &nbsp;DWORD PTR [rsi], eax\n&nbsp; &nbsp; &nbsp; &nbsp; ret\n</code></pre><p>我们可以发现，在使用 <code>restrict</code> 关键字标注了 foo 函数的第三个参数后，在为指针 <code>y</code> 进行值累加前，编译器不会再重复性地从内存中读取指针 <code>z</code> 对应的值（对应上面第一行代码）。而这对程序的执行来说，无疑是一种性能上的优化。</p><p>另外你需要注意的是，若一个指针已被标记为 <code>restrict</code> ，但在实际使用时却发生了 aliasing，此时的行为是未定义的。</p><h2>技巧四：消除不必要的内存引用</h2><p>在某些情况下，可能我们只需要对程序的结构稍作调整，便能在很大程度上提升程序的运行性能。你可以先看看下面这段代码，思考下优化方式：</p><pre><code class=\"language-c++\">#define LEN 1024\nint data[LEN] = { ... };\nint foo(int* dest) {\n&nbsp; *dest = 1;\n&nbsp; for (int i = 0; i &lt; LEN; i++) {\n&nbsp; &nbsp; *dest = *dest * data[i];\n&nbsp; }\n}\n</code></pre><p>在这段代码中，函数 foo 主要用来计算数组 data 中所有元素的乘积，并将计算结果值拷贝给指针 dest 所指向的整型变量。函数的逻辑很简单，但当我们仔细观察函数 foo 内部循环逻辑的实现时，便会发现问题所在。</p><p>在这个循环中，为了保存乘积在每一次循环时产生的累积值，函数直接将这个值更新到了指针 dest 指向的变量中。并且，在每次循环开始时，程序还需要再从该变量中将临时值读取出来。我们知道，从内存中读取数据的速度是慢于寄存器的。因此，这里我们可以快速想到一个优化方案。优化后的代码如下所示：</p><pre><code class=\"language-c++\">#define LEN 3\nint data[LEN] = { 1,2,4 };\nint foo(int* dest) {\n&nbsp; register int acc = 1;\n&nbsp; for (int i = 0; i &lt; LEN; i++) {\n&nbsp; &nbsp; acc = acc * data[i];\n&nbsp; }\n&nbsp; *dest = acc;\n}\n</code></pre><p>在上面的代码中，我们一共做了两件事情：</p><ol>\n<li>将循环中用于存放临时累积值的 “*dest” 替换为一个整型局部变量 “acc”；</li>\n<li>在定义时为该变量添加额外的 <code>register</code> 关键字，以建议编译器将该值存放在寄存器中，而非栈内存中。</li>\n</ol><p>通过消除不必要的内存引用，我们就能够减少程序访问内存的次数，进而提升一定的性能。</p><h2>总结</h2><p>好了，讲到这里，今天的内容也就基本结束了。最后我来给你总结一下。</p><p>这一讲，我主要介绍了可用于 C 代码优化的几种常见策略，它们分别是利用高速缓存、使用代码内联和 <code>restrict</code> 关键字，以及消除不必要的内存引用，具体如下：</p><ul>\n<li>高速缓存利用了 CPU 的局部性，使得满足局部性的程序可以更加高效地访问数据；</li>\n<li>代码内联通过直接使用函数定义替换函数调用的方式，减少了程序调用 <code>call</code> 指令带来的额外开销；</li>\n<li><code>restrict</code> 关键字通过限制指针的使用，避免 aliasing，进而给予了编译器更多的优化空间；</li>\n<li>消除不必要的内存引用，则是通过减少程序与内存的交互过程，来进一步提升程序的运行效率。</li>\n</ul><h2>思考题</h2><p>最后，给你留个小作业：尝试了解一下什么是高速缓存的“抖动”，并在评论区告诉我你的理解。</p><p>今天的课程到这里就结束了，希望可以帮助到你，也希望你在下方的留言区和我一起讨论。同时，欢迎你把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"17｜标准库：断言、错误处理与对齐","id":481159},"right":{"article_title":"19｜极致优化（下）：如何实现高性能的 C 程序？","id":482493}}},{"article_id":482493,"article_title":"19｜极致优化（下）：如何实现高性能的 C 程序？","article_content":"<p>你好，我是于航。</p><p>在上一讲中，我介绍了几个用于编写高性能 C 代码的实用技巧。今天，我们继续聊这个话题，来讨论其他几种常见的 C 代码和程序优化技巧，它们分别是利用循环展开、使用条件传送指令、尾递归调用优化，以及为编译器指定更高的编译优化等级。</p><h2>技巧五：循环展开（Loop Unrolling）</h2><p>为了让你更好地理解“循环展开”这个优化技巧背后的原理，我们先从宏观角度看看 CPU 是如何运作的。</p><p>早期的 CPU 在执行指令时，是以串行的方式进行的，也就是说，一个指令的执行开始，需要等待前一个指令的执行完全结束。这种方式在实现上很简单，但存在的问题也十分明显：由于指令的执行是一个涉及多个功能单元的复杂过程，而在某一时刻，CPU 也只能够对指令进行针对当前所在阶段的特定处理。</p><p>那么，将 CPU 处理指令的流程划分为不同阶段，并让它对多条指令同时进行多种不同处理，这样是否可以进一步提升 CPU 的吞吐量呢？事实正是如此。</p><p>现代 CPU 为了进一步提升指令的执行效率，通常会将单一的机器指令再进行拆分，以达到指令级并行的目的。比如，对于一个基本的五级 RISC 流水线来说，CPU 会将指令的执行细分为指令提取（IF）、指令译码（ID）、指令执行（EX）、内存访问（MEM），以及寄存器写回（WB）共五个步骤。</p><!-- [[[read_end]]] --><p>在这种情况下，当第一条机器指令经过了指令提取阶段的处理后，即使该条指令还没有被完全执行完毕，CPU 也可以立即开始处理下一条机器指令。因此，<strong>从宏观上来看，机器指令的执行由串行变为了并行，程序的执行效率得到了提升</strong>。</p><p>其中，指令提取是指从内存中读取出机器指令字节的过程。CPU 根据得到的指令字节，在译码阶段，从相应的寄存器中获得指令执行所需要的参数。而在执行阶段，ALU 可以选择执行指令明确的操作，或者是计算相关内存引用的有效地址等操作。随后，在访存阶段，根据指令要求，CPU 可以将数据写回内存，或从内存中读出所需数据。类似地，在写回阶段，CPU 可以将指令执行得到的结果存入寄存器。</p><p>而当五个阶段全部执行完毕后，CPU 会更新指令指针（PC），将其指向下一个需要执行的指令。你可以通过下图来直观地理解这个过程：</p><p><img src=\"https://static001.geekbang.org/resource/image/b5/3a/b5ed49da043c67f5ef05d54dd03fe33a.jpg?wh=2248x1106\" alt=\"\"></p><p>那么，如何将 CPU 的吞吐量最大化呢？相信你心中已经有了答案。我们需要做的，就是<strong>让 CPU 在执行程序指令时，能够以满流水线的方式进行</strong>。</p><p>但现实情况并非总是这样理想。这里，我要介绍的代码优化技巧“循环展开”便与此有关。让我们先来看一段代码：</p><pre><code class=\"language-c++\">#define LEN 4096\nint data[LEN] = { ... };\nint foo(void) {\n&nbsp; int acc = 1;\n&nbsp; for (int i = 0; i &lt; LEN; ++i) {\n&nbsp; &nbsp; acc = acc * data[i];\n&nbsp; }\n&nbsp; return acc;\n}\n</code></pre><p>在这段代码中，我们定义了一个名为 data 的全局整型数组，并在其中存放了若干个值。而函数 foo 则主要用来计算该数组中所有数字的乘积之和。</p><p>此时，如果我们在 main 函数中调用函数 foo，CPU 在实际执行它的代码时，<code>for</code> 循环的每一轮都会产生两个数据相关：循环控制变量 i 的下一个值依赖于本次循环变量 i 在经过自增运算后得到的结果值。同样地，计数变量 acc 的下一个值也依赖于该变量在当前循环中经过乘积计算后的结果值。</p><p>而这两个数据相关会导致 CPU 无法提前计算下一轮循环中各个参与变量的值。而只有在寄存器写回，或内存访问阶段执行完毕，也就是变量 acc 和 i 的值被最终更新后，CPU 才会继续执行下一轮循环。</p><p>那么，应该如何优化这个过程呢？我们直接来看优化后的代码：</p><pre><code class=\"language-c++\">#define LEN 4096\nint data[LEN] = { ... };\nint foo(void) {\n&nbsp; int limit = LEN - 1;\n&nbsp; int i;\n&nbsp; int acc0 = 1;\n&nbsp; int acc1 = 1;\n&nbsp; for (i = 0; i &lt; limit; i += 2) {  // 2x2 loop unrolling.\n&nbsp; &nbsp; acc0 = acc0 * data[i];\n&nbsp; &nbsp; acc1 = acc1 * data[i + 1];\n&nbsp; }\n&nbsp; for (; i &lt; LEN; ++i) {  // Finish any remaining elements.\n&nbsp; &nbsp; acc0 = acc0 * data[i];\n&nbsp; }\n&nbsp; return acc0 * acc1;\n}\n</code></pre><p>可以直观地看到，参与到程序执行的局部变量变多了。而这里的主要改动是，<strong>我们为函数 foo 中的循环结构应用了 2x2 循环展开</strong>。</p><p>循环展开这种代码优化技术，主要通过增加循环结构每次迭代时计算的元素个数，来减少循环次数，同时优化 CPU 的指令集并行与流水线调度。而所谓的 2x2 ，是指在优化后的代码中，循环的步长变为了 2，且循环累积值被分别存放在两个独立变量 acc0 与 acc1 中。</p><p>循环展开带来的最显著优化，就是减少了循环的迭代次数。使用多个独立变量存储累积值，各个累积值之间就不会存在数据相关，而这就增大了 CPU 多个执行单元可以并行执行这些指令的机会，从而在一定程度上提升了程序的执行效率。</p><p>需要注意的是，循环展开一方面可以带来性能上的提升，另一方面它也会导致程序代码量的增加，以及代码可读性的降低。并且，编译器在高优化等级下，通常也会对代码采用隐式的循环展开优化。因此，在大多数情况下，我们并不需要手动地改变代码形式来为它应用循环展开，除非是在那些你确定编译器没有进行优化，并且手动循环展开可以带来显著性能提升的情况下。</p><h2>技巧六：优先使用条件传送指令</h2><p>通常来说，CPU 指令集中存在着一类指令，它们可以根据 CPU 标志位的不同状态，有条件地传送数据到某个特定位置，这类指令被称为“<strong>条件传送指令</strong>”。举个例子，指令 <code>cmove</code> 接收两个参数 S 和 R，当 CPU 标志寄存器中的 ZF 置位时，该指令会将 S 中的源值复制到 R 中。</p><p>与条件传送指令类似的还有另外一类指令，它们被称为“<strong>条件分支指令</strong>”。顾名思义，这类指令在执行时，会根据 CPU 标志位的不同状态，选择执行程序不同部分的代码。比如指令 <code>jz</code> ，该指令接收一个参数 L，当 CPU 标志寄存器中的 ZF 置位时，该指令会将下一条待执行指令修改为 L 所在内存位置上的指令。</p><p>对于 C 代码中的某些逻辑，使用条件传送指令与条件分支指令都能够正确完成任务。但在程序的执行效率上，这两种方式却可能带来极大的差别。而这主要是由于条件分支指令可能会受到 CPU 分支预测错误带来的惩罚。</p><p>现代 CPU 一般都会采用投机执行，其中的一个场景是：处理器会从它预测的，分支可能会发生跳转的地方取出指令，并提前对这些指令进行译码等操作。处理器甚至会在还未确认预测是否正确之前，就提前执行这些指令。之后，如果 CPU 发现自己预测的跳转位置发生错误，就会将状态重置为发生跳转前分支所处的状态，并取出正确方向上的指令，开始重新处理。</p><p>由此，上述两种指令在 CPU 的内部执行上便产生了不同。由于条件分支指令会导致 CPU 在指令实际执行前作出选择，而当 CPU 预测错误时，状态的重置及新分支的重新处理过程会浪费较多的 CPU 周期，进而使程序的运行效率下降。相对地，条件传送指令不会修改处理器的 PC 寄存器，因此它不会导致 CPU 需要进行分支预测，也就不会产生这部分损失。</p><p>至于 CPU 是如何进行分支预测的，相关内容超出了这门课的范畴，这里我就不详细介绍了。但你需要知道的是，在发生类似问题时，我们可以进一步观察程序，并尝试使用条件传送指令优化这些逻辑。为了方便你理解，我们来看个例子。你可以看看下面这段代码中函数 foo 的实现细节：</p><pre><code class=\"language-c++\">#define LEN 1024\nvoid foo(int* x, int* y) {\n&nbsp; int i;\n&nbsp; for (i = 0; i &lt; LEN; i++) {\n&nbsp; &nbsp; if (x[i] &gt; y[i]) {\n&nbsp; &nbsp; &nbsp; int t = x[i];\n&nbsp; &nbsp; &nbsp; x[i] = y[i];\n&nbsp; &nbsp; &nbsp; y[i] = t;\n&nbsp; &nbsp; }\n&nbsp; }\n}\n</code></pre><p>函数 foo 接收两个整型数组 x 与 y，并依次比较这两个数组中位于相同索引位置上的元素，最后将较大者存放到数组 y 的对应位置上。我们可以看到，在遍历数组的过程中，我们在循环结构内使用了 <code>if</code> 语句，来判断数组 x 中的元素值是否大于数组 y 对应位置上的元素。而在代码实际编译时，<code>if</code> 语句通常会由对应的条件分支指令来实现。因此，在循环结构的“加持”下，由 CPU 分支预测错误引发的惩罚，在经过每一轮迭代的累积后，都可能会变得更加可观、更加明显。</p><p>下面，我们就来使用条件传送指令优化这段代码。条件传送指令一般会用于实现 C 语法中的三元运算符 <code>?:</code>，因此对上述代码的优化过程也就显而易见：</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\n#define LEN 16\nvoid foo(int* x, int* y) {\n&nbsp; int i;\n&nbsp; for (i = 0; i &lt; LEN; i++) {\n&nbsp; &nbsp; int min = x[i] &lt; y[i] ? x[i] : y[i];\n&nbsp; &nbsp; int max = x[i] &lt; y[i] ? y[i] : x[i];\n&nbsp; &nbsp; x[i] = min;\n&nbsp; &nbsp; y[i] = max;\n&nbsp; }\n}\n</code></pre><p>可以看到，这里我们没有使用 <code>if</code> 语句来判断，是否应该调整两个数组对应位置上的数字值，而是直接使用三元运算符，来将每一次迭代时的最大值与最小值结果计算出来，并拷贝到数组中的相应位置上。</p><p>通过这种方式，我们虽然解决了 CPU 分支预测失败带来的惩罚，但与此同时，每一次循环中也会多了几次比较与赋值操作。你可能想问：这样的一来一回真的可以提升性能吗？我的回答是：不要小看 CPU 指令并行处理能力的高效性，但也不要小看 CPU 分支预测带来的性能损耗。</p><h2>技巧七：使用更高的编译优化等级</h2><p>除了可以通过调整代码写法来优化程序运行外，我们还可以为编译器指定更高优化等级的选项，来让编译器自动为我们进行更多程序执行细节上的优化。</p><p>以 GCC 为例，它为我们提供了 -O0、-O1、-O2、-O3、-Os、-Ofast 等优化选项。我把它们各自的大致优化内容整理成了一张表格，你可以参考：<br>\n<img src=\"https://static001.geekbang.org/resource/image/9b/26/9b35b768yye83e26bf36a03e0c7bee26.jpg?wh=2248x1452\" alt=\"\"></p><h2>技巧八：尾递归调用优化（Tail-Call Optimization）</h2><p>尾递归调用优化也是一个重要的代码优化技巧。关于它的原理和代码编写方式，我已经在 <a href=\"https://time.geekbang.org/column/article/469250\">06 讲</a>中为你介绍过，如果你觉得记忆有些模糊了，可以返回那一讲回顾下相关知识。</p><p>总的来看，尾递归调用优化通过将函数的递归调用过程优化为循环结构，减少了程序执行时对 <code>call</code> 指令的调用次数，进而减少了栈帧的创建与销毁过程，提升了程序的执行性能。并且你需要注意，<strong>尾递归调用优化的效果在那些函数体本身较小，且递归调用次数较多的函数上体现得会更加明显</strong>。</p><h2>总结</h2><p>讲到这里，今天的内容也就基本结束了。最后我来给你总结一下。</p><p>今天我主要介绍了四种可用于实现高性能 C 程序的技巧：</p><ul>\n<li>循环展开让我们可以进一步利用 CPU 的指令级并行能力，让循环体执行得更快；</li>\n<li>优先使用条件传送指令，让我们可以在一些特定的场景中，防止使用条件分支指令带来的 CPU 周期浪费；</li>\n<li>使用更高的编译优化等级，让我们可以借编译器之手，利用更多“黑科技”进一步优化我们的代码；</li>\n<li>尾递归调用优化让我们可以用循环代替递归，减少函数调用时的栈帧创建与销毁过程，让递归进行得更快。</li>\n</ul><h2>思考题</h2><p>最后，给你留个思考题：“达夫设备（Duff’s Device）”有什么作用？它的实现原理是怎样的呢？欢迎在评论区告诉我你的发现。</p><p>今天的课程到这里就结束了，希望可以帮助到你，也希望你在下方的留言区和我一起讨论。同时，欢迎你把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"18｜极致优化（上）：如何实现高性能的 C 程序？","id":481903},"right":{"article_title":"20｜生产加速：C 项目需要考虑的编码规范有哪些？","id":483183}}},{"article_id":483183,"article_title":"20｜生产加速：C 项目需要考虑的编码规范有哪些？","article_content":"<p>你好，我是于航。</p><p>在本模块前面的几讲中，我主要介绍了可以为项目编码提速的 C 标准库，以及优化 C 代码的相关技巧。而在接下来的三讲中，我将为你介绍大型 C 项目在工程化协作时需要关注的编码规范、自动化测试和结构化编译。当项目由小变大，参与人数由少变多时，这些便是我们不得不考虑的重要内容。</p><p>和一个人参与项目、写代码时的“单打独斗”相比，多人协作从理论上来看可以大幅提高生产效率。但现实情况却可能是，效率在提升的同时，代码质量下降、沟通成本变高等一系列问题也随之而来。甚至在某些情况下，团队人数的增加反而会导致项目推进效率的降低。</p><p>那为什么会出现这样的问题呢？这是因为，当参与到项目开发中的人员数量逐渐增多时，工程师们对于代码编写规范，以及项目开发生命周期（SDLC，Software Development Life Cycle）等关键事项没有形成统一的标准。而因为代码审查不通过导致的频繁返工甚至妥协，以及协作流程上的不明确与延期，使得项目的迭代周期变长，进而生产效率下降。因此，如何为团队制定统一的编码规范，并明确 SDLC 的整体流程以及其中各节点的重点注意事项，就成为了决定团队协作效率的一个重要因素。</p><p>那么，这一讲我们就来聊一聊，对于使用 C 语言编写的、需要多人协作的项目，我们应该从哪些角度来制定团队的编码规范。这里我会以 GNU C 编码规范为例来进行介绍，在此之前，我们先来看看什么是 GNU。</p><!-- [[[read_end]]] --><h2>GNU 与 GUN？傻傻分不清楚</h2><p>你应该对 GNU 这个由三个英文字母组成的标识并不陌生，虽然有时我也会把它与“文明用语” GUN 搞混。不过你可能还不清楚，<strong>它实际上是 GNU’s Not Unix 的递归首字母缩写词，而且读音类似于中文“革奴”的发音</strong>。</p><p>具体来讲，GNU 最初是指由 Richard Matthew Stallman 于 1983 年创立的一项计划，该计划旨在创建一套完全自由的操作系统和相关系统软件的集合。该计划执行至今，除了仍然处在开发阶段的 GNU 操作系统内核 Hurd 以外，其他相关系统软件都已经得到了社区的广泛应用。其中不乏我们熟知的 GCC 编译器、GDB 调试器，以及 Emacs 文本编译器等。目前（截止到 2022 年 1 月），一共有 384 个 GNU 软件包被托管到 GNU 的官方开发站点上。其中，GCC 和 GDB 的第十二个大版本也处在紧张的开发过程中。</p><p>当年发起 GNU 计划的一个初衷，是让业界重视软件界合作互助的团结精神，而在经过了将近 40 年的发展后，这一精神可以说在 GNU 旗下的项目上被体现得淋漓尽致。以 GCC 为例，就该项目而言，被正式记载到官方贡献者列表中的开发者就超过了 500 人。而如果将它的 Git 仓库下载下来，并通过相关命令统计所有提交过代码的贡献者人数（根据邮箱区分），这个数字将高达 3500。由此可见，GCC 作为 GNU 旗下使用人数最多的开源项目之一，它能够一直以来被社区广泛采纳，除了源于自身极高的项目质量外，也离不开贡献者之间默契的协作，其中就包括在编码规范上的统一。</p><p>为了保证 GNU 旗下的开源项目都能够采用统一的代码格式，Richard Stallman 和一众来自 GNU 开源项目的志愿者，从 1992 年起便开始着手制定一套统一的编码规范，GNU Coding Standards（后简称“GNU 编码规范”）。制定这套编码规范，是为了保持 GNU 操作系统以及相关软件有干净、一致的编码风格，并保持足够高的可移植性与可靠性。这套编码规范更适用于 C 语言编写的程序，但其中的许多规则与原则也同样适用于其他编程语言。</p><p>接下来，我们就以 GNU 编码规范为例，来看一看围绕 C 语言项目制定编码规范时，具体都需要考虑哪些方面。在充分了解这些内容后，你就可以根据自己团队与项目的情况，来选择性制定更加合适的编码规范了。</p><h2>GNU C 编码规范</h2><p>GNU 编码规范将 C 语言项目需要考虑的编码细则分为了多个不同类别，下面我们来依次看看这些内容中最常用的 9 个方面。至于更具体的信息，你可以参考<a href=\"https://www.gnu.org/prep/standards/html_node/Writing-C.html#Writing-C\">这个链接</a>。</p><h3>格式</h3><p>这一类别中的规则主要约束了 C 代码的具体编写格式。比如，GNU 规范建议将每一行代码的字符数量保持在 79 个以内，以便在大多数情况下获得最好的代码可读性；C 函数定义时使用的开始花括号 “{” 建议作为每行的第一个字符，这样有助于兼容大多数代码分析工具。而类似地，为了更好地识别函数定义，函数名称同样需要放置于每行的起始位置，同时也利于某些特定工具对函数的识别。</p><p>除此之外，在函数定义或声明中，若函数参数过长，则需要将超过行长度限制的参数放到函数名所在的下一行，并与上一行中第一个参数的开头保持对齐。而对于结构或枚举类型，可以选择在符合行长度限制的情况下，将它们在一行内完整定义。或采用类似函数的定义方式，将包裹定义的开始与结束花括号放置在单独一行，两行之间为具体的定义内容。</p><p>你可以看下这个例子，它便符合我在上面提到的几点 GNU 编码规范对代码格式的要求：</p><pre><code class=\"language-c++\">int\nlots_of_args (int an_integer, long a_long, short a_short,\n              double a_double, float a_float)\n{\n  // ...\n}\nstruct foo \n{\n  int a, b;\n}\nstruct bar { int x, y; }\n</code></pre><p>这里我们提到的仅是一些较为重要的代码格式化规则，但除此之外，还有很多其他 GNU 代码格式要求的规范细节。关于这些内容，你可以参考 GNU 旗下的 <code>indent</code> 工具。</p><p>这个工具提供了多种不同选项，可以对 C 源代码应用多种不同的代码格式化风格，你可以点击<a href=\"https://www.gnu.org/software/indent/manual/indent.html\">这个链接</a>来了解这些信息。这些风格主要针对缩进、括号，以及换行等字符或语法元素在特定代码场景中的不同使用方式。但无论哪种方式，<strong>你都需要确保在同一个 C 项目中，仅使用唯一的一种风格（规则）来格式化你的代码</strong>。</p><h3>注释</h3><p>注释的用途显而易见。一个优秀程序的最基本特征，就是可以让任何一个工程师都能在最短的时间内，了解这个程序的基本实现逻辑。而注释就是达成这一目的的“秘密武器”。</p><p>在文件方面，GNU 规范建议程序 main 函数所在源文件应以描述程序基本用途的注释作为开头，而其他源文件则以文件名和描述该源文件基本功能的注释作为开头。</p><p>对于函数，则需要为其添加用于描述函数基本功能、参数类型、参数用途、参数可能取值，以及返回值含义（如果有）等内容的注释信息。对于每一个全局和静态变量，也应该为其添加相应的注释，来描述它们的基本用途与可能取值。除基本 C 语法代码外，诸如预处理指令 #else 与 #endif 也需跟随有相应的注释，以标注相应分支的位置和含义。</p><p>一般情况下，为保证国际化和通用性，应以英语形式撰写注释。若代码与注释在同一行，则注释应起始于该行代码最后一个字符后间隔两个空格的位置。注释应使用完整的句子，并在一般情况下保持首字母大写。最后需要注意的是，<strong>若在注释中谈论到了变量的值，则应将该变量对应标识符完全大写</strong>。比如在注释文本“the inode number NODE_NUM” 中提到的 NODE_NUM ，便代表 C 代码中变量 node_num 对应的具体值。</p><h3>语法约定</h3><p>这部分规范对 C 语言编码时需要遵循的一些基本习惯作出了规定。这里举几个例子：</p><ul>\n<li>显式地为所有使用到的值标注类型，尤其是直接使用在表达式中的数字字面量值；</li>\n<li>选择性地为编译器添加 “-Wall” 参数，并根据警告信息来优化代码；</li>\n<li>选择性地看待静态代码分析工具给出的建议，在不影响程序正常功能的情况下，不要为了满足它们的要求而牺牲代码可读性；</li>\n<li>外部函数和后续才会使用函数的声明，应该被放置在当前源文件开头处统一的地方，或选择放在单独的头文件中；</li>\n<li>使用名字具有一定意义的不同变量来完成不同任务，且尽量使变量的声明处在恰好可以完成其“任务”的最小作用域中。除此之外，也不要声明会遮盖全局变量的局部变量。</li>\n</ul><p>在代码写法上，GNU 代码规范也作出了规定，比如：</p><ul>\n<li>不要将通过一个类型关键字声明的多个变量分散在多行；</li>\n<li>可以将同类型的多个变量放在同一行声明，或选择在不同行使用独立的声明语句来声明多个变量；</li>\n<li>当使用嵌套的流程控制语句（比如 <code>if</code> 语句）时，总是将内部的嵌套逻辑包裹在大括号中，以保证代码清晰可读；</li>\n<li>尽量避免在 <code>if</code> 语句的条件判断处，也就是小括号内部做赋值操作（而在 <code>while</code> 语句中是可以的）。</li>\n</ul><h3>命名</h3><p>编码中的命名规范可以说是理解起来最简单，而行动上最复杂的部分。在 C 语言项目中，程序内使用到的全局变量和函数，它们的名称有时可以直接替代注释来说明它们的功能。因此，<strong>需要确保对于它们的命名是具有一定意义的</strong>。而相对地，局部变量由于仅作用在一个较短的上下文中，它的名字可以更短，只要能大概描述它的作用即可。</p><p>变量名一般采用下划线命名法，即通过下划线将其中不同的单词进行分割。变量名中可以使用缩写，但需要确保这些缩写是已经被人们熟知的，而不会产生任何歧义。并且，<strong>尽量仅使用小写字母、数字和下划线来组成变量名，</strong><strong>而把大写字母留给对宏常量以及枚举常量命名</strong>。另外，当需要定义数字常量值时，请优先使用枚举常量而非宏常量，这将有利于调试器对程序执行逻辑的分析。比如下面这段代码：</p><pre><code class=\"language-c++\">enum Settings {\n&nbsp; LIMITATION = 1000\n};\nconst char* author_name = \"Jason\";\nconst int author_age = 28;\n</code></pre><h3>系统可移植性</h3><p>GNU 规范中提到的“系统可移植性”主要是指将 C 应用移植到不同 Unix 版本系统上的能力。对于 GNU 程序来说，这种可移植性是可取的，但并非最重要的。</p><p>通常来说，你可以直接使用 GNU 旗下的 Autoconf 工具来部分实现这种能力。Autoconf 支持多种 Unix 系统，它可以根据当前所在宿主环境，自动生成进行程序编译所需的配置文件，比如 Makefile 与 configure 脚本文件。对于其他非 Unix 系统，则需要针对目标系统做特殊的兼容性开发。除此之外，在程序中应该尽量使用来自标准库（如 C 标准库、POSIX 标准接口等）中的函数，而非与特定系统强相关的底层能力。</p><p>最后，可以选择为 C 语言项目定义名为“_GNU_SOURCE” 的宏常量，当在 GNU 或 GNU/Linux 系统上编译定义有该宏常量的 C 项目时，预处理器会“启用”所有的 GNU 库扩展函数。这样，编译器在编译项目时，便会及时检查是否存在用户的自定义函数导致这些库函数被覆盖的问题。在保证程序系统兼容性方面，这是可以关注的一个点。</p><h3>CPU 可移植性</h3><p>不同 CPU 之间可能会存在着字节序、对齐要求等差异。因此，我们在编码时不应该假设一个 <code>int</code> 类型变量在内存中的起始地址与它的最低有效位（LSB）地址相同。同样地，<strong>当使用 <strong><code>char</code></strong> 类型时，应显式指出它的符号性</strong>。对于指针，应尽量避免出现将指针类型转换成数字值的过程，以保持程序最大的兼容性。</p><p>对于基本类型大小，GNU 标准不会处理 <code>int</code> 类型小于 32 位的情况。同样，也不会考虑 <code>long</code> 类型小于指针类型和 <code>size_t</code> 类型的情况。</p><h3>系统函数</h3><p>C 程序可以通过调用 C 标准库或 POSIX 库提供的函数，来使用相应的系统功能，但这些库函数在某些系统上可能存在着相应的可移植性问题。而借助 Gnulib，我们可以在一定程度上解决这个问题。</p><p>Gnulib 是 GNU 旗下的可移植性库，它为许多缺乏标准接口的系统提供了对标准接口的实现，其中包括对增强型 GNU 接口的可移植性实现等。Gnulib 可以直接与 GNU Autoconf 和 Automake 集成使用，来减少程序员编写可移植代码时的大部分负担。Gnulib 使得我们可以通过配置脚本，来自动确定缺少哪些功能，并使用 Gnulib 中的代码来“修复”缺少的部分。</p><h3>国际化</h3><p>GNU 规范也考虑到了 C 程序国际化的问题。同解决系统函数可移植性问题一样，GNU 也提供了名为 GNU gettext 的库，可以轻松地将程序中的消息翻译成各种语言。</p><h3>字符集</h3><p>在 GNU 源代码注释、文本文档，以及其他相关上下文中，请首选使用 ASCII 字符集中的字符。如果需要使用非 ASCII 字符，我们要确保文档的编码方式保持统一。通常来说，<strong>UTF-8 应是首选的编码方式</strong>。</p><h2>总结</h2><p>好了，讲到这里，今天的内容也就基本结束了。最后我来给你总结一下。</p><p>这一讲，我以 GNU 编码规范为例，介绍了在进行 C 项目编码时我们需要注意的几方面内容。从最基本的编码格式到可能影响程序正确运行的可移植性，这些内容涵盖了一个完整 C 工程项目在制定编码标准时需要考虑的绝大部分问题。</p><p>GNU 编码规范的出发点，是确保所有 GNU 旗下项目都能够采用统一的编码行为，以保证这些软件都能够在 GNU 操作系统上正确无误地运行。了解 GNU 规范的基本内容之后，你就能以此为基础，根据自身需求制定更加详细和个性化的 C 编码规范。</p><p>编码规范的制定，是项目从单人开发逐渐走向多人协作，让团队效率达到 1+1&gt;2 效果的必经之路。因此，如何合理制定规范并加以落实并持续实践，是一个非常值得关注的问题。</p><h2>思考题</h2><p>最后想请你来聊一聊：你所在的团队是否制定了相应的编码规范？如果制定了，是怎样落实的？践行过程中又是否遇到哪些问题呢？欢迎在留言区告诉我你的想法。</p><p>今天的课程到这里就结束了，希望可以帮助到你，也希望你在下方的留言区和我一起讨论。同时，欢迎你把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"19｜极致优化（下）：如何实现高性能的 C 程序？","id":482493},"right":{"article_title":"21｜生产加速：如何使用自动化测试确保 C 项目质量？","id":484677}}},{"article_id":484677,"article_title":"21｜生产加速：如何使用自动化测试确保 C 项目质量？","article_content":"<p>你好，我是于航。</p><p>“测试”是每个软件在其开发生命周期（SDLC）中都不可或缺的一个重要阶段。通过对软件进行各种不同类型的测试，我们能够从多个维度验证软件的功能表现，并在出现偏差时及时修正，以确保它们可以按照预期工作。根据实施方式、深入粒度、应用场景及目的等因素的不同，测试可以被分为多种类型。其中，有些测试较为基础和通用，甚至被作为软件开发流程中的必备一环；而有些测试则仅适用于某些特定情况。</p><p>因此，为了尽量保证本讲内容的通用性，这里我挑选了 C 项目中最为常用的几种测试类型，主要包括单元测试、集成测试、功能测试与性能测试。接下来，我将为你分别介绍它们的作用，以及它们之间的区别和联系，还有如何进行这些测试。在这一讲的最后，我还会介绍什么是自动化测试，以及如何更进一步地做到“真正”的测试自动化。</p><h2>单元测试</h2><p>我们先来看通常会最先接触到的一种测试类型，单元测试（Unit Testing）。顾名思义，单元测试就是对组成程序整体结构的基本单元（也可称为模块）进行功能正确性验证的过程。它的目标是，隔离程序的每个部分，并单独验证这些部分能否按照预期正常工作。<strong>对于 C 程序来说，这<strong><strong>里的</strong></strong>单元通常为程序使用到的各个函数</strong>。</p><p>既然要对这些基本单元的功能进行测试，那便需要编写一些代码来使用这些单元，并为它们提供多种不同输入，来验证相应的输出或副作用变化是否符合单元的正常功能实现。而为了让目标单元在测试过程中正常运作，我们通常还需要为它准备特定的配套测试环境，比如用于替换真实代码（如外部函数调用）的桩（Stub）代码，以及各类 Mock 资源（如 DB 访问层、外部 API 接口）等。这样做的目的在于，隔离单元需要依赖的外部环境，使测试范围可以尽量集中在单元的内部逻辑上。</p><!-- [[[read_end]]] --><h3>使用 CUnit 进行 C 单元测试</h3><p>CUnit 是一个专门用于 C 语言的轻量级单元测试框架。接下来，我就通过它来向你展示一个最基本的单元测试用例是如何编写的。直接来看下面这段代码：</p><pre><code class=\"language-c++\">// ...\nint maxi(int x, int y) {  // 被测试函数；\n&nbsp; return (x &gt; y) ? x : y;\n}\nvoid test_maxi(void) {  // 测试用例；\n&nbsp; CU_ASSERT(maxi(0, 2) == 2);\n&nbsp; CU_ASSERT(maxi(0, -2) == 0);\n&nbsp; CU_ASSERT(maxi(2, 2) == 2);\n}\n// ...\n</code></pre><p>关于 CUnit 的具体使用方式，这里我不过多介绍了，你可以点击<a href=\"http://cunit.sourceforge.net/index.html\">这个链接</a>来查看更多信息。</p><p>在这段代码中，我们为函数 maxi 编写了一个基本的单元测试用例 test_maxi。maxi 函数在执行时会接收两个整型参数，并返回两者中值较大的那一个。作为测试用例，test_maxi 方法在它的内部便会按照被测试函数的已知功能逻辑，来验证不同输入下对应输出的正确性。可以看到，我们在用例中分三次调用了 maxi 函数，并将返回值与相应的正确结果值进行比较（“==”）。而借助 CU_ASSERT 等一系列断言函数，框架可以在测试运行后，帮助我们从整体角度追踪各个具体测试用例的执行情况，并给出相应的测试报告。</p><p>当单元测试进行完毕后，我们可以得到如下图所示的测试报告。这里，测试结果会按照测试用例的不同类别分开展示。比如对 CUnit 来说，多条断言语句通常组成一个针对某个具体单元的 Test 函数，而多个相关的 Test 函数则组成一个针对某类功能的 Suite 测试函数集。</p><p><img src=\"https://static001.geekbang.org/resource/image/yy/bc/yy47bbfcb62985e87431554dd7babbbc.png?wh=1082x650\" alt=\"图片\"></p><p>当然，除了可用于测试基本逻辑条件的断言外，CUnit 还提供了名为 CU_PASS 和 CU_FAIL 的断言，可用于测试程序的执行流是否符合预期，比如下面这段示例测试代码：</p><pre><code class=\"language-c++\">// ...\nstatic jmp_buf buf;\nvoid foo(void) {}\nvoid test_longjmp(void) {\n&nbsp; int i = setjmp(buf);\n&nbsp; if (i == 0) {\n&nbsp; &nbsp; foo();\n&nbsp; &nbsp; CU_PASS(\"run_other_func() succeeded.\");\n&nbsp; } else {\n&nbsp; &nbsp; CU_FAIL(\"run_other_func() issued longjmp.\");\n&nbsp; }\n}\n// ...\n</code></pre><p>这里，我们用上述两个断言测试了函数 foo 在执行时，是否调用 longjmp 改变了程序的执行流程。代码的逻辑十分简单，你可以结合我在 <a href=\"https://time.geekbang.org/column/article/475867\">12 讲</a> 中介绍的非本地跳转执行方式，来理解这个测试用例的具体执行过程。</p><h2>测试框架的其他重要能力</h2><p>关于 C 项目可以使用的更多单元测试框架，你可以点击<a href=\"https://en.wikipedia.org/wiki/List_of_unit_testing_frameworks#C\">这个链接</a>查阅相关信息。</p><p>作为测试框架，CUnit 仅提供了与单元测试相关的最基础，也是最核心的功能，即通过设置断言来追踪目标单元（函数）在不同输入下的执行结果是否正确。但除此之外，TAP、Fixture、Generator，以及生成 Code Coverage 等能力，也是用于完善单元测试，甚至是支持其他类型测试进行的重要功能。接下来我将为你逐一介绍它们的基本作用。</p><p>其中，TAP（Test Anything Protocol）是一种标准协议，该协议定义了一种独立于编程语言的特定文本格式，可用于表示测试用例的执行结果。你可以观察下面的文本，对它的格式有个大致印象：</p><pre><code class=\"language-plain\">1..4\nok 1 - Input file opened\nnot ok 2 - First line of the input valid\nok 3 - Read the rest of the file\nnot ok 4 - Summarized correctly # TODO Not written yet\n</code></pre><p>TAP 通过一种可移植的方式，将测试结果从不同的测试框架中“抽离”出来，并将其展示格式统一化。这样做的好处在于，对测试结果进行统一的收集、分析和处理将变得更加容易。你可以点击<a href=\"https://testanything.org\">这个链接</a>，来了解有关 TAP 的更多信息。</p><p>Fixture 为我们提供了可以在测试用例执行前后，对测试环境进行准备和清理的能力。在简单的场景中，我们可能需要在测试进行前创建一些必要的模拟数据（比如通过 malloc 创建的堆对象），并且在测试结束后再对它们进行清理。而在一些复杂场景中，我们还可能需要提前将准备好的测试数据集填充到数据库中，然后在测试完成后，及时清空数据库内容，并断开连接。</p><p>在支持 Fixture 功能的 C 测试框架中，相关能力可能会通过宏函数，或通过实现带有特定名称回调函数的形式被提供。用户可以通过这些方式，来指定整个测试过程在不同时刻需要执行的不同任务。</p><p>至于 Generator，它的功能很直观地体现在它的名字上。借助 Generator，我们可以让测试代码根据指定规则来自动生成测试用例所需要使用的各类数据。通过这种方式，测试将变得更具动态性，且流程也更加自动化。</p><p>而 Code Coverage，即代码覆盖率，是用于衡量一个项目测试用例完备性的重要指标。该指标的值为当测试用例运行时，其所能够测试到的不同程序逻辑的比例。按照维度的不同，这个覆盖率可以被细分为函数覆盖率、指令覆盖率、判断覆盖率，等等。总的来看，代码覆盖率一定是越高越好。但现实情况中，并非所有类型的代码覆盖率都能到全覆盖，即 100% 覆盖。</p><p>最后，我们需要知道，并不是所有测试框架都支持我们上面提到的这些测试辅助功能，它们中的某些功能可以由另外的独立框架或库单独提供。</p><h2>C 项目常用的其他测试</h2><p>接下来，我们再来看看除单元测试外的其他几种常用测试类型。</p><h3>集成测试</h3><p>当组成程序的各个单元都能够正常工作时，我们便可以将测试的粒度进一步扩大，来看看当不同单元或模块被整合在一起时，它们是否也可以很好地协同工作。而这类测试通常被称为“集成测试（Integration Testing）”。</p><p>我给你举一个简单的例子：对于一个在线购物系统，我们通常会提供“用户注册”的功能，以便让系统使用者可以用合法的方式建立账户。假设这个功能对应于代码中名为 signUp 的函数，由于注册的流程涉及到接收网络请求、更新数据库记录等一系列操作，因此，该函数在内部实现时，便需要调用与网络和数据库操作，以及注册逻辑计算等功能相关的另外一些函数。而在这种情况下，当我们对 signUp 函数使用来自于真正外部依赖项的资源进行测试时，便是进行了一次集成测试。</p><p>可以看到，这类测试通常需要使用数据库、网络连接等真实的外部资源，因此在使用测试框架进行测试时，便需要利用框架提供的 Fixture 等功能，来在测试执行前正确地配置相关环境。</p><p>另外需要注意的是，<strong>并非每一种测试类型都有与其直接对应的一种专用测试框架</strong>。测试框架的目的只是为你提供进行测试的一系列相关能力。而用例的测试主体（如单个函数或多个函数）、测试的功能范围，以及进行方式（如使用桩代码和模拟资源，或使用真实系统环境）等因素，才综合决定了测试的所属类型以及相应目的。</p><p>因此，你可以直接使用支持 Fixture 功能的测试框架来实现 C 项目的集成测试。其中，Fixture 用于初始化测试用例需要使用的相关外部环境依赖，而断言则用于验证测试用例的执行结果。</p><h3>功能测试</h3><p>功能测试（Functional Testing）的目的与集成测试十分类似，但也稍有不同。相同点在于，两者在测试时都涉及程序的多个单元，并使用真实的外部依赖来提供测试所需要的资源；而不同点在于，功能测试对测试结果的正确性要求可能会更加严格。通常，这个结果需要满足业务需求中的相应规定。</p><p>举个例子：在集成测试中，我们在验证某个测试用例是否通过时，可能仅会关注用例中的函数在调用后，是否返回了某个类型的值。而在功能测试中，相应的用例在返回该类型值时，受限于业务需求的约束，值的具体表现形式（如浮点数值保留的位数、字符串值的固定宽度等）也必须满足相应要求。</p><p>功能测试的目标在于验证整个应用程序的全部功能，或部分子功能是否可以按照业务需求正常运作。它是软件在被正式提交或上线前确保其质量的最重要一环。</p><h3>性能测试</h3><p>除此之外，性能测试（Performance Testing）也是 C 语言项目必不可少的一个重要测试类型。</p><p>我在<a href=\"https://time.geekbang.org/column/article/481903\">18讲</a> 中曾提到过，粗略来看，可以直接使用“运行时间”和“内存使用率”这两个指标来作为程序运行性能的度量单位。但除此之外，由于软件系统的整体架构可能有所不同，因此，更多场景下的细分性能指标也显得十分重要。</p><p>在大多数情况下，我们可以使用 Perf 来进行 Linux 系统上的应用性能测试。Perf 是一个在 Linux 2.6 以上内核版本中添加的程序性能调试工具，功能十分强大。它提供了一系列常用且精细的性能指标，并抽象了不同 CPU 在硬件上的差异，以便更加统一地“评价”不同体系上的程序性能情况。</p><p>Perf 以命令行的形式使用，通过指定不同参数，我们可以测量程序在软件和硬件层面的多种性能指标，比如程序运行期间发生的页错误数量、经过的 CPU 时钟数、CPU 分支预测失败的次数，等等。当然，某些硬件指标是否可用，还要看对应 CPU 上的 PMU（Performance Monitoring Unit）单元是否支持。</p><p>比如，通过 <code>perf stats</code> 命令，我们可以查看某个程序在运行时，有关 CPU 计数器的一些关键信息。可能的输出结果如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/00/54/0051883c65ee49c6dd1b9630acf3e754.png?wh=1058x526\" alt=\"图片\"></p><p>你可以点击<a href=\"https://perf.wiki.kernel.org/index.php/Tutorial#:~:text=Perf%20is%20a%20profiler%20tool%20for%20Linux%202.6%2B,article%20demonstrates%20the%20perf%20tool%20through%20example%20runs.\">这个链接</a>，来查看有关上图中各个指标以及 Perf 工具的更多信息。</p><p>在 macOS 与 Windows 平台上，我们也可以相应地使用名为 <a href=\"https://help.apple.com/instruments/mac/current/#\">Instruments</a> 与 <a href=\"https://docs.microsoft.com/en-us/windows-hardware/test/wpt/windows-performance-recorder\">WPR</a> 等工具，来进行类似的软件性能测试。当然，它们的具体使用方式和支持的测量指标可能有所不同，你可以点击上文中的相应链接来了解关于它们的更多信息。</p><h3>其他测试</h3><p>除了我在上面提到的几种常见测试类型外，其他测试方法还有兼容性测试、安全性测试、无障碍测试、端到端测试等，它们在不同的场景下也同样发挥着重要作用。而上面讲过的功能测试，通常也可以再被细分为冒烟测试、回归测试、健全测试等几种子类型，它们都对软件的功能进行测试，但侧重点却各不相同。</p><p>比如，对于敏捷开发模式下的软件交付，由于新功能会以固定周期的间隔不断迭代，如何合理应用回归测试来确保已有功能的正常运作，便成为软件交付中的重要一环。而在瀑布开发模式中，软件会作为一个整体进行交付，因此，如何通过完备的系统测试来保障用户功能工作正常，就相对更加重要。而在某些需要软硬件结合的项目中，受到软件与硬件开发模式不一致等因素的制约，就需要把更多不同类型的测试组合起来使用，以确保整个系统可以稳定运转。</p><p>“软件测试”是一个庞大而复杂的话题，在不同的软件开发策略和软件架构下，需要侧重应用的测试种类都会有所不同。而且，从实际情况来看，不同技术项目、不同团队，乃至不同开发者，通常都会对同一种测试类型有着不同的理解。因此，这里我不想为你输入过多的“测试专有名词”。你可以从这一讲中提到的几种最基本的测试类型开始实践，然后再不断体会它们在整个软件开发流程中的作用。</p><h2>什么是“真正”的测试自动化？</h2><p>通常来说，我们谈到的“测试自动化”是指使用脚本或测试框架，以编程的方式代替传统的人工方式，来对软件功能进行测试的过程。因此，<strong>只要涉及了测试框架、软件或脚本的使用，我们就可以称这样的测试为自动化测试</strong>。</p><p>但与之相比更有意义的，是如何进一步地把一些重要的测试环节融入到我们的日常开发和功能迭代中，来让整个 DevOps（即软件开发、质量保证以及系统运维）的过程更加自动化。</p><p>通常的做法是，让一些针对软件基础功能的测试（如单元测试、功能测试等）成为每一次生产发布前都必须执行的环节，并指定一定的覆盖率作为通过基准。而这一般要求公司提供针对某一类项目（比如 C 语言项目）的统一发布平台，且支持对它们进行集中的持续编译、测试、部署、发布等一系列操作，并让所有相关流程可以按“管道”的方式依次有序执行。这部分内容涉及企业基础 IT 设施架构，这里我就不详细展开了，你可以点击<a href=\"https://www.cloudbees.com/continuous-delivery/continuous-integration\">这个链接</a>来获取更多信息。</p><h2>总结</h2><p>好了，讲到这里，今天的内容也就基本结束了。最后我来给你总结一下。</p><p>今天我主要介绍了与 C 语言项目有关的一些常用测试类型，包括单元测试、集成测试、功能测试与性能测试：</p><ul>\n<li>单元测试通常以函数作为单元，来测试组成程序的各个独立单元自己的功能正确性；</li>\n<li>集成测试将测试的范畴进一步扩大，它测试当多个功能单元组合在一起时，是否还能够正常运作；</li>\n<li>功能测试与集成测试类似，不过，它对测试结果的正确性要求会更加严格，而这些额外的正确性要求通常是与业务需求紧密相关的；</li>\n<li>性能测试则是每一个软件在交付前都需要进行的重要环节，它可以保证软件的运作满足用户对软件响应性等指标的要求。</li>\n</ul><p>除了这几种常见的测试类型外，兼容性测试、安全性测试等其他测试类型也在一些特定场景下发挥着重要作用。</p><p>最后，我还介绍了什么是自动化测试，以及我认为的“真正的”测试自动化。自动化测试是指借助脚本或测试框架等工具进行软件测试的过程。相较于人工测试，自动化测试使得测试用例可以被频繁多次执行，且大大降低了人工成本。而更进一步，通过结合企业统一的应用发布平台，自动化测试的过程可以与整个 DevOps 结合得更加紧密。</p><h2>思考题</h2><p>你所在团队的项目是如何进行测试的，测试过程中又遇到了哪些困难？测试覆盖率会作为生产发布的严格要求吗？欢迎在评论区跟同学们分享你的经历。</p><p>今天的课程到这里就结束了，希望可以帮助到你，也希望你在下方的留言区和我一起讨论。同时，欢迎你把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"20｜生产加速：C 项目需要考虑的编码规范有哪些？","id":483183},"right":{"article_title":"22｜生产加速：如何使用结构化编译加速 C 项目构建？","id":485191}}},{"article_id":485191,"article_title":"22｜生产加速：如何使用结构化编译加速 C 项目构建？","article_content":"<p>你好，我是于航。</p><p>在之前的课程中，我们曾遇到过很多段示例代码。而这些代码有一个共性，就是它们都十分短小，以至于可以被整理在一个单独的 .c 文件中。并且，通过简短的一行命令，我们就可以同时完成对代码的编译和程序的运行。</p><p>但现实情况中的 C 项目却往往没这么简单，动辄成百上千的源文件、各种各样的外部依赖与配置项，这些都让事情变得复杂了起来。因此，当 C 项目的体量由小变大时，如何组织其源代码的目录结构与编译流程，就成了我们必须去着重考虑的两个问题。而今天我们就来聊一聊，应该从哪些角度看待这两个问题。</p><h2>如何组织 C 项目的源代码目录结构？</h2><p>我们先来看与源码目录结构相关的话题。其实，对于 C 项目的源代码目录结构，应该使用哪种组织方式，通常没有所谓的“最佳实践”，而是要具体问题具体分析。</p><p>对于小型项目，我们可以简单地将 .h 与 .c 这两类源文件分别归纳在两个独立的目录 include 与 src 中，甚至是全部混放在同一个目录下。而当项目逐渐变大时，不同的 C 源文件就可以按照所属功能，再进行更细致的划分。</p><p>比如，能够以模块为单位，以库的形式进行抽象的实现，可以统一放在名为 libs 的目录下进行管理。而使用库接口实现的应用程序代码，则可放置在名为 src 的目录中。其他与 C 源代码没有直接关系的文件，可以自由保存在项目根目录，或放置在以对应分类命名的独立目录内。</p><!-- [[[read_end]]] --><p>在下图中，我给出了两种你可以参考的目录结构。但需要注意的是，并没有默认的或最好的 C 项目目录结构，无论采用哪种形式，你都要随着项目的发展而学会不断变通。</p><p><img src=\"https://static001.geekbang.org/resource/image/77/bb/77afa57230c1606fa79940fc31f1f3bb.png?wh=1920x1516\" alt=\"图片\"></p><p>对于源代码目录结构的组织，一个基本原则是“清晰易懂”。其中，“清晰”是指即使在不了解具体实现的情况下，仅通过一层层展开项目代码的目录树，我们也能够以自顶向下的方式，来了解它在代码层面的基本组成结构。而“易懂”则是指在上面这个过程中，通过观察文件夹和文件的名字，我们可以对项目的基本功能与模块化实现有一个大致印象。</p><h2>如何组织 C 项目的编译流程？</h2><p>随着源代码目录被不断调整，项目的编译流程也相应地发生了变化。</p><p>假设有一个简单的 C 项目，它一共包含有三个源文件。按照我在上面介绍的第一种目录组织方式，这些文件被分别整理在项目根目录下的 src 与 include 文件夹内。而它们各自包含的内容则如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/d0/6a/d0159509d46a6211908d1d034d75da6a.png?wh=1920x571\" alt=\"图片\"></p><p>其中，文件 src/main.c 为程序入口 main 函数的所在文件。而 src/mod.h 与 include/mod.c 两个文件，则一同为模块 mod 提供了相应的外部接口声明与具体实现。</p><p>按照我们之前的习惯，通过下面这行命令，便能够借助 GCC 编译器来完成对这个项目的编译过程。其中，我们指定了所有需要参与编译的 .c 文件。使用 <code>-I</code> 选项，我们为编译器指定了在查找头文件时，需要搜索的目录，即 “./include”。而使用 <code>-l</code> 选项，程序运行时依赖的 math 数学库可以在运行时被顺利链接。</p><pre><code class=\"language-plain\">gcc src/main.c src/mod.c -I./include -lm -o bin/main\n</code></pre><p>到这里，你可能会觉得相较于单文件 C 应用来说，多文件 C 应用的编译也不过如此，只是命令中参与编译的源文件数量和使用到的配置项多了一些。</p><p>但随着项目体量的逐渐增大，这种编译方式会面临两个重要问题。首先便是如何对冗长的编译命令进行管理。这个问题关系到，<strong>我们是否可以清楚地知道项目每次编译时的具体状态，以及能否快速准确地对这些配置项进行相应修改</strong>。</p><p>其次，上述命令在每一次执行时，都仅会生成最终的二进制可执行文件，这使得编译的中间结果无法被有效利用。因此，代码在每一次修改后，都需要再次经历完整的编译流程。对于大型项目来说，这无疑降低了开发效率。</p><p>那有没有办法来解决这两个问题呢？答案是肯定的。首先来看，我们可以如何利用 Makefile 来进行结构化的 C 项目编译。</p><h3>使用 Makefile 进行结构化编译</h3><p>Makefile 是一种在（类）Unix 操作系统中常用的，用于组织项目代码编译流程的方式，它通常需要配合名为 make 的构建自动化工具一起使用。</p><p>make 最初由贝尔实验室的 Stuart Feldman 于 1976 年实现，后来被整合到了 Unix 系统中。make 在执行时，会去搜索当前目录下名为 Makefile 的文本文件，并按照其内部指定的一系列规则，有序地对项目进行编译。</p><p>比如，对于上面提到的例子，我们可以编写如下所示的一段文本内容，并将它保存到项目根目录下名为 Makefile 的文件内。紧接着，通过在该文件所在目录下直接执行 make 命令，项目得以被正确编译。</p><pre><code class=\"language-plain\">bin/main: src/main.c src/mod.c\n  gcc src/main.c src/mod.c -I./include -lm -o bin/main\n</code></pre><p>Makefile 使用了一种与声明式编程语言类似的简化语法，以方便开发者灵活配置项目的编译流程。这里，上述配置文本的第一行指定了一个编译目标（bin/main），以及与该目标相关的依赖文件（src/main.c 与 src/mod.c）。而接下来以 Tab 键缩进的所有行（这里即第二行），均用于配置依赖文件到目标文件的编译转换细节。可以看到，我们使用了与之前完全相同的命令来实现这个过程，但是两者在编译时的差异已逐渐显现。</p><p>通过这种方式，我们已经部分解决了之前提到的问题，即每一次代码修改后，由于直接运行编译命令导致“全量编译”，进而带来的开发效率下降。make 命令在每次实际进行编译前，都会首先追踪各个编译目标与其依赖项的版本信息（通常为“最后修改时间”）。而只有当相关依赖的内容在上一次编译后发生改变，或目标文件不存在时，才会再次编译该目标。通过这种方式，我们可以<strong>将大部分时间内的项目编译过程都集中在必要的几个源文件上</strong>，而不用“浪费”已编译好的其他中间目标文件。</p><p>接下来，我们尝试进一步优化 Makefile 中的配置项，来让最终的二进制编译目标与各个中间依赖项作进一步分离。并且，通过抽离编译命令中的可配置部分，我们也可以让整个编译脚本变得更具可读性与可用性。优化后的文件内容如下所示：</p><pre><code class=\"language-plain\"># 用于控制编译细节的自定义宏；\nCC = gcc\nCFLAGS = -I./include\nLDFLAGS = -lm\nTARGET_FILE = bin/main\n\n# 描述各个目标的详细编译步骤；\n$(TARGET_FILE): $(patsubst src/%.c,src/%.o,$(wildcard src/*.c))\n  $(CC) $^ $(LDFLAGS) -o $@\n\nsrc/%.o: src/%.c include/%.h\n  $(CC) $&lt; $(CFLAGS) -c -o $@\n</code></pre><p>可以看到，通过以 “#” 开头的注释信息，我们将整个 Makefile 文件的内容划分成了两个部分。</p><p>第一部分包含用户可配置的一些宏常量，这些宏将在 make 运行时被替换到下面已经配置好的具体编译命令中。这样，用户可以通过修改这些量值来在一定范围内自定义期望使用的编译流程。</p><p>而第二部分则对应于各个编译目标的具体编译细节，这里我们将最初的那条编译命令拆分成了如下两步：</p><ol>\n<li>编译器将 src 与 include 文件夹内同名的 .c 与 .h 文件编译为对应的 .o 对象文件；</li>\n<li>编译器将所有的 .o 文件一次性编译，并生成最后的二进制可执行文件。</li>\n</ol><p>利用这种方式，我们增加了可复用的中间编译结果，使通过 make 命令进行的每一次编译过程，都仅局限在被修改的 .c 或同名的 .h 文件上。如此一来，我们便可以做到最大程度上的“中间结果复用化”。</p><p>为了帮你理解这部分配置代码，我将代码中你可能不太熟悉的 Makefile 语法元素的含义进行了整理，并放在了下面的表格中，你可以参考：</p><p><img src=\"https://static001.geekbang.org/resource/image/96/eb/96323c780fe1d16b7e865b2eecee6aeb.jpg?wh=1920x1057\" alt=\"图片\"></p><p>Makefile 帮助我们很好地解决了单一编译命令具有的可读性低、中间结果复用性差等诸多问题。你可以点击<a href=\"https://www.gnu.org/software/make/manual/make.html#toc-Overview-of-make\">这个链接</a>，来了解与它的可用语法和 make 工具相关的更多信息。</p><p>不过，仔细观察后你会发现，我们在 Makefile 中使用的各类命令与参数选项，都与程序当前运行所在的操作系统和平台直接相关。那么，当同一个 Makefile 文件被拷贝到其他环境中时，它是否还能正常工作呢？答案是 “it depends”。但很明确的是，“Makefile + make” 这种方式，本身就无法直接在除了（类）Unix 以外的其他操作系统上使用。因此，如何进一步满足 C 项目的跨平台自动化编译，便成了社区思考的另一个重要方向。接下来我们看看这个问题是如何被解决的。</p><h3>使用 CMake 进行跨平台的自动化构建</h3><p>“抽象”通常是用来解决这类问题的一大法宝。为了保证项目编译脚本的可移植性，我们便不能使用与具体软硬件实现相关的各类信息。因此，我们可以采取这样一种简单的方式：通过提供平台无关的中立配置选项，把与项目构建相关的所有重要特征“抽离”出来。并且，在项目开始真正编译之前，再根据目标平台的具体情况对项目进行构建。</p><p>接下来我为你介绍的工具 CMake（Cross-platform Make）便是按照这样的思路实现的。只不过相较于直接编译代码，CMake 会根据所在平台的具体情况，生成相应的“平台本地构建项目”。比如，在（类）Unix 系统上，它会生成项目对应的 Makefile 文件；而在 Windows 系统上，则会生成项目对应的 Visual Studio 工程文件。在此基础上，再利用所在平台上的相关工具，CMake 便可完成项目的真正构建。</p><p>同 Makefile 类似，CMake 规定用于描述项目编译细节的配置信息，也需要被保存在名为 CMakeLists.txt 的文本文件中。作为对比，你可以使用如下所示的这段 CMake 配置信息，来编译我们在这一讲开头处介绍的那个 C 项目。关于其中每一行“代码”的具体作用，你可以参考它们上方的注释来进一步理解。</p><pre><code class=\"language-makefile\">cmake_minimum_required(VERSION 3.10)\n# 设置项目名称；\nproject(Test)\n# 设置二进制目标文件名称；\nset(TARGET_FILE \"main\")\n# 添加源文件目录；\naux_source_directory(./src DIR_SRCS)\n# 设置二进制目标文件的依赖；\nadd_executable(${TARGET_FILE} ${DIR_SRCS})\n# 设置头文件查找目录；\ntarget_include_directories(${TARGET_FILE} PUBLIC \"${PROJECT_SOURCE_DIR}/include\")\n# 设置需要链接的库；\ntarget_link_libraries(${TARGET_FILE} PUBLIC m)\n</code></pre><p>可以很明显地看到，相较于 Makefile，CMake 的配置信息更加清晰易懂。比如，关于命令 target_include_directories 的具体用途，我们从它的名字上就能猜个大概。实际上，它便对应于 GCC 编译器的 <code>-I</code> 参数，可用于指定查找头文件时的搜索目录。你可以点击<a href=\"https://cmake.org/cmake/help/v3.22\">这个链接</a>，来查看与 CMake 有关的更多信息。</p><p>当项目的 CMakeLists.txt 文件编写完毕后，通过下面这几个步骤，我们便能够完成项目的编译：</p><ol>\n<li>使用命令 <code>mkdir build &amp;&amp; cd build</code> 创建并进入用于存放编译结果文件的临时目录；</li>\n<li>使用命令 <code>cmake ..</code> 生成本地化构建项目。这里，CMake 会根据用户在 CMakeLists.txt 中指定的信息，来对当前环境进行相关检查，其中包括针对编译器的 ABI、可用性，以及支持特性的检查等。而当检查结束后，CMake 便会根据检查结果，动态生成<strong>可用于支持项目在当前环境下进行编译的本地化构建项目</strong>；</li>\n<li>使用命令 <code>cmake --build .</code> 让 CMake 利用本地的相关工具，完成项目的最终编译过程。</li>\n</ol><h3>其他可选用工具</h3><p>其实，早在 CMake 出现之前，GNU 旗下就已经出现了类似的跨平台自动化构建工具，即 Autotools 工具集。它们可以帮助我们把各类项目的源代码移植到多种不同的 Unix 系统上。但由于其学习成本较高，使用较为繁琐，因此它们在逐渐被 CMake 取代。</p><p>当然，除此之外，还有 <a href=\"https://mesonbuild.com\">Meson</a>、<a href=\"https://gittup.org/tup\">Tup</a>、<a href=\"https://docs.bazel.build/versions/main/guide.html\">Bazel</a> 等构建工具可供你选择。它们在使用方式上都不尽相同，你可以点击相应链接来了解更多信息。但从实际情况来看，具有完善的功能、成熟的社区及解决方案的 CMake ，无疑仍是目前进行 C 项目跨平台自动化构建的最佳选择。</p><h2>总结</h2><p>讲到这里，今天的内容也就基本结束了。最后我来给你总结一下。</p><p>今天我主要为你介绍了如何组织 C 项目的源代码目录结构，以及如何在（类）Unix 系统上使用 Makefile 和 CMake 等工具，来进行 C 项目的结构化编译与跨平台自动化构建。</p><p>其中，对于如何组织 C 项目的源代码目录结构，社区并没有所谓的最佳实践。正确的方式是结合项目的实际情况，在保证清晰易懂的前提下，再对项目结构进行及时、动态的调整。</p><p>相较于每次使用完整的编译命令，结构化编译可以通过复用各类中间编译结果，进一步提升编译效率。同时，“可编程”的编译配置脚本也使得项目的编译细节更具可读性与可用性。</p><p>而借助 CMake 等工具，我们可以在此基础之上实现跨平台的项目自动化构建。CMake 通过抽象平台相关的配置信息，让开发者可以通过中立的方式描述项目的构建细节。而在项目被真正编译前，CMake 会进行一系列检查与分析，并最终生成适合在当前环境下使用的本地化构建项目。</p><h2>思考题</h2><p>你所在团队的项目使用了哪种自动化构建工具？你觉得它们有哪些优点和不足呢？欢迎在评论区跟同学们一起交流。</p><p>今天的课程到这里就结束了，希望可以帮助到你，也希望你在下方的留言区和我一起讨论。同时，欢迎你把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"21｜生产加速：如何使用自动化测试确保 C 项目质量？","id":484677},"right":{"article_title":"期中测试｜来检验下你的学习成果吧！","id":485770}}},{"article_id":485770,"article_title":"期中测试｜来检验下你的学习成果吧！","article_content":"<p>你好，我是于航。</p><p>不知不觉间，我们课程的前三个模块已经快要更新完了。在“C 工程实战篇”剩下的最后两讲中，我会带你实现一个完整的 C 语言项目。而在此之前，不如做套题来检验一下自己对 C 语言相关知识的掌握程度吧。通过这种方式，你就可以对我们在项目实战中要用到的知识做一个较为完整的总结与回顾，同时，也能为接下来学习最后一个模块“C 程序运行原理篇”打下更坚实的基础。</p><p>这次期中测试，我根据前面讲过的知识，给你出了 20 道选择题，考试范围截止到第 23 讲之前的内容，你可以检验一下自己的学习成果。如果你有什么不理解的地方，欢迎在评论区留言。</p><p>快点击下面的按钮开始测试吧，我期待着你满分的好消息！<br>\n<a href=\"http://time.geekbang.org/quiz/intro?act_id=1583&exam_id=3897\"><img src=\"https://static001.geekbang.org/resource/image/28/a4/28d1be62669b4f3cc01c36466bf811a4.png?wh=1142x201\" alt=\"\"></a></p><!-- [[[read_end]]] -->","neighbors":{"left":{"article_title":"22｜生产加速：如何使用结构化编译加速 C 项目构建？","id":485191},"right":{"article_title":"23｜实战项目（上）：一个简单的高性能 HTTP Server","id":486342}}},{"article_id":486342,"article_title":"23｜实战项目（上）：一个简单的高性能 HTTP Server","article_content":"<p>你好，我是于航。</p><p>在“C 核心语法实现篇”中，通过观察 C 代码被编译后的产物，我们了解了 C 基本语法在机器指令层面的多种具体实现细节。进入“C 工程实战篇”后，通过探索 C 标准库，我们发现了 C 语言为我们提供的更多优秀能力，并同时深入分析了它们的内部实现原理。在此基础之上，通过探讨 C 项目编码规范、代码优化技巧、自动化测试与结构化编译等话题，我们对 C 语言在实际工程中的应用方式又有了更深刻的理解。</p><p>但“光说不练假把式”，在本模块最后，就让我们通过实现一个完整的 C 语言项目，来整体回顾之前的学习内容，并尝试在实战过程中体会 C 这门语言的独特魅力。</p><h2>这是一个怎样的实战项目？</h2><p>俗话说得好，“有趣是第一生产力”。但似乎是从大学时代第一次接触 C 语言开始，我们就对使用这门语言开发的项目有了刻板印象，感觉它们不是枯燥的用户后台管理系统，就是各类晦涩的、与操作系统或硬件深入“绑定”的底层应用。但现实情况却并非如此。正如我在开篇词中介绍的那样，C 语言可以被广泛使用在应用软件、系统软件、编程语言、嵌入式开发等各类场景中。而今天我们要做的项目，便是应用软件类目下服务器应用中的一种，“HTTP Server”。</p><p>Server 翻译过来即“服务器”，它在整个互联网世界中，主要用于接收由客户端发来的请求，并在处理之后返回相应结果。而 HTTP 服务器则将可处理的请求类型限定为了 “HTTP 请求”。这类服务器的稳定运行，支撑了我们日常生活中需要与互联网打交道的大多数事务。比如，每一次打开网页，都伴随着浏览器发出 HTTP 请求，服务器返回 HTTP 响应的过程。而这些返回的内容在经过浏览器渲染后被呈现在了你的面前。</p><!-- [[[read_end]]] --><p>当然，考虑到篇幅和实现难度，在本次实战中，我们不会实现一个支持完整 HTTP 协议的服务器应用。我将会带你实现一个名为 “FibServ” 的程序。<strong>在这一讲接下来的内容中，我将从理论的角度，来为你介绍应该如何使用 C 语言在 Linux 环境下实现它的主要功能。而在下一讲，我们将带着这些理论成果进入到实际的编码环节。</strong></p><p>FibServ 在运行时可以接收形式为 “<strong>/?num={pos}</strong>” 的 GET 请求。其中，参数 num 对应的值 pos 为一个具体的整数。随后，程序会将该值作为一个索引信息，并返回斐波那契（Fibonacci）数列中对应该位置上的值。</p><p>你可以参考下面这张动图，来观察程序的实际运行状态。</p><p><img src=\"https://static001.geekbang.org/resource/image/01/98/01ca0facac8101fb802d33972627c898.gif?wh=1996x880\" alt=\"图片\"></p><p>图片中包含有左右两个命令行窗口。在右侧窗口中，我们首先运行了 FibServ。它会在当前计算机的 8080 端口上监听即将收到的 HTTP 请求。紧接着，在左侧窗口里，我们使用 curl 命令，向当前计算机（127.0.0.1）的 8080 端口发送了一个带有 “num=10” 参数的 GET 请求。经过一段时间，当 FibServ 处理完该请求后，包含有结果值 “55” 的响应被传送回来。</p><p>可以看到，FibServ 的功能十分简单。接下来，我们就从方案设计的角度入手，来看应该如何实现它的主要功能。</p><h2>如何使用 POSIX 接口实现 TCP Server？</h2><p>实际上，FibServ 的最核心功能便是对 HTTP 请求的接收与应答。在本次实战中，我们将以 HTTP 1.1 标准作为实现要求。如下所示，根据 <a href=\"https://www.rfc-editor.org/rfc/rfc7230.txt\">RFC 7230</a> 对该标准的规定，HTTP 作为一种应用层协议，需要基于以传输层 TCP 协议建立的网络连接来实现。</p><blockquote>\n<p>Although HTTP is independent of the transport protocol, the “http” scheme is specific to TCP-based services because the name delegation process depends on TCP for establishing authority.</p>\n</blockquote><p>在 Linux 系统中，借助套接字（Socket）接口，我们便能够建立这样的一个连接。这套接口属于 POSIX.1 标准的一部分，因此，它也同时被 Unix 与各种类 Unix 操作系统采用。套接字接口的全称一般为“套接字网络进程间通信接口”。从名称上就可以看出，通过这个接口，多个进程之间便可进行在同一网络下，甚至是跨不同网络的通信过程。对应到上面的动图，FibServ 与 curl 之间的交互过程便是如此。</p><p>而<strong>通过配合使用名为 socket、bind、listen、accept 以及 close 的五个接口，我们便能够完成 FibServ 最核心的网络请求接收功能</strong>。</p><p>其中，socket 接口用于创建套接字。套接字是一种用于描述通信端点的抽象实体，你可以这样简单理解：无论是客户端还是服务器，只要是能够参与到网络通信，并且可以进行数据传递的实体，它们都可以被抽象为一种特定类型的 socket 对象。</p><p>相应地，socket 接口暴露出了三个参数，用于指定这些不同对象在多个重要特征（通信域、套接字类型，及所使用的协议）上的不同。该接口的函数原型如下所示，接口在调用后会返回一个整型的文件描述符，以用于在后续代码中指代该 socket 资源。</p><pre><code class=\"language-bash\">int socket(\n  int domain, \n  int type, \n  int protocol);\n</code></pre><p>接下来，通过名为 bind 的接口，我们可以让套接字与一个具体的地址进行关联。通常来说，bind 被更多地用于为服务器类型端点对应的 socket 对象分配固定地址。这样，客户端便可通过这个地址来连接该服务器程序。</p><p>但需要注意的是，bind 接口使用的地址必须是在程序进程运行所在的计算机上有效的。在 FibServ 的实现中，我们将直接使用本机地址 “127.0.0.1”。bind 接口在调用时共接收两部分信息，一部分为某个具体 socket 对象对应的文件描述符；另一部分为与所关联地址相关的数据结构。它的函数原型如下所示：</p><pre><code class=\"language-bash\">int bind(\n  int sockfd, \n  const struct sockaddr *addr, \n  socklen_t addrlen);\n</code></pre><p>此时，通过名为 listen 的接口，我们可以将一个 socket 对象变为“被动 socket”，也就是说，该 socket 会在某个地址上持续被动地等待从外部发来的连接请求，而不会自己主动发起连接。当该接口调用完毕后，所有 socket 接收到的连接请求都会被暂时存放到一个队列中，以等待下一步处理。</p><p>如下面的函数原型所示，listen 接口共接收两个参数，第一个参数为某个具体 socket 对象对应的文件描述符；第二个参数用于控制“暂存队列”的大小。当该队列发生溢出时，后续的连接请求将会被直接拒绝（ECONNREFUSED）。</p><pre><code class=\"language-bash\">int listen(int sockfd, int backlog);\n</code></pre><p>最后，通过 accept 接口，我们可以从被动 socket 对应的暂存队列中依次取出已经到来的连接请求。这里，该接口会为每一个已接受的请求建立一个新的、表示已连接的 socket 对象。而在接下来的程序中，通过使用 read 与 write 等 IO 接口，我们便可直接使用该 socket，来读取出对应请求携带的数据，并同时将适当的结果返回给客户端。而若在调用 accept 接口时，暂存队列中没有待处理的连接请求，则接口调用者将会进入阻塞状态，直到下一个连接请求的到来。</p><p>通过下面的函数原型，你可以看到该接口接收的参数与 bind 接口十分类似。</p><pre><code class=\"language-bash\">int accept(\n  int sockfd, \n  struct sockaddr *restrict addr, \n  socklen_t *restrict addrlen);\n</code></pre><p>与 IO 操作类似的是，当这个新创建的、对应于已接受连接的 socket 对象被使用完毕后，我们也需要通过 close 接口来关闭它所对应的文件描述符。在这个过程中，与该 socket 相关的系统资源会被清理，并且，对应的 TCP 连接也会被关闭。</p><pre><code class=\"language-bash\">int close(int fd);\n</code></pre><p>至此，通过上面的几个简单步骤，我们便可成功实现一个基本的 TCP Server。这里你可以暂缓脚步，通过下面这张图片，来回顾一下上述实现流程。</p><p><img src=\"https://static001.geekbang.org/resource/image/80/54/8070520e113ca0cececc799bf27a6a54.jpg?wh=2284x555\" alt=\"\"></p><p>TCP 协议主要规定了应该如何在通信双方之间，提供可靠和有序的数据流传输能力。因此，它并未对基于该连接传送的具体数据格式做任何要求和假设。而对这些传输字节流的解释，则由 TCP 连接双方根据应用层的具体协议来进行。在此基础上，我们便能够进一步来实现 HTTP 协议。</p><h2>TCP 之上：HTTP 协议有何不同？</h2><p>与 TCP 协议的复杂性比起来，HTTP 协议就相对简单很多。</p><p>在 HTTP 1.1 中，请求与响应的报文均是以纯文本的形式来在客户端与服务器之间传递的。这也就意味着，当 FibServ 在处理一个 HTTP 请求时，实际上就是在处理这个请求对应的，一堆按照特定格式组织的 ASCII 字符。至于这些字符的具体内容，你可以通过 read 接口，从已被接受的连接对应的 socket 对象中读取出来。</p><p>对 FibServ 来说，一个正确的 HTTP 请求报文的格式可能如下所示：</p><pre><code class=\"language-bash\">GET /?num=10 HTTP/1.1\nHost: 127.0.0.1:8080\nUser-Agent: ApacheBench/2.3\nAccept: */*\n</code></pre><p>整个报文被分为三部分，即<strong>起始行、首部字段，以及主体</strong>。其中，起始行中包含有与该请求相关的方法（GET）、路径（/?num=10），以及协议与版本（HTTP/1.1）信息。而首部字段中则包含所有的请求头信息，这些信息通常用于控制客户端或服务器应该如何处理该请求。对于某些属于特定方法的请求，报文中通常还可能包含有与请求一同发送过来的必要数据，这部分数据则被整理在了报文“最下方”的主体部分中。</p><p>如下所示，相应的 HTTP 响应报文也有着同样的三部分结构，只是起始行中包含的信息发生了变化：</p><pre><code class=\"language-bash\">HTTP/1.1 200 OK\nContent-type: text/plain\nContent-length: 2\n\n55\n</code></pre><p>这里的 “200” 和 “OK” 分别表示了该响应的状态码与可读状态信息。总的来看，请求报文的起始行描述了这个请求“希望要做的事情”；而响应报文的起始行则描述了“这件事做完后的结果状态”。与之前的请求报文不同，这个响应报文中还包含有主体部分的数据 “55”，而这部分数据便是从服务器返回的请求结果。</p><p>另外还值得一提的是，标准中规定，起始行和首部的每一行都需要以 CRLF，即“回车符”加“换行符”的形式结尾。而在首部字段与主体之间，则需要以 CRLF 结尾的一行空行进行分割。这是我们在代码中构建 HTTP 报文时需要注意的一点。</p><p>HTTP 1.1 除了对报文的具体格式做了详细规定外，它还对 TCP 连接控制、缓存管理、认证机制等其他重要功能的实现要求进行了说明。但考虑到实现成本，在本次实战中，我们仅会对 FibServ 收到的 HTTP 请求报文进行适当解析，并返回相应的响应报文。而在其他部分的实现上，可能并没有遵循 HTTP 协议的相关规定（比如默认情况下应使用长连接）。</p><h2>我们会应用哪些优化策略？</h2><p>为了尽可能提高 FibServ 处理请求时的性能，我们将从几个很容易想到的地方入手，来对程序进行适当的优化。</p><h3></h3><h3>简易线程池</h3><p>首先来思考下：如何让程序充分利用多核 CPU 的多个处理单元？相信这个问题一定难不倒你。没错，答案就是使用多线程。</p><p>在 FibServ 的实现中，我们将为它构建一个拥有固定 N 个处理线程的简易线程池。其中，N 可以由用户在运行 FibServ 时，通过添加额外的参数 “thread_count” 来指定。每一个线程在运行时，都会通过 accept 接口，独立地从 socket 对应的暂存队列中取出下一个待连接请求，并进行相应处理。通过这种方式，我们可以充分利用多个 CPU 核心，以让它们并行地处理多个请求。</p><h3>尾递归调用</h3><p>另一方面，对于斐波那契数列的计算函数，我将分别提供它的正常递归版本与尾递归版本。通过这种方式，你能够明显地观察到尾递归优化带来的，可观的性能提升。</p><h3>避免忙等待</h3><p>最后一个优化点虽然不会带来直观的性能改变，但对于理解“条件变量”在实际项目中的应用方式，却是十分有帮助的。</p><p>为了确保 FibServ 能够在请求处理线程异常退出时，仍然保证线程池中的线程数量为 N，这里我不会使用忙等待的方式持续判断存活的线程数量。相对地，我会使用条件变量，来让处理线程在退出时，及时通知主线程创建新的处理线程。而主线程也将在处理线程数量满足要求时，再次进入阻塞状态。</p><h2>总结</h2><p>好了，讲到这里，今天的内容也就基本结束了。最后我来给你总结一下。</p><p>今天我主要为你介绍了与本次实战项目相关的一些理论性知识，以便为下一讲的实际编码打下基础。</p><p>我们要构建的是一个名为 FibServ 的程序，该程序在运行时会扮演 HTTP 服务器的角色，并持续监听来自本地的 HTTP 请求。相应的请求需要为 GET 方法，并携带名为 “num” 的查询参数。FibServ 在收到该类型请求后，会计算斐波那契数列中在对应位置上的项，并将该值返回给客户端。</p><p>在 Unix 与类 Unix 系统中，借助 POSIX.1 标准提供的五个接口，即 socket、bind、listen、accept 与 close，我们可以为程序实现监听并接收 TCP 连接请求的功能。而 HTTP 协议作为一种基于纯文本的应用层协议，我们可以在此基础上，在程序层面完成对请求报文的解析，以及响应报文的构建过程。</p><p>为了进一步提升 FibServ 处理请求时的效率，我们还将为它提供了简易的线程池实现，以通过增加工作线程的方式，来进一步利用多核 CPU 的处理单元。同时，通过适当改写用于求取斐波那契数列的计算函数，编译器可以帮助我们将它的实现方式由递归优化为迭代，进而大幅提升运行性能。最后，借助条件变量，我们可以优化线程池在线程异常退出时的处理方式，让整个处理流程变得更加优雅。</p><h2>思考题</h2><p>针对我们的实战项目 FibServ，你还能想到哪些可以进一步优化的地方呢？欢迎在评论区告诉我你的想法。</p><p>今天的课程到这里就结束了，希望可以帮助到你，也希望你在下方的留言区和我一起讨论。同时，欢迎你把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"期中测试｜来检验下你的学习成果吧！","id":485770},"right":{"article_title":"24｜实战项目（下）：一个简单的高性能 HTTP Server","id":487230}}},{"article_id":487230,"article_title":"24｜实战项目（下）：一个简单的高性能 HTTP Server","article_content":"<p>你好，我是于航。</p><p>在 <a href=\"https://time.geekbang.org/column/article/486342\">23 讲</a> 中，我对本次实战项目将要构建的程序 FibServ 的功能做了基本介绍，并从理论的角度，带你对它的基本实现方案有了一个初步认识。而这一讲，我们将通过实际编码，来应用这些理论知识。</p><p>为了便于你理解这一讲的内容，我已经将本项目的完整代码实现放到了 GitHub 上，你可以点击<a href=\"https://github.com/Becavalier/tiny-http-echo-server/tree/geektime\">这个链接</a>，先大致浏览一下每个源文件的内容。而在后续讲解到相关代码时，我也会在整段代码的第一行，通过注释的方式将这些代码的所在源文件标注出来。比如注释 “libs/structs.h#L9-L11”，便表示当前所示的代码段对应于项目 libs 目录下，structs.h 文件内的第 9 到 11 行。其他注释的含义你可以此类推。</p><p>接下来，我会带你从基本的项目目录创建，到模块功能编写，再到代码编译和程序运行，一步步地完成整个项目的开发过程。</p><h2>项目基本结构</h2><p>首先，我们来看应该如何组织整个项目的目录结构。根据预估的项目体量，我使用了如下图所示的目录结构：</p><p><img src=\"https://static001.geekbang.org/resource/image/f9/8c/f9fcf00722c6b785052f1yyd8d27aa8c.png?wh=760x616\" alt=\"图片\"></p><p>这里，整个项目包含有三个目录：build、libs 以及 src。其中，build 目录用于存放程序在 CMake 下的临时编译结果。如果你对这个目录还不太熟悉，可以参考我在<a href=\"https://time.geekbang.org/column/article/485191\"> 22 讲</a> 中为你介绍的例子。libs 目录中主要存放可以模块化的独立功能实现，这些功能会以头文件的形式来提供外部可用接口，以供不同的应用程序使用。而最后的 src 目录则存放有与应用程序 FibServ 实现相关的源代码。</p><!-- [[[read_end]]] --><p>在此基础之上，你会发现我们分别在 libs 目录与项目根目录下，同时创建了用于控制 CMake 编译流程的 CMakeLists.txt 文件。其中，前者主要用于控制 libs 目录内 C 源代码的编译流程；而后者则用于控制应用程序 FibServ 的编译流程。我在这一讲后面的“编译与运行”一节中，还会再具体介绍这两个文件中的配置项。</p><h2>处理用户输入参数</h2><p>FibServ 在启动时可以接收一个由用户指定的，名为 “thread_count” 的参数。这个参数被用于控制 FibServ 应启用多少线程来处理收到的 HTTP 请求。</p><p>这里，我专门封装了一个用于描述服务器整体配置状态的结构类型 serverSettings，其中仅有的 threadCount 字段便对应于该参数，代码如下：</p><pre><code class=\"language-c++\">// libs/structs.h#L9-L11\ntypedef struct {\n&nbsp; int threadCount;\n} serverSettings;\n</code></pre><p>而通过对 main 函数的两个参数 argc 与 argv 进行解析，我们能够得到用户在运行程序时传入的所有参数。在名为 setupServerSettings 的函数中，我们通过上述这种方式，完成了对用户传入参数的解析与保存过程，解析得到的所有合法选项均被存放在一个 serverSettings 类型的对象中。该函数的实现代码如下所示：</p><pre><code class=\"language-c++\">// libs/helpers.h#L67-L86\nvoid setupServerSettings(int argc, const char** argv, serverSettings* ss) {\n&nbsp; while (argc-- &gt; 1) {\n&nbsp; &nbsp; // process key.\n&nbsp; &nbsp; const char* keyHead = argv[argc];\n&nbsp; &nbsp; const char* keyPos = strchr(keyHead, '=');\n&nbsp; &nbsp; const size_t keyLen = keyPos - keyHead + 1;\n&nbsp; &nbsp; char key[keyLen];\n&nbsp; &nbsp; wrapStrFromPTR(key, keyLen, keyHead, keyPos);\n&nbsp; &nbsp; // process value.\n&nbsp; &nbsp; const char* valHead = keyHead + keyLen;\n&nbsp; &nbsp; const char* valPos = strchr(valHead, '\\0');\n&nbsp; &nbsp; const size_t valLen = valPos - valHead + 1;\n&nbsp; &nbsp; char val[valLen];\n&nbsp; &nbsp; for (size_t i = 0; valHead &lt;= valPos; valHead++)\n&nbsp; &nbsp; &nbsp; val[i++] = *valHead;\n&nbsp; &nbsp; if (strcmp(key, \"thread_count\") == 0) {\n&nbsp; &nbsp; &nbsp; ss-&gt;threadCount = atoi(val);\n&nbsp; &nbsp; }\n&nbsp; }\n}\n</code></pre><p>可以看到，通过判断 argc 的值是否大于 1（略过 argv 的第一个“程序文件名”参数），我们便能够对经由 argv 传递过来的输入参数进行遍历。每一次的遍历过程都分为两个步骤，即分别获取形如 “key=value” 的设置项的 key 与 value 两部分内容。</p><p>这里，我们使用 C 标准库中的 strchr 函数，来得到每个选项中 “=” 与字符串结尾空字符 “\\0” 的位置，并以此将整个选项分为两段。在此基础之上，通过分别收集这两个区间（首字符至 “=”，以及 “=” 至结尾空字符）内的字符，我们能够将一个选项的“键”与“值”进行拆分。最后，使用 strcmp 函数来比对所得到的键是否有效，若有效，则将相应的值存储到指定的 serverSettings 对象中。</p><p>至此，FibServ 便完成了用户配置项的初始化工作。接下来，我们继续为它实现 TCP Server 的核心功能。</p><h2>实现 TCP Server</h2><p>根据在上一讲中得到的结论，我们将使用来自 POSIX.1 标准的五个接口，socket、bind、listen、accept 与 close，来实现基本的 TCP 请求监听与连接创建等功能。</p><h3>监听请求</h3><p>为了将 FibServ 接受和处理 HTTP 请求的代码抽离出来，以方便后续的多线程改造，这里我将 TCP Server 的实现过程分为两个部分来介绍。</p><p>首先来看如何让程序进入“监听”状态，并持续等待 TCP 连接请求的到来。这部分代码将由 main 函数所在线程来执行，对应的代码如下所示：</p><pre><code class=\"language-c++\">// src/main.c#L70-95\nint serverFd;&nbsp;\nsockaddr_in address;\nint addrLen = sizeof(address);\n\n// establish a socket.\nif ((serverFd = socket(AF_INET, SOCK_STREAM, 0)) == 0) { ... }\n\nbzero(&amp;address, addrLen);&nbsp;\naddress.sin_family = AF_INET;\naddress.sin_addr.s_addr = INADDR_ANY;&nbsp; // -&gt; 0.0.0.0.\naddress.sin_port = htons(PORT);\n&nbsp;&nbsp;\n// assigns specified address to the socket.\nif (bind(serverFd, (sockaddr*) &amp;address, sizeof(address)) &lt; 0) { ... }\n\n// mark the socket as a passive socket.\nif (listen(serverFd, MAX_LISTEN_CONN) &lt; 0) { ... }\n</code></pre><p>观察上述代码的第 7、15 与 18 行，你会发现，我们按顺序分别调用了接口 socket、bind 与 listen。其中，socket 接口共接收三个参数：AF_INET 宏常量表明使用 IPV4 因特网域；SOCK_STREAM 宏常量表明使用有序、可靠、双向，且面向连接的字节流；最后的参数 0 表明，让接口根据前两个参数自动选择使用的协议。当然，在这样的配置组合下，将默认使用 TCP 协议。</p><p>接下来，借助 bind 接口，我们可以为前一步创建的 socket 对象绑定一个地址。在 IPV4 域下，对应的地址用 sockaddr_in 类型的结构来表示。在代码的第 10~12 行，我们对该类型的一个对象 address 进行了初始化。其中，sin_addr 结构内的 s_addr 字段用于配置相应的地址信息。这里，INADDR_ANY 宏常量表示将 socket 绑定到地址 “0.0.0.0”。<strong>通过这种方式，程序可以监听其运行所在的机器上发送到所有网卡（网络接口）的网络请求。</strong></p><p>另外需要注意的是，我们在为 address 对象设置用于表示网络端口的 sin_port 字段时，使用了名为 htons 的方法，来将一个 short 类型的端口值转换为<strong>网络协议所要求字节序（通常为大端序）下的表示形式</strong>。而之所以这样做，是为了让异构计算机在交换协议信息的过程中，不会被不同平台的不同字节序混淆。</p><p>紧接着，通过调用 listen 接口，程序开始监听即将到来的 TCP 连接请求。这里，通过它的第二个参数，我们指定了暂存队列最多能够存放的待连接请求个数为 MAX_LISTEN_CONN 个。</p><h3>管理连接</h3><p>到这里，程序便可以通过 accept 接口来不断地接受连接请求。此时，配合使用 read 和 write 这两个 IO 接口，我们可以获取客户端发来的数据，并在数据处理完毕后，再将特定内容返回给客户端。最后，当连接不再使用时，调用 close 接口即可将它关闭。关于这部分实现，你可以参考文件 “src/main.c” 中第 36~39 行，以及第 60 行的代码。</p><h2>处理 HTTP 请求和响应</h2><p>当 TCP 连接成功建立后，我们便可在此基础之上进行与 HTTP 协议相关的操作，整个流程也十分简单，可以分为三个步骤：</p><ol>\n<li>通过解析收到的 HTTP 请求报文，我们可以获取由客户端发送过来的参数值 num；</li>\n<li>调用斐波那契数列计算函数，相应的结果项可以被计算出来；</li>\n<li>通过构造一个合法的 HTTP 响应报文，我们可以将这个计算结果返回给客户端。</li>\n</ol><p>下面，我们来依次看看这几个步骤的具体实现。</p><h3>解析请求</h3><p>先来看第一步，解析请求。为了简化实现，这里我们将 HTTP 请求报文的解析过程分为了简单、直接的两个步骤，即<strong>提取路径（URI）<strong>和</strong>解析查询参数值</strong>。</p><p>当然，现实中的 HTTP 服务器应用通常会首先对报文的格式进行完整性校验，然后再进行类似的后续处理。与这部分逻辑相关的实现被封装在了名为 retrieveGETQueryIntValByKey 的函数中，它的实现代码如下所示：</p><pre><code class=\"language-c++\">// libs/helpers.c#L37-L65\nint retrieveGETQueryIntValByKey(char* req, const char* key) {\n&nbsp; int result = 0;\n\n&nbsp; // extract uri;\n&nbsp; const char* uriHead = strchr(req, ' ') + 1;\n&nbsp; const char* uriTail = strchr(uriHead, ' ');\n&nbsp; size_t uriLen = uriTail - uriHead + 1;\n&nbsp; char strUri[uriLen];\n&nbsp; wrapStrFromPTR(strUri, uriLen, uriHead, uriTail);\n\n&nbsp; // parse uri;\n&nbsp; UriUriA uri;\n&nbsp; UriQueryListA* queryList;\n&nbsp; int itemCount;\n&nbsp; const char* errorPos;\n&nbsp; if (uriParseSingleUriA(&amp;uri, strUri, &amp;errorPos) == URI_SUCCESS) {\n&nbsp; &nbsp; if (uriDissectQueryMallocA(&amp;queryList, &amp;itemCount, uri.query.first, uri.query.afterLast) == URI_SUCCESS) {\n&nbsp; &nbsp; &nbsp; while (itemCount--) {\n&nbsp; &nbsp; &nbsp; &nbsp; if (strcmp(queryList-&gt;key, key) == 0) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; result = atoi(queryList-&gt;value);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; break;\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; queryList = queryList-&gt;next;\n&nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; uriFreeQueryListA(queryList);\n&nbsp; &nbsp; }\n&nbsp; }\n&nbsp; return result;\n}\n</code></pre><p>我在上一讲中曾为你介绍过 HTTP 请求报文的基本格式。其中，路径信息位于报文的“起始行”部分，而起始行中的每个元素则均以空格进行分割。因此，这里我们的第一步便是要<strong>获取当整个报文从头向后逐字符遍历时，遇到的前两个空格之间的那段文本</strong>。从代码中可以看到，这里我们再次使用了名为 strchr 的标准库函数来达到这个目的。</p><p>接下来，我们就会遇到“如何从路径文本中解析出给定查询参数的值？”这个棘手的问题。由于路径的形式可能有多种变化，比如未带有给定参数（/?foo=1）、带有除给定参数外的其他参数（/?foo=1&amp;num=10）、带有子路径的参数（/child/?num=10），等等。因此，为了完善地处理这类情况，这里我们选用了一个开源的第三方 URI 解析库，uriparser。</p><p>uriparser 的使用方式十分简单，通过配合使用 uriParseSingleUriA 与 uriDissectQueryMallocA 这两个接口，我们可以将所传入 URI 的查询参数与值提取成一个单链表。而通过对它进行遍历（itemCount 表示参数个数），我们便能够找到目标参数的值。你可以点击<a href=\"https://github.com/uriparser/uriparser\">这个链接</a>，来了解关于 uriparser 的更多信息。</p><h3>计算斐波那契数列</h3><p>此时，我们已经得到了由客户端通过 HTTP 请求传送过来的参数 num。而下一步要完成的，便是 FibServ 的核心功能，即计算斐波那契数列第 num 项的值。与此相关的代码实现如下所示：</p><pre><code class=\"language-c++\">// libs/helpers.c#L8-L20\nint __calcFibTCO(int n, int x, int y) {\n&nbsp; if (n == 0)\n&nbsp; &nbsp; return x;\n&nbsp; if (n == 1)\n&nbsp; &nbsp; return y;\n&nbsp; return __calcFibTCO(n - 1, y, x + y);\n}\n\nint __calcFibRecursion(int n) {\n&nbsp; if (n &lt;= 1)\n&nbsp; &nbsp; return n;\n&nbsp; return __calcFibRecursion(n - 1) + __calcFibRecursion(n - 2);\n}\n\nint calcFibonacci(int n) {\n  // return __calcFibTCO(n, 0, 1);  // TCO version. \n  return __calcFibRecursion(n);  // recursion version.\n}\n</code></pre><p>这里，我为你提供了两种不同的函数实现。其中，函数 __calcFibRecursion 为正常递归版本；而函数 __calcFibTCO 为对应的尾递归版本。由于这两个版本函数需要的参数个数不同，因此为了统一对外的调用接口，我们为外部代码又提供了另一个稳定接口 calcFibonacci，而该接口在内部则可根据需要动态调用上述的两种函数实现。</p><h3>返回响应</h3><p>当计算过程结束后，我们便可以构造 HTTP 响应报文，并将结果返回给客户端。<strong>表示操作成功的响应报文应使用内容为 “HTTP/1.1 200 OK” 的响应头。</strong>在本例中，我们没有返回任何首部字段，因此，响应头与主体之间可以直接使用以 CRLF 结尾的一行空行进行分割。关于这部分实现，你可以参考文件 “src/main.c” 中第 55~56 行的代码。</p><h2>整合多线程</h2><p>经过上面几个步骤，我们已经可以让 FibServ 正常地接收与处理 HTTP 请求，并返回包含有正确结果的 HTTP 响应。但为了进一步提升 FibServ 的请求处理效率，我们将使用多线程技术来对它进行优化。</p><h3>分离处理线程</h3><p>首先，我们把请求处理相关的逻辑全部提取并封装在了名为 acceptConn 的函数中。这样，每一个线程便能够完全独立地来处理一个连接。该函数的完整实现代码如下所示：</p><pre><code class=\"language-c++\">noreturn void* acceptConn(void *arg) {\n&nbsp; acceptParams* ap = (acceptParams*) arg;\n&nbsp; int acceptedSocket;\n\n&nbsp; while (1) {\n&nbsp; &nbsp; pthread_cleanup_push(renewThread, &amp;acceptedSocket);\n&nbsp; &nbsp; // extracts a request from the queue.\n&nbsp; &nbsp; if ((acceptedSocket = accept(ap-&gt;serverFd, ap-&gt;addr, ap-&gt;addrLen)) &lt; 0) {\n&nbsp; &nbsp; &nbsp; perror(\"In accept\");\n&nbsp; &nbsp; &nbsp; pthread_exit(NULL);\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; // deal with HTTP request.\n&nbsp; &nbsp; char reqBuf[HTTP_REQ_BUF];\n&nbsp; &nbsp; bzero(reqBuf, HTTP_REQ_BUF);&nbsp;\n&nbsp; &nbsp; const size_t receivedBytes = read(acceptedSocket, reqBuf, HTTP_REQ_BUF);\n&nbsp; &nbsp; if (receivedBytes &gt; 0) {\n&nbsp; &nbsp; &nbsp; char resBuf[HTTP_RES_BUF];\n\n&nbsp; &nbsp; &nbsp; // retrieve number from query.\n&nbsp; &nbsp; &nbsp; pthread_mutex_lock(&amp;mutex);\n&nbsp; &nbsp; &nbsp; const int num = retrieveGETQueryIntValByKey(reqBuf, \"num\");\n&nbsp; &nbsp; &nbsp; pthread_mutex_unlock(&amp;mutex);\n\n&nbsp; &nbsp; &nbsp; int fibResult = calcFibonacci(num);\n&nbsp; &nbsp; &nbsp; // follow the format of the http response.\n&nbsp; &nbsp; &nbsp; sprintf(resBuf, \"HTTP/1.1 200 OK\\r\\n\\r\\n%d\", fibResult);\n&nbsp; &nbsp; &nbsp; write(acceptedSocket, resBuf, strlen(resBuf));\n&nbsp; &nbsp; }\n&nbsp; &nbsp; close(acceptedSocket);\n&nbsp; &nbsp; pthread_cleanup_pop(0);\n&nbsp; }\n}\n</code></pre><p>为了能够在线程内部获取与 socket 相关的文件描述符、地址，以及地址长度信息，以便于后续 accept 等接口的调用，这里我将这三个参数封装在了名为 acceptParams 的结构中。该结构的一个对象将在线程创建时以指针的形式传递进来，供所有处理线程使用。</p><p>在上述代码的第 5 行，通过一个死循环结构，线程便可持续不断地处理收到的连接请求。接下来，通过 accept 接口，我们可以从暂存队列中接受一个连接请求。代码的第 16 行，借助 read 函数，程序获取到了由客户端发送来的数据。这些数据将随着第 22 与 25 行的处理，最终变为我们需要的计算结果。最后，在代码的第 27~28 行，我们将该结果整合在一个 HTTP 响应报文中，并返回给客户端。</p><h3>优雅地处理异常</h3><p>除此之外，你可能会发现，我们在代码的第 6 与 31 行，还调用了名为 pthread_cleanup_push 与 pthread_cleanup_pop 的两个函数。这两个函数的主要目的在于为线程添加退出时会自动执行的回调函数。这样，我们便能够在线程由于 accept 调用失败而退出时，及时地通知主线程重新创建新的处理线程，以保证线程池中线程的数量维持在一个稳定状态。关于这两个函数的更详细用法，你可以点击<a href=\"https://man7.org/linux/man-pages/man3/pthread_cleanup_push.3.html\">这个链接</a>来了解。</p><p>但也正是因为需要对线程的状态进行更细致的管理，在本次实战项目中，我们并没有使用 C 标准中的线程库 threads.h，而是选用了 POSIX 标准下的 pthread 接口。但对于大多数的线程控制接口来说，两者只是在接口名称和使用方式上稍有差异，而背后的运行原理是完全一致的。</p><p>如下面的代码所示，在这个回调函数中，我们首先关闭了退出线程当前正在使用的 TCP 连接。接着，在互斥锁的保护下，我们更新了用于记录活动线程数量的全局变量 threadCounter，并通过 pthread_cond_signal 来通知 main 函数所在线程，重新创建处理线程（如果你对这里条件变量相关接口的使用方式还不太熟悉，可以重新回顾 <a href=\"https://time.geekbang.org/column/article/478213\">14 讲</a> 的相关内容）。</p><pre><code class=\"language-c++\">void renewThread(void *arg) {&nbsp;&nbsp;\n&nbsp; int* acceptedSocket = (int*) arg;\n&nbsp; close(*acceptedSocket);\n&nbsp; pthread_mutex_lock(&amp;mutex);\n&nbsp; threadCounter--;\n&nbsp; pthread_cond_signal(&amp;cond);&nbsp; // notify main thread.\n&nbsp; pthread_mutex_unlock(&amp;mutex);\n}&nbsp;\n</code></pre><p>到这里，一切准备就绪。最后，让我们回到 main 函数内部，将“命运的齿轮”转动起来。</p><h3>创建线程</h3><p>如下面的代码所示，位于 main 函数内的死循环结构主要用于不断地创建新的处理线程。可以看到，在代码的第 11~12 行，我们使用 pthread_create 接口创建新的线程，并同时递增了工作线程计数器，即全局变量 threadCounter 的值。而直到该值大于等于程序配置状态对象 serverSettings 中 threadCount 的值时，通过调用 pthread_cond_wait 接口，main 线程进入到了阻塞状态。这个状态将会一直维持，直至有工作线程发生异常退出。</p><pre><code class=\"language-c++\">// src/main.c#L97-L109\nwhile (1) {\n&nbsp; pthread_mutex_lock(&amp;mutex);\n&nbsp; while (threadCounter &gt;= ss.threadCount)\n&nbsp; &nbsp; pthread_cond_wait(&amp;cond, &amp;mutex);\n&nbsp; pthread_mutex_unlock(&amp;mutex);\n\n&nbsp; // create new thread to handle the request.\n&nbsp; pthread_t threadId;\n&nbsp; acceptParams ap = { serverFd, (sockaddr*) &amp;address, (socklen_t*) &amp;addrLen };\n&nbsp; pthread_create(&amp;threadId, NULL, acceptConn, &amp;ap);\n&nbsp; atomic_fetch_add(&amp;threadCounter, 1);\n&nbsp; printf(\"[Info] Thread Created: No.%d\\n\", threadCounter);\n}\n</code></pre><p>到这里，FibServ 在 C 代码层面的基本实现就结束了。接下来，我们将编写用于该项目的 CMake 配置文件，并尝试使用 cmake 命令对它进行编译。</p><h2>编译与运行</h2><p>我曾在这一讲的第一个小节“项目基本结构”中提到，在本项目中，我们将使用两个 CMakeLists.txt 文件，来分别控制 libs 目录内的源代码，以及 FibServ 应用程序的编译过程。通过这种方式，CMake 会首先将前者编译为独立的 “.a” 静态库文件，然后再将该文件与 src 下的源代码一起编译，并生成最终的可执行文件。</p><p>libs 目录下的 CMakeLists.txt 文件内包含有以下内容：</p><pre><code class=\"language-c++\"># libs/CMakeLists.txt\naux_source_directory(. DIR_LIB_SRCS)\nadd_library(core STATIC ${DIR_LIB_SRCS})\n</code></pre><p>其中，指令 aux_source_directory 用于收集当前目录下所有源文件的名称，并将这些名称存储到变量 DIR_LIB_SRCS 中。随后，通过 add_library 命令，从前一步收集而来的源文件将被一同编译，并生成名为 “core” 的静态库。</p><p>返回项目根目录，我们再来看用于控制应用程序 FibServ 编译的 CMakeLists.txt 文件中的内容，具体如下所示：</p><pre><code class=\"language-c++\">cmake_minimum_required(VERSION 3.21)\nproject(mini-http-server)\n\nset(TARGET_FILE \"http-echo-server\")\nset(CMAKE_BUILD_TYPE Release)\nset(CMAKE_C_STANDARD 17)\n\n# a simple way to check non-standard C header files (includes the atomic-related one).\ninclude(CheckIncludeFiles)\ncheck_include_files(\"pthread.h;stdatomic.h;sys/socket.h;netinet/in.h;unistd.h\" EDEPS)\nif (EPTHREAD EQUAL 1)\n&nbsp; message(FATAL_ERROR \"Necessary header files are not found!\")\nendif()\n\n# for headers in \"/libs\" and other external installed packages.\ninclude_directories(. /usr/local/include)\n\n# load source files and sub-directories.\naux_source_directory(./src DIR_SRCS)\nadd_subdirectory(libs/)\n\n# load packages.\nfind_package(uriparser 0.9.6 CONFIG REQUIRED char)\n\n# for executable.\nadd_executable(${TARGET_FILE} ${DIR_SRCS})\ntarget_link_libraries(${TARGET_FILE} PUBLIC core m pthread uriparser::uriparser)\n</code></pre><p>其中，你需要关注的是第 9~13 行的配置代码。这里，通过名为 check_include_files 的宏函数，我们能够让 CMake 在编译代码前，检测应用所需的指定头文件是否可以在当前环境下使用。若否，则直接终止项目的编译配置过程。</p><p>在接下来的第 16 行代码中，我们指定了程序编译时的头文件查找目录。通过第 19~20 行代码，FibServ 对应实现的源文件，以及所需要的内部依赖项（core 静态库）被引用进来。在第 23 行，通过 find_package 指令，CMake 可以帮助我们查找程序需要使用的外部依赖包（这里即 uriparser）。</p><p>需要注意的是，uriparser 在可以被 CMake 正常使用之前，它需要被正确地编译和安装，你可以点击<a href=\"https://github.com/uriparser/uriparser\">这个链接</a>来查看更详细的说明。最后，通过 add_executable 与 target_link_libraries 两个指令，我们便可完成 FibServ 二进制文件的编译和链接过程。</p><p>当然，同我们在上一讲中介绍的方法类似，使用下面这行命令，我们可以一次性完成项目的编译前配置、代码编译与程序运行：</p><pre><code class=\"language-c++\">mkdir build &amp;&amp; cd build &amp;&amp; cmake .. &amp;&amp; cmake --build . &amp;&amp; ./fibserv\n</code></pre><h2>总结</h2><p>好了，讲到这里，今天的内容也就基本结束了。最后我来给你总结一下。</p><p>在这一讲中，我带你从基本的项目目录创建，到模块功能编写，再到代码编译和程序运行，一步步地完成了整个 FibServ 项目的开发过程，并为你详细介绍了这个项目的各个重要组成部分在代码层面的具体实现方式。</p><p>在“C 工程实战篇”的最后，我用两讲的篇幅带你实现了一个完整的 C 语言项目。希望通过这些内容，你能够对 C 语言在真实项目中的应用方式有更深刻的理解。同时，也希望你能以此为起点，在实践中持续运用这个模块中介绍到的各种 C 标准库功能与工程化实践技巧，进一步加深对整个 C 语言，乃至相关技术、工具和框架的理解。</p><h2>思考题</h2><p>你知道如何通过复用 TCP 连接来进一步优化 FibServ 的性能吗？欢迎在评论区告诉我你的实现方案，也欢迎你直接提交 PR！</p><p>今天的课程到这里就结束了，希望可以帮助到你，也希望你在下方的留言区和我一起讨论。同时，欢迎把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"23｜实战项目（上）：一个简单的高性能 HTTP Server","id":486342},"right":{"article_title":"25｜可执行二进制文件里有什么？","id":487944}}},{"article_id":487944,"article_title":"25｜可执行二进制文件里有什么？","article_content":"<p>你好，我是于航。从这一讲开始，我们就进入到了“C 程序运行原理篇”的学习。</p><p>和之前的内容相比，在这一模块中，我们将会从“台前”走向“幕后”：从由 C 代码直观表示的程序逻辑，走向程序在运行过程中，背后与操作系统交互时的具体原理。相信学习完这个模块后，你会对一个 C 程序从代码编写，到通过编译，再到最终被操作系统运行的完整过程有更深入的理解。其中，程序的运行细节仅与所在操作系统紧密相关，因此，这一模块中介绍的原理性知识也同样适用于由 Rust、C++，以及 Go 等其他系统级编程语言编写的程序。</p><p>而今天我们先来看下，经常被提及的“二进制可执行文件”究竟是什么。</p><h2>可执行文件的格式</h2><p>我们都知道，一份 C 代码在经过编译器处理后，便可得到能够直接运行的二进制可执行程序。而在不同操作系统上，这些编译生成的可执行文件都有着不同的特征，其中最明显的差别便是文件后缀名。比如，在 Microsoft Windows 操作系统上，通常会以 “.exe” 为后缀名来标注可执行文件；而在类 Unix 操作系统上，可执行文件通常没有任何后缀名。</p><p>除此之外，更重要的不同点体现在各类可执行文件在内部数据的组织和结构上。通常来说，最常见的几种可执行文件格式有针对微软 Windows 平台的 PE（Portable Executable）格式、针对类 Unix 平台的 ELF（Executable and Linkable Format）格式，以及针对 MacOS 和 IOS 平台的 Mach-O 格式。</p><!-- [[[read_end]]] --><p>另外，值得一提的是，在 Unix 系统诞生早期，那时的可执行程序还在使用一种名为 “a.out” 的可执行文件格式。“a.out” 的全称为 “Assembler Output”，直译过来即“汇编器输出”。该名称来源于 Unix 系统作者 Ken Thompson 最早为 PDP-7 微型计算机编写的汇编器的默认输出文件名。时至今日，这个名称依然是某些编译器（比如 GCC）在创建可执行文件时的默认文件名。不仅如此，作为第一代可执行程序格式，它对后续出现的 ELF、PE 等格式也有着重要的参考意义。</p><p>接下来，我就以类 Unix 平台上最常使用的 ELF 格式为例，来带你看看这些可执行文件格式，究竟是以怎样的方式存储应用程序数据的。</p><h2>ELF 文件格式</h2><p>不同的可执行文件格式会采用不同方式，来组织应用程序运行时需要的元数据。但总体来看，它们对数据的基本组织方式都符合这样一个特征：<strong>使用统一的“头部（header）”来保存可执行文件的基本信息。而其他数据则按照功能被划分在了以 Section 或 Segment 形式组织的一系列单元中</strong>。当然，ELF 格式也不例外。</p><blockquote>\n<p>需要注意的是，在一些中文书籍和文章中，Section 和 Segment 这两个单词可能会被统一翻译为“段”或“节”。但对于某些格式，比如 ELF 来说，它们实际上则分别对应着不同的概念，因此为了保证同学们理解的准确性，这里我直接保留了英文。</p>\n</blockquote><p>接下来，让我们从一个真实的 C 程序入手，通过观察这个程序对应二进制文件的内容，你可以得到对 ELF 格式基本结构的一个初步印象。该程序的 C 源代码如下所示：</p><pre><code class=\"language-c++\">// elf.c\n#include &lt;stdio.h&gt;\nint main (void) {\n  const char* str = \"Hello, world!\";\n  printf(\"%s\", str);\n&nbsp; return 0;\n}\n</code></pre><p>经过编译后，我们可以得到上述代码对应的二进制可执行文件。接下来，使用 <code>file</code> 命令可以确认该文件的格式信息。该命令的执行返回结果如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/6f/72/6ff02c8c3a27be1fayye00b39af18c72.png?wh=1896x364\" alt=\"图片\"></p><p>根据命令执行结果开头处的信息，我们可以确认这是一个 ELF 格式的可执行文件。其中的 64-bit 表示该文件采用的是 64 位地址空间。除此之外，命令还回显出了该 ELF 格式的版本，是否采用动态链接，以及使用的动态链接器地址等信息。</p><p>接下来，我们通过 <code>readelf</code> 命令来查看该可执行文件的内部组成结构。顾名思义，这个命令专门用于读取特定 ELF 格式文件的相关信息。</p><h3>ELF 头</h3><p>通过为 readelf 指定 “-h” 参数，我们可以观察该文件的 ELF 头部内容。命令执行结果如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/1e/02/1e65c570bfe1a2eacfd2eed890441a02.png?wh=1920x1353\" alt=\"图片\"></p><p>ELF 头内包含有描述整个可执行文件重要属性的相关信息。应用程序在被执行时，操作系统可以借助其头部的相关字段，来快速找到支持程序运行所需要的数据。</p><p>其中，操作系统通过 Magic 字段来判断该文件是不是一个标准的 ELF 格式文件，该字段一共长 16 个字节，每个字节代表着不同含义。前四个字节构成了 ELF 文件格式的“魔数”，第一个字节为数字 0x7f，后三个字节则对应于三个大写字母 “ELF” 的 ASCII 编码。剩下的字节还标记出了当前 ELF 文件的位数（如 32/64）、字节序、版本号，以及 ABI 等信息。</p><p>除该字段外，ELF 头中还包含有 ELF 文件类型、程序的入口加载地址（0x4004b0），即程序运行时将会执行的第一条指令的位置，以及该可执行文件适用的目标硬件平台和目标操作系统类型等信息。ELF 作为一种文件格式，不仅在可执行文件中被使用，静态链接库、动态链接库，以及核心转储文件等也都可以采用这种格式。我们会在下面的 “ELF 文件类型” 小节中继续讨论这个问题。</p><h3>ELF Section 头</h3><p>在 ELF 格式中，Section 用于存放可执行文件中按照功能分类好的数据，而为了便于操作系统查找和使用这些数据，ELF 将各个 Section 的相关信息都整理在了其各自对应的 Section 头部中，众多连续的 Section 头便组成了 Section 头表。</p><p>Section 头表中记录了各个 Section 结构的一些基本信息，例如 Section 的名称、长度、它在可执行文件中的偏移位置，以及具有的读写权限等。而操作系统在实际使用时，便可直接从 ELF 头部中获取到 Section 头表在整个二进制文件内的偏移位置，以及该表的大小。</p><p>通过观察上图中的 ELF 头信息，我们能够得知，该 ELF 文件内包含有 30 个 Section 头，即对应 30 个 Section 结构，且第一个 Section 头位于文件开始偏移第 15512 个字节处。而通过为 <code>readelf</code> 命令指定 “-S” 参数，我们可以查看所有这些 Section 头的具体信息。</p><p>该命令的执行结果如下图所示（这里限于篇幅，我只列出了较为重要的几个 Section 头部的内容）：</p><p><img src=\"https://static001.geekbang.org/resource/image/1d/ee/1d083d9e4fd121bd87e2b6c34657b1ee.png?wh=1920x907\" alt=\"图片\"></p><p>可以看到，这里我主要筛选出了 .text、.rodata、.data、.bss 这四个 Section 对应头部的详细内容。如果你还记得我在 <a href=\"https://time.geekbang.org/column/article/465228\">02 讲</a> 和 <a href=\"https://time.geekbang.org/column/article/473400\">10 讲</a> 中介绍过的数据存储位置的相关知识，那对这四个 Section 一定不会陌生。其中，.text 主要用于存放程序对应的机器代码；.rodata 用于存放程序中使用到的只读常量值；.data 中包含有程序内已经初始化的全局变量或静态变量的值；而 .bss 中则存放有初始值为 0 的全局或静态变量值。</p><p>Section 头部中也标记了各个 Section 实际数据的所在位置。对于 .rodata 来说，我们可以在文件偏移第 0x658 个字节，或程序运行时在进程 VAS 中的偏移位置 0x400658 处看到它的实际内容。这里我们可以用 <code>objdump</code> 命令来验证一下。</p><p><code>objdump</code> 命令是一个可以用来查看二进制文件内容的工具，通过为它指定 “-s” 参数，我们可以查看某个 Section 的完整内容。该命令的执行结果如下所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/cf/5c/cf1da757ce431193e875db1e7b99025c.png?wh=1384x454\" alt=\"图片\"></p><p>可见，我们在 C 代码中使用到的字符串数据 “Hello, world!”，便被放置在了该 Section 距离其开头偏移 0x10 字节的位置上。</p><p>在 ELF 格式中，众多的 Section 组成了描述该 ELF 文件内容的静态视图。而静态视图的一大作用，便是完成应用程序整个生命周期中的“链接”过程。链接意味着不同类型的 ELF 格式文件之间会相互整合，并最终生成可执行文件，且该文件可以正常运行的过程。根据整合发生的时期，链接可以被分为“静态链接”与“动态链接”，这部分内容我会在后面的 27 讲与 29 讲中再为你深入介绍。</p><h3>ELF Program 头</h3><p>除了由 Section 组成的静态视图外，众多的 Segment 则组成了描述可执行文件的动态视图。Segment 指定了应用程序在实际运行时，应该如何在进程的 VAS 内部组织数据。同样地，我们也可以通过为 <code>readelf</code> 命令指定 “-l” 参数，来观察这一讲开头那个程序对应可执行文件的 Segment 情况。该命令的执行结果如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/a8/80/a8a703a4a2556ebd9fbf48e782804980.png?wh=1520x1986\" alt=\"图片\"></p><p>与 Section 类似的是，每个 Segment 也都有其对应的头部，以描述该 Segment 的一些基本信息，我们一般将其称为 Program 头。</p><p>Program 头中包含着各个 Segment 的类型、偏移地址、大小、对齐情况，以及权限等信息。其中，被标注为 “LOAD” 类型的 Segment 将会在程序运行时被真正载入到进程的 VAS 中，而其余 Segment 则主要用于辅助程序的正常运行（比如进行动态链接）。不仅如此，Program 头表的具体偏移位置和大小也被放置在了 ELF 头部中，因此操作系统可以在需要时，随时快速地得到这些信息。</p><p>通常来说，各个 Segment 与 Section 之间会有一定的对应关系。比如在上面的图片中，第一个 LOAD 类型的 Segment 便包含有 .text 和 .rodata 在内的多个 Section，而 .data 则被包含在第二个 LOAD 类型的 Segment 中。如果进一步观察，你会发现，第一个 LOAD Segment 具有的权限为 “RE”，也就是可读可执行；而第二个 LOAD Segment 具有的权限为 “RW”，即可读可写。那为什么这样分配呢？相信此时你一定有了答案。</p><p>另外我们观察到，第一个 LOAD Segment 所包含的内容，对应到可执行文件内的偏移（Offset）为 0。这意味着，操作系统在执行该程序时，除了各个 Segment 对应的 Sections 外，它还会将该文件的 ELF 头，连同它的 Program 头表一同加载到内存中。</p><p>到这里，我们已经对 ELF 格式二进制可执行文件的内部情况有了一个大致了解，如果想了解更多有关 ELF 格式的详细信息，你可以参考<a href=\"https://www.cs.cmu.edu/afs/cs/academic/class/15213-f00/docs/elf.pdf\">这个链接</a>。</p><p>虽然上面的内容没有涉及 ELF 内部的所有设计细节，但对于日常学习而言，其实掌握 ELF 格式的基本组成结构（ELF 头、Section 与 Segment 分别对应的静态视图和动态视图）就足够了。你可以参考下图，来更加直观地回顾一下这些内容：</p><p><img src=\"https://static001.geekbang.org/resource/image/c0/12/c0fa2a73133c42c5a8d790713b983f12.jpg?wh=1920x1692\" alt=\"图片\"></p><p>接下来，我们再一起看看如何使用 C 语言进行 ELF 编程。</p><h2>ELF 编程</h2><p>目前在 Linux 系统中，我们可以直接使用内核提供的头文件 elf.h 来进行针对 ELF 格式的应用编程。在该头文件中，预定义有针对不同 ELF 概念实体的各类结构类型与宏。</p><p>比如，对于 ELF 头部，我们可以直接在代码中使用该头文件中定义的 ElfN_Ehdr（N 根据所在系统的不同，可能取 32 或 64）类型来表示。下面这段 C 代码展示了如何使用这个类型：</p><pre><code>#include &lt;stdio.h&gt;\n#include &lt;elf.h&gt;\n\nvoid print_elf_type(uint16_t type_enum) {\n  switch (type_enum) {\n    case ET_REL: printf(&quot;A relocatable file.&quot;); break;\n    case ET_DYN: printf(&quot;A shared object file.&quot;); break;\n    case ET_NONE: printf(&quot;An unknown type.&quot;); break;\n    case ET_EXEC: printf(&quot;An executable file.&quot;); break;\n    case ET_CORE: printf(&quot;A core file.&quot;); break;\n  }\n}\n\nint main (void) {\n  Elf64_Ehdr elf_header;\n  FILE* fp = fopen(&quot;./elf&quot;, &quot;r&quot;);\n  fread(&amp;elf_header, sizeof(Elf64_Ehdr), 1, fp);\n  print_elf_type(elf_header.e_type);  // &quot;An executable file.&quot;\n  fclose(fp);\n  return 0;\n}\n</code></pre><p>在这段 C 代码中，我们简单地打开了当前目录下名为 “elf” 的二进制可执行文件，并从它的开头处直接读取了对应 Elf64_Ehdr 类型大小的数据，存放到名为 elf_header 的变量中。最后，通过访问该结构对象的 e_type 字段，我们便可得到该 ELF 文件的类型。在 elf.h 头文件中，定义有众多表示 ELF 特定指标的宏常量，比如，若 e_type 字段的值等于宏常量 ET_EXEC，那么表示该文件是一个可执行文件。</p><p>可以说，<strong>elf.h 头文件中包含有可用于描述所有合法 ELF 格式文件的各种自定义类型</strong>。因此，通过选择性地阅读和实践，来深入了解 ELF 的设计细节不失为一个好方法。如果想了解关于该头文件的更多信息，你可以通过命令 “man 5 elf” 来查看有关该头文件的 Linux 帮助文档，或者直接在<a href=\"https://man7.org/linux/man-pages/man5/elf.5.html\">这里</a>找到它的在线版本。</p><h2>ELF 文件类型</h2><p>在这一讲结束之前，让我们再来看一个问题： ELF 作为一种文件格式，它究竟在被哪些类型的文件使用呢？</p><p>通过上一小节的编程实战，我们可以得知：在 elf.h 头文件的定义中，ELF 格式可以应用在四种不同的文件类型上，它们对应的宏常量分别是 ET_REL、ET_DYN、ET_EXEC，以及 ET_CORE。</p><p>这里，我将上述四个宏常量与它们对应的 ELF 文件类型整理在了下面的表格中，供你参考：</p><p><img src=\"https://static001.geekbang.org/resource/image/60/e7/60921c618740bc18e3f267d225d750e7.jpg?wh=1920x1150\" alt=\"图片\"></p><p>这四种 ELF 文件类型，虽然名称各不相同，但其内部数据的整体组织方式都遵循同样的 ELF 文件格式标准。而不同点在于，由于每种文件类型的功能定位各不相同，因此其内部的 ELF 格式组成结构也各有差异。</p><p>就拿可重定位文件来说吧，该类型文件可用于支持大型项目的增量式开发，也就是将程序中可以模块化、独立分发的功能进行单独编译，并形成可重定位文件。而依赖于这些功能实现的应用程序代码，便可与这些可重定位文件一起编译。最后，在经过链接器的静态链接处理后，便能够得到程序对应的可执行文件。这种方式的好处在于，当每次程序功能发生变化时，都可以将需要重新编译的代码约束在最小的范围。</p><p>可重定位文件内仅包含有 Section 的相关信息，而没有 Program 头等用于支持其运行的 ELF 结构，因此该类型的文件无法被直接运行。而静态链接的一个主要作用，便是根据程序在 <code>main</code> 函数内的调用情况，收集各个可重定位文件中需要使用的功能实现，并最终生成对应含有 Program 头的可执行文件。那么，这个过程具体是怎样进行的呢？我将在下一讲中为你揭晓答案。</p><h2>总结</h2><p>好了，讲到这里，今天的内容也就基本结束了。最后我来给你总结一下。</p><p>这一讲的内容主要是以可执行二进制文件作为切入点的。我首先介绍了在不同操作系统上的几种常见可执行文件格式，然后以最常见的 ELF 格式为例，带你对它的组成细节进行了更为深入的探究。</p><p>ELF 文件格式的基本组成结构可以被划分为 ELF 头、Section 和 Segment 三大主要部分。其中，各个 Section 中包含有按照功能类别划分好的、用于支撑 ELF 功能的各类数据。这些数据共同组成了 ELF 文件的静态视图，以用于支持 ELF 文件的链接过程。而众多的 Segment 则组成了 ELF 文件的动态视图，该视图描述了 ELF 文件在被操作系统加载和执行时，其依赖的相关数据在进程 VAS 内的分布情况。</p><p>除了通过操作系统自带的 <code>readelf</code> 等工具来观察 ELF 文件的内部情况外，我们也可以利用 Linux 内核提供的 elf.h 头文件。该头文件内预先定义了众多的 ELF 元素类型，可辅助我们编写符合自身需求的 ELF 分析和处理工具。</p><p>最后，我们还探讨了几种不同 ELF 文件类型之间的区别。可重定位文件、共享目标文件、可执行文件，以及核心转储文件，它们虽然有着各自不同的应用场景和内部数据组成，但也都作为 ELF 文件类型的一种，遵循着 ELF 格式的基本规则。</p><h2>思考题</h2><p>尝试编写一个 C 程序，该程序可以读取并打印一个指定 ELF 文件的 Section 信息（Section 名称、大小，以及偏移地址）。</p><p>今天的课程到这里就结束了，希望可以帮助到你，也希望你在下方的留言区和我一起讨论。同时，欢迎你把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"24｜实战项目（下）：一个简单的高性能 HTTP Server","id":487230},"right":{"article_title":"26｜进程是如何使用操作系统内存的？","id":489139}}},{"article_id":489139,"article_title":"26｜进程是如何使用操作系统内存的？","article_content":"<p>你好，我是于航。</p><p>对于计算机软件的正常运作，内存（Main Memory）所发挥作用的重要性不言而喻。无论是处在“幕后”的操作系统，还是位于“台前”的用户应用程序，它们在运行时都会将所需数据从磁盘等外部存储器转移至内存。实际上，内存和 CPU 芯片上的 L1、L2 等高速缓存，一同构成了计算机中用于支撑程序高效运行的缓存系统。</p><p>今天，我们会先从整体的视角看看内存在计算机系统中的作用，然后再一起探究进程是如何在操作系统的控制下与计算机内存交互的。</p><h2>计算机内部的缓存系统</h2><p>通常，文件会被存放在容量较大的磁盘中。但磁盘作为一种提供数据持久化存储的设备，采用了机械式的数据寻址方式，这就使得它<strong>无法匹配 CPU 在完成相关操作时，所需数据在访问速度上的要求</strong>。而内存则以快于磁盘几万甚至十几万倍的读写效率，承担起了与 CPU 直接交互的重任。</p><p>但随着摩尔定律的不断应验，CPU 与内存两者在数据访问效率的“供需关系”上又出现了问题。因此，现代计算机通过在这两者之间引入更多读写速度更快，容量却更小的高速缓存层，并基于局部性原理，让 CPU 经常使用到的数据可以被更快地再次访问。通过这种方式，<strong>由 L1、L2 等片上高速缓存</strong><strong>，</strong><strong>以及内存组成的缓存系统，便成为了计算机中用于承载应用运行时数据的主要部件</strong>。</p><!-- [[[read_end]]] --><p>网上有一个十分形象的例子，描述了内存在整个计算机系统中的“地位”：假设你作为负责人，每天都在一间专属办公室里处理各种事务。办公室内有一个硕大的档案柜，里面存放着你有权限接触的所有办公材料。当每一次需要处理某个具体事务时，你都会首先将需要的相关材料一次性地从档案柜中全部拣选出来，并将它们陈列在书桌上，然后再继续进行处理。而随着时间的推移，那些经常被翻阅的、相关性较强的材料会被摆放在距离你手边较近的位置，而相关性较弱的材料则会被放在较远的位置。</p><p>将这个例子类比到计算机，你会发现两者之间有着类似的行为模式。每一个程序的机器代码（事务）在可以被 CPU（负责人）正常执行前，操作系统都需要先将它们从磁盘（档案柜）“搬移”到内存（书桌）中。而随着程序的不断运行，那些被经常访问的数据便会被存放到较高级别的缓存（较近位置）中。相反，不常用的数据则会被存放在较低级别的缓存（较远位置），甚至驻留在内存中。</p><p>但是，对计算机而言，程序与内存之间的交互细节远比“办公室日常”要复杂得多。现代操作系统会同时执行十几个甚至几十个程序。因此，如何从有限的内存中合理地为它们分配所需资源，并同时兼顾安全性、高效性，便成为需要考虑的首要问题。</p><p>现代计算机通过名为“虚拟内存”的机制，做到了这一点。下面，我们来进一步看看这个机制的具体工作原理。</p><h2>虚拟内存机制</h2><p>顾名思义，虚拟内存（Virtual Memroy）对应于物理内存（Physical Memory）。其中，前者是由操作系统抽象出来的一个概念，它在后者的基础之上进行了一层抽象，以帮助运行于其上的应用程序合理地分配内存，并管理内存使用。</p><p>因此，如下面的代码所示，我们在应用程序中打印出的各种指针值，它们实际上都对应于虚拟内存中的某个地址，而非实际的物理内存地址（Physical Address，PA）。这些地址被称为“虚拟地址（Virtual Address，VA）”。所有程序可以使用的虚拟地址则构成了虚拟地址空间（VAS）。</p><pre><code class=\"language-bash\">#include &lt;stdio.h&gt;\nint main(void) {\n  int x = 10;\n&nbsp; printf(\"%p\", &amp;x);&nbsp; // 0x7fff32cf54fc.\n&nbsp; getchar();\n&nbsp; return 0;\n}\n</code></pre><p>CPU 在访问内存中的数据时，会借助其芯片上名为“内存管理单元（MMU）”的硬件，首先将虚拟地址动态翻译为对应的物理地址，然后再进行实际的数据获取。你可以通过下图来直观地理解这个过程。</p><p><img src=\"https://static001.geekbang.org/resource/image/95/33/95352d3362a6569133153c1ace5b1833.jpg?wh=1920x571\" alt=\"图片\"></p><p>虚拟内存机制的一个最重要特征，就是<strong>为每一个应用程序进程都抽象出了独立于物理内存的虚拟地址空间</strong>。这意味着，从进程的角度来看，它可以独享整个计算机上的所有内存。现代操作系统通常采用 32 或 64 位地址空间，两者分别拥有 $2^{32} $ 与$2^{64}$个地址。通过这种方式，编译器在构建应用时，便不需要考虑各二进制数据段应该被实际加载到内存中的何处，所有应用均可使用统一的静态文件结构。</p><p>比如，在 64 位 Linux 系统中，与应用代码相关的 Segment 会从 VAS 的固定地址 0x400000 处开始加载。而其他 Section 内容将在满足一定对齐要求的情况下，按顺序被连续加载到高地址方向的虚拟内存中。这样，无论是程序在二进制文件内的静态视图，还是被加载到 VAS 后的运行时视图，它们都可以在虚拟内存的隔离下，在表现层有着稳定一致的布局。</p><p>而通过下面这行命令，我们便可以查看某个运行进程的 VAS 布局情况。注意，其中的 “<pid>” 需要被替换为进程对应的 ID。</pid></p><pre><code class=\"language-bash\">cat /proc/&lt;pid&gt;/maps\n</code></pre><p>这里，我们尝试将本小节开头处的那个 C 程序的 ID 替换到上述命令中。在运行该命令后，可以得到如下图所示的输出结果。</p><p><img src=\"https://static001.geekbang.org/resource/image/f5/64/f5626dd486fed604c418d8a3a1554164.png?wh=1406x712\" alt=\"图片\"></p><p>这里，命令按照地址由低到高的顺序打印出了进程 VAS 内，每一块已经被占用的连续虚拟内存地址，对应的映射信息。如最右侧一列所示，这些内存中的内容或是来自于某个具体文件（/www/workspace/main），或被用作其他用途（[heap]）。</p><h3>VAS 中的数据布局</h3><p>将上图中的信息进行归类，我们可以得到如下图所示的 Linux 进程在 VAS 内的统一数据布局结构。这里我根据类别，将不同的数据用不同的颜色进行了标注。并且，为了方便你找到这两个图之间的内存段对应关系，我将上图中的一些关键性地址信息也选择性地标注在了下图中。</p><p><img src=\"https://static001.geekbang.org/resource/image/7b/0e/7b63dce096e20e31731c354dc6d2e70e.jpg?wh=1920x2125\" alt=\"图片\"></p><p>总的来看，Linux 进程 VAS 中的数据，按照地址由低到高的顺序，可以被分为下面这几个主要部分。</p><ul>\n<li><strong>LOAD Segments</strong>：这部分数据被加载到从地址 0x400000 开始的虚拟内存中。其主要内容为应用程序 ELF 二进制文件内定义的各种 LOAD Segment 结构。按照顺序，与代码相关的 Text Segment（包含 .text、.rodata 等多个 Section）位于最低地址处，紧接着为包含有已初始化和未初始化数据的 Data Segment（包含 .data，.bss 等多个 Section）。</li>\n<li><strong>堆（Heap）</strong>：关于堆内存，我已经在 <a href=\"https://time.geekbang.org/column/article/471937\">08 讲</a> 中介绍过。随着动态数据的不断产生，它将向 VAS 的高地址方向不断增长。</li>\n<li><strong>共享库数据</strong>：这部分内存中包含有与各类 .so 共享库相关的数据，程序会在运行时通过动态链接器来完成对它们的加载和处理。我会在第 29 讲再为你详细介绍。</li>\n<li><strong>栈（Stack）</strong>：关于栈内存，我已经在 <a href=\"https://time.geekbang.org/column/article/468171\">05 讲</a> 中介绍过。随着各种局部变量的不断产生，它将向 VAS 的低地址方向不断增长。</li>\n<li><strong>用于系统调用加速的内核数据</strong>：接下来的三个虚拟内存区域 [vvar]、[vdso]，以及 [vsyscall] 中包含有操作系统内核的代码和数据结构，它们主要提供了用户进程可以直接与内核进行交互的接口。其中，[vvar] 中包含有只读的内核数据。而另外的 [vdso] 与 [vsyscall] 则包含有用于辅助操作系统，加速用户进程执行某些系统调用过程的信息。</li>\n<li><strong>其他内核数据</strong>：除此之外，在进程 VAS 的高地址处，还可能包含有与当前进程相关的各种数据结构。甚至，该区域内的某段虚拟内存页还会被直接映射到某段被所有进程共享的物理内存页上（比如用于 MMIO）。</li>\n</ul><p>可以看到，得益于虚拟内存机制的抽象，进程可以使用完全统一、独立的内存数据布局，而不用考虑这些数据在真实物理内存中的具体存储细节。那么，虚拟内存机制究竟是如何对物理内存进行管理的呢？接下来我们具体看看。</p><h3>使用页表维护虚拟页状态</h3><p>为了保证效率，操作系统通常会以“页”为单位，来在磁盘与内存之间传递数据。而实际上，它也正是通过为每一个进程提供独立的“页表”结构，来维护 VAS 中的虚拟页在对应物理内存中的映射状态的。</p><p>页表本身被维护在物理内存中，其内部由众多的“页表项（Page Table Entry，PTE）”组成。进程 VAS 中的每个虚拟页都对应于页表中的某个 PTE，而 PTE 中则包含有用于描述该虚拟页状态的众多字段。每一次 MMU 需要将一个虚拟地址翻译为物理地址时，它都会首先读取页表，以查询相关的 PTE 信息。然后，再根据虚拟地址内隐含的偏移信息，找到对应页中的目标位置。</p><p>在简化的实现中，PTE 可能由一个“有效位”字段与一个“地址”字段组成。其中，有效位用于表明该虚拟页是否已被缓存在物理内存中。若该位置位，则地址字段中存放有该页在物理内存中的起始位置。而在该位复位的情况下，若地址字段为空，则表明该虚拟页还未被分配。否则，地址字段中便保存有虚拟页内容在磁盘上的起始位置。</p><p>当 CPU 需要访问某个虚拟地址上的数据时，通常会发生以下两种情况：</p><ul>\n<li>MMU 查找进程页表，发现目标数据已被缓存，进而直接通过 PTE 中的物理地址获取并返回所需要的数据；</li>\n<li>MMU 查找进程页表，发现目标数据未被缓存，此时它会触发一个“缺页异常”。</li>\n</ul><p>在第二种情况中，缺页异常将会调用内核中特定的异常处理程序，该程序会在物理内存中选择一个页，以用来承载当前虚拟地址所对应的物理数据。其中，对于空闲页，内核会直接将虚拟页对应的内容从磁盘拷贝到该物理页中；而对于非空闲页，若该页已经被修改，则内核会首先将它的内容换出，即更新到磁盘。然后，再将磁盘上的内容拷贝至这块物理页中。</p><p>这里你可以先暂缓脚步，通过下图来直观地理解 CPU、MMU、页表、物理内存，以及磁盘五者之间的协作关系。</p><p><img src=\"https://static001.geekbang.org/resource/image/e5/1b/e5c86f61aefdfb4121034c0060ab921b.jpg?wh=1920x770\" alt=\"图片\"></p><p>页表隔离了进程的 VAS 与物理内存，使得两者之间的映射关系变得更加自由。而在这种方式下，当不同进程使用不同页表维护其各自 VAS 中虚拟页的映射时，多个进程之间便可做到真正的数据共享。而我将在 29 讲中介绍的“动态链接”技术便以此为基础。不仅如此，独立的 VAS 与页表也使得进程之间的私有内存不会被相互访问。</p><p>另外，通过在 PTE 中增加用于访问控制的相关字段（如可读、可写、可执行），CPU 可以在程序尝试非法访问某块内存数据时做出异常响应。</p><h3>使用多级页表压缩页表体积</h3><p>但是，上面介绍的一级页表有时却可能无法满足需求。试想，以目前常用的 64 位地址空间为例，假设页大小为已知最大的 2MiB，为保证完整映射，每个 PTE 大小为 8 字节。而为了能够在单一页表内维护进程整个 64 位 VAS 中所有虚拟页的信息，那么便需要为其匹配一个大小为 65535 GiB 的页表，而这显然是不现实的。因此，现代计算机通常会采用“多级页表”的方式，来优化页表的大小。</p><p>多级页表的思路很简单。以二级页表为例，假设在一个 32 位地址空间中，页大小为 4KiB，每个页表的大小也为 4KiB，且其中的每个 PTE 大小为 4 字节。此时，MMU 在进行物理地址查询时，首先会根据虚拟地址中隐含的虚拟页号信息来查找一级页表内的目标 PTE，而一级页表中的每个 PTE，此时实际上负责映射 VAS 中的一个 4MiB 的片。</p><p>按照树的形式展开，每个一级页表也都对应着一个独立的二级页表，二级页表中的每一个 PTE 则负责映射当前一级页表的 4MiB 的片中的某个 4KiB 的块。当一级页表查询完毕后，MMU 便可得到指向目标二级页表的地址。通过该地址，再联合虚拟地址中的另一部分虚拟页号信息，它便可找到目标数据所在物理内存的具体页。最后，结合虚拟地址中的页偏移信息，目标数据的最终物理地址便可被成功地“转换”出来。你可以通过下图来进一步理解上述流程：</p><p><img src=\"https://static001.geekbang.org/resource/image/bb/32/bb2903b5463fbb211e7390ee48817432.jpg?wh=1920x1182\" alt=\"图片\"></p><p>多级页表可以节省内存空间的两个最重要因素是：</p><ul>\n<li>当一级页表中的某个 PTE 没有实际映射时，其对应的二级页表便不会被创建；</li>\n<li>只有一级页表才需要常驻内存，二级页表可以仅在需要时再创建，或从磁盘调入。</li>\n</ul><p>实际上，上述二级页表的使用形式可以被推广到任意的 N 级。但总体来看，页表的级数并非越多越好，因为更多的页表级数也就意味着更长的物理地址查询时间。目前常见的多级页表为 4 级，而在 Ice Lake 等处理器中，也出现过 5 级页表。</p><h3>使用 TLB 加速 PTE 查询</h3><p>多级页表虽然可以压缩页表占用的内存量，但用 MMU 进行页表的逐级查询，这个过程也并不是毫无成本的。现实情况中，计算机通常会结合使用名为“翻译后备缓冲器（Translation Lookaside Buffer，TLB）”的硬件设备来加速这一流程。</p><p>TLB 属于 MMU 的一部分，它可以加快 MMU 根据虚拟地址查询 PTE 的过程。你可以将 TLB 理解为一个简单的具有 N 行 M 列的矩阵，MMU 会从对应虚拟地址中提取出用于查询表项的 TLB 索引与 TLB 标记。这两个值可以联合起来使用，并定位到 TLB 中的一个具体单元格。而此时，若该单元格内有值，则 MMU 可以直接使用该值，来与虚拟地址中的其他信息一起组成最终的物理地址。否则，MMU 仍然需要通过逐级查询页表的方式来获取目标页的物理地址。</p><h3>再谈共享对象与私有对象</h3><p>上面，我曾在“使用页表维护虚拟页状态”一节的最后提到，借助虚拟内存机制，不同进程之间可以共享物理内存上的同一段数据。</p><p>这些数据在物理内存中实际存放时，可能并不是连续的。而借助于页表实现的“虚拟页与物理页映射关系分离”，我们可以确保 CPU 能够按照连续的方式来使用这些数据。</p><p>而当某个共享进程试图对这些共享数据进行修改时，操作系统便会通过“写时复制（Copy-on-write）”的方式，来将被变更数据所在的物理页进行复制，并通过修改页表，来让修改进程可以私有化这部分数据。</p><h2>总结</h2><p>这一讲，我主要为你介绍了进程是如何在操作系统的控制下使用内存资源的。</p><p>在现代计算机中，内存和 CPU 芯片上的高速缓存一起构成了用于承载应用运行时数据的缓存系统。而这个缓存系统，在名为“虚拟内存”机制的帮助下，能够以一种更加优雅的方式运作。</p><p>虚拟内存机制为每一个进程都抽象出了独立且私有的虚拟地址空间（VAS）。VAS 中使用虚拟地址进行寻址，当 CPU 需要通过该地址访问内存中的某个数据时，芯片上的内存管理单元（MMU）会将该地址转换为对应的物理地址。不同的操作系统都会在 VAS 中为进程使用相对统一的数据布局方式，这样，编译器便可简化其构建应用的流程。</p><p>操作系统使用名为“页表”的数据结构来维护 VAS 中虚拟页与物理页之间的映射关系。通过查询页表项（PTE）的状态，操作系统可以直接获得目标数据所在页的物理地址，或是通过触发缺页异常，来让操作系统内核将目标数据从磁盘加载到物理内存中，然后再重新获取该地址。在这个过程中，内核可能会将物理内存中，某个已修改的非空闲页的内容换出到磁盘。</p><p>为了减小分配给每个进程的页表大小，现代计算机通常采用多级页表的方式来管理虚拟页与物理页的映射关系。而在这种方式下，由于需要查询的表项过多，计算机还会采用名为 TLB 的硬件设备，来缓存之前的表项查询结果，并加速下一次相同虚拟页的查询过程。</p><p>最后，虚拟内存机制使得多个进程可以同时共享物理内存中的某段数据，而无需将数据拷贝多份。但当某个进程试图修改这些共享数据时，操作系统会通过“写时复制”的方式来将被修改数据进行拷贝，并使其对修改进程私有化。</p><h2>思考题</h2><p>试着查阅资料来了解一下，为什么 Linux 进程 VAS 从地址 0x0 开始，直到 0x400000 的低地址段，没有存放任何数据？欢迎在评论区告诉我你的发现。</p><p>今天的课程到这里就结束了，希望可以帮助到你，也希望你在下方的留言区和我一起讨论。同时，欢迎你把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"25｜可执行二进制文件里有什么？","id":487944},"right":{"article_title":"27｜编译器在链接程序时发生了什么？","id":489879}}},{"article_id":489879,"article_title":"27｜编译器在链接程序时发生了什么？","article_content":"<p>你好，我是于航。</p><p>我曾在<a href=\"https://time.geekbang.org/column/article/464550\"> 01 讲</a> 的最后提到，C 代码的完整编译流程可以被分为四个阶段：代码预处理、编译优化、汇编，以及链接。在前三个阶段中，编译器会对输入的源代码文件依次进行分析、优化和转换，并生成可以在当前平台上使用的对象文件。紧接着，链接过程可以将程序依赖的所有对象文件进行整合，并生成最终的二进制可执行文件。</p><p>今天，我就来带你深入看看，这个“链接”的过程究竟是怎样执行的。按照发生时刻的不同，链接可以被分为编译时链接、加载时链接，以及运行时链接三种类型。其中，编译时链接又被称为“静态链接”，它是链接的一种最基本形态，今天我们便从它开始入手。</p><p>这一讲中，我会以 Linux 系统下的静态链接为例来进行介绍。虽然在其他操作系统中，这个过程的发生细节可能有所不同，但总的来看，静态链接在处理对象文件时采用的基本方法和目的都是一致的，你可以依此类推，举一反三。</p><h2>静态链接 vs 动态链接</h2><p>一个程序在被编译时，我们可以选择性地为其使用静态链接或动态链接。那么，二者的概念和使用场景有什么区别呢？这是经常被大家讨论的一个问题，接下来我们一起看看。</p><p>“静态链接”中的“静态”，实际上是指<strong>在用户准备执行这个程序前，<strong><strong>它</strong></strong>正常运行所依赖的全部代码实现便已经“静静地躺在那里”，成为了整个可执行文件的一部分</strong>。相对地，使用动态链接编译的程序，编译器只会为这些依赖代码在可执行程序文件中留下用于临时占位的“槽”。而只有当用户开始调用程序时，相关代码才会被真正加载到内存。而这就是“动态”一词的重要体现之一。</p><!-- [[[read_end]]] --><p>静态链接与动态链接两者的区别，也同样体现在了与程序相关的一些性质上，其中最关键的三点是<strong>程序可执行文件的体积、程序的执行效率，以及程序的可移植性</strong>。</p><p>对于静态链接来说，由于所有依赖代码都被打包在一起，因此它对应的可执行文件体积会相对较大。但也正是因为不需要外部依赖，所以可移植性较好，程序的执行效率也不会受到影响。相对地，动态链接由于不会将依赖代码打包，所以它对应的可执行文件可以被维持在一个较小的体积。但由于需要程序运行所在环境中包含这些依赖，因此可移植性相对较差。并且，由于这些依赖代码仅会在用户实际调用程序那一刻，才被加载进内存，程序的启动效率会受到一定影响。</p><p>但实际来看，在具体使用上，静态链接与动态链接两者并不是完全互斥的。通常来说，在编译程序时，我们会对那些基础且常见的公有代码库（如 libc、libm、libthread 等）采用动态链接。这些系统库已经成为支持现代操作系统正常运作的一部分，因此在大多数情况下它们都不可或缺。而对于应用程序独有的那部分实现，我们一般采用静态链接，让它们能够直接成为二进制可执行文件的一部分。</p><h2>静态链接的处理过程</h2><p>接下来，我们将使用如下所示的两段代码，来进一步探究静态链接的详细发生过程（这里为了方便你观察，我将它们放在了同一个代码块中）。你可以通过每段代码上方的注释信息，来区分它们所属的不同文件。</p><pre><code class=\"language-c++\">// main.c\n#define LEN 2\nextern int sharedArr[LEN];\nextern int sum(int *arr, int n);\nint* array = sharedArr;\nint main(void) {\n&nbsp; int val = sum(array, LEN);\n&nbsp; return val;\n}\n\n// sum.c\n#define LEN 2\nint sharedArr[LEN] = { 1, 2 };\nint sum(int *arr, int n) {\n  int i, s = 0;\n  for (i = 0; i &lt; n; i++) {\n    s += arr[i];\n  }\n  return s;\n}\n</code></pre><p>这个程序的逻辑十分简单。在文件 sum.c 中，我们首先定义了名为 sharedArr 的全局数组。接着，又定义了名为 sum 的函数，该函数会计算并返回给定数组 arr 的前 n 个元素之和。而在文件 main.c 中，我们定义了指针变量 array，该变量将会引用 sum.c 文件内的全局数组 sharedArr。而在 main 函数中，通过调用 sum 函数，我们返回了指针 array 所指向数组的前两项之和。</p><p>接着，我们使用 GCC 来将上述代码分别编译为一个二进制可执行文件 main，以及对应的两个目标文件 main.o 与 sum.o。与上述编译流程相关的命令如下所示：</p><pre><code class=\"language-bash\">gcc main.c sum.c -o main  # 生成可执行文件 main；\ngcc -c main.c -o main.o  # 生成目标文件 main.o；\ngcc -c sum.c -o sum.o  # 生成目标文件 sum.o；\n</code></pre><p>在接下来的内容中，我将以这三个文件为例，来带你深入观察上面两个目标文件是如何在静态链接的一系列处理后被整合在一起，并体现在最终的可执行文件里的。首先，让我们从目标文件入手，来看看 Linux 平台上的 .o 文件究竟有何不同。</p><h3>可重定位目标文件的基本结构</h3><p>回顾我在 <a href=\"https://time.geekbang.org/column/article/487944\">25 讲</a> 中“ELF 文件类型”这一小节里介绍的内容，你能够知道，Linux 平台上的 .o 目标文件实际上是一种被称为“可重定位文件”的 ELF 文件类型。因此，它的内部也同样遵循着与 ELF 二进制可执行文件类似的布局方式。只是相较于后者，它不包含有与动态视图相关的多种 Segment 与 Program 头部。因此，各种不同类型的 Section 便成为了用于描述它所有特征的基本组成结构。</p><p>这里，我将目标文件中的几个与静态链接过程密切相关的 Section 整理在了表格中，你可以先对它们的基本功能有一个大致印象。我会在接下来的内容中，带你仔细观察它们是如何在链接过程中发挥重要作用的。</p><p><img src=\"https://static001.geekbang.org/resource/image/9f/cc/9fe80e68cfe78beb4b6efc5cfa9af4cc.jpg?wh=1920x1069\" alt=\"图片\"></p><p>每一个可重定位目标文件内都存在有一个符号表，它包含了该文件对应源码内使用到的所有全局变量和函数信息。而通过使用名为 “nm” 的命令，我们可以查看这些文件中的符号表。这里，通过对 main.o 与 sum.o 这两个目标文件使用该命令，你会得到如下图所示的输出结果：</p><p><img src=\"https://static001.geekbang.org/resource/image/63/d3/639d95be36f2d19ffa01b20875db16d3.png?wh=1604x298\" alt=\"图片\"></p><p>可以看到，不带有任何参数的 nm 命令会打印出有关符号的三部分信息（对应于图片中的三列）：</p><ul>\n<li>第一列的数字值为符号在对应 Section 中的偏移位置；</li>\n<li>第二列中的大写字母表明了符号的具体类型。这里，D 表明符号为已初始化的全局数据，即位于 .data Section；T 表示符号为函数，即位于 .text Section；U 则表示符号是未定义的；</li>\n<li>第三列为符号的具体名称。</li>\n</ul><p>链接器在整合 main.o 与 sum.o 这两个目标文件时，它的最重要工作之一就是为每一个程序使用到的符号找到与它匹配的符号定义，这个过程通常被称为“符号解析”。而如果链接器在搜索完所有输入的目标文件后，仍存在无法被解析的符号，它便会终止程序处理，并抛出类似 “undefined reference to <code>symbol</code>” 的错误信息。</p><p>但在此之前，链接器会首先对这些目标文件进行扫描，来获取它们各自的 Section 相关信息，同时计算出待输出文件中的 Section 布局信息。而为了便于后续处理，链接器还会将所有目标文件内的符号信息收集起来，统一放到一起，作为一个“全局符号表”来使用。接下来，我们就详细看看静态链接的第一个步骤，符号解析的具体流程。</p><h3></h3><h3>步骤一：符号解析</h3><p>编译器在编译源代码时，会为无法在当前编译单元内找到定义的符号生成一个特定的符号表条目，同时把“为该符号寻找定义”这个重任交给链接器。而链接器在随后进行符号解析时，便会在包含有全部符号信息的全局符号表中进行搜索。</p><p>如果链接器在这个过程中找到了符号的多个定义，它便会按照一定的规则来进行解析。编译器在编译源代码时，会为每一个全局符号指定对应的“强弱”信息，并同时将其隐含地编码在符号对应的符号表条目中。通常来说，函数和已初始化的全局变量为强符号，而未初始化的全局变量则是弱符号。而链接器对符号定义的选择会根据如下规则进行：</p><ul>\n<li>如果有一个强符号和多个弱符号同名，则选择强符号；</li>\n<li>如果有多个弱符号同名，则从这些弱符号中任意选一个（通常会选择其中类型占用空间最大的那个）；</li>\n<li>如果存在多个强符号同名，则抛出链接错误。</li>\n</ul><p>符号之所以会有强弱之分，主要是为了做到这一点：<strong>当不确定某个符号是否被用户显式定义的情况下，链接器仍然可以选择使用对应的弱类型符号版本来编译程序</strong>。这种能力通常被用在各类框架中，以便为某类程序编译所依赖的代码部分提供默认实现。除此之外，在模块化的代码调试场景中（比如单元测试中的桩代码），当某个待测试模块的依赖模块还没有被实现时，链接器可以选用标记为弱类型的默认版本来编译程序。</p><p>比如，在 GCC 中，我们可以通过为函数显式添加 <code>__attribute__((weak))</code> 标记的形式，来将它标记为弱符号。但需要注意的是，这种方式会对代码的可移植性产生一定影响。</p><h3>步骤二：重定位</h3><p>通过上面的步骤，链接器已经可以为每一个外部符号引用，找到一个与之关联的符号定义了。比如，对于这一讲开头的实例来说，位于 main.o 文件内的未定义符号 sharedArr 与 sum 便会与 sum.o 文件内的同名符号进行匹配。</p><p>到这里，链接器便可以根据之前收集到的所有信息，开始将多个目标文件内相同类型的 Section 进行合并。同时，为这些 Section，以及所有输出文件内使用到的符号指定运行时的 VAS 地址。在这一步中，链接器会通过名为“重定位”的步骤来修改 .data 与 .text 两个 Section 中，对每个符号的引用信息，使得它们可以指向正确的运行时地址。</p><p>重定位的一个主要目的在于，将之前各个独立编译单元（目标文件）内，所有对外部符号的引用地址进行修正。比如在我们之前的例子中，main.o 文件内便存在有两个外部符号引用 sharedArr 与 sum。编译器在编译该文件时，由于尚不清楚这些符号定义的真实所在位置，因此会使用默认值（比如 0）来作为它们在机器代码中的地址占位符。</p><p>当然，除了对引用地址的修正外，可以看到，同样是在 main.o 文件内，array 变量的具体值实际上也依赖于外部符号 sharedArr 的确切所在地址。而且，已初始化的全局变量，其初始值被存放在了 .data 中，因此，这个位于该 Section 中的 array 变量的初始值，也需要被一同修改。</p><p>到这里，我们能够得知，链接器的另一个重要作用便是在组合各个目标文件的同时，对我们上面提到的这些值进行修正。而这一过程的正确执行，便依赖于我在前面介绍的两个特殊 Section，即 .rela.data 与 .rela.text。通过为 readelf 命令添加 “-r” 参数，我们可以查看 main.o 文件内，这两个 Section 的内容，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/b4/f8/b4bcf85eae4edff6eb97c260c15545f8.png?wh=1626x464\" alt=\"图片\"></p><p>这两个特殊的 Section 通常也被称为“重定位表”，在它们的内部，以一行行表项的形式分别保存着链接器在重定位时需要在 .text 与 .data 中修改的具体位置和方式。这里每个表项中第一列的 Offset 属性，表明该重定向目标在对应 Section 中的偏移；Type 属性表明了重定位类型，即链接器在处理该重定位表项时，需要使用的特定方式；Sym.Value 属性为当前重定位符号的值；最后的 “Sym. Name + Addend” 属性为符号的名称，外加在计算该符号地址时需要被修正的量。</p><p>通过使用 objdump 命令，我们可以在 main.o 文件内找到上述重定向目标在各个 Section 中的位置，具体如下图所示（这里，我用红色的框将这些位置标注了出来）：</p><p><img src=\"https://static001.geekbang.org/resource/image/b3/17/b3ac03dd8382ce12a7f3e5605745aa17.png?wh=1690x1110\" alt=\"图片\"></p><p>总的来看，上面我提到的重定位类型，在 X86-64 体系下可以被分为 6 种，如下表所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/8e/bd/8eed9bba0e0977ab5b212c011e5784bd.jpg?wh=1920x842\" alt=\"图片\"></p><p>在本例中，我们需要特别关注的是其中的 R_X86_64_PC32、R_X86_64_PLT32 与 R_X86_64_64。表格中的最后一列指明了链接器在更正地址时需要遵循的计算方式。这里，S 表示符号的实际地址；A 表示重定位条目中符号对应的 Addend（在 i386 中，由于 ELF32 的特殊要求，这个值被直接存放在被修改的内存位置上）；P 表示被修改的具体位置；L 表示在 PLT 中该符号的入口地址（PLT 通常用于实现函数的间接调用，我会在第 29 讲中介绍与它相关的内容）。</p><p>接下来，我们以 .rela.text 中的第一个重定位条目为例，来看看链接器在处理重定位时的具体流程。根据标注的类型 R_X86_64_PC32，我们能够知道更正值的具体计算方式为 “S + A - P”。其中，S 表示符号 array 在输出文件中的实际地址，这里我们可以通过 nm 命令来查看：</p><p><img src=\"https://static001.geekbang.org/resource/image/1b/93/1be3a781276fa45d2f06dfb9a948ea93.png?wh=1340x100\" alt=\"\"></p><p>可以看到，这个地址为十六进制值 0x601020。紧接着，A 表示符号 array 在重定位条目中的 Addend，即 -4。最后，P 表示当前重定向条目在输入文件中的修改位置。同样地，使用 objdump 命令，我们可以得到这个值。</p><p><img src=\"https://static001.geekbang.org/resource/image/79/8c/79f7a99821bfc6c35e8ce64ae7c8218c.png?wh=1920x525\" alt=\"图片\"></p><p>上图中的红框标注了该行机器指令的起始位置，在此基础之上，再向“右侧”移动 3 个字节，我们便可得到重定向的修改位置，即 0x400541。最后，按照公式 “S + A - P” 进行计算，即 数学公式: $0x601020 - 0x4 - 0x400541$，链接器便可得到最终的修改值 0x200adb。通过与上图中使用绿色框标注的内容进行比对，我们可以验证这个结果。这里需要注意的是，图中的“左侧”为低地址位（LSB），因此其字节顺序与我们的结果相反。</p><p>通过类似的方式，链接器可以完成对所有重定位条目的处理过程。而在此之后，输出的可执行文件中，所有符号也都有了正确的初始值和引用地址。随后，程序便可以被操作系统加载进内存，正常运行。</p><h2>总结</h2><p>今天我主要为你介绍了 Linux 中的静态链接，以此为例，带你深入了解了编译器在链接程序时发生了什么。</p><p>静态链接与动态链接相对应，主要是指“<strong>在链接过程中，来自于不同目标文件的代码会被整合为二进制可执行文件的一部分</strong>”这个过程。总的来看，静态链接被分为两个步骤：符号解析与重定位。</p><p>其中，符号解析是指为应用程序使用的所有符号正确匹配对应符号定义的过程。当有重名的多个符号定义存在时，链接器会按照一定规则来选择适用的版本。</p><p>而在重定位过程中，链接器会将输入的多个目标文件的同类型 Section 进行合并，并为它们和所有程序使用到的符号分配运行时的 VAS 地址。紧接着，借助重定位表中的信息，链接器可以对上一步中得到的外部符号，进行地址及值上的修正。</p><h2>思考题</h2><p>查阅相关资料，尝试了解下：在 Linux 系统中，以后缀 “.a” 结尾的静态库文件与 .o 目标文件，二者之间有什么关系呢？欢迎在评论区告诉我你的发现。</p><p>今天的课程到这里就结束了，希望可以帮助到你，也希望你在下方的留言区和我一起讨论。同时，欢迎你把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"26｜进程是如何使用操作系统内存的？","id":489139},"right":{"article_title":"28｜程序可以在运行时进行链接吗？","id":490462}}},{"article_id":490462,"article_title":"28｜程序可以在运行时进行链接吗？","article_content":"<p>你好，我是于航。</p><p>在上一讲中，我介绍了有关 Linux 下静态链接的内容。而这一讲，我们将继续程序的“链接”之旅，来看看我之前提到的另外两种链接类型，加载时链接与运行时链接。</p><p>实际上，加载时链接与运行时链接均可归为动态链接，只是在这两种方式中，程序进行链接的具体时刻有所不同。其中，加载时链接发生在程序代码被真正执行之前；而运行时链接则可发生在程序运行过程中的任意时刻。</p><h2>为什么要使用动态链接？</h2><p>在上一讲中，我已经简单介绍了静态链接与动态链接两者的区别。其实，动态链接技术出现的最重要目的，便是为了解决静态链接具有的一些明显缺点。试想，假设一个应用程序依赖于多个第三方模块提供的函数实现，而这些模块均以静态库（包含有多个目标文件）的方式提供。那么，每次想要使用它们的最新版本时，我们都需要显式地将程序与它们重新进行链接。对于大多数普通的应用使用者来说，这个过程所花费的成本当然是无法接受的。</p><p>另外，使用完全静态链接也会导致那些本可以被多次重用的通用功能函数，无法被统一“提取出来”，这便会导致程序的二进制可执行文件体积变大。并且，这些通用代码的副本会随着多个进程的运行，被多次加载到内存中，而这也极大地浪费了宝贵的内存资源。而动态链接技术的出现，便可以解决上述这些问题。</p><!-- [[[read_end]]] --><p>能够使用动态链接加载的库被称为“共享库（Shared Library）”。在 Linux 中，这类库文件通常以 “.so” 后缀结尾。在深入介绍动态链接的基本原理之前，我们先来看看如何在真实项目中使用它。</p><h2>使用共享库</h2><p>回顾<a href=\"https://time.geekbang.org/column/article/487944\"> 25 讲</a> 中的内容，我们能够知道，动态库本身也是 ELF 格式的一种具体文件类型，它对应着 elf.h 中的宏常量 ET_DYN。接下来，我仍以上一讲中的两段代码为例，来带你看看如何在实际项目中使用动态库。</p><p>这里，我们将把 sum.c 文件编译成动态库，并让 main.c 对应的应用程序使用。整个过程可以分为如下几步：</p><ol>\n<li>使用命令 <code>gcc sum.c -shared -fPIC -o libsum.so</code> 将文件 sum.c 编译成名为 libsum.so 的动态库文件。这一步中使用的参数 “-shared” 表明创建一个动态库；参数 “-fPIC” 表明生成“位置无关代码”。关于这个选项的详细用途，我会稍后为你介绍。</li>\n<li>使用命令 <code>gcc -o main main.c -lsum -L.</code> 编译应用程序。这里我们将 main.c 与第一步生成的 libsum.so 共享库放在一起编译。命令中，参数 “-L.” 可用于为编译器指定更多的共享库查找目录，这里我们为其添加了 libsum.so 的所在目录；参数 “-l” 则用于指定需要参与编译的共享库，通过指定名称 “sum”，编译器会自动使用搜索到的，合法的 libsum.so 文件。</li>\n<li>使用命令 <code>export LD_LIBRARY_PATH=.:$LD_LIBRARY_PATH</code> 设置动态链接器在查找相关动态库时的位置。顾名思义，动态链接器是一段在程序运行时，用于帮助其查找所需共享库的代码。它在查找指定共享库文件时，会按照一定顺序，从多个不同位置进行查找。而这里通过 LD_LIBRARY_PATH 环境变量指定的位置，便是其中一个。</li>\n<li>使用命令 <code>./main</code> 运行程序。</li>\n</ol><p>需要注意的是，除了可以使用上述第三步介绍的“修改 LD_LIBRARY_PATH 变量”的方式来指定共享库的运行时查找目录外，我们还可以使用 <a href=\"https://en.wikipedia.org/wiki/Rpath\">rpath</a> 和 <a href=\"https://man7.org/linux/man-pages/man8/ldconfig.8.html\">ldconfig</a> 这两种方式。它们分别通过“将动态库所在路径嵌入到可执行文件”，以及“将共享库安装到当前系统可访问的全局环境中”这两种方式，使得对应的共享库可以顺利地被动态链接器查找。这里，你可以直接点击对应的链接，来了解更多信息。</p><p>而为了让共享库真正地做到“可以被多个进程共享”，我们便需要让它的代码成为“位置无关代码”。下面我们来看看这个概念。</p><h2>位置无关代码</h2><p>位置无关代码（Position Independent Code，PIC）是一类特殊的机器代码，这些代码在使用时，可以被放置在每个进程 VAS 中的任意位置，而无需链接器对它内部引用的地址进行重定位。大多数现代 C 编译器在编译源代码时，均会默认产生这种 PIC 代码，而无需用户显式指定。当然，为了以防万一，你也可以通过添加 “-fPIC” 等参数的方式来明确指出。</p><p>通常来说，我们可以将模块（可以理解为独立的应用程序，或共享库）之间的数据引用分为四种方式：</p><ul>\n<li>模块内部的函数调用；</li>\n<li>模块内部的数据访问；</li>\n<li>模块之间的函数调用；</li>\n<li>模块之间的数据访问。</li>\n</ul><p>其中，模块内部的函数调用在大多数情况下可以直接以 PC-relative 的寻址方式进行，因此它并不依赖于目标函数在整个进程 VAS 内的绝对地址。而对于模块内部的数据访问，由于编译器在生成模块代码时，其 .data 与 .text 两个 Section 之间的相对位置是固定的，数据的访问也可以使用稳定的相对地址进行。总的来看，发生在模块内部的数据或函数资源引用，都不会因为模块代码被加载到进程 VAS 的不同地址而受到影响。但对于不同模块之间来说，事情就变得复杂了起来。</p><p>来看一个简单的例子。假设有一个共享库 M，它在内部的某个函数需要引用由应用程序定义的某个全局变量。而此时，程序 A 与 B 都想使用 M 中的这个函数。但相关的共享库代码（引用处）以及程序代码（被引用处），两者在进程 VAS 中的具体加载位置都并不确定。因此，在大多数情况下，两个程序对 M 中该变量引用地址的重定位修改值也并不相同。而这便会导致它们无法真正地共享同一份物理内存中模块 M 的代码。</p><p>PIC 的出现使得共享库代码可以做到真正地被多个进程复用，它利用了一个很简单的思想，即“将易变的部分抽离到进程独享的可修改内存中”。而为了做到这一点，编译器需要为各个模块添加额外的 Section 结构，这就是我接下来要讲的“全局偏移表”。</p><h3>全局偏移表</h3><p>全局偏移表（Global Offset Table，GOT）是位于每个模块 Data Segment 起始位置处的一个特殊表结构，其内部的每个表项中都存放有一个地址信息。而这些地址便分别对应于被当前模块引用的外部函数或变量在进程 VAS 中的实际地址。</p><p>模块在被编译时，其 Text Segment 与 GOT 之间的相对距离是能够计算出来的。因此，编译器可以利用这一点，来让代码直接引用 GOT 中的某个表项。同时，编译器还会为这些表项生成相应的重定位记录。这样，当程序被加载进内存时，动态链接器就可以根据实际情况，通过修正 GOT 表项中的值，来做到间接修正代码中对应符号的实际引用地址。你可以通过下图来直观地感受这个流程：</p><p><img src=\"https://static001.geekbang.org/resource/image/09/cf/09e2f8a04f1d221ef5ee50c918e6b9cf.jpg?wh=1920x881\" alt=\"图片\"></p><p>但需要注意的是，<strong>并非所有编译器都会通过 GOT 来间接引用模块使用到<strong><strong>的</strong></strong>所有全局变量</strong>。为了优化程序在某些特殊场景下的性能，编译器可能还会采用 Copy Relocation 等方式，来实现同样的效果。但对于外部函数的调用来说，GOT 在整个过程中仍然扮演着十分重要的角色。</p><h3>过程链接表</h3><p>虽然我们可以让动态链接器在程序加载时，将其代码中使用到的所有外部符号地址，更新在相应的 GOT 表项中，但当程序依赖的外部符号越来越多时，重定位的成本也会越来越高。而这便会导致程序初次运行时的“启动延迟”逐渐变大，甚至影响到程序正常功能的运作。为了解决这个问题，编译器为模块另外添加了名为“过程链接表（Procedure Linkage Table，PLT）”的 Section 结构。该表将协同 GOT，一起进行针对函数符号地址的“延迟绑定”。</p><p>PLT 是位于 Text Segment 中的一个表结构，其内部同样由众多表项组成。每个表项中都有着一段特殊的机器代码，用于完成相应任务。其中，PLT[0]（即 PLT 中的第一个表项，其他写法依此类推）较为特殊，它内部存放的代码专门用于调用动态链接器。而其他表项中则依次存放着，用于完成用户函数调用过程的相关代码。这些表项的地址将被程序中的 <code>call</code> 指令直接使用。</p><p>除此之外，在 ELF 文件中，GOT 对应的整个 Section 实际上被划分为更细致的 .got 与 .got.plt 两个部分。其中，前者主要用于保存相关全局变量的地址信息；而后者则主要参与到函数符号的延迟绑定过程中。.got.plt 中的前三个表项具有特殊意义，它们保存的具体内容描述如下：</p><ul>\n<li>第一个表项中保存的是 .dynamic 的地址。这个 Section 中保存了动态链接器需要使用的一些信息；</li>\n<li>第二个表项中保存的是当前模块的描述符 ID；</li>\n<li>第三个表项中保存的是函数 _dl_runtime_resolve 的地址。该函数由操作系统的运行时环境提供，它将参与到 GOT 的运行时重定位过程中。</li>\n</ul><p>接下来，我们详细看看延迟绑定的具体执行过程。这里，我将以上面“使用共享库”小节中，共享库里 sum 函数的调用过程为例来进行介绍。你可以先看看下面的图片，对整体流程有个大致的感知，然后跟我具体来看每个步骤。</p><p><img src=\"https://static001.geekbang.org/resource/image/26/c3/26a3afb43b5210f350d1c2cca24ef7c3.png?wh=3360x2084\" alt=\"\"></p><p>sum 函数的初次调用过程可以分为四步：</p><ol>\n<li>程序通过 <code>call</code> 指令，调用对应于 sum 函数的 PLT 表项中的代码；</li>\n<li>该表项中的第一行代码（位于 0x400560）会通过 .got.plt 的第四个表项中的值进行间接跳转。该表项对应于函数 sum 的真实地址，但在第一次访问时，其值为对应 PLT 表项中第二条指令的地址（即 0x400566）；</li>\n<li><code>push</code> 指令（位于 0x400566）将 sum 函数的 ID 压入栈中。通过 <code>jmp</code> 指令（位于 0x40056b），程序跳转到 PLT[0]；</li>\n<li><code>push</code> 指令（位于 0x400550）将 GOT[1] 中存放的模块描述符 ID 压入栈中，然后通过 <code>jmp</code> 指令（位于 0x400556）跳转到 GOT[2] 中存放的 _dl_runtime_resolve 函数的所在地址。该函数会使用当前存放于栈上的两个参数，来完成 sum 函数在 GOT 中的重定位。最后，它会将执行流程重新转移至 sum 函数内部。</li>\n</ol><p>至此，sum 函数的第一次执行便结束了。而在经过上述这一系列步骤后，sum 函数在整个进程 VAS 中的真实地址，便已经被更新到了对应的 GOT 表项中。因此，当它被再次访问时，程序仅通过以下这两个步骤便可完成调用：</p><ol>\n<li>程序通过 <code>call</code> 指令调用 sum 函数对应 PLT 表项中的第一行代码（位于 0x400560）；</li>\n<li>该行 <code>jmp</code> 指令通过 sum 函数在 GOT 对应表项中已经修正的地址，间接跳转到该函数的第一行代码。</li>\n</ol><p>以上便是 sum 函数初次进行地址延迟绑定，以及再次访问时的整体流程。到这里，我已经为你介绍了动态链接的基本实现方式，下面我们来看看基于此进行的加载时链接与运行时链接这两者的主要区别。</p><h2>加载时链接</h2><p>实际上，加载时链接作为动态链接的一种具体类型，便是基于我上面介绍的 GOT 与 PLT 两个表结构进行的。它的一个最主要特征是，<strong>动态链接器进行的符号重定位过程发生在程序代码被真正执行之前</strong>。而为了做到这一点，操作系统执行应用程序的具体步骤也发生了改变。</p><p>操作系统内核在将应用程序装载到内存后，会根据其具体 ELF 类型的不同，来选择不同的处理方式。对于采用完全静态链接的可执行文件来说，内核会将控制权直接转移给应用程序，并执行其 Text Segment 中的入口代码。而对于使用了动态链接的可执行文件来说，在执行程序代码前，内核会首先根据名为 .interp 的 Section 中的内容，将相应的动态链接器共享库（ld.so）映射至进程的 VAS 中，并同时将控制权转移给它。</p><p>动态链接器在执行过程中，会通过其自身 .dynamic 中记录的信息，来完成对自己的重定位工作。接着，通过访问应用程序的 .dynamic，动态链接器可以获得它依赖的所有外部共享库，并在此基础之上完成对整个程序的动态链接过程。</p><h2>运行时链接</h2><p>顾名思义，运行时链接即符号的重定位发生在程序的运行过程中。这种方式有时也被称为“动态载入”或“运行时加载”，它的基本原理与正常的动态链接完全一致，只是链接的发生过程被推迟到了程序运行时。通过这种方式，程序可以自由选择想要加载的共享库模块，并在不使用时及时卸载，程序的模块化组织变得更加灵活。</p><p>运行时链接主要通过由动态链接器提供的四个 API，即 dlopen、dlsym、dlerror，以及 dlclose 来实现。来看一个简单的例子：</p><pre><code class=\"language-bash\">#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;dlfcn.h&gt;\ntypedef double (*cos_t)(double);\nint main(void) {\n  cos_t cosine;\n  char *error;\n  void* handle = dlopen(\"libm.so.6\", RTLD_LAZY);\n  if (!handle) {\n    fprintf(stderr, \"%s\\n\", dlerror());\n    exit(EXIT_FAILURE);\n  }\n  dlerror();\n  cosine = (cos_t) dlsym(handle, \"cos\");\n  error = dlerror();\n  if (error != NULL) {\n    fprintf(stderr, \"%s\\n\", error);\n    exit(EXIT_FAILURE);\n  }\n  printf(\"%f\\n\", (*cosine)(2.0));\n  dlclose(handle);\n  return 0;\n}\n</code></pre><p>这段代码的逻辑十分简单。我们通过“运行时链接”的方式，在程序的运行过程中从共享库文件 libm.so.6 内部加载了函数 cos。而在程序最后，我们使用实参 2.0 调用了这个函数，并打印出了执行结果。</p><p>这里，函数 dlopen 用于打开一个指定的共享库。通过它的第二个参数，我们能够指定符号重定位的具体执行方式。这里的 RTLD_LAZY 表示延迟绑定，即动态链接器仅会在特定函数被调用时，才对其使用到的相关符号进行解析。</p><p>函数 dlsym 则用于从一个打开的共享库实例中获取某个具体符号的地址。而在此之后，我们便能够以函数指针的形式对它进行调用。最后，当共享库使用完毕，通过 dlclose 函数，我们可以减少共享库实例的被引用次数。而当该次数变为 0，且共享库对象中的符号没有被其他对象引用时，该共享库对应内存便会从当前进程的 VAS 中被卸载，卸载的具体时机则由操作系统决定。</p><p>在上述整个流程中，我们可以使用 dlerror 函数，随时获取 dlopen API 函数在执行过程中产生的错误诊断信息。</p><h2>总结</h2><p>这一讲，我主要为你介绍了动态链接的基本实现方式，和基于此进行的加载时链接与运行时链接这两者的主要区别。</p><p>动态链接利用 GOT，将需要重定位的部分，分离到所在进程的 Data Segment，进而使得共享库文件可以被加载到进程 VAS 中的任意位置。在这种情况下，多个进程便能够做到真正地共享同一段物理内存中的共享库代码。而为了降低程序初次执行时，大量符号重定位带来的性能损耗，编译器又利用名为 PLT 的表结构，实现了对函数符号的延迟绑定。</p><p>加载时链接，是指在程序被真正执行前，动态链接器会首先完成对符号的重定位过程。而运行时链接则把这个过程推迟到了程序运行过程中，它的实现基于 dlopen、dlsym、dlerror，以及 dlclose 等几个动态链接器函数。</p><h2>思考题</h2><p>尝试了解一下 Linux 共享库使用的 soname 机制，并在留言区告诉我你的理解。</p><p>今天的课程到这里就结束了，希望可以帮助到你，也希望你在下方的留言区和我一起讨论。同时，欢迎你把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"27｜编译器在链接程序时发生了什么？","id":489879},"right":{"article_title":"29｜C 程序的入口真的是 main 函数吗？","id":491189}}},{"article_id":491189,"article_title":"29｜C 程序的入口真的是 main 函数吗？","article_content":"<p>你好，我是于航。</p><p>“main 函数是所有 C 程序的起始入口”，相信对于这句话，每个同学在刚开始学习 C 语言时都很熟悉，因为这是一个被各种教材反复强调的“结论”。但事实真是如此吗？</p><p>实际上，这句话对，但也不完全对。在一段 C 代码中定义的 main 函数总是会被优先执行，这是我们在日常 C 应用开发过程中都能够轻易观察到的现象。不过，如果将目光移到那些无法直接通过 C 代码触达的地方，你会发现 C 程序的执行流程并非这样简单。</p><p>接下来，我们先通过一个简单的例子，来看看在机器指令层面，程序究竟是如何执行的。</p><h2>真正的入口函数</h2><p>这里，我们首先在 Linux 系统中使用命令 “gcc main.c -o main” ，来将如下所示的这段代码，编译成对应的 ELF 二进制可执行文件。</p><pre><code class=\"language-bash\">// main.c\nint main(void) {\n&nbsp; return 0;\n}\n</code></pre><p>在上述代码中，由于没有使用到任何由其他共享库提供的接口，因此，操作系统内核在将其对应的程序装载到内存后，会直接执行它在 ELF 头中指定的入口地址上的指令。紧接着，使用 readelf 命令，我们可以获得这个地址。然后，通过 objdump 命令，我们可以得到这个地址对应的具体机器指令。</p><p>我将这两个命令的详细输出结果放在了一起，以方便你观察，如下图所示：</p><!-- [[[read_end]]] --><p><img src=\"https://static001.geekbang.org/resource/image/35/4c/355a3e083abd79dfc5dfd0byy4d8b94c.png?wh=1920x672\" alt=\"图片\"></p><p>可以看到，程序并没有直接跳转到 main 函数中执行。相反，它首先执行了符号 _start 中的代码。那么，这个符号从何而来？它有什么作用？相信只要弄清楚这两个问题，你就能够知道 main 函数究竟是如何被调用的。下面让我们详细看看。</p><h3>_start 从何而来？</h3><p>实际上，_start 这个标记本身并没有任何特殊含义，它只是一个人们约定好的，长久以来一直被用于指代程序入口的名字。</p><p>通常来说，_start 被更多地用在类 Unix 系统中，它是链接器在生成目标可执行文件时，会默认使用的一个符号名称。链接器在链接过程中，会在全局符号表中找到该符号，并将其虚拟地址直接存放到所生成的可执行文件里。具体来说，它会将这个值拷贝至 ELF 头的 e_entry 字段中。</p><p>而这一点，也能够在各个链接器的默认配置中得到验证。比如，通过命令 “ld --verbose”，我们便能够打印出 GNU 链接器所使用的链接控制脚本的默认配置。在下面的图片中，命令语句 “ENTRY(_start)” 便用于指定<strong>其输出的可执行文件在运行后</strong><strong>，</strong><strong>第一条待执行指令的位置</strong>，这里也就是符号 _start 对应的地址。</p><p><img src=\"https://static001.geekbang.org/resource/image/8c/73/8c37ee2e91bd7587a54ca0fff43ea273.png?wh=1404x238\" alt=\"图片\"></p><p>既然链接器控制着程序执行入口的具体选择，我们便同样可以对此进行修改。比如，对于 GCC 来说，参数 “-e” 可用于为链接器指定其他符号，以作为其输出程序的执行入口。</p><p>至此，我们已经知道了 _start 这个标记的具体由来。但是在程序对应的 C 代码，以及编译命令中，我们都没有引入同名的函数实现。那么，它所对应的实际机器代码从何而来呢？</p><p>通过在编译时为编译器添加额外的 “-v” 参数，你可能会有新的发现。该参数可以让 GCC 在编译时，将更多与编译过程紧密相关的信息（如环境变量配置、执行的具体指令等）打印出来。这里，我截取了其中的关键一段，如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/16/52/16cb2d34b9cyy953e66e4990a0d40652.png?wh=1920x509\" alt=\"图片\"></p><p>实际上，GCC 在内部会使用名为 “collect2” 的工具来完成与链接相关的任务。该工具基于 ld 封装，只是它在真正调用 ld 之前，还会执行一些其他的必要步骤。可以看到，在实际生成二进制可执行文件的过程中，collect2 还会为应用程序链接多个其他的对象文件。而 _start 符号的具体定义，便来自于其中的 crt1.o 文件。</p><h3>_start 有何作用？</h3><p>crt1.o 是由 C 运行时库（C Runtime Library，CRT）提供的一个用于辅助应用程序正常运行的特殊对象文件，该文件在其内部定义了符号 _start 对应的具体实现。</p><p>接下来，我们以 GNU 的 C 运行时库 glibc 为例（版本对应于 Commit ID 581c785），来看看它是如何为 X86-64 平台实现 _start 的。在下面的代码中，我为一些关键步骤添加了对应的注释信息，你可以先快速浏览一遍，以对它的整体功能有一个简单了解。当然，你也可以点击<a href=\"https://github.com/bminor/glibc/blob/b92a49359f33a461db080a33940d73f47c756126/sysdeps/x86_64/start.S\">这个链接</a>来获取它的原始版本。</p><pre><code class=\"language-bash\">#include &lt;sysdep.h&gt;\n\nENTRY (_start)\n  cfi_undefined (rip)\n  xorl %ebp, %ebp  /* 复位 ebp */\n  mov %RDX_LP, %R9_LP\t /* 保存 FINI 函数的地址到 r9 */\n#ifdef __ILP32__\n  /* 模拟 ILP32 模型下的栈操作，将位于栈顶的 argc 放入 rsi */\n  mov (%rsp), %esi  \n  add $4, %esp  /* 同时让栈顶向高地址移动 4 字节 */\n#else\n  popq %rsi  /* 将位于栈顶的 argc 放入 rsi */\n#endif\n  mov %RSP_LP, %RDX_LP  /* 将 argv 放入 rdx */\n  and $~15, %RSP_LP  /* 对齐栈到 16 字节 */\n  pushq %rax  /* 将 rax 的值存入栈中，以用于在函数调用前保持对齐状态 */\n  pushq %rsp  /* 将当前栈顶地址存入栈中 */\n\n  xorl %r8d, %r8d  /* 复位 r8 */\n  xorl %ecx, %ecx  /* 复位 ecx */\n#ifdef PIC\n  /* 将 GOT 表项中的 main 函数地址存放到 rdi */\n  mov main@GOTPCREL(%rip), %RDI_LP  \n#else\n  mov $main, %RDI_LP  /* 将 main 函数的绝对地址存放到 rdi */\n#endif\n  /* 调用 __libc_start_main 函数 */\n  call *__libc_start_main@GOTPCREL(%rip)\n  hlt\t\nEND (_start)\n  .data\n  .globl __data_start\n__data_start:\n  .long 0\n  .weak data_start\n  data_start = __data_start\n</code></pre><p>总的来看，这部分汇编代码主要完成了相应的参数准备工作，以及对函数 __libc_start_main 的调用过程。这个函数的原型如下所示：</p><pre><code class=\"language-bash\">int __libc_start_main(int (*main) (int, char**, char**), \n                      int argc, \n                      char **argv, \n                      void (*init) (void), \n                      void (*fini) (void), \n                      void (*rtld_fini) (void), \n                      void *stack_end);\n</code></pre><p>该函数一共接收 7 个参数。接下来，让我们分别看看其中每个参数的具体准备过程。</p><ul>\n<li>第一个参数为用户代码中定义的 main 函数的地址。在汇编代码的第 21~26 行，根据宏 PIC 是否定义，程序将选择性地使用 GOT 表项中存放的 main 函数地址，或是 main 符号的绝对地址，并将它放入寄存器 rdi。</li>\n<li>第二个参数为 argc。在汇编代码的第 7~13 行，根据宏 <strong>ILP32</strong> 是否定义，程序将选择性地按照不同的数据模型方式，操纵位于栈顶的 argc 参数的值。</li>\n<li>第三个参数为 argv。在汇编代码的第 14 行，程序直接通过 <code>mov</code> 指令，将它的值（即此刻栈顶地址）放入了寄存器 rdx。</li>\n<li>第四、五个参数为当前程序的“构造函数”与“析构函数”。从 ELF 标准中可以得知，在动态链接器处理完符号重定位后，每一个程序都有机会在 main 函数被调用前，去执行一些必要的初始化代码。类似地，它们也可以在 main 函数返回后，进程完全结束之前，执行相应的终止代码。而新版本的 glibc 为了修复 “ROP 攻击” 漏洞，优化了这部分实现。因此，这里对应的两个参数只需传递 0 即可。更多信息你可以参考<a href=\"https://sourceware.org/bugzilla/show_bug.cgi?id=23323#c7\">这个链接</a>。</li>\n<li>第六个参数为用于共享库的终止函数的地址，该地址会在 _start 的代码执行前，被默认存放在 rdx 寄存器中。因此，这里在汇编代码的第 6 行，rdx 寄存器的值被直接拷贝到了 r9 中。</li>\n<li>第七个参数为当前栈顶的指针，即 rsp 的值。这里在汇编代码的第 17 行，程序将这个值通过栈进行了传递。</li>\n</ul><p>这样，__libc_start_main 的调用参数便准备完毕了。在汇编代码的 28 行，我们对它进行了调用。</p><p>__libc_start_main 在其内部，会为用户代码的执行，进行一系列前期准备工作，其中包括但不限于以下这些内容：</p><ul>\n<li>执行针对用户 ID 的必要安全性检查；</li>\n<li>初始化线程子系统；</li>\n<li>注册 rtld_fini 函数，以便在动态共享对象退出（或卸载）时释放资源；</li>\n<li>注册 fini 处理程序，以便在程序退出时执行；</li>\n<li>调用初始化函数 init；</li>\n<li>使用适当参数调用 main 函数；</li>\n<li>使用 main 函数的返回值调用 exit 函数。</li>\n</ul><p>可以看到，一个二进制可执行文件的实际运行过程十分复杂，应用程序代码在被执行前，操作系统需要为其准备 main 函数调用依赖的相关参数，并同时完成全局资源的初始化工作。而在程序退出前，这些全局资源也需要被正确清理。</p><h2>什么是 CRT？</h2><p>到这里，我们已经把 _start 的由来和作用这两个关键问题弄清楚了，我想你已经知道了 main 函数究竟是如何被调用的。最后我们再来看一个问题：在上面我提到了 C 运行时库，即 CRT，那么它究竟是什么呢？</p><p>实际上，CRT 为应用程序提供了对启动与退出、C 标准库函数、IO、堆、C 语言特殊实现、调试等多方面功能的实现和支持。CRT 的实现是平台相关的，它与具体操作系统结合得非常紧密。</p><p>当然，真正参与到 CRT 功能实现的并不只有 crt1.o 这一个对象文件。通过观察我之前介绍 collect2 程序调用时给出的参数截图，你会发现与程序代码一同编译的还有其他几个对象文件。这里我将它们的名称与主要作用整理如下：</p><ul>\n<li>crt1.o，提供了 _start 符号的具体实现，它仅参与可执行文件的编译过程；</li>\n<li>crti.o 和 crtn.o，两者通过共同协作，为共享对象提供了可以使用“构造函数”与“析构函数”的能力；</li>\n<li>crtbegin.o 和 crtend.o，分别提供了上述“构造函数”与“析构函数”中的具体代码实现。</li>\n</ul><p>到这里，对于“C 程序的入口真的是 main 函数吗”这个问题，相信你已经有了答案。虽然在这一讲中，我主要以 Linux 下的程序执行过程为例进行了简单介绍，但我想让你了解的并不是这其中的许多技术细节，而是“操作系统在真正执行 main 函数前，实际上会帮助我们提前进行很多准备工作”这个事实。这些工作都为应用程序的正常运行提供了保障。</p><h2>总结</h2><p>这一讲，我从“C 程序的入口真的是 main 函数吗”这个问题入手，围绕它带你进行了一系列的实践与研究。</p><p>通过观察 Linux 系统下程序的运行步骤，我们可以发现，程序在执行时的第一行指令并非位于 main 函数中。相对地，通过首先执行 _start 符号下的代码，操作系统可以完成执行应用程序代码前的准备工作，这些工作包括堆的初始化、全局变量的构造、IO 初始化等一系列重要步骤。随着这些重要工作的推进，用户定义的 main 函数将会在 __libc_start_main 函数的内部被实际调用。</p><p>而上述提到的所有这些重要工作，都是由名为 CRT 的系统环境为我们完成的。它在支持应用程序正常运行的过程中，扮演着不可或缺的角色。</p><h2>思考题</h2><p>你知道当我们在 Linux 的 Shell 中运行程序时，操作系统是怎样对程序进行处理的吗？请试着查阅资料，并在评论区告诉我你的理解。</p><p>今天的课程到这里就结束了，希望可以帮助到你，也希望你在下方的留言区和我一起讨论。同时，欢迎你把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"28｜程序可以在运行时进行链接吗？","id":490462},"right":{"article_title":"30｜ABI 与 API 究竟有什么区别？","id":492443}}},{"article_id":492443,"article_title":"30｜ABI 与 API 究竟有什么区别？","article_content":"<p>你好，我是于航。</p><p>今天我们来聊另外一个老生常谈的话题：“ ABI 与 API 这两个概念究竟有什么区别？”</p><p>也许你之前也思考过这个问题。ABI 与 API 这两个英文缩写只差一个字符，因此它们对应的概念在很多线下讨论和博客文章中会被经常混用，甚至是乱用。当然，时不时地，这个问题也会成为人们在技术社交圈内的丰富谈资。这一讲，就以你熟悉的 C 语言体系为例，我们来一起看看 ABI 与 API 二者分别指代什么内容，有什么区别。</p><h2><strong>API</strong></h2><p>API 的全称为“应用程序编程接口（Application Programming Interface）”。从它的名字我们就能看出来，这一类接口的侧重点在于“编程”。因此，通过遵循 API 规范，我们可以在相应的编程语言代码中使用这些接口，以操作计算机系统来完成某项特定任务。而对 C 语言来说，那些由 C 标准库提供的，被定义在不同头文件中的函数原型，便是一种 API 的具体表现形式。</p><h3>重要特征</h3><p><strong>API 具有的一个最重要特征，便是隐藏了其背后具体功能的内部实现细节，<strong><strong>只</strong></strong>公开对编码有意义的部分</strong>（如接口名称、可接收参数的个数与类型等）。通过保持这部分特征的一致性，API 提供者与调用者便可在相对隔离的环境下被独立维护。在这种情况下，这部分相对统一和稳定的特征也可被单独抽离出来，成为相应的 API 规范。</p><!-- [[[read_end]]] --><p>如下面的代码所示，C 标准库函数 fopen 在 API 层面有着稳定的特征，但实际上，使用这些 API 构建的应用程序却可以在不修改代码的情况下，灵活选用不同的接口实现方案（如 musl 和 glibc）。这其中的一个重要原因，便是<strong>C 标准库的 API 规范是独立于具体实现的</strong>。</p><pre><code class=\"language-bash\">FILE *fopen(const char* filename, const char* mode)\n</code></pre><h3>发展简史</h3><p>API 对应的概念最早出现于上世纪 40 年代，而直到 1968 年，API 这个术语才在发表于 AFIPS（American Federation of Information Processing Societies）会议的一篇论文中首次出现，随后逐渐被业界广泛采用。而随着计算机互联网的普及，API 一词开始被更多地用于表示与 Web 领域相关的标准接口。其中，使用最为广泛的当属那些基于 REST、SOAP 等风格构架的 Web API。下面是一个简单的例子：</p><pre><code class=\"language-bash\">POST https://docs.googleapis.com/v1/documents/{documentId}:batchUpdate\n</code></pre><p>截至目前，在没有具体上下文的情况下，我们通常默认用 API 一词来表示那些与 Web 领域相关的标准接口。</p><p>总的来看，API 的最重要特征在于<strong>提供相应功能的同时隐藏实现细节，让其使用者可以按照较为统一和稳定的方式来使用系统能力</strong>。按照这个结论，API 的概念可以被应用在更加广泛的领域中。比如，对于操作系统调用来说，我们也可以称其为由操作系统内核提供的一种 API。通过这些 API，系统库乃至上层应用都可以使用内核的能力，但使用者又无需了解它的内部具体实现细节。</p><p>可以看到，API 的概念还是十分简单和清晰的。接下来我们看看与它仅有一字之差的 ABI，到这里，事情变得复杂了起来。</p><h2><strong>ABI</strong></h2><p>ABI 的全称为“应用程序二进制接口（Application Binary Interface）”。与 API 不同的是，ABI 的侧重点并不在于 “Programming”，而在于 “Binary”，即机器指令层面的具体格式。因此，与 API 相反，<strong>ABI 将程序与操作系统</strong><strong>、</strong><strong>硬件平台之间紧密协作需要遵守的特定规则暴露了出来</strong>。这些规则指定了基于这个体系运行的二进制应用程序，应该如何在机器代码层面进行数据访问或函数调用等一系列操作。</p><p>规则的重要性不言而喻。我曾在<a href=\"https://time.geekbang.org/column/article/468171\"> 05讲 </a>中介绍过，运行在 x86-64 平台上的类 Unix 系统会遵循名为 “System V AMD64 ABI” 的调用约定，来进行函数的实际调用过程。而在这个约定中，函数调用需要使用固定的寄存器传递参数，并按照一定顺序，在满足栈对齐等一系列要求的情况下进行。当然，你可能会问：如果不满足这些要求，程序就无法正常运行吗？下面，让我们来做一个简单的实验。</p><h3>不遵循 ABI 的程序能否运行？</h3><p>这里，为了验证不满足 ABI 要求的程序能否正常运行，我们将直接使用 Intel 格式的汇编代码来编写程序入口函数 _start 的具体实现。在该函数内部，我们会按照违背 SysV 调用约定的方式，调用直接由 C 代码编译而来的函数 sub，并将所得计算结果作为程序的最终返回值。</p><p>首先，我们来看 sub 函数的实现代码：</p><pre><code class=\"language-c++\">// sub.c\nint sub(int x, int y) {\n&nbsp; return x - y;\n}\n</code></pre><p>该函数的逻辑十分简单：它接收两个整型参数 x 与 y，并返回表达式 <code>x - y</code> 的值。紧接着，我们来编写 _start 部分的逻辑，代码如下所示：</p><pre><code class=\"language-c++\"># main.asm\nextern sub\nglobal _start\nsection .text\n_start:\n&nbsp; and&nbsp; &nbsp;rsp, 0xfffffffffffffff0\n&nbsp; sub&nbsp; &nbsp;rsp, 1\n&nbsp; mov&nbsp; &nbsp;esi, 2  # the 1st param.\n&nbsp; mov&nbsp; &nbsp;edi, 1  # the 2nd param.\n&nbsp; call&nbsp; sub\n&nbsp; mov&nbsp; &nbsp;edi, eax\n&nbsp; mov&nbsp; &nbsp;eax, 60\n&nbsp; syscall\n</code></pre><p>这部分逻辑的实现过程主要分为下面几个步骤：</p><ol>\n<li>代码第 6 行，通过 <code>and</code> 指令，栈顶首先被对齐到 ABI 要求的 16 字节，接着通过下一行的 <code>sub</code> 指令，我们让栈失去“对齐”这一特性；</li>\n<li>代码第 8~9 行，我们使用寄存器 esi 存放传入 sub 函数的第一个参数，使用 edi 存放其第二个参数（与 SysV 中的规定相反）；</li>\n<li>代码第 10 行，调用 sub 函数；</li>\n<li>代码第 11~13 行，调用 exit 系统调用，并将存放在寄存器 eax 中的计算结果作为程序结束的返回值。</li>\n</ol><p>紧接着，分别执行下面这几行命令，以完成上述代码的编译过程（注：这里我们使用的 nasm 是一个 x86 汇编器，详情可以参考<a href=\"https://www.nasm.us\">这个链接</a>）：</p><pre><code class=\"language-c++\">gcc -c sub.c -o sub.o\nnasm -f elf64 ./main.asm -o ./main.o\nld ./main.o ./sub.o -o ./main\n</code></pre><p>最后，运行程序，通过命令 <code>echo $?</code> ，我们可以查看到程序退出时的实际返回值。</p><p>在这一系列操作后，你会发现程序可以被正常编译和执行，只是得到的返回结果并不符合我们的预期。实际上，出现这个问题的原因正是由于我们编写的 _start 入口代码没有遵循统一的 SysV 调用规范。</p><p>在代码的第 8~9 行，我们以相反的顺序（即先 esi 后 edi）传入了 sub 函数需要的两个实参。而在 sub 函数对应的机器代码实现中，GCC 会按照 SysV 规范来分配该函数需要使用的各个参数。因此，实际上由 esi 传入的第一个参数，便会被 sub 函数当作第二个参数。同样地，由 edi 传入的第二个参数则会被当作第一个参数。</p><p>除此之外，虽然未对齐的栈顶并未导致 sub 函数的调用失败，但这只是由于我们的实验用例比较幸运。在真实的 x86-64 体系中，有很多指令（如 <code>movapd</code> 、<code>movaps</code>）在被实际调用前，都是需要栈顶位于特定边界（如 16、32、64 字节）对齐的，否则会抛出相应异常（如 #GP）。这些指令可能被广泛地使用在各类标准库实现中，因此，<strong>为了能够正确使用这些函数，满足栈对齐这一要求也是不可或缺的</strong>。</p><h3>ABI 的主要内容</h3><p>总的来看，ABI 规范通常会涵盖以下这些内容：</p><ul>\n<li>函数调用规范；</li>\n<li>处理器可以访问的数据类型其大小与对齐方式；</li>\n<li>进程初始化细节（如栈和寄存器的状态变化）；</li>\n<li>对象文件（如 .o）的基本结构；</li>\n<li>程序载入和动态链接的细节；</li>\n<li>……</li>\n</ul><p>对于 C 程序来说，稳定的 ABI 对<strong>保障同一个程序<strong><strong>在</strong></strong>多个不同平台（如不同的类 Unix 系统）上的兼容性</strong>有着重要作用。C 标准中并未规定 C 代码应该按照怎样的方式执行，内存应该如何布局和分配。而与 C 程序运行时相关的一切细节，实际上都是由相应平台的 ABI 来决定的。比如，在 SysV ABI 规范手册的第一章内容中，我们可以看到下面这句话：</p><blockquote>\n<p>No attempt has been made to specify an ABI for languages other than C. However, it is assumed that many programming languages will wish to link with code written in C, so that the ABI specifications documented here apply there too.</p>\n</blockquote><p>翻译过来就是：“我们没有尝试为 C 以外的语言指定 ABI。然而，假定许多其他编程语言都希望与使用 C 语言编写的代码进行链接，那么这里记录的 ABI 规范也同样适用于那些情况。”可以看到，C 语言的特殊地位使得操作系统厂商会选择使用它来作为编写相应 ABI 规范的“基准语言”。</p><p>比如在 SysV 中，规范将 C 语言里的各种基本类型与处理器类型进行了一一映射，对结构和联合的对齐要求进行了说明，对可变参数列表的具体实现方式进行了说明，等等。所有这些细则都将共同约束编译器，使其按照某一特定方式编译和构建 C 程序。</p><h2>总结</h2><p>今天，我主要为你讲解了 API 与 ABI 这两个概念之间的区别。</p><p>API 的全称为“应用程序编程接口”，它是程序员可以通过编程语言调用的一种特殊资源。API 通过隐藏功能的内部实现细节隔离了其使用方与提供方，使得 API 实现与应用程序实现可以通过遵循统一、稳定的 API 规范，来达到各自独立维护的目的。API 有着多种具体表现形式，比如源代码形式的函数，或是基于互联网的 Web 接口。</p><p>ABI 的全称为“应用程序二进制接口”，它是一套描述了应用程序应该如何在机器指令层面与特定操作系统和硬件平台正常协作的一系列规范。这些规范决定了应用程序应该如何进行数据访问、函数调用，乃至使用操作系统的能力。不遵循 ABI 规范的应用程序也许可以运行，但它却可能会失去在同一个体系下的兼容性以及运行正确性。</p><h2>思考题</h2><p>尝试使用 x86-64 汇编语言编写一个程序，使它能够产生由于栈未对齐而导致的异常。希望你可以动手实践下，然后在评论区分享你的经验，或者提出你遇到的问题。</p><p>今天的课程到这里就结束了，希望可以帮助到你，也希望你在下方的留言区和我一起讨论。同时，欢迎你把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"29｜C 程序的入口真的是 main 函数吗？","id":491189},"right":{"article_title":"31｜程序如何与操作系统交互？","id":493092}}},{"article_id":493092,"article_title":"31｜程序如何与操作系统交互？","article_content":"<p>你好，我是于航。</p><p>在上一讲中我曾提到，你可以将操作系统内核暴露的“系统调用”也作为 API 的一种具体表现形式，因为调用者可以通过这些接口来使用内核提供的某种能力，但是却无需了解它们的内部实现细节。在之前的课程中，我也多次提到过有关系统调用的内容。那么，系统调用究竟是什么？它与我们编写的应用程序函数有何不同？通常情况下它又是怎样实现的呢？这一讲，我们就来看看这些问题的答案。</p><h2>什么是系统调用？</h2><p>不知道你还记不记得我在<a href=\"https://time.geekbang.org/column/article/475253\"> 11 讲</a> “用于低级 IO 接口的操作系统调用”小节中给出的例子，通过这个例子我们能够发现，操作系统调用实际上是由操作系统内核封装好的一些可供上层应用程序使用的接口。这些接口为应用提供了可以按照一定规则访问计算机底层软件与硬件相关服务（如 IO、进程、摄像头等）的能力。其中，内核作为中间层，隔离了用户代码与硬件体系。</p><p>接下来，我们再通过一个简单的例子，来快速回顾下如何在 x86-64 平台上使用系统调用。在大多数情况下，位于内核之上的各类系统库（如 glibc、musl）会将这些系统调用按照不同类别进行封装，并提供可以直接在 C 代码中使用的函数接口。通过这种方式，我们就可以间接地使用系统调用。当然，在这些函数内部，系统调用的具体执行通常是由汇编指令 <code>syscall</code> 完成的。</p><!-- [[[read_end]]] --><p>比如，POSIX 标准中有一个名为 getpid 的函数，该函数用于获取当前进程的唯一标识符（ID）。如果查看 musl 中该函数针对 x86-64 平台的具体实现，你会发现这样一段代码：</p><pre><code class=\"language-c++\">#include &lt;unistd.h&gt;\n#include \"syscall.h\"\npid_t getpid(void) {\n  return __syscall(SYS_getpid);\n}\n</code></pre><p>这段 C 代码作为“封装层（Wrapper）”，向上屏蔽了内部的 sys_getpid 系统调用。函数实现中传入的 SYS_getpid 是一个值为 39 的宏常量，这个值便为 sys_getpid 系统调用对应的唯一 ID。紧接着，通过名为 __syscall 的另一个函数，程序可以执行系统调用，并获取由内核返回的相关数据。这里，该函数直接由汇编代码定义，内容如下所示：</p><pre><code class=\"language-c++\">.global __syscall\n.type __syscall,@function\n__syscall:\n  movq %rdi, %rax\n  movq %rsi, %rdi\n  movq %rdx, %rsi\n  movq %rcx, %rdx\n  movq %r8, %r10\n  movq %r9, %r8\n  movq 8(%rsp), %r9\n  syscall\n  ret\n</code></pre><p>在这段 AT&amp;T 格式的汇编代码中，第 4 行的 <code>movq</code> 指令将传入该函数的系统调用 ID 存放到了 rax 寄存器中；接下来的第 5~10 行，代码将系统调用需要使用的参数也放到了相应寄存器中（这里，你可以看到 SysV 规范中对于普通函数和系统调用参数的不同处理方式）；最后，代码的第 11 行，通过 <code>syscall</code> 指令，系统调用得以被正确执行。</p><p>可以看到，系统调用的使用十分简单。那么，你有没有思考过这个问题：为什么系统调用需要使用特殊的 <code>syscall</code> 指令，而非“普通”的 <code>call</code> 指令进行调用呢？想要知道答案，那就要先从二者之间不同的代码执行环境开始说起了。</p><h2>系统调用 vs 用户函数</h2><p>系统调用与一般函数（或者说“用户函数”）的最大区别在于，<strong>系统调用执行的代码位于操作系统底层的内核环境中，而用户函数代码则位于内核之上的应用环境中</strong>。这两种环境有时也被称为内核态与用户态。</p><p>现代计算机通常采用名为“保护环（Protection Rings）”的机制来保护整个系统的数据和功能，使其免受故障和外部恶意行为的伤害。这种方式通过提供多种不同层次的资源访问级别，即“特权级别”，来限制不同代码的执行能力。</p><p>比如，在 Intel x86 架构中，特权级别被分为 4 个层次，即 Ring0~Ring3。其中，Ring0 层拥有最高特权，它具有对整个系统的最大控制能力，内核代码通常运行于此。相对地，Ring3 层只有最低特权，这里是应用程序代码所处的位置。而位于两者之间的 Ring1 和 Ring2 层，则通常被操作系统选择性地作为设备驱动程序的“运行等级”。你可以通过下面这张图（图片来自 <a href=\"https://en.wikipedia.org/wiki/Protection_ring\">Wikipedia</a>）来直观地理解特权级别的概念。</p><p><img src=\"https://static001.geekbang.org/resource/image/a0/71/a046a1c0f7fbea2cdbcc1536fd950071.png?wh=1920x1385\" alt=\"图片\"></p><p>根据特权级别的不同，CPU 能够被允许执行的机器指令以及可使用的寄存器也有所不同。比如位于 Ring3 层的应用程序，可以使用最常见的通用目的寄存器，并通过 <code>mov</code> 指令操作其中存放的数据。而位于 Ring0 层的内核代码则可以使用除此之外的 cr0、cr1 等控制寄存器，甚至通过 <code>in</code> 与 <code>out</code> 等机器指令，直接与特定端口进行 IO 操作。但如果应用程序尝试跨级别非法访问这些被限制的资源，CPU 将抛出相应异常，阻止相关代码的执行。</p><p>到这里，对于“为什么系统调用需要通过特殊的机器指令来使用”这个问题，你应该已经有了答案。系统调用是由内核提供的重要能力，而这些能力的具体实现代码属于内核代码的一部分。因此，为了执行这些代码，我们便需要一种能够在 Ring0 层将它们触发的方法，而 <code>syscall</code> 指令便能够做到这一点。</p><p>最后，再让我们来进一步看看系统调用通常是如何实现的。</p><h2>系统调用的基本实现</h2><p>事实上，在 x86-64 体系中，我们可以采用多种方式来执行一个系统调用。以 <a href=\"https://time.geekbang.org/column/article/492443\">30讲</a> 中“不遵循 ABI 的程序能否运行？”这一小节里的汇编代码为例，在不对编译命令做任何修改的情况下，你也可以使用下面这段代码来完成同样的工作。</p><pre><code class=\"language-c++\">extern sub\nglobal _start\nsection .text\n_start:\n&nbsp; and&nbsp; &nbsp;rsp,0xfffffffffffffff0\n&nbsp; sub&nbsp; &nbsp;rsp, 3\n&nbsp; mov&nbsp; &nbsp;esi, 2\n&nbsp; mov&nbsp; &nbsp;edi, 1\n&nbsp; call&nbsp; sub\n  # use \"int\" to invoke a system call.\n&nbsp; mov&nbsp; &nbsp;ebx, eax  \n&nbsp; mov&nbsp; &nbsp;eax, 1\n&nbsp; int   0x80\n</code></pre><p>观察上述代码的最后三行，你会发现我们触发 exit 系统调用的方式发生了变化。<code>int</code> 指令是一个用于产生软中断的汇编指令，它在调用时会接收一个中断号作为参数。</p><p>当中断发生时，执行环境会从 Ring3 切换至 Ring0，以准备执行内核代码。在这里，CPU 会首先根据 <code>int</code> 指令的参数，来从名为“中断向量表”的结构中查找下一步需要执行的中断处理程序。这里对于中断号 0x80 来说，其对应的中断处理程序便专门用于处理，由用户程序发起的系统调用请求。紧接着，这个处理程序会根据<strong>程序通过寄存器 eax 传入的系统调用号</strong>，来再次查找待执行的系统调用函数。最后，通过 ebx 等寄存器，系统调用函数可以获得所需参数，并完成内核某段具体代码的执行过程。</p><p>在这个过程中发生了特权级别的转换，因此，为了通过隔离执行环境来保证内核安全，CPU 在进入内核态前，通常还会进行栈的切换。比如在 Linux 中，CPU 在用户态与内核态会使用不同的栈，来分别处理发生在不同特权级别下的函数调用等过程。每一个进程都对应于独立的内核栈，这个栈中会首先存放与用户态代码执行环境相关的一系列寄存器（如 esp、eip 等）的值。而当发生在内核态的相关过程（如系统调用）结束后，进程使用的栈还需要从内核栈被再次切换回用户栈，并同时恢复保存的寄存器值。</p><p>你可以通过下图来观察上述系统调用的整个执行过程：</p><p><img src=\"https://static001.geekbang.org/resource/image/f6/90/f609a18f22ef044e4e8fcd2722011390.jpg?wh=2284x882\" alt=\"\"></p><p>以上便是通过 <code>int</code> 指令来进行系统调用的大致过程。需要注意的是，虽然我们可以在 x86-64 体系上使用这种方式，但它实际仅适用于 i386 体系。在这里，我只是以这种最经典的使用方式为例，来向你展现系统调用的一种基本实现原理。</p><p>而在目前被广泛使用的 x86-64 体系中，通过 <code>syscall</code> 指令进行系统调用仍然是最高效，也最具兼容性的一种方式。<code>syscall</code> 指令的全称为“快速系统调用（Fast System Call）”，CPU 在执行该指令时不会产生软中断，因此也无需经历栈切换和查找中断向量表等过程，执行效率会有明显的提升。</p><h2>总结</h2><p>这一讲，我主要带你看了三个问题，分别是什么是系统调用，系统调用与用户函数的区别，以及系统调用通常是如何实现的。</p><p>系统调用是由操作系统内核封装好的，一些可供上层应用程序使用的接口，这些接口可以让程序方便、安全地通过使用内核的能力，来间接地与底层软件和硬件进行交互。</p><p>与用户函数不同的是，系统调用需要 CPU 执行位于内核中的代码，而现代计算机采用的“保护环”机制则将整个系统的资源访问能力划分为了多个不同的特权级别。其中，Ring0 层拥有最大执行权限，它也是内核代码的运行所在。而 Ring3 层则仅有最小权限，它是上层应用程序的默认运行层级。</p><p>系统调用的经典实现方式是通过基于 <code>int</code> 指令的软中断进行的。借助软中断，CPU 可以从中断向量表中找到专门用于处理系统调用的中断处理程序，而该程序再通过由特定寄存器传入的系统调用号，来执行相应的系统调用函数。在这个过程中，操作系统通常会进行由用户栈到内核栈的转换，以及相关寄存器的存储过程。</p><p>而在 x86-64 体系中，通过 <code>syscall</code> 指令进行的系统调用，由于不需要进行软中断和表查询，通常会有着更高的执行效率。</p><h2>思考题</h2><p>请查阅相关资料，了解 Linux 下的 vDSO 机制是如何参与“虚拟系统调用”的执行过程的，并在评论区说说你的理解。</p><p>今天的课程到这里就结束了，希望可以帮助到你，也希望你在下方的留言区和我一起讨论。同时，欢迎你把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"30｜ABI 与 API 究竟有什么区别？","id":492443},"right":{"article_title":"春节策划一 | 构建自己的知识体系，让学习的“飞轮”持续转动","id":484220}}},{"article_id":484220,"article_title":"春节策划一 | 构建自己的知识体系，让学习的“飞轮”持续转动","article_content":"<p>你好，我是于航。时间过得很快，一转眼我们来到了壬寅之年。这篇加餐发布时，恰逢除夕，在这里首先祝你新年快乐，希望你在新的一年，学业进步，工作顺利！</p><p>趁着节日的氛围，今天我想和你聊点轻松的内容，来分享下我对“学习”的一些认知。</p><h2>学习的两个基本原则</h2><p>事实上，在职业发展的这些年，我一直遵循着学习的两个基本原则：</p><ul>\n<li>自己的知识体系，需要由点成线，再成网（也可以叫“面”，但“网”更形象一些）地进行构建；</li>\n<li>需要不断地重复获取和咀嚼知识。这样在“飞轮效应”下，学习效率和理解深度才会进一步提升。</li>\n</ul><p><strong>其中，第一个原则可以帮我们构建更紧密的知识体系，把很多容易被遗忘的，或者你理解得并不深刻的“单点知识”联系在一起，并从表象打通到原理，建立一个完整的知识网络。</strong></p><p>以学习 C 语言为例，“在 C 语言中，关键字 <code>int</code> 被用来定义整型变量”，这就是针对 C 语法的一个单点知识。而下面这些问题的答案，都是由这个单点知识衍生出来的，包含了来自不同视角的另一些相关知识点：</p><ul>\n<li>整型变量在汇编（机器）代码层面如何体现？</li>\n<li>在程序运行时，变量的数据会被存放在内存中的什么位置？</li>\n<li>在内存中，整型变量数据会被如何编码？</li>\n<li>……</li>\n</ul><p>当我们将知识由点到线，再到网地进行构建后，在这个归类和整理的过程中，由于我们对知识进行了“主动加工”，因此对它们的理解和记忆也会变得更加深刻。</p><!-- [[[read_end]]] --><p>至于第二个原则，也很好理解，“读书百遍，其义自见”说的就是这个道理。我们常说，学习一项新技术，只有在理解原理的同时再配合大量的实践，才能够快速掌握，并且对原理有着更深的理解。<strong>而实践，便是对知识进行重复“咀嚼”的过程</strong>。</p><p>学习技术是这样，通过读书来学习某个领域的知识也是如此。在信息获取如此便利的今天，讨论同一个话题的书籍有很多，它们的质量和内容可以说是千差万别。因此，如何高效地利用时间，并在众多资源中“去伪存真”，快速学习到自己还未掌握的知识，便显得尤为重要。</p><h2>利用“飞轮”学习法，加速构建知识网络</h2><p>接下来，我想为你介绍我经常使用的方法。总的来说，这个方法可以概括为两个步骤：</p><ol>\n<li>熟读经典，来完成你对某个领域知识的“原始资本积累”；</li>\n<li>在第一步的基础之上，再去广泛涉猎更多相关书籍，并进一步查缺补漏，加深理解。</li>\n</ol><p>对于某一个特定的知识领域，当你阅读的相关书籍越来越多时，你能从每一本书中获得的新知识可能会越来越少，因此，你阅读整本书所花费的时间也会越来越短。而在阅读“新书”的过程中，里面涉及到的“旧知识”又会刺激你大脑中先前已经构建好的，与这块知识相关的神经元，从而让你对这部分知识的记忆变得更加牢固。随着你掌握的知识越来越多，新知识逐渐变为旧知识，而旧知识又不断变得更加深刻，你对新书的“消化”速度也会越来越快。长此以往，便会形成我们常说的“飞轮效应”。</p><p><img src=\"https://static001.geekbang.org/resource/image/cb/83/cb6277a6a5c3e6b95a047ef03663d983.jpg?wh=2284x1836\" alt=\"\"></p><p>书籍作为某个特定领域知识内容的集合，提供了网络碎片化知识通常无法提供的知识“网”。而如果我们想对网中的某个知识点再进行更加深入的了解，仍需要借助互联网的帮助，从博客、论文等相对碎片化的载体中汲取知识。<strong>总之，要在已构建的“面”的基础上加深“点”，让知识网中的各个点互通有无。</strong></p><p><img src=\"https://static001.geekbang.org/resource/image/87/93/871713a1674340001928058d7e2f9693.jpg?wh=2284x1022\" alt=\"\" title=\"增强单点知识间的相关性，对整个知识体系的理解会更深刻\"></p><p>对大部分人来说，实行这个方法时最困难也最关键的，便是完成原始知识积累的过程。因此，抛开方法本身，我们首先要做到的是坚持不懈地认真看完一本书，这才是你决胜的关键点。下一次的春节加餐中，我会向你推荐一些经典的 C 语言学习书籍，希望你能够利用好这个春节假期，让学习的“飞轮”持续转动起来。</p><p>今天分享的都是我自己对学习方法的认知，希望能给你带来一些启发和帮助。如果你还有其他想要分享的学习技巧，欢迎在评论区交流讨论。</p>","neighbors":{"left":{"article_title":"31｜程序如何与操作系统交互？","id":493092},"right":{"article_title":"春节策划二 | 关于 C 语言，我有这些书籍想推荐给你","id":484383}}},{"article_id":484383,"article_title":"春节策划二 | 关于 C 语言，我有这些书籍想推荐给你","article_content":"<p>你好，我是于航。在上一篇加餐里我提到，为了产生学习的“飞轮效应”，我们可以先熟读经典书籍，来完成对某个领域知识的“原始资本积累”。那么，对于 C 语言学习来说，从基础到进阶，都有哪些经典书籍可以参考呢？</p><p>今天，我就向你介绍几本值得作为首批阅读材料的 C 语言书籍。这些书里的大部分我都读过不止一遍，希望它们也能对你有所帮助。</p><p><strong>第一本书是 Stephen Prata 的经典著作《C Primer Plus》。</strong></p><p><img src=\"https://static001.geekbang.org/resource/image/c1/b1/c12f950eee0c89667625927d76dde1b1.jpeg?wh=650x836\" alt=\"图片\"></p><p>你可能也对它很熟悉。这本书非常适合没有任何编程语言基础的同学，来作为初次学习 C 语言时的参考书籍。当然，如果你已经具备了一定的 C 语言基础和项目经验，也可以阅读本书来进行适当的查缺补漏。</p><p><strong>这本书详细地介绍了 C 基本语法（最新版，基于 C11 标准）的各类细节</strong>，并通过大量实例，展示了这些语法在实际项目中的使用方式。但稍显遗憾的是，本书对 C 标准库的相关内容仅在附录中做了简短介绍，如果你想了解如何正确使用标准库的相关接口，那它的参考价值就比较有限了。</p><p><strong>第二本书是 Jens Gustedt 的《Modern C》</strong>。</p><p><img src=\"https://static001.geekbang.org/resource/image/97/23/973112a60793040a75a69ed4a9587e23.png?wh=1920x2408\" alt=\"图片\"></p><p>这本书虽然没有上一本经典，但它是为数不多的以 C17 标准为主的 C 语言书籍。这本书采用了不同的角度将相关内容进行了分类，并且还讲解了代码风格、C 内存模型、多线程，以及原子操作等内容，这些都是《C Primer Plus》中没有涉及到的。</p><!-- [[[read_end]]] --><p>唯一美中不足的是，书中的用例相对来说较为复杂，理解成本比较高。但还是推荐你完整阅读一遍，相信读完后你会有不少收获。</p><p><strong>第三本书是 Randal E.Bryant 等人编写的《Computer Systems: A Programmer’s Perspective》，它的中文版书名为《深入理解计算机系统》</strong>。</p><p><img src=\"https://static001.geekbang.org/resource/image/2e/5a/2ec793fb536520997c94328955d0e95a.jpeg?wh=800x800\" alt=\"图片\"></p><p>同样地，这也是一本经典书籍，通常被简称为 “CSAPP”。我认为，这本书是每一个专业的程序员都应该反复阅读，甚至去动手实践的一本书。通过它，<strong>我们能够对计算机系统的内部运作机制有一个基本且全面的认识</strong>。</p><p>对于 C 语言开发者来说，掌握基本的语法只是职业生涯中的第一步。如果想触及与 C 语言密切相关的操作系统、编译器、虚拟机、系统编程等众多底层领域，就离不开与计算机系统打交道。因此，这本书可以说是 C 开发者的必读书之一。</p><p><strong>第四本书是 Igor Zhirkov 的《Low-Level Programming》</strong>。</p><p><img src=\"https://static001.geekbang.org/resource/image/18/70/18f0c41dyyd53f9d76b4c62843c7b770.jpeg?wh=1000x1429\" alt=\"图片\"></p><p>这本书可以作为学习 NASM 和 x86-64 的入门教材。NASM 是一个针对 x86 处理器的汇编器，它可以将我们使用纯 x86 汇编代码编写的程序，编译为对应的二进制可执行文件。</p><p>本书使用汇编代码与 C 代码，介绍了 x86-64 平台上的系统调用、虚拟内存、非本地跳转、调用约定，以及共享库等内容，信息量非常丰富。不过这本书也有一些不足的地方，比如某些章节的内容可能有些偏题（如 12.2 节介绍的递归下降算法），并且课后习题较为复杂（比如有一节的课后题是使用汇编实现一个 Forth Machine）。</p><p><strong>第五本书是潘爱民等人编写的《程序员的自我修养——链接、装载与库》。</strong></p><p><img src=\"https://static001.geekbang.org/resource/image/b1/a6/b103d17279118b5fb20c94dbcbc715a6.png?wh=1073x1281\" alt=\"图片\"></p><p>这本书可以作为 CSAPP 的后续拓展资料。<strong>该书详细地介绍了程序编译及运行时背后发生的一切细节</strong>，比如目标文件的结构、静态链接与动态链接的区别、Linux 共享库的版本控制，以及 CRT 的组成结构与运行原理等。但稍有遗憾的是，本书的相关内容是基于 IA-32 而非 x86-64 平台介绍的，两者在某些技术细节上可能稍有不同。</p><p><strong>第六本书是 Peter Van Der Linden 的《Expert C Programming: Deep C Secrets》</strong>。</p><p><img src=\"https://static001.geekbang.org/resource/image/24/9a/24c76d4daa17b5f89809c200d521399a.png?wh=898x1074\" alt=\"图片\"></p><p>这本书出版于 1994 年，因此其中的部分内容在如今的 C17 甚至 C2x 标准下，早已过时。但我仍然向你推荐它的一个重要原因是，这本书的作者以诙谐幽默的方式讲述了 C 语言在设计上的种种考量。如果你想知道为什么 C 语法会被如此设计，那么看完这本书，你可能会有新的发现。</p><p><strong>最后一本书是邓志的《x86/x64 体系探索及编程》</strong>。</p><p><img src=\"https://static001.geekbang.org/resource/image/95/e3/95ce3f3dfb5d302363e2b80e940411e3.png?wh=888x1254\" alt=\"图片\"></p><p>从名字上就能看出，这是一本专注于探索 x86/x64 平台处理器架构的书，因此它并非适合所有 C 开发者。如果你对 x86 ISA 指令的原理和使用细节感兴趣，又不想直接阅读英文版的 Intel x86 Manual，那这本书无疑是一个很好的选择。</p><p>当然，除了上面推荐的这几本书外，在学习 C 语言的过程中，你也可以参考 <a href=\"https://cplusplus.com\">cplusplus.com</a> 和 <a href=\"https://cppreference.com\">cppreference.com</a> 等较为权威的网站，来查询与具体 C 语法或标准库特性使用相关的内容。</p><p>“书山有路勤为径，学海无涯苦作舟。”希望本讲的内容能给你一些帮助，让我们一起在终身学习的旅程中继续前进。</p>","neighbors":{"left":{"article_title":"春节策划一 | 构建自己的知识体系，让学习的“飞轮”持续转动","id":484220},"right":{"article_title":"春节策划三 | JIT Compilation：一种特殊的程序执行方式","id":484465}}},{"article_id":484465,"article_title":"春节策划三 | JIT Compilation：一种特殊的程序执行方式","article_content":"<p>你好，我是于航。</p><p>这是最后一篇春节加餐了，今天我想和你分享的是一篇我之前写过的文章。这篇文章主要介绍了什么是 JIT Compilation 技术，以及如何使用 C++ 语言来实现一个简单的 JIT 编译器。</p><p>之所以跟你分享这篇文章，是因为编译器一直是 C 和 C++ 等语言可以大显身手的重要基础软件领域。同时，因为 JIT 是一种特殊的程序执行流程，了解它还能够为我们后续深入理解程序运行原理打下一定基础。并且，通过这篇文章，你能够大致感受到 C 和 C++ 这两种语言在使用上的差异。后面我还会专门写一篇比较 C 和 C++ 的特别放送，用专门的一讲来向你介绍它们在多个方面的异同。</p><p>在之前的版本基础上，结合最近写专栏时的思考，我对这篇文章进行了部分迭代和更新。并且，为了方便你理解文章的主要内容，当遇到 C++ 的专有特性时，我也会为你简单介绍。希望这篇文章对你有帮助，如果你有任何问题或者疑惑，欢迎在评论区给我留言，我们一起交流讨论。</p><p><strong>以下是文章正文部分。</strong></p><p>通过这篇文章，我希望能够让你了解到以下这些内容：</p><ul>\n<li>什么是 JIT Compilation 技术？它有哪些特性？</li>\n<li>如何使用 C++ 在不依赖任何框架的情况下实现一个简单的 JIT Compiler？</li>\n</ul><p>而限于篇幅和话题范围，本文不会涉及以下这些内容：</p><!-- [[[read_end]]] --><ul>\n<li>如何编写完备的 Interpreter / Compiler？</li>\n<li>相关的高级编译优化技术。</li>\n</ul><p>由于编写 JIT Compiler 涉及高级编程语言、汇编指令、计算机体系结构，以及操作系统等多方面知识，因此这里我假设你已经具备这些领域相关的基础知识，而当在文中提及相关内容时，我也会做简单的介绍。</p><p>在本文接下来将要介绍的例子中，考虑到完备性，以及为了便于进行 Benchmark，我们会为一个名为 Brainfuck 的真实存在的编程语言实现一个简单的 JIT Compiler。同时，我们也会为其实现一个相应的 Interpreter，从而比较 JIT Compilation 与 Interpretation 这两种方式在代码整体执行效率上的差异。而关于 Interpreter 部分的具体实现细节，你可以参考例子所在仓库中给出的源代码，限于篇幅，本文将不做赘述。在我们正式开始之前，以下是你继续阅读所需要提前了解的一些事项：</p><ul>\n<li>完整代码仓库：<a href=\"https://github.com/Becavalier/brainfuck-jit-interpreter\">https://github.com/Becavalier/brainfuck-jit-interpreter</a>；</li>\n<li>我们构建的 JIT Compiler 将以 x86-64 作为目标平台，其可以运行在 macOS 与 Linux 系统上；</li>\n<li>由于 Compiler 实现部分的代码较多，因此本文将有选择性地进行介绍，完整代码请参考上述仓库。</li>\n</ul><p>好的，那让我们开始吧。</p><h2>Brainfuck 编程语言</h2><p>Brainfuck 是一门从名字上来看就十分特殊的编程语言，它由 Urban Müller 于 1993 年创造。“brainfuck” 一词本身是一个俚语词汇，通常用来指带那些超出人们理解的、非常复杂和罕见的事物，而 Brainfuck 这门语言便是如此。例如，以下这段 Brainfuck 代码在正常执行后便会向控制台输出 “Hello, world!” 这几个字符。</p><pre><code class=\"language-c++\">++++++++++[&gt;+++++++&gt;++++++++++&gt;+++&gt;+&lt;&lt;&lt;&lt;-]&gt;++.&gt;+.+++++++..+++.&gt;++.&lt;&lt;+++++++++++++++.&gt;.+++.------.--------.&gt;+.&gt;.\n</code></pre><p>可以看到，通过肉眼识别代码本身，我们根本无法得知整段程序的意图，而这也正映射了 Brainfuck 语言其名称的含义。虽然如此，<strong>但 Brainfuck 语言本身确是一门图灵完备的极简编程语言</strong>。这门语言仅由 8 种不同的指令组成，所有由该语言编写的程序均包含由这 8 种不同指令组成的不同指令序列。而程序在运行时，其包含的这些指令序列将按顺序被依次执行。除此之外，Brainfuck 的执行模型也十分简单。</p><p>除这 8 种不同的指令外，程序在执行时还会维护一个至少包含 30000 个单元的一维字节数组（后面我们将简称其为“纸带”）。程序初始执行时，数组中的所有单元格均会被初始化为数值 0，一个可以前后移动的“数据指针”将默认指向这个数组的第一个单元。而程序在运行时将会根据不同的指令来前后移动这个数据指针，并相应地更新或使用当前所指向单元格中的内容。关于上述提到的 8 种指令，它们对应的字符和说明可以参考下面的表格：</p><p><img src=\"https://static001.geekbang.org/resource/image/83/66/8387e682d7a1c66ea210c49b27d7b566.jpg?wh=1920x1315\" alt=\"图片\"></p><p>为了加深理解，我们可以举一个简单的例子，比如下述这段 Brainfuck 代码。</p><pre><code class=\"language-c++\">++[-&gt;+&lt;]\n</code></pre><p>这段代码首先会将纸带第一个单元格内的值连续递增两次（<code>++</code>），即变为 2。随后， <code>[</code> 指令检查到当前单元格内的值不为 0（为 2），因此继续执行下一条指令。后续的四个指令 <code>-&gt;+&lt;</code> 会先将当前单元格内的值减一，接下来将数据指针向右移动到第二个单元格，然后将该单元格内的值加一，随后再返回第一个单元格，如此往复循环。直达最后的 <code>]</code> 指令判定第一个单元格内的值为 0 时，程序结束运行。</p><p>因此我们可以得知，这段程序的功能是更换纸带前两个单元格内的值。相应的，你也可以使用 <a href=\"https://brainfuck-visualizer.herokuapp.com\">Brainfuck Visualizer</a> 来查看上述程序的完整动态执行过程。</p><h2>什么是 JIT Compilation</h2><p>在了解了我们的目标语言后，接下来让我们一起看看 JIT Compilation 技术究竟是什么？相信无论是做前端、后端，还是移动端，对于 “JIT” 一词，你都肯定有所耳闻。JIT Compilation 的全称为 “Just-In-Time Compilation”，翻译过来为“即时编译”。<strong>其最显著的特征是代码的编译过程发生在程序的执行期间，而非执行之前</strong>。</p><p>通常在编译技术领域，我们会将 JIT 与 AOT 这两种方式进行对比。AOT 编译相信你十分熟悉，常见的比如：使用 Clang 对 C/C++ 代码进行编译、使用 Babel 编译 ES6 代码，甚至是将 JavaScript 代码编译为专用于某一 JS 引擎的 IR（Intermediate Representation）等过程都可以被认作是 AOT 编译的一种具体类型。而 JIT 与 AOT 之间的最大区别便是“编译过程发生的时间点”。对于 JIT 而言，其编译过程发生在程序的运行时；而对 AOT 来说，编译过程则发生在程序执行之前（通常为构建时）。</p><p>传统的 JIT 编译器在实际动态生成机器码前，会首先对原始代码或其相应的 IR 中间代码进行一系列的分析（profiling）。通过这些分析过程，编译器能够找到可以通过 JIT 编译进行性能优化的“关键代码路径”。而这里的取舍重点在于：<strong>对这些代码进行运行时优化而得到的性能提升收益，需要高于进行优化时所产生的性能开销</strong>。在后面的文章中我们将会看到，对于我们的实例而言，这些开销主要来自于代码的运行时编译，以及进行 OSR（On-Stack Replacement）的过程。而为了便于理解，在本文后续的实例中，我们将不会实现传统 JIT 所进行的代码预分析过程。</p><p>另外需要注意的是，通常的 JIT 编译器由于考虑到“启动延迟”的问题，因此一般会结合解释器一起使用。JIT 编译器所进行的代码分析过程越精细、所实施的优化越多，其动态生成的机器代码质量也会越高，但随之而来的初始代码执行延迟也会越大。而解释器的加入便可使代码的执行过程提前进行。而在此期间，JIT 编译器也会同时对代码进行分析和优化，并在特定的时刻再将程序的执行流程从解释执行转换到执行其动态生成的优化机器码。</p><p>因此，对于 JIT Compilation 这项技术而言，其实现方式需要取舍的一个重点是：<strong>在编译时间和生成的代码质量之间进行权衡</strong>。比如，JVM 便有着两种可以选择的 JIT 模式，client 与 server，其中前者会采用最小的编译和优化选项以最大程度降低启动延迟；而后者则会采用最大化的编译和优化策略，同时牺牲程序的启动时间。</p><h2>实现细节</h2><p>关于实现细节，我们将着重聚焦于源代码中的函数 bfJITCompile、函数 allocateExecMem，以及 VM 类这三个部分。这里建议在继续阅读前，先自行大致浏览一下源代码。</p><p>就如同上面我们所说的那样，JIT Compilation 的代码编译过程发生在程序的运行时，因此从源代码中也可以看到，我们通过用户在运行解释器程序时所提供的不同参数（–jit）来决定是采用 JIT 编译执行，还是直接解释执行。而对于 “JIT 编译执行” 这种方式来说，其流程可大致总结为：</p><ul>\n<li>读入源代码（包含 ASCII 形式的指令序列）；</li>\n<li>调用 bfJITCompile 函数，将源代码编译为机器码；</li>\n<li>调用 allocateExecMem 函数，将机器码动态分配在可执行的内存段上；</li>\n<li>调用 VM::exec 函数，通过 OSR 转移执行流程；</li>\n<li>代码执行完毕后再次转移回主流程；</li>\n<li>执行一些清理善后工作。</li>\n</ul><p>接下来，我们将重点介绍上述流程中的第二、三、四项的具体实现细节。</p><h3>编译机器码</h3><p>在这一步中，我们会将程序启动时输入的 Brainfuck 源代码中的所有指令字符全部“提取”出来，并直接按顺序为其生成相应的机器码版本的二进制代码。这些生成的二进制机器码将被存放在一个 <code>std::vector</code> 对象中以备后续使用。对于 <code>std::vector</code> ，你可以直接将它看作是与 C 语言中数组类似的一种容器。只不过相较数组来说，我们可以在程序运行过程中对它进行动态创建，并对其中的元素进行十分灵活的增删改查。</p><p>为了简化机器码的生成过程，我们简单地通过 switch 语句识别出指令对应的字符，并“返回”该指令对应的 x86-64 二进制机器码。而这些返回的机器码也将被直接“拼接”到用于存放机器码集合的 Vector 容器中。</p><p>这里需要注意的是，对于这些返回的二进制机器码，由于其中可能包含有引用的相对地址信息（RIP-Relative），因此在被实际存放到 Vector 容器之前，我们还需要通过诸如 _relocateAddrOfPrintFunc 等方法来对这些二进制机器码进行“地址重定位”处理。通过这些方法，我们能够准确计算出这些相对地址的实际信息，并对它们进行修正。</p><p>首先，在 bfJITCompile 函数的定义中，我们可以找到如下这段代码。通过这段代码，我们将 Brainfuck 执行模型中的“数据指针”其地址存放在了寄存器 rbx 中，这样后续我们便可以通过修改或使用该寄存器中的值来控制数据指针的位置，或者读取、修改当前数据指针所指向纸带单元格中的内容。这里代码中的 “/* mem slot */”，表示该注释所在位置的内容将在编译时被替换为实际引用的内存地址。而这个地址将来自于 bfState::ptr 的值在经过函数 _resolvePtrAddr 处理后返回的小端（little-endian）格式地址。</p><pre><code class=\"language-c++\">// prologue.\nstd::vector&lt;uint8_t&gt; machineCode {\n&nbsp; // save dynamic pointer in %rbx.\n&nbsp; 0x48, 0xbb, /* mem slot */\n};\n// ...\n</code></pre><p>接下来，随着不断读入的指令字符，bfJITCompile 函数便可以依次将这些指令转换为其对应的机器码版本。对于 “+ - &gt; &lt;” 这四个指令来说，它们对应的机器指令只需要通过操作我们先前存放在 rbx 寄存器中的数据指针的地址值，便可完成对 Brainfuck 抽象机器的状态改变。比如以 “+” 指令为例，我们可以找到如下这段代码：</p><pre><code class=\"language-c++\">// ...\ncase '+': {\n&nbsp; for (n = 0; *tok == '+'; ++n, ++tok);\n&nbsp; const auto ptrBytes = _resolvePtrAddr(ptrAddr);\n&nbsp; std::vector&lt;uint8_t&gt; byteCode {&nbsp;\n&nbsp; &nbsp; 0x80, 0x3, static_cast&lt;uint8_t&gt;(n),&nbsp; // addb $0x1, (%rbx)\n&nbsp; };\n&nbsp; _appendBytecode(byteCode, machineCode);\n&nbsp; --tok;\n&nbsp; break;\n}&nbsp;\n// ...\n</code></pre><p>对于这段代码中出现的 <code>static_cast</code> 运算符，你可以将它简单理解为 C 语言中的强制类型转换。这里我们首先使用了一个很容易想到的优化策略，那就是当遇到连续的 “+” 指令时，相较于为每一个出现的 “+” 指令都生成相同的、重复的机器码，我们可以选择首先计算遇到的，连续出现的 “+” 指令的个数，然后再通过一条单独的汇编指令 <code>addb $N, (%rbx)</code> 来将这多个 “+” 指令产生的状态变更一次性完成。相同的方式还可以被应用到其余的三种指令，它们分别对应数据指针所指向单元格内值的改变，以及数据指针本身的值的改变。</p><p>而对于 “,” 及 “.” 指令来说，由于它们涉及 IO 操作，因此这里对应的机器码将涉及对操作系统调用（System Call）的调用过程。操作系统调用需要遵循特定的调用惯例（Calling Convention）进行。比如对于 SysV ABI 来说，寄存器 rax 用于存放系统调用号、rdi 用于存放第一个参数、rsi 用于存放第二个参数，以及 rdx 用于存放第三个参数等等。同时，macOS 与 Linux 操作系统下的系统调用号也并不相同，这里我们通过预处理指令来进行区分。</p><pre><code class=\"language-c++\">// ...\ncase ',': {\n&nbsp; /**\n&nbsp; &nbsp; movl $0x2000003, %eax\n&nbsp; &nbsp; movl $0x0, %edi\n&nbsp; &nbsp; movq %rbx, %rsi\n&nbsp; &nbsp; movl $0x1, %edx\n&nbsp; &nbsp; syscall\n&nbsp; */\n&nbsp; std::vector&lt;uint8_t&gt; byteCode {&nbsp;\n#if __APPLE__\n&nbsp; &nbsp; 0xb8, 0x3, 0x0, 0x0, 0x2,\n#elif __linux__\n&nbsp; &nbsp; 0xb8, 0x0, 0x0, 0x0, 0x0,\n#endif\n&nbsp; &nbsp; 0xbf, 0x0, 0x0, 0x0, 0x0,\n&nbsp; &nbsp; 0x48, 0x89, 0xde,\n&nbsp; &nbsp; 0xba, 0x1, 0x0, 0x0, 0x0,\n&nbsp; &nbsp; 0xf, 0x5,\n&nbsp; };\n&nbsp; _appendBytecode(byteCode, machineCode);\n&nbsp; break;\n}\n// ...\n</code></pre><p>最后，对于 “[” 和 “]” 指令，其实现逻辑会稍微有些复杂。以 “[” 指令为例，如下代码所示。在这里，将 “[” 指令的语义逻辑直接映射到汇编代码是十分简单的，其逻辑是：判断当前数据指针所指向单元格的值是否为 0。若为 0，则执行流程跳转到后续与其配对的 “]” 指令的后一个指令；否则继续执行下一条指令。</p><p>因此，我们这里直接使用 <code>cmpb</code> 汇编指令来判断以寄存器 rbx 中的值作为地址时，其对应内存位置的值是否为 0。若为 0，则使用 <code>je</code> 汇编指令跳转到后续的指令位置，否则直接执行下一条指令。代码中对“后续指令地址”的使用将会在与其配对的 “]” 指令处理流程中对其进行重定向处理。因此，这里我们将使用连续四个字节的 0x0 值进行占位。另外需要知道的是，为了简化实现，这里我们将固定使用 “near jump” 模式。</p><pre><code class=\"language-c++\">// ...\ncase '[': {\n&nbsp; /*\n&nbsp; &nbsp; cmpb $0x0, (%rbx)\n&nbsp; &nbsp; je &lt;&gt;\n&nbsp; */\n&nbsp; std::vector&lt;uint8_t&gt; byteCode {&nbsp;\n&nbsp; &nbsp; 0x80, 0x3b, 0x0,\n&nbsp; &nbsp; 0xf, 0x84, 0x0, 0x0, 0x0, 0x0, /* near jmp */\n&nbsp; };\n&nbsp; // record the jump relocation pos.\n&nbsp; _appendBytecode(byteCode, machineCode);\n&nbsp; jmpLocIndex.push_back(machineCode.size());\n&nbsp; break;\n}\n// ...\n</code></pre><p>至此，我们便完成了机器指令的动态编译工作。通过这个阶段，我们的程序可以将输入的 Brainfuck 指令字符序列转换成对应的平台相关的二进制机器码。你可以在 bfJITCompile 函数的最后看到如下所示的这样一段“收尾代码”。这段代码主要用于在程序退出前“推出”标准输出流中缓存的内容，并重置 rip 寄存器的值，以将程序执行流程退回到 C++ 代码中。后续我们还将回顾这部分内容。</p><pre><code class=\"language-c++\">// epilogue.&nbsp;\n// mainly restoring the previous pc, flushing the stdout buffer.\n/**\n&nbsp; cmpq $0, %r11\n&nbsp; je 8\n&nbsp; callq &lt;print&gt;\n&nbsp; jmpq *(%rsp)\n&nbsp; */\nstd::vector&lt;uint8_t&gt; byteCode {\n&nbsp; 0x49, 0x83, 0xfb, 0x0,\n&nbsp; 0x74, 0x8,\n&nbsp; 0xe8, /* mem slot */\n&nbsp; 0xff, 0x24, 0x24,\n};\n</code></pre><h3>可执行内存分配</h3><p>接下来，我们将关注点从“如何动态生成机器码”转移到“如何动态执行机器码”这个问题上。关于这部分实现可以参考名为 allocateExecMem 的函数，相关如下代码所示。</p><pre><code class=\"language-c++\">// ...\nuint8_t* allocateExecMem(size_t size) {\n&nbsp; return static_cast&lt;uint8_t*&gt;(\n&nbsp; &nbsp; mmap(\n&nbsp; &nbsp; &nbsp; NULL,\n&nbsp; &nbsp; &nbsp; size,&nbsp;\n&nbsp; &nbsp; &nbsp; PROT_READ | PROT_WRITE | PROT_EXEC,&nbsp;\n&nbsp; &nbsp; &nbsp; MAP_PRIVATE | MAP_ANONYMOUS,&nbsp;\n&nbsp; &nbsp; &nbsp; -1,\n&nbsp; &nbsp; &nbsp; 0));\n}\n// ...\n</code></pre><p>在这个函数的定义中，我们调用名为了 mmap 的函数，而该函数便是支持“动态执行机器码”的关键所在。mmap 函数是一个由 C 标准库提供的系统调用，通过该函数，我们可以在当前进程的 VAS（Virtual Address Space）中创建一个映射。这个映射可以指向一个具体的文件、或者是一个匿名空间。关于 mmap 函数，我们最为熟知的一种使用方式便是在为目标文件分配虚拟页时，操作系统会使用该函数将页表条目指向目标文件中的适当位置。而在这里，我们则需要利用该函数来创建不指向任何实际文件的“匿名空间”，并将我们在上一步中编译得到的二进制机器码连续地放入到这段内存空间中。</p><p>不仅如此，通过为 mmap 函数的第三个参数指定 PROT_EXEC 属性，我们可以将这段申请的匿名内存空间标记为“可执行”。这便意味着，存放在这段内存空间中的机器指令可以被 CPU 执行。关于该函数其他参数的详细配置信息，你可以参考<a href=\"https://man7.org/linux/man-pages/man2/mmap.2.html\">这个链接</a>来查阅更多信息。allocateExecMem 函数的实际调用过程则被放置在了 VM 类的构造函数中，在这里我们通过 RAII 将资源的分配与销毁进行了简单的封装。</p><h3>OSR（On-Stack Replacement）</h3><p>当编译生成的二进制机器码被放入可执行匿名内存段后，接下来的重点便是：如何将程序的指令执行流程转移至这段内存的起始位置处？关于这部分实现，我们需要借助 Clang/GCC 编译器提供的 “C++ 内联汇编” 功能。你可以在 VM::exec 函数的实现中找到答案。这段代码如下所示：</p><pre><code class=\"language-c++\">// ...\nvoid exec() {\n&nbsp; // save the current %rip on stack (by PC-relative).\n&nbsp; // %r10 - stdout buffer entry.\n&nbsp; // %r11 - stdout buffer counter.\n&nbsp; asm(R\"(\n&nbsp; &nbsp; pushq %%rax\n&nbsp; &nbsp; pushq %%rbx\n&nbsp; &nbsp; pushq %%r10\n&nbsp; &nbsp; pushq %%r11\n&nbsp; &nbsp; pushq %%r12\n&nbsp; &nbsp; movq %1, %%r10\n&nbsp; &nbsp; xorq %%r11, %%r11\n&nbsp; &nbsp; lea 0x9(%%rip), %%rax&nbsp;\n&nbsp; &nbsp; pushq %%rax\n&nbsp; &nbsp; movq %0, %%rax\n&nbsp; &nbsp; addq %2, %%rax\n&nbsp; &nbsp; jmpq *%%rax&nbsp;\n&nbsp; )\":: \"S\" (mem), \"m\" (stdoutBuf), \"D\" (prependStaticSize));\n\n&nbsp; // clean the stack.\n&nbsp; asm(R\"(\n&nbsp; &nbsp; addq $8, %rsp\n&nbsp; &nbsp; popq %r12\n&nbsp; &nbsp; popq %r11\n&nbsp; &nbsp; popq %r10\n&nbsp; &nbsp; popq %rbx\n&nbsp; &nbsp; popq %rax\n&nbsp; )\");\n}\n// ...\n</code></pre><p>在这段代码中，我们使用了两次 asm 汇编指令。其中，第一次内联汇编的目的主要是为了将程序的执行流程转移到我们之前动态编译生成的机器码上。这里前 5 行对 <code>push</code> 指令的调用过程主要用于将这些寄存器中的值存放到栈上，以保护此刻的寄存器状态。而这些值将会在程序的执行流程返回到 C++ 代码后再被重新恢复。第 6 行的 <code>movq</code> 指令将标准输出流缓存区的首地址存放到了寄存器 r10 中，这个缓存区将用于缓存通过 “.” 指令输出的字符内容，以减少系统调用的实际调用次数，提升性能。接下来的第 8-9 行，我们将正常 C++ 代码执行流程的下一条指令其地址存放到了栈上，以便后续能够从动态执行流程中正常返回。第 10-11 行，我们正确地设置了匿名可执行内存段的地址以及相应的偏移位置（跨过了函数定义部分）。最后一行，通过 <code>jmpq</code> 指令，我们让 CPU 的执行流程跳转到以 rax 寄存器中的值作为内存地址的位置，即包含我们将要执行的第一条动态指令的位置。</p><p>至此，从 C++ 代码到动态指令的执行转移流程便完成了。而当动态生成的指令全部执行完毕后，我们需要通过类似的方式再将执行流程转移回正常的 C++ 代码中。还记得我们在“编译机器码”这一小节最后提到的那小段 “epilogue” 汇编代码吗？如果返回去查看，你会发现在这段代码的最后一条指令中，我们使用了 <code>jmpq *(%rsp)</code> 指令，这条指令将会把 CPU 的执行流程转移到以当前进程栈底存放的那个 qword 值作为地址的内存位置上。而这个值，便是我们在上一步中存放的 C++ 代码的返回地址。当执行流程返回到 C++ 代码后，我们遇到了第二个 <code>asm</code> 汇编指令。通过这段指令，我们可以清理栈上的内容并同时恢复相关寄存器的状态。到这里，程序的执行流程便基本结束了。</p><p>让我们将目光再移回到本小节的主题 “OSR” 上来。OSR 的全称为 “On-Stack Replacement”。借助 Google，我们可以找到对它的一个定义，如下所示：</p><blockquote>\n<p>On-stack-replacement (OSR) describes the ability to replace currently executing code with a different version, either a more optimized one (tiered execution) or a more general one (deoptimization to undo speculative optimization).</p>\n</blockquote><p>实际上，对于 OSR 我们可以将它简单理解为“从一个执行环境到另一个执行环境的转换过程”。比如在我们的实例中，VM::exec 函数在执行时，它会将执行环境从 C++ 代码转移至动态生成的机器码，最后再以同样的方式转移回来。而这样的执行环境转换便可被视为 OSR 的过程。下图是对上述 OSR 过程的一个形象展示。</p><p><img src=\"https://static001.geekbang.org/resource/image/07/7f/072932482d69569cc822a3323dfc307f.png?wh=1404x1170\" alt=\"图片\"></p><h2></h2><h2>Benchmark</h2><p>至此，我们已经介绍完了 Brainfuck JIT Compiler 几个关键点的实现细节。那现在让我们来看看这个粗糙版的 JIT 编译器其性能如何？项目的源代码中提供了两组测试，分别用于测试“IO 密集型”与“计算密集型”这两个应用场景。一组测试结果如下所示：</p><p>IO 密集型场景：</p><pre><code class=\"language-plain\">Benchmark for 10 seconds: (higher score is better)\n&nbsp; &nbsp;12950 interpreter\n&nbsp; &nbsp;35928 jit (win)\n</code></pre><p>计算密集型场景：</p><pre><code class=\"language-plain\">Benchmark Result: (lower time is better)\n&nbsp; &nbsp; 13.018s interpreter\n&nbsp; &nbsp; &nbsp;0.885s jit (win)\n</code></pre><p>可以看到，总体结果还算不错。对于 IO 密集型的测试用例，JIT Compilation 相比单纯的 Interpretation 可以带来将近 3 倍的性能提升。而对于计算密集型场景来说，JIT 带来的性能提升便十分可观了。在我们的“打印曼德布洛特集合”的测试用例中，使用 JIT Compilation 相较于 Interpretation 可以带来将近 15 倍的性能提升。当然，鉴于我们并没有采用更加完备的测试集合及测试方案，这些测试用例结果仅供参考。</p><h2>更多信息</h2><p>接下来，我们将会对额外的一些问题进行适当的讨论。当然，这些话题中每一个都可以展开形成一篇完整的文章，因此这里只做引申之意。</p><h3>Interpretation 之殇</h3><p>可以说，“分支预测失败（Branch Misprediction）” 是众多导致解释器运行缓慢的原因中最为重要的一个。例如我们在本文实例的源代码中实现的那个基于 switch 语句的解释器。这个解释器模型每次读取输入源文件中的一个字符指令，然后再根据指令内容相应地改变当前解释器的状态（如：数据指针、纸带内容等）。</p><p>而这样方式所产生的问题在于：从宏观来看，CPU 在实际执行这个 switch 语句时，无法得知下一次将要输入的可能符号指令是什么，而这便会导致 “PC 分支预测” 失败。从微观上来看，无法预测或预测失败都会导致 CPU 时钟周期的浪费（需等待结果，或丢弃错误预测值而导致流水线重填装等）。因此，由“流水线相关”导致的指令延迟也将在大量指令执行后凸显出来。</p><p>而对于诸如 “Direct Threading” 与 “Subroutine Threading” 等解释器模型来说，它们虽然可以较好地解决分支预测失败的问题，但随之而来的诸如：使用了过多的 <code>jmp</code> 指令、产生了无用的栈帧（没有内联）等问题也会大大降低解释器在解释程序时的性能。相对的，JIT Compilation 通过动态生成机器码、内联编译等基本优化策略便可轻松避免上述这些问题。不仅如此，某些 JIT 编译器甚至能够获得比 AOT 方式更高的运行时性能提升。而这主要源于 JIT 能够在代码运行时根据当前操作系统类型、CPU ISA 体系、代码 Profiling 结果进行更加动态、启发式的代码优化过程。</p><h3>JIT 实现策略与方式</h3><p>常见的 JIT 策略可以被分为这样几类：Method-based JIT、Trace-based JIT 以及 Region-based JIT。其中，Method-based JIT 使用“函数”作为独立的编译单元，编译器会在代码执行的过程中识别出热点函数（比如依据函数的被调用次数），然后再使用编译后的机器码版本进行替换。这种方式实现较为简单但也存在相应的问题，比如其 JIT 粒度较为粗糙，热代码的命中率较低，位于函数体中的耗时逻辑（比如“循环”）无法被准确捕捉。</p><p>相对的，Trace-based JIT 则使用 “Trace” 作为热代码的编译单元。一个 Trace 是指程序在运行时所执行的一段热代码路径。从源代码上来看，这些热代码的执行路径可能会横跨多个函数。而 JIT 编译器要做的事情，便是对这段路径上的热代码进行运行时的编译优化。</p><p>最后的 Region-based JIT 则是以 “Tracelet” 作为其编译单元的，这种 JIT 方案主要来自于 Facebook 的 HHVM 虚拟机实现。一个 Tracelet 通常是指一段可以被“类型特化”的最长的执行路径。更多的信息可以参考<a href=\"https://research.fb.com/wp-content/uploads/2018/04/hhvm-jit-a-profile-guided-region-based-compiler-for-php-and-hack.pdf\">这篇论文</a>。</p><p>除了上述这三种常见的 JIT 编译器实现策略外，对于实现细节，相较于我们在本文中使用的“人肉机器码编译”过程，通常我们会选择使用一些编译框架来提供更好的机器码拣选和编译功能。常用的框架比如：DynASM、LLVM 以及 Cranelift 等。这些框架通常不止提供基础的、针对具体平台的机器码编译功能、同时也还会提供相应的代码优化功能。比如对于 Method-based JIT 这种策略来说，通常一些可用于静态 AOT 编译的优化策略也可以被 JIT 编译器直接使用，而通过使用诸如 LLVM，我们便可以更简单地直接使用这些十分成熟的优化策略，免除了重复实现的烦恼。</p><h2>总结</h2><p>今天分享的这篇文章就到这里了，我来稍微总结一下本文的几个重点：</p><ul>\n<li>JIT 是一种程序优化技术，它会在程序运行时进行动态分析，并使用重新编译生成的优化机器码替换原程序中关键逻辑对应的原始机器码；</li>\n<li>JIT 在实现过程中会进行多次的程序执行上下文转换，其中涉及对程序运行时栈、寄存器的保存与恢复等过程。这个过程通常被统称为“OSR”；</li>\n<li>JIT 编译器动态生成的机器码会被放置在由 mmap 等系统调用创建的可执行内存中，然后通过调整程序的 PC 指针，这些代码可以在适当的时机被执行。</li>\n</ul><p>希望这篇文章可以帮助到你，也希望你在下方的留言区和我一起讨论。同时，欢迎你把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"春节策划二 | 关于 C 语言，我有这些书籍想推荐给你","id":484383},"right":{"article_title":"课堂答疑（一）｜前置篇、C 核心语法实现篇问题集锦","id":474252}}},{"article_id":474252,"article_title":"课堂答疑（一）｜前置篇、C 核心语法实现篇问题集锦","article_content":"<p>你好，我是于航。</p><p>看到这里的你，应该已经完成了本课程前两个模块的学习。随着课程的不断推进，我陆续收到了很多反馈。很高兴看到你在评论区积极留言，和大家一起讨论思考题。并且，还有很多同学提出了一些非常有意义的问题。那么，在继续学习后面更深入的内容之前，让我们先暂缓脚步，从问题出发，进行一次整体性的回顾。</p><p>在这一讲中，我会以加餐的形式，为你剖析一些值得讨论的思考题，以及你们提出的有代表性的问题。</p><p><strong>问题一：</strong>在 <a href=\"https://time.geekbang.org/column/article/464550\">01 讲</a> 的最后，我留给你的问题是：在这一讲第一部分的 C 代码实例中，我们为何要给函数 findAddr 添加 <code>static</code> 关键字？不添加这个关键字的话，程序是否可以编译运行？</p><p>这里，我将那段代码简化了一下，只提取出与问题相关的部分，放到了下面。因此，问题也变成了：对于下面这段代码来说，将函数 foo 定义中使用的 <code>static</code> 关键字去掉，是否会影响程序的正常编译和运行呢？</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\ninline static int foo(void) {&nbsp;\n&nbsp; return 0;\n}\nint main(void) {\n&nbsp; printf(\"%d\", foo());\n&nbsp; return 0;&nbsp;\n}\n</code></pre><p>实际上，如果你能够在 <a href=\"https://godbolt.org\">godbolt</a> 上快速实践一下，就会发现：在默认情况下（没有使用任何优化参数），编译器会报出类似 “error: ld returned 1 exit status” 的链接器错误；而在使用 “-O1” 及以上优化参数的情况下，编译器则可以正常编译。那么，为什么会这样呢？</p><!-- [[[read_end]]] --><p>实际上，虽然我们在课程中会使用 C17 标准对代码进行编译，但上述代码中使用的 <code>inline</code> 关键字却来源于 C99 标准。对于编译器来说，在这个标准下，标注了 <code>inline</code> 关键字的函数<strong>意味着函数的定义仅用于内联</strong>。而当编译器在低优化等级下不选择将函数进行内联处理时，便会尝试去寻找一个可以进行链接的函数实现。</p><p>关于这一点，我们也可以从 C 标准中得到印证。在<a href=\"https://web.archive.org/web/20181230041359if_/http://www.open-std.org/jtc1/sc22/wg14/www/abq/c17_updated_proposed_fdis.pdf\">这个链接</a>中， C17 标准文档的 91 页，第 6.7.4.7 小节对 <code>inline</code> 关键字进行了总结，你可以参考。</p><p>到这里，解决这个问题的方法就变得十分清晰了。通常，我们可以使用以下几个办法：</p><ol>\n<li>去掉 <code>inline</code> 关键字。由于该关键字通常只作为编译器的 hint，因此在使用优化的情况下，基本不会影响编译结果；</li>\n<li>使用 <code>static inline</code>，为函数提供 internal linkage。编译器总是能够使用在当前编译单元内具有静态链接的函数；</li>\n<li>使用 <code>extern</code> 为函数提供对应的 external definition。但这种方式与定义一个普通函数没有区别，从标准上来看，不符合内联的规则，即 inline definition。</li>\n</ol><p>另外，你也可以考虑使用 GNU C89 标准进行编译（-std=gnu89），以采用旧式的内联处理机制。但这种方式会让我们无法使用 C 语言的新特性，所以我并不推荐。</p><p><strong>问题二</strong>：在问题一的例子中，为什么使用 <code>inline static</code> 而不是 <code>static inline</code> 呢？</p><p>这是一个非常棒的问题。实际上，对于编译器而言，这两种写法都可以正常工作。但不同点在于，对于 C17 以前的标准来说，“声明标识符（Declaration Specifier）”是可以按照任意顺序摆放的。而在 C17 及以后的标准中则规定，声明标识符中的 “Storage-class Specifier” 应该被放置在各定义的最开头处，这其中便包含有 <code>static</code> 关键字。而对于其他形式，则会被视为过时的写法。但实际上，考虑到向前兼容，现代编译器都还支持这种旧式写法。</p><p><strong>问题三</strong>：有同学问到，为什么我们在文章代码中使用的内联汇编，与通过 C 代码编译而来的汇编，两者在风格上有很大差异？比如，对于同一个机器指令来说，两种风格在源操作数与目的操作数的使用顺序上竟然是完全相反的。</p><p>没错，这是一个相当细心的同学。实际上，对于 x86 汇编语言来说，目前工业界主要有两种不同的代码编写风格，即 Intel 风格和 AT&amp;T 风格。其中，前者被广泛使用在 Windows 操作系统及相关工具链上，而后者则被广泛使用在 “Unix 世界”中（因为 Unix 是从 AT&amp;T 贝尔实验室创建的）。因此，不同的代码风格便也对应着不同的代码编写方式。</p><p>这里，我把它们之间的一些主要区别，通过具体的例子进行了描述，并整理在了下面的表格中供你参考：</p><p><img src=\"https://static001.geekbang.org/resource/image/92/e8/9207fcyyce02361252ac01c29f6e8ee8.jpg?wh=1920x833\" alt=\"图片\"></p><p><strong>问题四</strong>：有同学在实践时发现，我在 <a href=\"https://time.geekbang.org/column/article/465228\">02 讲</a> 中介绍的一段本无法被正常编译的代码，却可以在 Clang 编译器下被正常编译。这里，为了方便你观察，我将这段代码直接放到了下面：</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\nint main(void) {\n&nbsp; const int vx = 10;\n&nbsp; const int vy = 10;\n&nbsp; int arr[vx] = {1, 2, 3};&nbsp; // [错误1] 使用非常量表达式定义定长数组；\n&nbsp; switch(vy) {\n&nbsp; &nbsp; case vx: {&nbsp; // [错误2] 非常量表达式应用于 case 语句；\n&nbsp; &nbsp; &nbsp; printf(\"Value matched!\");\n&nbsp; &nbsp; &nbsp; break;\n&nbsp; &nbsp; }\n&nbsp; }\n}\n</code></pre><p>正如代码中第 5 行和第 7 行注释所描述的那样，我们无法用非常量表达式（值）来作为定长数组的长度参数，或是直接用于 <code>case</code> 语句中。而这段代码之所以能在 Clang 中被正常编译，则是由于编译器通常会竭尽所能地去编译用户提供的代码。</p><p>因此，在这个例子中，Clang 会在默认情况下使用名为 “gnu-folding-constant” 的 GNU 扩展，来处理代码中不符合 C 标准的用法。该扩展可以在代码需要的地方，将非常量表达式转换为常量表达式使用。但实际上，这并非 C 标准的内容。</p><p>为此，我们可以通过在编译代码时指定 “-pedantic-errors” 选项，阻止编译器对扩展能力的使用。该选项会在编译器使用扩展时发出相应的错误警告。而 GCC 与 Clang 这两个编译器均支持该选项。</p><p><strong>问题五</strong>：学习 C 语言，真的有必要了解汇编吗？</p><p>相信这是一个困扰很多 C 语言初学者的问题，这里我来谈一谈自己的理解。</p><p>首先，这个问题是没有标准答案的。C 语言被创造出来的目的之一，就是抹平汇编语言在编码上的差异。通过这种方式，人们可以做到代码的一次编写，多次编译。所以，对于学习或编写 C 代码来说，实际上是不需要了解汇编语言的。编译器会以最好的方式，帮助你将 C 代码转换成对应的机器代码。</p><p>但如果是这些情况：在你的应用场景中，单纯使用 C 代码无法完成相关任务（比如需要使用“内联汇编”的场景），或者你对 C 程序的性能优化有着极致的追求，又或是你想对程序的运行细节有更多的理解……那么，适当学习汇编语言与计算机体系结构的相关知识便是必要的。</p><p>总而言之，是否需要学习汇编语言，还是要看学习者自身的目的。编程语言是一种工具，学习它首先是要做到能用起来，在此基础上，再根据每个人的不同需求，向不同方向深入。</p><p><strong>问题六</strong>：<code>leave</code> 指令在“清理栈”时会将相关内存清空（置零）吗？</p><p>这个问题非常好。一般来说，我们在编码过程中提及所谓“清空”或“清理”时，大部分人第一时间都会认为是将某个量重置为对应的初始值，这其中可能包含有将某个值置为 0 的过程。但实际上，对于 <code>leave</code> 指令来说，它仅会在执行时修改寄存器 rsp 和 rbp 的值，但并不会对“残留”在栈中的数据（比如前一个栈帧）做任何处理。你可以通过下面这段代码来验证这个结论：</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\nvoid foo(void) {\n&nbsp; int x;\n&nbsp; printf(\"%d\\n\", x);\n&nbsp; x = 10;\n}\nint main(void) {\n&nbsp; foo();\n&nbsp; foo();\n&nbsp; return 0;\n}\n</code></pre><p>因此，对于一个程序来说，相关寄存器中的值便能够完全表示这一时刻该程序的实际运行状态。在接下来的 <a href=\"https://time.geekbang.org/column/article/475867\">12 讲</a> 中，你将会看到，setjmp 与 longjmp 函数是如何通过保存寄存器的值来恢复函数的执行状态的。</p><p><strong>问题七</strong>：有同学问到，对于某些简单的算数运算逻辑，编译器为什么会使用 <code>lea</code> 指令，而非 <code>mov</code> 指令来实现呢？</p><p>实际上，对于某些特定格式的简单计算，使用 <code>lea</code> 指令可以获得比 <code>mov</code> 指令更好的性能。比如，来看下面这段 C 代码：</p><pre><code class=\"language-c++\">int foo(int n) {\n&nbsp; return 4 * n + 10;\n}\n</code></pre><p>对于这里的 foo 函数来说，编译器可以选择使用 <code>mov</code> 指令按照下面的方式来实现：</p><pre><code class=\"language-c++\">mov eax, edi\nsal eax, 2\nadd eax, 10\n</code></pre><p>当然，也可以使用 <code>lea</code> 指令，以一种更加精简的方式来实现：</p><pre><code class=\"language-c++\">&nbsp;lea&nbsp;eax, [10+rdi*4]\n</code></pre><p>可以看到，使用 <code>lea</code> 指令实现这段代码，可以让程序少执行两条机器指令，从而进一步提升程序的运行时性能。</p><p>在 x86 体系中，指令参数可以使用的一种内存地址形式为 [base + scale x offset + displacement]。其中，displacement 必须为 32 位有符号格式的立即数，scale 的可选值为 1、2、4 或 8，base 和 offset 可以由寄存器或者立即数组成。因此，通过这种方式，<code>lea</code> 指令就能够被用于实现多种基本的算术运算，并优化程序性能。</p><p><strong>问题八</strong>：C 语言可以实现类似 C++ 的函数重载吗？</p><p>这个问题很好，但遗憾的是，C 语言并没有提供用于实现多态的相关特性。不过在 C11 之后，借助泛型宏 _Generic，我们也可以在一定程度上实现类似的功能。具体你可以参考下面这段示例代码。而关于这个宏的详细使用方式，可以参考<a href=\"https://www.geeksforgeeks.org/_generic-keyword-c\">这个</a>链接。</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\n#define foo(N) _Generic((N), \\\n&nbsp; double: food, \\\n&nbsp; default: fooi, \\\n&nbsp; float: foof)(N)\nint fooi(int n) { return n; }\ndouble food(double n) { return n; }\nfloat foof(float n) { return n; }\nint main(void) {\n&nbsp; printf(\"%d\", foo(1));\n&nbsp; return 0;\n}\n</code></pre><p>好了，今天的答疑就到这里，感谢提出问题的各位同学。如果你还有其他问题，欢迎在评论区与我讨论。</p>","neighbors":{"left":{"article_title":"春节策划三 | JIT Compilation：一种特殊的程序执行方式","id":484465},"right":{"article_title":"课堂答疑（二）｜C 工程实战篇问题集锦","id":488595}}},{"article_id":488595,"article_title":"课堂答疑（二）｜C 工程实战篇问题集锦","article_content":"<p>你好，我是于航。</p><p>在这门课的第三个模块“C 工程实战篇”中，我带你学习了在大型工程实战中应用 C 语言时需要掌握的很多必备技巧。而这次的答疑加餐，我从这个模块的课后思考题中精选了同学们讨论比较多，也比较有代表性的三个问题，来对它们进行详细分析。接下来，就请跟随我的脚步，一起来看看吧。</p><h2><strong>问题一</strong></h2><p>我在<a href=\"https://time.geekbang.org/column/article/478213\"> 14 讲</a> 的“使用条件变量”一节中为你留下了这样一个问题：</p><p>在下面的代码中，为什么我们要在 while 语句，而不是 if 语句中使用 cnd_wait 呢？</p><pre><code class=\"language-c++\">// ...\nwhile (done == 0) {&nbsp;\n&nbsp; cnd_wait(&amp;cond, &amp;mutex);\n}\n// ...\n</code></pre><p>对于这个问题，评论区的一些同学给出了不错的回答。比如 @liu_liu 同学就指出了其中的一个原因：</p><blockquote>\n<p>当阻塞的线程被重新调度运行时，done 的值可能被改变了，不是预期值。</p>\n</blockquote><p>还有 @ZR2021 同学也提到了与此相关的另一个重要因素：</p><blockquote>\n<p>使用 while 是防止广播通知方式的虚假唤醒，需要用户进一步判断。</p>\n</blockquote><p>这里，我就在同学们的回答基础上，对这个问题做一个总结。</p><p>首先需要知道的是，使用 while 或 if 语句的主要目的，在于判断线程是否满足“可以进入阻塞状态”的基本条件。比如，在上述代码中，当全局变量 done 的值为 0 时，表明当前线程需要优先等待其他线程完成某项任务后，才能够继续执行。但在现实情况中，“等待线程”的执行恢复往往会在各种非正常情况下发生。通常来说，这些情况可以被总结为三类。</p><!-- [[[read_end]]] --><p>第一种情况：在某些特殊的操作系统中，为了满足实现上的灵活性，<strong>条件变量中已进入阻塞状态的线程，允许在未经 cnd_signal 函数通知的情况下被唤醒</strong>。而在这种情况下，当前的程序状态可能并不满足被唤醒线程继续执行的条件。因此，使用 while 循环重新对条件变量进行检查，便成为了保证程序能够正确运行的重点。</p><p>第二种情况：在某些多处理器核心的系统上，<strong>cnd_signal 函数的调用可能会同时唤醒所有等待线程</strong>。因此，在“生产者与消费者”等类似场景中，让唤醒线程重新对条件进行检查，便能够防止因“产物不足”而导致的程序运行问题。</p><p>第三种情况：<strong>由于线程之间存在竞态条件，可能会导致线程在被唤醒时无法正常处理需求</strong>。</p><p>假设存在三个线程 A、B、C。其中，A、B 负责处理队列中的元素，而线程 C 负责向队列中生产元素。首先，A 线程获取元素，队列变为空；接下来，由于无元素可处理，B 线程进入阻塞状态。此时，C 线程生产了一个元素，放入队列，并唤醒一个阻塞线程（这里即 B 线程）。而当 B 线程正准备去处理这个元素时，该元素可能已经被 A 线程处理完毕。因此，让 B 线程在真正开始处理元素前，首先对条件进行重新检测便十分有必要了。</p><p>对于上述这三种情况，我们一般称其为线程的“虚假唤醒（Spurious Weakup）”。而通过使用 while 语句代替 if 语句，来在线程被唤醒时优先对条件进行重复检测，便可解决这个问题。如果想了解更多信息，你可以参考<a href=\"https://wiki.sei.cmu.edu/confluence/display/c/CON36-C.+Wrap+functions+that+can+spuriously+wake+up+in+a+loop\">这个链接</a>。</p><h2><strong>问题二</strong></h2><p>在 <a href=\"https://time.geekbang.org/column/article/481903\">18 讲</a> 中，我为你留了一个小作业，希望你去尝试了解一下什么是高速缓存的“抖动”。这里我来具体解释一下。</p><p><strong>因为程序设计正好与运行所在平台的高速缓存策略（包括物理特性）产生冲突，导致同一个高速缓存块被反复加载和驱逐</strong>，这个过程就是“高速缓存抖动（Thrashing）”。在这种情况下，每一次加载到高速缓存中的数据都没有被程序充分利用，因此，程序的整体运行效率会有明显的下降。</p><p>我们可以通过 CSAPP 中的一段代码来理解缓存抖动的发生过程。这段代码如下所示：</p><pre><code class=\"language-c++\">float foo(float x[8], float y[8]) {\n&nbsp; float sum = 0.0;\n&nbsp; int i;\n&nbsp; for (i = 0; i &lt; 8; i++)\n&nbsp; &nbsp; sum += x[i] * y[i];\n&nbsp; return sum;\n}\n</code></pre><p>假设一台计算机拥有两个高速缓存行，每个缓存行大小为 16 字节，且它们被分别组织在不同的两个组中。对于这样的缓存行分组方式，我们一般称其为“直接映射高速缓存”。在这种情况下，上述代码在每一次交替访问数组 x 与 y 中的元素时，便可能会产生高速缓存抖动的问题。</p><p>在直接映射高速缓存中，数据在缓存中的存储位置是与它在内存中的地址一一映射的。在上面这个例子中，我们将所使用数据地址的最后 4 位作为“块偏移”的索引，用于指定所需数据在某个缓存行中的偏移位置（以“字节”为单位）；而地址的倒数第 5 位将用于选择不同的组。假设数组 x 与 y 在内存中被连续存放，<code>float</code> 类型为 4 字节大小，且 x 的起始地址从 0 开始。那么，我们可以得到如下表所示的数据与高速缓存行映射关系：</p><p><img src=\"https://static001.geekbang.org/resource/image/5b/e2/5b2fd8ffa1c16c6e96ab53cae1e465e2.jpg?wh=2284x1225\" alt=\"\"></p><p>可以看到，数组 x 与 y 中相同索引位置上的元素会被缓存到同一个缓存行中（同一个组）。因此，当交替访问它们时，高速缓存中的数据便会被不断地加载和驱逐，缓存并没有得到有效利用。</p><p>当然，对于上面这个例子，我们可以简单地通过将 x 定义为包含有 12 个元素的数组（额外填充 16 字节，即对应一个缓存行大小），来将两个数组相同索引位置上的元素“拆分”到不同的缓存行中。但总的来看，缓存抖动在采用了“直接映射高速缓存”的体系中较为常见，而在采用“全相联高速缓存”及其他缓存策略的体系中较少发生。因此，一般来说，我们并不需要对代码进行任何处理来预防这类问题。但当程序性能真正出现问题时，你可以将“高速缓存抖动”这个原因考虑进去。</p><h2><strong>问题三</strong></h2><p>在<a href=\"https://time.geekbang.org/column/article/482493\"> 19 讲</a> 的思考题中，我提到了一个名为“达夫设备”的概念。那么它有什么作用？它的实现原理是怎样的呢？</p><p>达夫设备（Duff’s Device）是 C 语言发展历史中出现的一个<strong>利用手动循环展开进行性能优化</strong>的知名实践案例，它由 Tom Duff 于 1983 年发现。</p><p>相较于我在 <a href=\"https://time.geekbang.org/column/article/482493\">19 讲</a>中介绍的循环展开方式，达夫设备通过结合使用 switch 语句与 do-while 语句，使得循环的“余数次项”可以不用单独进行处理。它的原始形式主要用于将 16 位的无符号整数从一个数组中复制到 MMIO 寄存器。而经过改写，我们可以得到以下更“普适”的版本。这个版本的代码可用于将指定内存段上的数据复制到另一个内存段中：</p><pre><code class=\"language-c++\">#include &lt;stdio.h&gt;\nvoid send(int* from, int* to, int count) {\n  int n = (count + 7) / 8;\n  switch (count % 8) {\n    case 0: do { *to++ = *from++;\n&nbsp; &nbsp; case 7:&nbsp; &nbsp; &nbsp; *to++ = *from++;\n&nbsp; &nbsp; case 6:&nbsp; &nbsp; &nbsp; *to++ = *from++;\n&nbsp; &nbsp; case 5:&nbsp; &nbsp; &nbsp; *to++ = *from++;\n&nbsp; &nbsp; case 4:&nbsp; &nbsp; &nbsp; *to++ = *from++;\n&nbsp; &nbsp; case 3:&nbsp; &nbsp; &nbsp; *to++ = *from++;\n&nbsp; &nbsp; case 2:&nbsp; &nbsp; &nbsp; *to++ = *from++;\n&nbsp; &nbsp; case 1:&nbsp; &nbsp; &nbsp; *to++ = *from++;\n&nbsp;               } while (--n &gt; 0);\n  }\n}\nint main(void) {\n&nbsp; int x[] = { 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 };\n&nbsp; int y[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };\n&nbsp; send(x, y, 10);\n&nbsp; for (int i = 0; i &lt; 10; i++) {\n&nbsp; &nbsp; printf(\"%d\", y[i]);\n&nbsp; }\n}\n</code></pre><p>可以看到，达夫设备的实现代码并不是正常程序员会写出来的（笑）。它利用了 case 分支的 “fall-through”，即可以连续执行的特性，使得 switch-case 与 do-while 语句可以像上述这样被结合起来使用。</p><p>这里程序在执行时，switch 语句会首先根据总迭代次数在当前循环展开形式下（这里即 8x1）的“余数次项”，跳转到对应分支（这里即 “case 2”）开始执行。而当程序按顺序执行完 “case 1” 对应的分支语句后，紧接着会对 while 语句的循环条件进行判断。这里，变量 n 用于控制 while 循环的执行次数。因此，若该值在递减后仍大于 0，则程序会重新从 “case 0” 语句，即 do…while 循环的起始处，开始新一轮的执行。</p><p>达夫设备采用的循环展开方式可以<strong>减少不直接有助于程序结果的操作数量</strong>，如循环索引计算与条件分支，因此可以在一定程度上提升性能。</p><p>但需要注意的是，通常来说，编译器在高优化等级下会自动对符合条件的代码采用循环展开。并且，从可读性、稳定性，甚至执行性能等角度考虑，上述用来进行数组元素拷贝的达夫设备代码，也并不如 C 标准库提供的 memcpy 函数来得有效。</p><p>好了，以上就是我对这门课第三个模块中，同学们讨论比较多的三个课后思考题的回答。如果你还有其他问题，欢迎在评论区与我讨论。</p>","neighbors":{"left":{"article_title":"课堂答疑（一）｜前置篇、C 核心语法实现篇问题集锦","id":474252},"right":{"article_title":"大咖助阵｜LMOS：为什么说 C 语言是一把瑞士军刀？","id":470130}}},{"article_id":470130,"article_title":"大咖助阵｜LMOS：为什么说 C 语言是一把瑞士军刀？","article_content":"<p>你好，我是LMOS。</p><p>很高兴受邀来到这个专栏做一期分享。也许这门课的一些同学对我很熟悉，我是极客时间上<a href=\"https://time.geekbang.org/column/intro/100078401?tab=catalog\">《操作系统实战45讲》</a>这门课的作者，同时也是LMOS、LMOSEM这两套操作系统的独立开发者。十几年来，我一直专注于操作系统内核研发，在C语言的使用方面有比较深刻的理解，所以想在这里把我的经验、见解分享给你。</p><p>操作系统和C语言的起源有着千丝万缕的联系，那么今天，我就先从C语言的起源和发展历史讲起。然后，我会从C语言自身的语法特性出发，向你展示这门古老的语言简单在哪里，又难在哪里。</p><h2><strong>C语言、<strong>UNIX的</strong>起源和发展</strong></h2><p>从英国的剑桥大学到美国的贝尔实验室，C语言走过了一段不平凡的旅程。从最开始的CPL语言到BCPL语言，再到B语言，到最终的C语言，一共经历了四次改进。从20世纪中叶到21世纪初，C语言以它的灵活、高效、通用、抽象、可移植的特性，在计算机界占据了不可撼动的地位。但是，C语言是如何产生的？诞生几十年来，它的地位为何一直不可动摇？请往下看。</p><h3>C语言是两位牛人“玩”出来的</h3><p>1969年夏天，美国贝尔实验室的肯·汤普森的妻子回了娘家，这位理工男终于有了自己的时间。于是，他以BCPL语言为基础，设计出了简单且接近于机器语言的B语言（取BCPL的首字母）。然后，他又用B语言写出了UNICS操作系统，这就是后来风靡全世界的UNIX操作系统的初级版本。</p><!-- [[[read_end]]] --><p>那么，肯·汤普森为什么要写这个操作系统呢？背后的原因是我们这些凡人想象不到的：为了玩一个叫“Space Travel”的游戏。牛人就是牛人，这个“玩出来”的操作系统成功到让人无法想象。</p><p>而肯·汤普森一位同样是牛人的朋友，也疯狂地热爱这款游戏，这个朋友就是C语言之父（请注意不是谭浩强老师），丹尼斯·里奇。他为了能早点儿玩上游戏，加入了汤普森的疯狂项目，一起开发UNIX。他的主要工作是改造B语言，使其更加成熟。1972年，丹尼斯·里奇在B语言的基础上设计出了一种新的语言，他取了BCPL的第二个字母作为这种语言的名字，这就是C语言。C语言实现之后，汤普森和里奇用它重写了UNIX。</p><h3>C语言和UNIX操作系统</h3><p>听到这儿，你应该可以理解，C语言和UNIX操作系统从诞生时就密切相关。那么，C语言对UNIX操作系统的发展具体有什么影响呢？我们先从C语言出现之前说起。</p><p>在C语言出现之前，UNIX操作系统的初级版本是用汇编语言编写的。用机器语言或者汇编语言开发的程序，是不可能在诸如X86、Alpha、SPARC、PPC和ARM等机器上任意运行的，想要运行就得重写所有代码。<strong>而用C语言编写的程序，则可以在任意架构的处理器上运行。</strong>只需要有那种架构的处理器对应的C语言编译器和库，然后将C源代码编译、链接成目标二进制文件，之后即可在该架构的处理器上运行。</p><p>正是C语言的这种高性能和强大的可移植性，促进了UNIX生态的发展。UNIX诞生后的40年间，出现的各种操作系统都是和UNIX有关系的，或者受其影响。甚至直到2021年，各种版本的UNIX内核和周边工具仍然使用C语言作为最主要的开发语言。</p><p>你可以看下这个UNIX家谱图（来自<a href=\"https://zh.wiki.hancel.org/wiki/UNIX\">维基百科</a>），更直观地感受UNIX的发展史：</p><p><img src=\"https://static001.geekbang.org/resource/image/89/53/89b00acd948yyab250dcdc8964353d53.gif?wh=1123x714\" alt=\"图片\"></p><p>看到这个庞大的家谱图，不知道你是否吃惊不已？但是我想说的是，这些操作系统内核都是使用C语言开发的，无一例外。甚至可以说，C语言就是开发操作系统的专用语言。也正因如此，C语言成了计算机史上的一颗明珠，一座灯塔，永远闪耀在计算机历史的长河之上。</p><h2>用一个程序体会C语言的简单性</h2><p>从对C语言起源的介绍中，你可以了解到，C语言最开始是被设计用来开发UNIX的，而这造就了它自身的语言特性：</p><ul>\n<li>要预知程序的运行流程和结果，就需要简单的类型系统和静态编译；</li>\n<li>需要用C语言开发底层核心代码，要求C语言能灵活地操控内存和寄存器。</li>\n<li>需要C语言是可以移植的，所以需要提供结构体、函数等抽象的编程机制。</li>\n</ul><p><strong>正是这些需求，导致了C语言的高效、简单、灵活和可移植性。</strong>所以，很多人说C语言是一种非常简单的语言。</p><p>我写了一个经典的C语言程序，Hello World ，你可以从中体会C语言的简单性。代码如下所示：</p><pre><code class=\"language-c++\">#include \"stdio.h\"\n// 定义申明两个全局变量：hellostr、global，类型分别是：char*、int；\nchar* hellostr = \"HelloWorld\";\nint global = 5;\n// 定义一个结构体类型 HW；\nstruct HW {\n  char* str;\n  int sum;\n  long indx;\n};\n// 函数；\nvoid show(struct HW* hw, long x) {\n  printf(\"%d %d %s\\n\", global, x, hellostr);\n  printf(\"%d %d %s\\n\", hw-&gt;sum, hw-&gt;indx, hw-&gt;str);\n}\n// 函数；\nint main(int argc, char const *argv[]) {\n  // 定义三个局部变量：x、parm、ishw，类型分别是：int、log、struct HW;\n  int x;\n  long parm = 10;\n  struct HW ishw;\n  // 变量赋值;\n  ishw.str = hellostr;\n  ishw.sum = global;\n  ishw.indx = parm;\n  // 调用函数;\n  show(&amp;ishw, parm);\n  return x;\n}\n</code></pre><p>这个短短的代码，就几乎包含了C语言90%的特性，有函数，有变量。其中，变量包括局部变量和全局变量；变量还有类型，用于存放各种类型的数据；还有一种特殊的变量即指针，指针也有类型，用于存放其它变量的地址。</p><p>总之一句话，<strong>C语言就是函数+变量</strong>。函数表示算法操作，变量存放数据，即数据结构，合起来就是程序=算法+数据结构。</p><h2><strong>C语言难在哪里？</strong></h2><p>你可以看到，从语言特性上来看，C语言极其简单。但是，很多程序员却说，C语言用起来无比困难，这又是为什么呢？</p><p>其实你可以这么理解：<strong>C语言就像一把锋利的瑞士军刀</strong>，使用起来非常简单，并不像飞机坦克一样难于驾驭；但同时，它对使用者的技巧要求极高，使用时稍有不慎，就会伤及自身。C语言可操控寄存器和内存的特性，对初级软件开发者极其不友好，很容易导致软件bug，而且bug查找起来非常困难。</p><h3><strong>通过汇编代码看C语言的本质</strong></h3><p>而C语言使用的困难之处，就要从C语言的本质说起了。</p><p>我们知道，C语言的代码是不能直接执行的，需要通过C编译器编译。C编译器首先将C代码编译成汇编代码，然后再通过汇编器编译成二进制机器代码。这刚好给了我们一个通过观察汇编代码了解C语言本质的机会。接下来，我们就按三个步骤观察下。</p><p>第一步，观察C语言如何处理全局变量。代码如下：</p><pre><code class=\"language-plain\">.globl hellostr  \t\n.section .rodata\n.LC0:\n\t.string\t\"HelloWorld\"  // 字符变量放在可执行文件的 rodata 段；\n\t.data\n\t.align 8\n\t.type hellostr, @object\n\t.size hellostr, 8\nhellostr:  // 字符指针变量放在可执行文件的 data 段；\n\t.quad .LC0\n\t.globl global\n\t.align 4\n\t.type global, @object\n\t.size global, 4\nglobal:\n\t.long 5  // long 型变量放在可执行文件的 rodata 段；\n\t.section .rodata\n</code></pre><p>我们看到，C语言对全局变量的处理是放在可执行文件的某个段中的，这些段会被操作系统的程序加载器映射到进程相应的地址空间中，代码通过地址就能访问到它们了。</p><p>第二步，观察C语言如何处理局部变量。代码如下：</p><pre><code class=\"language-plain\">main:\n.LFB1:\n\t.cfi_startproc\n\tpushq %rbp\n\t.cfi_def_cfa_offset 16\n\t.cfi_offset 6, -16\n\tmovq %rsp, %rbp\n\t.cfi_def_cfa_register 6\n\tsubq $64, %rsp  // 在栈中分配局部变量的内存空间；\n    // 保存 main 的两个参数；\n\tmovl %edi, -52(%rbp)\n\tmovq %rsi, -64(%rbp)\n    // long parm = 10;\n\tmovq $10, -8(%rbp)\n\tmovq hellostr(%rip), %rax\n    // ishw.str = hellostr;\n\tmovq %rax, -48(%rbp)\n\tmovl global(%rip), %eax\n    // ishw.sum = global;\n\tmovl %eax, -40(%rbp)\n\tmovq -8(%rbp), %rax\n    // ishw.indx = parm;\n\tmovq %rax, -32(%rbp)\n    // 处理给 show 函数传递的参数；\n\tmovq -8(%rbp), %rdx\n\tleaq -48(%rbp), %rax\n\tmovq %rdx, %rsi\n\tmovq %rax, %rdi\n    // 调用 show 函数；\n\tcall show\n\tmovl -12(%rbp), %eax\n\tleave\n\t.cfi_def_cfa 7, 8\n    // 返回；\n\tret\n\t.cfi_endproc\n</code></pre><p>由上可知，C语言把局部变量放在栈中。栈也是一块内存空间，数据从栈顶压入，也从栈顶弹出。所以栈的特性是先进后出，栈顶由RSP寄存器指向，因此RSP也被称为栈指针寄存器。上面的代码对RSP减去64，就是在栈中分配局部变量的空间。</p><p>还有call指令也要用到栈，以上述代码为例：它是把第31行的 <code>movl\t-12(%rbp), %eax</code> 的地址压入栈顶，然后跳转show函数的地址，开始运行代码。而在show函数的最后，有一条ret指令，从栈顶弹出返回地址（ <code>movl -12(%rbp), %eax</code> 的地址）到RIP（程序指针寄存器），使得程序流程回到main函数中继续执行。这样，就完成了函数调用。</p><p>第三步，观察C语言如何处理函数。代码如下：</p><pre><code class=\"language-plain\">show:\n.LFB0:\n\t.cfi_startproc\n\tpushq %rbp\n\t.cfi_def_cfa_offset 16\n\t.cfi_offset 6, -16\n\tmovq %rsp, %rbp\n\t.cfi_def_cfa_register 6\n    // 在栈中分配局部变量空间；\n\tsubq $16, %rsp\n    // 把 hw 和 x 两个参数变量放在栈空间中；\n\tmovq %rdi, -8(%rbp)\n\tmovq %rsi, -16(%rbp)\n    // 处理 printf 函数的参数；\n\tmovq hellostr(%rip), %rcx\n\tmovl global(%rip), %eax\n\tmovq -16(%rbp), %rdx\n\tmovl %eax, %esi\n\tmovl $.LC1, %edi\n\tmovl $0, %eax\n    // 调用 printf 函数；\n\tcall printf\n\tmovq -8(%rbp), %rax\n\tmovq (%rax), %rcx\n    // -8(%rbp) 指向的内存中放的 hw 指针；\n\tmovq -8(%rbp), %rax\n    // 16(%rax) 指向的内存中放的 hw-&gt;indx；\n\tmovq 16(%rax), %rdx\n\tmovq -8(%rbp), %rax\n    // 8(%rax) 指向的内存中放的 hw-&gt;sum；\n\tmovl 8(%rax), %eax\n\tmovl %eax, %esi\n    // $.LC1 指向的内存中放的 \"HelloWorld\"，即 hw-&gt;str；\n\tmovl $.LC1, %edi\n\tmovl $0, %eax\n    // 调用 printf 函数；\n\tcall printf\n\tnop\n\tleave\n\t.cfi_def_cfa 7, 8\n\tret\n</code></pre><p>上面的代码清楚地展示了C语言编译器是如何编译一个C语言函数，如何处理函数参数的。你可以发现，C语言编译出来的代码和你手写的汇编代码相差无几，有时甚至还要更高效。</p><p>因为汇编代码和机器指令直接对应，所以我们通过汇编代码，可以非常直观地观察到C语言编译器编译C代码的结果，清楚地看到一行C代码编译成的机器指令。在这个过程中，我们就可以清楚地知道C语言的变量、指针、函数的实现机制是什么，从而达到了解C语言本质的目的。</p><h3>C语言指针带来的陷阱</h3><p>在上面用汇编代码观察C语言的时候，我们看到了C语言是如何处理指针变量的。而这就是C语言的灵活之处，也是其难点。<strong>C语言的指针导致C语言程序员可以毫无节制地操控内存，这个特性赋予了C语言强大、灵活的特点，同时也带来了陷阱。</strong>下面我们用几个例子看看，具体有哪些陷阱。</p><p><strong>陷阱一：未初始化的指针</strong></p><p>指针变量中存放的是地址数据，未初始化即为地址数据不明，指向何处也就不清楚。如果你指向了一个关键内存地址，对其进行读写，就会破坏其中的重要数据，从而导致代码逻辑出现问题，而且这样的问题非常难于查找。</p><p>你可以观察下面的代码，思考它是不是有问题。</p><pre><code class=\"language-c++\">int main(int argc, char const *argv[]) {\n  int* p;\n  int k = *p;\n  for (int i = k; i &gt; 100; i++) {\n    printf(\"hello world\\n\");\n  }\n  return 0;\n}\n</code></pre><p>这代码有问题吗？有，p没有初始化，所以p的值是不确定的，可以指向任意地址。而这个地址中的数据也是不确定的，所以问题来了：i可能大于100，也可能小于100，代码的行为是不确定的，所以出问题之后就极其难以查找。</p><p><strong>陷阱二：指针越界</strong></p><p>我们经常用指针操作一块连续的内存，比如数组。这样的情况下，如果代码逻辑出现问题，很容易导致指针越界，超出指针指向这块内存的边界，从而改写不该操作的内存中的数据。</p><p>我们还是来看一个具体的代码：</p><pre><code class=\"language-c++\">char str[5] = { 0 };\nvoid stringcopy(char* dest, char* src) {\n  for(; *src != 0; dest++, src++) {\n    *dest = *src;\n  }\n  return;\n}\nint main(int argc, char const *argv[]) {\n  stringcopy(str, \"helloworld\");\n  return 0;\n}\n</code></pre><p>从上述代码可以看出，str只能存放5个字符，而helloworld是10个字符。而stringcopy函数的实现是把两个参数作为指针使用，所以这个代码一定会导致指针越界。如果 str[5]后面存放了关键数据，这个关键数据一定会被破坏，从而导致未知bug，并且这样的bug很难查找。</p><p><strong>陷阱三：栈破坏</strong></p><p>指针可以指向任意的内存，栈也是内存，因此用指针很容易操作栈中的内容。而栈中保存着函数的返回地址和局部变量，其中重要的函数返回地址，经常被黑客作为攻击点。他们通过改写返回地址，使函数返回到自己写好的函数上。下面来看看黑客们是如何操作的。</p><p>来看下面的代码，它展示了黑客们攻击时利用的“陷阱”。你可以先试想下这段代码的运行结果。</p><pre><code class=\"language-c++\">void test() {\n  printf(\"test\");\n  return;\n}\nvoid stackret(long* l) {\n *l-- = (long)test;\n *l-- = (long)test;\n *l-- = (long)test;\n *l-- = (long)test;\n *l-- = (long)test;\n  return;\n}\nint main(void) {\n  int* p;\n  long x = 0;\n  stackret(&amp;x);\n  return 0;\n}\n</code></pre><p>你一定想不到程序会输出“test”，可是我们明明没有调用test函数，这是为什么呢？</p><p>我们在stackret函数中不小心修改了栈中的内容，用test地址覆盖了返回地址。因为x变量在栈分配内存，我们传给stackret函数的就是x的地址，自然就可以修改栈中的内容。这个特性经常被木马程序所利用。</p><p>上面，我从三个方面向你展现了指针可能带来的危险。总之，C语言的指针给开发人员带来了内存的完全可控性，但是也给程序开发带来了困难，稍有不慎，就会坠入万劫不复的深渊。所以在使用指针时要非常小心。</p><h2>重点回顾</h2><p>今天的分享就到这里了，最后我来给你总结一下。</p><ol>\n<li>首先我带你回顾了C语言的起源，以及它和UNIX操作系统的密切联系。C 语言是牛人们“玩”出来的，而 C 语言和UNIX在发展过程中互相成就了对方。</li>\n<li>C语言最开始是被设计用来开发UNIX的，这导致了C语言的高效、简单、灵活和可移植性。我们用一个代码实例了解了C语言的简单性。</li>\n<li>我们通过观察汇编代码，了解了C语言的本质，进而理解了C语言指针可能带来的陷阱。</li>\n</ol><p>关于C语言，我想和你聊的还远不止这些。在“LMOS说C语言”的下篇，我会和你分享C语言在工程项目中的应用方式，以及如何用C语言来实现面向对象的编程方法，我们到时候见！</p>","neighbors":{"left":{"article_title":"课堂答疑（二）｜C 工程实战篇问题集锦","id":488595},"right":{"article_title":"大咖助阵｜LMOS：用面向对象的思想开发 C 语言程序","id":474870}}},{"article_id":474870,"article_title":"大咖助阵｜LMOS：用面向对象的思想开发 C 语言程序","article_content":"<p>你好，我是LMOS。</p><p>在“ LMOS 说 C 语言”的上篇里，我向你分享了C语言的起源，它与UNIX操作系统的联系，以及与C语言简单和困难相关的语言特性。今天我想和你聊聊，既然C语言是一把锋利但考验使用者技巧的瑞士军刀，我们可以拿它做什么，又怎么才能把它用好。</p><h2><strong>C</strong> <strong>语言能干什么？</strong></h2><p>对于“C语言能干什么”这个问题，我的回答是：C语言能干一切其他语言能干的事。</p><p>C语言自身的特性使得它能完全操作计算机所有的资源，因此它<strong>生来就是开发操作系统等底层核心软件的</strong>。不仅仅是开发操作系统，还有一些数据库和一些其他高级编程语言的编译器、解析器等。C语言简单的语法，被C++、Java、Go、JS 等语言效仿。其实从C语言的语言特性就可以看出来，它属于高级语言中的低级语言，又是低级语言中的高级语言，能适应一切底层开发。</p><p>然而，C语言既然能做一切底层开发，就一定能做一切上层开发，只是对开发者的能力要求远高于Java、Go这些高级语言。其实，所有的高级语言都有共同的目标，就是降低开发者的学习使用成本和心智负担，从而降低软件的开发和维护成本。比如，Java用虚拟机实现了一次编译处处运行，用垃圾内存回收机制解决了程序员使用内存的困难，不用时刻担心内存没有释放。这些归根结底是为了降低软件开发成本。</p><!-- [[[read_end]]] --><p>对于“C语言能干一切其他语言能干的事”这句话，你可能还有这样的疑问：C语言是一门面向过程的编程语言，而在工程应用中，我们多使用面向对象的编程方式。用C语言来做现代大型软件项目，是不是不太现实？</p><p>确实，由于C语言函数之间的强耦合和内存的低级控制特性，在用它开发大型工程项目时，如果不设计好架构和相关的编码规则，将会给项目的开发、协同和后期维护带来很多困难。但是，C语言是一门面向过程的编程语言，并不意味着我们不能用它来实现面向对象的编程方式。接下来，我就具体讲讲，怎么用面向对象的思想开发C语言程序。</p><h2>面向过程和面向对象的两种思想</h2><p>我先带你回顾下面向过程和面向对象这两种思想，以及一些容易混淆的相关概念。</p><p>对于计算过程的不同认识，产生了不同的计算模型。基于计算模型进行分类，我们可以将语言分为命令式、函数式、面向过程、面向对象四大类。如果从程序的本质上来看，可以进一步归纳为两种：命令式语言和说明式语言。</p><p>面向过程是命令式语言的主要实现手段，而面向对象是当前应用编程领域中最常用的语言类型。但是，无论从语言定义还是数据抽象发展来看，面向对象都是面向过程的衍生。</p><p>命令式这个词太过于学术化了，其实我们常见的编程语言，从汇编到 C 再到C++、 Java，都是命令式语言。命令式语言在很大程度上受到了“冯·诺依曼”计算体系的影响。这个体系又以“存储”和“处理”为核心，其中存储被抽象为<strong>内存</strong>，处理被抽象为<strong>运算指令和语句</strong>。于是，命令式的核心就是<strong>通过运算去改变内存（数据）</strong>。</p><p>听到这里，你应该能把这些概念的关系理清楚了：面向过程/面向对象这些概念，和命令式并不在同一个维度上。前者是运算类型，表现为语言；后者着重表达的则是程序设计和开发的方法。</p><p>C语言和C++都是命令式语言，不过C语言是面向过程的语言，C++是面向对象的语言，那么面向过程和面向对象有什么区别呢？其实它们大同小异，只不过是“思考问题的方式”不同。为了方便你理解，这里我用“吃饭”来类比。</p><p>过程是对每个功能或者动作的精确实现。用“吃饭”来举例子：吃饭这个“功能”，包含怎么吃，吃多少。小猫能吃饭，人也能吃饭，但二者吃饭的“过程”肯定有区别。这个逻辑可以用下面的代码来描述：</p><pre><code class=\"language-c++\">void cateat(cat* v) {\n  // 吃饭；\n  return;\n}\nvoid peopleeat(people* v) {\n  // 吃饭；\n  return;\n}\nint main(int argc, char const *argv[]) {\n  cateat(cat);\n  peopleeat(people);\n  return 0;\n}\n</code></pre><p>至于“面向对象”里的“对象”，可以这么理解：猫和人分别是两个对象，这两个对象都包含吃饭这个动作。对于人，会调用人的吃饭动作的函数；而对于猫，则会调用属于猫的吃饭动作。代码如下：</p><pre><code class=\"language-c++\">class Cat {  // 对象猫；\n public: \n  void eat();\n};\nvoid Cat::eat(void) {\n  // 猫吃饭；\n  return;\n}\nclass People {  // 对象人；\n public: \n  void eat();\n};\nvoid People::eat(void) {\n  // 人吃饭；\n  return;\n}\nint main(int argc, char const *argv[]) {\n  Cat c;\n  People p;\n  c.eat(); // 调用猫对象的吃饭动作；\n  p.eat(); // 调用人对象的吃饭动作；\n  return 0;\n}\n</code></pre><p>我们可以看到，面向过程和面向对象的思考方式截然不同。面向过程，是对每个不同动物的吃饭过程进行精确描述。而面向对象的思考方式却不同：认为猫和人是两个不同的对象，都有吃饭的动作，各自对吃饭这个动作进行封装和实现。最后，用对象自己调用自己的方法，完成相应的吃饭动作。</p><p>但仔细思考一下，猫和人其实都属于哺乳动物，哺乳动物间还是有一些共性的。那么，如何表示这种父子范畴关系呢？答案就是<strong>在封装的基础上进行继承操作</strong>。</p><p>这是因为，如果仅仅是把属性和方法封装成对象，这个意义还不是很大。封装是为了继承，继承是为了解耦和复用。当然，随着工程复杂度的发展，人们发现传统的单/多继承又会带来额外的复杂度，于是就又有了组合优于继承的思想，这里就不展开了。接下来让我们看看，怎么用 C 语言来实现封装和继承这两种面向对象编程的特性。</p><h2><strong>基于</strong> <strong>C</strong> <strong>语言的面向对象编程</strong></h2><p>首先，请一定要记住：面向对象是一种编程思想，并非特定语言（如C++、Java）实现的功能。C++、Java这些语言只是用语言的文法对这种思想进行规约，达到方便或者强制编程人员用面向对象的思想实现自己的代码逻辑的目的。</p><p>所以，我们不仅能用C++、Java这些“面向对象的编程语言”实现面向对象编程，用C或者汇编也可以实现，只是后者没有提供类似C++、Java中，可用于实现面向对象的语法糖而已。下面，我们就一起用 C 来实现面向对象的编程方法。</p><h3><strong>封装</strong></h3><p>我们首先用C语言来实现封装。封装是面向对象中最基础的思想，即把一些属性和方法组织在一起，形成一个对象。</p><p>接下来，我会用我的课程<a href=\"https://time.geekbang.org/column/intro/100078401?tab=catalog\">《操作系统实战45讲》</a>中的Cosmos的锁实现为实例，剖析用C语言来实现封装的方法。在操作系统中，用锁的模块很多，进程模块要用锁，内存模块也要用锁，它们对锁的要求也有不同。现在我们来封装最基本的锁，代码如下：</p><pre><code class=\"language-c++\">typedef struct SPINLOCK {\n  volatile U32 Lock; // int 类型，0 表示解锁，1 表示加锁；\n} SpinLock;\n// 加锁；\nvoid HalSpinLock(SpinLock *lock) {\n  __asm__ __volatile__(\n    \"1：lock; xchg %0, %1\\n\"\n    \"cmpl $0, %0\\n\"\n    \"jnz 2f\\n\"\n    \".section .spinlock.text,\"\"\\\"ax\\\"\"\n    \"2：cmpl $0, %1\\n\"\n    \"jne 2b\\n\"\n    \"jmp 1b\\n\"\n    \".previous\\n\"\n    :: \"r\"(1), \"m\"(*lock));\n  return;\n}\n// 解锁；\nvoid HalUnSpinLock(SpinLock *lock) {\n  __asm__ __volatile__(\n    \"movl   $0, %0\\n\"\n    :: \"m\"(*lock));\n  return;\n}\n</code></pre><p>上面的代码中，我们定义了一个SpinLock数据结构，并且围绕这个结构写好了两个函数，一个加锁，一个解锁。其中，代码是用嵌入汇编实现的，这里我们不用管它们的实现，只需明白它们能加锁和解锁就行了。</p><p>不过，仅仅是这样还体现不出封装的意义，我们继续修改代码：</p><pre><code class=\"language-c++\">typedef struct MLOCK {\n  SpinLock Locks;  // 锁；\n  UInt Count;  // 计数器；\n  void (*MLocked)(MLock* Lock);  // 加锁函数指针；\n  void (*MUnLock)(MLock* Lock);  // 解锁函数指针；\n} MLock; \n// 初始化；\nvoid MLockInit(MLock* init) {\n  SpinLockInit(&amp;init-&gt;Locks);\n  init-&gt;Count = 0;\n  init-&gt;MLocked = KrlMmLocked;\n  init-&gt;MUnLock = KrlMmUnLock;\n  return;\n}\n// 加锁；\nvoid KrlMmLocked(MLock* lock) {\n  HalSpinLock(&amp;lock-&gt;Locks);  // 调用基类加锁函数；\n  lock-&gt;Count++;\n  return;\n}\n// 解锁；\nvoid KrlMmUnLock(MLock* lock) {\n  HalUnSpinLock(&amp;lock-&gt;Locks);  // 调用基类解锁函数；\n  lock-&gt;Count--;\n  return;\n}\nMLock Lock;  // 定义一个 Lock 对象；\nMLockInit(&amp;Lock);  // 初始化对象；\nLock.MLocked(&amp;Lock);  // 调用对象方法；\nLock.MUnLock(&amp;Lock);\n</code></pre><p>上述代码中，MLock结构中的SpinLock相当于基类，并且扩展封装了一个计数器和两个成员方法，形成了新的MLock锁。</p><p>MLock锁封装了底层锁的实现机制，使用者不用考虑底层实现，在任何需要使用MLock的地方，只要定义一个MLock类型的对象，并对其初始化，需要的时候调用其中对应的方法就行了。你看，是不是有点C++的味道了？只是C++用语法糖包装了这些实现细节，而C语言的语法上没有 <code>new</code> ，没有 <code>class</code> ，也没有构造函数。但是C语言有 <code>struct</code> ，有函数指针，可以自己写初始化函数。</p><h3><strong>继承</strong></h3><p>在面向对象的编程思想中，把属性和方法封装成一个个对象是为了继承。若非如此，就失去了封装对象的意义。上面的MLock只是封装加上简单的继承，下面我们来看看复杂点的继承。</p><p>在操作系统中，内存管理需要很多数据结构（如果你想深入了解这些，可以看看我在极客时间的课程<a href=\"https://time.geekbang.org/column/intro/100078401?tab=catalog\">《操作系统实战45讲》</a>），内存管理的各种数据结构都需要锁来避免程序并发运行带来的破坏性结果。下面，我用其中几个结构作为实例，示范一下“继承”这个概念。</p><p>先来看这段代码：</p><pre><code class=\"language-c++\">// 物理地址块头链；\ntypedef struct PABHLIST {\n  MLock Lock;  // 锁对象；\n  U32  Status;\n  UInt Order;\n  UInt InOrderPmsadNR;\n  UInt FreePmsadNR;\n  UInt PmsadNR;\n  UInt AllocCount;\n  UInt FreeCount;\n  List FreeLists;\n  List AllocLists;\n  List OveLists;\n} PABHList;\n// 内存拆分合并结构；\ntypedef struct MSPLITMER {\n  MLock Lock;  // 锁对象；\n  U32  Status;\n  UInt MaxSMNR;\n  UInt PhySMNR;\n  UInt PreSMNR;\n  UInt SPlitNR;\n  UInt MerNR;\n  PABHList PAddrBlockArr[MSPLMER_ARR_LMAX];\n  PABHList OnePAddrBlock;\n} MSPlitMer;\n// 内存节点；\ntypedef struct MNode {\n  List Lists;\n  MLock Lock;  // 锁对象；\n  UInt Status;\n  UInt Flags;\n  UInt NodeID;\n  UInt CPUID;\n  Addr NodeMemAddrStart;\n  Addr NodeMemAddrEnd;\n  PHYMSPaceArea* PMSAreaPtr;\n  U64 PMSAreaNR;\n  U64 NodeMemSize;\n  Addr NodeMemResvAddrStart;\n  Addr NodeMemResvAddrEnd;\n  U64 NodeMemResvSize;\n  MArea MAreaArr[MEMAREA_MAX];\n  PMSADDireArr PMSADDir;\n} MNode;\n</code></pre><p>上面的三个数据结构，都需要用锁来保护其自身数据的完整体，避免并发访问带来的各种问题。要访问，先加锁，一旦加锁别人就无法访问了，这样就能保证数据是安全访问的，不会读取到状态不一致的数据。</p><p>你可能想问：难道我们要每种数据结构都写一套加锁、解锁的代码吗？当然不是。我们只需要在其他结构里包括这个MLock就行了，相当于继承MLock类。这样，我们就可以访问结构时先调用MLock中的加锁操作。例如：</p><pre><code class=\"language-c++\">MNode node;\nMnodeInit(&amp;node);\n\nnode.Lock.MLocked(&amp;node.Lock);\nnode.PMSAreaNR++;\nnode.Lock.MUnLock(&amp;node.Lock);\n</code></pre><p>从这段代码中我们看到，操作MNode中的数据，首先会调用MNode下的Lock中的加锁操作，然而这个Lock对象是继承于MLock类的。</p><p>由此我们可以发现，任何数据结构只要包含（继承）MLock类，就可以具有锁的功能了，而不用知道锁是如何实现的。并且，我们如果需要移植代码到不同的机器上，只用改动MLock中SpinLock的实现，就好了。这种高内聚，低耦合的状态，正是衡量软件工程设计是否优良的重要指标。</p><p>我们在工作中，不仅仅是要追求代码运行正常与否，更要在这个基础之上追求代码的可读性、可维护性、软件架构的优雅性。正如我们看到的这样，面向过程和面向对象是两种不同的编程设计思想。我们可以取其优势以用之，把这两种思想融会贯通，这样就能用面向过程的编程语言实现面向对象的编程方法。这就像剑法大成的独孤求败一样，已经不在乎用什么剑了。在他眼里，草木竹石均可为剑，以至于能达到更高的境界，“无剑胜有剑”。</p><h2>重点回顾</h2><p>今天的分享就到这里了，最后我来给你总结一下。</p><ol>\n<li>首先，我们了解了C语言能干什么：从操作系统到编译器，从数据库到应用软件，C语言都可以非常高效地实现它们。</li>\n<li>然后，我们对比了面向过程和面向对象这两种不同编程思想的“思考方式”。</li>\n<li>既然面向对象是一种编程思想，那么用 C 语言这种面向过程的编程语言也可以实现。最后，我们通过大量的实例，实现了面向对象的封装和继承特性。</li>\n</ol><h2>写在最后</h2><p>C语言是一把利剑，用好了威力无穷。如果想最大程度地发挥它的威力，我们还需要把它跟工程实践相结合，可以尝试用C语言开发一个工程，比如操作系统、数据库等。</p><p>今天我举的实例仅仅是一个数据结构，如果稍微扩展一下思维，你就会发现：一个C语言模块文件就是一个对象类，其中的数据结构和函数就是这个对象类的成员数据和成员方法。在<a href=\"https://time.geekbang.org/column/intro/100078401?tab=catalog\">《操作系统实战45讲》</a>这门课中，我带同学们实现了一个基于 x86 平台的 64 位多进程的操作系统——Cosmos。Cosmos中的CPU类、MMU类、List类、RBTree类、Atomic类、Queue类等，都是用C语言基于面向对象的思想实现的。总之，如果你想看到更多C语言在操作系统中应用的案例，我在这门课里等你。</p><p>感谢你看到这里，如果今天的内容让你有所收获，欢迎把它分享给你的朋友。</p>","neighbors":{"left":{"article_title":"大咖助阵｜LMOS：为什么说 C 语言是一把瑞士军刀？","id":470130},"right":{"article_title":"大咖助阵｜罗剑锋：为什么 NGINX 是 C 编程的经典范本？","id":476646}}},{"article_id":476646,"article_title":"大咖助阵｜罗剑锋：为什么 NGINX 是 C 编程的经典范本？","article_content":"<p>你好，我是罗剑锋，不过我更喜欢你称呼我的网名：Chrono。</p><p>很高兴受邀来到这个专栏做一期分享。先来简单地做个自我介绍：我是一个有差不多20年工作经验的编程“老兵”，出版过两本书《C++ 11/14高级编程》《Boost 程序库完全开发指南》，也在极客时间上写过专栏《透视 HTTP 协议》和《C++ 实战笔记》。</p><p>可以看到，我主要的研究方向是 C++。不过，因为 C++ 和 C “一脉相承”，而且我在大学的时候初学的编程语言就是 C，所以，C 语言对于我来说，也是一门有着深厚感情的语言。</p><p>最近这几年，我的研发重心逐渐转移到了 Linux 系统编程和 NGINX 深度定制上，而这两者都是用 C 语言实现的，所以 C 语言又重新占据了我不少的工作时间。相比 C++ 来说，C 更加简单纯粹，没有那么多复杂深奥的语法规范，写起来也就更加轻松自如一些。</p><p>有很多人在学习 C 语言的时候都有一种感慨：C 语言的语法、语义、库函数都很精悍干练，把这些东西全部弄懂并不需要花费太多力气。但想要再进一步，用它写出高效、实用的程序，这其中就有一道很大的“鸿沟”需要跨越，经常遇到的情况是面对一个问题不知道如何下手。</p><p><strong>我认为，要学好</strong> <strong>C</strong> <strong>编程，掌握基本的语言特性只是迈出了第一步。</strong>因为比起其他编程语言，C 更接近系统底层，所以还需要了解计算机原理、操作系统等知识，并且把它们在 C 语言里“打通”“融成一体”，这样才算是真正学会了 C 语言编程。</p><!-- [[[read_end]]] --><p>那么，学习 C 语言编程有没有什么好方法呢？</p><p>除了阅读经典著作和实际开发编码之外，我觉得还有一种很有效的方式：<strong>钻研优秀的开源项目。</strong>通过学习那些经过“千锤百炼”的一行行源码，践行鲁迅先生的“拿来主义”，把开源项目的精华部分转变为自己的知识储备。也就是那句老话：“他山之石，可以攻玉。”</p><p>所以，今天借着这个机会，我就来聊聊我个人认为的 C 语言编程的经典范本，NGINX，并向你展示用 NGINX 学习 C 语言编程的正确打开方式。</p><h2>什么是 NGINX？</h2><p>正式讲方法之前，我们需要先来了解一下什么是 NGINX。有后端开发、网络应用背景的同学应该都知道 NGINX，它是一个高性能、高稳定、功能齐备的 Web 服务器。</p><p>NGINX 具有运行效率高、资源占用低、支持海量并发、运维友好等特点，适应了互联网“爆炸式”发展的大潮。所以，自从2004年公开发布 0.1.0 版以来，NGINX 的市场占有率就一路攀升，当然，相应的就是竞争对手 Apache httpd、Microsoft IIS 份额的下跌。</p><p>到今年，也就是2021年的5月份，W3Techs 网站的统计数据表明，NGINX 不仅在前一千、前一百万，而且是在所有的网站中，使用率都超过了传统的 Apache，总计的站点数量超过了4亿个。这也就意味着，NGINX 取代了已经存在27年的 Apache httpd，正式成为全球最受欢迎的 Web 服务器。</p><p>然而，NGINX 的用途还远远不止于 Web 服务。由于它核心的框架机制非常灵活、易于扩展，在多年的发展过程中，官方团队和广大志愿者又为它添加了反向代理、负载均衡等能力。并且，由此进一步衍生出了内容缓存、API 网关、安全防护、协议适配等许许多多的额外特性。这让 NGINX 成长为了一个全能的网络服务器软件。</p><p>从上面的介绍中，我们可以看到，NGINX 经过了全球用户和各种实际场景的验证，获得了极大的成功，说它是世界顶级的开源项目之一也丝毫不为过。<strong>而它，正是用标准的</strong> <strong>ANSI C</strong> <strong>语言开发实现的。</strong></p><p>很自然地，我们会感到好奇：为什么仅仅使用最基本的 C 语言，NGINX 就能够编写出性能如此强劲、功能如此丰富的服务器应用呢？里面究竟有哪些奥秘呢？</p><p>如果你能挖掘出这些蕴含在 NGINX 源码之中的“奥秘”和“宝藏”，让它为己所用，无疑会很好地提升自己的C语言编程“功力”。这对于我们当前的具体工作，乃至今后的职场发展，都是非常有价值的。</p><h2>我们能从 NGINX 中学到什么？</h2><p>作为服务器领域里的“全能选手”，NGINX 源码里包含的内容非常丰富，上至配置文件的解析、各种协议的转换、限流限速、访问控制，下至端口监听、信号处理、多进程/多线程、epoll 调用，诸如此类，不一而足。可以说，在 Linux 环境里大部分的应用开发问题，都可以在 NGINX 里找到对应或者类似的解决方案。</p><p>而且，除了三个例外，这些功能全都是由 NGINX 从零开始编码实现的，具有高度的独立性。这三个例外的功能是数据压缩、正则表达式和加密解密，它们是由 NGINX 之外的开源项目 zlib、PCRE、OpenSSL 来完成的。而 zlib、PCRE、OpenSSL 这三个库，也是用 C 语言开发的久负盛誉的开源库，NGINX 是为了避免“重复造轮子”，这也情有可原。</p><p>由于 NGINX 里可研究的地方实在太多，下面我就挑出两个比较有代表性的知识点，给你简单地介绍一下。</p><p><strong>第一个点，是</strong> <strong>NGINX</strong> <strong>的跨平台兼容能力。</strong></p><p>我们都知道，操作系统的世界里不只有主流的 Windows、Linux，还有 macOS、FreeBSD 等等，而且每个操作系统还有不同的版本区别。</p><p>Java、Python 等语言有虚拟机，完全屏蔽了这些差异，而 C 程序更接近底层硬件，通常要直接调用系统函数编写代码，这就让代码的跨平台兼容成了一个大问题。</p><p>而 NGINX 却很好地实现了多系统平台的支持功能，能够在 Windows、Linux、macOS、FreeBSD、Solaris 等许多操作系统上运行，并且还兼容 GCC、Clang、Intel C 等不同的编译器和更下层的 x86、arm、SPARC 等硬件。那么，它是怎么做到的呢？</p><p>其实原理也很简单，就是<strong>引入“中间层”</strong>。具体手法是使用宏、条件编译还有包装函数，在代码层面把不同的系统底层调用封装起来。这样，上层使用的时候看到的就是一致的接口，不用再关心如何处理系统差异的“杂事”。</p><p>比如，对于 UNIX 系统里的非阻塞错误码（errno），NGINX 就使用条件编译，统一定义成宏 NGX_EAGAIN，从而消除了 HP-UX 与 Linux、FreeBSD 等其他系统的差异：</p><pre><code class=\"language-c++\">#if (__hpux__)\n#define NGX_EAGAIN&nbsp; &nbsp; &nbsp; &nbsp; EWOULDBLOCK\n#else\n#define NGX_EAGAIN&nbsp; &nbsp; &nbsp; &nbsp; EAGAIN\n#endif\n</code></pre><p>又比如，对于常用的函数 memcpy，NGINX 先是使用宏做了一层包装，然后再针对 Intel C 编译器做特别优化，最终使用的函数实际上是 ngx_copy：</p><pre><code class=\"language-c++\">#define ngx_memcpy(dst, src, n)&nbsp;(void) memcpy(dst, src, n)\n#define ngx_cpymem(dst, src, n)&nbsp;(((u_char *) memcpy(dst, src, n)) + (n))\n\n#if ( __INTEL_COMPILER &gt;= 800 )\nstatic ngx_inline u_char *\nngx_copy(u_char *dst, u_char *src, size_t len);\n#else\n#define ngx_copy ngx_cpymem\n#endif\n</code></pre><p>NGINX 还把许多操作系统独有的功能，分别定义在不同的头文件里，像 ngx_linux_config.h、ngx_darwin_config.h。然后，检测编译时的操作系统，再使用条件编译的方式包含进来，实现了针对不同操作系统的定制化：</p><pre><code class=\"language-c++\">#if (NGX_FREEBSD)\n#include &lt;ngx_freebsd_config.h&gt;\n\n#elif (NGX_LINUX)\n#include &lt;ngx_linux_config.h&gt;\n\n#elif (NGX_SOLARIS)\n#include &lt;ngx_solaris_config.h&gt;\n\n#elif (NGX_DARWIN)\n#include &lt;ngx_darwin_config.h&gt;\n\n#elif (NGX_WIN32)\n#include &lt;ngx_win32_config.h&gt;\n\n#else /* POSIX */\n#include &lt;ngx_posix_config.h&gt;\n\n#endif\n</code></pre><p>所以，研究了 NGINX 源码之后，我们就可以学会跨平台、兼容多系统这个对于 C 语言来说非常重要的技巧。</p><p><strong>下面我们来看第二个点，NGINX</strong> <strong>的内存管理能力。</strong></p><p>在 C 语言里，使用动态内存的标准函数是 malloc 和 free，但反复地调用它们分配和释放操作效率很低，而且容易导致内存碎片，影响系统稳定。</p><p>为了解决这个问题，NGINX 构造了两种内存池，块式内存池 ngx_pool 和页式内存池 ngx_slab_pool。原理是预先向系统申请较大的一块内存，之后自己在里面按需切分使用，使用完毕后再一次性释放。这样，就减少了系统调用的次数，也消除了内存碎片。</p><p>块式内存池 ngx_pool 多用在请求处理这种内存使用量不确定、生命周期短的场景，它的数据结构简单摘录如下：</p><pre><code class=\"language-c++\">typedef struct ngx_pool_s ngx_pool;  // ngx_palloc.h\n\nstruct ngx_pool_s { &nbsp; \n  ngx_pool_data_t    d;  // 描述本内存池节点的信息；\n&nbsp; size_t             max;  // 可分配的最大块；\n&nbsp; ngx_pool&nbsp; &nbsp; &nbsp;      *current;  // 当前使用的内存池节点；\n&nbsp; ngx_chain_t&nbsp; &nbsp; &nbsp;   *chain;  // 为 chain 做的优化，空闲缓冲区链表；\n&nbsp; ngx_pool_large_t&nbsp;  *large;  // 大块的内存，串成链表；\n&nbsp; ngx_pool_cleanup_t&nbsp;*cleanup;  //清理链表头指针；\n};\n</code></pre><p>ngx_pool 实际上是一个内存块链表，使用指针串联起多块动态分配的内存。小片的内存可以在块里直接移动指针分配，大块的内存就直接调用 malloc 分配，这就兼顾了不同的内存需求，非常灵活。</p><p>页式内存池 ngx_slab_pool 多用在进程间的共享内存、生命周期较长的场景。由于共享内存通常容量固定，不能动态增长，所以就需要“精打细算”，管理的难度比 ngx_pool 高很多。</p><p>ngx_slab_pool 的数据结构摘录如下：</p><pre><code class=\"language-c++\">typedef struct {\n&nbsp; size_t&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;min_size;  // 最小分配数量，通常是 8 字节；\n&nbsp; size_t&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;min_shift;  // 最小左移，通常是 3，即 2^3=8；\n&nbsp; ngx_slab_page_t&nbsp; *pages;  // 页数组；\n&nbsp; ngx_slab_page_t&nbsp; *last;  // 页链表指针，最后一页；\n&nbsp; ngx_slab_page_t&nbsp; free;  // 空闲页链表头节点；\n&nbsp; ngx_slab_stat_t&nbsp; *stats;  // 统计信息数组；\n&nbsp; ngx_uint_t&nbsp; &nbsp; &nbsp; &nbsp;pfree;  // 空闲页数量；\n&nbsp; u_char&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;*start;  // 共享内存的开始地址；\n&nbsp; u_char&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;*end;  // 共享内存的末尾地址；\n&nbsp; void&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;*addr;  // 内存的起始地址；\n} ngx_slab_pool;\n</code></pre><p>ngx_slab_pool 把内存划分成 4K 大小的 page，每个 page 又可以再划分成更小的8字节、16字节、32字节的 slab。</p><p>然后，NGINX 把这些 page 串成链表，就形成了一整片连续的内存。分配大块内存的时候，就从链表里摘下多个 page，释放的时候再重新接入链表；而分配小块内存的时候就取一个 page，使用 bitmap 的方式在 page 里切割小片的 slab 分配。</p><p>可以看到，NGINX 有着优秀的内存管理能力，能够应用于多种应用场景。我们完全可以把这些源码引入到自己的项目里，从而提升内存的使用效率。</p><h2>如何阅读 NGINX 的源码？</h2><p>看到 NGINX 源码里的这些编程技巧和架构设计，是不是觉得很值得借鉴？我猜你已经有种跃跃欲试的感觉了，那现在就动手下载源码并阅读吧。你可以从 <a href=\"http://nginx.org\">NGINX 官网</a>上下载源码压缩包，或者从 GitHub <a href=\"https://github.com/nginx/nginx\">这个网址</a>上获取 NGINX 的源码。</p><p>不过我必须要提醒你：虽然 NGINX 的源码写得很规范，但阅读起来并不轻松。</p><p>拿当前的稳定版 NGINX 1.20来说，源码大约有15万行（不包含空行）。虽然它的体量跟其他开源项目比起来算是中等规模，但想要弄懂其中错综复杂的数据结构和工作流程，也是一个很大的挑战。</p><p>所以，如果我们真的要把 NGINX 的源码读懂、读透，还是需要做些准备工作的。最好的方式就是<strong>分而治之，有的放矢。</strong></p><p><strong>首先，我们需要大概了解</strong> <strong>NGINX</strong> <strong>源码的组成结构。</strong></p><p>获取 NGINX 源码后，可以看到它里面有很多文件，目录结构我列在了下面：</p><pre><code class=\"language-plain\">nginx\n├── auto\n├── conf\n├── contrib\n├── html\n├── man\n└── src\n</code></pre><p>其中的 auto、conf、html，是预编译和配置示例等辅助文件，我们不需要太过关心。真正的 C 源码在 src 目录，这里又细分出几个子目录：</p><pre><code class=\"language-plain\">nginx/src\n├── core\n├── event\n│&nbsp; &nbsp;└── modules\n├── http\n│&nbsp; &nbsp;├── modules\n│&nbsp; &nbsp;└── v2\n├── mail\n├── misc\n├── os\n│&nbsp; &nbsp;└── unix\n└── stream\n</code></pre><p>这些子目录的命名都很明确，可以说是一目了然。比如，core 就是 NGINX 的核心框架功能，event 就是事件驱动机制，http 就是 HTTP 协议请求处理，os 就是具体的操作系统接口封装。</p><p><strong>然后，你就可以有针对性地去看这些目录里的源码了。</strong>我建议你只看自己感兴趣，或者当前急需了解的功能，避免不必要的时间和精力浪费。</p><p>接下来，在阅读 NGINX 源码的时候，我们也需要<strong>提前了解一下</strong> <strong>NGINX</strong> <strong>的编码风格，知道它的一些开发约定</strong>。这样，就可以比较容易地进入状态，减少理解 NGINX 源码的障碍。</p><p>这里，我简单列出一些 NGINX 源码的特点，你可以参考：</p><ul>\n<li>类型名、函数名使用前缀 “ngx_”，宏使用前缀 “NGX_”；</li>\n<li>枚举类型使用后缀 “_e”；</li>\n<li>函数指针类型使用后缀 “_pt”；</li>\n<li>结构体（struct）使用后缀 “_s”，同名的 “_t” 后缀是它的等价形式；</li>\n<li>为了节约内存，一些变量使用了“位域”特性（bit field）；</li>\n<li>大量使用了 <code>void*</code> 指针，通过类型强制转换，实现了其他语言里的类、泛型的功能。</li>\n</ul><h2>小结</h2><p>好了，今天的分享就到这里吧，最后做一个简单的小结：</p><ol>\n<li>学习 C 语言编程，可以选择阅读经典著作、工作开发实践和钻研开源项目三种方式；</li>\n<li>NGINX 集成了 Web 服务器、反向代理、负载均衡等能力，是一个优秀的 C 语言开源项目；</li>\n<li>NGINX 源码里蕴含了非常精妙的编程技巧和设计思想，非常值得仔细研究；</li>\n<li>NGINX 源码规模很大，要有选择、有目标地去阅读，这样才能事半功倍。</li>\n</ol><h2>课外小贴士</h2><ol>\n<li>W3Techs 的统计报告可参考<a href=\"https://w3techs.com/blog/entry/nginx_is_now_the_most_popular_web_server_overtaking_apache\">这个链接</a>。报告中有一个有趣的地方：排名第三的 CloudFlare Server 也是基于 NGINX 的。如果把它也算作是 NGINX 的话，那么 NGINX 的总份额就遥遥领先了，是绝对的“霸主”。</li>\n<li>在 DockerHub 网站上，NGINX 也是最受欢迎的项目之一，官方镜像的下载量已经超过了10亿次，与 MySQL、Redis、Python、Go 等流行技术是同一数量级。</li>\n<li>GitHub 上的 NGINX 源码实际上只是一个同步镜像，而真正的源码位置在<a href=\"https://hg.nginx.org\">这里</a>，是用一个比较“另类”的版本控制软件 Mercurial 管理的。</li>\n<li>NGINX 公司在2019年被 F5 networks 公司收购，之后就正式进入了中国市场，陆续推出了中文官网 <a href=\"https://www.nginx.org.cn\">nginx.org.cn</a> 和 <a href=\"https://www.nginx-cn.net\">nginx-cn.net</a>，分别面向社区用户和商业用户。网站里有很多技术干货，而且都翻译成了中文，值得一读。</li>\n<li>如果觉得直接看源码有困难，那么可以参考 GitHub 上的一些源码注释项目，比如我的：<a href=\"https://github.com/chronolaw/annotated_nginx\">https://github.com/chronolaw/annotated_nginx</a>。另外，我还有一本书《NGINX 完全开发指南》，里面有对 NGINX 数据结构、运行机制的详细解说，还配有图例，结合着源码注释，相信可以帮助你更好地学习。</li>\n</ol>","neighbors":{"left":{"article_title":"大咖助阵｜LMOS：用面向对象的思想开发 C 语言程序","id":474870},"right":{"article_title":"大咖助阵｜海纳：C 语言是如何编译执行的？（一）","id":491633}}},{"article_id":491633,"article_title":"大咖助阵｜海纳：C 语言是如何编译执行的？（一）","article_content":"<blockquote>\n<p>你好，我是于航。这一讲是一期大咖加餐，我们邀请到了海纳老师，来跟你聊聊与 C 程序编译相关的内容。C 语言是一门语法简单，且被广泛使用的编程语言，通过观察其代码的编译流程，你能够清楚地了解一个传统编译器的基本运作原理。海纳老师会用三到四讲的篇幅，来帮助你深刻理解 C 程序的编译全过程，这也是对我们专栏内容的很好补充。感谢海纳老师，也希望你能够有所收获，对 C 语言了解得更加透彻。</p>\n</blockquote><p>你好，我是海纳，是极客时间<a href=\"https://time.geekbang.org/column/intro/100094901?tab=catalog\">《编程高手必学的内存知识》</a>的专栏作者。</p><p>作为一名编译器开发工程师，在这里我想和你聊一下 C 语言的编译过程。对于 C 语言的开发者来说，深刻理解编译的过程是十分必要的。由于 C 语言非常接近底层，所以它是一门用于构建基础设施的语言。很多时候，C 语言的开发者要理解每一行代码在 CPU 上是如何执行的。所以，有经验的开发者在看到 C 的代码时，基本都能够判断它对应的汇编语句是什么。</p><p>在接下来的几篇加餐里，我会通过一个简单的例子，来说明一个 C 编译器有哪些基本步骤。在这个过程中，你也可以进一步通过操作 gcc 的相关工具，来掌握如何查看 C 编译过程的每一步的中间结果。</p><p>接下来，我们就先从对 C 编译器基本步骤的整体了解开始吧。</p><h2>编译的基本步骤</h2><p>一个 C 语言的源代码文件，一般要经过编译和链接两个大的步骤才能变成可执行程序。其中，编译的过程是将单个C源码文件翻译成中间文件。而链接器主要用于符号解析，它负责将中间文件中的符号进行跨文件解析，进而把中间文件组成一个二进制文件。关于链接的知识，于航老师已经在这个专栏的第 27~28 讲中深入地介绍过了，所以在这里我就不赘述了。</p><!-- [[[read_end]]] --><p>我们只聚焦于编译的过程，编译主要可以分为以下几个步骤：</p><ol>\n<li>预处理，主要是处理宏定义，将宏定义展开，这一步所使用的技术一般只涉及字符串替换；</li>\n<li>词法分析，将文本转成 token 序列；</li>\n<li>文法分析，将 token 序列转成抽象语法树；</li>\n<li>语义分析，文法只能检查局部的信息，有一些语义信息需要在这一步检查，例如非 void 的函数漏写 return 语句；</li>\n<li>平台无关优化，与具体的平台（体系结构）无关的结构优化，往往与语义相关；</li>\n<li>平台相关优化，与具体的体系结构相关的优化，例如考虑平台的缓存和流水线设计而做出的优化；</li>\n<li>指令选择，调度和寄存器分配，主要是为目标平台生成代码；</li>\n<li>中间文件生成，编译过程结束，一个编译单元会生成一个中间文件。</li>\n</ol><p>接下来的几节课，我们就按照先后顺序依次介绍编译的每一个步骤。这节课我主要介绍预处理和词法分析。下面来看第一个步骤，预处理。</p><h2>预处理</h2><p>预处理最重要的工作步骤是对宏进行处理。宏的概念比较简单，但想要精通却很难，所以大多数时候，我们需要依赖 gcc 的预处理命令对宏进行展开，以观察它的效果。这个命令如下：</p><pre><code class=\"language-plain\">$ gcc -E file.c\n</code></pre><p>接下来，我用一个具体的例子来说明预处理的工作原理，例子代码如下所示：</p><pre><code class=\"language-plain\">#include &lt;stdio.h&gt;\n\n#ifdef USE_MACRO\n#define square(x) (x)*(x)\n#else\ninline int square(int x) {\n&nbsp; &nbsp; return x * x;\n}\n#endif\n\nint main() {\n&nbsp; &nbsp; int a = 3;\n&nbsp; &nbsp; int b = square(++a);\n&nbsp; &nbsp; printf(\"%d\\n\", b);\n&nbsp; &nbsp; return 0;\n}\n</code></pre><p>在这个例子中，对 square 的调用（第13行）究竟是一个宏，还是一个内联函数调用，取决于“USE_MACRO”这个宏是否被定义。</p><p>我们分别使用“gcc -E -DUSE_MACRO”命令和“gcc -E”命令处理这个文件，就会得到不同的结果。先来看定义了“USE_MACRO”的情况：</p><pre><code class=\"language-plain\">// gcc -E macro_def.c -DUSE_MACRO \nint main() {\n&nbsp; &nbsp; int a = 3;\n&nbsp; &nbsp; int b = (++a)*(++a);\n&nbsp; &nbsp; printf(\"%d\\n\", b);\n&nbsp; &nbsp; return 0;\n}\n</code></pre><p>从以上代码中可以看到，square 是一个宏，而这个宏的定义已经消失了，而对 square 的调用也被替换为一个乘法（第4行）。</p><p>不知道这个结果有没有让你感到吃惊。因为我们的本意是想让变量 a 自增 1，然后再求变量 a 的平方，但从宏展开的结果来看，显然是做了两次自增运算，所以最终的运行结果是20，而不是16。从这个例子中，我们也可以看出，宏的替换本质上是字符串替换。也就是说，这里在宏展开的过程中，预处理器仅仅是把字符串“x”简单地替换成了“++a”而已。</p><p>如果没有定义“USE_MACRO”，那么预处理的结果就是这样的：</p><pre><code class=\"language-plain\">// gcc -E macro_def.c\ninline int square(int x) {\n&nbsp; &nbsp; return x * x;\n}\n\nint main() {\n&nbsp; &nbsp; int a = 3;\n&nbsp; &nbsp; int b = square(++a);\n&nbsp; &nbsp; printf(\"%d\\n\", b);\n&nbsp; &nbsp; return 0;\n}\n</code></pre><p>这一次的结果显然就是16了。这个结果是比较简单而且直观的，所以我就不再过多解释了，你可以自己动手试验并解释它的执行结果。</p><p>这里再留一个小练习：请你自己动手，使用“gcc -E”命令对以下程序进行预处理，并解释预处理的结果，以此来掌握井号和双井号在宏定义中的作用。如果这个过程中遇到什么问题，欢迎在评论区交流讨论。</p><pre><code class=\"language-plain\">#include &lt;stdio.h&gt;\n\n#define TYPE_Apple 1\n#define TYPE_Pear&nbsp; 2\n\nstruct Fruit {\n&nbsp; &nbsp; int _type;\n&nbsp; &nbsp; char* _name;\n};\n\n#define DECLARE(x) \\\nstruct Fruit x = {&nbsp; &nbsp; &nbsp; \\\n&nbsp; &nbsp; TYPE_##x,&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\\\n&nbsp; &nbsp; #x,&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\\\n};\n\nDECLARE(Apple)\nDECLARE(Pear)\n\nint main() {\n&nbsp; &nbsp; printf(\"%d, %s\\n\", Apple._type, Apple._name);\n&nbsp; &nbsp; printf(\"%d, %s\\n\", Pear._type, Pear._name);\n&nbsp; &nbsp; return 0;\n}\n</code></pre><p>预处理的核心工作就是对宏定义进行展开，展开的时候主要是进行字符串的直接替换，尤其是对于宏函数，不能把它真的当成函数进行处理。在理解了预处理器的工作原理之后，我们再来看下一个步骤，那就是词法分析。</p><h2>词法分析</h2><p>词法分析的作用是把字符进行分组，将有意义关联的字符分到同一个组里，每个组就是一个词。词法分析主要由词法分析器来完成。</p><p>例如，“double PI = 3.1415926”这句 C 语言的代码包含了多个字符，但人们在理解它的时候是先把它分成了这四个小组：（“double”，类型声明）、（“PI”，变量名）、（“=”，赋值操作符）、（“3.1415926”，浮点立即数）。</p><p>而词法分析的过程和人的理解过程是一致的，也是把字符串进行同样的分组。在编译的过程中，这种分组有一个专门的名称叫做 Token。Token 这个术语在计算机学科中经常出现，在不同的场景中代表不同的含义。例如在网络中，它被翻译成“令牌”，在客户端和服务端通信的场景中，token 又被作为授权验证的加速手段。所以，为了避免歧义，我们这里把 Token 称为词法单元，就代表一个词的意思。</p><p>词法分析的主要手段有两种，分别是正则表达式和<strong>有限状态自动机，简称为自动机</strong>。在这一讲中，我主要介绍自动机的方法，这是因为这种方法比较灵活，易于编写和理解。那什么是有限状态自动机呢？</p><p>有限状态自动机由一个有限的内部状态集合和一组控制规则组成，这些规则是用来控制在当前状态下可以接受什么输入，以及接受这些输入以后应转向什么状态。例如下图中的有限状态机就包含了3个状态：</p><p><img src=\"https://static001.geekbang.org/resource/image/fc/85/fcef0406f873a0702e7a01c121150a85.jpg?wh=2284x1040\" alt=\"\"></p><p>在这张图片中，状态 0 是自动机的初始状态，从状态 0 出发的箭头号标上了字母 a，表示这个状态可以接受字母 a，进入状态 1 。</p><p>从状态 1 出发的箭头有两条，分别是指回自己的箭头 a，和指向状态 2 的箭头 b。也就是说，状态 1 接受字母 a，仍然回到了状态 1，这就意味着自动机可以在状态 1 的情况下，接受无穷多个字母 a。而箭头 b 则意味着状态 1 还可以接受字母 b，变成状态 2。</p><p>状态 2 是比较特殊的一个状态，我们使用两个圈来绘制它，这代表它是一个终态。如果自动机进入到终态以后，就表示自动机完成了一次匹配。</p><p>实际上，这个自动机代表了这样一种模式：“a+b”，其中的加号表示，至少包含一个a，并且以b结尾的字符串。例如“aab”、“ab”，都符合“a+b”这个模式。这里你可以自己练习一下，当输入是这两个字符的时候，自动机的状态是如何变化的。</p><p>在理解了自动机的概念以后，我们再来看如何通过代码实现一个自动机。我们可以使用一个整型变量state来代表自动机的状态，然后根据输入，不断地改变这个变量。</p><p>我先举一个处理变量名的例子。C语言中的变量名可以使用字母和下划线开头，后面可以跟着数字、字母和下划线。所以变量名的正则表达式可以表示为“[a-zA-Z_][a-zA-Z_0-9]*”，其中，中括号表示待匹配的字符范围。这个规则表达成自动机，可以用下面的图片表示：</p><p><img src=\"https://static001.geekbang.org/resource/image/c7/bc/c7c5a929a888yy7496545106f8f38dbc.jpg?wh=2284x1111\" alt=\"\"></p><p>将这个自动机转换成代码是比较容易的，请你跟着下面的四个步骤来实现它。</p><p>第一步，先创建代码所需要的数据结构：</p><pre><code class=\"language-plain\">#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;string.h&gt;\n\nenum State {\n&nbsp; &nbsp; STATE_INIT,   /* 有限状态自动机的初始状态 */\n&nbsp; &nbsp; STATE_VAR,    /* 接受字符的状态 */\n};\n\nenum TokenType {\n&nbsp; &nbsp; TT_VAR,       /* 标示Token类型是变量 */\n&nbsp; &nbsp; TT_INTEGER,   /* token类型是整数 */\n&nbsp; &nbsp; TT_STRING,    /* token类型是字符串 */\n};\n\nunion TokenValue {\n&nbsp; &nbsp; char* _str;   /* 这里使用了一个union，即可以用于指向字符串，*/\n&nbsp; &nbsp; int&nbsp; &nbsp;_int;   /* 也可以是一个整数值。 */\n};\n\nstruct Token {\n&nbsp; &nbsp; enum TokenType _type;\n&nbsp; &nbsp; union TokenValue _value;\n};\n</code></pre><p>这段代码中，分别声明了代表自动机状态的枚举值State（第5行），代表token类型的枚举值TokenType（第10行），代表token的结构体Token（第16行至第21行）。这些类型的声明是比较直接的，我就不再多花篇幅一一介绍了，请你阅读代码进行理解，可以参考我加的注释。</p><p>第二步，实现创建token和销毁token的函数：</p><pre><code class=\"language-plain\">enum State state = STATE_INIT;\nchar* cur;\n\nstruct Token* create_token(enum TokenType tt, char* begin, char* cur) {\n&nbsp; &nbsp; struct Token* nt = (struct Token*)malloc(sizeof(struct Token));\n&nbsp; &nbsp; nt-&gt;_type = tt;\n\n    /* 这里只需要对变量进行处理，等号、分号等符号只需要类型就够了。 */\n&nbsp; &nbsp; if (tt == TT_VAR) {\n&nbsp; &nbsp; &nbsp; &nbsp; nt-&gt;_value._str = (char*)malloc(cur - begin + 1);\n&nbsp; &nbsp; &nbsp; &nbsp; strncpy(nt-&gt;_value._str, begin, cur - begin);\n&nbsp; &nbsp; &nbsp; &nbsp; nt-&gt;_value._str[cur-begin] = 0;\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; return nt;\n}\n\nvoid destroy_token(struct Token* t) {\n    /* 释放空间是和malloc对应的，也在变量的情况下才需要。 */\n&nbsp; &nbsp; if (t-&gt;_type == TT_VAR) {\n&nbsp; &nbsp; &nbsp; &nbsp; free(t-&gt;_value._str);\n&nbsp; &nbsp; &nbsp; &nbsp; t-&gt;_value._str = NULL;\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; free(t);\n}\n</code></pre><p>这段代码先定义了两个全局变量，state 代表自动机的内部状态（第1行），指针 cur 代表词法分析器当前的输入字符（第2行）。然后又定义了两个辅助函数，分别用于创建token（第4行至第16行），以及销毁过期的token（第18行至26行）。这里需要注意，create_token中的malloc和destroy_token中的free是成对出现的，否则就容易造成内存泄漏。</p><p>接下来的第三步，我们就可以实现next_token函数，用于从字符串中逐个分割单词，每调用一次next_token就会得到一个token：</p><pre><code class=\"language-plain\">struct Token* next_token() {\n&nbsp; &nbsp; state = STATE_INIT;\n&nbsp; &nbsp; char* begin = 0;\n\n&nbsp; &nbsp; while (*cur) {\n&nbsp; &nbsp; &nbsp; &nbsp; char c = *cur;\n&nbsp; &nbsp; &nbsp; &nbsp; if (state == STATE_INIT) {\n            /* 在初态下，遇到空白字符都可以跳过。 */\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (c == ' ' || c == '\\n' || c == '\\t') {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cur++;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n\n            /* 遇到字符则认为是一个变量的开始。 */\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if ((c &lt;= 'Z' &amp;&amp; c &gt;= 'A') ||\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (c &lt;= 'z' &amp;&amp; c &gt;= 'a') || c == '_') {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; begin = cur;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; state = STATE_VAR;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cur++;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; else if (state == STATE_VAR) {\n            /* 当前状态机处于分析变量的阶段，所以可以继续接受字母和数字。 */\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if ((c &lt;= 'Z' &amp;&amp; c &gt;= 'A') ||\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (c &lt;= 'z' &amp;&amp; c &gt;= 'a') ||\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (c &lt;= '9' &amp;&amp; c &gt;= '0') || c == '_') {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cur++;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; else { /* 否则的话，就说明这个变量已经分析完了。 */\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; return create_token(TT_VAR, begin, cur);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; return NULL;\n}\n</code></pre><p>上述代码就是一个自动机的典型实现：一开始，自动机的状态是INIT（第2行）；在初始状态下，如果遇到空格，制表符和换行符就可以自动忽略（第8行至第12行）；如果遇到字母，自动机的状态就转换为STATE_VAR，代表自动机当前正在分析的是一个变量名（第14行至第20行）。</p><p>如果自动机的状态是VAR，那么当前输入如果是字母或者数字，则状态不变，将字符直接移进即可（第23行至第28行）；否则就说明当前token已经结束了，可以把这个token直接返回出去了（第30行）。</p><p>如果分析到了整个字符串的最后，那控制流就跳出了while循环，通过第35行返回空值。</p><p>最后一步，我们在main函数中添加测试程序：</p><pre><code class=\"language-plain\">int main() {\n&nbsp; &nbsp; cur = \"int val1 = 1;\";\n\n&nbsp; &nbsp; struct Token* t = next_token();\n&nbsp; &nbsp; printf(\"%d, %s\\n\", t-&gt;_type, t-&gt;_value._str);\n&nbsp; &nbsp; destroy_token(t);\n\n&nbsp; &nbsp; t = next_token();\n&nbsp; &nbsp; printf(\"%d, %s\\n\", t-&gt;_type, t-&gt;_value._str);\n&nbsp; &nbsp; destroy_token(t);\n\n&nbsp; &nbsp; return 0;\n}\n</code></pre><p>编译并执行这个程序，我们就会发现程序正确地打印了前两个token的类型和值。</p><p>通过这个例子，相信你已经掌握如何使用自动机进行词法分析了，这里我再总体概括一下：我们先根据词法规则写出token的正则表达式，然后将正则表达式手绘成由圆圈和箭头组成的图形化的状态机，最后将这个状态机翻译成代码即可。从自动机的图形到代码，这个翻译过程是直接而简明的。</p><p>不过，当前的这个词法分析器只能处理变量名，而main函数中提供的例子，还要处理等号和整数，以及行尾的分号。接下来，我们就来一起完善它。</p><h2>完善词法分析器</h2><p>首先，我们在程序中增加对等号的处理。在C语言中，自动机遇到一个等号时，还不知道它是一个赋值操作，还是一个判断相等的操作，而前者是一个等号，后者是两个等号。所以我们只能继续向后看一个字符，把这个过程转化为代码，如下所示：</p><pre><code class=\"language-plain\">struct Token* next_token() {\n&nbsp; &nbsp; state = STATE_INIT;\n&nbsp; &nbsp; char* begin = 0;\n    while (*cur) {\n&nbsp; &nbsp; &nbsp; &nbsp; char c = *cur;\n&nbsp; &nbsp; &nbsp; &nbsp; if (state == STATE_INIT) {\n&nbsp;           // ....\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; else if (c == '=') {\n                /* 在初始状态下遇到等号，并不能立即确定这就是一个赋值操作，\n                 * 还需要再往后看一个字符。如果后面的字符也是等号，说明这\n                 * 是一个\"==\"操作符。如果不是等号，才说明当前的等号是赋值。*/\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; begin = cur;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; state = STATE_EQU;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cur++;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; }\n        //....\n        else if (state == STATE_EQU) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (c == '=') { /* \"==\" 操作符，先不处理 */\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; else { /* 赋值操作符 */\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; return create_token(TT_ASSIGN, begin, cur);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; return NULL;\n}\n</code></pre><p>如果只有一个等号，我们就可以判定当前token是一个赋值。如果有两个等号，就是“==”操作符，这段程序中先不支持（第19、20行），所以这个分支，可以先不实现。这样一来，赋值操作就可以支持了。</p><p>接下来，我们再来支持识别整数类型的token。作为练习，请你自己动手画出整数的自动机，然后再将它转换成代码。因为想鼓励你动手操作，我就不再给出中间步骤了，这里只把最终代码展示给你。你可以将这份代码与自己的代码进行对比，以检查自己的学习效果，也欢迎你在评论区分享自己的操作步骤和实践经验。</p><pre><code class=\"language-plain\">#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;string.h&gt;\n\nenum State {\n&nbsp; &nbsp; STATE_INIT,  /* 初始状态 */\n&nbsp; &nbsp; STATE_VAR,   /* 判定变量 */\n&nbsp; &nbsp; STATE_EQU,   /* 判定等号 */\n&nbsp; &nbsp; STATE_NUM,   /* 判定整数 */\n};\n\nenum TokenType {\n&nbsp; &nbsp; TT_VAR,      /* token类型为变量 */\n&nbsp; &nbsp; TT_INTEGER,  /* 整数 */\n&nbsp; &nbsp; TT_STRING,   /* 字符串 */\n&nbsp; &nbsp; TT_ASSIGN,   /* 赋值操作符 */\n&nbsp; &nbsp; TT_SEMICON,  /* 行尾分号 */\n};\n\nunion TokenValue {\n&nbsp; &nbsp; char* _str;\n&nbsp; &nbsp; int&nbsp; &nbsp;_int;\n};\n\nstruct Token {\n&nbsp; &nbsp; enum TokenType _type;\n&nbsp; &nbsp; union TokenValue _value;\n};\n\nenum State state = STATE_INIT;\nchar* cur;\n\n/*\n * 创建一个 token。token类型由 tt 指定，它的值由 begin 到 cur 的这一段\n * 字符串决定。如果类型是整型，还要把它的值从字符串转换成整数。\n */\nstruct Token* create_token(enum TokenType tt, char* begin, char* cur) {\n&nbsp; &nbsp; struct Token* nt = (struct Token*)malloc(sizeof(struct Token));\n&nbsp; &nbsp; nt-&gt;_type = tt;\n\n&nbsp; &nbsp; if (tt == TT_VAR) {\n&nbsp; &nbsp; &nbsp; &nbsp; nt-&gt;_value._str = (char*)malloc(cur - begin + 1);\n&nbsp; &nbsp; &nbsp; &nbsp; strncpy(nt-&gt;_value._str, begin, cur - begin);\n&nbsp; &nbsp; &nbsp; &nbsp; nt-&gt;_value._str[cur-begin] = 0;\n&nbsp; &nbsp; }\n&nbsp; &nbsp; else if (tt == TT_INTEGER) {\n&nbsp; &nbsp; &nbsp; &nbsp; int sum = 0;\n&nbsp; &nbsp; &nbsp; &nbsp; for (char* p = begin; p &lt; cur; p++) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sum *= 10;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sum += (*p - '0');\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; nt-&gt;_value._int = sum;\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; return nt;\n}\n\nvoid destroy_token(struct Token* t) {\n&nbsp; &nbsp; if (t-&gt;_type == TT_VAR) {\n&nbsp; &nbsp; &nbsp; &nbsp; free(t-&gt;_value._str);\n&nbsp; &nbsp; &nbsp; &nbsp; t-&gt;_value._str = NULL;\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; free(t);\n}\n\nvoid log_token(struct Token* t) {\n&nbsp; &nbsp; printf(\"%d\", t-&gt;_type);\n\n&nbsp; &nbsp; if (t-&gt;_type == TT_VAR) {\n&nbsp; &nbsp; &nbsp; &nbsp; printf(\", %s\\n\", t-&gt;_value._str);\n&nbsp; &nbsp; }\n&nbsp; &nbsp; else if (t-&gt;_type == TT_INTEGER) {\n&nbsp; &nbsp; &nbsp; &nbsp; printf(\", %d\\n\", t-&gt;_value._int);\n&nbsp; &nbsp; }\n&nbsp; &nbsp; else {\n&nbsp; &nbsp; &nbsp; &nbsp; printf(\"\\n\");\n&nbsp; &nbsp; }\n}\n\nchar is_alpha(char c) {\n&nbsp; &nbsp; return (c &lt;= 'Z' &amp;&amp; c &gt;= 'A') || (c &lt;= 'z' &amp;&amp; c &gt;= 'a') || c == '_';\n}\n\nchar is_num(char c) {\n&nbsp; &nbsp; return c &lt;= '9' &amp;&amp; c &gt;= '0';\n}\n\nstruct Token* next_token() {\n&nbsp; &nbsp; state = STATE_INIT;\n&nbsp; &nbsp; char* begin = 0;\n\n&nbsp; &nbsp; while (*cur) {\n&nbsp; &nbsp; &nbsp; &nbsp; char c = *cur;\n&nbsp; &nbsp; &nbsp; &nbsp; if (state == STATE_INIT) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (c == ' ' || c == '\\n' || c == '\\t') {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cur++;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (is_alpha(c)) { /* 初始状态下遇到字符 */\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; begin = cur;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; state = STATE_VAR;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cur++;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; else if (is_num(c)) { /* 初始状态下遇到数字 */\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; begin = cur;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; state = STATE_NUM;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cur++;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; else if (c == '=') { /* 初始状态下遇到等号，需要向后再看一位 */\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; begin = cur;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; state = STATE_EQU;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cur++;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; else if (c == ';') { /* 遇到分号则可以直接返回 */\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; begin = cur;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cur++;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; return create_token(TT_SEMICON, begin, cur);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; else if (state == STATE_VAR) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (is_alpha(c) || is_num(c)) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cur++;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; else {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; return create_token(TT_VAR, begin, cur);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; else if (state == STATE_NUM) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (is_num(c)) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cur++;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; else {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; return create_token(TT_INTEGER, begin, cur);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; else if (state == STATE_EQU) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (c == '=') { /* \"==\" 操作符 */\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; else { /* 赋值操作符 */\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; return create_token(TT_ASSIGN, begin, cur);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; return NULL;\n}\n\nint main() {\n&nbsp; &nbsp; cur = \"int val1 = 12;\";\n\n&nbsp; &nbsp; struct Token* t = next_token();\n&nbsp; &nbsp; while (t) {\n&nbsp; &nbsp; &nbsp; &nbsp; log_token(t);\n&nbsp; &nbsp; &nbsp; &nbsp; destroy_token(t);\n&nbsp; &nbsp; &nbsp; &nbsp; t = next_token();\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; return 0;\n}\n</code></pre><p>到这里，我们就对上述代码中第 151 行所展示的那一行 C 代码进行了正确的词法分析。那么下一节课，我们就把注意力放到文法分析上了。</p><h2>总结</h2><p>在这节课里，我先介绍了C语言编译的基本过程。把一个C语言源文件编译成可执行程序，最基本的步骤包括编译和链接两部分。而编译又可以细分为预处理、词法分析、文法分析、语义分析、中间代码生成、平台无关优化、平台相关优化、指令选择与调度、寄存器分配等等。</p><p>按照顺序，我在这节课里先展示了预处理和词法分析是如何工作的。</p><p>预处理的核心任务是进行宏展开，而宏展开的主要手段就是使用字符串替换，这一点在宏函数定义展开时往往会带来意想不到的问题，所以在使用宏的时候一定要非常慎重。如果自己对宏展开的结果没有把握，我们可以通过“gcc -E”命令来查看预处理的结果。</p><p>而词法分析任务主要是把输入的源代码字符串进行合理的分组，将字符串分割成一个个的token，每一种token有自己的类型和值。而词法分析的主要手段有正则表达式和有限状态自动机两种，这节课里我重点介绍了有限自动机的生成方式。</p><p>有限自动机是一种包括了状态和转换规则的数据结构，它的状态可以根据输入而不断地发生变化。如果有一种输入序列可以使得自动机从初态转移到终状，我们就称这种输入被自动机所接受。而词法分析的过程，就是不断地令自动机接受输入字符串并且识别token的过程。</p><p>最后，我通过一个实际的例子，向你展示了词法分析器如何正确地识别变量名和数字，以及赋值操作符、分号等等。</p><p>这节课就到这里了，如果今天的内容让你有所收获，欢迎把它分享给你的朋友。下一次的加餐，我将继续讲解 C 语言程序编译的下一个步骤，文法分析。我们到时候见！</p>","neighbors":{"left":{"article_title":"大咖助阵｜罗剑锋：为什么 NGINX 是 C 编程的经典范本？","id":476646},"right":{"article_title":"大咖助阵｜海纳：C 语言是如何编译执行的？（二）","id":493848}}},{"article_id":493848,"article_title":"大咖助阵｜海纳：C 语言是如何编译执行的？（二）","article_content":"<p>你好，我是海纳。</p><p>上节课，我整体介绍了编译过程包含的几个基本步骤：预处理、词法分析、文法分析、语义分析、中间表示的优化，以及目标文件生成等。然后，我又重点介绍了预处理和词法分析。那按照先后顺序，这节课我们继续来看文法分析。</p><p>文法分析技术不只用于编译器中，在JSON文件解析、XML文件解析等场景中也被广泛地使用，它其实是一种处理格式化文本的技术。所以学习这节课，你要掌握的不仅是文法分析的具体技术，更重要的是要理解它处理格式化文本的原理。只有深刻地理解了原理，我们才能做到在具体的场景中，根据需要自由地修改算法的实现。</p><p>接下来，我们就具体看看文法分析吧。</p><h2>文法分析</h2><p>文法，或者叫语法（Grammar），它描述了一套语言的产生规则。例如，一个合法的句子包含主语、谓语和宾语。那么，我们就可以这样定义句子的规则：</p><p>$Sent\\rightarrow S P O$</p><p>其中，Sent代表一个句子，S代表主语（Subject），P代表谓语（Predicate），O代表宾语（Object）。上述公式可以这么理解：句子可以<strong>推导</strong>成主语加谓语加宾语的结构。</p><p>主语则可以进一步定义成具体的人。例如，Tom或者Mary，这个定义也可以使用一个公式来表示：</p><!-- [[[read_end]]] --><p>$S\\rightarrow Tom | Mary$</p><p>也就是说，主语S可以继续推导，但Tom或者Mary则不能再继续推导下去了。这样，人们就把可以推导下去的符号称为<strong>非终结符</strong>，例如Sent、S都是非终结符，P和O当然也是非终结符；同时把不可以继续推导的符号称为<strong>终结符</strong>，例如Mary和Tom。</p><p>谓语和宾语也有对应的推导规则，举例来说：</p><p>$P \\rightarrow play | eat$</p><p>$O\\rightarrow basketball | apple$</p><p>这样的四条规则就组成了一个关于句子的文法。如果我们遇到句子“Tom plays basketball”，就可以反向使用规则，对这个句子进行分析。正向使用规则叫作<strong>推导</strong>，而反向使用规则被称为<strong>归约</strong>。我们看到Tom可以归约为S，play可以归约为P，basketball可以规约为O，所以上述句子经过第一层规约就变成了“SPO”。而这可以继续反向使用第一条规则，将其归约为Sent，也就是说这是一个合乎文法的句子。换句话说，句子“Tom plays basketball”被文法Sent接受了。</p><p>编程语言的解析也借助了文法这个概念。我们对源文件进行文法分析的过程，其实就是使用文法对源文件进行归约的过程。如果能归约到顶级规则，那就说明源文件是没有文法错误的，否则就应该报源文件有语法错误。</p><p>将源代码归约到顶级规则的手段，是一种<strong>自底向上</strong>的分析手段，它使用文法规则的时候是从右向左进行归约的。人们称这种分析方式为LR算法，其中的L代表源文件的分析方向是从左向右的，而R则代表规则的使用方向是从右向左的，或者说自底向上的。</p><p>很多自动化文法分析工具，例如yacc、javacc等，都是基于LR算法来进行文法分析的。这些工具为开发新的语言提供了便利。但实际上，近二十年来新出现的编程语言却越来越喜欢使用另外一种<strong>自顶向下</strong>的分析方法，它也叫作递归下降的分析方式。自顶向下的分析方法具有简洁直观的优点，代码易读易维护，深受编译器开发人员的喜爱。所以这节课，我就重点介绍递归下降的自顶向下的分析方法。</p><h2>自顶向下的分析方法</h2><p>自顶向下的分析方法，其特点是从顶层规则的最左侧的符号开始，尝试不断地使用文法中的各种规则，对输入字符串进行匹配。</p><p>而具体做法是将非终结符实现为函数，在函数中对终结符进行匹配。这里，我用表达式求值的程序来进行说明。一个表达式的文法规则可以这样定义：</p><p>$expr \\rightarrow term([+|-] term)*$</p><p>$term \\rightarrow factor([*|/]) factor) *$</p><p>$factor \\rightarrow NUM| (expr)$</p><p>顶级规则是expr，这条规则代表表达式的定义，一个表达式可以是多项式的一个项或者多个项的和或者差。</p><p>第二条规则是项的规则，一个项可以是一个因子，或者多个因子的积或者商。这条规则保证了乘除法的优先级高于加减法。</p><p>第三条规则是因子的规则，它可以是一个整数，或者是用括号括起来的表达式。这就定义了括号的优先级是最高的。</p><p>接下来，我分步骤来讲解文法分析的过程。</p><p>第一步，先扩展词法分析器，让它可以支持小括号、加减符号和乘除符号。这一段的核心逻辑在上一节课中已经讲过了，这里就不再赘述。完整的代码我已经放在了<a href=\"https://gitee.com/hinus/codelet/tree/1c4241ed57c3c026f6621c100bb4e3095c5ddda5/compiler\">gitee</a>上，请你自己去查看词法分析的代码。</p><p>第二步，定义文法分析器，将非终结符翻译成函数。表达式的文法里有三个非终结符，分别是 expr、term和factor，所以我们就定义三个函数，代码如下：</p><pre><code class=\"language-plain\">/* 表达式规则的文法解析过程 */\nint expr() {\n    int a = 0, b = 0;\n    a = term(); /* 一个表达式最少包含一项 */\n\n    while (t-&gt;_type == TT_ADD || t-&gt;_type == TT_SUB) {\n        if (t-&gt;_type == TT_ADD) {\n            t = next_token();\n            b = term();\n            a += b;\n        }\n        else if (t-&gt;_type == TT_SUB) {\n            t = next_token();\n            b = term();\n            a -= b;\n        }\n    }\n\n    return a;\n}\n\n/* 每一项的文法分析过程 */\nint term() {\n    int a = 0, b = 0;\n    a = factor(); /* 最少包含一个因子 */\n\n    while (t-&gt;_type == TT_MUL || t-&gt;_type == TT_DIV) {\n        if (t-&gt;_type == TT_MUL) {\n            t = next_token();\n            b = factor();\n            a *= b;\n        }\n        else if (t-&gt;_type == TT_DIV) {\n            t = next_token();\n            b = factor();\n            a /= b;\n        }\n    }\n\n    return a;\n}\n\nint factor() {\n    if (t-&gt;_type == TT_INTEGER) { /* 可以是一个整数 */\n        int a = t-&gt;_value._int;\n        t = next_token();\n        return a;\n    }\n    else if (t-&gt;_type == TT_LEFT_PAR) { /* 或者是括号里的表达式 */\n        t = next_token();\n        int a = expr();\n        if (!match(TT_RIGHT_PAR)) /* 不要忘了还有一个右括号 */\n            return 0;\n        else\n            return a;\n    }\n    else {\n        printf(\"Parse Error\\n\");\n        return 0;\n    }\n}\n</code></pre><p>其中，函数expr对应expr规则，函数term对应term规则，而函数factor对应factor规则。在对应的时候，或结构（中括号和竖线表示或）就会被翻译成if…else语句，而有零个或者多个（用*表示）就会被翻译成while语句。这种对应规则是非常简明的，只要你仔细对照体会，就能明白为什么人们更喜欢自顶向下的分析方法。只要能写出文法规则，那么翻译成代码的过程就非常直接。</p><p>这里我只给出了部分代码，完整的代码，你可以在<a href=\"https://gitee.com/hinus/codelet/tree/1c4241ed57c3c026f6621c100bb4e3095c5ddda5/compiler\">这里</a>找到。</p><p>但是你也要注意这种算法的一个重要限制，那就是不能有左递归。例如，表达式文法还有一种写法是这样的：</p><p>$expr \\rightarrow expr + term$</p><p>这种文法规则右侧的第一个非终结符和左侧的非终结符相同，这种情况就是左递归。如果采用自底向上的归约的办法，显然是可以把右侧的三个符号归约成左侧的一个符号的。但是对于自顶向下的算法就不行了。对它直接进行翻译，会产生如下代码：</p><pre><code class=\"language-plain\">int expr() {\n&nbsp; &nbsp; int a = expr(); /* 请注意这里，这是个没有终结条件的递归 */\n\n&nbsp; &nbsp; if (t-&gt;_type == TT_ADD) {\n&nbsp; &nbsp; &nbsp; &nbsp; t = next_token();\n&nbsp; &nbsp; &nbsp; &nbsp; int b = term();\n&nbsp; &nbsp; &nbsp; &nbsp; a += b;\n&nbsp; &nbsp; }\n    return a;\n}\n</code></pre><p>很明显，这是一个无穷递归。这也就说明了自顶向下的分析方法处理不了左递归。<br>\n遇到这种情况，我们可以通过将左递归文法改写成右递归文法，来避免无穷递归的问题。例如，上面提到的expr可以这样改写：</p><p>$expr \\rightarrow term~epxr’$</p><p>$expr’ \\rightarrow +term~expr’~|~\\epsilon$</p><p>其中，$\\epsilon$代表空，这表示expr’可以推导为空。这就把左递归文法改成了右递归，从而避免了翻译成代码时的无穷递归。把这个文法翻译成代码的练习就交给你自己完成了，欢迎在评论区交流你的心得。</p><p>我在做文法分析的过程中直接把表达式的值求出来了，但实际上，编译器并不会在文法分析阶段就对程序进行运算，而是会把程序先翻译成一种叫作抽象语法树（Abstract Syntax Tree, AST）的树形结构，然后再对这个树形结构做分析和变换，进而翻译成机器指令。接下来，我们就看一下抽象语法树的相关知识。</p><h2>抽象语法树</h2><p>我先用一个直观的例子来向你展示什么是抽象语法树。对于表达式“3 - 2 * 4 + 5”，它的抽象语法树如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/54/43/54130252c985a51f8e08118375692743.jpg?wh=1920x1991\" alt=\"图片\"></p><p>递归的函数调用本质上也是一棵树（如果你对这句话感到费解，可能需要先学习下数据结构相关的知识。不过这里看不懂也没关系，不影响对这节课主要内容的理解）。如果我们把递归函数的轨迹都使用一种结构记录下来，就可以得到这棵树。接下来，我直接通过代码来展示如何做这种记录，以及如何产生抽象语法树。</p><p>第一步，先定义抽象语法树的结点。</p><p>从上图中可知，一个表达式中包含了加减乘除运算的结点和代表整数的结点。所以，我们可以这样定义AST结点：</p><pre><code class=\"language-plain\">// ast.h\nenum NodeType {\n&nbsp; &nbsp; NT_INT,\n\n&nbsp; &nbsp; NT_ADD,\n&nbsp; &nbsp; NT_SUB,\n&nbsp; &nbsp; NT_MUL,\n&nbsp; &nbsp; NT_DIV\n};\n\ntypedef struct {\n&nbsp; &nbsp; enum NodeType ntype;\n} Node;\n\ntypedef struct {\n&nbsp; &nbsp; Node parent;\n&nbsp; &nbsp; int value;\n} IntNode;\n\ntypedef struct {\n&nbsp; &nbsp; Node parent;\n&nbsp; &nbsp; Node* left;\n&nbsp; &nbsp; Node* right;\n} BinOpNode;\n</code></pre><p>第二步，定义创建这些结点的函数：</p><pre><code class=\"language-plain\">Node* create_int(int v) {\n&nbsp; &nbsp; IntNode* in = (IntNode*)malloc(sizeof(IntNode));\n&nbsp; &nbsp; in-&gt;value = v;\n&nbsp; &nbsp; in-&gt;parent.ntype = NT_INT;\n&nbsp; &nbsp; return (Node*) in;\n}\n\nNode* create_binop(enum TokenType tt, Node* left, Node* right) {\n&nbsp; &nbsp; BinOpNode* node = (BinOpNode*) malloc(sizeof(BinOpNode));\n&nbsp; &nbsp; node-&gt;left = left;\n&nbsp; &nbsp; node-&gt;right = right;\n&nbsp; &nbsp; if (tt == TT_ADD) {\n&nbsp; &nbsp; &nbsp; &nbsp; node-&gt;parent.ntype = NT_ADD;\n&nbsp; &nbsp; }\n&nbsp; &nbsp; else if (tt == TT_SUB) {\n&nbsp; &nbsp; &nbsp; &nbsp; node-&gt;parent.ntype = NT_SUB;\n&nbsp; &nbsp; }\n&nbsp; &nbsp; else if (tt == TT_DIV) {\n&nbsp; &nbsp; &nbsp; &nbsp; node-&gt;parent.ntype = NT_DIV;\n&nbsp; &nbsp; }\n&nbsp; &nbsp; else if (tt == TT_MUL) {\n&nbsp; &nbsp; &nbsp; &nbsp; node-&gt;parent.ntype = NT_MUL;\n&nbsp; &nbsp; }\n\n&nbsp; &nbsp; return (Node*) node;\n}\n</code></pre><p>第三步，我们再把文法分析的过程从直接计算值改成创建抽象语法树结点：</p><pre><code>/* 表达式对应的函数 */\nNode* expr() {\n    Node* a = NULL, *b = NULL;\n    a = term();\n\n    while (t-&gt;_type == TT_ADD || t-&gt;_type == TT_SUB) {\n        if (t-&gt;_type == TT_ADD) {\n            t = next_token();\n            b = term();\n            /* 这里不再是直接计算，而是生成一个语法树结点 */\n            a = create_binop(TT_ADD, a, b);\n        }\n        else if (t-&gt;_type == TT_SUB) {\n            t = next_token();\n            b = term();\n            a = create_binop(TT_SUB, a, b);\n        }\n    }\n\n    return a;\n}\n\n/* 项的规则 */\nNode* term() {\n    Node* a = NULL, *b = NULL;\n    a = factor();\n\n    while (t-&gt;_type == TT_MUL || t-&gt;_type == TT_DIV) {\n        if (t-&gt;_type == TT_MUL) {\n            t = next_token();\n            b = factor();\n            a = create_binop(TT_MUL, a, b);\n        }\n        else if (t-&gt;_type == TT_DIV) {\n            t = next_token();\n            b = factor();\n            a = create_binop(TT_DIV, a, b);\n        }\n    }\n\n    return a;\n}\n\n/* 因子的规则 */\nNode* factor() {\n    if (t-&gt;_type == TT_INTEGER) {\n        /* 创建一个代表整型的语法树结点 */\n        Node* a = create_int(t-&gt;_value._int);\n        t = next_token();\n        return a;\n    }\n    else if (t-&gt;_type == TT_LEFT_PAR) {\n        t = next_token();\n        Node* a = expr();\n        if (!match(TT_RIGHT_PAR))\n            return NULL;\n        else\n            return a;\n    }\n    else {\n        printf(&quot;Parse Error\\n&quot;);\n        return NULL;\n    }\n}\n</code></pre><p>这个过程是比较简单的，我就不再解释了，你可以参考我加的注释来理解。最后，我们可以再使用二叉树的遍历来验证我们创建的抽象语法树是不是正确的：</p><pre><code class=\"language-plain\">void post_order(Node* root) {\n&nbsp; &nbsp; if (root-&gt;ntype == NT_INT) {\n&nbsp; &nbsp; &nbsp; &nbsp; printf(\"%d \", ((IntNode*)root)-&gt;value);\n&nbsp; &nbsp; }\n&nbsp; &nbsp; else {\n&nbsp; &nbsp; &nbsp; &nbsp; BinOpNode* binop = (BinOpNode*)root;\n&nbsp; &nbsp; &nbsp; &nbsp; post_order(binop-&gt;left);\n&nbsp; &nbsp; &nbsp; &nbsp; post_order(binop-&gt;right);\n\n&nbsp; &nbsp; &nbsp; &nbsp; enum NodeType tt = root-&gt;ntype;\n&nbsp; &nbsp; &nbsp; &nbsp; if (tt == NT_ADD) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; printf(\"+ \");\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; else if (tt == NT_SUB) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; printf(\"- \");\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; else if (tt == NT_DIV) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; printf(\"/ \");\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; else if (tt == NT_MUL) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; printf(\"* \");\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; }\n}\n</code></pre><p>运行这个程序，就会发现我们已经成功地把中缀表达式转成了后缀表达式输出。后缀表达式也叫作逆波兰序表达式。如果上述代码不使用后序遍历，而是使用前序遍历，程序的输出就是前缀表达式，你可以自己尝试一下。</p><p>更进一步，如果我们在对这个抽象语法树进行遍历的时候，同时进行求值和计算，这个过程就叫作<strong>解释执行</strong>。不同于编译执行，解释执行往往没有经过比较好的优化，所以它的执行效率往往比较低。</p><p>到这里，关于文法分析的知识我就介绍完了。</p><h2>总结</h2><p>这节课，我讲解了编译过程中的一个重要步骤，那就是文法分析。文法是一套语言产生的规则，根据文法规则来判断源文件是否符合文法的过程就是文法分析。</p><p>文法分析的方法主要分为两种，分别是自顶向下和自底向上的分析方法。其中，自底向上主要采用归约的办法，将终结符归约成顶级的非终结符，多数自动化工具都是采用了这种方法。而自顶向下的分析方法则比较简单明了，更符合人的直观思维。</p><p>自顶向下的分析方法简单地将非终结符转换成函数，把或结构转换成if语句，把多项结构转换成while语句。所以这种分析方法是不能处理左递归的，但是所有的左递归文法都可以按一定的模式转换成右递归的。</p><p>在编译器里，文法分析并不是直接对源文件进行求值运算的，而是会生成抽象语法树。它本质上是一棵树，我们可以通过遍历这棵树，对它进行各种变换，比如转换成字节码，或者其他的中间表示，等等。这些内容我将会在下节课进行讲解。</p><h2>课后练习</h2><p>你可以尝试定义C语言的变量定义、分支语句和循环语句的文法，并将它实现出来。这些完成以后，你基本上就可以得到一个可执行简单语句的小型C语言解释器了。完整的代码我放在了gitee上，供你参考。<a href=\"https://gitee.com/hinus/codelet/tree/37e0865adbd42cce387d02286f5dbea1f753b05c/compiler\">这里</a>是if语句的实现，<a href=\"https://gitee.com/hinus/codelet/tree/e1d6aea2ca21a92b756019eeae0e6c42e6922758/compiler\">这里</a>是变量定义和赋值的实现。</p><p>这节课就到这里了，如果今天的内容让你有所收获，欢迎把它分享给你的朋友。下一次的加餐，我将继续按顺序讲解 C 语言程序编译的基本步骤，我们到时候见！</p>","neighbors":{"left":{"article_title":"大咖助阵｜海纳：C 语言是如何编译执行的？（一）","id":491633},"right":{"article_title":"加餐 | 和 C 语言相比，C++ 有哪些不同的语言特性？","id":494537}}},{"article_id":494537,"article_title":"加餐 | 和 C 语言相比，C++ 有哪些不同的语言特性？","article_content":"<p>你好，我是于航。</p><p>在之前的<a href=\"https://time.geekbang.org/column/article/484465\">春节策划三</a>里，我为你介绍了如何使用 C++ 语言来实现一个简单的 JIT 编译器，你能够从中大致感受到 C 和 C++ 这两种语言在使用上的差异。那么这次的加餐，我就用专门的一讲，来为你介绍 C++ 与 C 相比究竟有何不同。</p><p>C 语言的语法简单，且贴近底层硬件。使用它，我们能在最大程度上为程序提供较高的运行时性能。但在 C 语言诞生的几年后，它开始逐渐无法满足人们在构建应用程序时对编码范式的需求。而一门基于 C 语言构建的，名为 C++ 的语言便由此诞生。作为一个 C 语言使用者，也许你还在犹豫要不要把 C++ 作为下一门继续学习的编程语言，那么相信在学习完这一讲后，你会有进一步的思考。</p><p>在具体比较 C 和 C++ 之前，我们先来看看 C++ 的发展历史和应用场景，从整体视角对它有一个了解。</p><h2>C++ 发展简史</h2><p>丹麦计算机科学家 Bjarne Stroustrup（下面简称 BS）从 1979 年开始研发 C++ 这门编程语言。BS 于 1979 年从剑桥大学取得博士学位，在撰写博士论文的过程中，他发现 Simula 语言（该语言被认为是第一个面向对象的编程语言）的某些特性对大型软件的开发十分有帮助，但遗憾的是，该语言本身的执行效率却并不高。</p><p>毕业之后，他前往位于美国新泽西州的贝尔实验室，以研究员的身份开始了职业生涯。在工作期间，为了解决遇到的一个棘手问题，BS 决定选择当时被广泛使用的，具备较高性能和兼容性的 C 语言作为基准语言，开始为其添加与 Simula 类似的，面向对象的相关特性。通过直接修改 C 编译器，包括类、继承、默认参数等在内的一系列新特性被“整合”到了 C 语言中，这一新语言在当时也被直观地称为 “C with Classes”。</p><!-- [[[read_end]]] --><p>而直到 1983 年，BS 才将 “C with Classes” 正式更名为 C++，并开始为它添加虚函数、运算符重载、引用类型等更多新特性。同时，BS 也为该语言单独开发了第一款专用的编译器 Cfront。该编译器可用于将 C++ 代码转译为 C 代码，而这些 C 代码需要再通过其他 C 编译器的处理后，才能够生成最终的目标文件。</p><p>在接下来的日子里，C++ 开始了不断“进化”的过程。这里，我将其中的一些重要时间节点整理如下：</p><ul>\n<li>1984 年，BS 为 C++ 添加了第一个流式的 IO 操作库；</li>\n<li>1985 年，第一本介绍 C++ 的权威书籍 “The C++ Programming Language” 第一版发布；</li>\n<li>1989 年，Cfront 2.0 发布，该版本为 C++ 语言新增了多重继承、抽象类、静态成员函数等特性；</li>\n<li>1991 年，ISO C++ 委员会成立，C++ 开始进入语言标准化时代；</li>\n<li>1998 年，C++98 发布，该版本新增了 RTTI、模板初始化、类型转换操作符等语言特性。同时，标准库也增加了对智能指针，以及 STL 相关容器和算法的支持；</li>\n<li>2003 年，C++03 发布，该版本修复了 98 中的一些重要 BUG；</li>\n<li>2011 年，C++11 发布，该版本新增了很多重要的语言特性。可以说，C++11 仍然是目前工业界内使用最多的 C++ 语言版本之一。</li>\n</ul><p>在随后的十年里，C++14、17，乃至 20 标准也都相继发布，而下一代的 C++23 标准也在酝酿之中。这些标准版本的迭代，为 C++ 语言注入了大量新鲜“血液”，使得 C++ 变得越来越复杂和庞大（C++20 标准的文档手册已经超过了 1800 页）。好在 C++ 也足够灵活，你可以仅使用它的一小部分重要特性来完成所有基本工作。而如果你想要进一步优化或抽象程序，C++ 也同样具备这些能力，只不过这也会带来相应的使用成本提高。</p><p>从整体发展趋势来看，C++ 旨在成为一个大而全的，支持多范式的系统级编程语言。</p><h2>C++ 应用场景</h2><p>C++ 与 C 在应用场景上有很大的重合，它们都可以应用于那些需要高运行时性能，或与底层硬件打交道的场景中。但总的来看，C++ 赋予了开发者进一步抽象程序逻辑的能力。但有些时候，这些抽象也会导致编译器无法保证其编译产物在机器代码层面能够获得完全一致的表现。</p><p>因此，对于某些较低层次的软件实现（如驱动程序），C 仍然是主流开发语言。同样地，当 C++ 需要与其他编程语言进行“通信”时（如 FFI），它们通常都会使用 <code>extern \"C\" {}</code> 等方式，来将两方的接口调用规范限定为 C 语言的 ABI，以在最大程度上保证兼容性。</p><p>不过我们也知道，无论如何，抽象都是会带来成本的。因此，在一些对程序性能有着极端要求的场景下，C 语言通常会表现得更好，更稳定。但另一方面，相较于 C 语言，<strong>C++ 往往可以带来更高的开发效率和可维护性</strong>。比如，C++ 在 STL 中为我们提供了可以直接使用的各种容器类型，如大小可自动伸缩的 <code>std::vector</code> 。但在 C 语言中，类似的数据结构则需要我们自行构建。因此，具体应该选择 C 还是 C++，我们就要视情况而定了。</p><p>除此之外，使用 C++ 构建的知名开源项目也有很多，比如 JavaScript 引擎 V8、浏览器引擎 Chromium、LLVM Compiler 套件、openJDK，等等。C++ 在 2022 年 3 月份公布的 TIOBE 榜单上位列第 4 名（C 语言为第 2 名），它在工程领域的使用人数之多和应用范围之广毋庸置疑。</p><p>接下来，我们具体看看在语言特性方面，C++ 跟 C 究竟有哪些不同。</p><h2>C++ 和 C 在语言特性上的不同</h2><p>需要注意的是，C++ 并非完全支持 C 语言的所有语法形式。比如，C++ 会执行比 C 更严格的类型规则检查和初始化要求。举个例子，下面这段代码是合法的 C 代码，但无法被 C++ 编译器正常编译：</p><pre><code class=\"language-c++\">void foo(void) {\n&nbsp; void *ptr;\n&nbsp; int *i = ptr;\n}\n</code></pre><p>除此之外，在编码体验上，C++ 也为我们提供了更多易用的语言能力。下面我们以 C++11 标准为例，来看看相较于 C 语言，C++ 有哪些完全不同的特性。</p><h3>类</h3><p>正如 C++ 的前身 “C with Classes” 的名字所表达的那样，C++ 引入了可用于支持面向对象（OOP）编程的相关特性和语法元素，比如类、继承、虚函数，等等。虽然在 C 中，我们也可以模拟 OOP 这种编程范式，但由于缺少语言层面的相关支持，能够实现的功能有限。且编译器对类定义、继承关系及访问权限等方面的检查往往也不够严格。而 C++ 则直接从语言层面入手解决了这个问题。</p><p>这里，我们可以通过下面这段代码，直观感受下 C++ 中与此相关的语法形式。限于篇幅，我不会完整介绍其中使用到的每一个 C++ 特性，但你可以参考注释信息来理解每一段代码的具体作用。</p><pre><code class=\"language-c++\">#include &lt;iostream&gt;\nenum class VehicleType {  // 枚举类；\n&nbsp; SUV, MPV, CAR\n};\nclass Vehicle {  // Vehicle 基类，属性默认私有；\n&nbsp; VehicleType type = VehicleType::CAR;\n&nbsp; int seats = 5;\n&nbsp;public:\n&nbsp; Vehicle() = default;  // 默认构造函数；\n&nbsp; Vehicle(VehicleType type, int seats) : type(type), seats(seats) {}  // 普通构造函数；\n&nbsp; Vehicle(const Vehicle&amp; v) { type = v.type; seats = v.seats; }  // 拷贝构造函数；\n&nbsp; void spec(void) {  // 成员函数；\n&nbsp; &nbsp; std::cout &lt;&lt; \"Vehicle has \" &lt;&lt; seats &lt;&lt; \" seats\" &lt;&lt; std::endl;\n&nbsp; }\n};\nstruct Car : Vehicle {  // 派生类 Car，继承自 Vehicle；\n&nbsp; Car() = default;\n&nbsp; Car(int seats) : Vehicle(VehicleType::CAR, seats) {}\n&nbsp; Car(const Car&amp; c) : Vehicle(c) {}&nbsp;\n&nbsp; void stop(void) {  // 成员函数；\n&nbsp; &nbsp; std::cout &lt;&lt; \"Car stops immediately!\" &lt;&lt; std::endl;\n&nbsp; }\n&nbsp; void stop(int delaySecs) {  // 重载的成员函数；\n&nbsp; &nbsp; std::cout &lt;&lt; \"Car stops after \" &lt;&lt; delaySecs &lt;&lt; \" seconds!\" &lt;&lt; std::endl;\n&nbsp; }\n};\nint main(void) {\n&nbsp; Car carA { 7 };  // 初始化一个 Car 类型对象；\n&nbsp; auto carB = carA;  // 拷贝对象 carA；\n&nbsp; carB.spec();\n&nbsp; carA.stop(10);\n&nbsp; return 0;\n}\n</code></pre><p>可以看到，我们分别在代码的第 5~15 行与 16~26 行定义了不同的两个类。其中，类 Car 继承自类 Vehicle。在每一个类定义中，我们都为它设置了相应的默认构造函数、拷贝构造函数，以及普通构造函数，这些函数控制着每一个类对象的具体构造过程。</p><p>除此之外，每一个类在其定义中也都包含有相应的成员属性与成员方法。这些成员反映了类对象的具体状态，以及对外的可交互接口。最后，在 main 函数中，通过列表初始化的方式，我们构造了类 Car 的一个对象，并完成了该对象的拷贝与成员函数的调用。</p><p>除此之外，C++ 中还有很多用于支持 OOP 的特性，如多重继承、移动构造函数、虚继承等等。这些特性都极大地增强了 C++ 支持 OOP 编程范式的灵活性。</p><h3>STL</h3><p>除了这些用于支持 OOP 的特性外，从标准库方面来看，C 与 C++ 的一个最大不同是，C++ 在其标准库中增加了对常用容器类型（如向量、双向链表、双端队列）的支持。这些数据结构与相应的算法、迭代器和适配器等，一同组成了“标准模板库（Standard Template Library，STL）”的主要内容。对这些容器类型的合理使用可以帮助我们大幅提高生产效率。</p><p>我们来看看下面的这个例子：</p><pre><code class=\"language-c++\">#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;algorithm&gt;\nint main(void) {\n&nbsp; std::vector&lt;int&gt; v { 1, 2, 3, 4, 5 };  // 构造一个 std::vector 对象 v；\n&nbsp; std::for_each(  // 对 v 的内容进行遍历；\n&nbsp; &nbsp; v.begin(),  // v 的首元素迭代器；\n&nbsp; &nbsp; v.end(),&nbsp;  // v 的尾后迭代器；\n&nbsp; &nbsp; [](int&amp; n){ std::cout &lt;&lt; n &lt;&lt; std::endl; });  // 遍历时对每个元素应用的 lambda 表达式；\n&nbsp; return 0;\n}\n</code></pre><p>这里，我们在代码的第 5 行创建了一个 <code>std::vector</code> 类型的对象 v。你可以将这个容器类型简单理解为<strong>一个大小动态可变且内存连续的数组</strong>。在代码的第 6~9 行，我们使用 STL 中的函数模板 <code>std::for_each</code> ，对该对象内的元素进行了遍历。该模板共接收三个参数，前两个参数用于通过迭代器来定位需要迭代的范围，最后一个参数则指明了对于每个迭代元素的具体处理方式。</p><p>在 C++ 中，STL 内所有标准容器类型的数据访问，都可以通过迭代器来进行。迭代器通过提供一组通用接口，屏蔽了不同容器在内部实现上的差异。</p><h3>模板</h3><p>模板是 C++ 中用于支持泛型编程的一个重要特性，C++ 编译器可以在编译时对每一处模板使用，根据其调用参数的实际情况进行自动推导和匹配。最简单的一种模板使用方式是函数模板，来看下面这个简单的例子：</p><pre><code class=\"language-c++\">#include &lt;iostream&gt;\ntemplate &lt;typename T&gt;  // 函数模板；\nT max(T x, T y) {&nbsp;\n&nbsp; return x &lt; y ? y : x;&nbsp;\n}&nbsp;\nint main(void) {\n&nbsp; double x = 10.1, y = 20.2;\n&nbsp; std::cout &lt;&lt; max(x, y) &lt;&lt; std::endl;  // 模板实例化并调用；\n&nbsp; return 0;\n}\n</code></pre><p>这里，我们构建了一个名为 max 的函数模板，该模板将根据输入的实参类型（即符号 T）来实例化相应的具体函数实现。函数在内部会判断两个输入参数的大小，并将其中较大者返回。通过这种方式，我们便能构建支持泛型参数的函数。</p><p>当然，模板的功能并不止于此。对于下面这个例子，编译器甚至可以在编译阶段就直接计算出给定参数 N 的阶乘，而不会带来任何运行时负载。</p><pre><code class=\"language-c++\">#include &lt;iostream&gt;\ntemplate &lt;unsigned N&gt;\nstruct factorial {\n&nbsp; static constexpr unsigned value = N * factorial&lt;N - 1&gt;::value;\n};\ntemplate &lt;&gt;\nstruct factorial&lt;0&gt; {\n&nbsp; static constexpr unsigned value = 1;\n};\nint main(void) {\n&nbsp; std::cout &lt;&lt; factorial&lt;4&gt;::value &lt;&lt; std::endl;\n&nbsp; return 0;\n}\n</code></pre><p>事实上，C++ 中的模板是图灵完备的，这意味着你可以单纯使用模板来构建一个编译时“运行”的图灵机。当然，前提是你觉得损失一定的代码可读性是能够接受的（笑）。</p><p>如今，这种使用模板进行编译期计算的编码方式已经“自成一派”，通常被称为“模板元编程（Template Programming，TMP）”。</p><h3>智能指针</h3><p>C++ 中智能指针的出现，主要是为了解决 C 编程中指针的使用不当所可能导致的内存泄露问题。智能指针借助 RAII 机制，使得堆上动态分配的资源可以随着栈对象的创建和销毁，相应地做出自动分配与回收。在这种情况下，我们只要使用方法得当，内存泄露问题便可以得到有效控制。来看下面这个例子：</p><pre><code class=\"language-c++\">#include &lt;iostream&gt;\n#include &lt;memory&gt;\n#include &lt;string&gt;\nstruct Person {\n&nbsp; std::string name;\n&nbsp; Person(const std::string&amp; name) : name(name) {}\n};\nvoid decorator(std::shared_ptr&lt;Person&gt; p) {\n&nbsp; p-&gt;name += \", handsome!\";  // 通过智能指针访问对象数据；\n}\nint main(void) {\n  // 创建一个指向 Person 类对象的，基于引用计数的智能指针(shared_ptr)；\n&nbsp; auto personPtr = std::make_shared&lt;Person&gt;(\"Jason\");\n&nbsp; decorator(personPtr);\n&nbsp; std::cout &lt;&lt; personPtr-&gt;name &lt;&lt; std::endl;\n}\n</code></pre><p>这里，我们首先在代码的第 4~7 行创建了名为 Person 的类。紧接着，在代码的第 13 行，我们通过名为 <code>std::make_shared</code> 的函数模板，在堆上创建了一个 Person 类的对象。函数在调用后会返回一个 <code>std::shared_ptr&lt;Person&gt;</code> 类型的智能指针，并将其指向该对象。<code>std::shared_ptr</code> 是一种基于引用计数的智能指针，它会通过计算所指向对象的实际被引用次数，来在适当时机自动将该对象资源回收。</p><h3>其他</h3><p>除了上面介绍的几个重要的 C++ 特性外，C++ 还有一些同样重要的语言功能，比如列表初始化、<code>decltype</code> 运算符、cast 类型转换操作符、右值引用，等等。不仅如此，如果上升到 C++20 标准，新加入的 “Big Four” 四大特性（Concepts、Ranges、Coroutines、Modules）也是我们不应错过的 C++ 重要改变。今天的介绍只是为你勾勒了一个 C++ 语言特性的大致图景，至于这些更加丰富的内容，就需要你在接下来的学习旅程中去自行探索了。</p><h2>总结</h2><p>这一讲，我向你简单介绍了 C++ 的发展历史和应用场景，然后主要带你看了 C 与 C++ 在语言特性上的一些重要区别。</p><p>C 是一种直接抽象于汇编语言之上的高性能编程语言。这种语言语法简单，且没有对机器代码做过多抽象，因此它被广泛应用在操作系统、编译器等需要保持足够性能，且 ABI 稳定可控的底层系统软件上。</p><p>和 C 相比，C++ 向上做了更多的抽象和扩展。C++ 提供了 STL、类、模板、智能指针等一系列新特性，这使其可以被应用在多种编程范式中。这些特性也使得基于 C++ 进行的大型软件开发变得更加高效，而且进一步避免了使用原始 C 时容易出现的内存泄露等问题。但有利就有弊，过多的新特性和抽象也使得 C++ 语言变得复杂和臃肿。所以每次面试候选人时，如果对方表示自己精通 C++，我通常也会心存疑虑。</p><p>总之，如果看完这一讲后你对 C++ 产生了一些兴趣，那么你可以在 C 语言的基础上继续对它展开学习。但是，是否要在工作项目中使用它，还需要你从多方面衡量，视具体情况而定。</p><h2>思考题</h2><p>你之前使用过 C++ 吗？如果用过，你觉得这门语言有哪些优点和缺点呢？欢迎在评论区告诉我你的想法。</p><p>今天的课程到这里就结束了，希望可以帮助到你，也希望你在下方的留言区和我一起讨论。同时，欢迎你把这节课分享给你的朋友或同事，我们一起交流。</p>","neighbors":{"left":{"article_title":"大咖助阵｜海纳：C 语言是如何编译执行的？（二）","id":493848},"right":{"article_title":"大咖助阵｜海纳：C 语言是如何编译执行的？（三）","id":495829}}},{"article_id":495829,"article_title":"大咖助阵｜海纳：C 语言是如何编译执行的？（三）","article_content":"<p>你好，我是海纳。今天是“C 语言是如何编译执行的？”这一加餐系列的最后一讲。</p><p>一个编译器通常分为前端、中端和后端三个典型模块。前端主要包括词法分析和文法分析两个步骤，它的作用是把源文件转换成抽象语法树（Abstract Syntax Tree, AST）。在前面两期加餐中，我讲解了预处理、词法分析、文法分析的编译过程基本步骤，带你实现了一个小型 C 语言编译器前端。它将源代码翻译成了AST，而且支持了变量定义和赋值，if语句和while语句。</p><p>中端则主要是将AST转成中间表示（Intermediate Representation, IR），常见的中间表示有三地址码、基于图的静态单赋值表示等等，例如LLVM IR就是最常见的一种中间表示。编译器的优化主要集中在中端。</p><p>而后端的作用是将中间表示翻译成目标平台的机器码，并生成相应平台的可执行程序。机器码是由CPU指令集决定的，例如x86平台就要使用x86指令集，而arm64平台就应该使用aarch64指令集。华为的鲲鹏平台也是采用了aarch64指令集。可执行程序的格式则是由操作系统决定，例如在Windows系统上，可执行程序是PE格式的，exe文件或者dll文件都是PE格式；而Linux系统上，可执行程序则是ELF文件。</p><!-- [[[read_end]]] --><p>如果完全按顺序来的话，这节课应该继续介绍中端和后端。但是中端优化和后端代码生成这两个话题都涉及很多内容，展开来讲的话，往往需要一整本书的篇幅。为了帮你通过有限的篇幅快速理解编译器的结构，这节课我会介绍一种最简单的执行模型：基于栈的字节码和虚拟机。</p><h2>字节码和虚拟机</h2><p>和静态编译一样，字节码也是一种非常常见的策略。由于字节码具有跨平台的特性，所以它得到了广泛的普及，其中最有影响力的就是 Java 和 Python 字节码。“javac”这个工具会把Java源代码翻译成class文件，这个class文件就是字节码文件，它的代码部分全部由Java字节码组成。Python也是一样的，编译器也会先把py文件翻译成pyc文件，而pyc文件的代码部分则由Python字节码组成。</p><p>Java和Python的相似之处在于，它们都采用了一种基于栈的计算模型。我们来看下这个Python源文件：</p><pre><code class=\"language-plain\">a = 1\nb = 2\ndef foo(c):\n  return a + b + 3 * c\n</code></pre><p>如果使用dis方法对foo函数进行反编译，就会得到如下输出：</p><pre><code class=\"language-plain\">&gt;&gt;&gt; dis.dis(foo)\n&nbsp; 2&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;0 LOAD_GLOBAL&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0 (a)\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 3 LOAD_GLOBAL&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1 (b)\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 6 BINARY_ADD\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 7 LOAD_CONST&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;1 (3)\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;10 LOAD_FAST&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0 (c)\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;13 BINARY_MULTIPLY\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;14 BINARY_ADD\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;15 RETURN_VALUE\n</code></pre><p>其中LOAD_XX指令的作用是把值加载到栈顶。GLOBAL表示当前字节码加载的是全局变量，CONST代表常量，FAST代表局部变量。</p><p>BINARY_ADD的作用是把栈上的两个变量出栈，然后把这两个值相加的和再压入栈中，这是对两个值进行求和。BINARY_MULTIPLY的作用是对两个值求积。这个过程比较简单，我就不再画图表示了，你可以想象一下每执行一个字节码，栈会发生怎样的变化。欢迎在评论区交流你的想法。</p><p>上面提到的每一条指令，在文件中都有一个编号。还是以Python虚拟机为例，它的指令编码可以在<a href=\"https://gitee.com/sync_repo/cpython/blob/main/Include/opcode.h\">这里</a>查看。指令总数不超过256，所以可以使用一个字节进行编码，这就是<strong>字节码(bytecode)</strong>这个名称的由来。</p><p>无论是在 arm 平台还是 x86 平台上，也不管是在 macOS 还是 Linux 系统上，相同的源文件翻译成的字节码都是相同的。字节码文件会被虚拟机加载、解析并执行。就像每个CPU可以执行自己指令集中的指令一样，虚拟机一般是由静态编译语言（例如C/C++/Rust）实现的，它就像一个CPU一样，逐条执行字节码，而字节码可以看成是虚拟机的指令集。</p><p>显然，不同平台的差异被虚拟机屏蔽掉了。正如上面所说，这种屏蔽底层差别，向上提供统一的指令集的办法，就像一个虚拟的计算机。这也正是语言虚拟机名字的由来。</p><p>基于栈的字节码，核心操作无非是压栈和出栈，大多数指令的操作数都在栈上，带有操作数的指令最多只带有一个操作数。基于栈的字节码，其指令不带参数或者只带一个参数，无论是编译器的实现还是虚拟机的实现都很简单。</p><p>接下来，我们就具体研究一下如何从AST生成基于栈的字节码。</p><h2>生成字节码</h2><p>如果你对后缀表达式求值比较熟悉的话，就会发现，上述字节码的执行过程是和后缀表达式求值相对应的。而且，<a href=\"https://time.geekbang.org/column/article/493848\">上节课</a>我讲到了，对表达式的AST进行后序遍历就可以生成后缀表达式。其实，上节课的程序只要稍加修改就可以变成字节码的生成程序，具体如下所示：</p><pre><code class=\"language-plain\">void code_object_emit_code(CodeObject* co, Node* root, Context* context) {\n&nbsp; &nbsp; if (root-&gt;ntype == NT_INT) {\n&nbsp; &nbsp; &nbsp; &nbsp; byte param = (byte)code_object_find_constant_index(co, ((IntNode*)root)-&gt;value);\n&nbsp; &nbsp; &nbsp; &nbsp; code_object_append_bytecode(co, LOAD_CONST, param);\n&nbsp; &nbsp; }\n&nbsp; &nbsp; else if (root-&gt;ntype == NT_ASN) {\n&nbsp; &nbsp; &nbsp; &nbsp; AssignNode* node = (AssignNode*)root;\n&nbsp; &nbsp; &nbsp; &nbsp; code_object_emit_code(co, node-&gt;value, context);\n&nbsp; &nbsp; &nbsp; &nbsp; context-&gt;is_store = Store;\n&nbsp; &nbsp; &nbsp; &nbsp; code_object_emit_code(co, node-&gt;var, context);\n&nbsp; &nbsp; &nbsp; &nbsp; context-&gt;is_store = Load;\n&nbsp; &nbsp; }\n&nbsp; &nbsp; else if (root-&gt;ntype == NT_VAR) {\n&nbsp; &nbsp; &nbsp; &nbsp; VarNode* node = (VarNode*)root;\n&nbsp; &nbsp; &nbsp; &nbsp; if (context-&gt;is_store == Store) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; byte param = (byte)code_object_find_variable_index(co, node-&gt;name);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; code_object_append_bytecode(co, STORE_NAME, param);\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; else {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; byte param = (byte)code_object_find_variable_index(co, node-&gt;name);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; code_object_append_bytecode(co, LOAD_NAME, param);\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; }\n&nbsp; &nbsp; else if (root-&gt;ntype == NT_IF) {\n&nbsp; &nbsp; &nbsp; &nbsp; IfNode* node = (IfNode*)root;\n&nbsp; &nbsp; &nbsp; &nbsp; code_object_emit_code(co, node-&gt;cond, context);\n&nbsp; &nbsp; &nbsp; &nbsp; code_object_jump_false(co, IF_ELSE);\n&nbsp; &nbsp; &nbsp; &nbsp; code_object_emit_code(co, node-&gt;then_clause, context);\n&nbsp; &nbsp; &nbsp; &nbsp; code_object_jump(co, IF_END);\n&nbsp; &nbsp; &nbsp; &nbsp; code_object_bind(co, IF_ELSE);\n&nbsp; &nbsp; &nbsp; &nbsp; code_object_emit_code(co, node-&gt;else_clause, context);\n&nbsp; &nbsp; &nbsp; &nbsp; code_object_bind(co, IF_END);\n&nbsp; &nbsp; }\n&nbsp; &nbsp; else if (root-&gt;ntype == NT_WHILE) {\n&nbsp; &nbsp; &nbsp; &nbsp; code_object_bind(co, WHILE_HEAD);\n\n&nbsp; &nbsp; &nbsp; &nbsp; WhileNode* node = (WhileNode*)root;\n&nbsp; &nbsp; &nbsp; &nbsp; code_object_emit_code(co, node-&gt;cond, context);\n\n&nbsp; &nbsp; &nbsp; &nbsp; code_object_jump_false(co, WHILE_END);\n&nbsp; &nbsp; &nbsp; &nbsp; code_object_emit_code(co, node-&gt;body, context);\n&nbsp; &nbsp; &nbsp; &nbsp; code_object_jump(co, WHILE_HEAD);\n&nbsp; &nbsp; &nbsp; &nbsp; code_object_bind(co, WHILE_END);\n&nbsp; &nbsp; }\n&nbsp; &nbsp; else if (root-&gt;ntype == NT_LIST) {\n&nbsp; &nbsp; &nbsp; &nbsp; ListNode* node = (ListNode*)root;\n&nbsp; &nbsp; &nbsp; &nbsp; for (int i = 0; i &lt; node-&gt;length; i++) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; code_object_emit_code(co, node-&gt;array[i], context);\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; }\n&nbsp; &nbsp; else if (root-&gt;ntype == NT_PRINT) {\n&nbsp; &nbsp; &nbsp; &nbsp; code_object_emit_code(co, ((PrintNode*)root)-&gt;expr, context);\n&nbsp; &nbsp; &nbsp; &nbsp; code_object_append_bytecode(co, PRINT, 0);\n&nbsp; &nbsp; }\n&nbsp; &nbsp; else {\n&nbsp; &nbsp; &nbsp; &nbsp; BinOpNode* binop = (BinOpNode*)root;\n&nbsp; &nbsp; &nbsp; &nbsp; code_object_emit_code(co, binop-&gt;left, context);\n&nbsp; &nbsp; &nbsp; &nbsp; code_object_emit_code(co, binop-&gt;right, context);\n\n&nbsp; &nbsp; &nbsp; &nbsp; enum NodeType tt = root-&gt;ntype;\n&nbsp; &nbsp; &nbsp; &nbsp; byte param = 0;\n&nbsp; &nbsp; &nbsp; &nbsp; if (tt == NT_ADD) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; code_object_append_bytecode(co, BINARY_ADD, param);\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; else if (tt == NT_SUB) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; code_object_append_bytecode(co, BINARY_SUB, param);\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; else if (tt == NT_DIV) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; code_object_append_bytecode(co, BINARY_DIV, param);\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; else if (tt == NT_MUL) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; code_object_append_bytecode(co, BINARY_MUL, param);\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; else if (tt == NT_LT) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; code_object_append_bytecode(co, COMPARE, COMPARE_LT);\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; }\n}\n</code></pre><p>我知道，当你第一次读到这段代码的时候，内心一定是崩溃的。但不要害怕，其实用C语言写出来的代码比使用C++实现的访问者模式还要直观。接下来，我带着你一起来分析这段代码，你就会发现，这段程序的逻辑是简明直接的。</p><p>下面，我举四个例子来说明这段程序的工作原理。</p><p>先来看第一个例子，表达式“1+2”的AST如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/c4/21/c4da4610259aca163ef063ed064c0b21.jpg?wh=1920x1073\" alt=\"图片\"></p><p>code_object_emit_code 在访问加号结点时，会先访问它的左子树（代码第57行），再访问它的右子树（第58行），这将保证加法的两个操作数都在栈上。对于“1+2”这个例子，左子树是整型，所以程序会在常量池里找到整型的序号（第3行），把它作为LOAD_CONST的参数（第4行）。之所以使用常量池序号作为LOAD_CONST的参数，而不是直接使用整数，是因为参数是一个字节，而表示一个整数需要4个字节。这同时也意味着常量池的大小不能超过256。</p><p>综上所述，“1+2”这个表达式对应的字节码如下：</p><pre><code class=\"language-plain\">LOAD_CONST 0 # 代表数字1在常量池中的序号\nLOAD_CONST 1 # 代表数字2在常量池中的序号\nBINARY_ADD\n</code></pre><p>第二个例子是赋值语句“int a = b”，这条语句所产生的AST如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/30/50/30aae724700ee409e91530fefbccc250.jpg?wh=1920x1049\" alt=\"图片\"></p><p>从图中可以看出，赋值结点的左孩子和右孩子都是变量名，但这两个变量却是有所区别的。对变量a的访问，应该生成STORE指令，而对变量b的访问则应该生成LOAD指令。所以在这里我使用了一个Context变量，来指定<strong>当访问的是赋值语句的左端变量时，就使用STORE_NAME指令（第9、16、17行），如果是访问普通的变量，则使用LOAD_NAME指令（第20、21行）</strong>。</p><p>和访问常量类似，我在生成代码的时候，也引入一个变量表。变量表和常量表都是一个列表，这里你也可以把它设计成哈希表，以加快查找速度。但总之，这两个表都是一种容器。所以，“int a = b”这个赋值语句所对应的字节码是：</p><pre><code class=\"language-plain\">LOAD_NAME 0 # 变量 b 在变量表中的序号\nSTORE_NAME 1 # 变量 a 在变量表中的序号\n</code></pre><p>第三个例子是分支语句，代码“if (1 &lt; 2) { print(1); } else {print(2);}”，它的AST如下图所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/e3/8e/e3926015c433f7b230e934b5cf73218e.jpg?wh=2284x1435\" alt=\"\"></p><p>这里说明下，print是我为了方便打印值而引入的一种非常规手段。由于支持函数调用需要的基础设施太多，我不可能在这短短的几节课内讲清楚，所以就把print当成了关键字来处理。遇到Print结点时，生成PRINT指令即可（第52、53行）。</p><p>对于If结点，它的cond、then_clause、else_clause的访问都很简单。难就难在，当条件不成立时，控制流应该跳过then_clause，转而去执行else_clause，这需要通过jump语句实现。</p><p>代码的第27行就是这个思路的直接体现。第27行的作用是生成JUMP_IF_FALSE指令，也就是说cond条件的执行结果为false时，就进行跳转。但是跳转的目标是哪里呢？答案是在then_clause结束，else_clause开始之前。</p><p>但这时候我们就遇到问题了：在生成JUMP指令的时候，我们还不知道then_clause会产生多少字节码，也就是说，我们并不知道JUMP的目标地址在哪里。所以，在生成JUMP指令的时候，我们只能将目标地址空着（第27行），当目标地址确定了以后，再把目标地址回填到JUMP指令处，这正是bind函数所做的事情（第30行）。</p><p>相信你对这个过程已经不陌生了，因为这就是<strong>重定位（Relocation）</strong>所做的工作：把目标地址回填到JUMP、CALL等指令参数里。为了能够在重定位时正确地找到需要重定位的那条jump指令，我们必须要在code_object_jump_false里将这条jump指令的地址记录下来。这种用于辅助重定位的信息就是重定位信息（Reloc Info）。</p><p>所以，经过重定位以后，这个例子中的分支语句最终生成的字节码就是：</p><pre><code class=\"language-plain\">\tLOAD_CONST\t1\n\tLOAD_CONST\t2\n\tCOMPARE\t&lt;\n\tJUMP_IF_FALSE\t5\n\tLOAD_CONST\t1\n\tPRINT\n\tJUMP\t3\n\tLOAD_CONST\t2\n\tPRINT\n</code></pre><p>其中，第4行的字节码JUMP_IF_FALSE的作用就是让控制流向后跳5个字节。由于第5行的LOAD_CONST和第7行的JUMP都带有一个参数，所以跳5个字节，控制流就指向了第8行，而这正是else_clause开始的地方。</p><p>第7行的JUMP指令则是then_clause结束的地方，这就意味着当if条件为true时，else_clause就被跳过了。</p><p>最后一个例子是循环语句，代码“int i = 0; while (i &lt; 10) { i = i + 1; print(i); }”。循环语句和分支语句有相似之处，它也包含两个跳转：第一个是当条件不成立时，要跳过循环体，第二个是循环体结束处，应该再跳转回循环头继续下一次判断。所以第一个跳转是条件跳转，第二个跳转则是绝对跳转。</p><p>而这两种跳转，我们都已经支持了。但是循环语句有一个分支语句所没有的特点，那就是循环体内可能会出现break。当遇到break语句时，控制流就应该直接跳到循环体的结尾。而循环体内可能有多个break语句，这就要求我们要在每个break语句处都记录下需要重定位的地址，所以我把这些重定位信息使用一个双向链表记录在了一起。具体的代码我就不在这里展示了，你可以去<a href=\"https://gitee.com/hinus/codelet/blob/master/compiler/code.c\">gitee</a>上查看。</p><p>同样地，最后一个例子的字节码展示如下：</p><pre><code class=\"language-plain\">\tLOAD_CONST\t0\n\tSTORE_NAME\ti\n\tLOAD_NAME\ti\n\tLOAD_CONST\t10\n\tCOMPARE\t&lt;\n\tJUMP_IF_FALSE\t12\n\tLOAD_NAME\ti\n\tLOAD_CONST\t1\n\tBINARY_ADD\n\tSTORE_NAME\ti\n\tLOAD_NAME\ti\n\tPRINT\n\tJUMP\t-20\n</code></pre><p>通过这四个例子，我就把最基本的变量、分支和循环全部实现了。接下来，我们就再看一下这些字节码是如何实现的。也就是说，我们需要再研究一下虚拟机的具体实现。</p><h2>虚拟机的实现</h2><p>跟编译器的实现相比，虚拟机的实现更加直观：通过一个循环，不断地取出字节码，然后按照这个字节码的语义对栈进行操作。</p><p>按照上面的分析，我在这里展示一种常见的虚拟机实现：</p><pre><code class=\"language-plain\">void interpret(VirtualMachine* vm, CodeObject* co) {\n&nbsp; &nbsp; for (int i = 0; i &lt; co-&gt;bytecodes-&gt;length; i++) {\n&nbsp; &nbsp; &nbsp; &nbsp; byte opcode = co-&gt;bytecodes-&gt;array[i];\n&nbsp; &nbsp; &nbsp; &nbsp; byte param = 0;\n&nbsp; &nbsp; &nbsp; &nbsp; int u, v;\n\n&nbsp; &nbsp; &nbsp; &nbsp; if (opcode &gt;= OP_CODE_PARAMETER) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; param = co-&gt;bytecodes-&gt;array[++i];\n&nbsp; &nbsp; &nbsp; &nbsp; }\n\n&nbsp; &nbsp; &nbsp; &nbsp; switch(opcode) {\n&nbsp; &nbsp; &nbsp; &nbsp; case LOAD_CONST:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; PUSH(co-&gt;constant_pool-&gt;array[param]);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; break;\n&nbsp; &nbsp; &nbsp; &nbsp; case STORE_NAME:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; u = POP();\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; vm-&gt;var_table-&gt;array[param] = u;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; break;\n&nbsp; &nbsp; &nbsp; &nbsp; case LOAD_NAME:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; PUSH(vm-&gt;var_table-&gt;array[param]);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; break;\n&nbsp; &nbsp; &nbsp; &nbsp; case BINARY_ADD:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; u = POP();\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; v = POP();\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; PUSH(u+v);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; break;\n&nbsp; &nbsp; &nbsp; &nbsp; case PRINT:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; u = POP();\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; printf(\"%d\\n\", u);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; break;\n&nbsp; &nbsp; &nbsp; &nbsp; case COMPARE:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; u = POP();\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; v = POP();\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (param == COMPARE_LT) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (v &lt; u) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; PUSH(1);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; else {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; PUSH(0);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; break;\n&nbsp; &nbsp; &nbsp; &nbsp; case JUMP_IF_FALSE:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; u = POP();\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (!u) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; i += param;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; break;\n&nbsp; &nbsp; &nbsp; &nbsp; case JUMP:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; i += param;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; break;\n&nbsp; &nbsp; &nbsp; &nbsp; default:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; printf(\"Error, unrecognized bytecode: %d\\n\", opcode);\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; }\n}\n</code></pre><p>这里，我以JUMP_IF_FALSE为例进行讲解：虚拟机先从栈顶得到一个元素，再判断这个元素是否为false。如果不是false，则什么都不做，直接执行下一条字节码；但如果为false，就会给变量i加上这个跳转指令的参数。这样一来，i 就变成跳转的目标地址了。</p><p>其他字节码都比较简单，我就不再一一解释了，你可以在<a href=\"https://gitee.com/hinus/codelet/tree/f6481d91d51df7bd59d16213e9dc1748fb05af84\">这里</a>查看全部代码。</p><h2>总结</h2><p>在这节课里，我介绍了一种最简单的执行模型：基于栈的字节码和虚拟机。</p><p>把AST转换成字节码的过程，主要是通过后序遍历整个语法树，分别生成相应的字节码。其中，最难的部分是重定位的过程。重定位是指<strong>指令在生成的时候，跳转的目标地址尚不能确定，只能先把这条指令记录下来，当目标地址确定以后<strong><strong>再</strong></strong>将地址回填到指令参数里</strong>。用于记录指令的信息称为重定位信息。条件语句的重定位信息只要有一条就够了，但循环语句因为存在break语句，所以重定位信息可能有多条，这就需要使用容器对它们进行管理。</p><p>字节码的指令不会超过256个，一个字节足够编码所有指令。另外，基于栈的字节码还有一个优势，就是参数都在栈上，所以指令参数的个数很少，最多只有一个参数，这就让字节码变得简洁，也让编译器的实现和虚拟机的实现都变得简单很多。</p><p>最后，我还展示了一个真实的虚拟机例子。典型的虚拟机的结构就是使用循环语句不断地取出字节码进行解析执行，循环体里包含一个巨大的switch-case。Python虚拟机和Java虚拟机都有类似的实现。</p><p>到这里，关于 C 语言编译过程的系列加餐先暂告一段落了。最后想说的是，编译器的设计是一个十分复杂的工程，因此很难在短短几篇文章中把中端后端的相关知识全部介绍给你。希望以后还有机会能在课程里带你从头开始实现一个完整的编译器。</p><p>青山不改，绿水长流，后会有期。我们有机会再见。</p>","neighbors":{"left":{"article_title":"加餐 | 和 C 语言相比，C++ 有哪些不同的语言特性？","id":494537},"right":{"article_title":"大咖助阵｜Tony Bai：Go 程序员拥抱 C 语言简明指南","id":500145}}},{"article_id":500145,"article_title":"大咖助阵｜Tony Bai：Go 程序员拥抱 C 语言简明指南","article_content":"<blockquote>\n<p>你好，我是于航。这一讲是一期大咖加餐，我们邀请到了 Tony Bai 老师，来跟你聊聊 C 语言的一个优秀“后辈”，Go 语言的故事。<br>\nGo 在语法上跟 C 类似，但它却通过提供垃圾回收机制，从侧面解决了 C 程序容易发生内存泄露的问题，进而使得程序的构建变得更加简单。除此之外，Go 还提供了大量用于编写并发程序的内置工具和库，因此它被大量应用于构架需要满足高并发性能的软件中，比如你最熟悉的 Kubernetes。<br>\n通过这一讲加餐，你可以了解到 C 与 Go 这两种语言之间的相似性和区别，相信你一定能有所收获。</p>\n</blockquote><p>你好，我是Tony Bai。</p><p>也许有同学对我比较熟悉，看过我在极客时间上的专栏<a href=\"https://time.geekbang.org/column/intro/100093501?tab=catalog\">《Tony Bai · Go 语言第一课》</a>，或者是关注了我的博客。那么，作为一个Gopher，我怎么跑到这个C语言专栏做分享了呢？其实，在学习Go语言并成为一名Go程序员之前，我也曾是一名地地道道的C语言程序员。</p><p>大学毕业后，我就开始从事C语言后端服务开发工作，在电信增值领域摸爬滚打了十多年。不信的话，你可以去翻翻<a href=\"https://tonybai.com\">我的博客</a>，数一数我发的C语言相关文章是不是比关于Go的还多。一直到近几年，我才将工作中的主力语言从C切换到了Go。不过这并不是C语言的问题，主要原因是我转换赛道了。我目前在智能网联汽车领域从事面向云原生平台的先行研发，而在云原生方面，新生代的Go语言有着更好的生态。</p><!-- [[[read_end]]] --><p>不过作为资深C程序员，C语言已经在我身上打下了深深的烙印。虽然Go是我现在工作中的主力语言，但我仍然会每天阅读一些C开源项目的源码，每周还会写下数百行的C代码。在一些工作场景中，特别是在我参与先行研发一些车端中间件时，C语言有着资源占用小、性能高的优势，这一点是Go目前还无法匹敌的。</p><p>正因为我有着 C 程序员和 Go 程序员的双重身份，接到这个加餐邀请时，我就想到了一个很适合聊的话题——在 Gopher（泛指Go程序员）与 C 语言之间“牵线搭桥”。在这门课的评论区里，我看到一些同学说，“正是因为学了Go，所以我想学好C”。如果你也对Go比较熟悉，那么恭喜你，这篇加餐简直是为你量身定制的：一个熟悉 Go 的程序员在学习C时需要注意的问题，还有可能会遇到的坑，我都替你总结好了。</p><p><strong>当然，我知道还有一些对 Go 了解不多的同学，看到这里也别急着退出去。</strong>因为 C 和 Go 这两门语言的比较，本身就是一个很有意思的话题。今天的加餐，会涉及这两门语言的异同点，通过对 C 与 Go 语言特性的比较，你就能更好地理解“C 语言为什么设计成现在这样”。</p><h2>C语言是现代IT工业的根基</h2><p>在比较 C 和 Go 之前，先说说我推荐Gopher学C的最重要原因吧：用一句话总结，C语言在IT工业中的根基地位，是Go和其他语言目前都无法动摇的。</p><p>C语言是由美国贝尔实验室的丹尼斯·里奇（Dennis Ritchie）以Unix发明人肯·汤普森（Ken Thompson）设计的B语言为基础而创建的高级编程语言。诞生于上个世纪（精确来说是1972年）的它，到今年（2022年）已到了“知天命”的半百年纪。年纪大、设计久远一直是“C语言过时论”兴起的根源，但如果你相信这一论断，那就大错特错了。下面，我来为你分析下个中缘由。</p><p>首先，我们说说C语言本身：<strong>C语言一直在演进，从未停下过脚步</strong>。</p><p>虽然C语言之父丹尼斯·里奇不幸于2011年永远地离开了我们，但C语言早已成为ANSI（美国国家标准学会）标准以及ISO/IEC（国际标准化组织和国际电工委员会）标准，因此其演进也早已由标准委员会负责。我们来简单回顾一下C语言标准的演进过程：</p><ul>\n<li>1989年，ANSI发布了首个C语言标准，被称为C89，又称ANSI C。次年，ISO和IEC把ANSI C89标准定为C语言的国际标准（ISO/IEC 9899:1990），又称C90，它也是C语言的第一个官方版本；</li>\n<li>1999年，ISO和IEC发布了<a href=\"https://www.iso.org/standard/29237.html\">C99标准(ISO/IEC 9899:1999)</a>，它是C语言的第二个官方版本；</li>\n<li>2011年，ISO和IEC发布了<a href=\"https://www.iso.org/standard/57853.html\">C11标准(ISO/IEC 9899:2011)</a>，它是C语言的第三个官方版本；</li>\n<li>2018年，ISO和IEC发布了<a href=\"https://www.iso.org/standard/74528.html\">C18标准(ISO/IEC 9899:2018)</a>，它是C语言的第四个官方版本。</li>\n</ul><p>目前，ISO/IEC标准化委员会正在致力于C2x标准的改进与制定，预计它会在2023年发布。</p><p>其次，<strong>时至今日，C语言的流行度仍然非常高</strong>。</p><p>著名编程语言排行榜TIOBE的数据显示，各大编程语言年度平均排名的总位次，C语言多年来高居第一，如下图（图片来自<a href=\"https://www.tiobe.com/tiobe-index\">TIOBE</a>）所示：</p><p><img src=\"https://static001.geekbang.org/resource/image/69/8f/696192949279c8bfde8554b77191be8f.png?wh=1920x797\" alt=\"图片\"></p><p>这说明，无论是在过去还是现在，C语言都是一门被广泛应用的工业级编程语言。</p><p>最后，也是最重要的一点是：<strong>C语言是现代IT工业的根基</strong>，我们说C永远不会退出IT行业舞台也不为过。</p><p>如今，无论是普通消费者端的Windows、macOS、Android、苹果iOS，还是服务器端的Linux、Unix等操作系统，亦或是各个工业嵌入式领域的操作系统，其内核实现语言都是C语言。互联网时代所使用的主流Web服务器，比如 Nginx、Apache，以及主流数据库，比如MySQL、Oracle、PostgreSQL等，也都是使用C语言开发的杰作。可以说，现代人类每天都在跟由C语言实现的系统亲密接触，并且已经离不开这些系统了。回到我们程序员的日常，Git、SVN等我们时刻在用的源码版本控制软件也都是由C语言实现的。</p><p>可以说，C语言在IT工业中的根基地位，不光Go语言替代不了，C++、Rust等系统编程语言也无法动摇，而且不仅短期如此，长期来看也是如此。</p><p>总之，C语言具有紧凑、高效、移植性好、对内存的精细控制等优秀特性，这使得我们在任何时候学习它都不会过时。不过，我在这里推荐Gopher去了解和系统学习C语言，其实还有另一个原因。我们继续往下看。</p><h2>C 与 Go 的相通之处：Gopher拥抱 C 语言的“先天优势”</h2><p>众所周知，Go 是在 C 语言的基础上衍生而来的，二者之间有很多相通之处，因此 Gopher 在学习 C 语言时是有“先天优势”的。接下来，我们具体看看 C 和 Go 的相通之处有哪些。</p><h3>简单且语法同源</h3><p>Go语言以简单著称，而作为<strong>Go先祖</strong>的C语言，入门门槛同样不高：Go有25个关键字，C有32个关键字（C89标准），简洁程度在伯仲之间。C语言曾长期作为高校计算机编程教育的首选编程语言，这与C的简单也不无关系。</p><p>和Go不同的是，C语言是一个<strong>小内核、大外延</strong>的编程语言，其简单主要体现在小内核上了。这个“小内核”包括C基本语法与其标准库，我们可以快速掌握它。但需要注意的是，与Go语言“开箱即用、内容丰富”的标准库不同，<a href=\"https://en.wikipedia.org/wiki/C_standard_library\">C标准库</a>非常小（在C11标准之前甚至连thread库都不包含），所以掌握“小内核”后，在LeetCode平台上刷题是没有任何问题的，但要写出某一领域的工业级生产程序，我们还有很多外延知识技能要学习，比如并发原语、操作系统的系统调用，以及进程间通信等。</p><p>C语言的这种简单很容易获得Gopher们的认同感。当年Go语言之父们在设计Go语言时，也是主要借鉴了C语言的语法。当然，这与他们深厚的C语言背景不无关系：肯·汤普森（Ken Thompson）是Unix之父，与丹尼斯·里奇共同设计了C语言；罗博·派克（Rob Pike）是贝尔实验室的资深研究员，参与了Unix系统的演进、Plan9操作系统的开发，还是UTF-8编码的发明人；罗伯特·格瑞史莫（Robert Griesemer）也是用C语言手写Java虚拟机的大神级人物。</p><p>Go的第一版编译器就是由肯·汤普森（Ken Thompson）用C语言实现的。并且，Go语言的早期版本中，C代码的比例还不小。以Go语言发布的第一个版本，<a href=\"https://github.com/golang/go/releases/tag/go1\">Go 1.0版本</a>为例，我们通过<a href=\"https://gitlab.com/esr/loccount\">loccount工具</a>对其进行分析，会得到下面的结果：</p><pre><code class=\"language-plain\">$loccount .\nall          SLOC=460992  (100.00%) LLOC=193045  in 2746 files\nGo           SLOC=256321  (55.60%)  LLOC=109763  in 1983 files\nC            SLOC=148001  (32.10%)  LLOC=73458   in 368 files\nHTML         SLOC=25080   (5.44%)   LLOC=0       in 57 files\nasm          SLOC=10109   (2.19%)   LLOC=0       in 133 files\n... ...\n</code></pre><p>这里我们看到，在1.0版本中，C语言代码行数占据了32.10%的份额，这一份额直至Go 1.5版本实现自举后，才下降为不到1%。</p><p>我当初对 Go “一见钟情”，其中一个主要原因就是Go与C语言的<strong>语法同源。</strong>相对应地，相信这种同源的语法也会让Gopher们喜欢上C语言。</p><h3>静态编译且基础范式相同</h3><p>除了语法同源，C语言与Go语言的另一个相同点是，它们都是静态编译型语言。这意味着它们都有如下的语法特性：</p><ul>\n<li>变量与函数都要先声明后才能使用；</li>\n<li>所有分配的内存块都要有对应的类型信息，并且在确定其类型信息后才能操作；</li>\n<li>源码需要先编译链接后才能运行。</li>\n</ul><p>相似的编程逻辑与构建过程，让学习C语言的Gopher可以做到无缝衔接。</p><p>除此之外，Go 和 C 的基础编程范式都是命令式编程（imperative programming），即面向算法过程，由程序员通过编程告诉计算机应采取的动作。然后，计算机按程序指令执行一系列流程，生成特定的结果，就像菜谱指定了厨师做蛋糕时应遵循的一系列步骤一样。</p><p>从 Go 看 C，没有面向对象，没有函数式编程，没有泛型（Go 1.18已加入），满眼都是类型与函数，可以说是相当亲切了。</p><h3>错误处理机制如出一辙</h3><p>对于后端编程语言来说，错误处理机制十分重要。如果两种语言的错误处理机制不同，那么这两种语言的代码整体语法风格很可能大不相同。</p><p>在C语言中，我们通常用一个类型为整型的函数返回值作为错误状态标识，函数调用者基于值比较的方式，对这一代表错误状态的返回值进行检视。通常，当这个返回值为0时，代表函数调用成功；当这个返回值为其他值时，代表函数调用出现错误。函数调用者需根据该返回值所代表的错误状态，来决定后续执行哪条错误处理路径上的代码。</p><p>C语言这种简单的<strong>基于错误值比较</strong>的错误处理机制，让每个开发人员必须显式地去关注和处理每个错误。经过显式错误处理的代码会更为健壮，也会让开发人员对这些代码更有信心。另外，这些错误就是普通的值，我们不需要额外的语言机制去处理它们，只需利用已有的语言机制，像处理其他普通类型值那样去处理错误就可以了。这让代码更容易调试，我们也更容易针对每个错误处理的决策分支进行测试覆盖。</p><p>C语言错误处理机制的这种简单与显式，跟Go语言的设计哲学十分契合，于是Go语言设计者决定继承这种错误处理机制。因此，当Gopher们来到C语言的世界时，无需对自己的错误处理思维做出很大的改变，就可以很容易地适应C语言的风格。</p><h2>知己知彼，来看看 C 与 Go 的差异</h2><p>虽说 Gopher 学习 C 语言有“先天优势”，但是不经过脚踏实地的学习与实践就想掌握和精通C语言，也是不可能的。而且，C 和 Go 还是有很大差异的，Gopher 们只有清楚这些差异，做到“知己知彼”，才能在学习过程中分清轻重，有的放矢。俗话说，“磨刀不误砍柴功”，下面我们就一起看看 C 与 Go 有哪些不同。</p><h3>设计哲学</h3><p>在人类自然语言学界，有一个很著名的假说——“<a href=\"https://en.wikipedia.org/wiki/Linguistic_relativity\">萨丕尔-沃夫假说</a>”。这个假说的内容是这样的：<strong>语言影响或决定人类的思维方式</strong>。对我来说，<strong>编程语言也不仅仅是一门工具，它还影响着程序员的思维方式</strong>。每次开始学习一门新的编程语言时，我都会先了解这门编程语言的设计哲学。</p><p>每种编程语言都有自己的设计哲学，即便这门语言的设计者没有将其显式地总结出来，它也真真切切地存在，并影响着这门语言的后续演进，以及这门语言程序员的思维方式。我在<a href=\"http://gk.link/a/10AVZ\">《Tony Bai · Go 语言第一课》</a>专栏里，将Go语言的设计哲学总结成了5点，分别是<strong>简单、显式、组合、并发和面向工程</strong>。</p><p>那么C语言的设计哲学又是什么呢？从表面上看，简单紧凑、性能至上、极致资源、全面移植，这些都可以作为C的设计哲学，但我倾向于一种更有人文气息的说法：<strong>满足和相信程序员</strong>。</p><p>在这样的设计哲学下，一方面，C语言提供了几乎所有可以帮助程序员表达自己意图的语法手段，比如宏、指针与指针运算、位操作、pragma指示符、goto语句，以及跳转能力更为强大的longjmp等；另一方面，C语言对程序员的行为并没有做特别严格的限定与约束，C程序员可以利用语言提供的这些语法手段，进行天马行空的发挥：访问硬件、利用指针访问内存中的任一字节、操控任意字节中的每个位（bit）等。总之，C语言假定程序员知道他们在做什么，并选择相信程序员。</p><p>C语言给了程序员足够的自由，可以说，在C语言世界，你几乎可以“为所欲为”。但这种哲学也是有代价的，那就是你可能会犯一些莫名其妙的错误，比如悬挂指针，而这些错误很少或不可能在其他语言中出现。</p><p>这里再用一个比喻来更为形象地表达下：从Go世界到C世界，就好比在动物园中饲养已久的动物被放归到野生自然保护区，有了更多自由，但周围也暗藏着很多未曾遇到过的危险。因此，学习C语言的Gopher们要有足够的心理准备。</p><h3>内存管理</h3><p>接下来我们来看 C 与 Go 在内存管理方面的不同。我把这一点放在第二位，是因为这两种语言在内存管理上有很大的差异，而且这一差异会给程序员的日常编码带来巨大影响。</p><p>我们知道，Go是带有垃圾回收机制（俗称GC）的静态编程语言。使用Go编程时，内存申请与释放，在栈上还是在堆上分配，以及新内存块的清零等等，这一切都是自动的，且对程序员透明。</p><p>但在C语言中，上面说的这些都是程序员的责任。手工内存管理在带来灵活性的同时，也带来了极大的风险，其中最常见的就是内存泄露（memory leak）与悬挂指针（dangling pointer）问题。</p><p>内存泄露主要指的是<strong>程序员手工在堆上分配的内存在使用后没有被释放（free），进而导致的堆内存持续增加</strong>。而悬挂指针的意思是<strong>指针指向了非法的内存地址</strong>，未初始化的指针、指针所指对象已经被释放等，都是导致悬挂指针的主要原因。针对悬挂指针进行解引用（dereference）操作将会导致运行时错误，从而导致程序异常退出的严重后果。</p><p>Go语言带有GC，而C语言不带GC，这都是由各自语言设计哲学所决定的。GC是不符合C语言的设计哲学的，因为一旦有了GC，程序员就远离了机器，程序员直面机器的需求就无法得到满足了。并且，一旦有了GC，无论是在性能上还是在资源占用上，都不可能做到极致了。</p><p>在C中，手工管理内存到底是一种什么感觉呢？作为一名有着十多年C开发经验的资深C程序员，我只能告诉你：<strong>与内存斗，其乐无穷</strong>！这是在带GC的编程语言中无法体会到的。</p><h3>语法形式</h3><p>虽然C语言是Go的先祖，并且Go也继承了很多C语言的语法元素，但在变量/函数声明、行尾分号、代码块是否用括号括起、标识符作用域，以及控制语句语义等方面，二者仍有较大差异。因此，对 Go 已经很熟悉的程序员在初学 C 时，受之前编码习惯的影响，往往会踩一些“坑”。基于此，我总结了Gopher学习C语言时需要特别注意的几点，接下来我们具体看看。</p><p><strong>第一，注意声明变量时类型与变量名的顺序。</strong></p><p>前面说过，Go与C都是静态编译型语言，这就要求我们在使用任何变量之前，需要先声明这个变量。但Go采用的变量声明语法颇似Pascal语言，即<strong>变量名在前，变量类型在后</strong>，这与C语言恰好相反，如下所示：</p><pre><code class=\"language-plain\">Go:\n\nvar a, b int\nvar p, q *int\n\nvs.\n\nC：\nint a, b;\nint *p, *q;\n</code></pre><p>此外，Go支持短变量声明，并且由于短变量声明更短小，无需显式提供变量类型，Go编译器会根据赋值操作符后面的初始化表达式的结果，自动为变量赋予适当类型。因此，它成为了Gopher们喜爱和重度使用的语法。但短声明在C中却不是合法的语法元素：</p><pre><code class=\"language-plain\">int main() {\n    a := 5; //  error: expected expression\n    printf(\"a = %d\\n\", a);\n}\n</code></pre><p>不过，和上面的变量类型与变量名声明的顺序问题一样，C编译器会发现并告知我们这个问题，并不会给程序带来实质性的伤害。</p><p><strong>第二，注意函数声明无需关键字前缀。</strong></p><p>无论是C语言还是Go语言，函数都是基本功能逻辑单元，我们也可以说<strong>C程序就是一组函数的集合。</strong>实际上，我们日常的C代码编写大多集中在实现某个函数上。</p><p>和变量一样，函数在两种语言中都需要先声明才能使用。Go语言使用func关键字作为<strong>函数声明的前缀</strong>，并且函数返回值列表放在函数声明的最后。但在C语言中，函数声明无需任何关键字作为前缀，函数只支持单一返回值，并且返回值类型放在函数名的前面，如下所示：</p><pre><code class=\"language-plain\">Go：\nfunc Add(a, b int) int {\n    return a+b\n}\n\nvs.\n\nC：\nint Add(int a, int b) {\n    return a+b;\n}\n</code></pre><p><strong>第三，记得加上代码行结尾的分号。</strong></p><p>我们日常编写Go代码时，<strong>极少手写分号</strong>。这是因为，Go设计者当初为了简化代码编写，提高代码可读性，选择了<strong>由编译器在词法分析阶段自动在适当位置插入分号的技术路线</strong>。如果你是一个被Go编译器惯坏了的Gopher，来到C语言的世界后，一定不要忘记代码行尾的分号。比如上面例子中的C语言Add函数实现，在return语句后面记得要手动加上分号。</p><p><strong>第四，补上“省略”的括号。</strong></p><p>同样是出于简化代码、增加可读性的考虑，Go设计者最初就取消掉了条件分支语句（if）、选择分支语句（switch）和循环控制语句（for）中条件表达式外围的小括号：</p><pre><code class=\"language-plain\">// Go代码\nfunc f() int {\n    return 5\n}\nfunc main() {\n    a := 1\n    if a == 1 { // 无需小括号包裹条件表达式\n        fmt.Println(a)\n    }\n\n    switch b := f(); b { // 无需小括号包裹条件表达式\n    case 4:\n        fmt.Println(\"b = 4\")\n    case 5:\n        fmt.Println(\"b = 5\")\n    default:\n        fmt.Println(\"b = n/a\")\n    }\n\n    for i := 1; i &lt; 10; i++ { // 无需小括号包裹循环语句的循环表达式\n        a += i\n    }\n    fmt.Println(a)\n}\n</code></pre><p>这一点恰恰与C语言“背道而驰”。因此，我们在使用C语言编写代码时，务必要想着补上这些括号：</p><pre><code class=\"language-plain\">// C代码\nint f() {\n        return 5;\n}\n\nint main() {\n    int a = 1;\n    if (a == 1) { // 需用小括号包裹条件表达式\n        printf(\"%d\\n\", a);\n    }\n\n    int b = f();\n    switch (b) { // 需用小括号包裹条件表达式\n    case 4:\n        printf(\"b = 4\\n\");\n        break;\n    case 5:\n        printf(\"b = 5\\n\");\n        break;\n    default:\n        printf(\"b = n/a\\n\");\n    }\n\n    int i = 0;\n    for (i = 1; i &lt; 10; i++) { // 需用小括号包裹循环语句的循环表达式\n        a += i;\n    }\n    printf(\"%d\\n\", a);\n}\n</code></pre><p><strong>第五，留意 C 与 Go 导出符号的不同机制。</strong></p><p>C语言通过头文件来声明对外可见的符号，所以我们不用管符号是不是首字母大写的。但在Go中，只有首字母大写的包级变量、常量、类型、函数、方法才是可导出的，即对外部包可见。反之，首字母小写的则为包私有的，仅在包内使用。Gopher一旦习惯了这样的规则，在切换到C语言时，就会产生“心理后遗症”：遇到在其他头文件中定义的首字母小写的函数时，总以为不能直接使用。</p><p><strong>第六，记得在switch case语句中添加break。</strong></p><p>C 语言与 Go 语言在选择分支语句的语义方面有所不同：C语言的 case 语句中，如果没有显式加入break语句，那么代码将向下自动掉落执行。而 Go 在最初设计时就重新规定了switch case的语义，默认不自动掉落（fallthrough），除非开发者显式使用fallthrough关键字。</p><p>适应了Go的switch case语句的语义后再回来写C代码，就会存在潜在的“风险”。我们来看一个例子：</p><pre><code class=\"language-plain\">// C代码：\nint main() {\n    int a = 1;\n    switch(a) {\n        case 1:printf(\"a = 1\\n\");\n        case 2:printf(\"a = 2\\n\");\n        case 3:printf(\"a = 3\\n\");\n        default:printf(\"a = ?\\n\");\n    }\n}\n</code></pre><p>这段代码是按 Go 语义编写的switch case，编译运行后得到的结果如下：</p><pre><code class=\"language-plain\">a = 1\na = 2\na = 3\na = ?\n</code></pre><p>这显然不符合我们输出“a = 1”的预期。对于初学C的Gopher而言，这个问题影响还是蛮大的，因为这样编写的代码在C编译器眼中是完全合法的，但所代表的语义却完全不是开发人员想要的。这样的程序一旦流入到生产环境，其缺陷可能会引发生产故障。</p><p>一些 C lint 工具可以检测出这样的问题，因此对于写C代码的Gopher，我建议在提交代码前使用lint工具对代码做一下检查。</p><h3>构建机制</h3><p>Go与C都是静态编译型语言，它们的源码需要经过编译器和链接器处理，这个过程称为<strong>构建(build)</strong>，构建后得到的可执行文件才是最终交付给用户的成果物。</p><p>和Go语言略有不同的是，C语言的构建还有一个预处理（pre-processing）阶段，预处理环节的输出才是C编译器的真正输入。C语言中的宏就是在预处理阶段展开的。不过，Go没有预处理阶段。</p><p>C语言的编译单元是一个C源文件（.c），每个编译单元在编译过程中会对应生成一个目标文件（.o/.obj），最后链接器将这些目标文件链接在一起，形成可执行文件。</p><p>而Go则是以一个包（package）为编译单元的，每个包内的源文件生成一个.o文件，一个包的所有.o文件聚合（archive）成一个.a文件，链接器将这些目标文件链接在一起形成可执行文件。</p><p>Go语言提供了统一的Go命令行工具链，且Go编译器原生支持增量构建，源码构建过程不需要Gopher手工做什么配置。但在C语言的世界中，用于构建C程序的工具有很多，主流的包括gcc/clang，以及微软平台的C编译器。这些编译器原生不支持增量构建，为了提升工程级构建的效率，避免每次都进行全量构建，我们通常会使用第三方的构建管理工具，比如make（Makefile）或CMake。考虑移植性时，我们还会使用到configure文件，用于在目标机器上收集和设置编译器所需的环境信息。</p><h3>依赖管理</h3><p>我在前面提过，C语言仅提供了一个“小内核”。像依赖管理这类的事情，C语言本身并没有提供跟 Go 中的Go Module类似的，统一且相对完善的解决方案。在C语言的世界中，我们依然要靠外部工具（比如CMake）来管理第三方的依赖。</p><p>C语言的第三方依赖通常以静态库（.a）或动态共享库（.so）的形式存在。如果你的应用要使用静态链接，那就必须在系统中为C编译器提供第三方依赖的静态库文件。但在实际工作中，完全采用静态链接有时是会遇到麻烦的。这是因为，很多操作系统在默认安装时是不带开发包的，也就是说，像 libc、libpthread 这样的系统库只提供了动态共享库版本（如/lib下提供了libc的共享库libc.so.6），其静态库版本是需要自行下载、编译和安装的（如libc的静态库libc.a在安装后是放在/usr/lib下面的）。所以<strong>多数情况下，我们是将静态、动态两种链接方式混合在一起使用的</strong>，比如像libc这样的系统库多采用动态链接。</p><p>动态共享库通常是有版本的，并且按照一定规则安装到系统中。举个例子，一个名为libfoo的动态共享库，在安装的目录下文件集合通常是这样：</p><pre><code class=\"language-plain\">2022-03-10 12:28 libfoo.so -&gt; libfoo.so.0.0.0*\n2022-03-10 12:28 libfoo.so.0 -&gt; libfoo.so.0.0.0*\n2022-03-10 12:28 libfoo.so.0.0.0*\n</code></pre><p>按惯例，每个动态共享库都有多个名字属性，包括real name、soname和linker name。下面我们来分别看下。</p><ul>\n<li>real name：实际包含共享库代码的那个文件的名字(如上面例子中的libfoo.so.0.0.0)。动态共享库的真实版本信息就在real name中，显然real name中的版本号符合<a href=\"https://semver.org/\">语义版本规范</a>，即major.minor.patch。当两个版本的major号一致，说明是向后兼容的两个版本；</li>\n<li>soname：shared object name的缩写，也是这三个名字中最重要的一个。无论是在编译阶段还是在运行阶段，系统链接器都是通过动态共享库的soname（如上面例子中的libfoo.so.0）来唯一识别共享库的。我们看到的soname实际上是仅包含major号的共享库名字；</li>\n<li>linker name：编译阶段提供给编译器的名字（如上面例子中的libfoo.so）。如果你构建的共享库的real name跟上面例子中libfoo.so.0.0.0类似，带有版本号，那么你在编译器命令中直接使用-L path -lfoo是无法让链接器找到对应的共享库文件的，除非你为libfoo.so.0.0.0提供了一个linker name（如libfoo.so，一个指向libfoo.so.0.0.0的符号链接）。linker name一般在共享库安装时手工创建。</li>\n</ul><p>动态共享库有了这三个名称属性，依赖管理就有了依据。但由于在链接的时候使用的是linker name，而linker name并不带有版本号，真实版本与主机环境有关，因此要实现C应用的可重现构建还是比较难。在实践中，我们通常会使用专门的构建主机，项目组将该主机上的依赖管理起来，进而保证每次构建所使用的依赖版本是可控的。同时，应用部署的目标主机上的依赖版本也应该得到管理，避免运行时出现动态共享库版本不匹配的问题。</p><h3>代码风格</h3><p>Go语言是历史上首次实现了代码风格全社区统一的编程语言。它基本上消除了开发人员在代码风格上的无休止的、始终无法达成一致的争论，以及不同代码风格带来的阅读、维护他人代码时的低效。gofmt工具格式化出来的代码风格已经成为Go开发者的一种共识，融入到Go语言的开发文化当中了。所以，如果你让某个Go开发者说说gofmt后的代码风格是什么样的，多数Go开发者可能说不出，因为代码会被gofmt自动变成那种风格，大家已经不再关心风格了。</p><p>而在C语言的世界，代码风格仍存争议。但经过多年的演进，以及像Go这样新兴语言的不断“教育”，C社区也在尝试进行这方面的改进，涌现出了像<a href=\"https://clang.llvm.org/docs/ClangFormat.html\">clang-format</a>这样的工具。目前，虽然还没有在全社区达成一致的代码风格（由于历史原因，这很难做到），但已经可以减少很多不必要的争论。</p><p>对于正在学习C语言，并进行C编码实践的Gopher，我的建议是：<strong>不要拘泥于使用什么代码风格，先用clang-format，并确定一套风格模板就好</strong>。</p><h2>小结</h2><p>作为一名对 Go 跟随和研究了近十年的程序员，我深刻体会到， Go 的简单性、性能和生产力使它成为了创建面向用户的应用程序和服务的理想语言。快速的迭代让团队能够快速地作出反应，以满足用户不断变化的需求，让团队可以将更多精力集中在保持灵活性上。</p><p>但 Go 也有缺点，比如缺少对内存以及一些低级操作的精确控制，而 C 语言恰好可以弥补这个缺陷。C 语言提供的更精细的控制允许更多的精确性，使得 C 成为低级操作的理想语言。这些低级操作不太可能发生变化，并且 C 相比 Go 还提高了性能。所以，如果你是一个有性能与低级操作需求的 Gopher ，就有充分的理由来学习 C 语言。</p><p>C 的优势体现在最接近底层机器的地方，而 Go 的优势在离用户较近的地方能得到最大发挥。当然，这并不是说两者都不能在对方的空间里工作，但这样做会增加“摩擦”。当你的需求从追求灵活性转变为注重效率时，用 C 重写库或服务的理由就更充分了。</p><p>总之，虽然 Go 和 C 的设计有很大的不同，但它们也有很多相似性，具备发挥兼容优势的基础。并且，当我们同时使用这二者时，就可以既有很大的灵活性，又有很好的性能，可以说是相得益彰！</p><h2>写在最后</h2><p>今天的加餐中，我主要是基于C与Go的比较来讲解的，对于Go语言的特性并没有作详细展开。如果你还想进一步了解Go语言的设计哲学、语法特性、程序设计相关知识，欢迎来学习我在极客时间上的专栏<a href=\"https://time.geekbang.org/column/intro/100093501?tab=catalog\">《Tony Bai · Go 语言第一课》</a>。在这门课里，我会用我十年 Gopher 的经验，带给你一条系统、完整的 Go 语言入门路径。</p><p>感谢你看到这里，如果今天的内容让你有所收获，欢迎把它分享给你的朋友。</p>","neighbors":{"left":{"article_title":"大咖助阵｜海纳：C 语言是如何编译执行的？（三）","id":495829},"right":{"article_title":"期末考试｜来赴一场满分之约吧！","id":495292}}},{"article_id":495292,"article_title":"期末考试｜来赴一场满分之约吧！","article_content":"<p>你好，我是于航。</p><p>《深入 C 语言和程序运行原理》这门课的正文内容已经全部结束了，非常感谢你一直以来的认真学习和支持。为了帮你检验自己的学习效果，我特意给你准备了一套结课测试题。这套测试题一共有 20 道，有单选，也有多选，考点都来自于我们前面讲到的重要知识。那么，快点击下面按钮开始测试吧！</p><p><a href=\"http://time.geekbang.org/quiz/intro?act_id=2945&exam_id=7785\"><img src=\"https://static001.geekbang.org/resource/image/28/a4/28d1be62669b4f3cc01c36466bf811a4.png?wh=1142*201\" alt=\"\"></a></p><p>按规划，这个专栏接下来除了结束语，还会更新几期加餐：</p><ul>\n<li>海纳老师会继续在<a href=\"https://time.geekbang.org/column/article/491633\">加餐</a>里来跟你聊聊与 C 程序编译相关的内容，帮助你深刻理解 C 程序的编译全过程；</li>\n<li>我还邀请了<a href=\"https://time.geekbang.org/column/intro/100093501\">《Tony Bai · Go 语言第一课》</a>的 Tony Bai 老师，来带你分析 C 与 Go 这两种语言之间的异同。如果你想了解 “C 语言为什么被设计成现在这样”，或者对 C 与 Go 之间的关系感兴趣，那请一定不要错过这篇；</li>\n<li>除此之外，针对这个专栏的第四模块 “C 程序运行原理篇”，我还计划出一期答疑。如果你对这个模块的内容有一些疑问，或者有一些思考题希望我来详细解答，欢迎在这一讲的评论区留言。</li>\n</ul><p>另外，我还给你准备了一个调查问卷。题目不多，大概两分钟就可以填完，主要是想听一下你对这门课的看法和建议。期待你的反馈！</p><p><a href=\"https://jinshuju.net/f/wi5O17\"><img src=\"https://static001.geekbang.org/resource/image/c5/cb/c5948bfa733fbbd183f01194cfd878cb.jpg?wh=1142x801\" alt=\"\"></a></p><!-- [[[read_end]]] -->","neighbors":{"left":{"article_title":"大咖助阵｜Tony Bai：Go 程序员拥抱 C 语言简明指南","id":500145},"right":{"article_title":"结束语｜工业 4.0 时代，C 语言还有哪些应用场景？","id":496932}}},{"article_id":496932,"article_title":"结束语｜工业 4.0 时代，C 语言还有哪些应用场景？","article_content":"<p>你好，我是于航。</p><p>首先，恭喜你完成了整个专栏的学习！今天是这门课中必学内容的最后一讲了，很荣幸能陪你一起走完这三个多月的 C 语言学习之旅。</p><p>其实，这趟“旅程”于我而言要更漫长一些：从去年 9 月底开始筹备这个专栏，到 12 月初课程上线，再到今天更新结束，时间跨度接近半年。这个过程也促使我对自己已有的知识体系进行了一次重新梳理。还要特别感谢那些经常在评论区提出问题、分享经验的同学，与你们的交流，让我在知识积累和认知广度上都获益良多。</p><p>在这场旅途的“终点”，想跟你聊点不一样的东西。就先从对“起点”的回顾开始吧。</p><h2>“新视角”与“旧语言”</h2><p>去年 9 月份的时候，得知极客时间想要出一门有关 C 语言的课程，我当时还是有点惊讶的。毕竟，与 Rust 和 Go 这类新兴语言相比，C 语言似乎显得有些基础和平常。我们知道，很多编程语言都是以 C 语法为原型来进行设计的，它们选用了同 C 类似甚至完全相同的语法形式，并且还进行了多方面的改进。虽然 C 这门语言是我在工作中使用最多的语言之一，但我还是有些担心：一些同学会不会认为 C 语言早已没什么“有特色”的内容，不值得学习了呢？</p><p>带着些许疑虑，我和这门课的编辑同学进行了大量前期调研。在调研的过程中，我们发现还是有不少同学对 C 语言感兴趣的。并且我们还发现，很多同学想要学习 C 语言，其实也是希望能通过这门抽象层次较低、贴近底层硬件的语言，来更好地理解计算机系统的底层运作机制。基于此，我对这门课的课程定位和设计思路进行了一些调整，把课程重点从对 C 基本语法的讲解，改为了<strong>从底层<strong><strong>视角</strong></strong>去<strong><strong>观察</strong></strong>C 这门编程语言的实现细节</strong>。于是，就有了你现在看到的《深入 C 语言和程序运行原理》。</p><!-- [[[read_end]]] --><p>虽然之前担心过有些同学认为“C 不值得”，但我自身还是对 C 语言非常有信心的。我在开篇词里说过，时至今日的 C 语言仍然“老当益壮”。而今天我要说的是：C 语言不仅在过去和现在发挥重要作用，它在未来也同样会发光发热。</p><h2>C 语言未来的发展方向是什么？</h2><p>我们能够明显地观察到，如今的 C 语言已“今非昔比”，它跟我们在大学课堂上一板一眼学习的 C89 标准早已有了很大区别。C99、C11，乃至 C17 标准中加入的新特性，保留了 C 语言原本“贴近底层硬件”的性质，不会对机器代码做过多抽象，同时进一步提升了开发者使用 C 语言的生产效率。</p><p>当前的 C 语言仍处在不断进化的过程中。ISO 标准委员会并不希望为 C 语言增加过多新特性，变动的重点在于<strong>保证 C 语言基本特征（易用、高性能、贴近硬件）的同时，进一步修复语言中的遗留问题</strong>，让它用起来更方便。</p><p>C17 标准之后的下一代 C 语言标准是 C2x 标准，它预计会在 2023 年发布。目前已经有很多修改草案被纳入到该版本中，这里我列出了其中一些比较重要的改动：</p><ul>\n<li>将 alignas、alignof、bool、true、false 等变为关键字（易用性）；</li>\n<li>增加预处理条件指令 #elifdef 与 #elifndef（易用性）；</li>\n<li>十六进制数字支持使用分隔符（易用性）；</li>\n<li>更好地支持为数组类型使用 <code>const</code> 关键字（易用性）；</li>\n<li>提供带溢出检查的、支持泛型的数学运算函数（易用性）；</li>\n<li>移除 K&amp;R 形式的函数声明（遗留问题修复）；</li>\n<li>标准化 <code>typeof</code> 运算符（新特性）；</li>\n<li>C 标准库中新增 strdup 与 memccpy 等函数（新特性）；</li>\n<li>……</li>\n</ul><p>从这些改动中，你可以对 C 语言的未来发展方向有一个基本感知。可以看到，大多数 C2x 中的新提案都是为了增强 C 这门语言的易用性，而并不会对语言本身做过多封装。这使得 C 语言变得更加易用，同时 ABI 也保持着稳定，可以说是兼顾了灵活性、高效性和兼容性。</p><p>随着 C 标准的发展，C 语言也被更多地应用在生产项目中。比如，就在不久之前，Linux 之父 Linus Torvalds 宣布，他希望尽快将 Linux 内核使用的 C 语言标准从 C89 升级至 C11。你可以点击<a href=\"https://lore.kernel.org/lkml/20220308215615.14183-4-arnd@kernel.org\">这个链接</a>来了解更多信息。</p><p><img src=\"https://static001.geekbang.org/resource/image/e9/b4/e92d2624a6573daa57f571d4efce35b4.png?wh=1640x522\" alt=\"图片\" title=\"相关话题的邮件讨论截图\"></p><p>C 语言仍在不断进化，并且，伴随着新生事物的出现，它的应用领域也正变得越来越广。随着“第四次工业革命”的快速展开，这一点将越发凸显。接下来我们就来看看，C 语言在工业 4.0 时代的应用场景。</p><h2></h2><h2>C 语言与第四次工业革命</h2><p>第四次工业革命也被称为工业 4.0，或 4IR。这个概念最早起源于 2011 年德国政府的一个高科技战略项目。随后，世界经济论坛创始人兼执行主席 Klaus Schwab 于 2015 年对其进行了推广，并强调了 4IR 对整个产业的影响。</p><p>4IR 在前三次工业革命（蒸汽时代、电气时代、数字时代）的基础上，进一步强调了“工业智能”的重要性。它的具体表现是：<strong>利用智能化技术，大幅降低人在整个工业生产链中的参与程度，以尽可能做到智能的自动化生产。</strong>这一过程涉及到的技术领域主要包括人工智能、大数据、（工业）物联网、虚拟现实、云计算、机器人，等等。而这些不同技术之间的无缝协作，便成为了这场革命决胜的关键。</p><p>现在，让我们从宏观走向微观，仔细看看上面所说的具体技术，你会发现其中的每一项都少不了 C 语言的“参与”。</p><p>我们都知道，用于支持计算机正常运行的底层系统软件大多基于 C 语言构建，这里就不再赘述。而除此之外，我们首先得承认的是，C 语言仍然是物联网、机器人这两个应用领域内的首选编程语言。</p><p>物联网与机器人编程需要软件能够直接与相关硬件通信，而 C 语言的低抽象层次正使得开发者可以灵活控制代码编译产物，做到对硬件的精准控制。同时，C 语言还有较高的运行时性能，这意味着对于同样的任务，开发者可以选用功耗相对更低的芯片。无论是从节能环保还是降本增效的角度来看，这都可以说是双赢。</p><p>在工业 4.0 时代，基于“统一计算设备架构（Compute Unified Device Architecture，CUDA）”编程模型等技术进行的高性能 GPU 计算，成为了推动虚拟现实、自动驾驶汽车，甚至是区块链等领域发展的关键技术点。而这类技术在设计时，也都默认提供了基于 C 语言的编程接口。可以看到，C 语言在需要与硬件直接打交道的场景中，仍发挥着重要作用。</p><p>不仅如此，为了进一步提升算法执行效率，C 语言在人工智能领域也有着重要应用，比如 TensorFlow 等框架就为 C 程序提供了相应的专用接口。而在大数据和云计算领域，Oracle、PostgreSQL、Apache、Nginx 等高性能数据库和服务器软件也均由 C 语言编写。基于 C 语言开发的各类框架为高性能的数据处理和计算提供了保障。</p><p>总之，在工业 4.0 时代，无论你是否直接使用 C 语言编码，都会在无形当中直接或间接地与 C 语言打交道。</p><h2>写在最后</h2><p>在这门课的最后，我想说的是：希望这一趟“不一样的 C 语言之旅”能让你有所收获。同时，结课并不意味着学习之旅的终结，而应该是你继续探索的新起点。</p><p>还记得我在<a href=\"https://time.geekbang.org/column/article/484220\">春节策划一</a>里提到的“飞轮学习法”吗？这里，再回想一遍其中的两个学习基本原则吧：第一，由点成线再成网地构建自己的知识体系；第二，不断地重复获取和咀嚼知识，让学习的飞轮转起来。</p><p>希望这门课可以帮助你把一些之前就了解过的“单点知识”联系起来，基本建立起一个关于 C 语言的知识网络。那么，接下来你要做的就是继续深入了解相关知识，并进行大量实践。这样，就能在已构建的“面”的基础上加深“点”，让知识网中的各个点互通有无。</p><p>正如<a href=\"https://book.douban.com/subject/27096665\">《现代操作系统》</a>一书中所说，“在计算机的历史中，每个新物种，无论是硬件还是软件，似乎都要经过它们前辈的发展阶段”。互联网技术的变化日新月异，似乎每一个新技术的出现，都在重复那些老技术之前已经走过的路。但也正是那些经历了时间的考验，仍稳定不变的技术理论体系，在支撑着这个世界的快速变化和发展。因此，如果你能通过 C 语言，从基础层面了解程序是如何工作的，并深入理解计算机系统的底层运作机制，那么就能更好地拥抱这个不断变化的世界，更快地理解并掌握新技术。</p><p>最后的最后，我还给你准备了一个<a href=\"https://jinshuju.net/f/wi5O17\">调查问卷</a>。题目不多，大概两分钟就可以填完，主要是想听一下你对这门课的看法和建议。期待你的反馈！<br>\n<a href=\"https://jinshuju.net/f/wi5O17\"><img src=\"https://static001.geekbang.org/resource/image/c5/cb/c5948bfa733fbbd183f01194cfd878cb.jpg?wh=1142x801\" alt=\"\"></a></p>","neighbors":{"left":{"article_title":"期末考试｜来赴一场满分之约吧！","id":495292},"right":[]}}]