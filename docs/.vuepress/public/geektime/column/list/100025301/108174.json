{"id":108174,"title":"36 | Facebook游戏实时流处理Beam Pipeline实战（下）","content":"<p>你好，我是蔡元楠。</p><p>在上一讲中，我们一起对怎样实现一个简易的游戏积分排行榜展开了讨论，也一起研究了如何使用批处理计算的方式在Beam中构建出一个数据流水线来得出排行榜结果。</p><p>我们知道，虽然批处理计算可以得到一个完整的结果，但是它也存在着自身的不足，比如会有一定的延时，需要额外的crontab来管理定时任务，增加了维护成本等等。</p><p>所以在上一讲的末尾，我们提出了使用实时流处理来改进这些不足，而其中就需要用到窗口、触发器和累加模式这几个概念。</p><p>相信学习了<a href=\"https://time.geekbang.org/column/article/105707\">第32讲</a>的内容后，你对于窗口在Beam中是如何运作的，已经比较了解了。对于有效时间为一周的积分排行榜来说，我们可以赋予一个“窗口时长为一周的固定窗口”给数据流水线。也就是说，我们最终的结果会按照每一周的时长来得出。</p><p>那接下来的问题就剩下我们怎么定义触发器和累加模式了。</p><p>首先，我想先讲讲触发器在Beam中是怎么运作的。在<a href=\"https://time.geekbang.org/column/article/100478\">第23讲</a>中，我们已经了解了触发器在Beam中的作用。它是用于告诉数据流水线，什么时候需要计算一遍落在窗口中的所有数据的。这在实时流处理中尤为重要。</p><p>在实时流处理当中，我们总是需要在数据结果的<strong>完整性</strong>和<strong>延迟性</strong>上做出一些取舍。</p><p>如果我们设置的触发器比较频繁，例如说每隔几分钟甚至是几秒钟，或者是在时间上很早发生的话，那就表示我们更倾向于数据流水线的延时比较小，但是不一定能够获得完整的数据。</p><!-- [[[read_end]]] --><p>如果我们设置的触发器是比较长时间的，像每隔一个小时才会触发一次窗口中的计算的话，那就表示我们更希望获得完整的数据集来得到最终结果。</p><p>为什么这么说呢？</p><p>因为在现实世界中，我们是没有办法保证数据流水线可以在某一刻能够得到在这一刻之前所产生的所有数据的。</p><p>就拿获得这个游戏积分排行榜的数据为例子来说明一下。</p><p>在现实生活中，可能很多用户是用手机来通关游戏，并且上传通关时间和积分的。有的地方可能因为信号差，上传数据会有很大的延迟。甚至可能有这样的情况：有一些用户是在坐飞机的时候玩的游戏（在飞行模式之下完成各种通关），等到飞机降落，手机重新有了信号之后，数据才被上传到服务器，这时候可能已经有了好几个小时的延时了。</p><p>如果提早触发窗口中的数据计算，可能会有很多“迟到”的数据未被纳入最终结果中，而这些“迟到”的数据有可能又会影响到游戏积分排行榜。</p><p>所以，在很多复杂的场景下，我们希望尽可能地将所有数据归入正确的时间窗口中，而且还要能够得到正确的结果。因此，除了要对触发器进行设置之外，我们还需要设置到底应不应该在一些“迟到”的数据来到的时候，重新计算一下整个结果。</p><p>在Beam中，我们可以为PCollection设置的触发器有4种模式：</p><p>1.<strong>基于事件时间的触发器</strong>（Event-Time Trigger）</p><p>如果设置了基于事件时间的触发器，那所有的计算都是基于PCollection中所有元素的事件时间的。</p><p>如果我们不显式地设置触发器的话，Beam的默认触发器就是基于事件时间的，如果要显式地设置基于事件时间的触发器，可以使用AfterWatermark类进行设置。</p><p>2.<strong>基于处理时间触发器</strong>（Process-Time Trigger）</p><p>如果设置了基于处理时间的触发器，那一个PCollection中的所有元素都会在数据流水线中的某一个时刻被处理。如果要显式地设置基于处理时间的触发器，可以使AfterProcessingTime类进行设置。</p><p>3.<strong>数据驱动的触发器</strong>（Data-Driven Trigger）</p><p>数据驱动的触发器一般是在每个元素到达每个窗口时，通过检查这个元素是否满足某个属性来触发的。</p><p>就好像我在<a href=\"https://time.geekbang.org/column/article/100478\">第23讲</a>所举的例子一样，检查元素是否在窗口中到达一定的数量，然后触发计算就是数据驱动的触发器的一种，在Beam中，可以使用AfterPane.elementCountAtLeast()函数来配置。</p><p>4.<strong>复合触发器</strong>（Composite Trigger）</p><p>复合触发器其实就是由上面所说三种基本触发器组合而成的。在<a href=\"https://time.geekbang.org/column/article/100478\">第23讲</a>中，我举过一个触发器的例子，例子中至少要等到有两个交易数据到达后才能触发计算。</p><p>有同学在留言中问我，如果现实中只有一个数据到达窗口，那岂不是永远都触发不了计算了？其实，这个时候就可以定义一个复合触发器，可以定义成累积有超过两个元素落入窗口中或者是每隔一分钟触发一次计算的复合触发器。</p><p>而像我之前提到的，如果我们需要处理“迟到”的数据，那在Beam中又是怎么操作呢？我们可以使用withAllowedLateness这个在Window类里定义好的函数，方法签名如下：</p><p>Java</p><pre><code>public Window&lt;T&gt; withAllowedLateness(Duration allowedLateness);\n</code></pre><p>这个函数接收的参数就是我们希望允许多久的“迟到”数据可以被纳入计算中。</p><p>最后需要说明的是累加模式。</p><p>在Beam中，我们可以设置两种累加模式，分别是<strong>丢弃模式</strong>和<strong>累积模式</strong>。它们可以分别通过Window类里的函数discardingFiredPanes()和accumulatingFiredPanes()来设置。</p><p>好了，那现在回到我们的积分排行榜问题当中。</p><p>虽然我们对输入数据集设定的窗口是一个窗口时长为1周的固定窗口，但是我们也需要尽可能地在近乎实时的状态下更新排行榜。所以，我们可以设置数据流水线在每5分钟更新一次。</p><p>那我们接受“迟到”多久的数据呢？</p><p>我在网上查询了一下，现在飞机航班直飞耗时最长的是新加坡飞往纽约的航班，大概需要19个小时。如果玩游戏的用户恰好也在这趟航班上，那么可能数据的延时可能就会超过19个小时了。那我们就设定允许“迟到”20个小时的数据也纳入我们的窗口计算当中。</p><p>一般情况下，我们可以从Pub/Sub数据流中读取实时流数据。为了简化数据流水线的逻辑，不在数据流水线中保存中间状态，我们现在假设在实际操作的时候，服务器已经判断好某一用户的分数是否是最高分，如果是最高分的话，再通过Pub/Sub将数据传入流水线。</p><p>这时，我们的累加模式可以定义为丢弃模式，也就是只保留最新的结果。</p><p>为此，我们可以写出一个Transform来设置所有上述描述的概念，分别是：</p><ol>\n<li>设置窗口时长为1周的固定窗口。</li>\n<li>每隔5分钟就会计算一次窗口内数据的结果。</li>\n<li>允许“迟到”了20个小时的数据被重新纳入窗口中计算。</li>\n<li>采用丢弃模式来保存最新的用户积分。</li>\n</ol><p>Java</p><pre><code>static class ConfigUserScores extends PTransform&lt;PCollection&lt;UserScoreInfo&gt;, PCollection&lt;UserScoreInfo&gt;&gt; {\n    private final Duration FIXED_WINDOW_SIZE = Duration.standardDays(7);\n    private final Duration FIVE_MINUTES = Duration.standardMinutes(5);\n    private final Duration TWENTY_HOURS = Duration.standardHours(20);\n\n    @Override\n    public PCollection&lt;UserScoreInfo&gt; expand(PCollection&lt;UserScoreInfo&gt; infos) {\n      return infos.apply(\n          Window.&lt;UserScoreInfo&gt;into(FixedWindows.of(FIXED_WINDOW_SIZE))\n              .triggering(\n                  AfterWatermark.pastEndOfWindow()\n                      .withEarlyFirings(\n                          AfterProcessingTime.pastFirstElementInPane().plusDelayOf(FIVE_MINUTES))\n                      .withLateFirings(\n                          AfterProcessingTime.pastFirstElementInPane().plusDelayOf(FIVE_MINUTES)))\n              .withAllowedLateness(TWENTY_HOURS)\n              .discardingFiredPanes());\n    }\n  }\n</code></pre><p>有了这个Transform去设定好我们在实时流处理中如何处理数据之后，我们其实只需要修改之前批处理数据流水线中很小的一部分，就可以达到我们想要的结果了。</p><p>Java</p><pre><code>...\npipeline.apply(\n            KafkaIO.&lt;String&gt;read()\n                .withBootstrapServers(&quot;broker_1:9092,broker_2:9092&quot;)\n                .withTopic(&quot;user_scores&quot;)\n                .withKeyDeserializer(StringDeserializer.class)\n                .withValueDeserializer(StringDeserializer.class)\n                .withLogAppendTime())\n        .apply(&quot;ConvertUserScoreInfo&quot;, ParDo.of(new ConvertUserScoreInfoFn()))\n        .apply(&quot;ConfigUserScores&quot;, new ConfigUserScores())\n        .apply(&quot;RetrieveTop100Players&quot;, new ExtractUserAndScore())\n...\n</code></pre><p>如代码所示，真正做出修改的地方就是将读取输入数据集的BigTableIO改成使用KafkaIO来读取。将批处理的两个Filter Transform替换成我们自定义的ConfigUserScores Transform。</p><p>到此为止，我们就可以“一劳永逸”，运行一个实时流处理的数据流水线来得到游戏积分排行榜结果了。</p><h2>小结</h2><p>今天我们一起设计了一个实时流处理的数据流水线，来完成之前自定义的一个简单游戏积分排行榜。</p><p>这里面有不少经验是值得我们在处理现实的应用场景中借鉴的。比如，我们应该考虑数据结果的完整性有多重要、我们能接受多大的延迟、我们是否接受晚来的数据集等等。</p><p>这些问题其实又回到了<a href=\"https://time.geekbang.org/column/article/100478\">第23讲</a>中提到过的——我们在解决现实问题时，应该回答好的“WWWH”这四个问题。</p><h2>思考题</h2><p>今天我们一起探讨了如何利用实时流处理的方式来解决游戏积分排行榜的问题，里面涉及了配置窗口，触发器和累加模式。这些配置可能还不是最优的，你觉得我们还有什么地方可以进行优化的呢？</p><p>欢迎你把自己的学习体会写在留言区，与我和其他同学一起讨论。如果你觉得有所收获，也欢迎把文章分享给你的朋友。</p><p></p>","comments":[{"had_liked":false,"id":115376,"user_name":"微思","can_delete":false,"product_type":"c1","uid":1004349,"ip_address":"","ucode":"853C48AA183A7B","user_header":"https://static001.geekbang.org/account/avatar/00/0f/53/3d/1189e48a.jpg","comment_is_top":false,"comment_ctime":1563546980,"is_pvip":true,"discussion_count":1,"race_medal":1,"score":"23038383460","product_id":100025301,"comment_content":"老师讲的很好！要是能提供一个完整的案例，包括测试数据和运行时，不需要读者折腾太多，下载下来直接就能运行，相信会引起更多的共鸣，将这个专栏衬托得更加精彩！","like_count":6,"discussions":[{"author":{"id":1226199,"avatar":"https://static001.geekbang.org/account/avatar/00/12/b5/d7/29d15a46.jpg","nickname":"挨踢青蛙","note":"","ucode":"ED1B289866016C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":2836,"discussion_content":"同意！！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1563962106,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":171019,"user_name":"时光机器","can_delete":false,"product_type":"c1","uid":1674708,"ip_address":"","ucode":"E1FC3FCFF3203F","user_header":"https://static001.geekbang.org/account/avatar/00/19/8d/d4/64eae0b3.jpg","comment_is_top":false,"comment_ctime":1578822942,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"10168757534","product_id":100025301,"comment_content":"感觉这个例子没有提现出流式计算的实时特性呀。老师能举个像阿里实时战报看板这样高实时性要求的例子吗，感谢感谢","like_count":3},{"had_liked":false,"id":243693,"user_name":"之渊","can_delete":false,"product_type":"c1","uid":1876212,"ip_address":"","ucode":"02B9299DBB4881","user_header":"https://static001.geekbang.org/account/avatar/00/1c/a0/f4/7e122a67.jpg","comment_is_top":false,"comment_ctime":1598251803,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5893219099","product_id":100025301,"comment_content":"参考https:&#47;&#47;blog.csdn.net&#47;a799581229&#47;article&#47;details&#47;106444576 这个博客入门以及触发器说明的也不错","like_count":1},{"had_liked":false,"id":248524,"user_name":"stephen","can_delete":false,"product_type":"c1","uid":1337994,"ip_address":"","ucode":"CDEB34771891A3","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/dAkTIgz3sFoO20qQMbRiaRqWrpicIWiaLMbkeLkribTOUvrzDZPOaRfZgQOvTtAgib35D7DKFiarejer74F4Qs0771mQ/132","comment_is_top":false,"comment_ctime":1600212671,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1600212671","product_id":100025301,"comment_content":"如果窗口跟滑动步长一样或者更大，比如推荐点击率，20秒窗口，每20秒计算一次，也要允许延迟前一个窗口期甚至几个窗口期的延迟数据重新计算，这种beam能好的支持么？还是说只能借助外部hbase一类实时转储结果？","like_count":0},{"had_liked":false,"id":185286,"user_name":"Geeker","can_delete":false,"product_type":"c1","uid":1896510,"ip_address":"","ucode":"937B190AE0EC6F","user_header":"https://static001.geekbang.org/account/avatar/00/1c/f0/3e/f9f021bf.jpg","comment_is_top":false,"comment_ctime":1583553156,"is_pvip":false,"replies":[{"id":"71865","content":"谢谢","user_name":"作者回复","user_name_real":"野鹤","uid":"1386753","ctime":1583740356,"ip_address":"","comment_id":185286,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1583553156","product_id":100025301,"comment_content":"例子很好！","like_count":1,"discussions":[{"author":{"id":1386753,"avatar":"https://static001.geekbang.org/account/avatar/00/15/29/01/20caec2f.jpg","nickname":"Yeon","note":"","ucode":"ED3549F94EB36E","race_medal":0,"user_type":4,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":486313,"discussion_content":"谢谢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1583740356,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":4}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":136650,"user_name":"Cool","can_delete":false,"product_type":"c1","uid":1248267,"ip_address":"","ucode":"7E83A5C7674CA8","user_header":"https://static001.geekbang.org/account/avatar/00/13/0c/0b/d475f530.jpg","comment_is_top":false,"comment_ctime":1569487570,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1569487570","product_id":100025301,"comment_content":"觉得这些例子逻辑上还是相对来说比较简单， 流式处理当输入源是多个的时候， 比如对于交易所来说  一个是实时 trade,  一个是实时的 price，都使用相同的 fix_window,  join 起来之后，再做计算输出等等","like_count":1},{"had_liked":false,"id":136649,"user_name":"Cool","can_delete":false,"product_type":"c1","uid":1248267,"ip_address":"","ucode":"7E83A5C7674CA8","user_header":"https://static001.geekbang.org/account/avatar/00/13/0c/0b/d475f530.jpg","comment_is_top":false,"comment_ctime":1569487218,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1569487218","product_id":100025301,"comment_content":"蔡老师， 对于流处理需要对pipeline中的数据，进行数据补充时，可以使用 sideinput, 但是我看了官方文档，只能是静态的metadata，然后再Pardo中加到每一条数据， 并不能动态更新这个sideinput（比如在数据库中动态查询), 请问这种情况能怎么解决？","like_count":0,"discussions":[{"author":{"id":1897610,"avatar":"","nickname":"Fiery","note":"","ucode":"CDB000687A6B14","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":205445,"discussion_content":"可能是需要把数据库信息当做sideinput传起来，ParDo里开一个client连接到数据库查询吧，或者如果你能把逻辑写成两个dataset互相join的形式的话，就把数据库中的表也加载到pipeline里作为另一个PCollection，然后直接做inner/outer join","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1584314395,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":117103,"user_name":"李孟","can_delete":false,"product_type":"c1","uid":1006768,"ip_address":"","ucode":"AD2349CB12F130","user_header":"https://static001.geekbang.org/account/avatar/00/0f/5c/b0/77e5f8c8.jpg","comment_is_top":false,"comment_ctime":1563968815,"is_pvip":true,"discussion_count":1,"race_medal":0,"score":"1563968815","product_id":100025301,"comment_content":"老师我想问下， PCollection&lt;String&gt;这个种懒加载出来的集合怎么转存成临时的list集合？","like_count":0,"discussions":[{"author":{"id":1625510,"avatar":"https://static001.geekbang.org/account/avatar/00/18/cd/a6/420da5c9.jpg","nickname":"谭俊杰","note":"","ucode":"FA93EAAF5926F2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":219572,"discussion_content":"老师 Google 开发大数据平台 注要语言是 Java 还是python 还是 go 啊 我说的是主流 谢谢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1585783757,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}