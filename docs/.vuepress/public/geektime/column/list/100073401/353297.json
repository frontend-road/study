{"id":353297,"title":"03 | RDD：为什么你必须要理解弹性分布式数据集？","content":"<p>你好，我是吴磊。</p><p>从今天开始，我们进入原理篇的学习。我会以性能调优为导向，给你详细讲讲Spark中的核心概念RDD和DAG，以及重要组件调度系统、存储系统和内存管理。这节课，咱们先来说说RDD。</p><p>RDD可以说是Spark中最基础的概念了，使用Spark的开发者想必对RDD都不陌生，甚至提起RDD，你的耳朵可能都已经听出茧子了。不过，随着Spark开发API的演进和发展，现在上手开发基本都是DataFrame或Dataset API。所以很多初学者会认为，“反正RDD API基本都没人用了，我也没必要弄明白RDD到底是什么。”</p><p>真的是这样的吗？当然不是。</p><h2>RDD为何如此重要</h2><p>首先，RDD作为Spark对于分布式数据模型的抽象，是构建Spark分布式内存计算引擎的基石。很多Spark核心概念与核心组件，如DAG和调度系统都衍生自RDD。<strong>因此，深入理解RDD有利于你更全面、系统地学习Spark的工作原理。</strong></p><p>其次，尽管RDD API使用频率越来越低，绝大多数人也都已经习惯于DataFrame和Dataset API，但是，无论采用哪种API或是哪种开发语言，你的应用在Spark内部最终都会转化为RDD之上的分布式计算。换句话说，<strong>如果你想要在运行时判断应用的性能瓶颈，前提是你要对RDD足够了解</strong>。还记得吗？定位性能瓶颈是Spark性能调优的第一步。</p><!-- [[[read_end]]] --><p>不仅如此，对于RDD不求甚解还有可能带来潜在的性能隐患，接下来，我们就从一个反例入手，一起来分析一下。</p><p>还记得，我们在第1讲中讲过的数据过滤与聚合的反例吗？通过这个例子我们明白了性能调优的必要性。那这个例子和RDD有什么关系呢？</p><p>别着急，我们先来回顾一下这个案例中的代码实现，去挖掘开发者采用这种实现方式的深层原因。</p><pre><code>  //实现方案1 —— 反例\ndef createInstance(factDF: DataFrame, startDate: String, endDate: String): DataFrame = {\nval instanceDF = factDF\n    .filter(col(&quot;eventDate&quot;) &gt; lit(startDate) &amp;&amp; col(&quot;eventDate&quot;) &lt;= lit(endDate))\n    .groupBy(&quot;dim1&quot;, &quot;dim2&quot;, &quot;dim3&quot;, &quot;event_date&quot;)\n    .agg(&quot;sum(value) as sum_value&quot;)\ninstanceDF\n}\n \npairDF.collect.foreach{\ncase (startDate: String, endDate: String) =&gt;\n    val instance = createInstance(factDF, startDate, endDate)\n    val outPath = s&quot;${rootPath}/endDate=${endDate}/startDate=${startDate}&quot;\n    instance.write.parquet(outPath)\n} \n\n</code></pre><p>在这段代码中，createInstance的主要逻辑是按照时间条件对factDF进行过滤，返回汇总的业务统计量，然后pairDF循环遍历每一对开始时间和结束时间，循环调用createInstance获取汇总结果并落盘。我们在<a href=\"https://time.geekbang.org/column/article/352035\">第1课</a>中分析过，这份代码的主要问题在于囊括上千万行数据的factDF被反复扫描了几百次，而且是全量扫描，从而拖垮了端到端的执行性能。</p><p>那么，我们不禁要问：开发者究竟为什么会想到用这种低效的方式去实现业务逻辑呢？或者说，是什么内驱因素让开发者自然而然地采用这种实现方式呢？</p><p>让我们跳出Spark、跳出这个专栏，把自己置身于一间教室内：黑板前，老师正在讲解《XX语言编程》，旁边是你的同学，他边听老师讲课，边翻看着桌上的课本。这个场景熟不熟悉？亲不亲切？回想一下，老师讲的、书本上教的和我们示例中的代码，是不是极其类似？</p><p>没错！我们的大脑，已经习惯了for循环，习惯了用函数处理变量、封装计算逻辑，习惯了面向过程的编程模式。在分布式计算出现以前，我们都是这么开发的，老师也是这么讲的，书本上也是这么教的，没毛病。</p><p>因此我认为，开发者之所以会选择上面的实现方式，根本原因在于他把factDF当成了一个普通变量，一个与createInstance函数中startDate、endDate同等地位的形参，他并没有意识到，factDF实际上是一个庞大的、横跨所有计算节点的分布式数据集合，更没有意识到，在分布式运行环境中，外面的for循环会导致这个庞大的数据集被反复地全量扫描。</p><p>这种对于分布式计算认知方面的缺失，究其缘由，还是我们对Spark核心概念RDD的理解不够透彻。所以你看，深入理解RDD还是很有必要的，<strong>对于RDD一知半解，极有可能在应用开发的过程中，不知不觉地留下潜在的性能隐患</strong>。</p><h2>深入理解RDD</h2><p>既然RDD如此重要，它究竟是什么呢？2010年，在一个夜黑风高的夜晚，Matei等人发表了一篇名为《Spark: Cluster Computing with Working Sets》的论文并首次提出了RDD的概念。RDD，全称Resilient Distributed Datasets，翻译过来就是弹性分布式数据集。本质上，它是对于数据模型的抽象，用于囊括所有内存中和磁盘中的分布式数据实体。</p><p>如果就这么从理论出发、照本宣科地讲下去，未免过于枯燥、乏味、没意思！不如，我先来给你讲个故事。</p><h3>从薯片的加工流程看RDD</h3><p>在很久很久以前，有个生产桶装薯片的工坊，工坊的规模较小，工艺也比较原始。为了充分利用每一颗土豆、降低生产成本，工坊使用 3 条流水线来同时生产 3 种不同尺寸的桶装薯片。3 条流水线可以同时加工 3 颗土豆，每条流水线的作业流程都是一样的，分别是清洗、切片、烘焙、分发和装桶。其中，分发环节用于区分小、中、大号 3 种薯片，3种不同尺寸的薯片分别被发往第1、2、3条流水线。具体流程如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/3c/6e/3c7ff059e50f3dc70bf4yy082c31956e.jpg?wh=9021*2316\" alt=\"\" title=\"RDD的生活化类比\"></p><p>看得出来，这家工坊制作工艺虽然简单，倒也蛮有章法。从头至尾，除了分发环节，3 条流水线没有任何交集。在分发环节之前，每条流水线都是专心致志、各顾各地开展工作：把土豆食材加载到流水线上，再进行清洗、切片、烘焙；在分发环节之后，3 条流水线也是各自装桶，互不干涉、互不影响。流水线的作业方式提供了较强的容错能力，如果某个加工环节出错，工人们只需要往出错的流水线上重新加载一颗新的土豆，整个流水线就能够恢复生产。</p><p>好了，故事讲完了。如果我们把每一条流水线看作是分布式运行环境的计算节点，用薯片生产的流程去类比Spark分布式计算，会有哪些有趣的发现呢？</p><p>仔细观察，我们发现：<strong>刚从地里挖出来的土豆食材、清洗过后的干净土豆、生薯片、烤熟的薯片，流水线上这些食材的不同形态，就像是Spark中RDD对于不同数据集合的抽象</strong>。</p><p>沿着流水线的纵深方向，也就是图中从左向右的方向，每一种食材形态都是在前一种食材之上用相应的加工方法进行处理得到的。<strong>每种食材形态都依赖于前一种食材，这就像是RDD中dependencies属性记录的依赖关系，而不同环节的加工方法，对应的刚好就是RDD的compute属性。</strong></p><p>横看成岭侧成峰，再让我们从横向的角度来重新审视上面的土豆加工流程，也就是图中从上至下的方向，让我们把目光集中在流水线开端那3颗带泥的土豆上。这3颗土豆才从地里挖出来，是原始的食材形态，正等待清洗。如图所示，我们把这种食材形态标记为potatosRDD，那么，<strong>这里的每一颗土豆就是RDD中的数据分片，3颗土豆一起对应的就是RDD的partitions属性</strong>。</p><p><img src=\"https://static001.geekbang.org/resource/image/a2/c8/a2f8bc7bf10c31fedb85196f33f44fc8.jpg?wh=9021*2373\" alt=\"\"></p><p>带泥土豆经过清洗、切片和烘焙之后，按照大小个儿被分发到下游的3条流水线上，这3条流水线上承载的RDD记为shuffledBakedChipsRDD。很明显，这个RDD对于partitions的划分是有讲究的，根据尺寸的不同，即食薯片会被划分到不同的数据分片中。<strong>像这种数据分片划分规则，对应的就是RDD中的partitioner属性。</strong> 在分布式运行环境中，partitioner属性定义了RDD所封装的分布式数据集如何划分成数据分片。</p><p>总的来说，我们发现，薯片生产的流程和Spark分布式计算是一一对应的，一共可以总结为6点：</p><ul>\n<li>土豆工坊的每条流水线就像是分布式环境中的计算节点；</li>\n<li>不同的食材形态，如带泥的土豆、土豆切片、烘烤的土豆片等等，对应的就是RDD；</li>\n<li>每一种食材形态都会依赖上一种形态，如烤熟的土豆片依赖上一个步骤的生土豆切片。这种依赖关系对应的就是RDD中的dependencies属性；</li>\n<li>不同环节的加工方法对应RDD的compute属性；</li>\n<li>同一种食材形态在不同流水线上的具体实物，就是RDD的partitions属性；</li>\n<li>食材按照什么规则被分配到哪条流水线，对应的就是RDD的partitioner属性。</li>\n</ul><p>不知道土豆工坊的类比，有没有帮你逐渐勾勒出RDD的本来面貌呢？话付前言，接下来，咱们来一本正经地聊聊RDD。</p><h3>RDD的核心特征和属性</h3><p>通过刚才的例子，我们知道RDD具有4大属性，<strong>分别是partitions、partitioner、dependencies和compute属性。正因为有了这4大属性的存在，让RDD具有分布式和容错性这两大最突出的特性。</strong>要想深入理解RDD，我们不妨从它的核心特性和属性入手。</p><p><strong>首先，我们来看partitions、partitioner属性。</strong></p><p>在分布式运行环境中，RDD封装的数据在物理上散落在不同计算节点的内存或是磁盘中，这些散落的数据被称“数据分片”，RDD的分区规则决定了哪些数据分片应该散落到哪些节点中去。RDD的partitions属性对应着RDD分布式数据实体中所有的数据分片，而partitioner属性则定义了划分数据分片的分区规则，如按哈希取模或是按区间划分等。</p><p>不难发现，partitions和partitioner属性刻画的是RDD在跨节点方向上的横向扩展，所以我们把它们叫做RDD的“横向属性”。</p><p><strong>然后，我们再来说说dependencies和compute属性。</strong></p><p>在Spark中，任何一个 RDD 都不是凭空产生的，每个 RDD 都是基于某种计算逻辑从某个“数据源”转换而来。RDD的dependencies属性记录了生成RDD 所需的“数据源”，术语叫做父依赖（或父RDD），compute方法则封装了从父 RDD到当前RDD转换的计算逻辑。</p><p>基于数据源和转换逻辑，无论RDD有什么差池（如节点宕机造成部分数据分片丢失），在dependencies属性记录的父RDD之上，都可以通过执行compute封装的计算逻辑再次得到当前的RDD，如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/fb/91/fba28ce0c70b4c5553505911663aa491.jpg?wh=5496*1251\" alt=\"\" title=\"基于dependencies和compute属性得到当前RDD\"></p><p>由dependencies和compute属性提供的容错能力，为Spark分布式内存计算的稳定性打下了坚实的基础，这也正是RDD命名中Resilient的由来。接着观察上图，我们不难发现，不同的RDD通过dependencies和compute属性链接在一起，逐渐向纵深延展，构建了一张越来越深的有向无环图，也就是我们常说的DAG。</p><p>由此可见，dependencies属性和compute属性负责RDD在纵深方向上的延展，因此我们不妨把这两个属性称为“纵向属性”。</p><p>总的来说，<strong>RDD的4大属性又可以划分为两类，横向属性和纵向属性。其中，横向属性锚定数据分片实体，并规定了数据分片在分布式集群中如何分布；纵向属性用于在纵深方向构建DAG，通过提供重构RDD的容错能力保障内存计算的稳定性</strong>。</p><p>同时，为了帮助你记忆，我把这4大核心属性的基本概念和分类总结在了如下的表格中，你可以看一看。</p><p><img src=\"https://static001.geekbang.org/resource/image/ca/1e/ca6ef660c2b7f3777e244a535020191e.jpeg?wh=1920*875\" alt=\"\"></p><p>除此之外，我还想再多说两句。在这节课开头的反例中，我们分析了开发者采用foreach语句循环遍历分布式数据集的深层次原因。<strong>这种不假思索地直入面向过程编程、忽略或无视分布式数据实体的编程模式，我将其称为单机思维模式</strong>。</p><p>在学习了RDD横向的partitions属性和纵向的dependencies属性之后，如果你能把它们牢记于心，那么在频繁调用或引用这个RDD之前，你自然会想到它所囊括的数据集合，很有可能在全节点范围内被反复扫描、反复计算。这种下意识的反思会驱使你尝试探索其他更优的实现方式，从而跳出单机思维模式。因此，<strong>深入理解RDD，也有利于你跳出单机思维模式，避免在应用代码中留下性能隐患</strong>。</p><h2>小结</h2><p>今天，我带你学习了RDD的重要性，以及它的2大核心特性和4大属性。</p><p>首先，深入理解RDD对开发者来说有百利而无一害，原因有如下3点：</p><ul>\n<li>Spark很多核心概念都衍生自RDD，弄懂RDD，有利于你全面地学习Spark；</li>\n<li>牢记RDD的关键特性和核心属性，有利于你在运行时更好地定位性能瓶颈，而瓶颈定位，恰恰是性能调优的前提；</li>\n<li><strong>深入理解RDD有利于你跳出单机思维模式，避免在应用代码中留下性能隐患。</strong></li>\n</ul><p>关于RDD的特性与核心属性，只要你把如下2点牢记于心，我相信在不知不觉中你自然会绕过很多性能上的坑：</p><ul>\n<li>横向属性partitions和partitioner锚定数据分片实体，并且规定了数据分片在分布式集群中如何分布；</li>\n<li>纵向属性dependencies和compute用于在纵深方向构建DAG，通过提供重构RDD的容错能力保障内存计算的稳定性。</li>\n</ul><h2>每日一练</h2><ol>\n<li>\n<p>在日常的开发工作中，你遇到过“单机思维模式”吗？有哪些呢？</p>\n</li>\n<li>\n<p>除了我们今天讲的4大属性，RDD还有个很重要的属性：preferredLocations。按照经验，你认为在哪些情况下，preferredLocations很重要，会提升I/O效率，又在哪些环境中不起作用呢？为什么？</p>\n</li>\n</ol><p>期待在留言区看到你的思考，也欢迎你分享工作中遇到过的“单机思维模式”，我们下节课见！</p>","neighbors":{"left":{"article_title":"02 | 性能调优的本质：调优的手段五花八门，该从哪里入手？","id":352577},"right":{"article_title":"04 | DAG与流水线：到底啥叫“内存计算”？","id":353808}},"comments":[{"had_liked":false,"id":284226,"user_name":"Shockang","can_delete":false,"product_type":"c1","uid":1263546,"ip_address":"","ucode":"B871D731F6E6B1","user_header":"https://static001.geekbang.org/account/avatar/00/13/47/ba/d36340c1.jpg","comment_is_top":false,"comment_ctime":1616127303,"is_pvip":false,"replies":[{"id":"103121","content":"不错的技巧～","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1616162293,"ip_address":"","comment_id":284226,"utype":1}],"discussion_count":1,"race_medal":0,"score":"212069524807","product_id":100073401,"comment_content":"RDD的5大特性总结起来就是：3个列表，2个函数。3个列表是分区列表，依赖列表和优先位置列表；2个函数就是：计算函数和分区函数。我这样总结是为了方便记忆的，分享给大家！","like_count":50,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":517278,"discussion_content":"不错的技巧～","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616162293,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":285432,"user_name":"Z宇锤锤","can_delete":false,"product_type":"c1","uid":2188142,"ip_address":"","ucode":"7DB36E986A7A51","user_header":"https://static001.geekbang.org/account/avatar/00/21/63/6e/6b971571.jpg","comment_is_top":false,"comment_ctime":1616812583,"is_pvip":true,"replies":[{"id":"103591","content":"66666666666666666 x 10的6次幂，全场你最6～","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1616816666,"ip_address":"","comment_id":285432,"utype":1}],"discussion_count":3,"race_medal":0,"score":"78926223911","product_id":100073401,"comment_content":"RDD的四大特性：两横两纵一漂移。两纵土豆每一个生产线的流转就是父RDD到子RDD的流转，其中的流转方法就是compute算子。两横：就是土豆和土豆片之间的工具，切出来的土豆片就是partitions,怎么切土豆片就是partitoner。漂移就是prefered location,选择在哪个RDD上取数据。","like_count":19,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":517673,"discussion_content":"66666666666666666 x 10的6次幂，全场你最6～","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616816666,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2068627,"avatar":"https://static001.geekbang.org/account/avatar/00/1f/90/93/5e94be87.jpg","nickname":"钝感","note":"","ucode":"50FE1DD4EAEB78","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":402503,"discussion_content":"优秀课代表！！！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633886106,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1634643,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/JWSOxD8l9gLAcL1OL1hwSdXeibUfw56J9ngPxwrqOvibRT6zNuJR0oW3Vw4ymDGrua1xlWk7kOEEZZ7Ero44o8ibw/132","nickname":"Michealkz","note":"","ucode":"6DCD497FA5B3AA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":363233,"discussion_content":"大锤👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617153283,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":284751,"user_name":"sparkjoy","can_delete":false,"product_type":"c1","uid":1000179,"ip_address":"","ucode":"827B3116EED3B8","user_header":"https://static001.geekbang.org/account/avatar/00/0f/42/f3/e945e4ac.jpg","comment_is_top":false,"comment_ctime":1616460341,"is_pvip":false,"replies":[{"id":"103307","content":"正解～","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1616474670,"ip_address":"","comment_id":284751,"utype":1}],"discussion_count":4,"race_medal":0,"score":"53156067893","product_id":100073401,"comment_content":"preferredLocations不起作用的场景有一种是存算分离的场景，计算节点在k8s集群里，远程读取分布式文件系统，例如hdfs或者ceph等，可能接入万兆SDN网络能够有一些收益","like_count":13,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":517454,"discussion_content":"正解～","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616474670,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":362598,"discussion_content":"能保证node_local以上的级别，就是“数据不动代码动”；保证不了，就是数据动\n","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1616989635,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1581245,"avatar":"https://static001.geekbang.org/account/avatar/00/18/20/bd/5656b5d7.jpg","nickname":"走刀口 💰","note":"","ucode":"C7E2B812A4A02C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":362199,"discussion_content":"没理解，存算分离，意味着数据向计算移动。你需要先把hdfs的数据读到k8s集群上。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616889633,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2188142,"avatar":"https://static001.geekbang.org/account/avatar/00/21/63/6e/6b971571.jpg","nickname":"Z宇锤锤","note":"","ucode":"7DB36E986A7A51","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":361957,"discussion_content":"那这样子 数据不就移动了。。没有移动计算。。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616812640,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":313353,"user_name":"sparkjoy","can_delete":false,"product_type":"c1","uid":1000179,"ip_address":"","ucode":"827B3116EED3B8","user_header":"https://static001.geekbang.org/account/avatar/00/0f/42/f3/e945e4ac.jpg","comment_is_top":false,"comment_ctime":1632387143,"is_pvip":false,"replies":[{"id":"113541","content":"入口其实都是runJob，driver首先创建并提交最后一个stage。然后依次向前回溯，边创建stage边提交，直到最前面的stage。<br><br>具体的代码调用，可以看看infoQ的那篇《权力的游戏：Spark调度系统》。链接我回头帮你搜搜，那篇代码路径写的非常清楚～<br><br>链接：https:&#47;&#47;www.infoq.cn&#47;article&#47;5aOHzQIaXX6NlHriLtSI","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1632484531,"ip_address":"","comment_id":313353,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18812256327","product_id":100073401,"comment_content":"老师，spark是惰性计算，action算子才能真正触发算子的计算逻辑，那么DAG（rdd的实例化以及dependency对象的创建）是什么时候构建的呢？没找到DAG创建的代码入口","like_count":5,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527323,"discussion_content":"入口其实都是runJob，driver首先创建并提交最后一个stage。然后依次向前回溯，边创建stage边提交，直到最前面的stage。\n\n具体的代码调用，可以看看infoQ的那篇《权力的游戏：Spark调度系统》。链接我回头帮你搜搜，那篇代码路径写的非常清楚～\n\n链接：https://www.infoq.cn/article/5aOHzQIaXX6NlHriLtSI","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1632484531,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":298050,"user_name":"慢慢卢","can_delete":false,"product_type":"c1","uid":1329566,"ip_address":"","ucode":"853D399100D83B","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/IcDlyK6DaBrssVGlmosXnahdJ4bwCesjXa98iaapSDozBiagZTqSCok6iaktu2wOibvpNv9Pd6nfwMg7N7KTSTzYRw/132","comment_is_top":false,"comment_ctime":1623896777,"is_pvip":false,"replies":[{"id":"108251","content":"666，没错，就是容错能力~","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1624008498,"ip_address":"","comment_id":298050,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14508798665","product_id":100073401,"comment_content":"读了两遍，开始不太理解容错和Resilient 有什么关系，读了两遍，有点感觉了：弹性描述物体在压缩和拉伸之后具备恢复原状的能力。类比RDD，rdd因为依赖和compute，具备了错误恢复能力，把这个性质称之为弹性。","like_count":4,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":522000,"discussion_content":"666，没错，就是容错能力~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1624008498,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":285547,"user_name":"走刀口 💰","can_delete":false,"product_type":"c1","uid":1581245,"ip_address":"","ucode":"C7E2B812A4A02C","user_header":"https://static001.geekbang.org/account/avatar/00/18/20/bd/5656b5d7.jpg","comment_is_top":false,"comment_ctime":1616890355,"is_pvip":false,"replies":[{"id":"103658","content":"是的，不能单纯根据分区数完成判断。<br><br>看算子，分类讨论。一类算子会直接记录宽窄依赖关系，另一类算子通过判断partitioner与父依赖是否一致来决定。<br><br>你可以在源码的RDD目录下查一查，哪些算子属于第一类，哪些属于第二类～","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1616979436,"ip_address":"","comment_id":285547,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14501792243","product_id":100073401,"comment_content":"老师，请教个问题，关于宽窄依赖划分。网上很多文章是根据父子rdd分区数量划分的，但我这样不对。比如cartsian算子，它父rdd一个分区对应子rdd多个分区，可它是窄依赖。<br>宽窄依赖划分依据到底是啥？","like_count":3,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":517706,"discussion_content":"是的，不能单纯根据分区数完成判断。\n\n看算子，分类讨论。一类算子会直接记录宽窄依赖关系，另一类算子通过判断partitioner与父依赖是否一致来决定。\n\n你可以在源码的RDD目录下查一查，哪些算子属于第一类，哪些属于第二类～","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616979436,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":315421,"user_name":"钝感","can_delete":false,"product_type":"c1","uid":2068627,"ip_address":"","ucode":"50FE1DD4EAEB78","user_header":"https://static001.geekbang.org/account/avatar/00/1f/90/93/5e94be87.jpg","comment_is_top":false,"comment_ctime":1633886388,"is_pvip":false,"replies":[{"id":"114408","content":"哈哈，一起加油~","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1633961929,"ip_address":"","comment_id":315421,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10223820980","product_id":100073401,"comment_content":"刚开始听的时候：“什么土豆工坊？什么土豆片，什么形态，什么流水线，什么加工方法？”这都是啥啊。。再往后听，我的天！！这形容比喻也太贴切了吧！！👍，虽然已是深夜，但还是从床上起了起来，边吃薯片边听，我要听一宿，我要学习！！！🙈","like_count":2,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527970,"discussion_content":"哈哈，一起加油~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633961929,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":285431,"user_name":"Z宇锤锤","can_delete":false,"product_type":"c1","uid":2188142,"ip_address":"","ucode":"7DB36E986A7A51","user_header":"https://static001.geekbang.org/account/avatar/00/21/63/6e/6b971571.jpg","comment_is_top":false,"comment_ctime":1616812173,"is_pvip":true,"replies":[{"id":"103592","content":"可以的，相当精辟～","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1616816782,"ip_address":"","comment_id":285431,"utype":1}],"discussion_count":2,"race_medal":0,"score":"10206746765","product_id":100073401,"comment_content":"# 关于RDD的单机思维模式<br>## RDD中的集合排序问题<br>RDD.collect.sort<br>","like_count":2,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":517672,"discussion_content":"可以的，相当精辟～","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616816782,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2068627,"avatar":"https://static001.geekbang.org/account/avatar/00/1f/90/93/5e94be87.jpg","nickname":"钝感","note":"","ucode":"50FE1DD4EAEB78","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":402504,"discussion_content":"还是你，课代表就你来当吧👏","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633886604,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":284361,"user_name":"zxk","can_delete":false,"product_type":"c1","uid":1221195,"ip_address":"","ucode":"4BB2BD9D2BCD04","user_header":"https://static001.geekbang.org/account/avatar/00/12/a2/4b/b72f724f.jpg","comment_is_top":false,"comment_ctime":1616211724,"is_pvip":false,"replies":[{"id":"103153","content":"正解，能举例说明吗？","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1616283516,"ip_address":"","comment_id":284361,"utype":1}],"discussion_count":3,"race_medal":0,"score":"10206146316","product_id":100073401,"comment_content":"preferredLocations，作业尽可能在在数据所在节点上运行，或者同个机架下等情况，都可以提升 I&#47;O 效率。<br>当数据不管落在哪个节点，都需要从远端拉取数据时，这时候作用可能就不是那么大。","like_count":2,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":517319,"discussion_content":"正解，能举例说明吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616283516,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":360925,"discussion_content":"算的，不过现在kafka和spark也可以在物理上share一个集群，在这种情况下，node_local还是可以有的哈~ 各自独立部署的话，就没办法保证node_loca的本地性了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616557938,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1137879,"avatar":"https://static001.geekbang.org/account/avatar/00/11/5c/d7/e4673fde.jpg","nickname":"October","note":"","ucode":"CEDA78F4A5F8B1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":360766,"discussion_content":"spark streaming 连kafka算一个例子吗","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616512636,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":284252,"user_name":"L3nvy","can_delete":false,"product_type":"c1","uid":1271157,"ip_address":"","ucode":"0B74B27C121D56","user_header":"https://static001.geekbang.org/account/avatar/00/13/65/75/f9d7e8b7.jpg","comment_is_top":false,"comment_ctime":1616140069,"is_pvip":false,"replies":[{"id":"103120","content":"1. 算的，非常好的单机思维案例，凡是上来就面向过程，把分布式数据集rdd、dataframe、dataset当成普通单机变量的，都是单机思维的一种表现。不停的调action，我怀疑是想迫切地看到计算结果，忽略了action会触发dag回溯。<br><br>2.没错！通过jdbc远程访问db通常没办法保证本地性，沿着计算和存储分离的思路，再想一想，还有其他案例吗？","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1616162259,"ip_address":"","comment_id":284252,"utype":1}],"discussion_count":8,"race_medal":0,"score":"10206074661","product_id":100073401,"comment_content":"1. “单机模式”，不知道算不算。不知道Spark可以开多线程触发action算子，同时提交多个不相关的作业，Spark UI同时运行的job拉满 : )。之前代码都是按面向过程的思维一步一步写的。<br>2. 处理数据源的时候，jdbc，读取本地文件不起作用<br>","like_count":2,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":517286,"discussion_content":"1. 算的，非常好的单机思维案例，凡是上来就面向过程，把分布式数据集rdd、dataframe、dataset当成普通单机变量的，都是单机思维的一种表现。不停的调action，我怀疑是想迫切地看到计算结果，忽略了action会触发dag回溯。\n\n2.没错！通过jdbc远程访问db通常没办法保证本地性，沿着计算和存储分离的思路，再想一想，还有其他案例吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616162259,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1271157,"avatar":"https://static001.geekbang.org/account/avatar/00/13/65/75/f9d7e8b7.jpg","nickname":"L3nvy","note":"","ucode":"0B74B27C121D56","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":361003,"discussion_content":"python描述下\nrddList: List[RDD]\nexecutor = ThreadPoolExecutor()\nfor rdd in rddList:\n    executor.submit(lambda rdd: rdd.count(), rdd)\n\n类似这样开线程去提交，driver端的代码继续往下执行，继续触发action算子提交作业","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1616577361,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":2,"child_discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":1271157,"avatar":"https://static001.geekbang.org/account/avatar/00/13/65/75/f9d7e8b7.jpg","nickname":"L3nvy","note":"","ucode":"0B74B27C121D56","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":362596,"discussion_content":"简直太精髓了！超级典型的单机思维，这个例子简直太贴切了！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616989510,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":361003,"ip_address":""},"score":362596,"extra":""},{"author":{"id":2028277,"avatar":"https://static001.geekbang.org/account/avatar/00/1e/f2/f5/b82f410d.jpg","nickname":"Unknown element","note":"","ucode":"34A129800D0238","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1271157,"avatar":"https://static001.geekbang.org/account/avatar/00/13/65/75/f9d7e8b7.jpg","nickname":"L3nvy","note":"","ucode":"0B74B27C121D56","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":534420,"discussion_content":"你好 请问为什么说这个例子是单机模式的写法呢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1638185053,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":361003,"ip_address":""},"score":534420,"extra":""}]},{"author":{"id":2431882,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epKgrcbDrMyBJjITP9YabicyialvkVzgPqIyQGNIW8U8EZsJZsw9bHrotkkBEEMjicUWv7jictZZDgLvA/132","nickname":"Geek_1ea676","note":"","ucode":"C95D2F6044ED30","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":371875,"discussion_content":"大佬，你好，2.jdbc，读取本地文件不起作用，可以展开讲讲吗？为什么jdbc读取本地文件会不起作用？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1620031878,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":2431882,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epKgrcbDrMyBJjITP9YabicyialvkVzgPqIyQGNIW8U8EZsJZsw9bHrotkkBEEMjicUWv7jictZZDgLvA/132","nickname":"Geek_1ea676","note":"","ucode":"C95D2F6044ED30","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":377038,"discussion_content":"我之前看错了，应该是：通过jdbc远程访问db通常没办法保证本地性；但是读取本地文件是可以的，之前没看到“本地文件”这几个字，一看到jdbc就先入为主地想到远程读取数据库，我的锅~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1622470912,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":371875,"ip_address":""},"score":377038,"extra":""}]},{"author":{"id":2536938,"avatar":"https://static001.geekbang.org/account/avatar/00/26/b5/ea/c3c5753f.jpg","nickname":"ImSoo","note":"","ucode":"6A5F66C323E9CF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":360999,"discussion_content":"想问一下，“Spark可以开多线程触发action算子”这句话怎么理解，不太明白","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616577009,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1271157,"avatar":"https://static001.geekbang.org/account/avatar/00/13/65/75/f9d7e8b7.jpg","nickname":"L3nvy","note":"","ucode":"0B74B27C121D56","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2536938,"avatar":"https://static001.geekbang.org/account/avatar/00/26/b5/ea/c3c5753f.jpg","nickname":"ImSoo","note":"","ucode":"6A5F66C323E9CF","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":361015,"discussion_content":"\n\npython描述下\nrddList: List[RDD]\nexecutor = ThreadPoolExecutor()\nfor rdd in rddList:\n    executor.submit(lambda rdd: rdd.count(), rdd)\n\n类似这样开线程去提交，driver端的代码继续往下执行，继续触发action算子提交作业","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1616580129,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":360999,"ip_address":""},"score":361015,"extra":""}]}]},{"had_liked":false,"id":286167,"user_name":"林建林","can_delete":false,"product_type":"c1","uid":2531593,"ip_address":"","ucode":"FE0CAF61D12708","user_header":"","comment_is_top":false,"comment_ctime":1617175102,"is_pvip":false,"replies":[{"id":"103897","content":"对，是这个道理，不过要考虑，有些情况，可以数据不动代码动，有些情况，就必须要动数据了。这也是这个问题想要大家去深入思考的，要分类讨论。","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1617239263,"ip_address":"","comment_id":286167,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5912142398","product_id":100073401,"comment_content":"preferredLocations：可以理解为最佳位置，移动计算不移动数据，数据在哪就在哪计算，减少IO","like_count":1,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":517890,"discussion_content":"对，是这个道理，不过要考虑，有些情况，可以数据不动代码动，有些情况，就必须要动数据了。这也是这个问题想要大家去深入思考的，要分类讨论。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1617239263,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":285310,"user_name":"Insomnia","can_delete":false,"product_type":"c1","uid":1751214,"ip_address":"","ucode":"5986A48988D6E3","user_header":"https://static001.geekbang.org/account/avatar/00/1a/b8/ae/085484e7.jpg","comment_is_top":false,"comment_ctime":1616733001,"is_pvip":false,"replies":[{"id":"103562","content":"没错，理解的非常到位！本质上就是这么个过程。<br><br>当然yarn也有yarn client和yarn cluster模式哈，不过本质上区别不大，无非是app master &#47; driver放哪的问题，都适用你说的那个过程。","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1616758215,"ip_address":"","comment_id":285310,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5911700297","product_id":100073401,"comment_content":"老师, 我这么理解不知道对不对? <br>当下比较流行的计算框架 Spark&#47;Flink, 如果使用 Yarn 来调度计算任务, 对于 Yarn 而言, 本地的 Spark&#47;Flink 都可以看作是 Yarn 的客户端, 而对于用户而言, 编写的 job 都可以看做是本地的 Spark&#47;Flink 的客户端,  他们共同的本质都是使用本地 Spark&#47;Flink, 将用户的 job 解析并优化成物理执行计划, 然后提交到 Yarn 上部署执行","like_count":1,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":517641,"discussion_content":"没错，理解的非常到位！本质上就是这么个过程。\n\n当然yarn也有yarn client和yarn cluster模式哈，不过本质上区别不大，无非是app master / driver放哪的问题，都适用你说的那个过程。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616758215,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":285191,"user_name":"Geek_d794f8","can_delete":false,"product_type":"c1","uid":2485585,"ip_address":"","ucode":"1E20DA4FF8B800","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIiaeebUYxl7e4jicPshDRKMbiculHUjKgZZ2ygDibn2S7bbsjeqYIdsEUdVyoryKNa43ZGnDQmWjv3ibQ/132","comment_is_top":false,"comment_ctime":1616661846,"is_pvip":false,"replies":[{"id":"103475","content":"反过来说可能更合适，你有个yarn集群，那么就可以拿来给spark应用调度资源，甚至不需要额外部署什么“spark”集群。一般说spark集群，通常指的是工作在standalone调度模式下的集群。当然，如果你本身有一个standalone的spark集群，想换用yarn做资源调度，那么就像你说的，yarn要和spark部署在同一个集群。","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1616672383,"ip_address":"","comment_id":285191,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5911629142","product_id":100073401,"comment_content":"老师，如果计算和存储分离，比如计算集群A，存储集群B，且spark计算基于yarn调度，那么是不是，yarn集群必须部署在集群A上？","like_count":1,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":517610,"discussion_content":"反过来说可能更合适，你有个yarn集群，那么就可以拿来给spark应用调度资源，甚至不需要额外部署什么“spark”集群。一般说spark集群，通常指的是工作在standalone调度模式下的集群。当然，如果你本身有一个standalone的spark集群，想换用yarn做资源调度，那么就像你说的，yarn要和spark部署在同一个集群。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616672383,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":343287,"user_name":"面对疾风吧","can_delete":false,"product_type":"c1","uid":1340357,"ip_address":"","ucode":"6BEBC7CAC7C45A","user_header":"https://static001.geekbang.org/account/avatar/00/14/73/c5/d0880e7a.jpg","comment_is_top":false,"comment_ctime":1650763558,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1650763558","product_id":100073401,"comment_content":"Rdd 特性，分布式、容错性弹性、计算靠近存储","like_count":0},{"had_liked":false,"id":338527,"user_name":"Stony.修行僧","can_delete":false,"product_type":"c1","uid":1061277,"ip_address":"","ucode":"0F2368F7D93E4A","user_header":"https://static001.geekbang.org/account/avatar/00/10/31/9d/daad92d2.jpg","comment_is_top":false,"comment_ctime":1647550118,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1647550118","product_id":100073401,"comment_content":"面试归来，二刷RDD","like_count":0},{"had_liked":false,"id":310519,"user_name":"tony","can_delete":false,"product_type":"c1","uid":1254277,"ip_address":"","ucode":"D5BBFBEB576BE5","user_header":"https://static001.geekbang.org/account/avatar/00/13/23/85/e19f8833.jpg","comment_is_top":false,"comment_ctime":1630718212,"is_pvip":false,"replies":[{"id":"112553","content":"对，主要是从存储、计算分离的角度考虑这个问题，一旦两者分离，preferecneLocations就没有意义了~","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1630852611,"ip_address":"","comment_id":310519,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1630718212","product_id":100073401,"comment_content":"纯算分离 有 计算节点+oss，所有计算节点从oss访问数据，网络io代价差不多。为了加速计算节点访问速度，还会在计算节点上加个缓存。<br><br>所以当计算节点访问数据不在cache，那么preferecneLocations应该就不起什么作用了。这么理解对吗？","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":526261,"discussion_content":"对，主要是从存储、计算分离的角度考虑这个问题，一旦两者分离，preferecneLocations就没有意义了~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1630852611,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":300881,"user_name":"一群孤儿","can_delete":false,"product_type":"c1","uid":2039833,"ip_address":"","ucode":"9A9460DCBED4BB","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erqPQcbrNpo7UcKiaDpNbPaaV1A2TIprO7ryaVL3XaG89zhP5uibv7HuApkQDoaibPS7JGnNqP4ykFIg/132","comment_is_top":false,"comment_ctime":1625415521,"is_pvip":false,"replies":[{"id":"109048","content":"RDD是数据抽象，它对标的是分布式数据集，通过属性来刻画数据集。你的code里面，定义了多少个RDD，就有多少个RDD。","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1625526200,"ip_address":"","comment_id":300881,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1625415521","product_id":100073401,"comment_content":"RDD里面装的是数据吗? 一个spark任务有几个RDD?<br>","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":522839,"discussion_content":"RDD是数据抽象，它对标的是分布式数据集，通过属性来刻画数据集。你的code里面，定义了多少个RDD，就有多少个RDD。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1625526200,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2861352,"avatar":"","nickname":"阿狸弟弟的包子店","note":"","ucode":"0CCF598B029075","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":548833,"discussion_content":"RDD是一种数据结构，定义了: 数据从哪取，怎么取，取了怎么用，上级是谁","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1643419322,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":290945,"user_name":"xuchuan","can_delete":false,"product_type":"c1","uid":1954690,"ip_address":"","ucode":"3967199AA078C7","user_header":"https://static001.geekbang.org/account/avatar/00/1d/d3/82/c3e57eb3.jpg","comment_is_top":false,"comment_ctime":1619870337,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1619870337","product_id":100073401,"comment_content":"简单易懂，单机思维和分布式思维模式总结到位","like_count":0},{"had_liked":false,"id":290923,"user_name":"aof","can_delete":false,"product_type":"c1","uid":1062864,"ip_address":"","ucode":"5815D63C4926BC","user_header":"https://static001.geekbang.org/account/avatar/00/10/37/d0/26975fba.jpg","comment_is_top":false,"comment_ctime":1619861687,"is_pvip":false,"replies":[{"id":"105436","content":"第一个取决于计算场景哈，在高阶函数中使用自定义数据结构、或是辅助性的数据结构来完成计算，倒不一定就是单机思维~<br><br>对于preferredLocations、或者Task的本地性级别来说，所有Executors分布到同一个节点，倒不是关键。可以沿着计算、存储分离的思路，再想一想~ 不过你说的这种情况，让我想起了YARN的Label Based Scheduling，就是在做资源调度的时候，可以指定具体用哪些物理节点的资源。","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1619946821,"ip_address":"","comment_id":290923,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1619861687","product_id":100073401,"comment_content":"1. 单机思维，在RDD&#47;Dataset后面的map函数中使用了HashMap，哈哈<br>2. 除了计算分离、单节点计算之外，还有一种情况，比如我申请了5个Executor，但因为资源的问题，导致这5个Executor全部启在了同一个节点上。","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":519326,"discussion_content":"第一个取决于计算场景哈，在高阶函数中使用自定义数据结构、或是辅助性的数据结构来完成计算，倒不一定就是单机思维~\n\n对于preferredLocations、或者Task的本地性级别来说，所有Executors分布到同一个节点，倒不是关键。可以沿着计算、存储分离的思路，再想一想~ 不过你说的这种情况，让我想起了YARN的Label Based Scheduling，就是在做资源调度的时候，可以指定具体用哪些物理节点的资源。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1619946821,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1062864,"avatar":"https://static001.geekbang.org/account/avatar/00/10/37/d0/26975fba.jpg","nickname":"aof","note":"","ucode":"5815D63C4926BC","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":371781,"discussion_content":"第一个是我在map()函数外面声明了一个hashmap，然后在map()函数内部使用了这个hashmap。\n\n第二个多谢老师拓展，之前安装CDH之后，配置过YARN的队列资源隔离，但是node label这个确实没有用过，去查了一下官网：https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/NodeLabel.html","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1619967065,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":285045,"user_name":"弦断觅知音","can_delete":false,"product_type":"c1","uid":1283398,"ip_address":"","ucode":"6234916B97268C","user_header":"https://static001.geekbang.org/account/avatar/00/13/95/46/1cd5ab5f.jpg","comment_is_top":false,"comment_ctime":1616591112,"is_pvip":false,"replies":[{"id":"103474","content":"这种不算哈，可以沿着计算存储分离的思路再想想～","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1616671884,"ip_address":"","comment_id":285045,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1616591112","product_id":100073401,"comment_content":"preferredLocations不起作用情况之一，比如有单独机器作为集群的客户端，然后提交的任务在集群的客户端上运行，这种情况算不算？","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":517563,"discussion_content":"这种不算哈，可以沿着计算存储分离的思路再想想～","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616671884,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":284191,"user_name":"老A","can_delete":false,"product_type":"c1","uid":1806678,"ip_address":"","ucode":"6B3BB0851583BD","user_header":"https://static001.geekbang.org/account/avatar/00/1b/91/56/f714ad14.jpg","comment_is_top":false,"comment_ctime":1616117999,"is_pvip":false,"replies":[{"id":"103122","content":"这块确实有点难，因为我们还没讲到调度系统，也还没细讲locality。再想一想，沿着计算和存储物理分离的思路哈～","user_name":"作者回复","user_name_real":"吴磊","uid":"1043100","ctime":1616162465,"ip_address":"","comment_id":284191,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1616117999","product_id":100073401,"comment_content":"preferredLocations 不起作用，应该在数据源是单节点情况，比如socket数据源，还有就是读取hdfs的数据块比较小不足一个split分片128M的情况，还有就是大的压缩数据块，比如snappy压缩，这种压缩不支持切分的情况。","like_count":0,"discussions":[{"author":{"id":1043100,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/ea/9c/230061e7.jpg","nickname":"吴磊","note":"","ucode":"136DC8CF1B10DC","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":517265,"discussion_content":"这块确实有点难，因为我们还没讲到调度系统，也还没细讲locality。再想一想，沿着计算和存储物理分离的思路哈～","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616162465,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]}]}