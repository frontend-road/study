{"id":495931,"title":"13 | 微博系统设计：怎么应对热点事件的突发访问压力？","content":"<p>你好，我是李智慧。</p><p>微博（microblog）是一种允许用户即时更新简短文本（比如140个字符），并可以公开发布的微型博客形式。今天我们就来开发一个面向全球用户、可以支持10亿级用户体量的微博系统，系统名称为“Weitter”。</p><p>我们知道，微博有一个重要特点就是部分明星大V拥有大量的粉丝。如果明星们发布一条比较有话题性的个人花边新闻，比如宣布结婚或者离婚，就会引起粉丝们大量的转发和评论，进而引起更大规模的用户阅读和传播。</p><p>这种突发的单一热点事件导致的高并发访问会给系统带来极大的负载压力，处理不当甚至会导致系统崩溃。而这种崩溃又会成为事件热点的一部分，进而引来更多的围观和传播。</p><p>因此，Weitter的技术挑战，一方面是微博这样类似的信息流系统架构是如何设计的，另一方面就是如何解决大V们的热点消息产生的突发高并发访问压力，保障系统的可用性。今天我们就来看看这样的系统架构该怎么设计。</p><h2>需求分析</h2><p>Weitter的核心功能只有三个：发微博，关注好友，刷微博。</p><p><img src=\"https://static001.geekbang.org/resource/image/27/0a/27dbd5c5f28b1d834a8be005391e7e0a.jpg?wh=1920x1077\" alt=\"图片\"></p><ol>\n<li>发微博：用户可以发表微博，内容包含不超过140个字的文本，可以包含图片和视频。</li>\n<li>关注好友：用户可以关注其他用户。</li>\n<li>刷微博：用户打开自己的微博主页，主页显示用户关注的好友最近发表的微博；用户向下滑动页面（或者点刷新按钮），主页将更新关注好友的最新微博，且最新的微博显示在最上方；主页一次显示20条微博，当用户滑动到主页底部后，继续向上滑动，会按照时间顺序，显示当前页面后续的20条微博。</li>\n<li>此外，用户还可以收藏、转发、评论微博。</li>\n</ol><!-- [[[read_end]]] --><h4>性能指标估算</h4><p>系统按10亿用户设计，按20%日活估计，大约有2亿日活用户（DAU），其中每个日活用户每天发表一条微博，并且平均有500个关注者。</p><p>而对于<strong>发微博所需的存储空间</strong>，我们做如下估算。</p><ul>\n<li><strong>文本内容存储空间</strong></li>\n</ul><p>遵循惯例，每条微博140个字，如果以UTF8编码存储汉字计算，则每条微博需要$\\small 140\\times3=420$个字节的存储空间。除了汉字内容以外，每条微博还需要存储微博ID、用户ID、时间戳、经纬度等数据，按80个字节计算。那么每天新发表微博文本内容需要的存储空间为100GB。</p><p>$\\small 2亿 \\times (420B +80B) = 100GB/天$</p><ul>\n<li><strong>多媒体文件存储空间</strong></li>\n</ul><p>除了140字文本内容，微博还可以包含图片和视频，按每5条微博包含一张图片，每10条微博包含一个视频估算，每张图片500KB，每个视频2MB，每天还需要60TB的多媒体文件存储空间。</p><p>$\\small 2亿\\div5\\times500KB+2亿\\div10\\times2MB=60TB/天$</p><p>对于<strong>刷微博的访问并发量</strong>，我们做如下估算。</p><ul>\n<li><strong>QPS</strong></li>\n</ul><p>假设两亿日活用户每天浏览两次微博，每次向上滑动或者进入某个人的主页10次，每次显示20条微博，每天刷新微博次数40亿次，即40亿次微博查询接口调用，平均QPS大约5万。</p><p>$\\small 40亿\\div（24\\times60\\times60）=46296/秒$</p><p>高峰期QPS按平均值2倍计算，所以系统需要满足10万QPS。</p><ul>\n<li><strong>网络带宽</strong></li>\n</ul><p>10万QPS刷新请求，每次返回微博20条，那么每秒需访问200万条微博。按此前估计，每5条微博包含一张图片，每10条微博包含一个视频，需要的<strong>网络总带宽</strong>为4.8Tb/s。</p><p>$\\small （200万\\div5\\times500KB+200万\\div10\\times2MB）\\times8bit=4.8Tb/s$</p><h2>概要设计</h2><p>在需求分析中我们可以看到，Weitter的业务逻辑比较简单，但是<strong>并发量</strong>和<strong>数据量</strong>都比较大，所以，<strong>系统架构的核心就是解决高并发的问题</strong>，系统整体部署模型如下。</p><p><img src=\"https://static001.geekbang.org/resource/image/c3/4d/c3f3c3abe0708f5ebe31bf25eec67f4d.jpg?wh=1920x1054\" alt=\"图片\"></p><p>这里包含了“Get请求”和“Post请求”两条链路，Get请求主要处理刷微博的操作，Post请求主要处理发微博的请求，这两种请求处理也有重合的部分，我们拆分着来看。</p><p>我们先来看看<strong>Get请求</strong>的部分。</p><p><img src=\"https://static001.geekbang.org/resource/image/c1/99/c19yy285078b6c40513c36503eee4799.jpg?wh=1920x1054\" alt=\"图片\"></p><p>用户通过CDN访问Weitter的数据中心、图片以及视频等极耗带宽的请求，绝大部分可以被CDN缓存命中，也就是说，4.8Tb/s的带宽压力，90%以上可以通过CDN消化掉。</p><p>没有被CDN命中的请求，一部分是图片和视频请求，其余主要是用户刷新微博请求、查看用户信息请求等，这些请求到达数据中心的反向代理服务器。反向代理服务器检查本地缓存是否有请求需要的内容。如果有，就直接返回；如果没有，对于图片和视频文件，会通过分布式文件存储集群获取相关内容并返回。分布式文件存储集群中的图片和视频是用户发表微博的时候，上传上来的。</p><p>对于用户微博内容等请求，如果反向代理服务器没有缓存，就会通过负载均衡服务器到达应用服务器处理。应用服务器首先会从Redis缓存服务器中，检索当前用户关注的好友发表的最新微博，并构建一个结果页面返回。如果Redis中缓存的微博数据量不足，构造不出一个结果页面需要的20条微博，应用服务器会继续从MySQL分片数据库中查找数据。</p><p>以上处理流程主要是针对读（http get）请求，那如果是发表微博这样的写（http post）请求呢？我们再来看一下<strong>写请求</strong>部分的图。</p><p><img src=\"https://static001.geekbang.org/resource/image/98/84/980db8e510ef320d44af9c53244d7e84.jpg?wh=1920x1054\" alt=\"图片\"></p><p>你会看到，客户端不需要通过CDN和反向代理，而是直接通过负载均衡服务器到达应用服务器。应用服务器一方面会将发表的微博写入Redis缓存集群，一方面写入分片数据库中。</p><p>在写入数据库的时候，如果直接写数据库，当有高并发的写请求突然到来，可能会导致数据库过载，进而引发系统崩溃。所以，数据库写操作，包括发表微博、关注好友、评论微博等，都写入到消息队列服务器，由消息队列的消费者程序从消息队列中按照一定的速度消费消息，并写入数据库中，保证数据库的负载压力不会突然增加。</p><h2>详细设计</h2><p>用户刷新微博的时候，如何能快速得到自己关注的好友的最新微博列表？10万QPS的并发量如何应对？如何避免数据库负载压力太大以及如何快速响应用户请求？详细设计将基于功能需求和概要设计，主要讨论这些问题。</p><h4><strong>微博的发表/订阅问题</strong></h4><p>Weitter用户关注好友后，如何快速得到所有好友的最新发表的微博内容，即发表/订阅问题，是微博的核心业务问题。</p><p>一种简单的办法就是“推模式”，即建一张用户订阅表，用户关注的好友发表微博后，立即在用户订阅中为该用户插入一条记录，记录用户id和好友发表的微博id。这样当用户刷新微博的时候，只需要从用户订阅表中按用户id查询所有订阅的微博，然后按时间顺序构建一个列表即可。也就是说，<strong>推模式是在用户发<strong><strong>微博</strong></strong>的时候推送给所有的关注者</strong>，如下图，用户发表了微博0，他的所有关注者的订阅表都插入微博0。</p><p><img src=\"https://static001.geekbang.org/resource/image/91/84/91c929429edf6302fdea61e9e41dfa84.jpg?wh=1920x804\" alt=\"图片\"></p><p>推模式实现起来比较简单，但是推模式意味着，如果一个用户有大量的关注者，那么该用户每发表一条微博，就需要在订阅表中为每个关注者插入一条记录。而对于明星用户而言，可能会有几千万的关注者，明星用户发表一条微博，就会导致上千万次的数据库插入操作，直接导致系统崩溃。</p><p>所以，对于10亿级用户的微博系统而言，我们需要使用“拉模式”解决发表/订阅问题。也就是说，用户刷新微博的时候，根据其关注的好友列表，查询每个好友近期发表的微博，然后将所有微博按照时间顺序排序后构建一个列表。也就是说，<strong>拉模式是在用户刷微博的时候拉取他关注的所有好友的最新微博</strong>，如下图：</p><p><img src=\"https://static001.geekbang.org/resource/image/95/37/95a92ce90c758f9ba814c15724be7137.jpg?wh=1920x691\" alt=\"图片\"></p><p>拉模式极大降低了发表微博时写入数据的负载压力，但是却又急剧增加了刷微博时候读数据库的压力。因为对于用户关注的每个好友，都需要进行一次数据库查询。如果一个用户关注了大量好友，查询压力也是非常巨大的。</p><p>所以，首先需要限制用户关注的好友数，在Weitter中，普通用户关注上限是2000人，VIP用户关注上限是5000人。其次，需要尽量减少刷新时查询数据库的次数，也就是说，微博要尽量通过缓存读取。</p><p>但即使如此，你会发现每次刷新的查询压力还是太大，所以Weitter最终采用“推拉结合”的模式。也就是说，如果用户当前在线，那么就会使用推模式，系统会在缓存中为其创建一个好友最新发表微博列表，关注的好友如果有新发表微博，就立即将该微博插入列表的头部，当该用户刷新微博的时候，只需要将这个列表返回即可。</p><p>如果用户当前不在线，那么系统就会将该列表删除。当用户登录刷新的时候，用拉模式为其重新构建列表。</p><p>那么如何确定一个用户是否在线？一方面可以通过用户操作时间间隔来判断，另一方面也可以通过机器学习，预测用户的上线时间，利用系统空闲时间，提前为其构建最新微博列表。</p><h4>缓存使用策略</h4><p>通过前面的分析我们已经看到，Weitter是一个典型的高并发读操作的场景。10万QPS刷新请求，每个请求需要返回20条微博，如果全部到数据库中查询的话，数据库的QPS将达到200万，即使是使用分片的分布式数据库，这种压力也依然是无法承受的。所以，我们需要大量使用缓存以改善性能，提高吞吐能力。</p><p>但是缓存的空间是有限的，我们必定不能将所有数据都缓存起来。一般缓存使用的是LRU淘汰算法，即当缓存空间不足时，将最近最少使用的缓存数据删除，空出缓存空间存储新数据。</p><p>但是LRU算法并不适合微博的场景，因为在拉模式的情况下，当用户刷新微博的时候，我们需要确保其关注的好友最新发表的微博都能展示出来，如果其关注的某个好友较少有其他关注者，那么这个好友发表的微博就很可能会被LRU算法淘汰删除出缓存。对于这种情况，系统就不得不去数据库中进行查询。</p><p>而最关键的是，系统并不能知道哪些好友的数据通过读缓存就可以得到全部最新的微博，而哪些好友需要到数据库中查找。因此不得不全部到数据库中查找，这就失去了使用缓存的意义。</p><p>基于此，我们在Weitter中使用<strong>时间淘汰算法</strong><strong>，</strong>也就是将最近一定天数内发布的微博全部缓存起来，用户刷新微博的时候，只需要在缓存中进行查找。如果查找到的微博数满足一次返回的条数（20条），就直接返回给用户；如果缓存中的微博数不足，就再到数据库中查找。</p><p>最终，Weitter决定缓存7天内发表的全部微博，需要的缓存空间约700G。缓存的key为用户ID，value为用户最近7天发表的微博ID列表。而微博ID和微博内容分别作为key和value也缓存起来。</p><p>此外，对于特别热门的微博内容，比如某个明星的离婚微博，这种针对单个微博内容的高并发访问，由于访问压力都集中一个缓存key上，会给单台Redis服务器造成极大的负载压力。因此，微博还会启用<strong>本地缓存模式</strong>，即应用服务器在内存中缓存特别热门的微博内容，应用构建微博刷新页的时候，会优先检查微博ID对应的微博内容是否在本地缓存中。</p><p>Weitter最后确定的本地缓存策略是：针对拥有100万以上关注者的大V用户，缓存其48小时内发表的全部微博。</p><p>现在，我们来看一下Weitter整体的缓存架构。</p><p><img src=\"https://static001.geekbang.org/resource/image/b0/8b/b039901b8cfaa6d1038007703ae1468b.jpg?wh=1920x691\" alt=\"图片\"></p><h4>数据库分片策略</h4><p>前面我们分析过，Weitter每天新增2亿条微博。也就是说，平均每秒钟需要写入2400条微博，高峰期每秒写入4600条微博。这样的写入压力，对于单机数据库而言是无法承受的。而且，每年新增700亿条微博记录，这也超出了单机数据库的存储能力。因此，Weitter的数据库需要采用分片部署的分布式数据库。分片的规则可以采用用户ID分片或者微博 ID分片。</p><p>如果按用户ID（的hash值）分片，那么一个用户发表的全部微博都会保存到一台数据库服务器上。这样做的好处是，当系统需要按用户查找其发表的微博的时候，只需要访问一台服务器就可以完成。</p><p>但是这样做也有缺点，对于一个明星大V用户，其数据访问会成热点，进而导致这台服务器负载压力太大。同样地，如果某个用户频繁发表微博，也会导致这台服务器数据增长过快。</p><p>要是按微博 ID（的hash值）分片，虽然可以避免上述按用户ID分片的热点聚集问题，但是当查找一个用户的所有微博时，需要访问所有的分片数据库服务器才能得到所需的数据，对数据库服务器集群的整体压力太大。</p><p>综合考虑，用户ID分片带来的热点问题，可以通过优化缓存来改善；而某个用户频繁发表微博的问题，可以通过设置每天发表微博数上限（每个用户每天最多发表50条微博）来解决。最终，Weitter采用按用户ID分片的策略。</p><h2>小结</h2><p>微博事实上是<strong>信息流应用产品</strong>中的一种，这类应用都以滚动的方式呈现内容，而内容则被放置在一个挨一个、外观相似的版块中。微信朋友圈、抖音、知乎、今日头条等，都是这类应用。因此这些应用也都需要面对微博这样的发表/订阅问题：<strong>如何为海量高并发用户快速构建页面内容</strong>？</p><p>在实践中，信息流应用也大多采用文中提到的<strong>推拉结合模式</strong>，区别只是朋友圈像微博一样推拉好友发表的内容，而今日头条则推拉推荐算法计算出来的结果。同样地，这类应用为了加速响应时间，也大量使用CDN、反向代理、分布式缓存等缓存方案。所以，熟悉了Weitter的架构，就相当于掌握了信息流产品的架构。</p><h2>思考题</h2><p>面对微博的高并发访问压力，你还能想到哪些方案可以优化系统？</p><p>欢迎在评论区分享你的思考，我们共同进步。</p>","neighbors":{"left":{"article_title":"期中测试 | 动手写一篇你自己的设计文档吧！","id":495175},"right":{"article_title":"14 | 百科应用系统设计：机房被火烧了系统还能访问吗？","id":496746}},"comments":[{"had_liked":false,"id":340341,"user_name":"ABC","can_delete":false,"product_type":"c1","uid":1054958,"ip_address":"","ucode":"7501AD9C0C4A70","user_header":"https://static001.geekbang.org/account/avatar/00/10/18/ee/a1ed60d1.jpg","comment_is_top":false,"comment_ctime":1648772216,"is_pvip":false,"replies":[{"id":"124460","content":"赞。这个方案应该可以解决前面同学 @猿人谷 提到的缓存一致性问题。","user_name":"作者回复","user_name_real":"作者","uid":"1007349","ctime":1648778709,"ip_address":"","comment_id":340341,"utype":1}],"discussion_count":1,"race_medal":0,"score":"44598445176","product_id":100105701,"comment_content":"在gitee上有一个jd-hotkey的项目，实现了热点数据推送至集群本地的功能，性能强悍。微博也可以用这种方式实现本地缓存。","like_count":11,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":559451,"discussion_content":"赞。这个方案应该可以解决前面同学 @猿人谷 提到的缓存一致性问题。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1648778709,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":338777,"user_name":"小荷才露尖尖角","can_delete":false,"product_type":"c1","uid":1068480,"ip_address":"","ucode":"C74284B1FEA6BB","user_header":"https://static001.geekbang.org/account/avatar/00/10/4d/c0/89a4194e.jpg","comment_is_top":false,"comment_ctime":1647731373,"is_pvip":false,"replies":[{"id":"123883","content":"给带来热点的大V们更多的缓存，比如百万以上粉丝的大V缓存所有历史微博数据，这样就根本不会访问数据库，也就没有热点压力。","user_name":"作者回复","user_name_real":"编辑","uid":"1007349","ctime":1647833034,"ip_address":"","comment_id":338777,"utype":1}],"discussion_count":2,"race_medal":0,"score":"14532633261","product_id":100105701,"comment_content":"用户 ID 分片带来的热点问题，可以通过优化缓存来改善；--老师可以再详细些么","like_count":3,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":557485,"discussion_content":"给带来热点的大V们更多的缓存，比如百万以上粉丝的大V缓存所有历史微博数据，这样就根本不会访问数据库，也就没有热点压力。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1647833035,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2825710,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eqMd9DibRjo8gqHo4DRSZO3lkZ2KMezY3z9ia77kNKv8hRLLDCics35Ll2HTMt2Eiadk8uZA0l0EiaOvLQ/132","nickname":"Tico","note":"","ucode":"768F5FD8562DF5","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":562466,"discussion_content":"那就是根据用户里设置缓存过期时长","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1649830457,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":344504,"user_name":"neohope","can_delete":false,"product_type":"c1","uid":1043475,"ip_address":"","ucode":"C0268F6E7E2B6E","user_header":"https://static001.geekbang.org/account/avatar/00/0f/ec/13/49e98289.jpg","comment_is_top":false,"comment_ctime":1651592348,"is_pvip":true,"replies":[{"id":"125787","content":"赞","user_name":"作者回复","user_name_real":"编辑","uid":"1007349","ctime":1651720462,"ip_address":"","comment_id":344504,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10241526940","product_id":100105701,"comment_content":"优化方面：<br>1、通过AI自动识别热点话题，识别地域性热点话题，热点话题加入服务端缓存<br>2、通过热点话题趋势预测，架构自动扩缩容<br>3、扛不住的时候，服务自动降级或熔断<br>4、跨区域多数据中心，就近访问<br>5、硬件方面，可以使用SSD，缓存新的非热点数据，替代内存，降低成本<br><br>功能方面：<br>1、热点话题管理<br>2、评论及转发管理<br>3、微博检索功能<br>4、微博合规性管理，包括屏蔽、删除功能<br>5、微博机器人识别","like_count":2,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":570267,"discussion_content":"赞","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1651720462,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":339126,"user_name":"猿人谷","can_delete":false,"product_type":"c1","uid":1100149,"ip_address":"","ucode":"85106C7FB14C43","user_header":"https://static001.geekbang.org/account/avatar/00/10/c9/75/62ce2d69.jpg","comment_is_top":false,"comment_ctime":1647933099,"is_pvip":true,"replies":[{"id":"123947","content":"微博不能修改，只需要处理删除的情况就可以。<br><br>分布式缓存在用户删微博的时候直接删除即可，本地缓存采用过期失效，过期失效时间2分钟。过期失效会导致明星删除微博后，失效到期前还能刷出微博内容，但这是运营方可以接受的，甚至是期望的。","user_name":"作者回复","user_name_real":"编辑","uid":"1007349","ctime":1647946542,"ip_address":"","comment_id":339126,"utype":1}],"discussion_count":2,"race_medal":0,"score":"10237867691","product_id":100105701,"comment_content":"对于特别热门的微博内容，启用本地缓存模式后，保证一致性（本地缓存、分布式缓存、数据库），大佬是用的哪种方案？","like_count":2,"discussions":[{"author":{"id":1100149,"avatar":"https://static001.geekbang.org/account/avatar/00/10/c9/75/62ce2d69.jpg","nickname":"猿人谷","note":"","ucode":"85106C7FB14C43","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":557859,"discussion_content":"是的，难点就是本地缓存的过期时间不好设定。运营方可以接受，但大V们不愿意接受，所以大V喜欢用“盗号”或“手抖”来解释这种现象。\n老师这篇文章实战型强，对解决信息流应用产品的架构设计提供了很好的思路，点赞","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1648003648,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":557732,"discussion_content":"微博不能修改，只需要处理删除的情况就可以。\n\n分布式缓存在用户删微博的时候直接删除即可，本地缓存采用过期失效，过期失效时间2分钟。过期失效会导致明星删除微博后，失效到期前还能刷出微博内容，但这是运营方可以接受的，甚至是期望的。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1647946542,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":338750,"user_name":"killer","can_delete":false,"product_type":"c1","uid":1047778,"ip_address":"","ucode":"E275AD8C4523FA","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/7P4wtgRQt1l0YQlVOtiaUKey2AFZqQCAcABzdCNTP0JR027tkhVkRYgj1iaYF8OlqsE8j6A6icsAvYHIAX8E31WNg/132","comment_is_top":false,"comment_ctime":1647699748,"is_pvip":false,"replies":[{"id":"123881","content":"1 用户上线后，先建立一个空的初始列表，如果这个时候好友发微博，就推到这个空的初始列表。然后用拉的方式构建一个拉列表，把拉列表内容接在前面的初始列表上。接的时候检查初始列表的内容是否在拉列表里，在的话，删除重复内容。<br>2 刷新微博就是按时间维度构建列表内容的，所以按照时间维度缓存，缓存不命中，说明关注的好友最近7天都不发微博，不活跃，大概率说明该用户自身也不活跃，符合缓存的设计目标。<br>","user_name":"作者回复","user_name_real":"编辑","uid":"1007349","ctime":1647832668,"ip_address":"","comment_id":338750,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10237634340","product_id":100105701,"comment_content":"1.推拉模式纬度是针对粉丝查询好友发布微博构造的列表，用户如果在线采用推方式构建一个列表，用户不在线，上线后分别拉好友消息构造列表，这里有一个疑问，上线后不是用推方式吗？如果是好友发表微博再用推的方式，那么怎么保证拉的方式和推的方式平滑过度呢？2.后面有一个缓存七天微博数据是按照用户id和发表微博的id进行缓存的，纬度是针对发表者来做的缓存。所以对粉丝刷新列表并没有命中缓存呢？这两个纬度不同解决的应该是不同的问题呢？3.最后一问题是回复Geek的问题，七天内数据缓存起来不需要每个用户拉20条，如果要实现这个不是应该按照用户id缓存所有好友的微博吗？如果是这样，大v发表一篇微博要进行所有粉丝id和微博id的缓存吗？不知道我有没有理解错误","like_count":3,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":557483,"discussion_content":"1 用户上线后，先建立一个空的初始列表，如果这个时候好友发微博，就推到这个空的初始列表。然后用拉的方式构建一个拉列表，把拉列表内容接在前面的初始列表上。接的时候检查初始列表的内容是否在拉列表里，在的话，删除重复内容。\n2 刷新微博就是按时间维度构建列表内容的，所以按照时间维度缓存，缓存不命中，说明关注的好友最近7天都不发微博，不活跃，大概率说明该用户自身也不活跃，符合缓存的设计目标。\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1647832668,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":338642,"user_name":"peter","can_delete":false,"product_type":"c1","uid":1058183,"ip_address":"","ucode":"261C3FC001DE2D","user_header":"https://static001.geekbang.org/account/avatar/00/10/25/87/f3a69d1b.jpg","comment_is_top":false,"comment_ctime":1647615043,"is_pvip":true,"replies":[{"id":"123880","content":"1 不是，我们这个设计里，反向代理用nginx，负载均衡用lvs。也有反向代理和负载均衡都用nginx的，这种一般系统规模比较小，反向代理同时承担负载均衡的职责，画在架构图里，只画一个组件。<br>2 这里存储的是图片小文件，HDFS不合适，FastDFS或者Ceph都可以。<br>3 用，所有有广告推荐的都有AI。<br>4 Witter会存储，存储的成本是逐年下降的，数据很重要。新浪微博会不会存储看用户协议。","user_name":"作者回复","user_name_real":"编辑","uid":"1007349","ctime":1647831976,"ip_address":"","comment_id":338642,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10237549635","product_id":100105701,"comment_content":"请教老师几个问题啊：<br>Q1：反向代理和负载均衡都用Nginx吗？<br>文中有反向代理和负载均衡两个功能实体，它们是分别用一个组件来实现吗？比如用A来完成反向代理，用B来实现负载均衡。<br>Nginx既可以做反向代理，又可以做负载均衡，所以，会采用Nginx来完成这两项功能吗？<br>Q2：用什么实现分布式文件系统？FastDFS？HDFS？<br>Q3：用什么表示“最新微博”？时间吗？还是设置一个标记？<br>Q4：新浪微博用了AI吗？<br>Q5：微博的信息会一直存吗？<br>比如新浪微博，每一年都会有大量的消息需要存储。二十年后数据会积累很多。这些数据会一直保存吗？会根据一定策略删除老数据吗？","like_count":2,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":557477,"discussion_content":"1 不是，我们这个设计里，反向代理用nginx，负载均衡用lvs。也有反向代理和负载均衡都用nginx的，这种一般系统规模比较小，反向代理同时承担负载均衡的职责，画在架构图里，只画一个组件。\n2 这里存储的是图片小文件，HDFS不合适，FastDFS或者Ceph都可以。\n3 用，所有有广告推荐的都有AI。\n4 Witter会存储，存储的成本是逐年下降的，数据很重要。新浪微博会不会存储看用户协议。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1647831976,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":338542,"user_name":"👽","can_delete":false,"product_type":"c1","uid":1274117,"ip_address":"","ucode":"D313AF941B412D","user_header":"https://static001.geekbang.org/account/avatar/00/13/71/05/db554eba.jpg","comment_is_top":false,"comment_ctime":1647566330,"is_pvip":false,"replies":[{"id":"123734","content":"赞，新浪微博在很早的时候就部署了北京、上海、广州三个数据中心。","user_name":"作者回复","user_name_real":"编辑","uid":"1007349","ctime":1647569470,"ip_address":"","comment_id":338542,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5942533626","product_id":100105701,"comment_content":"我觉得这篇专栏，高并发的设计已经相对比较全了：消息队列，缓存。<br><br>如果问我还有什么地方可以进一步优化的话，我觉得可以考虑的点：<br>1. 多地部署，就近访问。就近地区的用户请求，尽可能就近处理。同时，用户的相关信息是否可以就近访问，优先访问同一个数据中心的数据，然后再进行跨地域访问。个人理解，微博有一定地域性。比如，南方地区的人，是不是关注南方地区的博主就会多一些。东北，西北，以及国外，同理。（当然，这一点的可行性还没有深入分析，只是初步想法）。<br>2. 进一步深度定制。据我查询资料的结果来看的话呢，新浪微博的Redis组件和硬件搭配是经过定制的。Redis对于热点信息的存取做了优化，硬件方面使用SSD对于高频读写的数据做存储。<br>3. 就是通用类型的高可用保障，多地多可用区多副本的集群部署，个人认为，这个也可以结合数据优先就近访问。","like_count":1,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":556903,"discussion_content":"赞，新浪微博在很早的时候就部署了北京、上海、广州三个数据中心。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1647569470,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":355782,"user_name":"冷杉","can_delete":false,"product_type":"c1","uid":1726960,"ip_address":"北京","ucode":"1EF82CC877A1D2","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLTY07lEypfLdVCUbRHHyWLc76H4wwrSYicxbo3HKdMf32r9gGsQNIEibPX6J1AcNBobdrNA8KJzia7Q/132","comment_is_top":false,"comment_ctime":1661745514,"is_pvip":false,"replies":[{"id":"129681","content":"亿图","user_name":"作者回复","user_name_real":"编辑","uid":"1007349","ctime":1662099741,"ip_address":"北京","comment_id":355782,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1661745514","product_id":100105701,"comment_content":"请问一下李老师，您文稿中的图片用的是什么软件画的呀？","like_count":0,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":586306,"discussion_content":"亿图","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1662099742,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":"北京"},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":350239,"user_name":"Li Yao","can_delete":false,"product_type":"c1","uid":1129838,"ip_address":"","ucode":"703E1E5505F70D","user_header":"https://static001.geekbang.org/account/avatar/00/11/3d/6e/60680aa4.jpg","comment_is_top":false,"comment_ctime":1656677250,"is_pvip":false,"replies":[{"id":"127500","content":"是的","user_name":"作者回复","user_name_real":"编辑","uid":"1007349","ctime":1656987146,"ip_address":"","comment_id":350239,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1656677250","product_id":100105701,"comment_content":"如果一个大V有1000万粉丝，其中有100万粉丝在线，当大V发微博时，会触发给100万人的缓存中新增数据吗？","like_count":0,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":578714,"discussion_content":"是的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1656987146,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":350060,"user_name":"walle斌","can_delete":false,"product_type":"c1","uid":1062848,"ip_address":"","ucode":"0DB3243004951F","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83ersGSic8ib7OguJv6CJiaXY0s4n9C7Z51sWxTTljklFpq3ZAIWXoFTPV5oLo0GMTkqW5sYJRRnibNqOJQ/132","comment_is_top":false,"comment_ctime":1656551369,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1656551369","product_id":100105701,"comment_content":"1、redis 6.0 以后可以实现分钟级别的本地缓存+分布式缓存，这点lettuce 已经实现了，慢慢等<br>2、崩溃应对，redis 集群挂了请求会飘，这点要额外注意，防止请求挂了飘的问题，有时候牺牲一部分是为了更多<br>","like_count":0},{"had_liked":false,"id":341874,"user_name":"殷志鹏","can_delete":false,"product_type":"c1","uid":1108219,"ip_address":"","ucode":"6D6CBFCA90C19D","user_header":"https://static001.geekbang.org/account/avatar/00/10/e8/fb/5ba80331.jpg","comment_is_top":false,"comment_ctime":1649896951,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1649896951","product_id":100105701,"comment_content":"mysql qps，tps可以通过什么方法确定","like_count":0},{"had_liked":false,"id":341202,"user_name":"江楠大盗","can_delete":false,"product_type":"c1","uid":1241197,"ip_address":"","ucode":"D242C5EF70C176","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eo5vic8QksE4b8ricXxKrEWJyOX9pwiadhk3kvHYoLXoKRTWvbFCxibFTbExNQWDG4nvNfpic9t1umibKww/132","comment_is_top":false,"comment_ctime":1649418017,"is_pvip":true,"replies":[{"id":"124787","content":"每种缓存都有不命中的情况，热点内容在各种缓存都有。","user_name":"作者回复","user_name_real":"编辑","uid":"1007349","ctime":1649641734,"ip_address":"","comment_id":341202,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1649418017","product_id":100105701,"comment_content":"不理解为什么要用应用服务器的本地缓存，把这部分内容也放到CDN可以吗？","like_count":0,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":561453,"discussion_content":"每种缓存都有不命中的情况，热点内容在各种缓存都有。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1649641734,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":341198,"user_name":"江楠大盗","can_delete":false,"product_type":"c1","uid":1241197,"ip_address":"","ucode":"D242C5EF70C176","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eo5vic8QksE4b8ricXxKrEWJyOX9pwiadhk3kvHYoLXoKRTWvbFCxibFTbExNQWDG4nvNfpic9t1umibKww/132","comment_is_top":false,"comment_ctime":1649417175,"is_pvip":true,"replies":[{"id":"124785","content":"1 byte = 8 bit","user_name":"作者回复","user_name_real":"编辑","uid":"1007349","ctime":1649641606,"ip_address":"","comment_id":341198,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1649417175","product_id":100105701,"comment_content":"计算网络宽带时最后 x 8bit，不理解这个值的含义","like_count":0,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":561448,"discussion_content":"1 byte = 8 bit","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1649641606,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1014665,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/7b/89/34f2cbcc.jpg","nickname":"杨宇","note":"","ucode":"EB74DF6E269F03","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":571887,"discussion_content":"运营商的宽带是按bit卖的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1652448147,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":340995,"user_name":"食指可爱多","can_delete":false,"product_type":"c1","uid":1045721,"ip_address":"","ucode":"B918E07F55AB9E","user_header":"https://static001.geekbang.org/account/avatar/00/0f/f4/d9/e572ae4d.jpg","comment_is_top":false,"comment_ctime":1649258884,"is_pvip":true,"replies":[{"id":"124667","content":"汉字常用字基本是3个字节，这里用3字节估算。","user_name":"作者回复","user_name_real":"编辑","uid":"1007349","ctime":1649295916,"ip_address":"","comment_id":340995,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1649258884","product_id":100105701,"comment_content":"文章前面部分做了部分容量规划的内容，有个小疑问，UTF-8里汉字3或4个字节，这里按照140*3=420字节，是一个长期实践下来的经验值吗？","like_count":0,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":560351,"discussion_content":"汉字常用字基本是3个字节，这里用3字节估算。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1649295916,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":340938,"user_name":"农夫酸奶","can_delete":false,"product_type":"c1","uid":2191132,"ip_address":"","ucode":"2EF3D9538815D3","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/LR8PH9I0nvc5r3XQYibC4eDNnelWnib7Zhqib6HWImpDKM95V4e6k5fdWIBhV5ib6wGzJUEyxrvpeDsegGJup8XYgg/132","comment_is_top":false,"comment_ctime":1649234879,"is_pvip":false,"replies":[{"id":"124670","content":"不用消息队列。网络抖动用重试解决，宕机用Redis主主部署解决。","user_name":"作者回复","user_name_real":"编辑","uid":"1007349","ctime":1649296300,"ip_address":"","comment_id":340938,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1649234879","product_id":100105701,"comment_content":"老师，可以讲讲  在发布微博时（写链路）里，怎么保证数据有效的写入redis、写入消息队列吗？  例如网络抖动数据、异常宕机等场景","like_count":0,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":560355,"discussion_content":"不用消息队列。网络抖动用重试解决，宕机用Redis主主部署解决。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1649296300,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":340881,"user_name":"lxhxmf","can_delete":false,"product_type":"c1","uid":1098049,"ip_address":"","ucode":"15BC0AADC48869","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/wicH4ZZcMl8iaavjPldak0jxkm9tc19sjLiaGKsuicUNibEPbrvluaCIZnBCHLT61LBj6uic4lLibFau6U0v1ZxC6ZAqw/132","comment_is_top":false,"comment_ctime":1649211569,"is_pvip":true,"replies":[{"id":"124650","content":"不需要每个消费者一个进程呀，所有的消费者放在一个程序里也可以，当然还是建议按照低耦合高内聚原则分一下。","user_name":"作者回复","user_name_real":"编辑","uid":"1007349","ctime":1649238486,"ip_address":"","comment_id":340881,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1649211569","product_id":100105701,"comment_content":"老师，我们这里有个业务系统涉及的业务场景比较多，系统大量使用了RocketMQ技术对系统进行解耦，创建了30来个topic,这样做业务流程确实清晰了许多，业务需求有变化也能快速响应。但带来的问题是要启动大量的消息消费程序去订阅处理这些topic,占用了比较多的内存资源，而且这么多进程不好监控。针对这种应用场景，有没有什么好框架在不改变topic数量的情况下可以减少消息消费程序的数量，或者有没有其它好的建议，非常感谢。","like_count":0,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":560253,"discussion_content":"不需要每个消费者一个进程呀，所有的消费者放在一个程序里也可以，当然还是建议按照低耦合高内聚原则分一下。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1649238486,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":338604,"user_name":"Geek_7347cf","can_delete":false,"product_type":"c1","uid":2343516,"ip_address":"","ucode":"2E25574FAB1B3B","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/mmTEibMibic5ibsVpNZkR3HBlpPpZYt0gHGdIqOduLGxRHZpTWRG3q56CT1eejoLgNsdaW5aQGWXfyibN4vm9CicYb3w/132","comment_is_top":false,"comment_ctime":1647592203,"is_pvip":false,"replies":[{"id":"123771","content":"7天内微博是被缓存起来的，所以不需要每个用户拉20条，拉缓存中的就可以了。<br><br>拉取的时候发了微博，就会变成推模式，因为这个时候用户已经在线了。<br><br>","user_name":"作者回复","user_name_real":"编辑","uid":"1007349","ctime":1647601108,"ip_address":"","comment_id":338604,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1647592203","product_id":100105701,"comment_content":"使用拉的模式有个问题，用户是如何拉取20条数据的 是对2000个用户每个拉取20条 内存中排序的吗，对于被关注着来说 如果拉取时发布了新的微博 那么用户下一个20条如何拉取 如何与上一个20条去重","like_count":0,"discussions":[{"author":{"id":1007349,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/5e/f5/018907ac.jpg","nickname":"李智慧","note":"","ucode":"8C9980C438AFD1","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":557003,"discussion_content":"7天内微博是被缓存起来的，所以不需要每个用户拉20条，拉缓存中的就可以了。\n\n拉取的时候发了微博，就会变成推模式，因为这个时候用户已经在线了。\n\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1647601108,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]}]}