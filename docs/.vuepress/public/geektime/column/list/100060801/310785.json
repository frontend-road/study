{"id":310785,"title":"19｜NeuralCF：如何用深度学习改造协同过滤？","content":"<p>你好，我是王喆，今天，我们来学习协同过滤的深度学习进化版本，NeuralCF。</p><p>在<a href=\"https://time.geekbang.org/column/article/305182\">第15讲</a>里，我们学习了最经典的推荐算法，协同过滤。在前深度学习的时代，协同过滤曾经大放异彩，但随着技术的发展，协同过滤相比深度学习模型的弊端就日益显现出来了，因为它是通过直接利用非常稀疏的共现矩阵进行预测的，所以模型的泛化能力非常弱，遇到历史行为非常少的用户，就没法产生准确的推荐结果了。</p><p>虽然，我们可以通过矩阵分解算法增强它的泛化能力，但因为矩阵分解是利用非常简单的内积方式来处理用户向量和物品向量的交叉问题的，所以，它的拟合能力也比较弱。这该怎么办呢？不是说深度学习模型的拟合能力都很强吗？我们能不能利用深度学习来改进协同过滤算法呢？</p><p>当然是可以的。2017年，新加坡国立的研究者就使用深度学习网络来改进了传统的协同过滤算法，取名NeuralCF（神经网络协同过滤）。NeuralCF大大提高了协同过滤算法的泛化能力和拟合能力，让这个经典的推荐算法又重新在深度学习时代焕发生机。这节课，我们就一起来学习并实现NeuralCF！</p><h2>NeuralCF模型的结构</h2><p>在学习NeuralCF之前，我们先来简单回顾一下协同过滤和矩阵分解的原理。协同过滤是利用用户和物品之间的交互行为历史，构建出一个像图1左一样的共现矩阵。在共现矩阵的基础上，利用每一行的用户向量相似性，找到相似用户，再利用相似用户喜欢的物品进行推荐。</p><!-- [[[read_end]]] --><p><img src=\"https://static001.geekbang.org/resource/image/60/fb/604b312899bff7922528df4836c10cfb.jpeg?wh=1920*646\" alt=\"\" title=\"图1 矩阵分解算法的原理\"></p><p>矩阵分解则进一步加强了协同过滤的泛化能力，它把协同过滤中的共现矩阵分解成了用户矩阵和物品矩阵，从用户矩阵中提取出用户隐向量，从物品矩阵中提取出物品隐向量，再利用它们之间的内积相似性进行推荐排序。如果用神经网络的思路来理解矩阵分解，它的结构图就是图2这样的。</p><p><img src=\"https://static001.geekbang.org/resource/image/e6/bd/e61aa1d0d6c75230ff75c2fb698083bd.jpg?wh=1436*850\" alt=\"\" title=\"图2 矩阵分解的神经网络化示意图\"></p><p>图2 中的输入层是由用户ID和物品ID生成的One-hot向量，Embedding层是把One-hot向量转化成稠密的Embedding向量表达，这部分就是矩阵分解中的用户隐向量和物品隐向量。输出层使用了用户隐向量和物品隐向量的内积作为最终预测得分，之后通过跟目标得分对比，进行反向梯度传播，更新整个网络。</p><p>把矩阵分解神经网络化之后，把它跟Embedding+MLP以及Wide&amp;Deep模型做对比，我们可以一眼看出网络中的薄弱环节：矩阵分解在Embedding层之上的操作好像过于简单了，就是直接利用内积得出最终结果。这会导致特征之间还没有充分交叉就直接输出结果，模型会有欠拟合的风险。针对这一弱点，NeuralCF对矩阵分解进行了改进，它的结构图是图3这样的。</p><p><img src=\"https://static001.geekbang.org/resource/image/5f/2c/5ff301f11e686eedbacd69dee184312c.jpg?wh=1530*920\" alt=\"\" title=\"图3 NeuralCF的模型结构图 （出自论文Neural Collaborative Filtering）\"></p><p>我想你一定可以一眼看出它们的区别，那就是NeuralCF用一个多层的神经网络替代掉了原来简单的点积操作。这样就可以让用户和物品隐向量之间进行充分的交叉，提高模型整体的拟合能力。</p><h2>NeuralCF模型的扩展，双塔模型</h2><p>有了之前实现矩阵分解和深度学习模型的经验，我想你理解起来NeuralCF肯定不会有困难。事实上，NeuralCF的模型结构之中，蕴含了一个非常有价值的思想，就是我们可以把模型分成用户侧模型和物品侧模型两部分，然后用互操作层把这两部分联合起来，产生最后的预测得分。</p><p>这里的用户侧模型结构和物品侧模型结构，可以是简单的Embedding层，也可以是复杂的神经网络结构，最后的互操作层可以是简单的点积操作，也可以是比较复杂的MLP结构。但只要是这种物品侧模型+用户侧模型+互操作层的模型结构，我们把它统称为“双塔模型”结构。</p><p>图4就是一个典型“双塔模型”的抽象结构。它的名字形象地解释了它的结构组成，两侧的模型结构就像两个高塔一样，而最上面的互操作层则像两个塔尖搭建起的空中走廊，负责两侧信息的沟通。</p><p><img src=\"https://static001.geekbang.org/resource/image/66/cf/66606828b2c80a5f4ea28d60762e82cf.jpg?wh=1224*854\" alt=\"\" title=\"图4 双塔模型结构 [br]（出自论文 Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations）\"></p><p>对于NerualCF来说，它只利用了用户ID作为“用户塔”的输入特征，用物品ID作为“物品塔”的输入特征。事实上，我们完全可以把其他用户和物品相关的特征也分别放入用户塔和物品塔，让模型能够学到的信息更全面。比如说，YouTube在构建用于召回层的双塔模型时，就分别在用户侧和物品侧输入了多种不同的特征，如图5所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/e2/87/e2603a22ec91a9f00be4b73feyy1f987.jpg?wh=1920*944\" alt=\"\" title=\"图5 YouTube双塔召回模型的架构 [br]（出自论文 Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations）\"></p><p>我们看到，YouTube召回双塔模型的用户侧特征包括了用户正在观看的视频ID、频道ID（图中的seed features）、该视频的观看数、被喜欢的次数，以及用户历史观看过的视频ID等等。物品侧的特征包括了候选视频的ID、频道ID、被观看次数、被喜欢次数等等。在经过了多层ReLU神经网络的学习之后，双塔模型最终通过softmax输出层连接两部分，输出最终预测分数。</p><p>看到这里，你可能会有疑问，这个双塔模型相比我们之前学过的Embedding MLP和Wide&amp;Deep有什么优势呢？其实在实际工作中，双塔模型最重要的优势就在于它易上线、易服务。为什么这么说呢？</p><p>你注意看一下物品塔和用户塔最顶端的那层神经元，那层神经元的输出其实就是一个全新的物品Embedding和用户Embedding。拿图4来说，物品塔的输入特征向量是x，经过物品塔的一系列变换，生成了向量u(x)，那么这个u(x)就是这个物品的Embedding向量。同理，v(y)是用户y的Embedding向量，这时，我们就可以把u(x)和v(y)存入特征数据库，这样一来，线上服务的时候，我们只要把u(x)和v(y)取出来，再对它们做简单的互操作层运算就可以得出最后的模型预估结果了！</p><p>所以使用双塔模型，我们不用把整个模型都部署上线，只需要预存物品塔和用户塔的输出，以及在线上实现互操作层就可以了。如果这个互操作层是点积操作，那么这个实现可以说没有任何难度，这是实际应用中非常容易落地的，也是工程师们喜闻乐见的，这也正是双塔模型在业界巨大的优势所在。</p><p>正是因为这样的优势，双塔模型被广泛地应用在YouTube、Facebook、百度等各大公司的推荐场景中，持续发挥着它的能量。</p><h2>NeuralCF的TensorFlow实现</h2><p>熟悉了NerualCF和双塔模型的结构之后，我们就可以使用TensorFlow来实现它们了。通过之前Embedding+MLP模型以及Wide&amp;Deep模型的实现，我想你对TensorFlow中读取数据，定义特征，训练模型的过程肯定已经驾轻就熟了。我们只要更改之前代码中模型定义的部分，就可以实现NeuralCF。具体的代码你可以参考SparrowRecsys项目中的NeuralCF.py，我只贴出了NeuralCF模型部分的实现。下面，我们重点讲解一下它们的实现思路。</p><pre><code># neural cf model arch two. only embedding in each tower, then MLP as the interaction layers\ndef neural_cf_model_1(feature_inputs, item_feature_columns, user_feature_columns, hidden_units):\n    # 物品侧特征层\n    item_tower = tf.keras.layers.DenseFeatures(item_feature_columns)(feature_inputs)\n    # 用户侧特征层\n    user_tower = tf.keras.layers.DenseFeatures(user_feature_columns)(feature_inputs)\n    # 连接层及后续多层神经网络\n    interact_layer = tf.keras.layers.concatenate([item_tower, user_tower])\n    for num_nodes in hidden_units:\n        interact_layer = tf.keras.layers.Dense(num_nodes, activation='relu')(interact_layer)\n    # sigmoid单神经元输出层\n    output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(interact_layer)\n    # 定义keras模型\n    neural_cf_model = tf.keras.Model(feature_inputs, output_layer)\n    return neural_cf_model\n</code></pre><p>你可以看到代码中定义的生成NeuralCF模型的函数，它接收了四个输入变量。其中 <code>feature_inputs</code> 代表着所有的模型输入， <code>item_feature_columns</code> 和 <code>user_feature_columns</code> 分别包含了物品侧和用户侧的特征。在训练时，如果我们只在 <code>item_feature_columns</code> 中放入 <code>movie_id</code> ，在 <code>user_feature_columns</code> 放入 <code>user_id，</code> 就是NeuralCF的经典实现了。</p><p>通过DenseFeatures层创建好用户侧和物品侧输入层之后，我们会再利用concatenate层将二者连接起来，然后输入多层神经网络进行训练。如果想要定义多层神经网络的层数和神经元数量，我们可以通过设置 <code>hidden_units</code> 数组来实现。</p><p>除了经典的NeuralCF实现，我还基于双塔模型的原理实现了一个NeuralCF的双塔版本。你可以参考下面的模型定义。与上面的经典NerualCF实现不同，我把多层神经网络操作放到了物品塔和用户塔内部，让塔内的特征进行充分交叉，最后使用内积层作为物品塔和用户塔的交互层。具体的步骤你可以参考下面代码中的注释，实现过程很好理解，我就不再赘述了。</p><pre><code># neural cf model arch one. embedding+MLP in each tower, then dot product layer as the output\ndef neural_cf_model_2(feature_inputs, item_feature_columns, user_feature_columns, hidden_units):\n    # 物品侧输入特征层\n    item_tower = tf.keras.layers.DenseFeatures(item_feature_columns)(feature_inputs)\n    # 物品塔结构\n    for num_nodes in hidden_units:\n        item_tower = tf.keras.layers.Dense(num_nodes, activation='relu')(item_tower)\n    # 用户侧输入特征层\n    user_tower = tf.keras.layers.DenseFeatures(user_feature_columns)(feature_inputs)\n    # 用户塔结构\n    for num_nodes in hidden_units:\n        user_tower = tf.keras.layers.Dense(num_nodes, activation='relu')(user_tower)\n    # 使用内积操作交互物品塔和用户塔，产生最后输出\n    output = tf.keras.layers.Dot(axes=1)([item_tower, user_tower])\n    # 定义keras模型\n    neural_cf_model = tf.keras.Model(feature_inputs, output)\n    return neural_cf_model\n\n</code></pre><p>在实现了Embedding MLP、Wide&amp;Deep和NeuralCF之后，相信你可以感觉到，实现甚至创造一个深度学习模型并不难，基于TensorFlow提供的Keras接口，我们可以根据我们的设计思路，像搭积木一样实现模型的不同结构，以此来验证我们的想法，这也正是深度推荐模型的魅力和优势。相信随着课程的进展，你不仅对这一点能够有更深刻的感受，同时，你设计和实现模型的能力也会进一步加强。</p><h2>小结</h2><p>这节课，我们首先学习了经典推荐算法协同过滤的深度学习进化版本NerualCF。相比于矩阵分解算法，NeuralCF用一个多层的神经网络，替代了矩阵分解算法中简单的点积操作，让用户和物品隐向量之间进行充分的交叉。这种通过改进物品隐向量和用户隐向量互操作层的方法，大大增加了模型的拟合能力。</p><p>利用NerualCF的思想，我们进一步学习了双塔模型。它通过丰富物品侧和用户侧的特征，让模型能够融入除了用户ID和物品ID外更丰富的信息。除此之外，双塔模型最大的优势在于模型服务的便捷性，由于最终的互操作层是简单的内积操作或浅层神经网络。因此，我们可以把物品塔的输出当作物品Embedding，用户塔的输出当作用户Embedding存入特征数据库，在线上只要实现简单的互操作过程就可以了。</p><p>最后，我们继续使用TensorFlow实现了NerualCF和双塔模型，相信你能进一步感受到利用TensorFlow构建深度学习模型的便捷性，以及它和传统推荐模型相比，在模型结构灵活性上的巨大优势。</p><p>为了帮助你复习，我把刚才说的这些重点内容总结在了一张图里，你可以看看。</p><p><img src=\"https://static001.geekbang.org/resource/image/91/5f/9196a80181f41ba4a96bb80e6286c35f.jpeg?wh=1920*1080\" alt=\"\"></p><h2>课后思考</h2><p>对于我们这节课学习的双塔模型来说，把物品侧的Embedding和用户侧的Embedding存起来，就可以进行线上服务了。但如果我们把一些场景特征，比如当前时间、当前地点加到用户侧或者物品侧，那我们还能用这种方式进行模型服务吗？为什么？</p><p>欢迎把你的思考和疑惑写在留言区，也欢迎你把这节课转发出去，我们下节课见！</p>","neighbors":{"left":{"article_title":"18｜Wide&Deep：怎样让你的模型既有想象力又有记忆力？","id":310638},"right":{"article_title":"20 | DeepFM：如何让你的模型更好地处理特征交叉？","id":312881}},"comments":[{"had_liked":false,"id":263776,"user_name":"Evan-wyl","can_delete":false,"product_type":"c1","uid":1669274,"ip_address":"","ucode":"0E8E2DFBA030C4","user_header":"https://static001.geekbang.org/account/avatar/00/19/78/9a/296b3983.jpg","comment_is_top":false,"comment_ctime":1606266148,"is_pvip":false,"replies":[{"id":"95697","content":"这是从效果的层面考虑。如果从model serving的角度考虑，如果在物品侧或者用户侧加入场景特征的话，就没法做到预存embedding的serving方式了。因为场景特征是在线上不断变化的。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1606279868,"ip_address":"","comment_id":263776,"utype":1}],"discussion_count":1,"race_medal":0,"score":"100390513956","product_id":100060801,"comment_content":"不可以，如果是新闻推荐的话，地点信息会产生很大的影响；这时把地点信息仅仅是加入到用户侧没有任何作用。","like_count":24,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":510297,"discussion_content":"这是从效果的层面考虑。如果从model serving的角度考虑，如果在物品侧或者用户侧加入场景特征的话，就没法做到预存embedding的serving方式了。因为场景特征是在线上不断变化的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606279868,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":274071,"user_name":"AstrHan","can_delete":false,"product_type":"c1","uid":1944884,"ip_address":"","ucode":"14C5F3323A472D","user_header":"","comment_is_top":false,"comment_ctime":1610809946,"is_pvip":false,"replies":[{"id":"99568","content":"是这样的。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1610947845,"ip_address":"","comment_id":274071,"utype":1}],"discussion_count":3,"race_medal":0,"score":"74625253978","product_id":100060801,"comment_content":"embedding之后，如果使用点积，那么这两个embedding是在同一个向量空间；如果使用的MLP则不在同一个向量空间。因为点积不影响向量空间，线性变换矩阵会影响。老师这么说对吧。","like_count":17,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":513906,"discussion_content":"是这样的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1610947845,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2189183,"avatar":"https://static001.geekbang.org/account/avatar/00/21/67/7f/7aa8f1f7.jpg","nickname":"LT","note":"","ucode":"1A7AF1E780AFAA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":583597,"discussion_content":"实际应用都是加了MLP层的，那这样算出来的用户embedding和item embedding不在一个向量空间，还怎么相互召回？？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1660225338,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"贵州"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2351074,"avatar":"https://static001.geekbang.org/account/avatar/00/23/df/e2/3c6e8fff.jpg","nickname":"ぃ霓幻風ルァ","note":"","ucode":"0A022D0652BCC9","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":385236,"discussion_content":"那NeuralCF的用户embedding和item embedding是不是不在一个空间啊，他们之间不能直接计算距离吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1626951672,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":264143,"user_name":"定春一号","can_delete":false,"product_type":"c1","uid":1688793,"ip_address":"","ucode":"77EEB3137BCB66","user_header":"https://static001.geekbang.org/account/avatar/00/19/c4/d9/61705b32.jpg","comment_is_top":false,"comment_ctime":1606361272,"is_pvip":false,"replies":[{"id":"95801","content":"是这样的，离线有组合爆炸的风险。<br>一般不会有context塔，如果希望引入context特征，最好就不用双塔模型，因为双塔模型易线上serving的优势就不存在了。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1606376444,"ip_address":"","comment_id":264143,"utype":1}],"discussion_count":3,"race_medal":0,"score":"74620805304","product_id":100060801,"comment_content":"把context特征放进user塔或者item塔，那么离线生成user embedding或者item embedding的数量就要翻好多倍，能否考虑把context特征单独作为context塔呢？","like_count":18,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":510438,"discussion_content":"是这样的，离线有组合爆炸的风险。\n一般不会有context塔，如果希望引入context特征，最好就不用双塔模型，因为双塔模型易线上serving的优势就不存在了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606376444,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1697075,"avatar":"","nickname":"Sanders","note":"","ucode":"3D460FEEDCDF34","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":348349,"discussion_content":"如果把Context像Wide &amp; Deep中的Wide特征直接跟双塔模型concact后再输入到sigmoid呢？这样是不是可以更大程度使用Context信息，同时又不会过于增加Serving的复杂度。","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1612519242,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1461122,"avatar":"https://static001.geekbang.org/account/avatar/00/16/4b/82/5be29abf.jpg","nickname":"老叔叔安森","note":"","ucode":"EF61ACAC9A44FE","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":361684,"discussion_content":"老师，为什么说“双塔模型易线上serving的优势就不存在”","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616729189,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":267905,"user_name":"小小的天","can_delete":false,"product_type":"c1","uid":1284426,"ip_address":"","ucode":"A3EC02BA37B3B9","user_header":"https://static001.geekbang.org/account/avatar/00/13/99/4a/09ea6699.jpg","comment_is_top":false,"comment_ctime":1607992705,"is_pvip":false,"replies":[{"id":"97329","content":"这是个好问题。新闻的场景确实是很有意思的场景，因为时效性很强。这时候新闻id类的特征就不太管用了，因为如果不重新训练，id类特征对应的embedding没办法引入。<br><br>所以对于这类时效性很强的场景，还是推荐基于一些与id无关的feature来构建模型，比如新闻的类型、人物、地点、关键词等等。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1608078135,"ip_address":"","comment_id":267905,"utype":1}],"discussion_count":2,"race_medal":0,"score":"61737534849","product_id":100060801,"comment_content":"双塔模型对于新闻场景是不是也不太好？新闻时效性很强，在我们公司的数据里，大部分新闻曝光在2个小时内，双塔的训练数据有足够的曝光时，新闻的价值也失去了很多了","like_count":15,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":511782,"discussion_content":"这是个好问题。新闻的场景确实是很有意思的场景，因为时效性很强。这时候新闻id类的特征就不太管用了，因为如果不重新训练，id类特征对应的embedding没办法引入。\n\n所以对于这类时效性很强的场景，还是推荐基于一些与id无关的feature来构建模型，比如新闻的类型、人物、地点、关键词等等。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1608078135,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1284426,"avatar":"https://static001.geekbang.org/account/avatar/00/13/99/4a/09ea6699.jpg","nickname":"小小的天","note":"","ucode":"A3EC02BA37B3B9","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":335184,"discussion_content":"嗯嗯，目前就这么用的，把物品的各种标签分类特征，的embedding进行缓存，线上组装在计算。","likes_number":4,"is_delete":false,"is_hidden":false,"ctime":1608111697,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":265196,"user_name":"Sebastian","can_delete":false,"product_type":"c1","uid":1797634,"ip_address":"","ucode":"62E6FC13DB00E3","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/55lYKUdcPFgUHibRYmaRiaBdrsmnLGOHdPp4OicjBh197X0vyGa9qAwruEqicAPuUgibXO4Lz5jLudlcbtsqq2p3CpA/132","comment_is_top":false,"comment_ctime":1606810777,"is_pvip":false,"replies":[{"id":"96411","content":"因为将user的静态特征和实时context特征再过一遍DSSM是一个非常重的操作，需要把深度模型部署上线，做实时推断。<br><br>这样当然是可以的。但跟离线生成user 和 item emb预存起来，线上只做简单dot product这样的部署方式，显然复杂了许多。<br><br>业界往往追求的实用性的效率，这就是加不加入context特征的区别所在。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1606847639,"ip_address":"","comment_id":265196,"utype":1}],"discussion_count":2,"race_medal":0,"score":"61736352921","product_id":100060801,"comment_content":"老师，我还是没理解为什么不能加入context的特征。在训练DSSM的时候除了user和item的特征外，在user塔加入context的特征，比如用户的地理位置、手机型号等等，训练完后，将user和item的embedding存入redis后。线上请求时，将user的静态特征和实时context特征再过一遍DSSM，得到新的user embedding后，与存入redis的item emebdding取topN即可，为什么不妥呢？","like_count":15,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":510829,"discussion_content":"因为将user的静态特征和实时context特征再过一遍DSSM是一个非常重的操作，需要把深度模型部署上线，做实时推断。\n\n这样当然是可以的。但跟离线生成user 和 item emb预存起来，线上只做简单dot product这样的部署方式，显然复杂了许多。\n\n业界往往追求的实用性的效率，这就是加不加入context特征的区别所在。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606847639,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2414687,"avatar":"","nickname":"Geek_f30bcb","note":"","ucode":"69996919542668","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":344571,"discussion_content":"我认为用户的兴趣会随context 变化， 但是item的特征不应该随context 变化， 所以context 不应该单独成为一个塔， 最多是和user的 embed 交互作用，形成新的包含context info 的user embeding，然后再和item embed 交互作用","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1611502204,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":276325,"user_name":"Geek_790c43","can_delete":false,"product_type":"c1","uid":2156292,"ip_address":"","ucode":"FFFAE0636A91EF","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/4icayE3ic5IA7RWwZcrxpMZE4T1WViakEgPsDC3UnhZwU83ad65IjmxPficy0vNZz6Q6vCiclnmyBDc5IYf7soHAXrQ/132","comment_is_top":false,"comment_ctime":1611886926,"is_pvip":false,"replies":[{"id":"100613","content":"非常好","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1612361150,"ip_address":"","comment_id":276325,"utype":1}],"discussion_count":1,"race_medal":0,"score":"35971625294","product_id":100060801,"comment_content":"不可以，因为如有地点或者时间这种波动比较大的特征就不能用预存embedding来表示当前的用户或者当前的物品了。例如外卖推荐，在公司和家时用户的embedding应该是不同的。或者新闻网站早晨和晚上的也应该不同","like_count":9,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":514666,"discussion_content":"非常好","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1612361150,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":291730,"user_name":"🍃","can_delete":false,"product_type":"c1","uid":1384222,"ip_address":"","ucode":"3510E99C50E950","user_header":"https://static001.geekbang.org/account/avatar/00/15/1f/1e/f3365200.jpg","comment_is_top":false,"comment_ctime":1620452559,"is_pvip":false,"replies":[{"id":"105678","content":"数值特征从理解上就是错了，比如 用户id 1761 和用户id 1881，如果是数值特征说明他们两个是有可比性的，但其实并没有，我们需要id类的特征来单独表达他们这两个用户的行为特点。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1620582361,"ip_address":"","comment_id":291730,"utype":1}],"discussion_count":1,"race_medal":0,"score":"23095289039","product_id":100060801,"comment_content":"老师，我还是不理解为什么用用户id和物品id做one-hot编码？直接数值特征不好么？","like_count":6,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":519553,"discussion_content":"数值特征从理解上就是错了，比如 用户id 1761 和用户id 1881，如果是数值特征说明他们两个是有可比性的，但其实并没有，我们需要id类的特征来单独表达他们这两个用户的行为特点。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1620582361,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":276317,"user_name":"Geek_790c43","can_delete":false,"product_type":"c1","uid":2156292,"ip_address":"","ucode":"FFFAE0636A91EF","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/4icayE3ic5IA7RWwZcrxpMZE4T1WViakEgPsDC3UnhZwU83ad65IjmxPficy0vNZz6Q6vCiclnmyBDc5IYf7soHAXrQ/132","comment_is_top":false,"comment_ctime":1611885705,"is_pvip":false,"replies":[{"id":"100799","content":"也是。这就是为什么大厂模型动辄上亿维的原因。当然，如果需要，可以使用一些降维的方法。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1612594559,"ip_address":"","comment_id":276317,"utype":1}],"discussion_count":4,"race_medal":0,"score":"23086722185","product_id":100060801,"comment_content":"图二中，和之前deep crossing 以及 wide&amp;deep，把用户id的one hot向量作为输入, 如果有几亿的用户也这么处理么？","like_count":6,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":514661,"discussion_content":"也是。这就是为什么大厂模型动辄上亿维的原因。当然，如果需要，可以使用一些降维的方法。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1612594559,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2454131,"avatar":"https://static001.geekbang.org/account/avatar/00/25/72/73/d707c8be.jpg","nickname":"MutouMan","note":"","ucode":"E2E78C6EE25E80","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":379305,"discussion_content":"看图4，NeuralCF是去最后一层作为embedding，所以输入是one-hot。我觉得使用embedding输入应该也是可以的，图5就是这么做得。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1623821719,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1384222,"avatar":"https://static001.geekbang.org/account/avatar/00/15/1f/1e/f3365200.jpg","nickname":"🍃","note":"","ucode":"3510E99C50E950","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":372759,"discussion_content":"有个疑问 为啥不是直接用数值而是要转onehot到 embedding？比如用户id 304 就用304呢？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1620452887,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2156292,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/4icayE3ic5IA7RWwZcrxpMZE4T1WViakEgPsDC3UnhZwU83ad65IjmxPficy0vNZz6Q6vCiclnmyBDc5IYf7soHAXrQ/132","nickname":"Geek_790c43","note":"","ucode":"FFFAE0636A91EF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":366996,"discussion_content":"能不能用label encoding做input然后接embedding layer，而不是用one hot做input。 这样是不是可以节省用以储存几亿纬的空间。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618233475,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":274271,"user_name":"AstrHan","can_delete":false,"product_type":"c1","uid":1944884,"ip_address":"","ucode":"14C5F3323A472D","user_header":"","comment_is_top":false,"comment_ctime":1610949842,"is_pvip":false,"replies":[{"id":"99709","content":"理论上不是一定要加sigmoid函数。但tf这里如果值超过1会报错，已经接收了你的PR，感谢。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1611191382,"ip_address":"","comment_id":274271,"utype":1}],"discussion_count":2,"race_medal":0,"score":"23085786322","product_id":100060801,"comment_content":"双塔版本的模型是不是有些问题，点积之后应该还要加一层输出层吧？<br>output = tf.keras.layers.Dense(1, activation=&#39;sigmoid&#39;)(output)","like_count":6,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":513959,"discussion_content":"理论上不是一定要加sigmoid函数。但tf这里如果值超过1会报错，已经接收了你的PR，感谢。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1611190806,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":2453906,"avatar":"","nickname":"Geek_060174","note":"","ucode":"0CD31443EF0653","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":535342,"discussion_content":"要是用来预存embedding的话，内积之后是不是不应该再加dense层？可以改成output = tf.keras.layers.Activation(activation=&#39;sigmoid&#39;)(output)。 这样保证最终用的score的相对顺序不会变","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1638415698,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":513959,"ip_address":""},"score":535342,"extra":""}]}]},{"had_liked":false,"id":290182,"user_name":"Eayon","can_delete":false,"product_type":"c1","uid":1915541,"ip_address":"","ucode":"9239EA2CA3D19B","user_header":"https://static001.geekbang.org/account/avatar/00/1d/3a/95/e8fc39d5.jpg","comment_is_top":false,"comment_ctime":1619421268,"is_pvip":false,"replies":[{"id":"105349","content":"1. 由于他们不在一个空间内，所以不能点积，而不是反过来<br>2. 可以，物品和物品之间是一定在一个空间内的，但Embedding+MLP不可以直接物品和用户进行点积，因为他们是两个独立的embedding层。双塔模型如果训练的时候就是用用户emb点积物品emb训练的，那么他们是在一个空间内。<br><br>3.可以","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1619729347,"ip_address":"","comment_id":290182,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18799290452","product_id":100060801,"comment_content":"老师前面提到Embedding+MLP中的物品，Embedding不能计算物品和用户的相似度，提到不在一个空间向量（也说不能点乘就不在一个空间，其实还是不太理解）这里就有两个问题<br>1.不在一个空间究竟是什么概念，真就是不能点积就行了，还是跟里面数据内涵有点关系？<br>2.另外Embedding+MLP 中的Embedding能不能计算物品与物品之间的相似度呢？<br>然后是这节课双塔模型中又可以得到物品和用户的Embedding，可以通过点积得到相似度<br>3.那这时候的物品embedding能用来计算物品间的相似度吗？","like_count":5,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":519130,"discussion_content":"1. 由于他们不在一个空间内，所以不能点积，而不是反过来\n2. 可以，物品和物品之间是一定在一个空间内的，但Embedding+MLP不可以直接物品和用户进行点积，因为他们是两个独立的embedding层。双塔模型如果训练的时候就是用用户emb点积物品emb训练的，那么他们是在一个空间内。\n\n3.可以","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1619729347,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":284049,"user_name":"Alan","can_delete":false,"product_type":"c1","uid":2115316,"ip_address":"","ucode":"591A28E310A8F5","user_header":"https://static001.geekbang.org/account/avatar/00/20/46/f4/93b1275b.jpg","comment_is_top":false,"comment_ctime":1616050484,"is_pvip":false,"replies":[{"id":"103418","content":"基本是这个原因。简单来说就是加入context feature之后就无法使用纯预训练的方式进行model serving了。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1616636573,"ip_address":"","comment_id":284049,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18795919668","product_id":100060801,"comment_content":"答：肯定会有影响的！<br>首先，NeuralCF 模型计算的用户与物品之间的协同过滤后的计算结果，加入任何的维度，都会导致矩阵变化，失去其意义。<br>其次，因为时间、地点这两类特征因素具有很强的影响力！基于用户-物品的协同过滤在此情况下失去意义。就以视频推荐类App来说，白天推荐给我（在公司工作）的新闻、娱乐短视频的协同过滤的结果，到了晚上推荐给我（在校学习）学习类、游戏类长视频为主","like_count":5,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":517213,"discussion_content":"基本是这个原因。简单来说就是加入context feature之后就无法使用纯预训练的方式进行model serving了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616636573,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":273734,"user_name":"Geek_8ac51c","can_delete":false,"product_type":"c1","uid":2377965,"ip_address":"","ucode":"AE8E646F67B62E","user_header":"","comment_is_top":false,"comment_ctime":1610660994,"is_pvip":false,"replies":[{"id":"99144","content":"基础知识部分说了，mlp其实模拟的是一个函数，既然两个向量间的互操作当然是一个函数，所以mlp当然可以模拟。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1610668067,"ip_address":"","comment_id":273734,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14495562882","product_id":100060801,"comment_content":"老师，mlp层为啥可以替代点积操作。有理论资料学习吗？","like_count":4,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":513793,"discussion_content":"基础知识部分说了，mlp其实模拟的是一个函数，既然两个向量间的互操作当然是一个函数，所以mlp当然可以模拟。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1610668067,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":265395,"user_name":"范闲","can_delete":false,"product_type":"c1","uid":1073125,"ip_address":"","ucode":"F21FD7DF6BA53C","user_header":"https://static001.geekbang.org/account/avatar/00/10/5f/e5/54325854.jpg","comment_is_top":false,"comment_ctime":1606889066,"is_pvip":false,"replies":[{"id":"96520","content":"预存这里所谓的other塔确实有点得不偿失，因为线上的context特征，比如时间，地点变化会非常快。理想的方式就是做实时inference","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1606940277,"ip_address":"","comment_id":265395,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14491790954","product_id":100060801,"comment_content":"不可以直接加入用户侧或者物品侧，会产生组合爆炸的问题。<br>可以考虑变成3塔的结构，加个other塔~~，other embedding也可以预存。但是有个问题other的这些变化可能会比较快，对模型、embedding的更新要求会很高~~","like_count":4,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":510917,"discussion_content":"预存这里所谓的other塔确实有点得不偿失，因为线上的context特征，比如时间，地点变化会非常快。理想的方式就是做实时inference","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606940277,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":314758,"user_name":"lyx","can_delete":false,"product_type":"c1","uid":2713752,"ip_address":"","ucode":"3F73A31AB69137","user_header":"https://static001.geekbang.org/account/avatar/00/29/68/98/522e034c.jpg","comment_is_top":false,"comment_ctime":1633405243,"is_pvip":false,"replies":[{"id":"114116","content":"是的，生成embedding","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1633719594,"ip_address":"","comment_id":314758,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10223339835","product_id":100060801,"comment_content":"请问下DenseFeatures这层是做embedding的么，搜了半天不知道这层是干嘛的。","like_count":2,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527786,"discussion_content":"是的，生成embedding","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633719594,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":284663,"user_name":"Geek_71fed1","can_delete":false,"product_type":"c1","uid":2527569,"ip_address":"","ucode":"526351F33FADC9","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/5EgbE7BFRtWHIchE5eCoaXFX4RWxg3iblIbC8G9X2cV4sYlW9qCib1sMiaJusda6p3L5UUq8aoUfOPU1QSia7caibqA/132","comment_is_top":false,"comment_ctime":1616408301,"is_pvip":false,"replies":[{"id":"103432","content":"最后用点积作为互操作的embedding都可以视为在一个空间内。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1616637774,"ip_address":"","comment_id":284663,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10206342893","product_id":100060801,"comment_content":"老师，为什么两个embedding向量是在同一向量空间？","like_count":2,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":517423,"discussion_content":"最后用点积作为互操作的embedding都可以视为在一个空间内。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1616637774,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":278802,"user_name":"努力学习","can_delete":false,"product_type":"c1","uid":2403862,"ip_address":"","ucode":"A0C4E599CF27D2","user_header":"","comment_is_top":false,"comment_ctime":1613355587,"is_pvip":false,"replies":[{"id":"101389","content":"不可以，只要需要复杂online inference的都不可以加进去。<br><br>如果一定要加，可以考虑embedding+MLP，MLP做线上inference的结构。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1613529442,"ip_address":"","comment_id":278802,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10203290179","product_id":100060801,"comment_content":"关于课后思考请问老师，如果只考虑已有数据是不是就可以添加位置等信息了？<br>如果就是做位置推荐，那么位置信息还算是context吗？位置推荐若不能使用双塔模型应该优选什么模型那？谢谢老师","like_count":2,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":515507,"discussion_content":"不可以，只要需要复杂online inference的都不可以加进去。\n\n如果一定要加，可以考虑embedding+MLP，MLP做线上inference的结构。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1613529442,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":277737,"user_name":"LUO FAN","can_delete":false,"product_type":"c1","uid":2088083,"ip_address":"","ucode":"538E81E6FC4015","user_header":"https://static001.geekbang.org/account/avatar/00/1f/dc/93/bdbc45cc.jpg","comment_is_top":false,"comment_ctime":1612533539,"is_pvip":false,"replies":[{"id":"100822","content":"我觉得完全可以做embedding后再拼接，没问题。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1612599982,"ip_address":"","comment_id":277737,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10202468131","product_id":100060801,"comment_content":"请问在neuralCF的实现中，为什么是把物品特征和用户特征拼接起来送入网络，而不是先分别过embedding 层然后再拼接","like_count":2,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":515148,"discussion_content":"我觉得完全可以做embedding后再拼接，没问题。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1612599982,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":337929,"user_name":"Geek_e8024b","can_delete":false,"product_type":"c1","uid":2737277,"ip_address":"","ucode":"D33A659CD4514E","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIJZ9icLVZBrgxoUG6ibSnahNLs5ib50OFsqUJvgqs5qdqibsjbVaEf3iaND5IJcSycHiaDv4Yic7FPLUbAw/132","comment_is_top":false,"comment_ctime":1647163193,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"5942130489","product_id":100060801,"comment_content":"老师，想问一下比如新增了一个用户或者商品，比如用户数量变了，用户的onehot，那模型需要重新训练吗","like_count":1},{"had_liked":false,"id":314952,"user_name":"罗辑","can_delete":false,"product_type":"c1","uid":1539649,"ip_address":"","ucode":"06AB60316B51C4","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/OwZuBRbVUkziazePs2xTKskNpZachRtCBZLHlv4dAUgaBC5qHI292xaxvg3atGnHlDwjIOXPKEbc7zOrtMyicSNg/132","comment_is_top":false,"comment_ctime":1633610383,"is_pvip":false,"replies":[{"id":"114118","content":"神经网络end2end训练得到","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1633719644,"ip_address":"","comment_id":314952,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5928577679","product_id":100060801,"comment_content":"老师，tf.feature_column.embedding_column 中得到embedding向量是通过矩阵分解还是通过神经网络得到的？","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":527838,"discussion_content":"神经网络end2end训练得到","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1633719644,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":296555,"user_name":"Geek_fdb832","can_delete":false,"product_type":"c1","uid":2532699,"ip_address":"","ucode":"0BA1479D33DC07","user_header":"","comment_is_top":false,"comment_ctime":1623044875,"is_pvip":false,"replies":[{"id":"108160","content":"后面课程会讲到youtube模型，可以学习一下看看能不能解决你的疑问","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1623876509,"ip_address":"","comment_id":296555,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5918012171","product_id":100060801,"comment_content":"Youtube的双塔模型，serving的时候，每次用户点击都要整个模型跑一遍吗？那线上cost不会太高？","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":521484,"discussion_content":"后面课程会讲到youtube模型，可以学习一下看看能不能解决你的疑问","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1623876509,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":291175,"user_name":"维真","can_delete":false,"product_type":"c1","uid":1903862,"ip_address":"","ucode":"0EAAFEEFC8370A","user_header":"https://static001.geekbang.org/account/avatar/00/1d/0c/f6/8ae0beb3.jpg","comment_is_top":false,"comment_ctime":1620098406,"is_pvip":false,"replies":[{"id":"105687","content":"这是两种产生embedding的方法，都是基于embedding的召回。就是embedding模型的不同。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1620583083,"ip_address":"","comment_id":291175,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5915065702","product_id":100060801,"comment_content":"如果双塔模型用在召回层，那么之前您将的那个graph embedding据说也用在召回层呢，这两个召回层的区别是什么呀？","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":519392,"discussion_content":"这是两种产生embedding的方法，都是基于embedding的召回。就是embedding模型的不同。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1620583083,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":281319,"user_name":"Geek1254","can_delete":false,"product_type":"c1","uid":2028941,"ip_address":"","ucode":"BC2F7756A0676D","user_header":"","comment_is_top":false,"comment_ctime":1614688893,"is_pvip":false,"replies":[{"id":"102381","content":"这是个特征实时更新的问题，目前主流的方案是在一些流计算平台上完成特征的不断更新。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1615024002,"ip_address":"","comment_id":281319,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5909656189","product_id":100060801,"comment_content":"老师您好，Youtube的案例中。用户侧有用户正在观看的视频ID，这是需要及时获取的，然后视频的views和likes也需要及时更新。那么这些信息在变化，需要即时获取。那么u(x)和v(y)需要重新计算，请问是在什么时候放入特征数据库呢？","like_count":2,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":516357,"discussion_content":"这是个特征实时更新的问题，目前主流的方案是在一些流计算平台上完成特征的不断更新。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1615024002,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1636448,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epWOEWQYu9icQR8iaiayXyeJpzzrZIF6S4NdkrAGYELyrpnh4GxOicjcj6ZG9PnuuYfzEwMMGB0J1z9Tg/132","nickname":"Geek_e642b8","note":"","ucode":"CC355BE0C73F6E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":353121,"discussion_content":"我个人觉得，应该是实时的放到数据库中的。比如用flink 或spark 把实时数据存到特征数据库里边。不知道对不对？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1615018990,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":274058,"user_name":"骚动","can_delete":false,"product_type":"c1","uid":2280216,"ip_address":"","ucode":"EBEBF417C866D4","user_header":"https://static001.geekbang.org/account/avatar/00/22/cb/18/0139e086.jpg","comment_is_top":false,"comment_ctime":1610802311,"is_pvip":true,"replies":[{"id":"99569","content":"逻辑有点混乱，但这个思考方式是好的。到底在哪种情况下实用，确实跟模型更新方式和你的工程实现都有关系，但没有绝对。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1610948104,"ip_address":"","comment_id":274058,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5905769607","product_id":100060801,"comment_content":"这样看，双塔应该在实时里特别适用？但是emb的更新又是个问题，所以在一些emb更新节奏慢的实时业务情景下，是不是特别适用？","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":513902,"discussion_content":"逻辑有点混乱，但这个思考方式是好的。到底在哪种情况下实用，确实跟模型更新方式和你的工程实现都有关系，但没有绝对。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1610948104,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":272745,"user_name":"Geek_033ad5","can_delete":false,"product_type":"c1","uid":1739445,"ip_address":"","ucode":"F06909971DA28F","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/dliaGpsxSic6Km3NGL5A3FVOBuQ9qiaUZ1ewCSNPaxxqHBPQ66rc19bRKA9EDy3H1P1wfSMPF4CuTx7X7GPs57CRQ/132","comment_is_top":false,"comment_ctime":1610260294,"is_pvip":false,"replies":[{"id":"98859","content":"双塔模型的输出层大部分也是dot product，并不需要一定是softmax","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1610264311,"ip_address":"","comment_id":272745,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5905227590","product_id":100060801,"comment_content":"老师，我有个疑惑，双塔如果用在召回层在最后输出候选集阶段是怎么做呢？因为像item2vec这种方法是通过哈希去比较相似度可以提高效率，但双塔却是计算user和item两个embedding的softmax，那岂不是会one by one的去做运算导致计算量非常大？","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":513373,"discussion_content":"双塔模型的输出层大部分也是dot product，并不需要一定是softmax","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1610264311,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2405955,"avatar":"https://static001.geekbang.org/account/avatar/00/24/b6/43/21b2c2d4.jpg","nickname":"王兴鹏","note":"","ucode":"F3540E3B2CDDC9","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":373166,"discussion_content":"一些工业界常用的向量快速检索工具封装了很多向量近似快速检索算法，比如faiss, annoy, milvus ……可以快速召回候选集，不用one by one计算","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1620637704,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":264041,"user_name":"马龙流","can_delete":false,"product_type":"c1","uid":1087792,"ip_address":"","ucode":"16F9CE022297FF","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erUKWZy1fBBcJncWRNh9M3TkjThqgsIIpmGOTCyg2IN80IDf3COkeWyTLHliczAppIkfBgCJTsUn1g/132","comment_is_top":false,"comment_ctime":1606317945,"is_pvip":false,"replies":[{"id":"95799","content":"因为线上运算比较轻量级，所以适合用在召回层。但也不是排序不能用，看实际需求吧。<br><br>用户向量也是离线计算，跟物品向量一样存储起来。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1606376282,"ip_address":"","comment_id":264041,"utype":1}],"discussion_count":4,"race_medal":0,"score":"5901285241","product_id":100060801,"comment_content":"双塔模型一般用在召回吧?用户向量线上现算，物品向量存储起来?","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":510397,"discussion_content":"因为线上运算比较轻量级，所以适合用在召回层。但也不是排序不能用，看实际需求吧。\n\n用户向量也是离线计算，跟物品向量一样存储起来。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606376282,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1239343,"avatar":"https://static001.geekbang.org/account/avatar/00/12/e9/2f/3c989133.jpg","nickname":"不将就","note":"","ucode":"44138E2164DC83","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":351079,"discussion_content":"我司线上只存了物品向量，用户向量实时推理出来","likes_number":4,"is_delete":false,"is_hidden":false,"ctime":1614147564,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":2189183,"avatar":"https://static001.geekbang.org/account/avatar/00/21/67/7f/7aa8f1f7.jpg","nickname":"LT","note":"","ucode":"1A7AF1E780AFAA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1239343,"avatar":"https://static001.geekbang.org/account/avatar/00/12/e9/2f/3c989133.jpg","nickname":"不将就","note":"","ucode":"44138E2164DC83","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":583598,"discussion_content":"请问下，按前面的说法，如果双塔模型用了mlp层，那user和item的emb向量就不在一个向量空间，你们公司如果要用来召回的话，是不是没用mlp层，只用点积来训练的？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1660225561,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":351079,"ip_address":"贵州"},"score":583598,"extra":""}]},{"author":{"id":1239343,"avatar":"https://static001.geekbang.org/account/avatar/00/12/e9/2f/3c989133.jpg","nickname":"不将就","note":"","ucode":"44138E2164DC83","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":351081,"discussion_content":"是用在召回上","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1614147607,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":263822,"user_name":"JustDoDT","can_delete":false,"product_type":"c1","uid":1127175,"ip_address":"","ucode":"6AF0B80F00EAEF","user_header":"https://static001.geekbang.org/account/avatar/00/11/33/07/8f351609.jpg","comment_is_top":false,"comment_ctime":1606274000,"is_pvip":false,"replies":[{"id":"95700","content":"同学不懂复习啊。。共现矩阵怎么生成不是在15讲协同过滤那讲详细介绍过嘛。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1606280841,"ip_address":"","comment_id":263822,"utype":1}],"discussion_count":3,"race_medal":0,"score":"5901241296","product_id":100060801,"comment_content":"老师不讲武德，共现矩阵没交代怎么来的啊<br>共现矩阵的制作大致流程：<br>1、用户-物品喜好矩阵UI<br>2、物品-物品相似度方阵II<br>3、UI·II 得到 共现矩阵<br>参考：https:&#47;&#47;best-yz.cn&#47;2019&#47;07&#47;28&#47;ji-yu-xie-tong-guo-lu-cf-suan-fa-de-tui-jian-xi-tong&#47;","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":510320,"discussion_content":"同学不懂复习啊。。共现矩阵怎么生成不是在15讲协同过滤那讲详细介绍过嘛。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606280841,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1127175,"avatar":"https://static001.geekbang.org/account/avatar/00/11/33/07/8f351609.jpg","nickname":"JustDoDT","note":"","ucode":"6AF0B80F00EAEF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":329361,"discussion_content":"忘提了这是基于物品的协同过滤，典型列子：电影推荐、电商推荐","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606371991,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1127175,"avatar":"https://static001.geekbang.org/account/avatar/00/11/33/07/8f351609.jpg","nickname":"JustDoDT","note":"","ucode":"6AF0B80F00EAEF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":328999,"discussion_content":"哈哈，我大意了，没有复习。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606295366,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":263437,"user_name":"张弛 Conor","can_delete":false,"product_type":"c1","uid":2208459,"ip_address":"","ucode":"193EBA4A64BAB3","user_header":"https://static001.geekbang.org/account/avatar/00/21/b2/cb/9c6c7bf7.jpg","comment_is_top":false,"comment_ctime":1606133522,"is_pvip":false,"replies":[{"id":"95618","content":"不是特别准确。如果在训练模型的时候把场景特征加到物品塔和用户塔里，训练出的embedding不就可以包含场景特征了吗？","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1606181753,"ip_address":"","comment_id":263437,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5901100818","product_id":100060801,"comment_content":"不可以，因为生成的Embedding未包含新的场景特征","like_count":1,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":510192,"discussion_content":"不是特别准确。如果在训练模型的时候把场景特征加到物品塔和用户塔里，训练出的embedding不就可以包含场景特征了吗？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606181753,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":339116,"user_name":"夜枭","can_delete":false,"product_type":"c1","uid":2414668,"ip_address":"","ucode":"7A09EC9E003379","user_header":"","comment_is_top":false,"comment_ctime":1647929730,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1647929730","product_id":100060801,"comment_content":"老师想咨询一下对于双塔模型，如果user侧的一些特征是由内容画像积累而来，是否在进行onehot时将user侧和item侧的相同tag作为一个编码呢？最近再尝试双塔模型时候发现效果很差","like_count":0},{"had_liked":false,"id":336494,"user_name":"test","can_delete":false,"product_type":"c1","uid":1065849,"ip_address":"","ucode":"9A4973E591DD12","user_header":"https://static001.geekbang.org/account/avatar/00/10/43/79/18073134.jpg","comment_is_top":false,"comment_ctime":1646188761,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1646188761","product_id":100060801,"comment_content":"老师，请问下，像这种特征直接向量化后进入NN的，就不需要将特征归一化了吧？","like_count":0},{"had_liked":false,"id":324164,"user_name":"abc-web","can_delete":false,"product_type":"c1","uid":1371804,"ip_address":"","ucode":"DE3B873863EFF9","user_header":"https://static001.geekbang.org/account/avatar/00/14/ee/9c/abb7bfe3.jpg","comment_is_top":false,"comment_ctime":1638324630,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1638324630","product_id":100060801,"comment_content":"老师如果ID是uuid或类似雪花算法生成的长数字该如何进行embeding？","like_count":0},{"had_liked":false,"id":308337,"user_name":"Geek_8a732a","can_delete":false,"product_type":"c1","uid":2723806,"ip_address":"","ucode":"97A312D97F7B91","user_header":"","comment_is_top":false,"comment_ctime":1629542051,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1629542051","product_id":100060801,"comment_content":"场景特征本身就是实时变化的，无法做到提前预存","like_count":0},{"had_liked":false,"id":291551,"user_name":"Yvonne","can_delete":false,"product_type":"c1","uid":2577469,"ip_address":"","ucode":"85287A0AC7456C","user_header":"https://static001.geekbang.org/account/avatar/00/27/54/3d/366462d0.jpg","comment_is_top":false,"comment_ctime":1620358520,"is_pvip":false,"replies":[{"id":"105681","content":"e2e训练和预存embedding没有直接关系。只是说在线上服务的时候，如果有预存emb，就不用再在线上e2e inference一遍了。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1620582590,"ip_address":"","comment_id":291551,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1620358520","product_id":100060801,"comment_content":"老师，这种预存embedding的，是不是就不算End2End训练了?之前学习13讲的时候，就不太明白End2End怎么和embedding结合起来","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":519504,"discussion_content":"e2e训练和预存embedding没有直接关系。只是说在线上服务的时候，如果有预存emb，就不用再在线上e2e inference一遍了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1620582590,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":289726,"user_name":"Eayon","can_delete":false,"product_type":"c1","uid":1915541,"ip_address":"","ucode":"9239EA2CA3D19B","user_header":"https://static001.geekbang.org/account/avatar/00/1d/3a/95/e8fc39d5.jpg","comment_is_top":false,"comment_ctime":1619155895,"is_pvip":false,"replies":[{"id":"105127","content":"理解的基本正确。embedding是一个非常广的概念。利用item2vec生成，和利用模型的embedding layer生成都是可行的。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1619283747,"ip_address":"","comment_id":289726,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1619155895","product_id":100060801,"comment_content":"老师有点懵，问个小白的问题，前面提到Embedding是基于时序item2vec得来的，深度学习里面，似乎都用的是反向传播得出的？是两种么？那这两种emb表达的内涵应该都不是一回事了吧？是不是可以认为已经没有item2vec什么事了，而更多是基于rating中label的0、1来决定emb的内涵","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":519003,"discussion_content":"理解的基本正确。embedding是一个非常广的概念。利用item2vec生成，和利用模型的embedding layer生成都是可行的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1619283747,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":283141,"user_name":"FayeChen","can_delete":false,"product_type":"c1","uid":2421713,"ip_address":"","ucode":"72AA0C00128017","user_header":"https://static001.geekbang.org/account/avatar/00/24/f3/d1/0663e55c.jpg","comment_is_top":false,"comment_ctime":1615572626,"is_pvip":false,"replies":[{"id":"102834","content":"思路有点乱。<br><br>老用户为什么用双塔就合适，用户行为积累后为什么embedding+MLP合适，不是特别清晰。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1615793888,"ip_address":"","comment_id":283141,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1615572626","product_id":100060801,"comment_content":"如果想线上比较好友好地运用双塔模型是不是T+1生成user_embeding 比较好，因为用户的实时兴趣是很难实时存储的，跟据实时行为用户的embedding都一直在变化。个人认为，对于老用户，当日第一次访问用双塔模型就非常适合，但是随着用户行为的累计还是需要embeding + MLP这种方式","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":516944,"discussion_content":"思路有点乱。\n\n老用户为什么用双塔就合适，用户行为积累后为什么embedding+MLP合适，不是特别清晰。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1615793888,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":274649,"user_name":"hurun","can_delete":false,"product_type":"c1","uid":1883212,"ip_address":"","ucode":"001913A6B669C4","user_header":"https://static001.geekbang.org/account/avatar/00/1c/bc/4c/fb5452bd.jpg","comment_is_top":false,"comment_ctime":1611111380,"is_pvip":false,"replies":[{"id":"99711","content":"如果一定想使用字符串的话就可以当作项目中的genre来处理，可以参考相应的代码。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1611191602,"ip_address":"","comment_id":274649,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1611111380","product_id":100060801,"comment_content":"王老师好，想请教个编程问题<br># movie id embedding feature<br>movie_col = tf.feature_column.categorical_column_with_identity(key=&#39;movieId&#39;, num_buckets=1001)<br>movie_emb_col = tf.feature_column.embedding_column(movie_col, 10)<br><br>这里的id是整型，但生产环境的id一般是字符串，我想到到是把字符串数据先做处理映射到整型，然后再传给NeuralCF进行训练。有没有更好到方法可以在NeuralCF一步到位处理好，是不是可以使用tf.feature_column.categorical_column_with_vocabulary_list方法实现","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":514078,"discussion_content":"如果一定想使用字符串的话就可以当作项目中的genre来处理，可以参考相应的代码。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1611191602,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":272546,"user_name":"小灵城","can_delete":false,"product_type":"c1","uid":2404950,"ip_address":"","ucode":"9EF2943E19A19A","user_header":"https://static001.geekbang.org/account/avatar/00/24/b2/56/b71ee269.jpg","comment_is_top":false,"comment_ctime":1610120851,"is_pvip":false,"replies":[{"id":"98832","content":"1. 这个模型用于watch next的推荐，所以“用户正在观看的视频ID”指的是用户当前在看的视频id，或者是最近一次观看的视频id。物品塔中的是候选物品自己的id<br><br>2.是的，需要emb需要频繁更新。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1610222093,"ip_address":"","comment_id":272546,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1610120851","product_id":100060801,"comment_content":"有两个问题想问下老师。<br>1. “YouTube 召回双塔模型的用户侧特征包括了用户正在观看的视频 ID、频道 ID（图中的 seed features）、该视频的观看数、被喜欢的次数，以及用户历史观看过的视频 ID 等等。” 这里的用户正在观看的视频ID是什么意思？这个ID不是已经在物品塔里面提供了吗？<br>2. 当把embedding存入key value数据库后，serve的时候只需要输入用户ID作为key找推荐物品即可。那么embedding需要被频繁更新嘛？更新的话是不是在offline还要把更新的物品或用户特征经过模型得到更新的embedding？","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":513303,"discussion_content":"1. 这个模型用于watch next的推荐，所以“用户正在观看的视频ID”指的是用户当前在看的视频id，或者是最近一次观看的视频id。物品塔中的是候选物品自己的id\n\n2.是的，需要emb需要频繁更新。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1610222093,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2052928,"avatar":"https://static001.geekbang.org/account/avatar/00/1f/53/40/d599bf28.jpg","nickname":"冻糕","note":"","ucode":"B0A45E87795C69","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":368651,"discussion_content":"那既然这么说yoube的双塔这还是需要在线部署模型进行实时特征获取和推断。。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618793512,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":272414,"user_name":"梁栋💝","can_delete":false,"product_type":"c1","uid":1067594,"ip_address":"","ucode":"16EEF0DD596A80","user_header":"https://static001.geekbang.org/account/avatar/00/10/4a/4a/fdae1e16.jpg","comment_is_top":false,"comment_ctime":1610084677,"is_pvip":false,"replies":[{"id":"98792","content":"基本原理是训练好之后把模型中的部分layer取出来形成一个新的模型，然后做predict。<br><br>实践细节问题都建议自己搜索自己实践，相关文章太多了。","user_name":"作者回复","user_name_real":"王喆","uid":"1662192","ctime":1610145733,"ip_address":"","comment_id":272414,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1610084677","product_id":100060801,"comment_content":"感慨：万能的向量点积。<br><br>老师好，想问一下tensorflow双塔训练后，如何屏蔽掉最后的dot product层直接拿到双塔输出呢，谢谢。","like_count":0,"discussions":[{"author":{"id":1662192,"avatar":"https://static001.geekbang.org/account/avatar/00/19/5c/f0/46214d29.jpg","nickname":"王喆","note":"","ucode":"2EDC616F905F3F","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":513271,"discussion_content":"基本原理是训练好之后把模型中的部分layer取出来形成一个新的模型，然后做predict。\n\n实践细节问题都建议自己搜索自己实践，相关文章太多了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1610145733,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]}]}