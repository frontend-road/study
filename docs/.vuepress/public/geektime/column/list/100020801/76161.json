{"id":76161,"title":"23 | MySQL是怎么保证数据不丢的？","content":"<p>今天这篇文章，我会继续和你介绍在业务高峰期临时提升性能的方法。从文章标题“MySQL是怎么保证数据不丢的？”，你就可以看出来，今天我和你介绍的方法，跟数据的可靠性有关。</p><p>在专栏前面文章和答疑篇中，我都着重介绍了WAL机制（你可以再回顾下<a href=\"https://time.geekbang.org/column/article/68633\">第2篇</a>、<a href=\"https://time.geekbang.org/column/article/70848\">第9篇</a>、<a href=\"https://time.geekbang.org/column/article/71806\">第12篇</a>和<a href=\"https://time.geekbang.org/column/article/73161\">第15篇</a>文章中的相关内容），得到的结论是：只要redo log和binlog保证持久化到磁盘，就能确保MySQL异常重启后，数据可以恢复。</p><p>评论区有同学又继续追问，redo log的写入流程是怎么样的，如何保证redo log真实地写入了磁盘。那么今天，我们就再一起看看MySQL写入binlog和redo log的流程。</p><h1>binlog的写入机制</h1><p>其实，binlog的写入逻辑比较简单：事务执行过程中，先把日志写到binlog cache，事务提交的时候，再把binlog cache写到binlog文件中。</p><p>一个事务的binlog是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。这就涉及到了binlog cache的保存问题。</p><p>系统给binlog cache分配了一片内存，每个线程一个，参数 binlog_cache_size用于控制单个线程内binlog cache所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。</p><!-- [[[read_end]]] --><p>事务提交的时候，执行器把binlog cache里的完整事务写入到binlog中，并清空binlog cache。状态如图1所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/9e/3e/9ed86644d5f39efb0efec595abb92e3e.png?wh=1142*748\" alt=\"\"></p><center><span class=\"reference\">图1 binlog写盘状态</span></center><p>可以看到，每个线程有自己binlog cache，但是共用同一份binlog文件。</p><ul>\n<li>图中的write，指的就是指把日志写入到文件系统的page cache，并没有把数据持久化到磁盘，所以速度比较快。</li>\n<li>图中的fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为fsync才占磁盘的IOPS。</li>\n</ul><p>write 和fsync的时机，是由参数sync_binlog控制的：</p><ol>\n<li>\n<p>sync_binlog=0的时候，表示每次提交事务都只write，不fsync；</p>\n</li>\n<li>\n<p>sync_binlog=1的时候，表示每次提交事务都会执行fsync；</p>\n</li>\n<li>\n<p>sync_binlog=N(N&gt;1)的时候，表示每次提交事务都write，但累积N个事务后才fsync。</p>\n</li>\n</ol><p>因此，在出现IO瓶颈的场景里，将sync_binlog设置成一个比较大的值，可以提升性能。在实际的业务场景中，考虑到丢失日志量的可控性，一般不建议将这个参数设成0，比较常见的是将其设置为100~1000中的某个数值。</p><p>但是，将sync_binlog设置为N，对应的风险是：如果主机发生异常重启，会丢失最近N个事务的binlog日志。</p><h1>redo log的写入机制</h1><p>接下来，我们再说说redo log的写入机制。</p><p>在专栏的<a href=\"https://time.geekbang.org/column/article/73161\">第15篇答疑文章</a>中，我给你介绍了redo log buffer。事务在执行过程中，生成的redo log是要先写到redo log buffer的。</p><p>然后就有同学问了，redo log buffer里面的内容，是不是每次生成后都要直接持久化到磁盘呢？</p><p>答案是，不需要。</p><p>如果事务执行期间MySQL发生异常重启，那这部分日志就丢了。由于事务并没有提交，所以这时日志丢了也不会有损失。</p><p>那么，另外一个问题是，事务还没提交的时候，redo log buffer中的部分日志有没有可能被持久化到磁盘呢？</p><p>答案是，确实会有。</p><p>这个问题，要从redo log可能存在的三种状态说起。这三种状态，对应的就是图2 中的三个颜色块。</p><p><img src=\"https://static001.geekbang.org/resource/image/9d/d4/9d057f61d3962407f413deebc80526d4.png?wh=1142*639\" alt=\"\"></p><center><span class=\"reference\">图2 MySQL redo log存储状态</span></center><p>这三种状态分别是：</p><ol>\n<li>\n<p>存在redo log buffer中，物理上是在MySQL进程内存中，就是图中的红色部分；</p>\n</li>\n<li>\n<p>写到磁盘(write)，但是没有持久化（fsync)，物理上是在文件系统的page cache里面，也就是图中的黄色部分；</p>\n</li>\n<li>\n<p>持久化到磁盘，对应的是hard disk，也就是图中的绿色部分。</p>\n</li>\n</ol><p>日志写到redo log buffer是很快的，wirte到page cache也差不多，但是持久化到磁盘的速度就慢多了。</p><p>为了控制redo log的写入策略，InnoDB提供了innodb_flush_log_at_trx_commit参数，它有三种可能取值：</p><ol>\n<li>\n<p>设置为0的时候，表示每次事务提交时都只是把redo log留在redo log buffer中;</p>\n</li>\n<li>\n<p>设置为1的时候，表示每次事务提交时都将redo log直接持久化到磁盘；</p>\n</li>\n<li>\n<p>设置为2的时候，表示每次事务提交时都只是把redo log写到page cache。</p>\n</li>\n</ol><p>InnoDB有一个后台线程，每隔1秒，就会把redo log buffer中的日志，调用write写到文件系统的page cache，然后调用fsync持久化到磁盘。</p><p>注意，事务执行中间过程的redo log也是直接写在redo log buffer中的，这些redo log也会被后台线程一起持久化到磁盘。也就是说，一个没有提交的事务的redo log，也是可能已经持久化到磁盘的。</p><p>实际上，除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的redo log写入到磁盘中。</p><ol>\n<li>\n<p><strong>一种是，redo log buffer占用的空间即将达到 innodb_log_buffer_size一半的时候，后台线程会主动写盘。</strong>注意，由于这个事务并没有提交，所以这个写盘动作只是write，而没有调用fsync，也就是只留在了文件系统的page cache。</p>\n</li>\n<li>\n<p><strong>另一种是，并行的事务提交的时候，顺带将这个事务的redo log buffer持久化到磁盘。</strong>假设一个事务A执行到一半，已经写了一些redo log到buffer中，这时候有另外一个线程的事务B提交，如果innodb_flush_log_at_trx_commit设置的是1，那么按照这个参数的逻辑，事务B要把redo log buffer里的日志全部持久化到磁盘。这时候，就会带上事务A在redo log buffer里的日志一起持久化到磁盘。</p>\n</li>\n</ol><p>这里需要说明的是，我们介绍两阶段提交的时候说过，时序上redo log先prepare， 再写binlog，最后再把redo log commit。</p><p>如果把innodb_flush_log_at_trx_commit设置成1，那么redo log在prepare阶段就要持久化一次，因为有一个崩溃恢复逻辑是要依赖于prepare 的redo log，再加上binlog来恢复的。（如果你印象有点儿模糊了，可以再回顾下<a href=\"https://time.geekbang.org/column/article/73161\">第15篇文章</a>中的相关内容）。</p><p>每秒一次后台轮询刷盘，再加上崩溃恢复这个逻辑，InnoDB就认为redo log在commit的时候就不需要fsync了，只会write到文件系统的page cache中就够了。</p><p>通常我们说MySQL的“双1”配置，指的就是sync_binlog和innodb_flush_log_at_trx_commit都设置成 1。也就是说，一个事务完整提交前，需要等待两次刷盘，一次是redo log（prepare 阶段），一次是binlog。</p><p>这时候，你可能有一个疑问，这意味着我从MySQL看到的TPS是每秒两万的话，每秒就会写四万次磁盘。但是，我用工具测试出来，磁盘能力也就两万左右，怎么能实现两万的TPS？</p><p>解释这个问题，就要用到组提交（group commit）机制了。</p><p>这里，我需要先和你介绍日志逻辑序列号（log sequence number，LSN）的概念。LSN是单调递增的，用来对应redo log的一个个写入点。每次写入长度为length的redo log， LSN的值就会加上length。</p><p>LSN也会写到InnoDB的数据页中，来确保数据页不会被多次执行重复的redo log。关于LSN和redo log、checkpoint的关系，我会在后面的文章中详细展开。</p><p>如图3所示，是三个并发事务(trx1, trx2, trx3)在prepare 阶段，都写完redo log buffer，持久化到磁盘的过程，对应的LSN分别是50、120 和160。</p><p><img src=\"https://static001.geekbang.org/resource/image/93/cc/933fdc052c6339de2aa3bf3f65b188cc.png?wh=1142*2171\" alt=\"\"></p><center><span class=\"reference\">图3 redo log 组提交</span></center><p>从图中可以看到，</p><ol>\n<li>\n<p>trx1是第一个到达的，会被选为这组的 leader；</p>\n</li>\n<li>\n<p>等trx1要开始写盘的时候，这个组里面已经有了三个事务，这时候LSN也变成了160；</p>\n</li>\n<li>\n<p>trx1去写盘的时候，带的就是LSN=160，因此等trx1返回时，所有LSN小于等于160的redo log，都已经被持久化到磁盘；</p>\n</li>\n<li>\n<p>这时候trx2和trx3就可以直接返回了。</p>\n</li>\n</ol><p>所以，一次组提交里面，组员越多，节约磁盘IOPS的效果越好。但如果只有单线程压测，那就只能老老实实地一个事务对应一次持久化操作了。</p><p>在并发更新场景下，第一个事务写完redo log buffer以后，接下来这个fsync越晚调用，组员可能越多，节约IOPS的效果就越好。</p><p>为了让一次fsync带的组员更多，MySQL有一个很有趣的优化：拖时间。在介绍两阶段提交的时候，我曾经给你画了一个图，现在我把它截过来。</p><p><img src=\"https://static001.geekbang.org/resource/image/98/51/98b3b4ff7b36d6d72e38029b86870551.png?wh=1142*856\" alt=\"\"></p><center><span class=\"reference\">图4 两阶段提交</span></center><p>图中，我把“写binlog”当成一个动作。但实际上，写binlog是分成两步的：</p><ol>\n<li>\n<p>先把binlog从binlog cache中写到磁盘上的binlog文件；</p>\n</li>\n<li>\n<p>调用fsync持久化。</p>\n</li>\n</ol><p>MySQL为了让组提交的效果更好，把redo log做fsync的时间拖到了步骤1之后。也就是说，上面的图变成了这样：</p><p><img src=\"https://static001.geekbang.org/resource/image/5a/28/5ae7d074c34bc5bd55c82781de670c28.png?wh=1142*1522\" alt=\"\"></p><center><span class=\"reference\">图5 两阶段提交细化</span></center><p>这么一来，binlog也可以组提交了。在执行图5中第4步把binlog fsync到磁盘时，如果有多个事务的binlog已经写完了，也是一起持久化的，这样也可以减少IOPS的消耗。</p><p>不过通常情况下第3步执行得会很快，所以binlog的write和fsync间的间隔时间短，导致能集合到一起持久化的binlog比较少，因此binlog的组提交的效果通常不如redo log的效果那么好。</p><p>如果你想提升binlog组提交的效果，可以通过设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count来实现。</p><ol>\n<li>\n<p>binlog_group_commit_sync_delay参数，表示延迟多少微秒后才调用fsync;</p>\n</li>\n<li>\n<p>binlog_group_commit_sync_no_delay_count参数，表示累积多少次以后才调用fsync。</p>\n</li>\n</ol><p>这两个条件是或的关系，也就是说只要有一个满足条件就会调用fsync。</p><p>所以，当binlog_group_commit_sync_delay设置为0的时候，binlog_group_commit_sync_no_delay_count也无效了。</p><p>之前有同学在评论区问到，WAL机制是减少磁盘写，可是每次提交事务都要写redo log和binlog，这磁盘读写次数也没变少呀？</p><p>现在你就能理解了，WAL机制主要得益于两个方面：</p><ol>\n<li>\n<p>redo log 和 binlog都是顺序写，磁盘的顺序写比随机写速度要快；</p>\n</li>\n<li>\n<p>组提交机制，可以大幅度降低磁盘的IOPS消耗。</p>\n</li>\n</ol><p>分析到这里，我们再来回答这个问题：<strong>如果你的MySQL现在出现了性能瓶颈，而且瓶颈在IO上，可以通过哪些方法来提升性能呢？</strong></p><p>针对这个问题，可以考虑以下三种方法：</p><ol>\n<li>\n<p>设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count参数，减少binlog的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。</p>\n</li>\n<li>\n<p>将sync_binlog 设置为大于1的值（比较常见是100~1000）。这样做的风险是，主机掉电时会丢binlog日志。</p>\n</li>\n<li>\n<p>将innodb_flush_log_at_trx_commit设置为2。这样做的风险是，主机掉电的时候会丢数据。</p>\n</li>\n</ol><p>我不建议你把innodb_flush_log_at_trx_commit 设置成0。因为把这个参数设置成0，表示redo log只保存在内存中，这样的话MySQL本身异常重启也会丢数据，风险太大。而redo log写到文件系统的page cache的速度也是很快的，所以将这个参数设置成2跟设置成0其实性能差不多，但这样做MySQL异常重启时就不会丢数据了，相比之下风险会更小。</p><h1>小结</h1><p>在专栏的<a href=\"https://time.geekbang.org/column/article/68633\">第2篇</a>和<a href=\"https://time.geekbang.org/column/article/73161\">第15篇</a>文章中，我和你分析了，如果redo log和binlog是完整的，MySQL是如何保证crash-safe的。今天这篇文章，我着重和你介绍的是MySQL是“怎么保证redo log和binlog是完整的”。</p><p>希望这三篇文章串起来的内容，能够让你对crash-safe这个概念有更清晰的理解。</p><p>之前的第15篇答疑文章发布之后，有同学继续留言问到了一些跟日志相关的问题，这里为了方便你回顾、学习，我再集中回答一次这些问题。</p><p><strong>问题1：</strong>执行一个update语句以后，我再去执行hexdump命令直接查看ibd文件内容，为什么没有看到数据有改变呢？</p><p>回答：这可能是因为WAL机制的原因。update语句执行完成后，InnoDB只保证写完了redo log、内存，可能还没来得及将数据写到磁盘。</p><p><strong>问题2：</strong>为什么binlog cache是每个线程自己维护的，而redo log buffer是全局共用的？</p><p>回答：MySQL这么设计的主要原因是，binlog是不能“被打断的”。一个事务的binlog必须连续写，因此要整个事务完成后，再一起写到文件里。</p><p>而redo log并没有这个要求，中间有生成的日志可以写到redo log buffer中。redo log buffer中的内容还能“搭便车”，其他事务提交的时候可以被一起写到磁盘中。</p><p><strong>问题3：</strong>事务执行期间，还没到提交阶段，如果发生crash的话，redo log肯定丢了，这会不会导致主备不一致呢？</p><p>回答：不会。因为这时候binlog 也还在binlog cache里，没发给备库。crash以后redo log和binlog都没有了，从业务角度看这个事务也没有提交，所以数据是一致的。</p><p><strong>问题4：</strong>如果binlog写完盘以后发生crash，这时候还没给客户端答复就重启了。等客户端再重连进来，发现事务已经提交成功了，这是不是bug？</p><p>回答：不是。</p><p>你可以设想一下更极端的情况，整个事务都提交成功了，redo log commit完成了，备库也收到binlog并执行了。但是主库和客户端网络断开了，导致事务成功的包返回不回去，这时候客户端也会收到“网络断开”的异常。这种也只能算是事务成功的，不能认为是bug。</p><p>实际上数据库的crash-safe保证的是：</p><ol>\n<li>\n<p>如果客户端收到事务成功的消息，事务就一定持久化了；</p>\n</li>\n<li>\n<p>如果客户端收到事务失败（比如主键冲突、回滚等）的消息，事务就一定失败了；</p>\n</li>\n<li>\n<p>如果客户端收到“执行异常”的消息，应用需要重连后通过查询当前状态来继续后续的逻辑。此时数据库只需要保证内部（数据和日志之间，主库和备库之间）一致就可以了。</p>\n</li>\n</ol><p>最后，又到了课后问题时间。</p><p>今天我留给你的思考题是：你的生产库设置的是“双1”吗？ 如果平时是的话，你有在什么场景下改成过“非双1”吗？你的这个操作又是基于什么决定的？</p><p>另外，我们都知道这些设置可能有损，如果发生了异常，你的止损方案是什么？</p><p>你可以把你的理解或者经验写在留言区，我会在下一篇文章的末尾选取有趣的评论和你一起分享和分析。感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。</p><h1>上期问题时间</h1><p>我在上篇文章最后，想要你分享的是线上“救火”的经验。</p><p>@Long 同学，在留言中提到了几个很好的场景。</p><ul>\n<li>\n<p>其中第3个问题，“如果一个数据库是被客户端的压力打满导致无法响应的，重启数据库是没用的。”，说明他很好地思考了。<br>\n这个问题是因为重启之后，业务请求还会再发。而且由于是重启，buffer pool被清空，可能会导致语句执行得更慢。</p>\n</li>\n<li>\n<p>他提到的第4个问题也很典型。有时候一个表上会出现多个单字段索引（而且往往这是因为运维工程师对索引原理不够清晰做的设计），这样就可能出现优化器选择索引合并算法的现象。但实际上，索引合并算法的效率并不好。而通过将其中的一个索引改成联合索引的方法，是一个很好的应对方案。</p>\n</li>\n</ul><p>还有其他几个同学提到的问题场景，也很好，很值得你一看。</p><blockquote>\n<p>@Max 同学提到一个很好的例子：客户端程序的连接器，连接完成后会做一些诸如show columns的操作，在短连接模式下这个影响就非常大了。<br>\n这个提醒我们，在review项目的时候，不止要review我们自己业务的代码，也要review连接器的行为。一般做法就是在测试环境，把general_log打开，用业务行为触发连接，然后通过general log分析连接器的行为。</p>\n</blockquote><blockquote>\n<p>@Manjusaka 同学的留言中，第二点提得非常好：如果你的数据库请求模式直接对应于客户请求，这往往是一个危险的设计。因为客户行为不可控，可能突然因为你们公司的一个运营推广，压力暴增，这样很容易把数据库打挂。<br>\n在设计模型里面设计一层，专门负责管理请求和数据库服务资源，对于比较重要和大流量的业务，是一个好的设计方向。</p>\n</blockquote><blockquote>\n<p>@Vincent 同学提了一个好问题，用文中提到的DDL方案，会导致binlog里面少了这个DDL语句，后续影响备份恢复的功能。由于需要另一个知识点（主备同步协议），我放在后面的文章中说明。</p>\n</blockquote><p></p>","neighbors":{"left":{"article_title":"22 | MySQL有哪些“饮鸩止渴”提高性能的方法？","id":75746},"right":{"article_title":"24 | MySQL是怎么保证主备一致的？","id":76446}},"comments":[{"had_liked":false,"id":56870,"user_name":"锅子","can_delete":false,"product_type":"c1","uid":1323048,"ip_address":"","ucode":"4A9143AFB07FF2","user_header":"https://static001.geekbang.org/account/avatar/00/14/30/28/6e019a7a.jpg","comment_is_top":true,"comment_ctime":1546571347,"is_pvip":false,"replies":[{"id":"20527","content":"你看到的“binlog的记录”，也是从page cache读的哦。<br>Page cache是操作系统文件系统上的😄<br><br>好问题","user_name":"作者回复","comment_id":56870,"uid":"1264162","ip_address":"","utype":1,"ctime":1546573295,"user_name_real":"林晓斌"}],"discussion_count":15,"race_medal":0,"score":"9.2233727213011005e+18","product_id":100020801,"comment_content":"老师好，有一个疑问：当设置sync_binlog=0时，每次commit都只时write到page cache，并不会fsync。但是做实验时binlog文件中还是会有记录，这是什么原因呢？是不是后台线程每秒一次的轮询也会将binlog cache持久化到磁盘？还是有其他的参数控制呢？","like_count":160,"discussions":[{"author":{"id":2250622,"avatar":"https://static001.geekbang.org/account/avatar/00/22/57/7e/453a0db7.jpg","nickname":"大梧桐树","note":"","ucode":"1E910FF0194159","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":561152,"discussion_content":"磁盘：实际上我啥也没做，你们都被我骗了","likes_number":5,"is_delete":false,"is_hidden":false,"ctime":1649562248,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1008468,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/63/54/c9475cd0.jpg","nickname":"cz","note":"","ucode":"96385190176F78","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":391448,"discussion_content":"牛， 文件在 OS page cache 层共享了， 想读取原始磁盘文件，还要用特殊的option open file","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1630467021,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1692320,"avatar":"https://static001.geekbang.org/account/avatar/00/19/d2/a0/c8714628.jpg","nickname":"独一无二","note":"","ucode":"A7DE0EA2BD8FE3","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":60978,"discussion_content":"好问题，谢谢，不然我还以为binlog写的太快了，我跟不上的原因，难怪每次都能看到binlog更新的操作","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1574768093,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1780797,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/2c/3d/0bd58aa4.jpg","nickname":"Em","note":"","ucode":"32012A5C603C8A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1692320,"avatar":"https://static001.geekbang.org/account/avatar/00/19/d2/a0/c8714628.jpg","nickname":"独一无二","note":"","ucode":"A7DE0EA2BD8FE3","race_medal":0,"user_type":1,"is_pvip":true},"discussion":{"id":577917,"discussion_content":"哈哈哈哈哈哈哈哈","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1656411335,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":60978,"ip_address":""},"score":577917,"extra":""}]},{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435289,"discussion_content":"你看到的“binlog的记录”，也是从page cache读的哦。\nPage cache是操作系统文件系统上的😄\n\n好问题","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1546573295,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1788647,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/4a/e7/6c16af5d.jpg","nickname":"汉江","note":"","ucode":"01622D984B8F9B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":346570,"discussion_content":"666","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1611995464,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2249670,"avatar":"","nickname":"mofee888","note":"","ucode":"F1FB6F68DCF802","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":342814,"discussion_content":"Page cache 就不会写磁盘了吗？还是会写磁盘的吧？只是写磁盘的时机交给操作系统自己决定了而已，如果你的内存紧张也可能马上写入磁盘。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1610845724,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1788258,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/49/62/25de50e4.jpg","nickname":"白文召","note":"","ucode":"F3C538231BF5D6","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":292253,"discussion_content":"这个问题牛逼,原来开到的不是真正持久化到磁盘的内存,是和page cache一体的","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1595156145,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1593957,"avatar":"https://static001.geekbang.org/account/avatar/00/18/52/65/320eccb3.jpg","nickname":"王斯拉","note":"","ucode":"D00DD3CE432189","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":5576,"discussion_content":"那是不是这种情况宕机就会丢掉所有的binlog，\n如果服务器正常的关闭，会在关闭前调用fsync的吧","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1566358894,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":2,"child_discussions":[{"author":{"id":1308783,"avatar":"https://static001.geekbang.org/account/avatar/00/13/f8/6f/080973cf.jpg","nickname":"Edward","note":"","ucode":"10FAADF92D05F4","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1593957,"avatar":"https://static001.geekbang.org/account/avatar/00/18/52/65/320eccb3.jpg","nickname":"王斯拉","note":"","ucode":"D00DD3CE432189","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":11891,"discussion_content":"这种情况，如果是MySQL异常关闭不会丢数据，如果是主机掉电会丢数据。MySQL正常关闭前会调用fsync持久化，不会丢数据","likes_number":22,"is_delete":false,"is_hidden":false,"ctime":1568441342,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":5576,"ip_address":""},"score":11891,"extra":""},{"author":{"id":1780797,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/2c/3d/0bd58aa4.jpg","nickname":"Em","note":"","ucode":"32012A5C603C8A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1308783,"avatar":"https://static001.geekbang.org/account/avatar/00/13/f8/6f/080973cf.jpg","nickname":"Edward","note":"","ucode":"10FAADF92D05F4","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":577918,"discussion_content":"mysql异常关闭调不了fsync  但是数据还是在操作系统的cache中, 也不会丢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1656411393,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":11891,"ip_address":""},"score":577918,"extra":""}]},{"author":{"id":1010446,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/6b/0e/f4d5da3f.jpg","nickname":"helin","note":"","ucode":"08A5E56B0B810C","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":563888,"discussion_content":"linux os 本身也会有pdflush定时刷新page cache到disk","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1650104782,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1140175,"avatar":"https://static001.geekbang.org/account/avatar/00/11/65/cf/326c0eea.jpg","nickname":"x-ray","note":"","ucode":"8363F0C4D0AC0B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":325463,"discussion_content":"这个问题厉害了。。。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1605325153,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1314724,"avatar":"https://static001.geekbang.org/account/avatar/00/14/0f/a4/0b49469f.jpg","nickname":"木子00","note":"","ucode":"8F78CA722EB29B","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":310924,"discussion_content":"设置sync_binlog=0，binlog文件中的记录是page cache 中的？这样的话主从同步，是怎么同步的？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1602135004,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":3,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1274615,"avatar":"","nickname":"15652790052","note":"","ucode":"8A15D673C16A8F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":5438,"discussion_content":"可以裸读磁盘，跳过文件系统","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1566268979,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":3,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":56863,"user_name":"WilliamX","can_delete":false,"product_type":"c1","uid":1295476,"ip_address":"","ucode":"E915091A891873","user_header":"https://static001.geekbang.org/account/avatar/00/13/c4/74/27cf551a.jpg","comment_is_top":false,"comment_ctime":1546570221,"is_pvip":false,"replies":[{"id":"20521","content":"嗯，这个解释也很好。👍🏿","user_name":"作者回复","comment_id":56863,"uid":"1264162","ip_address":"","utype":1,"ctime":1546571101,"user_name_real":"林晓斌"}],"discussion_count":7,"race_medal":0,"score":"607136958957","product_id":100020801,"comment_content":"为什么 binlog cache 是每个线程自己维护的，而 redo log buffer 是全局共用的？<br>这个问题，感觉还有一点，binlog存储是以statement或者row格式存储的，而redo log是以page页格式存储的。page格式，天生就是共有的，而row格式，只跟当前事务相关","like_count":142,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435285,"discussion_content":"嗯，这个解释也很好。👍🏿","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1546571101,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1243369,"avatar":"https://static001.geekbang.org/account/avatar/00/12/f8/e9/f16a536b.jpg","nickname":"极客-绝影","note":"","ucode":"D302CE68123E74","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":128526,"discussion_content":"我跟这位同学一样，在这里联系到binlog的格式，statement记录的是更新的SQL，但是要写上下文，因此不能中断，要不同步到从库无法恢复一样的数据内容","likes_number":6,"is_delete":false,"is_hidden":false,"ctime":1578647419,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":2389270,"avatar":"https://static001.geekbang.org/account/avatar/00/24/75/16/6e28bf17.jpg","nickname":"初晨","note":"","ucode":"C5D95D13E49127","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1243369,"avatar":"https://static001.geekbang.org/account/avatar/00/12/f8/e9/f16a536b.jpg","nickname":"极客-绝影","note":"","ucode":"D302CE68123E74","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":589759,"discussion_content":"真棒","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1665303485,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":128526,"ip_address":"陕西"},"score":589759,"extra":""}]},{"author":{"id":2945508,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/kTIwKz8eeicPsWibiavOkCnhfys2HkhLFmNKN7hV3ax1GNsjs8Ss2BlH0ekelxFibZz4C3cy1R1YcEMopJhXCghqyQ/132","nickname":"Geek_c22ad7","note":"","ucode":"6A3ACF366C02CC","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":556976,"discussion_content":"redo log 中间插入其他的redo log不也是会造成结果得混乱吗？ 例如一个redo log A令a=1，redo log B令a=2，本来B应该在A后边，最终结果a=2，结果A被中断了，B跑到A前面，最终结果a=1，结果就不对了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1647592456,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1780797,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/2c/3d/0bd58aa4.jpg","nickname":"Em","note":"","ucode":"32012A5C603C8A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2945508,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/kTIwKz8eeicPsWibiavOkCnhfys2HkhLFmNKN7hV3ax1GNsjs8Ss2BlH0ekelxFibZz4C3cy1R1YcEMopJhXCghqyQ/132","nickname":"Geek_c22ad7","note":"","ucode":"6A3ACF366C02CC","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":577919,"discussion_content":"你这是对同一行数据同一个字段修改了吧,  这在上面锁的那一关就过不了      怎么会走到这里","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1656411885,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":556976,"ip_address":""},"score":577919,"extra":""}]},{"author":{"id":1851970,"avatar":"https://static001.geekbang.org/account/avatar/00/1c/42/42/2a04ada9.jpg","nickname":"毛小树","note":"","ucode":"E47DC07CE4959E","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":534796,"discussion_content":"评论区都是天才。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1638279549,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1731047,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/GmtqEx7x5hagZtXbd8Xs8ocUuHHLGIgiaqTwTcibPnpla1PVTbed2Ax7ZfzCjN2Qpeyao6ogq7L3icLzSB3vY1rlg/132","nickname":"Chanson","note":"","ucode":"74B3B180B4B953","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":298783,"discussion_content":"棒！","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1597398633,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":63987,"user_name":"alias cd=rm -rf","can_delete":false,"product_type":"c1","uid":1318325,"ip_address":"","ucode":"E7B27D76305B75","user_header":"https://static001.geekbang.org/account/avatar/00/14/1d/b5/971261fd.jpg","comment_is_top":false,"comment_ctime":1548637420,"is_pvip":false,"replies":[{"id":"22644","content":"不是。<br><br>说明一下哈，所谓的 redo log prepare，是“当前事务提交”的一个阶段，也就是说，在事务A提交的时候，我们才会走到事务A的redo log prepare这个阶段。<br><br>事务A在提交前，有一部分redo log被事务B提前持久化，但是事务A还没有进入提交阶段，是无所谓“redo log prepare”的。<br><br>好问题<br><br>","user_name":"作者回复","comment_id":63987,"uid":"1264162","ip_address":"","utype":1,"ctime":1548644158,"user_name_real":"林晓斌"}],"discussion_count":16,"race_medal":0,"score":"495469876460","product_id":100020801,"comment_content":"事务A是当前事务，这时候事务B提交了。事务B的redolog持久化时候，会顺道把A产生的redolog也持久化，这时候A的redolog状态是prepare状态么？<br>","like_count":116,"discussions":[{"author":{"id":1241770,"avatar":"https://static001.geekbang.org/account/avatar/00/12/f2/aa/32fc0d54.jpg","nickname":"失火的夏天","note":"","ucode":"10C6E66EB2A65F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":116234,"discussion_content":"你的名称充满了恶意","likes_number":34,"is_delete":false,"is_hidden":false,"ctime":1578058087,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1207495,"avatar":"https://static001.geekbang.org/account/avatar/00/12/6c/c7/c8a881ab.jpg","nickname":"labuladong","note":"","ucode":"D4FB8DFCD3A275","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":296781,"discussion_content":"这两个「提交」的含义是不一样的。MySQL 事务中执行 commit 命令是第一种「提交」，也就是我们常说的事务的提交。\n\n但是当你执行了 commit 命令之后，MySQL 是不是要确保这个事务结束？也就是要写入 redo log 和 binlog。为了保证 crash-safe 和数据一致等问题，redo log 和 binlog 的写入使用了两阶段提交协议，redo log 会有 prepare 和 committed 两种状态，redo log 提交后会从 prepare 状态进入 committed 状态，这就是第二种「提交」。\n\n总结来说，第一种「提交」就是一条表示事务结束命令，而第二种「提交」是 MySQL 底层的一种机制。","likes_number":33,"is_delete":false,"is_hidden":false,"ctime":1596644452,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":2,"child_discussions":[{"author":{"id":2154955,"avatar":"https://static001.geekbang.org/account/avatar/00/20/e1/cb/2d718a3e.jpg","nickname":"舟","note":"","ucode":"FD049300DFA316","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1207495,"avatar":"https://static001.geekbang.org/account/avatar/00/12/6c/c7/c8a881ab.jpg","nickname":"labuladong","note":"","ucode":"D4FB8DFCD3A275","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":332842,"discussion_content":"居然在这看到力扣大佬了","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1607353284,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":296781,"ip_address":""},"score":332842,"extra":""},{"author":{"id":2112092,"avatar":"https://static001.geekbang.org/account/avatar/00/20/3a/5c/60fdf8e2.jpg","nickname":"wtdd","note":"","ucode":"26C64BF9CCA061","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2154955,"avatar":"https://static001.geekbang.org/account/avatar/00/20/e1/cb/2d718a3e.jpg","nickname":"舟","note":"","ucode":"FD049300DFA316","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":394400,"discussion_content":"这个人在力扣被锤爆哈哈。白嫖别人的成果出书还不标注来源，不应该这样做的。","likes_number":4,"is_delete":false,"is_hidden":false,"ctime":1631869298,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":332842,"ip_address":""},"score":394400,"extra":""}]},{"author":{"id":2377275,"avatar":"https://static001.geekbang.org/account/avatar/00/24/46/3b/ac4b8ab0.jpg","nickname":"Stream上的帧","note":"","ucode":"325FBEFF80BD91","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":336822,"discussion_content":"事务未提交前，不会触发两阶段提交协议，这是前提。\n事务提交之前的SQL操作，执行的是内存操作、redo log buffer和binlog cache中的操作。\n事务提交以后，触发两阶段提交协议，开始将redo log buffer和binlog cache中的内容写入到操作系统的 page cache中和进行磁盘同步(这个需要看两阶段算法怎么实现了)，两阶段提交，标识这次binlog和redo log中的操作是否成功。如果不成果回滚。","likes_number":22,"is_delete":false,"is_hidden":false,"ctime":1608709823,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1115724,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLwSoTjHPX5tm4whBSfoZLX6toZxrZGUaLABQywKNf4MDc9toK3QSV7Z99ATcGicFCysoleQ5ISzmw/132","nickname":"乘风","note":"","ucode":"0420C5535DACB7","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":66537,"discussion_content":"基于上面的讨论可以这样理解吗:\n  事务A未提交前被动持久化到磁盘的事务此时不是prepare状态.\n  事务A提交时会先向innoDB发起请求,innoDB标记此时事务处于prepare状态并返回给server,server写入binlog后再通知innoDB,innoDB此时才会真正执行commit,将事务标记为正式状态.\n\n","likes_number":13,"is_delete":false,"is_hidden":false,"ctime":1575082964,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":2,"child_discussions":[{"author":{"id":1675475,"avatar":"https://static001.geekbang.org/account/avatar/00/19/90/d3/ab5db902.jpg","nickname":"Chiron","note":"","ucode":"76BBD1F32A35D1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1115724,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLwSoTjHPX5tm4whBSfoZLX6toZxrZGUaLABQywKNf4MDc9toK3QSV7Z99ATcGicFCysoleQ5ISzmw/132","nickname":"乘风","note":"","ucode":"0420C5535DACB7","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":115839,"discussion_content":"太绕了，头疼","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1578039562,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":66537,"ip_address":""},"score":115839,"extra":""},{"author":{"id":2355521,"avatar":"https://static001.geekbang.org/account/avatar/00/23/f1/41/76c0758f.jpg","nickname":"君战","note":"","ucode":"A8619A79A5CED9","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1675475,"avatar":"https://static001.geekbang.org/account/avatar/00/19/90/d3/ab5db902.jpg","nickname":"Chiron","note":"","ucode":"76BBD1F32A35D1","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":351066,"discussion_content":"简单理解，事务提交命令commit会进行三个动作，redo log持久化prepare，binlog持久化，redo log持久化commit。但是是不是真正的去持久化了，取决于sync_binlog以及binlog_group_commit_sync_delay以及binlog_group_commit_sync_no_delay_count以及innodb_flush_log_at_trx_commit。","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1614144165,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":115839,"ip_address":""},"score":351066,"extra":""}]},{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":437795,"discussion_content":"不是。\n\n说明一下哈，所谓的 redo log prepare，是“当前事务提交”的一个阶段，也就是说，在事务A提交的时候，我们才会走到事务A的redo log prepare这个阶段。\n\n事务A在提交前，有一部分redo log被事务B提前持久化，但是事务A还没有进入提交阶段，是无所谓“redo log prepare”的。\n\n好问题\n\n","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1548644158,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2107375,"avatar":"https://static001.geekbang.org/account/avatar/00/20/27/ef/a7f94eda.jpg","nickname":"Jerry You","note":"","ucode":"679A44B505482F","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":377557,"discussion_content":"事务A有一部分被提前持久化，那么等到A真正提交的时候，redolog 还是顺序往后写么？ ","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1622708662,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1117597,"avatar":"https://static001.geekbang.org/account/avatar/00/11/0d/9d/58d09086.jpg","nickname":"达达队长","note":"","ucode":"1C3F2E4F6B7637","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":261403,"discussion_content":"插眼，提前刷入的redo log buffer 状态","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1588952961,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1324501,"avatar":"https://static001.geekbang.org/account/avatar/00/14/35/d5/17833946.jpg","nickname":"八宝","note":"","ucode":"89D991A930FDEA","race_medal":1,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":403813,"discussion_content":"Mark","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1634168914,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1891368,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTL6EicLXHeU06fj2Dy5nA4GoVyNzRV5V68uVxVwuKSNYG6T23KLPJ3z570GI3GI2NA9x885DvSE5Xg/132","nickname":"刘磊","note":"","ucode":"8B0EBB3DA4B63E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":393828,"discussion_content":"只有执行到commit状态的事务，才会去考虑能否组提交","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631611957,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2021212,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/MdmRMTV2IwvQZF2IO0G0CFWbKxT9CIibmcdicS3J4SmrA4P1e36jCwyXZpia06ItwP4GibGnCrPJHicBbd5y9libTpiaA/132","nickname":"^_^","note":"","ucode":"301EE75D170771","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":342573,"discussion_content":"这里的redo log的prepare和commit代表的是事务执行到什么程度了，结合两阶段提交协议来理解就是两个系统做好约定: redo log prepare==>binlog done ==>redo log commit；两阶梯提交机制就是保证数据库在执行commit命令前所有工作已经完成","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1610718877,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1809802,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/8a/a2d34896.jpg","nickname":"一元(wx:abley1874)","note":"","ucode":"5E7A33642FC767","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":304744,"discussion_content":"那么会不会出现，事务A已经处于commit阶段，事务B先事务A一步将redo log buffer中事务A的redo log落盘呢？ ","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1599654061,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":3,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1526355,"avatar":"https://static001.geekbang.org/account/avatar/00/17/4a/53/063f9d17.jpg","nickname":"moonfox","note":"","ucode":"902BFF40EFA9FA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1809802,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/9d/8a/a2d34896.jpg","nickname":"一元(wx:abley1874)","note":"","ucode":"5E7A33642FC767","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":311328,"discussion_content":"我觉得可以，这也是redo log 在fsync时故意等，即组提交的效果","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1602310011,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":304744,"ip_address":""},"score":311328,"extra":""}]}]},{"had_liked":false,"id":56878,"user_name":"倪大人","can_delete":false,"product_type":"c1","uid":1193052,"ip_address":"","ucode":"4798D69F3E86FB","user_header":"https://static001.geekbang.org/account/avatar/00/12/34/5c/6b4757a0.jpg","comment_is_top":false,"comment_ctime":1546571663,"is_pvip":false,"replies":[{"id":"20671","content":"好问题，我写这篇文章的时候也为了这个问题去翻了代码，是这样的：<br>达到N次以后，可以刷盘了，然后再进入(sync_delay和no_delay_count)这个逻辑；<br><br>Sync_delay如果很大，就达到no_delay_count才刷；<br><br>只要sync_binlog=0,也会有前面的等待逻辑，但是等完后还是不调fsync😄","user_name":"作者回复","comment_id":56878,"uid":"1264162","ip_address":"","utype":1,"ctime":1546762468,"user_name_real":"林晓斌"}],"discussion_count":7,"race_medal":0,"score":"332259053455","product_id":100020801,"comment_content":"老师求解sync_binlog和binlog_group_commit_sync_no_delay_count这两个参数区别<br><br>如果<br>       sync_binlog = N<br>       binlog_group_commit_sync_no_delay_count = M<br>       binlog_group_commit_sync_delay = 很大值<br>这种情况fsync什么时候发生呀，min(N,M)吗？<br>感觉sync_binlog搭配binlog_group_commit_sync_delay也可以实现组提交？<br><br>如果<br>        sync_binlog = 0<br>         binlog_group_commit_sync_no_delay_count = 10<br>这种情况下是累计10个事务fsync一次？","like_count":77,"discussions":[{"author":{"id":1320050,"avatar":"https://static001.geekbang.org/account/avatar/00/14/24/72/9e2a651c.jpg","nickname":"家有邹太","note":"","ucode":"5636BD37EB1A99","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":55427,"discussion_content":"也就是说先要满足sync_binlog，这个时候准备刷盘了，然后才去判断是否要延迟组提交，是么？","likes_number":6,"is_delete":false,"is_hidden":false,"ctime":1574378050,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":2,"child_discussions":[{"author":{"id":1707393,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/0d/81/ed4957e8.jpg","nickname":"walzzz","note":"","ucode":"17D8079494189A","race_medal":1,"user_type":1,"is_pvip":false},"reply_author":{"id":1320050,"avatar":"https://static001.geekbang.org/account/avatar/00/14/24/72/9e2a651c.jpg","nickname":"家有邹太","note":"","ucode":"5636BD37EB1A99","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":382210,"discussion_content":"反了吧，他是说sync_binlog=0，前面等完后面还是不调fsync","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1625474581,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":55427,"ip_address":""},"score":382210,"extra":""},{"author":{"id":1226968,"avatar":"https://static001.geekbang.org/account/avatar/00/12/b8/d8/f81b5604.jpg","nickname":"hcyycb","note":"","ucode":"77FF6CA41F9E66","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1320050,"avatar":"https://static001.geekbang.org/account/avatar/00/14/24/72/9e2a651c.jpg","nickname":"家有邹太","note":"","ucode":"5636BD37EB1A99","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":532173,"discussion_content":"如果 sync_binlog = 0,那么即使进入(sync_delay和no_delay_count)这个逻辑的判断满足了，也不会刷盘，而是等待系统默认的闲时刷盘策略。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1637549300,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":55427,"ip_address":""},"score":532173,"extra":"{\"user_type\":1}"}]},{"author":{"id":2446024,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/GA9AqKGEdib009iaPw3FSluiaeibCXmen7yFIKicZB8qqEtczZJF2WmwBJ738eExnxDmPREIGjqc4BFVXiamyhuCZASw/132","nickname":"一缕阳光","note":"","ucode":"CA89C1B7CB16C0","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":587513,"discussion_content":"其实简单单理解，group提交的时候，是提交有多少准备fsync的数据，而fsync的数据是靠sync_binlog 来决定提供的。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1663123684,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435293,"discussion_content":"好问题，我写这篇文章的时候也为了这个问题去翻了代码，是这样的：\n达到N次以后，可以刷盘了，然后再进入(sync_delay和no_delay_count)这个逻辑；\n\nSync_delay如果很大，就达到no_delay_count才刷；\n\n只要sync_binlog=0,也会有前面的等待逻辑，但是等完后还是不调fsync😄","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1546762468,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":1,"child_discussions":[{"author":{"id":1132922,"avatar":"https://static001.geekbang.org/account/avatar/00/11/49/7a/229097af.jpg","nickname":"jiyeon2__","note":"","ucode":"7ADFD70438E661","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"discussion":{"id":580274,"discussion_content":"sync_binlog = N\nbinlog_group_commit_sync_no_delay_count = M\n这种情况应该是满足N个group（每个group有M个事务）后才fsync吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1658058333,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":435293,"ip_address":""},"score":580274,"extra":""}]},{"author":{"id":2036924,"avatar":"https://static001.geekbang.org/account/avatar/00/1f/14/bc/326284b1.jpg","nickname":"ambrella","note":"","ucode":"9C0019364DCBB5","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":377072,"discussion_content":"这里好晕","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1622477445,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":62660,"user_name":"Komine","can_delete":false,"product_type":"c1","uid":1040449,"ip_address":"","ucode":"1668595D691F3A","user_header":"https://static001.geekbang.org/account/avatar/00/0f/e0/41/8ae7a30a.jpg","comment_is_top":false,"comment_ctime":1548125506,"is_pvip":false,"replies":[{"id":"22190","content":"好问题<br><br>我觉得一个比较重要的原因是，一个线程只能同时有一个事务在执行。<br><br>由于这个设定，所以每当执行一个begin&#47;start transaction的时候，就会默认提交上一个事务；<br>这样如果一个事务的binlog被拆开的时候，在备库执行就会被当做多个事务分段自行，这样破坏了原子性，是有问题的。","user_name":"作者回复","comment_id":62660,"uid":"1264162","ip_address":"","utype":1,"ctime":1548138498,"user_name_real":"林晓斌"}],"discussion_count":4,"race_medal":0,"score":"302195836226","product_id":100020801,"comment_content":"为什么binlog 是不能“被打断的”的呢？主要出于什么考虑？","like_count":71,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":437294,"discussion_content":"好问题\n\n我觉得一个比较重要的原因是，一个线程只能同时有一个事务在执行。\n\n由于这个设定，所以每当执行一个begin/start transaction的时候，就会默认提交上一个事务；\n这样如果一个事务的binlog被拆开的时候，在备库执行就会被当做多个事务分段自行，这样破坏了原子性，是有问题的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1548138498,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2009461,"avatar":"https://static001.geekbang.org/account/avatar/00/1e/a9/75/dbccd12d.jpg","nickname":"稻草人","note":"","ucode":"6694EE2CD36B8C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":355861,"discussion_content":"binlog的基于事务维度来记录的，，就是说一个完整的binlog就是一个完整的事务，如果binlog拆开了，那这个事务的记录就不完整了、不原子了，所以一个事务的binlog不能拆开。而redo log的记录是基于数据页的，一个事务可以有很多数据页的记录，只要保证redo log的数据页维度记录是完整的就可以，所以redo log是可以拆开的。","likes_number":6,"is_delete":false,"is_hidden":false,"ctime":1615482123,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1261530,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKDKsicmpne7xQNocwRQ80DDZ3CzjsDoVIcH0SBiaYzS056oVOx4pEeEVeCaXE3QtsjUIEI0x1xQVTw/132","nickname":"muggle","note":"","ucode":"D78087BCAD0860","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":535381,"discussion_content":"\n答：binlog写入的前提条件是事务被提交，事务至少进入了prepare状态，若此时一个事务的binlog如果能拆分写，则意味着在备库执行时，就相当于拆分成了多个事务段执行，此时破坏了事务的原子性，可能导致一些不可预知的问题：例如备库binlog并行复制等复杂问题。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1638423244,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1320050,"avatar":"https://static001.geekbang.org/account/avatar/00/14/24/72/9e2a651c.jpg","nickname":"家有邹太","note":"","ucode":"5636BD37EB1A99","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":393923,"discussion_content":"redo log的每一个page都是独立的单元，每个page header都会记录事务id信息。所以打散了没关系，还能串起来。binlog一个事务只会记录一次事务id，如果打散了就串不起来了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631662942,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":58540,"user_name":"猪哥哥","can_delete":false,"product_type":"c1","uid":1311362,"ip_address":"","ucode":"ACBB4556516D34","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLkhgYnYZBdhdwKnXQibey04cy9N9ria3DadH7iagoKukaWK1FJwjfCoh0He4p7b2icSYVzHH71l8ZXiaQ/132","comment_is_top":false,"comment_ctime":1547108412,"is_pvip":false,"replies":[{"id":"21178","content":"你理解的是对的","user_name":"作者回复","comment_id":58540,"uid":"1264162","ip_address":"","utype":1,"ctime":1547134527,"user_name_real":"林晓斌"}],"discussion_count":3,"race_medal":0,"score":"173345800252","product_id":100020801,"comment_content":"老师 我想问下文件系统的page cache还是不是内存, 是不是文件系统向内核申请的一块的内存?","like_count":41,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":436112,"discussion_content":"你理解的是对的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1547134527,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1543040,"avatar":"https://static001.geekbang.org/account/avatar/00/17/8b/80/8702bd5f.jpg","nickname":"evan","note":"","ucode":"491B073D5AFEDE","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":319986,"discussion_content":"是内存 page cache是用作操作系统页缓冲的, 但是Mysql会使用direct io, 绕过操作系统的page cache, 而使用自己的buffer pool, 但自己的buffer pool也是向操作系统申请的...","likes_number":8,"is_delete":false,"is_hidden":false,"ctime":1604221245,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2029015,"avatar":"","nickname":"小钢炮","note":"","ucode":"676C4CCF3CCD0D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":411164,"discussion_content":"log buffer->os buffer->log file on disk","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1635859824,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":57390,"user_name":"某、人","can_delete":false,"product_type":"c1","uid":1308784,"ip_address":"","ucode":"ADB42AA12A11C1","user_header":"https://static001.geekbang.org/account/avatar/00/13/f8/70/f3a33a14.jpg","comment_is_top":false,"comment_ctime":1546776573,"is_pvip":false,"replies":[{"id":"20674","content":"1. Write的时候只要写进去了，fsync其实很快的。连续性是write的时候做的（写的时候保证了连续）<br><br>2. 你的理解应该是对的。不是表级","user_name":"作者回复","comment_id":57390,"uid":"1264162","ip_address":"","utype":1,"ctime":1546781232,"user_name_real":"林晓斌"}],"discussion_count":17,"race_medal":0,"score":"156165599229","product_id":100020801,"comment_content":"有调到非双1的时候,在大促时非核心库和从库延迟较多的情况。<br>设置的是sync_binlog=0和innodb_flush_log_at_trx_commit=2<br>针对0和2,在mysql crash时不会出现异常,在主机挂了时，会有几种风险:<br>1.如果事务的binlog和redo log都还未fsync,则该事务数据丢失<br>2.如果事务binlog fsync成功,redo log未fsync,则该事务数据丢失。<br>虽然binlog落盘成功,但是binlog没有恢复redo log的能力,所以redo log不能恢复.<br>不过后续可以解析binlog来恢复这部分数据<br>3.如果事务binlog fsync未成功,redo log成功。<br>由于redo log恢复数据是在引擎层,所以重新启动数据库,redo log能恢复数据,但是不能恢复server层的binlog,则binlog丢失。<br>如果该事务还未从FS page cache里发送给从库,那么主从就会出现不一致的情况<br>4.如果binlog和redo log都成功fsync,那么皆大欢喜。<br><br>老师我有几个问题:<br>1.因为binlog不能被打断,那么binlog做fsync是单线程吧?<br>如果是的话,那么binlog的write到fsync的时间,就应该是redo log fsync+上一个事务的binlog fsync时间。<br>但是测试到的现象,一个超大事务做fsync时,对其它事务的提交影响也不大。<br>如果是多线程做fsync,怎么保证的一个事务binlog在磁盘上的连续性？<br>2.  5.7的并行复制是基于binlog组成员并行的,为什么很多文章说是表级别的并行复制？","like_count":36,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435555,"discussion_content":"1. Write的时候只要写进去了，fsync其实很快的。连续性是write的时候做的（写的时候保证了连续）\n\n2. 你的理解应该是对的。不是表级","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1546781232,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1692320,"avatar":"https://static001.geekbang.org/account/avatar/00/19/d2/a0/c8714628.jpg","nickname":"独一无二","note":"","ucode":"A7DE0EA2BD8FE3","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":60997,"discussion_content":"找不到单独发评论的地方，正好看到你发的评论产生了一个疑问，也不知道有没有人回答。从库将自己执行的和已经接收的位置信息发给主库，主库show master status之后，看到的是持久化的文件还是也包括文件系统缓存的binlog？","likes_number":3,"is_delete":false,"is_hidden":false,"ctime":1574768758,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1320050,"avatar":"https://static001.geekbang.org/account/avatar/00/14/24/72/9e2a651c.jpg","nickname":"家有邹太","note":"","ucode":"5636BD37EB1A99","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1692320,"avatar":"https://static001.geekbang.org/account/avatar/00/19/d2/a0/c8714628.jpg","nickname":"独一无二","note":"","ucode":"A7DE0EA2BD8FE3","race_medal":0,"user_type":1,"is_pvip":true},"discussion":{"id":393925,"discussion_content":"我理解show master status应该是从表里获取的gtid吧。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631663649,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":60997,"ip_address":""},"score":393925,"extra":""}]},{"author":{"id":2009461,"avatar":"https://static001.geekbang.org/account/avatar/00/1e/a9/75/dbccd12d.jpg","nickname":"稻草人","note":"","ucode":"6694EE2CD36B8C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":355866,"discussion_content":"问：共同写一个binlog文件，这个过程应该需要锁来维持提交的时序吧，写文件的时候是不是可能会变成瓶颈点？\n\n作者回复: 不会的，大家分头写，然后一起持久化到磁盘","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1615483447,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":3,"child_discussions":[{"author":{"id":2336545,"avatar":"https://static001.geekbang.org/account/avatar/00/23/a7/21/9366cdd8.jpg","nickname":"三井寿","note":"","ucode":"325E9D64C22C0D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2009461,"avatar":"https://static001.geekbang.org/account/avatar/00/1e/a9/75/dbccd12d.jpg","nickname":"稻草人","note":"","ucode":"6694EE2CD36B8C","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":371242,"discussion_content":"分头写是怎么保证顺序的，不太明白这里","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1619693270,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":355866,"ip_address":""},"score":371242,"extra":""},{"author":{"id":2775007,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTI6LQLz15qzxQxxllMHKibevP2BpjRldqW0laElfFlHfSAER2OMBicp7pez90AevWKwWxwC6pp5iaWWw/132","nickname":"五月","note":"","ucode":"B984F2138C5345","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2336545,"avatar":"https://static001.geekbang.org/account/avatar/00/23/a7/21/9366cdd8.jpg","nickname":"三井寿","note":"","ucode":"325E9D64C22C0D","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":530718,"discussion_content":"我的理解, 顺序的保证是不是和这个binlog的LSN有关, 在落盘之前, 可能有一个机制来根据每个binlog的LSN来排序","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1637133835,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":371242,"ip_address":""},"score":530718,"extra":"{\"user_type\":1}"},{"author":{"id":1986739,"avatar":"https://static001.geekbang.org/account/avatar/00/1e/50/b3/9269cd59.jpg","nickname":"LWD","note":"","ucode":"DDA444DB113C01","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2009461,"avatar":"https://static001.geekbang.org/account/avatar/00/1e/a9/75/dbccd12d.jpg","nickname":"稻草人","note":"","ucode":"6694EE2CD36B8C","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":587765,"discussion_content":"组提交里面有个锁分段就是用来处理这个问题的，每个锁会维护一个队列，进入第一个队列以后，后续的阶段都要保持这个时序；通过这个机制就可以实现这几个阶段的并发","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1663259493,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":355866,"ip_address":"广东"},"score":587765,"extra":""}]},{"author":{"id":1324501,"avatar":"https://static001.geekbang.org/account/avatar/00/14/35/d5/17833946.jpg","nickname":"八宝","note":"","ucode":"89D991A930FDEA","race_medal":1,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":403815,"discussion_content":"Mark","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1634169137,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2009461,"avatar":"https://static001.geekbang.org/account/avatar/00/1e/a9/75/dbccd12d.jpg","nickname":"稻草人","note":"","ucode":"6694EE2CD36B8C","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":355864,"discussion_content":"就是说binlog的组提交时是在write时就保证了的，然后fsync的时候就一波执行不用考虑顺序性了。那么问题来了，binlog无法并发write？只能串行write?","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1615482568,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2355521,"avatar":"https://static001.geekbang.org/account/avatar/00/23/f1/41/76c0758f.jpg","nickname":"君战","note":"","ucode":"A8619A79A5CED9","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":351020,"discussion_content":"针对第3种场景，sync_binlog等于0的时候，不是每次事务提交都会持久化到磁盘的吗？这时候不就相当于redo log有prepare，在等binlog fsync。主机恢复MySQL重启的时候，就回滚该事务。怎么可能出现“如果该事务还未从FS page cache里发送给从库,那么主从就会出现不一致的情况”呢？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1614125016,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":2,"child_discussions":[{"author":{"id":1308784,"avatar":"https://static001.geekbang.org/account/avatar/00/13/f8/70/f3a33a14.jpg","nickname":"某、人","note":"","ucode":"ADB42AA12A11C1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2355521,"avatar":"https://static001.geekbang.org/account/avatar/00/23/f1/41/76c0758f.jpg","nickname":"君战","note":"","ucode":"A8619A79A5CED9","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":351204,"discussion_content":"sync binlog设置为0不是每次事务提交都会持久化到磁盘","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1614176966,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":351020,"ip_address":""},"score":351204,"extra":""},{"author":{"id":2355521,"avatar":"https://static001.geekbang.org/account/avatar/00/23/f1/41/76c0758f.jpg","nickname":"君战","note":"","ucode":"A8619A79A5CED9","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1308784,"avatar":"https://static001.geekbang.org/account/avatar/00/13/f8/70/f3a33a14.jpg","nickname":"某、人","note":"","ucode":"ADB42AA12A11C1","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":353731,"discussion_content":"谢谢回复，sync_binlog = 1才是每次提交都持久化到磁盘。搞混了~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1615197118,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":351204,"ip_address":""},"score":353731,"extra":""}]},{"author":{"id":1526355,"avatar":"https://static001.geekbang.org/account/avatar/00/17/4a/53/063f9d17.jpg","nickname":"moonfox","note":"","ucode":"902BFF40EFA9FA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":331357,"discussion_content":"还是没有回答binlog在write时是不是并发的，个人感觉不是，如果不是，那就是顺序的，那这样就会影响性能","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606834877,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1005164,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/56/6c/6e2fd5df.jpg","nickname":"Alan","note":"","ucode":"AB242424C998DC","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":45725,"discussion_content":"感觉 还是不能百分百绝对保证数据不丢呀 和标题不匹配","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1573061934,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":3,"child_discussions":[{"author":{"id":1275980,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eoicSMibHxGmeNXCLAnB6S7icPh814icIsw7VZ5vYzLOyKKUJYmFC5WGPekH5qI7rRbH3n4Y2obiaKlBTQ/132","nickname":"konh","note":"","ucode":"1CAD0D67067CC1","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1005164,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/56/6c/6e2fd5df.jpg","nickname":"Alan","note":"","ucode":"AB242424C998DC","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":317179,"discussion_content":"如果binlong和redolog策略都选择提交事务就持久化到磁盘，那不就保证数据不丢失了。\n现在是为了提升性能，所以抛弃了一定的数据安全性","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1603512526,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":45725,"ip_address":""},"score":317179,"extra":""},{"author":{"id":1357311,"avatar":"https://static001.geekbang.org/account/avatar/00/14/b5/ff/d1f205b0.jpg","nickname":"L","note":"","ucode":"5B847B2378854E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1005164,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/56/6c/6e2fd5df.jpg","nickname":"Alan","note":"","ucode":"AB242424C998DC","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":318600,"discussion_content":"可以百分百，但是你就要牺牲性能！  所有的设计，都是做权衡！","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1603789338,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":45725,"ip_address":""},"score":318600,"extra":""},{"author":{"id":1320050,"avatar":"https://static001.geekbang.org/account/avatar/00/14/24/72/9e2a651c.jpg","nickname":"家有邹太","note":"","ucode":"5636BD37EB1A99","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1005164,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/56/6c/6e2fd5df.jpg","nickname":"Alan","note":"","ucode":"AB242424C998DC","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":393926,"discussion_content":"双1配置的话，如果binlog和redo log都fsync成功，那自然没问题，如果任何一个fsync失败，那么recover的时候会回滚，数据也是一致的\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631663915,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":45725,"ip_address":""},"score":393926,"extra":""}]}]},{"had_liked":false,"id":128743,"user_name":"浩瀚有边","can_delete":false,"product_type":"c1","uid":1087384,"ip_address":"","ucode":"B4540E94EAFFE0","user_header":"https://static001.geekbang.org/account/avatar/00/10/97/98/5ef15aa0.jpg","comment_is_top":false,"comment_ctime":1566955879,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"113236105575","product_id":100020801,"comment_content":"刚开始我也遇到了jacy一样的问题，认为binlog写到file里面就是写到disk了，就不理解为什么还要fsync，后来仔细回读了文章，发现binlog写到file是指写到pagecache，并不是disk。<br>建议老师在描述binlog写盘的那两个步骤时，把写到file直接描述为写到pagecache，避免歧义","like_count":27},{"had_liked":false,"id":58286,"user_name":"xiaoyou","can_delete":false,"product_type":"c1","uid":1302588,"ip_address":"","ucode":"2B6E553E8187F0","user_header":"https://static001.geekbang.org/account/avatar/00/13/e0/3c/ae0f6f57.jpg","comment_is_top":false,"comment_ctime":1547026859,"is_pvip":false,"replies":[{"id":"21015","content":"你说的对，分析得很好","user_name":"作者回复","comment_id":58286,"uid":"1264162","ip_address":"","utype":1,"ctime":1547043584,"user_name_real":"林晓斌"}],"discussion_count":15,"race_medal":0,"score":"100331274667","product_id":100020801,"comment_content":"老师，请教一个问题，文章说innodb的 redo log 在commit的时候不进行fsync，只会write 到page cache中。当sync_binlog&gt;1,如果redo log 完成了prepare持久化落盘，binlog只是write page cache，此时commit标识完成write 但没有落盘，而client收到commit成功，这个时候主机掉电，启动的时候做崩溃恢复，没有commit标识和binglog，事务会回滚。我看文章说sync_binlog设置为大于1的值，会丢binlog日志,此时数据也会丢失吧？","like_count":23,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435988,"discussion_content":"你说的对，分析得很好","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1547043584,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1526355,"avatar":"https://static001.geekbang.org/account/avatar/00/17/4a/53/063f9d17.jpg","nickname":"moonfox","note":"","ucode":"902BFF40EFA9FA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":348920,"discussion_content":"所以文章中提到的客服端收到commit,日志就一定持久化了是不准确的吧","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1612776082,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":2,"child_discussions":[{"author":{"id":1901428,"avatar":"https://wx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLwIAiaxOJWE3Ut6hRvTzvFkCIibcURojC0XrQI1lC3h58enlNcpXQ98rmUOr5lA6ST3m24micj191Gw/132","nickname":"不疾","note":"","ucode":"18AA0F294C1586","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1526355,"avatar":"https://static001.geekbang.org/account/avatar/00/17/4a/53/063f9d17.jpg","nickname":"moonfox","note":"","ucode":"902BFF40EFA9FA","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":374956,"discussion_content":"对。假设binlog_sync设置为5，在执行第4个事务过程中服务器宕机，执行前3个事务的客户端虽然收到commit，但事务其实是还未持久化的","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1621418720,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":348920,"ip_address":""},"score":374956,"extra":""},{"author":{"id":2389270,"avatar":"https://static001.geekbang.org/account/avatar/00/24/75/16/6e28bf17.jpg","nickname":"初晨","note":"","ucode":"C5D95D13E49127","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1526355,"avatar":"https://static001.geekbang.org/account/avatar/00/17/4a/53/063f9d17.jpg","nickname":"moonfox","note":"","ucode":"902BFF40EFA9FA","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":589820,"discussion_content":"说的是双1场景","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1665326293,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":348920,"ip_address":"陕西"},"score":589820,"extra":""}]},{"author":{"id":1810156,"avatar":"","nickname":"poordickey","note":"","ucode":"2A436EC813AF97","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":334458,"discussion_content":"这个评论可以往前排不  这个可以说是数据丢失的一种场景了","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1607852839,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1810156,"avatar":"","nickname":"poordickey","note":"","ucode":"2A436EC813AF97","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":334456,"discussion_content":"两全不能齐美   要保证事物一致就得不断fsync从而性能就会变差   要想高性能就得承担事物丢失的风险","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1607852777,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1986739,"avatar":"https://static001.geekbang.org/account/avatar/00/1e/50/b3/9269cd59.jpg","nickname":"LWD","note":"","ucode":"DDA444DB113C01","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":561117,"discussion_content":"数据相对客户端是丢失了。但是redo和binlog还是能保持一致性的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1649555758,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1014347,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/7a/4b/1a7b36ab.jpg","nickname":"欧星星","note":"","ucode":"56365442E231A0","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":561000,"discussion_content":"如果要保证数据不丢，就要设置sync_binlog=1，但性能就会下降","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1649510098,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1320050,"avatar":"https://static001.geekbang.org/account/avatar/00/14/24/72/9e2a651c.jpg","nickname":"家有邹太","note":"","ucode":"5636BD37EB1A99","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":393927,"discussion_content":"其实fsync过程很快的，而且commit时间占交易时间的比率很低的，所以开启双1对性能影响其实没那么大。与其关注这个，不如关注下把应用程序写的好一点，索引设计的好一点，这个才是大头。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631664316,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1676246,"avatar":"https://static001.geekbang.org/account/avatar/00/19/93/d6/040e4965.jpg","nickname":"Omer","note":"","ucode":"8EE3E531313265","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":391267,"discussion_content":"请教个问题, 那如果说binlog丢失了, 但是commit刷磁盘了, 会怎么处理这个情况,我看恢复的时候如果commit了就直接ok了, 那这样binlog又没有数据呢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1630381420,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1155646,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKotsBr2icbYNYlRSlicGUD1H7lulSTQUAiclsEz9gnG5kCW9qeDwdYtlRMXic3V6sj9UrfKLPJnQojag/132","nickname":"ppd0705","note":"","ucode":"EB63D4E3FD1E9A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":270686,"discussion_content":"commit之前bin log应该已经fsync了吧？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1590036568,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":4,"child_discussions":[{"author":{"id":1323652,"avatar":"","nickname":"sibyl","note":"","ucode":"0D142011860D69","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1155646,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKotsBr2icbYNYlRSlicGUD1H7lulSTQUAiclsEz9gnG5kCW9qeDwdYtlRMXic3V6sj9UrfKLPJnQojag/132","nickname":"ppd0705","note":"","ucode":"EB63D4E3FD1E9A","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":294461,"discussion_content":"sync binlog = n时， 会等待有n个事务提交才会主动fsync，所以某个事务在提交时因为不足n所以不会主动fsync，但也会响应客户端成功，如果此刻文件系统也没有fsync并且crash了，那么这些binlog就没持久化。\n\n等重启后，即使有redolog但是不存在binlog，所以也不会恢复这个事务，那这个事务的变更操作就丢了😁","likes_number":10,"is_delete":false,"is_hidden":false,"ctime":1595898540,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":270686,"ip_address":""},"score":294461,"extra":""},{"author":{"id":1676246,"avatar":"https://static001.geekbang.org/account/avatar/00/19/93/d6/040e4965.jpg","nickname":"Omer","note":"","ucode":"8EE3E531313265","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1323652,"avatar":"","nickname":"sibyl","note":"","ucode":"0D142011860D69","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":391266,"discussion_content":"大佬请教个问题, 那如果说binlog丢失了, 但是commit刷磁盘了, 会怎么处理这个情况,我看恢复的时候如果commit了就直接ok了, 那这样binlog又没有数据呢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1630381415,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":294461,"ip_address":""},"score":391266,"extra":""},{"author":{"id":1055662,"avatar":"https://static001.geekbang.org/account/avatar/00/10/1b/ae/ec71a853.jpg","nickname":"Shan","note":"","ucode":"90374AC27C09D2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1676246,"avatar":"https://static001.geekbang.org/account/avatar/00/19/93/d6/040e4965.jpg","nickname":"Omer","note":"","ucode":"8EE3E531313265","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":396350,"discussion_content":"我觉得事务还是成功的，只不过bin log丢失了，如果在bin log 在page cache的时候没有下发到从库的话。就会导致主从数据不一致。如有问题，还请指出。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1632412099,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":391266,"ip_address":""},"score":396350,"extra":""}]}]},{"had_liked":false,"id":57204,"user_name":"一大只😴","can_delete":false,"product_type":"c1","uid":1310960,"ip_address":"","ucode":"92F3D2B7F63568","user_header":"https://static001.geekbang.org/account/avatar/00/14/00/f0/08409e78.jpg","comment_is_top":false,"comment_ctime":1546681795,"is_pvip":false,"replies":[{"id":"20630","content":"👍🏿<br>非常好<br><br>然后再补上我回答的这个逻辑，就完备了<br><br>","user_name":"作者回复","comment_id":57204,"uid":"1264162","ip_address":"","utype":1,"ctime":1546684534,"user_name_real":"林晓斌"}],"discussion_count":1,"race_medal":0,"score":"87446027715","product_id":100020801,"comment_content":"你是怎么验证的？等于0的时候虽然有走这个逻辑，但是最后调用fsync之前判断是0，就啥也没做就走了<br>回复老师:<br>       老师，我说的sync_binlog=0或=1效果一样，就是看语句实际执行的效果，参数binlog_group_commit_sync_delay我设置成了500000微秒，在=1或=0时，对表进行Insert，然后都会有0.5秒的等待，也就是执行时间都是0.51 sec，关闭binlog_group_commit_sync_delay，insert执行会飞快，所以我认为=1或=0都是受组提交参数的影响的。","like_count":21,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435460,"discussion_content":"👍🏿\n非常好\n\n然后再补上我回答的这个逻辑，就完备了\n\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1546684534,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":57830,"user_name":"Mr.Strive.Z.H.L","can_delete":false,"product_type":"c1","uid":1030198,"ip_address":"","ucode":"6D97E159E2EECD","user_header":"https://static001.geekbang.org/account/avatar/00/0f/b8/36/542c96bf.jpg","comment_is_top":false,"comment_ctime":1546920548,"is_pvip":false,"replies":[{"id":"21112","content":"你的理解很到位","user_name":"作者回复","comment_id":57830,"uid":"1264162","ip_address":"","utype":1,"ctime":1547118303,"user_name_real":"林晓斌"}],"discussion_count":9,"race_medal":0,"score":"78856331876","product_id":100020801,"comment_content":"老师你好，看了@倪大人的问题，个人认为：<br>sync_binlog和binlog_group_commit_sync_no_delay_count的最大区别主要在于，数据的丢失与否吧？<br><br>sync_binlog = N：每个事务write后就响应客户端了。刷盘是N次事务后刷盘。N次事务之间宕机，数据丢失。<br><br>binlog_group_commit_sync_no_delay_count=N： 必须等到N个后才能提交。换言之，会增加响应客户端的时间。但是一旦响应了，那么数据就一定持久化了。宕机的话，数据是不会丢失的。<br><br>不知道我这么理解对不对？<br>","like_count":19,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435780,"discussion_content":"你的理解很到位","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1547118303,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1395853,"avatar":"","nickname":"胖头欧巴","note":"","ucode":"97EF28759A4E4A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":533808,"discussion_content":"binlog_group_commit_sync_no_delay_count不影响响应时间呀，这是binlog延迟多久去调fsync而已","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1637982729,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1250580,"avatar":"https://static001.geekbang.org/account/avatar/00/13/15/14/21e0807e.jpg","nickname":"gm","note":"","ucode":"0E39AE5BE34E27","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":410453,"discussion_content":"可以通过不同角度看待，从客户端的角度看待sync_binlog，从mysql系统角度看待sync_no_delay_count","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1635692319,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1115149,"avatar":"https://static001.geekbang.org/account/avatar/00/11/04/0d/3dc5683a.jpg","nickname":"柯察金","note":"","ucode":"F722BF8FCD2C47","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":391055,"discussion_content":"如果 n 设置为 10，如果一直达不到 10 个，我的事务就卡死了，一直提交不了？？？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1630250271,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1707393,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/0d/81/ed4957e8.jpg","nickname":"walzzz","note":"","ucode":"17D8079494189A","race_medal":1,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":382211,"discussion_content":"感觉说的不对吧，binlog_group_commit_sync_no_delay_count=N也不是要等有第N个后第一个才返回吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1625474775,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1652836,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epKJlW7sqts2ZbPuhMbseTAdvHWnrc4ficAeSZyKibkvn6qyxflPrkKKU3mH6XCNmYvDg11tB6y0pxg/132","nickname":"pc","note":"","ucode":"1AD538B9A900B6","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":120579,"discussion_content":"按照之前的讨论，是要先判断sync_binlog？如果sync_binlog> binlog_group_commit_sync_no_delay_count，那么到达M值也不提交？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1578283291,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":3,"child_discussions":[{"author":{"id":1508329,"avatar":"https://static001.geekbang.org/account/avatar/00/17/03/e9/6358059c.jpg","nickname":"GalaxyCreater","note":"","ucode":"C79E8A088D57CF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1652836,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epKJlW7sqts2ZbPuhMbseTAdvHWnrc4ficAeSZyKibkvn6qyxflPrkKKU3mH6XCNmYvDg11tB6y0pxg/132","nickname":"pc","note":"","ucode":"1AD538B9A900B6","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":245732,"discussion_content":"满足sync_binlog或 binlog_group_commit_sync_no_delay_count中的一个就会提交","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1587695426,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":120579,"ip_address":""},"score":245732,"extra":""},{"author":{"id":2355521,"avatar":"https://static001.geekbang.org/account/avatar/00/23/f1/41/76c0758f.jpg","nickname":"君战","note":"","ucode":"A8619A79A5CED9","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1508329,"avatar":"https://static001.geekbang.org/account/avatar/00/17/03/e9/6358059c.jpg","nickname":"GalaxyCreater","note":"","ucode":"C79E8A088D57CF","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":365353,"discussion_content":"不是，是先满足sync_binlog，然后再判断是否满足binlog_group_commit_sync_delay或binlog_group_commit_sync_no_delay_count。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1617781900,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":245732,"ip_address":""},"score":365353,"extra":""},{"author":{"id":1707393,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/0d/81/ed4957e8.jpg","nickname":"walzzz","note":"","ucode":"17D8079494189A","race_medal":1,"user_type":1,"is_pvip":false},"reply_author":{"id":2355521,"avatar":"https://static001.geekbang.org/account/avatar/00/23/f1/41/76c0758f.jpg","nickname":"君战","note":"","ucode":"A8619A79A5CED9","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":382209,"discussion_content":"反了吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1625474438,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":365353,"ip_address":""},"score":382209,"extra":""}]}]},{"had_liked":false,"id":71299,"user_name":"melon","can_delete":false,"product_type":"c1","uid":1023773,"ip_address":"","ucode":"7A80C20EBCAAA4","user_header":"https://static001.geekbang.org/account/avatar/00/0f/9f/1d/ec173090.jpg","comment_is_top":false,"comment_ctime":1551317297,"is_pvip":false,"replies":[{"id":"25523","content":"前面的伪代码不错哈<br><br>”binlog_group_commit_sync_no_delay_count这个参数是不是不应该设置的比并发线程数大“，最好是这样的，否则的话，就只能等binlog_group_commit_sync_delay |时间到了","user_name":"作者回复","comment_id":71299,"uid":"1264162","ip_address":"","utype":1,"ctime":1551320027,"user_name_real":"林晓斌"}],"discussion_count":2,"race_medal":0,"score":"44500990257","product_id":100020801,"comment_content":"老师帮忙看一下我binlog 组提交这块理解的对不对<br><br>binlog write 阶段<br>组里面第一个走到 binlog write 的事务记录一个时间戳，用于在 binlog fsync 阶段计算 sync delay了多少时间，姑且计为 start_time<br>组里已 sync write 次数+1，姑且记为 group_write<br>全局已 sync wirte 次数+1，姑且记为 global_write<br><br>binlog fsync 阶段<br>IF ( NOW - sart_time ) &gt;= binlog_group_commit_sync_delay || group_write &gt;= binlog_group_commit_sync_no_delay_count<br>    IF sync_binlog &gt;0 &amp;&amp; global_write &gt;= sync_binlog<br>        fsync<br><br>    设置 binlog 组提交信号，让其它等待的事务继续<br>ELSE<br>    等待 binlog 组提交信号<br><br>另外 binlog_group_commit_sync_no_delay_count 这个参数是不是不应该设置的比并发线程数大，因为一个组里的事务应该不会比并发线程数多吧，设置大了也就没什么意义了，可以这么理解吧老师。","like_count":10,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":441098,"discussion_content":"前面的伪代码不错哈\n\n”binlog_group_commit_sync_no_delay_count这个参数是不是不应该设置的比并发线程数大“，最好是这样的，否则的话，就只能等binlog_group_commit_sync_delay |时间到了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1551320027,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1323652,"avatar":"","nickname":"sibyl","note":"","ucode":"0D142011860D69","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":294465,"discussion_content":"binlog fsync 阶段:\n\nif(binlog_group_commit_sync_delay > 0  || binlog_group_commit_sync_no_delay_count > 0){\n    while  ( NOW - sart_time <=          binlog_group_comnit_sync_delay &amp;&amp; group_write <= binlog_group_commit_sync_no_delay_count){}\n    fsync\n\n}\n\n IF sync_binlog > 0 &amp;&amp; global_write >= sync_binlog\n        fsync","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1595899088,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":71589,"user_name":"liao xueqiang","can_delete":false,"product_type":"c1","uid":1310325,"ip_address":"","ucode":"68713441579F6B","user_header":"https://static001.geekbang.org/account/avatar/00/13/fe/75/46742f12.jpg","comment_is_top":false,"comment_ctime":1551398442,"is_pvip":false,"replies":[{"id":"25732","content":"不是，这意思就是，即使异常掉电，只要redo log的prepare 部分+binlog完整，就会保证不丢数据。<br><br>也就是说，最多会丢失1秒的“redo log commit信息”，但是这个commit信息丢失，并不会影响数据（就是崩溃恢复慢一点）","user_name":"作者回复","comment_id":71589,"uid":"1264162","ip_address":"","utype":1,"ctime":1551403979,"user_name_real":"林晓斌"}],"discussion_count":8,"race_medal":0,"score":"40206104106","product_id":100020801,"comment_content":"每秒一次后台轮询刷盘，再加上崩溃恢复这个逻辑，InnoDB 就认为 redo log 在 commit 的时候就不需要 fsync 了，只会 write 到文件系统的 page cache 中就够了。老师好，这句话怎么理解呢？这不是服务器重启的情况下，会丢失1秒的数据吗","like_count":10,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":441220,"discussion_content":"不是，这意思就是，即使异常掉电，只要redo log的prepare 部分+binlog完整，就会保证不丢数据。\n\n也就是说，最多会丢失1秒的“redo log commit信息”，但是这个commit信息丢失，并不会影响数据（就是崩溃恢复慢一点）","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1551403979,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1889026,"avatar":"","nickname":"红颜铭心","note":"","ucode":"18F94E5444C71A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":230994,"discussion_content":"如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；\n如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。","likes_number":5,"is_delete":false,"is_hidden":false,"ctime":1586784162,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":2,"child_discussions":[{"author":{"id":1055662,"avatar":"https://static001.geekbang.org/account/avatar/00/10/1b/ae/ec71a853.jpg","nickname":"Shan","note":"","ucode":"90374AC27C09D2","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1889026,"avatar":"","nickname":"红颜铭心","note":"","ucode":"18F94E5444C71A","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":396355,"discussion_content":"> 如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；\nredo log commit 之后但是bin log 丢失的这种我理解也是成功？\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1632412358,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":230994,"ip_address":""},"score":396355,"extra":""},{"author":{"id":1302556,"avatar":"https://static001.geekbang.org/account/avatar/00/13/e0/1c/aa50dc27.jpg","nickname":"icyricky","note":"","ucode":"D63C285165309D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1055662,"avatar":"https://static001.geekbang.org/account/avatar/00/10/1b/ae/ec71a853.jpg","nickname":"Shan","note":"","ucode":"90374AC27C09D2","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":407576,"discussion_content":"binlog在redo log commit之前就落盘了，不会出现你说的binlog丢失的场景","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1635064239,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":396355,"ip_address":""},"score":407576,"extra":""}]},{"author":{"id":1366960,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLYicScS2u9alz421bWmOT0qKkAJbXcsFhtuqM6XByicnSL6nFHTQ5fPLM9R8HgjABicJXdqQljIJroQ/132","nickname":"上善若水","note":"","ucode":"DEB612BBF40014","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":342645,"discussion_content":"刷第三遍才豁然开朗，原来redolog日志在commit的时候，是继续写磁盘。之前一直以为是找到原来prepare的日志，修改为commit状态。所以才困惑，第二次也不是顺序写，没有节省时间。","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1610764221,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1526355,"avatar":"https://static001.geekbang.org/account/avatar/00/17/4a/53/063f9d17.jpg","nickname":"moonfox","note":"","ucode":"902BFF40EFA9FA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1366960,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLYicScS2u9alz421bWmOT0qKkAJbXcsFhtuqM6XByicnSL6nFHTQ5fPLM9R8HgjABicJXdqQljIJroQ/132","nickname":"上善若水","note":"","ucode":"DEB612BBF40014","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":348924,"discussion_content":"之前和你有一样的疑惑，看完你写的，又看了一遍原文，才明白","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1612777179,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":342645,"ip_address":""},"score":348924,"extra":""}]},{"author":{"id":1889026,"avatar":"","nickname":"红颜铭心","note":"","ucode":"18F94E5444C71A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":230997,"discussion_content":"丢数据是不可能的 只不过拿着xid去磁盘查找binlog 找到后再commit到redo log  完成事务提交","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1586784310,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1255820,"avatar":"https://static001.geekbang.org/account/avatar/00/13/29/8c/3a810521.jpg","nickname":"CaptainBerg","note":"","ucode":"4033CF49863F7E","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":301124,"discussion_content":"“commit 不fsync ，只write”，指的是redo log的那个commit标识。按照文中的说法，当配置为双1时，redo log的prepare阶段已经把redolog落盘了，所以就算redolog的commit阶段不fsync  commit标识，也不影响crash safe","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1598413569,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":99492,"user_name":"jacy","can_delete":false,"product_type":"c1","uid":1103456,"ip_address":"","ucode":"0022A8759DDCE6","user_header":"https://static001.geekbang.org/account/avatar/00/10/d6/60/f21b2164.jpg","comment_is_top":false,"comment_ctime":1559229259,"is_pvip":false,"replies":[{"id":"36697","content":"wrie很多次，fsync一次","user_name":"作者回复","comment_id":99492,"uid":"1264162","ip_address":"","utype":1,"ctime":1560003793,"user_name_real":"林晓斌"}],"discussion_count":2,"race_medal":1,"score":"35918967627","product_id":100020801,"comment_content":"1.先把 binlog 从 binlog cache 中写到磁盘上的 binlog 文件；<br>2.调用 fsync 持久化。<br><br>老师，这两步我不不太理解，写到磁盘binlog文件，不就是持久化了吗，为啥还要调用fsync再刷一次盘呢？能否帮忙解答一下，感谢🙏","like_count":8,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":452136,"discussion_content":"wrie很多次，fsync一次","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1560003793,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1082785,"avatar":"https://static001.geekbang.org/account/avatar/00/10/85/a1/2442332c.jpg","nickname":"郭俊杰","note":"","ucode":"D328E5738A4413","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":2010,"discussion_content":"我的理解是第1步，是将binlog cache中的写到了page cache中，只不过这个页缓存名字叫系统binlog文件","likes_number":6,"is_delete":false,"is_hidden":false,"ctime":1563178294,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":63950,"user_name":"alias cd=rm -rf","can_delete":false,"product_type":"c1","uid":1318325,"ip_address":"","ucode":"E7B27D76305B75","user_header":"https://static001.geekbang.org/account/avatar/00/14/1d/b5/971261fd.jpg","comment_is_top":false,"comment_ctime":1548609101,"is_pvip":false,"replies":[{"id":"22632","content":"每个事务在提交过程的prepare阶段，会把redolog持久化； “当前事务的redolog持久化后prepare状态么”这个描述还是不清楚，你用事务A、事务B这样来描述吧😆<br><br>redolog已经被持久化到磁盘了，那么当前事务提交时候，<br>（其实这里只是“部分”被持久化，因为这个事务自己在执行的过程中，还会产生新的日志），只需要继续持久化剩下的redo log","user_name":"作者回复","comment_id":63950,"uid":"1264162","ip_address":"","utype":1,"ctime":1548637167,"user_name_real":"林晓斌"}],"discussion_count":3,"race_medal":0,"score":"35908347469","product_id":100020801,"comment_content":"老师不好意思，我接着刚才的问题问哈<br>并发事务的redolog持久化，会把当前事务的redolog持久化，当前事务的redolog持久化后prepare状态么？redolog已经被持久化到磁盘了，那么当前事务提交时候，redolog变为prepare状态，这时候是从redologbuffer加载还是从磁盘加载？","like_count":9,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":437778,"discussion_content":"每个事务在提交过程的prepare阶段，会把redolog持久化； “当前事务的redolog持久化后prepare状态么”这个描述还是不清楚，你用事务A、事务B这样来描述吧😆\n\nredolog已经被持久化到磁盘了，那么当前事务提交时候，\n（其实这里只是“部分”被持久化，因为这个事务自己在执行的过程中，还会产生新的日志），只需要继续持久化剩下的redo log","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1548637167,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2166073,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/k3YD3y3BzGDSdrwRJyJY4BXsNJibfM4uzOdDVKIAlFApR2FZCLg2ibrZtJ4vuahA3LHLW9GKzH5CMGqCDhWjhZqg/132","nickname":"戒酒的李白","note":"","ucode":"744E1A22761647","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":406756,"discussion_content":"redolog不连续也没关系吗","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1634828282,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2797976,"avatar":"","nickname":"Geek_323a60","note":"","ucode":"CDC276EC255411","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":585348,"discussion_content":"小学没毕业吗？这病句写的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1661496305,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"四川"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":57912,"user_name":"Geek_527020","can_delete":false,"product_type":"c1","uid":1097150,"ip_address":"","ucode":"4DAAC586AB1563","user_header":"https://static001.geekbang.org/account/avatar/00/10/bd/be/53350286.jpg","comment_is_top":false,"comment_ctime":1546939265,"is_pvip":false,"replies":[{"id":"20885","content":"没事，这些操作没提交，崩溃恢复的时候就回滚了","user_name":"作者回复","comment_id":57912,"uid":"1264162","ip_address":"","utype":1,"ctime":1546950144,"user_name_real":"林晓斌"}],"discussion_count":4,"race_medal":0,"score":"35906677633","product_id":100020801,"comment_content":"事务还未结束，binlog和redo log就写到磁盘中了，如果出现了事务回滚，写到磁盘的数据要删除吗，如果不删除，MYSQL奔溃重启，岂不是多了操作，请老师解答下疑惑","like_count":9,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435826,"discussion_content":"没事，这些操作没提交，崩溃恢复的时候就回滚了","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1546950144,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2287841,"avatar":"https://static001.geekbang.org/account/avatar/00/22/e8/e1/6045b299.jpg","nickname":"LPF","note":"","ucode":"036C552D7251E9","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":331547,"discussion_content":"老师没给你回答清楚，的确redolog的数据可能持久化到磁盘，但是没有commit是不执行的，即不会对mysql有影响，你就当垃圾数据吧。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1606897840,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":2147472,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLbM6ZwjHTUuMNI1gIib8ZQTaljbnh1GxEE7RhffyO3SE5ibhh2fWwG1xkyb1XNnYzUhe5b2zaFYy8g/132","nickname":"Geek_8226bc","note":"","ucode":"9F67898DAC2223","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2287841,"avatar":"https://static001.geekbang.org/account/avatar/00/22/e8/e1/6045b299.jpg","nickname":"LPF","note":"","ucode":"036C552D7251E9","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":394683,"discussion_content":"那就是没有回滚redolog的意思了？只是在刷redolog不会刷prepare状态的？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1631978797,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":331547,"ip_address":""},"score":394683,"extra":""}]},{"author":{"id":2945508,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/kTIwKz8eeicPsWibiavOkCnhfys2HkhLFmNKN7hV3ax1GNsjs8Ss2BlH0ekelxFibZz4C3cy1R1YcEMopJhXCghqyQ/132","nickname":"Geek_c22ad7","note":"","ucode":"6A3ACF366C02CC","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":556986,"discussion_content":"写磁盘了但是没有commit标识，是无效的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1647595091,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":57161,"user_name":"Justin","can_delete":false,"product_type":"c1","uid":1305601,"ip_address":"","ucode":"D49723FEA66731","user_header":"https://static001.geekbang.org/account/avatar/00/13/ec/01/978d54af.jpg","comment_is_top":false,"comment_ctime":1546667621,"is_pvip":false,"replies":[{"id":"20611","content":"对的，lsn 就是写在数据页的<br>i","user_name":"作者回复","comment_id":57161,"uid":"1264162","ip_address":"","utype":1,"ctime":1546669816,"user_name_real":"林晓斌"}],"discussion_count":1,"race_medal":0,"score":"35906405989","product_id":100020801,"comment_content":"您说的Lsn 确保不会二次执行 意思是持久化在磁盘中的页也有和redo log record相关的lsn吗 然后根据lsn的大小在recovery阶段确定redo log需不需要执行？","like_count":9,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435437,"discussion_content":"对的，lsn 就是写在数据页的\ni","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1546669816,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":56789,"user_name":"慧鑫coming","can_delete":false,"product_type":"c1","uid":1324385,"ip_address":"","ucode":"7BAC9CA255630E","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLE4LYb3jrH63ZV98Zpc8DompwDgb1O3nffMoZCmiaibauRyEFv6NDNsST9RWxZExvMLMWb50zaanoQ/132","comment_is_top":false,"comment_ctime":1546562087,"is_pvip":false,"replies":[{"id":"20470","content":"是的是的哦<br><br>最好就是机器Io特别好，不用改最好了。实在要改就尽量选风险小的","user_name":"作者回复","comment_id":56789,"uid":"1264162","ip_address":"","utype":1,"ctime":1546564427,"user_name_real":"林晓斌"}],"discussion_count":1,"race_medal":0,"score":"31611333159","product_id":100020801,"comment_content":"这里提示和我一样的小白，注意老师最后的说的提升io性能方法3，是在主机掉电或os崩溃的时候，page cache 会丢失;而最后老师建议将redo log写到page cash，说的是能防止“MySQL异常重启时数据丢失”。也就是仅仅写数据的程序crash，那么已经写入page cash中的数据不会丢失，但如果系统crash或者重启的话，那就没办法啦😆","like_count":7,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435237,"discussion_content":"是的是的哦\n\n最好就是机器Io特别好，不用改最好了。实在要改就尽量选风险小的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1546564427,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":56901,"user_name":"HuaMax","can_delete":false,"product_type":"c1","uid":1118488,"ip_address":"","ucode":"2E78DE1AF098AF","user_header":"https://static001.geekbang.org/account/avatar/00/11/11/18/8cee35f9.jpg","comment_is_top":false,"comment_ctime":1546574955,"is_pvip":false,"replies":[{"id":"20536","content":"是的，write是到page cache","user_name":"作者回复","comment_id":56901,"uid":"1264162","ip_address":"","utype":1,"ctime":1546577669,"user_name_real":"林晓斌"}],"discussion_count":1,"race_medal":0,"score":"27316378731","product_id":100020801,"comment_content":"老师在解释组提交的原理那里的图中第二步应该是binlog cache写入到系统page cache的意思吧？","like_count":6,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435304,"discussion_content":"是的，write是到page cache","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1546577669,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":56813,"user_name":"往事随风，顺其自然","can_delete":false,"product_type":"c1","uid":1235692,"ip_address":"","ucode":"F266EC6B143E38","user_header":"https://static001.geekbang.org/account/avatar/00/12/da/ec/779c1a78.jpg","comment_is_top":false,"comment_ctime":1546563469,"is_pvip":false,"replies":[{"id":"21083","content":"Page cache是在文件系统的内存，还没持久化","user_name":"作者回复","comment_id":56813,"uid":"1264162","ip_address":"","utype":1,"ctime":1547100971,"user_name_real":"林晓斌"}],"discussion_count":1,"race_medal":0,"score":"27316367245","product_id":100020801,"comment_content":"binlog cache 和page cache 有啥区别，一个在内存一个在磁盘，page cache 不是已经在磁盘？","like_count":6,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435250,"discussion_content":"Page cache是在文件系统的内存，还没持久化","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1547100971,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":93673,"user_name":"莫名","can_delete":false,"product_type":"c1","uid":1487905,"ip_address":"","ucode":"852C2321C45EE3","user_header":"https://static001.geekbang.org/account/avatar/00/16/b4/21/17a88779.jpg","comment_is_top":false,"comment_ctime":1557556727,"is_pvip":false,"replies":[{"id":"34899","content":"是的<br><br>所以我们说，如果要保证数据不丢，就要设置=1","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1558709897,"ip_address":"","comment_id":93673,"utype":1}],"discussion_count":1,"race_medal":0,"score":"23032393207","product_id":100020801,"comment_content":"老师，sync_binlog=N，N之间客户端已明确收到事务提交，而如果期间机器崩溃或掉电，重启会导致数据库数据也丢失或回滚，那不是客户端处理的数据可能也会有问题？比如账户类数据、银行转账等？望解惑！","like_count":6,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":449726,"discussion_content":"是的\n\n所以我们说，如果要保证数据不丢，就要设置=1","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1558709897,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":63633,"user_name":"嘻嘻","can_delete":false,"product_type":"c1","uid":1063149,"ip_address":"","ucode":"C47140EF144225","user_header":"https://static001.geekbang.org/account/avatar/00/10/38/ed/72f73710.jpg","comment_is_top":false,"comment_ctime":1548424912,"is_pvip":false,"replies":[{"id":"22501","content":"第一个问题没看懂。<br><br>“如果写完page cache就返回也没有持久化吧”， 是的，<br><br>“客户端收到事务成功的消息，事务就一定持久化了”是建立在双1基础上的。","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1548433849,"ip_address":"","comment_id":63633,"utype":1}],"discussion_count":1,"race_medal":0,"score":"23023261392","product_id":100020801,"comment_content":"1. 如果客户端收到事务成功的消息，事务就一定持久化了；<br>commit是在什么阶段返回的？如果写完page cache就返回也没有持久化吧？","like_count":5,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":437662,"discussion_content":"第一个问题没看懂。\n\n“如果写完page cache就返回也没有持久化吧”， 是的，\n\n“客户端收到事务成功的消息，事务就一定持久化了”是建立在双1基础上的。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1548433849,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":57506,"user_name":"慧鑫coming","can_delete":false,"product_type":"c1","uid":1324385,"ip_address":"","ucode":"7BAC9CA255630E","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLE4LYb3jrH63ZV98Zpc8DompwDgb1O3nffMoZCmiaibauRyEFv6NDNsST9RWxZExvMLMWb50zaanoQ/132","comment_is_top":false,"comment_ctime":1546824372,"is_pvip":false,"replies":[{"id":"20725","content":"这样就是每10次fsync一下(sync_no_delay_count &gt;sync_binlog)","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1546827713,"ip_address":"","comment_id":57506,"utype":1}],"discussion_count":1,"race_medal":0,"score":"23021660852","product_id":100020801,"comment_content":"老师，请问binlog_group_commit_sync_no_delay_count和sync_binlog参数有什么区别，前者设置为10后者设置为5，那是几次write page_cache才写盘一次？","like_count":5,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435613,"discussion_content":"这样就是每10次fsync一下(sync_no_delay_count &amp;gt;sync_binlog)","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1546827713,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":124320,"user_name":"一只羊","can_delete":false,"product_type":"c1","uid":1303375,"ip_address":"","ucode":"6A3ADF7DA30DA3","user_header":"https://static001.geekbang.org/account/avatar/00/13/e3/4f/4709b019.jpg","comment_is_top":false,"comment_ctime":1565860005,"is_pvip":false,"replies":[{"id":"45668","content":"记录数据就是先写内存，然后写日志（redo和binlog），后台会有机会将内存的数据写到数据盘","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1565879978,"ip_address":"","comment_id":124320,"utype":1}],"discussion_count":2,"race_medal":0,"score":"18745729189","product_id":100020801,"comment_content":"也不知道还会不会有问题解答，试试。<br><br>我的问题是：现在知道 redo log 和 binlog 的落盘时机。但是我不知道记录数据是在什么时候、什么方式落盘的。<br>不知道还有机会得到解答不。","like_count":4,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":463115,"discussion_content":"记录数据就是先写内存，然后写日志（redo和binlog），后台会有机会将内存的数据写到数据盘","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1565879978,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2355521,"avatar":"https://static001.geekbang.org/account/avatar/00/23/f1/41/76c0758f.jpg","nickname":"君战","note":"","ucode":"A8619A79A5CED9","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":365374,"discussion_content":"前面讲过什么时候将脏页刷到磁盘：1、redo log写满了（要推进checkpoint，把对应的脏页刷盘）；2、内存满了（要淘汰数据页，如果数据页是脏页要先将脏页刷盘）；3、系统空闲的时候；4、mysql正常关闭的时候。","likes_number":2,"is_delete":false,"is_hidden":false,"ctime":1617784818,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":63076,"user_name":"J!","can_delete":false,"product_type":"c1","uid":1305003,"ip_address":"","ucode":"71C946119B59D1","user_header":"https://static001.geekbang.org/account/avatar/00/13/e9/ab/37903736.jpg","comment_is_top":false,"comment_ctime":1548245618,"is_pvip":false,"replies":[{"id":"22353","content":"不会的，大家分头写，然后一起持久化到磁盘","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1548257729,"ip_address":"","comment_id":63076,"utype":1}],"discussion_count":4,"race_medal":0,"score":"18728114802","product_id":100020801,"comment_content":"共同写一个binlog文件，这个过程应该需要锁来维持提交的时序吧，写文件的时候是不是可能会变成瓶颈点？","like_count":4,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":437459,"discussion_content":"不会的，大家分头写，然后一起持久化到磁盘","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1548257729,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1336951,"avatar":"https://static001.geekbang.org/account/avatar/00/14/66/77/194ba21d.jpg","nickname":"lzh","note":"","ucode":"C3D83DF4230109","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":10966,"discussion_content":"binlog buffer和binlog file间还隔着一个page cache呢","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1568345054,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1517390,"avatar":"https://static001.geekbang.org/account/avatar/00/17/27/4e/cfc94866.jpg","nickname":"鱼塘局码农","note":"","ucode":"D265DB38AC5EA0","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":387219,"discussion_content":"操作的数据有交集的话，行锁会阻塞维持顺序，操作不同数据，顺序无所谓的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1628059549,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1526355,"avatar":"https://static001.geekbang.org/account/avatar/00/17/4a/53/063f9d17.jpg","nickname":"moonfox","note":"","ucode":"902BFF40EFA9FA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":331367,"discussion_content":"同问，谁来保证顺序呀","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606835776,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":57805,"user_name":"Mr.Strive.Z.H.L","can_delete":false,"product_type":"c1","uid":1030198,"ip_address":"","ucode":"6D97E159E2EECD","user_header":"https://static001.geekbang.org/account/avatar/00/0f/b8/36/542c96bf.jpg","comment_is_top":false,"comment_ctime":1546914334,"is_pvip":false,"replies":[{"id":"21110","content":"1. 默认行为是opt_binlog_order_commits=ON，是保证顺序的；<br><br>2. 就是一个线程按顺序一个阶段一个阶段地调用下来，这么保证顺序的","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1547118226,"ip_address":"","comment_id":57805,"utype":1}],"discussion_count":1,"race_medal":0,"score":"18726783518","product_id":100020801,"comment_content":"老师好，关于组提交还是有几个疑惑：<br>我理解的，组提交分为binlog和redolog。<br>binlog如果没有组提交的话，是不是涉及到 写binlog的顺序与写redolog的顺序不一致的问题？这个顺序问题需要加锁来解决，事务之间串行执行prepare到commit的过程。<br>而binlog有了组提交，内部实际上通过队列的机制，既保证了组提交减少IOPS消耗，同时队列的机制保证了binlog和redolog写入的顺序性。<br><br>上述这么理解正确吗？<br><br>还有一个问题就是图5两阶段提交细化的过程：<br>binlog的write 到 sync之间插入了 redolog的 sync。图上的顺序表示binlog的sync必须等到redolog的sync执行后才能执行？ redolog在引擎内部，binlog在server端，这个串行是如何保证的？？（因为我认为server与innodb只会交互两次呀，第一次是prepare请求，第二次是最后的commit请求，binlog怎么做到等待redolog sync完后再sync？）","like_count":4,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435768,"discussion_content":"1. 默认行为是opt_binlog_order_commits=ON，是保证顺序的；\n\n2. 就是一个线程按顺序一个阶段一个阶段地调用下来，这么保证顺序的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1547118226,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":56821,"user_name":"往事随风，顺其自然","can_delete":false,"product_type":"c1","uid":1235692,"ip_address":"","ucode":"F266EC6B143E38","user_header":"https://static001.geekbang.org/account/avatar/00/12/da/ec/779c1a78.jpg","comment_is_top":false,"comment_ctime":1546564473,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"18726433657","product_id":100020801,"comment_content":"redolog 里面有已经提交事物日志，还有未提交事物日志都持久化到磁盘，此时异常重启，binlog 里面不是多余记录的未提交事物，干嘛不设计不添加未提交事物不更好","like_count":4},{"had_liked":false,"id":290826,"user_name":"NotFoundMoneyException:¥0","can_delete":false,"product_type":"c1","uid":2596556,"ip_address":"","ucode":"D454002955D09C","user_header":"https://static001.geekbang.org/account/avatar/00/27/9e/cc/1d57f923.jpg","comment_is_top":false,"comment_ctime":1619771748,"is_pvip":false,"discussion_count":3,"race_medal":0,"score":"14504673636","product_id":100020801,"comment_content":"老师，redo log在刷盘的时候把未提交的事务A也刷盘。<br>1、那么事务A真正刷盘的时候，日志是怎么在文件存放的。是直接追加，还是找到对应的事务日志上修改？<br>2、在刷脏页的时候把redo log的checkpoint往前推到超过A事务日志（此时还没提交）的位置，那么新落盘的redo log会把事务A的日志给覆盖掉，A事务日志提交后，然后宕机，恢复的时候A事务的数据会不会丢？","like_count":3,"discussions":[{"author":{"id":1261530,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKDKsicmpne7xQNocwRQ80DDZ3CzjsDoVIcH0SBiaYzS056oVOx4pEeEVeCaXE3QtsjUIEI0x1xQVTw/132","nickname":"muggle","note":"","ucode":"D78087BCAD0860","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":535390,"discussion_content":"同样对第一个问题感到困惑。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1638424876,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2680957,"avatar":"","nickname":"Geek_dbf688","note":"","ucode":"B9E078909700C3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":381712,"discussion_content":"问题1我觉得如果是追加的话，那之前组提交先刷盘又有什么意义呢，反正后面也要再走一次\n问题2我也有疑问，譬如如果一个长事务，一直不提交，部分redo log已经通过组提交持久化了，那么循环写的时候，肯定不是直接覆盖吧，不然就丢失了，，那究竟是怎么处理的？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1625192374,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1526355,"avatar":"https://static001.geekbang.org/account/avatar/00/17/4a/53/063f9d17.jpg","nickname":"moonfox","note":"","ucode":"902BFF40EFA9FA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":2680957,"avatar":"","nickname":"Geek_dbf688","note":"","ucode":"B9E078909700C3","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":544567,"discussion_content":"同问，如果你知道了答案，还请告诉我一下呀，感谢呀","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1641568000,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":381712,"ip_address":""},"score":544567,"extra":""}]}]},{"had_liked":false,"id":117564,"user_name":"沙漠里的骆驼","can_delete":false,"product_type":"c1","uid":1012559,"ip_address":"","ucode":"5EC18A71B3A594","user_header":"https://static001.geekbang.org/account/avatar/00/0f/73/4f/abb7bfe3.jpg","comment_is_top":false,"comment_ctime":1564094439,"is_pvip":true,"discussion_count":2,"race_medal":0,"score":"14448996327","product_id":100020801,"comment_content":"请教下，两阶段提交细化里面，redolog的fsync这一步是持久化落磁盘，我理解应该是最耗时的，为什么你反而说这一步非常快呢？","like_count":3,"discussions":[{"author":{"id":1314724,"avatar":"https://static001.geekbang.org/account/avatar/00/14/0f/a4/0b49469f.jpg","nickname":"木子00","note":"","ucode":"8F78CA722EB29B","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":310342,"discussion_content":"redo log 是顺序写，比随机写快。","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1601786095,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2166073,"avatar":"https://thirdwx.qlogo.cn/mmopen/vi_32/k3YD3y3BzGDSdrwRJyJY4BXsNJibfM4uzOdDVKIAlFApR2FZCLg2ibrZtJ4vuahA3LHLW9GKzH5CMGqCDhWjhZqg/132","nickname":"戒酒的李白","note":"","ucode":"744E1A22761647","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":406772,"discussion_content":"redolog只是记录对数据页的修改，没有完整的row数据，所以和binlog相比肯定小很多，故写起来快","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1634829131,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":99769,"user_name":"Tunayoyo","can_delete":false,"product_type":"c1","uid":1447213,"ip_address":"","ucode":"E77AFDE575CE04","user_header":"https://static001.geekbang.org/account/avatar/00/16/15/2d/8447e8c8.jpg","comment_is_top":false,"comment_ctime":1559294940,"is_pvip":false,"discussion_count":3,"race_medal":0,"score":"14444196828","product_id":100020801,"comment_content":"老师您好，innodb_flush_log_at_trx_commit设置和后台线程的刷盘操作的关系是啥？<br>","like_count":3,"discussions":[{"author":{"id":1232273,"avatar":"https://static001.geekbang.org/account/avatar/00/12/cd/91/3d6c53f8.jpg","nickname":"Nash.Z","note":"","ucode":"76B14722664402","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":6469,"discussion_content":"同问，看上边没写清楚，难道不管innodb_flush_log_at_trx_commit参数设置成什么，后台线程每秒都会刷盘一次吗？","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1566914330,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1336009,"avatar":"https://static001.geekbang.org/account/avatar/00/14/62/c9/7da27891.jpg","nickname":"DKSky","note":"","ucode":"69371A81033949","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1232273,"avatar":"https://static001.geekbang.org/account/avatar/00/12/cd/91/3d6c53f8.jpg","nickname":"Nash.Z","note":"","ucode":"76B14722664402","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":54176,"discussion_content":"我理解是的，这两个之间没有关系","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1574264305,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":6469,"ip_address":""},"score":54176,"extra":""}]},{"author":{"id":1035562,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/cd/2a/bdbed6ed.jpg","nickname":"无菇朋友","note":"","ucode":"80482C5F0464A3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":49113,"discussion_content":"应该是这样，当设置为0时，事务提交不会触发redo-log-buffer的write操作，而是留给后台线程每秒一次的刷盘操作，因此实例crash将最多丢失1秒钟内的事务。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1573556292,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":65034,"user_name":"miu","can_delete":false,"product_type":"c1","uid":1368901,"ip_address":"","ucode":"3D73FF3C09231A","user_header":"","comment_is_top":false,"comment_ctime":1549008251,"is_pvip":false,"replies":[{"id":"23187","content":"这两个逻辑不建议放到一起算<br>就是按照这样：<br>1. 有设置 BINLOG_GROUP_COMMIT_SYNC_NO_DELAY_COUNT这个值，（假设SYNC_DELAY很大），提交的时候就得等这么多次才能过；<br>2. 到了提交阶段，又要按照sync_binlog来判断是否刷盘。<br><br><br>新春快乐~","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1549270703,"ip_address":"","comment_id":65034,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14433910139","product_id":100020801,"comment_content":"老师，关于BINLOG_GROUP_COMMIT_SYNC_DELAY，<br>BINLOG_GROUP_COMMIT_SYNC_NO_DELAY_COUNT，<br>SYNC_BINLOG三个参数，我的理解是：<br>若SYNC_BINLOG&gt;1时，且设置了BINLOG_GROUP_COMMIT_SYNC_DELAY和BINLOG_GROUP_COMMIT_SYNC_NO_DELAY_COUNT两个参数。<br>例如 <br>sync_binlog=2，<br>BINLOG_GROUP_COMMIT_SYNC_DELAY=1000000，<br>BINLOG_GROUP_COMMIT_SYNC_NO_DELAY_COUNT=3，<br>那么在执行完第1个事务后，在第2个事务提交时，会根据后续的事务提交来判断fsync等待的时间，<br>若后续在1秒内没有累积3个事务的提交，则会等待1秒后再做fsync，从SQL语句来看，执行第一个语句很快，第二个语句需要等待1秒才成功。这时延时等待的时间是BINLOG_GROUP_COMMIT_SYNC_DELAY所设置的值。<br>若执行完第1个事务后，并行执行3个事务（1秒内完成），则后续3个事务会同时做fsync，这时延时等待的时间是BINLOG_GROUP_COMMIT_SYNC_NO_DELAY_COUNT设置的数量的事务提交的间隔时间。<br>也就是sync_binlog+BINLOG_GROUP_COMMIT_SYNC_NO_DELAY_COUNT-1 个事务做一次fsync。<br>我测试的版本是MySQL官方5.7.24，请老师点评。<br><br>","like_count":3,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":438287,"discussion_content":"这两个逻辑不建议放到一起算\n就是按照这样：\n1. 有设置 BINLOG_GROUP_COMMIT_SYNC_NO_DELAY_COUNT这个值，（假设SYNC_DELAY很大），提交的时候就得等这么多次才能过；\n2. 到了提交阶段，又要按照sync_binlog来判断是否刷盘。\n\n\n新春快乐~","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1549270703,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":63571,"user_name":"Geek_527020","can_delete":false,"product_type":"c1","uid":1097150,"ip_address":"","ucode":"4DAAC586AB1563","user_header":"https://static001.geekbang.org/account/avatar/00/10/bd/be/53350286.jpg","comment_is_top":false,"comment_ctime":1548403654,"is_pvip":false,"replies":[{"id":"22495","content":"不会啊，有MVCC的， 08篇再看下<br>","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1548413578,"ip_address":"","comment_id":63571,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14433305542","product_id":100020801,"comment_content":"您好，老师，我有一个以后，组提交，把为提交事务的redo log写入磁盘，如果有查询，岂不是查到未提交事务的更新内容了?","like_count":3,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":437641,"discussion_content":"不会啊，有MVCC的， 08篇再看下\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1548413578,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":58547,"user_name":"roaming","can_delete":false,"product_type":"c1","uid":1039232,"ip_address":"","ucode":"2736679690AB81","user_header":"https://static001.geekbang.org/account/avatar/00/0f/db/80/6b7629d7.jpg","comment_is_top":false,"comment_ctime":1547111021,"is_pvip":false,"replies":[{"id":"21179","content":"👍","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1547134531,"ip_address":"","comment_id":58547,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14432012909","product_id":100020801,"comment_content":"看了几遍，终于看明白了","like_count":3,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":436114,"discussion_content":"👍","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1547134531,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":57162,"user_name":"way","can_delete":false,"product_type":"c1","uid":1302713,"ip_address":"","ucode":"AD1CBEBA5FDBA9","user_header":"https://static001.geekbang.org/account/avatar/00/13/e0/b9/bca7ff9a.jpg","comment_is_top":false,"comment_ctime":1546668602,"is_pvip":false,"replies":[{"id":"20629","content":"额，这个是错误使用参数的好例子😄","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1546678714,"ip_address":"","comment_id":57162,"utype":1}],"discussion_count":1,"race_medal":0,"score":"14431570490","product_id":100020801,"comment_content":"老师新年好。之前遇到个有意思的现象。主从切换以后。从库延迟一直追不上。查下来是组提交的两个参数有设置。都调整为0以后，很快就追上了。","like_count":3,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435438,"discussion_content":"额，这个是错误使用参数的好例子😄","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1546678714,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":293101,"user_name":"张三丰","can_delete":false,"product_type":"c1","uid":1155275,"ip_address":"","ucode":"3A6215A40B3B21","user_header":"https://static001.geekbang.org/account/avatar/00/11/a0/cb/aab3b3e7.jpg","comment_is_top":false,"comment_ctime":1621217333,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"10211151925","product_id":100020801,"comment_content":"如果组提交的时候，未提交的事务被动落盘，而恰好这个被动提交事务又回滚了，这个时候这个未提交事务会从磁盘中删除么？","like_count":2,"discussions":[{"author":{"id":2680957,"avatar":"","nickname":"Geek_dbf688","note":"","ucode":"B9E078909700C3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":381710,"discussion_content":"同问","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1625192132,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":154280,"user_name":"jian","can_delete":false,"product_type":"c1","uid":1185102,"ip_address":"","ucode":"21CDBBB8000F0C","user_header":"https://static001.geekbang.org/account/avatar/00/12/15/4e/4636a81d.jpg","comment_is_top":false,"comment_ctime":1574403234,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"10164337826","product_id":100020801,"comment_content":"老师，你在文章中两个地方说到redo log的fsync操作。<br>第一个地方是图2说“日志写到 redo log buffer 是很快的，wirte 到 page cache 也差不多，但是持久化到磁盘的速度就慢多了”。我理解redo log的fsync操作涉及磁盘IO，会比较慢。<br>第二个地方在图5说“不过通常情况下第 3 步执行得会很快，所以 binlog 的 write 和 fsync 间的间隔时间短，导致能集合到一起持久化的 binlog 比较少，因此 binlog 的组提交的效果通常不如 redo log的效果那么好。” 这里说第3步redo log的prepare操作sync会很快。<br><br>这两个地方是否一致呢？<br>","like_count":2},{"had_liked":false,"id":120249,"user_name":"钱","can_delete":false,"product_type":"c1","uid":1009652,"ip_address":"","ucode":"2C92A243A463D4","user_header":"https://static001.geekbang.org/account/avatar/00/0f/67/f4/9a1feb59.jpg","comment_is_top":false,"comment_ctime":1564815323,"is_pvip":false,"discussion_count":3,"race_medal":0,"score":"10154749915","product_id":100020801,"comment_content":"打卡，假如写磁盘的速度和写内存一样，编程的世界我想会简单很多。","like_count":2,"discussions":[{"author":{"id":1032309,"avatar":"https://static001.geekbang.org/account/avatar/00/0f/c0/75/acc6ebef.jpg","nickname":"守拙","note":"","ucode":"44422C46F303EB","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":163221,"discussion_content":"不，还会有缓存；局部性永远存储；知识尺度的差异。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1581062049,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1243369,"avatar":"https://static001.geekbang.org/account/avatar/00/12/f8/e9/f16a536b.jpg","nickname":"极客-绝影","note":"","ucode":"D302CE68123E74","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":128530,"discussion_content":"假如重启内存数据也会不会丢失或重新载入，这个解决现在就可以用内存替换硬盘","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1578647863,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":1,"child_discussions":[{"author":{"id":1305538,"avatar":"https://static001.geekbang.org/account/avatar/00/13/eb/c2/90a701ea.jpg","nickname":"littleneko","note":"","ucode":"894F15B2D9A824","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":1243369,"avatar":"https://static001.geekbang.org/account/avatar/00/12/f8/e9/f16a536b.jpg","nickname":"极客-绝影","note":"","ucode":"D302CE68123E74","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":235856,"discussion_content":"NVM了解一下，虽然达不到内存的速度，但是现在已经有一些玩法了","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1587049777,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":128530,"ip_address":""},"score":235856,"extra":""}]}]},{"had_liked":false,"id":99752,"user_name":"Tunayoyo","can_delete":false,"product_type":"c1","uid":1447213,"ip_address":"","ucode":"E77AFDE575CE04","user_header":"https://static001.geekbang.org/account/avatar/00/16/15/2d/8447e8c8.jpg","comment_is_top":false,"comment_ctime":1559291979,"is_pvip":false,"replies":[{"id":"37467","content":"redo log不需要“顺序”持久化的","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1560473202,"ip_address":"","comment_id":99752,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10149226571","product_id":100020801,"comment_content":"是不是说并行的事务，都在提交，redo log就不能被顺带持久化?","like_count":2,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":452254,"discussion_content":"redo log不需要“顺序”持久化的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1560473202,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":63929,"user_name":"alias cd=rm -rf","can_delete":false,"product_type":"c1","uid":1318325,"ip_address":"","ucode":"E7B27D76305B75","user_header":"https://static001.geekbang.org/account/avatar/00/14/1d/b5/971261fd.jpg","comment_is_top":false,"comment_ctime":1548599650,"is_pvip":false,"replies":[{"id":"22607","content":"1. “这时候磁盘中的redolog的状态是什么状态呢？是prepare么？”这个“这时候”是什么意思😆<br>2. 还在，不过随时可以被覆盖","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1548608597,"ip_address":"","comment_id":63929,"utype":1}],"discussion_count":2,"race_medal":0,"score":"10138534242","product_id":100020801,"comment_content":"您好，我看文章后有俩点疑问，前提条件如果mysql设置双1<br><br>1、这时候磁盘中的redolog的状态是什么状态呢？是prepare么？<br>2、如果一个事务在进行中的时候redolog已经被持久化，在事务提交时候，这条redolog还在redolog-buffer中么？","like_count":2,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":437768,"discussion_content":"1. “这时候磁盘中的redolog的状态是什么状态呢？是prepare么？”这个“这时候”是什么意思😆\n2. 还在，不过随时可以被覆盖","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1548608597,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1226968,"avatar":"https://static001.geekbang.org/account/avatar/00/12/b8/d8/f81b5604.jpg","nickname":"hcyycb","note":"","ucode":"77FF6CA41F9E66","race_medal":0,"user_type":1,"is_pvip":true},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":409875,"discussion_content":"不存在这种情况。事务提交，redolog开始两阶段。其实，这时候log里的记录都是已经提交的事务完成的。redolog要分两阶段，和binlog配合，可以保证mysql的crash-safe。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1635522635,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":61960,"user_name":"菜菜","can_delete":false,"product_type":"c1","uid":1302241,"ip_address":"","ucode":"D798B831A89AAF","user_header":"https://static001.geekbang.org/account/avatar/00/13/de/e1/f648c746.jpg","comment_is_top":false,"comment_ctime":1547867024,"is_pvip":false,"replies":[{"id":"21957","content":"max_binlog_cache_size只是用来限制设置binlog_cache_size的时候的上限😅<br>并不参与执行语句的逻辑的","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1547869497,"ip_address":"","comment_id":61960,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10137801616","product_id":100020801,"comment_content":"林老师，你好！超过了binlog_cache_size，暂存到磁盘，那如果超过了max_binlog_cache_size 就直接报错了呢，这两个参数的关联是什么呢？","like_count":2,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":437049,"discussion_content":"max_binlog_cache_size只是用来限制设置binlog_cache_size的时候的上限😅\n并不参与执行语句的逻辑的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1547869497,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":57252,"user_name":"信信","can_delete":false,"product_type":"c1","uid":1303865,"ip_address":"","ucode":"8DF0EC045579FD","user_header":"https://static001.geekbang.org/account/avatar/00/13/e5/39/951f89c8.jpg","comment_is_top":false,"comment_ctime":1546698481,"is_pvip":false,"replies":[{"id":"20668","content":"我们文章中介绍的已经是演进过的版本，已经保证了写盘顺序，没有这个问题了哈","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1546746811,"ip_address":"","comment_id":57252,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10136633073","product_id":100020801,"comment_content":"网上说binlog的写入顺序需要和InnoDB层事务提交顺序一致，否则通过xtrabackup这种物理备份工具进行备份时，会出现主备不一致。分析原因五花八门，感觉都不够准备，请老师指点。","like_count":2,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435488,"discussion_content":"我们文章中介绍的已经是演进过的版本，已经保证了写盘顺序，没有这个问题了哈","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1546746811,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":57196,"user_name":"Justin","can_delete":false,"product_type":"c1","uid":1305601,"ip_address":"","ucode":"D49723FEA66731","user_header":"https://static001.geekbang.org/account/avatar/00/13/ec/01/978d54af.jpg","comment_is_top":false,"comment_ctime":1546680270,"is_pvip":false,"replies":[{"id":"20632","content":"1. 不是这么分的。 主键索引和普通索引都是由数据页组成；这些都有可能被缓存到bp里<br>2. 非聚簇索引页的修改。 主键索引不能使用change buffer哦","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1546690272,"ip_address":"","comment_id":57196,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10136614862","product_id":100020801,"comment_content":"想咨询一个问题，老师 我看bufferpool 分为数据页和索引页，那么主键索引不是包含行数据吗？那主键索引是在数据页还是索引页呢？ 还有 change buffer缓存的是对非聚簇索引页的修改(整行数据还是不缓存直接加到主键索引下)还是对具体行数据的添加或者修改呢？","like_count":2,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435457,"discussion_content":"1. 不是这么分的。 主键索引和普通索引都是由数据页组成；这些都有可能被缓存到bp里\n2. 非聚簇索引页的修改。 主键索引不能使用change buffer哦","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1546690272,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":57168,"user_name":"linqw","can_delete":false,"product_type":"c1","uid":1134138,"ip_address":"","ucode":"09DCFE98C54DD8","user_header":"https://static001.geekbang.org/account/avatar/00/11/4e/3a/86196508.jpg","comment_is_top":false,"comment_ctime":1546670692,"is_pvip":false,"replies":[{"id":"20636","content":"1. 额写一下没什么成本哦。被刷盘以后这个事务就彻底完成了呀。有这个commit标识，据说崩溃恢复也方便<br>2. 就是因为参数不认识，导致系统不启动的吧😄<br>3.对<br>4. 这个要看你怎么改的。（假设你用的是5.6及以上的版本）， 大改小要重做；小N改大M的话，如果NM都小于256不用，都大于256也不用；N&lt;256&lt;M 就要","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1546692277,"ip_address":"","comment_id":57168,"utype":1}],"discussion_count":1,"race_medal":0,"score":"10136605284","product_id":100020801,"comment_content":"老师打扰下，问几个问题哦<br>1、一次事务在提交前，redo log在prepare阶段就会刷盘，为什么在commit的时候，还需要write到文件系统的page cache中了？<br>2、有一次记得整个服务崩了，innodb_buffer_pool_size太小，修改了5.6 版的my.cnf文件那时多加了一句innodb_buffer_pool_chunk_size，这个好像在5.7之后新增的，导致mysqld.pid和mysqld.sock这两个文件没有生成，导致数据库服务报: Can&#39;t connect to local MySQL server through socket &#39;&#47;tmp&#47;mysql.sock&#39; (2)，那时将配置文件中的这行去掉，数据库才可以正常使用，其中的原理不是很清楚<br>3、rollback在commit之后立即执行，没有任何影响么？<br>4、varchar类型长度修改，varchar类型好像是没有存在聚簇索引中，若需要预留varchar类型字段，还无法确定实际需要的长度。而当需要启用到预留的字段时，表中可能已经有很多数据，此时要根据需要修改字段长度, 而不需要重做数据？","like_count":2,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435441,"discussion_content":"1. 额写一下没什么成本哦。被刷盘以后这个事务就彻底完成了呀。有这个commit标识，据说崩溃恢复也方便\n2. 就是因为参数不认识，导致系统不启动的吧😄\n3.对\n4. 这个要看你怎么改的。（假设你用的是5.6及以上的版本）， 大改小要重做；小N改大M的话，如果NM都小于256不用，都大于256也不用；N&amp;lt;256&amp;lt;M 就要","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1546692277,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":328343,"user_name":"大英雄不该去雪山打滚","can_delete":false,"product_type":"c1","uid":2867414,"ip_address":"","ucode":"8024FE2D5ED659","user_header":"https://static001.geekbang.org/account/avatar/00/2b/c0/d6/81b1b782.jpg","comment_is_top":false,"comment_ctime":1640677720,"is_pvip":false,"discussion_count":2,"race_medal":0,"score":"5935645016","product_id":100020801,"comment_content":"【1. 设置 binlog_group_commit_sync_delay和 binlog_group_commit_sync_no_delay_count参<br>数，减少binlog的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加<br>语句的响应时间，但没有丢失数据的风险。】为什么没有丢失数据的风险？我的理解是write了却没有fsync是类似于sync_binlog=N的，原文说这是可能会丢失N个事务的binlog日志的，不丢失数据是可以保证数据一致性的意思吗，望老师解答","like_count":1,"discussions":[{"author":{"id":1324550,"avatar":"https://static001.geekbang.org/account/avatar/00/14/36/06/08c46bcd.jpg","nickname":"聂利","note":"","ucode":"808E064089724D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":586795,"discussion_content":"个人理解， sync_bing 只是单纯的binlog 自己的刷盘策略，和relog 没有关系，\n设置innodb_flush_log_at_trx_commit=1，sync_binlog=N，relog 不丢，但是 binlog 会丢， 这个时候设置 binlog_group_commit_sync_no_delay_count=N，肯定也会丢binlog，丢不丢binlog数据是由sync_binlog来设置的，\n但是innodb_flush_log_at_trx_commit=1，sync_binlog=1，binlog_group_commit_sync_no_delay_count=N，这个时候是不会丢数据的，如果用户发出了commit的事务，delay_count=N，不仅同时控制了binlog组刷盘，还有redolog组刷盘的行为,延迟了binlog刷盘，同时也延迟了relog,这是binlog丢了，redlog也丢了，redo和binlog都是失败，事务失败回滚，但数据是一致的，就可以认为不丢数据。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1662519137,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1256203,"avatar":"https://static001.geekbang.org/account/avatar/00/13/2b/0b/3ed638ce.jpg","nickname":"rusk","note":"","ucode":"08709113CA30AD","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":542542,"discussion_content":"同问","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1640780421,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":276436,"user_name":"汉江","can_delete":false,"product_type":"c1","uid":1788647,"ip_address":"","ucode":"01622D984B8F9B","user_header":"https://static001.geekbang.org/account/avatar/00/1b/4a/e7/6c16af5d.jpg","comment_is_top":false,"comment_ctime":1611921744,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"5906889040","product_id":100020801,"comment_content":"mysql 刷脏页的时候，如果有未提交的数据，这时候这个数据能写入磁盘吗？","like_count":1,"discussions":[{"author":{"id":1324550,"avatar":"https://static001.geekbang.org/account/avatar/00/14/36/06/08c46bcd.jpg","nickname":"聂利","note":"","ucode":"808E064089724D","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":586797,"discussion_content":"没有提交的事务，也是要以刷脏的，比如一个大事务很大，不提交，当内存不够了，也可以触发一部分脏数据落盘","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1662519319,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"广东"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":252996,"user_name":"张卓","can_delete":false,"product_type":"c1","uid":1209049,"ip_address":"","ucode":"AD840AF264C32E","user_header":"https://static001.geekbang.org/account/avatar/00/12/72/d9/488739d1.jpg","comment_is_top":false,"comment_ctime":1602556978,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"5897524274","product_id":100020801,"comment_content":"老师好，有个疑问，文章中提到：<br>设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，减少 binlog 的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。<br><br>为什么没有丢失数据的风险？ 是设置了 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数后，要等到触发条件调用fsync之后才给客户端应答吗？也就是才算这个事务提交了？ <br>找了官方文档： Controls how many microseconds the binary log commit waits before synchronizing the binary log file to disk。<br>我理解事务提交后先在server层写binlog，等待group commit ，提交后就相当于commit可以给客户端应答处理成功，然后告诉引擎commit，写redo log commit。<br>我这个理解正确吗","like_count":1,"discussions":[{"author":{"id":2680957,"avatar":"","nickname":"Geek_dbf688","note":"","ucode":"B9E078909700C3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":381827,"discussion_content":"但是他又说“将sync_binlog 设置为大于1的值（比较常见是100~1000）。这样做的风险是，主机掉电时会丢binlog日志”，如果像你这么说没返回就不算丢，那这个也不算丢吧","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1625227103,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":240743,"user_name":"崔经刚","can_delete":false,"product_type":"c1","uid":1827943,"ip_address":"","ucode":"207FDF850860C4","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/P5lTnAkviacPGu5S5XJQGQdTpvkSjAVU9Nu2EYicIpMAjiaNP8aXDtfcIHicSnHw2fVIoqTWGGg48rZVzcficUlbgmw/132","comment_is_top":false,"comment_ctime":1597051042,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"5892018338","product_id":100020801,"comment_content":"老师，您好！有两个疑问，我在留言里面似乎没有找到答案。<br>1、关于图4<br>“1.先把binlog从binlog cache中写到磁盘上的binlog文件；”，这里是将binlog cache中的写到了page cache中，只不过这个页缓存名字叫系统binlog文件？<br>2、还有就是，关于提升IO性能瓶颈那里，“设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count参数，减少binlog的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。”<br>这里如果断电的话，也会有丢失数据的风险吧？","like_count":1,"discussions":[{"author":{"id":2680957,"avatar":"","nickname":"Geek_dbf688","note":"","ucode":"B9E078909700C3","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":381826,"discussion_content":"同问","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1625227010,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":224019,"user_name":"幼儿编程教学","can_delete":false,"product_type":"c1","uid":1237199,"ip_address":"","ucode":"F13F3150E6CAE9","user_header":"https://static001.geekbang.org/account/avatar/00/12/e0/cf/43f201f2.jpg","comment_is_top":false,"comment_ctime":1591256838,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5886224134","product_id":100020801,"comment_content":"老师，你好，请教个问题<br>日志逻辑序列号（log sequence number，LSN，我知道是8字节的，很大(‭16,777,216‬ TB)。<br>但想问一下，是否会出现用完的场景？如果出现了，会怎样？","like_count":1},{"had_liked":false,"id":159852,"user_name":"扬大宝","can_delete":false,"product_type":"c1","uid":1181888,"ip_address":"","ucode":"AC742196C894C8","user_header":"https://static001.geekbang.org/account/avatar/00/12/08/c0/9b97453f.jpg","comment_is_top":false,"comment_ctime":1575811100,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5870778396","product_id":100020801,"comment_content":"\b老师好，以下疑问没有查找到相关资料，麻烦老师可以解答下。innodb里的change buffer和flush list是一回事吗？如果不是的话 读数据时是merge flush list的还是change buffer的呢？以及是否有一个change buffer转化成flush list的过程呢？","like_count":1},{"had_liked":false,"id":126346,"user_name":"王斯拉","can_delete":false,"product_type":"c1","uid":1593957,"ip_address":"","ucode":"D00DD3CE432189","user_header":"https://static001.geekbang.org/account/avatar/00/18/52/65/320eccb3.jpg","comment_is_top":false,"comment_ctime":1566369194,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"5861336490","product_id":100020801,"comment_content":"现在留言不知道老师你能不能看到了，试试吧。<br>问题1：<br>没提交的事务A的redo log可能被持久化到磁盘上。那这个时候如果事务A回滚了，持久化的log怎么办呢？<br>有几个想法：<br>1. 擦磁盘？ 这样效率不会高吧，因为不是顺序操作。<br>2. 因为事务A的redo log没有commit，所以就当”脏“redo 放在磁盘里就好，即使这时候发生crash，也因为没有commit，甚至不是prepare 所以被忽略。<br>我更倾向于答案2，不知道具体是怎么样的。<br>问题2：<br>如果是2，那这个时候的LSN怎么办，比如这checkpoint刷脏时，脏页的LSN是100，但是这个redo的LSN是150，那是不是就错误了呢？","like_count":1,"discussions":[{"author":{"id":1707393,"avatar":"https://static001.geekbang.org/account/avatar/00/1a/0d/81/ed4957e8.jpg","nickname":"walzzz","note":"","ucode":"17D8079494189A","race_medal":1,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":381949,"discussion_content":"同问","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1625315959,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":81681,"user_name":"poplar","can_delete":false,"product_type":"c1","uid":1463444,"ip_address":"","ucode":"4D0ECC6AC87830","user_header":"","comment_is_top":false,"comment_ctime":1554005975,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"5848973271","product_id":100020801,"comment_content":"老师好，两阶段提交，redo log prepare阶段进行持久化，然后是binlog持久化，那么commit阶段做了什么，又是如何判断redo log已经是两阶段完成了呢","like_count":1,"discussions":[{"author":{"id":1065351,"avatar":"https://static001.geekbang.org/account/avatar/00/10/41/87/d26efb2e.jpg","nickname":"SuperSnow","note":"","ucode":"84C89AA8083E6A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":165033,"discussion_content":"如果是双1，那就是都进行了持久化。否则就不是。commit是将binlog cache写到binlog文件中，不做持久化操作。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1581250283,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":74775,"user_name":"kabuka","can_delete":false,"product_type":"c1","uid":1246009,"ip_address":"","ucode":"932DD1E875D850","user_header":"https://static001.geekbang.org/account/avatar/00/13/03/39/18956b2e.jpg","comment_is_top":false,"comment_ctime":1552296613,"is_pvip":false,"replies":[{"id":"27531","content":"page cache可以理解为操作系统维护的内存<br>fsync是写透到磁盘，会占用io，所以还是fsync占用资源高<br>","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1552407045,"ip_address":"","comment_id":74775,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5847263909","product_id":100020801,"comment_content":"寫入page cache 和 調用fsync  有什麼區別呀， 哪個會佔用IO，哪個消耗資源多一點？","like_count":1,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":442678,"discussion_content":"page cache可以理解为操作系统维护的内存\nfsync是写透到磁盘，会占用io，所以还是fsync占用资源高\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1552407045,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":73333,"user_name":"liao xueqiang","can_delete":false,"product_type":"c1","uid":1310325,"ip_address":"","ucode":"68713441579F6B","user_header":"https://static001.geekbang.org/account/avatar/00/13/fe/75/46742f12.jpg","comment_is_top":false,"comment_ctime":1551862570,"is_pvip":false,"replies":[{"id":"27157","content":"“这个fsync指把内存中的脏数据刷到datafile数据文件吗？”这里说的是redo log<br><br>单指&quot;commit的第二阶段，写redo log时不需要持久化到日志文件。“","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1552161217,"ip_address":"","comment_id":73333,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5846829866","product_id":100020801,"comment_content":"每秒一次后台轮询刷盘，再加上崩溃恢复这个逻辑，InnoDB 就认为 redo log 在 commit 的时候就不需要 fsync 了，只会 write 到文件系统的 page cache 中就够了。<br>这个fsync指把内存中的脏数据刷到datafile数据文件吗？redo log本来就是物理文件，如果是刷到redo log物理文件，那要是没刷成功，就是说物理文件没生成，那重启的话肯定会丢掉轮巡期间的这一秒数据","like_count":1,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":442029,"discussion_content":"“这个fsync指把内存中的脏数据刷到datafile数据文件吗？”这里说的是redo log\n\n单指&amp;quot;commit的第二阶段，写redo log时不需要持久化到日志文件。“","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1552161217,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":58553,"user_name":"猪哥哥","can_delete":false,"product_type":"c1","uid":1311362,"ip_address":"","ucode":"ACBB4556516D34","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLkhgYnYZBdhdwKnXQibey04cy9N9ria3DadH7iagoKukaWK1FJwjfCoh0He4p7b2icSYVzHH71l8ZXiaQ/132","comment_is_top":false,"comment_ctime":1547111692,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"5842078988","product_id":100020801,"comment_content":"老师好, 能说下innodb_log_buffer_size参数的作用吗","like_count":1},{"had_liked":false,"id":58205,"user_name":"匿名的朋友","can_delete":false,"product_type":"c1","uid":1316471,"ip_address":"","ucode":"D1A2A8E466FDD1","user_header":"https://static001.geekbang.org/account/avatar/00/14/16/77/73bd9d18.jpg","comment_is_top":false,"comment_ctime":1547009975,"is_pvip":false,"replies":[{"id":"20969","content":"1. 不用去找“所有innodb表”，用到再打开<br><br>2. 大家共用的<br>","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1547016480,"ip_address":"","comment_id":58205,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5841977271","product_id":100020801,"comment_content":"丁奇老师你好，对于undo和redo日志，有个疑问，mysql服务层调用引擎层去获取数据，比方说是innodb引擎，innodb引擎是不是可以获取到这个实例里边所有以innodb作为引擎的表，<br>  还有就是事务处理时会涉及到undo和redo日志文件，是不是所有以innodb为引擎的数据表共用undo和redo日志文件呢？","like_count":1,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435950,"discussion_content":"1. 不用去找“所有innodb表”，用到再打开\n\n2. 大家共用的\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1547016480,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":57781,"user_name":"月缺","can_delete":false,"product_type":"c1","uid":1362262,"ip_address":"","ucode":"029128BF847A9A","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0bvalmQic0PAVeoA8GEfoefV4xfmWY4UErdhxxxxNicibOK12icb7iaS07J3WoJGY1oMAKKDvT4w31nQ7buLdeoP8w/132","comment_is_top":false,"comment_ctime":1546910258,"is_pvip":false,"replies":[{"id":"20831","content":"不是，这个应该是最早的策略之一了","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1546917410,"ip_address":"","comment_id":57781,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5841877554","product_id":100020801,"comment_content":"事务还没提交的时候，redo log buffer 中的部分日志有可能被持久化到磁盘，这块是8.0重构redolog后的无锁化才有的新特性嘛，看源码之前是有个prepare commit mutex锁的","like_count":1,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435757,"discussion_content":"不是，这个应该是最早的策略之一了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1546917410,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":57270,"user_name":"慕塔","can_delete":false,"product_type":"c1","uid":1302106,"ip_address":"","ucode":"5C6C668C1106A5","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/A94RKUfWfwzRzb68T9xskctQ43TBgXSBIL78p0N0ria2tQxmsTTJebYmefhkbHK7zwpoxokxs43UxpgDTdwm5tg/132","comment_is_top":false,"comment_ctime":1546702652,"is_pvip":false,"replies":[{"id":"21102","content":"1. 一秒一次<br>2. 一般我建议将innodb_flush_method 设置成O_DIRECT，这样每次写的时候是直接写的；<br>刷数据是后台操作；<br>3. 是的，计算存储分离的架构对网络的要求很高；<br>4. innodb_use_native_aio 是设置成什么的 ？","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1547117469,"ip_address":"","comment_id":57270,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5841669948","product_id":100020801,"comment_content":"大佬 请教下啊 1.trx_commit参数设置为2,是写os cache即算事务成功，那何时会进行fync呢？<br>2.数据页的刷盘默认也是先写os cache，那它的fync频率又是多久啊？都是由操作系统决定？<br>3.redo进行fsync时，为避免read-modify-write(我的理解是:比如说硬盘block是4kb,如果fsync的块达不到4kb，那系统会先从硬盘对4kb，然后修改对应部分，在写回盘；若达到4kb，则fsync直接写盘，理解对吧？)<br>如果flush的block达不到4kb,会进行日志补齐，默认好像是8192(是不是与磁盘块一块比较好)，那问题来了，redo都是512字节为单位，如果小事务比较多，都生成不超过512字节，那不是增加了写盘的代价吗，如果主从传redo代替binlog(存储计算分离的架构)  那redo的网络流量也会增大啊  另外redo下沉到存储层，物化的速度越快越好，如果每次事务提交都fsync，计算层的性能岂不是影响很大吗(网络问题+redo物化)<br>4.在linux物理机，安装了libaio包，还是无法使用linux自带的AIO，搞不清为什么啊？<br>谢谢😁","like_count":1,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435500,"discussion_content":"1. 一秒一次\n2. 一般我建议将innodb_flush_method 设置成O_DIRECT，这样每次写的时候是直接写的；\n刷数据是后台操作；\n3. 是的，计算存储分离的架构对网络的要求很高；\n4. innodb_use_native_aio 是设置成什么的 ？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1547117469,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":57059,"user_name":"Justin","can_delete":false,"product_type":"c1","uid":1305601,"ip_address":"","ucode":"D49723FEA66731","user_header":"https://static001.geekbang.org/account/avatar/00/13/ec/01/978d54af.jpg","comment_is_top":false,"comment_ctime":1546610627,"is_pvip":false,"replies":[{"id":"21100","content":"你碰到过回滚失败的场景吗，如果碰到就描述下哦","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1547117127,"ip_address":"","comment_id":57059,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5841577923","product_id":100020801,"comment_content":"希望老师可以讲讲回滚的时候数据库具体做了哪些操作，还有什么情况会回滚失败，回滚失败应怎样处理呢？十分感谢","like_count":1,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435383,"discussion_content":"你碰到过回滚失败的场景吗，如果碰到就描述下哦","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1547117127,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":57056,"user_name":"Justin","can_delete":false,"product_type":"c1","uid":1305601,"ip_address":"","ucode":"D49723FEA66731","user_header":"https://static001.geekbang.org/account/avatar/00/13/ec/01/978d54af.jpg","comment_is_top":false,"comment_ctime":1546610109,"is_pvip":false,"replies":[{"id":"20573","content":"嗯… 你这个问题跟另外一个问题其实是一起的：回滚做了什么，我考虑下放到后面文章中","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1546611923,"ip_address":"","comment_id":57056,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5841577405","product_id":100020801,"comment_content":"可不可以这么理解 还没commit的 prepare 阶段的redo log 是可以写到磁盘里的 所以rollback那个事务只是在redo log追加了那个事务的恢复，还是checkpoint 不管没有commit阶段的redo log呢 ","like_count":1,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435382,"discussion_content":"嗯… 你这个问题跟另外一个问题其实是一起的：回滚做了什么，我考虑下放到后面文章中","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1546611923,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":57013,"user_name":"Justin","can_delete":false,"product_type":"c1","uid":1305601,"ip_address":"","ucode":"D49723FEA66731","user_header":"https://static001.geekbang.org/account/avatar/00/13/ec/01/978d54af.jpg","comment_is_top":false,"comment_ctime":1546600829,"is_pvip":false,"replies":[{"id":"20564","content":"完成一半的事务是可以写到数据盘的，按照这个再推理下😄","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1546608942,"ip_address":"","comment_id":57013,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5841568125","product_id":100020801,"comment_content":"如果redo log 中可能有还没commit的操作，那么他与checkpoint 的结合是什么样子的呢？是checkpoint 只管commit阶段不管prepare阶段的redo log 吗 ","like_count":1,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435359,"discussion_content":"完成一半的事务是可以写到数据盘的，按照这个再推理下😄","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1546608942,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":56994,"user_name":"一大只😴","can_delete":false,"product_type":"c1","uid":1310960,"ip_address":"","ucode":"92F3D2B7F63568","user_header":"https://static001.geekbang.org/account/avatar/00/14/00/f0/08409e78.jpg","comment_is_top":false,"comment_ctime":1546595349,"is_pvip":false,"replies":[{"id":"20565","content":"你是怎么验证的？等于0的时候虽然有走这个逻辑，但是最后调用fsync之前判断是0，就啥也没做就走了","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1546609062,"ip_address":"","comment_id":56994,"utype":1}],"discussion_count":2,"race_medal":0,"score":"5841562645","product_id":100020801,"comment_content":"经过测试发现sync_binlog=1或者=0，效果一样，都会直接受到组提交参数的影响。<br>&quot;root@localhost:mysql.sock  [test]&gt;show variables like &#39;sync_binlog&#39;;<br>+---------------+-------+<br>| Variable_name | Value |<br>+---------------+-------+<br>| sync_binlog   | 0     |<br>+---------------+-------+<br>1 row in set (0.00 sec)<br>&quot;root@localhost:mysql.sock  [test]&gt;insert into t values (58,55,55);  <br>Query OK, 1 row affected (0.51 sec)<br>&quot;root@localhost:mysql.sock  [test]&gt;show variables like &#39;sync_binlog&#39;;<br>+---------------+-------+<br>| Variable_name | Value |<br>+---------------+-------+<br>| sync_binlog   | 1     |<br>+---------------+-------+<br>1 row in set (0.00 sec)<br>&quot;root@localhost:mysql.sock  [test]&gt;insert into t values (60,60,60);<br>Query OK, 1 row affected (0.51 sec)<br><br>而sync_binlog=n时，1至n-1次响应不受组提交参数控制，第n次时会触发组提交参数(要么延迟，要么够事务个数)。<br>","like_count":2,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435350,"discussion_content":"你是怎么验证的？等于0的时候虽然有走这个逻辑，但是最后调用fsync之前判断是0，就啥也没做就走了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1546609062,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2389270,"avatar":"https://static001.geekbang.org/account/avatar/00/24/75/16/6e28bf17.jpg","nickname":"初晨","note":"","ucode":"C5D95D13E49127","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":589813,"discussion_content":"老哥，666。   跟着测试了下，确实是。sync_binlog=0或者sync_binlog=1时；变更操作的执行时间与binlog_group_commit_sync_delay直接相关。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1665323446,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"陕西"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":56915,"user_name":"尘封","can_delete":false,"product_type":"c1","uid":1247006,"ip_address":"","ucode":"CEE0C006387A03","user_header":"https://static001.geekbang.org/account/avatar/00/13/07/1e/bdbe93f4.jpg","comment_is_top":false,"comment_ctime":1546578876,"is_pvip":false,"replies":[{"id":"20547","content":"正文再看一遍😄 只是效果可能没那么好，但是还是有","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1546598005,"ip_address":"","comment_id":56915,"utype":1}],"discussion_count":3,"race_medal":0,"score":"5841546172","product_id":100020801,"comment_content":"如果设置sync_binlog＝1，是不是binlog就没有组提交了？因为每次事务提交都会调用fsync。","like_count":1,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435310,"discussion_content":"正文再看一遍😄 只是效果可能没那么好，但是还是有","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1546598005,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2389270,"avatar":"https://static001.geekbang.org/account/avatar/00/24/75/16/6e28bf17.jpg","nickname":"初晨","note":"","ucode":"C5D95D13E49127","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":589814,"discussion_content":"可以设置下binlog_group_commit_sync_delay，然后观察下情况，仍然使用了组提交。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1665323662,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":"陕西"},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1411040,"avatar":"https://static001.geekbang.org/account/avatar/00/15/87/e0/63e7d43d.jpg","nickname":"星空","note":"","ucode":"636A0A14608EF0","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":387555,"discussion_content":"感觉在拆解两阶段提交那里，binlog 的write 和 fsync 中间隔了redo log 的fsync ，所以也会使用到组提交。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1628242670,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":56890,"user_name":"锅子","can_delete":false,"product_type":"c1","uid":1323048,"ip_address":"","ucode":"4A9143AFB07FF2","user_header":"https://static001.geekbang.org/account/avatar/00/14/30/28/6e019a7a.jpg","comment_is_top":false,"comment_ctime":1546572967,"is_pvip":false,"replies":[{"id":"20533","content":"写到page cache你就能看见啦","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1546577348,"ip_address":"","comment_id":56890,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5841540263","product_id":100020801,"comment_content":"当设置sync_binlog=0时，每次commit都只是write到page cache，并不会fsync。但是做实验时binlog文件中还是会有记录，这是什么原因呢？是不是后台线程每秒一次的轮询也会将binlog cache持久化到磁盘？补充一下<br>设置binlog_group_commit_sync_delay=1000000，binlog_group_commit_sync_no_delay_count=10<br>","like_count":1,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435299,"discussion_content":"写到page cache你就能看见啦","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1546577348,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":56829,"user_name":"Dovelol","can_delete":false,"product_type":"c1","uid":1253384,"ip_address":"","ucode":"9B5DDF7720F307","user_header":"https://static001.geekbang.org/account/avatar/00/13/20/08/bc06bc69.jpg","comment_is_top":false,"comment_ctime":1546565474,"is_pvip":false,"replies":[{"id":"20500","content":"会讲到","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1546568784,"ip_address":"","comment_id":56829,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5841532770","product_id":100020801,"comment_content":"主从模式下，内网从库如果设置双1，刚还原的数据发现根本追不上主库，所以从库设置了0，老师后面章节会讲关于mysql包括主从监控这块的内容吗。","like_count":1,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435263,"discussion_content":"会讲到","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1546568784,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":56794,"user_name":"往事随风，顺其自然","can_delete":false,"product_type":"c1","uid":1235692,"ip_address":"","ucode":"F266EC6B143E38","user_header":"https://static001.geekbang.org/account/avatar/00/12/da/ec/779c1a78.jpg","comment_is_top":false,"comment_ctime":1546562376,"is_pvip":false,"replies":[{"id":"20474","content":"掉电会丢","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1546564778,"ip_address":"","comment_id":56794,"utype":1}],"discussion_count":1,"race_medal":0,"score":"5841529672","product_id":100020801,"comment_content":"pagecache 也算刷盘，和relog 文件写入刷盘有啥区别","like_count":1,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435238,"discussion_content":"掉电会丢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1546564778,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":356658,"user_name":"聂利","can_delete":false,"product_type":"c1","uid":1324550,"ip_address":"广东","ucode":"808E064089724D","user_header":"https://static001.geekbang.org/account/avatar/00/14/36/06/08c46bcd.jpg","comment_is_top":false,"comment_ctime":1662475661,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1662475661","product_id":100020801,"comment_content":"丁老师，想问一下，主备同步binlog的时候，dump线程是在write 阶段读page cache 中数据，还是从fsync后的从磁盘上读binlog 文 件数据。<br>   我个人思考肯定是应该是从page cache 中读，如果是从磁盘上去读，应该太慢了，主库落盘，从库落盘，就2次落盘了。<br>  但是找不到相关的资料进行确认。","like_count":0},{"had_liked":false,"id":354312,"user_name":"Geek1560","can_delete":false,"product_type":"c1","uid":2028949,"ip_address":"北京","ucode":"5F27A28B8002E6","user_header":"https://static001.geekbang.org/account/avatar/00/1e/f5/95/a362f01b.jpg","comment_is_top":false,"comment_ctime":1660276217,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1660276217","product_id":100020801,"comment_content":"请问 redolog 处于 prepare 阶段时，此时写到 redolog file 里了吗，还是是在 redologbuffer 里呀","like_count":0},{"had_liked":false,"id":351754,"user_name":"寥若晨星","can_delete":false,"product_type":"c1","uid":1447739,"ip_address":"","ucode":"2E87E43687DE72","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eou1BMETumU21ZI4yiaLenOMSibzkAgkw944npIpsJRicmdicxlVQcgibyoQ00rdGk9Htp1j0dM5CP2Fibw/132","comment_is_top":false,"comment_ctime":1658154822,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1658154822","product_id":100020801,"comment_content":"只有双1设置才有组提交吗","like_count":0},{"had_liked":false,"id":348264,"user_name":"大懒虫","can_delete":false,"product_type":"c1","uid":1440873,"ip_address":"","ucode":"51014C4A7074DA","user_header":"https://static001.geekbang.org/account/avatar/00/15/fc/69/02953435.jpg","comment_is_top":false,"comment_ctime":1654913611,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1654913611","product_id":100020801,"comment_content":"老师，请教一个问题，sync_log=1，会等到binlog fsync到disk完成，才去提交事务吗 ？ ","like_count":0},{"had_liked":false,"id":347615,"user_name":"boydenyol","can_delete":false,"product_type":"c1","uid":2019755,"ip_address":"","ucode":"869678C332F755","user_header":"https://static001.geekbang.org/account/avatar/00/1e/d1/ab/6e925b26.jpg","comment_is_top":false,"comment_ctime":1654226262,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1654226262","product_id":100020801,"comment_content":"老师，如果bin log在提交的过程中发生了崩溃，即redo logo有了commit标志，但是bin log还没有flync到磁盘，这里就会丢失日志，主从不一致了吗？","like_count":0},{"had_liked":false,"id":346415,"user_name":"const","can_delete":false,"product_type":"c1","uid":1500149,"ip_address":"","ucode":"258BA2B11ED1B2","user_header":"https://static001.geekbang.org/account/avatar/00/16/e3/f5/f076b407.jpg","comment_is_top":false,"comment_ctime":1653122548,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1653122548","product_id":100020801,"comment_content":"有个问题，innodb_flush_log_at_tx_commit 为1的时候，是内存中的redo log环中的ib_logfile中的数据 写入page cache然就到disk还是说    数据从redo log buffer中拿到 写入page cache再到disk ","like_count":0},{"had_liked":false,"id":342890,"user_name":"核桃","can_delete":false,"product_type":"c1","uid":1385204,"ip_address":"","ucode":"7AB05270CBCCCB","user_header":"https://static001.geekbang.org/account/avatar/00/15/22/f4/9fd6f8f0.jpg","comment_is_top":false,"comment_ctime":1650523413,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1650523413","product_id":100020801,"comment_content":"关于这章的内容，有一点困惑，对于oracle这些数据库来说，一般是不建议使用page cache的。因为本质上数据库自己是有一份内存在维护的，而使用了page cache，也只是利用系统的缓存，这样做只是把内容从用户态复制一遍到内核态进行搬运，但是意义不大啊，所以在这样的基础上，目前数据库利用page cache这个，我比较困惑。","like_count":0},{"had_liked":false,"id":342033,"user_name":"许宇宝","can_delete":false,"product_type":"c1","uid":1107388,"ip_address":"","ucode":"3FBB9621953EF1","user_header":"https://static001.geekbang.org/account/avatar/00/10/e5/bc/e5ff2613.jpg","comment_is_top":false,"comment_ctime":1649985174,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1649985174","product_id":100020801,"comment_content":"老师你好，有个问题咨询一下，我们服务器系统挂了，现在mysql是启不来了，安装目录下文件都还存在，这样如何才能恢复数据，试了好多的方法都没成功。","like_count":0},{"had_liked":false,"id":340844,"user_name":"谭爻","can_delete":false,"product_type":"c1","uid":1638791,"ip_address":"","ucode":"0555C52069B1FA","user_header":"https://static001.geekbang.org/account/avatar/00/19/01/87/1a2882ac.jpg","comment_is_top":false,"comment_ctime":1649174329,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1649174329","product_id":100020801,"comment_content":"看到这个位置 发现真的好难啊 每一篇认真看 还是没看懂","like_count":0},{"had_liked":false,"id":337754,"user_name":"鲁·本","can_delete":false,"product_type":"c1","uid":1209939,"ip_address":"","ucode":"F1DEB30C21B48E","user_header":"https://static001.geekbang.org/account/avatar/00/12/76/53/21d62a23.jpg","comment_is_top":false,"comment_ctime":1647011031,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1647011031","product_id":100020801,"comment_content":"b事务提交时顺带持久化了a事务的redo log，如果这时候，a事务要回滚，这个已经持久化的redo log要咋处理呢？","like_count":0},{"had_liked":false,"id":331961,"user_name":"AKEI","can_delete":false,"product_type":"c1","uid":2762604,"ip_address":"","ucode":"D6836002F27010","user_header":"https://static001.geekbang.org/account/avatar/00/2a/27/6c/5abd5e9f.jpg","comment_is_top":false,"comment_ctime":1642923027,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1642923027","product_id":100020801,"comment_content":"老师您好，有个问题困扰了很久烦请解答下。<br>图3那里的三个并发事务在prepare阶段，trx1第一个到达后被选为leader为时间节点a，trx1开始写盘为时间节点b，那trx2和trx3应该是在a和b之间进来了吧？那a和b之间trx1做了什么操作呢？<br>核心的问题就是多个事务在prepare阶段是怎样组织为一组的？","like_count":0},{"had_liked":false,"id":331871,"user_name":"AKEI","can_delete":false,"product_type":"c1","uid":2762604,"ip_address":"","ucode":"D6836002F27010","user_header":"https://static001.geekbang.org/account/avatar/00/2a/27/6c/5abd5e9f.jpg","comment_is_top":false,"comment_ctime":1642842521,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1642842521","product_id":100020801,"comment_content":"老师您好，有个问题困扰了很久烦请解答下。<br>图3那里的三个并发事务在prepare阶段，以为着这三个事务是同时在客户端执行commit命令了对吧。<br>trx1第一个到达后被选为leader为时间节点a，trx1开始写盘为时间节点b，那trx2和trx3应该是在a和b之间进来了吧？那a和b之间trx1做了什么操作呢？<br>核心的问题就是多个事务在prepare阶段是怎样组织为一组的？","like_count":0},{"had_liked":false,"id":328744,"user_name":"Geek_56d8e2","can_delete":false,"product_type":"c1","uid":1184778,"ip_address":"","ucode":"D44E94FF5BFD9F","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/hHAggykOyjScVG9qqSsdVaShDZoK6awO1uZYb3b75UA5QocVPMe3AT3AP3RDamtU7k8nekvc67DUzLRFDMTUQQ/132","comment_is_top":false,"comment_ctime":1640860089,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1640860089","product_id":100020801,"comment_content":"老师请教个问题哈  因为mysql好像并没保证 数据脏页和redolog 刷盘的顺序    如果数据脏页刷盘时机 先于redolog 刷盘时机  此时发生了crash 且 事务还没有提交   <br>问题1：这种现象会发生吗？<br>问题2：如果会发生 那重启后 mysql 是通过什么机制检测到这部分数据呢 ？<br>问题3：检测到后  mysql 又是怎么将这部分数据回滚的","like_count":0},{"had_liked":false,"id":325202,"user_name":"口罩妖精","can_delete":false,"product_type":"c1","uid":2810676,"ip_address":"","ucode":"07BED12094551A","user_header":"https://static001.geekbang.org/account/avatar/00/2a/e3/34/74868d54.jpg","comment_is_top":false,"comment_ctime":1638861625,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1638861625","product_id":100020801,"comment_content":"老师好，请问一下在图5中两阶段提交的最后一个redo log commit时write的是啥？在prepare阶段当前事务的redo log不是已经落盘了吗？望您解答，谢谢！","like_count":0},{"had_liked":false,"id":319925,"user_name":"非墨","can_delete":false,"product_type":"c1","uid":2739046,"ip_address":"","ucode":"6C2F75B04DA1EB","user_header":"https://static001.geekbang.org/account/avatar/00/29/cb/66/c34226a9.jpg","comment_is_top":false,"comment_ctime":1636009997,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1636009997","product_id":100020801,"comment_content":"自我理解：显示提交情形下，在commit命令执行前，redolog 和 binlog 就已经分别写在redolog buffer、binlog cache中了，等commit命令执行时，才会依次执行redolog、binlog写操作；<br>写redolog是由参数innodb_flush_log_at_trx_commit决定的：<br>当参数为0时，只需修改redo log状态；<br>当参数为1时，把redo log从redolog buffer写入page cache后fsync到磁盘，并修改redo log状态；<br>当参数为2时，把redo log从redolog buffer中写入page cache，并修改redo log状态；<br>写binlog:单单只是把binlog从binlog cache写入page cache；<br>而参数sync_binlog只是控制了是否把page cache中的binlog 异步刷新到磁盘；<br>当参数为0时，只进行写但不fsync；<br>当参数为1时，每次写操作完成后就fsync到磁盘；<br>当参数为N时，当积累N个事务后，才fsync到磁盘；<br>","like_count":1},{"had_liked":false,"id":319535,"user_name":"prader26","can_delete":false,"product_type":"c1","uid":1433707,"ip_address":"","ucode":"5EFFFC374ADECE","user_header":"https://static001.geekbang.org/account/avatar/00/15/e0/6b/f61d7466.jpg","comment_is_top":false,"comment_ctime":1635843832,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1635843832","product_id":100020801,"comment_content":"<br>通常我们说 MySQL 的“双 1”配置，指的就是 sync_binlog 和 innodb_flush_log_at_trx_commit 都设置成 1。<br>也就是说，一个事务完整提交前，需要等待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog。","like_count":0},{"had_liked":false,"id":312620,"user_name":"不凡","can_delete":false,"product_type":"c1","uid":2031689,"ip_address":"","ucode":"28A3EC4C309C56","user_header":"","comment_is_top":false,"comment_ctime":1631893230,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1631893230","product_id":100020801,"comment_content":"老师，有个问题请教，事物的大小是怎么计算的？1.是lsn的偏移量差值吗？如果是，lsn中的length是怎么计算出来的？2.binlog_cache_size大小默认32KB，这个length超过了32KB就会用到内存临时表是吗？","like_count":0},{"had_liked":false,"id":307326,"user_name":"征服天堂","can_delete":false,"product_type":"c1","uid":2445066,"ip_address":"","ucode":"686ED7ECC00004","user_header":"https://static001.geekbang.org/account/avatar/00/25/4f/0a/0ebfbb01.jpg","comment_is_top":false,"comment_ctime":1629029823,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1629029823","product_id":100020801,"comment_content":"老师，我想问一下，redo log不定期会刷盘，事务还没提交时候一部分数据就已经刷盘了，那事务回滚后redo log不就多了一部分日志了吗，这部分日志对业务没有妨碍吗？","like_count":0},{"had_liked":false,"id":305963,"user_name":"星空","can_delete":false,"product_type":"c1","uid":1411040,"ip_address":"","ucode":"636A0A14608EF0","user_header":"https://static001.geekbang.org/account/avatar/00/15/87/e0/63e7d43d.jpg","comment_is_top":false,"comment_ctime":1628245877,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1628245877","product_id":100020801,"comment_content":"老师，有一个疑问，是不是无论参数设置的是什么值，redo log 刷盘，都是write+fsync，只是什么时间做哪个步骤的问题而已，这样理解正确吗？<br>因为如果 redo log 那个参数=1，只fsync 的话，那该如何解释两阶段的4个步骤呢，比较疑惑。","like_count":0},{"had_liked":false,"id":305957,"user_name":"星空","can_delete":false,"product_type":"c1","uid":1411040,"ip_address":"","ucode":"636A0A14608EF0","user_header":"https://static001.geekbang.org/account/avatar/00/15/87/e0/63e7d43d.jpg","comment_is_top":false,"comment_ctime":1628242537,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1628242537","product_id":100020801,"comment_content":"当innodb_flush_log_at_trx_commit设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘，即直接fsync ，而不是write+fsync吧？那么在两阶段提交那里，拆解为4步，第一步redo prepare write ，是不是只有当 innodb_flush_log_at_trx_commit 不为1 时，才会是这样？","like_count":0},{"had_liked":false,"id":303845,"user_name":"小破孩","can_delete":false,"product_type":"c1","uid":1352328,"ip_address":"","ucode":"F7616DF0BCDA5E","user_header":"https://static001.geekbang.org/account/avatar/00/14/a2/88/3f79f13b.jpg","comment_is_top":false,"comment_ctime":1627024505,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1627024505","product_id":100020801,"comment_content":"一个事物没提交，而redo log已经写到page cache，如果这个事物回滚了，这个事物的redo log是不是还要从page cache上删掉，如果这个page cache已经落盘，是不是还要从disk上删掉","like_count":0},{"had_liked":false,"id":302269,"user_name":"jiez95","can_delete":false,"product_type":"c1","uid":1235647,"ip_address":"","ucode":"65E5B97B960805","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJicjzWf69FU1YLHtplL3mVY75CCuia4IB9p5BxtgS1gC2mzfwow6gGMeU4YttycugWGeKMskqYWkxw/132","comment_is_top":false,"comment_ctime":1626151620,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1626151620","product_id":100020801,"comment_content":"老师好，这里有一个疑问请教一下:<br>组提交都会把未commit的redo log刷盘<br>1. 那么如果此时redo log到达checkpoint触发数据刷盘是否会吧buffer_pool中的脏页刷到磁盘中.<br>2. 如果会那么如果这个时候crash, 仅通过redo log + bin log 好像无法将磁盘中的脏数据给处理掉吧<br>(即想问 crash恢复的策略： 1. 只恢复已提交事务 2. 重做所有事务，如果是未提交或回滚的通过undo log 回滚掉未提交事务)","like_count":0},{"had_liked":false,"id":302200,"user_name":"不吃辣👾","can_delete":false,"product_type":"c1","uid":1333649,"ip_address":"","ucode":"B25E0725B5E85F","user_header":"https://static001.geekbang.org/account/avatar/00/14/59/91/fa2d8bb2.jpg","comment_is_top":false,"comment_ctime":1626136219,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1626136219","product_id":100020801,"comment_content":"老师 binlog那个是配置的是1，redolog配置的为2。当服务器重启 binlog落盘后被备库执行了，redolog还没落盘，恢复的时候是不是就造成主备不一致了？","like_count":0},{"had_liked":false,"id":301319,"user_name":"尘","can_delete":false,"product_type":"c1","uid":1244251,"ip_address":"","ucode":"2C71FBCED5BFE6","user_header":"https://static001.geekbang.org/account/avatar/00/12/fc/5b/caa6a2a6.jpg","comment_is_top":false,"comment_ctime":1625630344,"is_pvip":false,"discussion_count":0,"race_medal":1,"score":"1625630344","product_id":100020801,"comment_content":"等 trx1 要开始写盘的时候，这个组里面已经有了三个事务，这时候 LSN 也变成了 160；为什么LSN是160，怎么算的","like_count":0},{"had_liked":false,"id":300947,"user_name":"walzzz","can_delete":false,"product_type":"c1","uid":1707393,"ip_address":"","ucode":"17D8079494189A","user_header":"https://static001.geekbang.org/account/avatar/00/1a/0d/81/ed4957e8.jpg","comment_is_top":false,"comment_ctime":1625463147,"is_pvip":false,"discussion_count":0,"race_medal":1,"score":"1625463147","product_id":100020801,"comment_content":"事务还没提交的时候，redo log buffer中的部分日志就可能被持久化到磁盘——那如果此时进行回滚，持久化了的redo log将如何处理呢？","like_count":0},{"had_liked":false,"id":300946,"user_name":"walzzz","can_delete":false,"product_type":"c1","uid":1707393,"ip_address":"","ucode":"17D8079494189A","user_header":"https://static001.geekbang.org/account/avatar/00/1a/0d/81/ed4957e8.jpg","comment_is_top":false,"comment_ctime":1625463140,"is_pvip":false,"discussion_count":0,"race_medal":1,"score":"1625463140","product_id":100020801,"comment_content":"事务还没提交的时候，redo log buffer中的部分日志就可能被持久化到磁盘——那如果此时进行回滚，持久化了的redo log将如何处理呢？","like_count":0},{"had_liked":false,"id":300760,"user_name":"精神病","can_delete":false,"product_type":"c1","uid":1199038,"ip_address":"","ucode":"3066FE896874E4","user_header":"https://static001.geekbang.org/account/avatar/00/12/4b/be/83cbb285.jpg","comment_is_top":false,"comment_ctime":1625376199,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1625376199","product_id":100020801,"comment_content":" 在一个事务里有多条语句， 是执行一条语句生成一条redolog 吗？如果事务还未提交，后台异步线程把未提交的redolog fsync 写入磁盘不会有问题吗?","like_count":0},{"had_liked":false,"id":296062,"user_name":"cake","can_delete":false,"product_type":"c1","uid":1966533,"ip_address":"","ucode":"55A7FC6CC1204C","user_header":"https://static001.geekbang.org/account/avatar/00/1e/01/c5/b48d25da.jpg","comment_is_top":false,"comment_ctime":1622725559,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1622725559","product_id":100020801,"comment_content":"hello 老师 可以从原理上解释下 为什么binlog 必须一次写入,log buffer 中内容却可以搭顺风车吗","like_count":0},{"had_liked":false,"id":294104,"user_name":"T","can_delete":false,"product_type":"c1","uid":1668015,"ip_address":"","ucode":"4CC56C9EC26B8E","user_header":"https://static001.geekbang.org/account/avatar/00/19/73/af/a0c708ec.jpg","comment_is_top":false,"comment_ctime":1621762758,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1621762758","product_id":100020801,"comment_content":"这一章 是不是可以提及下double write 机制？感觉会深一点","like_count":0},{"had_liked":false,"id":294057,"user_name":"汉江","can_delete":false,"product_type":"c1","uid":1788647,"ip_address":"","ucode":"01622D984B8F9B","user_header":"https://static001.geekbang.org/account/avatar/00/1b/4a/e7/6c16af5d.jpg","comment_is_top":false,"comment_ctime":1621737809,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1621737809","product_id":100020801,"comment_content":"看了老师的文章，也看了同学们的评论，有一个疑问，老师说只有事务A进入到commit阶段，redolog 才会有 redolog prepare 状态，crash-safe数据恢复的时候去找redolog，碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务，恢复数据。那在假设事务执行过程中事务A在提交前，有一部分redo log被事务B提前持久化，这个时候断电，还需要通过扫描redolog和binlog 看是否需要提交数据吗？","like_count":0},{"had_liked":false,"id":293303,"user_name":"lleft","can_delete":false,"product_type":"c1","uid":1970443,"ip_address":"","ucode":"D573EB509455AE","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIx1V1QAxC4NHaxYZGyuibBN8lcURJWc5nrnO4yic1kxnDemYV2FJGialf47kYX9qtDnZZOfe1SJeLicg/132","comment_is_top":false,"comment_ctime":1621328916,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1621328916","product_id":100020801,"comment_content":"没有提交的事务的redo log被动刷盘都是只刷到文件系统的page cache还是说只有redo log buffer占到innodb_buffer_pool_size的一半这种情况才会只刷到page cache，其他的都是直接落盘到redo log文件？","like_count":0},{"had_liked":false,"id":285813,"user_name":"T","can_delete":false,"product_type":"c1","uid":1668015,"ip_address":"","ucode":"4CC56C9EC26B8E","user_header":"https://static001.geekbang.org/account/avatar/00/19/73/af/a0c708ec.jpg","comment_is_top":false,"comment_ctime":1617018410,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1617018410","product_id":100020801,"comment_content":"总结一下：只有事务提交 才会触发 两阶段提交，提交之前，binlog,redo log 各自在内存里面玩（binlog cache，redo log buffer）,然后innodb每秒会把redolog buffer的数据写到page cache,然后持久化（所以会出现还没提交的redolog被持久化），还有两种情况会出现没提交的redolog被写到磁盘中；1.redo log buff 占用空间到了buff_size的一半，会主动写盘，但是因为事务没提交，所以直接到了pagecache,2.并行事务也可能把redo log buff 里面的日志全部丢到磁盘或者page cache(取决于参数innodb_flush_log_at_trx_commit等于几，自己可以看23章)，但是这3种情况，都是没问题的，为什么，因为有binlog，开篇我就说了两阶段提交是在提交后触发，所以 就算事务最后没提交，因为没binlog，所以会回滚掉redo log。","like_count":0},{"had_liked":false,"id":281459,"user_name":"Bin","can_delete":false,"product_type":"c1","uid":1304406,"ip_address":"","ucode":"26BA010D2990C4","user_header":"https://static001.geekbang.org/account/avatar/00/13/e7/56/87f45704.jpg","comment_is_top":false,"comment_ctime":1614756419,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1614756419","product_id":100020801,"comment_content":"老师好，当参数sync_binlog=0：binlog什么时候会做fsync操作？","like_count":0,"discussions":[{"author":{"id":1299041,"avatar":"https://static001.geekbang.org/account/avatar/00/13/d2/61/c77f63df.jpg","nickname":"zhangchuan","note":"","ucode":"8EF11A6A6DF5CF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":368356,"discussion_content":"为0时，只是把缓存数据写到page cache中，不刷盘","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618668114,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":277827,"user_name":"从远方过来","can_delete":false,"product_type":"c1","uid":1797551,"ip_address":"","ucode":"4791DBC7E05B1D","user_header":"","comment_is_top":false,"comment_ctime":1612609220,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1612609220","product_id":100020801,"comment_content":"为什么redo log 叫buffer，binlog叫cache呢？他们有什么区别么？","like_count":0},{"had_liked":false,"id":276922,"user_name":"励研冰","can_delete":false,"product_type":"c1","uid":1106394,"ip_address":"","ucode":"FCBC8266018FA0","user_header":"https://static001.geekbang.org/account/avatar/00/10/e1/da/d7f591a7.jpg","comment_is_top":false,"comment_ctime":1612178592,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1612178592","product_id":100020801,"comment_content":"老师: 我不建议你把 innodb_flush_log_at_trx_commit 设置成 0。因为把这个参数设置成 0，表示 redo log 只保存在内存中，这样的话 MySQL 本身异常重启也会丢数据，风险太大。而 redo log 写到文件系统的 page cache 的速度也是很快的，所以将这个参数设置成 2 跟设置成 0 其实性能差不多，但这样做 MySQL 异常重启时就不会丢数据了，相比之下风险会更小。<br>老师，设置成0跟2都是其实都是写到内存里面，只不过设置成2是写入系统的page cache中，为什么设置成2就不丢数据呢？是因为每一秒的fsync吗？如果是那这一秒之间的数据是不是也有丢的风险？","like_count":0},{"had_liked":false,"id":275307,"user_name":"helloworld","can_delete":false,"product_type":"c1","uid":1101762,"ip_address":"","ucode":"003700A99A910B","user_header":"https://static001.geekbang.org/account/avatar/00/10/cf/c2/a5b3ceaf.jpg","comment_is_top":false,"comment_ctime":1611459573,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1611459573","product_id":100020801,"comment_content":"林老师, 你好.<br><br>关于优化的第一条(设置 binlog 组提交的参数), 我的理解是如果还没达到 binlog 组提交的次数,这时如果主机断电或者异常重启,也会导致这部分还没持久化的 binlog 丢失吧.<br><br>为什么林老师说不会有数据丢失的风险呢? 我不太理解.","like_count":0},{"had_liked":false,"id":273164,"user_name":"刘震","can_delete":false,"product_type":"c1","uid":1836971,"ip_address":"","ucode":"64D0A2BA0F4A03","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIWFAJGwjiadzt3Cv7Wgv3jqcpu113lbuhBEKIEDEqaF615bGPr0Fib5eDlyIeUxm7XE7SbiavdMyI0w/132","comment_is_top":false,"comment_ctime":1610461512,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1610461512","product_id":100020801,"comment_content":"老师好，请问一下redo log打commit标的问题，在事务执行中就已经被redo就被持久化的情况下，后续要再打prepare标或commit标的时候，是直接在磁盘里再顺序写一个打标的日志么？还是要找到之前持久化日志的位置，然后给日志打标？","like_count":0,"discussions":[{"author":{"id":1366960,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLYicScS2u9alz421bWmOT0qKkAJbXcsFhtuqM6XByicnSL6nFHTQ5fPLM9R8HgjABicJXdqQljIJroQ/132","nickname":"上善若水","note":"","ucode":"DEB612BBF40014","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":342651,"discussion_content":"有同样疑惑，感觉应该是顺序再写日志，否则还需要找到之前的记录进行更新，也就没有顺序写的优势了。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1610765518,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":272162,"user_name":"潇洒的毅小峰","can_delete":false,"product_type":"c1","uid":1118141,"ip_address":"","ucode":"24638DAED92F08","user_header":"https://static001.geekbang.org/account/avatar/00/11/0f/bd/7a9b2a0c.jpg","comment_is_top":false,"comment_ctime":1609957386,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1609957386","product_id":100020801,"comment_content":"老师主机掉电和异常重启有什么区别，将innodb_flush_log_at_trx_commit设置为2 风险是主机掉电会丢失数据和所以将这个参数设置成 2 跟设置成 0 其实性能差不多，但这样做 MySQL 异常重启时就不会丢数据了，相比之下风险会更小 有点分不清了","like_count":0,"discussions":[{"author":{"id":1440185,"avatar":"https://static001.geekbang.org/account/avatar/00/15/f9/b9/21b0553f.jpg","nickname":"叶少波","note":"","ucode":"CDF3DEEC7DFEA0","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":343473,"discussion_content":"主机掉电，会导致文件系统缓存（page cache）中的数据丢失；异常重启，我理解说的是mysql进程重启，没断电的话，文件系统缓存中的数据不会丢","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1611056442,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":269646,"user_name":"张三","can_delete":false,"product_type":"c1","uid":1004092,"ip_address":"","ucode":"1155528FAE1546","user_header":"https://static001.geekbang.org/account/avatar/00/0f/52/3c/d6fcb93a.jpg","comment_is_top":false,"comment_ctime":1608726005,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1608726005","product_id":100020801,"comment_content":"这篇值得看好多遍，包括文中提到的第二篇和第15篇","like_count":0},{"had_liked":false,"id":265587,"user_name":"AluAlu","can_delete":false,"product_type":"c1","uid":1309974,"ip_address":"","ucode":"ACDE9CD9D7B459","user_header":"https://static001.geekbang.org/account/avatar/00/13/fd/16/719fa5c3.jpg","comment_is_top":false,"comment_ctime":1606957908,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1606957908","product_id":100020801,"comment_content":"老师好，如果A事务的部分redolog被B事务commit掉，如果A事务回滚了怎么办？","like_count":0},{"had_liked":false,"id":265403,"user_name":"LPF","can_delete":false,"product_type":"c1","uid":2287841,"ip_address":"","ucode":"036C552D7251E9","user_header":"https://static001.geekbang.org/account/avatar/00/22/e8/e1/6045b299.jpg","comment_is_top":false,"comment_ctime":1606890697,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1606890697","product_id":100020801,"comment_content":"请问老师，mysql的redo log持久化到磁盘了，但是binlog没正确写入，此时要回滚，那么redolog持久化到磁盘的数据不就是脏数据吗。","like_count":0},{"had_liked":false,"id":261402,"user_name":"x-ray","can_delete":false,"product_type":"c1","uid":1140175,"ip_address":"","ucode":"8363F0C4D0AC0B","user_header":"https://static001.geekbang.org/account/avatar/00/11/65/cf/326c0eea.jpg","comment_is_top":false,"comment_ctime":1605323447,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1605323447","product_id":100020801,"comment_content":"binlog在刷磁盘的时候，比如一个完整事务的binlog在刷盘，刷一半断电了，会怎样？","like_count":0},{"had_liked":false,"id":261004,"user_name":"kali","can_delete":false,"product_type":"c1","uid":1042714,"ip_address":"","ucode":"7159F913A83016","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/1NMAMj2T81BGLJhsnJ7IZL9BeP6LoX6ajukkTKficABoStaE6mAFHBibRQ3HiaG3VNJibVtqQy5m9RMibGfic62yibd7g/132","comment_is_top":false,"comment_ctime":1605170571,"is_pvip":false,"discussion_count":0,"race_medal":1,"score":"1605170571","product_id":100020801,"comment_content":"老师好，有二个疑问：<br>1：当设置为sync_binlog=0,innodb_flush_log_at_trx_commit=0的时候，只执行语句，不commit，是先写binlog cache ,还是先写redo log cache ，还是同时写呢？ 如果是先写redo log cache ,为什么执行大的insert into select * from big_table的时候，会报超过max_binlog_size 大小呢？<br>2：在做事务冲突检测的时候，会有数据写到binlog cache中吗？<br>2：","like_count":0},{"had_liked":false,"id":258494,"user_name":"dbtiger","can_delete":false,"product_type":"c1","uid":1324202,"ip_address":"","ucode":"05E8447593318C","user_header":"https://static001.geekbang.org/account/avatar/00/14/34/aa/431de942.jpg","comment_is_top":false,"comment_ctime":1604461740,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1604461740","product_id":100020801,"comment_content":"就单单提升性能而选择丢 binlog 日志或者丢数据这种选择是不理性的，数据库意义就在于安全存数据，对于牺牲丢数据来换取性能是下下策。","like_count":0},{"had_liked":false,"id":256663,"user_name":"lanco","can_delete":false,"product_type":"c1","uid":1188352,"ip_address":"","ucode":"C24A0A8716C78C","user_header":"https://static001.geekbang.org/account/avatar/00/12/22/00/abb7bfe3.jpg","comment_is_top":false,"comment_ctime":1603700257,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1603700257","product_id":100020801,"comment_content":"看到文章的两句话，写到磁盘与持久化到磁盘，可以这么理解，写到磁盘是写到文件系统层面，持久化到磁盘才是落到磁盘上，linux在裸磁盘上封装了一层文件系统，这样子操作系统不是直接读裸磁盘，而是通过文件系统去和磁盘交互","like_count":0},{"had_liked":false,"id":250677,"user_name":"Geek_b2933e","can_delete":false,"product_type":"c1","uid":1370020,"ip_address":"","ucode":"B9398B99B9914D","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKKUmQ9Vu1JmWw1ZMIZvN6QibLuSVibiaPQrO5TzCOYNfu4T74vMvXJk12J7C0jZGYhUJWET0h0AG0Rw/132","comment_is_top":false,"comment_ctime":1601194063,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1601194063","product_id":100020801,"comment_content":"page cache 是一块内存 吗？","like_count":0,"discussions":[{"author":{"id":1788647,"avatar":"https://static001.geekbang.org/account/avatar/00/1b/4a/e7/6c16af5d.jpg","nickname":"汉江","note":"","ucode":"01622D984B8F9B","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":346611,"discussion_content":"是的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1612005700,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":245734,"user_name":"summer_7196","can_delete":false,"product_type":"c1","uid":1390813,"ip_address":"","ucode":"B61E9F29D0D8CE","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJ2QFSebcWYzvSibOicRbaeqGmq1kFuHVvwjadDsicQnIbovlGqSfmfibtib9TSwcIqWfcxkKw8DSxTTVg/132","comment_is_top":false,"comment_ctime":1599036960,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1599036960","product_id":100020801,"comment_content":"在双1的配置下，sync_binlog=1,指事物提交时才fsync。假设一个事物里有多个更新语句，是等所有语句执行完，再一次性fsync的，还是每个sql执行完就刷盘了。他是怎么判定事物提交这个动作的。我是理解成只有commit的时候，才叫事物提交时。但是这样又不符合崩溃恢复原理。事物提交时指一个语句执行完？？如果不是，他怎么知道我有几个更新语句的？","like_count":0},{"had_liked":false,"id":241845,"user_name":"${name}","can_delete":false,"product_type":"c1","uid":2044025,"ip_address":"","ucode":"EE643BCFC70661","user_header":"https://static001.geekbang.org/account/avatar/00/1f/30/79/cc553d32.jpg","comment_is_top":false,"comment_ctime":1597465217,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1597465217","product_id":100020801,"comment_content":"老师，我有个问题<br>innodb_flush_log_at_trx_commit设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘；<br>这句话我理解就是 commit + write + fsync <br>那为什么每秒一次后台轮询刷盘，再加上崩溃恢复这个逻辑，<br>InnoDB 就认为 redo log 在 commit 的时候就不需要 fsync 了，只会 write 到文件系统的 page cache 中就够了。","like_count":0},{"had_liked":false,"id":237794,"user_name":"Romber","can_delete":false,"product_type":"c1","uid":1205508,"ip_address":"","ucode":"3FB24B736FF7E3","user_header":"https://static001.geekbang.org/account/avatar/00/12/65/04/fea2dcf9.jpg","comment_is_top":false,"comment_ctime":1595955678,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1595955678","product_id":100020801,"comment_content":"如果binlog已write到page cache了，正在fsync到磁盘的过程中突然服务器掉电了，这个时候会怎么样？binlog文件损坏吗？","like_count":0},{"had_liked":false,"id":237632,"user_name":"sibyl","can_delete":false,"product_type":"c1","uid":1323652,"ip_address":"","ucode":"0D142011860D69","user_header":"","comment_is_top":false,"comment_ctime":1595905615,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1595905615","product_id":100020801,"comment_content":"老师好，按照我得理解，binlog sync 设置为1，innodb_flush_log_at_trx_commit设置为2，也是有可能丢失数据和主从不一致的吧？<br><br>因为12配置保证在响应客户端之前binlog持久化但是不保证redolog持久化，假如在响应客户端处理成功后立刻crash了，那么重启后，只有binlog没有redolog所以无法恢复事务，造成数据丢失;并且从库能获取binlog并执行，所以造成主从不一致。<br><br>老师，这样理解对么？","like_count":0},{"had_liked":false,"id":237608,"user_name":"sibyl","can_delete":false,"product_type":"c1","uid":1323652,"ip_address":"","ucode":"0D142011860D69","user_header":"","comment_is_top":false,"comment_ctime":1595899220,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1595899220","product_id":100020801,"comment_content":"老师好，参考melon描述binlog fsync阶段的伪代码，做了一点修改: 设置delay后，事务会等待条件，所以我用了while表示，具体如下:<br><br><br>binlog fsync 阶段:<br><br>if(binlog_group_commit_sync_delay &gt; 0 || binlog_group_commit_sync_no_delay_count &gt; 0){<br>    while ( NOW - sart_time &lt;= binlog_group_comnit_sync_delay &amp;&amp; group_write &lt;= binlog_group_commit_sync_no_delay_count){}<br>    fsync<br><br>}<br><br> IF sync_binlog &gt; 0 &amp;&amp; global_write &gt;= sync_binlog<br>        fsync","like_count":0},{"had_liked":false,"id":237601,"user_name":"sibyl","can_delete":false,"product_type":"c1","uid":1323652,"ip_address":"","ucode":"0D142011860D69","user_header":"","comment_is_top":false,"comment_ctime":1595898054,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1595898054","product_id":100020801,"comment_content":"1.请问老师，在一个事务响应客户端前redolog和binlog一定是flush的么？<br><br>如果与配置有关，那是不是双1才能保证一定flush，此时才不会丢数据对么？<br><br>2.innodb flush log at trx commit 影响的是 redolog  prepare flush吧？<br><br>3.binlog sync 设置成100，redolog flush 设置成0&#47;2，那么可能在响应客户端成功时并没有flush redolog 和 binlog，然后立刻crash了，这不就完成数据丢失了么？","like_count":0},{"had_liked":false,"id":235455,"user_name":"jack","can_delete":false,"product_type":"c1","uid":1783638,"ip_address":"","ucode":"37CE8FC549732B","user_header":"https://static001.geekbang.org/account/avatar/00/1b/37/56/7f98bf2c.jpg","comment_is_top":false,"comment_ctime":1595043426,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1595043426","product_id":100020801,"comment_content":"老师好，我现在使用mysql5,7.31版本搭建主从复制，在生产环境中bin-log 格式是使用mixed还是row的。","like_count":0},{"had_liked":false,"id":231036,"user_name":"`","can_delete":false,"product_type":"c1","uid":1556919,"ip_address":"","ucode":"BBE7BE85F22CEE","user_header":"https://static001.geekbang.org/account/avatar/00/17/c1/b7/e638e5a7.jpg","comment_is_top":false,"comment_ctime":1593570306,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1593570306","product_id":100020801,"comment_content":"所以一个log的写入分三步，写入buffer&#47;cache -&gt; 写入文件系统pagecache -&gt;写入磁盘。我的一个问题是为什么要第二步呢，不可以从log buffer&#47;cache直接写入磁盘吗？","like_count":0},{"had_liked":false,"id":226972,"user_name":"shiziwen","can_delete":false,"product_type":"c1","uid":1016917,"ip_address":"","ucode":"ADADC770D82D66","user_header":"https://static001.geekbang.org/account/avatar/00/0f/84/55/1e40bd61.jpg","comment_is_top":false,"comment_ctime":1592238273,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1592238273","product_id":100020801,"comment_content":"Wal机制使得 redo log 和bin log都顺序写，这句话怎么理解呢？","like_count":0},{"had_liked":false,"id":226968,"user_name":"shiziwen","can_delete":false,"product_type":"c1","uid":1016917,"ip_address":"","ucode":"ADADC770D82D66","user_header":"https://static001.geekbang.org/account/avatar/00/0f/84/55/1e40bd61.jpg","comment_is_top":false,"comment_ctime":1592237006,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1592237006","product_id":100020801,"comment_content":"老师在回答同学的问题时提到“所谓的 redo log prepare，是“当前事务提交”的一个阶段，也就是说，在事务A提交的时候，我们才会走到事务A的redo log prepare这个阶段。”<br>是不是意味着，一个事务，在commit的时候，才会写redo log？<br><br>在第二章介绍“update 语句提交过程”时提到“引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。”，从这段话中，无法判断redo log写入的时机。","like_count":0,"discussions":[{"author":{"id":1299041,"avatar":"https://static001.geekbang.org/account/avatar/00/13/d2/61/c77f63df.jpg","nickname":"zhangchuan","note":"","ucode":"8EF11A6A6DF5CF","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":368323,"discussion_content":"对于问题1的解答是事务在执行时会写redo log buffer，而在提交时会将redo log buffer中的日志写入到文件系统的page cache中然后调用fsync刷到磁盘","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1618654212,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":224438,"user_name":"Geek_f40120","can_delete":false,"product_type":"c1","uid":2028635,"ip_address":"","ucode":"7EF9C529B7AE9A","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKawxntLfibLJJmbicIiczetxQBOsn8uNTbNBANje21Chiay38FiaA43CuY7sxLQp12ghDvWXghNTXrGNQ/132","comment_is_top":false,"comment_ctime":1591400059,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1591400059","product_id":100020801,"comment_content":"老师，看了这章后，我有以下几个问题：<br>1：事务未提交，mysql遭遇断电重启，但是redo-log已经被持久化到磁盘，这种情况怎么处理？<br>2：文件系统的page cache是只在内存中有，还是在磁盘上也会有？<br>3：如果把 innodb_flush_log_at_trx_commit 设置成 1，那么 redo log 在 prepare 阶段就要持久化一次，这个持久化是持久化到磁盘吗？<br>4：根据图5，可以看出redo-log是在prepare阶段持久化日志到磁盘的，在事务提交的时候，redo-log日志写到pagecahe中的，这样理解对吗？","like_count":0},{"had_liked":false,"id":220715,"user_name":"ad","can_delete":false,"product_type":"c1","uid":1060556,"ip_address":"","ucode":"7AC650031EB7A9","user_header":"https://static001.geekbang.org/account/avatar/00/10/2e/cc/964a8bcb.jpg","comment_is_top":false,"comment_ctime":1590311672,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1590311672","product_id":100020801,"comment_content":"老师您好，文中提到“然后就有同学问了，redo log buffer 里面的内容，是不是每次生成后都要直接持久化到磁盘呢？答案是，不需要。如果事务执行期间 MySQL 发生异常重启，那这部分日志就丢了。由于事务并没有提交，所以这时日志丢了也不会有损失。“，会不会出现事务执行期间mysql 发生异常重启，redo log buffer日志丢失，但是binlog日志存在？如果出现这种情况mysql后续的逻辑是怎样的？","like_count":0},{"had_liked":false,"id":220436,"user_name":"注意力$","can_delete":false,"product_type":"c1","uid":1142316,"ip_address":"","ucode":"7FB3399A1EAB72","user_header":"https://static001.geekbang.org/account/avatar/00/11/6e/2c/e2f3cfc0.jpg","comment_is_top":false,"comment_ctime":1590241665,"is_pvip":false,"discussion_count":0,"race_medal":1,"score":"1590241665","product_id":100020801,"comment_content":"老师好，请问 事务在执行过程中，生成的 redo log 是要先写到 redo log buffer 的。  redo log buffer 是一块内存，那应该是先写日志呢还是先写内存呢？内存不是容易丢失吗","like_count":0},{"had_liked":false,"id":214950,"user_name":"…","can_delete":false,"product_type":"c1","uid":1297845,"ip_address":"","ucode":"207C7F95192129","user_header":"https://static001.geekbang.org/account/avatar/00/13/cd/b5/2e60f2b0.jpg","comment_is_top":false,"comment_ctime":1588855656,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1588855656","product_id":100020801,"comment_content":"老师说的组提交是 从redo log buffer批量write呢，还是从page cache批量fsync呢？<br>图3看起来是批量从redolog buffer批量write，但是图5顺序的优化只是将fsync 拿到后面了，并不会等到更多redolog buffer里面的内容进行批量write 呀","like_count":0,"discussions":[{"author":{"id":1526355,"avatar":"https://static001.geekbang.org/account/avatar/00/17/4a/53/063f9d17.jpg","nickname":"moonfox","note":"","ucode":"902BFF40EFA9FA","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":331380,"discussion_content":"个人理解是尽可能多的延后fsync的调用，write也是一个一个来的，写到pagecache中，攒多了以后，再调用一次fsync就行了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1606838383,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":211346,"user_name":"深海极光","can_delete":false,"product_type":"c1","uid":1096111,"ip_address":"","ucode":"331024F7E99C64","user_header":"https://static001.geekbang.org/account/avatar/00/10/b9/af/f59b4c7c.jpg","comment_is_top":false,"comment_ctime":1587950736,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1587950736","product_id":100020801,"comment_content":"老师最近反复看了redolog部分被持久化但是事物没有提交成功的场景的问题，开启binlog的情况下，在崩溃恢复时扫描到这部分redolog时是根据对应的xid入binlog里找，如果没有commit则通过undolog回滚掉，这也是判断所有redolog是否commit的背后逻辑吧，但是还有一个场景是如果没有开始binlog的情况下就没地方来检查是否提交，那又是怎么处理的呢，还有就是我理解的redolog在在文件里没有状态吧，无论是定时刷新，还是prepare刷新的，而这些状态都是binlog里的希望老师解答，谢谢🙏","like_count":0},{"had_liked":false,"id":205803,"user_name":"冬风向左吹","can_delete":false,"product_type":"c1","uid":1066928,"ip_address":"","ucode":"376C45C5134F93","user_header":"https://static001.geekbang.org/account/avatar/00/10/47/b0/a9b77a1e.jpg","comment_is_top":false,"comment_ctime":1586741978,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1586741978","product_id":100020801,"comment_content":"应该是这样：只要binlog写成功了，无论redo有没有commit，其实整个事务都已经是成功的了，因为可以根据redo log和bin log中的xid确认事务的最终状态。","like_count":0},{"had_liked":false,"id":205800,"user_name":"冬风向左吹","can_delete":false,"product_type":"c1","uid":1066928,"ip_address":"","ucode":"376C45C5134F93","user_header":"https://static001.geekbang.org/account/avatar/00/10/47/b0/a9b77a1e.jpg","comment_is_top":false,"comment_ctime":1586741821,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1586741821","product_id":100020801,"comment_content":"总感觉两阶段提交没有介绍完整。<br>1、prepare阶段，写了redo log，尚未落盘；<br>2、写binlog日志；<br>3、执行redo log的commit。<br>问题是：第2步的写的binlog日志是个什么状态，此时能同步到slave节点吗。我理解，因为没有执行第3步，所以是不能同步到slave的。如果这样，执行第3步后，那岂不是还需要记一次binlog的commit日志，如果此时服务器挂了呢，这个binlog的commit没记成功呢？","like_count":0},{"had_liked":false,"id":202780,"user_name":"浮生醉","can_delete":false,"product_type":"c1","uid":1783354,"ip_address":"","ucode":"7549E41BD65511","user_header":"https://static001.geekbang.org/account/avatar/00/1b/36/3a/335db90a.jpg","comment_is_top":false,"comment_ctime":1586068011,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1586068011","product_id":100020801,"comment_content":"老师说binlog是不能被打断的<br>那么为什么binlog是不能被打断的？<br>我的理解:因为binlog是逻辑日志，如果一个事务被打断了，那么在从库执行的时候会出现数据不一致的问题<br><br>那么如果两个事务的执行顺序换了呢?<br>我的理解:<br>在RR的隔离机制下，如果两个事务同时对一个表的行记录进行修改，那么后申请锁的SQL(事务B）会等待，等另一个事务(事务A)先执行完成释放锁然后才会继续执行。在binlog里事务A会在前面,不会出现顺序不正确的情形<br><br>那么在RC的隔离级别下:<br>有没有可能出现上述Bin log顺序不对的问题","like_count":0},{"had_liked":false,"id":187555,"user_name":"ipofss","can_delete":false,"product_type":"c1","uid":1018620,"ip_address":"","ucode":"DE3061C9259F9E","user_header":"https://static001.geekbang.org/account/avatar/00/0f/8a/fc/d1dd57dd.jpg","comment_is_top":false,"comment_ctime":1584157604,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1584157604","product_id":100020801,"comment_content":"小结中的问题4，我觉得有点体会。之前在与一个同事对接，我用的Java，他用的.net，他调用我的接口，然后说收不到成功的结果，就认为是失败。我觉得他收到成功，就一定是成功；收到失败就一定是失败；如果收不到结果，或者异常，就有可能是网络的问题，需要重新查一次，看看是否需要再调用一次。而且我的接口要保证幂等性。同理于问题4，对于外界调用的数据库服务，只要数据库内部，和主备数据库之间能保证数据一致性就可以了，不需要关注业务层的调用，业务层再来查一次看看是否成功就行了。","like_count":0},{"had_liked":false,"id":179561,"user_name":"斐波那契","can_delete":false,"product_type":"c1","uid":1464006,"ip_address":"","ucode":"85E2EBC01392B1","user_header":"https://static001.geekbang.org/account/avatar/00/16/56/c6/0b449bc6.jpg","comment_is_top":false,"comment_ctime":1582031841,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1582031841","product_id":100020801,"comment_content":"老师 问个问题 我的理解是 在redo log或者bin log写入page cache时 就进入了操作系统层面 那fsync应该有操作系统决定 那这个跟mysql什么关系呢?","like_count":0},{"had_liked":false,"id":178532,"user_name":"凌云","can_delete":false,"product_type":"c1","uid":1028756,"ip_address":"","ucode":"A092ACE7FA40DF","user_header":"https://static001.geekbang.org/account/avatar/00/0f/b2/94/6111101d.jpg","comment_is_top":false,"comment_ctime":1581735990,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1581735990","product_id":100020801,"comment_content":"通常我们说 MySQL 的“双 1”配置，指的就是 sync_binlog 和 innodb_flush_log_at_trx_commit 都设置成 1。也就是说，一个事务完整提交前，需要等待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog。<br>-----redo log 和 binlog 刷盘的时刻点应该都是在事务提交的时候，因此&quot;redo log（prepare 阶段）&quot; 是否应该修改为 redo log commit阶段。","like_count":0},{"had_liked":false,"id":174417,"user_name":"RedDevil","can_delete":false,"product_type":"c1","uid":1131128,"ip_address":"","ucode":"F8F5DC209BB3B9","user_header":"https://static001.geekbang.org/account/avatar/00/11/42/78/7ba89c75.jpg","comment_is_top":false,"comment_ctime":1580201050,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1580201050","product_id":100020801,"comment_content":"老师关于redo log写盘策略我有个疑问<br>在文中，您提到了 innodb_flush_log_at_trx_commit 参数，它有三种可能取值设置为 1 的时候，表示每次事务提交时都将 redo log 直接fsync到磁盘；<br>但是在后续内容，您又指出 innodb_flush_log_at_trx_commit 设置为1时，在redo log prepare阶段就会fsync到磁盘；<br>这里我不太明白，innodb_flush_log_at_trx_commit 参数影响的是redolog prepare阶段还是commit阶段？","like_count":0},{"had_liked":false,"id":172353,"user_name":"板栗饼","can_delete":false,"product_type":"c1","uid":1405020,"ip_address":"","ucode":"2DA25B053D7721","user_header":"https://static001.geekbang.org/account/avatar/00/15/70/5c/ebb274eb.jpg","comment_is_top":false,"comment_ctime":1579159533,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1579159533","product_id":100020801,"comment_content":"老师好，文中有个地方一直理解不了：图五下面说:<br>不过通常情况下第 3 步执行得会很快，所以 binlog 的 write 和 fsync 间的间隔时间短，导致能集合到一起持久化的 binlog 比较少，因此 binlog 的组提交的效果通常不如 redo log 的效果那么好。<br><br>按照图5，步骤3是redo log落盘，步骤2是bin log write到paper cache,按照这边的逻辑，应该是步骤3落盘执行的比较慢，bin log的write和fsync之间时间更长一点，组提交效果更好吧，还是有其他影响因素呢。","like_count":0},{"had_liked":false,"id":171941,"user_name":"最初的印象","can_delete":false,"product_type":"c1","uid":1228852,"ip_address":"","ucode":"4DD68307FA274E","user_header":"https://static001.geekbang.org/account/avatar/00/12/c0/34/0574bb44.jpg","comment_is_top":false,"comment_ctime":1579056150,"is_pvip":false,"replies":[{"id":"66715","content":"page cache是操作系统用来缓存读写文件的机制。<br>可以搜一下 “文件系统 page cache”","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1579088612,"ip_address":"","comment_id":171941,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1579056150","product_id":100020801,"comment_content":"可以稍微介绍一下page cache吗，感觉对这个东西不是很清楚。","like_count":0,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":481555,"discussion_content":"page cache是操作系统用来缓存读写文件的机制。\n可以搜一下 “文件系统 page cache”","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1579088612,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":171938,"user_name":"最初的印象","can_delete":false,"product_type":"c1","uid":1228852,"ip_address":"","ucode":"4DD68307FA274E","user_header":"https://static001.geekbang.org/account/avatar/00/12/c0/34/0574bb44.jpg","comment_is_top":false,"comment_ctime":1579055662,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1579055662","product_id":100020801,"comment_content":"如 redo log 写到 page cache，但还没有进行fsync此时数据库异常关闭，重启后数据会不会丢失？","like_count":0},{"had_liked":false,"id":170303,"user_name":"意琦行","can_delete":false,"product_type":"c1","uid":1310737,"ip_address":"","ucode":"07E7D1031DAC01","user_header":"https://static001.geekbang.org/account/avatar/00/14/00/11/fd201938.jpg","comment_is_top":false,"comment_ctime":1578564018,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1578564018","product_id":100020801,"comment_content":"将 innodb_flush_log_at_trx_commit 设置为 2。这样做的风险是，主机掉电的时候会丢数据。<br>=======<br>请教下老师，如果服务器安装了raid电容卡，是否可以规避设置为2主机掉电丢失数据的风险？","like_count":0},{"had_liked":false,"id":169883,"user_name":"88591","can_delete":false,"product_type":"c1","uid":1254656,"ip_address":"","ucode":"04CE3E46455185","user_header":"https://static001.geekbang.org/account/avatar/00/13/25/00/3afbab43.jpg","comment_is_top":false,"comment_ctime":1578468037,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1578468037","product_id":100020801,"comment_content":"这就是理论与实践的差异。理论上面要求 数据是持久化的。但是实现过程中，还的权衡性能。如果想持久化 一定成功，那么就的牺牲性能。不同业务场景使用方式不一样。","like_count":0},{"had_liked":false,"id":167660,"user_name":"Danpier","can_delete":false,"product_type":"c1","uid":1463474,"ip_address":"","ucode":"11E208FDE34961","user_header":"https://static001.geekbang.org/account/avatar/00/16/54/b2/5ea0b709.jpg","comment_is_top":false,"comment_ctime":1577888378,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1577888378","product_id":100020801,"comment_content":"“但是，将 sync_binlog 设置为 N，对应的风险是：如果主机发生异常重启，会丢失最近 N 个事务的 binlog 日志。”<br>这个表述是不是有问题？主机异常重启时，binlog cache 最多有 N-1 个事务 binlog 日志，所以应该是丢失的事务 binlog 日志不超过 N-1 吧？<br>","like_count":0},{"had_liked":false,"id":167316,"user_name":"阿杜","can_delete":false,"product_type":"c1","uid":1066705,"ip_address":"","ucode":"349D3572F5ABE7","user_header":"https://static001.geekbang.org/account/avatar/00/10/46/d1/a1ddf49f.jpg","comment_is_top":false,"comment_ctime":1577762352,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1577762352","product_id":100020801,"comment_content":"redo log,binlog 都是先写入page cache，然后批量写入磁盘","like_count":0},{"had_liked":false,"id":167145,"user_name":"李瞳","can_delete":false,"product_type":"c1","uid":1212029,"ip_address":"","ucode":"7407B4D49D793B","user_header":"https://static001.geekbang.org/account/avatar/00/12/7e/7d/f54bfa0b.jpg","comment_is_top":false,"comment_ctime":1577698325,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1577698325","product_id":100020801,"comment_content":"innodb_flush_log_at_trx_commit  = 1的时候，提交事务就写盘，还是顺序写吗？","like_count":0},{"had_liked":false,"id":159734,"user_name":"长期规划","can_delete":false,"product_type":"c1","uid":1019332,"ip_address":"","ucode":"5EF65E9115834B","user_header":"https://static001.geekbang.org/account/avatar/00/0f/8d/c4/6f97daea.jpg","comment_is_top":false,"comment_ctime":1575768496,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1575768496","product_id":100020801,"comment_content":"老师好，有个两个问题请教一下，<br>问题1：MySQL内存中的数据页会定期刷到磁盘，但如果MySQL宕机时，可能有未刷入磁盘的数据页。当重启后，磁盘读到的就是旧数据页，然后会对这些数据页重放redo log，但只重放没有刷盘的那部分，对吗？<br>问题2：redo log与内存数据页的数据始终是一致的，对吗<br>","like_count":0},{"had_liked":false,"id":156425,"user_name":"jian","can_delete":false,"product_type":"c1","uid":1185102,"ip_address":"","ucode":"21CDBBB8000F0C","user_header":"https://static001.geekbang.org/account/avatar/00/12/15/4e/4636a81d.jpg","comment_is_top":false,"comment_ctime":1574869717,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1574869717","product_id":100020801,"comment_content":"“问题 2：为什么 binlog cache 是每个线程自己维护的，而 redo log buffer 是全局共用的？回答：MySQL 这么设计的主要原因是，binlog 是不能“被打断的”。”请问老师，这里说binlog不能打断，是不是为了从库执行binlog的顺序需要和主库的保持一致？","like_count":0},{"had_liked":false,"id":150807,"user_name":"helloworld","can_delete":false,"product_type":"c1","uid":1015754,"ip_address":"","ucode":"00DF2FEC58D2E6","user_header":"https://static001.geekbang.org/account/avatar/00/0f/7f/ca/ea85bfdd.jpg","comment_is_top":false,"comment_ctime":1573612497,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1573612497","product_id":100020801,"comment_content":"位于系统的 page cache中的数据，当系统重启后数据会丢失吗？","like_count":0,"discussions":[{"author":{"id":1111037,"avatar":"https://static001.geekbang.org/account/avatar/00/10/f3/fd/ca3a1b4a.jpg","nickname":"nofrish","note":"","ucode":"8A5A47FE242891","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":300364,"discussion_content":"page cache是内存，所以系统重启后数据会丢失的\n我感觉最后那个地方讲的也有点奇怪，从可靠性方面来说，写入page cache和写入redo log buffer应该没有本质区别，为什么就说写入page cache就可以保证数据不丢失呢？","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1598065002,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":143192,"user_name":"我不吃甜食","can_delete":false,"product_type":"c1","uid":1086808,"ip_address":"","ucode":"1718E6D78F2852","user_header":"https://static001.geekbang.org/account/avatar/00/10/95/58/95e9507d.jpg","comment_is_top":false,"comment_ctime":1571644829,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1571644829","product_id":100020801,"comment_content":"更新后的数据是不是在redo log的commit阶段写入磁盘？","like_count":0},{"had_liked":false,"id":132770,"user_name":"later","can_delete":false,"product_type":"c1","uid":1621789,"ip_address":"","ucode":"1F7844D991C26F","user_header":"https://thirdwx.qlogo.cn/mmopen/vi_32/djAZwFHFWrjZgM22hCOKw8qweicSvWGjj0ExbM521pfMtufATMNzG4tdK89m6wUJZzxXtbXFkianIJdaMzW0qPDQ/132","comment_is_top":false,"comment_ctime":1568216416,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1568216416","product_id":100020801,"comment_content":"老师是不是只要没有进行fsync操作之前，异常断电，是不是都会造成数据丢失","like_count":0},{"had_liked":false,"id":131549,"user_name":"Geek_b74670","can_delete":false,"product_type":"c1","uid":1649282,"ip_address":"","ucode":"083AF837FB0112","user_header":"https://wx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLGAV2NgUo0VVNjiagIJCZmPHvogtAJcUib6icLCbR4vcvfziashHZjpZ0FUxSdawFnHGUSmIaePvDaWQ/132","comment_is_top":false,"comment_ctime":1567790048,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1567790048","product_id":100020801,"comment_content":"图5两阶段提交细化流程图中，步骤2中是binlog日志是由binlog cache写入了图1中的bin log files不？步骤1是redo log日志由redo log buffer写入了fs page cache不？","like_count":0},{"had_liked":false,"id":131540,"user_name":"Yann","can_delete":false,"product_type":"c1","uid":1005761,"ip_address":"","ucode":"A2778D84359D65","user_header":"https://static001.geekbang.org/account/avatar/00/0f/58/c1/ecf857d4.jpg","comment_is_top":false,"comment_ctime":1567787205,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1567787205","product_id":100020801,"comment_content":"老师好，如果 sync_binlog=0 , innodb_flush_log_at_trx_commit = 2 , binlog_group_commit_sync_delay = 0, binlog_group_commit_sync_no_delay_count = 0,情况下只有每秒后台每秒轮循下会持久化到磁盘中，但由于进程调度策略并不会每次都会100%的“每秒”， 如果在下一秒刷磁盘前正常关闭mysql,在关闭前mysql会执行一次持久化磁盘操作吗","like_count":0},{"had_liked":false,"id":131535,"user_name":"Yann","can_delete":false,"product_type":"c1","uid":1005761,"ip_address":"","ucode":"A2778D84359D65","user_header":"https://static001.geekbang.org/account/avatar/00/0f/58/c1/ecf857d4.jpg","comment_is_top":false,"comment_ctime":1567785429,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1567785429","product_id":100020801,"comment_content":"mysql sever正常stop前会将page cache 持久化到磁盘吗","like_count":0},{"had_liked":false,"id":130706,"user_name":"heyman","can_delete":false,"product_type":"c1","uid":1173894,"ip_address":"","ucode":"92EF9EF1B1B1B3","user_header":"https://static001.geekbang.org/account/avatar/00/11/e9/86/d34800a4.jpg","comment_is_top":false,"comment_ctime":1567514944,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1567514944","product_id":100020801,"comment_content":"老师您好。看了你的一个回复：<br><br>「说明一下哈，所谓的 redo log prepare，是“当前事务提交”的一个阶段，也就是说，在事务A提交的时候，我们才会走到事务A的redo log prepare这个阶段。<br><br>事务A在提交前，有一部分redo log被事务B提前持久化，但是事务A还没有进入提交阶段，是无所谓“redo log prepare”的。」<br><br>不是很明白，“事务A在提交前，有一部分redo log被事务B提前持久化，但是事务A还没有进入提交阶段，是无所谓“redo log prepare”的”，既不是prepare ，又不是commit，那是另一种没有提到的状态吗？<br><br>假如这时事务A回滚了，它这些已经持久化的redo log怎么处理呢？<br><br>","like_count":0},{"had_liked":false,"id":127998,"user_name":"马以","can_delete":false,"product_type":"c1","uid":1344431,"ip_address":"","ucode":"3FEA06CA14DE28","user_header":"https://static001.geekbang.org/account/avatar/00/14/83/af/1cb42cd3.jpg","comment_is_top":false,"comment_ctime":1566818795,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1566818795","product_id":100020801,"comment_content":"binlog file也是一块内存单元吗？如果是为什么要增加这一块内存呢？感觉这样很消耗内存，如果不是内存为什么不直接写磁盘呢？","like_count":0},{"had_liked":false,"id":116262,"user_name":"愚人","can_delete":false,"product_type":"c1","uid":1355952,"ip_address":"","ucode":"40DE41849EF9EA","user_header":"https://static001.geekbang.org/account/avatar/00/14/b0/b0/30b29949.jpg","comment_is_top":false,"comment_ctime":1563809594,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1563809594","product_id":100020801,"comment_content":"组提交场景下，如果事务rollback该如何处理redo log？","like_count":0,"discussions":[{"author":{"id":1065351,"avatar":"https://static001.geekbang.org/account/avatar/00/10/41/87/d26efb2e.jpg","nickname":"SuperSnow","note":"","ucode":"84C89AA8083E6A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":165041,"discussion_content":"也应该是回滚吧。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1581250745,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":108425,"user_name":"微笑","can_delete":false,"product_type":"c1","uid":1363834,"ip_address":"","ucode":"6E8E2964D0191F","user_header":"https://static001.geekbang.org/account/avatar/00/14/cf/7a/51951b07.jpg","comment_is_top":false,"comment_ctime":1561770428,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1561770428","product_id":100020801,"comment_content":"老师好  redo commit阶段将redo更新为commit状态是什么时候刷盘","like_count":0,"discussions":[{"author":{"id":1065351,"avatar":"https://static001.geekbang.org/account/avatar/00/10/41/87/d26efb2e.jpg","nickname":"SuperSnow","note":"","ucode":"84C89AA8083E6A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":165043,"discussion_content":"看策略，文中有。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1581250801,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":107326,"user_name":"老江","can_delete":false,"product_type":"c1","uid":1303409,"ip_address":"","ucode":"7033BBF9AF43A9","user_header":"https://static001.geekbang.org/account/avatar/00/13/e3/71/45eb3475.jpg","comment_is_top":false,"comment_ctime":1561514903,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1561514903","product_id":100020801,"comment_content":"关于IO问题，还有一些方式可以考虑：<br>1）分析请求SQL，性能是否合理，是否有影响性能<br>2）业务请求是否合理，是否空跑一些冗余请求<br>3）好的机器","like_count":0},{"had_liked":false,"id":106404,"user_name":"搞怪者😘 😒 😏 👿","can_delete":false,"product_type":"c1","uid":1300678,"ip_address":"","ucode":"40DFF5D3E3B24C","user_header":"https://static001.geekbang.org/account/avatar/00/13/d8/c6/2b2a58cf.jpg","comment_is_top":false,"comment_ctime":1561291095,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1561291095","product_id":100020801,"comment_content":"假设一个事务有两条sql语句，sql1和sql2，写redo log的时候是不是当sql1先执行完写进redo log buffer，sql2执行完又写入redo log buffer一次，还是等全部完成再写入","like_count":0},{"had_liked":false,"id":99766,"user_name":"Tunayoyo","can_delete":false,"product_type":"c1","uid":1447213,"ip_address":"","ucode":"E77AFDE575CE04","user_header":"https://static001.geekbang.org/account/avatar/00/16/15/2d/8447e8c8.jpg","comment_is_top":false,"comment_ctime":1559294738,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1559294738","product_id":100020801,"comment_content":"innodb_flush_log_at_trx_commit =1，并行事务提交，log怎么还有在buffer里面的情况？不是直接持久化到磁盘吗？","like_count":0,"discussions":[{"author":{"id":1065351,"avatar":"https://static001.geekbang.org/account/avatar/00/10/41/87/d26efb2e.jpg","nickname":"SuperSnow","note":"","ucode":"84C89AA8083E6A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":165044,"discussion_content":"总得容个时间处理","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1581250865,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":95169,"user_name":"Lane","can_delete":false,"product_type":"c1","uid":1008257,"ip_address":"","ucode":"F70459D1BBD9F4","user_header":"https://static001.geekbang.org/account/avatar/00/0f/62/81/ad80f427.jpg","comment_is_top":false,"comment_ctime":1557977258,"is_pvip":true,"discussion_count":0,"race_medal":0,"score":"1557977258","product_id":100020801,"comment_content":"疑问：<br>老师说  设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 会导致延迟但是不会丢失。<br>这个参数是延迟fsync的时机，那么write后未fsync，宕机，不还是会丢吗？","like_count":0},{"had_liked":false,"id":91961,"user_name":"liao xueqiang","can_delete":false,"product_type":"c1","uid":1310325,"ip_address":"","ucode":"68713441579F6B","user_header":"https://static001.geekbang.org/account/avatar/00/13/fe/75/46742f12.jpg","comment_is_top":false,"comment_ctime":1557145710,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1557145710","product_id":100020801,"comment_content":"老师好，这个问题，我想了很久，还是没能理解下面这句话，也给您就这个问题留了好几次言。<br>每秒一次后台轮询刷盘，再加上崩溃恢复这个逻辑，InnoDB就认为 redo log 在 commit 的时候就不需要fsync 了，只会 write 到文件系统的 page cache 中就够了。<br><br>如果只写到redo log只写到了page cache中，那服务器重启，不就没有了这一秒的redo log的信息了。没有了这一秒的redo log的信息怎么实现奔溃恢复呢？奔溃恢复需要redo log和binlog，没有了redo log，光有binlog，怎么接续起来呢？","like_count":0,"discussions":[{"author":{"id":1702886,"avatar":"https://static001.geekbang.org/account/avatar/00/19/fb/e6/1b9edb91.jpg","nickname":"练习生","note":"","ucode":"60203A2AA0EA36","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":293994,"discussion_content":"redolog进入prepare阶段时就已经持久化到磁盘了，所以不会出现仅有Binlog的情况","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1595754882,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":90715,"user_name":"Break","can_delete":false,"product_type":"c1","uid":1508922,"ip_address":"","ucode":"6D1CCFC60E11EF","user_header":"https://static001.geekbang.org/account/avatar/00/17/06/3a/68bed1d9.jpg","comment_is_top":false,"comment_ctime":1556615840,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1556615840","product_id":100020801,"comment_content":"&lt;li&gt;图中的 write，指的就是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快。&lt;&#47;li&gt;<br><br>如果把sync_binlog设置为0, 那么就永远不会持久化到磁盘吗? 这样没问题吗? 但是我看评论里又说page  cache也是文件系统, 那么就是放在磁盘的? 那还是变成写入到磁盘啊......","like_count":0},{"had_liked":false,"id":85230,"user_name":"杨春鹏","can_delete":false,"product_type":"c1","uid":1172056,"ip_address":"","ucode":"518F38232F97B5","user_header":"https://static001.geekbang.org/account/avatar/00/11/e2/58/8c8897c8.jpg","comment_is_top":false,"comment_ctime":1555024087,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1555024087","product_id":100020801,"comment_content":"Redolog的prepare阶段的fsync过程，不是已经把事务持久化到磁盘了吗？那么redolog的commit状态还有用吗？","like_count":0,"discussions":[{"author":{"id":1702886,"avatar":"https://static001.geekbang.org/account/avatar/00/19/fb/e6/1b9edb91.jpg","nickname":"练习生","note":"","ucode":"60203A2AA0EA36","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":293991,"discussion_content":"有用，崩溃恢复的时候有作用。如果发现事务有完整的prepare阶段的redolog,并且有commit标记，就直接认为事务提交了做相应数据的更改，否则的话还要拿xid去binlog文件找是否有无完成的binlog","likes_number":1,"is_delete":false,"is_hidden":false,"ctime":1595754751,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":84369,"user_name":"liao xueqiang","can_delete":false,"product_type":"c1","uid":1310325,"ip_address":"","ucode":"68713441579F6B","user_header":"https://static001.geekbang.org/account/avatar/00/13/fe/75/46742f12.jpg","comment_is_top":false,"comment_ctime":1554855529,"is_pvip":false,"discussion_count":1,"race_medal":0,"score":"1554855529","product_id":100020801,"comment_content":"每秒一次后台轮询刷盘，再加上崩溃恢复这个逻辑，InnoDB 就认为 redo log 在 commit 的时候就不需要 fsync 了，只会 write 到文件系统的 page cache 中就够了。<br><br>老师，这句话单独拎出来无法理解，重启服务器会丢1秒数据啊。这句话的前提是不是innodb_flush_log_at_trx_commit=1","like_count":0,"discussions":[{"author":{"id":1702886,"avatar":"https://static001.geekbang.org/account/avatar/00/19/fb/e6/1b9edb91.jpg","nickname":"练习生","note":"","ucode":"60203A2AA0EA36","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":293990,"discussion_content":"这时丢的只是commit阶段的redolog,prepare阶段的redolog已经持久化道磁盘了，接下来做数据奔溃恢复仍然是没问题的，只是由于少了commit阶段的relog，可能恢复的过程会慢点，因为要拿xid去Binlog文件中查找匹配的binlog","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1595754482,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":84252,"user_name":"清风浊酒","can_delete":false,"product_type":"c1","uid":1302407,"ip_address":"","ucode":"4BB111C61A40C4","user_header":"https://static001.geekbang.org/account/avatar/00/13/df/87/0e05dadd.jpg","comment_is_top":false,"comment_ctime":1554813026,"is_pvip":false,"replies":[{"id":"30752","content":"要看你的ha策略哦<br><br>考虑数据可靠性，一般还是要的<br>","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1555147464,"ip_address":"","comment_id":84252,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1554813026","product_id":100020801,"comment_content":"老师，mgr环境还有必要设置双一吗？","like_count":0,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":446294,"discussion_content":"要看你的ha策略哦\n\n考虑数据可靠性，一般还是要的\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1555147464,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":76262,"user_name":"一梦如是","can_delete":false,"product_type":"c1","uid":1305308,"ip_address":"","ucode":"9CCB1D0E547C83","user_header":"https://static001.geekbang.org/account/avatar/00/13/ea/dc/9a970e98.jpg","comment_is_top":false,"comment_ctime":1552560438,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1552560438","product_id":100020801,"comment_content":"Binlog的是不是组提交，和redo log的组提交有必然联系吗？这块没太明白。测试的时候binlog里面的last_commited值有的相同有的不相同。如果last_commited值相同，是不是意味着redo log里这几个事务也必须是组提交的呢","like_count":0},{"had_liked":false,"id":75592,"user_name":"Snake","can_delete":false,"product_type":"c1","uid":1034894,"ip_address":"","ucode":"C3E80DE87EACD1","user_header":"https://static001.geekbang.org/account/avatar/00/0f/ca/8e/5768649e.jpg","comment_is_top":false,"comment_ctime":1552438506,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1552438506","product_id":100020801,"comment_content":"老师，请问文中说到的binlog_cache和redo_log_buffer是是针对一个数据库实例的，还是针对实际下具体某一个库的？如果针对是针对实例，那么有没有哪些配置或者机制是针对库的呢？","like_count":0},{"had_liked":false,"id":60722,"user_name":"似水流年","can_delete":false,"product_type":"c1","uid":1304443,"ip_address":"","ucode":"D114A8E273133C","user_header":"https://static001.geekbang.org/account/avatar/00/13/e7/7b/71da8283.jpg","comment_is_top":false,"comment_ctime":1547537456,"is_pvip":false,"replies":[{"id":"21670","content":"就是文件系统的page cache，是属于操作系统的内存的一部分","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1547551926,"ip_address":"","comment_id":60722,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1547537456","product_id":100020801,"comment_content":"我网上查pagecache是在内存里的，这与您讲的一样吗？","like_count":0,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":436598,"discussion_content":"就是文件系统的page cache，是属于操作系统的内存的一部分","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1547551926,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":2028635,"avatar":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKawxntLfibLJJmbicIiczetxQBOsn8uNTbNBANje21Chiay38FiaA43CuY7sxLQp12ghDvWXghNTXrGNQ/132","nickname":"Geek_f40120","note":"","ucode":"7EF9C529B7AE9A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":279705,"discussion_content":"操作系统的内存，那岂不是断电就没有了","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1591400986,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":57832,"user_name":"Mr.Strive.Z.H.L","can_delete":false,"product_type":"c1","uid":1030198,"ip_address":"","ucode":"6D97E159E2EECD","user_header":"https://static001.geekbang.org/account/avatar/00/0f/b8/36/542c96bf.jpg","comment_is_top":false,"comment_ctime":1546920979,"is_pvip":false,"replies":[{"id":"21113","content":"写binlog可以并发写的，大家约好磁盘自己写自己的就行^_^","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1547118722,"ip_address":"","comment_id":57832,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1546920979","product_id":100020801,"comment_content":"老师你好：<br>这一节的疑惑比较多，嘻嘻<br>还想在确认一个问题：<br>我认为redolog的组提交 是从write开始的组提交。个人认为write到pagecache的时候是不需要加锁的。<br>而binlog的组提交，在write阶段，都是单线程对自己的binlog cache write到pagecache。这个时候必须加锁。虽然sync阶段，两者都是批量进行的。但是从write阶段来看，binlog并没有实现真正意义上实现组提交，没法解决上锁问题。（在网上看到，binlog真正的组提交，分为三个阶段，每个阶段一个队列，这种实现好像是比较新的mysql版本才使用的）<br><br>我这么理解对吗？","like_count":0,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435782,"discussion_content":"写binlog可以并发写的，大家约好磁盘自己写自己的就行^_^","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1547118722,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":57408,"user_name":"52rock","can_delete":false,"product_type":"c1","uid":1025632,"ip_address":"","ucode":"3C4376A8EAAEF6","user_header":"https://static001.geekbang.org/account/avatar/00/0f/a6/60/0eac2751.jpg","comment_is_top":false,"comment_ctime":1546782865,"is_pvip":true,"replies":[{"id":"20684","content":"删除了什么log后正常的？<br>","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1546798077,"ip_address":"","comment_id":57408,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1546782865","product_id":100020801,"comment_content":"老师好，windows系统下MySQL偶尔有坏库的情况，恢复数据比较麻烦，有什么配置可以优化<br>1.某个表提示打不开，也无法重建表<br>2.mysql无法启动 1067<br>3.binlog日志文件无法写入，删了log文件后正常。<br><br>my.ini配置如下<br>[mysqld]<br># use 5.6.20<br>[mysqld]<br>bind-address = 0.0.0.0<br>character-set-server=utf8<br>log-bin=my.bin<br>binlog_format=statement<br>server-id=1<br><br>#不需要同步的库<br>binlog-ignore-db=information_schema<br>binlog-ignore-db=performance_schema<br>binlog-ignore-db=mysql<br><br>max_connect_errors = 3000<br>wait_timeout=2880000<br>interactive_timeout=2880000<br><br>query_cache_size = 0<br>query_cache_type = 0<br><br>sql-mode=NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION<br><br>max_allowed_packet =256MB<br>read_buffer_size = 8M<br>read_rnd_buffer_size = 16M<br>lower_case_table_names = 1<br>key_buffer_size = 15M<br><br>table_open_cache = 400<br>table_definition_cache = 400<br>table_open_cache_instances = 64<br>metadata_locks_hash_instances=64<br><br>sort_buffer_size = 16M<br>join_buffer_size = 16M<br>thread_cache_size = 768<br>query_cache_size = 0<br>query_cache_type = 0<br>tmp_table_size = 96M<br>performance_schema=OFF<br>open_files_limit = 65535<br>back_log = 1024<br><br>innodb_buffer_pool_size=800MB<br># 4MB-8MB ok<br>innodb_file_per_table = 1                                               <br>external-locking = FALSE<br>#skip-external-locking<br>expire_logs_days=45<br>max_binlog_size=200M<br>skip-name-resolve=OFF<br>transaction-isolation=repeatable-read<br>log_warnings=0","like_count":0,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435565,"discussion_content":"删除了什么log后正常的？\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1546798077,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":57404,"user_name":"滔滔","can_delete":false,"product_type":"c1","uid":1303342,"ip_address":"","ucode":"6968B5771AF79D","user_header":"https://static001.geekbang.org/account/avatar/00/13/e3/2e/77ad18f4.jpg","comment_is_top":false,"comment_ctime":1546781987,"is_pvip":false,"replies":[{"id":"20683","content":"嗯，这样很快的","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1546797953,"ip_address":"","comment_id":57404,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1546781987","product_id":100020801,"comment_content":"老师，想请教一个问题，想从一个有自增主键(id)的表中取出主键值最大的n条记录，怎样操作效率最高呢？使用order by id limit n是最快的方式吗？🤔","like_count":0,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435564,"discussion_content":"嗯，这样很快的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1546797953,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1065351,"avatar":"https://static001.geekbang.org/account/avatar/00/10/41/87/d26efb2e.jpg","nickname":"SuperSnow","note":"","ucode":"84C89AA8083E6A","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":165046,"discussion_content":"得加一个DESC吧。","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1581251061,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":57063,"user_name":"Justin","can_delete":false,"product_type":"c1","uid":1305601,"ip_address":"","ucode":"D49723FEA66731","user_header":"https://static001.geekbang.org/account/avatar/00/13/ec/01/978d54af.jpg","comment_is_top":false,"comment_ctime":1546611871,"is_pvip":false,"replies":[{"id":"20579","content":"不会出问题，LSN确保不会二次执行<br>","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1546618465,"ip_address":"","comment_id":57063,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1546611871","product_id":100020801,"comment_content":"还有一个问题 checkpoint之后的redo log一定是还未flush的嘛？ 如果不是的话，如果机器坏了重启 从checkpoint之后重新执行redo log 看到已经flush过的页 不会出问题吗？","like_count":0,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435386,"discussion_content":"不会出问题，LSN确保不会二次执行\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1546618465,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":57062,"user_name":"朱月俊","can_delete":false,"product_type":"c1","uid":1017707,"ip_address":"","ucode":"4DA0728B862FBD","user_header":"https://static001.geekbang.org/account/avatar/00/0f/87/6b/0b6cd39a.jpg","comment_is_top":false,"comment_ctime":1546611746,"is_pvip":false,"discussion_count":0,"race_medal":0,"score":"1546611746","product_id":100020801,"comment_content":"请教一个问题，插入一条语句的时候，返回这条记录的自增id。","like_count":0},{"had_liked":false,"id":57052,"user_name":"nero","can_delete":false,"product_type":"c1","uid":1110627,"ip_address":"","ucode":"BACD4A95B5FA09","user_header":"https://static001.geekbang.org/account/avatar/00/10/f2/63/1f495e51.jpg","comment_is_top":false,"comment_ctime":1546609758,"is_pvip":false,"replies":[{"id":"20577","content":"没事😄","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1546615177,"ip_address":"","comment_id":57052,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1546609758","product_id":100020801,"comment_content":"老师请教下：<br>事务还没提交的时候，redo log buffer 中的部分日志有可能被持久化到磁盘，这不会有什么问题吗？","like_count":0,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435380,"discussion_content":"没事😄","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1546615177,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":57037,"user_name":"朱月俊","can_delete":false,"product_type":"c1","uid":1017707,"ip_address":"","ucode":"4DA0728B862FBD","user_header":"https://static001.geekbang.org/account/avatar/00/0f/87/6b/0b6cd39a.jpg","comment_is_top":false,"comment_ctime":1546605791,"is_pvip":false,"replies":[{"id":"20562","content":"还没有这个语法，这个是要return 啥呢…","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1546608499,"ip_address":"","comment_id":57037,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1546605791","product_id":100020801,"comment_content":"请教一个问题，mysql支持insert into xxx returning xxx;吗？ ","like_count":0,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435371,"discussion_content":"还没有这个语法，这个是要return 啥呢…","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1546608499,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":56954,"user_name":"夹心面包","can_delete":false,"product_type":"c1","uid":1301957,"ip_address":"","ucode":"002BBA49D83D17","user_header":"http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJCscgdVibmoPyRLRaicvk6rjTJxePZ6VFHvGjUQvtfhCS6kO4OZ1AVibbhNGKlWZmpEFf2yA6ptsqHw/132","comment_is_top":false,"comment_ctime":1546586182,"is_pvip":false,"replies":[{"id":"21098","content":"看看是不是 log_queries_not_using_indexes设置成on了？<br><br>还有看看long_query_time 设置的是多少<br><br>再贴个慢查询日志的例子看看哈<br>","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1547116922,"ip_address":"","comment_id":56954,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1546586182","product_id":100020801,"comment_content":"老师,请教一个与本课无关的案例,环境是每天生成一张表,每个月一个库,每天的数据量不固定,但是都是热数据,都有可能被查询.随着数据量的增多,负载持续升高.慢日志出现很多扫描几千行的语句.cpu使用率很低,iowait为5-10,buffer_pool命中率还是100%.磁盘在压力大时候处于繁忙状态.是否可以认为,压力在于磁盘瓶颈(磁盘配置8块7200转组成的raid10),但是iowait并非很高,命中100% 不能理解,","like_count":0,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435327,"discussion_content":"看看是不是 log_queries_not_using_indexes设置成on了？\n\n还有看看long_query_time 设置的是多少\n\n再贴个慢查询日志的例子看看哈\n","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1547116922,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":56873,"user_name":"令狐少侠","can_delete":false,"product_type":"c1","uid":1334516,"ip_address":"","ucode":"36390E67AF0779","user_header":"https://static001.geekbang.org/account/avatar/00/14/5c/f4/88f107d9.jpg","comment_is_top":false,"comment_ctime":1546571392,"is_pvip":false,"replies":[{"id":"20526","content":"没配就是使用默认值，show variables 命令可以看","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1546573221,"ip_address":"","comment_id":56873,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1546571392","product_id":100020801,"comment_content":"请问下sync_binlog参数在哪，为啥我的my.cnf配置项里没有，是有默认值吗？<br>port        = 3306<br>socket      = &#47;tmp&#47;mysql.sock<br>port        = 3306<br>socket      = &#47;tmp&#47;mysql.sock<br>datadir = &#47;usr&#47;local&#47;mysql&#47;var<br>skip-external-locking<br>key_buffer_size = 32M<br>max_allowed_packet = 1M<br>table_open_cache = 128<br>sort_buffer_size = 768K<br>net_buffer_length = 8K<br>read_buffer_size = 768K<br>read_rnd_buffer_size = 512K<br>myisam_sort_buffer_size = 8M<br>thread_cache_size = 16<br>query_cache_size = 16M<br>tmp_table_size = 32M<br>performance_schema_max_table_instances = 1000<br>explicit_defaults_for_timestamp = true<br>#skip-networking<br>max_connections = 500<br>max_connect_errors = 100<br>open_files_limit = 65535<br>#log-bin=mysql-bin<br>binlog_format=mixed<br>server-id   = 1<br>expire_logs_days = 10<br>#loose-innodb-trx=0<br>#loose-innodb-locks=0<br>#loose-innodb-lock-waits=0<br>#loose-innodb-cmp=0<br>#loose-innodb-cmp-per-index=0<br>#loose-innodb-cmp-per-index-reset=0<br>#loose-innodb-cmp-reset=0<br>#loose-innodb-cmpmem=0<br>#loose-innodb-cmpmem-reset=0<br>#loose-innodb-buffer-page=0<br>#loose-innodb-buffer-page-lru=0<br>#loose-innodb-buffer-pool-stats=0<br>#loose-innodb-metrics=0<br>#loose-innodb-ft-default-stopword=0<br>#loose-innodb-ft-inserted=0<br>#loose-innodb-ft-deleted=0<br>#loose-innodb-ft-being-deleted=0<br>#loose-innodb-ft-config=0<br>#loose-innodb-ft-index-cache=0<br>#loose-innodb-ft-index-table=0<br>#loose-innodb-sys-tables=0<br>#loose-innodb-sys-tablestats=0<br>#loose-innodb-sys-indexes=0<br>#loose-innodb-sys-columns=0<br>#loose-innodb-sys-fields=0<br>#loose-innodb-sys-foreign=0<br>#loose-innodb-sys-foreign-cols=0<br>default_storage_engine = InnoDB<br>innodb_file_per_table = 1<br>innodb_data_home_dir = &#47;usr&#47;local&#47;mysql&#47;var<br>innodb_data_file_path = ibdata1:10M:autoextend<br>innodb_log_group_home_dir = &#47;usr&#47;local&#47;mysql&#47;var<br>innodb_buffer_pool_size = 128M<br>innodb_log_file_size = 32M<br>innodb_log_buffer_size = 8M<br>innodb_flush_log_at_trx_commit = 1<br>innodb_lock_wait_timeout = 50<br><br>[mysqldump]<br>quick<br>max_allowed_packet = 16M<br>no-auto-rehash<br>key_buffer_size = 32M<br>sort_buffer_size = 768K<br>read_buffer = 2M<br>write_buffer = 2M<br>[mysqlhotcopy]<br>interactive-timeout<br>","like_count":0,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435290,"discussion_content":"没配就是使用默认值，show variables 命令可以看","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1546573221,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":56850,"user_name":"布衣骇客","can_delete":false,"product_type":"c1","uid":1256280,"ip_address":"","ucode":"5226B0F67090D1","user_header":"https://static001.geekbang.org/account/avatar/00/13/2b/58/11c05ccb.jpg","comment_is_top":false,"comment_ctime":1546567869,"is_pvip":false,"replies":[{"id":"20529","content":"嗯嗯，是否双1，这个性能差距效果还是比较明显的","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1546573403,"ip_address":"","comment_id":56850,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1546567869","product_id":100020801,"comment_content":"DD,打卡，未设置过这些参数。如果手动捣鼓去改变这两个参数？是否需要给做数据库压测才能看出效果呢","like_count":0,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435277,"discussion_content":"嗯嗯，是否双1，这个性能差距效果还是比较明显的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1546573403,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":56816,"user_name":"往事随风，顺其自然","can_delete":false,"product_type":"c1","uid":1235692,"ip_address":"","ucode":"F266EC6B143E38","user_header":"https://static001.geekbang.org/account/avatar/00/12/da/ec/779c1a78.jpg","comment_is_top":false,"comment_ctime":1546563863,"is_pvip":false,"replies":[{"id":"21096","content":"write 是写到page cache<br>fsync是持久化到磁盘<br>如果设置了trx_commit=0或者2 ，确实可能会丢的","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1547116718,"ip_address":"","comment_id":56816,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1546563863","product_id":100020801,"comment_content":"relog 的write 和fsync 哪个是持久化到磁盘，前面说没有提交的事物可能持久化到磁盘，后面又又说，只是在page cache 中，没有提交的事物，此时异常重启怎么办？","like_count":0,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435252,"discussion_content":"write 是写到page cache\nfsync是持久化到磁盘\n如果设置了trx_commit=0或者2 ，确实可能会丢的","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1547116718,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":56812,"user_name":"Second Sight","can_delete":false,"product_type":"c1","uid":1309199,"ip_address":"","ucode":"E979B311AA3491","user_header":"https://static001.geekbang.org/account/avatar/00/13/fa/0f/14bdda08.jpg","comment_is_top":false,"comment_ctime":1546563405,"is_pvip":false,"replies":[{"id":"20481","content":"我也这么做过😄","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1546565979,"ip_address":"","comment_id":56812,"utype":1}],"discussion_count":1,"race_medal":0,"score":"1546563405","product_id":100020801,"comment_content":"主从复制延迟过大的时候调整过双1的参数，先救火😂","like_count":0,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435249,"discussion_content":"我也这么做过😄","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1546565979,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]}]},{"had_liked":false,"id":56799,"user_name":"往事随风，顺其自然","can_delete":false,"product_type":"c1","uid":1235692,"ip_address":"","ucode":"F266EC6B143E38","user_header":"https://static001.geekbang.org/account/avatar/00/12/da/ec/779c1a78.jpg","comment_is_top":false,"comment_ctime":1546562681,"is_pvip":false,"replies":[{"id":"20475","content":" 参考你上一个问题😓","user_name":"作者回复","user_name_real":"林晓斌","uid":"1264162","ctime":1546564792,"ip_address":"","comment_id":56799,"utype":1}],"discussion_count":2,"race_medal":0,"score":"1546562681","product_id":100020801,"comment_content":"binlog cache 写入入binlog 文件，这个不就是持久化吗？后面干嘛还要fsync 持久化，不是多余","like_count":0,"discussions":[{"author":{"id":1264162,"avatar":"https://static001.geekbang.org/account/avatar/00/13/4a/22/2681d602.jpg","nickname":"林晓斌","note":"","ucode":"CDE42D44F26240","race_medal":0,"user_type":2,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":435240,"discussion_content":" 参考你上一个问题😓","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1546564792,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":true,"parent_id":0,"ip_address":""},"score":2,"extra":"{\"reply\":true,\"user_type\":2}","child_discussion_number":0,"child_discussions":[]},{"author":{"id":1702886,"avatar":"https://static001.geekbang.org/account/avatar/00/19/fb/e6/1b9edb91.jpg","nickname":"练习生","note":"","ucode":"60203A2AA0EA36","race_medal":0,"user_type":1,"is_pvip":false},"reply_author":{"id":0,"avatar":"","nickname":"","note":"","ucode":"","race_medal":0,"user_type":1,"is_pvip":false},"discussion":{"id":293985,"discussion_content":"binlog cache 持久化到binlog文件其实要经过两个步骤。第一步：先write 到磁盘的page cache（pagecache仍然在内存）中，第二步fsync 把page cache中的数据真正写到磁盘中","likes_number":0,"is_delete":false,"is_hidden":false,"ctime":1595753685,"is_liked":false,"can_delete":false,"is_complain":false,"is_top":false,"parent_id":0,"ip_address":""},"score":2,"extra":"","child_discussion_number":0,"child_discussions":[]}]}]}